#!/usr/bin/env python3
"""
DCAS è¯¾ç¨‹çŸ¥è¯†å›¾è°±å¯è§†åŒ–ç•Œé¢

åŸºäºStreamlitçš„äº¤äº’å¼Webç•Œé¢
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import json
import networkx as nx
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="DCAS è¯¾ç¨‹çŸ¥è¯†å›¾è°±",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

class CourseKnowledgeGraphDashboard:
    """è¯¾ç¨‹çŸ¥è¯†å›¾è°±å¯è§†åŒ–ä»ªè¡¨æ¿"""
    
    def __init__(self):
        self.load_data()
        
    @st.cache_data
    def load_data(_self):
        """åŠ è½½çŸ¥è¯†å›¾è°±æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
        # è‡ªåŠ¨æ£€æµ‹æ•°æ®ç›®å½•
        possible_dirs = [
            "knowledge_graph_output_production",
            "knowledge_graph_output"
        ]
        
        data_dir = None
        for dir_name in possible_dirs:
            if Path(dir_name).exists():
                data_dir = Path(dir_name)
                break
        
        if data_dir is None:
            st.error("âŒ æ‰¾ä¸åˆ°çŸ¥è¯†å›¾è°±æ•°æ®ç›®å½•")
            return None, None, None, None
        
        try:
            # åŠ è½½çŸ¥è¯†å›¾è°±
            graph_files = list((data_dir / "graphs").glob("*.pkl"))
            if graph_files:
                latest_graph_file = max(graph_files, key=lambda x: x.stat().st_mtime)
                with open(latest_graph_file, 'rb') as f:
                    graph = pickle.load(f)
            else:
                graph = None
            
            # åŠ è½½embeddings
            embedding_files = list((data_dir / "embeddings").glob("*.pkl"))
            if embedding_files:
                latest_embedding_file = max(embedding_files, key=lambda x: x.stat().st_mtime)
                with open(latest_embedding_file, 'rb') as f:
                    embedding_data = pickle.load(f)
                    embeddings = embedding_data['embeddings']
                    courses = embedding_data['courses']
                    metadata = {k: v for k, v in embedding_data.items() 
                              if k not in ['embeddings', 'courses']}
            else:
                embeddings = None
                courses = []
                metadata = {}
            
            # åŠ è½½åˆ†æç»“æœ
            analysis_files = list((data_dir / "analysis").glob("*.json"))
            if analysis_files:
                latest_analysis_file = max(analysis_files, key=lambda x: x.stat().st_mtime)
                with open(latest_analysis_file, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
            else:
                analysis_data = {}
            
            return graph, embeddings, courses, analysis_data
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None, None, None, None
    
    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.sidebar.title("ğŸ“ DCAS è¯¾ç¨‹çŸ¥è¯†å›¾è°±")
        st.sidebar.markdown("---")
        
        # æ•°æ®æ¦‚è§ˆ
        if self.courses:
            st.sidebar.markdown("### ğŸ“Š æ•°æ®æ¦‚è§ˆ")
            st.sidebar.metric("è¯¾ç¨‹æ€»æ•°", len(self.courses))
            if self.embeddings is not None:
                st.sidebar.metric("å‘é‡ç»´åº¦", self.embeddings.shape[1])
            if self.graph is not None:
                st.sidebar.metric("å›¾è°±è¿æ¥", len(self.graph.edges))
        
        st.sidebar.markdown("---")
        
        # åŠŸèƒ½é€‰æ‹©
        st.sidebar.markdown("### ğŸ” åŠŸèƒ½å¯¼èˆª")
        page = st.sidebar.selectbox(
            "é€‰æ‹©åŠŸèƒ½",
            ["ğŸ  é¦–é¡µæ¦‚è§ˆ", "ğŸ” è¯¾ç¨‹æœç´¢", "ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±", "ğŸ“Š ä¸»é¢˜åˆ†æ", "ğŸ¯ ç›¸ä¼¼åº¦åˆ†æ", "ğŸ“ˆ ç»Ÿè®¡æŠ¥å‘Š"],
            index=0
        )
        
        return page
    
    def render_home(self):
        """æ¸²æŸ“é¦–é¡µ"""
        st.title("ğŸ“ DCAS è¯¾ç¨‹çŸ¥è¯†å›¾è°±å¯è§†åŒ–å¹³å°")
        st.markdown("---")
        
        if not self.courses:
            st.error("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼Œè¯·å…ˆè¿è¡ŒçŸ¥è¯†å›¾è°±æ„å»ºè„šæœ¬")
            return
        
        # ä¸»è¦æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="ğŸ“š è¯¾ç¨‹æ€»æ•°",
                value=len(self.courses),
                delta=f"å·²å¤„ç†"
            )
        
        with col2:
            if self.embeddings is not None:
                st.metric(
                    label="ğŸ”¢ å‘é‡ç»´åº¦",
                    value=self.embeddings.shape[1],
                    delta="Qwen3-Embedding"
                )
        
        with col3:
            if self.graph is not None:
                st.metric(
                    label="ğŸ•¸ï¸ å›¾è°±è¿æ¥",
                    value=len(self.graph.edges),
                    delta=f"å¯†åº¦: {nx.density(self.graph):.3f}"
                )
        
        with col4:
            if self.analysis_data:
                unique_topics = len(self.analysis_data.get('topic_distribution', {}))
                st.metric(
                    label="ğŸ·ï¸ ä¸»é¢˜æ•°é‡",
                    value=unique_topics,
                    delta="å·²è¯†åˆ«"
                )
        
        # ä¸»é¢˜åˆ†å¸ƒå›¾è¡¨
        if self.analysis_data and 'topic_distribution' in self.analysis_data:
            st.markdown("### ğŸ“Š çƒ­é—¨ä¸»é¢˜åˆ†å¸ƒ")
            
            topic_dist = self.analysis_data['topic_distribution']
            top_topics = dict(list(topic_dist.items())[:15])
            
            fig = px.bar(
                x=list(top_topics.values()),
                y=list(top_topics.keys()),
                orientation='h',
                title="å‰15ä¸ªçƒ­é—¨ä¸»é¢˜",
                labels={'x': 'è¯¾ç¨‹æ•°é‡', 'y': 'ä¸»é¢˜'},
                color=list(top_topics.values()),
                color_continuous_scale='viridis'
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
        
        # å¿«é€Ÿæœç´¢
        st.markdown("### ğŸ” å¿«é€Ÿæœç´¢")
        search_term = st.text_input("æœç´¢è¯¾ç¨‹å…³é”®è¯", placeholder="è¾“å…¥è¯¾ç¨‹åç§°ã€ä¸»é¢˜æˆ–æè¿°å…³é”®è¯")
        
        if search_term:
            results = self.search_courses(search_term, top_k=5)
            if results:
                st.markdown(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³è¯¾ç¨‹ï¼š")
                for i, result in enumerate(results, 1):
                    with st.expander(f"{i}. {result['course_name']} (ç›¸å…³åº¦: {result['score']})"):
                        st.write(f"**ä¸»é¢˜**: {', '.join(result['topics'][:5])}")
                        st.write(f"**æè¿°**: {result['description']}")
            else:
                st.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è¯¾ç¨‹")
    
    def render_search(self):
        """æ¸²æŸ“æœç´¢é¡µé¢"""
        st.title("ğŸ” è¯¾ç¨‹æœç´¢")
        st.markdown("---")
        
        if not self.courses:
            st.error("âŒ æ²¡æœ‰æ•°æ®å¯ä¾›æœç´¢")
            return
        
        # æœç´¢é€‰é¡¹
        col1, col2 = st.columns([3, 1])
        
        with col1:
            search_query = st.text_input(
                "æœç´¢å…³é”®è¯",
                placeholder="è¾“å…¥è¯¾ç¨‹åç§°ã€ä¸»é¢˜ã€æè¿°å…³é”®è¯",
                help="æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼Œä¸åŒºåˆ†å¤§å°å†™"
            )
        
        with col2:
            max_results = st.selectbox("æœ€å¤§ç»“æœæ•°", [5, 10, 20, 50], index=1)
        
        # é«˜çº§æœç´¢é€‰é¡¹
        with st.expander("ğŸ”§ é«˜çº§æœç´¢é€‰é¡¹"):
            col1, col2 = st.columns(2)
            
            with col1:
                # ä¸»é¢˜è¿‡æ»¤
                all_topics = set()
                for course in self.courses:
                    all_topics.update(course['topics'])
                selected_topics = st.multiselect(
                    "æŒ‰ä¸»é¢˜è¿‡æ»¤",
                    sorted(list(all_topics)),
                    help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªä¸»é¢˜è¿›è¡Œè¿‡æ»¤"
                )
            
            with col2:
                # æœç´¢æƒé‡è®¾ç½®
                st.markdown("**æœç´¢æƒé‡è®¾ç½®**")
                name_weight = st.slider("è¯¾ç¨‹åç§°æƒé‡", 1, 20, 10)
                desc_weight = st.slider("æè¿°æƒé‡", 1, 20, 5)
                topic_weight = st.slider("ä¸»é¢˜æƒé‡", 1, 20, 3)
        
        # æ‰§è¡Œæœç´¢
        if search_query:
            # è‡ªå®šä¹‰æœç´¢å‡½æ•°
            results = self.advanced_search(
                search_query, selected_topics, max_results,
                name_weight, desc_weight, topic_weight
            )
            
            if results:
                st.success(f"ğŸ¯ æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³è¯¾ç¨‹")
                
                # ç»“æœå±•ç¤º
                for i, result in enumerate(results, 1):
                    with st.container():
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            st.markdown(f"### {i}. {result['course_name']}")
                            st.write(f"**ç›¸å…³åº¦è¯„åˆ†**: {result['score']}")
                            st.write(f"**ä¸»é¢˜**: {', '.join(result['topics'][:5])}")
                            
                            # æè¿°ï¼ˆå¯å±•å¼€ï¼‰
                            with st.expander("æŸ¥çœ‹è¯¾ç¨‹æè¿°"):
                                st.write(result['description'])
                        
                        with col2:
                            # ç›¸ä¼¼è¯¾ç¨‹æŒ‰é’®
                            if st.button(f"æŸ¥æ‰¾ç›¸ä¼¼è¯¾ç¨‹", key=f"similar_{i}"):
                                similar_courses = self.find_similar_courses_by_index(result['course_index'], 5)
                                st.write("**ç›¸ä¼¼è¯¾ç¨‹:**")
                                for sim_course in similar_courses:
                                    st.write(f"â€¢ {sim_course['course_name']} ({sim_course['similarity']:.3f})")
                        
                        st.markdown("---")
            else:
                st.info("ğŸ¤·â€â™‚ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è¯¾ç¨‹ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯")
    
    def render_knowledge_graph(self):
        """æ¸²æŸ“çŸ¥è¯†å›¾è°±é¡µé¢"""
        st.title("ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±å¯è§†åŒ–")
        st.markdown("---")
        
        if self.graph is None:
            st.error("âŒ æ²¡æœ‰çŸ¥è¯†å›¾è°±æ•°æ®")
            return
        
        # å›¾è°±æ§åˆ¶é€‰é¡¹
        col1, col2, col3 = st.columns(3)
        
        with col1:
            max_nodes = st.slider("æ˜¾ç¤ºèŠ‚ç‚¹æ•°", 10, min(100, len(self.graph.nodes)), 50)
        
        with col2:
            layout_type = st.selectbox(
                "å¸ƒå±€ç®—æ³•",
                ["spring", "kamada_kawai", "circular", "random"],
                help="ä¸åŒçš„å¸ƒå±€ç®—æ³•ä¼šäº§ç”Ÿä¸åŒçš„å¯è§†åŒ–æ•ˆæœ"
            )
        
        with col3:
            node_size_factor = st.slider("èŠ‚ç‚¹å¤§å°", 0.5, 3.0, 1.0, 0.1)
        
        # ä¸»é¢˜ç­›é€‰
        if self.courses:
            all_topics = set()
            for course in self.courses:
                all_topics.update(course['topics'])
            
            selected_topics_filter = st.multiselect(
                "æŒ‰ä¸»é¢˜ç­›é€‰èŠ‚ç‚¹",
                sorted(list(all_topics)),
                help="é€‰æ‹©ä¸»é¢˜æ¥é«˜äº®ç›¸å…³è¯¾ç¨‹"
            )
        
        # ç”Ÿæˆå›¾è°±å¯è§†åŒ–
        fig = self.create_interactive_graph(
            max_nodes, layout_type, node_size_factor, selected_topics_filter
        )
        
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        
        # å›¾è°±ç»Ÿè®¡ä¿¡æ¯
        st.markdown("### ğŸ“Š å›¾è°±ç»Ÿè®¡")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("èŠ‚ç‚¹æ•°", len(self.graph.nodes))
        with col2:
            st.metric("è¾¹æ•°", len(self.graph.edges))
        with col3:
            st.metric("å¯†åº¦", f"{nx.density(self.graph):.4f}")
        with col4:
            st.metric("è¿é€šåˆ†é‡", nx.number_connected_components(self.graph))
        
        # ä¸­å¿ƒæ€§åˆ†æ
        st.markdown("### ğŸ¯ ä¸­å¿ƒæ€§åˆ†æ")
        
        # è®¡ç®—ä¸­å¿ƒæ€§æŒ‡æ ‡
        degree_centrality = nx.degree_centrality(self.graph)
        betweenness_centrality = nx.betweenness_centrality(self.graph)
        
        # è·å–topè¯¾ç¨‹
        top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]
        top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**åº¦ä¸­å¿ƒæ€§æœ€é«˜çš„è¯¾ç¨‹**")
            for i, (node_id, centrality) in enumerate(top_degree, 1):
                course_name = self.graph.nodes[node_id]['name']
                st.write(f"{i}. {course_name[:50]}... ({centrality:.3f})")
        
        with col2:
            st.markdown("**ä»‹æ•°ä¸­å¿ƒæ€§æœ€é«˜çš„è¯¾ç¨‹**")
            for i, (node_id, centrality) in enumerate(top_betweenness, 1):
                course_name = self.graph.nodes[node_id]['name']
                st.write(f"{i}. {course_name[:50]}... ({centrality:.3f})")
    
    def render_topic_analysis(self):
        """æ¸²æŸ“ä¸»é¢˜åˆ†æé¡µé¢"""
        st.title("ğŸ“Š ä¸»é¢˜åˆ†æ")
        st.markdown("---")
        
        if not self.analysis_data:
            st.error("âŒ æ²¡æœ‰ä¸»é¢˜åˆ†ææ•°æ®")
            return
        
        # ä¸»é¢˜åˆ†å¸ƒåˆ†æ
        if 'topic_distribution' in self.analysis_data:
            topic_dist = self.analysis_data['topic_distribution']
            
            # æ€»ä½“ç»Ÿè®¡
            st.markdown("### ğŸ“ˆ ä¸»é¢˜åˆ†å¸ƒæ¦‚è§ˆ")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æ€»ä¸»é¢˜æ•°", len(topic_dist))
            with col2:
                total_courses = sum(topic_dist.values())
                st.metric("è¯¾ç¨‹-ä¸»é¢˜å…³è”", total_courses)
            with col3:
                avg_per_topic = total_courses / len(topic_dist)
                st.metric("å¹³å‡æ¯ä¸»é¢˜è¯¾ç¨‹æ•°", f"{avg_per_topic:.1f}")
            with col4:
                max_count = max(topic_dist.values())
                st.metric("æœ€çƒ­é—¨ä¸»é¢˜è¯¾ç¨‹æ•°", max_count)
            
            # ä¸»é¢˜åˆ†å¸ƒå›¾è¡¨
            st.markdown("### ğŸ“Š ä¸»é¢˜çƒ­åº¦åˆ†å¸ƒ")
            
            # é€‰æ‹©æ˜¾ç¤ºçš„ä¸»é¢˜æ•°é‡
            top_n = st.slider("æ˜¾ç¤ºå‰Nä¸ªä¸»é¢˜", 10, min(50, len(topic_dist)), 20)
            
            top_topics = dict(list(topic_dist.items())[:top_n])
            
            # åˆ›å»ºäº¤äº’å¼æŸ±çŠ¶å›¾
            fig = px.bar(
                x=list(top_topics.values()),
                y=list(top_topics.keys()),
                orientation='h',
                title=f"å‰{top_n}ä¸ªçƒ­é—¨ä¸»é¢˜åˆ†å¸ƒ",
                labels={'x': 'è¯¾ç¨‹æ•°é‡', 'y': 'ä¸»é¢˜'},
                color=list(top_topics.values()),
                color_continuous_scale='plasma'
            )
            fig.update_layout(height=600, yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
            
            # ä¸»é¢˜è¯äº‘ï¼ˆä½¿ç”¨æ¡å½¢å›¾æ¨¡æ‹Ÿï¼‰
            st.markdown("### â˜ï¸ ä¸»é¢˜çƒ­åº¦äº‘å›¾")
            
            # åˆ›å»ºé¥¼å›¾
            fig_pie = px.pie(
                values=list(top_topics.values()),
                names=list(top_topics.keys()),
                title=f"å‰{top_n}ä¸ªä¸»é¢˜å æ¯”åˆ†å¸ƒ"
            )
            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig_pie, use_container_width=True)
        
        # èšç±»åˆ†æ
        if 'cluster_analysis' in self.analysis_data and self.analysis_data['cluster_analysis']:
            st.markdown("### ğŸ¯ èšç±»åˆ†æ")
            
            cluster_data = self.analysis_data['cluster_analysis']
            num_clusters = self.analysis_data.get('num_clusters', len(cluster_data))
            
            st.write(f"ç³»ç»Ÿè¯†åˆ«å‡º **{num_clusters}** ä¸ªè¯¾ç¨‹èšç±»")
            
            # èšç±»è¯¦æƒ…
            for cluster_name, topics in cluster_data.items():
                with st.expander(f"ğŸ“ {cluster_name} - ä¸»è¦ä¸»é¢˜"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**ä¸»é¢˜è¯é¢‘:**")
                        for topic, count in topics.items():
                            st.write(f"â€¢ {topic}: {count}")
                    
                    with col2:
                        # è¯¥èšç±»çš„é¥¼å›¾
                        if topics:
                            fig_cluster = px.pie(
                                values=list(topics.values()),
                                names=list(topics.keys()),
                                title=f"{cluster_name} ä¸»é¢˜åˆ†å¸ƒ"
                            )
                            st.plotly_chart(fig_cluster, use_container_width=True)
        
        # ä¸»é¢˜ç›¸å…³æ€§åˆ†æ
        if self.embeddings is not None and self.courses:
            st.markdown("### ğŸ”— ä¸»é¢˜ç›¸å…³æ€§çŸ©é˜µ")
            
            # è®¡ç®—ä¸»é¢˜-ä¸»é¢˜ç›¸å…³æ€§
            topic_correlation = self.calculate_topic_correlation()
            
            if topic_correlation is not None:
                fig_heatmap = px.imshow(
                    topic_correlation,
                    title="ä¸»é¢˜ç›¸å…³æ€§çƒ­åŠ›å›¾",
                    color_continuous_scale='RdBu',
                    aspect='auto'
                )
                st.plotly_chart(fig_heatmap, use_container_width=True)
    
    def render_similarity_analysis(self):
        """æ¸²æŸ“ç›¸ä¼¼åº¦åˆ†æé¡µé¢"""
        st.title("ğŸ¯ ç›¸ä¼¼åº¦åˆ†æ")
        st.markdown("---")
        
        if self.embeddings is None or not self.courses:
            st.error("âŒ æ²¡æœ‰embeddingæ•°æ®")
            return
        
        # è¯¾ç¨‹é€‰æ‹©
        st.markdown("### ğŸ¯ é€‰æ‹©ç›®æ ‡è¯¾ç¨‹")
        
        # æœç´¢è¯¾ç¨‹
        search_course = st.text_input("æœç´¢è¯¾ç¨‹", placeholder="è¾“å…¥è¯¾ç¨‹åç§°è¿›è¡Œæœç´¢")
        
        # è¯¾ç¨‹åˆ—è¡¨
        course_options = []
        if search_course:
            # è¿‡æ»¤è¯¾ç¨‹
            for i, course in enumerate(self.courses):
                if search_course.lower() in course['course_name'].lower():
                    course_options.append((i, course['course_name']))
        else:
            # æ˜¾ç¤ºæ‰€æœ‰è¯¾ç¨‹ï¼ˆé™åˆ¶æ•°é‡ï¼‰
            course_options = [(i, course['course_name']) for i, course in enumerate(self.courses[:50])]
        
        if course_options:
            selected_course_idx = st.selectbox(
                "é€‰æ‹©è¯¾ç¨‹",
                options=[idx for idx, _ in course_options],
                format_func=lambda x: next(name for idx, name in course_options if idx == x),
                help="é€‰æ‹©ä¸€ä¸ªè¯¾ç¨‹æ¥åˆ†æå…¶ç›¸ä¼¼è¯¾ç¨‹"
            )
            
            # ç›¸ä¼¼åº¦è®¾ç½®
            col1, col2 = st.columns(2)
            with col1:
                similarity_threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.0, 1.0, 0.5, 0.05)
            with col2:
                max_similar = st.slider("æœ€å¤§ç›¸ä¼¼è¯¾ç¨‹æ•°", 5, 50, 20)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similar_courses = self.find_similar_courses_by_index(selected_course_idx, max_similar)
            
            # è¿‡æ»¤ä½äºé˜ˆå€¼çš„è¯¾ç¨‹
            filtered_similar = [
                course for course in similar_courses 
                if course['similarity'] >= similarity_threshold
            ]
            
            # æ˜¾ç¤ºç›®æ ‡è¯¾ç¨‹ä¿¡æ¯
            st.markdown("### ğŸ“‹ ç›®æ ‡è¯¾ç¨‹ä¿¡æ¯")
            target_course = self.courses[selected_course_idx]
            
            col1, col2 = st.columns([2, 1])
            with col1:
                st.write(f"**è¯¾ç¨‹åç§°**: {target_course['course_name']}")
                st.write(f"**ä¸»é¢˜**: {', '.join(target_course['topics'])}")
                with st.expander("æŸ¥çœ‹è¯¾ç¨‹æè¿°"):
                    st.write(target_course['course_description'])
            
            with col2:
                # ç›®æ ‡è¯¾ç¨‹çš„ä¸»é¢˜åˆ†å¸ƒ
                if target_course['topics']:
                    fig_target = px.pie(
                        values=[1] * len(target_course['topics']),
                        names=target_course['topics'],
                        title="ç›®æ ‡è¯¾ç¨‹ä¸»é¢˜"
                    )
                    fig_target.update_traces(showlegend=False)
                    st.plotly_chart(fig_target, use_container_width=True)
            
            # æ˜¾ç¤ºç›¸ä¼¼è¯¾ç¨‹
            if filtered_similar:
                st.markdown(f"### ğŸ” ç›¸ä¼¼è¯¾ç¨‹ (é˜ˆå€¼ â‰¥ {similarity_threshold})")
                st.write(f"æ‰¾åˆ° {len(filtered_similar)} ä¸ªç›¸ä¼¼è¯¾ç¨‹")
                
                # ç›¸ä¼¼åº¦åˆ†å¸ƒå›¾
                similarities = [course['similarity'] for course in filtered_similar]
                fig_dist = px.histogram(
                    x=similarities,
                    bins=20,
                    title="ç›¸ä¼¼åº¦åˆ†å¸ƒ",
                    labels={'x': 'ç›¸ä¼¼åº¦', 'y': 'è¯¾ç¨‹æ•°é‡'}
                )
                st.plotly_chart(fig_dist, use_container_width=True)
                
                # ç›¸ä¼¼è¯¾ç¨‹åˆ—è¡¨
                for i, similar_course in enumerate(filtered_similar, 1):
                    with st.expander(f"{i}. {similar_course['course_name']} (ç›¸ä¼¼åº¦: {similar_course['similarity']:.3f})"):
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.write(f"**ä¸»é¢˜**: {', '.join(similar_course['topics'][:5])}")
                            st.write(f"**æè¿°**: {similar_course['description']}")
                        
                        with col2:
                            # ä¸»é¢˜é‡å åˆ†æ
                            target_topics = set(target_course['topics'])
                            similar_topics = set(similar_course['topics'])
                            overlap = target_topics.intersection(similar_topics)
                            
                            if overlap:
                                st.write("**é‡å ä¸»é¢˜**:")
                                for topic in overlap:
                                    st.write(f"â€¢ {topic}")
            else:
                st.info(f"æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦ â‰¥ {similarity_threshold} çš„è¯¾ç¨‹")
            
            # é™ç»´å¯è§†åŒ–
            st.markdown("### ğŸ“ˆ ç›¸ä¼¼åº¦å¯è§†åŒ–")
            
            if len(filtered_similar) > 0:
                # å‡†å¤‡æ•°æ®
                target_embedding = self.embeddings[selected_course_idx:selected_course_idx+1]
                similar_embeddings = np.array([
                    self.embeddings[course['course_index']] 
                    for course in filtered_similar
                ])
                all_embeddings = np.vstack([target_embedding, similar_embeddings])
                
                # é™ç»´
                reduction_method = st.selectbox("é™ç»´æ–¹æ³•", ["PCA", "t-SNE"])
                
                if reduction_method == "PCA":
                    reducer = PCA(n_components=2)
                else:
                    perplexity = min(30, len(all_embeddings) - 1)
                    reducer = TSNE(n_components=2, perplexity=max(2, perplexity), random_state=42)
                
                try:
                    reduced_embeddings = reducer.fit_transform(all_embeddings)
                    
                    # åˆ›å»ºæ•£ç‚¹å›¾
                    labels = ['ç›®æ ‡è¯¾ç¨‹'] + [f"ç›¸ä¼¼è¯¾ç¨‹ {i}" for i in range(1, len(filtered_similar) + 1)]
                    colors = ['red'] + ['blue'] * len(filtered_similar)
                    
                    fig_scatter = go.Figure()
                    
                    # æ·»åŠ ç›®æ ‡è¯¾ç¨‹
                    fig_scatter.add_trace(go.Scatter(
                        x=[reduced_embeddings[0, 0]],
                        y=[reduced_embeddings[0, 1]],
                        mode='markers',
                        marker=dict(size=15, color='red'),
                        name='ç›®æ ‡è¯¾ç¨‹',
                        text=[target_course['course_name']],
                        hovertemplate='%{text}<extra></extra>'
                    ))
                    
                    # æ·»åŠ ç›¸ä¼¼è¯¾ç¨‹
                    fig_scatter.add_trace(go.Scatter(
                        x=reduced_embeddings[1:, 0],
                        y=reduced_embeddings[1:, 1],
                        mode='markers',
                        marker=dict(size=10, color='blue', opacity=0.7),
                        name='ç›¸ä¼¼è¯¾ç¨‹',
                        text=[course['course_name'] for course in filtered_similar],
                        hovertemplate='%{text}<br>ç›¸ä¼¼åº¦: ' + 
                                    '<br>'.join([f"{course['similarity']:.3f}" for course in filtered_similar]) +
                                    '<extra></extra>'
                    ))
                    
                    fig_scatter.update_layout(
                        title=f"{reduction_method} é™ç»´å¯è§†åŒ–",
                        xaxis_title=f"{reduction_method} 1",
                        yaxis_title=f"{reduction_method} 2"
                    )
                    
                    st.plotly_chart(fig_scatter, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"é™ç»´å¯è§†åŒ–å¤±è´¥: {e}")
        else:
            st.info("è¯·æœç´¢å¹¶é€‰æ‹©ä¸€ä¸ªè¯¾ç¨‹è¿›è¡Œç›¸ä¼¼åº¦åˆ†æ")
    
    def render_statistics(self):
        """æ¸²æŸ“ç»Ÿè®¡æŠ¥å‘Šé¡µé¢"""
        st.title("ğŸ“ˆ ç»Ÿè®¡æŠ¥å‘Š")
        st.markdown("---")
        
        if not self.courses:
            st.error("âŒ æ²¡æœ‰æ•°æ®")
            return
        
        # æ€»ä½“ç»Ÿè®¡
        st.markdown("### ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("è¯¾ç¨‹æ€»æ•°", len(self.courses))
        
        with col2:
            if self.embeddings is not None:
                st.metric("å‘é‡ç»´åº¦", self.embeddings.shape[1])
        
        with col3:
            if self.graph is not None:
                density = nx.density(self.graph)
                st.metric("å›¾è°±å¯†åº¦", f"{density:.4f}")
        
        with col4:
            if self.analysis_data:
                total_topics = len(self.analysis_data.get('topic_distribution', {}))
                st.metric("è¯†åˆ«ä¸»é¢˜æ•°", total_topics)
        
        # è¯¾ç¨‹é•¿åº¦åˆ†å¸ƒ
        st.markdown("### ğŸ“ è¯¾ç¨‹æè¿°é•¿åº¦åˆ†å¸ƒ")
        
        desc_lengths = [len(course['course_description']) for course in self.courses]
        
        fig_length = px.histogram(
            x=desc_lengths,
            bins=30,
            title="è¯¾ç¨‹æè¿°é•¿åº¦åˆ†å¸ƒ",
            labels={'x': 'æè¿°é•¿åº¦(å­—ç¬¦)', 'y': 'è¯¾ç¨‹æ•°é‡'}
        )
        st.plotly_chart(fig_length, use_container_width=True)
        
        # ä¸»é¢˜æ•°é‡åˆ†å¸ƒ
        st.markdown("### ğŸ·ï¸ æ¯è¯¾ç¨‹ä¸»é¢˜æ•°é‡åˆ†å¸ƒ")
        
        topic_counts = [len(course['topics']) for course in self.courses]
        
        fig_topics = px.histogram(
            x=topic_counts,
            bins=max(topic_counts),
            title="æ¯è¯¾ç¨‹ä¸»é¢˜æ•°é‡åˆ†å¸ƒ",
            labels={'x': 'ä¸»é¢˜æ•°é‡', 'y': 'è¯¾ç¨‹æ•°é‡'}
        )
        st.plotly_chart(fig_topics, use_container_width=True)
        
        # å›¾è°±åˆ†æ
        if self.graph is not None:
            st.markdown("### ğŸ•¸ï¸ å›¾è°±æ‹“æ‰‘åˆ†æ")
            
            # åº¦åˆ†å¸ƒ
            degrees = [self.graph.degree(n) for n in self.graph.nodes()]
            
            col1, col2 = st.columns(2)
            
            with col1:
                fig_degree = px.histogram(
                    x=degrees,
                    bins=20,
                    title="èŠ‚ç‚¹åº¦åˆ†å¸ƒ",
                    labels={'x': 'åº¦', 'y': 'èŠ‚ç‚¹æ•°é‡'}
                )
                st.plotly_chart(fig_degree, use_container_width=True)
            
            with col2:
                # è¿é€šåˆ†é‡
                components = list(nx.connected_components(self.graph))
                component_sizes = [len(comp) for comp in components]
                
                fig_components = px.bar(
                    x=range(1, len(component_sizes) + 1),
                    y=component_sizes,
                    title="è¿é€šåˆ†é‡å¤§å°",
                    labels={'x': 'åˆ†é‡ID', 'y': 'èŠ‚ç‚¹æ•°é‡'}
                )
                st.plotly_chart(fig_components, use_container_width=True)
        
        # æ•°æ®è´¨é‡æŠ¥å‘Š
        st.markdown("### âœ… æ•°æ®è´¨é‡æŠ¥å‘Š")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        missing_names = sum(1 for course in self.courses if not course['course_name'])
        missing_descriptions = sum(1 for course in self.courses if not course['course_description'])
        missing_topics = sum(1 for course in self.courses if not course['topics'])
        
        quality_data = {
            "æŒ‡æ ‡": ["è¯¾ç¨‹åç§°å®Œæ•´æ€§", "è¯¾ç¨‹æè¿°å®Œæ•´æ€§", "ä¸»é¢˜æ ‡ç­¾å®Œæ•´æ€§"],
            "å®Œæ•´æ•°é‡": [
                len(self.courses) - missing_names,
                len(self.courses) - missing_descriptions,
                len(self.courses) - missing_topics
            ],
            "ç¼ºå¤±æ•°é‡": [missing_names, missing_descriptions, missing_topics],
            "å®Œæ•´ç‡": [
                f"{(1 - missing_names/len(self.courses))*100:.1f}%",
                f"{(1 - missing_descriptions/len(self.courses))*100:.1f}%",
                f"{(1 - missing_topics/len(self.courses))*100:.1f}%"
            ]
        }
        
        quality_df = pd.DataFrame(quality_data)
        st.dataframe(quality_df, use_container_width=True)
        
        # å¯¼å‡ºåŠŸèƒ½
        st.markdown("### ğŸ’¾ æ•°æ®å¯¼å‡º")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("å¯¼å‡ºè¯¾ç¨‹åˆ—è¡¨"):
                courses_df = pd.DataFrame([
                    {
                        'course_name': course['course_name'],
                        'topics': ', '.join(course['topics']),
                        'description_length': len(course['course_description'])
                    }
                    for course in self.courses
                ])
                st.download_button(
                    label="ä¸‹è½½CSV",
                    data=courses_df.to_csv(index=False),
                    file_name="courses_list.csv",
                    mime="text/csv"
                )
        
        with col2:
            if st.button("å¯¼å‡ºä¸»é¢˜ç»Ÿè®¡"):
                if self.analysis_data and 'topic_distribution' in self.analysis_data:
                    topic_df = pd.DataFrame([
                        {'topic': topic, 'count': count}
                        for topic, count in self.analysis_data['topic_distribution'].items()
                    ])
                    st.download_button(
                        label="ä¸‹è½½CSV",
                        data=topic_df.to_csv(index=False),
                        file_name="topic_statistics.csv",
                        mime="text/csv"
                    )
        
        with col3:
            if st.button("å¯¼å‡ºå›¾è°±æ‘˜è¦"):
                if self.graph is not None:
                    summary = {
                        'total_nodes': len(self.graph.nodes),
                        'total_edges': len(self.graph.edges),
                        'density': nx.density(self.graph),
                        'components': nx.number_connected_components(self.graph)
                    }
                    st.download_button(
                        label="ä¸‹è½½JSON",
                        data=json.dumps(summary, indent=2),
                        file_name="graph_summary.json",
                        mime="application/json"
                    )
    
    # è¾…åŠ©æ–¹æ³•
    def search_courses(self, keyword, top_k=10):
        """æœç´¢è¯¾ç¨‹"""
        results = []
        keyword_lower = keyword.lower()
        
        for i, course in enumerate(self.courses):
            score = 0
            
            if keyword_lower in course['course_name'].lower():
                score += 10
            if keyword_lower in course['course_description'].lower():
                score += 5
            for topic in course['topics']:
                if keyword_lower in topic.lower():
                    score += 3
            
            if score > 0:
                results.append({
                    'course_index': i,
                    'course_name': course['course_name'],
                    'score': score,
                    'topics': course['topics'],
                    'description': course['course_description'][:200] + "..." if len(course['course_description']) > 200 else course['course_description']
                })
        
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:top_k]
    
    def advanced_search(self, query, topics_filter, max_results, name_weight, desc_weight, topic_weight):
        """é«˜çº§æœç´¢"""
        results = []
        query_lower = query.lower()
        
        for i, course in enumerate(self.courses):
            # ä¸»é¢˜è¿‡æ»¤
            if topics_filter:
                if not any(topic in course['topics'] for topic in topics_filter):
                    continue
            
            score = 0
            
            # åŠ æƒæœç´¢
            if query_lower in course['course_name'].lower():
                score += name_weight
            if query_lower in course['course_description'].lower():
                score += desc_weight
            for topic in course['topics']:
                if query_lower in topic.lower():
                    score += topic_weight
            
            if score > 0:
                results.append({
                    'course_index': i,
                    'course_name': course['course_name'],
                    'score': score,
                    'topics': course['topics'],
                    'description': course['course_description'][:200] + "..." if len(course['course_description']) > 200 else course['course_description']
                })
        
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:max_results]
    
    def find_similar_courses_by_index(self, target_idx, top_k=5):
        """æ ¹æ®ç´¢å¼•æŸ¥æ‰¾ç›¸ä¼¼è¯¾ç¨‹"""
        if self.embeddings is None:
            return []
        
        similarities = cosine_similarity([self.embeddings[target_idx]], self.embeddings)[0]
        similar_indices = np.argsort(similarities)[::-1][1:top_k+1]  # æ’é™¤è‡ªå·±
        
        results = []
        for idx in similar_indices:
            results.append({
                'course_index': idx,
                'course_name': self.courses[idx]['course_name'],
                'similarity': float(similarities[idx]),
                'topics': self.courses[idx]['topics'],
                'description': self.courses[idx]['course_description'][:200] + "..." if len(self.courses[idx]['course_description']) > 200 else self.courses[idx]['course_description']
            })
        
        return results
    
    def create_interactive_graph(self, max_nodes, layout_type, node_size_factor, topic_filter):
        """åˆ›å»ºäº¤äº’å¼å›¾è°±"""
        if self.graph is None:
            return None
        
        # èŠ‚ç‚¹é€‰æ‹©é€»è¾‘
        if topic_filter:
            # æ ¹æ®ä¸»é¢˜ç­›é€‰èŠ‚ç‚¹
            filtered_nodes = []
            for node, data in self.graph.nodes(data=True):
                node_topics = data.get('topics', [])
                if any(topic in node_topics for topic in topic_filter):
                    filtered_nodes.append(node)
            
            if len(filtered_nodes) > max_nodes:
                # å¦‚æœç­›é€‰åè¿˜æ˜¯å¤ªå¤šï¼ŒæŒ‰åº¦æ•°é€‰æ‹©
                degrees = dict(self.graph.degree())
                filtered_nodes = sorted(filtered_nodes, key=lambda x: degrees[x], reverse=True)[:max_nodes]
            
            subgraph = self.graph.subgraph(filtered_nodes)
        else:
            # æŒ‰åº¦æ•°é€‰æ‹©topèŠ‚ç‚¹
            degrees = dict(self.graph.degree())
            top_nodes = sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:max_nodes]
            subgraph = self.graph.subgraph([node for node, _ in top_nodes])
        
        if len(subgraph.nodes) == 0:
            st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„èŠ‚ç‚¹")
            return None
        
        # å¸ƒå±€è®¡ç®—
        if layout_type == "spring":
            pos = nx.spring_layout(subgraph, k=1, iterations=50)
        elif layout_type == "kamada_kawai":
            pos = nx.kamada_kawai_layout(subgraph)
        elif layout_type == "circular":
            pos = nx.circular_layout(subgraph)
        else:  # random
            pos = nx.random_layout(subgraph)
        
        # åˆ›å»ºè¾¹çš„traces
        edge_x = []
        edge_y = []
        
        for edge in subgraph.edges():
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])
        
        # åˆ›å»ºèŠ‚ç‚¹çš„traces
        node_x = []
        node_y = []
        node_text = []
        node_info = []
        node_sizes = []
        
        for node in subgraph.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            
            # èŠ‚ç‚¹ä¿¡æ¯
            node_data = subgraph.nodes[node]
            node_name = node_data['name']
            node_topics = node_data.get('topics', [])
            
            node_text.append(node_name[:30] + "..." if len(node_name) > 30 else node_name)
            node_info.append(f"è¯¾ç¨‹: {node_name}<br>ä¸»é¢˜: {', '.join(node_topics[:3])}")
            
            # èŠ‚ç‚¹å¤§å°åŸºäºåº¦æ•°
            degree = subgraph.degree(node)
            node_sizes.append(10 + degree * node_size_factor * 2)
        
        # åˆ›å»ºå›¾å½¢
        fig = go.Figure()
        
        # æ·»åŠ è¾¹
        fig.add_trace(go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=0.5, color='#888'),
            hoverinfo='none',
            mode='lines',
            name='è¿æ¥'
        ))
        
        # æ·»åŠ èŠ‚ç‚¹
        fig.add_trace(go.Scatter(
            x=node_x, y=node_y,
            mode='markers+text',
            hoverinfo='text',
            hovertext=node_info,
            text=node_text,
            textposition="middle center",
            textfont=dict(size=8),
            marker=dict(
                size=node_sizes,
                color='lightblue',
                line=dict(width=2, color='blue')
            ),
            name='è¯¾ç¨‹'
        ))
        
        fig.update_layout(
            title=dict(
                text=f"è¯¾ç¨‹çŸ¥è¯†å›¾è°± ({len(subgraph.nodes)} ä¸ªèŠ‚ç‚¹)",
                font=dict(size=16)
            ),
            showlegend=False,
            hovermode='closest',
            margin=dict(b=20,l=5,r=5,t=40),
            annotations=[ dict(
                text="è¯¾ç¨‹å…³è”å›¾è°± - çº¿æ¡è¡¨ç¤ºç›¸ä¼¼å…³ç³»",
                showarrow=False,
                xref="paper", yref="paper",
                x=0.005, y=-0.002,
                xanchor='left', yanchor='bottom',
                font=dict(color="grey", size=12)
            )],
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=600
        )
        
        return fig
    
    def calculate_topic_correlation(self):
        """è®¡ç®—ä¸»é¢˜ç›¸å…³æ€§çŸ©é˜µ"""
        try:
            # è·å–æ‰€æœ‰ä¸»é¢˜
            all_topics = set()
            for course in self.courses:
                all_topics.update(course['topics'])
            
            topic_list = sorted(list(all_topics))
            
            # é™åˆ¶ä¸»é¢˜æ•°é‡ä»¥æé«˜æ€§èƒ½
            if len(topic_list) > 20:
                # é€‰æ‹©æœ€æµè¡Œçš„20ä¸ªä¸»é¢˜
                topic_counts = {}
                for course in self.courses:
                    for topic in course['topics']:
                        topic_counts[topic] = topic_counts.get(topic, 0) + 1
                
                topic_list = sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)[:20]
                topic_list = [topic for topic, _ in topic_list]
            
            # åˆ›å»ºä¸»é¢˜å‘é‡
            topic_vectors = []
            for topic in topic_list:
                topic_courses = []
                for i, course in enumerate(self.courses):
                    if topic in course['topics']:
                        topic_courses.append(i)
                
                if topic_courses and self.embeddings is not None:
                    # è®¡ç®—è¯¥ä¸»é¢˜çš„å¹³å‡embedding
                    topic_embeddings = self.embeddings[topic_courses]
                    topic_vector = np.mean(topic_embeddings, axis=0)
                    topic_vectors.append(topic_vector)
                else:
                    topic_vectors.append(np.zeros(self.embeddings.shape[1]))
            
            if topic_vectors:
                topic_vectors = np.array(topic_vectors)
                correlation_matrix = cosine_similarity(topic_vectors)
                return correlation_matrix
            
        except Exception as e:
            st.error(f"ä¸»é¢˜ç›¸å…³æ€§è®¡ç®—å¤±è´¥: {e}")
        
        return None
    
    def run(self):
        """è¿è¡Œä»ªè¡¨æ¿"""
        # åŠ è½½æ•°æ®
        self.graph, self.embeddings, self.courses, self.analysis_data = self.load_data()
        
        # æ¸²æŸ“ä¾§è¾¹æ 
        page = self.render_sidebar()
        
        # æ ¹æ®é€‰æ‹©çš„é¡µé¢æ¸²æŸ“å†…å®¹
        if page == "ğŸ  é¦–é¡µæ¦‚è§ˆ":
            self.render_home()
        elif page == "ğŸ” è¯¾ç¨‹æœç´¢":
            self.render_search()
        elif page == "ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±":
            self.render_knowledge_graph()
        elif page == "ğŸ“Š ä¸»é¢˜åˆ†æ":
            self.render_topic_analysis()
        elif page == "ğŸ¯ ç›¸ä¼¼åº¦åˆ†æ":
            self.render_similarity_analysis()
        elif page == "ğŸ“ˆ ç»Ÿè®¡æŠ¥å‘Š":
            self.render_statistics()

def main():
    """ä¸»å‡½æ•°"""
    dashboard = CourseKnowledgeGraphDashboard()
    dashboard.run()

if __name__ == "__main__":
    main()