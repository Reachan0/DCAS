# DCAS è¯¾ç¨‹çŸ¥è¯†å›¾è°±æ„å»ºå™¨ - éƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬é¡¹ç›®ä¸ºDCASç³»ç»Ÿæ„å»ºè¯¾ç¨‹çŸ¥è¯†å›¾è°±ï¼Œä½¿ç”¨Qwen3-Embedding-0.6Bæ¨¡å‹å¯¹è¯¾ç¨‹å¤§çº²è¿›è¡ŒåµŒå…¥ï¼Œå¹¶åŸºäºç›¸ä¼¼åº¦æ„å»ºçŸ¥è¯†å›¾è°±ã€‚

## æ–‡ä»¶è¯´æ˜

### è„šæœ¬æ–‡ä»¶
- `course_knowledge_graph_builder.py` - æœ¬åœ°æµ‹è¯•ç‰ˆæœ¬ï¼ˆå¤„ç†20ä¸ªæ ·æœ¬ï¼‰
- `course_knowledge_graph_production.py` - ç”Ÿäº§ç‰ˆæœ¬ï¼ˆå¤„ç†å…¨é‡æ•°æ®ï¼Œå†…å­˜ä¼˜åŒ–ï¼‰
- `deploy_knowledge_graph.sh` - æœåŠ¡å™¨éƒ¨ç½²è„šæœ¬

### è¾“å‡ºæ–‡ä»¶
- `knowledge_graph_output/` - æœ¬åœ°æµ‹è¯•ç»“æœ
- `knowledge_graph_output_production/` - ç”Ÿäº§ç¯å¢ƒç»“æœ

## æœ¬åœ°æµ‹è¯•

### è¿è¡Œæ¡ä»¶
âœ… **å·²åœ¨dcas condaç¯å¢ƒä¸­æµ‹è¯•æˆåŠŸ**
- Python 3.12+
- æ‰€éœ€åŒ…å·²å®‰è£…ï¼ˆtransformers, torch, pandas, numpy, networkx, etc.ï¼‰
- å†…å­˜éœ€æ±‚ï¼š~2GB

### æµ‹è¯•å‘½ä»¤
```bash
# è¿è¡Œæœ¬åœ°æµ‹è¯•ï¼ˆå¤„ç†20ä¸ªæ ·æœ¬ï¼‰
python course_knowledge_graph_builder.py
```

### æµ‹è¯•ç»“æœ
- âœ… æˆåŠŸåŠ è½½20ä¸ªè¯¾ç¨‹
- âœ… ç”Ÿæˆ1024ç»´embeddingå‘é‡
- âœ… æ„å»ºåŒ…å«101æ¡è¾¹çš„çŸ¥è¯†å›¾è°±
- âœ… è¯†åˆ«20ä¸ªç‹¬ç‰¹ä¸»é¢˜
- âœ… ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’Œåˆ†ææŠ¥å‘Š

## æœåŠ¡å™¨éƒ¨ç½²

### ç³»ç»Ÿè¦æ±‚
- **å†…å­˜**ï¼šå»ºè®®16GB+ï¼ˆå…¨é‡2370ä¸ªè¯¾ç¨‹ï¼‰
- **å­˜å‚¨**ï¼šè‡³å°‘10GBå¯ç”¨ç©ºé—´
- **Python**ï¼š3.8+
- **GPU**ï¼šå¯é€‰ï¼ŒCUDAæ”¯æŒå¯åŠ é€Ÿembeddingç”Ÿæˆ

### éƒ¨ç½²æ­¥éª¤

1. **ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨**
```bash
scp course_knowledge_graph_production.py user@server:/path/to/dcas/
scp deploy_knowledge_graph.sh user@server:/path/to/dcas/
```

2. **è¿è¡Œéƒ¨ç½²è„šæœ¬**
```bash
cd /path/to/dcas/
bash deploy_knowledge_graph.sh
```

3. **æ¿€æ´»condaç¯å¢ƒ**
```bash
conda activate dcas  # æˆ–ä½ çš„ç¯å¢ƒå
```

4. **è¿è¡Œç”Ÿäº§è„šæœ¬**
```bash
# åŸºæœ¬è¿è¡Œ
python course_knowledge_graph_production.py

# è‡ªå®šä¹‰å‚æ•°
python course_knowledge_graph_production.py \
  --data-dir "datasets/Course Details/General" \
  --output-dir knowledge_graph_output_production \
  --batch-size 200 \
  --max-memory 16.0 \
  --similarity-threshold 0.65
```

### å‘½ä»¤è¡Œå‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--data-dir` | `datasets/Course Details/General` | è¯¾ç¨‹æ•°æ®ç›®å½• |
| `--output-dir` | `knowledge_graph_output_production` | è¾“å‡ºç›®å½• |
| `--batch-size` | `100` | æ‰¹å¤„ç†å¤§å°ï¼ˆè°ƒæ•´ä»¥é€‚åº”å†…å­˜ï¼‰ |
| `--max-memory` | `12.0` | æœ€å¤§å†…å­˜ä½¿ç”¨é™åˆ¶(GB) |
| `--similarity-threshold` | `0.7` | çŸ¥è¯†å›¾è°±è¾¹çš„ç›¸ä¼¼åº¦é˜ˆå€¼ |
| `--no-resume` | `False` | ç¦ç”¨æ–­ç‚¹ç»­ä¼  |

### å†…å­˜ä¼˜åŒ–å»ºè®®

| è¯¾ç¨‹æ•°é‡ | æ¨èbatch-size | æ¨èå†…å­˜ |
|----------|----------------|----------|
| <500 | 50-100 | 4GB |
| 500-1500 | 100-200 | 8GB |
| 1500-3000 | 200-500 | 16GB |
| 3000+ | 500+ | 32GB+ |

## è¾“å‡ºæ–‡ä»¶ç»“æ„

```
knowledge_graph_output_production/
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ course_embeddings_production_YYYYMMDD_HHMMSS.pkl
â”œâ”€â”€ graphs/
â”‚   â””â”€â”€ course_knowledge_graph_production_YYYYMMDD_HHMMSS.pkl
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ topic_analysis_production_YYYYMMDD_HHMMSS.json
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ progress.json
â”‚   â”œâ”€â”€ courses_cache.pkl
â”‚   â””â”€â”€ embeddings_cache.pkl
â””â”€â”€ production_report_YYYYMMDD_HHMMSS.md
```

## ç‰¹æ€§åŠŸèƒ½

### ğŸ”„ æ–­ç‚¹ç»­ä¼ 
- è‡ªåŠ¨ä¿å­˜å¤„ç†è¿›åº¦
- æ”¯æŒä»ä¸­æ–­ç‚¹ç»§ç»­å¤„ç†
- ç¼“å­˜å·²å¤„ç†çš„æ•°æ®

### ğŸ’¾ å†…å­˜ç®¡ç†
- æ‰¹é‡å¤„ç†å¤§å‹æ•°æ®é›†
- å®æ—¶å†…å­˜ç›‘æ§
- åƒåœ¾å›æ”¶ä¼˜åŒ–

### ğŸ“Š æ•°æ®åˆ†æ
- ä¸»é¢˜åˆ†å¸ƒç»Ÿè®¡
- è¯¾ç¨‹èšç±»åˆ†æ
- çŸ¥è¯†å›¾è°±å¯è§†åŒ–

### ğŸš€ æ€§èƒ½ä¼˜åŒ–
- GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
- å¤šè¿›ç¨‹åµŒå…¥ç”Ÿæˆ
- å†…å­˜å‹å¥½çš„ç›¸ä¼¼åº¦è®¡ç®—

## ä½¿ç”¨ç¤ºä¾‹

### åŠ è½½å·²ç”Ÿæˆçš„æ•°æ®
```python
import pickle
import networkx as nx

# åŠ è½½çŸ¥è¯†å›¾è°±
with open('knowledge_graph_output_production/graphs/course_knowledge_graph_production_*.pkl', 'rb') as f:
    graph = pickle.load(f)

# åŠ è½½embeddings
with open('knowledge_graph_output_production/embeddings/course_embeddings_production_*.pkl', 'rb') as f:
    data = pickle.load(f)
    embeddings = data['embeddings']
    courses = data['courses']

# åˆ†æå›¾è°±
print(f"è¯¾ç¨‹æ•°é‡: {len(graph.nodes)}")
print(f"è¿æ¥æ•°é‡: {len(graph.edges)}")
print(f"å›¾è°±å¯†åº¦: {nx.density(graph)}")
```

### æŸ¥æ‰¾ç›¸ä¼¼è¯¾ç¨‹
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def find_similar_courses(target_course_idx, embeddings, courses, top_k=5):
    similarities = cosine_similarity([embeddings[target_course_idx]], embeddings)[0]
    similar_indices = np.argsort(similarities)[::-1][1:top_k+1]  # æ’é™¤è‡ªå·±
    
    for idx in similar_indices:
        print(f"ç›¸ä¼¼åº¦: {similarities[idx]:.3f} - {courses[idx]['course_name']}")
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
   - å‡å°batch-sizeå‚æ•°
   - å¢åŠ max-memoryé™åˆ¶
   - å…³é—­å…¶ä»–ç¨‹åºé‡Šæ”¾å†…å­˜

2. **GPUå†…å­˜ä¸è¶³**
   - è„šæœ¬ä¼šè‡ªåŠ¨å›é€€åˆ°CPU
   - æˆ–å‡å°batch-size

3. **æ•°æ®åŠ è½½å¤±è´¥**
   - æ£€æŸ¥æ•°æ®ç›®å½•è·¯å¾„
   - ç¡®è®¤JSONæ–‡ä»¶æ ¼å¼æ­£ç¡®

4. **æ¨¡å‹ä¸‹è½½å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - è„šæœ¬ä¼šè‡ªåŠ¨ä½¿ç”¨å¤‡é€‰æ¨¡å‹

### ç›‘æ§è¿›åº¦

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f nohup.out

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
htop

# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ£€æŸ¥è¿›åº¦æ–‡ä»¶
cat knowledge_graph_output_production/checkpoints/progress.json
```

## ç”Ÿäº§ç¯å¢ƒå»ºè®®

1. **ä½¿ç”¨screenæˆ–tmux**è¿è¡Œé•¿æ—¶é—´ä»»åŠ¡
2. **å®šæœŸå¤‡ä»½**è¾“å‡ºæ–‡ä»¶
3. **ç›‘æ§èµ„æºä½¿ç”¨**æƒ…å†µ
4. **è®¾ç½®æ—¥å¿—è½®è½¬**é¿å…æ—¥å¿—æ–‡ä»¶è¿‡å¤§

## è”ç³»æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. è¾“å‡ºæ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯
2. ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
3. æ•°æ®æ–‡ä»¶å®Œæ•´æ€§

---
*DCAS Course Knowledge Graph Builder v1.0*