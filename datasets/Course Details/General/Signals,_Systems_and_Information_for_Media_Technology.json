{
  "course_name": "Signals, Systems and Information for Media Technology",
  "course_description": "This class teaches the fundamentals of signals and information theory with emphasis on modeling audio/visual messages and physiologically derived signals, and the human source or recipient. Topics include linear systems, difference equations, Z-transforms, sampling and sampling rate conversion, convolution, filtering, modulation, Fourier analysis, entropy, noise, and Shannon’s fundamental theorems. Additional topics may include data compression, filter design, and feature detection. The undergraduate subject MAS.160 meets with the two half-semester graduate subjects MAS.510 and MAS.511, but assignments differ.",
  "topics": [
    "Engineering",
    "Electrical Engineering",
    "Signal Processing",
    "Telecommunications",
    "Systems Engineering",
    "Computational Modeling and Simulation",
    "Fine Arts",
    "Media Studies",
    "Engineering",
    "Electrical Engineering",
    "Signal Processing",
    "Telecommunications",
    "Systems Engineering",
    "Computational Modeling and Simulation",
    "Fine Arts",
    "Media Studies"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hour / session\n\nCombined Undergraduate/Graduate Subject\n\nThe undergraduate and graduate versions of this class meet together. MAS.160 is the undergraduate subject number. The graduate version has additional assignments, and is split into a pair of half-semester subjects, MAS.510 and MAS.511.\n\nFirst Half: MAS.510 Signals, Systems, and Information for Media Technology\n\nFundamentals of signals and information theory with emphasis on modeling audio/visual messages and physiologically derived signals, including sampling, sampling rate conversion, reconstruction, quantization, Fourier analysis, entropy, and noise. Shannon's fundamental theorems.\n\nSecond Half: MAS.511 Systems and Signal Processing for Media Technology\n\nFundamentals of signal processing and linear systems theory as applied to audio/visual messages and physiologically-derived signals. Linear systems, difference equation, Z-transforms, convolution, filtering. Additional topics may include filter design, feature detection, communication systems.\n\nPrerequisites\n\n18.02 Calculus II\n\nFor MAS.511, the prerequisite is either MAS.510 or 6.003 Circuits and Systems.\n\nTexts\n\nRequired\n\nMcClellan, J. H., R. W. Schafer, and M. A. Yoder.\nDSP First: A Multimedia Approach\n. East Rutherford, NJ: Prentice Hall, 1998. ISBN: 9780132431712.\n\nShannon, C. E., and W. Weaver.\nThe Mathematical Theory of Communication\n. Champaign, IL: University of Illinois Press, 1998. ISBN: 9780252725463. [Download a copy of the\noriginal 1948 paper by Shannon (PDF - 4.43MB)\n, upon which the book is based, from Bell Labs.]\n\nRecommended for those who want more help\n\nKaru, Zoher Z.\nSignals and Systems Made Ridiculously Simple\n. Huntsville, AL: ZiZi Press, 1995. ISBN: 9780964375215.\n\nComputer Facilities\n\nMATLAB will be used throughout the semester.\n\nExams\n\nThere will be two in-class quizzes. Both are open-book and open-notes, and we suggest bringing along a calculator that knows about trigonometric functions.\n\nGrading\n\nYour grade will be determined as a weighted average:\n\nACTIVITIES\n\nPERCENTAGES\n\nHomework\n\n40%\n\nQuizzes\n\n50%\n\nClass participation\n\n10%\n\nObligatory Policy Statement\n\nWe think collaboration is a fine thing, and encourage studying in groups and discussing the topics covered in class. However, for homework problems the work you hand in should be done at least 95% by you alone. If you can think of a system that gives a good evaluation of individual performance and is even better at facilitating learning of this material, please suggest it to us.\n\nLate Homework\n\nWe realize that many of our students lead complicated and demanding lives, and will allow you to hand in up to two problem sets late -- without penalty -- as long as you get permission from one of the faculty or TAs at least a day in advance of the regular due date. The delay is limited, however, and under no circumstances will you receive credit for a problem set after we have made available the solutions.\n\nCalendar\n\nThe calendar below provides information on the course's lecture (L) and recitation (R) sessions.\n\nSES #\n\nTOPICS\n\nKEY DATES\n\nL1\n\nIntroduction\n\nOverview of subjects to be covered during the term; basic math concepts; notation; vocabulary. Representation of systems\n\nProblem set 1 out\n\nR1\n\nSinusoids and complex exponentials\n\nL2\n\nSinusoids\n\nComplex exponentials\n\nL3\n\nSpectra\n\nSpectrum plots, AM\n\nProblem set 1 due\n\nProblem set 2 out\n\nR2\n\nPeriodic waveforms, Fourier series\n\nL4\n\nPeriodic waveforms\n\nFourier series, frequency modulation (FM)\n\nL5\n\nBasis functions and orthogonality\n\nDefinition of orthogonality; Walsh functions and other basis sets; discrete Fourier basis matrix\n\nProblem set 2 due\n\nProblem set 3 out\n\nR3\n\nPeriodicity\n\nL6\n\nSampling I\n\nSampling theorem, aliasing\n\nR4\n\nPeriodicity, spectrum of a periodic functions, basis functions, D-to-C conversion\n\nL7\n\nSampling II\n\nReconstruction\n\nProblem set 3 due\n\nProblem set 4 out\n\nL8\n\nPsychophysics, psychoacoustics, and other physiological signals\n\nR5\n\nC-to-D conversion, folding, aliasing, resampling, unsharp mask, psychoacoustics\n\nR6\n\nIntroduction to information theory, Markov processes, entropy coding\n\nL9\n\nCommunication theory I\n\nErgodic processes/Markov models; choice, uncertainty and entropy; Shannon's fundamental theorem for a noiseless channel; entropy coding\n\nL10\n\nCommunication theory II\n\nDiscrete channels with noise; continuous channels; error detection and correction\n\nR7\n\nNoisy channels, repeat rodes, Hamming code error correction\n\nL11\n\nPre-quiz wrap-up\n\nProblem set 4 due\n\nL12\n\nQuiz 1\n\nEnd of MAS.510; start of MAS.511\n\nL13\n\nDiscrete-time systems I\n\nFIR filters. Impulse response. Convolution\n\nProblem set 5 out\n\nL14\n\nDiscrete-time systems II\n\nImplementations of general LTI systems\n\nR8\n\nQuiz review\n\nFIR filters, impulse response, convolution, block diagrams\n\nL15\n\nFrequency response I\n\nResponse of FIR systems; properties\n\nProblem set 5 due\n\nProblem set 6 out\n\nL16\n\nFrequency response II\n\nR9\n\nFIR filters, impulse response, convolution review, frequency response\n\nL17\n\nZ-transform, I\n\nDefinitions; convolution and the Z-transform; poles and zeros\n\nProblem set 6 due\n\nProblem set 7 out\n\nR10\n\nFrequency response, system response, Z-transform\n\nL18\n\nIIR systems\n\nDefinitions; impulse response and frequency response\n\nL19\n\nZ-transforms II\n\nInverse Z-transform; stability; partial fraction expansion\n\nProblem set 7 due\n\nL20\n\nSpectrum analysis I\n\nThe DFT; fast algorithms\n\nProblem set 8 out\n\nR11\n\nInverse Z-transform, zeros, partial fraction expansion, long division, DFT, FFT\n\nL21\n\nSpectrum analysis II\n\nThe DTFT\n\nL22\n\nPractical filter design\n\nR12\n\nPhase, equivalent system representation, filter design, windows, and cepstrum analysis\n\nL23\n\nPre-quiz wrap-up and practical communication systems\n\nReal-world modulation and demodulation methods; spread-spectrum\n\nProblem set 8 due\n\nL24\n\nQuiz 2",
  "files": [
    {
      "category": "Assignment",
      "title": "Problem Set 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/5739321cdd1d8835600f16b5b78784e4_ps1.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMAS 160/510 Problem Set One\nDue in class Wednesday September 12, 2007\n1. Periodicity\nDetermine the fundamental period of each of the following signals:\n(a) xa(t) = cos(4 πt)\n(b) xa(t) = 10 cos(3t + π )\n(c) x[n] = cos(0.04πn)\n(d) x[n] = cos(5πn) + cos( 4\n5 πn)\n2. Sampling\n(a) Let Ts, the sampling period for a continuous time signal, be 3/2 and let x(t) = cos(2 πt).\nSketchx[n] = x(nTs) for n = 0,1,.....8.\n(b) Let Ts = 1/3 and let x(t) = cos(2 πt). Sketchx[n] = x(nTs) for n = 0,1,.....8.\n3. Review of Complex Numbers( DSP First problems at the end of appendix A)\n(a) A.3(b)\n(b) A.3(c)\n(c) A.4(a) to (e)\n(d) A.8\n4. Systems and Block Diagrams\nThe video and audio components of the DVD are stored in a compressed format (MPEG-2 for video\nand Dolby Digital for audio). These compression processes can only take in digital signals as inputs.\nAssume that all our inputs (e.g. film, audio tapes, etc.) and outputs (e.g. TV, speakers, etc.) are\nanalog signals. Draw the block diagrams of the audio and video systems necessary for DVD creation\nand playback.\nYou are given the following components:\n(a) Lots of A-to-D converters\n(b) Lots of D-to-A converters\n(c) an MPEG-2 encoder\n(d) an MPEG-2 decoder\n(e) a Dolby Digital encoder\n(f) a Dolby Digital decoder\n(g) an Optical Disc Writer\n(h) an Optical Disk Reader\n\n5. Matlab: Introduction For those of you using MATLAB the first time here are some instructions on\nhow to start:\n(a) Find Matlab\n- Go to any Athena Cluster.\n- At the Athena prompt, type add matlab to setup MATLAB locker in your Athena environ\nment (you only need to do this the first time you use MATLAB).\nOR\n- Login to any media lab unix machine\n(b) Start Matlab\n- type matlab at the prompt\nthis should initiate the Matlab shell, and display a prompt like below:\n>>\n(c) Use Matlab\nThe following steps will guide you through the Matlab exercises(Note the % indicates\na comment and need not be entered.) At the Matlab prompt, type\nx = [1:1:140]; % sets up the domain\nyCarrier = cos(pi*x/8); % create a sinusoid to act as a carrier\nplot(x,yCarrier); % and plot it\nySignal = rand(size(yCarrier)); % create a signal to be transmitted\nplot(x,ySignal); % and plot that too\nySum = yCarrier + ySignal; % create an average signal\nyDiff = yCarrier - ySignal; % create a difference signal\n(d) Using only linear combinations of the ySum and yDiff signals, recover the ySignal and plot it.\nThe following MATLAB exercises (found in Appendix C of the DSP First text) should be treated as\nwalkthrough tutorials to important concepts. You can ignore any references to instructor verification\nor a lab report. We will specify which items we would like turned in as part of the homework. However,\nit would be difficult to do only the parts that are to be turned in (i.e. it would be unwise to skip steps\nin the lab).\n6. DSP First Lab 1\nItems to be turned in:\n(a) The expand function from C.1.2.6.\n(b) The replacez function from C.1.2.7.\n(c) Plots specified in C.1.3.1.\n7. DSP First Lab 2\nItems to be turned in:\n(a) Your sumcos function and resulting plots from C.2.2.2.\n\n(b) Plots specified in C.2.3.2.\n(c) Plots and answers to questions specified in C.2.4.\n8. Additional problem (for MAS.510): Listening to Sinusoids\nWe have seen many examples of sinusoids where amplitude, frequency, and phase remain constant.\nHowever, these parameters can be varied, often with interesting and surprising results. In this problem,\nyou will use MATLAB to explore these possibilities.\nStart with a basic sinusoid of the following form:\nx(t) = A(t) sin(f ∗ 2πt + g(t))\n(1)\n(a) In MATLAB, use the equation above to create a constant amplitude (A(t) = 1) constant phase\n(g(t) = 0) 300 Hz tone lasting two seconds. Then alter its frequency so that it rises linearly from\n300 Hz to 3000 Hz. Listen to the resulting signal using the MATLAB function sound. Plot enough\nof the signal so that the change in frequency is visible. This signal is called a chirp. (Note: use\nthe sound command at the Matlab prompt. And when you are selecting a sampling rate try to\nuse 8000 Hz, and see if your results sound better.)\n(b) Start again with the 300 Hz tone. This time, vary the amplitude using the following equation:\nA(t) = sin(N2πt)\n(2)\nKeep the phase constant (i.e. g(t) = 0). Vary N with a few values from 1 to 300 and listen to the\nresult. How does the sound change with different values of N? Plot enough of the signal so that\nthe change to the signal is apparent.\n(c) Return to the constant amplitude signal (A(t) = 1). This time change the phase to be the\nfollowing:\ng(t) = cos(M2πt)\n(3)\nTry several values of M between 5 and 500 and listen to the result. How does the sound change\nwith different values of M? Plot enough of the signal so that the change in the signal is apparent.\n(d) Oftentimes, the modifications themselves contain the signal of interest, while the original sinusoid\nbecomes what is called the carrier signal, with frequency f. The changes applied in parts (b) and\n(c) are called Amplitude Modulation (AM) and Frequency Modulation (FM), respectively. Where\nelse have you heard these terms? Give some examples of your favorite values of f."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/8100b11d0824d7cdd9b92271141bb35c_ps2.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMAS 160/510 Problem Set Two\n1. Phase and Time shifting. DSP First 2.17(a)\n2. Switching between frequency-domain and time-domain\n(a) DSP First 3.2\n(b) DSP First 3.3(a),3.3(b)\n3. Fourier Series\nDetermine the Fourier series for the following periodic signals of period To:\n(a)\nx(t) = t2, 0 ≤t < To\n(b)\nx(t) =\nt,\n0 ≤t < To/2\n1, To/2 ≤t < To\nFor the following lab exercises (found in Appendix C of the DSP First text), please turn in a hard\ncopy of your functions.\n4. DSP First Lab 3\nYou only need to synthesize one of the 5 musical pieces given (your choice).\nItems to be turned in:\n(a) Your note function.\n(b) Your play scale fuction.\n(c) A function that outputs sound for one of the given musical pieces.\n(d) (MAS.510) Now that you have listened to your synthesised notes, aren't the transitions between\ndifferent notes very choppy and abrupt? Generate a function that outputs the same piece of music\nyou had selected in (c) but with a smoother transition or basically gives the notes a nice fade.\nHint: make a mathematical expression or function that degrades the magnitude of the note against\ntime.\n\n5. DSP First Lab 4\nYou only need to synthesize one of the FM instruments (bell or clarinet).\nItems to be turned in:\n(a) Your mychirp function (this should look familiar :).\n(b) Your beat function.\n(c) Plots and answers to questions specified in C.4.3.3.\n(d) Either your bellenv and bell functions, or your woodwenv and clarinet functions.\n6. Additional problem (for MAS.510)\nPlaying with sounds in your envoironment\n(a) Record a simple \"pure\" tone. Choose any length of time you desire. Plot the sound in time\nand also using a spectrogram (use the specgram function in MATLAB). Try to determine the\ndominant pitch in the simple tone and justify how it was determined.\n(b) Record your favorite piece of music or any sound for a time duration of 2 secs(in wav format, using\nwavread command in MATLAB). Plot the spectrogram of the sound you just recorded. Suggest\na way in which you could determine the pitch from the spectrogram if you didn't know what it\nwas to begin with."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/6420580653d86721091014312bc69ed5_ps3.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMAS16O: Signals, Systems & Information for Media Technology\nProblem Set 3\nProblem 1: Basis Functions\nIt is possible to use the definition of orthonormality to derive sets of basis functions. What\nwe will use here is a simple version of what is known as the Graham-Schmidt Procedure.\nAssume we care about our functions only on the interval (-1 5 t < 1). First we choose\nsome basis function 40(t) such that it satisfies the requirement\nThen a second member of the basis set,\nmust satisfy\nand\n1;Oo(tU,(t)dt = 0.\na third member 42(t) must satisfy three equations, and so forth\nConsider (on the interval from -1to 1)the basis functions\n4o(t) = A ,\n$lit)= B t + C and\n= ~t~ t E t tF\n(a) What are the values of A, B, C,D, E and F needed to make these orthonormal on this\ninterval?\n(b) Sketch these three basis functions in the interval (-1 5 t 5 1)\n(c) What are the coefficients for a series approximation (using q50(t), &it), and\nof\nthe function pit) = 1+ cos(7rt) for -1 < t < 17\nThese functions, the &(t)'s, are known as Legendre polynomials, and a tremendous amount\nis known about them. If you're interested you can find out much, much more at mathworld.\nhttp://mathworld.wolfram.com/LegendrePolynomial.html\nProblem 2: AM and Sampling\n(DSP First 4.6)\n\nProblem 3: Frequency, Sampling and Bit Rate\nThe high-frequency limit of human hearing extends to approximately 20,000 Hz,but studies\nhave shown that intelligible speech requires frequencies only up to 4,000 Hz.\n(a) Justify why the sampling rate for an audio Compact Disc (CD) is 44.1 kHz.\n(b) What is the Nyquist rate for reliable speech communications? Why do you think\npeople sound different on the phone from in person?\nThe bit rate of a system can be calculated quite simply as follows:\nbit rate = (sampling rate) (number of bits per sample)\n(c) Suppose intelligible speech requires 7 bits per sample. If the phone system is designed\nto just meet the requirements for speech (which is the case), what is the maximum bit\nrate allowable over telephone lines? From your result, do you think computer modems\n(not cable modems, ISDN, or DSL) will get any faster?\n(d) CDs use 16 bits per sample. What is the bit rate of music coming off a CD? Is a\nmodem connection fast enough to support streamed CD quality audio?\nProblem 4: Non-ideal D-to-C Conversion\n(DSP First 4.8)\nProblem 5: Representing Irrational Frequencies\n(for MAS 510)\nLater in this course we will describe how if a signal is periodic in time, then it is discrete in\nfrequency, and vice-versa. At first glance, Fig 3.17 seems to violate this statement; however,\nif you look closer, it does not. Let's explore what is going on.\nConsider the following signals\n(a) Plot the two signals in the time domain on the same page.\n(b) Plot the two signals in the frequency domain using the stem function in MATLAB.\nIs x(t) really discrete in the frequency domain? What is the computer's approximation\nof the irrational frequencies?"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/bc45046e3a8daad2bd8361f7f09ef8dc_ps4.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nDUE: October 20, 2003\nand Rosalind Picard\nT.A. Jim McBride\nMAS160: Signals, Systems & Information for Media Technology\nProblem Set 4\nInstructors: V. Michael Bove, Jr.\nProblem 1: Simple Psychoacoustic Masking\nThe following MATLAB function performs a simple psychoacoustic test. It creates bandlimited\nnoise, centered at 1000 Hz and also creates a sinusoid. It then plays the noise alone and\nthen the noise plus the sinusoid. Try different values of f and A to see whether you can\ndetect the sinusoid. For a particular value of f we'll call Amin(f) the minimum amplitude\nat which the frequency f sinusoid could still be heard. Plot several values on the graph of\nf vs. Amin to determine a simple masking curve.\nfunction mask(f,A)\n% MASK Performs a simple psychoacoustic masking test by creating\n%\nbandlimited noise around 1000 Hz and a single sinusoid at\n%\nfrequency f with amplitude A. It then plays the noise\n%\nalone, and then the noise plus the sinusoid.\n%\n%\nf - frequency of sinusoid (0 to 11025)\n%\nA - amplitude of sinusoid (0 to 1)\n% Set sampling rate to 22050 Hz\nfs = 22050;\n% Create a bandpass filter, centered around 1000 Hz. Since the\n% sampling rate is 22050, the Nyquist frequency is 11025.\n% 1000/11025 is approximately 0.09, hence the freqeuency\n% values of 0.08 and 0.1 below. For more info, do 'help butter'.\n[b,a] = butter(4,[0.08 0.1]);\n% Create a vector of random white noise (equal in all frequencies)\nwn = rand(1,22050);\n% Filter the white noise with our filter\nwf = filter(b,a,wn);\n% By filtering, we've reduced the power in the noise, so we normalize:\nwf = wf/max(abs(wf));\n% Create the sinusoid at frequency f, with amplitude A:\ns = A*cos(2*pi*f/fs*[0:fs-1]);\n% Play the sounds\nsound(wf,22050)\npause(1)\n% Pause for one second between sounds\nsound(wf+s,22050)\nPS 4-1\n\nProblem 2: Markoff processes, entropy, and grading ;\nA particularly lazy teaching assistant is faced with the task of assigning student grades. In\nassigning the first grade, he decides that the student has a 30% chance of getting an A, a\n40% chance of getting a B, and a 30% chance of getting a C (he doesn't give grades other\nthan A, B, or C). However, as he continues to grade, he is affected by the grade he has just\ngiven. If the grade he just gave was an A, he starts to feel stingy and there is less chance\nhe will give a good grade to the next student. If he gives a C, he starts to feel guilty and\nwill tend to give the next student a better grade. Here is how he is likely to grade given\nthe previous grade:\nIf he just gave an A, the next grade will be: A (20% of the time), B (30%), C (50%).\nIf he just gave a B, the next grade will be: A (30%), B (40%), C(30%).\nIf he just gave a C, the next grade will be: A (40%), B (50%), C(10%).\n(a) Draw a Markoff graph of this unusual grading process.\n(b) Calculate the joint probability of all successive pairs of grades (i.e. AA, AB, AC, etc.)\n(c) Calculate the entropy, H, of two successive grades given.\nProblem 3: Entropy Coding\nOften it is the case that a set of symbols we want to transmit are not equally likely to occur.\nIf we know the probabilities, then it makes sense to represent the most common symbols\nwith shorter bit strings, rather than using an equal number of binary digits for all symbols.\nThis is the principle behind variable-length coders.\nAn easy-to-understand variable-length coder is the Shannon-Fano code. The way we\nmake a Shannon-Fano code is to arrange all the symbols in decreasing order of probability,\nthen to split them into two groups with approximately equal probability totals (as best we\ncan, given the probabilities we have to work with), assigning 0 as an initial code digit to\nthe entries in the first group and 1 to those in the second. Then, keeping the symbols in the\nsame order, we recursively apply the same algorithm to the two groups till we've run out\nof places to divide. The pattern of ones and zeros then becomes the code for each symbol.\nFor example, suppose we have an alphabet of six symbols:\nSymbol % probability\nBinary code\nShannon-Fano code\nA\nB\nC\nD\n12.5\nE\n6.25\nF\n6.25\nLet's see how much of a savings this method gives us. If we want to send a hundred of\nthese symbols, ordinary binary code will require us to send 100 times 3 bits, or 300 bits.\nPS 4-2\n\nIn the S-F case, 75 percent of the symbols will be transmitted as 2-bit codes, 12.5 as 3-bit\ncodes, and 12.5 as 4-bit codes, so the total is only 237.5 bits, on average. Thus the binary\ncode requires 3 bits per symbol, while the S-F code takes 2.375.\nThe entropy, or \"information content\" expression gives us a lower limit on the number\nof bits per symbol we might achieve.\nm\nH = -\nX\npi log2(pi)\ni=1\n= -[0.25 log2(0.25) + 0.25 log2(0.25) + 0.25 log2(0.25) + 0.125 log2(0.125)\n+0.0625 log2(0.0625) + 0.0625 log2(0.0625)]\nIf your calculator doesn't do base-two logs (most don't), you'll need the following high-school\nrelation that many people forget:\nloga(x) = log10(x)/ log10(a),\nso\nlog2(x) = log10(x)/0.30103.\nAnd the entropy works out to 2.375 bits/symbol. So we've achieved the theoretical rate\nthis time. The S-F coder doesn't always do this well, and more complex methods like the\nHuffman coder will work better in those cases (but are too time-consuming to assign on a\nproblem set!).\nNow it's your turn to do some coding. The below is a letter-frequency table for the En\nglish language (provided as file ps4_freq.txt).\nE\n13.105\nN\n7.098\nH\n5.259\nC\n2.758\nY\n1.982\nV\n0.919\nQ\n0.121\nT\n10.468\nR\n6.832\nD\n3.788\nM\n2.536\nP\n1.982\nK\n0.420\nZ\n0.077\nA\n8.151\nI\n6.345\nL\n3.389\nU\n2.459\nW\n1.539\nX\n0.166\nO\nS\nF\nG\nB\nJ\n7.995\n6.101\n2.924\n1.994\n1.440\n0.132\n(a) Twenty-six letters require five bits of binary. What's the entropy in bits/letter of\nEnglish text coded as individual letters, ignoring (for simplicity) capitalization, spaces,\nand punctuation?\n(b) Write a Shannon-Fano code for English letters. How many bits/letter does your code\nrequire?\n(c) Ignoring (as above) case, spaces, and punctuation, how many total bits does it take\nto send the following English message as binary? As your code? [You don't need to\nwrite out the coded message, just add up the bits.]\n\"There is too much signals and systems homework\"\n(d) Repeat (c) for the following Clackamas-Chinook sentence (forgive our lack of the\nnecessary Native American diacritical marks!).\n\"nugwagimx lga dayaxbt, aga danmax wilxba diqelpxix.\"\nPS 4-3\n\nProblem 4: Error Correction\nA binary communication system contains a pair of error-prone wireless channels, as shown\nbelow.\nSender 1\nReceiver 1/Sender 2\nReceiver 2\n1/8\nError Rate\n1/16\nError Rate\nAssume that in each channel it is equally likely that a 0 will be turned into a 1 or that a 1\ninto a 0. Assume also that in the first channel the probability of an error in any particular\nbit is 1/8, and in the second channel it is 1/16.\n(a) For the combined pair of channels, compute the following four probabilities:\n- a 0 is received when a 0 is transmitted,\n- a 0 is received when a 1 is transmitted,\n- a 1 is received when a 1 is transmitted,\n- a 1 is received when a 0 is transmitted.\n(b) Assume that a very simple encoding scheme is used: a 0 is transmitted as three\nsuccessive 0's and a 1 as three successive 1's. At the decoder, a majority decision rule\nis used: if a group of three bits has more 0's than 1's (e.g. 000, 001, 010, 100), it's\nassumed that a 0 was meant, and if more 1's than 0's that a 1 was meant. If the\noriginal source message has an equal likelihood of 1's and 0's, what is the probability\nthat a decoded bit will be incorrect?\nProblem 5: Data Compression\nYou are given a data file that has been compressed to a length of 100,000 bits, and told\nthat it is result of running an \"ideal\" entropy coder on a sequence of data.\nYou are also told that the original data are samples of a continuous waveform, quantized\nto two bits per sample. The probabilities of the uncompressed values are\ns\np(s)\ns\np(s)\n1/2\n1/16\n3/8\n1/16\n(a) What (approximately) was the length of the uncompressed file, in bits? (You may\nnot need to design a coder to answer this question!)\n(b) The number of (two-bit) samples in the uncompressed file is half the value you com\nputed in part a). You are told that the continuous waveform was sampled at the\nminimum possible rate such that the waveform could be reconstructed exactly from\nthe samples (at least before they were quantized), and you are told that the file rep\nresents 10 seconds of data. What is the highest frequency present in the continuous\nsignal?\nPS 4-4"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/58ae2d88f324ffcd0c22746e7394b0c2_ps5.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nDUE: November 5, 2003\ns\nand Rosalind Picard\nT.A. Jim McBride\nMAS160: Signals, Systems & Information for Media Technology\nProblem Set 5\nInstructor : V. Michael Bove, Jr.\nProblem 1: Unit-step and running average (DSP First 5.5)\nProblem 2: Convolution\nFor each of the following sets of signals, compute their convolution (1) graphically by hand,\n(2) with MATLAB (you may use the conv function), and (3) by expressing the signals\nin terms of δ[n] and computing the convolution sum. In matlab, plot your results with\nstem, but be sure to fix the n-axis appropriately (use stem(n,y) where n is a vector of the\nappropriate range).\nFor each of the following of signals, compute their convolution with x[n] = cos(2π( 1 )n)\nusing matlab (you may use the conv function). Use stem to plot your result over the range\n[0:99], assuming the sinusoid exists for all time. Compare each convolution with x[n].\n(a) h[n] =\n(b) h[n] = δ[n] - δ[n - 1]\n1δ[n] + 1δ[n - 1]\nPS 5-1\n\nProblem 3: Time-domain response of FIR filters (DSP First 5.6)\nProblem 4: LTI Systems\nConsider the interconnection of LTI systems as shown below.\nh1[n]\nh4[n]\nh3[n]\nh2[n]\n+\nx[n]\ny[n]\n-\n(a) Express the overall impulse response, h[n], in terms of h1[n], h2[n], h3[n] and h4[n].\n(b) Determine h[n] when\nh1[n]\n=\n1 , 4\n1 , 1\n{\n2 }\nh2[n]\n= h3[n] = (n + 1)u[n]\nh4[n]\n= δ[n - 2]\nProblem 5: Block Diagrams (DSP First 5.9)\nProblem 6: MAS.510 Additional Problem\nIt is possible to determine the impulse response for a LTI system using a system of equations,\ngiven enough information about the system. For example, if we know that the system is\nFIR and has no delay and that y[0] = 1 if x[n] = δ[n], then\ny[n]\n= ax[n]\ny[0] = ax[0]\n= a ∗ 1\na\n=\nUsing systems of equations, compute the impulse response given the following system\ndescriptions and input-output pairs\n(a) FIR and single delay, x[n] = δ[n], y[0] = 2, y[1] = -2\n(b) FIR and double delay, x[n] = δ[n], y[0] = 3, y[1] = -4, y[2] = 3/2\n(c) FIR and double delay, x[n] = 4δ[n] + δ[n - 1], y[0] = 2, y[1] = 2, y[2] = -1\n(d) Calculate y[3] for each of the preceding systems.\nPS 5-2"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 6",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/d34b47a5622f003d580d374b76240f8e_ps6.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nDUE: November 12, 2003\ns\nand Rosalind Picard\nT.A. Jim McBride\nMAS160: Signals, Systems & Information for Media Technology\nProblem Set 6\nInstructor : V. Michael Bove, Jr.\nProblem 1: Frequency response of FIR filters (DSP First 6.4)\nProblem 2: Simple sound filtering\nUsing our old friend the sumcos function, create a sound with a fundamental frequency\nof 440 Hz, with 12 harmonics of equal amplitude and zero phase, and using the following\nparameters:\nfs = 11025;\n% Sets sampling rate to 11025 Hz\nf = 440*[1:12];\n% Creates frequency vector of 12 harmonics of 440 Hz\nX = ones(1,12);\n% Creates amplitudes of 1\ndur = 1;\n% Sets duration to be 1 sec\nUse MATLAB to perform the following tasks:\n(a) Create a three-point averaging FIR filter and plot the frequency response (magnitude\nand phase) of this filter using freqz. What is this filter supposed to do? Filter the\nsound you created above with this filter. How does it compare to the original sound?\n(b) Create a two-point first difference FIR filter and plot the frequency response (magni\ntude and phase) of this filter using freqz. What is this filter supposed to do? Filter\nthe original sound you created above using this new filter. How does it compare to\nthe original sound?\nProblem 3: Return of the Labs: DSP First Lab 5\nItems to be turned in:\n(a) Plots and answers to questions specified in C.5.2.1.\n(b) Plots and answers to questions specified in C.5.3.2.\n(c) Demonstrate linearity and time-invariance of filter (C.5.3.3 and C.5.3.4).\n(d) Plots and answers to questions specified in C.5.3.5.\nPS 6-1\n\nProblem 4: Additional Problem (for MAS.510)\nThe matlab function zplane is great for plotting the poles and zeros of a system in the\nz-plane. Use zplane as well as freqz to answer the following questions.\n(a) Consider the general N-point FIR averaging filter, where each coefficient bk is simply\n1 . Plot the zeros of this system in the z-plane as well as the frequency response\nN\n(magnitude and phase) for N = 3, 4, 5, and 10. How does the position of the zeros\nchange? Qualitatively, how does the frequency response change, and how does this\nrelate to the location of the zeros? Does N being an even or odd number have any\neffect?\n(b) Consider the general N-point FIR difference filter, where each coefficient bk is simply\n(-1)k . Plot the zeros of this system in the z-plane as well as the frequency response\nN\n(magnitude and phase) for N = 3, 4, 5, and 10. How does the position of the zeros\nchange? Qualitatively, how does the frequency response change, and how does this\nrelate to the location of the zeros? Does N being an even or odd number have any\neffect?\nPS 6-2"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 7",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/87377d49608ef2a7b4857f7836afeb4a_ps7.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nDUE: November 19, 2003\ns\nand Rosalind Picard\nT.A. Jim McBride\nMAS160: Signals, Systems & Information for Media Technology\nProblem Set 7\nInstructor : V. Michael Bove, Jr.\nProblem 1: z-Transforms, Poles, and Zeros\nDetermine the z-transforms of the following signals. Sketch the corresponding pole-zero\npatterns.\n(a) x[n] = δ[n - 5]\n(b) x[n] = nu[n]\n(c) x[n] =\n-1 n u[n]\n(d) x[n] = (an + a-n)u[n], a real\n(e) x[n] = (nan cos ω0n)u[n], a real\n(f) x[n] =\n1 n (u[n - 1] - u[n - 10])\nProblem 2: z-Transform Properties\nGiven x[n] below, use the properties of the z-transform to derive the transform of the\nfollowing signals.\nx[n] → X(z) =\nz-1\n(1 - z-1)2\n(a) x[n - 3]\n(b) x[n] ∗ δ[n - 3]\n(c) x[n] - x[n - 1]\n(d) x[n] ∗ (δ[n] - δ[n - 1])\n(e) 5x[n - 1] + 4\n-3\n1 n u[n]\nPS 7-1\n\nProblem 3: Relating pole-zero plots to frequency- and impulse-\nresponse\n(a) DSP First 8.16\n(b) DSP First 8.17\nProblem 4: DSP First Lab 10\nItems to be turned in:\n(a) Answers to questions from C.10.4.\n(b) Answers to questions from C.10.5.\n(c) Plots and answers to questions from C.10.6.\nPS 7-2"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 8",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/a758a02ea3385d78b2884238f4ef66ba_ps8.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMAS160: Signals, Systems & Information for Media Technology\nProblem Set 8\nDUE: December 1st, 2003\nInstructors: V. Michael Bove, Jr. and Rosalind Picard\nT.A. Jim McBride\nProblem 1: Return of the rabbits!\nConsider the case of the Fibonacci rabbits: They become fertile at one month of age, they have a gestation period\nof one month, each litter is one male and one female, and they live and breed \"forever,\" from our perspective.\nFrom that description, we could write the following difference equation for the output of a system:\nr[n] = r[n -1] + r[n -2],\nwhere r is pairs of rabbits and n is months, and we will introduce 1 pair of rabbits into the system at n = 1(more\nexplicitly, for n ≤0, r[n] = 0, and r[1] = 1).\n(a) Let's think about this a bit more explicitly in z-transform terms. Where are the poles and zeroes of this\nsystem?\n(b) Suppose we add a new twist: only P percent of the fertile (i.e. at-least-two-month-old) rabbits give birth\nin any given month. Rewrite the difference equation. Now where are the poles and zeroes? If it makes\nyour life easier, from this point on you can forget that r must always be an integer. If you are looking for\na challenge, try to retain that constraint!\nProblem 2: Inverse z-Transforms\nDetermine all possible signals that can have the following z-transforms with the given conditions.\n(a)\n1-3\n2 z-1+ 1\n2 z-2\n(b)\n2-3\n2 z-1\n1-3\n2 z-1+ 1\n2 z-2 , causal\n(c)\n1-10\n3 z-1+z-2 , stable\n(d)\n1-1\n2 z-1\n1+ 1\n2 z-1 , right-handed\nProblem 3: Utilizing the z-transform (DSP First 8.12)\nProblem 4: MAS 510 Additional Problem\n(All-Pass System) Consider the causal linear shift-invariant system with system function\nH(z) = 1 -a-1z-1\n1 -az-1\nwhere a is real\n(a) For what range of values of a is the system stable?\n(b) If 0 < a < 1, plot the pole-zero diagram and shade the region of convergence. Do the same for a > 1.\n(c) H(z) is to be cascaded with a system ˆH(z) so that the overall system function is unity. With 0 < a < 1\nand ˆH(z) specified to be a stable system, determine its impulse response ˆh(n).\nPS 8-1\n\nProblem 5: Discrete Fourier Transforms (DSP First 9.2)\nProblem 6: Inverse DFT (DSP First 9.3)\nProblem 7: Convolution revisited\n(a) In matlab, create two vectors as follows:\nx1 = [1 1 1 1 0 0 0 0];\nx2 = [0 0 1 1 1 1 0 0];\nNow convolve the two using the conv function and plot the result using stem.\n(b) Now create two new vectors as follows:\nx3 = [1 1 1 1 1 0 0 0];\nx2 = [0 0 1 1 1 1 1 0];\nAgain convolve the two using the conv function and plot the result using stem.\n(c) Remember convolution in the time domain is equivalent to multiplication in the Fourier (frequency) domain.\nSo now calculate the convolution from part (a) by taking the FFT of both vectors (using the fft function),\nmultiplying the FFTs (using .*), and inverse transforming back to the time domain (using the ifft\nfunction). You may need to take the real part of the inverse transform since very small numerical errors\nwill accumulate in MATLAB during the FFT and IFFT process. How does your result compare with part\n(a)?\n(d) Repeat this procedure for the vectors in part (b). How does your result compare with part (b)? Explain\nwhat appears to be happening.\nHint 1: We've seen a similar phenomenon earlier in the semester.\nHint 2: What is the FFT/DFT doing in the frequency domain?\nProblem 8: MAS 510 Additional Problem\nStart in matlab with the following commands:\nn = 0:31;\nx = cos(2*pi*0.11*n);\nX = abs(fft(x));\n(a) Explain what the last line accomplishes. Plot x and X using stem. What information does the plot of X\nconvey? Does it look like what you'd expect?\n(b) Now zero-pad x to a length of 2048 using the following command:\nx1 = [x zeros(1,2016)];\nAgain take the FFT and plot the magnitude of the result. Explain what is going on.\n(c) Now window x with a Hanning window and zero-pad to a length of 2048 using the following command:\nx2 = [x.*hanning(32)' zeros(1,2016)];\nTake the FFT of x2 and plot the magnitude of the result. Compare this to your plot from part(b). How\nis it similar and how is it different? Explain what is going on.\nPS 8-2"
    },
    {
      "category": "Resource",
      "title": "Basis functions and transforms",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/c9d17ae82425e19a0a68764e96b8a60c_0919_basis.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nZ\n(\nZ\n(\nMAS160/510 Supplemental Notes\nBasis functions and transforms\nWhile it's typical to concentrate on representing signals as weighted sums\nof complex exponential functions, here we're going to examine the more\ngeneral case of linear combinations of any basis functions.\nLet's assume we have a set of N basis functions (where N may or may\nnot be finite) φ0(t), φ1(t), ...φN-1(t). We will represent a function x(t):\nNX\n-1\nx(t) ≈ xˆ(t) =\naiφi(t).\n(1)\ni=0\nNote that for the moment we use the approximation symbol ≈ rather\nthan the equal symbol because we haven't spelled out the conditions under\nwhich the sum is exact rather than an approximation.\nFor the moment, assume the basis functions φi are real-valued. They are\nsaid to be orthogonal over some interval (t1 ≤ t ≤ t2) if for all j\nt2\nφi(t)φj (t) =\n0,\ni =6\nj .\n(2)\nλj ,\ni = j\nt1\nFor complex-valued basis sets this complicates slightly to\nt2\n0,\ni = j\nφi(t)φ∗\nj (t) =\nλj ,\n.\n(3)\ni = j\nt1\nIf λj = 1 for all j, then the basis functions are said to be orthonormal.\nWe can use the definition of orthogonality in (3) above to determine the\ntransform coefficients. To compute ak for a particular basis function φk we\nmultiply both sides of (1) by φ∗\nk and integrate:\nZ t2\nZ t2\n\"NX\n-1\n#\nφk\n∗ xˆ(t)dt =\nφk\n∗\naiφi(t) dt.\n(4)\nt1\nt1\ni=0\nNow we reverse the order of summation and integration:\nZ t2\nNX\n-1\nZ t2\nφk\n∗xˆ(t)dt =\nai\nφ∗\nkφi(t)dt\n(5)\nt1\ni=0\nt1\nAnd by (3) we know that the right side is equal to akλk, since all other terms\nof the summation are zero. So the coefficient for the kth basis function is\nsimply\n1 Z t2\nak = λk\nt1\nφk\n∗xˆ(t)dt.\n(6)\n\nn\n(\nIn the case where the basis functions are complex exponentials (which are\northonormal), this becomes\nZ t2\nak =\ne-jkω0t xˆ(t)dt.\n(7)\nt2 - t1\nt1\nA common measure of the degree to which the sum of weighted basis\nfunctions approximates the desired function x(t) is the mean squared error,\nor MSE:\nZ\n\"\n#2\nt2\nNX\n-1\nMSE =\nx(t) -\naiφi(t)\ndt.\n(8)\nt2 - t1\nt1\ni=0\nNow if for all functions x(t) in some class the MSE goes to zero in the limit:\nZ t2 \"\nNX\n-1\n#2\nlim\nx(t) -\naiφi(t)\ndt = 0\n(9)\nN→inf t2 - t1\nt1\ni=0\nwe say that the series approximation converges in the mean to x(t), and that\nthe set of {φi(t)} is complete for all the functions x(t) over that interval.\nWalsh Functions\nAn interesting set of orthonormal basis functions is the Walsh functions.\nThese are defined only on the range (0 ≤ t ≤ 1).\nThere are a number of conventions for ordering the Walsh basis set. All\ngive the same set of functions, but they generate them in differing orders.\nHere we will be using sequency order, where the index k gives the number\nof zero-crossings in the interval.\nThe first sixteen Walsh functions are shown in sequency order in Figure\n1. Note that for even k the ends match in sign, while for odd k they are\nopposite. We can generate these by a recursion formula. First we define the\nzeroth-order basis function:\nφ0(t) =\n1, 0 ≤ t ≤ 1 .\n(10)\nNow, if there isn't a zero-crossing at 1/2 we can add one simply by inverting\nthe second half of the interval. So for odd k,\nφk(t) =\nφk-1(t),\n0 ≤ t < 2\n.\n(11)\n-φk-1(t),\n1 < t ≤ 1\n\n(\nFor even k, we can repeat a squeezed version of φk/2. But if k/2 is odd, we\nneed to invert the second copy so the ends match up, or else there would be\nan extra, unwanted crossing in the middle:\nφk/2(2t),\n0 ≤ t < 1\nφk(t) =\n(-1)k/2φk/2(2t - 1),\n1 < t ≤ 1\n2 .\n(12)\nExample: Represent the function\nx(t) = sin(πt)\n(13)\nwith Walsh functions over the interval (0 ≤ t ≤ 1). Find the first four\ncoefficients.\nTo find the coefficient for each basis function φk(t) we solve (6):\nZ 1\nak =\nφk(t)sin(πt)dt.\n(14)\nFor k = 0, this is simply\nZ 1\na0 =\n(1) sin(πt)dt = - cos(πt) = 0.637.\n(15)\nπ\n\nSimilarly,\nZ 1/2\nZ 1\na1 =\n(1) sin(πt)dt +\n(-1) sin(πt)dt = 0\n(16)\n1/2\nZ 1/4\nZ 3/4\nZ 1\na2 =\n(1) sin(πt)dt +\n(-1) sin(πt)dt +\n(1) sin(πt)dt = -0.264\n1/4\n3/4\n(17)\nZ 1/4\nZ 1/2\nZ 3/4\nZ 1\na3 =\n(1) sin(πt)dt+\n(-1) sin(πt)dt+\n(1) sin(πt)dt+\n(-1) sin(πt)dt = 0.\n1/4\n1/2\n3/4\n(18)\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nFigure 1: The first 16 Walsh basis functions on the interval from 0 to 1."
    },
    {
      "category": "Resource",
      "title": "Error-Correcting Codes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/94144b6cc83df4bea4f9cef22c91baf4_1017_error.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMAS 160/510 Additional Notes: Error-Correcting Codes\nThe fundamental idea behind coders for noisy discrete channels is redundancy. We're going to\nmake individual messages somehow \"more unique\" so that noise won't corrupt enough of the symbols\nin a message to destroy its uniqueness, and we're going to try to do it in a more organized way than\njust repeating the same message over and over again.\nAnother key ingredient in coders for noisy channels is often called noise averaging, and we can\nsee what this means by a simple example. Suppose on average 1% of the received bits have been\ncorrupted by the channel. Looking at a bit, can we tell if it's a \"good\" bit or a \"bad\" bit? No. If\nwe look at a block of ten bits, can we identify the bad ones? No, but we can make some statistical\nobservations about how likely it is that some number of bits is incorrect:\np(10 good) = .9910 ≈ 9 × 10-1\n10!\np(1 bad) = .999 × .01 × (number of combinations : 1!(10 - 1)!) ≈ 9 × 10-2\n10!\np(2 bad) = .998 × .012 × 2!(10 - 2)! ≈ 4 × 10-3\n10!\np(3 bad) = .997 × .013 × 3!(10 - 3)! ≈ 1 × 10-4\nSumming these and subtracting from 1, we find that the probability that more than three bits in\na block have been corrupted is about 2 × 10-6 . So on average only two blocks in a million will\nhave more than three bad bits. If we had some way of correcting no more than three bad bits out\nof a block of ten, 999,998 times out of a million we'd be alright, which might be good enough for\nmany applications. Were we to make the blocks still bigger than 10 bits, we'd find that the average\nnumber of bad bits per block would converge to the 1% figure.\nThe redundancy requirement clearly suggests that if we have n-bit blocks we can't allow all\n2n possible sequences to be valid codes, or else we wouldn't know when a received block is bad.\nGoing further, it seems as if correcting all possible errors of t bits/block will require us to make\nevery legitimate message block differ from every other legitimate message block in at least 2t + 1\nbit positions (the number of bit positions in which two code blocks differ is called the Hamming\ndistance).\nAn error-correcting code, then, is an orderly way of mapping some number of symbols into a\ngreater number so as to increase the Hamming distance between any two valid sequences. They can\nbe divided into two basic types:\n- Block codes map a k-symbol input sequence into an n-symbol output sequence, where each n-\nsymbol output depends upon only the k symbols input and no others. Block codes are usually\nspecified as (n, k) codes, where k is in the range of 3 to a few hundred, and k/n is between\nroughly 1/4 and 7/8. Block codes are also sometimes called group codes.\n- Tree codes are more like state machines - each set of output symbols depends on the current\nset of inputs as well as some number of earlier inputs. These codes are said to have memory,\nand are also called convolutional codes, since the encoding operation can be considered as\nconvolving a sequence of inputs with an \"impulse response\".\nIn this handout, we'll look at block codes, which can be modeled using binary linear algebra.\nThe simplest block code is a parity-check code. We can write the (4,3) example as taking three\nbits (a0, a1, a2) and producing a 4-vector ~a. As this is usually written as a column vector, for\ntypographical convenience we'll show it transposed:\n~a T = (a0, a1, a2, a0 + a1 + a2),\n\nwhere the addition is modulo-2, so 1 + 1 = 0 and subtraction is equivalent to addition. While this\nwon't correct errors (not enough distance between valid sequences to identify which bit is bad if the\nfourth entry isn't the modulo-2 sum of the other three) it will identify blocks with a single bit error.\nA better code might be the (6, 3) code given by:\n~a T = (a0, a1, a2, a0 + a1, a1 + a2, a0 + a1 + a2).\nThis can be written as a system of linear equations:\na3 = a0 + a1\na4 = a1 + a2\na5 = a0 + a1 + a2\nSince in modulo-2, -a = a we can say\na0 + a1 + a3 = 0\na1 + a2 + a4 = 0\na0 + a1 + a2 + a5 = 0\nand this can also be written as a \"parity-check matrix\":\n⎤\n⎡\nH = ⎣011010 ⎦.\nNow we can say that a valid code word is one that satisfies the equation\nH~a = ~0.\nTo test this idea, we can encode a particular sequence, say (100), which comes out as ~aT = (100101),\nand indeed we find that\n⎤\n⎡\n⎢⎢⎢⎢⎢⎢⎣\n⎥⎥⎥⎥⎥⎥⎦\n⎤\n⎡ 110100\n⎤\n⎡ 0\n⎣011010 ⎦\n⎣0 ⎦\n=\n.\nThere is a particular set of (2m - 1, 2m - m - 1) codes called Hamming codes, in which the\ncolumns of the parity-check matrix are the nonzero binary numbers up to 2m . Thus the matrix for\nthe (7, 4) Hamming code is\n⎤\n⎡\n⎣\n0110011 ⎦\nH =\n,\nand ~a is valid if\na3 + a4 + a5 + a6 = 0\na1 + a2 + a5 + a6 = 0\na0 + a2 + a4 + a6 = 0.\nSince a0, a1, and a3 appear only once here, it'll be mathematically easier if we let a2, a4, a5, and a6\nbe our 4-bit input block and compute the other three bits from the above equations. For example:\n(1010)\n(a0a11a3010) = (1011010).\n⇒\n\nNow, how do we correct an error? Consider that we have sent some good sequence ~g, but an error\npattern ~e has been added by the channel, so what is received is\n~r = ~g + ~e.\nUpon receiving ~r, we multiply it by H and get a vector ~s, called the \"syndrome\" (Webster: \"A\ngroup of signs that occur together characterizing a particular abnormality.\"). Thus\n~s = H~r = H~g + H~e.\nBut recall that by definition\nH~g = ~0,\nso\n~s = H~e.\nIn other words, the syndrome depends upon only the error, no matter what the message is. Let's\ntake our valid code (1011010) above, and add an error in the last position: (1011011). Multiplying\nit by H (try it yourself!) we get the answer\n~s T = (111),\nand therefore\n~e T = (0000001).\nIn general, in Hamming codes, the syndrome resulting from an error in the n-th position is the\nn-th column of the H array. But the n-th column is also the number of the bit position with the\nerror, making correction easy. More complicated methods exist for constructing codes that correct\nmultiple-bit errors, and for shuffling data to optimize for partcular kinds of errors (predominantly\nimpulsive noise versus drop-outs of several bits in sequence, for instance). For more information see\nPeterson and Weldon, Error-Correcting Codes (Barker TK5101.P485), or Clark and Cain, Error-\nCorrection Coding for Digital Communications (Barker TK5102.5.C52)."
    },
    {
      "category": "Resource",
      "title": "Modulation",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/7df297c0c228664dad6391e7c325cbbf_1210_modulation.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMAS 160/510 Additional Notes: Modulation\nFrom Amplitude Modulation to Frequency Modulation\nAs usually implemented, FM uses much more bandwidth than AM. You'll note, for\ninstance, that FM radio stations in the US are spaced 200KHz apart, while AM stations\nare spaced only 10KHz apart. So why would one want to use FM? Among other interesting\nfeatures, it allows signal-to-noise ratio, or SNR, to be traded off for bandwidth.\nWe've already seen that amplitude modulation simply requires us to multiply our input\nsignal f(t) by a \"carrier\" sinusoid c(t) = cos ωct, where ωc (or more precisely ωc/2π Hertz)\nis the frequency to which you tune your radio dial in order to receive this signal. In order\nto simplify receiver design, actual AM broadcasts are of the form\ns(t) = K[1 + mf(t)] cos ωct,\nwhere m is chosen so that |mf(t)| < 1. This causes the \"envelope\" of the signal to follow\nthe shape of the input, preventing a negative f(t) from flipping the phase of the sinusoid.\nThis permits demodulating the signal very simply: a narrow bandpass filter is tuned to the\nfrequency of the desired station, its output goes to a nonlinear device called a rectifier which\nremoves the negative portion of the signal, and a lowpass filter then essentially connects\nthe peaks to recover the envelope, which is (1 + mf(t)).1 Such a receiver requires less\nprecision than synchronous demodulation, or multiplying the received signal by a phase-\nlocked sinusoid to shift a spectral replica back down so that it centers on zero frequency\n(this method is used, however, in some of the digital modulation methods we will examine\nlater).\nWe can rethink the formulation of our sinusoidal carrier c(t). Let θ(t) = ωct. In this case,\nθ(t) is a linear function of time, and ωc is its derivative. But in other kinds of modulation\nθ(t) won't be linear with time, and we can't think about frequency as we're accustomed to\ndo. Thus we need to define something called instantaneous frequency ωi as the derivative\nof the angle:\ndθ\nc(t) = cos θ(t),\nωi =\n.\ndt\nIn FM, we want ωi to vary linearly with the modulating signal f(t). Therefore,\nωi = ωc + Kf(t),\nwhich implies that\nZ\nZ\nθ(t) =\nωidt = ωct + K\nf(t)dt.\nThe analysis of FM is far harder than that for AM, as superposition doesn't hold. It's\ntypical, nevertheless, to consider what happens when our f(t) is a sinusoid:\nf(t) = a cos ωmt.\nNow\nωi = ωc + Δω cos ωmt, Δω ωc.\nIf you've ever built an AM receiver, you will justifiably charge us with gross oversimplification, but the\nbasic idea is correct.\n\nZ\nThen\ns(t) = cos(ωct + β sin ωmt),\nwhere we call β the modulation index and define it as the ratio of the maximum frequency\ndeviation to the bandwidth of f(t):\nΔω .\nβ ≡ Δωm\nWhat we're going to investigate is how the bandwidth of the signal s(t) depends on β.\nAM:\nm\nm\nωc-ωm ωc ωc+ωm\nNBFM:\n-β/2\nβ/2\nωc-ωm ωc ωc+ωm\nFigure 1: Spectra for AM and NBFM, given a modulating signal that is a single sinusoid.\nConsider first the expansion of the above s(t):\ns(t) = cos ωct cos(β sin ωmt) - sin ωct sin(β sin ωmt).\nIf β π/2, which is called narrowband FM,\ncos(β sin ωmt) ≈ 1,\nand\nsin(β sin ωmt) ≈ β sin ωmt\nso\ns(t) ≈ cos ωct - β sin ωmt sin ωct.\nIf you consider how we got here, you should be able to see that for small β, for any f(t),\nsNBFM (t) ≈ cos ωct - K\nf(t)dt sin ωct.\nIf we recall that\nsAM (t) = cos ωct + mf(t) cos ωct,\nwe can see that narrowband FM of a sinusoidal f(t) is very similar to AM except that the\nsidebands are π/2 radians out of phase with the carrier. The bandwidth is essentially the\nsame. If f(t) = cos ωmt the spectra look like the illustration in Figure 1. Possible systems\nfor generating each are shown in Figure 2.\nBut NBFM is more complicated and doesn't appear to offer us any real advantages.\nLet's now consider wideband FM (β > π/2).\n\n×\nΣ\nf(t)\ncosωct\n+\n+\nAM:\n×\nΣ\n∫\nf(t)\ncosωct\n-\n+\n90o\nshift\nNBFM:\nFigure 2: Modulators for AM and NBFM.\nWhen β 6 π/2 the approximation we did above doesn't hold. To understand what\nhappens as β increases, it's usual to expand s(t) into a power series and to retain all the\nsignificant terms. See Schwartz's book, referenced at the end of these notes, for more details.\nWe'll let an illustration suffice. For a sinusoidal modulating signal again, with β ≈ 2, we\nget a spectrum as in Figure 3.\nThe bandwidth of FM is, strictly speaking, infinite. But since the terms far away from\nthe carrier are very, very small, they can usually be ignored. A common rule of thumb is\nto say that if the maximum frequency in f(t) is B, then the approximate FM bandwidth\nis 2B(1 + β). For broadcast FM radio, β = 5 and B is 15KHz, giving us a bandwidth of\n180KHz, which corresponds well with the 200KHz channel spacing.\nGiven that an integrator was used in the generation of the signal, you shouldn't be\nsurprised that we use a differentiator to recover it. Since the gain of a differentiator varies\nlinearly with frequency, the output is the input signal with its amplitude (or envelope)\nvarying as the modulating input f(t). Then we can just use an envelope detector (as in\nAM) to get back f(t), as in Figure 4.\nIncidentally, there is an important theorem called Logan's Theorem2 that applies to\nFM. It states that if the bandwidth of a signal is less than an octave, the signal may be\nrecovered exactly (except for a multiplicative constant) from its zero-crossings.3 Analog\nlaser videodiscs work in this fashion, as the video signal is FM modulated and the spacing\nof the pits on the disc records the position of the zero-crossings of the FM signal.\nDigital Modulation - PSK, QAM\n2B. F. Logan, \"Information in the Zero Crossings of Bandpass Signals,\" Bell Sys. Tech. J., 56, pp.\n487-510, April 1977.\nThere is also a requirement that the signal have no zeros in common with its Hilbert transform, among\nother provisos not important here.\n\nωc-2ωm ωc-ωm ωc ωc+ωm ωc+2ωm\n1-β/4\nβ/2\n-β/8\n-β/2\nβ/8\nω\nFigure 3: Spectrum for FM, with a modulating signal of a single sinusoid.\nWe have only a brief amount of time and space to dedicate to the important topic of\ndigital modulation, so we will concentrate on some basic methods. Readers with greater\ninterest in this topic should consult the additional references cited below.\nThe simplest method we will examine is Phase-Shift Keying, or PSK.4 Consider a system\nin which we have two carriers out of phase by π/2 radians, in other words in quadrature\nwith each other. We could then send two bits at a time by converting our pair of bits to\ntwo signals i(t) and q(t) which multiply the cosine and sine components respectively:\nbit pair\ni\nq\n(0,0)\n(0,1)\n(1,0)\n-1\n(1,1)\n-1\nWe call the group of bits transmitted at one time a \"symbol.\" See Figure 5. You can\nalso think about this as a complex multiplication, and the results are often illustrated that\nway.\nA plot of the possible signals (called a constellation) is shown in Figure 6.\nThis system is called QPSK (for Quaternary PSK), or 4-PSK. More bits can be sent at\nonce by selecting more closely-spaced points on the unit circle and multiplying the carriers\nby the sines and cosines of those angles, though the noise immunity decreases as points are\nadded. Decoding a PSK signal requires a stable phase reference, which may be difficult\nto generate, so a variant is Differential QPSK, or DQPSK. Here the phase reference is the\njust-transmitted bit pair, and each bit pair shifts the phase from the preceding one. So (0,0)\nis sent as a shift of π/4 radians, (0,1) shifts by 3π/4, et cetera (the π/4 spacing assures that\nThe word \"keying\" hearkens back to the days when the only binary information on the radio was Morse\nCode from radio telegraph keys! Who says there is no respect for tradition in this fast-moving field?\n\nd/dt\nFigure 4: Effect of a differentiator on an FM signal.\nthere is always a phase shift from bit pair to bit pair).\nSince maximum noise immunity requires as much distance as possible (for a given\namount of signal power) between adjacent points in the constellation, we should be able to\ndo better if we change both amplitude and phase of the carriers. This is called APK, or\nAmplitude-Phase Keying; QAM, or Quadrature Amplitude Modulation is a very common\nspecial case.5\nSuppose we take the preceding modulator and stipulate that we send four bits at once\nwith two each going to generate an i and a q that can each take one of four values. Then\nour 16-QAM constellation looks like a square grid, as in Figure 7.\nIn practice, we need to lowpass filter i(t) and q(t), since if the bit stream has square\npulses, the bandwidth is essentially infinite no matter what the bit rate. With proper\nbandlimiting 16-QAM can carry up to four bits per second per Hertz of channel bandwidth\n(so we could send four megabits per second in a 1MHz channel).\nIn the most general case, APK needn't be on a square array. Triangular packing maxi\nmizes Euclidean distance between points, and is how 64-APK is usually implemented.\nDigital Modulation - CDMA, OFDM\nSpread-spectrum techniques, just like FM, modulate a signal in a way that occupies\nmore bandwidth than the minimum needed to transmit the signal. They do this by shifting\nthe carrier frequency as a function of time. Advantages include increased security, less\nsensitivity to interference at a fixed frequency, and less sensitivity to transmission channels\nthat may have reduced frequency response in a particular narrow frequency range.\nQAM shows up in the analog world as well, where it is used for the color-difference signals in NTSC and\nPAL color television. It is no mere coincidence that the NTSC color-difference signals are called i and q!\n\n×\nΣ\ncosωct\n+\n+\n90o\nshift\n×\ni(t)\nq(t)\nbit\nstream\ni,q\ngen-\nerator\nFigure 5: Digital quadrature modulator.\ni\nq\nFigure 6: Constellation for 4-PSK.\nThe first such method was invented and patented in 1942 by actress Hedy Lamarr and\ncomposer George Antheil, and is nowadays known as frequency-hopping code division multi\nple access, or FH-CDMA. A transmitter and receiver are synchronized, and the \"hoppping\"\nfrom frequency to frequency takes place many times a second under control of an algorithm\nsuch as a pseudo-random sequence.\nA related technique, direct sequence CDMA (or DS-CDMA), combines the data with\na spreading sequence (or \"chipping code\") which divides the data among the carriers with\na degree of redundancy (similarly to the error-correcting codes we examine in this class).\nThis adds an additional layer of robustness against data loss.\nIt's usually the case that an RF signal will be received with several trailing echoes, as\nthe signal bounces off buildings or large geographical features. This effect, called multipath,\nis the source of \"ghosts\" on an analog television picture, and can also be thought of as the\n\ni\nq\nFigure 7: Constellation for 16-QAM.\nΣ\n+\n+\n+\nmbol 1\n+ jq1)\nmult by\ncarrier 1\nmbol 2\n+ jq2)\nmult by\ncarrier 2\nmbol n\n+ jqn)\nmult by\ncarrier n\nFigure 8: Orthogonal frequency-division multiplexing.\nconvolution of the signal with an impulse response having a series of weighted delays. In a\ndigital modulation system, if the delays are on the order of the length of time it takes to\ntransmit a symbol, we can get intersymbol interference, or ISI, in which a delayed symbol\narrives at the same time as a symbol on the direct path. While it's possible to detect\nthe echoes and equalize for them by deconvolving at the receiver, greater immunity to ISI\ncomes at the cost of reducing the symbol rate. Orthogonal frequency-division multiplex\ning (OFDM) methods do this by performing simultaneous digital modulation onto a large\nnumber of closely-spaced carriers, each sending one symbol at a very low symbol rate (and\nthus a low bandwidth) as in Figure 8. Thus if there are n carriers, each modulator takes\nevery n-th symbol. As shown in Figure 9, the digital signals are rectangular pulses (not\nbandlimited) in the time domain and thus sinc-shaped in the frequency domain. Appropri\nate spacing of the carriers makes them orthogonal and thus there is no interference between\nthem (like FM, the bandwidth is strictly speaking infinite). Note that multiplying a set of\ncomplex numbers by a set of orthogonally-spaced sinusoids and summing their products is\nthe same as an inverse DFT, and indeed this system is generally implemented by performing\nan IFFT (of as many points as the number of carriers) in the modulator and then converting\nfrom digital to analog just before transmitting. Similarly the demodulation is done using\n\nFigure 9: If COFDM signals are rectangular pulses in time, they are sinc-shaped in fre\nquency. If the carriers are spaced orthogonally, there is no interference from one carrier to\nanother. (Adapted from Maddocks, 1993)\nan FFT. The result is a system with the same spectrum efficiency as the basic modulation\nmethod used on each carrier, but with much more immunity to multipath and interference.\nIf the data have an error correcting code applied before modulation, the system is called\ncoded OFDM, or COFDM.\nAdditional Reading\nB. E. Keiser, Broadband Coding, Modulation, and Transmission Engineering, Prentice-\nHall, 1989.\nM. C. D. Maddocks, An Introduction to Digital Modulation and OFDM Techniques,\nBBC Research Department Report BBC RD 1993/10, 1993.\n(http://www.bbc.co.uk/rd/pubs/reports/1993\nH. K. Markey and G. Antheil, US Patent 2,292,387, Aug. 11, 1942.\nM. Schwartz, Information Transmission, Modulation, and Noise, McGraw-Hill, 1990.\n-10.pdf)"
    },
    {
      "category": "Resource",
      "title": "Yet more notes on partial fraction expansion Revised Edition",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/e1d0af0afe697e8f48bf2b582508fb67_1121_partial_fra.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nYet more notes on partial fraction expansion\nRevised Edition\nThe most general case of partial fraction expansion assumes you have a proper\nfraction with all positive powers of z (if it's not proper, carry out long division\nuntil it is; if it has negative powers multiply by zn/zn, where -n is the highest\nnegative power).\nLet's suppose we've satisfied the above requirements, then we have an X(z)\nthat can be written as\nB(z)\nX(z) =\n,\nA(z)\nwhere the numerator is of order m and the denominator of order n, m ≤ n. The\nfirst step is to factor the denominator:\nB(z)\nX(z) =\n,\n(z - p1)(z - p2) . . . (z - pn)\nwhere the pi are poles of X(z). Then we need to expand this into a sum of\nterms\nX(z) = c0 + c1z + c2z + . . . + cnz\n,\nz - p1\nz - p2\nz - pn\nthe inverse z-transform of each of which we can look up in a table.\nThe individual ci factors are solved for as follows:\nc0 = X(z) z=0 ,\n|\nwhich is actually just the ratio of the constant terms in the numerator and\ndenominator, while for 0 < i ≤ n\nz - pi\n\nci =\nX(z)\n.\nz\nz=pi\nExample: Find x[n] when\nX(z) =\n3 - 5 z-1\n.\n1 - 2\n3 z-1 + 2\n1 z-2\nFirst, we need to multiply through by z2/z2 to make all the powers positive,\nleaving us with\nX(z) =\n3z2\n- 5 z\n.\nz2\nz + 1\n-\nThen we factor the denominator:\nX(z) =\n3z2\n- 2\n5 z\n.\n(z - )(z - 1)\n\nNow solve for the ci:\n0 = 0\nc0 = 1\n\n=\nz=\n\n-\n= 1\n\n.\n-\nz -\n3z\n-\n)(z - 1)\nz\n= 2\n=\nc1\n(z -\nz\nz - 1\n3z\n-\n-\n-\n)(z - 1)\nz\n=\n=\nc2\n(z -\nz\nz=1\nThus\n2z\nz\nX(z) = z -1\n+\n,\nz - 1\nwhich we can look up in the table to find\n1 n\n\n\" 1 n-1\n#\nx[n] = u[n] 2\n+ 1n\n= u[n]\n+ 1 .\nRepeated poles: The method explained above needs an additional step\nwhen a pole appears more than once in the denominator. Suppose some pole\npi shows up r times, or in other words the denominator contains the expression\n(z - pi)r . Then the expansion requires all the terms\nci1 z\nz - pi\n+\nci2 z\n(z - pi)2\nr\n+ . . . +\ncir z\n,\n(z - pi)r\nwhich can be iteratively (tediously) solved for as\n(z - pi)r\n\ncir =\nX(z)\n,\nzr\nz=pi\nr\n(z - pi)r-1\ncir z\n\n=\n,\nci(r-1)\nzr-1\nX(z) - (z - pi)r\nz=pi\n(\n(z - pi)r-2 \"\ncir zr\nzr-1 #)\n=\n,\nci(r-2)\nzr-2\nX(z) - (z - pi)r - (\nc\nz\ni(r\n-\n-1)\npi)r-1\nz=pi\nand so on. Note that you must simplify the expressions inside the braces be\nfore doing the z = pi substitution; if you don't, and if there are any (z - pi)\ndenominators, you will find it difficult to evaluate the result correctly."
    },
    {
      "category": "Resource",
      "title": "Z-transforms: Part I",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/3554d860cdffc5781821592e9d99dba3_1121_zx1.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nZ-transforms : Part I\nMIT MAS 160/510 Additional Notes, Spring 2003\nR. W. Picard\nRelation to Discrete-Time Fourier Transform\nConsider the following discrete system, written three different ways:\ny[n]\n= b-1y[n + 1] + b1y[n - 1] + a-1x[n + 1] + a0x[n] + a2x[n - 2]\nY (z)\n= b-1zY (z) + b1z-1Y (z) + a-1zX(z) + a0X(z) + a2z-2X(z)\nY (z)\na-1z + a0 + a2z-2\nH(z)\n=\n=\n(1)\nX(z)\n-b-1z + 1 - b1z-1\nSimple substitution finds the Z-transform for a discrete system represented by a linear\nconstant coefficient difference equation (LCCDE). Simply replace y[n] with Y (z), x[n] with\nX(z), and shifts of n0 with multiplication by zn0 . That's almost all there is to it.\nSet\njωˆ\nz = re\nand let r = 1 for the moment. Then a shift in time by n0 becomes a multiplication in the\nZ-domain by ejωn0 . This should look familiar given what you know about Fourier analysis. Now\nhere's the formula for the Z-transform shown next to the discrete-time Fourier transform of\nx[n]:\ninf\nZ-transform :\nX(z)\n=\nX\nx[n]z-n\nn=-inf\nj ˆ\ninf\nωn\nDTFT:\nX(e ω)\n=\nX\nx[n]e-j ˆ ,\nn=-inf\nwhere we have used the notation X(ejωˆ) instead of the equivalent X(ˆω), to emphasize similarity\nwith the Z-transform . Substituting z = rejωˆ in the Z-transform ,\ninf\nωn\nX(z) =\nX\n(x[n]r-n)e-j ˆ ,\nn=-inf\nreveals that the Z-transform is just the DTFT of x[n]r-n . If you know what a Laplace transform\nis, X(s), then you will recognize a similarity between it and the Z-transform in that the Laplace\ntransform is the Fourier transform of x(t)e-σt . Hence the Z-transform generalizes the DTFT\n\nX\nX\nin the same way that the Laplace transform generalizes the Fourier transform. Whereas the\nLaplace transform is used widely for continuous systems, the Z-transform is used widely in\ndesign and analysis of discrete systems.\nYou may have noticed that in class we've already sneaked in use of the \"Z-plane\" in talking\nabout the \"unit circle.\" The \"Z-plane\" contains all values of z, whereas the unit circle contains\nonly z = ejωˆ. The Z-transform might exist anywhere in the Z-plane; the DTFT can only exist\non the unit circle. One loop around the unit circle is one period of the DTFT.\n(For those who know Laplace transforms, which are plotted in the S-plane, there is a\nnonlinear mapping between the S-plane and the Z-plane. The Im{s} axis maps onto the unit\ncircle, the left half plane (σ < 0) maps inside the unit circle, and the right half plane (σ > 0)\nmaps outside the unit circle. Poles and zeros in the Laplace transform are correspondingly\nmapped to poles and zeros in the Z-transform .)\nM\nX\nDiscrete transfer function\nEquation (1) gave the transfer function, H(z), for a particular system. In general the form for\nLCCDE systems is\nN\nX\naly[n - l]\nbkx[n - k]\n=\nl=-N\nN\n=\nM\nX\nk=-M\nwhich transforms to\nalz-lY (z)\nbkz-kX(z)\nM\nX\nl=-N\nk=-M\nbkz-k\nH(z) = Y (z)\n=\nk=-M\nN\nX(z)\nl=-N\nNote that the limits M, N do not impose symmetry on the number of terms in either direction.\nWe could have b-1 = b1, etc. One could also have N = 0 with M finite, yielding an FIR system,\nor N = 0 and M = inf yielding an IIR system, or an IIR system can be created with N > 0 and\nM = 0. There are many possibilities, but in each case the transfer function H(z) completely\ncharacterizes the linear shift invariant system. The following relationships hold:\ny[n]\n= x[n] ∗ h[n]\nY (z)\n= X(z)H(z)\nWe can learn to look at H(z) and infer properties of the system. Is it low-pass, single-pole, FIR,\nIIR, stable, etc.? In order to do this, we need to consider its poles, zeros, and (like the Laplace\ntransform) regions of convergence.\nalz-l\n\nh[n]\nn\nPoles, Zeros, Regions of Convergence\nExample 1: Infinite-length right-sided\nConsider the causal sequence:\nh1[n] = a n u[n]\nThis impulse response might be used to model signals which decay over time, like echos.\nConsider its Z-transform :\ninf\nn\nH1(z)\n=\nX\na u[n]z-n\nn=-inf\ninf\nn\n=\nX\na z-n\nn=0\ninf\n=\nX\n(az-1)n .\n(2)\nn=0\nRemember the following useful result from mathematics of series summations:\ninf\nX\n=\n,\nγ < 1.\nn=0\nγn\n1 - γ\n| |\nNotice this result is only true when γ < 1. Forgetting this constraint is dangerous. When\n| |\n|γ| ≥ 1 then the series does not converge, and we say \"it does not exist\" or \"it blows up.\" To\nproceed with (2) we must therefore have az-1 < 1, or z > a . This completes the result:\n|\n|\n| |\n| |\nn\nZ\na u[n]\n,\nz > a .\n←→ 1 - az-1\n| |\n| |\nThe region in the Z-plane where the transform exists is called the region of convergence\n(ROC), e.g., z > a for this example. Even though we can evaluate\nfor z\na , it is\n1-az-1\n| |\n| |\n| | ≤| |\nusually inappropriate to do so since this expression for the Z-transform is only defined within\nits ROC.\nLet's draw a picture of this. First we need to think about the poles and zeros of H1(z).\nPoles are the values of z for which the Z-transform is inf and zeros are the values of z for which\n\nz > a\na\nX\nthe Z-transform is 0. Every Z-transform has the same number of poles as it has of zeros. It is\ngood practice to count them up when you think you've found them all. For the example above\nthere is one pole and one zero, and the ROC is outside the pole:\npole: z = a\nH1(z) =\n,\nz > a .\n1 - az-1\n| |\n| |\nzero: z = 0\nThe zero at z = 0, outside the ROC, comes only from the expression\nwithout considering\n1-az-1\nits ROC. If you are troubled that there is a finite value (namely zero) found outside the ROC\nthen you are currently in good company - because the staff is still troubled by this as well: how\ncan the function be said to be zero outside its ROC when it doesn't even exist outside its ROC?\nNote we do not have trouble saying there is a pole outside the ROC, because a pole is where the\nfunction \"blows up\" which is just what you'd expect when you're not in the ROC. Nonetheless,\nall the standard texts put that zero there, outside the ROC. We will keep you posted if we\nconvince the authors of the standard texts not to do that, or if they convince us not to worry\nabout it.\nDoes the DTFT exist for h1[n]? For the Laplace transform, the Fourier transform existed\nif the ROC included the jω axis. For the Z-transform the DTFT exists if the ROC includes the\ninf\nunit circle. If this is true, we say the system is \"stable,\" i.e.,\nX\n|h[n]| < inf, or the impulse\nn=-inf\nresponse is \"absolutely summable.\" For h1[n], we see that the DTFT exists if a < 1.\n| |\nExample 2: Infinite-length left-sided\nConsider the anti-causal sequence obtained by looking at the previous example through a\nmirror:\nh2[n]\n= -a n u[-n - 1]\nH2(z)\n= -\ninf\na n u[-n - 1]z-n\nn=-inf\n-1\nn\n=\nX\na z-n\n-\nn=-inf\ninf\np\n=\nX\na-pz\n-\np=1\n\nz < a\na\ninf\n=\n1 -\nX\n(a-1 z)p\np=0\n=\n,\na-1 z < 1\n1 - 1 - a-1z\n|\n|\n1 - az-1\n=\n1 - az-1 --az-1\n,\nz < a\n1 - az-1\n| |\n| |\n=\n,\nz < a .\n1 - az-1\n| |\n| |\nSimplifying the last step gives:\nn\nZ\n- a u[-n - 1] ←→ 1 - az-1 , |z| < |a|.\nThe only difference between this Z-transform and the one in (2) is the ROC. For the\nanti-causal case we have the same poles and zeros, but the picture is shaded inside the pole:\npole: z = a\nH2(z) =\n,\nz < a .\nzero: z = 0\n1 - az-1\n| |\n| |\nIn general, an infinite single-pole sequence will have an ROC inside the pole if it is left-sided,\nand outside the pole if it is right-sided. Looking at the ROC for h2[n] tells us its DTFT will\nonly exist if a > 1.\n| |\nWhat is the effect of time-shifting on the Z-transform ? Consider shifting the right-\nsided h1[n] right by one sample, hˆ1[n] = an-1u[n - 1], so that it only contains nonzero terms\nwhen n ≥ 1. The Z-transform is\nz-1\npole: z = a\nHˆ1(z) = 1 - az-1 , |z| > |a|\nzero: z = inf.\nShifting the sequence has moved the zero out to infinity, but has not affected the pole. Fur\nthermore, all subsequent shifts to the right will result in additional zeros at infinity (and corre\nsponding poles at the origin.)\nThe zeros do not affect the ROC. Intuitively this is pleasing - shifting does not affect\nconvergence of the sequence.\n\n< z <\na\nb\na\nb\nExample 3: Infinite-length two-sided.\nLet's add the two one-sided examples above, allowing the possibility for them to have\ndifferent amplitudes:\nh3[n] = -bn u[-n - 1] + a n u[n]\nEverything we've been doing in these notes is linear so the Z-transforms also add. However,\nto satisfy both ROC's requires taking their intersection. If a = b then the intersection is the\nempty set - so the new Z-transform has no ROC, i.e., H3(z) doesn't exist. The picture is a\nsequence decaying on one side of the origin and blowing up on the other. The only hope of the\nZ-transform converging is if a < b, i.e., the ROC: a < z < b .\n| |\n| |\n| |\nExample 4: Finite length Consider a finite-length sequence:\nh4[n]\n= δ[n] + a1δ[n - 1] + a2δ[n - 2]\nH4(z) = 1 + a1z-1 + a2z-2\nWhere is the ROC? If z = 0 we have division by zero, so we see there is a pole at z = 0. The\nzeros can be found by solving the roots of the quadratic. There will be two solutions, hence two\nzeros. Since the number of poles must be the same as the number of zeros, we need to find a\nsecond pole. This will be at z = 0 also.\nBecause we can factor any polynomial in z, we can always find its poles and zeros, e.g.,\n1 + 4z-2 = (1 + 2z-1)(1 - 2z-1) has zeros: z = 2, -2 and a \"double pole\" at z = 0. In fact,\nevery finite length sequence will converge, so it will not have any poles other than possibly at\nz = 0 or z = inf. It will only have poles at z = 0 if it contains negative powers of z (causal\nterms) and it will only have poles at z = inf if it contains non-causal terms. The ROC will exist\neverywhere except possibly at z = 0, inf. The ROC for any FIR filter is 0 < |z| < inf.\nFour cases have been introduced above, corresponding to four cases of ROC's. These four\ncases are summarized with the properties of an ROC:\nProperties of an ROC:\n1. Bounded by circles (dependent only on z ).\n| |\n2. Connected and bounded by poles or by inf. (It can't contain a pole!)\n3. If h[n] is absolutely summable, then the ROC contains the unit circle, the system has a\nDTFT and is said to be \"stable.\"\n\n4. A stable and causal sequence has all its poles inside the unit circle.\n5. Right-sided infinite sequence: ROC lies outside the outermost pole, R- < |z| < inf. If also\ncausal, then the ROC includes |z| = inf.\n6. Left-sided infinite sequence: ROC lies inside the innermost pole, 0 < z < R+. If also\n| |\nanti-causal, then the ROC includes z = 0.\n| |\n7. Two-sided infinite sequence: ROC lies between the two poles, R- < |z| < R+. The ROC\ndoes not include |z| = 0 or |z| = inf.\n8. Finite-length sequence: Always converges. ROC always includes 0 < |z| < inf. ROC\nincludes 0 if sequence is anti-causal, or includes inf if causal.\nThe three infinite length cases, and the finite length case (with 3 examples) are summarized\npictorially in Fig. 1.\n\nx n( )\nn\nFIR\nIIR\nRegion of Convergence\nX z[ ]\nAll z\nexcept\nz = 0\nAll z\nexcept\nz = inf\nAll z\nexcept\nz = 0\nz = inf\nz >R-\nz <R+\nR-< z <R+\nFigure 1: Example ROC's for finite and infinite length sequences."
    },
    {
      "category": "Resource",
      "title": "Z-transforms: Part II",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/9d171c9c6ead6c737391369c0ae6395a_1121_zx2.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nZ-transforms : Part II\nMIT MAS 160/510 Additional Notes, Fall 2003\nR. W. Picard\nKey Properties\nFrom the relationship between the DTFT and the Z-transform we might expect that many of\nthe DTFT properties carry over. We're right! Most of the properties can be derived with a line\nor two of algebra. Here are a few useful ones:\nLinearity:\ninf\nZ-transform {ax[n] + by[n]} =\nX\n(ax[n] + by[n])z-n\nn=-inf\ninf\ninf\n= a\nX\nx[n]z-n + b\nX\ny[n]z-n\nn=-inf\nn=-inf\nZ\nax[n] + by[n]\naX(z) + bY (z)\n←→\nDifferentiation:\ndX(z)\ninf\ndz\n= -\nX\nx[n]nz-n-1\nn=-inf\ninf\n= -z-1 X\n(nx[n])z-n\nn=-inf\nnx[n]\nZ\ndX(z)\ndz\n←→ -z\nShifting:\nZ-transform {x[n + n0]} =\ninf\nX\nx[n + n0]z-n\n=\nn=-inf\ninf\nX\nx[p]z-p+n0\n=\np=-inf\nz n0\ninf\nX\nx[p]z-p\np=-inf\nZ\nx[n + n0]\nzn0 X(z)\n←→\n\nWhen you are in doubt about how to apply properties from a table, then try deriving\nthe Z-transform directly from your sequence. The formula is usually easy to simplify given\nPinf\nn=0 αn =\n, |α| < 1.\n1-α\nInverse Z-transform\nThe goal of an inverse Z-transform is to get x[n] given X(z). Here are four ways to find an\ninverse Z-transform , ordered by typical use:\n1. Use a Z-transform table. (See additional handouts.)\n2. Partial fraction expansion.\n3. Long division.\n4. Contour integration.\nUsing the tables can be easiest, but they are not always with you when you need them,\nand sometimes the case you want isn't in a table.\nPartial fraction expansion and long division are the two simplest methods. Contour inte\ngration can almost always be avoided. You are not responsible for knowing how to do contour\nintegration, but we can show you how it works outside of class if you're interested. However, it\nis good to have at least seen a contour integral so that you can recognize it if you see it again.\nBriefly, imagine C to be a closed contour that surrounds the origin of the z-plane and lies in\nthe region of convergence for some X(z). Then:\n1 I\nx[n] =\nX(z)z n-1dz,\n2πj\nC\nwhere the intergration is counterclockwise over C. There are simple ways to evaluate this integral\nfor most of the functions we'll deal with in this class, but we'll leave this for outside discussions,\nas you will not be responsible for knowing this method.\nIn the rest of these notes we will work examples using partial fraction expansions and long\ndivision. For both cases, it does not matter whether you prefer z-1's or z's, but always do the\nfollowing first:\nMake sure the fraction contains only nonpositive or only nonnegative powers of z.\nHere's a quick example:\n1 + az-1 + bz-2\nz-1 + az-2 + bz-3\nz2 + az + b\n=\nor\ncz + d + ez-1\nc + dz-1 + ez-2\ncz3 + dz2 + ez\nIf you try to work these methods without doing this, you are exceedingly likely to make mistakes.\nMany a quiz point has been lost by a student who forgets to do this step first. You have been\nwarned.\n\nPartial Fraction Expansion\nFor this method, we assume you know that both\nz\n1 - az-1\nand\nz - a\ntransform either to anu[n] or to -anu[-n - 1] depending on whether\nrespectively.\n|z| > |a| or |z| <\n(1)\n|a|\nTo find the inverse Z-transform using partial fraction expansion there are two steps:\n1. Convert the Z-transform to the form of a proper fraction.\n2. Convert the proper fraction to a linear combination of expressions like (1).\nExample: Find h[n] by partial fraction expansion, given\nz-1 + z-2\nH(z) =\n.\n1 - 4 z-1 + 8 z-2\nFirst, let's make it proper. We can do this by dividing until it is a proper fraction, or by factoring\nout some z's or z-1's and later applying the shifting property. The latter is usually easier:\n1 + z-1\nzH(z) = H1(z)\n=\n3 z-1 + 1 z-2\n1 - 4\n1 + z-1\n= (1 - 1 z-1)(1 - 1 z-1)\nA\nB\n=\n+\n,\n1 - 4\n1 z-1\n1 - 2\n1 z-1\nwhere we need to find the constants A and B. Cross multiplying and dividing gives\nA[1 - z-1] + B[1 - z-1] = 1 + z-1 .\nEquating powers of z gives the two equations:\nA + B =\nA\nB\n- 2 - 4\n=\n1.\nThe solutions are A = -5, B = 6, which we plug back in. Then we can recognize the inverse\ntransform:\nH1(z)\n=\n-\n+\n1 - 4 z-1\n1 - 2 z-1\nZ\n←→ -5( )n u[n] + 6( )n u[n].\nApplying shifting yields:\nH(z)\n=\nz-1H1(z)\nH(z)\nZ\n-5(1)n-1 u[n - 1] + 6( 1)n-1 u[n - 1].\n←→\n\nHow did we know to pick the right-sided inverse transforms as opposed to the left-sided\nones or some mixture of both? We didn't; in fact they may not be the correct choice. We can't\nknow which one is correct yet - we need more information first.\nLet's back up and consider all the combinations for inverting H1(z) (before shifting):\n-5(1 u[n] + 6(1\n4)n\n)nu[n]\nright-sided\n)n\n)n\n5(\nu[-n - 1] + -6(\n)n\nu[-n - 1] left-sided\n)n\n-5(\nu[n] + -6(\nu[-n - 1] + 6(1\nu[-n - 1]\ntwo-sided\n)n\n4)n\n5(\nu[n]\nimpossible\nSince there are two poles in this system (z\n), there are three ways the ROC's can\n= ,\nhave a non-empty intersection (and a fourth case where there is no intersection). These four\ncases correspond to the ROC's:\n2 < z\nright-sided\n|\n|\nleft-sided\n|z| < 4\ntwo-sided\n< z <\n| |\nand\n(no intersection!)\n|z| <\n< |z|\nTo know which of three possible answers it is, you have to know if the signal is left-, right-,\nor two-sided. Knowing it is absolutely summable would also give the answer uniquely. In general\nfor p ≥ 2 poles, the ROC is one of p + 1 cases: the region inside the innermost pole, the region\noutside the outermost pole, or one of the regions between two poles. Don't forget: the ROC can\nnever contain a pole.\nLong Division\nConsider finding h[n] by long division, given\nH(z) =\n.\n1 - az-1\n1 + az-1\n2 z-2\n+ a\n+ . . .\n1 - az-1\n1 - az-1\naz-1\naz-1 - a 2 z-2\na 2 z-2\n. . .\n\nDivision gives the result, h[n] = anu[n] which converges if a < 1. But what if a > 1? Consider\n| |\n| |\nthe same division, \"flipped around\":\n-az-1 + 1\n\n-a-1z\n-a-2 z 2 - . . .\n-a-1 z\na-1 z\na-1 z - a-2 z 2\na-2 z 2\n. . .\nFlipping the divisor gives a different result, h[n] = -anu[-n - 1] which converges if |a| > 1.\nBeware how you execute long division! For starters, make sure you have converted the\nnumerator and denominator to be either all in powers of z-1 or all in powers of z, but not a\nmixture of both. Then it may be easier to split the fraction into a sum of fractions, each having\na single term in the numerator as in the example above. Then be careful how you divide - try\nboth of the above ways if you are unsure, and look at whether the coefficients are growing or\nshrinking. In general the method of long division is simple for one-sided sequences; however, it\ncan lead to confusion if you are not careful at each step.\nWhen in doubt, try working the same problem using two or more methods - it is a good\nway to catch those inevitable algebra mistakes, since the different methods should all lead to\nthe same result."
    },
    {
      "category": "Resource",
      "title": "MATLAB help sheet",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/c89d6b542f7a34eb5c6f33342a20c176_rec2_matlab_help.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n»x=1\n%scalar (% signs are comments and aren't evaluated)\nx =\n»y=[1 2 3 4 5 6] % sequence vector (row)\ny =\n1 2 3 4 5 6\n»z=[1;2;3;4;5;6] % list vector (column)\nz =\n»a=[1 2 3;4 5 6;7 8 9] % matrix\na =\n1 2 3\n4 5 6\n7 8 9\n»b=[y;y;y]\n%matrix (list of sequences)\nb =\n1 2 3 4 5 6\n1 2 3 4 5 6\n1 2 3 4 5 6\n»c=[z z z]\n%matrix (sequences of lists)\nc =\n1 1 1\n2 2 2\n3 3 3\n4 4 4\n5 5 5\n6 6 6\n»y'\n%conjugate transpose\nans =\n»y=[j*1, j*2, j*3, j*4, j*5, j*6]\ny =\nColumns 1 through 2\n0 + 1.00000000000000i 0 + 2.00000000000000i\nColumns 3 through 4\n0 + 3.00000000000000i 0 + 4.00000000000000i\nColumns 5 through 6\n0 + 5.00000000000000i 0 + 6.00000000000000i\n»y'\n%conjugate transpose (watch out, it switches sign of the complex part!) (converts col to row, row to col)\nans =\n0 - 1.00000000000000i\n0 - 2.00000000000000i\n0 - 3.00000000000000i\n0 - 4.00000000000000i\n0 - 5.00000000000000i\n0 - 6.00000000000000i\n»y(:)\n%makes column (this is another way -- this always makes it a column)\nans =\n0 + 1.00000000000000i\n0 + 2.00000000000000i\n0 + 3.00000000000000i\n0 + 4.00000000000000i\n0 + 5.00000000000000i\n0 + 6.00000000000000i\n»d=0:1/10:1\n%sequence (beg: step: end)\nd =\nColumns 1 through 4\n0 0.10000000000000 0.20000000000000 0.30000000000000\nColumns 5 through 8\n0.40000000000000 0.50000000000000 0.60000000000000 0.70000000000000\nColumns 9 through 11\n0.80000000000000 0.90000000000000 1.00000000000000\n»e=sin(2*pi*d)\n%operation on sequence (operation on each element of sequence)\ne =\nColumns 1 through 4\n0 0.58778525229247 0.95105651629515 0.95105651629515\nColumns 5 through 8\n0.58778525229247 0 -0.58778525229247 -0.95105651629515\nColumns 9 through 11\n-0.95105651629515 -0.58778525229247 0\n»f=[0:1/8:1;0:1/16:.5;0:1/32:.25] %list of sequences\nf =\nColumns 1 through 4\n0 0.12500000000000 0.25000000000000 0.37500000000000\n0 0.06250000000000 0.12500000000000 0.18750000000000\n0 0.03125000000000 0.06250000000000 0.09375000000000\nColumns 5 through 8\n0.50000000000000 0.62500000000000 0.75000000000000 0.87500000000000\n0.25000000000000 0.31250000000000 0.37500000000000 0.43750000000000\n\n0.12500000000000 0.15625000000000 0.18750000000000 0.21875000000000\nColumn 9\n1.00000000000000\n0.50000000000000\n0.25000000000000\n»g=sin(2*pi*f)\n%operation on list of sequences (ex.could have a list of sines sequences with different frequencies)\ng =\nColumns 1 through 4\n0 0.70710678118655 1.00000000000000 0.70710678118655\n0 0.38268343236509 0.70710678118655 0.92387953251129\n0 0.19509032201613 0.38268343236509 0.55557023301960\nColumns 5 through 8\n0 -0.70710678118655 -1.00000000000000 -0.70710678118655\n1.00000000000000 0.92387953251129 0.70710678118655 0.38268343236509\n0.70710678118655 0.83146961230255 0.92387953251129 0.98078528040323\nColumn 9\n1.00000000000000\n»whos\n%variable list and sizes ( helpful when doing vector multiplication)\nName Size Bytes Class\na 3x3 72 double array\nans 1x10 4192 struct array\nb 3x6 144 double array\nc 6x3 144 double array\nd 1x11 88 double array\ne 1x11 88 double array\nf 3x9 216 double array\ng 3x9 216 double array\nx 1x1 8 double array\ny 1x6 48 double array\nz 6x1 48 double array\nGrand total is 276 elements using 5264 bytes\nleaving 307693008 bytes of memory free.\n»\n»y-1\n%addition\nans =\n0 1 2 3 4 5\n»z\nz =\n»z*(y-1)\n%outer product 6x1 x 1x6 = 6x6 (makes a list of sequences, each sequence y multiplied by corresponding element of list in z)\nans =\n0 1 2 3 4 5\n0 2 4 6 8 10\n0 3 6 9 12 15\n0 4 8 12 16 20\n0 5 10 15 20 25\n0 6 12 18 24 30\n»(y-1)*z\n%inner product 1x6 x 6x1 = 1x1 (multiplies each corresponding element of y and z, then adds the resulting elements together)\nans =\n»0*1+1*2+2*3+3*4+4*5+5*6 inner product\nans =\n»[1 2 3]*g\n%vector x matrix (sequence of inner products)\nans =\nColumns 1 through 4\n0 2.05774461196511 3.56226385946836 4.22157654526793\nColumns 5 through 8\n4.12132034355964 3.63506112074366 3.18585215990695 3.00061592475332\nColumn 9\n3.00000000000000\n»%g was the list of sine sequences;\n»% but you can also think of it as a sequence of lists\n»%with each list being the values for the three sinewaves at different times in the sequence.\n»%you are doing an inner product between [1 2 3] and each column (list) of the sine sequence.\n»%at each time in the sequence, you are scaling each sine wave by a different amount then adding them together.\n»%g = [sine1(t0) sine1(t1) sine1(t2)...\nsine2(t0) sine2(t1) sine2(t2)..\nsine3(t0) sine3(t1) sine3(t2)...]\n»%[1 2 3]*g=[1*sin1(t0)+2*sin2(t0)+3*sine(t0), 1*sin1(t1)+2*sine2(t1)+3*sine3(t1), ...\n=====\nFunction:\ninput: f (row),X(row),fs(scalar),dur(scalar)\noutput: xx(row)\nfunction xx=sumcos(f,X,fs,dur)\n.\n.\n.\nxx =?\n\nsave as sumcos.m\n======\n»z1=5*exp(j*0.5*pi);\n»z2=5*exp(j*-0.25*pi);\n»zp=sumcos([1, 1/3],[z1,z2],10,1)\nzp =\nColumns 1 through 4\n3.53553390593274 1.25442657826475 -0.08738044898976 0.18315912149992\nColumns 5 through 8\n2.05422141231050 4.82962913144534 7.39395888240421 8.64101238876062\nColumns 9 through 11\n7.90188453672496 5.20887876016010 1.29409522551261\n»plot(zp)\n-1\n»stem(zp)\n-1\n=======\noutput xx and t\nfunction [xx,t]=sumcos(f,X,fs,dur)\n%make time sequence from fs & dur\nt=?\n% use outer product to make a list of complex exponential sequences using f and t\n% use the inner product to multiply list of phasors X with list of complex exponential sequences\nxx=?\n=====\n»[zp,t]=sumcos([1, 1/3],[z1,z2],10,1)\nzp =\nColumns 1 through 4\n3.53553390593274 1.25442657826475 -0.08738044898976 0.18315912149992\nColumns 5 through 8\n2.05422141231050 4.82962913144534 7.39395888240421 8.64101238876062\nColumns 9 through 11\n7.90188453672496 5.20887876016010 1.29409522551261\nt =\n\nColumns 1 through 4\n0 0.10000000000000 0.20000000000000 0.30000000000000\nColumns 5 through 8\n0.40000000000000 0.50000000000000 0.60000000000000 0.70000000000000\nColumns 9 through 11\n0.80000000000000 0.90000000000000 1.00000000000000\n»plot(t,zp)\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n-1\n»cd dspfirst % change directory (you either must be in directory to use the functions, or add path of directory)\n»ls % list directory\nWriting_Fast_MATLAB_Code.pdf pkinterp.m\nalphacon.m pkpick.m\namdemod.m pretty_w.m\nb5syn.mat pumpkin.m\nbaboon.mat replacez.m\nbeatcon.m rrecks.mat\nbeatconb.m show_img.m\nclip.m showspec.m\ncosgen.m sinedri\ndspf.mat spectgr.m\ndspf1.mat striplot.m\ndspf2.mat sumprod.m\ndspfirst.m tools.gif\ndtmfchck.m tools.mat\ndtmfmain.m trusize.m\nechar512.mat ucplot.m\nechart.mat vowel_d.m\nexpand.m wavesnds.m\nfenotes.m wavwrisc.m\nfirfilt.m wngui.m\nfurelise.mat wngui.mat\nimsample.m woodwenv.m\ninout.m wreck.mat\nlab6dat.mat wrinotes.m\nlab7dat.mat zcat.m\nlenna.mat zcoords.m\nlenna512.mat zdrill\nlenna_bl.mat zone.mat\nmanipsin.m zone512.mat\nmattostr.m zone_mak.m\nmusiclab zprint.m\nmysound.m zvect.m\nnveloper.m\npez_31\n»help zprint % if you don't know what the command does, use help\nZPRINT printout complex # in rect and polar form\n------\nusage: zprint(z)\nz = vector of complex numbers; each one will be printed\nin a format showing real, imag, mag and phase\n\n»zprint([z1 z2])\nZ = X + jY Magnitude Phase Ph/pi Ph(deg)\n-0 5 5 1.571 0.500 90.00\n3.536 -3.536 5 -0.785 -0.250 -45.00\n\n»help zvect\nZVECT Plot vectors in complex z-plane from zFrom to zTo\n\nusage: HV = zvect(zFrom, <zTo>, <LTYPE>, <SCALE>)\n\nZ: is a vector of compplex numbers; each one will be\ndisplayed as an arrow emanating from the origin.\nLTYPE: string containing any valid line type (see PLOT)\nSCALE: controls size of arrowhead (default = 1.0)\n(order of LTYPE and SCALE args doesn't matter)\nHV: output handle from graphics of vector plot\n\n** With only one input vector: zvect(Z)\n\ndisplays Z as arrows emanating from the origin.\n** If either zFrom or zTo is a scalar all vectors will\nstart or end at that point.\n\nSee also ZCAT, PLOT, COMPASS, ROSE, FEATHER, QUIVER.\n»zvect([z1, z2])\n-3\n-2\n-1\n-3\n-2\n-1\n»help zcat\nZCAT Plot vectors in z-plane end-to-end\n\nusage: hv = zcat(Z, <LTYPE>, <SCALE>)\n\nZ = vector of complex numbers; each complex # is displayed\nas a vector, with the arrows placed end-to-end\nLTYPE: string containing any valid line type (see PLOT)\nSCALE: varies size of arrowhead (default = 1.0)\n(order of LTYPE and SCALE args doesn't matter)\nhv: output handle from graphics of vector plot\n\nSee also ZVECT, COMPASS, ROSE, FEATHER, QUIVER.\n»zcat([z1,z2])\n-1\n0.5\n1.5\n2.5\n3.5\n4.5"
    },
    {
      "category": "Resource",
      "title": "Recitation 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/834c29a46b7c89e04e418eab2f07448b_rec1.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nLinear Time Invariant Systems\nx(t)\nLinear\ny(t)\nTime\nInvariant\nSystem\nLinearity\ninput\noutput\nAy1(t)+By2(t)\nAx1(t)+Bx2(t)\nscaling & superposition\nTime invariance\nx(t-)\ny(t-)\nCharacteristic Functions\nest\ns=a+jb\ncomplex exponentials\nSinusoids\n(rad) y1=sin( ) y2=cos( )\n/6\n.5\n0.866\n/4\n0.707\n0.707\n/3\n0.866\n0.5\n/2\n\n3/2\nPeriodic\ny( )=y( +2n)\nsine odd\ncosine even\nsin(- )=sin( )\ncos(- )=-cos( )\nComplex Exponential Signals\ns=a+jb\nest\ns=\ne-t\nexponential decay\ns=±j\ne±jt\nsinusoids\ns=- ±j\ne-±jt\nexponential sinusoids\nj\nj\ne\n+ e\ncos =\ncharacteristic functions of LTI systems\ny(t)=A sin(t+)\nx(t)=sin(t)\nLinear\nTime\nInvariant\nSystem\noutput has same frequency as input\nbut is scaled and phase shifted\nContinuous sinusoids\n= (t)\ny(t)=A sin(t+)\ny(t)=A sin(2ft+)\nParameters:\nA: amplitude\n: phase (radians)\n: radian frequency (radians/sec)\nor\nf: frequency (cycles/sec-Hz)\nRelations:\n=2f\nrad/sec= (2 rad/cycle)*cycle/sec\nT:period (sec/cycle)\ny(t)=y(t+T)\nT = 1/f= 2/\nsec/cycle= 1/ (cycle/sec)= (2 rad/cycle)/(rad/sec)\n\nContinuous sinusoids\n= (t)\nSampled Continuous Sinusoid\nsampled continuous sinusoids\ny(t)=A sin(t+)\ny(t)=A sin(2ft+)\nContinuous Sinusoid\n0.8\n0.6\nParameters:\ny(t) = sin(2t)\n0.4\nTextEnd\nA: amplitude\nSample rate: T = 50 sec\ns\ny[n]=cos(2*pi*n/50)\n0.2\n: phase (radians)\n: radian frequency (radians/sec)\nt = nT s\n-0.2\n-0.4\nor\nf: frequency (cycles/sec-Hz)\nDiscrete Sinusoid\n-0.6\n-0.8\n-1\nn - samples\nPhase shift\ny n[ ] = sin(2 1 n)\nIn: x(t)=1sin(t)\nx(0)=0\ny n\nsin(\n)\nn\ny[n]\n[ ] =\n25 n\nOut: y(t)=0.5sin(t-/3)\ny(/3)=0\n0.125\n0.249\n0.368\n0.4818\nDiscrete sinusoids\n= [n]\nn=0, 1, 2...\nPeriod of discrete sinusoids\nperiod of discrete sinusoids\n0.8\nex: y[n]=cos(2(3/16)n)\ny[n]=A sin(n+)\n0.6\nWhat is the period N?\n0.4\ny[n]=A sin(2fn+)\n: radian frequency (radians/sample)\nTextEnd\nfrequency: f=3/16 cycles/sample\ny[n]=cos(2*pi*3/16*n)\n0.2\n-0.2\n-0.4\n-0.6\nN:period\n-0.8\n(samples/repeating cycle [integer])\n-1\nn - samples\nSmallest integer N such that y[n]=y[n+N]\nFind an integer k so N=k/f is also an integer\nf=3/16\nlet k=3\nN=(3)*16/3=16\nf = k/N (rational number -> k/N is ratio of integers)\ny[n]=A cos(2fn+)\nA: amplitude\n: phase (radians)\nf: frequency (cycles/sample)\nRelations:\n=2f rad/sample= (2 rad/cycle)*cycle/sample\nN:period (samples/repeating cycle [integer])\nSmallest integer N such that y[n]=y[n+N]\nFind an integer k so N=k/f is also an integer\nN 1\nf\nf = k/N (f: rational number -> k/N is ratio of integers)\n\ny n =\n50 n)\n[ ]\nsin(2 3\nf =\n3 cycles\n50 sample\ny n =\nN ]\n[ ]\ny[n +\nN=?? samples\nN: integer\nN 1\nf\n50/3 integer\nAperiodic discrete sinusoids 1\n0.8\ncontinuous function\n0.6\ny t( ) = sin(2 2 t)\n0.4\nT =\n2 sec\nperiodic\n0.2\n-0.2\nsample\nt = nTs\nTs = 25 sec\n-0.4\n-0.6\n-0.8\ndiscrete function\n-1\nPeriod of discrete sinusoids: ex2.\ny=sin(2*pi*sqrt(2)/25*n)\nPeriod of discrete sinusoids: ex2.\ndiscrete function\ny n = sin(2 3 n)\n[ ]\ncycles\nfrequency: f = 50\nsec\nperiod: N=?? samples\ny n[ ] = y[n + N ]\nf N = k\nN, k:integers\n3 N = k\nN\n50 samples\nratio of integers\nperiodic\n=\nk\ncycle\nrational number\nN=50 samples, k=3 cycles\nPeriodicity\narbitrary continuous signal\nT:period (sec/cycle)\ny(t+)=y(t)\nAfter what interval does\nthe signal repeat itself?\nN=?? samples\n(integer)\nirrational frequency\nTextEnd\ny n = sin(2 25 n)\nperiod?\ny n =\nN ]\n[ ]\n[ ]\ny[n +\n0.5\n1.5\ntime (sec)\n2.5\n3.5\nf =\nf N = k\nN,k: integers\nN\n25 2\nnot a ratio of integers\n=\nk\nirrational number\nsampled discrete sinusoid aperiodic\n\nEx: Period of sum of sinusoids\n0.5\n-0.5\n-1\nT1=0.2 seconds, T2=0.75 seconds\n-1\n-2\ntime (sec)\nTsum=? seconds\nInstantaneous frequency\ny( )=sin( )\ntime varying argument\n= (t)\ninstantaneous frequency\n=d /dt\nsinusoid constant frequency\ny(t)=A sin(t+)\n=t+\nd /dt=\nchirp linearly swept frequency\n=d /dt\nt\n=((1-0)/T)t +0\n0 0\nintegrate\n=(1-0)/2T t2 +0t + C\nychirp(t)=A sin((1-0) /(2T) t2 +0t + )\nLeast common multiple\nseconds to complete\nseconds to complete\ncycles\ncycles\nT1=1/5 seconds\nT2=3/4 seconds\n1/5s, 2/5s, 3/5s ...\n3/4s, 6/4s, ...\n4/20s, 8/20s, 12/20s,\n15/20s. 30/20s,\n16/20s, 20/20s, 24/20s,\n45/20s, 60/20s\n28/20s, 32/20s, 36/20s,\n40/20s, 44/20s, 48/20s,\n4 cycles\n52/20s, 56/20s, 60/20s\n1/5*k=3/4*l\n15 cycles\nk/l=15/4\nrational number\nTsum=15*T1=15/5=3 seconds\nTsum=4*T2=3/4*4=3 seconds\nTsum=3 seconds\nRepresentations of a sinusoid\ny(t)=A cos(t+)\ntrig function\n[\n]\n\nj\ny(t) = Ae j e jt + e jt\ncomplex conjugates\ne ( ) = e j(\n)\nt+\nj\njt\n= e e\ny(t)=Re{Aejej(t)}\nreal part of\ncomplex exponential\nX= Aej\ncomplex amplitude (constant)\ny(t)=Re{Xej(t)}\nrotating phasor\nEuler's relations\nej =cos( )+jsin( )\ncos = ej + ej\nsin = ej ej\n2 j\n\n.\n\n=\n\nComplex Exponentials\nComplex Exponentials\nWhy use complex exponentials?\nTrigonometric manipulations -> algebraic operations on exponents\nTrigonometric identities\nProperties of exponentials\ncos(x)cos(y) = 1\n2 [cos(x y)[cos(x + y)]]\nrexey= rex+y\ncos2(x) = 1+cos 2x\n(rex)n= rnenx\n(\n)\n\nn\n1/ n\nx = x\n= x\nx\nVector representation (graphical)\nRepresentations of a sinusoid\ny(t)=A cos(t+)\ntrig function\ne jt + e jt\nj\nj t+\ny(t) = Ae j [\n]\ncomplex conjugates\ne ( ) = e (\n)\nj\njt\n= e e\ny(t)=Re{Aejej(t)}\nreal part of\ncomplex exponential\nX= Aej\ncomplex amplitude (constant)\ny(t)=Re{Xej(t)}\nrotating phasor\nAmplitude modulation (multiply two sinusoids of different frequencies)\nAcos( 1t) B cos(2t+)= C(cos(3t +2)+ cos(4t +2))\n*sum formula\n.\n.\n.\nA cos 1\nB cos 2\nfor sin & cos\n.\n.\n.\n.\n.\nA B cos 1\ncos 2 cos\nsin 2 sin 2\ntrig id\n.\n.\n.\n.\n.\n.\n.\nA B cos 1 cos 2\nA B cos 1 sin 2 sin 2\n*product formula\ncos 2\nsin 2\nfor sin & cos\ncos 2\nsin 2\n.\n.\n.\n.\nA B\n.cos 2\nA B\n.sin 2\ntrig id\ncos s\ncos d\nsin s\nsin d\n.\n.\n.\n.\nA B\n.cos 2\nA B\n.sin 2\n*sum formula\n.\n.\n.\n.\n.\n.\n.\nA B cos 2 cos s\ncos 2 cos d\nsin 2 sin s\nsin 2 sin d\nfor sin & cos\n2 1\ntrig id\n.\n.\n.\nA B cos s\nsin d\nor\n.\n.\n.\nA cos 1\nB cos 2\nj. 1\nj. 1\nj. 2\n\nj. 2\n\ncos = complex conj\ne\ne\ne\ne\n.\nA.\nB.\nmult. exponentials\n1 .\n.\n.\nA B exp j.\nexp\nj.\nexp\nj.\nexp j.\n.\ncos = complex conj\n. . . 2 cos\nA B\n2 cos\n.\n.\n.\nA B cos\ncos\ncomplex numbers\ncartesian\ns=a+jb\nj =\npolar\ns=rej\nconversion\na = r cos( )\nb = r sin( )\nej0=1\nr = a2 + b2\nej/2=i\nEuler's relations\natan2\nconjugate\ns*=a-jb=re-j\nquadrants!\nej =cos( )+jsin( )\ncos = ej + ej\nsin = ej ej\n2 j\nb\nej=-1\na\n\ncomplex numbers\ncartesian\ns=a+jb\nj =\npolar\ns=rej\nconversion\na = r cos( )\nb = r sin( )\nr = a2 + b2\nb\n= a tan\n\na\nconjugate\ns*=a-jb=re-j\ncomplex arithmetic\nAddition\nSubtraction\nMultiplication Division\nPowers\nRoots\nej=-1\nej/2=j\nej0=1\n1j = (ej0) j\n= ej(j)(0)\n= e-1(0)\n= e0 = 1\nex.\nex. cos(j)?\n1/j?\nremember:\ncomplex numbers\ncartesian\ns1=3+j2\n.j atan\n= 32\n22 .e\nej 0.588\n=\ns2=-2+j1\nj. atan\n2 2\n=\n12 .e\n=\n5 ej2.678\npolar\ns1=\nej 0.588\n=\n13 .cos 0.588\n.\nj.\n13 sin 0.588\n=3+j2\nj.\n5 sin 2.678\n=\nej2.678\n5 .cos 2.678\ns2= 5\n.\n=-2+j1\nAddition\ncartesian\ns1=a1+jb1\ns1+s2=a1+jb1 + a2+jb2\ns2=a2+jb2\n=(a1 + a2) +j(b1+b2 )\npolar\ns1=r1ej 1\nconvert to cartesian\ns2=r2ej 2\nadd\nconvert back to polar\nvector\nplace tail of s2 at\nhead of s1\nconnect origin to s2\n\nAddition - example\nSubtraction\ncartesian\ncartesian\ns1=3+j2\ns1+s2= a1 + a2 +j(b1+b2 )\ns1=a1+jb1\ns1-s2=a1+jb1 - (a2+jb2)\ns2=-2+j1\n= 3 -2 +j(2+1 )\ns2=a2+jb2\n=(a1 - a2) + j(b1-b2 )\n= 1 +j3\npolar\npolar\ns1= 13 ej 0.588\ns1= 13 cos(0.588)+j 13 sin(0.588)= 3+j2\ns1=r1ej 1\nconvert to cartesian\nadd\ns2= 5 ej2.678\ns2=r2ej 2\ns2= 5\n5 sin(2.678)= -2+j1\nconvert back to polar\ncos(2.678)+j\nvector\ns1+s2 = 1 +j3\nvector\n.\n32 .ej atan 3\n=\nrotate s2 180° (-s2)\n.\n10 .ej 1.249\n=\nplace tail of -s2 at\nhead of s1\nconnect origin to s2\nSubtraction - example\nMultiplication\ncartesian\ncartesian\ns1=a1+jb1\ns1s2=(a1+jb1 ) (a2+jb2)\ns1=3+j2\ns1-s2 =(a1 - a2) + j(b1-b2 )\ns2=a2+jb2\n= a1a2 + ja1b2 + ja2b1 + jb1jb2\ns2=-2+j1\n=(3 - (-2)) + j(2-1 )\n= a1a2 + j2b1b2 + j(a1b2+a2b1 )\npolar\n=5 + j1\n= a1a2 -b1b2 + j(a1b2+a2b1 )\ncos(0.588)+j 13 sin(0.588)= 3+j2\npolar\nej 0.588\ns1= 13\ns1= 13\ns2= 5 ej2.678\ns2= 5 cos(2.678)+j 5 sin(2.678)= -2+j1\ns1=r1ej 1\ns1s2 =r1ej 1 r2ej 2\ns2=r2ej 2\n=r1r2ej 1 ej 2\ns1-s2 = 5 +j1\n=r1r2ej 1+ 2\n.j atan\n=\nvector\n52 .e\nj 0.197\n=\n26 .e .\nmagnitudes multiply\nangles add\nxaxb=xa+b\nvector\n\nMultiplication - example\nDivision\ncartesian\ncartesian\ns1s2= a1a2 -b1b2 + j(a1b2+a2b1 )\ns1=a1+jb1\ns1/s2=(a1+jb1 ) / (a2+jb2)\ns1=3+j2\n= 3(-2) -2(1) + j(3(1)+(2)(2) )\ns2=a2+jb2\ns2=-2+j1\n=(a1+jb1 ) (a2-jb2) / (a2+jb2) (a2-jb2)\n= -6 -2 + j(3-4 )\n=(a1+jb1 ) (a2-jb2) / (a2\n2+b2\n2)\npolar\n= -8 - j1\npolar\n=s1s2\n* / |s2 |2\ns1= 13 ej 0.588\ns1s2 =r1r2ej 1+ 2\ns1=r1ej 1\ns1/s2 =r1ej 1 / r2ej 2\ns2=\n5 ej2.678\n= 13\n5ej(0.588+2.678)\ns2=r2ej 2\nej3.266\n= 65\n=r1ej 1 (r2ej 2 )1\n=(r1/r2 ) ej 1 e-j 2\n= 65\ncos(3.266)+\nj sin(3.266)\n= (r1/r2 ) ej 1- 2\n= -8 - j1\nvector\ndivide magnitudes\nangles subtract\nxa/xb=xa-b\nvector\ns1s2\nDivision - example\ns1/s2 =s1s2\n* / |s2 |2\nPowers\ncartesian\n=(a1+jb1 ) (a2-jb2) / (a2\n2+b2\n2)\ncartesian\ns1=3+j2\n=(3+j2 ) (-2-j1) / (22+12)\ns=a+jb\nsn=(a+jb)n\nBinomial expansion\nn\n=(3(-2)-j3(1)+j2(-2)+2(1)) / (5)\nn\ns2=-2+j1\n= n(n 1)(n 2)K(n (k 1))\nk!\nk\nn\nnk jb\n(\n)\n\nwhere\n=\na\nk\nk\nk= 0\n=(-6-j3-j4+2) / (5)\npolar\n=(-4-j7) / (5)\npolar\nsn=(rej )n\ns1= 13 ej 0.588\ns=rej\nsn=rnejn\ns2=\n5 ej2.678\n=(\ns1/s2 = (r1/r2 ) ej 1- 2\n/ ) ej0.5882.678\nvector\n13/ ) ej0.5882.678\nvector\n=(\n.\n=\n.e j 2.09\n= 5cos(-2.09)+j 5 sin(-2.09)\nmagnitude raised to power n\nangle multiplied by n\n=-0.8-j1.4\n(xa)n=xan\n\nPowers - example\ns2=(2+j1)2\nRoots\ncartesian\ncartesian\ns=a+jb\ns1/n=(a+jb)1/n\n???\ns=2+j1\n1/ n\n12 e\nb\n1 b\n1/n\nb\n1/n\nb\n.j atan\n1/ n\na\n= 1+ j\nj\nj\nvector\n=\n+K\n+\n+\n=\n.\na\nn a\na\na\npolar\ns=rej\nsn=rnejn\n.\n5 e .j 0.464\n=\n.\n5 e .j 0.464\n=\ns2=r2ej2\ns2=\n2ej2(0.464)\ns2= 5ej0.927\n=5cos(0.927)+j5sin(0.927)\n=3+j4\npolar\nvector\ns=rej\nnth positive root of magnitude\ncircle evenly divided by n starting at angle/n\ns1/n=(rej )1/n\ns1/n=r1/nej( /n+2k/n)\n1+ j\n\nx\nn\n= x1/ n\nk=0,1,2,...,n-1\nRoots - example\ncartesian\ns1/3 =(a+jb)1/3\ns1/n=r1/nej( /n+2k/n)\nk=0,1,2,...,n-1\ns=2+j1\npolar\ncartesian\npolar\ncartesian\ns=a+jb\ns=rej\ns = a2 + b2 e\nja tan b a\n(\n)\n\ns = rcos + jr sin\nComplex Conversions\npolar\ns1/3 = 5 1/3ej(0.464/3+2k/3)\nk=0,1,2\n. j 0.464\ns1/3 = 1.308 ej(0.464/3)\n=\n5 e .\n= 1.308 ej(0.464/3+21/3)\n= 1.308 ej(0.464/3+22/3)\nvector\nAddition\ncartesian\nPowers\npolar\nRoots\npolar\na1 + jb1\n(\n) + a2 + jb2\n(\n) = a1 + a2\n(\n) + j b1 + b2\n(\n)\nSubtraction\ncartesian\nMultiplication\npolar\nDivision\npolar\nr1e j1 r2e j 2 = r1r2e\nj 1 + 2\n(\n)\na1 + jb1\n(\n) a2 + jb2\n(\n) = a1 a2\n(\n) + j b1 b2\n(\n)\nr1e j1\nr2e j 2 = r1\nr2\ne\nj 1 2\n(\n)\nre j\n(\n)\nn = rne jn\nzn = s = re j\nz = s1/ n = r1/ ne\nj / n +2k / n\n(\n)\nk = 1,2Kn 1\nComplex Arithmetic\ns1/3 = 1.308 ej0.155=1.292+j0.202\n= 1.308 ej2.249=-0.821+j1.019\n= 1.308 ej4.343=-0.472-j1.22"
    },
    {
      "category": "Resource",
      "title": "Recitation 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/66c9d296a29c7e96d7ceb3be945e2d71_rec2.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nPeriod of a Discrete Sinusoid\ny n = sin(2 1 n)\n[ ]\nT=50 samples\ny n = y[n + 50]\n[ ]\nsin(0) = sin(2)\ny n = sin(2\n50 n)\n50 n = 2k\n[ ]\ny n = y[n + T]\nT=?? samples\nn = 50 samples\nRatio of\n[ ]\nsin(0) = sin(2k)\nk\n3 cycle\nintegers\nk=1,2...\nrational number\nperiodic\nT=n=50 samples, k=3 cycles\ny n[ ] = sin(2 3 n)\ny n =\nT]\nT=?? samples [integer]\n50/3 integer\n[ ]\ny[n +\nirrational frequency\n0.8\n0.6\nTextEnd\ny t( ) = sin(2 2 t)\n0.4\n0.2\nT =\nsec\ncontinuous function\n-0.2\nperiodic\n-0.4\n-0.6\n-0.8\n-1\n0.5\n1.5\n2.5\n3.5\ntime (sec)\nTs=1/25 sec\ny n[ ] = sin(2 25\n2 n)\n2 n = 2k\ny n = y[n + T]\nT=?? samples\n[ ]\nn\n25 2\n=\nsin(0) = sin(2k)\nk=1,2...\nk\nEquiv. discrete sinusoid not periodic\nirrational number\ny=sin(2*pi*sqrt(2)/25*n)\n\nPeriod of Sum of Sinusoids\ny t = y t + T\n( )\n(\n)\n\nLeast common multiple\nseconds to complete\nseconds to complete\ncycles\ncycles\nT1=1/5 seconds\nT2=3/4 seconds\n1/5s, 2/5s, 3/5s ...\n3/4s, 6/4s, ...\n4/20s, 8/20s, 12/20s,\n16/20s, 20/20s, 24/20s,\n28/20s, 32/20s, 36/20s,\n15/20s. 30/20s,\n45/20s, 60/20s\n40/20s, 44/20s, 48/20s,\n4 cycles\n52/20s, 56/20s, 60/20s\n1/5*k=3/4*l\n15 cycles\nk/l=15/4\nrational number\nTsum=15*T1=15/5=3 seconds\nTsum=4*T2=3/4*4=3 seconds\nTsum=3 seconds\n0.5\n-0.5\n-1\nT1=0.2 seconds, T2=.75 seconds\n-1\n-2\ntime (sec)\nTsum=3 seconds\nComplex Conversions\ncartesian\npolar\npolar\ncartesian\n(\n)\ns=a+jb\ns =\na2 + b2 e\nja tan b a\ns=rej\ns = rcos + jr sin\nComplex Arithmetic\nAddition\ncartesian\njb1 +\njb2 =\n+ j b1 +\nSubtraction\ncartesian\n(\n) (\n)\n(\n)\na1 +\na2 +\n(\n)\na1 +\n(\n)\n(\n)\n(\n)\na2\nb2\njb1\njb2 =\n+ j b1 b2\n(\n)\n\na1 +\na2 +\na1 a2\n(\n)\n\nMultiplication\npolar\nr1e j1 r2e j 2 = r1r2e\nj 1 + 2\nr1e j1\nr1\n(\n)\nDivision\npolar\nj 2 =\ne\nj 1 2\nr2e\nr2\nPowers\npolar\nre j\nn =\nne jn\n(\n)\nr\nRoots\npolar\nzn =\n1/ s\nn = re\n1/\nj\nn\n(\n)\nk =1,2Kn 1\nj / n +\nk / n\nz = s\n= r\ne\n\nComplex Conversions\nRepresentations of Sinusoids\ncartesian\npolar\npolar\ncartesian\nAcos 2kf0t +\nRe Ae j 2ft +\nAe j (\ne j 2ft +e j 2ft )\n(\nk )\n{\n}\n(\n)\n= Re{Ae je j 2ft }\n= X (\ne j 2ft +\ne j 2ft )\nja tan 4 3 = 5e j 0.927\n2e\nj\n3 = 2cos\n3 + j2sin =1+ j\n3 + j4 =\n+\ne\n= Re{Xe j 2ft }\nSum multiple cosines same frequency\nn\nn\nn\ncos 2ft +\n\n{\n2ft +k }\n{\nke2ft }\nAk\n(\nk ) =\nRe Ake\n=\nRe Ake\nk=1\nk=1\nk=1\nn\n\n= Re{Akek }e2ft\nk=1\n\nEx.\n3cos 2 40t + 1cos 2 40t +2cos 2 40t +\n(\n2 )\n(\n6 )\n(\n)\n\nj\n2 e j2 40t\nj\n6 e j2 40t\n\n3 e j2 40t\nRe 3\ne\n1e\n+2e\n\nj\nj\nj2 40t\nRe3e 2 1e\n6 +2e 3 e\n\nRe 5.234\n{\ne j1.545 e 2 40t }\n5.234 cos 2 40t +\n)\n(\n1.545\nComposite signals (waveform synthesis)\nComplex Arithmetic\nAddition\ncartesian\n1+ j2\n(\n) + 3 + j4\n(\n) = 4 + j6\n(\n)\nSubtraction\ncartesian\n1+ j2\n(\n) 3 + j4\n(\n) = 2 j2\n(\n)\nMultiplication\npolar\n5e\nj\n3 6e\nj\n4 = 5 6e\nj\n3 +\n(\n4 ) = 30e\nj 7\nDivision\npolar\n10e\nj\n2 ÷ 5e\nj\n4 =\n5( )e\nj\n(\n4 ) = 2e\nj\nPowers\npolar\n3e\nj\n(\n)\n\n= 33 e\nj 3\n(\n) = 27e\nj 3\n(\n)\n\nRoots\npolar\nz = 641/ 3 e\nj 0/ 3+2k / 3\n(\n) = 4e\nj 2k / 3\n(\n)\nz3 = 64 = 64e j 0\n4e\nj 2\n(\n/ 3)\n4e\nj 4\n(\n/ 3)\nmultiply cosines of different frequency\nAk cos 2kf0t +\n=\nRe\n(\nk )\nX0 +\nk=1\nXke j 2kf0t\nx(t) = A0 +\nA1cos 1t A2 cos 2t +\nk=1\n(\n)\n(\n)\nA1\ne j1t + e\nj1 t\n\nA2\ne\nj(2 t +) + e\n\nj(2t +)\n\ndecompose a periodic signal x(t) into a sum of a series of\n\nsinusoids - the Fourier series.\nA1A2 (e j1 te\nj(2 t +) + e j1te\n\nj(2t +) + e\nj1te\nj(2 t +) + e\nj1te\n\nj(2t +))\nNote: The sum of periodic functions is periodic.\nA1A2 (e\nj(1 t +2t +) + e\n\nj(2 t\n1t +) + e\nj(2 t\n1t +) + e\n\nj(1t +2t +))\nex.\nA1\nA2 (cos((1 + 2 )t + ) + cos((2\n1)t + ))\nXk =\n\nk 2\nk odd\nk even\nf0 = 25Hz\n\n=\n\nComposite signals (waveform synthesis)\nComposite signals (waveform synthesis)\nXke j 2kf0t\nx(t) = A0 +\ncos 2kf0t + k ) = X0 + Re\nAk\n(\nXke j 2kf0t\nx(t) = A0 +\ncos 2kf0t + k ) = X0 + Re\nAk\n(\nk=1\nk=1\nk=1\n\nk=1\nk odd\nXk =\n2k 2 e j\nk odd\n=\n8 e j\nk odd\nXk\n2k 2\nXk\n2k 2\n\nk even\nk even\nk even\nk=1\nk=3\nx(t) = 0.8105cos 225t +\nx(t) = 0.8105cos 225t + ) + 0.0901cos 275t +\n(\n)\n(\n(\n)\n0.8\n0.8\n0.8\n0.8\n0.6\n0.6\n0.6\n0.6\n0.4\n0.4\n0.4\n0.4\n0.2\n0.2\n0.2\n=\n0.2\n=\n-0.2\n-0.2\n-0.2\n-0.2\n-0.4\n-0.4\n-0.4\n-0.4\n-0.6\n-0.6\n-0.6\n-0.6\n-0.8\n-0.8\n-0.8\n-0.8\n-1\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.8\nComposite signals (waveform synthesis)\n0.6\nXke j 2kf0 t\nspectrum\n0.4\nx(t) = A0 +\ncos 2kf0t + k ) = X0 + Re\nAk\n(\nk=1\nk=1\n0.2\n0.45\n-0.2\n0.4053e j\nj\n-0.4\n8 e j\nk odd\n0.4053e\nXk =\n\n0.4\n2k 2\n-0.6\n-0.8\nk even\n0.35\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\nk=5\n0.3\nx(t) = 0.8105cos 225t + ) + 0.0901cos 275t + ) + 0.0324cos 2125t +\n(\n(\n(\n)\nX 0.25\n0.2\n0.8\n0.8\n0.6\n0.6\n0.15\n0.4\n0.4\n=\n0.2\n0.2\n0.1\n0.0450e j\n0.0450e j\n-0.2\n0.05\n-0.2\n0.0162e j\n0.0162e j\n-0.4\n-0.4\n-0.6\n300f\n-300\n-200\n-100\n-0.8\n-125\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\nx(t) = 0.8105cos 225t +\n(\n-75\n-25\n) + 0.0901cos 275t +\n(\n) + 0.0324 cos 2125t + ) + ...\n(\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-0.8\n-0.6\n\nFourier Series\nFourier Series\nx(t) = t 0 t < T0\njk\nFor a given signal, how do we find Xk = Ake\nk=1\nXke j 2kf0t\nx(t) = A0 +\ncos 2kf0t + k ) = X0 + Re\nfor each k ?\nAk\n(\nk=1\n0.04\nFourier Analysis\nT0\n0.04\nx(t)dt\nX0 =\nXke j 2kf0 t\nT0\nx(t) = A0 +\ncos 2kf0t + k ) = X0 + Re\nAk\n(\nk=1\nk=1\nt\n0.02\nT0\nwhere\nT0\n1 t 2\n1 T0\nT0\n=\n=\n0.01\n0.02\n0.03\n0.04\nT0\n=\ntdt =\nT0 2\nt\n0.04\nT0\nT0 2 0\nX0 = T0 x(t)dt\nf0:fundamental frequency\nT0 = 1/ f0\nMathematica:\nT0\nj 2kt\nathena%add math\nXk =\nx(t)e\nT0 dt\nathena%math\nT0 0\nIn[1]:=1/T*Integrate[t,{t,0,T}]\nOut[1]:=T/2\nXk = 2\nT\n\nx(t)e\nj 2kt\nT0 dt\nT0\nFourier Series\nFourier Series\n0 t < T0\nx(t) = A0 +\ncos 2kf0t + k ) = X0 + Re\nAk\n(\nx(t) = t\nj 2kf0t\nXk\nk=1\ne\nMathematica:\nk=1\nT0\nX0 = T0\nj 2kt\nIn[2]:= 2/T*Integrate[t*Exp[-I*2*Pi*k*t/T],{t,0,T}]\nT0 dt\nXk =\nte\nT0\nT0\nj 2kt\nXk =\nte\nT0 dt\nT0 0\n(2 I) k Pi\nT0 ( j2k + 1)\n2 jk\nT0\nk\n-((-1 + E\n- (2 I) k Pi) T)\nXk =\n2k 2\ne\n2 2k 2\ne2 jk = (e j 2)\nOut[2]= -----------------------------------\nT0 ( j2k + 1)\nT0\n1k\n(2 I) k Pi 2 2\nXk =\n2k 2\n2 2k 2\n=\n2 E\nk Pi\n= 1\ne2 jk = 1\nXk = j T0\n\n2k\n2k\n\n2 + 2\nT\nk 2 2\nT\nk 2\nIn[3]:= Simplify[%,Element[k,Integers]]\ne jk = 1k\nT0\nT0\nj\nI T\nXk = j\n=\ne\nOut[3]= ----\nT0\nT0\nj\nk\nk\nk Pi\nXk = j k = k e\n\n(\n)\n\n(\n)\n(\n)\n=\n=\n\nFourier Series\nFourier Series\nx(t) = t 0 t < T0\nx(t) = t 0 t < T0\n\nA0 +Ak\n(\nk )\nX0 +\nXk\nj 2kf0t\nA0 +Ak\n(\nk )\nX0 +\nXk\nj 2kf0t\nx(t) =\ncos 2kf0t +\n=\nRe\ne\n\nx(t) =\ncos 2kf0t +\n=\nRe\ne\n\nk=1\nk=1\n\nk=1\nk=1\n\nT0\nT0\nX0 =\nX0 =\nf0:fundamental frequency\nXk = T0 e\nj\nT0 =1/ f0\nXk = T0 e\nj\nk\nk\nx(t) = T0 +\nT0 cos 2kf0t +\nx(t) = T0 +\nT0 cos 2kf0t +\nk=1 k\nk=1 k\nx(t) =\n+\ncos 2\n+\ncos 2\n+K\nx(t) =\n+\ncos 2\n+\ncos 2\n+K\nT\nT\n\n(\nf0t +\n2 )\nT\n\n(\n2 f0t +\n2 )\nT\nT\n\n(\nf0t +\n2 )\nT\n\n(\n2 f0t +\n2 )\n0.04\n0.04\n0.04\n0.04\nf0 = 25Hz\ny t\nT0 =1/ f0 = 0.04\ny t\n0.02\nDefined between 0<t<0.04\n0.02\nt\nt\nPeriodic with period 0.04\n7 terms\n0.01\n0.02\n0.03\n0.04\n0.04\n0.02\n0.02\n0.04\nt\n0.04\n0.04\nt\n0.04\nFourier Series:Square Wave\nFourier Series:Square Wave\nT0\n1.1\nj 2kt\nT0\nj 2kt\n0 t < T0\nXk =\n1e\nT0 dt +\n1e\nT0 dt\nx(t) =\nT0\nT0 T0\nz t\n1 T0 2 t < T0\n1.1\nIn[2]:=2/T*Integrate[Exp[-I*2*Pi*k*t/T],{t,0,T/2}]+\n0.01\n0.02\n0.03\n0.04\nt\n2/T*Integrate[- Exp[-I*2*Pi*k*t/T],{t,T/2,T}]\n-I k Pi\nI k Pi\n-I (1 - E\n) I (-1 + E\n)\n0.04\nT0\nT0\nOut[2]= ----------------- + ---------------\nX0 = T0 1dt + T0 1dt\nk Pi\n(2 I) k Pi\nT0 2\nE\nk Pi\nIn[3]:= Simplify[%,Element[k,Integers]]\nj 11)\n(\n)\n(\nj 2\nIn[1]:=1/T*Integrate[1,{t,0,T/2}]+ 1/T*Integrate[-1,{t,T/2,T}]\nk 2\nXk =\nj(1+ 1\nk )\nXk\nk\nk\nOut[1]:=0\n-I (-1 + (-1) )\nk\n= j4\nOut[7]= ----------------\n\nk\nX0 = 0\nk Pi\nXk = j k\nk odd\n\nk even\nj(1+1)\nXk =\nk\n\n0 t < T0\n1 T0 2 t < T0\nx(t) =\nX0 = 0\n=\nj\nk even\ne\nj\nk odd\nk odd\nXk\nk\nXk =\nk\nk even\nj 2kf0t\nx(t) = A0 +\ncos 2kf0t + k ) = X0 + Re\nAk\n(\nXke\nk=1\nk=1\n\n1.2\n0.5\n0.5\nx(t) = 4 cos 2f0t ) + 4 cos 2 3 f0t ) + K\n\n(\n(\ny t\nz t\n1.2\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\n0.04\nt\n0.04"
    },
    {
      "category": "Resource",
      "title": "Recitation 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/6533cd190b17ad896f055390f5bf85d4_rec3.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n0.8\n0.8\n0.6\n0.6\n0.4\n=\n0.4\n0.2\n0.2\n-0.2\n-0.2\n-0.4\n-0.4\n-0.6\n-0.6\n-0.8\n-0.8\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\nComposite signals (waveform synthesis)\ninf\n∑ Ak cos 2πkf0t + φk ) = X0 + Re\n(\n\ninf\n∑\nk=\nXke j 2πkf0t\n\nx(t) = A0 +\nk=1\nXk =\nπ 2k 2 e jπ\nk odd\n\nk even\n\nk=5\nx(t) = 0.8105cos 2π 25t + π ) + 0.0901cos 2π 75t + π) + 0.0324 cos 2π125t + π\n(\n(\n(\n)\n\nspectrum\n0.4\n0.35\n0.3\nX 0.25\n0.2\n0.15\n0.1\n0.05\n-300\n-200\n-100\n0.45\n0.4053e- jπ\n0.4053e jπ\n0.0450e jπ\n0.0450e- jπ\n0.0162e jπ\n0.0162e- jπ\n0.02\n0.04\n0.06\n0.08\n0.1\n-1\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n0.8\n-125\n-75\n-25\nf\nx(t) = 0.8105cos 2π 25t + π ) + 0.0901cos 2π 75t + π) + 0.0324 cos 2π125t + π ) + ...\n(\n(\n(\n0.12\n\n0.4053e- jπ\n0.4053e jπ\n0.0450e jπ\n0.0450e- jπ\n0.0162e jπ\n0.0162e- jπ\nspectrum\n0.4\n0.35\n0.3\nX 0.25\n0.2\n0.15\n0.1\n0.05\n-300\n-200\n-100\n0.45\n0.8\n0.6\n0.4\n0.2\n-0.2\n-0.4\n-0.6\n-0.8\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-125 -75 -25\n25 75 125\nf\nx(t) = 0.8105cos 2π 25t + π )+ 0.0901cos 2π 75t + π)+ 0.0324 cos 2π125t + π )+ ...\n(\n(\n(\nComplex conjugate form\nx(t) = 0.8105 e j(2π 25t+π ) +\ne- j(2π 25t+π )\n+ 0.0901 e j(2π 75t+π ) +\ne- j(2π 75t+π )\n+ 0.0324 e j(2π125t+π ) +\ne- j(2π125t+π )\n+ ...\n\n0.4053e- jπ\n0.4053e jπ\n0.0450e jπ\n0.0450e- jπ\n0.0162e jπ\n0.0162e- jπ\nspectrum\n0.4\n0.35\n0.3\nX 0.25\n0.2\n0.15\n0.1\n0.05\n-300\n-200\n-100\n0.45\n0.8\n0.6\n0.4\n0.2\n-0.2\n-0.4\n-0.6\n-0.8\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-125 -75 -25\n25 75 125\nf\nComplex conjugate form\nx(t) = 0.8105 e j(2π 25t+π ) + e- j(2π 25t+π )\n+ 0.0901 e j(2π 75t+π ) + e- j(2π 75t+π )\n+ 0.0324 e j(2π125t+π ) + e- j(2π125t+π )\n+ ...\nx(t) = 0.4053e j(2π 25t+π ) + 0.4053e- j(2π 25t+π ) + 0.0450e j(2π 75t+π ) + 0.0450e- j(2π 75t+π )\n+ 0.0162e j(2π125t+π ) + 0.0162e- j(2π125t+π ) + ...\n\nspectrum\n0.8\n0.6\n0.4\n0.2\n-0.2\n-0.4\n-0.6\n-0.8\n-1\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n-300\n-200\n-100\nX\n-125 -75 -25\n25 75 125\nf\n0.4053e- jπ\n0.4053e jπ\n0.0450e jπ\n0.0450e- jπ\n0.0162e jπ\n0.0162e- jπ\nx(t) = 0.4053e j(2π 25t+π ) + 0.4053e- j(2π 25t+π ) + 0.0450e j(2π 75t+π ) + 0.0450e- j(2π 75t+π )\n+ 0.0162e j(2π125t+π ) + 0.0162e- j(2π125t+π ) + ...\nx(t) = 0.4053e jπ e j(2π 25t) + 0.4053e- jπ e- j(2π 25t) + 0.0450e jπ e j(2π 75t) + 0.0450e- jπ e- j(2π 75t)\n+ 0.0162e jπ e j(2π125t) + 0.0162e- jπ e- j(2π125t) + ...\n\n0.4053e- jπ\n0.4053e jπ\n0.0450e jπ\n0.0450e- jπ\n0.0162e jπ\n0.0162e- jπ\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-1\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n0.8\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n-300\n-200\n-100\nX\n-125\n-75\n-25\nf\nx(t) = 0.0162e- jπ e- j(2π125t) + 0.0450e- jπ e- j(2π 75t) + 0.4053e- jπ e- j(2π 25t)\n+ 0.4053e jπ e j(2π 25t) + 0.0450e jπ e j(2π 75t) + 0.0162e jπ e j(2π125t) + ...\n\n0.4053e- jπ\n0.4053e jπ\n0.0450e jπ\n0.0450e- jπ\n0.0162e jπ\n0.0162e- jπ\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n-1\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n0.8\n\n-300\n-200\n-100\n0.45\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\nX\n-125\n-75\n-25\nf\n\"two sided Fourier Series\"\n) = Re\n\n=\ninf\n∑\ninf\n∑\ninf\n∑ Zk\nXke j2πkf0t\ne j2πkf0t\nx(t) = A0 +\nAk cos 2πkf0t + φk\n(\nk=1\nn=0\nk=-inf\n\nFourier Series\nFor a given signal, how do we find Xk = Ake jφk\nfor each k in the Fourier Series ?\nFourier Analysis\ninf\n∑ Ak cos 2πkf0t + φk ) = X0 + Re\n(\n\ninf\n∑\nk=\nXke j 2πkf0t\n\nx(t) = A0 +\nk=1\nwhere\nX0 = 1\nT\n∫\nx(t)dt\nf0:fundamental frequency\nT0\nT0 = 1/ f0\nXk = T\nT\n∫\nx(t)e\n- j 2πkt\nT0 dt\n\nFourier Series: Sawtooth\nx(t) = t 0 ≤ t < T0\ninf\n∑ Ak cos 2πkf0t + φk ) = X0 + Re\n(\n\ninf\n∑\nk=\nXke j 2πkf0t\n\nx(t) = A0 +\nk=1\nX0 = T\nXk = π\nT\nk\n0 e\nj π\nx(t) = T0\ninf\nπ\nT\nk\n0 cos 2πkf0t + π\n2 + ∑\n(\n2 )\nk=1\nx(t) = T\n0 + T\nπ\n0 cos 2πf0t + π\n2 ) + 2\nT\nπ\n(\ncos 2π 2 f0t + π ) + K\n(\n0.02\n0.04\n0.04\ny t\nt\nDefined between 0<t<0.04\nPeriodic with period 0.04\n0.04\n0.02\n0.02\n0.04\n0.04\nt\n0.04\n\nFourier Series:Square Wave\nx(t) =\n\n-\n1 T\n≤ t < T0 2\n2 ≤ t < T0\n\nk odd\nX0 = 0\nXk =\nkπ\nk odd\n=\n- j 4\nXk\n\nkπ e\n- j π\n\nk even\n\nk even\ninf\n∑\n\n1.2\ninf\n∑\nk=\n\nx(t) = A0 +\nAk cos 2πkf0t + φk ) = X0 + Re\n(\ne j 2πkf0t\nXk\nk=1\nx(t) = 4 cos 2πf0t -π\n4 cos 2π 3 f0t -π ) + K\nπ\n(\n2 ) + 3π\n(\n0.5\ny t\nx(t) = π\n(\nπ\n(\nz t\nsin 2πf0t) +\nsin 2π 3 f0t) + K\n0.5\n1.2\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\n0.04\nt\n0.04\n\nFourier Series:Square Wave Spectrum\n\nXk = - j 4\nk odd\nXk =\n4 e\n- j π\nk odd(1,3,5...)\nX0 = 0\nkπ\nkπ\nk even\n\nk even(2,4,6...)\n\nAk cos 2πkf0t + φk ) = X0 + Re\n(\n\ninf\n∑\nk=\nXke j 2πkf0t\n\ninf\n∑\nx(t) = A0 +\nk=1\nx(t) = π\n(\n) + 3\nπ\n(\nsin 2πf0t\nsin 2π 3 f0t) + K\n1.4\n1.2\n0.8\nComplex conjugate form\ne j 2πkf0t + e- j 2πkf0t\n0.6\namp\ninf\n∑\n\nx(t) = X0 +\nXk\n-10\n-8\n-6\n-4\n-2\ne j 2πkf0t\n0.4\n\n0.2\nk=1\ne j 2πkf0t\ninf\n∑\n\ninf\n∑\nx(t) =\nXk\nZk\n\n=\n\"two sided Fourier Series\"\nk=\nk=\n\n- j 2\nk = ±1,±3,...\n=\nZ0 = 0 Zk\nkπ\n0.5\nphase\n\n-0.5\n\nk = ±2,±4...\n2 k\nπ\n1.5\n-inf\n-inf\n-1\n\ne\n-\nk = ±1,±3...\nXk\n\n-1.5\nZk =\nk π\n-2\n-10\n=\n-8\n-6\n-4\n-2\nk = ±2,±4...\n\nProperties of Fourier Series\nOdd functions f (-x) = - f (x) consist only of sums of sines (φ = -π )\nEven functions f (-x) = f (x) consist only of sums of cosines (φ = 0)\nEx. Square wave\n1.2\nx(t) =\n0 ≤ t < T0\n0.5\nodd function\n-1 T0 2 ≤ t < T0\ny t\nz2 t\nX0 = 0\nXk =\nkπ e\n- j π\nk odd\n\n0.5\n\nk even\n(\n1.2\nπ\n3π\n0.04\n0.03\n0.02\n0.01\n0.01\n0.02\n0.03\n0.04\nx(t) = 4 cos 2πf0t -π ) + 4\n(\n0.04\n,\ncos 2π 3 f0t -π ) + K\nt t\n0.04\nx(t) = π\n4 sin 2( πf0t) + 3\nπ\n(\nsin 2π 3 f0t) + K\n\nProperties of Fourier Series\nOdd functions f (-x) = - f (x) consist only of sums of sines (φ = -π )\nEven functions f (-x) = f (x) consist only of sums of cosines (φ = 0)\nEx. Square wave\n1.2\nx(t) =\n0 ≤ t < T0\n0.5\ny t\nodd function\n-1 T0 2 ≤ t < T0\nz2 t\n2. π. t\n4 e\n- j π\n4 . sin\nT0\n2. π.5. t\nX0 = 0\nXk =\nkπ\nk odd\nπ\n4 . sin\n3. π\n\nT0\n0.5\n\nk even\n1.2\nt t\n0.04\nx(t) = π\n(\nπ cos 2π 3 f0t -π\n2 ) + K\n0.04\n,\ncos 2πf0t -π ) +\n(\nx(t) = π\n4 sin 2( πf0t) + 3\nπ\n(\nsin 2π 3 f0t) + K\n0.04\n0.03\n0.02\n0.01\n0.01\n0.02\n0.03\n0.04\n\nProperties of Fourier Series\nOdd functions f (-x) = - f (x) consist only of sums of sines (φ = -π )\nEven functions f (-x) = f (x) consist only of sums of cosines (φ = 0)\nEx. Square wave\n1.2\nx(t) =\n\n-\n1 T\n≤ t < T0\n0.5\nodd function\ny t\n2 ≤ t < T0\nz2 t\n2. π. t\nsin\nT0\nX0 = 0\nXk =\nkπ e\n- j π\nk odd\n\n2. π. t\nT0\n\nk even\ncos\n0.5\nx(t) = 4 cos 2πf0t -π ) + 4\n(\n1.2\ncos 2π 3 f0t -π ) + K\nπ\n3π\n0.04\n0.03\n0.02\n0.01\n0.01\n0.02\n0.03\n0.04\n(\n0.04\n,\n0.04\nt t\nx(t) = π\n4 sin 2( πf0t) + 3\nπ\n(\nsin 2π 3 f0t) + K\n\nProperties of Fourier Series\nOdd functions f (-x) = - f (x) consist only of sums of sines (φ = -π )\nEven functions f (-x) = f (x) consist only of sums of cosines (φ = 0)\nEx.Triangle wave\nx(t) =\n\n-\nt\nt\n+\n+\nT\nT\n-\nT\n≤\n0 /2\nt <\n≤\nT\nt\n< 0 even function\n0.5\n\nX0 = T\nT\n∫\nx(t)dt\n0.5\nX0 = T\nT\n∫\n(-4t - T0 )dt + 1\nT\n∫\nz t\n(4t - T0 )dt\nT0\n- T0\n.5\nt\n.5\nIn[1]:= 1/T*Integrate[-4*t-T,{t,-T/2,0}]+\n0.2\n0.4\n1/T*Integrate[4*t-T,{t,0,T/2}]\nOut[1]= 0\nX0 = 0\n\nProperties of Fourier Series\nOdd functions f (-x) = - f (x) consist only of sums of sines (φ = -π )\nEven functions f (-x) = f (x) consist only of sums of cosines (φ = 0)\nEx. Triangle wave\nx(t) =\n4t + T0\n-T0 /2 ≤ t < 0 even function\n0.5\n-4t + T0\n0 ≤ t < T0\nT0\nXk = 2 ∫\nx(t)e\n- j 2πkt\nz t\nT0 dt\nT0 -T0\n0.5\n0.2\n0.4\n.5\nt\n.5\nXk = T\nT\n∫\n(-4t + T0 )e\n- j 2πkt\nT0 dt + T\n0 -T∫\n0 2\n(4t + T0 )e\n- j 2πkt\nT0 dt\n\nT0 2\n- j 2πkt\n- j 2πkt\nEx. Xk = T0 ∫\n(-4t + T0 )e\nT0 dt + T0 -T∫\n0 2\n(4t + T0 )e\nT0 dt\nIn[3]:= 2/T*Integrate[(T+4*t)*Exp[-I*2*Pi*k*t/T],{t,-T/2,0}]+\n2/T*Integrate[(T-4*t)*Exp[-I*2*Pi*k*t/T],{t,0,T/2}]\nI k Pi\nI k Pi\n(-2 - I k Pi + E (2 - I k Pi)) T\n(2 + I k Pi + E (-2 + I k Pi)) T\nOut[3]= --------------------------------------\n+\n-----------------------------------------\nI k Pi 2 2\n2 2\nE\nk Pi\nk Pi\nIn[4]:= Simplify[%,Element[k,Integers]]\nk\nk\nk\n(-1 + (-1) ) (2 - 2 (-1) + I (1 + (-1) ) k Pi) T\nOut[4]= ------------------------------------------------\nk 2 2\n(-1) k Pi\n.\n. k.π\n1 k\n1 k\n2.\n1 k\n1j. 1\n.T0\nXk k\n1 k.k2.π2\n.\n4 T0 .\nXk k\n1 k\nk2.π2\n-2\nk odd\n8T\nk odd\n(-1)\nk -1 = 0\nk even\nXk =\n\nk 2\nπ 2\nk even\n\nProperties of Fourier Series\nOdd functions f (-x) = - f (x) consist only of sums of sines (φ = -π )\nEven functions f (-x) = f (x) consist only of sums of cosines (φ = 0)\nEx.\nx(t) =\n\n-\nt\nt\n+\n+\nT\nT\n-\nT\n≤\n0 /2\nt <\n≤\nT\nt\n< 0 even function\n0.5\n\n8T\nRe Y t\nz t\nX0 = 0\nXk =\nk 2π 2\nk odd\n\nk even\n0.5\n8T\nXk =\nk 2π 2 e j 0\nk odd\n\nk even\n0.5\n0.5\n1.5\nt\n1.5\nx(t) = π\n8T\n2 cos 2πf0t\n8T\nπ 2 cos 2π 3 f0t\n(\n) +\n(\n) + K\nf0 = 1\n\nProperties of Fourier Series\nOdd functions f (-x) = - f (x) consist only of sums of sines (φ = -π )\nEven functions f (-x) = f (x) consist only of sums of cosines (φ = 0)\nEx.\nx(t) =\n\n-\nt\nt\n+\n+\nT\nT\n-\nT\n≤\n0 /2\nt <\n≤\nT\nt\n< 0 even function\n\nRe Y t\nz t\n0.5\n8T\nX0 = 0\nXk =\nk 2π 2\nk odd\n8 . cos 2.π.t\n\nπ\nk eve\nn\n8 .cos 2. π.3 t.\n0.5\n8T\n9.π2\nXk =\nk 2π 2 e j 0\nk odd\n\nk even\n0.5\n0.5\n1.5\nt\n1.5\nx(t) = π\n8T\n2 cos 2πf0t\n8T\nπ 2 cos 2π 3 f0t\n(\n) +\n(\n) + K\nf0 = 1\n\nProperties of Fourier Series\nSymmetric functions with f (-x) = - f (x + T /2) only have odd harmonics\nSymmetric functions with f (-x) = f (x + T /2) only have even harmonics\nEx. Triangle wave (only odd harmonics)\nx(t) =\n\n4t + T0\n-T0 /2 ≤ t < 0\n-4t + T0\n0 ≤ t < T0 2\n0.5\nz t\n= 0\nXk =\nk\n2π\nT\nk odd\nXk\nY t\n1 cos 2. π.t\nX0\nk even\nXk 3\n.\ncos 2. π.3 t.\n.\n\n.\nXk 5 cos 2. π.5 t.\n\nXk =\n\nk\n2π\nT\n2 e j 0\nk odd\n0.5\n\nk even\n\n1.5\n0.5\n0.5\n1.5\n1.5\nt\n1.5\nx(t) = π\n8T\n2 cos 2πf0t) + 32\n8T\nπ 2 cos 2π 3 f0t) + K\n(\n(\nf0 = 1\n\nProperties of Fourier Series\nSymmetric functions with f (-x) = - f (x + T /2) only have odd harmonics\nSymmetric functions with f (-x) = f (x + T /2) only have even harmonics\nEx. Abs sine wave (only even harmonics)\nX0 = T\nT\n∫\nx(t)dt\n0.2\n0.4\n0.6\n0.8\nt\nx(t) = sin 2\nT0\n\nπ\n0 ≤ t < T0\nt\nz t\n0.5\n\nf0 = 1\nT0 2\nT0\ndt + 1\nT0\nT0\n∫\nT0 2\nsin 2π\nT0\n\nt\n\ndt = 1\nsin 2π\nT0\n\nt\n\n-sin 2\nT0\n\nπ\nX0 =\ndt\n∫\n∫\nt\nT0\nT0\nIn[2]:= 1/T*Integrate[Sin[2*Pi*t/T],{t,0,T/2}]+\n1/T*Integrate[- Sin[2*Pi*t/T],{t,T/2,T}]\nOut[2]= -\nPi\nX0 = 2\nπ\n\nT0 2\nT0\n-sin 2\nt\nπ\nT0\n\ne\n\n- j 2πkt\n- j 2πkt\n- j 2πkt\nT0\n\nT0 dt\nT0 dt\nT0 dt\nXk =\n∫\nt e\n∫\nt\n∫\nT0 2\n+\n=\nT0\nT0\nT0\n\nsin 2\nsin 2\ne\nIn[5]:= 2/T*Integrate[Sin[2*Pi*t/T]*Exp[-I*2*Pi*k*t/T],{t,0, T/2}]+\nT\nT\nT\n2 (T + -------)\n2 (------- + -----------)\nE\nE\nE\nOut[5]= ------------------ + ------------------------\n(2 Pi - 2 k Pi) T\n(2 Pi - 2 k Pi) T\nk 2\n\nπ\nT0\n\n2/T*Integrate[- Sin[2*Pi*t/T]*Exp[-I*2*Pi*k*t/T],{t,T/2,T}]\nI k Pi\nI k Pi (2 I) k Pi\nIn[6]:= Simplify[%,Element[k,Integers]]\n(1 + (-1) )\nk\n(\n)\n(\n)\nOut[6]= -(------------)\n-\n+\nX\n-\n=\nk\n-1+ k 2\n(-1 + k ) Pi\n(\n)π\nπ\nT0\n\nk odd\n\nXk =\nk even\n(-1+ k 2 )π\n\nProperties of Fourier Series\nSymmetric functions with f (-x) = - f (x + T /2) only have odd harmonics\nSymmetric functions with f (-x) = f (x + T /2) only have even harmonics\nEx. Abs sine wave (only even harmonics)\nx(t) = sin 2\nT0\n\nπ\n0 ≤ t < T0\nt\n\nz t\n0.8\n0.6\ny t\nX0 = 2\n0.4\nπ\n2. π. 2. t\nπ\n4 . cos\nπ\n0.2\n3. π\nT0\n2. π. 4. t\n. cos\nπ\n15. π\nT0\n2. π. 6. t\nk odd\n. cos\nπ\n36. π\nT0\nXk =\n\nk even\n(-1+ k 2 )π\n0.424413\n0.6\n0.2\n0.4\n0.6\n0.8\n,\nt t\nx(t) = π + 3\nπ cos 2π2 f0t + π ) + 15\nπ cos 2π 4 f0t + π ) + K\n(\n(\n\nHow it works\nEx. sine wave\n\nx(t) = sin 2\nT0\nπ\n\nt\n0 ≤ t < T0\nX0 = 1\nT\n∫\nx(t)dt\nT0\nt\n= 1\nT0\nsin 2π\nT\nT\n\n∫\n2. π.\nsin\n\nT\nX0\ndt\nt\n0.5\nT0\n-1\n= 2π\n2 π\nT0\nt\nt\n= 0\n\ncos\n\nX0\nAverage of a sinusoid over one period is equal to zero.\n\nEx. sine wave\n\nx(t) = sin 2\nT0\nπ\n\nt\n0 ≤ t < T0\nT\n1j. 2. π.k. 1 .t\nt\n.\nXk\nsin 2.π .\n.e\nT\ndt\nT\nT\nT\nt\nt\nt\n.\n.\n2.π .k.\n2.π .k.\nXk\nsin 2.π .\nT\n. cos\n1j sin\ndt\nT\nT\nT\nT\nT\n.\nt\nt\n2 1j .\nt\nt\n.\n2.π .k.\n2.π .k.\nXk\nsin 2.π .\nT\n.cos\ndt\nsin 2.π.\n.sin\ndt\nT\nT\nT\nT\nT\n\nEx. sine wave\nT\nT\n.\nt\nt\n2 1j .\nt\nt\n.\n2.π .k.\n2.π .k.\nXk\nsin 2.π .\nT\n.cos\ndt\nsin 2.π.\n.sin\ndt\nT\nT\nT\nT\nT\nk = 1\nT\nT\n.\nt\nt\ndt\n2 1j\nt\nt\n.\n.\nsin 2.π.\n.cos 2.π.\nsin 2.π.\n.sin 2.π .\ndt\nX1 T\nT\nT\nT\nT\nT\n0.499013\n0.5\n2. π. t\n2. π. t\n2. π. t\n2. π. t\nsin\n. sin\n0.5\nsin\n. cos\nT\nT\nT\nT\n0.499013\n0.5\n0.5\n0.5\nt\nt\nT\nT\nt\nt\nt\nt\nsin 2.π .\n.sin 2.π .\ndt = 0.5\ncos 2.π.\n.sin 2.π .\ndt = 0\nT\nT\nT\nT\n.\n2 1j . 1 .T\nX1\nT\n1i\nX1\nπ\n.\n1 e\nX1\ncos(ωt + φ) = cos(φ)cos(ωt)- sin(φ)sin(ωt)\n\nEx. cos wave + phase\ncos(ωt + φ) = cos(φ)cos(ωt)- sin(φ)sin(ωt)\nT\nT\n.\nt\n2 j .\nt\n.\n.\n2.π .k.\n2.π .k.\ncos 2.π .\nφ .cos\ndt\ncos 2.π .\nφ sin\ndt\nXk T\nT\nT\nT\nT\nT\nk = 1\nT\nT\n.\nt\nt\n2 j .\nt\nπ\nt\n.\ncos 2.π .\nφ .cos 2.π .\ndt\ncos 2.π .\n.sin 2.π .\ndt\nXk T\nT\nT\nT\nT\nT\n0.1462\n0.5\n0.853307\n0.5\n2. π. t\n2. π. 1.t\nπ\n2. π. t\ncos 2. π. 1. t\nπ . sin\ncos\n.cos\n0.5\n0.853307\n0.1462\n0.5\n0.5\n0.5\nt\nt\nT\nT\nt\nt\n.\n.\n.\nt\nt\ncos 2.π .\nφ cos 2.π .\ndt cos φ\n2 j .\n.\ncos 2.π .\nφ .sin 2.π .\ndt\n1j sin φ\nT\nT\nT\nT\nT\nT\n.\ncos φ\n1j sin φ\nX1\n.\nj. φ\n1 e\nX1\n\nEx. sine wave\nT\nT\n.\nt\nt\n2 1j .\nt\nt\n.\n2.π .k.\n2.π .k.\nXk\nsin 2.π .\nT\n.cos\ndt\nsin 2.π.\n.sin\ndt\nT\nT\nT\nT\nT\nk = 2\nT\nT\n.\nt\nt\n2 1j .\nt\nt\n.\n2.π .2.\n2.π .2.\nsin 2.π.\nT\n.cos\ndt\nsin 2.π.\n.sin\ndt\nX2 T\nT\nT\nT\nT\n0.769421\nsin 2. π. t . sin\n2. π. 2 t.\nsin 2. π. t . cos\n2. π. 2 t.\n0.769421\n0.5\n0.5\nt\nt\nT\nT\nt\nt\nt\nt\ncos 2.π .\n.cos 2.π .2.\ndt 0\ncos 2.π .\n.sin 2.π .2.\ndt = 0\nT\nT\nT\nT\nX2\n\nEx. sine wave\nk = 1\nT\nT\n.\nt\nt\n2 1j .\nt\nt\n.\n2.π .k.\n2.π .k.\nXk\nsin 2.π .\nT\n.cos\ndt\nsin 2.π.\n.sin\ndt\nT\nT\nT\nT\nT\nT\nT\nt\nt\nt\nsin 2.π .\n.cos 2.π .k.\ndt = 0\nsin 2.π .\n.sin 2.π .k. t\ndt 0\nT\nT\nT\nT\nXk\nIn[11]:=\n2/T*Integrate[Sin[2*Pi*t/T]*Sin[2*Pi*k*t/T],{t,0,T}]+\n2*I/T*Integrate[Sin[2*Pi*t/T]*Cos[2*Pi*k*t/T],{t,0,T}]\n(2 I) Sin[k Pi] Sin[2 k Pi]\nOut[11]= ---------------- + -----------\nPi - k Pi\n(-1 + k ) Pi\nIn[12]:= Simplify[%,Element[k,Integers]]\nOut[12]= 0\n\nHow it works\nEx. sine wave\n\nx(t) = sin 2\nT0\nπ\n\nt\n0 ≤ t < T0\n0.5\nX0 = 0\n2. π. t\nsin\nT\n1e\n-\nk > 1\nt\n\nπ\nk = 1\nXk =\n\ninf\n∑\nk=\nXke j 2πkf0t\ninf\n∑\nx(t) = A0 +\nAk cos 2πkf0t + φk ) = X0 + Re\n(\nk=1\nx(t) = cos 2πf0t -π )\n(\nx(t) = sin 2πf0t)\n(\nx(t) = sin 2\nT0\nπ\n\nt\n\n0 ≤ t < T0\n\nHow it works\nEx. sine wave\n\nx(t) = sin 2\nT0\nπ\n\nt\n0 ≤ t < T0\n2. π. t\nsin\nT\nX0 = 0\n1e\n-\nk = 2,3,...\n\nπ\nk = 1\n0.5\nXk =\nt\n\ne j 2πkf0t\n\ninf\n∑\ninf\n∑\nk=\nx(t) = A0 +\nAk cos 2πkf0t + φk ) = X0 + Re\n(\nXk\nk=1\n(\n0.9\n0.8\nx(t) = cos 2πf0t -π )\n0.7\n0.6\nx(t) = sin 2πf0t\n(\n)\n0.5\n0.4\n0.3\n0.2\n0.1\ne j 2πkf0t + e- j 2πkf0t\nx(t) = Z0 +\ninf\n∑\n\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\nZk\n\n1.5\nZ0 = 0\nk=1\n0.5\n\n2 e\n-π\n2 k\nk = ±1\nXk\nZk =\n=\n\n-0.5\n\n-1.5\n\nk = ±2,±3...\n-1\n-2\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n\nHarmonic sinusoid\nXk = 2\nT0\n∫\n2 π mt e\n\n- j 2πkt\nT0 dt\nA\nif\nm = k\n\nAcos\nT0 0\nT0\nXk = 0 if\nm = k\n\nSum of harmonic sinusoids\ninf\n∑\n\nT0\n=\n) e\nT0\nXk\nT\n∫\n[\n(\n(\n(\n]e\n- j 2πkt\n=\nA1 cos 2πf0t) + A2 cos 2π2 f0t) + A3 cos 2π 3 f0t) +...\nT0 dt\n= 2\nT0\nA1 cos 2πf0t\n- j 2πkt\nT0 dt + 2\nT0\nA2 cos 2π 2 f0t\n- j 2πkt\nT0 dt + 2\nT0\nA3 cos 2π 3 f0t\n- j 2πkt\nT0 dt +...\nT0\nT0 ∫\n(\n)e\nT0 ∫\n(\n)e\nXk\n∫\n(\n)e\nA1\nif\nk=1\nA2\nif\nk= 2\nA3\nif\nk= 3\nif\nk=1\nif\nk=2\nif\nk=3\n\n∫\nT0\nX\nA\n=\nk\nk\n- j 2πkt\ncos 2πkf0t\n(\nT0 dt\nXk\nAk\nk=1\n\nClipped Sinewave\n\nif\n(\nAsin 2πf0t) > 1\nXk\n\n(\n=\n-1\nif\nAsin 2πf0t) < 1\nA = 2\nx t\nAsin 2( πf0t)\notherwise\n\nT0 = 1 = 2\nf0\nt\n2. π\nXo 0\nT1\nT2\nT3\n.e\n1j. 2. π.k.\nT\n1 .\ndt\ne\n1j. 2. π.k.\nT\n1 .\ndt\n1j. 2. π.k. 1 .\nt\nt\nt\nt\nt\n.\n.\n2.π .\n.\n.\n.\n2.π .\nXk\nA sin\nA sin\n.e\nT\ndt\nT\nT\nT\nT\nT1\nT\nT2\nT4\nT\n1j. 2. π.k.\nT\n1 .t\n1j. 2. π.k. 1 . t\nt\n.\n.\n.\n.\n1 e\ndt\nA sin 2.π .\n.e\nT\ndt\nT\nT\nT3\nT\nT4\n\nClipped Sinewave\nRe Y t\n.\n2 sin t\n0.5\n.\nRe Xk 1 e1j t\n.\n0.45\nXk 3\n.\n3j t\n. e\n0.4\nRe\nXk 5\n0.35\n.\n5j t\n. e\nRe\n0.3\n0.25\n0.2\n0.15\n0.1\n0.05\nt\n6.283185\n-10\nClipping adds harmonics\n1.5\nwhich distorts the pure tone.\n\"richer\" sound\n0.5\nt=0:1/8192:0.5;\ny=sin(2*pi*440*t);\n-0.5\nsound(y/2)\n-1\n-1.5\nsound(y)\n-2\n-10\nsound(2*y)\nsound(5*y)\nsound(10*y)\n-8\n-6\n-4\n-2\namp\nphase\n-8\n-6\n-4\n-2"
    },
    {
      "category": "Resource",
      "title": "Recitation 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/b338e7dd431d89ffd1c63e77fd868bb9_rec4.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n[\nWhat do you do with negative amplitudes?\nPeriod of Sum of Sinusoids\nAmplitudes always positive\nC cos 2ft = C cos 2ft ±\n(\n)\n(\n)\ncomplex amplitude spectrum\nAbsorb the minus sign into the angle\n1.8\n1.6\n3cos 2 5t +\n3 = 3cos 2 5t +\n(\n)\n(\n3 )\nx t( ) = cos 25t\n(\n)\n1.4\n1.2\n= 3cos 2 5t 2\n(\n3 )\nTextEnd\n1.5e\nj 2\n1.5e\nj 2\ncomplex amplitude - X\n0.8\n0.6\n0.4\n0.2\nj 2ft +\nj 2ft +\ne\n+ e\ny t = cos 2\n4 t\n-6\n-4\n-2\n( )\n( )\n(\n3 )\ncos 2ft + =\nfrequency - f\n(\n)\nj\nj 2ft\nj\nj2ft\ne e\n+ e\ne\namplitude spectrum\n=\nTextEnd\n1.5\n1.5\n1.5\n= Xkme j 2ft + Xkpe j 2ft\nXkm = 1\n2 e j\namplitude - A\n0.5\n= Xke j 2ft\n-6\n-4\n-2\nz t( ) = x t( ) + y t( )\n2 e j\nk = f\nTextEnd\nphase spectrum\nz t( ) = z t( + T),T = ?\n2 e j\nk = f\nX =\notherwise\nphase - phi\n-1\n-2\nalways a odd\npair\n-3\n-6\n-4\n-2\nfrequency - f\nLeast common multiple\n( )\n(\n( ) )\nFourier Series\nx t( ) = cos 2( 5t)\ny t = cos 2\n4 t\nt\n2. .\nT\nsin 2t) 0 t <1\nseconds to complete cycle\nx(t) =\n(\nsin\nseconds to complete cycle\nT =3/4 seconds\n\n0.5\ny\n= 0 +1 cos 2t + 0 cos 22t + 0 cos 23t +K\nTx=1/5 seconds\nt\n\n3/4s, 6/4s, ...\nX0 = 0\n1/5s, 2/5s, 3/5s ...\nX\n1e\nj /2\nk =1\nk =\n4/20s, 8/20s, 12/20s,\n15/20s. 30/20s,\nk 1\n16/20s, 20/20s, 24/20s,\n28/20s, 32/20s, 36/20s,\n45/20s, 60/20s\nX0 = 1 T\n\n0 x(t)dt\n40/20s, 44/20s, 48/20s,\n4 cycles\nT0\n52/20s, 56/20s, 60/20s\n1/5*k=3/4*l\n= sin(2t)dt = 0\n15 cycles\nk/l=15/4\nrational number\n2 T0\nj2 k t\nXk =\nx(t)e\nTo dt\nz t( ) = x t( ) + y t( )\nT0\nj2\nTz=15*Tx=15/5=3 seconds\nTz=4*Ty=3/4*4=3 seconds\n= 2 sin(2\n\nt)e\nktdt\nz t( ) = z t( + T )\nz\n= 2 sin(2t) cos(2kt)+ j sin(2kt)]dt\nTz=3 seconds\n\nFourier Series\nFourier Series (frequency space)\nT\n. . . . t\nj\nk\n.\nT\ncos(2kt)\nsin(2t)cos(2kt)\nsin(2t)cos(2kt)dt\n.\n.\nT\nz t\ne\n\ndt\nz t\ndt\nXk T\nsin(2t)\nsin(2kt)\nsin(2t)sin(2kt)\n\n1 sin(2t)sin(2kt)dt\nXk\nX0 T\nt\n. . . .\nj\nk\n.\n2..\n.t\ncos 2..5 t.\ncos\ndt\n2 .\nX0\ncos 2..5 t.\ncos 2.. 4 .t\n.e\n3 dt\nXk\n= 0\n=1e\nj /2\nX0\n2 exp\n2 i k\nk3\n2 k3\n241 exp\n2 i k\nk\nk =1\n.\n.\n. .\n.\n.\n.\n.\n. .\n.\n.\n241 k\n.\ni\nXk\n= 0.5\n.k4\n241..k2\n3600.\nk4 , 15\nk\n4 , k\n\n2 1 k3\n2 k3\n241 1 k\n= 0\n. .\n.\n. .\n.\n241 k\nXk 1i.\n.\n.\n.\n.\nk\nk\nk\nk\n4 15\n= 0\nX ,\nXk\nk = 2\n= 0\nSo, use L'Hopitals Rule\n= 0\nXk\n.\n.\n. .\n.\n. .\n.\n.\n.\n. .\n.\n.\n.\n. .\n.\n.\n.\n. .\n4 1i exp\n2 1i k\nk3\n6 exp\n2 1i k\nk2\n6 k2\n482i..exp\n2 1i k\nk\n241 exp\n2 1i k\n.1i.\n. k\nk\n.\n.\n.\n.\n.\n.\n.\nk\n. k\nk\nk\n. k\nk\nk\n. k\nk\nk\nk = 3\n= 0\n= 0\nX15\nX4\nFourier Series (frequency space)\nAperiodic Sum of Sinusoids w/ an Irrational Frequency\nSpectrum of z=cos(2pi*5t)+cos(2pi*(4/3)t)\nX0\naperiodic sum of sinusoids\nperiod:3/4 seconds\nperiod:5sqrt(2) seconds\n0.9\nk4 , 15\nXk\n0.8\nX\n0.7\nX15\n0.6\n0.5\nx t = cos 25 2t\n( )\n(\n)\n-0.5\n-1\n1 TextEnd\n0.5\ny t = cos 2\n4 t\n( )\n( )\n(\n3 )\n-0.5\n0.5\nTextEnd\n0.4\nX\n0.3\n0.2\n0.1\nTextEnd\n-1\n-20\n-15\n-10\n-5\nfrequency\nperiod:?seconds\nz t( ) = x t( ) + y t( )\n-1\nTextEnd\nz t( ) = z t( + T),T = ?\n-2\ntime\n\nx\n5 2\nFourier Series for Irrational Frequency\nx t( ) = cos 25 2t\ny t = cos 2\n4 3 t\n(\n)\nLeast common multiple\n( )\n(\n)\n( )\n\"What's the frequency, Kenneth?\"\nAperiodic sum of sinusoids\nseconds to complete cycle\nIn 1986, CBS Anchorman Rather was confronted about 11 p.m. while walking on\nseconds to complete cycle\n0.5\nPark Avenue, when he was punched from behind and knocked to the ground then\nT =\nseconds\nchased into a building and kicked him several times in the back while the assailant\n-0.5\nT\nseconds\n5 2\n=\n-1\nTextEnd\ny\ndemanded to know 'Kenneth, what is the frequency?' The assailant was convinced\n0.5\nperiod:3/4 seconds\nperiod:5sqrt(2) seconds\nthe media had him under surveillance and were beaming hostile messages into\ns,\ns,\nsK\n-0.5\n5 2 5 2\n-1\nTextEnd\ns, s, sK\n-1\nTextEnd\nhis head, and he demanded that Rather tell him the frequency being used.\nperiod:? seconds\nIn the Fourier Series for an aperiodic signal\n-2\ntime\n\"what's the period, Quinn?\"\n0.6\n0.410218\nk =\nl\n5 2\nT\nT\n. . . . t\n1j 2 k\n0.4\nz t\ndt\n.\n.\nA k\nk\n15 2\nX0\nT\n.\nXk\nT\nz t\ne\n\nT dt\n=\nirrational number\n0.2\nl\n.\n5.252191 10\nz t( ) = x t( ) + y t( )\nPS3-5\nk\nz t = z t + T\n( )\n(\n)\nz\nPick a T, plot the spectrum, then repeat with larger T's.\nT = seconds\nz t( ) aperiodic\nz\nBases are building blocks to form more complex things\nQUAD8 Numerically evaluate integral, higher order method.\nQ = QUAD8('F',A,B) approximates the integral of F(X) from A to B\n'F' is a string containing the name of the function.\nSynthesize x from a weighted sum of basis elements,\nm\nThe function must return a vector of output values given a vector of input values.\nx =Akk\nor\nQ = QUAD8('F',A,B,TOL,TRACE,P1,P2,...) allows coefficients P1, P2, ...\nto be passed directly to function F: G = F(X,P1,P2,...).\nk=1\nDecompose x into a weighted sum of basis elements,\nTo use default values for TOL or TRACE, you may pass in the empty\nmatrix ([]).\nBasis Vector\nx(t) = cos\n2 (\n)\n2ft dt\nV1\nV1\nfunction y = myintegrand(t,f)\nV\nV2\ny=cos(2*pi*f*t).^2;\nV2\nV\nsave as myintegrand.m\nx2\nx1 V = axˆ1 + bxˆ2\nx2\nV = axˆ1 + bxˆ2\n»f=1;\nx1\n»quad8('myintegrand',0,1,[],[],1)\nans =\nPrefer orthonormal basis vectors\n0.50000000000000\nT\nV\nV-x2\nV\nT\n. . . . t\nX0 T\n1 .\nXk T\nz t\ne\n1j 2 k\nT dt\nV-x2\nprojections\nz t\ndt\n.\n.\nPick a T, compute X0, loop over Xk's, plot the spectrum, then repeat with larger T's.\nx2\nx2\nV-x1\nV-x1\nx1\nx1\nV = V - x1 xˆ1 + V - x2 xˆ2\nV V - x1 xˆ1 + V - x2 xˆ2\n(\n)\n(\n)\n(\n)\n(\n)\n\n=\n=\nBasis Functions\nBasis Functions\n\nb\njk\n*dt =\n1 if\nj = k\nnormalized\nx(t) =Akk (t)\nx(t),k (t) are functions\na\n0 if\nj k orthogonality condition\nk\nover an interval\na t b\nEx:\nWhen are functions orthogonal to each other?\nb\n1 = 3\n6 cos 2( t)\n12dt =\n(\n( ( )\n3 )\ncos 2t\n)\n6 cos 2\n1 t dt\northogonal\nb\nover an interval\n*dt =\n1 if\nj = k\nnormalized\n2 =\ncos 2\n1 t\n( )\njk\n0 if\nj k\northogonality condition\na t b\n(\n3 )\na\n= 0\na\nb\nover an interval\ncos 2t)\n6 cos 2t dt\nnormalized\nHow do you \"project\" functions onto each other?\n0 t 3\n11dt =\n(\n(\n)\na\n=1\nb\nb\nAk = x(t)k\n*dt\nHow much of k (t) is in x(t) ?\n22dt =\n( ( )\ncos 2\n1 t)\n6 cos 2\n1 t dt\n( ( ) )\nnormalized\na\na\n=1\nIf k (t) are orthonormal:\nb\nwhere\n=\nx(t)k\n*dt\nFourier Series\nx(t) =Akk (t)\nAk\nj 2kt\n0.816497\n. cos\nk\na\nk = 1\nT0 e\nT0\n.2\n.\nt\n1 . t\n2. .\n. cos\nComplex exponentials\n0.816497\nt\nBezier Curves\nBezier Curves\nP1\n0.5\ny t\nx t\nP0\nP2\nP1\nP2\ny t\ncubic spline basis function\ny t\ncubic spline basis function\n0.5\n0.5\n0.5\n0.5\nP3\n1 = (t 1)\n0 t 1\nP3\n1 = (t 1)\n0 t 1\n0.5\nP00\nx t\n0.5\n0.5\nt\nt\n2 = 3t t( 1)\n2 = 3t t( 1)\n3 = 3t 2 (t 1)\nt\n3 = 3t 2 (t 1)\nt 3\nP0=(0,0)\nP1=(.5,1)\nP0=(0,0)\nP1=(.5,1)\nt 2\nt 2\nt\n0.5\nt\n0.5\n3. t.\n3. t.\nP2=(.75,.8)\nP2=(.75,.8)\n0.5\n0.5\n4 = t 3\nt\n4 = t 3\nP3=(1,0)\nP3=(1,0)\nt .\nt .\n3.\n3.\nt\nt\nt\n0.5\n0.5\nx t\nx t\n0.5\n0.5\nt\nt\nx(t) = P0x (1 t)3 + 3P1x (1 t)2 t + 3P2x (1 t)t 2 + P3x (1 t)t 3\nx\nx\nx\nx\nx(t) = P0 (1 t)3 + 3P1 (1 t)2 t + 3P2 (1 t)t 2 + P3 (1 t)t 3\ny(t) = P0y (1 t)3 + 3P1y (1 t)2 t + 3P2y (1 t)t 2 + P3y (1 t)t 3\nparametric curve\ny(t) = P0y (1 t)3 + 3P1y (1 t)2 t + 3P2y (1 t)t 2 + P3y (1 t)t 3\nparametric curve\n1 = (t 1)\n\nb\n12dt =\n(t 1)\n33t t( 1)\n2 dt\nnot orthogonal\n1 = (t 1)\n\nb\n12dt =\n(t 1)\n33t t( 1)\n2 dt\nnot orthogonal\na\na\n2 = 3t t( 1)\n2 = 3t t( 1)\ny t\n\n+\n\n(\n)\n(\n(\n) )\n(\n(\n) (\nMake your own set of basis functions\n1. Pick an initial basis function 1 and an interval a t b\n2. Normalize 1\nb\n11dt =1\n1 eqn\na\n3. Pick a general formula for a second function 2\n4. \"Orthonormalize\"\na. make 2 orthogonal to 1\nb. normalize 2\nb\nb\n12dt = 0\n22dt =1\n2 eqns\na\na\n5. Pick a general formula for a second function 3\n6. \"Orthonormalize\"\na. make 3 orthogonal to 1& 2\nb. normalize 3\nb\nb\nb\n31dt = 0\n32dt = 0\n33dt =1\n3 eqns\na\na\na\n7. Continue for k\nk eqns\nMake your own set of basis functions\n1. Pick an initial basis function 1 with one parameter & an interval\n1 = A\n0 t 1\n0.5\n0.6\nt 2\ny x\n2. Normalize 11dt =1\n0.4\nt1\n.\nAAdt =1\n0.5 x\n0.5\n0.2\nA\n2t =1\nA2 =1\n0.5\nx\nA =1\nLinear segments\n1 =1\n3. Pick an second basis function\nwith two parameters\n2 = Bt + C\n4. Orthonormalize\nMake your own set of basis functions\n1. Pick an initial basis function 1 with one parameter, & interval\na t b\n2. Normalize 1\nb\n11dt =1\n1 eqn\na\n3. Pick a general formula for a second function 2 with 2 parameters\n4. \"Orthonormalize\"\na. make 2 orthogonal to 1\nb. normalize 2\nb\nb\n12dt = 0\n22dt =1\n2 eqns\na\na\n5. Pick a general formula for a second function 3 with 3 parameters\n6. \"Orthonormalize\"\na. make 3 orthogonal to 1& 2\nb. normalize 3\nb\nb\nb\n31dt = 0\n32dt = 0\n33dt =1\n3 eqns\na\na\na\n7. Continue for k\nwith k parameters\nk eqns\n1 =1\n2 = 2 3t 3\n5. Pick an third basis function 3 with three parameters\nbt + a\nt c\n0.6\n0.5\n3 = (bc + a) b(t c) t > c\ny x\n0.4\n.\n0.5 x\n0.5\n0.2\n6. Orthonormalize\nt 2\nt 2\nt 2\n0.5\n33dt =1\n31dt = 0\n32dt = 0\nx\nt1\nt1\nt1\nLinear segments\nB2\nB2\nB\nc\nt 2\nt 2\nB\n(bt + a)(bt + a)dt + (bc + a b t( c))3dt =1\n=\ndt =1\n21dt = 0\nt1\nt1\nc\nc\n(Bt + C)(Bt + C)dt =1\n(Bt + C)1dt = 0\nB = ±2 3\nbx + a 1dt +\nbc + a b x c 1dt = 0\nc\nc\nC = m\nB\n2t\n2 +C\n2t\n1 =1\nB + C = 0\n(bx + a)(2 3t 3)dt +\nbc + a b x c ) 2 3t 3)dt = 0\n3+ 2CBt\nc\nB2\n+ BC + C2 =1\nC = B\n2 = 2 3t 3\n& 2 zero-crossings\n& 1 zero-crossings\n\n( )(\n\n6. Orthonormalize\nDecomposition via the \"Q\" basis\n1.732051\n.\n1 .b2 1\n1 =1\n0 t 1\n.\n. 3\n. .\n.\n. 2\n. .\n.\n.\n2 b2 c\n2 b\n2 b a\nc\n2 b\nb\n2 a c a\na b\n2 = 2 3t 3\n.\nx\n\nc2\n.\n2 c\n.b\na 0\n4 3t 3\nt 1\ny x\n3 =\n1.732051\n.\n. .\n.\n.\n.\n3 b\n2 c\n2 c\n3 .\n.\n2 c 1 0\n(2 3t + 3) 4 3(t\n1.732051\n) t >\n.\ny x\nx\n\n( )\nc =\nb + a = 0\na =\nb\nx(t) = cos t\nLinear segments\nb\n1.732051\n0.5\nx\nx(t) =Akk (t) where\nx(t)k\n*dt\nb\nAk =\n0.5\nx(t)3 dt\nA3 =\nx\nk\na t b\na\na = 3\nb = 4 3\nc =\na\nb\nb\nLinear segments\n=\ncos t 4 3t 3)dt\nx(t)2 dt\nA3\n( )(\nA1 =\nx(t)1 dt\nA2 =\n4 3t 3\nt 1\na\na\n3 =\n=\ncos 2t 1dt\nA2\n(\n)\n3)dt\n+ cos t 2 3t + 3 4 3(t 1\n2 ))dt\n(2 3t + 3) 4 3(t 1\n2) t > 1\n1 =1\nA1\n(\n)\n=\ncos 2t (2 3t\n2 = 2 3t\n1 2\nA3 = 0.702\nA1 = 0\nA2 = 0\n1.2159\n4 3t 3\nt 1\n3 =\ncos 2. .x\n(2 3t + 3) 4 3(t 1\n2) t > 1\n.\n0.702 y x\nx(t) = 0.7023(t)\n1.211036\n0.5\nx\nDecomposition via the \"Q\" basis\nOrthonormal Cubic Splines\n\n2.645751\nx(t) = sin t\n0 t 1\n.\n7 t\nT\nT\nx(t)3 dt\n.\n.7\n5 t3\n.\n.6\n5 t2\nA3 =\nx(t) =Akk (t) where\nAk =\nx(t)k\n*dt\nk\n1 2\nA3 = sin\n2 t (4 3t 3)dt\n.\n21.\nt\n.\n3. 10. 3\nt\n.\n10. 3 t\nT\nT\n.\n35 t3\n.\n60 t2\n.\n30 t\nx(t)1 dt\nA2 =\nx(t)2\nA1 =\ndt\n\n+\nsin\nt(2 3t + 3 4 3(t 1\n2 ))dt\n0.5\nsin\nsin\n2 t (\n)\n2 3t 3\nA2\ndt\nt\n1dt\nA1 =\nt\n=\n1 2\n.\nt\nsin\n.\nt\nt2\nsin 2..t\nA3 = 0.06\ncos\nA1 = 0.673\nA2 = 0.301\n1.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n\nSampling and Aliasing\nD/A Conversion\ny[n]\n0.8\n0.6\nDtoC\n0.4\n0.2\n-0.2\n-0.4\n-0.6\n-0.8\n-1\nTs = 1 /fs\n0.5\n1.5\n2.5\n3.5\ny(t)\n0.5\n1.5\n2.5\n3.5\n-1\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n0.8\nIdeal discrete to continuous converter for sample spacing Ts\nInterpolates discrete samples to form a continuous signal\n0.8\n0.6\n0.4\n0.2\n-0.2\n-0.4\n-0.6\n-0.8\n-1\n0.5\n1.5\n2.5\n3.5\nD/A Conversion\nD/A Conversion\nPulse\nPulse\nFor each sample y[n], a pulse p(t) is produced\nFor each sample y[n], a pulse p(t) is produced\ny(t) =\ny[n]p(t nTs )\ny(t) =\ny[n]p(t nTs)\nn=\n0.9\n0.9\n0.8\n0.8\n0.7\n0.7\ny[n]\ny(t)\n0.6\nDtoC\n0.6\n0.5\n0.5\n0.4\n0.4\n0.3\nTs = 1 /fs\n0.3\n0.2\n0.2\n0.1\n0.1\n-10\n-8\n-6\n-4\n-2\nn=\n0.9\n0.8\n0.7\ny[n]\ny(t)\n0.6\nDtoC\n0.5\n0.4\n0.3\nTs = 1 /fs\n0.2\n0.1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n-10\n-8\n-6\n-4\n-2\n-10\n-8\n-6\n-4\n-2\n-10\n-8\n-6\n-4\n-2\n1 t T\nT t T\ns\ns\ns\notherwise\n1 T 2 < t T 2\ny(t) = p(t) =\ns\ns\ny(t) = p(t) =\notherwise\nDifferent pulse shapes produce different D-to-C interpolations\nDifferent pulse shapes produce different D-to-C interpolations\n\n0.6\nD/A Conversion\nD/A Conversion\nPulse\nPulse\nFor each sample y[n], a pulse p(t) is produced\nFor each sample y[n], a pulse p(t) is produced\n= y[n]p(t nT )\ns\n0.9\n0.9\nn=\n0.8\ny(t) = y[n]p(t nTs )\n0.8\n0.7\nn=\n0.7\n0.6\n0.6\n0.5\n0.5\ny[n]\ny(t)\n0.4\n0.9\nDtoC\n0.4\n0.9\n0.3\n0.8\n0.3\n0.8\n0.2\n0.7\n0.2\n0.7\ny[n]\ny(t)\n0.1\nTs = 1 /fs\n0.6\n0.1\n0.6\nDtoC\n-10\n-8\n-6\n-4\n-2\n0.5\n0.5\n-10\n-8\n-6\n-4\n-2\n0.4\n0.4\n0.3\n0.3\nTs = 1 /fs\ny(t) = y[0]p(t) + y[1]p(t Ts)\n0.2\n0.2\nt T\nT t T\n0.1\ny(t) =1p(t) + 1\n2 p(t Ts)\np(t) =\ns\ns\ns\n0.1\ny(t) = y[0]p(t) + y[1]p(t Ts)\n-10\n-8\n-6\n-4\n-2\ny(t) = ap(t) + bp(t Ts)\n\notherwise\n-10\n-8\n-6\n-4\n-2\ny(t) =1p(t) + 0.5 p(t 1)\n1 T 2 < t T 2\n\n0 t < T\n\n0 t < T\np(t) =\ns\ns\n\ns\ns\notherwise\n1+ t T\nT t < 0\ns\ns\n0 T t < 0\n1 0( ) + 0.5 0 = 0 t < 1 2\n\n( )\ns\ny(t) = a 1 t Ts\n0 t < Ts + b 1+ (t Ts) Ts\n0 t < Ts\n1 1\n( ) =\n1 2 < t <1 2\n( ) + 0.5 0\ny(t) =\n1(t T ) Ts\nTs t < 2Ts\n0 T t < 2T\ns\n1 0( ) + 0.5 1 = 0.5 1 2 < t < 3/2\n\n( )\ns\n\n0 t > 2T\n\n0 t > 2T\n1 0\n( ) = 0\n3/2\n\n< t\n( ) + 0.5 0\na\n1.4\nD/A Conversion\n0.9\nb\n1.2\n0.8\nIdeal\n0.7\ny[n]\ny(t)\nDtoC\n0.8\n0.5\n0.6\n0.4\n0.3\nTs = 1 /fs\n0.4\n0.2\n0.2\n0.9\n0.1\n0.8\n-10\n-8\n-6\n-4\n-2\n-10\n-8\n-6\n-4\n-2\nT =1\n0.7\ns\n0.6\n\n0 t < Ts\n0.5\n1+ t T\nT t < 0\n0.4\ns\ns\n0.3\n0.2\ny(t) = a(1 t Ts) + b(1+ (t Ts) Ts) 0 t < Ts\n0.1\n1(t T ) T\nT t < 2T\n0.8\ny(t)\n0.6\ny[n]\nDtoC\n0.4\nTs = 1 /fs\n0.2\n-0.2\n-10\n-8\n-6\n-4\n-2\n\ns\ns\ns\ns\n-0.4\n\n0 t > 2Ts\n-10\n-8\n-6\n-4\n-2\n\nt\nsin\n\n0 t < Ts\nTs\ny(t) = p(t) =\nfor < t <\n1+ t T\nT t < 0\ns\ns\nt\n\ns\n1 t Ts\nTs t < 2Ts\nt\n\n0 t > 2Ts\n= sin c\nT\ns\nlinear interpolation\ny(t) = a + (b a) t Ts\n0 t < Ts\nT\n\nWalsh functions\northogonality condition\nnormal\njk\n*dt\na\nb\n\n= 1 if\nj = k\n0 if\nj k\n\n*dt\n\n= 11\n\n= 4\n*dt\n\n= 11+ 1 1\n(\n)+11+ 1 1\n(\n)\n(\n) = 4\n*dt\n\n=11+11+ 1 1\n(\n)+ 1 1\n(\n) =1+111 = 0\nnot normal\nnot normal\northogonal\nWalsh functions\n0.5\n1.5\n2.5\n3.5\n-1\n-0.8\n-0.6\n-0.4\n-0.2\n0.2\n0.4\n0.6\n0.8\nt\nx(t)\nTextEnd\nx(t) = t\nx(t) =\nAk\nk k (t)\nAk = 1\nk\nx(t)\n* t( )dt\n\n= 1\n4 x(t)W (2, k +1)dt\n\nwhere\n0 t 4\nA0 = 1\n4 t 1dt\n\n= t2\n2 0\n4 = 1\n4 8 = 2\nA1 = 1\n4 t 1dt\n\n+ 1\n4 t 1\n(\n)dt\n\n= 1\nt2\n2 0\n2 1\nt2\n2 2\n4 = 1\n4 2 6\n(\n) = 4 1\n4 = 1\nA2 = 1\n4 t 1dt\n\n+ 1\n4 t 1\n(\n)dt\n\n+ 1\n4 t 1dt\n\n= 1\nt2\n1 t2\n2 1\n3 + t2\n(\n) = 1\n2 9\n2 1\n[\n]+ 16\n2 9\n[\n]\n(\n) = 0\nb\na jk\n*dt = k\n2 1\nt\n+ t\nt\nA = 1 t 1dt + 1 t 1 dt + 1 t 1 dt + 1 t 1 dt = 1\nt\n= 4 if\nj = k\n(\n)\n( )\n3 (\n)\n4 ( 2\n2 )\n] 16\nif\nj k\n= 4 ( 2 [ 4\n2 1\n2 ]+[ 2\n9 4\n[ 2 9\n2 ]) = 2 1\n4 = 1\nWalsh functions\nx(t) =\nAk\nk k (t)\nAk = 2,1, 0, 1 2\n[\n]\n[2 2 2 2]+[-1 -1 1 1] + [0 0 0 0]+[-0.5 0.5 -0.5 0.5 ]=[0.5 1.5 2.5 3.5]\n0.5\n1.5\n2.5\n3.5\n0.5\n1.5\n2.5\n3.5\nt\nx(t) , xhat(t)\nTextEnd"
    },
    {
      "category": "Resource",
      "title": "Recitation 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/1bb9e76aaffed02e9ea8fe93ddd69a90_rec5.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nSampling\nShannon Sampling Theorem\nf > 2 f\nf\n< f 2\nt = Tsn\nx t = cos 21500t\ns\nmax\nmax\ns\n( )\n(\n)\nT = 1\nfs = 2 fmax\nNyquist rate\ns\nfs\nt = T n\ns\nf = 1500 Hz\no\nx n = cos 2 1500 T n\n[ ]\n(\ns )\n0.5\nf = 8000Hz\ns\ns\ns\nfs\nf = 8000 Hz\nT = 1 =\nsec\n-0.5\nx n = cos 2 1500 8000 n\n[ ]\n(\n)\n-1\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nt - sec\nx 10-3\noversampling\nf = 1500 Hz\no\n0.8\n2A\n0.6\n0.5\n0.4\n0.2\nfmax\nfmax\n-0.5\n-1\n-0.5\n0.5\n-1\nf\n\nfs\nfo f - freq fo\nfs\nf\nx 104\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\ns\nHz\ns\nt - sec\nx 10-3\nTime domain\nsampled sinewave\n1500 Hz\n0.8\n0.9\n0.6\n0.8\n0.4\n0.7\nx\n1500 Hz\n0.2\n0.6\nsampling\n0.5\n-0.2\n0.4\n0.5\n-0.4\n0.3\n-0.6\n0.2\n-0.8\n0.1\n-1\nt - sec\nx 10-3\nx 10-4\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\n0.5\n1.5\n2.5\n3.5\n4.5\n-0.5\nTs\n2Ts\n3Ts\n4Ts\n-1\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nt - sec\nx 10-3\nsinewave\nFrequency domain\noversampling\nspectrum\n0.9\n0.9\ncopied\n0.8\n0.8\n0.8\nf\nf\no\no\naround\n0.7\n0.7\n0.6\n0.6\neach comb\n0.6\nf + f\nf f\ns\no\ns\no\n2A\n0.5\n2A\n0.5\ncomb\n2A\n0.4\n\"tooth\"\n0.4\nf + f\n0.4\ns\no\nf f\ns\no\n0.3\nf\n0.3\n0.2\n\nf\ns\ns\nD-to-C\n0.2\n0.2\nonly reconstructs\n0.1\n0.1\n-1\n-0.5\n0.5\nfrequencies\n-1\n-0.5\n0.5\nff - freq\nx 104\nf/fs - freq\nx 104\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\nx 104\nHz\nf\nf\nbetween\no\no\n2 f\nf\nf\n2 f\ns\ns\ns\ns\nfs\nfs\n2 f 2\n\nNormalized frequency\nSampling: Folding\nx[n] = x(nTs ) = cos(2fonTs) = cos(onTs)\nf < f < f\ns\nˆ\n= ˆ\n2 = fT = f\nf\no\ns\n= Ts\nfˆ\n(\n)\ns\ns\n0.5 < fˆ <1\no\nx[n] = cos(2fnˆ ) = cos(nˆ)\nf = 1500 Hz\nf = 5600 Hz\nf = 8000 Hz\no\no\ns\nfo , fapparent\n0.5\n0.5\nfapparent = fs fo\nfrequencies\n= 8000 5600Hz\ndivided by\n-0.5\n-0.5\n= 2400Hz\nsampling rate\no +freq\n-1\n-1\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nx -freq\nt - sec\nx 10-3\nt - sec\nx 10-3\nK 2nd - copy\noversampling\nwaveform spectrum\nR 1st -copy\nfolding\ncopies centered\nB orig\nfˆ = f\nf\nfˆ\nBo > 2\no\ns\n1+ f\nf\n1 f\nf\n0.8\no\ns\no\ns\nf\nf\nat integer values\nG 1st +copy\n0.8\no\ns\nfˆ\nBx <\nf\nf\nf\nf\no\ns\no\ns\nof fˆ\nK 2nd +copy\n0.6\n2 + f\nf\n1+ f\nf\n1 f\nf\no\ns\no\ns\no +freq\n2A\n0.6\n2 f\nf\no\ns\no\ns\nx -freq\n0.4\n2A\n0.4\nreconstructed\n1 f\nf\no\ns\n1+ f\nf\nR -copy\no\ns\n0.2\n0 > fˆ\nGx > 2\nB orig\n0.2\nShannon Sampling\nG +copy\n2 < fˆ\nRo < 0\nTheorem\n-1.5\n-1\n-0.5\n0.5\n1.5\n-1.5\n-1\n-0.5\n0.5\n1.5\nfˆf - freq\nfˆ\nmax < 2\nfˆf - freq\nx > o\n\" flipped\"\nSampling: Aliasing\nSampling:\nf f <1.5 f\ns\no\ns\n1 fˆ <1.5\no\nf = 8700 Hz\nf = 8000 Hz\no\ns\nfo , fapparent\n0.5\nfapparent = fo fs\n= 8700 8000Hz\n-0.5\n= 800Hz\nfs\nx -freq\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\no +freq\n-1\n...\nt - sec\nx 10-3\nK 2nd - copy\naliasing\nR 1st -copy\n\noversampled\nfold\nalias\nfˆ\nBo >\nf\nf\nB orig\n1+ f\nf\n1 f\nf\no\ns\no\ns\nG 1st +copy\n0.8\nK 2nd +copy\n0.6\n2A\nfˆ\nBx <\ns\ns\n0.4\n2 f\nf\no\ns\nreconstructed\ninput frequency fo\nf\nf\no\ns\nf\nf\n2 + f\nf\n0.2\no\ns\no\ns\n0 > fˆ\nRo > 2\n1 < fˆ\nGx < 0\nfreqramp\n-1.5\n-1\n-0.5\n0.5\n1.5\nf - freq\no > x\napparent frequency\n\nVary Sample rate\nVary Sample rate\nx t( ) = cos 2( 1200t)\nx t = cos 21200t)\n( )\n(\nt = Tsn\nvar y T\nt = Tsn\nvar y T\ns\ns\nx n = cos 2 1200 T n)\n[ ]\ncos 2( 1200 T\nfolding\n[ ]\n(\ns\nx n =\nsn)\nfs=4200 Hz,\nfo=1200Hz\nfs=1900 Hz,\nfo=1200Hz\n0.5\n0.5\n-0.5\n-0.5\n-1\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\n-1\nt - sec\nx 10-3\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nt - sec\nx 10-3\nfs\n\nfs\noversampling\nfolding\n0.8\n0.8\n0.6\n0.6\n2A\n2A\n0.4\n0.4\n0.2\n0.2\n-6000\n-4000\n-2000\n-2500\n-2000\n-1500\n-1000\n-500\nfs\n\nfs\nchangerate\nf\nf/fs - freq\nf/fs - freq\nf\nSampling: Composite Signal\nSampling: Composite Signal\n1200t) + cos 2\nx t\n) + cos 2\nx t( ) = cos 2(\n(\n600t)\n( ) = cos 2( 1200t\n(\n600t)\n[ ]\n(\ns )\ns = 3800Hz\n[ ]\n(\ns )\ns =\nx n = cos 2 1200 Tsn) + cos 2( 600 T n\nf\nx n = cos 2 1200 Tsn) + cos 2( 600 T n\nf\n2200Hz\nfs=3800 Hz,\nfo=1200Hz, f1=600Hz\nfs=2200 Hz,\nfo=1200Hz, f1=600Hz\n0.5\n0.5\n-0.5\n-0.5\n-1\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\no +freq1\nt - sec\nx 10-3\no +freq1\n-1\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nx -freq1\noversampling\nx -freq1\nt - sec\nx 10-3\nd +freq2\nd +freq2\nfolding\n1200Hz folded\n+ -freq2\n0.8\n+ -freq2\n600Hz oversample\nK 2nd - copy\n0.8\nR -copy\n0.6\nR 1st - copy\nB orig\n2A\n0.4\nB orig\n0.6\nG +copy\nG 1st +copy\n0.4\n0.2\nK 2nd +copy\n0.2\n-1.5\n-1\n-0.5\n0.5\n1.5\nf/fs - freq\n-0.5\n0.5\n1.5\n-1.5\n-1\nf/fs - freq\n\nSampling: Composite Signal\nResampling\n1200t) + cos 2\nx t( ) = cos 2(\n(\n600t)\nx n[ ] = cos 2 1200 Tsn) + cos 2( 600 Ts\nf =1000Hz\n(\nn)\ns\nfs=1000 Hz,\nfo=1200Hz, f1=600Hz\n0.5\nNeighbor)\n-0.5\nno pre-blur\no +freq1\n-1\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nt - sec\nx -freq1\nx 10-3\nd +freq2\nfolding\n1200Hz folded\n+ -freq2\n600Hz fold\nK 2nd - copy\n0.8\nR 1st - copy\n0.6\nB orig\nG 1st +copy\n0.4\nK 2nd +copy\n0.2\nNeighbor)\n-1.5\n-1\n-0.5\n0.5\n1.5\nf/fs - freq\nAliased Voice Expt.\nPsychophysics\nPsychophysics:Vision\nColor Matching\nthe relationship between physical stimuli and what you perceive\nabsolute thresholds, discrimination thresholds, and scaling.\nThreshold: the point of intensity that you can just detect the presence of, or difference in, a stimulus.\nabsolute threshold -- level at which the subject is able to detect the presence of the stimulus (50%)\ndifference threshold -- the difference between two stimuli of differing intensities you can detect (50%)\nadjust one stimulus until it is perceived as the same as the other,\ndescribe the magnitude of the difference between two stimuli\ndetect a stimulus against a background.\ndiscrimination experiments --what point the difference between two stimuli is detectable.\nSchemat\nic of subject\nstanding\nin fr\nont of\nbox\nwith\nan op\ne\nn\ni\nng, light shin\ning on the\nopening and subject looking through the opening to the back of the box. The box contains a vertically-divided white screen on the rear wall, with test light illuminating one side of screen and three separate Red/Green/Blue sources illuminating the other side.\nTurn knobs for R,G, &B until combined light matches\ncolor of test light.\nhttp://en.wikipedia.org/wiki/Psychophysics\nhttp://www.ling.upenn.edu/courses/ling525/color_vision.html\nFigure by MIT OpenCourseWare. After Wandell, Foundations of Vision.\nCourtesy of Sean T. McHugh. Used with permission.\n\nPsychophysics: Vision\nPsychophysics: Vision\nUnsharp Mask\nbefore\nafter\nunsharp\nmask\nPsychophysics: Vision\nUnsharp Mask\nappear sharper.\"\nPsychophysics: Vision\nUnsharp Mask\noriginal\n+\ninvert\n+\n\"unsharp mask\"\nblur\nCourtesy of Wayne Fulton, http://www.scantips.com. Used with permission.\nBy exaggerating contrast along edges in the image, the edges stand out more, making them\n\nPsychoacoustics: Sound Masking\nYou know I can't hear you when the water is running!\nThis statement carries the essentials of the conventional wisdom about sound masking. Low-\nfrequency, broad banded sounds (like water running) will mask higher frequency sounds which\nare softer at the listener's ear (a conversational tone from across the room)\nImage removed due to copyright restrictions.\nhttp://hyperphysics.phy-astr.gsu.edu/hbase/sound/mask.html\nChirp\n+1200Hz\nBroadband white noise tends to mask all frequencies, and is approximately linear in that masking.\nBy linear you mean that if you raise the white noise by 10 dB, you have to raise everything else\n10 dB to hear it. -- http://hyperphysics.phy-astr.gsu.edu/hbase/sound/mask.html\nPsychoacoustics\nmask.m plays noise, then noise plus a sinewave of amplitude A\nand frequency f. You are supposed to determine the smallest\namplitude that you can hear the sinewave over the noise. Repeat\nthis for several values of f, and plot f vs. Amin.\nmask.m is linked in the assignments section.\nTip:\nIn mask.m change\nsound(wf,22050)\nA\n%add so you get feedback of A\n%pause\n%comment out, so you don't wait\nsound(wf+s,22050)\n>> f=1000; for A=0.01:.01:.1; mask(f,A); end\nPress cmd+. to stop when you detect sinewave.\nPsychoacoustics\nThe following MATLAB function performs a simple\npsychoacoustic test. It creates bandlimited noise, centered at 1000\nHz and also creates a sinusoid. It then plays the noise alone and\nthen the noise plus the sinusoid. Try different values of f and A to\nsee whether you can detect the sinusoid. For a particular value of\nf we'll call Amin(f) the minimum amplitude at which the\nfrequency f sinusoid could still be heard. Plot several values on\nthe graph of f vs. Amin to determine a simple masking curve.\nA typical masking experiment might proceed as follows. A\nshort, about 400 msec, pulse of a 1,000 Hz sine wave\nacts as the target, or the sound the listener is trying\nto hear. Another sound, the masker, is a band of noise\ncentered on the frequency of the target (the masker\ncould also be another pure tone). The intensity of the\nmasker is increased until the target cannot be heard\nMinimum audible sinusoid amplitude with\nnoise centered at 1000Hz (A=1)\n0.25\n0.20\n0.15\nAmin 0.10\n0.05\n0.00\nf\nf\nAmin\n0.0003\n0.00003\n0.006\n0.03\n0.19\n0.215\n0.19\n0.08\n0.074\n0.052\n0.07\n0.04\n0.014\n0.0023\n0.001\n0.0012\n0.0007\n0.0004\n0.0007"
    },
    {
      "category": "Resource",
      "title": "Recitation 6",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/4ff57516c6b8c6664992952b49d870ed_rec6.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nBalance\nSuppose you have eight billiard balls. One of them\nis defective -- it weighs more than the others.\nHow do you tell, using a balance, which ball is\ndefective in two weighings? Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nInformation Theory\nHow do you define the information a message carries?\nHow much information does a message carry? How much of a message is\nredundant?\nHow do we measure information and what are its units?\nHow do we model a transmitter of messages?\nWhat is the average rate of information a transmitter generates?\nHow much capacity does a communication channel have (with a given data\nformat and data frequency)?\nCan we remove the redundancy from a message to fill the capacity of a\nchannel? (lossless compression)\nHow much can we compress a message and still exactly recover message?\nHow does noise affect the capacity of a channel?\nCan we use redundancy to accurately recover a signal sent over a noisy\nline? (error correction)\n\nInformation Theory\nmessage1\nmessage2\nmessage3\nInformation\nsource\ntransmitter\n(encode)\nreceiver\n(decode)\ndestination\nmessage\nsignal\nmessage\nnoise\nsource\ncommunication\nchannel\n...\nOR\nsymbol1\nsymbol2\nsymbol3\n...\nAND\nmessage1=symbol1, symbol2\nmessage2=symbol3, symbol5\nInformation source selects a\nDestination decides which message\ndesired message from a set of possible messages\namong set of (agreed) possible messages,\nOR\nthe information source sent.\nselects a sequence of symbols from a set of symbols\nto represent a message.\n\nWhy are we interested in Markov Models?\nWe can represent an information source as an engine\ncreating symbols at some rate according to probabilistic\nrules. The Markov model represents those rules as\ntransition probabilities between symbols.\nA\nB\nC\n1/2\n4/5 1/5\n1/2\n2/5\n1/2\nACBBA...\n1/10\nIn the long term, each symbol has a certain\nsteady state probability.\nvss = [ 3\n27 ]\nBased on these probabilities, we can define the\namount of information, I, that a symbol carries\nand what the average rate of information or entropy,\nH, a system generates.\n\nDiscrete Markov Chain\nTransition Matrix\nA Markov system (or Markov process or Markov chain) is a system that can be in one of several\n(numbered) states, and can pass from one state to another each time step according to fixed probabilities.\nIf a Markov system is in state i, there is a fixed probability, pij, of it going into state j the next time step, and\npij is called a transition probability.\nA Markov system can be illustrated by means of a state transition diagram, which is a diagram showing\nall the states and transition probabilities.\nThe matrix P whose ijth entry is pij is called the transition matrix associated with the\nsystem. The entries in each row add up to 1. Thus, for instance, a 2 2 transition matrix P\nwould be set up as in the following figure.\nhttp://people.hofstra.edu/faculty/Stefan_Waner/RealWorld/Summary8.html\n\nDiscrete Markov Chain\n0.4\n0.2\n0.35\n0.6\n0.8\n0.5\n0.15\nArrows originating in State 1\nArrows originating in State 2\nArrows originating in State 3\nTo\n0.2\n0.4\n0.5\n0.8\n0.6\n0.35 0.15\nFrom\n\n1-step Distribution\nDistribution After 1 Step: vP\nIf v is an initial probability distribution vector and P is the transition matrix for a Markov\nsystem, then the probability vector after 1 step is the matrix product, vP.\ninitial probabilities\ntransition probabilities\ni\np(i)\nA\nB\nC\npi(j)\nj\nA\nB\nC\ni\nA 0\nB\nC\nInitial probability\nTransition matrix\nDistribution\nafter 1 step\nvector\nv = [ 9\n2 ]\n\nvP = [ 1\n2 ]\n27 ,27 ,27\nP =\n� 2\n10�\n\nn-steps Distribution\nDistribution After 1 Step: vP\nIf v is an initial probability distribution vector and P is the transition matrix for a Markov\nsystem, then the distribution vector after 1 step is the matrix product, vP.\nDistribution After 2 Steps: vP2\nThe distribution one step later, obtained by again multiplying by P, is given by\n(vP)P = vP2.\nDistribution After n Steps: vPn\nSimilarly, the distribution after n steps can be obtained by multiplying v on the right by P n\ntimes, or multiplying v by Pn.\n(vP)PP...P = vPn\nThe ijth entry in Pn is the probability that the system will pass from state i to state j in n steps.\n\nStationary\nWhat happens as number of steps n goes to infinity?\nVssP= Vss\nvss=[vx vy vz ...]\nn+1 equations\nv + v + v + . . .=1\nx\ny\nz\nn unknowns\nA steady state probability vector is then given by vss=[vx vy vz ...]\nIf the higher and higher powers of P approach a fixed matrix P, we\nrefer to P as the steady state or long-term transition matrix.\nv\nv\nv\n\nx\ny\nz\nP = vx\nvy\nvz\nvss=[vx vy vz ...]\nv\nv\nv\nx\ny\nz\n\nExamples\n0.2 0.8\nLet\nP =\n0.4\n0.6\n\nand v = [0.2 0.4 0.4] be an initial probability distribution.\n\n� 0.5 0.5\n0 �\n0.5\n0.6\n0.4\n0.8\n0.2\n0.5\n32123...\nThen the distribution after one step is given by\n0.2 0.8\nvP = [0.2 0.4 0.4]0.4\n0.6 = [0.4 0.36 0.24]\n� 0.5 0.5\n0 �\n0.2(0.2)+(0.4)(0.4)+(0.4)(0.5)=0.04+0.16+0.20=0.4\n\n(\n)\n[\n]\n[\n]\n\nThe distribution after one step is given by\n0.2 0.8\nvP = [0.2 0.4 0.4]0.4\n0.6 = [0.4 0.36 0.24]\n� 0.5 0.5\n0 �\nThe two-step distribution one step later is given by\n0.2 0.8\nvP 2 = vP P = 0.4 0.36 0.24 0.4\n0.6 = 0.344 0.44 0.216\n� 0.5 0.5\n0 �\nTo obtain the two-step transition matrix, we calculate\n0.2 0.8\n0 0.2 0.8\n0.36 0.16 0.48\nP 2 = 0.4\n0.60.4\n0.6 = 0.38 0.62\n� 0.5 0.5\n0 �� 0.5 0.5\n0 ��\n0.3\n0.4\n0.3 �\nThus, for example, the probability of going from State 3 to State 1 in two steps is given\nby the 3,1-entry in P2, namely 0.3.\n\nThe steady state distribution is given by\n0.2 0.8\nvssP = vss\n\n[vx\nvy\nvz ]0.4\n0.6 = [vx\nvy\nvz ]\n� 0.5 0.5\n0 �\nv + v + v = 1\nx\ny\nz\n0.2v + 0.4v + 0.5v = v\nx\ny\nz\nx\n0.8v + 0.5v = v\nx\nz\ny\n0.6v = v\ny\nz\nv + v + v = 1\nx\ny\nz\n0.354 0.404 0.242\nvss = [0.354 0.404 0.242]\nP = 0.354 0.404 0.242\n� 0.354 0.404 0.242�\nsteady state distribution\n\nDigram probabilities\nWhat are the relative frequencies of the combination of symbols\nij=AA,AB,AC... (digram)? What is the joint probability p(i,j)?\np(i,j)=p(i)pi(j)\ni\np(i)\nA\nB\nC\npi(j)\nj\nA\nB\nC\ni\nA 0\nB\nC\np(i,j) j\nA\nB\nC\ni\nA 0\nB\nC\np(A,A)=p(B,C)=0; AA, BC never occurs\np(B,A) occurs most often; 4/15 times\nShannon & Weaver pg.41\n\nWhy are we interested in Markov Models?\nWe can represent an information source as an engine\ncreating symbols at some rate according to probabilistic\nrules. The Markov model represents those rules as\ntransition probabilities between symbols.\nA\nB\nC\n1/2\n4/5 1/5\n1/2\n2/5\n1/2\nACBBA...\n1/10\nIn the long term, each symbol has a certain\nsteady state probability.\nvss = [ 3\n27 ]\nBased on these probabilities, we can define the\namount of information, I, that a symbol carries\nand what the average rate of information or entropy,\nH, a system generates.\n\nInformation\nWe would like to develop a usable measure of the information\nwe get from observing the occurrence of an event having\nprobability p . Our first reduction will be to ignore any\nparticular features of the event, and only observe whether or not\nit happened. In essence this means that we can think of the\nevent as the observance of a symbol whose probability of\noccurring is p. We will thus be defining the information in\nterms of the probability p.\nAn introduction to information theory and entropy-- Tom Carter\n\nInformation\nW w l o r i m a u e I t s v r l p\ne i l want u nformation e s r (p) o have e e a roperties:\n. n\nm t o s\n\nu n i y (p)\n1 I for a i n i a non-nega tive q a t t : I 0.\n2 If e e t h p o a i i y 1 w n f o o c r e c t e e\n. an v n as r b b l t , e get o information r m the c u r n e of h vent:\nI( 1 ) = 0.\n[information is surprise, freedom of choice, uncertainty...]\n3. If t w o in de pe nd en t ev e n t s oc cu r (w h o s e jo in t pr o bability is t h e pr od uc t of th ei r\np o a i i i s , t t e i w f o t e e s i\nindividual r b b l t e ) hen h nformation e get r m observing h vent s the\no t o i mat ions :\nsum f the w nfor\n- p ) = I p ) + ( h s i t e c p o e t . . )\nI(p1\n( 1 I(p2). T i s h ritical r p r y .\n4 W w nt o i for at o t a c ( n , i f c , m\n.\ne will a ur n\nm i n measure o be ontinuous a d n a t onotonic)\no p o a il t c a g s i p o a i i y s r s l s i h es\nfunction f the r b b i y (slight h n e n r b b l t hould e u t in l g t chang\ni f rma i n).\nin n o\nt o\nAn introduction to information theory and entropy-- Tom Carter\n\nInformation\nI( p ) = lo g\nb( 1 / p ) = -lo gb (p) ,\nx=yn\nlogy(x)=n\nf s m c n t n T e b b d t e u its w u i g.\nor o e positive o s a t b. h ase etermines h n e are s n\nlog2� units of I are bits\nlog2(x)=log10(x)/log10(2)\nEx. Flip a fair coin (pH=0.5, pT=0.5 )\n1 flip: H or T\nI= -log 2(p)= -log2(0.5)= log2(2)=1 bit\nn flips: HTTH...n times\nI= -log2(p p p p ...)= -log2(pn)\n= -nlog 2(p) = nlog2(1/p)= =n log2(2)\n= n bits\nAdditive property\n-log2(p1p2)= -log2(p1) -log2(p2)\nAlso think of switches\n1 switch = 1 bit (21=2 possibilities)\n3 switches = 3bits (23 =8 possibilities)\nI1and I2= I1+ I2\n\nEx. Flip an unfair coin (pH=0.3, pT=0.7 )\n1 flip: H\nI= -log2(pH)= -log2(0.3)= 1.737 bit\nless likely, more info\n1 flip: T\nmore likely, less info\nI= -log2(pT)= -log2(0.7)= 0.515 bit\n5 flips: HTTHT\nI= -log2(pH pT pT pH pT)\n= -log2(0.3-0.7 - 0.7 - 0.3 - 0.7) = -log2 (0.031)\n= 5.018 bits\n1.004 bits/flip\n5 flips: THTTT\nI= -log2(pT pH pT pT pT)\n= -log2(0.7-0.3 - 0.7 - 0.7 - 0.7) = -log2 (0.072)\n= 3.795 bits\n0.759 bits/flip\n\nEntropy\nEx. Flip an unfair coin (pH=0.3, pT=0.7 )\n1 flip:\nIH= 1.737 bits,\nIT= 0.515 bits\nSo what's the average bits/flip for n flips as n ?\nUse a weighted average based on probability of information per flip.\nCall this average information/flip, Entropy H\nH=pH IH + pTIT\n=pH [-log2(pH)] + pT[-log2(pT)]\n=0.3(1.737 bits) + 0.7(0.515 bits)\n=0.822 bits\n\n(\n)\n\nEntropy\nAverage information/symbol called Entropy H\nH = pi log pi\ni\nH(X,Y)=H(X)+H(Y)\nH also obeys additive property\nif events are independent.\nFor unfair coin, pH=p, pT=(1-p)\nThe average information per symbol is greatest when\nthe symbols equiprobable.\n\nBalance\nSuppose you have eight billiard balls. One of them\nis defective -- it weighs more than the others.\nHow do you tell, using a balance, which ball is\ndefective in two weighings? Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nWrong way\n50/50 split\nOnly allowed 2 weighings.\nWeighing #1\nHeavy\nWeighing #2\n\nHeavy\nWhich is heavier, 1 or 2? Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nWrong way\n50/50 split\nOnly allowed 2 weighings.\nWeighing #1\nHeavy\nWeighing #2\n\nHeavy\nWhich is heavier, 1 or 2? Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nWrong way\nBalance has 3 states\n50/50 split\nHeavy L, Heavy R, Equal\n50/50 split doesn't let all\n3 states be equally probable\nWeighing #1\nHeavyL\nWeighing #2\n\nHeavyL\nWhich is heavier, 1 or 2? Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nOptimal way\nCase #1\n~1/3,~1/3,~1/3 split\nNow, HL,HR,B\nAlmost equiprobable\nWeighing #1\nOnly allowed 2 weighings.\n(1,2,3) vs. (4,5,6)\nHeavyL\nWeighing #2\n1 vs 2\nHeavyL\n2 is the odd ball Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nOptimal way\nCase #1b\n~1/3,~1/3,~1/3 split\nNow, HL,HR,B\nAlmost equiprobable\nWeighing #1\nOnly allowed 2 weighings.\n(1,2,3) vs. (4,5,6)\nHeavyL\nWeighing #2\n1 vs. 2\nBalanced\n3 is the odd ball Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nOptimal way\nCase #2\n~1/3,~1/3,~1/3 split\nNow, HL,HR,B\nAlmost equiprobable\nWeighing #1\nOnly allowed 2 weighings.\n(1,2,3) vs. (4,5,6)\nHeavyR\nWeighing #2\n4 vs. 5\nHeavyR\n5 is the odd ball Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.\n\nOptimal way\nCase #3\n~1/3,~1/3,~1/3 split\nNow, HL,HR,B\nAlmost equiprobableClip art style drawing of a balance scale.\nWeighing #1\nOnly allowed 2 weighings.\n(1,2,3) vs. (4,5,6)\nBalanced\nWeighing #2\n7 vs. 8\nHeavyR\n8 is the odd ball\nFigure by MIT OpenCourseWare.\n\nOptimal way\nCase #3\n~1/3,~1/3,~1/3 split\nNow, HL,HR,B\nAlmost equiprobable\nWeighing #1\nOnly allowed 2 weighings.\n(1,2,3) vs (4,5,6)\nBalanced\nWeighing #2\n7 vs 8\nHeavy\n8 is the odd ball\nTry to design your experiments to maximize the information\nextracted from each measurement by making possible outcomes\nequally probable. Clip art style drawing of a balance scale.\nFigure by MIT OpenCourseWare.Clip art style drawing of a balance scale.\n\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nZIP implosion algorithm uses this\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nASCII 7bits/character, so 217 bits\nFrequency chart\no\n0.194\n\nH =\npi log pi\n(\n)\n\nc\n0.161\ni\nh\n0.129\nH=-(0.194 log20.194 + 0.161 log20.161 +...)\nw\n0.129\nH=2.706 bits/symbol, so 83.7 bits for sentence\nu\n0.129\nd\n0.097\nk\n0.065\nm\n0.032\no has -log20.194=2.37 bits of information\na\n0.032\nl has -log20.032= 4.97 bits of information\nl\n0.032\nThe rare letters carry more information\n\nCompression\nShannon Fano\nSplit symbols so probabilities halved\n(or as close as possible)\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nFrequency chart\no\n0.194\n0.194\nc\n0.161\n0.29\n0.161\nh\n0.129\n0.484\n0.129\nw\nu\n0.129\n0.129\n0.516\n0.258 0.129\n0.129\nd\n0.097\n0.258\n0.097\nk\n0.065\n0.161 0.065\nm\n0.032\n0.096\n0.032\na\n0.032\n0.064 0.032\nl\n0.032\n0.032\n\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nFrequency chart\no\n0.194\nc\nh\n0.161\n0.129 1\nw\nu\n0.129\n0.129 0\nd\n0.097\nk\n0.065\nm\n0.032\na\n0.032\nl\n0.032\n\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\n\"Prefix free - one code is never the start of another code\"\nFrequency chart\no\n0.194\nc\n0.161\nh\n0.129 1\nw\n0.129 0\nu\n0.129\nd\n0.097\nk\n0.065\nm\n0.032\na\n0.032\nl\n0.032\n\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nEncoding chart\np\no\nc\nh\nw\nu\nd\nk\nm\n000001 a\n000000 l\n0.194\n0.161\n0.129\n0.129\n0.129\n0.097\n0.065\n0.032\n0.032\n0.032\n#\n6(2)+5(3)+4(3)+4(3)+4(3)+\n3(3)+2(4)+1(5)+1(6)+1(6)\n=97 bits\n97bits/31 characters\n=3.129 bits/character\nH=2.706 bits/symbol\n\nCompression\nShannon Fano\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nDecoding chart\no\nc\nh\nw\nu\nd\nk\nm\n000001 a\n000000 l\nh\no w\nm u c h\nw o o d\n011110100000000010000010111111001101 36\nw o u\nl\nd\na\nw o o d c\nh u c\nk\nc\nh u c\nk\n97bits\n\nCompression\nShannon Fano\nDecoding chart\no\n52bits\nc\nh\nw\nu\nd\nk\nm\n000001 a\n000000 l\n\nCompression\nShannon Fano\na\nl\nw\nDecoding chart\no\nc\nh\nw\nu\nd\nk\nm\n000001 a\n000000 l\nk\na\nm\na\nc\nk\nd\nd\nu\n\n52bits/ 12 characters = 4.333 bits/character\ngreater than before\nbecause character\nfrequencies are different\n\nHuffman Coding\nAdd two lowest probabilities\nJPEG, MP3\ngroup symbols\nResort\nRepeat\nEx. \"How much wood would a woodchuck chuck\"\nFrequency chart\no\n0.149\no\n0.149\no\n0.149\no\n0.149\nc\n0.161\nc\n0.161\nc\n0.161\nc\n0.161\nh\n0.129\nh\n0.129\nh\n0.129\nalmk 0.161\nw\n0.129\nw\n0.129\nw\n0.129\nh\n0.129\nu\n0.129\nu\n0.129\nu\n0.129\nw\n0.129\nd\n0.097\nd\n0.097\nd\n0.097\nu\n0.129\nk\n0.065\nk\n0.065\nalm\n0.096\nd\n0.097\nm\n0.032\nal\n0.064\nk\n0.065\na\n0.032\nm\n0.032\nl\n0.032\n\nHuffman Coding\nEx. \"How much wood would a woodchuck chuck\"\n0.194\n0.161\n0.129\n0.129\n0.129\n0.097\n0.065\n0.032\n0.032\n0.032\no\n0.194\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nk\n0.065\nal\n0.064\nm\n0.032\no\n0.194\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nalm\n0.096\nk\n0.065\no\n0.194\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nalmk\n0.161\nhw\n0.258\nalmkc\n0.322\nudo\n0.420\nalmkchw 0.580\nud\n0.226\no\n0.194\nc\n0.161\nalmk\n0.161\nud\n0.226\no\no\n0.194\nc\nc\n0.161\nh\nalmk\n0.161\nw\nh\n0.129\nu\nw\n0.129\nd\nk\nm\na\nl\nalmkchwudo 1\nhw\n0.258\nalmkc\n0.322\nudo\n0.420\nud\n0.226\nhw\n0.258\no\n0.194\n\nHuffman Coding\nEx. \"How much wood would a woodchuck chuck\"\no\nc\nh\nw\nu\nd\nk\nal\nm\no\nc\nh\nw\nu\nd\nalm\nk\no\nc\nalmk\nh\nw\nu\nd\nalmkc\nhw\nalmkc\nudo\nud\no\nudo\nhw\nalmkchw 1\nud 01\no\no\nc\nc\nh\nalmk\nw\nh\nu\nw 100\nd\nk\nm\na\nl\nalmkchwudo 1\nhw\nud\no\nc\nalmk\nbackward pass\nassign codes\n\nHuffman Coding\nEx. \"How much wood would a woodchuck chuck\"\no\nc\nh\nw\nu\nd\nk\nal\nm\no\nc\nh\nw\nu\nd\nalm\nk\no\nc\nalmk\nh\nw\nu\nd\nalmkc\nhw\nud\no\nudo\nalmkc\nhw\nalmkchw\nudo\nud\no\no\nc\nc\nh\nalmk\nw\nh\nu\nw 100\nd\nk\nm\na\nl\nalmkchwudo 1\nhw\nud\no\nc\nalmk\nfind codes for single\nletters\n\nHuffman Coding\nEx. \"How much wood would a woodchuck chuck\"\nHuffman\no\n6(2)+5(3)+4(3)+4(3)+4(3)+\nShanon Fano\nc\n3(3)+2(4)+1(5)+1(6)+1(6)\no\nc\nh\nh\n=97 bits\nw\nw\nu\nu\nd\nd\nk\nk\n97bits/31 characters\nm\nm\na 110111\n=3.129 bits/character\na\nl\nl 110110\n97bits/31 characters\n=3.129 bits/character\nNotice o has 2 bits;\nH=2.706 bits/symbol\na,l have 6 bits\n\nHuffman's algorithm is a method for building an extended\nbinary tree of with a minimum weighted path length from a set\nof given weights.\nHuffman\no\nc\nh\nw\nu\nd\nk\nm 11010\na 110111\nl 110110\no\nd\n110110 l\na\nm\nk\nc\nw\nh\n\nu\nFrequencies*(edges to root)= weighted path length\n\nHuffman's algorithm is a method for building an extended\nbinary tree of with a minimum weighted path length from a set\nof given weights.\nHuffman\no\nc\nh\nw\nu\nd\nk\nm 11010\na 110111\nl 110110\no\nd\na\nm\nk\nc\nw\nh\n\nu\nl\nEach branch adds a bit. Minimize (#branches * frequency)\nLeast frequent symbol further away. More frequent, closer.\n\nMP-3\nHuffman coding is used in the final step of creating an MP3 file. The MP3 format\nuses frames of 1152 sample values. If the sample rate is 44.1kHz, the time that\neach frame represents is ~26ms. The spectrum of this 1152-sample frame is\nspectrally analyzed and the frequencies are grouped in 32 channels (critical bands).\nThe masking effects within a band are analyzed based on a psycho-acoustical\nmodel. This model determines the tone-like or noise-like nature of the masking in\neach channel and then decides the effect of each channel on its neighboring bands.\nThe masking information for all of the channels in the frame is recombined into a\ntime varying signal. This signal is numerically different from the original signal but\nthe difference is hardly noticeable aurally. The signal for the frame is then Huffman\ncoded. A sequence of these frames makes up an MP3 file.\nhttp://webphysics.davidson.edu/faculty/dmb/py115/huffman_coding.htm"
    },
    {
      "category": "Resource",
      "title": "Recitation 7",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/cabdc1fc461763602ea8c13432503e1f_rec7.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nInformation Theory\nTransition Matrix\ncommunication\nchannel\nmessage\nsignal\nInformation\nsource\ntransmitter\n(encode)\nnoise\nsource\nmessage\nmessage1\nmessage2\nmessage3\n...\nOR\nsymbol1\nsymbol2\nsymbol3\n...\nAND\nmessage1=symbol1, symbol2\nmessage2=symbol3, symbol5\nInformation source selects a\nDestination decides which message\ndesired message from a set of possible messages\namong set of (agreed) possible messages,\nOR\nthe information source sent.\nselects a sequence of symbols from a set of symbols\nto represent a message.\nreceiver\n(decode)\ndestination\nDiscrete Markov Chain\nTo\n0.2 0.8\nArrows originating in State 1\n0.4\n0.6\nFrom\nArrows originating in State 2\n0.5 0.5\nArrows originating in State 3\n0.4\n0.2\n0.5\n0.6\n0.8\n0.5\nFrom\nThe first number has a 20% chance of being 1, 40% of being 2, and 40% of being 3\nStarting from 1, the next number will be 1 (20%), 2(80%), 3 (0%)\nStarting from 2, the next number will be 1 (40%), 2( 0%), 3 (60%)\nStarting from 3, the next number will be 1 (50%), 2(50%), 3 (0%)\nTo\nv = [0.2 0.4 0.4]\n0.2 0.8\n0.2 0.8\n0.4\n0.6\nP = 0.4\n0.6\n� 0.5 0.5\n0 �\n0.5 0.5\nDigram probabilities\nWhat are the relative frequencies of the combination of symbols\nij=11,12,13... (digram) after one time step?\np(i,j)=p(i)pi(j)\ni\np(i)\n0.2\n0.4\n0.4\npi(j)\nj\ni\n0.2 0.8 0\n0.4 0\n0.6\n0.5 0.5 0\n4%\n12 16%\nAfter one step\n0%\np(i,j) j\ni\n0.04\n0.16\n0.16\n0.24\n0.2\n0.2\n21 16%\n0%\n23 24%\n31 20%\n32 20%\n0%\nmymarkovonestep.m\nWhat about in steady state?\n\nSteady State Digram probabilities\nWhat is the probability distribution in the steady state?\nWhat are the steady state relative frequencies of the combination\nVssP= Vss\nvss=[vx vy vz ...]\nof symbols ij=11,12,13,... (digram)?\nn+1 equations\nvx + vy + vz + . . .=1\nn unknowns\np(i,j)=p(i)pi(j)\nVssP= Vss\n0.2 0.8\n1 35.4%\n[vx\nvy\nvz ]0.4\n0.6 = [vx\nvy\nvz ]\n2 40.4%\n� 0.5 0.5\n0 �\n3 24.2%\ni\np(i)\n0.354\n0.404\n0.242\npi(j)\nj\ni\n0.2 0.8 0\n0.4 0\n0.6\n0.5 0.5 0\n0.2vx + 0.4vy + 0.5vz = vx\n7%\nStep in steady state\n12 28%\n0.8v + 0v + 0.5v = v\nx\ny\nz\ny\np(i,j)\nj\ni\n0.0708\n0.2832\n0.1616\n0.2424\n0.121\n0.121\n0%\n0v + 0.6v + 0v = v\nx\ny\nz\nz\n21 16%\nv + v + v =1\n0%\nx\ny\nz\n23 24%\n31 12%\n1 35.4%\n32 12%\n[vx\nvy\nvz ] = [0.354 0.404 0.242]\n2 40.4%\nmymarkov.m,\n0%\nmymarkovss.m\n3 24.2%\nmymarkovss2.m\nH=-(0.708)log2(0.708)-(0.2832)*log2(0.2832)-0-(0.1616)log2(0.1616)- (0.2424)log2(0.2424)- (0.121)log2(0.121)\nIn the homework, the initial and steady state probability distributions are the same.\n= 2.526 bits/(symbol combo)\nEntropy\nInformation Theory\nInformation\nsource\ntransmitter\n(encode)\ncommunication\nAverage information/symbol called Entropy H\nchannel\nH = pi log pi\n0/1's\n(\n)\n\nreceiver\n(decode)\ndestination\ni\nHsource(p)\nsymbols\nsymbols\nH(X,Y)=H(X)+H(Y)\nH also obeys additive property\nif events are independent.\nH is the average number of bits/symbol to represent the information. If you encode using more\nbits/symbol, then the extra bits are redundant. Compression removes the redundancy. You\nFor unfair coin, pH=p, pT=(1-p)\ncan't compress more after the redundancy is gone; all you are left with is information.\nThe entropy gives us a lower limit on the number of bits per symbol we can achieve.\n\"Quinn's interpretation\"\nWhen sending straight binary code, if some letters are more common than others, 0's and\n1's won't be equally probable in the (0/1) stream. Using encoding, we can try to make\nthe (0/1) stream have equiprobable 0's and 1's.\nShannon-Fano coding splits the symbol frequency chart 50/50, then repeats for each branch.\nEach (0/1) stream will be answering \"is the symbol you want to send in the upper branch\nor lower branch?\" and there's a (close to) equiprobable chance it will be either.\nSo, the amount of information in the (0/1) stream is increased using the compression coding\nThe average information per symbol is greatest when\nover the simple binary coding. Using more complicated compression coding, you can come\ncloser to the (0/1) stream having equiprobable 0's and 1's.\nthe symbols equiprobable.\n\nCompression\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nShannon Fano\nSplit symbols so probabilities halved\nZIP implosion algorithm uses this\n(or as close as possible)\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nASCII 7bits/character, so 217 bits\nFrequency chart\nlog pi\no\n0.194\nH =\npi\n(\n)\n\nc\n0.161\ni\nh\n0.129\nH=-(0.194 log20.194 + 0.161 log20.161 +...)\nw\n0.129\nH=2.706 bits/symbol, so 83.7 bits for sentence\nu\n0.129\nd\n0.097\nk\n0.065\nm\n0.032\no has -log20.194=2.37 bits of information\na\n0.032\nl has -log20.032= 4.97 bits of information\nl\n0.032\nThe rare letters carry more information\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nFrequency chart\no\n0.194\nc\nh\n0.161\n0.129 1\nw\nu\n0.129\n0.129 0\nd\n0.097\nk\n0.065\nm\n0.032\na\n0.032\nl\n0.032\nFrequency chart\no\n0.194\n0.194\nc\n0.161\n0.29\n0.161\nh\n0.129\n0.484\n0.129\nw\n0.129\n0.516\n0.129\n0.258\nu\n0.129\n0.129\nd\n0.097\n0.258\n0.097\nk\n0.065\n0.161 0.065\nm\n0.032\n0.096\n0.032\na\n0.032\n0.064 0.032\nl\n0.032\n0.032\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\n\"Prefix free - one code is never the start of another code\"\nFrequency chart\no\n0.194\nc\nh\n0.161\n0.129 1\nw\nu\n0.129\n0.129 0\nd\n0.097\nk\n0.065\nm\n0.032\na\n0.032\nl\n0.032\n\nCompression\nShannon Fano\nSplit symbols so probabilities halved\nEx. \"How much wood would a woodchuck chuck\"\n31 characters\nEncoding chart\np\no\n0.194\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nk\n0.065\nm\n0.032\n000001 a\n0.032\n000000 l\n0.032\n#\n6(2)+5(3)+4(3)+4(3)+4(3)+\n3(3)+2(4)+1(5)+1(6)+1(6)\n=97 bits\n97bits/31 characters\n=3.129 bits/character\nH=2.706 bits/symbol\nHuffman Coding\nAdd two lowest probabilities\ngroup symbols\nResort\nRepeat\nFrequency chart\no\n0.149\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nk\n0.065\nm\n0.032\na\n0.032\nl\n0.032\nEx. \"How much wood would a woodchuck chuck\"\no\n0.149\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nalm\n0.096\nk\n0.065\no\n0.149\nc\n0.161\nalmk 0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nHuffman Coding\no\n0.149\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nk\n0.065\nal\n0.064\nm\n0.032\nHuffman Coding\nEx. \"How much wood would a woodchuck chuck\"\n0.194\n0.161\n0.129\n0.129\n0.129\n0.097\n0.065\n0.032\n0.032\n0.032\no\n0.194\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nk\n0.065\nal\n0.064\nm\n0.032\no\n0.194\nc\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nalm\n0.096\nk\n0.065\no\n0.194\nc\n0.161\nalmk\n0.161\nh\n0.129\nw\n0.129\nu\n0.129\nd\n0.097\nud\n0.226\no\n0.194\nc\n0.161\nalmk\n0.161\nh\n0.129\nw\n0.129\nhw\n0.258\nud\n0.226\no\n0.194\nc\n0.161\nalmk\n0.161\nalmkc\n0.322\nhw\n0.258\nud\n0.226\no\n0.194\nudo\n0.420\nalmkc\n0.322\nhw\n0.258\nalmkchw 0.580\nudo\n0.420\nalmkchwudo 1\no\nc\nh\nw\nu\nd\nk\nm\na\nl\nEx. \"How much wood would a woodchuck chuck\"\no\nc\nh\nw\nu\nd\nk\nm\na\nl\no\nc\nh\nw\nu\nd\nk\nal\nm\no\nc\nh\nw\nu\nd\nalm\nk\no\nc\nalmk\nh\nw\nu\nd\nud\no\nc\nalmk\nh\nw\nhw\nud\no\nc\nalmk\nalmkc\nhw\nud\no\nudo\nalmkc\nhw\nalmkchw\nudo\nalmkchwudo\n\nHuffman Coding\nHuffman Coding\no\nc\nh\nw\nu\nd\nk\nm\na\nl\no\nc\nh\nw\nu\nd\nk\nal\nm\no\nc\nh\nw\nu\nd\nalm\nk\no\nc\nalmk\nh\nw\nu\nd\nud\no\nc\nalmk\nh\nw\nhw\nud\no\nc\nalmk\nalmkc\nhw\nud\no\nudo\nalmkc\nhw\nalmkchw\nudo\nalmkchwudo\nEx. \"How much wood would a woodchuck chuck\"\nEx. \"How much wood would a woodchuck chuck\"\nHuffman\no\n6(2)+5(3)+4(3)+4(3)+4(3)+\nShanon Fano\no\nc\n3(3)+2(4)+1(5)+1(6)+1(6)\nc\nh\n=97 bits\nh\nw\nw\nu\nu\nd\nd\nk\nk\nm 11010\n97bits/31 characters\nm\na 110111\n=3.129 bits/character\n000001 a\n000000 l\nl 110110\n97bits/31 characters\n=3.129 bits/character\nNotice o has 2 bits;\nH=2.706 bits/symbol\na,l have 6 bits\nHuffman's algorithmis a method for building an extended\nHuffman's algorithm is a method for building an extended\nbinary tree of with a minimum weighted path length from a\nbinary tree of with a minimum weighted path length from a\nset of given weights.\nset of given weights.\nHuffman\nHuffman\no\no\nc\nc\nh\nh\nw\nw\nu\nu\nd\nd\nk\nk\nm 11010\nm 11010\na 110111\na 110111\nl 110110\nl 110110\no\nd\nk\nc\no\nd\nu\na\nm\nk\nc\nw\nh\n\nu\nl\na\nm\nw\nh\nl\nEach branch adds a bit. Minimize (#branches * frequency)\nFrequencies*(edges to root)= weighted path length\nLeast frequent symbol further away. More frequency, closer.\n\nHuffman\nHuffman coding is used in the final step of creating an MP3 file. The MP3 format\nuses frames of 1152 sample values. If the sample rate is 44.1kHz, the time that\neach frame represents is ~26ms. The spectrum of this 1152-sample frame is\nspectrally analyzed and the frequencies are grouped in 32 channels (critical bands).\nThe masking effects within a band are analyzed based on a psycho-acoustical\nmodel. This model determines the tone-like or noise-like nature of the masking in\neach channel and then decides the effect of each channel on its neighboring bands.\nThe masking information for all of the channels in the frame is recombined into a\ntime varying signal. This signal is numerically different from the original signal but\nthe difference is hardly noticeable aurally. The signal for the frame is then Huffman\ncoded. A sequence of these frames makes up an MP3 file.\nhttp://webphysics.davidson.edu/faculty/dmb/py115/huffman_coding.htm\nNoisy Channel\nA binary communication system contains a pair of error-prone wireless channels,\nas shown below.\n1/6\n1/12\nsender1\nreceiver1/\nreceiver2\nsender2\nerror rate\nerror rate\nAssume that in each channel it is equally likely that a 0 will be turned into a 1 or that a 1\ninto a 0. Assume also that in the first channel the probability of an error in any particular\nbit is 1/6, and in the second channel it is 1/12.\nCompute the four probabilities:\n- 0 sent 0 received\n- 0 sent 1 received\n- 1 sent 0 received\n- 1 sent 1 received\nInformation Theory\nmessage\ncommunication\nchannel,\ncapacity C\nInformation\nsource\ntransmitter\n(encode)\nsignal\nnoise\nsource\nreceiver\n(decode)\ndestination\nH(p)\nnoise\nmessage\nsymbol1, p(1)\nsymbol1 -> 0\nsymbol2, p(2)\nsymbol2 -> 1\n0 + noise= ?? -> symbol?\n1 + noise= ?? -> symbol?\nsend+noise\nHy(x)\nsent noise\nreceived flipped?\nno\n\n0 -> no flipped bit p('not flip')\nno\n1 -> flipped bit\np('flip') = 1 - p('not flip')\nyes\n\nyes\n\nHy(x) max when\np('not flip') = p('flip')=1/2\nequivocation: 'confusion in received signal' or 'spurious information in noise'\nHy(x) min when\nentropy of noise source.\np('not flip') =1, p('flip')=0\nOR\nH (x) = - p('not flip') log2(p('not flip')) - p('flip') log2(p('flip'))\ny\np('not flip') =0, p('flip')=1\nR= H(x) - Hy(x)\nActual info transmission rate is the info source entropy minus the noise source entropy\nC = max{R} over all possible information sources\nC >H(x) then you can encode to get errors (error correction codes -> use redundancy)\n1/6\n1/12\nsender1\nreceiver1/\nreceiver2\nsender2\nerror rate\nerror rate\n11/12\n5/6\n1/12\n1/12\n1/6\n11/12\nChannel symmetric\nSo p(0->0)= p(1->1), etc.\n11/12\n1/6\n1/12\n5/6\n1 1/12\nCompute the four probabilities:\n11/12\n- 0 sent 0 received: 000, 010\n- 0 sent 1 received: 001, 011\n- 1 sent 0 received: 100, 110\n- 1 sent 1 received: 101, 111\n\nsender1\n1/6\nreceiver1/\n1/12\nerror rate\nsender2\nerror rate\nreceiver2\nsender1\np(000) = p1(0->0)*p2(0->0)\n11/12\np(001) = p1(0->0)*p2(0->1)\n5/6\n1/12\n1/12\np(010) = p1(0->1)*p2(1->0)\n1/6\np(011) = p1(0->1)*p2(1->1)\n11/12\nChannel symmetric\nSo p(0->0)= p(1->1), etc.\n11/12\np(100) = p1(1->0)*p2(0->0)\n1/6\np(101) = p1(1->0)*p2(0->1)\n1/12\n5/6\n1 1/12\np(110) = p1(1->1)*p2(1->0)\np(111) = p1(1->1)*p2(1->1)\n11/12\nCompute the four probabilities:\n- 0 sent 0 received: p(000)+p(010)\n- 0 sent 1 received: p(001)+p(011)\n- 1 sent 0 received: p(100)+p(110)\n- 1 sent 1 received: p(101)+p(111)\nError Correction: Repeat Code\nA binary communication system contains a pair of error-prone wireless channels,\nas shown below.\n1/6\n1/12\nsender1\nreceiver1/\nsender2\nerror rate\nerror rate\nRepeat code: a 0 is transmitted as three successive 0's and a 1 as three successive\n1's. At the decoder, a majority decision rule is used: if a group of three bits has\nmore 0's than 1's (e.g. 000, 001, 010, 100), it's assumed that a 0 was meant, and if\nmore 1's than 0's that a 1 was meant.\nIf the original source message has an equal likelihood of 1's and 0's, what is the\nprobability that a decoded bit will be incorrect?\nreceiver2\nsender1\n1/12\n1/6\nreceiver1/\nreceiver2\nerror rate\nsender2\nerror rate\np(000): (5/6)*(11/12)= 55/72\n11/12\np(001): (5/6)*(1/12) = 5/72\n5/6\n1/12\n1/12\np(010): (1/6)*(1/12)= 1/72\n1/6\np(011): (1/6)*(11/12) = 11/72\n11/12\nChannel symmetric\nSo p(0->0)= p(1->1), etc.\n11/12\np(100): (1/6)*(11/12)= 11/72\np(101): (1/6)*(1/12) = 1/72\n1/12\n1/6\n5/6\n1 1/12\np(110): (5/6)*(1/12)= 5/72\np(111): (5/6)*(11/12) = 55/72\n11/12\nCompute the four probabilities:\n- 0 sent 0 received: p(000)+p(010)= 55/72 +1/72= 56/72 0.778\n- 0 sent 1 received: p(001)+p(011)= 5/72 + 11/72 = 16/72 0.222\n- 1 sent 0 received: p(100)+p(110)= 11/72 + 5/72 = 16/72 0.222\nmyflipsim.m\n- 1 sent 1 received: p(101)+p(111)=1/72 + 55/72 = 56/72 0.778\nError Correction: Repeat Code\nA binary communication system contains a pair of error-prone wireless channels,\nas shown below.\n- 0 sent 0 received: 0.778\n1/6\nreceiver1/\n1/12\n- 0 sent 1 received: 0.222\nreceiver2\n- 1 sent 0 received: 0.222\nsender2\nerror rate\nerror rate\n- 1 sent 1 received: 0.778\nRepeat code: a 0 is transmitted as three successive 0's and a 1 as three successive\n1's. At the decoder, a majority decision rule is used. What is the probability that a\ndecoded bit will be incorrect?\nbits\nsend\nsender1 receiver2\ndecision flipped\np\n0 bits flipped\n0.778* 0.778 * 0.778 =0.471\n1 bits flipped\n0.222*0. 778 *0. 778 =0.134\n2 bits flipped\n0.222 * 0.222 *0. 778 = 0.038\n3 bits flipped\n0.222 * 0.222 * 0.222 = 0.011\nmyflipsim2.m\n\nError Correction: Repeat Code\nA binary communication system contains a pair of error-prone wireless channels,\nas shown below.\n- 0 sent 0 received: 0.778\nsender1\n1/6\nreceiver1/\nsender2\n1/12\nreceiver2\n- 0 sent 1 received: 0.222\n- 1 sent 0 received: 0.222\nerror rate\nerror rate\n- 1 sent 1 received: 0.778\nRepeat code: a 0 is transmitted as three successive 0's and a 1 as three successive\n1's. At the decoder, a majority decision rule is used. What is the probability that a\ndecoded bit will be incorrect?\nbits\nsender1 receiver2\ndecision flipped\nsend\np\ndecoded bit incorrect\n0.471\n0.134\n011, 101, 110, 111\n0.134\n0.0308\n0.0308+0.0308+0.0308+0.011=0.126\n0.134\n0.0308\n0.0308\n12.6% chance decoded bit will be incorrect\n0.011\nCheck using Matlab simulation\nCompression\nCompression\nYou are given a data file that has been compressed to a length of 100,000 bits,\nand told that it is result of running an \"ideal\" entropy coder on a sequence of\ndata. You are also told that the original data are samples of a continuous\nwaveform, quantized to two bits per sample. The probabilities of the\nuncompressed values are\ns\np(s) s p(s)\n00 1/2 10 1/16\n01 3/8 11 1/16\nWhat (approximately) was the length of the uncompressed file, in bits?\ncompressed file\nuncompressed file\nH=-(0.5 log20.5 )- ... = h bits/sample\n2 bits/sample\n100,000 bits\nx bits\nx bits\n2 bits / sample\n=\n100000 bits\nh bits / sample\nError Correction: Hamming Code (7,4)\n(2m-1,2m-m-1), m=3\nThe number of (two-bit) samples in the uncompressed file is half the value you\ncomputed in part a). You are told that the continuous waveform was sampled at\nthe minimum possible rate such that the waveform could be reconstructed\nexactly from the samples (at least before they were quantized), and you are told\nthat the file represents 10 seconds of data. What is the highest frequency present\nin the continuous signal?\nuncompressed file\np(s) s p(s)\n2 bits/sample\ns\n00 1/2 10 1/16\nx bits\n01 3/8 11 1/16\nCompute number of samples\ny sample = x bits / (2 bits/sample)\nCompute sampling rate\nsampling rate = y samples / t seconds\nUse Shannon Sampling Theorem\nMax frequency (Nyquist rate) = sampling rate/2\nr\nin\na\nH\na0\na1\na2\na3\n\na0\na1\na2\na3\n\n�\n\n�\n\na4\na5\n\ncolumns are\nbinary digits\nvalid codes satisfy\nr\nHa = 0\na0\na1\n0001111a2\n0110011a3 = 0\n� 1010101�a4\na5\na6\na3+a4+a5+a6=0\na2+a3+a5+a6=0\na0+a2+a4+a6=0\n� a6 �\nfrom 1 to 2m-1\nH tests if a is a valid code\nsolve system of equations for remaining\nuse modulo-2 math\nbits a4, a5, a6 to make valid code\n\nError Correction: Hamming Code (7,4)\nError Correction: Hamming Code (7,4)\nr\nr\nr\nr a\nasend\nar'cvd\nin\na\nvalid codes satisfy\na2\na0 = a2 + a4 + a6\nH\nin\nvalid code if\na = 0\na4\na1 = a2 + a5 + a6\n\nr\na0\n\na0\na5\n\na2\n\na\na1\na3=a4+a5+a6\na6\na3 = a4 + a5 + a6\nnoisy\n1=0+1+0\na2\n\na4\n\na1=a2+a5+a6\n� a3\n= 0\na3\n0=1+1+0\na5\na4\n� 1010101�\na0=a2+a4+a6\n�\na6\n�\n1=1+0+0\na5\na6\n� 0��\n0�\n� 0\nr\nmake a\neasier to solve for remaining\na valid code\nsender\nreceiver\nbits to make a valid code if\na3=a4+a5+a6\na3+a4+a5+a6=0\nusing this layout.\na1=a2+a5+a6\na1+a2+a5+a6=0\na0=a2+a4+a6\na0+a2+a4+a6=0\nuse\nmodulo-2 math\nError Correction: Hamming Code (7,4)\nr\na 0\nso there is an error\ncorrect for 1 bit\nerrors\n\nout\n1 noisy\n\n=\n=\n\na2\n\na4\n\n� 1010101�0\n� 1��\n1�\n\n=\nr\n\nr\nH\nasend\nHamming (7,4) can\nar'cvd\na5\na6\nsame as\nin. Bit flip\ncorrected\nmod2\n� 0��\n0�\n� 0�\nsender\nreceiver\nsame as 3rd column, therefore\nerror in the 3rd position"
    },
    {
      "category": "Resource",
      "title": "Recitation 8",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/ee27328f66c3c7c063eaa392474bca76_rec8.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n-2\n-1\nTextEnd\nCausal FIR filter\n3 point average\ncausal running average or backward average\nM\ny n =\nbkx n k\n[ ]\n[\n]\nM\nk= 0\ny n =\nkx n k]\n[ ]\nb [\nk= 0\n[ ]\nb\n1x n 1\nK + b\n[\ny n =\n0 x n[ ] + b [\n] +\nM x n M]\nb0 =\nb1 =\nb2 =\nThe output y at each sample n is a weighted sum of the\npresent input, x[n], and past inputs, x[n-1], x[n-2],..., x[n-M].\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\ndifference equation\nL=3\nM=L-1=2\nLength 3 2nd order\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\nx n ={0 0 1.11 1.16 1.01 1.12 1.01 1.08 0 0}\n3 point average\n[ ]\nn= -2 -1\ny n =\n[ ] + x n 1] + x n 2]\n[ ] = x 0 +\n[\n] + x 2 = 1.11+ 0 + 0 = 0.36\n[ ]\nx n\n[\n[\ny 0\n[ ]\nx 1\n[\n]\nx n ={0 0 1.11 1.16 1.01 1.12 1.01 1.08 0 0}\n[ ]\nsliding window\nx[n]\nn=-2 -1\n6 7\n1.4\n1.2\n0.8\nTextEnd\ny[n]\nb\nx[n]\n0.5\n1.5\nn\n0.5\nTextEnd\nb0\nb1\nb2\n0.6\n-2\n-1\n0.4\n0.5TextEnd\nb0x[0]\n0.2\n-2\n-1\n-2\n-1\nn\nn\nrunning onto data\n\n-1\nn\nn\ny n = x n + x n 1 + x n 2\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\n[ ]\n[\n]\n[\n]\nx n = 0 0 1.11 1.16 1.01 1.12 1.01 1.08 0 0\nx n = 0\n1.11 1.16 1.01 1.12 1.01 1.08 0 0\n[ ]\n{\n}\n[ ]\n{\n}\nn= -2 -1\nn= -2 -1\ny 1 = x 1 + x 0 + x 1 = 1.16 + 1.11+ 0 = 0.76\ny 2 = x 2 + x 1 + x 0 = 1.01+ 1.16 + 1.11 =1.09\n[ ]\n[ ]\n[ ]\n[\n]\n[ ]\n[ ]\n[ ]\n[ ]\n1.5\n-2\n-1\n-2\n-1\nTextEnd\n0.5\nTextEnd\nb2\nb0\nb1\n1.5\n-2\n-2\n-1\nn\nn\nTextEnd\n0.5\nTextEnd\ny[n]\nb\nx[n]\ny[n]\nb\nx[n]\n0.5\n0.5\n0.5TextEnd\nb0x[0]\nb0x[1]+b1x[0]\n0.5TextEnd\n-2\n-1\n-2\n-1\nn\nn\nweighted sum\ny n = x n + x n 1 + x n 2\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\n[ ]\n[\n]\n[\n]\nx n ={0\n1.11 1.16 1.01 1.12 1.01 1.08 0 0}\nx n ={0\n1.11 1.16 1.01 1.12 1.01 1.08 0 0}\nn= -2 -1\nn= -2 -1\n[ ]\n[ ]\ny 3 = x 3 + x 2 + x 1 = 1.12 + 1.01+ 1.16 =1.10\ny 4 = x 4 + x 3 + x 2 = 1.01+ 1.12 + 1.01 =1.05\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n1.5\n-2\n-1\n-2\n-1\nTextEnd\n0.5\nTextEnd\n1.5\n-2\n-1\n-2\n-1\nTextEnd\n0.5\nTextEnd\ny[n]\nb\nx[n]\ny[n]\nb\nx[n]\n0.5\n0.5\n1.5\n0.5TextEnd\nTextEnd\n0.5\n-2\n-1\n-2\n-1\nn\nn\n\ny n = x n + x n 1 + x n 2\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\n[ ]\n[\n]\n[\n]\nx n = 0\n1.11 1.16 1.01 1.12 1.01 1.08 0\n\nx n = 0\n1.11 1.16 1.01 1.12 1.01 1.08 0 0\n[ ]\n{\n}\n[ ]\n{\n}\nn= -2 -1\ny 5 = x 5 + x 4 + x 3 = 1.08 + 1.01+ 1.12 =1.07\ny 6 = x 6 + x 5 + x 4 = 0 + 1.08 + 1.01 = 0.70\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n1.5\n-2\n-1\n-2\n-1\n-2\n-1\nTextEnd\n0.5\nTextEnd\n1.5\n-2\n-1\nn\nn\nTextEnd\n0.5\nTextEnd\ny[n]\nb\nx[n]\n0.5\n0.5\ny[n]\nb\nx[n]\n1.5\n1.5\nTextEnd\nTextEnd\n0.5\n0.5\n-2\n-1\n-2\n-1\nn\nn\nrunning off data\ny n = x n + x n 1 + x n 2\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\n[ ]\n[\n]\n[\n]\nx n ={0\n1.11 1.16 1.01 1.12 1.01 1.08 0 0}\nx n ={0 0 1.11 1.16 1.01 1.12 1.01 1.08 0.0 0.0}\n[ ]\n[ ]\nn= -2 -1\ny n ={0 0 0.36 0.75 1.09 1.10 1.05 1.07 0.7 0.36}\n[ ]\nn= -2 -1\ny 7 = x 7 + x 6 + x 5 = 0 + 0 + 1.08 = 0.36\n[ ]\n[ ]\n[ ]\n[ ]\nsliding window\n1.5\n-2\n-1\n-2\n-1\nTextEnd\n0.5\nTextEnd\n1.5\n-2\n-1\nn\n-2\n-1\nn\nTextEnd\n0.5\nTextEnd\ny[n]\nb\nx[n]\n0.5\n0.5\ny[n]\nb\nx[n]\n1.5\nTextEnd\n1.5\nTextEnd\nNotice:\ny[n] is longer than x[n].\nx[n] is M/2 delayed\n0.5\n0.5\n-2\n-1\n-2\n-1\nn\nn\nrunning off data\nrunning onto data\nweighted sum\nrunning off data\n\n[ ]\n\n[\n]\n2 point difference\n2 point difference\ny n = x n x n 1\ny n = x n x n 1\n[ ]\n[ ]\n[\n]\n[ ]\n[ ]\n[\n]\n1 n 0\n1 n 0\n=\nu n[ ]\nu n[ ] = 0 n < 0\nx n[ ]\nn\n=\nu n[ ]\nu n[ ] = 0 n < 0\nn\nx n[ ]\n0.4\nTextEnd\nTextEnd\n/16\nTextEnd\nunit step function\nunit step function\n0.8\n0.9\n0.6\n0.5TextEnd\n0.8\n0.7\n0.2\n0.6\n-2\n-1\nu[n]\nn\nx[n]\nTextEnd\n0.4\n0.3\n0.8\n0.6\n0.2\n0.4\n0.1\n0.2\n-2\n-1\n-2\n-1\nn\nn\ny n = x n x n 1\n[ ]\n[ ]\n[\n]\nfinite difference\nImpulse response\nn\napproximation to\nx n =\nu n\nM\n[ ]\n[ ]\na derivative.\ny n =bkx n k\nFIR filter\n[ ]\n[\n]\nk= 0\nx n = 0\n[ ]\n{\n16}\nn = 0\nderivatives enhance\nx n =\n[ ]\n[n] =\nKronecker delta function\n2n 1 u n 1\nnoise (and high frequencies)\n[\n]\n0 otherwise\n={0\ny n[ ]\n} =\n0.4TextEnd\nk= 0\n0.2\n-2\n-1\nimpulse response\nn\n0.5\n0.4\n0.3\n0.2TextEnd\n0.8\nM\nn = k\n0.6\ny n = h[n] =\nbk n k\n[n k] =\ny[n]\nx[n]\n0 otherwise\nThe impulse response is the output of the system when\nthe input is a delta function.\n0.1\n-2\n-1\nn\n\n-2\n-1\n-2\n-1\n-1\n-1\n\nImpulse response\nImpulse response of 3 pt. average\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\n0 otherwise\nn = 0\nM\nn = k\n=\nx n = [n] =\n[ ]\nDelta function\nh[n] = y n =\nn k\n[n k]\n[ ] bk [\n]\nk= 0\n0 otherwise\ny n =\nn +\nn 1 +\nn 2\nk = n\n[ ]\n[ ]\n[\n]\n[\n]\nk = 0\nh[n] = b0[n 0] + b1[n 1] +K + b [n n] +K + bM[M 1]\nn\n0.5\n0.5\nb0\nb1\nb2\nb0\n=\n+\n+K + b 0 +\nM 1\nb0[n 0]\nb1[n 1]\n[ ]\nK + bM [\n]\nn\nx[n]\ny 0 =\n0 + 1 + 2\n[ ]\n[ ]\n[\n]\n[\n]\n= b00 + b10 +K + bn1+K + bM 0\nz = 0\n[z] =\n0 otherwise\n= bn\nimpulse response\n1+ 0 + 0 =\nb\n= 3\nThe impulse response is just the filter coefficients.\n0.5\nFinite length filter, finite impulse response (FIR).\ny[n]\n-2\n-1\nImpulse response of 3 pt. average\nImpulse response of 3 pt. average\ny n = x n + x n 1 + x n 2\ny n = x n + x n 1 + x n 2\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\n[ ]\n[\n]\n[\n]\nn = 0\nDelta function\nx n[ ] = [n] = 1\nn = 0\nDelta function\nx n[ ] = [n] = 0 otherwise\notherwise\ny n =\nn +\nn 1 +\nn 2\ny n =\nn +\nn 1 +\nn 2\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\n[ ]\n[\n]\n[\n]\n-2\n-2\n0.5\nTextEnd\nTextEnd\nb2\nb0\nb1\nb0\nb1\n0.5\n0.5\nx[n]\nx[n]\n-2\n-1\n-2\n-1\n0.5\nTextEnd\nTextEnd\nb2\nb\nb0\nb1\nb0\nb1\nb2\n[ ]\n[ ]\n[ ]\n[\n]\n\n[ ]\n[ ]\n[ ]\ny 1\ny 2\n0[ ]\n+\n+\n+\n+\n=\n=\n0 + 1+ 0 =\n0 + 0 +\nb\ny[n]\ny[n]\nb\nb\n=\n=\n=\ny[n]\nb\ny[n]\n0.5\n-2\n-1\n-2\n-1\nn\nn\n0.5\n\nImpulse response of 3 pt. average\nImpulse response of 3 pt. average\nn = 2 1\ny n =\n[ ] + x n 1] + x n 2]\n[ ]\nx n\n[\n[\n[ ]\n[ ]\n{\n}\nx n = n = 0\n\nn = 0\nx n[ ] = [n] =\nDelta function\nh[n] = y n\nx[n]= [n] ={0\n0}\n={0\nb0\nb1 b2\n0}\n0 otherwise\n[ ]\ny n =\nn +\nn 1 +\nn 2\n[ ]\n[ ]\n[\n]\n[\n]\n-2\n-1\n-2\n-1\n0.5\nTextEnd\nTextEnd\nb0\nb1\nb2\nb2\nb0\nb1\nTextEnd\n0.8\n0.5\nx[n]\n0.6\n0.4\n[ ]\n1 [ ]\n1 [ ]\n1 [ ]\nx[n]\ny[n]\nx[n]\ny 3\n+\n+\n=\n0.2\n0 + 0 + 0 = 0\nb\n-2\n-1\n=\ny[n]\nb\n0.2\n-2\n-1\nTextEnd\nb0\nb1\nb2\nn\n-2\n-1\nn\nCoefficients from impulse response\nCoefficients from impulse response\nM\nM\n[ ]\n[ ]\ny n =\nkx n k]\nh[n] = y n\n[ ]\n[ ]\ny n =\nkx n k]\nh[n] = y n\n[ ]\nb [\n[ ]\n[ ]\nb [\n[ ]\nx[n]= [n]\nx n = n\nx[n]= [ n]\nx n = n\nk= 0\nk= 0\n={0 0 1 0 0 0 0}\nb0,b1,KbM = ???\n={0\n0}\n={0 0 1 0 0 0 0}\n{b0,b1,b2} ={ 4\n8, 8\n2, 1\n8}\n={0\n0}\nn = 2 1\nn = 2 1\n={0\nb0\nb1 b2\n0}\n0.4TextEnd\n0.8\n0.8\n0.6\n0.6\n0.4TextEnd\n0.8\n0.6\ny[n]\ny[n]\n0.4\n0.5\nx[n]\nx[n]\nh[n]\nx[n]\nh[n]\nx[n]\n0.2\n0.2\n-2\n-1\n-2\n-1\nTextEnd\n0.8\n0.8\nTextEnd\nb0\nb1\nb2\n0.6\nh[n]\nh[n]\n0.4\n0.2\n0.2\n-2\n-1\n-2\n-1\nn\nn\n0.4\n0.6\n\n[ ] [ ] [\n]\n\n[ ]\n[\n]\n[ ] [ ] [\n]\nResponse from 2 impulses\nResponse from 2 impulses\nx[n]\nM\nM\ny n =\ny n[ ] =bkx n[ k]\ny n[ ] =\ny n[ ] =bkx n[ k]\n[ ]\nx n = n +0.5[n 2\nx n = n\n[ ]\n[ ]\n]\n[ ]\n[ ]\nk= 0\nk= 0\n={0\n0 1 0\n0.5\n\n}\n{b0,b1,b2} ={ 4\n8, 2\n8, 1\n8}\n{0\n8 + 16\n1 }\n={0 0 1 0 1 0 0} h[n] ={b0,b1,b2} ={ 4\n8, 2\n8, 1\n8}\n{0\n8 + 16\n1 }\nn = 2 1\nn = 2 1\ny n = 0\nb0 x 0\n1x 0\n2 x 0 +b0 x 2\n1x 3\n2 x 4\ny n = 0\nh 0 x[ ]\nh 1 x[ ]\nh 2 x[ ]\n0 + h 0 x[ ]\nh 1 x[ ]3\nh 2 x[ ]\n4 }\n[ ] {\n[ ] b [ ] b [ ]\n[ ] b [ ] b [ ]}\n[ ] {\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\nTextEnd\nTextEnd\ny 2 = h 0 x 2 0 +\n[ ]\n[ ] [\n]\n0.8\n0.8\nx[n]\nx[n]\nx[n]\nh 1 x 2 1]\n[ ] [\n0.6\n0.6\n+\n0.4\n0.4\nh 2 x 2 2\n[ ] [\n]\n0.2\n0.2\n-2\n-1\n-2\n-1\ny n =\nh k x n k\n0.8\n0.8\nk= 0\n0.6\ny[n]\nSum the responses of\ny[n]\n0.6\nConvolution sum\n0.4\n0.4\n0.2\n0.2\neach impulse\n-2\n-1\n-2\n-1\nn\n1 n 0\n0 n < 0\nConvolution\nx n[ ] =\nu n\n[ ]\n[ ]\nu n =\nx n = 0\n16}\n[ ]\n{\nn = 2 1 0\nM\ny n =\nbkx n k\nFIR filter\nTextEnd\nk= 0\n0.9\nbn\nn = 0,1K M\n0.8\nh[n] = y n[ ]\nimpulse response\n=\n[n]= [n]\notherwise\nx\n0.7\n0.6\n0.5\nx[n]\n0.4\nM\n0.3\n0.2\ny n =\nh k x n k\nconvolution sum\n0.1\nk= 0\n-2\n-1\nn\nor\ny n = h * x\n[ ]\n[ ]\n[ ] + 1\n[\n] + 4\n[\n] + 9\n[\n] + 16\n[\n]\nx n = 0 n\nn 1\nn 2\nn 3\nn 4\nThe output y[n] is equal to the input x[n] convolved with\nAny discrete signal be thought of a weighted sum of delayed impulses\nthe unit impulse response h[n].\n\nn\n0.5\nn 2\nx n = 0\n\nh[n] ={ 4\n8}\nx n =\nu n\nM\n[ ]\n{\n}\n[ ]\n[ ]\ny n[ ]\ny n =h k x n k\n=\n[ ]\n[ ] [\n]\n(1/16)*d[n-1]\n1/16*d[n-1]*h[n]\nk= 0\nx n = 0\n[ ]\n{\n}\nn = 0\nh[n] ={ 4\n1}\n0.5\n0.5TextEnd\n0.5TextEnd\n4/16*d[n-2]\n4/16*d[n-2]*h[n]\n0.9\n0.9\n0.8\n0.8\n0.7\n0.7\n0.5\n0.5\n0.6\n0.6\nx[n]\nh[n]\n0.4\n0.4\n0.3\n0.3\n9/16*d[n-3]\n9/16*d[n-3]*h[n]\n0.2\n0.2\n0.1\n0.1\n-2\n-1\n-2\n-1\n0.5\n0.5\nn\nn\n[ ]\n[ ]\n[ ]\n2 1*d[n-4] 4\n21*d[n-4]*h[n]4\nx n\n*\nh n\n=\ny n\nx[n]=0*d[n]+1/16*d[n-1]\ny[n]=0*d[n]*h[n]+1/16*d[n-1]*h[n]\n+4/16*d[n-2]+9/16*d[n-3]+16/16*d[n-4]\n+4/16*d[n-2]*h[n]+9/16*d[n-3]*h[n]+16/16*d[n-4]*h[n]\n0.5\n0.5\n0.5TextEnd\n0.5\nx[n]\nx n = 0\n\nh[n] ={ 4\n8}\nx n = 0\n\nh[n] ={ 4\n8}\n[ ]\n{\n}\n[ ]\n{\n}\nn = 0\nn = 0\n4/8\n2/8\n1/8\n1/16\n4/8\n2/8\n1/8\nx[n]\nh[n]\n1/16\n4/16\n9/16\n16/16\nx[n]\n4/16\n9/16\n16/16\nh[n]\n===============================================\n===============================================\n4/128\n2/128\n1/128\n===============================================\n===============================================\n\nx n[ ] = 0\n{\n}\nh[n] =\nn = 0\n{\n}\nx[n] 0\n1/16\n4/16\n9/16\n16/16\nh[n] 4/8 2/8 1/8\n===============================================\n0 0 0\n4/128 2/128 1/128\n16/128 8/128 4/128\n===============================================\nx n[ ] = 0\n{\n}\nh[n] =\nn = 0\n{\n}\nx[n] 0\n1/16\n4/16\n9/16\n16/16\nh[n]\n4/8\n2/8\n1/8\n===============================================\n0 0 0\n4/128 2/128 1/128\n16/128 8/128 4/128\n36/128 18/128 9/128\n===============================================\nx n[ ] = 0\n{\n}\nh[n] =\nn = 0\n{\n}\nx[n] 0\n1/16\n4/16\n9/16\n16/16\nh[n]\n4/8\n2/8\n1/8\n===============================================\n0 0 0\n4/128 2/128 1/128\n16/128 8/128 4/128\n36/128 18/128 9/128\n64/128 32/128 16/128\n===============================================\ny[n] 0 4/128 18/128 45/128 86/128 41/128 16/128\nx n[ ] = 0\n{\n}\nh[n] =\nn = 0\n{\n}\nx[n] 0\n1/16\n4/16\n9/16\n16/16\nh[n]\n4/8\n2/8\n1/8\n===============================================\n0 0 0\n4/128 2/128 1/128\n16/128 8/128 4/128\n36/128 18/128 9/128\n64/128 32/128 16/128\n===============================================\ny[n] 0 4/128 18/128 45/128 86/128 41/128 16/128\n0.5\nx[n]\nTextEnd\nn\n0.5\nh[n]\nTextEnd\nn\n0.5\ny n[ ] = h * x\ny[n]\nTextEnd\nn\n\n[ ] [ ] [\n]\nn\ny 2[ ] = h 0[ ]x 2 0\n[\n]+ h 1[ ]x 2 1\n[\n]+ h 2[ ]x 2 2\n[\n]\nx[n]\n1/16\n4/16\n9/16\n16/16\nh[n]\n4/8\n2/8\n1/8\n===============================================\ny 2[ ] = h k[ ]x 2 k\n[\n]\nk=0\n\n4/128 2/128\n1/128\n16/128\n8/128\n4/128\nM\n36/128\n18/128 9/128\n64/128 32/128 16/128\ny n =h k x n k\n[ ]\n[ ] [\n]\nconvolution sum\n===============================================\ny[n] 0\n4/128\n18/128 45/128 86/128 41/128\n16/128\nk= 0\ny 2 = h 0 x 2 0 + h 1 x 2 1 + h 2 x 2 2\n[ ]\n[ ] [\n]\n[ ] [\n]\n[ ] [\n]\n0.5\nx[n]\nTextEnd\nh[n]\ny[n]\ny n = h * x\n[ ]\nTextEnd\n0.5\n0.5TextEnd\nn\nn\nn\nx n = 0\n\nL=3, M=L-1=2\nx n = 0\n\nL=3, M=L-1=2\n[ ]\n{\n}\nh[n] ={\n}\n[ ]\n{\n}\nh[n] ={\n}\nn = 0\nn = 0\nx n = 0 n + 1 n 1 + 4 n 2 + 9 n 3 + 16 n 4\nh n = 4\n[ ] + 2\n[\n+ 1\n8 n 2]\n[ ]\n[ ]\n[\n]\n[\n]\n[\n]\n[\n]\n[ ]\nn\nn 1]\n[\nM\ny n =\nh k x n k\nconvolution sum\nk= 0\ny 0 = [ ]x[0 0]+ [ ]x[0 1 + [ ]x[0 2] = 4\n2 0 + 8\n1 0 = 0\n[ ]\nh 0\nh 1\n]\nh 2\n8 0 +\ny 1 = h 0 x 1 0 + h 1 x[11 + h 2 x 1 2 = 4 1 + 2 0 + 1 0 = 4\n[ ]\n[ ] [\n]\n[ ]\n]\n[ ] [\n]\nx n[ ] =\n[ ]\n16 n 1]\n16 n 2]\n16 n 3]\n[\n0 n + 1\n[\n+ 4\n[\n+ 9\n[\n+ 16 n 4]\nh n = 4\n[ ] + 8\n[\n+ 1\n8 n 2]\n[ ]\nn\nn 1]\n[\nM\ny n = [ ]x n[ k\nconvolution sum\n[ ]\nh k\n]\nk= 0\ny 0 = [ ] [\n+ h 1 x 0 1]\n[ ] [\n= 4\n8 0 + 1\n8 0 = 0\n[ ]\nh 0 x 0 0]\n[ ] [\n+ h 2 x 0 2]\n0 + 2\ny 1 = [ ] [\n+ h 1 x[11 + h 2 x 1 2]\n8 0 = 128\n[ ]\nh 0 x 1 0]\n[ ]\n]\n[ ] [\n= 4 1 + 2 0 + 1\ny 2 = h 0 x 2 0 + h 1 x 2 1 + h 2 x 2 2 = 8\n4 4\n2 1\n[ ]\n[ ] [\n]\n[ ] [\n]\n[ ] [\n]\n16 +\n16 + 8 0 = 128\ny 3 = [ ] [\n]+ [ ] [\n]+ [ ] [\n] = 4\n2 4\n1 1 = 45\n[ ]\nh 0 x 3 0\nh 1 x 31\nh 2 x 3 2\n8 16\n9 +\n16 +\ny[ ]\n4 = [ ] [\n]+ [ ] [\n]+ [ ] [\n] = 8 16\n8 9\n1 4 = 128\nh 0 x 4 0\nh 1 x 4 1\nh 2 x 4 2\n16 + 2\n16 +\nh 0 x 5 0\n[ ]\n+ h 2\n]\n8 0 + 2\n16 + 1\n8 16\ny[ ]\n5 = [ ] [\n] + h 1 x[5 1]\n[ ]x[5 2 = 4\n= 41\ny 6 = h 0 x 6 0 + h 1 x 6 1 + h 2 x 6 2 = 8 0 + 2 0 + 1\n= 128\n[ ]\n[ ] [\n]\n[ ] [\n]\n[ ] [\n]\n\nx n = 0\n\n[ ]\n{\n}\nh[n] ={ 8\n8}\nn = 0\nLTI Systems\nx[n]\n1/16\n4/16\n9/16\n16/16\nh[n]\n4/8\n2/8\n1/8\nh[n]\nh1[n]\ny[n]=h[n]*x[n]\nx[n]\n===============================================\nx[n]*h[n] 0\n4/128\n18/128 45/128 86/128 41/128\n16/128\n0.3125\n0.1406\n0.3516\n0.6719\n0.3203\n0.125\ny[n] = h1[n]* h2[n]* x n[ ]\nx[n]\nh2[n]\nMATLAB\n»conv([4/8, 2/8, 1/8], [0, 1/16, 4/16, 9/16, 16/16])\nh1[n]\nans =\n+\ny[n] = (h1[n] + h2[n\n[ ]\n])* x n\n0.0312 0.1406 0.3516 0.6719 0.3203 0.1250\nx[n]\n+\nh2[n]\nLTI Systems\nLTI Systems\nx[n]\ny[n]=h[n]*x[n]\nh[n]\nh1[n]\ny[n] = h [n]* h [n]* x n\n[ ]\n+\nx[n]\ny[n]\nh1[n]* h2[n]\nx[n]\nh3[n]\n+\nh2[n]\ny[n] = (h [n] + h [n])* x n\n[ ]\nx[n]\nh1[n] + h2[n]\n\nLTI Systems\nLTI Systems\n[n]\nx[n]\ny[n]\ny\nh3[n]\nx[n]\nh1[n] + h2[n]\nh3 * (h1[n] + h2[n])\nBlock Diagrams\nBlock Diagrams: Direct Form\nM\ny n =\nbkx n k\n[ ]\nunit delay\ny[n]=x[n-1]\nx n = n\n[ ]\n[\n]\nh[n] = y n\nx[n]= [ n]\n[ ]\n[ ]\nk= 0\nx[n]\n={0 0 1 0 0 0 0}\n{b0,b1,b2} ={ 4\n8, 8\n2, 1\n8}\n={0\n0}\nn = 2 1\nL=3, M=L-1=2\n={0\nb0\nb1 b2\n0}\ny[n]=Ax[n]\nx[n]\nA\nTextEnd\ny[n]=x[n]+z[n]\n0.8\n+\n0.6\nx[n]\nx[n]\n0.4\n+\n0.2\nz[n]\n-2\n-1\n-2\n-1\nn\nx[n]\n0.2\n0.4\n0.6\n0.8\nh[n]\nTextEnd\nh[n]\n\nBlock Diagrams: Direct Form\nBlock Diagrams: Transpose Form\nM\nM\ny n =\nkx n k]\nh[n] = y n[ ]\ny n =\nkx n k]\nh[n] = y n[ ]\n[ ]\nb [\n[ ]\nb [\nx[n]= [n]\nx n = n\nx[n]= [ n]\nx n = n\n[ ]\n[ ]\n[ ]\n[ ]\nk= 0\nk= 0\n={0 0 1 0 0 0 0}\n{b0,b1,b2} ={ 4\n8, 8\n2, 1\n8}\n={0\n0}\n={0 0 1 0 0 0 0}\n{b0,b1,b2} ={ 4\n8, 8\n2, 1\n8}\n={0\n0}\nn = 2 1\nL=3, M=L-1=2\n={0\nb0\nb1 b2\n0}\nn = 2 1\n={0\nb0\nb1 b2\n0}\ny n[ ] =\n0 x n + b [\n+ b [\ny n =\n0 x n + b [\n+ b [\nb [ ]\n1x n 1]\n2 x n 2]\n[ ]\nb [ ]\n1x n 1]\n2 x n 2]\nx[n]\nx[n]\nunit delay\nx[n-1]\nunit delay\nx[n-2]\nb0\nb1\nb2\nb2\nb1\nb0\nb2 x n 2\nb1x n\nb0 x n\nb1x n 1]\n[\n]\n[ ]\n[ ]\n[\nb0 x n\nb2 x n\n[ ]\n[ ]\n+\nunit delay\n+\n+\n+\n+\n+\nunit delay\n+\ny[n]\n+\ny[n]\nb2 x n 1\nb2 x n 2 + b1x n 1\n[\n]\n[\n]\n[\n]\nBlock Diagrams to\nBlock Diagrams to\nDifference Equations\nDifference Equations\nx[n]\nx[n]\nb2\nb1\nb\nb2\nb1\nb\nunit delay\n+\n+\n+\n+\n+\nunit delay\nunit delay\n+\ny[n]\nv n\n+\ny[n]\nv n\n2 [ ]\n2[ ]\nv n\nv [ ]\n[ ]\n[ ]\nb [ ]\n]\nb\n+ v\n[ ]\n[ ]\n[ ]\nb [ ]\n[\n=\n0 x n\n[ ]\nv1 n\nunit delay\n+\n1[ ]\nn = b2 x n\nv n =\n1x n + v [n 1\ny n =\n0 x n\nn 1\nv n = b2 x n\nv n =\n1x n + v n 1]\ny n\nb\n+ v n 1\n[ ]\n[ ]\n1[\n]\n[ ]\n[ ]\n1[\n]\ny n = b0 x n + v1 n 1\ny n = b0 x n + v n 1\nv1 n =\n1x n[ ] + v2 n 1]\nv1[n 1] = b [\n+ v2 n 2]\n[ ]\n[ ]\n[\n]\n[ ]\n[ ]\n1[\n]\n[ ]\nb\n[\n1x n 1]\n[\n2 [ ]\n[ ]\n2 [\n]\n[\n]\nv n = b2 x n\nv n 2 = b2 x n 2\n\nBlock Diagrams to\nBlock Diagrams to\nDifference Equations\nDifference Equations\nx[n]\nx[n]\nb2\nb1\nb\nb2\nb1\nb\nunit delay\n+\n+\n+\n+\n+\nunit delay\nunit delay\n+\ny[n]\nv2 n\n+\ny[n]\nv2 n[ ]\nv n\n[ ]\nv1 n\n[ ]\nunit delay\n+\n1[ ]\nv2 n = b2 x n\nv1 n = b1x n + v2 n 1\n[ ]\n[ ]\n1[\n]\nv2 n = b2 x n\nv1 n = b1x n + v2 n 1\n[ ]\n[ ]\n1[\n]\n[ ]\n[ ]\n[ ]\n[ ]\n[\n]\ny n = b0 x n + v n 1\n[ ]\n[ ]\n[ ]\n[ ]\n[\n]\ny n = b0 x n + v n 1\ny n =\n0 x n + v1 n 1]\n[ ] = b [ ]\n1x n 1] + b2 x n 2]\n[ ]\nb [ ]\n[\ny n\n0 x n + b [\n[\n1[\n]\n[\n]\n[\n]\nv n 1 = b1x n 1 + b2 x n 2\nBlock Diagrams to\nBlock Diagrams to\nDifference Equations\nDifference Equations\nx[n]\nunit delay\nunit delay\nv1 n[ ]\nv2 n[ ]\nblock diagram\nx[n]\nb2\nb1\nb\nb0\nb1\nb2\nunit delay\n+\n+\n+\nunit delay\n+\n+\ny[n]\nv2 n[ ]\n+\n+\nv1 n[ ]\n+\ny[n]\nv2 n = b2 x n\nv1 n = b1x n + v2 n 1\n[ ]\n[ ]\n[\n]\ny n =\n0 x n + v1[\n[ ]\n[ ]\n[ ]\nb [ ]\nn 1]\nv2 n = [ ]\nv1 n = v2 n 1]\ny n = b0v2 n + b1v1[ ] + b2v1 n 1]\n[ ]\nx n\n[ ]\n[\n[ ]\n[ ]\nn\n[\ny n = b0 x n + b1x n 1 + b2 x n 2\ndifference equation\n[ ]\n[ ]\n[\n]\n[\n]\ny n = b\n2 n + b\n1 n + b\n1 n 1\nh n[ ] =\n0 n + b [\n+ b [\nimpulse response\n[ ]\n0v [ ]\n1v [ ]\n2v [\n]\nb [ ]\n1 n 1]\n2 n 2]\nv1 n = v2 n 1]\n[ ]\n[\nv2 n = x n\n[ ]\n[ ]\nequivalent ways\nof describing system\n\nBlock Diagrams to\nBlock Diagrams to\nDifference Equations\nDifference Equations\nunit delay\nunit delay\nv1 n[ ]\nv2 n\nunit delay\nunit delay\nv1 n[ ]\nv2 n\n[ ]\n[ ]\nx[n]\nx[n]\nb0\nb1\nb2\nb0\nb1\nb2\n+\n+\n+\n+\n+\n+\n+\ny[n]\n+\ny[n]\n1[ ]\n2 [\ny n = b\n2 n + b\n1 n + b\n1 n 1\n2 [ ]\n1[ ]\n2 [\ny n = b\n2 n + b\n1 n + b\n1 n 1\nv [ ]\nn = x n[ ]\nv n = v n 1]\n[ ]\n0v [ ]\n1v [ ]\n2v [\n]\nv n = x n[ ]\nv n = v n 1]\n[ ]\n0v [ ]\n1v [ ]\n2v [\n]\ny n = b\n2 n + b\n1 n + b\n1 n 1\ny n = b0 x n + b1x n 1 + b2 x n 2\nv n = [ ]\nv1[n 1] = v2 [n 2]\n[ ]\n0v [ ]\n1v [ ]\n2v [\n]\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\nx n\nv2 n 2] = x n 2]\n[\n[\nv n = v n 1\nv2 n 1] = x n 1]\n1[ ]\n2 [\n]\n[\n[\nHomework:\n3 point average\nL-point running average\ny n = x n + x n 1 + x n 2\nx n = sin(2n 15) u n\n[ ]\n1 n 0\n[ ]\nu n =\nL\n0 n < 0\nn\nfor input sequence\n[ ]\n3 [ ]\n3 [\n]\n3 [\n]\n[ ]\nn\nk.\n.\ny\na\nu\n\np5_1:\nL\nn\nk\nx[n]=anu[n], n0\nk = 0\nN\nM\nN\nk\nlet z=n-k\nhint:\n\nk = M\nk=n-z\nL\n0.8\n1 .\naz.u z\n0.6\nL\nn\nz = 0\n0.4\n0.2\nn\nL\nz\nremember n0\n.\naz.u\nL\nz = n\n-0.2\np5_6: FIR & delays\n-0.4\nFIR and single delay\n-0.6\n-0.8\n-1\n-5\ny[n]=ax[n]+bx[n-1]\nn\nx[n]\nTextEnd"
    },
    {
      "category": "Resource",
      "title": "Recitation 9",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-160-signals-systems-and-information-for-media-technology-fall-2007/469837e1f4301c9ca4047cef7a915278_rec9.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.160 / MAS.510 / MAS.511 Signals, Systems and Information for Media Technology\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nCausal FIR filter\nx n\nCausal FIR filter\ny n\n[ ]\n[ ]\nQ:What is the definition of an FIR filter?\n\nCausal FIR filter\nx n\nCausal FIR filter\ny n\n[ ]\n[ ]\nQ:What is the definition of an FIR filter?\nA: The output y at each sample n is a weighted sum\nof the present input, x[n], and past inputs,\nx[n-1], x[n-2],..., x[n-M].\n\nCausal FIR filter\nx n\nCausal FIR filter\ny n\n[ ]\n[ ]\nQ:What is the formula for an FIR filter?\n\nCausal FIR filter\nx n\nCausal FIR filter\ny n\n[ ]\n[ ]\nQ:What is the formula for an FIR filter?\ny n = b0 x n + b1x n 1 +K + bM x n M\n[ ]\n[ ]\n[\n]\n[\n]\nM\ny n = kx n k]\n[ ]\nb [\nk= 0\n\nn\nx n\n[ ]\n\n?\nCausal FIR filter\nb0 =1,b1 = 3,b2 =1\nx n[ ] = n[ ]\ny n[ ] =\n?\ny n\n[ ]\nh n\n[ ] ?\ny 1\n[ ] ?\n0.9\n0.8\n0.7\n0.6\n0.5TextEnd\n0.4\n0.3\n0.2\n0.1\n-2\n-1\nn\n=\n=\n=\nx[n]\n\nCausal FIR filter\nb0 =1,b1 = 3,b2 =1\ny[n]\nn\nx n\n[ ]\nh n\n[ ]\n=\nx n = [ ]\n[ ]\nn\ny n\n[ ]\nx[n]=[ n] 0\nb0 1\nb1 3\n\ny n =1x n + 3x n 1 +1x n 2\nb2 1\n\n[ ]\n[ ]\n[\n]\n[\n]\n\nh[n] = [ ] =1 n + 3 n 1]+1 n 2]\n� 0 �\ny n\n[ ]\n[\n[\n� 3\n0 �\nh n = b\n[ ]\nn\nh[ ]1 =\n[ ]+ 3[11 +\n[\n1 1\n] 1 1 2]\nTextEnd\nh[0]=b0\nh[1]=b1\nh[2]=b2\n0.5TextEnd\nh 1 =1 1 + 3 0 +1 1\n0.9\n[ ]\n[ ]\n[ ]\n[\n]\n2.5\n0.8\n0.7\n0.6\nh 1 =1 0 + 3 1 +1 0\n[ ]\n( )\n( )\n( )\n1.5\ny[n]\nx[n]\n0.4\n[ ]\n0.3\nh 1 = 3\n0.2\n0.5\n0.1\n-2\n-1\n-2\n-1\nn\nn\n\nCausal FIR filter\nb0 ,b1,b2\nx n[ ]\ny n[ ]\nh[n]\nM\ny n[ ] =\nbkx n k\n[\n]\n\nweighted sum of\ndelayed inputs\nk= 0\nh n[ ] = b n\ny n[ ] = h[k]x n k\n[\n]\nk=0\nM\n\nConvolution of\nimpulse response\nand input\ny n[ ] = h[n]* x[n]\n\nx[n] =\nn\nx n\n[ ]\n[n]\n)u\nCausal FIR filter\nb0 =1,b1 = 3,b2 =1\nh[n] = 1, 3,\n[\n]\nsin 2 0.33n\n(\n\n0.81�\ny n\n[ ] ?\n0.88\n0.84\n0.06\n0.90\ny 3\n[ ] ?\n0.8\n0.6\n0.4\n0.2\nx[n]\n=\n=\n-0.2\n-0.4\n-0.6\n-0.8\n-1\n0TextEnd\n0.5\n1.5\n2.5\n3.5\n4.5\nn\n\nx[n]\nsin 2 0.33n\n(\nn\nx n\n[ ]\nn\ny n\n[ ]\n=\n[n]\n)u\nCausal FIR filter\nb0 =1,b1 = 3,b2 =1\nh[n] = 1, 3,\n[\n]\n\n0.81�\n\n�\n0.88\n0.88\n1.78\n0.84\nM\nM h[k]x n k\n[\nbk x n k\n+ 3x n\n]\n[\n[\ny n\n[ ]\n]\n=\n=\n0.06\n1.72\nk = 0\nk\n1 ]\n=\n1x n\n[ ]\n\nx n\n]\n1x 3 2\n[\n[\n0.90\n0.13\ny n\n[ ]\n]\n+\n=\n1.84\ny 3\n[ ] 1x 3\n[ ]+ 3x 3\n[ ]\n[\n[ ]+\nx\nx\n1x 1[ ]\n] +\n=\ny 3\n[ ]\n+\n=\n1.5\n0.5\nTextEnd\n(\n1 0.88\n0TextEnd\n-0.5\n0.2\ny 3\n[ ] 1(0.06 + 3(0.84\n)\n)\n)\n+\n=\n0.8\ny 3 = 1.72\n[ ]\n0.6\n0.4\ny[n]\nx[n]\n-1\n-0.2\n-0.4\n-0.6\n-1.5\n-0.8\n-1\n-2\n0.5\n1.5\n2.5\n3.5\n4.5\n0.5\n1.5\n2.5\n3.5\n4.5\nn\nn\n\n-2\n-1\n-1\n-0.5\n0.5\ny[n]\nTextEnd\nx[n]\nGraphical Convolution\ny n[ ] = h[n]* x[n] = x[n]* h[n]\nsum\nM\n\ny n[ ] =\n[k]x n k] =\n[k]h n k]\nh\n[\nx\n[\nk=0\nk=\nmultiply\nshift\nflip\n0TextEnd\n0.5\n0.5\nTextEnd\nx[n]\n-0.5\n-0.5\n-1\n-2\n-1\nn\n-1\n-2\n-1\nn\nh[-n]\nTextEnd\n-2\n-1\n0.5\n1.5\n2.5\nn\nh[-n]\nTextEnd h[0]=b0\nh[1]=b1\nh[2]= b2\nflip\nb1=3\nb2=1\nb0=1\n-2\n-1\nn\ny n = x n 2 h[n (n 2)]+ x n 1 h[n (n 1)]+ x[n]h n n\n[ ]\n[ ]\n[\n]\n[\n]\n[ ]\n[\n]\n[\n]\n[\n]\ny n = h[0]x n + h[1]x n 1 + h[2]x n 2\nn\n\n-1\nTextEnd\n-2\n-1\n-0.5\n0.5\nn\nTextEnd\ny n[ ] =\nx[k]h n k\n[\n]\nk= M\n\nflip\nshift\nmultiply\nsum\nGraphical Convolution\nmultiply\nn=0\nb1=3\nb2=1\nb0=1\nx[n]\nflip/\nshift by n\nh[-n]\n-1\n-0.5\n0.5\ny[n]\nTextEnd\n-2\n-1\nsum\nn\n-2\n-1\nn\ny 0 = x 2 h[2]+ x 1 h[1]+ x[0]h 0\n= 0 1+ 0 3+ 0 1 = 0\n[ ]\n[\n]\n[\n]\n[ ]\n( )\n( )\n( )\n\n-1\nGraphical Convolution\nsum\ny n = x[k]h n k\n[ ]\n[\n]\nk= M\nmultiply\nn=1\nflip\nshift\n0.5\n-2\nn\nTextEnd\n-2\n-1\nn\nTextEnd\nmultiply\nsum\n0.88\nb1=3\nb2=1\nb0=1\nx[n]\n-0.5\n-1\nflip/\nshift by n\nh[-n]\ny[n]\n0.88\n0 TextEnd\n-1\n-2\n-2\n-1\nn\ny 1 = x 1 h[2]+ x 0 h[1]+ x[1]h 0\n= 0 1+ 0 3+ 0.88 1 = 0.88\n[ ]\n[\n]\n[ ]\n[ ]\n( )\n( )\n(\n)\n\nn\nGraphical Convolution\nsum\ny n = x[k]h n k\n[ ]\n[\n]\nk= M\nmultiply\nn=2\nflip\nshift\n0.5\n-2\n-1\n0TextEnd\n-2\n-1\nn\nTextEnd\nb1=3\nb2=1\nb0=1 multiply\nsum\n0.88\n-0.84\nx[n]\n-0.5\n-1\nflip/\nshift by n\nh[-n]\ny[n]\n1.78\n0 TextEnd\n-1\n-2\n-2\n-1\nn\ny 2 =\n] [2]+ x 1 [1]+ x\n= 0 1+ 0.88\n( 0.84 1 =\nh\nh\n[2]h 0\n3+\n1.78\n[ ]\nx[0( )\n[ ]\n[ ]\n( )\n(\n)\n)\n\nn\nGraphical Convolution\nsum\ny n = x[k]h n k\n[ ]\n[\n]\nk= M\nmultiply\nn=3\nflip\nshift\n0.5\n-2\n-1\n0TextEnd\n-2\n-1\nn\nTextEnd\nb1=3\nb2=1\nb0=1 multiply\n0.88\n-0.84\n-0.06\nx[n]\n-0.5\n-1\nflip/\nshift by n\nh[-n]\ny[n]\nsum\n0 TextEnd\n-1\n-1.71\n-2\n-2\n-1\nn\ny 3 = x 1 h[2]+ x 2 h[1]+ x\n= 0.88 1+ ( 0.84 3+\n1 = 1.72\n[3]h 0\n( 0.06\n[ ]\n[ ]\n[ ]\n[ ]\n(\n)\n)\n)\n\nGraphical Convolution\nx[n]\ny n = [k]h n k]\n[ ]\nx\n[\nk= M\ny n = x[k]* h[k]\n[ ]\n0.5\n-0.5\n-1\n-2\n-1\nn\n0TextEnd\nh[n]\nTextEnd\nb1\nb0\nb2\n-2\n-1\nn\n-2\n-1\ny[n]\nTextEnd\n-2\n-1\nn\n\nGraphical convolution by decomposition\n1. Remember impulse response\nx[n] =[n]\nb0 ,b1,b2\nh[n]\ncausal FIR filter\nh[n] =\nn + n 1 +\nn 2\nb0 [ ]\nb1 [\n]\nb2 [\n]\n1.5\nTextEnd\n0.9\n2.5\n0.8\n0.7\n0.6\nTextEnd\nh[0]=b0\nh[1]=b1\nh[2]=b2\nx[n]\n0.5\ny[n]\n0.4\n0.3\n0.2\n0.5\n0.1\n-2\n-1\n-2\n-1\nn\nn\n\nn\nn\nn\nn\n-0.6\n0.6\nx[n]\nGraphical convolution by decomposition\n2. Decompose input into sum of scaled delayed impulses\nInput\nInput as impulses\nx[n] = 0.88[n 1] 0.84[n 2] 0.06[n 3]\n+ 0.90[n 4] 0.81[n 5]\nx[n] = sin 2 0.33n\n(\n)u[n]\nTextEnd\nx[5]\nx[4]\nx[3]\nx[2]\nx[1]\n0TextEnd\n-2\n-2\n-1\n0.8\n0.4\n-2\nTextEnd\n-2\n-1\n0.2\n-0.2\n-2\nTextEnd\n-2\n-1\n-0.4\n-0.8\n-2\n-2\n-1\nTextEnd\n-1\n-2\n-1\nn\nTextEnd\n-2\n-2\n-1\nn\n\nn\nn\nn\nn\nn\nn\nn\nn\nGraphical convolution by decomposition\n3. find impulse responses to each impulse\nInput as impulses\nImpulse responses\nh[n]\nn\nn 1\nn 2\n= b0 [ ]+b1 [\n]+b2 [\n]\nTextEnd\nx1[n 1] = 0.88[n 1]\nTextEnd\ny1[n] = 0.88 h[n 1]\n(\n)\nx[5]h[n-5]\nx[4]h[n-4]\nx[3]h[n-3]\nx[1]h[n-1]\n-2\n-2\n-2\n-1\n-2\n-1\n-2\n-1\n-2\nx[2]h[n-2]\nTextEnd\n-2\nTextEnd\n-2\n-1\n-2\nx[2]\nTextEnd\n-2\nTextEnd\ny2 [n] = 0.84 h[n 2]\n(\n)\ny3[n] = 0.06 h[n 3]\n(\n)\nFIR\nx1[n 2] = 0.84[n 2]\nx1[n 3] = 0.06[n 3]\n-2\n-1\n-2\n-1\nTextEnd\nTextEnd\ny4 [n] = 0.06 h[n 4]\n(\n)\n-2\n-2\n-2\n-1\n-2\n-1\n-2\nTextEnd\n-2\nTextEnd\ny5[n] = 0.81 h[n 5]\n(\n)\n-2\n-1\n-2\n-1\nn\nn\nx[5]\nx[4]\nx[3]\nx[1]\n\nn\nn\nn\nn\nn\nn\nn\nn\nx[5]\nx[4]\nx[3]\nx[2]\nx[1]\nGraphical convolution by decomposition\n3. sum impulse responses to get total response\nInput as impulses\nImpulse responses\nsum\ntotal response\n-2\n-1\n-2\nx[1]h[n-1]\nTextEnd\n-2\n-1\n-2\nx[2]h[n-2]\nTextEnd\n-2\n-1\n-2\nx[3]h[n-3]\nTextEnd\n-2\n-1\n-2\nx[4]h[n-4]\nTextEnd\n-2\n-1\n-2\nn\nx[5]h[n-5]\nTextEnd\nFIR\nTextEnd\n-2\n-2\n-1\n0 TextEnd\n-2\n-2\n-1\n0 TextEnd\n-2\n-2\n-1\n0 TextEnd\n-2\n-2\n-1\nTextEnd\n-2\n-2\n-1\nn\n-2\ny[n]\nTextEnd\n-2\n-1\nn\n\nn\nn\nn\nn\nn\nn\nGraphical convolution by decomposition\n-1\nx[n]\nTextEnd\nInput\n-2\n-1\n-2\nh[n]\nTextEnd\nImpulse response\n-2\n-1\n-2\nx[1]h[n-1]\nTextEnd\nImpulse responses\n-2\n-1\n-2\nx[2]h[n-2]\nTextEnd\n-2\n-1\n-2\nx[3]h[n-3]\nTextEnd\n-2\n-1\n-2\nx[4]h[n-4]\nTextEnd\n-2\n-1\n-2\nx[5]h[n-5]\nTextEnd\n-2\n-1\nn\n-2\ny[n]\nTextEnd\ntotal response\n-2\n-1\nn\n\nSynthetic polynomial multiplication\nn\n-2\n-1\n\nx[n]\n0.88\n-0.84 -0.06 0.90\n-0.81\nh[n]\n===============================================\n0.88 2.64\n0.88\n-0.84 -2.52 -0.84\n-0.06 -0.18 -0.06\n0.9\n2.7\n-0.81\n===============================================\ny[n]\n0.88\n1.80\n-1.7\n-0.12 1.83\ntry h1[n]* h2[n]\nh1[n]=[1/3,1/3,1/3]\nh2[n]=[1/3,-1/3,1/3]\n\n[ ]\n[\n]\n\n[ ]\n[\n]\n\nImpulse response\nM\ny n =\nbkx n k\nFIR filter\nk= 0\nn = 0\n[n]\nx n =\n[ ]\nDelta function\n= 0 otherwise\nM\nh[n] =\nbk[n k\ny n\n[ ]\n]\n=\nx= [n ]\nk= 0\nimpulse response\ny n =\nh[n]x n k\nconvolution sum\nLTI: FIR, IIR\nk=\n\n[ ]\n\nFrequency response\nM\nh k x n k\nconvolution\n[ ] [\n]\ny n\n[ ] =\nk= 0\nx n[ ] = Ae je j ˆn\nComplex exponential input\nˆ = Ts\nM\n=\nh k Ae je\njˆ(nk)\n[ ]\ny n\n[ ]\nk= 0\nM\n\nh k e jˆk Ae je jˆn\n=\nlet\n\nM\nk= 0\nH ˆ\n( ) =\nh[k]e jˆk\n= H ˆ Ae je jˆn\nk= 0\n( )\nH ˆ\nfrequency response\n( )\n\nM\ny n = [ ]x n[ k\nconvolution\n[ ]\nh k\n]\nk= 0\nx n[ ] = Ae je jˆn\ncomplex exponential input\nM\n[ ]\nH ˆ\ne\n( )\n]e\n( )\ny n =\nAe j\njˆn\nH ˆ =h[k\njˆk\nk= 0\nfrequency response\ncomplex\n(\n( )\nAe\nj +H ˆ )e jˆn\noutput same frequency\ny n = H ˆ\n[ ]\n( )\nas input, but amplitude scaled\nand a phase shift\nLTI: FIR & IIR\n\nsystem\nh n[ ]\ny[n]\nn\nx n\n[ ]\n= y n[ ]\n1/3\n[ ]\nn\n1 x n = [ ]\nx[n]=[ n]\n\n1/3\n[ ]\n?\n\n1/3\n\ny n =\n�> 5\n0 ��\n0 �\n\nEx.\nh n = 1 [ ]\n3 n 2]\n3 n 4]\nFIR\n[ ]\n3 n +\n[\n+\n[\ny n =\n[ ]+ 3 x n 2]+ 3 x n 4]\n[ ]\n3 x n\n1 [\n1 [\nH ˆ = h[k]e\njˆk\n( )\nk=0\n= h[0]e\njˆ 0 + h[2]e\njˆ 2 + h[4]e\njˆ 4\n= 1\n3 + 1\n3 e\njˆ 2 + 1\n3 e\njˆ 4\nAlso try by inspection\n= 1\n3 (1+ e\njˆ 2 + e\nj2ˆ 4 )\nif bk's symmetric, then factor out\njˆ 2\njˆ 2\njˆ 2\ne\njˆ ( M /2) where M is the order of\n= 3 e\n(e\n+1+ e\n)\nthe filter. This leaves complex\nconjugate paired exponentials\n= 1\n3 e\njˆ 2 (1+ 2cos2 ˆ)\nto transform into trigonometric\nfunctions (cosines/sines).\n\nH ˆ = 1\njˆ 2 1+ 2cos2 ˆ\n( )\n3 e\n(\n)\nH ˆ\n( ) = 1\n3 1+ 2 cos 2 ˆ\n(\n)\nH ˆ\n( ) 0\n0.5\nNote:\nH\n3( ) = 0\n-0.5\nH 2\n3( ) = 0\n-3\n-1\n-2\n-1\nH ˆ\n( ) = 2 ˆ\nH ˆ\n(\n) = H ˆ\n( )\nlinear phase\n-1\nH ˆ\n( )\n-2\n-3\n-3\n-2\n-1\nˆ\nprincipal value of phase fn\n< H ˆ\n( ) <\nif not, add multiples of 2\nWant positive magnitudes, H ˆ\n( ) 0\nso absorb negative sign into phase by adding\nan additional\nat each zero\n\nzeros\n3 1+ 2 cos2 ˆ\n(\n)\n\n( )\n3 e\nj 2ˆ(\n)\nH ˆ =\n1+ 2cos2 ˆ\n( )\n0.5\nH ˆ = (1+ 2cos2 ˆ)\n( ) 0\nH ˆ\n-0.5\nNote:\nH ( ) = 0\n-1\n= 0\n-3\n-2\n-1\nH ( )\nH ˆ = 2ˆ\n( )\nlinear phase\n\n2ˆ\n0 ˆ < 3\nH( )\nˆ\n\n-1\n-2\n= 2ˆ +\n3 ˆ < 2 3\n-3\n-2\n-1\n2ˆ + 2\n2 /3 ˆ <\n-3\nˆ\nphase odd function\nH ˆ = H ˆ\n(\n)\n( )\nprincipal value of phase fn\n<\nˆ <\nH ( )\nzero\nband stop filter\n3 1+ 2 cos2 ˆ\n(\n)\n\n-3\n-2\n-1\n-1\n\nLinear Phase\ndelay of n0 sample periods\ny[n] = [\nn0\nx n\n]\nFIR filters are linear phase if\nH ˆ = e\njˆn0\nthe coefficients are symmetric\n( )\n=1\nH ˆ = ˆ\nlinear phase\nH ˆ( )\n( )\nn0\n(\ns )\nhigher frequencies need larger phase shifts\ny = sin 2(t + nT )\nthan lower frequencies to achieve same time\n= sin(2t + 2nTs )\ndelay\n= sin(2t +)\n= 2T n\ns\nlinear phase,\n\nH ˆ = 2ˆ\n( )\n2 sample delay\n\n2ˆ\n0 ˆ < 3\nH ( )\nˆ\n= 2ˆ +\n3 ˆ < 2 3\n-1\n-2\n\n-3\n2ˆ + 2\n2 /3 ˆ <\n-3\n-2\n-1\nˆ\n\nLinear Phase\n\"It turns out that, within very generous\ntolerances, humans are insensitive to\n[audio] phase shifts. ...\"- Floyd E. Toole,\nPhD\nVice President Acoustical Engineering\nHarman International Industries, Inc.\n\"For data transmission, a nonlinear\nphase delay causes intersymbol\ninterference which increases error\nrate, particulary if the signal-to\nnoise ration is poor\" - Digital Signal\nProcessing in Communication\nSystems By Marvin E. Frerking\n\"These are the pulse responses of each of the filters.The pulse response is nothing more than a positive\ngoing step response followed by a negative going step response. The pulse response is used\nhere because it displays what happens to both the rising and falling edges in a signal.\nHere is the important part: zero and linear phase filters have left and right edges that look the same,\nwhile nonlinear phase filters have left and right edges that look different.\nMany applications cannot tolerate the left and right edges looking different. One example is the\ndisplay of an oscilloscope, where this difference could be misinterpreted as a feature of the signal being\nmeasured. Another example is in video processing. Can you imagine turning on your TV to\nfind the left ear of your favorite actor looking different from his right ear?\"\nhttp://www.dspguide.com/ch19/4.htm\n\nFREQZ Z-transform digital filter frequency response.\nWhen N is an integer, [H,W] = FREQZ(B,A,N) returns the N-point frequency\nvector W in radians and the N-point complex frequency response vector H\nof the filter B/A:\n-1\n-nb\njw B(z) b(1) + b(2)z + .... + b(nb+1)z\nH(e) = ---- = ---------------------------\n-1\n-na\nA(z) 1\n+ a(2)z + .... + a(na+1)z\ngiven numerator and denominator coefficients in vectors B and A.\n<snip>\nFREQZ(B,A,...) with no output arguments plots the magnitude and\nunwrapped phase of B/A in the current figure window.\nH ˆ = 1\n2 jˆ 1+ 2cos2 ˆ = 1\njˆ 2 + 1\njˆ 4\n( )\n3 e\n(\n)\n3 + 3 e\n3 e\njˆ\nz\n= e\n3 + 1\n3 z\n2 + 1\n3 z\nb(1) = 1\n3,b(2) = 0,b(3) = 1\n3,b(4) = 0,b(5) = 1\n( )\nH ˆ =\na(1) =1\n>> freqz([1/3,0,1/3,0,1/3],[1])\n-1\n\n-< < .\n\nH ˆ = 1\nj 2ˆ 1+ 2cos2 ˆ = 1\njˆ 2 + 1\njˆ 4\n( )\n3 e\n(\n)\n3 + 3 e\n3 e\n>> freqz([1/3,0,1/3,0,1/3],[1])\nBode Plot (frequency response curve, amp and phase)\n-60\n-50\n-40\n-30\n-20\n-10\nMagnitude Response (dB)\nTextEnd\ndecibels (dB) = 20log10(|H|)\nNote: In this plot the\nMagnitude response is plotted\non a logarithmic scale.\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nNormalized frequency (Nyquist == 1)\nnormalized frequency goes\nfrom DC to Nyquist (\n= ),\n-150\n-100\n-50\nPhase (degrees)\nTextEnd\nso this is just one side.\nWe normally plot from\nRemember:\nFor real filter coefficients,\nmagnitude is an even function;\nphase is an odd function\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nNormalized frequency (Nyquist == 1)\n\nSuperposition and the frequency response\n[ ]\n3 + 3cos 0.6n)\ny n[ ] = 1 [ ]+ 1\n3 x n 2]+ 1\n3 x n 4]\nx n =\n(\ninput\n3 x n\n[\n[\nFIR filter\nsample domain\ny n =1+ cos 0.6n +1+ cos 0.6 n 2 +1+ cos 0.6 n 4\n[ ]\n(\n)\n(\n(\n))\n(\n(\n))\n= 3+\n(\ncos 0.6n)\n(\ncos 1.2\nsin 0.6n\n(\n+ cos 0.6n)\n(\n)+\n(\n)sin 1.2)\n(\ncos 2.4\nsin 0.6n\n(\n+ cos 0.6n)\n(\n)+\n(\n)sin 2.4)\n= 3+[1+\n(\n+\n(\n]cos 0.6n)\ncos 1.2)\ncos 2.4)\n(\n+ sin 1.2 +sin 2.4 sin 0.6n\n[\n(\n)\n(\n)]\n(\n)\n= 3+ Acos 0.6n)\n(\n(\n+ Bsin 0.6n)\n= 3+ A\n2 + B\n2 cos(0.6n+ tan\n1(B/ A))\n= 3+ 0.618cos 0.6n 0.2\n(\n)\n\nfrequency domain\n3 + 3cos 0.6n)\nx n[ ] =\n(\n-3\n-2\n-1\n( )\nH ˆ = 3 (1+ 2cos2 ˆ)\nˆ\nH 0 =1\nH(0.6) = 0.206\n( )\nH( )\nˆ\n2 ˆ\n\n( ) = 0\n( 2 0.6 + =\n= +\nH 0\nH\n)\n0.2\ny[n = ( )\n(\ncos 0.6\n(\nn\n] 3 1 + 3 0.206)\n0.2)\n= 3+ 0.618cos 0.6n 0.2\n(\n)\n-1\nH ˆ\n( )\ncloser\nto a zero,\nthe smaller the\noutput.\nˆ\n-3\n-2\n-1\n-3\n-2\n-1\nH ˆ\n( )\n\nchirp\n-1\nH ˆ\n( )\n-3\n-2\n-1\n-3\n-2\n-1\nˆ\n-3\n-2\n-1\nH ˆ\n( )"
    }
  ]
}