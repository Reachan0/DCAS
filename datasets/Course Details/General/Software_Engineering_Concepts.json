{
  "course_name": "Software Engineering Concepts",
  "course_description": "This is a reading and discussion subject on issues in the engineering of software systems and software development project design. It includes the present state of software engineering, what has been tried in the past, what worked, what did not, and why. Topics may differ in each offering, but will be chosen from: the software process and lifecycle; requirements and specifications; design principles; testing, formal analysis, and reviews; quality management and assessment; product and process metrics; COTS and reuse; evolution and maintenance; team organization and people management; and software engineering aspects of programming languages.",
  "topics": [
    "Business",
    "Project Management",
    "Engineering",
    "Computer Science",
    "Software Design and Engineering",
    "Systems Engineering",
    "Systems Design",
    "Business",
    "Project Management",
    "Engineering",
    "Computer Science",
    "Software Design and Engineering",
    "Systems Engineering",
    "Systems Design"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 1 session / week, 3 hours / session\n\nObjective\n\nMost complex systems today contain a great deal of software and digital components and will contain even more in the future. At the same time, software is becoming the Achilles heel of complex system development: At least half of all large software-intensive system projects are cancelled or suffer major delays and problems. System engineers and managers are often unprepared to cope with this new technology. The goal of this class is to learn why building these systems is so difficult and to provide system engineers, managers, and software engineers with the tools and knowledge to avoid these problems. At the end of the class, you will be able to exercise professional judgment in selecting approaches for a particular project based on an understanding of how the present state of software engineering practice came about, what was tried in the past, what worked and what did not work, and why. Note that the class is a system engineering of software class, not a standard software engineering class and as such will not provide basic training in programming or in specific approaches or tools for developing software.\n\nRequired Background\n\nThere are no prerequisites and no required background although it will help if you have some minimal knowledge of programming. Having some system engineering project experience will also be helpful. What you get out of the class will be a function of what you bring to it along with your personal goals and objectives. Each student may find they get different things out of the class.\n\nReadings\n\nInstead of a textbook, required reading will consist of a carefully selected set of historically important and foundational papers as well as more current ones reflecting the latest thoughts. Some papers will be technical while others will be opinions or essays. The literature is vast, and papers have been selected for their historical relevance in the development of the field or for their ability to help you critique the assumptions underlying current software/system engineering dogma.\n\nAssignments\n\nThere will be no programming assignments. Because my goal is to enhance your ability to make successful professional judgments rather than use a specific set of tools or a particular approach to engineering software, most assignments will involve evaluation and interpretation rather than practice in applying particular techniques or tools.\n\nThere will be two types of assignments: Before each class session, you will be required to submit a short (one half to one page) summary of each paper assigned for that week along with a critique of the paper (see instructions below) and occasionally answers to a few specific questions on that topic or paper. Because class sessions will involve a lot of discussion of the readings, late summaries will not be accepted.\n\nThere will be no exams. The summaries from the last week will involve synthesizing what you have learned in the class.\n\nClass Sessions\n\nClass meetings will include a mixture of lecture and discussion. You will find that most concepts are easily learned from the readings and do not require my explaining them to you. A few topics are difficult to learn on your own or I could not find any good tutorial papers on them so they will be described in class. You will get the most out of the class if you participate in the class discussions.\n\nGrading\n\nGrades will be based on the weekly assignments.\n\nSchedule\n\nThe topic is vast and cannot be completely covered in one semester. The specific topics to be covered have been chosen somewhat arbitrarily and may change in future offerings of the class. A schedule and list of assigned readings are available in the\ncalendar\nand\nreadings\nsections respectively. Copies of the class lecture notes are available in the\nlecture notes\nsection.\n\nInstructions for Reading Assignments\n\nBefore each class session, you will submit a short (one half to one page) summary of each paper assigned for the week along with the answers to the following general questions:\n\nWhat are the main ideas or themes? (i.e., a very brief summary of the paper)\n\nCritical evaluation of the paper: What things in particular did you agree with or like? What things did you disagree with? How does it measure up with your experience?\n\nAny additional thoughts or ideas you had while reading it?\n\nBecause it obviously will not be possible to read the papers for the first class by the first class meeting (as they were not available), their summaries will have special due dates as noted on the schedule.\n\nIn addition, there may be some short assignments during the semester that will be given and described in class.",
  "files": [
    {
      "category": "Resource",
      "title": "cnotes1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/c57003754c71b9f43d8eae03b4362cd5_cnotes1.pdf",
      "content": "16.355\nSoftware Engineering Concepts\nProf. Nancy Leveson\nFall 2005\n\nOutline\nIs There a Problem?\nWhy is Software Engineering Hard?\nSyllabus and Class Description\nCopyright\nc\nNancy Leveson, Sept. 2000\n\nIs there a problem?\nExamples:\nAAS (FAA Advanced Automation System)\nFBI CIC\nIRS Modernization Program\nC-17\nAriane 5\nHead of AF Systems Command: ''Software is the\nachilles heel of weapons development\"\n7 out of every 10 major weapons development\nprograms are encountering software problems\nand the rate is increasing.\nCopyright\nc\nNancy Leveson, Sept. 1999\n\nSome \"Data\" (Myths?)\nRisks of cancellation or major delays rise rapidly\nas overall application size increases (Capers Jones):\nFailure or cancellation rate of large software\nsystems is over 20% (Capers Jones)\n25 % for those over 100,000 LOC\n50% for systems exceeding half million LOC\ncancelled before completion\n65% of large systems (over 1,000,000 LOC) are\nthe most risky business undertakings in the\nmodern world (Capers Jones)\n5000 function points (~500,000 LOC) is one of\nDevelopment of large applications in excess of\n\nNancy Leveson, Sept. 1999\nCopyright\nc\n\nMore \"Data\" (Myths?)\nAfter surveying 8,000 IT projects, Standish Group\nreported about 30% of all projects were cancelled.\nAverage cancelled project in U.S. is about a year\nbehind schedule and has consumed 200% of\nexpected budget (Capers Jones).\nWork on cancelled projects comprises about 15%\nof total U.S. software efforts, amounting to as much\nmuch as $14 billion in 1993 dollars (Capers Jones).\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nAnd Yet More\nOf completed projects, 2/3 experience schedule\ndelays and cost overruns (Capers Jones)\n[bad estimates?]\n2/3 of completed projects experience low reliability\nand quality problems in first year of deployment\n(Jones).\nSoftware errors in fielded systems typically range\nfrom 0.5 to 3.0 occurrences per 1000 lines of code\nBell Labs survey).\nCivilian software: at least 100 English words\nproduced for every source code statement.\nMilitary: about 400 words (Capers Jones)\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nHave you ever been on a project where the\nsoftware was never finished or used?\nWhat were some of the problems?\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nDeath March Projects\nFeature (scope) creep\nThrashing\nIntegration problems\nOverwriting source code\nConstant re-estimation\nRedesign and rewriting during test\nNo documentation of design decisions\nEtc.\nCopyright\nc Nancy Leveson, Sept. 1999\n\nTypes of Problem Projects (Yourdan)\nMission Impossible\nLikely to succeed, happy workers\nUgly\nLikely to succeed, unhappy workers\nKamikaze\nUnlikely to succeed, happy workers\nSuicide\nUnlikely to succeed, unhappy workers\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nDevelopment costs are only\nthe tip of the iceberg.\n\n!\n#\n$\n%\n'\n%\n)\n+\n-\n\n.\n/\n%\n%\n)\n\n+\n\n+\n\nUnderstanding the Problem\n1/3 planning\nc\nCopyright\nNancy Leveson, Sept. 1999\nDevelopment Costs\nCoding\nTest\nPlanning\n1/4 system test\n1/6 coding\n1/4 component test\n+\n:\n\nUnderstanding the Problem (2)\nSoftware Maintenance:\n20% error correction\n20% adaptation\n60% enhancements\nMost fielded software errors stem\nfrom requirements not code\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nSoftware Evolution (Maintenance)\nBelady and Lehman's Laws:\nSoftware will continually change.\nSoftware will become increasingly\nunstructured as it is changed.\nLeveson's Law:\nIntroducing computers will not reduce\npersonnel numbers or costs.\nCopyright\nc\nNancy Leveson, Sept. 1999\n\nAre Things Improving?\nIs software improving at a slower rate than hardware?\n\"Software expands to fill the available memory\"\n(Parkinson)\n\"Software is getting slower more rapidly than\nhardware becomes faster\" (Reiser)\nExpectations are changing\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nIs software engineering more difficult than\nhardware engineering?\nWhy or why not?\n\nWhy is software engineering hard?\n\"Curse of flexibility\"\nOrganized complexity\nIntangibility\nLack of historical usage information\nLarge discrete state spaces\nCopyright\nc\nNancy Leveson, Sept. 1999\n\nThe Computer Revolution\nDesign separated from physical representation;\ndesign became a completely abstract concept.\nGeneral\nSpecial\nPurpose\n+\nSoftware\n=\nPurpose\nMachine\nMachine\nMachines that were physically impossible or\nimpractical to build become feasible.\nDesign can be changed without retooling or\nmanufacturing.\nEmphasis on steps to be achieved without worrying\nabout how steps will be realized physically.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nThe Curse of Flexibility\n\"Software is the resting place of afterthoughts.\"\nNo physical constraints\nTo enforce discipline on design, construction\nand modification\nTo control complexity\nSo flexible that start working with it before fully\nunderstanding what need to do\nThe untrained can get partial success.\n\"Scaling up is hard to do\"\n''And they looked upon the software and saw that it\nwas good. But they just had to add one other feature ...''\nCopyright\nc\nNancy Leveson, Sept. 1999\n\nWhat is Complexity?\nThe underlying factor is intellectual manageability\n1. A \"simple\" system has a small number of unknowns in its\ninteractions within the system and with its environment.\n2. A system becomes intellectually unmanageable when the\nlevel of interactions reaches the point where they cannot\nbe thoroughly\nplanned\nunderstood\nanticipated\nguarded against\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nWays to Cope with Complexity\nAnalytic Reduction (Descartes)\nDivide system into distinct parts for analysis purposes.\nExamine the parts separately.\nThree important assumptions:\n1. The division into parts will not distort the\nphenomenon being studied.\n2. Components are the same when examined singly\nas when playing their part in the whole.\n3. Principles governing the assembling of the components\ninto the whole are themselves straightforward.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nWays to Cope with Complexity (con't.)\nStatistics\nTreat as a structureless mass with interchangeable parts.\nUse Law of Large Numbers to describe behavior in\nterms of averages.\nAssumes components sufficiently regular and random\nin their behavior that they can be studied statistically.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\n:\n\nWhat about software?\nToo complex for complete analysis:\nSeparation into non-interacting subsystems\ndistorts the results.\nThe most important properties are emergent.\nToo organized for statistics\nToo much underlying structure that distorts\nthe statistics.\n\"Organized Complexity\" (Weinberg)\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nOther Factors\nHard to diagnose problems\nTransient hardware faults vs. software errors\nHard to experiment with and manage\nInvisible interfaces\nContinuous vs. discrete math\nCannot test exhaustively\nLacks repetitive structure found in computer circuitry\nLarge discrete state spaces\nIntangibility\n=\n=\n>\n>\nNancy Leveson, Sept. 1999\nCopyright\nc\n\nAnd One More\nNo historical usage information\nto allow measurement, evaluation, and\nimprovement of standard designs over time.\nAlways specially constructed.\nUsually doing new things.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nsuggests that the claimed benefits, in fact, may not exist.\nVessey and Weber\n1. Students will be able to evaluate software engineering\ntechniques and approaches.\nClass Objectives\nHawthorne Effect\nReligious approach to SE (vs. scientific):\nAccept on faith (because sounds right)\nGurus (Jackson, Yourdan, etc.)\nSects (OO, Ada vs. Modula 2)\nArguments:\nProof by vigorous handwaving.\nUnsupported hypotheses.\nFalse analogies.\ntesting, what little evidence has been obtained sometimes\nc\nCopyright\nNancy Leveson, Sept. 1999\n\"It is important that students bring a certain ragamuffin\nbarefoot irreverance to their studies. They are here\nnot to worship what is known, but to question it.\"\nJacob Bronowski, The Ascent of Man\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n@\n@\n@\n@\n@\n@\n@\n@\n@\n@\n@\n@\n\"The developed theories ...have rarely been subjected to\nempirical testing, and so their value remains unknown. They\nprovide zealots with opportunities to market a rash of seminars\nand courses and to flood the literature with papers advocating\nthe new technologies. When the theories are subjected to\n\nClass Objectives\n2. Students will be able to exercise professional\njudgement in selecting an approach for a particular\nproject based on an understanding of:\nHow the present state of software practice came about\nWhat was tried in the past\nWhat worked and what did not work\nWhy\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nSome additional short assignments\nAny additional thoughts\nCritical evaluation\nMain ideas or themes\nReading summaries:\nNo programming\nAssignments\nRequired Background\nAB\nCD\nNancy Leveson, Sept. 1999\nCopyright\nc\n\nReading: Both classic papers and new ones\nI would like to see computer science teaching set deliberately\nin a historical framework.... The absence of this element in\ntheir training causes people to approach every problem from\nfirst principles. They are apt to propose solutions that have\nbeen found wanting in the past. Instead of standing on the\nshoulders of their precursors, they try to go it alone.\nMaurice Wilkes\nc\nCopyright\nNancy Leveson, Sept. 1999"
    },
    {
      "category": "Resource",
      "title": "cnotes2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/fde8c18b46373e9262961027b620636f_cnotes2.pdf",
      "content": "Waterfall Model\n\"Big Bang\" testing, \"stubs\", daily build and smoke test\nDocument-driven process\nDeliverables - baselines\nFeasibility\nV&V\nStudy\nRequirements\nDesign\nCoding\n\"A Rational Design Process and How to Fake It\"\nV&V\nV&V\nV&V\nTest\nV&V\n\nEvolutionary Model\nPrototyping - \"Do it twice\"\nto assess feasibility\nto verify requirements\nMay only be a front end or executable specification\nOr develop system with less functionality or quality attributes\n3 approaches:\n1) Use prototyping as tool for requirements analysis.\nNeed proper tools\n2) Use to accomodate design uncertainty.\nPrototype evolves into final product\nDocumentation may be sacrificed\nMay be less robust\nQuality defects may cause problems later\n3) Use to experiment with different proposed solutions\nbefore large investments made.\n\nEvolutionary Models (2)\nDrawbacks:\nCan be expensive to build\nCan develop a life of its own - turns out to be product itself\nHard to change basic decisions made early\nCan be an excuse for poor programming practices\nExperimental Evaluation:\nBoehm: prototyping vs. waterfall\nWaterfall: addressed product and process control risks better\nResulted in more robust product, easier to maintain\nFewer problems in debugging and integration due to\nmore thought-out design\nPrototyping: addressed user interfaces better\nAlavi: prototyping vs. waterfall applied to an information system\nPrototyping: users more positive and more involved\nWaterfall: more robust and efficient data structures\n\nIncremental Model\nFunctionality produced and delivered in small increments.\nFocus attention first on essential features and add functionality\nonly if and when needed\nSystems tend to be leaner -- fights overfunctionality syndrome\nMay be hard to add features later\nVariant: Incremental implementation only\nFollow waterfall down to implementation\nDuring requirements analysis and system design\nDefine useful subsets that can be delivered\nDefine interfaces that allow adding later smoothly\nDifferent parts implemented, tested, and delivered according\nto different priorities and at different times.\n\nSpiral Model\nIncludes every other model\nRisk driven (vs. document driven or increment driven)\nRadius of spiral represents cost accumulated so far\nDo you need one uniform process over entire project?\nIn requirements analysis, identify aspects that are uncertain\ne.g., library:\ncheckout and checkin (inventory control) - relatively certain\ncard catalogue, user search - relatively uncertain\nthen have separate processes for the different parts.\n\nSoftware Factory\nMost software organizations strictly separated between\ninitial development and later maintenance.\nNo incentive to produce a system that can be easily\nmaintained.\nNo incentive to produce reusable components.\nProject management vs. product management\nExtend management responsibility to cover family of\nproducts rather than an individual product (product families)\n\nDespite the rhetoric, CMM emphasizes control over flexibility and learning\nControl orientation seeks to maintain predictable operations, minimize\nvariation, and avoid surprises.\nLearning orientation seeks to increase variation in order to explore\nopportunities.\nFormal bureaucratic control undermines intrinsic motivation needed for\ncreative and flexible responses to uncertainty.\nSenge: humanistic values of caring and individual freedom are\nessential to building learning organizations.\nCarroll: \"In too many TQM programs, it is the difficult-to-implement\nportions of the program that are being finessed or ignored\nand the rhetoric that is being retained.\"\n\nOther CMM Problems\nTreats people as assembly line workers, i.e., replaceable, unreliable\nHumans are subordinated to defined processes\nWhy five levels? Why a rigid order?\nCreates inflexible organizations and the illusion of control\nPlaces the focus on the wrong things"
    },
    {
      "category": "Resource",
      "title": "cnotes3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/f5a9c0cbbfc7847208f14e7122ceb77d_cnotes3.pdf",
      "content": "Requirements Specification:\nA structured document that sets out the services\nthe system is expected to provide.\nShould be precise so that it can act as a contract\nbetween the system procurer and software developer.\nNeeds to be understandable by both.\nDescribes what the system will do but not how it will\ndo it (objectives but not how objectives will be achieved.\nDesign Specification:\nAn abstract description of the software that serves as a\nbasis for (or describes) detailed design and implementation\nDescribes how the requirements will be achieved.\nPrimary readers will be software designers and\nimplementers rather than users or management.\nGoals and constraints specified in requirements document\nshould be traceable to the design specification (and from\nthere to the code.\n\nContents of Requirements Documents\nIntroduction: Describes the need for the system and places it\nin context, briefly describing its functions and presenting a\nrationale for the software. Describes how the system fits into\nthe overall business or strategic objectives of the organization\ncommissioning the software.\nSystem Model: Shows the relationships between the system\ncomponents and the system and its environment. An abstract\ndata model should also be described if appropriate to the type\nof system.\nSystem Evolution: Fundamental assumptions on which the\nsystem is based and anticipated changes due to hardware\nevolution, changing user needs, etc.\nFunctional Requirements: The services provided for the user.\nThis includes timing and accuracy requirements.\n\nContents of Requirements Documents (2)\nConstraints: Constraints on how the goals can be achieved\n(restrictions on behavior of software and freedom of designer),\ne.g., safety, hardware, programming languages, standards\nthat must be followed. Includes quality requirements such as\nmaintainability, availability, etc.\nPriorities: Guides tradeoffs and design decisions if all\nrequirements and constraints cannot be completely achieved.\nInterfaces to the Environment: Input or output interfaces and\nrelevant assumptions about environmental components with\nwhich the software will be interacting.\nGlossary: Definitions of technical terms used in the document.\nIndexes: Various types of indexes may be provided.\n\nAttributes of a good requirements document:\nReadable and understandable by customers, users, and\ndesigners.\nSpecifies only external system behavior (black box)\nStructured to be easy to change.\nSpecifies both goals and constraints.\nAble to serves as a reference for system maintainers.\nConsistent, complete, unambiguous, realistic, and testable\nSpecified acceptable responses to undesired events.\nSpecifies what should not do as well as what should do.\nSpecified incremental subsets if desried or minimum and\nmaximum functionality\nSpecifies changes anticipated in the future (for both\nenvironment and software)\n\nRequirements must be testable\nAn untestable requirement:\nThe system shall be easy to use by experienced\ncontrollers and shall be organized in such a way\nthat user errors are minimized.\nA testable requirement:\nExperienced controllers shall be able to use all\nthe system functions after a total of two hours\ntraining. After this training, the average number\nof errors made by experienced users shall not\nexceed two per day.\n\nEnsuring a Successful Product\nRight Product\nAppropriate and\nValidated Requirements\nProducibility\nConstraints\nProduction\nRequirements\nIn-service\nExperience\nResolution\nIssue\nLessons\nLearned\nAccidents\nIncidents\nand\nTechnology\nChanges\nRequirements\nAirline\nIndustry\nTrends\nRequirements\nCustomer\nPublic\nPerceptions\nRegulatory\nRequirements\nPolitical\nWorld\nAirports and\nGroundside\nRequirements\nAirspace\nand ATC\nRequirements\nInfrastructure\nRequirements\nBoeing\nMarket Driven\nAllocated\nRequirements\nFHA\nTrees\nFault\nFMEA\nPreliminary\nValidate\nAnalyze and\nCompliance\nRequirements\nTesting\nVerification\nCertification\nProduct\nSuccessful\nDesign\nDetailed\nSafety\nReliability\nAvailability\nMaintainability\nSupportability\nAnalyses\nPhysical and\nPreliminary\nFunctional Def.\nProduct Right\n\nTypes of Specifications\nInformal\nFree form, natural language\nAmbiguity and lack of organization can lead to\nincompleteness, inconsistency, and misunderstandings\nFormatted\nStandardized syntax (e.g., UML)\nBasic consistency and completeness checks\nImprecise semantics implies other sources of error\nmay still be present.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nTypes of Specifications (2)\nFormal\nSyntax and semantics rigorously defined.\nPrecise form, perhaps mathematical.\nEliminate imprecision and ambiguity.\nProvide basis for mathematically verifying equivalence\nbetween specification and implementation.\nMay be hard to read without training.\nSemantic distance too great?\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nINPUT SPACE\nOUTPUT SPACE\nF(I) = O\nA program is a mathematical object\nA programming language is a mathematical language.\nTherefore, we can prove properties about the program.\nI\nO\nF\ne.g. does it do what it is supposed to do\ndoes it not do anything harmful\nBuilding a model like engineers do, but need discrete rather than\ncontinuous mathematics.\nCopyright\nc Nancy Leveson, Sept. 1999\n\nInput-Output Assertions\nS {P} Q\nIf S holds before execution of S, then Q holds afterward.\nExamples:\nn\n1. sum = 0 { for i=1 to n do sum:=sum+a(i) } sum =\na\nj=1\nj\n2. proc search(A,n,x) int;\npre\npost\nn\n(result = 0\n(result = i\ni\n{1,...,i-1} : A[i] = x)\n{1,...,n} : A[i] = x)\ni\n1 i\nn\nA[i] = x\nCopyright\nc\nNancy Leveson, Sept. 1999\n\nAbstract Model Specifications\nBuild an abstract model of required software behavior using\nmathematically defined (perhaps using axioms) types (e.g.,\nsets, relations).\nDefine operations by showing effects of that operation on the\nmodel.\nSpecification includes:\nModel\nInvariant properties of model\nFor each operation:\nname\nparameters\nreturn values\nPre and post conditions on the operations\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nZ (pronounced Zed)\nZ specifications are made up of \"schemas\"\nA schema is a named, relatively short piece of specification\nwith two parts:\nAbove the line: the definition of the data entities\nBelow the line: the definition of invariants that hold\non those data entities\nCopyright\nc Nancy Leveson, Sept. 1999\n\nZ : Defining the Abstract Model\nLibrary\nbooks: P BOOK\nstatus: BOOK\nSTATUS\nbooks = dom status\nDeclaration says library has two visible parts of its state:\nbooks is a set of BOOKS, which are atomic elements.\nstatus is a partial function that maps a BOOK into a STATUS\n(which is another atomic element that can take values In or Out)\nThe invariant says the set of books is precisely the same as\nthe domain of the function status.\nSays every book in the Library has exactly one status\nTwo books may have the same status.\nExample of a legal state for Library is:\nbooks = {Principia Mathematica, Safeware}\nstatus = (Principia Mathematica\nIn,\nSafeware\nOut}\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nZ : Defining Operations\nbook? is the input\nA prime indicates the value after the operation\nLibrary declaration says operation modifies state of Library\nthe book to be borrowed must be currently checked in.\nThe first invariant defines a pre-condition on the operation, i.e.,\nThe second invariant defines the semantics of borrowing, i.e.,\nBorrow\nbook?: BOOK\nLibrary\nstatus' = status\n(book?\nstatus (book?) = In\nOut)\nit overwrites the entry in the status function for the borrowed book.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nZ : Proving Properties\nExample: After a borrow operation, the set of books in the\nlibrary remains unchanged.\nbooks' = books\nbooks' = dom status'\n[from invariant of Library]\n= dom (status\n{book?\nOut})\n[from post-condition of Borrow]\n= dom\nFollow from mathematics\n= dom\n= book\n= book\n[true because first invariant of Borrow implies\n(status\nstatus\ndom ({book?\nbook?\nOut})\n{book?\nOut})\nthat book? is an element of books]\nCopyright\nc\nNancy Leveson, Sept. 1999\n\nExample of a State Machine Model\nWater\nReading at set point /\nlevel\nClose drain pipe\nhigh\nReading at setpoint /\nWater\nTurn off pump\nlevel at\nHigh reading /\nsetpoint\nOpen drain pipe\nWater\nLow reading /\nlevel\nActivate pump\nlow\n\ncruise control\nturned on /\ninitialize cc\nCruise\nCruise\nControl On\nand in\nControl\nStandby\nincrease speed commanded /\nOff\ncruise control\nMode\nsend command to throttle\nturned off\nto increase at X rate\nbrake depressed\nIncreasing\nor accelerator\nSpeed\ndepressed /\ndiscontinue\ncruise control\nset point reached / reduce\nthrottle\nSpeed\nMaintaining\nread wheel turning rate /\nadjust throttle\n\nSpecTRM\nComplete traceability\nDocumentation of design rationale\nBased on\nSystem engineering tools for software-intensive systems\nenvironment\nIntegrates hazard analysis into engineering decision-making\nA \"CATIA\" for the logical parts of the system\nRequirements errors found early while cheaper to fix\nGoal of enhancing communication and expert review\nInformation available when needed and in form that has\nmaximum impact on decisions.\nFor verification and validation\nTo support change and upgrade process\nCognitive engineering research on how experts solve problems\nBasic principles of system engineering\n\n!\n#\n%\n\n&\n\n(\n*\n,\n&\n.\n,\n\n%\n\n&\n\n*\n<\n%\n\n,\n&\n\n!\n#\n%\n\n&\n\n*\n,\n&\n.\n,\n\nD\n\n%\n\n*\n,\n&\n.\n,\n\n&\n.\nG\n\n&\n\nI\n.\n\n,\n\n%\n\nPart-Whole\nIntent\nEnvironment\nValidation\nVerification\nOperator\nSystem\nLevel 1: System\nArchitecture\nLevel 3: System\nOperations\nLevel 6: System\nRefinement\nLevel 5: Physical\nRepresentation\nRepresentation\nLevel 4: Design\nDesign Principles\nLevel 2: System\nPurpose\nManagement\nLevel 0: Program\n>\n\nK\nL\nN\nO\nQ\nO\nS\nT\nV\nX\nY\nZ\n\\\nT\nO\n]\n_\n`\nK\na\nb\nS\nc\ne\nf\nT\ne\n`\n\\\nj\ne\nf\n\\\nc\ne\nf\nT\n\\\nT\nO\n]\n_\n`\nO\nl\nT\nn\nO\no\nT\nl\np\nq\nr\nZ\n\\\nT\nO\n]\n_\n`\nu\nl\nj\nQ\nO\n]\nn\ne\nv\nn\na\n`\nS\nf\na\nv\nO\n\\\nT\nO\n]\n_\n`\nK\na\nb\nS\nc\ne\nf\nT\nn\na\n\\\nT\nu\nj\ne\nf\n\\\nc\ne\nf\nT\ne\nO\nO\nT\nV\nN\nv\nQ\n]\n`\nO\nS\nf\nL\nn\nS\n]\na\n`\nO\ny\nL\n\\\n]\nS\nl\nf\na\nn\nT\n\\\nL\nf\nT\nO\nz\nl\nT\nf\ne\nS\na\nf\nV\ne\n`\nL\ne\nv\nO\n|\ne\n]\n`\nS\nT\n`\ne\n`\nn\nT\nX\ne\n~\ne\nf\n\\\ny\n`\ne\nv\nQ\nO\n]\nO\nX\nY\nZ\nV\na\n\\\nT\nv\nO\n\nv\ne\nn\n\nN\na\n\nb\nL\n`\nn\nS\n]\na\n`\ne\nv\nZ\n`\nS\nT\nf\nb\ne\nn\nT\nO\nl\nT\nn\n]\nb\n]\nn\ne\nS\n]\na\n`\nO\nY\na\n`\nO\nS\nf\ne\n]\n`\nS\nO\ny\nO\nO\nL\nV\nl\nS\n]\na\n`\nO\no\nT\n\n]\nT\nc\nO\n\ne\nv\n]\n\\\ne\nS\n]\na\n`\nl\nv\ne\n`\ne\n`\n\\\nf\nT\nO\nL\nv\nS\nO\nu\ny\n`\ne\nv\nQ\nO\n]\nO\nl\nv\ne\n`\nO\ne\n`\n\\\nf\nT\nO\nL\nv\nS\nO\nu\nn\na\n`\nS\nf\na\nv\nv\ne\nc\nO\nu\n\na\n_\n]\nn\nl\nf\n]\n`\nn\n]\nl\nv\nT\nO\nu\nK\nQ\nO\nS\nT\nV\nX\ne\n~\ne\nf\n\\\ny\n`\ne\nv\nQ\nO\n]\nO\n\nf\ne\n]\n`\n]\n`\n_\nV\ne\nS\nT\nf\n]\ne\nv\nO\n\nf\na\n_\np\n|\n_\nV\nS\np\nX\ne\n~\ne\nf\n\\\ny\n`\ne\nv\nQ\nO\n]\nO\nu\n\nf\nT\nv\n]\nV\n]\n`\ne\nf\nQ\nK\nQ\nO\nS\nT\nV\n\nL\nf\nl\na\nO\nT\n\nf\n]\n`\nn\n]\nl\nv\nT\nO\nK\nQ\nO\nS\nT\nV\n\nK\nQ\nO\nS\nT\nV\ny\nf\nn\nj\n]\nS\nT\nn\nS\nL\nf\nT\n\nT\nO\n]\n_\n`\n\nf\nf\na\nf\nf\nT\nl\na\nf\nS\nO\nu\nn\nj\ne\n`\n_\nT\nf\nT\n\nL\nT\nO\nS\nO\nu\nT\nS\nn\np\n\nT\nO\nS\nl\nv\ne\n`\nO\ne\n`\n\\\nf\nT\nO\nL\nv\nS\nO\n\nT\nO\nS\nl\nv\ne\n`\nO\ne\n`\n\\\nf\nT\nO\nL\nv\nS\nO\n\nT\nf\nb\na\nf\nV\ne\n`\nn\nT\nV\na\n`\n]\nS\na\nf\n]\n`\n_\ne\n`\n\\\ne\nL\n\\\n]\nS\nO\no\nT\nl\np\nz\nl\nT\nf\ne\nS\n]\na\n`\nO\n\nj\nQ\nO\n]\nn\ne\nv\n\nV\na\n\\\nT\nv\nO\nz\nl\nT\nf\ne\nS\na\nf\n\ne\nO\n\nK\nQ\nO\nS\nT\nV\n_\na\ne\nv\nO\nu\nj\n]\n_\nj\n\nv\nT\n\nT\nv\nf\nT\n\nL\n]\nf\nT\nV\nT\n`\nS\nO\nu\n\\\nT\nO\n]\n_\n`\nn\na\n`\nO\nS\nf\ne\n]\n`\nS\nO\nu\nv\n]\nV\n]\nS\ne\nS\n]\na\n`\nO\n\nS\nT\nf\n`\ne\nv\n]\n`\nS\nT\nf\nb\ne\nn\nT\nO\nZ\n\nf\nT\n\nL\n]\nf\nT\nV\nT\n`\nS\nO\n\ne\nO\n\ne\n`\ne\nv\nQ\nO\nT\nO\no\nT\n\nL\n]\nf\nT\nV\nT\n`\nS\nO\n\ne\nO\n\ne\nv\nv\na\nn\ne\nS\n]\na\n`\nb\nL\n`\nn\nS\n]\na\n`\ne\nv\n\\\nT\nn\na\nV\nl\na\nO\n]\nS\n]\na\n`\ne\n`\n\\\ne\nv\nv\na\nn\ne\nS\n]\na\n`\n\nf\na\n\nT\nn\nS\nV\ne\n`\ne\n_\nT\nV\nT\n`\nS\nl\nv\ne\n`\nO\nu\nO\nS\ne\nS\nL\nO\n]\n`\nb\na\nf\nV\ne\nS\n]\na\n`\nu\nO\ne\nb\nT\nS\nQ\nl\nv\ne\n`\nu\nT\nS\nn\np\n\n`\n\n]\nf\na\n`\nV\nT\n`\nS\nV\na\n\\\nT\nv\nO\nV\na\n\\\nT\nv\nO\no\nT\nO\nl\na\n`\nO\n]\nN\n]\nv\n]\nS\n]\nT\nO\nY\na\n`\nS\nf\na\nv\nO\nu\n\\\n]\nO\nl\nv\ne\nQ\nO\n\n¡\n¢\n£\n¤\n\n¥\n¦\n\n(c)\na\n«\n¥\n¬\n«\n\n¤\n£\n\n¬\n\n(r)\n¦\n¤\n«\n(r)\n°\n\n±\n(r)\n«\n\n¥\n\n¤\nx\n\nLevel 1: Environment\nDescription of environment in which interacts\nAssumptions about environment\nEA-1: Altitude information is available from intruders with\nminimum precision of 100 feet\nEA-2: All aircraft will have legal identification numbers\nLevel 1: Operator\nPilot Responsibilities and Tasks\nOperator requirements\nOP-5: TCAS advisories shall be executed in such a\nway as to minimize the aircraft's deviation from\nit's ATC clearance\nHuman-Machine Interface Requirements\nHMI-3: A red visual alert shall be provided in the primary field of\nview for each pilot for resolution advisories.\n\nLevel 1 Functional Goals:\nG1: Provide affordable and compatible collision avoidance system\noptions for a broad spectrum of National Airspace users.\nLevel 1 Functional Requirements\nFR-1: TCAS shall provide collision avoidance protection for any\ntwo aircraft closing horizontally at any rate up to 1200 knots\nand vertically up to 10,000 feet per minute.\nAssumption: Commercial aircraft can operate up to 600 knots\nand 5000 fpm during vertical climb or controlled descent and\ntherefore the planes can close horizontally up to 1200 knots\nand vertically up to 10,000 pfm.\n\nRA beyond CPA>\n<Intruder maneuver causes logic to delay\n...\nAltitude reports put threat outside corrective RA position\nto be calculated>\n<Process/display connectors fail>\n<Display hardware fails>\n<Display is preempted by other functions>\nSurveillance does not pass adequate track to the logic\nSurveillance puts threat outside corrective RA position.\nTCAS unit is not providing RAs.\nNo RA is generated by the logic\nInputs do not satisfy RA criteria\nAltitude errors put threat in non-threat position.\n<Surveillance error causes incorrect range or range rate\n1.23.1\n2.22\nSC4.8\n2.35\nSC4.2\n1.23.1\n1.23.1\n2.19\nL.5\n1.23.1\nNo RA inputs are provided to the display.\nTCAS does not display a resolution advisory.\n<Threat is non-Mode C aircraft>\n<Intruder altitude error>\n<Own Mode C altitude error>\n<Own radar altimeter error>\n<Uneven terrain>\n<Surveillance failure>\n...\nAltitude errors put threat on ground\nSensitivity level set such that no RAs are displayed.\n<Self-monitor shuts down TCAS unit>\n...\n\nTCAS displays a resolution advisory that the pilot does not follow.\nPilot does not execute RA at all.\nCrew does not perceive RA alarm.\n<Inadequate alarm design>\n1.4 to 1.14\n2.74, 2.76\n<Crew is preoccupied>\n<Crew does not believe RA is correct.>\nOP.1\n...\nPilot executes the RA but inadequately\n<Pilot stops before RA is removed>\nOP.10\n<Pilot continues beyond point RA is removed>\n<Pilot delays execution beyond time allowed>\n\nOP.4\nOP.10\n\nLevel 1: System Limitations\nL-5: TCAS provides no protection against aircraft with\nnon-operational or non-Mode C transponders [FTA-370]\nμ\n\nLevel-1 Safety Constraints and Requirements\nSC-5: The system must not disrupt the pilot and ATC operations\nduring critical phases of flight nor disrupt aircraft operation.\n[H3]\nSC-5.1: The pilot of a TCAS-equipped aircraft must have the\noption to switch to the Traffic-Advisory mode where traffic\nadvisories are displayed but display of resolution advisories\nis prohibited [2.37]\nAssumption: This feature will be used only during final\napproach to parallel runways when two aircraft are\nprojected to come close to each other and TCAS would\ncall for an evasive maneuver [6.17]\n¶\n\nSC-7: TCAS must not create near misses (result in a hazardous\nlevel of vertical separation that would not have occurred\nhad the aircraft not carried TCAS) [H1]\nSC-7.1: Crossing maneuvers must be avoided if possible.\n[2.36, 2.38, 2.48, 2.49.2]\nSC-7.2: The reversal of a displayed advisory must be extremely\nrare [2.51, 2.56.3, 2.65.3, 2.66]\nSC-7.3: TCAS must not reverse an advisory if the pilot will have\ninsufficient time to respond to the RA before the closest point\nof approach (four seconds or less) or if own and intruder\naircraft are separated by less then 200 feet vertically when\nten seconds or less remain to closest point of approach [2.52]\n·\n\nExample Level-2 System Design for TCAS\nReversal-Provides-More-Separation m-301\nSENSE REVERSALS\n2.51 In most encounter situations, the resolution advisory sense will be\nmaintained for the duration of an encounter with a threat aircraft.\n[ SC-7.2 ]\nHowever, under certain circumstances, it may be necessary for\nthat sense to be reversed. For example, a conflict between two\nTCAS-equipped aircraft will, with very high probability, result in\nselection of complementary advisory senses because of the\ncoordination protocol between the two aircraft. However, if\ncoordination communications between the two aircraft are\ndisrupted at a critical time of sense selection, both aircraft may\nchoose their advisories independently.\n[ FTA-1300 ]\nThis could possibly result in selection of incompatible senses.\n[ FTA-395 ]\n2.51.1 [Information about how incompatibilities are handled]\n\nLevel 3 Specification (modeling) language goals\nSpecify allocation of functionality to components\nReadable and reviewable\nMinimize semantic distance\nMinimal: blackbox behavior only (transfer function)\nEasy to learn\nUnambiguous and simple semantics\nVisualization tools\nComplete (can specify everything need to specify\nAnalyzable (formal, mathematical foundation)\nExecutable (acts as a prototype)\nAnimation and simulation\nTools to check completeness, consistency, nondeterminism\nIncludes human (operator) procedures and analysis\nExtensible (e.g., connecting to MATLAB, Simulink)\nAPI, built on Eclipse\n\nSpecTRM-RL\nCombined requirements specification and modeling language\nA state machine with a domain-specific notation on top of it.\nIncludes a task modeling language\nCan add other notations and visualizations of state machine\nEnforces or includes most of completeness criteria\nSupports specifying systems in terms of modes\nControl modes\nOperational modes\nSupervisory modes\nDisplay modes\no\n»\n\nMeasured Variable 2\nMeasured Variable 1\nDevice\nSupervisor\nControlled\nControl Input\nDisplay Output\nControl\nCommand\nMeasured Variable\n(Feedback)\nSensor\nEnvironment\nCONTROL\nINFERRED SYSTEM OPERATING MODES\nController\nMODES\nDISPLAY\nINFERRED SYSTEM STATE\nSUPERVISORY\nMODE\nMODES\no\n1⁄4\n\nSpecTRM Model of HETE Attitude Control System\nOrbit Day\nOrbit Night\nGround Command\nMODES\nCONTROL\nPaddles\nDetumble\nDeploy Paddles\nReorient\nDeploy Wheel\nAcquire\nOrbit Day\nOrbit Night\nGround Command\nTorque\nElevation Angle\nAzimuth Angle\nBias\nMagnetic Fields (X,Y,Z)\nOrbit\nDeployed\nNot deployed\nUnknown\nUnknown\nNot tracking\nTracking\nOptical System\nUnknown\nNight\nDay\nUnknown\nNot deployed\nDeployed\nWheel\nWheel\nMomentum\nCoils\nDeploy Paddles\nPaddles\nCONTROL\nMODES\nSun\nSensors\nMagnetometers\nAcquire\nDeploy Wheel\nReorient\nDetumble\nSpinup\nWait\nHETE ACS\nOps\nMission\no\n\nControl Mode\nACS Mode (2)\n= Detumble (Mode 1)\nThe purpose of detumble mode is to minimize the magnitude of body momuntum vector in the X-Z plane.\nAs soon as the magnitude falls below a threshold,e software should transition to spinup mode. The mode\ndelay provides hysteresis in the mode transitions to prevent the software from jumping between modes too rapidly.\nIn detumble mode, the wheel actuator shall be controlled such that the wheel maintains the velocity it had upon\nentering the mode, and the magnetic moment along the Y axis shall be controlled to minimize the angular velocity\nabout the X and Z axes.\nOR\nControl Mode\nState Values\nSpinup\nDetumble\nWait\nGround Control\nTime since entered wait >= 10 sec\nTime since entered detumble < 100 sec\nxz momentum error > xz momentum error threshold\nTime since entered spinup >= 100 sec\nPaddles in-state deployed\nOptical system in-state tracking\nTime since entered ground control >= 10 sec\nT\nT\nT\nT\nT\nT\nT\nT\nF\nT\nT\nT\nT\nT\nF\nF\nT\n.\no\no\n\nOutput Command\nName\nDestination:\nAcceptable Values:\nUnits:\nGranularity:\nException Handling:\nHazardous Values:\nTiming Behavior:\nInitiation Delay:\nCompletion Deadline:\nOutput Capacity Assumptions:\nLoad:\nMin time between outputs:\nMax time between outputs:\nHazardous timing behavior:\nException-Handling:\nFeedback Information:\nVariables:\nValues:\nRelationship:\nMin. time (latency):\nMax. time:\nException Handling:\nReversed By:\nComments:\nReferences:\nDEFINITION\n= ...\no\n\nRequirements Analysis\nModel Execution, Animation, and Visualization\nCompleteness\nState Machine Hazard Analysis (backwards reachability)\nHuman Task Analysis\nTest Coverage Analysis and Test Case Generation\nAutomatic code generation\no\nμ\n\nDoes It Work?\nIt is being used for aerospace and automotive systems.\nHave found important errors in requirements\nVery complex systems modeled\nLevel 3 models used to maintain TCAS II for past 10 years\nAll suggested changes and upgrades first modeled\nand evaluated through simulation.\no\n¶\n\nSummary\nIntegrate design rationale and safety information into\nspecification and its structure\nCapture domain knowledge (reusable architectures)\nProvides traceability from high-level requirements to\ndetailed design and code.\nBlackbox models at Level 3\nExecutable and analyzable\ne.g., completeness, robustness, mode confusion, hazard\nanalysis, test case generation, code generation\nSpecification acts as an executable prototype\nCan interface with system simulation\nVisualization tools\nInterface to contractors\no\n·"
    },
    {
      "category": "Resource",
      "title": "cnotes4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/98b70cac8085d893ae06d7bc556a286f_cnotes4.pdf",
      "content": "c\n.\nOutline: Software Design\nGoals\nHistory of software design ideas\nDesign principles\nDesign methods\nLife belt or leg iron? (Budgen)\nCopyright\nNancy Leveson, Sept. 1999\n\nc\nA Little History ...\nAt first, struggling with programming languages, small programs,\nmath algorithms.\nWorried about giving instructions to machine (efficiency)\n\"Think like a computer\"\nFound that life cycle costs depend far more on how well\ncommunicates with people than how fast it runs.\nSeparated the two and more emphasis began on\nHow to write software to communicate algorithms and\nstructure to humans\nHow to structure design process itself.\nCopyright\nNancy Leveson, Sept. 1999\n\nStructured Programming\nGoal: mastering complexity\nDijkstra, Hoare, Wirth:\nConstruction of correct programs requires that programs\nbe intellectually manageable\nKey to intellectual manageability is the structure of the\nprogram itself.\nDisciplined use of a few program building blocks facilitates\ncorrectness arguments.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nStructured Programming (2)\nRestricted control structures\nLevels of abstraction\nStepwise refinement\nProgram families\nAbstract data types\nSystem structure:\nProgramming-in-the-large vs. programming-in-the-small\nModularization\nMinimizing connectivity\nCopyright\nc Nancy Leveson, Sept. 1999\n\nRestricting Control Structures\nDijkstra: 3 main mental tools\nEnumerative reasoning\nMathematical induction\nAbstraction (e.g., variable, procedure, data type)\n1. Restrict programs to constructs that allow us to use\nthese mental aids.\nSequencing and alternation (enumeration)\nIteration and recursion (induction)\nProcedures, macros, and programmer-defined data types\nSESX\nSmall procedures\nMake program structure fit problem structure.\n2.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nLevels of Abstraction\n1968: Dijkstra paper on his experiences with T.H.E.\nMultiprograming system\nDesigned using \"levels of abstraction\"\nSystem design described in layers\nHigher levels could use services of lower levels\nLower levels could not access higher levels\nLowest level implemented first\nProvided a \"virtual machine\" for implementation of next level\nProcess continued until highest level completed.\nA \"bottom up\" technique\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nStepwise Refinement\nWirth (1971): \"Divide and conquer\"\nA top-down technique for decomposing a system from\npreliminary design specification of functionality into more\nelementary levels.\nProgram construction consists of sequence of refinement steps.\nUse a notation natural to problem as long as possible.\nRefine function and data in parallel.\nEach refinement step implies design decisions. Should be\nmade explicit.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nCopyright\nc Nancy Leveson, Sept. 1999\nPrime Number Program\nbegin var table p;\nfill table p with first 1000 prime numbers\nprint table p\nend\nAssumes type \"table\" and two operators\nDesign decisions made:\nAll primes developed before any printed\nAlways want first 1000 primes\nDecisions not made:\nRepresentation of table\nMethod of calculating primes\nPrint format\n\nc\nCopyright\nNancy Leveson, Sept. 1999\nProgram Families\nBasic premise: Software will inevitably exist in many versions\nDifferent services for slightly different markets\nDifferent hardware or software platforms\nDifferent resource tradeoffs (speed vs. space)\nDifferent external events and devices\nBug fixes\nThink of development as a tree rather than a line\nNever modify a completed program\nAlways begin with one of intermediate forms\nContinue from that point making design decisions\nOrder of decisions important in how far have to back up.\nMake early decisions only those that can be shared by\nall family members\nPut off decisions as long as possible.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nAbstract Data Types\nDefines a class of objects completely characterized by\noperations available on those objects.\nReally just programmer-defined data type\nBuilt-in types work same way\nAllows extending the type system\nPascal, Clu, Alphard, Ada\nWant language to protect from foolish uses of types\n(strong typing or automatic type conversion)\nCriteria:\n1. Data type definition must include definitions of all\noperations applicable to objects of the type.\n2. User of ADT need not know how objects of type\nare represented in storage\n3. User of ADT may manipulate objects only through\ndefined operations and not by direct manipulation\nof storage representation.\n\nc\nCopyright\nNancy Leveson, Sept. 1999\nSystem Structure\nDeRemer and Kron (1976):\nStructuring a large set of modules to form a system is an\nessentially distinct and different intellectual activity from\nthat of constructing the individual modules (programming\nin the large, MILs)\nActivity of producing detailed designs and implementations\nis programming in the small.\nModularization\nWant to minimize, order, and make explicit the connections\nbetween modules.\nCombining modularity with hierarchical abstraction turned\nout to be a very powerful combination (part-whole and\nrefinement abstractions)\n\nCopyright\nc Nancy Leveson, Sept. 1999\nModule Specification\nStarted to distinguish between design and \"packaging\"\nDesign is process of partitioning a problem and its solution\ninto significant pieces.\nPackaging is process of clustering pieces of a problem\nsolution into computer load modules that run within system\ntime and space constraints without unduly compromising\nintegrity of original design.\nOptimization should only be considered in packaging and\ncare should be taken to preserve design structure.\nReuse\nAssumed hundreds of reusable building-block modules\ncould be abstracted and added to program libraries.\nWhy didn't happen?\n\nCopyright\nc Nancy Leveson, Sept. 1999\nStepwise Refinement vs. Module Specification\nSR: Intermediate steps are programs that are complete except\nfor implementation of certain operators and operands.\nMS: Intermediate stages are not programs. Instead they are\nspecifications of externally visible collective behavior of\nprogram groups called modules.\nSimilarities\nPrecise representation of intermediate stages in program\ndesign.\nPostponement of decisions: Important decisions postponed\nuntil late stages or confined to well-delineated subset of\ncode.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nStepwise Refinement vs. Module Specification (2)\nDifferences\nDecision Making\nSR: Decision-making order critical. May have to backtrack\nmore than really want. Sequencing decisions made\nearly because intermediate reps are programs.\nMS: May be easier to reverse decisions without repeating\nso much work. Sequencing decisions made last.\nEffort\nSR: Less work than either classical approach (because\nkeeps complexity in control) or MS.\nMS: Significant amount of extra effort because only works\nif external characteristics of each module sufficiently\nwell specified that code can be written without looking\nat implementation of other modules. In return, get\nindependent development potential.\n\nCopyright\nNancy Leveson, Sept. 1999\nMinimizing Connectivity\nc\nYourdan; Constantine and Myers\nCohesion: relationship between functions a module provides\nCoupling: relationship between modules, intermodule\nconnections\nIntermodule Friction\nSmaller modules tend to be interfaced by \"larger surfaces\"\nReplacement of module with large interface causes\nfriction, requiring rewrites in other modules.\nUses relationship\nPrimary goal: locality of visibility\n\nCopyright\nNancy Leveson, Sept. 1999\nMinimizing Connectivity (2)\nc\nAdvantages of reducing connectivity (coupling)\nIndependent development (decisions made locally, do not\ninterfere with correctness of other modules).\nCorrectness proofs easier to derive\nPotential reusability increased.\nReduction in maintenance costs (less likely changes will\npropagate to other modules)\nComprehensibility (can understand module independent of\nenvironment in which used).\nSome studies show less error-prone."
    },
    {
      "category": "Resource",
      "title": "cnotes5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/5c4493536832111845f291d3d62a6f38_cnotes5.pdf",
      "content": "Copyright\nc Nancy Leveson, Sept. 1999\n1980s:\nOO design: added inheritance, multiple inheritance, and\npolymorphism to ADT.\nIn process added complexity and increased\nsome types of connectivity.\nLots of claimed advantages -- so far empirical\nevaluation is not supporting them well.\n1990s:\nArchitecture\nPatterns\nFrameworks\nKits\netc.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nSoftware Design Principles\nDesign is a creative, problem-solving activity.\nNo recipe for doing it - always need some type of \"magic\".\nQuality and expertise of designers is determinant for success.\nSimon: An expert has over 50,000 chunks of domain\nknowledge at hand.\nSolving a problem involves mapping into knowledge\navailable.\nThe larger this knowledge and the more accessible,\nthe more successful the process will be.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nSoftware Design Principles (2)\nBrooks, Curtis: Successful software development often\ndepends on small number of exceptional designers who\n\"think on a system level.\"\nCurtis: Such people might not be particularly good\nprogrammers.\nDesign problem: How to decompose system into parts\neach with a lower complexity than system as a whole\nwhile minimizing interaction between the parts\nsuch that the parts together solve the problem.\nNo universal way of doing this.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nFour Primary Design Principles\n1. Separation of concerns\nDeal with separate aspects of a problem separate.\n2. Abstraction\nIdentify important aspects of a phenomenon and ignore\ndetails that are irrelevant at this stage.\nHierarchical abstraction: build hierarchical layers of abstraction\nProcedural (functional) abstraction\nData abstraction\nControl abstraction (abstract from precise sequence of\nevents handled, e.g., nondeterminacy)\n\nCopyright\nc Nancy Leveson, Sept. 1999\nFour Primary Design Principles (2)\n3. Simplicity\nEmphasis on software that is clear, simple, and\ntherefore easy to check, understand, and modify.\n4. Restricted visibility\nLocality of information\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGeneral Software Design Concepts\nImplementations of the general principles\nDecomposition\nCan decompose with respect to time order, data flow,\nlogical groupings, access to a common resource,\ncontrol flow, or some other criterion.\nFunctional decomposition seems to be a natural way for\npeople to solve problems as evidenced by its wide use.\nTop-down decomposition: start at high levels of abstraction\nand progress to levels of greater and greater detail.\nBottom-up: form and layer groups of instruction sequences\nuntil work way up to a complete solution.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGeneral Software Design Concepts (2)\nDecomposition (con't.)\nIterative decision making process:\nList difficult decisions and decisions likely to change\nDesign a module specification to hide each such decision\nBreak module into further design decisions.\nContinue refining until all design decisions hidden\nin a module\nProgram Families: design for flexibility, not generality\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGeneral Software Design Concepts (3)\nVirtual Machines\nA module provides a virtual machine: a set of operations\nthat can be invoked in a variety of ways and orders to\naccomplish a variety of tasks.\nDon't think of systems in terms of components that\ncorrespond to steps in processing.\nDo provide a set of virtual machines that are useful for\nwriting many programs.\nInformation Hiding\nEach design unit hides internal details of processing activities.\nDesign units communicate only through well-defined interfaces.\nEach design unit specified by as little information as possible\nIf internal details change, client units should need no change\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGeneral Software Design Concepts (4)\nModularity\nSeparation of concerns:\n1. Deal with details of each module in isolation (ignoring\ndetails of other modules)\n2. Deal with overall characteristics of all modules and their\nrelationships in order to integrate them into a coherent\nsystem.\nBase on hierarchy and abstraction:\nAbstraction handled through information hiding\nHierarchy by defining uses and is-composed-of relations\nMinimize connectivity\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGeneral Software Design Concepts (5)\nModularity (con't.)\nSample things to modularize and encapsulate:\nabstract data types\nalgorithms (e.g., sort)\ninput and output formats\nprocessing sequence\nmachine dependencies (e.g., character codes)\npolicies (e.g., when and how to do garbage collection)\nexternal interfaces (hardware and software)\nBenefits:\nAllows understanding each part of a system separately\nAids in modifying system\nMay confine search for a malfunction to a single module.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nDesign Methods\nSet of guidelines, heuristics, and procedures on how to go\nabout designing a system.\nUsually offer a notation to express result of design process.\nTrying to provide a systematic means for organizing the\ndesign process and its products.\nDesign method may be based on:\nFunctional decomposition\nData flow\nData structures\nControl flow\nObjects\nVary in degree of prescriptiveness\n\nCopyright\nc Nancy Leveson, Sept. 1999\nDavid Budgen, Software Design Methods: Life Belt\nor Leg Iron (IEEE Software, Sept/Oct. 99)\nWill the adoption of a design method help the software\ndevelopment process (be a \"life belt\") or is there significant\nrisk that its use will lead to suboptimum solution (be a\n\"leg iron\")?\nArgument:\nTwo general design characteristics:\n1. \"Wicked\" nature of any design process:\nAdopting a particular solution approach to a problem\nmay make task of solving it more intractible, i.e., the\ndesign process is not neutral.\n2. Expert designers engage in opportunistic behavior:\nAs solution's form emerges, problem solving strategy\nis adapted to meet new characteristics that are revealed,\ni.e., expert designers do not follow a single method.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nThese challenge the belief that good software engineering design\nsolutions will most likely come from systematically following a\nprescriptive procedural method.\n60s and 70s: people recognized that a systematic approach to\ndevelopment needed to cope with large-scale projects. Needed\na way to promulgate and encourage the adoption of desirable\npractices.\nA procedural form (do this, then do this, then this ...) lent\nitself to this role.\nAlso easily conveyed through books and courses, easy to\nteach, easy to write exam questions.\nYourdan, Michael Jackson, etc.\nMet some real needs.\nBy late 70s, use of procedural form was entrenched.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nBut some good practices that did not lend themselves to such a\nform, e.g., information hiding (for which no satisfactory form of\nprocedural development practice has yet been devised).\nReaction in 80s to shortcomings was to \"pile more on\"\nMore diagrammatical forms\nMore models\nMore complexity\n\"Arguably, much of this complexity stems from the paradox of\nobject orientation, which seems to provide excellent paradigms\nfor analysis and implementation, but present major difficulties\nfor the designer.\"\nIn 90s, attempts to develop other paradigms for transferring design\nknowledge, e.g., patterns and architectures.\n\nPeculiarity of software design: extent to which commercial\ninterests have dominated the codifying of associated practices\nMore widely known design methods have been developed\nand marketed largely by consultants and commercial\norganizations.\nNot true for requirements or testing\nSuggests a real need for design skills, but does not create\nan objective forum for evaluation.\nConclusions:\nLife belt has become waterlogged and acting more like a leg iron.\nNeed to stop pretending that software design is largely a matter\nof following a set of well-defined activities. Recognize it as a\ncreative process that requires us to develop design skills needed\nto build software systems of the future.\nHow do we identify, grow, and encourage those talents needed\nfor the great designers who will create elegant and effective\nsolutions to problems?"
    },
    {
      "category": "Resource",
      "title": "cnotes6.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/e2c44b1eee0792b7da412b01108bbefe_cnotes6.pdf",
      "content": "Copyright\nc Nancy Leveson, Sept. 1999\nReuse\n(Assume have source code, not a commercial product)\nAriane 5, Therac-25, British ATC, ...\nExpectation:\nSignificantly lower development costs and time. Amortize\ncosts among all users or uses.\nAssumptions:\nWill be reused enough to recoup extra costs\nCan easily and cheaply integrate components into a new\nenvironment (interoperability).\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nReuse: Empirical Data\nHigh reuse in some limited environments, not widespread\nhowever.\nNASA Goddard Study\nGarlan, Allen, Ockerbloom:\nPerformance problems (from large size and complexity)\nComplexity frequently inappropriate for tasks performed.\nTrouble fitting components together.\nIn some cases, took significant reengineering to make\nthe interoperate properly.\nMaintaining synthesized system difficult in absence\nof low-level understanding.\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nReuse: Empirical Data (2)\nSiemens (hardware ASICs) reuse study:\nTime to build a reusable component can be 120-150%\nof time needed to develop component for single use\n(excludes documentation).\nFor reusuable component, needed to develop new\ndocumentation -- took one to two times the effort\nof designing the component.\nOverhead to develop a reusable component (design + doc)\nrecaptured after fifth use.\nFrequency of reuse increases with degree of comprehensibility.\nHabitability even more important: measure of how \"at home\"\na potential user of reusable component feels. Highly\nsubjective but effect even greater than that of comprehensibility.\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nReuse: Technical Issues\nConfiguration control problems\nMay change continuously (any developer may be able to\ncheck out and change).\nUnneeded functionality (interoperability and performance issues)\nMay need to write software utilities (restrictive wrappers)\nto restrict functionality.\nMuch of savings may be offset by need for more testing\n(Weyuker)\nDebugging may be significantly more difficult (Weyuker)\nLongevity -- does ppotential for reuse decrease over time?\nReuse designs rather than finished products?\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nReuse: Other\nManagement issues (e.g., reward structures)\nPlatforms and reuse at Xerox (hopefully, one of the Xerox\nstudents can tell us about this).\nOne organization within Xerox reports they use half\ndozen different software platforms to build half dozen\ndifferent products.\nAchieve approximately 80-90% reuse\nOther comments or experiences?\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nCOTS\nMain difference from reuse is lack of source code\nPotential advantages:\nReduce front-end acquisition or development costs.\nAmortize costs over large number of users.\nCompensate for lack of expertise (Shelley Hayes)\nAllow for more rapid infusion of technology\nBut new risk drivers\nLoss of market control (less control leads to higher risks)\nHigh speed market\nMust deal with rapid obsolescence (shortened lifetimes)\nNew versions or releases brought to market frequently.\nFor government, shift from \"buyer's market\" to \"seller's market\"\n\nCopyright\nc Nancy Leveson, Sept. 1999\nCOTS: Management Issues\nLower development costs offset by higher lifetime costs?\n\"Sustainment\" costs substantial -- need to be planned and\nmanaged.\nWhat if vendor goes out of business or stops producing\nand will not maintain old versions?\nEven if escrow agreements, hard to maintain software\nyou did not write and must hire developers expert in\nthat code.\nDependency on vendor. Can charge anything or make\nother demands (e.g., Microsoft case findings of fact).\nHigher speed of change requires greater strategic flexibility.\nRequires flexible and proaction system evolution management.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nCOTS: Technical Issues\nFunctionality provided may not remain what you need\nover time.\nFew parts in a software system truly independent.\nMay need wrappers and patches as substitutes for\nreal source-code-based maintenance.\nDifferences (e.g., timing) may be introduced in new products\nWhat happens when support from COTS vendor ceases?\nCan user change requests be satisfied?\nMay be Trojan horses or security flaws in COTS software\nand almost certainly will not know until too late.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nCOTS: Technical Issues (2)\nMust be accepted \"as is\" and may not satisfy user\nrequirements. Compromises may be required.\nMay be difficult or impossible to certify (safety).\nNeed to defend yourself from mistakes in supplier's code.\nDeveloped to commercial not government or safety standards.\nRequires continuous lifetime system engineering effort.\nIdentify and integrate product obsolescence information\nwith technology trends and new user requirements.\n\nYour experiences and comments:\n.\n."
    },
    {
      "category": "Resource",
      "title": "cnotes7.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/2595db843b206fcaa30fc563a3c1db94_cnotes7.pdf",
      "content": "Software Metrics\n1.\nLord Kelvin, a physicist\n2.\nGeorge Miller, a psychologist\n\nSoftware Metrics\nProduct vs. process\nMost metrics are indirect:\nNo way to measure property directly or\nFinal product does not yet exist\nFor predicting, need a model of relationship of predicted variable\nwith other measurable variables.\nThree assumptions (Kitchenham)\n1. We can accurately measure some property of software or process.\n2. A relationship exists between what we can measure and\nwhat we want to know.\n3. This relationship is understood, has been validated, and can be\nexpressed in terms of a formula or model.\nFew metrics have been demonstrated to be predictable or related\nto product or process attributes.\n\nSoftware Metrics (2)\n.\nCode\nStatic\nDynamic\nProgrammer productivity\nDesign\nTesting\nMaintainability\nManagement\nCost\nDuration, time\nStaffing\n\nCode Metrics\nEstimate number of bugs left in code.\nFrom static analysis of code\nFrom dynamic execution\nEstimate future failure times: operational reliability\n\nStatic Analysis of Code\nHalstead's Software Physics or Software Science\nn1 = no. of distinct operators in program\nn2 = no. of distinct operands in program\nN1 = total number of operator occurrences\nN2 = total number of operand occurrences\nProgram Length: N = N1 + N2\nProgram volume: V = N log 2 (n1 + n2)\n(represents the volume of information (in bits) necessary\nto specify a program.)\nSpecification abstraction level: L = (2 * n2) / (n1 * N2)\nProgram Effort: E = (n1 + N2 * (N1 + N2) * log2 (n1 + n2)) / (2 * n2)\n(interpreted as number of mental discrimination required\nto implement the program.)\n\nMcCabe's Cyclomatic Complexity\nHypothesis: Difficulty of understanding a program is\nlargely determined by complexity of control flow graph.\nCyclomatic number V of a connected graph G is the\nnumber of linearly independent paths in the graph or\nnumber of regions in a planar graph.\nR1\nR2\nR4\nR5\nR3\nClaimed to be a measure of testing diffiiculty and\nreliability of modules.\nMcCabe recommends maximum V(G) of 10.\n\nStatic Analysis of Code (Problems)\nDoesn't change as program changes.\nHigh correlation with program size.\nNo real intuitive reason for many of metrics.\nIgnores many factors: e.g., computing environment,\napplication area, particular algorithms implemented,\ncharacteristics of users, ability of programmers,.\nVery easy to get around. Programmers may introduce\nmore obscure complexity in order to minimize\nproperties measured by particular complexity metric.\n\nStatic Analysis of Code (Problems con't)\nSize is best predictor of inherent faults remaining\nat start of program test.\nOne study has shown that besides size, 3 significant\nadditional factors:\n1. Specification change activity, measured in pages of\nspecification changes per k lines of code.\n2. Average programmer skill, measured in years.\n3. Thoroughness of design documentation, measured\nin pages of developed (new plus modified) design\ndocuments per k lines of code.\n\nBug Counting using Dynamic Measurement\nEstimate number remaining from number found.\nFailure count models\nError seeding models\nAssumptions:\nSeeded faults equivalent to inherent faults in\ndifficulty of detection.\nA direct relationship between characteristics and\nnumber of exposed and undiscovered faults.\nUnreliability of system will be directly proportional\nto number of faults that remain.\nA constant rate of fault detection.\n\nBug Counting using Dynamic Measurement (2)\nWhat does an estimate of remaining errors mean?\nInterested in performance of program, not in how\nmany bugs it contains.\nMost requirements written in terms of operational\nreliability, not number of bugs.\nAlternative is to estimate failure rates or future\ninterfailure times.\n\nEstimating Failure Rates\nInput-Domain Models: Estimate program reliability\nusing test cases sampled from input domain.\nPartition input domain into equivalence classes,\neach of which usually associated with a program path.\nEstimate conditional probability that program correct\nfor all possible inputs given it is correct for a specified\nset of inputs.\nAssumes outcome of test case given information about\nbehavior for other points close to test point.\nReliability Growth Models: Try to determine future\ntime between failures.\n\nReliability Growth Models\nSoftware Reliability: The probability that a program\nwill perform its specified function for a stated time\nunder specified conditions.\nExecute program until \"failure\" occurs, the underlying\nerror found and removed (in zero time), and resume\nexecution.\nUse a probability distribution function for the interfailure\ntime (assumed to be a random variable) to predict future\ntimes to failure.\nExamining the nature of the sequence of elapsed times\nfrom one failure to the next.\nAssumes occurrence of software failures is a stochastic\nprocess.\n\nSoftware Uncertainty\nAssumption: The mechanism that selects successive\ninputs during execution is unpredictable (random).\nProgram p\nF\nI\nInput space I\nO F\nOutput space O\nO\nis the image set of I F under the mapping p\nF\n\nSample Interfailure Times Data\nExecution time in seconds between successive failures.\n(Read left to right in rows).\n\nUsing the Models\nLV\nJM\n40 50 60 70 80 90 100 110 120 130\nDifferent models can give varying results for the same\ndata; there is no way to know a priori which model\nwill provide the best results in a given situation.\n''The nature of the software engineering process is too\npoorly understood to provide a basis for selecting a\nparticular model.\"\n\nProblems with Software Reliability Modeling\nThere is no physical reality on which to base our assumptions.\nAssumptions are not always valid for all, or any, programs:\nSoftware fault (and failures they cause) are independent.\nInputs for software selected randonly from an input space.\nTest space is representative of the operational input space.\nEach software failure is observed.\nFaults are corrected without introducing new ones.\nEach fault contributes equally to the failure rate.\nData collection requirements may be impractical.\n\nSoftware Requirements Metrics\nFairly primitive and predictive power limited.\nFunction Points\nCount number of inputs and output, user interactions, external\ninterfaces, files used.\nAssess each for complexity and multiply by a weighting factor.\nUsed to predict size or cost and to assess project productivity.\nNumber of requirements errors found (to assess quality)\nChange request frequency\nTo assess stability of requirements.\nFrequency should decrease over time. If not, requirements\nanalysis may not have been done properly.\n\nProgrammer Productivity Metrics\nBecause software intangible, not possible to measure directly.\nIf poor quality software produced quickly, may appear to be more\nproductive than if produce reliable and easy to maintain software\n(measure only over software development phase).\nMore does not always mean better.\nMay ultimately involve increased system maintenance costs.\nCommon measures:\nLines of source code written per programmer month.\nObject instructions produced per programmer month.\nPages of documentation written per programmer month.\nTest cases written and executed per programmer month.\n\nProgrammer Productivity Metrics (2)\nTake total number of source code lines delivered and divide by\ntotal time required to complete project.\nWhat is a source line of code? (declarations? comments? macros?)\nHow treat source lines containing more than a single statement?\nMore productive when use assembly language? (the more expressive\nthe language, the lower the apparent productivity)\nAll tasks subsumed under coding task although coding time represents\nsmall part of time needed to complete a project.\nUse number of object instructions generated.\nMore objective.\nDifficult to estimate until code actually produced.\nAmount of object code generated dependent on high-level\nlanguage programming style.\n\nProgrammer Productivity Metrics (3)\nUsing pages of documentation penalizes writers who take time to\nexpress themselves clearly and concisely.\nSo difficult to give average figure.\nFor large, embedded system may be as low as 30 lines/programmer-month.\nSimple business systems may be 600 lines.\nStudies show great variability in individual productivity. Best are\ntwenty times more productive than worst.\n\nSoftware Design Metrics\nNumber of parameters\nTries to capture coupling between modules.\nUnderstanding modules with large number of parameters will\nrequire more time and effort (assumption).\nModifying modules with large number of parameters likely to have\nside effects on other modules.\nNumber of modules.\nNumber of modules called (estimating complexity of maintenance).\nFan-in: number of modules that call a particular module.\nFan-out: how many other modules it calls.\nHigh fan-in means many modules depend on this module.\nHigh fan-out means module depends on many other modules.\nMakes understanding harder and maintenance more time-consuming.\n\nSoftware Design Metrics (2)\nData Bindings\nTriplet (p,x,q) where p and q are modules and X is variable\nwithin scope of both p and q\nPotential data binding:\n-\nX declared in both, but does not check to see if accessed.\n-\nReflects possibility that p and q might communicate through the\nshared variable.\nUsed data binding:\n- A potential data binding where p and q use X.\n- Harder to compute than potential data binding and requires more\ninformation about internal logic of module.\nActual data binding:\n- Used data binding where p assigns value to x and q references it.\n- Hardest to compute but indicates information flow from p to q.\n\nSoftware Design Metrics (3)\nCohesion metric\nConstruct flow graph for module.\n- Each vertex is an executable statement.\n- For each node, record variables referenced in statement.\nDetermine how many independent paths of the module go through\nthe different statements.\n- If a module has high cohesion, most of variables will be used by\nstatements in most paths.\n- Highest cohesion is when all the independent paths use all the\nvariables in the module.\n\nManagement Metrics\nTechniques for software cost estimation\n1. Algorithmic cost modeling:\nModel developed using historical cost information that\nrelates some software metric (usually lines of code) to\nproject cost.\nEstimate made of metric and then model predicts effort required.\nThe most scientific approach but not necessarily the most\naccurate.\n2. Expert judgement\n3. Estimation by analogy: useful when other projects in same\ndomain have been completed.\n\nManagement Metrics (2)\n4. Parkinson's Law: Work expands to fill the time available.\nCost is determined by available resources\nIf software has to be developed in 12 months and you have\n5 people available, then effort required is estimated to be 60\nperson months.\n5. Pricing to win: estimated effort based on customer's budget.\n6. Top-down estimation: cost estimate made by considering overall\nfunction and how functionality provided by interacting sub-functions.\nMade on basis of logical function rather than the components\nimplementing that function.\n7. Bottom-up function: cost of each component estimated and then\nadded to produce final cost estimate.\n\nAlgorithmic Cost Modeling\nBuild model by analyzing the costs and attributes of completed projects.\nDozens of these around -- most well-known is COCOMO.\nAssumes software requirements relatively stable and project will be\nwell managed.\nBasic COCOMO uses estimated size of project (primarily in terms\nof estimated lines of code) and type of project (organic, semi-detached,\nor embedded).\nEffort = A * KDSIb\nwhere A and b are constants that vary with type of project.\nMore advanced versions add a series of multipliers for other factors:\nproduct attributes (reliability, database size, complexity)\ncomputer attributes (timing and storage constraints, volatility)\npersonnel attributes (experience, capability)\nproject attributes (use of tools, development schedule)\nand allow considering system as made up of non-homogeneous\nsubsystems.\n\nEvaluation of Management Metrics\nParameters associated with algorithmic cost models are highly\norganization-dependent.\nMohanty: took same data and tried on several models. Estimates\nranged from $362,000 to $2,766,667.\nAnother person found estimates from 230 person-months to\n3857 person-months.\nRelies on the quantification of some attribute of the finished\nsoftware product but cost estimation most critical early in\nproject when do not know this number.\nLines of code: very difficult to predict or even define.\nFunction points:\n- Heavily biased toward a data processing environment\nAssessment of complexity factors leads to wide variations\n-\nin estimates.\n\nEvaluation of Management Metrics (2)\nValue of parameters must be determined by analysis of historical\nproject data for organization. May not have that data or may no\nlonger be applicable (technology changes quickly).\nNeed to be skeptical of reports of successful usage of these models.\nProject cost estimates are self-fulfilling: estimated often used to\ndefine project budget and product adjusted so that budget figure\nis realized.\nNo controlled experiments.\nSome interesting hypotheses (that seem to be well accepted):\nTime required to complete a project is a function of total effort\nrequired and not a function of number of software engineers involved.\n- A rapid buildup of staff correlates with project schedule slippages\n- Throwing people at a late project will only make it later.\n\nEvaluation of Management Metrics (3)\nProgrammer ability swamps all other factors in factor analyses.\nAccurate schedule and cost estimates are primarily influenced by\nthe experience level of those making them.\nWarning about using any software metrics:\nBe careful not to ignore the most important factors simply\nbecause they are not easily quantified."
    },
    {
      "category": "Resource",
      "title": "cnotes8.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/e63235a79344dd6698c6aac23285f380_cnotes8.pdf",
      "content": "What is Testing?\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nBasic Testing Guidelines\nA test case has two parts:\n1. Description of input data\n2. Precise description of correct output for that input\nA programmer should avoid testing his or her programs.\nA programming organization should not test its own programs.\nThe results of each test should be thoroughly inspected (lots\nof errors are missed).\nTest cases must be written for invalid and unexpected as\nwell as valid and expected input conditions.\nCopyright\nc Nancy Leveson, Sept. 1999\n\nBasic Testing Guidelines (2)\nExamining a program to see if it does not do what it is\nsupposed to do is only half the battle. The other half is\nseeing whether the program does what it is not supposed\nto do (i.e., must examine for unintended function and\nside effects.\nAvoid throw-away test cases unless the program is a\nthrow-away program.\nTest cases are a valuable investment -- regression\ntesting.\nDo not plan a testing effort under the tacit assumption that\nno errors will be found.\nc\nCopyright\nNancy Leveson, Sept. 1999\n\nBasic Testing Guidelines (3)\nThe probability of the existence of more errors in a section\nof a program is proportional to the number of errors already\nfound in it.\nprob.\nof\nmore\nerrors\n# errors already found\nTesting is an extremely creative and challenging task.\nExceeds creativity required in designing program.\nDon't put your worst or newest people here.\nA good test case is one that has a high probability of\ndetecting an as-yet undiscovered error.\nCopyright\n\nNa ncy Leveson, Sept. 1999\n\nBuilding Assurance (Confidence)\nDynamic Analysis\nStatic Analysis\nQuality Assurance (conformance to standards)\nV&V of non-software lifecycle products (e.g., user manual)\nAcceptance (user) testing\nCopyright\nc\nNancy Leveson, Sept. 1999\n\nDynamic Analysis\nMonitoring run-time behavior\nAutomated test case generation\nCoverage analysis\nAssertions\nTesting\nWhite Box\nBlack Box\n\nBlack Box Testing\nis impractical.\nSo for most programs, exhaustive input testing\nvalid and invalid sequences.\nIf program has ''memory'', need to test all possible unique\nvalid and invalid programs)\nAlso all invalid input (e.g., testing Ada compiler requires all\nValid inputs up to max size of machine (not astronomical)\n(since black box, only way to be sure to detect\nthis is to try every input condition)\nx := y * 2\nif x = 5 then y := 3\nNeed to test every possible input\nTest data derived solely from specification (i.e.,\nwithout knowledge of internal structure of program).\n\nl\nWhite Box Testing\nDerive test data by examining program's logic.\nExhaustic path testing: Two flaws\n1) Number of unique paths through program is astronomical.\noop 20x\n+ 5\n+ 5\n+ ... + 5 = 10\n= 100 trillion\nIf could develop/execute/verify one\ntest case every five minutes = 1 billion years\nIf had magic test processor that could\ndevelop/execute/evaluate one test per\nmsec = 3170 years.\n(control-flow graph)\n\nWhite Box Testing (con't)\n2) Could test every path and program may still have errors!\nDoes not guarantee program matches specification,\ni.e., wrong program.\nMissing paths: would not detect absence of necessary paths\nCould still have data-sensitivity errors.\ne.g. program has to compare two numbers for convergence\nif (A - B) < epsilon ...\nis wrong because should compare to abs(A - B)\nDetection of this error dependent on values used for A\nand B and would not necessarily be found by executing\nevery path through program.\n\nStatic Analysis\nSyntax checks\nLook for error-prone constructions\n(enforce standards)\nProgram structure checks\nGenerate graphs and look for structural flaws\nModule interface checks\nDetect inconsistencies in declarations of data structures\nand improper linkages between modules\nHuman Reviews\nChecklists (inspections)\nWalkthroughs (reviews)\n\nStatic Analysis (con't)\nEvent sequence checking\nCompare event sequences in program with\nspecification of legal sequences\nSymbolic execution\nA := X + 5\nB = 2 * (X + 5)\nB := 2 * A\nif 2 * (X + 5) > 0\nIf B>0 then C := |B| - 1\nthen |2 * (X + 5)| - 1\nelse C := |B| + 1\nelse |2 * (X + 5)| + 1\nFormal verification\nUse theorem proving methods to show equivalence of\ncode and a formal specification of required behavior.\n\nFormal Design Reviews\nAssociated with each of documentation phases.\nEvaluate with respect to:\nCustomer requirements\nPrescribed standards and practices\nContractual requirements\nTradeoff priorities\nResults of previous phases\netc.\nAfter review, released to configuration control and\nbecomes baseline.\n\nStructured Walkthroughs\n''Egoless programming'' (Weinberg,The Psychology of Computer\nProgramming)\nReviewee and 3-5 reviewers\nCustomers and users should be included. Managers should not.\nGoal is to discover and note problems. Problems not resolved\nin walkthrough session.\nFollowup meeting or memo to inform reviewers of actions taken.\nMajor problems only.\nSuccessful use dependent on establishing a positive, nonthreatening\natmosphere.\nModerator should receive training.\nMust not be used as vehicles for employee evaluation.\n\nBenefits of Walkthroughs\nErrors caught at earliest possible time.\nGreatly improved software quality.\nProject communication improved.\nSoftware easier to maintain.\nBetter project control.\nQuicker integration of new personnel.\nIncreased programmer expertise.\nLess disruption with personnel leave.\nSwitch emphasis from individual contemplation to clear,\nprecise communication with others.\nEnhanced employee morale: social interaction, involvement.\n\nSoftware Inspections\nStarted by IBM in 1972 (Fagan)\nProcess driven by a checklist of likely errors\nBuild checklists through experience and feedback.\nSome companies consider checklists proprietary.\nPerformed after design complete and after coding complete.\nLast about 2 hours, cover about 100 statements per hour.\nEvaluation of walkthroughs and inspections:\nFind about 70-80% of errors.\nMost errors found before unit testing."
    },
    {
      "category": "Resource",
      "title": "cnotes9.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/5ab720f0c9da832dd1ce8737ad21131a_cnotes9.pdf",
      "content": "Copyright\nc Nancy Leveson, Sept. 1999\nProgramming Languages\nAs difficult to discuss rationally as religion or politics.\nProne to extreme statements devoid of data.\nExamples:\n\"It is practically impossible to teach good programming to\nstudents that have had a prior exposure to BASIC; as\npotential programmers they are mentally mutilated beyond\nhope of regeneration.\" (Dijkstra)\n\"The use of COBOL cripples the mind; its teaching should,\ntherefore, be regarded as a criminal offence.\" (Dijkstra)\nLike anything else, decision making should be a rational\nprocess based on the priorities and features of the project.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nSome Decision Factors\nFeatures of application:\nHard real time?\nNot just efficiency\nPredictability (need to guarantee deadlines will be met)\nHigh assurance?\nPortability?\nMaintainability?\nOthers?\nFeatures of development environment:\nAvailability of programmers, compilers, development tools?\nSchedule constraints?\nOthers?\n\nCopyright\nc Nancy Leveson, Sept. 1999\nRelationship between PL and Correctness\nDecreasing emphasis as an explicit design goal and\nresearch topic.\nMasterability\nNot complex: programmers understand it in its entirety\nThe most important decisions in language design concern\nwhat is to be left out.\" (Wirth)\nPowerful features OK only if easy to use correctly.\nBalance against need to keep language simple\n\"Natural\"\nLanguage should not surprise us in any of its effects.\nShould correspond to our experience with natural\nlanguages, mathematics, and other PLs\n\nCopyright\nc Nancy Leveson, Sept. 1999\nRelationship between PL and Correctness (2)\nError Proneness\nLanguage design should prevent errors.\nShould be difficult or impossible to write an incorrect program.\nIf not possible, then allow their detection (as early as possible)\nNeed for general principles and hypotheses so can predict\nerror-prone features and improve language design.\nSome hypotheses and data about:\nGo to\nGlobal variables\nPointers\nSelection by position (long parameter lists)\nDefaults and implicit type conversion\nAttempts to interpret intentions or fix errors\nMeaning of features should be precisely defined (not\ndependent on compiler.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nRelationship between PL and Correctness (3)\nUnderstandability\n\"The primary goal of a programming language is accurate\ncommunication among humans.\"\nReadability more important than writeability.\nWell \"punctuated\" (easy to directly determine statement types\nand major subunits without intermediate inferences)\nUse of distinct structural words (keywords, reserved words)\nfor distinct concepts (no overloading, e.g., = for equal, assignment)\nAvoidance of multiple use of symbols unless serve completely\nanalogous functions (e.g., commas as separators, parentheses for\ngrouping).\nNecessary to be able to see what is being accomplished at a\nhigher level of abstraction.\nPermit programmers to state their \"intentions\" along with\ninstructions necessary to carry them out.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nRelationship between PL and Correctness (4)\nMaintainability\nLocality -- possible to isolate changes.\nSelf-documenting\nProgramming decisions should be recorded in program,\nindependent of external documentation.\nGood comment convention, freedom to choose meaningful\nvariable names, etc.\nUser-defined types and named constants\ne.g., type direction=(north, south, east, west)\nExplicit interfaces\nShould cater to construction of hierarchies of modules\n\nCopyright\nc Nancy Leveson, Sept. 1999\nRelationship between PL and Correctness (5)\nCheckability\nEvery error should transform a correct program into one\nwhose errors are detectable by the system.\nAll error detection based on redundancy (but some forms\ncan cause errors).\nExamples of userful redundancy:\ntype declarations and type checking\ndeclarative redundancy\ninvariance conditions or assertions\nRun-time assertions, exception handling\nchecking subscripts vs. array bounds\ncase selector vs. case bounds\n\nCopyright\nc Nancy Leveson, Sept. 1999\nRelationship between PL and Correctness (6)\nGeneral\nHigh-level languages take many decisions out of\nprogrammer's hands.\nOne reason they are so fiercely resented by\nexperienced programmers.\nLanguage should restrict programmer to decisions\nthat really matter.\nDecisions should be recorded in program independent\nof external documentation.\nSimplicity of language less important than ability to\nwrite conceptually simple programs.\n\nCan programming language influence correctness?\nLanguages affect the way we think about problems:\n\"The tools we use have a profound (and devious) influence\non our thinking habits, and, therefore on our thinking abilities?\"\nDijkstra, 1982\nAdditional experimental evidence:\nC130J software written in a variety of languages by a variety\nof vendors.\nAll certified to DO-178B standards (FAA).\nThen subjected to a major IV&V exercise by the MoD\nSignificant, safety-related errors found in Level A certified\nsoftware\nResidual error rate of Ada code on aircraft was one tenth\nthat of code written in C.\nResidual error rate of SPARK code (Ada subset) one tenth\nthat of the Ada code.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGreen: Design and Use of PLs\n\"Clarifying the psychological processes of using programming\nlanguages will, I believe, clarify the requirements of language\ndesign and of environmental support.\"\nSome examples of structured programming hypotheses:\nControl structures should be hierarchical. Thus they should\nbe nested, rather than allowed to have arbitrary branching.\nIn this way, successive layers of detail can be added.\nThe comprehensibility of hierarchically constructed programs\nwill be easier, since they can be understoof by a reverse\nprocess -- understand the outer layer, then the inner layers, etc.\nThese programs will be easy to modify because the\ninter-relations between parts will be simple.\nHave accepted these hypotheses but have never been validated.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGreen: Program Comprehension\nCites experiments (\"atheoretical\" ) that evaluate only current\nprogramming practice.\nMore interesting question: Can we elucidate underlying\npsychological principles to allow generalization of results to\nother classes of information structure in programming?\nHypothesis 1: If one language is better than another, it\nis always better, whatever the context.\nHypothesis 2: Every notation highlights some type of\ninformation at the expense of others; the better notation\nfor a given task is theone that highlights the information\nthat given task needs.\nMore generally, the comprehensibility of a notation may depend\non the number and complexity of mental operations required to\nextract needed information.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGreen: Program Comprehension (2)\nCites results supporting second hypothesis better than first.\nNot predicted by arguments of structured programming,\nwhich are based solely on presence or absence of good structure.\nProgrammers were not simply decoding programming structure\ntop down into some undescribed mental representation. Were\nreworking one structure into another.\nDifficulty of answering questions depended not only on source\nstructure but also on relation between source and target structures.\nObserves that result \"appears to raise insuperable difficulties\nfor those simple-minded computer scientists who attempt to\nmeasure 'psychological complexity' of a program by means\nof a single number, such as McCabe.\"\n\nStatement of Problem:\nFry: everything that is juicy but not hard\nBoil: everything that is hard\nChop and roast: everything that is neither hard nor juicy\nif hard go to L1\nif hard then\nif hard: boil\nL2: fry stop\nL1: boil stop\nchop roast stop\nif juicy go to L2\nbegin boil end\nelse\nbegin\nif juicy then\nbegin fry end\nnot hard:\nif juicy: fry\nnot juicy: chop roast\nend juicy\nend hard\nelse\nbegin chop roast end\nend\nUsing Dijkstra's guarded command:\nif hard: boil\nif not hard, juicy: fry\nif not hard, not juicy: chop roast\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGreen: Program Creation\nPrograms as plans.\nRole expressiveness: Outcome of a programmer's effort\nis a structure in which each part plays some role vis-a-vis\nthe programmer's original intention.\nEasy program comprehension and creation requires role expressiveness.\nRapid chunking into components\nVisible or easily inferred purposes for each part\nVisible or easily inferred relationships between\neach part and the larger structure.\nImportant to alleviate mismatches between programmer's task\nand program structure.\nHypothesis that role expressiveness tends to detract from reusability\nof program fragments.\n\"When a program fragment makes its role and purpose very clear,\nit is probably not easy to transport it unchanged to a new\nenvironment, because its role may be slightly but significantly different.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nGreen: Program Creation (2)\nLinguistic consistency\nMetarules vs. BNF (simplified syntax rules)\nNot the number of rules that counts but the consistency\nbetween the form of the rules.\nSimilar roles should be indicated by similar syntax: syntax\nshould map roles consistently.\nSignificant omissions (defaults)\nPerceptual cues\nHumans not good at discerning structure of a string of arbitrary\nsymbols but good at differentiating shapes, spatial positions,\nand other perceptual cues.\nDangling else: use of indentation the best solution\nGreen asks: \"Why did it take so long to find the solution?"
    },
    {
      "category": "Resource",
      "title": "cnotes10.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/c9fd670ff2373cd51504feddc4fef9d1_cnotes10.pdf",
      "content": "Copyright\nc\nNancy Leveson, Sept. 1999\nA Model of Team Development\nStage 1: Forming\nStage 2: Storming\nStage 3: Norming\nStage 4: Performing\nFrequently an iterative process, phases often overlap\n\nCopyright\nc Nancy Leveson, Sept. 1999\nStage 1: Forming\nTeam members begin to discover what behaviors are\nacceptable.\nUsually highly unstructured environment\nAttempt to identify tasks, how to accomplish them\nDecisions on what information is needed\nHesitant participation\nTest behavioral assumptions, how to handle each other\nIntellectualizing\nComplaints about organizational issues\nSuspicions, fear, anxiety about new situation\nMinimal work accomplished\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nStage 2: Storming\nSome members become overzealous or hostile as a way\nto express individuality, resist group formation.\nOften infighting, defensiveness, competition\nOften establish unrealistic goals\nOften disunity, tension, jealousy over others roles\nPolarization of team members\nConcerns over excessive work\nEstablish pecking order\nRecognize the extent of task requirements, often\nemotional responses from team.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nStage 3: Norming\nMembers accept team, team norms, their own roles,\neach others idiosyncracies.\nAttempts to patch up previously conflicting relationships.\nTeam leader attempts to take charge.\nAnxieties about task outcome and products.\nConfusion over team priorities, usually temporary\nExcessive meetings\nCopyright\nc\nNancy Leveson, Sept. 1999\nStage 3: Norming (2)\nDistrust and blaming by some; higher level of sharing\nand confiding by others.\nJockeying for position\nStress reactions.\nSense of team spirit and common goals emerge.\nModerate work accomplished.\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nStage 4: Performing\nMembers experience insight into personal and\ninterpersonal processes.\nConstructive self-change occurs.\nGreat deal of work accomplished.\nTeam becomes capable of diagnosing and\nsolving problems.\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nStress and Programmers\nFujigaki:\nFound high levels of stress among Japanese programmers\nBlamed on current tendency to manage programmers with\ntechniques from manufacturing industry:\n\"The software process is not the manufacturing process.\nThe time management system that developed in\nmanufacturing should not be applied to the software\nprocess without modificaions.\nSuggests that the software process is a learning and\ncommunication process. Management's role is to\nfacilitate this learning and communication.\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nStress and Programmers (2)\nFuruyama, Arai, Iio:\nMeasured effects of stress.\nProgrammers working under stress make far more mistakes\n37% of mistakes would have been avoided \"by appropriate\nscheduling and placing no stress on the developers.\"\nDesign particularly vulnerable to stress-caused errors.\nFound 42% of all design faults directly attributable to\nprogrammer stress.\n\nCopyright\nc Nancy Leveson, Sept. 1999\nStress and Programmers\nZawacki: conducted studies on programmers 1979-1993\nCompared with rest of society, programmers had high\nneed to succeed, low need to socialize with other people.\nAlarming drop in job satisfaction from 1979 to 1993.\nNeed management better prepared to deal with changing\nneeds of programmers in the 90's:\nFind ways to improve motivation of programmers.\nImprove feedback between managers and programmers.\nAdd more people to mix with higher social needs (to\nmatch more team-oriented, user-focused approaches\nof the 90s).\n\nCopyright\nc\nNancy Leveson, Sept. 1999\nExtroversion (E) and Introversion (I)\nE: Other people is source of energy\nSociability charges batteries\nFinds breadth more appealing\nMultiplicity of relationships\nI: Private spaces both mentally and physically\nBeing alone charges batteries\nLikes to work alone or small group\nFinds depth more appealing\nLimited relationships\n\nCopyright\nc Nancy Leveson, Sept. 1999\nIntuition (N) and Sensation (S)\n(Differences place widest gulf between people)\nN: Innovative, likes metaphor, futurist\nHead may seem to be in the clouds, but able to\ntake very complex ideas and see them as a whole.\nUsually entrepreneurial, ingenious\nS: Wants facts and data, believes in experience\nUsually observant about details\nRealistic, practical, down-to-earth\n\nCopyright\nc Nancy Leveson, Sept. 1999\nThinking (T) and Feeling (F)\nT: Usually prefer impersonal choice when making decisions\nObjective, principles, follow laws and policies\nUsually hides feelings; may be thought of as cold or\nunemotional (not necessarily true, just able to cover up)\nF: Personal basis and experience used when making decisions\nSubjective, extenuating circumstances\nPersuasive, social values\nOften expressive of emotions\n\nCopyright\nc Nancy Leveson, Sept. 1999\nJudging (J) and Perceiving (P)\nJ:\nChoose closure over keeping options open\nMay experience a sense of urgency pending a decision\nEstablishes deadlines and takes them seriously\nStrong work ethic; plans ahead, decisive,\n\"get the show on the road\"\nP: Likes to gather more data, decisions frequently left pending\nLikes to adapt as they go, keep life open\nDon't think deadlines should be hard\nTakes a \"wait and see\" and \"something will turn up\" attitude\n\nCopyright\nc Nancy Leveson, Sept. 1999\nMetzger: Managing Programming People, 1987\n(Prentice-Hall)\nA team made up of individuals, each with own personal goals.\nProject management task is to make team out of individuals\nwhereby individual goals reconciled into one goal for project\nas whole.\nImportant to identify project goals at early stage and\ncommunicate them to project members.\nOught to know what is expected of them.\nIf uncertainty, will determine their own goals.\nDiverging goals may lead to severe problems.\nDebra Tannen: You Just Don't Understand\nDifferences between male and female communication styles"
    },
    {
      "category": "Resource",
      "title": "bach_reading.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/8a1324544e946179174bdffa8d6f3ed6_bach_reading.pdf",
      "content": "The Immaturity of CMM\nby James Bach\n(Formerly of Borland International)\nThis article was originally published in the September =9194 issue of American\nProgrammer.\nThe Software Engineering Institute's (SEI) Capability Maturity Model (CMM) gets a lot\nof publicity. Given that the institute is funded by the US Department of Defense to the\ntune of tens of millions of dollars each year [1], this should come as no surprise=97 the\nfolks at the SEI are the official process mavens of the military, and have the resources to\nspread the word about what they do. But, given also that the CMM is a broad, and\nincreasingly deep, set of assertions as to what constitutes good software development\npractice, it's reasonable to ask where those assertions come from, and whether they are in\nfact complete and correct.\nMy thesis, in this essay, is that the CMM is a particular mythology of software process\nevolution that cannot legitimately claim to be a natural or essential representation of\nsoftware processes.\nThe CMM is at best a consensus among a particular group of software engineering\ntheorists and practitioners concerning a collection of effective practices grouped\naccording to a simple model of organizational evolution. As such, it is potentially\nvaluable for those companies that completely lack software savvy, or for those who have\na lot of it and thus can avoid its pitfalls.\nAt worst, the CMM is a whitewash that obscures the true dynamics of software\nengineering, suppresses alternative models. If an organization follows it for its own sake,\nrather than simply as a requirement mandated by a particular government contract, it may\nvery well lead to the collapse of that company's competitive potential. For these reasons,\nthe CMM is unpopular among many of the highly competitive and innovative companies\nproducing commercial shrink-wrap software.\nA short description of the CMM\nThe CMM [7] was conceived by Watts Humphrey, who based it on the earlier work of\nPhil Crosby. Active development of the model by the SEI began in 1986.\nIt consists of a group of \"key practices\", neither new nor unique to CMM, which are\ndivided into five levels representing the stages that organizations should go through on\nthe way to becoming \"mature\". The SEI has defined a rigorous process assessment\nmethod to appraise how well a organization satisfies the goals associated with each level.\nThe assessment is supposed to be led by an authorized lead assessor.\nThe maturity levels are:\n1. Initial (chaotic, ad hoc, heroic)\n2. Repeatable (project management, process discipline)\n3. Defined (institutionalized)\n\n4. Managed (quantified)\n5. Optimizing (process improvement)\nOne way companies are supposed to use the model is first to assess their maturity level\nand then form a specific plan to get to the next level. Skipping levels is not allowed.\nThe CMM was originally meant as a tool to evaluate the ability of government\ncontractors to perform a contracted software project. It may be suited for that purpose; I\ndon't know. My concern is that it is also touted as a general model for software process\nimprovement. In that application, the CMM has serious weaknesses.\nShrink-wrap companies, which have also been called commercial off-the-shelf firms or\nsoftware package firms, include Borland, Claris, Apple, Symantec, Microsoft, and Lotus,\namong others. Many such companies rarely if ever manage their requirements documents\nas formally as the CMM describes. This is a requirement to\nachieve level 2, and so all of these companies would probably fall into level 1 of the\nmodel.\nCriticism of the CMM\nA comprehensive survey of criticism of the CMM is outside the scope of this article.\nHowever, Capers Jones and Gerald Weinberg are two noteworthy critics.\nIn his book Assessment & Control of Software Risks [6], Jones discusses his own model,\nSoftware Productivity Research (SPR), which was developed independently from CMM\nat around the same time and competes with it today. Jones devotes a chapter to outlining\nthe weaknesses of the CMM. SPR accounts for many factors that the CMM currently\nignores, such as those contributing to the productivity of individual engineers.\nIn the two volumes of his Quality Software Management series [12,13], Weinberg takes\nissue with the very concept of maturity as applied to software processes, and instead\nsuggests a paradigm based on patterns of behavior. Weinberg models software processes\nas interactions between humans, rather than between formal constructs. His approach\nsuggests an evolution of \"problem-solving leadership\" rather than canned processes.\nGeneral problems with CMM\nI don't have the space to expand fully on all the problems I see in the CMM. Here are the\nbiggest ones from my point of view as a process specialist in the shrink-wrap world:\n=B7 The CMM has no formal theoretical basis. It's based on the experience of \"very\nknowledgeable people\". Hence, the de facto underlying theory seems to be that experts\nknow what they're doing. According to such a principle, any other model based on\nexperiences of other knowledgeable people has equal veracity.\n=B7 The CMM has only vague empirical support. That is, the empirical support for\nCMM could also be construed to support other models. The model is based mainly on\nexperience of large government contractors, and Watts Humphrey's own experience in\nthe mainframe world. It does not account for the success of shrink-wrap companies, and\nlevels 1, 4, and 5 are not well represented in the data: the first because it is\nmisrepresented, the latter two because there are so few organizations at those levels. The\n\nSEI's, Mark Paulk can cite numerous experience reports supporting CMM, and he tells\nme that a formal validation study is underway. That's all well and good, but the anecdotal\nreports I've seen and heard regarding success using the CMM could be interpreted as\nevidence for the success of people working together to achieve anything. In other words,\nwithout a comparison of alternative process models under controlled conditions, the\nempirical case can never be closed. On the contrary, the case is kept wide open by\nongoing counterexamples in the form of successful level 1 organizations, and by the\ncurious lack of data regarding failures of the CMM (which may be due to natural\nreluctance on the part of companies to dwell on their mistakes, or of the SEI to record\nthem).\n=B7 The CMM reveres process, but ignores people. This is readily apparent to\nanyone who is familiar with the work of Gerald Weinberg, for whom the problems of\nhuman interaction define engineering. By contrast, both Humphrey and CMM mention\npeople in passing [5], but both also decry them as unreliable and assume that defined\nprocesses can somehow render individual excellence less important. The idea that process\nmakes up for mediocrity is a pillar of the CMM, wherein humans are apparently\nsubordinated to defined processes. But, where is the justification for this? To render\nexcellence less important the problem solving tasks would somehow have to be embodied\nin the process itself. I've never seen such a process, but if one exists, it would have to be\nquite complex. Imagine a process definition for playing a repeatably good chess game.\nSuch a process exists, but is useful only to computers; a process useful to humans has\nneither been documented nor taught as a series of unambiguous steps. Aren't software\nproblems at least as complex as chess problems?\n=B7 The CMM reveres institutionalization of process for its own sake. Since the\nCMM is principally concerned with an organization's ability to commit, such a bias is\nunderstandable. But, an organization's ability to commit is merely an expression of a\nproject team's ability to execute. Even if necessary processes are not institutionalized\nformally, they may very well be in place, informally, by virtue of the skill of the team\nmembers. Institutionalization guarantees nothing, and efforts to institutionalize often lead\nto a bifurcation between an oversimplified public process and a rich private process that\nmust be practiced undercover. Even if institutionalization is useful, why not instead\ninstitutionalize a system for identifying and keeping key contributors in the organization,\nand leave processes up to them?\n=B7 The CMM contains very little information on process dynamics. This makes it\nconfusing to discuss the relationship between practices and levels with a CMM\nproponent, because of all the hidden assumptions. For instance, why isn't training on\nlevel 1 instead? Training is especially important at level 1, where it may take the form of\nmentoring or of generic training in any of the skills of software engineering. The answer\nseems to be that nothing is placed at level 1, because level 1 is defined merely as not\nbeing at level 2. The hidden assumption here is that who we are, what problems we face,\nand what we're already doing doesn't matter: just get to level 2. In other words, the CMM\ndoesn't perceive or adapt to the conditions of the client organization. Therefore training\nor any other informal practice at level 1, no matter how effective it is, could be squashed\n\naccidentally by a blind and static CMM. Another example: Why is defect prevention a\nlevel 5 practice? We use project post mortems at Borland to analyze and improve our\nprocesses -- isn't that a form of defect prevention? There are many such examples I could\ncite, based on a reading of the CMM 1.1 document (although I did not review the\nvoluminous Key Practices document) and the appendix of Humphrey's Managing the\nSoftware Process [5]. Basically, most and perhaps all of the key practices could be\nperformed usefully at level 1, depending on the particular dynamics of the particular\norganization. Instead of actually modeling those process dynamics, the way Weinberg\ndoes in his work, the CMM merely stratifies them.\n=B7 The CMM encourages displacement of goals from the true mission of\nimproving process to the artificial mission of achieving a higher maturity level. I call this\n\"level envy\", and it generally has the effect of blinding an organization to the most\neffective use of its resources. The SEI itself recognizes this as a problem and has taken\nsome steps to correct it. The problem is built in to the very structure of the model,\nhowever, and will be very hard to exorcise.\nFeet of clay: The CMM's fundamental misunderstanding of level 1 Organizations\nThe world of technology thrives best when individuals are left alone to be different,\ncreative, and disobedient. -- Don Valentine, Silicon Valley Venture Capitalist [8]\nApart from the concerns mentioned above, the most powerful argument against the CMM\nas an effective prescription for software processes is the many successful companies that,\naccording the CMM, should not exist. This point is most easily made against the\nbackdrop of the Silicon Valley.\nTom Peters's, Thriving on Chaos [9], amounts to a manifesto for Silicon Valley. It places\ninnovation, non-linearity, ongoing revolution at the center of its world view. Here in the\nValley, innovation reigns supreme, and it is from the vantage point of the innovator that\nthe CMM seems most lost. Personal experience at Apple and Borland, and contact with\nmany others in the decade I've spent here, support this view.\nProponents of the CMM commonly mistake its critics as being anti-process, and some of\nus are. But a lot of us, including me, are process specialists. We believe in the kinds of\nprocesses that support innovation. Our emphasis is on systematic problem-solving\nleadership to enable innovation, rather than mere process control to enable cookie-cutter\nsolutions.\nInnovation per se does not appear in the CMM at all, and it is only suggested by level 5.\nThis is shocking, in that the most innovative firms in the software industry, (e.g., General\nMagic, a pioneer in personal digital communication technology) operate at level 1,\naccording to the model. This includes Microsoft, too, and certainly Borland [2]. Yet, in\nterms of the CMM, these companies are considered no different than any failed startup or\nparalyzed steel company. By contrast, companies like IBM, which by all accounts has\nmade a real mess of the Federal Aviation Administration's Advanced Automation Project,\n\nscore high in terms of maturity (according to a member of a government audit team with\nwhom I spoke).\nNow, the SEI argues that innovation is outside of its scope, and that the CMM merely\nestablishes a framework within which innovation may more freely occur. According to\nthe literature of innovation, however, nothing could be further from the truth.\nPreoccupied with predictability, the CMM is profoundly ignorant of the dynamics of\ninnovation.\nSuch dynamics are documented in Thriving on Chaos, Reengineering the Corporation\n[4], and The Fifth Discipline [10], three well known books on business innovation. Where\ninnovators advise companies to get flexible, the CMM advises them to get predictable.\nWhere the innovators suggest pushing authority down in the organization, the CMM\npushes it upward. Where the innovators recommend constant constructive innovation, the\nCMM mistakes it for chaos at level 1. Where the innovators depend on a trail of learning\nexperiences, the CMM depends on a trail of paper.\nNowhere is the schism between these opposing world-views more apparent than on the\nmatter of heroism. The SEI regards heroism as an unsustainable sacrifice on the part of\nparticular individuals who have special gifts. It considers heroism the sole reason that\nlevel 1 companies succeed, when they succeed at all.\nThe heroism more commonly practiced in successful level 1 companies is something\nmuch less mystical. Our heroism means taking initiative to solve ambiguous problems.\nThis does not mean burning people up and tossing them out, as the SEI claims. Heroism\nis a definable and teachable set of behaviors that enhance and honor creativity (as a unit\nof United Technologies Microelectronics Center has shown [3]). It is communication,\nand mutual respect. It means the selective deployment of processes, not according to\nmanagement mandate, but according to the skills of the team.\nPersonal mastery is at the center of heroism, yet it too has no place in the CMM, except\nthrough the institution of a formal training program. Peter Senge [10], has this to say\nabout mastery:\n\"There are obvious reasons why companies resist encouraging personal mastery. It is\n'soft', based in part on unquantifiable concepts such as intuition and personal vision. No\none will ever be able to measure to three decimal places how much personal mastery\ncontributes to productivity and the bottom line. In a materialistic culture such as ours, it\nis difficult even to discuss some of the premises of personal mastery. 'Why do people even\nneed to talk about this stuff?' someone may ask. 'Isn't it obvious? Don't we already know\nit?'\"\nThis is, I believe, the heart of the problem, and the reason why CMM is dangerous to any\ncompany founded upon innovation. Because the CMM is distrustful of personal\ncontributions, ignorant of the conditions needed to nurture non-linear ideas, and content\nto bury them beneath a constraining superstructure, achieving level 2 on the CMM scale\nmay very well stamp out the only flame that lit the company to begin with.\n\nI don't doubt that such companies become more predictable, in the way that life becomes\npredictable if we resolve never to leave our beds. I do doubt that such companies can\nsucceed for long in a dynamic world if they work in their pajamas.\nAn alternative to CMM\nIf not the maturity model, then by what framework can we guide genuine process\nimprovement?\nAlternative frameworks can be found in generic form in Thriving on Chaos, which\ncontains 45 \"prescriptions\", or The Fifth Discipline, which presents--not surprisingly--\nfive disciplines. The prescriptions of Thriving on Chaos are embodied in an\norganizational tool called The Excellence Audit, and The Fifth Discipline Fieldbook [11],\nwhich provides additional guidance in creating learning organizations, is now available.\nAn advantage of these models is that they provide direction, without mandating a\nparticular shape to the organization. They actually provide guidance in creating\norganizational change.\nSpecific to software engineering, I'm working on a process model at Borland that consists\nof a seven-dimensional framework for analyzing problems and identifying necessary\nprocesses. These dimensions are: business factors, market factors, project deliverables,\nfour primary processes (commitment, planning, implementation, convergence), teams,\nproject infrastructure, and milestones. The framework connects to a set of scaleable\n\"process cycles\". The process cycles are repeatable step by step recipes for performing\ncertain common tasks.\nThe framework is essentially a situational repository of heuristics for conducting\nsuccessful projects. It is meant to be a quick reference to aid experienced practitioners in\ndeciding the best course of action.\nThe key to this model is that the process cycles are subordinated to the heuristic\nframework. The whole thing is an aid to judgment, not a prescription for institutional\nformalisms. The structure of the framework, as a set of two-dimensional grids, assists in\nprocess tailoring and asking \"what if...?\"\nIn terms of this model, maturity means recognizing problems (through the analysis of\nexperience and use of metrics) and solving them (through selective definition and\ndeployment of formal and informal processes), and that means developing judgment and\ncooperation within teams. Unlike the CMM, there is no a priori declaration either of the\nproblems, or the solutions. That determination remains firmly in the hands of the team.\nThe disadvantage of this alternative model is that it's more complex, and therefore less\nmarketable. There are no easy answers, and our progress cannot be plotted on the fingers\nof one hand. But we must resist the temptation to turn away from the unmeasurable and\nsometimes ineffable reality of software innovation.\nAfter all, that would be immature.\n\nPostscript 02/99\nIn the five years since I wrote this article, neither the CMM situation, nor my assessment\nof it, has changed much. The defense industry continues to support the CMM. Some\ncommercial IT organizations follow it, many others don't. Software companies pursuing\nthe great technological goldrush of our time, the Internet, are ignoring it in droves.\nStudies alleging that the CMM is valuable don't consider alternatives, and leave out\ncritical data that would allow a full analysis of what's going on in companies that claim to\nhave moved up in CMM levels and to have benefited for that reason.\nOne thing about my opinion has shifted. I've become more comfortable with the\ndistinction between the CMM philosophy, and the CMM issue list. As a list of issues\nworth addressing in the course of software process improvement, the CMM is useful and\nbenign. I would argue that it's incomplete and confusing in places, but that's no big deal.\nThe problem begins when the CMM is adopted as a philosophy for good software\nengineering.\nStill, it has become a lot clearer to me why the CMM philosophy is so much more\npopular than it deserves to be. It gives hope, and an illusion of control, to management.\nFaced with the depressing reality that software development success is contingent upon\nso many subtle and dynamic factors and judgments, the CMM provides a step by step\nplan to do something unsubtle and create something solid. The sad part is that this step-\nby-step plan usually becomes a substitute for genuine education in engineering\nmanagement, and genuine process improvement.\nOver the last few years, I've been through Jerry Weinberg's classes on management and\nchange artistry: Problem Solving Leadership, and the Change Shop. I've become a part of\nhis Software Engineering Management Development Group program, and the SHAPE\nforum. Information about all of these are available at http://www.ge=\nraldmweinberg.com. In my view, Jerry's work continues to offer an excellent alternative\nto the whole paradigm of the CMM: managers must first learn to see, hear, and think\nabout human systems before they can hope to control them. Software projects are human\nsystems=97deal with it.\nOne last plug. Add to your reading list The Logic of Failure, by Dietrich Dorner. Dorner\nanalyzes how people cope with managing complex systems. Without mentioning\nsoftware development or capability maturity, it's as eloquent an argument against CMM\nphilosophy as you'll find.\nReferences\n1. Berti, Pat, \"Four Pennsylvania schools await defense cuts.\", Pittsburgh Business\nTimes, Jan 22, 1990 v9 n24\n2. Coplien, James, \"Borland Software Craftsmanship: a New Look at Process, Quality\nand Productivity\", Proceedings of the 5th Borland International Conference, 1994\n3. Couger, J. Daniel; McIntyre, Scott C.; Higgins, Lexis F.; Snow, Terry A., \"Using a\nbottom-up approach to creativity improvement in IS development.\", Journal of Systems\nManagement, Sept 1991 v42 n9 p23(6)\n\n4. Hammer, Michael; Champy, James, Reengineering the Corporation, HarperCollins,\n5. Humphrey, Watts, Managing the Software Process, ch. 2, Addison-Wesley, 1989\n6. Jones, Capers, Assessment & Control of Software Risks, Prentice-Hall, 1994\n7. Paulk, Mark, et al, Capability Maturity Model 1.1 (CMU/SEI-93-TR-24)\n8. Peters, Tom, The Tom Peters Seminar: Crazy Times Call for Crazy Organizations,\nRandom House, 1994\n9. Peters, Tom, Thriving on Chaos: Handbook for a Management Revolution,\nHarperCollins, 1987\n10. Senge, Peter, The Fifth Discipline, Doubleday, 1990\n11. Senge, Peter, The Fifth Discipline Fieldbook, Doubleday, 1994\n12. Weinberg, Gerald M., Quality Software Management, v. 1 Systems Thinking, Dorset\nHouse, 1991\n13. Weinberg, Gerald M., Quality Software Management, v. 2 First-order measurement,\nDorset House, 1993"
    },
    {
      "category": "Resource",
      "title": "brit_scha_cond.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/f568f347bbe4349841df7c4a1beab6e1_brit_scha_cond.pdf",
      "content": "Testing in NASA Human-Rated Spacecraft Programs:\nHow much is just enough?\nby\nKeith J. Britton\nM.S. Systems Management, Florida Institute of Technology, 1992\nB.S. Mechanical Engineering, University of Central Florida, 1983\nand\nDawn M. Schaible\nM.S. Space Systems Operations, Florida Institute of Technology, 1992\nB.S. Mechanical Engineering, Bradley University, 1987\nSubmitted to the System Design and Management Program\nin Partial Fulfillment of the Requirements for the Degree of\nMaster of Science in Engineering and Management\nat the\nMassachusetts Institute of Technology\nFebruary 2003\n(c) 2003 Keith J. Britton and Dawn M. Schaible.\nThe authors hereby grants to MIT permission to reproduce and to\ndistribute publicly paper and electro nic copies of this thesis document in whole or in part.\nSignature of Author\nKeith J. Britton\nSystem Design and Management Program\nFebruary 2003\nSignature of Author\nDawn M. Schaible\nSystem Design and Management Program\nFebruary 2003\nCertified by\nNancy Leveson\nThesis Supervisor\nProfessor of Aeronautics and Astronautics\nAccepted by\nSteven D. Eppinger\nCo-Director, LFM/SDM\nGM LFM Professor of Management Science and Engineering Systems\nAccepted by\nPaul A. Lagace\nCo-Director, LFM/SDM\nProfessor of Aeronautics & Astronautics and Engineering Systems\n\nTesting in NASA Human-Rated Spacecraft Programs:\nHow much is just enough?\nby\nKeith J. Britton\nand\nDawn M. Schaible\nSubmitted to the System Design and Management Program in\nPartial Fulfillment of the Requirements for the Degree of\nMaster of Science in Engineering and Management\nABSTRACT\nTesting has long been recognized as a critical component of spacecraft development\nactivities at the Nationa l Aeronautics and Space Administration (NASA). Determining the\nappropriate amount of testing, however, is a very difficult task. The objectives of this\nthesis are to document the test approaches and philosophies used within NASA and other\norganizations, to determine if these factors can be applied to all human-rated spacecraft\nprograms, and to provide lessons learned for future projects. Through a series of expert\ninterviews and review of current literature, a number of themes, findings and\nrecommendations emerged.\nSome of the major themes the resulted from expert interviews include:\nSubjectivity of test requirements development: Typically, the actual test requirement\ndecision process is not documented as a formal process but relies heavily on the judgme nt\nof the decision makers, adding to the overall subjectivity. Due to this subjectivity, testing\npractices are not consistent across the aerospace industry.\nParadoxical nature of testing: Testing alone does not make a project successful, but it does\nraise confidence in the likelihood of success. Testing is often regarded as a drain on\nproject resources, rather than a valuable undertaking.\nVulnerability to changes and cutbacks: Most testing occurs late in the development phase.\nSince the budget and schedule pressures are most keenly felt at the end of a development\nprogram, testing becomes vulnerable to changes.\nInadequate attention to testing: Testing, in general, does not receive as much attention as it\nshould. Testing is often overlooked during the early planning phases of a project, in\ncurrent literature, training programs and academia and in organizational status.\n\nSome of the major findings include:\nFor some projects, software is considered a stand-alone system: Today's systems are\nbecoming increasingly more reliant on software to operate successfully. Yet for many\nprojects software is not being treated as an integral part of the overall system but as a\nseparate stand-alone system.\nWhile testing practices vary, decision factors do not: Contrary to common belief, there is\nconsistency in the decision factors used by the various decision makers. These common\ndecision factors can be divided into technical (safety, risk and confidence building) and\nnon-technical (resource availability, process, individual decision-making behavior and\npolitical/cultural influences). Decision makers must consider each of the sources of\nuncertainty, especially the effects of reuse, an inexperienced team and potential unexpected\nemergent behavior.\nCurrent methods of tracking testing costs are not sufficient: Actual cost figures for\nspacecraft testing programs are very difficult to determine because they are not typically\ntracked as a discrete line item in spacecraft programs. Life-cycle cost estimating is another\narea that should be enhanced and used in making test decisions.\nUpfront planning is a key to success, but be prepared for change: Early planning in both\nsystems engineering and testing is necessary to manage the complexity of human-rated\nspacecraft programs. The early involvement of the test organization is also essential in\nestablishing a set of firm test requirements that will be less vulnerable to changes later in\nthe program.\nTesting is more of an art than a science: Experience and mentoring are more important\nthan formal training in developing test engineering expertise. In order to maintain the\nknowledge base and core capabilities, test engineering should be treated as a valid\nprofession with the same prestige level as other engineering disciplines.\nA few of the recommendations proposed include:\no Form an agency-wide team to seek out best practices in the test engineering field.\no Enhance the current risk management practices to include an assessment of all\ndecisions making factors that contribute to the overall level of likelihood.\no Establish improved training and mentoring programs for test engineers, perhaps\nthrough the creation of a test engineering corps.\no Assign both responsibility and accountability for software to system engineering.\nThesis Supervisor:\nNancy Leveson\nTitle:\nProfessor of Aeronautics and Astronautics\n\nAcknowledgements\nWe would like to acknowledge the following individuals for their support in making our\ntime at MIT an experience of a lifetime.\nFirst, we would like to thank our families for their patience, encouragement and support\nespecially Gina, Spencer and Sarah Britton, Carol Schaible and Kimberly Squire. It was\ntheir sacrifices, rather than ours, that made it possible for us to be active participants in the\nSystem Design and Management Program.\nWe also want to thank our NASA supervisors, managers, mentors and co-workers. Their\nunderstanding, encouragement and cooperation made it possible for us to take full\nadvantage of our time at MIT. In particular, we would like to thank Ken Payne, Tip\nTalone and Randy Galloway for their mentorship, and Mr. Roy Bridges for his support of\nthe PMDP-ALO Program.\nWe would also like to acknowledge the expert interviewees that shared their time,\nexperience and knowledge with us. Without their contributions this thesis would not have\nbeen possible.\nFinally, we would like to thank our advisor, Professor Nancy Leveson. Her patience,\nguidance and expertise made the development of this thesis a valuable and rich learning\nexperience. In additio n, Nancy's support of us, SDM and NASA has served as an\ninspiration for our future endeavors and is greatly appreciated.\n\nTable Of Contents\nABSTRACT ..........................................................................................................................3\nAcknowledgements ...............................................................................................................5\nList of Figures.......................................................................................................................8\nList of Tables.........................................................................................................................8\nAcronyms ..............................................................................................................................9\nChapter 1: Introduction.....................................................................................................10\n1.1\nMotivation............................................................................................................10\n1.2\nHypotheses and Objectives ..................................................................................11\n1.3\nThesis Approach and Structure ............................................................................12\nChapter 2: Testing Classifications and Methodologies...................................................14\n2.1\nThe NASA Development Process........................................................................14\n2.2\nMethodologies Used in the Verification Process .................................................16\n2.3\nStages of Verification Process..............................................................................16\n2.3.1 Development Stage ..........................................................................................17\n2.3.2 Qualification Stage ...........................................................................................18\n2.3.3 Acceptance Stage .............................................................................................18\n2.3.4 Pre-Launch Stage (Integration) ........................................................................19\n2.4\nThe Role of Testing..............................................................................................19\nChapter 3: Research Methodology and Data Analysis...................................................21\n3.1\nData Collection through Interviews .....................................................................21\n3.2\nInterview Methodology........................................................................................21\n3.3\nInterview Categories ............................................................................................22\n3.4\nInterview Questions ..............................................................................................23\n3.5\nGoal of Interviews ................................................................................................23\n3.6\nOverview of Interviews and Method of Data Analysis........................................24\nChapter 4:\nThemes Resulting from Expert Interviews ..............................................26\n4.1\nIntroduction..........................................................................................................26\n4.2\nPrimary Themes ...................................................................................................26\n4.2.1 Subjectivity of Test Requirement Development ..............................................26\n4.2.2 Paradoxical Nature of Testing..........................................................................27\n4.2.3 Vulnerability to Changes and Cutbacks...........................................................28\n4.2.4 Inadequate Attention to Testing .......................................................................28\n4.2.5 Organizational Influences on the Testing Process ...........................................29\nChapter 5: Findings Derived from the Expert Interviews .............................................33\n5.1\nIntroduction..........................................................................................................33\n5.2\nStand-alone Software System...............................................................................33\n5.3\nVarying Attitudes Toward Test Effectiveness .....................................................36\n5.4\nTest Program Decision Factors ............................................................................38\n\n5.4.1 Technical Factors .............................................................................................38\n5.4.2 Non-Technical Factors .....................................................................................42\n5.4.3 Retest Considerations .......................................................................................44\n5.5\nThe Role of Planning............................................................................................45\n5.6\nTracking Testing Costs.........................................................................................47\n5.7\nTesting Is An Art ..................................................................................................48\n5.8\nThe Importance of System Engineering...............................................................49\n5.9\nProgram/Agency Culture......................................................................................50\nChapter 6: Lessons for the Future ....................................................................................51\n6.1\nRisk Management Process ...................................................................................51\n6.1.1 Current Risk Management Techniques............................................................51\n6.1.2 Application to Testing......................................................................................55\n6.2\nAdditional Keys to Success..................................................................................58\n6.2.1 Status of Testing...............................................................................................58\n6.2.2 Organizational Considerations .........................................................................58\n6.2.3 Knowledge Transfer .........................................................................................59\n6.2.4 Alignment of Goals ..........................................................................................60\n6.3\nTesting Decision-Making Considerations ............................................................60\n6.3.1 Risk-Tolerance .................................................................................................60\n6.3.2 Long-Term View ..............................................................................................61\n6.3.3 Systems Perspective .........................................................................................62\nChapter 7:\nSummary .....................................................................................................63\n7.1\nConclusions ..........................................................................................................63\n7.1.1 Major Themes from Expert Interviews ............................................................63\n7.1.2 Major Findings of Thesis .................................................................................64\n7.1.3 Review of Original Hypotheses .......................................................................66\n7.2\nRecommendations ................................................................................................66\n7.3\nFuture Work .........................................................................................................68\nNotes ....................................................................................................................................69\nReferences...........................................................................................................................72\nAppendix A - Expert Interv iew Questionnaire ...............................................................74\nAppendix B - Glossary .......................................................................................................77\n\nList of Figures\nFigure 1 - Hierarchical Structure of a Generic System (Derived from [10]) ......................14\nFigure 2 - Generic Overview of the NASA Project Cycle [12] ...........................................15\nFigure 3 - Typical Depictio n of a Weibull Distribution (Bathtub Curve) [14]...................17\nFigure 4 - Simplified Integrated Product Team Structure ...................................................34\nFigure 5 - Simplified Organizational Structure with Segregated Software Group .............35\nFigure 6 - DoD Model for System Development [43] .........................................................35\nFigure 7 - NASA Generic Risk Matrix [65].........................................................................51\nFigure 8 - Risk Matrix Showing Risk Assessment Code (RAC) (Adapted from [68])......53\nFigure 9 - NASA Program Risk Matrix [70] .......................................................................54\nFigure 10 - Risk Matrix with Scoring [72]..........................................................................54\nFigure 11 - Adapted DoD Hazard Criticality Index Matrix [73].........................................55\nList of Tables\nTable 1 - Mapping of Expert Interviewee Responses ..........................................................24\nTable 2 - Sources of Uncertainty..........................................................................................40\nTable 3 - Non-Technical Factors...................................................................42\nTable 4 - Sources of Uncertainty.........................................................................................56\n\nAcronyms\nDOD\nDepartment of Defense\nFAA\nFederal Aviation Administration\nFPGA\nField Programmable Gate Array\nIPT\nIntegrated Product Team\nISS\nInternational Space Station\nIV&V\nIndependent Verification and Validation\nMCO\nMars Climate Orbiter\nMEIT\nMulti-Element Integration Test\nMIT\nMassachusetts Institute of Technology\nMPIAT\nMars Program Independent Assessment Team\nNASA\nNational Aeronautics and Space Administration\nPRA\nProbability Risk Assessment\nRAC\nRisk Assessment Code\nRMP\nRisk Management Plan\nSDM\nSystems Design and Management\nV&V\nVerification and Validation\nWIRE\nWide Field Infrared Explorer\n\nChapter 1: Introduction\n1.1\nMotivation\n\"A thorough test and verification program is essential for mission success\"\nNASA Mars Program Independent Assessment Team Summary Report [1]\nThe above statement was cited as a lesson learned by the National Aeronautics and Space\nAdministration (NASA) Mars Program Independent Assessment Team (MPIAT) in their\nMarch 2000 report. The MPIAT was chartered to review and analyze three successful and\nthree unsuccessful Mars and deep space missions in order to provide recommendations for\nfuture NASA projects. This is just one example of a review committee finding that\nthorough testing is needed to ensure a successful mission. Another example includes the\nHuygens Probe. While on its way toward Saturn's largest moon Titan in 2000, the\nHuygens Probe experienced anomalies in its communication system. An enquiry board\nwas assembled to investigate the problems and included in their recommendations that \"an\nend-to-end test should have been performed on the complete system as a final test\". [2]\nEven with these and numerous additional examples that point to the benefit of testing,\nmany programs still cut back on the amount of testing that is performed, only to meet with\nless than optimal results.\nNASA is not the only agency, and aerospace is not the only industry, that has experienced\nmajor failures that perhaps could have been prevented if more testing would have been\nconducted. Just one of a plethora of examp les was in the floating rescue capsule aboard the\nill-fated Russian submarine Kursk. According to published reports \"some of the 118\nRussian sailors who died...could have been [saved] if rescue gear aboard the ship had ever\nbeen tested\". [3] It was also reported that the capsule testing was deleted from the testing\nprogram because construction of the ship was falling behind schedule. [4]\nIf testing is recognized as such a benefit, then why is more testing not performed? Given\nunlimited time and unlimited budget, more testing would be performed. Since it is\nunfeasible for programs to perform exhaustive testing, a balance must be struck between\ntoo little testing and too much testing. Not enough testing adds risk to a program, while\ntesting too much can be very costly and may add unnecessary run-time on the equipment.\nDetermining exactly how much testing is just enough is an extremely difficult question for\nmany program managers and other decision makers. The decision process often appears\narbitrary and has received little attention in the past.\nThe role of testing in a successful program is to allow an opportunity for errors to be\ndiscovered and corrected before the system is put into operation. Testing is performed for\nrisk mitigation; it serves as an insurance policy against failed missions. Even though the\nimportance of testing is generally recognized, relatively little attention has been paid to this\narea in either the NASA Systems Engineering Handbook [5] or the NASA Program and\nProject Management Process and Requirements Policy Guide. [6] While the structure of a\n\ntest and verification program is addressed in these documents, actual implementation and\nguidelines on how much testing should be performed are not covered in detail.\nBecause testing is performed in almost every industry and in all NASA programs, a more\nnarrow focus is required. This thesis will begin to address the challenges of testing\nNASA's human-rated spacecraft programs. The focus on human-rated spacecraft was\nchosen due to the inherent criticality of protecting against loss of life. Also of interest is the\ninfluence that expendable and human-rated spacecraft philosophies have on each other, and\nthe relationship between the two types of programs. This thesis will address the following\nconcerns that served as motivation for this research:\no Difficulty in striking a balance between too much and too little testing\no Perceived arbitrary nature of the decision-making process\no The vulnerability of testing to cutbacks as a program progresses\no Apparent lack of attention to testing in established NASA program and managerial\nprocesses\n1.2\nHypotheses and Objectives\nThis thesis poses several hypotheses. The first is that while most decision makers\nrecognize the importance of testing, they rely on highly subjective decision factors and do\nnot use a holistic approach to determining how much testing should be performed. The\nnext hypothesis is that cost and budget factors tend to be the major drivers in determining\nthe level of testing, but actual life-cycle costs are not adequately addressed in the decision-\nmaking process. When life-cycle costs are considered, they are out-weighed by more\npressing issues of the moment. Also, when actual life-cycle estimates are obtained, it\nwould be reasonable to believe that testing on the ground would a more cost-effective\noption than finding and correcting the problem on-orbit. The third hypothesis is that the\ndecision-making process plays a significant role in determining what testing will be\nperformed. Engineers and managers are typically unaware how this process will affect\ntheir decisions. The final hypothesis is that organizational factors are important to a test\nprogram's success. However this relationship may not be well understood or appreciated\nby program managers. A summary of the hypotheses is as follows:\no Many decisions makers do not utilize a holistic approach in addressing testing\nrequirements\no Life-cycle costs are not adequately addressed in the decision-making process\no Decision makers are not fully aware of the influences inherent in the decision-\nmaking process\no The influence of organizational factors is not fully appreciated\nThe first objective of this thesis is to document the role of testing, along with the approach\nand philosophy used within the agency's test programs and across similar industries. From\n\nthis research, decision criteria and the critical factors involved in making testing decisions\nwill be determined. A second objective is to determine whether a common set of decision\nfactors can be formed from the various approaches studied. Using this set of factors, this\nthesis will propose recommendations for architecting future test programs and will address\nthe third objective of providing lessons learned for future projects.\nA fourth objective is to understand how various test managers and systems engineers deal\nwith this issue of unexpected emergent behavior in systems. When the overall system's\nbehavior depends upon the interaction between two or more sub-systems, this is referred to\nas emergent behavior. This emergent behavior is usually anticipated and is necessary for\nthe system to operate successfully. However, interactions between sub-systems can result\nin unexpected, and often undesirable, system responses. This unexpected emergent\nbehavior can usually be explained after it reveals itself but is not anticipated ahead of time.\nAs Eric Bonabeau (2002) noted, \"Because of their very nature, emergent phenomena have\nbeen devilishly difficult to analyze, let alone predict\". [7] This thesis will attempt to\ncapture current methods of driving out unexpected emergent behavior and provide\nrecommendations for the future.\nA summary of the thesis objectives is as follows:\no Document testing approaches and philosophies used and determine decision criteria\nand critical factors\no Determine if these factors can be universally applied to all programs and propose a\nframework for architecting test programs\no Provide lessons learned for future projects\no Understand how various programs address the issue of unexpected emergent\nbehavior in systems\n1.3\nThesis Approach and Structure\nThe research methodology used for this thesis includes a review of current literature on the\nsubject of test and verification from system engineering, decision theory, and\norganizational behavior sources. Since previous research in this area is limited, a series of\nexpert interviews was conducted with NASA, contractor and industry personnel. From\nthese interviews and the literature review, common themes and findings were established,\nalong with recommendations for architecting future test programs. This research will be\ndescribed in this thesis as follows:\nChapter 2 provides a foundation for understanding the NASA development process and the\nrole of testing in this process. In addition, this chapter explains the basic terminology of\ntesting as described in the literature. This is necessary since each program and industry\ntend to use the terms for slightly different applications. A common understanding of the\nterminology is established for the remainder of this thesis. This chapter also briefly\n\ndiscusses the purpose of testing, test implementation and challenges faced in a test\nprogram.\nChapter 3 summarizes the expert interview process. The survey questions are described\nalong with the approach used in cond ucting the interviews. The data analysis methodology\nis explained. General themes are identified for detailed review in Chapter 4.\nChapter 4 outlines the common themes that were observed from the interview process and\nits applicability to the literature review.\nChapter 5 presents the findings derived from the themes described in Chapter 4.\nChapter 6 offers recommendations for architecting future test programs. These\nrecommendations were developed based on the work outlined in the previous chapters and\naddresses both the technical and non-technical factors that influence the testing decision-\nmaking process.\nChapter 7 provides a brief summary of this thesis, makes recommendations for future\nNASA human-rated spacecraft programs and proposes future work that should be\nconducted in the area.\n\nChapter 2: Testing Classifications and Methodologies\n\"The purpose of testing and evaluation is to determine the true system characteristics and\nensure that the system will successfully fulfill its intended mission.\"\n- Blanchard [8]\nThis chapter discusses the NASA spacecraft development process and the role testing\nplays toward spacecraft integration and verification. Because testing terminology is not\nused consistently across different programs and industries, a set of common definitions is\nestablished for use in this thesis. The discussion also includes a description of the NASA\nproject cycle including the technical aspects. All of this provides the background for\nfurther discussions regarding the stages of the verification process and methods used for\nverification. Finally, the role of testing is discussed in terms of its contribution to the\noverall verification process.\n2.1\nThe NASA Development Process\nThe NASA Systems Engineering Handbook (SP-6105) addresses the program and project\nlife-cycle process and how the technical aspects are incorporated into each phase. In\ngeneral, the NASA development process is \"requirements driven\" and uses hierarchical\nterminology for decomposing a system from its highest leve l to successively finer layers,\ndown to individual parts. [9] A general hierarchical structure of a system is depicted in\nFigure 1.\nHierarchical Structure of a System\nSystem\nSegment\nElement\nAssembly\nSubassembly\nPart\nSubsystem\nFigure 1 - Hierarchical Structure of a Generic System (Derived from [10])\nThis structure serves as the framework for systems requirements development that in turn\nprovides the functional requirements that must be verified. Testing is used to accomplish\nthis verification process.\nThe systems engineering approach encompasses the entire technical effort required to\ndevelop, deploy, operate and dispose (decommission) a spacecraft. The objective of the\n\nsystems engineering process is to ensure that the system is designed, built, and operated in\naccordance with its intended purpose and in the most effective way possible, considering\ncost, schedule and risk.\nThe NASA program and project life-cycle process identifies various activities for the\npreliminary design, detailed design, fabrication & integration and preparation for\ndeployme nt phases. NASA has adapted the generic Forsberg and Mooz \"Vee\" chart\n(Figure 2) that describes the technical aspects of a project cycle in terms of the\ndecomposition and definition sequence (referred to as definition) and the integration and\nverification sequence (referred to as verification). [11] The definition sequence (left side\nof Vee) defines the process for understanding user requirements, developing system\nrequirements, expanding them to \"design-to\" specifications and finally, evolving to\n\"build-to\" documentation and inspection plans. During each step of the definition\nsequence a set of verification requirements should be developed. These requirements\n(sometimes referred to as verification and validation requirements) serve as the framework\nfor ensuring the system will perform as desired in its intended operating environment. The\nverification sequence (right side of Vee) of the NASA project cycle provides the\nrequirements for inspection of the \"build-to\" hardware, verification of the \"design-to\"\ndocumentation, integration of the system performance, and demonstration/validation of the\ncomplete systems in accordance with user requirements.\nTechnical Aspect\nUnderstand Customer\nof the\nDemonstrate and\nRequirements, Develop\nValidate System to\nSystem Concept and\nProject Cycle\nUser Validation Plan\nValidation Plan\nIntegrate System and\nDevelop System Specification\nPerform System Verification\nand System Verification Plan\nto Performance\nSpecifications and Plan\nExpand Specifications into\nIntegrate CIs and\nCI \"Design -to\"\nPerform CI Verification\nSpecifications and CI\nto CI \"Design -to\"\nVerification Plan\nSpecifications and Plan\nEvolve \"Design-to\"\nVerify to \"Build-to\"\nSpecifications into\nDocumentation\n\"Build-to\" Documentation\nand Inspection Plan\nAnd Inspection Plan\nFab, Assemble, and Code to\n\"Code-to\" and \"Build-to\"\nDocumentation\nFigure 2 - Generic Overview of the NASA Project Cycle [12]\n\n2.2\nMethodologies Used in the Verification Process\nThere are various methods of accomplishing the objectives of the verification sequence\nincluding analysis, similarity, inspection, simulation and testing. These methods provide a\nlevel of certainty and knowledge regarding the system behavior and performance, and they\nverify the activities of the definition sequence. The following paragraphs provide a brief\ndescription of the verification alternatives and how those methods meet specific\nverification requirements.\nAnalysis uses specific techniques, such as statistics, modeling, or qualitative methods\nto verify compliance to specification/requirements. Analysis is used in lieu of testing\nwhen the methods can be proven to provide rigorous and accurate results and when\ntesting is not cost-effective.\nSimilarity is a verification technique that uses comparison of similar hardware\ncomponents. The acceptance data or hardware configuration and application for a\nparticular piece of hardware is compared to one that is identical in design and\nmanufacturing process and has been previously qualified to equivalent or more\nstringent specifications.\nInspection techniques are used to physically verify design features. This implies a\nphysical inspection but can also refer to documentation. Construction features,\nworkmanship, dimensional features and cleanliness are all applications for inspection.\nSimulation is a technique for verification that uses hardware or software other than\nflight items, but built to behave in an identical manner as the flight systems.\nTesting is a method of verification in which the actual equipment is allowed to operate\nunder conditions that demonstrate its ability to perform as specified by the design\nrequirements. Various stages of testing may be required, as the system is configured,\nin order to verify functionality at each stage of assembly.\n2.3\nStages of Verification Process\nThe verification sequence of the NASA spacecraft development process, as shown in the\nverification sequence of Figure 2, can be further divided into stages that correspond to\ndefined periods in which different verification goals are met. [13]\nThe six generic\nverification stages are:\no Development\no Qualification\no Acceptance\no Pre-launch (Integration)\no Operational\no Disposal\n\nFor human-rated spacecraft, the role of testing is prevalent in the first four stages and is\nused less in the operational environment and lesser still in the disposal stage. Therefore,\nthe following paragraphs will focus on those stages that most relate to the testing activities\n(the development, qualification, acceptance and pre-launch).\n2.3.1\nDevelopment Stage\nDevelopment or component level testing is intended to verify that the lowest level\ncomponents of a system actually perform their intended functions in accordance with\nthe specified requirement(s). A component can be considered a single \"part\" or a\nseries of parts configured to perform a function. Component testing occurs at an early\nstage of systems development in order to provide the building blocks that will comprise\nthe overall system. The data collected during this phase of testing serves as the\nfoundation for system reliability, maintainability and cost effectiveness. Reliability\ndata is usually compiled on each system component according to the mathematical\nrelationships of continuously operated systems.\nThese reliability equations help determine infant and wear-out failure rates and thus\ndetermine the remaining component failure probabilities in a range containing random\noccurrences. The period of operation in which only random failures occur is considered\nthe useful operating life of the component. This is valuable information because it\ndetermines how long a particular component may be used before its replacement\nbecomes necessary. It also defines the amount of higher level testing to which the\ncomponent can be subjected before the wear-out period is entered. A graphic depiction\nof this distribution is referred to as a \"Bathtub Curve\" in which the hazard function is\ndivided into the three regions described in Figure 3.\nFigure 3 - Typical Depiction of a Weibull Distribution (Bathtub Curve) [14]\n\n2.3.2\nQualification Stage\nThe qualification stage of spacecraft development is intended to verify that fight\nhardware meets functional, performance and design requirements. [15] Specific\nrequirements evolve from performance measures that are traceable back to system level\nrequirements and to customer requirements. Verification requirements in this stage are\nmore severe than the conditions expected during operation in order to establish that the\nhardware will perform satisfactorily in the flight environment with sufficient margins.\n[16]\nBlanchard provides a further description of qualification testing as addressing the need\nto prioritize requirements according to criticality, in order to allow an integrated test\nplan to be developed.\nThis places the proper emphasis on the most critical\nrequirements and eliminates redundancies that would increase costs.\nIdeally,\nqualification tests should be scheduled as a series of individual tests performed in an\nintegrated manner as one overall test. [17] However, for highly complex spacecraft\nsystems being developed in stages, at geographically separate facilities, or when\ncontractually fragmented, such integration testing is not always possible.\nSpecific testing objectives that are typically defined in qualification testing include\noverall performance, structural, environmental (thermal), and vibration testing.\nSoftware validation should also be performed during qualification testing but is often\nperformed with simulation or development software that does not represent the final\nreleased versions. Validation of the software ensures that the system behaves per the\nuser requirements. Actual verification that the software meets the stated requirements\ncan only be completed after the final flight version is released.\nThe performance margins established in this stage will determine the amount of system\nflexibility that can be utilized downstream. Even though each individual component\nmay be within specified tolerance, the aggregate of all the components may result in an\nout-of-tolerance condition for the system. These system tolerances are a key factor to\nbe considered at this point because neglecting them may result in unexpected emergent\nproperties during system integration or worse yet, discovering an out-of-tolerance\ncondition of the system late in the development phase.\n2.3.3\nAcceptance Stage\nThe acceptance stage defines the period in which the delivered spacecraft (end-item) is\nshown to meet the functional, performance and design requirements as specified by the\nmission requirements. [18] This stage often concludes with the shipment of the\naccepted item to the launch site.\nAcceptance activities typically occur after the initial qualification testing and before\nfinal integration testing of the spacecraft and are intended to evaluate system\nperformance using the actual production components that will constitute the final\n\nspacecraft.\nAcceptance testing also serves to verify the \"workmanship\" of the\nassembled products.\n2.3.4\nPre-Launch Stage (Integration)\nThe pre-launch stage typically begins with the arrival of flight hardware and software\nat the launch site and ends with the successful launch of the spacecraft. This stage is\nintended to verify requirements of the integrated spacecraft as well as integration\nbetween the spacecraft and launch vehicle or launch facilities. The integration phase\nallows interfaces between different portions of the spacecraft to be brought together\nand tested for fit as well as function, thus providing the opportunity to assemble all the\nspacecraft components in their final configuration. If necessary, the entire system can\nbe run under actual operating conditions. For human-rated spacecraft such as the\nInternational Space Station (ISS), integration testing with flight hardware is not\nfeasible because the various ISS elements are in different stages of development.\nTherefore, integration testing is often comprised of a mixture of actual flight hardware\nand software with emulators of other parts of the overall system.\nFor unmanned spacecraft that have no on-orbit repair capability, problems found and\ncorrected in the integr ation test may be the final determinant for mission success.\nAlthough not the intended purpose, integration testing does provide the final\nopportunity to verify the system meets the intended user requirements and to identify\nany system-level performance shortfalls. In a perfect world, the integration phase\nwould test interfaces only and would not identify any lower level failures (assuming\nthe previous test phases were performed successfully). In reality, integration testing is\noften the first system-level checkout of flight hardware and software interfaces. This\nthesis will focus on the integration test phases.\n2.4\nThe Role of Testing\nIn general, the purpose of test and evaluation activities is to determine the true system\ncharacteristics and to ensure that the system will successfully fulfill its intended mission.\n[19] Testing serves a dual purpose of verifying fulfillment of requirements while also\ndriving out uncertainty in system behavior due to imperfect requirements (which will\nalways exist).\nAs discussed, testing is considered one method of meeting the system verification and\nvalidation (V&V) goals and usually is performed to address risk and uncertainty that\ncannot be satisfactorily mitigated by other, less expensive, means (i.e. analysis, simulation,\ninspection). Spacecraft testing is sometimes considered synonymous with system V&V;\nhowever, this view may be misleading. V&V is the process by which systems are\nevaluated and has a twofold objective: to determine if the system meets the design\n(verification) and to verify that design performs the intended tasks (validation) and meets\nthe customer's needs. Stated differently, verification is the process of verifying that\nhardware and software operate according to the specified requirements (i.e. it does what it\nis asked to do) while validation is the process of determining whether the end product\n\nmeets the design and user intentions (i.e. it does what it is suppose to do). As such, system\nvalidation activities would be performed at a higher level in the system hierarchy. It\nshould also be noted that while verification establishes that the equipment being tested\nmeets the specified requirements, it does not evaluate the validity of the requirement.\nTherefore, special emphasis should be placed in the development of the requirements to\nensure they represent the actual intended system operation.\n\nChapter 3: Research Methodology and Data Analysis\n\"The beginning of knowledge is the discovery of something we do not understand.\"\n- Frank Herbert [20]\n3.1\nData Collection through Interviews\nIn order to capture expert knowledge regarding integration testing of human-rated\nspacecraft, a series of interviews with recommended experts in the testing discipline was\nconducted. The interview process was intended to solicit the tacit knowledge of the\ninterviewee and was not structured to obtained data for statistical analysis. A total of\nfourteen experts were interviewed. Nine of these experts were from NASA while five\nrepresented either government contractors or the aerospace industry. The number of\ninterviewees represented a broad spectrum of the testing community (from test engineers to\ntest program managers, both from government agencies and contractors), but was not\ndeemed large enough to constitute a valid statistical data population. From the interview\nprocess additional data was sought that would provide a statistical foundation for\nverification of the findings and recommendations presented in the testing framework. In\nfact, the statistical data was not forthcoming in sufficient quality or quantity to be useful.\nThe lack of statistical data, however, does not deter from the qualitative value of the\nknowledge obtained through the interviews and subsequent response analysis.\n3.2\nInterview Methodology\nThe interview methodology consisted of private sessions with each individual (or in some\ncases two individuals). Interviewees were selected from several sources, recommendations\nfrom Massachusetts Institute of Technology (MIT) professors and advisors, reputation,\npersonal knowledge of the researchers, associations with the MIT Systems Design and\nManagement (SDM) Program and recommendations from the actual expert interviewees.\nThe sessions were conducted in person wherever possib le or otherwise via telephone and\ntypically lasted approximately one hour.\nIn general, the interviews consisted of the two researchers asking questions regarding one\nof four focus areas of testing. The interviewees were provided an opportunity to describe\ntheir backgrounds and basic philosophies regarding system testing and systems\nengineering in general. This introduction period allowed the researchers to tailor the\nquestions toward a specific area of interest or expertise the interviewee may have\npossessed. For instance, a test engineer may have described their expertise in\nenvironmental (thermal) testing of hardware and how certain barriers existed that made\nconducting these tests difficult. In this case the engineer would be allowed to elaborate on\nthat specific aspect of testing (component and qualification level). The questions were\nfocused on their experiences, perceptions and challenges, based on their background.\nOften the interview included a discussion on philosophies regarding spacecraft testing\nprograms and then flowed into a discussion on the strengths and weaknesses of the\napproach in question. The interviewee was provided ample time to respond and then,\n\nthrough follow-up questions, asked to elaborate on the previous response. Confident ially\nwas assured so that the expert interviewees could provide frank responses without\nconsideration of consequences and to protect any proprietary knowledge regarding testing\nprocesses and procedures or financial information.\n3.3\nInterview Categories\nThe interview questionnaire consisted of five sections, an introduction and biography\nsection for the interviewee, and four sections on specific focus areas regarding spacecraft\ntesting. These areas include the role of testing, decision factors that influence how test\nprograms are implemented, cost factors that influence test programs and organizational\nissues relating to test programs.\nThe actual interview questionnaire is contained in\nAppendix A.\nSection I, a biographical section, was required to allow the researchers and interviewees to\nbecome familiar with each other. This section provided contact information, prior\nexperience and current responsibilities. The information was also used for demographic\nanalysis regarding coverage of the spacecraft-testing spectrum.\nSection II of the questionnaire focused on the role of testing and requirements definition.\nThis section identified the type of testing (i.e. qualification, acceptance, integration) that\nthe interviewee was most familiar with and how that particular testing phase adds value to\nthe overall spacecraft development process. Questions regarding the criteria and processes\nused to define testing requirements and how these are coordinated with the actual hardware\nand software development processes were also discussed. Finally, several questions\nregarding decision and cost factors were included to serve as transition points to follow-on\nsections.\nSection III of the questionnaire focused on factors that are considered in deciding what\ntests to perform on a spacecraft. Internal and external factors were sought as well as how\nmuch weight specific factors carry in influencing the final test requirements. This section\nalso introduced questions regarding the integration of hardware and software in human-\nrated spacecraft test programs and the implications of treating software differently from\nhardware and in delaying the integration of the two. Factors that influence decisions to\nmodify test programs were also sought.\nIn this context, the researchers explored\nsubjective influences such as the political environment and the effects they play on\nmaintaining or changing planned testing programs. The final objective of this section was\nto explore the value of identifying unexpected emergent properties in human-rated\nspacecraft through testing. This was an important issue to the researchers because of the\nperceived tendency for test programs to verify known requirements and not seek to identify\nunexpected behaviors prior to deployment.\nSection IV, budget and cost considerations, provided a transition from the decision-making\nfactors because these considerations serve as a separate influence on the level of testing\nperformed on human-rated spacecraft. The focus of the cost-related questions was to\ndetermine how well test program costs are planned, budgeted, monitored and reviewed\n\nupon completion of the program. Rules of thumb and other budgetary guidelines were\nsought for use in planning and implementing various phases of a human-rated spacecraft\ntest program. In addition, the influence of cost factors on the decision process was\ndiscussed.\nThe final section, Section V, of the questionnaire focused on organizational factors that\ninfluenced the success of test programs. Comparisons were made between actual test\nprogram organizational structures against those that the experts deemed most effective.\nQuestions also addressed organizational considerations given to software versus hardware\ntesting and the integration of the two. This section also sought out insights on how well\nknowledge is captured, retained and transferred to future programs.\nFinally, the\neffectiveness of documenting lessons learned and transferring them within the current\norganization, and to other programs, was discussed.\nAfter all the questionnaire topics were covered, a period of open dialog was provided in\nwhich the expert could elaborate further on any topic previously discussed and offer more\ninsights on other aspects of testing not included in the questionnaire. These discussions\nwere captured under a generic category called \"Other\" and served as the conclusion of the\ninterview process.\n3.4\nInterview Questions\nAs previously mentioned, the questions used in the interview process were designed to\ndraw out the tacit knowledge of the individuals as opposed to a verification of their formal\nknowledge regarding human-rated spacecraft testing or systems testing in general. The\nsequence of the questions was intended to begin with basic concepts and progress into\nmore abstract areas that are not widely covered in academia or formally considered in\nsystems testing documentation.\nThe interview questionnaire contained a total of fifty-two questions (Appendix A). Some\nquestions contained follow-up queries while others sought informational data only. Forty-\nfive separate questions related to expert knowledge of the individual while another seven\nwere for informational purposes.\nAlthough all questions were covered in the interview\nprocess, not all were sufficiently answered by the respondents. This reflects the wide\nspectrum of experience sought in the research.\nFinally, several questions contained\noverlapping themes that allowed the interviewee to answer them simultaneously, if they so\nchoose. For instance, question (20) asks about cost factors for determining the extent in\nwhich testing is performed. As the response was delivered and elaborated upon, it was\noften possible to segue to question (31), which addressed testing budgets. Therefore the\nquestionnaire was used as a guide rather than a formal process.\n3.5\nGoal of Interviews\nEach of the four major sections of the questionnaire correlated with specific areas of focus\nregarding human-rated spacecraft. The interviews were intended to capture knowledge of\nexperts regarding current test practices within NASA programs as well as the aerospace\n\nindustry in general. In concert with capturing knowledge regarding current testing\npractices, recommendations for improving on those practices, within the four focus areas,\nwere also sought. The body of knowledge compiled from the interviews served as the\nfoundation for further comparison to system engineering principles. A second goal of the\ninterview process was to gather enough responses from a diverse spectrum of testing\nexperts to allow identification of common themes that apply to system testing in general\nand human-rated spacecraft testing specifically. Finally, the interviews attempted to\ncapture best practices, as well as deficiencies, in organizing and implementing programs.\nThis goal is not specifically oriented toward test programs but toward an overall spacecraft\nprogram organization that provides the best chance of success.\n3.6\nOverview of Interviews and Method of Data Analysis\nThe interview process was conducted with both researchers present. Responses were\nrecorded individually by the researchers and later compared for consistency.\nThe\nresponses were then compiled electronically into a larger data set. The data set was built\naccording to the focus sections in the questionnaire. All responses were analyzed and\ncommon themes were drawn from each section through a process of grouping like\nresponses from different interviewees together.\nA system of maintaining anonymity was established that masked the responses but allowed\ntraceability back to the specific expert interviewees. The final data set of responses\nconsisted of over 500 separate items that were used in the analysis. A distribution of\nresponses to expert interviewee function is depicted in Table 1.\nINTERVIEW SECTIONS/FOCUS AREAS\nFunction\nII - Role\nIII - Factors\nIV - Cost\nV - Org/KM\nVI - Other\nTest Manager\nTest Engineer\nSystems Manager\nSystems Engineer\nIndependent\nVerification & Validation\nEnd User\nTotals\nTable 1 - Mapping of Expert Interviewee Responses\n\nThe process for evaluating the data consisted of categorizing each response individually\naccording to the focus section being reviewed. After all four sections were completed, a\nsecond phase of grouping the responses according to common themes was conducted.\nThis phase also identified themes that applied across each section. Those crossover themes\nwere also compiled and addressed in the final analysis.\nDevelopment of the common themes from the interviews was accomplished from the\nperspectives of the researchers' testing experiences.\nAn internal perspective was\ndeveloped from the researcher with extensive experience in human-rated spacecraft testing\nwhile an external perspective was developed from the researcher with limited testing\nexperience. These differing approaches to the interview responses provided a deeper\nunderstanding of the knowledge captured and resulted in a broad set of recommendations\nfor future test programs. Finally, after the interview data analysis was completed, a\ncollection of overall themes and insights emerged. These along with the literature\ninformation were used to develop the common themes and findings described in Chapters\n4 and 5.\n\nChapter 4: Themes Resulting from Expert Interviews\n\"It All Depends\"\n- Expert Interviewee [21]\n4.1\nIntroduction\nUpon completion of the interview process, as described in the previous chapter, a set of\ngeneral themes was developed from the compilation of the expert responses. These themes\nrepresent the most commonly held opinions and perceptions among the expert interviewees\nbased on their testing experience. This chapter will address five primary themes that were\nthe most prevalent topics from the aggregate of the expert responses. General insights and\nfindings derived from the interviews are presented in the next chapter.\nThe primary themes that emerged from the interviews are:\no Subjectivity of test requirement development\no Paradoxical nature of testing\no Vulnerability to changes and cutbacks\no Inadequate attention to testing\no Organizational influence on the testing process\nEach of these is now discussed further.\n4.2\nPrimary Themes\nThe primary themes represent a common set of knowledge derived from the expert\ninterviews. These themes, along with literature research, serve as a foundation for the\ndevelopment of findings and recommendations presented in later chapters.\n4.2.1\nSubjectivity of Test Requirement Development\nAlthough not specifically asked in the interview process, the subjective nature of\ntesting was mentioned by almost all of the expert interviewees. The essence of this\nsubjectivity comes partly from the risk identification and mitigation process and partly\nfrom the systems requirements process. As mentioned in Chapter 2, testing serves as\nrisk mitigation. Risk is traditionally discussed in terms of both the likelihood of a\nspecific outcome occurring and the consequences that would result. [22] Because\ndetermining risk levels is highly subjective, especially for new designs and\narchitectures, testing will in turn be highly subjective. It is also impossible to perfectly\n\nrelate risk to testing since so many additional factors apply, such as the ability to\nrecreate the operating environment on the ground. [23]\nIn system requirements development, the system architect must answer the question \"is\nthis what the customer wants\"? Once answered, the requirements for the system can be\nestablished. Test requirements flow from these system requirements and attempt to\nanswer the question \" how do I prove it\"? [24] Because each system is different and\nhas different system requirements, the test requirements will be different as well. These\ndifferences in system and test requirements make it difficult to generalize testing.\nOne additional reason that testing is very subjective is the nature in which test\nrequirements decisions are made. There currently are no concrete rules on how much\ntesting must be performed. The decision is a trade-off between available resources to\nperform the testing and the amount of risk the program is willing to accept. These\nfactors change with the situation, and when added to the biases of the individual\ndecision maker, a quantitative answer is not likely. [25] Some even report that a \"well\nguided gut instinct works about as well as anything else\". [26] The subjective nature of\ntesting is a significant factor in every facet of a test program, as will be demonstrated\nthroughout this thesis.\nDue to the subjectivity, testing practices are not consistent across the aerospace\nindustry or in comparison with the commercial aircraft industry. These inconsistencies\ncan be observed in every phase of the test program. Most notably is in the inconsistent\nway in which terms are used to describe test activities. This lack of standardization in\nterms required the need to establish definitions for use in this thesis (Chapter 2).\nAnother source of inconsistency is the wide variation in the way projects are organized,\nwithin and across programs and companies. A third inconsistency is in the process of\ndefining, implementing and tracking test requirements. All programs treat testing\ndifferently due to unique requirements and conditions. Interestingly, most expert\ninterviewees would like to see some level of standardization to minimize the\nsubjectivity but they are very skeptical that this standardization could ever be\nsuccessfully accomplished.\n4.2.2\nParadoxical Nature of Testing\nAnother prevalent theme throughout the expert interview process was the paradoxical\nnature of testing. Intuitively, people know that more testing is better than less testing.\nWith unlimited time and budget, testing would never be an issue because the program\nwould simply test everything. In reality, cost and schedule constraints are always\npresent. The program success is not only based on the successful operation of the\nsystem but also on whether it was completed on time and within budget. Testing is\noften considered an insurance policy against future failures. Program management\nmust perform a risk-benefit analysis to determine the wisest use of program resources.\n[27]\n\nEven on the technical side, what constitutes a successful test is itself a paradox. A\nhardware test that uncovers multiple problems can be considered just as successful as a\ntest that verifies the flawless operation of a perfectly designed and built system.\nConversely, for software it is easy to write test cases that will be successful, however,\nthese cases will only be effective if they show how the system does not work. Both\nhardware and software testing serve the purpose of risk mitigation towards ensuring a\ncorrectly operating system. This paradox creates a managerial view of testing as an\nunrecoverable program cost rather than a value proposition of long-term program cost-\navo idance. True costs for testing are not calculated in terms of cost prevention, only in\nterms of actual costs to perform the test. Hence, the cost savings of identifying an error\non the ground and fixing it before launch is often not a consideration in determining a\ntest program's success.\n4.2.3\nVulnerability to Changes and Cutbacks\nAdding to the subjectivity and paradoxical nature of testing is the fact that most testing\noccurs late in the development phase. The prevalence of late testing leads to the next\ncommon theme: testing is vulnerable to changes and cutbacks.\nThe first source of change comes from incomplete test requirements. Very often the\nactual design itself is in flux and the system requirements are continuously changing.\nThis in turn results in a changing test program. The higher the fidelity of the early test\nrequirements, the more stable the testing requirements and planning will be at the end\nof the development phase. [28] Also, as new knowledge is gained about system\noperation, new methods of testing may be developed and synergies between stages of\ntesting can be incorporated into the test plan.\nAs budget and schedule pressures increase during the development phase, managers\ntend to accept more risks and are therefore willing to agree to more cutbacks in testing.\nAgain, the more stringent the requirements, the less vulnerable the test program will be\nto these reductions. [29] Since the budget and schedule pressures are most keenly felt\nat the end of a development program, testing is extremely vulnerable because it is one\nof the only remaining opportunities left to make up schedule or cut costs. Some test\nprograms are budgeted early in a program and the budget is placed in a reserve status.\nHowever, if proper care is not taken to preserve the funding, the test budget can be\ndecimated by the time the testing is scheduled to begin. Even fiscal year considerations\nmay change the timing of a test program. One interviewee reported that testing can be\ndelayed until the start of the fiscal year when new funding became available. [30]\n4.2.4\nInadequate Attention to Testing\nThe fact that testing, as an activity as well as an organization, does not receive the same\nattention as other elements of a program was another common theme of the expert\ninterviews. In general, testing is recognized as an important part of a project. Yet as\nmentioned earlier, because testing typically occurs at the end of development, it does\nnot receive as much emphasis during the initial planning phases as it should. The\n\ninadequate attention can be in the form of time, budget, or forethought spent on the\nvarious activities. Understandably, design has to take precedence in defining the\nfunction and form of the system in the beginning of development. It is only after the\nprogram is well underway that testing begins to receive the consideration it deserves. If\nconsideration to testing is not given at the beginning of a program, it may be too late to\nensure the most efficient and thorough test planning and implementation. Many of the\ninterviewees expressed frustration with this trend. It was common to hear how test\nrequirements were not finalized soon enough. One expert summed it up as \"not enough\nemphasis is placed early enough on high-quality test requirements, equipment, and\nprocedures. We make it work but its not efficient\". [31]\nAnother concern within the testing arena that was repeatedly mentioned in the expert\ninterviews is a lack of training and mentoring. Formal training in testing is not typically\nprovided. The skills needed to be a good test engineer are learned on-the-job but these\nskills are not proactively maintained or developed. Within NASA, the standard\nprogram processes and procedures do not address the detailed implementation\nstrategies for testing. Much time and effort has been put into other areas of program\nand project planning, but testing has not received its fair share. According to some of\nthe expert interviewees, the lack of a detailed documented testing strategy has meant\nthat each program, or new program participant, has had to relearn important lessons\nfrom the past. The experts recommended that more should be done to capture these\nbest practices in order to provide decision makers with some guidelines for test\nplanning. [32] The subjective nature of testing, along with a concern about the ability\nto generalize the knowledge, may be possible reasons that these best practices have not\nbeen documented in the past.\nAlso emphasized during the expert interviews was the desire to perform test planning\nin parallel, but one step out of phase, with the development of the hardware and\nsoftware. As one piece of the design process is completed, test planning should take\nplace. The same is true for actual test implementation. Several of the expert\ninterviewees suggested that the deficiencies in test planning might be an organizational\nissue. Not enough forethought tends to be given to how a program will be structured to\nallow for the most effective test planning and implementation. Many of the expert\ninterviewees reported that test engineers do not hold the same status or standing that\nother engineers do within the program. These test engineers are often not as respected\nas other engineers and as such, do not receive the same opportunities or receive as\nmuch attention. Other divisions within the program and/or organization tend to receive\nmore prominence than testing. This inequality leads to the next common theme found\nin the expert interviews: the effect of organizational structure on test program success.\n4.2.5\nOrganizational Influences on the Testing Process\nA number of the expert interviewees, especially the contractor representatives,\ndescribed the benefits of having a separate testing organization that can concentrate on\nthis one area of the development process. However, an independent testing\norganization does have limitations and poses new challenges that must be addressed.\n\nThis section will focus on these organizational issues, from the point of view of the\nexpert interviewees.\nOne observation made from the interviews is that there was not a consistent\ninterpretation of what was meant by \"test organization\". For some, the test organization\nincludes the actual technicians that perform the operations on the flight and ground\nequipment. For others, the test organization is those individuals in a program office that\nare responsible for overseeing test activities. For the purpose of the interviews, and for\nthis thesis, \"test organization\" will refer to those engineers accountable for\nimplementing test requirements and the program management functions responsible for\nthese activities.\nA prevalent assertion encountered during the interview process was the need to develop\ntest-engineering skills. Having a separate test organization was recommended as one\nmethod of developing skills, facilitating knowledge transfer and improving\ncommunication. This independent organization also allows for a consistent test\nphilosophy to be established and implemented. It ensures that attention is focused on\ntesting activities eve n while the program management may be concentrating on other\nissues. To receive the maximum benefit, the test organization should be involved in the\nvery early stages of design and planning.\nAnother benefit of having a separate pool of test engineers is the ability to be flexible\nwith the resources. Flexibility is particularly important in the component, qualification\nand integration testing stages of development. During component and qualification\ntesting, the schedule is constantly changing and resource loading must always be\nadjusted. A pool of test engineers can be an efficient use of engineering resources. [33]\nFor integration testing, a dedicated test team is important because the test engineers\nneed to be are familiar with the overall system operation. Because these same\nindividuals have been involved with the earlier testing, they will have developed an\nunderstanding of the operation of the system and any idiosyncrasies that may be\npresent. [34] Having previous experience with the hardware and software can be very\nimportant in recognizing system trends and unexpected emergent behavior.\nSome organizations provide a mixture of a dedicated test team, along with other\nindependent reviews. As an example, the commercial aircraft industry uses a separate\ntest group for highly critical systems. The Federal Aviation Administration (FAA) has\nmandated that independent testers and inspectors verify all critical requirements in the\ncommercial airline industry. [35] For lower criticality systems, two developers verify\neach other's work.\nWhile having a separate testing organization can be beneficial, it cannot operate in a\nvacuum. Good communication is essential, especially between test engineering, system\nengineering, software/hardware designers and operations personnel. Many expert\ninterviewees emphasized the need to establish good relationships early and to maintain\nthe interfaces throughout the project. Very often adversarial relationships are formed\n\nbetween the different groups, severely hampering communicatio n and negatively\naffecting the development process.\nThere are other limitations of having a separate test organization. Besides the increased\nneed for good communication, comprehensive integration is also required. This need is\nmagnified with geographical distance and contractual differences between designers,\ntesters and system integration organizations. Having a separate test organization can\nactually detract from the effectiveness of the project and create inconsistencies rather\nthan standardization when these geographic distances or contractual differences are\npresent. Extra care is needed to provide strong system engineering and integration\nbetween the various groups when extreme organizational differences are present.\nThe need for a strong functional organization to maintain skills was also cited in the\ninterviews. Having a strong functional organization is important for both a dedicated\ntest teams, as well as for Integrated Product Teams (IPT). A number of contractor\nexpert interviewees reported success using the IPT structure. Keys to its success\nincluded a strong functional organization to support the test representatives and strong\nintegration between the individual IPTs. [36]\nOther interviewees described\nunsatisfactory experiences with the IPTs. A lack of a strong functional foundation and\nweak integration were possible explanations for the poor execution of the IPT\nstructure. It should also be noted that even for those organizations that utilized IPTs,\neach was implemented in a different manner. These findings imply the need for better\nunderstanding of effective IPT structuring. A further description of an IPT structure is\nprovided in the next chapter.\nDuring the expert interviews, questions about the NASA software Independent\nVerification and Validation (IV&V) process were asked. The responses provided a\nunique, and useful, insight into NASA's test philosophies and practices. The following\ndiscussion was not utilized in the development of the overall findings because it is not\ntechnically considered a testing organization. However, parallels can be drawn between\nIV&V and testing. Because this information is deemed to be valuable, it is included in\nthis chapter.\nWhile the IV&V organization does not perform actual testing of software products, it\ndoes provide an independent review and monitoring of the processes used in test\nrequirement development, test conduct and data analysis. NASA has criteria for\ndetermining when a particular project is required to employ IV&V. [37] The programs\nthemselves are responsible for proactively performing a self-assessment and arranging\nfor an IV&V review. The researchers found little evidence, however, that this process\nof self-assessment was well understood outside the IV&V community. In fact, the\ncriteria used for performing the self-assessment was not clearly defined in program\nmanagement processes, nor was it readily available for use by program managers.\nThe IV&V community does police programs to ensure proper use of the IV&V review.\nOne factor hampering their ability to assess the need to perform IV&V on NASA\nprojects is the difficulty in compiling a complete list of all projects currently underway.\n\nA hit-or-miss record of involving IV&V in software development has resulted from the\nunavailability of a complete list of NASA projects. [38] Fortunately, IV&V has been\ninvolved in human-rated spacecraft development, most likely due to the limited\nnumber and high visibility of the programs.\nIronically, each individual project must finance the IV&V effort. There was evidence\nthat some projects do not want to have an IV&V audit performed. This resistance is\noften a result of not understanding the value added in performing an independent\nreview. Often projects see this review as a drain on resources, both in time and money.\nThese resources are usually needed for other efforts that are perceived to be more\nvaluable. From this standpoint, IV&V and testing suffer from the same barriers, biased\nperceptions and lack of appreciation.\n\nChapter 5: Findings Derived from the Expert Interviews\n\"Test Early and Often\"\n- Expert Interviewee [39]\n5.1\nIntroduction\nThe expert interviews, along with the literature review, yielded some significant findings,\nwhich are described in this chapter. These findings are meant to shed light on some the\nchallenges that the testing community currently faces as well as to provide the foundation\nfor the recommendations described in Chapter 6. With over 500 individual responses\ncollected and analyzed from the expert interviews, a great deal of information regarding\nhuman-rated spacecraft testing was captured. For this thesis, the most significant findings\nare discussed in detail. These findings include:\no For some projects, software is considered a stand-alone system\no Optimism varies with organizational position\no While testing practices vary, decision factors do not\no Upfront planning is a key to success but be prepared for change\no Current methods of tracking testing costs are not sufficient\no Testing is more of an art than a science\no Good sub-system engineering is not a substitute for proper system engineering\no Program/Agency culture strongly affects testing\n5.2\nStand-alone Software System\nToday's systems are becoming increasing more reliant on software to operate successfully.\nHowever, there is evidence that for some projects, software is not being treated as an\nintegral part of the overall system. Instead, software is viewed as separate stand-alone\nsystem, posing a number of challenges and concerns, especially for the testing activities.\nBecause the system hardware and software are usually highly interdependent, they must be\nconsidered as one integrated system. Very often both the hardware and software must be\npresent for the system to operate. To truly verify the system requirements, the actual flight\nhardware must be integrated and tested with the flight software. Some of the evidence that\npoints to the premise that software is being treated as a system of itself is provided by the\norganizational structure, the process by which the software is tested and delivered, and the\nlimited insight that sub-system engineers have into the software development process.\nA human-rated spacecraft project's organizational structure is one indicator of how\nsoftware is handled in general. Some projects and programs use Integrated Product Teams\n(IPTs) with software being an integral part of each IPT. An IPT is an organizational\nstructure that consists of cross-functional teams dedicated to an individual product, project\n\nor system. Each team includes representatives from the various functional departments.\nThe IPT structure is used to increase communication and coordination between the\ndifferent disciplines involved in a common system. [40] A simplified example of an IPT is\nshown in Figure 4.\nIPT #1\nIPT #1\nIPT #1\nSoftware\n\nSoftware\n\nSoftware\n\nMechanical\n\nMechanical\n\nMechanical\n\nElectrical/\n\nElectrical/\n\nElectrical/\n\nAvionics\n\nAvionics\n\nAvionics\n\nQuality\n\nQuality\n\nQuality\n\nProject Manager\nIPT #2\nProject Manager\nIPT #2\nProject Manager\nIPT #2\nIPT #3\nIPT #3\nIPT #3\nFigure 4 - Simplified Integrated Product Team Structure\nOn the other hand, some projects have segregated all software engineering into a separate\norganization. At the extreme, the separate software group is housed in an entirely different\ndivision from the systems engineers (as shown in Figure 5). This organizational distance\nalso serves to disassociate software from the rest of the system and limits the sub-system\nengineer's visibility into the software development process. In one interview, a system\nengineering expert admitted that sub-system engineers do not typically see the software\nspecifications or the test procedures. [41] This lack of visibility goes completely against\nthe philosophy of true systems engineering.\n\nProject\nManager\nSpacecraft\nSystems\nAvionics and\nSoftware\nProject\nManager\nSpacecraft\nSystems\nAvionics and\nSoftware\nProject\nManager\nSpacecraft\nSystems\nAvionics and\nSoftware\nSub-System Engineers\n\nSoftware Developers\n\nFigure 5 - Simplified Organizational Structure with Segregated Software Group\nAnother organizational concern with the software development process is the contractual\nstructure for breaking down the software segments. Some program split the responsibility\nof software development between contractors. When the split also involves a substantial\ngeographic distance (as is common), effective communication is hampered. In addition, the\ndevelopment of the hardware and software for the same system may also be parceled out to\ndifferent companies. The software product then becomes a program deliverable in and of\nitself, providing a further indication that for some programs, software is handled as a\ndistinct element. The inclination to treat software separately is not unique to NASA. US\nDepartment of Defense (DoD) standards have actually mandated this separation as recently\nas 1997 (Figure 6). [42]\nFigure 6 - DoD Model for System Development [43]\n\nOnce delivered, the process for testing the software differs from that of the hardware.\nSome differences should be anticipated because software is not a tangible element and\ncannot be tested to failure as is done with hardware. Because there is not a physical\nembodiment of the system, the tester must rely completely on the quality of the\nspecification in order to verify the intent. In addition, the same building block approach for\ntesting may not be applicable to software, as it is with hardware. While the software may\nbe developed in discrete modules, it often cannot be tested as a standalone module.\nThere are lessons from hardware testing that should be incorporated into software testing.\nOne example relates to retest. Typically when hardware is replaced after a test has been\nconducted, the retest is typically quite intensive. Not only are the interfaces retested but in\nmany cases, the integration tests are also performed again. The tendency in software is to\njust retest the module in question and then to plug it back into the system without an\nintegrated test. [44] This is one indication of the popular (but false) perception that\nsoftware is easier, and safer, to change than hardware. In fact, this is not true. According to\nLeveson (Safeware, 1995):\n\"Changes to software are easy to make. Unfortunately, making changes\nwithout introducing errors is extremely difficult. And, just as for hardware,\nthe software must be completely reverified and recertified every time a\nchange is made, at what may be an enormous cost. In addition, software\nquickly becomes more 'brittle' as changes are made - the difficulty of\nmaking a change without introducing errors may increase over the lifetime\nof the software\" [45]\nThe system engineer must be an integral part of this process of evaluating the changes and\nsubsequent implementation in order to maximize the chances of success.\nOne theory as to why software is treated separately from hardware may be the history of\nthe program and the background of test managers themselves. In general, there is not a\ngood understanding of software engineering by those not in this profession. Most managers\ncurrently have a hardware engineering background. They may not truly appreciate the\nunique aspects of software development and testing. Many of these managers try to apply\nto software the same hardware paradigm that worked so well for them in the past.\nSoftware, however, has many fundamental differences in the way it is developed and\ntested. As mentioned in the previous chapter, testing is inherently subjective, but the\nabstract nature of software makes the testing of software even more subjective. When\nsoftware is treated as a separate system, compounded with this added subjectivity, stronger\nintegration and greater attention to details becomes critical. Unfortunately, the temptation\nto delegate the decisions to the software community is also greatest under these\ncircumstances.\n5.3\nVarying Attitudes Toward Test Effectiveness\nAn insight that resulted from the interview process was the observed differences in attitude\ntoward the effectiveness of testing among those at various levels of the organization. It was\n\nevident that the lower level system and test engineers were much more pessimistic and felt\nthat too much risk was being taken by not testing enough. They did not have a clear\nunderstanding of the process that the decision makers went through, and they were the\nmost likely to see the process as arbitrary. Our research showed that the optimism level\nclearly increased as one went up the chain-of-command toward the managers. Most\nmanagers were proud of what had been accomplished and were confident that their test\nprograms were highly successful.\nThere are several possible reasons for why an individual's outlook on testing changes with\ntheir organizational position. The first is an individual's ability to take a holistic view of\nthe entire project. Senior managers have a larger view than many engineers at the lower\nlevels. The lower-level system and test engineers are primarily concerned with their own\nsystem and its successful operation. Managers on the other hand must balance the entire\nsystem, along with the external influences. They are the ones that understand the political\nfactors involved with the project. In turn, the program manager's risk aversion level is\ndifferent from that of the lower-level engineers. The program managers must make the\ntrade-offs and, as such, are perceived to have a higher tolerance for risk. These project\nmanagers do understand, however, that they are responsible for accepting risk as part of the\ntrade-off decisions. As one project manager stated \"I was willing to take the risk of not\ntesting what I flew. As the project manager for the ...mission, I was the one who\nultimately decided what risks to take...\". [46]\nAnother possible reason for the differing level of optimism is that the understanding of the\ndetailed technical information is most likely not consistent across the organization. It is\nreasonable to think that the lower-level engineers understand the operation of their system\nbetter than the managers. Information may not be conveyed to managers in a way that\nallows proper risk evaluation. When this less-than-perfect knowledge is combined with the\nother external pressures, managers may be accepting more risk than they think.\nThe established culture also plays a role in the differences in optimism. NASA has\nhistorically had a culture of risk taking but at times has also been accused of being too risk\nadverse. Depending on the culture of a particular project, acceptable risk level changes. In\naddition, while the current NASA culture is very accustomed to fixing technical problems\nas soon as they are discovered, the process for reversing bad decisions made early in a\nprogram has not yet been institutionalized. It should be noted that program and test\nmanagers do not make bad decisions on purpose or out of incompetence. Early in a\nprogram, all the information may not be available or may not be accurate. Managers make\nthe best decisions they can at the time but these decisions are rarely re-evaluated. The\nlower-level engineers may recognize these as bad decisions, but the managers may not\neven be aware there is an issue. The tendency is to just work around the issue, rather than\nchange the ground rules. This tendency is not unique to human-rated spacecraft or to\nNASA but can be observed in many industries.\n\n5.4\nTest Program Decision Factors\nBecause of the subjectivity and inconsistency of test programs, many interviewees thought\nthat parallels could not be drawn across programs. In contrast, we found that there is\nconsistency in the decision factors used by the various decision makers. What does\nchanges are the decisions that are made based on these same factors. Each decision maker\ntakes a slightly different approach to making test requirement decisions. Some rely on the\ninputs of the system engineers more than others. Some have a formalized thought process,\nwhile others rely more on instinct. When probed further, there is a common set of factors\nthat are included in the decision process. These factors are not all equally weighted nor\ndoes the weighting remain constant throughout the process. Situational and other external\nfactors do have a large influence. Perhaps the biggest variable is in the differences between\nthe decision makers themselves.\n5.4.1\nTechnical Factors\nThree technical decision-making factors have been identified that deal directly with the\nspacecraft systems -safety, risk and confidence level. These technical factors are now\ndescribed further.\n5.4.1.1 Safety\nIt was clear through the expert interviews that safety is the first priority when making\ntesting decisions. NASA's Program and Project Management Processes and\nRequirements document defines safety as:\n\"Freedom from those conditions that can cause death, injury,\noccupational illness, damage to or loss of equipment or property, or\ndamage to the environment\" [47]\nAny items that could pose a threat to the safety of the astronauts are weighted the\nhighest. The next concern was the safety of the spacecraft and the people working on\nit.\nSafety is never intentionally compromised in the decision-making process. This is\nnot to say that safety in itself is never compromised. The failure of the Mars missions\nmentioned earlier in this thesis is evidence of this unintended consequence. Had\nmore, or better, testing been performed, it is likely the missions would not have\nfailed. A difficulty that program managers face is understanding what conditions\nconstitute a threat to safety. While every program manager knows that safety is the\nfirst priority, they may not know when their decisions actually compromise safety.\nAnother component of safety that factors into decisions is that of ground operations.\nSome tests pose a serious safety concern when performed during integration testing,\nin particular, when they require the use of hazardous materials. In these cases, the\nproject manager must weigh the benefits of performing the test in actual flight\n\nconditions versus the possibility of the ground team being exposed to hazards during\noperations. Again, it appears that safety does weigh very heavy in this decision\nprocess. All other means are explored first and performing hazardous operations on\nthe ground are only conducted when absolutely necessary.\n5.4.1.2 Risk\nBeyond safety, other aspects of risk were a major factor in the decision-making\nprocess. NASA's Program and Project Management Processes and Requirements\ndocument (NPG 7120) defines risk as:\n\"The combination of (1) the probability (qualitative or quantitative)\nthat a program or project will experience an undesired event such as\ncost overrun, schedule slippage, safety mishap, compromise of\nsecurity, or failure to achieve a needed technological breakthrough;\nand (2) the consequences, impact, or severity of the undesired event\nwere it to occur.\" [48]\nThe greater the risk, whether in the form of likelihood or consequence, the more\ntesting will typically be performed. The risk assessment, and minimally acceptable\nrisk, depends on the particular project and the circumstances. There are often pre\nconceived biases of the likelihood and consequences are for particular projects.\nThese pre-conceived opinions have led to some general misconceptions. For\nexample, in one interview, the expert denoted that human-rated and expendable\nspacecraft must be treated differently. Human-tended spacecraft have the ability to\nmake repairs on orbit while satellites do not have the same opportunity. [49] In\nreality, the same factors apply to both types of spacecraft but the only difference is in\nthe respective consequences. In addition, it is often believed that human-tended\nspacecraft can accept more risk of finding non-critical errors on-orbit due to the\nability of repairing. This does not address the fundamental issue of the likelihood\nthat the error can be detected or corrected once discovered. The ability to detect and\ncorrect a failure must be included in determining the consequence level. Each\nproject must assess the relative risk but the resulting actions for testing will differ\nbased on the circumstances.\n5.4.1.3 Building Confidence\nAnother prime factor that may not be as obvious to the decision maker is the amount\nof uncertainty present. Uncertainty defines how well the risk can be determined. It is\nbased on the amount of system knowledge that is available at the time of the\ndecision. For example, the amount of previous experience with a design or the\namount of testing previously completed contributes to the overall system knowledge.\nAs system knowledge increases, confidence in the system's operation also increases.\nThere are a number of other factors that also contribute to the overall level of\nconfidence in a system. The sources of uncertainty in the system's operation are\noutlined in Table 2. It is important to note that it is these factors that are often\n\noverlooked or underestimated in the decision-making process. By not considering\nthese factors, many program managers have encountered difficulties.\nSources of Uncertainty\n- New design\n- New interfaces\n- Previous testing\n- Hardware/software maturity (design and build)\n- Complexity of system\n(including number of interfaces/interactions)\n- Possible unexpected emergent behavior\n- New technology\n- New application for reuse\n- Reliability of information\n- Team experience\n- Required fidelity of results\nTable 2 - Sources of Uncertainty\nMost managers and decision makers recognize that new designs, technology, and\ninterfaces create additional uncertainty, while previous testing increases confidence\nfor the project. However, one of the most under-appreciated sources of uncertainty is\nreusing existing components in new applications. Decision makers repeatedly\nassume that reuse of a component of hardware or software will reduce the\nuncertainty level of the system. Unfortunately this is often not the case. The new\napplication and new interfaces may in fact increase the uncertainty, unless enough\ntime and effort is invested in a thorough review and analysis. One example of the\nperils of software reuse was experienced on the maiden flight of the Ariane 5\nlauncher in June 1996. [50] Approximately 40 seconds into the flight, the launcher\nveered off course sharply, began to break up and then exploded. An investigation\ninto the accident revealed the cause of the failure to lie in the Inertial Reference\nSystem. At approximately 37 seconds into flight, the backup inertial reference\nsystem became inoperative when an internal variable that refers to the horizontal\nvelocity exceeded a specified limit within the software. Simultaneously, the active\ninertial reference system experienced the same error, because both were operating\nwith the same software. At this point the internal reference system fed diagnostic\ninformation back to the main computer. The main computer interpreted the\ndiagnostic data as flight data and adjusted accordingly, sending the launcher off\ncourse. The resulting forces created by the drastic correction caused the launcher to\ndisintegrate and then self-destruct.\n\nThe software used in the Ariane 5 launcher was the same inertial reference system\nsoftware that successfully operated in the Ariane 4. The team chose to reuse the\nsoftware for the new launcher, even though all the features were not needed in the\nnew application. The team failed to recognized ahead of time the differences\nbetween the Ariane 4 and Ariane 5 initial acceleration and trajectory. The Ariane 4\nlauncher would have never reached the internal horizontal velocity limit within the\nsoftware. However, the Ariane 5 reached, and exceeded, the limit by design. The\nteam did not appreciate the impact of reusing the software and their review process\nwas not stringent enough to catch the problems that would be caused by the internal\nreference system sending bad data to the main computer. In addition, since the\ninertial reference system was used previously on the Ariane 4, it was not tested under\nthe Ariane 5 flight conditions. This test could have caught the error prior to launch.\n[51]\nNASA's Mars Climate Orbiter (MCO) also experienced a failure due to a reuse of\nsoftware without a thorough understanding of the implications. The MCO reused\nsoftware code originally developed for another spacecraft for the thruster trajectory\nequation. The conversion code was in British units but the specification called for\nmetric. The code was obscure and the specification was not well understood or\nreviewed with the reuse application. The subsequent mismatch of units resulted in\nthe loss of the MCO. [52]\nThese examples (and many other losses resulting from the reuse of software)\ndemonstrate a possible downside of reuse; decision makers may be lulled into a false\nsense of security due to success in the past. There was a general impression among\nthe expert interviewees that as they gained more experience with the systems, their\nconfidence level increased. There is a potential that this confidence could translate\ninto rationale to cut back on planned testing. Sometimes such reductions may be the\nappropriate action but a thorough review and analysis must take place first.\nAppropriate decision-making must take into account that similar components are not\nguaranteed to behave identically.\nAn additional source of uncertainty includes the overall experience level of the team.\nIf the project team includes a large number of relatively inexperienced engineers,\nthere is an increased chance that an error will be made in the development process.\nProject managers cannot necessarily rely on good engineering practices to ensure the\nproper design and manufacture of the spacecraft systems. Additional testing is\nwarranted to mitigate the effects of an inexperienced team.\nMost of the interviewees recognized unexpected emergent behavior as a source of\nuncertainty in the system's operation yet few could describe a standard process for\ndriving out this behavior. Most system and test engineers suggested additional\ntesting in off-nominal and maximum use conditions as a means of discovering\nunexpected behavior. A number of the managers, however, believed that their\ncurrent test programs were sufficient to drive out this uncertainty. Consciously\n\naddressing any potential unexpected emergent properties is important and the test\nprogram should be designed to uncover as much of this behavior as possible.\nThe remaining sources of uncertainty include: the maturity of the hardware and\nsoftware, the complexity of the system, the reliability of the information available to\nthe decision maker and the required fidelity of the results.\nThese factors are\nrecognized and understood by the decision makers but may not be a conscious\nconsideration during the decision-making process. In order to achieve the best\npossible results, decision makers should think through each of the sources of\nuncertainty before making a final decision.\n5.4.2\nNon-Technical Factors\nJus t as strong of an influence can come from external or non-technical factors. Even\nthough they occur outside of the system, non-technical factors can apply a great deal of\npressure on the system or on the decision maker. These factors are included in Table 3\nand are discussed further in the following sections.\nNon-Technical Factors\nAvailable Resources\nProcess\n-\nBudget\n-\nRequirements\n-\nSchedule\n-\nTest strategy\n-\nTest Equipment\n-\nHardware/software development\n-\nFacility Readiness\n-\nContract type\n-\nAbility to test\n-\nOrganizational structure\n-\nSimulators/emulators\n-\nProcedures\n-\nPersonnel resources\n-\nLimited life (lifecycle)\nPolitical/Cultural Environment\n-\nChanging priorities\nIndividual Decision Making Behavior\n-\nNature of relationships\n-\nKnowledge\n-\nOptimism/pessimism\n-\nSubjectivity\n-\nInternational implications\n-\nBiases\n-\nFunding Source\nTable 3 - Non-Technical Factors\n5.4.2.1 Resource Availability\nTesting decisions regarding resource availability involve cost, schedule, equipment,\nfacility readiness and personnel. While resource issues are addressed during the\nplanning process for testing, they often become subject to changing events that are\n\nunrelated to the specific program under development. Therefore, in reaction to\nexternal events, adjustments to resources often appear as the best and only\nalternative. Consideration of resource alternatives in response to individual\ncircumstances, while ignoring other related factors, can have a detrimental effect on\na test program. For instance, delays in testing schedule are often made to\naccommodate the needs of other programs. An approach that accepts delays without\nconcessions often results in increased costs to the program incurring the delay.\nAnother example of the need to address resource availability in a holistic manner is\nillustrated by the various resource alternatives such as simulators, emulators and test\nequipment.\nBy addressing the total resources available for accomplishing test\nactivities, managers can often decide to substitute a planned test with an acceptable\nalternative using a different approach, thus preventing cost and schedule impacts.\n5.4.2.2 Process\nProcesses have an important role in ensuring successful implementation of test\nprograms.\nDecisions regarding the testing strategy, contract approach, process\nrigidity and organizational structure must be considered early in the program in order\nto ensure proper resource availability later in the program.\nPerhaps the most\nimportant of the process-related factors involves test requirement development and\nimplementation. Ambiguity in requirements often has the down-stream effect of\nincreased changes during test implementation phase, which often results in cost and\nschedule impacts.\nContract strategy is another important process decision that\nshould be given careful consideration early in a test program. While fixed-price\ncontracts offer cost and schedule fidelity, they often do not adequately address\nchanges nor are they flexible enough to add new work without significant cost\nimpacts.\nTest implementation involves a number of processes such as change management,\nconfiguration control and test procedure development and performance. The\nformality and stringency of these processes will affect the success of the overall test\nprogram. For example, decision-making processes for testing are established to deal\nwith changes in testing requirements. A rigid process will increase the chances that\ntesting decisions will be made in accordance with the established guidelines.\nConversely, a process that is not firm will allow subjective considerations to heavily\ninfluence decisions. Because processes are used as a means to accomplish the tasks\nof a particular project, they should be tailored to the needs of the each project. In\naddition, changing processes once a test program has begun is extremely difficult\nwithout incurring heavy impacts on other aspects of the program, namely cost and\nschedule. Changes to the established processes should not be undertaken without\nserious consideration or unless absolutely necessary. It is much more efficient to\nensure that the required processes are established during the planning phases of a\nproject.\n\n5.4.2.3 Individual Decision-Making Behavior\nThe ability of the decision maker to gather and interpret information regarding test\ndecisions is rarely addressed while planning or evaluating test programs. Because it\nis accepted that decision makers achieve their positions through technical and\nmanagerial competence, there is usually no mechanism for reviewing the quality of\nprevious decisions as part of the process for making current decisions. Factors such\nas the decision maker's technical and managerial ability, individual biases, and the\nsubjectivity of the information all influence the quality of their testing decisions. Of\nthese factors, decision biases are least likely to be controlled because sufficient\noversight or independent review of the decisions is rarely provided. Therefore, any\nframework for decision-making should attempt to minimize biases of the decision\nmaker.\nFor instance, a manager with a background in hardware development might\nconsider software testing decisions in the context of their previous hardware testing\nexperience, while another manager with a project management background might\nemphasize cost and schedule considerations equally to those of technical\nrequirements.\nFinally, it should be noted that decisions are only as good as the\ninformation that is available. Therefore, quantifiable data that can be compared in\nequivalent terms is essential for any testing decision to be effective.\n5.4.2.4 Political/Cultural Environment\nPolitical and cultural factors have the most under-appreciated effects on testing\nprograms. While they often have significant influence on decisions later in the\ndevelopment process, they are rarely consciously considered in the early decision-\nmaking process. Both political and cultural factors are important, yet they often go\nunnoticed by all but those in the highest positions, such as program managers and\nother key decision makers. Therefore, the influence of political and cultural factors\nmay be greater than the other decision factors on those decision makers that are\nkeenly aware of the political and cultural climate.\nFor NASA, political factors\ninvolve pressures from competing programs as well as from organizations outside of\nthe agency, such as Congress. The increasing international involvement in NASA\nprograms also provides a new dimension to the cultural differences and political\npressures that project managers must consider.\nIt should be noted that decision makers might weigh these non-technical factors\nheavier than technical factors because they are often the pressures that are more\nreadily felt at the time of the decision. Much of the risk component deals with \"what\nifs\" in the future but resource availability is a present concern for the decision\nmakers. The near term nature of the non-technical factors, along with the vagueness\nof the long-term technical effects, creates an imbalance for the decision maker.\n5.4.3\nRetest Considerations\nAnother finding from the expert interviews was the general perception that retest\ndecisions did not receive the same rigor as original test requirement decisions. When a\n\nproblem was uncovered during a test and subsequently repaired, the system often was\nnot retested as thoroughly as the initial test. The decision to not retest is not necessarily\nimproper, if a thorough review and evaluation is performed. Indications from the expert\ninterviews point to the fact that this review does not always take place. The purpose of\nthe retest is to verify the reconnected interfaces, to confirm the corrective action was\nsufficient to remove the error and to ensure that no other errors were introduced into\nthe system during the replacement process. The same decision factors used in assessing\nthe initial test requirements must be considered for retest.\n5.5\nThe Role of Planning\nHuman-rated spacecraft have always been extremely complex systems. As more electronic\ncomponents and software are introduced into the functional operations of the system, the\ncomplexity will continue to increase, requiring that more rather than less testing be\nperformed on the spacecraft. To manage this complexity, early planning in both systems\nengineering and testing is necessary. Statements such as \"test early and often\" and \"poor\ndecisions made early will kill you later\" [53] were common responses during the expert\ninterviews.\nThe need for more planning of test activities is also recognized by organizations outside\nNASA, such as the commercial aircraft industry. For aircraft, the Federal Aviation\nAdministration (FAA) establishes rigid requirements for testing that must be addressed\nearly in the life-cycle of the program. These requirements are established by regulation and\ncannot be reduced. However, for unique spacecraft with no regulatory requirements to\nguide test development, it very difficult to establish a firm program for testing. Often the\nsystem requirements are so unique there is no previous test history to help determine the\nbest approach, or in many cases, the time between programs hinders the knowledge\ntransfer process. Furthermore, new designs are susceptible to changes, which translates\ninto uncertainty because the engineer is unsure of the final system configuration.\nAmbiguity in system requirements can make the test requirements unstable and may result\nin more required testing.\nThe success of a testing program is only as good as the test requirements that are\ndeveloped. However, early emphasis on high quality test requirements is often missing\nfrom program planning decisions.\nThe expert interviews revealed that inadequate\nrequirements could lead to poor test procedures and a lack of proper test equipment. [54]\nThe experts also advised that getting an early start on philosophical and policy decisions is\nnecessary to establish the right priorities regarding the level of testing and criticality level\nof the requirements. [55]\nAn illustration of the importance of test requirements can be drawn from the Huygens\nProbe that was launched with the Cassini Spacecraft in 1997. The probe experienced a\ncommunications anomaly during a routine test while en-route to its destination (the Saturn\nmoon of Titan). The unexpected behavior occurred when a simulated Doppler shift was\napplied to a signal being sent to the Huygens Probe Support Avionic receiver. The\nDoppler shift caused the data signal to fall outside of the receiver's narrow-band bit-loop\n\ndetector. The enquiry board could find no evidence of requirements or specifications\nregarding Doppler Shift on subcarrier or data rate in the receiver radio frequency telemetry.\nHad this been a requirement and tested prior to launch, the problem could have been\nidentified on the ground and corrected by a software change. The software was not\nchangeable after launch. Although the Huygens Program made use of independent tests\nand verifications, the following conclusion was drawn: \"The problem on Huygens has\nshown the value of an end-to-end test simulating the various mission conditions as close as\npossible during ground testing.\" [56]\nIn the case of Huygens, early involvement of test engineers may have been able to\ninfluence the decision not to perform the end-to-end testing. One role of the test engineer\nis to find system problems that the designers did not anticipate. The added evaluation by\nthe test engineers and a subsequent end-to-end test would have helped to ensure the\nspacecraft's robustness. Finally, through early involvement, the test organization would be\nmore familiar with decisions made by the designers and therefore would have the\nnecessary understanding to develop stringent test requirements that would validate the\nactual mission conditions. These same findings can be applied to all programs.\nThe early involveme nt of the test organization is also essential in establishing a set of firm\ntest requirements that will be less vulnerable to changes later in the program.\nBy\nestablishing critical test requirements that must be performed, program managers and test\nmanagers are in a better position to respond to program changes. Less critical\nrequirements can also be established early in the program, but can be accomplished by\nother methods of verification, or not performed in favor of cost or schedule considerations.\nThis is appropriate as long as the risks associated with not performing the test are\nacceptable.\nEarly decisions regarding the testing approach to human-rated spacecraft are made at the\nprogram management and system engineering levels. The program manager is responsible\nfor overall resource allocation and cross-system integration decisions but must consider\nrecommendations from the systems engineers. The systems engineers in turn base their\nrecommendations on the inputs of the various hardware and software owners. For human-\nrated spacecraft, this simplified decision hierarchy involves many organizations and groups\nassigned to various aspects of the program. Decision makers at all levels must consider a\nwide range of variables when addressing testing programs. These include when to perform\ntests, what tests to perform, where to test, fidelity of tests, the amount of software IV&V to\nperform and how much retest should be allocated as contingency.\nUpfront planning also allows for the opportunity to begin testing early. An advantage of\nearly testing is to verify component behavior under system-level conditions. Gaining this\nknowledge of actual system operations and behaviors is useful in driving down the level of\nuncertainty in the system. This testing allows transients to be identified at an early stage.\nThe experts regarded this early emphasis as necessary to begin the process of addressing\nthe \"little glitches\", or unexpected emergent behavior, that must be understood as part of\nthe overall system is developed. Ignoring these small details can lead to maintenance\nissues during operation, or even worse, on-orbit system failures.\n\nThe process of identifying unexpected emergent properties of human-rated spacecraft must\nbegin at an early stage in the program to ensure that as many as possible are recognized\nand addressed. Analytical methods can be applied to early systems to find and correct\npossible interactions before the design is complete. Analysis alone will not identify all\nunexpected emergent behaviors and testing is necessary in order to ensure that those\ninteractions that do present themselves will not pose an unacceptable situation for the\nspacecraft or crew.\nAn example of this kind of unexpected behavior occurred on the Wide Field Infrared\nExplorer (WIRE) experiment launch in March of 1999. After its launch, a system anomaly\noccurred in which the telescope aperture cover was opened prematurely, resulting in the\nrelease of the spacecraft's cryogenic hydrogen. The subsequent report on the incident\ntraces the behavior to a field-programmable gate array (FPGA) that was used in a circuit\nfor which it was not well suited. The mishap investigation determined that a transient\nsignal occurred after start up of the FPGA. The WIRE report indicated that the testing\nmethod used for the spacecraft was performed at the hardware-box level only, a method\nthat would not have identified the transient. The report also stressed the point that the\nspacecraft should be \"tested as it is going to be used\" in order to identify these types of\nbehaviors. [57]\nAllowing enough time in the testing schedule to address these unexpected emergent\nbehaviors, and other contingencies, is also important. Because testing occurs at the end of\nthe development phase, the remaining ava ilable schedule is tightly controlled. The\nobjectives of later tests may become vulnerable if too much time is spent correcting errors\nuncovered by the early test procedures. While schedules are typically optimistic, testing\nwill find errors and the planning should account for these contingencies.\nFinally, early planning also allows program managers to develop enough flexibility in the\ntest program to make adjustments during the later phases. Often, windows of opportunity\ndevelop from changes in other parts of the program (i.e. delays in launch schedule) that\ncreate time for more testing. If a prioritization of additional test activities is not readily\navailable, these opportunities can be lost. The International Space Station (ISS) Program\nprovides a prime example of taking advantage of a window of opportunity. The original\nISS baseline contained almost no integrated testing of the major elements. When a\nschedule opportunity became available, ISS program management was able to use the time\nto perform a series of Multi-Element Integration Tests (MEIT). [58] These tests have\nproven to be successful in finding and correcting problems prior to launch.\n5.6\nTracking Testing Costs\nActual cost figures for spacecraft testing programs are very difficult to determine because\nNASA does not typically track them as a discrete line item in spacecraft programs. Pure\ntest costs are often obscured by engineering and operational funding, making them\nsusceptible to misinterpretation. An effort was made to determine the availability of actual\ncost data for use in a case study for this thesis, but what we found was either cited as\n\nproprietary or deemed to be in an unusable format for proper analysis. Therefore, it is\nrecommended that actual financial data be obtained for use in evaluating testing cost\nperformance and for use in program planning.\nTest costs are not consistently defined from one program to another, making comparisons\ndifficult between programs. Contractors, however, have attempted to establish heuristics\nfor estimating testing costs for use in developing cost proposals. These estimating \"rules\nof thumb\" are subject to negotiation during the proposal development phase as well as\nduring final contract negotiations with the customer. During the actual performance of\ntesting activities, contractors also provide better cost tracking, but do not typically make\nthe details of these costs available to others for proprietary reasons. Contractors are often\nrequired to submit detailed financial information to the government, but again this\ninformation is not easily broken down to actual test costs.\nBetter estimating and tracking of test activities is needed to establish a consistent\nestimating tool that can be used in early program planning. Accurate test cost data can also\nbe used to establish the savings that testing brings to a program in the form of cost\navoidance from errors that may have been overlooked had the testing been eliminated.\nLife-cycle cost consideration is another deficient area in making test decisions. For\nhuman-rated spacecraft it is often attractive to forego a test and accept the risk that an on-\norbit repair will be necessary. However, when the cost of on-orbit repairs are considered\nin the decision, it often becomes apparent that performing a test is money well spent in the\nlong run. The trade-off between performing testing and accepting the risk of an expensive\non-orbit repair is often not assessed because of the urgent nature of the decision at hand\nand the lack of useful and accurate cost data. The manager will be tempted to \"save\" the\ncost of the test and apply it toward a possible repair effort. With improved cost data\nregarding testing and on-orbit activities, decisions to perform more testing may be easier to\njustify.\n5.7\nTesting Is An Art\nThe finding that testing is more of an art than a science further reinforces the theme of\nsubjectivity in testing and also recognizes the innate difficulty of test engineering.\nExperience and mentoring are more important than formal training in developing test\nengineering expertise. One reason for the lower prominence of formal training may be the\nlack of testing emphasis in systems engineering literature, including government and\ncorporate policies and procedures. Although NASA is attempting to address testing as part\nof its program and project management policies, our expert interviews revealed that\ndocumented guidelines may be one or two revisions away from giving testing adequate\nattention. [59]\nThe lack of testing literature is not limited to NASA. College curriculums and industry\nalso give testing superficial emphasis. Testing is mentioned as a necessary component of\nsystem development but does not include a discussion of actual test implementation.\nFormal training is also not provided either in college or in most industries.\n\nBecause testing practices are not formally documented, the most valuable knowledge is\nretained within the individual experts as tacit knowledge. This finding is reflected by the\nexpert interview responses that recognize the human relationship component that exists in\nthe test engineering community. As organizations change from experienced-based\nknowledge to process-based knowledge, there is a danger of losing the testing expertise\nthat resides within the organization. Once this knowledge is lost, the chances of repeating\npast mistakes increases.\nIn order to maintain the knowledge base and core capabilities, test engineering should be\ntreated as a valid profession with the same prestige level as other engineering disciplines.\nProviding test engineers with a viable career path will prevent them from moving to other,\nmore rewarding, assignments and will also serve to attract talented new engineers to the\nprofession. Currently, test engineering is not given the recognition appropriate to the\namount of creativity and difficulty involved as compared to design engineering. The\nexpert interviews pointed out that test engineers need to know the system design and then\nmust be more creative in trying to identify system faults. [60] Finally, any organizational\nstructure should attempt to capture and retain the core knowledge of its testing group.\nMentoring and On-the-Job-Training are two ways of retaining testing knowledge and\npassing it along to new programs.\nBarriers to knowledge transfer exist in several forms. First, most knowledge management\nsystems are poorly funded and fail to document root causes of problems in a form usable\nfor application toward new problems. Second, a culture of addressing only those problems\nrelated to the current program exists, without regard to preventing problems in later\nprograms. Contractual issues also pose a barrier to knowledge transfer in the form of test\ndata created by contractors not being a required deliverable to the government. Finally,\nknowledge transfer is relationship dependent. Programs that have good relationships\nbetween organizations tend to transfer knowledge easier than those that have adversarial\nrelationships or are geographically dispersed.\n5.8\nThe Importance of System Engineering\nGood sub-system engineering is not a substitute for proper overall system engineering.\nDesigning and testing at the sub-system level is a necessary process that attempts to\nconfine functionality within the sub-system while providing higher-level controls over the\ninterfaces between the various sub-systems. In doing so, the complexity of the higher-\nlevel system can be managed through the lower-level sub-systems. Focusing on the sub\nsystem level does not imply, however, that early attention should not be applied to the\noverall system level performance and the possible interactions between the sub-systems.\nOur expert interviews suggested that another role of testing is to capture those sub-system\ninteractions without having to give them thoughtful attention during the early development\nstages. While testing does drive out errors, it is not intended to serve as a substitute for the\ndesign process (from a systems integration perspective). Nor should a conservative design\nprocess tha t attempts to provide system robustness and fault-tolerance serve as a substitute\nfor proper testing. The bottom line is that system engineering must give a voice to both\ndesign and testing in the proper proportions.\n\nThe need for a strong system engineering perspective is becoming increasingly more\nimportant as systems become more complex and the projects more distributed. Many of\nNASA's human-rated spacecraft projects are broken down into individual work packages\nand dispersed between centers and contractors. In general, good system engineering is\nperformed for each of these packages. When the project is broken up in this manner, the\nsystem engineering must be even stronger. More coordination and communication is\nrequired and only through the system engineering function can this be accomplished. Very\noften each of the work package owners follows their own similar, yet different, processes.\nThe system engineers must ensure some level of consistency and that a minimum standard\nis met. Integration testing, by its very nature, crosses these organizational, contractual and\ngeographic boundaries. Proper system engineering is essential to the success of a test\nprogram.\nIn very large programs, individual work package groups or organizations may be tempted\nto operate as autonomous entities. They can become focused on delivering their particular\nproduct and lose focus on the larger picture. It is the responsibility of system engineering\nto ensure that working relationships are established and a free flow of information is\nmaintained. Several expert interviewees noted that these individual organizations\nsometimes exhibit \"engineering arrogance\". They do not recognize the need for system\nengineering and they do not think outside their particular area of expertise.\nAs one\ninterviewee described, these groups operate as if they were on separate islands. System\nengineering must build the bridges to connect each island. [61]\n5.9\nProgram/Agency Culture\nProgram and agency culture strongly affects testing. A traditional engineering culture\nplaces emphasis on design because the design must come before testing. In addition, the\nrole of the designer is to build a robust system while the role of the tester is to find errors\nand shortcomings with the design. Both groups must be disciplined enough to recognize\nthe role of the other and avoid adversarial behavior. As mentioned earlier, test engineering\nhas a stigma associated with it due to its lower priority within the organization. This\ninequality in organizational status exacerbates the adversarial relationship and can hamper\ncommunications between the design and test groups, resulting in severe negative effects on\nprogram success.\nAnother cultural aspect that affects testing programs is the mindset that each program\nstands on its own. Very little resources are spent on trying to make testing easier on the\nnext program by understanding today's failures and sharing lessons learned. The repetitive\nnature of the tasks in the commercial aircraft industry makes the transfer of lessons learned\neasier. Even so, for most engineering cultures, the process of mentoring is much more\neffective in transferring knowledge than through documentation methods.\n\nChapter 6: Lessons for the Future\n\"Taking action in advance to prevent or deal with disasters is usually worthwhile, since\nthe costs of doing so are inconsequential when measured against the losses that may ensue\nif no action is taken\"\n- Nancy Leveson (Safeware, 1995) [62]\nFrom the themes and findings discussed previously in this thesis, recommendations for\nassessing future test requirement decisions are outlined in this chapter. First, the current\nrisk management process is described, along with its applicability to test requirement\ndecisions. Suggestions for improvement of the risk management process are also offered.\nSecond, additional keys to a successful test program are discussed. Finally, this chapter\nexplores the nuances and challenges faced in the individual decision-making process.\n6.1\nRisk Management Process\n6.1.1\nCurrent Risk Management Techniques\nAs discussed in the preceding chapters, testing serves the purpose of risk mitigation by\ndiscovering errors and building confidence in the overall system operation. All NASA\nprograms, along with other industries, currently use risk management programs that\nhave been tailored to their own individual needs, constraints and philosophies. Each\nprogram utilizes some form of likelihood and consequence as a means to assess risk.\nNASA defines likelihood as: \"the probability that an identified risk event will occur.\"\n[63] Consequence is defined as \"an assessment of the worst credible potential result(s)\nof a risk\". [64] In order to assess the overall risk, likelihood and consequence must be\nevaluated together. One tool used to aid decision makers in this evaluation is a risk\nmatrix. The generic risk matrix that NASA has adopted is shown in Figure 7.\nLIKELIHOOD ESTIMATE\nCONSEQUENCE\nCLASS\nLikely to\nOccur\nProbably\nwill Occur\nMay\nOccur\nUnlikely to\nOccur\nImprobable\nCatastrophic\nCritical\nModerate\nNegligible\nHigh Risk -\nMedium Risk -\nLow Risk -\nFigure 7 - NASA Generic Risk Matrix [65]\n\nThe matrix in Figure 7 illustrates only one option for comparing risk. While this matrix\nhas four levels of consequence and 5 levels of likelihood, each program and industry\nhas tailored the matrix to suit their own needs. Typically the scaling varies between 3\nand 6 levels for each component of risk. Likelihood is typically measured on a scale\nranging from Likely-to-Occur to Improbable or Impossible. Consequence usually\nranges from Catastrophic to Negligible. No matter which scaling method is used, the\nhighest risks are those with the highest likelihood and the worst consequences.\nRisks are not limited to technical concerns but can include risks to schedule and budget\nas well. Regardless of the source, once a risk is identified, likelihood and consequence\nmust be determined so the risk can be mapped on the risk matrix. This evaluation can\nbe either quantitative or qualitative. Some of the methods used to analyze risk include:\nProbabilistic Risk Assessment (PRA), statistical analysis of historical data, Fault Tree\nAnalysis, and Failure Mode and Effects Analysis. [66]\nTraditionally, hardware reliability also is used to determine the likelihood of failure.\nHowever, using hardware reliability as the only means of assessing likelihood\nrepresents two erroneous assumptions. The first incorrect assumption is that hardware\nfailures are the only causes of accidents. This is not true and in fact is often not the case\nin many large-scale accidents. Accidents and unintended events can result from human\nerror, bad requirements, processes not being followed or design deficiency. Managers\nand decision makers must consider all of the possible causes of accidents or overall\nsystem failure when assessing the total risk for a project.\nThe second incorrect assumption is that reliability can be equated to successful\noperation. This assumption is particularly not true for software. Each component or\nmodule may operate as intended and hence be very reliable. A combination of\ncomponents may, however, produce unintended behavior that results in a system\nfailure. Unclear requirements or design flaws may also yield highly reliable\ncomponents that do not meet the intent of the system's operation. Program managers\nmust be conscious of these misconceptions when evaluating the overall program risk.\nOnce risks are identified and plotted on the risk matrix, there must be a way to compare\nand prioritize all of the risks. Again, each program and industry has chosen different\nmethods of accomplishing this risk ranking process. NASA's Risk Management\nProcedures and Guidelines (NPG8000.4) suggests using a Risk Assessment Code\n(RAC). The RAC are numerical values assigned to each field in the risk matrix, as\nillustrated in Figure 8. [67] The RAC values appear to be assigned in an evenly\ndistributed, impartial manner. Risks with a RAC of 1 are the highest and should receive\ntop priority in terms of resources and attention.\n\nLIKELIHOOD ESTIMATE\nCONSEQUENCE\nCLASS\nLikely to\nOccur\nProbably\nwill Occur\nMay\nOccur\nUnlikely to\nOccur\nImprobable\nCatastrophic\nCritical\nModerate\nNegligible\nFigure 8 - Risk Matrix Showing Risk Assessment Code (RAC) (Adapted from [68])\nIndividual NASA programs use the risk matrix as a management tool to manage and\ntrack risk mitigation actio ns. Each risk is assigned a managing organization that has the\nresponsibility of establishing a plan to reduce the likelihood of the risk occurring or of\nlessening the severity of the consequence should the event actually take place. This\nplan is entered into a database and the action tracked until the risk is reduced to an\nacceptable level. [69] The program manager is typically responsible for determining\nthe acceptable risk level. One downside of this management tool is that risks are\nevaluated individually. Any unexpected emergent behavior that may result from a\ncombination of risks will not be discovered or considered through the use of the risk\nmatrix.\nThe NASA Risk Management Procedures and Guidelines (NPG 8000.4) provides the\nbasic principles of a risk management plan. Each program manager is then required to\ndevelop a detailed risk management plan specific to their individual program/project,\nbased on the general guidelines. Each program manager is responsible for determining\nhow their risks should be ranked and prioritized and they must also determine what\nlevel constitutes acceptable risk. While the ability to tailor the risk management\nprocess does allow managers to better meet the needs of their project, it also adds to the\ninconsistencies of test approaches across the agency and industry.\nOne example of how a large-scale NASA program has adapted the NASA risk\nmanagement guidelines is depicted in Figure 9. In this application, the risk matrix is\ncomprised of 5 levels of likelihood and 5 levels of consequence. These levels are\nlabeled numerically 1-5 with 5 being the highest or most severe.\n\nL\nI\nK\nE\nL\nI\nH\nO\nO\nD\nLEGEND\nHigh\nprocess(es) or change\nbaseline plan(s)\nmanage; consider\nalternative process\nLEGEND\nHigh -Implement new\nprocess(es) or change\nbaseline plan(s)\nMedium - Aggressively\nmanage; consider\nalternative process\nLow - Monitor\nCONSEQUENCES\nFigure 9 - NASA Program Risk Matrix [70]\nThe risk management plan for this program suggests that for each risk, the likelihood\nand consequence should be multiplied together to determine a risk score. [71] These\nscores are then used to rank and prioritize all of the risks. For example, a risk with a\nlikelihood of 4 and a consequence of 5 would receive a risk score of 20. This score is\nnot an absolute number but rather a relative ranking used to prioritize all risks. The\nmethodology of multiplying likelihood times consequence, however, does little more\nthan assign a value to each field in the matrix, similar to the concept of the RAC used\nin NASA's generic risk matrix. The assignment of risk scores to matrix fields is\nillustrated in Figure 10.\nL\nI\nK\nE\nL\nI\nH\nO\nO\nD\nLEGEND\nHigh\n-\nprocess(es ) or change\nbaseline plan(s)\nmanage; consider\nalternative process\nLEGEND\nHigh -Implement new\nprocess(es) or change\nbaseline plan(s)\nMedium - Aggressively\nmanage; consider\nalternative process\nLow - Monitor\nCONSEQUENCES\nFigure 10 - Risk Matrix with Scoring [72]\nThe approach of multiplying likelihood and consequence can be misleading. First,\nlikelihood and consequence are two different entities and are not presented in the same\nterms. Likelihood traditionally is in the form of a probability, while consequence is not\n-yielding a product with meaningless dimensions. Second, it may misrepresent the\nrelative distance between two risks. For example, a risk with a consequence of 5 and a\nlikelihood of 4 has a score of 20, while a risk with the same consequence of 5 but a\n\nlikelihood of 2 has a score of 10. It is unreasonable to assume that the risk with a score\nof 10 is actually twice as good as the risk with a score of 20.\nThe Department of Defense (DoD) uses a hazard criticality index matrix that may serve\nas a better approach to prioritizing risks. A simplified example of this matrix is shown\nin Figure 11.\nFrequent\nProbable\nOccasional\nRemote\nImprobable Impossible\nCatastrophic\nCritical\nMarginal\nNegligible\nFigure 11 - Adapted DoD Hazard Criticality Index Matrix [73]\nFor this application, the number in each field represents the criticality of various\nidentified hazards as part of the DoD's safety program. The number values are not\ndistributed evenly, showing that some thought and methodology went into assigning\nratings to each field. Any hazard below the dark line is considered acceptable. The goal\nof the mitigation activity is to drive down the criticality to a rating of 9 or higher\n(below the line). [74] Reducing criticality can be accomp lished through design\nchanges, additional redundancy, safety features or operational workarounds. This same\nmethodology can be used for risk management. In addition, if the matrix values can be\nassigned at the agency level, then consistency in determining acceptable risk can be\nachieved throughout the program. The subjectivity of assigning likelihood and\nconsequence values would still remain, however.\nThe preceding discussion on risk management techniques is only a cursory review.\nFurther analysis of the various risk management processes and the relative benefits and\ndrawbacks is work that should be covered by a subsequent thesis. A general\nunderstanding of risk management is needed for the purposes of this thesis. The\napplication of risk management to testing is discussed further in the following section.\n6.1.2\nApplication to Testing\nThe intention of risk management activities is to identify and mitigate risks in every\nstage of a program. Poorly defined risks or those risks that will not be realized until far\nout into the future are usually not plotted on a risk matrix due to the lack of solid\ninformation on which to base likelihood and consequence magnitude decisions. In the\nearly stages of programs, risk assessment focuses on the design activities. At this stage,\ntest requirements are typically unclear and will not be implemented until the end of the\nprogram. As a result, risk assessments do not deal with the early test requirement\n\ndecisions. It is only when the test activities are underway that the risk matrix is\ntypically applied to testing. The risk matrix approach can, and should, be applied to\nearly test requirement decisions.\nBecause testing builds confidence in a system's operation and serves to mitigate risk,\nthe same risk matrix principles described above apply equally to testing as to the other\nparts of a project, such as design and safety. There is a weakness, however, with the\ncurrent implementation of the risk matrix: likelihood is no longer an easily measured\nquantity (such as hardware reliability) in complex, software-intensive systems.\nBecause today's systems are becoming increasingly more complex assessing the\nlikelihood of an event occurring is also becoming more difficult.\nWhile consequence evaluations are still relatively straightforward, most assessments of\nlikelihood currently leave out too many factors and only consider traditional hardware\nreliability data. Testing serves to build confidence in the system engineer's assessment\nof the likelihood that an event actually taking place. As described in Chapter 5, and\nshown again in Table 4, these sources of uncertainty factors also need to be a central\ncomponent in any likelihood evaluation.\nSources of Uncertainty\n- New design\n- New technology\n- New interfaces\n- New application for reuse\n- Previous testing\n- Reliability of information\n- Hardware/software maturity (design and build)\n- Team experience\n- Complexity of system\n(including number of interfaces/interactions)\n- Required fidelity of results\n- Possible unexpected emergent behavior\nTable 4 - Sources of Uncertainty\nWhile there does need to be a better method of estimating likelihood, it should be noted\nthat testing alone does not change the likelihood of an event occurring. Testing does,\nhowever, increase the confidence in the system engineer's assessment of likelihood.\nTesting also allows for problems to be discovered on the ground so that corrective\naction can be taken. Testing also does not change the consequence, unless it provides\nthe system engineers with new knowledge about the system's operation.\n\nAnother concern in the traditional use of the risk matrix is that risks are evaluated on\nan individual basis. By addressing each risk separately, any unexpected emergent\nbehavior that may result from a combination of risks will not be captured by the matrix\napproach. Because another goal of testing is to drive out these unexpected emergent\nbehaviors, the risk matrix approach should be expanded to evaluate a combination of\nrisks. Combining risks, however, may be misleading because the number of\ncomponents involved in each test will vary from requirement to requirement. Testing\nwill often address multiple risks at once, making side-by-side comparisons more\ncomplicated than comparing individual risks. For example, a component test\nrequirement typically involves only one or two components while an integrated test\nrequirement can include many different components. The differences in testing\nconfiguration and the weighting of the factors must be assessed in conjunction with any\nother rating that is derived from the analysis of the combined risks.\nPerhaps the greatest strength of the risk matrix, as it is applied to testing, is in the\nmethodical thought process that the decision maker must go through in order to use the\ntool. The first benefit is in reviewing and evaluating all the factors that are included in\nlikelihood and consequence, especially the confidence factors. Most system engineers\nand decision makers are experienced in plotting likelihood and consequence on a risk\nmatrix. Traditionally, each of the confidence factors has not been assessed in an\nindependent or formal manner. This is unfortunate because the main goal of testing is\nto drive down uncertainty and build up confidence in the system. As discussed\npreviously, the confidence factors include many aspects beyond what is traditionally\nconsidered as a source of uncertainty. Typically a new design is identified as a source\nof uncertainty but too often project managers choose to reuse components to reduce\nuncertainty. As described earlier, reuse can actually be a large source of uncertainty\nbecause managers are too over-confident with the reuse. Thinking through the total\nlevel of uncertainty will aid decision makers in identifying weaknesses in time to test\nand correct before on-orbit operations. The true pay-off comes in consciously thinking\nthrough each decision factor individually and in context with the other factors.\nFinally, one additional concern with the current risk management practices, as applied\nto testing, should be addressed. This concern deals with the competition between\ntechnical and cost risks. NASA, like other industries, typically tracks technical, cost\nand schedule risks. Because testing takes time and costs money, decision makers are\nforced to trade-off the technical risk of not performing a test with the cost and schedule\nrisks of adding additional testing. When considering the cost risk, some programs only\naddress the cost of abating the risk and not the cost of the risk if it would occur. [75]\nThis is counter to the purpose of testing. As described previously in this thesis, testing\nis both vulnerable to cutbacks and testing costs are not tracked in a manner that allows\ntrue life-cycle comparisons to be made. These conditions only serve to give more\nweight to the cost and schedule risks over technical risks. Decision makers must be\ncognizant of the se influences, especially when using the risk matrix to assess test\nrequirements.\n\n6.2\nAdditional Keys to Success\nA key to any successful test program is a holistic view of both the technical and non\ntechnical factors involved in all projects. One set of factors should not be weighted more\nthan the other; each plays an important role in the overall process. In addition to the risk\nmanagement and decision-making process factors described earlier, there are other\nimportant aspects that can increase the effe ctiveness of a test program and in turn increase\nthe chances for the project's success. These recommendations for ensuring success are\ndiscussed in this section.\n6.2.1\nStatus of Testing\nAs discussed in the previous chapters, test engineers, and testing in general do not\nreceive the attention or status that they deserve. It is important for program managers to\ngive testing as much consideration as the other aspects of a project. Testing also needs\nto receive attention from the very beginning of the development process. While testing\nmay not be the top priority in the early stages, it cannot be ignored either. Including\ntest engineering representation in the design definition phase is one way that a program\nmanager can provide this early involvement.\nTesting is a vital component in all projects and good test engineers are valuable assets\nnot only to the project itself but also to NASA as a whole. NASA, and all contractors\ninvolved in human-rated spacecraft, should work to raise the prestige of testing within\nthe agency. Test engineering needs to be considered a valid profession and it should\nhave its own viable career path. A test organization should be made up of experienced\nsystem engineers, and it should not be used as a first assignment for new engineers.\nBecause testing is more of an art than a science, management should proactively seek\nout those engineers that demonstrate the ability to be good artisans in the testing arena.\nTesting skills should be viewed as desirable and rewarded as such. When a project is\nsuccessful, it is typically the design engineers who receive all of the recognition and\nrewards. Too often, test engineers do not receive the credit they deserve for their\ncontribution to the success of a project. A good balance between all disciplines is\nneeded to ensure the proper balance of the project itself.\n6.2.2\nOrganizational Considerations\nThe organizational structure that a project manager selects has a significant impact on\nthe overall success of the project. Consideration must be given at the earliest stages to\nthe appropriate structure that best serves every phase of the project. It is easy for\nmanagers to focus solely on the tasks at hand when first organizing the project,\nbelieving that the organization can change along with phase of the project. This belief\nis valid but only to a limited extent. The organizational structure can be adjusted\nslightly as time progresses, but it is important that the organization allows for the\nproper flow of communication and facilitates the involvement of all the essential\nplayers. Both system engineers and test engineers should be included as essential\nparticipants from the earliest stages.\n\nThere are a number of advantages in establishing a separate test organization, as was\ndiscussed in previous chapters. The primary benefits are in the ability to maintain a\nfocus on the testing activities, to ensure a consistent test philosophy, and to develop\ntest engineering skills. While having a separate organization is beneficial, it also\nrequires increased coordination. Strong system engineering is essential, especially if\nthe team is widely dispersed. The coordination mechanisms must be addressed at the\ntime the project is structured and put into place from the beginning.\nAnother important organizational consideration is in the division of a system into sub\nsystems. Project managers have become adept at partitioning systems in such a way to\nlimit the number of interfaces between sub-systems. [76] Project managers must also\nconsider what each sub-system should include, such as software. Software should not\nbe treated as a standalone sub-system. To ensure that software is integrated into each\nsub-system, the organizational structure should also include software representation in\neach sub-system group. Accountability, along with responsibility, for software must be\ngiven to the system engineers. Software is an integral part of the system and should be\ntreated equally with the other system components.\n6.2.3\nKnowledge Transfer\nAs discussed previously, test engineering skills are not formally taught and must be\nlearned on the job. To ensure successful test programs, both project managers and\nfunctional supervisors should establish mentoring programs for test engineers. Rather\nthan the typical ad hoc nature of testing training that is evident today, managers must\nbe proactive in developing the testing talent that will be required in the future.\nCapturing and retaining testing skills is especially important after the completion of\nlarge projects. A great deal of knowledge is gained through the course of completing\nlarge-scale or long-duration projects. This knowledge and expertise is often lost after\nthe team is disbanded, and the next project must start from scratch in developing the\nneeded testing skills.\nA more strategic approach should be taken in capturing testing knowledge and in\nmaintaining skills. One solution would be to create a small testing corps that remains\nintact after one project completes and then moves on to another project. While the\nsystems would vary from one project to another, the same testing skills would apply. In\naddition, this testing corps would also be mentoring other engineers on the project,\nproliferating the needed expertise throughout the agency.\nAdditionally, NASA should also consider the need for agency-wide knowledge-sharing\non testing. Currently the program and project guidelines (NPG 7120.5) do not address\nactual test implementation. An agency-wide team should be formed to seek out best\npractices in the testing arena and update NPG 7120.5 to include more guidelines.\nFormal training programs in test engineering could also be investigated and\nestablished. This training would not replace the need for mentoring.\n\n6.2.4\nAlignment of Goals\nFor any project to be successful, all participants must be aligned with the overall goals\nof the project. The primarily tool that program managers use to determine the\norganization's ability to meet its goals is performance metrics. Each organization is\ntypically only measured against the group's individual output. For example, the\ndesign organization is evaluated on their ability to deliver a good design while the\ntesting organization is measured against the ability to meet testing milestones.\nBecause testing occurs at the end of the project, many of the initial groups involved\nwith the design and manufacturing are disbanded. Problems found during testing that\nneed to be corrected often result in a delay to the schedule. Because the test\norganization is evaluated on the ability to meet milestones, these delays can reflect\nnegatively on their performance. If the problem is a result of a design deficiency, it\nshould be attributed to the design organization. Too often the test organization is often\nleft to assume the full responsibility of the system's operation. The design organization\nshould share the responsibility for the systems final performance and should be rated\non the testing activities as well. In fact, the test organization should be rewarded, rather\nthan sanctioned, for finding the flaw prior to on-orbit operations, rather than sanctioned\nfor the delay in schedule.\nA better approach to performance measurement would be for each organization to be\nmeasured against the overall success of the project. Project managers need to establish\na method of delaying the organization's final rating until the completion of the project,\nso that all groups can be held accountable for the systems ability to meet the project's\nultimate goals.\n6.3\nTesting Decision-Making Considerations\nAs discussed in the previous chapter, decision makers are faced with both technical and\nnon-technical influences when making decisions. This section will describe the differing\neffects these influences can have on individuals with various decision-making preferences\nand style s.\nEvery person has their own decision-making style based upon personal preferences,\nexperiences and expertise toward viewing decision alternatives. In order to ensure that\ntesting decisions are made in a consistent manner, these decision-making influences must\nbe understood by the decision maker. Three broad perspectives have been identified that\naffect individual decision makers: risk-tolerance, long-term view and systems approach.\nBy understanding the influences on the decision-making process, managers will be better\nequipped to face the challenges of a development program.\n6.3.1\nRisk-Tolerance\nIn an ideal world, managers compare decision alternatives from a neutral perspective\nand make choices based on the expected value of the outcomes under cons ideration.\n\nWhen two or more alternatives have the same expected value, a manager will\nconsistently make the same choice based on established selection criteria. However, in\nthe real world, decisions are not always framed in terms of expected value and the\nselection process is not always consistent between individuals. One way to describe\ndifferences between decision makers is by the amount of risk they are willing to accept,\nreferred to as their risk tolerance level. A manager with a high risk-tolerance level will\nbe willing to accept more risk than a manager with a low risk-tolerance level (risk\naverse).\nIt is important for managers to understand their personal risk-tolerance levels when\nfaced with difficult decisions. In the testing environment, a technical manager who is\nrisk-averse will want to perform more tests in order to decrease the chance of a system\nfailure. By making decisions that reduce risk, the test manager will contribute to\nimproved safety of the system. However, if a risk-averse manager is considering a test\ndecision from a cost perspective only, a decision to delete a test may be chosen in order\nto reduce the risk of a cost overrun. In the case of the cost-related decision, the\nmanager is reducing business risk at the expense of technical risk. Therefore, to avoid\nthe paradox described above, the technical and non-technical decision factors must be\nconsidered as a whole.\nOne way to benefit from the differences of individual decision-making preferences is to\nmatch decision-making styles to specific types of management positions. Managers\nresponsible for safety-related issues should have a risk-averse personality, while a\nmanager who has a high tolerance for risk may be more qualified making resource and\npolitical decisions. The best approach is to create a management team the blends risk\naverse personalities with those that can accept higher levels of risk. A balanced team\nwill provide a collaborative environment that will place proper emphasis on all of the\ndecision factors being considered.\n6.3.2\nLong-Term View\nThe timeframe for realizing the effects of a decision is another way that managers\ndiffer in their decision-making preferences. In general, managers will give the\nimmediate impacts of a decision more weight than the long-term effects. One reason\nthat short-term impacts have more influence is that there is less time to mitigate short-\nterm effects and therefore they take on a sense of urgency. Another reason is the false\nperception that there may by more options available to address long-term concerns,\nallowing test managers time to avoid them in the future. By downplaying the long-\nterm effects of decisions, managers are vulnerable to a \"wishful thinking\" mentality\nthat may create more, and bigger, problems in the future.\nTesting decisions are also viewed differently depending on the phase of the program in\nwhich the decision is made. Early in a development program, decisions can be made in\nan aggregate fashion in which trade-offs can be properly analyzed. As time progresses,\nhowever, decisions must be evaluated on an individual basis with fewer alternatives to\n\nconsider. The result is that decisions to add testing may be harder to implement in the\nlater phases of a development program.\n6.3.3\nSystems Perspective\nDecision makers at all levels must consider their decision alternatives from a systems\nperspective that considers the higher-level objectives of the organization, rather than\nthose of their immediate domain.\nOften, managers from different parts of an\norganization are faced with situations in which they must compete for available\nresources. Without a systems approach, one manager's gain will become another's\nloss. Viewing decision alternatives in a holistic manner will often provide a synergistic\nalternative in which all factors can be successfully addressed. However, to be\nsuccessful, managers must be willing to accept a less than optimum alternative for their\nparticular part of the overall program. In an era of decreasing resources, this approach\nis vital to ensuring successful spacecraft test programs.\nIn addition to considering decisions alternatives in terms of higher organization\nobjectives, the scope of the decision must also be viewed from a systems perspective.\nIndividual decisions are often perceived to have a larger impact to the decision maker\nthan those that are considered in the context of an overall program change. For\ninstance, if a spacecraft test program had an estimated cost of $30M. Considered as an\nindividual event, there would be concern that the cost was too high. However, if the\ncost of the testing were compared to the total cost of the entire program, say $12\nbillion, it becomes clear that the testing cost is more acceptable. In this case, the cost\nof the test program accounts for only small percentage of the total program cost and\ncan provide benefits that far exceed the $30M cost of testing. These benefits can come\nin the form of increased confidence in the performance of the spacecraft.\nFinally, taking a systems approach to decision making allows managers make the\nnecessary trade-offs between the technical and non-technical factors. Risk mitigation,\ncost and schedule must be considered when making testing decisions, but the technical\nobjectives of the program must be maintained to ensure overall success.\nIn summary, the three decision-making considerations discussed above are interrelated\nand can be summarized as follows.\nThe systems approach helps decision-makers\nunderstand the importance of the long-term view of decisions. Systems' thinking also\nallows decision-makers to consider technical and non-technical factors relating to\ntesting. The timing of decisions is also important in maintaining a long- term view.\nDecisions made early in a test program allow the decision maker to take a long-term\nview, but as time progresses the number of available alternatives may diminish.\nFinally, decision-makers must be aware of their individual decision-making\npreferences regarding risk tolerance. A balanced team that consists of risk averse and\nrisk tolerant managers will provide the best combination for consistent decision-\nmaking.\n\nChapter 7: Summary\nThe overall objectives of this thesis were to document the test approaches and philosophies\nused within NASA and other organizations, to determine if the critical decision factors can\nbe applied to all human-rated spacecraft programs, to provide lessons learned for future\nprojects and to understand how various programs address unexpected emergent behavior.\nThis final chapter will review the conclusions and recommendations that resulted from the\nresearch conducted towards meeting these objectives. Finally, suggestions for future\nresearch in this area are outlined.\n7.1\nConclusions\nThe primary research for this thesis included interviews with experts in the system and test\nengineering fields. From these expert interviews, major themes were observed and findings\nestablished. This section will briefly summarize the major themes and findings.\n7.1.1\nMajor Themes from Expert Interviews\nSubjectivity of test requirements development: One purpose of testing is to reduce\nthe risk that a system will fail to meet its intended performance goals. Because\ndetermining risk levels is highly subjective, especially for new designs and\narchitectures, testing in turn becomes highly subjective. Typically, the actual test\nrequirement decision process is not documented as a formal process but relies heavily\non the judgment of the decision makers, adding to the overall subjectivity. Due to this\nsubjectivity, testing practices are not consistent across the aerospace industry or in\ncomparison with the commercial aircraft industry.\nParadoxical nature of testing: Intuitively, people know that more testing is better\nthan less testing but all projects are under tight cost and schedule constraints. Managers\nmust constantly balance the trade-off between too much and too little testing. Testing\nalone does not make a project successful, but it does raise confidence in the likelihood\nof success. Testing is often regarded as a drain on project resources, rather than a\nvaluable undertaking.\nVulnerability to changes and cutbacks: Most testing occurs late in the development\nphase. Since budget and schedule pressures are most keenly felt at the end of a\ndevelopment program, testing is extremely vulnerable because it is one of the only\nremaining opportunities left to make up schedule or cut costs.\nInadequate attention to testing: Testing in general does not receive as much attention\nas it should in order to ensure a project's success. First, testing typically does not\nreceive enough emphasis during the initial planning phases. Second, testing is not\ngiven enough attention in literature, training programs or academia. Third, test\norganizations do not hold the same status or standing as do other groups within a\nprogram due partly to the focus on design activities.\n\nOrganizational influence on the testing process: The structure of an organization\ndoes play a role in the overall success a program. Having a separate test organization\nwas recommended as one method of developing skills, facilitating knowledge transfer,\nimproving communication and establishing a consistent test philosophy. It ensures that\nattention is focused on testing activities even while the program management may be\nconcentrating on other issues. In addition, having previous experience with hardware\nand software can be very important in recognizing system trends and unexpected\nemergent behavior. However, an independent testing organization does have\nlimitations and requires increased integration and communication.\n7.1.2\nMajor Findings of Thesis\nFor some projects, software is considered a stand-alone system: Today's systems\nare becoming increasingly more reliant on software to operate successfully. Yet for\nmany projects software is not being treated as an integral part of the overall system.\nInstead, software is viewed as a separate stand-alone system, as evidenced by the\nproject's organizational structure, the process by which the software is tested and\ndelivered, and the limited insight that some sub-system engineers have into the\nsoftware development process. In addition, many of today's managers have a\nbackground in hardware development and try to apply the same principles to software.\nSoftware, however, has many fundamental differences in the way it is developed and\ntested.\nOptimism varies with organizational position: The interview process revealed\ndifferences in attitude toward the effectiveness of testing among those at various levels\nof the organizatio n. The optimism level in the adequacy of the test programs increased\nas one went up the chain-of-command toward the managers. One possible explanation\nfor this trend includes the senior managers' ability to take a larger view of the overall\nproject. These managers are also required to balance limited resources, political factors\nand a larger constituency than many engineers at the lower levels. In addition, the\ninformation that managers receive may be less-than-perfect and they may be accepting\nmore risk than they realize.\nWhile testing practices vary, decision factors do not: Contrary to common belief,\nthere is consistency in the decision factors used by the various decision makers. These\ncommon decision factors can be divided into technical (safety, risk and confidence\nbuilding) and non-technical (resource availability, process, individual decision-making\nbehavior and political/cultural influences). Due to their salient nature, non-technical\nfactors often carry as much, or more, weight to the decision maker as do technical\nfactors. Perhaps the most under-appreciated factors are those that build confidence by\naddressing the various sources of uncertainty. Decision makers should thoroughly\nconsider each of the sources of uncertainty, especially the effects of reuse, an\ninexperienced team and potential unexpected emergent behavior.\nUpfront planning is a key to success, but be prepared for change: Early planning\nin both systems engineering and testing is necessary to manage the complexity of\n\nhuman-rated spacecraft programs. A key to the success of a testing program is in\ndeveloping high-quality test requirements. The early involvement of the test\norganization is also essential in establishing a set of firm test requirements that will be\nless vulnerable to changes later in the program. In addition, upfront planning also\nallows for the opportunity to begin testing early and allows program managers to\ndevelop enough flexibility in the test program to make adjustments later in the project.\nCurrent methods of tracking testing costs are not sufficient: Actual cost figures for\nspacecraft testing programs are very difficult to determine because they are not\ntypically tracked as a discrete line item in spacecraft programs. Other engineering and\noperational funding often obscures pure test costs, which is unfortunate because\naccurate test cost data could be used to establish the savings that testing brings to a\nprogram in the form of cost avoidance. Life-cycle cost estimating is another area that\nshould be enhanced and used in making test decisions. When the cost of on-orbit\nrepairs are considered in the decision, it often becomes apparent that performing a test\nis money well spent in the long run.\nTesting is more of an art than a science: Experience and mentoring are more\nimportant than formal training in developing test engineering expertise. Because\ntesting practices are not formally documented, the most valuable knowledge is retained\nwithin the individual experts as tacit knowledge. In order to maintain the knowledge\nbase and core capabilities, test engineering should be treated as a valid profession with\nthe same prestige level as other engineering disciplines.\nGood sub-system engineering is not a substitute for proper system engineering:\nWhile designing and testing at the sub-system level is necessary to reduce complexity,\nearly attention should be applied to the overall system level performance and the\npossible interactions between the sub-systems. Because of the increased complexity of\ntoday's systems and distributed nature of projects, strong system engineering\nperspective is becoming increasingly more important. In addition, integration testing,\nby its very nature, crosses organizational, contractual and geographic boundaries--\nmaking proper system engineering essential to the success of a test program.\nProgram/Agency culture strongly affects testing: A traditional engineering culture\nplaces emphasis on design because the design must come before testing. In addition,\ndesign organizations tend to have more status within an organization than the testing\nteam. This inequality can lead to an adversarial relationship and can hamper\ncommunications between the design and test groups, resulting in severe negative\neffects on program success. Another cultural affect observed within testing programs\nis the mindset that each program stands on its own. Few resources are spent on trying\nto improve testing practices for the next program by understanding the current failures\nand sharing lessons learned.\n\n7.1.3\nReview of Original Hypotheses\nThrough the interview process with experts in the testing field and subsequent analysis,\nthe hypotheses stated at the beginning of the thesis were confirmed. The hypotheses\nwere:\nHypothesis 1: Many decisions makers do not utilize a holistic approach in addressing\ntesting requirements.\nMost decision makers have good intentions and are making the best possible decisions\nbased of the information they have available to them. In order to improve their\ndecisions, all decision factors need to be considered, especially confidence factors and\ndecision-making biases.\nHypothesis 2: Life-cycle costs are not adequately addressed in the decision-making\nprocess.\nAgain, decision makers must use the information that is available. Unfortunately,\ntesting and on-orbit repair cost are not divided and tracked in a manner to yield high-\nfidelity life-cycle cost estimates.\nHypothesis 3: Decision makers are not fully aware of the influences inherent in the\ndecision-making process.\nThere are numerous decision-making factors and influences that decision makers must\nevaluate and balance. Many decision makers may not fully appreciate the significance\nof each decision factor or the long-term effects of their decisions. In addition, proactive\nefforts are typically not taken to minimize unintended decision-making behaviors or to\ncapitalize on the desired biases.\nHypothesis 4: The influence of organizational factors is not fully appreciated.\nMost managers do understand that the organizational structure does influence the\noverall efficiency of the project. What is not fully appreciated is the significant impact\nthat organizational considerations have on testing and integration efforts later in the\nprogram. Most important, the ability to integrate software into each sub-system is\nstrongly affected by organizational considerations.\n7.2\nRecommendations\nNumerous recommendations for improving future NASA human-rated spacecraft test\nprograms have been discussed throughout this thesis. The most significant\nrecommendations are summarized in this section. Even though these proposals specifically\n\naddress NASA programs, each can be applied, in principle, to other programs and\nindustries.\no Form an agency-wide team to seek out best practices in the test engineering field.\nNPG 7120.5 should then be updated to give managers detailed guidelines for test\nplanning and implementation.\no Enhance the current risk management practices to include an assessment of all\ndecisions making factors that contribute to the overall level of likelihood. In\naddition, the current rationale used to rank competing risks should re-evaluated.\no Establish improved training and mentoring programs for test engineers. The agency\nshould also evaluate the feasibility of establishing a small testing corps that would\nremain intact and move from one project to another, augmenting the resident\ntesting teams of each project. This testing corps would mentor the other engineers\non the project, while learning new skills and best practices as well. This approach\nwould proliferate the needed test expertise throughout the agency, which is\nimportant to maintain because contractor organizations are not consistent between\nprograms and projects.\no Assign both responsibility and accountability for software to system engineering.\nSoftware is an integral part of the system and should be treated equally with the\nother system components.\no Consider test engineering a valid profession with a viable career path for test\nengineers. This would help to improve the current leve l of prestige that testing\nreceives within the agency and also help to retain the critical test engineering skills.\no Track actual testing costs in a manner that will allow for better estimates of future\ntest requirement costs. In addition, a better method for tracking and estimating life-\ncycle costs should be established.\no Include testing in the earliest stages of the spacecraft's development process.\nProper system and test engineering representation in the design definition phase\nwill increase the fidelity of the test requirements and effectiveness of test programs.\nIn addition, having previous experience with the hardware and software can be very\nimportant in recognizing system trends and unexpected emergent behavior in the\nlater phases of the program.\no Recognize and understand personal risk-tolerance levels and how individual\ndecision-making styles affect decisions. Furthermore, decision-making styles could\nbe matched to specific types of management positions. A balanced team of risk-\nadverse and risk-tolerant personalities will provide a collaborative environment that\nwill place proper emphasis on all of the decision factors being considered.\n\no Establish separate test organizations within the projects in order to develop skills,\nfacilitate knowledge transfer, improve communication, and establish consistent test\nphilosophies. If a separate test organization is established, however, increased\nintegration and communication will be required.\no Align all project participants with the overall goals of the project and hold them\naccountable for the systems ultimate success or failure.\n7.3\nFuture Work\nBased on the findings and recommendations presented in this thesis, three suggestions for\nfuture research are provided. These suggestions are offered as next steps for additional\nunderstanding of the nature of testing within spacecraft development programs.\no Interviews from outside the human-rated spacecraft arena should be conducted to\ncapture the expert testing knowledge that exists across NASA and outside of the\nagency. A comparison of the common themes and findings could be made to those\nidentified in this thesis in order to build on the existing foundation of knowledge.\no Investigation into the current methods for estimating and tracking spacecraft testing\nlife-cycle costs should be conducted and a reliable cost estimating tool developed.\nSuch a tool would be useful for future spacecraft development program planning\nand budgeting.\no Further research into the individual decision-making process, as it applies to\ntesting, is also suggested. A deeper understanding of the testing decision-making\nprocess will serve as a starting point for the development of a rigid decision making\nframework.\n\nNotes\n[1]\nYoung, T. \"Mars Program Independent Assessment Team Report \". NAS A,\nMarch 14, 2000.\n[2]\nLink, D.C.R (Chairman). \"Report of the Huygens Communications System\nInquiry Board\". NASA, December 2000.\n[3]\nZarakhovich, Y. \"Why No One Escaped From The Kursk\". Time Magazine.\nJune 3, 2002.\n[4]\nZarakhovich, p. 1.\n[5]\nNASA. NASA Systems Engineering Handbook, SP-6105. NASA, June, 1995.\n[6]\nNASA. Program and Project Management Policy Guide, NPG 7120.5B.\nNASA. 2000.\n[7]\nBonabeau, Eric. \"Predicting The Unpredictable \". Harvard Business Review.\nMarch, 2002.\n[8]\nBlanchard, B.S. and Fabrycky, W.J. Systems Engineering and Analysis. Prentice\nHall. January, 1998, p.121.\n[9]\nNASA (SP-6105), p. 3.\n[10]\nNASA (SP-6105), p. 3.\n[11]\nNASA (SP-6105), p. 21.\n[12]\nNASA (SP-6105), p. 21.\n[13]\nNASA (SP-6105), p. 106.\n[14]\nWilkins, D. J. \"The Bathtub Curve, Infant Mortality and Burn-in\". Reliability\nHot Wire, http://weibull.com/hotwire/issues21/hottopics21.htm.\n[15]\nNASA (SP-6105), p. 106.\n[16]\nNASA (SP-6105), p. 106.\n[17]\nBlanchard, p. 126.\n[18]\nNASA (SP-6105), p. 106.\n[19]\nBlanchard, p. 121.\n[20]\nHerbert, F. http://www.quotationspage.com.\n[21]\nExpert Interview #8, October 1, 2002.\n[22]\nNASA (SP-6105), p. 38.\n[23]\nExpert Interview #9, October 2, 2002.\n[24]\nExpert Interview #11, October 8, 2002.\n[25]\nExpert Interview #1, August 13, 2002.\n[26]\nExpert Interview #6, August 29, 2002.\n\n[27]\nExpert Interview #6, August 29, 2002.\n[28]\nExpert Interview #7, September 30, 2002.\n[29]\nExpert Intervie w #13, October 29, 2002.\n[30]\nExpert Interview #5, August 20, 2002.\n[31]\nExpert Interview #7, September 30, 2002.\n[32]\nExpert Interview #11, October 8, 2002.\n[33]\nExpert Interview #6, August 29, 2002.\n[34]\nExpert Interview #10, October 4, 2002.\n[35]\nExpert Interview #13, October 29, 2002.\n[36]\nExpert Interview #8, October 1, 2002.\n[37]\nNASA (NPG 7120.5B), p. 64.\n[38]\nExpert Interview 12, October 28, 2002.\n[39]\nExpert Interview #13, October 29, 2002.\n[40]\nRobbins, S.P. Organizational Behavior, 9th Edition. Prentice Hall. 2001, p. 424.\n[41]\nExpert Interview #5, August 20, 2002.\n[42]\nForsberg, K and Mooz, H. Visualizing Project Management. John Wiley and\nSons. May, 2000.\n[43]\nForsberg, p. 21.\n[44]\nExpert Interview #6, August 29, 2002.\n[45]\nLeveson, N.G. Safeware: System Safety and Computers . Addison Wesley,\n1995.\n[46]\nMargolies, D. \"Test What You Fly?\". NASA, ASK Magazine, Volume 9, p. 7\nOctober 2002.\n[47]\nNASA (NPG 7120.5B), p. 91.\n[48]\nNASA (NPG 7120.5B), p. 91.\n[49]\nExpert Interview #9, October 2, 2002.\n[50]\nLions, J.L. (Chairman). \"Ariane 501 Failure: Report by the Inquiry Board\".\nEuropean Space Agency, 19 July, 1996.\n[51]\nLions, p. 16.\n[52]\nLeveson, N.G. \"The Role of Software in Spacecraft Accidents\". Massachusetts\nInstitute of Technology. 2002.\n[53]\nExpert Interview #4, August 20, 2002.\n[54]\nExpert Interview #7, September 30, 2002.\n[55]\nExpert Interview #6, August 29, 2002.\n\n[56]\nLink, p. 7.\n[57]\nBranscome, D.R. (Chairman). \"WIRE Mishap Investigation Board Report \".\nNASA, June 8, 1999.\n[58]\nArceneaux, W.H. \"International Space Station (ISS) Integration and\nVerification Methods, Current Status, and Future Plans \". AIAA. October,\n2002.\n[59]\nExpert Interview #11, October 8, 2002.\n[60]\nExpert Interview #9, October 2, 2002.\n[61]\nExpert Interview #9, October 2, 2002.\n[62]\nLeveson (Safeware), p. 75.\n[63]\nNASA. \"Risk Management Procedures and Guidelines\", NPG8000.4. NASA.\nApril, 2002.\n[64]\nNASA (NPG 8000.4), p. 11.\n[65]\nNASA (NPG 8000.4), p. 12.\n[66]\nNASA (NPG 8000.4), p. 10.\n[67]\nNASA (NPG 8000.4), p. 11.\n[68]\nNASA (NPG 8000.4), p. 12.\n[69]\nNASA. International Space Station Program, Risk Management Plan, SSP\n50175A. NASA. April, 2002.\n[70]\nNASA (SSP-50175A), p. 18.\n[71]\nNASA (SSP-50175A), p. 14.\n[72]\nNASA (SSP-50175A), p. 18.\n[73]\nLeveson (Safeware), p. 273.\n[74]\nLeveson (Safeware), pp. 272-273.\n[75]\nNASA (SSP-50175A), p. 18.\n[76]\nAllen, T.J. \"Organizing for More Effective Product Development (Working\nPaper). January, 2002.\n\nReferences\nAllen, T.J. \"Organizing for More Effective Product Development (Working Paper).\nJanuary, 2002.\nArceneaux, W.H. \"International Space Station (ISS) Integration and Verification\nMethods, Current Status, and Future Plans \". AIAA. October, 2002.\nBlanchard, B.S. and Fabrycky, W.J. Systems Engineering and Analysis. Prentice Hall.\nJanuary, 1998.\nBonabeau, Eric. \"Predicting The Unpredictable \". Harvard Business Review. March,\n2002.\nBranscome, D.R. (Chairman). \"WIRE Mishap Investigation Board Report \". NASA,\nJune 8, 1999.\nChandler, S. MEIT Overview. NASA, November, 2001.\nChiles, J. Inviting Disaster. Harper Collins. 2001.\nForsberg, K and Mooz, H. Visualizing Project Management. John Wiley and Sons.\nMay, 2000.\nGallina, T. 6A MEIT I. NASA. August, 2002.\nHasting, D. Space Systems Architecture and Design. Space Sys tems, Policy\nArchitecture Research Consortium. March, 2002.\nJordan, J., Michel, F. The LEAN Company, Making The Right Choices. Society of\nManufacturing Engineers. 2001.\nKahneman, D. Choices, Values and Frames. Cambridge University Press. 2002.\nKohler, H. Statistics For Business and Economics, 2nd Edition. Scott, Forsman and\nCompany. 1988.\nKrieck, J. \"Lessons on Program Management, How To Accumulate Scar Tissue \".\nMIT, Systems Design and Management. July, 2002.\nLeveson, N.G. \"The Role of Software in Spacecraft Accidents\". Massachusetts Institute\nof Technology. 2002.\nLeveson, N.G. Safeware: System Safety and Computers . Addison Wesley, 1995.\n\nLink, D.C.R (Chairman). \"Report of the Huygens Communications System Inquiry\nBoard\". NASA, December 2000.\nLions, J.L. (Chairman) \"Ariane 501 Failure: Report by the Inquiry Board\". European\nSpace Agency, 19 July, 1996.\nMargolies, D. \"Test What You Fly?\". NASA, ASK Magazine, Volume 9. October 2002.\nMcManus, H, Warmkessel, J. New Methods for Architecture Selection and Conceptual\nDesign, SPARC Program Overview. Space Systems, Policy Architecture Research\nConsortium. March, 2002.\nNASA. Independent Verification and Validation (IV&V) Criteria, NPG 2820. NASA.\nProposed Appendix.\nNASA. International Space Station Program, Risk Management Plan, SSP 50175A.\nNASA. April, 2002.\nNASA. NASA Systems Engineering Handbook, SP-6105. NASA, June, 1995.\nNASA. Program and Project Management Policy Guide, NPG 7120.5A. NASA. 2000.\nNASA. Risk Management Procedures and Guidelines, NPG 8000.4. NASA. April,\n2002.\nNASA. Software Independent Verification and Validation (IV&V) Policy, NPD\n8730.4. NASA, August 2001.\nRobbins, S.P. Organizational Behavior, 9th Edition. Prentice Hall. 2001.\nSchultz, D., Bachman, J. A Matrix Approach to Software Process Definition.\nNovember, 2000.\nSterman, J. Business Dynamics, Systems Thinking and Modeling For A Complex\nWorld. McGraw Hill. 2000.\nUrlich, K, Eppinger, S. Product Design and Development. McGraw Hill Company.\n2000.\nYoung, T. \"Mars Program Independent Assessment Team Report \". NASA, March 14,\n2000.\nZarakhovich, Y. \"Why No One Escaped From The Kursk\". Time Magazine. June 3,\n2002.\n\nAppendix A - Expert Interview Questionnaire\nSection I: Basic Information\n1. Full Name (optional): _______________________________________ 2. Date: ___/___/___\n3. Organization: ________________ 3A. Location (City/State): _______________________\n4. Job Title: _____________________\n5. Number of years working at your job: ___ 6. Area of Expertise: _____________________\n7. Which of these best describes your Job Title:\n(a) Systems Engineer\n(b) Project Manager (c) Other (please specify): ___________________\n8. Email Address: _______________________\n9. Telephone Number: _________________\nSection II: The Role of Testing and Requirement Definition:\n10.\nWhat type of testing is performed by your organization? (qualification, acceptance,\nintegration, etc.).\n11.\nWhat purpose does testing serve in your program, how important is it? (In other\nwords, is it a double-check or is it the only way items are verified)?\n12.\nWould you consider one type of testing more important than the others?\n13.\nWhat would you consider to be the optimal phase in a new program to address test\nrequirements for spacecraft programs and why?\na. In your experience, when does it actually take place?\nb. What are the advantages and disadvantages?\nc. What are the barriers to the optimal timing?\n14.\nHow is criticality determined and functionality prioritized? What systematic way\ndo yo u use to establish this priority and when in the process is it accomplished?\n15.\nWhat criteria are used to establish the robustness and accuracy of emulators and\nsimulators. How does this decision affect other testing decisions?\n16.\nWhat process do you use to define/evaluate/approve test requirements initially?\n\n17.\nWhat is the process for determining the level of testing to be performed and the\ntime/phase when it is performed?\n18.\nHow and when are decisions made regarding the use of prototyping, proto-flights,\nor struc tural test articles?\n19.\nAre test requirement reviews held in parallel with other system level reviews?\nWhy or why not?\n20.\nHow are cost factors used in deciding when, and to what extent, testing is\nperformed?\nSection III: Decision Making Factors\n21.\nWhat factors do you consider when deciding what tests to perform?\na. Are the factors always the same or do they change based on the situation?\nb. Where does the data come from that decisions are based on?\nc. What do you use (or have you seen used) as the basis for decisio ns (for\nexample: past experience, organization/program policy, defined framework,\ngut feeling, political influence?\n22.\nWhat other external factors influence the decisions?\n23.\nWhat cost factors influence test requirement development?\n24.\nRelatively, how are these factors weighted and does this weighting change\ndepending on the situation?\n25.\nUnder what circumstances does planned testing change?\n26.\nSometimes during testing the system will act in an unexpected manner, allowing\nyou to learn more about the design and/or unintended behavior. Do you anticipate\nthat this will happen and if so, how do you handle this in developing requirements?\nHow do you handle the risk of unknown system behavior?\n27.\nIs hardware and software system testing treated differently? In what way?\n28.\nWhat is the best time to merge hardware and software testing? Who makes that\ndecision?\na. What are the trade-offs between the different options?\nb. How are these trade-offs handled...what determines the priority?\n29.\nWhat are the similarities between the hardware and software testing environments\nand what are the differences?\n\n30.\nFor software testing, how do you determine what tests are repeated (after a new s/w\nrelease or change) vs. those that can be simulated?\nSection IV: Testing Budgets and Cost Considerations\n31.\nIs there a separately identifiable budget line item for testing in your program? If,\nso what amount is it and what percentage of the total program cost does it\nrepresent?\n32.\nHow does this compare to other programs?\n33.\nHow much of the program budget should be spent on testing?\n34.\nAre life cycle costs considered in testing decisions and if so how?\nSection V: Organizational Factors and Knowledge Transfer\n35.\nWhat would you consider to be the optimal way to organize to support testing\n(should there be a separate testing group)?\na. In your experience, how are the programs organized?\nb. What are the advantages and disadvantages?\nc. What are the barriers to the optimal organization?\n36.\nWho \"owns\" (or should own) the requirements?\n37.\nWho makes the recommendations and who is the final decision maker when it\ncomes to testing?\n38.\nHow does System Engineering affect the different stages of testing? How does\nreality compare to the ideal situation?\n39.\nWhat best practices can be obtained from earlier programs and how can they be\nincorporated into cur rent testing programs? How well are these lessons transferred\nto other programs?\n40.\nWhat would you change about your testing program if you could?\n\nAppendix B - Glossary\nAnalysis:\nThe use of specific techniques, such as statistics, modeling, or\nqualitative methods to verify compliance to\nspecifications/requirements.\nConsequence:\nAn assessment of the worst credible potential result(s) of a risk.\nInspection:\nTechniques used to physically verify design features.\nLikelihood:\nThe probability that an identified risk event will occur.\nRisk:\nThe combination of (1) the probability (qualitative or quantitative)\nthat a program or project will experience an undesired event such\nas cost overrun, schedule slippage, safety mishap, compromise of\nsecurity, or failure to achieve a needed technological\nbreakthrough; and (2) the consequences, impact, or severity of the\nundesired event were it to occur.\nSafety:\nFreedom from those conditions that can cause death, injury,\noccupational illness, damage to or loss of equipment or property,\nor damage to the environment.\nSimilarity:\nA verification technique that uses comparison of similar hardware\ncomponents.\nSimulation:\nA technique for verification that uses hardware or software other\nthan flight items, but built to behave in an identical manner as\nflight systems.\nTest Organization:\nThose engineers accountable for implementing test requirements\nand the program management functions for these activities.\nTesting:\nA method of verification in which the actual equipment is allowed\nto operate under conditions that demonstrate its ability to perform\nas specified by the design requirements.\nUncertainty:\nThe lack of knowledge about an outcome or event that hampers a\nmanager's ability to make decisions and draw conclusions.\nValidation:\nDetermining that a system performs as intended by the customer.\nVerification:\nDetermining that a system performs according to the design\nrequirements."
    },
    {
      "category": "Resource",
      "title": "fse.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/cb49f1c3119d0ed720843897f9772009_fse.pdf",
      "content": "Making Embedded Software Reuse Practical and Safe\nNancy G. Leveson, Kathryn Anne Weiss\nAeronautics and Astronautics; Engineering Systems\nMassachusetts Institute of Technology\nABSTRACT\nReuse of application software has been limited and some\ntimes has led to accidents. This paper suggests some re\nquirements for successful and safe application software reuse\nand demonstrates them using a case study on a real space\ncraft.\nCategories and Subject Descriptors\nC.3 [Computer Systems Organization]: Real-Time and\nEmbedded Systems; D.2.1 [Software Engineering]: Re-\nquirements/Specifications; D.2.2 [Software Engineering]:\nDesign Tools and Techniques--Software Libraries; D.2.13\n[Software Engineering]: Reusable Software\nGeneral Terms\nDocumentation, Design\nKeywords\nSoftware reuse, Real-time and embedded software\n1.\nUNDERSTANDING THE PROBLEM\nReuse is clearly a partial solution to the long and costly\ndevelopment problems we are experiencing with complex\ncontrol systems.1 Development costs for such systems can\nreach billions of dollars, and they can take a decade to com\nplete. In some cases, the technology has become obsolete\nbefore the systems are finished (e.g., the FAA's microwave\nlanding system). The reuse of application software, how\never, has not lived up to its promises and has, at times,\nresulted in spectacular losses. In spacecraft, for example,\nNASA, the European Space Agency, and the Air Force have\nlost billions of dollars and important scientific missions due\nto software reuse and poorly designed changes to operating\nsoftware [10].\nFor a very comprehensive survey of software reuse and an\nextensive bibliography, see Kruger [7].\nSIGSOFT'04/FSE-12, Oct.31-Nov. 6, 2004, Newport Beach, CA, USA.\nCopyright 2004 ACM 1-58113-855-5/04/0010 ...$5.00.\nExamining the Mars Climate Orbiter (MCO) loss is in\nstructive. The loss of the MCO involved minor changes to\nsoftware that was being reused from the Mars Global Sur\nveyor (MGS) spacecraft [3]. According to the developers\n(but surprisingly absent from the accident report), the orig\ninal software contained a conversion from imperial to metric\nunits, but that conversion was not documented and was in\nadvertently omitted when a new thruster equation had to\nbe used because MCO had a different size Reaction Control\nSystem (RCS) thruster. \". . . the 4.5 conversion factor, al\nthough correctly included in the MGS equation by the pre\nvious development team, was not immediately identifiable\nby inspection (being buried in the equation) or commented\nin the code in an obvious way that the MCO team recog\nnized it\" [3].\nThe problems are not simply related to safety. Goodman\ndescribes the experiences United Space Alliance had in try\ning to take GPS software that was created for aircraft and\nreuse it for spacecraft. Although they assumed that the\noff-the-shelf GPS units with proven design and performance\nwould reduce acquisition costs and require minimal adapta\ntion and minimal testing, the time, budget, and resources\nneeded to test and resolve software issues greatly exceeded\ninitial projections:\nSoftware evolves and changes over time. Many\nvendors have a library of software modules, many\nof which are used in multiple applications. Soft\nware errors that manifest in a particular applica\ntion may be deemed to have \"no impact\" to the\nuser and are not corrected. This causes software\nerrors to propagate through succeeding product\nlines, with the potential for affecting future users\nin different applications. Changes in operating\nenvironment that come with a new application\nmay invalidate assumptions made during initial\nrequirements definition and result in software is\nsues during testing and operation [5, p.3].\nSome successful reuse reports have been premature. The\nmodules may be reused in the next similar project, but\nfewer can be used in later projects. In fact, in the well-\nknown NASA Goddard reuse experiment, while reuse was\nhigh in the next project (about 70%), it quickly dwindled\nover time to the point where the original extra cost of pro\nducing reusable modules was never recovered [15]. While it\nmay appear that new versions of embedded systems do not\nchange dramatically, in fact there are enough changes in the\nmissions and design of the physical systems and devices the\nsoftware is controlling--after all, the reason a new system\n\nis being built at all is to change or augment functionality--\nthat changes to the software will usually be required to reuse\nit. This fact does not preclude application software reuse,\nbut it does suggest some requirements for reuse, including\nthe fact that it must be possible to make changes easily and\nsafely.\nThe question is how to get the benefits of reuse without\nthe drawbacks [19]. The answer may rest in the development\nlevel at which reuse is applied. The most problematic reuse\nhas been attempted at the code level, but reuse may be more\neffective and safe by going back to an earlier development\nphase and beginning the reuse from that phase (i.e., reuse\nthe work performed up to that phase). Because coding is\nsuch a small part of the software engineering process, partic\nularly for real-time embedded control software, and coding\nfor these applications can even be partially automated from\nrequirements specifications, the cost of repeating the coding\nstep is insignificant compared to the potential cost of revali\ndating the reused code. In addition, safely changing code is\neasier when the changes are made at an earlier development\nphase.\nThe rest of this paper describes the requirements we be\nlieve must be satisfied for successful, large-scale reuse of em\nbedded control software and a case study using a real system\nto evaluate the feasibility of satisfying these requirements.\nNote that this paper focuses on application software reuse,\nnot system software although some of the requirements and\nsolutions may be similar.\n2. REQUIREMENTS FOR EFFECTIVE\nSOFTWARE REUSE\nKnowledge capture in the specification of the software and\nthe controlled system is critical for successful reuse of appli\ncation software. That specification must contain the follow\ning:\n- Documentation of design rationale: A basic require\nment for successful and safe reuse is having thoroughly\ndocumented design rationale and design assumptions\nfor both the system and the software design. The\nlack of such specifications has been cited in most of\nthe well-known spacecraft accidents in the recent past\nwhere reuse of software components was an important\nfactor in the loss [10]. The accident report on the Ar\niane 501 explosion, for example, mentions poor speci\nfication practices in several places and notes that the\nstructure of the documentation obscured the ability to\nreview the critical design decisions and their underly\ning rationale [12]. The report recommends that justifi\ncation documents be given the same attention as code\nand that techniques for keeping code and its justifica\ntions consistent be improved. One of the conclusions\nof the GPS project mentioned above was that they\nneeded insight into the rationale and requirements that\ngoverned the original design of the GPS units to suc\ncessfully reuse them in a different environment from\nthat for which they were designed [4]. Goodman notes\nthat the documentation they received was limited to\n\"how\" and often did not include \"why\":\nSoftware requirements documents contain equa\ntions to be used, but rarely provide insight\ninto how the equations were derived, or how\nvalues of constants were determined. This\ninformation exists on paper at some point,\nin the form of informal memos and company\ninternal letters. However, over time, this in\nformation is lost due to employee attrition,\nclean-out of offices, retirements and corpo\nrate takeovers. Many mathematical results\nused in navigation algorithms no longer exist\nin the open literature. Corporate knowledge\nloss makes it difficult for engineers to under\nstand, evaluate, and modify software years\nor decades after it was written and certified\n[4, p.9].\n- Documentation of the assumptions about the opera\ntional environment that are implicit in the software:\nThese assumptions include interfaces with other com\nponents and other structural features, but also include\nassumptions about behavior. In the SOHO (SOlar He\nliospheric Observatory) mission interruption [13], crit\nical assumptions about the operation of the gyros were\nnot recorded anywhere and were violated when the\nground control software modules were reused. The\nGPS integration attempt described earlier found that\nvendors tend to perform the minimum amount of lab\ntesting necessary to ensure that the unit meets con\ntract specifications. Without specification of the as\nsumptions of the environment in which the system was\ndeveloped, tested, and used, it is not possible to deter\nmine what additional testing and analysis needs to be\nperformed or what changes may be necessary to meet\nthe conditions in a different operational environment.\nFor example, many of the software issues that arose\nwith the GPS units involved design problems that are\nnot manifested in aviation applications where flight\ntimes may last minutes or hours but may appear in\nthe much longer space flight applications. Goodman\nnotes that the documentation United Space Alliance\nreceived about the GPS units did not include the as\nsumptions made in designing the GPS receiver for ter\nrestrial applications that were invalid for the new space\napplications [4].\n- Traceability from high-level system requirements to sys\ntem design to software requirements to code and vice\nversa: By traceability, we do not mean simply in\ncluding the standard traceability matrix showing the\nmapping between high-level requirements and software\nmodules or CSCIs but instead traceability to system\ndesign features and decisions. Such traceability al\nlows those planning reuse to make sure that the re\nquirements and assumptions about the operation of\nthe component fit the new use and to determine any\ninteractions with other components that need to be\nconsidered. In the SOHO mission interruption, the\naccident report cites one factor as a lack of system\nknowledge by the person modifying the software pro\ncedure. Clearly the same was true for MCO. Not hav\ning this system knowledge and traceability can lead to\nfear of modifying reused software modules, which was\na factor in both the Ariane and Milstar launch acci\ndents [14]. Traceability potentially provides a way to\nacquire the system knowledge necessary to successfully\nreuse software.\n\n- Documentation of hazard analysis and safety informa\ntion: A hazard analysis needs to be performed for each\nsafety-critical system. Without information about the\noriginal hazard analysis and the specific safety con\nstraints related to the reused software component, it\nis very difficult to perform this analysis. This diffi\nculty, coupled with lack of documentation of reused\nsoftware module and common issues with proprietary\ninformation, makes reuse very hazardous. While soft\nware may be perfectly safe in one environment, it can\nlead to accidents in another. The Ariane 501 loss is an\nexample, where a difference in the Ariane 5 trajectory\nfrom the Ariane 4 trajectory triggered the unsafe soft\nware behavior. The same software error that led to the\nTherac-25 deaths had a benign manifestation in the\nearlier Therac-20. The blackbox (externally visible)\nbehavior of a component can only be determined to be\nsafe by analyzing its effects on the system in which it\nwill be operating. Cost-effective reuse of safety-critical\nsoftware requires clear documentation of the assump\ntions and procedures underlying the original hazard\nanalysis.\nSimply including this necessary information in the speci\nfications is, however, not enough. The information must be\nspecified in a way that is easy to find, use, and change. Most\nprojects have voluminous documentation, but it is often dif\nficult to understand and is incomplete, inconsistent, and am\nbiguous. In addition, validation and verification of the new\nsystem and the reused components within it will require the\ncollaborative efforts of many types of domain experts. The\nlanguage used in the specifications must be easily readable\nand reviewable with minimal training by non-software engi\nneers. Accomplishing this goal requires minimizing semantic\ndistance between the specification and the engineers' men\ntal models, incorporating standard notations when possible,\nminimizing obscure notations, and including animation and\nvisualization tools to assist in understanding the behavior\nspecified or modeled.\nSome other characteristics and practices can, in our ex\nperience, assist with reuse, but are not necessarily required.\nOne is model-based development using blackbox models of\nsoftware behavior. Such model-based development is not\nby itself enough to make reuse safe, but combined with the\nrequired characteristics above, reuse can start with the mod\nels, necessary changes can be made, the changes validated,\nand then code generated (either manually or automatically)\nfrom the models. In fact, there is evidence that this pro\ncess works: TCAS has been maintained and gone through\nmultiple versions since our first model was created in the\nearly 1990s [11]. Each time a new version is needed, the de\nvelopers go back to the RSML specification, make changes\nto the model, and then validate the newly changed model.\nWhen they are convinced that the changes are effective and\nsafe, new code is created by incorporating any changes that\nhave been made in the models. Because our specification in\ncludes complete traceability from the TCAS models to the\ncode, the process of making and verifying changes to the\ncode is greatly simplified.\nPerhaps more controversial, we believe that object-oriented\nsystem design may inhibit safe reuse of embedded applica\ntion software and has other important drawbacks. The au\nthors' experience and that of others on complex projects\n(e.g., Pathfinder [17] and Iridium [8]) is that functional de\ncomposition of embedded control software is safer and more\neffective than object-oriented system design, particularly with\nrespect to establishing the very high level of confidence nec\nessary in control software and in its maintenance and reuse.\nProblems in OOD arise particularly from the tight func\ntional coupling involved in spreading control functions among\nthe objects rather than providing the functionally cohesive\nmodules that result from functional decomposition of the\nsystem requirements.\nVerification of the safety of the original, reused, or changed\ncode is basically impossible for object-oriented system de\nsign. Those building such systems in the aviation realm have\nsuggested that object-oriented technology is inappropriate\nfor safety-critical applications [6].\nSafety problems arise\nfrom interactions among components involved in achieving\nsafety-critical functions. Safety analysis, therefore, focuses\non the safety-critical system functions, which in object-oriented\nsystem design can potentially be spread throughout so many\nobjects (and involve multiple inheritance levels) that high\nconfidence in the system behaving safely is impossible to\nprovide. Note that only programming-in-the-large is being\nconsidered here. Object-oriented design within the individ\nual models is perfectly reasonable and usually safe.\n3.\nA CASE STUDY\nThe approach to reuse employed in the case study starts\nfrom a library of generic executable component specifica\ntions describing the component's blackbox hardware and\nsoftware behavior. Only externally observable behavior is\nspecified, not the internal design. The developer then selects\nappropriate components, assembles them into subsystems\nand system specifications, and uses simulation (the specifi\ncations are executable) and analysis (the specifications are\nformal) to validate the design and perform at least partial\nsystem testing. For embedded software, testing and formal\nanalysis are not adequate to find all the errors so human\nreview by a varied group of domain experts is also required.\nHuman review can be enhanced by visualization tools. Later\nverification and testing of the reused and perhaps changed\nmodules and system can be assisted by automatic generation\nof test data from the component models, and the executable\nspecifications can act as a test oracle during the code testing\nprocess.\nAlthough several different toolsets can be used to imple\nment such a approach, Weiss used a commercial require\nments specification tool called SpecTRM [16] to perform a\ncase study of reuse on a family of autonomous spacecraft\n(nanosatellites) called SPHERES [18]. SPHERES (Synchronous\nPosition Hold Engage Reorient Experimental Satellites) was\ncreated by MIT's Space Systems Laboratory to provide NASA\nand the Air Force with a reusable, space-based testbed for\nhigh-risk metrology, control, and autonomy technologies crit\nical to the operation of distributed satellite and docking\nmissions, such as the Terrestrial Planet Finder and Orbital\nExpress. The SPHERES testbed was designed to operate\nin the micro-gravity conditions on the International Space\nStation although deployment has been delayed due to the\nColumbia accident. In addition, it is planned for guest sci\nentists from around the world to have access to this testbed\nto independently design and evaluate estimation, control,\nand autonomy algorithms for autonomous coordination and\nsynchronization of multiple spacecraft in tightly controlled\nspatial configurations. The very nature of the purpose of\n\nProgram\nGuest Scientist\ntype of reasoning about it. Refinement and decomposition\noccurs within each level of the specification, rather than be\ntween levels.\nThis structure is designed to facilitate several activities\nStructure\nSphere\nController\nSubsystem\nElectrical\nnecessary for successful reuse. First, hyperlinks are used to\nmap between levels and facilitate reasoning across hierarchi-\nPropulsion\nCommunication\nPADS\nSubsystem\nSubsystem\nFiring Thrusters\nBeacons\nSPHERES\nLaptop\nFigure 1: The Functional Structure of SPHERES\nSPHERES implies that reuse of software could save enor\nmous amounts of programming effort by the guest scientists.\nFigure 1 shows the functional decomposition of SPHERES.\nThe Sphere controller provides the overall coordination of\nthe actions of the onboard components as well as deter\nmining the overall operating mode of the Sphere. Each\nSphere controller provides the interface for and control of\nthat Sphere's propulsion, position and attitude determina\ntion, communication, guest scientist program, electrical, and\nstructural subsystems. Because the focus of the case study\nwas on subsystems that contain both hardware and software,\nthe structural and electrical subsystems were not modeled,\nalthough they easily could have been included.\nEach Sphere receives attitude and position information\nfrom its PADS (Position and Attitude Determination Sub\nsystem). The Sphere controller uses this information to cal\nculate the position and orientation of each Sphere. The\nguest scientist program running on board a Sphere per\nforms either state estimation, control calculations, or both\nto determine which control actions need to be performed to\nachieve a new position and/or attitude. Two guest scientist\nprograms were created for this study: a rate damper and a\nrate matcher.\nSphere control is actuated through the propulsion subsys\ntem and the Spheres coordinate action through their com\nmunication subsystems. Astronauts on the ISS load and\nunload programs and information to and from the Spheres\nthrough a laptop computer.\n3.1 Modeling and Analysis of the SPHERES\nComponents\nThe SpecTRM specification/modeling tool used in the\ncase study is based on intent specifications [9]. Briefly, an\nintent specification differs from a standard specification pri\nmarily in its structure: the intent specification is structured\nas a hierarchy of \"models\" designed to describe the sys\ntem from different viewpoints, with complete traceability\nbetween models (see Figure 2). Levels do not represent the\nmore familiar refinement abstraction, but a why or intent ab\nstraction with higher levels providing the rationale (why) for\nthe lower levels. Rather than each level representing more\ndetailed information than the higher levels, each level of an\nintent specification represents a different model of the same\nsystem from a different perspective and supports a different\ncal levels. They also implement the tracing of system-level\nrequirements and design constraints to related design de\ncisions, and vice versa, to explain why the design decisions\nwere made. Note that the structure of the specification does\nnot imply that the development must proceed from the top\nlevels down to the lower levels in that order, only that at\nthe end of the development process, all levels are complete.\nAn environment that involves extensive reuse, for example,\nmight follow a very different development process from one\nthat involves a lot of first-time development.\nInformation about design rationale, as argued above, is\ncritical to successful reuse. The necessary design rationale\ninformation, including the underlying assumptions upon which\nthe design and validation is based, is integrated directly into\nthe intent specification and its structure, rather than relying\non it being captured and maintained in separate documents.\nTo avoid accidents and mission losses, reused components\nmust be analyzed to determine whether they violate the de\nsign rationale, assumptions, and safety constraints of the\nsystem within which they are to be used. This process is\nusually impractical, if not impossible, for reuse at the code\nlevel but not for reuse at the blackbox model specification\nlevel and above (Levels 1 to 3), where most of the original\nsafety analysis is done.\nDuring operations, if changes are made to any physical\nsystem component (or if software is to be reused in a differ\nent system), potential violation of assumptions underlying\nthe original system design must trigger re-analysis of the\nsoftware. To accomplish this goal, not only must the engi\nneers know when assumptions change, but they must be able\nto figure out which parts of the design rely on those assump\ntions in order to reduce the costs of revalidating correctness\nand safety. Intent specifications are designed to make that\nprocess feasible and practical.\nLevel 0\nThe top level (Level 0) of an intent specification provides\na project management view and insight into the relation\nship between the plans and the project development status\nthrough links to the other parts of the intent specification.\nOne problem in managing large projects is simply getting\nvisibility into the progress of the project, particularly when\na lot of software in involved. The project management level\nmight include project plans, such as risk management plans,\npert charts, system safety plans, etc., with embedded hyper\nlinks to the various parts of the intent specification where\nthe plans are implemented.\nLevel 1\nLevel 1 is the customer view of the project and includes the\nhigh-level goals, contractual requirements (the shall state\nments or functional requirements), design constraints, envi\nronmental constraints and assumptions, operator and inter\nface requirements, system hazard analyses and hazard lists,\nand system limitations. Links from these parts of the specifi\ncation down to other levels provides understanding of design\nrationale and the ability to determine how the requirements,\n\nPart-Whole\n(Interface between System and Component Engineers)\n(Management View)\n(Customer View)\n(System Engineering View)\n(Component Designer View)\n(Component Implementer View)\n(Operations View)\nSystem\nOperator\nEnvironment\nVerification\nValidation\nLevel 0: Program\nManagement\nLevel 1: System\nPurpose\nLevel 2: System\nDesign Principles\nLevel 4: Design\nRepresentation\nRepresentation\nLevel 5: Physical\nRefinement\nLevel 6: System\nOperations\nLevel 3: System\nArchitecture\nIntent\nFigure 2: The Structure of an Intent Specification\nResponsibilities\nRequirements\nI/F requirements\nSystem goals, high-level\nrequirements, design\nconstraints, limitations\nExternal\ninterfaces\nTask analyses\nControls, displays\nTask allocation\nfunctional decomposition\nand allocation\nProject management plans, status information, safety plan, etc.\nEnvironment\nmodels\nmodels\nOperator Task\nHCI models\nBlackbox functional\nmodels\nInterface specifications\nConstraints\nAssumptions\nReviews\nValidation plan\nand results,\nAnalysis plans\nand results,\ncontrol laws,\nLogic principles,\nSystem Hazard\nAnalysis\nHazard Analysis\nSubsystem\nHCI design\nSoftware and hardware\ndesign specs\nRep.\nGUI design,\nphysical controls\ndesign\nSoftware code, hardware\nassembly instructions\nAudit\nprocedures\nOperator manuals\nMaintenance\nTraining materials\nError reports, change\nrequests, etc.\nTest plans\nand results\nTest plans\nand results\nPerformance\nmonitoring\nand audits\nRep.\nOperations\nLevel 5\nPhysical\nLevel 4\nLevel 3\nLevel 1\nLevel 6\nLevel 0\nProg. Mgmt.\nHazard Analysis,\nPreliminary\nSystem\nPurpose\nPrinciples\nSystem\nLevel 2\nDesign\nSystem\nArchitecture\nEnvironment\nOperator\nSystem and components\nV&V\nFigure 3: Example Contents of an Intent Specification\n\nenvironmental assumptions, and hazard analysis informa\ntion are implemented in the system design.\nAn example requirement for the propulsion subsystem (re\nferred to below) is:\n[FR.4] If force and torque vectors are received from\nthe Sphere Controller, the propulsion subsystem shall\ndetermine on and off times for each thruster based on\nthe thruster's location and the force and torque needed\n[↓ DP.3.2].\nRationale: The guest scientists should have the\nability to stock compute firing times for the thrusters\nbased on desired force and torque vectors.\n[FR.7] The Propulsion Subsystem shall include enough\nthrusters to provide actuation throughout the six-degrees-\nof-freedom [↓ DP.1.3.].\nRationale: The SPHERES system is designed to\noperate in space and therefore must be able to\ntranslate in three dimensions and rotate in three\ndimensions.\nA propulsion subsystem hazard is:\n[H.1] A pressure rise in the propulsion subsystem above\n4500 psi [← SC.3].\nRationale: Such a pressure rise may result in an\nexplosion that could either injure an astronaut or\ndamage the Sphere.\nThe safety constraint at Level 1 related to this hazard is:\n[SC.3] A mechanical system must be included in each\nSphere that will mitigate a pressure rise in the propul\nsion subsystem [→ H.1, ↓ DP.2.4].\nLevel 2\nLevel 2 is the system engineering view and assists engineers\nin recording and reasoning about the system in terms of the\nphysical principles and application design principles upon\nwhich the system design is based. It describes how the Level\n1 requirements are achieved in the overall system design,\nincluding any \"derived\" requirements and design features\nnot related to the Level 1 requirements, and how the Level\n1 design constraints are enforced. It is at this level that the\nuser of the intent specification can get an overview of the\nsystem design and determine why the design decisions were\nmade, either by information included at this level or via the\nhyperlinks to Level 1. Examples from Level 2:\n[DP.1.3] The thrusters are arranged on the Sphere to\nprovide pure body-axis force or torque using only two\nthrusters, assuming uniform mass and inertia proper\nties. The twelve thrusters are arranged in six back-\nto-back pairs, allowing for full six-degrees-of-freedom\nactuation. Figure 2 shows the Sphere thruster config\nuration [↑ FR.7].\nRationale: It is expected that the majority of ma\nneuvers will involve primarily body-axis rotations,\nand the flight thruster geometry is significantly\nmore propellant-efficient than other geometries for\nthese maneuvers.\n[DP.2.4] There are two pressure release mechanisms,\nor burst disks, in the propulsion subsystem. One is\nattached to the tank coupling and one is on the reg\nulator itself. These mechanisms burst if the pressure\nbuilds to greater than 4500 psi [↑ H.1, SC.3].\nRationale: The burst disks will rupture before the\ntank reaches a hazardous pressure of greater than\n4500 psi, thereby releasing the pressure buildup.\n[DP.2.5] The regulator is used to expand the liquid\nCO2 into a gas and simultaneously decrease the thruster\nfeed pressure to between 0 and 35 psig.\nRationale: At 35 psig, the average thruster force\nis approximately 0.1N, which is the desired oper\nating thrust for each thruster.\n[DP.3.2.1] The Pulse Modulation software calculates\nthe duration that thrusters should be opened based\non body-referenced force and torque vectors from the\nSphere controller using the following equations . . . [↑\nFR.4, ↓ Thruster Pair 17 Calculation, . . . ].\nLevel 3\nLevel 3 is the System Architecture Level. It includes infor\nmation about the allocation of the design decisions at Level\n2 to individual system components (hardware, software, and\noperators) and the component blackbox behavior that im\nplements those decisions. Level 3 in turn has links to the\nimplementation of the specified behavior (i.e., behavioral\nrequirements) in the design of the software, hardware, and\noperator procedures. If it is necessary to make a change to\na component or to reuse it in a different system, it is pos\nsible to trace the function implemented by that component\nupward in the intent specification to determine its design\nassumptions, the requirements it is satisfying, related de\nsign principles, the design rationale, the safety-critical con\nstraints enforced, and its role in the overall system design.\nLevel 3 essentially serves as an unambiguous interface be\ntween system engineers and component engineers. At Level\n3, the system functions defined at Level 2 are allocated to\ncomponents and specified rigorously. Blackbox behavioral\ncomponent models are used to specify and reason about\nthe logical design of the system as a whole and the inter\nactions among individual system components without being\ndistracted by component design and implementation details.\nWe believe the models at this level are the most effective\nplace to start most reuse efforts. For the case study, we cre\nated generic Level 3 models that can be instantiated for any\nparticular system in which the component is to be reused.\nThe design of the formal language at this level, called\nSpecTRM-RL, is the result of lessons learned from the use\nof RSML and later variants of RSML on real projects and\nin laboratory experiments on specification language design,\nparticularly lessons about error-prone features. For exam\nple, although internally broadcast events were included in\nRSML, they caused so many errors and so much difficulty\nin review of the models that they are not used in SpecTRM-\nRL. The primary goals for the new language were readability\nand reviewability (ability to find errors), completeness with\nrespect to safety, and assisting with system safety analysis\nof the requirements.\nSpecTRM-RL has a formal foundation (a simple state ma\nchine) so it can be executed and subjected to some types\n\nolenoid Valve 1 State\n= Unknown\nPropulsion Subsystem in mode Startup\nT\nT\n*\n*\nSystem Start\n= Open\nPropulsion Subsystem in mode Force Torque\nThruster Pair 17 Calculation () > 0 nanoseconds\nlast\nTime since Desired Thruster 1 State\nentered Open < Thruster Pair 17 Calculation ()\nPrevious value of Desired Thruster 1 State\nin state Closed\nDesired Thruster 1 State has never entered Open\nPropulsion Subsystem in mode Direct\nSystem Start\nDirect Control Thruster 1 is On\nT\nT\n*\n*\n*\n*\nF\nT\nT\n\nT\nT\n\nT\nT\n\nT\n*\n*\nF\nF\nF\nF\n\nT\n*\nF\n*\n= Closed\nSystem Start\nPropulsion Subsystem in mode Direct\nPropulsion Subsystem in mode Force Torque\nDirect Control Thruster 1 is Off\nThruster Pair 17 Calculation () = 0 nanoseconds\nTime since Desired Thruster 1 State\nPrevious value of Desired Thruster 1 State\nin state Open\nentered Open >= Thruster Pair 17 Calculation ()\nT\n*\n*\n*\nF\nT\nT\nT\n\nT\n*\n*\n*\nF\nF\nF\n\nF\nF\n\nT\nT\n*\n*\nFigure 4: The and/or tables used to specify the logic\nunder which the state variable Solenoid Valve 1 State\nis assigned the values Unknown, Open, and Closed.\nTables evaluate to true (and the state transition is\ntaken) if any of the columns in the table evaluate\nto true, i.e., each row of the column is true. Aster\nisks represent \"don't care\" conditions. For exam\nple, the first column in the logic describing when\nthe Solenoid Valve 1 State will have the value Open\nsays that the state variable should have this value if\nthe propulsion subsystem is not in the startup state,\nits current control mode is Direct Mode, and it has\nreceived an input to turn the thruster On. When\nthe propulsion system is in Force Torque Mode, it\nreceives a force/torque vector from the Sphere Con\ntroller that specifies the forces and torques needed\nto accomplish a required maneuver. The Propulsion\nSubsystem then calculates how long the thrusters\nneed to be on to achieve the actuation (the Thruster\nPair 17 Calculation, the details of which are not\nshown). Solenoid Valve 1 stays open until the time\nsince the valve was opened is greater than or equal\nto the calculated Open duration for the thruster.\nof formal analysis, such as completeness and consistency\nanalysis, while being designed to be readable with minimal\ntraining--the models can be read and reviewed by engineers\nand operators after about 10-15 minutes instruction. Fig\nure 4 shows an example of the specification of detailed logic\nusing and/or tables. These tables essentially incorporate\nformal propositional logic in disjoint normal form in a way\nthat is easily reviewed (and written) by those not trained\nin formal logic. The tables can be machine parsed and exe\ncuted.\nWe have also experimented with visualization to under\nstand whether usability of formal specification languages\nmight also be improved through the use of interactive visual\nizations automatically generated from the underlying formal\nmodel [1, 2].\nLevels 4, 5, and 6\nThe Design Representation and Physical Representation lev\nels provide the information necessary to reason about indi\nvidual component design and implementation issues. Some\nparts of Level 4 may not be needed if at least portions of\nthe physical design can be generated automatically from the\nmodels at Level 3. The final level, Operations, provides a\nview of the operational system and is useful in mapping be\ntween the designed system and its underlying assumptions\nabout the operational environment envisioned during design\nand the actual operational environment. Level 6 provides a\nplace to accumulate the operational information helpful in\nreusing the component in a different system or in a new use\nof the same system.\nLevels 4, 5 were not created for the case study (although\nthe Spheres code obviously exists) because they were not\nneeded to evaluate the potential for reuse at the higher lev\nels. Spheres operation has been delayed due to the Columbia\naccident (it was scheduled to go up to the ISS on the next\nshuttle flight after Columbia) so operational information is\nnot available for Level 6.\n3.2\nEvaluation of Reuse in the Case Study\nFor the case study, Weiss produced a library of generic in\ntent specifications (Levels 1, 2, and 3) that could be reused\nby the guest scientists to create new algorithmic test envi\nronments and by the SPHERES team itself for future ver\nsions of the system. The effort took about six person-weeks,\nincluding developing a simulation environment and an ani\nmation of the Spheres moving in space as the SpecTRM-RL\nmodels are \"executed\" together in a simulation environment.\nThe first version of the system included only one Sphere\nand a guest scientist program called a Rate Damper. Later,\nto demonstrate reuse, a second Sphere was assembled from\nthe preexisting components and a second Rate Matcher guest\nscientist program integrated into the two-Sphere configuration--\nall in under an hour. The changes were then simulated\nto evaluate their correctness. A new version of the ba\nsic SPHERES platform is planned, and we will evaluate\nwhether and how well the generic models and intent speci\nfications assist with reuse of the original code.\n4.\nCONCLUSIONS\nThis paper described a set of requirements we believe are\nnecessary for reuse of embedded application software to be\nboth practical and safe. A description of a case study using\na commercial system engineering development environment\n\non a real spacecraft followed. We believe that similar types\nof engineering environments, where reuse is attempted at\nthe software behavioral requirements level rather than the\ncode level, will allow engineering teams to tailor reused com\nponents and designs to fit their needs rather than requiring\nthem to fit their needs to a particular piece of code. It also\nmakes the process of validating and verifying the correctness\nand safety of reused software practical and, in turn, may al\nlow more safety-critical software reuse. This hypothesis, of\ncourse, needs to be more thoroughly validated in realistic\ndevelopment environments.\n5.\nACKNOWLEDGEMENTS\nThis research was partially supported by NSF ITR Grant\nCCR-0085829 and NASA Engineering for Complex Systems\nGrant NAG2-1543.\n6.\nREFERENCES\n[1] Nicolas Dulac. Empirical Evaluation of Design\nPrinciples for Increasing Reviewability of Formal\nRequirements Specifications through\nVisualization. Master's Thesis, Aeronautics and\nAstronautics, MIT, August 2003.\n[2] Nicholas Dulac, Thomas Viguier, Nancy Leveson,\nand Margaret-Anne Storey, On the use of\nvisualization in formal requirements specification.\nInternational Conference on Requirements\nEngineering, Essen, Germany, September 2002.\n[3] E.E. Euler, S.D. Jolly, and H.H. Curtis. The\nfailures of the Mars Climate Orbiter and Mars\nPolar Lander: A perspective from the people\ninvolved. Proceedings of Guidance and Control\n2001, American Astronautical Society, paper\nAAS 01-074, 2001.\n[4] John L. Goodman. Lessons learned from flights\nof 'off-the-shelf' aviation navigation units on the\nSpace Shuttle. Joint Navigation Conference,\nOrlando Florida, May 2002.\n[5] John L. Goodman. A software perspective on\nGNSS receiver integration and Operation.\nSatellite Navigation Systems: Policy,\nCommercial, and Technical Interaction,\nInternational Space University, Strasbourg,\nFrance, May 2003.\n[6] Kelly J. Hayhurst and C. Michael Holloway.\nConsidering object-oriented technology in\naviation applications. Digital Avionics Systems\nConference, 2003.\n[7] Charles Kruger. Software reuse. ACM Computing\nSurveys, Vol. 24, No. 2, June 1992, pp. 131-183.\n[8] Ray Leopold. Personal communication. May\n2004.\n[9] Nancy G. Leveson Intent specifications: An\napproach to building human-centered\nspecifications. IEEE Transactions on Software\nEngineering, Vol. SE-26, No. 1, January 2000.\n[10] Nancy G. Leveson The role of software in\nspacecraft accidents. AIAA Journal of Spacecraft\nand Rockets, Vol 41, No. 4, July 2004.\n[11] Nancy G. Leveson, Mats P.E. Heimdahl, Holly\nHildreth, and Jon Damon Reese. Requirements\nspecification for process-control systems. IEEE\nTransactions on Software Engineering, SE-20,\nNo. 9, September, 1994.\n[12] J.L. Lions (Chair). Ariane 501 Failure: Report\nby the Inquiry Board. European Space Agency,\nJuly 19, 1996.\n[13] NASA/ESA Investigation Board. SOHO Mission\nInterruption. NASA, August 31, 1998.\n[14] J.G. Pavlovich (Chair). Formal Report of\nInvestigation of the 30 April Titan IV B/Centaur\nTC-14/Milstar-3 (B-32) Space Launch Mishap.\nU.S. Air Force, 1999.\n[15] Linda Rosenberg. Personal communication.\nAugust 2001.\n[16] Safeware Engineering Corporation. SpecTRM\nUser Manual. 2003.\n[17] Steven A. Stolper. Streamlined design approach\nlands Mars Pathfinder. IEEE Software, Vol. 16,\nNo. 5, September/October 1999.\n[18] Kathryn Anne Weiss. Component-Based Systems\nEngineering for Autonomous Spacecraft.\nMaster's Thesis, Aeronautics and Astronautics,\nMIT, August 2003.\n[19] Elaine Weyuker. Testing component-based\nsoftware: A cautionary tale. IEEE Software,\nSeptember/October 1998."
    },
    {
      "category": "Resource",
      "title": "highsmith_people.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/2b20a4073ba55635daf5267861d961e1_highsmith_people.pdf",
      "content": "I\nS O F T W A R E M A N A G E M E N T\nAgile Software\nDevelopment:\nThe People Factor\nAlistair Cockburn, Humans and Technology\nJim Highsmith, Cutter Consortium\nand skills of individuals and molds\nprocess to specific people and teams, not\nthe other way around.\nAGILE IS FOR PEOPLE\nThe most important implication to\nmanagers working in the agile manner is\nthat it places more emphasis on people\nfactors in the project: amicability, talent,\nskill, and communication.\nThese qualities become a primary con\ncern for the would-be agile team. Skill\ndevelopment is important, so that each\nperson can deliver more value with time.\nThe attention to the human issues\ngives agile projects a particular feel. It is\nAgile development focuses\non the talents and skills of\nindividuals, molding the\nprocess to specific people\nand teams.\nn a previous article (\"Agile Software\nDevelopment: The Business of Inno\nvation,\" Computer, Sept. 2001, pp.\n120-122), we introduced agile soft\nware development through the prob\nlem it addresses and the way in which it\naddresses the problem. Here, we describe\nthe effects of working in an agile style.\nAGILE RECAPPED\nOver recent decades, while market\nforces, systems requirements, implemen\ntation technology, and project staff were\nchanging at a steadily increasing rate, a\ndifferent development style showed its\nadvantages over the traditional one. This\nagile style of development directly ad\ndresses the problems of rapid change.\nA dominant idea in agile development\nis that the team can be more effective in\nresponding to change if it can\n- reduce the cost of moving informa\ntion between people, and\n- reduce the elapsed time between\nmaking a decision to seeing the con\nsequences of that decision.\nTo reduce the cost of moving infor\nmation between people, the agile team\nworks to\n- place people physically closer,\n- replace documents with talking in\nperson and at whiteboards, and\n- improve the team's amicability--its\nsense of community and morale--\nso that people are more inclined to\nrelay valuable information quickly.\nTo reduce the time from decision to\nfeedback, the agile team\n- makes user experts available to the\nteam or, even better, part of the team\nand\n- works incrementally.\nMaking user experts available as part\nof the team gives developers rapid feed\nback on the implications to the user of\ntheir design choices. The user experts,\nseeing the growing software in its earliest\nstages, learn both what the developers\nmisunderstood and also which of their\nrequests do not work as well in practice\nas they had thought.\nThe term agile, coined by a group of\npeople experienced in developing software\nthis way, has two distinct connotations.\nThe first is the idea that the business\nand technology worlds have become tur\nbulent, high speed, and uncertain, requir\ning a process to both create change and\nrespond rapidly to change.\nThe first connotation implies the sec\nond one: An agile process requires\nresponsive people and organizations.\nAgile development focuses on the talents\nnot simply a matter of reducing paper\nwork and hoping that everything else will\nfall into place. To paraphrase one devel\noper, \"A small, rigorous methodology\nmay look the same as an agile method\nology, but it won't feel the same.\"\nThe agile group concept grows to span\nteams, organizations, and other working\nrelationships. It is very difficult for agile\npeople to function well in a rigid organi-\nzation--and vice versa.\nINDIVIDUAL COMPETENCE\nAgile development teams focus on\nindividual competency as a critical fac\ntor in project success.\nIf the people on the project are good\nenough, they can use almost any process\nand accomplish their assignment. If they\nare not good enough, no process will\nrepair their inadequacy--\"people trump\nprocess\" is one way to say this.\nHowever, lack of user and executive\nsupport can kill a project--\"politics\ntrump people.\" Inadequate support can\nkeep even good people from accom\nplishing the job.\nThe \"CHAOS Chronicles Version II,\"\na recent update of the Chaos Report\nNovember 2001\n\nS o f t w a r e M a n a g e m e n t\nfrom the Standish Group (http://www.\npm2go.com), outlines a recipe for suc\ncess that includes 10 items. The first three\nitems are executive support, user involve\nment, and experienced project manage\nment.\nThese items are certainly key, and we\nagree with having them in the top 10.\nHowever, \"competent staff\" is buried\ninside the tenth item: \"Other.\"\nWhile it is true that \"politics trump peo\nple,\" it is equally true that the developers\nwon't succeed in producing a system if\nthey lack the basic competency for the job.\nInterestingly, people working together\nwith good communication and interac\ntion can operate at noticeably higher lev\nels than when they use their individual\ntalents. We see this time and again in\nbrainstorming and joint problem-solving\nsessions.\nTherefore, agile project teams focus on\nincreasing both individual competencies\nand collaboration levels.\nIn Now, Discover Your Strengths,\n(Simon & Schuster, New York, 2001),\nMarcus Buckingham and Curt Coffman\ndiscuss the outcome of a long-running\nresearch program by the Gallup organi\nzation, in which 80,000 managers in 400\ncompanies were interviewed over a 25\nyear period In this book, they highlight\nthe interplay between talent, skill, and\nknowledge. Regarding high-performance\nworking environments, they write:\nThe larger, establishment camp is com\nprised of those organizations that leg\nislate the process of performance. ...\nThey try to teach each employee to\nwalk the same path.\nThis [people-based] type of organiza\ntion focuses not on the steps of the\njourney but on the end of the journey.\nThe distinction between the two camps\nis real. Step-by-step organizations are\ndesigned to battle the inherent indi\nviduality of each employee. Strength-\nbased organizations are designed to\ncapitalize on it.\nExtending their ideas, it's not that orga\nnizations that employ rigorous processes\nvalue people less than agile ones, it's that\nthey view people--and how to improve\ntheir performance--differently. Rigorous\nprocesses are designed to standardize\npeople to the organization, while agile\nprocesses are designed to capitalize on\neach individual and each team's unique\nstrengths: One-size-fits-one--every pro\ncess must be selected, tailored, and\nadapted to the individuals on a particu\nlar project team.\ndesigned to capitalize on\neach individual and each\nAgile processes are\nteam's unique strengths.\nToo often, software engineering and\nrigorous process adherents confuse\nprocess and competence. Process can\nprovide a useful framework for groups\nof individuals to work together, but\nprocess per se cannot overcome a lack of\ncompetency, while competency can\nsurely overcome the vagaries of a\nprocess--again, \"people trump process.\"\nWhen you look under the cover of XP,\nScrum, Adaptive Software Development,\nCrystal Methods, Feature-Driven De\nvelopment (FDD), or Dynamic Systems\nDevelopment Methodology (DSDM), the\nemphasis on people and their talent, skill,\nand knowledge becomes evident.\nThis is a competency attitude, not an\nelitist one. Whether it's the practices of\npair programming and mentoring in XP\nor chief programmers and inspections in\nFDD, the goal remains consistent--\nworking jointly to improve the knowl\nedge and skill of individuals. A recent\nbook by Pete McBreen, an agile devel\nopment practitioner, is therefore appro\npriately titled not software engineering\nbut Software Craftsmanship (Addison-\nWesley, Reading, Mass., 2001).\nTEAM COMPETENCE\nAgile teams are characterized by self-\norganization and intense collaboration,\nwithin and across organizational bound\naries.\nSelf-organizing teams are not leaderless\nteams; they are teams that can organize\nagain and again, in various configura\ntions, to meet challenges as they arise.\nAgility requires that teams have a com\nmon focus, mutual trust, and respect; a\ncollaborative, but speedy, decision-mak-\ning process; and the ability to deal with\nambiguity.\nWe distinguish collaboration from\ncommunication. Communication is the\nsending and receiving of information.\nCollaboration is actively working to\ngether to deliver a work product or make\na decision.\nThe DSDM manual, for example,\nidentifies the differences between tradi\ntional and agile project managers, one of\nwhich is: \"A traditional project manager\nwill normally focus on agreeing to a\ndetailed contract with customers about\nthe totality of the system to be delivered\nalong with the costs and timescales. In a\nDSDM project, the project manager is\nfocused on setting up a collaborative\nrelationship with the customers.\"\nScrum projects are characterized by\nintense 15 to 30 minute daily meetings in\nwhich participants constantly adjust to\nthe realities of high-change projects.\nAll too often, project teams are given\nthe ultimate accountability for product\ndelivery, while staff groups--project\noffices, process management, data admin-\nistrators--are given decision power. In\norder to innovate and react to change,\nagile teams reflect a better alignment of\naccountability and responsibility. It is\nagain an emphasis, at the team level, on\ncompetency rather than process.\nAGILE ORGANIZATIONS\nAn agile team working within a rigid\norganization has as difficult a time as\nagile individuals working within a rigid\nteam. Many project teams we have inter\nviewed report that when they responded\nto customers' requests and to technology\nplatform changes to deliver usable value\nto the customer, their management\nadmonished them for lack of confor\nmance to the original plan.\nAgile organizations and agile man\nagers understand that demanding cer\ntainty in the face of uncertainty is\ndysfunctional. Agile companies practice\nleadership-collaboration rather than\ncommand-control management. They set\ngoals and constraints, providing bound\naries within which innovation can flour\nComputer\n\nish. They are macromanagers rather than\nmicromanagers. They understand that\nwho makes decisions isn't as important\nas collaboration on information to make\ninformed decisions. They understand\nthat agility depends on trusting individ\nuals to apply their competency in effec\ntive ways.\nDoug DeCarlo has labeled traditional\nproject management \"Newtonian neu\nrosis.\" In this context, neurosis means\nattacking complex, nonlinear problems\nwith simplistic, linear processes.\nAGILE ECOSYSTEMS\nA project is built from people having\ndiffering personalities and differing skills,\nworking in a physical environment\nwithin an organizational culture. The\npeople, environment, and organizational\nculture all influence one another. When\na strong person leaves, the organization\nrearranges itself to compensate; when the\nteam spreads itself across multiple floors,\ncommunications change; and so on. The\nproject is an ecosystem.\nUsing the term ecosystem to convey\nthe totality of the project at hand brings\nus to the discussion of processes and\necosystems and fitting the two together.\nInstalling a process within an ecosys\ntem offers two choices: Fit the ecosystem\nto the process or fit the process to the\necosystem. In reality, both the process\nand ecosystem change, but the agile\napproach honors the ecosystem and rec\nognizes that not every process will work\nin every ecosystem.\nAGILE EFFECTIVENESS\nNearly 200 people from a wide range\nof organizations in North America,\nEurope, Australia, India, and other loca\ntions responded to a survey of agile and\nrigorous methodologies conducted by\nthe Cutter Consortium in 2001. This sur\nvey showed three interesting results.\nFirst, compared to a similar study con\nducted late in 2000, many more organi\nzations said they were using at least one\nagile methodology.\nSecond, agile methodologies showed\nslightly better delivery performance than\nrigorous methodologies in terms of busi\nness performance, customer satisfaction,\nand quality.\nThird, agile methodologies scored bet\nter than rigorous methodologies in terms\nof employee morale. This is particularly\nsurprising in that 54 percent of the respon\ndents were IT and executive managers and\nonly 12 percent were developers.\nOne study is, of course, only one study,\nand we should view the conclusions\naccordingly. However, these preliminary\nresults reflect the effectiveness and con\ntribution of agile approaches to morale.\nAGILE DOMAINS\nAgile development is not for everyone.\nImposing agile principles on process-cen-\ntric, noncollaborative, optimizing organi\nzations is likely to fail. Imposing a change-\nembracing process on sedate project\nteams may not be reasonable. Attempting\nto get close user collaboration with orga\nnizations that have little time to spend\nwith developers won't work.\nAgile development is more difficult\nwith larger teams. The average project\nhas only nine people, well within the\nreach of the most basic agile processes.\nNevertheless, it is interesting to occa\nsionally find successful agile projects with\n120 or even 250 people.\nA\ngile development excels in ex\nploratory problem domains--\nextreme, complex, high-change\nprojects--and operates best in a people-\ncentered, collaborative, organizational\nculture. This approach has proved to be\neffective at solving many problems and at\nforging attractive work environments in\nmany organizations. While it is not suited\nfor everyone, it is suited for many. ✸\nAlistair Cockburn is Consulting Fellow\nat Humans and Technology. Contact him\nat arc@acm.org.\nJim Highsmith is director of the Cutter\nConsortium's e-Project Management\nPractice. Contact him at jimh@\nadaptivesd.com.\nEditor: Barry Boehm, Computer Science\nDepartment, University of Southern\nCalifornia, Los Angeles, CA 90089;\nboehm@sunset.usc.edu\nInnovative technology for computer professionals\nHow to Reach\nComputer\nWriters\ndetailed information, write for a\nContributors' Guide (computer@\nNews Ideas\nContact Lee Garber at lgarber@\nfeatures or news briefs.\nProducts and Books\nSend product announcements to\nStephanie Kawada at skawada@\nments.\nLetters to the Editor\nPlease provide an e-mail address or\ndaytime phone number with your\nCA 90720-1314; fax +1 714 821\nmation about joining and getting\ninvolved with the Society and\nComputer.\nMagazine Change of Address\nSend change-of-address requests\nfor magazine subscriptions to\naddress.change@ieee.org. Make\nsure to specify Computer.\nMissing or Damaged Copies\nIf you are missing an issue or\nReprint Permission\nto +1 714 821 4010.\nWe welcome submissions. For\ncomputer.org) or visit our Web site:\nhttp://computer.org/computer/.\ncomputer.org with ideas for news\nproducts@computer.org. Contact\ncomputer.org with book announce-\nletter. Send letters to Letters,\nComputer, 10662 Los Vaqueros\nCir., PO Box 3014, Los Alamitos,\n4010; computer@computer.org.\nOn the Web\nVisit http://computer.org for infor-\nreceived a damaged copy, contact\nmembership@computer.org.\nTo obtain permission to reprint\nan article, contact William Hagen,\nIEEE Copyrights and Trademarks\nManager, at whagen@ieee.org.\nTo buy a reprint, send a query to\ncomputer@computer.org or a fax\nNovember 2001"
    },
    {
      "category": "Resource",
      "title": "intro_softarch.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/4b3577da7baf3801621e092a5fa32b92_intro_softarch.pdf",
      "content": "An Introduction to Software Architecture\nDavid Garlan and Mary Shaw\nJanuary 1994\nCMU-CS-94-166\nSchool of Computer Science\nCarnegie Mellon University\nPittsburgh, PA 15213-3890\nAlso published as \"An Introduction to Software Architecture,\" Advances in Software Engineering\nand Knowledge Engineering, Volume I, edited by V.Ambriola and G.Tortora, World Scientific\nPublishing Company, New Jersey, 1993.\nAlso appears as CMU Software Engineering Institute Technical Report\nCMU/SEI-94-TR-21, ESC-TR-94-21.\n(c)1994 by David Garlan and Mary Shaw\nThis work was funded in part by the Department of Defense Advanced Research Project Agency under grant\nMDA972-92-J-1002, by National Science Foundation Grants CCR-9109469 and CCR-9112880, and by a grant\nfrom Siemens Corporate Research. It was also funded in part by the Carnegie Mellon University School of\nComputer Science and Software Engineering Institute (which is sponsored by the U.S. Department of Defense).\nThe views and conclusions contained in this document are those of the authors and should not be interpreted\nas representing the official policies, either expressed or implied, of the U.S. Government, the Department of\nDefense, the National Science Foundation, Siemens Corporation, or Carnegie Mellon University.\nKeywords: Software architecture, software design, software engineering\n\nAbstract\nAs the size of software systems increases, the algorithms and data structures of\nthe computation no longer constitute the major design problems.\nWhen\nsystems are constructed from many components, the organization of the\noverall system--the software architecture--presents a new set of design\nproblems. This level of design has been addressed in a number of ways\nincluding informal diagrams and descriptive terms, module interconnection\nlanguages, templates and frameworks for systems that serve the needs of\nspecific domains, and formal models of component integration mechanisms.\nIn this paper we provide an introduction to the emerging field of software\narchitecture. We begin by considering a number of common architectural\nstyles upon which many systems are currently based and show how different\nstyles can be combined in a single design. Then we present six case studies to\nillustrate how architectural representations can improve our understanding of\ncomplex software systems.\nFinally, we survey some of the outstanding\nproblems in the field, and consider a few of the promising research directions.\n\nContents\n1.\nIntroduction .....................................................................................................\n\n2.\nFrom Programming Languages to Software Architecture.....................\n\n2.1.\nHigh-level Programming Languages ...................................................................\n\n2.2.\nAbstract Data Types...........................................................................................\n\n2.3.\nSoftware Architecture ........................................................................................\n\n3.\nCommon Architectural Styles......................................................................\n\n3.1.\nPipes and Filters ................................................................................................\n\n3.2.\nData Abstraction and Object-Oriented Organization ...........................................\n\n3.3.\nEvent-based, Implicit Invocation ........................................................................\n\n3.4.\nLayered Systems ................................................................................................\n\n3.5.\nRepositories .......................................................................................................\n\n3.6.\nTable Driven Interpreters ...................................................................................\n\n3.7.\nOther Familiar Architectures.............................................................................\n\n3.8.\nHeterogeneous Architectures...............................................................................\n\n4.\nCase Studies ......................................................................................................\n\n4.1.\nCase Study 1: Key Word in Context .....................................................................\n\n4.2.\nCase Study 2: Instrumentation Software ..............................................................\n\n4.3.\nCase 3: A Fresh View of Compilers.....................................................................\n\n4.4.\nCase 4: A Layered Design with Different Styles for the Layers ...........................\n\n4.5.\nCase 5: An Interpreter Using Different Idioms for the Components........................\n\n4.6.\nCase 6: A Blackboard Globally Recast as Interpreter ...........................................\n\n5.\nPast, Present, and Future ...............................................................................\n\nAcknowledgements....................................................................................................\n\nBibliography .................................................................................................................\n\nList of Figures\nPipes and Filters .......................................................................................................\n\nAbstract Data Types and Objects............................................................................\n\nLayered Systems .....................................................................................................\n\nThe Blackboard.......................................................................................................\n\nInterpreter................................................................................................................\n\nKWIC - Shared Data Solution.............................................................................\n\nKWIC - Abstract Data Type Solution.................................................................\n\nKWIC - Implicit Invocation Solution ...............................................................\n\nKWIC - Pipe and Filter Solution ........................................................................\n\n10 KWIC - Comparison of Solutions ......................................................................\n\n11 Oscilloscopes - An Object-oriented Model........................................................\n\n12 Oscilloscopes - A Layered Model ........................................................................\n\n13 Oscilloscopes - A Pipe and Filter Model............................................................\n\n14 Oscilloscopes - A Modified Pipe and Filter Model..........................................\n\n15 Traditional Compiler Model...............................................................................\n\n16 Traditional Compiler Model with Shared Symbol Table .............................\n\n17 Modern Canonical Compiler ..............................................................................\n\n18 Canonical Compiler, Revisited...........................................................................\n\n19 PROVOX - Hierarchical Top Level.....................................................................\n\n20 PROVOX - Object-oriented Elaboration ............................................................\n\n21 Basic Rule-Based System......................................................................................\n\n22 Sophistocated Rule-Based System......................................................................\n\n23 Simplified Rule-Based System............................................................................\n\n24 Hearsay-II .................................................................................................................\n\n25 Blackboard View of Hearsay-II ............................................................................\n\n26 Interpreter View of Hearsay-II ............................................................................\n\nGarlan & Shaw: An Introduction to Software Architecture\n\n1.\nIntroduction\nAs the size and complexity of software systems increases, the design problem\ngoes beyond the algorithms and data structures of the computation: designing\nand specifying the overall system structure emerges as a new kind of problem.\nStructural issues include gross organization and global control structure;\nprotocols for communication, synchronization, and data access; assignment of\nfunctionality to design elements; physical distribution; composition of design\nelements; scaling and performance; and selection among design alternatives.\nThis is the software architecture level of design. There is a considerable\nbody of work on this topic, including module interconnection languages,\ntemplates and frameworks for systems that serve the needs of specific domains,\nand formal models of component integration mechanisms. In addition, an\nimplicit body of work exists in the form of descriptive terms used informally to\ndescribe systems. And while there is not currently a well-defined terminology\nor notation to characterize architectural structures, good software engineers\nmake common use of architectural principles when designing complex\nsoftware.\nMany of the principles represent rules of thumb or idiomatic\npatterns that have emerged informally over time. Others are more carefully\ndocumented as industry and scientific standards.\nIt is increasingly clear that effective software engineering requires facility in\narchitectural software design. First, it is important to be able to recognize\ncommon paradigms so that high-level relationships among systems can be\nunderstood and so that new systems can be built as variations on old systems.\nSecond, getting the right architecture is often crucial to the success of a software\nsystem design; the wrong one can lead to disastrous results. Third, detailed\nunderstanding of software architectures allows the engineer to make\nprincipled choices among design alternatives. Fourth, an architectural system\nrepresentation is often essential to the analysis and description of the high-\nlevel properties of a complex system.\nIn this paper we provide an introduction to the field of software\narchitecture. The purpose is to illustrate the current state of the discipline and\nexamine the ways in which architectural design can impact software design.\nThe material presented here is selected from a semester course, Architectures\nfor Software Systems, taught at CMU by the authors [1]. Naturally, a short\npaper such as this can only briefly highlight the main features of the terrain.\nThis selection emphasizes informal descriptions omitting much of the course's\nmaterial on specification, evaluation, and selection among design alternatives.\nWe hope, nonetheless, that this will serve to illuminate the nature and\nsignificance of this emerging field.\nIn the following section we outline a number of common architectural\nstyles upon which many systems are currently based, and show how\nGarlan & Shaw: An Introduction to Software Architecture\n\nheterogeneous styles can be combined in a single design. Next we use six case\nstudies to illustrate how architectural representations of a software system can\nimprove our understanding of complex systems. Finally, we survey some of\nthe outstanding problems in the field, and consider a few of the promising\nresearch directions.\nThe text that makes up the bulk of this article has been drawn from\nnumerous other publications by the authors. The taxonomy of architectural\nstyles and the case studies have incorporated parts of several published papers\n[1, 2, 3, 4]. To a lesser extent material has been drawn from other articles by the\nauthors [5, 6, 7].\n2.\nFrom Programming Languages to Software Architecture\nOne characterization of progress in programming languages and tools has been\nregular increases in abstraction level--or the conceptual size of software\ndesigners building blocks. To place the field of Software Architecture into\nperspective let us begin by looking at the historical development of abstraction\ntechniques in computer science.\n2.1.\nHigh-level Programming Languages\nWhen digital computers emerged in the 1950s, software was written in\nmachine language; programmers placed instructions and data individually and\nexplicitly in the computer's memory.\nInsertion of a new instruction in a\nprogram might require hand-checking of the entire program to update\nreferences to data and instructions that moved as a result of the insertion.\nEventually it was recognized that the memory layout and update of references\ncould be automated, and also that symbolic names could be used for operation\ncodes, and memory addresses. Symbolic assemblers were the result. They were\nsoon followed by macro processors, which allowed a single symbol to stand for\na commonly-used sequence of instructions.\nThe substitution of simple\nsymbols for machine operation codes, machine addresses yet to be defined, and\nsequences of instructions was perhaps the earliest form of abstraction in\nsoftware.\nIn the latter part of the 1950s, it became clear that certain patterns of\nexecution were commonly useful--indeed, they were so well understood that\nit was possible to create them automatically from a notation more like\nmathematics than machine language. The first of these patterns were for\nevaluation of arithmetic expressions, for procedure invocation, and for loops\nand conditional statements. These insights were captured in a series of early\nhigh-level languages, of which Fortran was the main survivor.\nHigher-level languages allowed more sophisticated programs to be\ndeveloped, and patterns in the use of data emerged. Whereas in Fortran data\ntypes served primarily as cues for selecting the proper machine instructions,\nGarlan & Shaw: An Introduction to Software Architecture\n\ndata types in Algol and it successors serve to state the programmer's intentions\nabout how data should be used. The compilers for these languages could build\non experience with Fortran and tackle more sophisticated compilation\nproblems. Among other things, they checked adherence to these intentions,\nthereby providing incentives for the programmers to use the type mechanism.\nProgress in language design continued with the introduction of modules to\nprovide protection for related procedures and data structures, with the\nseparation of a module's specification from its implementation, and with the\nintroduction of abstract data types.\n2.2.\nAbstract Data Types\nIn the late 1960s, good programmers shared an intuition about software\ndevelopment:\nIf you get the data structures right, the effort will make\ndevelopment of the rest of the program much easier. The abstract data type\nwork of the 1970s can be viewed as a development effort that converted this\nintuition into a real theory. The conversion from an intuition to a theory\ninvolved understanding\n- the software structure (which included a representation packaged with\nits primitive operators),\n- specifications (mathematically expressed as abstract models or algebraic\naxioms),\n- language issues (modules, scope, user-defined types),\n- integrity of the result (invariants of data structures and protection from\nother manipulation),\n- rules for combining types (declarations),\n- information hiding (protection of properties not explicitly included in\nspecifications).\nThe effect of this work was to raise the design level of certain elements of\nsoftware systems, namely abstract data types, above the level of programming\nlanguage statements or individual algorithms. This form of abstraction led to\nan understanding of a good organization for an entire module that serves one\nparticular purpose.\nThis involved combining representations, algorithms,\nspecifications, and functional interfaces in uniform ways. Certain support was\nrequired from the programming language, of course, but the abstract data type\nparadigm allowed some parts of systems to be developed from a vocabulary of\ndata types rather than from a vocabulary of programming-language constructs.\n2.3.\nSoftware Architecture\nJust as good programmers recognized useful data structures in the late 1960s,\ngood software system designers now recognize useful system organizations.\nGarlan & Shaw: An Introduction to Software Architecture\n\nOne of these is based on the theory of abstract data types. But this is not the\nonly way to organize a software system.\nMany other organizations have developed informally over time, and are\nnow part of the vocabulary of software system designers. For example, typical\ndescriptions of software architectures include synopses such as (italics ours):\n-\"Camelot is based on the client-server model and uses remote procedure\ncalls both locally and remotely to provide communication among\napplications and servers.\"[8]\n-\"Abstraction layering and system decomposition provide the appearance\nof system uniformity to clients, yet allow Helix to accommodate a\ndiversity of autonomous devices. The architecture encourages a client-\nserver model for the structuring of applications.\"[9]\n-\"We have chosen a distributed, object-oriented approach to managing\ninformation.\" [10]\n-\"The easiest way to make the canonical sequential compiler into a\nconcurrent compiler is to pipeline the execution of the compiler phases\nover a number of processors. . . . A more effective way [is to] split the\nsource code into many segments, which are concurrently processed\nthrough the various phases of compilation [by multiple compiler\nprocesses] before a final, merging pass recombines the object code into a\nsingle program.\"[11]\nOther software architectures are carefully documented and often widely\ndisseminated. Examples include the International Standard Organization's\nOpen Systems Interconnection Reference Model (a layered network\narchitecture) [12], the NIST/ECMA Reference Model (a generic software\nengineering environment architecture based on layered communication\nsubstrates) [13, 14], and the X Window System (a distributed windowed user\ninterface architecture based on event triggering and callbacks) [15].\nWe are still far from having a well-accepted taxonomy of such architectural\nparadigms, let alone a fully-developed theory of software architecture. But we\ncan now clearly identify a number of architectural patterns, or styles, that\ncurrently form the basic repertoire of a software architect.\n3.\nCommon Architectural Styles\nWe now examine some of these representative, broadly-used architectural\nstyles. Our purpose is to illustrate the rich space of architectural choices, and\nindicate what are some of the tradeoffs in choosing one style over another.\nTo make sense of the differences between styles, it helps to have a common\nframework from which to view them. The framework we will adopt is to treat\nan architecture of a specific system as a collection of computational\nGarlan & Shaw: An Introduction to Software Architecture\n\ncomponents--or simply components---together with a description of the\ninteractions between these components--the connectors. Graphically speaking,\nthis leads to a view of an abstract architectural description as a graph in which\nthe nodes represent the components and the arcs represent the connectors. As\nwe will see, connectors can represent interactions as varied as procedure call,\nevent broadcast, database queries, and pipes.\nAn architectural style, then, defines a family of such systems in terms of a\npattern of structural organization. More specifically, an architectural style\ndetermines the vocabulary of components and connectors that can be used in\ninstances of that style, together with a set of constraints on how they can be\ncombined.\nThese can include topological constraints on architectural\ndescriptions (e.g., no cycles).\nOther constraints--say, having to do with\nexecution semantics--might also be part of the style definition.\nGiven this framework, we can understand what a style is by answering the\nfollowing questions:\nWhat is the structural pattern--the components,\nconnectors, and constraints? What is the underlying computational model?\nWhat are the essential invariants of the style?\nWhat are some common\nexamples of its use? What are the advantages and disadvantages of using that\nstyle? What are some of the common specializations?\n3.1.\nPipes and Filters\nIn a pipe and filter style each component has a set of inputs and a set of\noutputs. A component reads streams of data on its inputs and produces\nstreams of data on its outputs, delivering a complete instance of the result in a\nstandard order.\nThis is usually accomplished by applying a local\ntransformation to the input streams and computing incrementally so output\nbegins before input is consumed. Hence components are termed \"filters\". The\nconnectors of this style serve as conduits for the streams, transmitting outputs\nof one filter to inputs of another. Hence the connectors are termed \"pipes\".\nAmong the important invariants of the style, filters must be independent\nentities: in particular, they should not share state with other filters. Another\nimportant invariant is that filters do not know the identity of their upstream\nand downstream filters. Their specifications might restrict what appears on the\ninput pipes or make guarantees about what appears on the output pipes, but\nthey may not identify the components at the ends of those pipes. Furthermore,\nthe correctness of the output of a pipe and filter network should not depend on\nthe order in which the filters perform their incremental processing--although\nfair scheduling can be assumed. (See [5] for an in-depth discussion of this style\nand its formal properties.) Figure 1 illustrates this style.\nCommon specializations of this style include pipelines, which restrict the\ntopologies to linear sequences of filters; bounded pipes, which restrict the\namount of data that can reside on a pipe; and typed pipes, which require that\nthe data passed between two filters have a well-defined type.\nGarlan & Shaw: An Introduction to Software Architecture\n\nData flowASCII stream\nComputation filter\nFigure 1: Pipes and Filters\nA degenerate case of a pipeline architecture occurs when each filter\nprocesses all of its input data as a single entity.1 In this case the architecture\nbecomes a \"batch sequential\" system. In these systems pipes no longer serve\nthe function of providing a stream of data, and therefore are largely vestigial.\nHence such systems are best treated as instances of a separate architectural style.\nThe best known examples of pipe and filter architectures are programs\nwritten in the Unix shell [16]. Unix supports this style by providing a notation\nfor connecting components (represented as Unix processes) and by providing\nrun time mechanisms for implementing pipes.\nAs another well-known\nexample, traditionally compilers have been viewed as a pipeline systems\n(though the phases are often not incremental). The stages in the pipeline\ninclude lexical analysis, parsing, semantic analysis, code generation.\n(We\nreturn to this example in the case studies.) Other examples of pipes and filters\noccur in signal processing domains [17], functional programming [18], and\ndistributed systems [19].\nPipe and filter systems have a number of nice properties. First, they allow\nthe designer to understand the overall input/output behavior of a system as a\nsimple composition of the behaviors of the individual filters. Second, they\nsupport reuse: any two filters can be hooked together, provided they agree on\nthe data that is being transmitted between them. Third, systems can be easily\nmaintained and enhanced: new filters can be added to existing systems and old\nfilters can be replaced by improved ones. Fourth, they permit certain kinds of\nspecialized analysis, such as throughput and deadlock analysis. Finally, they\nnaturally support concurrent execution. Each filter can be implemented as a\nseparate task and potentially executed in parallel with other filters.\nBut these systems also have their disadvantages.2 First, pipe and filter\nsystems often lead to a batch organization of processing. Although filters can\n1In general, we find that the boundaries of styles can overlap. This should not deter us from\nidentifying the main features of a style with its central examples of use.\n2This is true in spite of the fact that pipes and filters, like every style, has a set of devout\nreligious followers--people who believe that all problems worth solving can best be solved using\nthat particular style.\nGarlan & Shaw: An Introduction to Software Architecture\n\nprocess data incrementally, since filters are inherently independent, the\ndesigner is forced to think of each filter as providing a complete\ntransformation of input data to output data. In particular, because of their\ntransformational character, pipe and filter systems are typically not good at\nhandling interactive applications.\nThis problem is most severe when\nincremental display updates are required, because the output pattern for\nincremental updates is radically different from the pattern for filter output.\nSecond, they may be hampered by having to maintain correspondences\nbetween two separate, but related streams.\nThird, depending on the\nimplementation, they may force a lowest com\nmon denominator on data transmission, resulting in added work for each\nfilter to parse and unparse its data. This, in turn, can lead both to loss of\nperformance and to increased complexity in writing the filters themselves.\n3.2.\nData Abstraction and Object-Oriented Organization\nIn this style data representations and their associated primitive operations are\nencapsulated in an abstract data type or object. The components of this style are\nthe objects--or, if you will, instances of the abstract data types. Objects are\nexamples of a sort of component we call a manager because it is responsible for\npreserving the integrity of a resource (here the representation). Objects interact\nthrough function and procedure invocations. Two important aspects of this\nstyle are (a) that an object is responsible for preserving the integrity of its\nrepresentation (usually by maintaining some invariant over it), and (b) that\nthe representation is hidden from other objects. Figure 2 illustrates this style.3\nobj\nobj\nobj\nobj\nobj\nobj\nobj\nobj\nop\nop\nop\nop\nop\nop\nop\nop\nop\nop\nop\nop\nop\nop\nop\nop\nobj is a manager\nop is an invocation\nADT\nManager\nProc call\nFigure 2: Abstract Data Types and Objects\n3We haven't mentioned inheritance in this description. While inheritance is an important\norganizing principle for defining the types of objects in a system, it does not have a direct\narchitectural function. In particular, in our view, an inheritance relationship is not a connector,\nsince it does not define the interaction between components in a system. Also, in an architectural\nsetting inheritance of properities is not restricted to object types--but may include connectors and\neven architectural styles.\nGarlan & Shaw: An Introduction to Software Architecture\n\nThe use of abstract data types, and increasingly the use of object-oriented\nsystems, is, of course, widespread. There are many variations. For example,\nsome systems allow \"objects\" to be concurrent tasks; others allow objects to\nhave multiple interfaces [20, 21].\nObject-oriented systems have many nice properties, most of which are well\nknown. Because an object hides its representation from its clients, it is possible\nto change the implementation without affecting those clients. Additionally,\nthe bundling of a set of accessing routines with the data they manipulate\nallows designers to decompose problems into collections of interacting agents.\nBut object-oriented systems also have some disadvantages.\nThe most\nsignificant is that in order for one object to interact with another (via\nprocedure call) it must know the identity of that other object. This is in\ncontrast, for example, to pipe and filter systems, where filters do need not\nknow what other filters are in the system in order to interact with them. The\nsignificance of this is that whenever the identity of an object changes it is\nnecessary to modify all other objects that explicitly invoke it. In a module-\noriented language this manifests itself as the need to change the \"import\" list\nof every module that uses the changed module. Further there can be side-\neffect problems: if A uses object B and C also uses B, then C's effects on B look\nlike unexpected side effects to A, and vice versa.\n3.3.\nEvent-based, Implicit Invocation\nTraditionally, in a system in which the component interfaces provide a\ncollection of procedures and functions, components interact with each other by\nexplicitly invoking those routines.\nHowever, recently there has been\nconsiderable interest in an alternative integration technique, variously referred\nto as implicit invocation, reactive integration, and selective broadcast. This\nstyle has historical roots in systems based on actors [22], constraint satisfaction,\ndaemons, and packet-switched networks.\nThe idea behind implicit invocation is that instead of invoking a\nprocedure directly, a component can announce (or broadcast) one or more\nevents. Other components in the system can register an interest in an event by\nassociating a procedure with the event. When the event is announced the\nsystem itself invokes all of the procedures that have been registered for the\nevent. Thus an event announcement ``implicitly'' causes the invocation of\nprocedures in other modules.\nFor example, in the Field system [23], tools such as editors and variable\nmonitors register for a debugger's breakpoint events. When a debugger stops at\na breakpoint, it announces an event that allows the system to automatically\ninvoke methods in those registered tools. These methods might scroll an\neditor to the appropriate source line or redisplay the value of monitored\nvariables. In this scheme, the debugger simply announces an event, but does\nGarlan & Shaw: An Introduction to Software Architecture\n\nnot know what other tools (if any) are concerned with that event, or what they\nwill do when that event is announced.\nArchitecturally speaking, the components in an implicit invocation style\nare modules whose interfaces provide both a collection of procedures (as with\nabstract data types) and a set of events. Procedures may be called in the usual\nway. But in addition, a component can register some of its procedures with\nevents of the system. This will cause these procedures to be invoked when\nthose events are announced at run time. Thus the connectors in an implicit\ninvocation system include traditional procedure call as well as bindings\nbetween event announcements and procedure calls.\nThe main invariant of this style is that announcers of events do not know\nwhich components will be affected by those events. Thus components cannot\nmake assumptions about order of processing, or even about what processing,\nwill occur as a result of their events. For this reason, most implicit invocation\nsystems also include explicit invocation (i.e., normal procedure call) as a\ncomplementary form of interaction.\nExamples of systems with implicit invocation mechanisms abound [7].\nThey are used in programming environments to integrate tools [23, 24], in\ndatabase management systems to ensure consistency constraints [22, 25], in user\ninterfaces to separate presentation of data from applications that manage the\ndata [26, 27], and by syntax-directed editors to support incremental semantic\nchecking [28, 29].\nOne important benefit of implicit invocation is that it provides strong\nsupport for reuse. Any component can be introduced into a system simply by\nregistering it for the events of that system. A second benefit is that implicit\ninvocation eases system evolution [30]. Components may be replaced by other\ncomponents without affecting the interfaces of other components in the\nsystem.\nIn contrast, in a system based on explicit invocation, whenever the identity\nof a that provides some system function is changed, all other modules that\nimport that module must also be changed.\nThe primary disadvantage of implicit invocation is that components\nrelinquish control over the computation performed by the system. When a\ncomponent announces an event, it has no idea what other components will\nrespond to it.\nWorse, even if it does know what other components are\ninterested in the events it announces, it cannot rely on the order in which they\nare invoked. Nor can it know when they are finished. Another problem\nconcerns exchange of data. Sometimes data can be passed with the event. But\nin other situations event systems must rely on a shared repository for\ninteraction. In these cases global performance and resource management can\nbecome a serious issue.\nFinally, reasoning about correctness can be\nproblematic, since the meaning of a procedure that announces events will\nGarlan & Shaw: An Introduction to Software Architecture\n\ndepend on the context of bindings in which it is invoked. This is in contrast to\ntraditional reasoning about procedure calls, which need only consider a\nprocedure's pre- and post-conditions when reasoning about an invocation of it.\n3.4.\nLayered Systems\nA layered system is organized hierarchically, each layer providing service to\nthe layer above it and serving as a client to the layer below. In some layered\nsystems inner layers are hidden from all except the adjacent outer layer, except\nfor certain functions carefully selected for export. Thus in these systems the\ncomponents implement a virtual machine at some layer in the hierarchy. (In\nother layered systems the layers may be only partially opaque.) The connectors\nare defined by the protocols that determine how the layers will interact.\nTopological constraints include limiting interactions to adjacent layers. Figure\n3 illustrates this style.\nCore\nLevel\nBasic Utility\nUseful Systems\nUsers\nComposites of\nvarious elements\nUsually\nprocecure calls\nFigure 3: Layered Systems\nThe most widely known examples of this kind of architectural style are\nlayered communication protocols [31]. In this application area each layer\nprovides a substrate for communication at some level of abstraction. Lower\nlevels define lower levels of interaction, the lowest typically being defined by\nhardware connections. Other appli-cation areas for this style include database\nsystems and operating systems [9, 32, 33 ].\nLayered systems have several desirable properties. First, they support\ndesign based on increasing levels of abstraction. This allows implementors to\npartition a complex problem into a sequence of incremental steps. Second,\nthey support enhancement. Like pipelines, because each layer interacts with at\nmost the layers below and above, changes to the function of one layer affect at\nmost two other layers. Third, they support reuse. Like abstract data types,\ndifferent implementations of the same layer can be used interchangeably,\nprovided they support the same interfaces to their adjacent layers. This leads\nto the possibility of defining standard layer interfaces to which different\nGarlan & Shaw: An Introduction to Software Architecture\n\nimplementors can build. (A good example is the OSI ISO model and some of\nthe X Window System protocols.)\nBut layered systems also have disadvantages. Not all systems are easily\nstructured in a layered fashion. (We will see an example of this later in the\ncase studies.) And even if a system can logically be structured as layers,\nconsiderations of performance may require closer coupling between logically\nhigh-level functions and their lower-level implementations. Additionally, it\ncan be quite difficult to find the right levels of abstraction. This is particularly\ntrue for standardized layered models. One notes that the communications\ncommunity has had some difficulty mapping existing protocols into the ISO\nframework: many of those protocols bridge several layers.\nIn one sense this is similar to the benefits of implementation hiding found\nin abstract data types. However, here there are multiple levels of abstraction\nand implementation. They are also similar to pipelines, in that components\ncommunicate at most with one other component on either side. But instead of\nsimple pipe read/write protocol of pipes, layered systems can provide much\nricher forms of interaction.\nThis makes it difficult to define system-\nindependent layers (as with filters)--since a layer must support the specific\nprotocols at its upper and lower boundaries. But it also allows much closer\ninteraction between layers, and permits two-way transmission of information.\n3.5.\nRepositories\nIn a repository style there are two quite distinct kinds of components: a central\ndata structure represents the current state, and a collection of independent\ncomponents operate on the central data store.\nInteractions between the\nrepository and its external components can vary significantly between systems.\nThe choice of control discipline leads to major subcategories. If the types of\ntransactions in an input stream of transactions trigger selection of processes to\nexecute, the repository can be a traditional database. If the current state of the\ncentral data structure is the main trigger of selecting processes to execute, the\nrepository can be a blackboard.\nFigure 4 illustrates a simple view of a blackboard architecture. (We will\nexamine more detailed models in the case studies.) The blackboard model is\nusually presented with three major parts:\nThe knowledge sources: separate, independent parcels of application-\ndependent knowledge.\nInteraction among knowledge sources takes\nplace solely through the blackboard.\nThe blackboard data structure: problem-solving state data, organized into an\napplication-dependent hierarchy. Knowledge sources make changes to\nthe blackboard that lead incrementally to a solution to the problem.\nGarlan & Shaw: An Introduction to Software Architecture\n\nControl: driven entirely by state of blackboard. Knowledge sources respond\nopportunistically when changes in the blackboard make them applicable.\nBlackboard\n(shared\ndata)\nks1\nks2\nks3\nks4\nks5\nks6\nks7\nks8\nComputation\nMemory\nDirect access\nFigure 4: The Blackboard\nIn the diagram there is no explicit representation of the control\ncomponent. Invocation of a knowledge source is triggered by the state of the\nblackboard. The actual locus of control, and hence its implementation, can be\nin the knowledge sources, the blackboard, a separate module, or some\ncombination of these.\nBlackboard systems have traditionally been used for applications requiring\ncomplex interpretations of signal processing, such as speech and pattern\nrecognition. Several of these are surveyed by Nii [34]. They have also appeared\nin other kinds of systems that involve shared access to data with loosely\ncoupled agents [35].\nThere are, of course, many other examples of repository systems. Batch-\nsequential systems with global databases are a special case. Programming\nenvironments are often organized as a collection of tools together with a\nshared repository of programs and program fragments [36]. Even applications\nthat have been traditionally viewed as pipeline architectures, may be more\naccurately interpreted as repository systems. For example, as we will see later,\nwhile a compiler architecture has traditionally been presented as a pipeline, the\n\"phases\" of most modern compilers operate on a base of shared information\n(symbol tables, abstract syntax tree, etc.).\n3.6.\nTable Driven Interpreters\nIn an interpreter organization a virtual machine is produced in software. An\ninterpreter includes the pseudo-program being interpreted and the\ninterpretation engine itself. The pseudo-program includes the program itself\nand the interpreter's analog of its execution state (activation record). The\ninterpretation engine includes both the definition of the interpreter and the\ncurrent state of its execution.\nThus an interpreter generally has four\ncomponents: an interpretation engine to do the work, a memory that contains\nGarlan & Shaw: An Introduction to Software Architecture\n\nthe pseudo-code to be interpreted, a representation of the control state of the\ninterpretation engine, and a representation of the current state of the program\nbeing simulated. (See Figure 5.)\nData\n(program\nstate)\nInputs\nOutputs\nSelected data\nSelected instruction\nSimulated\nInterp-\nretation\nEngine\nInternal\nInterpreter\nState\nProgram\nBeing\nInterpreted\nMemory\nComputation\nstate mach\nData access\nFetch/store\nFigure 5: Interpreter\nInterpreters are commonly used to build virtual machines that close the\ngap between the computing engine expected by the semantics of the program\nand the computing engine available in hardware. We occasionally speak of a\nprogramming language as providing, say, a \"virtual Pascal machine.\"\nWe will return to interpreters in more detail in the case studies.\n3.7.\nOther Familiar Architectures\nThere are numerous other architectural styles and patterns.\nSome are\nwidespread and others are specific to particular domains. While a complete\ntreatment of these is beyond the scope of this paper, we briefly note a few of the\nimportant categories.\n- Distributed processes: Distributed systems have developed a number of\ncommon organizations for multi-process systems [37]. Some can be\ncharacterized primarily by their topological features, such as ring and\nstar organizations. Others are better characterized in terms of the kinds\nof inter-process protocols that are used for communication (e.g.,\nheartbeat algorithms).\nOne common form of distributed system architecture is a \"client-server\"\norganization [38]. In these systems a server represents a process that provides\nservices to other processes (the clients). Usually the server does not know in\nadvance the identities or number of clients that will access it at run time. On\nthe other hand, clients know the identity of a server (or can find it out through\nsome other server) and access it by remote procedure call.\n- Main program/subroutine organizations: The primary organization of\nmany systems mirrors the programming language in which the system\nGarlan & Shaw: An Introduction to Software Architecture\n\nis written. For languages without support for modularization this often\nresults in a system organized around a main program and a set of\nsubroutines. The main program acts as the driver for the subroutines,\ntypically providing a control loop for sequencing through the\nsubroutines in some order.\n- Domain-specific software architectures: Recently there has been\nconsiderable interest in developing \"reference\" architectures for specific\ndomains [39]. These architectures provide an organizational structure\ntailored to a family of applications, such as avionics, command and\ncontrol, or vehicle management systems.\nBy specializing the\narchitecture to the domain, it is possible to increase the descriptive\npower of structures. Indeed, in many cases the architecture is sufficiently\nconstrained that an executable system can be generated automatically or\nsemi-automatically from the architectural description itself.\n- State transition systems: A common organization for many reactive\nsystems is the state transition system [40]. These systems are defined in\nterms a set of states and a set of named transitions that move a system\nfrom one state to another.\n- Process control systems: Systems intended to provide dynamic control\nof a physical environment are often organized as process control systems\n[41]. These systems are roughly characterized as a feedback loop in which\ninputs from sensors are used by the process control system to determine\na set of outputs that will produce a new state of the environment.\n3.8.\nHeterogeneous Architectures\nThus far we have been speaking primarily of \"pure\" architectural styles.\nWhile it is important to understand the individual nature of each of these\nstyles, most systems typically involve some combination of several styles.\nThere are different ways in which architectural styles can be combined.\nOne way is through hierarchy. A component of a system organized in one\narchitectural style may have an internal structure that is developed a\ncompletely different style. For example, in a Unix pipeline the individual\ncomponents may be represented internally using virtually any style--\nincluding, of course, another pipe and filter, system.\nWhat is perhaps more surprising is that connectors, too, can often be\nhierarchically decomposed.\nFor example, a pipe connector may be\nimplemented internally as a FIFO queue accessed by insert and remove\noperations.\nA second way for styles to be combined is to permit a single component to\nuse a mixture of architectural connectors. For example, a component might\naccess a repository through part of its interface, but interact through pipes with\nother components in a system, and accept control information through\nGarlan & Shaw: An Introduction to Software Architecture\n\nanother part of its interface. (In fact, Unix pipe and filter systems do this, the\nfile system playing the role of the repository and initialization switches playing\nthe role of control.)\nAnother example is an \"active database\".\nThis is a repository which\nactivates external components through implicit invocation.\nIn this\norganization external components register interest in portions of the database.\nThe database automatically invokes the appropriate tools based on this\nassociation. (Blackboards are often constructed this way; knowledge sources are\nassociated with specific kinds of data, and are activated whenever that kind of\ndata is modified.)\nA third way for styles to be combined is to completely elaborate one level of\narchitectural description in a completely different architectural style. We will\nsee examples of this in the case studies.\n4.\nCase Studies\nWe now present six examples to illustrate how architectural principles can be\nused to increase our understanding of software systems. The first example\nshows how different architectural solutions to the same problem provide\ndifferent benefits. The second case study summarizes experience in developing\na a domain-specific architectural style for a family of industrial products. The\nthird case study examines the familiar compiler architecture in a fresh light.\nThe remaining three case studies present examples of the use of heterogeneous\narchitectures.\n4.1.\nCase Study 1: Key Word in Context\nIn his paper of 1972, Parnas proposed the following problem [42]:\nThe KWIC [Key Word in Context] index system accepts an ordered set of\nlines, each line is an ordered set of words, and each word is an ordered\nset of characters. Any line may be ``circularly shifted'' by repeatedly\nremoving the first word and appending it at the end of the line. The\nKWIC index system outputs a listing of all circular shifts of all lines in\nalphabetical order.\nParnas used the problem to contrast different criteria for decomposing a\nsystem into modules. He describes two solutions, one based on functional\ndecomposition with shared access to data representations, and a second based\non a decomposition that hides design decisions. Since its introduction, the\nproblem has become well-known and is widely used as a teaching device in\nsoftware engineering. Garlan, Kaiser, and Notkin also use the problem to\nillustrate modularization schemes based on implicit invocation [7].\nWhile KWIC can be implemented as a relatively small system it is not\nsimply of pedagogical interest. Practical instances of it are widely used by\nGarlan & Shaw: An Introduction to Software Architecture\n\ncomputer scientists. For example, the \"permuted\" [sic] index for the Unix Man\npages is essentially such a system.\nFrom the point of view of software architecture, the problem derives its\nappeal from the fact that it can be used to illustrate the effect of changes on\nsoftware design. Parnas shows that different problem decompositions vary\ngreatly in their ability to withstand design changes. Among the changes he\nconsiders are:\n- Changes in processing algorithm: For example, line shifting can be\nperformed on each line as it is read from the input device, on all the\nlines after they are read, or on demand when the alphabetization\nrequires a new set of shifted lines.\n- Changes in data representation: For example, lines can be stored in\nvarious ways.\nSimilarly, circular shifts can be stored explicitly or\nimplicitly (as pairs of index and offset).\nGarlan, Kaiser, and Notkin, extend Parnas' analysis by considering:\n- Enhancement to system function: For example, modify the system so\nthat shifted lines to eliminate circular shifts that start with certain noise\nwords (such as \"a\", \"an\", \"and\", etc.).\nChange the system to be\ninteractive, and allow the user to delete lines from the original (or,\nalternatively, from circularly shifted) lists.\n- Performance: Both space and time.\n- Reuse: To what extent can the components serve as reusable entities.\nWe now outline four architectural designs for the KWIC system. All four\nare grounded in published solutions (including implementations). The first\ntwo are those considered in Parnas' original article. The third solution is based\non the use of an implicit invocation style and represents a variant on the\nsolution examined by Garlan, Kaiser, and Notkin. The fourth is a pipeline\nsolution inspired by the Unix index utility.\nAfter presenting each solution and briefly summarizing its strengths and\nweakness, we contrast the different architectural decompositions in a table\norganized along the five design dimensions itemized above.\nSolution 1: Main Program/Subroutine with Shared Data\nThe first solution decomposes the problem according to the four basic\nfunctions performed: input, shift, alphabetize, and output.\nThese\ncomputational components are coordinated as subroutines by a main program\nthat sequences through them in turn. Data is communicated between the\ncomponents through shared storage (\"core storage\"). Communication between\nthe computational components and the shared data is an unconstrained read-\nGarlan & Shaw: An Introduction to Software Architecture\n\nwrite protocol. This is made possible by the fact that the coordinating program\nguarantees sequential access to the data. (See Figure 6.)\nMaster Control\nInput\nCircular Shift\nAlphabetizer\nOutput\nInput\nMedium\nCharacters\nIndex\nAlphabetized\nIndex\nOutput\nMedium\nDirect Memory Access\nSystem I/O\nSubprogram Call\nFigure 6: KWIC - Shared Data Solution\nUsing this solution data can be represented efficiently, since computations\ncan share the same storage. The solution also has a certain intuitive appeal,\nsince distinct computational aspects are isolated in different modules.\nHowever, as Parnas argues, it has a number of serious drawbacks in terms\nof its ability to handle changes. In particular, a change in data storage format\nwill affect almost all of the modules.\nSimilarly changes in the overall\nprocessing algorithm and enhancements to system function are not easily\naccomodated. Finally, this decom-position is not particularly supportive of\nreuse.\nSolution 2: Abstract Data Types\nThe second solution decomposes the system into a similar set of five modules.\nHowever, in this case data is no longer directly shared by the computational\ncomponents. Instead, each module provides an interface that permits other\ncomponents to access data only by invoking procedures in that interface. (See\nFigure 7, which illustrates how each of the components now has a set of\nprocedures that determine the form of access by other components in the\nsystem.)\nThis solution provides the same logical decomposition into processing\nmodules as the first. However, it has a number of advantages over the first\nsolution when design changes are considered. In particular, both algorithms\nand data representations can be changed in individual modules without\naffecting others. Moreover, reuse is better supported than in the first solution\nGarlan & Shaw: An Introduction to Software Architecture\n\nbecause modules make fewer assumptions about the others with which they\ninteract.\nMaster Control\nInput\nOutput\nInput\nMedium\nOutput\nMedium\nSystem I/O\nSubprogram Call\nCharacters\nCircular Shift\nAlphabetic\nShifts\nFigure 7: KWIC - Abstract Data Type Solution\nOn the other hand, as discussed by Garlan, Kaiser, and Notkin, the solution\nis not particularly well-suited to enhancements. The main problem is that to\nadd new functions to the system, the implementor must either modify the\nexisting modules--compromising their simplicity and integrity--or add new\nmodules that lead to performance penalties. (See [7] for a detailed discussion.)\nSolution 3: Implicit Invocation\nThe third solution uses a form of component integration based on shared data\nsimilar to the first solution. However, there are two important differences.\nFirst, the interface to the data is more abstract. Rather than exposing the\nstorage formats to the computing modules, data is accessed abstractly (for\nexample, as a list or a set). Second, computations are invoked implicitly as data\nis modified. Thus interaction is based on an active data model. For example,\nthe act of adding a new line to the line storage causes an event to be sent to the\nshift module. This allows it to produce circular shifts (in a separate abstract\nshared data store).\nThis in turn causes the alphabetizer to be implicitly\ninvoked so that it can alphabetize the lines.\nThis solution easily supports functional enhancements to the system:\nadditional modules can be attached to the system by registering them to be\ninvoked on data-changing events. Because data is accessed abstractly, it also\ninsulates computations from changes in data representation. Reuse is also\nsupported, since the implicitly invoked modules only rely on the existence of\ncertain externally triggered events.\nGarlan & Shaw: An Introduction to Software Architecture\n\nOutput\nMedium\nMaster Control\nInput\nOutput\nInput\nMedium\nLines\nCircular\nShift\nAlphabetizer\nLines\nSystem I/O\nSubprogram Call\nImplicit Invocation\nFigure 8: KWIC - Implicit Invocation Solution\nHowever, the solution suffers from the fact that it can be difficult to control\nthe order of processing of the implicitly invoked modules. Further, because\ninvocations are data driven, the most natural implementations of this kind of\ndecomposition tend to use more space than the previously considered\ndecompositions.\nSolution 4: Pipes and Filters\nThe fourth solution uses a pipeline solution. In this case there are four filters:\ninput, shift, alphabetize, and output. Each filter processes the data and sends it\nto the next filter. Control is distributed: each filter can run whenever it has\ndata on which to compute. Data sharing between filters is strictly limited to\nthat transmitted on pipes. (See Figure 9.)\nThis solution has several nice properties. First, it maintains the intuitive\nflow of processing. Second, it supports reuse, since each filter can function in\nisolation (provided upstream filters produce data in the form it expects). New\nfunctions are easily added to the system by inserting filters at the appropriate\npoint in the processing sequence. Third, it supports ease of modification, since\nfilters are logically independent of other filters.\nInput\nInput\nMedium\nCircular\nShift\nPipe\nSystem I/O\nOutput\nOutput\nMedium\nAlphabetizer\nFigure 9: KWIC - Pipe and Filter Solution\nGarlan & Shaw: An Introduction to Software Architecture\n\nOn the other hand it has a number of drawbacks. First, it is virtually\nimpossible to modify the design to support an interactive system. For example,\nin order to delete a line, there would have to be some persistent shared storage,\nviolating a basic tenet of this approach. Second, the solution is inefficient in\nterms of its use of space, since each filter must copy all of the data to its output\nports.\nComparisons\nThe solutions can be compared by tabulating their ability to address the design\nconsiderations itemized earlier. A detailed comparison would have to involve\nconsideration of a number of factors concerning the intended use of the\nsystem: for example, is it batch or interactive, update-intensive or query-\nintensive, etc.\nFigure 10 provides an approximation to such an analysis, based on the\ndiscussion of architectural styles introduced earlier. As Parnas pointed out, the\nshared data solution is particularly weak in its support for changes in the\noverall processing algorithm, data representations, and reuse. On the other\nhand it can achieve relatively good performance, by virtue of direct sharing of\ndata. Further, it is relatively easy to add a new processing component (also\naccessing the shared data). The abstract data type solution allows changes to\ndata representation and supports reuse, without necessarily compromising\nperformance. However, the interactions between components in that solution\nare wired into the modules themselves, so changing the overall processing\nalgorithm or adding new functions may involve a large number of changes to\nthe existing system.\nShared\nMemory\nADT\nEvents\nDataflow\nChange in Algorithm\n_\n_\n+\n+\nChange in Data Repn\n_\n+\n_\n_\nChange in Function\n+\n_\n+\n+\nPerformance\n+\n+\n_\n_\nReuse\n_\n+\n_\n+\nFigure 10: KWIC - Comparison of Solutions\nThe implicit invocation solution is particularly good for adding new\nfunctionality. However, it suffers from some of the problems of the shared\ndata approach: poor support for change in data representation and reuse.\nMoreover, it may introduce extra execution overhead. The pipe and filter\nsolution allows new filters to be placed in the stream of text processing.\nTherefore it supports changes in processing algorithm, changes in function,\nGarlan & Shaw: An Introduction to Software Architecture\n\nand reuse. On the other hand, decisions about data representation will be\nwired into the assumptions about the kind of data that is transmitted along the\npipes. Further, depending on the exchange format, there may be additional\noverhead involved in parsing and unparsing the data onto pipes.\n4.2.\nCase Study 2: Instrumentation Software\nOur second case study describes the industrial development of a software\narchitecture at Tektronix, Inc. This work was carried out as a collaborative\neffort between several\nTektronix product divisions and the Computer\nResearch Laboratory over a three year period [6].\nThe purpose of the project was to develop a reusable system architecture\nfor oscilloscopes. An oscilloscope is an instrumentation system that samples\nelectrical signals and displays pictures (called traces) of them on a screen.\nAdditionally, oscilloscopes perform measurements on the signals, and also\ndisplay these on the screen. While oscilloscopes were once simple analogue\ndevices\ninvolving little software, modern oscilloscopes rely primarily on\ndigital technology and have quite complex software. It is not uncommon for a\nmodern oscilloscope to perform dozens of measurements, supply megabytes of\ninternal storage, interface to a network of workstations and other instruments,\nand provide sophisticated user interface including a touch panel screen with\nmenus, built-in help facilities, and color displays.\nLike many companies that have had to rely increasingly on software to\nsupport their products, Tektronix was faced with number of problems. First,\nthere was little reuse across different oscilloscope products. Instead, different\noscilloscopes were built by different product divisions, each with their own\ndevelopment conventions, software organization, programming language, and\ndevelopment tools. Moreover, even within a single product division, each\nnew oscilloscope typically required a redesign from scratch to accommodate\nchanges in hardware capability and new requirements on the user interface.\nThis problem was compounded by the fact that both hardware and interface\nrequirements were changing increasingly rapidly. Furthermore, there was a\nperceived need to address \"specialized markets\". To do this it would have to\nbe possible to tailor a general-purpose instrument, to a specific set of uses.\nSecond, there were increasing performance problems because the software\nwas not rapidly configurable within the instrument.\nThis problem arises\nbecause an oscilloscope can be configured in many different modes, depending\non the user's task. In old oscilloscopes reconfiguration was handled simply by\nloading different software to handle the new mode. But as the total size of\nsoftware was increasing, this was leading to delays between a user's request for\na new mode and a reconfigured instrument.\nThe goal of the project was to develop an architectural framework for\noscilloscopes that would address these problems. The result of that work was a\ndomain-specific software architecture that formed the basis of the next\nGarlan & Shaw: An Introduction to Software Architecture\n\n---\ngeneration of Tektronix oscilloscopes. Since then the framework has been\nextended and adapted to accommodate a broader class of system, while at the\nsame time being better adapted to the specific needs of instrumentation\nsoftware.\nIn the remainder of this section, we outline the stages in this architectural\ndevelopment.\nAn object-oriented model\nThe first attempt at developing a reusable architecture focused on producing an\nobject-oriented model of the software domain. This led to a clarification of the\ndata types used in oscilloscopes: waveforms, signals, measurements, trigger\nmodes, etc. (See Figure 11.)\nOscilloscope\nobject\nwaveform\nx-y wvfm\naccumulate wvfm\nmax-min wvfm\nFigure 11: Oscilloscopes - An Object-oriented Model\nWhile this was a useful exercise, it fell far short of producing the hoped-for\nresults. Although many types of data were identified, there was no overall\nmodel that explained how the types fit together. This led to confusion about\nthe partitioning of functionality.\nFor example, should measurements be\nassociated with the types of data being measured, or represented externally?\nWhich objects should the user interface talk to?\nA layered model\nThe second phase attempted to correct these problems by providing a layered\nmodel of an oscilloscope.\n(See Figure 11.)\nIn this model the core layer\nrepresented the signal manipulation functions that filter signals as they enter\nthe oscilloscope. These functions are typically implemented in hardware. The\nnext layer represented waveform acquisition. Within this layer signals are\ndigitized and stored internally for later processing. The third layer consisted of\nwaveform manipulation, including measurement, waveform addition,\nFourier transformation, etc. The fourth layer consisted of display functions.\nThis layer was responsible for mapping digitized waveforms and\nmeasurements to visual representations. The outermost layer was the user\ninterface. This layer was responsible for interacting with the user and for\ndeciding which data should be shown on the screen. (See Figure 12.)\nGarlan & Shaw: An Introduction to Software Architecture\n\nHardware\nDigitization\nVisualization\nUser interface\nFigure 12: Oscilloscopes - A Layered Model\nThis layered model was intuitively appealing since it partitioned the\nfunctions of an oscilloscope into well-defined groupings. Unfortunately it was\nthe wrong model for the application domain. The main problem was that the\nboundaries of abstraction enforced by the layers conflicted with the needs for\ninteraction between the various functions. For example, the model suggests\nthat all user interactions with an oscilloscope should be in terms of the visual\nrepresentations. But in practice real oscilloscope users need to directly affect\nthe functions in all layers, such as setting attenuation in the signal\nmanipulation layer, choosing acquisition mode and parameters in the\nacquisition layer, or creating derived waveforms in the waveform\nmanipulation layer.\nA Pipe and Filter Model\nThe third attempt yielded a model in which oscilloscope functions were\nviewed as incremental transformers of data. Signal transformers serve to\ncondition external signals. Acquisition transformers derive digitized\nwaveforms from these signals. Display transformers convert these waveforms\ninto visual data. (See Figure 13.)\nTrigger subsystem\nCouple\nAcquire\nTo-XY\nClip\nMeasure\nSignal\nWaveform\nTrace\nMeasurement\nTimes\nFigure 13: Oscilloscopes - A Pipe and Filter Model\nThis architectural model was a significant improvement over the layered\nmodel in that it did not isolate the functions in separate partitions.\nFor\nexample, nothing in this model would prevent signal data directly feeding into\ndisplay filters. Further, the model corresponded well to the engineers' view of\nsignal processing as a dataflow problem. The main problem with the model\nwas that it was not clear how the user should interact with it. If the user were\nsimply at one end of the system, then this would represent an even worse\ndecomposition than the layered system.\nGarlan & Shaw: An Introduction to Software Architecture\n\nA Modified Pipe and Filter Model\nThe fourth solution accounted for user inputs by associating with each filter a\ncontrol interface that allows an external entity to set parameters of operation\nfor the filter. For example, the acquisition filter might have parameters that\ndetermine sample rate and waveform duration.\nThese inputs serve as\nconfiguration parameters for the oscilloscope. Formally, the filters can be\nmodelled as \"higher-order\" functions, for which the configuration parameters\ndetermine what data transformation the filter will perform. (See [17] for this\ninterpretation of the architecture.) Figure 14 illustrates this architecture.\nCouple\nAcquire\nClip\nTo-XY\nMeasure\nSignal\nWaveform\nTrace\nMeasurement\nTimes\nCoupling\nKind,Rate\nTrans\nSize\nTrigger subsystem\nFigure 14: Oscilloscopes - A Modified Pipe and Filter Model\nThe introduction of a control interface solves a large part of the user\ninterface problem. First, it provides a collection of settings that determine\nwhat aspects of the oscilloscope can be modified dynamically by the user. It\nalso explains how changes to oscilloscope function can be accomplished by\nincremental adjustments to the software.\nSecond it decouples the signal\nprocessing functions of the oscilloscope from the actual user interface: the\nsignal processing software makes no assumptions about how the user actually\ncommunicates changes to its control parameters. Conversely, the actual user\ninterface can treat the signal processing functions solely in terms of the control\nparameters. This allowed the designers to change the implementation of the\nsignal processing software and hardware without impacting an interface,\nprovided the control interface remained unchanged.\nFurther Specialization\nThe adapted pipe and filter model was a great improvement. But it, too, had\nsome problems. The most significant problem was that the pipe and filter\ncomputational model led to poor performance. In particular, waveforms can\noccupy a large amount of internal storage: it is simply not practical for each\nfilter to copy waveforms every time they process them. Further, different\nfilters may run at radically different speeds: it is unacceptable to slow one filter\ndown because another filter is still processing its data.\nTo handle these problems the model was further specialized. Instead of\nhaving a single kind of pipe, several \"colors\" of pipes were introduced. Some\nof these allowed data to be processed without copying. Others permitted data to\nbe ignored by slow filters if they were in the middle of processing other data.\nThese additional pipes increased the stylistic vocabulary and allowed the\nGarlan & Shaw: An Introduction to Software Architecture\n\npipe/filter computations to be tailored more directly to the performance needs\nof the product.\nSummary\nThis case study illustrates the issues involved in developing an architectural\nstyle for a real application domain. It underscores the fact that different\narchitectural styles have different effects on the ability to solve a set of\nproblems. Moreover, it illustrates that architectural designs for industrial\nsoftware must typically be adapted from pure forms to specialized styles that\nmeet the needs of the specific domain. In this case, the final result depended\ngreatly on the properties of pipe and filter architectures, but found ways to\nadapt that generic style so that it could also satisfy the performance needs of the\nproduct family.\n4.3.\nCase 3: A Fresh View of Compilers\nThe architecture of a system can change in response to improvements in\ntechnology. This can be seen in the way we think about compilers.\nIn the 1970s, compilation was regarded as a sequential process, and the\norganization of a compiler was typically drawn as in Figure 15. Text enters at\nthe left end and is transformed in a variety of ways--to lexical token stream,\nparse tree, intermediate code--before emerging as machine code on the right.\nWe often refer to this compilation model as a pipeline, even though it was (at\nleast originally) closer to a batch sequential architecture in which each\ntransformation (\"pass\") was completed before the next one started.\nLex\nSyn\nSem\nOpt\nCode\nText\nCode\nFigure 15: Traditional Compiler Model\nIn fact, even the batch sequential version of this model was not completely\naccurate. Most compilers created a separate symbol table during lexical analysis\nand used or updated it during subsequent passes. It was not part of the data\nthat flowed from one pass to another but rather existed outside all the passes.\nSo the system structure was more properly drawn as in Figure 16.\nSymTab\nLex\nSyn\nSem\nOpt\nCode\nText\nCode\nFigure 16: Traditional Compiler Model with Shared Symbol Table\nAs time passed, compiler technology grew more sophisticated.\nThe\nalgorithms and representations of compilation grew more complex, and\nincreasing attention turned to the intermediate representation of the program\nGarlan & Shaw: An Introduction to Software Architecture\n\nduring compilation. Improved theoretical understanding, such as attribute\ngrammers, accelerated this trend. The consequence was that by the mid-1980s\nthe intermediate representation (for example, an attributed parse tree), was the\ncenter of attention. It was created early during compilation and manipulated\nduring the remainder; the data structure might change in detail, but it\nremained substantially one growing structure throughout.\nHowever, we\ncontinued (sometimes to the present) to model the compiler with sequential\ndata flow as in Figure 17.\nLex\nSyn\nSem\nOpt\nCode\nSymTab\nTree\nText\nCode\nComputations\n(transducers and\ntransforms)\nMemory\nData fetch/store\nVestigal data flow\nFigure 17: Modern Canonical Compiler\nIn fact, a more appropriate view of this structure would re-direct attention\nfrom the sequence of passes to the central shared representation. When you\ndeclare that the tree is the locus of compilation information and the passes\ndefine operations on the tree, it becomes natural to re-draw the architecture as\nin Figure 18. Now the connections between passes denote control flow, which\nis a more accurate depiction; the rather stronger connections between the\npasses and the tree/symbol table structure denote data access and\nmanipulation. In this fashion, the architecture has become a repository, and\nthat is indeed a more appropriate way to think about a compiler of this class.\nHappily, this new view also accommodates various tools that operate on\nthe internal representation rather than the textual form of a program; these\ninclude syntax-directed editors and various analysis tools.\nS ym T a b\nTree\nLex\nSyn\nSem\nOpt2\nCode\nEdit\nSyn\nMig\ne\nrule-based\nOpt1\nht b\nFigure 18: Canonical Compiler, Revisited\nGarlan & Shaw: An Introduction to Software Architecture\n\nNote that this repository resembles a blackboard in some respects and\ndiffers in others. Like a blackboard, the information of the computation is\nlocated centrally and operated on by independent computations which interact\nonly through the shared data. However, whereas the execution order of the\noperations in a blackboard is determined by the types of the incoming database\nmodifications, the execution order of the compiler is predetermined.\n4.4.\nCase 4: A Layered Design with Different Styles for the Layers\nThe PROVOX(r) system by Fisher Controls offers distributed process control for\nchemical production processes [43]. Process control capabilities range from\nsimple control loops that control pressure, flow, or levels to complex strategies\ninvolving interrelated control loops. Provisions are made for integration with\nplant management and information systems in support of computer integrated\nmanufacturing. The system architecture integrates process control with plant\nmanagement and information systems in a 5-level layered hierarchy. Figure\n19 shows this hierarchy: the right side is the software view, and the left side is\nthe hardware view.\nPROVOXplus Controllers\nPROVUE Consoles\nENVOX Configuration\nPROVOXplus\nApplication Software\nCorp\nComputers\nInterface to\nHost Computers\nProcess Measurement\nand Control\nProcess\nSupervision\nProcess\nManagement\nCorp\nMgmt.\nPlant\nManagement\nLevel 5\nLevel 4\nLevel 3\nLevel 2\nLevel 1\nSoftware\nFigure 19: PROVOX - Hierarchical Top Level\nEach level corresponds to a different process management function with its\nown decision-support requirements.\n- Level 1: Process measurement and control: direct adjustment of final\ncontrol elements.\n- Level 2: Process supervision: operations console for monitoring and\ncontrolling Level 1.\nGarlan & Shaw: An Introduction to Software Architecture\n\nDATA\nACTION\nSERVICES\nOPERATING\nTUNING\nCONFIGURATION\nALGORITHM\nNAME(S)\nTEMPLATE\nDATA\nACTION\nSERVICES\nOPERATING\nTUNING\nCONFIGURATION\nALGORITHM\nNAME(S)\nTEMPLATE\nDATA\nACTION\nSERVICES\nOPERATING\nTUNING\nCONFIGURATION\nALGORITHM\nNAME(S)\nTEMPLATE\n- Level 3:\nProcess management: computer-based plant automation,\nincluding management reports, optimization strategies, and guidance to\noperations console.\n- Levels 4 and 5:\nPlant and corporate management:\nhigher-level\nfunctions such as cost accounting, inventory control, and order\nprocessing/scheduling.\nDifferent kinds of computation and response times are required at different\nlevels of this hierarchy. Accordingly, different computational models are used.\nLevels 1 to 3 are object-oriented; Levels 4 and 5 are largely based on\nconventional data-processing repository models.\nFor present purposes it\nsuffices to examine the object-oriented model of Level 2 and the repositories of\nLevels 4 and 5.\nTAG\nTAG\nTAG\nTAG\nDATA\nACTION\nSERVICES\nOPERATING\nTUNING\nCONFIGURATION\nCOMMUNICATION\nTRACE\nALARMS\nETC\nALGORITHM\nNAME(S)\nTEMPLATE\nFigure 20: PROVOX - Object-oriented Elaboration\nFor the control and monitoring functions of Level 2, PROVOX uses a set of\npoints, or loci of process control. Figure 20 shows the canonical form of a point\ndefinition; seven specialized forms support the most common kinds of\ncontrol.\nPoints are, in essence, object-oriented design elements that\nencapsulate information about control points of the process. The points are\nindividually configured to achieve the desired control strategy. Data associated\nwith a point includes: Operating parameters, including current process value,\nsetpoint (target value), valve output, and mode (automatic or manual).\nTuning parameters, such as gain, reset, derivative, and alarm trip-points.\nConfiguration parameters, including tag (name) and I/O channels.\nIn addition, the point's data can include a template for a control strategy.\nLike any good object, a point also includes procedural definitions such as\ncontrol algorithms, communication connections, reporting services, and trace\nfacilities.\nA collection of points implements the desired process control\nstrategy through the communication services and through the actual dynamics\nGarlan & Shaw: An Introduction to Software Architecture\n\nof the process (e.g., if one point increases flow into a tank, the current value of\na point that senses tank level will reflect this change).\nAlthough the\ncommunication through process state deviates from the usual procedural or\nmessage-based control of objects, points are conceptually very like objects in\ntheir encapsulation of essential state and action information.\nReports from points appear as input transactions to data collection and\nanalysis processes at higher design levels. The organization of the points into\ncontrol processes can be defined by the designer to match the process control\nstrategy. These can be further aggregated into Plant Process Areas (points\nrelated to a set of equipment such as a cooling tower) and thence into Plant\nManagement Areas (segments of a plant that would be controlled by single\noperators).\nPROVOX makes provisions for integration with plant management and\nbusiness systems at Levels 4 and 5.\nSelection of those systems is often\nindependent of process control design; PROVOX does not itself provide MIS\nsystems directly but does provide for integrating a conventional host computer\nwith conventional database management.\nThe data collection facilities of\nLevel 3, the reporting facilities of Level 2, and the network that supports\ndistributed implementation suffice to provide process information as\ntransactions to these databases. Such databases are commonly designed as\nrepositories, with transaction processing functions supporting a central data\nstore---quite a different style from the object-oriented design of Level 2.\nThe use of hierarchical layers at the top level of a system is fairly common.\nThis permits strong separation of different classes of function and clean\ninterfaces between the layers. However, within each layer the interactions\namong components are often too intricate to permit strict layering.\n4.5.\nCase 5: An Interpreter Using Different Idioms for the Components\nRule-based systems provide a means of codifying the problem-solving know\nhow of human experts.\nThese experts tend to capture problem-solving\ntechniques as sets of situation-action rules whose execution or activation is\nsequenced in response to the conditions of the computation rather than by a\npredetermined scheme.\nSince these rules are not directly executable by\navailable computers, systems for interpreting such rules must be provided.\nHayes-Roth surveyed the architecture and operation of rule-based systems [44].\nThe basic features of a rule-based system, shown in Hayes-Roth's rendering\nas Figure 21, are essentially the features of a table-driven interpreter, as\noutlined earlier.\n- The pseudo-code to be executed, in this case the knowledge base\n- The interpretation engine, in this case the rule interpreter, the heart of\nthe inference engine\nGarlan & Shaw: An Introduction to Software Architecture\n\n- The control state of the interpretation engine, in this case the rule and\ndata element selector\n- The current state of the program running on the virtual machine, in\nthis case the working memory.\nRule\nBase\nFact\nMemory\nKnowledge Base\nWorking\nMemory\nInputs\nOutputs\nSelected data\nSelected rule\nRule\nInterpreter\nRule and\nData Element\nSelection\nMemory\nComputation\nstate mach\nFigure 21: Basic Rule-Based System\nRule-based systems make heavy use of pattern matching and context\n(currently relevant rules). Adding special mechanisms for these facilities to\nthe design leads to the more complicated view shown in Figure 22. In adding\nthis complexity, the original simple interpreter vanishes in a sea of new\ninteractions and data flows.\nAlthough the interfaces among the original\nmodules remain, they are not distinguished from the newly-added interfaces.\nHowever, the interpreter model can be rediscovered by identifying the\ncomponents of Figure 22 with their design antecedents in Figure 21. This is\ndone in Figure 23. Viewed in this way, the elaboration of the design becomes\nmuch easier to explain and understand. For example, we see that:\n- The knowledge base remains a relatively simple memory structure,\nmerely gaining substructure to distinguish active from inactive\ncontents.\n- The rule interpreter is expanded with the interpreter idiom (that is, the\ninterpretation engine of the rule-based system is itself implemented as a\ntable-driven interpreter), with control procedures playing the role of the\npseudo-code to be executed and the execution stack the role of the\ncurrent program state.\n- \"Rule and data element selection\" is implemented primarily as a\npipeline that progressively transforms active rules and facts to\nprioritized activations; in this pipeline the third filter (\"nominators\")\nalso uses a fixed database of metarules.\n- Working memory is not further elaborated.\nGarlan & Shaw: An Introduction to Software Architecture\n\nRule Memory\n\nFact Memory\nInactive\nInactive\nMulti-\nTriggering\nActivation/\nrules\nfacts\ndimensional\ndata\ndeactivation\nInputs\nworking\nmemory\nActive\nActive\nrules\nfacts\nOutputs\nActive\nrules\nand\nfacts\nData\nUpdates\nRule and\nfact\ncompiler\nRule\nantecedent\nsubexpressions\nUnfinished\nData-flow\nactions\nnetwork\nby partially\nExecution\nstack\nInterpreter\nevaluated\nrule activations\nNext action\nDelete\ncompleted\nactivations\nMatching\nSelected\n<rule, data>\naction\npairs\nIncomplete\nprocedures\nPrioritized\nCandidate\nRule and\nactivations\nAgenda\n<rule, data>\nfact\nControl\nScheduler\nactivations\ncompiler\nprocedures\nPreferences\nand\npriorities\nMetarules\nFigure 23: Sophisticated Rule-Based System\nThe interfaces among the rediscovered components are unchanged from\nthe simple model except for the two bold lines over which the interpreter\ncontrols activations.\nThis example illustrates two points. First, in a sophisticated rule-based\nsystem the elements of the simple rule-based system are elaborated in response\nto execution characteristics of the particular class of languages being\ninterpreted. If the design is presented in this way, the original concept is\nretained to guide understanding and later maintenance. Second, as the design\nis elaborated, different components of the simple model can be elaborated with\ndifferent idioms.\nGarlan & Shaw: An Introduction to Software Architecture\n\nKnowledge\nBase\nWorking\nMemory\nRule Memory\nFact Memory\nInactive\nInactive\nMulti-\nTriggering\nActivation/\nrules\nfacts\ndeactivation\ndimensional\ndata\nInputs\nworking\nmemory\nActive\nActive\nrules\nfacts\nOutputs\nActive\nrules\nand\nfacts\nData\nUpdates\nRule and\nfact\ncompiler\nRule\nantecedent\nsubexpressions\nUnfinished\nData-flow\nactions\nnetwork\nby partially\nExecution\nstack\nInterpreter\nevaluated\nNext action\nrule activations\nDelete\ncompleted\nactivations\nMatching\nSelected\n<rule, data>\naction\npairs\nIncomplete\nprocedures\nPrioritized\nCandidate\nRule and\nactivations\nControl\nScheduler\nAgenda\n<rule, data>\nfact\nactivations\ncompiler\nprocedures\nPreferences\nand\npriorities\nRule Interpreter\nRule and data\nMetarules\nelement\nselection\nFigure 23: Simplified Sophisticated Rule-Based System\nNote that the rule-based model is itself a design structure: it calls for a set of\nrules whose control relations are determined during execution by the state of\nthe computation. A rule-based system provides a virtual machine--a rule\nexecutor--to support this model.\n4.6.\nCase 6: A Blackboard Globally Recast as Interpreter\nThe blackboard model of problem solving is a highly structured special case of\nopportunistic problem solving. In this model, the solution space is organized\ninto several application-dependent hierarchies and the domain knowledge is\nGarlan & Shaw: An Introduction to Software Architecture\n\nLevel n\npartitioned into independent modules of knowledge that operate on\nknowledge within and between levels [34].\nFigure 4 showed the basic\narchitecture of a blackboard system and outlined its three major parts:\nknowledge sources, the blackboard data structure, and control.\nKnowledge Sources\nLevel n\nCondition\nAction\nCondition\nBlackboard\nMonitor\nScheduling\nQueue\nFocus of\nControl\nDatabase\nScheduler\nBlackboard\nBlackboard\nChange\nCondition Part\nLevel 3\nLevel 2\nLevel 1\nAction\nCondition\nAction\nStimulus\nResponse Frame\n(\nControl flow-----Data flow)\nFigure 24: Hearsay-II\nThe first major blackboard system was the HEARSAY-II speech recognition\nsystem. Nii's schematic of the HEARSAY-II architecture appears as Figure 24.\nThe blackboard structure is a six- to eight-level hierarchy in which each level\nabstracts information on its adjacent lower level and blackboard elements rep\nresent hypotheses about the interpretation of an utterance. Knowledge sources\ncorrespond to such tasks as segmenting the raw signal, identifying phonemes,\ngenerating word candidates, hypothesizing syntactic segments, and proposing\nsemantic interpretations. Each knowledge source is organized as a condition\npart that specifies when it is applicable and an action part that processes\nrelevant blackboard elements and generates new ones. The control component\nis realized as a blackboard monitor and a scheduler; the scheduler monitors the\nblackboard and calculates priorities for applying the knowledge sources to\nvarious elements on the blackboard.\nHEARSAY-II was implemented between 1971 and 1976 on DEC PDP-10s;\nthese machines were not directly capable of condition-triggered control, so it\nshould not be surprising to find that an implementation provides the\nmechanisms of a virtual machine that realizes the implicit invocation\nsemantics required by the blackboard model.\nGarlan & Shaw: An Introduction to Software Architecture\n\nLevel n\nBlackboard\nLevel n\nCondition\nAction\nCondition\nBlackboard\nMonitor\nScheduling\nQueue\nFocus of\nControl\nDatabase\nScheduler\nBlackboard\nKnowledge Sources\nBlackboard\nChange\nCondition Part\nLevel 3\nLevel 2\nLevel 1\nAction\nCondition\nAction\nStimulus\nResponse Frame\nNot\nrelevant to\nblackboard\nmodel\nKS\nKS\nKS\n(\nControl flow-----Data flow)\nFigure 25: Blackboard View of Hearsay-II\nFigure 24 not only elaborates the individual components of Figure 4; it also\nadds components for the previously-implicit control component.\nIn the\nprocess, the figure becomes rather complex. This complexity arises because it is\nnow illustrating two concepts: the blackboard model and realization of that\nmodel by a virtual machine. The blackboard model can be recovered as in\nFigure 25 by suppressing the control mechanism and regrouping the\nconditions and actions into knowledge sources.\nThe virtual machine can be seen to be realized by an interpreter using the\nassignment of function in Figure 26. Here the blackboard cleanly corresponds\nto the current state of the recognition task.\nThe collection of knowledge\nsources roughly supplies the pseudocode of the interpreter; however, the\nactions also contribute to the interpretation engine. The interpretation engine\nincludes several components that appear explicitly in Figure 24: the blackboard\nmonitor, the focus of control database, and the scheduler, but also the actions\nof the knowledge sources. The scheduling queue corresponds roughly to the\ncontrol state. To the extent that execution of conditions determines priorities,\nthe conditions contribute to rule selection as well as forming pseudocode.\nHere we see a system initially designed with one model (blackboard, a\nspecial form of repository), then realized through a different model\n(interpreter). The realization is not a component-by-component expansion as\nGarlan & Shaw: An Introduction to Software Architecture\n\nLevel n\nin the previous two examples; the view as an interpreter is a different\naggregation of components from the view as blackboard.\nProgram State\nPseudo-Code\n(Working Meomory)\n(Knowledge Base)\nLevel n\nCondition\nAction\nCondition\nBlackboard\nMonitor\nScheduling\nQueue\nFocus of\nControl\nDatabase\nScheduler\nBlackboard\nKnowledge Sources\nBlackboard\nChange\nCondition Part\nLevel 3\nLevel 2\nLevel 1\nAction\nCondition\nAction\nStimulus\nResponse Frame\nInterpretation\nEngine\nNote: Actions are also part of\ninterpretation engine\nControl\nState\n(\nControl flow-----Data flow)\nFigure 26: Interpreter View of Hearsay-II\n5.\nPast, Present, and Future\nWe have outlined a number of architectural styles and shown how they can be\napplied and adapted to specific software systems. We hope that this has\nconvinced the reader that analysis and design of systems in terms of software\narchitecture is both viable and worth doing. Further we hope to have made it\nclear that an understanding of the emerging vocabulary of architectural styles\nis a significant--if not necessary--intellectual tool for the software engineer.\nThere is, of course, much more to software architecture than we have had\nspace to cover. In particular, we have said very little about existing results in\nthe areas of analysis, formal specification, domain-specific architectures,\nmodule interconnection languages, and special-architecture tools.\nThis is not to say that more work isn't needed. Indeed, we can expect to see\nsignificant advances in a number of areas including:\n- Better taxonomies of architectures and architectural styles.\nGarlan & Shaw: An Introduction to Software Architecture\n\n- Formal models for characterizing and analyzing architectures.\n- Better understanding of the primitive semantic entities from which\nthese styles are composed.\n- Notations for describing architectural designs.\n- Tools and environments for developing architectural designs.\n- Techniques for extracting architectural information from existing code.\n- Better understanding of the role of architectures in the life-cycle process.\nThese are all areas of active research both in industry and academia. Given\nthe increasing interest in this emerging field, we can expect that our\nunderstanding of the principles and practice of software architecture will\nimprove considerably over time. However, as we have illustrated, even with\nthe basic concepts that we now have in hand, design at the level of software\narchitecture can provide direct and substantial benefit to the practice of\nsoftware engineering.\nAcknowledgements\nWe gratefully acknowledge our many colleagues who have contributed to\nthe ideas presented in this paper. In particular, we would like to thank Chris\nOkasaki, Curtis Scott, and Roy Swonger for their help in developing the course\nfrom which much of this material was drawn. We thank David Notkin, Kevin\nSullivan, and Gail Kaiser for their contribution towards understanding event-\nbased systems. Rob Allen helped develop a rigorous understanding of the pipe\nand filter style. We would like to acknowledge the oscilloscope development\nteam at Tektronix, and especially Norm Delisle, for their part in demonstrating\nthe value of domain-specific architectural styles in an industrial context.\nFinally, we would like to thank Barry Boehm, Larry Druffel, and Dilip Soni for\ntheir constructive comments on early drafts of the paper.\nBibliography\n[1] D. Garlan, M. Shaw, C. Okasaki, C. Scott, and R. Swonger, \"Experience\nwith a course on architectures for software systems,\" in Proceedings of the Sixth SEI\nConference on Software Engineering Education, Springer-Verlag, LNCS 376, October 1992.\n[2] M. Shaw, \"Toward higher-level abstractions for software systems,\" in Data & Knowledge\nEngineering, vol. 5, pp. 119-128, North Holland: Elsevier Science Publishers B.V., 1990.\n[3] M. Shaw, \"Heterogeneous design idioms for software architecture,\" in Proceedings of the\nSixth International Workshop on Software Specification and Design, IEEE Computer\nSociety, Software Engineering Notes, (Como, Italy), pp. 158-165, October 25-26, 1991.\n[4] M. Shaw, \"Software architectures for shared information systems,\" in Mind Matters:\nContributions to Cognitive and Computer Science in Honor of Allen Newell, Erlbaum, 1993.\n[5] R. Allen and D. Garlan, \"A formal approach to software architectures,\" in Proceedings of\nIFIP'92 (J. van Leeuwen, ed.), Elsevier Science Publishers B.V., September 1992.\nGarlan & Shaw: An Introduction to Software Architecture\n\n[6] D. Garlan and D. Notkin, \"Formalizing design spaces: Implicit invocation mechanisms,\" in\nVDM'91: Formal Software Development Methods. (Noordwijkerhout, The Netherlands),\npp. 31-44, Springer-Verlag, LNCS 551, October 1991.\n[7] D. Garlan, G. E. Kaiser, and D. Notkin, \"Using tool abstraction to compose systems,\" IEEE\nComputer, vol. 25, June 1992.\n[8] A. Z. Spector et al., \"Camelot: A distributed transaction facility for Mach and the Internet\nan interim report,\" Tech. Rep. CMU-CS-87-129, Carnegie Mellon University, June 1987.\n[9] M. Fridrich and W. Older, \"Helix: The architecture of the XMS distributed file system,\"\nIEEE Software, vol. 2, pp. 21-29, May 1985.\n[10] M. A. Linton, \"Distributed management of a software database,\" IEEE Software, vol. 4, pp.\n70-76, November 1987.\n[11] V. Seshadri et al., \"Sematic analysis in a concurrent compiler,\" in Proceedings of ACM\nSIGPLAN '88 Conference on Programming Language Design and Implementation, ACM\nSIGPLAN Notices, 1988.\n[12] M. C. Paulk, \"The ARC Network: A case study,\" IEEE Software, vol. 2, pp. 61-69, May 1985.\n[13] M. Chen and R. J. Norman, \"A framework for integrated case,\" IEEE Software, vol. 9, pp. 18\n22, March 1992.\n[14] NIST/ECMA reference model for frameworks of software engineering environments.\" NIST\nSpecial Publication 500-201, December 1991.\n[15] R. W. Scheifler and J. Gettys, \"The X window system,\" AACM Transactions on Graphics, vol.\n5, pp. 79-109, April 1986.\n[16] M. J. Bach, The Design of the UNIX Operating System, ch. 5.12, pp. 111-119. Software\nSeries, Prentice-Hall, 1986.\n[17] N. Delisle and D. Garlan, \"Applying formal specification to industrial problems: A\nspecification of an oscilloscope,\" IEEE Software, September 1990.\n[18] G. Kahn, \"The semantics of a simple language for parallel programming,\" Information\nProcessing, 1974.\n[19] M. R. Barbacci, C. B. Weinstock, and J. M. Wing, \"Programming at the processor-memory-\nswitch level,\" in Proceedings of the 10th International Conference on Software Engineering,\n(Singapore), pp. 19-28, IEEE Computer Society Press, April 1988.\n[20] G. E. Kaiser and D. Garlan, \"Synthesizing programming environments from reusable\nfeatures,\" in Software Reusability (T. J. Biggerstaff and A. J. Perlis, eds.), vol. 2, ACM Press,\n1989.\n[21] W. Harrison, \"RPDE: A framework for integrating tool fragments,\" IEEE Software, vol. 4,\nNovember 1987.\n[22] C. Hewitt, \"Planner: A language for proving theorems in robots,\" in Proceedings of the First\nInternational Joint Conference in Artificial Intelligence, 1969.\n[23] S. P. Reiss, \"Connecting tools using message passing in the field program development\nenvironment,\" IEEE Software, July 1990.\n[24] C. Gerety, \"HP Softbench: A new generation of software development tools,\" Tech. Rep.\nSESD-89-25, Hewlett-Packard Software Engineering Systems Division, Fort Collins,\nColorado, November 1989.\n[25] R. M. Balzer, \"Living with the next generation operating system,\" in Proceedings of the 4th\nWorld Computer Conference, September 1986.\nGarlan & Shaw: An Introduction to Software Architecture\n\n[26] G. Krasner and S. Pope, \"A cookbook for using the model-view-controller user interface\nparadigm in Smalltalk-80,\" Journal of Object Oriented Programming, vol. 1, pp. 26-49,\nAugust/September 1988.\n[27] M. Shaw, E. Borison, M. Horowitz, T. Lane, D. Nichols, and R. Pausch, \"Descartes: A\nprogramming-language approach to interactive display interfaces,\" Proceedings of\nSIGPLAN '83:\nSymposium on Programming Language Issues in Software Systems, ACM\nSIGPLAN Notices, vol. 18, pp. 100-111, June 1983.\n[28] A. N. Habermann and D. S. Notkin, \"Gandalf: Software development environments,\" IEEE\nTransactions on Software Engineering, vol. SE-12, pp. 1117-1127, December 1986.\n[29] A. N. Habermann, D. Garlan, and D. Notkin, \"Generation of integrated task-specific\nsoftware environments,\" in CMU Computer Science: A 25th Commemorative (R. F. Rashid,\ned.), Anthology Series, pp. 69-98, ACM Press, 1991.\n[30] K. Sullivan and D. Notkin, \"Reconciling environment integration and component\nindependence,\" in Proceedings of ACM SIGSOFT90:\nFourth Symposium on Software\nDevelopment Environments, pp. 22-23, December 1990.\n[31] G. R. McClain, ed., Open Systems Interconnection Handbook. New York, NY: Intertext\nPublications McGraw-Hill Book Company, 1991.\n[32] D. Batory and S. O'Malley, \"The design and implementation of hierarchical software\nsystems using reusable components,\" Tech. Rep. TR-91-22, Department of Computer Science,\nUniversity of Texas, Austin, June 1991.\n[33] H. C. Lauer and E. H. Satterthwaite, \"Impact of MESA on system design,\" in Proceedings of\nthe Third International Conference on Software Engineering, (Atlanta, GA), pp. 174-175,\nIEEE Computer Society Press, May 1979.\n[34] H. P. Nii, \"Blackboard systems Parts 1 & 2,\" AI Magazine, vol. 7 nos 3 (pp. 38-53) and 4 (pp.\n62-69), 1986.\n[35] V. Ambriola, P. Ciancarini, and C. Montangero, \"Software process enactment in oikos,\" in\nProceedings of the Fourth ACM SIGSOFT Symposium on Software Development\nEnvironments, SIGSOFT Software Engineering Notes, (Irvine, CA), pp. 183-192, December\n1990.\n[36] D. R. Barstow, H. E. Shrobe, and E. Sandewall, eds., Interactive Programming Environments.\nMcGraw-Hill Book Co., 1984.\n[37] G. R. Andrews, \"Paradigms for process interaction in distributed programs,\" ACM Computing\nSurveys, vol. 23, pp. 49-90, March 1991.\n[38] A. Berson, Client/Server Architecture. McGraw-Hill, 1992.\n[39] E. Mettala and M. H. Graham, eds., The Domain-Specific Software Architecture Program.\nNo. CMU/SEI-92-SR-9, Carnegie Mellon Software Engineering Institute, June 1992.\n[40] D. Harel, \"Statecharts: A visual formalism for complex systems,\" Science of Computer\nProgramming, vol. 8, pp. 231-274, 1987.\n[41] K. J. Astrom and B. Wittenmark, Computer-Controlled Systems Design. Prentice Hall,\nsecond ed., 1990.\n[42] D. L. Parnas, \"On the criteria to be used in decomposing systems into modules,\"\nCommunications of the ACM, vol. 15, pp. 1053-1058, December 1972.\n[43] \"PROVOX plus Instrumentation System: System overview,\" 1989.\n[44] F. Hayes-Roth, 'Rule-based systems,\" Communications of the ACM, vol. 28, pp. 921-932,\nSeptember 1985.\nGarlan & Shaw: An Introduction to Software Architecture"
    },
    {
      "category": "Resource",
      "title": "jsr.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/364e4d0c757e93e44abbc89758f2e69c_jsr.pdf",
      "content": "The Role of Software in Spacecraft Accidents\n∗\nNancy G. Leveson\nAeronautics and Astronautics Department\nMassachusetts Institute of Technology\nAbstract: The first and most important step in solving any problem is understanding the\nproblem well enough to create effective solutions. To this end, several software-related space\ncraft accidents were studied to determine common systemic factors. Although the details in\neach accident were different, very similar factors related to flaws in the safety culture, the\nmanagement and organization, and technical deficiencies were identified. These factors include\ncomplacency and discounting of software risk, diffusion of responsibility and authority, limited\ncommunication channels and poor information flow, inadequate system and software engineer\ning (poor or missing specifications, unnecessary complexity and software functionality, software\nreuse without appropriate safety analysis, violation of basic safety engineering practices in the\ndigital components), inadequate review activities, ineffective system safety engineering, flawed\ntest and simulation environments, and inadequate human factors engineering. Each of these\nfactors is discussed along with some recommendations on how to eliminate them in future\nprojects.\nIntroduction\nSoftware is playing an increasingly important role in aerospace systems. Is it also playing an\nincreasing role in accidents and, if so, what type of role? In the process of a research project\nto evaluate accident models, I looked in detail at a variety of aerospace accidents that in some\nway involved software.1,2 Many of the factors were in common across several of the accidents.\nTo prevent accidents in the future, we need to attack these problems.\nThe spacecraft accidents investigated were the explosion of the Ariane 5 launcher on its\nmaiden flight in 1996; the loss of the Mars Climate Orbiter in 1999; the destruction of the\nMars Polar Lander sometime during the entry, deployment, and landing phase in the following\nyear; the placing of a Milstar satellite in an incorrect and unusable orbit by the Titan IV\nB-32/Centaur launch in 1999; and the loss of contact with the SOHO (SOlar Heliospheric\nObservatory) spacecraft in 1998.\nOn the surface, the events and conditions involved in the accidents appear to be very\ndifferent. A more careful, detailed analysis of the systemic factors, however, reveals striking\nsimilarities. Systemic factors are those that go beyond the specific technical causes, such as\na flawed O-ring design in the Space Shuttle Challenger accident, and include the reasons why\nthose failures or design errors were made. For Challenger, the latter include flawed decision\nmaking, poor problem reporting, lack of trend analysis, a \"silent\" or ineffective safety program,\nThis paper has been accepted for publication in the AIAA Journal of Spacecraft and Rockets.\n\ncommunication problems, etc. Systemic factors are those related to the overall system within\nwhich the technical device is developed and operated.\nA difficulty was encountered in that several of the accident reports implicated the software\nbut then, for some unknown reason, never investigated the software development process in any\ndepth to determine why the error was made. In some cases, it was possible to find information\nabout the software development problems from sources outside the official accident investigation\nreport. One conclusion from this observation might be that accident investigation boards must\ninclude more software experts and must more thoroughly investigation the reasons for the\nintroduction of the errors and their lack of detection once introduced if we are to learn from\nour mistakes and improve our processes.\nThe accidents are first briefly described for those unfamiliar with them, and then the com\nmon factors are identified and discussed. These factors are divided into three groups: (1)\nflaws in the safety culture, (2) management and organizational problems, and (3) technical\ndeficiencies.\nThe Accidents\nAriane 501\nOn June 4, 1996, the maiden flight of the Ariane 5 launcher ended in failure. About 40 s after\ninitiation of the flight sequence, at an altitude of 2700 m, the launcher veered off its flight path,\nbroke up, and exploded. The accident report describes what they called the \"primary cause\"\nas the complete loss of guidance and attitude information 37 s after start of the main engine\nignition sequence (30 seconds after liftoff ).3 The loss of information was due to specification\nand design errors in the software of the inertial reference system. The software was reused\nfrom the Ariane 4 and included functions that were not needed for Ariane 5 but were left in for\n\"commonality.\" In fact, these functions were useful but not required for the Ariane 4 either.\nMars Climate Orbiter (MCO)\nThe Mars Climate Orbiter (MCO) was launched December 11, 1998 atop a Delta II launch\nvehicle. Nine and a half months after launch, in September 1999, the spacecraft was to fire its\nmain engine to achieve an elliptical orbit around Mars and to skim through the Mars upper\natmosphere for several weeks, in a technique called aerobraking, to move into a low circular\norbit. On September 23, 1999, the MCO was lost when it entered the Martian atmosphere in\na lower than expected trajectory. The investigation board identified what it called the \"root\"\ncause of the accident as the failure to use metric units in the coding of a ground software file\nused in the trajectory models.4 Thruster performance data were instead in English units.\nMars Polar Lander (MPL)\nLike MCO, Mars Polar Lander (MPL) was part of the Mars Surveyor program. It was launched\nJanuary 3, 1999, using the same type of Delta II launch vehicle as MCO. Although the cause\nof the MPL loss is unknown, the most likely scenario is that the problem occurred during the\nentry, deployment, and landing (EDL) sequence when the three landing legs were to be deployed\nfrom their stowed condition to the landed position.5,6 Each leg was fitted with a Hall Effect\nmagnetic sensor that generates a voltage when its leg contacts the surface of Mars. The descent\nengines were to be shut down by a command initiated by the flight software when touchdown\n\nwas detected. The engine thrust must be terminated within 50 milliseconds after touchdown\nto avoid overturning the lander. The flight software was also required to protect against a\npremature touchdown signal or a failed sensor in any of the landing legs.\nThe touchdown sensors characteristically generate a false momentary signal at leg deploy\nment. This behavior was understood and the flight software should have ignored it. The\nsoftware requirements did not specifically describe these events, however, and consequently the\nsoftware designers did not account for them. It is believed that the software interpreted the\nspurious signals generated at leg deployment as valid touchdown events. When the sensor data\nwas enabled at an altitude of 40 meters, the software shut down the engines and the lander free\nfell to the surface, impacting at a velocity of 22 meters per second and was destroyed.\nTitan/Centaur/Milstar\nOn April 30, 1999, a Titan IV B-32/Centaur TC-14/Milstar-3 was launched from Cape Canaveral.\nThe mission was to place the Milstar satellite in geosynchronous orbit. An incorrect roll rate\nfilter constant zeroed the roll rate data, resulting in the loss of roll axis control and then yaw\nand pitch control. The loss of attitude control caused excessive firings of the reaction control\nsystem and subsequent hydrazine depletion. This erratic vehicle flight during the Centaur main\nengine burns in turn led to an orbit apogee and perigee much lower than desired, placing the\nMilstar satellite in an incorrect and unusable low elliptical final orbit instead of the intended\ngeosynchronous orbit.\nThe accident investigation board concluded that failure of the Titan IV B-32 mission was due\nto an inadequate software development, testing, and quality assurance process for the Centaur\nupper stage.7 That process did not detect the incorrect entry by a flight software engineer of a\nroll rate filter constant into the Inertial Navigation Unit software file.\nThe roll rate filter itself was included early in the design phase of the first Milstar space\ncraft, but the spacecraft manufacturer later determined that filtering was not required at that\nfrequency. A decision was made to leave the filter in place for the first and later Milstar flights\nfor \"consistency.\"\nSOHO (SOlar Heliospheric Observatory)\nSOHO was a joint effort between NASA and ESA to perform helioseismology and to monitor the\nsolar atmosphere, corona, and wind. The spacecraft completed a successful two-year primary\nmission in May 1998 and then entered into its extended mission phase. After roughly two months\nof nominal activity, contact with SOHO was lost June 25, 1998. The loss was preceded by a\nroutine calibration of the spacecraft's three roll gyroscopes and by a momentum management\nmaneuver.\nThe flight operations team had modified the ground operations procedures as part of a\nground systems reengineering effort to reduce operations costs and streamline operations, to\nminimize science downtime, and to conserve gyro life. Though some of the modifications were\nmade at the request of the SOHO science team, they were not necessarily driven by any specific\nrequirements changes. A series of errors in making the software changes along with errors in\nperforming the calibration and momentum management maneuver and in recovering from an\nemergency safing mode led to the loss of telemetry. 8 Communication with the spacecraft was\neventually restored after a gap of four months.\n\nFlaws in the Safety Culture\nThe safety culture is the general attitude and approach to safety reflected by those working in an\nindustry. The accident reports all described various aspects of complacency and a discounting\nor misunderstanding of the risks associated with software.\nSuccess is ironically one of the progenitors of accidents when it leads to overconfidence\nand cutting corners or making tradeoffs that increase risk. This phenomenon is not new, and\nit is extremely difficult to counter when it enters the engineering culture in an organization.\nComplacency is the root cause of most of the other accident factors described in this paper and\nwas exhibited in all the accidents studied.\nThe Mars Climate Orbiter (MCO) report noted that because JPL's navigation of interplan\netary spacecraft had worked well for 30 years, there was widespread perception that \"orbiting\nMars is routine\" and inadequate attention was devoted to navigation risk management and\ncontingency planning. The MCO investigators found that project management teams appeared\nprimarily focused on meeting mission cost and schedule objectives and did not adequately fo\ncus on mission risk. A recommendation common to several of the accident reports was to pay\ngreater attention to risk identification and management.\nThe official report on the MPL loss concludes that the pressure of meeting the cost and\nschedule goals resulted in an environment of increasing risk in which too many corners were cut\nin applying proven engineering practices and in the checks and balances necessary for mission\nsuccess. \"Lack of adequate risk identification, communication, management, and mitigation\ncompromised mission success.\"6\nIn the SOHO loss, overconfidence and complacency, according to the accident report, led to\ninadequate testing and review of changes to ground-issued software commands to the spacecraft,\na false sense of confidence in the team's ability to recover from a safe-hold mode (emergency sun\nreacquisition) from which a recovery sequence must be commanded and executed under ground\noperator control, the use of tight schedules and compressed timelines that eliminated any time\nto handle potential emergencies, inadequate contingency planning, responses to emergencies\nwithout taking the designed-in time to consider the options, etc. Protections built into the\nprocess, such as formal reviews of critical decisions by senior management and engineering\nstaff, were bypassed. The functional content of an operational procedure was changed without\nappropriate documentation and review of the changes.\nAfter two previous SOHO spacecraft retreats to safe mode, the software and procedures\nwere not reviewed because (according to the accident report) higher priority had been assigned\nto other tasks. The report concludes that the success in recovering from the previous safe mode\nentries led to overconfidence by the operations team in their ability to recover and a lack of\nappreciation of the risks involved in entering and recovering from the safing mode.\nThe Ariane 5 accident report notes that software was assumed to be correct until it was\nshown to be faulty. As noted by the Ariane accident investigation board, the opposite assump\ntion is more realistic. A similar attitude prevailed in Titan/Centaur operations. For example,\non the day of the launch, the attitude rates for the vehicle on the launch pad were not properly\nsensing the earth's rotation rate (the software was consistently reporting a zero roll rate) but\nno one had the responsibility to specifically monitor that rate data or to perform a check to see\nif the software attitude filters were operating correctly. In fact, there were no formal processes\nto check the validity of the filter constants or to monitor attitude rates once the flight tape was\nactually loaded into the Inertial Navigation Unit at the launch site. Potential hardware failures\nare usually checked up to launch time, but it may have been assumed that testing removed all\nsoftware errors and no further checks were needed.\n\nWhile management may express their concern for safety and mission risks, true priorities\nare shown during resource allocation. Although budget decisions are always difficult when\nresources are constrained--and budgets are almost always less than is optimal--the first things\nto be cut are often system safety, system engineering, mission assurance, and operations, which\nare assigned a low priority and assumed to be the least critical parts of the project.\nIn the Milstar satellite loss, the Titan Program Office had no permanently assigned civil\nservice or military personnel nor full-time support to \"work\" the Titan/Centaur software. They\nhad decided that because the software was \"mature, stable, and had not experienced problems\nin the past,\" they could best use their limited resources available after the initial development\neffort to address hardware issues. The Titan program office had cut support for monitoring the\nsoftware development and test process by 50% since 1994 and had greatly cut the number of\nengineers working launch operations.\nThe SOHO Mission Management Plan required that the NASA Project Operations Direc\ntor be responsible for programmatic matters, provide overall technical direction to the flight\noperations team, and interface with the ESA technical support director. The position had been\ndescoped over time by NASA from a dedicated individual during launch and commissioning to\none NASA individual spending less than 10% of his time tracking SOHO operations. ESA was\nto retain ownership of the spacecraft and to be responsible for its technical integrity and safety,\nbut they were understaffed to perform this function in other than routine situations. In both\nSOHO and MCO, the operations group did not have a mission assurance manager.\nComplacency can also manifest itself in a general tendency of management and decision\nmakers to discount unwanted evidence of risk. A culture of denial 9 arises in which any evidence\nof significant risk is dismissed. In the MCO, SOHO, and Titan losses, warning signs existed\nthat the software was flawed, but they went unheeded.\nThe problems experienced with the Mars Climate Orbiter (MCO) software during the early\nstages of the flight did not seem to raise any red flags. During the first four months of the MCO\nmission, the ground software angular momentum desaturation (AMD) files were not used in\nthe orbit determination process because of multiple file format errors and incorrect spacecraft\nattitude data specifications. Four months were required to fix the files. Almost immediately\n(within a week) it became apparent that the files contained anomalous data that was indicat\ning underestimation of the trajectory perturbations due to desaturation events. Despite all\nthese hints that there were serious problems in the software and perhaps the development pro\ncess, reliance was still placed on the supposedly fixed software without extra manual checks or\nalternative calculations to check the results.\nThree months before the loss of the SOHO telemetry, ground software problems had trig\ngered an emergency sun reacquisition (a safe hold mode entered when there are attitude control\nanomalies) and a shortcut in the recovery from this emergency sun reacquisition led to a second\none. A resulting recommended comprehensive review of the software and procedures had not\nbeen implemented before the accident because higher priority had been assigned to other tasks.\nEngineers noticed the problems with the Titan/Centaur software after it was delivered to\nthe launch site and they were reported back to LMA in Denver, but nobody seemed to take\nthem seriously.\nSome of the complacency can arise from a misunderstanding of the risks associated with\nsoftware. Throughout the accident reports, there is an emphasis on failures as the cause of\naccidents and redundancy as the solution. Accidents involving software, however, are usu\nally system accidents that result from dysfunctional interactions among components, not from\nindividual component failure. All these accidents (as well as almost all the software-related\naccidents known to the author) resulted from the software doing something wrong rather than\n\nthe computer hardware or software failing to operate at all. In fact, in most cases the software\nor hardware components operated according to their specifications (i.e., they did not fail), but\nthe combined behavior of the components led to disastrous system behavior.\nAll the accidents investigated for this paper displayed some aspects of system accidents.\nSystem accidents are caused by interactive complexity and tight coupling.10 Software allows us\nto build systems with a level of complexity and coupling that is beyond our ability to control;\nin fact, we are building systems where the interactions among the components (often controlled\nby software) cannot all be planned, understood, anticipated, or guarded against. This change\nis not solely the result of using digital components, but it is made possible because of the\nflexibility of software. Note that the use of redundancy only makes the problem worse--the\nadded complexity introduced by redundancy has resulted in accidents that otherwise might not\nhave occurred.\nThe Ariane 5 accident report notes that according to the culture of the Ariane program,\nonly random failures were addressed and they were primarily handled with redundancy. The\nengineers designing the Ariane 5 inertial guidance system opted to shut down the computer when\nan exception was raised in an unnecessary function (the alignment function after takeoff ):\nThe reason behind this drastic action lies in the culture within the Ariane pro\ngramme of only addressing random hardware failures. From this point of view,\nexception--or error--handling mechanisms are designed for a random hardware\nfailure which can quite rationally be handled by a backup system.3\nThis approach obviously failed in the Ariane 5's first flight when both the primary and backup\n(redundant) Inertial Reference System computers shut themselves down--exactly as they were\ndesigned to do--while processing the same unexpected input value.\nSoftware and digital systems require changes to important aspects of engineering practice.\nNot only are failures not random (if the term \"failure\" makes any sense when applied to some\nthing like software that is pure design separated from the physical realization of that design),\nbut the complexity of most software precludes examining all the ways it could \"misbehave.\"\nAnd the failure modes (the way it misbehaves) can be very different than for physical devices.\nThe JPL Mars Polar Lander accident report, like others, recommends using FMEA (Failure\nModes and Effects Analysis) and FTA (Fault Tree Analysis) along with appropriate redundancy\nto eliminate failures. But these techniques were developed to cope with random wearout fail\nures in hardware and are not very effective against design errors, the only type of error found\nin software. Although computer hardware can fail, software itself is pure design and thus all\nerrors are design errors and appropriate techniques for handling design errors must be used.\nManagement and Organizational Factors\nThe five accidents studied during this exercise, as well as most other major accidents, exhibited\ncommon organizational and managerial flaws, notably a diffusion of responsibility and authority,\nlimited communication channels, and poor information flow.\n4.1\nDiffusion of Responsibility and Authority\nIn all of the accident reports, serious organizational and communication problems among the\ngeographically dispersed partners are mentioned or implied by the recommendations. Respon\nsibility was diffused without complete coverage and without complete understanding by anyone\nabout what all the groups were doing. Roles were not clearly allocated.\n\nBoth the Titan and Mars '98 programs were transitioning to process \"insight\" from pro\ncess \"oversight,\" reflecting different levels of feedback control over lower levels and a change\nfrom prescriptive management control to management by objectives, where the objectives are\ninterpreted and satisfied according to the local context.\nJust as the MPL reports noted that \"Faster, Better, Cheaper\" was not defined adequately\nto ensure that it meant more than simply cutting budgets, this change in management role\nfrom oversight to insight seems to have been implemented on the Mars '98 projects as well as\nthe Titan/Centaur program simply as a reduction in personnel and budgets without assuring\nthat anyone was responsible for specific critical tasks. For example, the MCO report says:\n\"NASA management of out-of-house missions was changed from 'oversight' to 'insight'--with\nfar fewer resources devoted to contract monitoring.\" One of the results of faster-better-cheaper\nwas a reduction in workforce while maintaining an expectation for the same amount of work to\nbe accomplished. In many of these accidents, the people were simply overworked--sometimes\ndriven by their own dedication.\nThe process used in the Titan/Centaur program to develop the constants used in the flight\nsoftware was neither well defined nor completely understood by any of the multiple players\ninvolved in that process. Procedures for creating and updating the database were not formally\ndocumented and were left to the flight software engineer's discretion. The root problem is\nprobably not the lack of documentation itself but the lack of anyone being in charge of the\nentire process. There were several people who performed part of the process, but they only\ncompletely understood their own specific part. The Accident Investigation Board could not\nidentify a single process owner responsible for understanding, designing, documenting, control\nling configuration, and ensuring proper execution of the overall software development process.\nInstead, responsibility was diffused among the various partners, without complete coverage.\nFor example, the Centaur Inertial Navigation Unit consists of two major software components\ndeveloped by different companies. LMA developed the Flight Control System (FCS) software\nand was responsible for overall INU testing. Honeywell developed the Inertial Measurement\nSystem (IMU) and was partially responsible for its software development and testing. The\nerroneous constants were processed by the Honeywell-built IMU, but were designed and tested\nby LMA. LMA, in turn, focused its flight software process on the FCS and not the IMS software\nand had little knowledge of IMS operations.\nTitan launch operations exhibited the same problems. The Space and Missile Systems Cen\nter Launch Directorate and the 3rd Space Launch Squadron had undergone personnel reductions\nand were also transitioning from a task oversight to a process insight role. That transition had\nnot been managed by a detailed plan. According to the accident report, Air Force responsibil\nities under the insight concept were not well defined and how to perform those responsibilities\nhad not been communicated to the work force. There was no master surveillance plan in place\nto define the tasks for the engineers remaining after the reductions--so the launch personnel\nused their best engineering judgment to determine which tasks they should perform, which\ntasks to monitor, and how closely to analyze the data from each task. This approach, however,\ndid not ensure that anyone was responsible for specific tasks. In particular, on the day of the\nlaunch, the attitude rates for the vehicle on the launch pad were not properly sensing the earth's\nrotation rate, but nobody had the responsibility to specifically monitor that rate data or to\ncheck the validity of the roll rate and no reference was provided with which to compare. So\nwhen the anomalies occurred during launch preparations that clearly showed a problem existed\nwith the software, nobody had the responsibility or ability to follow up on them.\nIn MPL, there was essentially no JPL line management involvement or visibility into the\nsoftware development and minimal involvement by JPL technical experts. Similarly, the MCO\n\nreport suggests that authority and accountability were a significant issue in the accident and\nthat roles and responsibilities were not clearly allocated. There was virtually no JPL oversight\nof LMA subsystem development. The MCO report says:\nLine managers at the field centers need to be held accountable for the success of all\nmissions at their centers . . . The line management should be held accountable for\nasking the right questions at meetings and reviews, and getting the right people to\nthose reviews to uncover mission-critical issues and concerns early in the program.4\nFor SOHO, a transfer of management authority to the SOHO Project Scientist resident at\nGoddard Space Flight Center left no manager, either from NASA or ESA, as the clear champion\nof spacecraft health and safety. Instead, the accident report concludes that the transfer encour\naged management decisions that maximized science return over spacecraft risk. In addition, the\ndecision structure for real-time divergence from agreed-upon ground and spacecraft procedures\nwas far from clear: The flight operations staff was apparently able to change procedures without\nproper review.\nThe Ariane 501 accident report is almost totally silent about organizational structure prob\nlems: It does not describe the allocation of responsibility and authority for safety nor does\nit mention any organizational or management factors that may have influenced the accident.\nThere is one hint that there may have been problems, however, in a recommendation at the\nend of the report that says:\nA more transparent organization of the cooperation among partners in the Ariane\n5 programme must be considered. Close engineering cooperation, with clear cut\nauthority and responsibility, is needed to achieve system coherence, with simple\nand clear interfaces between partners.3\nInadequate transition from development to operations played a role in several of the acci\ndents. Engineering management sometimes has a tendency to focus on development and to put\nless effort into planning the operational phase. The MCO report states:\nThe overall project plan did not provide for a careful handover from the develop\nment project to the very busy operations project. Transition from development\nto operations--as two separate teams--disrupted continuity and unity of shared\npurpose.4\nThe operations teams (in those accidents that involved operations) also seemed isolated from\nthe developers. The MCO report notes this isolation and provides as an example that the\noperators did not know until long after launch that the spacecraft sent down tracking data that\ncould have been compared with the ground data, which might have identified the software error\nwhile it could have been fixed. The operations crew for the Titan/Centaur also did not detect\nthe obvious software problems, partly because of a lack of the knowledge required to detect\nthem.\nMost important, responsibility for safety does not seem to have been clearly defined outside\nof the quality assurance function on any of these programs. All the accident reports (except\nthe Titan/Centaur) are surprisingly silent about their safety programs. One would think that\nthe safety activities and why they had been ineffective would figure prominently in the reports.\nSafety was originally identified as a separate responsibility by the Air Force during the\nballistic missile programs of the 1950s and 1960s to solve exactly the problems seen in these\naccidents--to make sure that safety is given due consideration in decisions involving conflicting\n\npressures and that safety issues are visible at all levels of decision making. An extensive system\nsafety program was developed by NASA after the Apollo launch pad fire in 1967. However,\nthe Challenger accident report noted that the system safety program had become \"silent\" over\ntime and through budget cuts. Has this perhaps happened again? Or are the system safety\nefforts just not handling software effectively?\nOne common mistake is to locate the safety efforts within the quality assurance function.\nPlacing safety only under the assurance umbrella instead of treating it as a central engineering\nconcern is not going to be effective, as has been continually demonstrated by these and other\naccidents. While safety is certainly one property (among many) that needs to be assured, safety\ncannot be engineered into a design through after-the-fact assurance activities alone.\nHaving an effective safety program cannot prevent errors of judgment in balancing conflicting\nsafety, schedule, and budget constraints, but a safety program can at least make sure that\ndecisions are informed and that safety is given due consideration. It also ensures that someone\nis focusing attention on what the system is not supposed to do, i.e., the hazards, and not just\non what it is supposed to do. Both perspectives are necessary if safety and mission assurance\nare to be optimized.\n4.2\nLimited Communication Channels and Poor Information Flow\nAll the accident reports mention poor information flow and communication problems except\nthe Ariane 5, which includes very little information beyond the technical details. The Ti-\ntan/Centaur accident report, for example, notes that \"fragmentation/stovepiping in the flight\nsoftware development process, coupled with the lack of an overall defined process, resulted in\npoor and inadequate communication and interfacing among the many partners and subpro\ncesses.\" The report suggests that many of the various partners were confused about what\nthe other groups were doing. For example, the LMA software group personnel who created\nthe database from which the erroneous load tape constants were generated, were not aware\nthat the independent verification and validation testing did not use the as-flown constants but\ninstead used default values. The company responsible for the independent verification and\nvalidation (Analex-Denver) did not know that the division actually doing the independent ver\nification adn validation (Analex-Cleveland) was only verifying the functionality of the design\nconstant and not what was actually loaded into the Centaur for flight. The Defense Contract\nManagement Command software surveillance personnel were not aware that the filter constants\ncontained in the flight software were generated by a manual input and were never tested by\nLMA in their preflight simulation nor subjected to independent verification and validation by\nAnalex-Cleveland.\nAll the accidents involved one engineering group not getting the information they needed\nfrom another engineering group. The MCO report cited deficiencies in communication between\nthe project development team and the operations team. For example, the report notes that\n\"Critical information on the control and desaturation of the MCO momentum was not passed to\nthe operations navigation team.\" As another example, a decision was made that the \"barbecue\nmode\" (a daily 180* flip to cancel angular momentum buildup) was not needed and it was\ndeleted from the spacecraft operations plan, but the operations navigation team was never\nnotified. Communication was poor in the other direction too. Throughout the first nine months\nof the MCO mission, concerns regarding discrepancies observed between navigation solutions\nwere reported by the navigation operations team only informally and were not communicated\neffectively to the spacecraft operations team or project management.\nA significant factor in the MPL loss was that test results and new information about the Hall\n\nEffect sensors derived during testing was not communicated to all the component designers that\nneeded it. In general, system engineering on several of the projects did not keep abreast of test\nresults from all areas and communicate the findings to other areas of the development project.\nThe MPL report concludes that the effect of inadequate peer interaction was, in retrospect, a\nmajor problem that led to a breakdown in intergroup communications. Communication is one\nof the most important functions in any large, geographically distributed engineering project\nand must be carefully planned and fostered.\nThe Titan/Centaur accident also involved critical information not getting to the right peo\nple. For example, tests right before launch detected the zero roll rate but there was no com\nmunication channel established for getting that information to those who could understand it.\nA guidance engineer at the launch site noticed the anomalous roll rates and called LMA in\nDenver, leaving a voice mail message to call her or her supervisor. She also sent an email to\nher supervisor at Cape Canaveral explaining the situation. Her supervisor was on vacation and\nwas due back at the office the next Monday, but the engineer herself was scheduled to work\nthe second shift that day. Two LMA engineers in Denver, the control dynamics engineer who\nhad originally specified the filter values and his supervisor, listened to the voice mail from the\nlaunch site guidance engineer and called her supervisor, who had just returned from vacation.\nHe was initially unable to find the email she had sent him during their conversation and said\nhe would call back. By the time he called back, the control dynamics engineer who had created\nthe filter values had left his supervisor's office. At no time did the LMA Denver engineers speak\ndirectly with the launch site guidance engineer who had originally noticed the anomaly.\nSOHO had similar communication problems between the operations team and technical\nexperts. For example, when a significant change to procedures was implemented, an internal\nprocess was used and nobody outside the flight operations team was notified.\nIn the Titan/Centaur and Mars Climate Orbiter accidents, there was evidence that a prob\nlem existed before the loss occurred, but there was no communication channel established for\ngetting the information to those who could understand it and to those making decisions or,\nalternatively, the problem-reporting channel was ineffective in some way or was simply unused.\nThe MCO report concludes that project leadership did not instill the necessary sense of author\nity and accountability in workers that would have spurred them to broadcast problems they\ndetected so that those problems might be \"articulated, interpreted, and elevated to the highest\nappropriate level, until resolved.\" The report concludes that \"Institutional management must\nbe accountable for ensuring that concerns raised in their own area of responsibility are pursued,\nadequately addressed, and closed out.\"\nResearchers have found that the second most important factor in the success of any safety\nprogram (after top management concern) is the quality of the hazard information system. Both\ncollection of critical information as well as dissemination to the appropriate people for action\nis required, but these activities were haphazard at best for most of the projects involved in\nthese accidents. The MCO report concludes that lack of discipline in reporting problems and\ninsufficient followup was at the heart of the mission's navigation mishap. Email was used to\nsolve problems rather than the problem tracking system:\nA critical deficiency in Mars Climate Orbiter project management was the lack of\ndiscipline in reporting problems and insufficient follow-up. The primary, structured\nproblem-reporting procedure used by the Jet Propulsion Laboratory--the Incident,\nSurprise, Anomaly process--was not embraced by the whole team.4\nFor SOHO, critical information about the required operation of gyros used for changing the\nsoftware was also provided informally to the flight operations team via email.\n\nIn the Titan/Centaur loss, the use of voice mail and email implies there either was no formal\nanomaly reporting and tracking system or the formal reporting procedure was not known or\nused by the process participants for some reason. The report states that there was confusion\nand uncertainty as to how the roll rate anomalies should be reported, analyzed, documented\nand tracked because it was a \"concern\" and not a \"deviation.\" There is no explanation of these\nterms.\nIn all the accidents (except for Ariane, where anomaly reporting is not mentioned), the\nexisting formal anomaly reporting system was bypassed and informal email and voice mail was\nsubstituted. The problem is clear but not the cause, which was not included in the reports and\nperhaps not investigated. When a structured process exists and is not used, there is usually a\nreason. Some possible explanations may be that the system is difficult or unwieldy to use or\nit involves too much overhead. Such systems may not be changing as new technology changes\nthe way engineers work.\nThere is no reason why reporting something within the problem-reporting system should\nbe much more cumbersome than adding an additional recipient to email. Large projects have\nsuccessfully implemented informal email processes for reporting anomalies and safety concerns\nor issues to system safety personnel. New hazards and concerns will be identified throughout\nthe development process and into operations, and there must be a simple and non-onerous way\nfor software engineers and operational personnel to raise concerns and safety issues and get\nquestions answered at any time.\nTechnical Deficiencies\nThese cultural and managerial flaws manifested themselves in the form of technical deficiencies:\n(1) inadequate system and software engineering, (2) inadequate review activities, (3) ineffective\nsystem safety engineering, (4) inadequate human factors engineering, and (5) flaws in the test\nand simulation environments.\n5.1\nInadequate System and Software Engineering\nFor any project as complex as those involved in these accidents, good system engineering is\nessential for success. In some of the accidents, system engineering resources were insufficient\nto meet the needs of the project. For example, the MPL report notes that insufficient system\nengineering during the formulation stage led to important decisions that ultimately required\nmore development effort than originally foreseen as well as inadequate baseline decisions and\nhazard identification. In others, the process followed was flawed, such as in the flowdown\nof system requirements to software requirements or in the coordination and communication\namong project partners and teams. As just one example, the MCO report notes that navigation\nrequirements were set at too high a management level and that there was insufficient flowdown\nto the subsystem level and inadequate validation of the requirements.\nThe Centaur software process was developed early in the Titan program and many of the\nindividuals who designed the original process were no longer involved in it due to corporate\nmergers and restructuring and the maturation and completion of the Titan/Centaur design and\ndevelopment. The accident report notes that much of the system and process history was lost\nwith their departure and therefore nobody knew enough about the overall process to detect\nthat it omitted any testing with the actual load tape or knew that the test facilities had the\ncapability of running the type of test that could have caught the error.\n\nPreventing system accidents falls into the province of system engineering--those building\nindividual components have little control over events arising from dysfunctional interactions\namong components. As the systems we build become more complex (much of that complexity\nbeing made possible by the use of computers), system engineering will play an increasingly im\nportant role in the engineering effort. In turn, system engineering will need new modeling and\nanalysis tools that can handle the complexity inherent in the systems we are building. Appro\npriate modeling methodologies will have to include software, hardware and human components\nof systems.\nGiven that software played a role in all the accidents, it is surprising the reports reflected\nso little investigation of the practices that led to the introduction of the software flaws and a\ndearth of recommendations to fix them. In some cases, software processes were declared in the\naccident reports to have been adequate when the evidence shows they were not.\nThe accidents all involved very common system and software engineering problems, includ\ning poor specification practices, unnecessary complexity and software functions, software reuse\nwithout appropriate safety analysis, and violation of basic safety engineering design practices\nin the digital components.\n5.1.1\nPoor or Missing Specifications\nAlmost all software-related aerospace accidents (and accidents in other industries) have been\nrelated to flawed requirements and misunderstanding about what the software should do--\nthe software performed exactly as the designers intended (it did not \"fail\"), but the designed\nbehavior was not safe from a system viewpoint.11 There is not only anecdotal but some hard data\nto support this hypothesis. Lutz examined 387 software errors uncovered during integration\nand system testing of the Voyager and Galileo spacecraft.12 She concluded that the software\nerrors identified as potentially hazardous to the system tended to be produced by different error\nmechanisms than non-safety-related software errors. She showed that for these two spacecraft,\nthe safety-related software errors arose most commonly from (1) discrepancies between the\ndocumented requirements specifications and the requirements needed for correct functioning\nof the system and (2) misunderstandings about the software's interface with the rest of the\nsystem. This experiential evidence points to a need for better specification review and analysis.\nAll the reports refer to inadequate specification practices. The Ariane accident report men\ntions poor specification practices in several places and notes that the structure of the documen\ntation obscured the ability to review the critical design decisions and their underlying rationale.\nInadequate documentation of design rationale to allow effective review of design decisions is a\nvery common problem in system and software specifications. The Ariane report recommends\nthat justification documents be given the same attention as code and that techniques for keeping\ncode and its justifications consistent be improved.\nThe MCO report contains little information about the software engineering practices but\nhints at specification deficiencies in statements about \"JPL's process of cowboy programming\"\nand \"the use of 20-year-old trajectory code that can neither be run, seen, or verified by anyone\nor anything external to JPL.\"\nThe MPL report notes that the system-level requirements document did not specifically\nstate the failure modes the requirement was protecting against (in this case possible transients)\nand speculates that the software designers or one of the reviewers might have discovered the\nmissing requirement if they had been aware of the rationale underlying the requirements. The\nsmall part of the requirements specification shown in the accident report (which may very\nwell be misleading) seems to avoid all mention of what the software should not do. In fact,\n\nstandards and industry practices often forbid such negative requirements statements. The result\nis that software specifications often describe nominal behavior well but are very incomplete with\nrespect to required software behavior under off-nominal conditions and rarely describe what the\nsoftware is not supposed to do. Most safety-related requirements and design constraints are best\ndescribed using such negative requirements or design constraints. In addition, the requirements\nflowdown process for MPL was clearly flawed, and the rationale for requirements did not appear\nto be included in the specification.\nNot surprising, the interfaces were a source of problems. It seems likely from the evidence\nin several of the accidents that the interface documentation practices were flawed. The MPL\nreport includes a recommendation that in the future \"all hardware inputs to the software\nmust be identified . . . The character of the inputs must be documented in a set of system-level\nrequirements.\" This information is usually included in the standard interface specifications,\nand it is surprising that it was not.\nThere are differing accounts of what happened with respect to the MCO incorrect units\nproblem. The official accident report seems to place blame on the programmers and recom\nmends that the software development team be provided additional training in \"the use and\nimportance of following the Mission Operations Software Interface Specification (SIS).\" Al\nthough not included in the official NASA Mars Climate Orbiter accident report, James Oberg\nin an IEEE Spectrum article on the accident13 claims that JPL never specified the units to be\nused. It is common for specifications to be incomplete or not to be available until late in the\ndevelopment process.\nA different explanation for the MCO units error was provided by the developers.14 According\nto them, the files were required to conform to a Mars Global Surveyor (MGS) heritage software\ninterface specification. The equations used in the erroneous calculation were supplied by the\nvendor in English units.\nAlthough starting from MGS-heritage software, the coded MGS thruster equation\nhad to be changed because of the different size RCS thruster that MCO employed\n(same vendor). As luck would have it, the 4.45 conversion factor, although correctly\nincluded in the MGS equation by the previous development team, was not immedi\nately identifiable by inspection (being buried in the equation) or commented in the\ncode in an obvious way that the MCO team recognized it. Thus, although the SIS\nrequired SI units, the new thruster equation was inserted in the place of the MGS\nequation--without the conversion factor.14\nThis explanation raises questions about the other software specifications, including the require\nments specification, which seemingly should include descriptions of the computations to be\nused. Either these did not exist or the software engineers did not refer to them when making\nthe change. Formal acceptance testing apparently did not use the (MGS) software interface\nspecification because the test oracle (computed manually) used for comparison contained the\nsame error as the output file.14\nComplete and understandable specifications are not only necessary for development, but\nthey are critical for operations and the handoff between developers, maintainers, and operators.\nIn the Titan/Centaur accident, nobody other than the control dynamics engineers who designed\nthe roll rate constants understood their use or the impact of filtering the roll rate to zero. When\ndiscrepancies were discovered right before the Titan/Centaur/Milstar launch, as noted earlier,\nnobody understood them. The MCO operations staff also clearly had inadequate understanding\nof the automation and therefore were unable to monitor its operation effectively.\n\nThe SOHO accident report mentions that no hard copy of the software command procedure\nset existed and the latest versions were stored electronically without adequate notification when\nthe procedures were modified. The report also states that the missing software enable command\n(which led to the loss) had not been included in the software module due to a lack of system\nknowledge of the person who modified the procedure: he did not know that an automatic\nsoftware function must be re-enabled each time Gyro A was despun. The information had been\nprovided, but via email. Such information, particularly about safety-critical features, obviously\nneeds to be clearly and prominently described in the system specifications.\nGood specifications that include requirements tracing and design rationale are critical for\ncomplex systems, particularly those that are software-controlled. And they must be reviewable\nand reviewed in depth by domain experts.\n5.1.2\nUnnecessary Complexity and Software Functionality\nOne of the most basic concepts in engineering critical systems is to \"keep it simple.\"\nThe price of reliability is the pursuit of the utmost simplicity. It is a price which\nthe very rich find most hard to pay. 15\nThe seemingly unlimited ability of software to implement desirable features often, as in the case\nof most of the accidents examined in this paper, pushes this basic principle into the background:\nCreeping featurism is a common problem in software-intensive systems:\n'And they looked upon the software, and saw that it was good. But they just had\nto add this one other feature' . . . A project's specification rapidly becomes a wish\nlist. Additions to the list encounter little or no resistance. We can always justify\none more feature, one more mode, one more gee-whiz capability. And don't worry,\nit'll be easy--after all, it's just software. We can do anything.\nIn one stroke, we are free of nature's constraints. This freedom is software's\nmain attraction, but unbounded freedom lies at the heart of all software difficulty\n(Frank McCormick, unpublished essay).\nAll the accidents, except MCO, involved either unnecessary software functions or software\noperating when it was not necessary. The MCO report does not mention or discuss the software\nfeatures.\nBoth the Ariane and Titan/Centaur accidents involved software functions that were not\nneeded, but surprisingly the decision to put in these unneeded features was not questioned in\nthe accident reports. The software alignment function in the reused Ariane 4 software had no\nuse in the different Ariane 5 design. The alignment function was designed to cope with the\nunlikely event of a hold in the Ariane 4 countdown: the countdown could be restarted and a\nshort launch window could still be used. The feature had been used once (in 1989 in flight 33 of\nthe Ariane 4). The Ariane 5 has a different preparation sequence and cannot use the feature at\nall. In addition, the alignment function computes meaningful results only before liftoff--during\nflight, it serves no purpose but the problem occurred while the function was operating after\nliftoff.\nThe Ariane accident report does question the advisability of retaining the unused Ariane\n4 alignment function in the Ariane 5 software, but it does not question whether the Ariane 4\nsoftware should have included such a non-required but convenient software function in the first\nplace. Outside of its effect on reuse (which may reasonably not have been contemplated during\n\nAriane 4 development), a tradeoff was made between possibly delaying a launch and simplifying\nthe software.\nThe Mars Polar Lander accident also involved software that was executing when it was not\nnecessary to execute, although in that case the function was required at a later time in the\ndescent sequence. The report states that the decision to start the software early was based\non trying to avoid transients in CPU loading. The tradeoff in this case may have seemed\njustified, but executing software when it is not needed or including unnecessary code raises risk\nsignificantly. The MPL independent accident investigation report also noted that requirements\ncreep was a factor in the accident.\nThe Titan/Centaur accident report explains that the software roll rate filter involved in\nthe loss of the Milstar satellite was not needed but was kept in for consistency. The same\njustification is used to explain why the unnecessary software function leading to the loss of the\nAriane 5 was retained from the Ariane 4 software. Neither report explains why consistency was\nassigned such high priority. While changing software that works can increase risk, executing\nunnecessary software functions is also risky.\nFor SOHO, there was no reason to introduce a new function into the module that eventually\nled to the loss. A software function already existed to perform the required maneuver and could\nhave been used. There was also no need to despin Gyro A between gyro calibration and the\nmomentum maneuvers.\nIn all these projects, tradeoffs were obviously not considered adequately (considering the\nconsequences), perhaps partially due to complacency about software risk. The more features\nincluded in software and the greater the resulting complexity (both software complexity and\nsystem complexity), the harder and more expensive it is to test, to provide assurance through\nreviews and analysis, to maintain, and to reuse in the future. Well-reasoned tradeoff decisions\nmust include a realistic assessment of the impact of these extra difficulties. Software functions\nare not \"free.\"\n5.1.3\nSoftware Reuse or Changes without Appropriate Safety Analysis\nReuse and the use of commercial off-the-shelf software (COTS) is common practice today in\nembedded software development. The Ariane 5 software involved in the loss was reused from\nthe Ariane 4. According to the MCO developers, the small forces software was reused from the\nMars Global Surveyor project, with the substitution of a new thruster equation.14 Technical\nmanagement accepted the \"just like MGS\" argument and did not focus on the details of the\nsoftware. The SOHO software was changed without appropriate analysis of the changes.\nIt is widely believed that because software has executed safely in other applications, it will\nbe safe in the new one. This misconception arises from confusion between software reliability\nand safety: most accidents involve software that is doing exactly what it was designed to do,\nbut the designers misunderstood what behavior was required and would be safe, i.e., it reliably\nperforms the wrong function.11\nThe blackbox (externally visible) behavior of a component can only be determined to be safe\nby analyzing its effects on the system in which it will be operating, that is, by considering the\nspecific operational context. The fact that software has been used safely in another environment\nprovides no information about its safety in the current one. In fact, reused software is probably\nless safe because the original decisions about the required software behavior were made for\na different system design and were based on different environmental assumptions. Changing\nthe environment in which the software operates makes all previous usage experience with the\nsoftware irrelevant for determining safety.\n\nThe problems in the Ariane 5 software arose from an overflow of a 16-bit integer variable.\nThe horizontal velocity of the Ariane 4 cannot reach a value beyond the limit of the software,\ni.e., the value will always fit in 16 bits. The initial acceleration and trajectory of the Ariane\n5, however, leads to a buildup of horizontal velocity five times more rapid than that of the\nAriane 4, leading to an overflow. For some unexplained reason, the Ariane 5 requirements and\nspecifications did not include the Ariane 5 trajectory data. This omission was not simply an\noversight--the accident report states that the partners jointly agreed not to include it. The\nreport provides no reason for this very strange decision, which negatively impacted the ability\nto detect the problem during reviews and testing.\nThe philosophy of the Ariane 5 program, as stated in the accident report, that it was not\nwise to change software that had worked well on the Ariane 4 unless it was proven necessary\nto do so is well founded: Errors are often introduced when software is changed, particularly by\nthose who did not originally write it, as occurred with SOHO. However, in this case, there is a\ntradeoff with safety that needs to be carefully evaluated. The best solution may not have been\nto leave the software as it was but to rewrite it from scratch--such a decision depends on the\ntype of change required, the specific design of the software, and the potential effect of the feature\non system safety. The cost of the decision to reuse the Ariane 4 software without rewriting it\n(in terms of both money and program delays) was much greater than the cost of doing a proper\nanalysis of its safety. The same is true for the Centaur software with respect to the losses\nresulting from leaving in the unneeded filter function. If the cost of the analysis of reused (or\nCOTS) software or of changes to software is prohibitively expensive or beyond the state of the\nart, then redeveloping the software or completely rewriting it may be the appropriate decision.\nA reasonable conclusion to be drawn is not that software cannot be reused, but that a safety\nanalysis of its operation in the new system context is mandatory: Testing alone is not adequate\nto accomplish this goal. For complex designs, the safety analysis required stretches the limits of\ncurrent technology. For such analysis to be technically and financially feasible, reused software\nmust contain only the features necessary to perform critical functions--another reason to avoid\nunnecessary functions.\nCOTS software is often constructed with as many features as possible to make it commer\ncially useful in a variety of systems. Thus there is tension between using COTS versus being\nable to perform a safety analysis and have confidence in the safety of the system. This tension\nmust be resolved in management decisions about specific project risk--ignoring the potential\nsafety issues associated with COTS software can lead to accidents and potential losses that are\ngreater than the additional cost would have been to design and build new components instead\nof buying them.\nIf software reuse and the use of COTS components are to result in acceptable risk, then\nsystem and software modeling and analysis techniques must be used to perform the necessary\nsafety analyses. This process is not easy or cheap. Introducing computers does not preclude\nthe need for good engineering practices nor the need for difficult tradeoff decisions, and it\nalmost always involves higher costs despite the common myth that introducing automation,\nparticularly digital automation, will save money.\nA similar argument applies to changing existing software. Changes to software appear to\nbe easy. While it is indeed easy to change software, it is very difficult to change it correctly and\nthe difficulty increases over time. The Mars Climate Orbiter software was changed to include\na new thruster equation, but the 4.45 correction factor (the difference between the metric and\nimperial units), buried in the original code, was not noticed when the new vendor-supplied\nequation was used to update the software. Modifications to the SOHO command procedures\nwere subjected to very little testing and review, perhaps because they were considered to be\n\nminor.\nThe more changes that are made to software, the more the original design erodes and\nthe more difficult it becomes to make changes without introducing errors. In addition, the\nassumptions and rationale behind the design decisions are commonly not documented and are\neasily violated when the software is changed. To prevent accidents, all changes to software\nmust be thoroughly tested and, in addition, analyzed for their impact on safety. Such change\nanalysis will not be feasible unless special steps are taken during development to document the\ninformation needed.\nThe environment in which the system and software are operating will also change over time,\npartially as a result of the introduction of the automation or system itself. Basic assumptions\nmade in the original hazard analysis process must be recorded and periodically evaluated to\nassure they are not being violated in practice. Incident and accident analysis are also important\nas well as performance monitoring and periodic operational process audits.\n5.1.4\nViolation of Basic Safety Engineering Practices in the Digital Components\nAlthough system safety engineering textbooks and standards include principles for safe design,\nsoftware engineers are almost never taught them. As a result, software often does not incor\nporate basic safe design principles--for example, separating and isolating critical functions,\neliminating unnecessary functionality, designing error-reporting messages such that they can\nnot be confused with critical data (which occurred in the Ariane 5 loss), and reasonableness\nchecking of inputs and internal states.\nConsider the Mars Polar Lander loss as an example. The JPL report on the accident states\nthat the software designers did not include any mechanisms to protect against transient sensor\nsignals nor did they think they had to test for transient conditions. Runtime reasonableness\nand other types of checks should be part of the design criteria used for any real-time software.\nThe Ariane 5 software appears not to have included simple and fairly standard range checks and\noverflow checks (without using exception handling) that would have been simple to implement\nin Ada (the programming language used), which was designed to provide the facilities required\nto perform real-time checking of software.\nThe SOHO, Titan/Centaur, and MCO accident reports are silent about whether the code\nincluded features to prevent the problem but were implemented incorrectly or, alternatively,\nsuch features were omitted. From the outside, it appears that safety-related design features\ncould easily have been used with minimal impact on hardware resources. System and software\nhazard analysis procedures can provide the information needed to implement the critical features\nwith little cost in terms of programming or execution time. We need to start applying safe design\nprinciples to software just as we do for hardware.\nThe practices involved, however, may need to be very different than those used for hard\nware, as witnessed by the misunderstanding of the effectiveness of redundancy in the Ariane\n5 accident. Traditional system engineering techniques to protect against accidents caused by\ncomponent failure usually involve increasing the reliability (integrity) of the individual compo\nnents, including redundancy to protect against component failure, and building error margins\ninto components to protect against analysis or manufacturing flaws. None of these techniques\nare useful in protecting against system accidents or software-related accidents, where the prob\nlems result from system design flaws: Increasing component integrity will have no effect on\naccidents where the software operated exactly as it was required and designed to do, but the\nrequirements were incorrect. Every one of the accidents considered in this paper fit this de\nscription, except perhaps the Titan/Centaur loss, which resulted from a typo in a software load\n\ntape.\nMisunderstanding the differences between the failure modes in hardware and those in soft\nware has led to attempts to increase reliability and safety through software redundancy, often in\nthe form of independent groups writing multiple versions of the software with majority voting\non the outputs. This approach is based on the assumption that such versions will fail in a\nstatistically independent manner, but this assumption has been shown to be false in practice\nand by scientific experiments (see, for example, Knight and Leveson16). Common-cause (but\nusually different) logic errors tend to lead to incorrect results when the various versions at\ntempt to handle the same unusual or difficult-to-handle inputs, as in the Ariane 5. In addition,\nsuch designs usually involve adding to system complexity, which can result in failures itself. A\nNASA study of an experimental aircraft with two versions of the control system found that all\nof the software problems occurring during flight testing resulted from errors in the redundancy\nmanagement system and not in the control software itself, which worked perfectly. 17 We need\nto devise protection features for software that reflect the \"failure\" modes of software and not\nthose of hardware.\n5.2\nInadequate Review Activities\nGeneral problems with the way quality and mission assurance was practiced were mentioned in\nthe MCO, MPL, and Titan reports. QA often becomes an ineffective activity that is limited\nsimply to checking boxes signifying the appropriate documents have been produced without\nverifying the quality of the contents. The Titan/Centaur accident report makes this point\nparticularly strongly. According to the report, the LMA Quality Assurance Plan is a top-level\ndocument that focuses on verification of process completeness, not on how the processes are\nexecuted or implemented. Its basis was the original General Dynamics Quality Assurance Plan\nwith updates to ensure compliance with ISO 9001. Following this plan, the LMA Software\nQuality Assurance staff only verified that the signoff report containing the software load con\nstants had all the proper signatures; they left the constant generation and verification process\nto the flight software and control dynamics engineers. Software QA involvement was limited\nto verification of software checksums and placing quality assurance stamps on the software\nproducts that were produced.\nReview processes (outside of QA) are also described as flawed in the reports but few details\nare provided to understand the problems. The Ariane 5 report states that reviews including\nall major partners in the Ariane 5 program took place, but no information is provided about\nwhat types of reviews were held or why they were unsuccessful in detecting the design flaws. It\ndoes say that the limitations of the inertial reference system software were not fully analyzed in\nreviews, and it was not realized that the test coverage was inadequate to expose such limitations.\nFor example, the report states \"there is no evidence that any trajectory data was used to analyze\nthe behavior of the three unprotected variables.\" Given that the specifications did not include\nthe Ariane 5 trajectory data, it is unlikely such reviews would have uncovered the problem.\nAn assumption by the Ariane 5 developers that it was not possible to perform a complete\nsystem integration test made reviews, including simulation and analysis, even more important.\nThe Ariane accident report recommends including external (to the project) participants when\nreviewing specifications, code, and justification documents and to make sure that these reviews\nconsider the substance of arguments, rather than check that the verifications have been made.\nThe latter seems to imply that reviewers and assurance personnel may have simply ticked off\non checklists that activities had been performed without reviewing their quality and substance.\nThe MCO report recommends that NASA \"conduct more rigorous, in-depth reviews of the\n\ncontractor's and team's work,\" which it states were lacking on the MCO. The report also con\ncludes that the operations team could have benefited from independent peer reviews to validate\ntheir navigation analysis technique and to provide independent oversight of the trajectory anal\nysis. There is no mention of software quality assurance activities or the software review process\nin the MCO report.\nIn the MPL descent engine control software reviews, apparently nobody attending was\nfamiliar with the potential for spurious Hall Effect sensor signals. The independent MPL\naccident report noted that JPL and LMA failed to ensure adequate independent reviews.6\nThe SOHO accident report states that the changes to the ground-generated commands\nwere subjected to very limited review. The flight operations team placed high reliance on ESA\nand Matra Marconi Space representatives who were quite knowledgeable about the spacecraft\ndesign, but there were only two of them and neither was versed in the computer language\nused to define the commands. A simulation was performed on the new compressed SOHO\ntimelines, but the analysis of a problem detected during simulation was still going on as the\nnew procedures were being used.\nThe Titan/Centaur report was the only one to mention the existence of an independent\nverification and validation review process by a group other than the developers. In that process,\ndefault values were used for the filter rate constants and the actual constants used in flight were\nnever validated. An engineer at the launch site detected the anomalous roll rate data at the\ntime of tower roll back, but he was not able to identify the problem, partly because (according\nto the accident report) he had no documented requirements or procedures to review the data\nand no reference with which to compare.\nConcerns about proprietary software is increasingly preventing external reviewers familiar\nwith the spacecraft from a systems viewpoint from reviewing the software (see, for example, the\nCassini/Huygens communications link enquiry board report.18 The problem is not limited to\naerospace, but is occurring in all industries. Adequate review is not possible when the system\nengineers do not have access to the complete design of the spacecraft.\nIn general, software is difficult to review and the success of such an effort is greatly dependent\non the quality of the specifications. However, identifying unsafe behavior, i.e., the things that\nthe software should not do and concentrating on that behavior for at least part of the review\nprocess, helps to focus the review and to ensure that critical issues are adequately considered.\nSuch unsafe (or mission-critical) behavior should be identified in the system engineering\nprocess before software development begins. The design rationale and design features used to\nprevent the unsafe behavior should also have been documented and can be the focus of such a\nreview. This presupposes, of course, a system safety process to provide the information, which\ndoes not appear to have existed for the projects that were involved in the accidents studied.\nAs mentioned earlier, almost all software-related accidents have involved incomplete re\nquirements specification and unhandled or mishandled system states or conditions. The two\nidentified Mars Polar Lander software errors, for example, involved incomplete handling of\nsoftware states and are both examples of very common specification flaws and logic omissions\noften involved in accidents. Such errors are most likely to be found if spacecraft and subsystem\nexperts participate actively in the reviews.\nSoftware hazard analysis and requirements analysis techniques and tools exist to assist in\nfinding these types of incompleteness. To make such a review feasible, the requirements should\ninclude only the externally visible (blackbox) behavior; all implementation-specific information\nshould be put into a separate software design specification (which can be subjected to a later\nsoftware design review by a different set of reviewers). The only information relevant for a\nsoftware requirements review is the software behavior that is visible outside the computer.\n\nSpecifying only blackbox behavior (in engineering terminology, the transfer function across\nthe digital component) allows the reviewers to concentrate on the information of importance\nto them without being overwhelmed by internal design information that has no impact on\nexternally observable behavior.\nThe language used to specify the software requirements is also critical to the success of such\na review. The best way to find errors in the software requirements is to include a wide range of\ndisciplines and expertise in the review process. The reviewers must be able to read and under\nstand the specifications without extensive training and, ideally, the notation should not differ\nsignificantly from standard engineering notations. While formal and executable specification\nlanguages have tremendous potential for enhancing our ability to understand the implications\nof complex software behavior and to provide correct and complete requirements, most of the\nlanguages created by computer scientists require too much reviewer training to be practical. A\nhigh priority on readability and learnability has not been placed on the development of such\nlanguages.\n5.3\nIneffective System Safety Engineering\nAll of the accident reports studied are surprisingly silent about the safety programs and system\nsafety activities involved. The MCO report cryptically says only that the \"safety and mission\nassurance group was not properly engaged during the operations stage.\" All the reports, how\never, do cite inadequate hazard analysis or component criticality analysis. The MCO report\nnotes that there was an absence of a process, such as fault tree analysis, for determining what\ncould go wrong during a mission to assist in design, reviews, and contingency planning. The\nMPL report also notes inadequate hazard identification: During MPL development, fault tree\nand other hazard analysis activities were used \"inconsistently.\"\nThere did appear to be a criticality analysis performed on the Ariane and MCO projects,\nalbeit flawed ones. The Ariane 5 report recommends reconsidering the definition of critical\ncomponents, taking failures of software components into account (particularly single point fail\nures). Clearly the handling of an overflow in the alignment function by turning off the guidance\nand control computer was flawed. Unfortunately, not enough information is given about how\nthe criticality analysis was performed to determine why it was unsuccessful.\nLike other systemic factors, the Ariane 5 report is silent about the tradeoff analysis process.\nThe report describes the decisions that resulted but not the process used to reach those decisions.\nFor example, the fact that several software variables were unprotected is not the root of the\nproblem: There is always a limit as to how much checking and protection is feasible--spacecraft\ncomputers are limited by size and weight, which in turn limits processor power and memory\nand timing constraints may preclude extensive checking software. The problem was that there\nwas a lack of effective analysis to determine which variables should be protected. Important\ninformation that is missing includes how the analysis and trade studies were performed and what\nadditional information or additional analysis techniques could have allowed better decisions to\nbe made.\nThe MCO accident report also concludes there was \"inadequate identification of mission-\ncritical elements throughout the mission.\" The criticality of specific elements of the ground\nsoftware that impacted the navigation trajectory was not identified, for example.\nThe source of these problems may stem from the common practice of applying the same engi\nneering analysis techniques developed for electromechanical systems (e.g., FMEA and FMECA)\nto the new software-intensive systems. This approach will be limited because the contribution\nof software to accidents, as noted previously, is different than that of purely mechanical or\n\nelectronic components. In particular, software does not fail in the sense assumed by these\ntechniques.\nOften hazard analyses simply omit software, and when included it is often treated superfi\ncially at best. The hazard analysis produced after the Mars Polar Lander loss is typical. The\nJPL report on the loss identifies the hazards for each phase of the entry, descent, and landing\nsequence, such as Propellant line ruptures, Excessive horizontal velocity causes lander to tip over\nat touchdown, and Premature shutdown of the descent engines. For software, however, only one\nhazard--Flight software fails to execute properly--is identified, and it is labeled as common to\nall phases. Such a software \"hazard\" is not very useful--it is equivalent to substituting the\ngeneral statement Hardware fails to operate properly for all the hardware-related hazards noted\nabove. Identifying specific unsafe software behaviors as is done for hardware, such as Software\nprematurely shuts down the descent engines, would be much more helpful during development\nin identifying ways to mitigate risk.\nProviding the information needed to make safety-related engineering decisions is the major\ncontribution of system safety techniques to engineering. It has been estimated that 70 to 90%\nof the safety-related decisions in an engineering project are made during the early concept\ndevelopment stage.19 When hazard analyses are not performed, are done only after the fact (for\nexample, as a part of quality or mission assurance of a completed design), or are performed but\nthe information is never integrated into the system design environment, they can have no effect\non these decisions and the safety effort reduces to a cosmetic and perfunctory role.\nTake SOHO for example. A hazard analysis surely would have shown that the roll rate and\nthe status of gyros A and B were critical, and this information could have guided the design\nof feedback channels to the operators about the current gyro state. A rigorous system safety\nprocess also would have triggered special safety analyses when changes were made to the SOHO\noperational procedures involving safety-critical components. In addition, a strong system safety\nprogram would have ensured that high priority was given to the analysis of previous emergency\nsun reacquisitions, that greater controls were placed on safety-critical operational procedures,\nand that safety-related open operational reports, such as the one reporting the difficulty the\nSOHO operators were having in reviewing telemetry data, did not stay open for four years and\ninstead were tracked and resolved in a timely manner.\nThe description of the MCO problem by the developers15 says that the best chance to find\nand eliminate the problem existed at the early stages of development, but the team failed to\nrecognize the importance of the small forces ground software and it was not given the same\nattention as the flight software.\nThe Titan/Centaur accident provides another example of what happens when such analysis\nis not done. The risk analysis, in that case, was not based on determining the steps critical\nto mission success but instead considered only the problems that had occurred in previous\nlaunches. Software constant generation was considered to be low risk because there had been\nno previous problems with it. There is, however, a potentially enormous (perhaps unlimited)\nnumber of errors related to software and considering only those mistakes made previously, while\ncertainly prudent, is not adequate.\nNot only is such a fly-fix-fly approach inadequate for complex systems in general, particularly\nwhen a single loss is unacceptable, but considering only the specific events and conditions\noccurring in past accidents is not going to be effective when new technology is introduced into\na system. Computers are, in fact, introduced in order to make radical changes in functionality\nand design. In addition, software is often used precisely because it is possible to make changes\nfor each mission and throughout operations--the system being flown today is often not the\nsame one that existed yesterday. Proper hazard analysis that examines all the ways the system\n\ncomponents (including software) or their interaction can contribute to accidents needs to be\nperformed and used in the original development and when making changes during operations.\nAt the same time, system-safety techniques, like other engineering techniques, need to be\nexpanded to include software and the complex cognitive decision making and new roles played by\nhuman operators.11 Existing approaches need to be applied, and new and better ones developed.\nIf system hazard analysis is performed prior to software implementation (not just prior to\ntesting, as is recommended in the MPL report), requirements can be analyzed for hazardous\nstates and protection against potentially hazardous behavior designed into the software logic\nfrom the beginning.\nThe Mars Climate Orbiter accident report recommended that the NASA Mars Program\ninstitute a classic system safety engineering program: 1) Continually performing the system\nhazard analyses necessary to explicitly identify mission risks and communicating these risks\nto all segments of the project team and institutional management; 2) Vigorously working to\nmake tradeoff decisions that mitigate the risks in order to maximize the likelihood of mission\nsuccess; and 3) Regularly communicating the progress of the risk mitigation plans and tradeoffs\nto project, program, and institutional management.4 The other spacecraft accident reports, in\ncontrast, recommended applying classic reliability engineering approaches that are unlikely to\nbe effective for system accidents or software-related causal factors.\nOne of the benefits of using system-safety engineering processes is simply that someone\nbecomes responsible for ensuring that particular hazardous behaviors are eliminated if possible\nor their likelihood reduced and their effects mitigated in the design. Almost all attention\nduring development is focused on what the system and software are supposed to do. System\nsafety and software safety engineers are responsible for ensuring that adequate attention is also\npaid to what the system and software are not supposed to do and verifying that hazardous\nbehavior will not occur. It is this unique focus that has made the difference in systems where\nsafety engineering successfully identified problems that were not found by the other engineering\nprocesses.\n5.4\nFlaws in the Test and Simulation Environments\nIt is always dangerous to conclude that poor testing was the \"cause\" of an accident. After the\nfact, it is always easy to find a test case that would have uncovered a known error. It is usually\ndifficult, however, to prove that the particular test case would have been selected beforehand,\neven if testing procedures were changed. By definition, the cause of an accident can always\nbe stated as a failure to test for the condition that was determined, after the accident, to\nhave led to the loss. However, all the accidents reports studied mention omissions that reflect\npoor decisions related to testing, particularly with respect to the accuracy of the simulated\noperational environment.\nA general principle in testing aerospace systems is to fly what you test and test what you\nfly. This principle was violated in all the spacecraft accidents, especially with respect to soft\nware. The software test and simulation processes must reflect the environment accurately.\nAlthough implementing this principle is often difficult or even impossible for spacecraft, no\nreasonable explanation was presented in the reports for some of the omissions and flaws in the\ntesting for these systems. One example was not testing the Titan/Centaur software with the\nactual load tape prior to launch. Another example was the use of Ariane 4 trajectory data in\nthe simulations of the Ariane 5 software even though the Ariane 5 trajectory was known to\nbe different. The Ariane inertial reference system specification, in addition, did not include\noperational restrictions arising from the implementation and needing to be considered during\n\ntest.\nTesting of SOHO operational procedures was primarily performed using a simulator, but\nthe simulator had not been maintained with all the on-board software changes that had been\nimplemented on the spacecraft, essentially making such testing useless. The MPL touchdown\nsensing software was not tested with the lander in the flight configuration. Various other types\nof test cases were also not included. The JPL MPL report concludes:\nThe laboratory needs to reinforce the system-level test principle of 'test as you fly,\nand fly as you test.' Departures from this principle must be carefully assessed, and\nif they are determined to be necessary, alternative measures, such as independent\nvalidation, should be incorporated. Such items must be reflected in the project\nrisk management plan, communicated to senior management for concurrence, and\nreported at reviews.5\nFor both the Ariane 5 and Mars '98 projects, a conclusion was reached during development\nthat the components implicated in the accidents could not be tested and simulation was substi\ntuted. After the fact, it was determined that such testing was indeed possible and would have\nhad the ability to detect the design flaws. For example, the Ariane 5 report says:\nIt would have been technically feasible to include almost the entire inertial reference\nsystem in the overall system simulations which were performed. For a number of\nreasons, it was decided to use the simulated output of the inertial reference system,\nnot the system itself or its detailed simulation. Had the system been included, the\n[design error] could have been detected.3\nThe same occurred with the Titan/Centaur accident, where default and simulated values were\nused in system testing although the real roll rate filter constants could have been used. Like\nAriane, the Titan/Centaur engineers incorrectly thought the rigid-body simulation of the vehicle\nwould not exercise the filters sufficiently. In addition, the corporate consolidation/evolution\nprocess had led to a loss of knowledge that the test bed could use the actual roll rate filter\nconstants. The current engineers thought only default constants could be used in the test bed.\nEven the tests performed on the Titan/Centaur right before launch (because anomalies had\nbeen detected) used a default set of constants to filter the measured roll rate instead of the\nactual constants, and thus were unsuccessful in detecting the error. After wiring errors were\ndiscovered in the MPL testing process, for undisclosed reasons the tests necessary to detect the\nsoftware flaw were not rerun.\nNot all problems in testing can be traced to the simulation environment, of course. There\nhave been cases of spacecraft losses involving inadequate, inappropriate, and ill-suited testing.\nA basic problem is one of piecemeal testing and not testing at the system level for system-\nlevel effects and emergent behavior. The rush to get the ground software operational after a\nproblem was discovered post-launch in MCO resulted in the testing program being abbreviated.\nFor example, the testing of the ground software changes did not test the correctness of the\nfile formats but simply made sure that the file could be moved across on the file server.14\nAt a November 10, 1999 press conference, Alfred Stephenson, the chief accident investigator,\nadmitted, \"Had we done end-to-end testing, we believe this error would have been caught.\" But\nthe rushed and inadequate preparations left no time to do it right. The problem lies not only\nin testing, but in relying on software that had not been adequately tested without additional\nmanual or other checks to gain confidence. The same lack of system test also contributed to\nthe WIRE (Wide-Field Infrared Explorer Mission) spacecraft where a contributing cause cited\n\nin the accident report was that no system level end-to-end test with live pyrotechnic devices in\nthe as-flown configuration had been done.20\nAnother common problem in software testing is inadequate emphasis on off-nominal and\nstress testing. Most software-related accidents have involved situations that were not considered\nduring development or were assumed to be impossible and not handled by the software. For\nexample, the error in the Ariane exception handling software might have been found if off-\nnominal testing had been performed on the Ariane despite the fact that an incorrect assumption\nabout the Ariane trajectory had been made in the specifications. The recent emphasis on \"use\ncases\" in software testing exacerbates the lack of off-nominal and stress testing. Inadequate\nand unsafe software logic is much more likely to be found when inputs violate the specifications\nthan when they simply test the expected cases.\nBetter system testing practices are needed for components containing software (almost ev\nerything these days), more accurate simulated environments need to be used in software testing,\nand the assumptions used in testing and simulations need to be carefully checked.\n5.5\nInadequate Human Factors Design for Software\nUnderstanding the impact of software design on human error is still in the early stages. Acci\ndents, surveys and simulator studies, however, have emphasized the problems pilots are having\nin understanding digital automation and have shown that pilots are surprisingly uninformed\nabout how the automation works.21,22\nHuman factors experts have written extensively on the potential risks introduced by the\nautomation capabilities of glass cockpit aircraft. Among those problems identified are: causing\nmode confusion and situational awareness problems; providing inadequate feedback to support\neffective monitoring and decision making; creating over reliance on automation; increasing\nworkload during periods of already high workload and decreasing it during periods of already\nlow workload; being \"clumsy\" or difficult to use; being opaque or difficult to understand; and\nrequiring excessive experience to gain proficiency in its use. Not all of this information seems\nto have affected engineering practice.\nAs more sophisticated automation has been introduced into spacecraft control and control of\nsafety-critical functions is increasingly shared between humans and computers, the same prob\nlems found in high-tech aircraft are appearing. Ground controllers rely on indirect information\nabout the object they are controlling. Their effectiveness depends on the information they are\ngiven and the format in which it is presented. Many of the problems found in human automa\ntion interaction lie in the human not getting appropriate feedback to monitor the automation\nand to make informed decisions.\nFor the three accidents studied that involved operators (MCO, Titan, and SOHO), all the\naccident reports mentioned human factors issues. Neither the Mars Climate Orbiter nor the\nTitan/Centaur mission operations personnel understood the system or software well enough to\ninterpret the data they saw as indicating there was a problem in time to prevent the loss.4,7\nAs noted earlier, the MCO navigation operations team did not know that the spacecraft sent\ndown tracking data that could have been compared with the ground data to detect the error\nand to validate the changes in the software. Complexity in the automation combined with poor\ndocumentation and training procedures are contributing to these problems.\nProblems abound in the design of the interfaces between humans and automation. As noted\nearlier, the SOHO operations personnel had filed a report about the difficulty they were having\ninterpreting the telemetry data using the interface they were given. For diagnostic purposes,\nSOHO was designed to store within its on-board computer the last three telemetry frames\n\nthat precede entry into the safe mode, but the ground operators were unable to display this\ninformation in a usable format. If the information had been available to them, the operators\ncould have determined the status of the gyros and avoided the loss. No explanation for why\nthe problem was not fixed is provided in the accident report. Several other places in the SOHO\naccident report also hint at the controllers not having the information they needed about the\nstate of the gyros and the spacecraft in general to make appropriate decisions. The diagnosis of\nthe wrong gyro as the bad one and its subsequent deactivation raises many important questions\nabout the information provided to the operators that are not answered in the accident report.\nThe SOHO report also says that the software had been modified incorrectly by the operations\nteam due to lack of system knowledge of the person making the changes. The flight operations\nteam was not sufficiently versed regarding details of the spacecraft design and its idiosyncrasies,\nand this problem became worse as turnover occurred and there was no time for new personnel\nto take advantages of training sessions.\nComplexity in the automation combined with inadequate documentation and training pro\ncedures are contributing to the problems we are seeing. Sometimes the incorrect assumption\nis made that introducing computers lessens the need for in-depth knowledge by operational\npersonnel but the opposite is true. Some of the spacecraft accidents where operators were im\nplicated involved a failure to transfer skill and knowledge from those who operated spacecraft\nin prior missions, and they were, therefore, unable to detect the software deficiencies in time\nto save the mission. Either the design of the automation we are building needs to be improved\nfrom a human factors engineering viewpoint or new training methods are needed for those who\nmust deal with the clumsy automation and confusing, error-prone interfaces we are designing.\nConclusions\nThis paper has described common factors noted in the accident reports for five recent software-\nrelated spacecraft losses: Ariane 501, Mars Climate Orbiter, Mars Polar Lander, Titan IV B-32,\nand SOHO communications. Some suggestions for ways to avoid these problems were provided\nthroughout the paper, although a comprehensive discussion of how to solve these very complex\nproblems is beyond its scope. The first step in preventing accidents, however, is learning from\nthose that have already occurred.\nComplacency and misunderstanding software and its risks were at the root of all these\naccidents. Software presents tremendous potential for increasing our engineering capabilities.\nAt the same time, it introduces new causal factors for accidents and requires changes in the\ntechniques used to prevent the old ones. We need to apply the same good engineering practices\nto software development that we apply to other engineering technologies while at the same time\nunderstanding the differences and making the appropriate changes to handle them. There is\nno magic in software--it requires hard work and is difficult to do well, but the result is worth\nthe effort.\nAcknowledgements\nThis research was partially supported by a grant from the NASA Ames Design for Safety\nprogram and by the NASA IV&V Center Software Initiative program.\n\nReferences\n1Leveson, N.G., \"Evaluating Accident Models using Recent Aerospace Accidents: Part I.\nEvent-Based Models,\" MIT ESD Technical Paper, ESD-WP-2002-06, June 2001.\n2Weiss, K., Leveson, N.G., Lundqvist, K., Farid, N., and Stringfellow, M., \"An Analysis of\nCausation in Aerospace Accidents,\" Proceedings of the Digital Aviation Systems Conference,\nDaytona, October 2001, pp. 137-147.\n3Lions, J.L. (Chairman) \"Ariane 501 Failure: Report by the Inquiry Board,\" European\nSpace Agency, 19 July, 1996.\n4Stephenson, A., \"Mars Climate Orbiter: Mishap Investigation Board Report,\" NASA,\nNovember 10, 1999.\n5JPL Special Review Board, \"Report on the Loss of the Mars Polar Lander and Deep Space\n2 Missions,\" NASA Jet Propulsion Laboratory, 22 March 2000.\n6Young, T. (Chairman), \"Mars Program Independent Assessment Team Report,\" NASA,\n14 March, 2000.\n7Pavlovich, J.G., \"Formal Report of Investigation of the 30 April 1999 Titan IV B/Centaur\nTC-14/Milstar-3 (B-32) Space Launch Mishap,\" U.S. Air Force, 1999.\n8NASA/ESA Investigation Board, \"SOHO Mission Interruption,\" NASA, 31 August 1998\n9Hopkins, A., Managing Major Hazards: The lessons of the Moira Mine Disaster, Allen &\nUnwin, Sidney, Australia, 1999.\n10Perrow, C. Normal Accidents: Living with High-Risk Technology, Basic Books, Inc., New\nYork, 1984.\n11Leveson, N.G., Safeware: System Safety and Computers, Addison Wesley, Boston, 1985.\n12Lutz, R.R., \"Analyzing Software Requirements Errors in Safety-Critical, Embedded Sys\ntems,\" Proceedings of the International Conference on Software Requirements, IEEE, January\n1992, pp. 53-65.\n13Oberg, J., \"Why the Mars Probe Went Off Course,\" IEEE Spectrum Magazine, Vol. 36,\nNo. 12, December 1999.\n14Euler, E.E., Jolly, S.D., and Curtis, H.H., \"The Failures of the Mars Climate Orbiter and\nMars Polar Lander: A Perspective from the People Involved,\" Proceedings of Guidance and\nControl 2001, American Astronautical Society, paper AAS 01-074, 2001.\n15Hoare, A.A., \"The Emperor's Old Clothes,\" Communications of the ACM, Vol. 24, No.\n2, Jan. 1981, pp. 75-83.\n16Knight, J.C. and Leveson, N.G., \"An Experimental Evaluation of the Assumption of\nIndependence in Multi-Version Programming,\" IEEE Transactions on Software Engineering,\nVol. SE-12, No. 1, January 1986, pp. 96-109.\n17Mackall, D.A., \"Development and Flight Test Experiences with a Flight-Critical Digital\nControl System,\" NASA Technical Paper 2857, Dryden Flight Research Facility, November\n1988.\n18D.C.R Link (Chairman), \"Report of the Huygens Communications System Inquiry Board,\"\nNASA, December 2000.\n19Frola, F.R. and Miller, C.O., \"System Safety in Aircraft Acquisition,\" Logistics Manage\nment Institute, Washington D.C., January 1984.\n20Branscome, D.R. (Chairman), \"WIRE Mishap Investigation Board Report,\" NASA, June\n8, 1999.\n21Sarter, N. D. and Woods, D., \"How in the world did I ever get into that mode?: Mode\nerror and awareness in supervisory control,\" Human Factors, Vol. 37, No. 1, 1995, pp. 5-19.\n\n22Bureau of Air Safety Investigation, \"Advanced Technology Aircraft Safety Survey Report,\"\nDepartment of Transport and Regional Development, Australia, June 1996."
    },
    {
      "category": "Resource",
      "title": "kearney.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/7112cecd79cfcd4f052d062f1d0a505e_kearney.pdf",
      "content": "ARTICLES\nSOFTWARE COMPLEXITY MEASUREMENT\nInappropriate\nuse of software complexity measures can have large, damaging\neffects by rewarding poor programming practices and demoralizing good\nprogrammers. Software complexity measures must be critically evaluated to\ndetermine the ways in which they can best be used.\nJOSEPH K. KEARNEY, ROBERT L. SEDLMEYER, WILLIAM B. THOMPSON,\nMICHAEL A. GRAY, and MICHAEL A. ADLER\nIn recent years much attention has been directed\ntoward reducing software cost. To this end,\nresearchers have attempted to find relationships\nbetween the cha.racteristics of programs and the\ndifficulty\nof performing programming tasks. The\nobjective has been to develop measures of software\ncomplexity that can be used for cost projection,\nmanpower allocation, and program and pro-\ngrammer evaluation.\nDespite the growing body of literature\ndevoted to\ntheir development, analysis, and testing, software\ncomplexity\nmeasures have yet to gain wide accep-\ntance. Early claims for the validity\nof the metrics\nhave not been supported, and considerable criticism\nhas been directed at the methodology of the experi-\nments that support the measures. Nonetheless, new\ncomplexity\nmeasures continue to appear, and new\nsupport for old measures is earnestly sought.\nComplexity\nmeasures offer great potential for con-\ntaining the galloping cost of software development\nand maintenance. Successful software-complexity-\nmeasure development must be motivated by a the-\nory of programming behavior. An integrated ap-\nproach to metric development, testing, and use is\nessential as development should anticipate the de-\nmands of the measure's usage. Testing should be\nperformed with specific applications in mind, and\nwhere possible the test environment\nshould simulate\nthe actual use.\nComplexity\nmeasures have been developed with-\nout any particular\nuse in mind. Lacking a theory of\nO11186 ACM OOOl-0782,/R6/1100-1044 75~\nprogramming behavior, researchers have sought\nmeaningful\napplications through experimentation.\nThe results of these explorations\nare difficult\nto in-\nterpret and provide only weak support for the use of\ncomplexity\nmeasures. Until more comprehensive\nevidence is available, software complexity\nmeasures\nshould be used very cautiously.\nWHAT\nIS COMPLEXITY?\nThe first problem encountered when attempting to\nunderstand program complexity\nis to define what it\nmeans for a program to be complex. Basili defines\ncomplexity\nas a measure of the resources expended\nby a system while interacting\nwith a piece of soft-\nware to perform a given task [3]. If the interacting\nsystem is a computer, then complexity\nis defined by\nthe execution time and storage required to perform\nthe computation.\nIf the interacting\nsystem is a pro-\ngrammer, then complexity\nis defined by the diffi-\nculty of performing tasks such as coding, debugging,\ntesting, or modifying the software. The term software\ncomplexity is often applied to the interaction\nbetween\na program and a programmer working on some pro-\ngramming task.\nUsually these measures are based on program\ncode disregarding comments and stylistic attributes\nsuch as indentation\nand naming conventions. Mea-\nsures typically\ndepend on program size, control\nstructure, or the nature of module interfaces. The\nmost widely known measures are those devised by\nHalstead and his colleagues that are collectively\nknown as software science [ll].\nThe Halstead mea-\nsures are functions of the number of operators and\nCommunications of the ACM\nNovember 1986\nVolume 29\nNumber 11\n\nArticles\noperands in the program. The major components of\nsoftware science are\nq1 the number of unique operators,\nq2 the number of unique operands,\nN, the total number of operators,\nN2 the total number of operands.\nHalstead defined the volume, V, of a program to be\nv = (N* + N2)log2(71 + 72)\nand program difficulty,\nD, to be\n71 x N2\nD=-.\nHalstead derived a number of other measures. The\nmost extensively\nstudied of these is an estimate of\nthe effort, E, required to implement a program:\nE=DxV\nThe cyclomatic number, developed by McCabe [l4]\nhas also received a great deal of attention. McCabe\nconsiders the program as a directed graph in which\nthe edges are lines of control flow and the nodes are\nstraight line segments of code. The cyclomatic num-\nber represents the number of linearly independent\nexecution paths through the program. For a well-\nstructured module, the cyclomatic number is simply\none plus the number of branching statements in the\nmodule. The cyclomatic number is strongly related\nto the Halstead metrics [5, 121. Both are computed\nby counting lexical entities, and it has been shown\nthat the measures are highly correlated. These\ntoken-based methods are strongly related to the most\nsimplistic complexity\nmeasure, a count of the num-\nber of lines in the program.\nThe Halstead and McCabe measures treat a pro-\ngram or procedure as a single body of code. Henry\nand Kafura present a measure that is sensitive to the\nstructural decomposition of the program into proce-\ndures and functions [13]. Their measure depends on\nprocedure size and the flow of information\ninto pro-\ncedures (the fan-in) and out of procedures (the fan-\nout). Henry and Kafura define the complexity\nof a\nprocedure as\nlength X (fan-in X fan-out)2.\nMany other complexity\nmeasures have been de-\nveloped. Those presented here are only representa-\ntive examples of the work in the field.\nMETRIC\nDEVELOPMENT:\nTHE\nNEED\nFOR\nA THEORY\nOF PROGRAMMING\nSoftware complexity\nmeasures attempt to relate the\ncontribution\nof the program to the difficulty\nof per-\nforming programming tasks. One of the reasons that\nNovember 1986\nVolume 29\nNumber II\nthe development of software complexity\nmeasures is\nso difficult\nis that programming behaviors are poorly\nunderstood. A behavior must be understood before\nwhat makes it difficult\ncan be determined. To\nclearly state what is to be measured, we need a the-\nory of programming that includes a model of the\nprogram, the programmer, the programming envi-\nronment, and the programming task.\nProgramming behaviors are very complex and can\nbe influenced\nby the experience and ability of the\nprogrammer, the specific task, the underlying\nprob-\nlem domain, and the programming environment,\nas\nwell as by the properties of the program. Although\nthe experimental\nresults are incomplete, there is\nample evidence to suggest that all of these factors\ncan affect the difficulty\nof performing programming\ntasks. Most complexity\nmeasures have been de-\nsigned without\nregard to the programmer, task, prob-\nlem domain, or environment\nand ignore the stylistic\ncharacteristics of the program. This approach im-\nplicitly\nassumes that the properties of the program\ndetermine the ease of performing programming tasks\nindependent of these other factors. This assumption\nis unsupported. The available results indicate that\nthe contribution\nof the program, that is, program\ncomplexity,\nis highly dependent on nonprogram\nfactors.\nProgrammers are required to perform a variety of\nprogramming tasks including\ndesign, coding, debug-\nging, testing, modification,\nand documentation.\nIt\nshould not be expected that all tasks are equally\ndifficult.\nFurther, it is unlikely\nthat the factors that\nfacilitate or hinder coding will influence\ndebugging\nor maintenance activities in similar ways. A study\nperformed by Dunsmore and Gannon, for example,\nfound that the use of global variables for data com-\nmunication\namong modules decreased error occur-\nrence during program construction\n[8]. However,\nformal parameters proved less error prone for modi-\nfication tasks. Before it can be determined which\ncommunication\nstrategy leads to less complex\nprograms, the task under consideration\nmust be\nspecified.\nExperience surely influences the difficulty\nof the\ntask. Experiential\nfactors include general knowledge\nof programming languages, techniques, and algo-\nrithms, and specific knowledge of one or more appli-\ncation areas. Programming skills developed through\npractice, such as interpreting\nsystem diagnostics, are\nalso important. The factors that contribute\nto the\ndifficulty\nof performing programming tasks may be\nvery different for novices and experts. Soloway and\nEhrlich present evidence that experienced program-\nmers develop schemata for stereotypical action se-\nquences in programs [li']. For example, the pro-\nCommunications of the ACM\n\nArficles\ngrammer may have schemata for a RUNNING\ning of the program. So we would like to develop a\nTOTAL LOOP or for an ITEM SEARCH LOOP.\nThese schemata provide the expert programmer a\nmeasure of program comprehensibility.\nOur study of\nthe understanding\nprocess suggests that the diffi-\nframework for understanding\nthe program and set\nup expectations, for the detailed structure and func-\ntion of program fragments. Soloway and Ehrlich also\nsuggest that expert programmers follow a set of rules\nfor programming discourse-conventions\nsuch as\nchoosing variable names to reflect their function. Al-\nthough schema and discourse rules assist the expert\nin understanding\ntypical programs, violations of dis-\ncourse rules and abnormal program structures can\nculty of understanding\ndepends, in part, on certain\nstructural properties of the program. Now, we have\nspecified what we want to measure, but why do we\nwant to measure it? Just exactly how do we intend\nto use this index? If our measure is to be used as a\ntool to judge the quality of the programs, we must\noperate under a very different set of constraints than\nif the measure is to be used to allocate manpower for\nmaintenance. When a measure is used to evaluafe a\nbe a source of confusion. A pair of experiments per-\nformed by Soloway and Ehrlich suggests that novices\nare less disturbed by unusual structures and usages\nthan experts. They argue that novices have not de-\nveloped a repertoire of programming rules and\nhence have fewer expectations about the program.\nThus, novices are less confused by unconventional\nprogramming practices.\nThe large majority of software complexity\nmea-\nsures have been developed with little regard for the\nprogrammer's work, it had better be the case that\nreductions in the measure lead to improvements\nin\nthe programs; otherwise the use of the measure can\nbe counterproductive.\nWhether or not the users plan\nto use the measure to direct the programming pro-\ncess, one can be sure that, if contracts or salaries are\nat stake, programmers will soon be writing programs\nthat will minimize\nthe measure.\nSome important applications of complexity\nmet-\nrics, such as manpower allocation, do not evaluate\nprogrammer, the programming task, or the program-\nming environment.\nIt is unlikely\nthat the advances\nin software complexity\nmeasurements will be made\nthe quality of the program. For these applications,\nsoftware metrics are used only as descriptive tools.\nThe demands of the measure are much less stringent\nuntil programmers and the programming process are\nbetter understood. This must be achieved by study-\ning programmers and the means they use to con-\nhere. For the example, it is adequate to know that a\nmeasure is strongly associated with the difficulty\nof\nunderstanding.\nThe metric may be useful whether\nstruct, understand, and modify programs.\nor not techniques that cause variations in measure\nimprove the program.\nMETRIC\nDEVELOPMENT:\nThere is an important distinction\nto be made here\nANTICIPATING\nTHE\nUSE\nAdvocates of software complexity\nmetrics have sug-\ngested that these tools can be used to predict pro-\ngram length, program development time, number of\nbugs, the difficulty\nof understanding\na program, and\nthe future cost of program maintenance. Measures,\nthus far, have been designed without\nany particular\nuse in mind. A developer attempts to quantify what\nhe or she considers to be an important characteristic\nof a program and then studies programs with the\nhope of discovering a relationship\nbetween the\nbetween program properties that cause the program\nto be complex and program characteristics\nthat are\nassociated with complexity.\nConsider, for example,\nthe number of program changes made during pro-\ngram development. It has been shown that the num-\nber of changes correlates well (r = 0.8) with errors\n[8]. It would be difficult\nto argue that the changes\nthemselves cause the errors. More likely, the\nchanges are indicative\nof the trouble that the pro-\ngrammer had constructing\nthe program. Although\nprogram changes are associated with the occurrence\nmeasure and some independent\nmeasure of program\nquality.\nSoftware metrics must be designed to meet the\nneeds of the end user. The properties of a metric\ncritically\ndetermine the ways in which it can\nof errors, we would not want to uniformly\nadvocate\nthat programmers should minimize\nthe number of\nchanges made during development. (Although it\nmight be found that some practices, such as extend-\ning the design phase, lead to both fewer changes and\nbe used. This dependency must be kept in mind\nby those who are developing metrics and those\nwho use metrics.\nFor example, let us say that we are interested in\nprogram debugging. Suppose that we have studied\nprogrammers and formed a model of the debugging\nprocess. Our model of the task proposes that effec-\ntive debugging must be preceded by an understand-\nbetter programs.) And, though using the number of\nprogram changes to predict future difficulties\nor di-\nrect debugging efforts might be considered, program\nchanges should not be used for salary review.\nTHE\nPROPERTIES\nOF MEASURES\nSeveral properties of measures determine the way in\nwhich the measure can be used.\nCommunications\nof the ACM\nNovember 1986\nVolume 29\nNumber II\n\nArticles\nRobustness\nIf software complexity\nmeasures are to be used to\nevaluate programs, then it is important to consider\nthe measure's responsiveness to program modifica-\ntions. Not only should the measure be shown to reli-\nably predict the complexity\nof the software, but pro-\ngramming techniques that minimize\nthe measure\nshould be examined to assure that reductions in the\nmeasure consistently produce improvements\nin the\nprogram. In particular,\nit should not be possible to\nreduce the measure through incidental\nmodifica-\ntions of the program. Also, programming techniques\nthat modify the program in a desirable way with\nrespect to one property must not produce an unde-\nsirable change in another property as a side effect. A\nrobust measure of software complexity\nis sensitive to\nthe underlying\ncomplexity\nof the program and can-\nnot be misdirected by incidental\nmodifications\nto the\nprogram.\nSeveral authors have examined the relationship\nbetween complexity\nmeasures and commonly ac-\ncepted axioms for good programming [l, 2, 9, lo].\nTheir strategy has been to study how complexity\nmeasures are affected by following\nmaxims of good\nprogramming style. Halstead's E, the cyclomatic\nnumber, and the number of lines have been exam-\nined for their responsiveness to modularization,\nthe\nuse of temporary variables, initialization\nprocedures,\nand such. The results of these analyses do not pro-\nvide strong support for these measures. For some\nclasses of programs, some measures are reduced by\nsome good programming practices.\nEven if it could be shown that some favored pro-\ngramming technique consistently\nleads to reductions\nin a measure, this is not strong evidence for the\nmeasure's robustness. One problem with this ap-\nproach is that there is only weak evidence that these\nrules actually lead to better programs [15]. More im-\nportantly, this approach is limited because there\nmay also be techniques that reduce the measure and\nworsen the quality of the program. Likewise, just\nbecause a measure is not responsive to some im-\nprovements does not mean that the measure is\nnot valid and robust-it\nis unreasonable to expect a\nmetric to be responsive to all possible improvements.\nWhat must be demonstrated is that reductions in the\nmeasure, however they are achieved, will lead to an\nimprovement\nin the program.\nNormativeness\nThe interpretation\nof complexity\nmeasurements is\nfacilitated if the metric provides a norm against\nwhich measurements can be compared. Without\nsuch a standard, it is meaningless to apply the met-\nric to programs in isolation. To judge whether or\nNovember 1986\nVolume 29\nNumber 11\nnot a program is overly complex, a norm that identi-\nfies some acceptable level of complexity\nmust be\nspecified.\nSpecificity\nSoftware complexity\nanalysis may provide an assess-\nment tool that can be used during program develop-\nment and testing. Designers and programmers could\nuse the measure to find deficiencies in program con-\nstruction. A complexity\nmeasure might also be used\nas a guide to testing and maintenance efforts. The\ndegree to which a measure is able to perform these\nfunctions will depend on how well it specifies what\nis contributing\nto the complexity\nof a program.\nHenry and Kafura, for example, argue that com-\nplexity usually arises from a small number of dis-\nproportionately\ncomplex procedures [13]. Their\nmeasure of information\nflow assigns a value of com-\nplexity to each procedure. The major contributors\nto\ncomplexity\ncan be identified\nby comparing complex-\nity measurements from the set of procedures. Often\nlarge software systems are layered into levels of ab-\nstraction. Henry and Kafura argue that such systems\nshould distribute complexity\nevenly across levels.\nThey suggest that, if the total complexity\nwithin\na\nlevel is large compared to surrounding\nlevels, then\nthere is evidence that a level of abstraction is miss-\ning from the system design. As a demonstration\nof\nthe usefulness of their measure, Henry and Kafura\napplied their measure to a portion of the UNIX@\noperating system. They discovered that their mea-\nsure produced inordinately\nhigh values for one level\nof the system, due largely to the density of inter-\nconnections between procedures at this and adjacent\nlevels. They plausibly argue that the system could\nbe simplified by the introduction\nof another layer of\nabstraction.\nPrescriptiveness\nIf software complexity\nmeasures are to prove useful\nin the containment\nof program complexity,\nthen\nthey must not only index the level of a program's\ncomplexity,\nbut also should suggest methods to re-\nduce the amount of complexity.\nA measure could\nprescribe techniques to avoid excess complexity\nas\nwell as direct modification\nof overly complex pro-\ngrams already written.\nHenry and Kafura's work illustrates how a mea-\nsure can influence program design. Their measure\nheavily penalizes single procedures with a large\nnumber of interconnections.\nThey show how this\ncan encourage modularization\nand simple patterns\nUNIX\nis a trademark\nof AT&T\nBell\nLaboratories\nCommunications of the ACM\n\nArticles\nof module communication.\nNote, however, that this\nis not the only way to minim.ize their measure. The\nsmallest value can be achieved by writing a program\nas a single module with no procedures and, hence,\nno flow of information\nbetween procedures.\nProperty Definition\nThe properties identified\nabove are not rigorously\ndefined, and it is sometimes difficult\nto tell whether\nor not a metric possesses one or another of these\nproperties. Although\nthe preceding list of properties\nmay be flawed, it is essential that the designers and\nusers of software complexity\nmeasures recognize\nthat the properties of measures constrain their use-\nfulness and applicability.\nTESTING\nOnce a measure has been developed, it must be\ntested to be sure it actually measures what it\npurports to measure.\nExperimental\nDesign\nResearchers attempting to validate measures of soft-\nware complexity\nface a methodological\nmorass. An\nenormous number of parameters may influence\nthe\noutcome of an experiment.\nSubject selection, pro-\ngramming language, programming task, and the algo-\nrithms implemented\ncan all profoundly\naffect both\nthe nature of the results and the extent to which\nexperimental\nobservations will generalize to a larger\nset of programming environments.\nThe problem is\ncompounded by the uncertainty\nof how these param-\neters interact to determine programmer behavior.\nWorse yet, there are not even good methods to quan-\ntify parameters such as programmer ability and\nproblem difficulty.\nOnce the programming environment\nis specified,\nthe experimenter\nmust devise a method to manipu-\nlate the independent\nvariable-typically\nsome pro-\ngram property. If research is conducted as a natural\nexperiment\n(observing actual programs produced in\na real work setting), then the problem is to find pro-\ngrams that differ only in the variables of interest.\nThe difficulty\nof obtaining uncontrived\nprograms\nthat vary only in one or two dimensions should not\nbe underestimated.\nNext, a measurement technique for the dependent\nvariable-programmer\nperformance in some task or\nprogram quality-must\nbe selected. A large number\nof human performance variables have been sug-\ngested including\ntime to implement or modify a pro-\ngram, number of debugging runs, number of bugs\ndetected, and level of understanding\nas measured by\nability to recall, reconstruct, and answer questions\nabout a program's function. Program quality has\nbeen assessed by run-time efficiency and number of\nerrors. Detailed analysis of the problems associated\nwith subject selection criteria, manipulation\nof pro-\ngram properties, and choice of performance mea-\nsures can be found in [1.5].\nThe uncertainty\nof how complexity\nmeasures re-\nlate to one another and to performance measures has\nled to a style of experimentation\nthat is exploratory.\nFaced with an enormous number of variables, many\nresearchers have chosen to examine multiple\ncombi-\nnations of program properties, environmental\nparam-\neters, and performance measures. Such experiments\ntend to become probes for viable hypotheses rather\nthan tests of specific predictions. Dunsmore and\nGannon, for example, examined the importance of\nfive program properties in construction\nand mainte-\nnance tasks [8]. They studied construction\nin two\nprogramming languages and separated subjects in\ntwo groups based on the experimenter's\njudgments\nabout the quality of their performance. Their experi-\nment includes a total of 20 different statistical tests.\nWhen large numbers of experimental\nconditions are\nexamined, the likelihood\nof finding accidental rela-\ntionships is high. The unfortunate\nconsequence of\nthis practice is a substantial inflation\nof the probabil-\nity of making a type I error-inferring\nthe existence\nof a nonexistent\nrelationship.\nTherefore, the experi-\nmentwide confidence in these results is sharply\nreduced.\nConsider a series of three experiments,\nperformed\nby a research group at General Electric, testing the\nHalstead and McCabe measures against a simple\ncount of program lines [6, 7, 161. Across the three\nexperiments, a total of 170 statistical tests are re-\nported (correlations between pairs of complexity\nmeasures and between complexity\nmeasures and\nperformance measures). More recently, Basili and\nHutchens examined a family of related complexity\nmeasures [4]. They report 120 correlation\ncoeffi-\ncients and mention another set of tests that were\nperformed but not given because the correlations\nwere not significant.\nThe likelihood\nof obtaining a\nstatistically\nsignificant\nresult due to sampling error\nor measurement error for any one or any small set\nof tests is quite high when the number of tests\nis as large as in these experiments.\nExploration\nas an Experimental\nParadigm\nDisregarding the statistical significance of the find-\nings, how good a strategy is this approach? There are\nseveral reasons why these explorations\nare unlikely\nto be productive.\nIt is possible to devise an enormous\nnumber of measures based on intuitions\nand intro-\nCommunications of the ACM\nNovember 1986\nVolume 29\nNumber 11\n\nArticles\nspection about programming. The likelihood\nthat\nany one of these will reveal insights into a behavior\nas complex and intricate as programming is small. If\nan index of comprehension\nis wanted, the processes\nby which programmers come to understand pro-\ngrams should be studied first. If an index of errors is\nwanted, the causes of errors must be determined.\nRobust, prescriptive\nmeasures of complexity\nwill\nprobably not be found by groping for relationships\nbetween the surface features of programs and pro-\ngram or programmer behavior.\nEven when a large correlation is discovered, the\nfinding often has little practical value. Without an\nunderstanding\nof the underlying\nprocesses that lead\nto the association, it is difficult\nto know how to use\nthis result to advantage. The existence of a linear\nrelationship\nbetween a measure of program size and\nthe number of bugs in the program does not mean\nthat program size is a good predictor of errors. Nor\ndoes it suggest that program size should be mini-\nmized to minimize\nthe number of errors. It is also\ntrue that the weight of basketball players is highly\ncorrelated with scoring ability. This does not mean\nthat we should choose players by weight or force-\nfeed players to raise their scoring averages.\nIt would be surprising if the number of bugs in a\nprogram were not related to the size of the program.\nIf it turned out that a specific linear relationship\nheld over a population of programs, implementing\na\nvariety of problems, written by many programmers,\nthen this measure could be considered as the mea-\nsure to predict bugs.\nThe danger of these experiments is that the results\nare easily misinterpreted.\nThe potential for misinter-\npreting is illustrated\nby Basili and Hutchens' [a] re-\ncent study. Motivated by an analysis of several syn-\ntactic complexity\nmeasures, Basili and Hutchens\nproposed a measure, Syntactic Complexity\n(Sync),\nwhich is a hybrid of volume and control organiza-\ntion measures. They.attempted\nto validate the mea-\nsure by looking for a relationship\nbetween program\nchanges made during development, which are corre-\nlated with errors (r = 0.8) and Sync. The study was\nbased on 18 compilers written by student program-\nmers. No significant correlations were found over\ngrouped data, so the authors examined each individ-\nual's programs separately. They found that for a\ncollection of program segments written by a single\nprogrammer Sync and program changes were well\ncorrelated (r = 0.8). Lines were fitted to each pro-\ngrammer's data. A graph of the results is presented\nin Figure 1. Basili and Hutchens noted the variation\nin the slope of the best-fit lines and proposed that\n\"the slope of the line may be viewed as a measure\nNovember 1986\nVolume 29\nNumber 11\nof a programmer's ability to cope with complexity\nsince it estimates the number of program changes he\nmakes in developing a program for each unit of com-\nplexity.\"\nThey conclude that \"slope . . . measures the\nrelative skills of programmers at handling a given\nlevel of complexity\"\nand suggest that the measure\nmay eventually\nbe used in managerial decisions.\nThis inference is unwarranted\nfrom the data. An\nequally plausible explanation\nis that those program-\nmers with steep slopes worked harder, made more\nchanges, and consequently\nfound a better solution,\nwith a lower value of Sync. Under this interpreta-\ntion a high slope indicates a greater ability to deal\nwith complexity.\nNeither interpretation\nis justified\nby the results. The confusion can be attributed to a\nmisunderstanding\nof the meaning of the correlations.\nFor individual\nprogrammers, Sync is only correlated\nwith changes that are correlated with errors. Changes\nare not errors and Sync is not complexity.\nThe slope\nof the line that relates program changes to errors\n(unmeasured in this experiment)\nmay vary between\nprogrammers. On the basis of the evidence, the\nchanges of one programmer cannot be equated to\nthose of another.\nThe relationship\nbetween program changes and\nSync is serving double duty. Let us assume, for the\nsake of the argument, that errors are in constant\nproportion to changes for all programmers. The cor-\nrelation between changes and Sync is first used to\nestablish Sync as a measure of complexity-more\nspecifically\nas a predictor of errors. The slope argu-\n90 -\nAd hoc individual\n80 -\nregression\nlines\n70 -\n60 -\nSync\nFIGURE 1. Each Line Is a Regression Line Relating Sync to\nProgram Changes for Program Modules Written by a Single\nProgrammer (reprinted with permission 0 1983 IEEE)\nCommunications of the ACM\n\nArticles\nment then treats Sync as an independent\nmeasure\nof complexity.\nTwo programs of equal length, gen-\nerated by different programmers, are considered to\nbe of equal complexity;\nif one programmer made\nmore changes than another to implement his or her\npiece of software, then he or she is judged to be less\ncompetent. But remember, in this experiment\nstu-\ndents implemented\nthe same problem. By the slope\ncriteria, a programmer can implement the same\nproblem with lower Sync and make fewer changes\nand cause fewer errors, but will be judged less com-\npetent than another programmer because the ratio of\nchanges to SynC is greater.\nIt can be argued that, with limited understanding\nof programs and programming, exploratory\nwork is\nnecessary to provide direction for further study. Ex-\nperiments that examine the relationship\nbetween\nprogram properties and programmer behavior, such\nas the Dunsmore and Gannon study, can serve to\nfocus attention on particular\naspects of the program-\nming process. However, it should be realized that\nthese experiments are not sufficient\nto justify the\nuse of complexity\nmetrics. Another phase of testing\nis needed that is directed toward a particular\nappli-\ncation. The properties of the metric must be exam-\nined to be sure that the metric is appropriate for the\nsuggested use; specific, testable hypotheses must be\ngenerated. The experiment\nshould mimic the antici-\npated application as closely as possible.\nCONCLUSION\nSoftware complexity\nmeasures have not realized\ntheir potential for the reduction and management of\nsoftware cost. This failure derives from the lack of a\nunified approach to the development, testing, and\nuse of these measures.\nA suggested approach for the creation of complex-\nity measures: Before a measure can be developed, a\nclear specification\nof what is being measured and\nwhy it is to be measured must be formulated. This\ndescription should be supported by a theory of pro-\ngramming behavior. The developer must anticipate\nthe potential uses of the measure, which should be\ntested in the intended arena of usage.\nComplexity\nmeasures currently\navailable provide\nonly a crude index of software complexity.\nAd-\nvancements are likely to come slowly as program-\nming behavior becomes better understood. Users of\ncomplexity\nmeasures must be aware of the limita-\ntions of these measures and approach their applica-\ntions cautiously.\nBefore a measure is incorporated\ninto a programming environment,\nthe user should be\nsure that the measure is appropriate for the task at\nCommunications\nof the ACM\nhand. The measure must possess the properties de-\nmanded by the use. Finally, users should always\nview complexity\nmeasurements with a critical eye.\nREFERENCES\n1. Baker, A.L. The use of software\nscience in evaluating\nmodularity\nconcepts. IEEE Trans. Sojfw. Eng. SE-S, 2 (Mar. 1979), 110-120.\n2. Baker, A.L., and Zweben, S.H. A comparison\nof measures of control\nflow complexity.\nIEEE Trans. Softw. Eng. SE-6,6 (Nov. 1980).\n506-512.\n3. Basili, V.R. Qualitative\nsoftware\ncomplexity\nmodels: A summary.\nIn\nTutorial on Models and Methods for Software Management and Engi-\nneering. IEEE Computer\nSociety Press, Los Alamitos,\nCalif., 1980.\n4. Basili, V.R., and Hutchens,\nD.H. An empirical\nstudy of a syntactic\ncomplexity\nfamily.\nIEEE Trans. Softw. Eng. SE-g, 6 (Nov. 1963),\n664-672.\n5. Basili, V.R., Selby, R.W., Jr., and Phillips,\nT. Metric\nanalysis and data\nvalidation\nacross Fortran projects. IEEE Trans. Softm. Eng. SE-g. 6\n[Nov. 1983), 652-663.\n6. Curtis, B., Milliman.\nP., and Sheppard, S.B. Third\ntime charm:\nStronger prediction\nof programmer\nperformance\nby software\ncom-\nplexity\nmetrics. In Proceedings ofthe 4th IEEE Conference on Software\nEngineering. IEEE Computer\nSociety Press, Los Alamitos.\nCalif., 1979,\n356-360.\n7. Curtis, B., Sheppard, S.B., Milliman,\nP.. Borst, M.A.. and Love, T.\nMeasuring\nthe psychological\ncomplexity\nof software\nmaintenance\ntasks with the Halstead and McCabe metrics. IEEE Trans. Softw. Eng.\nSE-5, I (Jan. 1979), 45-50.\n8. Dunsmore,\nH.E., and Gannon, J.D. Analysis\nof the effects of program-\nming factors on programming\neffort. I. Syst. Softw. I, 2 (Feb. 1980),\n141-153.\n9. Evangelist,\nW.M. Software\ncomplexity\nmetric sensitivity\nto program\nstructuring\nrules. I. Syst. Softw. 3, 3 (Sept. 1983), 231-243.\n10. Gordon, R.D. Measuring\nimprovements\nin program clarity.\nIEEE\nTrans. Softm. Eng. SE-5, 2 (Mar. 1979), 79-90.\n11. Halstead, M.H. Elements of Software Science. Elsevier\nNorth-Holland,\nNew York, 1977.\n12. Henry, S., and Kafura. D. On the relationship\namong three software\nmetrics. Perform. Eval. Rev. IO, 1 (Spring 1981). 81-88.\n13. Henry, S., and Kafura, D. The evaluation\nof software\nsystems' struc-\nture using quantitative\nsoftware\nmetrics. Sofk\nPmt.\nExper. 14,\n6 Uune 1984). 561-573.\n14. McCabe, T.H. A complexity\nmeasure. ZEEE Trans. Soffw. Eng. SE-Z, 6\n(Dec.1976). 308-320.\n15. Sheil, B.A. The psychological\nstudy of programming.\nACM Comput.\nSum 13,l\n(Mar. 1981), 101-120.\n16. Sheppard, S.B., Milliman,\nP., and Curtis. B. Experimental\nevaluatjon\nof on-line program construction.\nGE Tech. Rep. TR-79-388100-6,\nGeneral Electric,\nDec. 1979.\n17. Soloway, E., and Ehrlich,\nK. Empirical\nstudies of programming\nknowledge.\nIEEE Trans. Sojfw. Eng. SE-IO, 5 (Sept. 1984). 595408.\nCR Categories\nand Subject Descriptors:\nD.2.8 [Software\nEngineer-\ning]: Metrics-complexity\nmeasures; software science; D.m [Miscella-\nneous]: software psychology; K.6.3 [Management\nof Computing\nand In-\nformation\nSystems]: Software\nManagement\nGeneral\nTerms: Human Factors. Measurement\nAuthors'\nPresent Addresses: Joseph K. Kearney,\nDept. of Computer\nSci-\nence. Cornell\nUniversity,\nIthaca, NY 14853; Robert L. Sedlmeyer,\nDept.\nof Computer\nTechnology,\nPurdue University.\nWest Lafayette,\nIN 47907;\nWilliam\nB. Thompson,\nDept. of Computer\nScience, University\nof Minne-\nsota. Minneapolis,\nMN 55455; Michael\nA. Gray. MCC, Austin,\nTX 78712;\nMichael\nA. Adler, Control\nData Corporation,\nBloomington,\nMN 55440.\nPermission\nto copy without\nfee all or part of this material\nis granted\nprovided\nthat the copies are not made or distributed\nfor direct commer-\ncial advantage,\nthe ACM copyright\nnotice and the title of the publication\nand its date appear, and notice is given that copying is by permission\nof\nthe Association\nfor Computing\nMachinery.\nTo copy otherwise,\nor to\nrepublish,\nrequires\na fee and/or\nspecific permission.\nNovember\nVolume\nNumber"
    },
    {
      "category": "Resource",
      "title": "leveson.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/16e8fb91482d19558712fbf4cedc32b0_leveson.pdf",
      "content": "! #\"$\n%\n\n&\n')(\n*\n$(\n+-,.$,\n/0214357698:<;>=?;A@CB?1\nDE14FG=?;IHJ@KFGLM5NBPORQS02@KTFU14V2LKB?1\nWE;A3>;IX9YZ;IH\\[I]^_[a`P`Pb\nc?dfehgjiakmlonmpAdoqsrIgutvl4lxwaq)y{zAlfzAdoq|n}y~n}zAd4aqsjr2}4n}lxwAqsdo4wq|rIgjxtMn}qsdoqsr2>gjdxgjfhe\n\nzAdloqstowAian}jnk}egj'towaJiak}giak.fnyJfllxwKl'lfwaqgjiAyn}dfKlxgunJiiaqMtsqMfoJdfe9lxn J}q\nknn>rEpAdxqMrIgjtslfgun}iaRgjgj'pAjeian}l}Kgj{KAuqJ'iAfloqM}r2lxwAn}zak}whl_ZnJzAurunn}EKl\nlxwAqpa}flJiartszIdxdoqvihllJlxq'nJyZfn}y{l*Kdoq'qsiak}giaqMqvdxgiak JiarzaxqlxwAgj<hguqs)p~n}gilRlxn\nyn}df¡zA{Kloqfn}¢q¡wehp~n}lxwAqMxqsK£n}zIl<)wJlRlfwaq¡y{zAlxzIdoq ¤¥a¦K§ a(c)¡wAn}ur2~lxwJlRgjM2fn}¢q\nn}y lxwaqRpKlxwa$n}zAjr#jgj}q<lonxqsqzA$loJqJ\n«\nn}y{lZJdoq#qviak}giaqMqvdxgjiAk¬w}¡tsn}¢q¬unJiakZefgiatMq¢lxwaqglxgjqM(r)Kiar\\lxwAq Adol\nJlfloqs'pAlx¡lonEKq#n}zAd(r)Aqsur gilxnJi9qsiakJgjiaqsqsdxgiakrIguftsgpAjgiaq}iy}tslMlfwaqAdol\nflxqspa¡giatszarAqsrlxwaq iaJ q'gjlxxqsy°±)wAgjtow doqs2AqMtslxqMrlxwaq kn3Jn}y$gjihlxdxn>r>zatsgiak¬qviak}g\niaqsqsdxgiakμrIgjxtvgjpAgjiaqgjihlon lxwaq xn}y{lZJdoq#rIqsqvun}pI qvilpAdontMqsxM\n\nzAd¡}towAgjqsqv qvihlo\nlonZJdorlxwIgu4kn3JIgjiatvjzarAq|Rk}dxqJlxqsd4zAiarAqvdolJiar>gjiakn}y£lfwaq)don}jq)n}yPKaflfd}tvlxgunJi Kiar\nxqvpJdoJlxgjn}i\\nJy)tMn}iAtMqsdfiagi\\fn}y{lZJdoq¢qsiak}giaqMqvdxgiakA?lxwaqgjihlxdxn>r>zatslfgun}in}y*¢nrIzA{Kdf\ngjleJiarlxwaq#ianJlxgunJia¡n}y_Exn}y{lZJdoqjgyqtsetvuq}4pAdxn>tsqMxs¢q}zAdoqv qvihl*Kaflfd}tvl\nfp~qMtvgjatMJlxgjn}ia|Jiar#ianJlJlfgun}iasAqslxt}\n¶nl_n}ylxwaqsxqmgurAqM}$tMn}¢qmrIgjdxqMtvlxje y{don}·qviak}giaqMqvdxgjiAkAaJlxwan}zAk}wlxwaqve#iaqMqsrAqMr\nlon.£qEJraJpAlxqMr-lon.lxwaq¬zIiAgu 3zaq¬pIdon}Ajqs¢¢lfwJl#Kdxgufqgi-ZnJdxhgjiak)glxw1r>gjo~qsdoqvihl\nJiarμ¢n}dxq¡Jalxdo}tslR JloqvdxguJus_»lxwanJzak}wEwJdxrIZJdoq(r)qviak}gjiAqMqsdxRJdxq(r)Jufn gjih}n}j}qMr\ngjirAqMguk}iP1⁄4lfwaqseJdoqkJzAgurAqsrJiar jg¢gloqsrhe\\lfwaqiJlfzAdKZ{$¡nJy|lfwaq JloqvdxguJu\n)gjlfw)wIgutow¬lfwaqsgd$rAqMguk}iA|¡zAfl$£qmgj'pAjqs¢qsihloqsr2\n«\nn}y{lZJdoq 1⁄2¿3⁄433⁄4Ax1⁄2}Ao¤ZianJl|lxn'wa}q\nlxwAqMxqoK qRlehp£qs_n}y iJlfzAdKPjgj'gjlxMhAzAl$lon~qmgiAAiAgloqvje 2AqvgjAjqJiarJuqMJAuqJ\niAdxqJgjle}lxwAqjg¢glo¡q¿gufl¢AzAl Jdoq fg¢pIjejqMx'n}hhgun}zAJiar9 nJdoqdoqsuJloqsr9lxn\njg¢glJlfgun}iA4giwzIJi¬JAgjglxguqslfwJi jg¢glJlfgun}ia1⁄4gi lfwaqRpAwhefgutMJPn}dxjr2\ncZwhzalfwaq(r)AdolAy{le¬eqKdo eμ~q'towaJd}tvloqvdxguAsqMr\\}mn}zAdmuqMJdxiAgiakJ~n}zAlmlxwAq\njg¢glo?n}yn}zAd±aqsjr2)wAgutow¢JdxqZgjihlfgj JloqvjeR~n}zAiar¡zAp)glxw(r)lxwAq*jgj'gjlx?n}ytMn}'pAuq¿gjle\n)gjlfw(r))wAgutowwhzA Jia1⁄4tMJi'tMn}p~q}\n\nzAd±lonn}u±Jiar(r)loqstowAiAgu 3zaqsJdoq*zafqMrlonm}ffgjfl1⁄4zagi\nrAqMJjgiak¢)glxwμlfwAgutMn}'pAuq¿gjlelxwaJl_gjM~lxn waqvjpμ Jqn}zAd<efloqv <gihloqsuqstslxzaJje\nA\n\nJi}k3KAuqJ±A\\qmrAnlxwIgu*he#gj'p£n}fgjiAk¡n}i lxwaqmxnJy{l*JdxqrIqsqvun}pI qvil|pAdxn>tsqMx$lxwAq\nrIgjxtsgpAjgiaq_lfwJl)iJlfzAdoqmgj'p~nxqs)n}ilxwaqRwJdxrIZJdoqqsiakJgjiaqsqsdxgiak(r)pAdontMqsxsA.qwa}q\n~qMqsiEjqJdfiAgjiAk )wJl<lehp~qMRn}y4r>guxtvgjpAgjiaqJdxqiaqstMqMfoJdfeJiarμwAnC7lon¢£qsflRqviAyn}dotsq\nlxwAqs\nÆZqMgurAqs1⁄4qsiakJgjiaqsqsdxgiakRJiAr¡Jia}kqs¢qsihl±rIguftsgjpIjgjiAq}CZqZwa}q$Jufn_~qMqsijqJdfiAgjiak\nwanClon JpApAe Jlfwaqs JlxgjtJPdfguknJd_KiarμrIgjxtsgpAjgiaqRlonfn}y{lZJdoq¡rIqsqvun}pI qvilM<c?n\nlxwIguqsiar2Kie'n}y£lxwaq|pAgun}iAqMqsdxZn}y2n}zAdaqsjr wq<wan)i#lxwaq|doqv{Jlfgun}iawAgjp'n}y2xn}y{l\nZJdoq)glxwμ Jlfwaqs JlxgjtMJiarμlfwaqzafq¡n}y1⁄4 JlxwaqvKlxguts|giExnJjhgjiak¢n}zAd<pIdon}Ajqs¢M\ncZwaqsxq$}towAgjqs}qs¢qsihlo1⁄4gjiAtsjzArAqlfwaq*Kgjn}KlxguAMJlxgjn}in}yapAdxnk}dK¢'gjiak${Kiak}z}k}qMKiar\nraJlo¡lep~qMsayn}dx J£}qsdfgjatMJlxgjn}iPJiar#yn}dfK2fp~qMtvgjatMJlxgjn}iJiarJiJefgus\n»lxwan}zAk}wZqRwqmtsn} qm¡jn}iak¡Ze gji#AzAgurIgiaklfwaqmqsiak}giaqMqvdxgiakJiar# JlxwI\nqs JlfgutK±yn}zAiAraJlxgjn}ia<nJyZfn}y{l*KdoqqsiakJgjiaqsqsdxgiakJiarEgiEgj'pAdonhgjiak n}zAdJAgjgle lxn\nAzAgurEtMn}'pAuq¿Exn}y{lZJdoqJ|Jl lfwaq¬xJ q lxg qlxwaqpAdon}Iuqs¢ZqEKdoqEJlfloqv¢pAlfgjiak\nlonfn}j}q w}q ~qMqviAkqvlxlfgjiakE¢n}doq#rIgE'tszAl ¶¬Ji2EEdoqM}tow-KjZe'xqsqs¢lxn.q¿h\ntMqsqMrμwAgj_k}do}fp2<cZwaqpIdon}Ajqs¢<Jdxq¡Jjxn¢towJiak}giak gi¬lxwAqsgjd|y{zAiarAJ qvihlJiJlxzIdoq}\ncZwaq'qJdfjgjqsdmqs'pAwJfguRnJi\\qvE¢tvguqviatsew}mwAgjy{lxqMrlonJi\\qv¢pIw}fgjmn}i\\tsn}dxdxqMtvlxiaqsx\nJiar'zAlxgjgle}4Zq_~qMtsn}¢q|giatsdxq}gjiak}e(r)rAqvp£qviarAqsihl)nJi#tMn}'pAzAlxqsdxgi#JpApIjgutMJlxgjn}ia\n)waqvdoqRunfxqs)rIzaq<lon(r)tsn}'pAzAloqvd$qsdfdon}dx$Jdoq_p~n}lxqsihlxguJje'whzak}q}4I1⁄4tMn}iAn}¢gjt<tMnJiafgjrAqsd\nJlfgun}ia<wa}q¢giatsdxq}fqMr.lfwaqqs'pAw}gumn}idoqvzaxq¢JiardoqvzaoJIuq'tMn}'p£nJiaqsihlos¢»|iar\nJlxwan}zAk}wn}zAdmqKdxjeμrae>mqsdoqAuqMrμ)glxwAzAgurIgiak iaqvIxn}y{lZJdxq}?Zq¢Jdoq(r)¢n}doq\nJiar¢n}doqtMnJiafzA¢qMr)gjlfw.lfwaq'pIdon}Ajqs¢Rn}yZ JgiloJgjiIgjiak#Kiar\\qvn}giak qvgulxgjiAk\nxnJy{l*Jdxq}mi}rAr>gjlxgjn}iP~}<n}zId<feloqs¢mk}donCAgjkkqsd_JiarμdxqM 3zAgdoquJdokqloqMJ n}y\nrAqsfgukJiaqsdxMq#wq floJdxlxqMrlonqvIJ'gjiaqlfwaq#*ewzIJiA'tsn}juJ~n}dJlxqJiArlxn\nrAqvgjxqRZe|lon'}xgul|lfwaqsIlon(r)ZnJdx#lon}kqslfwaqsd|qso~qMtvlxgqse\ncZwaqMfqxJ¢q<lxdoqviarA))gj2tsn}ihlxgjihzaqRgi#lxwaqRiaq¿>l)Iy{leeqMJdos)glxw#p~qsdfwJpa$qs}qsi\nuqsxRqv¢pAwa}fgjRn}itMnrIgjiakJiarE nJdoq(r)n}iElfwaqn}lxwaqvd}fp~qMtvlomn}y4lxwAq(r)xn}y{lZJdoqqviak}g\niaqsqsdxgiak<pAdxn>tsqMxs4ÆzAllfwaqsdxq))gjj~qZiaqsEtowJuqviakqM4Kiar¡p£qvdxwKpaiaqs-JpApAdxn3}towaqs\nJiar#r>gjdoqstslfgun}ialxwKlZ)gj£q_dxqM 3zAgdoqMrlxn¡xnJjqlxwaq_pIdon}Ajqs¢Zn}yPlfwaq_iaq¿l)tMqvilfzAdxe}\nc?n}rArIdxqMx(r)lfwaqMfq#towJjjqsiak}qMMq eiaqsqMr lonEwAgjy{ln}zAd(r)qv¢pAwa}xqs¢Kiaryn}jjn\nxnJ q<iaqvIpJlfwaM\nyn}zAdpAdxn}Ajqs¢gjiAzAgjjrIgjiAk<Jiar¡gihloqsdo}tslfgjiak)gjlxw¡tMn}'pAuq¿¡efloqv 4KdoqZdxqJje\ndonn}lxqMr¢gi¢gihloqsuqstslxzaJaKi}k3JIgjjgle¡Kiar¢whzA Ji gj'gjlx±gji¢Jia}k}gjiAktsn}'pAuq¿>gle\nlxwAqsi Zqm)gj£iaqsqMrlxn¢lxdxqslotowlxwaqsxqmjg¢glo4lonAzAgjjr#qs}qsd| n}dxqRtMn}'pAjqv#efloqv s\nÆzAl}gut¢whzA JiKAgjgjleμgjianJl¡towJiAk}gjiakI¬c?nμfzAtMtMqsxy{zAje.AzIgjur\\JiarnJp£qvdJlxq\nqs}qsd¢n}doqμtsn}'pAuq¿-e>loqv s_ZqE)gj|iaqMqsrÐlxnAiar1*e#lonN1⁄2}§}N}O AvOaOwhzA Ji\nJAgjgle?£n}lfwgji\\loqsdf n}y$feloqs rAqMguk}iAqsdo¡Jiar feloqsOzaxqvdosE»_towAgjqshgjiaklxwAgj\nkn3K_¢£qvjguqvqJ_)gj<doqs hzIgjdoq.JzakJ qvilfgjiakn}zId¬qviak}gjiAqMqsdfgjiakEJiarO JlxwaqvKlxgutMJ\nyn}zAiAraJlxgjn}ia*)glxwgurAqM})y{don}ItMnkJiAgjlfgjq<pAfetowan}jnk}eJiAr lfwaqmxntsg{KPxtvguqsiAtMqMs\nA1wAgjjq*n}zAd±Adol×}Ø_eqMJdo1⁄4wq)fqMqvi¢za1⁄4rIqsqvun}p'n}zId4tMn}iatsqspAlx4n}yxn}y{lZJdoq$J4Ji\nqsiAk}gjiaqsqsdxqMr¡pAdxn>rIzAtsl1⁄4Kiar(r) JlxwAqs JlxgjtJhn}>UqMtslMuqsxKlxloqvihlxgunJi¡w} £qsqsi(r)yntszafqMr\nU\n\nn}ifn}y{l*Kdoq}whzA Ji pAdxn>r>zatsl'JiAr n}itMn}'pAzAlxqsdx}¡rAqvgjtMqs¡lxwJlgjihloqvd}tvl\n)gjlfw Jiar}ffgjfl)whzA JiamUUJ*n}pAp~nxqsr#lon¡doqvpA{JtsgjiAklxwaqv#U¿\n«\nn}y{lZJdoqRqviak}giaqMqvdxgjiAk\ngu_pAdon}Iuqs fn}jhgiak_JtslxghgjleJiar(r)xnJy{l*Jdxq$qsiak}giaqMqvdxgiak_loqstowAiAgj hzAqMJiar¡lonn}jJdxq\nzafqMr¬lxn }ffgjfl$whzAKia|gilfwAgu|}tvlxggleY1lxwAqqvo£qstslfgjqviaqMf<n}y±n}zAd$lonn}u$tsn}zAur~q\nk}dxqJlfje¬giatsdxq}fqMrgjyZq}fqMrlxwaqvgjdmrAqsfgukJi\\n}iftsguqvihlxgjAthian)jqMrAkq¢J~n}zAlRwan\nwhzA Jia)xnJjq<pIdon}Ajqs¢M\n\nzAd*xn}y{lZJdoqRpAdxn>r>zatslx$JdoqRKuxn¡zAxqMrn}dZ n}iIgjlonJdoqMr¢e\nwhzA JiaMIJiar lfwaqZe lfwJln}zAd*fn}y{lZJdoq_gjZrAqsfgjk}iaqMr¢longilxqsdo}tsl)gjlxw¢whzAKiagj\n(r)tsdfgjlxgjtJ~y}tslxn}d$gji#)waqvlxwaqvdlfwaqmxn}y{lZJdxqgj*zaxqvy{zA?lonn}d)zaxJAuqRhelfwaqs\nA1waqsi¢tsdxqJlfgjiak<iAqs-fn}y{lZJdoq$qsiAk}gjiaqsqsdfgjiak<¢qslfwan>rI4Jiar(r)lonn}usJq$n}y{loqvi'gi}r>\nqvdxlxqsihlxeqsiAyn}dxtMq)pJdflxgjtszAuJdpAdxn}Auqv' xn}hgjiakflxdoJloqsk}guqsMhn}y{lxqsilxwaq$n}iAq$pIdoqsyqvdxdxqMr\nheElfwaqμrAqsfgjk}iaqsdn}yRlxwaq qvlxwanr-n}dlxn>nJOA\\q¬iAqMqMr1lxn\\uqMJdxi-¢n}dxqμJ~n}zAl¢wz>\nJipAdon}IuqsÞxn}giakAIpaJdxlfgutszI{Jdfje')gjlxw doqsfp~qMtvllxn¢fn}y{l*Kdoqqsiak}giaqMqvdxgiak'lo}fs\nJiar¬k}gj}qn}zAd_flfzarAqsihlxm¢£qvlxlxqsd<kJdon}zAiArIgjiak'gji¬tMnk}iIgjlxgqpafetowan}jnk}e}<ßan}d<q¿IJ'\npAjq}hpafetowan}jnk}gjflowq|yn}zAiar lfwJlian}ln}iAerAnpAdxn}Auqv' xn}hgjiakRlxdKloqMkJguqMJJdxe\nJ¢n}iakμgiarIgjhgjrIzJjM±AzIl'giarIggjrIzJjJJdfe\\lxwAqsgjdlxdoJloqsk}guqs(r)rIehiJ'gutKjjerIzIdxgjiAk\npAdonJAuqv' xn}giak#}tvlxggle'c?nrAqsfgjk}i n}dxqqso~qMtslfgj}q¢KiarzAoJAjqxn}y{lZJdoq'qsi>\nk}giaqMqvdxgjiAk qvlxwanrARJiArlxn>nJuM~Zq(r)iaqsqMrlon#qsiAfzAdxqlfwaqseμrAn#ian}lRjg¢gl|n}dm}ffzA¢q\ntMqvdxloJgjipIdon}Ajqs fn}jhgjiAklxdoJloqsk}guqsZAzAl*giaflxq}r fzApAp~n}dfl*¡zAlxgjpIuq)flfdJlxqMk}gjqM)Kiar\nJunOyn}d$fwAgy{lxgiakJ¢n}iak(r)flfdJlxqMk}gjqM$rIzAdfgjiak(r)pAdxn}AjqsÞfn}jhgiakA\n\nzAdmloqMtowIiAgu 3zaqs¡Jiarlonn}j<ian}ln}iAeμwq¢Ji.qso~qMtsln}i.n}zAdmpAdxn}Auqv' xn}hgjiak\nJAgjgleClxwaqve¡JjxnRKo£qstsl±lfwaq*qvdxdonJdo±qZ JqZ)wIgjuqxn}hgjiak|lxwanfqZpAdxn}Auqv s±cZwhzas\nn}zAd$lxn>n}j$Jiar qvlxwanrA$fwAn}zAurJjxn(r)doqv2aqMtvlwhzA Ji jgj'gjloJlxgjn}iaJiar tKpJAgjgjlfguqsM\n)wAgjtow)gjdxqM 3zAgdoq nJzAdjqJdfiAgjiak¢n}doq¢J~n}zAlwzIJiqsdxdxn}doJiar\\gj'gjloJlxgjn}ia_gi\np~qsdxynJdx'gjiak(r)fn}y{l*KdoqmqsiakJgjiaqsqsdxgiak(r)l}_JiArgizafgiakn}zAd$lonn}u*JiarpAdonrIzatvloM\niO}rAr>gjlxgjn}iAlxn.lfwaqMfq¬iaqstowKjuqviakqs¢gjiEKgiakn}zAdfn}y{lZJdoqμqviak}giaqMqvdxgjiAk\nloqstowAiAgj hzAqM n}dxqμwhzAKiI tsqsihloqvdoqMr£_gj'p£nJdxlKil pAdon}Iuqs¢JdxqEflKdxlxgiaklon9Jdfgufq\ngjirIqMfgjk}iAgiak¬whzA JiI fn}y{lZJdoqgilxqsdfy}tMqsJiar gjihloqvd}tvlxgjn}iaMilxwaq#qviak}giaqMqvdxgjiAk\nn}dxjr2lfwaqtowaJjjqsiakqs|gi¬AzIgjur>gjiakwAgukJwI lxqMtowμefloqv _tMn}'p£n}xqMr¬n}ywhzA Jia<Kiar\n}towAgjiAqMZw}qmiAqMtMqsxgjlKloqMrJzakJ qvilfgjiaklxdJrIgjlfgun}iKwhzA Ji#y}tvlon}dx$JpApAdxn3}towaqs\nlon¢tMn}iAfgurIqsd_lfwaqtJpKAgjgjlxgjqM$JiAr¬jg¢glJlfgun}ian}ylfwaqwhzA JiEqvuqv qvil|gjitMnJ¢pAjqv\nfeloqs¢MAa¦xN}Oaa{OGa{a}A#AvON}a{O£AAvA¿a{ON(r)guloqvdxalxwKlwJtMnJ qlonμrIqsian}lxq¢lfwaq tsn}'\nAgiJlxgjn}in}ygurIq}$y{don}Sefloqv _qsiak}giaqMqvdxgiakAtMnk}iIgjlxgqmpafetowanJunk}e}£Kiar¬whzA Ji\ny}tvlon}dxlxntsn}p£q$)gjlfw¢lfwaqMfq_towKjuqviakqsM±A1glxw¢tMn}'pAzAlxqsdo4pAuehgiak¢n}dxqKiar¢¢n}doq\ngj'p~n}dxloJihl¢dxn}uqs¢gjiElxwaqsxqEe>loqv s_tMnJ¢pAzIloqsd xtvguqsiAtMqJiarAqMfp~qMtvg{Jje9xnJy{l*Jdxq\nqsiAk}gjiaqsqsdfgjiak(r)iaqsqMrA$lon(r)~qmgihloqMkJdJlxqMr#)gjlfwlfwaqMfqnJlxwaqvdtsn}iatsqsdxiAM\n~qsguqs}qRlxwJl) Jihe#n}y lxwAqmpIdon}Ajqs¢$Jdxgjfgiak¡gjin}zId_Klxloqv¢pIlo*lonAzAgur#tsn}'\npAjqvOe>loqv JdoqEdxn>n}lxqMrOgjiOlxwAqu}to1n}ygjihlxqMk}doJlxgjn}iOn}y¡fn}y{lZJdoqqsiakJgjiaqsqsdxgiakA\nfeloqsaqsiAk}gjiaqsqsdfgjiakAJiAr tMn}k}iAgjlfgj}qqviak}gjiAqMqsdfgjiakIA.qiaqsqMr lxnAzAgur nJdoq)AdxgjrAkqs\n~qslqMqsi9lxwAqMxq#lfwAdoqsq#rIguftsgjpIjgjiAqMMcZwAqpIdon}Ajqs¢gi AzAgjjrIgjiAk¬tMnJ¢pAjqv.feloqs¢\nlonrae n}y{loqviJdxgjxqgji¬lfwaqa{OaOAvA{as1⁄2æA¤)£qvlZqsqsilxwaqtMn}'p£nJiaqsihloY1)waqvdoqlfwaq¡tsn}'\nc\n\np~n}iaqsihlx' e£q#wKdorIZJdoqJZfn}y{l*Kdoq}Zn}d(r)whzAKiP\n\niAqq¿AK¢pAjqgu¡lfwaq dxqMtsqsihl\nk}u}x)tsn>tohpAgl|JgjdxtsdKy{l$}tMtvgurAqvihlo))waqsdxqRlxwaqRqvqsihlxwqR~qMqviAuJ¢qMr#n}iwhzA Ji\nqsdfdon}dM~AzIl< nJdoqmpAdon}p~qsdfjedoqv2aqMtvlmrIgjE'tvzAjlfguqM$gjilxwaqtMn}{JlxqsdKrIqMfgjk}iEn}y1⁄4lfwaq(r)Jgdf\ntsdoJy{lPlfwaq'hgjn}iAgutsmfeflxqs¢MKiarlfwaqrAqs JiarImpI{}tsqMrn}i.lfwaq(r)pAgjjn}los(r)A\\q(r)iaqsqMr\n¢qslxwAn>rAnJunk}gjqM(r)lxwaJlqM}xqμtsn>nJdorIgiJloqsrArAqsfgjk}i1n}yRlfwaq¬tsn}¢p~n}iaqvihlo#JiArAlxwaq gjiI\nloqvdxy}tsqMJiarμgihloqsdo}tslfgun}iA_£qvlZqsqsi.lxwaq(r)tsn}¢p~n}iaqvihlomJiarElfwJlRpAdxnChgjrAq(r)xqMJ¢jqMf\nlxdoJiagjlxgjn}ia)Kiar JpApIgjiak*~qslqMqvi¬lfwaqmrIguftsgjpIjgjiAqMZgi}n}j}qMr2\n»ianJlxwaqvd<qvIJ'pAjqn}y±lxwaqgj'p£n}dflJihl| 3zaqMlxgjn}iaqiAqMqMrμlxn¢lo}tohuqgj|lfwaqmdoqC\nxnJiJAjqsiaqsx_nJyn}zAd|knJu)gji loqvdx¢$n}y±dxqspAu}tsgiak'whzA JiaUGzatow}$pAgun}lxMIihzAdxxqMs\ny}tvlon}dfe n}dx}qsdooUZetMn}'pAzAlxqsdos1⁄4»_gurAq<y{dxn}Ilfwaq< nJdJ£Jiar#pAwAgunfn}pAwAgjtJ~ 3zaqM°\nlxgjn}iaslfwaqsdxqKdoqloqstowAiAgjtJ$n}iAqMM e}q q nC}qsdxxn}jreUGJj~qsgl¡gjiJrIqvdxloqvihlxjeIUlxwAq\nJAgjgle¡n}y£tMn}'pAzAlxqsdo4lonmdoqvpA{JtMq$wzIJi¢gjihloqvjgukqviatMq)KiarJIgjjgleIe\n\ny{lxqsiPhZqfg'\npAeRJzAlxn} Jloq)wKltMJim£qJzIlon} JloqsrR)wAgjjquqhgjiAk*wzIJiA?)glxwJi}xfn}dxlf qvihl\nn}y?'guxtsqs{Jiaqsn}zaZlo}f)lxwaJl* e¢£q<waJdorAqvd)lonrAntMnJdxdoqstslfje gi#gufn}{Jlfgun}i2»*l$lxwAq\noK q¡lfgj¢q}~q'}f¬wzIJiA<lon#p£qvdxyn}dfe)waJlJdoq¡nJy{loqsig¢p~nxgjAjq¢n}iAglon}dfgjiak\nn}da}tohzAp lo}fJiar¡lfwaqsi'A{K qlxwaqvi)waqsi'lxwAq*gjiaqvglJIuq*JtMtsgjrAqsihlxntMtvzAdi<n\nqgjiAtsdoqM}xqmdxgjf#nJdgj'pAjetowJiakqmgjl$he#zagjiak'tMn}'pAzAlxqsdx|lxn¢pAdxnChgjrAqtsn}ihlxdxn}?n}y\np~n}loqvilfg{Jje'raJiAkqsdxn}za$feflxqs¢)dJlfwaqsd)lfwJi¬}xguflfgjiak¡whzA Jia*gi rAn}gjiAk(r)~qslfloqvd\nUn} n}y?tMn}ihlfdon}jgjiAkmlfwaqsecZwAq_{Jlfloqvdgj¢n}doq|rIgE¢tvzAjl~qMtKzaxq_gldxqM 3zAgdoqMZrAqsqsp\nzAiarIqsdolJiArIgjiak(r)nJy2whzAKi#tJpaJAgjgjlfguqMJiAr jg¢glJlfgun}iasJAzIlZ)gjgjlkqslzaZyJdflxwaqvd\ngji9lxwAq¬qsiAre cZwaqsxqEJdxqfn}¢qn}y_lxwaqiaqs·gjxzaqM¢£qvjgjqsq xnJy{l*Jdxq¬qviak}gjiAqMqsdx\n)gj4wq lxnμtMn}iIy{don}ihlμc nμfn}j}q lxwAqsi)gjj4dxqM 3zAgjdxq¢dxqMtMn}k}iAguAvgjiak lxwaq¢gj'p£n}dflJihl\ndonJuq¡n}ypae>towAn}unkJeμgjixnJy{l*Jdxqqsiak}giaqMqvdxgiakA?JzakJ qvilfgjiak#nJzAdmyn}zAiaraKlxgunJia_)gjlfw\nJpApIdon}pAdfg{Jlxq<hian)uqMrIkq}JiAr AzIgjur>gjiakgjiA*)glxw tMnkJiAgjlfgjqRqviak}giaqMqvdxgjiAkA\n\nzAdjgiA¢)glxw1lxwAqμxntsguJ_ftsgjqsiatsqMJjxn\\iaqsqMr1lon~qμlxdoqviak}lfwaqsiaqsr2ic?dfzAje\nzAiarIqsdolJiArIgjiakKiar}rIJJiatvgjiak¡loqMtowIian}un}k}e¢dxqM 3zAgdoqM*zIiarAqsdxfloJiarIgiak¡gjlxwAgjflonJdxe\nxtvguqvilfgjatm}gus~Kiar lfwaqtszAlxzAdoJ Jiarxntsg{K2¢gjgjqsz#gji )wAgjtow¬gjl$nJp£qvdJlxqMM*c qstowI\nian}jnk}e rAn>qs)ian}l$qvgjfl|n}zAlxfgurIqRn}y±lfwaqmtMn}ihloq¿lnJy1⁄4¡whzAKifn>tvguqvle~\nA.qRpAdoqvloqsiArlxwaJl$loqMtowIian}un}k}ean}zId|lxqMtowAiAn}unkJeAgu$fn} qvlxwAgiakn}y±gjyq\nyn}dxtMqJ? )gjjU2JiAr. lfwAdxzAflmn}ygjlx<n)iPPn}i)wAgutowqtJiAuJ qJjU\n)glxwμ)wAgjtowEZq(r)tMJiqvpAuJgjiμJjU£Kiar¬gji¬lxwaq¡qviarμhe¬¢qJiA_n}y4)wAgjtow\nqtMJi¢qv>tszafq<n}zAdxxqvjqsmð\nc<>nzAehuqvdon}zIiakgi o.1⁄2}Oa{O'o1⁄2}OG§AoA4qMrIgloqsr\nheoPn}zAgj$i¡aoPqshgjiAq}o|neJ\n\niloJdxgjn'¶ zafqszAc nJdon}ihlonI\nA÷3ø\n×KuG\nA\\qRiaqsqMr lon(r)pA{JtMq<¢n}doqRqv¢pAwa}fgj|nJi zIiarAqsdxfloJiarIgiak'lfwaqmqso~qMtvlo|n}ylfwaqRloqstowI\nian}jnk}emq)tsdoqMJloq)nJi(r)lxwaq*n}dxjr2A.q*wq*wa}r'_lxdoqv qviarAn}zAqso~qMtvl4n}iwzIJi(r)gjyq\nJiarwhzA Ji#fn>tvguqvleIAzIl)n}iAe yqsÐtMn}'pAzAlxqsd)ftsgjqsihlxgjfloZxqMqvIlxn¡£q<tsn}iagurAqvdxgjiAk\nlxwAqMxqqso~qMtvlo¢lxn\\Kie9rAqsk}doqsq}AA1wIgjuqtMJzak}whl'zApAgiElfwaq yqvdx}n}d#JiArEq¿Itvgjlxqs¢qsihl\nn}yrAqs}qsjn}pAgjiAk¬#iaqsIJiardoqs}n}jzIlxgunJiJdxeiaqsloqMtowIian}un}k}eμ)gjlfw.lfwaq(r)p£nJloqsihlfg{Jlxn\ntowJiAkq#lxwaqn}dxjr gjipAdonJyn}zAiar Zesq'gukJwl£q#q¿ItvzaxqsrEyn}dtsn}iatsqsihlxdoJlxgiak\nu\n\nn}iElfwaqloqstowAiAgjtJlonlxwAq¡qv>tszafgjn}in}y1⁄4lfwaq¡xntsguJ<ÆzAl<qwq¡iAnC7 JlxzAdxqMr¬lxn\nlxwAq¡p£n}gihl<)waqsdxq(r)Zq(r)iaqsqMrlonfloJdxl}ffzA'gjiAkdoqMp£nJiafgAgjgjleyn}d<)wKlqrAnA»\n}gut¡pAdxqMtsqspAlgji¢nflRqviak}giaqMqvdxgjiAkpIdon}yqsxfgjn}iJtMnrAqMn}ytMn}iar>zatslmgu<lfwJlmqviak}g\niaqsqsdo)wJ~wanJur pKdJ¢n}zAihlZlfwaq<xJyqsle}IwaqKjlxw2AJiarqsyJdoqn}y?lxwaqpAzAAgutgilxwAq\np~qsdxynJdx JiatMqmn}ylxwaqvgjd$pAdxn}yqMffgunJiJ rIzAlfguqMsZ»_JlfzAdxgiak¡aqvur2aq)gjPiaqsqMrlxn\nrAqvqsjn}pn}zAdRn)ifloJiaraKdorAmJiArEtMnrAqMRn}y4pAdxn}yqMffgjn}iJ±tMn}iar>zatslJiAr¢n}dxqy{zAje\n}tstMqspIl_n}zId|dxqMp£n}iAfgjIgjjgle¢ynJd)lxwaqRzafqM<Kiar p~n}lxqsihlxguJ2'gufzAxqM$n}yn}zAd$gi}qsihlxgjn}ias\nyn}dlxwAq qvo£qstsl'Zqwqn}iExntsguqvleJiar9whzAKiEgjyq}JiAr9yn}d'n}zId'dxn}uqgilxwanfq\nqs}qsihlos\ncZwaqwIguflxn}dxemnJyAxnJy{l*JdxqZqviak}gjiAqMqsdfgjiak$w}?~qMqsi¡n}iaqn}yAtsn}¢giak$lon|xqMqlxwKl)wKl\nn}dfguk}giJje'xqMqv qsrlxn¢~qmgj'gjlfuqMf)}tvlxzJje rAn>qs|wa}qgj'gjlos>zAiArAqsdxflKiarIgjiAk¢lxwAq\niJlfzAdoqn}y1⁄4lxwAnxqjgj'gjlxMJiAr¬lxwaqviExqMJdotowIgjiakyn}d|Ze_lxnqvpKiarμlxwaqv¬c?ntMn}i>\nlxgihzaqnJzAdpIdonk}dxqMfMZq)gj2iAqMqMrlon tsn}ihlxgizAqAzAgurIgiakn}zAdxtvguqsihlfgjatmhian)uqMrIkq\nJ~n}zAl)lfwanxqRgj'gjloZJiar xqMJdotowAgiakyn}d)iaqsIJiar rIgjo~qsdxqsihl$*e$lonflfdoqslxtow¬lfwaqs\n×"
    },
    {
      "category": "Resource",
      "title": "levesonintent.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/aadb0f82bb1e0c3fbb90ec099866d72f_levesonintent.pdf",
      "content": "\"\n\n%\n&\n\n(\n*\n\n,\n.\n&\n\n*\n\n:\n<\n>\n@\nA\nB\nD\nF\nH\nF\nJ\nK\n<\nM\nF\nN\nO\nB\nK\nP\nQ\nK\nR\nN\nS\nO\nF\nU\nV\n>\nX\nF\n<\n>\nF\n:\n<\n\\\n]\n<\n_\nX\n<\nF\nF\nU\nX\n<\n_\na\n<\nX\nH\nF\nU\nJ\nX\nO\n@\nK\nP\nd\n:\nJ\nf\nX\n<\n_\nO\nK\n<\nh\ni\nj\nk\nl\nn\np\nk\ns\nt\nv\nx\ny\n{\n}\n{\n\n}\n\nx\n\ny\n}\n\n{\n\n{\n\ny\n\ny\n}\n\n}\n{\n\n{\n\n}\n\nv\n\nx\n\nx\n\ny\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\ny\n\ny\n\n}\n\nv\nx\n\ny\n¢\ny\n\ny\n\nv\n\n¢\n\nx\n\nx\n£\n\n{\ny\n¢\n\nv\n\n¤\n\n¢\n\n}\n\nv\n¥\n\n}\n\n}\n\nv\nx\n\nx\n\n}\n\nx\n\n§\nt\nv\n\n}\n¤\nx\ny\n\n{\n\n£\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n}\n\ny\n¥\n{\n{\n\nv\n¥\n\n}\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nv\n\n}\ny\n¬\ny\n\nv\n}\n\nv\n¥\n\n}\n\ny\n\n¥\ny\n\n{\n\nx\n\ny\n\n}\n\n£\n\n¤\n\n{\n\n}\n\n£\n\n¤\n¥\n\nx\n\n§\n±\n\n¢\n{\n\ny\n{\n\nx\n\n}\n\nx\n\n}\n¤\n¤\n\nμ\n¶\n·\n\nμ\n·\no\n»\n\n1⁄4\n\n1⁄2\n1⁄4\n3⁄4\n·\n\n¿\nμ\no\n\nx\ny\n\ny\n\n¥\n\n¥\n{\n\nv\nx\ny\n¥\n\n¤\n¢\nx\n\n¥\n\n}\n\nx\n\n§\nA\nA\nA\nA\nA\nÆ\nC\nE\nE\nA\nE\nE\n\n}\n\nx\ny\n}\nv\n¥\n\n}\n\n{\n\n¥\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n}\n\n¥\ny\n\nv\n\n¤\n{\nv\n¥\n\n}\n\ny\n{\n\nv\n\n£\n}\n\nx\n\n¥\ny\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nx\n£\nx\n\nx\n\ny\nx\n\n£\n\n¤\n£\n\nx\n\nI\n¥\nx\n\ny\n}\n\n}\n¤\n¢\ny\nx\ny\n\ny\n\n}\n\ny\nx\n\n£\nx\n\ny\ny\nN\n£\n\nx\n\n}\n\nx\n\n}\n\n£\n}\n¤\n\nx\n\n}\n\nx\n\nO\n\n¥\n\nx\n\n}\nx\n\n}\n\n}\n\n£\n\n¤\n¥\n\nx\n\n}\n\nx\n\nx\n\n§\nt\nv\nx\ny\n{\n}\n{\n\ny\n\nx\n\ny\n}\n\n}\n{\n{\n\n}\n\nv\n\n}\n¤\n¤\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\ny\nx\n\nx\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n}\n\n{\n\nx\n}\n¤\n¤\n¢\n\nv\n}\n\ny\nv\n¥\n\n}\n\n{\n\ny\ny\n\nx\n\n}\n\n¥\ny\n\n¢\n\n¥\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\n{\ny\n¢\n\nv\n\n¤\n\nx\n\n}\n¤\n{\n\nx\n\nx\n{\n¤\n\ny\n\nv\n\nv\n¥\n\n}\n\ny\n¥\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\ny\n\n¤\n£\n\n{\n\n¤\n\ny\n}\ny\n\n¤\n¤\n}\ny\n\n}\ny\nx\n\ny\n¢\ny\n\nx\n\nx\n\n{\n\nx\n\nx\n{\n¤\n\ny\n§\n×\ny\nx\n\ny\n¥\n\nv\n}\n\n}\n{\n{\n\n}\n\nv\n}\n¤\n¤\n\ny\n¥\ny\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n\nx\n\nv\ny\n\nv\n}\n\nv\n\n¢\n\nx\n¤\n¤\n\n¥\ny\n}\n\n¤\n\n}\n\nØ\n\nx\n£\n\n§\n±\ny\n\n}\n¤\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\ny\n\nx\n\n}\n\n}\n¤\n}\n\nx\n\n}\n¤\n}\ny\n{\n\ny\n\ny\n\n}\n\n£\n\n¤\n\n{\n\n}\n\nv\n}\n\nv\n\nx\n\nx\n\n}\n\nx\n\n§\nU\nv\nx\n¤\n\n}\n\nv\n\n}\n\nx\n\n}\n¤\n\nv\n\nx\nI\n¥\n\ny\n}\n\n¥\ny\n\n¥\n¤\nx\n\ny\n\n{\n}\n\ny\n\nv\n\n£\n\n¤\n\n{\n\n{\n\ny\ny\n}\n\n}\n\n¥\n\nx\n}\n¤\nx\n\n£\n\n¤\n\n{\nx\n\ny\n\n}\n\nx\n\nx\n\n}\n¤\ny\n¢\ny\n\ny\n\nx\n\n}\n¤\n\nv\n\nx\nI\n¥\n\ny\n\nx\n¤\n¤\n}\n¤\n\n}\n¢\ny\n\n}\n¤\n}\n\n{\n}\n\nN\nx\n\ny\n\nO\n\n}\n\n¢\n\n{\n¤\n\ny\n\n}\n\n£\n\n¤\n\n{\n\nU\nU\n¥\n\n¤\ny\nv\n}\n£\n\n¤\nx\n\nx\n\ny\nx\n\nv\n}\n\nv\n\n}\n\n¥\n}\n¤\ny\n¢\ny\n\nv\n}\ny\n{\n\n{\n\nx\n\ny\n\n¢\n\nv\n\n¤\n\n}\n\n}\n\nv\n\n}\n\nx\n\n}\n¤\n\nv\n\ny\n\n}\n\nv\n}\n\n¤\n\n}\n¤\n¤\n}\ny\n{\n\ny\n\ny\n¢\ny\n\n£\n\n¤\n\n{\n\n§\nt\n\n¥\ny\n\nx\n\n¤\n¢\nx\n\nx\n\n¥\ny\n\n¢\n\n¥\n\n}\n{\n{\n\n}\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n¥\ny\n\nx\n£\n\n¢\n\nv\n\nN\nÞ\nO\n\ny\n¢\ny\n\n}\n\nx\n\n}\n¤\n¤\n¢\n}\n\n}\n¤\nx\ny\n\nx\n\n}\n¤\n¤\n¢\n\n}\n¤\n}\n\n}\n\nx\n\n}\n\n}\n\nv\n\nß\na\na\na\na\na\næ\nc\ne\na\ne\na\ne\ne\nc\ne\na\ne\ni\ni\ni\na\ni\ne\ne\næ\nc\ne\nð\nn\no\ni\no\no\no\no\no\nc\ne\n÷\ne\no\no\no\nø\nu\nø\nu\nu\nu\nu\ne\n÷\nn\no\ni\no\no\ny\no\nc\ne\n÷\ne\nþ\nþ\ny\nø\nu\n\nu\n\nu\n\nu\n\n}\n\nx\n\n}\n¤\n}\n\n}\n\nv\n\n}\n\nx\n\n}\n¤\n}\ny\n{\n\ny\n\ny\n\n}\n\n£\n\n¤\n\n{\n\n}\n\nN\n\nO\n\n}\n¬\n\nv\n\n}\n¤\n{\n}\n\ny\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n}\ny\nx\n¤\n¢\n\n}\n\n}\n\n¤\n\n¥\n\ny\n\n}\n\n}\n\n¤\n\n}\n\n¥\ny\n}\n\n¤\n\n¢\n\n£\n\n¢\n\nx\n\n£\n\n¤\n£\n\nx\n\nv\n\n£\n\n¤\n\n{\n\n}\n\n}\nx\n\n}\n\n{\n\ny\ny\n§\nE\n{\n\nx\n\n}\n\nx\n\ny\ny\nv\n\n¥\n¤\n\n}\n¤\ny\n\nv\n}\n\n¥\n\n}\n\nx\n¤\nx\n\n¢\n\nx\n\nI\n¥\n}\n¤\nx\n\n¢\n}\n\n¥\nx\n¤\n\n£\n\n¤\n£\n}\n\n¤\n\n}\n\nv\n}\n\n}\n\n¤\n\ny\n¢\ny\n\ny\n§\n\ny\ny\n\nx\n}\n¤\ny\n¢\ny\n\n¤\n\n£\n\n¤\n{\n\n{\n\nx\n\ny\nN\ny\n¥\n\nv\n}\ny\ny\n}\n\n¢\n}\n\ny\n\n¥\n\nx\n\n¢\nO\n\n¥\ny\n\n¥\nx\n¤\n\nx\n\nv\n\ny\nx\n\nv\n\nx\n\nx\n\nv\n\n¢\n\n}\n\n}\n\ny\nx\n\n{\n¤\n¢\n\n}\n\ny\n¥\n\n}\n\n}\n\n§\n×\n{\n\n{\n¤\n}\n\nx\n\n}\n\nv\n}\n\ny\n\nv\n\n£\n\n¤\n\n{\n\n{\n\ny\ny\n}\n\n}\n\nv\nx\n\n£\n\n{\n}\n\nx\n\n¥\n¤\n}\n\nx\n£\n\ny\n§\nt\nv\n\ny\n\nv\n}\n\ny\nx\n\n¤\n¥\n\n¥\ny\nx\n\n}\n\nx\n\ny\n}\n\nv\n\nx\nI\n¥\n\ny\n\n}\ny\n\nx\n\n}\n\n¥\n\n{\n}\n\nx\n\n¥\n¤\n}\n\n{\n\n{\n\nx\n\ny\n\ny\n\n¥\n\nx\n\nv\n\ny\n¢\ny\n\n}\n\nv\n\ny\n\n}\n\nx\n\nx\n\n}\n\nv\nx\n\n£\n\nv\n\n}\n\n£\n}\n¤\nx\n\n}\n\nx\n\nN\n}\n\n}\n\nv\ny\n\n{\n\ny\n\n}\n\nx\n\nv\n\n£\n\n¢\n\nx\n\nx\n\ny\n¢\ny\n\n£\n\n¤\n\n{\n\nO\n\nv\n}\n\nv\n\n£\n\n¤\n£\n\nx\n\ny\n¢\ny\n\nv\n}\ny\n\nv\n\ny\nx\n\nI\n¥\n}\n¤\nx\n\nx\n\ny\n§\nU\n¥\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n¥\ny\n\n}\n\ny\n¥\n{\n{\n\nv\nx\ny\n{\n\ny\ny\n§\n\n}\n\nx\n\nx\n\ny\n¢\ny\n\ny\n}\n\ny\n\n}\n\n}\n\nx\n\n¥\n}\n¤\n¤\n¢\n\nv\n}\n\nx\n\n}\n\n£\n\n¤\n£\n\nx\n\nv\n\n¢\n\n¥\ny\n\ny\nx\n\nv\n}\n\n}\n\n¤\n\n}\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n¥\ny\n\ny\n¥\n{\n{\n\n£\n\n¤\n¥\n\nx\n\nx\n\nv\n\n¥\n\n{\n\nx\ny\nx\n\nv\n\nx\n\nv\n\n{\n\n{\n\nx\n\ny\n\nv\n}\n\nx\n\nx\n\nx\n}\n¤\n¤\n¢\n£\n\nx\n\n§\n\n}\n\n¢\n\nv\n\nx\n\n}\ny\nx\n\nv\nx\ny\n{\n}\n{\n\n}\n\nx\n£\n\n}\n\n{\n\ny\n\n¢\n\nx\n\nx\n£\n\n{\ny\n¢\n\nv\n\n¤\n\nx\ny\n\ny\n\nx\n\ny\n\n}\n\nv\n¥\n\n}\n\n}\n\ny\n\n{\n\ny\n\ny\nx\n\n}\n\ny\n{\n\nx\n\n¢\nv\n¥\n\n}\n\n}\n\nv\nx\n\nx\n\n}\n\ny\n§\nt\nv\n\nv\n¥\n\n}\n\n}\n\nv\nx\n\nx\n\n}\n\n{\n\n£\nx\n\ny\n}\n\n{\n\ny\n\n}\n\nx\n\nv\n\ny\n\n}\n\nv\n\ny\n¢\ny\n\nv\n}\n\nv\n\n{\n\n}\n\n}\n\n¥\ny\n\ny\n\n¤\n£\n\n{\n\n¤\n\ny\n}\n\n{\n\n¤\n\nx\n\nx\n\n}\n\nx\n}\n\ny\nx\ny\n\n}\ny\n¬\ny\n§\n\n¥\ny\n\n}\ny\n\nv\n\n¤\n{\n}\n\n¤\nx\n\n}\n{\n¤\n}\n\nx\ny\n\nv\n\nx\n\n}\n\nv\n\n{\n\n}\n\n}\n\nv\n\n{\n¤\n}\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\nI\n¥\nx\n\ny\n}\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\nv\n\nx\n\n}\n\nv\n\ny\n¢\ny\n\ny\nx\n\ny\n}\n\n¥\nx\n¤\n\ny\n\n¥\nx\n¤\n\ny\n}\n\n}\nx\n\n}\nx\n\ny\n§\nt\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nv\n\n¤\n{\n\nv\n\ny\nx\n\n¥\nx\n¤\n\ny\n\n¥\n\n}\nx\n\n}\nx\n\n¥\n\ny\n\n}\n\nv\n\ny\n¢\ny\n\n¤\n¤\n\n¥\n\nv\n\n}\n\n}\n{\nv\n¢\ny\nx\n\n}\n¤\n\n{\n\n¤\n\ny\nx\n\nv\n}\n\nv\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\n§\nt\nv\n\n{\n}\n{\n\nx\ny\n\nx\n£\nx\n\nx\n\n{\n}\n\ny\n§\nt\nv\n\ny\n\n{\n}\n\ny\n\nx\n\ny\ny\n\n}\ny\nx\n\nx\n\n}\ny\nx\n\ny\n¢\ny\n\ny\n\nv\n\n¢\n}\n\nÞ\n\nx\n\nx\n£\n\nx\n\nx\n\n§\nt\nv\n\ny\n\n{\n}\n\ny\n\nx\n\ny\n}\n\n¢\n{\n\ny\n{\n\nx\n\n}\n\nx\n\nv\n\n}\n¤\n¤\n\nμ\n·\n\nμ\n·\no\n»\n\n1⁄4\n\n1⁄2\n1⁄4\n3⁄4\n·\n\n¿\nμ\no\n\n¥\nx\n¤\n\n¥\n{\n\nv\n\ny\n\n}\ny\nx\n\nx\n\n}\ny\n\nv\n}\n\nx\ny\n\ny\nx\n\ny\n}\n\nx\ny\n\n¢\n\nv\n\n}\n¤\ny\n¤\nx\ny\n\n}\n\n£\n\nx\n§\n\n§\n\nv\n}\n\nv\n¥\n\n}\n\n{\n\ny\ny\nx\n\n}\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nx\n\n}\n\n}\n¤\n}\n\nx\n\n}\n¤\n}\ny\n{\n\ny\n\ny\n\n}\n\n£\n\n¤\n\n{\n\n}\n\nv\n}\n\n¥\n\n}\n\nx\n¤\nx\n\n¢\n\nx\n\nI\n¥\n}\n¤\nx\n\n¢\n}\n\n¥\nx\n¤\n\n£\n\n¤\n£\n}\n\n¤\n\n}\n\nv\n}\n\n}\n\n¤\n\ny\n¢\ny\n\ny\n§\n\nA\n\n\"\n$\n\nC\n&\n(\n\"\n&\n+\n,\n-\nE\n\"\n&\nA\nÆ\nC\nE\nE\nA\nE\n\nC\nE\n\n&\nt\n\n¥\ny\n\n¥\n¤\n\n}\n\n¥\ny\n}\n\n¤\n\n¢\nv\n¥\n\n}\n\ny\n\ny\n\n¤\n£\n\n{\n\n¤\n\ny\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\n}\n\ny\n¢\ny\n\ny\nx\n\ny\nv\n\n¥\n¤\n\n}\ny\n\n}\n\n¥\n\ny\n\n}\n\nx\n\nv\n\n{\n\n¤\n\n}\ny\n¬\n\nv\n}\n\nv\n\n¥\ny\n\nx\ny\ny\n\n¤\n£\nx\n\n§\nt\nv\n\ny\n¢\ny\n\ny\n\ny\nx\n\n}\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n¥\ny\n\nx\n\n{\n\ny\n\n}\n\ny\n\nv\n¥\n\n}\n\ny\n§\nU\n\n¥\n\ny\n\n}\n\nv\n\ny\n\n}\n\ny\n}\n\nv\n\nv\n¥\n\n}\n\ny\n¥\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\ny\n\n¤\n£\n\n{\n\n¤\n\ny\nx\n\n}\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n}\n\n}\ny\n\n}\n\n¤\n\n}\n\ny\n}\n\nv\n}\n\n}\ny\ny\nx\ny\n\nv\n¥\n\n}\n\ny\nx\n\n}\n\n¢\nx\n\n¥\n\nv\n\nx\n\n}\ny\n¬\ny\n§\n\n¤\n¢\n\ny\n\nv\n\n¤\n}\n\n¥\n}\n\nx\n\nv\nx\n\nv\n\ny\n{\n\nx\n\n¢\n{\n\n¤\n\ny\nv\n}\n£\n\n}\n\nØ\n\n¥\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nx\n¤\nx\n\n¢\n\nx\n\n}\n¤\ny\n\n}\nØ\n\ny\n\nv\n\ny\n\n}\n¬\n\nv\nx\n¤\n\ny\n\n¤\n£\nx\n\nv\n\ny\n\n{\n\n¤\n\ny\n§\nU\n¥\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\nx\n\ny\n\nv\n}\n\nx\ny\n¬\n\n}\n\n¥\n\nv\n¥\n\n}\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\n}\n\n}\n{\n}\n\nx\n¤\nx\n\nx\n\ny\n§\n±\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nx\n£\nx\n\n¢\nx\n\n£\n\n¤\n£\n\ny\n}\n\nv\nx\n\n£\nx\n\n}\n\n}\n¤\n\n¢\ny\n\n¤\n\nx\n\n}\n\n¥\ny\nx\n\ny\n\n}\n\nx\n\ny\n\n£\n\nv\n\n¥\n\ny\n\n}\n\nv\n\n}\n¤\ny\n\n}\n\n§\nE\n¥\n\ny\ny\n\n{\n\ny\n\ny\n\n¤\n\nx\n\n}\n\nØ\n\nx\n£\n\ny\n\n}\n\n¢\n\ny\n\ny\n\n}\n\nx\n\ny\n}\n\n}\nx\n\nx\n\nv\n\nx\n\n}\n\nx\n\ny\ny\n}\n\n¢\n\n}\n\n¢\n\n¥\n\nv\n}\n\ny\n\n}\n\n¢\ny\n¥\n\ny\ny\n\n¥\n¤\n¤\n¢\n§\nE\n{\n\nx\n\n}\n\nx\n\ny\n¥\ny\n\nx\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\ny\n¬\ny\n}\n\ny\n\n¥\n\n{\n\n£\nx\n\n}\ny\ny\nx\ny\n\n}\n\nx\n\nv\nx\ny\n{\n\ny\ny\n§\n\nx\n\nx\n£\n\n{\ny\n¢\n\nv\n\n¤\n\n¢\nv\n}\ny\n\n¤\n¢\n\ny\n\n}\n\n¤\nx\ny\nv\n\nv\n}\n\nv\n\n{\n\ny\n\n}\n\nx\n\nv\n\n{\n\n¤\n\n{\n\n£\nx\n\n{\n\n¤\n\ny\n\n¤\n£\n\ny\n\n}\n\n}\nØ\n\nv\n\nx\n\n{\n\n}\n\nN\ny\n\n}\n\n:\n<\n\n}\ny\n¥\n\n£\n\n¢\n\nv\nx\ny\n\ny\n\n}\n\nv\nO\n§\n\n}\n\nU\n\ny\n\n¤\n}\nx\n\ny\n\nv\n}\n\nv\n\n}\n\n¥\n\n}\n¤\n\n{\n\ny\n\n}\n\nx\n\ny\nU\n\n@\n<\nU\nt\nv\n\n{\n\ny\n\n}\n\nx\n\ny\n}\n£\n}\nx\n¤\n}\n\n¤\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\n\nx\n\nv\n\n}\n\ny\n¥\n{\n{\n\n{\n\n}\n\n§\nt\n\n{\n\n£\nx\n\n}\ny\ny\nx\ny\n\n}\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nv\n\nI\n¥\nx\n\ny\n\nv\n}\n\n£\n\n¤\n\n{\n}\n\nv\n\nx\n\n}\n¤\n\n}\ny\nx\ny\n\nx\n\nx\n\nv\nx\n\nv\n\n{\n\ny\n\n}\n\nx\n\ny\ny\n¥\n{\n{\n\nØ\n\nx\n£\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\ny\n\n}\n\nx\n\ny\n§\nB\n\n}\n\n{\n¤\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n{\n\n}\n\n}\n\nx\n\n{\n\n£\n\n¢\n{\n\n£\nx\n\nx\n\n{\n\ny\n\n}\n\nx\n\ny\n\nv\n}\n\n¥\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\n\nD\ny\n\n¢\n¤\n\n}\n\nE\nF\nE\nH\n@\n<\n}\n\nv\n}\n\nx\ny\n{\n¤\n}\n¢\nI\nJ\nL\nM\nO\nP\nQ\nP\nT\nU\nU\nO\nM\nP\nO\nU\nU\nY\nP\nO\nM\na\na\ne\ne\nð\nc\n\\\ne\na\ne\ne\na\ne\na\n]\næ\n\\\nð\ne\næ\nn\nð\n÷\næ\ne\nð\ne\na\nð\n]\næ\n\\\no\na\n÷\ne\ne\na\næ\n÷\næ\n_\na\nn\nð\ne\na\n_\nc\næ\n\\\na\ni\na\ne\nð\n\\\na\nð\n÷\na\na\n÷\nð\nð\nc\na\n÷\na\nc\n]\næ\na\n÷\na\ne\na\ne\nð\ne\na\ni\n]\na\næ\ni\nø\næ\na\ni\nc\ne\n÷\nn\na\ni\n\\\ne\n÷\na\n_\ne\n]\ne\næ\nc\na\ne\næ\n]\næ\ne\nð\na\na\ne\na\ne\na\nð\n]\na\ne\ni\ni\nð\n÷\na\nð\na\næ\n_\no\ni\na\ni\nn\nø\na\n÷\na\na\na\na\na\nø\ne\nð\n]\na\na\ni\na\ne\nð\n\\\na\n]\næ\n\\\ne\næ\na\nð\nn\næ\n_\na\ni\n\\\ne\n÷\na\ne\n÷\nn\n\\\ne\n]\na\na\n÷\nð\na\n[\na\na\nð\na\nð\n]\na\ne\ni\ni\nð\n÷\na\nð\na\na\ne\ne\nð\n÷\nð\n]\nð\na\na\na\ne\ne\ne\nð\nn\ne\ni\na\n\\\nð\n÷\ne\na\n÷\na\ne\nc\ne\nn\na\ne\na\næ\n÷\ne\ni\na\ni\n\\\ne\n÷\n_\ne\n]\nø\ne\næ\nc\na\ne\ne\ne\nc\næ\ne\n]\na\nð\na\ne\næ\n]\næ\n÷\na\na\nn\nð\nc\ne\na\nð\n]\ne\ne\ne\no\na\ni\na\ne\na\nð\na\ne\n÷\nn\ni\na\n\\\na\ne\ne\ne\na\næ\n÷\na\næ\n_\ne\na\nð\na\ni\n\\\ne\n÷\nð\ni\nð\n\\\nð\n÷\ne\na\n÷\n]\næ\n\\\ne\ni\nð\nk\na\ni\na\ne\nð\n\\\na\n[\n\nv\n\nx\n\nx\n\n}\n¤\n}\n\nx\n\n¥\n\ny\n\ny\n\n¤\n£\n\nv\n\n{\n\n¤\n\nx\n\n}\n{\n\n{\n\n¥\n}\n¤\n¤\n¢\ny\n}\n¤\nx\n\n}\n¢\nE\nE\nm\n<\n§\n±\n{\n\n¤\n\ny\n\n¤\n£\nx\n\ny\n\n}\n\n¢\nx\ny\n}\n\n}\n\ny\n\n}\n\nx\n\ny\n\nx\n\nx\n\ny\nx\ny\n\n}\ny\n\nx\n\n}\n{\n{\n\n}\n\nv\n\nv\n}\n\n}\n\nx\nn\n\n¢\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\n¤\n\n{\n\ny\n\n}\n\nx\n\n}\n\nx\n\n{\n\n}\n\nx\n\ny\n\n£\n}\n\nx\n\ny\nq\nr\n@\n<\n§\n\n}\n\n{\n¤\n\ny\n\ny\n\n}\n\nx\n\ny\n}\n\nv\n¢\n{\n\nv\n\ny\nx\ny\n}\n\ny\n\n{\n}\n\nx\n\nx\n\nx\ny\nx\n\ny\n\n}\n\nv\n\n}\ny\n\nx\n\n¢\n}\n\n}\n¤\n\n¢\n\n}\n\n{\n\n¤\n\nx\n\n}\n¤\ny\n\n}\n\nv\n§\nE\n\n{\n¥\n\ny\n\nx\n\ny\n\n}\n\nv\n\ny\nv\n}\n£\n\n{\n\n{\n\ny\n\nv\n\nx\n\ny\n}\n\n¥\n\nv\n\n}\n¤\n\n¤\ny\n}\n\ny\n\n}\n\nx\n\ny\n¥\ny\n\nx\n\n{\n\n}\n\n¥\n\ny\n\n}\n\nx\n\n}\ny\n¬\ny\nN\n\n}\n\n{\n¤\n\ny\n\ny\n¥\n\nv\n\n¤\ny\n}\n\nt\n\nH\n:\n\nu\n\nH\nw\n\nr\n\nH\nx\n\nE\n\nx\n\nE\n\nH\ny\n<\nO\n§\n±\n¤\n\nv\n\n¥\n\nv\n\nv\nx\ny\n}\n{\n{\n\n}\n\nv\ny\n\ny\n¥\ny\n\n¥\n¤\n\nx\n\n}\n¢\n\n¥\n\n¥\n\nx\nz\n\n¥\n¤\n\nv\n}\n\n}\n{\n{\n\n}\n\ny\n\nv\n\ny\n¥\n\n}\n\n§\n\n}\n\nv\n\nv\n\n¥\ny\n\ny\n\n}\ny\n{\n\nx\n\n}\n\nx\n\n}\n¢\nN\n}\n\n{\n\n}\n\n¤\n¢\n\nx\n¤\n¤\nO\nv\n}\n£\n\nx\nØ\n\n}\n¤\n\n¤\ny\n\nv\n\ny\n¢\ny\n\n{\n\nx\n\ny\n¥\n\nv\n\n}\n\ny\n}\ny\n{\n\nx\n\n{\n\nx\n\nv\n\n}\ny\n¬\n\nv\nx\n\nv\n\nv\n\n¤\nx\ny\n\nx\n\n¥\ny\n\n}\n\nv\n\nx\n\n¤\n\nx\n\nv\n\ny\n¢\ny\n\n±\nt\nm\n\n|\n¥\n\nH\nx\n\nu\n¥\n\nH\nx\n\nq\n\n}\nm\n<\n§\nt\nv\n\ny\n}\n\n{\n\ny\n\n}\n¢\nv\n}\n£\n\n¥\n¤\n\nx\n{\n¤\n\n}\n¤\n\n¤\ny\n\n}\ny\n¢\ny\n\n}\n\n£\n\nv\n}\n£\n\nx\n\n}\n\nx\n\n¢\n\n¤\ny\n\nv\n\ny\n}\n\ny\n¢\ny\n\ny\n\ny\n\ny\n\nx\n\n¥\n\n}\n{\n\n¤\n\n{\n\n{\n¤\n\nu\n¥\n\nH\nx\n<\nE\n\n}\n\nx\n\ny\n}\n¤\ny\n\ny\n\nv\nx\n\nv\n¤\n¢\n£\n}\n\nx\n}\n\n¤\n\n§\n±\ny\n\n¥\n\n¢\n\nv\n}\n\n¥\ny\n\n{\n\n¤\n}\n\n}\n¤\n¢\ny\nx\ny\n\nx\n\nv\n\n¥\n\n¤\n\ny\nv\n\nx\n\ny\n\n}\n\nx\n\ny\n\n{\n\ny\ny\nx\n\n}\n¤\n\nv\n\nx\n\nx\n}\n\ny\n\n¬\nx\n\n¤\n\nx\n\nI\n¥\nx\n{\n\n¥\n\nv\n}\n\ny\n\nI\n¥\n\ny\n\n}\n\nx\n\ny\n\nx\n\nx\n\n}\n¤\n\n£\n\nv\n\n¥\n\nv\n\nv\n\nv\n\nx\n\nx\n}\n\ny\n\n{\n\nx\n\nv\n\ny\n}\n\n}\ny\n¬\n\n£\n\n¢\n\nx\n\nN\nx\n§\n\n§\n\nx\n\n}\n\n}\n¥\n¤\n\n¢\n\n¤\n\nx\n\n{\n\nO\nq\n}\ny\nH\nw\n<\n§\n\n¤\n¢\n\ny\n\n}\n\nv\ny\n\n}\n\nx\n\ny\n£\n}\n\n¢\n}\n\nx\n\nx\n£\nx\n\n¥\n}\n¤\ny\n\nv\n\ny\n}\n\n{\n\n¤\n\n¥\n\n}\n{\n\ny\n\n}\n¢\n£\n}\n\n¢\nv\nx\ny\n\nv\n\ny\n\n}\n\n¢\n\n¢\n\n}\n\nx\n\n}\n¤\n¤\n¢\n\n¥\n\nx\n\n}\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nx\n£\nx\n\n¢\nU\n\nØ\n\nx\n£\n\n{\n\n¤\n\ny\n\n¤\n£\n\ny\n\nv\n}\n\ny\n\n}\n\nx\n\ny\n\nI\n¥\n\n¤\n¢\n\nx\n\n¥\n\n£\n\n¤\n\n}\n¤\n\nx\nz\n\n¥\n¤\n\nx\n\ny\n\n¥\n\n}\n¤\n\nv\n\ny\n\n¤\n¥\n\nx\n\n{\n}\n\nv\n}\n\ny\n{\n\nx\n\n}\n\nx\n\nv\n}\n\nv\n}\n\ny\n\nv\n\nx\n£\n\ny\n}\n\ny\n¥\n\n}\n¤\ny\n\nv\n\n}\n¤\n\n¬\n¤\n\n}\n\n}\n\nv\nx\n\n£\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\n¥\n\n}\n¤\n§\n\n}\n{\n{\n\n}\n\ny\n\nv\n\nv\n}\n\n}\n¤\n¤\n\n¥\n¤\n\nx\n{\n¤\n\n¥\ny\n\ny\n}\n\nØ\n\nx\n£\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nN\nx\n\n¤\n¥\n\nx\n\ny\nv\nx\n\nx\n\n}\n\ny\n\n}\n\nx\n\ny\nO\n\ny\n{\n\nx\n\n}\n\nx\n\ny\ny\nv\n\n¥\n¤\n\ny\n¥\n{\n{\n\n}\n¤\n¤\n{\n\ny\n\ny\nx\n\n¤\n\ny\n\n}\n\nx\n\ny\n\nv\n}\n\n}\n¢\n\n}\n\n}\ny\n¬\n\n}\n¤\n¤\n\n¥\n¤\n\nx\n{\n¤\n\n¥\ny\n\ny\n\nv\n\n{\n\ny\n\n}\n\nx\n\ny\nv\n\nx\n\n}\n¤\n\n¬\n¤\n\n}\n\n¢\ny\nv\nx\n\nx\n\ny\n\n}\n\nx\n\ny\n\n¥\n\nx\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nx\nØ\n\nx\n\nx\n£\n\n}\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\ny\n\n¢\n¤\n\ny\n§\nU\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\ny\n¥\n\nv\n\nv\n}\n\n¥\ny\n\ny\n\n}\n\n}\ny\nx\n¤\n¢\n\nx\n\nv\n\nx\n\n}\n\nx\n\nv\n\n¢\n\n}\n\n¤\n\ny\ny\n\nv\n\nx\n\n}\n¤\n\n¤\n\n{\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\ny\n\n}\n\nx\n\ny\n§\nt\nv\n}\n\nx\ny\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\ny\nv\n\n¥\n¤\n\n¤\n}\n\nv\n\n}\n¤\n\n}\ny\n¬\ny\n¥\ny\n\ny\n\n{\n\nx\n\nv\n\nv\n\nx\n\n}\n\nx\n\n¥\n\n¤\nx\n\nx\n\ny\n{\n\nx\n\n{\n\n}\n¢\ny\n\n}\n\n¢\nx\n\n¥\n\nv\n\ny\n\n}\ny\n¬\ny\n§\nU\n\n}\ny\n\nv\n¢\n\n}\n\n¢\ny\n\n}\n\nx\n\nx\n\n¤\ny\n}\n\n£\nx\n\ny\n}\n\n}\n\nx\n¤\n¢\n}\n\n{\n\n}\ny\nx\n¤\n¢\n¥\ny\n\nx\ny\nt\n\nv\n}\n\nv\n\n¢\nx\n\n{\n¤\n¢\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\n¤\n\n¤\n}\n\n{\n\nx\n}\n¤\n¥\ny\n\ny\n\n¬\n\nv\n\n¥\n\nv\n{\n\n¤\n\ny\n¥\ny\nx\n\n¤\n¢\n\n}\n£\n\n¢\n¤\nx\n\nx\n\n¥\n\ny\n\n}\n\nx\n\ny\n\n¥\ny\n¥\n}\n¤\n¤\n¢\n\nv\n\ny\n\n}\n\n¢\n\ny\n\n}\n\nx\n\ny\n{\n\n¢\n\nv\n\ny\nx\n\nv\n\n¤\n§\nt\nv\n\n}\n¤\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\nx\n\ny\nv\n\n¥\n¤\n\n}\n¬\n\nx\n\n}\ny\n¢\n\n¥\ny\n\ny\n\n}\n\n}\n\n¥\ny\n\nv\n\nx\n\n{\n\n}\n\nx\n\n}\n\nx\n\nv\n\ny\n{\n\nx\n\n}\ny\n¬\n}\n\nv\n}\n\nx\n\nv\n\n¥\n\n}\ny\ny\n¥\n\nx\n\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\n¤\n\n¤\ny\n\n¤\nx\n\nx\n\nx\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\ny\n\n}\n\nx\n\ny\n\n{\n¤\n\n¢\n\n¢\n\nv\n\n¥\ny\n\ny\n\nv\n\n¥\n\n§\nt\nv\n\ny\n\nv\nx\ny\n{\n}\n{\n\ny\n\nx\n\ny\n}\n\n}\n{\n{\n\n}\n\nv\n\n}\n\nv\nx\n\n£\n\nv\nx\ny\n\n}\n¤\n§\n}\n~\nC\nE\n\nC\n&\nA\n&\n$\n(\nC\n\n\"\n\nA\n\n\"\n\n$\n\nC\n&\n\nA\n$\nA\nC\n+\nC\nE\nC\n\n$\nC\n\n-\n\nC\nÆ\n$\nA\nÆ\nC\nE\nE\nA\nE\n\nC\nE\n\n&\n×\n\n¤\n¢\nx\n\n}\n\n¢\n\nv\n\n¤\n\n¢\nx\ny\n}\n\n}\ny\ny\n¥\n\n»\n\n¿\n1⁄4\n\no\no\n§\n\n¥\n\n}\ny\n\nv\n\n{\n\ny\ny\n\n¥\ny\n\ny\n¥\n{\n{\n\nv\n\n}\ny\nx\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\nx\n\nx\n\n}\ny\n¬\ny\n§\n±\n\nv\n\nx\n\n}\n\n¥\n\n¤\n¢\nx\n\ny\n¢\ny\n\nx\n\nx\n\n{\n\ny\ny\nx\ny\n\nv\n\ny\n\n{\n\n}\ny\n{\n\nx\n\n}\n\nx\n\nv\n\n¤\n\n¢\n§\n\n}\n\nx\n\nx\n\nx\n\nx\n£\n\n{\ny\n¢\n\nv\n\n¤\n\nx\ny\n\ny\ny\n¥\n\ny\n\nv\n}\n\nv\n\n}\ny\n{\n\ny\n\nx\n\n}\n\ny\nx\n\n¥\ny\n\n}\n\ny\ny\n\nx\n\nv\n\nx\n\n}\n\nx\ny\n\ny\n\n£\n\n}\ny\n}\n\nØ\n\nx\n£\n\nx\n¥\n\nU\nN\nÞ\nO\n1⁄4\n¿\nμ\n·\n\nμ\n·\nN\n\nv\n}\n\ny\n\n}\n\nx\n\nx\n\n}\n\nx\n\ny\nv\n\n¥\n¤\n\n}\nx\n\nx\n\nv\n\n{\n\ny\n\n}\n\nx\n\nx\n£\n\nv\n\n}\n¤\ny\n}\n\n}\ny\n¬\ny\n\nv\n\n¥\ny\n\ny\n\nN\n/\nO\no\n·\n\n1⁄4\n·\n\nN\nv\n\ny\nx\n\nv\n\n{\n\ny\n\n}\n\nx\n\ny\n\nv\n}\n\nv\n\n¥\ny\n\n}\n\n}\n\nv\n\nx\n\n}\n\nx\n\nO\n\n}\n\nN\n:\nO\n\n¿\n\nN\n\nv\n\n}\n\nx\n\n}\n\nv\n\nx\n\n}\n\nO\n\nq\nm\n<\n§\nt\nv\n\ny\n\nx\n\ny\n\n}\n\nx\n\n}\n\nv\n\nv\n\ny\n\n¥\n\n}\ny\n{\n\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\nx\n\n¥\n\n§\n\n±\n\n¢\ny\n¢\ny\n\ny\n{\n\nx\n\n}\n\nx\n\nv\n\ny\nv\n\n¥\n¤\n\ny\n¥\n{\n{\n\nv\n\ny\n¢\ny\n\ny\n\nx\n\nx\n\n{\n\ny\ny\n§\nt\nv\nx\ny\n{\n\ny\ny\n{\n\n£\nx\n\ny\n}\n¤\n\nx\n\n}\n¤\ny\n\n¥\n\n¥\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nN\ny\n\nB\nx\n\n¥\n\nÞ\nO\n§\nB\nx\n\ny\n\n}\n\n{\n\n¤\n\nx\ny\ny\n{\n\nx\n\nx\n\ny\n\nx\n£\n\ny\n\nv\n}\n\nv\n\ny\n¢\ny\n\n¥\ny\n\ny\n}\n\nx\ny\n\n¢\n}\n\nx\n\nx\n}\n\nv\n}\n\n}\n\n¥\ny\n\n}\n\n¬\n}\n¤\n\n}\n\nx\n£\n\ny\nx\n\ny\n§\nt\nv\n\n}\n{\n\ny\ny\n\ny\n¢\ny\n\ny\n¢\n\nv\n\ny\nx\ny\n\n}\n¬\n\ny\n{\n¤\n}\n\nv\n}\n\ny\n¥\n¤\n\ny\nx\n\n}\ny\n\n}\n¤\n\n}\n\nx\n£\n\ny\nx\n\ny\n§\n\n}\n\nv\n\nv\n\ny\n\n}\n¤\n\n}\n\nx\n£\n\ny\nx\ny\n}\n\n}\n\n¤\n¢\nn\n\n}\n\n£\n}\n¤\n¥\n}\n\nx\n\ny\n\nv\n\ny\n\n}\n\nx\n£\n\ny\n}\n\ny\nx\n\nx\n\nx\n}\n\n}\n\n}\n¤\n\n}\n\nx\n£\n\nx\ny\ny\n\n¤\n\nx\n\n{\n¤\n\n§\n\n{\n\n}\n\nx\n\nv\n\n{\n\ny\ny\nx\ny\nv\nx\n\nv\n¤\n¢\nx\n\n}\n\nx\n£\n\nU\nt\nv\n\ny\n¥\n¤\n\ny\n\n¤\n}\n\ny\n\n}\n\ny\n}\n\n}\n\n¬\n\n}\n\n¤\n¢\ny\n\n}\n\ny\n\nx\n\n¢\n\nx\n£\n\ny\n\nx\n\nx\n}\n\ny\nx\n\n}\n¤\n\n}\n\nx\n£\n\ny\n\n}\n\ny\n\n§\n|\n\ny\nx\n\n}\n¤\n\n}\n\nx\n£\n\ny\n}\n\n}\n\nv\n\n¥\n\nv\n}\n{\n\ny\ny\n\ny\n¢\ny\n\n}\n\nv\nx\n\n¥\n\n£\n\n¤\n\n{\n\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\n§\nt\nv\n\ny\n¢\ny\n\nx\n\ny\n\n}\n¬\n\nv\n\ny\n¢\ny\n\nx\n\n}\ny\n\ny\n¥\n\nSelect one alternative\nfor implementation\nIdentify objectives and criteria\nGenerate alternative designs,\nidentifying subsystem functions\nand constraints, major system\ninterfaces, and subsystem\ninterface topology\nobjectives and criteria\nEvaluate alternatives against\nB\nx\n\n¥\n\nÞ\nU\nt\nv\n\n}\ny\nx\n\ny\n¢\ny\n\ny\n\nx\n\nx\n\n{\n\ny\ny\n§\ny\n¢\ny\n\ny\n\nv\n\nx\n\nv\n\nv\n\n¥\n\nx\n\ny\n}\n\ny\n\n}\nx\n\ny\nx\n\n{\n\ny\n\n¥\n{\n\nv\n\nx\n\nx\n£\nx\n\n¥\n}\n¤\ny\n¥\n\ny\n¢\ny\n\ny\nx\n\ny\n\nv\n\n}\n\ny\n¢\ny\n\nx\n\n}\n\ny\n\n}\n\nv\n\ny\n¥\n\ny\n¢\ny\n\nx\n\n}\n\n{\n\n¤\n\n¢\n§\nt\nv\n\ny\n\n}\ny\n{\n\ny\n}\n\n}\n\n}\n¤\n¢\nn\n\nx\n\nv\n\ny\n{\n\ny\nx\n\ny\n¢\ny\n\n{\n\n}\n\nv\n}\n\n}\n\nx\ny\n\nx\n\ny\n}\n\ny\n\n}\nx\n\ny\n\n}\n\nv\n\n{\n\ny\ny\nx\ny\nx\n\n}\n\n¥\n\nx\n¤\n}\n\n}\n\n{\n\n}\n\n¤\n\ny\n¢\ny\n\ny\nx\n\ny\n¥\n¤\n\ny\n§\nt\nv\n\n{\n\n¤\nx\n\nx\n\n}\n\n¢\n\ny\nx\n\n}\n\nv\n\nv\nx\ny\n{\n\ny\ny\n\n¥\ny\n\ny\n\nx\n\nx\n\ny\n¥\nz\n\nx\n\n}\nx\n¤\n\nv\n}\n\ny\n¥\n\ny\n¢\ny\n\nx\n\n{\n¤\n\n}\n\nx\n\n}\n\n{\n\nx\n\n{\n\n¤\n¢\n§\nt\nv\n\ny\n\n}\n\nI\n¥\nx\n\ny\n}\n\ny\nx\n\n{\n\ny\ny\n}\n\ny\nx\n\n{\n¤\n¢\ny\n¥\n\ny\n\ny\n\nv\n\n¤\n}\n\ny\n¢\ny\n\nx\n\nx\n\n{\n\ny\ny\n§\nE\n¢\ny\n\nx\n\nx\n\n£\nx\n\ny\n\n}\n\nv\ny\n¢\ny\n\n}\ny\n}\n\nx\n\n}\n\nv\n\n¤\n\n£\n\nv\n\n¥\n\nv\nx\n\nx\ny\n\n{\n\ny\n\nx\n£\n\ny\n\ny\n{\n\nx\n}\n¤\n\nx\nn\n\n{\n\ny\n\nv\nx\n\nv\n\n}\n¢\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\n¤\n\nx\n\n}\n¤\nN\ny\n\n}\n\nO\n\nv\n¥\n\n}\n\n§\nt\nv\n\nx\n£\n\nx\ny\n\ny\nx\n\ny\n¥\n\ny\n¢\ny\n\ny\n\nv\n}\n\nv\n\nx\n\n}\n\nx\n\nv\n\nv\n\n¤\n\n{\n\n£\nx\n\nv\n\ny\n\nØ\n\nx\n£\n\ny\n¢\ny\n\n{\n\ny\ny\nx\n\n¤\n\n}\n\nv\nx\n\n£\n\nv\n\n£\n\n}\n¤\n¤\n\nx\n£\n\ny\n§\nt\nv\n\ny\n\nv\n}\n¤\n¤\n\nx\n\n{\n\n¤\n\ny\nx\n\n¥\nx\n¤\n\nx\n\n{\n¤\n\ny\n¢\ny\n\ny\n\n}\n¢\n}\n\nx\ny\n\nx\n\nv\n\nx\n\n}\n\ny\n\n{\n\ny\n§\nU\n\n}\n\n{\n¤\n\nx\ny\n\nv\n\nv\nx\n\nv\n¤\n¢\n}\n¥\n\n}\n\n}\nx\n\n}\n\nv\n\ny\n\nx\n\nx\n\ny\n}\n\n}\n\nx\n\ny\nv\n}\n£\n\n¤\n}\n\nv\n¥\n\n}\n\n¥\n\n{\n\n{\n\n¤\n¢\n\nx\nz\n\n¥\n¤\n\nx\n\ny\nx\n\nv\n\n¤\n¤\n}\n\n}\n¤\n\ny\nx\n\nv\n\n}\nx\n\n}\n\nv\n\n}\n£\nx\n\nx\n\ny\ny\n¢\ny\n\ny\n\nv\n\n¬\n{\nx\n\nx\ny\n{\n¤\n}\n¢\ny\n}\n\n¤\ny\n\n}\n\nv\n\n}\n\ny\n{\n¤\n}\n\nv\n\n{\nx\n¤\n\ny\n§\nU\nv\n}\n\n¢\n{\n\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\ny\n¥\n{\n{\n\nv\n¥\n\n}\n\ny\nx\n\nv\nx\ny\ny\n¢\ny\n\nx\n\nx\n\n{\n\ny\ny\n}\n\ny\n{\n\nx\n\n¢\n\nv\n\ny\n¥\n¤\n\ny\n\n|\n\ny\nx\n\nx\ny\nx\n\ny\n}\n\n}\n\nv\ny\n\n}\n\n¥\ny\n\n}\n{\n{\n\nx\n\nv\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\n\nv\n\n¢\n}\n\nx\n£\n\ny\n}\n\nx\ny\n\n¢\n\nx\n\nv\n\n}\n\n¤\nx\n\nx\ny\nx\n\ny\n\n}\n{\n{\n\nN\n\n}\n\nO\n\n¤\n}\n\ny\n\n}\n\ny\n\nv\n\n{\n\ny\ny\n\ny\n¥\n¤\n\nx\n\nx\n\n}\ny\n\n}\n\n¤\n\ny\ny\nN\n\n}\n{\n¤\n\ny\ny\nO\n\nv\n\n{\n\ny\ny\nx\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n¢\ny\n\nI\n¥\nx\n\ny\n\n{\n\nI\n¥\nx\n\ny\n}\n\n:\n\ny\nx\n\ny\n§\nt\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n¥\ny\n\n}\n¤\ny\n\ny\n¥\n{\n{\n\nv\n\n£\n}\n\nx\n\n¥\ny\n\n¢\n{\n\ny\n\n}\n¤\n}\n\nx\n\n}\n¤\n}\n\n}\n¤\n¢\ny\nx\ny\n¥\ny\n\nx\n\n}\n¤\n\n}\n\nx\n£\n\ny\nx\n\ny\n}\n\n£\n\nx\n\n¢\n\nv\n\ny\n¥\n¤\n\ny\n\nv\n\ny\nx\n\n{\n\ny\ny\n§\nB\nx\n\n}\n¤\n¤\n¢\n\nv\n\n¢\n\n¥\ny\n\n}\ny\ny\nx\ny\n\nx\n\nv\n\nx\n\n}\n\ny\nx\n\nv\n\n{\n\ny\n}\n\nv\n\nx\n\n}\n\ny\n\nv\n\n§\n\n¡\n\n£\n¤\n\n£\n¤\nt\nv\n\ny\n\n{\n\n}\ny\n{\n\nx\n\n}\n\nx\n\nv\n\n¤\n\n¢\nx\ny\n\nv\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\n|\n\nx\n\nx\n\n}\n{\n\n{\n\n{\n\nx\n}\n\n1⁄4\n¿\nμ\n·\n\nμ\n·\n\nI\n¥\nx\n\ny\n\ny\nx\n\nx\n\nv\n}\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nx\n¤\n¤\n\n¥\ny\n\nv\n}\n\nx\ny\n\nv\n\n{\n\n¤\n\ny\n\nv\n}\n\nv\n¥\n\n}\n\ny\n}\n\n¢\nx\n\ny\n\n¤\n£\n\nv\n\nv\n\n¢\n¥\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\nr\n\n£\nx\n\n¥\ny\n¤\n¢\n\n¤\n\n¬\n\n}\n\n}\n\n}\n\ny\n¤\nx\n\nv\nx\ny\n{\n\n¤\n\nv\n}\n\ny\nv\n\n¥\n¤\n\n}\nx\n\nx\n\n¤\n}\n\n¬\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n{\n\ny\ny\n\n¤\ny\n\n}\n\ny\n¥\n\nv\n}\n\nv\n\ny\n¥\n¤\n\nx\n\nx\n\n{\n¤\n\n}\n\nx\n\ny\n}\n\nx\n\n}\n¤\n¤\n¢\n\n{\n¤\n\nu\nF\n\nÞ\n\nu\n\n£\n@\n<\n§\nt\nv\nx\ny\n{\n}\n{\n\n}\n\n}\nx\n\ny\nx\n\ny\n\nv\n\nI\n¥\n\ny\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n¥\n\nx\n\nv\nx\n\n}\n¤\n}\n\n§\nt\nv\nx\ny\nI\n¥\n\ny\n\nx\n\nx\ny\n\nx\n\nx\n\n}\n¤\n\n}\n¥\ny\n\nx\n\nx\n£\n\n{\ny\n¢\n\nv\n\n¤\n\nx\ny\n\ny\nv\n}\n£\n\nx\n\nv\n}\n\n{\n\n{\n¤\n\nx\n\nx\n\n}\n\nx\n\n¥\n\nx\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nv\n}\n\nx\ny\n\n{\n\ny\n\nx\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\nv\n\n{\n\n¤\n\n§\n\n{\n\nx\n\ny\n\nv\n\ny\n\n{\n\n¤\n\ny\n\n¤\n£\n\ny\n\nx\n£\n\nx\n\n{\n¤\n\n{\n\ny\n\n}\n\nx\n\ny\n\nv\nx\n¤\n\nv\n\ny\n\nx\n£\n\n}\n\n¢\n\n{\n\ny\n\n}\n\nx\n\n}\n\n}\n¤\n¤\n\nv\n\ny\n\nx\n\nv\n\n{\n\ny\n\n}\n\nx\n\nx\n\nB\nE\nu\nx\nH\n\nE\n\nx\nH\n<\n§\n±\n\nx\n\n{\n¤\n\n{\n\n¤\n\n{\n\ny\n\n}\n\nx\n\n}\n\n¥\n}\n¤\n¤\n¢\n\n»\n3⁄4\n\na\n{\n\n}\n\n}\n¥\ny\n\nv\n\ny\n¥\n\ny\n\n¤\n¢\n\nx\n\n}\ny\n}\n\n{\n\nv\n\ny\nx\n£\n\n}\n\n¥\n\nv\n\n¥\n¤\n\n{\n\ny\n\n}\n\nx\n\nv\n\n¢\n\n}\nx\n¤\n\ny\nx\n\nx\n\n{\n\n}\n\n}\n\ny\n\n¤\nx\n\n}\n\n¤\n¢\n\nx\n\nv\n\n{\n\ny\n\n}\n\nx\n\ny\n§\nt\nv\n¥\ny\n\nx\n\n{\n\n£\nx\n\nx\n\nv\n}\n\nx\n\n{\n¤\n\n{\n\n¤\n\n{\n\ny\n\n}\n\nx\n\nN\ny\n{\n\nx\n\n}\n\nx\n\nO\n\n}\n\n}\n\n¥\n}\n¤\n¤\n¢\n¤\n\n}\n\ny\n\n{\n\n}\n\nv\n}\n\nv\n}\n£\nx\n\n{\n\ny\n\n}\n\nx\n\n}\n\n}\n¤\n¤\n\nq\n<\n§\nU\n\n{\n\ny\ny\nx\n\n¤\n\n{\n¤\n}\n\n}\n\nx\n\nv\n\ny\n\ny\n¥\n¤\n\ny\nx\ny\n\nv\n}\n\ny\n\n{\n\n¤\n\ny\n\n¤\n£\n\ny\n\nx\n\ny\n\n}\n¥\ny\n\nv\n\n¢\n\n¥\n\n}\n\n}\n\nx\n\n{\n\n}\n\nx\n\nx\n\n}\n\nx\n\n§\nF\n\n£\n\nv\n\n£\nx\n\ny\n}\n\n{\n\ny\n\n}\nx\n¤\n\n¥\ny\n\nx\n\n}\n\nx\n\n¤\n\n¥\n\nv\n\nx\n}\n\n}\n\ny\n\nx\n\nv\n\nv\nx\n\nv\n\nv\n\n¢\n\n{\n\ny\n\n£\n\nv\n\n¥\n\nv\n\nv\n\n{\n\ny\n\n¥\n¤\n\n{\n\n}\n\n}\n\nv\nx\ny\nx\n\n}\n\nx\n\n§\nB\nx\ny\n\nv\n\nØ\n\nv\n\nx\n\ny\n¥\n\nv\n}\n\n{\n\nx\n\nx\n\n£\n\n¤\n£\nx\n\n}\n¥\n¤\n\nx\n}\n\n}\n\ny\n\n}\n\nx\n\n¥\n\nx\n\n}\n\n(r)\n\n¥\n\ny\nx\n\nv\n\n¥\n\nx\n\n{\nv\n\nB\nE\nu\nx\nH\n<\n§\nU\n\n{\n¤\n}\n\ny\n\n}\n\nx\n\nx\n\nx\n\nv\n}\n\ny\nv\n\n¥\n¤\n\nx\n\n}\ny\n¢\ny\n\ny\n{\n\nx\n\n}\n\nx\n\nx\ny\n\nx\n\nv\n\n}\ny\nx\n\ny\n¢\ny\n\ny\n\nv\n\n¢\n\nv\nx\n\nv\n\ny\n}\no\n±\no\n·\n\n}\ny\n}\ny\n\n{\n\ny\n\nv\n}\n\n}\n\nv\n\n}\ny\n}\n\nv\n\n¤\n\n}\n\nv\nx\n\n£\n\ny\n\n}\n¤\n\nx\n£\n\n§\nt\nv\n\n{\n\ny\n}\n\n}\n¤\n¤\nx\n\n¤\n}\n\n}\n\n}\n\nx\n\nv\n\nx\n\n¤\n¢\n\nx\n\nx\n\n¤\n¢\n\n}\n\nv\n\nv\n\n§\nt\nv\nx\ny\n\n{\n\n}\ny\n¢\ny\n\n¤\nx\n\ny\n\nv\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n\nv\n}\n\nv\n\ny\n¢\ny\n\n}\n¤\ny\n\n}\n\n}\n\nv\n}\n\ny\n¢\ny\n\ny\n}\n\n}\n\nx\ny\n\nx\n\nv\n}\n\nx\ny\n\n}\n{\n}\n\n¤\n\nx\n\ny\n\n{\n}\n\n}\n\nx\n\n{\n\nx\n\nx\n\ny\ny\n¥\n\nv\n\nv\n}\n\nv\n\nx\n\nx\n\n}\n\nx\n£\n\nv\n}\n£\nx\n\nv\n}\n\nx\ny\n\ny\n\n}\n\ny\n\nx\n\n§\nt\nv\n\ny\n¢\ny\n\no\n·\n3⁄4\n·\n\n}\n\n}\n\n¢\n{\n\nx\n\nx\n\nx\n\nx\ny\n\nv\n\ny\n\n¤\n\n£\n}\n\n{\n\n{\n\nx\n\ny\n\ny\n\nx\n\nx\n\nv\n\ny\n¢\ny\n\n}\n\nv\n}\n\nx\n\n§\nt\nv\n\ny\n¢\ny\n\nμ\n\n¿\nμ\n\nμ\n·\nx\ny\n}\ny\n\n{\n\ny\nN\n}\n\nv\n\nx\n\n{\n\n{\n\nx\n\ny\nO\n\nv\n}\n\n}\n\n{\n}\n\nv\n\ny\n¢\ny\n\n¥\n\nv\n\ny\n\nv\n}\n£\nx\n\n}\n\n}\nØ\n\nv\n\ny\n¢\ny\n\ny\n\n}\n\n§\nt\nv\n\nx\ny\n\n}\n\n¥\n\n}\n\n¢\n\nv\n\ny\n¢\ny\n\n}\n\nx\n\ny\n\n£\nx\n\nx\n\n{\n¤\nx\n\nx\n\n¤\n¢\n\ny\n}\ny\n\nμ\n»\n\n·\no\n\n¿\n\n·\n»\n\n·\no\n}\n\n¢\n\nv\nx\n\nv\n}\n\ny\ny\n\ny\n\nv\n}\n\n¥\n\n}\n\n¢\n§\n\nx\ny\n£\n\n¢\nx\n\n{\n\n}\n\n¥\n\ny\n\n}\n\nv\n}\n\n}\ny\n¢\ny\n\nx\ny\n}\n¤\n\n}\n¢\ny\n}\n\n¤\n\n}\n\n}\n\ny\n\n}\n\nx\n\n1⁄4\n¿\nμ\n1⁄4\n\na\n\n±\n·\nμ\n\n3⁄4\nμ\n3⁄4\n·\n±\no\n·\n§\nB\n\nv\n\ny\n}\n\n}\n\n}\n\ny\n¢\ny\n\n}\n\ny\n\n£\n\n}\n¢\ny\n\n}\n\nx\nØ\n\n{\n¥\n\n{\n\ny\n\nv\n}\n\nv\n\ny\nx\n\n}\n\n}\n¢\n}\n¤\ny\n\n¥\ny\n\nx\nØ\n\n¤\n\n£\n}\n\n{\n\n{\n\nx\n\ny\n§\nt\nv\n¥\ny\n\nv\n\n}\n¢\n\n¥\n¤\n\nx\n{\n¤\n\n(r)\n\ny\n¢\ny\n\n¤\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\nt\n\ny\n¥\n\ny\nx\ny\n\n¢\n}\n\nv\n}\n\n¥\n\nx\n\n}\n\nx\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\nx\ny\n\nI\n¥\nx\n\nv\n}\n\ny\n\nv\n\nU\no\nE\n¢\ny\n\n¥\n\n}\n\n¢\n\no\n\n{\n¥\n\ny\n}\n\n¥\n\n{\n¥\n\ny\n\no\n\n{\n\ny\n\no\nE\n\n¥\n\n¥\n\no\nq\n\n¤\n\n£\n}\n\nx\n\n}\n\nx\n\ny\n\n{\n\ny\n}\n\nv\n\n}\n\ny\n\n¢\n\nv\nx\n\nv\n\nv\n\ny\n¢\ny\n\n}\nx\n\ny\nx\n\ny\nx\n\nx\n\n¢\nN\n\nv\n\nv\n}\n£\nx\n\nv\n\n{\n\ny\n}\n\nv\n\nx\n\nØ\n\nv\n\n£\n\n}\n¤\n¤\ny\n¢\ny\n\ny\n\n}\n\nO\n\n}\n\no\nr\n¥\n\n{\n\ny\n\n}\n¤\ny\n\nv\n\ny\n¢\ny\n\nv\n}\n\n}\n¬\n\ny\nx\n\n}\ny\n\n}\n\n¤\n\ny\nx\n\nx\n\n}\n\nv\n\nx\n\n¢\nv\n\nH\nÞ\n<\n§\n±\n¤\n¤\n\nv\n\ny\n\n{\n\n{\n\nx\n\ny\n\nx\n\n¤\n¥\n\nx\n\n}\n\n{\n¤\n\ny\n¢\ny\n\n¤\n\ny\n{\n\nx\n\n}\n\nx\n\n}\n¤\n\nx\n\nv\n}\n\ny\n\nx\n{\n\nx\n\nv\n\n}\ny\n{\n\ny\n\nv\n\n£\nx\n\nv\n}\n\n}\n\n}\nØ\n\nv\n\ny\n¢\ny\n\ny\n\n}\n\n§\n\ny\n\nv\n\ny\n\n}\ny\n{\n\ny\n}\n\n}\n¤\n\n}\n\n¢\nx\n\n¤\n¥\n\nx\n\n¥\n\n¥\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n§\nF\n\n£\n\nv\n\n¤\n}\ny\n\nx\n\n}\n\nx\n\n}\n\n¥\n\n{\n¥\n\n{\n\ny\n\nx\n\nx\ny\n\n§\nU\n\nv\n\ny\n\nx\n\n{\n\n}\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\n\nv\n\n¤\ny\n¥\n\n¤\n¢\nx\n\ny\n\n¥\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n\nv\n\n}\n¤\n}\n\nx\n\n}\n¤\n\nx\ny\n\nv\n}\n\nv\n\n¢\n\n}\n\n}\n¤\n¤\n\n¥\ny\n\nx\n\nv\n}\n\nx\ny\n\n{\n¤\nx\n\nx\n\n¤\n¢\n\n{\n\ny\n\nx\n\nv\n\n¤\n\nx\n\n¤\n¥\n\nx\n\nv\n\nx\n\nx\n\nx\n\ny\n\nv\nx\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\n¢\n§\nt\nv\nx\ny\nx\n\nx\n\n}\n¤\nx\n\n}\n\nx\n\nx\ny\n\nx\n\nx\n\n}\n¤\nx\n\nv\n\ny\nx\n\n}\n\n£\n\n¤\n¥\n\nx\n\ny\n\n}\n\n§\n±\ny\nF\n}\n\n}\n\nv\n}\ny\ny\n}\nx\n\n{\n\n}\n\nx\n\n}\n¤\n\n}\ny\n\nx\n\nx\ny\n\nx\n\nv\n\nv\n}\n\nx\n\nv\nx\n¤\n\n}\n¤\n\n}\ny\n\nx\n\nx\n\nv\n\nv\n}\n\n¤\nx\n\n£\n\nF\n}\n\nH\n<\n§\n(r)\nB\n\n}\n¤\n¤\n\nx\n\n}\n\n¥\n\ny\n}\n\n3⁄4\n»\n\n¿\n\n¥\n\n}\n¤\ny\n\nx\n\nv\n\n}\n\n{\n¤\nx\n\nx\n\n¤\n¢\n\n¤\n\nv\n\n}\ny\n\n¥\n\nx\n\n}\n¤\n\n}\ny\n\nx\n\n}\n¤\ny\n\nx\n\nv\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\n\n¤\ny\n\n}\n\n¥\n\nv\n\n{\n\ny\n\ny\n{\n\nx\n\nv\n\nv\n\ny\n\n}\n\n}\nØ\n}\nx\n\ny\nx\n\nv\n\n}\n¤\n\n¤\n\nF\n}\n\nH\n<\n§\n\nv\n\n¤\n¥\ny\nx\n\ny\n\n¥\n\n{\n}\n{\n\ny\n\nx\n\nx\n\n¥\n\n{\n\nx\n\ny\ny\n{\n\nx\n\n¢\nx\n\nv\n\nI\n¥\nx\n\ny\n\nt\n±\nE\n\nN\n}\n\n}\nx\n\n}\n\n¤\n¤\nx\ny\nx\n\n}\n£\n\nx\n\n}\n\ny\n¢\ny\n\nO\n\nU\ny\n\n£\n\ny\n\nx\n\nx\n\nt\n±\nE\n\n¥\n\nx\n\nx\n\n{\n\ny\ny\nx\n\n¤\n\nx\n£\n\nv\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nx\n\n¤\n¢\n\nv\n\n{\ny\n\n¥\n\n}\n\n}\n\n}\n\n{\n}\n\n¢\nx\n\n¤\nx\ny\nv\n¤\n}\n\n¥\n}\n\ny\n\nx\n{\n\nx\n\n§\n±\n¤\n\nv\n\n¥\n\nv\n\nv\n\n}\ny\nx\n\nx\n\n}\n\nx\n\n}\ny\n}\n¤\n¤\n\nv\n\nv\n\nx\n\n}\ny\n¤\n}\n\n¤\n¢\n\nx\ny\ny\nx\n\n}\n\nv\n\n}\n{\n\n{\nx\n\n}\n¤\ny\n\ny\n\n}\nx\n\ny\n\ny\n{\n\nx\n\ny\nx\n\nx\ny\nx\n\ny\n§\nt\nv\n\nx\ny\n\nx\n\n¥\nx\ny\nv\nx\n\nI\n¥\nx\n\ny\n}\n\n}\n\nx\n\n}\n\ny\n\nv\n\nx\n\n{\n¤\n\n}\n\nx\n\n}\ny\n\n{\n\ny\ny\nx\n\n¤\n\nx\n\n}\n¤\n¤\n\n}\ny\n\ny\n§\n±\ny\nv\n}\ny\n\nx\ny\n\n£\n\n¢\n\ny\n\n{\n\n{\n¤\n\n}\n\n{\n\nx\n\n}\nx\n\n}\nx\n\ny\n¥\n\nv\ny\n¢\ny\n\ny\n\n}\n\n}\n¥\n\nx\n\n}\nx\n¤\n\nv\n\nx\n\ny\nx\n\ny\n}\n\nv\n\n}\ny\n\ny\n\nv\n¢\n\nx\ny\nx\n\ny\n\n}\n\nx\ny\n}\n\ny\n\n¤\n¥\n\n¤\n¢\n\ny\ny\n\nx\n}\n¤\n§\nt\nv\nx\ny\n\n}\ny\n\n¢\nt\n±\nE\n\n£\n\nv\n\nÞ\n@\n¢\n\n}\n\ny\n\nx\n\ny\n\n£\n\n¤\n\n{\n\n}\n\nv\n\ny\n\ny\n{\n\ny\nx\n\n¤\n\nv\n\ny\n¢\ny\n\n}\n¢\n}\n\n¥\n\n¤\n¢\n}\n\n{\n\nx\n\ny\n\n¥\n\nx\ny\nx\n\n}\n¬\nx\n\nx\n\n}\n\nx\n\n¤\n\ny\n}\n\n{\n\n}\n\n¢\n§\nB\n\nv\n\ny\n\n{\n}\n\n¤\n¢\n\n{\n\ny\n\nx\ny\n}\n\n¤\n\n{\n¤\n}\nx\n\nv\n¢\ny\n\nx\ny\nx\n\ny\n\n}\n\nv\n¢\n\nv\nx\n\ny\n\ny\nx\n\nx\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\n¢\nu\nF\nF\nq\ny\n<\n§\nt\nv\n\nx\ny\n\nx\n\ny\n{\n\n}\n\n}\n\n}\n\n¥\n\nv\n\ny\nx\n\n}\n\nx\n\n}\n¤\n\nN\nx\n\nO\nx\n\n}\n\nx\n\nx\n\n¥\n\ny\n\n}\n\n{\n¤\n\ny\n\n}\n\n¤\n¢\n}\n\nz\n\nx\n\n¤\n¢\n\nv\n}\n\n}\n\n}\n¤\n¢\nn\n\nv\n\nx\n\n{\n}\n\nv\n}\n\ny\n\nx\n\n§\nU\nx\n\nv\n\n¥\n\n}\n\nx\n\nx\n\n{\n\n}\n\nx\ny\nx\n\ny\n\n}\n\n¥\n\n¥\n\nx\n\n}\nx\n\n}\n\nU\n\n}\n\n¢\ny\n\nx\n\n¥\ny\n}\n\nx\n\ny\n}\n\n¤\n\ny\ny\n\ny\n\n}\n\n}\n\nv\n\n}\n\nv\n}\n\n}\ny\n¢\ny\n\nx\n\n{\n\n}\n\n}\ny\nx\n\n}\n¥\ny\n\nv\n}\n\ny\n\nv\n}\n\n¥\n¤\n¤\n¢\n\nx\n\n}\n\n¥\n¤\n¤\n¢\n}\n\n}\n¤\n¢\nn\n\nx\n\nv\n\nx\n\nØ\n\ny\nu\n\n£\n@\n<\n§\nU\nv\n}\n\nx\ny\n\ny\n\n¤\n\n}\n\nx\ny\n\nv\n\n}\n\ny\n\n¥\n\n¥\n\nv\n\nx\n\n}\n\nx\n\nv\n}\n\nx\ny\n\n§\nE\nx\n\n{\n¤\n¢\n¬\n\n{\nx\n\n}\n\n}\n¥\n\nx\n\n}\nx\n¤\n\nx\ny\nx\n\ny\n}\n\nv\n\n}\n\ny\n\ny\n\nv\nx\n\nv\n\n}\ny\n\nv\n\n¢\n}\n\n}\n\nx\ny\n\n{\n\n}\n\nx\n\n}\n¤\n§\nt\nv\n\n¥\n\nx\ny\nx\n\ny\n\n}\n\nx\n\n}\n\n¢\n¤\n}\n\n{\n\nx\ny\n\n¥\ny\n§\n\n£\n\nx\n\nx\n\n{\n\ny\ny\nx\n\n¤\n\nx\n\nv\n\n}\n¤\n¤\n\nx\n\nv\n\n{\n\n{\n\nx\n\n}\n\nx\n\nv\n\ny\n\ny\n\n}\nv\n\n{\n\n¤\n\ny\ny\n\n}\ny\n¬\nx\n\ny\n\n¥\n\n¥\n\n}\n{\n{\n\n{\n\nx\n}\n\n¤\n¢\n§\nU\nv\n}\n\nx\ny\n\nx\ny\n}\ny\n{\n\nx\n\n}\n\nx\n\nv\n\nx\n\nN\n\n}\n¤\ny\n\ny\n\n}\nx\n\ny\n\n}\n\ny\nx\n\n}\n\nx\n\n}\n¤\n\nO\n\nv\n\nx\n\nx\n\n}\n\nx\n\n¥\ny\n\ny\n{\n\nx\n\nx\n\n}\n¥\ny\n}\n\n¤\n\n}\n\n{\n\n{\n\n¥\n}\n¤\n¤\n¢\ny\n}\n¤\nx\n\n}\n\n§\nt\nv\n}\n\nx\ny\n\n}\n\n}\n\n¬\n\nx\n\nv\nx\n\nv\nx\n\nv\n\ny\n\n¤\n\n}\n\ny\n{\n\nx\n\n¢\n\nv\n\ny\nx\n\nx\ny\nx\n\ny\n\nv\n}\n\n}\n\n£\n\n¤\n\n{\n}\n\n}\nx\n\n}\nx\n\ny\n\n}\n\n§\n\n»\n¤\n\n1⁄4\n\n¤\n1⁄4\n\nt\nv\n\nv\nx\n\n}\ny\n{\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\no\n·\n\n1⁄4\n·\n\nx\ny\n\nv\n\n}\n\ny\nx\ny\n\n}\n\nx\nn\nx\n\nx\n\n}\n\nx\n\nx\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n§\nt\nv\n\nx\n\n}\n\nx\n\n}\n¢\n}\n¤\n¤\n\nx\n\n¤\n¥\n\ny\n\nv\n\n¥\n\nx\n\n}\n¢\n\nv\n}\n\nx\n\nv\n\n¤\n}\n\nx\n\ny\nv\nx\n{\n\nx\n\n}\n\nx\n\ny\n{\n\nx\n\n¤\ny\n\nv\n\n§\nr\n\n¤\n\ny\n\n¤\n£\nx\n\nx\n\nv\n\n¤\n\nx\n\n}\n¤\ny\n¢\ny\n\ny\n\n}\n¬\n\ny\n{\n¤\n}\n\nx\n\nv\nx\n\nv\n\n}\n\n{\n¤\n\n}\n¥\ny\n}\n¤\n\n¬\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\n|\n\nH\nx\n\nq\n}\ny\nH\nw\n\nq\n\n}\nm\n\nq\n<\n\n}\n\nv\n\ny\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\n\nx\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n§\nt\nv\n\nx\n\n}\n\nx\n\ny\n\n¤\n£\n\n}\n{\n\n¤\n\n}\n¢\n}\n¤\n¤\n\nx\n\n¤\n¥\n\ny\n\nv\n\nx\n\nv\n\n}\ny\ny\n\n¥\n\n}\n\nx\n\n¥\ny\n\nx\n\n¤\n}\n\n{\n\ny\n\n¥\n\nx\n\n}\n¢\n\nv\n}\n\nv\n\nx\n\nv\n\n¤\n}\n\nx\n\ny\nv\nx\n{\n\nx\n\n}\n\nx\n\ny\n{\n\nx\n\n¤\ny\n\nv\n\n§\nr\ny\n¢\n\nv\n\n¤\n\nx\n\n}\n¤\n\n{\n\nx\n\ny\nx\n\n{\n\n¤\n\ny\n\n¤\n£\n\nx\n\nv\n}\n\n{\n\n{\n¤\n\n}\n\n{\n\nx\n\n}\n\nx\n¤\n¢\n\n{\n\n{\n\n¥\n}\n¤\n¤\n¢\ny\n}\n¤\nx\n\nx\n\n}\n\nx\n\nE\nE\nm\n<\n§\nt\nv\n\n}\n¤\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\nx\n\ny\nv\n\n¥\n¤\n\n}\n¬\n\nx\n\n}\ny\n¢\n\n¥\ny\n\ny\n\n}\n\n}\n\n¥\ny\n\nv\n\nx\n\n{\n\n}\n\nx\n\n}\n\nx\n\nv\n\ny\n{\n\nx\n\n}\ny\n¬\n}\n\nv\n}\n\nv\nx\n\nv\nx\n\n¤\n¥\n\ny\n}\n¤\n¤\n{\n\nx\n}\n¤\n\n}\ny\n¬\ny\n\n¤\n}\n\n¥\ny\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n§\n\nx\n\nx\n£\n\nx\n\ny\ny\n{\n\n}\n¬\n\nv\nx\ny\n{\n\n¤\n\n}\ny\n(r)\nx\n\n}\n\nx\n\n{\nx\n\n¬\n¥\n{\n\nU\n\n@\n<\n§\n\n¥\ny\n\n}\n¥\ny\n\nv\n\nx\n\n}\n\nx\n\nx\ny\nx\n\nv\n\nx\n\n}\n\ny\n\n}\n\nv\n}\n\nv\n\n{\n\n}\n\n}\n\nx\n\n}\ny\nx\n¤\n¢\n§\nt\nv\n\ny\n}\n\nx\ny\n\n¥\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\nt\nv\n\n{\n\n¤\n\nx\n\n}\n\nx\n\n{\nx\n\n¬\n¥\n{\nx\ny\n\n{\n\n¥\n\n¢\n\nv\n\n}\n\nv\n}\n\nv\n\nx\ny\ny\n\n¥\n\nv\nx\n\n}\n\nx\n\nx\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\nx\n¤\n\n¤\n¢\n}\ny\n\n}\n¤\n¤\ny\n¥\n\ny\n\nx\n\n}\n¢\n\n¤\n\n£\n}\n\nx\n\n}\n\n¢\n\nx\n£\n\n§\n¿\ns\n¿\ns\nA\nA\nA\nA\nA\nA\nÆ\nC\nE\nk\nE\nt\nv\n\n{\n\n¤\n\ny\nx\n\n¥\nx\n¤\n\nx\n\n}\n\nx\n\n}\n\nx\n\nx\n\nv\ny\n¢\ny\n\ny\n\n¤\n¢\n}\n\nx\n\n{\n¤\n\nx\n\n¢\n}\n\nx\n\n¤\n¤\n\n¥\n}\n¤\n\n}\n\n}\n\n}\n\nx\n¤\nx\n\n¢\n§\n±\n\n}\ny\nx\n\n}\n\n{\n\nx\n\nx\n{\n¤\n\nx\n\nx\n\nx\ny\n\n¬\n\n{\n\nv\nx\n\ny\ny\nx\n\n{\n¤\n\n§\nt\nv\nx\ny\n{\n\nx\n\nx\n{\n¤\n\n¥\n\ny\n\nx\ny\n\n}\ny\nx\n\ny\n\n}\n\nv\n}\n\n§\n±\ny\nv\n\n¢\nD\ny\nu\n}\n\nq\n\nI\n¥\nx\n\ny\nx\n\n}\n\nx\n\n¢\n±\ny\nv\nw\n<\n\n¤\n¤\ny\n¥\ny\n\nv\n}\n\nv\n\nx\ny\n}\n¤\nx\n\nx\n\nv\n\ny\nx\n\n{\n¤\n\n}\n\n}\n¬\n\n¤\ny\n¢\ny\n\ny\n\nx\n\n¤\n¥\n\nx\n\nv\n\ny\n\ny\nx\n\ny\n\n{\n\ny\n\nx\n\ny\n\n}\n\n}\n\ny\n\nx\n¤\n¤\nv\n}\n£\n\nv\n\nØ\n\nx\n£\n\n§\n\n}\n\nx\n\nx\n\n}\ny\nx\n\nv\n¥\n\n}\n\n}\n\nx\n¤\nx\n\n¢\nx\ny\n\nv\n}\n\nx\n\n§\n\nv\n¥\n\n}\n\ny\n\n}\n\n¥\nx\n¤\n\n}\n\n{\n\n}\n\nx\n\n}\ny\nx\n\n¤\n¢\n\n{\n¤\n\ny\n¢\ny\n\ny\n\nx\n\n}\ny\n\nv\n}\n\nx\ny\nx\n\n¤\n¤\n\n¥\n}\n¤\n¤\n¢\n\n}\n\n}\n\n}\n\n¤\n\n§\nt\nv\n}\n\nx\ny\n\nx\n¤\n¤\n\n}\n¢\ny\n\n3⁄4\n\nE\n\nμ\n·\nv\n¥\n\n}\n\n}\n\nx\n¤\nx\n\n¢\n§\nt\nv\n\ny\nx\n\n¥\n}\n\nx\n\nx\ny\n\nv\n\n{\n\n¤\n\ny\ny\n§\n±\ny\nq\n}\ny\n\n¥\ny\ny\n\ny\n\n£\n\ny\n\nv\n\n{\n¤\n\nx\n\n¢\n\n}\ny\n¢\ny\n\nx\ny\n\n}\n\nx\n£\n\n}\n\n¥\n\nv\n\ny\n¢\ny\n\nq\n}\ny\nH\n@\n<\n§\nU\n\ny\n\n£\n\n{\n¤\n\nx\n\n¢\n\n{\n\ny\n¥\n{\n\nv\n\n¤\n\n£\n\n¤\n\ny\n\n¤\n¥\n\nx\n\n¥\n{\n\nv\nx\n\nv\n\nv\n\ny\n¢\ny\n\nx\ny\n\nx\n\ny\nx\n\n§\n±\ny\nx\n\n{\n¤\n\ny\n\n{\n¤\n\nx\n\ny\n\n£\n\nv\n\n¥\n\nv\n}\n\nx\n\ny\n\n{\n\n§\n\n{\n¤\n\nx\n\n¢\n\nv\n\n}\n\n¤\n¢\n\nx\n\nv\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\n{\n\ny\n\n}\n\nx\n\n}\ny\n¢\ny\n\n}\n\nv\n\n}\n\n¤\n¢\n\n}\ny\n¥\n\n¤\n}\n\nx\n£\n\nv\n\ny\n¢\ny\n\ny\n\ny\n\n£\n\n}\n\nv\n\ny\n}\n\n¤\n\n£\n\n¤\n\n}\n\ny\n\n}\n\nx\n\n§\nt\nv\n¥\ny\n\n}\n\n}\n¢\n\n{\n\nx\n\nv\n\n{\n¤\n\ny\n¢\ny\n\ny\nx\ny\n\ny\n\n¥\n\n¥\n\nv\n\ny\nx\n\n¥\n}\n\nx\n\ny\n¥\n\nv\n\nv\n}\n\nv\n\ny\n\n£\n\n}\n\n}\n\ny\n\nv\n\n{\n\n¤\n\nx\n\ny\n\n¤\n£\n\n}\n¤\n\n£\n\n¤\n\n}\n\ny\n\n}\n\nx\n\nx\n\nv\n¤\n\ny\ny\n\ny\n\n¤\n¥\n\nx\n\n§\nt\nv\n\n{\n¤\n\nx\n\n¢\n\n}\n\n¢\n\nv\n\n¥\nx\n¤\n\ny\n\n@\n\n¥\ny\n\ny\n\n}\ny\n¢\ny\n\nx\ny\n\nx\n\n¢\n\nv\n\nx\n\nμ\n·\n3⁄4\n·\n\n¿\na\n¶\n\n·\no\nN\n\n{\n\ny\n\n}\n\nx\n\ny\nO\n\nv\n\nx\n\n}\n¤\ny\n\n}\n\nv\n\ny\n¢\ny\n\n§\nU\n\n¥\nx\n¤\n\ny\n¥\n\nv\n\n}\n¤\n\n¤\ny\n}\n\n¥\n{\n\n}\n\nv\n\n}\ny\n\nv\n}\n\ny\n\n£\n\n}\n\n¥\n\nv\n\ny\n¢\ny\n\nv\n}\n\nx\ny\n\n¢\n\n}\n\ny\n\n¥\n\nx\n\n}\n\nv\n\ny\n¢\ny\n\n§\nt\nv\n\nv\n\n}\n{\n{\n}\n\n{\n¤\n\nx\n\n¢\n\n}\ny\n¢\ny\n\n¥\n¤\n\nx\n\n}\n\n¤\n¢\n\n{\n\ny\n¥\n{\n\nv\n\nv\n\n¤\n\n¢\n\nv\n\nx\n\n}\n\ny\n¢\ny\n\nq\n}\ny\nH\n@\n<\n§\nt\nv\n\ny\n\n¤\n¥\n\nx\n\nv\n\n{\n¤\n\nx\n\n¢\n{\n\n¤\n\nx\ny\n\n}\n¬\n\n}\n\n£\n}\n\n}\n\nv\n\ny\n\n{\n\n¥\n¤\n\ny\n\n¥\n\ny\n{\n\n{\n¤\n\nv\n}\n£\n\n}\n¤\nx\n\nx\n\nv\n\n{\n¤\n\nx\n\n¢\n§\n\n}\n\nv\n}\ny\n\n(r)\nr\n\n{\n¤\n\nD\n\nx\n\n}\n¤\nx\n\nx\n\nv\n\n{\n¤\n\nx\n\n¢\nx\n\nv\n\n¢\nv\n}\n£\n\ny\n\n}\n¢\n\n¤\n¤\nx\n\nv\n}\n\n¤\nx\n\nx\n\n§\n§\n§\n\n}\n{\n\ny\n\nx\ny\n}\n¤\n¤\n\ny\n\n¥\n\n¥\n\n}\n\n{\n¤\n\ny\nx\n\n¥\n}\n\nx\n\n}\n\nx\n\nv\nx\ny\n{\n\n{\n\n¥\n}\n¤\n}\n\n{\n\n¥\n}\n¤\n\ny\n\ny\nv\n\n{\n¤\n\nx\n\n¢\nx\ny\n\n}\n\nØ\n\nx\n£\n\n{\n\n}\n\nw\nw\n\nq\n}\ny\nH\n@\n<\n§\nt\nv\n¥\ny\n\n{\n¤\n\nx\n\n¢\nx\n\ny\n\n¤\n\nx\ny\n\n}\n{\n\n¤\n\nx\n\nv\n¥\n\n}\n\ny\n}\n\n{\n\ny\n\nx\n\nv\n\n}\n\nx\n\n¥\n¤\nx\n\n}\n\nx\n\nx\n\n}\n\nv\n\ny\n\n¥\n\n¥\n\n§\n¿\ns\n¿\ns\nI\nI\nE\nÆ\nl\nn\nl\np\nI\nE\nÐ\nI\nÆ\nA\nl\nE\nt\n\n}\n¢\ny\nv\n¥\n\n}\n\ny\n\n{\n\nx\n\nv\n\n{\n¤\n\nx\n\n¢\nx\ny\n\n¥\ny\n\n{\n\n}\ny\n\nx\n\n}\n\ny\n\n}\n\nx\n\nv\nx\n\n}\n\nv\nx\n\ny\n§\nt\n¥\nx\n¤\n\nx\n\ny\n¢\ny\n\ny\n\n¥\n{\n\n¬\ny\n\n¤\n}\n\nx\n£\n\n¤\n¢\ny\nx\n\n{\n¤\n\ny\n¢\ny\n\ny\n§\nt\n¥\n\n}\ny\n\nv\n\n¥\n\n}\ny\n\ny\n}\n\ny\n\nv\n}\n\n¥\ny\n\ny\nx\n\nx\n\n}\ny\n\ny\n\nv\nx\ny\n}\n{\n{\n\n}\n\nv\n\ny\n¥\n\n¬\n}\n\n¤\n\n¢\n\nv\n\n¤\nx\n\nx\n\ny\n\nv\n¥\n\n}\n\n¢\n}\n\n¤\n\nx\n\n}\n¤\n}\n\nx\n¤\nx\n\n¢\n\n{\n\nx\n\nv\n\nv\n\n{\n¤\n\nx\n\n¢\n§\nt\n\n{\n\n}\ny\n\nx\n\nx\ny\n}\n\n}\n¢\n\n}\n\n}\n\nx\n\nv\n}\n\n{\n¤\n\nx\n\n¢\n§\n±\n\nv\n\ny\n}\n\nx\n\nv\n}\n£\n\n¥\n\nv\n}\n\n{\n¥\n\n{\n\n}\ny\n\nx\n\nx\ny\n\n}\n\nI\n¥\n}\n\n}\n¤\n\nv\n¥\n\n}\n\ny\n\nx\n\n{\n\nx\n\nv\n\n¥\n{\n\n}\ny\n\nx\n\n§\nt\nv\n¥\ny\n\nv\n\ny\n\n¥\n\n¥\n\nv\n\nx\n\n}\n\nx\n\n¥\ny\n\n}\n¤\n¤\n\n}\ny\n\nx\n\nx\n\nv\n\nx\n\nx\n\ny\n§\n\n}\n\nx\n\nx\n\nv\n¥\n\n}\n\ny\n\n{\n\nx\n\nv\n\n{\n¤\n\nx\n\n¢\n\n¢\n\n¥\nx\n¤\n\nx\n\ny\n\n}\n\nx\n\nv\nx\n\n}\n\nv\nx\n\ny\n§\n\n¤\ny\n\n{\n¤\n\ny\n¢\ny\n\ny\n\n}\n\n{\n\ny\ny\n\nx\n\ny\n\n}\nμ\n\n3⁄4\n\n1⁄4\nμ\n±\n\n¤\n\n£\n\n¤\ny\n\n}\n\nx\nn\n}\n\nx\n\n}\n\nv\n\n{\n¤\n\nv\n}\n\nv\n\n¤\n\nv\n\n}\n¤\n\n£\n\n¤\nx\ny\n\nv\n}\n\n}\n\nx\nn\n\n¢\nv\n}\n£\nx\n\nE\n\nμ\n·\n{\n\n{\n\nx\n\ny\n§\nt\nv\n\n{\n\nx\ny\n\nv\n\nx\n\n}\n\nv\n}\n\n}\n\n}\n\n¢\n\nx\n£\n\n¤\n\n£\n\n¤\n\n{\n¤\n\nx\n\n¢\n\ny\n\n{\n\n{\n\nx\n\ny\n\nv\n}\n\n}\n\nx\ny\n\nx\n\nv\n}\n\n¤\n\n£\n\n¤\nN\n\n}\n\nv\n}\n\n¤\n\n£\n\n¤\nO\n}\n\nx\n\n¥\n\nx\n\n¤\n\n§\nE\n¥\n\nv\n{\n\n{\n\nx\n\ny\n\nx\ny\n\n}\n\n¤\n\n¤\n\n£\n\n¤\ny\nx\n\nv\n\ny\n\ny\n\nv\n}\n\nv\n\n¢\n}\n\n}\n\nx\n\n¤\n\ny\ny\nx\n\nv\n\n¤\n}\n\n¥\n}\n\n}\n{\n{\n\n{\n\nx\n}\n\nv\n\ny\n\n¤\n\n£\n\n¤\ny\n§\nB\n\n}\n\n{\n¤\n\nv\n\ny\nv\n}\n{\n\n}\n\n}\n{\n{\n¤\n\n}\n¤\n\nv\n\n¥\n\nv\n\n£\n\n¥\n}\n¤\n¤\n¢\n\n{\n¤\n}\nx\n\n}\n\n¤\n\nx\n\ny\n\nv\n\n¤\n¤\ny\n\nv\n\n}\n{\n{\n¤\n\nv\n}\ny\n\n}\n\nx\n\n}\n\nv\n}\n\n¤\n\n¤\n\n£\n\n¤\n\ny\n\nx\n{\n\nx\n\n§\nq\n\n¥\n¤\n}\n\n¢\n\n1⁄4\n¿\nμ\n·\n\n¿\n·\n}\n\nx\n\nx\n\n£\n\n¤\n£\n\ny\nx\n\n{\n\ny\nx\n\ny\n\n}\nx\n\ny\n¥\n{\n\nv\n\n}\n\nx\n£\nx\n\n¢\n}\n\n¤\n\n£\n\n¤\n\n}\nv\nx\n\n}\n\nv\n¢\n§\nt\nv\n\ny\n\ny\n\n}\nx\n\ny\n\nv\n\n(r)\n¤\n}\n\ny\n\nv\n}\n£\nx\n\n}\n\nv\n}\n\n¤\n\n£\n\n¤\n\nv\n}\n\n¢\nx\n\n¤\n\n}\n\nx\n£\nx\n\n¢\n\n}\n\nx\n\n¥\n¤\n}\n\n}\nv\nx\n\nv\n\n¤\n\n£\n\n¤\nN\n\nv\n}\n£\nx\n\nO\n§\nF\nx\n\n}\n\nv\nx\n\ny\n}\n\nv\n}\n\n}\n\nx\nn\n\n¢\n\n¤\n{\n\ny\ny\n\ny\n\n{\n\n}\n\nx\n\n}\n\nv\n\nx\n\n}\n\ny\n\n¤\n\n£\n\n¤\ny\n§\nv\n\n¬\n¤\n}\n\n{\n¤\n}\nx\n\ny\nx\n\nU\n±\n\n¢\n\ny\n\nx\n{\n\nx\n\n}\n\n¤\n{\n\ny\ny\n\n}\nx\n¤\ny\n}\n\n¥\n{\n{\n\n¤\n\n£\n\n¤\nx\n\n{\n\ny\nx\n\ny\n\n}\nx\n\ny\n¥\n{\n\nv\n\n¤\n\n§\nt\nv\n\n¥\n{\n{\n\n¤\n\n£\n\n¤\nx\ny\n}\ny\n\n¥\n\n}\n\n}\n¤\n\n}\n\nx\n£\n\nN\ny\nx\n\n{\n¤\n\nO\n\ny\n\nx\n{\n\nx\n\nv\n\n¤\n\n¤\n\n£\n\n¤\nx\n\ny\n\ny\n{\n\nx\n\n¥\n\nx\n\ny\n\nv\n}\n\n}\n\n}\ny\n}\n\ny\n¥\n¤\n\nv\n\nx\n\n{\n\ny\nx\n\nx\n\ny\n\n}\nx\n\ny\nv\n\nH\nÞ\n\n{\n\n§\nH\nx\n<\n§\nF\nx\n\n}\n\nv\n¢\n\nv\n\n¢\n\n}\n¤\ny\n\nx\n\nv\n\nv\n\n¥\n\n}\n\n}\n¤\n\nx\nØ\n\ny\n\n¤\n\n£\n\n¤\n\n{\n¤\n\nx\n\n¢\n}\n\n}\n\nv\n\n§\n\ny\n¥\n¤\n\nx\n\n}\n\n}\nx\n\nx\ny\n\n{\n¤\n}\nx\n\nv\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\n\nx\n\n¤\n\n£\n\n¤\ny\nU\n\nv\n}\n\n}\n\ny\n\nv\n\n¤\n\n£\n\n¤\ny\n\nv\n}\n\ny\n\n{\n}\n\n}\n\ny\n\nv\n\n}\n\nv\n}\n\n¤\nx\n\n¬\ny\n\nv\n\n§\n\n{\n\n{\n\nx\n\ny\n}\ny\ny\n\nx\n\n}\n\nx\n\nv\n}\ny\n\n{\n\ny\n}\n\n¤\n\n£\n\n¤\nx\n\n}\nv\nx\n\n}\n\nv\n¢\n}\n\n¤\n}\n\ny\n\n}\nx\n\ny\n¥\n{\n\nv\n\nv\n\ny\n\n{\n\ny\n§\n\nv\n\nv\nx\ny\n{\n}\n{\n\nx\n\nx\ny\nx\n\n{\n\n}\n\nv\n}\n\ny\n\nx\n\nx\n\nv\n\n{\n\n{\n\nx\n\ny\n\ny\n¥\n¤\n\nx\n\nv\n\nx\n\n{\n\ny\nx\n\nx\n\ny\n\n}\nx\n\ny\n\nI\n¥\nx\n\ny\n}\n¤\n}\n\n¥\n}\n\n}\n\n}\nv\nx\n\nv\n\n¤\n\n£\n\n¤\nN\n}\n\n}\n¤\n\n£\n\n¤\nO\na\n\nO\n\nμ\n·\n\nv\n}\n\nv\n}\n\ny\n\nx\n\nx\n\nv\n\n{\n\ny\n\nv\n\ny\n\n¤\n£\n\ny\n§\nt\nv\n¥\ny\n\nx\n\ny\n\nx\n{\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n}\n\nI\n¥\nx\n\n}\n\n}\n\nv\nv\nx\n\n}\n\nv\nx\n\n}\n¤\n¤\n\n£\n\n¤\n§\nt\nv\n\n{\n\n¤\n\nv\n\ny\n\nx\n\nx\n\n}\n{\n{\n\n{\n\nx\n}\n\n¢\n{\n\ny\n\nv\nx\n\n}\n\nv\nx\n\n}\n¤\n}\n\ny\n\n}\n\nx\n\nv\n}\n\n}\n¤\n¤\n\nv\n\n{\n\n}\n\n¥\n{\n\n}\ny\n\nx\n\n§\n\n{\n¥\n\ny\n\nx\n\nv\n}\n£\n\n}\n\n¥\n\nv\n¥\ny\n\n{\n}\n\nv\n\n¤\n\n}\n\ny\n\n}\n\nx\n\ny\n\nv\n\n}\n\nv\n¤\n\n£\n\n¤\n\n}\nv\nx\n\n}\n\nv\n¢\n\n{\n\ny\n\ny\n}\n\n}\n\n}\n\nx\n\nv\n\n{\n\ny\n}\n\n}\n¤\n\n¤\n\n£\n\n¤\n}\n\nx\n\n}\n\nx\n\nv\nx\n\nx\n\n}\n\ny\n\n}\n\nx\n\ny\n\nv\n\n}\n\nv\n¤\n\n£\n\n¤\n\n}\nx\n\ny\n\nv\n\ny\n}\n\n{\n\n¥\n}\n¤\nx\n\n}\n\nx\n\n¥\n\nv\nx\n\ny\ny\n\n}\nx\n¤\ny\n}\n\n¥\n\nv\n\n{\n\ny\n\nv\n}\n\nx\ny\n\n}\n\nv\n¤\n\n£\n\n¤\nx\ny\n}\n\nv\n\nx\n\n}\n\nx\n\n}\n\n}\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n§\n\n}\n\nv\n¤\n\n£\n\n¤\n\n¥\n\ny\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n\nv\n\n¥\n\nv\n\n}\ny\n{\n\n£\nx\n\nx\n\nO\nμ\n3⁄4\n·\nx\n\n}\n\nx\n\nv\nx\n¤\n\nv\n\n¤\n\n¤\n\n£\n\n¤\n\ny\n\nx\n\ny\nμ\n¿\nO\n§\nE\n¥\n\nv\nv\nx\n\n}\n\nv\nx\n\ny\n\nv\n\n£\n\n{\n\n£\nx\n\nx\n\n}\n\nx\n\n}\n\n¥\n\nO\nμ\n±\n§\nF\nx\n\nv\n\n¤\n\n£\n\n¤\n\nx\n\n}\n\nx\n\n}\n\n¥\n\n{\n¥\n\n{\n\ny\n\nx\n\n}\n\nx\n\nv\n}\n\n}\n¤\n¤\n¢\nx\n\n¤\n¥\n\nx\n\ny\n¥\n\nv\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\n|\n\ny\nx\n\ny\n\n}\n¢\n\ny\n¥\n¤\n\nv\n\nx\n\nv\n\n¥\n\ny\ny\nx\n\n¤\n¢\n}\n\n¥\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\nx\n\nx\n\nx\n\n¥\n\nx\ny\nx\n\n}\n¬\nx\n\n{\n\ny\ny\n§\nB\n\n}\n\n{\n¤\n\nv\nx\n¤\n\ny\n{\n\nx\n\n¢\nx\n\nv\n\ny\n¢\ny\n\nI\n¥\nx\n\ny\n\nt\n±\nE\n\nu\nF\nF\nq\ny\n<\n\n¤\n\n}\n\n{\n\ny\n\nv\n}\n\ny\ny\nx\n\n}\n\n¥\n£\n\ny\n}\n\n}\n£\n\nx\n\nx\n\nv\n\ny\nx\n\ny\n}\n\n¢\n\n}\ny\n\ny\n§\nt\nv\n\n}\n\n}\n¤\n¢\ny\nx\ny\n\nv\nx\n\nv\n\nv\nx\ny\n\nx\ny\nx\n\nx\ny\n\n}\ny\n\ny\n{\n}\n\n¤\n¢\n\n{\n\nx\n\n¥\n\nx\n\nt\n±\nE\ny\n¢\ny\n\ny\n\nx\n\n}\n¤\n}\nx\n\n}\n\n}\n\n{\n}\n\n¤\n¢\n}\ny\n}\n\ny\n¥\n¤\n\n}\n\ny\nx\n£\n\ny\n}\n\n¢\n}\n\n}\n¤\n¢\ny\nx\ny\n{\n\nv\n\ny\n¢\ny\n\n§\nt\nv\nx\ny\n\ny\nx\n\ny\n\n}\nx\n\n¥\n¤\n\n}\n{\n{\n}\n\nx\n\ny\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n¥\n\n¤\n\ny\ny\nx\n\n}\n\nx\n\nv\n\ny\n\n}\n\nx\n\n¥\n¤\n\n}\ny\nx\n¤\n¢\n\n£\nx\n\n¤\n}\n\n¥\n\nx\n\ny\n¢\ny\n\nx\n\n}\n\nx\n\n¥\n\n¤\n\ny\ny\nx\n\n}\ny\n\n}\n\n}\ny\nx\n¤\n¢\n¤\n\n}\n\n§\nt\n¥\n\nv\n\n}\n\n}\n\ny\n\n}\n\nx\n\ny\n\nv\n}\n\n}\n\n¥\ny\n\nx\n\ny\n\n}\n\nx\n\nw\n\nv\nx\n\n}\n\nv\nx\n\ny\n\nv\n\nv\n}\n\n{\n}\n\nv\n\n¤\n\n}\n\ny\n\n}\n\nx\n\n§\nU\nv\nx\n¤\n\nx\n\n£\n\ny\n\nx\n\n}\n\nx\n\nv\n\ny\nx\n\ny\n}\n\nv\n¥\n\n}\n\n}\n\nv\nx\n\nx\n\n}\n\nx\n\nq\n}\ny\n\n¥\ny\ny\n\ny\n\n¥\n\nx\n\n{\n\n¤\ny\n\n¢\n{\n\n{\n¤\n\n¬\nx\n\n{\n¤\n\ny\n¢\ny\n\ny\nN\n{\n\ny\ny\n{\n¤\n}\n\n{\n\n}\n\ny\n}\n\n{\n¥\n\n}\nx\n\n}\nx\n\ny\nO\n}\n\n¥\n\nv\n}\n\nv\n\n¢\ny\n\n¥\n\n¥\n\nv\n\ny\n¢\ny\n\n}\n¤\n\nx\n\ny\nx\n\ny\nU\nN\nÞ\nO\n}\n{\n}\n\nv\n\n¤\n\n}\n\ny\n\n}\n\nx\n\nx\n\nv\nx\n\nv\n\nv\n\ny\n¢\ny\n\nx\ny\n£\nx\n\n}\ny\n}\n\n¥\n{\n\n¤\n}\n\n{\n\ny\n}\n\ny\n\n£\n\n}\n¤\n¤\n\n£\n\n¤\ny\n\n{\nv\n¢\ny\nx\n\n}\n¤\n}\n\n}\n\nx\n\n}\n\nN\n\nO\n}\n\n}\n\ny\n\ny\n}\n\ny\n\n}\n\nx\n\nq\n}\ny\nH\nw\n<\n§\n¿\ns\n¿\ns\n¿\nØ\nÆ\nn\nU\nj\nU\nU\nU\nU\nj\nI\nE\nÆ\nl\nn\nl\np\nI\nE\nÆ\nj\n\n}\n\n}\n\ny\n\n}\n\ny\n\n}\n\nx\n\n}\n\nv\n¤\n\n£\n\n¤\n\n{\n\ny\n\ny\n}\n\nx\n\n¤\n\nv\n\ny\n}\n\ny\n¢\ny\n\n§\n±\n\n}\n\n¢\n{\n\nx\n\nx\n\nv\n\nv\nx\n\n}\n\nv\n¢\n\nv\n\nx\n\n}\n\nx\n\n}\n\n¤\n\n£\n\n¤\n}\n\ny\n}\ny\n\nv\n\n}\n¤\ny\nN\n\nv\n\ny\nO\n\nx\n\nv\n\ny\n{\n\nv\n\n¤\n}\n\nv\n\n¤\n\n¤\n\n£\n\n¤\nN\n\nv\n\n}\n\ny\nO\n§\nt\nv\n¥\ny\n\nx\n\n}\n\n}\n\ny\n\ny\n}\n\ny\n\n}\n\nx\n\nv\n\n¥\n\n¤\n\n£\n\n¤\ny\n{\n\nx\n\ny\nO\nμ\n3⁄4\n·\n\nv\n\n¤\n\n£\n\n¤\n\n¤\n\nμ\n¿\nO\n\n}\n\nv\n\n¤\n\n£\n\n¤\n}\n\n£\n\nO\nμ\n±\nq\n}\ny\nH\nw\n<\n§\n\ny\ny\n\nv\nx\ny\nx\n\nx\n\n}\n\nx\n\nx\ny\n\nx\n\nv\n\ny\n\ny\n\ny\n¢\ny\n\nv\n\n¢\nU\nU\nv\n\n£\nx\n\n¤\n\n£\n\n¤\n\nv\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\nv\n\nv\n}\n\nx\n\ny\n¢\ny\n\n{\n\n{\n\nx\n\ny\n\n{\n\ny\n\nx\ny\n\n¤\n¢\n\n£\n}\n¤\n\n}\nx\n¤\ny\n\nx\n\n}\n\nx\n\nv\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\n}\n\nx\n}\n¤\n{\n\n{\n\nx\n\ny\n§\n\n¥\n\n}\n\n}\n¤\n¤\n¢\n\nx\n\n}\n\nx\n\nx\ny\n}\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n{\n\nx\n\nx\n{\n¤\n\ny\n\n£\n\nx\n\nv\n\nx\n\n}\n\nx\n\nv\n\n£\n}\n\nx\n\n¥\ny\n\n¥\n\nx\n\ny\n\n¤\n\ny\n}\n\nv\n\n¤\n\n¤\n\n£\n\n¤\n§\n\n}\n\n}\n\ny\n¢\ny\n\ny\n\nv\n\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n{\n\nx\n\nx\n{\n¤\n\ny\n}\n\n}\n\n¥\n\n}\n¤\n¤\n¢\n\nx\n£\n\nv\n\n{\n¥\n\n{\n\ny\n\nv\n\ny\n¢\ny\n\nx\n§\n\n§\n\nv\n\n}\ny\n\ny\n\nv\n\n¥\n\n}\n\nx\n\ny\n}\n\nv\n\n¤\n\n£\n\n¤\n\ny\nx\n\nq\n}\ny\nH\nw\n<\n±\n\nv\n}\n\n¤\n\n£\n\n¤\nx\n\n£\n\n¤\n£\n\ny\n\nv\n}\ny\nv\nx\n\nx\n\n{\n\ny\n}\n\nx\n\nv\n\n{\n\ny\n\n}\n\nx\n\ny\n\n¥\n\n¥\n\n}\ny\n\n¤\n¤\n}\ny\n}\n\nv\n}\n\nx\n\nv\n\nx\n\n}\n\nx\n\ny\n¥\nx\n\n}\n\n¤\n\nv\n}\n\n}\n\nx\nn\n\nv\n\ny\n\n}\n\nv\n\n¥\n\nx\n\n{\n\n}\n\nx\n\n}\n\nv\n\n£\n}\n\nx\n\n¥\ny\n¤\n\n£\n\n¤\ny\nq\n}\ny\nH\nw\n<\n§\n\n}\n\nv\n¤\n\n£\n\n¤\nx\n\n}\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\n¢\n\ny\n\nx\n\ny\n\nv\n\ny\n¢\ny\n\nx\n\ny\n\n}\n\nx\nØ\n\ny\n\n}\n\nx\n\n¥\n\ny\n\n(r)\n¤\n}\n\n¥\n}\n\n§\n\n¤\ny\n}\n\nv\n\n¤\n\n¤\n\n£\n\n¤\ny\n}\n\n¤\n}\n\n}\ny\n{\n\nx\n\n{\nv\n¢\ny\nx\n\n}\n¤\nx\n\n{\n¤\n\n}\n\nx\n\nv\n}\n\n}\n\ny\n\n£\n\ny\n\n£\n\n}\n¤\n{\n¥\n\n{\n\ny\n\ny\n\nv\nx\n¤\n\nv\n\ny\n\n}\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n}\n\n¤\n}\n\n}\ny\n{\n\nx\n\n{\n¥\n\n{\n\ny\n\nv\n}\n\n}\n\n}\n¤\nx\nn\n\n¢\ny\n\n£\n\n}\n¤\n{\nv\n¢\ny\nx\n\n}\n¤\nx\n\n{\n¤\n\n}\n\nx\n\ny\n§\nv\n}\n\ny\nx\n\n}\n¤\ny\n\nx\n¤\n¤\n{\n\n{\n}\n\n}\n\n}\n\nv\n\n¥\n\nv\n\nv\n\n¤\n\n£\n\n¤\ny\n\nv\nx\n¤\n\nv\n}\n\ny\nx\n\nv\n\n{\nv\n¢\ny\n\nx\n\n}\n¤\n\ny\n\n¥\n\ny\nN\ny\n¥\n\nv\n}\ny\n\n}\n¥\n¤\n\ny\n\n}\nx\n¤\n¥\n\ny\nO\n\nx\n¤\n¤\n{\n\n{\n}\n\n}\n\n¥\n{\n\n}\n\n§\n\nv\n\ny\n\ny\n\n}\n\ny\n\n}\n\n¤\n¢\n\ny\n\nx\n\n}\ny\n\ny\n\n}\n¥\n¤\n\ny\n\nx\n\nv\n\nv\n\nx\n\nx\n\n¥\n\nx\n\n}\n¤\n{\n¥\n\n{\n\ny\n\n§\nt\nv\n¥\ny\n\n}\ny\n\ny\n\n{\n\n{\n\n¥\n\nx\n\n}\n\nx\n£\n\n(r)\n\n{\n\n§\n\n}\ny\n\n}\n¥\ny\n\ny\n\nx\n\n{\n\n{\n\n¥\n\nx\n\n{\n\n¥\n{\n\nv\n}\n\ny\nx\n\nv\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\n¤\n\nN\nx\n§\n\n§\n\nv\n\nx\n\n{\n¤\n\n}\n\nx\n\nO\n}\n\nv\n¥\ny\n\nv\n\n¢\n}\n\n{\n¤\n}\nx\n\n(r)\n\n¥\n{\n\nq\n\n<\n§\n\n}\n{\n{\nx\n\ny\n\n¤\n\n£\n\n¤\ny\n}\n\n}\n\n¢\n\n}\n\n¢\nU\n\n{\n\ny\n\nv\n\n¤\n\n¤\n\n£\n\n¤\ny\n\n}\n\ny\n\n£\n\ny\n\n£\n\n}\n¤\n{\n¥\n\n{\n\ny\n\ny\n\nv\nx\n¤\n\n{\n¥\n\n{\n\ny\n\ny\n}\n\n}\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\n}\n¢\n\n}\n¤\nx\nn\n\n¥\ny\nx\n\ny\n\n£\n\n}\n¤\n\n{\n\ny\n\nv\n\n¤\n\n¤\n\n£\n\n¤\n\n¤\n§\nt\nv\n\ny\n\n}\n¤\n\nx\n\n¤\nx\n\n¬\ny\n\n¤\n\n£\n\n¤\ny\n\n}\n\n¤\n¤\n\nx\n\nx\n\nv\n\nx\n\nx\n\nx\n\nx\n\nv\n\nv\n\n}\n\ny\n\n¢\n\nv\nx\n\nv\n}\n\n¥\n\nx\n\n}\n¤\n\n}\n\n}\n\n{\n¤\nx\ny\nv\n\nN\n}\n¤\nx\n\n¬\n\nv\n\n¤\n\n£\n\n¤\n\n¤\n\nO\n\nv\n\n}\n¤\ny\n\n¥\n\nx\n\ny\n}\n\n}\n\n}\nØ\n\nN\n}\n¤\nx\n\n¬\n\nv\n\n¤\n\n£\n\n¤\n}\n\n£\n\nO\n§\nE\n\nv\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\n¢\n\n}\n\n}\n£\n\ny\n\nx\n\nx\n\nv\n\n}\n\n{\n\nN\n\ny\n\n}\n\ny\nO\n\n}\n\n¥\n{\nN\n\n}\n\ny\n\ny\nO\n\nx\n\nx\n\n§\n±\ny\ny\n\n}\n\n}\n\n¤\nx\n\n¥\n\n{\n\ny\n\n}\n\nx\n\ny\n\n{\n\n¤\n\ny\nv\n}\n£\n\n}\n\nx\n\n{\n\n}\n\nØ\n\n¥\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nx\n¤\nx\n\n¢\n}\n\nv\n\ny\n\n}\n\nx\n\ny\n\n¥\ny\n\n}\n\nv\n\nx\ny\n\n}\ny\n\n¤\nx\n\n£\n\nv\n}\n\n{\n\ny\n\nx\n\nv\n\n{\n\n¤\n\ny\n{\n}\n\n}\ny\n}\n\n}\n\ny\n\ny\n\n}\n{\n{\nx\n\n{\n\n£\nx\n\ny\n¥\ny\n\n¥\n¤\n\n}\n\ny\n¥\n{\n{\n\nx\ny\nx\n\n}\n¬\nx\n\n}\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n§\n\ny\nx\n\n}\n\nx\n\n{\n¥\n\n{\n\ny\n\n}\ny\n\nN\n\n{\n\n}\n\n}\n¤\n¢\ny\nx\ny\nx\n\n}\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\n¢\nO\nv\n}\ny\n\ny\nv\n\n{\n¤\n}\n¢\n}\n\n}\n\n¤\n\nx\n\n¥\n\ny\n\n}\n\nx\n\nv\n\n{\n\n}\n\nx\n\n{\n¤\n\ny\n¢\ny\n\ny\nq\n}\ny\nH\n@\n<\n§\nq\n¥\n\nx\n\nD\ny\n}\n\n}\n¤\n¢\ny\nx\ny\n\nv\nx\ny\n}\n\n{\n\ny\n\n¥\n\ny\n\n}\n\nv\n\n¥\n\nx\n\n}\n\n}\n\n}\nD\ny\ny\nv\n¥\n\nN\n}\ny\n\nx\n\nx\n\nq\n}\ny\nm\n<\nO\n{\n\n£\nx\n\ny\n}\n\n}\n\n{\n¤\n\nv\n\n¤\n\nx\n\n{\n¥\n\n{\n\ny\n\nx\n\n¥\n\ny\n\n}\n\nx\n\n}\ny\n¢\ny\n\n§\nq\n¥\n\nx\n\ny\n\nx\n\ny\nv\nx\ny\n\n}\n¤\n\nØ\n\ny\nx\n\ny\n\nx\n£\nx\n\n}\n¤\n¤\n\nv\n\n¤\n\ny\n\nv\n\ny\nv\n¥\n\nx\n\ny\n\nv\n\nx\n\n¥\n\nx\n\nx\n\nv\n\nv\n\n¤\n\n}\n\nv\n\nv\n}\n\n{\n¤\n}\nx\n\nx\n\nv\n\nv\n\nx\n\nx\n£\nx\n\n¥\n}\n¤\n{\n}\n\ny\n\n¬\n\nU\nF\n\nv\n\n¢\n\n¬\n\n}\ny\nx\n\nx\n}\n\n¤\n¢\n\n¤\n\n}\n\nv\n\nv\n\nx\n\n¥\n\nx\n\n}\ny\n¬\n\n§\nq\n}\ny\n\n¥\ny\ny\n\n}\n\n¥\n\ny\n\nv\n}\n\nv\nx\ny\n}\n{\n{\n\n}\n\nv\nv\n}\ny\n\nv\n\n}\n\n£\n}\n\n}\n\nv\n}\n\ny\n\n¤\n¥\n\nx\n\ny\n\ny\n¥\n\n{\n\n¤\n\ny\n}\n\nx\n\nx\n\n}\n\n¤\n\nx\n\nv\n\ny\n{\n\nv\n\nx\n\n{\n¤\n}\n\nx\n\nv\n\nv\n\n¤\n\n{\nx\n\n¥\n\n}\n\nx\n\nx\ny\nx\n\nx\n}\n\n¤\n¢\n{\n\ny\ny\nx\n\n¤\n\n¥\n\nv\n\nv\n\n}\ny\n\n¤\n¥\n\nx\n\nx\ny\n\n§\n\n}\ny\n\n}\n\n¥\nx\n\nv\n\n{\n}\n\ny\n\nv\n\n}\n¢\n\nv\n\n¢\n\n¬\nx\ny\n\n¥\n\nv\n\nx\nz\n\n¥\n¤\n\n}\n¥\ny\n\nx\n\nI\n¥\nx\n\ny\ny\n¢\n\nv\n\ny\nx\ny\nU\nE\n\n¤\n¥\n\nx\n\ny\n\ny\n¥\n\n{\n\n¤\n\ny\n\n¥\ny\n\nx\n\nx\ny\n\n¤\n}\n\nx\n\n}\n\nv\n\nx\n\ny\ny\nx\ny\n\nx\n\nx\n}\n\n¤\n¢\n}\n{\n{\n}\n\n§\nE\n¥\n{\n{\n\nv\nx\ny\n}\n\n¥\n\n}\n\n¥\n\nx\n\nv\n\nx\nz\n\n¥\n¤\n\nx\n\ny\n±\n\ny\n\n}\n\nv\n\ny\nv\n}\n£\n\n¥\n\nv\n\n¤\nx\n\nv\n\n¥\n\nx\n\nv\n}\n\nx\n\n}\n¤\n\n£\nx\n\ny\n(r)\n\n¥\n{\n\nv\n\n¥\n\nx\n\nv\n\n{\n\ny\n§\n|\n\nE\n¤\n\n}\n\nt\n\n¥\n\nv\n}\n\nx\n\nx\n\nv\n\n¥\n\nx\n\n}\n\n¤\n\nx\n\n¥\nn\nn\n\ny\n\n¤\n\n¤\n¢\n\nv\n\ny\n\n¥\n\n¥\n\n}\n\nv\n}\n£\nx\n\nv\n\n{\n}\n\ny\n\nI\n¥\nx\n\ny\n\n{\n¤\n\n}\ny\n\nx\n\n|\nt\nH\n:\n<\n§\nq\n}\ny\n\n¥\ny\ny\n\ny\n¥\n\ny\n\ny\n\nv\n}\n\nv\n\ny\n¥\n¤\n\nx\n\nx\n\n{\n\ny\ny\nx\ny\n£\n\n¢\n}\n\nx\n\nx\n}\n¤\n\n{\n}\n\nv\n\n{\n\nx\n\n{\n\ny\ny\n\n¥\nx\n\n¢\n\n¥\n\nx\n\n}\n¤\n\ny\nx\n\n}\n\nx\n\ny\n}\ny\n\ny\n\nx\n\n¢\nq\n¥\n\n§\n(r)\n\nv\n\n|\n\nE\n¤\n\nt\n\n¤\n\nx\n\nx\n¤\n¤\n\nx\nz\n\n¥\n¤\n\ny\n\nv\n\ny\n\nv\n\ny\n\nv\nx\n¤\n\nq\n¥\n\nx\n\nD\ny\n\ny\n\nx\n{\n\nx\n\n}\n{\n{\n\n}\n\ny\n\n¥\nx\n\n¢\n}\n\nx\n\ny\n\n¢\n\n{\n\ny\n{\n\nx\n£\n\nq\n}\ny\nm\n<\n§\na\n¤\n}\ny\n\n}\n\nv\nx\ny\n¥\n\ny\n\nv\n}\n\n{\n\ny\n}\n\ny\n¥\n\ny\ny\n\n¥\n¤\n{\n\n¤\n\ny\n\n¤\n£\n\ny\n\n¥\ny\n\ny\n\n}\n\n}\n¤\n¢\nn\nx\n\nv\n\n¥\n\nx\n\n}\n¤\ny\n\n¥\n\n¥\n\nv\n\n{\n\n¤\n\n}\n\n}\nv\nx\n\nv\n¤\n\n£\n\n¤\n\n}\n\nx\n\ny\n\n}\n\nx\n\n}\n\nv\n\n}\n\nv\n\nx\n\ny\n\n}\n\nv\n\n}\ny\n\n¤\n¥\n\nx\n\n¢\n\n¥\ny\nx\n\n}\nx\n¤\ny\na\nH\nH\n<\n§\nq\n\n{\n\ny\n\n}\n\nx\n\ny\n\nv\n}\n\ny\n\n}\nx\n\ny\n\n}\n\nv\nx\n\n}\n\n}\n¢\n\nv\n}\n\nx\ny\n\n{\n¤\nx\n\nx\n\n¤\n¢\n\n¤\n}\n\nv\n\n{\n¥\n\n{\n\ny\n\nx\n\nv\nx\n\nv\n\nv\n\ny\n¢\ny\n\nx\ny\n\ny\nx\n\nv\n}\n£\n\ny\nv\n\nØ\n\nx\n£\n\nv\n}\n\nv\n\ny\n\nv\n}\n\n}\n¥\ny\n\nv\n\n¢\n\n}\n\nx\n¤\nx\n\n}\n\nv\n\n¢\n{\n\n}\n¤\n\nx\n\nv\n}\n£\nx\n\nv\nx\n\nx\n\n¢\n\n{\n\ny\n\nr\n@\n<\n§\nt\nv\n\ny\nv\n\n¥\n¤\n\n}\n\n¤\n\nx\n\n{\n\n£\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nI\n¥\nx\n\nx\n\ny\n\n}\n\n£\n\n¤\n\n{\n\n}\n\n£\n\n¤\n¥\n\nx\n\n}\ny\n¬\ny\n\n¢\n{\n\n£\nx\n\nx\n\n}\n\n{\n\ny\n\n}\n\nx\n\nN\nx\n§\n\n§\n\ny\n{\n\nx\n\n}\n\nx\n\nO\n\nv\n\ny\n¢\ny\n\nv\n}\n\n}\n\nx\n¤\nx\n\n}\n\ny\n\n}\n¤\n\nx\n\ny\n\n}\n\nv\n\n¢\n\n}\n¬\nx\n\n{\n¤\nx\n\nx\n\nv\n\n}\n¤\ny\n\n¤\n}\n\n}\n\nv\n\n{\n\n§\n\nx\n\nx\n\n}\ny\n¢\ny\n\n}\nv\nx\n\nv\n¤\n\n£\n\n¤\n\n}\n\ny\n\n}\n\nx\n\nx\ny\n\n¤\nx\n\nx\n\n}\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\n¢\n\n¥\n\ny\n\n§\n\ny\n\nv\nx\n\n}\n\nv\nx\n\ny\n}\n¤\n¤\n\ny\n\n£\n\ny\n¢\ny\n\ny\n}\n\n}\n¤\n\ny\ny\n\n}\nx\n¤\n\n¤\n\n£\n\n¤\n§\nt\nv\n\nx\nØ\n\nx\ny\n\nv\n}\n\nv\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\n¢\nx\ny\n\n{\n¤\nx\n\nx\n\n¤\n¢\nE\n¿\n3⁄4\n·\n¿\n\nμ\n·\n\na\n}\n\nv\n¥\ny\n}\ny\ny\nx\ny\n\ny\n\n}\n¤\n\nx\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n§\nU\nx\n\nv\n\nv\n\nv\nx\n\n}\n\nv\nx\n\ny\nN\ny\n¥\n\nv\n}\ny\n\nv\n\n{\n}\n\nv\n\n¤\n\nv\nx\n\n}\n\nv\nx\n\ny\n\n¥\ny\n\nx\n\n{\n¥\n\ny\n\nx\n\nO\n\nv\n\n¤\nx\n\n¬\ny\n\n¤\n\n£\n\n¤\ny\n}\n\ny\ny\n}\n\nx\n¤\n¢\n\n¤\n}\n\n}\n¤\ny\n§\nE\n\n}\n¤\n\nv\n\n¥\n\nv\nx\n\nx\ny\n{\n\ny\ny\nx\n\n¤\n\n¥\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n\n}\n\ny\n\n}\n\nx\n\ny\n\n¤\n\n}\ny\n¥\n\ny\n¢\ny\n\nx\n\ny\n\n}\n\ny\n\n}\nx\n\ny\n\n}\n\nv\n\nv\n\ny\n¥\n\nv\n\nv\nx\n\n}\n\nv\n¢\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\n¥\n\ny\n¢\ny\n\ny\n\ny\ny\n}\n\nx\n¤\n¢\n\n}\nx\n\ny\n¢\ny\n\n{\n\ny\n\n¤\n\n£\n}\n\nv\n\n}\n¤\ny\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\n\nx\ny\n\ny\nx\n\nx\n\n§\n\na\na\n\na\na\na\n\n¤\næ\n¤\nc\n\n£\ne\nt\nv\n\n}\n¤\n}\ny\n{\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\nx\ny\n\nv\n\n}\n\n¥\n}\n¤\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n§\n±\n¤\n\nv\n\n¥\n\nv\n\nv\nx\ny\nx\ny\n\nv\n\ny\n\n}\n\nv\n\ny\nx\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n\nv\n\n¥\n\n}\ny\n{\n\ny\n}\n\n¥\n\n}\n¤\n¤\n¢\nv\n}\n£\n\n}\n\nx\n\nx\n\ny\n\nx\n\nv\n\n{\n\ny\ny\n\ny\n¥\n{\n{\n\nv\n\nx\n\nx\n\nv\n}\n\nv\n\ny\nv\n\n¥\n¤\n\nv\n\nv\n\nv\n\nx\n¤\n¤\n\ny\n\n¥\n\n¥\n\n}\n¬\n\nv\n\nx\n\n}\n\nx\n\n}\ny\nx\n¤\n¢\n¤\n\n}\n\n}\n\n¥\ny\n\n}\n\n}\n¤\n¤\n¢\n\nv\n\nv\n\n¤\n}\n\n¥\n}\n\ny\nv\n\n¥\n¤\n\n}\n¬\n\n§\n±\n¤\n¤\n\n¥\n\n}\ny\n\n{\n\ny\n\n}\n\ny\ny\n\n¤\n¢\nx\n\ny\n\nv\n\n}\n\n}\n¤\n\n¢\ny\nx\ny\n\n{\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n¥\n\n}\n¤\ny\n\nx\n\nv\n\ny\n{\n\nv\n¥\n\n}\n\n{\n\n{\n\n¥\n}\n¤\n}\n\nx\n\nx\n£\n\n}\n{\n}\n\nx\n¤\nx\n\nx\n\ny\n§\n\nv\n}\n\nv\n\nx\n\ny\n\n¤\n\n¥\ny\n\n}\n¤\ny\n\ny\nx\n\n}\n{\ny\n¢\n\nv\n\n¤\n\nx\n\n}\n¤\ny\n\n}\n\n{\n\nx\n\nU\nt\nv\n\n¥\ny\n}\n\nx\n¤\nx\n\n¢\n\nv\n\n¤\n}\n\n¥\n}\n\nx\n¤\n¤\n\n{\n\nv\n¥\n\n}\n\n{\n\n{\n\n¥\n}\n¤\n}\n\nx\n\nx\n£\n\ny\n\n}\n\nx\n\ny\n§\nB\n\n}\n\n{\n¤\n\nB\nx\n\n}\n\na\n\ny\n\nx\n\nv\n\n}\n\nx\n\n¥\n\ny\n\n}\n\n}\n\nx\n\nx\n\nv\n\ny\n{\n\nv\n¥\n\n}\n\n{\n\n{\n\nx\n\n}\n\n¥\n\ny\n\n}\n\nx\n\nB\na\nx\n<\n§\n}\ny\n\n}\ny\nÞ\n<\n}\n\nv\n\ny\nv\n}\n£\n\n}\n\n¥\n\nv\n}\n\nv\n\n¥\n\nx\n¤\nx\n\n¢\n\n}\n\n¢\nx\n\n}\n\nx\n\n{\n\ny\n\n}\n\nx\n\nx\ny\n}\n\n¥\n\nx\n\nv\n\n·\n3⁄4\no\ne\n\nv\n}\n\nv\n\n{\n\ny\n\n}\n\nx\n\nx\ny\n\nx\n\n¥\ny\n\ny\n¥\n{\n{\n\n§\nB\n\n}\n\n{\n¤\n\n}\ny\n¢\n\n¤\nx\n\n{\n\ny\n\n}\n\nx\n\nx\n\nv\n\nv\n}\n\n}\n\n}\n{\nv\nx\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\ny\n¬\n\n¥\n\ny\n\nv\n\ny\n§\n\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\nx\ny\n\nx\n\n{\n\n{\n\ny\n\nv\n\n§\nU\n\ny\n\n¥\ny\n\n¤\n}\n\nx\n\n¢\n\nv\n}\n\ny\n\n{\n\ny\ny\n\n}\n\ny\nx\n\n¤\n}\n\n¥\n}\n\ny\n\nv\n}\n\n{\n\ny\ny\n\nv\n}\n\nx\n\n}\n\nx\n\n}\n{\n{\n\n{\n\nx\n}\n\n¤\n¢\n}\n\nØ\n\nx\n£\n\n¤\n¢\n§\n\n}\n\nx\n\nx\n\nx\nØ\n\n¢\n{\n\ny\n\ny\n¢\ny\n\ny\n\nI\n¥\nx\n\nx\nØ\n\n¢\n{\n\ny\n\n¤\n}\n\n¥\n}\n\ny\n§\n±\n¤\n¤\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\n}\n\ny\n\n}\n\nx\n\ny\n\nv\n\n¢\n¤\n\n}\n£\n\n¥\n\n¥\n\nx\n\n{\n\n}\n\n}\nx\n¤\ny\n§\nU\nv\n}\n\nx\ny\nx\n\n{\n\n}\n\nx\n¤\n¤\n\n{\n\nv\n\n{\n\n¤\n\nx\n\ny\n\n¤\n£\n\n§\nB\n\nx\nØ\n\n¢\n{\n\ny\n\ny\n¢\ny\n\ny\n\nv\n\nx\n\n{\n\n}\n\n}\n\nx\nz\n\n¥\n¤\n\n}\ny\n{\n\ny\n\nx\nØ\n\n§\nB\n\n}\n\n{\n¤\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n¤\n¤\n\ny\n\n}\n¢\n\n{\nv\n}\ny\nx\nn\n\n¤\n\n£\n\n}\n\n}\n\nN\n\nv\nx\n\nv\nx\ny\n\n¤\n}\n\nx\n£\n\n¤\n¢\n\nx\n£\nx\n}\n¤\n\nv\n\ny\n\ny\n¢\ny\n\ny\nO\n\nv\nx\n¤\n\n}\n\n}\n\n}\n\ny\n\n}\n\nx\n\nx\n\n}\n\nx\n\n}\n\n}\n\ny\n¢\ny\n\ny\n\nx\n\nv\n\n{\n¤\n}\n\n{\nv\n}\n\ny\nx\ny\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n}\n\n}\n\nv\n}\n\n¤\n\n§\n±\n\n{\n\ny\n\nx\n\n¤\n¥\n\n£\n\n¢\n\nv\nx\n\nx\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n}\n\n¤\n¢\nx\n\n{\n\n}\n\nx\n\n}\n¤\n\n¥\n\nx\n\n£\n\n¤\n£\n\n}\ny\n\nØ\n\n}\n\n}\n\n¥\n\n¤\nx\n¬\n\n¤\n¢\n\nv\n\n¥\n\ny\n}\n\ny\n\nv\n\n¥\n¤\n\ny\n\nx\n\n¥\ny\n\n¢\n{\n\ny\n§\nt\n\n}\n¥\ny\n\nv\n\nx\n\n{\n\n}\n\n{\n¤\n\ny\ny\n\n}\ny\n}\n\n¥\n\n}\n\n¤\nx\n\nx\n\nx\n\n}\n\n¤\n¢\n\nv\n}\n\ny\n\nx\n\n¤\n¥\n\ny\n\nv\n\ny\n\nx\n\n{\n\n}\n\n{\n\n¤\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\n§\nt\nv\nx\ny\n{\n}\n{\n\n}\n¤\ny\n\nx\n\nv\n{\n\ny\ny\n\n}\n\ny\n\n¥\n\n¥\n\n¥\n\nN\n\n}\n\nx\n\nO\n§\nU\n\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n\n¥\nx\n¤\n\n¥\n{\n\nv\n\n¥\n\n}\n\nx\n\n¤\n}\nx\n\nx\n\nv\nx\ny\n{\n}\n{\n\n}\n\nv\n\n{\ny\n¢\n\nv\n\n¤\n\nx\n\n}\n¤\n{\n\nx\n\nx\n{\n¤\n\ny\n\n¥\n\nv\n\n¢\n\nx\n¤\n¤\n\ny\n\nx\n\nx\n\n¥\n\n¥\n\n{\n}\n{\n\ny\n§\ne\ni\n&\n$\nA\n&\n$\n\nA\n\n\"\n$\n\nC\n&\n(\nt\nv\n\ny\n\n}\ny\nx\n\nx\n\n}\ny\n{\n\n£\nx\n\nv\n\n¥\n\n}\n\nx\n\nv\n}\n\n}\n¤\n¤\n\nμ\n·\n\nμ\n·\no\n»\n\n1⁄4\n\n1⁄2\n1⁄4\n3⁄4\n·\n\n¿\nμ\no\n§\nt\nv\n\n¢\nv\n}\n£\n\n£\n\n¤\n\n{\n\n}\n\n¥\ny\n\ny\n¥\n\ny\ny\n\n¥\n¤\n¤\n¢\nx\n\nx\n\nx\n£\n\nx\n\nx\n\n¢\n\nx\n\n}\n\nq\n}\ny\n\n¥\ny\ny\n\nv\n\ny\nx\n\n{\n\n}\n\nx\n\n}\n\ny\n\n}\n{\n\ny\ny\n\nv\n\n¢\n\n}\n¤\n¤\n\n1⁄4\n¿\n·\n¿\nE\n\n1⁄4\n3⁄4\n·\n\nμ\n·\n\n3⁄4\n1⁄4\n\na\n\no\n\nE\nμ\n|\n\nw\n\nx\n\nÞ\n<\n§\nt\nv\n\n}\n\n¥\n\n}\n\nv\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\n¢\n¤\n\n£\n\n¤\ny\n\n}\n¢\n\nx\nØ\n\n}\nx\n\n}\nx\n\n§\nF\n\n{\n\ny\n\n}\ny\n\n¥\n\n¥\n\n{\n\ny\ny\ny\n¢\ny\n\ny\n\nx\n\nv\ny\nv\n}\n\ny\n\n}\n\n}\n\nv\n¥\n\n}\n\n¤\n§\n\nx\n\nv\n\n}\ny\nx\n\nx\n¤\nx\n\n¢\n\nv\nx\ny\n}\n{\n{\n\n}\n\nv\n\ny\n{\n\nx\n\n¢\nx\n\n}\n\n{\n¤\n\ny\n¢\ny\n\nv\n\n}\n¤\nt\n±\nE\n\n}\nx\n\n}\n\n¤\n¤\nx\ny\nx\n\n}\n£\n\nx\n\n}\n\ny\n¢\ny\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\n{\n\n£\nx\n\n¥\ny\n¤\n¢\n\nu\nF\nF\nq\ny\n<\n\nx\n\n¤\n¥\n\nx\n\nx\n\n}\n\nx\n\n}\n\nv\n\nx\n\n}\n\nx\n\nv\n}\n\n}\n\n{\n\ny\ny\n\n}\n¤\n¤\n¢\n\n¥\n\nx\ny\n\nx\n\n}\n\n{\n¤\n\ny\n¢\ny\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\n§\nU\n\n}\n\n¥\n\n¤\n¢\n}\n{\n{\n¤\n¢\nx\n\nv\n\n}\n{\n{\n\n}\n\nv\n\nv\n\n}\n\n{\n¤\n\ny\n\nx\n\n¤\n¥\n\nx\n\n}\n±\nE\n±\n\n}\n\n{\n}\n\nv\n\n×\n§\nE\n§\n±\nx\n\nt\n\n}\nz\n\n¤\nE\n¢\ny\n\n§\nt\nv\n\nt\n±\nE\n\ny\n{\n\nx\n\n}\n\nx\n\nx\ny\n¥\ny\n\n}\ny\n}\n\n}\n\n{\n¤\n\nx\n\nv\nx\ny\n{\n}\n{\n\n§\ni\nt\nv\n\n}\n\n¤\n\ny\n\nv\n\n}\n\n{\n¤\n\nt\n±\nE\n\nE\n¢\ny\n\nq\n\nI\n¥\nx\n\ny\nE\n{\n\nx\n\n}\n\nx\n\nN\ny\nv\n\nx\n\nB\nx\n\n¥\n\n:\nO\n\n}\n¢\n\nv\n\n¤\n{\n\n¥\n¤\nx\n\n¤\n\nð\nn\ni\nc\na\nþ\no\no\no\no\no\n÷\ne\nð\n÷\ne\no\ne\nð\n]\na\no\n]\ne\ne\na\næ\n÷\no\n]\næ\n\\\ne\ni\nð\ne\nð\na\ni\na\ne\nð\n\\\na\ne\nð\n]\na\no\nø\n]\ne\ne\na\næ\n÷\no\na\na\næ\ne\nð\nc\n\no\no\ne\ne\na\nð\na\ni\næ\n÷\na\n\nn\no\ne\na\næ\ni\na\ni\ni\nc\ne\na\nð\nð\n÷\ne\na\nc\nð\na\ne\nð\n]\na\no\n]\ne\nø\ne\na\næ\n÷\n]\ne\n÷\n÷\næ\ne\no\nð\na\n÷\n]\ni\ni\nn\nð\nn\na\n÷\ne\na\na\na\ne\ne\ne\nð\nc\n\no\ne\n]\ne\n÷\no\nð\ne\n]\n]\nð\na\na\nð\nn\n_\nc\næ\n\\\na\ne\ne\ne\n÷\nø\nø\na\na\na\n\n]\na\n\na\ne\na\na\na\n÷\na\ne\næ\n÷\n\nð\nn\ni\nø\na\næ\n\\\nð\na\nø\ni\nð\ne\nð\na\næ\n÷\n\nH\n\n¤\n\nx\n\nv\n\ny\n\nx\n{\n\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\n\nv\n}\n\nv\n\n¤\n¢\n{\n}\n\nt\n±\nE\n\nv\n}\n\ny\n{\n\nx\n\n{\n\n£\nx\n\n¥\ny\n¤\n¢\nx\ny\ny\n\nx\n\n:\n§\ny\n}\n\n{\n}\n\ny\n\n:\n§\n:\n§\n\nv\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n}\n£\n\n¥\nx\n¤\n\n}\n¤\ny\n¢\ny\n\ny\n\nv\n}\n£\n\n¥\n\nv\n\n}\n{\n{\n\n}\n\nv\n\n{\n\n}\n\nx\n\n}\n¤\n\nx\n\n}\n\ny\n\nv\n\nx\n\n}\n\nx\n\nx\n\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nx\ny\n}\n¤\n\n}\n\n¢\n¤\n\n}\n\ny\n\nv\n\nx\n\nv\n\n£\n\n¤\n¥\n\nx\n\n¥\ny\n\n¥\n\n}\n\nx\n\n¤\n}\n\ny\n¢\ny\n\ny\n§\nt\nv\n\n{\n\n¤\n\nx\n\nv\n\ny\n\ny\n¢\ny\n\ny\n¥\ny\n¥\n}\n¤\n¤\n¢\n¤\nx\n\ny\nx\n\nx\n\ny\n{\n\nx\n\nx\n\n}\n\nx\n\nv\n\nx\n\nx\ny\n\nx\n\n}\n\nx\n\nv\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\n\nx\n\n}\n\nx\n\n}\n\nx\n\n¥\n\ny\n\n}\n\nx\n\nv\n\ny\n¢\ny\n\ny\nx\n\n}\n\nv\n¢\nx\n\n}\ny\n\ny\nx\n\nv\n}\n\n}\n¢\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\n}\n\n}\ny\ny\nx\ny\n\nx\n\nv\n\nv\n\ny\n\n}\ny\n¬\ny\n§\nE\n¢\ny\n\n}\n\ny\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n\n¢\n{\n\nx\n\n{\n\n{\n\ny\n\n¤\nx\n¬\n\nv\n\ny\n\n¥\ny\n\nx\n\n¤\n\nx\n\n}\n¤\nx\n\n}\n\ny\nx\n\n}\n\n}\n\nx\nn\n\n}\n¤\n\nx\n\ny\nx\n\ny\nU\nx\n\n}\n\ny\n\n}\n\nx\n\n}\n\n{\n}\n\nv\n\n¤\n\n}\n\ny\n\n}\n\nx\n\nN\ny\n\nB\nx\n\n¥\n\nO\n§\nt\nv\n\ny\n\nx\n\ny\nx\n\ny\n\ny\n\nx\n\n¥\n\nv\n\n{\n\n¤\n\ny\n{\n}\n\nx\n\nv\nx\n\nv\n\nv\n\nv\n¥\n\n}\n\n}\n£\nx\n\n}\n\ny\n§\nt\nv\n\n{\n}\n\nv\n\n¤\n\nN\nv\n\nx\nn\n\n}\n¤\nO\n\nx\n\ny\nx\n\nv\nx\n\nv\nx\n\ny\n\n¤\n\n}\n\ny\n\n{\n}\n\n}\n\nx\n\n}\n\n{\n\ny\nx\n\nx\n\n}\n¤\n¤\n\ny\n¥\ny\n\ny\n\nv\n}\n\nv\n\nx\n\n¥\ny\n\n}\n\nx\n\n¤\n\ny\ny\n\n}\nx\n¤\n\n£\nx\n\ny\n\nx\n\nv\nx\n\n}\n\nv\n¤\n\n£\n\n¤\n\n¤\n§\nt\nv\n\n£\n\nx\n\n}\n¤\n\nx\n\ny\nx\n\ny\n{\n\nx\n\ny\n\nv\n\n¤\n\n£\n\n¤\n\nx\n\n}\n\nv\nx\n\nv\n\nv\n\n{\n\n¤\n\nx\ny\n\nx\n\ny\nx\n\nx\n§\n\n§\n\nv\n\n¤\n}\n\n¥\n}\n\n¤\n\nv\n}\n\nx\ny\n\n¥\n\n¤\n¢\n\nx\n\n¥\ny\n\n§\na\n\næ\n\n¤\nu\nu\nu\n\nu\n\ny\nc\na\n\n£\n\nc\n\n£\n\n{\n¥\n\ny\n\nx\n\n¤\n¢\n¥\ny\n\ny\n\n¢\n{\n\ny\n\n{\n}\n\nv\n\n¤\n\n}\n\ny\n\n}\n\nx\n\ny\n§\n\n3⁄4\n\n3⁄4\n·\n·\n\n·\na\n\n1⁄4\n¿\n\n»\n¿\no\n\n·\n\n¿\nμ\nN\n\nx\n\ny\n\n{\n\n{\n\ny\nx\n\n}\n\n}\n\nx\n\nO\ny\n\n{\n}\n\n}\n\ny\n¥\n\nx\n\ny\nx\n\nN\n{\n\nv\n}\n{\ny\nx\n\n}\n\nx\n\nO\n\n{\n\ny\n\nv\n\ny\n}\n\n¢\n{\n\n§\n\nE\n\n}\n\nv\n}\n\ny\n\n}\n\n{\n¤\n\nv\n\ny\n\n{\n\ny\n}\n\n}\n¤\n¤\n\nv\n\n}\n¤\n\n{\n\ny\n}\n\nv\n\n{\n\ny\ny\n\n}\n\n}\n\nx\n\ny\n¥\n¤\n\ny\nx\n\n}\n\nv\n\n}\n¤\n{\n\n¥\n\n§\n\n}\n\nv\n\nv\n\n{\nx\n\ny\n\nv\n\n{\n}\n\n}\n¤\n¤\n\n¤\n\n{\n\ny\nx\n\nx\n\nE\n\n}\n\nv\n}\n\ny\nx\ny\n}\ny\n\n}\n\n}\n\nv\nx\n\n}\n¤\n\nv\n\n¥\n\nv\n\n}\n\nv\ny\n\n}\n\n}\n\nv\nx\n\nx\n¤\n¤\nx\n\n}\n¤\n\nx\nØ\n\n§\nt\nv\n\ny\n\n¢\n{\n\n{\n}\n\nv\n\n¤\n\n}\n\ny\n\n}\n\nx\n\n1⁄2\nμ\n\nμ\n·\n\n}\n¬\n\ny\n}\n\n¥\n\nx\n\n}\n\n}\n¬\ny\nx\n\nx\n\n}\nx\n¤\n\ny\n\n{\ny\n§\n±\n\n}\n\n{\n¤\n\nx\ny\n\nv\n\nx\n\nx\n\n}\ny\n\ny\n\n}\n\ny\nx\n\n}\ny\n¥\n{\n\ny\n\n}\n\nx\n\nE\n\n}\n\nv\n}\n\ny\n§\n\nr\n\nx\n\ny\n\ny\n¥\n\nv\n}\n\ny\n\n}\n\nx\n\ny\nv\n}\n£\n\n}\n{\n{\n¤\nx\n\nv\n\ny\n\n}\n\ny\n}\n\n}\n\ny\nx\n\nx\n\ny\n\nv\n\n¢\n{\n\n£\nx\n\n}\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\n}\n\n}\n{\nx\n\nv\n\n§\n\n{\n\n}\n\nx\n\n}\n\ny\n\n}\n\nx\n\ny\n}\n\n{\n\ny\n\n¢\n{\n\n¥\n\ny\n\ny\n¥\n\n{\n\n}\n\ny\n§\n\nv\n}\n\nx\n\nv\n\nv\n\ny\n\n¢\n{\n\ny\n\n}\n\ny\n\n}\n\nx\n\nx\ny\n}\n\n(r)\n\n{\n\n{\n\n¢\n\n}\n\ny\n\ny\n}\n\ny\n\n}\n\nx\n\nv\n\nv\n\n¤\n\nx\ny\ny\nx\n\n{\n¤\n¢\n\n¬\n\n¥\n{\nx\n\n}\n\n}\nx\n¤\n\ny\n\nx\n{\n\nx\n\n§\n±\n\nx\n\nx\n\n}\n¤\nx\n\n}\n\nx\n\ny\n¥\n\nv\n}\ny\nx\n\nx\ny\n\n{\n\n£\nx\n\n}\n\nv\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n§\n±\n¤\n\nv\nx\ny\nv\n\nx\nn\n\n}\n¤\n\nx\n\ny\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\n¬\n\n¥\n{\nx\n\nv\n\n{\n}\n\ny\n§\nt\nv\n\ny\n\n¤\n¥\n\n}\nx\n\ny\nx\n\n}\n\nx\n\n}\n\n¥\n\nv\n}\n\n}\n\nx\ny\n\nx\n\ny\n\nv\n\n£\nx\n\nv\n}\n\n}\nØ\n\ny\n\nv\n\n}\n\nx\n¤\nx\n\n¢\n\n}\n\nv\nx\n\n£\n\nv\n\ny\n¢\ny\n\n}\n¤\ny\n}\n\ny\nx\n\ny\n\n}\nx\n\ny\n§\nB\n\n}\n\n{\n¤\n\nx\n\nt\n±\nE\n\nv\n\ny\nx\n\ny\n\nx\n\n}\n\nx\n\n}\n\n¥\n\nv\n\n{\n\n}\n\nx\n\nv\n\n¥\n\n}\ny\n\n±\nt\ny\n¢\ny\n\nx\n\n¥\n¤\n\n¤\n¤\n\nv\n\ny\n¢\ny\n\n¤\n\n£\n\n¤\n\ny\n\n}\nx\n\nx\n\nx\n\nx\n\nv\nx\n\n§\n\n}\n\nx\n\n}\n\n¥\n\nv\n\n£\nx\n\nx\ny\n}\n¤\ny\n\ny\n\n¢\n{\n\ny\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\n}\n\n}\n¤\ny\n¢\ny\n\ny\nx\n\n§\nB\n\n}\n\n{\n¤\n\nv\n\ny\nx\n\nv\n\ny\n¥\n\n£\n\nx\n¤\n¤\n}\n\n¤\n\nx\n\nx\n\nt\n±\nE\n\n{\n\ny\n\nv\n\nv\n}\n\n}\n\nx\ny\n\nx\n\ny\n\nv\n\n}\n\ny\n{\n\ny\n\n}\n\nx\n\nv\n\n}\nx\n\n}\n\nx\n\nv\n\nv\nx\n\nv\n\nv\n\ny\n¥\n\n£\n\nx\n¤\n¤\n}\n\n¤\n\nx\n\nx\n\n}\n\ny\n§\nt\nv\n\ny\n\n¤\n¥\n\nv\n\nv\n\nx\nn\n\n}\n¤\n\nx\n\ny\nx\n\nx\ny\nx\n\n}\n\nx\n\n}\n\n¥\n\nv\n¥\n\n}\n\n{\n\n}\n\ny\n\n¥\ny\n\ny\n§\nt\n\nv\n¥\n\n}\n\n}\n\ny\n\ny\nx\n\n}\n\ny\n\n}\n\ny\nx\n\nx\ny\n\nx\n\n{\n\n¤\n¢\n§\n\n}\n\n¢\n}\n\nx\n\ny\n}\n\nx\n\nx\n\ny\nx\n\n}\nx\n\n}\n\nx\n\nv\n}\n\n£\n}\n\n}\n¥\n\n}\n\nx\n\nv\n}\n£\n\n¤\n}\n\nv\n¥\n\n}\n\nv\n}\n\nv\n}\ny\n\nx\n\n¥\n\n¢\n\nv\n\ny\nx\n\nv\n\n}\n¥\n\n}\n\nx\n\n§\nB\n\n}\n\n{\n¤\n\nU\n\nx\n\nx\n\n¥\n\nv\n\n1⁄4\n·\n\no\n±\n3⁄4\n\n·\n¿\n\n3⁄4\n·\n\n¿\nμ\n\ny\n\nx\n\n}\n¥\n\n}\n\nx\n\nv\n}\n\n{\n¤\n}\n\ny\n}\n\nx\n\nx\n\n}\n¤\n}\n\n¥\n\n£\n\n¤\n¢\n\nx\ny\n\nx\n\n¥\n\n¬\n¤\n\n}\n\n¥\n\nx\n\n}\n\nx\n\n}\n\nx\n\n}\n\nx\n\n}\n\ny\n\n{\nx\n¤\n\ny\n\nx\n\nv\n\n¥\n\n}\n\nI\n¥\n}\n\ny\n¥\n{\n{\n\nU\n\nx\nH\n<\nO\n§\nE\n}\n\nU\n\ny\n\n}\n\nt\nx\n¤\n¤\nx\n\ny\nE\nU\nt\n@\n<\n\ny\n\nx\n\n}\n\nx\n\nx\n\n}\n¤\n{\n\n¤\n\ny\n}\ny\ny\n\nx\n}\n\nx\n\nv\n\n}\n\nx\n\n}\n¤\n}\n\n¬\n\n¤\n\n}\n\ny\n}\n\n}\n¬\n\ny\nx\n\n}\n\n}\n\ny\ny\n}\n\n(r)\n}\n¥\n\n}\n\nx\n\ny\n¥\n\n{\n\nx\ny\n\ny\n\nv\nx\n\nv\n\nv\n\n¢\n}\n\nx\n\n¥\n\n·\n\n1⁄4\nμ\nμ\n¿\n·\n¿\nE\n±\n¶\n1⁄4\n\nμ\n·\n\na\n3⁄4\n\n·\n¿\n\n3⁄4\n·\n\n¿\nμ\nU\nt\n\nv\n\ny\nx\n\ny\n\nv\n\n}\n¥\n\n}\n\nx\n\n¥\ny\n\n¤\n¥\n\ny\nx\n£\n\n¤\n¢\n\nv\n\nx\n\n}\n¤\n}\ny\n{\n\ny\n\ny\n¥\n\nv\n}\ny\n\nv\n\n}\n{\n{\nx\n\ny\n\n}\n\nx\n\n{\n¥\n\ny\n\n¥\n\n{\n¥\n\ny\n\n}\n\nv\n\n}\n\nx\n\n}\n¤\n\n¤\ny\n\nI\n¥\nx\n\ny\n\n¥\n\nx\n\n}\n¤\nx\n\n¢\n\n}\n\nv\n\nv\n\nx\n\n}\n¤\n\n}\nx\n¤\ny\n}\n\n{\n\n¤\n\ny\nx\n\n}\n¤\n\nv\n\n{\n¥\n\nv\n\n¢\n\n£\n\n¥\n\nv\n}\n\nx\n\nv\n\nx\n\nx\n£\n\n}\n\nv\n\n}\n\ny\n\nv\n\n}\n¥\n\n}\n\nx\n\ny\nx\n\nv\n\n{\n\n}\n\n§\nU\n\n}\n¤\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\ny\n\nx\n\n}\n\nv\n\nx\n\n}\n\nx\n\ny\nx\n\n(r)\nv\n¥\n\n}\n\n}\n¥\n\n}\n\nx\n\nx\n\nv\n\ny\n¢\ny\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\n§\nU\n\n}\n\n}\n¤\ny\n\n¬\nx\n\n}\n\n}\n¤\n¢\ny\nx\ny\n\nv\n\nx\nI\n¥\n\ny\n\nx\n\nx\n\n¢\n{\n\n¤\n\n}\n\nx\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\nx\n\n}\n\n¥\n\ny\nx\n\n{\n\nx\n\nv\n\nv\n¥\n\n}\n\ny\n}\n\n¤\nx\n¬\n\n¤\n¢\n\n¥\n\nu\nr\nE\nx\n<\n§\nt\nv\nx\ny\nx\n\n}\n\nx\n\n}\n\n¥\ny\n\nx\n\nv\n\nv\n\n}\n¥\n\n}\n\nx\n\ny\nx\n\n}\n\nx\n\nv\n\ny\nx\n\nv\n\n{\n\n}\n\n{\n\n¥\n\ny\n\n}\ny\n¬\ny\n\nx\n\n}\n\n}\n\n}\nx\n\nx\n\n§\nt\nv\n\nv\nx\n\n{\n}\n\nv\n\nv\n\nx\nn\n\n}\n¤\n\nx\n\ny\nx\n\nx\ny\n\nv\n\ny\n¢\ny\n\nx\n\ny\n\n¤\n\n}\n\nx\n\ny\n\n{\n\ny\nx\n\nx\n\n}\n¤\n\nv\n\n{\n}\n\nv\n\n¤\n\nx\n\ny\nx\n\n§\na\n\n£\n¤\n\n£\n¤\ny\nc\na\n\n£\n\nc\n\n£\nt\nv\n\nN\n£\n\nx\n\n}\n¤\nO\n\nx\n\ny\nx\n\nv\n}\ny\n\n£\n\nv\nx\n\n}\n\nv\nx\n\n}\n¤\n¤\n\n£\n\n¤\ny\n\n}\n\nv\n{\n\n£\nx\n\nx\n\nx\n\nN\n(r)\n\nv\n¢\n\nO\nx\n\n}\n\nx\n\n}\n\n¥\n\nv\n\n¤\n\n£\n\n¤\n\n¤\n\n§\n\n}\n\nv\n¤\n\n£\n\n¤\nx\ny\n\n}\n{\n{\n\nv\n\n}\n{\n{\n\n{\n\nx\n}\n\n{\n}\n\ny\n\nv\n\nx\n\n¤\n\n£\n\n¤\ny\n}\n\n£\n\n}\n\n¤\n\nx\n\n{\n\n£\nx\n\nx\n\nRepresentation)\n(Physical\nCode\nRepresentation\nDesign\nBehavior\nBlackbox\nPrinciples\nSystem\nPurpose\nSystem\nComponents\nSystem\nEnvironment\nOperator\nIntent\nRefinement\nDecomposition\nB\nx\n\n¥\n\nU\nt\nv\n\ny\n\n¥\n\n¥\n\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n\ny\n¢\ny\n\ny\n§\n·\n\n3⁄4\n1⁄4\n\n3⁄4\n\n·\n\n·\n±\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n¢\ny\n\nI\n¥\nx\n\ny\n}\n\ny\n\n}\nx\n\ny\n\nN\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\nO\n}\n\n£\nx\n\n£\n\ny\n}\n§\n\n}\n\nv\n¤\n\n£\n\n¤\n}\n¤\ny\n\ny\n¥\n{\n{\n\ny\n}\n\nx\nØ\n\n¢\n{\n\n}\ny\n\nx\n\n}\n\n¥\n\nv\n\ny\n¢\ny\n\nx\n\nv\n\nv\n\nv\nx\n\nv\n\ny\n\n¤\n\n£\n\n¤\n}\ny\ny\nx\ny\n\nx\n\ny\n¢\ny\n\ny\n\nx\n\ny\nx\n\nv\n\nx\n\n}\ny\n\nx\n\n}\n\n¥\n\ny\n¢\ny\n\n¤\n\n£\n\n¤\n\n}\n¤\ny\n\ny\n\n}\nx\n\ny\n\n{\n\nx\n\nx\n\nx\n\ny\n\n}\n\n}\n\nØ\ny\n§\nt\nv\n\ny\n\n¤\n\n£\n\n¤\n\nE\n¢\ny\n\n|\n\ny\nx\n\nr\n\nx\n\nx\n{\n¤\n\ny\n\n}\n¤\n¤\n\ny\n\nx\n\ny\n\n}\n\ny\n\n}\n\n¥\n\nv\n\ny\n¢\ny\n\nx\n\ny\n\nv\n\n{\nv\n¢\ny\nx\n\n}\n¤\n{\n\nx\n\nx\n{\n¤\n\ny\n}\n\n¤\n}\n\ny\n¥\n{\n\nv\nx\n\nv\n\nv\n\ny\nx\n\nx\ny\n\n}\ny\n\n§\nt\nv\n\nt\n¤\n}\n\n¬\n\nt\n\nv\n}\n£\nx\n\n¤\n\n£\n\n¤\n\nv\n}\n\ny\n\n}\ny\n\nx\n\n}\n\n¥\n\nv\n\n¤\n\nx\n\n}\n¤\n\ny\nx\n\nv\n\ny\n¢\ny\n\n}\ny\n}\n\nv\n\n¤\n\n}\n\nv\n\nx\n\n}\n\nx\n\ny\n\nv\n\n{\n\ny\n}\ny\n\n¤\n¤\n}\ny\n\nv\n\n¥\n\nx\n\n}\n¤\ny\n\n}\n\nx\n\nv\n\n¥\n\nx\n\nx\ny\n\n}\n\n¢\nx\n\n{\n¤\n\n}\n\nx\n\nx\ny\ny\n¥\n\ny\n§\nt\nv\n\n¤\n\ny\n\n¤\n\n£\n\n¤\ny\n{\n\n£\nx\n\nv\n\nx\n\n}\n\nx\n\ny\ny\n}\n\n¢\n\n}\ny\n\n}\n\n¥\n\nx\n\nx\n£\nx\n\n¥\n}\n¤\n\n{\n\ny\nx\n\n}\n\nx\n\n{\n¤\n\n}\n\nx\n\nx\ny\ny\n¥\n\ny\n§\nt\nv\n\n}\n{\n{\nx\n\ny\n\n¤\n\n£\n\n¤\ny\n{\n\n£\nx\n\nv\n\n¤\n}\n\nx\n\n}\n¤\nx\n\n}\n\nx\n\nv\n}\n\n}\n¤\n¤\n\ny\n\n}\ny\n\nx\n\n}\n\ny\ny\nv\nx\n\n}\n\nv\nx\n\n}\n¤\n¤\n\n£\n\n¤\ny\n§\n\n}\n\nv\n¤\n\n£\n\n¤\nN\n\n{\n\nv\n\n{\n¤\n\n£\n\n¤\nO\n}\n¤\ny\n\nx\n\n¤\n¥\n\ny\n}\ny\n{\n\nx\n\n}\n\nx\n\nv\n\nI\n¥\nx\n\ny\n}\n\ny\n¥\n¤\n\ny\n\n£\n\nx\n\n}\n\nx\n\n£\n}\n¤\nx\n\n}\n\nx\n\n}\n\nx\n£\nx\n\nx\n\ny\n\nv\n\nx\n\n}\n\nx\n\n}\n\nv\n}\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n\n£\n\n¤\n§\nt\nv\n\n{\n¤\n\n£\n\n¤\n\ny\n\nx\n\n¤\n¥\n\nv\nx\ny\nx\n\n}\n\nx\n\nN\n\n{\n\n{\n\nv\n}\n{\ny\n\n{\n}\n\ny\n\nv\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\nO\n\n}\n¥\ny\n\nx\n\nx\ny\n\n¤\n\n}\n\nv\n}\n\n¢\n{\n\ny\n\n£\n}\n¤\nx\n\n}\n\nx\n\n¥\n\ny\nx\n\n{\n\n£\nx\n\n¥\n¤\n\n}\n{\n{\n\n{\n\nx\n}\n\n}\n\nv\nx\ny\nv\nx\n\nv\n\ny\n\n¤\n\n£\n\n¤\n\nx\n\n}\n\ny\n\n}\n\nx\n\n§\ns\nI\ns\nA\n\nE\nj\nk\nÆ\nA\n\nl\nA\nA\nj\nÆ\n±\n¤\n\nv\n\n£\n\nx\n\n}\n¤\n\nx\n\ny\nx\n\nv\n\nv\nx\n\nv\n\ny\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n\n£\n\n¤\n\n±\no\n·\n\n»\n¿\no\n\n}\nx\n\ny\n\nv\n\nN\nÞ\nO\ny\n¢\ny\n\n}\n¤\ny\n\nN\n\nO\n\ny\nx\n\ny\n\n}\nx\n\ny\n\nN\n:\nO\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n\nN\ny\nO\n¤\nx\n\nx\n\n}\n\nx\n\ny\n\nN\n@\nO\n\ny\nx\n\n£\n}\n¤\n¥\n}\n\nx\n\nx\n\nx\n}\n}\n\n{\n\nx\n\nx\n\nx\n\ny\n\n}\n\nN\nw\nO\n\ny\n¥\n¤\n\ny\n\n}\n\n}\n¤\n¢\ny\n\ny\n\ny\n¢\ny\n\n¤\n\n£\n\n¤\nI\n¥\n}\n¤\nx\n\nx\n\ny\n§\n\n}\n\n{\n¤\n\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\nE\n¿\n3⁄4\n·\no\nN\n{\n¥\n\n{\n\ny\n\nO\n\nt\n±\nE\n\n}\n\nU\na\nÞ\nU\n\n¿\n\na\n\n3⁄4\nO\n¿\n\na\n3⁄4\n\n·\n\n3⁄4\nμ\na\n1⁄4\n¿\n\n»\n3⁄4\n·\n\n·\n\n1⁄4\n¿\n·\n·\n\no\n\n¿\nμ\n3⁄4\n¿\n\na\n¶\n3⁄4\nμ\n1⁄4\n\no\n±\no\n·\n\n¿\n»\n·\n\n¿\nμ\no\n\n¿\n\n3⁄4\n\n¿\n3⁄4\na\no\n»\n\n1⁄4\n·\n\n¿\n\n3⁄4\n¶\n·\n\n¿\nμ\n3⁄4\n·\n\no\n»\n3⁄4\n1⁄4\n\n±\no\n·\n\no\n\no\n\na\n\nU\n\n·\n\n1⁄4\n·\n»\n¿\n·\n\nμ\n·\n\n3⁄4\n·\n\na\n3⁄4\n\n1⁄4\n¿\n·\n·\n\no\n\n¿\nμ\no\nO\n\n·\nμ\n¿\n·\nμ\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\nμ\n3⁄4\n·\n·\n\n·\n\n¿\n\n¿\n·\n¿\nE\n\n1⁄4\n3⁄4\n·\n1⁄4\n¿\nμ\na\n\n·\n\n¿\nμ\no\n\n×\ny\n¥\n}\n¤\n¤\n¢\n\nx\n\nv\n\n}\n\n¤\n¢\ny\n\n}\n\ny\n\n}\n{\n\n}\n¤\ny\n}\n\ny\n\n}\n\nx\n\n£\n\n¢\n\n}\n¤\n\ny\n§\nU\n\nv\n\ny\n\ny\n\n{\ny\nx\n\nx\n\ny\n¢\ny\n\nI\n¥\nx\n\ny\nx\ny\n\nv\n\n}\n¤\ny\nx\n\ny\n\n}\n\n¤\n\n}\n\n}\n\nv\nx\n\n£\n}\n\n¤\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\nI\n¥\nx\n\ny\n§\nB\n\na\nÞ\n}\n\n£\n\n}\n\ny\n¥\n\n}\n¤\nx\ny\nU\nq\nÞ\nU\n\n¿\n\na\n\n1⁄4\n¿\n·\n·\n\no\n\n¿\nμ\n3⁄4\n¿\n\na\n3⁄4\nμ\n1⁄4\n\n»\n\n¿\n·\n\n1⁄4\n·\n\n¿\nμ\n\n¿\n\n3⁄4\nμ\n±\n·\nO\n¿\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n1⁄4\n·\n¿\no\n\nμ\nE\nμ\n¿\n\n¿\nμ\n·\n3⁄4\n·\n·\n±\n3⁄4\n·\n3⁄4\nμ\n±\n\n3⁄4\n·\n\n»\n·\n¿\n\ne\nμ\n¿\n·\no\n3⁄4\nμ\na\n\n·\n\n1⁄4\n3⁄4\n·\n·\n±\n\n»\n·\n¿\n\n·\n»\n\nμ\n\n·\n\nt\nv\nx\ny\n\n¢\n{\n\n}\n\n}\ny\n\nx\n\nx\ny\n\n}\n\nv\n\nE\n¢\ny\n\nr\n¥\n\n{\n\ny\n\n¤\n\n£\n\n¤\n\n¥\ny\nx\n\n}\n\n}\n{\n{\n\n{\n\nx\n}\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\nN\n\ny\n\n¤\nx\n¬\n\n¤\n¢\n\n¤\nx\ny\nv\nO\n§\nq\n\nI\n¥\nx\n\ny\nN\n}\n\ny\n\n}\nx\n\ny\nO\n}\n\n}\n¤\ny\n\nx\n\n¤\n¥\n\nv\n\nÞ\nm\n\n1. System Purpose\n4. Physical and Logical Function\n1.1 Introduction\n4.1 Human-Computer Interface Design\n1.2 Historical Perspective\n4.2 Pilot Operations (Flight) Manual\n1.3 Environment\n4.3 Software Design\n1.3.1 Environmental Assumptions\n4.4 Physical Requirements\n1.3.2 Environmental Constraints\n4.4.1 Definition of Standard Conditions\n1.4 Operator\n4.4.2 Performance Capability of Own Aircraft's\n1.4.1 Tasks and Procedures\nMode S Transponder\n1.4.2 Pilot-TCAS Interface Requirements\n4.4.3 Receiver Characteristics\n1.5 TCAS System Goals\n4.4.4 TCAS Transmitter Characteristics\n1.6 High-Level Functional Requirements\n4.4.5 TCAS Transmitter Pulse Characteristics\n1.7 System Limitations\n4.4.6 TCAS Pulse Decoder Characteristics\n1.8 System Constraints\n4.4.7 Interfence Limiting\n1.8.1 General Constraints\n4.4.8 Aircraft Suppression Bus\n1.8.2 Safety-Related Constraints\n4.4.9 TCAS Data Handling and Interfaces\n1.9 Hazard Analysis\n4.4.10 Bearing Estimation\n2. System Design Principles\n4.4.11 High-Density Techniques\n4.5 Hardware Design Specifications\n2.1 General Description\n4.6 Verification Requirements\n2.2 TCAS System Components\n2.3 Surveillance and Collision Avoidance Logic\n5. Physical Realization\n2.3.1 General Concepts\n5.1 Software\n2.3.2 Surveillance\n5.2 Hardware Assembly Instructions\n2.3.3 Tracking\n5.3 Training Requirements (Plan)\n2.3.4 Traffic Advisories\n5.4 Maintenance Requirements\n2.3.5 Resolution Advisories\n2.3.6 TCAS/TCAS Coordination\nA. Constant Definitions\n2.4 Performance Monitoring\nB. Table Definitions\n2.5 Pilot-TCAS Interface\n2.5.1 Controls\nC. Reference Algorithms\n2.5.2 Displays and Aural Annunciations\nD. Physical Measurement Conventions\n2.6 Testing and Validation\nE. Performance Requirements on Equipment\n2.6.1 Simulations\nthat Interacts with TCAS\n2.6.2 Experiments\n2.6.3 Other Validation Procedures and Results\nF. Glossary\nG. Notation Guide\n3. Blackbox Behavior\nH. Index\n3.1 Environment\n3.2 Flight Crew Requirements\n3.2.1 Tasks\n3.2.2 Operational Procedures\n3.3 Communication and Interfaces\n3.3.1 Pilot-TCAS Interface\n3.3.2 Message Formats\n3.3.3 Input Interfaces\n3.3.4 Output Interfaces\n3.3.5 Receiver, Transmitter, Antennas\n3.4 Behavioral Requirements\n3.4.1 Surveillance\n3.4.2 Collision Avoidance\n3.4.3 Performance Monitoring\n3.5 Testing Requirements\n\nB\nx\n\n¥\n\n:\nU\nt\nv\n\ny\n\nv\n\ny\n}\n\n{\n¤\n\nt\n±\nE\n\nE\n{\n\nx\n\n}\n\nx\n\nÞ\nÞ\n\nv\n¥\n\n}\n\n{\n\n}\n\nv\n\nv\n¥\n\n}\n\n{\n¥\n\nx\n\n}\n\n}\n\nv\n\n£\nx\n\nx\n\nv\nx\n\nv\nt\n±\nE\n\nx\n¤\n¤\n\n{\n\n}\n\n§\nq\n\nI\n¥\nx\n\ny\n\nv\n\n{\n\n}\n\nN\nx\n\nv\nx\ny\n\n}\ny\n\nv\n\n{\nx\n¤\n\nO\n}\n\n¥\ny\n\n¥\nx\n\nv\n\ny\nx\n\nv\n\nt\n±\nE\n\n{\nx\n¤\n\nx\n\n}\n\nx\n\nv\n\n}\ny\n¬\ny\n}\n\n{\n\n¥\n\ny\n\n}\nx\n\n}\n\nx\n\nv\n\n}\n\n¥\n}\n¤\ny\n\n}\n\n}\nx\n\nx\n\n{\n¤\n}\n\ny\n}\n\n{\n\n}\n\n§\nu\nx\n\n¬\ny\n}\n\n{\n\n£\nx\n\ny\nv\n\nv\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\n§\n\n}\n\n{\n¤\n\nt\n±\nE\n\n{\n\n}\n\nI\n¥\nx\n\ny\n}\n\nU\nU\nÞ\nU\n\n·\n\n·\nμ\n\n·\nμ\n\n3⁄4\n·\n\no\n\no\n¿\n·\n\na\n\n·\nμ\n\n»\n\n·\n¿\n·\no\nμ\n3⁄4\n·\n·\n\n·\n\nμ\n»\n\n¿\n\n»\n·\n·\n±\n3⁄4\nμ\na\no\n\n¿\n¿\n·\nμ\n·\n±\n·\n¿\nμ\n\no\n\nμ\n\n»\n\n¿\n\no\n·\n±\n3⁄4\no\n¶\no\n\nE\nμ\n\na\n\"\n\nE\nμ\n·\n»\n3⁄4\n·\nμ\n\nU\n&\nU\n$\nμ\n\n»\n\n·\n¿\n·\n\no\n·\nμ\n¿\n·\n\n3⁄4\nμ\n\n¿\nμ\n·\nμ\n\n3⁄4\no\n\no\n¿\n\n3⁄4\n$\n\n3⁄4\n\n¶\n1⁄2\n1⁄4\n\na\n\no\n¿\n\n±\n¿\nμ\n·\n±\n\no\n\nE\nμ\n1⁄4\n¿\nμ\no\n·\n\n3⁄4\n\nμ\n·\no\n}\n\ny\n\nx\n\nx\n\ny\n\nv\n\nv\n\ny\n¢\ny\n\n}\n\n}\n\nv\nx\n\n£\n\nx\n\ny\n{\n¥\n\n{\n\ny\n\n§\nB\n\n}\n\n{\n¤\n\nt\n±\nE\nx\ny\n\n}\n¤\n\n¤\n\nx\n\nx\n\nv\n\nv\n\n¥\n\n¤\n\n£\n\n¤\n}\nx\n\n}\nz\n\n¤\ny\n¢\ny\n\nv\nx\n¤\n\nx\n\nx\ny\n\n¢\nx\n\n}\nx\n\n}\nx\n\n}\n\nI\n¥\n}\n\ny\n\n{\n\n}\n\n}\n\nx\n\n}\nx\n\n}\n\n§\n±\n£\n\nx\n\nx\n\nx\n\nx\ny\n\n}\n\n}\n¤\n\n{\n¥\n\n{\n\ny\n\nt\n±\nE\n\nv\n\ny\n\n}\n¢\n\n}\n\nv\nx\n\n£\n\nx\n\nx\ny\n\n¥\nx\n¤\n\nv\n\ny\n¢\ny\n\n}\n\n}\n¤\n¤\n§\n\nx\ny\nx\n\ny\n\n}\n\n}\n\ny\n\n}\nx\n\nv\n\nv\n\ny\n¢\ny\n\n}\n\n}\n\nv\nx\n\n£\n\nx\n\ny\n{\n¥\n\n{\n\ny\n\nx\n§\n\n§\n\n}\n\ny\n\n}\nx\n\nv\n\n{\n\nx\n}\n¤\ny\n¢\ny\n\ny\nx\n\ny\n§\nt\n\n}\n¥\ny\n\nv\n\n£\n}\n¤\n¥\n}\n\n}\n\n¤\n}\n\nx\n\n¢\n\n}\n\nØ\ny\n}\n\n}\n¤\n\n}\n\nx\n£\n\ny\nx\n\ny\n\ny\n\n{\n}\n\n}\n\nx\n\nv\n\ny\n\n¢\n{\n\ny\n\nx\n\nx\n\n}\n\nx\n\nN\n\n}\n¤\ny\n}\n\ny\nx\n\ny\n\n}\nx\n\ny\nO\nx\ny\nx\n\n{\n\n}\n\n§\nB\n\ny\n}\n\n¢\n\nx\n\nx\n\n}\n¤\ny\n¢\ny\n\ny\n\ny\n\n}\nx\n\ny\ny\nv\n\n¥\n¤\n\n¥\n\nv\n\ny\n\n{\n}\n\n}\n\nx\n\n}\n¤\n}\n\ny\n}\n\n¢\n\n¤\n}\n\n§\n\n}\n\n{\n¤\n\ny\n\nμ\n¿\nμ\n¶\no\n3⁄4\n\n·\n±\n1⁄4\n¿\nμ\no\n·\n\n3⁄4\n\nμ\n·\no\n\nt\n±\nE\n\n}\n\nU\nÞ\nU\n$\nμ\n\no\n±\no\n·\n\no\n·\n\no\n\n·\nμ\n\n·\n\n3⁄4\nμ\no\n»\n¿\nμ\na\n\no\n\n¿\n\n·\n\nμ\n\n·\n±\n1⁄4\n3⁄4\n\na\n\n±\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\n¿\n\nE\n\n¿\n\nμ\na\n\n$\n(\n»\n\n»\n¿\no\n\no\n\n&\nU\n\n¿\na\n\n3⁄4\n·\n\n¿\nμ\no\n\n¿\n\n1⁄4\n\nμ\n·\n*\n\n»\n¿\n·\n\n1⁄4\n\no\n3⁄4\nμ\na\n»\nμ\n\n·\n¿\no\n¿\n»\nμ\n\no\n\no\n·\n\n,\n\na\n\n3⁄4\n\n·\n±\n¶\n\n·\n3⁄4\n·\n\na\n1⁄4\n¿\nμ\no\n·\n\n3⁄4\n\nμ\n·\no\ny\nv\n\n¥\n¤\n\nv\n}\n£\n\n}\n¢\n¤\nx\n\n¬\ny\n\nv\n\ny\n¢\ny\n\nv\n}\nn\n}\n\n¤\n\n}\n\n{\n\nv\n}\n{\ny\n¤\nx\n\n¬\ny\n\n}\n\n¢\n}\n\n}\n¤\n¢\ny\nx\ny\n\ny\n¥\n¤\n\ny\n\nv\n}\n\n¤\n\nv\n}\n\ny\n\n}\nx\n\nx\n\nx\n\nx\n\n§\nF\n}\nn\n\n}\n\n}\n\n}\n¤\n¢\ny\n\ny\ny\n{\n\nx\n\nv\nx\ny\n¤\n\n£\n\n¤\n}\n\n¤\nx\n\n¬\n\nu\n\n£\n\n¤\nÞ\n\nI\n¥\nx\n\ny\n}\n\ny\n\n}\nx\n\ny\n\nv\nx\ny\n¤\n\n£\n\n¤\n\ny\nx\n\n}\n\n¥\n\ny\n\nu\n\n£\n\n¤\n&\n\n}\n\ny\n¢\ny\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\nN\n\n}\n\n{\n\nx\ny\n¬\ny\nO\n§\n\n}\n\n{\n¤\n\ny\n}\n\n¢\n\ny\n\n}\nx\n\ny\n}\n\nU\nE\nÞ\nU\n$\nμ\n\no\n±\no\n·\n\no\n·\nE\n\nμ\n\n3⁄4\n·\n\n3⁄4\na\n\no\n¿\n\no\n·\nμ\n3⁄4\n·\n\n,\n\n3⁄4\no\n·\n\n·\n·\n·\n\na\n\n3⁄4\n·\n\n¿\nμ\n3⁄4\no\n»\n¿\no\no\n\n·\n\n¿\n\n$\n(\n1⁄4\n·\n\n3⁄4\n\n3⁄4\nμ\n1⁄4\n\no\n\nE\n&\nU\n$\nμ\n\no\n±\no\n·\n\no\n·\nμ\n¿\n·\na\n\no\n\n»\n·\n·\nμ\n\n»\n\n·\n¿\n·\n3⁄4\nμ\na\n\n$\n(\n¿\n»\n\n3⁄4\n·\n\n¿\nμ\no\na\n\nμ\nE\n1⁄4\n\n·\n\n1⁄4\n3⁄4\n·\n»\nμ\n3⁄4\no\n\no\n¿\n\n\"\n\nE\nμ\n·\n\nv\n}\n\n1⁄2\nμ\n\nμ\n·\n\n¥\n\ny\n}\n\nv\n\ny\n}\n\n¤\n\n£\n\n¤\n\nv\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nN\ny\n\nB\nx\n\n¥\n\n&\nO\n§\nB\n\n}\n\n{\n¤\n\nv\n\ny\n}\n\n¢\n\ny\n\n}\nx\n\nE\n:\n\n}\n\nE\nÞ\nU\n$\nμ\n\no\n±\no\n·\n\no\n·\nμ\n¿\n·\n\nμ\n·\n\nO\n\n·\nμ\n·\nμ\n\nE\n\n¿\n\nμ\na\n\n$\n(\no\n±\no\n·\n\n¿\n\n¿\n·\nμ\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n·\n\n3⁄4\nμ\no\n\no\no\n\n¿\nμ\no\n·\n¿\n·\nμ\n\nE\n\n¿\n\nμ\na\n\n$\n(\no\n±\no\n·\n\nE\nÞ\n§\nÞ\nU\n$\nμ\n\no\n±\no\n·\n\na\n\no\n\nE\nμ\n\no\n·\n·\n\n·\n\nμ\n·\n\n¶\n\nμ\n1⁄4\n\nO\n\n·\nμ\nE\n\n¿\n\nμ\na\n¶\n\n3⁄4\no\n\na\no\n\n1⁄4\n¿\nμ\na\n3⁄4\n\n±\no\n\n·\n·\n3⁄4\nμ\n1⁄4\n\n3⁄4\na\n3⁄4\n\na\n\no\n·\n3⁄4\nμ\n1⁄4\n\n¶\n\n3⁄4\no\n\nμ\nE\n\n,\n\n»\n\nμ\n·\n1⁄4\nμ\n3⁄4\nμ\n¶\nμ\n\n·\no\n\n3⁄4\nμ\na\nO\n\n·\nμ\n¿\n·\nμ\n\n3⁄4\na\n\n¿\no\n\n1⁄4\n\no\n·\nμ\n3⁄4\n·\n¿\n»\n\n3⁄4\n·\n\nμ\n·\nμ\n\n;\n\n,\n\nμ\n1⁄4\n±\n\n3⁄4\nμ\na\n\nE\nÞ\n§\nÞ\n§\nÞ\nU\n$\nμ\n\na\n\no\n\nE\nμ\n¿\n\n·\nμ\n\n¿\na\n\nO\n3⁄4\n\n¿\n\no\n\no\n\na\n\n±\n$\n(\n\no\n·\n»\n\n¿\n\na\n\n1⁄4\n¿\n\n»\n3⁄4\n·\n\n·\n\n·\n±\nO\n\n·\nμ\n¿\na\n\no\n\n3⁄4\nμ\na\n(\n¿\n\n·\nμ\n\nE\n\n¿\n\nμ\na\n¶\n\n3⁄4\no\n\na\no\n\n1⁄4\n¿\nμ\na\n3⁄4\n\n±\no\n\n·\n·\n3⁄4\nμ\n1⁄4\n\n3⁄4\na\n3⁄4\n\no\n±\no\n·\n\nE\nÞ\n§\nÞ\n§\nÞ\nU\n$\nμ\n\n,\n\nμ\n1⁄4\n±\no\n»\n\n1⁄4\n·\n\n¿\n\n¿\na\n\n·\n\n3⁄4\nμ\no\n\no\no\n\n¿\nμ\no\n\no\n·\n\n1⁄4\n¿\nμ\n·\n\n¿\n·\n·\n\na\n·\n¿\n»\n\n¿\n¶\n·\n\n1⁄4\n·\n3⁄4\na\n?\n3⁄4\n1⁄4\n\nμ\n·\na\n\no\n·\n3⁄4\nμ\n1⁄4\n\n¶\n\n3⁄4\no\n\nμ\nE\n\n,\n\n»\n¶\n\nμ\n·\n1⁄4\nμ\n3⁄4\nμ\nμ\n\n·\no\n\nE\nÞ\n§\nÞ\n§\nÞ\nU\n$\nμ\n\na\n\no\n\nE\nμ\n\no\n·\n\nμ\no\n\n·\n\n1⁄4\n·\n\n¿\n\n3⁄4\nE\n¶\nμ\n\n·\n\n1⁄4\n1⁄4\n¿\n\n»\n3⁄4\n·\n\n·\n\n·\n±\n\n·\nO\n\nμ\n$\n(\n\n3⁄4\nμ\na\n\nE\nÞ\n§\n&\nU\n\n·\n·\n\n»\n·\n\n$\n(\n\nμ\n\n·\no\nO\n\n·\nμ\n\nμ\na\n\n·\n\n1⁄4\n·\n\n¿\nμ\n\n3⁄4\nμ\nE\n\n¿\n\n¿\nμ\n\n3⁄4\nμ\n¿\n·\nμ\n\nB\n3⁄4\n»\n»\n\n¿\nD\n\n3⁄4\n·\n\n·\n±\n\nμ\n\nE\n\no\n·\n\na\n\no\n\nE\nμ\n\na\n·\n¿\n·\n\n·\n·\nμ\n\n¿\nO\nμ\n·\n\n3⁄4\nμ\no\n\no\no\n\n¿\nμ\no\n\no\n·\nμ\n\nμ\n\n¿\n\no\n\n1⁄4\nμ\n$\n(\n\nμ\n\n·\no\nO\n\n·\nμ\n\nμ\n·\nμ\n\no\n\nE\n\n¿\nμ\n\nμ\n1⁄4\n\n3⁄4\no\n\no\n\n·\nμ\n\nμ\n·\n\n¿\nE\n3⁄4\n·\n\n¿\nμ\n\n3⁄4\n·\n\n3⁄4\nμ\na\n»\n¿\nO\n\n3⁄4\n·\n·\n¿\n1⁄4\n3⁄4\n·\n\n¿\nμ\n\n¿\n\n3⁄4\n1⁄4\nμ\n¿\n\n·\nμ\n\no\n·\na\n\n¶\n1⁄4\n\n3⁄4\no\n\nμ\n¿\n\na\n\n·\n¿\n»\n\nμ\n·\n\nμ\na\n\no\n\na\n\nμ\n·\n\n¶\n\nμ\n1⁄4\n\nO\n\n·\nμ\n\n$\n(\n\nF\nμ\n\n¿\nμ\n\nμ\n·\n\nI\n¥\nx\n\ny\n}\n\ny\n\n}\nx\n\ny\n\n}\n¢\n¤\n\n}\n\ny\n\nx\n\nx\n\ny\n\nv\n\n¥\ny\n\nv\n\ny\n¢\ny\n\nv\n\ny\n¢\ny\n\ny\n}\n\n¢\n}\n\nv\n\n}\n\n}\n¤\n¢\ny\n\ny\n\nx\n\nv\n}\n\nv\n\nI\n¥\nx\n\ny\nv\n\n¤\n\nv\n\n¤\n}\n\ny\n¢\ny\n\nx\n\nv\nx\n\nv\n\nv\n\ny\n¢\ny\n\nx\n\ny\nx\n\nx\ny\n\n¥\ny\n\n§\n\n}\n\n{\n¤\n\ny\n\nt\n±\nE\nx\n\n¤\n¥\n\nU\n\nÞ\nU\n\n¿\nμ\nE\n·\nμ\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\nμ\n\n¿\nμ\n\nμ\n·\n3⁄4\n·\n3⁄4\n·\n\n·\no\n\n·\nμ\n\nμ\n\n¶\n3⁄4\n\n1⁄4\nμ\n±\no\nμ\n3⁄4\n·\n·\n\nG\nH\n\nμ\na\no\nμ\n\n3⁄4\n\nμ\n3⁄4\no\n1⁄2\n\no\n·\n»\n\n¿\n\n·\n±\n\n·\nμ\n\nμ\n·\nμ\n\nJ\n\n¿\n\nμ\na\n>\n\n¿\nD\n\n·\n±\nH\n3⁄4\n\nμ\n\nμ\nE\n\n±\no\n·\n\nB\nJ\n>\nH\n\nE\n\n·\nμ\n\nμ\n$\n(\n\n&\nU\n$\nμ\n\nμ\n3⁄4\n\n¿\n\n¿\n\nμ\n·\n\n3⁄4\n1⁄4\n·\n\n¿\nμ\n¿\n\nμ\n¿\nμ\n¶\n$\n(\n\n,\n\n»\n¶\n\nμ\n·\nO\n\n·\nμ\n$\n(\n\no\n·\nμ\n¿\n·\na\n\nE\n\n3⁄4\na\n\n·\nμ\n\n»\n\n¿\n\n3⁄4\nμ\n1⁄4\n\n¿\n\n·\nμ\n\n$\n(\n\n,\n\n»\n\nμ\n·\n¿\n\n·\nμ\n\n»\n\n¿\n\n3⁄4\nμ\n1⁄4\n\n¿\n\n·\nμ\n\n,\n\n»\n\nμ\n·\nO\n\n·\nμ\nO\nμ\n\n1⁄4\nμ\n$\n(\n\nμ\n·\n\n3⁄4\n1⁄4\n·\no\n\n:\nU\n$\nμ\n\n$\n(\n\n3⁄4\n·\n\n·\no\n3⁄4\nμ\na\n3⁄4\na\n\no\n¿\n\no\n\no\n·\n\nμ\na\n\n»\n\nμ\n¶\na\n\nμ\n·\n¿\n\n·\nμ\n¿\no\n\no\n\nμ\nE\n·\nμ\n\n3⁄4\no\n·\n\n1⁄4\n3⁄4\n\n·\n\n¿\nμ\n3⁄4\nμ\na\nO\n3⁄4\n\nμ\n\nμ\nE\no\n±\no\n·\n\no\no\n\n»\n·\n\n¿\nμ\no\n}\n\ny\n{\n\nx\n\nv\n\n}\n{\n{\n\n{\n\nx\n}\n\n}\n\n}\n¤\n¤\n¤\n\n£\n\n¤\ny\n\nv\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n{\n¤\n}\nx\n\n}\n\nx\ny\nx\n\n¥\n\n}\n\n}\n¤\nx\n\n}\n\nx\n\nv\nx\n\nv\n\nv\n\ny\nx\n\nx\ny\n\n}\ny\n\n§\nt\nv\n\ny\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n}\n\n¥\ny\n\nx\n\nv\n\ny\n}\n\n¢\n\nv\n\n}\n\n}\n¤\n¢\ny\n\ny\n\nx\n\n}\n¬\nx\n\n¤\n\n¤\n\n£\n\n¤\n\ny\nx\n\nx\ny\nx\n\ny\n§\nB\n\n}\n\n{\n¤\n\n{\n\n}\n\nx\n\n}\n¤\ny\n}\n\n¢\n\n{\n\ny\n\nv\n\n}\n\n¥\n\n}\n\n¢\n\nv\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n}\n\n¤\ny\n¥\n\n¤\n¢\nx\n\nv\n\ny\nx\n\n}\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\n{\n\ny\ny\n\ny\n§\nt\nv\n\n{\n\n}\n\nx\n\n}\n¤\ny\n¢\ny\n\ny\nv\n\n¥\n¤\n\nx\n\ny\n¥\n\nN\nÞ\nO\n\nv\n}\n\nx\n\nx\ny\n\ny\n\n¥\n\n{\n\n}\n\n}\n\n}\nx\n\n}\nx\n\nx\n\nv\n\n}\n\n}\ny\ny\n¥\n\n¢\n\nv\n\ny\nx\n\ny\n\nN\n&\nO\n\nv\n}\n\nv\n\n¤\ny\n}\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n¥\ny\n\n¥\n\nx\n\nx\n\nx\n\nx\n}\n¤\n\nx\ny\nx\n\n}\n¬\nx\n\n}\n\ny\nx\n\n}\n\nN\n:\nO\n\nv\n}\n\nv\n\n¤\ny\n}\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n}\n\n£\nx\n\n¤\n}\n\n¢\n\nv\n}\n\ny\nx\n\nv\n\ny\n¢\ny\n\nÞ\n&\n\ny\n¥\n\nv\n}\ny\n\n¬\n}\n\n¥\n\ny\n\n¥\n\n}\n¥\n\nv\n\nx\nn\n\nv\n}\n\ny\nx\n\n{\n\n¥\n\ny\n\n¢\n\nv\n}\n\ny\nx\n\nv\n\n£\nx\n\nu\n\n£\n@\n<\n§\nU\n{\n\n}\n\nx\n\n}\n¤\n\n}\n\n¬\n\ny\n\nx\n\nx\n\ny\n\n}\n\n}\n\nx\n\ny\ny\nv\n\n¥\n¤\n\nx\n\n}\n\n}\n¤\n¢\ny\nx\ny\n\nv\n\n}\n{\n{\n\n{\n\nx\n}\n\n§\nu\nx\n\n¬\nx\n\nv\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n\nv\n\n¥\n\nv\n\n¥\n\nv\n\n¥\n\nx\n\nv\n\nv\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\nN\n\n}\n\n{\n¤\n\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\nx\n\nv\n\ny\n¢\ny\n\n}\n¥\n¤\n\ny\nO\n\nx\n¤\n¤\n}\ny\ny\nx\ny\n\nx\n\n{\n\nx\n\ny\n}\n\n¢\n\n}\nx\n\n}\n\n}\n\nx\n£\nx\n\nx\n\ny\n§\n\n}\n\n{\n¤\n\ny\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n}\ny\ny\n\nx\n}\n\nx\n\nv\n\nI\n¥\nx\n\ny\n\nv\n\ny\n\n¤\n\n£\n\n¤\n\nv\n\nt\n±\nE\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nU\nq\nÞ\nU\n\n¿\n\na\n\n1⁄4\n¿\n·\n·\n\no\n\n¿\nμ\n3⁄4\n¿\n\na\n3⁄4\nμ\n1⁄4\n\n»\n\n¿\n·\n\n1⁄4\n·\n\n¿\nμ\n\n¿\n\n3⁄4\nμ\n±\n·\nO\n¿\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n1⁄4\n·\n¿\no\n\nμ\nE\nμ\n¿\n\n¿\nμ\n·\n3⁄4\n·\n·\n±\n3⁄4\n·\n3⁄4\nμ\n±\n\n3⁄4\n·\n\n»\n·\n¿\n\ne\nμ\n¿\n·\no\n3⁄4\nμ\na\n\n·\n\n1⁄4\n3⁄4\n·\n·\n±\n\n»\n·\n¿\n\n·\n»\n\nμ\n\n·\n\nh\nj\nj\n\nA\nA\nk\nE\nA\nU\nU\n$\nμ\n\no\n\n,\n\nμ\n·\n\no\na\n\na\n\n¿\n\n·\nμ\n\n3⁄4\no\no\n\n»\n·\n\n¿\nμ\n·\nμ\n3⁄4\n·\n1⁄4\n¿\n\n1⁄4\n\n3⁄4\n·\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n1⁄4\n3⁄4\nμ\n¿\n»\n\n3⁄4\n·\n\n»\n·\n¿\nO\n\ne\nμ\n¿\n·\no\n3⁄4\nμ\na\nP\n\n»\n\na\n\n¶\n\nμ\nE\n\n·\n\n1⁄4\n3⁄4\n·\n1⁄4\n·\n\n¿\n\n1⁄4\n¿\nμ\n·\n\n¿\n·\n·\n\na\na\n\no\n1⁄4\n\nμ\n·\nB\n3⁄4\nμ\na\n·\nμ\n\n¿\n\n·\nO\n¿\n»\n·\n3⁄4\nμ\n\no\n1⁄4\n3⁄4\nμ\n1⁄4\n·\n¿\no\n\nμ\n¿\n\n¿\nμ\n·\n3⁄4\n·\n·\n±\n\n»\n·\n¿\n\ne\nμ\n¿\n·\no\n3⁄4\nμ\na\n\n·\n\n1⁄4\n3⁄4\n·\n·\n±\n\n»\n·\n¿\n\n»\n\nE\n\nq\n:\nU\n$\n(\n\no\nμ\n3⁄4\n·\n·\n¿\n»\n\n3⁄4\n·\n\nμ\n\nμ\n\n¿\n\n·\n\n3⁄4\nμ\na\n·\n\nμ\n3⁄4\n·\n3⁄4\n\n3⁄4\no\nO\n\n·\nμ\n·\n\n3⁄4\nR\n1⁄4\na\n\nμ\no\n\n·\n\no\n\n»\n·\n¿\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n»\n\no\n,\n\n3⁄4\n\nμ\n3⁄4\n\n·\n\n1⁄4\n3⁄4\n·\n\n·\n\no\nB\n\nV\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\nO\n\n·\nμ\n\nμ\nP\nμ\n\nE\n\nh\nj\nj\n\nA\nA\nk\nE\nA\nU\nU\n$\n\n3⁄4\nR\n1⁄4\na\n\nμ\no\n\n·\n±\n\n3⁄4\n±\n\nμ\n1⁄4\n\n3⁄4\no\n\n·\n¿\n·\nμ\n\no\n·\n\n·\n\n±\n\n3⁄4\nμ\na\n·\nμ\n\no\nO\n\n·\n·\n\n·\nμ\n\n3⁄4\nD\n\n¶\n\na\n\nμ\no\n\n·\n±\n¿\n\n·\nμ\n\nμ\n\nD\n·\n\n±\n\n3⁄4\n\no\n\n±\n\n}\n\n{\n¤\n\n}\n\n}\ny\ny\n¥\n\n{\n\nx\n\n}\ny\ny\n\nx\n}\n\nx\n\nv\n}\ny\n}\n\n¢\n\ny\n\n}\nx\n\nx\ny\nU\nE\n@\nU\n$\nμ\n\no\n±\no\n·\n\no\n·\nμ\n¿\n·\na\n\no\n\n»\n·\n·\nμ\n\n»\n\n·\n¿\n·\n3⁄4\nμ\na\n\n$\n(\n¿\n»\n¶\n\n3⁄4\n·\n\n¿\nμ\no\na\n\nμ\nE\n1⁄4\n\n·\n\n1⁄4\n3⁄4\n·\n»\nμ\n3⁄4\no\n\no\n¿\n\n\"\n\nE\nμ\n·\nμ\n¿\n\na\n\no\n\n»\n·\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n¿\n»\n\n3⁄4\n·\n\n¿\nμ\n\nE\n@\n§\nÞ\nU\n$\nμ\n\n»\n\n·\n¿\n·\n¿\n\n3⁄4\n$\n(\n\n¶\n\n,\n\n»\n»\n\na\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\no\n·\nμ\n3⁄4\n\n·\nμ\n\n¿\n»\n·\n\n¿\nμ\n·\n¿\no\nO\n\n·\n1⁄4\nμ\n·\n¿\n·\nμ\n\n$\n\n3⁄4\nR\n1⁄4\n¶\n\na\n\no\n¿\n\n±\n¶\nX\nμ\n·\n±\n\n¿\na\n\nO\nμ\n\n$\n\no\n3⁄4\n\na\n\no\n»\n·\n3⁄4\n±\n\na\n\n·\na\n\no\n»\n·\n3⁄4\n±\n¿\n\no\n¿\n·\n\n·\n\n¿\nμ\n3⁄4\na\n\no\n¿\n\no\n\no\n\nμ\nμ\n\n¶\n\n·\n\na\n\nh\nj\nj\n\nA\nA\nk\nE\nA\nU\nU\n$\nμ\n\no\n\n3⁄4\n·\n\nO\n\n·\n·\n\no\n\na\na\n\nμ\nE\n1⁄2\nμ\n3⁄4\n·\n3⁄4\n»\n»\n\n¿\n3⁄4\n1⁄4\nμ\n·\n¿\n»\n3⁄4\n\n3⁄4\n·\n·\n\n·\n\nμ\nO\n3⁄4\n±\no\n\nO\nμ\n\nμ\n·\nO\n¿\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n3⁄4\n\n»\n\n¿\n?\n\n1⁄4\n·\n\na\n·\n¿\n1⁄4\n¿\n\n1⁄4\n·\n¿\no\n\n·\n¿\n\n3⁄4\n1⁄4\nμ\n¿\n·\nμ\n\n3⁄4\nμ\na\n$\n(\n\nO\n¿\n\n·\na\n1⁄4\n3⁄4\n·\n·\n\n¿\n\n3⁄4\nμ\n\n3⁄4\no\n\n3⁄4\nμ\n\no\no\n\n»\n·\n\n¿\nμ\no\n\n}\n¢\n}\n¤\ny\n\n}\n{\n{\n¤\n¢\n\n}\n\n¥\n\ny\n\nv\n\n£\nx\n\n§\n\n}\n\n{\n¤\n\ny\n\n£\nx\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n\nt\n±\nE\n}\n\nv\n}\n\nU\n\n±\nÞ\nU\n\n·\n·\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\nμ\n3⁄4\n\n·\n\nE\n3⁄4\n·\n\na\n\nμ\n·\n\n1⁄2\n1⁄4\n3⁄4\n·\n\n¿\nμ\nμ\n\no\n\n±\nR\nU\n\n·\n·\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n1⁄4\n3⁄4\n\n±\n·\n\n3⁄4\nμ\no\n»\n¿\nμ\na\n\no\n\n±\n:\nU\n$\nμ\n\n$\n(\n\n¶\n\n,\n\n»\n»\n\na\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n1⁄4\n3⁄4\n\no\n3⁄4\n¿\na\n\n¶\n\n3⁄4\n\n·\n\n3⁄4\nR\n1⁄4\n1⁄4\n¿\nμ\n·\n\n¿\n·\n·\n\n3⁄4\nμ\no\n»\n¿\nμ\na\n\nO\nμ\n¿\no\n\n»\n·\n\no\n\nμ\n1⁄4\n·\n\na\n\nμ\n1⁄4\n¿\na\n\na\n3⁄4\n·\n·\n\n·\n\na\n\nO\nμ\n\nμ\n3⁄4\n»\n»\n\n¿\n»\n\n3⁄4\n·\n\n·\n±\n\nμ\n·\n\n¿\nE\n3⁄4\n·\n\na\n\n±\ny\nU\n\n·\n·\n\n·\n\na\n\nμ\n\n¿\n\n3⁄4\n·\n\n¿\nμ\n\no\n3⁄4\n3⁄4\n\n·\n3⁄4\n\n·\n\n¿\n\nμ\n·\n\na\n\nμ\nE\n·\n3⁄4\n\nE\n\n·\no\nO\n\n·\nμ\n3⁄4\n\nμ\n\n»\n\n1⁄4\n\no\n\n¿\nμ\n¿\n\n·\n\n±\n@\nU\n$\nμ\n\n3⁄4\n·\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\nO\n\n·\n·\nμ\n¿\n·\n\n3⁄4\ne\n\n3⁄4\nμ\n3⁄4\n\n»\n·\n\n3⁄4\nμ\n\n·\nμ\n3⁄4\n·\n·\nμ\nO\n3⁄4\n\n·\no\n·\nμ\n\n$\n(\n\no\n1⁄4\n3⁄4\n»\n\n3⁄4\nμ\n\nE\n¢\ny\n\n·\n\n·\n3⁄4\n·\n\n¿\nμ\no\n}\n\n}\n¤\ny\n\ny\n{\n\nx\n\n}\n\nu\n\n£\n\n¤\nÞ\n\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n§\nE\n\n}\n¢\n\n¤\n}\n\nv\n\n}\ny\nx\n\n¥\n\nx\n\n}\n¤\n\nI\n¥\nx\n\ny\n\ny\n¥\n\nv\n}\ny\nU\nu\nÞ\nU\n$\n(\n\na\n¿\n\no\nμ\n¿\n·\n1⁄4\n\nμ\n·\n·\n±\n\nμ\na\n\n1⁄4\n3⁄4\n·\n\nμ\n¿\n\n¿\nμ\n·\n3⁄4\n·\n\no\n1⁄4\n3⁄4\n»\n\n3⁄4\nμ\n\no\n3⁄4\nμ\na\n·\nμ\n\n¿\n\na\n¿\n\no\nμ\n¿\n·\nB\n3⁄4\nμ\na\n\no\nμ\n¿\n·\n\nμ\n¶\n·\n\nμ\na\n\na\n·\n¿\nE\n\nμ\n1⁄4\n\n3⁄4\no\n\nμ\n¿\n\n¿\nμ\n·\n3⁄4\n·\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n\nu\nx\n\nx\n\n}\n\nx\n\ny\n\n}\n¢\n}\n¤\ny\n\n¤\n}\n\n£\nx\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n§\nB\n\n}\n\n{\n¤\n\ny\n¢\ny\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\n\n¤\n}\n\nv\n\n£\nx\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n}\n\n£\n\nx\n\n¤\n¥\n\nU\nu\nR\nU\n$\n(\n\n»\n\n¿\n\na\n\no\nμ\n¿\n»\n\n¿\n·\n\n1⁄4\n·\n\n¿\nμ\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\nO\n\n·\nμ\nμ\n¿\nμ\n¿\n»\n\n3⁄4\n·\n\n¿\nμ\n3⁄4\n·\n·\n\n3⁄4\nμ\no\n»\n¿\nμ\na\n\no\n\nu\n:\nU\n\n1⁄4\n\n3⁄4\n\n·\n»\n\n¿\n\n3⁄4\nμ\n1⁄4\n\n·\n\n·\n3⁄4\n·\n\n¿\nμ\no\n1⁄4\n¿\nμ\no\n·\n\n3⁄4\n\nμ\n·\nμ\n\n3⁄4\nE\n¶\nμ\n\n·\n\na\n\n¿\n\n·\nμ\n\no\n1⁄4\n3⁄4\n»\n\n3⁄4\nμ\n\n·\nμ\n3⁄4\n·\n·\nμ\n\n\"\n\nE\nμ\n·\n1⁄4\n\nO\n1⁄4\n3⁄4\nμ\no\n3⁄4\n\n·\n±\n\nD\n\n1⁄4\n\n·\n\nμ\n\no\n»\n¿\nμ\no\n\n·\n¿\n3⁄4\n\no\n¿\n·\n\n·\n\n¿\nμ\n3⁄4\na\n\n¶\no\n¿\n\n±\n\n\\\n·\n\no\n»\n¿\no\no\n\n·\n\n¿\n\n·\nμ\n\no\n\n·\n\n·\n3⁄4\n·\n\n¿\nμ\no\n·\n¿\n»\n\n1⁄4\n·\n\na\n\n3⁄4\no\n\n1⁄4\n1⁄4\n\no\no\n\n·\n\no\n¿\n·\n\n·\n\n¿\nμ\n¿\n\n·\nμ\n\n1⁄4\n¿\nμ\n\"\n\n1⁄4\n·\n\nu\ny\nU\n$\n(\n\no\na\n\n»\n\nμ\na\n\nμ\n·\n¿\nμ\n·\nμ\n\n3⁄4\n1⁄4\n1⁄4\n\n3⁄4\n1⁄4\n±\n¿\n\n·\nμ\n\n·\nμ\n\n3⁄4\n·\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n]\no\n\n»\n¿\n\n·\n\na\n3⁄4\n·\n·\n\n·\n\na\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n3⁄4\no\no\n\n3⁄4\nμ\n1⁄4\n\n3⁄4\n±\n\na\n\nE\n\n3⁄4\na\n\na\n\n±\n\n¿\n\no\n\nμ\n\nμ\n·\n\na\n\n»\n\no\no\n\n3⁄4\n·\n·\n\n¶\n·\n\na\n\n3⁄4\no\n\n»\n¿\n\n·\n\na\n\n±\n·\nμ\n\n·\n\n3⁄4\nμ\no\n»\n¿\nμ\na\n\n¿\n\n·\nμ\n\nμ\n·\n\na\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\nh\nj\nj\n\nA\nA\nk\nE\nA\nU\n^\n$\nμ\n\no\n·\n\n·\n3⁄4\n·\n\n¿\nμ\nμ\n¿\n·\na\no\n\n¿\n\nD\n¶\n\no\n·\n\nμ\nE\n3⁄4\n\no\n»\n3⁄4\n1⁄4\n\nO\nμ\n\n3⁄4\nμ\n±\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\no\n\n»\n\no\n¶\no\n\n3⁄4\n·\n·\n\n·\n\no\n\n3⁄4\n·\nμ\n\n·\nμ\n3⁄4\nμ\nJ\n\no\n\n¿\n\n3⁄4\n\n¶\n1⁄4\n\n3⁄4\n\n·\n\nμ\no\n·\n3⁄4\n·\n·\nJ\n\no\n±\no\n·\n\no\nO\n\n·\nμ\nE\n\n3⁄4\n·\n\n3⁄4\n1⁄4\n1⁄4\n\n¶\n\n3⁄4\n1⁄4\n±\n·\nμ\n3⁄4\nμ\n1⁄4\n\nμ\n·\n»\n\no\no\n\n3⁄4\n·\n·\n\n·\n\no\n\n·\nμ\n\no\n·\n\n¶\n\n·\n3⁄4\n·\n\n¿\nμ\nO\n\n·\n·\n\na\n\n1⁄4\n\na\n¿\n\n·\n\nμ\n3⁄4\n·\n\na\n\nu\nx\n\nx\n\n}\n\nx\n\ny\n}\n\n}\ny\ny\n\nx\n}\n\nx\n\nv\nv\n}\nn\n}\n\ny\n\nv\n}\nn\n}\n\n}\n¥\ny\n}\n¤\n\n}\n\ny\n\nv\n}\n\n¥\n¤\n\n{\n¤\n\n¤\n¢\n\n¤\nx\n\nx\n\n}\n\n¤\n¤\n\nx\n\nv\n\ny\nx\n\n§\nt\nv\n¥\ny\n\nv\n\n¢\n\n{\n\ny\n\n}\n\n{\n\nx\ny\n¬\ny\n§\nB\n\n}\n\n{\n¤\n\nU\nu\n@\nU\n$\n(\n\nO\n\n·\n·\nμ\n¿\n·\n\no\no\n\n3⁄4\nμ\n3⁄4\na\n\no\n¿\n\n±\n\n·\n\no\n·\n\nμ\n\na\n¿\nμ\n¿\n\nμ\n3⁄4\n\n·\n\na\n·\n¿\n\no\no\n\no\n¿\n·\n\n·\n\n¿\nμ\n3⁄4\na\n\no\n¿\n\no\n\nμ\n·\nμ\n\na\na\n·\n\n¿\n\n3⁄4\n1⁄4\n¿\nμ\n\"\n\n1⁄4\n·\nB\na\n*\n$\n\n¶\nV\n\nP\nE\ne\n\nu\nw\nU\n\\\n\n¿\nμ\n·\n±\n¿\nμ\n\n¿\n\n·\nO\n¿\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\no\n$\n(\n\n,\n\n»\n»\n\na\nO\nμ\n\n·\n\n·\nμ\n\n¿\n·\nμ\n\nμ\n3⁄4\no\n¿\nμ\n·\n±\n\n$\n(\nf\nh\n\n3⁄4\n·\n·\n\n·\n\na\n\n¶\n\n»\n¿\n\n·\n\nμ\nE\n1⁄4\n3⁄4\n¶\n»\n3⁄4\n\n·\n\n·\n±\n\n·\nμ\n\n3⁄4\no\no\n\n3⁄4\nμ\n1⁄4\n\n¿\n\no\n3⁄4\n\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n\n3⁄4\n±\n\na\n\n1⁄4\n\na\nB\na\n*\n$\n\n¶\n\nE\n\n¥\n\nt\n±\nE\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nv\n\nv\n\ny\n\ny\n¢\ny\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\nv\n}\n£\n\n{\n\nx\n\ny\n\ny\nx\n\nv\n\n}\n¥\n¤\n\n}\n\n¥\n\nx\n\nv\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\n\nt\n±\nE\n\n§\nB\nx\n\n}\n¤\n¤\n¢\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\n\n}\n¢\n\n¤\n}\n\n{\n\n¤\n\ny\n\n¥\n\n}\n\nØ\ny\n\n}\n\n¥\n\nx\n\nv\n\ny\n¢\ny\n\ny\nx\n\n{\n\ny\ny\nN\n\n¤\n\n¤\n\n£\n\n¤\ny\n\nv\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nO\n§\nB\n\n}\n\n{\n¤\n\nt\n±\nE\nv\n}\ny\n}\nu\n\n£\n\n¤\nÞ\n{\n\n}\n\nx\n\nx\n\nI\n¥\nx\n\nv\n}\n\n¤\n\nv\n\nx\n\n¤\n¥\ny\nx\n\n}\ny\n\n¤\n\ny\n\n¥\n\nx\n\nx\n\nv\n\ny\n¢\ny\n\ny\nx\n\nx\n\nv\n\nv\n\nt\n±\nE\nk\na\na\nð\ne\næ\na\n÷\ne\nð\nc\ne\næ\ny\na\no\nø\nu\no\nu\nn\nð\n÷\næ\ne\nð\na\ne\na\nð\no\næ\nk\ni\ne\no\nð\ni\ni\nð\nn\nu\no\nu\na\n÷\ne\na\nð\nl\nð\ne\nð\ni\nø\nu\n_\ne\ni\ni\ne\ne\nc\nð\nð\ne\n÷\ne\ni\ni\na\na\na\nÞ\n:\n\nx\ny\n\n{\n\n}\n\nx\n\n¤\n¢\n§\nt\nv\n\n¤\n¤\n\nx\n\ny\n¢\ny\n\n¤\nx\n\nx\n\n}\n\nx\n\n¤\n}\n\ny\n\nv\nx\ny\ny\n\n¤\n\ny\n\n}\n\nx\n¤\nx\n\n¢\nU\nu\nx\nU\nm\no\n\n±\n·\nμ\n\n»\n\n·\n¿\n·\n¿\n\n·\nμ\n\no\n\n·\n\n¶\n·\n\no\n·\n\nμ\n1⁄4\n·\n\n¿\nμ\n\nμ\n\"\n\nE\nμ\n·\nO\n\n·\n·\n\nμ\nμ\n\n·\n$\n(\n\n¿\n»\n\n3⁄4\n·\n\n¿\nμ\n\n¿\n\n»\n·\n¿\n\no\n\n1⁄4\n¿\nμ\na\no\na\n\n»\n\nμ\na\n\nμ\nE\n\n»\n¿\nμ\n·\nμ\n\nμ\n\n¿\n\n·\n3⁄4\n\nE\n\n·\no\n\nμ\nE\n·\n\n3⁄4\n1⁄4\ne\n\na\n\n$\nμ\n\n$\n(\n·\n\n3⁄4\nμ\no\n»\n¿\nμ\na\n\nO\n\n·\n·\nμ\n¿\n·\n\nμ\n1⁄4\n·\n\n¿\nμ\na\n\nμ\nE\no\n¿\n\n»\n¿\n\n·\n\n¿\nμ\n¿\n\n·\nμ\n\no\n\n·\n\n¶\n·\n\no\n·\no\n\n,\n\nμ\n1⁄4\n\ny\n\nv\n\ny\n\ny\n¢\ny\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\n\nx\n¤\n¤\n\n}\n\nx\n\nv\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n\n£\n\n¤\ny\n\nv\n\n¥\ny\n\n¥\n\n}\n\nx\n\n§\n\nv\n\n}\ny\n\n}\n\n}\n£\nx\n\nx\n\ny\ny\n¢\ny\n\n¤\nx\n¬\n\nt\n±\nE\n\nv\nx\ny\ny\n{\n\nx\n\n}\n\nx\n\nx\n\n¤\n¥\n\ny\n\nv\n\nr\nx\n¤\n\nU\n{\n\n}\n\nx\n\ny\nN\nB\n¤\nx\n\nv\n\nO\n\n}\n\n¥\n}\n¤\n\n¤\n\n£\n\n¤\ny\n\n¥\n\nt\n±\nE\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n§\n±\n\n}\n\n{\n¤\n\nx\ny\ny\nv\n\nx\n\nv\n\ny\n\nx\n\n§\nF\n3⁄4\n·\n\n3⁄4\n·\n\n¿\nμ\n1⁄4\n\n·\n\n3⁄4\n}\n\n»\n\n¿\n\n·\n\no\n}\n\n¥\ny\n\ny\n\n¤\n£\n\nx\n\ny\n}\n\n}\n¤\ny\n}\n\ny\nx\n\ny\n\n}\nx\n\ny\n}\n\n¥\nx\n\ny\nx\n\nv\n\nx\n\ny\n}\n\n¤\n\n¤\n\n£\n\n¤\ny\n§\nt\nv\nx\ny\nx\n\n}\n\nx\n\nv\n}\ny\n\nx\n\n¤\n¥\n\nx\n\nv\n\nt\n±\nE\n\n}\n\n{\n¤\n\ny\n{\n\nx\n\n}\n\nx\n\n}\ny\n\n}\ny\n¥\n\n}\n\n¤\n\n¥\n\nv\n\nv\n\ny\n\nx\ny\nx\n\ny\n\n}\n\n¥\n\nx\n\nv\n\nt\n±\nE\n\ny\nx\n\n{\n\ny\ny\n§\nB\nx\n\n}\n¤\n¤\n¢\n\nu\n\n£\n\n¤\nÞ\n\n}\nx\n\ny\n\nv\n\n}\n\n}\n¤\n¢\ny\nx\ny\n\ny\n¥\n¤\n\ny\n\ny\n¢\ny\n\n¤\n\n£\n\n¤\nN\n\nO\n{\n\n{\n\nx\n\ny\ny\n¥\n\nv\n}\ny\ny\n}\n\n¢\n\ny\n\n¥\n\nx\n\n¢\n§\nB\n\nv\n\nt\n±\nE\ny\n{\n\nx\n\n}\n\nx\n\n}\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\nN\nx\n\n¤\n¥\n\nx\n\n}\n¥\n¤\n\n}\n\n}\n¤\n¢\ny\nx\ny\n}\n\n}\nx\n¤\n¥\n\ny\n}\n\nØ\n\ny\n}\n\n}\n¤\n¢\n\ny\nx\ny\nO\n\n}\ny\n{\n\n}\n\nx\ny\nx\n\n¤\n¥\n\n}\n\n¤\nx\n\n¬\n\nv\n\ny\n}\n\n¢\n\nx\n\nx\n\n}\n¤\n\ny\nx\n\ny\n\n}\nx\n\ny\n\nv\nx\ny\n¤\n\n£\n\n¤\n}\n\n¤\n\n¤\n\n£\n\n¤\n\ny\nx\n\nx\ny\nx\n\ny\n\n}\ny\n\nv\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n\n¢\ny\nx\ny\n§\nU\nv\n\n£\n\nv\n}\n\ny\n}\n\n}\n\nx\n\ny\n}\n\n¢\n\nx\n\nx\n\n}\n¤\ny\n¢\ny\n\ny\n\ny\n\n}\n\nN\n\n¥\n\nx\n\n£\n\n¤\n\n{\n\n¥\n\nx\n\n}\nx\n\n}\n\n}\n\n£\n\n¤\n¥\n\nx\n\nO\n\nv\n\ny\n}\n\n¢\n\nv\n\nv\n}\n\ny\n\n£\n}\n¤\n¥\n}\n\n§\nt\nv\nx\ny\n{\n\ny\ny\n\n}\n\nx\nz\n\n¥\n¤\n\n}\n\n{\n\ny\nx\n£\n\n§\nt\n¢\n{\n\n£\nx\n\nx\n\n¤\nx\n\n¬\ny\n\nv\n\n¥\n\nv\n\n¥\n\nv\n\n¤\n\n£\n\n¤\ny\n\nv\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nx\n\ny\nv\n\n¥\n¤\n\n}\ny\n¢\n\n}\ny\ny\n\ny\ny\n\nv\n\nv\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\nx\n\nx\ny\nx\n\n{\nx\n\n}\ny\n\n}\ny\n\nv\n\nx\n\nx\n\n}\n¤\ny\n}\n\n¢\n}\n\n}\n¤\n¢\ny\nx\ny\n\ny\n}\n\n¢\n\n¤\n}\n\ny\nx\n\ny\n\n}\nx\n\n§\n\ns\nI\ns\nI\n\nE\nj\nk\nÆ\nA\no\nÆ\nj\nE\np\nU\n\nl\nE\nU\np\nE\nA\nA\nÆ\nj\nt\nv\n\ny\n\n¤\n\n£\n\n¤\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n}\nx\n\ny\n\n±\no\n·\n\no\n\nE\nμ\n\nμ\n1⁄4\n\n»\n·\n\no\n\nv\n\n}\ny\nx\n\ny\n¢\ny\n\ny\nx\n\n}\n\ny\n\nx\n\nx\n\n}\n\nx\n\nx\n\n{\n\nx\n\nx\n{\n¤\n\ny\n\n}\n\nv\nx\n\n£\n\nv\n\nv\n}\n£\nx\n\ny\n{\n\nx\n\nx\n\nv\n\n{\n¤\n\n£\n\n¤\n§\nt\nv\n\nv\n\nx\nn\n\n}\n¤\n\nx\n\ny\nx\n\n}\n\n}\nx\n\n}\n¤\n¤\n\ny\n}\n\ny\n\n}\n\nx\n\n}\n\nv\n\n}\ny\nx\n\ny\n¢\ny\n\n{\n\nx\n\nx\n{\n¤\n\ny\n¥\n{\n\nv\nx\n\nv\n\nv\n\ny\nx\n\nx\ny\n{\n\nx\n\n}\n\n§\nB\n\nt\n±\nE\n\nv\nx\ny\n¤\n\n£\n\n¤\nx\n\n¤\n¥\n\ny\ny\n¥\n\nv\n\n}\n¤\n{\n\nx\n\nx\n{\n¤\n\ny\n}\ny\n\nv\n\n}\ny\nx\n\n·\n3⁄4\n\n{\n\nv\nx\n\nv\nx\ny\n\n¤\n}\n\n}\n¤\n¤\n\nv\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n}\n¤\n\nx\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\nU\nr\nq\nÞ\nU\nF\n3⁄4\n1⁄4\nμ\n$\n(\n\n¶\n\n,\n\n»\n»\n\na\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\no\no\n\n¿\n\nμ\na\n\na\n\n±\n3⁄4\n»\n\n¿\n·\n\n1⁄4\n·\n\na\n¿\n·\n\n¿\n\n3⁄4\n\no\n»\n3⁄4\n1⁄4\n\n$\nμ\n\n¿\n\nμ\na\n3⁄4\n\no\n¿\n\n·\nμ\n\no\n¿\n·\n\n3⁄4\n\no\nμ\n3⁄4\n»\n\na\n\n±\n·\nμ\n\n·\n3⁄4\n\n3⁄4\nμ\na\n\nX\n\n1⁄4\n\n¶\n·\n\n3⁄4\n\nr\nq\nÞ\n§\nÞ\nU\n$\n\nm\nG\n\\\nμ\n1⁄4\n¿\n·\n·\n\no\n\n¿\nμ\n3⁄4\n¿\n\na\n3⁄4\nμ\n1⁄4\n\n·\n\n¶\n·\n¿\n¶\nE\n¿\n·\n¿\n·\nμ\n\n1⁄4\n·\n¿\no\n\no\n·\n»\n¿\n\nμ\n·\n¿\n\n3⁄4\n»\n»\n\n¿\n3⁄4\n1⁄4\nμ\nB\n(\n\nE\n\no\n\n¿\n\n»\n¿\n\n·\n3⁄4\nμ\n·\n·\nμ\n3⁄4\nμ\na\n\no\n·\n3⁄4\nμ\n1⁄4\n\n¶\n·\n¿\n¶\nE\n¿\n·\n¿\n·\nμ\n\n(\n\n$\n3⁄4\n\no\n3⁄4\nμ\n3⁄4\n»\n»\n\n¿\nD\n\n3⁄4\n·\n\n¿\nμ\n¿\n\n·\nμ\n\n·\n\nμ\no\n\n1⁄4\n¶\n¿\nμ\na\no\n·\n¿\n(\n\n$\n3⁄4\n\n,\n\n3⁄4\n·\no\nO\n\n·\n\no\n·\nμ\n\no\n·\n3⁄4\nμ\n·\n\n3⁄4\nμ\nE\n\nμ\nμ\n\na\n\na\n\na\n\n±\n·\nμ\n\n1⁄4\n·\n¿\no\n\nμ\nE\no\n»\n\na\n\nμ\ne\nμ\n¿\n·\no\n\nr\nq\nÞ\n§\nR\nU\n\nX\n\nG\n\\\n\n·\nμ\n\n3⁄4\n·\n\n¿\n\n1⁄4\n·\n¿\no\n\no\n\n±\n·\n¿\nO\n\n3⁄4\n·\n3⁄4\n\nE\n\n·\n1⁄4\n¿\n\n·\na\no\n·\n\n»\n\nμ\n\n±\n1⁄4\n·\n¿\no\n\nO\n\n·\nμ\n¿\n\n·\n1⁄4\n\n¿\no\no\n¶\n\nμ\nE\n·\nμ\n\n·\n3⁄4\n\n¿\n\nμ\na\n3⁄4\n\no\n3⁄4\nμ\na\n·\n\nE\nE\n\nμ\nE\n3⁄4\nμ\n3⁄4\na\n¶\n\no\n¿\n\n±\n\n\\\nμ\n¿\n\na\n\n·\n¿\n»\n\n¿\n\na\n\n3⁄4\na\na\n\na\n»\n\n¿\n·\n\n1⁄4\n·\n\n¿\nμ\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n3⁄4\n»\n¿\no\no\n\n·\n\n3⁄4\nμ\n\n¿\n\no\n»\n\na\n1⁄4\nμ\n3⁄4\nμ\nE\n\n±\n\n·\nμ\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\n·\nμ\n\n·\n3⁄4\n\n¿\n\nμ\na\n3⁄4\n\no\n3⁄4\n\n¿\na\n¶\n\n1⁄2\n\na\nB\n1⁄4\n3⁄4\n·\n·\n\na\n\nX\n\nE\n\nX\n\n3⁄4\n\no\na\n\n»\n\nμ\na\n\nμ\nE\n¿\nμ\n¿\nO\nμ\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n]\no\n3⁄4\n·\n·\n\n·\n\na\n\nE\n\n$\n3⁄4\n\n·\n\nt\nv\n\n{\n\nx\n\nx\n{\n¤\n\ny\n}\n\n¤\nx\n\n¬\n\nv\n\n¤\n}\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\nI\n¥\nx\n\ny\n\ny\n\n}\nx\n\ny\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n\n¤\nx\n\nx\n\n}\n\nx\n\ny\n\n}\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\n}\ny\n\n¤\n¤\n}\ny\n¤\nx\n\n¬\n\n¤\n\n¤\n\n£\n\n¤\ny\n¢\ny\n\ny\nx\n\n}\n\n¥\n\n}\n\nx\n\n§\n±\ny\ny\n¥\n\n{\n\nx\n\ny\n¥\ny\n\nx\n\nv\n\n¥\n¤\n}\n\nx\n\nv\n\ny\nx\n\n{\n\nx\n\nx\n{\n¤\n\ny\n\n}\n¢\n}\n¤\ny\n\ny\n{\n\nx\n\n}\n\nv\nx\ny\n¤\n\n£\n\n¤\n§\nB\n\n}\n\n{\n¤\n\nv\n\nt\n±\nE\n\ny\nx\n\nv\n}\ny\n}\n\n¥\nx\n¤\n\nx\n\nx\n}\ny\n}\n\n}\nx\n\ny\n\n}\n\nx\n\n}\n\n£\nx\ny\n\nx\n\ny\n\nv\n}\n\n¥\n¤\n\ny\n¥\n¤\n\nx\n\nv\n\n}\nx\n\n}\n\ny\ny\nx\n\n{\n}\n\nv\ny\nN\n\n}\n¤\n¤\n\n3⁄4\n·\n·\n\n·\n\na\n\n1⁄4\n\n¿\no\no\n¶\n\nμ\nE\n3⁄4\na\n\no\n¿\n\no\nO\n§\nr\nq\n:\nw\n§\nR\nU\n\n3⁄4\no\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n3⁄4\n·\n·\n\n·\n\na\n\n1⁄4\n\n¿\no\no\n\nμ\nE\nf\n\no\n\no\n3⁄4\n·\no\n¿\n\no\n\na\n\nμ\no\n\n·\n\n3⁄4\n·\n\n¿\nμ\no\n\nμ\n¿\n·\n\nμ\nE\n\nμ\n·\n\na\n\n·\n\n·\n¶\n¿\nO\no\n3⁄4\n·\n·\n\n3⁄4\no\n·\nO\n\n·\n3⁄4\n\n¿\n\n¿\n\n·\n¿\nO\n·\nμ\n\n$\n(\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\n\\\nμ\no\n\n1⁄4\nμ\n3⁄4\no\n\n·\n\n3⁄4\n·\n\n¿\nμ\n\n3⁄4\nμ\n3⁄4\n·\n·\n\n·\n\na\n\n¶\n1⁄4\n\n¿\no\no\n\nμ\nE\n3⁄4\na\n\no\n¿\n\n±\n\no\na\n\na\n\n3⁄4\nμ\n\nμ\n·\n\na\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n·\nμ\n3⁄4\n·\n\no\n»\n\n¿\n?\n\n1⁄4\n·\n\na\n·\n¿\n1⁄4\n\n¿\no\no\n¿\nO\nμ\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n]\no\n3⁄4\n·\n·\n\n·\n\na\n\no\n\n¿\n\n·\nμ\n3⁄4\nμ\nO\n\n·\n3⁄4\nO\n3⁄4\n±\n\n·\n\n1⁄4\n3⁄4\n·\n·\n±\nN\ny\nz\n{\n|\n}\n~\n\n|\n\n~\n\n|\n\ne\n\nO\n§\nh\nj\nj\nb\nA\nA\nk\nE\nA\nU\n^\n\\\nμ\n\n¿\no\n·\n1⁄4\n3⁄4\no\n\no\n\n·\nμ\n\nμ\n·\n\na\n\nO\n\n·\n·\n\nE\n\nμ\n3⁄4\n·\n\n·\n¶\n¿\nO\n\n3⁄4\nμ\n\nO\nμ\n\nμ\n\n·\n\no\n\n¿\n\n·\nμ\n3⁄4\nμ\nO\n\n·\n3⁄4\nO\n3⁄4\n±\n3⁄4\nμ\na\no\n¿\no\nμ\n¿\n\n·\na\nμ\n3⁄4\n\n3⁄4\nE\n\n3⁄4\n·\n·\n±\n\na\n\n1⁄4\n\na\n\n·\n\n1⁄4\n3⁄4\n·\n\n3⁄4\n·\n\n±\n·\nμ\n\n·\n\n·\n\no\nO\n\n·\nμ\n\nμ\n\n·\n¿\n\n·\no\n3⁄4\n·\n·\n\n·\n\na\n\n1⁄4\n·\n\n3⁄4\n\n3⁄4\nμ\n1⁄4\n\nB\n·\nμ\n\n±\n\n·\nμ\n\nμ\n¿\n·\n\n,\n\nμ\nE\n3⁄4\nμ\nf\n\n·\n·\n\n·\no\n¿\nO\n\n¿\n\n·\nμ\n3⁄4\nμ\n\n·\n3⁄4\nO\n3⁄4\n±\n¿\n\n,\n\nμ\nE\n3⁄4\nμ\n¿\nμ\n¶\n1⁄4\n\n¿\no\no\n\nμ\nE\n3⁄4\na\n\no\n¿\n\n±\n\n¿\n\n·\n\n·\n¶\n¿\nO\no\n\nE\n\nμ\n3⁄4\n\n·\n\no\n1⁄4\n\n¿\no\no\n\na\n\n·\n\n¿\n\n·\nμ\n\nO\n\n¿\n¿\n·\n·\nμ\n\no\nμ\n¶\n¿\n·\na\n\no\n\n3⁄4\n1⁄4\nμ\n\na\nE\n\nt\nv\n\n}\n\n{\n¤\n\n}\n\n£\n\nx\n\n¤\n¥\n\ny\n}\n{\n\nx\n\nv\n\n{\n}\n\nv\n\n¤\n}\n\n¬\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\nN\nz\n{\n|\n}\n~\n\n|\n\n~\n\n|\nO\n\nv\n}\n\nx\n\ny\n\nv\n\ny\nx\n\n{\n\nx\n\nx\n{\n¤\n\n§\n±\ny\n}\n\nv\n\n}\n\n{\n¤\n\nv\n\n¢\n{\n\n¤\nx\n\n¬\ny\n\nv\n}\n\n}\n¢\n\n¥\n\nu\n\n£\n\n¤\nR\n}\n\nv\n\n¤\n\n£\n\n¤\ny\n}\n\n£\n\n}\n\n¤\n\nx\n\ny\nx\n\nv\n\n¤\n¤\n\nx\n\n§\nt\n±\nE\n\n}\n\n£\nx\ny\n\nx\n\ny\n\n}\n¢\n\nx\n\nv\nx\n\nx\n\n}\n¥\ny\n\n}\n\nx\n\n}\n\nI\n¥\n}\n\n¤\nx\n\n{\n\n}\n\nv\n\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\nx\n\n}\n\nv\nx\n\nv\nt\n±\nE\n\nx\ny\nx\n\ny\n\n}\n¤\n¤\n\n§\nt\nv\n\n¤\n¤\nx\ny\nx\n\n}\n£\n\nx\n\n}\n\n}\n\n¥\n£\n\ny\n{\n\ny\n\na\na\nð\ne\nð\nc\ne\na\n]\ne\ni\nn\na\n\\\nð\n÷\na\na\næ\n÷\nc\n]\ne\ni\ni\nð\nn\n\nc\ni\na\nð\nn\ne\næ\nn\nð\ne\nð\nc\n\\\na\n÷\nð\na\na\nð\ne\na\nð\nc\ne\nn\ne\na\na\næ\nc\na\nð\na\na\na\næ\ni\ni\nn\no\nð\na\na\na\ni\nð\nn\ne\ne\nc\na\nð\na\n_\nc\næ\n\\\n\nu\no\ne\næ\nu\nu\no\n_\nð\nð\ne\nc\nn\nð\ne\nð\n÷\nn\na\n÷\na\næ\n÷\ne\na\nð\na\nþ\no\no\ne\na\nc\n]\nc\ne\n_\ne\n\na\ne\ni\ne\na\ne\ni\nn\nð\nu\nÞ\ny\n\n}\ny\n}\n\n£\nx\ny\n\nx\n\ny\nN\n\n}\n¤\n¤\n\nq\n±\ny\n\nq\n\ny\n\n¤\n¥\n\nx\n\n±\n\n£\nx\ny\n\nx\n\ny\nO\n\n¢\nt\n±\nE\n\n}\ny\ny\n¥\n\n}\n\n}\nx\n\n}\n\nD\ny\n}\n\nx\n¤\nx\n\n¢\n\ny\n}\n\n¤\n¢\n}\n\nv\nx\n\n£\n\nv\n\n§\n\nx\n\nx\ny\n¤\nx\n¬\n\n¤\n¢\n\nv\n\n¢\n}\n\n¢\n\nv\n\n}\n{\n}\n\nx\n¤\nx\n\n¢\n\nv\n\n}\nx\n\n}\n\nv\n\nt\n±\nE\n\n¥\ny\n\n¬\n\nv\n}\n\ny\n\nx\n\n}\n\nv\n}\n\nx\n\ny\ny\n\n}\n\n¢\n}\n\nx\ny\ny\n¥\n\n}\n\n}\n¤\n\n}\n\nx\n£\n\n}\n\n£\nx\n\ny\n\n¢\n§\nt\nv\n\n{\n\n}\n\nv\n}\n\n}\n\nx\ny\n\nx\n\ny\n}\n\n{\n\n£\nx\n\nt\n±\nE\n\nv\n\n¥\n\nv\n\nv\n\n}\nx\n\n}\n\nx\n\n}\n\n§\n±\n\n}\n\n{\n¤\n\ny\nx\n\n{\n\nx\n\nx\n{\n¤\n\nN\n\n¤\n}\n\nv\nx\ny\n{\n\n¤\n\nO\n\n¥\n\nu\n\n£\n\n¤\n\nv\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nx\ny\nU\nr\nq\n:\nU\nh\n\n1⁄4\n3⁄4\n\no\n\n¿\n\n·\nμ\n\n·\n\n·\n\na\nμ\n\n¿\n\nμ\n»\n\n·\no\n·\n¿\n$\n(\n\n¿\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n»\n\n¿\n\n3⁄4\nμ\n1⁄4\n\nμ\nμ\n\n·\no\n\nμ\no\n¿\n\nμ\no\n·\n3⁄4\nμ\n1⁄4\n\no\nO\nμ\n\nμ\nμ\n\n·\n\nμ\nE\nf\n\no\nO\n¿\n\n·\na\n\n3⁄4\n»\n»\n\n¿\n»\n\n3⁄4\n·\n\n·\n\no\nμ\n¿\n·\n»\n¿\no\no\n\n·\n\n·\n¿\na\n¿\no\n¿\nB\n\nE\n\n\\\nμ\n·\nμ\n\no\n\n1⁄4\n3⁄4\no\n\no\n\n$\n(\n\n3⁄4\n±\n1⁄4\n¿\n\n3⁄4\nμ\na\n\n3⁄4\nμ\n\no\n·\nμ\n3⁄4\n·\n\n3⁄4\n±\no\n\nE\nμ\n\n1⁄2\n1⁄4\n3⁄4\nμ\n·\n·\n±\n\na\n\n1⁄4\n\no\n·\n3⁄4\n·\n·\n\n3⁄4\n\nE\n\nμ\no\n¿\n\no\n\n·\n·\n\nμ\no\n·\n3⁄4\n·\n·\nO\n3⁄4\n\nμ\n\nμ\nE\nB\n\n(\n\nE\n\n(\n¿\nμ\na\n\n·\n\n¿\nμ\no\nO\nμ\n\n·\nμ\n\no\n\n3⁄4\n±\n¿\n1⁄4\n1⁄4\n\nμ\n1⁄4\n·\n\na\n\n$\nμ\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\"\n\nE\nμ\n·\n\n3⁄4\nμ\n\n3⁄4\n·\n¿\n\n\"\n\nE\nμ\n·\n\n3⁄4\nμ\n\n3⁄4\n·\no\n\n»\n»\n·\n\nμ\n·\no\nμ\n¿\n\n·\na\n»\n\n¿\n\na\n\nμ\n\n¿\n\n3⁄4\n·\n\n¿\nμ\n1⁄4\n¿\nμ\n1⁄4\n\nμ\n\nμ\nE\n·\nμ\n\no\n3⁄4\no\n»\n\n1⁄4\n·\n¿\n\n$\n(\n\no\n¿\n·\nμ\n3⁄4\n·\n\"\n\nE\nμ\n·\n1⁄4\n\nO\no\n\n3⁄4\n±\n·\n3⁄4\ne\n\n3⁄4\n»\n»\n\n¿\n»\n\n3⁄4\n·\n\n3⁄4\n1⁄4\n·\n\n¿\nμ\nB\ny\n\n)\n\n·\n¿\n·\n»\n\n¿\n1⁄4\n\na\n\no\n¿\nμ\n\n·\n3⁄4\nμ\na\n\n1⁄4\n\n3⁄4\n\n·\n*\n·\n\nE\nμ\n·\n3⁄4\nμ\n\n3⁄4\n·\n¿\nμ\n\n·\nV\nE\n\nB\nx\n\n}\n¤\n¤\n¢\n\n{\n\nx\n\nx\n{\n¤\n\ny\n\n}\n¢\n\n}\n\nØ\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\n§\n±\ny\n\n}\n\n{\n¤\n\ny\nU\nr\nq\n\nU\n$\n\n3⁄4\na\n\n¿\nO\no\n\no\n·\n\n3⁄4\na\n\n·\nO\n\nμ\nμ\n\n1⁄4\n\no\no\n3⁄4\n\n±\n»\n\n¿\n·\n\n1⁄4\n¶\n·\n\n¿\nμ\nB\nJ\n\nE\n3⁄4\nμ\na\n\nμ\nμ\n\n1⁄4\n\no\no\n3⁄4\n\n±\n3⁄4\na\n\no\n¿\n\no\nB\n\n(\nP\nE\n\n$\nμ\n\no\n\no\n3⁄4\n1⁄4\n1⁄4\n¿\n\n»\n·\n\no\nμ\n\na\n\n±\n1⁄4\n¿\nμ\n·\n\n¿\n·\n·\n\nμ\nE\n·\nμ\n\no\n\nμ\no\n\n·\n\n·\n±\n·\n\n·\n\nO\nμ\n\n1⁄4\nμ\n1⁄4\n¿\nμ\n·\n\n¿\n·\no\n·\nμ\n\n·\n3⁄4\n\n3⁄4\nμ\na\n·\nμ\n\n¿\n\n·\nμ\n\na\n\nμ\n¶\no\n\n¿\nμ\no\n¿\n\n·\nμ\n\n»\n\n¿\n·\n\n1⁄4\n·\n\na\n3⁄4\n\no\n»\n3⁄4\n1⁄4\n\n3⁄4\n\n¿\n\nμ\na\n\n3⁄4\n1⁄4\nμ\n$\n(\n\n¶\n\n,\n\n»\n»\n\na\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n\n$\nμ\n\nE\n\n3⁄4\n·\n\n·\nμ\n\no\n\nμ\no\n\n·\n\n·\n±\n·\n\n·\n\n·\nμ\n\n¿\n\n»\n\n¿\n·\n\n1⁄4\n·\n\n¿\nμ\n\no\n»\n\n¿\n\na\n\na\n\n·\n·\nμ\n\nμ\n\nE\nμ\n\no\n·\nμ\n\nμ\n1⁄4\n\na\n\nμ\n1⁄4\n\n¿\n\nμ\nμ\n\n1⁄4\n\no\no\n3⁄4\n\n±\n3⁄4\n·\n\n·\no\n\nμ\no\n\n·\n\n·\n±\n·\n\n·\n\no\na\n\n·\n\nμ\n\na\n\n±\n\nr\nq\n:\nH\nU\n$\nμ\n\nμ\n\na\n·\n¿\n\nμ\nμ\n\n·\n\n¡\n¢\n£\n¥\nf\n\no\n\n1⁄4\n3⁄4\n\no\n\n¿\n\nμ\n3⁄4\na\n¶\n\n,\n\n3⁄4\n·\n\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n1⁄4\n·\n\n»\n\n¿\n\n3⁄4\nμ\n1⁄4\n\nO\n\n·\n·\n\nμ\n1⁄4\n\n3⁄4\no\n\n·\nμ\n\n·\n\ne\n\n·\n\nμ\n¿\n¿\na\n¿\n\n$\n(\n\n\\\n\\\nB\n3⁄4\nE\n\no\no\n\nμ\nE\n1⁄4\n\n¿\no\no\n\nμ\nE\n\n3⁄4\nμ\n\n¶\n\no\n\nO\nμ\n\n1⁄4\nμ\n\nμ\n·\n\nμ\n\nμ\n1⁄4\n\n3⁄4\no\n\no\n·\nμ\n\n»\n¿\no\no\n\n·\n\n·\n±\n·\nμ\n3⁄4\n·\n3⁄4\nμ\nf\n\n3⁄4\n±\n\n·\nμ\nO\n3⁄4\n\n·\n\na\n\n±\n·\nμ\n\nμ\n·\n\na\n\n3⁄4\nμ\n\nμ\nE\nB\n\n(\n¦\n\n*\n$\n\n¶\n\nP\n\nE\n\nB\n\nE\n1⁄4\n3⁄4\n\no\n\nμ\nE\n3⁄4\nμ\n\nμ\n1⁄4\n\n3⁄4\no\n\nμ\n§\n\n(c)\n\na\n§\nf\n\no\n3⁄4\n·\n·\n¿\nO\n3⁄4\n·\n·\n\n·\n\na\n\nB\n\n(\n«\n\nE\n\n3⁄4\nμ\na\nB\n1⁄4\nE\n»\n\n¿\n\na\n\nμ\nE\nμ\n¿\nf\n\no\n\n·\n¿\nO\n·\nμ\n\na\n\no\n1⁄4\n\nμ\na\n\nμ\nμ\n\n·\n·\n\n·\nB\n\n·\n3⁄4\n\n¿\n\nE\n\n¿\n\nμ\na\n·\n\n·\n¿\nμ\n·\n3⁄4\ne\n\n¿\nO\n3⁄4\nμ\na\n\n·\n3⁄4\n\n¿\n\nE\n\n¿\n\nμ\na\n·\n\n·\n¿\nμ\n3⁄4\n»\n»\n\n¿\n3⁄4\n1⁄4\nμ\nE\n\nP\ns\nI\ns\n¿\n\nA\nn\np\n(r)\ni\nA\nC\n\nÆ\nI\nn\n\nE\nA\nl\nt\n\nx\n\nx\n\n}\n\nv\n\nv\nx\n\n¤\n\n£\n\n¤\n\nh\n·\n3⁄4\n1⁄4\ne\n\n¿\nD\nh\n\nμ\n3⁄4\n\n¿\n\n¤\n\n£\n\n¤\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n\ny\n\n}\nx\n\nx\n\n}\n\nx\n\n}\n\nx\n¤\nx\n}\n\ny\n\n}\n\nx\n\ny\n§\n±\n\n£\n\nv\nx\ny\n¤\n\n£\n\n¤\n\n¥\n\nv\n\nv\n\nx\n\n}\n\nx\n\nx\n\n¤\n\n}\n\n}\n\n¢\n\nv\n\nx\ny\n\n¥\n\nx\n\ny\n¢\ny\n\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\nt\nv\n\nt\n¤\n}\n\n¬\n\nt\n\nv\n}\n£\nx\n\n¤\n}\n\nv\n\nv\n\n¤\n\ny\n¢\ny\n\n£\nx\n\n{\n\nx\n\ny\n{\n\nx\n\ny\n\nv\n\ny\n¢\ny\n\n{\n\ny\n}\n\nv\n\nx\n\nx\n\n}\n\ny\n\nx\n\n¤\n¥\n\nx\n\nv\n\nv\n¥\n\n}\n\n{\n\ny\nN\n\n{\n\n}\n\ny\nO\n§\nB\nx\n\n¥\n\ny\ny\nv\n\ny\n}\ny\n¢\ny\n\n¤\n\n£\n\n¤\n£\nx\n\nt\n±\nE\n\n}\n\nx\n\ny\n\n£\nx\n\n§\n\n}\n\nv\ny\n¢\ny\n\n{\n\nv\n}\n£\nx\n\n}\n¤\n\ny\n\nx\n{\n\nx\n\n}\n\n}\n\nv\nx\n\n}\n\nx\ny\n\nx\n\nv\n\n}\n¤\n\n}\n¢\n}\n¤\n\nv\n\nv\n\nx\nn\n\n}\n¤\n\nx\n\ny\nx\n\ny\n§\nt\nv\n\n£\nx\n\ny\n\nx\n{\n\nx\n\nx\n\n¤\n¥\n\ny\n\nv\n\n}\ny\ny\n¥\n\nv\n}\n£\nx\n\nv\n\n}\n¤\n\n{\n\ny\nN\ny\n¥\n\nv\n}\ny\n\nv\n\n}\n¤\n\nx\n\ny\n}\n\n}\n\ny\n{\n\ny\n\nt\n±\nE\nO\n\nx\n\n¤\n¥\n\nx\n\n{\n\nv\n}\n{\ny\n\n}\nx\n¤\n¥\n\nv\n}\n£\nx\n\n¥\n{\n\nv\nx\n\nv\n\nv\n\ny\ny\n\nv\n\ny\n¢\ny\n\ny\nx\n\nx\ny\n{\n\nx\n\n}\n\n}\n¤\n\nx\n\nv\n}\n\ny\n\nx\n{\n\nx\n\nv\n\nx\n\n}\n\ny\n\nv\n\nt\n±\nE\ny\n¢\ny\n\n}\n\nx\n\ny\n\n£\nx\n\n§\nB\nx\n\n¥\n\n@\ny\nv\n\ny\n{\n}\n\n}\ny\n\n}\n\n}\n\nv\nx\n\ny\n\nx\n{\n\nx\n\n}\n\n£\nx\n\n{\n\nx\n\nv\nx\ny\n\n}\ny\n\n}\n\n}\n¤\n\nx\n\n§\nq\n\nv\n}\n\nv\n\n¥\n\n}\n\nx\n\ny\n\n}\ny\n¢\ny\n\n}\n\n{\n¥\n\n¤\n¢\n}\n\n}\n\ny\n\n}\n\nx\n\n}\n\n}\n\ny\n\n}\n\n¢\n\nv\n\n£\n\nx\n\nv\n\n{\n¥\n\n{\n\ny\n\ny\n\nv\n\ny\n{\n\nx\n\n§\n\nv\nx\ny\n\n}\ny\n\nx\n\n¤\n¥\n\n}\ny\n\n£\nx\n\n}\n\n¢\n\n{\n\nv\n}\n\n}\ny\n}\n¤\n\n}\n\n¢\n\nv\n\n}\nx\n\n}\n\nx\n\nv\n\n}\nx\n\ny\n{\n}\n\n¤\ny\n¢\ny\n\n}\n\n}\ny\n\n¤\n¢\n\ny\nx\n\n¥\nx\n¤\n\n}\ny\n{\n}\n\nv\n\nt\n±\nE\n\nØ\n\n§\na\n\nx\n\n}\n¤\n\nv\nx\ny\n¤\n\n£\n\n¤\n\nv\n\nx\n\nv\n\n}\n\nv\n}\n\nx\n\nB\nx\n\n¥\n\ny\n\n{\n\ny\n\ny\n}\n\n¥\n\nx\n\n}\n\nx\n\n}\n\ny\n\ny\n\nx\n\nx\n\n}\nx\n¤\n§\n\n}\n\nv\n\nN\n\n{\n\nO\n}\n¤\ny\n\ny\n\n§\nU\nv\n}\n\nx\ny\nx\n\n¤\n¥\n\nx\n\nv\n\n{\n\ny\nx\n\nx\n\nv\n\n{\n\nx\n¤\n¤\n\n{\n\nv\n\nv\n\nv\n\n{\n\nx\ny\n{\n}\n\nv\n\n£\nx\n\n{\n}\n\nv\n\ny\n¢\ny\n\nx\n\ny\n\n¥\n\n§\nt\nv\n\n¤\n}\n\n¥\n}\n\n¥\ny\n\ny\n\nx\n\nv\n\n{\n\ny\n\n}\n¢\n}\n¤\ny\n\n£\n}\n\n¢\n§\n\n¥\ny\n\n}\ny\n\n}\n\n}\n\nv\nx\n\n¤\n}\n\n¥\n}\n\n}\n¤\n¤\n\nE\n{\n\nt\nq\n\nq\nu\nN\nE\n{\n\nx\n\n}\n\nx\n\nt\n\n¤\ny\n}\n\nq\n\nI\n¥\nx\n\ny\n\nv\n\n¤\n\n¢\n\nq\n\nI\n¥\nx\n\ny\nu\n}\n\n¥\n}\n\nO\n\nv\nx\n\nv\nx\ny\n}\ny\n¥\n\ny\ny\n\nv\n\n¤\n}\n\n¥\n}\n\nN\nq\nE\n\nu\nO\n¥\ny\n\nx\n\n¥\n\nz\n\nx\n}\n¤\nt\n±\nE\n\ny\n{\n\nx\n\n}\n\nx\n\nu\nF\nF\nq\ny\n<\n§\nB\nx\n\n¥\n\nw\ny\nv\n\ny\n{\n}\n\nv\n\nE\n{\n\nt\nq\n\nq\nu\n\ny\n\nx\n{\n\nx\n\nv\n\nv\n}\n£\nx\n\nv\n\n±\nE\nN\n\n¤\n¤\nx\ny\nx\n\n}\n£\n\nx\n\n}\n\ny\n¢\ny\n\nO\ny\n¥\n\n{\n\n§\nE\n{\n\nt\nq\n\nq\nu\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\nx\n\nv\n\n}\ny\nx\n¤\n¢\n\n}\n\n}\n\n¤\n\nx\n\nv\n\nx\n\nx\n\n¥\n\nx\n\ny\n\n¥\n\nx\n\n}\n\n}\n¤\n¤\n¢\n}\n\n}\n¤\n¢\nn\n}\n\n¤\n\nN\n\nv\n}\n£\n\n}\ny\n\n}\n\n}\n¤\n¢\ny\nx\ny\n\n¤\ny\n\nv\n}\n\n¬\n\nv\n\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nO\n§\n\nv\n}\n\nv\n\nv\n}\n£\nx\n\n}\n¤\n\ny\n\nx\n{\n\nx\n\ny\n}\n\nv\nx\ny\n¤\n\n£\n\n¤\n}\n\n{\n¥\n\n¤\n¢\n\n¤\n}\n\n¬\n\nU\nt\nv\n\n¢\n\ny\n\nx\n\nv\n\nx\n\n{\n¥\n\ny\n}\n\n¥\n\n{\n¥\n\ny\n\n}\n\nv\n\n{\n\n}\n\nv\n\nx\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\n¿\nμ\n·\n±\nx\n\ny\n\n}\n¤\n¤\n¢\n£\nx\ny\nx\n\n¤\n\n£\n}\n\nx\n}\n\n¤\n\ny\n\ny\n\n}\n\n}\n\nv\n\n}\n\nx\n\n}\n¤\n\n¥\n\nx\n\ny\n§\n±\n\n¢\n\nv\n\ny\n\n{\n\ny\nN\n\n{\n\nv\n\nv\n¥\n\n}\n\ny\n\n¥\n\ny\n\nO\n\n¥\n¤\n\nx\n\n{\n¤\n\nx\n\nv\n\nx\n\nv\n}\n\n}\n\ny\n\n}\n\nN\n}\n\nx\n\n}\n\ny\n\nv\n\nt\n±\nE\ny\n¥\n\n£\n\nx\n¤\n\n¤\n}\n\n¥\n\nx\n\ny\n}\n\nx\n\n{\n¤\n\n¥\ny\nx\n\n}\n\n}\n¤\n\n£\nx\n\ny\n\n¢\ny\n\n£\n\ny\nO\n§\n|\n\nx\ny\nx\n\ny\n}\n\n¥\n\n{\nv\n¢\ny\nx\n\n}\n¤\nx\n\n{\n¤\n\n}\n\nx\n\ny\n\n}\n\ny\nx\n\nx\n\n}\n¤\n£\n}\n\nx\n}\n\n¤\n\ny\n\n}\n\ny\n\n}\n\n¤\nx\n\nx\n\n¤\n\n£\n\n¤\ny\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n¤\n\nv\nx\ny\n\n§\nU\n\nv\n\nx\n\n}\n\nx\n\n}\n\nv\nx\ny\n¤\n\n£\n\n¤\n\nx\n\nv\n\nx\n\n¤\n¥\n\nx\n\nv\n\nI\n¥\nx\n\ny\ny\n¥\n\nv\n}\ny\n\ny\n\nx\n{\n\nx\n\n}\ny\n¬\ny\n}\n\n{\n\n}\n\nx\n\n}\n¤\n{\n\n¥\n\ny\n\nx\n\n}\n\nI\n¥\nx\n\ny\n\n}\n\nv\n\ny\n\nx\n\nI\n¥\nx\n\ny\n\nv\n\n¥\n\nx\n\n}\n¤\nx\n\n¢\n\ny\n\nx\n\nv\nx\ny\n¤\n\n£\n\n¤\n§\nU\n\nv\n}\n£\n\n£\n\n¤\n\n{\n\n}\n£\nx\ny\n¥\n}\n¤\n\n{\n\n}\n\n}\ny\n¬\n\n¤\nx\n\n¤\n}\n\n¥\n}\n\nv\n}\n\n}\n\n}\n\ny\n¤\n}\n\nE\n{\n\nt\nq\n\nq\nu\nÞ\n@\n\nAir Data\nComputer\nPressure\nAltimeter\nPilot\nMode Selector\nTCAS\nOWN AIRCRAFT\nGround Station\nRadio\nAltimeter\nDiscretes\nTransmitter\nMode-S\nTransponder\nA/C\nDisplays and\nAural Alerts\nAntennas\nIntruders\nB\nx\n\n¥\n\ny\nU\nE\n¢\ny\n\n£\nx\n\n{\n\nx\n\ny\nv\n\nx\n\nv\n\ny\n¢\ny\n\nx\n\n}\n\n{\n\n¤\n\n¢\n\nv\n\nt\n¤\n}\n\n¬\n\nt\n\nv\n}\n£\nx\n\n¤\n\n£\n\n¤\n\nv\n\nt\n±\nE\ny\n{\n\nx\n\n}\n\nx\n\n§\nÞ\nw\n\nALTIMETER\nRADIO\nOperating Normally\nMalfunction Undetected\nStuck on Single Value\nSending Random Values\nSending Max Value\nSending Zeros\nFailed Self-Test\nNot Sending Output\nMalfunction Detected\nB\nx\n\n¥\n\n@\nU\nr\n}\n\nv\n\nE\n{\n\nt\nq\n\nq\nu\n\ny\n\nx\n{\n\nx\n\n}\n\n£\nx\n\n{\n\nN\n}\n\n}\n\nx\n\n}\n¤\n\nx\n\nO\n§\n\n¤\nx\n\n}\nx\n¤\n¥\n\nv\n}\n£\nx\n\nx\ny\n\ny\n{\n\nx\n}\n¤\n¤\n¢\nx\n\n{\n\n}\n\ny\n}\n\n¢\n}\n\n}\n¤\n¢\ny\n\ny\n§\n\nv\nx\ny\n\n}\n\n{\n¤\n\nN\nÞ\nO\n\nv\n\n}\n¤\n\nx\n\n}\n¢\n\n{\n\n}\n\nx\n\n¤\n¢\n\nN\n\nO\nx\n\n}\n¢\nv\n}\n£\n\n}\nx\n¤\n\nx\n\n}\n\n}\n¢\n\nv\n}\n\nv\n\n}\nx\n¤\n¥\n\n}\n\n¢\nt\n±\nE\n\nN\nx\n§\n\n§\n\nx\n\n}\nx\n¤\ny\n}\ny\n\n¤\n\ny\n\n}\n\ny\n\ny\n}\ny\n\n}\n\n¥\ny\n\ny\ny\n}\n\nt\n±\nE\n\nx\n\nx\ny\n\ny\n\nx\n\n}\n\n¢\n\n¥\n\n{\n¥\n\n}\n\n}\n¤\n¤\nO\n\nN\n:\nO\n\nv\n\n}\n¤\n\n¥\n\nx\n\nx\n\nx\ny\n¥\n\n}\n\nx\n\ny\n\ny\n}\n\nx\n\n}\n\nx\n\n}\n¤\n\nx\n\n¥\n\n§\n}\n\nv\n¥\ny\n{\n\nx\n\ny\nx\n\n}\n\ny\nx\n\n¥\n¤\n}\n\nx\n\n}\n\n}\n\n}\n¤\n¢\ny\nx\ny\n\nv\n\nx\n\ny\n¢\ny\n\nx\n\n¤\n¥\n\nx\n\nv\n¥\n\n}\n\n{\n¥\n\nx\n\n}\n\nx\n\ny\nt\nu\nH\n<\n§\ns\nI\ns\no\nÆ\nj\nE\np\nU\n°\nÆ\nA\nl\nÆ\nj\nÆ\nU\nk\nn\nk\nE\nA\nU\nt\nv\n\n¤\n\ny\n\n¤\n\n£\n\n¤\ny\n\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n{\n\n£\nx\n\nv\n\nx\n\n}\n\nx\n\ny\ny\n}\n\n¢\n\n}\ny\n\n}\n\n¥\n\n{\n\ny\nx\n\n}\n\nx\n\n{\n¤\n\n}\n\nx\n\n§\nt\nv\n\n¥\n\nv\n¤\n\n£\n\n¤\n\no\n\nE\nμ\nf\n\n»\n\no\n\nμ\n·\n3⁄4\n·\n\n¿\nμ\n\n}\nx\n\ny\n\ny\nx\n\nx\n\n}\n\nx\n\n§\n\ny\n\nx\n¤\n¤\n\n{\n\nv\n\nv\n\nv\n\n{\n}\n\nx\n\n¥\n¤\n}\n\n¥\n\nx\n\nx\ny\n\nx\n\nx\n\n{\n¤\n\n¥\ny\nx\n\n}\n\n}\n¤\n\nx\n\nx\n\n}\n¤\n\n£\nx\n\ny\n\nv\n§\n\n}\n\n¢\n\n}\ny\n\nv\nx\ny\n¤\n\n£\n\n¤\nx\ny\n\nv\n\ny\n\n{\n¤\n}\n\nv\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nv\n\n¥\n¤\n\nx\n\n¤\n¥\n\nx\n\n}\n\nx\n\n}\n\n¥\n\nv\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\n¤\n\nx\n\n}\n¤\nx\n\n{\n¤\n\n}\n\nx\n\nv\n\n{\n\ny\n§\nB\n\n¥\n\nx\n\ny\nx\n\n{\n¤\n\nx\n\nx\n\n}\n¤\n\n{\n¥\n\ny\n\nv\n\n¥\n\nv\n¤\n\n£\n\n¤\n\nx\n\nv\n\n}\nx\n\nv\n\n¥\ny\n¥\n}\n¤\ny\n\n}\n\ny\nx\n\n¥\n\ny\n\nx\n\nx\n\nv\n\n}\nx\n\nx\n\n}\n\nx\n\nx\nØ\n\nv\n}\n\n}\n¤\n¤\n¢\ny\n{\n\nx\n\n§\n±\n\n}\nx\n\nv\nx\ny\n¤\n\n£\n\n¤\nx\ny\n¤\nx\n\n¬\n\nv\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n{\n\nx\n\n}\n\nx\n\n§\nt\nv\n\ny\nx\n\nx\n\nx\n\n}\n\nx\n\n}\n¢\n\n}\n¤\n¤\n\n{\n¤\n\n¤\n¢\n¤\nx\n\n¬\n\n}\n\n}\n\n}\n\n¤\n\n¥\n{\n\n}\n\nv\n\n¤\n\n£\n\n¤\ny\n}\n\n£\n\nv\n\n|\n\ny\nx\n\nq\n\n{\n\ny\n\n}\n\nx\n\n}\n\n{\n¤\n\ny\nx\n\nx\ny\nx\n\ny\n\n}\ny\n\n{\n\n}\n\nv\n\nx\ny\ny\n¥\n\ny\n¥\n\n¤\n}\n\nI\n¥\nx\n\ny\n\ny\n\n}\nx\n\ny\n\ny\n¥\n\nv\n}\ny\n\nv\n\n¥\ny\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\n{\nv\nx\n\ny\n{\n}\n\n¬\n}\n\n}\n¥\ny\n\nv\n\n{\n\n}\n\ny\n}\n\n}\n\nx\n¤\nx\n}\n\nx\n\nv\nx\n\nx\n\nx\ny\n\n}\ny\n¢\n\n¤\n\n}\n\n§\nE\n\nx\n\nv\n}\n\nv\n\ny\n\nx\n\ny\nx\n\ny\n}\n\nμ\n¿\n·\n¤\nx\n\n¬\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n{\n¥\n\n{\n\ny\n\nx\ny\nx\n\n{\n\n}\n\n¥\n\nx\n\ny\n\n}\n\n}\nx\n\n}\n\n}\n\n£\n\n¤\n¥\n\nx\n\n}\n\nx\n£\nx\n\nx\n\ny\n§\nt\nv\n\n¥\n\nv\n¤\n\n£\n\n¤\n\nv\n\n}\n\n{\n¤\n\nt\n±\nE\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\n{\n¤\n¢\n\n}\nx\n\ny\n\nv\n\nz\n\nx\n}\n¤\n{\ny\n\n¥\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n§\nt\n¥\n\nv\nx\ny\n¤\n\n£\n\n¤\n\nx\n\nv\n\n}\nx\n\nx\n\n}\n\nx\n\nx\nØ\n\nv\n}\n\n¥\ny\n¥\n}\n¤\n¤\n¢\nx\n\n¤\n¥\n\nx\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\nB\n\n}\n\n{\n¤\n\nE\n\n¤\n\n}\n¢\n\n§\n}\n¤\n§\nE\n\n¤\nH\nH\n<\n\ny\n\nx\n\nv\n\n{\n\n¤\n\nx\n\n¢\nx\n\n}\nx\n\nx\n\n¤\n\n}\n¤\nx\nn\n\n{\n¤\n}\n\ny\nN\n{\n¤\n}\n\ny\n\ny\n\nv\n\n}\ny\n\nx\n\nv\n{\nx\n\ny\ny\n{\n\n}\n\nv\n\n¥\n\nv\n\n¥\n\nv\n\ny\n\n}\n\nO\n§\nt\nv\n\n¢\n\n¥\ny\nx\n\n{\n\nx\n\ny\n\nv\n}\nx\n\nv\n\n{\nx\n\ny\n\nv\n\n¥\n\n}\n\nØ\n\nx\n£\n\n}\n{\n{\n\n}\n\nv\n\nx\n\nv\n\n{\n¥\n\nv\n\n{\n¤\n}\n\ny\n\nv\n\n}\n}\n\nv\n\nv\nx\n\nv\n\ny\nx\n\n{\n\ny\n\n}\n\nx\n\n¤\n\n£\n\n¤\n}\n\n{\n\nx\n\nv\n\n¤\n\n}\n¤\nx\nn\n\n{\nx\n\ny\nx\n\nv\n\n¤\n\n¤\n\n£\n\n¤\n\nr\nv\n¢\ny\nx\n\n}\n¤\n\n{\n\ny\n\n}\n\nx\n\n§\nt\nv\n\n{\n\n}\n\nx\n\n}\n¤\nx\n\n¢\n\nv\nx\ny\n}\n{\n{\n\n}\n\nv\n\n¥\n\ny\n\ny\n\nx\n\n§\nE\n\n¤\n\n}\n¢\n\n§\n}\n¤\n§\n}\n¤\ny\n\nv\n}\n\n£\nx\n\ny\nv\n}\n£\n\nx\nz\n\n¥\n¤\n\n¢\n\n£\nx\n\nx\n\n}\n\n¥\n\ny\n\n}\n\nx\n\nv\n}\n\nv\n}\ny\n\n{\n\nx\n\nx\nn\n\n§\nt\n\n}\ny\ny\nx\ny\n\nx\n\n£\nx\n\ny\n}\n\n}\n¤\n¬\n\nv\n\n¥\n\nv\ny\n\nv\n\n¥\n\n{\n\nx\n\nx\nn\n\ny\n\nx\n\ny\n\nx\n\nv\n\ny\nv\n\nx\n\nv\n\nv\n\n|\n\ny\nx\n\nq\n\n{\n\ny\n\n}\n\nx\n\n}\n¤\n\nx\n\nv\n\n}\n{\n{\nx\n\ny\n\nv\n\n}\n\n¥\n}\n¤\n\n{\n\nx\n\nx\nn\n\n}\n\nv\n\n¤\n\nx\n\n{\n¤\n\n}\n\nx\n\n¤\n\n£\n\n¤\n§\nt\nv\n\n{\n\ny\ny\nx\n\nx\n¤\nx\n\nx\n\ny\n\n¢\n{\n\ny\n\nx\n\n}\n\nx\n\n}\n\n{\n\nÞ\nx\n\nThreat\nINTRUDER.STATUS\nOther-Traffic\nProximate-Traffic\nPotential-Threat\nThreat\nA\nN\nD\nT\nF\nT\nT\nT\nF\nF\nT\nF\nT\nOR\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\nA threat is reclassified as other traffic if its altitude reporting\nhas been lost ( PR13) and either the bearing or range inputs are invalid;\nif its altitude reporting has been lost and both the range and bearing are\nvalid but neither the proximate nor potential threat classification criteria\nDescription:\nare satisfied; or the aircraft is on the ground\n( PR12).\nAlt-Reporting in-state\nOther-Aircraft\nin-state\nLost\nOn-Ground\nm-478\nProximate-Traffic-Condition\nPotential-Threat-Condition\nBearing-Valid\nRange-Valid\nOther-Traffic\nMapping to Level 4:\nMapping to Level 2:\nSection 7.1, Traffic-Advisory\nv-398\nm-498\nm-494\nPR29\nPR23,\nB\nx\n\n¥\n\nw\nU\nr\n}\n\n}\nE\n{\n\nt\nq\n\nq\nu\nt\n¤\n}\n\n¬\n\nt\n\nv\n}\n£\nx\n\n¤\n\n£\n\n¤\n\ny\n\nx\n{\n\nx\n\nv\n\nx\n\nx\n}\n\n}\n\nx\n\nv\n\ny\n\n}\n\n¥\ny\n\n}\n\nx\n\n¥\n\nN\nx\n\n¥\n\n{\n\n£\n\n¤\n¥\n\nO\n\nx\n\n¤\n}\n\n¤\n\n}\n\nv\n\n}\n\nx\n\ny\nx\n\ny\nx\n\n{\n¤\n¢\n}\ny\n\nv\n\n}\nz\n\n§\n\n¥\n\ny\n\n}\n\n¤\n}\ny\ny\nx\n\nx\n\n}\ny\nx\n\nx\n\n{\n\n}\n\n}\ny\n}\n\nv\n\n}\n\n}\n{\n\nx\n}\n¤\n\nv\n\n}\n\n{\n\nx\n\n}\n\n}\nz\n\n}\n\nv\n\n}\nz\n\n§\n\nv\n\n}\n\n{\n¤\n\nv\n\nx\n\nx\n\n}\n¬\nx\n\nv\n\n}\n\ny\nx\n\nx\n\ny\n\n}\n\n$\nμ\n\n3⁄4\n·\n\ny\n\n}\n\nX\n·\nμ\n\n$\n\n3⁄4\nR\n1⁄4\nx\ny\n\n{\n\ny\n\n¢\n}\n\n±\n|\nU\nq\n\n}\n\n¤\n\nv\nx\n\nv\n\n£\n}\n¤\n¥\n}\n\ny\n\nx\n\n}\n\n¢\n\nx\n\ny\n\n¤\n¥\n\ny\n\n£\n}\n¤\n¥\n}\n\ny\n\n§\n±\n\n¤\n¥\n\nx\ny\n\nx\n\n}\n¤\n¤\n\nx\n\ny\n\ny\n\nv\n}\n\nv\n}\n£\n\n}\n(r)\nt\n\n}\n\n}\n\n}\n¤\n¤\n\nx\n\ny\n\ny\n\nx\n\nv\n}\n\n(r)\nB\n\n}\n\nμ\n¡\n(c)\n\n§\nq\n\ny\n\n}\nx\n\nx\n\n}\n\n{\n\ny\n\n(r)\n\nD\n\n}\n\nx\n\nx\n\ny\n§\nt\nv\n\ny\n¥\n\ny\n\nx\n{\n\ny\n\nv\n\n¢\n{\n\n{\n\ny\ny\nx\n\nN\n\n§\n\n§\n\n¶\n\nx\n\n{\n¥\n\n£\n}\n\nx\n}\n\n¤\n\n·\n\n}\n\n|\n\n}\n\n¤\n\n}\n\n¥\n\nx\n\nO\n}\ny\n\n¤\n¤\n}\ny\n\nv\n\n{\n}\n\nx\n\nv\n\n¥\n\nv\nx\n\nv\n\nv\n\n{\n\ny\ny\nx\n\nx\ny\n\n§\n±\n\n}\n\nx\ny\ny\nx\n\n{\n¤\n¢\n}\n\n±\n|\nU\nq\n\n}\n\n¤\n\n¥\ny\n\nx\n\n{\n¤\n\n}\n\n}\n\ny\n\n}\n\nx\n\nv\n}\n\ny\nx\n\n{\n¤\nx\n\ny\n}\n\nv\n\n}\n\n¤\n\n§\nÞ\nH\n\ny\n\n}\n\nx\n\ny\n}\n\nv\nx\ny\n¤\n\n£\n\n¤\n\nv\n\nx\n\nv\nx\n\n}\n\nv\n¢\nx\ny\n\nv\n\ny\n¥\n\n¤\n\ny\n\n}\n\nv\n§\nU\n\nv\n\nx\n\n}\n\nx\n\n}\n\nv\nx\ny\n¤\n\n£\n\n¤\n\nx\n\nv\n\nx\n\n¤\n¥\n\nv\n}\n\n}\n\ny\nx\n\ny\n\nx\n{\n\nx\n\ny\n\nv\n\nv\n¥\n\n}\n\n{\n¥\n\nx\n\n}\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nv\n\n{\nx\n¤\n\n{\n\n}\n\nx\n\ny\nN\n\nx\n\nv\n\nO\n\n}\n\n¥\n}\n¤\n\n}\n\n£\n\nx\n\n}\n\nx\n\nI\n¥\nx\n\ny\n\nv\n\nI\n¥\nx\n\ny\n}\n\ny\nx\n\ny\n{\n\nx\n\nv\nx\ny\n¤\n\n£\n\n¤\n§\ns\nI\ns\n\nI\nE\nj\nE\np\nn\nA\n°\nÆ\nA\nl\nÆ\nj\nÆ\nU\nk\nn\nk\nE\nA\nU\nt\nv\n\n¤\n\ny\n\n¤\n\n£\n\n¤\nx\n\n¤\n¥\n\ny\n}\n\ny\n\nx\n{\n\nx\n\nv\n\n{\nv\n¢\ny\nx\n\n}\n¤\nx\n\n{\n¤\n\n}\n\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n}\n\n£\n\n§\n\nx\n\nv\n\nx\n\n¤\n¥\n\nv\n\ny\n\n}\n\nx\n\ny\n\n¤\n\nv\n}\n\n}\n\n}\ny\ny\n\n¤\n¢\nx\n\ny\n\n¥\n\nx\n\ny\n\n}\nx\n\nx\n\nI\n¥\nx\n\ny\nN\n{\n¤\n}\n\nO\n\n§\ns\nI\ns\no\nU\nC\nn\nA\nA\nA\nÆ\nt\n\nx\n¤\n¤\n¥\ny\n\n}\n\nv\nx\ny\n}\n{\n{\n\n}\n\nv\n\ny\n\n¥\n\n¥\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\ny\n\n}\n¤\n¤\n\n}\n\n{\n¤\n\nx\ny\n¥\ny\n\n¤\n}\n\n}\n\nx\n\ny\n\n¤\n¥\n\nx\n\n}\n\n£\nx\ny\n\nx\n\ny\n§\nt\n±\nE\ny\n\n¤\n\ny\n}\n\ny\n\n¤\n¥\n\nx\n\n}\n\n£\nx\ny\n\n¢\nN\n£\n\nx\n\n}\n¤\n\ny\n\n}\n{\n\n}\n\n¥\n£\n\nO\n}\n\n}\nx\n\ny\n\nv\n\n}\nx\n\n}\n\nv\n}\n\n}\n\ny\nx\n\n}\n\nv\n\n}\n\nv\n\n}\nx\n\n}\n\nv\nx\n\nv\n\nv\n\nt\n±\nE\ny\n¢\ny\n\ny\nx\n\ny\n§\n±\n\ny\n\n¤\n¥\n\nx\n\n}\n\n£\nx\ny\n\n¢\nN\nq\n±\nO\nv\n}\ny\n\nv\n}\ny\n\ny\n\nN\n¥\n{\n\n}\n\n}\n\nO\n}\n\n}\ny\n\nv\nN\n£\n\nx\n\n}\n¤\n\n}\n\nO\n\n}\n\nx\n\n}\n\n{\n\ny\nx\n\nx\n£\n\nN\n\n§\n\n§\n\n¡\n¢\n£\n¥\nO\n\n}\n\nx\n£\n\nN\n\n§\n\n§\n\n§\n1⁄4\na\n1⁄2\n\n¡\n¢\n£\n¥\nO\n§\n\nv\n\ny\n\n}\n\n£\n}\n¤\n¥\n}\n\nv\n\ny\n\ny\n\nv\n\ny\n\n}\n\n}\nx\n\ny\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\nv\n\n}\n\nv\n\nx\ny\n}\n{\n\n¥\n\n{\n¥\n\nv\n}\n\nx\ny\n\n}\n¤\n¤\n\n}\n(r)\n|\n\nD\n\n}\n\nt\n\ny\n\n§\n\nt\nv\n\ny\n\n}\n\nx\n\ny\n\n¤\n\nN\nu\n\n£\n\n¤\n@\nO\n\n¥\n¤\n\n}\nx\n\ny\n}\n\n¥\n\nx\n\n{\n¤\n\n}\n\nx\n\nx\ny\nx\n\ny\n}\n\n}\n¤\ny\n\n}\n{\n\nx\n\n¥\n{\n\nv\n\nu\n\n£\n\n¤\ny\n\ny\nx\n\n¥\n\n}\n\nx\n\n}\n\nv\n\n¥\n{\n\nv\n\nu\n\n£\n\n¤\n:\n\n¤\n}\n\n¬\n\ny\n\nx\n{\n\nx\n\nv\nx\ny\n\ny\n\ny\nv\n\nx\n\nB\nx\n\n¥\n\nx\n§\n\n¥\n\nv\n\n¤\n}\n\n¬\n\nN\nu\n\n£\n\n¤\n:\nO\n\ny\n\nx\n{\n\nx\n\nv\n\n|\n\n}\n\nt\n\ny\n\n¥\n¤\n\n¤\nx\n\n¬\n\nu\n\n£\n\n¤\n\n{\n¤\n}\n\n}\n\nx\n\ny\n\nv\n\nx\n\nv\n\ny\n\n}\n\nv\n\n}\ny\n\nv\nx\n\nN\n\nv\n¢\nO\n\nv\n\ny\nx\n\nv\n\ny\n\n§\nB\n\n}\n\n{\n¤\n\n¥\n\nu\n\n£\n\n¤\nt\n±\nE\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n}\nx\n\ny\n\nv\n\n¤\n¤\n\nx\n\nU\n\n°\n¿\n^\no\nA\nU\n3⁄4\nk\nU\nA\nn\nl\nÆ\nU\nÐ\nÆ\nj\nk\ns\nH\nμ\n\nμ\n$\n(\n\no\na\n\no\n»\n·\n3⁄4\n±\n\nμ\nE\n3⁄4\nμ\nf\n\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n¿\nμ\n\n·\nμ\n\n3⁄4\n·\n3⁄4\nμ\na\n·\nμ\n\nμ\n3⁄4\n·\n·\n\n»\n·\no\n·\n¿\n1⁄4\nμ\n¿\n¿\no\n\n3⁄4\no\n\nμ\no\n\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n3⁄4\no\n\n1⁄4\n¿\nμ\na\n·\nμ\n\n3⁄4\n·\n\n·\n\no\n¿\n\n·\n\nμ\na\n\no\n\n3⁄4\n\n·\n\n·\n¿\n1⁄4\nμ\n¿\n¿\no\n\n·\nμ\n\no\n3⁄4\n\no\n\nμ\no\n\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n\n·\n3⁄4\no\nO\n3⁄4\no\n1⁄4\nμ\n¿\no\n\nμ\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n·\nμ\n\n1⁄2\n\no\n·\n·\nμ\n\n3⁄4\n·\n\nμ\n\n·\nμ\n\no\no\n\nμ\no\n\no\nμ\n¿\n·\n¿\n»\n·\n\n3⁄4\n·\n\n¿\n\n·\nμ\n\nμ\n\nO\n·\nμ\n\n3⁄4\n·\n\nX\nμ\n\n3⁄4\na\n3⁄4\nμ\n·\n3⁄4\nE\n\no\na\n\no\n»\n·\n3⁄4\n±\n1⁄4\n¿\nμ\n·\n\n¶\nμ\n\n·\n±\nB\n\n(\nO\nE\n\nμ\n¿\n·\nμ\n\n3⁄4\na\n3⁄4\nμ\n·\n3⁄4\nE\n\no\n·\nμ\n3⁄4\n·\n·\nμ\n\n»\n\n·\n¿\n·\n\n3⁄4\n±\n\n3⁄4\nμ\n\n¿\n\no\nμ\n3⁄4\n\n»\n·\n±\n·\n¿\n\nμ\n1⁄4\n\n3⁄4\no\n\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n\n¿\n·\nμ\n·\nμ\n\n3⁄4\n·\no\n\n\\\n\n3⁄4\na\n\n3⁄4\n·\no\n\nμ\no\n\n3⁄4\na\n\no\n¿\n\n±\n\no\nE\n\nμ\n\no\n\n1⁄4\nμ\n3⁄4\no\n§\n1⁄4\na\n1⁄2\n\n¡\n¢\n£\n¥\nμ\na\n§\n§\n1⁄4\na\n1⁄2\n\n§\n\n(c)\n\na\n§\n\n3⁄4\n\n·\n\n1⁄4\n3⁄4\n·\n\n3⁄4\nμ\n\n·\n¿\n\nμ\n¶\n1⁄4\n\n3⁄4\no\n\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n¿\nμ\n\n·\nμ\n\n3⁄4\n·\n\na\n\n1⁄4\n\no\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n·\nμ\n\n¿\n·\nμ\n\n·\nμ\n\n3⁄4\n·\n\n$\nμ\n\n¿\no\n·\n\n»\n¿\n\n·\n3⁄4\nμ\n·\n3⁄4\na\n3⁄4\nμ\n·\n3⁄4\nE\n\nμ\n¿\nO\n\no\n·\n¿\n3⁄4\n¿\n\na\no\n3⁄4\n1⁄4\n¶\n\n1⁄2\n1⁄4\n\nμ\nE\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n\nμ\n3⁄4\n»\n»\n\n¿\n»\n\n3⁄4\n·\n\n·\n±\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n·\nμ\n\n1⁄2\n\no\n·\n·\nμ\n\n3⁄4\n·\n\nμ\n¿\n\na\n\n·\n¿\nE\n3⁄4\n\nμ\n3⁄4\n\n3⁄4\n\nE\n\nμ\n3⁄4\n·\n3⁄4\na\n3⁄4\nμ\n¶\n·\n3⁄4\nE\n\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n·\nμ\n\no\n\n1⁄4\n¿\nμ\na\n·\nμ\n\n3⁄4\n·\n\n$\nμ\n\na\n¿\nμ\n]\n·\n¶\n1⁄4\n3⁄4\n\n·\n\no\n·\na\n\n·\n\nμ\n\no\n·\nμ\n\n·\n3⁄4\n·\n\n3⁄4\na\n3⁄4\nμ\n·\n3⁄4\nE\n\no\n¿\n\n¿\n»\n·\n\nμ\nE\n·\nμ\n\no\n\nμ\no\n\n3⁄4\nE\n3⁄4\n\nμ\no\n·\n·\nμ\n\nμ\n\nO\n·\nμ\n\n3⁄4\n·\n\no\n\no\no\n\n·\n\n1⁄4\n·\n\nμ\nE\n·\nμ\n\no\n3⁄4\n\no\n\nμ\no\n\n¿\n\n¿\n·\nμ\n·\nμ\n\n3⁄4\n·\no\n\nH\nμ\n\nμ\n·\nμ\n\n¿\n\n¿\n\n·\nO\n\nE\nμ\no\n·\nμ\n\n·\n3⁄4\n·\n·\n\n·\nμ\n\n·\nμ\n\n3⁄4\n·\n\no\n1⁄4\n3⁄4\n·\n·\n\na\n3⁄4\na\n¿\n¶\n1⁄4\n3⁄4\n\n·\nμ\n\n3⁄4\n·\nA\n¿\n·\nμ\n¶\n\nO\n\no\n\n·\nμ\n\n·\nμ\n\n3⁄4\n·\n\no\n3⁄4\na\n¿\nμ\n]\n·\n¶\n1⁄4\n3⁄4\n\n·\nμ\n\n3⁄4\n·\n\nt\nv\nx\ny\nu\n\n£\n\n¤\n\ny\n\nx\n{\n\nx\n\nx\n\n¥\n\n{\n\nx\n\ny\n¥\n{\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\n}\n¤\ny\n\n}\nx\n\n}\nx\n\ny\n\n{\n}\n\n}\n\nx\n\n}\nx\n\n}\n\n}\n\ny\n\n}\nx\n\ny\nN\n\nv\ny\n}\n\n¢\n\n¤\n}\n\n}\n\ny\n}\n\n¢\n\n¤\n}\n\nO\n\nv\n\nv\nx\ny\n\n}\n\n}\n\nv\nx\n\n£\n\n§\nU\n\n¥\n\nv\nx\n¤\n\ny\n\n¥\n\nx\n\nv\n\nt\n±\nE\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nv\n}\n\nv\n}\n£\nx\n\n{\n\n£\nx\n\nv\n\ny\n\n¤\nx\n\n¬\ny\nx\n\nx\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\n\nv\n}\n\nx\n\ny\n\n¥\n\n}\n\n¢\n\nv\n\n¥\n\nx\n\n{\n¤\nx\n\n¢\n\nv\n\ny\nx\n\n}\n\ny\n\nv\n\ny\nx\n\n¥\n\n}\n\nx\n\n§\n×\n\ny\n\n}\n\nx\n\nv\n\ny\nx\n\nv\n\n|\n\nD\n\n}\n\nt\n\ny\n\n}\n¤\ny\n\nI\n¥\nx\n\ny\n¥\n\ny\n\n}\n\nx\n\nv\n\n{\n\ny\n\ny\n\ny\n\ny\n\n¤\n\nx\n\n}\n\n}\nx\n\n}\n\ny\n\n{\n}\n\n}\n\nx\n\nI\n¥\nx\n\ny\n\nv\n}\n\n}\n\n¥\ny\n\nx\n\nv\n\n¤\n}\n\n¬\n\ny\n\nx\n{\n\nx\n\nN\n}\n\nx\n\nv\n\nx\n\n{\n¤\n\n}\n\nx\n\nO\n\nv\n\n|\n\nD\n\n}\n\nt\n\ny\n\n{\n\n¥\n\n§\nB\n\n}\n\n{\n¤\n\nv\n\ny\n\n{\n}\n\n}\n\nx\n\n}\nx\n\n}\n\nx\n\nB\nx\n\n¥\n\nx\nx\ny\n\nx\n\ny\n\nμ\n¡\n¢\n£\n§\nt\nv\n\n{\n\nx\ny\n¥\ny\n\nx\n\nv\n\nu\n\n£\n\n¤\n:\n\n¥\n\n}\n\nx\n\n¥\n\nv\n\n}\n\nx\n\n}\n\nx\n\nv\nx\n\n¥\ny\nx\n\nv\n\n{\n\nx\ny\n\nx\n\nv\n\n}\ny\nx\n\nt\n±\nE\n\ny\nx\n\n{\n\nx\n\nx\n{\n¤\n\ny\n}\n\nu\n\n£\n\n¤\nU\n\n°\nI\n^\nh\nA\nA\nØ\ns\nμ\n¡\n¢\n£\n\no\n·\nμ\n\na\n\no\n\na\n¿\n\nA\n3⁄4\na\n\n¶\n,\n\n3⁄4\n·\n\nA\n3⁄4\n\n¿\n\nμ\n·\n¿\n\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n\n·\nO\n\nμ\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n·\nμ\n3⁄4\n·\n$\n(\n\no\na\n\no\n\nE\nμ\n\na\n·\n¿\n\n·\n\n$\nμ\n\no\n3⁄4\n\n¿\n\nμ\n·\n3⁄4\n\no\n\n¿\n\nV\n\n·\n¿\n¦\n\n·\n\na\n\n»\n\nμ\na\n\nμ\nE\n¿\nμ\n¿\nO\nμ\n3⁄4\n\n1⁄4\n\n3⁄4\n\n·\n]\no\n3⁄4\n·\n·\n\n·\n\na\n\nμ\n¡\n¢\n£\n\nμ\n1⁄4\n·\n\na\n\no\n3⁄4\n·\n·\n¿\nO\n3⁄4\nμ\n1⁄4\n\no\n·\n¿\n3⁄4\n1⁄4\n1⁄4\n¿\n\nμ\n·\n\n¿\n\nμ\n·\n\na\n\n3⁄4\nμ\na\n¿\nO\nμ\n3⁄4\n·\n·\n\n·\n\n±\n\n¿\n\no\n3⁄4\nμ\na\n\n·\n\n1⁄4\n3⁄4\n·\n·\n\n3⁄4\n1⁄4\ne\n\nμ\nE\n\nμ\n1⁄4\n\n·\n3⁄4\n\nμ\n·\n\no\n·\nμ\n3⁄4\n·\n3⁄4\nO\n\n1⁄4\n·\n·\n\n3⁄4\n1⁄4\ne\n»\n\n¿\n?\n\n1⁄4\n·\n\n¿\nμ\no\nB\no\n\nV\nf\n\nE\n\n$\nμ\n\n3⁄4\n·\n\n¿\n\nμ\n¡\n¢\n£\n\nμ\n1⁄4\n\n3⁄4\no\n\no\nO\n\n·\nμ\n3⁄4\n·\n·\n\n·\n\na\n\n·\n¿\n\n\"\n\n1⁄4\n·\n\nμ\n1⁄4\n\n3⁄4\no\n\na\n3⁄4\n·\n·\n\n·\n\n±\n\n¿\n\nB\n\n(\nV\n\nP\nE\n3⁄4\nμ\na\n·\nμ\n\nμ\n\na\n·\n¿\n\nμ\n¶\n1⁄4\n\n3⁄4\no\n\n·\n\n3⁄4\n1⁄4\ne\n\na\no\n\n»\n3⁄4\n\n3⁄4\n·\n\n¿\nμ\n3⁄4\n·\nμ\n\nE\nμ\n\n3⁄4\n·\n·\n\n·\n\na\n\no\n\nt\nv\n\n¤\n}\n\n¬\n\nv\n}\n£\nx\n\n}\n¤\ny\n{\n\nx\n\n}\n\nx\n\ny\nv\n\nx\n\nB\nx\n\n¥\n\nx\n}\n¤\ny\n\n{\n\nx\n\ny\n\nv\n\n¥\n¤\n\nv\n}\n\nx\n\n{\n¤\n\ny\n\nv\nx\ny\n\nI\n¥\nx\n\nv\n}\n£\nx\n\nx\n\nv\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nu\n\n£\n\n¤\ny\n§\nB\n\nt\n±\nE\n\n{\ny\n\n¥\n\n}\ny\n¥\ny\n\nv\n\ny\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n§\nB\nx\n\n¥\n\nH\ny\nv\n\ny\n\nv\n\n{\ny\n\n¥\n\n{\n\n£\nx\n\n¢\n\nt\nq\n\nv\n\n|\n\nD\n\n}\n\nt\n\ny\n\n§\nt\nv\n\ny\n\n¥\n\n¥\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nv\n}\ny\n}\n\n£\n}\n\n}\n\ny\nx\n\ny\n\n¤\n£\nx\n\n£\n}\n\nx\n\n¥\ny\ny\n\n}\n\nx\n\nx\n\n{\n\n¤\n\ny\n\ny\n¥\n\nv\n}\ny\n\nv\n}\n\nx\n\nI\n¥\nx\n\ny\n\n{\n\n}\n\n¥\n\ny\n\n}\n\nx\n\n}\nx\n\n}\nx\n\nx\n\n}\n\nv\n}\n\nx\n\n}\n\n£\n}\n¤\nx\n\n}\n\nx\n\n}\ny\n\nx\ny\n\n¥\ny\ny\n\nx\n\nv\n\ny\n\nx\n\n§\nÞ\n\n[\nPR1]\n[\nPR35\nSense.Dont-care-test\nPR1]\nAbbreviations:\nALIM = Positive-RA-Altitude-Limit-Threshold\nMacro: Don't-Care-Test(i)\nA\nN\nD\nin-state\nNew\nClimb\nDescend\nin-state\nin-state\nnot-in-same-state-as\nSome\nSome\nComment: The last two entries in the AND/OR table ensure that\nthere exists at least one other aircraft that is a threat and has\nselected a sense opposite that of the current aircraft, and that\nMapping to Level 4:\nMapping to Level 2:\nopposite (second choice) sense.\nthe modeled separation for that aircraft following a leveloff is\nworse than the modeled separation for the current aircraft in the\nOR\n.\n.\n.\n.\n.\n.\nF\nF\nF\nF\nT\nT\nT\nT\nT\nT\n.\n.\nT\nT\nF\nF\n.\n.\n.\n.\nT\nT\n.\n.\n.\n.\nT\nT\nT\nT\n.\n.\n.\n.\n(RELALT, TAUM, TRTRU, TVPE)\nTAUM = Min (Max (Modified-Tau-Capped\nTRTRU = True-tau-Capped\nTVPE = XTVPETBLX\nRELALT = Own-Tracked-Alt\n= TCAS-TA/RA\nAircraft(i).Capability\nAircraft(i).Status\nAircraft(i).Sense\nAircraft(i).Sense\nDown-Separation\nUp-Separation\nOwn-RA-Sense\nOwn-RA-Sense\nAircraft(j).Sense\nAircraft(i).Sense\nAircraft(j).Vertical-Miss-Distance\nv-392\nf-517\nf-542\n< Separation-Second-Choice(i) f-538\nf-543\nt-545\nf-529\nf-522\nf-542\nt-552\n< ALIM\n< ALIM\nDescend\nClimb\nin-state\nin-state\n[Alt-Layer-Value f-510 ]\n+ (4 s x Own-Tracked-Alt-Rate f-528\n, 10 s, True-Tau-Uncappedf-542 )\n[Other-Sensitivity-Level v-391]\n) - Other-Tracked-Altf-524\nClimb\nDescend\nUnknown\nClimb\nDescend\nNo RA\nAIRCRAFT(i).SENSE\nOWN-RA-SENSE\nEstablished\nNew\nAIRCRAFT(i).STATUS\nB\nx\n\n¥\n\nx\nU\nt\nv\nx\ny\n\n}\n\nx\ny\n¥\ny\n\nx\n\nv\n\nx\n\nv\nx\n\nv\n\ny\n\n¤\n¥\n\nx\n\n}\n\n£\nx\ny\n\n¢\n\nx\n¤\n¤\n\nv\n\ny\n\nv\n\n¥\n¤\n\nx\n{\n¤\n\n}\nx\n\n}\n\nN\n\nv\n\n}\n\ny\nO\n}\n\nx\n\n£\n\n¤\n£\n\n}\n\nv\n\ny\n\n{\n¤\nx\n\n}\n\n}\ny\n{\n\ny\n\nv\n\n¤\n¤\nx\ny\nx\n\n}\n£\n\nx\n\n}\n\n¤\n\nx\n\n§\n±\n\n£\nx\n}\n\nx\n\ny\n}\n\n¥\ny\n\nv\n}\n\n}\n\n}\n\nx\n¤\nx\n\n¢\n§\n\nm\n\nr\nq\nU\n\nE\nE\nE\n\ny\n\n§\n|\n\nD\n\n}\n\ny\n\nN\n\nO\nÆ\n\nC\n|\nE\n\n~\n\n~\n\n|\n\ne\n\nE\nE\nN\n\nO\nE\n{\n\n·\nI\nÆ\n~\n\nI\nI\nI\n\nÐ\n\nI\n\n|\n\ne\n\nE\nN\nU\nu\n\nv\n\n}\n\nO\n\nv\n\n}\n\nv\n\ny\n\nU\nu\n\n¢\nx\ny\nx\n\n{\n¥\n\n}\ny\n¬\nO\nN\nt\nB\n\nv\n\n}\n\nO\n\nv\n\n}\n\n}\n\nx\n\nx\n\n¤\n\n{\n\n¤\n\nO\n\nB\nN\n\nx\n\nv\n\ny\n\ny\n\n{\n\n£\nx\n\ny\n}\n\nI\n¥\n}\n\ny\n\n{\n}\n\n}\n\nx\n\nO\nt\nF\n\nE\n\nt\n|\n\nD\n\n}\n\n}\n\nU\nu\n\nv\n\n}\n\nu\nE\n\nu\n\n±\nq\n|\n\nD\n\n}\n\n}\n\nU\nu\n\nv\n\n}\n\nB\nN\n\ny\n\n¤\n¥\n\nx\n\n}\n\n£\nx\ny\n\nx\n\ny\ny\nv\n\n}\nr\n\ny\nx\n\nx\n£\n\nx\n\ny\n\nv\n\nx\n\ny\n\ny\n\nO\nt\nF\n\n}\n¤\n\n¥\n¤\n}\n\n}\n¤\n\nx\n\n¥\n\n¤\n¤\n\nx\n\n}\n¤\n\n£\n\n¤\n\nØ\n\nq\n\nr\n\n±\nt\nU\nF\n\nu\n\nN\n\nx\n\ny\nx\n\nv\n\n}\n\n¤\n\n±\n|\n\nD\n\n}\n\n}\n\nU\nu\n\nv\n\n}\n\ny\n\nO\n\nB\nN\n\ny\n\n¤\n¥\n\nx\n\n}\n\n}\nx\n\ny\n\nt\nB\n\nv\n\n}\n\ny\nv\n\ny\n}\nr\n\ny\nx\n\nx\n£\n\nx\n\ny\n}\n\ny\n\ny\n\n}\ny\ny\n\nv\n\nx\n\nU\nu\n\nv\n\n}\n\nO\nt\nF\n\n}\n¤\n\n¥\n¤\n}\n\n}\n¤\n\nx\n\n¥\n\n¤\n}\n\nx\n£\n\nt\nB\n\nv\n\n}\n\n}\n\nx\n\n¤\n\n£\n\n¤\n\nØ\n\nN\n\ny\n¥\n¤\n\nO\n\n}\n\nD\n\nU\nu\n\nv\n\n}\n\nO\n±\nu\nu\n£\n\nx\n\n}\n¤\n\nx\ny\ny\n\nx\ny\n\n}\n\n}\n¤\n\n¥\n¤\n}\n\nx\n\nN\n\n¤\n}\n¤\n\n¤\n£\n\n}\n\ny\n\n}\n\nx\n\nN\nU\nu\n\nv\n\n}\n\nO\n\nx\n\nN\nU\nu\n\nv\n\n}\n\nO\n\n¤\nx\n{\n\nx\n\nN\nU\nu\n\nv\n\n}\n\nO\nO\n\nB\nN\ny\n\n{\n\nx\n\nv\n¤\n\n£\n\n¤\n\nØ\n£\ny\n§\nt\nq\n\nv\n\n}\n\n¤\n\ny\ny\n\nv\n}\n\nv\n}\n\ny\n\nv\n\nx\n\n}\n\n¥\n£\n\n£\ny\n§\nU\nu\n\nv\n\n}\n\nO\nt\nF\n\nE\n\nt\n|\n\nD\n\n}\n\n}\n\nv\n\nU\nu\n\nv\n\n}\n\nN\n}\n¤\n¤\n\ny\n\nv\n\nx\n\ny\n\ny\n\nO\nE\n\n¤\n\nv\n\n}\n\n¤\n\n¢\n\n|\nq\n\nr\n\n±\nt\n\n|\n|\n\nD\n\n}\n\ny\n\nB\nx\n\n¥\n\nH\nU\nt\nv\n\n{\ny\n\n¥\n\nv\n\n|\n\nD\n\n}\n\nt\n\ny\n\n§\n)\nÞ\n\nO\ni\n&\n$\nA\n&\n$\n\nA\n\n\"\n$\n\nC\n&\n\n-\n\nC\nÆ\n$\n\nC\nÆ\n\nC\n\n$\nO\n\"\nÆ\nA\n×\n&\n\n&\nA\nA\nÆ\n\n&\nA\nÆ\nC\nE\n\nE\nA\nE\n\nC\nE\n\n&\n±\ny\ny\n\n}\n\n}\n\n¤\nx\n\n¥\n\n{\n\ny\n\n}\n\nx\n\ny\n\n{\n\n¤\n\ny\nv\n}\n£\n\n}\n\nx\n\n{\n\n}\n\nØ\n\n¥\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\n}\n\nx\n¤\nx\n\n¢\n}\n\nv\n\ny\n\n}\n\nx\n\ny\n\n¥\ny\n\n§\n±\n\n}\ny\nx\n\nv\n¢\n{\n\nv\n\ny\nx\ny\n\nv\nx\ny\n{\n}\n{\n\nx\ny\n\nv\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nx\n¤\n¤\ny\n¥\n{\n{\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nI\n¥\nx\n\n{\n\ny\n\n}\n\nx\n\nx\n\n}\ny\n¬\ny\n§\nt\nv\nx\ny\nv\n¢\n{\n\nv\n\ny\nx\ny\ny\n\ny\n{\n}\n\nx\n\n¥\n¤\n}\n\n¤\n¢\n\n¤\n\n£\n}\n\nx\n\nv\n\ny\n{\n\n}\ny\n¬\ny\nx\n\n£\n\n¤\n£\nx\n\n¥\n\n}\n\nx\n\n}\n\n{\n\n}\n\n¥\n\ny\n\n}\n\nx\n\ny\n\n}\n\nv\n\ny\nx\n\n£\n}\n¤\nx\n\n}\n\nx\n\ny\n}\n\n¢\n}\ny\ny\n¥\n\n}\n\n}\nx\n\n}\n\n}\n\n£\n\n¤\n¥\n\nx\n\n§\nU\n\nU\nU\n1⁄4\n\næ\n¤\nc\n\n£\næ\n£\nU\n\nU\n\næ\na\nY\n£\nU\n\nu\n\n¤\næ\n£\nU\nc\n£\nU\n¥\n\nx\ny\n\n·\n\n3⁄4\n·\n\nE\n\nH\nH\n<\n\nx\n\n}\n\n¤\n\ny\n\n¥\n\n¢\n\nv\n\nI\n¥\nx\n\ny\n}\n\ny\nx\n\n{\n\ny\ny\n\nÞ\nx\n¤\n}\n\ny\n¢\ny\n\ny\n§\nt\nv\n\n¢\n\n¥\n\nv\n}\n\ny\n¥\n\ny\n\n}\n\nx\n}\n¤\n\ny\nx\n\nØ\n\nx\n\n{\n\ny\n\n}\ny\ny\n{\n\nx\n\n}\n\nx\n\n}\n\n¥\n\ny\n\n}\n\nx\n\n}\n\nv\n\ny\n\n}\nØ\n\nv\n\nv\n\n}\n{\n{\n¤\nx\n\n}\n\nx\n\n}\nx\n\n}\n\nv\n\nv\n\ny\n¢\ny\n\ny\nv\n\n¥\n¤\n\n{\n\nx\n\nv\nx\n\nx\n\n§\nt\nv\n\ny\n\ny\n¥\n\ny\ny\n\n¥\n¤\n\ny\nx\n\ny\n¥\n\ny\n\nv\n\n}\n{\n{\n¤\nx\n\n}\n\nx\n\n}\nx\n\n}\n\n}\n\n{\n\n}\n\nx\n\nx\n\n¢\nx\n\n¥\n\ny\n\n}\n\nI\n¥\nx\n\ny\n\ny\n\n}\nx\n\ny\n\n{\n\nx\n\nx\n\nx\n\ny\n}\n\n}\n{\n{\nx\n\nv\n\ny\n\n}\n\nv\n\n{\n¥\n\n}\n\nx\n\n}\n¤\ny\n\n¥\n\n¥\n\ny\n§\nt\nv\nx\ny\nx\ny\n\n}\n\n¤\n¢\n\nv\n\nx\n\n}\n\nx\n\nv\n}\n\nx\ny\nx\n\n¤\n¥\n\nx\n\nv\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\nv\n\n}\n{\n{\nx\n\ny\n\nv\n\ny\n\n}\n\n§\nt\nv\n¥\ny\n¥\ny\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\ny\nv\n\n¥\n¤\n\nv\n\n¤\n{\n\nx\n\nv\n\n¥\n\n}\n\nx\n\nx\n\nv\n\ny\n\n¥\n\nx\n}\n¤\n}\ny\n{\n\ny\n\nv\n\ny\n¢\ny\n\ny\nx\n\nv\n\n£\n\n¤\n\n{\n\ny\n}\n\n}\nx\n\n}\nx\n\ny\n}\n\n}\n¥\n\nv\n\n}\n\nx\n¤\nx\n\nx\n\ny\n\nv\n\nx\n§\n\n§\n\nx\n\n}\ny\n\nv\n\nx\n\n¤\n¤\n\n¥\n}\n¤\n\n}\n\n}\n\n}\n\nx\n¤\nx\n\n¢\n\nv\n\n}\ny\n¬\n§\nU\n\n»\n\næ\n\nu\n»\n¤\n\næ\n¤\n\nU\nc\n\nx\n\n}\n\nq\n}\ny\n\n¥\ny\ny\n\nv\n}\n£\n\nv\n}\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\nx\n\ny\n\ny\n\n}\nx\n\ny\n\n}\n\nv\nx\n\n}\n¥\ny\n\n¥\n¤\n\n}\n¢\n\n¢\n{\n\n£\nx\n\nx\n\n}\n\n}\n\nx\n¤\nx\n\n¢\n\nv\n\nv\nx\n\nv\n\ny\n\n¤\n\n£\n\n¤\n\n}\n¤\ny\n\n}\n\ny\n\nx\n\n{\n¤\n\n}\n\nx\n\ny\n\nv\n\n{\n\ny\n\nq\nX\n<\n§\nt\n¢\ny\n\n}\n\nx\n\nv\n\ny\n\n}\n\nv\n}\n\n}\nv\nx\n\nv\n¤\n\n£\n\n¤\n\n}\n\ny\n\n}\n\nx\n\n}\n\nv\n\nx\n\nx\n\nv\nx\n\nv\n{\n}\n\nv\n\ny\n¢\ny\n\nx\ny\n\n¤\n\n£\n}\n\nv\n\n¥\n\n}\n¤\ny\n\nv\n\n¥\ny\n\n}\n\n}\n\nv\n\ny\n¥\n\nv\n\nv\nx\n\n}\n\nv\n¢\n\nv\n\n}\n¤\n\nx\n\ny\n\nU\nt\nv\n\n{\n}\n\ny\n\nv\n\ny\n¢\ny\n\n{\n\nx\n\nv\n\n¥\n\nx\n\nx\n\ny\n\n}\n\n}\ny\nx\n¤\n¢\n\nx\n\n§\nt\nv\nx\ny\n\n¢\n{\n\n(r)\nn\n\nx\n\nx\n\nv\n}\n£\nx\n\nv\n}\ny\n\ny\n\n£\n\nx\n\n}\n¤\n}\n\n¥\n\n{\ny\n¢\n\nv\n\n¤\n\nx\n\n}\n¤\ny\n\n¥\n\nx\n\ny\n\n{\n\n{\n\n¤\n\ny\n\n¤\n£\n\ny\n§\nq\n\ny\n\n}\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nv\n}\n£\nx\n\ny\nx\ny\n\n¤\n¢\ny\nv\n\ny\n\nv\n}\n\n{\n\ny\ny\n{\n\n}\n\n}\n\n}\n¤\n\nv\n\nx\n\nx\n\n}\n\n}\n¤\n¢\nn\nx\n\nv\n\n¥\n\nx\n\n}\n¤\ny\n\n¥\n\n¥\n\n}\n{\n\n¤\n\n}\n\n}\nv\nx\n\nv\n¤\n\n£\n\n¤\n\n}\n\ny\n\n}\n\nx\n\n}\n\nx\n\nx\n\n}\nx\n¤\ny\nt\nr\nH\nx\n\nt\nE\nÞ\n\na\nH\nH\n\nq\n}\ny\nH\nw\n\ny\nH\n@\n<\n§\nU\nx\n\nv\n\nv\n\nv\nx\n\n}\n\nv\nx\n\ny\n\nv\n\n¤\nx\n\n¬\ny\n\n¤\n\n£\n\n¤\ny\n}\n\ny\ny\n}\n\nx\n¤\n¢\n\n¤\n}\n\n}\n¤\ny\n§\nE\n\n}\n¤\n\nv\n\n¥\n\nv\nx\n\nx\ny\n{\n\ny\ny\nx\n\n¤\n\n¥\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n\n}\n\ny\n\n}\n\nx\n\nx\n\n}\ny\n\n}\n\n}\n\n{\n\ny\nx\n\nx\n\nv\nx\n\n}\n\nv\n¢\n\ny\n\n¤\n\n}\ny\n¥\n\ny\n¢\ny\n\nx\n\ny\n\n}\n\ny\n\n}\nx\n\ny\n\n}\n\nv\n\nv\n\ny\n¥\n\nv\n\nv\nx\n\n}\n\nv\n¢\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\n¥\n\ny\n¢\ny\n\ny\n\ny\ny\n}\n\nx\n¤\n¢\n\n}\nx\n\ny\n¢\ny\n\n{\n\ny\n\nv\n}\n\n}\n\n¤\n\n£\n}\n\nv\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\n\nv\n}\n\nv\n\n{\n\n¤\n\ny\n\n¤\n£\n\nx\ny\n\ny\nx\n\nx\n\n§\n×\n{\n\n}\n\ny\n\n}\n\nv\nx\n\nv\n\nv\nx\n\n}\n\nv\n¢\n\ny\n¥\n\nv\n}\ny\n\nv\n}\n\nI\n¥\nx\n\n¥\n\nx\n\nx\ny\n}\n¤\ny\n\ny\n¥\n{\n{\n\n¢\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\n\nx\n\n}\n\nq\n}\ny\n\n¥\ny\ny\n\n¤\n}\nx\n\nN\n}\n\nv\n}\n£\n\n{\n\nx\n\n}\n¤\n\n£\nx\n\ny\n¥\n{\n{\n\nO\n\nv\n}\n\nx\n\n{\n\n}\n\ny\n\n¤\n¢\n}\n\ny\nx\ny\n\n¤\n¢\n\nx\n}\n\ny\n\n}\n¥\n¤\n\ny\n\nv\n\n¢\n\n¥\ny\n\nv\n}\n£\n\n}\n\ny\ny\n\nv\nx\n\nv\n\n¥\n\nx\n\n}\n¤\nx\n\n}\n\nx\n\ny\nx\n\nv\nx\ny\nx\n\n}\n\nx\n\n{\n\n£\nx\n\ny\n}\n\n{\n\nx\n\nx\n\nv\n\nv\n\ny\n¢\ny\n\no\nμ\n¿\n\n·\na\n\n{\n\n}\n\nx\n\n§\nE\n\n}\n\ny\n\n}\n\n¤\n¢\n\ny\n\nx\n\n}\ny\n\ny\n\n}\n¥\n¤\n\ny\n\nx\n\nv\n\nv\n\nx\n\n{\n¥\n\n{\n\ny\n\n§\n±\n\nx\n\nx\n\n}\n¤\n¤\n¢\n\n}\n¥\ny\n\ny\n\nx\n\n{\n\n{\n\n¥\n\nx\n\nx\n\n{\n\n¥\n{\n\n}\ny\n{\n\ny\n\nv\n\nx\n\n{\n¤\n\n}\n\nx\n\n§\nt\nv\n¥\ny\n\nv\n\n¢\n}\n\n{\n¤\n}\nx\n\n¥\n{\n§\nt\nv\n\ny\n}\n\n}\n\n¥\n\ny\n\ny\n\n}\n{\n{\n¤\n¢\n\ny\n\n}\n\n¥\n\nx\n\n§\nt\nv\n\nx\ny\n\n£\nx\n\ny\n¥\n{\n\n{\n\nv\nx\ny\nv\n¢\n{\n\nv\n\ny\nx\ny\n§\n×\ny\nx\n\n{\n\n¤\n}\n\n}\n¤\n¢\ny\nx\ny\n\ny\ny\n\n¢\n\n¥\n\nv\n}\n\nv\n\ny\n\ny\n¥\n\ny\ny\n\n¥\n¤\n\n¥\n\ny\nv\n}\n\n}\n(r)\ny\n¢\ny\n\n£\nx\n\nv\n\ny\n\n}\n\ny\nH\n@\n<\n§\ns\nI\ns\nA\no\nÆ\nj\nE\np\nU\nA\nl\nE\nk\nÆ\nl\nE\nn\nn\nU\nU\nU\n\nn\nA\n\nn\nk\nE\nA\nU\n±\n\nx\n\ny\n\nx\n\nx\n\n{\n¤\nx\n\n}\n\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\ny\n\nv\n\nx\n\n{\n\nx\n}\n¤\n\nØ\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\nx\n\n§\nE\n¥\n\nv\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nx\n\nv\n\n¤\n¢\n\n¥\ny\n\n¥\n\ny\n\n}\n\n}\n\n£\n}\n¤\nx\n\n}\n\ny\nx\n\ny\n\n¥\n\n}\n¤\ny\n\n¥\nx\n\nv\n\n§\n±\n\n}\n\n{\n¤\n\n}\n\ny\nx\n\nx\n\nx\n\n}\n{\n{\n\n{\n\nx\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nx\n\nv\n\nx\n\nx\n\nx\nn\n\nv\n\n¥\n\n}\n\n¢\n\n}\n{\n{\nx\n\ny\n\n¤\n\n£\n\n¤\ny\nx\n\ny\n\n}\nx\n\n}\n\ny\n\n}\n\nv\n}\n\n¤\nx\n\nx\n\nv\n\nØ\n\ny\n\nv\n}\n\ny\nx\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n¥\n{\n\nv\n\n¤\n\n¤\n\n£\n\n¤\ny\n§\n\nx\n\nx\n\nx\nn\nx\n\n}\n\n¢\n\n}\n\n¢\nN\n\n}\n\n¢\n\nO\n\n}\n{\n{\nx\n\ny\n\n¥\n¤\n\nx\n\n}\n\nx\n\nx\n\n}\ny\n\n}\n\nx\n£\nx\n\nx\n\ny\n\nv\n}\n\nI\n¥\nx\n\n¤\n¤\n\nx\n\n¥\n{\n\n}\n\n¤\nx\n\n¬\ny\n}\n\nx\n\nx\n\nx\nn\n\nv\n\ny\nx\n\nØ\n\ny\n\n¤\n\n¤\n\n£\n\n¤\n\nv\n}\n\ny\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\ny\ny\nx\ny\n\nx\n\nx\n\nx\n\n¢\nx\n\nx\n\n¤\n}\n\ny\n\n¥\n\n¥\n\n}\n¤\n\n{\n\nx\n\ny\nN\n\n}\n\n¢\n\n}\n\n¢\n\n}\n{\n\n{\nx\n\ny\n}\n\ny\ny\nv\nx\n\n}\n\nv\nx\n\n}\n¤\n¤\n\n£\n\n¤\ny\nO\n\n}\n¤\n¤\n\nx\n\nx\n\nx\nn\nx\n\nv\n\n¥\n\nx\n\ny\nx\n\n}\n\nv\n\n¢\n\n¤\n}\n\nx\n\n¢\n\nv\n\n}\n\nØ\ny\n\nx\n\n}\n\nx\n\nx\n\n}\n¤\ny\n§\nE\n\n}\n\nx\n\nx\n\n}\n\n{\n\ny\n\n¥\n{\n¤\nx\n\n¥\n¤\n\ny\nv\n}\n£\n\n¤\nx\n\nx\n\n{\n\nx\n\n}\n\nx\n¤\n¢\n\nv\n\ny\nx\n\n¤\n\n£\n\n¤\n§\nr\n\nv\n}\n{\ny\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n}\n\n{\n\n£\nx\n\n}\n¥\ny\n}\n\n¤\n\nx\n\nx\n\n¥\n{\n¤\nx\n\nx\n\nv\n\ny\n{\n\n{\n\n{\n\nx\n\ny\n}\n\n}\ny\n\ny\nx\ny\n\nx\n\n}\n¬\nx\n\ny\nx\n\n}\n\nØ\ny\n\n£\n}\n\nx\n\n¥\ny\n\n¢\n{\n\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\n¥\n{\n¤\nx\n\n§\nX\nX\n\nU\n\nÞ\nc\n£\nc\na\nc\nß\nc\n£\nU\n¤\nu\n\nU\na\n\n¤\n\na\na\n\na\n1⁄4\nc\n\nu\na\n\n£\n¤\n\n¡\nu\næ\n£\nU\n\nF\n\n{\n\n¥\n¤\n¤\n¢\n\nv\n\nv\nx\n\nv\n\ny\n\n¤\n\n£\n\n¤\ny\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\nx\n¤\n¤\n\nv\n}\n\n¥\n\ny\n\nx\n\ny\n\nv\n\n¢\n\ny\n{\n\nx\n}\n¤\n¤\n¢\n\n¥\n\nx\n\n£\n\n¤\n\n{\n\n}\ny\ny\n¢\ny\n\nI\n¥\nx\n\ny\n\n¥\n\ny\n\n§\nB\n¥\n\nx\n\n}\n¤\n}\n\nx\n\n}\ny\n{\n\ny\n}\n\n{\n\ny\n\nv\n\n¥\n\nv\n\n¥\n\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n¥\n\nx\n\nx\n\n}\ny\nx\n\n¤\n¢\n}\n\ny\n\n}\n\n}\n\n¤\n\n}\n¤\n\ny\n}\n\nv\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n§\nt\nv\n\nv\nx\n\nv\n\ny\n\n¤\n\n£\n\n¤\ny\n\n{\n\ny\n\ny\n\n}\n\n¤\n\ny\nx\n\n}\n¤\ny\n\nv\n}\n\n}\n\n¤\n\ny\ny\n¤\nx\n¬\n\n¤\n¢\n\nv\n}\n\nN\ny\n¥\n\nv\n}\ny\n\nx\n\n{\n\nx\n}\n¤\n\nv\n\n}\n\ny\nx\n\nt\n±\nE\nO\n\n¥\n\nv\n\nv\n\n¢\n\nv\n\n¢\nv\n}\n£\n\nv\n\ny\n\nx\n\n{\n\n}\n\nN\n}\n\ny\n\n¤\n¢\nO\n\n{\n\n¥\ny\ny\nx\n\ny\n\nv\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\nx\n\n}\n\n£\n\n¤\n\n{\n\n}\n\nv\n\n¢\n\n}\n¢\n\nI\n¥\nx\n\n}\n\n}\n¤\n¢\n\ny\nx\ny\n}\n\nv\n}\n\ny\n}\n\n}\n¤\n¤\n\nv\n\n¤\n\n¤\n\n£\n\n¤\ny\n§\nU\n\n}\n\n¤\n\nx\n\nv\n\n{\n\nx\n}\n¤\n\nØ\n\ny\n\nv\n}\n\ny\n}\n\n{\n\n}\n\nx\n£\n\n¤\n¢\n\ny\nx\n\nx\n\nx\n\nx\nn\n\nv\n\n§\nq\n\n£\n\ny\n}\n¤\ny\nx\n\nt\n±\nE\n}\n\n}\n\n}\n\n{\n¤\n\nv\nx\ny\n§\n±\n\n¥\n\n¥\n\n¢\n\n}\n\ny\n}\n\nv\n\nx\n\nx\n\n}\n¤\nt\n±\nE\ny\n{\n\nx\n\n}\n\nx\n\n}\ny\n\nx\n\n{\n\ny\n\nx\ny\n\n£\n\nv\n}\n\nx\n\nx\n\n}\n\nI\n¥\n}\n\n¤\n¢\n\n£\n\nI\n¥\nx\n\ny\nx\n\n£\n\n¤\n£\nx\n\nv\n\n}\ny\n\nv\n\nv\n\n{\nx\n¤\n\n}\n\nx\n\n¥\n\n}\nx\n\n}\n\ny\n\n¤\n¤\n\nv\nx\ny\n\nv\n\nt\n±\nE\n}\n\n£\nx\ny\n\n¢\n}\n\nv\n¥\ny\nt\n±\nE\n\n¥\ny\n\nv\n}\n\nv\n\n}\n\n£\nx\ny\n\n¢\n\nx\n\ny\n\n{\nx\n¤\n\n§\nt\nv\nx\ny\n\nv\n}\n\nx\n\n}\ny\nx\n\nI\n¥\nx\n\ny\n\n}\n¥\ny\n\ny\nx\n£\n\nv\n}\n\ny\nx\n\nv\n\nt\n±\nE\n\ny\nx\n\ny\n\nv\nx\n\nv\nx\n\n¥\n\n}\n\nx\n\nx\n\n}\n¤\ny\n¥\n\n¤\n\n{\n\n¤\n\ny\n}\n\ny\n\nv\n}\n\n¬\n¢\n\n}\n\ny\n\nx\ny\n\n£\n\n}\n\nx\n\n¢\n§\n±\n\nx\n\nx\n{\n}\n\nx\n\n}\n\n¤\n¢\n\nv\n}\n\nv\n}\n\ny\n\nx\n¤\n¤\n\n¥\n\n}\n\ny\nx\n\nx\n\nx\n\nx\n\nx\nn\n\nv\n\nØ\n\ny\n\nv\n\ny\n\nv\n}\n\ny\nx\ny\n\nx\n\n¥\n¤\n\n}\n\nv\n\n{\n\n}\n¤\n\nx\n\ny\n\nx\n\n}\n\n}\n\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n\nx\n\n}\n¤\n¤\n¢\n{\n\n£\nx\n\nv\n\nx\n\nx\n¤\nx\n\n¢\n}\n\nx\n\n}\n\nx\n\ny\ny\n}\n\n¢\n\ny\nx\n\n}\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\n\nI\n¥\nx\n\ny\n\nv\n}\n\ny\n\nx\n\nv\n\n¥\n\nv\n}\n£\nx\n\n{\n\nx\n\n}\n\n¤\n¢\n\nv\nx\n\nv\n\nv\n}\n\ny\n\nx\n¤\n¤\n\n¥\n\nU\nt\nv\n\n}\n\ny\n\n}\n\nx\n\n}\n\ny\nx\n\n}\n\n}\ny\n\nx\n\nN\ny\n¢\ny\n\nI\n¥\nx\n\ny\nO\n\n}\n\nv\n\nv\n}\n\n{\n}\n\nv\n\n¤\n\n¤\n}\n\nx\n\ny\nv\nx\n{\ny\nN\n\nv\nx\n\nv\n}\n\nv\n\n¤\n\n}\ny\n\n¤\nx\n¬\n\n¤\n¢\n\nv\n}\n\nx\n\nv\n\ny\n{\n\nI\n¥\nx\n\n£\nx\n\nv\n}\n\ny\nO\n§\nU\n\na\ny\n\nc\nU\n£\n\na\na\n1⁄4\n£\nu\næ\nc\na\n\nc\n\n¤\nc\n\n£\n\nB\nx\n\n}\n¤\n¤\n¢\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n¢\n}\ny\ny\nx\ny\n\ny\n\n}\n\nx\n\ny\nx\n\ny\nx\n\nx\n\nØ\n\nx\n£\n\n}\n¥\n¤\n\n¤\n\n}\n\nv\n}\n\nx\ny\n\ny\n§\n|\n\nx\n\n¥\n\n}\n\nx\n\nx\n{\n}\n\n}\n¥\n¤\n\ny\n\n¥\n\nx\n\n¥\n\nx\n\nv\n}\ny\n\n¥\n\n¥\n\n}\n£\n\n¢\n\nx\nz\n\n¥\n¤\n\n{\n\n¤\n\n§\nB\n\n}\n\n{\n¤\n\nx\n\n¥\n\n{\nx\n\nx\n\n}\n¤\ny\n\n¥\n\nx\n\ny\n\n¥\n\nv\n}\n\n{\n\n}\n\ny\nv\n}\n\nx\nz\n\n¥\n¤\n\n¢\n\nx\n\nx\n\nØ\n\nx\n£\n\n}\ny\ny\n\nx\n\ny\n\nx\n\ny\nx\n\n¥\n\nx\n\ny\n\n}\n\nu\nE\nE\nm\n<\n§\n\nv\n}\n£\n\ny\n¥\n\ny\n\nv\n}\n\n¥\ny\nx\n\ny\n¥\n¤\n\ny\n\ny\n}\n\n¢\n}\n\n}\n¤\n¢\ny\n\ny\n\nx\n\nv\n\nv\n\n¤\n{\nx\n\nx\n\nx\n\nv\nx\n\nv\n}\ny\ny\n\nx\n\ny\n}\n\nI\n¥\nx\n\n}\n\nv\n\nv\n\ny\n\nx\n\n{\n\n}\n\ny\nu\n\n£\nÞ\n<\n§\nt\nv\n\nx\n\n}\n\nx\n\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n\nx\n\nx\n\nI\n¥\nx\n\ny\n\ny\nx\n\ny\n\n}\nx\n\ny\n\n}\n\nv\n}\nn\n}\n\n}\n\n}\n¤\n¢\ny\n\ny\n\nv\n\n¥\n\nv\n\nv\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\nx\n\n{\n\ny\ny\n\nv\n\ny\n\n}\n\n¥\n¤\n\nN\n}\n\n}\n\n¬\nO\n\nx\n\nv\n\n}\ny\ny\nx\ny\n\nx\n\nv\n\nx\n\nx\n\nx\n£\n\n}\n\n¥\ny\n\n¥\n¤\n}\ny\ny\n\nx\n\ny\n\n}\n¤\n£\nx\n\n¤\n}\n\nx\n\ny\n\ny\n¢\ny\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\n§\nU\n\nU\n»\næ\na\n\n¤\ne\nc\n\n1⁄4\n\næ\n£\n\n±\n\n{\n¤\n\ny\n}\n\n¢\n}\n\n}\n¤\n¢\ny\nx\ny\n}\n\nv\n\n¤\n\n¢\n\n¥\nx\n¤\n\nx\n\ny\n}\n\n¢\n\nx\n\nx\n\n}\n¤\ny\n¢\ny\n\ny\n\nI\n¥\nx\n\ny\nx\n\nx\n\n¢\nx\n\nv\n\ny\n¢\ny\n\n¤\n\n£\n\n¤\ny\n}\n\n¢\n\nI\n¥\nx\n\ny\n}\n\ny\n\n}\nx\n\ny\n}\n\nv\n\n}\n\nx\n\nv\n\nv\n\n{\n\ny\nu\n\n£\n@\n<\n§\n±\n\nv\n\ny\n}\n\n¢\n\nx\n\nx\n\n}\n¤\n\nv\n}\n£\nx\n\n}\n\nv\n\n{\n\nv\n}\ny\n\nx\n\nN\nx\n\n¤\n¥\n\nx\n\nv\n\nx\n\n{\n¤\nx\n\n}\n\nx\n\ny\n\nx\n\ny\n\nv\n}\n£\nx\n\nv\n\nv\n\n{\n\ny\nx\n\n}\n\nx\n\nv\n\n}\n\nv\n\nv\n\nO\n\n£\n\nx\n\n}\n\nx\n\nx\ny\n\nI\n¥\nx\n\nv\n}\n\nv\n\n{\n\ny\n\n£\nx\n\n¤\n}\n\nv\n\nx\n\nx\n\ny\n}\n\n¢\n\n¤\n}\n\nv\n}\n£\nx\n\n}\n¤\n\ny\n\n}\nx\n\ny\n§\n\n}\n\nx\n\nx\n\nv\n\n£\n\n}\n\n¢\n\nv\n}\n\nx\ny\n\n}\n\nv\n\ny\n¢\ny\n\nv\n\nx\n\n}\n\nx\n\nx\ny\n\n}\nx\n\nv\n}\n\nx\n\ny\n\nv\n\ny\n}\n\n¢\n\nv\n\ny\nx\n\nx\n\n¥\n\n£\n}\n¤\nx\n\n}\n\nx\n\nx\ny\n\nI\n¥\nx\n\ny\n¥\n\nv\n}\n\nv\n\nv\n}\n\ny\n\n}\n\ny\n¢\ny\n\ny\n}\n\n¢\n§\nt\n\n}\n¬\n\nv\nx\ny\n£\n\nx\n\n}\n\nx\n\nN\n}\n\n£\n\nx\n\n}\n\nx\n\nO\n\n}\ny\nx\n\ny\n}\n\n¢\n\nx\n\nx\n\n}\n¤\n{\n}\n\ny\n\nv\n\ny\n\n}\n\ny\nv\n\n¥\n¤\n\nx\ny\n\n¤\n}\n\n}\n\nx\n\nx\n\nx\nn\n\n§\nt\nv\nx\ny\n}\n\n}\n¤\n¢\ny\nx\ny\n\n}\n\n{\n\nz\n\nx\n\n¤\n¢\n¥\n\n¤\n\ny\ny\n\nv\n\ny\n\n}\n¬\nx\n\nx\ny\nx\n\ny\n}\n\n¥\n\nv\n}\n\ny\n}\n\nv\n\ny\n\n}\n\n¥\n\n}\n¤\n¤\n¢\n\n}\n¬\nx\n\nv\n\nv\n}\n\ny\n¬\n\nv\nx\n\nv\n{\n}\n\ny\n\nv\n\ny\n¢\ny\n\n}\nØ\n\n}\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\n}\n\n¢\n\ny\nx\n\ny\n\n}\nx\n\n§\nE\n{\n\nx\n\n}\n\nx\n\ny\n\nx\n\n¤\n¥\n\n}\n\nv\n\ny\nx\n\nx\ny\nx\n\ny\n\n¤\n}\n\n}\ny\nx\n\ny\n}\n\n¢\n\n¤\n}\n\ny\n¢\ny\n\n}\n¤\ny\n\ny\n\n}\nx\n\ny\n\n}\n\nv\n}\nn\n}\n\ny\nN\nx\n\n¤\n¥\n\nx\n\nv\n\n}\n¤\n\ny\nx\n\n{\n\nx\n\nx\n{\n¤\n\ny\n}\n\nx\n\nx\n}\n}\n\n}\nx\n¤\n\ny\nx\n\nx\ny\nx\n\ny\nO\n\nv\n\n}\ny\ny\n¥\n\n{\n\nx\n\ny\n¥\n\n¤\n¢\nx\n\nv\n\ny\n\nx\ny\nx\n\ny\n\n}\n\nv\n¢\n\nv\n\nx\ny\nx\n\ny\n\n}\n\n}\n\n{\n}\n\nx\n\n¥\n¤\n}\n\ny\nx\n\n}\n\n¥\n\ny\nx\n\n¤\n¥\n\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n{\n\n¥\n\nv\nx\ny\nx\n\n}\n\nx\n\n}\n\n{\n\n£\nx\n\nv\n\n}\n\nx\n¤\nx\n\n¢\n\n}\n\ny\nx\n\n}\n\n¥\n\ny\n¥\n{\n\n}\n\ny\n{\n\nx\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n¢\ny\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\n§\nU\n\ne\n»\n\na\n¤\ne\næ\n\nÞ\næ\nc\n£\n¤\n\n£\næ\n£\n\næ\n£\nU\nU\ni\n\nu\n1⁄4\nu\n¤\nc\n\n£\n±\n¤\n\nv\n\n¥\n\nv\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n{\n\n£\nx\n\ny\n¥\n{\n{\n\n}\n\n{\n\n}\n\nx\n\n}\n¤\n\ny\nx\n\n{\n\ny\ny\n\nv\n\n¢\n\n}\n¢\n\n£\n\nx\n\n{\n\n}\n\nv\n\n}\nx\n\n}\n\n}\n\n£\n\n¤\n¥\n\nx\n\n{\n\ny\ny\n\nv\n}\n\nv\n\nx\n\nx\n\n}\n¤\n\ny\nx\n\ny\n{\n\nx\n}\n¤\n¤\n¢\n\ny\n\n}\n¤\n¤\n\n¤\n\ny\ny\n\n{\n¤\n\ny\n¢\ny\n\ny\n§\nE\n\n}\n\n£\n\n¤\n¥\n\nx\n\nx\ny\n\nv\n}\n¤\n¤\n\nx\n\n}\n¥\ny\n\nx\n\nx\n\n£\n\n¤\n£\n\ny\n\n}\n\n¢\n\n{\n¤\n\nx\n\nx\n£\n\n{\n\ny\ny\n\ny\n\ny\n¥\n\nv\n}\ny\n¥\n\ny\n\n}\n\nx\n\nv\n\ny\n¢\ny\n\nD\ny\ny\n\n¥\n\n¥\n\n}\n\n¥\n\nx\n\n¥\n\ny\n\n}\n\nx\n\nv\n\n}\n\n¥\n\n}\n\nx\n\n}\n\nv\n\n}\n{\n{\nx\n\nv\n\n}\n\n¤\n\n}\n\nx\n\nx\n\ny\nx\ny\n\nx\n\ny\n}\n\ny\n\nv\n}\n\nI\n¥\nx\n\n{\n¤\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\ny\n\n}\n\nx\n\ny\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n{\n\n£\nx\n\nv\n\ny\n\n¥\n\n¥\n\nI\n¥\nx\n\nY\n:\n\nx\n\nv\n\ny\n\nx\n\n{\n\n}\n\ny\nx\n\n}\n\nx\n\n}\n¤\n\nx\n\n}\n\nx\n\nx\n§\n\n§\n\nv\n}\n\n¤\n}\n\nv\n\n{\n¥\n\n{\n\ny\n\n}\n\nx\n\nv\n\ny\n¢\ny\n\n}\n\n¤\n\n}\n\nx\n\nx\n\nv\n\n§\nt\nv\n\n¢\n\nv\n\n}\n\n}\ny\ny\nx\ny\n\nx\n\nv\n\ny\n\n}\n\nv\n}\n\n{\n\ny\ny\n§\nU\nv\nx\n¤\n\n¢\nx\n\n¥\nx\n¤\n\n}\n\n¤\n\nt\n±\nE\n\nx\ny\n\n£\n\nv\n}\n\nv\n\nx\n\nx\n\n}\n¤\n\n{\n\n¥\n}\n¤\n\n¤\n\nv\n\nt\n±\nE\ny\n¢\ny\n\ny\nx\n\nv\n}\n\n}\n\n£\n\nv\n\n¢\n\n}\n\ny\n}\ny\n\nv\n}\n\ny\n\n}\n\nv\n\n{\ny\n\n¥\n\ny\n{\n\ny\n\n¥\n\nI\n¥\nx\n\ny\n\n¥\n\ny\n\n}\n\nx\n\nv\n\n{\n\n¤\n\nx\n\ny\n\n¤\n£\n\nv\n}\n\ny\n\n£\n}\n\nx\n\n¥\ny\n¬\nx\n\ny\n\n}\n\ny\nx\n\n¥\n\n¥\n\nx\n\n{\n\n£\nx\n\n¥\ny\n\nv\n}\n\ny\n§\nt\nv\n\ny\n{\n\nx\n\nv\n}\n\ny\n\n}\n\ny\nx\n\n{\n¤\nx\n\nv\n\n{\n\ny\ny\n\n}\n¬\nx\n\nv\n\nv\n}\n\nx\n\nx\n\nx\nn\n\nv\n\n}\n\n¥\n\nv\n}\n\nv\n}\n\n¥\n\n{\n¤\nx\n\n}\n\n}\n\nv\n\nx\n\nx\n\n}\n¤\n\n¤\n§\n\nv\n}\n£\nx\n\n}\n\n¢\n\n¤\n\n}\n\n{\n\ny\n\n}\n\nx\n\nv\n\n¤\n}\n¤\ny\n\nx\n\n¥\n\nx\n\ny\n\n}\n\n}\n\nx\n\n£\n\nv\n\n¢\n\n}\n\ny\n\nv\n}\n\ny\n\nv\n\n{\ny\n\n¥\n\n§\nt\n¢\n\nv\n\nx\n\nx\n\n¥\nx\n¤\n\n}\n\n{\n\ny\n\n}\n\nx\n\nv\n\n¥\n\n¤\n¢\nx\n\n{\n\n¥\n}\n¤\n\n¤\n\n¥\n\nv\n}\n\nv\n\ny\n¢\ny\n\ny\nx\n\n}\ny\n¥\n\ny\ny\n}\n\nx\n¤\n¢\n\n{\n¤\n\n}\n\n¤\n}\n\n¬\n\n{\n\n¥\n}\n¤\n\nv\n\n¢\nx\n\n}\n\n¢\n\ny\n{\n\ny\n\n¥\n\nv\n}\n\n}\n\nv\n\nv\n}\n\n}\ny\n}\n\n¥\n}\n¤\n¤\n¢\n\n¢\nx\n\n}\nx\n\n}\n\n§\n\n¤\nx\n\n£\n\nv\n}\n\n}\n¬\n\nx\n\nv\n}\n\ny\n\nx\n\nv\n\n¥\n\nx\n\n¥\n\nx\n\ny\n\n¥\n\ny\ny\n}\n\nx\n¤\n¢\n\n{\n¤\nx\n\n}\n\nx\n\nv\n\ny\n¥\n¤\n\nx\n\n{\n\n¥\n}\n¤\n\n¤\n\n¥\n¤\n\nv\n}\n£\n\ny\nx\n\n{\n¤\nx\n\nx\n\nv\n\nt\n±\nE\ny\n\n}\nØ\nv\n}\n\nv\n}\n\n}\n\n¤\n}\n\n¬\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\nv\n\ny\n¢\ny\n\n§\n\n£\n\n¤\n¥\n\nx\n\nv\n\n{\ny\n\n¥\n\n¥\n¤\n\nv\n}\n£\n\nv\n}\n\n£\n\nx\n\nv\n\n}\nx\n\nx\n\n}\n\nx\n\nv\n}\n\ny\n{\n\nx\n\n}\n\nx\nn\n\nx\n\n}\n\n}\n¢\n\nv\n}\n\nx\n\n¥\n¤\n\n}\ny\nx\n¤\n¢\n\n¥\n\n}\n\n}\n\nv\n\n§\nt\n\n¤\ny\n\ny\n\n¥\n\n¥\n\nx\n\nv\n}\n£\n\n£\n\n¤\n\n{\n\n{\n\nx\n\nv\n\nv\nx\ny\n\n{\n\n¤\n\nx\n\n}\ny\nx\n\n{\n¤\n\nx\n\n¢\n}\n\n}\ny\nx\n\nv\n\n¢\n\n}\nx\n\n}\nx\n\na\n@\n<\n§\n×\ny\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nx\n¤\n¤\n\n¤\nx\n\nx\n\n}\n\nv\nx\ny\n\n¥\n\nv\n\n{\n\nx\n\nx\n¤\n¤\n\n¥\n\n¢\n{\n\n£\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n}\n\n}\ny\ny\nx\ny\n\nx\n\nv\n\n£\n\n¤\n¥\n\nx\n\n{\n\ny\ny\n}\n\nx\n\n{\n\n}\n\n}\ny\ny\nx\ny\n\nx\n\n¥\nx\n¤\n\nx\n\ny\n\n}\n\nv\n}\n\nx\ny\n\n}\ny\nx\n¤\n¢\n\n£\n\n¤\n£\n\n}\n\n}\nx\n\n}\nx\n\n§\nE\n¥\n\nv\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n¢\n}\n¤\n¤\n\n}\n\n¬\nx\n\n¥\n{\n}\n\n}\n¬\nx\n\nv\n}\n\ny\nx\n\n}\n\n}\n¢\n\nv\n}\n\nx\n¤\n¤\n\n}\n\nv\n\n¥\n\n¤\n¢\nx\n\n{\n\n¥\n}\n¤\n\n¤\n\n}\n¥\ny\n\nv\n\n¤\nx\ny\n\n{\n¤\nx\n\nx\n\n¤\n¢\n\ny\n\nx\n\n}\n\nx\n\ny\nx\n\n{\n¤\nx\n\n}\n\nx\n\ny\n\n}\n\n¤\n\n£\n\n¤\n\n¤\n\n£\n\n¤\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n¢\n}\n¤\ny\n\n}\n¤\n¤\n\n¤\n¤\n\nv\n}\n\ny\n\nv\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n\nv\n\n¤\nx\n\nv\n\n¢\n\ny\ny\n}\n\n¢\n§\n\n}\nx\n\n}\n\n}\n\n£\n\n¤\n¥\n\nx\n\ny\n\n}\n\nv\nv\n}\ny\n\n¥\ny\n\n}\n¢\ny\n\nx\n\nx\n\n¢\n}\n\n}\n{\n\n¥\n\nx\n\n}\n\nx\n\n¤\n\n}\n\n¢\n\n§\nU\nv\nx\n¤\n\n¥\ny\n\n¥\n¤\n\ny\n\n¤\n£\nx\n\nx\n\n{\n\n}\n\ny\nv\n\n{\n\n¤\n\ny\n\n¥\n\n¤\n\n}\n¤\ny\nv\n\n¥\n¤\n\ny\n{\n\nx\n\n¢\n}\n\ny\nx\n\ny\n¢\ny\n\ny\n\nv\n}\n\n¤\n\nv\n\ny\n\n¤\n£\n\ny\n\nv\n}\n\n}\ny\nx\n¤\n¢\n\nv\n}\n\nx\ny\n\n£\n\n¤\n£\n}\n\n¤\n\ny\n¢\ny\n\ny\n§\n±\n\nv\nx\n\n£\nx\n\nv\nx\ny\n\n}\n¤\n\nI\n¥\nx\n\ny\n\n£\nx\ny\n\nx\n\nv\n\n¤\n\nx\n\ny\n\nv\n}\n\ny\n¥\n{\n{\n\nv\n}\n\nv\n\n¥\n\nv\n\n¥\n\nv\n\nx\n\ny\n¢\ny\n\n¤\nx\n\n¢\n\n¤\n\nI\n¥\nx\n\ny\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\nx\n\n{\n¤\n\n}\n\nx\n\n}\n\n}\nx\n\n}\n\n§\nB\n\n}\n\n{\n¤\n\n}\n¢\n\n}\n\n¤\n\n}\n\nx\nn\n\nx\n\n}\n\n}\n¢\n\nv\n}\n\nx\n¤\n¤\n\nx\n\nx\n\nx\nn\n\nv\n\n}\n\n¥\n\nv\n}\n\ny\n\nv\n}\n\nv\n}\n\ny\n\n£\n}\n¤\n¥\n}\n\nv\n\nx\n\nx\n\nx\n\n}\n\nv\n}\n\nx\ny\ny\n}\n\n}\ny\n\n}\n\n¤\n\n§\n\ny\n¥\n\n}\n\n¢\n\n¤\nx\n\n£\n\nv\n}\n\nØ\n\nx\n£\n\ny\n¥\n{\n{\n\ny\n¥\n\nv\n\n£\n\n¤\n£\n}\n\n¤\n\ny\n¢\ny\n\ny\n\nx\n¤\n¤\n\nI\n¥\nx\n\n}\n\n{\n}\n\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\n}\n\ny\nx\n\n}\n\nv\n¢\n{\n\nv\n\ny\nx\nn\n\nv\n}\n\ny\n¥\n\nv\n}\n{\n}\n\n}\n\nx\n\nx\n\nv\n\nx\n\n}\n\ny\n\n}\n\nx\n\ny\n\n}\ny\n\nx\n\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n{\n\n£\nx\n\nv\n\n}\n\n¬\n\nx\n\n¤\n¥\n\nv\n\nx\n\n}\n\nx\n\n}\nx\n\n}\nx\n\ny\n\nx\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\n§\nt\nv\n\n¢\nx\n\n}\ny\n\nv\n\nx\n\n}\n\nx\n\ny\n\nv\n}\n\n¤\n\ny\ny\nx\n\nx\n\nN\n}\n\n¥\n\ny\ny\nx\n\nO\nx\ny\n\nI\n¥\nx\n\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n¤\n¢\ny\n¥\n{\n{\n\n£\n\n¤\n¥\n\nx\n\n}\n\n}\nx\n\n}\n\n¥\n\nv\n\n¢\n\n}\n¢\n\n£\n\n¤\n£\n}\n\n¤\n\nv\n\ny\n\n¤\n£\n\ny\n\nv\nx\n\nv\n\n¥\n¤\n\n}\ny\n\nv\n\n{\n\n¤\n\n¬\n\n{\nx\n\n¥\n\n}\n\nx\n\n}\n\nx\n\n{\n¤\n\n}\n\nx\n\ny\nx\ny\n\n§\n\n}\n\nx\n\nx\n\nv\n\n¢\n}\n¤\ny\n\n{\n\n£\nx\n\nv\n\n{\n\ny\ny\nx\n\nx\n¤\nx\n\n¢\n\ny\nx\n\nx\n\n£\n\n¤\n¥\n\nx\n\ny\n\nv\n}\n\nv\n\ny\n¢\ny\n\ny\n\n¥\nx\n¤\n\n}\n\n}\ny\nx\n¤\n¢\n\n}\nx\n\n}\nx\n\n}\n\n£\n\n¤\n£\n\n§\ni\n~\nC\n&\n\nE\n-\n(\n\nC\n&\n(\nE\n{\n\nx\n\n}\n\nx\n\ny\n}\n\ny\n\n¥\n\nv\n\n¤\n{\n¥\ny\ny\n\n¤\n£\n\n{\n\n¤\n\ny\n§\n±\n\n¢\n\nv\n\n¢\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\nv\n\ny\nv\n\n¥\n¤\n\n}\ny\n\n¥\n\n}\n\n}\n¤\n\n{\n\ny\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nv\n}\n£\nx\n\n§\n\ny\nv\n\n¥\n¤\n\n}\n¤\ny\n\ny\n¥\n{\n{\n\nv\n\n}\ny\nx\n\ny\n¢\ny\n\ny\n\nx\n\nx\n\n{\n\ny\ny\n§\nt\nv\nx\ny\n{\n}\n{\n\nv\n}\ny\n{\n\ny\n\ny\n¥\n\nv\n}\n{\n{\n\n}\n\nv\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\ny\n\n¥\n\n¤\n¢\nx\n\nx\n\n}\ny\n\n{\ny\n¢\n\nv\n\n¤\n\n¢\n\ny\n¢\ny\n\ny\n\nv\n\n¢\n\nv\n¥\n\n}\n\n}\n\ny\n\ny\n¢\ny\n\nx\n\nx\n\n}\n\nx\n\nx\n£\n\nx\n\nx\n\n§\nt\nv\n\nv\n\nx\n\ny\n\n¥\n\n¥\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\nv\n}\n£\n\n}\n{\n\n¥\n\nØ\n\nv\n\n¬\nx\n\nx\n\nx\n£\n\n{\n\ny\ny\nx\n\nv\n}\n\nv\n\n¥\ny\n\n¥\ny\n\nx\n\n}\n\n¥\ny\n\n}\ny\n{\n\nx\n\n}\n\nx\n\nv\n\n}\ny\n¬\ny\nx\n\n£\n\n¤\n£\n\nx\n\ny\n¢\ny\n\n}\n\ny\n\n}\n\ny\nx\n\n}\n\ny\n\n¥\n\nx\n\n}\nx\n\n}\n\n}\n\n£\n\n¤\n¥\n\nx\n\n§\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n{\n\n£\nx\n\n}\n\n}\n¢\n\n{\nx\n\nx\n\nv\n\nv\n\n{\n¤\n\nx\n\n¢\n\nv\n\nx\n\nx\n£\n\n}\n\ny\n\nv\n\n¥\nx\n¤\n\ny\n}\n\n}\nx\n\n}\nx\n\ny\n\n}\n¥\n\n}\n\ny\n¢\ny\n\ny\n\n¢\n\n}\ny\nx\n\n¥\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n}\n\ny\n\ny\n}\ny\n\n¤\n¤\n}\ny\n{\n}\n\nv\n\n¤\n\n}\n\ny\n\n}\n\nx\n\ny\n§\n\n¤\nx\n\n£\n\nv\n}\n\nv\n\n¤\n\n£\n\n¤\ny\n\nv\n\n}\n\ny\n\ny\nv\nx\n\n}\n\nv\n¢\n\n}\n\n}\n\nx\n\n}\n¤\n\ny\nx\n\n{\nv\nx\n¤\n\ny\n\n{\nv\n¢\n\nv\n\ny\n¢\ny\n\ny\n\nx\n\nx\n\n{\n¤\n\ny\n¢\ny\n\ny\n}\n\nv\n¥\ny\n}\n\n}\n\nx\n\n}\n¤\n\n}\n¢\n\ny\n{\n\nx\n\n¢\n\nv\n\ny\n¥\n¤\n\ny\n\nv\n\n{\n\ny\ny\n§\nt\nv\n\n¢\n{\n\n£\nx\n\n}\n{\n{\nx\n\nN\n\n}\n\nx\n\nO\n\nx\ny\nx\n\ny\n\n}\n\n}\n\n¤\nx\n\nx\n\nv\n\n¤\n}\n\ny\n\n}\n\ny\n\nv\n\n{\n\ny\ny\n§\n|\n\ny\nx\n\nx\ny\nx\n\ny\n}\n\n}\n\nv\n¤\n\n£\n\n¤\n}\n\n¤\nx\n\n¬\n\nv\n\n}\n¤\ny\n}\n\ny\n\n}\nx\n\ny\n\nv\n\n¢\n}\n\nx\n£\n\ny\n}\n\nx\ny\n\n¢\n§\n±\ny\n\n}\n\n¤\n\ny\ny\nN\n\n}\n{\n¤\n\ny\ny\nO\n{\n\ny\ny\nx\n\nx\ny\n\nv\nx\n\nv\n\n¤\n\n£\n\n¤\ny\n¢\ny\n\nI\n¥\nx\n\ny\n\n{\n\nI\n¥\nx\n\ny\n\ny\nx\n\n}\n\nx\n\n{\n¤\n\n}\n\nx\n\n§\n\n}\n\nx\n\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n{\n\n£\nx\n\n}\n\n}\n¢\n\nx\n\n}\n\nx\n\n}\n¤\n}\n\nx\n\n}\n¤\n}\ny\n{\n\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\n\n{\n¤\n\n¤\n¢\nx\n\n}\n¤\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n{\n¤\n\ny\n¢\ny\n\ny\n+\ny\n\n¥\n\nx\n\n¤\n\n¢\n}\n\nx\nz\n\n¥\n¤\n\n£\n}\n¤\nx\n\n}\n\n§\n\n{\n¤\n\n¤\n¢\n\n}\n¤\ny\n{\n\nx\n\n}\n\nx\n\ny\n{\n\n£\nx\n\nv\n\n{\n\nx\n}\n¤\n\n}\n\nv\n\n}\n\nx\n\n}\n¤\n}\n\n}\n¤\n¢\ny\nx\ny\n}\n\n{\n\ny\n\n¥\n\nx\n\ny\ny\n}\n\n¢\nx\n\n}\n\nx\n\nv\n}\n\n}\n\ny\n{\n\nx\n\n}\n¤\n¤\n¢\n§\nE\n\n}\n¤\n}\n{\n{\n\n}\n\nv\n\ny\n\nI\n¥\nx\n\n¥\nx\n¤\n\nx\n\ny\n{\n\nx\n}\n¤\n\n¤\ny\nx\n\n}\n\nx\n\nx\n\nv\n\n¥\n¤\n}\n\ny\n¢\ny\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\n\n¤\nx\n\n£\n\nv\n}\n\nv\n\nx\n\ny\n{\n\n}\n\n¥\ny\n\n}\n¤\ny\n{\n\nx\n\n}\n\nx\n\ny\nx\n\nx\n\n¥\ny\n\n¢\n\nx\n¤\n¤\n\nI\n¥\nx\n\nv\n\n£\n\n¤\n\n{\n\n}\n¤\ny\n{\n\nx\n\n}\n\nx\n\ny\n\nv\n}\n\n}\n\n}\n\n}\n\n¤\n\nx\n\nv\n\nx\n\nx\n\n}\n¤\n\n}\nx\n\nx\n\nI\n¥\nx\n\ny\n}\n\nv\n}\n\n}\n\nx\n\n}\n\nx\n\nv\nx\n\n}\n¤\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\n\n}\n¤\n¤\n¢\n\n}\n¤\n}\n\n}\n¤\n¢\ny\nx\ny\ny\nv\n\n¥\n¤\n\nI\n¥\nx\n\n¥\nx\n¤\n\nx\n\ny\n{\n\nx\n}\n¤\n\n¤\ny\n\nv\n}\n\n¥\n{\n¤\nx\n\n}\n\nv\n\nx\n\n}\n\nx\n\nx\n\n¤\n¥\n\nx\n\nv\n\ny\n{\n\nx\n\n}\n\nx\n\nx\n\nx\ny\n¥\n\n¤\nx\n¬\n\n¤\n¢\n\nv\n}\n\nx\n\n¥\ny\n\n¢\n\nx\n¤\n¤\n\nv\n\n¥\ny\n\n}\n¤\n\nv\n\ny\n\ny\n\nØ\n\nx\n£\n\n§\n±\n\n}\n\n{\n¤\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\nt\n±\nE\n\nv\n}\ny\n\ny\n\n¥\n\n}\n\n}\ny\n¥\ny\n\n}\ny\n}\n\n}\n\n{\n¤\n\nx\n\nv\nx\ny\n{\n}\n{\n\n§\nt\nv\n\n}\n\nx\ny\n\n}\n¥\n\nx\n\nv\n\n£\n\nv\n}\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n}\n\n}\n¤\n\nx\n\n}\n¤\n}\n\ny\n\n}\n\nx\n\nv\n}\n\n}\n\n}\n¤\nx\nn\n\nx\n\n}\n\n¢\n\nx\nØ\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\n}\n¢\ny\n§\nt\nv\n}\n\nx\ny\n\nv\n\n{\n}\n\nx\n\n¥\n¤\n}\n\n}\n\nx\nn\n}\n\nx\n\n¥\ny\n\nv\n\nt\n±\nE\ny\n{\n\nx\n\n}\n\nx\n\nx\ny\ny\nx\n\n{\n¤\n¢\n\n{\n\ny\ny\nx\n\n¤\n\n{\nv\n¢\ny\nx\n\n}\n¤\n\n}\n¤\nx\nn\n}\n\nx\n\nv\n\n}\n¤\n¤\n\nx\n\n}\n¤\n\n}\n\nx\nn\n}\n\nx\n\nx\n\nv\n\nx\n\nx\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n§\ni\ni\n×\nð\n×\ni\n×\nn\n~\n×\n\n±\nt\nm\n<\n|\n§\n±\n\n¬\n\n}\n\n}\n\n§\n\n§\nt\n}\n¥\n\nx\n\ny\n§\n\nμ\n·\n3⁄4\n·\n¿\na\n\n·\no\n3⁄4\nμ\na\n;\n\n3⁄4\nμ\n¶\n(\n¿\n\n»\n\n·\n\n\\\nμ\n·\n\n¶\n3⁄4\n1⁄4\n·\n\n¿\nμ\n§\n\nv\n\nF\n\n¤\n¤\n}\n\n±\n\ny\n\n}\n\nÞ\nm\n§\n±\ny\nv\nw\n'\n<\nU\n§\nq\n§\n±\ny\nv\n\n¢\n§\nr\n\nx\n\nx\n{\n¤\n\ny\n\nv\n\ny\n\n¤\n\n}\n\nx\nn\nx\n\ny\n¢\ny\n\n§\nx\n\nF\n§\n\nB\n\ny\n\n}\n\na\n§\nU\n§\no\n\n{\n\nN\n\ny\n§\nO\n\nμ\n1⁄4\n\n»\n·\n\no\n¿\n\n·\n\n¶\nX\n\nE\n3⁄4\nμ\n\n3⁄4\n·\n\n¿\nμ\n\nr\n\n}\n\nÞ\nw\n'\n§\nt\nr\nH\nx\n<\n\n§\nt\n\n£\n\nx\n\n}\n\n§\nr\n}\n\n¬\nx\n\ny\n§\n\nx\ny\n¥\n}\n¤\n\n{\n\ny\n\n}\n\nx\n\nx\n\n}\n\n}\n¤\n\nx\n\n}\n¤\n{\n\n}\n\ny\n\n¤\n£\nx\n\n§\n\n¿\n\n±\n3⁄4\nμ\na\n(\n¿\nE\nμ\n\n·\n\n¿\nμ\n\n£\n§\nÞ\n@\n\nÞ\nH\nx\n§\nt\n\nH\n:\n<\nq\n§\nt\n\n¬\ny\n§\nt\n\n}\n\ny\n}\n\nv\n\n¢\n\n{\n\nv\n\ny\nx\n\n{\n¥\n\n{\n\n}\n\ny\n§\n\\\nμ\n·\n\no\n¿\n\nμ\n3⁄4\n·\n¿\n\n3⁄4\nμ\n¶\n3⁄4\n1⁄4\nμ\n\nμ\n\n·\n\na\n\no\n\nÞ\nH\nU\n@\ny\n:\n\n@\n@\ny\n\nÞ\nH\n:\n§\nt\nu\nH\n<\n\n§\nt\n\n}\n\n§\na\n§\nu\n\n£\n\ny\n\n§\n\n¤\nx\n\n¤\n¤\n\nt\n}\ny\n¬\ny\n\nE\n}\n\n¢\n±\n\n}\n¤\n¢\ny\nx\ny\n§\n\n1⁄4\n¿\nμ\na\nH\n¿\n\ne\no\nμ\n¿\n»\n¿\nμ\n;\n\n3⁄4\nμ\nF\n\n¿\n\n3⁄4\nμ\na\n\n±\no\n·\n\n¶\n\n·\n¿\n»\n\nμ\n·\n\nE\n\n}\n\n¤\n\n±\n{\n\nx\n¤\nÞ\nH\n§\nt\nE\nÞ\n<\n\n§\n±\n§\nt\n¥\n\nx\n\nx\n\n}\n\nr\n§\n\n§\nE\n}\n\ny\n\n§\n\n}\n\n¥\n\ny\nx\n\n£\nx\ny\n¥\n}\n¤\n\nx\ny\n{\n¤\n}\n¢\n\ny\nx\n\n¢\n{\n\ny\n\n}\nx\n¤\n¥\n\nx\n\n}\ny\n¬\ny\n§\n;\n\n3⁄4\nμ\n*\n3⁄4\n1⁄4\n¶\n·\n¿\n\no\n\n:\n:\n\nÞ\nÞ\n§\n}\ny\nÞ\n<\nE\n§\n\n§\n}\ny\n\n§\n±\n\n}\ny\n¬\n}\n\n}\n¤\n¢\n\nx\n\n}\n{\n{\n\n}\n\nv\n\nv\n\n}\n¥\n\n}\n\ny\nx\n\n}\n{\nv\nx\n\n{\n\ny\n\n}\n\nx\n\ny\n§\n\n(\n$\n\n3⁄4\nμ\no\n3⁄4\n1⁄4\n·\n\n¿\nμ\no\n¿\nμ\nJ\n\n3⁄4\n»\nμ\n\n1⁄4\no\n\n£\n\n¤\n§\nÞ\nm\n\n§\n'\n\n±\n{\n\nx\n¤\nÞ\nÞ\n§\nv\n\nH\nÞ\n<\nr\n§\nv\n\n¬\n¤\n}\n\n§\n\n±\no\n·\n\no\n$\nμ\n\nμ\ne\n\nμ\nE\n\n±\no\n·\n\no\n\n3⁄4\n1⁄4\n·\n\n1⁄4\n\n§\n\nv\n\nU\nx\n¤\n\n¢\n÷\nE\n\ny\n\nÞ\nH\nÞ\n§\nE\n\nH\nH\n<\nt\n§\n¥\n\nx\ny\n\nF\n§\nE\n\n}\ny\n\n}\n\n§\n\ny\n\n§\n±\n\n¤\n\ny\n\n¥\n\n¢\n\nv\n\ny\n\n}\n\ny\nx\n\n{\n\ny\ny\n\n¤\n}\n\ny\n¢\ny\n\ny\n§\n(\n¿\n\nμ\n\n1⁄4\n3⁄4\n·\n\n¿\nμ\no\n¿\n\n·\nμ\n\n(\n\n:\nÞ\nN\n'\nO\nU\nÞ\n'\nw\nH\n\nÞ\n'\nH\nx\n\nÞ\nH\nH\n§\n|\nt\nH\n:\n<\n|\n\nE\n¤\n\n}\n\n§\nE\n§\nt\n\n§\n±\ny\ny\n¥\n\n{\n\nx\n\ny\n}\n\n}\n\nx\n\n¥\nx\n\nx\n\ny\nx\n\nv\n}\n\nx\ny\n\nx\n\n}\n¤\n\n¤\ny\n§\n\n|\n§\na\n\n}\n\n±\n§\nu\n§\nE\n\n£\n\ny\nN\n\ny\n§\nO\n\nμ\n·\n3⁄4\n·\n¿\na\n\n·\no\n\nu\n}\n\n¤\n\n}\n¥\n\nÞ\nH\n:\n§\n|\n\nw\n<\n§\n|\nx\n\n}\n\nx\ny\n}\n\nE\n§\n\n§\n\nx\n\n§\n\n¤\n\nx\n\n}\n¤\nx\n\n}\n\ny\nx\n\n}\n{\n\n{\n¤\n}\n\n}\n\ny\n¥\n\ny\n¢\ny\n\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n3⁄4\n1⁄4\n·\n\n¿\nμ\no\n¿\nμ\n\n1⁄4\n·\n\n3⁄4\n\n1⁄4\n\n¶\n\nμ\n1⁄4\n\nx\n\n{\n\ny\ny\n§\n|\n\nH\nx\n<\n|\n§\n|\n\n§\nU\n\nv\n\nx\nz\n\n¥\n¤\n\nx\n\ny\n{\n\n{\n¤\n\nv\n}\n£\n\nx\n\n}\n¤\nx\n\nx\n\nv\n\n{\n¤\n\nx\n\n¢\n§\n\ny\nq\n}\ny\n\n¥\ny\ny\n\nE\n\nx\n\nv\n|\n¥\n\n}\n\n}\n\n}\n\nI\n¥\n\ny\nu\n\n{\n¤\n}\n\nx\n\ny\n\nO\n$\n\n1⁄4\nμ\nμ\n¿\n·\n¿\nE\n±\n3⁄4\nμ\na\n;\n\n3⁄4\nμ\nF\n\n¿\n\n{\n}\n\ny\nx\n\nÞ\nm\n\nv\n\nU\nx\n¤\n\n¢\n÷\nE\n\ny\n\nø\n\n¬\n\nÞ\nH\nx\n§\n|\n¥\n\nH\nx\n<\nE\n§\n|\n§\n|\n¥\n\n}\n\n§\nq\n\nx\n\ny\n\n}\n¥\n¤\n\nx\n}\n\ny\n\nx\n\n{\n\nx\ny\n\n§\n\ny\nq\n}\ny\n\n¥\ny\ny\n\nE\n\nx\n\nv\n|\n¥\n\n}\n\n}\n\n}\n\nI\n¥\n\ny\nu\n\n{\n¤\n}\n\nx\n\ny\n\nO\n$\n\n1⁄4\nμ\nμ\n¿\n·\n¿\nE\n±\n3⁄4\nμ\na\n;\n\n3⁄4\nμ\nF\n\n¿\n\n{\n}\n\ny\n'\nw\nÞ\n\n'\nw\n\nv\n\nU\nx\n¤\n\n¢\n÷\nE\n\ny\n\nø\n\n¬\n\nÞ\nH\nx\n§\nB\nE\nu\nx\nH\n<\nt\n§\nB\nx\ny\n\nv\n\nØ\n\nr\n§\nE\n¤\n\n£\nx\n\n}\n\nE\n§\nu\nx\n\nv\n\ny\n\nx\n\n§\nB\n}\n¥\n¤\n\ny\nU\nE\n\ny\nx\n\nx\n£\nx\n\n¢\n\ny\n\nx\n\n}\n\n}\nx\n¤\n¥\n\n{\n\n}\n\nx\n¤\nx\n\nx\n\ny\n\n{\n\n¤\n\n{\n\ny\n\n}\n\nx\n\n§\no\n¿\n\n¶\nμ\n3⁄4\n·\n¿\n\nF\nD\n»\n\nμ\n·\n3⁄4\n·\n\no\n±\n1⁄4\nμ\n¿\n·\n¿\nE\n±\nG\n;\n\n3⁄4\nμ\n\n¶\n1⁄4\n\n»\n·\n\n¿\nμ\n3⁄4\nμ\na\n\n¿\n\n3⁄4\nμ\n1⁄4\n\n£\n\n¤\n§\ny\n\nÞ\nx\nH\n§\nB\na\nx\n<\nB\nx\n\n}\n\na\n\n§\nU\nv\n\nx\n}\n\n}\n\ny\n\n}\n¬\n\n{\n\n}\n\nx\n\n¤\n}\n\n¥\n}\n\ny\n\n§\n\\\nμ\n·\n\no\n\n¿\n\n3⁄4\nμ\nu\n3⁄4\n1⁄4\nμ\n\nμ\n\n·\n\na\n\no\n\nÞ\nÞ\nU\n'\n:\n@\n\n'\nw\nÞ\n\nÞ\nx\n§\na\nH\nH\n<\nq\n§\na\n¤\n}\ny\n\n}\n\n§\nt\n§\nF\n§\nv\nx\n§\nU\n£\n\n£\nx\n\n§\n\nq\n§\na\n¤\n}\ny\n\n§\nt\n§\nF\n§\nv\nx\n\n}\n\n§\n\n§\nB\n}\n\nx\n\ny\n\n$\nμ\n\n3⁄4\n·\n\n¿\n\nF\nD\n»\n\n·\n\no\n\n§\n\n¤\n\n}\n¥\n\nF\nx\n¤\n¤\ny\n\n}\n¤\n\ny\n\n¢\n\nÞ\nH\nH\n§\na\n@\n<\nU\n§\na\n\nx\ny\n\n¤\n\n}\n\n|\n§\n\n¬\nx\n\n§\n±\n\nv\nx\n\n¥\n\n}\n¤\n\n}\n\nØ\ny\n\n}\n\n}\n\nx\n\n{\n\ny\n\n£\nx\n\n{\n\n}\n\ny\n\n¥\n\n¥\n\nx\n\n¤\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n3⁄4\n1⁄4\n·\n\n¿\nμ\no\n¿\nμ\n\n¿\n\n·\nO\n3⁄4\n\nF\nμ\nE\n\nμ\n\nμ\nE\n\n'\nÞ\nN\ny\nO\nU\n'\nx\n@\n\n'\nH\nx\n\n}\n\nv\nÞ\n@\n§\nF\n}\n\nH\n'\n<\na\n§\nF\n}\n\n}\n\n§\nu\n\nx\n\n}\ny\n\nx\n\n}\n\n¤\n\nx\n\n§\n\n3⁄4\nμ\nE\n\n3⁄4\nE\n\nμ\na\n\n3⁄4\nμ\na\nh\n\n3⁄4\n\nμ\n\nt\n§\nU\n§\nE\nx\n\n}\n\nq\n§\n\n§\nE\n\nv\n\n¤\n\ny\nN\n\ny\n§\nO\n\nu\n}\n\n¤\n\n}\n¥\n\n±\ny\ny\n\nx\n}\n\ny\n\nÞ\nH\n'\n§\n\nu\nF\n\nÞ\n<\n\n§\nE\n§\n\n}\nØ\n\n§\na\n§\nu\n\n£\n\ny\n\n§\nr\n§\n\n§\nF\n\nx\n\n}\nv\n¤\n\n}\n\nt\n§\n\n¤\nv\n}\n\n§\nE\n\n}\n\nI\n¥\nx\n\ny\n}\n\n}\n¤\n¢\ny\nx\ny\n\n}\n¤\n\nx\n\n{\n\ny\ny\n\n¤\ny\n¢\ny\n\ny\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n\n¿\nμ\n\n¿\n\n·\nO\n3⁄4\n\nF\nμ\nE\n\nμ\n\nμ\nE\n\nE\n\nÞ\nx\nN\n:\nO\n\n}\n\nv\nÞ\nÞ\n§\n'\n@\n\nE\nE\nm\n<\n§\n±\n§\nE\n}\n{\n¤\n}\n\n}\n\nF\n§\n±\n§\nE\nx\n\n§\n\ny\n\n}\n\nv\n\nx\n\ny\nx\n\nv\n\n§\n(\n¿\nE\nμ\n\n·\n\no\n±\n1⁄4\nμ\n¿\n·\n¿\nE\n±\n\n£\n\n¤\n§\n\nÞ\nm\n§\nE\nF\nE\nH\n@\n<\nE\n§\nE\n\n£\ny\n¬\n¢\n\n§\nq\n§\nF\n}\n¢\n\ny\n\n}\n\nF\n§\n±\n§\nE\nx\n\n§\nU\nv\n¢\n}\n\ny\n\n{\n\n¤\n\ny\nv\n}\n\n£\nx\n\nt\n\nF\n}\n\nx\n§\n(\n¿\nE\nμ\n\n·\n\no\n±\n1⁄4\nμ\n¿\n·\n¿\nE\n±\n\n£\n\n¤\n§\nÞ\nx\n\nÞ\nH\n@\n§\nu\n\nH\nw\n<\nE\n§\nu\n\n£\ny\n¬\n¢\n§\n\nx\n\nx\n£\n\n{\n\ny\ny\n\ny\nx\n\n{\n\n}\n\n{\n\nv\n\ny\nx\n\n§\n\n¿\n1⁄4\n\na\n\nμ\nE\no\n¿\n\n·\nμ\n\n*\n\no\n·\nH\n¿\n\ne\no\nμ\n¿\n»\n¿\nμ\nF\n\n»\n\n1⁄4\n3⁄4\n·\n\n·\n\na\n\no\n¿\n\n¿\nE\n\n3⁄4\n\n¶\n\no\n\n{\n}\n\ny\n@\nH\n\nx\n§\n±\n\n¤\n\nr\n¥\n\n¤\nx\ny\nv\nx\n\nÞ\nH\nw\n§\nu\n\n£\nÞ\n<\n§\na\n§\nu\n\n£\n\ny\n\n§\nE\n\n}\n\ny\n}\n\n¢\nx\n\n{\n¥\n\ny\n¢\ny\n\ny\n§\n(\n¿\n\nμ\n\n1⁄4\n3⁄4\n·\n\n¿\nμ\no\n¿\n\n·\nμ\n\n(\n\n£\n\n¤\n§\n:\ny\n\n§\n\nB\n\n¥\n}\n\n¢\nÞ\nÞ\n§\nu\n\n£\n@\n<\n§\na\n§\nu\n\n£\n\ny\n\n§\n\n3⁄4\n\nO\n3⁄4\n\nG\n\n±\no\n·\n\n3⁄4\n\n·\n±\n3⁄4\nμ\na\n(\n¿\n\n»\n\n·\n\no\n§\n±\n\nx\ny\n\nU\n\ny\n¤\n\n¢\nr\n¥\n\n¤\nx\ny\nv\nx\n\n{\n}\n\n¢\n\nÞ\n@\n§\nu\nE\nE\nm\n<\n§\na\n§\nu\n\n£\n\ny\n\nE\n§\nE\n§\nv\n}\n\n§\n§\nE\n\nx\n\nv\n\n}\n\nt\n§\n\n§\nE\nv\nx\n\n}\n¤\n¤\n§\nt\nv\n\n¥\ny\n\ny\n\n¤\n\nv\n\n¬\ny\n}\n\n£\n\nx\n\nx\n\ny\n\n}\n\nx\n\nU\n±\n\n{\nx\n\nx\n\n}\n¤\ny\n\n¥\n\n¢\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n3⁄4\n1⁄4\n·\n\n¿\nμ\no\n¿\nμ\n\n¿\n\n·\nO\n3⁄4\n\nF\nμ\nE\n\n¶\nμ\n\nμ\nE\n\n£\n\n¤\n§\nE\n\nÞ\nw\n\n§\ny\n\n±\n{\n\nx\n¤\nÞ\nm\n§\nu\nF\nF\nq\ny\n<\n§\na\n§\nu\n\n£\n\ny\n\n§\nr\n§\n\n§\nF\n\nx\n\n}\nv\n¤\n\nF\n§\nF\nx\n¤\n\nv\n\n}\n\n§\n|\n§\nq\n\ny\n\n§\nq\n\nI\n¥\nx\n\ny\ny\n{\n\nx\n\n}\n\nx\n\n{\n\ny\ny\n\n¤\ny\n¢\ny\n\ny\n§\n$\n\n3⁄4\nμ\no\n\n¿\nμ\n\n¿\n\n·\nO\n3⁄4\n\nF\nμ\nE\n\nμ\n\nμ\nE\n\nE\n\nm\nN\nO\n\nE\n\n{\n\nÞ\ny\n§\nu\nr\nE\nx\n<\n§\na\n§\nu\n\n£\n\ny\n\nu\n§\n|\n§\nr\nx\n\n¤\n\nE\n§\n|\n§\nE\n}\n\n¢\ny\n\nE\n§\nE\n\n}\n\n}\n\n§\n|\n§\nq\n\ny\n\n§\n±\n\n}\n¤\n¢\nn\nx\n\ny\n\n}\n\ny\n{\n\nx\n\n}\n\nx\n\ny\n\n¥\ny\nx\n\n{\n\nx\n}\n¤\n§\nU\n\n¬\ny\nv\n\n{\n\nF\n¥\n\n}\n\n}\n\nE\n¢\ny\n\n|\n\n£\n\n¤\n\n{\n\na\n¤\n}\ny\n\n}\n\nv\nÞ\nx\nx\n§\nu\n¥\n\nH\nx\n<\n|\n§\n±\n§\nu\n¥\n\n}\ny\n§\n\n}\n¤\n\n¤\ny\n}\n\nv\n\n¤\n\n¢\n§\n\ny\nq\n}\ny\n\n¥\ny\ny\n\nE\n\nx\n\nv\n|\n¥\n\n}\n\n}\n\n}\n\nI\n¥\n\ny\nu\n\n{\n¤\n}\n\nx\n\ny\n\nO\n$\n\n1⁄4\nμ\nμ\n¿\n·\n¿\nE\n±\n3⁄4\nμ\na\n;\n\n3⁄4\nμ\nF\n\n¿\n\n{\n}\n\ny\n:\n\nÞ\n\n:\n\n@\n§\n\nv\n\nU\nx\n¤\n\n¢\n÷\nE\n\ny\n\nø\n\n¬\n\nÞ\nH\nx\n§\n\nw\nw\n<\n\n§\nq\n§\n\n}\n\n§\n\ny\nx\n\nv\n¥\n\n}\n\n}\n{\n}\n\nx\n¤\nx\n\n¢\n\nv\n\n¥\n\nv\nx\n\n}\n\nx\n\n{\n\ny\ny\nx\n\n}\n\nx\ny\n{\n¤\n}\n¢\ny\n¢\ny\n\ny\n§\nt\n\nv\n\nx\n\n}\n¤\nq\n\n{\n\nE\nr\n\n@\nw\nm\n\nE\n¢\ny\n\n|\n\n£\n\n¤\n\n{\n\n{\n\n}\n\nx\n\nÞ\nw\nw\n§\n\n:\n<\n|\n§\n±\n§\n\n}\n\n§\n$\nμ\n\nμ\nE\no\n·\nμ\n3⁄4\n·\n3⁄4\ne\n\no\n\n3⁄4\n\n·\n§\n±\n\nx\ny\n\nU\n\ny\n¤\n\n¢\nr\n¥\n\n¤\nx\ny\nv\nx\n\n{\n}\n\n¢\n\nÞ\n:\n§\nq\nr\n@\n<\n\n§\nq\n}\ny\n\n¥\ny\ny\n\n}\n\n±\n§\nr\n\ny\n\n§\n\nx\n\n¥\n}\n¤\n\n¤\n\n¢\n\n¬\n§\n\n§\n\n§\nB\n¤\n}\n\nv\n\nr\n§\n±\n§\nF\n}\n\n¬\n\nE\n§\n}\nx\n\n}\n\nE\n§\n\n§\n\nx\n\nx\n\ny\n\nμ\nF\n1⁄4\n¿\n¶\n·\n¿\nE\n\n1⁄4\n3⁄4\n·\n\n»\n»\n\n¿\n3⁄4\n1⁄4\nμ\n·\n¿\n;\n\n3⁄4\nμ\n3⁄4\n1⁄4\nμ\n\nμ\n\n±\no\n·\n\no\n\\\nG\n\nJ\n·\n¿\n\n3⁄4\n·\n\no\n»\n\n1⁄4\n·\n\n¤\n\n}\n¥\n\nF\nx\n¤\n¤\ny\n\n}\n¤\n\ny\n\n¢\n\nÞ\n@\n§\n§\nr\n\nH\nx\n<\n§\nr\n\nx\n\n§\nE\n\nx\n\n¥\n¤\n¥\ny\ny\n\n¥\n\n¥\n\ny\n}\n\n}\n¤\n\n{\n\ny\n\n}\n\nx\n\ny\nx\n\n{\n\n{\n\nv\n\ny\nx\n\n{\n¥\n\n{\n\n}\n\ny\n§\n(\n¿\nE\nμ\n\n·\n\no\n±\n1⁄4\nμ\n¿\n·\n¿\nE\n±\nÞ\nU\n\n@\n\n:\ny\nÞ\n\nÞ\nH\nx\n§\nq\n}\ny\nH\n@\n<\n\n§\nq\n}\ny\n\n¥\ny\ny\n\n§\nt\nv\n\nq\n\n¤\n\nv\nx\n\n}\n\nv\nx\n\n}\n¤\n¬\n\n¤\n\n{\n\ny\n\n}\n\nx\n\nx\n\nx\ny\nx\n\n}\n¬\nx\n\n}\n\ny\n¢\ny\n\n}\n\n}\n\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n3⁄4\n1⁄4\n·\n\n¿\nμ\no\n¿\nμ\n\n±\no\n·\n\no\n\n3⁄4\nμ\n\n3⁄4\nμ\na\n(\n±\n\nμ\n\n·\n\n1⁄4\no\n\n£\n\n¤\n§\nE\n\nÞ\n@\n\n§\n\n}\n\nv\n±\n{\n\nx\n¤\nÞ\nH\n@\n§\nq\n}\ny\nH\nw\n<\n\n§\nq\n}\ny\n\n¥\ny\ny\n\n§\n\\\nμ\n\n¿\n\n3⁄4\n·\n\n¿\nμ\n\n¿\n1⁄4\n\no\no\n\nμ\nE\n3⁄4\nμ\na\n;\n\n3⁄4\nμ\nu\n3⁄4\n1⁄4\nμ\n\nμ\n\n\\\nμ\n·\n\n3⁄4\n1⁄4\n·\n\n¿\nμ\nG\n\nμ\n\n»\n»\n\n¿\n3⁄4\n1⁄4\nμ\n·\n¿\n(\n¿\nE\nμ\n\n·\n\nF\nμ\nE\n\nμ\n\nμ\nE\n§\n\nv\nF\n\n¤\n¤\n}\n\nÞ\nH\nw\n§\nq\n}\ny\nm\n<\n\n§\nq\n}\ny\n\n¥\ny\ny\n\n§\n\n}\n¤\n\n¤\ny\n}\n\nv\n\n¤\n\n}\n\nx\n\nx\n\n{\n¤\n\n£\nx\n\ny\n§\n\n|\n§\n±\n\n¬\n\n}\n\n}\n\n§\n\n§\nt\n}\n¥\n\nN\n\ny\n§\nO\n\nμ\n¶\n·\n3⁄4\n·\n¿\na\n\n·\no\n3⁄4\nμ\na\n;\n\n3⁄4\nμ\nu\n(\n¿\n\n»\n\n·\n\n\\\nμ\n·\n\n3⁄4\n1⁄4\n·\n\n¿\nμ\n\n¤\ny\n\n£\nx\n\nN\n\nv\n\nF\n\n¤\n¤\n}\n\nO\n\nÞ\nm\n\n{\n{\n§\ny\nÞ\n\nw\n§\nq\n\n}\nm\n<\n\n§\nq\n\n}\ny\n\n§\n;\n\n3⁄4\nμ\nF\n\n¿\n\n§\n}\n\nx\n\n×\n\nx\n£\n\ny\nx\n\n¢\nr\n\ny\ny\n\nÞ\nm\n§\nE\nU\nt\n@\n<\n§\n|\n§\nE\n}\n\n|\n§\n|\n§\nU\n\ny\n\n}\n\n§\n\n§\nt\nx\n¤\n¤\nx\n\ny\n§\n±\n¥\n\n}\n\nx\n\nE\n¥\n\n{\n\nx\ny\n\ny\n§\nx\n\na\n§\nE\n}\n¤\n£\n\n¢\nN\n\n§\nO\n;\n3⁄4\nμ\na\n\n¿\n¿\ne\n¿\n\n;\n\n3⁄4\nμ\n*\n3⁄4\n1⁄4\n·\n¿\n\no\n\nF\n\nE\n¿\nμ\n¿\n\n1⁄4\no\n\nx\n\nx\n\nU\nx\n¤\n\n¢\n\nø\n\n¬\n\nx\n\n{\n\ny\ny\n§\nE\n\nx\n<\nt\n§\nE\nv\n\nx\n\n}\n\n}\n\nq\n§\n\n}\n¢\n\n§\nE\n¢\n\n}\n\nx\n\ny\n\n}\n\nx\n\nx\n\n}\n\nx\n\ny\nx\n\n{\n\n}\n\nv\n}\n£\nx\n\nU\n±\n\n¤\n}\n\n{\n\nx\n\n}\n¤\n\ny\n¥\n¤\n\ny\n§\n(\n¿\n\n»\n\n·\n\n3⁄4\nμ\na\n\\\nμ\n\n¿\n\n1⁄4\n\nμ\n1⁄4\n\no\n\nH\nN\n:\nO\nU\n\nÞ\n\n:\nH\n\nÞ\nx\n§\nE\n\nx\nH\n<\na\n§\nB\n§\nE\n\nx\n\nv\n§\nq\n\n{\n\ny\n\n}\n\nx\n\n}\n¤\n\nØ\n\ny\n\nv\n\ny\n\n¤\n£\nx\n\n}\n\n¥\n\ny\n\n¥\n\n¥\n\nx\ny\nx\n\n{\n\n¤\n\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n3⁄4\n1⁄4\n·\n\n¿\nμ\no\n¿\nμ\n\n±\no\n·\n\no\n\n3⁄4\nμ\n\n3⁄4\nμ\na\n(\n±\n\nμ\n\n·\n\n1⁄4\no\n\n£\n\n¤\n§\nE\n\nÞ\n\nÞ\nH\n\n{\n{\n§\nÞ\nm\nH\n:\n\nÞ\nm\nm\n§\nE\n\nH\ny\n<\n\n§\nE\n\n¤\n\n}\n¢\n}\n\nE\n§\n\nv\n\n¤\nx\n\nv\n§\n\n{\nx\n\nx\n\n}\n¤\ny\n\n¥\n\nx\n\ny\n\n{\n\n}\n\nx\n\n¬\n\n¤\n\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n\n¿\nμ\n\n¿\n\n·\nO\n3⁄4\n\nF\nμ\nE\n\nμ\n\nμ\nE\n\n£\n\n¤\n§\nE\n\nÞ\nm\nN\n@\nO\nU\n@\n@\n\nw\nm\n\nÞ\nH\ny\n§\nE\n\n¤\nH\nH\n<\n\n§\nE\n\n¤\n\n}\n¢\n\n§\nr\nx\n\nE\n§\nu\n\n£\ny\n¬\n¢\n\n|\n§\nu\nx\n\n}\n\n}\n\nq\n§\nu\n}\n\n{\n\n§\n|\n\ny\nx\n\nx\n\n¥\n\n}\n\nx\n\n{\n\ny\n}\n\n¤\n\n}\n¤\nx\nn\n\n{\n¤\n}\n\ny\n§\n(\n¿\n\nμ\n\n¶\n1⁄4\n3⁄4\n·\n\n¿\nμ\no\n¿\n\n·\nμ\n\n(\n\n:\nÞ\nN\n\nO\nU\nÞ\n\n@\n\nÞ\n\nw\nx\n\nÞ\nH\nH\n§\n\ny\nH\n@\n<\n\n§\n\ny\ny\n\n¢\n§\n\n{\n\nx\ny\n\nx\n\n¥\n\nx\n\n{\n¥\n\n{\n\n}\n\ny\nU\n±\n{\n\ny\ny\n}\n\n}\n¤\n¢\ny\nx\ny\n§\n\\\nμ\n·\n\no\n\n¿\n\n3⁄4\nμ\nu\n3⁄4\n1⁄4\nμ\n\nμ\n\n·\n\na\n\no\n\n£\n\n¤\n§\n\n:\n\nÞ\nH\n@\n§\n\nx\n\nÞ\n<\nE\n§\n\n§\n\nx\n\n§\nE\n¥\n{\n{\n\nx\n\n¬\n\n¤\n\n}\ny\n\nv\n}\n£\nx\n\nv\n\n¥\n\nv\n\n¤\n\nx\n\n}\n¤\nx\n\n}\n\ny\nx\n\n§\nr\nv\n§\n|\n§\n|\nx\ny\ny\n\n}\n\nx\n\n×\n\nx\n£\n\ny\nx\n\n¢\n\n¤\n¤\nx\n\nx\ny\n}\n\n×\n\n}\n\n}\n\nv\n}\n\n{\n}\n\nÞ\nÞ\n§\n\nw\n\nr\n@\n<\nE\n§\n\n§\n\nx\n\nE\n§\nv\n\nx\ny\n\nØ\n\ny\n\n}\n\n±\n§\nr\n\n¬\n\n¤\nx\n\n§\nE\n¥\n{\n{\n\nx\n\n{\n\n}\n\n{\n\n¤\n\ny\n\n¤\n£\nx\n\nv\n\n¥\n\nv\n\n¤\n\nx\n\n}\n¤\nx\n\n}\n\ny\nx\n\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n3⁄4\n1⁄4\n·\n\n¿\nμ\no\n¿\nμ\n\n±\no\n·\n\no\n\n3⁄4\nμ\n\n3⁄4\nμ\na\n(\n±\n\n¶\nμ\n\n·\n\n1⁄4\no\n\n@\nN\ny\nO\nU\n@\n\n@\ny\n@\n\nÞ\n@\n§\n\nq\nm\n<\nE\n§\n\n§\n\nx\n\n}\n\n§\nq\n}\ny\n\n¥\ny\ny\n\n§\nt\nv\n\n¤\n\n¢\n\nv\n¥\n\n}\n\n}\n\nv\nx\n\ny\n¢\ny\n\ny\n\nU\n\nx\n}\n\nx\n\nx\n\n{\n\n{\n\nx\n\nx\n\n{\n¤\n\n¬\n\n}\nx\n\ny\n§\nF\n1⁄4\n¿\n·\n¿\nE\n\n1⁄4\n3⁄4\n·\n\no\n±\n1⁄4\nμ\n¿\n·\n¿\nE\n±\n\nN\n:\nO\nU\n\nm\nx\n\ny\n\nÞ\nm\n§\n\nq\n\n<\nE\n§\n\n§\n\nx\n\n}\n\n§\nq\n}\ny\n\n¥\ny\ny\n\n§\n\n¤\n\nx\n\n}\n¤\nx\n\n}\n\ny\nx\n\nU\nt\nv\n\nx\n\n}\n¤\n\n¥\n\n}\n\nx\n\ny\n§\n\\\nF\nF\nF\n$\n\n3⁄4\nμ\no\n\n¿\nμ\n\n±\no\n·\n\no\n\n3⁄4\nμ\n\n3⁄4\nμ\na\n(\n±\n\nμ\n\n·\n\n1⁄4\no\n\n£\n\n¤\n\n§\ny\n\n¥\n¤\n¢\n±\n¥\n\n¥\ny\n\nÞ\n\n§\nU\n\nx\nH\n<\n\n§\nu\n§\nU\nx\n\n§\n;\n\n3⁄4\nμ\n*\n3⁄4\n1⁄4\n·\n¿\n\no\n¿\n\na\n3⁄4\nμ\n1⁄4\n\na\n$\n\n1⁄4\nμ\nμ\n¿\n·\n¿\nE\n±\nB\nA\nJ\n·\n3⁄4\no\no\n(\n¿\n1⁄4\ne\n»\n\n·\nA\nE\n$\n\n3⁄4\nμ\no\n»\n¿\n\n·\n\n¶\n1⁄4\n\n3⁄4\n\n·\n§\n±\nE\n±\n\n}\n\nq\n\n{\n\nÞ\nx\nx\n@\n\nH\n\n±\nE\n±\n±\n\ny\nq\n\ny\n\n}\n\nv\n\n¥\n\nÞ\nH\n§\nU\n\n@\n<\n|\n§\n|\n§\nU\n\ny\n§\nt\n\n}\n\n}\n\nv\n\nx\n\n}\n¤\n\n}\ny\n\n{\n\ny\n\n}\n\nx\n\ny\nx\n\nx\n\nv\n\n{\n¥\n\nx\n¥\n\nU\n\n¤\n\nx\n\n}\n¤\n{\n\n{\n\nx\n\n}\n\n}\nx\n\nx\n\nv\n¥\n\n}\n\nx\n\nx\n\n§\n\n§\n\n§\nB\n¤\n}\n\nv\n\nr\n§\n±\n§\nF\n}\n\n¬\n\nE\n§\n}\nx\n\n}\n\nE\n§\n\n§\n\nx\n\nx\n\ny\n\nμ\nF\n1⁄4\n¿\n¶\n·\n¿\nE\n\n1⁄4\n3⁄4\n·\n\n»\n»\n\n¿\n3⁄4\n1⁄4\nμ\n·\n¿\n;\n\n3⁄4\nμ\n3⁄4\n1⁄4\nμ\n\nμ\n\n±\no\n·\n\no\n\\\nG\n\nJ\n·\n¿\n\n3⁄4\n·\n\no\n»\n\n1⁄4\n·\n\n¤\n\n}\n¥\n\nF\nx\n¤\n¤\ny\n\n}\n¤\n\ny\n\n¢\n\nÞ\n@\n§\n\nx"
    },
    {
      "category": "Resource",
      "title": "parnas_ease.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/16-355j-software-engineering-concepts-fall-2005/1c68d0f98909a126ec5eb6a0ff358ec7_parnas_ease.pdf",
      "content": "_~ZS_ZG~X_m_G_SO~I_~A~OR ZASE OF__.ZXTZWSXO.\nA~D CONIRACTION\nDavid L. Parnas\nDepartment of Computer Science\nUniversity of Ncrth Carolina at Chapel Hill\nABSTRAC~\nDesigning software to\nbe\nextensinle\nand\neasily\ncontracted\nis\ndiscussed\nas\na\nspecial came\nof\ndesign\nfor\nchange.\nA\nnumber\nof\nways\nthat\nextension\nand\ncontraction proble m~\nmanifest\ntheasel yes\nin\ncurrent\nsoftware are explained.\nFour\nsteps in the design of\nsoftware\nthat\nis\nmore\nflexible\nare\nt~hen\ndiscussed.\nThe\nmost critical step\nis\nthe\ndesigu\nof\na\nsoft wa re\nstructure\ncalle d\nthe\n\" useS\"\nrelation.\nSome\ncriteria\nfor\ndesign\ndecisions\nare given and iliustrated using\na small example.\nIt\nis\nshown\nthat\nthe\nidentification\nof\nmin_imai\nsubsets\nand\nminimal extensions can\nlean\nto\nsoftware\nthat\ncan\nbe\ntailored\nto the needs of a\nbroad variety of users.\nI.\n' IN TRODUCTION.\nThis paper is being\nwritten\nbecause\nthe\nfollowing\ncomplaints\naUout\n~ftware\nsystems are so commpn:\n(A)\n\"We were behind schedule\nand\nwanted\nto\ndeliver\nan\nearly\nrelease\nwith only\n<proper subset of intended\ncapabilities>,\nbut\nfound that that subset would not work\nuntil everything worked.\"\n{B)\n\"We\nwanted\nto\nadd\n<simple\ncapability>, but to do so would have meant\nrewriting\nall\nor\nmost\nof\nthe\ncurrent\nc ode. \"\n(C)\n\"We wanted to simplify and\ns~eed\nup\nthe\nsystem\nby\nre moving\nthe\n<unneeded\ncapability>, but to take advantage of this\nsimplification\nw~\nwould\nhave\nhad\nto\nrewrite major sections of the code.\"\n(D)\n\"Our SYSG£N was intendea to allow\nus\nto tailor a system to our customers' needs\nbut it was not\nflexible\nenough\nto\nsuit\nUS. \"\nAfter studying a number of such systems, I\nhave\nidentified some simple concepts that\ncan help programmers to deign\nsoftware so\nthat sub~ts\nand extens~ion are mo~e easily\nobtained.\nThe~\nconcepts\nare\nsimple\nif\nyou\nthink\nabout\nsoftware\nin\nthe\nway\nsuggested by t.his limper.\nProgrammers\ndo\nnot commonly do so.\nXI.\nSOFTWARE AS A FAMILY OF PROGRA85.\nWhen we were first taught how to\nprogram,\nwe\nwere given a specific problem and told\nto write\none\nprogram\nto\ndo\nthat\njob.\nLater\nwe\ncompared our program to others,\nconsidering suc~ issues as space ann\ntime\nutilization,\nbut\nstill\nassuming that we\nwere producing a single product.\nEven the\nmost\nrecent\nliterature\non\nprogramming\nmethodology\nis\nwritten\non\nthat\nbasis.\nDijkstra's \"Discipline of Programming\" [ I ]\nuses p~edicate transformers to specAfy the\ntask to be performed by the ~rogram to\nbe\nwritten.\nThe use of the definite article\nimplies that there is a unique prohle.m\nto\nbe solved and but one program to write.\nToday, the\nsoftware\ndesignea\nshould\nbe\naware\nthat\nhe\nis not designing a single\nprogram but\na\nfamily\nof\nprograms.\nAs\ndiscussed\nin\nan\nearlier\npaper\n~2], we\nconsider a set of ~rograms to he a p~oNr~\nfamily i£ they have so much in common that\nit pays\nto\nstudy\ntheir\ncommon\naspects\nbefore\nlooking\nat\nthe\naspects\nthat\ndifferentiate them.\nThis rather pragmatic\ndefinition d~s\nnot tell us what pays, but\nit\nd~s\nexplain\nthe\nmotivation\nfor\ndesigning\nprogram\nfamilies.\nWe want to\nexploit the commonalities, share code, and\nreduce maintenance costs.\nSome of the ways that\nthe\nmembers\nof\na\nprogram\nfami ly\nmay\ndiffer\nare\nlisted\nbelow:\n(I}\nThey may run\non\ndifferent\nharaware\nconfig ura tions.\n(2)\nThey may perform the\nsame\nfunctAons\nbut\ndiffer in the format o~ the input and\noutput data.\n\n(3)\nThey\nmay\ndiffer\nin\ncertain\ndata\nstructures\nor\nalgorithms\nbecause\nof\ndifferences in the available resources.\n(q)\nThe y\nmay\ndiffer\n~\nsome\ndata\nstructures\nor\nalgorithms\nbecause\nof\ndifferences in the size of the input\ndata\nsets\nor the relative frequency of certain\nevents.\n(5)\nSome users may require only a\nsubset\nof\nthe\nservic~es\nor\nfeatures that other\nusers need.\nThese \"less demanding\"\nusers\nmay\ndemand that they not be forced to pay\nfor the resourc~s consumed b~ the unneeded\nfeatures.\nEngineers are taught that they must try to\nanticipate\nthe\nchanges that may be made,\nand are shown how to achieve aesigns\nthat\nca n\nea si ly\nbe\na Ite re d\nwhen\nt hese\nanticipated changes occur.\nFor\nexample,\nan\nelectrical\nengineer\nwall\nbe adv~ed\nthat the whole world has not\nstandardized\noD 60-cycle, 1|O-volt current.\nTelevision\ndesigners are fully aware oi the differing\ntransmission conventions that exist in the\nworld.\nIt is standard pra~ice\nto\ndesign\nproducts\nthat are easily c~anged in those\naspects.\nUnfortunately, there is no magic\ntechni ~ue\nfor\nhandling\nunan t~cipat ed\nchanges.\nThe\nmakers\nof\ncon ve~tion al\nwatches\nhave\nno\ndifficult X\naltering\na\nwatch\nthat\nshows\nthe\nday\nso\nthat\nit\ndisplays\n\"NEE\"\ninstead\nof\n\"W~D,\" but\nwould expect a\nlong\ndelay\nfor\nredesign\nwere\nthe\nworld\nto\nswit~\nto a ten day\nweek.\nSoftwa~\nengineers have not\n~en\ntra~ed\nix,\nthis\nway.\nThe\nusual\nprogramming\ncourses\nneither\nmention\n~ae\nneed\nto\nanticipate\nchanges\nnor\ndo\nthe X\noffer\ntechnigues for designing programs in which\nchanges\nare\neasy.\nBecause programs are\nabstract\nmathematical\nobjects,\nthe\nsoftware\nengineers'\ntecnni~ues\nfor\nresponding to anticipated c~anges are more\nsubtle\nand\nmore\ndifficult to grasp than\nthe\ntechnigues\nused\nby\ndesigners\nof\nphysical\nobjects.\nFurthe=, we have beem\nled\nastray\nby\nthe\nother\ndesigners\nof\nabstract\nobjects-\nmathematicians\nwho\nstate\nand\nprove\ntheorems.\nWhen\na\nmathematician\nbecomes\naware\nof the need\nfor a set of closely related theore~s,\nhe\nresponds\nby\n~r oving\na\nmore\ngeneral\ntheorem.\nFor\nmathematicians,\na\nmore\ngeneral\nresult\nis\nalways\nsuperior to a\nmore specialized product.\nThe eng~eering\na halo9 y\nto\nthe\nmathematician's approach\nwould\nbe\nto\ndesd gn\ntelevision\nsets\ncontaining\nvariable\ntransformers\nand\ntusers\nthat\nare\ncapable\nof\ndetecting\nseveral types of signals.\nExcept for U.S.\narmed forces stationed overseas, t~ere\nis\nlittle\nmarket for such a product.\nFew of\nus consider relocations sO likely that\nwe\nare\nwilling to pay to have ~he generality\npresent in the product.\nMy 9uess ~.~ that\nthe\nmarket\nfor\ncalendar\nwatches\nfor a\nvariable length week is even smaller\nthan\nthe\nmarket\nfor\nthe televis/on sets ]ust\nde~ribed.\nIn [ 2] I have treated the subject\nof\nthe\ndesign\nof\nprogram\nf~ilies\nrathe/\ngenerally\nand\nin\nterms\not\ntext\nin\na\nprog ra mining\nlanguage.\nIn\nthis\npaper I\nf~us\non\nthe\nfifth\nsituation\ndescribed\nabove;\nfamilies of programs in which some\nmembers\nare\nsubsets\nof\nother\nfamily\nmembers\nor several family m~bers\nshare a\ncommon subset°\nI discuss an earlier stage\nof\ndesign,\nthe stage when one identifi~\nthe major components\nof\nthe\nsystem\nand\ndefines\nrelations\nbetween\nthose\ncomponents.\nWe focus on this early\nstage\nbecause\nthe\n~roblems\nde~ri1~ d\nin\nthe\nintzod uc ti on\nre sult\nf tom\nfail u~e\nto\ncarefully consider early design decisions.\nIIX.\nHOW DOES THE\nLACK\nOF\nSUBSETS\nAND\nEXTENSIONS MINIFEST ITSELF?\nAlthough we often speak of\nprograms\nthat\nare\n\"not subsetable\" or \"not extensible,\"\nwe\nmust\nrecognize\nthat\nphrase\nas\ninaccurate.\nIt\nis\nalways\npossible\nto\nremove code from\na\nprogram\nand\nhave\na\ntunable\nresult.\nAny software system can\nbe\nextended\n(TSO\nproves\nthat) .\nThe\npr~lem\nis\nthat\nthese\nsubsets\nand\nextensions are not the\n~r~rams\nthat\nwe\nwould\nhave\ndesigned if we had set out to\ndesign just that\nproduct.\nFurther,\nthe\na mount\nof\nwork\nneeded\nt o\no brain\nt he\nproduct seems all out of proportion to the\nnature\nof\nthe\nchange.\nThe\nproblems\ne~ounter~d\nin trying to extend or\nshrink\nsystems fall into four cla~es.\nA.\nExcessive information distribution.\nA system may be hard to extend or contract\nif too many programs were written assuming\nthat a given feature\nis\npresent\nor\nnot\npresent.\nThis\ncan\nbe illustrated by an\nold,rating system in which am earl i\ndesign\ndecision was that %Ae system would support\nthDee\nconversational\nlanguages.\nThere\nwere\nmany\n~ctions\nof\nthe s~stem where\nknowledge of this decision was used.\nFor\nexample, error message tables had room for\nthree entries.\nAn extensi(~ to allow four\nlanguages would have re,u/red that a great\ndeal\nof\ncode\nbe\nrewritten.\nMore\nsurprisingly, i% would have been difficult\nto\nreduce\nthe\nsystem\nto\none\nthat\nefficiently\nsupported\nonly\ntwo\nof\nthe\nlanguage s.\nOne\ncould\nremove\nthe\nthird\nlanguage,\nbut\nto regain the table space,\none would have had\nto\nrewrite\nthe\nsame\nsections\nof\ncode that would ~\nrewritt~\nto add a language.\n\nB.\nA\nchain\nof\ndata\ntrans~ormin g\ncomponents.\nMany programs are structured as a chain of\ncomponents,\neach\nreceiving data from the\nprevious\ncomponent,\nprocessing\nAt\n(and\nchanging\nthe\nformat) , before sending the\ndata to the next program in the chain.\nIf\none component in this chain is not needed,\nthat code is often hard to remove\nbecause\nthe\noutput\nof\nits\npredecessor\nis\nnot\ncompatible with the input re~luirements\nof\nits\nsuccessor.\nA\nprogram\n~hat\ndoes\nnothing but\nchange\nthe\nformat\nmust\nbe\nsubstituted.\nOne illustra~ion wou~d be a\npayroll\nprogram\nthat\nassumeu\nunsorted\ninput.\nOne\nof\nthe\ncomponents\nof\nthe\nsystem\naccepts\nthe\nunsorted\ninput\nand\nproduces\noutput\nthat\nis\nsorted by some\nkey.\nIf\nthe\nfirm\nadopts\nan\noffice\npr~edure\nthat\nresults\nin sorted input,\nthis\nphase\nof\nthe\nprocessing\nis\nunnecessary.\nTo\neliminate taat program,\none\nmay\nha ve\nto\nadd\na\nprogram\nthat\ntransfers\ndata\nfrom\na file in the input\nformat to a file in the format appropriate\nfor\nthe\nmext phase.\nIt may be almost as\nefficient\nto\nallow\nthe\noriginal\nSORT\ncomponent to sort the sorted in~ut.\nC.\nComponents that perform more than\none\nfunction.\nAnother common error\nis\nto\ncombine\ntwo\nsimple\nf unctions\ninto\none\ncornpon ent\nbecause the functions seem ~oo\nsimple\nto\nseparate.\nFor\nexample,\none\nmight\nbe\ntempted to\ncombine\nsynchronization\nwith\nmessage\nsending\nand\nacknowledgment\nin\nbuilding an\no~e ra ti mg\nsxstem.\nThe\ntwo\nfu~tions\nseem closely related; one might\nexact\nthat for the\nsake\nof\nreliability\none\nshould\ninsist\non a \"handshake\" with\neach exchange of\nsychronization\nsignals.\nIf\none later encounters an application .in\nwhich\nsynchronization\nis\nneeded\nvery\nfrequently,\none may find that there is no\nsimple way to strip\nthe\nmessage\nsending\nout\nof\nthe\nsynchronization\nroutines.\nAnother example is the inclusi~\nof\nrun-\ntime type-checlting in the basic subroutine\ncall\nmechanism.\nIn\na ~plication s\nwhere\ncompile-time\nchecking\nor\nverification\neliminates the need for the ~un-time type-\ncheck,\nanother\nsubroutine call mech~ism\nwill\n~\n~eeded.\nThe\nirony\nof\nthese\nsituations\nis\nthat\nthe\n\"more powerful\"\nmechanism could have ~en\nbuilt senarately\nfrom,\nbut\nusin£,\ns/mpler\nmechanisms.\nse~ration\nwould result\nin\na\ns~stem\nin\nwhich\nthe\nsubset\nfunction was ava/~able\nfor use where it suffic~nd.\nD.\nLoops in the \"uses\" relation.\nIn\nmany\nsoftware\ndesign\nprojects,\nthe\ndecisions\nabout\nwhat\nother\ncomponent\npr~rams\nto use\nare\nleft\nto\nindividual\nsystems\n~rog rammers.\nIf\na\np~og~amm er\nknows of a program in another module,\na/Id\nfeels\nthat\nit\nwould\nbe\nuseful\nin his\nprog ra m,\nhe\nincludes\na\ncall\non\nthat\nprogram\nin\nhis\ntext.\nProgrammers\nare\nencouraged\nto\nuse\nthe\nwork\nof\nother\nprogrammers\nas\nmuch as possible because,\nwhe n\neach\npr~ Ea miner writes\nhis\nown\nroutines\nto\n~e~form common functions, we\nend u~ with a system that is\nmuch\nlarger\nthan it need be.\nUnfortunately, there are two sides to\nthe\nquestion\nof\nFro9 ram\nusage.\nUnless some\nrestraint is exercised,\none\nsay\nend\nup\nwith a system in which nothin 9 works until\neverything works.\nFor example,\nwhile\nit\nmay\nseem wise to have an operating system\nschedule[ use the file system to store its\ndata\n{rather\nthan\nuse\nits\nown\ndisk\nroutines) , the result\nwill\nbe\nthat\nthe\nfile\nsystem\nmust\nbe pre~nt\nand working\nbefore any task\nscheduling\nis\npossible.\nThere\nare\nusers\nfor\nwhom\nan operating\nsystem subset without a file s~stem\nwould\nbe useful.\nEven if one has no such users,\nthe\nsubset\nwould\nbe\nuseful\ndur/a g\ndevelopment and testing.\nIV.\nSTEPS TORAHDS A BETTER 52ROCT~RE.\nThis section discusses\nfou~\nparts\nof\na\nmethodology\nthat\nI ~lieve\nwill help the\nsoftwa~\nengineer to build systems that do\nnot evidence the problems discussed above.\nA.\nRequirements\ndefinition:\n1denti£)in g\nthe subsets first.\nOne of the clearest morals in the\nearlier\ndiscus~on\nabout \"design for change\" as it\nis taught in other areas of engineering ks\nthat\none\nmust\nanticipate changes before\none\nbegins\nthe\ndesign.\nAt\na\nrecent\nconference\n[ 3],\nmany\nof\nthe\npapers\nexhorted the audience to spend\nmore\ntime\nidentifying the actual requirements before\nstarting on a desi9n.\nI\ndunmt\nwant\nto\nrepeat such exhortations, but I do want to\npoint out that the identification\nof\nthe\npossible\nsubsets\nis\n~art of identifying\nthe\nrequirements.\nTreating\nthe\neasy\navailability\nof\noe rtauin\nsubsets\nas\nan\noperational\nrequirement\nis\nespecially\nimportant\nto\ngovernment\nofficials\nwho\npurchase software.\nMany officials de~spair\nof\nplacing\nstrict\ncontrols\non\nthe\npr~ uction\nmethods\nused\nby\ntheir\ncontractors\nbecause they are forbidden by\nlaw to tell the contractor now to\n~erform\nhis\njob.\nThey\nmay\ntell\nhim what they\nrequire,\nbut\nnot\nhow\nto\nbuild\nit.\nFortunatel~,\nthe\navailabilit X of subsets\nmay\nbe\nconst rued\nas\nan\noperation al\nproperty of the software.\nOn the other hand, the\nidentification\nof\nthe\nrequired\nsubsets\nks\nnot\na\nsimple\n\nmatter of asking potential users what they\ncould\n4o\nwithout.\nFirst, users tend to\noverstate their reguirements.\nSecond, the\nanswer\nwill\nnot\ncharacterize the set of\nsubsets\nthat\nmight\nbe\nwanted\nin\nthe\nfuture.\nIn my experience, identification\nof the potentially desirable subset.s is\na\ndemanding\nintellectual\nexercise in which\none first searches for the m_in~m__al\n-\nsubset\nthat\nmigh t\nconceivably\nperform a useful\nservice and then searches\nfor\na\nset\nof\nminimal\ninc re sents\nto\nthe system.\nEach\nincrement is\nsmall -\nsometimes\nso\nsmall\nthat\nit\nseems\ntrivial.\nThe emphasis on\nmini~lity\nstems from our desire to\navoid\ncomponents\nthat\nperform\nmore\nthan\none\nfunction as discussed\nin\nsection\nIII. C.\nidentifying\nthe\nminimal\nsubset\nis\ndifficult because the\nminimal\nsystem\nis\nnot\nusually\na\nprogram\none\nthat an ~one\nwould ask for.\nIf we are going\nto\nbuild\nthe software family, the minimal subset is\nuseful,\nbut\nit\nis\nnot\nusually\nworth\nbuilding\nby\nitself.\nSimilarly,\nthe\nmaximum flexibility is obtained by looking\nfor\nthe\nsmallest\npossible increments in\ncapability;\noften\nthese\nare\nsmall e/\nincrements\nthan\na\nuser\nwould think of.\nWhether or not\nhe\nwould\nthink\nof\nthem\nbefore system development, he ks like.ly to\nwant that flexibility later.\nThe\nsearch\nfor\na\nminimal\nsubset\nand\nminimal extensions can best be shown by an\nexample.\nOne example of a minimal\nsubset\nis\ngiven in [ 4].\nAnother example will be\ngiven later in this paper.\nB.\nInformation\nhiding:\n~nterface\nand\nsod ule definition.\nIn an earlier section we touchea upon\nthe\ndifference\nbetween\nthe\nmathematician's\nconcept of generality\nand\nan\nengineer's\napprc~ch to design flexibility.\nWhere the\nmathematician wants his product, a theorem\nor\nmethod\nof\nproof,\nto\nbe as\ngeneral\nas\npossible, i.e applicable, without\nchange,\nin\nas\nmany\nsituations\nas\npossible,\nengineer often must tailor aim product\nto\nthe\nsituation\nactuall~ at aand.\nLack of\ngenerality\nis\nnecessary\nto\nmake\nthe\n~ro~ ram\nas\nefficient\nor\ninexpensive as\npossible,\nif he must develop a family\nof\nprod uc ts,\nhe\ntries\nto\nisol ate\nt he\nchangeable parts in modules and to develop\nan\ninterface\nbetween\nthe module and the\nrest of the product that remains wa]id for\nall versions.\nThe crucial steps are:\na.\nIdentification of the items that\nare\nlikely to change.\nThese items\nare termed \"secrets.\"\nb.\nLocation of the specialized\ncomponents in separate modules.\nc.\nDesigning intermodule interfaces\nthat\nare\ninsensitive\nto\nthe\nanticipated\nthe\nchanges.\nThe\nchangeable\naspects\nare termed the\n\"secrets\" of the modules.\nIt is exactly this\nthat\nthe\nconcept\nof\ninformation\nhiding [5], encapsulation, or\na~straction [6]\nis\nintended\nto\ndo\nfOE\nsoftware°\nBecause software is an abstract\nor mathematical product, the\nmodules\nmax\nnot\nhave\nany\neasily recognized phxsical\nidentity.\n~hey\nare\nnot\nnecessarily\nseparately\ncompilable\nor coincident with\nmemory overlay units.\nThe interface\nmust\nbe general but the contents should not be.\nSpecialization is\nnecessary\nfor\neconomy\nand efficiency.\nThe concept of information hiding is\nvery\ngeneral\nand\nis\napplicable\nin\nmany\nof\nsoftware change situations-\nnot just\nthe\nissue\nof\nsubsets\nand extensions that we\naddress in this\npaper.\nThe\nideas\nhave\nalso\nbeen\nextensively\ndiscussed\nin the\nliterature\n[ 5,6,7,8,9].\nThe\nspecial\nimplications\nfor\nour\nproblem are simply\nthat,\nas\nfar\nas\npossible,\neven\nthe\npresence\nor absence of a component should\nbe hidden from other components.\nIf\none\npE W ram\nuses\nanother\ndirectl y,\nthe\npresence of the second program\ncannot\nbe\nfully\nhidden\nfrom\nits\nuser.\n~owever,\nthere is ~ver\nany reason for a\ncompon~t\nto\n\"know\" how many other programs use it.\nAll\ndata\nstructures\nthat\nreveal\nthe\npresence\nor\nnumber of cert4uin compon~ts\nshould be included in separate ~formation\nhiding\nmodules\nwith\nabstract interfaces\n[ 10].\nSpace and other considerations make\nit\nimpossible\nto\ndiscuss\nthis\nconcept\n£urther\nin\nthis\npaper;\nit\nwill\nbe\nillustrated\nin\nthe example.\nReaders for\nwhom this concept is new\nare\naavised\nto\nread some of the articles mentioned a~ve.\nC.\nThe virtual machine concept.\nTo\navoid\nthe\n~r oblems\nt~at\nwe\nhave\ndescribed as \"a chain of data transforming\ncomponents,\"\nit\nis\nnecessary\nto\nstop\nthinking of systems in terms o£ components\nthat\ncorrespond\nto\nsteps\nin\nthe\npr~e ssing.\nThis\nwax\nof\nthin kin g dies\nhard.\nIt\nis\nalmost\ncertain\nthat\nyour\nfirst\nintroduction\nto programming was in\nterms of a series d\nstatements\nintended\nto be executed in the order that they were\nexplained to you.\nWe are\ngoal\noriented;\nwe\nknow\nwhat\nwe\nstart with and what we\nwant to produce.\nIt is natural\nto\nthink\nin terms of steps progressing towards that\ng~l.\n~t\nis\nthe\nfact\nthat\nwe\nare\ndesigning\na\nfamily of systems that makes\nthis \"natural\" approach the wrong one.\nThe viewpoint that seems most\nappropriate\nto\ndesigning\nsoftware\nfamilies is often\ntermed\nthe\nvirtual\nmachine\napproach.\nRather\nthan\nwrite\nprograms that perform\n\nthe\ntransformation\nfrom\ninput\ndata\nto\noutput\ndata,\nwe\ndesign software machine\nexten~ons\nthat mill be useful in\nwriting\nmany\nsuch\nprograms.\nWhere our hardware\nmachine\n~rovide s\nus\nwith\na\nset\nof\ninstructions\nthat\noperate on a small set\nof data types,\nthe\nextended\nor\nvirtual\nmachine will have additional data types as\nwell\nas\n\"software\ninstructions\"\nthat\noperate\non those data types.\nThese added\nfeatures will be tailored to the class\nof\nprograms\nthat we are building.\nWhile the\nVM\ninstructions\nare\ndesigned\nto\nbe\ngenerally\nuseful, they can be left out of\na final product\nif\nthe\nuser's\nprograms\ndon't\nuse\nthem°\nThe programmer writing\nprograms Zor the\nvirtual\nmachine\nshould\nnot\nneed\nto\ndistinguish\nbetween\ni nstructi ons\nth at\nare\nim~lemen ted\nin\nsoftware\nand\nthose\nthat\nare\nhardware\nimplemented.\nTo achieve\na\ntrue\nvirtual\nmachine,\nthe\nhardware resources that are\nused\nin\nimplementing\nthe\nextended\ninstruction set must be unavailable to the\nuser\nof\nthe\nvirtual\nmachine.\n~e\nhas\ntraded\nthese\nresources\nfo~ the new data\nelements and instructions.\nAn~ attempt to\nuse\nthose resources again will invalidate\nthe concept of virtual machine and lead to\ncomplications.\nFailure\nto\nprovide\nfor\nisolation\nof\nresources\nis\none\no~\nthe\nreasons\nfor\nthe failure or some attempts\nto\nuse\nmacros\nto\nprovide\na\nvirtual\nmachine.\nThe\nmacro user must De careful\nnot to\nuse\nthe\nresources\nused\nin\nthe\nmacros.\nThere\nis\nno\nreason\nto\naccomplish\nthe\ntransformation\nfrom\nthe hardware machine\nto a\nvirtual\nmachine\nwith\nall\nof\nthe\ndesired\nfeatures\nin\na\nsingle\nleap.\nInstead we will use the machine at hand to\nimplement a few new instructions.\nAt each\nstep\nue\ntake\nadvantage\nof\nthe\nnewly\nintroduced\nfeatures.\nSuch a step-by-step\napproach turns a large problem into a\nset\nof\nsmall\nones and, as we will see later,\neases\nthe\nproblem\nof\nfinding\nthe\nappropriate subsets.\nEach element in this\nseries of virtual\nmachines\nis\na\nuseful\nsubset of the system.\nD.\nDesigning the \"uses\" st;ucture.\nThe concept of anabstract\nmachine\nis\nan\nintuitive way of thinking about design.\nA\nprecise description of the\nconcept\ncomes\nthrough\na\ndiscussion\nof\nthe\n~elation\n\"uses\" [ 11,12].\n1.\nThe relation \"uses.\"\nWe consider a system to be divided into\na\nset of ~ograms\nt3at can be invoked either\nby the normal flow of control\nmechanisms,\nby\nan\ninterrupt,\nor\nby\nan\nexception\nhandling\nmechanism.\nEach\nof\nthese\nprog rams\nis\nassumed\nto\nhave\na\nspecification\nthat\ndefines\nexactly\nthe\neffect\nthat\nan invocation of the program\nshould have.\nWe say of two programs A and B that A use__s\nB\nif\ncorrect\nexecution\nof\nB\nma~\nbe\nnecessary\nfor\nA\nto\ncomplete\nthe\ntask\ndescribed\nin its specification.\nThat is,\nA uses B\nif\nthere\nexist\nsituations\nin\nwhich the correct functioning oz A depends\nupon\nthe\na vai lability\nof\na\ncorrect\nimplementation\nof B.\nNote that to decide\nwhether A _uses B or not, one must\nexamine\nb_ot_hh\nthe\ni aple ment ation\nan_~d\nt he\nspecification of A.\nThe \"u_~_s\"\nrelation\nand\n\"invokes\"\nvery\nof re n\ncoincide,\nbut\n_uses\ndiffers\nfrom\ninvokes in two ways:\n(I)\nCertain invocations may not be\ninstances\nof\n\"u_~_~s.\"\nIf\nA0s\nspecification requires only that\nA\ninvoke\nB\n~hen\ncertain conditions\noccur, then\nA\nhas\nfulfilled\nits\nspecification when it has generated\na correct call to B.\nA is\ncorrect\neven\nif\nB is incor~.ect or absent.\n& proof o£ correctness\nof\nA\nneed\nonly make assumptions about the way\nto invoke B.\n(2)\nA program A may use B even though\nit\nne ver\nin yoke s\ni t.\nThe\nbest\nillustration of this\nis\ninterrupt\nhandling.\nMost\nprograms\nin\na\ncomputer system are onl 2 correct on\nthe\nassumption\nthat the interrupt\nhandling\nroutine\nwill\ncorrectly\nhandle\nthe\ninterrupts\n(leave the\nprocessor in an acceptable\nstate).\nSuch\nprograms\nuse\nthe\ninterrupt\nhandling routines even though\nthey\nnever\ncall\nthem.\n\"~ses\"\ncan be\nmore\nprecisely\nformulated\nas\n\"requires the ~resence o£ a correct\nversion of. \"\nsystems\nthat\nhave\nachieve~\na\ncertain\n\"elegance\"\n(e.g.,\nT.tt.E. iS],\nVenus [6])\nhave done so by having parts of the system\n\"-u_.se, other\nI~arts in such a way that the\n\"user\"\nprc~ rams\nwere\nsimplified.\nFor\nexample,\nthe transput stream mechanism in\nTo ~. E°\nuses the segmenting\nmechanism\nto\ngreat\nadvantage.\nIn contrast, many large\nand\ncomplex\noperating\nsystems\nachieve\ntheir\nsize\nand\ncomple~i ty\nby\nhav~g\n\"inde l~nde nt\" parts.\nFor\nexample,\nthere\nare\nmany\nsystems\nin\nwhich\n\"spooling,\"\nvirtual memory management,\nand\nthe\nfile\nsystem\nall perform their own backup store\noperations.\nCode\nto\nperform\nthese\nfunctions\nis\npresent\nin\neach\nof\nthe\ncomponents.\nWhenever such components must\nshare\na single device, complex interfaces\nexist.\n\nThe disadvantage of\nunrestrained\n\"usage\"\no£\neach\nothers\nfacilities\nis\nthat the\nsystem parts become highly interdependent.\nOften\nthere\nare no subsets of the system\nthat can be used before the\nwhole\nsystem\nis\ncomple re.\nIn\npractice,\nsome\nduplication of effort seems preferable\nto\na\nsystem\nin\nwhich\nnothing\nruns unless\neverything run~\n2.\nThe uses hierarchy.\nBy restricting the relation \"uses\" so that\nits\ngraph\nis loop free we can retain the\nprimary advantages of having system\nparts\n\"~se\"\neach\nother\nwhile\neliminating the\nproblems.\nIn that case it is possible\nto\nassign\nthe\nprograms\nto\nthe levels of a\nhierarchy b~ the following rules-\n2.\nLevel 0 is the set of all programs\nthat u_se_ no other program.\nLevel i is the set of all pEog£ams\nthat\nu~\nat\nleast one program on\nlevel i-I and no ~rog~am at a level\nhigher than i-l.\nIf such a\nhierarchical\nordering\nexists,\nthen\neach\nlevel\noffers\na\ntestable and\nusable subset of the system.\nIn fact, one\ncan\nget\nadditional\nsubsets by including\nonly parts of a level.\nThis\npropert 2\nis\nvery\nvaluable for the construction of any\nsoftware\nsystem\nand\nis\nvital\nfor\ndeveloping a broad family oI systems.\nThe design of the \"uses\" hierarchy\nshould\nbe one of the major milestones in a design\neffort.\nThe division of the\ns~stem\ninto\nindependently\ncallable subprograms has to\ngo on in parallel with the decisions about\nuses,\nbecause\nthey influence each otaero\n3.\nThe criteria to be\nused\nin\nallowing\none program to use another.\nWe propose to allow A \"use_~' B when all of\nthe followin 9 conditions hold:\n(a)\nA is essentially simplez because\nit uses B.\n(b)\nS is not substantially more\ncomplex\nbecause\nit is not allowed\nto use A.\n(c)\nThere is a useful subset\ncontaining E and not needing A.\n(d) There is no conceivably useful\nsubset contalsing A but not ~.\nDuring the process of designing the \"Uses\"\nrelation,\nwe\noften\nfind\nourselves in a\nsituation\nwhere\ntwo\nprograms\ncould\nobviously\nbenefit\nfrom\nusing each other\nand\nthe\nconditions\nabove\ncannot\nbe\nsatisfied.\nIn such situations, we resolve\nthe apparent con£1icts by a technique that\nwe\ncall\n\"sandwiching.\"\nOne\no£\nthe\nprograms is \"sliced\" into two parts\nin\na\nway that allows the programs to \"use\" each\nother\nand\nstill\nsatisfy\nthe\nabove\nconditions.\nIf\nwe\nfind\nourselYes in a\nposition where A would benefit ~rom\nusing\nB, but B can also benefit from using A, we\nmay split s into two programs:\nB| and B2.\nWe then allow A to use B2 and BI to use A.\nThe result would appear to be\na\nsandwich\nwith\nB as the bread and A as the filling.\nOften, we then go on to split A.\nMe start\nwith a few levels and end up with many.\nThe most frequent instances\nof\nsplitting\nand\nsandwiching case because initially we\nweD~ assuming that a \"level\"\nwould\nbe\na\n\"module\"\nin the sense of IV.\nB.\nWe will\ndiscuss this in the\nfinal\npart\nof\nthis\npaper.\n4.\nUse of the word \"convenience.\"\nIt will trouble some readers\nthat\nit\nis\nusual\nto\nuse\nthe\nword \"convenience\" to\ndescribe\na\nreason\nfor\nintroducing\na\ncertain\nfacility\nat a given level of the\nhierarchy.\nA more substantial basis would\nseem mode scientific.\nAs discussed in [ 11]\nand\n[ 13],\nwe\nmust\nassume that the hardware itself is capable\nof performing all necessary functions.\nAs\none\ngoes\nhigher\nin\nthe levels, one can\nlose\ncapabilities\n(as\nresouces\nare\nconsumed\n) -\nnot gain them.\nOn the other\nhand,\nat\nthe\nhigher\nlevels\nthe\nnew\nfunctions\ncan be implemented with simpler\nprograms\nbecause\nof\nthe\nadditional\nprograms\nthat\ncan\nbe used.\nWe speak of\n\"convenience\" to make it\nclear\nthat\none\ncould\nimplement\nany functions on a lower\nlevel,\nbut\nthe\navailability\noZ\nthe\nadditional programs at the higher level is\nuseful.\nFor each\nfunction\nwe\ngive\nthe\nlowest\nlevel\nat\nwhich the features that\nare useful for implementing that\nfunction\n(with\nthe\nstated\nrestrictions) ,\nare\navailable.\nIn\neach\ncase,\nwe\nsee\nno\nfunctions\navailable\nat\nthe\nnext higher\nlevel\nthat\nwould\nbe\nuse£ul\nfor\nimplementing\nthe\nfunctions as described.\nLf we implemented the\nprogram\none\nlevel\nlower\nwe would have to duplicate programs\nthat become available at that level.\nV.\nEXAMPLE:\nAN\nADDRESS\nPROCESSING\nSOBSXSTEM\nAs\nan\nexample\nof\ndesigning\nfor\nextensibility\nand\nsubsets, we consider a\nset of programs to\nread\nin,\nstore,\nand\nw rite\nout\nlists\nof\naddresses.\nThis\nexample has also been used, to\nillustrate\na\ndifferent\npoint,\nin [ 10 ] and has been\nused in several classroom\nexperiments\nto\ndemonstrate module interchangeability.\n\nA.\n_o._~_~asi_c_!s~s.mations_..__~_e-\nI.\nThe information items discussed in\nF_~ure\nwill\nbe the items to be\nproc~ ssed\nblf\nall\napplication\nprograms.\n2.\nThe input formats of the addresses\nare subject to change.\n3.\nThe output £ormats oz ~e\naddresses\nare subject to change.\n4.\nSome systems will use a sinsle\nfixed\nformat for input and output.\nOther systems will need the ability\nto\nchoose from several of mtput or\noutput formats at\nrun-time.\nSome\nsystems\nwill\n~\nrequired Jm which\nthe user\ncan\nspecify\nthe\nformat\nusing\nan address format definltion\nlanguage.\n5.\nThe representation o~ addresses in\nmain\nstorage will vary ~om\nsystem\nto system.\n6.\nIn most systems, only a subset of\nthe\ntotal\nset o~ addresses stored\nin\nthe\nsystem\nneed\nbe\nin\nma/n\nstorage\nat\nany\none\ntime.\nThe\nnumber of addresses needed may vary\nfrom\nsystem to system ann, in some\nsystems the num~r\no~ addresses\nto\nbe\nkept in main memory may vary at\nrun-time.\nThe following items of information will\nbe found in the addresses to be processed\nand constitute the only items of relevance\nto the application programs:\n- Last name\n- Given names (first name and possible\nmiddle names)\n- Organization (Connnand or Activity)\n- Internal identifier (Branch or Code)\n- Street address or P.O. box\n- City or nmil unit identifier\n-State\n-Zip code\n-Title\n-Branch of se~-~ice if military\n-GS grade if civil se~ice\nEach of the above will be strings of\ncharacters in the standard ~uNSI alphabet,\nand each of the above nmy be empty or blank.\nFIGURE l\nB.\nEe___P zoo~o_se___!th_s___Le~_ owi___anH___D_DSs i_sn\nDecis~_s:\nI.\nThe input and output programs w i l l\nbe\ntable\ndriven;\nthe\ntable w i l l\nspecify the format to be\nused\nfor\n2.\n4.\ninput and output.\nTae contents and\norganization of these format tables\nwill\nbe the 'secrets' oZ the i~put\nand output modules.\nThe representation of aadresses in\ncore\nwill\nbe\nthe\n'secret' of an\nAddress Storage Nodule ~ASM).\nThe\nimplementation\nch~en\nfor\nthis\nmodule\nwill\nM\nsuch\nthat\nthe\noperations ~\nchangin s a portion of\nan\naddress\nwill\nbe\nrelatively\ninexpen~ve,\ncompares to maKin 9 the\naddress table larger or smaller.\nWhen the number of a~resses\nto be\nstored\nexceeds\nthe capacity of an\nASM, prc~rams will use\nan\nAddress\nFile\nModule\n(AFM).\nAn AFM ca~ be\nmade upward compati~e\nw~th an ASM;\nprograms\nthat\nwere written to use\nASA's could operate using an AFM in\nthe\nsa~\nway.\nThe\nAFa provides\nadditional commands to\nallow\nmore\nefficient usage by p~ogr~s\nthat do\nnot\nassume\nthe\nrandom\naccess\nprope rties\nof\nan\nAS~.\nThese\nprograms new descri~\n~low.\nOur implementaton of an AFM would\nu~\nan\nASM as a submodule as ~ell\nas another submodule that\nwe\nwill\ncall\nBlock File Module &BFM).\nThe\nBFM stores blocks of data that\nare\nsufficiently\nlarge to represent a/l\naddress,\nbut\nthe\nBFM\nis\nnot\ns~cializ~d\nto\nthe\nhandling\nof\naddres~s.\nAn\nASa\nthat\nis\nused\nwithin\nan\nAFM may be said to have\ntwo\ninterfaces.\nIn\nthe\n\"normal\ninterface\"\nthat an AS~ presents to\nan outside user, an\naddress\nis\na\n~t\nof\nfields\nand\n~he\naccess\nfunctions hide or abstL'act from the\nrepre~ntation.\nFigure 2 is a list\nof\nthe\naccess\nprograms\nthat\ncomprise\nthis\ninterface.\nIn the\nsecond\ninterface,\nthe\nASM\ndeals\nwith\nblocks\nof contiguous storage\nand abstracts\nfrom\nthe\ncontents.\nThere\nare\ncommands for the AS~ to\ninput and\noutput\n'addresses'\nbut\nthe\no~rands\nare\nstorage\nblocks\nwho~\ninter ~retation\nas\naddresses\nis\nknown only within the ASa.\nThe\nAFM\nmakes\nassumptions\nabout\nthe\na ss~ia ti on\n~t ween\nbl oc~ks\nan d\nadd~ sses but\nnot\nabout\nthe\nway\nthat\nan\naddress' s\ncomponents are\nrepre~nted\nas blocks.\n~'he BFM\n/s\ncompletely\nindependent of ~he fact\nthat\nthe\nblocks\ncontain\naddress\ninformation.\nThe\nBFM\nmight,\nin\nfact, be\na\nmanufacturer\nsupplied\naccess method.\n\nACCESS FITNCTIONS WOR \"NORMAL INTEI~FACE\"\nMODULE:\nASM\nNAMF OF\nACCESS PI~O~P#M*\nI~mUT PAR#\"ETE~S\n*ADOTIT:\nasm\nX\ninteger\nX\nADDGN:\nasm\nX\ninteger\nX\nAOD L N:\nasm\nX\ninteger\nX\nADDSERV:\nasm\nX\ninteger\nX\nADDBORC:\na=m\nX\ninteger\nX\nADDCORA:\nasm\nX\ninteger\nX\nADDSORP:\naim\nX\ninteger\nX\nADDCITY:\nasm\nX\ninteger\nX\nADDSTATE:\nasm\nX\ninteger\nX\nADDZIP:\nasm\nX\ninteger\nX\nADDGSL:\nasm\nX\ninteger\nX\n$ETN UM:\nasm\nX\ninteger\nFETTIT:\nasm\nX\ninteger\n--\nFETGN:\nesm\nX\ninteger\nFETGN:\nasrn\nX\ninteger\nFETLN:\nasm\nX\ninteger\nF ETSE RV:\nasm\nX\ninteger\nF ETBO RC:\nasm\nX\nintege r\nFETCORA:\nasm\nX\ninteger\n- -\nFETSORP:\nasm\nX\ninteger\nFETCITY:\nasm\nX\ninteger\n- -\nF ETSTAT E:\nasm\nX\ninteger\nFETZIP:\nasm\nX\ninteger\nFETGSL:\nasm\nX\ninteger\nFETNUM:\nesm\n~\ninteger\nstring\nItrlng\nstring\nstring\nstring\nstring\nstring\nstring\nstring\nstring\nstring\nlsm\nstring\nstring\nstring\nstring\nstring\nstring\nstring\nstr~ng\nstrlr~J\nstring\nstring\nstring\nOUTPUT\n~'\n-\n\"~\nBm\n-\n\"~\nl|m\n\"\n-~\nISm\n-4\n85m\n- ~\na s m\n*\n\"+\nasm\n-\n~IGURE 2 -\nSYNTAX OF ASM FUNCTIONS\n*These are abreviatio~s:\nADDTIT = ADD TITI,F; ADDGN = ADD ~IVEN N~HE, etc.\n\nC.\nI.\nnodule:\nINAD:\nC~om~one___~nt_E~&~/rams.\nAddress Input\nReads in an address that is\nassumed\nto\nbe in a format\nspecified by a format table\nand\ncalls\nAS~\nor\nAYM\nfunctions to store it.\nINFSL :\nSelects a\nformat\nfrom\nan\nexisting\nset\nof\nformat\ntables.\nThe\nselected\nformat is the one that will\nbe used by INAD°\nThere\nis\na lways\na\nfo~aat selected.\nINFCR:\nAdds a new\nformat\nto\nthe\ntables\nused Oy INFSL.\nThe\nfor mat is\nspecified\nin\na\n'format\ni anguage. '\nSelection\nis\nnot\nchanged\n(i.e.,\nTNAD still uses the\nsame format table) .\nINTASEXT:\nAdds a blank table\nto\nthe\nset of input format tables.\nINTASCHG:\nRewrites\na\ntable\nin\nthe\ninput format tables using a\ndescri pti on\nin\na\nform at\nlanguage.\nSelection is not\nchanged.\nIN FDEL :\nDeletes a\ntable\nfrom\nthe\nset\nof format tables.\nThe\nselected format\ncannot\nbe\nde feted.\nINADSEL:\nR~ads in an\naddress\nusing\none\nof\na\nset of formats.\nChoice is specified\nby\nan\ninteger parameter.\nINADFO:\nReads in an\naddress\nin\na\nformat\nspecified as one of\nits parameters (a string in\nthe\nformat\ndefinition\nlanguage} .\nThe\n~ormat\nis\nselected\nand\nadded to the\ntables\nand\nsubseluent\naddresses\ncould be read in\nusing INAD.\nAddress Output\nPrints\nan\naddress\nin\na\nformat\nspecified\nby\na\nf or mat\ntable.\nThe\ninformation\nto\nbe printed\nis assumed to be in an\nASM\nand\nidentified\nby\nits\nposition in an ASM.\nOUTFSL:\nSelects a format table from\nan\neKisting\nset o£ output\nf ormat\nta~les.\nThe\nselected\nFGaMAT is the one\nthat will be used by OUTAD.\n2.\nModule:\nOUTAD:\nOUTTABEXT:\nOUTTABCHG:\nAdds a \"blank\" table to the\nset\nof\noutput\nformat\ntables.\nRewrites the contents of\na\nf or mat\ntable\nusing\ninformation\nin\na\nformat\nlanguage.\nOUTFCR:\nAdds a new\nformat\nto\nthe\nset\nof formats that can be\nselected\nby\nOUTFSL\nin\na\nf or mat\ndescription\nlanguage.\nOUT ~D EL :\nDeletes a\ntable\nfrom\nthe\nset\nof\nFORMAT tables that\ncan\nbe selectea by OUTFSL.\nOUTADSEL:\nPrints out an address using\none of a set of formats.\nOUTADFO:\nPrints out an address in\na\nformat\nspecified\nin\na\nformat definition\nlanguage\nstring, which is one oZ the\nactual\nparameters.\nThe\nformat\nis\nadded\nto\nthe\ntables and selected.\n3.\nModule:\nAddress StoraNe tASa)\nFET (Component Name} :\nThis is a set oZ\nfunctions\nused\nto\nread\ninform ation\nfrom\nan\naddress\nstore.\nReturns\na\nstring\nas\na\nvalue.\nSee F~gu~e 2.\nADD (Component Name):\nThis is a set of\nfunctions\nused\nto\nwrite information\nin an address store.\nEach\ntakes\na\nstring\nand\nan\ninteger as parameters.\nThe\ninteger\nspecifies\nan\naddress\nwithin\nzae\nASM.\nSee Figure 2.\nOBLOCK:\nTakes an integer parameter,\nreturns\na s~oraNe block as\na value.\nISLOCK:\nAccepts a storage block and\ninteger as ~arameters.\nIts\neffect\nis\nto\nchange\nthe\ncontents\no~\nan\naddress\nstore-\nwhica is\nreflected\nby\na\nchange in the values\nof the FET l~ogramso\nAS MEXT :\nExtends an a~dress store by\nappending\na\nnew\naddress\nwith\nempty\ncomponents\nat\nthe\nend\noz\nthe\naddress\nstore.\n\nAS MS,R:\n\"Shrinks\"\nthe\naddress\ns tore.\nAS MCR:\nCreates\na\nnew\naddress\nstore.\nTae\nparameter\ns~ecifies\nthe\nnumber\nof\ncomponents.\nAll components\nare initiall£ empty.\nAS~DEL:\nDeletes an exAstin 9 address\nstore.\n~.\nModule:\nBlock File Module\nt~L~' ~T :\nAccepts\nan\ninteger\nas\na\nparameter\nand\nreturns\na\n\"block.\"\nBLSTO:\nAccepts\na\nOlock\nand\nan\ninteger\nann\nstores\nthe\nb lock.\nB F~T :\nExtends\nBfM\nby\nadding\nadditional\nolocks\nto\nits\ncapacity.\n8FSHR:\nReduces the size o~ the BYM\nb~ removing some blocks.\nBFMCR:\nCreates\na f~les of blocks.\nBF~DEL:\nDeletes an existing file of\nb lock s.\n5.\nModule:\nAddress File Module\nThis modules includes\nimplementations\nof\nall of the AS~ functions except OBLOCK and\n£BLOCK.\nTo avoid confusion in the diagram\nshowing the uses hierarchy we have changed\nthe names to:\nAFMADD(Component Name}\ndefined as\nin\nFig ure 2\nAFZFET(Com~onent Marne) defined as\nin\nFig ure I\nAFMEXT\ndefined as in BF~ above\nAMFSBB\ndefined as in BF~ above\nAFMCR\ndefined as in BFM aooYe\nAFMDEL\ndefined as in B~i~ above\nD.\nUses Relation\nFigure 3 shows the us_~e_s relation\nbetween\nthe\ncomponent\nprograms.\nIt is important\nto note that we\nare\nnow\n~iscuss~ 9\nthe\nimplementation of those programs, not just\ntheir specification.\nThe u~e.~s relation is\ncharacterized by the fact that there are a\nlarge number of relatively sim~le,\nsin~l_e\n~u~p~q_se_ frograms on the lowest level.\nThe\nupper level ~rograms\nare\nimplemented\nby\nmeans\nof\nthese\nlower\nlevel programs so\nthat they too are quite simple.\nThis uses\n~e/ation\ndiagram characterizes the set of\npossible sub se ks.\n!\nI\ni\nI\nH\nr~\nuJ\nL;_\n\nE.\nDisc ussi on\nTo pick a subset, one iden~fies\nthe\nset\nof\nup~r\nlevel\n~r ograms\nthat\nthe user\nneeds and\nincludes\nonly\nthose\nprograms\nthat\nthos~\nprograms\nuse\n(directly\nor\nindirectly).\nFor example, a user who uses\naddresses in a single format does not need\nthe\ncomponent\nfrograms\nthat\ninterpret\normat\ndescription\nlanguages.\nSystems\nthat work with a small\nset\nof\naddresses\ncan\nbe\nbuilt without any BFM components.\nA program that works as a ~aery system and\nnever\nprints out a complete addi'ess would\nnot seed any Address Output com~onemts.\nThe syst£m is also easily\nextended,\nf'or\nexample,\none\ncould\nadd\na capability to\nread\nin\naddresses\nwith\nsel z- defining\nfiles.\nIf the first recor~ on a file was\na descril~-tion of the format\nill\nsomething\neiuiva~nt\nto\nthe\nformat\ndescription\nlanguage, one could write a\nprogr~\nthat\nwould\nbe able to read in that record, use\nINTABCHG to build a new format taOle,\nand\nthen read in t/~e addresses.\nPLograms that\ndo things with addresses\n{such\nas\nprint\nout\n\"~rsonalized\"\nform letters)\ncam also\nbe\nadded\nusing\nthese\nprograms\nand\nselecting\nonly\nthose\nca~abilit ies\nthat\nthey actually need.\nOne other observation that can be made\nis\nthat\nthe upper level programs can be used\nto \"generate,' lower level\nvers/ons.\nFor\nexample,\nthe format descri£tion i~guages\ncan. be used to generate\nthe\ntables\nused\nfor\nthe\nfixed format versions.\nThe~e is\nno need tot a separate SYSGEN program.\nWe will elaborate on this\nobservation\nin\nthe conclusion.\nX.\nSOME\nREMARKS\nON\nOPhRATING\nSYSTEMS:\nWHY\nGENERALS\nARE\nSUP BRIOR\nTO\nCO LO ~E LS\nAn\nearlier\nreport\n[ll]\ndiscusses\nthe\ndesign of a \"uses,' aierarch X for operating\nsystems.\nAlthough there\nhave\nbeen\nsome\nrefinements\nto\nthe\nproposals\nof\nthat\nreport, its ba~c\ncontents are\nconsistent\nwith\nthe present proposals.\nThis section\ncom~res\nthe\nap~r bach\nouzlined\nJ~\nthis\npa~er\nand\nthe\n\"kernel\"\napproach\nor\n\"nuc le us\"\nap~r bach\nto\nOS\ndesign\n[ |8,19,20].\nIt\nis\ntemp~ng\nto say that\nthe\nsuggestions\nin\nthis\npaper\ndo\nnot\nconflict\nwith\nthe\n\"kernel\"\napproach.\nThese\nproposals\ncan\nbe\nviewed\nas\na\nrefinement\nof\nthe nucleus approach.\nThe\nfirst few levels of our\nsystem\ncould\nbe\nlabeled\n\"kernel,\"\nand one could conclude\nthat\nwe\nare\nj us,\ndiscussing\na\n~in e\nstructure within the kernel.\nTo yie/~ to ~at\ntemptation\nwould\nbe\nto\nignore an es~ntial\ndifference between the\napproaches suggested in this paper and the\nkernel approach.\nThe system keLneis kl,own\nto me ar£ such that scme desirable subsets\ncannot\nh~ obtai~d\nwithout ma]oL\" surgery.\nIt was assumed that the nucleus must De in\nevery system family member.\nIn the ~C4000\nsystem\nthe\ninability\n~o\nseparate\nsy~hronization\nfrom\nmessage passang has\nled some u~rs\nto\nbypass\nthe\nKernel\nto\nperform\nteletype\nhandling ~unctions.\nla\nHydra as originally ~roposed\n[ 19],\n\"type\nchecking\"\nwas\nso\nintrinsic\nto the call\nmechanism that it appeared\nimpossible\nto\ndisable\nit\nwhen\nit\nwas\nnot\nneeded or\naff bramble.*\nDrawing a line between\n\"kernel\"\nan~\nthe\nrest\nof\nthe\nsystem,\nand\np uttin g\n\"es~ ntial\"\nservices\nof\n\"critical\n~rograms\"\nin\nthe nucleus yields a system\nin which kernel features cannot be removed\nand\ncertain\nextensions\na~e impractical.\nLooking for a n/nima ! subset and a set\nof\nminimal\nindependent\nincremental function\nleads to a system in which\none\ncan\ntrim\naway\nunneeded\nfeatures,\ni\nknow\nof no\n£eature that is always\nneeded.\nWhen\nwe\nsay\nthat\ntwo functions are ~most\n~iways\nused t~e the r,\nwe\nshould\nremember\nthat\n\"almost\" is a euphemism for \"not.\"\nXT.\nSUMMATION\nThis\n~afer\ndescribes\nan\napproach\nto\nsoftware\nintended\nto\nresult\nin systems\nthat can be tailored to fit the needs of a\nbr~d\nvariety\nof users.\n~he points most\nworthy of emphasis are:\nI.\nTh_e_Re.~uirements includ~\nSubsets\nan d\nExtensions.\nIt\nis\nessential\nto\nrecognize\nthe\nidentification\nof useable subsets as part\nof the pre~minaries\nto\nsoztware\ndesign.\nFlexibility\ncannot\n~\nan\ndrier,hough,.\nSubsetability is needed, not just to\nmeet\na\nvariety\nof\ncustomers'\nneeds,\nbut to\nprovide\na\nfail-soft\nway\nof\nhandling\nsched u/~ slippage.\n2.\nAdvan taqe s\nof\nthe. Vi_rtua!_ Mac~ne\n_A~a_c~.\nDesigning software as\na\nset\nof\nvirtual\nmachines\nhas deflate\nadvantages over the\nconventional\n(flow\nchart)\napproach\nto\nsystem\ndesign.\nThe\nvirtual\nmachine\n\"instr,,ions\"\nprovide facilities that are\nuseful\nZor\npurposes\nbeyond\nthose\nbrig iaally conceived.\nThese\ninstructions\ncan\neasily\nbe\nomitted\nfrom a system if\n*Accurate reports on\nthe\ncurrent\nstatus\nand\n~erformance\nof\nthat\ns?stem are not\navailable to me.\n\nthey are not needed.\nRemove a\nmajor\nbox\nfrom\na\nflow\nchart\nand there is often a\nneed to \"fill the\nhole\"\nwith\nconversion\npr og ra ms.\n3.\n_on____th_e___Di_~f~_ere~ce__ s e~_~een__ s_~_~ ~a_~_Se\n~_.e_ ra tit_x_an~ s__o~_~__~are_S_~_!e__xA~il i_~_X.\nSoftware can be considered \"general\" if it\ncan\nbe used, without change, in a variety\nof situations.\nSoftware can be considered\nflexible,\nif\nit\nis easiIy_g_hhan~e_~ to be\nused\nin\na\nvariety\nof\nsituations.\nIt\nappears\nunavoidable\nthat there is a run-\ntime\ncost\nto\nbe\npaid\nfo~\ngeneral it y.\nClever\ndesigners\ncan achieve flexibility\nwithout\nsignificant\nrun-tAme\ncost,\nbut\nthere\nis\na design-time cost.\nOne should\nincur the design-time\ncost\nonly\ni£\none\nexpects\nto\nrecover\nit\nwhen changes are\nmade.\nSome organizations may choose to\npay\nthe\nrun-time\ncost for generality.\nThey build\nge~ral\nsoftware\nrather\nthan\nflexible\nsoftware\nbecause\nof\nthe\nmainten~ ce\nproblems\nassociated\nwith\nmaintaining\nseveral\ndifferent\nversions.\nFactors\ninfluencing this decision include {a}\nthe\navailability\nof extra ccmputer resources,\n(b) the facilities for program change\nand\n~inte na ace\na vai lable\nat\neach\ninstallation, and (c) the extent to\nwhich\ndesign\ntech ni~ues\nease\nthe\ntask\nof\napplying the same change to many\nversions\nof a program.\nNo\none\ncan\ntell\na\ndesigner\nhow\nmuch\nflexibility and generality should be built\ninto a product, but the decis~ion should be\na\nconseious one.\nOften, it just happens.\n4.\nOn the.di s tinctiRn\nb_etetw_e_ee_e.~nen__mo\nd ul_es,\ns,b~_oS_za_ms_L_a_n_~d__leJ~e!_s.\nSeveral\nsystems\nand\na~\nleast\none\ndissertation\n[lq,15,16, 17 ] have,\ni.l my\no~inion, blurred the\ndistinction\nbetween\nmodules,\nsubprograms\nand\nlevels.\nConventional\nprogramming\ntechniques\nconsider\na\nsubroutine\nor other callable\nprogram to be a module.\nIf one wants\nthe\nmodules\nto include all prcgr~s\nthat must\nbe designed togei/ler and changed together,\nthen, as ou~ example illustrates, one will\nusually include many small subprograms\nin\na\nsingle\nmodule.\nIt doe~'t\nmatter what\nword we use; the point is that the unit of\nchange\nis\nnot\na\nsingle\ncall able\nsubprogram.\nin several\nsystems,\nmodules\nand\nlevels\nhave\ncoincided\n[ Iq,15].\nThis had led to\nthe phrase \"level of\nabstraction.\"\n~ach\nof\nthe\nmodules\nin\nthe example abstract\nfrom some detail that is assumed likely to\nchange.\nHowever,\nthere\nis\nno\ncorrespondence between modules and levels.\nFurther,\nI\nhave\nnot\n£oun~\na relation,\n\"more abstract than,\" that would allow\nme\nto\ndefine\nan abstraction hierarchy [ 12]o\nAlthough I am myself guilty Of\nusing\nit,\nin\nmost\ncases\nthe\nphrase\n\"levels\nof\nabstraction\" is an abuse of language.\nJanson has suggested that a design such as\nthis\none\n(or\nthe one discussed in [ 11])\ncontain \"s~t\nmodules\" that can\nrepresent\na\nbreach\nof\nsecu rit~\nprinciples.\nObviously an error in any program\nin\none\nof\nour\nmodules can violate the integrity\nof that module.\nAll module programs\nthat\nwill be included in a given subset must be\nconsidered in proving the\ncorrectness\nof\nthat\nmodule.\nHowever, I see no way that\nallowing the component programs to\nbe\non\ndifferent\nlevels\nof\na\n\"use~' hierarchy\nmakes this process more difficult or makes\nthe system less secure.\nThe boundaries of\nour modules are\n~uite\nfirm\n~d\nclearly\nidentified.\nThe\nessential\ndifference\nbetween\nthis\npaper\nand\nother\ndiscussions\nof\nhierarchically structured designs\nis\nthe\nemphasis\non\nsubsets\nand extensions.\nMy\nsearch for\na\ncriterium\nto\nbe\nused\nin\ndesigning the uses hierarchy has convinced\nme that if one d~s\nnot\nc~ire about\nthe\nexistence\nof\nsub~ts,\nit doesn't really\nmatter\nwhat\nhierarch X\none\nuses.\nAny\ndesign\ncan ~\nbent until it works,\nit is\nonly in the\nease\nof\ndecomposition\nthat\nthey di/fe r.\n5.\nOn Av__oidinS_) u)l_icatio__n.\nsome earlier work [21] has suggested\nthat\none\nneed s\nto\nh ave\nd upli care\nor\nn ear\nduplicate\nmo~ ules\ni n\na\nbier ar chicall y\nstructured\nsyste m-\nFor\nexample,\nthey\nsuggest t~at ode n~ds\none\niaplemeutation\nof\npriests\nto\ngive\na fixed number of\nprocesses at a low level\nmud\nanother\nto\n~rovide\nfor a varying num~r\nof processes\nat a user's\nlevel.\nSimilar\nideas\nhave\nappeared elsewhere.\nMere suc~h duplication\nto be\nnecessary,\nit\nwould\nbe\na\nsound\nargument\nagainst\nthe use o£ \"structured\"\napproaches.\nOne\ncan\navoid\nsuch\nduplication\nif\no~\nallows\nthe programs\nthat vary the size of a data structure\nto\nbe\non\na\nhigher\nlevel\nthan\nthe\nother\npro9 ra ms\nthat\noperate\non\nthat\ndata\nstructure.\nFor\nexample, in a~ operating\nsystem, the programs to create and\ndelete\npr~esses\nneed not be on the same level as\nthe\nmore\nfrequently\nused\nscheduling\no~e rations.\nIn\ndesigning\nsoftware,\nI\nrega rd\nthe\nneed\nto\nper £orm\nsireil ar\nfunctions in two programs as ~\nindication\nof a fundamental error in my thinking.\n6.\n_De_s_ii~_ni_n~_f_~rSubsets_.~and _~_~tensions\ncan\n~educe the Need for Support Software.\nwe have already mentioned that t~is design\napproach\ncan\neliminate\nthe\nneed\nfor\n\nsepa rate SXSGE N\nprograms,\nWe\ncan\nalso\neliminate\nthe\nneed\nfor\ns_.~_c_ia! purpose\ncompilers.\nThe price of\nthe\nconvenience\nfeatures\noffered\nby\nsuch\nlanguages\nis\noften\na\ncompiler\nand\nrun-time\npackage\ndistinctly\nlarger\nthan\nthe systeJa being\nbuilt.\nIn\nour\napproach,\neach\nlevel\nprovides a language extention available to\nthe prGgrammers of\nthe\nnext\nlevel.\nWe\nnever\nbuild a compiler; we just build our\nsystem, but we\nget\nconvenleno~\nfeatures\nanyway.\n7.\nEKte nsion\nat R_un-~ime\nVs. Extension\nDu~_~_S_,__S ~_E~~.\nAt a later stage in\nthe\ndesign\nwe\nwill\nhave\nto\nchoose\ndata structures and take\nthe difference between run-time\nextension\nand\nS~SGEN\nextension into consideration.\nCertain data structures\nare\nmore\neasily\naccessed\nbut\nharder\nto e~ztena wh/le the\nprogram\nis\nrunning:\nothers\nare\neasily\nextended\nbut\nat\nthe expense of a higher\naccess cost.\nThese\ndifferences\ndo\nnot\naffect\nour early design decisions because\nthey are hidden in modules.\n8.\nOn the ~alne of a model.\nMy work on this example and\nsimila~\nones\nha S\ngone\nmuch\nfaster\nl~cause\n~\nhave\nlearned to exploit a pattern that Z\nfirst\nnoticed\nin\nthe design diz~:ussed in [ 11 ].\nLow level o~erations assume the\nexistence\nof\na\nfixed\ndata structure of some type.\nThe operations on the next level allow the\nswapping\nof\na\ndata\nelement with others\nfrom a fixed set of similar elements.\nThe\nhigh level programs allow the creation ~und\ndeletion\nof\nsuch\ndata\nelements.\nThis\npattern\nappears\nseveral\ntimes\n~n\nMth\ndesigns.\nAlthough\nI\nhave\nnot\ndesigned\nyour\nsystem\nfor\nyou, i believe that yo~\ncan take advantage of a\nsimilar\npattern.\nIf\nso, this pai~r has served its purpose.\nAC KNOW IEDG ME NTS\nThe ideas presented\nin\nthis\npaper\nhave\nbeen\ndevelofed\nover a lengthy period and\nwith the\ncooperation\nand\nhelp\nof\nmany\ncollaborators.\n~he\nearliest\nwork\nwas\nsupported\nby\nN¥\nPhili ~s\nComputer\nindustrie, A~eldoorn, The Netherlands, amd\n£\nam\ngrateful\nto\nnumerous\nPhilips\nemployees\nfor\nthGught provoking comments\nand\nquestions.\nWilliam\nPrice's\ncollaboration\nand\nNSf\nsupport\nwere\ninvaluable at Carnegie-Mellow\nUniversity.\nThe support of the German Federal Ministry\nfor Research and ~echnology (BMFT} and the\nhelp\nof\n~. 8artussek,\nG. Haundzel,\nand\nH. Wuerges at\nthe\nTechnische\n~ochschule\nDarmstadt led to substantial imrrovements°\nKathryn Heninger, David\nWeiss,\nand\nJohn\nShore\nat\nthe\nNaval\nResearch La~JEator y\nhelped me to understand the application of\nthe concepts in areas other than operating\nsystems.\nBarbara Trombka and John\nGuttag\nboth helped in the design of pilots of the\naddress process system.\nDiscussions\nwith\nP. J. Courtois\nhave\nhelped\nme to better\nunderstand the relation\nbetween\nsoftware\nstructure\nand run-time characteristics of\ncomputer\nsystems.\nDr. Edward\nBritton,\n~r. H.\nRettenmaier,\nBr. Laslo\nBe.lady,\nDr. Donald\nStanat,\nG. Frank,\nand\nDr. William\nWright\nmade\nmany\nhelpful\nsuggestions about an earlier draft of this\npaper.\nIf you find portions of this paper\nhelpful, these people deserve your thanks.\nRE ~ER ENC ES\n[ ]]\nDijkstra,\nE.W.\n*\nDis_cia!ine____of\nProi~amain ~.\nPrentioe-Hall, 1976.\n[ 2]\nParuas,D.L.\n\"On\nthe\nDesign\nand\nDevelopment\nof\nProgram\nFamilies.\"\nI E~E\nTransactions\non\nSoftware\nEn qineer/a g,\nMarch 1976.\n[ 3]\n2nd\nInternational\nConference\non\nSoftware\nEngineering, 13-15 Octobe~r 1976;\nS pecia I\nissue\nof\nIEEE\nTransactions\non\nSoftwa~.Knqineerin~,\n~cember\nt97b.\n[ ~]\nParnas,\nD.L.,\nHandzel,\nG.,\nand\nH. Wuerges.\n\"Design and Specification of\nthe Minimal Subset of an Operating\nSystem\nFamily.\"\nPresented\nat 2nd International\nConference on Software Engineering,\n|3-15\nOctober\n1976;\npublished in special issue\nof\nZEEE\nTransactions\non\nSoftware\nE_nqineerin~, December 1976.\n[ 5]\nPumas,\nD.L.\n\"On the Criteria to be\nUsed in Decomposing Systems into Modules.\"\nC__omm._ AC._.~M,Decem~r\n1972.\n[ 6]\nLinden, T.A.\n\"The Us~\nof\nAbstract\nData\nTy[es\nto\nSimplify\nProgram\nModifications.\"\nProceedings o£ Conference\non\nData:\nAbstraction,\nDefinition\nand\nStructure, March 22-2~, 1976; published in\nACM S_IGP_LAN N_o_tice_s, Vol. Ii, 1976 Special\nIssue.\n[ 7 ]\nParnas,D.L.\n\"A\nTec~nilue\nfor\nSoftware\nModule\nSpecification\nwith\nExamples.\"\nComm. ACM, May 1972.\n8]\nPumas,\nDistribution\nMethodology.\"\nD.L.\n\"I n formation\nAspects\nof\nDes ign\n[ 9]\nPumas,\nD.L.\n\"The\nUse\nof\nPrecise\nSpecifications\nin\nthe Development\nof\ns of t wa re. \"\nP_~oc_L__~!_1p__ c on~ces_sL__j_gl2,\nNorth Holland Publishing Company.\n\n[ 10 ]\nParnas,\nD.L.\n\"Use\nof\nAbstract\nInterfaces\nin the Development o~ Software\nfor\nEmbedded\nComputer\nSystems.\"\nI~RL\n~eport\n8047,\n~aval\nResearch\nnabozatory,\nWashington,\nB.C.,\nJune\n1977.\n[ |I]\nParnas, D.L.\n\"Some Hypotheses About\nthe\n'Uses'\nHierarchy\nfor\nOperating\nSystems. \"\nTechnical\nReport,\n~echnische\nH ochschule\nDarmstadt,\nDarmstadt,\n~est\nGermany, March 1976.\n[ 12]\nPa rnas,\nD.L.\n\"On\na\n' Buzzword' :\nHierarchical\nStructure.\"\nProc. _/Fl_P__qo_n~r_ess~_ 197_4,\n~ ortn\naol I an d\nPublishing Company, 1974.\n[ I_]]\nParnas,\nD.L. and\nD.L. Siewlore~.\n',Use of the Concept of Transparency in the\nDesign\nof\nHierarchicall~\nStructur ed\nSystems.\"\nCO@_m.__AC~_,.__]8 I_7), July 1975.\n[ 1~,]\nDijkstra, E.W.\n\"The\nStructure\nof\nthe \"THE\"-Moltiprogramming\nSystem.\"\nCA CMM,\n|1, 5 {~ay 1968), ~p. 341-340.\n[ 15]\niiskov, E.\n\"The Design of the Venus\nO~erating\nSystem.\nCACM,\n15,,\n(March\n1972), pp. 144-149°\n[ 16]\nJanson, P.A.\n\"Using Type\nExtension\nto\nOrganize\nVirtual\nMemo=y zechanisms°\"\nM[T-LCS-TR-167,\nLab. for\nComptr. Sci.,\nM.I.T.,\nCambridge, Mass., September 1976.\n[ 17 ] Janson, P.A.\n\"Using\nType-Extension\nto\nOrganize\nVirtual\n~'1emote y Mechanisms.\"\nResearch Report BZ 858\n{#2~909)\n8/31/77,\nIBM\nZurich\nResearch\nLaboratory,\nSwitzerland.\n[ 18]\nBrinch-Hansen, P.\n\"The\nnucleus\nof\nthe Multiprogramming\nSystem.,,\n_CACM_, 13, 4\n(April 1970), pp. 238-2~I, 250.\n[ 19]\nWulf,\nW.,\nCohen,\nE.,\nJones,\nA.,\nLewin,\nR.,\nPierson,\nC., and ¥.\nPollack.\n\"HYDRA:\nThe KeL nel\nof\na\nM ultipro cessor\nO~era ting\nSystem. \"\nCA C@,\n17,\n(June\n1974), p~. 337-345.\n[20]\nPo~ek,\nG.J. and\nC.S. Kline.\n\"The\nDesign\no£\na Verified Protection System.\"\nP~oc. Intl. WorksJ~op\non\nProt. in\nO~er. Syst., I~IA, pp. 1 18~-196.\n[21]\nSaxena,\nA.H. and\nT.~. bredt.\n\"A\nStructured Specification of a Hierarchical\nOperating\nSystem. \"\nP r ocee~s__~o f\nthe\nInternational Conference on Reliab~\nSoftware."
    }
  ]
}