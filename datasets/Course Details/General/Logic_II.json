{
  "course_name": "Logic II",
  "course_description": "This course begins with an introduction to the theory of computability, then proceeds to a detailed study of its most illustrious result: Kurt Gödel’s theorem that, for any system of true arithmetical statements we might propose as an axiomatic basis for proving truths of arithmetic, there will be some arithmetical statements that we can recognize as true even though they don’t follow from the system of axioms. In my opinion, which is widely shared, this is the most important single result in the entire history of logic, important not only on its own right but for the many applications of the technique by which it’s proved. We’ll discuss some of these applications, among them: Church’s theorem that there is no algorithm for deciding when a formula is valid in the predicate calculus; Tarski’s theorem that the set of true sentence of a language isn’t definable within that language; and Gödel’s second incompleteness theorem, which says that no consistent system of axioms can prove its own consistency.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Theory of Computation",
    "Humanities",
    "Philosophy",
    "Logic",
    "Mathematics",
    "Mathematical Logic",
    "Engineering",
    "Computer Science",
    "Theory of Computation",
    "Humanities",
    "Philosophy",
    "Logic",
    "Mathematics",
    "Mathematical Logic"
  ],
  "syllabus_content": "A list of topics by lecture is available in the\ncalendar\nlisted below.\n\nCourse Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nDescription\n\nWe'll begin with an introduction to the theory of computability, then proceed to a detailed study of its most illustrious result: Kurt Godel's theorem that, for any system of true arithmetical statements we might propose as an axiomatic basis for proving truths of arithmetic, there will be some arithmetical statements that we can recognize as true even though they don't follow from the system of axioms. In my opinion, which is widely shared, this is the most important single result in the entire history of logic, important not only on its own right but for the many applications of the technique by which it's proved. We'll discuss some of these applications, among them: Church's theorem that there is no algorithm for deciding when a formula is valid in the predicate calculus; Tarski's theorem that the set of true sentence of a language isn't definable within that language; and Godel's second incompleteness theorem, which says that no consistent system of axioms can prove its own consistency.\n\nThe text for the course will be\nlecture notes\n.\n\nGrading\n\nThere will be homework assignments every week or two, and they will be the basis for your grade in the course. I would encourage you to work together on the homework, but when you finally sit down to write up your answers, you should work by yourself without looking at anyone else's efforts.\n\nCalendar\n\nLEC #\n\nTOPICS\n\nKEY DATES\n\nWhy Study Computability?\n\n2-3\n\nKey Computability Concepts\n\nThe Language of Arithmetic\n\nChurch-Turing Thesis\n\nNonstandard Models of Arithmetic\n\nGodel Numbering\n\nHomework 1 due\n\nRobinson's Arithmetic\n\nHomework 2 due\n\n9-10\n\nCoding Proofs\n\n11-12\n\nPeano Arithmetic\n\nHomework 3 due in Lec #12\n\n13-14\n\nSelf-Reference Lemma\n\n15-16\n\nFirst Incompleteness Theorem\n\nHomework 4 due in Lec #16\n\nInterpretations\n\nTarski's Theory of Truth\n\nHomework 5 due\n\nGodel, Mechanism, and Mind\n\nArticles by Lucas and Benacerraf\n\n20-21\n\nSecond Incompleteness Theorem\n\nHomework 6 due in Lec #21\n\nIntroduction to Modal Logic\n\n23-24\n\nProvability Logic\n\nHomework 7 due in Lec #23\n\nDefining Exponentiation\n\nHomework 8 due",
  "files": [
    {
      "category": "Resource",
      "title": "hw1_solutions.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/a7f3c362d9fbb186d02dfade985dc257_hw1_solutions.pdf",
      "content": ""
    },
    {
      "category": "Resource",
      "title": "hw1sample.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/82e189138094e97564ff891424483d5a_hw1sample.pdf",
      "content": "Subject 24.242. Logic 11. Sample problems from the fust homework, due February 26\n1.\nWrite down a bounded formula whose extension is the set of triples e,y,z> such that x,y, and z\nare positive integers and z is a common divisor of x andy.\n2.\nDefine, for F,a finite set of natural numbers, CodeQ to be\nZEx,so that Fis the set of places\nxEF\nin the binary decimal expansion of CodeQ where 1s appear. Give the Arabic numeral for\nCode({2,4,6,8})."
    },
    {
      "category": "Resource",
      "title": "hw1sampleans.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/a7c7e14401362f72cb70944883977c1b_hw1sampleans.pdf",
      "content": "Subject 24.242. Logic 11. Answers to the first sample homework.\n1.\nWrite down a bounded formula whose extension is the set of triples e,y,z> such that x,y, and z\nare positive integers and z is a common divisor of x and y.\n(((0 < x A 0 <y) A 0 <z) A ((3u < sx)(uz) =x) A (3v< sy)(vz) =y)).\n2.\nDefine, for F, a finite set of natural numbers, CodeQ to be\nZEr, so that F is the set of places\nxEF\nin the binary decimal expansion of CodeQ where 1s appear. Give the Arabic numeral for\nCode({2,4,6,8}).\nCode({2,4,6,8)) = (2E2) + (2E4) + (2E6) + (2E8) = 4 + 16 + 64 + 256 = 340."
    },
    {
      "category": "Resource",
      "title": "hw2sample.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/d0a3ee8c5a2c812a8801c9ec8b5799a7_hw2sample.pdf",
      "content": "Subject 24.242. Logic 11. Sample problems from the second homework, due March 4.\nA register machine consists of an infinite number of memory locations, named Register 1, Register 2,\nRegister 3, and so on, each of which is capable of holding a natural number. A registerprogram is a finite\nnumbered list of instructions, which take the following five forms:\nAdd 1 to the number in Register i.\nSubtract 1 from the number in Register j, unless that number is already 0.\nIf the number in Register k is 0, go to instruction m\nGo to instruction n.\nSTOP.\nA computation starts at the first instruction, and proceeds from an instruction to the next, unless instructed\notherwise. To calculate an n-ary partial function, begin with the inputs in Registers 1 through n, and with\nzero in all the other registers. If the computation eventually reaches the STOP instruction, the computation\nhalts, and the number in Register 1 is the output. If the computation never reaches the STOP instruction, the\nfunction is undefined for that input. For example, the following program computes the successor function:\n1. AddltoRegisterl.\n2. Stop.\nThe following program computes the characteristic hction of the identity relation, the binary function that\nyields output 1 if x =y and 0 if x + y:\n1. If the number in Register 1 is 0, go to instruction 6.\n2. If the number in Register 2 is 0, go to instruction 10.\n3. Subtract 1 from the number in Register 1, unless that number is already 0.\n4. Subtract 1 from the number in Register 2, unless that number is already 0.\n5. Go to instruction 1.\n6. If the number in Register 2 is 0, go to instruction 8.\n7. STOP.\n8. Add 1 to the number in Register 1.\n9. STOP.\n10. Subtract 1 from the number in Register 1, unless that number is already 0.\n11. If the number in Register 1 is 0, go to instruction 9.\n12. Go to instruction 10.\n1.\nWrite a register program that calculates (x +y).\n2.\nShow that a set is A if and only if its characteristic function is x.(The characteristicfinction X, of a\nset Sis given by stipulating that xdn) = 1 if n E S, and it's equal to 0 if n @ S.)"
    },
    {
      "category": "Resource",
      "title": "hw2sampleans.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/03fa4666e98d99cc0b1ddcee41c3fc22_hw2sampleans.pdf",
      "content": "Subject 24.242. HW Sample answers.\n1.\nWrite a register program that calculates (x + y).\n1. If Register 2 is 0, go to 5.\n2. Subtract 1from Register 2, unless it's 0.\n3. Add 1to register 1.\n4. Go to 1.\n5. STOP.\n2.\nShow that a set is A if and only if its characteristic hction is x.(The characterkticfinction X, of a\nset S is given by stipulating that XJn) = 1 if n E S, and it's equal to 0if n B S.\n(*) If the set Sis A, then there are bounded formulas q(x,y) and @(x,y) such that S= {x:\n(3y)q(x,y), and its complement is {x: (3y)@(x,y)}. Then h i s equal to {qp:(3y)((cp([x]#) A z\n= so) V (Jr(x,y) A z = 0)).\n(*) Suppose &is A; say it's {Qp:\nand\n(3z)8([x],b],z). The Sis equal to {x: (3~)8([x],sO,z)~\nits complement is (x: (3~)8([x],O,z)}."
    },
    {
      "category": "Resource",
      "title": "HW2Sampleanswer.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/86e496f6d2ad6b74d9e15023c1a277bf_HW2Sampleanswer.pdf",
      "content": ""
    },
    {
      "category": "Resource",
      "title": "hw3sample.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/26b4c0c16dc311c0adb839ea99c0faa0_hw3sample.pdf",
      "content": "Subject 24.242. Logic 11. Sample problems from the third homework, due Thursday, March 18\nFor each term T, we have defined a code number 'V, according to the following prescription:\nPair(x,y)is, you will recall, %(x+y)(x +y + 1 ) +x.\n1 .\nGive the Arabic numeral for r(0+011.\n2.\nShow that a set of natural numbers is decidable if and only if it is either finite or the range of an\nincreasing calculable total function. (A total function f is increasing iff, for any x andy, if x <y,\nthen.@) <&).I"
    },
    {
      "category": "Resource",
      "title": "hw3sampleans.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/9f87d9cc6dc1b123c1fbdf0ecf00b7dd_hw3sampleans.pdf",
      "content": "Subject 24.242. Logic 11. HW3 Sample Answers\nFor each term T, we have defined a code number 'V, according to the following prescription:\nPair(x,y) is, you will recall, %(x + y)(x + y + 1 ) + x.\n1 .\nGive the Arabic numeral for r(0 + 011.\nTriple@, rDl, rD1) = Pair(S,Pair(@l, @I)) = Pair(S,Pair(4,4)) = Pair(5,40) = 1040.\n2.\nShow that a set of natural numbers is decidable if and only if it is either finite or the range of an\nincreasing calculable total function. (A total function f is increasing iff, for any x and y, if x < y,\nthenf(x) <Rv).)\n(*) IfS is ininfite, it is the range of the following increasing total function:\nf(O) = the least element of S.\nfln+l) = the least element of S greater thanfln).\nIf S is decidable, f can be calculated by testing the natural numbers, one after another, for\nmembership in S.\n(=)A fmite set is obviously decidable, just by incorporating a list of the set into the\nprogram. IfS is the range of an increasing, calculable total functionf, we can test whether\nn is an element of S by calculatingflO),fll), fl2), and so on, until we reach an i withflz3 2 n.\nIfflz') = n, then n is in S. Ifflz') > n, then n rE S."
    },
    {
      "category": "Resource",
      "title": "HW3SampleAnswers.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/94c99d32a3fc6b347488703966b48f6a_HW3SampleAnswers.pdf",
      "content": ""
    },
    {
      "category": "Resource",
      "title": "hw4sample.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/e54af08ef5dedb9f2451fbbe7a99e295_hw4sample.pdf",
      "content": "Subject 24.242. Logic 11. Sample problems from the fourth homework, due April 8\nDefine the restricted sentential calculus (RSC)as follows: The atomic RSC sentences are \"A,,\"\n\"A,,\" \"A,,\",\nand so on, and the RSC sentences are the atomic sentences and expressions formed\nkom RSC sentences by one or more applications of the operations of forming conditionals\n(sentences of the form ( 4 - q)) and negations (sentences of the form -4). A normal huth\nassignment (NTA) is a functions 3taking the RSC sentences to {0,1) that meets these conditions,\nfor any 4 and q:3((4 - q)) = 1 iff either 3(4) = 0 or 3($) = 1 (or both); 3(-4) = 1 iff a($) =\n0. An RSC sentence is a tautology iff it's assigned the value 1by every NTA.\nAn RSC derivation is a finite sequence of sentences, each with an associated f i ~ t e\npremise set of\nsentences, conforming to the following rules:\nYou may write 4 with {I$) as its premise set.\n(CP) If you've written $ with I? as its premise set, you may write ( 4 - JI) with I?- {@) as\nits premise set.\n)\nIf you've written ( 4 - q ) with r as its premise set and you've written 4 with A as its\npremise set, you may write q with I? u A as its premise set.\n(MT) If you've written (-4 - -q) with I? as its premise set and you've written $ with A as its\npremise set, you may write 4 with\nu A as its premise set.\nWe encode the RSC numerically by associating with each RSC sentence 4 a code number re,\naccording to the following stipulation:\n1.\nGive a derivation of of the following sentence fiom the empty set of premises:\n(a) ((-40 - 4 ) - ( ( 4 - 4 ) - (A0 -A2)))\n2.\nShow that the set of codes of RSC sentences in x.(You don't need to go all the way to\nprimitive notation here; you may use reasonable abbreviations.)\nLearned commentary. In Benson Mates's book, Elementay Logic, you can find a proof that an\nRSC sentence is derivable fiom the empty set iff it's a tautology. Putting this observation\ntogether with the results of problems 4 and 5, we can conclude that the set of code numbers of\ntautologies is A. This is a striking difference between sentential calculus and predicate calculus.\nChurch's Theorem, which we'll prove shortly, tells that the set of valid sentences of the\npredicate calculus, though 2, is not A."
    },
    {
      "category": "Resource",
      "title": "chuh_trng_thesis.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/489f7e42fb619645158d7c21a8fb83ad_chuh_trng_thesis.pdf",
      "content": "The Church-Turing Thesis\nWe now know that every 2 set or relation is effectively enumerable. The central thesis of\nrecursion theory is that the converse also holds, so that we have:\nChurch-Turing Thesis. A set or relation is effectively enumerable iff it's 2.\nSince we know that a set is decidable iff it and its complement are both effectively enumerable,\nand we also know that a set is A iff it and its complement are both 2 , we see that the Church-\nTuring thesis entails that a set or relation is decidable iff it's A. Also, a partial function is\ncalculable iff it's x , and a total function is calculable iff it's A.\n\"Calculable\" here means calculable in principle: there is a mechanical procedure that, if\ncarried out tirelessly and without error, will compute the function. The notion makes no\nallowance for senility, death, or limited disk space. If a computation takes up more bits of\nmemory than there are particles in the universe, we still allow it. The theoretical aim is to give an\nextreme outer limit of what it's possible to compute, then to leave it to more practical-minded\nengineers to attempt to approximate that ideal in practice.\nOne cannot hope rigorously to prove the Church-Turing. Before we can rigorously prove\nthings about decidability and effective enumerability, we first have to have mathematically\nprecise characterizations of those notions, and we are looking to the thesis to give us such\ncharacterizations. There is, however, quite a body of evidence in the thesis' favor. Let us now\nsurvey some of it.\nThe biggest piece of evidence is simply that every known enumeration procedure\ngenerates a 2 set and every known decision procedure determines a A set. It's more than that.\nEvery know enumeration procedure produces a set that is obviously x. Once you know a few\ntricks of the trade, it will be easy, once you know an algorithm of producing a set, to write down\n\nChurch-Turing Thesis, p. 2\na x formula that describes the set. The only times we get stuck is when we don't really know the\nalgorithm, or we don't know it explicitly. For example, we don't know how to write down a x\nformula that lists the code numbers of grammatical English sentences, but that's because, even\nthough we presume there is an algorithm that generates the set, we don't know what it is.\nAfter the Church-Turing thesis was proposed during the 1930s, a fair amount of effort\nwas devoted specifically to the program of showing the thesis to be false by presenting a\ndecision procedure that wasn't A. None of these efforts got anywhere. The utter failure to obtain\na counterexample to the thesis makes it quite likely that there is no such counterexample, and it\nmakes it a moral certainty that, if there is a counterexample, it must be an algorithm that is quite\nunlike any algorithm that we have today.\nThere are certain standard procedures for taking familiar algorithms and using them to\ncreate new algorithms; for example, substitution and recursive definition. The fact that the class\nof x partial functions is closed under all known techniques of this sort is another bit of evidence\nin favor of the Church-Turing thesis. Any counterexample to the thesis would have to involve\nsome completely novel method of computation. There is no hope of getting a counterexample by\ncombining familiar algorithms in complex ways.\nDuring the 1930s and 1940s, many different people were working on the problem of\nunderstanding computability, which may different approaches and perspectives. All of them\ncame up with the same answer. This convergence gives us reason to suppose that the answer they\ncame up with was the right one. Generally speaking, if different clever people working\nindependently on a problem all arrive at the same answer, this is reason to think that the answer\n\nChurch-Turing Thesis, p. 3\narrived at is the right one. This is particularly so if the methods employed by different reseachers\nare highly dissimilar, since this lessens the likelihood that they have all made the same mistake.\nIf you come upon the same concept starting from several quite different approaches, this\nis reason to suppose that the concept you have reached is a basic and natural one; for it is likely\nto avoid the arbitrariness that often afflicts concepts that are only constructed from a single point\nof view.\nLet me describe some of these methods that arrive at the identification of the effectively\nenumerable sets with the Z sets. The proofs that these methods all yield the same result is labor\nintensive and not a little tedious, so I won't attempt it here.\nTuring machines. Alan Turing, in his senior undergraduate thesis at Cambridge, attempted to\ngive a model, pared down to its bare essentials, of what a human computing agent does when\nsolving a computational problem by applying a system of rules. The agent writes symbols down\nin a zigzag fashion, starting at the left, proceeding until she reaches the right margin, then\nstarting again at the left, this time one line down. Our first simplification is to cut the lines apart\nand glue them together, so that they all lie along a single very long line. Thus our agent writes\nsymbols side-by-side along a very long tape.' Actually, we shall assume the tape is infinite, since\nBeing able to depict a problem pictorially may help us find a solution that would elude us\nif we were forced to do all our symbolic representations in one dimension. So if we were\nattempting to describe the creative processes by which new problem solutions are\ndiscovered, demanding that all our symbols be laid in a line would introduce terrible\ndistortions. But that's not our aim. We want to look at the purely mechanical\nimplementation of computational algorithms, a stage of problem-solving at which\n\nChurch-Turing Thesis, p. 4\nwe don't want to count a problem as unsolvable in principle if the only reason we've failed to\nsolve it is that we've run out of scratch paper.\nIn deciding what to write next, the agent will sometimes look back over her previous\nwork. There is no real loss of generality in supposing that the agent looks over her previous work\none symbol at a time, so that we can think of the agent as having a movable tape reader that she\npasses over the tape one symbol at a time, moving sometimes one square to the left and\nsometimes one square to the right, and pausing sometimes to erase an old symbol or write a new\none. In having her work one symbol at a time, we are just breaking down what the agent does\ninto the simplest possible steps.\nA finite, numbered list of detailed instructions tells the agent how to proceed with the\ncomputation. Things like, \"If the square you are examining is blank, write the letter 'Q' in it and\ngo to instruction 112\" and \"If the square you are examining has 'W' written in it, erase it and\nproceed to instruction 13\" and \"If the square you are examining has 'B' written in it, move one\nsquare to the right, and go to instruction 99.\" If the input number is n, the computation begins\nwith the reader at the left end of a sequence of n \"1\" on an otherwise blank tape. If, when the\ncomputation finally ends, the reader is at the left end of a sequence of exactly m \"l\"s, then m is\nthe output. If the computation never ends, then n isn't in the domain of the partial function being\ncomputed. If the machine halts on a certain input, that input is said to be accepted by a machine.\nA mechanical device that implements such a system of instructions is called a Turing\nmachine. Turing proposed such machines as a model of human computation. Of course, what the\nmachine does isn't what the human computing agent does; it's a highly simplified and stylized\ncreativity is no longer called for.\n\nChurch-Turing Thesis, p. 5\nmimicry of what the human agent does. But the differences are in inessential details, not in\nfundamental computational capacities. Everything a human compute? can do can be simulated,\nor so Turing proposes, by a Turing machine.\nThe details here are pretty arbitrary. The number of symbols can be few or many, as long\nas it's finite. The inputs and outputs can be Arabic numerals, instead of strings of \"1\"s. We can\nallow auxiliary tapes for scratch work. We can even allow indeterministic computations. These\nare machines programmed with conflicting sets of instructions, so that, at certain junctures, the\nmachine chooses, arbitrarily, which instruction to follow.\nHowever we work out the details, the result is the same. A function is computed by a\nTuring machine iff it is x. A set is accepted by a Turing machine iff it is x.\nRegister machines. Turing's machines were intended to provide a model of what human\ncomputing agents do. Register machines are intended as a model of what electronic computers\ndo. A machine contains an unlimited numbe? of memory locations or registers, and a program\nfor the machine consists of simple instructions for manipulating the numbers contained in those\nmemory locations. Thus we can add 1 to the number in a particular register; we can set a\nparticular register equal to 0; we can compare the contents of two different registers, then decide\nwhat to do next on the basis of whether the two contents are equal; and so on.\nWhen Turing talked about a \"computer,\" he meant a human computing agent, since at the\ntime he wrote, in the early 30s, elecronic computers hadn't been invented yet. During the\n40s (after the war; during the war he was busy breaking the German naval code), he went\non to build one of the first electronic computers.\nKeep in mind that we are attempting to characterize computability in principle.\n\nChurch-Turing Thesis, p. 6\nWe say that a register machine accepts a set of sentences S iff, for any n, if the machine\nis started with n in register 0 and 0 in all the other registers, the machine will eventually halt if n\nis in S, whereas if n isn't in S the computation will do on forever.\nThere is a register machine that accepts S if and only if S is X. Once again, this result is\nresilient, so that, for example, we get nothing new if we permit indeterministic register machines.\np-recursive functions. Our next characterization looks at the ways calculable functions are\ndefined in arithmetic, specifically, at the ways new calculable functions are defined on the basis\nof old ones. Two such methods we have discussed previously, substitution and recursive\ndefinition.\nFor example, if we have 0 and s, we can recursively define +, *, and E:\nx + o = x\nx + (y+l) = s(x + y)\nx*O = 0\nx*(y+l) = (xay) + x\nxEO = 1\nxE(y+l) = (xEy)*x\nHere is another way to make new calculable functions out of old:\nDefinition. Given an n-ary partial function f, pxo[f(x,,,xl, ...,a = 0] is the\nn-ary partial function defined as follows: Given <xl, ...,%> as input,\npxo[f(xo,xl ,..., %) = 0] will be defined and equal to y iff f(y,x ,,.., %) is\ndefined and equal to 0 and, for each z < y, f(z,xl, ...,a is defined and\ndifferent fiom 0.\n\nChurch-Turing Thesis, p. 7\nNotice that, even iff is total, px,[f(x,,,x,, ...,a = 01 needn't be total, for there might not be any\nvalue of x, that makes f(x,,,xl, ...,a equal to 0.\nIt's clear that, iff is calculable, pxo[f(xo,xl, ...,%) = 0] is also calculable. Just plug in\nsuccessive numbers until you get the output 0.\nDefinition. The p-recursiveJicnctions constitute the smallest class of total\npartial functions that includes the successor function, the constant function\n0 (the unary function that gives 0 for every input), and the projection\nfunctions (for each j and n, j I n, there is a projection function that takes\n<xl,x,, ...,%> to x,; we need them for bookkeeping purposes), and is closed\nunder substitution, recursive definition, and the p operator.\nA partial function is p-recursive iff it is x.\nMarkov algorithms. Our next characterization of the x sets is based upon syntactic, rather than\narithmetical, computations. We start with a finite alphabet. A word is a finite string of letters\n(including the empty string). Aproduction system is a finite set of ordered pairs of words. A\nword u is derivable from a word p iff there is finite system of transformations of the form\naApA6 - aAyA6,\nwhere <p,y> is in the production system, that begins with p and ends with o; here \"A\" denotes\nthe concatenation operation. A set of words S is accepted by given production system iff, for any\nword o, o E S iff there is a derivation of the empty word from S. A set is\niff there is a\nproduction system that accepts it.\nRepresentability in a theory. Our final characterization takes seriously the idea that, if there is\na \"proof procedure\" for S, then, if n is in S, one ought to be able to right down a description of S\n\nChurch-Turing Thesis, p. 8\non the basis of which it is possible to prove that n is in S. There must be some theory\nthat\ndescribes the natural number system and some predicate a describing S such that o([n]) is a\nconsequence of I? if and only if n is in S. We introduce a name for this state of affairs:\nDefinition. The formula o weakly represents S in the theory r just in\ncase, for any n, n is an element of S if and only if o([n]) is a consequence\nof r.\nIf n is in S, you can prove that n is in S by providing a proof of o([n]). If n isn't in S, you don't\nnecessarily have any way of proving that n isn't in S. In cases, whenever n isn't in S, you can\nprove that n isn't in S by proving -o([n]), a is said to strongly represent S:\nDefinition. The formula o strongly represents S in the theory just in\ncase, for any n, n is an element of S if and only if o([n]) is a consequence\nof I?, whereas n is outside S if and only if -o([n]) is a consequence of r.\nWe'll actually prove the following result, instead of me asking you to take my word for\nit:\nTheorem. A set natural numbers S is\niff there is a finite set of axioms\nand a formula o of the language of arithmetic that weakly represents S in\nr. S is A iff there is a formula o that strongly represents S in r.\nWhen we attempt to formalize ordinary mathematical reasoning, often we find ourselves\nworking, not within a finite system of axioms, but within a finite system of axioms and axiom\nschemata. For example, the principle of mathematical induction is represented within the\nlanguage of arithmetic, not by a single axiom, but by the induction axiom schema:\n((R(O) A (W@(x) - R(sx))) - Wx)R(x))\n\nChurch-Turing Thesis, p. 9\nEach of the infinitely many sentences you get from this schema by plugging in a formula for \"R,\"\nthen prefixing universal quantifiers to bind the resulting free variables is an induction axiom. Ow\nearlier theorem is upheld when we allow axiom schemata as well as single axioms:\nTheorem. For S a set of natural numbers, the following are equivalent:\nS is E.\nS is weakly represented within some finite system of axioms.\nS is weakly represented within some finite system of axioms and axiom\nschemata.\nS is weakly represented within some E system of axioms and axiom\nschemata.\nLikewise, the following are equivalent:\nS is A.\nS is strongly represented within some finite system of axioms.\nS is strongly represented within some finite system of axioms and axiom\nschemata.\nS is strongly represented within some\nsystem of axioms and axiom\nschemata.\nThroughout its history, mathematics has been a demonstrative science. Because of the\npreeminence of the axiomatic method in mathematical reasoning, this theorem provides potent\nevidence for the Church-Turing Thesis. If there is an algorithm that enumerates the set S, then it\nought to be possible to describe the algorithm precisely, and then to verifl mathematically that\ncomputations are correct. If this verification looks anything like traditional mathematics, it can\n\nChurch-Turing Thesis, p. 10\nbe formalized within a finite system of axioms and axiom schemata. S will be weakly\nrepresented within the axiom system, and so, according to the theorem, E."
    },
    {
      "category": "Resource",
      "title": "coding_proofs.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/31dfcdf2bebfafc1bcf14c16b2a90552_coding_proofs.pdf",
      "content": "Coding Proofs\nWhat we'd like to do now is to see how to take proofs and code them arithmetically. The\ndetails are complicated, but the idea is simple. A proof is a sequence of expressions, and we\nknow already how to code expressions as a numbers and how to code a sequence of numbers as a\nsingle number.\nA couple of technical points require attention. The logical system we learned in Logic I\nrequired an infinite reservoir of infinite constants. It's not hard to give a system of rules that\ndoesn't need the constants, but it's even easier to expand our system of Godel numbering to\naccommodate the extra constants. Where 'Sf is the language of arithmetic, let 'Sf, be the language\nobtained from 'Sf by adding infinitely many new individual constants c,, c,, c,, c,,. . . . We can\nextend our system of Godel numbering by letting rc,l be Pair(3,n). That's why we skipped pairs\nand triples beginning with 3 when we gave our earlier Godel numbering for Sf; we were leaving\nroom for the new constants.\nOur deductive calculus from Logic I included bunch of simple rules and one very\ncomplicated rule, Tautological Consequence (TC), which permits you to write down any\nsentence that is either a tautology or a tautological consequence, taking as premiss set the union\nof the premiss sets of those earlier lines. TC is complex enough that it would be a lot of work to\ndescribe its operation arithmetically. Rather than doing so, we can replace TC with a bunch of\nsimpler rules. There are many ways to do this. One method, which is particularly simple and\nwhich fits seamlessly with the system of rules we learned in Logic I, is to replace the rule TC\nwith three new rules:\nModus Ponens: If you've derived 4 with premise set r and ( 4 - q ) with premise\nset A, you may write $ with premiss set I? u A.\n\nModus Tollens: If you've derived 4 with premise set I? and (- @ - - 4) with\npremise set A, you may write @ with premise set r u A.\nDeJnitional Exchange: You may replace (4 V @) with (-4 - @) or vice versa,\nkeeping the same premise set. Similarly for (4 A @) and -(a - -@); and for (4\n* $1 and ((4 - @I A (@ - 4))).\nFor a proof that these new rules are a satisfactory replacement for TC, see Benson Mates,\nElementary Logic (New York: Oxford University Press, 1972). It's not surprising that the Mates'\nsystem meshes nicely with the rules from Logic I, since the rules for Logic I were lifted fiom his\nbook.\nWhere 4 is a sentence of St! and I? is a A set of sentences1 of St!, a number s is said to be a\nproof of 4 from I? just in case s is a sequence of ordered pairs <x,y> with the following\nproperties:\nx is a code of a finite set n of sentences of St!,.\ny is a code of a sentence @ of St!,.\nEither @ is an element of n (so that @ is derivable from n by rule\nPI) or @ is derivable with premiss set\nfiom one or more of the\nearlier members of s by one of the rules other than PI.\nThe last member of s has r@ as its second component and the code of a subset of\nI? as its first.\nTo spell this out in detail, we would have to specifl, rule by rule, what it takes for one line to be\nWhat this really means is that the set of code numbers of members of I? is A. In the\nfuture, we shall frequently efface the distinction between a sentence or set of sentences\nand its code number. I hope that no confusion results.\n\nderived from an earlier line by a rule. For example <x,y> is derived from <z,w> by rule CP iff\nthere is a v < y such that y = Triple(l3,v,w) and, for any u < s, u E z iff (u E x or u = v). Going\nthrough the details helps inculcate the virtues of patience and endurance, but it doesn't inspire\nany intellectual virtues, so we won't do it here.\nWhat we get is a x formula Br that strongly represents the relation {<s, re>:\ns is the\ncode of a proof of 4 from I')' in Q, and hence in any consistent theory that includes Q. If we\ndefine a x formula Bewr (from the German \"Beweis,\" for \"proof ') by:\nBewr(x) =D,, ( 3 s ) ~\nBr x,\nwe get a formula that weakly represents {x: x is the code of a consequence of I?) in Q and in any\nother o-consistent theory that includes Q.\nIn defining \"Bewr,\" we have supposed that I' is a A system of axioms. This looks\nunnecessarily restrictive. In order to have a proof procedure for the set of consequences of a set\nof axioms, it's enough to have a proof procedure for the set of axioms; we don't need a decision\nprocedure. To generate the consequences, we need to be reliably able to recognize the axioms;\nwe don't have to be able to recognize the nonaxioms. Thus it would appear that we would\nbenefit from employing a more liberal notion of provability that allowed us to start with a 2 set\nof axioms, rather than a A set. It turns out that this appearance is illusory, because of the\nIn writing out the formula that strongly represents proofs in I', we'll use some x formula\ny(x) to strongly represent to set of axioms of I'. There are lots of different x formulas we\ncould use to strongly represent I', and the each choice would give us a different formula\nto represent the proof-in-I' relation. In some out-of-the-way comers of logic, this makes a\ndifference, but it won't matter for us here. To be hlly explicit, we ought to write \"By(X),''\nrather than \"Br,\" but the mildly ambiguous notation won't do us any harm.\n\nfollowing theorem:\nCraig's Theorem. Let\nbe a\nset of sentences. Then there is a A set of\nsentences that has the same consequences as r.\nProof: If I? is the empty set, it's already A, and we're done. If I? is nonempty, it is the range of\nsome A total function, call it f. Let n = {Triple(lS,n,f(n)): n a natural number}.\nn is A. It's obviously 2. To see that it's 11, note that its complement is {z: lstin3(z) + 15\nor 3rdin3 (z) + f(2ndin3(z))}.\nThe members of n are all obtained from members of r by prefixing a vacuous universal\nquantifier. The members of\nare obtained from members of\nby deleting a vacuous initial\nuniversal quantifier. So r and n are logically equiva1ent.H"
    },
    {
      "category": "Resource",
      "title": "exponentiation.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/6f694a7ff7c9c20c60e0fa5ef4486142_exponentiation.pdf",
      "content": "Defining Exponentiation\nHere's a loose end that needs tying up. In proving the incompleteness theorems, we took\nthe language of arithmetic to include exponentiation among its primitive symbols. This was\nconvenient, because it made it easy to encode a finite set of numbers by an single number. It was\na convenient extravagance, but an unnecessary one. We can prove all our results in a restricted\nversion of the language of arithmetic that eliminates \"E\" from among its symbols and that\nremoves (47) and (48) from the axioms of Robinson's arithmetic.\nThe proof, which was part of Godel's original paper, makes use of the following\nvenerable theorem of number theory:\nChinese Remainder Theorem (Qin Jiushao). Givenp,, p,, ..., p,\nrelatively prime integers > 1 (that is, no two of the pis have a common\ndivisor other than I), and given a sequence a,, a,, ..., a,, with each ai <pi,\nwe can find a number c such that, for each i, ai is the remainder on\ndividing c by p,.\nProof: We first show that, whenever q andp are relatively prime, we can find c and d with qc =\npd + 1. To do this, find the least positive integer r such that there exist c and d with qc = pd + r,\nand assume, for reductio ad absurdurn, that r >1. There are two cases:\nCase 1. r doesn't divide q. Then we can find e > 0 and s with 0 < s < r so that q + s = re . Then\nqce =pde + re, and so q(ce - 1) =pde + s. This contradicts the leastness of r.\nCase 2. r divides q. Then r doesn't dividep, and so we can find f > 0 and t with 0 < t < r so thatp\n+ t = r - Then qcf =pdf + rf, and so qcf =p(df - 1) + t. This again contradicts the leastness of r.\nNow let Q be the product of the pis, and let qi be the quotient of Q divided by p,. Then qi\nand pi are relatively prime, so that we can find ci and di with qi *ci = p,di + 1. Thus the remainder\n\nDefining Exponentiation, p. 2\non dividing qi .ci by pi is equal to 1, and so the remainder on dividing qi .ci.ai by pi is equal to ai.\nLet e be the sum E qj .cj a? pi divides each of the qjs other than q , and so the remainder on\ndividing e by pi is the same as the remainder on dividing qi.ci ai by pi, which is a,EI\nWe now define Godel's P-function. Let P(u,v,w) to be the remainder obtained on\ndividing u by (v~w) + 1. P can be defined by a bounded formula in the language of arithmetic.\nFor x > 0, we have (xEy) = z if and only if the following formula is satisfied:\n(3u)(3v)((P(u,v,O) = 1 A (Yw <y)P(u,v, sw) = (P(u,v,w) .x)) A P(u,v,y) = 2).\nThe right-to-left direction of this characterization is obvious. What is hard is to find u and v that\nverify the left-to-right direction. Given x, y, and z with (xEy) = z, let v = z!, the product of the\npositive integers I z. If s < t I z, then (s-v) + 1 and (t'v) + 1 are relatively prime, since ifp were\na prime that divided both of them, p would divide (t - s)v, and so, since (t - s) is one of the factors\nof v, p would divide v. But this enables us to conclude that the remainder on dividing (t'v) + 1 by\np is one, contrary to our assumption that p divides (t'v) + 1. Use the Chinese Remainder\nTheorem to find u so that, for each t I y, xEt is the remainder on dividing u by (t'v) + 1 .Ell\nAs long as our sole interest is the language of arithmetic, the fact that exponentiation can\nbe treated as defined rather than primitive is a mere technical curiosity. It's practical utility\ncomes when we try to show that theories expressed in languages other than the language of\narithmetic are undecidable by interpreting Robinson's arithmetic into those other theories. If, in\ndoing this, we don't have to worry about exponentiation, it makes life a lot easier.\n(47) and (48) are the recursive definition of exponentiation, and we can use Godel's beta\nfunction to convert this recursive definition into an explicit definition. We cannot take the\nprocess a step further by converting (Q5) and (Q6), which are the recursive definition of\n\nDefining Exponentiation, p. 3\nmultiplication, into an explicit definition, thereby eliminating multiplication as one of the\nprimitive operations of the language. This follows fiom a 1929 theorem of Mojzesz Presburger,\nwho showed that there is a decision procedure for the set of sentences of the language with\nnonlogical symbols \"0\", \"s,\" \"+,\" and \"<\" that are true in the standard model. Adding \".\" gives\nus an undecidable theory, so \".\" must not be explicitly definable.'\n'It is perhaps worth pointing out that \"0,\" \"<\" and \"s\" can all be defined in terms of \"+.\"\n\"x = 0\" can be defined as \"(x + x) = x.\" \"x < y\" is defined by \"(- x = y A (3z)(x + z) = y).\" For\n6L sx = y,\" we use \"(Vz)(x < z - ('y = z V y < z)).\" Thus, for us, the import of Presburger's theorem\nis that you can't define multiplication in terms of addition."
    },
    {
      "category": "Resource",
      "title": "goedel_numbering.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/ece70acfd3a0f1284ae0503ac8cf40d5_goedel_numbering.pdf",
      "content": "Godel Numbering\n{x: x is a horse) is a collection that has all the worlds horses as elements, and nothing\nelse. Thus we have\nFor any y, y E {x: x is a horse) if and only if y is a horse.\nTraveler, for example, is a horse, so Traveler E {x: x is a horse). We would expect this pattern to\nhold generally, so that we have:\nFor any y, y E {x: x is\n) if and only if y is\n,\nfor any way of filling in the blank.\nThat's what we'd expect. But now try filling in the blank with \"not an element of itself ';\nwe get:\nFor any y, y E {x: x is not an element of itself) if and only if y is not an\nelement of itself.\nSubstitute \"{x: x is not an element of itself)\" for \"y,\" and we get a contradiction:\n{x: x is not an element of itself) E {x: x is not an element of itself) if and\nonly if {x: x is not an element of itself) is not an element of itself.\nThis is Russell's paradox, one of several set-theoretic paradoxes that shook the\nfoundations of mathematics around the beginning of the twentieth century. The reason these\nparadoxes were so disturbing is that, during the last few decades of the nineteenth century, the\nidea of a set had played an increasing role in clarifling and securing the foundations of\nmathematics, particularly the calculus. By making set theory insecure, the paradoxes threatened\nto undo all these gains.\nA strategy for responding to the paradoxes is to adopt, hopefully on a principled basis,\naxioms that restrict the way the blanks can be filled in enough to prevent contradictions but not\nso much as to prevent set theory from playing its useful mathematical roles. That's a good\nquestions, but how do we know that our axioms still don't still produce contradictions? The\naxioms are chosen to block the path by which Russell obtained a contradiction, but how can we\nbe sure we won't still arrive at a contradiction by some, more devious path?\n\nGodel Numbering, p. 2\nDavid Hilbert proposed an innovative solution to this problem. Ordinarily,\nmathematicians study things like points, lines, planes, functions, and numbers, and they use\nmathematical proofs as a means of learning about these things. Hilbert proposed to treat\nmathematical proofs as themselves the objects of mathematical investigation. A new branch of\nmathematics, metamathematics, would study proofs the way geometers study points, lines, and\nplanes. The hope would be that an investigation of proofs would enable us to prove that the\naxioms of set theory wouldn't lead to a contradiction. Graph theorists investigate when it is\npossible to find a path fiom one location to another within a complex network of points\nconnected by curves. Proof theorists do something similar, looking to see whether there is a path\nleading from the axioms to a contradiction. Russell's paradox has taught us to be wary of proofs\nin set theory. Hilbert thinks we needn't be similarly chary of the proofs produced by proof\ntheorists. The difference is that sets are fiequently infinite, and so impossible to display\nconcretely or survey fully. Proofs, on the other hand, are finite objects that we can actually write\nout on paper.\nMetamathematics, as Hilbert envisaged, is separate from the rest of mathematics, because\nit studies a different kind of thing fiom the things ordinary mathematicians study. Godel devised\na method of assimilating proof theory into ordinary mathematics by assigning arithmetical codes\nto the different symbols, thereby turning the question whether a particular sentence is provable\nfrom a certain set of axioms into an arithmetical question.\nThe details of the coding are fairly arbitrary. What we'll see here is one possibility\namong many. We'll begin by encoding terms by ordered pairs and ordered triples. For any x, y,\nand z, Triple(x,y,z) = Pair(x,Pair(y,z)). If w = Triple(x,y,z),then lstin3(w) = x, 2ndin3(w) = y,\nand 3rdin3(w) = z.\nThe code for \"0\" is the pair Pair(1 ,O), which we abbreviate Ql.\nThe code for \"%\" is the pair Pair(2,n), which we abbreviate r q l .\nThe code for ST is the pair Pair(4,91), which we abbreviate rs~l.\n\nGodel Numbering, p. 3\nThe code for ( ~ + p )\nis the triple Triple(5, 91, rpl), which we abbreviate r ( ~\n+ p)l.\nThe code for (TOP) is the triple Triple(6,91, rpl), which we abbreviate r ( ~\nl p)l.\nThe code for (T E p) is the triple Triple(7,91, rpl), which we abbreviate r ( ~\nE p)l.\nA number is the code of a term if and only if it is an element of every set S of numbers\nthat meets the following conditions:\nPair(1,l) ES.\nPair(2,i) E S.\nIf x is in S, so is Pair(4,x).\nIf x and y are in S, so are Triple(S,x,y), Triple(6,x,y), and Triple(7,x,y).\nAny set that meets these conditions will be infinite, and we can't talk about infinite sets within\nthe language of arithmetic. If we want to talk about the set of codes within the language of\narithmetic, we need to figure out ways to say the things we want to say using only finite sets, so\nthat we can take advantage of the fact that finite sets have numerical codes. Such an effort yields\nthe following theorem:\nTheorem. The set of codes of terms is a A set.\nProof. The set of codes of terms in 2. x is the code of a term if and only if it's an element of a\nfinite set s with the following properties:\nIf Pair(4,y) E s, y E s.\nIf Triple(S,y,z) E s, then y E s and z E s.\nIf Triple(6,y,z) E s, then y E s and z E s.\nIf Triple(7,y,z) E s, then y E s and z E s.\nIf y E s, then either y = Pair(1,O) or ( I n < y)y = Pair(2,n) or\n( I n < y)y = Pair(4,n) or (3m < s)(3 n < s)y = Triple(S,m,n) or\n(3m < s)(3 n < s)y = Triple(6,m,n) or (3m < s)(3 n < s)y = Triple(7,m,n).\nThe properties the code number of s has to satisfy for these conditions to be met can be\nexpressed by a bounded formula.\n\nGodel Numbering, p. 4\nThe complement of the set of codes of terms is x. It will be helpful to have the following\ndefinition on board:\nDefinition. x ;-y = x - y if x 2 y;\n=Oifx<y.\nNote that x ;-y = z iff ((z + y) = x V (x < y A z = 0)); since this is a bounded formula, ;-is a A\ntotal function.\nIf x isn't the code of a closed term, then, if we try to form the structure tree for x, there\nwill a branch that doesn't terminate either in \"0\" or a variable. Thus, x is not a code of a term if\nand only if there is a finite sequence s with the following properties:\n(s)~\n= X.\nIf n < length(s) and (s), = Pair(4,y), then n+l < length(s) and (s),,\n= y.\nIf n < length(s) and (s), = Triple(S,y,z), then n+l < length(s) and (s),,\nis equal to\neither y or z.\nIf n < length(s) and (s), = Triple(6,y,z), then n+l < length(s) and (s),,\nis equal to\neither y or z.\nIf n < length(s) and (s), = Triple(7,y,z), then n+l < length(s) and (s),,\nis equal to\neither y or z.\nIf n+l < length(s), then either (s), = Pair(4,(s),,) or (32 < s)(s), is equal to\neither Triple(S,(s),,,z) or Triple(S,z,(s),,) or Triple(6,(s),,,z)\nor Triple(6,z,(s),,)\nor Triple(7,(s),+,,z) or Triple(7,z,(s),,).\n(s)lenpth(s)\nT\n1 + Pair(1,O).\n-(In < S)(S)~,,~~(~)\n= Pair(2,n). IXI\nThe set of codes of closed formulas is A; just leave off the clause for variables.\nTheorem. The set of pairs <x,y> for which y is a term and x a subterm of y is A.\n\nGodel Numbering, p. 5\nProof: Where I say \"y is a term and x is a subterm,\" what I really mean is that y is the code of a\nterm and x the code of a subterm. Most of the time, I'll neglect this distinction. You'll get used\nto it.\nIf y is a term, x is a subterm of y if and only if x is an element of every finite set that\nmeets the following conditions:\ny is in the set.\nIf Pair(4,z) is in the set, z is in the set.\nIf Triple(S,z,w), Triple(6,z,w), or Triple(7,zkw) is in the set, z and w are in the\nset.\nThis shows that the set of pairs <x,y> with y a term and x a subterm is n. To see that it's also x,\nnote that, for y a term. x is a subtern of y if and only if there is a number s coding a finite set with\nwith the following properties:\ny is in the set.\nIf Pair(4,z) is in s, z is in the set.\nIf Triple(S,z,w), Triple(6,z,w), or Triple(7,zkw) is in tbe set, z and w are in the\nset.\nIf t < s is the code of a set containing y with the properties that z is in the set\ncoded by t whenever Pair(4,z) is in the set coded by t and that z and w are in the\nset coded by t whenever any of Triple(S,z,w), Triple(6,z,w), or Triple(7,z,w) in in\nthe set coded by z, then x is an element of the set coded by t.M\nAJinite tree is a finite set of sequences with the property that any initial segment of a\nmember of the set is a member of the set; the statement that s is the code of a fine tree can be\nformalized by a bounded formula. AJinite binary tree is a finite tree consisting entirely of\nsequences of 0s and 1s. Where x is a code of a term, a structure tree for x is a pair Pair(s,f),\nwhere s is a code of a finite binary true and f is a function with domain the set of elements of the\nset coded by s that satisfies the following properties:\n\nGodel Numbering, p. 6\nf assigns x to the trunk of the tree, < >.\nIf y E s and f(y) = Pair(4,z), then y A <O> E s and f(y A <0>) = z, and y A <1> C s.\nIf y E s and f(y) = Triple(S,z,w), then y A <0> and y A <1> are both in s, and\nf(y A <0>) = z and f(y A <I>) = w.\nIf y E s and f(y) = Triple(G,z,w), then y A <0> and y A <1> are both in s, and\nf(y A <0>) = z and f(y A <I>) = w.\nIf y E s and f(y) = Triple(7,z,w), then y A <0> and y A <1> are both in s, and\nf(y A <0>) = z and f(y A <I>) = w.\nIf y A <O> E s and f(y A <0>) = z, then either f(y) = Pair(4,z) or\n(3w < s)(f(y A <I>) is defined and equal to w and f(y) = Triple(S,z,w)) or\n(3w < s)(f(y A <I>) is defined and equal to w and f(y) = Triple(6,z,w)) or\n(3w < s)(f(y A <I>) is defined and equal to w and f(y) = Triple(7,z,w)).\nIf y A <1> E s and f(y A <I>) = w, then, for some z < s, f(y A <O> is defined and\nequal to z and either f(y) = Triple(S,z,w) or f(y) = Triple(6,z,w) or f(y) =\nTriple(7,z,w).\nIf y E s and neither y A <0> nor y A <1> is in s, then either f(y) = Pair(1,O) or\n(3n < s)f(y) = Pair(2,n).\nUnique Readability Lemma. Every (code of a) term has a unique structure tree.\nThe most straightforward way to prove this would be to show that the set of terms for\nwhich there is a unique structure tree contains Pair(1,l) and Pair(2,i), for each i, and that it\ncontains Pair(4,y), Triple(S,y,z), Triple(6,y,z), and Triple(7,y,z) whenever it contains y and z.\nSuch a proof talks about infinite set of numbers, so it can't be carried out within the language of\narithmetic. To get a purely aritmetical version of the proof, we have to pick a particular number\ny that codes a term and show that every subterm of y has a unique structure tree, formulating the\nargument in such a way that it only talks about subterms ofl. I won't go through the details.\nTheorem. The function Den that takes a closed term to the number it denotes is A.\n\nGodel Numbering, p. 7\nProof: Den(x) = v iff there is a finite set s with the following properties:\nPair(x,v) E s.\nIf y E s, lst(y) is a closed term.\nIf Pair(Pair(1 , 1,), u) is in s, then y = 0.\nIf Pair(Pair(4,y),u) is in s, then u > 0 and Pair(y,u 7 1) is in s.\nIf Pair(Triple(S,y,z),u) is in s, there there are t and w with Pair(y,t) and Pair(z,w) in\nandwithu=t+w.\nIf Pair(Triple(6,y,z),u) is in s, there there are t and w with Pair(y,t) and Pair(z,w) in\nandwithu=t*w.\nIf Pair(Triple(7,y,z),u) is in s, there there are t and w with Pair(y,t) and Pair(z,w) in\nS\nand with u = tw.\nThis can be formalized by a x formula. Since Den is a x partial function with a A domain, it's\nA.m\nWe encode formulas the same way:\nIf T and p are terms, the code for T = p is Triple(8, r ~ l ,\nrpl), which we abbreviate\nrT = pl.\nIf T and p are terms, the code for T < p is Triple(9, r ~ l ,\nrpl), which we abbreviate\n'T < P1.\nIf 4 is a formula, the code for -4 is Pair(l0, r@), which we abbreviate r- @.\nIf 4 and q are formulas, the code for ( 4 V q ) is Triple(l1, r@, v),\nwhich we\nabbreviate r(4 V $)I.\nIf 4 and q are formulas, the code for ( 4 A q ) is Triple(l2, r e , rql), which we\nabbreviate '(4 A qp.\n\nGodel Numbering, p. 8\nIf 4 and q are formulas, the code for ( 4 - q ) is Triple(l3, r e , v),\nwhich we\nabbreviate r(@ - $)I.\nIf 4 and q are formulas, the code for ( 4 - q ) is Triple(l4, r e , rql), which we\nabbreviate '(4 - qp.\n1f 4 is a formula, the code for (b'%)@ is Triple(lS,n, re), which we abbreviate\nTb'rZ34'-\nIf 4 is a formula, the code for (I%)$ is Triple(l6,n, r@), which we abbreviate\n'(3rZ3@\nTheorem. The set of codes of formulas is A.\nThe proof is so close to the proof of the analogous proof for codes of terms that there's no real\npoint in going through it. Same for the proof that the set of pairs <x,y> with x the code of a\nsubformula of the formula coded by y is A. We define structure trees for formulas the way we did\nfor terms, and once again we have unique readability.\nTheorem. The function Sub that, for 8 a formula, T a term, and n a natural number,\ntakes < a l p ,\nto @%lTl is A.\nProof: First note that the function that, given terms T and a natural number n, takes < r p 1 , n , TI> to\nrpX.1~1 is 2 , and hence, as a 2 partial function with a A domain, A. That's so because the value\nthe function takes with input < 'pl,n,\nis equal to z if and only if there is a finite set s with the\nfollowing properties:\nPair( rp1,z) is in s.\nIf y is in s, then lst(y) and 2nd(y) are both in s.\nIf Pair(Pair(1 , l),y) is in s, then y = Pair(1,l ,).\nIf Pair(Pair(2,i),y) is in s, with i + n, then y = Pair(2,i).\nIf Pair(Pair(2,n),y) is in s, then y = 91.\nIf Pair(Pair(4,u),y) is in s, then lst(y) = 4 and Pair(u,2nd(y)) is in s.\n\nGodel Numbering, p. 9\nIf Pair(Triple(S,u,v),y) is in s, then 1 st(y) = 5 and Pair(u,2ndin3(y)) and\nPair(v,3rdin3(y)) are both in s.\nIf Pair(Triple(6,u,v),y) is in s, then 1 st(y) = 6 and Pair(u,2ndin3(y)) and\nPair(v,3rdin3(y)) are both in s.\nIf Pair(Triple(7,u,v),y) is in s, then 1 st(y) = 7 and Pair(u,2ndin3(y)) and\nPair(v,3rdin3(y)) are both in s.\nIf 0 is an atomic formula, r a term, and n a number, @%/,1 is given by:\nrp = ox\"/, 1 = Triple(8, rps/,l, Fox./,').\nrp < ox\"/, 1 = Triple(9, rpX.1~1, ro~/,l).\nTo complete the proof, we need to do the same thing with formulas that we just did with terms. I\nwon't give the details, which are tedious and don't involve any new ideas.m"
    },
    {
      "category": "Resource",
      "title": "interpretations.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/05cfcbceb879c7766765031b8fb3531e_interpretations.pdf",
      "content": "Interpretations\nThe first incompleteness theorem applies not only to the language of arithmetic but to\nother languages into which one can translate the language of arithmetic. The notion of\n\"translation\" we'll be using comes from Tarski, Mostowski, and Robinson's book Undecidable\nTheories.' Let Ee be a language that includes the first-order predicate calculus and might or might\nnot include other logical apparatus as well. We translate the language of arithmetic into St! by\npicking a formula N(x,) of Ee to represent \"x, is a natural number,\" picking a formula \"Z(x,)\" to\nrepresent \"x, = 0,\" and picking formulas \"S(x,,x,),\" \"A(xo,xl,x2),\" \"M(xo,xl,x2),\" \"E(xo,xl,x2),\" and\n\"L(x,,x,),\" to represent \"x, is the successor of x,,\" \"x2 = (x, + x,),\" \"x2 = (x, *x,),\" \"x2 = (x, E x,),\"\nand \"x, < x,,\" respectively.\nAs an example, let us take Ee to be the language of set theory, which is the language\nwhose only non-logical symbol is the binary predicate \"E\" (\"is an element of '). Our technique\nfor formulating arithmetical statements within the language of arithmetic is due to John von\nN e ~ a n n . ~\nWe use the empty set, 0, to represent 0, we use {a) to represent 1, we use {a, (0))\nto represent 2, and so on, representing a number n as the set of the sets that we use to represent\nAmsterdam: North-Holland, 1953. The notion we are developing here is what they call\nrelative interpretation.\nAn earlier proposal for reducing number theory to set theory, put forward by Ernst\nZermelo, was to identify0 with the empty set and to identify a successor with the unit set of its\nimmediate predecessor, so that we associate 1 with {0],2 with { (0) ), 3 with (((0) ) ), and so\non. If we're only interested in arithmetic, one suggestion is as good as the other. The reason von\nNeumann's technique has generally been preferred is that it extends seamlessly into the\ntransfinite. You can read the papers by Zermelo and von Neumann in Jean van Heijenoort's\nFrom Frege to Godel (Cambridge, Mass.: Harvard University Press, 1965). The fact that there\nare multiple equally effective reductions of number theory to set theory has been thought to have\nprofound and disturbing implications for the philosophy of mathematics. See Paul Benacerraf,\n\"What Numbers Could Not Be,\" in Benacerraf and Hilary Putnams, eds. Philosophy of\nMathematics, 2nd ed. (Cambridge: Cambridge University Press, 1984).\n\nInterpretations, p. 2\nthe numbers less than n. One way to think of it is that we reduce number theory to set theory by\ntaking numerals to refer to certain sets. In terms of the reduction, we can say that a number is\nequal to the set of its predecessors.\n\"Z(x)\" will just be \"- (3y)y E x\"; this identifies the zero element with the empty set. The\nsuccessor function is represented by the operation that takes x to x u {x), so we set \"S(x,y)\"\nequal to \"@i)(z E y - (z E x V z = x)).\" \"N(x)\" will say that x has four properties:\nx is transitive: (Vy)@i)((y E x A z E y) - z E x).\nxis connected: ('dy)@i)((y E X A Z\nE X ) - (y ~ z V y = z V z\n~ y ) ) .\nx is well-founded: (Vy)((3z)(z E y A z E x) - (3z)((z E x A z E y) A\n- ( ~ w ) ( w ~ x ~ w ~ y ~ w ~ z ) ) ) .\nx contains no limits: (Vy)((y E x A (3z)z E y) - (3z)(z E x A\n(VW)(W\nE y - (w E z V w = z)))).\nThe third conditions is what gives us the principle of mathematical induction. The most\ncommon formalization of the axioms of set theory has an axiom that says every set is well-\nfounded. In the presence of such an axiom, the third clause is superfluous. The fourth clause tells\nus that every number is either 0 or a successor.\nIn order express addition, multiplication, and exponentiation set-theoretically, we first\nneed a set-theoretic analogue of Pair, a function that encodes an ordered pair of sets as a single\nset.3 For that purpose, we define, for any sets a and b,\n<a.b.>=,,, {{a}, {a.b)).\nThe specific function we use was devised by Kazimierz Kuratowski, although the basic\nidea was due to Norbert Weiner. Both their papers are in the van Heijenoort volume.\n\nInterpretations, p. 3\nIt is easy to prove that, for any a, b, c, and d, we have <a.B.> = <c,& if and only if a = c and b =\nd. Once we have the pairing hction, we can get ow formulas \"A(x,y,z),\" \"M(x,y,z),\" and\n\"E(x,y,z)\" by applying our usual method for converting recursive definitions into explicit\ndefinitions. \"L(x,y)\" is just \"x E y.\"\nOnce we have our translation scheme we translate arithmetical formulas into 9\nby the\nfollowing procedure: Given a sentence 4 , we eliminate the nesting of hction signs. rewriting 4\nas a logically equivalent formula in which the atomic formulas take one of the following seven\nforms:\nWe leave the first of these alone, and we replace the others by \"L(x, xj),\" \"Z(xi),\" \"S(xi,xj),\"\n\"A(x3xj,xb),\" \"M(xi,xj,xb),\" and \"E(x3xj,xb),\" respectively, changing bound variables as needed to\navoid collisions. Finally, we replace \"(Vxi)\" and \"(3~~)\"\nby \"(Vxi)(N(xi) - ...)\" and \"(3xi)(N(xi) A\nTo take an example, let's translate (Q4), \"(Vx)(Vy)(x + sy) = s(x + y).\" We first find an\nequivalent sentence in which the atomic formulas all have the prescribed form. There are a\nnumber of ways to do this, but they're all logically equivalent. This is one:\n\nInterpretations, p. 4\n(~~O)@;C~)(~~~)@;C~)(~X~~WX~)(((X~\n= =I\nA x3 = (xo + ~ 2 ) ) A\n(x4 = (xo + xl) A X5 = S X ~ ) ) - X3 = x5).\nMaking the substitutions, we get:\n(~xO)(N(XO) - (vxl)(N(xl) - (vx2)(N(x2) - (vx3)(N(x3) - (vx4)(N(x4) - (~xS)(N(XS)\n- ( ( ( S ( x 1 ~ 2 ) A A ( x O ~ 2 ~\n~ 3 ) ) A ( A ( x 0 ~ 1 ~ 4 ) A S ( x 4 ~ 5 ) ) ) - x3 = ~ 5 ) ) ) ) ) ) .\nGiven an arithmetical theory r and a theory A expressed in $f, we say that A interprets I?\nif A entails each of the following:\nThe translation of each of the axioms of I?.\n(3x)@jl)((Nb) A Zb)) - Y = x).\n(Vx)(N(x) - (3y)@i)((N(z) A S(x*z)) - z = Y))\nO'x)@jl)((N(x) A Nb)) - (3z)@iv)((N(w) A A(X)Y)~)) - w = 2))\nO'x)@jr)((N(x) A Nb)) - (3z)@iv)((N(w) A M(x,y*w)) - w = 4)\nO'x)@jl)((N(x) A Nb)) - (3z)@iv)((N(w) A E(X)Y)~)) - w = 2))\nThese sentences express the constraints about what's related to what that are built into the\nfunction-sign notation.\nThe following, very weak theory of sets is able to interpret Q:\n(vx)@jl)((vz)(z E x - z E Y ) - x = Y )\n( ~ x ) - ( ~ Y ) Y\nE x\n(VX)(V~)(~Z)(~W)(W\nE z - (w E x V w = y))\nLet A be a recursively axiomatized theory into which Q can be interpreted. In talking\nabout a theory in\nbeing \"recursively axiomatized,\" I am presuming that a system of code\nnumbers has been assigned to the expressions of Sf is a reasonable way. What will be required of\n\nInterpretations, p. 5\nthis coding, for our purposes here, is that the function that takes an arithmetical sentence to its\ntranslation be recursive. Another way to express the thesis that A is recursively axiomatized is to\nsay that the set of consequences of A is effectively enumerable; this way of putting things\ndepends on the Church-Turing thesis. Another way of saying it is that A can be axiomatized by a\nsingle axiom schema. Here we use a theorem of Robert Vaught4 that a theory in a language built\nfrom a finite vocabulary into which we can interpret Q is recursively axiomatizable if and only if\nit is axiomatizable by a single axiom schema.\nGiven A a recursively axiomatized theory into which we can interpret Q, there can't be\nany recursive set D that includes the theorems of A and excludes all the sentences refutable in A,\nsince if there were such a set, the set of arithmetical sentences whose translations are elements of\nD would be a recursive set of arithmetical sentences that included the theorems of Q and\nexcluded the sentences refutable in Q. It follows that, if A is consistent, it is incomplete.\nVirtually every known example of an undecidable theory has been obtained this way.\nOur notion of interpretation requires that a formula of the language of arithmetic be\ntranslated as a formula of 9. It does not require that an arithmetical term be translated as a term\nof 9 , since Sf might be a language like the language of set theory, which has no terms other than\nvariables. What we can do, however, is to translate arithmetical terms into definite descriptions\nin S f . For example the numeral \"[2]\" is translated \"(1~)(3y)(3z)((N(x) A NO) A N(z)) A (Z(z) A\nS(z,y) A S(y,x)).\" We can then use Russell's technique5 to eliminate the definite descriptions\n\"Axiomatizability by a Schema,\" Journal of Symbolic Logic 32 (1967): 473-479.\n\"On Denoting,\" Mind n.s. 14 (1905): 479-493. We talked about Russell's account in\nLogic I.\n\nInterpretations, p. 6\nfrom formulas of P. For now, let me ignore this complication and pretend that the formulas of 5l!\nare represented by code numbers that are denoted by numerals in P , just the way we have it in\nthe language of arithmetic.\nLet $(x) be a formula of P. The self-reference lemma, applied within the language of\narithmetic, gives us an arithmetical sentence 4 such that\nQ I($ - (3y)y)(v is the translation into P of [ r @ ] A $(v)).\nHere I am taking advantage of the fact that the function that takes the code number of an\narithmetical formula to the code number of its translation can be functionally represented by a Z\nformula. Let 0 be the translation into 5l! of 4. Then\nQ t('dy)(y is the translation into P of [ r @ ] - y = [@I).\nBecause A interprets Q,\nA t (0 - $( el)).\nThus the self-reference lemma applies not only to the language of arithmetic but to languages\ninto which we can translate the language of arithmetic.\nI have been taking it for granted that the \"=\" sign of the language of arithmetic is\ntranslated as the \"=\" sign of P. This isn't obligatory. We can pick a formula I(x,y) of P to\ntranslate \"x = y,\" as long as we make sure that our interpreting theory A proves statements that\ncorrespond to the facts about identity that are used in proving the theorems of r. Specifically, A\nshould prove that \"I\" designates an equivalence relation:\n(W(N(x) - I(x*x))\n(W@jl)((N(x) A Ny)(v)) - (I(x9y) - IOl,x)))\n(W@ly)(W((N(x) A NOI) A N(z)) - ((I(~*Y)\nA I(%+) - I(x*z)))\n\nInterpretations, p. 7\nand it should prove that 'T'\nis a congruence:\n(vx)Wu)((N(x) A N(u)) - ((Z(x) A Z(u)) - I(x, u)))\n(vx)@jl)(vu)(vv)((N(x)\nA NOI) A N u ) A N(v)) - (((S(x9y) A S(u9v)) A I(x9u))\n- IOIA))\n( ~ x ) W ) ( ~ ~ ) ( ~ ~ ) ( ~ V ) W W ) ( ( N ( X )\nA NO.) A N(z) A N(u) A N(v) A N(w))\n- (((A (x, y,z) A A (u, v, w)) A (I(& u) A I(y, v))) - I(z, w)))\n( ~ x ) W ) ( ~ ~ ) ( ~ ~ ) ( ~ V ) W W ) ( ( N ( X )\nA NOI) A N(z) A N(u) A N(v) A N(w))\n- (((M(x, y, z) A M(u, v, w)) A (I(& u) A IO, v))) - I(z, w)))\n( ~ x ) W ) ( ~ ~ ) ( ~ ~ ) ( ~ V ) W W ) ( ( N ( X )\nA NOI) A N(z) A N(u) A N(v) A N(w))\n- (((E(x, y,z) A E(u, v, w)) A (I(& u) A I(y, v))) - I(z, w)))\n(vx)@jl)(vu)(vv)((N(x) A Nb)\nA N(u) A N(v)) - ((('(x9u)\nA IbJv)) A L ( x j ~ ) ) -\nL(u,v)))"
    },
    {
      "category": "Resource",
      "title": "key_coptbty_cons.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/ed0bd05ec59b448cbfe0b2599f68e177_key_coptbty_cons.pdf",
      "content": "Computability Theory: Key Concepts\nThe general problem we want to confront is this: given a set or relation, when is there an\nalgorithm for testing membership in that set? We can reduce this problem to another problem\nthat, at first, appears to be much more restricted, namely, given a set of natural numbers, when is\nthere an algorithm for testing membership in that set? We can effect this reduction by coding the\ngiven problem as a problem about numbers. A few examples will illustrate how this is done:\nExample: We already know that there is an algorithm for testing whether an SC sentence is\nvalid. Let us see how this problem can be coded as a problem about numbers. We first associate,\nwith each simple symbol of our SC language, a numerical code, as follows:\n1 is the code for \"(\"\n2 is the code for \")\"\n3 is the code for \"V\"\n4 is the code for \"A\"\n5 is the code for \"-\"\n6 is the code for \"-\"\n7 is the code for \"1\"\n8 is the code for \"A\"\n9 is the code for \"B\"\n10 is the code for \"C\"\n1 1 is the code for \"D\"\nAnd so on. We can think of a sentence of the SC language as a finite sequence of symbols, so we\ncan encode a sentence as a finite sequence of numbers. Moreover, as we shall see in a moment, it\nis possible to code a finite sequence of natural numbers as a single natural numbers. Putting\n\nKey Computability Concepts, p. 2\nthese two encodings together, we associate a code number with each sentence. What I have in\nmind by talking about coding is this: there is an algorithm which, given a an SC sentence as\ninput, gives the code number of that sentence as output. Furthermore, there is an algorithm that,\ngiven a number as input, first determines whether the number is the code of an SC sentence; if it\nis, the algorithm gives you the sentence. Once we have such a coding, we see that the problem of\ndetermining whether a given SC sentence is valid reduces to the problem of testing whether a\ngiven natural number is the code of a valid SC sentence.\nCoding a pair of natural numbers. Given natural numbers x and y, let pair(x,y) = %(x2 + 2xy +\ny2 + x + 3y). pair is a bijection1 from the set of ordered pairs of natural numbers to the set of\nnatural numbers. There is an algorithm that, given x and y, givens you pair(x,y), and another\nalgorithm that, given z, gives you the unique numbers x and y with pair(x,y) = z. Let's write x =\n1 st(z) and y = 2nd(z).\nCoding a finite set of natural numbers. Where F is a finite set of natural numbers, let Code(F)\n= C {2\": n E F). Code is a bijection from the set of finite sets of natural numbers to the set of\nRecall that a function from a set A to a set B is a set f c A x B with the property that, for\neach element a of A, there is one and only one element b of B with <a,b> E f. If <a,b> E\nf, we write f(a) = b. A is the domain of the function, and the set of all elements b of B\nsuch that, for some a E A, f(a) = bI is the range. If the range off is all of B, f is said to be\nsurjective or onto. If, for each a and a* in A, if f(a) = f(a*), then a = a, f is said to be\ninjective or one-one. Iff is both surjective and injective, f is said to be bijective or a one-\none correspondence. Iff is a bijection form A to B, the inverse off, fml, {<b,a>: <a,b> €\nf), is bijection from B to A.\n\nKey Computability Concepts, p. 3\nnatural numbers. There is an mechanical procedure that, given F, will calculate Code(F).\nMoreover, there is a algorithm in the opposite direction, that, given a number n, computes the\nunique set F with Code(F) = n: write n in binary notation, and take F to be the set of places\nwhere 1 s appear.\nCoding a finite sequence. Given a finite sequence <so, s,, s,, ..., s p , let its code be\nCode( {pair(O,s,), pair(1 ,s,), pair(2,s2),. . ., pair(n,s$)).\nExample: We can form two infinite lists, one of which lists all the expressions of English in\nalphabetical order, and the other of which lists all the expressions of Russian in alphabetical\norder. There is a mechanical procedure by which, given an English expression, we can find the\nposition of the expression on the list, and also a procedure by which, given a number n, we can\nfind the nth expression on the list. Then the problem of determining, given an English expression\nand an Russian expression whether the latter is an acceptable translation of the former, is\nequivalent to the arithmetical problem of determining, for given m and n, whether pair(m,n) is an\nelement of {pair(i j): the ith English expression is an acceptable translation of the4 jth Russian\nexpression.\nExample: The core of the Star Wars nuclear defense system is envisaged to be a gigantic\nsupercomputer that takes radar traces of attacking missiles as inputs and yields instructions to US\nmissiles that will shoot the attacking missiles down as outputs. Now it isn't possible to assign a\ndistinct numerical code to each possible trajectory of an incoming missile, because there are\nmore possible trajectories than there are natural numbers. However, the apparatus we use to\nsense the incoming missiles has limited sensitivity, so that it will be unable to distinguish among\ntrajectories that are very close together. If we group together trajectories that the instruments are\n\nKey Computability Concepts, p. 4\nunable to distinguish, we find that there are only finitely many discernibility classes of\ntrajectories, and these can be assigned numerical codes. The instructions the computer sends to\nthe defensive missiles can likewise be given numerical codes, so that the computer's problem\ncan be coded as a numerical problem.\nWe now present some key definitions. The definitions utilize colloquial notions that\nhaven't been made mathematical precise, but they will nonetheless be precise enough to permit\nus to prove some theorems:\nDefinitions. Apartial function from the natural numbers to the natural\nnumbers is a subset f of N x N that meets the following condition:\n(Vx)(Vy)(vz)((<x,z> E f A <y,*\nE f ) - x = y)\nIn other word, f is a function from a subset of N onto a subset of N.\nA partial function f is total iff its domain is all off. Thus, in our usage,\ntotal functions are a kind of partial function.\nA partial function f is calculable iff there is an algorithm such that, given\nn as input, the algorithm gives f(n) as output if n is in the domain off; iff\nisn't in the domain off, the algorithm gives no output.\nA decision procedure for S is an algorithm that calculates the\ncharacteristic function of S; that is, if the input is a member of S, the\noutput is 1, whereas if the input is a nonmember, the output is 0.\nS is decidable iff there is a decision procedure for S.\n\nKey Computability Concepts, p. 5\nAproofprocedure for S is an algorithm that calculates a partial function\nwhose domain includes S that assigns the value 1 to an input if and only if\nthe input is an element of S.\nAn enumeration procedure for S is an algorithm that lists the elements of\nS. The function that takes a number n to the nth element on the list is a\ncalculable partial function whose domain is an initial segment of the\nnatural numbers and whose range is S.\nS is eflectively enumerable iff there is an enumeration procedure for S.\nTheorem. There is an proof procedure for S if and only if S is effectively\nenumerable.\nProof: (*) A proof procedure for S calculates a partial function f with Dom(f) 2 S and f(n) = 1\niff n E S, for n E Dom(f). We want to find an enumeration procedure for f. Here's a proposal that\ndoesn't work:\nFirst, calculate f(0). If f(0) = 1, put 0 on the list.\nSecond, calculate f(1). If f(1) = 1, put 1 on the list.\nThird, calculate f(2). If f(2) = 1, put 2 on the list.\nFourth, calculate f(3). If f(3) = 1, put 3 on the list.\nAnd so on.\nThe trouble is that, when the algorithm gets to something that's not in the domain off, it gets\nstuck. We want to modify the algorithm so that meeting up with a number that's not in the\ndomain won't prevent it form going on to consider greater numbers. We might try this:\n\nKey Computability Concepts, p. 6\nFirst, attempt to calculate f(0). If 0 @ Dom(f), skip to step 2. if 0 E Dom(f)\nand f(0) = 1, put 0 on the list.\nSecond, attempt to calculate f(1). If 1 @ Dom(f), skip to step 3. If 1 E\nDom(f) and f(1) = 1, put 1 on the list.\nThird, attempt to calculate f(2). If 2 @ Dom(f), skip to step 4. If 2 E\nDom(f) and f(2) = 1, put 2 on the list.\nFourth, attempt to calculate f(3). If 3 CE Dom(f), skip to step 5. If 3 E\nDom(f) and f(3) = 1, put 3 on the list.\nAnd so on.\nThe trouble is that, in general, we won't have any test to tell us whether a number is in the\ndomain off. If n is in the domain off, our algorithm for f will compute f(n), but iff isn't in the\ndomain, the algorithm will typically keep running forever without giving an output. We want to\narrange our procedure so that we never give up on trying to calculate f(n), but doing this won't\nprevent us fiom considering numbers greater than n. We accomplish this by a technique called\ndovetailing that weaves different computations together:\nStep 1. Take one step in the attempt to compute f(0). If you succeed, see\nwhether f(0) = 1. If it is, put 0 on the list.\nStep 2. Take one step in the attempt to compute f(1). If you succeed, see\nwhether f(1) = 1. If it is, put 1 on the list.\nStep 3. Take another step in the attempt to compute f(0) (if you didn't\nalready succeed in calculating f(0) at step 1). If you succeed in calculating\nf(O), see whether it's equal to 1. If it is, put 0 on the list.\n\nKey Computability Concepts, p. 7\nStep 4. Perform one step in the attempt to calculate f(2). If you succeed\nand f(2) = 1, put 2 on the list.\nStep 5. Take another step in the attempt to compute f(1) (if you didn't\nalready succeed in calculating f(1) at step 2). If you succeed in calculating\nf(1) and it's equal to 1, put 1 on the list.\nStep 6. Take another step in the attempt to compute f(0) (if you didn't\nalready calculate f(0) at step 1 or step 3). If you succeed in calculating f(0)\nand it's equal to 1, put 0 on the list.\nStep 7. Perform one step in the attempt to calculate f(3). If you succeed\nand f(3) = 1, put 3 on the list.\nStep 8. Perform another step in the attempt to calculate f(2) (if you didn't\nalready succeed in calculating f(2) at step 4). If you succeed in calculating\nf(2) and it's equal to 1, put 2 on the list.\nStep 9. Perform another step in the attempt to calculate f(1) (if you didn't\nalready succeed in calculating f(1) at step 2 or step 5). If you succeed in\ncalculating f(1) and it's equal to 1, put 1 on the list.\nStep 10. Perform another step in the attempt to calculate f(0) (if you\nhaven't succeeded in calculating f(0)). If you succeed in calculating f(0)\nand it's equal to 1, put 0 on the list.\nStep 11. Carry out one step in the attempt to calculate f(4). If you succeed\nand f(4) = 1, put 4 on the list.\n\nKey Computability Concepts, p. 8\nStep 12. Perform another step in the attempt to calculate f(3) (if you\ndidn't already succeed in calculating it). If you succeed in calculating f(3)\nand it's equal to 1, put 3 on the list.\nStep 13. Perform another step in the attempt to calculate f(2) (if you\nhaven't already calculated it successfblly). If you succeed in calculating\nf(2) and it's equal to 1, put 2 on the list.\nStep 14. Perform another step in the attempt to calculate f(1) (if you\nhaven't calculated it already). If you succeed in calculating f(1) and it's\nequal to 1, put 1 on the list.\nStep 15. Perform another step in the attempt to calculate f(0) (if you\nhaven't calculated it already). If you succeed in calculating f(0) and it's\nequal to 1, put 0 on the list.\nAnd so on.\n(*) If we have an enumeration procedure for S, our proof procedure for S will e this:\nGiven n. Begin listing S. If and when n appears on the list, give the output\n1.m\nTheorem. A set is decidable if and only if it and its complement are both\neffectively enumerable.\nProof: (-) If S is decidable, then there is an algorithm for computing the characteristic function,\nx,, of S. This algorithm will also be a proof procedure for S. The algorithm that takes n to 1 -\nx,(n) will be a proof procedure for the complement of S.\n\nKey Computability Concepts, p. 9\n(*) Given n, begin listing both S and its complement simultaneously. If n appears on the list for\nS, give the output 1. If n appears on the list for the complement, give the output 0.H\nWe've spoken about decidable and effectively enumerable sets, but we can also talk\nabout decidable and effectively enumerable relations, and the same theorems will hold, with the\nsame proofs. Similarly, we described \"calculable partial function\" for 1-place functions, but we\ncan also talk about functions of more than one argument. We have:\nTheorem. A partial function of one argument is calculable if and only if,\nregarded as a binary relation, it is effectively enumerable.\nProof: (-) Suppose that f is a calculable partial function. Here is a proof procedure for f,\nthought of as a binary relation: given m and n, attempt to calculate f(m). If you get an output,\ncheck whether it's equal to n. If it is, give the output 1.\n(*) Given an enumeration procedure for f, here is an algorithm for calculating f: given m, begin\nenumerating f. As a pair appears on the list, check whether its first component is equal to m. If it\nis, give the second component as output.8\nTheorem. A total function of one argument is calculable if and only if, regarded\nas a binary relation, it's decidable.\nProof: (*) Given that f is a calculable total function, here is a decision procedure. Given m and\nn, begin calculating f(m). If f(m) is equal to n, given the output 1. If f(m) is different from n, give\nthe output 0.\n(*) Any decidable total function will be an effectively enumerable partial function, and so\ncalculable. H\n\nKey Computability Concepts, p. 10\nTheorem. The union of two effectively enumerable sets is effectively\nenumerable.\nProof: Given enumeration procedures for A and B, here is a proof procedure for A u B: given n,\nbegin simultaneously listing A and B. If n appears on either list, give the output 1 .B\nTheorem. The intersection of two effectively enumerable sets is\neffectively enumerable.\nProof: Given enumeration procedures for A and B, here is a proof procedure for there\nintersection: given n, begin enumerating A If n appears on the list, then stop worrying about A\nand start listing B. If n appears, give the output 1 EI\nTheorem. A set is effectively enumerable iff it's the domain of a\ncalculable partial function.\nProof: (-) If A is effectively enumerable, then there is a proof procedure for A. By definition,\nthat means that there is a calculable partial function f such that, for any n, n is in A if and only n\nis in the domain off and f(n) = 1. Define a calculable function g by the following algorithm:\nBeing calculating f(n). If you get a value, check whether it's equal to 1. If\nit is, give the output 1\nThen A is the domain of g.\n(*) Iff is a calculable total function, a proof procedure for the domain off is the following:\nBegin calculating f(n). If you get an output, give the output 1 .B\nTheorem. A set is effectively enumerable iff it's the range of a calculable\npartial function.\n\nKey Computability Concepts, p. 1 1\nProof: (-) If A is effectively enumerable, then it's the range of the partial function that takes n\nto the nth number on the list.\n(*) Iff is calculable, then, regarded as a binary relation, it's effectively enumerable. A algorithm\nfor listing the range off is the following:\nList f. Whenever an ordered pair appears, give it's second member as an\noutput. rn\nTheorem. A set is effectively enumerable iff it's either the empty set or\nthe range of a calculable total function.\nProof: (*) Suppose that A is effectively enumerable and nonempty. If A is infinite, then the\nfunction that takes n to the nth element on the list is a calculable total function whose range is A.\nIf A is finite, then it has the form A = {a,, a,, q , ..., a,). Then A is the range of the function f,\ndefined as follows:\nIf i = 0, f(i) = a,,.\nIf i = 1, f(i) = a,.\nIfi = 2, f(i) = q .\n.........................\nIf i = k, f(i) = a,.\nIf i > k, f(i) = a,.\n(*) If A is the empty set, it's enumerated by the lazy algorithm that never gives any output. If A\nis the range of a calculable total function, then it's the range of a calculable partial function.H\nTheorem. A set is effectively enumerable iff it's either finite or the range\nof a one-one calculable total function.\n\nKey Computability Concepts, p. 12\nProof: (-) If A is infrnitc and cffcctivcly cnumcrablc, it can bc listcd without rcpciitions.\nSimply modify the lisling procedure so that a number can only be added to the list if it hasn't\nbeen listed already. Then the fbction h t takes n to the nth item on the list is a onwne\ncalculable total function whose range is f.\n(-) If A is finite, it's effectively enumerable. If A is the range of a one-one calculable total\nfunction, it's the range of a calculable partial functionJ\nTheorem. If A and B are effectively enumerable sets, them there are\neffectively enumerable sets C and D with\nC r A\nD r B\nC n D = a\nC u D = A u B\nProof: Here arc enumeration procedures for C\natld D: bcgin sirnultancously to list A and B. Lf a\nnumber n appears on the list for A at a stage at\nwhich it has not yct appcarcd on thc list for B, put n on thc list for C,\nIf n appcars on thc list for\nB at a stage at which it has not yet appeared on the list for A, put n on the list for D. If n appears\non boh lists at h e same stage, put n on the list for A.\nTheorem. Tf R is an effectively enumerable relation such that\nVx)(3y)R(x,y), then there is a calculable total fimction f such that R(xJrx)),\nfor every x.\n\nKey Computability Concepts, p. 13\nProof: Here is an algorithm fbr calculating f: given n,\nbegin mumerating the ordered pairs in R until you\ncome to one whose k t\ncomponent is equal to n. The\nfirst time you encounter such a pair, give its second\ncomponent as output. H\nIff ia a calculable partial functim (of m e\nv e n t , say), then there is a computer program that\ncalculates f. That is, there is a program that, given a number n as an input, will calculate far a\nwhile, then give the output qn), then Mt,\nif n is in the domain off. Ifn isn't in the domain off,\nthe program will keep runnjng fomver, without giving any output. (We'll look at this a little later\non in more detail.) We can write arrange all the possible program in alphabetical order (or\nsomething like it), so that, for each calculable partial function f, there is a number m such that\nthe mth machine calculates f. Given m and n, we can write out the mth program, then calculate\nwhat output, if any, the program gives on the output n. The haltingproblem is this: given m and\nn, to detemk whether the 111th program halts when it's given the input n. There is a proof\nprocedure for the halting problem, consisting in just carrying out the computation. Them is,\nhowever, no decision procedure.\nTheorem. There is no decision procedure for the halting problem,\nProof: If there were such a decision procedure, then the following recipe would compute a\ncalculable total hctim - call it f:\nGiven m. If the mth machine yields the output k on input m, give the output\nk+1. If the mth machine doesn't halt on in@ m, give the output 0.\n\nKey Computability Concepts, p. 14\nBecause f is calculable, there is a machine that calculates f; let's say it's the jth machine.\nBecause f is total, the jth machine yields an output on every input. In particular, the jth machine\nyields an output on the input j, and we have:\n1 + the output of the jth machine on input j\n= f(j) [by the way f was defined]\n= the output of the jth machine on input j [by the way j was chozen]\nContradiction. H\nTheorem. There are disjoint, effectively enumerable sets A and B such that there\nisn't any decidable set that includes A and in disjoint fiom B.\nProof: Let A = {m: the mth machine gives output 0 on\ninput m). Let B = {m: the mth machine\ngives output 1 on input m). Then A and B are disjoint ~L 2l\\ <~\nand effectively enumerable. Pretend there were a\ndecidable set C that included A and was disjoint fiom B.\nSince C is decidable, its characteristic function is\ncalculable. Let's say the kth machine calculates the\ncharacteristic function of the complement of C.\nIf k is in C, then x,(k) = 1, and so the kth machine yields output 1 on input k, which\nmeans that k is in B. But that's impossible, since B is disjoint from C.\nSo k isn't in C, and so x,(k) = 0, that is, the kth machine gives output 0 on input k. But\nthat means that k is in A, which is a subset of C. Contradicti0n.H\n\nKey Computability Concepts, p. 15\nTheorem. There is a calculable partial function that can't be extended to a\ncalculable total function.\nProof: Using A and B fiom the last theorem, define a calculable partial function g by:\ng(n) = 1 ifn E A\n= O i n n € B\nSuppose, for reductio ad absurdurn, that there were a calculable total function h that extended g.\nThen the function that takes an input n to the maximum of h(n) and 1 would be the characteristic\nfunction of a decidable set that included A and was disjoint from B.H\nSomething important to remember is that effective enumerability and decidability are\nproperties of sets. Whether a set is decidable doesn't depend on how the set is named, and it\ndoesn't depend on our epistemic state. Often, a set can be named in many different ways. S\nmight be {n: n has property P} and it might also be {n: n has property Q}, and it might turn out\nthat we have an algorithm for answering all question of form \"Does\nhave property P?\"\n(where the blank if filled in with an Arabic numeral2) but no algorithm for answering all\nquestions of the form \"Does\nhave property Q?\" In such a case, S would count as\ndecidable. A set S is decidable iff there is some property3 P such that S is the set of numbers that\nS to be decidable, we don't have to be able to answer questions like, \"Does the number of\nfish in Lake Anza have property P?\"\nHere I am using the notion of property \"pleonastically,\" so that to say that Traveler has\nthe property of horseness is just another way of saying that Traveler is a horse. We could\nexpress the same idea without getting tangled in the metaphysics by talking about\npredicates. S is decidable iff there is some predicate 4 such that S = {n: @(n)} and such\n\nKey Computability Concepts, p. 16\nhave property P and such that there is an algorithm for answering questions of the form \"Does\nhave property P?' The fact that there is some other property Q such that S is the set of\nnumbers that have property Q and such that there is no known algorithm for answering questions\nof the form \"Does\nhave property Q?\" doesn't spoil the decidability of S.\nTo take an example, let D = {numbers n: there is a string of n or more successive 7s in\nthe decimal expansion of IT). D is clearly effectively enumerable. The enumeration procedure is\nsimply to start grinding out the decimal expansion of IT and to add n to the list when you come\nacross a string of n 7s. Is D also decidable? No one knows how to answer questions of the form\n\"If\nis D?' No one knows whether 1000 is in D, or whether 1,000,000 is in D. As far as\nanyone knows, every number could be in D. Nonetheless, D is decidable. If it happens to be the\ncase that every number is in D, the a decision proacedure for D is the following:\nNo matter what the input, give the output 1.\nIf not every number is in D, then there is a number k such that D = {n: n I k). In that case, a\ndecision procedure for D is this:\nGive the output 1 is the input is I k. If the input is > k, give the output 0.\nOne way or another, there is a decision procedure for D.\nThe same goes for functions: a partial function is a set of ordered pairs, and whether it's\ncalculable doesn't depend on how the function is names. To take an example, the Continuum\nthat there is an algorithm for determining the truth values of sentences obtained from the\nopen sentence @(x) by replacing free occurrences of \"x\" by a numeral. It doesn't matter\nif there is another predicate $ such that S = (n:$(n)) for which there is no such\nalgorithm.\n\nKey Computability Concepts, p. 17\nHypothesis is the most famous unproved conjecture in set t h e ~ r y . ~\nNot only hasn't anyone ever\nbeen able either to prove or to refbte the Continuum Hypothesis, but it's known that the\nhypothesis can't be either proven or refuted on the basis of the currently accepted axioms of set\ntheory. Now consider the function c, defined as follows:\nf(n) = n+l if the Continuum Hypothesis is true\n= n it the Continuum Hypothesis is not true\nIt is not possible, on the basis of the currently accepted of set theory, to determine any of\nthe values of the function c. Nonetheless c is calculable. Either c is the successor function, which\nis calculable, or c is the identity map, which is calculable.\nWe've managed to identify some general structural properties of the set of effectively\nenumerable sets, but we haven't yet attempted to say precisely which the effectively enumerable\nsets are. We are going to wind up identifying the effectively enumerable sets as those that are\nnamed by especially simple formulas of the language of arithmetic. So what we need to do now\nis to introduce the language of arithmetic.\nTo make the point we're making here, it doesn't matter what the hypothesis says.\n\nKcy Computability Concepts, p. 18"
    },
    {
      "category": "Resource",
      "title": "lange_of_arithmt.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/69264e67df9852bb9c5eb003b6c7fdb6_lange_of_arithmt.pdf",
      "content": "The Language of Arithmetic\nThe language of arithmetic is the language whose only individual constant is \"0,\" whose\nfunction signs are \"s,\" \"+,\" \"a,\" and \"E,\" and whose predicates are \"<\" and \"=.\" In the standard\nmodel, which we call 'bN,\"l \"0\" denotes the number 0, the four functions signs denote the\nsuccessor function, addition, multiplication, and exponentiation, respectively, \"<\" stands for\n\"less than,\" and \"=\" stands for identity. More specifically:\n\"0\" is a term of the language of arithmetic.\nThe variables \"x,,\" \"x,,\" \"x,,\" \"x,,\" and so on are terms of the language of\narithmetic.,\nIf T and p are symbols of the language of arithmetic, so are ST, (T + p),\n(Top), and (TEP).\nNothing else is a term of the language of arithmetic, unless it is required to\nbe by the three clauses above.\nWe have unique readability: every term is built up in a unique way. More specifically,\nfor each term o, there is a unique finite labeled tree, called the structure tree for a, with the\nfollowing features:\nThe trunk of the tree is labeled with o.\nIf a node of the true is labeled by ST, then there is directly beneath it one\nnode labeled by T.\nWe also use \"N\" to denote the set of natural numbers. I hope that no confusion will\nresult.\nWe'll only use these variables on black-tie occasions. Most of the time, we'll use other\nletters from the end of the alphabet as variables, to avoid proliferation of subscripts.\n\nThe Language of Arithmetic, p. 2\nIf a node is labeled by (T + p), by (zap), or by (TE~), then there are two\nnodes directly beneath it, the left labeled by T and the right by p.\nEach leaf of the tree is labeled either by \"0\" or by a variable.\nA closed term is a term that contains no variables. Within the standard model, each\nclosed term denotes a natural number, uniquely determined as follows:\nDen(\"0\") = 0.\nDen(sz) = Den(T) + 1.\nDen((T + p)) = Den(7) + Den@).\nDen((vp)) = Den(z)*Den(p)\nDen((TEp)) = ~en(T)~\"(~).\nWe introduce a standard numeral for each number by stipulating that [n] is the symbol obtained\nby writing n \"s\"s in fiont of \"0,\" so that, for example [7] = \"sssssssO.\"\nThe function that takes the symbol T to the number Den(z) is calculable. One algorithm\nyou might use for this purpose is, first, to produce a labeled tree with T at its trunk, representing\nthe structure of T, as described above; and then to associate a number with the label for each\nnode, working fiom the leaves toward the trunk. \"0,\" which labels the leaves, is associated with\n0. If If the nodes associated with p and p are associated with n and m, respectively, associate\nn+m with (p + p). And so on.\nThe atomic formulas of the language of the arithmetic are expressions of one of the forms\nT < p or T = p, for T and p terms. The formulas are characterized by the following stipulation:\nEvery atomic formula is a formula.\nI f 0 and q are formulas, so are ( 0 V q), ( 0 A q), ( 0 - q), ( 0 - q), -0,\n\nThe Language of Arithmetic, p. 3\n(3xJ4, and (VxJ4, for each n.\nNothing is a formula, unless it's required to be by the clauses above.\nWe have unique readability for formulas, just as for terms.\nAn occurrence of the variable x, within a formula is bound iff it occurs within some\nsubformula that begins with (Vq)\nor (3%). Occurrences that aren't bound areji-ee. A sentence is\na formula that contains no free variables.\nFor 4 a formula and r a term, let 4%lr be the formula obtained from 4 by substituting r\nfor each free occurrence of x, in 4. Where there's no threat of confbsion about which variable is\ninvolved, we'll sometime write @(r) instead.\nTruth in the standard model is defined by first stating the truth conditions for atomic\nsentences, then seeing how the truth conditions for complex sentences are determined by the\ntruth conditions for simpler sentences. A special feature of the standard model is that every\nmember of the domain of discourse is named by some numeral. This special feature will simplifl\nthe definition of truth, since we can define truth directly, rather than having to define truth in\nterms of satisfaction.\nr < p is true if the standard model iff Den(.r;) < Den@).\nr = p is true in the standard model iff Den(r) = Den@).\n( 4 V $) is true in the standard model iff either or both of 4 and $ are true in\nthe standard model.\n( 4 A $) is true in the standard model iff both 4 and $ are true in the standard\nmodel.\n( 4 - $) is true in the standard model iff either 4 isn't true in the standard model\n\nThe Language of Arithmetic, p. 4\nor $ is.\n( 4 - $) is true in the standard model iff either 4 and $ are both true in the\nstandard model or neither of them is.\n-4 is true in the standard model iff 4 isn't true in the standard model.\n(3x39 is true in the standard model iff, for some k,\nis true in the\nstandard model.\n(VxJ@ is true in the standard model iff, for every k, @%I\nis true in the\n[kl\nstandard model.\n4 is false in the standard model iff -4 is true in the standard model.\nTrue arithmetic is the set of sentences true in the standard model We shall see that there\nis no decision procedure for true arithmetic, or even a proof procedure. We do, however, have\nthis much:\nProposition. There is a decision procedure for the set of true quantifier-free\nsentence^.^\nProof: First note that there is a decision procedure for the set of true atomic sentences. Namely,\nT < p is true iff Den(7) < Den(p) and T = p is true iff den(^) = Den@). The truth of a quantifier-\nfree sentence is determine by the truth or untruth of its atomic components by the laws of the\nsentential calculus. A way to determine the truth or falsity of a quantifier-free sentence 0 is to\nform the structure true for 0, then associating a truth value, truth or falsity, with the label of each\nnode, starting with the leaves and working toward the trunk. For example, a node labeled ( 4 V\nExcept when there's an indication to the contrary, by \"true\" arithmetical sentence, I shall\nmean an arithmetical sentences true in the standard model.\n\nThe Language of Arithmetic, p. 5\n$) will be labeled \"true\" if and only if one or both of the nodes immediately beneath it is labeled\n\"true.\"H\nWe introduce the bounded quantiJiers: for 4 a formula and T term, (3% < T)@ will be an\nabbreviation for (3rZ3(% < T A 4). (b'q < T)@ abbreviates (b'%)(x, < T - 4). The bounded\nformulas are characterized as follows:\nEvery atomic formula is bounded.\nIf 4 and $ are bounded formulas, so are ( 4 V $), ( 4 A $), ( 4 - $), ( 4 - $)\n-4, (3% < T)@, and @'% < T)@, for each n and T.\nNothing else is a bounded formula.\nWe use \"p I T\" and an abbreviation for \"p < ST.\" Thus, if 4 is a bounded formula, so are (3% I\nT)@ and @iZ, I T)@, for each n and T.\nA bounded set is the extension of a bounded formula, that is, it is a set of the\nform {x: @([XI)), for some bounded formula 4 . Similarly for bounded relations.\nThe functions Pair, 1 st, and 2nd are bounded. So is the relation that holds between x and\ny iff x is an element of the set whose code number is y; we'll abuse notation slightly by writing\n\"x E y.\" The set of code numbers of sequences is a bounded set, as is the partial function that\ntakes x and i to the ith member of the sequence coded by x (which we write \"(x)?) if x codes a\nsequence of length i or greater, and is undefined otherwise.\nProposition. There is a decision procedure for the set of true bounded sentences.\nProof: Working fiom the outside in, replace each subformula of the form (Vx < T)@ by the\nconjunction4 of all the $([k])s for k < Den(z). Replace (3x < T)$ by the disjunction of all the\nTo make this work out smoothly, we adopt the convention that the conjunction of ($1 is\n\nThe Language of Arithmetic, p. 6\n$([k])s for k < den(^). Continue this until you've eliminated all the bounded quantifiers, then\ntest the truth of the quantifier-free sentence that resu1ts.H\nCorollary. There is a decision procedure for each bounded set.\nProof: If S is a bounded set, then it is the extension of a bounded formula @(x). To test whether\nn is in S, check whether @([n]) is true.H\nEvery bounded set is decidable, but not every decidable set is bounded. To see this, we\nemploy a variant of Cantor's diagonal argument. We can recognize a bounded formula by its\nsyntactic structure, so it is possible to list all the bounded formulas that have \"x\" as their only\nfree variable. This gives us a list of all the bounded sets. Let C = {n: n is not an element of the\nnth bounded set on the list}. C is decidable. To check whether n is in C, just write out the nth\nbounded formula on the list and check whether n satisfies it. C is not, however, bounded. For, is\nC were bounded, then there would be a number k such that C = the kth set of the list. But then\nwe would have:\nk E the kth set on the list\niff k E C (by the way k was chosen)\niff k B the kth set of the list (by the way C was defined)\nWe can employ the same argument to thwart any attempt to provide a program that\ngenerates programs that decide each decidable set. Either some of the programs generated won't\njust $, and the conjunction of the empty set of formulas is \"0 = 0.\" For the conjunction fo\na many-element set of formulas, the order in which the conjuncts are taken and the way\nthey are grouped together can be chosen any way you like. Similarly, the disjunction of\n($1 is $, and the disjunction of the empty set of formulas is \"- 0 = 0.\"\n\nThe Language of Arithmetic, p. 7\nbe decision procedures (because they will fail to provide answers for some membership\nquestions) or there will be some decidable sets for which no decision procedure is generated.\nWe can, however, provide a program that list programs that list each effectively\nenumerable set. For any decidable set S, there will be a program on the list that enumerates S and\nanother program that enumerates the complement of S. Taken together, these two programs\nprovide a program that decides S. Knowing this doesn't provide us with a method for listing\ndecision procedures, because we have no algorithm for matching up the program that enumerates\nS with the program that enumerates its complement.\nIn a similar way, we can show that there isn't any program that lists programs for\ncalculating the calculable total functions. Any program that attempts to do this will either list a\nprogram for a function that isn't total or it will leave out some calculable total function. To see\nthis, suppose, for reduction ad absurdum, that we had such a master program. Define a total\nfunction f by:\nf(n) = 1 + the output given by the nth program on input n.\nBecause f is a calculable total function, there will be a program on the list that calculates f; say\nit's the kth program. Then\nthe output given by the kth program on input k\n= f(k) (by the way k was chosen)\n= 1 + the output given by the kth program on input k (by the way f was defined)\nThus the best we can obtain is a program that lists programs that list the calculable partial\nfunctions.\nThe Zformulas are the formulas obtained by prefixing a block of existential quantifiers\n\nThe Language of Arithmetic, p. 8\nto a bounded formula.\nProposition. There is a proof procedure for the set of true 2 sentences.\nProof: Say the sentence is (3vl)(3v,) ...( 3vb4, where 4 is bounded. The proof procedure is to\nsubstitute various k-tuples of numerals for the free variables in 4 until you get a sentence that's\ntrue.\nTo prove a X procedure, all you have to do is to provide a witness. To rehte a X\nsentence, you have to shoot down infinitely many potential witnesses, and it's not too surprising\nthat there is no algorithm for doing that. As we shall see later on, the set of true X sentences is\neffectively enumerable but not decidable.\nA Cset of natural numbers is the extension of a X formula; that is, S is X iff there is a X\nformula 4 such that S = {n: @([n])). X relations are defined similarly.\nCorollary. There is proof procedure for each 2 set.\nProof: Say S is the set of numbers that satisfy the X formula $(x). To enumerate S, start\nenumerating the true X sentences, and add n to the list for S whenever you add @([n]) to the list\nof true X sentences.H\nProposition. If S is a 2 set, then there is a bounded formula @(x,y) such\nthat S = {x: (3y)@([x],y)}. In other words, to define a X set, we don't\nrequire a block of existential quantifiers. A single existential quantifier\nwill do.\nProof: If S is a X set, then there is a bounded formula $(x,yl,y2, ...,ym) such that S = {x:\n(~Y~)(~Y~)...(~YJ$([xI,Y~,Y~,-.-,Y~)~.\nThen S = {x: ( ~ z ) ( ~ Y I\n< z)(3~2 < z).--(3Ym < z)\n$([x],y,,y2, ...,y,)); the stuff that comes after the \"(32)\" is a bounded formu1a.H\n\nThe Language of Arithmetic, p. 9\nIf, instead of starting with a block of existential quantifiers, we start with a block of\nuniversal quantifiers,followed by a bounded formula, the result is a ll formula. The block of\nuniversal quantifiers can be replaced with a single quantifier. The extension of a\nformula is a\nll set. Thus the ll sets are the complements of the x sets. A set that is both x and ll is said to be\nA.\nA confusing terminology has become entrenched. A set or relation is said to be recursive\niff it's A. A set or relation is recursively enumerable or r.e. iff it's x. So far so good, but a x\npartial function is referred to as apartial recursive function. That's confusing, for two reasons.\nFirst, the phrase - \"partial recursive function\" as opposed to \"recursive partial function\" -\nsuggests that what we are dealing with is a part of a total recursive function, but in fact, as we\nshall see later on, there are partial recursive functions that cannot be extended to total recursive\nfunctions. Second, it means that, even though a partial function (of one variable) is a kind of\nbinary relation, a partial recursive function isn't a recursive binary relation, but only a\nrecursively enumerable one. When there's any chance of confusion, I'll try to use ''A\" and \"x\"\nin place of \"recursive\" and \"recursively enumerable.\"(For total functions, the confusion happily\ndissipates, since a recursive total function is recursive.)\nNote that the extension of a bounded set is always x , since we can tack a vacuous\nexistential quantifier onto the front of the bounded formula. Since the negation of a bounded\nformula is bounded, it follows that the extension of a bounded formula is always A.\nThe union of two x sets is x , as is their intersection. If R is a x relation, {x: (3y)Rxy),\n{x: (3y < k)Rxy), and (x: (Vy < k)Rxy) are all x sets, for each k.\n\nThe Language of Arithmetic, p. 10\nAny x total function is A, as indeed is any x partial function with a A domain. A set is\nA iff its characteristic function is A.\nProposition. The following are equivalent, for any set S of natural numbers:\nS is x.\nS is the domain of a Z partial function.\nThere is a x partial function f with domain including S such that f(n) = 1 iff n E\nS.\nThere is a A relation R such that S = {x: (3y)R([x],y)).\nThere is a Z relation R such that S = {x: (3y)R([x],y)).\nS is either empty or the range of a x total function.\nS is the range of a x partial function whose domain is an initial segment of the\nnatural numbers.\nS is the range of a x partial function.\nS is either finite or the range of a one-one x total function.\nProof: The proofs are analogous to the proofs of the corresponding propositions with\n\"effectively enumerable\" in place of \"Z.\" The only part I want to prove here is that, if S is x ,\nthen it's either finite or the range of a one-one x total function. If S is x , it has the form {x:\n(3y)@([x],y)}, for some bounded formula @. If S is infinite, we can define a total function with\nrange S as follows:\nf(0) = lst(the least z with @(lst(z),2nd(z)).\nf(n+l) = 1 st(the least z such that @(lst(z),2nd(z)) and 1 st(z) is different from all\nthe f(i)s with i I n)\n\nThe Language of Arithmetic, p. 1 1\nIn other words,\nf(n) = lst(the least z such that @(lst(z),2nd(z)) A (b'w < z)(either\n-@(lst(w),2nd(w)) or (3i < n)f(i) = lst(w))).\nPut a different way, f(x) = y iff there is a finite sequence s of length m that meets the following\nconditions:\n(b'n < m)(3z)(@(l st(z),2nd(z)) A @iy < z)(-@(1 st(w),2nd(w)) V (3i<n)(s), =\nlst(w))A lst(z) = (s)$.\nx < m A (s), = y.\nThis all gets encoded as a x formula. There is a little more to this than meets the eye, since \"lst,\"\n\"2nd,\" and the notation for the components of a finite sequence aren't part of the language of\narithmetic, but part of the dialect of English we use in talking about numbers informally. The\nrelation \"y = lst(x),\" \"y = 2nd(x),\" \"x encodes a sequence of length y,\" and \"x encodes a\nsequence whose yth component is z\" can all be written out as bounded formulas of the language\nof arithmetic. f(x) = y iff\n(3s)(3m I s)(s encodes a sequence of length m A\n(b'n < m)(3z I s((3u I z)(3v I z)((u = lst(z) A v = lst(z)) A @(u,v)) A\n(b'w < z)((3u I x)(3v1 W)(U = lst(w) A v = 2nd(w) A -@(u,v))\nV (3i < n)(3t I s)(s encodes a sequence whose ith member is t A t = lst(w))) A\n(3u I z)(u = lst(z) A s encodes a finite sequence whose nth member is u))\nA x < m A s encodes a finite sequence whose xth member is y).\nWhen you write this out in primitive notation and apply our rules for pulling quantifiers to the\nfront (taking care to avoid collisions of bound variables), you really do get a x formu1a.H\n\nThe Language of Arithmetic, p. 12\nWe have just witnessed a special case of a general technique, devised by Frege and Godel,\nfor turning recursive definitions into explicit definitions. Let us now describe the technique a little\nmore abstractly. Recursive definitions of functions of one variable take two familiar forms. (For\nfunctions of more than one variable, not much changes. The extra variables go along for the ride.)\nThe more common form of recursive definition occurs when the value of the function only\ndepends on the immediately preceding value of the function. Thus the definition takes the form:\nf(0) = k\nf(n+ 1) = g(n+ 1, f(n))\nwhere k is a number and g is a (total) function that is already known. We turn this into an explicit\ndefinition by stipulating\nf(x) = Y =I,,,\n( 3 sequence s)(3m I s)(m is the length of s A (s), = k\nA (for any n with n+l < m, (s),,\n= g(n+l ,(s)J) A x < m and (s), = y).\nA little more explicitly:\n(3s)(3m I s)(s encodes a sequence of length m A\ns encodes a sequence whose 0th member is [k] A\n(Vn < m)((n + [I]) < m - (3w I s)(3z I s)(s encodes a sequence\nwhose (n + [l])st member is w A s encodes a sequence whose nth member is z\nA g((n + [l]),z) = w) A s encodes a sequence whose xth member is y)\nWe can write this out a a x formula, once we replace \"g((n + [l],z) = w)\" by a x formula.\nThe other form, which was the form we witnessed above, is where a value of the function\ndepends on all the earlier values. For f a function, let f I n be the code number for the sequence\n\nThe Language of Arithmetic, p. 13\n<f(O),f(l), ..., f(n-I)>. For s the code number of a sequence of length n or greater, let s In be the\ncode number for the sequence <(s),,(s),, ...,( s),-~>. I realize I'm using the same symbol for two\ndifferent purposes, but it should be harmless. Our recursive definition takes the form\nf(n) = h(f I n),\nwhere h is already known. It's explicit version is this:\nf(x) = Y =a,\n( 3 finite sequence s)(3m I s)(m is the length of s A\n(b'n < m)(s), = h(s I n) A x < m A (s), = y).\nIf h is x , so is f.\nHere again, I am claiming that a set is x on the basis of having described it by a x hybrid\nformula that contains symbols from both formal and informal arithmetic. Let me describe a\ngeneral procedure that justifies such claims. The procedure only applies to formulas that don't\ncontain \"-\" or \"-,\" apart from the \"-\"s that occur in bounded universal quantifiers, but there's\nno loss of generality in that. Suppose a set S is defined by a x formula of the language obtained\nfrom the language of arithmetic by adding an extra unary function sign f that is used to denote a\nunary total recursive function. The same technique will work for sets and relations defined using\nmore than one function sign, and it will work with function signs with more than one agurnent.\nWe restrict our attention to the single unary function case just to keep the notation manageable.\nThe strategy is simple. We cash out any atomic formula containing \"f' either in terms of\nthe x definition or the II definition, as appropriate, then pull the quantifiers to the front. The\ndetails are messy, however.\nA recursive total function is II as well as x. Let's say we have f(x) = y iff (3z)@(x,y,z) iff\n\nThe Language of Arithmetic, p. 14\n(VZ)~(X,~,Z),\nwhere $ and 0 are bounded. We describe a procedure for converting a x formula\ncontaining f that defines S to a x formula containing one fewer occurrence off that also defines\nS. By applying the procedure repeatedly, we obtain a x formula of the language of arithmetic that\ndefines S.\nOur given occurrence off is either within an atomic formula or within a bounded\nexistential quantifier or within a bounded universal quantifier. It is this multiplicity of\npossibilities, as well as the fact that we sometimes utilizize the x definition off and other times\nthe II definition, that makes the procedure complicated to describe.\nThe procedure proceeds in two stages. At the first stage, if the given occurrence off\nappears within an atomic formula of the form xVIf(\nreplace the atomic formula with\n7)'\n(3~)(3z)($(z,v,z) A x), if the atomic sentence is within the scope of an even number of negation\nsigns, or with @ir)(Vz)(~(z,v,z)\n+ x), if it's within the scope of an odd number of negation signs.\nIf, on the other hand, the given occurrence off takes the form (3u < pv~f(T))~,\nreplace it with\n(3~)(3z)(x(z,v,z) A (3u < p ) ~ ) ,\nif the occurrence is within the scope of an even number of\nnegation signs, or with (Vv)(Vz)(e(z,v,z) - (3u < p ) ~ ) ,\nif the number of negations is odd. If, on\nthe third hand (!), the given occurrence off takes the form (tlu < pvIf(T))~, replace it with either\n(~v)~z)($(T,v,z)\nA (Vu < p ) ~ )\nor (Vv)(Vz)(e(z,v,z) - (Vu < p ) ~ ) ,\ndepending on whether the\noccurrence is within the scope of an even or odd number of negation signs.\nThe first stage has introduced a new unbounded quantifier. The second stage applies the\nusual methods for pulling the negation sign to the front. Here are the \"usual methods\"; we assume\nthat v doesn't occur free in V, and we change bound variables as required to avoid collisions:\nReplace ((3v)p V V) by (3v)(p V v).\n\nThe Language of Arithmetic, p. 15\nReplace (V V (3v)p) by (3v)(v V p)\nReplace (@ir)p v V) by (b'v)(p V v).\nReplace (V V (Vv)p) by (VV)(V V p)\nReplace ((3v)p A V) by (3v)(p A v).\nReplace (V A (3v)p) by (3v)(v A p)\nReplace (@ir)p A V) by ('dv)(p A v).\nReplace (V A (Vv)p) by (VV)(V A p)\nReplace (3u < ~ ) ( 3 v ) p\nby (3v)(3u < ~ ) p .\nReplace (3u < ~)(Vv)p by ('dt)(3u < T)(Vv < t)p.\nReplace ('du < ~ ) ( 3 v ) p\nby (3t)('du < ~ ) ( 3 v\n< t)p.\nReplace (Vu < ~)(Vv)p by ('dv)(Vu < T)p.\nReplace -(3v)p by ('dv)-p.\nReplace -(Vv)p by (3~)-p.\nThe eventual result will be a x formula defining S.\nLet me now state, without going through the proofs, a couple of structural properties of x\nsets and relations, directly analogous to properties we noted earlier for effectively enumerable\nsets and relations:\nProposition (Reduction Principle for x sets). For any 2 sets A and B,\ntherearexsetsCandDsuchthatCcA,DrB,CnD=ca,andCuD=\nA u B.\nProposition (Uniformization Priniciple for x relations). For any 2\nrelation R, there is a x partial hction f with Dom(f) = {x: (3y) <x,y> E\n\nThe Language of Arithmetic, p. 16\nR) and <x,f(x)> € R for each x € Dom(f)."
    },
    {
      "category": "Resource",
      "title": "modal_logic.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/14fd086c8c3edf68af8b3d7d9653d36f_modal_logic.pdf",
      "content": "An Introduction to Modal Logic\nOrdinary logic studies the partition of sentences1 into two categories, true and false.\nModal logic investigates a finer classification. A sentence can be either necessary (true, and it\ncouldn't have been otherwise), contingently true (true, but it might have been false), contingently\nfalse (false, but it might have been true). or impossible (couldn't have been true). The informal\nstudy of the logical properties of modality goes back at least to Aristotle, but the advent of\nformal systems of symbolic modal logic dates from the publication of C. I. Lewis's Survey of\nSymbolic Logic2 in 19 18. Lewis started with the sentential calculus, and added symbols to\nrepresent \"it is necessary that,\" \"it is possible that,\" and imp lie^.\"^ He then developed deductive\ncalculi by adopting various appealing axioms and deriving their conseqeunces.\nWhat redeemed formal modal logic fiom empty symbol pushing was the development of\npossible-world semantics. The idea comes fiom Leibniz, who thought of God as surveying all\npossible worlds, selecting the one that was best, and making it actual. The idea that this is the\nbest of all possible worlds is a nutty idea, even by philosophers' standards - see Voltaire's\nCandide - but it proved fruitful. Possible-world semantics for modal sentential calculus were\ndeveloped by J.C.C. MacKensie and Alfied Tarski in the 1940s; and they were extended to\nI am restricting attention to sentences used to make assertion, setting aside sentences\nused to ask questions or make requests or issue promises. A general theory that encompasses\nthese other ways of employing language is developed by John Searle in Speech Acts (Cambridge:\nCambridge University Press, 1969).\nBerkeley, Calif.: University of California Press.\nRecall my polemics in Logic I against reading \"-\" as \"implies.\" The confusion of\n\"implies,\" which is a transitive verb, with a sentential connective originates with Alfied North\nWhitehead and Bertrand Russell's Principia Mathematica (Cambridge: Cambridge University\nPress, 1910). See W. V. Quine, \"Reply to Professor Marcus,\" Synthese 20 (196 I), reprinted in\nQuine, The Ways of Paradox (Cambridge, Mass.: Harvard University Press, 1966).\n\"On Closed Elements in Closure Algebra,\" Annals of Mathematics 47 (1 946): 122- 162.\n\nModal Logic, p. 2\nmodal predicate calculus by Saul Kripke in the 1 9 6 0 ~ ~\nWe'll only talk about modal sentential\ncalculus here, and that only s~perficially.~\nWe start with a version of the sentential calculus with infinitely many atomic sentences\nand add an operator \"0,\" read \"it is necessary that\"; if 4 is a sentence, so is 04. We treat\nLewis's symbol for possibility, \"0,\" as defined: 04 =,,,\n- - 4 . We'll have no need for\nLewis's symbol for implication.\nOur interest here is in the interpretation of the modal sentential calculus in which \"0\"\nmeans \"It is provable that,\" so that \"0\" means \"It is consistent that.\"\nA Kripke model is an ordered quadruple <W,R,I,a>, where W, the set of worlds, is a\nnonempty set; R, the accessibility relation is a binary relation on W; I, the interpretation\nfunction, is a function that assigns to each pair <@,w> with 4 a sentence and w a world either\nthe value 0 or the value 1; and a E W is the actual world. The triple <W,R,I> is afiame. For 4\nand atomic sentence and w a world, 4 is true in w if and only if I(@,w) = 1. A conjunction is true\nin w iff both conjuncts are true in w, a disjunction is true in w if and only if one or both disjuncts\nare true in w, and so on. 04 is true in w iff 4 is true in every world v with Rwv. A sentence is\ntrue in the model iff it's true in a.\nA sentence is valid for a frame or set of frames iff it's true at every world in every\nmember of the set.\n\"Semantical Considerations on Modal Logic,\" Acta Philosophica Fennica 16 (1 963):\n83-94.\nFor a fuller treatment, see Brian Chellas, Modal Logic (Cambridge: Cambridge\nUniversity Press, 1980), G. E. Hughes and Max Cresswell, A New Introduction to Modal Logic\n(Routledge, 1996), or J. C. Beall and Bas van Fraassen, Possibilities and Paradox (Oxford:\nOxford University Press, 2003).\n\nModal Logic, p. 3\nA normal modal system is a set of sentences I? with the following properties:\nTautological consequence: Every tautological consequence of\nis in r.\nNecessitation: If 4 is in r , so is 0 4 .\nSchema (K): Each instance of the axiom schema\n(K)\n( U 4 + $1 + ( 0 4 +\n$1)\nis in I?.\nTheorem. For\na set of sentences, the following are equivalent:\n(i)\nI? is a normal model system.\n(ii)\nThere is a class of frames such that I? is the set of sentences valid for\nevery member of the class\n(iii)\nEither I? is the set of all sentences or there is a frame <W,R,I> such that I?\nis the set of sentences valid for <W,R,I>.\n.\nProof: That (ii) implies (i) is easy to check. That (iii) implies (ii) is immediate; if r is the set of\nall sentences, our class of frames will be the empty class. So we only need to worry about\nshowing that (i) implies (iii). Given\na normal modal system, let's say a set of sentences is r-\nconsistent iff it contains all the members of I? and it is consistent by the sentential calculus. A\nmaximal r-consistent set is a r-consistent set such that, for every sentence, either the sentence\nof its negation is in the set. Let W be the class of all maximal r-consistent sets of sentences;\nunless\nis the set of all sentences, W will be nonempty. For u and v elements of W, define Ruv\niff 4 is in v whenever 04 is in W. Define I(@,w) = 1 iff 4 E w, for 4 atomic. We want to show\nthat, for any sentence 4 , 4 is true in w in the frame <W,R,I> iff 4 E w. This will tell us that the\nfolowing are equivalent:\n\nModal Logic, p. 4\n4 ~ r\n4 is an element of every maximal r-consistent set\n4 is an element of every world w in W\n4 is true in every world w in W\n4 is valid for the frame <W,R,I>\nThe proof that, for any sentence @ , a is true in w if and only if 4 E w proceeds by\ninduction on the complexity of 4. The only part of this that isn't entirely routine is to show that\nO$ is true in w iff its a element of w. Here's the proof of the right-to-left direction: If O$ is an\nelement of w, then, by definition of R, $ is an element of every world accessible from w. It\nfollows by inductive hypothesis that $ is true in every world accessible from w, that is, that O$\nis true in w.\nFor the other direction, suppose that 01) isn't an element of w. We want to see that there\nis a world accessible from w in which $ isn't true. This means, according to the inductive\nhypothesis, that we want a world accessible from w that contains $. That is, given the definition\nof R, we want a maximal r-consistent set of sentences that includes all the sentences 8 with 08\nin w but that doesn't include $. To get this, it will suffice to show that I' u {sentences 8: q 8 E\nw) u {- $1 is tautologically consistent. If it is, we can expand I? u (8: 8 E w) u {-$1 to a\nmaximal r-consistent set by the familiar technique of marching through the sentences one by\none, for each sentence when we come to it adding either it or its negation to the set, preserving\nr-consistency at every stage. Because of Necessitation, if y is in r , O y is in I', and so O y is in\nw and y is in (8: 08 E w). So it will be enough to show that (8: 08 E w) u z{-$1 is\ntautologically consistent. If not, then there exist sentences 8,, 8,, ..., 8, such that each O8i is in\n\nModal Logic, p. 5\nw and such that (0, - (0, - ... - (0, - q ) ...)) is a tautology. It follows by Tautological\nConsequence and Necessitation that O(0, - (0, - ... - (0, - q ) ...)) is a member of r , and\nhence, by multiple applications of Tautological Consequence and Schema (K), that (00, - (08,\n- ... - (00, - O q ) ...)) isn in r , and hence in w. Because w is closed under modusponens, it\nfollows that O* is in w, contrary to our assumption.\nThe fi-ame <W,R,I > that we just constructed is called the canonicalfiame for I?. The\nprincipal moral of the theorem is that, if a sentence is outside I?, then there is a world in the\ncanonical fi-ame in which it is fa1se.W\nLet me write down some axioms schemata; the schemata were named by different people\nat different times, so the nomenclature is annoyingly haphazard:\n(TI\n( 0 4 - 4 )\n(4)\n( 0 4 - 0 0 4 )\n(B)\n( 4 - 0 0 4 )\n(5)\n( 0 4 - 0 0 4 )\nLet me also write down some notable properties of binary relations:\nR is a reflexive relation on W iff, for each w in W, we have Rww.\nR is transitive iff, for each u, v, and w, if Ruv and Rvw, then Ruw.\nR is symmetric iff, for each u and v, if Ruv, then Rvu.\nR is Euclidean iff, for each u, v, and w, if Ruv and Ruw, then Rvw.\nK is defined to be the smallest normal modal system (that is, every other normal modal\nsystem includes K), so that a sentence is an element of K iff it is derivable fi-om instances of\nschema (K) by the rules TC and Necessitation. A sentence is in K iff it is true in every world in\n\nModal Logic, p. 6\nevery frame. Why? The set of sentences valid for every frame is a normal modal system, so it\nincludes K. If 4\nisn't in K, then there is a frame in which there is a world in which 4\nis false,\nnamely, the canonical model for K.\nKT is defined to be the smallest normal modal system that includes (T), so that a sentence\nis an element of KT iff it is derivable from (K) and (T) by the rules TC and Necessitation. A\nsentence is a element of KT iff it is true in every world in every reflexive frame. Why? Given a\nmodel <W,R,I,a>, with R reflexive, if 04\nis true in a, then 4\nis true in every world accessible\nfrom a; in particular, 4\nis true in a itself; so all instances of schema (T) are true in the model.\nConsequently, the set of sentences valid for every reflexive frame is a normal modal system that\nincludes (T). Moreover, the canonical frame for KT is reflexive; for any world w in the canonical\nframe, if 04\nis in w, 4 is in w, so we have Rww. Thus, if 4\nisn't in KT, then there is a reflexive\nframe in which there is a world in which 4\nis false, namely, the canonical frame for KT.\nK4 is defined to be the smallest normal modal system that includes (4). A sentence is an\nelement of K4 iff it's true in every world in every transitive frame. Why? Given a model\n<W,R,I,a> with R transitive, if q 4 is true in a and w is a world accessible from a, then every\nworld accessible from w is accessible from a.. Since 4\nis true in every world accessible from a,\n4 must be true in every world accessible from w, so that q 4\nis true in w. We have shown that\nq 4\nis true in every world accessible from a, so that\nis true in a. Thus we see that all\ninstances of schema (4) are true in the model, so that the set of sentences true in every transitive\nmodel will be a normal modal system that includes (4). Moreover, the canonical frame for K4 is\ntransitive. If u, v, and w are worlds in the canonical frame for K4 with Ruv and Rvw, then if 04\nis in u,\nq 4\nis in u, so that 04\nis in v and 4\nis in w. Consequently, Ruw. Thus, if $ is not in\n\nModal Logic, p. 7\nKT, then the canonical frame for KT will be a transitive frame in which there is a world in which\n4 is false.\nKB is the smallest normal system that contains (B). A sentence is in KB iff it's valid for\nthe class of symmetric frames.\nK5 is the smallest normal modal system that includes (5). A sentence is in K5 iff it's\nvalid for the class of Euclidean frames.\nKT4, which Lewis called 34,\" is the smallest normal modal system that includes both\n(T) and (4). A sentence is is KT4 iff it's valid for the class of reflexive, transitive frames.\nKTB is the smallest normal modal system that includes both (T) and (B) A sentence is in\nKTB iff it's valid for the class of reflexive, symmetric frames.\nKT5, which Lewis called (SS), is the smallest normal modal system that includes both\n(T) and (5). A sentence is in KT5 iff it's valid for the class of reflexive, Euclidean frames. Since\na binary relation that is reflexive and Euclidean will also be transitive and symmetric, KT5 is the\nsame as KT4B5.\nI could keep doing this for a long time, but you get the point.\nThe mystery component of the story is the accessibility relation. I have never heard a\nremotely satisfling explanation of why one possible world should or should not be accessible\n\nModal Logic, p. 8\nfrom an~ther.~\nAs far as I can tell, the accessibility relation is something we tack on ad hoc so as\nto get the pretty relations between frames and axiom systems.\nWe sometimes think if the march of history as following a forked path through a\ncontinually unfolding array of branching possibilities, so that what happens now can constrain\nwhat will be possible tomorrow. It could happen that, as of now, it's possible that I should fly to\nJamaica tomorrow, but that some untoward event could happen tonight that would render it\nimpossible for me to fly to Jamaica tomorrow; I might, for example, be eaten by a tiger escaped\nfrom a circus. So, even though it's not possible for me to fly to Jamaica tomorrow, it might\nbecome impossible for it to be possible for me to fly to Jamaica tomorrow, so that some\ninstances of schema (5) can fail. To represent this conception formally, we take a \"possible\nworld\" to be, not (as we would have expected) a possible complete course of history, but rather\nan ordered pair consisting of a complete course of history and a time. A statement will be\npossible at <h,t> if its truth is compatible with the course of history according to h as it has\nunfolded up to time t. A statement not involving modality will be true in <h,t> iff it's true in h. A\npair <h',t'> will be accessible from <h,t> if t' is later than or equal to t and if h and h' agree in\ntheir depiction of the history of the world up to time t. The appropriate modal logic will be KT4."
    },
    {
      "category": "Resource",
      "title": "nonstandrd_modls.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/ef3e9da20b387581eee9daef90a4ab82_nonstandrd_modls.pdf",
      "content": "Nonstandard Models of True Arithmetic\nWe have talked a lot about the standard model of the language of arithmetic, but there are\nother models of true arithmetic (the set of sentences true in the standard model) that aren't\nisomorphic to the standard model. Indeed, consider the theory r' consisting of true arithmetic,\ntogether with all sentences \"[n] < c,\" where \"c\" is a new constant. If A is a finite subset of I?,\nthen we can model of A by expanding the standard model by letting \"c\" denote a number larger\nthan any of the numbers n with \"[n] < c\" E A. It follows by the compactness theorem that there\nis a model of r'. A model of r will be a nonstandard model of true arithmetic, that is, a model of\ntrue arithmetic that isn't isomorphic1 to the standard model.\nAn initial segment of a nonstandard model U of true arithmetic is defined just as it is for\nthe standard model: S r IUI is an initial segment iff, for any y E S, any element of IUI that is <' y\nis an element of S. The map taking n to [n]' is an isomorphism from the standard models onto an\ninitial segment of 9. The elements of 191 that aren't in the range of this isomorphism are the\nnonstandard elements. To see that the range of the isomorphism is an initial segment, note first\nthat U can't hide any nonstandard elements below o', because \"(Vx)- x < 0\" is part of true\narithmetic. It can't sneak any nonstandard elements below [n+l]', because ('dx)(x < [n+l] - (x =\nWhere U and 23 are models of the language of arithmetic, an isomorphism from U to 23 is\na bijection f from IUI to 1231 with the property that f(0') =0', f(x +' y) = f(x) +' f(y), x 2'\ny iff f(x) <' f(y), and so on. If o is a variable assignment for U, then o satisfies the same\nformulas in U that foo satisfies in 23. (Here foo is the variable assignment for 23 given by\nfoo(v) = f(o(v)).) It follows that the same sentences are true in U and in 23.\n\nNonstandard Models, p. 2\n[0] V x = [I] V ... V x = [n]))\" is in true arithmetic. Because we have \"(Vx)(Vy)(x < y V x = y V\ny < x),\" all the nonstandard elements are greater than all the standard elements.\nLet a be a nonstandard element. Because true arithmetic assures us that every number has\nan immediate successor and that every number other than 0 has an immediate predecessor, the\nimmediate neighborhood of a looks just like the (positive and negative) integers. [2]' *' a is\nbigger than all the a +' [nl's, and the immediate neighborhood of [2]' 0' a looks just like the\nintegers. Similarly, [3]' *' a is bigger than all the ([2]' *' a) +' [nl's, and the immediate\nneighborhood of [3]' *' a looks just like the integers. a *' a is bigger than all the [n]' *' as, and\nthe immediate neighborhood of a *' a looks just like the integers.\na satisfies either \"x is even\" or \"x is odd.\"2 If the former, then there is a nonstandard\nelement that when doubled yields a. If the latter, there is a nonstandard element that, when\ndoubled yields a +' [I]'. Either way, we get a nonstandard number that is approximately one-\nhalf of a. The immediate neighborhood of that nonstandard model looks just like the integers.\nSimilarly, there is a nonstandard number that is approximately one-third of a, one that is\napproximately two-thirds of a, and so on. For any positive integers p and q, there is a\nnonstandard number b such that [q]' 0'\nb and [p]' *' a differ by a standard number. In other\nwords, there is a nonstandard number that is approximately equal to\ntimes a.\nJust looking at the order, we can say precisely what the countable nonstandard models\nlook like. There is an initial segment that looks like the natural numbers, followed by a bunch of\ncopies of the integers. The copies of the integers are ordered; we can say that one copy is less\nthan another iff the members of the first are -?\" the members of the second. The order on the\nThat is, a satisfies either \"(3y)([2]0y) = x\" or (3y)(([2]*y) + [I]) = x.\"\n\nNonstandard Models, p. 3\ncopies is isomorphic to the order on the rational numbers. This description characterizes the\norder relation on countable, nonstandard models of true arithmetic, uniquely up to isomorphism.\n(For uncountable models, the picture is similar, but harder to make precise, since uncountable\nnonstandard models aren't mutually isomorphic.) I won't go through the proof here, but you\ncould look it up in Chapter 17 of Boolos and Jeffre~.~\nNonstandard models are troubling, epistemologically. The name \"Fido\" refers to\nsomething we've scratched behind the ears, and the causal connection between our usage of the\nword \"Fido\" and the dog Fido is part of the explanation of how it came to pass that the word\nrefers as it does. For theoretical terms and other terms that don't refer to things to which we are\ncausally connected, there isn't a direct causal explanation, but there may be an indirect causal\nexplanation. We have a, probably informal, theory that tells how the theoretical entities are\nrelated to the entities to which we are directly causally connected, and the theoretical terms refer\nto whatever entities come the closest to playing the role the theory ascribes to them. (\"Comes the\nclosest to playing the role\" rather than \"plays the role,\" since it would be silly to pretend that our\ntheories are completely accurate.) The closer the theoretical entity is to the objects of experience,\nthe more prominent the role that causal connections will play in pinning down reference. When\nwe get to things that are very far removed from the objects of experience, like numbers, the\ncausal connections have nearly dropped out of the picture. To be sure, we use numbers to count\neveryday objects, but for counting purposes, we use only numbers at the very beginning of the\nnatural number system, so the way we use those numbers doesn't go far at all in telling us about\nGeorge Boolos and Richard Jeffrey, Computability and Logic, 3rd ed. (New York and\nCambridge: Cambridge University Press, 1989).\n\nNonstandard Models, p. 4\nthe structure of the natural numbers as a whole. It is only a slight exaggeration to say that the\nmeaning of our mathematical terms is given by ow mathematical theories.\nNow we have a problem. As we shall see in detail later on, our arithmetical theory - the\nset of arithmetical sentences we can recognize as true - stops far short of true arithmetic. But\neven if we were able to help ourselves to true arithmetic, that isn't enough to pin down the\nmeanings of the arithmetical terms. Even if our arithmetical theory were true arithmetic, that\nwouldn't be enough to pin down the structure of the natural numbers, because the theory has\nnonstandard models.\nAn easy response would be to say that our arithmetical theory isn't isolated. Our beliefs\nabout natural numbers are embedded in a larger system of beliefs that include our beliefs about\nreal numbers and our beliefs about sets. We should be looking at the role of arithmetical terms\nwithin that larger theoretical system.\nThis is an easy response, but not a useful one, since we can apply the same argument to a\nlarger language that includes the language of set theory and the language of real analysis. The\ncompactness theorem still applies, so the set of true sentences of the larger language will still\nhave models with nonstandard natural numbers. We are still left with a deeply disturbing cause\nfor skepticism about arithmetic.\nA different response is that we shouldn't be formalizing our mathematical theory within\nthe predicate calculus, but within some more robust logic to which the compactness theorem\ndoes not apply. (The alternative that is usually proposed is the second-order predicate calculus,\nwhich we'll describe briefly presently.) This response is potentially more helpful, but it's not as\neasy. It arouses the suspicion that we have \"solved\" our problem by Enron-style accounting\n\nNonstandard Models, p. 5\npractices. Some ideas that we used to refer to as \"mathematical\" notions have now been\nrechristened \"logical\" notions, so that what used to be a problem about the foundations of\nmathematics is now a problem about the foundations of logic. We've relabeled a problem, but\nwe haven't solved anything, since the old difficulty about fixing the meanings of mathematical\nterms has reemerged as a problem about fixing the meaning of the new logical terms we\nintroduce when we move beyond the first-order predicate calculus. Or so one suspects. The issue\nremains highly controversial, and we've no hope of resolving it here."
    },
    {
      "category": "Resource",
      "title": "peano_arithmetic.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/2ba966be09dd1301d41d98be9276f3d1_peano_arithmetic.pdf",
      "content": "Peano Arithmetic\nPeano Arithmetic1 or PA is the system we get from Robinson's Arithmetic by adding the\ninduction axiom schema:\n((R(0) A (Yx)(R(x) - R(sx))) - (Yx)R(x)).\nWhat this means is that any sentence of the language of arithmetic that you get from the schema\nby replacing the schematic letter \"R\" with a formula, then prefixing universal quantifiers to bind\nall the free variables is an axiom of PA. Thus PA consist of the axioms (Ql) through (Q1 I),\ntogether with infinitely many induction axioms.\nThe induction axiom schema formalizes a familiar method of reasoning about the natural\nnumbers. To show that every natural number has the property expressed by the formula we\nsubstitute for \"R,\" we begin by showing that 0 has the property; this is the base case. Next we\nderive, by conditional proof, the conditional\nWx)(R(x) - R(sx));\nwe assume R(x) as inductive hypothesis, then derive R(sx). The rule of mathematical induction\npermits us to infer (Vx)R(x).\nVirtually all of our ordinary mathematical reasoning about the natural numbers can be\nformalized in PA. Indeed, after some initial awkwardness, in which we produce proofs of facts\nof elementary arithmetic that we've taken for granted since childhood, reasoning in PA is nearly\nindistinguishable from ordinary arithmetical thinking.\n1'11 do a couple of these early proofs informally here, just to get an idea of what's going\non.\nThe so-called Peano axioms were first formulated by Richard Dedekind. Peano said as\nmuch in a footnote, but somehow \"Peano Arithmetic\" was the name that stuck.\n\nPeano Arithmetic, p. 2\nProposition 1. PA t(Vx)(x = 0 V (3y)x = sy).\nProof: Use the following induction axiom:\n[[(0 = 0 V (3y)O = sy) A (Vx)((x = 0 V (3y)x = sy) - (sx = 0 V (3y)sx = sy))]\n- ('V'x)(x = 0 v (3y)x = sy)]\nThe antecedent is a theorem of pure 1ogic.m\nProposition 2. PA ~(VX)(O\n+ x) = x.\nProof: Use the following induction axiom:\n[[(0 + 0) = 0 A (Vx)((O + x) = x + (0 + sx) = sx)] - (Vx)(O + x) = x]\nThe base clause, \"(0 + 0) = 0,\" follows from (43). To get the induction step, assume, as\ninductive hypothesis (M) that (0 + x) = x. We have\n(0 + sx) = s(0 + x)\n[by (44)]\n= sx\n[by IH] . q\nProposition 3. PA t(Vx)(Vy)(sx + y) = s(x + y).\nProof: We use the following induction axiom:\n(Vx)[[(sx + 0) = s(x + 0) A (Vy)((sx + y) = s(x + y) - (sx + sy) = s(x + sy))]\n- ('V'Y)(SX\n+ Y) = s(x + Y)I.\nThe base clause is easy. Two applications of (43) yield\n(sx + 0) = sx\n= s(x + 0)\nTo get the induction step, assume, as IH,\n(SX + y) = s(x + y).\nWe have:\n\nPeano Arithmetic, p. 3\n(SX + SY) = s(sx + Y) [by (4411\n= ss(x + y) [by IH]\n= S(X + sy) [by (44) again]. H\nProposition 4 (Commutative law of addition). PA t(b'x)(Vy)(x + y) = (y + x).\nProof: We use this induction axiom:\n(b'x)[[(x + 0) = (0 + x)\nWY)((X + Y) = (Y + x) + (x + SY) = (SY + x))l\n- (b'y)(x + Y) = (Y + x)l.\n(43) gives us \"(x + 0) = x,\" and Proposition 2 gives us \"(0 + x) = x\"; these together yield the\nbase clause, \"(x + 0) = (0 + x).\" To get the induction step, assume as IH:\n(x + Y) = (Y + XI-\nWe have:\n(X + SY) = s(x + Y)\n[by (4411\n= s(y + x)\n[by IH]\n= (sy + x)\n[by Proposition 31 H\nProposition 5 (Associative law of addition). PA t(b'x)(Vy)(b'z)((x + y) + z)\n= (x + (y + z)).\nProof: Two applications of (43) give us the basis clause, \"((x + y) + 0) = (x + (y + O)).\" To get\nthe induction step, assume as IH:\n((x + Y) + z) = (x + (Y + z)).\nWe have:\n((x + y) + sz) = s((x + y) + z)\n[by (4411\n= s(x + (y + z))\n[by IHI\n\nPeano Arithmetic, p. 4\n= (x + s(y + z))\n[by (4411\n= (X + (y + sz))\n[by (4411--\nProposition 6. PA t('dx)(o.x) = 0.\nProof: The base clause, \"(0.0) = 0,\" comes from (Q5). To get the induction, assume as IH:\n(0.x) = 0.\nWe have:\n(0.s~) = ((0.x) + 0) [by (4611\n= (0.x)\n[by (4411\n=O\n[by IH] . q\nProposition 7. PA t(~x)(b'~)(sx.~)\n= ((xmy) + y).\nProof: We derive the base clause as follows:\n(sx.0) = o\n[by (Q5)\n= (x.0)\n[by (Q5) again1\n= ((x0y) + 0) [by (Q3)I.\nAssuming, as IH,\n(sx0y) = ((x0y) + Y),\nwe compute:\n(sxosy) = ((sxoy) + sx)\n[by (4611\n= (((X~Y)\n+ Y) + sx)\n[by IHI\n=((x.y) + (y + sx))\n[by Proposition 51\n= ((X~Y)\n+ S(Y + x))\n[by (4411\n=((x.y) + s(x + y))\n[by Proposition 41\n\nPeano Arithmetic, p. 5\n= ((x*~)\n+ (x + SY)) [by (4411\n= (((xmy) + x) +sy)\n[by Proposition 51\n= ((x*sY) + SY)\n[by (4611-rn\nProposition 8 (Commutative Law of Multiplication). PA t(x*y) = (y*x).\nProof: The base clause, \"(x*O) = (O*x),\" uses (Q5) and Proposition 6. As inductive hypothesis,\nassume:\n(x*Y) = (Y*x).\nWe compute:\n(X*SY)\n= ((x*~)\n+ x)\n[by 4611\n= ((y*x) + x) [by IHI\n= (sy*x)\n[by Proposition 71. rn\nProposition 9 (Distributive law). PA t(b'x)(Vy)(Vz)(x*(y + z)) = ((x*y) + (xmz)).\nProof: We prove this equivalent formula:\n(b'y)(~z)Wx)(x*(y + 4 ) = ((x*y) + (xaz)),\nby using this induction axiom:\n(b'Y)(W [[(Om (Y + 4 ) = ((O*Y)+ (0.~1) A Wx)((x* (Y + 4 ) = ((x*y) + (x*z)) -\n(sx*(y + z)) = ((sx*y) + (sxez)))l - (b'x)(x*(y + z)) = ((x*y) + (x*z))l\nTo get the base clause, we compute:\n(O*(y + z)) = 0\n[by Proposition 61\n= (0 + 0)\n[by (4311\n= ((0.y) + (0.z))\n[by Proposition 6 again].\nIn proving the induction step, we assume the IH:\n\nPeano Arithmetic, p. 6\n(x*(Y + z)) = ((x*Y) + (xaz)).\nNow we calculate:\n(SX*(Y\n+ z)) = ((x*(Y + z)) + (Y + z))\n[by Proposition 71\n= (((x0y) + (xaz)) + (Y + 4 )\n[by IHI\n= ((x*y) + ((x*z) + (y + z)))\n[by Proposition 51\n= ((x*y) + (((xoz) + y) + z))\n[by Proposition 51\n= ((x*y) + ((y + (x*z)) + z))\n[by Proposition 41\n= ((x*y) + (y + ((x*z) + z)))\n[by Proposition 51\n= (((x*y) + y) + ((x*z) + z))\n[by Proposition 51\n= ((sxoy) + (sx*z))\n[by Proposition 71. H\nProposition 10 (Associative law of multiplication). PA t(~x)(b'~)(Vz)((x~~)*z)\n= (x* (y*z)).\nProof: The induction axiom we intend to employ is this:\n(V~)(VY)[[((~*Y)~~)\n= (x0(y*O)) A (Vz)(((x0y).z) = (x*(y0z)) - ((xay)*sz) =\n(x*(yasz)))l - (Vz)((xay)*z) = (xa(y*z))l.\nWe get the base clause thus:\n((x* y ) * ~ )\n= o\n[by (4611\n= (x*O)\n[by (4611\n= (x*(yaO)) [by (4611.\nTo get the induction step, we assume this IH:\n((xay)*z) = (xa(y*z)).\nWe compute:\n\nPeano Arithmetic, p. 7\n((xay)*sz) = (((xay)*z) + (x*~))\n[by (4611\n= ((xa(y*z)) + (x0y))\n[by IHI\n= (x*((yaz) + Y))\n[by Proposition 91\n= (x*(yosz))\n[by (4611-rn\nWe could keep going like this for a very long time.\nThe induction axiom schema we have been using is sometimes called the \"weak\ninduction schema,\" to distinguish it form the following strong induction schema:\n(WX)(WY < X)SY - Sx) - 0'~)s~)-\nIn applying this schema, we assume as inductive hypothesis that every number less than x has\nthe property represented by Sx, then try to show that x has the property. If we succeed, we\nconclude that every number has the property. We don't need to assume the instances of the\nstrong induction schema as additional axioms, because we can derive them using the regular\ninduction schema. Specifically, the induction axiom we use is this:\n[[(VY < 0)SY A (Vx)((Vy < x)Sy - (VY < sx)Sy)l - Wx)(Vy < x)Syl.\nThe inductive hypothesis, \"(Vy < O)Sy,\" is a consequence of (Q9). (Q10) tells us that the\ninduction clause, \"(Vx)((Vy < x)Sy - (Vy < sx)Sy),\" is equivalent to this:\nWX)((VY < X)SY - (VY)((Y < x v Y = x) - SY)),\nwhich, in turn is equivalent to this:\n(Vx)((Vy < x)Sy - ((VY < x)Sy A Sx)),\nwhich is equivalent to\n(Vx)((Vy <x)Sy - Sx).\nThus we have this:\n\nPeano Arithmetic, p. 8\n((VX)((~Y\n< X)SY - Sx) - (VX)(VY < x)SY).\nWe also have this:\n((VX)(VY < X)SY - Wx)Sx),\nwhich we obtain by the following derivation:\n1 - (VX)(VY)(Y < x - SY)\n2- (VY)(Y < sa - SY)\n3. (a < sa - Sa)\n(Ql 0)\n4. (Vx)(Vy)(x < sy - (x < y V x = y))\n(Ql 0)\n5. (Vy)(a < sy - (a < y V a = y))\n(Ql 0)\n6. (a < sa - (a < a V a = a))\n7 . a = a\n(Ql 0)\n8. a < sa\n1, (QlO)\n9. Sa\n1, (QlO)\n10. (VX)SX\n(Ql 0)\n1 1. ((Vx)(Vy < x)sy - (VX)SX)\nPI\nu s , 1\nu s , 2\nu s , 4\nu s , 5\nRI\nTC, 6,7\nTC, 3,8\nUG, 9\nCP, 1, 10\nCombining results, we obtain:\n((Vx)((Vy < x)Sy - Sx) - (Vx)Sx).\nWhat we'd like to do now is reverse the process, showing how we could, if we had\nchosen, have taken the strong induction schema as axiomatic, and derived the weak induction\nschema. However, our attempt to do so runs into a glitch. We used weak induction to derive\nProposition 1, the statement that every number is either 0 or a successor. If we replace weak by\nstrong induction, we can't derive Proposition 1. Indeed, it's possible to put together a model of Q\n\nPeano Arithmetic, p. 9\n+ the strong induction schema in which Proposition 1 is false (though we won't do so here).\nWhat we can show, however, is that Q + Proposition 1 + the strong induction schema entails the\nweak induction schema. Thus, what we want to show is this:\n((RO A Wx)(Rx - Rsx)) - Wx)Rx).\nStrong induction gives us this:\n(Wx)(Wy < ~ ) R Y - Rx) - (Vx)Rx).\nSo what we need to show is this:\n((RO A Wx)(Rx - Rsx)) - Wx)(Wy < ~ ) R Y -\nAssume\nRO\nand\n(Vx)(Rx - Rsx)\nTake any y. What we want to show is this:\n(WY < ~ ) R Y - Rx).\nIf x = 0, this follows immediately from our assumption that RO. So we may assume (using\nProposition 1) that x is a successor; say x = sz. So what we have to show is this:\n((Vy < sz)Ry - RSZ.\nWe assumed (Vx)(Rx - Rsx), which gives us this:\n(Rz - Rsz).\nSo what we need is this:\n((Vy < sz)Ry - Rz).\nIn other words,\n\nPeano Arithmetic, p. 10\n(TI\nWe have\n((Vy)(y < sz - Ry) - (z < sz - Rz)).\nSince \"z < sz\" is a consequence of (Q1 I), (T) follows immediately.\nPlug in \"- Qx\" in place of \"Sx\" in the strong induction schema, and you get a schema\nlogically equivalent to the following:\n((3x)Qx - (3x)(Qx A (VY < - QY)).\nThis schema is a formalized version of the well-orderingprinciple: Every nonempty collection\nof natural numbers has a least element.\nThe induction axiom schema is a formalized version of the\nPrinciple of Mathematical Induction. Any collection that contains 0 and\ncontains the successor of any natural number it contains contains every\nnatural number.\nThis principle is central to out reasoning about the natural numbers. A reason for this\ncentrality is singled out in the following:\nTheorem (Richard Dedekind). Any two models of Q that both satisfl the\nprinciple of mathematical induction are is om or phi^.^\nAn isomorphism fiom a model U to a model 23 of the language of arithmetic is a bijection\nf fiom IUI to 1231 that satisfies the following conditions:\nf(03) = oB.\nf(ser(x)) = sB(f(x)).\nf(x\ny) = f(x) +% f(y).\n\nPeano Arithmetic, p. 1 1\nProof: Let f be the smallest subcollection of IUI x 1231 that meets these conditions:\n(Dl)\n<OU,OB> is in the collection.\n(D2)\nIf <x,y> is in the collection, so is <sU(x), s'(~)>.\nThat is, f is the intersection of all subcollections of IUI x 1231 that satisfl (Dl) and (D2).\nf is a function from 131 to 1231. To see this, note, first, that f pairs 0' with one and only one\nU\nB\nelement of 1231: <O , 0 > E f by (Dl). If y + oB, f - {<o',~>) satisfies (Dl) and (D2), which\nimplies, since f is smallest, that f - {<o',~>) = f and <o',~> C f.\nNext, assume that f pairs x with one and only one element y of 1931. Because f satisfies\n(D2), the pair <sU(x),\nis in f. Suppose that z + s ~ ( ~ ) .\nLet g = f - {<sU(x),*). Because U\nsatisfies (Ql), sU(x) + o', and so g satisfies (Dl). To see that g also satisfies (D2), take <a,b> E\ng. If sU(a) + sU(x), <sU(a), sB(b)> will be in g because it's in f. If sU(a) = sU(x), then, because U\nsatisfies (Q2), a = x. Because f pairs x with only one element of 131, b must be equal to y, and so\nsB(b) + Z; hence, again, <sU(a), sB(b)> is in g. Thus g satisfies (Dl) and (D2). Because f is the\nsmallest class that satisfies (Dl) and (D2), g must be equal to f, which means that <sU(x), z> isn't\nin f. Consequently, f pairs sU(x) with s ~ ( ~ ) ,\nand with nothing else.\nf(x 0% y) = f(x) 0% f(y).\nf(x E' y) = f(x) E~ f(y).\nx 3\ny iff f(x) <' f(y).\nIf o is a variable assignment for U, then, for any formula 4 , o satisfies 4 in U iff foo\nsatisfies 4 in 23. (foo is defined by setting foo(v) equal to f(o(v)).) It follows that the\nsame sentences are true in U and in 23.\n\nPeano Arithmetic, p. 12\nLet C be the set of elements of IUI that are paired by f with exactly one element of 131. We\nsee that 0% is in C and that, whenever x is in C, sU(x) is in C. Because U satisfies the principle of\nmathematical induction, C must be equal to IUI, which means that f is a function fiom IUI to 1231.\nA similar argument, this time using the fact that 23 satisfies the principle of mathematical\ninduction, shows that f is a bijection.\nTo complete the proof that f is an isomorphism, we have to show several things. We have\nto show that f(oU) = oB; this follows immediately fiom the way f was defined. For each of the\nfunction signs of the language, we have to show that f respects the operation of the function sign;\nfor example, we have to show that f(x +' y) = f(x) +' f(y). Finally, we have to show that f\npreserves the \"<\" relation, that is, that x 3\ny iff f(x) <' f(y). Of these, we'll only write out the\nproofs for \"s\" and \"+\" here.\n(Dl) tells us that, if <x,y> E f, <sU(x), s ~ ( ~ ) >\nE f. Consequently, for x E IUI, since\n<s,f(x)> E f, <sU(x), sB(f(x))> E f, that is, f(s3(x)) = sB(f(x)).\nTo get the clause for \"+,\" pick x E 1'311. Let E = {y E IUI: f(x +' y) = f(x) +' f(y)). We\nwant to show that 0' is in E, and also to show that, if y is in E, so is s'(~). Because U satisfies the\nprinciple of mathematical induction, this will suffice to show that every member of IUI is in E.\nBecause U satisfies (Q3), x +' 0' = X. Because 23 satisfies (Q3), f(x) +' 0% = f(x).\nConsequently, f(x +' 0%) = f(x) = f(x) +% oB = f(x) +B f(oQL),\nand 0' is in E.\nSuppose that y is in E. We compute\nf(x +U syY)) = f(sU(x y))\n[because U satisfies (Q4)]\n= sB(f(x\ny))\n[because f respects \"s\"]\n= sB(f(x) +% f(y))\n[because y E El\n\nPeano Arithmetic, p. 13\n= f(x) + S (f(~))\n[because U satisfies (Q4)]\n= f(x) +23 f(syY))\n[because f respects \"s\"].\nTherefore, s'(~) is in E.H\nNow we have a puzzle. Dedekind's theorem tells us that any model of Q that satisfies the\nprinciple of mathematical induction is isomorphic to the standard model. In particular, since true\narithmetic includes Q and it also includes all the instances of the induction axiom schema, all\nmodels of true arithmetic ought to be isomorphic to the standard model. But they aren't. The\nCompactness Theorem tells us that there are nonstandard models of true arithmetic, that is,\nmodels of true arithmetic that aren't isomorphic to the standard model.\nThe solution to this puzzle is to realize that the induction axiom schema doesn't hlly\nsucceed in expressing the content of the principle of mathematical induction. What the induction\naxiom schema tells us is that the principle of mathematical induction is satisfied by every\ncollection that is named by some predicate of the lang~age.~\nThere's no way the schema could\ntell us about collections that aren't named by predicates of the language. The collections that\nappear in the proof of Dedekind's theorem - the domain of the function f, and so on - aren't\nnamed by predicates of the language.\nTo put the matter a little more precisely, let U be a model of the language of arithmetic.\nExtend the language of arithemetic by adding a new constant to serve as a standard name\nof each element of the universe of U. If U satisfies all the induction axioms, we are\nassured that the priniciple of mathematical induction holds for every subcollection of IUI t\nhat is the extension of some predicate of the extended language. The slogan is that the\npriniciple holds for collections that are named by some \"predicate with parameters\" in U.\n\nPeano Arithmetic, p. 14\nTo realize the full strength of the principle of mathematical induction, we have to go\nbeyond the familiar language of arithmetic to the language of second-order arithmetic. In\naddition to the familiar symbols of the language of arithmetic, this new language includes the\nsecond-order variables, \"X,,\" \"X,,\" \"X,,\" \"X,,\" and so on.4 The definition of \"formula\" is\nchanged in two ways: For any term T, KT is an atomic formula. Also, if 4 is a formula, so are\n(3XJ4 and @'&)a.\nThe distinction of \"free\" and \"bound\" occurrences of second-order\nvariables, and the distinction between sentences and other formulas, works exactly the way it did\nfor the first-order language.\nThe definition of \"model\" is unchanged, but there are small changes in the semantics. A\nvariable assignment for a model U assigns an element of IUI to each ordinary variable (or each\nindividual variable, as they're called in this context), and it assigns a subset of IUI to each\nsecond-order variable. a satisfies &T iff the individual T denotes with respect to a is an element\nof o(X,,,).\nAn &-variant of a variable assignment a agrees with a except perhaps in what it\nassigns to K. a satisfies (3X,,,)4\nin U iff some &-variant of a satisfies 4 in U. a satisfies\n(VX,,,)$ in U iff every &-variant of a satisfies 4 in U.\nWe are allowing second-order variables to take the place of unary predicates. We could\nalso, if we wanted, allow second-order variables that take the place of predicates of more\nthan one arguments. As far as what what we're doing here goes, this wouldn't make any\ndifferencebecause we can use the hction Pair to translate things we want to say about\nbinary relations on the natural numbers into statements about properties of natural\nnumbers.\n\nPeano Arithmetic, p. 15\nSecond-order PA consists of axioms (Q 1) through (Q 1 I), together with the following\nsecond-order induction axiom:\n(vxo)((xoo A WY)(XOY - Xosy)) - (~Y)XOY).\nThus we can write down second-order PA as a single sentence of the second-order language of\narithmetic.\nBecause the second-order variables range over all subcollections of the universe of\ndiscourse, not just those subcollections that happen to be named by some formula or other, the\nsecond-order induction axiom expresses the full strength of the principle of mathematical\ninduction. Dedekind's theorem amounts to the following:\nCorollary. Second-order PA is categorical; that is, any two models of the\ntheory are isomorphic."
    }
  ]
}