{
  "course_name": "Sensation And Perception",
  "course_description": "This course provides an introduction to important philosophical questions about the mind, specifically those that are intimately connected with contemporary psychology and neuroscience. Are our concepts innate, or are they acquired by experience? (And what does it even mean to call a concept ‘innate’?) Are ‘mental images’ pictures in the head? Is color in the mind or in the world? Is the mind nothing more than the brain? Can there be a science of consciousness? The course will include guest lectures by Professors.",
  "topics": [
    "Health and Medicine",
    "Sensory-Neural Systems",
    "Science",
    "Biology",
    "Neuroscience",
    "Cognitive Science",
    "Social Science",
    "Psychology",
    "Health and Medicine",
    "Sensory-Neural Systems",
    "Science",
    "Biology",
    "Neuroscience",
    "Cognitive Science",
    "Social Science",
    "Psychology"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nCourse Description\n\nThis course provides an introduction to important philosophical questions about the mind, specifically those that are intimately connected with contemporary psychology and neuroscience. Are our concepts innate, or are they acquired by experience? (And what does it even mean to call a concept 'innate'?) Are 'mental images' pictures in the head? Is color in the mind or in the world? Is the mind nothing more than the brain? Can there be a science of consciousness? The course will include guest lectures by Professors.\n\nPrerequisites\n\nNone. Introductory material on the relevant parts of psychology and neuroscience will be given as we proceed.\n\nGuest Lectures\n\nAs part of our effort to convey the truly interdisciplinary nature of many philosophical issues abut the mind, we have invited six distinguished philosophers and cognitive scientists, whose work overlaps both fields, to give guest lectures to the class. The topics of these guest lectures have been arranged to dovetail with the lectures by us.\n\nCourse Readings\n\nReading, discussing, and writing about the assigned readings are the central activities of this class. (No outside research will be necessary.) There is a reading assignment for each lecture. Some are (a) very difficult, or (b) very long, or (c) both. All demand careful study. You should complete the assigned readings\nbefore\neach lecture as the lecture will often presuppose familiarity with the material in the texts.\n\nCourse Grading, Assignments, Exams\n\n20% Recitation Grade\n\nRecitation evaluation will be based on attendance, preparation, contributions to discussion, and any written or oral assignments, including: 2 argument analysis exercises (2-3 pages). (The two exercises together must total at least\nfive\npages.)\n\n60% 3 5-page Papers\n\nPaper topics will be distributed in advance and will ask students to analyze and discuss material covered in class. Guidelines for papers will be handed out in class. (The three papers together must total at least\nfifteen\npages.)\nEither the first or second paper must be rewritten and resubmitted\n(this is\nrequired\nof all students to fulfill the CI requirement). You are\nstrongly advised\nto rewrite your first paper. Your grade for the revised paper will be the average of the grades for the two versions. (Note that revised papers are held to a higher standard.)\n\n20% Final Exam\n\nYou will be required to take a 3-hour final exam on material covered throughout the term. The final exam will be at least 2/3 essay format, and essay questions will be distributed in the final lecture of the term. The exam will be closed-notes and closed-books. (There is no midterm exam.) The instructors reserve the right to fail any student in the course who fails to perform at a passing level in any of the grading areas listed above; so, for example, attendance at recitation is required and consistent failure to attend will result in an F for the course.\n\nACTIVITIES\n\nPERCENTAGES\n\nProblem sets\n\n20%\n\nMid term I\n\n25%\n\nMid term II\n\n25%\n\nFinal exam\n\n30%\n\nCriteria for HASS CI Subjects\n\nCommunication intensive subjects in the humanities, arts, and social sciences should\nrequire at least 20 pages of writing\ndivided among 3-5 assignments. Of these 3-5 assignments, at least one should be revised and resubmitted. HASS CI subjects should further offer students substantial opportunity for oral expression, through presentations, student-led discussion, or class participation. As this is a CI subject, the\noral component\nis essential. Active participation in both lectures and (especially) recitations is required. Students will be asked to give oral presentations on the reading in recitation.\n\nMIT Statement on Plagiarism\n\nPlagiarism--use of another's intellectual work without acknowledgement--is a serious offense. It is the policy of the Literature Faculty that students who plagiarize will receive an F in the subject, and that the instructor will forward the case to the Committee on Discipline. Full acknowledgement for all information obtained from sources outside the classroom must be clearly stated in all written work submitted. All ideas, arguments, and direct phrasings taken from someone else's work must be identified and properly footnoted. Quotations from other sources must be clearly marked as distinct from the student's own work. For further guidance on the proper forms of attribution, consult the style guides available at the\nWriting and Communication Center\nand the\nMIT Web site on Plagiarism\n.\n\nHow to Cite a Source\n\nIf your paper discusses a single essay assigned for the course, and if you make clear what essay that is in the body of the text, then you may cite the essay by putting the page number (section number if the essay is in html) of the quotation in parentheses next to the stretch of text. For example: In his essay, \"What is a Neural Correlate of Consciousness?\", David Chalmers offers an account of when a state of a system is a neural correlate of a certain phenomenal property. According to Chalmers, \"A state N1 of system N is a neural correlate of phenomenal property P if N's being in N1 directly correlates with the subject having P.\" (9) If you use a source not assigned for the course, include the full reference for the source in a bibliography and at the point in the text where you need to cite the source, put the author's last name, date of publication, and page number, for example (Chomsky 1978, 75).\n\nCalendar\n\nSES #\n\nTOPICS\n\nKEY DATES\n\nIntro to perception\n\nBasic psychophysics\n\nEye, retina\n\nEye, retina (cont.)\n\nProblem set 1 due 4 days after Ses #4\n\nSpatial vision\n\nSpatial vision (cont.)\n\nMid-level vision\n\nMid-level vision (cont.)\n\nObject recognition\n\nProblem set 2 due\n\nFace recognition\n\nMid term I\n\nColor and lightness\n\nProblem set 3 due\n\nDepth\n\nBinocular vision\n\nMotion\n\nMotion (cont.)\n\nScenes\n\nThe ear\n\nMid term II\n\nProblem set 4 due 5 days after Ses #19\n\nAudition\n\nAudition (cont.)\n\nProblem set 5 due\n\nMusic and speech\n\nProblem set 6 (part 1) due 5 days after Ses #22\n\nTouch\n\nHaptics\n\nProblem set 6 (full) due 1 day after Ses #24\n\nSmell\n\nTaste, last day of classes",
  "files": [
    {
      "category": "Assignment",
      "title": "Problem Set #1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/5fc2ac4815273d593cae64a3aaa4ac5d_MIT9_35s09_pset01.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n9.35 Spring 2009\nProblem Set #1: 100 Points\nPlease turn in all results and source code in a single document (hint: try the 'publish'\nfunctions in Matlab), preferably a PDF or hard copy. Please document your source code\nappropriately. Submissions may be made online, to the TA's. Be sure to label all figures\nappropriately. Collaboration is encouraged, but each student must turn in a unique report.\n1. Light from a bright star falls on the receptive field of an ON midget retinal\nganglion cell.\n1.a) Describe, in two or three sentences, the steps and circuitry involved in transducing\nthe light from the star into an electrical potential on the RGC. (15 Points)\n1.b) Sometimes the light will hit only the center of the receptive field, sometimes it will\nhit only the surround, and sometimes it will hit both. For each case, compared to when\nno star is in the receptive field, is the RGC more or less likely to create an action\npotential? Why? (15 Points)\n2. As an ON midget retinal ganglion cell, you do not see the star itself, but only 'see'\ninput from upstream neurons. Each processing step between the physical light and\nthe final input introduces noise. Thus, your center and surround inputs are noisy.\nLet's say that this noise is Gaussian.\n2.a) We can simulate the center and surround inputs to this RGC by drawing two vectors\nof 1000 samples each from a normal distribution, using the syntax randn(1000, 1). By\ndefault this returns Gaussian noise with mean 0 and variance 1. Name these vectors Ci_n\nand Si_n. These are random samples from the center and surround inputs in the absence\nof any signal (that is, just noise). Let each sample represent the total input to the RGC on\na single trial, so that Ci_n(i) and Si_n(i) can be used as inputs from the same trial.\nNow, create two more vectors representing the center and surround inputs if the starlight\nwere to fall exclusively in that subregion of the receptive field. Assume that the signal\nincreases the input by a mean of 4 from baseline - so, simply add 4 to two new vectors\ndrawn from randn. Call these vectors Ci_s and Si_s.\nPlot and label the distribution of input magnitudes from all four vectors over the range [\n10, 10] in the same figure (use syntax like distr_Ci_s = hist(Ci_s, linspace(-10, 10)), and\nfunctions like plot, hold, and xlim). (5 Points)\n2.b) An RGC soma does not know whether input is coming from the center or the\nsurround, but only its final membrane potential. What simple, arithmetic rule does an\nON midget RGC use to combine center and surround input? Use this rule to combine\n\nyour input vectors above into four new vectors, representing the final RGC membrane\npotential response under each input condition:\n1) V_n in the absence of any signal (using Ci_n and Si_n)\n2) V_c for signal in the center, but noise in surround (Ci_s and Si_n)\n3) V_s for signal in the surround, but noise in the center (Si_s and Ci_n), and\n4) V_b for signal in both the center and surround (Ci_s and Si_s).\nEach of these vectors should still be 1000 random samples representing the response for\n1000 different trials.\nCreate a second figure plotting the histograms of each of these vectors. Provide a legend\nto indicate which 'bump' corresponds to which condition. (15 Points)\n2.c) This RGC will fire an action potential whenever its membrane potential exceeds\nsome threshold. An action potential counts as a 'hit' when it is caused by a signal in the\ncenter and not in the surround. An action potential in any other condition is a 'false\nalarm.'\nConsidering the four vectors in 2.b, if the threshold for this RGC were 3, how many hits\n(of the possible 1000) would this cell get? How many 'false alarms' (of the possible\n3000)? (Hint: try using logical operators like '>', and 'sum') (5 Points)\n2.d) Define a vector of 100 different threshold levels in the range [-5, 5] (e.g., thr =\nlinspace(-5, 5)). Use a 'for' loop to repeat the computation in 2.c for each threshold\nvalue in your vector. In other words, for each threshold value, count the number of hits\nand false alarms your cell would make given the four 'membrane potential' vectors you\ncreated above.\nPlot the number of hits (y axis) as a function of the number of false alarms (x axis). Each\ndata point will correspond to a particular threshold value. This is an ROC curve. (20\nPoints)\n2.e) If the input to this cell was much more noisy, what would the curve look like? If the\ninput to this cell was not noisy at all, what would the ROC curve look like? Sensitivity is\nlimited by noise. With this in mind, in general, what is the relationship between the ROC\ncurve and the sensitivity of the cell? (10 Points)\n2.f) Let's pretend that your grade on this assignment depends on how well this RGC can\ndetect starlight. You get 1 point for every 10 hits the cell makes and lose one point for\nevery 30 false alarms. Write a simple equation that describes your grade as a function of\nthe cell's threshold using the hits and false alarms counted in 2.d. Plot this 'reward'\nfunction, and find the threshold that gives you the best grade. Where is this point on the\nROC curve? Where is it on the histogram in 2.b? What grade do you deserve? (15\nPoints)"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 1: Solutions Guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/f7ed78f1d4e6e1636afbe6c60cb4e726_MIT9_35s09_sol_pset01.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n!\n\n! \"#$% # & &\n!'#\n\n(\n\n\"#$%\n) * !+\n\n( *\n\n*\n\n** &\n& * *\n#\n\n&**, **\n+ - * .\n-\n\n(& ,\n\n** *\n*\n\n-* / .\n\n&\n\n#\n& 0\n\n&\n\n&\n\n2343225 26789 !$\n\n!\n\n!\n\"#\n$%&'(&)* +)),+'-\n.*\n.*\n.*\n.\"*\n/$0\n*\n$$$$\n0 1 '$2\n7\"\n8\" 5.\n$0\n$.$.$.$.\"\n0 . . . .\"\n34\".0)\n7\"\n8\" ).\n2343225 26789 !$\n\n!\n7 & : &\n* *&\n; 0 *& 8\n*\n* < *\n\n* =>.\n=> => > * ** 0\n\n8 * ? & <\n\n9/:$$;$$977\n$<\n$9/.$\n=9/\">...\"?\n=99/=9/\"$\n$\n@A\n=9\n<<\n6 1\n2343225 26789 !$\n\n!\n(& &\n\n( & * $\n.;$ (&\n* & 0 &*\n\n& <\n),\n$*AA\n%0$$\n$9/.$\n=99/=9/\"$\n\n=9$\n8\" =9\n7\" 6\n34 ),0$\n\n* /-@ **\n\n2 * *\n**\n* 3 * (0 @ * ? /-@\n8 1\n2343225 26789 !$\n\n!\n** *\n@*\n& & 0 &\n*\n/-@\n\n*\n*3\n- & &*&\n& , /-@ 7\n&\n* & *\n# & *\n\n* - 0 &\n* /-@ *&\n* \" &\n&\n& *\n* /-@ *&\n\n& /-@\n\n# ) & =>\n=> & *\n.* .& &\n* * &\n\" &\n( *\n=> =>\n\n( & &\n& *\n&\n& <\n)\n\n0 $B*=9B<\n>C8D C8D 5 ?80\nC8D\nC8D ($$$C8D 5\n$0\n8\" ($$\n7\" D\n34)\n=D\n$\nC8D ($$C8D\n$\n0$\n$\nC8D ($$A #*\n$\nE($$ 60\nA 1\n2343225 26789 !$\n\n!\n$\n=9C8D 5 $C8D 5\n$\n0 ), E($$ 1 $&\nE($$ ),\nC8D\nF@4@GG@\nC8D ($$\n4GGG@\n9 1\n2343225 26789 !$\n\n!\n+\n!*\n\n4 1\n2343225 26789 !$\n\n!\n*&\n&\n* & &\n(<\n\n1 1\n2343225 26789 !$"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/437dd07a9704edc1720be308ef042dfb_MIT9_35s09_pset02.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n9.35 Spring 2009\nProblem Set 2 - 100 Points\nNB: This problem set assumes you have the Image Processing toolbox installed in\nMatlab. This is the case if you work on Athena or have downloaded the full version to\nyour personal computer. If you can't get access to the Image Processing toolbox, or you\nare working in another environment (like Python) then other solutions are possible -\nplease ask for help if needed.\nPlease turn in all code, figures and results in a single PDF or Word document and post to\nStellar. You may also turn in a paper copy or email your PDF to the TA's if you cannot\nget Stellar submission to work.\nTip: try to write as much code as possible with vector and matrix commands, instead of\nfor loops. This will greatly easy your life! Also beware the difference between matrix\noperations and element-wise operations, ie A*B vs A.*B. Ask for help if needed.\nFor clarity, Matlab syntax is provided in monospace, programmatic instructions are\nitalics, and conceptual questions are in bold.\nPage 1 of 6\n\n1. Linear receptive fields (20 points)\nLet's assume that we can model the receptive field of a neuron as a linear filter. In other\nwords, the response of the neuron is a weighted linear summation of light in its receptive\nfield.\n1.a) (10 points) Let's create a model of a receptive field as a 2D Gaussian (like an ON-\ncenter cell, but without surround inhibition). Use the syntax [X Y] = meshgrid(\n20:20) to map a piece of a 'retina' in X and Y coordinates.\nA Gaussian filter can be defined as:\n{\n- x- x0 2- y- y0 2\n}\nF x, y ∝exp\n2σ2\nWhere (x0, y0) is the center of the receptive field, and σ is standard deviation in both x and\ny (approximately 1/3 the width of the RF).\nUse this expression, and the matrices X and Y, to create a 2D Gaussian with a standard\ndeviation of 4. Normalize the filter so that it integrates to 1. Call this G1, and use\nimagesc and colormap('gray') to display this receptive field. If this is the\nstructure of a linear receptive field, what does the intensity of any particular pixel\nmean? What is a reasonable assumption about the wiring of the retina that would\nmake the linear weights of pixels in the receptive field decrease with distance from\nthe center?\n1.b) (5 points) Create another 2D Gaussian receptive field (G2) with a smaller standard\ndeviation (2), normalize, and display it. If G1 and G2 were the receptive fields of two\nganglion cells, which one would have greater sensitivity to light? Why?\n1.c) (5 points) Subtract G1 from G2 to make another filter, DoG (Difference of\nGaussians), and display this image. Now, plot the (1D) cross section through the\nmiddle of this receptive field.\nPage 2 of 6\n\n2. Predicting ganglion cell responses to natural images (50 points)\nWe will be modeling the output of cells as a continuous value, but keep in mind that this\nrepresents the firing rate.\n2.a) (5 points) Given that we assume our receptive fields are linear, we can predict the\noutput of each cell as the weighted sum of image intensities. That is:\nO=∑ F x , y I x , y\nx, y\nWhere O is the output, x, y are the coordinates of each pixel of the receptive field, F is the\nthe receptive field filter, and Ix, y is the intensity of the input to pixel x, y.\nWhat would be the output of a ganglion cell with the receptive field created in 1.a if a\nspot of light of intensity 1 fell on the center (0,0) pixel? What if a second spot of intensity\n1 fell on (2,3)? What if the whole field were covered with intensity 1 spots?\n2.b) (5 points)Use im = imread('peppers.png') to load a still life picture from\nthe Image Processing toolbox (if you do not have this toolbox, use an image of your\nchoice). Note that some images load as 8-bit integers, and if this is the case, you should\nconvert it using the syntax im = double(im)/255;. For simplicity, we will only\nuse black and white images, so extract the green channel using im = im(:, :, 2);.\nDisplay the image.\nIf a ganglion cell with a DoG receptive field (from 1.c) were centered on pixel 125,125\n(such that the receptive field spanned pixels 105 to 145 in each dimension), what would\nthat ganglion cell's output be?\n2.c) (15 points) We can model the response of a population of cells using a mathematical\nconcept called convolution. In plain English, how does convolution model a\npopulation of cells? Describe how you would implement this algorithm in Matlab.\nDue to complications at the edge of images, it is actually somewhat tricky for beginning\nprogrammers to implement a convolution algorithm. You should use filter2 instead\nof writing your own function (unless you are particularly ambitious!).\n2.d) (10 points) Model the response of a population of ganglion cells to the peppers\nimage with your DoG filter. Display the output using imagesc and\ncolormap('gray').\nWhat is a plausible (based on what you know about the cells in the retina)\ninterpretation of negative values in this output? What features of the image provide\ngreatest stimulation to cells with a DoG receptive field, and why? How would you\nchange the properties of this receptive field to make the cell more sensitive to fine-\ngrained features, such as the wrinkles in the cloth?\nPage 3 of 6\n\n2.e) (10 points) Repeat this convolution with the two other (G1 and G2) filters from\nproblem 1. This would correspond to the output of two populations of retinal ganglion\ncells without inhibitory surrounds. Display these two images in one figure using\nsubplot. What is different between the output of the two filters? Why is it\nimportant that we normalized the integral to 1 (with respect to the DoG, and also by\nitself)? What would happen if we didn't?\n2.f) (5 points) Find a picture of yourself and repeat the three convolutions. You will\nprobably need to resize your picture (or redefine the filters) to produce interesting results.\nPage 4 of 6\n\n3. Predicting V1 simple cell responses to natural images (30 points)\nWe will now move further along the visual stream and model the response properties of\nidealized, linear, oriented receptive fields, like those found in V1. Filters of this type are\ncommonly modeled with Gabors, which are the product of an oriented sine wave and a\nGaussian envelope.\nIn problem 1 we created several Gaussian envelopes, now we need only to create the\nsinusoidal grating. We can define a grating of any given orientation as:\nGx , y =sin {2∗ f ∗ x cosφ y sin φ }\nWhere f is the spatial frequency in cycles per pixel,φ is the angle about the x-axis, and x,\ny are the indices of each pixel.\n3.a) (5 points) Use the grid from 1.a and the equation above to create a sinusoidal\ngrating with 4 cycles total, rotated 0 degrees about x. Display this grating in grayscale.\nTip: write a function, or anonymous function, to return a grating of a given orientation.\n3.b) (10 points) If this grating were reproduced in print, at 300 pixels per inch, what\nwould be the spatial frequency of the image (in cycles per degree of visual angle,\ncpd) if you stood 3 feet away? How far away would you have to stand to make this\nvalue around 10 cpd (roughly the peak of your contrast sensitivity function)? If you\nwere standing 4 feet away, what would the wavelength have to be (in pixels), to\nmake the grating 10 cpd?\n3.c) (10 points) Multiply this grating by a Gaussian envelope (i.e., G1), renormalize, and\ndisplay. This Gabor function can serve as a simple edge detector, and is a good\napproximation of receptive fields of certain cells in V1. Create another three V1 filters,\noriented at 45, 90 and 135 degrees. Convolve both images (you and peppers) with all\nfour receptive fields and display the results.\n3.d) (5 points) What aspects of real RGC or V1 cells do our toy linear filter models\nnot explain?\nPage 5 of 6\n\n4. Feedback\nWe are perpetually refining the Matlab component of this course. Please let us know\nhow many hours you spend on this problem set, if anything was particularly difficult, or\nif you have any general comments for this assignment or others in the future.\nPage 6 of 6"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2: Answer key",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/49d4a8e271a66bf7cb828b49faf3e28f_MIT9_35s09_sol_pset03.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem set 2\nAnswer key\nContents\nInit\nProblem 1\nProblem 2\nInit\nclear all\nclose all\nclc\nProblem 1\n1a natural images have a characteristic 1/f^n power spectrum (where n is somewhere between 1 and 2.5). Meaning that the amplitude of frequencies is\ninversely proportional to the frequency. This makes sense, since the amplitude of a frequency, roughly, indicates how much the image is changing at that\nfrequency. Natural images have spatial correlations: nearby pixels are more likely to be the same than pixels farther away. This means that hte image will be\nchanging less at high spatial frequencies, and will thus have less power at higher frequencies. Thus, we will have a ~1/f power spectrum. Since peppers\nand you are natural images, it was safe to assume that you too would have such a power spectrum.\nim = imread('peppers.png');\nim = double(im(:,:,2))./255;\nadelson=double(imread('adelson.tiff'))/255;\nadelsonFT = fftshift(fft2(adelson));\npeppersFT = fftshift(fft2(im));\nfigure();\nsubplot(2,2,1);\nimagesc(log(abs(adelsonFT))); colormap gray, axis image, axis off\ntitle('log abs(fft2(adelson.tiff))')\nsubplot(2,2,2);\nsemilogy((-124:124)/128, abs(adelsonFT(125,:)));\ntitle('Adelson - Magnitude Profile')\nxlabel('f_x Cycles Per Pixel')\nylabel('abs(fft2)')\nsubplot(2,2,3);\nimagesc(log(abs(peppersFT))); colormap gray, axis image, axis off\ntitle('log abs(fft2(peppers.png))')\nsubplot(2,2,4);\nsemilogy((-191.5:191.5)/383, abs(peppersFT(:, 255)));\nxlabel('f_x Cycles Per Pixel')\nylabel('abs(fft2)')\ntitle('Peppers - Magnitude Profile')\n\n1b whitened images have equal power across the full spectrum, so there is more power at high spatial frequencies than we are used to with a 1/f\nspectrum.\nrandPeppers = fft2(randn(size(im)));\nrandAdelson = fft2(randn(size(adelson)));\ni = sqrt(-1);\nadelsonFT = ifftshift(adelsonFT);\npeppersFT = ifftshift(peppersFT);\nscrambledAdelson = real(ifft2(abs(adelsonFT).*exp(i*angle(randAdelson))));\nscrambledPeppers = real(ifft2(abs(peppersFT).*exp(i*angle(randPeppers))));\nwhiteAdelson = real(ifft2(abs(randAdelson).*exp(i*angle(adelsonFT))));\nwhitePeppers = real(ifft2(abs(randPeppers).*exp(i*angle(peppersFT))));\nfigure();\nsubplot(2, 2, 1);\nimagesc(whiteAdelson); colormap gray, axis image, axis off;\ntitle('Whitened Adelson');\nsubplot(2, 2, 2);\nimagesc(scrambledAdelson); colormap gray, axis image, axis off;\ntitle('Scrambled Adelson');\nsubplot(2, 2, 3);\nimagesc(whitePeppers); colormap gray, axis image, axis off;\ntitle('Whitened Peppers');\nsubplot(2, 2, 4);\nimagesc(scrambledPeppers); colormap gray, axis image, axis off;\ntitle('Scrambled Peppers');\n\n1c phase determines the spatial structure of the image, and we care about spatial structure more than the power spectrum. Hence, phase determines what\nwe see in these hybrids.\npeppersResized = im((1:249)+100, (1:249)+200);\npeppersFT = fft2(peppersResized);\nfigure();\nsubplot(1,2,1);\nmodIMG = real(ifft2(abs(adelsonFT).*exp(i*angle(peppersFT))));\nimagesc(modIMG); colormap gray, axis image, axis off;\ntitle('pepper phase, adelson Amp');\nsubplot(1,2,2);\nmodIMG = real(ifft2(abs(peppersFT).*exp(i*angle(adelsonFT))));\nimagesc(modIMG); colormap gray, axis image, axis off\ntitle('adelson phase, pepper Amp');\n\n1d Convolving an image with a Gaussian filter blurs the image, because it is a weighted average of intensity over a local area. In other words, we lose\nhigh-frequency information. If multiplying the Fourier transforms is the same as convolution, then multiplying with a Gaussian FT should reduce the\namplitude of high frequencies. So, a Gaussian FT looks like a radial mask (actually, it is mathematically identical to another Gaussian!). Now, multiplying\nthe Gaussian FT by the FT of an image causes the high-frequencies to dissapear, but preserves the lower frequencies.\nFor more complex filters, we can understand the FT by looking at the components. A DoG filter selects out certain frequencies but responds poorly to\nambient (low frequencies) or very high frequencies. Thus, it is a 'band-pass' filter, and the FT will look like a ring. Sine waves are single points in an FT\n(because sines are the basis function), and multiplying them by a Gaussian will simply introduce some frequency spill-off around those points. Different\norientations of sine waves of the same frequency will simply have different components in f_x and f_y, so the points will be rotated about the origin.\nIt is important to note the inverse relationship between image distance and frequency. For instance, the wider Gaussian has a sharper FT, because it has\nlower frequencies, while a narrower (low STD) Gaussian has more high-frequencies and will have a broader FT. Correspondingly, high-frequency sine waves\nwill be points further from the origin.\n[X Y] = meshgrid(-20:20);\n% Anonymous functions are a shortcut for repeated calculations like this\nGaussian = @(s) exp(-.5*(X.^2+Y.^2)/(s^2));\nG1 = Gaussian(4);\nG2 = Gaussian(2);\n% Normalize (integrate to 1)\nG1n = G1 ./ sum(G1(:));\nG2n = G2 ./ sum(G2(:));\n% make diff. of. gauss\nDoG = G2n-G1n;\n% make gabors\nf = 4/size(X,1);\nphi = (0:3)*pi/4;\nfor i = 1:4\nI{i} = G1.*sin(2*pi*f*(X*cos(phi(i))+Y*sin(phi(i))));\nend\nG1p = padarray(G1, [104 104]);\ng1FT = fftshift(fft2(G1p));\nfigure();\nsubplot(1,2,1);\nimagesc(abs(g1FT)); colormap gray, axis image, axis off\ntitle('abs(Gaussian FFT)');\nsubplot(1,2,2);\nnewFT = ifftshift(g1FT).*adelsonFT;\n\nmodIMG = ifftshift(real(ifft2(newFT))); % For some reason, the phase shifts by pi here, requires ifftshift\nimagesc(modIMG); colormap gray, axis image, axis off\ntitle('Reconstructed FT multiplication')\n% Anonymous function for simplicity\ndispFT = @(im) imagesc(fftshift(abs(fft2(im))));\nfigure\nsubplot(2, 2, 1)\ndispFT(G2); colormap gray, axis image, axis off;\ntitle('G2')\nsubplot(2, 2, 2)\ndispFT(DoG); colormap gray, axis image, axis off;\ntitle('DoG')\nsubplot(2, 2, 3)\ndispFT(I{1}); colormap gray, axis image, axis off;\ntitle('Gabor 1')\nsubplot(2, 2, 4)\ndispFT(I{2}); colormap gray, axis image, axis off;\ntitle('Gabor 2')\n\nProblem 2\nHybrid images look like one image at close distances and the other image at longer distances because of your contrast sensitivity function. There is more\ncontrast \"energy\" (contrast weighted by your sensitivity to it) in the high spatial frequency image when you are close, and more of this energy in the low\nspatial frequency image when you are far. This works because we have a U shaped contrast sensitivity function that drops off for high and low spatial\nfrequencies alike.\n[X Y] = meshgrid([-124:124], [-124:124]);\n[Th, R] = cart2pol(X,Y);\nmask = (R<=16);\nadelsonFT = fft2(adelson);\nwolfe = double(imread('wolfe.tif'))/255;\nwolfeFT = fft2(wolfe);\nfigure();\nsubplot(3,2,1);\nimagesc(log(abs(fftshift(adelsonFT))));\ncolormap gray\ntitle('Adelson power spectrum')\nsubplot(3,2,2);\nimagesc(log(abs(fftshift(wolfeFT))));\ncolormap gray\ntitle('Wolfe power spectrum')\nsubplot(3,2,3);\nimagesc(mask);\ncolormap gray\ntitle('low-pass mask');\nsubplot(3,2,4);\nimagesc((~mask));\ncolormap gray\ntitle('high-pass mask');\nsubplot(3,2,5);\nimagesc(log(abs(fftshift(adelsonFT)).*(~mask)));\ncolormap gray\ntitle('Adelson masked power spectrum')\nsubplot(3,2,6);\nimagesc(log(abs(fftshift(wolfeFT)).*mask));\ncolormap gray\n\ntitle('Wolfe masked power spectrum')\nscaleIm = @(im) (im-min(im(:)))/(max(im(:))-min(im(:)));\nwolfeLowPass = scaleIm(real(ifft2(fftshift(mask).*wolfeFT)));\nadelsonHighPass = scaleIm(real(ifft2(fftshift(~mask).*adelsonFT)));\nhybrid = wolfeLowPass + adelsonHighPass;\nfigure();\nimagesc(hybrid); colormap gray, axis image, axis off\n\nPublished with MATLAB(r) 7.7"
    },
    {
      "category": "Resource",
      "title": "Auditory Scene Analysis",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/3b5d1b394e863c388802f38cbb2742f2_MIT9_35s09_lec01_auditory.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nAuditory Scene Analysis\nKimo Johnson\nApril 23, 2009\nTuesday, April 28, 2009\n\n- Source segregation\n- Spatial separation\n- Spectral and temporal qualities\n- Stream segregation\n- proximity: frequency or time\n- continuity: follow trajectory\n- similarity: frequency, timbre, intensity\n- symmetry and closure\nAuditory scene analysis\nTuesday, April 28, 2009\n\nSingle sound organization\nadapted from Handel figure 7.2\nTuesday, April 28, 2009 Single sound organization - onsets, overtones, intensities.\nFigure by MIT OpenCourseWare.\nSingle sound organi\nzation - onsets, o\nvertones, intensities\n.\n\nOld-plus-new heuristic\nFigures removed due to copyright restrictions.\nTuesday, April 28, 2009\n\nAuditory stream\nFigures removed due to copyright restrictions.\nTuesday, April 28, 2009\n\nStream segregation\n- Proximity\n- Continuity\n- Similarity\n- Symmetry and closure\nTuesday, April 28, 2009\n\nMultiple sounds\nadapted from Handel figure 7.4\nTuesday, April 28, 2009\nMultiple\nsounds - frequency versus time.\nFigure by MIT OpenCourseWare.\n\nMultiple sound organization\n- Tone sequences\n- Vary parameters to cause perception of\nsubsequences\n- Conflicting organizations\n- Ambiguous sequences that put strategies in\nconflict\nTuesday, April 28, 2009\n\nProximity A graphical representation of how sound is affected by proximity.\nTuesday, April 28, 2009 1 figure from Page 11 - Multiple sounds.\nFigure by MIT OpenCourseWare.\n\nResults\nfrom van Noorden, 1975\nTuesday, April 28, 2009\nFr\neq\nu\ne\nn\ncy\nse\npar\nati\non versus tone repet\nition time.\nFigure by MIT OpenCourseWare.\n\nJ.S. Bach\n- Toccata and Fugue in D Minor ~1700\nTuesday, April 28, 2009\n\nJ.S. Bach\n- Toccata and Fugue in D Minor ~1700\nTuesday, April 28, 2009\nB\na\nc\nh, D Minor.\nFigure by MIT OpenCourseWare.\n\nSimilarity\n- Sounds are grouped by timbre\nTuesday, April 28, 2009\n\nSimilarity\n- Sounds are grouped by timbre\nExample\nfrom Music, Cognition, and Computerized Sound, ed. Perry Cook\nTuesday, April 28, 2009\n\nCompeting organizations\nBregman and Pinker, 1978\nTuesday, April 28, 2009\nCompeting\norg\na\nn\nizations - frequency versus time.\nFigure by MIT OpenCourseWare.\n\nScale illusion\n- Deutsch, 1975\nTuesday, April 28, 2009\nScale\nillusi\non.\nFigure by MIT OpenCourseWare.\n\nScale illusion\n- Deutsch, 1975\nDemo\nTuesday, April 28, 2009\nScale\nillusi\non.\nFigure by MIT OpenCourseWare.\n\nScale illusion\n- Deutsch, 1975\nTuesday, April 28, 2009\nScale\nillusi\non.\nScal\ne illu\nsion.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\n\nContinuity\nKluender and Jenison 1992 - glides\nTuesday, April 28, 2009\nConti\nnuit\ny.\nFigure by MIT OpenCourseWare.\n\nContinuity\nadapted from Bregman, 1990\nTuesday, April 28, 2009\n\nContinuity\nadapted from Bregman, 1990\nTuesday, April 28, 2009\n\nRestoration\n- Sasaki (1980) - familiar piano melodies\n- Warren and Sherman (1974)\n- the *eel fell off the car\n- The *eal fell off the table\nTuesday, April 28, 2009\n\nFrequency Graphs\nFigures removed due to copyright restrictions.\nTuesday, April 28, 2009\n\nMelodies\nDiana Deutsch, 1972\nTuesday, April 28, 2009\n\nMelodies\nmelody 1\nDiana Deutsch, 1972\nTuesday, April 28, 2009\n\nMelodies\nmelody 1\nmelody 2\nDiana Deutsch, 1972\nTuesday, April 28, 2009\n\nMusic\nTuesday, April 28, 2009\n\nMusic\nguitar and sax\nTuesday, April 28, 2009\n\nMusic and Speech\nPerception\nKimo Johnson\nApril 29, 2008\nTuesday, April 28, 2009\n\nLinguistic universals\n- Discreteness\n- Semanticity\n- Arbitrariness\n- Openness\n- Duality of patterning\nHockett, 1963\nTuesday, April 28, 2009\n\nMusic grammars\n- Discreteness: N pitches per octave\n- Semanticity: scales, chords, keys\n- Arbitrariness\n- Openness\n- Duality\nTuesday, April 28, 2009\n\nOctave\n- Frequency ratio 2:1\n- Greatest number of identical\novertones\n- First overtone is 2 : 1\nTuesday, April 28, 2009\n\nSensory dissonance\nPlomp and Levelt, 1965\nTuesday, April 28, 2009\nSensory dis\nsonance.\nFigure by MIT OpenCourseWare.\n\nLocal consonance\nSethares, 1993\nTuesday, April 28, 2009\nLocal con\nsonance.\nFigure by MIT OpenCourseWare.\n\nPythagorean comma\nC\nG\nD\nA\nE\nB\nF♯\nC♯\nG♯\nE♭\nB♭\nF\nC′\nf1\n=\n2 f0\nfi\n=\n2 fi-1\nTuesday, April 28, 2009\n\nPythagorean comma\nC\nG\nD\nA\nE\nB\nF♯\nC♯\nG♯\nE♭\nB♭\nF\nC′\nf1\n=\n2 f0\nfi\n=\n2 fi-1\n! 3\n\"12\n≈ 27\n≈ 1.0136\nTuesday, April 28, 2009\n\nPythagorean tuning\nC\nC#\nD\nEb\nE\nF\nF#\nG\nG#\nA\nBb\nB\n1/\n256/\n9/\n32/\n81/\n4/\n729/\n3/\n128/ 27/\n16/ 243/\nC : E = 81/64 = 1.2656\nC : E = 5/4 = 1.25\nC : Eb = 32/27 = 1.1852\nC : Eb = 6/5 = 1.20\nC# : F# = 1.3515 = 1.333\nTuesday, April 28, 2009\n\nPythagorean tuning\nC\nC#\nD\nEb\nE\nF\nF#\nG\nG#\nA\nBb\nB\n1/\n256/\n9/\n32/\n81/\n4/\n729/\n3/\n128/\n27/\n16/\n243/\nC : E = 81/64 = 1.2656\nC : E = 5/4 = 1.25\nC : Eb = 32/27 = 1.1852\nC : Eb = 6/5 = 1.20\nwolf\nC# : F# = 1.3515 = 1.333\nTuesday, April 28, 2009\n\nOther tuning systems\n- Just diatonic\n- Meantone (1400)\n- Well-temperaments\n- Werckmeister (1645-1706)\n- Young (1773-1829)\n- Equal temperament (~1900)\nTuesday, April 28, 2009\n\nOptimal well-temperament\nPolansky et. al, 2008\nTuesday, April 28, 2009 Optimal well-temperament.\nTempering of major triad\nEb\nBb\nF\nC\nG\nD\nA\nE\nB\nF#\nC#\nG#\nMajor triadOptimal well-temperament.\nOWT2\nOWT1\nY2\nW3\nFigure by MIT OpenCourseWare."
    },
    {
      "category": "Resource",
      "title": "Hearing",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/ba046354a9a229c6537a917c07ea03b0_MIT9_35s09_lec02_hearing.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nHearing\nKimo Johnson\nApril 14, 2009\nTuesday, April 28, 2009\n\nPsychoacoustics\n- Ask listeners how sounds are perceived\n- Pressure (dB) => loudness\n- Frequency (Hz) => pitch\n- Critical bandwidths\nTuesday, April 28, 2009\n\nTuesday, April 28, 2009\nC\no\nchlea\nt\nu\nned t\no\n\ndiffe\nr\ne\nnt fr\ne\nq\nuenci\ne\ns\nand\n\nt\nh\ne\nim\npact of the cochlea when\nun\ncoil\ned.\nFigure by MIT OpenCourseWare.\n\nCritical bands\n- Auditory filters\n-40\n-30\n-20\n-10\nFrequency (kHz)\nAmplitude (dB)\nTuesday, April 28, 2009\n\nCritical bands\n- Width of \"auditory filters\"\n- Fletcher (1938)\n- Zwicker (1960,1990)\n- Moore, Glasberg\nfrequency\nnoise\nbw\nprobe\nintensity\nTuesday, April 28, 2009\n\nCritical bands\nTuesday, April 28, 2009\nA\nplo\nt o\nf b\nand\nwidt\nh da\nta\nw\nhe\nn\na\nHz tone is used.\nFigure by MIT OpenCourseWare.\n\nCritical bandwidth\n0.1\n0.2\n0.5\nCenter Frequency (kHz)\nCritical Bandwidth (Hz)\nTuesday, April 28, 2009\n\nCenter frequency\n- Bark scale\n- Zwicker and Fastl, 1990\n! 0.76 f \"\n#! f \"2$\nB( f ) = 13 arctan\n+ 3.5 arctan\nBark\nFrequency (kHz)\nTuesday, April 28, 2009\n\nMasking\n- Masking experiments to investigate\nfrequency selectivity\n- Tones masking tones demo\nFrequency\nAmplitude\nmasker\nprobe\nTuesday, April 28, 2009\n\nZwicker and Fastl, 1990\nTuesday, April 28, 2009\nChart showing\nfrequ\nen\ncy\nve\nrsu\ns s\nig\nna\nl\nbet\nwee\nn 2\nan\nd\nk Hz.\nFigure by MIT OpenCourseWare.\n\nUpward spread of masking\nTuesday, April 28, 2009\nU\np\nward\ns\np\nread\nof masking.\nFigure by MIT OpenCourseWare.\n\nMP3 Compression\n- Perceptual coding\n- ISO Standard 1991\n- 10 : 1 compression\n- Typical song size: 3.75 MB vs. 40 MB (CD\nOriginal iPod (2001)\n5GB = 1000 songs\nTuesday, April 28, 2009\n\nQuantization\n16 bits = 65536 levels\n10 : 1 compression = 1.6 bits\nTuesday, April 28, 2009\n\nTone masking noise\nFrequency\nAmplitude\nmasker\nnoise\nnoise level\nnoise\nbandwidth\nTuesday, April 28, 2009\n\nTone masking noise\nTuesday, April 28, 2009\n\nComplex tones\nTuesday, April 28, 2009\n\nHearing\n- Sound localization\n- Perception of complex periodic sounds\n- pitch\n- timbre\n- Auditory scene analysis\nTuesday, April 28, 2009\n\nLocalization\nTuesday, April 28, 2009\nA\nc\ntivati\non of receptors based on the position of the image on the retina.\nFigure by MIT OpenCourseWare.\n\nTuesday, April 28, 2009\nInteraural tim\ne differences for\ndifferent positi\nons around the he\nad.\nFigure by MIT OpenCourseWare.\n\nInteraural time difference\nTuesday, April 28, 2009\nInt\ne\nrau\nral\nti\nme\ndif\nfer\nen\nces\nfo\nr s\noun\nd so\nurce\ns va\nryin\ng in\nazi\nmuth.\nFigure by MIT OpenCourseWare.\n\nInteraural level difference\nTuesday, April 28, 2009\nI\nnt\neraural\n\nin\ntens\ni\nty\ndif\nf\nerences for different frequency\nto\nnes.\nFigure by MIT OpenCourseWare.\n\nCones of confusion\nTuesday, April 28, 2009\nC\nones of confusion.\nFigure by MIT OpenCourseWare.\n\nAuditory distance perception\n- Relative intensity\n- Spectral composition\nTuesday, April 28, 2009\n\nAuditory distance perception\n- Relative intensity\n- Spectral composition\nTuesday, April 28, 2009\n\nComplex periodic sounds\n- Pitch\n- Timbre\nTime\nAmplitude\nTuesday, April 28, 2009\n\nComplex sounds: pitch\nTuesday, April 28, 2009\nH\na\nr\nm\no\nni\nc\nen\nvi\nro\nnm\nen\nt\nal s\nounds.\nFigure by MIT OpenCourseWare.\n\nFundamental frequency\n- Lowest harmonic usually perceived pitch\n- Fundamental can be missing\nTuesday, April 28, 2009\n\nFundamental frequency\n- Lowest harmonic usually perceived pitch\n- Fundamental can be missing\n261.6\n523.2\n784.8\n1046.4\n1569.6\n1831.2\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\nTuesday, April 28, 2009\n\nFundamental frequency\n- Lowest harmonic usually perceived pitch\n- Fundamental can be missing\n261.6\n523.2\n784.8\n1046.4\n1569.6\n1831.2\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\n261.6\n523.2\n784.8\n1046.4\n1569.6\n1831.2\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\nTuesday, April 28, 2009\n\nTuesday, April 28, 2009\nHarm\nonic\ns of\nthe\nsame fu\nndamenta\nl frequen\ncy.\nFigure by MIT OpenCourseWare.\n\nOdd harmonics\n- Clarinet\n- cylindrical bore, closed at one end\n-5\n-10\n-15\n-20\n-25\n-30\n-35\n-40\n-45\n-50\nFrequency (Hz)\nTuesday, April 28, 2009\nAmplitude (dB)\n\nPitch illusion\n- Shepard tone\nfrom Music, Cognition, and Computerized Sound, ed. Perry Cook\nTuesday, April 28, 2009\nPitch ill\nusion - Shepa\nrd tone\n.\nFigure by MIT OpenCourseWare.\n\nMel scale\n- Stevens,Volkmann and Newman 1937\n- Equal in distance\nfrom Music, Cognition, and Computerized Sound, ed. Perry Cook\nTuesday, April 28, 2009\nM\nel\nsca\nle.\nFigure by MIT OpenCourseWare.\n\nPitch helix\n- Drobish (1855)\n- Shepard (1982)\nTuesday, April 28, 2009\nPi\ntc\nh\nhe\nli\nx.\nFigure by MIT OpenCourseWare.\n\nComplex sounds: timbre\n- Not well defined\n- Overtones\n- Formants\n- Attack and decay\n- Synchrony of microvariations\nTuesday, April 28, 2009\n\nHarmonics fuse\n- Energy in harmonics typically falls off\n- Harmonics perceptible in unusual spectra\nTuesday, April 28, 2009\n\nHarmonics fuse\n- Energy in harmonics typically falls off\n- Harmonics perceptible in unusual spectra\nFrequency\nAmplitude\nTuesday, April 28, 2009\n\nHarmonics fuse\n- Energy in harmonics typically falls off\n- Harmonics perceptible in unusual spectra\nFrequency\nAmplitude\nFrequency\nAmplitude\nTuesday, April 28, 2009\n\nFrequency\nHarmonics fuse\n- Energy in harmonics typically falls off\n- Harmonics perceptible in unusual spectra\nFrequency\nAmplitude\nAmplitude\nFrequency\nAmplitude\nTuesday, April 28, 2009\n\nTuesday, April 28, 2009\nThroat Singing\nFigure removed due to copyright restrictions.\n\nFormants\n- Fixed resonances\nTuesday, April 28, 2009\nForma\nnts\n- Fixed\nreso\nnances.\nA\nB\nFigure by MIT OpenCourseWare.\n\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\nTuesday, April 28, 2009\n\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\nTuesday, April 28, 2009\n\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\nTuesday, April 28, 2009\n\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\n-60\n-50\n-40\n-30\n-20\n-10\nFrequency (Hz)\nAmplitude (dB)\nTuesday, April 28, 2009\n\nMicrovariations\n- modulations of harmonics can affect fusion\nTuesday, April 28, 2009\n\nMicrovariations\n- modulations of harmonics can affect fusion\nfrom Music, Cognition, and Computerized Sound, ed. Perry Cook\nExample\nTuesday, April 28, 2009\n\nAttacks and decays\n- Basic transitions\n- attack, sustain, decay, release (ADSR)\nhttp://en.wikipedia.org/wiki/ADSR_envelope\nTuesday, April 28, 2009\n\nInstrument quiz\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz\nInstrument 1\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz\nInstrument 1\nInstrument 2\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz\nInstrument 1\nInstrument 2\nInstrument 3\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz\nInstrument 1\nInstrument 2\nInstrument 3\nInstrument 4\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz 2\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz 2\nInstrument 1\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz 2\nInstrument 1\nInstrument 2\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz 2\nInstrument 1\nInstrument 2\nInstrument 3\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nInstrument quiz 2\nInstrument 1\nInstrument 2\nInstrument 3\nInstrument 4\nbassoon,\nclarinet,\nhorn,\noboe,\npiano,\nsax,\nsynth,\ntrumpet\nTuesday, April 28, 2009\n\nAttacks\nFigure removed due to copyright restrictions.\nTuesday, April 28, 2009"
    },
    {
      "category": "Resource",
      "title": "Taste",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/761bb872070b78e6c680e2816eeea7ab_MIT9_35s09_lec04_taste.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nTaste\n\nTaste versus Flavor\nRetronasal olfactory sensation: The sensation of an\nodor that is perceived when chewing and swallowing\nforce an odorant in the mouth up behind the palate\ninto the nose\n- Such odor sensations are perceived as originating\nfrom the mouth, even though the actual contact of\nodorant and receptor occurs at the olfactory\nmucosa\nFlavor: The combination of true taste (sweet, salty, sour,\nbitter) and retronasal olfaction\n\nFigure 14.1 Movement of molecules released into the air inside our mouths as we chew and\nswallow foodMovement of molecules released into the air inside our mouth.\nFigure by MIT OpenCourseWare.\n\nTaste versus Flavor\nWhat happens when we cannot perceive taste but can\nstill perceive smell?\n- Patient case: Damaged taste, but normal\nolfaction--could smell lasagna, but had no flavor\n- Similar effect created in lab: Chorda tympani\nanesthetized with lidocaine\n- Chorda tympani: The branch of cranial nerve VII\n(the facial nerve) that carries taste information from\nthe anterior, mobile tongue (the part you can stick\nout)\n\nTaste versus Flavor\nConnection between taste and smell:\n- Brain imaging studies: Brain processes odors\ndifferently, depending on whether they come from\nnose or mouth\n- Food industry: Adds sugar to intensify sensation of\nfruit juice\nIncrease in sweetness (a pure taste sensation)\nincreases perceived olfactory sensation of fruit\n\nAnatomy and Physiology of the Gustatory System\nTaste buds:\n- Create neural signals conveyed to brain by taste\nnerves\n- Embedded in structures: Papillae (bumps on\ntongue)\n- Each taste bud contains taste receptor cells\n- Information is sent to brain via cranial nerves\n\nAnatomy and Physiology of the Gustatory System\nFour kinds of papillae:\n- 1. Filiform papillae: Small structures on the tongue\nthat provide most of the bumpy appearance. Have\nno taste function\n- 2. Fungiform papillae: Mushroom-shaped\nstructures (maximum diameter 1 mm) that are\ndistributed most densely on the edges of the\ntongue, especially the tip. An average of six taste\nbuds per papilla are buried in the surface\n\nAnatomy and Physiology of the Gustatory System\nFour kinds of papillae: (cont'd)\n- 3. Foliate papillae: Folds of tissue containing taste\nbuds. Located on the rear of the tongue lateral to\nthe circumvallate papillae, where the tongue\nattaches to the mouth\n- 4. Circumvallate papillae: Circular structures that\nform an inverted V on the rear of the tongue (three\nto five on each side). Moundlike structures\nsurrounded by a trench. Much larger than\nfungiform papillae\n\nFigure 14.2 The locations of each type of taste papilla and their neural connections to the brainThe locations of each type of taste papilla.\nFigure by MIT OpenCourseWare.\n\nAnatomy and Physiology of the Gustatory System\nTaste buds and taste receptor cells\n- Microvilli: Slender projections on the tips of some\ntaste bud cells that extend into the taste pore\nContain the sites that bind to taste substances\nNot tiny hairs (as the name implies): We now\nknow they are extensions of the cell membrane\n\nFigure 14.4 Taste budsFigures showing details of the taste buds.\nFigure by MIT OpenCourseWare.\n\nAnatomy and Physiology of the Gustatory System\nTastant: Any stimulus that can be tasted\nTastants can be divided into two large categories:\n- Some are made up of small, charged particles that\ntaste salty or sour\nSmall ion channels in microvilli membranes\nallow some types of charged particles to enter\nbut not others\n- Other tastants are perceived via G protein-coupled\nreceptors (GPCRs) similar to that in the olfactory\nsystem. These molecules taste sweet or bitter\n\nFigure 14.5 The different receptor mechanisms for ionic stimuli and those using a lock-and-key\nmechanism\nFigure showing different receptor mechanisms.\nK\nFigure by MIT OpenCourseWare.\n\nAnatomy and Physiology of the Gustatory System\nTaste processing in the central nervous system\n- Pathway: Taste buds to cranial nerves to medulla\nand thalamus and then on to cortex\n- Insular cortex: Primary cortical processing area for\ntaste. The part of the cortex that first receives taste\ninformation\n- Orbitofrontal cortex: The part of the frontal lobe of\nthe cortex that lies above the bone (orbit)\ncontaining the eyes\nReceives projections from insular cortex\nInvolved in processing of temperature, touch,\nsmell, and taste, suggesting it may be an\nintegration area\n\nFigure 14.6 Taste information projects from the tongue to the medulla, then the thalamus, then the\ninsula, and finally to the orbitofrontal cortexTaste information projects from the tongue to the medulla.\nFigure by MIT OpenCourseWare.\n\nAnatomy and Physiology of the Gustatory System\nInhibition: Plays an important role in processing taste\ninformation in the brain.\n- Function: To protect our whole mouth perception of\ntaste when we have injuries to taste system.\nDescending inhibition from taste cortex blocks pain\nperception\n- Has survival value because we need to eat even if\nour mouth has been injured\n\nThe Four Basic Tastes\nFour basic tastes:\n- Salty\n- Sour\n- Bitter\n- Sweet\n\nThe Four Basic Tastes\nSalty:\n- Salt is made up of two charged particles: Cation\nand anion.\n- Ability to perceive salt is not static\nLow-sodium diets will increase in intensity of\nsalty foods over time\n- Liking for saltiness is not static\nEarly experiences can modify salt preference.\nChloride-deficiency in childhood leads to\nincreased preference for salty foods later\nGestational experiences may affect liking for\nsaltiness\n\nThe Four Basic Tastes\nSour:\n- Comes from acidic substances\n- At high concentrations, acids will damage both\nexternal and internal body tissues\n\nThe Four Basic Tastes\nBitter:\n- Quinine: Prototypically bitter-tasting substance\n- Cannot distinguish between tastes of different\nbitter compounds\n- Many bitter substances are poisonous\n- Ability to \"turn off\" bitter sensations--beneficial to\nliking certain vegetables\n- Bitter sensitivity is affected by hormone levels in\nwomen, intensifies during pregnancy\n\nThe Four Basic Tastes\nSweet:\n- Evoked by sugars\n- Many different sugars that taste sweet:\nGlucose: Principle source of energy for most\nanimals\nFructose: Even sweeter than glucose\nSucrose: Common table sugar. Combination of\nglucose and fructose\n- Single receptor responsible for all sweet\nperception\nDifferent sweeteners stimulate different parts of\nreceptor\nArtificial sweeteners stimulate this receptor as\nwell\n\nFigure 14.9 Structure of the T1R2-T1R3 heterodimer sweet receptor\nStructure of\nthe T1R2-T1R3\nheterodimer\nsweet receptor.\nFigure by MIT OpenCourseWare.\n\nThe Four Basic Tastes\nThe special case of umami:\n- Candidate for fifth basic taste\n- Comes from monosodium glutamate (MSG)\n- Glutamate: Important neurotransmitter\n- Safety issues in human consumption:\nCan lead to numbness, headache, flushing,\ntingling, seating, and tightness in the chest if\nsensitive individuals consume a large amount\nFor most people, MSG does not pose a\nproblem in small doses\n\nThe Four Basic Tastes\nSurvival value of taste\n- Taste is a system for detecting nutrients and\nantinutrients\nBitter: Might signal poisons\nSour: Configured to detect acidic solutions that\nmight harm the body\nSweet and Salty: Our bodies need sodium and\nsugar to survive\n\nFigure 14.11 In our evolutionary past, specific hungers for sugar and salt were adaptiveHow specific hungers for sugar and salt were adaptive in our evolutionary past.\nFigure by MIT OpenCourseWare.\n\nThe Pleasures of Taste\nInfants' behavior and facial expressions reveal innate\npreferences for certain foods\nDifferent flavored foods placed on tips of infants'\ntongues:\n- Sweet food evokes a \"smilelike\" expression\nfollowed by sucking.\n- Sour produced pursing and protrusion of lips\n- Bitter produced gaping, movements of spitting, and\nsometimes vomiting movements\n\nFigure 14.10 The two toddlers' facial expressions reveal the taste qualities experienced\nFigures removed due to copyright restrictions.\n\nThe Pleasures of Taste\nSpecific hungers theory: The idea that deficiency of a\ngiven nutrient produces craving (a specific hunger) for\nthat nutrient\n- Cravings for salty or for sweet are associated with\ndeficiencies in those substances\n- However, the theory has not been supported for\nother nutrients, such as vitamins\n- Theory only holds for sweet and salty foods\n\nCoding of Taste Quality\nLabeled lines:\n- Theory of taste coding in which each taste fiber\ncarries a particular taste quality\nMajor source of controversy in literature\n- Other possibility: Patterns of activity across many\ndifferent taste neurons\n- Examples of both types of coding in other senses:\nColor vision and olfaction use pattern coding\nHearing uses labeled-line approach\n\nFigure 14.12 The tastes that human subjects perceive for each of four stimuli: sucrose, NaCl, HCl,\nand quinine\nThe t\nastes\nthat\nhuma\nn su\nbjec\nts per\nceive\nfor eac\nh o\nf fo\nur stim\nuli: sucrose, NaCl\n, HCl\n, and\nquinine.\nFigure by MIT OpenCourseWare.\n\nCoding of Taste Quality\nTaste adaptation and cross-adaptation:\n- All sensory systems show adaptation effects\n- Constant application of certain stimulus temporarily\nweakens subsequent perception\nExample: Adaptation to salt in saliva affects our\nability to taste salt\n- Cross-adaptation: When the taste of one food\naffects the taste of another\nExample: A sour beverage tastes too sour after\neating a sweet substance\n\nGenetic Variation in Taste Experience\nArthur Fox (1931) discovered that phenylthiocarbamide\n(PTC) tastes dramatically different to different people\n- Bitter taste to some but not to others\n- 1960s: Started using propylthioracil (PROP)\ninstead of PTC because it is safer\nGene for PTC/PROP receptors discovered in 2003\n- Individuals with two recessive genes are\nnontasters of PTC/PROP\n- Individuals with one or more of the genes are\ntasters of PTC/PROP\n\nFigure 14.13 The chemical structures of PTC (a) and PROP (b)\nT\nh\ne\n\nc\nh\ne\nm\ni\nc\na\nl\n\nstr\nu\nc\nt\nu\nr\ne\ns\n\no\nf\n\nP\nTC and PRO\nP\n.\nFigure by MIT OpenCourseWare.\n\nGenetic Variation in Taste Experience\nSupertaster: Individual who is a taster of PTC/PROP\nand has a high density of fungiform papillae\n- Perceives the most intense taste sensations\nFigures removed due to copyright restrictions.\n\nGenetic Variation in Taste Experience\nCross-modality matching:\nAbility to match the\nintensities of sensations\nthat come from different\nsensory modalities\n- Used to assess intensity of taste\nsensations for nontasters, medium\ntasters, and supertasters\nGenetic variat\nion in taste\nexperience.\nFigure by MIT OpenCourseWare.\n\nGenetic Variation in Taste Experience\nHealth consequences of taste sensation\n- Variations in sensory properties of foods and\nbeverages affects food preferences and therefore\ndiet\nFor instance, some vegetables have a bitter\ntaste and so might be avoided by supertasters\n- Valerie Duffy and colleagues showed that among\nmen getting routine colonoscopies, those tasting\nPROP as the most bitter had the most colon\npolyps\n- Note that fats also taste bitter to supertasters, so\nthis may cause them to eat fewer high-fat foods,\nwhich could lower their risk for heart disease\n\nGenetic Variation in Taste Experience\nPleasure and retronasal versus orthonasal olfaction\n- Orthonasal olfaction: Olfaction through the nostrils\n- Do we learn to like or dislike smells separately for\nretronasal versus orthonasal olfaction? Possibly\nExample: Many people like the smell of freshly\ncut grass, but wouldn't want to eat it\n- However, if an aversion is acquired retronasally, it\nusually shows up orthonasally as well\nExample: Becoming sick from eating fish and\nthen disliking even the smell of fish\n\nGenetic Variation in Taste Experience\nChili Peppers\n- Acquisition of chili pepper preference depends on\nsocial influences\n- Restriction of liking to humans\n- Variability across individuals, depending on\nnumber of papillae\n- Capsaicin: The chemical that produces the burn in\nchilis. Desensitizes pain receptors\n- Desensitization:\nIf a food is too hot for your palate, wait for burn\nto subside after the first mouthful. Your palate\nwill desensitize (from the capsaicin) and you\nshould be able to eat the rest of your meal\n\nFigure 14.16 Do these images inspire fear or delight in your taste buds?\nFigures removed due to copyright restrictions."
    },
    {
      "category": "Resource",
      "title": "The Retina",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/4296c1ad40c401365885bbf2c9f25dad_MIT9_35s09_lec03_retina.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nLast time\nThis time...\nThis time...\nPoke yourself in the eye\nThe retina\n9.35 - The Retina\nLast time\n- Optics - How images are formed in cameras.\n- The eye as a pinhole camera\n- How to use lenses to correct focusing problems.\nThis time...\nThis time...\n- The Retina - the \"recording surface\" of the eye.\n- The Retina - the \"recording surface\" of the eye.\n- Retinal anatomy - What kinds of cells do you have?\n- Retinal anatomy - What kinds of cells do you have?\n- Retinal topography - What is the organization of the retina?\n- Retinal topography - What is the organization of the retina?\n- Retinal pathology - What can go wrong with your retina?\n- Retinal pathology - What can go wrong with your retina?\nPoke yourself in the eye\n(wait for instructions, please...)\n- Observe the flickering light\n- Why does it look like light?\n-Mueller's law of specific nerve energies\n-Where is the light in visual space?\nFigure removed due to copyright restriction.\nThe retina\nFigure removed due to copyright restriction. How images are formed in camera.\nFigure by MIT OpenCourseWare.\n\nThe retina and the eye\nRed-eye and reflection from the retina\nWhy don't you see all the junk in the way?\nStabilization demo\nThis time...\nBeyond the receptors\nThe retina and the eye\nRed-eye and reflection from the retina\nWhen pupil is large, and flash is next to lens,\nlight is focused and bounces back along same\nline. Human retina has dark backing (pigment\nepithelium), but blood vessels give red cast.\nNote: Cats are nocturnal, rod dominated,\nwith \"reflective tapetum\" to give photons\na second chance to be absorbed.\nFigure removed due to copyright restriction.\nWhy don't you see all the junk in the way?\nBecause all that stuff is stabilized\nWith respect to the retina.\nIt turns out that our visual system is\nInsensitive to things that are\nPerfectly still relative to the retinal\nSurface.\nWhen you go to the optometrist (or\nStick your own bright light at the side\nOf your eye) you can get a transient\nView of the blood vessels because\nYou've interrupted the stable image.\nStabilization demo\nThis time...\nBeyond the receptors\n- The Retina - the \"recording surface\" of the eye.\n- Retinal anatomy - What kinds of cells do you have?\n- Retinal topography - What is the organization of the retina?\n- Retinal pathology - What can go wrong with your retina?\n5 primary cell types:\n-Rods and Cones\n- Horizontal Cells\n-Bipolar Cells\nFigure removed due to copyright restriction.\n-Amacrine Cells\n-Ganglion Cells\nThe\nretina\nand th\ne eye.\nThe\nretina\nand th\ne eye.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\n\nBeyond the receptors\nRods and Cones\nVisual purple and rhodopsin\nThe rhodopsin cascade\nHyperpolarization\nWhy hyperpolarize?\nBeyond the receptors\nRods and Cones\nThe outer segment of a rod or a cone is filled with photo-sensitive chemicals.\nIn rods, we call this rhodopsin and in cones we usually just call it color pigment.\nFigure removed due to copyright restriction.\nVisual purple and rhodopsin\n1876: Franz Boll saw a reddish pigment in frog retina,\nwhich bleached to yellow when exposed to light.\nKuhne called the pigment visual purple (now called\nrhodopsin). He had a rabbit stare at a window, killed the\nrabbit, and found the inverted image where the rhodopsin\nwas bleached away.\nFigure removed due to copyright restriction.\nMythology: \"Thus it was alleged that if the last object seen by a\nmurdered person was his murderer, the portrait drawn upon the\neye would remain a fearful witness in death to detect the guilty, and\nlead to his conviction. \" (New York Observer).\nThe rhodopsin cascade\nRhodopsin is a mixture of a protein called\nscotopsin and 11-cis-retinal. This stuff is\nMade from Vitamin A, which is why you\nshould eat your carrots to avoid vision\nproblems!\nAll trans Retinal is \"straightened\" II-cis-\nRetinal.\nNote: This pathway is rod-specific, but the\npathway for cones looks pretty much just\nthe same.\nHyperpolarization\nYou're probably used to thinking about\nneurons doing something like this:\nThe rods and cones actually\nwork differently.\n1.They hyperpolarize when stimulated with light. This means they actually\nare producing less neurotransmitter when they're stimulated (glutamate).\n2.\nThe produce graded potentials rather than \"all-or-none\" potentials.\nWhy hyperpolarize?\nMight reduce noise - depolarization all the time means lots of Na+ ions\naround all the time. Random ion channel closing/opening won't make much\nof a dent against the background of lots of ions, so harder to get spurious\nactivity without a photon.\nR\no\nd\ns\n\na\nn\nd C\nones.\nThe rhodo\npsin cascade.\nHyper\np\nolar\nizat\nion.\nA\nW\nhy\nhyp\nerp\nola\nriz\ne?.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\n\nRods and Cones\nDark adaptation experiments\nScotopic vs. Photopic sensitivity\nRod Vision vs. Cone Vision\nCone sensitivities\nCoarse coding and color vision\nRods and Cones\nQuestion: How do you design a visual system that can respond to the high\nillumination levels that occur during daytime, and to the low light levels\nthat occur at night?\nAnswer: The \"duplicity theory\" of vision (J. von\nKries, 1896): Use two different classes of\nphotosensitive receptors that operate in different\nluminance regimes\nFigure removed due to copyright restriction.\n- Scotopic vision: Low light levels, rod dominated\n- Photopic vision: High light levels, cone dominated\n- Mesopic vision: Medium light levels, mixed rod and cone\nresponse.\nDark adaptation experiments\nScotopic vs. Photopic sensitivity\nPhotopic vision has peak\nsensitivity at ~550nm.\nThus 5mw green laser pointers\n(532nm) look much brighter than\n5mw red ones (~635-670nm),\nalthough equal in power.\nScotopic vision has peak\nsensitivity at ~505nm (Purkinje\nshift), and are effectively \"blind\"\nto red light.\nRod Vision vs. Cone Vision\n- Rod vision is more sensitive than cone vision\n- individual rods are more sensitive to light cones.\n- higher convergence from rods to ganglion cells (120 to 1)\nthan from cones to ganglion cells (6 to 1; in the fovea it's\nvery often 1 to 1).\n- Rod vision has lower acuity than cone vision\n- higher convergence from rods, i.e., larger integration area.\n-rods also are slower, i.e., have longer integration time.\nFigure removed due to copyright restriction.\n- Rods offer no color vision, since only one type.\nCones provide color vision, with three cone types.\n- Rods are absent from the fovea; scotopic sensitivity is\nhighest slightly in the periphery (Arago's phenomenon).\nCone sensitivities\n\"red\" cones = \"long wavelength\" cones = L cones\n\"green\" cones = \"middle wavelength\" cones = M cones\n\"blue\" cones = \"short wavelength\" cones = S cones\nPrinciple of univariance: A receptor responds only to how much\nlight is absorbed, not to its wavelength. It delivers a single scalar.\n(The wavelength has to be \"inferred\" by the responses of the three cone types.)\nCoarse coding and color vision\nLet's say you want to locate something along a continuum. How do you do it?\n1.Build lots of finely-tuned sensors that can cover or \"tile\" the whole continuum.\n2.Build a few broadly-tuned sensors to do the same, and let 'em overlap.\nFigure removed due to copyright restriction.\nFigures removed due to copyright restriction.\nDa\nrk\nadaptation experi\nment\ns.\nS\ncot\noph\nic\nvs.\nPh\noto\nphi\nc S\nens\ni\ntiv\nity\n.\nCone se\nnsitivi\nties.\nCone se\nnsitivi\nties.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\n\nBeyond the receptors\nBipolar cells\nBeyond the receptors\nGanglion cells\nRF size and eccentricity\nCenter-surround cells\nBeyond the receptors\nBipolar cells\nRemember our photoreceptors who are hyperpolarizing away in response to\nLight and releasing less glutamate? An OFF bipolar cell will hyperpolarize when this\nHappens, an ON bipolar cell will depolarize.\nFigures removed due to copyright restriction.\nFigure removed due to copyright restriction.\nBeyond the receptors\nWe actually learned about the Ganglion\nCells first for technical reasons...\nGanglion cells\n-Two main kinds of ganglion cells defined anatomically:\n- midget and parasol.\n-Two main kinds of ganglion cells defined functionally (recordings):\n- parvocellular and magnocellular.\n-Don't get confused about M and P: parasol -> magno, and midget -> parvo.\n-M = Magno cells are larger, achromatic (no color), and prefer transient/ moving stimuli.\n-P = Parvo cells are smaller, care about luminance and color, and prefer steady stimuli.\nFor both cell types, the size of\nthe dendritic field (and the\nreceptive field) increases with\neccentricity (distance from fovea)\nFigure removed due to copyright restriction.\nRF size and eccentricity\nCenter-surround cells\nFirst center-surround RF discovered by\nKuffler (1953) This is an example of a\n\"circularly symmetric\" center-surround\norganization\nFigure removed due to copyright restriction.\nGanglion cells.\nRF si\nze an\nd ecc\nentricity\n.\nC\ne\nn\nt\ne\nr\n\n-\n\ns\nurround cells.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\n\nWhat do these cells respond to?\nWhat do these cells respond to?\n- Luminance of a homogeneous region?\nFigure removed due to copyright restriction.\n- Difference between center luminance and\naverage surrounding luminance\nOn-center and Off-center cells\nBreaking down center-surround\nThe Hermann Grid\nBergen grid\nThis time...\nOn-center and Off-center cells\nCourtesy of Palmer, Stephen E. 1999. Vision Science: Photons to Phenomenology. The MIT Press. Used with permission.\nBreaking down center-surround\nThe Hermann Grid\nWhat do you see at the\nIntersections?\nBergen grid\nCount the black dots!\nYou see the black holes in the\nperiphery, not where you are fixating.\nNeed the right RF size.\nThis time...\n- The Retina - the \"recording surface\" of the eye.\n- Retinal anatomy - What kinds of cells do you have?\n- Retinal topography - What is the organization of the retina?\n- Retinal pathology - What can go wrong with your retina?\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\n\nInhomogeneities in the retina\nThe blind spot\nInhomogeneities in the retina\nOne of the most important things to note about the retina is that it\nis remarkably non-uniform.\nThe blind spot\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\n- Draw this on a piece of paper.\n- Close one eye\n- Fixate the 'X' and move the paper back and forth until the 'O' vanishes\n- Discovered in 1688 by l'Abbe Edme Marriote\n- Louis XIV supposedly enjoyed \"beheading\" courtiers this way.\nThe retina is inhomogeneous\nDistribution of receptors in the eye\nThe retina is inhomogeneous\nDistribution of receptors in the eye\nCones in fovea...NO rods.\nPeriphery...mix of both.\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\nCourtesy of Helga Kolb. Used with permission.\n\nAnstis eye chart\nA Natural Scene version of the same thing\nAnstis eye chart\nResolution falls in\nproportion to distance\nfrom fovea\nA Natural Scene version of the same thing\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\nWhat about color sensitivity?\nIndividual variation\nProblems you might have with your retina\nSpots and Floaters\nIndividual variation of human\nTrichromatic Cone Mosaic.\nProblems you might have with your retina\n- Spots and Floaters\n- Retinal Detachment\n- Macular Degeneration\n- Retinitis Pigmentosa\n- Color-Blindness\nSpots and Floaters\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\n\nRetinal Detachment\nMacular Degeneration\nRetinal Detachment\nMacular Degeneration\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\nThe macula is the central part of your retina.\nRetinitis pigmentosa\nColor-blindness\nHow does it play out?\nDeuteranopia\nRetinitis pigmentosa\nHereditary disease in which rods slowly deteriorate and die. The fovea is spared\nLeaving patients with \"tunnel vision.\"\nColor-blindness\n- Protoanomaly (~1% of men) - \"Red Weak\"\n- Deuteranomaly (~5% of men) - \"Green Weak\"\n-Dichromacy (Protanope & Deuterope) ~1% of men each\nG\nR\nB\nHow does it play out?\nDeuteranopia\nCourtesy of Jay Neitz. Used with permission.\nFigure removed due to copyright restriction.\nFigure removed due to copyright restriction.\nCourtesy of Jay Neitz. Used with permission.\n\nColor-blindness\nColor-blindness\nCourtesy of Jay Neitz. Used with permission."
    },
    {
      "category": "Resource",
      "title": "Depth Cues",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/31ef37ac76305c94207d0d4c6e3e21a4_MIT9_35s09_rec01_depth_cues.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nDepth Cues\n\nName some depth cues.\n- What gives us information about depth?\n- What do we need to know (assume) to use\nthis information?\n- When would using this information make\nus go wrong?\n- How does \"precision\" depend on distance?\n\nFigure removed due to copyright\nrestriction.\nG\nr\nap\nhs\nd\nep\nict\ning\nde\npth\n.\nFigure by MIT OpenCourseWare.\n\nDepth cues!\nFigure s\nhowing depth cues.\nFigure by MIT OpenCourseWare."
    },
    {
      "category": "Resource",
      "title": "Eye and Retina",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/086d219123b0de7af3a6d32d9a335f7c_MIT9_35s09_rec02_eye_and_retina.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n9.35 Recitation 1\nEye and Retina\n\nHello, my name is...\nAnd I've worked on...\nAnd you?\n\nEarly Ideas\n\"In man, soul and body touch each\nother only at a single point, the pineal\ngland in the head.\"\nRenee Descartes\n\nEarly Ideas\nFigures removed due to copyright restrictions.\n\nEarly Ideas\nIs there really a homunculus?\n\nRays are not Colored\n\"And if at any time I speak of Light and Rays as\ncoloured or endued with Colours, I would be\nunderstood to speak not philosophically and\nproperly... For the Rays to speak properly are\nnot coloured. In them there is nothing else than\na certain Power and Disposition to stir up a\nSensation of this or that Colour.\"\nSir Isaac Newton, Opticks, 1730\n\nBetter Ideas\nNeurons, not the soul, process light!\nFigures removed due to copyright restrictions.\n\nBut Wait!\nWhat's a neuron??Figure explaining a neuron.\nFigure by MIT OpenCourseWare.\n\nBut Wait!\nWhat's a neuron?\nA neuron knows nothing but it's input\nNT's change electrical potential across membrane\nof neuron\nNeuron can then release NT's on other neurons\nReceptive Field\nReally, just the input to a neuron\nBy extension, the properties of the world that\ninfluence firing\n\nBut Wait!\nWhat's a neuron?\nNothing magic, but our senses/thoughts can\nonly be conveyed through electricity!\nLaw of Specific Nerve Energy\n\nBut Wait!\nWe will discuss recordings:\nFigure removed due to copyright restriction.\n\nRetina\nFigures removed due to copyright restrictions.\n\nPhotoreceptors\nFigures removed due to copyright restrictions.\n\nBipolars\nON/OFF\nFigures removed due to copyright restrictions.\n\nHorizontal Cells\n1st step of lateral inhibition\nFigures removed due to copyright restrictions.\n\nLateral Inhibition\nWolfe et al: Ambient light invariance\nBut, this is really about edge detection\n\nGanglion Cells\nRGC's have the most lateral inhibition\nDepolarization -> AP's\nAlmost perfect inhibition\nLinear Summation\nDifference of Gaussians\nFigures removed due to copyright restrictions.\n\nSombrero Function\nHow does this RF detect edges?\nFigures removed due to copyright restrictions.\n\nSombrero Function\n-10\n-8\n-6\n-4\n-2\n-0.2\n-0.1\n0.1\n0.2\n0.3\n0.4\n0.5\nExcitation from center\nDistance from center of RF\nInhibition from surround\nCell Response\nLinear summation result:\nRF = Center - Surround\nLinear summation result:\nRF = Center - Surround\n\nConvolution\nFigures removed due to copyright restrictions.\n\nMach Bands\nFigures removed due to copyright restrictions.\n\nGrids\nDOG's explain some effects...\nFigures removed due to copyright restrictions.\n\nGrids\nBut not others!\nFigures removed due to copyright restrictions.\n\nMidgets and Parasols\nIn addition to ON/OFF pathways, there is a\nsecond parallel system\n\nMidgets and Parasols\nMidgets/beta/X ganglion cells\nSmall, slow AP's, small RF, colored, linear\nParasols/alpha/Y ganglion cells\nLarge, fast AP's, large RF, nonlinear, motion\nsensitive\nNames depend on species and method of\ndiscovery, assumed homologous\n\nMidgets\nSmall RF's\n(1 cone center\nnear fovea)\nwebvision\nCovergence o\nf cones and bi-pol\nar cells upon ON and OFF center beta cells.\nConvergence of cones and bipolar cells upon ON- and OFF-center beta cells.\nFigure by MIT OpenCourseWare.\n\nMidgets\nSmall RF's\nwebvision\nModel\nof two-cone bi\npolar types.\nFigure by MIT OpenCourseWare.\n\nMidgets\nLinear summation responses\nBecause they have few cone inputs, can also be color\nopponents (ie Red Center, Green Surround)\nwebvision\nFigure removed due to copyright restriction.\n\nParasols\nHUGE RF's!\nwebvision\nConvergence of c\nells to alpha and\nbeta cells.\nModel\nof nu\nmbers of cone bipolar cells.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\n\nMidgets and Parasols\nMidgets\nHigh SF, -> Parvocellular LGN -> 'What'\npathway/ventral visual stream\nIf I say 'Ganglion Cell,' this is what I mean!\nParasols\nLow SF, high temporal frequencies\n-> Magnocellular LGN -> 'What' and 'Where'\npathways/dorsal and ventral visual streams\n\nReading\nKolb, How the Retina Works (online)\nUnderstand:\nEye structure, 5 basic cell types, adaptation, lateral\ninhibition, rod/cone, ON/OFF and midget/parasol\npathways, receptive fields\nIgnore:\nNeurotransmitters, rhodopsin, cell subtypes (e.g., AII,\nA17 etc)\n\nAdditional Resources\nhttp://webvision.med.utah.edu"
    },
    {
      "category": "Resource",
      "title": "Motion",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/9-35-sensation-and-perception-spring-2009/f54376b82b97dad2ff4de546d138bc0f_MIT9_35s09_rec03_motion.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n9.35 Sensation And Perception\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMotion\n4/7/08\n\nA few motion issues\n- Motion is time dependent - processing takes\ntime.\n- dx/dt - what is X?\n- Recognition from motion.\n\nDealing with delays.\n- Prediction.\n- Retina\n- Flash Lag\n- Postdiction (making yourself consistent).\n\nPrediction in the retina.\nA\nnt\ni\ncipa\ntio\nn\nof\nmov\ni\nng\n\nstimuli by th\ne retina.\nFigure by MIT OpenCourseWare.\n\nDecoding from retinal motion\nsignal\nFigures removed due to copyright restriction.\n\nFlash Lag\n- http://www.michaelbach.de/ot/mot_flashlag\n1/flashlag‐fillin‐2.swf\n\nPost‐diction\nFigures removed due to copyright restriction.\n\ndx/dt. What is x?\n- Stuff in the world moves.\n- We move (eyes, head, body).\n- We measure the projections of (possibly)\nmoving stuff onto our moving sensory organs.\n- Retina\n- Apertures and knowledge.\n\nMotion on the retina\nFigure removed due to copyright restriction.\n\nAccounting for eye-motion\nQ. When do we see an object move?\nA. When its image moves on the retina.\nIs this really true?Figures show how the eye accounts for motion.\nFigure by MIT OpenCourseWare.\n\nAccounting for eye-motion (contd.)\nThe corollary discharge model (Teuber, 1960)\nPredictions: 1. Pushing on the eyeball would cause the world to --------\n2. A stabilized after-image would appear to ------- when the eye is\nmoved voluntarily\n3. If your eye was paralyzed with curare and you then attempted to\nmove it, you would see the world --------Figures show how the eye accounts for motion.\nFigure by MIT OpenCourseWare.\n\nMotion and inference.\n- http://www.michaelbach.de/ot/mot_bounce/\nindex.html\n- http://www.michaelbach.de/ot/mot_motionB\ninding/index.html\n\nSeeing from motion\n- http://www.biomotionlab.ca/Demos/BMLwal\nker.html\n\nFun\n- http://www.michaelbach.de/ot/mot_mib/ind\nex.html"
    }
  ]
}