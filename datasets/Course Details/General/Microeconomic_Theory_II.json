{
  "course_name": "Microeconomic Theory II",
  "course_description": "This course offers an introduction to noncooperative game theory. The course is intended both for graduate students who wish to develop a solid background in game theory in order to pursue research in the applied fields of economics and related disciplines, and for students wishing to specialize in economic theory. While the course is designed for graduate students in economics, it is open to all students who have taken and passed 14.121.",
  "topics": [
    "Social Science",
    "Economics",
    "Microeconomics",
    "Game Theory",
    "Social Science",
    "Economics",
    "Microeconomics",
    "Game Theory"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hours / session\n\nSyllabus (\nPDF\n)\n\nThis course offers an introduction to noncooperative game theory. The course is intended both for graduate students who wish to develop a solid background in game theory in order to pursue research in the applied fields of economics and related disciplines, and for students wishing to specialize in economic theory. While the course is designed for graduate students in economics, it is open to all students who have taken and passed 14.121.\n\nThe recommended primary text for the course is Drew Fudenberg and Jean Tirole's text,\nGame Theory\n(MIT Press, 1991). The text covers all the material in the course and much more, but has less in the way of intuition and examples than some students would like. For this reason, students might alternatively wish to use Robert Gibbons'\nGame Theory for Applied Economists\n(Princeton University Press, 1992) as their primary reference. Gibbons' book contains more readable discussions of the material and a lot of nice examples, but omits a few of the topics we'll cover.\n\nThe course will be graded on the basis of five problem sets and a three-hour final exam. In order to learn the material it is absolutely essential to do the problem sets. The problem sets will count for approximately one-fourth of the course grade. Five graded problem sets will be due during the term of the course. One week after the last problem set is due an optional sixth problem will be discussed in recitation. The final exam will be held in the week after. (See assignments section.)",
  "files": [
    {
      "category": "Resource",
      "title": "Handout #1: Finding PBE in Signaling Games",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/0c77aa544ed2ea3d26fed6f9e4460551_pbe.pdf",
      "content": "Game Theory 14.122: Handout #l\nFinding PBE in Signaling Games\n1 General Strategy\nIn a 2 x 2 signaling game, there can be any or all of the following Perfect Bayesian\nEquilibria (PBE): both types of Player 1 may play pure strategies in equilibrium\n(if they play the same strategy, we say it is a pooling equilibrium; if they differ,\nwe say it is a separating equilibrium); one type of Player 1 may play a pure\nstrategy while the other plays a mixed strategy (leading to a semi-separating\nequilibrium); or both types of Player 1 may play mixed strategies. (We won't\ndeal with the latter case.)\nWhen looking for a PBE...\n1. Decide whether you're looking for a separating, pooling, or semi-separating\nequilibrium.\n2. Assign a strategy (a message for each type) to Player 1; make sure it is\nnot strictly dominated.\n3. Derive beliefs for Player 2 according to Bayes' rule at each information set\nreached with positive probability along the equilibrium path. Set arbitrary\nbeliefs for Player 2 at information sets that are never reached along the\nequilibrium path.\n4. Determine Player 2's best response.\n5. In view of Player 2's response, check to see whether Player 1 has an in-\ncentive to deviate from the strategy you assigned her in any state of the\nworld (in other words, for all types of Player 1). If she does not, you have\nfound a PBE. If she does, this is not an equilibrium - return to step 2 and\nassign Player 1 a different strategy.\n6. Once you have exhausted all possible strategies within an equilibrium\nsubset, return to step 1 and select a different type of PBE.\n\n2 Example\nNature moves first. With equal probabilities, Nature assigns Player 1 type\nt E {t1,t2).\nPlayer 1 knows her type, and chooses whether to play L or R.\nPlayer 2 does not know what player's 1 type is, but he sees whether she\nplays L or R. He chooses U or D.\nFigure 1: Game\nThe extensive form of the game and its payoffs are presented in Figure 1.\nFor example, if Player 1 is of type tr and plays R, and Player 2 plays U, the\npayoffs are 5 to Player 1 and 4 to Player 2.\nNote that if Player 1 is of type t2 and plays R, and Player 2 plays U, the\npayoff to Player 1 is x. Different values of x will be used at different points.\nNote also that for Player 1 of type tr, R strictly dominates L: playing L,\nshe will always get 2; playing R, she will get at least 3. This means that in\nany PBE, type tr will always play R. This is intended to simplify the search for\nequilibria by eliminating half of the possible equilibria of each type (more than\nhalf of the semi-separating equilibrium possibilities). In a more general set up,\nthese additional possibilities would need to be explored.\n\n3 Finding a Separating PBE\n3.1 Player 1 Strategy\nAssume for now that x = 2.\nIn a separating PBE, each Player 1 type chooses a different message, so that\nthe message perfectly identifies the player type. There are only two possibilities\nfor separating strategies for Player 1. One possibility is that type 1 will choose\nR and type 2 will choose L. The other possibility is that type 1 will choose L and\ntype 2 will choose R. If either type has one message which strictly dominates\nthe other, that type of Player 1 will never play the dominated strategy, so the\nselection of strategies to test is simplified. In this case, because for type tl, R\nstrictly dominates L - as explained above - if there exists a separating PBE, it\nmust be that type 1 plays R and type 2 plays L. In other words,\n01 (t) =\nR if t = ti\nL if t = t2\n'\n3.2 Beliefs for Player 2\nLet ,LL (&IA) be the probability Player 2 assigns to type i after observing action\nA.\nIf Player 2 sees that Player 1 plays L (in other words, in the left-hand\ninformation set) she will assign probability 1 to type 2. If she sees Player 1 play\nR, she will assign probability 1 to type 1. These are the only beliefs consistent\nwith Bayes' rule, because both the left-hand and the right-hand information\nsets are reached with positive probability along the equilibrium path.\nTo see this, recall Bayes' rule:\n~ (tllR) = p cRltl) p ctl) =\np (Wl) p (a\nP CR)\nP (Rltd P (tl) + P (Ritz) P (tz)'\nWe know from the structure of the game that\nP (tl) = P (tz) = 0.5. By construction (the assignment of Player l's strategy\nabove) we know that\nP(Rltl) = 1\nand\nP (Rlt2) = 0.\nPlugging in and solving, we get\nCL (tl I@ = 1\n(and therefore, p (t2lR) = 0).\nIn the same way, we solve for p (tl IL) = 0.\n3.3\nBest Response for Player 2\n3.3.1 Against R\nPlayer 2's expected utility from playing U and D at the right-hand information\nset, respectively, is\n\n~2 (u,R) = p((tllR) * U2 (U,R;h) +~(t2lR)\n* u2 (U,R;t2) = 4\nand\nr&u2 (D, R) = p (t11R) * U2 (D, R; tl) + P (tzlR) * U2 (D, R; t2) = 1.\nTherefore BR2 (R) = U.\n3.3.2 Against L\nIEu2 (U,L) = p(t1lL) * u2 (U&h) + P((t2lL) * u2 (U,L;t2)\n= 0.\nlEu2 (D, L) = /A (t1 IL) * u2 (D, L; t1) + P (tzlL) * u2 (D, L; t2) = 1.\nTherefore BR2 (L) = D.\n3.4 Is this an Equilibrium?\nSince Player 2's beliefs are Bayesian by constrution, and Player 2's strategy is\na best response given those beliefs, this is an equilibrium if and only if neither\ntype of Player 1 has an incentive to deviate.\nWe already know that type tl will not deviate, because for her R strictly\ndominates L.\nType t2 will follow the assigned strategy as long as the payoff it yields is at\nleast as high as the one she would get if she deviated.\nType tz's payoff along the equilibrium path is lJ1 (L, D; tz) = 2.\nIf she deviated and played R instead, Player 2's beliefs would continue to be\nas above; in other words, he would believe, upon seeing R played, that Player 1\nwas of type tl with probability 1, and would therefore play U. Player l's payoff\nfrom deviating would therefore be Ul (R, U; t2) = z = 2. Since this is no higher\nthan her equilibrium payoff, she will not deviate.\nSince neither type of Player 1 will deviate, the beliefs derived above are\ncorrect, and the following is a PBE:\nCl (t) =\nR\nif t=tl\nL if t = t2\n02 (al, p (al)) =\nU\nif\nal = R\nD\nif\nal=L\nand\nPLad= (\n:[::1$ ) =\n(\ni ).\nNote that the beliefs are an integral part of the equilibrium; these beliefs\nsupport the equilibrium strategies. If Player 2 had different beliefs, his optimal\nstrategy might be different.\n3.5 Comments\n1. If type tl did not have a dominant strategy, we would have to also check\nwhether a separating equilibrium in which type tl plays L and t2 plays R.\nExercise 1 Suppose x = 4. Show that no separating equilibrium exists.\n\n4 Finding a Pooling PBE\n4.1 Player 1 Strategy\nAssume, as before, that z = 2.\nIn a pooling PBE, both types of Player 1 choose the same message, so that\nthey cannot be distinguished on the basis of their behavior. There are only\ntwo possibilities for separating strategies for Player 1: play R always, or play L\nalways. In this case, because for type ti, R strictly dominates L - as explained\nabove - if there exists a pooling PBE, both types of Player 1 must play R:\ng1 (t) =\nR\nif t=tl\nR if t = t2\n'\n4.2 Beliefs for Player 2\nIf Player 2 sees that Player 1 plays R - along the equilibrium path - Bayes' rule\napplies:\np (tll@ = p Wd p (tl) =\np (ml) P(b)\np CR)\nP (Rltl) P (tl) + P (R(h) P (t2)\nWe know from the structure of the game that P (tl) = P (tz) = 0.5. By\nconstruction (the assignment of Player l's strategy above) we know that\nP (Rltl) = 1\nand\nP (Ritz) = 1.\nPlugging in and solving, we get\np (tllR) = p (t21R) = 0.5.\nIf, however, Player 1 plays L, which never occurs along the equilibrium path,\nBayes' rule does not apply:\nP (tl IL) # p(L:;g(tl)\nbecause P(L) = 0. In this case, we get to arbitrarily assignment beliefs.\nIt is not possible at this point to know what, if any, beliefs regarding off-\nequilibrium path behavior will sustain a pooling equilibrium. So for now assume\nthat p (ti IL) = X E [0, 11.\n4.3\nBest Response for Player 2\n4.3.1 Against R\nPlayer 2's expected utility from playing U at the right-hand information set is\nEL72\n(U, R) = p (tllR) * U2 (U, R; tl) + P (t2lR) * U2 (U, R; tz) = 2.\nSimilarly,\nlfW2 (D, R) = p (tl\\R) * U2 (D, R; tl) + p (t2lR) * U2 (D, R; td = 1.\nTherefore U dominates D, and Player 2 will always respond to R with U:\nBR2 (R) = U.\n\n4.3.2 Against L\nlEu2 (U,L) = p((t1lL) * u2 (U, L;h) + p (t2IL) * u2 (U, L;b) = A.\nEU2 (D, L) = p (tl IL) * u, (D, L; t1) + p (t21L) * u2 (D, L; t2) = 1 - A.\nWhich is the best response therefore depends on the beliefs of Player 2:\nif X > 0.5\nif X < 0.5\nqU+(l-q)D\ni\nf\nX=0.5(q~\n[O,l]) '\n4.4 Is this an Equilibrium?\nSince Player 2's beliefs are Bayesian by constrution, and Player 2's strategy is\na best response given those beliefs, this is an equilibrium if and only if neither\ntype of Player 1 has an incentive to deviate.\nWe already know that type tl will not deviate, because for her R strictly\ndominates L.\nType t2 will follow the assigned strategy as long as the payoff it yields is at\nleast as high as the one she would get if she deviated.\nType tz's payoff along the equilibrium path is lJ1 (R, U; t2) = z = 2. If she\ndeviated and played L instead, Player 2's off-equilibrium path beliefs would kick\nin.\nIf X < 0.5, he would play D, and Player l's payoff from deviating would\ntherefore be lJ1 (L, D; t2) = 2. Since this is no higher than her equilibrium\npayoff, she will not deviate. This would therefore be an equilibrium.\nIf X > 0.5, he would play U, and Player l's payoff from deviating would\ntherefore be lJ1 (L, U; t2) = 4, which is higher than her equilibrium payoff.\nShe will deviate, which means the strategies reassigned her will not hold up as\nequilibrium strategies under the specified beliefs.\nIf X = 0.5, Player 2 is indifferent between U and D, and may play any\n(possibly degenerate) combination of the two. Because the expected payoff to\nPlayer 1 from any non-degenerate mixture by player 2 is strictly greater than\n2 (the equilibrium payoff she gets), the belief X = 0.5 can be sustained in\nequilibrium only if q, the probability that Player 2 plays U, is 0.\nSummarizing, the following are pooling PBEs of this game:\ng1 (t) =\nR\nif\nt=ti\nR if t = t2\n02 (a1,/J(a1))\n=\n.\nand\np((al)= ( ;;;;I;;\\ -:( ;~;05A50.5.\nAlthough the equilibrium strategies are uniquely defined, the above repre-\nsents a continuum of equilibria in which X takes on values along [0,0.5] .\n\n4.5 Comments\n1. This example serves to illustrate the importance of off-equilibrium path\nbeliefs. If X > 0.5, Player 2's off-equilibrium path behavior would change.\nBecause in equilibrium Player 1 knows Player 2's strategy (both on and\noff the equilibrium path), this changed in Player 2's strategy would change\nPlayer l's best response, and the equilibrium reconstructed would crumble.\n2. If type tr did not have a dominant strategy, we would have to also check\nwhether a pooling equilibrium in which both types of Player 1 play L\nexists.\nExercise 2 For what, 2f any, values sf x does no pooling equilibrium exist?\n5 Finding a Semi-Separating PBE\n5.1 Player 1 Strategy\nContinue to assume that x = 2.\nIn a semi-separating PBE, one type of Player 1 plays a pure strategy while\nthe other plays a mixed strategy. As a result, Player 2 is able to imperfectly\nupdate his prior beliefs about Player l's type. Contrast this with the case of\na pooling equilibrium, in which no updating is possible (the posterior belief\nalong the equilibrium path are the same as the priors), and with a separating\nequilibrium, in which updating is perfect (in each information set correct beliefs\nplace probability 1 on one type and probability 0 on the other). For example,\nsuppose all smart types go to MIT, while dumb types may go to either Harvard\nor MIT. Then if you observe someone going to Harvard, you know she's a dumb\ntype, but if you observe someone going to MIT you cannot tell whether he is\nsmart or dumb.\nIn a 2 x 2 (2 players, 2 pure strategies for each) game of the type with which\nwe're concerned there are four possible semi-separating equilibria. If Player 1\nof type tr mixes L and R, Player 1 of type t2 could potentially play only R or\nonly L. Similarly, if it is type t2 which is mixing, type tl could play either L all\nof the time or R all of the time. Again, having R strictly dominate L for type\ntl greatly simplifies things in our example, because she can neither makes nor\nplay L only. Therefore, if there is a semi-separating equilibrium in this game, it\nmust take the form that Player 1 of type tl plays R exclusively, and Player 1 of\ntype t2 mixes L and R. The only uncertainty regards the mixing probabilities\nfor type t2. For now, to be completely general, let the strategy be\ng1 (t) =\nR\nif t = tl\npL + (1 - p) R\nif\nt = t2 ' P E (0,11.\n\n5.2 Beliefs for Player 2\nBecause both L and R are played with positive probability along the equilibrium\npath, Bayes' rule applies in both information sets for Player 2.\nP(W) = P(Rltl)P(tl) _\nP(Rltl)P(t~)\n0.5\nP(R)\n- P(Rltl)P(tl)+P(Rlta)P(tn)\n= 0.5+0.5(1--p) = 2--p'\n!JLhlL) = 0.\n5.3\nBest Response for Player 2\n5.3.1 Against R\nIEU~ (u,R) = p(tllR) * Uz (U,R;h) +/J(W) * u2 (U,Rtz) = $jp\nw2 (D, R) = P (tllR) * U2 (D, R; h) + P (t2lR) * U2 (D, R t2) = 1.\nTherefore BR2 (R) = U.\n5.3.2 Against L\nEU2 (U, L) = p (tllL) * u2 (U, L; t1) + P tt2lL) * u2 v-4 L; t2) = 0.\nr&U2 (D, L) = P((tllL) * u2 (D,L;h) + PL(t2IL) * u2 (D,L;tz) = 1.\nTherefore BR2 (L) = D.\n5.4 Is this an Equilibrium?\nSince Player 2's beliefs are Bayesian by constrution, and Player 2's strategy is\na best response given those beliefs, this is an equilibrium if and only if neither\ntype of Player 1 has an incentive to deviate.\nWe already know that type tl will not deviate, because for her R strictly\ndominates L.\nType t2 will follow the assigned strategy as long as she is exactly in different\nbetween playing L and playing R - if she is not, she will deviate and always\nplay the strategy which yields the highest payoff.\nType t2's payoff along the equilibrium path is Ur (R, U; t2) = z = 2 if she\nplays R, and Ur (L, D; t2) = 2 if she plays L. So she is indifferent, which means\nshe is willing to play a mixture strategy, so Player 2's beliefs are correct.\nSummarizing, the following are semi-separating PBEs of this game:\nal(t) =\nR\nif t = tl\npL + (1 - p) R\nif\nt = t2 ' P E ml)\nU if ar = R\nD if al = L\n5.5 Comments\n1. Notice that in this case, because the semi-separating equilibria are sup-\nported by (almost) the entire unit interval, the separating equilibrium is\n\nsimply the limit of the semi-separating equilibria as p -+ 1. The pooling\nequilibria are not obtained by taking the limit as p -+ 0 because Bayes'\nrule fails to apply in that case.\n2. If type tr did not have a dominant strategy, we would have to also check\nwhether any (or all) of the other three possible configurations of a semi-\nseparating equilibrium work in this case.\nExercise 3 Suppose lJz (U, R; tl) = 1.5 (instead o,f 4 as in the diagram). What\n({fany)\nt 't'\nres rzc sons would this put on the semi-separating equilibrium?\nExercise 4 Suppose x = 1. For what, if any, values of ?Yl (U, R; tl) is there\na PBE in which both types of Player I play mixed strategies? Note that {f\nU1 (U, R; tl) 5 2 then Player 1 of type tl no longer has a strictly dominant\nstrategy."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/f956cd1eb715b9f9f6c6c4bc8550d566_ps1q.pdf",
      "content": "14.122 Problem Set #1\n1. Find a game which is not solvable by pure strategy iterated strict dominance but\nwhich does have an unique pure strategy Nash equilibrium.\n2.\nConsider the model of Cournot competition discussed in class where the inverse\ndemand function is P(q) = 1 -q and the firms have zero marginal costs. Show that it\nis strictly dominated for the firms to produce any quantity greater than 1\n2 Write the set\nof strategies which are not strictly dominated for the firms as an interval [S1, S1]. Find\nthe interval of strategies [S2, S2] which are not strictly dominated when a firm's opponent\nchooses a quantity in [S1, S1]. Prove by induction that when the iterated strict dominance\nprocess is continued the set of strategies remaining at stage 2k is the interval [S2k, S2k]\nwhere\nS2k =\nk\n\nj=1\n4j .\nS2k = 1\n2 -1\nk-1\n\nj=1\n4j .\nConclude that the game is solvable by iterated strict dominance.\n3. Consider the following game-theoretic model of the equilibrium determination of\nthe cleanliness (and effort distribution) of an apartment shared by two roommates. In the\ngame, the two roommates simultaneously choose the effort, e1 e2, to spend on apartment\ncleaning. They each get utility from the cleanliness of the apartment (which is a function\nof the sum of the efforts) and disutility from the effort they personally expend. Player 1\nplaces a higher valuation on cleanliness. Specifically, assume that e1 and e2 are chosen from\nthe set of nonnegative real numbers and that\nu1(e1, e2)\n=\nk log(e1 + e2) -e1\nu2(e1, e2)\n=\nlog(e1 + e2) -e2,\nwhere k > 1\n(a) Find the two players best response functions.\n(b) Find the pure strategy Nash equilibria of the game.\nHow does the equilibrium\ndistribution of effort reflect the differences in the players' tastes.\n(c) Try to write down a modification of the model above in which the outcome seems\nmore fair.\n4. Write out a formal specification (strategy sets, payofffunctions, etc.) of the two\nplayer version of the game described in problem 1.8 of Gibbons. What is the pure strategy\nNash equilibrium of the two player game?\n\n5. Find all of the Nash equilibria of the following games.\n1.8.\nConsider a population of voters uniformly distributed along\nthe ideological spectrum from left\n= 0) to right\n= 1). Each of\nthe candidates for a single office simultaneously chooses a cam-\npaign platform (i.e., a point on the line between x = 0 and x = 1).\nThe voters observe the candidates' choices, and then each voter\nvotes for the candidate whose platform is closest to the voter's\nposition on the spectrum.\nIf there are two candidates and they\nchoose platforms\n=\nand\n=\nfor example, then all\nvoters to the left of x =\nvote for candidate 1, all those to\nthe right vote for candidate 2, and candidate 2 wins the elec-\ntion with 55 percent of the vote. Suppose that the candidates\ncare only about being elected-they do not really care about their\nplatforms at all.\nIf there are two candidates, what is the pure-\nstrategy Nash equilibrium. If there are three candidates, exhibit\na pure-strategy Nash equilibrium. (Assume that any candidates\nwho choose the same platform equally split the votes cast for that\nplatform, and that ties among the leading vote-getters are resolved\nby coin flips.) See Hotelling (1929) for an early model along these\nlines."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/d31882f525b7d6dddcb39e7a66348bd9_ps2q.pdf",
      "content": "14.122 Problem Set #2\n1. Find all of the Nash equilibria of the following games.\n2. Consider a game in which two students simultaneously choose effort levels e1, e2 ∈\n[0, 1] in studying for an exam. The exam is graded on a curve and effort directly determines\nperformance, so the student who works harder will get an A and the other student will get\na B. If the students exert identical effort assume that they both get B's. Assume that the\neach student receives one extra util from getting an A instead of a B and a disutility of 2e2\nutils from expending effort e. Find a mixed strategy Nash equilibrium of this game.\nIf you have time it would also be educational to try to prove that there are no other\nNash equilibria.\n3. Consider a version of the Bertrand price competition game. Firms 1 and 2 simul-\ntaneously choose p1 and p2 from the set of positive real numbers. Assume that there are\nno costs of production. If pi < pj assume that firm i gets demand D(pi) and firm j gets\ndemand 0, with D(p) = √1+p. If the firms charge equal prices assume that demand is split\nevenly.\n(a) Give a case-by-case argument to show that the only pure strategy Nash equilibrium\nis p∗= p∗= 0.\n(b) While it only has one pure strategy Nash equilibrium, the model above actually has\nan infinite number of mixed strategy Nash equilibria. Show by direct construction that the\nmodel has a symmetric mixed strategy Nash equilibrium where the players choose strategies\nfrom a distribution with full support on [8, inf). What is funny about the set up of this\nmodel that lets these equilibria exist?\nHint: What must the payoffin such an equilibrium be?\n3,0\n\n4. When I give an exam in 14.122, my utility is decreasing in the effort which it takes\nme to make up new questions and increasing in the amount of time which students spend\nlearning the material the course covers. I have two options to choose from: to make up\nnew questions or to reuse questions from old exams. In preparing for the exam students\nalso have two choices: to spend their time available for studying trying to learn the course\nmaterial, or to try to find out what questions were asked in past years and memorize the\nanswers. While I don't necessarily have these sentiments in real life, assume for the purposes\nof this question that having students only memorize old questions is sufficiently annoying\nto me that I derive utility from having them fail an exam containing new questions if this\nis all they've done. Assume that students care mostly about their score on the exam (but\nperhaps also about learning) so that if I ask new questions students are best offlearning\nthe material, while if I ask old questions they are best offmemorizing old answers.\nWrite down what you would think are reasonable utility functions for a typical student\nand for me (consistent with the description of the game above). Find the Nash equilibrium\nof the game and comment on how the probability with which I put old questions on the\nexam is affected by the parameters of the utility function."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/62b5cc06fc5ea76e0a9c79286ca8df71_ps3q.pdf",
      "content": "14.122 Problem Set #3\n1. Prove the following theorem (known as the Debreu-Fan-Glicksburg Theorem), which\nestablishes sufficient conditions for the existence of a pure strategy Nash equilibrium in\ncertain games with continuous action spaces.\nTheorem 1 Let G be a normal form game. Suppose that the strategy sets Si are nonempty,\ncompact, convex subsets of Euclidean space and that the payofffunctions ui are continuous\nin s and quasiconcave in si. Then G has a pure strategy Nash equilibrium.\n(Hint: the proof is very similar to that of Nash's Theorem.)\n2. Let G be a two player normal form game with strategy spaces A1 and A2. A mixed\nstrategy Nash equilibrium σ∗is said to be totally mixed if σi\n∗(ai) > 0 for all ai ∈Ai. Show\nthat if G has more than one totally mixed Nash equilibrium then it must have infinitely\nmany.\nCan you give an example of a game which has more than one but finitely mixed strategy\nNash equilibria (which are not pure strategy NE)?\nLet G be the game shown below where a drunk student is trying to get from Kendall\nSquare to Harvard Square, but can not recall each time the doors of the subway open how\nmany stops (if any) have passed.\n4.\n3. (a) Write out a complete description of the set of nodes, information sets, action,\nsuccessor and payoff functions, etc. in the game below.\n(b) Write out the normal representation of the game and find all of the pure strategy\nNash equilibria.\nA\n\n----\n--\n\n----\n--\n: .: .: .\n. . . .\n. . . .\n\ndoes this idea not extend to games of imperfect recall in the way in which you might have\nexpected? What might the proper generalization be? (Feel free to not think about this\ngame much if you think it confuses you and will make you forget the basic point that payoffs\nare linear in mixing probabilitites.)\n′\n′\n′\n(a) A game is said to have perfect recall if whenever x and x are in the same information\nset neither is a predecessor of the other, and whenever x′′ ∈h(x′), x is a predecessor of x′\nand the same player i moves at x and x there exists a node ˆx (possibly equal to x) such\nthat ˆ\nx is a predecessor of x′′ and the action taken\nx is in the same information set as x, ˆ\nat x along the path to x is the same as the action taken at ˆx along the path to x′′. (See\nFudenberg-Tirole p. 81.) Show formally that the game above does not have perfect recall.\n(b) How many pure strategies does player 1 have in this game. What is the set of mixed\n(behavior) strategies available to him?\n(c) What payoffdoes player 1 receive from each of his pure strategies? What payoff\ndoes player 1 receive from mixing and getting offwith probability p? What is the optimum\nchoice of p?\n(d) I've repeated many times in this class that players utility functions are a linear\nfunction of the probabilities with which they mix over their pure strategies strategies. Why"
    },
    {
      "category": "Assignment",
      "title": "Problem Set #4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/10215815f14c129e623aff8360cea268_ps4q.pdf",
      "content": "14.122 Problem Set #4\nSuppose two companies, one American and one Japanese, can each produce a ho-\nmogeneous good for sale in the U.S. market at marginal cost c, 0 ≤c < 1. However, the\nJapanese firm must also pay a tariffof t per unit sold. Assume that the inverse demand is\ngiven by P(Q) = 1 -Q where Q is the total quantity produced by the two firms.\n(a) Find the Nash equilibrium of the Cournot-like game where the firms simultaneously\nchoose quantities qA and qJ (with t fixed). How high must the tariffbe to eliminate all\nJapanese imports?\n(b) Suppose the U.S. government chooses t before the firms choose quantities, and that\nthe objective of the govermment is to maximize the sum of consumer surplus, the profit\nof the domestic firm and tax revenues. What tarifflevel is chosen in a subgame perfect\nequilibrium?\n(c) Find a Nash equilibrium of the game above in which the U.S. government achieves\na lower utility level than it does in the subgame perfect equilibrium.\nConsider the following model of monetary policy. In the first stage, the firms in\nthe economy form an expectation πe of what the inflation rate will be and sign wage\ncontracts, make investments, etc. on the basis of these expectations. Next, the Federal\nReserve takes actions which determine the actual inflation rate π.\nUnexpectedly high\ninflation stimulates the economy and increases aggregate output Y , but any departures\nof inflation from expectations cause losses to the firms. In particular, assume that Y =\nY0 + a log(1 + π -πe) and that the firms' profits are -(π -πe)2. Suppose also that the\nutility of the Federal Reserve Chairman is given by Ufed = Y -cπ2.\nFind the inflation level in the subgame perfect equilibrium of this game.\nDoes the\nsubgame perfect equilibrium involve rational expectations (i.e. is πe = π)? Comment on\nhow the equilibrium inflation rate varies with a and c?\n4.\n3.\n1. For each of the extensive forms below say whether the set of successors of the\nindicated nodes are or are not subgames.\n2. Find all of the subgame perfect equilibria of the following extensive form game and\ngive the payoffs obtained by the players in each of them.\n\\\n\nL\nR\nL\nR\n0, 0\n2, 2\nU\n-10, x\ny, 0\n0, 0\nD\n8, 4\nU\n0, 0\n4, 8\nD\n4. Consider the one player infinite horizon game in which player 1 chooses an action\nat ∈{0, 1} at t = 1, 2, 3, . . ., and receives a payoffof 1 if limt→infat >\notherwise.\n2 and a payoffof zero\n(a) Show that the payoffs in this game are not continuous at infinity.\n(b) Find a strategy profile which is not a subgame perfect equilibrium despite the fact\nthat the player can not change his strategy at a single information set h and improve his\npayoffconditional on that information set being reached.\nSuppose that two players play each other for two periods. In the first period they\nplay the game at left below, and in the second period they play the game at right. There\nis no discounting between periods. Players observe the action their opponent took in the\nfirst period before choosing their second period actions.\n(a) For x ≤2 and y ≤6, find a subgame perfect equilibrium in which player 1 receives\na payoffof 10.\n(b) For x = 5 and y = 3, find a subgame perfect equilibrium in which player 2 receives\na payoffof 10.\n(c) For x = y = 4 show that there is no subgame perfect equilibrium in which (U, L) is\nplayed in the first period.\n5."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/5cbb0849562cb38c9eeac4bb032877dc_ps5q.pdf",
      "content": "14.122 Problem Set #5\n1. Suppose two firms are engaged in repeated Cournot competition with demand being\nP(q1, q2) = 1-(q1+q2). Show that using punishments which involve a permanent reversion\nto the static Cournot equilibrium (q1 = q2 = 1\n3) the firms can support full collusion (q1 =\nq2 = 1\n4) as a subgame perfect equilibrium provided that δ ≥9\n17.\n2. A payoffvector v = (v1, v2, . . . , vI) ⊂RI is said to be feasible in a game G if there\nexist action profiles a1, a2, . . . , ak and nonnegative weights w1, w2, . . . , wk with P\nj wj = 1\nsuch that\nvi = w1gi(a1) + w2gi(a2) + . . . + wkgi(ak).\nA payoffvector v is said to be strictly individually rational if\nvi >\nmin\nσ-i∈Σ-i\nmax\nσi(σ-i)∈Σi\ngi(σi(σ-i), σ-i)\nfor all i.\n(a) What are the feasible and individually rational payoffs in the Cournot game.\n(b) In answering (a) you should have noted that the feasible individually rational payoff\nvectors for the Cournot game include some where the players receive lower payoffs than they\nwould if they repeatedly played the static Cournot equilibrium. Use the no single period\ndeviation criterion to show that the symmetric strategy profile (q, q) described below is a\nsubgame perfect equilibrium if δ ≥2\n3 and show that the \"average\" payoffs players receive\nfrom it corresponds to a payoffvector in which each player earns less than the Cournot\nprofit.\nq(ht) =\n\n3/8\nif t = 0\n3/8\nif t > 0 and both players followed strategy q in the previous period\n1/2\notherwise\n(Be sure to note that the \"punishment\" q1 = q2 =\n2 lasts for only one period after a\ndeviation.)\nComment on how the punishments above are similar to and different from those which\nI showed in class make it possible for firm 1 to produce q = 1 in a Nash equilibrium of the\nStackelberg model.\nFor extra credit you could try to describe how one might construct punishments related\nto those above (but different) to sustain full collusion in the repeated Cournot game for\nsome discount factors which are less than\n17.\n3. Two players are working together to try to complete a project. When players 1 and 2\nchoose effort levels e1, e2 ∈[0, 1], the probablility that the project is successfully completed\nis 1\n2(1+e1)e2. Assume that players receive one util if the project is succesful, and that they\nincur a disutility of effort which makes their expected payoffin the game equal to\nui(e1, e2; c1, c2) = 1\n2(1 + e1)e2 -cie2\ni ,\n\nwhere c1 and c2 are constants greater than or equal to one which parameterize the disutility\nof effort.\nAssume that it is common knowledge that c2 is equal to one, but that c1 is known only\nto player 1, with player 2's prior being that nature chooses c1 from the probability density\nfunction\nf(x) =\n( 2\n5x\nif x ∈[2, 3]\notherwise.\nFind the Bayesian Nash equilibrium of this game.\n4. Consider the following strategic situation. Two opposed armies are poised to seize\nan island which is currently unoccupied. Each army's general can choose either to \"attack\"\nor to \"not attack\". In addition, each army is either strong or weak with its strength being\nknown to its general alone. General 1's prior is that army 2 is strong with probability 1\n(and that this event is independent of army 1's strength) and general 2's prior is that army\n1 is strong with independent probability 1\n3. These priors are common knowledge among\nthe players.\nSuppose that the payoffs in the game are reflect additively both the benefit of capturing\nthe island and cost suffered in fighting. Specifically assume that the island is worth M if\ncaptured, and that an army captures the island if and only if it attacks when its opponent\ndoes not or it attacks when its rival does also, but it is strong and its rival is weak. (Note\nthat when two weak or two strong armies fight neither captures the island.) The cost of\nfighting is s if an army is strong and w if an army is weak (with s < w) regardless of the\nstrength of the attacking rival army (with no fighting costs being incurred if one or both\narmies choose not to attack and there is no battle).\nIdentify all of the pure strategy Bayesian Nash Equilibria of this game.\n5. Glenn Ellison and Josh Angrist are trying to meet for lunch. At twelve o'clock each\nof them must go to one of two places: Florentina's or the trucks behind the swimming\npool. Because they need to talk about something, assume that each receives a benefit of\n3 utils if they meet. Assume also that each incurs a disutility cost of w from waiting in\nline outside Florentina's in the cold. Because Josh came in on the subway just before noon\nhe knows how long the Florentina's line is, i.e. he knows w, while Glenn's prior is that w\nis distributed uniformly on [0, 1]. While it is common knowledge that Josh is completely\nindifferent between the food choices at each place, assume that Glenn incurs a disutility of\n3d if he eats at the trucks. The strength of Glenn's dislike for the trucks varies from day\nto day -- assume that Glenn knows d while Josh's prior is that d is distributed uniformly\nin [0, 1].\nTo summarize the payoffs, when the wait at Florentina's is w and Glenn's disutility\nfrom going to the trucks is d the payoffs in the game are (with Josh as player 1)\n\n0, -w\n3 -w, 2\n3 -w\n3, 2\n3 -3d\n-w, -3d\nFlorentina\nTrucks\nFlorentina\nTrucks\n(a) How would you specify this game formally as a Bayesian game? In particular, what\nwould the sets of types be and how would the payofffunctions depend on the types? What\nform would you expect the equilibrium strategies to take?\n(b) Find the Bayesian Nash equilibrium of this game. How often do Glenn and Josh\nhave have lunch together?"
    },
    {
      "category": "Resource",
      "title": "Final 2000: Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/ae6573aedf3280a150c8fa49c2a21dc5_f2000s.pdf",
      "content": "Guide for solving the 2000 exam for 14.122\nQuestion 1\n(4\nSee the lecture notes or FT for the formal definition. We care about continuity at infinity because\nif this property is satisfied, then checking a proposed SPE is equivalent to checking the single-deviation-\nproperty (ie that no player can achieve a higher payoff by deviating from their equilibrium strategy at a\nsingle node, and playing according to their equilibrium strategy at all other nodes).\n@I\nYes, it has a unique NE (u,A). This is also the only outcome that survives iterated strict\ndominance. To see this, start by noting that for player 2, C is strictly dominated by ;A + ZB (or other\ncombinations of A and B will work as well), and go from there.\nCc)\nSee the notes for the definitions. The assumption that breaks down in the \"name the largest\nnumber\" game is that C, the space of strategy profiles, is not compact (because there is no limit on how\nlarge the numbers named by the players can be).\n(4\nThis is false. If a property holds for generic games, then for any game for which the property\ndoesn't hold, there is another game, where the payoffs are arbitrarily close to the first game, for which the\nproperty does hold. So clearly this isn't true in, for example, games where all the payoffs are strictly negative.\n(e)\nThere are two subgames (three if you also count the whole game as a subgame). One begins at\nl's node just above the terminal nodes (1,l) and (2,0). The other begins at the upper of 2's non-singleton\nnodes.\n(BTW: According to the way FT, and I believe Glenn, defines things, all games are proper\nsubgames of\nthemselves, so by this definition the whole game is also a subgame.\nGibbons, on the other hand, doesn't\ncount the original game as being one of the subgames).\n(0\nThe centipede game that Glenn discussed in class is an example where SPE/backward induction\nrules out a reasonable outcome. If you remember, the SPE is to play down immediately, giving the players a\nlow payoff. But it is probably more reasonable from an empirical point of view to expect players to cooperate\nfor a while before they play down.\nAn example where SPE gives an unreasonable result - Glenn gives several of these in the notes. He\ndiscusses games in which SPE allows equilibria that involve players choosing actions at an information set\nthat are inconsistent with any possible set of beliefs the player could hold at that information set. Signalling\ngames will often have unreasonable SPE, because there are no subgames (you can't separate parts of the\ngame tree without cutting information sets).\n(8)\nFirstly note that D and then B can be eliminated by iterated strict dominance. There are no\npure strategy NE of the resulting 2x2 game. The mixed strategy NE is (SU + $M, $A + SC).\nThe NE is al = $$, a2 = E (found by solving the two best response functions simultaneously).\n(9\nRemember for the Intuitive Criterion you basically have to establish two things\n- heuristically (1)\nthat the type making the speech gets a higher payoff under the deviation and some best response to the\ndeviation than under the PBE, and (2) that the other type does not have an incentive to make such a speech.\nSo Irving's argument is ok - you can verify that the B = 3 type could do better by choosing e = 1, but the\n0 = 2 type could not. Freddy's argument doesn't make sense, because neither type has an incentive to make\nsuch a speech.\nCourtesy of James Vickery.\nUsed with permission.\n\nQuestion 2\n(4\nTree not drawn. But player 1 has 3x2~2~2 = 24 pure strategies, and player 2 has 3x3x3 = 27\npure strategies.\nFor example, can check that the strategy profile where player 1 plays: (give other player\n$2, D, D, D), and player 2 plays: (B if player 1 gave up 2, C otherwise) is a NE. Given the strategy\nof the other player, neither player can achieve a higher payoff by unilaterally adopting a different strategy.\nCc)\nIfJ:<Othen(U,A)' 1s not a NE of the subgame, and thus the only NE of the subgame is (D, B).\nThen by backward induction player 1 will choose to give up 0 at the first stage of the game. So the condition\nfor a unique SPE is z < 0.\n(4\nWe are looking for an SPE where the static NE (U, A) will be used to reward player 1 when he\ngives up $2 at the first stage of the game (we can't use\n(U, A) as the punishment NE because x > 0 so the\npunishment won't be big enough). So along the equilibrium path, player 1 will get payoff of x, which must\nbe greater than 2 + 1 (since the second stage outcome must always be a NE of the second stage game).\nSo x > 3 will ensure that the strategy profile where player 1 plays (give other player $2, A if 1 gave\naway $2 at the first stage, D otherwise) and player 2 plays (A if player 1 gave up $2, B otherwise) is an\nSPE.\n(e)\nNo, because the lowest-payoff NE in the second stage gives payoff of at least zero to both players\n(zero occurs only when x = 0). So player 1 can always keep both dollars at the first stage of the game, and\nin any SPE will at worst get 0 in the second stage, for a total payoff of 2.\nQuestion 3\n(a)\n01 = {type who doesn't know 4). 02 = {1,2,3}. MIT has 2x2x2=8 pure strategies (a choice\nbetween two actions for each of three types), while Harvard has only 2 pure strategies.\n(b)\nThe actions a2(q = 3) = don't admit, and a2(q = 1) = admit are both conditionally dominated.\nIn words, MIT will never let in a\n4 = 1 student because even if Harvard does not make the student an offer,\nthe payoff for MIT is less than 0. In contrast, MIT will always admit a\n4 = 3 student regardless of Harvard's\nst,rategy, because even if Harvard makes the student an offer, MIT's payoff is 0.65\nx 1.5 - 1\nx 0.35, which is\ngreater than zero. No actions are conditionally dominated for MIT when\nq = 2, because they want to admit\nthe student if and only if Harvard does not admit the\nst,udent.\nHarvard has no conditionally dominated strategies.\n(cl\nGiven the discussion in part (b), the only possible\nBNE's are\n1.\nal = Admit; a2(q = 1) = aQ(q = 2) = Don't admit, a2(q = 3) = Admit\n2.\nal = Don't admit; az(q = 1) = Don't admit, az(q = 2) = a2(q = 3) = Admit\nYou can check that the first of these possible equilibria doesn't work. In the first putative equilibrium,\nHarvard's expected payoff from admitting the student is\nU(Admit) = -0.5 x l/3 + 0.5 x l/3 + (0.35 x 1.5 - 1 x 0.65) x l/3, which is negative. So Harvard would\nchoose to deviate and not admit the student.\nBy similar calculations, can check that the second potential equilibrium really is a BNE.\nSo the unique BNE will be al = Don't admit; a2(q = 1) = D on't admit, a2(q = 2) = a2(q = 3) = Admit.\n(4\nNo, observing MIT's action won't help. If q = 2 or q = 3 (ie if Harvard observes ADMIT),\nHarvard will make a negative expected payoff trying to compete for the student. If\nq = 1 (Harvard observes\nNO ADMIT), H arvard is better off not admitting the student.\n\nQuestion 4\n(4\nNO, because in this case PHMO = 500 and PFULL = 2000. So the unhealthy type gets utility\n0 from choosing full insurance, and utility 500 from choosing the HMO. Consequently, they would deviate\nfrom their equilibrium strategy.\n(b)\nThe pooling equilibrium we're looking for is:\n~(0) = FULL for 6' E {healthy,not\nhealthy}\nsz(FULL)\n= 1oooq + 2000(1 - q)\ns2(HMO) = 1000\n~(0 = healthy ( s1 = FULL) = q\np(B = healthy ( sl=HMO)=O\nNote that player 2's beliefs are the same as her priors, because this is a pooling equilibrium. Off the\nequilibrium path, we want player 2 to have the 'worst' possible beliefs, so that the set of admissable q's is\nas large as possible. Also note that the price for full insurance is equal to the expected payout, because of\nthe quadratic nature of player 2's utility function.\nNow have to check this is an equilibrium. Firstly, player 2 will not deviate, since they are getting their\nmaximum possible payoff.\nSecondly, the unhealthy type has no incentive to deviate from this equilibrium, since the price for full\ninsurance is less than 2000 (if they chose the HMO option, their utility would be zero).\nWhat about the healthy type? They will not deviate as long as:\n2000 - [lOOOq + 2000(1 - q)] 2 1500 - moo\nThis expression simplifies to q > 0.5\n(cl\nIn this case you might expect the equilibrium to take the form of a cutoff rule - player 1 will\nchoose full insurance when their cost c > c*.\nFor the cutoff type: 2000 - c*/2 - pffin/ro\n= 2000 - PFULL. Also note that the prices for both types of\nhealth insurance must reflect the expected payouts, so:\nPFI/LL = $c* + 2000)\nPHMO = zC*\nSubstituting these prices into our cutoff rule, we find that c* = 2000, which implies that with probability\n1, full insurance is not taken up.\n(4\nThe model shows that because of adverse selection, private insurance markets are often unable\nto provide a high enough level of insurance. To think about the problem more seriously, would need to take\ninto account the possibility of screening by health insurers, as well as the risk aversion of individuals (which\nwill determine the optimal demand for insurance - in this model there is no real need for insurance in the\nfirst place because everyone is risk-neutral)."
    },
    {
      "category": "Exam",
      "title": "Final Exam 2000",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/d942ce843a40fd4a6c0567ec5b0ef77d_f2000q.pdf",
      "content": "14.122 Final Exam\nAnswer all questions. You have 3 hours in which to complete the exam.\n1. (60 Minutes - 40 Points) Answer each of the following subquestions briefly. Please\nshow your calculations and provide rough explanations where you can't give formal state-\nments so I can give you partial credit.\n(a) Give a formal definition of what it means for a multistage game with observed\nactions to be continuous at infinity? Why do we care whether games are continuous at\ninfinity?\n(b) Is the game below solvable by iterated strict dominance? Does it have a unique\nNash equilibrium?\n(c) State Kakutani's theorem. What correspondence is it applied to in the proof that\nany finite game has a Nash equilibrium? Where does the argument break down if you try\nto use Kakutani's theorem in the same way to prove the existence of an equilibrium in the\n\"Name the Largest Number\" game?\n(d) Is the following statement true or false: In generic finite normal form games player\n1's equilibrium payoffis positive.\n(e) Find all of the subgames of the following extensive form game.\n(f) Given an example of a game in which you could argue that the subgame perfect\nequilibrium concept is too restrictive and rules out a reasonable outcome. Give an example\nof a game in which you could argue that the subgame perfect equilibrium concept is not\nrestrictive enough and fails to rule out an unreasonable outcome. (Explain briefly what\nyou would argue about each example.)\n(g) Find all of the Nash equilibria of the following game.\n\n(h) Find the Nash equilibrium of the simultaneous move game where player 1 chooses\na1 ∈R, player 2 chooses a2 ∈R, and the payoffs are\na2 + 22\nu1(a1, a2) = -(a1 -1)2\n\na1 -\n-\nand\na1 + 22\nu2(a1, a2) = -(a2 -3)2\n\na2 -\n-\n.\n(i) Suppose that in class I presented the following slight variant on Spence's job market\nsignalling model. Nature first chooses the ability θ ∈{2, 3} of player 1 (with both choices\nbeing equally likely). Player 1 observes θ and chooses e ∈{0, 1}. Player 2 then observes\ne and chooses w\n.\nThe players' utility functions are u1(e, w; θ) = w -ce/θ2 and\n∈R\nu2(e, w; θ) = -(w -θ)2 For c = 4.25 this model has both a pooling equilibrium:\n( = 2) = 0\n∗θ\n.\n( = 0) = 2 5\n∗e\n.\nμ2(θ = 2 e = 0) = 0.5\n|\n|\ns\ns\n( = 3) = 0\n∗θ\n( = 1) = 2\n∗e\nμ2(θ = 2 e = 1) = 1\ns\ns\nand a separating equilibrium:\n( = 2) = 0\n∗θ\n( = 0) = 2\n∗e\nμ2(θ = 2 e = 0) = 1\n|\n|\ns\ns\n( = 3) = 1\n∗θ\n( = 1) = 3\n∗e\nμ2(θ = 2 e = 1) = 0\ns\ns\nSuppose that after class two students come up to you in the hallway and ask you to\nsettle an argument they are having about whether the equilibria fail the Cho-Kreps Intuitive\nCriterion. Assume that Irving argues\nThe pooling equilibrium violates the intuitive criterion. The θ = 3 type could\nmake a speech saying 'I am choosing e = 1. I know you are supposed to believe\nthat anyone who gets an education is the low type, but this is crazy. The θ = 2\ntype would be worse offswitching to e = 1 even if you did choose w = 3. I,\non the other hand, being the θ = 3 type will be better from having switched to\ne = 1 if you choose w = 3. Hence you should believe that I am the high type\nand give me a high wage.'\nFreddy argues\nThe separating equilibrium violates the intuitive criterion. It is inefficient. Be-\nfore he learns his type player 1 could make a speech saying. 'This equilibrium is\ncrazy. Education is of no value, yet with some probability I am going to have to\nincur substantial education costs. This is entirely due to your arbitrary belief\nthat if I get no education I am the low type. If you instead believed that I was\nthe low type with probability one-half in this case, then the return to education\nwould be sufficiently low so as to allow the inefficiency to be avoided. Moreover,\nthis more reasonable belief would turn out to be correct as I would then choose\ne = 0 regardless of my type.'\nWhat would you tell them?\n\n2. (40 Minutes - 20 Points)\nConsider the following multistage game.\nPlayer 1 first has to choose how to divide\n$2 between himself and player 2 (with only integer divisions being possible). Both players\nobserve the division, and they then play the simultaneous move game with the dollar payoffs\nshown below.\nAssume that each player is risk neutral and has utility equal to the sum of the number\nof dollars he or she receives in the divide the dollar game and the dollar payoffhe receives\nin the second stage game\n(a) Draw a tree diagram to represent the extensive form of this game. How many pure\nstrategies does each player have in the normal form representation of this game?\n(b) Show that for any x the game has a Nash equilibrium in which player chooses to\ngive both dollars to player 2 in the initial divide-the-two-dollars game.\n(c) For what values of x will the game have an unique subgame perfect equilibrium?\n(d) For what values of x is there a subgame perfect equilibrium in which player 1 gives\nboth dollars to player 2 in the initial divide-the-two-dollars game.\n(e) Can the game have a subgame perfect equilibrium in which player 1's total payoff\nis less than 2?\n\n3. (40 Minutes - 20 Points)\nHarvard and MIT are both considering whether to admit a particular student to their\neconomics Ph.D. programs. Assume that MIT has read the student's application carefully\nand knows the quality q of the student. Assume that Harvard faculty members are too\nbusy to read applications carefully. Instead they must base their decisions on their prior\nabout the student's ability. Harvard's prior is that q may be 1, 2 or 3 and that each of\nthese values is equally likely.\nAssume that each school must make one of two decisions on the student: admit with\nfinancial aid or reject (the student has no source of support and could not attend graduate\nschool without financial aid). The schools make these decisions simultaneously.\nAssume that each school's payoffin the game is 0 if they do not offer the student\nadmission, -1 if the student is offered admission and turns them down (this is costly both\nbecause the school loses prestige and because the slot could have been given to another\nstudent), and q -1.5 if the student is offered admission and decides to come.\nAssume that if the student is admitted to both schools she chooses to come to MIT\nwith probability 0.65 and to go to Harvard with probability 0.35.\nIn the following questions treat this as a two player game between Harvard (player 1)\nand MIT (player 2).\n(a) What type spaces Θ1 and Θ2 would you use to represent this situation as a static\ngame of incomplete information? How many elements are in each set? Write down the val-\nues of the utility functions ui(a1, a2; θ1, θ2) for a couple values of i, a1, a2, θ1, θ2 to illustrate\nhow to compute them. How many pure Bayesian strategies does each player have?\n(b) What actions are strictly (conditionally) dominated for each possible type of each\nplayer?\n(c) Find the Bayesian Nash equilibrium of this game.\n(d) Would Harvard be any better offif it could observe MIT's admission decision before\nmaking its decision?\n\n4. (40 Minutes - 20 Points)\nConsider the following model in which a worker's choice of health play may signal\nhis health to his insurance company. Suppose nature first chooses the health of the worker\nchoosing θ ∈{healthy, not healthy}. Assume that the probability that the worker is healthy\nis q. Player 1 observes whether he is healthy and then chooses a1 ∈{HMO, full insurance}.\nPlayer 2, the competitive insurance market, observes a1 and then chooses a price p for the\nchosen plan.\nAssume that the HMO plan will always pay half of the worker's health care expenses,\nwhile the full insurance plan will pay all of the worker's health care expenses. Assume that\nthe worker's expected health care expenses are $1000 if the worker is healthy and $2000 if\nthe worker is not healthy. Assume that the worker is risk neutral and that his expected\nutility from each health plan is equal to 2000 minus the sum of p and his unreimbursed\nhealth care expenditures, i.e.\nu1(HMO, p; healthy)\n=\n1500 -p\nu1(full insurance, p; healthy)\n=\n2000 -p\nu1(HMO, p; not healthy)\n=\n1000 -p\nu1(full insurance, p; not healthy)\n=\n2000 -p\nTo model a competitive insurance market assume that player 2's has a quadratic utility\nfunction that makes it want to set p equal the expected payments that will be made under\na plan, i.e.\nu2(HMO, p; healthy)\n=\n-(p -500)2\nu2(full insurance, p; healthy)\n=\n-(p -1000)2\nu2(HMO, p; not healthy)\n=\n-(p -1000)2\nu2(full insurance, p; not healthy)\n=\n-(p -2000)2\n(a) Does the model have a separating PBE where only the unhealthy workers buy full\ninsurance?\n(b) For what values of q does this model have a pooling PBE where all types of player\n1 buy full insurance?\n(c) Suppose that rather than there being just two types of player 1 there are a continuum\nof possible types. In particular, assume that player 1 observes his expected health care\nexpenditures for the year before making his health plan choice and that player 2's prior is\nthat these are uniformly distributed on [0, 2000]. What kinds of equilibria seem like they\nmight be possible in this model? Show that there is no PBE in which player 1 buys full\ninsurance with positive probability.\n(d) What does this model suggest about the dangers of a free market in health insurance?\nWhat modifications to the model would be necessary if you wanted to think about the\ninefficiency of health insurance more seriously?"
    },
    {
      "category": "Resource",
      "title": "Final 2001: Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/63c028d07534bad0884d4d62985bfe6f_f2001s.pdf",
      "content": "._ -,--..Y\nCourtesy of Ivan Fernandez-Val.\nUsed with permission.\n\n. b-2\n\ni&?-Tc\n-\n= 0.58\\ i -2.\n\nIi h\nn=\n6%\n-4-i\n\n2*PQ\n* ,C-."
    },
    {
      "category": "Exam",
      "title": "Final Exam 2001",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-122-microeconomic-theory-ii-fall-2002/e576f8e0a1de65f28b5840e8366d1d5f_f2001q.pdf",
      "content": "14.122 Final Exam\nAnswer all questions. You have 3 hours in which to complete the exam. The exam\nis pretty long so I've put stars next to questions I guessed might be the hardest. You may\nwant to leave these until the end if you are worried that you may end up being short on\ntime.\n1. (55 Minutes - 36 Points) Answer each of the following subquestions briefly. Please\nshow your calculations and provide rough explanations where you can't give formal state-\nments so I can give you partial credit.\n(a) Give a formal definition as you can of what it means for a multistage game with\nobserved actions to be continuous at infinity?\nGive an example of a game that is not\ncontinuous at infinity.\n(b) Give as formal a definition as you can of what it means for a property to hold\ngenerically.\nWhat theorems that we saw in class were about properties that only hold\ngenerically.\n(c) In class I defined payofffunctions differently when definining finite extensive form\ngames and infinite horizon multistage games with observed actions. How did the domains\nof the payofffunctions differ and why did I make the change?\n(d) Give a formal definition of a strategy in an extensive form game.\n(e) Give an example of a game in which an outcome which does not seem reasonable is\npossible in a subgame perfect equilibrium.\n(f) How many pure strategies does player 1 have in the extensive form game shown\nbelow. Write out the normal form payoffmatrix. How many subgames does the game\nhave?\n(g) Find all of the Nash equilibria of the following game.\n(h) Find the subgame perfect equilibrium of a two stage game where player 1 chooses\n\na at cost a/16 and players 1 and 2 then play the simultaneous move game shown below.\n(i) Find the Nash equilibrium of the simultaneous move game where player 1 chooses\na1 ∈R, player 2 chooses a2 ∈R, and the payoffs are\nu1(a1, a2) = (3 -a2)a1 -a1\nand\nu2(a1, a2) = (4 -a1)a2 -a2.\n-I-\n-I-\n\n2. (30 Minutes - 18 Points)\nConsider the following game about trust that has been played in many experiments.\nThe experimenter starts by giving player 1 ten dollars and player 2 zero dollars.\nThe\nexperimenter then asks player 1 how many dollars he is willing to give back to help player\n2. If he chooses to give x dollars back to the experimenter, then the experimenter gives\nplayer 2 3x dollars. Subsequently, player 2 has the opportunity to give any or all (or none)\nof the money he has received to player 1.\n(a) Assuming that the two players are risk neutral and care only about their own payoff\nfind the subgame perfect equilibrium of this game. (The subgame perfect equilibrium, by\nthe way, is not what seems to happen in experiments. Usually player 1 gives some, but not\nall of the money back to the experimenter.)\n(b) Does the game have a Nash equilibrium in which the players receive higher payoffs?\n(c) Suppose we modified the game so that after the two stages above player 1 had the\nchance to punch player 2. Suppose that this would reduce player 1's utility by 1 dollar\nand reduce player 2's utility by 5 dollars. Would this change your answers to parts (a) and\n(b)? How about if we instead had the players play the game shown below after the second\nstage? Do these predictions seem reasonable to you.\n(d*) An alternate explanation for the experimental results is that the players may be\naltruistic. Show that the simplest representation of altruism -- each player maximizing\na weighted sum of his own dollar payoffand the other player's dollar payoff-- can not\naccount for the experimental regularity except for one very special (and not compelling)\nchoice of the weights. Can you think of utility functions that might be used to account for\nthe experimental result?\nA\n\n3. (60 Minutes - 28 Points)\nTwo drivers are side-by-side in adjacent lanes on the highway. The two lanes are con-\ntinually narrowing and the two cars getting closer and closer together as they approach a\nconstruction site. If neither driver slows down and merges in behind the other they will\ncrash at some point within the next minute.\n(a) To model this situation as a simple normal form game, suppose each player simul-\ntaneously chooses the time ti ∈[0, 1] at which he or she will slow down if the other driver\nhas not yet done so. Assume that each player i gets a payoffof -1 if the cars crash, 0 if\nthey do not crash and player i ends up behind the other player, and 1 if they do not crash\nand player i ends up in front of the other player.\nAssume that the probability that the cars crash is min(t1, t2), i.e. it is as if the time at\nwhich a crash occurs would be uniform on [0, 1] if neither car ever slows down. (Note for\na crash to occur with probability one as it does in this specification the hazard rate at t\n(the likelihood of a crash occurring between t and t+dt conditional on there being no crash\nbefore t) must go to infinity as t approaches 1. Here the hazard rate is 1/(1 -t) as long as\nboth cars haven't yet slowed down and zero if one car has slowed down.)\nShow that the game has an infinite number of asymmetric pure strategy Nash equilibria.\nIf you can, show that there are no other pure strategy Nash equilibria.\n(b*) Find a symmetric mixed strategy Nash equilibrium in which the players mix on\nsome interval [0, t].\n(c) Consider an incomplete information version of this game. To simplify things, assume\nthat there are only two times at which drivers can slow down. Each driver i must pick either\nti = 0 or ti = 1\n2. Assume that driver i gets a payoffof θi if there is a crash, 0 if there is\nno crash and driver i slows down before or at the same time as the other driver, and 1 if\nthere is no crash and driver i slows down second (which can only happen here if ti = 1\n2 and\n-i = 0.) Consistent with the previous formulation assume that the probability of a crash\nis 0 if at least one driver slows down at t = 0 and\nt\nif both drivers slow down at t =\n.\nSuppose that θi is known only to player i. Suppose that θ1 and θ2 are independent.\nSuppose that θ1 is equal to -0.5 with probability 1\n3 and equal to -2 with probability 2.\nSuppose that θ2 equals -3 with probability 2\n5 and that with probability 3\n5 player 2 actually\nlikes crashing more than slowing down and has θ2 = 0.2.\nFind the Bayesian Nash Equilibrium of this game.\n\n4. (35 Minutes - 18 Points)\nConsider the following game. There are two players. Player 1 is Mike Tyson. Player 2 is\nanother heavyweight boxer, e.g. Buster Douglas. For the purposes of this question assume\nthat Mike Tyson is good enough to defeat and perhaps seriously injure Buster Douglas if he\ntrains hard and shows up for a fight in good shape. He is not good enough to beat Buster\nDouglas if he shows up fat and out of shape. Whether Mike Tyson trains hard is not a\nstrategic choice that he makes. It depends entirely on his state of mind between the time\nthe contract is signed and the time of the fight and this is beyond everyone's control.\nSuppose (and here the question gets less realistic) that might Tyson is very aware of the\ncurrent state of his psychological problems and the temptations he will face during training.\nSpecifically, suppose that when the contract for the fight is about to be signed Mike Tyson\nalready knows whether he will train hard. Buster Douglas does not. Douglas' prior is that\nthe probability that Mike Tyson will train hard is 2\n3.\nSuppose that just before the contract is signed, Lenox Lewis shows up at the press\nconference and offers Buster Douglas $1 million dollars if he gives up his right to fight Mike\nTyson (so that Tyson will surely be the champion when he later fights Lenox Lewis.) Mike\nTyson then has the opportunity to make one of two speeches to Buster Douglas \"you should\ntake his money because I'm going to train hard and whip your ...\" or \"I will show up fat\nand out of shape so you'd be better offnot taking the money, beating me in this fight, and\ngetting $10 million for a later rematch.\" Buster Douglas then has to decide whether to\naccept Lewis's offer and not fight Tyson or to decline the offer and fight Tyson.\nAssume that if Douglas accepts, the payoffs are 0 utils for Tyson and 1 for Douglas.\nAssume that if Douglas declines Lewis's offer and fights Tyson the payoffs will be 2 utils\nfor Tyson and -2 for Douglas if Tyson trains hard and -2 utils for Tyson and 10 utils for\nDouglas if Tyson doesn't train hard.\n(a) Describe formally how you would represent this situation as a dynamic game of in-\ncomplete information between Mike Tyson and Buster Douglas. (Nature would be included\nalso in the game tree, but don't include Lenox Lewis). Be clear what the type spaces are\nand draw a game tree.\n(b) Show that there is no separating equilibrium where Mike Tyson truthfully makes\nthe first speech if and only if he will train hard.\n(c) Is there a pooling equilibrium where Mike Tyson claims that he will train hard\nregardless of whether this is true?\n(d*) Try to descibe completely the set of semiseparating equilibria of the model. Are\nthe semiseparating equilibria here like either of the semiseparating equilibria I discussed in\nclass?"
    }
  ]
}