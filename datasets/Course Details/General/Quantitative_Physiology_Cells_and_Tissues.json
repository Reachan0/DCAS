{
  "course_name": "Quantitative Physiology: Cells and Tissues",
  "course_description": "In this subject, we consider two basic topics in cellular biophysics, posed here as questions:\n\nWhich molecules are transported across cellular membranes, and what are the mechanisms of transport? How do cells maintain their compositions, volume, and membrane potential?\nHow are potentials generated across the membranes of cells? What do these potentials do?\n\nAlthough the questions posed are fundamentally biological questions, the methods for answering these questions are inherently multidisciplinary. As we will see throughout the course, the role of mathematical models is to express concepts precisely enough that precise conclusions can be drawn. In connection with all the topics covered, we will consider both theory and experiment. For the student, the educational value of examining the interplay between theory and experiment transcends the value of the specific knowledge gained in the subject matter.\nThis course is jointly offered through four departments, available to both undergraduates and graduates.",
  "topics": [
    "Health and Medicine",
    "Anatomy and Physiology",
    "Science",
    "Biology",
    "Biophysics",
    "Cell Biology",
    "Molecular Biology",
    "Health and Medicine",
    "Anatomy and Physiology",
    "Science",
    "Biology",
    "Biophysics",
    "Cell Biology",
    "Molecular Biology"
  ],
  "syllabus_content": "\"In scientific thought we adopt the simplest theory which will explain all the facts under consideration and enable us to predict new facts of the same kind. The catch in this criterion lies in the word 'simplest'. It is really an aesthetic canon such as we find implicit in our criticisms of poetry or painting. The layman finds such a law as\nless simple than 'it oozes', of which it is the mathematical statement. The physicist reverses this judgment, and his statement is certainly the more fruitful of the two, so far as prediction is concerned.\"\n\n- Haldane, 1985\n\nCourse Meeting Times\n\nLectures: 3 sessions / week, 1 hour / session\n\nRecitations: 2 sessions / week, 1 hour / session\n\nSubject Contents\n\nIn this subject, we consider two basic topics in cellular biophysics, posed here as questions:\n\nWhich molecules are transported across cellular membranes, and what are the mechanisms of transport? How do cells maintain their compositions, volume, and membrane potential?\n\nHow are potentials generated across the membranes of cells? What do these potentials do?\n\nAlthough the questions posed are fundamentally biological questions, the methods for answering these questions are inherently multidisciplinary. For example, to understand the mechanism of transport of molecules across cellular membranes, it is essential to understand both the structure of membranes and the principles of mass transport through membranes. Since the transported matter may combine chemically with membrane-spanning macromolecules and/or carry an electrical charge, it is essential to understand the principles of chemical kinetics and of transport of charged molecules in an electric field.\n\nKnowledge of transport through membranes is based on measurements. These measurements lead to physically and chemically based mathematical models that are used to test concepts based on measurements. The role of mathematical models is to express concepts precisely enough that precise conclusions can be drawn (see quote by Haldane, above). In connection with all the topics covered, we will consider both theory and experiment. For the student, the educational value of examining the interplay between theory and experiment transcends the value of the specific knowledge gained in the subject matter.\n\nTeaching Methods\n\nSeveral kinds of activities are provided to help the learning process.\n\nThree lectures each week to introduce new material.\n\nTwo recitations each week to review material, solve problems, and answer questions.\n\nTwo projects - one experimental and the other theoretical - to help students learn to pose testable hypotheses, to conduct research, and to communicate results.\n\nWeekly homework assignments to encourage students to\nactively\nassimilate the course material.\n\nTwo evening examinations and one final examination to provide an occasion to integrate the subject material and to obtain an objective evaluation of the student's understanding of the material.\n\nHomework\n\nWeekly homework assignments provide an opportunity to develop intuition for new concepts by actively applying the new concepts to solve problems and answer questions. The process of actively struggling with the use of new ideas until you understand them is an effective and rewarding form of education.\n\nWeekly homework assignments will typically be due exactly one week after being issued, in recitation.\nLate homework will not be accepted\n. Homework assignments will be corrected, graded, and returned the week after they are due. Solutions to the homework will be distributed with the corrected homework.\n\nHomework problems will be chosen for their educational value. Some of our best problems were assigned in previous years, and it is a relatively easy matter to acquire solutions.\nIf you skip the process of personally struggling with the use of new concepts, you will have destroyed your most important educational experience\n. Reading someone's solution to a problem is not educationally equivalent to generating your own solution. We encourage students to work together to understand the concepts in the homework. However, each student should work out his/her own solutions. Submitted homework should reflect the knowledge of the individual. If you work with other students (living students or the written testaments of previous students), please include their names on your homework sets.\n\nIt is generally tempting to postpone working on homework until the night before it is due. This is a poor plan because it limits your ability to interact with fellow students and the teaching staff.\n\nExaminations\n\nTwo evening examinations will be given: one between lectures 13 and 14; and one between lectures 24 and 25. Students will have two hours to complete the exam, which will be designed as a one-hour exam. These exams are closed-book: notes on both sides of one 8 1/2 × 11 sheet of paper may be used for reference in the first examination, and notes on both sides of two 8 1/2 × 11 sheets of paper may be used for reference in the second examination.\n\nA three-hour final examination, given during the Final Examination Period, will cover all the material in the subject, but will be weighted more heavily on material not covered in the examinations given during the term. The final examination is closed-book; notes on both sides of three 8 1/2 × 11 sheets of paper may be used for reference.\n\nComputer-Aided Exercises\n\nSix software packages will be used:\n\nThe random-walk model of diffusion,\n\nMacroscopic diffusion processes,\n\nChemically-mediated transport across membranes,\n\nThe Hodgkin-Huxley space-clamped model for neural membranes,\n\nThe Hodgkin-Huxley propagated action potential model, and\n\nVoltage-gated ion channels in membranes.\n\nThese software packages will be used in lectures, recitations, and homework. No knowledge of computers is required to perform these exercises.\n\nThis term we will use versions of each software package based on MATLAB(r). Documentation is available online, and can be found in the\ntools\nsection.\n\nProjects\n\nThis subject includes two projects. The first is a laboratory project on microfluidics. It provides an opportunity to study molecular transport and diffusion. In the second project, a software representation of the Hodgkin-Huxley model for a neural membrane will be used to introduce students to the use of computer simulation to understand the behavior of complex systems.\n\nThe projects provide an opportunity to learn about:\n\nPlanning experiments,\n\nAcquiring, processing, and interpreting data, and\n\nCommunicating the results to others.\n\nBoth projects require a written proposal, which includes a well-defined hypothesis and procedures to test the hypothesis. For the laboratory project, you will use equipment in an MIT laboratory. You will have to schedule a 2-hour session to complete an introductory pre-lab exercise. You can then schedule additional time at your convenience to complete your project (typically 3-4 hours total). The theoretical project is done on a computer.\n\nStudents are encouraged to work in pairs for both projects. Partners are encouraged to submit a joint proposal, to cooperate in processing data, in discussing interpretations, and in preparing their reports. Partners are also encouraged to submit a joint report. We strongly believe that students learn more by working with other students than by working in isolation.\n\nThe report for the first project is written. It should be approximately 10 pages long and structured as a scientific paper. The report for the second project is oral. It should be 12 minutes in length and should be delivered during the next to last week of the semester.\n\nThe reports for both projects have\nfirm due dates\n, which are listed in the\ncalendar\nsection.\nThere is a severe lateness penalty:\nthe grade for a late report will be multiplied by a lateness factor\n\nL\n= 0:3_e_\n-t\n/4\n+ 0.7_e_\n-t\n/72\n\nwhere\nt\nis the number of hours late.\n\nCommunications Intensive: Crafting Technical Presentations\n\nThis subject is communications intensive. We feel that communications skills are essential for professional engineers and scientists. We also feel that the process of creating written manuscripts and oral presentations can help clarify thinking and can be an effective way to\nlearn technical material\n.\n\nHomework assignments and examinations will often ask you to explain something or to define something that you have been taught. In addition, each of the projects is communications intensive. For each project, you and your partner must submit a written proposal and revise the proposal until it is approved by the staff. For each project, you and your partner must prepare a formal report that is structured as a scientific paper or an oral presentation. First drafts of each report are due approximately one week before the final drafts, and will be reviewed by the technical staff, staff from the MIT Writing Program, and by student peers. You and your partner will be assigned to prepare a written critique of a first draft from a different team. The critiques will be discussed during a special recitation session held between the first draft and final draft deadlines.\n\nEECS students can satisfy their junior year communications requirement in their major (CI-M) by taking this subject. Phase 2 credit can also be awarded by the Writing Program to students who receive a B or higher grade for their participation in the writing clinic and for communication skills demonstrated in this subject.\n\nStudent-Staff Responsibilities\n\nYou, the student, have a right to expect the staff to be prepared and responsive and punctual. While we cannot always deliver entertaining and incisive lectures and recitations, you have a right to expect us to act professionally. The staff will be available for consultation at mutually agreeable times. We expect to return all graded problem sets and exams within one week of submission and all experimental project reports within three weeks of submission. The theoretical project report will be returned at the end of the semester.\n\nWe also have expectations for you. We expect you to do the work and to submit your work on time! Furthermore, we expect that the work you submit to us under your name is\nyour\nwork. Interaction of students on the concepts involved in the homework assignments is often helpful and is encouraged, but each student should work out his/her own solutions. Submitted homework should reflect the knowledge of the individual. If you do work with other students, please include their names on your problem sets. Submission of problem sets that are copies of solutions previously distributed in this subject is immature, dishonest, a waste of everyone's time, and a discredit to the perpetrator. In general, submission of work that is not your own - in the form of solutions to homework assignments, laboratory reports, proposals, or reports - constitutes\nplagiarism\nand is as serious an offense as is cheating on examinations.\n\nGrade\n\nBecause of the variety of work in this subject, grades do not depend heavily on performance on any single assignment or examination. The letter grade for the subject will be determined from a weighted sum of letter grades for the homework assignments, projects, and examinations.\n\nThe weighting factors are:\n\nActivities\n\nPercentages\n\nHomework\n\n5%\n\nExam I\n\n15%\n\nExam II\n\n20%\n\nLab Project\n\n15%\n\nHH Project\n\n15%\n\nFinal Exam\n\n30%\n\nFor students near grade boundaries, other factors may be taken into account, including participation in class, laboratory performance not evidenced in the laboratory grade, etc. The grades are determined by the staff. Students registered for undergraduate and graduate versions of this subject will be graded separately.\n\nTexts\n\nThe course text has two volumes:\n\nWeiss, Thomas F.\nCellular Biophysics: Transport\n. Vol. 1. Cambridge, MA: MIT Press, 1996. ISBN: 9780262231831.\n\n------.\nCellular Biophysics: Electrical Properties\n. Vol. 2. Cambridge, MA: MIT Press, 1996. ISBN: 9780262231848.\n\nFor the portion of the subject that deals with electrical properties of cells, supplementary reading is available in the following texts:\n\nVander, Arthur J., James H. Sherman, and Dorothy S. Luciano.\nHuman Physiology, The Mechanisms Body Function\n. New York, NY: McGraw-Hill, 1998. ISBN: 9780070670655.\n\nAidley, David J.\nThe Physiology of Excitable Cells\n. 4th ed. Cambridge, UK: Cambridge University Press, 1998. ISBN: 9780521574211.\n\nKandel, Eric R., James H. Schwartz, and Thomas M. Jessell.\nPrinciples of Neural Science\n. New York, NY: Elsevier, 1991. ISBN: 9780444015624.",
  "files": [
    {
      "category": "Resource",
      "title": "hw1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/f46dd65cf1554fe0b930bb449f8a3fd3_hw1.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #1\nIssued: September 8, 2004\nDue: September 16, 2004\nReading\nLecture 2 -- Volume 1: 3.1-3.1.3 3.2-3.2.2\nLecture 3 -- Volume 1: 3.1.4-3.1.5 3.5-3.5.2.1\nLecture 4 -- Volume 1: 3.6-3.6.1.2 3.7-3.7.2\nAnnouncements\nHomework will consist of Exercises and Problems. Exercises are generally more conceptual and\nrequire less number crunching. Exercises often require writing sentences to explain what you have\nlearned. Written solutions should be submitted for both Exercises and Problems.\nExercise 1. According to the random walk model, solute molecules move and thereby diffuse be\ncause of collisions with water molecules. Solute collisions with other solute molecules are gener\nally ignored under the assumption that the water molecules vastly outnumber the solute molecules.\nTo get a feeling for the validity of this assumption, and to appreciate the number of particles and\nspatial scales involved, consider the diffusion of potassium ions in the cytoplasm of a red blood\ncell. Assume that the volume of the cell is 90 fL, and that the concentration of potassium ions in\nthe cytoplasm is 150 mmol/L.\nPart a. Estimate the number of potassium ions in the cytoplasm of the cell.\nPart b. Estimate the average distance between potassium ions in the cell.\nPart c. Estimate the number of water molecules in the cytoplasm of the cell.\nPart d. Estimate the average distance between water molecules in cytoplasm.\nPart e. Determine the ratio of water molecules to potassium ions in cytoplasm.\nExercise 2. At a junction between two neurons, called a synapse, there is a 20 nm cleft that\nseparates the cell membranes. A chemical transmitter substance is released by one cell (the pre\nsynaptic cell), diffuses across the cleft, and arrives at the membrane of the other (post-synaptic)\ncell. Assume that the diffusion coefficient of the chemical transmitter substance is D = 5 ×\n10-6 cm2/s. Make a rough estimate of the delay caused by diffusion of the transmitter substance\nacross the cleft. What are the limitations of this estimate? Explain.\n\nExercise 3. The time course of one-dimensional diffusion of a solute from a point source in space\nand time has the form\ncn(x, t) =\nno\n√\n4πDt e-x2/4Dt,\nwhere no is the number of moles of solute per unit area placed at x = 0 at t = 0. cn(x, t) is\ncomputed as a function of time for locations xa and xb, and shown in the following figure.\nt\n\nxa\nxb\ncn(x, t)\nIs xa > xb or is xa < xb? Explain.\nProblem 1. A general solution to a first-order linear differential equation with constant coefficients\ncan be written as\nn(t) = ninf+ (n0 -ninf)e-t/τ.\na) Determine the slope m0 = dn/dt at t = 0 in terms of the constants ninf, n0 and τ.\nb) If this slope were extended for t > 0 (i.e., if n∗(t) = n0 + m0t), for what value of t will\nn∗(t) = ninf?\nc) Plot n(t) and n∗(t) when n0 = -10, ninf= 10, and τ = 1.\nProblem 2. Four solutions to the differential equation\ndx(t)\ndt\n+ Ax(t) + B = 0\nare shown in the following plot.\n-3\nPart a. Find values of A and B that are consistent with curve a. Are these values unique? If not,\nfind a second set of constants that are consistent.\nPart b. Repeat part a for curve b. Compare these results to those of part a. Explain similarities and\ndifferences.\nPart c. Repeat part a for curve c. Compare these results to those of parts a and b. Explain\nsimilarities and differences.\nPart d. Repeat part a for curve d. Determine all possible values of A and B for this case.\n\nProblem 3. Assume that no mol/cm2 of sucrose (with a diffusion constant D 0.5 × 10-5 cm2/s)\nare placed in a trough of water at a point x = 0 at time t = 0. Assume that the concentration of\nsucrose is a function of x and t only.\na) Show that for any fixed point xp the maximum concentration occurs at time tm = xp/2D.\nb) How long does it take for the concentration to reach a maximum at x = ±1 cm?\nProblem 4. The following figure illustrates a cascaded system of two water tanks. Water flows out\nof the first tank and into the second at a rate r1(t), and out of the second tank at a rate r2(t).\nh1\nr1\nh2\nr2\n(t)\n(t)\n(t)\n(t)\nThe rates of flow out of the tanks are proportional to the heights of the water in the tanks: r1(t) =\nk1h1(t) and r2(t) = k2h2(t), where k1 and k2 are each 0.02 m2/minute. The height of tank 1 is 1 m\nand that of tank 2 is 2 m. The cross-sectional area of tank 1 is A1 = 4 m2 and that of the second\ntank is A2 = 2 m2. At time t = 0, tank 1 is full and tank 2 is empty.\na. If the height of water in tank 2 ever exceeds the height of the tank (2 m), the water will\noverflow. Will the water ever overflow? Explain.\nb. Set up a system of differential equations to determine h2(t). Solve the equations to determine\nan expression for h2(t).\nc. At what time does the water in tank 2 reach its peak? What will be the maximum height of\nwater ever achieved in tank 2?\nd. At what time will the water stop flowing out of tank 1? Explain your answer in mathematical\nterms and then in physical terms.\ne. If both tanks were full at t = 0, would the second tank ever overflow? Explain.\n\nProblem 5. Transport by diffusion tends to move solutes from regions of high concentration to\nregions of low concentration, thereby making the spatial distribution of solute more uniform. Thus\ndiffusion is often associated with mixing. However, diffusion can also be used to separate solutes in\na mixture. Such separation is important as a mechanism to purify mixtures of biological materials\n(such as mixtures of DNA fragments) and is currently being exploited in microfabricated systems\nfor biological and medical analysis (which we will look at in greater detail in the Microfluidics\nLaboratory Project).\nAssume that a mixture of two molecular species is loaded into a long and narrow channel filled\nwith water. Let x represent distance in the the longitudinal direction and assume that n0 molecules\nof solute A and n0 molecules of solute B are loaded into location x = 0 at time t = 0. Assume that\nsolutes A and B have different molecular weights and that their diffusivities are DA = 10-7 cm2/s\nand DB = 4 × 10-7 cm2/s, respectively. The following figure illustrates how the two species tend\nto separate as they diffuse.\nx (μ\ni\n-10\nm)\nConcentrat ons\nof A and B\nPart a. As time elapses, the number of molecules of solute A that remain in a test region within\nthe 10μm of the starting position (i.e., -10μm< x < 10μm) decreases. Determine the amount of\ntime t0 required to get 5% of solute A to leave the test region.\nPart b. At time t = t0 found in part a, determine the amount of solute B in the test region.\nPart c. Determine the ratio of solute A to solute B in the test region at time t = t0. Explain how\ndiffusion has lead to a separation of solute A from solute B."
    },
    {
      "category": "Resource",
      "title": "hw2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/19081b33c5d8a2dec15f7eb1310b8a9d_hw2.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #2\nIssued: September 16, 2004\nDue: September 23, 2004\nReading\nLecture 5 -- Volume 1: 3.8-3.8.5\nLecture 6 -- Volume 1: 4.1-4.3.2.3 4.4-4.5.1.2\nLecture 7 -- Volume 1: 4.7-4.7.1.2\nLecture 8 -- Volume 1: 4.7.2-p.230 Fig.4.26 Fig.4.28 4.8.2-4.8.3\nExercise 1. Describe the dissolve-diffuse theory for diffusion through cellular membranes.\nExercise 2. Two time constants are involved in two-compartment diffusion through a membrane:\nthe steady-state time constant of the membrane (ss) and the equilibrium time constant for the two\ncompartments (eq ). Without the use of equations, describe these two time constants.\nExercise 3. A solute n diffuses through a membrane that separates two compartments that have\ndifferent initial concentrations. The concentrations in the two compartments as a function of time,\na\nb\ncn(t) and cn(t), are shown in the following figure.\nt\nc a\nn(t)\nc b\nn(t)\nThe volumes of the two compartments are Va and Vb. Is Va > Vb or is Va < Vb? Explain.\nExercise 4. Define osmolarity.\nExercise 5. The following three formulas for the sugar (trisaccharide) raffinose (found in sugar\nbeets) were proposed:\nC\nC\nC12H28O14,\n18H42O21,\n36H84O42.\nDe Vries (1888) used a plant cell to determine that plasmolysis occurred with a solution containing\n59.4 grams of raffinose per liter of water whereas plasmolysis occurred in a solution of sucrose at a\n\nconcentration of 0.1 mol/L. Based on these measurements, de Vries determined the correct formula\nfor raffinose. Which formula would you choose and why would you choose it?\nProblem 1. Consider diffusion through a thin membrane that separates two otherwise closed com\npartments. As illustrated in Figure 1, the membrane and both compartments have cross sectional\nareas A = 1 cm2 . Compartment 1 has length L1 = 50 cm, compartment 2 has length L2 = 10\nc(\n)\nc1(t)\nc2(t)\nW\n-4 cm\nL1\nx, t\nArea = 1 cm\n= 10\n= 50 cm\nL2 = 10 cm\nFigure 1: Two compartments separated by a membrane.\ncm, and the membrane thickness is W = 10-4 cm. Assume that (1) the compartments contain\nsugar solutions and that both compartments are well stirred so that the concentration of sugar in\ncompartment 1 can be written as c1(t) and that in compartment 2 can be written as c2(t); (2) the\nconcentration of sugar in the membrane can be written as c(x, t), where x represents distance\nthrough the membrane; (3) the diffusivity of sugar in the membrane is Dsugar = 10-5 cm2/s and\nthe membrane:water partition coefficient km:w is 1; (4) the concentration of sugar in the membrane\nhas reached steady state at time t = 0 and that c1(0) = 1 mol/L and c2(0) = 0 mol/L.\na) Compute the flux of sugar through the membrane at time t = 0, s(0).\nb) Compute the final value of concentration of sugar in compartment 1, c1(1).\nc) Let eq characterize the amount of time required to reach equilibrium. What would happen\nto eq if the diffusivity of sugar in the membrane were doubled? Explain your reasoning.\n\nProblem 2. A thin membrane and a thick membrane, that are otherwise identical, are used to\nseparate identical solutions of volume V = 1 cm3 (Figure 2). All the membrane surfaces facing\nthe solutions have area A = 1 cm2 . The thin membrane has thickness ds = 10-4 cm; the thick\nmembrane has thickness dl = 1 cm. For t < 0 the aqueous solutions on both sides of the membrane\nare identical and do not contain solute n. At t = 0 a small concentration of solute n is added to\nthe solution on side 1 of the membrane. You may assume that there is no water flow across the\nmembrane. The diffusion coefficient and membrane:solution partition coefficient of n in both\nmembranes are Dn = 10-5 cm2/s and kn = 2, respectively.\nThin membrane\nThick membrane\nds\ndl\nV\nc 1\nn\nV\nAn\nc 2\nn\nV\nc 1\nn\nV\nAn\nc 2\nn\nSurface area A\nFigure 2: Schematic diagrams of thin and thick membranes.\na) For each membrane, estimate the time ss that it takes for the concentration profile in the\nmembrane to reach its steady-state spatial distribution.\nb) For each membrane, find the time eq that it takes for the solutions on the two sides of\nthe membrane to come to equilibrium assuming that the spatial distribution of solute in the\nmembrane is the steady-state distribution.\nc) Is it reasonable to assume that Fick's Law for membranes applies for the thin membrane at\neach instant in time, i.e., does\nn(t) = Ps(c n(t) - c n(t)) ?\nwhere Ps is the permeability of the thin membrane.\nd) Is it reasonable to assume that Fick's Law for membranes applies for the thick membrane at\neach instant in time, i.e., does\nn(t) = Pl(cn(t) - cn(t)) ?\nwhere Pl is the permeability of the thick membrane.\n\nProblem 3. Glucose is dripped at a constant rate R = 2μmol/s into a bath that contains 1012\nidentical red blood cells, as shown in the following figure.\nAssume that each red blood cell has a volume\n=\nμ\n25 (\nVC\nm)3 and a surface area AC = 80 (μm)2 ,\nand that neither of these changes over the time interval considered in this problem. Assume that\nthe volume of the bath is 1 L, and that the bath is well stirred. (You may assume that the amount\nof water dripped into the bath is negligibly small.) The concentration of glucose in the bath, cb(t),\nif found to increase as a function of time t, as shown in the following plot.\ncb(t) (mmol/L)\nt (s)\nPart a. Is the following logic True or False?\nThe flux of glucose through each of the cell membranes cannot be constant over the\ntime 0 < t < 900 s, because if it were, the concentration cb(t) would be a linear\nfunction of time.\nIf the truthfulness of this statement cannot be determined from the information provided, describe\nwhat additional information is needed.\nPart b. Determine the flux of glucose through the membrane of each cell at time t = 900 s.\nUse our normal convention that outward flux (i.e., flux leaving the cell) is positive and inward\nflux is negative. Determine the numerical value (or numerical expression) and units. If you\ncannot determine the numerical value from the information provided, describe what additional\ninformation is needed.\nPart c. Determine the flux of glucose through the membrane of each cell at time t = 0 s. Use\nour normal convention that outward flux (i.e., flux leaving the cell) is positive and inward flux\nis negative. Determine the numerical value (or numerical expression) and units. If you cannot\ndetermine the numerical value from the information provided, describe what additional information\nis needed.\n\nProblem 4. All cells are surrounded by a cell membrane. The cytoplasm of most cells contains a\nvariety of organelles that are also enclosed within membranes. Assume that a spherical cell with\nradius R = 50μm contains a spherical organelle called a vesicle, with radius r = 1μm, as shown\nin the following figure.\ni\nl\nicl\ni\nμm\ni\nl\nll\ni\nμm\nspher ca ves\ne\nrad us r = 1\nspher ca ce\nrad us R = 50\nbath\nAssume that the membranes surrounding the cell and vesicle are uniform lipid bilayers with iden\ntical compositions and the same thickness d = 10 nm. Assume that solute X is transported across\nboth the cell and vesicle membrane via the dissolve and diffuse mechanism. Assume that X dis\nsolves equally well in the bath and in the aqueous interiors of the vesicle and cell. Assume that\nthe solute X dissolves 100 times less readily in the membrane (i.e., the partitioning coefficient is\n0.01). Assume the diffusivity of X in the membranes is 10-7cm2/s.\nInitially, the concentration of X is zero inside the cell and inside the vesicle. At time t = 0, the\ncell is plunged into a bath that contains X with concentration 1 mmol/L.\na) Estimate the time that is required for the concentration of X in the cell to reach 0.5 mmol/L.\nFind a numerical value or explain why it is not possible to obtain a numerical value with the\ninformation that is given.\nb) Estimate the time that is required for the concentration of X in the vesicle to reach\n0.5 mmol/L. Find a numerical value or explain why it is not possible to obtain a numeri\ncal value with the information that is given.\n\nProblem 5. As your first assignment at Tinyfluidics Inc., you are asked to design a microfluidic\ndevice that will remove small molecules from a sample of fluid that contains both large molecules\nand small molecules. After some thinking, you design the laminar flow device shown below.\nL\nW\nin\nin\nle in\nfil\nd\nδ\nbuffer\nbuffer\nsamp\nwaste out\nwaste out\ntrate out\nThe sample is injected in a port with width . The sample flow is surrounded by buffers injected\non both sides of the sample. The combined flow then passes through a channel that has width W\nand length L after which the fluids are separated into a desired filtrate output (in a channel of width\nd) and two waste outputs. Assume that the fluid moves with the same speed v in all parts of the\nmicrofluidic device (although this is not generally true, it is a convenient starting point). Assume\nthat << d, and that W is sufficiently large that it can be taken to be infinity.\nTo test the device, you mix a solution that contains equal concentrations of 2 proteins, A and B.\nThe diffusivity of solute B is four times that of solute A.\nPart a. Briefly explain how this device takes advantage of differences in diffusivities to achieve\nseparation.\nPart b. Let fA represent the ratio of the amount of solute A found in the filtrate divided by the\namount of solute A in the sample. Determine an expression for fA. Determine an expression for\nthe analogous ratio fB for solute B.\nThe following figure shows a plot of the dependence of fA and fB on L, when = 1μm, d = 20μm,\nv = 1 mm/s, and DA = 10-7 cm2/s.\n\nf A\nf B\n0.5\nand\n\nL (mm)\nPart c. Which curve (dashed or solid) represents fA? Explain.\nPart d. Determine L0, the value of L that maximizes the difference between fA and fB . Briefly\nexplain why this difference is smaller when L << L0 and when L >> L0."
    },
    {
      "category": "Resource",
      "title": "hw3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/60f50d1fd6eac140617966c1563272b8_hw3.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #3\nIssued: September 23, 2004\nDue: September 30, 2004\nReading\nLecture 8 -- Volume 1: 6.1-6.2.1.4\nLecture 9 -- Volume 1: 6.4-6.4.1.4\nLecture 10 -- Volume 1: 6.4.2-6.4.3 6.6-6.7.4\nLecture 11 -- Volume 1: 7.2.1 7.2.3 7.2.4.1 7.4\nAnnouncements\nExam 1 will be held on Thursday, October 7, 2004 from 7:30 PM to 9:30 PM\nThe exam is closed-book: notes on both sides of one 8 1 × 11 sheet of paper\nmay be used for reference. Calculators may be used, but computers and wireless\ndevices may not be used.\nThere will be no recitations on the day of the exam.\nExercise 1. It is known that the membrane of a certain type of cell is highly permeable to water,\nbut relatively impermeable to L-glucose, sodium ions, and chloride ions. When the cell is removed\nfrom interstitial fluids and placed in a 150 mmol/L NaCl solution, the cell neither shrinks nor\nswells.\na) Would the cell shrink, swell, or remain at constant volume if placed in 150 mmol/L solution\nof L-glucose? Explain.\nb) Would the cell shrink, swell, or remain at constant volume if placed in a 300 mmol/L solution\nof L-glucose? Explain.\nExercise 2. If Equation 4.68 in volume 1 of the text is multiplied by A(t), the result can be written\nas\ndVi(t)\n-\n= A(t)LV RT\n(t) - Ci\nCo\n(t) .\ndt\nUsing no mathematical formulas or equations, describe the meaning of of this equation in a few\nwell chosen English sentences.\n\nExercise 3. The following figure shows schematic diagrams of two cells that have the same volume\nbut quite different shapes.\nOne cell (left panel) is spherical, the other is approximately cylindrical but contains a large number\nof microvilli. The cell membranes have the same hydraulic conductivity to water. If the two cells\nare subjected to the same decrease in extracellular osmolarity, which cell swells more rapidly?\nExplain.\nExercise 4. Consider the simple, symmetric, four-state carrier model. For each of the following\nE, NES\ni , No\nconditions, find NE\ni , No\nES, and S. Explain the physical significance of each of your\nanswers.\na) = 0.\nb) φ = 0.\nc) K = 0.\ni\no\nExercise 5. Consider the simple, symmetric, four-state carrier model when c\n= cS = 0. Sketch\nS\nthe carrier density in each of its four states as a function of /φ. Give a physical interpretation of\nyour results.\n\nProblem 1. A volume element with constant cross-sectional area A has rigid walls and is divided\ninto two parts by a rigid, semipermeable membrane that is mounted on frictionless bearings so that\nthe membrane is free to move in the x-direction as shown in the following figure.\nc1\nc2\nx\n10 (cm)\nThe semipermeable membrane is permeable to water but not to the solutes (glucose or NaCl or\nCaCl2). At t = 0, solute 1 is added to side 1 to give an initial concentration of c1(0) and solute\n2 is added to side 2 to give an initial concentration of c2(0). Concentrations are specified as the\nnumber of millimoles of glucose or NaCl or CaCl2 per liter of solution. The initial position of\nthe membrane is x(0). For each of the following parts, find the final (equilibrium) values of the\nmembrane position x(1), and the concentrations, c1(1) and c2(1).\n(a.) cglucose(0) = 0; cglucose(0) = 10; x(0) = 5.\nc\n(b.)\nglucose(0) = 30; cglucose(0) = 70; x(0) = 7.\n(c.) cglucose(0) = 20; cglucose(0) = 10; x(0) = 3.\n(d.) cglucose(0) = 30; cN aCl(0) = 20; x(0) = 4.\n(e.)\n(0) = 20; cN aCl (0) = 30; x(0) = 3.\ncCaCl2\nProblem 2. A spherical cell has a freely distensible membrane that is permeable to solute A, im\npermeant to solute B, and permeable to water. The cell contains NI moles of impermeant solutes,\nand is allowed to equilibrate in a bath in which the concentration of A is zero and the concentration\nof B is c1. The bath is large compared to the cell. The cell volume in this bath is V0. At t = 0, the\ncell is moved to a bath that contains equal concentrations of A and B, cA = cB = 2 c1.\na. Is the new bath hyper-, hypo-, or iso-osmotic with the cell at t = 0?\nb. If the hydraulic conductivity of the cell is LV , what is the rate of increase of the volume,\ndV(t)/dt just after the cell is moved (i.e., at t = 0+)?\nc. What is the equilibrium volume of the cell in terms of V0? Explain briefly.\n\nProblem 3. The following figure shows the design of a miniature pump that can be implanted in\nthe body to deliver a drug. No batteries are required to run this pump!\nRigid,\nFrictionless,\nsemipermeable\nimpermeable\nChamber 1\nChamber 2\nDrug\n0.7 cm\n(solute)\n(drug)\norifice\nmembrane\npiston\n3 cm\nThe pump contains two cylindrical chambers filled with incompressible fluids: the two chambers\ntogether have a length of 3 cm and a diameter of 0.7 cm. Chamber 1 is filled with a solution whose\nconcentration is 10 mol/L; the osmolarity of this solution greatly exceeds that of body fluids.\nChamber 2 is filled with the drug solution. The two chambers are separated by a frictionless, mass\nless, and impermeable piston. The piston moves freely and supports no difference in hydraulic\npressure between the chambers; the piston allows no transport of water, solute or drug between\nchambers. The pump walls are rigid, impermeable and cylindrical with an orifice at one end for\ndelivering the drug and a rigid, semipermeable membrane at the other end. The orifice diameter is\nsufficiently large that the hydraulic pressure drop across this orifice is negligible and sufficiently\nsmall so that the diffusion of drug through the orifice is also negligible. The semipermeable mem\nbrane is permeable to water only, and not permeable to the solute. Assume that T = 300 K.\na) Provide a discussion of 50 words or fewer for each of the following:\ni) What is the physical mechanism of drug delivery implied by the pump design?\nii) What is(are) the source(s) of energy for pumping the drug?\niii) Assume there is an adequate supply of drug in the pump for the lifetime of the im\nplanted subject and that it is necessary to provide a constant rate of drug delivery.\nWhich fundamental factors limit the useful lifetime of this pump in the body?\nb) When implanted in the body, the pump delivers the drug at a rate of 1 μL/h. Find the value\nof the hydraulic conductivity, LV , of the semipermeable membrane.\n\nProblem 4. A large fraction of the molecules in a cell membrane are phospholipids, which have a\nhydrophilic head and hydrophobic tails. When purified phospholipids are added to a saline solu-\ntion, the phospholipids self assemble into a variety of stable structures, one of which is spherical\nand is called a liposome.\nLiposome\nBath\nLiposomes have saline interiors and exteriors that are separated\nby a phospholipid bilayer, much like a biological cell. Liposomes\ncan be used as artificial cells to test theories about membrane trans-\nport.\nAssume that a liposome is created in a solution that contains\n200 mmol/L of a solute I that cannot permeate the phospholipid bi-\nlayer. Assume that the inner solution initially contains 200 mmol/L\nof solute I and the initial radius is 30μm. Assume that the thickness\nof the bilayer is much smaller than the diameter of the liposome.\nAssume that water can permeate the phospholipid bilayer, and that hydraulic pressure gradients\nacross the bilayer can be ignored. Assume that the temperature is 300 K.\nAssume that the liposome is transfered at time t = 0 to a bath that contains 200 mmol/L of\nsolute A and 100 mmol/L of solute B. The liposome initially shrinks but then swells and reaches\nan ultimate radius of approximately 38μm as shown in the following plots. The left plot shows the\ntime course for the first 1000 seconds. The right plot shows just the first 100 seconds of the same\ndata.\n\nRadius (μm)\nRadius (μm)\nTime (seconds)\nTime (seconds)\n\nPart a. Determine the asymptotic value of concentration cI(t) of solute I in the liposome as time\nincreases, i.e., determine\nlim\nt→infcI(t).\nProvide a numerical value (or numerical expression) with units. If it is not possible to determine\nthe concentration from the information provided, explain why.\nPart b. Indicate which, if either, of the solutes A and B can permeate through the artificial mem-\nbrane? If it is not possible to determine this information, explain why.\nPart c. Determine the hydraulic conductivity LV of the artificial membrane. Provide a numer-\nical value (or numerical expression) with units. If it is not possible to determine the hydraulic\nconductivity from the information provided, explain why.\n\nProblem 5. A large fraction of the molecules in a cell membrane are phospholipids, which have\na hydrophobic head and hydrophilic tails. When purified phospholipids are added to a saline\nsolution, the phospholipids self assemble into a variety of stable structures, one of which is called\na liposome.\nLiposome\nBath\nLiposomes have saline interiors and exteriors that are separated by a phospholipid bilayer, much\nlike a biological cell, as illustrated above. Liposomes can be used as artificial cells to test the\nories about membrane transport. Assume that a liposome is created in a solution that contains\n100 mmol/L of a solute A that cannot permeate the phospholipid bilayer. Assume that water can\npermeate the phospholipid bilayer, and that the liposome comes to equilibrium with a volume of\n1 pL (10-12 L) of internal solution containing A with concentration 100 mmol/L.\nThe liposome is then transferred to one of the following solutions\n- solution 1: 100 mmol/L of A plus 10 mmol/L of B\n- solution 2: 90 mmol/L of A plus 10 mmol/L of B\n- solution 3: 100 mmol/L of B\nwhere B is a solute that can permeate the phospholipid bilayer. Both A and B are nonelectrolytes,\nand the baths are large compared to the volume of the liposome. Assume that transport of water\nand transport of the permeant solute B are independent of each other, i.e., water transport does not\neffect transport of B and vice versa.\n(a.) Calculate the equilibrium volume of the liposome in solution 1. Discuss your result briefly.\n(b.) Calculate the equilibrium volume of the liposome in solution 2. Discuss your result briefly.\n(c.) Calculate the equilibrium volume of the liposome in solution 3. Discuss your result briefly.\nProblem 6. A monosaccharide, M, is known to be transported through a cell membrane by a\ncarrier so that\n\n!\no\nci(t)\nc\n= max\n-\no\nK + ci(t)\nK + c\no\nwhere ci(t) is the intracellular concentration of M, c is the external concentration of M, is the\noutward flux of M (mol/cm2 ·s) and max is the maximum flux with which the carrier system\nis capable of transporting M. The area of the cell, A, is 10-6cm2, and K is 100 mmol/L. The\nfollowing experiment is performed: the cell initially contains zero moles of M, and at t = 0 the\ncell is placed in an isotonic solution containing a concentration of M equal to co (constant), where\noc K. The internal concentration of M is found to be\ni\no\nc (t) = c (1 - e -t/ ), t 0\nwhere = 100 s. The volume of the cell remained roughly constant at 10-10 mL throughout the\nexperiment. Determine max."
    },
    {
      "category": "Resource",
      "title": "hw4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/02e82fba379279e3fbcd502be08c1733_hw4.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #4\nIssued: October 8, 2004\nDue: Thursday October 14, 2004\nReading\nLecture 15 -- Volume 1: 7.5\nLecture 16 -- Volume 1: 7.5\nAnnouncements\nThis homework assignment is smaller than average to give you time to work on your lab reports.\nFirst drafts of your lab reports are due Friday, October 15, 2004 at 10:00 AM. Bring 3 copies.\nOne will be reviewed by the technical staff. One will be reviewed by the writing staff. One will\nbe reviewed by a peer student group. You and your partner will be assigned to review the report of\nanother student group. All reviews are due Tuesday October 19, 2004 when they will be discussed\nat the Writing Clinic, to be held at 7:30 PM.\nExercise 1. Define electroneutrality and briefly explain its physical basis.\nExercise 2. Define the Nernst equilibrium potential and briefly explain its physical basis.\nProblem 1. Two compartments of a fluid-filled chamber are separated by a membrane as shown in\nthe following figure.\nI\nV\n1 mmol/L NaCl\n0.1 mmol/L KCl\n0.1 mmol/L NaCl\n1 mmol/L KCl\nCompartment 1\nMembrane\nCompartment 2\n+\n-\nThe area of the membrane is 100 cm2 and the volume of each compartment is 1000 cm3 . The\nsolution in compartment #1 contains 1 mmol/L NaCl and 0.1 mmol/L KCL. The solution in com\npartment #2 contains 0.1 mmol/L NaCl and 1 mmol/L KCL. The temperatures of the solutions are\n24C. The membrane is known to be permeable to a single ion, but it is not known if that ion is\nsodium, potassium, or chloride. Electrodes connect the solutions in the compartments to a battery.\nThe current I was measured with the battery voltage V = 0 and was found to be I = -1 mA.\na) Identify the permeant ion species. Explain your reasoning.\nb) Draw an equivalent circuit for the entire system, including the battery. Indicate values for\nthose components whose values can be determined.\n\nc) Determine the current I that would result if the battery voltage were set to 1 volt. Explain\nyour reasoning.\nProblem 2. Three compartments are separated from each other by semi-permeable membranes, as\nillustrated in the following figure.\nVm\nIm\n+\n-\ncNa = 100\ncK = 0\ncCl = 100\ncNa = 20\ncK = 80\ncCl = 100\ncNa = 10\ncK = 0\ncCl = 10\ncompartment 1 compartment 2 compartment 3\npermeant to\npermeant to\nNa+ only\nCl- only\nEach compartment contains well-stirred solutions of sodium, potassium, and chloride ions, with\nconcentrations indicated in the figure (in mmol/L). The membrane between compartment 1 and 2\nis permeant to sodium ions only, and its specific electrical conductivity GN a is 5 mS/cm2 . The\nmembrane between compartment 2 and 3 is permeant to chloride ions only, and its specific electri\ncal conductivity GCl is 2 mS/cm2. Both membranes have areas A = 10 cm2. The temperature T is\nsuch that RT /(F log e) = 60 mV.\na) Sketch an electrical circuit that represents the steady-state relation between current and volt\nage for the three compartments. Label the nodes that correspond to compartments 1, 2, and\n3. Include the switch in your sketch. Label Im, Vm, and the conductances.\nb) Let V1 and V2 represent the steady-state potentials in compartments 1 and 2 with reference\nto compartment 3 when the switch is open. Calculate numerical values for V1 and V2.\nc) Compute the steady-state value of the current Im when the switch is closed."
    },
    {
      "category": "Resource",
      "title": "hw5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/876a85fa826247003f8dfefd6036b36c_hw5.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #5\nIssued: October 14, 2004\nDue: October 21, 2004\nReading\nLecture 17 -- Volume 2: Chapter 1\nLecture 18 -- Volume 2: 2.1-2.4.2\nLecture 19 -- Volume 2: 2.4.3-2.5\nAnnouncements\nThe recitation on October 19 is cancelled so that we can meet that evening for a Writing Clinic. The\nWriting Clinic will be held from 7:30 to 9:30 PM. Please return your written critiques of your\npeer's laboratory report at that time. You will also receive critiques from the technical and\nwriting staffs.\nExercise 1. Active ion transport is said to have a direct and an indirect effect on the resting\npotential of a cell. Define both effects and discuss the distinction between the two effects.\nExercise 2. Describe the distinctions between the following terms that refer to ion transport across\na cellular membrane: electrodiffusive equilibrium, steady-state, resting conditions, and cellular\nquasi-equilibrium.\n\nExercise 3. Figure 1 shows measurements of the resting potential of a glial cell for different values\nof extracellular potassium concentration (left panel). These measurements are to be interpreted in\nterms of the network model shown in the right panel of the same figure. Assume that co\n= 150\nNa\n\nMud puppy\nSlope:\nglial cell\n59 mV/decade\n+\n-\n+\n-\nIm\nIp\nIp\nK\nIa\nK\nIa\nG\nGK\nVK\nNa\nNa\nNa\nResting potential (mV)\n-20\n+\n-40\n-60\nV o\nm\n-80\nVNa\n-100\n-\n-120\n0.1\nco\nK (mmol/L)\nFigure 1: Measurements and model of electrical responses of a glial cell.\ni\nmmol/L, c\n= 15 mmol/L and that the external solution is maintained isotonic with the cyto-\nNa\nplasm by controlling impermeant solutes. Assume that sodium and potassium concentrations are\no\na\nconstant, except for cK, and that the pump system, which consists of I a and IK, is nonelectro-\nNa\ngenic.\na) Consider only the region for which the data are well fit by the straight line of slope 59\nmV/decade. Indicate whether the following statements are true or false and give a brief\nreason for each answer.\ni Im = 0.\nii) V o VK.\nm\niii) GNa GK.\niv) VNa > VK.\ni\nv) cK = 100 mmol/L.\na\na\nvi) I\n= -INa.\nK\np\np\nvii) I\n= -INa.\nK\na\nviii) I\n= -GNa(V o - VNa).\nNa\nm\nb) It is proposed that deviation of the data from the straight line for the lowest co is a result of\nK\na change in GK that occurs when V o < -110 mV. For the data shown, is this a reasonable\nm\nhypothesis? Does it require that GK for V o = -125 mV is larger or smaller than GK for\nm\nV o > -100 mV? Explain.\nm\n\nExercise 4. The ionic concentrations of a uniform isolated cell are given in the following table.\nConcentration (mmol/L)\nInside\nOutside\nPotassium\nSodium\nAn electrode is inserted into the cell and connected to a current source so that the current through\nthe cell membrane is Im. The steady-state voltage across the cell membrane Vm is determined as a\nfunction of the current as shown in the following figure.\n-\n+\n+\n-\n+\n-\n+\n-\n\n(mV)\n-40\n0.4\nVm\nVm\nVm\nIm\nIm\nIK\nI\nV\nVK\nG\nGK\nIm (nA)\nNa\nNa\nNa\nAssume that: (1) the cell membrane is permeable to only K+ and Na+ ions; (2) the Nernst equi\nlibrium potentials are Vn = (60/zn) log10(cn/ci\no\nn) (mV); (3) ion concentrations are constant; (4)\nactive transport processes make no contribution to these measurements.\na) Determine the equilibrium potentials for sodium and potassium ions, VNa and VK.\nb) What is the resting potential of the cell with these ionic concentrations?\nc) With the current Im adjusted so that Vm = VK, what is the ratio of the sodium current to the\ntotal membrane current, INa/Im?\nd) What is the total conductance of the cell membrane Gm = GNa + GK?\ne) Determine GNa and GK.\n\nProblem 1. The resting membrane potential, V o, of two uniform, isolated cells is measured as a\nm\no\nfunction of the external concentration of potassium, cK, with the sodium concentration held fixed\non\no\nat its normal value, cNa, and then as a function of the external sodium concentration, cNa, with\nthe potassium concentration held fixed at its normal value, con. The results for these two cells are\nK\nshown in the following figure.\nCell 1\nCell 2\n-150\n-100\n-50\nSlope: 60 mV/decade\nSlope: 48 mV/decade\nResting potential (mV)\n-150\n-100\n-50\nco (mmol/L)\nco (mmol/L)\nK\nK\nSlope: 12 mV/decade\nSlope: 0 mV/decade\nResting potential (mV)\n-150\n-100\n-50\n-150\n-100\n-50\no\no\ncN a (mmol/L)\ncN a (mmol/L)\nYou may assume that for each cell: (1) external solutions are isotonic; (2) the membranes are\nimpermeable to ions other than potassium and sodium; (3) the internal concentrations of potassium\nand sodium are maintained constant by a non-electrogenic active transport mechanism; (4) the\ntotal membrane conductance is 10 nS; (5) the normal resting potential is -60 mV; (6) the internal\nconcentration of sodium is 20 mmol/L.\nG\na) For each cell, determine the total conductance of the membrane to potassium and to sodium,\nK and GNa, respectively. If either value is indeterminate from the information given, de\nscribe what additional information would be needed.\nb) For each cell, determine the internal and external concentrations of potassium and the ex\nternal concentration of sodium at the normal resting potential (-60 mV). If the value is\nindeterminate from the information given, describe what additional information would be\nneeded.\n\nc) For each cell, determine the simplest equivalent electric network model that relates the de\npendence of the resting potential of the cell on the ion concentrations. Indicate the values of\nall elements in the network.\nProblem 2. The membrane of a cell is known to be permeable to Na+ and K+ only, with\npassive ionic conductances of GNa = 10-6 S/cm2 and GK = 10-3 S/cm2 , and contains a\n(Na+- K+)ATPase active transport mechanism that transports 3 molecules of Na+ outward and\n2 molecules of K+ inward through the membrane for each molecule of ATP split into ADP and\nphosphate. In the experiment shown in Figure 2, the cell is kept at a temperature of 24C. For\nt\nt1\nt2\n¡60\n¡60\n¡80\nInjection of\nPerfusion\nsodium ions\nwith ouabain\nV o\nm\nFigure 2: Effect of sodium injection and ouabain on resting potential.\nt < t1, the cell is in its normal resting state with resting potential V o -60 mV, and resting ion\nm\nconcentrations shown in the following table.\nIon\nConcentration (mmol/L)\nInternal\nExternal\nSodium\nPotassium\nAt t = t1, Na+ is injected rapidly into the cell interior, without the passage of any current through\nthe membrane, to double the intracellular sodium concentration. When the injection is completed,\nthe membrane potential hyperpolarizes to approximately -80 mV. At t = t2 ouabain, a blocker\nof the active transport mechanism, is applied to the cell and the membrane potential returns to\napproximately its normal resting value.\na) Is the active transport mechanism electrogenic or nonelectrogenic? Explain!\nb) Does the active transport mechanism contribute appreciably to the resting potential for t <\nt1? Explain!\nc) How many moles of ATP are split per second by a cm2 of membrane during the interval\n(t1, t2)?\n\nProblem 3. The membrane of a cell contains an active transport mechanism that pumps three\nsodium ions out of the cell for every two potassium ions that it pumps into the cell. The membrane\nalso supports the passive transport of sodium and potassium ions, but is impermeant to all other ions\nand is impermeant to water. The sodium conductivity is 10-5 S/cm2 and the potassium conductivity\nis 10-4 S/cm2. The cell is allowed to come to steady state and its membrane potential is -52.5 mV.\nThe Nernst equilibrium potential for sodium is 60 mV and the Nernst equilibrium potential for\n-60\npotassium is\nmV. The net outward current density due to active transport is\nμA/cm2 .\na) Draw an electrical circuit to represent ionic transport across the membrane of this cell. In\nclude labels for each of the 6 numbered parameters provided in the problem statement.\nb) Is the cell at rest? If yes, prove that it is at rest. If no, explain why not.\nc) Is the cell in quasi-equilibrium? If yes, prove that it is at quasi-equilibrium. If no, explain\nwhy not.\nd) Is the active transport mechanism electrogenic? Explain.\nProblem 4. Consider the model of a cell shown in the following figure.\n+\n-\n+\n-\n+\n-\nV o\nm\nIm\nIp\nIp\nK\nIa\nK\nIa\nG\nGK\nV\nVK\n+\n-\nIp\nCl\nGCl\nVCl\nN a\nN a\nN a\nN a\nThe cell has channels for the passive transport of sodium, potassium, and chloride as well as a\npump that actively transports sodium out of the cell and potassium into the cell. The pump ratio\nis Ia\nK = -1.5. The following table shows the intracellular and extracellular concentrations,\nNernst equilibrium potentials, and conductance ratios for sodium and potassium. Some informa\ntion is also given for chloride; blank entries represent unknown quantities.\nNa/Ia\nci\nn\nco\nn\nVn\nGn/GK\n(mmol/L) (mV)\nNa+\n+68\n0.1\nK+\n-68\nCl-\nThe cell also contains impermeant intracellular ions. Assume that the cell is in equilibrium at t = 0,\ni.e., assume that at t = 0 the cell has reached a condition for which all solute concentrations, the\ncell volume, and the membrane potential are constant.\na) Choose one of the following statements and explain why it is true.\n\ni) The cell resting potential depends on GCl.\nii) The cell resting potential depends on VCl.\niii) The cell resting potential depends on both GCl and VCl.\niv) The cell resting potential does not depend on GCl.\nv) The cell resting potential does not depend on VCl.\nvi) The cell resting potential does not depend on either GCl or VCl.\nb) Determine V o .\nm\nc) At t = 0, the external concentration of chloride is reduced from 150 mmol/L to 50 mmol/L\nby substituting an isosmotic quantity of an impermeant anion for chloride. Assume that the\nconcentrations of sodium and potassium both inside and outside the cell remain the same\nand that the volume of the cell does not change.\ni) Determine V o\nm(0+), the value of the membrane potential immediately after the change\nin solution. You may ignore the effect of the membrane capacitance.\nii) Determine V o\nm(1), the value of the membrane potential after the cell has equilibrated.\ni\niii) Determine cCl(1), the intracellular chloride concentration after the cell has equili\nbrated.\niv) Give a physical interpretation of your results in i), ii), and iii).\nv) Discuss the validity of the assumptions that the sodium and potassium concentrations\nin the cell are constant and that the volume does not change."
    },
    {
      "category": "Resource",
      "title": "hw6.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/fa768d461f96d3694f1cde02e1fc29b4_hw6.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #6\nIssued: October 21, 2004\nDue: October 28, 2004\nReading\nLecture 20 -- Volume 2: 4.1-4.1.2.3 4.2-4.2.2.2\nLecture 21 -- Volume 2: 4.2.3-4.2.3.1\nLecture 22 -- Volume 2: 4.2.3-4.2.3.2\nAnnouncements\nLaboratory reports are DUE Monday October 25 at noon. You should submit one copy of the\nfinal draft of the report. You should include the following items in an appendix: final proposal,\ncopy of your critique of a peer's first draft, peer critique of your first draft, critique of your first\ndraft by writing program, critique of your first draft by technical staff, photocopies of notes taken\nduring original lab session. Note that there is a SEVERE LATENESS PENALTY. The grade for\na late report will be multiplied by a lateness factor\n-t/72\nL = 0.3e -t/4 + 0.7e\nwhere t is the number of hours late. The lateness factor is plotted below. Notice that the maximum\ngrade for a report that is more than ONE DAY LATE is less than 50%.\n8 1\nThe exam is closed-book: notes on both sides of two\nLateness factor L\n1.0\n0.5\n0.0\none day\nTime t past deadline (hours)\nThis lateness factor is applied regardless of the reason for the lateness, except for health related\nproblems or personal problems certified by the Dean's office. Specifically, lateness due to computer\nand/or printer problems is not exempt.\nExam 2 will be held on Thursday, November 4 from 7:30 PM to 9:30 PM\n× 11 sheets of paper may be\nused for reference. Calculators may be used, but computers and wireless devices may not be used.\nThere will be no recitations on the day of the exam.\n\nExercise 1. Give a physical explanation for why the conduction velocity is larger in larger diameter\nfibers, if all other factors are the same.\nExercise 2. Give a physical explanation of the meaning of Equation 2.18 (in volume 2 of the text)\nwithout the use of equations.\nExercise 3. Let the function f(z, t) represent a solution to the wave equation. This solution is\nshown in the following figure as a function of time t at the position z = 0.\nf(0\n)\n, t\nt (ms)\nNotice that f(0, t) is non-zero for 0 < t < 2 ms and zero elsewhere.\na) Suppose that the wave is propagating in the +z-direction with a propagation velocity of 100\nmm/ms. Plot f(z, t) versus z at time t = 2 ms.\nb) Suppose that the wave is propagating in the -z-direction at a propagation velocity of 100\nmm/ms. Plot f(z, t) versus z at time t = 2 ms.\nProblem 1. The following two experiments are performed on a squid giant axon:\n- Experiment #1: The axon is placed in a large volume of sea water, and the size of the\ntransmembrane action potential is measured by means of an intracellular micropipet and is\nfound to have a peak-to-peak value of 100 mV. The conduction velocity is 36 m/s.\n- Experiment #2: The axon is placed in oil and the trans-membrane potential is still found to\nbe 100 mV peak-to-peak. The peak-to-peak size of the extracellular action potential is 75\nmV.\nEstimate the expected conduction velocity in Experiment #2. State your assumptions.\n\nProblem 2. A fine platinum wire with a resistance per unit length of 130\n/cm is inserted inside a\nportion of a squid axon as illustrated below.\nV1(t)\nV2(t)\ni\nial\nWi\nz\nAxon\nact on\npotent\nre\n(cm)\nz1\nz2\nThe wire is so thin that its volume can be ignored. The axon (500 μm diameter) is electrically stim\nulated to produce a propagated action potential traveling in the +z direction. The action potential\nis recorded at two intracellular sites: V1(t) is recorded at z = z1 and V2(t) is recorded at z = z2.\nThe distance between the stimulus electrode (not shown) and z1 is 2 cm. Results are shown in the\nfollowing figure.\n-\n-\nV1(t)\nV2(t)\n+50\nIntracellular potential\n(mV)\nTime (ms)\nThe resistivity of the axoplasm of this axon is 23\n-cm. The resistance per unit length of the\nexternal solution is 1.2\n/cm. The wire begins at some location between z1 and z2, but the exact\nposition of the beginning is not known and should not be used in any of your calculations.\na) Determine the instantaneous speed of the action potential as it's peak passes the point z = z1.\nb) Determine the instantaneous speed of the action potential as it's peak passes the point z = z2.\nc) Sketch the extracellular potential as a function of space (z) that results at the time that the\npeak of the action potential passes the point z = z1. Include distances z1 -4 < z < z1 +4 cm.\nIndicate the scale for the y axis. Describe the important features of this plot.\nd) Sketch the extracellular potential as a function of space (z) that results at the time that the\npeak of the action potential passes the point z = z2. Include distances z2 -4 < z < z2 +4 cm.\nIndicate the scale for the y axis. Describe the important features of this plot.\n\nProblem 3. In measurement 1, a cylindrical unmyelinated axon of radius a is placed in a large\nvolume of isotonic sea water and the conduction velocity of the action potential is measured to\nbe 1. The osmotic pressure of the sea water is then doubled by increasing the salt concentration,\nand the axon is allowed to come to osmotic equilibrium. Then, in measurement 2, the conduction\nvelocity is measured to be 2. Assume that during these experiments\n- the number of ions transported through the axon membrane is negligible compared to the\nnumber of ions inside the axon,\n- the volume of the axon is negligible compared to the volume of the bath,\n- the specific electric properties of the membrane (the capacitance per unit area and the con\nductance per unit area) are the same in both measurements,\n- the length of the axon remains unchanged, and\n- the external resistance per unit length of the axon, ro, is negligible compared to the internal\nresistance per unit length of the axon.\nPart a. Let ri1 and ri2 represent the internal resistance per unit length of the axon in measurements\n1 and 2, respectively. Determine the numerical value (or a numerical expression) for the ratio of\nthese resistances: ri2/ri1. Briefly explain your reasoning.\nPart b. Determine the numerical value (or a numerical expression) for the ratio of speeds: 2/1.\nBriefly explain your reasoning."
    },
    {
      "category": "Resource",
      "title": "hw7.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/814f9b9b439e99f3cf00e547bf563080_hw7.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #7\nIssued: November 8, 2004\nDue: November 18, 2004\nReading\nLecture 23 -- Volume 2: 4.3\nLecture 24 -- Volume 2: 4.4.8\nLecture 25 -- Volume 2: 4.4.1\nLecture 26 -- Volume 2: 3.1-3.2.1 3.3-3.4.2.1\nLecture 27 -- Preparing an oral presentation\nLecture 28 -- Volume 2: 3.4.2.4-3.4.3.1 3.4.3.3-3.5\nLecture 29 -- Volume 2: 5.1-5.2.4.4\nLecture 30 -- Volume 2: 5.3-5.7\nLecture 31 -- Volume 2: 6.1-6.1.1 6.4-6.4.1.5 6.2-6.2.2 6.5-p407\nAnnouncements\nThere is no homework assignment due this week, because of Veteran's day. This assignment is due\non the Thursday after Veteran's day (November 18).\nFirst Drafts of your HH project is due on November 19 (one day after this homework is due!).\nThe first draft should consist of hardcopies of 3-5 technical slides of the type you plan to show\nduring your final oral presentation. Each slide should be accompanied by a separate sheet of paper\nthat lists approximately three bullet points that you will discuss in your presentation of this slide.\nThe first draft should also contain a 1 page extended abstract for your HH project. The abstract\nshould summarize your findings and explain why they are interesting.\nPlease take advantage of THIS week to work on your project plus the HH portion of this\nhomework assignment!\nExercise 1. The following assertions apply to responses calculated according to the Hodgkin-\nHuxley model in response to a step of membrane potential applied at t = 0. For each assertion,\nstate if it is true or false and explain your answer.\na) The leakage conductance is constant.\nb) The sodium conductance is discontinuous at t = 0.\nc) The potassium conductance is discontinuous at t = 0.\nd) The leakage current is constant.\ne) The sodium current is discontinuous at t = 0.\nf) The potassium current is discontinuous at t = 0.\ng) The factors n(t), m(t), and h(t) are discontinuous at t = 0.\n\nh) The time constants n, m, and h are discontinuous at t = 0.\ni) The steady-state values n1, m1, and h1 are discontinuous at t = 0.\nExercise 2. Figure 1 shows the relation between the membrane potential and the membrane current\ndensity during a propagated action potential as computed from the Hodgkin-Huxley model. The\nV m (mV)\nJ m (mA/cm )\nJm\nVm\n0.4\n-40\n-80\n-0.4\nTime (ms)\nFigure 1: Relation of membrane potential and membrane current density during a propagated\naction potential. The dotted vertical line marks the time of occurrence of the peak of the action\npotential.\nmembrane current density consists of an initial outward current followed by an early inward current\nwhose peak occurs before the peak in the action potential.\na) The initial outward current is due primarily to which of the following:\ni) an ionic current carried by sodium ions.\nii) an ionic current carried by potassium ions.\niii) an ionic current carried by chloride ions.\niv) an ionic current carried by calcium ions.\nv) a capacitance current.\nb) The early inward current is due primarily to which of the following:\ni) an ionic current carried by sodium ions.\nii) an ionic current carried by potassium ions.\niii) an ionic current carried by chloride ions.\niv) an ionic current carried by calcium ions.\nv) a capacitance current.\nc) Before the peak of the action potential, the membrane potential increases from its resting\nvalue whereas the membrane current density is first outward (increasing and then decreasing)\nand then reverses polarity to become inward (decreasing and then increasing again). Discuss\nthis complex relation between membrane potential and current. In particular, explain how\nthe Hodgkin-Huxley model accounts for the fact that the current can be both inward and\noutward during an interval of time when the membrane potential is depolarizing.\n\nExercise 3. Does the time constant of a cylindrical cell depend on its dimensions? Does the space\nconstant of a cylindrical cell depend on its dimensions?\nExercise 4. For each of the following statements, assume that the electrical properties of a patch\nof the membrane of the cell can be represented as a parallel resistance and capacitance. Assume\nthat the cell has a cylindrical shape with a radius that is small compared to the length of the cell.\nDetermine if each assertion is true or false and give a reason for your choice.\na) For an electrically small cell, the membrane potential in response to a step of current through\nthe membrane is an exponential function of time.\nb) If a step of current is applied through one part of the membrane of an electrically small cell,\nthe resulting changes in membrane potential will be constant along the length of the cell for\nall times after the step.\nc) For an electrically large cell, the steady-state value of the membrane potential in response to a\nstep of current applied through the membrane at one position along the cell is an exponential\nfunction of longitudinal position along the cell.\nd) For an electrically large cell, the steady-state value of the membrane potential in response to\na step of current applied through the membrane at one position along the cell is a Gaussian\nfunction of position along the cell.\n\nProblem 1. The Hodgkin-Huxley model was used to compute propagated action potentials for\ndefault values of the parameters and for 4 test cases. The following plots show the spatial depen\ndence of membrane potential that results 1 ms after the stimulus current was applied at z = 0.\nMembrane potential\nMembrane potential\n(mV)\n(mV)\nA\nB\nC\nMembrane potential\nMembrane potential\n(mV)\n(mV)\n-20\n-20\n-40\n-40\n-60\n-60\n-80\n-80\nDistance (cm)\nDistance (cm)\nD\n-20\n-20\n-40\n-40\n-60\n-60\n-80\n-80\nDistance (cm)\nDistance (cm)\nEach of A-D shows a plot with two curves: the thin gray curve was obtained for default parameters\nand the thick black curve was obtained for one of the tests cases. In each test case, a single\nparameter was changed from its default value. Default values of the axon characteristics are as\nfollows -- length: 3 cm, radius: 0.0238 cm, cytoplasm resistivity: 35.4\n·cm, extracellular specific\nresistance: 0\n/cm.\na. Which of A-D shows results when intracellular sodium concentration was reduced from\nicNa = 50 to 25 mmol/L. Explain.\nb. Which of A-D shows results when the maximum potassium conductance GK was increased\nfrom 36 to 72 mS/cm2? Explain.\nc. Which of A-D shows results when cytoplasmic resistivity was decreased from 35.4 to\n·cm? Explain.\n\nProblem 2. Ionic currents are calculated for a space-clamped squid giant axon using the Hodgkin-\nHuxley model, with all parameters set to their default values (as listed on page 191 of volume 2\nof the text) except for one parameter. For times t < 0, the membrane potential is held at -75 mV\nand the model is at steady state. At t = 0, the membrane potential is stepped to +5 mV and the\nresulting ionic current density is computed. Results for six calculations are shown in the following\nfigure.\nTime (ms)\nIonic Current Density\n(mA/cm2)\n-2\n-1\nJ2\nJ3\nJ5\nJ4\nJ6\nJ1\nPart a. Which curve represents the ionic current that results when all parameters have default\nvalues except co\nNa = 50 mmol/L? Explain.\nPart b. Which curve represents the ionic current that results when all parameters have default\nvalues except co\nK = 400 mmol/L? Explain.\nPart c. Which curve represents the ionic current that results when all parameters have default\nvalues except GNa = 0? Explain.\nPart d. Which curve represents the ionic current that results when all parameters have default\nvalues except GK = 0? Explain.\nProblem 3. Space-clamped responses of the Hodgkin-Huxley model were calculated with the\nleakage conductance set to zero, GL = 0, and with all other parameters set to their default val-\nues. The model was stimulated with a pulse of membrane current density of duration 0.5 ms; the\namplitude was varied. The following figure shows the response for an amplitude of 40 μA/cm2.\n-500\n-400\n-300\n-200\n-100\n0.5\n1.5\n2.5\nVm\nJion\nJm\nmV and μA/cm2\nTime (ms)\n\nFor each amplitude of the pulse of membrane current density, the ionic current density Jion and\nthe membrane potential Vm were determined at t = 0.7 ms, where t = 0 marks the onset of the\ncurrent pulse. The relation between Jion at t = 0.7 ms and Vm at t = 0.7 ms that results when\nthe pulse amplitude is varied is shown in the following figures. The left panel shows results for a\nbroad range of membrane potential, from -80 to +60 mV. The right panel shows results for the\nnarrower range from -76 to -62 mV.\n-400\n-300\n-200\n-100\n-0.2\n-0.1\nJ ion(t\n.\nμA/cm2 )\n= 0 7 ms) (\n-80 -60 -40 -20\n-76 -74 -72 -70 -68 -66 -64 -62\nVm(t = 0.7 ms) (mV)\nPart a. Determine the value of the resting potential to within 1 mV. Explain your choice.\nPart b. If the current stimulus is such that Vm(t) = -66 mV at t = 0.7 ms, does the membrane\npotential increase with time or decrease with time? Explain.\nPart c. Determine the value of the threshold potential to within 1 mV. Explain your choice.\nPart d. Between the resting potential and this threshold potential, determine whether |JNa| > |JK|,\n|JNa| = |JK|, or |JNa| < |JK|. Explain.\nPart e. Just above the threshold potential, determine whether |JNa| > |JK|, |JNa| = |JK|, or\n|JNa| < |JK|. Explain.\nProblem 4. The Hodgkin-Huxley model of a space-clamped squid giant axon stimulated by a\npulse of membrane current of amplitude 20 μA/cm2 and of duration 0.5 ms produces a membrane\naction potential. You can demonstrate this to yourself by running the space-clamped version of\nthe Hodgkin-Huxley simulation software provided with this subject. Start by using the default\nparameters. If you change the membrane capacitance from 1 μF/cm2 to 20 μF/cm2, no action\npotential occurs.\nPart a. Explain why no action potential occurs for the larger value of membrane capacitance. You\nmay base your explanation on comparison of the membrane currents, conductances, and activation\nvariables for the default parameters and for the increased capacitance condition. Alternatively, you\nmay wish to perform additional computations with other values of membrane capacitance.\nPart b. With membrane capacitance fixed at 20 μF/cm2, determine a set of parameters that produce\nan action potential with a waveform that is identical to the action potential obtained with the default\nparameters. To determine whether or not the action potential is identical to that obtained with the\ndefault parameters, you can superimpose plots and/or look at the parameters computed from the\nresponses. You should use the computer as a tool to check your ideas and not as a substitute\nfor thinking. You should avoid a strictly trial-and-error approach. There are simply too many\nparameters in the Hodgkin-Huxley model for you to explore them all randomly. When you have\narrived at a satisfactory solution, explain why your parameter change produces the desired result.\n\nProblem 5. Constant currents I1 and I2 are applied to the exteriors of Axons 1 and 2, respec\ntively, and the resulting time-independent changes in membrane potential are vm1(z) and vm2(z),\nrespectively. I1 and I2 are adjusted so that vm1(0) = vm2(0) = 10 mV. This change in potential is\nsufficiently small so that the membrane voltage-current characteristic may be assumed to be linear.\nYou may also assume that ro ri for both axons and that ro is the same for both axons. The\ngeometries and parameters for Axons 1 and 2 are given below, where a is the axon radius, i is the\ncytoplasmic resistivity, and Gm is the specific membrane conductance.\nAxon 1\nI1\nAxon 2\nI2\nAxon\na\ni\nGm\n#\n(μm) (\n·cm)\n(S/cm2)\n5×10-3\n(1/8)×10-3\n-0.1\nz (cm)\na) Let vm1(-0.1) and vm2(-0.1) be the membrane potential changes at z = -0.1 cm for the\ntwo axons. Determine the value of the ratio A = vm1(-0.1)/vm2(-0.1).\nb) Determine the value of the ratio B = I1/I2.\nProblem 6. A large unmyelinated axon is immersed in oil, and five different arrangements of\nelectrodes for delivering current stimuli and for measuring potential responses are attached to the\naxon as shown below.\n\n+\n-\n+\n-\n+\n-\n+\n-\n+\n-\na\nb\nc\nd\ne\nie(t)\nv(t)\n5λC\nie(t)\nv(t)\n5λC\nλC\n5λC\n5λC\nλC\n5λC\nλC\nie(t)\nv(t)\nie(t)\nv(t)\nie(t)\nv(t)\nThe stimulus current, a brief positive pulse at t = 0, is the same for each arrangement of electrodes.\nThe pulse has a duration that is much shorter than the membrane time constant of the cell, and a\nstrength that is low enough that the cell's voltage response remains in its linear range of operation.\nThe space constant of the cell is λC. In arrangement d, the potential is recorded and the current is\ndelivered at the same longitudinal position. In part e, the electrodes are much longer than λC.\nFor each of the different arrangements (parts a-e in the figure) determine which of the following\nwaveforms for v(t) represents the deviation of the measured potential from its resting value. For\neach waveform, the horizontal axis corresponds to v(t) = 0, and the vertical axis to t = 0. If no\nwaveform applies, answer None. Explain the basis of your choice in each case.\nv1(t)\nv2(t)\nv3(t)\nv4(t)\nv5(t)\nv6(t)\nv7(t)\nv8(t)\nv9(t)\nv10(t)\nv11(t)\nv12(t)\nv13(t)\nv14(t)"
    },
    {
      "category": "Resource",
      "title": "hw8.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/693cce695cbb5a11d31b9670068ce4fb_hw8.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #8\nIssued: November 18, 2004\nDue: December 2, 2004\nReading\nLecture 32 -- Volume 2: 6.5-p407\nLecture 33 -- Volume 2: p407-416\nLecture 34 -- Volume 2: 6.3.2-6.3.6\nLecture 35 -- Volume 2: 6.6 6.7\nAnnouncements\nThis homework assignment is due in 2 weeks, on December 2. Please note, however, that the final\nHH oral presentations take place on December 1 and 3. Therefore, you might want to get started\nearly on this assignment.\nHH Dry Runs are scheduled for November 23 (see schedule in the calendar section). Recitations on\nthat day are cancelled.\nExercise 1. Estimate the conduction velocity of the action potential from the measurements on a\nsingle myelinated nerve fiber shown in Figures 5.19-5.21 in volume 2 of the text..\nExercise 2. Define the safety factor.\nExercise 3. The following figure shows two putative records of membrane currents recorded from\ntwo membrane patches, each of which contains a single channel, in response to a step of depolar\nizing membrane potential.\nt\nVm(t)\n(1)\n(2)\nEach of these channels has a linear voltage-current characteristic when the channel is open.\na) Which, if any, of these records could be from a single, voltage-gated channel? Explain.\n\n¡\nb) Which, if any, of these records could be from a single channel that is not voltage-gated?\nExplain.\n\nProblem 1. A myelinated axon, shown schematically in Figure 5.8 of volume 2 of the text, has\nthe dimensions L = 2 mm, D = 14 μm, d = 10 μm, l = 0.7 μm. The resistivity of the cytoplasm\ni = 110\n·cm, and the resistance of the extracellularly space can be assumed to be negligible.\nThe membrane potential, Vm, and current per unit length, Km, are shown in Figure 1 for a location\nat an internode as an action potential propagates down the fiber. Assume that the internode can be\n0.5\n1.0\n+50\n+25\n¡25\n¡50\nTime (ms)\nV m (mV)\nVm\nKm\nKm (nA/cm)\nFigure 1: Membrane potential and current at an internode.\nrepresented by a linear cable with the equivalent membrane model shown in Figure 2.\n+\n¡\ngmi\nV o\nm\nKm\ncmi\nExtracellular\nFigure 2: Model for voltage-current relation at an internode.\na) Estimate the conductance, gmi, and capacitance, cmi, per unit length of internode from the\ndata given. [Hint - the capacitance current is zero when dVm/dt = 0 and largest when\ndVm/dt is large.]\nb) Find the values of the membrane time constant, M i, and the axon space constant, Ci, of the\ninternode.\nc) Find the specific conductance, Gmi, and capacitance, Cmi, per unit area of internodal myelin.\nd) Given that the myelin is composed of 150 lamellae, find the specific conductance Gm, and\ncapacitance, Cm, per unit area for a single layer of myelin membrane. How do these values\ncompare to those of unmyelinated fibers?\ne) Now consider an unmyelinated fiber whose diameter is 10 μm and whose membrane has a\nspecific capacitance, Cm, and conductance, Gm, per unit area equal to that found in part d).\nWhat is the time constant, M , and space constant, C , of this fiber? Compare these results\nto those found in part b). What is the physiological significance of the difference?\nIntracellular\n+\nVm\nMembrane\n\n0.8\n¡0.8\n5.0\n¡5.0\nToad node\nof Ranvier\nSquid giant\naxon\nJ\nJK\nJ\nJK\nJ (mA/cm2 )\nNa\nNa\nTime (ms)\nFigure 3: Comparison of ionic currents during an action potential for an unmyelinated squid giant\naxon and a myelinated toad node of Ranvier. These ionic currents are based on calculations of\nmodels of the squid giant axon (adapted from Cooley and Dodge, 1965, Figure 2.4) and toad node\nof Ranvier (adapted from Frankenhaeuser and Huxley, 1964, Figure 6).\nProblem 2. A squid giant axon (which is an unmyelinated axon) has a diameter of 500 μm. The\nionic currents during the passage of one action potential are shown in Figure 3. The normal internal\nconcentration of sodium is 40 mmol/L. In contrast, consider a frog myelinated fiber for which the\naxon diameter (not including the myelin) is 10 μm, the fiber diameter (including the myelin) is\n14 μm, the internodal length is 2 mm, the nodal length is 0.7 μm, and the nodal area is 22 μm .\nWe shall assume that action potentials occur only at the nodes. The ionic currents at the node of\nRanvier during the passage of an action potential are also shown in Figure 3. You may assume that\nthe sodium current is negligible in the internodes. The normal internal concentration of sodium is\n10 mmol/L in the frog fiber.\nBoth the squid unmyelinated fiber and the frog myelinated fiber conduct action potentials with\nabout the same conduction velocity. This problem concerns the energetic efficiency of these two\nfibers.\na) Compute the number of moles of sodium entering each fiber per action potential per unit\nlength of fiber.\nb) Assume that the energy expended to pump the accumulated sodium out of the cell can be\nmeasured in terms of the number of ATP molecules hydrolyzed to ADP and assume that 3\nmoles of Na+ are transported out of the axon for every mole of ATP hydrolyzed to ADP\ninside the axon by the (Na+-K+)ATPase pump. Find the ratio of energy expended per unit\nlength per action potential in order to pump out the accumulated sodium for the squid un\nmyelinated fiber to that for the frog myelinated fiber.\nc) Describe the advantages of the frog myelinated fiber over the squid unmyelinated fiber.\nProblem 3. Figure 4 shows a detail of a propagating action potential calculated using a model of\na myelinated nerve fiber (Figure 5.31 in volume 2 of the text).\na) Describe a method by which the data in Figure 4 could be analyzed to estimate the current\n\nV m(z, t o )¡ V o (mV)\nm\nto = 0.75\nNode Number\nFigure 4: Membrane potential along a myelinated fiber computed from a model of electrical char\nacteristics of the node and internode (Figure 5.31 in volume 2 of the text). The membrane potential\nis plotted as a function of distance along the fiber (expressed in units of internodal length where\nL = 1.38 mm).\nIm flowing out of a node. Apply your method to calculate the current flowing out of node 6\nat t0 = 0.75 ms. Assume that ri = 140 M\n/cm>> ro.\nb) Describe a method by which the data in Figure 4 could be analyzed to estimate the current\ndensity Km flowing out of an internode. Apply your method to determine whether current is\nflowing into or out of the internode between nodes 5 and 6 at t0 = 0.75 ms.\nProblem 4. Although there is considerable scatter, the ratio of the inner diameter d to outer diam\neter D of the layer of myelin that encircles a myelinated fiber tends to be about 0.74, as shown in\nthe following figure, where every symbol represents measurements of d/D and d for a different\nfiber.\n0.9\n\nvagus nerve\n\nsciatic nerve\nd/D\n0.85\n0.8\n0.75\n0.7\n0.65\n0.6\n0.55\n0.5\nD\nd\n0.5 1 1.5 2 2.5 3 3.5 4 4.5 5\nd (μm)\nThe point of this problem is to investigate the hypothesis that this relation between d and D results\nfrom an evolutionary optimization of the cable model.\nPart a. Assume that the myelinated part (the internode) of a myelinated fiber can be represented by\nthe cable model. Assume the myelin can be represented by a homogeneous electrical material with\nresistivity m and permittivity ρm. Assume the intracellular conductor is a homogeneous conductor\nwith resistivity w . Assume that the extracellular conductor has negligible resistance. Determine\nan expression for the space constant C of this model in terms of the inner diameter d and the outer\ndiameter D of the layer of myelin. Hint: The radial resistance of a cylindrical shell is given below.\n\nq\nD\nd\nρ o\n+\n-\nV\nln\nR =\n=\nI\n2πL\nd\nPart b. The expression derived in part a is plotted below\n0.6\n0.4\nλC/λo\n0.2\n0.5\nd/D\nwhere o = D\nm/8w. Thus, if D is fixed (i.e., if the axon is constrained to fit into a constant\nvolume), then o is a constant, and C is maximum when d 0.6D.\nb1) Explain in physical terms why the space constant gets smaller as the value of d decreases\nbelow 0.6D.\nb2) Explain in physical terms why the space constant gets smaller as the value of d increases\nabove 0.6D.\nPart c. The value of d/D that maximizes the space constant of the cable model is remarkably close\nto the ratio of 0.74 seen experimentally. Nevertheless, it is smaller. One possible reason why it is\nsmaller is that we ignored the resistance of the outer conductor ro. How would the space constant's\ndependence on d/D change if the resistance of a thin layer of saline (thickness = 0.1D) were\nincluded in the calculation. Make a plot that contains both the old relation (shown in the previous\nplot) and the new relation. Briefly describe how the addition of the outer resistance changes the\npredicted space constant.\nD\nL\nd\nV\nρο\nD"
    },
    {
      "category": "Resource",
      "title": "hw9.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/895736a7dd2a39dfbe7be8c0154afdc6_hw9.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHomework Assignment #9\nIssued: December 2, 2004\nThis homework assignment will not be collected.\nExercise 1. Explain the origin of gating current.\nExercise 2. State whether each of the following are true or false and give a reason for your answer.\na) Tetrodotoxin blocks the flow of potassium through the sodium channel.\nb) The macroscopic sodium current recorded by an electrode in a cell is a sum of the single-\nchannel sodium currents that flow through single sodium channels.\nc) The macroscopic sodium current recorded by an electrode in a cell is the average of the\nsingle-channel sodium currents that flow through single sodium channels.\nd) Ionic and gating currents give identical information about channel kinetic properties.\nExercise 3. Explain why the gating current is outward in response to a depolarization independent\nof the sign of the charge on the gate.\nExercise 4. List 4 distinct properties shown by ionic currents measured from single voltage-gated\nion channels.\n\nProblem 1. The voltage across a membrane patch is stepped from V o to V f at t = 0 and single-\nm\nm\nchannel ionic currents are recorded as a function of time. Typical records at 6 different values of\nV f are shown in the following figure.\nm\nVf\nm\n(mV)\n-1\n-20\n-1.4\n-40\n-1.8\n-60\n-2.2\n-80\n-100\nCurrent (pA)\n-2.6\n-3\nTime (ms)\na) Is the open-channel voltage-current characteristic of this channel linear or nonlinear?\nb) What is the conductance of the open channel?\nc) What is the equilibrium (reversal) potential for this channel?\nd) It is proposed that this channel is the voltage-gated sodium channel responsible for sodium-\nactivated action potentials. Discuss this suggestion.\n\nProblem 2. Transport of an ion through a cell membrane can be represented by a population of\nvoltage-gated channels where each channel contains one two-state gate. The two states are state S0\nand state S1 and transitions between these states obey first-order kinetics with voltage dependent\nrate constants.\n(Vm )\nτ\nS0 γ S1.\n(Vm )\nIn response to a step of voltage across the channel, the state occupancy of the channel, the single-\nchannel current, and the probability that the channel occupies state S1 are shown in the following\nfigure.\nMembrane\nProbability of\nSingle-channel\nState\npotential\noccupancy\ncurrent (pA)\noccupancy\n(mV)\nof state 1\n+20\n-60\n0.5\n-2\nS0\nS1\nTime (ms)\na) For which state is the channel non-conducting?\nb) Determine both the equilibrium (reversal) potential for conduction through this channel and\nthe conductance of the channel when the channel is conducting.\nc) For Vm = 20 mV determine the rate constant β(20) and (20) where the voltage is expressed\nin mV.\nd) Sketch the probability that the channel occupies state S0 as a function of time.\ne) Briefly describe one experimental method that can provide an estimate of channel density.\nBe specific about which data you propose to use and how you propose to estimate the density\nfrom these data.\nf) Measurements indicate that there are 1000 channels per μm2 in the membrane of this cell.\nSketch the ionic current density Jm(t) that would be expected with the voltage step shown\nin the figure. Indicate relevant dimensions on the sketch.\n\nProblem 3. This problem deals with the relation of current to voltage for single ion channels.\nAssume that conduction through an open ion channel is governed by the equation\nI = (Vm - Ve),\nV\nwhere I is current through a single open channel, is the conductance of a single open channel,\nm is the membrane potential across the channel, and Ve is the equilibrium (reversal) potential for\nthe channel. For each of the channels in this problem, assume that = 25 pS and Ve = 20 mV.\na) The membrane potential Vm and the average single-channel current i obtained from three\ndifferent single channels (A, B, and C) are shown in Figure 1. Both the membrane potential\nChannel A\nChannel B\nChannel C\nt\nt\nt\n-60\n-60\n-20\n-20\n+10\n+80\nt\nt\nt\n-1\n-0.5\n-0.5\n-0.75\n-0.2\n+0.3\nVm(t\ni(t\nVm(t\ni(t\nVm(t\ni(t\n) (mV)\n) (pA)\n) (mV)\n) (pA)\n) (mV)\n) (pA)\nFigure 1: Average single-channel currents.\nand current are plotted on a time scale such that the changes appear instantaneous and only\nthe final values of these variables can be discerned in the plots; i.e., the kinetics are not\nshown. For each of these channels, answer the following questions and explain your answers:\ni) Is this channel voltage-gated for the illustrated depolarization?\nii) Is the channel activated (opened) or inactivated (closed) by the illustrated depolariza\ntion?\nb) Assume that each voltage-gated channel contains one two-state gate where is the time\nconstant of transition between states. For each of the channels, sketch the time course of i(t)\non a normalized time scale t/ . Clearly show the current near t = 0.\nProblem 4. Three three-state voltage-gated channels (channels a, b, and c) have the kinetic dia\ngram and state occupancy probabilities shown in Figure 2. These channels have the same voltage\ndependent rate constants and the same equilibrium potential which is +40 mV. For the membrane\npotential shown, the channels are in state 1 with probability 1 for t < 0 and have the indicated rate\nconstants for t > 0. The channels differ only in their state conductances and state gating charges as\nshown in Figure 3. Denote the expected values of the single-channel random variables as follows:\nthe conductance as ga(t), gb(t), and gc(t); the ionic currents as ia(t), ib(t), and ic(t); the gating\ncharges as qa(t), qb(t), and qc(t); the gating currents as iga(t), igb(t), and igc(t).\na) Which of the waveforms shown in Figure 4 best represents gb(t)? Explain.\nb) Which of the waveforms shown in Figure 4 best represents gc(t)? Explain.\n\n0.5\n0.5\n1.5\nState occupancy probability\nVm(t)\nS1\nS2\nS3\nx1(t)\nx2(t)\nx3(t)\nTime (ms)\nFigure 2: State diagram and occupancy probabilities for a three-state channel. The state occupancy\nprobabilities for states S1, S2, and S3 are x1(t), x2(t), and x3(t), respectively.\nChannel a\n\nChannel b\n°1\n°1\n°2\n°2\n°3\n°3\nS1\nS2\nS3\nS1\nS2\nS3\nQ1 = -1\nQ1\nQ2\nQ2\nQ3\nQ3\n= 10\n= 0\n= 0\n= 10\n= 0\n= 0\n= 0\n= 0\n= 0\n= 0\n= 1\nChannel c\n\n°1\n°2\n°3\nS1\nS2\nS3\nQ1\nQ2\nQ3\n= 0\n= 0\n= 10\n= 1\n= 0\n= 0\nFigure 3: State diagrams of three three-state channel models. The models differ in state conduc\ntances and state gating charge but not in rate constants.\nc) Which of the waveforms shown in Figure 4 best represents iga(t)? Explain.\nd) Which of the waveforms shown in Figure 4 best represents igc(t)? Explain.\ne) Which of these channel models exhibits activation followed by inactivation of the ionic cur\nrent? Explain.\nf) Which of these channel models exhibits an ionic current that does not inactivate? Explain.\ng) Which of these channel models represents a channel that closes on depolarization? Explain.\n\nt\nt\nVm(t)\nVm(t)\nw1(t)\nw2(t)\nw3(t)\nw4(t)\nw5(t)\nw6(t)\nw7(t)\nw8(t)\nFigure 4: Waveforms of responses. The horizontal axis corresponds to w(t) = 0, and the vertical\naxis to t = 0.\nProblem 5. Figure 5 shows a model of a voltage-gated ion channel with one three-state gate plus\nrepresentative single-channel ionic and gating current records.\na) Assume that the voltage-current characteristic of the channel is the same for states 1 and 3\nand is linear. Determine the open channel conductance and equilibrium (reversal) potential\nfor this channel.\nb) The ionic current trace shown in Figure 5 has three non-zero segments. Determine which\nstate the gate is in during each non-zero segment. Explain your reasoning.\nc) Figure 6 illustrates the dependence of the steady-state probability that the channel will be\nin each of its three states on the membrane potential. Let iss represent the average value\nof the ionic current that results after steady-state conditions are reached in a voltage clamp\nexperiment in which Vm is held constant. Assume that the experiment is repeated for a\nnumber of different values of membrane potential Vm. Plot the relation between iss and Vm.\nDescribe the important features of your plot.\n\nstate 1\nt (ms)\n+50\n-50\ninside\noutside\n-\n-\n-\n-\n+\nVm (mV)\nstate 2\ni (pA)\nt (ms)\ninside\noutside\n-\n-\n-\n-\n+\nstate 3\nt (ms)\ninside\noutside\n-\n-\n-\n-\n+\nig (pA)\nFigure 5: Channel with one three-state gate. The left panels illustrate the three states: states 1 and\n3 are open states, state 2 is a closed state. The right panels illustrate the responses of the channel\nto a step in membrane potential Vm(t) at time t = 0 (top right) which gives rise to the ionic current\ni(t) and gating current ig (t) illustrated in the middle right and lower right panels, respectively.\n-100\n0.5\nx11\nx21\nx31\nMembrane potential (mV)\nFigure 6: Steady-state probabilities for a channel with one three-state gate. x11, x21, and x31\nrepresent the steady-state probabilities of being in state 1, state 2, and state 3, respectively, as a\nfunction of membrane potential."
    },
    {
      "category": "Resource",
      "title": "hhprojects.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/ba544804eab386e987d1026e4e36ad93_hhprojects.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science,\nDepartment of Mechanical Engineering,\nDivision of Bioengineering and Environmental Health,\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE.370J/BE.470J/HST.541J\nHodgkin-Huxley Project\nThis theoretical project is intended to provide an opportunity to learn about the complex behav\niors that can be exhibited by the Hodgkin-Huxley model and to compare behaviors of the model\nwith behaviors of electrically excitable cells. We have two simulations. The first models a space-\nclamped axon. That model generates membrane action potentials. The second models an axon\nwithout space-clamp (although the second model can simulate a space clamp since the longitudi\nnal resistances can be set to zero). The second model can produce propagated action potentials.\nThe second model can be used to explore a wider range of phenomena than the first. The first\nmodel is faster and simpler than the second. Thus both models are useful, and your project can use\neither or both of the models.\nStudents are STRONGLY encouraged to work in pairs, however, individual projects will be\napproved if there are extenuating circumstances. If a pair of students collaborate on a project they\nshould submit a single proposal and a single report which identifies both members of the team and\ngives both email addresses. Proposals should be submitted via the form available on the MIT\nserver. Proposals will be returned as soon as possible so that students can revise them. Only the\nfinal, accepted proposal will be given a grade.\nThe demonstration project performed in lecture on the effect of temperature cannot be the basis\nof a student project.\nPractical considerations in the choice of a topic\nProjects can involve almost any of the properties of the Hodgkin-Huxley model. However, to avoid\nprojects whose aims are vague (e.g., \"I would like to understand how the Hodgkin-Huxley model\nworks\") the proposed project should be in the form of a specific and testable hypothesis. Projects\nthat involve months of computation should obviously be avoided. The amount of computation time\nshould be explicitly taken into account in planning a project. For example, any project that involves\nmeasuring the threshold of occurrence of an action potential for many different parameter values is\nbound to be very time consuming, because determining the threshold for a single set of parameters\nitself involves many computations. The task is to choose a physiological property of the excitation\nof the action potential that is of interest, and then to define a specific, feasible project.\nChoice of topics\nTopics can involve comparing predictions of the Hodgkin-Huxley model with measurements on\ncells. For example, the text contains data on the effects of many external parameters (e.g., ionic\nconcentrations, cell type) on action potentials. A project might involve reading the original pa\npers that describe such measurements (some were made before the Hodgkin-Huxley model was\nformulated), and testing the hypothesis that these measurements are (or are not) consistent with\n\nthe Hodgkin-Huxley model. Similarly, a project might involve examining the effect of some phar\nmacological substance on measurements of the action potential and testing the hypothesis that the\nsubstance produces its effect by changing one or another parameter of the model. These projects\nwill require some reading of original literature which is often difficult and usually time consuming.\nHowever, such a project can lead to a very rewarding educational experience. Alternatively, the\nproject might involve a purely theoretical topic in which some property of the model is explained\nin terms of its underlying structure. This type of project does not necessarily involve reading the\noriginal literature.\nExamples of hypotheses\n1. Hypothesis -- The effect of temperature on the conduction velocity of the squid giant axon\ncan be fit by the Hodgkin-Huxley model. Articles in the literature should be consulted for\nthis project:\n- Chapman, R. A. (1967). Dependence on temperature of the conduction velocity of the\naction potential of the squid giant axon. J. Physiol. 213:1143-1144.\n- Easton, D. M. and Swenberg, C. E. (1975). Temperature and impulse velocity in giant\naxon of squid loligo pealei. Am. J. Physiol. 229:1249-1253.\n2. Hypothesis -- When two action potentials are elicited, one just after another, the velocity\nof the second is slower than the velocity of the first action potential. This phenomenon is\npredicted by the Hodgkin-Huxley model. Articles in the literature should be consulted for\nthis project:\n- George, S. A., Mastronarde, D. N., and Dubin, M. W. (1984). Prior activity influences\nthe velocity of impulses in frog and cat optic nerve fibers. Brain Res. 304:121-126.\n3. Hypothesis -- The threshold current for eliciting an action potential with an intracellular\nelectrode is higher for a space-clamped than for an unclamped model of an axon.\n4. Hypothesis -- Increasing the membrane capacitance will decrease the conduction velocity.\n5. Hypothesis -- Increasing the membrane conductance (by scaling all the ionic conductances)\nwill increase the conduction velocity.\n6. Hypothesis -- Increasing the external concentration of sodium will increase the conduction\nvelocity.\n7. Hypothesis -- Increasing the external concentration of potassium will increase the conduc\ntion velocity.\n8. Hypothesis -- Increasing the external concentration of calcium will increase the conduction\nvelocity.\n9. Hypothesis -- Increasing the temperature will increase the conduction velocity.\n10. Hypothesis -- The difference in waveform of the action potential of a frog node of Ranvier\nand of a squid giant axon (Figure 1.9 in volume 2 of the text) can be reproduced by the\nHodgkin-Huxley model of a squid giant axon by a change in temperature.\n\n11. Hypothesis -- The membrane capacitance determines the time course of the rising phase of\nthe action potential. Increasing the membrane capacitance decreases the rate of increase of\nthe rising phase of the action potential.\n12. Hypothesis -- The falling phase of the action potential (repolarization) can occur in the\nabsence of a change in potassium conductance.\n13. Hypothesis -- Increasing the temperature sufficiently blocks the occurrence of the action\npotential because the membrane time constant limits the rate at which the membrane vari\nables can change and prevents the difference in time course of the sodium and potassium\nactivation which is responsible for initiation of the action potential.\n14. Hypothesis -- The initiation of the action potential is independent of the potassium conduc\ntance.\n15. Hypothesis -- The prolonged plateau of the cardiac muscle action potential can be accounted\nfor by the Hodgkin-Huxley model with a potassium conductance that has a slow activation.\n16. Hypothesis -- The effect of tetraethylammonium chloride (TEA) on the action potential of\nthe squid giant axon can be modelled with the Hodgkin Huxley model by decreasing Kn and\nincreasing Kh. Articles in the literature should be consulted for this project:\n- Armstrong, C. M. (1966). Time course of TEA+-induced anamalous rectification in\nsquid giant axons. J. Gen. Physiol. 50:491-503.\n- Armstrong, C. M. and Binstock, L. (1965). Anomalous rectification in the squid giant\naxon injected with tetraethylammonium chloride. J. Gen. Physiol. 48:859-872.\n- Tasaki, I. and Hagiwara, S. (1957). Demonstration of two stable potential states in the\nsquid giant axon under tetraethylammonium chloride. J. Gen. Physiol. 40:859-885.\n17. Hypothesis -- The shape of the action potential in the presence of tetraethylammonium chlo\nride (TEA) can be accounted for by the Hodgkin-Huxley model with a reduced maximum\nvalue of the potassium conductance. Articles in the literature should be consulted for this\nproject:\n- Armstrong, C. M. (1966). Time course of TEA+-induced anamalous rectification in\nsquid giant axons. J. Gen. Physiol. 50:491-503.\n- Armstrong, C. M. and Binstock, L. (1965). Anomalous rectification in the squid giant\naxon injected with tetraethylammonium chloride. J. Gen. Physiol. 48:859-872.\n- Tasaki, I. and Hagiwara, S. (1957). Demonstration of two stable potential states in the\nsquid giant axon under tetraethylammonium chloride. J. Gen. Physiol. 40:859-885.\n18. Hypothesis -- Increasing the external calcium concentration will block the occurrence of the\naction potential because this will reduce the difference in the time constant of sodium and\npotassium activation which is responsible for the initiation of the action potential.\n19. Hypothesis -- Increasing the external concentration of potassium will decrease the refractory\nperiod; decreasing this concentration will lengthen the refractory period.\n20. Hypothesis -- Increasing the external concentration of sodium will decrease the refractory\nperiod; decreasing this concentration will lengthen the refractory period.\n\n21. Hypothesis -- Absolute and relative refractory periods are decreased by increasing the rate\nconstants for sodium inactivation and for potassium activation.\n22. Hypothesis -- Repolarization cannot occur if the potassium activation rate constant is zero.\n23. Hypothesis -- The threshold of the action potential to a brief pulse of current decreases as\nthe external potassium current is increased.\n24. The Hodgkin-Huxley model with default parameters does not exhibit accommodation. Hy\npothesis -- Accommodation occurs if the leakage conductance is increased.\n25. The Hodgkin-Huxley model with default parameters does not exhibit accommodation. Hy\npothesis -- Accommodation occurs if the potassium conductance is increased.\n26. Hypothesis -- Increasing the leakage equilibrium potential will block the action potential.\n27. Hypothesis -- The effect of the changes in concentration of sodium ions on the action po\ntential of the giant axon of the squid can be accounted for by the Hodgkin-Huxley model.\nArticles in the literature should be consulted for this project:\n- Hodgkin A. L. and Katz, B. (1949). The effect of sodium ions on the electrical activity\nof the giant axon of the squid. J. Physiol. 108:37-77.\n- Baker, P. F., Hodgkin, A. L., and Shaw, T. I. (1961). Replacement of the protoplasm of\na giant nerve fibre with artificial solutions. Nature 190:885-887.\n28. Hypothesis -- In response to rectangular pulses of current, the rheobase of the strength-\nduration relation increases as temperature increases.\n29. Hypothesis -- An increase in temperature results in a decrease in the duration of the refrac\ntory period.\n30. Hypothesis -- The threshold membrane potential at which the Hodgkin-Huxley model pro\nduces an action potential in response to a brief pulse of current is equal to the membrane\npotential for which the linearized Hodgkin-Huxley equations have unstable eigenvalues.\n31. Application of a long-duration constant current to the Hodgkin-Huxley model produces a\ntrain of action potentials. Hypothesis -- The frequency of the action potentials increases\nwith increasing current amplitude.\n32. Application of a long-duration constant current to the Hodgkin-Huxley model produces a\ntrain of action potentials. Hypothesis -- The frequency of action potential increases as the\nparameter Kn is increased.\n33. Application of a long-duration constant current to the Hodgkin-Huxley model produces a\ntrain of action potentials. Hypothesis -- The frequency of action potential increases as the\ntemperature is increased.\n34. Hypothesis -- An increase in the external concentration of potassium increases the threshold\npotential at which an action potential is elicited.\n35. Hypothesis -- Increasing Kh will result in an increase in the steepness of the repolarization\nphase of the action potential.\n\nAny of these (or other) hypotheses can be the starting point for a project. Most of the hy\npotheses given above are simplistic, and a careful investigation will reveal their shortcomings. The\nHodgkin-Huxley model is sufficiently complex that investigation of any of the hypotheses will\nmost likely lead to unexpected results. You should pursue these unexpected results and try to un\nderstand their bases. For example, you may find that in pursuing some hypothesis you choose to\nchange some parameter of the model that you expect to result in some change in action potential\nwaveform. The resulting computation might reveal, much to your surprise and chagrin, that no\naction potential has occurred. Determine why no action potential occurred. The explanation will\nusually be instructive. Your aim should be not simply to reject or accept the hypothesis but to delve\ninto the topic in sufficient depth so as to a deepen your understanding of the model. One outcome\nof the project might be to restate your original hypothesis in a new and more sophisticated form.\nBeginning with the proposal and extending through the project, you should keep clearly in\nmind that you are not investigating nerve membrane in these exercises. You are investigating\nthe Hodgkin-Huxley model for nerve membrane. Your explanations of all phenomena must be\nin terms of the primitive concepts of this model -- the ionic conductances, ionic concentrations,\nionic currents, the capacitance, and the variables m, n, and h. Explanations in terms of molecular\nchannel mechanisms or electrodiffusion of ions in the membrane are irrelevant in so far as they are\nnot contained in the Hodgkin-Huxley model!"
    },
    {
      "category": "Resource",
      "title": "analysis_micro_03.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/c4e637b3505697f95c9dc9fdb4d00753_analysis_micro_03.pdf",
      "content": "In order to read your data use the command imread\nA = imread('FILENAME','bmp')\nThis will create a 3-D (480 rows, 640 columns, 3 deep) array.\nThe command image(A) will display the snapshot associated with FILENAME.bmp.\n(Fig. 1)\nFig.1 Snapshot at 3 mm down the channel (image(A)).\nSuperimposed vertical line indicates the axis\nwhose profile will be further analyzed.\nYou can choose to selectively display the red, green or blue components of the image by\ntyping image(A(:,:,1)), image(A(:,:,2)) or image(A(:,:,3)) respectively.\nThe command plot will allow you to display single line profiles, much like the camscope\nsoftware. You will need to specify the line index, for instance plot(A(:,100,3)) displays\nthe blue profile along the axis defined by the line passing through the 100th pixel on the y\naxis (Fig.2).\nIf you wish to do any operation on the profile, such as averaging, you must first convert\nthe numbers to double precision format. To do this, use the command double.\nProfile = double(A(:,100,3));\nAverage_Profile = (double(A(:,100,3)) + double(A(:,101,3))) / 2 will give you the\naverage of two adjacent profiles.\n\nFig. 2 Blue absorption profile along\nFig. 3\nplot(flipud(A(:,100,3))\naxis indicated in Fig. 1 (plot(A(:,100,3)))\nSame as Fig.2 (\nThe command \"flipud\" will allow you to reverse the x axis so you can plot the profile as\nan increasing function of distance.\nplot(flipud(A(:,100,3) will yield Fig.3.\nYou will also find the function erf useful if you wish to compare the measured profile to\nthe integral of a gaussian function.\n120*(erf((x -200)/(sqrt(2)*10)) + 1) + 50 yields the integral of a gaussian distribution\nwith ? = 200, ? = 10, amplitude = 120 and offset = 50.\nFig. 4. Measured profile along with\nintegral of gaussian distribution."
    },
    {
      "category": "Resource",
      "title": "micfluiprolab_03.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/f2563f7e51412b4aa5e5e69afce5111c_micfluiprolab_03.pdf",
      "content": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDepartment of Electrical Engineering and Computer Science\nDepartment of Mechanical Engineering\nDivision of Bioengineering and Environmental Health\nHarvard-MIT Division of Health Sciences and Technology\nQuantitative Physiology: Cells and Tissues\n2.791J/2.794J/6.021J/6.521J/BE370J/BE470J/HST541J\nFall, 2003\nMicroFluidics Project Laboratory\n\nIntroduction\nThis page contains helpful information about the proposal, experimentation, analysis, and\nreport-writing stages of this laboratory. You should read through it at each stage to make\nsure you understand what is required.\nOverview\nThis laboratory project is intended to provide an opportunity to learn about\n1. designing an experiment,\n2. acquiring, processing, and interpreting experimental data, and\n3. communicating the results to others.\nThis laboratory project is also intended to introduce the emerging field of microfluidics.\nMicrofluidics refers to the use of devices in which fluid flows are restricted to channels\nwith micrometer dimensions. Such devices are interesting for at least 3 reasons:\n1. Microfluidic devices can be manufactured using photolithographic techniques that\nallow many devices to be constructed simultaneously (just as modern electronic\ndevices are manufactured). Bulk manufacturing reduces the cost per device.\n\n2. Since they are small, many devices can be fit into a small volume, leading to the\nidea of total \"labs-on-a-chip\" replacing labs that occupy benches or even whole\nrooms today.\n3. Flows in microscopic chambers can exhibit behaviors that are difficult or\nimpossible to produce in macroscopic chambers. These flow regimes can be used\nto simplify measurements that are difficult or impossible to make\nmacroscopically.\nThis laboratory project is intended to take advantage of microfluidics to measure the\nproperties of molecular transport by diffusion.\nMicrofluidics\nMore than any other single factor, bulk fabrication has made possible today's vast array\nof powerful and inexpensive electronic devices. The millions of components in a modern\ncomputer are fabricated in parallel, making the manufacture of such integrated circuits\nlittle more costly than the manufacture of circuits that contain only tens of components.\nSimilar bulk fabrication techniques are currently being developed for fluidic devices, and\nthe resulting microfluidic devices hold promise to similarly revolutionize chemical and\nbiochemical analysis systems. For example, the integration of all of the components\nneeded for the sequencing of DNA (i.e., valves to control flows, incubation chambers,\nmixing chambers, heating/cooling chambers) may soon allow \"labs-on-a-chip\" to replace\nwhole biochemistry labs.\nMicrofluidic devices are smaller than conventional macrofluidic components, and their\nsmaller size facilitates many kinds of analysis. For example, when two fluids come into\ncontact, they mix by a variety of mechanisms. The most familiar mechanism from our\nmacroscopic experiences is convection: i.e., the mixing of fluids caused by motions of\nfluid, as in stirring. When fluids are constrained to small volumes, convection is\nconstrained and mixing results almost entirely by diffusion (i.e., by random collisions\nbetween molecules). As a result, it is possible to design microfluidic systems in which\ndissimilar fluids flow along side each other over long distances without significant\nmixing. Such \"laminar-flow\" profiles are difficult or impossible to produce\nmacroscopically and provide unique opportunities to study molecular transport by\ndiffusion.\nMethods\nThis section describes basic experimental methods used in microfluidic systems. The\ndescriptions are not complete: you are encouraged to devise more detailed procedures\nwhere appropriate. You may also substitute your own novel methods. However, if your\nnovel methods require the use of additional equipment, you are responsible for obtaining\nthat equipment. The staff is only responsible for supplying the equipment described in\nthis section.\n\nIn this experiment, you will use dyes and other chemicals that could stain or irritate your\nskin. Wash your hands thoroughly immediately after exposure to any chemicals. Clean up\nminor chemical spills immediately. Report major spills to the staff. Rubber gloves will be\navailable.\nNo foods or beverages will be allowed in the laboratory.\nChambers\nOur experiment chambers are 2-dimensional microscopic channels formed on the surface\nof a transparent silicone rubber. The silicone rubber is then bonded to glass slide.\nFabrication methods can be found in the literature (Whitesides-1998).\nThe following figure shows the topology. The channels are 500 &mum wide and\napproximately 100 &mum deep. The inlet channels are approximately 25 mm long. The\noutlet channel is approximately 35 mm long.\n\nEstablishing Fluid Flow\nA variety of methods have been used to pump fluids through microchambers. Some\ninvestigators use macroscopic pumps (e.g., syringe pumps, peristaltic pumps, etc.).\nOthers use electrically driven flows (e.g., electro-osmosis or electrophoresis). In this lab,\nwe recommend that you use gravity flow. With our channel designs, a few millimeter\ndifference in fluid level is sufficient to drive flow rates on the order of micrometers per\nsecond, which are satisfactory for most experiment designs.\nInput and output ports connect the microfluidic channels to macroscopic fluid reservoirs,\nas shown in the following photograph.\n\nWhile gravity feed is simple to implement, it is also very sensitive to external\ndisturbances, such as table vibrations. Be aware that even atmospheric disturbances\n(caused by breathing) can affect your results.\nGravity feed can also be difficult to start. We recommend the following procedure for\nfilling your chamber with fluid.\n-\nFill the input reservoir(s) approximately 2/3's full with the desired liquids, taking\ncare not to introduce any foreign matter, and not to break the reservoirs off of the\nslide.\n-\nCarefully attach the provided syringe to the output reservoir, and use the syringe\nto gently pull liquid through the channel. Watch the channel carefully to see if\nliquid has been pulled through. Because of the small width of the channel, you\nmay not build up a noticeable amount of liquid in the output reservoir, but if the\nchannel is full, the experiment will work fine.\n-\nNow fill the output chamber with liquid until the liquid reaches approximately the\nsame height as the input chambers. You are now ready to begin observation of\nyour channel.\n\nPlease take care when using these chambers. They are easily broken. Always flush your\nchamber with deionized water after use. If saline solutions are allowed to evaporate, the\nsalts will clog the channels and solids are not easily removed.\nMicroscope\nOur microscopes have been customized for this microfluidics laboratory, as shown\nbelow.\n\nThe microfluidics chambers can be clamped to the stage of the microscope using a slide\nholder that has two position control knobs. The microscope has 3 objectives: 4X, 10X,\nand 20X. These objectives focus an image of the chamber onto a video camera.\nIllumination is provided by LEDs and can come from the top (epi-illumination) or bottom\n(trans-illumination). Epi-illumination works best for fluorescent imaging and trans-\nillumination works best for brightfield illumination. The microscope has a focus control\nknob that allows focusing with &mum resolution.\nPlease avoid touching the optical components. They are sensitive, and easily scratched.\nEven fingerprints can badly degrade the images you will get.\n\nMeasuring Flow Rates\nQuantitative interpretation of data from microfluidic systems often requires knowledge of\nthe flow rates. Although flow rates can in principle be determined by measuring the time\nit takes for some known volume of fluid to flow through system, it is often more\nconvenient to measure flow rates by tracking microscopic particles that are suspended in\nthe fluid. Microscopic polystyrene beads with diameters on the order of 1 &mum are\navailable for this purpose. Bead solutions can be used in separate experiments to calibrate\nflow rates. Alternatively, beads can be added to test solutions to directly measure the flow\nrates of test solutions. If the concentration of beads is dilute and if the flow rates are slow,\nthen individual beads can be tracked across frames that are recorded at a 10-30\nframe/second rate (depending on the speed of the computer). If the concentration of beads\nis dense or if the flow rates are high, then the LED can be pulsed to produce a\nstroboscopic illumination with multiple strobes per frame. Then multiple images of each\nbead on a single frame can be analyzed to determine the flow rate.\nComputer\nA computer running Linux is attached to the video camera via FireWire. A program\ncalled camscope can be used to view and record images and brightness profiles.\nActivating the Software\nThe main program for acquiring and processing data is called camscope. Source code for\ncamscope is available at http://www.sourceforge.net/projects/camscope.. This program\nstores results and temporary files in the current working directory. At the login prompt,\nlog in with the username knoppix and the password knoppix. To avoid confusing your\ndata with that of another group, each laboratory group should store results in a separate\ndirectory. Please use the following naming convention. If you are in laboratory group B2,\nthen type the Linux commands\n> cd\n> mkdir B2\n> cd B2\nto make a new directory named B2 and to make that directory the current working\ndirectory. Then type\n> camscope\nto activate the main program. The camscope program provides facilities to view and\nrecord images and to view and record simple brightness profiles. All of these facilities are\ndirectly accessible from a single main control screen illustrated in the following figure.\n\nButtons on the right provide the following functions (top to bottom, with keyboard\nshortcuts in parentheses):\n- EXIT (ctrl-q): terminate camscope and return to Linux prompt.\n- PLAY (ctrl-p): display live images from video camera, or loop through previously\nrecorded images if the program is in Analyze mode.\n- PAUSE (ctrl-z): stop displaying new images and hold last one displayed.\n- RECORD (ctrl-r): start recording images and brightness traces. Records ten images\nand then stops (your TA can change this behavior if needed, but it is your responsibility\nto make sure your measurements fit on a CD). Note: pressing the record button takes you\nout of Analyze mode.\n- SNAPSHOT (ctrl-s): record a singe image and associated brightness traces.\n- STOP (ctrl-b): stop recording.\n- Analyze (ctrl-a): toggles Analyze mode, which displays previously recorded images.\n- BACK (ctrl-left_arrow): display previous recorded image (only works in Analyze\nmode).\n- NEXT (ctrl-right_arrow): display next recorded image (only works in Analyze mode).\n- Screen Capture (ctrl-d): save image of screen (screendump).\nUsing Multiple Data Sets to Organize Your Measurements\nIn addition to these buttons, the upper left corner of the screen has + and - buttons (with\nkeyboard shortcuts ctrl-. (period) and ctrl-, (comma) respectively). These buttons control\nwhich data set is currently being recorded or analyzed. All of camscope's other features\n\n(record, analyze, playback, etc) operate on only the current data set (which can be\nchanged on the fly). Although you can do the entire lab without using multiple data sets,\nthey are extremely useful for organizing your data. You should use a separate data set for\neach type of measurement, and for each measurement location. Be sure to make a note in\nyour protocol book about which data set corresponds to which measurement!\nManual Gain Control\nBy default, the camera uses automatic gain control to set the brightness and exposure\ntime to levels that give a good image. However, in some cases you may wish to manually\nset these values in order to quantitatively compare brightnesses under different lighting\nconditions (for example, comparing brightnesses with two different dye concentrations in\nthe chamber). Although there are no buttons to adjust these values, you can use the\nfollowing keyboard shortcuts:\n- Ctrl-1: turn down the brightness by 3 points (brightness varies from 0 to 511).\n- Ctrl-2: turn up the brightness by 3 points.\n- Ctrl-3: turn on auto-brightness (Ctrl-1 and Ctrl-2 both turn it off).\n- Ctrl-5: turn down the exposure by 3 points (exposure varies from 0 to 511).\n- Ctrl-6: turn up the exposure by 3 points.\n- Ctrl-7: turn on auto-exposure (Ctrl-1 and Ctrl-2 both turn it off).\n- Ctrl-9: turn down the color saturation by 3 points (saturation varies from 0 to 255, and\nhas no auto mode).\n- Ctrl-0: turn up the saturation by 3 points. When any of these keys is pressed, the\ncurrent values of these parameters are printed to the console.\nTaking Measurements\nCamscope allows you to make quantitative measurements both in real-time and from\npreviously recorded images, by switching to/from Analyze mode. Several types of\nmeasurements can be made:\n1. Pixel Values: When the cursor is moved into the image, the position of the cursor\nand the RGB values of the pixel at that position are displayed in the lower right.\n2. Line Plots: When the cursor is moved into the image, its vertical (and horizontal)\nposition selects a line (and column) whose brightness is displayed below (and to\nthe side of) the image. When images are being recorded, the red, green, and blue\nintensities in these brightness contours are also saved as text files (the Ctrl-r and\nCtrl-s keyboard shortcuts are handy for saving files while the cursor is in the\nimage).\n3. Average Brightness: When a box is drawn with the right mouse button, the\naverage RGB values within the box are displayed in the lower right corner of the\nscreen.\n4. Distance/Velocity: When a line is drawn by holding the left mouse button and\ndragging the mouse, the x, y, and total distance of the line is displayed in pixels at\nthe bottom of the screen. In addition, the velocity is computed automatically by\n\nsubtracting the time at which the line was started from the current time (in\nAnalyze mode, the times at which the images were acquired are used instead). To\nmeasure the velocity of a bead in Analyze mode, for example, you would click\nand hold the mouse button over a bead, press Ctrl-right_arrow to switch to the\nnext image (or to skip through several images), and move the pointer to the new\nbead position. The velocity of the bead will be reported at the bottom of the\nscreen, next to the distance.\nFile Formats\nImages are recorded sequentially as .BMP files. The first image recorded into an empty\ndirectory is named image.000.000000.bmp, the second is named\nimage.000.000001.bmp, and so on. Changing the data set changes the three-digit\nnumber near the beginning of the file, and resets the six-digit counter to zero. If the\ncursor is in the image at the time of recording, a text file is also created that contains the\nred, green, and blue intensities that were displayed below and to the right of the image.\nThe text file associated with image.000.000000.bmp is named info.000.000000.txt.\nScreen dumps are saved in a similar sequential fashion, with the first one named\nprint.000.000000.bmp.\nSaving Your Results\nWhen you are ready to leave the lab, you should save your data. We cannot guarantee\nthat your data will be preserved on the lab computer, so copy everything before you\nleave. The easiest way to save your data is to record it on a CD. Put a blank CD into the\nCD burner and type\ncdcp .\nat the linux prompt. This command will record a CD that contains all of the files the\nworking directory (i.e., \".\") and its subdirectories. If your directory is larger than the size\nof one CD (about 700 MB), you will need to split your data into multiple subdirectories\nand copy each onto a separate CD. Your TA can help you do this.\nAnalyzing Results\nThe camscope program is intended to provide sufficient information for you to monitor\nhow your experiment is proceeding while you are in the lab. This is important so that you\ncan discover problems and fix the problems before taking your final data. It is also\nimportant so that you have a good idea that your experiment was successful or not before\nyou leave the lab. If you discover problems with your data, it is generally easier to take\nnew data now than it is to come back at a later time and start again.\nResults from camscope can also be directly incorporated into your final report. However,\nquantitative statistics to test specific hypotheses generally require additional analyses,\nbased on images and brightness profiles saved by the camscope program. Every time\n\ncamscope takes a picture, it saves the image as a .BMP file. When the cursor marks a\n\"line-of-interest\" and a \"column-of-interest\" at the time that an image is recorded, the red,\ngreen, and blue intensitives of those lines and columns of interest are also recorded as\n\"info\" files (see \"File Formats\" above). The following figure shows a graphical\nrepresentation of these two files.\n\nIntensity Profiles\nThe numbers in the info files can also be read by text processing / spreadsheet / plotting\nprograms and used to generate plots. The following figure shows the red, green, and blue\ntraces obtained from the center lines of two images saved at different times by camscope.\n\nSome trends are easy to see just from the traces. However, the traces are noisy, and\naveraging can give more reliable statistics. Brightnesses can be averaged in the horizontal\nor vertical direction from the line-of-interest and column-of-interest numbers contained in\na single info file. Brightnesses can be averaged across time by combining information\ncontained in many info files. Arbitrary analyses are possible by calculating directly from\nthe images. Many software packages, including Matlab, provides functions that access\nbrightness values in .bmp image files.\nMore meaningful statistics can be generated from analytic theories and/or simulations.\nThe course software (available on the MIT server) can be used to calculate solutions to the\ndiffusion equation. The following plots show calculated concentration profiles for solute\nconfined in a 1D box for 3 successive times starting from an initial step concentration.\n\nThese plots illustrate that as time proceeds, the concentration profile flattens. Based on\nthis observation, one might measure the slope of the brightness contour measured in the\ncenter of the laminar flow chamber and compare that slope the one measured in the\nsimulation. Alternatively, one might measure the minimum and maximum brightnesses\nand compare those statistics to the simulation. The following figure illustrate some\npotentially meaningful statistics to extract from brightness contours. You may be able to\nsuggest better statistics for your particular study.\n\nYou could also analyze your data by comparing it to an analytic theory. Such a theory is\ndeveloped in the course text (volume 1, Figure 3.16). Based on that theory, we expect the\nconcentration profiles to be integrals of the gauss function (i.e., the error function, erf).\nOne could find the erf function that best fits the measured brightness contours as a way to\nestimate how much diffusion has occured.\nEach of these analysis methods has advantages and disadvantages. Fitting the data with a\nknown function takes advantage of ALL the brightness data, and may therefore be good\nfor reducing the effects of measurement noise. However, the erf analysis does not take\nthe walls of the laminar flow chamber into account. Numerical analysis, using the course\nsoftware or some user written code, can take the walls into account, and thereby be more\naccurate. However, numerical analysis may be more difficult to implement.\nThere is not single best way to analyse your data. Simple methods are fine so long as\ntheir limitations are taken into account. Part of your project should be developing an\nanalysis method that makes sense for the question that you are addressing.\nExperiments\nBasic Observations: Laminar Flow and Diffusion\nBefore beginning your project, you should perform a vew basic observations to\nfamiliarize yourself with the equipment.\n\nDraw about 1 mL of deionized water into an empty syringe. Add 100 &muL of\nmicrospheres to the syringe. Draw a few mL of air into the syringe and shake to disperse\nthe microspheres. Fill one input reservoir of a laminar flow chamber with this fluid.\nRepeat the procedure, substituting food coloring for deionized water, and fill the second\ninput reservoir.\nFilling the input reservoirs will not necessarily start the flow. To start the flow, carefully\nattach the provided syringe to the output reservoir, and use the syringe to gently pull\nliquid through the channel. Watch the channel carefully to see if liquid has been pulled\nthrough. Because of the small cross-sectional area of the channel, you may not be able to\nsee fluid in the output reservoir even after the flow has started.\nMove the chamber to the video microscope. Start the camscope program. Position the\nstage so that you see the microchannel. Positioning can be tricky: you must get the\nmicrochannel centered under the objective AND in focus in order to see any image at all!\nWhen properly focused, you should see microspheres streaking across the image. Add or\nremove liquid to the input and output reservoirs to adjust the flow rate. Measure the flow\nrate by recording a sequence of images and measuring the distance traved by one\nmicrosphere per frame. Are all of the beads moving at the same velocity? Should they\nmove at the same velocity?\nYou should see laminar flow. Estimate the maximum spatial gradient of brightness. is the\nmaximum centered in the microchannel? Should it be centered? Can you make it more\noff center?\nProjects\nYour project is the main educational experience of this laboratory. You and your partner\nshould plan your project well in advance of going to the laboratory. This section lists\nseveral topics that you could explore as your project. You may choose one of these or\nyou can construct an entirely new one. The descriptions given here are incomplete. Your\nplan should be well-defined. Keep it simple so that you can complete the work, including\nsome preliminary plotting of results and thinking about interpretation within a several-\nhour lab session. You may also want time to check your interpretation by taking\nadditional measurements.\nLinearity of Fick's Law\nMotivation: Fick's law states that the diffusive flux of a solute should be proportional to\nthe gradient of concentration of that solute. Design an experiment to test if this is true.\nHypothesis: The flux of a solute is proportional to the gradient of the concentration of\nthat solute and is independent of the absolute concentration of solute.\n\nMethod: Perform laminar flow experiments with pairs of solutions with concentrations X\nand X+Y of dye. Vary X keeping Y constant and test whether the diffusive flux depends\non X.\nDiffusion of one Species in the Presence of Others\nMotivation: Fick's law states that the diffusive flux of a solute should be proportional to\nthe gradient of concentration of that solute and independent of the presense of other\nsolutes. Design an experiment to test if this is true.\nHypothesis: The flux of a solute is proportional to the gradient of the concentration of\nthat solute and is independent of the presence of other solutes.\nMethod: Perform laminar flow experiments with pairs of solutions with fixed differences\nin the concentration of dye but variable amounts of added glucose.\nEffect of Solvent on Diffusivity\nMotivation: According to the random walk model, solutes diffuse because they collide\nwith water molecules. Replacing water by a different solvent might change the number or\nmagnitude of these collisions.\nHypothesis: The diffusivity of a dye in water is greater than that of the same dye in oil.\nMethod: Perform laminar flow experiments with food coloring in one input reservoir and\neither water or oil in the other.\nAnalysis of Microfluidic Data\nMotivation: A typical laminar flow experiment can generate many megabytes of data.\nHow should one analyze this data to get the most information about diffusivity?\nHypothesis: Tracking the slope of concentration near the center of a laminar flow\nprovides more information about diffusivity that does tracking the width of the mixed\nregion.\nMethod: Determine transverse concentration profiles across a laminar flow at multiple\nlocations along the channel. Determine the spatial derivative of these concentrations\nacross that channel. According to the simple theory developed in lecture, these derivative\ncurves should have gaussian shapes. Compare estimates of diffusivity based on the\nheights and widths of these gaussian shapes.\nMicrofluidic Mixing\nMotivation: Microscale flows are dominated by viscosity. Therefore, mixing is primarily\nby diffusion. But can we actually ignore other mechanisms?\n\nHypothesis: Diffusion is not the only important mixing mechanism in laminar flow.\nMethod: Measure mixing of two fluids that contain particles that are so large that they\nshould not diffuse during the experiment (e.g., microspheres). Any mixing that occurs\ncould not be due to diffusion.\nPractical Considerations in Choosing a Topic\nProjects can involve any of the topics discussed above or a topic of your own creation. A\nwell thought-out project, whether based on one of the ones above or not, will usually\npromote better data collection, better report writing, and ultimately a better grade. If you\ncreate a novel project, you must obtain any supplies or equipment that is not part of the\nstandard laboratory setup described in Methods. For example, studying the diffusivity of\nsome large biological molecule like a drug molecule might be an interesting project.\nHowever, you are responsible for obtaining the biological molecule and determining a\nmethod to measure its concentration.\nWhen you choose your topic, remember that your experiment should take only a few\nhours to complete. Think through how many measurements you will need to make and\nhow long it will take to make each measurement.\nFormulate a specific and testable hypothesis, and center your project on that hypothesis.\nAvoid vague hypotheses, such as: \"I would like to understand how concentration affects\nthe diffusivity of dyes.\" Instead choose a more narrrowly focused hypothesis, such as:\n\"Increasing the concentration of dye to near saturation values will decrease the diffusivity\nof the dye.\" This more-focused hypothesis is testable: it can be true or false. If you form a\nclear hypothesis, you will be able to plan a logical set of measurements to test the\nhypothesis, and you will be able to come to a clear conclusion when you write your\nreport.\nWhen you do your experiment, you may get unexpected results. For example, you may\nhave planned to measure effects of glucose on the diffusivity of a dye. However, you may\nfind that the added glucose affects the velocity of flow in the chambers. You should\nexplore unexpected results and try to understand their bases. Your aim should be not\nsimply to reject or accept your hypothesis, but to develop insight into the phenomena. For\nexample, perhaps changes in velocity result from changes in viscosity and changes in\nviscosity of the medium affect your estimate of diffusivity. If so, the unanticipated\nchanges in velocity could be key to understanding the measured changes in diffusivity.\nKeep in mind that this is an experimental project. Your goal is to characterize what\nhappens, not why it is happening. Theoretical analyses may support your experimental\nfindings. However, your grade will be primarily based on the reliability of your data.\n\nControl observations are important parts of the design of any experiment. The purpose of\na control observation is to determine whether the variable that is directly manipulated by\nthe experimenter is the one that controls the change in response. Two common kinds of\ncontrol experiments test repeatability (i.e., if you make the same measurement several\ntimes, do you get the same answer) and reversibility (i.e., if you make a change and then\nundo it, does the response go back to what it was before the change), although other\ncontrol observations are often used. Suppose, for example, that you wish to determine the\neffect of adding glucose to the diffusion of a dye. You could measure the time-space\nevolution of dye concentration with no glucose, repeat the measurement with glucose,\nand compare. If the results are different, can you conclude that the reason is the glucose?\nWhat if you inadvertently filled the supply reservoirs differently in the two experiments?\nPerhaps the difference is because the flow rates were different, not because glucose was\nadded. Control observations are intended to assess the extent to which factors that are not\npart of the experimental design are contributing to response patterns. Simply repeating\nthe experiment with no glucose is a good way to assess many sources of error. Repeated\nsequences of measurements can be even better.\nProposals, Reports, and Logistics\nScheduling a Laboratory Session\nStudents should schedule a time slot for their laboratory session by submitting an\nelectronic schedule form. At that time, you may also request a partner. The laboratory\naccomodates 10 students in each session. We will work out the laboratory schedule in\nlecture 6. You have the best chance to get your most desired time slot by submitting your\nschedule form by lecture 5. After initial laboratory assignments have been made, you will\nbe permitted to change your laboratory session only if you request the change more than\n24 hours before your assigned slot and only if there is an open slot in the schedule at your\ndesired time.\nProposal\nYou and your partner should meet to plan your project and to write a proposal. The\nproposal should contain a brief statement of the hypothesis you propose to test and the\nmethod that you will use to test it. Include a list of the experiments you will perform and\nthe measurements you plan to make in each experiment. Indicate how the measurements\nwill be used to help you test your hypothesis. The proposal should fit on a single sheet of\npaper. A sample proposal is shown in following figure. The proposal should be submitted\nby lecture 5. You can submit your proposal electronically. The staff will review the\nproposals and make suggestions. Acceptable proposals will be APPROVED; flawed\nproposals will be REJECTED. Proposals that are not approved may be revised and\nresubmitted.\nProposal: Linearity of Mixing in Microchambers\nControl Observations\n\nPartner Names (E-mail):} Partner One (pone@email) and Partner Two\n(ptwo@email)\nHypothesis: The process by which fluids mix as they flow through microchambers is\nlinear.\nBackground: The primary mechanism by which fluids mix when they flow through\nmicrochambers is diffusion. Since diffusion is a linear process (i.e., the relation between\nflux and concentration gradient is linear), we expect that the fluid mixing in\nmicrochambers will be linear.\nProcedure: A laminar flow chamber with two inputs will be used to assess fluid mixing\nin microchambers. The concentration of dye in the two chambers will be investigated in 3\nconditions:\n\ninput 1 input 2\ncondition 1 0%\n50%\ncondition 2 50%\n50%\ncondition 3 50%\n100%\nMixing will be assessed by analyzing video images of the flow at a point 3 mm\ndownstream from the point where the laminar flow begins. Under the assumption that\nmixing is linear, the results for condition 3 should be the sum of the results for conditions\n1 and 2.\nTo increase the confidence in these results, images will also be obtained at 2 additional\nlocations. The entire experiment will then be repeated to assess effects of uncontrolled\nvariables, such as flow rate.\nLaboratory Notebook\nThe written record of your experiment is the original record of your work and the basis\nfor everything that you conclude. Such records should be kept in a laboratory notebook,\nwhich is typically a special notebook with sewn binding (not a loose-leaf notebook),\nwhose pages were numbered when the notebook was printed. Records should be written\nin ink. The laboratory notebook is the permanent record of your experiment.\nLaboratory notes should be sufficiently detailed so that (1) the experiment could be\nrepeated at some later time, (2) results from different experiments can be compared, and\n(3) so that your procedures can be reconstructed at a later time without relying on your\nmemory. The first page for each experiment should give the date and time, as well as a\nbrief description of the purpose of the experiment. All relevant procedures and\nobservations should be entered in the protocol book and the time should be indicated\nregularly.\n\nNothing should ever be erased. If an error is detected in some procedure or some reading,\nthat should be noted in the book. The original observation should under no circumstances\nbe obliterated so that it cannot be read. Perhaps you will subsequently find that the\noriginal observation was correct and that the correction was in error. The general rule is\nto write down everything that is done that may later become relevant. Scientists are rarely\nsorry that they wrote too much in the protocol book -- only that they wrote too little.\nYou do not have to purchase a special laboratory notebook for this project. However, we\ndo ask that you take laboratory notes during your experiment, as a step toward learning\nabout effective practices in experimental work. You will be asked to attach your notes to\nyour laboratory report, and we will assess these notes as part of the grading procedure.\nProject Report\nThe project report should be concise. Do not repeat material that is easily referenced. For\nexample, there is no need to reproduce any figure from this laboratory manual or from the\ncourse text: simply refer to it. Technical writing is necessarily directed at some particular\nintended audience. Write the project report as though it were to be published in a journal\nthat is read primarily by students who have taken this subject. Thus, you can assume\nsome working knowledge about the subject. The project report should contain the\nfollowing sections.\n-\nCover Page. On the cover page include the title of the laboratory session, the\nauthors' names, your laboratory subsection, the dates of the laboratory session(s),\nand the name of your partner (if not a co-author).\n-\nAbstract. The abstract is a one paragraph (<100 words) summary of the report\nincluding the question investigated, the methods used, and the principal results\nand conclusions. Your intended audience should be able to understand the abstract\nwithout having to read any of the report. This section should be written last.\n-\nIntroduction. The introduction is a brief section (about 1 page) designed to\nmotivate the reader. Include background information on the problem, hypotheses\nto be tested, significance of the work, etc. You may give citations to material in\nthis laboratory manual or elsewhere. The introduction should be directly relevant\nto your report; broad discussions of microfabrication or biology are not necessary\nor desireable.\n-\nMethods. Briefly describe any special methods that you used that are not in this\nlaboratory description. Give details of calculations used to obtain the results. Do\nnot repeat material that is in this description; just refer to it.\n-\nResults. Describe the measurements (whether or not they fit with expectations) in\nthe results section. Generally, results can be communicated more efficiently and\naccurately with pictures and graphs than with words alone. Describe those aspects\nthat are important to your interpretation, but omit interpretations from this section.\nA collection of printed graphs without a written description of their relevance is\nunacceptable as a results section. Students frequently err on the side of including a\nlarge number of graphs and little description of their relevance. You need only\ninclude results that are relevant to your conclusions. Most of us have trouble\n\nleaving things out. Ask yourself why a particular result is a necessary part of your\nstory; omit those that aren't necessary.\n-\nDiscussion. In the discussion section, assess the results for dependability and\naccuracy, and interpret results in the light of other knowledge. The discussion\nsection can include relevant speculations and ideas for improving the experiment\nto test the hypotheses more rigorously.\n-\nAppendix. The appendix should include a copy of the notes taken in your lab\nnotebook during the laboratory session.\nReports that are written haphazardly and without planning are usually unintelligible and\nreceive poor grades. We strongly recommend that you start by writing an outline to\nstructure the logic of the report. Revise your outline until the flow of your argument\nmakes sense (ask yourself, \"If this were someone else's report, would I believe the\nconclusion?\"). At that point, you can usually write the report by fleshing out the outline.\nGrade\nThe grade for the experimental project will be based on the proposal and on the project\nreport using the following considerations:\n-\nFirst draft & Critique (15%). Your first draft and your critique of a colleague's\nfirst draft will be graded primarily for completeness.\n-\nReport structure (15%). The sections of the report should be coherent.\n-\nClarity/Conciseness (20%). A good report is easy to read. The content of each\nparagraph and each graph should be clear. Everything included in the report\nshould be there for a reason. Points will be deducted for extraneous material.\nReports should be less than 10 pages long, unless there are good reasons for\nadditional pages.\n-\nConceptual correctness (20%). Is the report free of obvious errors,\nexaggerations, and omissions? Are the prominent features of the data described\naccurately? Are the results (which follow directly from the measurements) clearly\nseparated from the interpretations (which rely on information other than what was\nobserved)? Can the conclusions be derived from the results?\n-\nInsightfulness (30%). Insightfulness can be demonstrated by (1) proposing an\nexperimental method that can resolve some scientific issue, (2) carrying out\nexperiments and/or analyses that lead to clear conclusions, (3) preparing a report\nthat demonstrates a clear understanding of the strengths and weaknesses of your\nresults and analyses. Simply performing one of the standard experiments and\nshowing unmotivated measurements will receive 0 points. Clever design of an\nexperiment or imaginative analysis of the results will receive 30 points.\nDemonstrating a clear understanding of your experiment, your analyses, and what\ncan be concluded is sufficient for 15 points.\nDUE DATES ARE FIRM, AND THERE IS A SEVERE LATENESS PENALTY.\nThe grade for a late report will be multiplied by a lateness factor\n\nL = 0.3 exp(-t/4) + 0.7 exp(-t/72)\nwhere t is the number of hours late. The lateness factor is plotted below. Notice that the\nmaximum grade for a report that is more than ONE DAY LATE is less than 50%."
    },
    {
      "category": "Resource",
      "title": "cmt.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/554ecf92abc292dd702528953df7d286_cmt.pdf",
      "content": "3-0\n\nChapter 4\nSTEADY-STATE CHEMICALLY\nMEDIATED TRANSPORT\n4-1\n\n4-2\nCHAPTER 4. STEADY-STATE CHEMICALLY MEDIATED TRANSPORT\n\nContents\nSTEADY-STATE CHEMICALLY MEDIATED TRANSPORT\n4-1\n4.1\nINTRODUCTION\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-7\n4.2\nMODEL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-7\n4.2.1\nSingle solute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-7\n4.2.2\nTwo solutes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-10\n4.2.3\nChoice of numerical parameters . . . . . . . . . . . . . . . . . . . 4-12\n4.3\nGUIDE\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-12\n4.3.1\nInteractive environment\n. . . . . . . . . . . . . . . . . . . . . . . 4-12\n4.3.2\nGraph environment . . . . . . . . . . . . . . . . . . . . . . . . . . 4-16\n4.4\nPROBLEMS\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-20\n4-3\n\n4-4\nCONTENTS\n\nList of Figures\n4.1\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-8\n4.2\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-10\n4.3\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-13\n4.4\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-15\n4.5\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-17\n4.6\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4-18\n4-5\n\n4-6\nLIST OF FIGURES\n\n4.1. INTRODUCTION\n4-7\n4.1\nINTRODUCTION\nTransport of many solutes including important metabolites (e.g. simple sugars or amino\nacids) through cellular membranes is accomplished by membrane-bound carrier molecules\n(transporters) that combine with the solute molecule on one face of the membrane, then\ntranslocate in the membrane and uncombine at the other face. Thus transport involves\nbinding and unbinding chemical reactions at a site on the transporter. Different molecules\ncompete for this site; for example, glucose and sorbose (two sugars) compete for the sugar\ntransporter site. Hence, transport of one sugar can inhibit transport of another simply by oc-\ncupying a site to which both can bind. This type of transport is called chemically-mediated\ntransport.\nThere are canonical models of chemically-mediated transport that capture important\nproperties of the transport of metabolites. It is important to understand these canonical\nmodels in order to understand how metabolites are transported across membranes. Deriva-\ntions of predictions of these models are not particularly difficult to follow; the individual\nsteps are simple. However, the models typically result in messy algebraic expressions that\nrelate flux to concentration and transport parameters. Thus it is easy to get lost in algebraic\nmanipulation as well as in a sea of parameters so that an intuitive grasp of the models can\nbe missed. The simulation of these equations is intended to develop intuition for these\nmodels.\n4.2\nDESCRIPTION OF THE MODEL\nDescriptions of chemically-mediated transport as well as models of such transport pro-\ncesses can be found elsewhere [Weiss, 1996]. Here we consider two models, one a special\ncase of the other, and list both the assumptions and important results. First we consider a\ntransporter that binds only one solute; then we consider a transporter that binds two solutes\nwith different affinities. Because the resulting equations for equilibrium of the transporter\nwith solute are analogous to those of the binding of an enzyme to its substrate we refer to\nthe transporter as an enzyme.\n4.2.1\nSingle solute\nWe assume that the membrane contains\nmoles of enzyme per\nof membrane.\nEach of these enzymes exist in one of four states which we label\n,\n,\n, and\n(Figure 4.1). In the\nstates, the solute\nis bound to the enzyme\n; in the\nstate the enzyme is unbound. In the\nand\nstates, the enzyme, bound and unbound,\ncommunicates with the solution on the inner side of the membrane. In the\nand\nstates, the enzyme, bound and unbound, communicates with the solution on the outer side\nof the membrane. The concentrations of enzyme in the four states are\n,\n,\n, and\nmoles/cm . The fluxes of bound and unbound enzyme are\nand\nand the flux of\nsolute is\n. The flux is defined as positive when the flux is in the outward direction; the\nunits are in moles/cm -sec. The model is defined by the following assumptions:\n\n4-8\nLIST OF FIGURES\nFigure 4.1: Kinetic diagram of a chemically-mediated transport model in which the carrier binds a\nsingle solute.\nThe total amount of enzyme, bound and unbound, is constant, i.e. the sum of the\nconcentration of enzyme over all of its states equals the total concentration of enzyme\n(4.1)\nSince the enzyme resides permanently in the membrane, the total flux of enzyme\nmust be zero, i.e.\n(4.2)\nThe only way the solute can cross the membrane is when it is bound to the enzyme;\nis assumed to undergo a reversible change in conformation to the form\n.\nWe assume that the unbound enzyme undergoes a similar reaction between the two\nconformations\nand\n. These two reactions are assumed to be first-order reactions\nwith forward and reverse rate constants,\n,\n,\n, and\n. Therefore,\n(4.3)\nand\n(4.4)\nThe fluxes equal the rates of change of enzyme concentration, so that\n(4.5)\nSimilarly,\n(4.6)\n\n4.2. MODEL\n4-9\nThe binding reactions at the membrane interfaces are assumed to be rapid compared\nto the rate of transport of solute across the membrane so that the membrane interface\nreactions are assumed to be at equilibrium, i.e.,\nand\n(4.7)\nwhere\nand\nare the dissociation constants on the two membrane interfaces.\nWe wish to sove these equations to find the\n's and the\n's as a function of the concen-\ntrations of solute\nand of the transport parameters. One way to obtain these solutions is\nto solve for the\n's in terms of the concentrations and transport parameters and then to use\nEquations 4.5 and 4.6 to find the\n's. By combining Equations 4.2, 4.5, and 4.6, we obtain\n(4.8)\nWe can express Equations 4.7, 4.8, and 4.1 as a matrix equation as follows:\n(4.9)\nThe first two rows correspond to the two relations in Equation 4.7. The third row results\nfrom Equation 4.8, and the fourth row corresponds to Equation 4.1. This set of simultane-\nous equations has the following solutions:\n(4.10)\n(4.11)\n(4.12)\n(4.13)\nwhere\n(4.14)\nand\ncan be obtained from Equations 4.5 and 4.6.\n\n4-10\nLIST OF FIGURES\nFigure 4.2: Kinetic diagram of a chemically-mediated transport model in which the carrier can bind\none of two solute.\n4.2.2\nTwo solutes\nThe single-solute model shown in Figure 4.1 can be extended to account for the binding\nof two solutes that compete competitively for binding sites on the enzyme (Figure 4.2).\nIn this scheme, solutes\nand\ncan combine with enzyme\nbut with different affinities.\nThe binding to solute\nhas dissociation constants\nand\nand the binding to\nhas\ndissociation constants\nand\n.\nThe kinetic equations are analogous to those derived for the single-solute case except\nthat the enzyme now has 6 states:\nWe assume that the total amount of enzyme, free and complexed, is constant,\n(4.15)\nwhere\nis the total concentration of enzyme in the membrane.\nSince the enzyme remains in the membrane, the net flux of enzyme must be zero\n(4.16)\nThe fluxes equal the rate of change of enzyme concentration so that for solute\n(4.17)\n\n4.2. MODEL\n4-11\nFor solute\n(4.18)\nAlso\n(4.19)\nThe reactions at the membrane interfaces are assumed to take place so rapidly com-\npared to the rate of transport of solute across the membrane that the membrane inter-\nface reactions are assumed to be at equilibrium, i.e.,\nand\n(4.20)\nwhere\n,\n,\nand\nare the dissociation constants for solutes\nand\n,\nrespectively at the two membrane interfaces.\nBy combining Equations 4.16 and 4.17, 4.18, and 4.19, we obtain\n(4.21)\nWe wish to obtain the flux of solutes\nand\nas a function of both concentrations and\nthe transport parameters\n,\n,\n,\n,\n,\n,\n,\n,\n,\n, and\n.\nTherefore, it is useful to regard the system of algebraic equations given by Equations 4.16\nthrough 4.21 as a set of 6 equations in the 6 unknowns\n,\n,\n,\n,\n, and\n.\nWith this in mind we can rewrite the equations in matrix form as follows:\n(4.22)\nThe first four rows correspond to the four relations in Equation 4.20. The fifth row results\nfrom Equation 4.21, and the sixth row corresponds to Equation 4.15. This set of simulta-\nneous equations has solutions:1\n(4.23)\n(4.24)\n(4.25)\n1Solutions were obtained using the symbolic mathematics software packages MACSYMA and MATHE-\nMATICA. Equations 4.10-4.13 were obtained by setting\nin Equations 4.23-4.28.\n\n4-12\nLIST OF FIGURES\n(4.26)\n(4.27)\n(4.28)\nwhere\n(4.29)\n4.2.3\nChoice of numerical parameters\nThe software enables the user to compute the\n's and\n's for any values of the parameters,\nthe\n's,\n's, and\n's, and the concentrations of solute, the 's. The software is initiated\nwith default parameters chosen to approximate hexose transport in human erythrocytes\n[Carruthers, 1984, Stein, 1986] assuming a symmetric transport scheme. The density of\ntransporters was set to\npmoles/cm . The dissociation constant of solute\nwas\nset to approximate that of D-glucose,\nmoles/cm , and that of\nwas set\nto that of a solute to which the transporter binds with lower affinity, approximating that\nof D-xylose, so that\nmoles/cm . All the rate constants were set equal\nwith a value that made the maximum flux\npmoles/cm -s so that\ns\n. The concentrations of solute were chosen arbitrarily as follows:\n,\n,\n,\nmoles/cm .\n4.3\nUSER'S GUIDE\nThe software has two environments. In the interactive environment, the user can change\nthe independent variables also called the parameters (the rate constants, the\n's and\n's;\nthe dissociation constants, the\n's; and the concentrations, the 's) and observe changes\nin the dependent variables (the enzyme concentrations, the\n's; and the fluxes, the\n's). In\nthe graphing environment the user can plot any dependent variable versus any independent\nvariable over a specified range of the independent variable.\n4.3.1\nInteractive environment\nWhen the software is initiated, it is in the interactive environment. The display (Figure 4.3)\ncontains a large window with a menubar and two panels. One panel is labelled Transport\nParameters (left) and we shall refer to it as the Parameters panel. The other is labelled\n\n4.3. GUIDE\n4-13\nFigure 4.3: Display when software is initiated. The software is in the Interactive Environment with\nthe Single Solute mode selected.\n\n4-14\nLIST OF FIGURES\nTransport State (right) and we shall refer to it as the State panel. The Parameters panel\nshows a schematic diagram of the transport mechanism with both the independent and de-\npendent variables shown. The State panel, shows the state of the transport mechanism, i.e.\nthe values of all the dependent variables, for the chosen (initially the default) values of the\nindependent variables. The lengths of the dark bars are proportional to the concentrations\nof the enzyme in its four permissible states. The arrows indicate the directions and the\nrelative magnitudes of the fluxes; the thickness of the arrow is proportional to the relative\nmagnitude of the flux. The menubar contains File, Edit, Print, Graph, Mode, Help and\nQuit options.\nFile\nFile handling is the same as described in the chapter on Random Walk Model of Diffusion.\nThe only difference is that file extensions in the Chemically Mediated Transported package\nare .cmt. The File menu has three choices: read in data from file, write to file, delete a\nfile. All three choices allow the user to search their directory tree to find the file to be read,\nwritten or deleted. When any of the three options is selected, a scroll bar is displayed show-\ning all the filenames in the current directory. Selecting any filename or typing a filename\ninto the text edit window results in one of two possibilities. If the selected filename is the\nname of a directory, then that directory can be selected by clicking on Set Directory. If\nthe filename is the name of a file then that file can be read, written or deleted. Selecting the\nRead in data from file... entry reads a file containing all the parameter values but does not\nchange simulation modes. The order in which the values are read and stored in the file is\nas follows:\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n, and\n. The Write to file... entry writes the values of\nall the parameters to the chosen file. If the file already exists, it is overwritten. The Delete\na file... entry is used to delete a file from the directory.\nEdit\nSelection of Edit allows modification of the parameters of the simulation. When the soft-\nware is initiated, all parameters have their default values and those values are not displayed.\nThe Edit menu has three options.\nIf Show Parameters is selected, then a rectangle containing the value of a parameter\nis displayed next to each parameter (Figure 4.4). Clicking on a value allows the user to\nchange that parameter. The parameter can be changed by typing into the rectangle or by\nchanging the value using the mouse. Clicking on the\nor\nsymbols allows the value to\nbe increased/decreased by a fixed amount. Clicking on\nor\nincreases/decreases the\nparameter at a fixed rate. Clicking on the\nstops the increasing/decreasing process. As\nthe parameter is changed, the bar graph of enzyme states and the flux arrows are changed\nappropriately.\nSelecting Reset Defaults resets all parameters to their default values.\nSelecting Increment Value allows the user to set the value of increment used to change\nparameter values -- the increment is initially set to 1.\n\n4.3. GUIDE\n4-15\nFigure 4.4: Display after Show Parameters is selected.\n\n4-16\nLIST OF FIGURES\nPrint\nPrint allows selection of a printer for printing the contents of the screen. This option is\ndescribed fully in the description of the Random Walk Model of Diffusion.\nGraph\nSelecting Graph transfers control to the Graph Environment.\nMode\nTheir are currently two simulation modes, Single Solute and Two Solutes, which can be\nselected with this menu. When the Two Solutes mode is selected the Parameters and State\npanels are changed to that shown in Figure 4.5.\nHelp\nHelp is only partially implemented at this time.\nQuit\nQuit transfers control out of the chemically mediated transport software to the main menu\nwhich allows access to other software.\n4.3.2\nGraph environment\nTo switch to the Graph Environment, click on Graph. The screen now contains both the\nParameters and State panels in the upper half of the screen. Several options are available\nafter selecting Graph.\nFile, Print, Help and Quit\nSee above sections.\nGraph\nSelecting Graph allows several options. Selecting Setup Graph... allows the user to\nchoose to plot several vertical (dependent) variables versus one horizontal (independent)\nvariable. The range of the chosen independent variable is shown in two text edit boxes and\ncan be changed by the user. Each axis can be linear or logarithmic. The logarithm of the\nmagnitude is used for the ordinate; if the ordinate is zero, the value is not plotted. The\ntitle of the graph can also be chosen. The user can Start Graph or Cancel the choices\nby clicking on the appropriate button (see Figure 4.6). If Start Graph is chosen, then the\nrelation between the dependent variables and the independent variable are computed. When\n\n4.3. GUIDE\n4-17\nFigure 4.5: Display when the Two Solutes Mode is chosen.\n\n4-18\nLIST OF FIGURES\nFigure 4.6: Choosing graph variables. The display shows dialog box used to choose variables for\nplotting after a graph has been completed. The graph is shown in the background window.\n\n4.3. GUIDE\n4-19\nthe computation is completed, bar graphs of enzyme state and flux arrows are updated\ncontinuously as the graph is plotted.\nZoom allows the user to zoom in on a small part of the graph to look at details of the\ngraph. To return to the original scale, click on Unzoom.\nAnnotate allows the user to type and place a text string on the graph area.\nEdit\nThe user can select the Number of Samples of the independent variable at which the\ndependent variables are computed for the specified range of the independent variable. The\nrate at which the curves are displayed can be decreased by increasing the Plotting Interval.\nMode\nIf in the graph environment, choice of one of the allowable mode transfers control to the\ninteractive environment.\n\n4-20\nLIST OF FIGURES\n4.4\nPROBLEMS\nProblem 4.1 This problem is intended to develop your intuition for the chemically-mediated\ntransport model for a single solute. You will observe the effects of changes in parameters\non both the flux and the enzyme concentrations. Use the Single Solute mode and start with\nall the parameters at their default values.\na) What is the relation of\nand\n? Explain.\nb) What is the relation of the direction of\nto the sign of\n? Explain.\nc) How does the state of the enzyme depend on concentration?\ni) Do changes in\nchange\nand\n? If so, how? If not, why not?\nii) Do changes in\nchange\nand\n? If so, how? If not, why not?\niii) Do changes in\nchange\nand\n? If so, how? If not, why not?\niv) Do changes in\nchange\nand\n? If so, how? If not, why not?\nReset all the parameters to their default values, except set\ns\n.\nd) What is the relation of the direction of\nto the sign of\n? Explain.\nReset all the parameters to their default values, except set\ns\n.\ne) What is the relation of\nto\n? Explain.\nProblem 4.2 This problem is designed to explore the functional relation between flux and\nconcentration when expressed in different coordinates. Use the Single Solute mode and\nstart with all the parameters at their default values, except set\n. In parts a) through\nc) your job is to estimate the values of\nand\nfrom the graphs specified, where\nis the maximum flux of\nwith\n.\na) Obtain a graph of\nversus\nin linear coordinates.\nb) Obtain a graph of\nversus\nin double logarithmic coordinates.\nc) Obtain a graph of\nversus\n.\nd) Determine the values of\nand\nfrom the model parameters.\ne) Compare the 4 sets of values you have obtained for\nand\n.\nProblem 4.3 Use the Single Solute mode and start with all the parameters at their default\nvalues, except set\n. Obtain a graph of all four enzyme states as a function of\n.\nSome of the these\n's increase, others decrease, while others remain constant. Summarize\nand explain the results you found.\n\n4.4. PROBLEMS\n4-21\nProblem 4.4 Use the Two Solute mode and start with all the parameters at their default\nvalues. Set the concentrations of\nand\nto zero on both sides of the membrane.\na) Explain the initial enzyme states and flux values.\nb) Increase\nand observe both the enzyme states and the flux. What is the relation of\nthe flux of\nto\n?\nc) Now set\nand increase\n. How do the fluxes of\nand\ndepend upon\n?\nd) Set\nand\n. Now increase\nfrom an initial value of 0. How do the\nfluxes of\nand\ndepend upon\n? Pay particular attention to the direction of the\nflux of\n.\n\n4-22\nLIST OF FIGURES\n\nBibliography\n[Carruthers, 1984] Carruthers, A. (1984). Sugar transport in animal cells: The pasive hex-\nose transfer system. Proj. Biophys. Molec. Biol., 43:33-69.\n[Stein, 1986] Stein, W. (1986). Transport and Diffusion Across Cell Membranes. Aca-\ndemic Press, New York.\n[Weiss, 1996] Weiss, T. F. (1996). Cellular Biophysics: Volume 1: Transport. MIT Press,\nCambridge, MA.\n4-23"
    },
    {
      "category": "Resource",
      "title": "macro.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/2dec3d0ac557365b9b31de361b77e3ad_macro.pdf",
      "content": "2-0\n\n3-1\nChapter 3\nMACROSCOPIC DIFFUSION\nPROCESSES\n\n3-2\n\nContents\n3 MACROSCOPIC DIFFUSION PROCESSES\n3-1\n3.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-7\n3.1.1\nBackground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-7\n3.1.2\nMacroscopic Model of Diffusion . . . . . . . . . . . . . . . . . . . 3-7\n3.1.3\nOverview of Software . . . . . . . . . . . . . . . . . . . . . . . . 3-8\n3.2\nMethods of Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-10\n3.2.1\nExact Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-11\n3.2.2\nNumerical Solutions . . . . . . . . . . . . . . . . . . . . . . . . . 3-14\n3.2.3\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-14\n3.3\nUser's Guide to the Software . . . . . . . . . . . . . . . . . . . . . . . . . 3-15\n3.3.1\nOptions and environments . . . . . . . . . . . . . . . . . . . . . . 3-15\n3.3.2\nScreen Layout . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-17\n3.3.3\nRunning a Simulation . . . . . . . . . . . . . . . . . . . . . . . . 3-21\n3.3.4\nSaving Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-25\n3.3.5\nNumerical issues . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-26\n3.4\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-27\n3-3\n\n3-4\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\n\nList of Figures\n3.1\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-9\n3.2\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-17\n3.3\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-22\n3.4\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3-24\n3-5\n\n3-6\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\n\nINTRODUCTION\n3-7\n3.1 Introduction\n3.1.1 Background\nDiffusion is an important transport process in physical, chemical, and biological systems.\nTwo theoretical models of diffusion capture complementary aspects of the phenomenon.\nThe microscopic model describes the probabilistic behavior of a population of individ\nual solute particles which execute statistically independent, but otherwise identical, ran\ndom walks. Software dealing with such a microscopic model of diffusion is described in\nChapter 2. The software described in this chapter involves macroscopic diffusion which\ndescribes the aggregate behavior of large populations of solute molecules.\n3.1.2 Macroscopic Model of Diffusion\nIn 1855, Adolph Fick proposed a macroscopic model for passive diffusion [Fick, 1855].\nBy analogy to Fourier's law of heat conduction and Ohm's law for electrical conduction,\nFick proposed that the flux of solute particles at a point in space is proportional to the\nconcentration gradient at that point. Mathematically, this relation is expressed by Fick's\nFirst Law, which, in its one-dimensional form, is as follows:\n(3.1)\nis the solute flux. The constant of\n(in the absence of sources or sinks or of chemical reactions that create or destroy particles)\nresults in a second relation between concentration and flux, the Continuity Equation:\nwhere\nis the solute concentration and\nproportionality,\n, is known as the diffusion coefficient. Conservation of solute particles\n(3.2)\nDifferentiating both sides of Equation 3.1 with respect to and using the Continuity Equa\ntion yields Fick's Second Law, or the One-Dimensional Diffusion Equation:\n(3.3)\nIn principle, any one-dimensional diffusion process can be modelled by solving this equa\ntion subject to the appropriate initial conditions and boundary conditions.\nWe next consider the same problem but with a body force acting uniformly on the solute\nparticles so that they are convected and a chemical reaction occurring between the solute\nparticles and the solvent. The solute flux,\n, is now the sum of the diffusive flux, given\nby Fick's law, and the convective flux due to the body force. Thus, in this case,\n(3.4)\n\n3-8\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nwhere\nis the convection velocity of the solute particles; i.e., the velocity at which the\nparticles would move in response to the body force but no diffusion. If is the reaction rate\nbetween solute and solvent, then the Continuity Equation becomes\n(3.5)\nCombining these expressions yields a modified diffusion equation:\n(3.6)\nThus, solute convection and a chemical reaction rate between solute and solvent appear as\nadditional terms in the Diffusion Equation.\nIf the initial concentration,\nis known in some region of space and if the relation\nbetween the concentration and flux is known at each boundary of this region, then a unique\nsolution exists for\n. This agrees with intuition: given an initial concentration profile,\n, Fick's laws govern the unique evolution of the concentration profile for all later\ntimes.\n3.1.3 Overview of Software\nWhile macroscopic diffusion has been successfully modelled by Fick's equations, studying\nthe equations alone provides only limited insight into the behavior of diffusion processes.\nThe goal of this software is to help students gain intuition about diffusion in one dimension.\nThe solutions to the diffusion equation are functions of two variables: one spatial variable,\n, and time, . These solutions can be plotted either as a function of time at a particular point\nin space or as a function of the spatial variable at a particular instant in time. Such isolated\n\"snapshots\", however, do not fully convey the dynamic behavior of diffusion processes.\nWith this software, the user can view a \"movie\" of the solute concentration or flux profile,\nas a function of position, as it evolves in time. Thus, the software enables the student\nlearning about diffusion theory to gain intuition about the dynamic behavior of macroscopic\ndiffusion processes.\nFurthermore, the software provides an opportunity for students to experiment with the\nmacroscopic model. For example, the user can explore how changing the diffusion co\nefficient affects the time-course of the simulation. The user can also specify transparent\nor reflecting boundaries and can explore how a body force acting on the solute particles\nor a chemical reaction between solute and solvent influence the diffusion process. Thus,\nthe software can be used as a tool for investigating how various parameters and boundary\nconditions influence diffusion.\nFive classes of initial concentration profiles, corresponding to five characteristic one-\ndimensional diffusion problems, are implemented in the software (Figure 3.1). Four of\nthese problems involve diffusion from a specified initial concentration profile contained\nwithin a single compartment (which may be infinite), while the fifth involves diffusion\nbetween two compartments, through a membrane.\n\n3-9\nINTRODUCTION\nc(x,t=0)\nImpulse\nSinusoid\nDiscontinuity\nArbitrary\nTwo-Compartment\nx\nx\nx\nx\nx\nFigure 3.1: Schematic representation of the five classes of initial concentration profiles for\none-dimensional problems simulated by the software.\n\n3-10\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nOne-Compartment Diffusion\nIn one-compartment diffusion problems, the initial concentration can be chosen to be one\nof four types: impulses, sinusoids, piece-wise constant, and arbitrary distributions. An\nimpulse of solute concentration is a mathematical idealization corresponding to a finite\namount of solute initially concentrated at a single point in space. The user can specify the\nmagnitude and position of up to four impulses. This case illustrates diffusion from point\nsources. Initially sinusoidal concentration profile illustrate the spatial frequency response\nof a system governed by the Diffusion Equation, specifically, the low-pass spatial filtering\neffect of diffusion. By superimposing up to four sinusoids, the student can observe the de\npendence of the space-time evolution of a concentration distribution on its spatial frequency\ncontent. An initial concentration profile may be piecewise-constant but contain jump dis\ncontinuities (as, for example, if a thin, impermeable membrane separating two baths with\nunequal solute concentrations is suddenly removed). The user can specify the magnitude\nand location of up to four such discontinuities. The user can also explore the response for\nmore complicated initial conditions which can be specified by drawing on the workstation\nscreen with a mouse.\nFor these different initial distributions, the user can specify the boundary type (trans\nparent or reflecting), the value of the convection velocity, and the chemical reaction rate\nbetween the solute particles and the solvent.\nTwo-Compartment Diffusion through a Membrane\nThe user can also investigate diffusion between two well-stirred compartments, or baths,\nthrough a membrane which is permeable to the solute. Two-compartment diffusion through\na membrane is an important transport process in biological systems. It can model, for\nexample, diffusion between the cytoplasm of a cell and the extracellular fluid, across the\nplasma membrane. The baths are assumed to be well-stirred, so that the concentration\nwithin each bath varies with time only. The total amount of solute in the system is assumed\nto be finite. The user can specify the width of each bath and of the membrane, the initial\nconcentration of each bath, and an arbitrary initial concentration profile in the membrane.\n3.2 Methods of Solution\nFor several of the diffusion problems implemented in the software, exact solutions of the\nmodified diffusion equation (Equation 3.6) are available in a form that makes computation\nefficient. Such solutions have been used wherever possible. The remainder of the solutions\nwere obtained by numerical methods. The methods are described in some detail elsewhere\n[Berkenblit, 1990]; only a brief summary of the methods is given here.\nThe method used to obtain solutions depends upon the type of boundary condition.\nTwo types of boundary conditions for the diffusion problems can be selected by the user:\ntransparent or reflecting boundary conditions. If transparent boundaries are specified, then\nthe region over which diffusion occurs is infinite; the \"boundaries\" are merely the endpoints\n\n3-11\nMETHOD OF SOLUTION\nof the region viewed by the user. At a reflecting boundary, on the other hand, the solute\nflux is constrained to be zero, since no solute particles can cross such a boundary.\n3.2.1 Exact Solutions\nExact solutions were used to compute the response for all one-compartment diffusion prob\nlems with transparent boundaries. These are described in this section.\nImpulse response -- Green's function\nNo convection, no chemical reaction. First we shall find the spatial and temporal evo\nlution of the solute concentration profile,\n, in the absence of convection and in the\nabsence of a chemical reaction when the initial profile consists of a unit impulse in con\ncentration, located at position\nand delivered at time\n. That is we need to find a\nsolution to Equation 3.3 subject to the initial condition\n(3.7)\n(3.8)\nThe solution, called the Green's function\n, can be shown by a variety of methods\nto be\nThus, the concentration profile is a Gaussian function of the spatial variable. The standard\ndeviation of the curve,\n, increases with increasing time, but the total area under the\nconcentration curve remains constant, corresponding to conservation of particles.\nConvection but no chemical reaction. We next consider the same problem but with a\nnon-zero convection term. In this case, the concentration satisfies the modified diffusion\nequation, Equation 3.6, with\n:\n(3.9)\nwith the initial condition\n(3.10)\nThe solution can be shown to be\n(3.11)\nThus, the response in this case is a Gaussian function, as before, but the entire profile\n\"drifts\" in the positive -direction with velocity .\n\n3-12\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nConvection and chemical reaction. With a non-zero chemical rate, , and convection\nvelocity, , we need to solve Equation 3.6 which has a solution\n(3.12)\nIn general, if\nis the solution to Equation 3.3, with a specified initial concen\ntration profile and transparent boundaries, then the solution to the modified equation, 3.6,\nsatisfying the same intitial conditions, is given by\n(3.13)\nSinusoid\nFirst we consider the solution to Equation 3.3 with the initial condition\n(3.14)\nfor some arbitrary constant amplitude, , spatial radian frequency, , and phase, . The\nsolution for\nis given by\n(3.15)\nwhich can be verified by substituting this expression into Equation 3.3. Thus, an initially\nsinusoidal concentration profile remains sinusoidal for all later time, but the amplitude\ndecreases exponentially with time. The rate of attenuation is proportional to the square of\nthe spatial frequency.\nWith convection and a chemical reaction between solute and solvent, the solution is\n(3.16)\nwhere is the convection velocity and is the reaction rate.\nDiscontinuous Initial Profile\nWe next consider the case of an initial profile that is piecewise-constant but contains a jump\ndiscontinuity at\n. The initial condition is that\n(3.17)\nwhich can also be written as\n(3.18)\n\n3-13\nMETHOD OF SOLUTION\nFor\n, we can integrate the Green's function defined by Equation 3.8 to obtain the\nsolution:\n(3.19)\nwhere the complementary error function,\n, is defined by the integral\n(3.20)\nWith a convection velocity, , and reaction rate, , the solution is\n(3.21)\nArbitrary Initial Profile\nSuppose\nis an arbitrary periodic function of , with period . Then\ncan be\nexpanded in a Fourier series,\n(3.22)\nwhere\nis the sequence of complex Fourier coefficients, defined by\n(3.23)\nBy an extension of the solution for a sinusoidal initial profile, 3.15, the solution for\nis\n(3.24)\nThus, the complex Fourier coefficients of\ncan be obtained from the Fourier coef\nficients of the initial profile,\n, by multiplying each term by the appropriate attenu\nation factor. For simulation purposes, an arbitrary initial profile is represented as a dis\ncrete sequence of samples. If\nis the number of samples per period, then the waveform\nis completely specified by its\nFourier coefficients, obtained by taking the spatial Dis\ncrete Fourier Transform of the initial profile. If\nis a power of two, then the transform\ncan be computed efficiently via any of several Fast Fourier Transform (FFT) algorithms\n[Oppenheim and Schafer, 1975]. Applying this result, the evolution of a concentration pro\nfile from an arbitrary periodic initial profile can be determined as follows:\n\n3-14\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\n1. Compute the FFT of\nand store the result.\n2. At any later time, , multiply each Fourier coefficient of\nby the appropriate\nattenuation factor,\n.\n3. Perform an inverse FFT to obtain\n.\n3.2.2 Numerical Solutions\nOne-compartment problems with reflecting boundaries and the two-compartment problem\nare solved using numerical methods. To solve a diffusion problem numerically over some\nspecified spatial region and some specified time interval, the position and time variables\nare discretized. Denoting the time increment by\nand the position increment by\n, we\ndefine\n(3.25)\nwhere\n(3.26)\nA general approach to solving partial differential equations numerically is to replace the\npartial derivatives by finite-difference approximations. The finite-difference expressions\ninvolve the\nterms defined above and result in sets of algebraic equations that can be\nsolved by numerical methods for solving matrix equations. In the software, the equation\nwith no convective term is solved by the implicit Crank-Nicolson algorithm, while for prob\nlems with a non-zero convective term, this algorithm is combined with the explicit Two-\nStep Lax-Wendroff method [Press et al., 1988, Gerald and Wheatley, 1989] by a technique\nknown as operator splitting. When a non-zero chemical reaction rate, , is specified, the\ncomputed concentration is multiplied by the attenuation factor,\n. The Crank-Nicolson\nand Lax-Wendroff formulas involve the parameters\nand\nfor the one-compartment case and\nand\nfor the two-\ncompartment case, where\nand\nare the widths of the baths of the two compartments.\nThe numerical methods give stable solutions provided\n,\n, and\n.\n3.2.3 Summary\nA variety of techniques are used to find exact solutions to one-compartment diffusion prob\nlems with transparent boundaries. The specific methods used in the software to solve one-\ncompartment problems depend on the initial conditions and are summarized in Table 3.1.\nWith two reflecting boundaries and in the absence of convection, the exact solutions con\nsist of infinite series. Thus it is cumbersome to compute these exact solutions. With two\nreflecting boundaries and with convection, exact solutions are in general not available.\nTherefore, we have chosen to solve these problems numerically using the Crank-Nicolson\n\n3-15\nUSER'S GUIDE TO THE SOFTWARE\nOption\nImpulse\nReflecting\nCrank-Nicolson\nSinusoid\nDiscontinuity\nReflecting\nCrank-Nicolson\nArbitrary\nFFT\nReflecting\nCrank-Nicolson\nCrank-Nicolson\nBoundary Type\nComputational Method\nTransparent\nExact solution (Gaussian)\nTransparent\nExact solution (sinusoid)\nTransparent\nExact solution (erfc)\nTransparent\nTwo-Compartment\nTable 3.1: Summary of computational methods.\nand Lax-Wendroff methods. The latter methods are also used to compute the solutions to\nthe two-compartment problem.\n3.3 User's Guide to the Software\n3.3.1 Options and environments\nThe four one-compartment diffusion problems and the two-compartment problem are im\nplemented in the software as five options: Impulse, Sinusoid, Discontinuity, Arbitrary, and\nTwo-Compartment. At all times, one of these options is the current option. Each option\nhas a corresponding set of parameters specific to that option.\nImpulse Parameters\nThe magnitude and position of four impulses. The user can set the position of each\nimpulse only if the magnitude is non-zero.\nThe boundary type (transparent or reflecting), and, if the boundaries are reflecting,\nthe positions of the two boundaries.\nDiffusion coefficient, convection velocity, and chemical reaction rate.\n\n3-16\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nSinusoid Parameters\nThe amplitude, frequency, and phase of four sinusoids. The user can set the frequency\nand phase of a sinusoid only if its amplitude is non-zero.\nDiffusion coefficient, convection velocity, and chemical reaction rate.\nDiscontinuity Parameters\nA constant concentration offset.\nThe magnitude and position of four jump discontinuities. The user can set the posi\ntion only if the magnitude is non-zero.\nBoundary type and position (for reflecting boundaries).\nDiffusion coefficient, convection velocity, and chemical reaction rate.\nArbitrary Profile Parameters\nBoundary type and position (for reflecting boundaries).\nSpatial period of the profile (for transparent boundaries).\nThe initial profile. The user draws the initial profile on the workstation screen by\nmoving the mouse. The details are described in Section 3.3.2.\nDiffusion coefficient, convection velocity, and chemical reaction rate.\nTwo-Compartment Parameters\nBath widths and the initial concentration in each bath.\nMembrane width and the initial membrane concentration profile, drawn with the\nmouse (as described in Section 3.3.2).\nDiffusion coefficient, convection velocity, and chemical reaction rate.\nThe software is always in one of five environments. When the program is in the Pa\nrameters environment, the user can modify the values of the option-specific parameters,\nchange the graph parameters, and run a simulation. The other environments (Simulate,\nPaused, Continue, and Done), indicate the state of a simulation run. These environments\nare described in more detail in Section 3.3.3.\nWhen the software is initiated, the Impulse option is initially selected and the program\nis in the Parameters environment. A typical session with the software consists of selecting\none of the five options, modifying the values of the option-specific parameters and possibly\nthe graph parameters, and then executing a simulation using the current parameter values.\nThe results can be saved in a file or printed.\n\n3-17\nUSER'S GUIDE TO THE SOFTWARE\nFigure 3.2: Appearance of the workstation screen after the software has been initiated.\n3.3.2 Screen Layout\nFigure 3.2 shows the appearance of the workstation screen after the software has been\ninitiated. The screen is divided into a number of rectangular regions.\nMenubar\nThe title bar at the top of the screen is generated by the window manager program. Just\nbelow this title bar is a menubar, containing entries labelled File, Print, Parameters, Sim\nulate, and Quit. Pointing to one of these labels and clicking a mouse button causes the\nsoftware to take an action that depends on which menubar entry was selected:\nFile: Causes the file-handling menu to be posted. File handling is discussed in Sec\ntion 3.3.4.\nPrint: Causes the printer menu to be posted so that a printed version of the screen contents\nmay be obtained. Printing is discussed in Section 3.3.4.\nParameters: Returns the software to the Parameters environment when a simulation run\nhas been completed or paused. When the software is already in the Parameters envi\nronment, this item is inactive and is displayed in gray (as in Figure 3.2).\n\n3-18\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nSimulate: When the software is in the Parameters environment, clicking on this entry\ncauses the Simulation Parameters menu to be posted. The parameters in this menu\nare discussed below, in the section on running a simulation (3.3.3). A simulation\ncan only be run if a non-trivial initial concentration profile has been specified. In\nFigure 3.2, no non-zero impulses have been specified, so the initial concentration\nis identically zero. Thus, the Simulate menubar entry is currently inactive and is\nprinted in gray. When a simulation is running, clicking on this menubar entry pauses\nthe simulation, and clicking on it while a simulation is paused causes the paused\nsimulation to resume running.\nQuit: Exits from the software. To prevent the user from exiting accidentally, a dialogue\nbox is posted asking the user to confirm that he or she \"really wants to quit.\"\nGraphs\nThree graphs occupy large regions of the screen. The largest one is called the time graph,\nsince it displays a plot of concentration, flux, or position versus any other one of these\nvariables at each successive point in time during a simulation. The current simulation time\nis displayed in the title of the graph. In Figure 3.2, since no simulation is running, the\nsimulation time is zero. Since no initial profile has been specified, no points are plotted.\nClicking on the \"Parameters\" button in the upper right-hand corner of the time graph\nwindow causes a graph parameter menu to be posted in the graph window. The graph\nparameters (i.e., which variable is plotted on each axis, and the minimum and maximum\naxis bounds) can then be modified by selecting the appropriate menu entry. Axis bounds\nare modified by clicking on the menu entry and then typing in the modified value, followed\nby a carriage return or another button press on the same entry. The horizontal and vertical\nvariables are implemented as toggle variables; clicking on one of these parameters causes\nit to toggle between two different values. There are three possible values for each variable\n(concentration, flux, and position), but the menu entry will only toggle between the two\nvariables that are not displayed on the other axis. Thus, trivial plots of one variable versus\nitself are avoided. To save time when changes are made to the parameters, the graph is not\nredrawn until the user exits from the menu (by clicking on the \"DONE\" entry or clicking\noutside the menu). The user can force the graph to be redrawn at any time by clicking on\nthe \"REDRAW GRAPH\" menu entry.\nThe two smaller graphs at the bottom of the screen are the position graphs; each dis\nplays a plot of concentration, flux, or time versus any other one of those variables at a fixed\nposition. The parameters for each graph are modified by clicking on the \"Parameters\"\nbutton in the upper right-hand corner, as described for the time graph.\nThe position corresponding to each position graph is indicated both in the graph title and\nby the two arrows just below the position axis of the time graph. By default, the positions\nare initially 0 and 1, as in Figure 3.2. To modify the position for one of the position\ngraphs, the user clicks on the title region of the graph. A dialog box is then displayed in\nthe graph window. The dialog box contains a button labelled \"DONE\" and a twiddle box\nwhich allows the user to make incremental changes to a variable. To change the value of\n\n3-19\nUSER'S GUIDE TO THE SOFTWARE\nthe position, the user can either click on the old value and type in a new one or use the\ntwiddle box knobs to increment or decrement the value by a fixed amount. As the value is\nvaried, the arrow on the position axis of the time graph moves to indicate the current value.\nNo changes are permanent, however, until the user clicks on the DONE button. Clicking\nelsewhere aborts the procedure, and the position retains its previous value.\nOption Buttons\nIn the upper left-hand corner of the screen, just below the menubar, five radio buttons,\ncorresponding to the five options, are displayed. In figure 3.2, the Impulse button is high\nlighted, indicating that this option is currently selected. To change the current option, the\nuser simply clicks on the name of the new option.\nOption-Specific Parameters\nJust below the option buttons, the option-specific parameters for the selected option are\ndisplayed. Often, a change in a parameter value requires that the time graph be redrawn\nto correctly portray the initial concentration profile. In order to speed up the parameter\nselection process, the graph is not redrawn every time such a change occurs. Instead, a\nbutton labelled \"Redraw Graph\" is posted in the center of the time graph whenever the\ngraph is not up to date. Clicking on that button causes the graph to be redrawn. Thus, the\ntime graph only needs to be redrawn once after changes to several parameters have been\nmade.\nThere are several types of parameters for each option. For most parameters, the name,\nunits, and value are displayed. To modify the value of the parameter, the user clicks on the\nparameter and then types in the new value, followed either by a carriage return or another\nbutton press on the same parameter. Clicking a mouse button when the pointer is not on\nthe parameter aborts the procedure and cause the parameter to retain its previous value. For\nparameters that represent positions (i.e., the positions of reflecting boundaries, impulses,\nor discontinuities), the value may also be modified by using the mouse, in the following\nmanner:\nThe user clicks on the parameter and then clicks in the time graph window.\nThe cursor changes to a pointing hand when the pointer moves outside the bound\naries of the time graph. When the pointer is within the graph boundaries, the cursor\nvanishes and a vertical line (or a horizontal line, in the unlikely case that position is\nplotted on the vertical axis) indicating the pointer position appears on the graph and\nmoves with the pointer.\nClicking any mouse button within the time graph window sets the parameter value\nto the current pointer position. Clicking outside the time graph window, on the other\nhand, aborts the procedure, and the parameter retains its previous value.\nThis method can only be used if position is one of the variables plotted on the time graph\nand if the time graph is up to date (i.e., if the \"Redraw Graph\" button is not posted).\n\n3-20\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nThe boundary type is indicated by a toggle parameter whose value toggles between\n\"TRANSPARENT\" and \"REFLECTING.\" For the Arbitrary and Two-Compartment op\ntions, the user can draw an initial profile by clicking on the \"DRAW INITIAL PROFILE\"\nparameter and can erase an existing profile by selecting the \"ERASE INITIAL PROFILE\"\nparameter. The ERASE parameter does not become active until a profile has been drawn,\nand it becomes inactive after a profile has been erased. The implementation of the user-\ndrawn profile feature is described in the next section.\nUser-Drawn Concentration Profile\nRepresentation of an Arbitrary Profile An arbitrary concentration profile is represented\nby the software as a sequence of concentration values at an arbitrarily spaced, monoton\nically increasing sequence of position coordinates. The position and concentration coor\ndinates corresponding to the Arbitrary and Two-Compartment options are stored in span\nstructures. A span structure has three members: the array of position coordinates, the cor\nresponding array of concentration values, and a member indicating the number of points in\nthe span.\nFor computation purposes, the software must determine the initial concentration values\nat a specified number of equally spaced sample points. Such an array is generated from the\nspan data as follows:\nFor the Arbitrary option with transparent boundaries, the profile is assumed to be\nperiodic; the period, specified by the user, may be longer than the length of the profile\nstored in the span structure. The period is divided into 256 equal subintervals. At\neach position, the initial concentration is determined by linear interpolation between\nthe two surrounding points of the span. At points lying beyond the end of the span,\nthe initial concentration is taken to be zero. For example, if the user has drawn\na profile of length 1 cm and specified a period of 2 cm, the concentration will be\nidentically zero for half of each period.\nFor the Arbitrary option with reflecting boundaries, the distance between the bound\naries is divided into a specified number of equally spaced points. The number of\npoints is set by the user, using the Simulate menu, as discussed in Section 3.3.3.\nAt positions that lie within the span, the initial concentration is determined by lin\near interpolation between the two surrounding points of the span, while at points\nlying outside the span, the initial concentration is taken to be zero. For the Two-\nCompartment option, the initial membrane concentration profile is computed in the\nsame manner.\nDrawing a Profile The user can draw an initial profile only if the time graph has concen\ntration plotted on its vertical axis and position on its horizontal axis. When the user clicks\non the \"DRAW INITIAL PROFILE\" parameter (in the Arbitrary or Two-compartment op\ntion): the cursor changes to a pencil whenever the pointer is outside the time graph window;\n\n3-21\nUSER'S GUIDE TO THE SOFTWARE\nwhen the pointer is within the time graph window, the cursor vanishes and the pointer po\nsition is indicated by vertical and horizontal cross-hairs.\nDrawing a profile consists of generating a list of concentration values at a corresponding\narray of positions. The user selects these points by moving the mouse and clicking any\nmouse button. As the pointer moves within the window, a \"rubber-band\" line joins the last\npoint which was selected to the current pointer position. There are two modes of action\nthat the user can use to draw the profile:\nClicking a mouse button within the time graph window adds a position and concen\ntration value to the coordinate lists and draws a line segment from the previous point\nto the current point. In this manner, the user can construct a profile made up of line\nsegments.\nMoving the mouse while a mouse button is held down causes a series of points to be\nadded to the coordinate lists. In this manner, the user can construct more complicated\ncurves.\nThe two methods can be combined in drawing a single profile. As soon as a complete\nprofile has been drawn, the drawing routine terminates and stores the profile data in the\nappropriate span structure.\nWhen a button is pressed, the position and concentration that are added to the coordinate\narrays depend on the pointer location:\nA button press at a position that does not lie to the right of the previous point is\nignored, in order to ensure that the user-drawn concentration profile is a single-valued\nfunction of position.\nIf a button is pressed within the boundaries of the time graph, then the coordinates of\nthe pointer location are added to the list.\nIf a button is pressed outside the boundaries of the graph (but still within the graph\nwindow), then the point that is added to the list is the point of intersection between\nthe graph boundary and a line from the previous point to the current position. Thus,\nwhile a profile is being drawn, it is constrained to lie entirely within the boundaries\nof the graph.\nBy default, the concentration at the left-hand point of the profile is zero. The user\ncan change the first value, however, by making the first button press at the desired\nvertical location but to the left of the concentration axis.\nClicking outside the time graph window at any time aborts the drawing procedure.\n3.3.3 Running a Simulation\nOnce a non-trivial initial concentration profile exists for the current option, the user can\nrun a simulation. The following criteria are used to determine whether a non-trivial initial\nprofile has been specified:\n\n3-22\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.3: Appearance of the workstation screen after an initial concentration profile, consisting of\ntwo impulses, has been specified but the simulation has not yet been run.\nFor the Impulse, Sinusoid, and Discontinuity options, a non-trivial profile exists if\nthere is at least one impulse, sinusoid, or discontinuity of non-zero magnitude.\nFor the Arbitrary and Two-Compartment options, a profile exists if the user has drawn\na complete profile (and not erased it).\nThe \"Simulate\" menubar entry is active only when an initial profile exists for the current\noption. Figure 3.3 shows the appearance of the workstation screen when a typical initial\nprofile has been specified but the simulation has not yet been run. In this case, the profile\nconsists of two impulses, which are indicated schematically by tall vertical arrows on the\ntime graph with the magnitude of each impulse displayed in parentheses next to each arrow.\nThe positions corresponding to each position graph have been changed from their default\nvalues, and the variables and axis bounds of the position graphs have been modified.\nDuring a simulation run, the concentration and/or flux are computed at successive points\nin time until the specified final time. At each step, the time is incremented by a specified\namount. The final time and the time increment are set by clicking on the \"Simulate\" entry in\nthe menubar at the top of the screen. The menu which is then posted contains the following\nentries:\n\n3-23\nUSER'S GUIDE TO THE SOFTWARE\nFinal time: The time (in seconds) at which the simulation will end. This is the simulation\ntime, not actual elapsed time.\nTime increment: Amount (in seconds) by which the simulation time is incremented at\neach step. This increment is different from the integration time increment used in the\nnumerical computation methods.\nNumber of sample points: For computations involving the Crank-Nicolson algorithm, the\nnumber of spatial sample points. This parameter is inactive if another computation\nmethod is used. The default value is 128, but it can be set as high as 256 for greater\naccuracy or as low as 32 for greater speed. The value does not have to be a power of\ntwo, but since the region of the workstation screen in which the time graph is plotted\nis 512 pixels wide, setting this number to be power of two ensures that the sample\npoints will be evenly spaced.\nSTART SIMULATION: Starts the simulation run.\nEXIT FROM MENU: Exits from the menu without starting a simulation run. Clicking a\nmouse button anywhere outside the menu window has the same effect.\nWhen a simulation run is started, the program enters the Simulate environment. The\ngraph parameter buttons disappear, the initial concentration profile is replotted if necessary,\nand all the menubar entries are inactivated except the Simulate entry, whose name changes\nto \"Pause.\" At each step of the simulation, the following sequence of actions occurs:\nThe simulation time is incremented by the specified amount, and the new simulation\ntime is displayed in the title of the time graph.\nThe specified time graph parameters (concentration and/or flux) are computed as\nfunctions of position at the current time, and the time graph is replotted.\nThe specified position graph parameters for each graph are computed at the current\ntime and the specified positions, and a new point is added to each position graph.\nPausing and Resuming a Simulation\nClicking on the Pause entry of the menubar while a simulation is running suspends the\nsimulation. The program enters the Paused environment, in which the Print, Parameters,\nHelp, and Quit menubar entries are activated. The name of the Pause entry changes to \"Re-\nsume\"; clicking on this entry causes the paused simulation to resume running. Clicking on\nthe Parameters entry, however, returns the software to the Parameters environment and re\nsets the simulation time to zero. When a simulation is paused, the graph parameter buttons\nreappear, so that the graph parameters may be modified. The positions corresponding to\neach position graph, however, can only be modified from the Parameters environment.\n\n3-24\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.4: Appearance of the workstation screen after a simulation has been continued four times.\nThe software is now in the Done environment; the \"Done\" menubar entry is inactive since the\nsimulation cannot be continued further.\nContinuing a Simulation\nWhen the simulation time has reached the specified final time, the simulation halts. The\nisolated points plotted on the position graphs are joined by lines, and the software enters\nthe Continue environment. In this environment, all the menubar entries are active, and\nthe name of the Simulate entry is changed to \"Continue.\" Clicking on this entry causes a\nmenu similar to the Simulate menu to be posted. By selecting the appropriate entries from\nthis menu, the user can modify the time increment and the new final time; clicking on the\n\"CONTINUE SIMULATION\" entry causes the simulation to continue running, from the\ncurrent time until the specified final time.\nA simulation run may be continued up to four times. After the fourth continuation, the\nsoftware enters the Done environment. This environment resembles the Continue environ\nment, except that the name of the Continue menubar entry is changed to \"Done\" and this\nentry is inactive, since the simulation cannot be continued further. The user can return to\nthe Parameters environment (by clicking on the appropriate menubar entry) to run a new\nsimulation. Figure 3.4 shows the workstation screen after a simulation has been continued\nfour times.\n\n3-25\nUSER'S GUIDE TO THE SOFTWARE\nSummary of a Simulation Run\nAfter setting the option-specific parameters for the current option, the user can set the\nsimulation parameters and start a simulation. While a simulation is running, it can be\npaused by clicking on the Pause menubar entry; a paused simulation can be made to resume\nby clicking on the Resume menubar entry. When a simulation run has finished, it may be\ncontinued up to four times by clicking on the Continue menubar entry and selecting the\nappropriate entry from the menu. After four continuations, the simulation is done and may\nnot be continued again. Clicking on the Parameters menubar entry returns the software to\nthe Parameters environment.\n3.3.4 Saving Results\nSimulation parameters and results may be preserved in two ways: by obtaining a hardcopy\nprintout of the screen image and by saving the simulation state in a data file, which can be\nread in by the simulation at a later time.\nPrinting\nTo obtain a printed copy of the screen contents, the user simply clicks on the \"Print\"\nmenubar entry, which is active in all environments except the Simulate environment (i.e.,\nwhile a simulation is running). Clicking on this entry causes a menu to appear which con\ntains a list of all available printers. The screen contents are sent to the printer selected by\nthe user; alternatively, the user can select the \"Default Printer\" entry, in which case the\nuser's default printer is used.\nFile Handling\nClicking on the \"File\" menubar entry, which is active in the Parameters, Continue, and\nDone environments, causes the file-handling menu to be posted. Selecting the appropriate\nentry from this menu allows the user to read from a data file, write the current state of the\nsoftware to a data file, or delete a file. Selecting any one of these entries cause a file dialog\nbox to be posted in the center of the screen. For the diffusion software, all data files have\nthe extension \".D\". Currently, only one file may be selected at a time.\nThe following data are written to the file:\nThe application name and version (\"diffuse, version 1.0\"), file name, date and time.\nThe current option, followed by the values of all option-specific parameters that have\nvalues that the user can modify.\nFor the Arbitrary and Two-Compartment options, information about the user-drawn\nprofile (as stored in the appropriate span structure).\nThe position graph locations.\n\n3-26\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nThe axis bounds.\nTime graph parameters.\nSimulation parameters (including the simulation time, number of iterations, and\nnumber of continuations) and the current environment.\nFor cases in which the Crank-Nicolson method is used, the current concentration\nprofile.\nTime graph plotting data.\nPosition graph parameters and plotting data.\nThus, the current state of the simulation is written to the data file. A file may be written\nwhen the software is in the Parameters, Continue, or Done environment. An error message\nis posted if the software is unable to write to the specified file. Reading a file into the\nsoftware results in reading the above items from the specified file and resetting all the\nparameters. An error message is posted if the specified file could not be opened for reading,\nif the file is of the wrong format, or if the user tries to read a file when the software is not\nin the Parameters environment.\n3.3.5 Numerical issues\nComputations of concentration and flux are performed at each point in time at 256 points\nequally spaced between the position axis bounds. These results are used to plot the time\nand space graphs. As indicated in Table 3.1, for the Impulse, Sinusoid, and Discontinuity\noptions with transparent boundaries, the exact solution described in Section 3.2 are im\nplemented directly. For the Arbitrary option with transparent boundaries, the profile is\nassumed to be periodic in space. The spatial period is one of the option-specific parameters\nfor the Arbitrary option; thus, its value is chosen by the user. However, the period must be\nchosen to be at least as long as the length of the span of the user-drawn profile. The initial\nconcentration profile is constructed from the span structure as described in Section 3.3.2.\nThe FFT methods is used to compute the concentration at any later time.\nFor all one-compartment problems with reflecting boundaries, as well as the Two-\nCompartment option, numerical methods are used to approximate the solutions. The value\nof\nused in the numerical methods must be chosen small enough so that the methods are\nstable. The software determines such values of\nautomatically. However, for a particular\nchoice of parameters, the maximum value of\nthat can be used will often be smaller, and\nsometimes considerably smaller, than the time increment specified for the simulation run.\nNote -- the increments at which the solution is computed is not the same as the time incre\nment between displayed solutions. Thus, at each step of the simulation, many iterations of\nthe numerical methods must be performed. When the user starts a simulation, the software\ndetermines the number of iterations,\n, that must be performed at each step. Depending\non the value of this number, one of several actions then occurs:\n\nPROBLEMS\n3-27\nIf\n, the simulation run proceeds normally.\nIf\n, a message is posted warning the user that the simulation will\nbe \"somewhat slow,\" due to the large number of computations to be performed. The\nuser must click in the message window to continue.\nIf\n, a more emphatic message is posted, warning the user that the\nsimulation \"will be slow.\" The user can abort the simulation run by clicking on the\n\"Pause\" entry in the menubar and then returning to the Parameters environment.\nFinally, if\n, the software posts a message warning the user that the simu\nlation could not be run because of the huge number of computations required.\n3.4 Problems\nProblem 3.1 In this problem you will investigate the space-time evolution of solute diffu\nsion from a point source. For all parts of this problem use a single impulse and transparent\nboundaries. Set the impulse strength to 100 moles/cm , place the impulse at position 0.5\ncm, and set the drift velocity and the reaction rate to zero. Set the position for the posi\ntion graphs to 0.55 and 0.6 cm unless indicated otherwise. Set the diffusion coefficient to\ncm s and run the simulation for 1000 seconds (simulation time). Obtain a print of the\nsolution on appropriate ordinate scales. The time graph should contain the spatial distribu\ntion of concentration at 1000 seconds and position graphs should contain the concentration\nversus time at the two position. Also obtain a print of the flux versus position and time for\nthe same parameters. Repeat these two steps for a diffusion coefficient of\ncm s.\na) Describe qualitatively the effect of the change in diffusion coefficient on the spatial\ndistribution of concentration. Be brief.\nb) Using the time graph, determine for both values of the diffusion coefficient the max\nimum amplitude of the concentration versus position and the width of the spatial\ndistribution of concentration at an amplitude that is\nof its peak value. Explain the\nnumerical values of all four measurements. Be brief and precise; state your assump\ntions explicitly.\nc) For the diffusion coefficient at\ncm s, examine the concentration versus time at\nthe two positions 0.55 and 0.6 cm. Describe qualitatively the differences in concen\ntration versus time at the two positions. Be brief.\nd) For the diffusion coefficient at\ncm s, measure the maximum concentration\nas a function of time at the two positions and the time of occurrence of this maxi\nmum. Explain the values of all four measurements. Be brief and precise; state your\nassumptions explicitly.\n\n3-28\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\ne) Explain the shape of the spatial distribution of flux for a diffusion coefficient of\ncm s.\nf) Explain the relation between the flux and concentration versus time at location 0.55\ncm for a diffusion coefficient of\ncm s.\ng) Rerun the simulation for a diffusion coefficient of\ncm s at positions 0.45 and\n0.55 cm. Explain the differences in the flux as a function of time for these two\nlocations.\nProblem 3.2 This problem deals with the solution from a point source in the presence\nof convection. Set the impulse strength to 100 moles/cm ; place the impulse at position\n0.5 cm; set the diffusion coefficient to\ncm s, and the reaction rate to zero. Set the\nposition for the position graphs to 0.75 and 0.9 cm unless indicated otherwise.\na) Set the boundary conditions to TRANSPARENT and the drift velocity to zero and\nrun the simulation for 1000 s. Now set the drift velocity to\ncm/s and run the\nsimulation again for 1000 s. Describe the effect of the convection on the spatial\ndistribution of concentration. Account quantitatively for the position of the peak of\nthe spatial distribution at 1000 s.\nb) Set the boundary conditions to REFLECTING and the drift velocity to zero. Run\nthe simulation until the spatial distribution is no longer a function of time. This is\nthe equilibrium distribution. What is the spatial distribution at equilibrium? Explain\nyour answer.\nc) Set the boundary conditions to REFLECTING, the drift velocity to\ncm/s, and\nrun the simulation. Describe the effect of convection on the spatial distribution of\nconcentration. Illustrate your description with printed copies of the distribution at\ncharacteristic times.\nd) With the boundary conditions still set to REFLECTING and the drift velocity\ncm/s,\ndetermine the equilibrium spatial distribution of concentration. Account quantita\ntively for this distribution.\ne) It is known that the density of air decreases exponentially with distance above the\nearth's surface. Explain this phenomenon.\nProblem 3.3 Two-compartment diffusion was examined in Chapter 3 of the Notes begin\nning with 4 assumptions:\n1. The two compartments are well-mixed so that the concentrations of solute\nare\nuniform and have values at time of\nand\n.\n2. Solute particles are conserved, e.g., there is no chemical reaction present that either\ncreates or destroys particles.\n\nPROBLEMS\n3-29\n3. The membrane is sufficiently thin and the number of solute particles contained in the\nmembrane at any time is negligibly small.\n4. The membrane is sufficiently thin that at each instant in time the concentration profile\nin the membrane is in steady state.\nThis problem concerns the conditions for the validity of assumptions 3 and 4. Specifically,\nyou will explore the effect of bath dimensions on two-compartment diffusion without mak\ning these two assumptions.\nIn all parts of the problem, use the Two-compartment mode of the software. Set the\nmembrane Width to 0.01 cm, and the concentration of Bath #1 to 70 and Bath #2 to 10\nmol/cm . Leave the Drift velocity and Reaction rate at 0 and the Diffusion Coefficient\nat\nmembrane and a little of each bath are visible on the screen -- e.g., display a portion of\nthe bath that is 0.0005 cm to the left and right of the membrane. Note that the left edge of\nthe membrane is at a position of 0 cm. Using DRAW INITIAL PROFILE, draw the initial\nconcentration in the membrane. It is a bit tricky, but after a few trials you should get it.\ncm /s. Set the parameters of the plot of concentration versus position so that the\n.\nMake sure all ordinate scales on all plots are 0 to 100 mol/cm\nKeep these parameters\nfixed throughout this problem. Initially set the simulation parameters to be a Final time of\n5 s, a Time increment of 0.2 s, and the Number of sample points at 128. You may wish\nto adjust these parameters to observe different aspects of the diffusion processes.\nFor each of the pairs of bath widths -- Bath #1 = 1 cm, Bath #2 = 1 cm; Bath #1 = 0.1\ncm, Bath #2 = 0.1 cm; Bath #1 = 0.01 cm, Bath #2 = 0.01 cm; Bath #1 = 0.01 cm, Bath #2\n= 0.05 cm; Bath #1 = 0.001 cm, Bath #2 = 0.001 cm; -- answer the following questions.\na) Assess the validity of assumption 4.\ni) Make rough estimates of both the steady-state (\n) and equilibrium (\n) time\nconstants from the computations.\nii) Estimate the same two time constants from the developments in Chapter 3 of\nthe Notes.\niii) What is your conclusion based on your computations and your estimates of time\nconstants?\nb) Assess the validity of assumption 3.\ni) Before you do the computation, make an estimate of the final concentration in\neach bath. Then do the computation, and check your initial estimates against\nthe computed values\nii) If they differ, explain the basis of the difference.\niii) How good is the assumption that the quantity of solute in the membrane is\nnegligible? If you decide that the quantity of solute in the membrane is not\nnegligible, design a simulation experiment to test your conclusion.\ne) Are the bath concentrations exponential functions of time? Explain.\n\n3-30\nCHAPTER 3: MACROSCOPIC DIFFUSION PROCESSES\nProblem 3.4 Some problems in diffusion with a reflecting boundary can be solved by us\ning the solution for a transparent boundary and the method of images to match the reflecting\nboundary condition. This problem explores the successes and pitfalls of this method. In\nall parts of this problem, set the drift velocity to zero, the reaction rate to zero, and the\ndiffusion coefficient to\ncm s unless state otherwise.\na) Use REFLECTING boundaries, and an initial impulse of concentration of strength\n100 moles/cm located at 0.2 cm. Run the simulation for 1000 s and obtain a print of\nthe spatial distribution of concentration at time 1000 s and the concentration versus\ntime at locations 0 and 0.3 cm.\nb) At a reflecting boundary, the flux must be zero. Change the boundary condition\nto TRANSPARENT and determine the parameters of two impulses: one to match\nthe left boundary condition and another to independently match the right boundary\ncondition. Run the simulation again and compare with the results in part a). Does\nthis \"method of images\" work exactly? Explain.\nProblem 3.5 Diffusion from an initial sinusoidal concentration distribution gives impor\ntant insights into the space-time evolution of diffusion processes. In all parts of this prob\nlem, use a drift velocity of zero, a reaction rate of zero, and a diffusion coefficient of\ncm s unless state otherwise.\nand\na) Use an initial sinusoidal concentration distribution with amplitude 50 moles/cm\na spatial frequency of 1 cycle/cm. Run the simulation for 1000 s and print the spa\ntial distribution of concentration at 1000 s and the concentration versus time at 0.25\nand 0.75 cm. Repeat this procedure for sinusoids with the same amplitudes but the\nfollowing spatial frequencies: 3, 5, and 7 cycles/cm. Summarize your results both\nqualitatively (in words) and then quantitatively (with suitable calculations).\nb) Construct a periodic waveform from four sinusoids with the following amplitudes\n(moles/cm ) and spatial frequencies (cycles/cm): 105, 1; 35, 3; 21, 5; 15, 7. Run\nthe simulation and observe the spatial distribution of concentration. Summarize your\nresults and relate them to results of part a).\nc) Switch to the Arbitrary initial distribution option and set the boundary conditions to\nreflecting. Using the mouse draw an arbitrary, preferably jagged, initial profile. Run\nthe simulation and watch the spatial distribution of concentration change. Summarize\nyour results. What is the effect of diffusion on the spatial distribution?\n\nBibliography\n[Berkenblit, 1990] Berkenblit, S. I. (1990). Design of a software diffusion simulator and\nanalysis of a problem in two-compartment diffusion. Master's thesis, Massachusetts\nInstitute of Technology, Cambridge, MA.\n[Fick, 1855] Fick, A. (1855). On liquid diffusion. Philos. Mag., 10:30-39.\n[Gerald and Wheatley, 1989] Gerald, C. F. and Wheatley, P. O. (1989). Applied Numerical\nAnalysis. Addison-Wesley, Reading, MA.\n[Oppenheim and Schafer, 1975] Oppenheim, A. V. and Schafer, R. W. (1975). Digital\nSignal Processing. Prentice-Hall, Englewood Cliffs, NJ.\n[Press et al., 1988] Press, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T.\n(1988). Numerical Recipes in C. The Art of Scientific Computing. Cambridge University\nPress, Cambridge, Massachusetts.\n3-31"
    },
    {
      "category": "Resource",
      "title": "misc.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/1eb419a99c5d7bdbd201c9b2fa04f56d_misc.pdf",
      "content": "SOFTWARE FOR CELLULAR\nPHYSIOLOGY AND BIOPHYSICS\nPART 1\n2.791J / 2.794J / 6.021J / 6.521J / HST541J\nThomas F. Weiss, Giancarlo Trevisan, Elana B.Doering,\nDevang M. Shah, David Huang, and Scott I. Berkenblit\nDepartment of Electrical Engineering and Computer Science\nMassachusetts Institute of Technology\nFall 1996\n\n0-0\n\nChapter 1\nGENERAL INSTRUCTIONS\n1-1\n\n1-2\nCHAPTER 1. GENERAL INSTRUCTIONS\n\n1.1. DO I HAVE TO BE A COMPUTER EXPERT?\n1-3\n1.1 Do I have to be a computer expert to use the software?\nThe software has been written for use by students of physiology and biophysics and focusses on\nthose topics. The programs are written in C and operated under the UNIX operating system on\nworkstations operated by Project Athena. However, you will need to know nothing about C and\nvirtually nothing about the workstations, Project Athena or the UNIX operating system. Although\nnot required, some knowledge of these is helpful to make management of your data files efficient,\nand to allow flexibility in obtaining prints and plots of your results. If you wish to obtain knowledge\nabout Athena and UNIX that exceeds that required to carry out the assignments, read the Project\nAthena \"Essential\"publications such as \"Essential Athena\"and \"Essential UNIX\".You may also\nwish to attend lectures offered on these and other topics by Project Athena.\n1.2 How do I start the subject software?\nTo login to a workstation, first make sure the power is turned on and then type\n. After\na pause, a window will appear that gives directions for login. To connect to the subject software\nsimply use the hierarchic pull-down menu (on the dashboard) to select Courseware, Electrical\nEngineering, Quantitative Physiology. If a rectangular window appears on the screen, click the\nleft mouse button and wait. A menu, entitled Quantitative Physiology: Cells & Tissues, will\nappear that shows the names of the applications programs that are available. If an application\nprogram is available, you will be able to highlight it by moving the mouse and to select it by\nclicking any mouse button. After you have selected an application, the computer will beep and in\na short time a window for controlling the selected software will appear. If the subject software is\nnot available through the dashboard, then type\nadd 6.021J\nThen type one of the following acronyms to start that software package:\ncmt\nhh\ndiffuse\nrwalk\nchannel\nSoftware package\nacronym\nSteady-State Chemically Mediated Transport\nHodgkin-Huxley Model\nMacroscopic Diffusion\nRandom Walk Diffusion\nVoltage-Gated Ion Channels\n1.3 How do I logout?\nFirst click on Quit in the application software and then Quit in the subject software menu. Then\nlogout of the workstation."
    },
    {
      "category": "Resource",
      "title": "rwalk.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/558023884c98ea9c7ec141d2f7d2946b_rwalk.pdf",
      "content": "1-0\n\n2-1\nChapter 2\nRANDOM WALK MODEL OF\nDIFFUSION\n\n2-2\n\nContents\n2 RANDOM WALK MODEL OF DIFFUSION\n2-1\n2.1\nINTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-7\n2.1.1\nHistorical Background . . . . . . . . . . . . . . . . . . . . . . . . 2-7\n2.1.2\nMicroscopic and Macroscopic Models . . . . . . . . . . . . . . . . 2-7\n2.1.3\nOverview of Software . . . . . . . . . . . . . . . . . . . . . . . . 2-8\n2.2\nDESCRIPTION OF THE RANDOM-WALK MODEL . . . . . . . . . . . 2-9\n2.2.1\nParticle Parameters Within a Region . . . . . . . . . . . . . . . . . 2-9\n2.2.2\nBoundary Conditions . . . . . . . . . . . . . . . . . . . . . . . . . 2-12\n2.2.3\nParameters that Change the Number of Particles in the Field . . . . 2-16\n2.2.4\nStatistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-16\n2.3\nUSER'S GUIDE TO THE SOFTWARE . . . . . . . . . . . . . . . . . . . 2-18\n2.3.1\nThe Parameter Environment . . . . . . . . . . . . . . . . . . . . . 2-18\n2.3.2\nThe Simulation Environment . . . . . . . . . . . . . . . . . . . . . 2-23\n2.4\nPROBLEMS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-25\n2-3\n\n2-4\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\n\nList of Figures\n2.1\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-10\n2.2\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-11\n2.3\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-14\n2.4\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-15\n2.5\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-19\n2.6\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-19\n2.7\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-20\n2.8\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-21\n2.9\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-22\n2.10\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-24\n2.11\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-26\n2.12\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2-29\n2-5\n\n2-6\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\n\n2-7\nINTRODUCTION\nEquation\nOne Dimension Three Dimensions\nFick's First Law\nContinuity Equation\nDiffusion Equation\nTable 2.1: The macroscopic laws of diffusion for a concentration of particles diffusing in a homoge\nneous region with a constant diffusion coefficient\n, in the absence of a body force on the particles\nor convection of the medium, and where the particles are conserved.\n2.1 INTRODUCTION\n2.1.1 Historical Background\nA bolus of soluble material will gradually spread out in its solvent, until a uniform solution\nresults. This process has long been intuitively familiar. However, equations that descibe\nthe change in solute concentration, the macroscopic diffusion equations, did not evolve un\ntil the 1850s, and a microscopic or particle-level model, not until the turn of this century.\nThe macroscopic diffusion equations are named for Fick, who presented them (empirically)\nin 1855 [Fick, 1855]. They show that a concentration gradient causes a solute flux and a\nconsequent concentration change; they may be solved to show the space-time evolution of\nsolute concentration from an initial concentration. Fifty years later, Einstein considered en\nsembles of particles in Brownian (random) motion, and showed that statistical averages of\nthe motion of these particles give rise to the macroscopic laws of diffusion [Einstein, 1956].\n2.1.2 Microscopic and Macroscopic Models\nDiffusion plays such an important role in physical as well as biological systems, that it is\nimportant for students of these disciplines to develop an understanding of the macroscopic\nlaws of diffusion and their microscopic basis. These are described in a number of textbooks\n(e.g. Weiss, 1995). Here we will review some important characteristics of the macroscopic\nlaws of diffusion and their relation to random-walk models.\nMacroscopic laws of diffusion\nThe macroscopic laws of diffusion for the simple case when the particles are not subject\nto a body force, when the medium does not convect the particles, when the diffusion co\nefficient is a constant, and when the particles are conserved are summarized in one and\nthree dimensions in Table 2.1. These equations relate the flux of particles ( ), which is the\nnumber of moles of particles transported through a unit area in a unit time, to the concen\n\n2-8\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\ntration of particles ( ), which is the number of moles of particles per unit volume. Fick's\nFirst Law relates flux to particle concentration; it is analogous to other laws that relate\na flow to a force such as Ohm's Law of electric conduction, Darcy's Law of convection,\nand Fourier's Law of heat flow. The Continuity Equation follows from conservation of\nparticles, and the Diffusion Equation is obtained by combining Fick's First Law with the\nContinuity Equation.\nImportant characteristics of diffusion processes are revealed by examining the space-\ntime evolution of concentration from a unit point source. Consider the one-dimensional\nDiffusion Equation with a unit point source located initially at\nfunction of concentration having a strength (area) of 1 mole/cm . The solution is\n; a spatial Dirac delta\nwhich is a Gaussian or Normal distribution in space whose maximum value is at\nand whose width (standard deviation) is equal to\n. Hence, an initial unit source of\nparticles spreads out in space at a rate that is\nalthough the mean position of the\nparticles remains at\n.\nMicroscopic basis of diffusion\nIn a one-dimensional random walk in a homogeneous region of space, we assume a par\nticle moves along the -axis in a series of statistically independent steps of length\nor\n, where the time between steps is . In an unbiased walk, positive and negative steps are\nequally likely, i.e., each has probability 1/2. This simple model can be shown [Weiss, 1995]\nto yield Fick's First Law and consequently the Gaussian distribution of space-time evolu\ntion from a point source. Analysis also shows that the diffusion coefficient, which charac\nterizes the macroscopic laws of diffusion, is related to length and duration of steps, which\ncharacterize the random walk, as follows:\n2.1.3 Overview of Software\nThe software described here is intended to allow students to investigate the properties of\nthe simplest microscopic model that captures the essence of diffusion: the discrete-time,\ndiscrete-space random-walk model.\nIn the discrete-time, discrete space random walk model described here, there is a pop\nulation of particles which execute statistically-independent, but otherwise identical two-\ndimensional random walks in a rectangular field. The field can be divided into one, two, or\nthree homogeneous regions whose widths are specifiable, and whose properties may differ.\nEach particle undergoes a random walk with parameters that include: the probability that\nthe particle takes a step to the left or right, and the step size. These parameters can be set\nindependently in the three regions. The particles can be set to have a specifiable lifetime.\n\nDESCRIPTION OF THE RANDOM-WALK MODEL\n2-9\nOne source and one sink of particles can be placed in the field and the initial concentration\nof particles can be specified in each of the three regions. Characteristics of the boundary\nconditions between regions can also be specified. With this software package it is possible:\nto visualize the spatial evolution of particle concentration from a variety of initial distri\nbutions selectable by the user; to examine the evolution of particle concentration from a\nsource and in the presence of a sink; to examine diffusion in regions of differing diffusion\ncoefficients; to simulate diffusion of particles subjected to a body force; to simulate dif\nfusion between two compartments separated by a membrane; to investigate the effects of\nchemical reactions or recombination which consume particles at a fixed; and to investigate\nthe effects of different boundary conditions between regions. Two diffusion regimes can be\nrun and displayed simultaneously to allow direct comparison between the space-time evo\nlution of two different diffusion processes. In addition, a variety of statistics of the spatial\ndistribution of particles can also displayed.\nBy watching the particles move and by comparing simulation results to expectations,\nthe user can develop an intuition for the way in which the random motions of particles lead\nto their diffusive spread.\n2.2 DESCRIPTION OF THE RANDOM-WALK MODEL\nIn this simulation, the discrete-time, discrete-space random walk takes place on a finite two-\ndimensional grid of locations accessible to the particles and called the field. The location of\neach particle is specified by giving its coordinates on this grid\nwhere is the horizontal\ncoordinate and ranges from 0 to 399 and is the vertical coordinate and ranges from 0 to\n99. The horizontal distance between adjacent grid locations is 1 unit of distance and all\nspatial dimensions of the random walk are expressed as multiples of this unit distance. The\nposition of the particle in the grid can change probabilistically at each step of the random\nwalk. Thus successive steps represent successive times that are separated by a unit time\ninterval. All times are expressed in terms of the number of steps of the random walk.\nThe field can be divided into one, two or three homogeneous regions (Figure 2.1).\nCertain parameters of the simulation are defined for the entire field, others at boundaries\nbetween regions, and still others are defined independently for each region. The latter\nparameters will be described first and include: region size, particle step size, directional\nprobabilities, and initial particle distribution.\n2.2.1 Particle Parameters Within a Region\nThe parameters that define the random walk are identical at each location within a region\n-- each region is homogeneous. These parameters are:\nRegion size\nThe width of each region can be specified, but the sum of the widths cannot exceed 400.\nThis allows a variety of diffusion regimes to be defined. For example, if Region 1 has\n\nFigure 2.1: Definition of simulation field, regions, and boundaries. Solid lines delimit the perime-\nter boundaries of the field; dashed lines indicate the internal vertical boundaries that separate the\nregions.\nwidth of 400 then the other two regions must have width 0 and the random walk is defined\nfor one homogeneous region. By specifying two regions with non-zero widths, it is possi-\nble to define a diffusion process with different initial conditions in the two regions. This\nallows a rich variety of initial distributions to be defined. Three non-zero width regions al-\nlows simulation of diffusion between two regions separated by a third region with different\nproperties. This might be used to investigate diffusion between two baths separated by a\nmembrane.\nStep size\nThe step size defines the distance, in multiples of unit distances, that particles may move\nin each step of time. Varying the step size simulates varying the diffusion coefficient. The\nsize of a region is always set to a multiple of the step size in that region; all particles in\na region are located at integer multiples of the step size starting from the left boundary of\nthe region. This ensures that particles at a boundary fall on the boundary and simplifies the\nspecification of particle motion at a boundary.\nParticle motion --\ndirectional probabilities\nAt each instant in time, a particle is at some location in the region. The disposition of\nthe particle at the next instant in time is determined by one of six mutually exclusive and\ncollectively exhaustive possibilities as illustrated in Figure 2.2. The particle can move one\nstep size to the upper left, upper right, lower left, or lower right; stay in the same location\n(center); or be eliminated (expire). The prbabilities for each of the six outcomes is as\nfollows:\nP[expired]\n2-10\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\nP[center]\nP[upper left]\n\nFigure 2.2: Schematic diagram of motion of a particle in a homogeneous region. The grid of\npossible particle locations, separated by unit distances, are indicated by\n2-11\nDESCRIPTION OF THE RANDOM-WALK MODEL\nsymbols. A particle is\nshown in the center of the figure at one instant in time. One time step later the particle either stays\nin the same location or moves to one of 4 possible locations (indicated by the shaded particle) or it\nexpires (is removed from the field). If the particle moves it translates one step size (here shown as 2\nunits of distance) in both the vertical and the horizontal direction.\n\n2-12\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\nP[upper right]\nP[lower left]\nP[lower right]\n(2.1)\nwhere\nis the average lifetime of the particle, i.e. the average number of time steps to\nexpiration;\nis the conditional probability that the particle moves to the right given that\nit has not expired; is the conditional probability that the particle moves to the left given\nthat it has not expired. Note that while the probability of moving to the left and to right\ncan differ, the probability of moving up or down is always the same. Because the six\nprobabilities define all the possible outcomes at each instant in time, they sum to unity.\nDifferent types of random walks are described by changing the directional probabilities.\nThe random walk defined by assuming\nis the simple, unbiased random\nwalk described in Section 2.1. In general, if\nthe random walk is unbiased; there\nis no statistical tendency for particles to move preferentially in either horizontal direction.\nHowever, if\n, the random walk is biased so that there is a tendency for particles to\nmove in one horizontal direction. For a step size of , the mean distance\nthat the\nparticle moves to the right in\nunits of time is\nInitial distribution of particles\nThe initial distribution of particles can be specified in each of the three regions. Particles\nmust start at locations that are integral multiples of the step size in each region. The initial\ndistribution of particles can be:\nEmpty which implies that initially there are no particles in the region.\nImpulse which implies that a specified number of particles are placed at a specified\nhorizontal position in the region and spaced randomly in the vertical direction.\nLinear which implies that a linear concentration profile is generated whose slope\nand number of particles are specified. Negative concentrations are not allowed: if the\nparameters are chosen such that the concentration would become negative at some\npoint in the region, these putative negative concentrations are set to zero.\nSine which implies that the spatial distribution is sinusoidal with a specified period\nand number of particles.\n2.2.2 Boundary Conditions\nThe field contains three different types of boundaries (Figure 2.1) which are, in order of\nincreasing complexity, horizontal perimeter boundaries at the top and bottom of the field,\nvertical perimeter boundaries at the left and right ends of the field, and vertical internal\nboundaries that separate regions.\n\n2-13\nDESCRIPTION OF THE RANDOM-WALK MODEL\nHorizontal perimeter boundaries\nHorizontal perimeter boundaries act as perfectly reflecting walls. If a particle is located\nwithin one step size of such a boundary and takes a step toward the boundary then the\nnew vertical location of the particle is determined in the following manner: the vertical\ndistance the particle travels to reach the wall plus the vertical distance the particle travels\nafter reflecting from the wall must sum to the step size. This relation determines the new\nposition given the old postion and the value of the step size.\nVertical perimeter boundaries\nThe vertical perimeter boundaries are also reflecting walls. Because the probabilities of\nstepping to the left and right need not be the same, we found that purely reflecting wall\nof the type described for the horizontal perimeter boundaries created undesirable artefacts\nespecially when the conditional probabilities of moving to the left and right were not equal\n(\n). Therefore, we modified the boundary condition so that a particle that would have\ncrossed a vertical perimeter boundary at a given step was placed on the boundary and then\nsubject to the following boundary condition which is illustrated for the left boundary in\nFigure 2.3 and whose directional probabilities are:\nP[expired]\nP[center]\nP[upper right]\nP[lower right]\n(2.2)\ni.e. the particle cannot move to the left.\nVertical internal boundaries\nThe motion of particles at a vertical internal boundary is similar to that within a homoge\nnous region. The differences are that: the step sizes in the two adjacent regions may differ;\nand special directional probabilities, specified by the user, apply at the boundary. These\nhave been provided to allow users to explore the consequences of a rich variety of bound\nary conditions. To simplify boundary conditions, the software ensures that particles do not\ncross this boundary in one time step but rather they land on the boundary. This is guaranteed\nby forcing the width of boundaries, initial particle locations, locations of sources and sinks\nto be commensurate with the step size. Given this restriction, the possible outcomes for a\nparticle on a boundary are shown schematically in Figure 2.4. The directional probabilities\nare identical to those in a homogeneous (region given above) except that the conditional\nand\nprobability of moving to the left and to the right given that the particle did not expire (\nin the homogeneous region) are independently specified at each internal boundary. The\nstep size to the left is equal to the step size in the region to the left of the boundary; the step\nsize to the right is equal to the step in the region to the right of the boundary.\n\nFigure 2.3: Schematic diagram of motion of a particle at a vertical perimeter boundary. For purposes\nof illustration, the particle motion at the left boundary is shown. Conditions at the right boundary\nare the mirror-image of those shown here.\n2-14\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\n\nFigure 2.4: Schematic diagram of motion of a particle at an internal vertical boundary between two\nregions. The step size is 1 to the left of the boundary and 2 to the right of the boundary.\n2-15\nDESCRIPTION OF THE RANDOM-WALK MODEL\n\n2-16\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\n2.2.3 Parameters that Change the Number of Particles in the Field\nAfter the simulation has been initiated with some initial distribution of particles, there are\nthree ways in which the total number of particles in the field can change.\nParticle lifetime\nThe average lifetime\nof particles at any location in the field is specifiable. The effect of\nparticle lifetime on the directional probabilities was described earlier.\nSource\nOne source can be placed at a horizontal location in the field and covers the entire vertical\nheight of the field. The source must be located at an integer multiple of the step size from\nthe left boundary of each region in which it is located. The rate of generation of particles is\nspecified by giving the number of particles (specified as a two-digit number) produced in\nsome number of time steps (specified as a two-digit number). Thus the rate of generation of\nparticles can be a rational number. The particles are generated at the horizontal position of\nthe of the source and are distributed randomly along the vertical direction using a uniform\ndistribution.\nSink\nA sink can be placed at a horizontal location in the field and covers the entire vertical height\nof the field. The sink must be located at an integer multiple of the step size from the left\nboundary of each region in which it is located. Particles that land on the sink are absorbed;\nhence the number of particles at the sink is always zero.\n2.2.4 Statistics\nTwo sets of computations are performed simultaneously during a simulation: statistics\nbased on the actual locations of particle and statistics based on the expected locations of\nparticles. Given a particle location at one step and a set of directional probabilities, a ran\ndom number generator is used to determine which of the possible new locations occurs at\nthe next step. These sequence of locations determines the positions of the particles on the\nscreen and all the statistics labelled actual. However, given a particle location at one time\nand the same directional probabilities, it is possible to estimate the expected location of\nthe particle in the next step. Thus during a simulation both the set of actual and expected\nlocations for the particles are computed. Both the actual and expected statistics may be\nexamined.\nHistogram of horizontal particle locations\nHistograms summarize the spatial distribution of particle locations. Each histogram con\nsists of a set of bins that span the field; the number of bins depends upon the specification\n\n2-17\nDESCRIPTION OF THE RANDOM-WALK MODEL\nof the bin size. With a bin size of 10, there are 40 bins that span the entire field of 400\nlocations. The histogram shows the number of particles in each bin as a function of bin\nlocation. Choice of bin size is important. If the bin size is small then each bin will contain\nrelatively few particles and the number of particles will fluctutate randomly from bin to\nbin. However, a small bin size depicts the particle distribution with a high spatial distribu\ntion. Conversely, a large bin size gives a histogram with poor spatial resolution but a larger\namount of statistical averaging of the spatial distribution of particles.\nThe shape of the histogram is sensitive to the choice of bin size and can lead to con\nfusing patterns. For example, suppose the bin size is five and the step size is two. Suppose\nfurther that particles are located uniformly in the field; one particle per accessible location.\nHowever, the step size constrains the possible locations that a particle may occupy to be\nseparated by 2. Therefore, with a bin size of five, successive bins in the histogram alternate\nbetween 2 and 3 particles. Thus the histogram will not appear uniform, but oscillatory. This\nproblem is cured if the bin size is an integral multiple of the step size. If the step size differ\nin the three regions, then the bin size should be set equal to the least common multiple of\nthe three step sizes.\nStatistics as a function of step number\nA number of statistics (both actual and expected) can be plotted versus step number. These\nare:\nMean Position is the mean position of the particles in the entire field.\nStandard Deviation is the standard deviation of particle location in the entire field.\n#Generated is the cumulative number of particles generated by the source since the\nbeginning of the simulation.\n#Absorbed is the cumulative number of particles absorbed by the sink since the\nbeginning of the simulation.\n#Expired is the cumulative number of particles lost due to the finite lifetime of par\nticles since the beginning of the simulation.\nTotal #Particles is the total number of particles in the entire field at each step number.\nRegion 1 #Particles is the total number of particles in Region 1 at a given step\nnumber.\nRegion 2 #Particles is the total number of particles in Region 2 at a given step\nnumber. For this total only, the particles located at the boundary between Region 1\nand Region 2 are counted as belonging to Region 2.\nRegion 3 #Particles is the total number of particles in Region 3 at a given step\nnumber. For this total only, the particles located at the boundary between Region 2\nand Region 3 are counted as belonging to Region 3.\n\n2-18\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\nThese statistics allow a quantitative evaluation of a simulation. A systematic change in the\nmean position of the particles as a function of step number demonstrates a drift or migration\nof the particles as can be achieved by a bias in the directional probabilities. A difference in\nthe standard deviation of two distributions can be achieved by changing the step size. The\ndependence on step number of the number of particles in the field, in a region, generated,\nabsorbed, or expired can be used to assess whether a particle distribution has reached steady\nstate. The change in the total number of particles in each region can be used to estimate the\nrate of transport of particles between regions.\n2.3 USER'S GUIDE TO THE SOFTWARE\nThe program has two environments: the parameter and the simulation environments. The\nparameter environment allows the user to change the characteristics of the random walk,\nthe initial conditions, and the inter-region boundary conditions. The user may also load\nand save data files, and view the initial conditions, without leaving this environment. In the\nsimulation environment, the user may watch the particles execute the random walk, while\nhistograms display their actual and expected distribution along the horizontal axis. In both\nenvironments, the user may view statistics of the random walk and print the contents of the\nscreen.\n2.3.1 The Parameter Environment\nWhen the program is initiated, it puts a window (bordered box for display of text and\ngraphics) on the screen. At startup, the program is in the parameter environment, and the\nwindow is as shown in Figure 2.5.\nThe menu bar\nThe menu bar at the top of the window contains three commands: Simulation, Files, and\nStatistics. To select a command, the user highlights it by positioning the arrow cursor, and\nclicks any mouse button. Clicking on a highlighted command causes a drop-down menu\nto appear, as shown in Figure 2.6. Items in the drop-down menu are selected with the\nmouse as they were in the menu bar. In both the menu bar and the drop-down menu, if the\ncommand cannot be highlighted, it is not available for selection.\nSimulation. Selection of Simulation allows five options:\nEdit allows modification of the random walk parameters by clicking on any high\nlighted value to modify it (detailed below). After selecting Edit and changing param\neter values, the Statistics option is no longer available because the new parameters\ndo not correspond to the computed statistics.\n\n2-19\nUSER'S GUIDE TO THE SOFTWARE\nFigure 2.5: Window in the parameter environment after the View option has been selected to show\nthe initial distribution of particles.\nFigure 2.6: Window in the parameter environment showing the drop-down menu for the Simulation\ncommand.\n\n2-20\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\nFigure 2.7: Window in the parameter environment showing the drop-down menu used to select the\nprinter.\nView allows viewing the initial conditions of the random walk for the chosen param\neters (Figure 2.5) without exiting the Parameter environment. (View always shows\ninitial conditions, even after a simulation has been run.)\nStart transfers control to the Simulation environment.\nPrint Screen allows selection of a printer for printing the contents of the screen\n(Figure 2.7).1\nQuit transfers control out of the random walk software and to the main menu that\nallows access to other software.\nFiles. Selection of Files allows several options (Figure 2.8):\nClicking on Simulation allows selection of the simulation that will be read or written.\nEach click changes the selection between #1 and #2.\nClicking on Read in data from file... allows reading the results of a previous simu\nlation into simulation #1 (top) or #2 (bottom) as selected previously.\nClicking on Write data to file... allows writing the results of a simulation to a file.\nClicking on Delete file... allows files to be deleted.\n1Printing the screen is VERY slow! Do not overuse it!\n\n2-21\nUSER'S GUIDE TO THE SOFTWARE\nFigure 2.8: Window in the parameter environment showing the associated menu when Files is\nselected.\nWhen any of the file handling options are selected, a new menu appears that allows selec\ntion of files and directories (Figure 2.9). The contents of the current directory is shown.\nThe current directory can be changed to a subdirectory either by clicking on the name of\nthe subdirectory or by typing its name into the rectangular window. In either case, click\non set directory after selecting the directory. (Recall that two dots .. means back up one\nlevel in directory hierarchy.) Clicking on a filename selects that file for subsequent action.\nClicking on Read reads the file. Typing into the rectangular window allows naming a file\nfor purpose of writing to disk. Filenames must end in .rw.\nStatistics. Selection of Statistics allows graphic display of the latest statistics. This com\nmand is available only after a simulation has been run for 1 or more steps or has been loaded\nfrom a data file. Statistics allows the user to display statistics of the simulation as well as\nthe expected statistics for the simulation plotted versus step number. However, only 400\nentries can be saved in a file. If the step number exceeds 400, then the sequence of entries\nis decimated by a factor of two (the data for every other step are discarded); each entry\ncorresponds to the data from every other step. As the simulation proceeds, the decimation\nprocess is continued to maintain a number of entries less than or equal to 400.\nThe simulation parameters\nRegion Size. The user may define up to three regions, whose combined width may\nnot exceed 400.\n\n2-22\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\nFigure 2.9: Window in the parameter environment showing the associated menu when Read in data\nfrom file... has been selected from the Files menu.\nStep Size. The step size can be specified independently in each region.\nRight Step Prob. The conditional probability of a step to the right given that the\nparticle has not expired can be specified independently in each region.\nLeft Step Prob. The conditional probability of a step to the right given that the\nparticle has not expired cannot be specified but is set so that in each region the sum\nof the conditional probabilities of stepping to the left and right and staying in the\nsame place all sum to one.\nStay Prob. The conditional probability that the particle stays in the same location\ngiven that the particle has not expired can be specified independently in each region.\nInitial Distribution Of Particles. The initial distribution of particles can be specified\nindependently in the three regions. Selection of a different function allows selection\nof the parameters for that function.\nBoundary Cases. The perimeter boundaries of the field act as reflecting boundaries;\nthe boundaries between regions are characterized by user-defined boundary condi\ntions or Boundary Cases. Boundary conditions are defined as shown in Figure 2.5:\nleft-step-probability\n, stay probability\n, and right-step-probability\nat the\nboundary between Region and Region\n(Region #1-#2, Region #2-#3). For ex\nample, if the Region #1-#2 has the set of probabilities\nthen\nparticles at the boundary may only step to the right. Therefore, to a particle from\n\n2-23\nUSER'S GUIDE TO THE SOFTWARE\nRegion #2, this looks like a reflecting boundary, whereas all particles reaching the\nboundary from Region #1 will cross into Region #2. As with the directional proba\nbilities within a region, the user selects the probability of a step to the right and the\nprobability of no step; the probability of a step to the left is then computed so that\nthe three probabilities sum to one.\nSource. The location of the source can be specified as well as the number of particles\ngenerated in a specified number of steps.\nSink. The particle sink may be turned ON and its location specified.\nAverage Lifetime. The user may define the average particle lifetime in steps. There\nis one quirk to this -- in order to set the lifetime to infinity (particles do not expire),\ntype zero for the average lifetime. The display will indicate that the lifetime is now\ninfinite.\nHistogram. The histogram binsize determines the resolution of the histogram. Small\nbin sizes produce histograms of particle locations with high spatial resolution but a\ngreat deal of statistical variation. Large bin sizes result in histograms with poorer\nspatial resolution but less statistical variation in the histogram. The binsize should be\na multiple of the particle step size. Selecting scaling allows the ordinate scale of the\nhistogram to be selected manually or automatically.\n2.3.2 The Simulation Environment\nWhen Start is selected in the parameter environment, control passes to the simulation\nenvironment. Initially, the screen might look like the one shown in Figure 2.10. There is\nno single Menu Bar; instead, the top of the screen shows Display Controls and Simulation\nControls.\nDisplay Controls\nExpected Histogram ON or OFF. Click on ON or OFF at any time while the simu\nlation is running. The simulation runs faster with the expected histogram OFF.\nParticle Display ON or OFF. Click on ON or OFF at any time while the simulation\nis running. The simulation runs much faster with the particle display OFF. When the\nsimulation is PAUSED, the particle display automatically reappears.\nSimulation Controls\nAvailable commands are in boldface type; they are selected by pointing to them with the\nmouse and clicking. (Unlike other menus, pointing and clicking does not highlight Simu\nlation Controls.)\n\n2-24\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\nFigure 2.10: Window in the simulation environment before (upper) and after (lower) running the\nsimulation for 356 steps using the the parameters shown in Figure 2.5.\n\nPROBLEMS\n2-25\nPAUSE. Halt particle motion, and calculate actual and expected values. A running\nsimulation must be PAUSED before any other choices are available.\nCONTINUE. Resume particle motion, i.e., run the simulation. The simulation must\nbe CONTINUING if Display Controls are to be changed.\nGRAPH. Graph statistics, just as in the Parameter environment (Statistics item in\nMenu Bar). An example of the display is shown in Figure 2.11.\nPRINT. Print contents of screen on a designated printer, just as in the Parameter\nenvironment (Print Screen option, Simulation item in Menu Bar).\nSTOP. Return to Parameter environment.\n2.4 PROBLEMS\nProblem 2.1 This problem deals with random walks for particles that all begin from the\nsame location at an initial time, i.e. the initial distributions are impulses.\na) Use the default simulation parameters, run the simulation for about 100 steps, and\nthen pause the simulation. Note that the parameters of Simulation #1 and #2 differ\nonly in step size. Examine graphs of the average and the standard deviation of the\nhorizontal locations of the particles versus step number.\ni) Explain quantitatively the differences in the graphs in terms of the difference in\nstep size of the two simulations.\nii) Why does the slope of the standard deviation decrease with step number? What\ntype of dependence on step number do you expect?\nb) Now set the step size to 2 for both simulations and decrease the number of particles\nin the impulse for one of the simulations to 25. Rerun the simulation. How does the\nnumber of particles affect the dependence of average position and standard deviation\non step number?\nc) Set all the parameters at their default values and then set the step size for both Sim\nulation #1 and #2 to 2. For simulation #1 set the right step probability to 0.75, the\nleft step probability to 0.25, place an impulse of 50 particles at location 100. For\nsimulation #2 set the right step probability to 0.25, the left step probability to 0.75,\nplace an impulse of 50 particles at location 300. Run the simulation for at least 100\nsteps. Examine graphs of the average and the standard deviation of the horizontal\nlocations of the particles versus step number. Explain these results quantitatively.\nProblem 2.2 This problem deals with the steady-state distribution of particles in the pres\nence of a source and sink for both unbiased and biased random walks. For all parts of this\nproblem set the parameters for both Simulation #1 and #2 as follows: make the size of\n\n2-26\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\nFigure 2.11: Example of statistics option. The displays show the mean (upper) and standard devi\nation (lower) of the distributions of horizontal particle locations plotted versus step number for the\nsimulations shown in Figures 2.5 and 2.10.\n\nPROBLEMS\n2-27\nRegion #1 400; the step size 20; and make the initial distribution of particles empty. Also\nplace a source at location 0 and a sink at location 400 and make the histogram bin size 20.\na) Make the random walks for both Simulation #1 and #2 unbiased with a right step\nprobability of 0.5. For simulation #1 make a source that generates 1 particle every\n2 steps and for Simulation #2 make a source that generates 1 particle every 1 step.\nMake the particle lifetime infinite for both simulations. Now run the simulation.\nIn the steady-state, by definition the particle distribution will not depend upon step\nnumber.\ni) Before you run the simulation, estimate the form of the steady-state particle\ndistribution. Is it uniform, exponential, an impulse, linear, Gaussian, or none of\nthese?\nii) Using the statistics available, determine a criterion for estimating when the par\nticle distribution is in steady state.\niii) Now run the simulation until your criterion for steady state is met. What is the\nsteady-state particle distribution? Does it fit with your initial expectation?\niv) How can you explain the difference in steady-state distribution for the two sim\nulations?\nv) Show that the steady-state particle distribution you have found for the random\nwalks is consistent with Fick's Laws.\nb) Use the same parameters for Simulation #2 as in a), but change those of Simulation\n#1 so that the source rate is also 1 particle every 1 step; and so that the probability of\na right step is 0.55. Run the simulation until it has reached a steady state.\ni) Compare the steady-state distributions for the biased and unbiased random\nwalks. How do they differ?\nii) What is the shape of the steady-state distribution for the biased walk?\niii) How would you modify Fick's First Law to account for not only diffusion of\nparticles but a steady drift of particles of velocity ? What steady-state distri\nbution of particles is predicted from Fick's Laws and the Continuity Equation\nin the presence of this steady drift of particles? Is this consistent with the sim\nulation results you obtained?\nc) Keep the parameters of Simulation #1 and #2 the same as in b), but change the right\nstep probability of Simulation #2 to 0.48. Explain the differences in the shapes of the\nsteady-state distributions for the two simulations.\nProblem 2.3 This problem deals with the effect of a finite particle lifetime on the statistics\nof random walks.\n\n2-28\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\na) Define a simulation with an initial particle distribution that is a uniform distribution\nof particles in space, but with a finite average particle lifetime. Run the simulation\nuntil all the particles have expired. Examine a graph of # particles versus step num\nber. Explain the shape of this function.\nb) Define another simulation that is identical with the one in a), but this time with a\nsource of particles. Do you expect a steady state to be reached between the the\nsource and expirations? Determine a criterion for steady state and check out your\nintuition.\nc) Design a combination of source rate and lifetime such that the distribution reaches a\nsteady state. This might correspond, for example, to a drug concentration reaching\nsteady state in the body, as it is both infused and eliminated.\nd) Design a combination of source rate and lifetime such that most particles in the region\nhave expired by the time the source injects the next batch. This might correspond to\nthe drug concentration when the dosing interval is longer than the elimination half-\nlife of the drug.\nProblem 2.4 This problem deals with a random walk in three regions. Set up the param\neters as shown in Figure 2.12. For both simulations, the two end regions contain uniform\nconcentrations of particles; but the number of particles differ. There is a concentration dif\nference between the end regions. The center region can be regarded as a membrane that\nseparates the two end regions. The random walk in the membrane region is unbiased in one\nsimulation and biased in the other. Run the simulation for several hundred steps.\na) Explain the differences between the distributions of particles for the two simulations.\nb) Quantitatively describe the flux of particles between the two end compartments --\nboth the magnitude and sign of the flux.\nc) What physical process might this simulation represent?\nProblem 2.5 Design a three region diffusion regime where the center region is considered\nto be a membrane. Design membrane characteristics such that the membrane is transparent\nfor particles moving from left to right but purely reflecting for particles moving from right\nto left. Test your design by running the simulation.\nProblem 2.6 Start with two identical simulations with Regions #1 and #2 that have: a\nregion size of 400; a step size of 2; unbiased random walks; no sources or sinks; infinite\nparticle lifetimes; and sinusoidal initial particle distributions. Choose one simulation with\na period of 200 and the other with a period of 50. Choose an appropriate bin size for the\nhistograms. Run the simulation.\na) What is the shape of the equilibrium distribution of particles?\nb) Which particle distribution approaches this equilibrium faster?\nc) Experiment with different frequencies and generalize your conclusion from b).\n\nPROBLEMS\n2-29\nFigure 2.12: Random walk in 3 regions.\n\n2-30\nCHAPTER 2: RANDOM WALK MODEL OF DIFFUSION\n\nBibliography\n[Einstein, 1956] Einstein, A. (1956). Investigations on the Theory of the Browninan Move\nment. Dover Publications. Translation of original publications.\n[Fick, 1855] Fick, A. (1855). On liquid diffusion. Phil. Mag., 10:30-39.\n[Weiss, 1995] Weiss, T. (1995). Cellular Biophysics -- Volume 1: Transport. MIT Press,\nCambridge, MA.\n2-31"
    },
    {
      "category": "Resource",
      "title": "manual4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/dcf09f6e9e48390c841f7603c6fbd774_manual4.pdf",
      "content": "CELLULAR BIOPHYSICS\nSOFTWARE BASED ON MATLAB\nThomas Fischer Weiss\nand\nTanmaya Shubham Bhatnagar\nDepartment of Electrical Engineering and Computer Science\nMassachusetts Institute of Technology\nFall 1997\nDate of last modification: October 25, 1997\n\nii\n\niii\nPreface\nHistorical perspective\nDuring the 1980's the use of computers and information technologies began to\nhave an impact on higher education (Kulik and Kulik, 1986; Balestri, 1988; Wil\nson and Redish, 1989; Athena, 1990a; Athena, 1990b). As an integral part of this\ntrend, in 1983 MIT in partnership with the Digital Equipment Corporation and the\nIBM Corporation launched Project Athena which was designed to make computa\ntion available to undergraduate students through a network of computers located\nin public clusters on the MIT campus (Athena, 1990a; Athena, 1990b). A major\nobjective of Project Athena was to improve undergraduate education through\nthe use of computation and information technologies. Faculty were encouraged\nto participate, and support for faculty software developers was provided on a\ncompetitive basis.\nOne of us (TFW) has been involved in teaching cellular biophysics at MIT since\nthe 1960's. The possibility of using software as a pedagogical aid was intriguing.\nWith support from Project Athena, a software package on the Hodgkin-Huxley\nmodel for nerve excitation was developed as part of an undergraduate thesis (by\nDavid Huang), and was first used to teach cellular biophysics in the Fall 1984\nsemester. The software was designed to be easy to use so that a student's atten\ntion would be focussed on the Hodgkin-Huxley model and not on the computer.\nInformal discussions with students and a survey of student views showed that the\nsoftware was an enormous success. During the first semester, the software was\nused primarily in lecture demonstrations and as the basis for student projects.\nBoth pedagogic methods were found to be effective. The use of the software\nin lecture was very effective in motivating and engaging students. The student\nprojects were effective in allowing students to pursue a research project of their\nchoice with staff assistance. For many students this was their first experience\nwith a research project. The use of these projects, developed in the first year,\nwas so successful that it has been used ever since.\nThe initial results with the Hodgkin-Huxley software were so successful ed\nucationally, that several other software development projects involving student\nprogrammers were launched. In all, 5 software packages were developed and\nhave been used every year to teach the subject. All of these packages were re\nvised extensively in response to suggestions from students and staff. The original\nsoftware runs on UNIX workstations under MIT's Project Athena and is available\nto the MIT community on a network of about 1000 UNIX workstations located in\npublic clusters on the MIT campus as well as in some living groups. All this soft\nware was written in C and XWindows and was based on a library of graphic user\ninterface subroutines written by one of the students (Giancarlo Trevisan). The\nsoftware has been used in lectures, in recitations held in an electronic classroom\nin which each student uses a workstation, in homework assignments, and in stu\n\niv\ndent projects. Various modes of use of the software in teaching were developed\nand are described briefly elsewhere (Weiss et al., 1992) and more extensively in\nthe last chapter of this manual. The software has become an integral part of the\nsubject, and it is difficult to imagine teaching the subject without the software.\nSeveral problems became apparent in the development and utilization of the\nsoftware. First, it was very expensive, in time and in money, to develop the soft\nware with the software tools available in the late 1980's. Much of the time was\nexpended in the development of graphic user interfaces that make the software\neasy for the user but which are tedious for the programmers to specify. These\ngraphic user interfaces had to be written in a low-level language (XWindows).\nWhen Project Athena ended in 1991 and the funds from corporate sponsors were\nno longer available to support the development of new software, this develop\nment slowed considerably. Second, maintenance of the software became a major\nheadache. It became difficult for a single faculty member with research, teaching,\nand other academic commitments to maintain a library of software in the face\nof changes in the operating systems. Third, as word spread about the existence\nof the software, educators and students outside of MIT requested the software.\nThese requests accelerated dramatically after one of the software packages en\ntitled Hodgkin-Huxley Model won the 1990 EDUCOM/NCRIPTAL Higher Educa\ntion Software award for Best Engineering Software. However, almost all of the\nrequests came from students and faculty with access to Macintosh or PC com\nputers and not to UNIX workstations. Thus, when these people were informed\nthat the software ran only on UNIX workstations, they invariably lost interest.\nAt the time the software was written, the computational power of workstations\nso exceeded that of personal computers (PCs) that it was simply not possible\nto provide the type of performance on PCs that was achieved on the worksta\ntions. Furthermore, MIT's Project Athena was committed to a network of UNIX\nworkstations. Thus, for both software and hardware considerations, it did not\nmake sense to port the existing software to PCs. Furthermore, the high cost of\nsoftware development and maintenance did not justify further development of\neducational software on UNIX workstations alone. Thus, the development of new\nsoftware was terminated in 1991.\nBy 1995, a number of developments made it feasible to address the problems\ndescribed above and to develop software for teaching cellular biophysics in a\nmanner that would make it easier to maintain, easier to modify, and widely avail\nable. Thus, all the software was rewritten to operate under MATLAB, which is a\nsoftware package produced by The MathWorks, Inc., for the following reasons:\nMATLAB is a powerful interpretive computational and visualization soft\n-\nware package with a large number of higher-level built-in functions. Thus,\nit is suitable for the development of educational software packages.\nMATLAB is available for Macintosh computers running on MacOS, PCs run\n-\nning Microsoft Windows, and UNIX workstations running XWindows. Thus,\n\nv\nMATLAB runs on all the platforms commonly found in academic settings.\nThe vendor supports changes in MATLAB that are required as changes in\ncomputer platforms occur. With the use of software built on MATLAB, this\nmajor maintenance job is transferred from individual faculty members to\nthe vendor who has both the financial incentive and expertise to maintain\nthe vendor software.\nLarge improvements in performance of PCs have made the development of\n-\ncomputationally intensive educational software feasible on these platforms.\nMATLAB has provided increasingly sophisticated tools for building graphic\n-\nuser interfaces (GUIs). These GUIs are essential for building user-friendly\neducational software packages.\nMATLAB has rapidly become the de facto leader in supporting educational\n-\ncomputational subjects at MIT and elsewhere. Thus, students are exposed\nto MATLAB in other subjects and the different exposures are mutually re\ninforcing.\nThe effort to port the software to MATLAB was supported for 3 years by the Na\ntional Science Foundation. The present software manual describes this software.\nAlthough the software is not linked directly to any textbook, it was developed in\nparallel with textbooks in cellular biophysics (Weiss, 1996a; Weiss, 1996b).\nAcknowledgement\nA number of people contributed to the success of the development of this soft\nware. We thank Project Athena, especially its two directors Steven Lerman and\nEarll Murman, for their support. In addition Gerald Wilson, Joel Moses, Richard\nAdler, Paul Penfield, and Jeffrey Shapiro were unfailingly supportive of this effort.\nA number of students were involved in this effort. David Huang wrote the first\nversion of the Hodgkin-Huxley model package. David Koehler also contributed to\nthis package. Devang M. Shah wrote the first version of the random-walk model\npackage which was also revised by Elana B. Doering. Chapter 2 is based heav\nily on Devang's thesis (Shah, 1990). Scott I. Berkenblit wrote the first version of\nthe macroscopic diffusion package. Chapter 3 is based heavily on Scott's thesis\n(Berkenblit, 1990). Stephanie Peek and Leela Obilichetti helped to develop the\ncarrier-mediated transport package. Giancarlo Trevisan was a major contributor\nto all the packages. He wrote the first version of the voltage-gated ion channel\npackage. He later rewrote the Hodgkin-Huxley package and the carrier-mediated\ntransport package. He wrote all the graphic user interface routines that were\nultimately used by all the packages. Generations of students benefited from his\nefforts. The recipients of the 1990 EDUCOM/NCRIPTAL Higher Education Soft\nware Award for Best Engineering Software for the Hodgkin-Huxley package were\n\nvi\nThomas Weiss, Giancarlo Trevisan, and David Huang. More than a dozen gener\nations of the students who took the subject helped to find flaws in the software\nand made valuable suggestions for its improvements.\nBesides the support from Project Athena, the development of the software\nwas supported by the Howard Hughes Medical Institute for which we are grate\nful. TFW was supported in part by the Thomas and Gerd Perkins professorship.\nThe porting of the software to MATLAB was supported by the National Science\nFoundation (NSF), Division of Undergraduate Education. We would particularly\nlike to thank Dr. Herbert Levitan, Section Head of Course and Curriculum De\nvelopment of NSF. Dr. Karen C. Cohen has been helpful in the evaluation of the\nsoftware.\nThe division of labor on the present MATLAB-based software is as follows:\nThe software was designed by both TSB and TFW but is based heavily on the\nprevious software. The MATLAB code was written by TSB. Both TSB and TFW\ntested the software extensively. The manual was written primarily by TFW.\n\nContents\n1 INTRODUCTION\n1.1 Overview Of Software Packages . . . . . . . . . . . . . . . . . . . . . . .\n1.2 Brief Introduction To MATLAB . . . . . . . . . . . . . . . . . . . . . . .\n1.2.1 Jargon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.2 Help . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3 Starting And Quitting The Software . . . . . . . . . . . . . . . . . . . .\n1.3.1 Directory structure . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3.2 Starting the software . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3.3 Quitting the software . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4 Common Features Of Software Packages . . . . . . . . . . . . . . . . .\n1.4.1 Controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.2 Quitting a package . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.3 Printing/saving a figure . . . . . . . . . . . . . . . . . . . . . . .\n1.4.4 Reading from and saving to a file . . . . . . . . . . . . . . . . .\n1.4.5 Flexible graphic resource . . . . . . . . . . . . . . . . . . . . . .\n1.4.6 Scripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2 RANDOM WALK MODEL OF DIFFUSION\n2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.1.1 Historical background . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.1.2 Macroscopic and microscopic models . . . . . . . . . . . . . . . 16\n2.1.3 Overview of software . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.2 Description Of The Random-Walk Model . . . . . . . . . . . . . . . . . 18\n2.2.1 Particle parameters within a region . . . . . . . . . . . . . . . . 19\n2.2.2 Boundary conditions . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.3 Parameters that change the number of particles in the field .\n2.2.4 Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.3 User's Guide To The Software . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.3.1 RW controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.3.2 Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.3.3 Particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.3.4 Histogram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.3.5 Graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nvii\n\nviii\nCONTENTS\n2.3.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.3.7 Miscellaneous issues . . . . . . . . . . . . . . . . . . . . . . . . . 31\n2.4 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3 MACROSCOPIC DIFFUSION PROCESSES\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n3.1.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n3.1.2 Macroscopic model of diffusion . . . . . . . . . . . . . . . . . . 38\n3.1.3 Overview of software . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.2 Methods of Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n3.2.1 Exact solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n3.2.2 Numerical Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n3.2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n3.3 User's Guide To The Software . . . . . . . . . . . . . . . . . . . . . . . . 45\n3.3.1 MD controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n3.3.2 Initial concentration profile . . . . . . . . . . . . . . . . . . . . . 46\n3.3.3 Numerics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n3.3.4 Analysis figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.3.5 Arbitrary concentration profiles . . . . . . . . . . . . . . . . . . 55\n3.4 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4 CARRIER-MEDIATED TRANSPORT\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n4.2 Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n4.2.1 Steady-state behavior of a simple, four-state carrier that binds\none solute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n4.2.2 Steady-state behavior of a simple, six-state carrier that binds\ntwo solutes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n4.2.3 Transient and steady-state behavior of a general, four-state\ncarrier that binds one solute . . . . . . . . . . . . . . . . . . . . 67\n4.3 Numerical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n4.3.1 Numerical methods . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n4.3.2 Choice of numerical parameters . . . . . . . . . . . . . . . . . . 71\n4.4 User's Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n4.4.1 CMT controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n4.4.2 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n4.4.3 Steady-state interactive analysis . . . . . . . . . . . . . . . . . . 76\n4.4.4 Steady-state graphic analysis . . . . . . . . . . . . . . . . . . . . 77\n4.4.5 Transient analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\n4.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n5 HODGKIN-HUXLEY MODEL\n5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n5.1.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n\nCONTENTS\nix\n5.1.2 Overview of the software . . . . . . . . . . . . . . . . . . . . . . 86\n5.2 Description Of The Model . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n5.2.1 Voltage-clamp and current-clamp configurations . . . . . . . . 87\n5.2.2 The membrane current density components . . . . . . . . . . 87\n5.2.3 The membrane conductances . . . . . . . . . . . . . . . . . . . . 88\n5.2.4 The activation and inactivation factors . . . . . . . . . . . . . . 88\n5.2.5 The rate constants . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n5.2.6 Time constants and equilibrium values of activation and in\nactivation factors . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n5.3 Numerical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n5.3.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n5.3.2 Choice of integration step t . . . . . . . . . . . . . . . . . . . . 90\n5.3.3 Method for computing solutions . . . . . . . . . . . . . . . . . . 91\n5.4 User's Guide To The Software . . . . . . . . . . . . . . . . . . . . . . . . 92\n5.4.1 Controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n5.4.2 Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n5.4.3 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n5.4.4 Scripting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n5.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n5.6 PROJECTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n5.6.1 Practical considerations in the choice of a topic . . . . . . . . 116\n5.6.2 Choice of topics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\n5.6.3 The proposal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n5.6.4 The computations . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n5.6.5 The report . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n6 VOLTAGE-GATED ION CHANNELS\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n6.1.1 Historical background . . . . . . . . . . . . . . . . . . . . . . . . 126\n6.1.2 Overview of software . . . . . . . . . . . . . . . . . . . . . . . . . 126\n6.2 Description Of The Model . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n6.3 Numerical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n6.3.1 Integration step . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n6.3.2 Initial conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n6.4 User's Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n6.4.1 Controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n6.4.2 Channel parameters . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n6.4.3 Membrane potential . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n6.4.4 Numerics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n6.4.5 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\n6.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\n\nx\nCONTENTS\n\nList of Figures\n1.1 Softcell figure showing the available software packages . . . . . . . .\n1.2 The print figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3 Example of the use of the flexible graphic resource . . . . . . . . . .\n1.4 The select x,y figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5 The axis scale figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.1 Definition of grid of particle locations . . . . . . . . . . . . . . . . . . 18\n2.2 Definition of simulation field, regions, and boundaries . . . . . . . . 19\n2.3 Motion of a particle in a homogeneous region . . . . . . . . . . . . . . 20\n2.4 Motion of a particle at a vertical perimeter boundary . . . . . . . . . 22\n2.5 Motion of a particle at an internal vertical boundary . . . . . . . . . . 23\n2.6 The rw controls figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.7 Parameters figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.8 Initial locations of particles . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.9 Locations of particles after a 100 step random walk . . . . . . . . . . 29\n2.10 Histogram of particle locations after a 100 step random walk . . . . 30\n2.11 Standard deviation of particle location versus step number . . . . . 30\n2.12 Numerical summary of statistics after a 100 step random walk . . .\n2.13 Parameters for a random walk in 3 regions . . . . . . . . . . . . . . . 34\n2.14 Initial locations of particles for a random walk in 3 regions . . . . . 35\n3.1 Classes of initial concentration profiles simulated by the software .\n3.2 The MD controls figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n3.3 Initial concentration figure for impulses . . . . . . . . . . . . . . . . . 47\n3.4 Initial concentration figure for sinusoids . . . . . . . . . . . . . . . . . 48\n3.5 Initial concentration figure for discontinuities . . . . . . . . . . . . . 49\n3.6 Initial concentration figure using the arbitrary option . . . . . . . . . 50\n3.7 Initial concentration figure for the two compartments option . . . . 51\n3.8 The diffusion parameters figure . . . . . . . . . . . . . . . . . . . . . . 52\n3.9 The numerics figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.10 Plots versus position figure . . . . . . . . . . . . . . . . . . . . . . . . . 54\n3.11 Plots versus time figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.1 Kinetic diagram of the simple, four-state carrier . . . . . . . . . . . . 63\n4.2 Kinetic diagram of a simple, six-state carrier that binds two solutes\nxi\n\nxii\nLIST OF FIGURES\n4.3 Kinetic diagram of a general, four-state carrier model . . . . . . . . . 68\n4.4 Controls figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n4.5 Units of all variables in the carrier models . . . . . . . . . . . . . . . . 72\n4.6 Parameters and state figures for the simple, four-state carrier model\nthat binds one solute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n4.7 Parameters and state figures for the simple, six-state carrier that\nbinds two solutes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n4.8 Parameters and state figures for the general, four-state carrier that\nbinds one solute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n4.9 The steady-state graphic analysis figure . . . . . . . . . . . . . . . . . 78\n4.10 The transient analysis figure . . . . . . . . . . . . . . . . . . . . . . . . 79\n4.11 The set up transients figure . . . . . . . . . . . . . . . . . . . . . . . . . 80\n4.12 The transient numerics figure . . . . . . . . . . . . . . . . . . . . . . . . 81\n5.1 Voltage-clamp configuration . . . . . . . . . . . . . . . . . . . . . . . . . 87\n5.2 Current-clamp configuration . . . . . . . . . . . . . . . . . . . . . . . . 87\n5.3 The controls figure after the software is initiated . . . . . . . . . . . . 92\n5.4 The controls figure after the software is initiated . . . . . . . . . . . . 93\n5.5 The parameters versus membrane potential figure . . . . . . . . . . . 95\n5.6 The select y figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n5.7 Stimulus figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n5.8 Example of a stimulus waveform . . . . . . . . . . . . . . . . . . . . . . 98\n5.9 The numerics figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n5.10 The block diagram figure . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n5.11 Expansion of the current clamped block . . . . . . . . . . . . . . . . . 100\n5.12 The simulink figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n5.13 The sink figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n5.14 Block diagram with oscilloscope attached . . . . . . . . . . . . . . . . 102\n5.15 The oscilloscope screen . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n5.16 The plot versus time figure . . . . . . . . . . . . . . . . . . . . . . . . . 103\n5.17 The variable summary figure. . . . . . . . . . . . . . . . . . . . . . . . . 104\n5.18 Comparison figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n5.19 Phase-plane plot of membrane conductance versus membrane po\ntential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n5.20 Membrane potential obtained at different temperatures . . . . . . . 107\n5.21 Simulation results for different parameters that block the action\npotential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n5.22 Examples of action potentials . . . . . . . . . . . . . . . . . . . . . . . . 117\n5.23 Dependence of the action potential on temperature . . . . . . . . . . 118\n5.24 Effect of extracellular sodium concentration on the action potential 118\n5.25 Sample project proposal . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n6.1 Kinetic diagram of a channel that has 5 states . . . . . . . . . . . . . 127\n6.2 The probability of occurrence of more than 1 event in an interval t 131\n\nLIST OF FIGURES\nxiii\n6.3 The controls figure after the software is initiated . . . . . . . . . . . . 132\n6.4 The channel parameters figure . . . . . . . . . . . . . . . . . . . . . . . 133\n6.5 Rate constant window . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\n6.6 View rate constant figure after both the forward and reverse rate\nconstants have been defined . . . . . . . . . . . . . . . . . . . . . . . . 135\n6.7 Membrane potential figure . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n6.8 Numerics figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n6.9 State occupancy figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n6.10 Single channel ionic current . . . . . . . . . . . . . . . . . . . . . . . . . 139\n6.11 Summary figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\n6.12 Comparison figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n\nxiv\nLIST OF FIGURES\n\nList of Tables\n2.1 The macroscopic laws of diffusion . . . . . . . . . . . . . . . . . . . . . 16\n3.1 Summary of computational methods.\n. . . . . . . . . . . . . . . . . . 45\n4.1 Modifiable parameters of the carrier models . . . . . . . . . . . . . . . 76\nxv\n\nxvi\nLIST OF TABLES\n\nChapter 1\nINTRODUCTION\n1.1 Overview Of Software Packages\nThe software for cellular biophysics consists of 5 software packages. The titles\nof the software packages, with acronyms in parentheses and brief descriptions,\nare:\nRandom Walk Model of Diffusion (RW) allows users to select parameters of the\nrandom walks of particles in a field and to observe the resulting space-\ntime evolution of particle location. This package is intended to link the\nmacroscopic laws of diffusion to its probabilistic, microscopic basis.\nMacroscopic Diffusion Processes (MD) allows users to select the initial spatial\ndistribution of solute concentration, the diffusion parameters, and to ob\nserve the resulting space-time evolution of solute concentration and flux.\nThis package is intended to give users intuition about macroscopic diffu\nsion processes.\nCarrier-Mediated Transport (CMT) allows users to examine simple models of\ncarrier-mediated transport through cellular membranes. For each of three\nmodels, the user can change any parameter and can instantly see the effect\non the state of the carrier-model. This interactive mode is intended to build\nintuition about these models. In addition, there is a graphic mode that\nallows display of steady-state and transient responses to changes in any\nparameter.\nHodgkin-Huxley Model (HH) allows users to change parameters of the Hodgkin-\nHuxley model of a space-clamped giant axon of a squid, and to perform\nsimulation experiments in either the voltage-clamp or the current-clamp\nconfiguration. This package is built on a block-diagram language providing\nusers a graphic access to the model.\nVoltage-Gated Ion Channels (IC) allows users to design a voltage-gated ion chan\nnel. The user selects the number of states, the conductance and gating\n\nCHAPTER 1. INTRODUCTION\ncharge associated with each state, and the voltage-dependence of state tran\nsition rates. The user can then perform simulation experiments on the\nchannel.\nThese packages are all designed to enhance comprehension of topics in cellular\nbiophysics by providing pedagogic tools that can be used as a basis for lecture\ndemonstration, open-ended problems that lend themselves to classes held in an\nelectronic classroom in which students have access to computers, homework\nproblems, and research projects. Although independent of any textbook, this\nsuite of software packages was developed in parallel with textbooks in cellular\nbiophysics (Weiss, 1996a; Weiss, 1996b).\n1.2 Brief Introduction To MATLAB\nAll the software packages are written in MATLAB/SIMULINK which is an interac\ntive programming environment for numerical and symbolic computations and for\nvisualization of computational results. MATLAB is especially effective in systems\nanalysis and signal processing. Because MATLAB runs on all the major computer\nplatforms, the cellular biophysics software operates on all the major platforms:\nPCs using Windows, Macintosh computers using MacOS, and Unix workstations.\nBoth MATLAB (version 4.2c) and SIMULINK (version 1.3) are required to operate\nthis software.1\nThe MATLAB environment is interpretive. That is, commands can be entered\nat a prompt and interpreted within the scope of a MATLAB session. Thus, com\nputational results generated by a simulation are available to the user for further\nanalysis. The software is designed to perform all the simulations with mini\nmal typed commands. The graphical user interface allows navigation through\nthe software using a sequence of mouse events (e.g., clicking the mouse, pulling\ndown a menu, dragging the mouse).\nUsers of the software do not need to learn MATLAB to use the software. How\never, knowledge of MATLAB can enhance user's usage of the software. A number\nof texts on MATLAB are available (Hanselman and Littlefield, 1996). In addition,\nMATLAB manuals can be ordered directly from MathWorks. Section 1.2.1 is a\nglossary of some useful terms in the MATLAB vocabulary. Section 1.2.2 men\ntions resources that can provide on-line help with MATLAB.\n1.2.1 Jargon\nThe following terms are useful in navigating in the MATLAB environment.\n1Although not tested extensively, RW, MD, CMT, and IC run on the Student Version of MAT\nLAB. However, it may be that parameters can be chosen for these packages which will not satisfy\nthe limitations of the Student Version. HH requires SIMULINK in addition to MATLAB. However,\ncurrently HH does not run on the Student Versions of MATLAB plus SIMULINK.\n\n1.2. BRIEF INTRODUCTION TO MATLAB\nworkspace A collection of variables in the current session of MATLAB. When\nMATLAB is started, the workspace is empty. Each software package defines\nits own variables and parameters which it adds to the workspace.\ncommand window The window that appears when MATLAB is started. Com\nmands entered at the MATLAB prompt (>>) in this window are evaluated in\nthe workspace.\nfigure A rectangular window containing graphical objects, such as axes, buttons,\nand menu items. See the MATLAB command figure.\naxes The area in a figure containing plots and annotation. See the MATLAB com\nmand axes.\nbuttons Rectangular regions allowing a sequence of commands to be executed\nwhen they are clicked, selected, or edited. See the MATLAB command\nuicontrol.\npopup-menu A rectangular region showing the current popup-menu selection.\nWhen clicked, the menu is expanded to show all the options. See the MAT\nLAB command uicontrol.\nmenubar A bar at the top of a figure (Windows and UNIX implementations) or at\nthe top of the monitor screen (MacOS implementation) associated with the\ncurrently selected figure. When selected, the menu item expands to show\nits related submenu items. Submenu items marked with a check-mark are\ncurrently active selections.\nM-file A text file containing a sequence of commands to be evaluated in the MAT\nLAB workspace. The software contains a collection of m-files which can be\nrecognized by the extension .m.\nMAT-file A binary data file containing MATLAB variables. Each software package\nuses and stores a different set of variables.\nparameters Numeric values that define each model.\nvariables Numeric values of independent variables set by the user or of depen\ndent variables calculated from the model.\nSIMULINK A block-diagram language that extends MATLAB's capabilities to sim\nulate dynamic systems.\n\nCHAPTER 1. INTRODUCTION\n1.2.2 Help\nHelp on MATLAB and SIMULINK is available through the command window using\nthe following commands at the MATLAB prompt (>>)\nwho lists the variables in the current workspace.\nhelp function provides some help on the command function.\nhelp help provides help on getting started using help.\nlookfor word finds functions that involve word.\nAdditional help is available in the descriptions of individual software packages.\n1.3 Starting And Quitting The Software\n1.3.1 Directory structure\nThe software is designed to be run from a directory that includes the following\nfiles/directories:\ncmt is a directory that contains the carrier-mediated transport software.\nhh is a directory that contains the Hodgkin-Huxley model software.\nic is a directory that contains the voltage-gated ion channel software.\nmd is a directory that contains the macroscopic diffusion processes software.\nrw is a directory that contains the random walk model software.\nsoftcell.m is a MATLAB m-file that initializes the software and allows the user to\nchoose software packages from a menu.\ntlib is a directory that contains a library of software routines used by all the\npackages.\n1.3.2 Starting the software\nThe software is accessible through MATLAB/SIMULINK via a menu that allows\nselection of the software packages and initializes all packages. The startup pro\ncedure is given for the different platforms.\n\n1.3. STARTING AND QUITTING THE SOFTWARE\nFigure 1.1: Softcell figure showing the\navailable software packages.\nUNIX workstation on Project Athena. From the dashboard at the top of the mon\nitor select\nCourseware =≥\nElectrical Engineering and Computer Science =\n6.021J/6.521J Quantitative Physiology =≥\n≥\nNew MATLAB Software\nThis procedure displays the softcell figure shown in Figure 1.1. Clicking on\nany package, initializes that package and hides the softcell figure.\nWindows, MacOS, UNIX, and other operating systems. Initialize MATLAB, and\ntype the following instruction (in the MATLAB window) at the MATLAB\nprompt (>>)\n>> cd directory\nwhere directory is the name of the directory (folder) that houses the cel\nlular biophysics software.2 Then type\n>> softcell\nThis command displays the softcell figure shown in Figure 1.1. Clicking on\nany package, initializes that package and hides the softcell figure.\nIn addition, there are two m-files used by the software that may not be part\nof the standard distribution of MATLAB 4.2c.\nODE Suite. One feature of the packages (transient response for CMT) makes\nuse of MATLAB's ODE Suite (specifically, the ode solver ode15s), a col\nlection of algorithms optimized for solving ordinary differential equa\ntions. To use transient response with CMT, it is imperative that the\nODE Suite be on MATLAB's search path. Use the following checklist\nto insure that the ODE Suite is accessible to the cellular biophysics\nsoftware:\n2To verify that the directory is the right one, either type pwd to indicate the name of the\npresent directory or type ls to list the contents of the directory. It should contain the file\nsoftcell.m. If it does not contain this file then either the selected directory is wrong or the\ncellular biophysics software is not installed on your computer.\n\nCHAPTER 1. INTRODUCTION\n1. At the MATLAB prompt, type\nwhich ode15s.\nIf MATLAB returns the name of a file, the ODE Suite is already\ninstalled; skip the rest of the checklist.\n2. Check if the ODE Suite is resident in your computer. If the suite\ncame with MATLAB, it is most likely in the directory (folder) hier\narchy\nmatlab/toolbox/contrib.\nIf you can find the file ode15s.m, skip to step 4.\n3. Install a copy of the ODE Suite on your computer. You can down\nload it from the MathWorks website at the URL\nhttp://www.mathworks.com/\nPlace the new directory (folder) into contrib.\n4. Append the folder which contains the ODE Suite to MATLAB's search\npath. If the ODE Suite resides in\nmatlab/toolbox/contrib/ode,\ntype the command\n>> path(path,'matlab/toolbox/contrib/ode');\n[For a Windows/PC system the directory (folder) is specified by an\naddress that looks like c:\\matlab\\toolbox\\contrib\\ode, whereas\non MacOs, the directory (folder) is specified by an address that\nlooks like MacHD:matlab:toolbox:contrib:ode.]\nFor the remainder of the session, MATLAB will look through the\nfolder matlab/toolbox/contrib/ode when searching for files from\nthe ODE Suite. To make this change permanent, see MATLAB doc\numentation on setting the default MATLAB search path.\nPrinting. All the packages make use of an m-file (printdlg.m) for printing.\nUse the following check list to insure that printdlg.m is accessible to\nthe software.\n1. At the MATLAB prompt, type\nwhich printdlg.\nIf MATLAB returns the name of a file, printdlg.m is already in\nstalled; skip the rest of the checklist.\n2. The m-file printdlg.m is distributed in a folder called uitools. Check\nif uitools is resident in your computer. If the uitools came with\nMATLAB, it is most likely in the directory (folder) hierarchy\nmatlab/toolbox/uitools.\nIf you can find the file printdlg.m, skip to step 4.\n3. Install a copy of the uitools folder on your computer. You can\ndownload it from the MathWorks website or their ftp site which\ncan be reached through their web site:\n\n1.4. COMMON FEATURES OF SOFTWARE PACKAGES\nftp://ftp.mathworks.com/pub/mathworks/toolbox/uitools\n.\nPlace the new directory (folder) into toolbox.\n4. Append the folder which contains the uitools folder to MATLAB's\nsearch path, i.e., type the command\n>> path(path,'matlab/toolbox/uitools');\n1.3.3 Quitting the software\nQuitting any package displays the softcell figure again. To quit MATLAB, click\non QUIT in the menubar and select Exit MATLAB. The menubar is located at the\ntop of the figure in UNIX and Windows implementations and at the top of the\nmonitor screen in the MacOS implementation.\n1.4 Common Features Of Software Packages\nCertain features are common to all the software packages and these are described\nhere. When any of the software packages is selected in the softcell figure, one or\nmore windows is displayed on the screen. MATLAB refers to these as figures.\n1.4.1 Controls\nEach package has a controls figure that allows the user to control the package.\nAlthough individual packages have different controls figures, all controls figures\ncontain a log panel and a message panel. The log panel contains options for\nrecording log entries of the session. Log entries are records of actions of the\nuser during the simulation session. Clicking on Select file displays a window\nthat allows choosing the name of the log file into which the log entries will be\nsaved. The log entries can also be displayed in the message panel. In general,\nthe message panel is used to send messages to the user.\n1.4.2 Quitting a package\nEach figure associated with each package contains a menubar. The menubar\noccurs at the top of the figure in UNIX and Windows implementations and at the\ntop of the screen in Macintosh versions of the software. This menubar enables\nthe user to quit the software package by clicking on XX and then selecting quit\nXX, where XX is the acronym for the package (e.g., CMT for carrier-mediated\ntransport).\n\nCHAPTER 1. INTRODUCTION\nFigure 1.2: The print figure after Print\nwas selected in the RW package (Parti\ncles #1 figure).\n1.4.3 Printing/saving a figure\nThe menubar for each figure associated with each package also contains Print\nwhich if selected brings up the print figure (Figure 1.2). The user can either print\nthe figure to the default printer, print to any printer by editing Device Option (to\nsee how to do it type help print at the MATLAB prompt), or store a postscript\nfile of the figure.\n1.4.4 Reading from and saving to a file\nA variety of information about the software can be saved in MAT-files using the\nstandard MATLAB binary file format (see MATLAB's save and load commands).\nFor example, all the packages allow storage of simulation parameters to allow a\nsimulation to be repeated at a later time. In addition, results of simulations can\nalso be saved in files for later retrieval. However, the information stored varies\nfor different software packages, and the individual descriptions of the packages\nshould be consulted for more detailed information.\nTo restore state variables from a prior simulation, use Read parameters push-\nbuttons which are found on some of the figures of all of the packages. Although\ndata can be restored using load from the command-line, this method will not, in\ngeneral, restore all relevant state variables necessary to run the software.\n1.4.5 Flexible graphic resource\nA flexible graphics resource is used by all the software packages to compare\nresults of simulations. This resource is customized for each software package\nbut contains features that are common to all the software packages and these are\ndescribed in detail here. We illustrate the usage of this resource with examples\nfrom the carrier-mediated transport package. Selection of graphic analysis in the\ncontrols figure of the carrier-mediated transport package results in the display\nof the steady-state graphic analysis figure (Figure 1.3). This is a typical usage of\nthe graphic resource. This figure contains a number of panels.\nPlot control. The panel in the upper left corner controls plotting in the manner\ndescribed below.\n\n1.4. COMMON FEATURES OF SOFTWARE PACKAGES\nFigure 1.3: An example of the use of the flexible graphic resource in the CMT package.\nThe steady-state graphic analysis figure shows a plot of fluxes and carrier densities\ni\nversus the inside concentration of solute S, cS , in linear ordinate and abscissa scales.\n\nCHAPTER 1. INTRODUCTION\nFigure 1.4: The select x,y figure that produced the\nplot shown in Figure 1.3. Note that ci (which is\nS\nhighlighted in blue) was selected as the indepen\ndent variable that defines the abscissa (horizontal\naxis) in the plot. The variables E , ES , nE\ni , no\nE ,\nnES , and no\ni\nES were selected as the dependent vari\nables and plotted as the ordinates (vertical axis).\nSelect x,y. Clicking on this entry results in the display of the Select x,y fig\nure (Figure 1.4) which allows selection of one independent variable\nwhich determines the abscissa of the plot and multiple dependent vari\nables which determine the ordinates. Clicking on an independent vari\nable selects it for the abscissa variable and deselects a previously se\nlected variable. Clicking on an unselected dependent variable adds it to\nthe collection of selected variables. Clicking on a selected dependent\nvariable deselects it. A maximum of four types of dependent variables\ncan be selected for plotting. In some packages (CMT), the range of the\nindependent variable is selected in this figure.\nSelect data files. Clicking on this entry displays a figure that allows selec\ntion of a file from which previously stored parameters can be read. The\ntypes of data that are read varies with each package.\nGraph x,y. Clicking on this entry results in a plot of the selected data.\nOverlay. When this button is activated, the next set of plots are overlayed\nover the current set. When this option is not checked, the following\nplots replace the current ones.\nUse data files. When this button is activated, the next set of plots are de\nrived from the selected data files.\nSave results. Clicking this button displays a figure that allows selection of\na file into which the current data can be stored. The types of data that\nare stored varies with each package.\nClear. Clicking this button clears the plot area as well as the legend and\ncross-hair information.\n\n1.4. COMMON FEATURES OF SOFTWARE PACKAGES\nFigure 1.5: The axis scale figure after the\nabscissa was selected in Figure 1.3.\nAxes control. The lowest panel in the figure shows the selected plots. The axes\ncan be changed by clicking on either the ordinate or the abscissa variable\nwhich results in the display of the axis scale figure (Figure 1.5). The axis\nscale can be chosen to be linear, logarithmic, and/or reciprocal. If none of\nthe options is chosen, the scale is linear. If log scale is chosen, the scale is\nlogarithmic. If invert is chosen (available only in CMT) then the reciprocal of\nthe abscissa variable is plotted either on a linear or on a logarithmic scale.\nIn logarithmic coordinates, negative values of a variable (i.e., the fluxes) are\ntruncated. Clicking on done hides the figure.\nLegend. The legend panel records a list of all data plotted. The following are\nrecorded.\nTime stamp. The time and date when the curves were generated are indi\ncated. Clicking on the time stamp alternately displays and hides all\nthe curves associated with this legend item.\nLine and symbol type. The color, line style, and symbol type are used to\nencode a particular variable; this marker is shown in the legend.\nVariable name. The name of the variable that was plotted is shown. Click\ning on the variable name alternately displays and hides the curve as\nsociated with this entry. When variables are added or deleted, the axis\nis auto-scaled if that option is selected -- it is selected by default -- in\nthe axis figure.\nCross-line value. When the cross line is used, the value of all variables at a\nparticular value of the independent variable is displayed. These values\nare accurate only when cross line is selected in the mouse-event controls\npanel (see below).\nMessage window. Messages to the user are displayed in the message window.\n\nCHAPTER 1. INTRODUCTION\nMouse-event controls. The plot can be modified or queried in several ways.\nAnnotate. Click on annotate and then click on a desired location in the plot\narea. A text edit box appears at that location. Type the annotation in\nthe text edit box and type <RETURN> when the annotation is completed.\nClicking on the annotation and dragging the mouse moves the annota\ntion to a desired location in the plot field. Clicking on clear removes\nthe annotation.\nCross hair. Clicking on cross hair places a mouse-controlled cross hair in\nthe plot field. Clicking the mouse at some location in the plot field\nplaces (in the cross-hair panel) the values of all variables at the location\nof the cursor. Clicking on hide removes the cross-hair values.\nCross line. Clicking on cross line displays a vertical line, the cross line, in\nthe plot field at the location of the pointer cursor. The line follows\nthe cursor as it moves across the plot field. The values of all plotted\nvariables at the intersection with the cross line are displayed in the\nlegend. The value of the independent variable is displayed above the\nlegend. Clicking on reset removes the cross-line values from the legend\nand clicking off cross line removes the cross line from the plotting field.\nZoom. Clicking on zoom allows the user to magnify a region of the plot\nting field. Clicking and dragging the mouse produces a rectangle in a\nportion of the plot field; the rectangle defines the region to be mag\nnified. Additional magnification can be achieved by zooming again.\nClick unzoom to undo the effects of all prior zooms.\n1.4.6 Scripts\nScripting commands alleviate the burden of being present while repetitive, time\nconsuming simulations are computed.3 The set of commands available to the\nsoftware user can be found by issuing the command help XXscr, where XX is\nthe acronym for the package.\nScripting can also be used to create customized plots of variables. For exam\nple, in the Hodgkin-Huxley package, after running a simulation, the time depen\ndance of the sodium conductance can be plotted on a separate figure using the\nfollowing commands:\nu_gna = hhscr('get','G_Na'); %get the sodium conductance vector\nu_time = hhscr('get','t'); %get the vector of sampled time values\nfigure; %create a new figure\nplot(u_time,u_gna); %plot sodium conductance vs. time\n3A sample script is given in the chapter on the Hodgkin-Huxley model.\n\n1.4. COMMON FEATURES OF SOFTWARE PACKAGES\nOnce the values of these variables are so obtained, they can be manipulated,\nmodified, and saved to files. It is important to practice safe-workspace-integrity\ntechniques by creating names of variables that are similar to but different from\nthose defined in the workspace. To see a list of variables in the workspace, type\nwho. In general, prefix the names of your own variables with a set of characters\nsuch as u_. In this way, variables can be manipulated or plotted without danger\nof creating inconsistencies in the workspace.\nAlthough the set of scripting commands in the various XXscr files is not ex\nhaustive enough to allow operating all aspects of the software from the command-\nline, it is sufficient to carry out some of the time-consuming elements of the sim\nulation. Furthermore, by issuing only sanctioned scripting commands from the\nMATLAB >> prompt, the user is assured that variables in the workspace will not\nbe corrupted with inconsistencies.\n\nCHAPTER 1. INTRODUCTION\n\nChapter 2\nRANDOM WALK MODEL OF\nDIFFUSION\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\n2.1 Introduction\n2.1.1 Historical background\nA bolus of soluble material will gradually spread out in its solvent until a uniform\nsolution results. This diffusion process must have been familiar to humans in\nantiquity. However, a mathematical description of these macroscopic changes in\nconcentration was not available until the 1850s (Fick, 1855), and a microscopic\nor particle-level model, not until the turn of this century (Einstein, 1906).\nDiffusion plays an important role in such a wide range of disciplines, that it is\nimportant for students of science and engineering to develop an understanding\nof the macroscopic laws of diffusion and their microscopic basis. We will review\nsome important characteristics of the macroscopic laws of diffusion and their\nrelation to random-walk models. A fuller treatment is available elsewhere (Weiss,\n1996a).\n2.1.2 Macroscopic and microscopic models\nMacroscopic laws of diffusion\nThe macroscopic laws of diffusion for the simple case when the particles are not\nsubject to a body force, the medium does not convect the particles, the diffusion\ncoefficient is a constant, and the particles are conserved are summarized in one\nand three dimensions in Table 2.1. These equations relate the flux of particles\nEquation\nOne Dimension Three Dimensions\nFick's first law\n= -D θc\nθx\n\n= -Dinfc\nContinuity equation\nθ\nθx = - θc\nθt\ninf·\n= - θc\nθt\nDiffusion equation\nθc\nθt = D θ2c\nθx2\nθc\nθt = Dinf2c\nTable 2.1: The macroscopic laws of diffusion for a concentration of particles diffusing\nin a homogeneous region with a constant diffusion coefficient D, in the absence of a\nbody force on the particles or convection of the medium, and where the particles are\nconserved.\n(), which is the number of moles of particles transported through a unit area in\na unit time, to the concentration of particles (c), which is the number of moles\nof particles per unit volume. Fick's first law relates flux to particle concentra\ntion; it is analogous to other laws that relate a flow to a force such as Ohm's\nlaw of electric conduction, Darcy's law of convection, and Fourier's law of heat\n\n2.1. INTRODUCTION\nflow. Fick's first law implies that a solute concentration gradient causes a solute\nflux in a direction to reduce the concentration gradient. The continuity equation\nfollows from conservation of particles, and the diffusion equation is obtained by\ncombining Fick's first law with the continuity equation.\nMicroscopic basis of diffusion\nAn important notion in understanding diffusion processes is to relate the macro\nscopic laws of diffusion to microscopic models of diffusing particles. The sim\nplest microscopic model that captures the essence of diffusion is the discrete-\ntime, discrete-space random walk. In a one-dimensional random walk in a ho\nmogeneous region of space, we assume a particle moves along the x-axis in a\nseries of statistically independent steps of length +l or -l, where the time be\ntween steps is . In an unbiased walk, positive and negative steps are equally\nlikely, i.e., each has probability 1/2. It can be shown that statistical averages of\nproperties of a population of particles obey the macroscopic laws of diffusion.\nIn particular, this simple model can be shown (Weiss, 1996a) to yield Fick's first\nlaw with a diffusion coefficient,\nl2\nD\n.\n=\nTherefore, the connection between the random walk of a particle and the laws of\nmacroscopic diffusion can be made clear if the motion of a number of particles\n(on the order of 50) can be visualized for a number of steps.\n2.1.3 Overview of software\nThe software described here is intended to allow users to investigate the prop\nerties of the simplest microscopic model that captures the essence of diffusion:\nthe discrete-time, discrete-space random-walk model.\nIn the discrete-time, discrete space random walk model described here, there\nis a population of particles which execute statistically-independent, but otherwise\nidentical two-dimensional random walks in a rectangular field. The field can be\ndivided into one, two, or three homogeneous regions whose widths are specifi\nable, and whose properties may differ. Each particle undergoes a random walk\nwith parameters that include: the probability that the particle takes a step to the\nleft or right, and the step size. These parameters can be set independently in the\nthree regions. The particles can be set to have a specifiable lifetime. One source\nand one sink of particles can be placed in the field and the initial concentration\nof particles can be specified in each of the three regions. Characteristics of the\nboundary conditions between regions can also be specified. With this software\npackage it is possible: to visualize the spatial evolution of particle concentra\ntion from a variety of initial distributions selectable by the user; to examine the\nevolution of particle concentration from a source and in the presence of a sink;\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\n1 unit\nj +2\nj +1\nFigure 2.1: Definition of grid of particle locations. A particle\nj\nis shown at the grid location (i, j). The distance between\nj -1\nadjacent grid locations, in both the horizontal and vertical\ndirections, is the unit distance.\ni -2\nj -2\ni -1 i\ni +1 i +2\nto examine diffusion in regions of differing diffusion coefficients; to simulate\ndiffusion of particles subjected to a body force; to simulate diffusion between\ntwo compartments separated by a membrane; to investigate the effects of chem\nical reactions or recombination which consume particles at a fixed rate; and to\ninvestigate the effects of different boundary conditions between regions. Two\ndiffusion regimes can be run and displayed simultaneously to allow direct com\nparison between the space-time evolution of two different diffusion processes.\nIn addition, a variety of statistics of the spatial distribution of particles can also\nbe displayed.\nBy watching the particles move and by comparing simulation results to ex\npectations, the user can develop an intuition for the way in which the random\nmotions of particles lead to their diffusive spread.\n2.2 Description Of The Random-Walk Model\nIn this simulation, the discrete-time, discrete-space random walk takes place on\na finite two-dimensional grid of locations accessible to the particles and called\nthe field. The location of each particle is specified by giving its coordinates on\nthis grid (i, j) where i is the horizontal coordinate and ranges from 0 to 399 and\nj is the vertical coordinate and ranges from 0 to 99 (Figure 2.1). The horizontal\ndistance between adjacent grid locations is 1 unit of distance and all spatial di\nmensions of the random walk are expressed as multiples of this unit distance.\nThe location of the particle in the grid can change probabilistically at each step\nof the random walk. Thus, successive steps represent successive times that are\nseparated by a unit time interval. All times are expressed in terms of the number\nof steps of the random walk.\nThe field can be divided into one, two or three homogeneous regions (Fig\nure 2.2). Certain parameters of the simulation are defined for the entire field,\nothers at boundaries between regions, and still others are defined independently\nfor each region. The latter parameters will be described first and include: region\nsize, particle step size, directional probabilities, and initial particle distribution.\n\n2.2. DESCRIPTION OF THE RANDOM-WALK MODEL\nRegion 1\nRegion 2\nRegion 2\nRegion 1 size\nvertical internal\nboundaries\nperimeter boundary:\nvertical\nhorizontal\nFigure 2.2: Definition of simulation field, regions, and boundaries. Solid lines delimit the\nperimeter boundaries of the field; dashed lines indicate the internal vertical boundaries\nthat separate the regions.\n2.2.1 Particle parameters within a region\nThe parameters that define the random walk are identical at each location within\na region -- each region is homogeneous. These parameters are described below.\nRegion size\nThe width of each region can be specified, but the sum of the widths cannot\nexceed 400. This allows a variety of diffusion regimes to be defined. For exam\nple, if Region 1 has width of 400 then the other two regions must have width 0\nand the random walk is defined for one homogeneous region. By specifying two\nregions with non-zero widths, it is possible to define a diffusion process with\ndifferent initial conditions in the two regions. This allows a rich variety of initial\ndistributions to be defined. Three non-zero width regions allows simulation of\ndiffusion between two regions separated by a third region with different prop\nerties. This might be used to investigate diffusion between two baths separated\nby a membrane.\nStep size\nThe step size defines the distance, in multiples of unit distances, that particles\nmay move in each step of time. Varying the step size simulates varying the\ndiffusion coefficient. The size of a region is always set to a multiple of the step\nsize in that region; all particles in a region are located at integer multiples of\nthe step size starting from the left boundary of the region. This ensures that\nparticles at a boundary fall on the boundary and simplifies the specification of\nparticle motion at a boundary.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nupper left\nupper right\nstep size\nexpired\nlower left\nlower right\nstep size\nFigure 2.3: Schematic diagram of motion of a particle in a homogeneous region. The grid\nof possible particle locations, separated by unit distances, are indicated by + symbols.\nA particle is shown in the center of the figure at one instant in time. One time step later\nthe particle either stays in the same location or moves to one of 4 possible locations\n(indicated by the shaded particle) or it expires (is removed from the field). If the particle\nmoves, it translates one step size (here shown as 2 units of distance) in both the vertical\nand the horizontal direction.\nParticle motion -- directional probabilities\nAt each instant in time, a particle is at some location in the region. The dis\nposition of the particle at the next instant in time is determined by one of six\nmutually exclusive and collectively exhaustive possibilities as illustrated in Fig\nure 2.3. The particle can move one step size to the upper left, upper right, lower\nleft, or lower right; stay in the same location (center); or be eliminated (expire).\nThe probabilities for each of the six outcomes is as follows:\nP[expired]\n1/L ,\n=\nP[center]\n(1 - 1/L) (1 - p - q) ,\n=\nP[upper left]\n0.5 (1 - 1/L) q ,\n=\nP[upper right]\n0.5 (1 - 1/L) p ,\n(2.1)\n=\nP[lower left]\n0.5 (1 - 1/L) q ,\n=\nP[lower right]\n0.5 (1 - 1/L) p ,\n=\nwhere L is the average lifetime of the particle, i.e. the average number of time\nsteps to expiration; p is the conditional probability that the particle moves to the\nright given that it has not expired; q is the conditional probability that the particle\nmoves to the left given that it has not expired. Note that while the probability\nof moving to the left and to the right can differ, the probability of moving up\nor down is always the same. Because the six probabilities define all the possible\noutcomes at each instant in time, they sum to unity.\nDifferent types of random walks are described by changing the directional\nprobabilities. The random walk defined by assuming p = q = 1/2 is the simple,\n\n2.2. DESCRIPTION OF THE RANDOM-WALK MODEL\nunbiased random walk described in Section 2.1. In general, if p = q the random\nwalk is unbiased; there is no statistical tendency for particles to move preferen\ntially in either horizontal direction. However, if p q, the random walk is biased\nso that there is a tendency for particles to move in one horizontal direction. For\na step size of S, the mean distance E[m] that the particle moves to the right in\nn units of time is\nE[m] = Sn(1 - 1/L)(p - q) .\nInitial distribution of particles\nThe initial distribution of particles can be specified in each of the three regions.\nParticles start at locations that are integral multiples of the step size in each\nregion. Particles are distributed randomly (with a uniform distribution) in the\nvertical direction and have the selected distribution in the horizontal direction.\nThe initial distribution of particles can be selected to be one of the following.\nEmpty implies that initially there are no particles in the region.\n-\nPulsatile implies that a specified number of particles are placed at a spec\n-\nified horizontal location in the region and spaced randomly in the vertical\ndirection.\nLinear implies that a linear concentration profile is generated whose slope\n-\nand number of particles are specified. A uniform distribution of particles is\nobtained if the slope is set to zero. Negative concentrations are not allowed:\nif the parameters are chosen such that the concentration would become\nnegative at some point in the region, these putative negative concentrations\nare set to zero.\nSinusoidal implies that the spatial distribution is sinusoidal with a specified\n-\nperiod and number of particles.\n2.2.2 Boundary conditions\nThe field contains three different types of boundaries (Figure 2.2) which are, in\norder of increasing complexity, horizontal perimeter boundaries at the top and\nbottom of the field, vertical perimeter boundaries at the left and right ends of\nthe field, and vertical internal boundaries that separate regions.\nHorizontal perimeter boundaries\nHorizontal perimeter boundaries act as perfectly reflecting walls. If a particle\nis located within one step size of such a boundary and takes a step toward the\nboundary then the new vertical location of the particle is determined in the fol\nlowing manner: the vertical distance the particle travels to reach the wall plus\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nstep size\nupper right\nlower right\nexpired\nFigure 2.4: Schematic diagram of motion\nleft vertical\nof a particle at a vertical perimeter bound-\nperimeter\nary. For purposes of illustration the parti\nboundary\ncle motion at the left boundary is shown.\nConditions at the right boundary are the\nmirror-image of those shown here.\nstep size\nthe vertical distance the particle travels after reflecting from the wall must sum\nto the step size. This relation determines the new location given the old location\nand the value of the step size.\nVertical perimeter boundaries\nThe vertical perimeter boundaries are also reflecting walls. Because the prob\nabilities of stepping to the left and right need not be the same, we found that\npurely reflecting wall of the type described for the horizontal perimeter bound\naries created undesirable artefacts especially when the conditional probabilities\nof moving to the left and right were not equal (p q). Therefore, we modified the\nboundary condition so that a particle that would have crossed a vertical perime\nter boundary at a given step was placed on the boundary and then subject to\nthe following boundary condition which is illustrated for the left boundary in\nFigure 2.4 and whose directional probabilities are:\nP[expired]\n1/L ,\n=\nP[center]\n(1 - 1/L) (1 - p) ,\n(2.2)\n=\nP[upper right]\n0.5 (1 - 1/L) p ,\n=\nP[lower right]\n0.5 (1 - 1/L) p ,\n=\ni.e. the particle cannot move to the left.\nVertical internal boundaries\nThe motion of particles at a vertical internal boundary is similar to that within a\nhomogenous region. The differences are that: the step sizes in the two adjacent\nregions may differ; and special directional probabilities, specified by the user,\napply at the boundary. These have been provided to allow users to explore the\nconsequences of a rich variety of boundary conditions. To simplify boundary\nconditions, the software ensures that particles do not cross this boundary in one\ntime step but rather they land on the boundary. This is guaranteed by forcing the\nwidth of boundaries, initial particle locations, locations of sources and sinks to be\n\n2.2. DESCRIPTION OF THE RANDOM-WALK MODEL\nstep size in\nright region\nstep size in\nleft region\nstep size in\nright region\nupper left\nupper right\nlower left\nlower right\nexpired\nleft region\nright region\ninternal vertical\nboundary\nFigure 2.5: Schematic diagram of mo\ntion of a particle at an internal vertical\nboundary between two regions. The\nstep size is 1 to the left of the bound\nary and 2 to the right of the boundary.\ncommensurate with the step size. Given this restriction, the possible outcomes\nfor a particle on a boundary are shown schematically in Figure 2.5. The directional\nprobabilities are identical to those in a homogeneous (region given above) except\nthat the conditional probability of moving to the left and to the right given that\nthe particle did not expire (p and q in the homogeneous region) are independently\nspecified at each internal boundary. The step size to the left is equal to the step\nsize in the region to the left of the boundary; the step size to the right is equal\nto the step size in the region to the right of the boundary.\n2.2.3 Parameters that change the number of particles in the field\nAfter the initial distribution of particles is chosen, there are three ways in which\nthe total number of particles in the field can change.\nParticle lifetime\nThe average lifetime L of particles at any location in the field is specifiable. The\neffect of particle lifetime on the directional probabilities was described earlier.\nSource\nOne source can be placed at a horizontal location in the field and covers the entire\nvertical height of the field. The source must be located at an integer multiple of\nthe step size from the left boundary of each region in which it is located. The rate\nof generation of particles is specified by giving the number of particles (specified\nas a two-digit number) produced in some number of time steps (specified as a\ntwo-digit number). Thus the rate of generation of particles can be a rational num\nber. The particles are generated at the horizontal location of the source and are\ndistributed randomly along the vertical direction using a uniform distribution.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nSink\nA sink can be placed at a horizontal location in the field and covers the entire\nvertical height of the field. The sink is located at an integer multiple of the step\nsize from the left boundary of each region in which it is located. Particles that\nland on the sink are absorbed; hence the number of particles at the sink is always\nzero.\n2.2.4 Statistics\nTwo sets of computations are performed simultaneously during a simulation:\nstatistics based on the actual locations of particle and statistics based on the\nexpected locations of particles. Given a particle location at one step and a set\nof directional probabilities, a random number generator is used to determine\nwhich of the possible new locations occurs at the next step. These sequence\nof locations determines the locations of the particles on the screen and all the\nstatistics labelled actual. However, given a particle location at one time and the\nsame directional probabilities, an expected location of the particle in the next step\nis also computed. Thus, during a simulation both the set of actual and expected\nlocations for the particles are computed and can be displayed.\nHistogram of horizontal particle locations\nHistograms summarize the spatial distribution of particle locations. Each his\ntogram consists of a set of bins that spans the field in the horizontal direction;\nthe number of bins depends upon the specification of the bin size. With a bin size\nof 16, there are 25 bins that span the entire field of 400 locations. The histogram\nshows the number of particles in each bin as a function of bin location. Choice of\nbin size is important. A small bin size depicts the particle distribution with high\nspatial distribution. However, a small bin size implies that each bin will contain\nrelatively few particles and the number of particles will fluctuate randomly from\nbin to bin. Conversely, a large bin size gives a histogram with poor spatial res\nolution but a larger amount of statistical averaging of the spatial distribution of\nparticles.\nThe shape of the histogram is sensitive to the choice of bin size and can lead to\nconfusing patterns. For example, suppose the bin size is five and the step size is\ntwo. Suppose further that particles are located uniformly in the field; one particle\nper accessible location. However, the step size constrains the possible locations\nthat a particle may occupy to be separated by 2. Therefore, with a bin size of\nfive, successive bins in the histogram alternate between 2 and 3 particles. Thus\nthe histogram will not appear uniform, but oscillatory. This problem is cured if\nthe bin size is an integral multiple of the step size. If the step sizes differ in the\nthree regions, then the bin size should be set equal to the least common multiple\nof the three step sizes.\n\n2.3. USER'S GUIDE TO THE SOFTWARE\nStatistics as a function of step number\nA number of statistics (both actual and expected) can be plotted versus step num\nber. These are:\nMean is the mean location of the particles in the entire field.\n-\nStandard Deviation is the standard deviation of particle location in the\n-\nentire field.\n#Generated is the cumulative number of particles generated by the source\n-\nsince the beginning of the simulation.\n#Absorbed is the cumulative number of particles absorbed by the sink since\n-\nthe beginning of the simulation.\n#Expired is the cumulative number of particles lost (due to their finite life\n-\ntimes) since the beginning of the simulation.\nTotal #Particles is the total number of particles in the entire field at each\n-\nstep number.\nRegion 1 #Particles is the total number of particles in Region 1 at each step\n-\nnumber.\nRegion 2 #Particles is the total number of particles in Region 2 at each step\n-\nnumber. For this total only, the particles located at the boundary between\nRegion 1 and Region 2 are counted as belonging to Region 2.\nRegion 3 #Particles is the total number of particles in Region 3 at each step\n-\nnumber. For this total only, the particles located at the boundary between\nRegion 2 and Region 3 are counted as belonging to Region 3.\nThese statistics allow a quantitative evaluation of simulation results. We give\na number of examples of the use of these statistics. A systematic change in\nthe mean location of the particles as a function of step number demonstrates a\ndrift or migration of the particles as can be achieved by a bias in the directional\nprobabilities. A difference in the standard deviation of two distributions can\nbe achieved by changing the step size. The dependence on step number of the\nnumber of particles in the field, in a region, generated, absorbed, or expired can\nbe used to assess whether a particle distribution has reached steady state. The\nchange in the total number of particles in each region can be used to estimate\nthe rate of transport of particles between regions.\n2.3 User's Guide To The Software\nWhen this software package is selected, 3 figures are displayed (in addition to\nMATLAB's command window) -- RW Controls, Parameters #1, and Particles #1.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.6: The controls figure.\n2.3.1 RW controls\nThe controls figure controls the random walk software and is shown in Figure 2.6.\nThe part of the controls figure below the menubar is divided into four horizontal\npanels. The top panel indicates which aspects of the simulation(s) are to be\ndisplayed. Two independent simulations can be run simultaneously. The left-\nhand side contains the controls for Simulation #1 and the right-hand side for\nSimulation #2. Clicking on Histogram #1, for example, displays a histogram of\nparticle locations for Simulation #1. Clicking on it again hides this histogram.\nThese displays are described in detail below. The next panel down allows the\nsimulation to be started, paused, continued, or stopped. The number of steps in\nthe random walk before the simulation pauses can be entered in the text edit box.\nThe end step indicates the current maximum value of the number of steps. This\nvalue is incremented if the simulation pauses and is continued. Clicking 1-step\nexecutes one step of the random walk. The third horizontal panel from the top is\na message window that displays information to the user. The log panel contains\noptions for recording log entries of the session and is described in Chapter 1. The\nbottom right panel allows reading parameters from a file and saving parameters\nto a file.\n2.3.2 Parameters\nThe parameters figure is shown in Figure 2.7. The parameters figure allows se\nlection of the parameters of the simulation(s). The parameters are given below.\nRegion Size. The user may define up to three regions, whose combined\n-\nwidth may not exceed 400. To eliminate a region, enter 0 for the region\nsize. Regions can also be of size k(step - size) where k\n3, 4, 5, .... That\n=\nis, regions of size stepsize and 2(stepsize) are not allowed.\n\n2.3. USER'S GUIDE TO THE SOFTWARE\nFigure 2.7: Parameters figure.\nStep Size. The step size can be specified independently in each region.\n-\nInitial Distribution Of Particles. The initial distribution of particles can be\n-\nspecified independently in the three regions. Each initial distribution has\nparameters that are specific for that distribution.\nRight Step Prob. The conditional probability of a step to the right given that\n-\nthe particle has not expired can be specified independently in each region.\nLeft Step Prob. The conditional probability of a step to the left given that\n-\nthe particle has not expired cannot be specified. It is set automatically so\nthat in each region, the sum of the probabilities of all possible outcomes is\none.\nStay Prob. The conditional probability that the particle stays in the same lo\n-\ncation given that the particle has not expired can be specified independently\nin each region.\nProbabilities at Boundaries. The perimeter boundaries of the field act as\n-\nreflecting boundaries; the boundaries between regions are characterized\nby user-defined boundary conditions. Boundary conditions are defined as\nshown in Figure 2.7: left-step-probability L, stay probability S , and right-\nstep-probability R at the boundary between regions. For example, if the\nRegion #1-#2 has the set of probabilities (L, S, R) = (0, 0, 1) then particles\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.8: Initial locations of particles for the parameters shown in Figure 2.7. Initially\nthere are 50 particles located at position 200 and spread randomly with a uniform\ndistribution in the vertical direction.\nat the boundary may only step to the right. Therefore, to a particle from Re\ngion #2, this looks like a reflecting boundary, whereas all particles reaching\nthe boundary from Region #1 will cross into Region #2. As with the direc\ntional probabilities within a region, the user selects the conditional (on not\nexpiring) probability of a step to the right and the conditional probability\nof no step; the conditional probability of a step to the left is then computed\nso that probabilities of all possible outcomes sum to one.\nSource. The location of the source can be specified as well as the number\n-\nof particles generated in a specified number of steps. When the source is\nturned on, a small + is placed at the horizontal location of the source just\nabove the field.\nSink. The particle sink may be turned ON and its location specified. When\n-\nthe sink is turned on, a small - is placed at the horizontal location of the\nsink just above the field.\nAverage Lifetime. The user may define the average particle lifetime defined\n-\nas the number of steps it takes, on average, for the particle to expire.\n2.3.3 Particles\nThe particles figure shows the locations of particles in the field as shown for an\ninitial distribution of particles in Figure 2.8. When the simulation is started by\nclicking the Start button in the controls figure, the random walks of the particles\nare exhibited in the particles figure. A step counter indicates the number of steps\ntaken in the random walks. After 100 steps of the random walks of particles, the\nparticles figure is as shown in Figure 2.9.\n\n2.3. USER'S GUIDE TO THE SOFTWARE\nFigure 2.9: Locations of particles after a 100 step random walk for the same parameters\nas shown in Figure 2.7 and for the initial locations of particles shown in Figure 2.8.\n2.3.4 Histogram\nSelecting Histogram in the controls figure displays the histogram figure (Fig\nure 2.10). The binwidth of the histogram can be selected in the upper right-\nhand corner. The binwidth determines the resolution of the histogram. Small\nbin widths produce histograms of particle locations with high spatial resolution\nbut a great deal of statistical variation. Large bin widths result in histograms\nwith poorer spatial resolution but less statistical variation in the histogram. The\nbinwidth should be a multiple of the particle step size to avoid artefacts that\nresult from incommensurate values. Clicking on the ordinate axis label displays\nan axis figure that allows the user to change the ordinate scale.\n2.3.5 Graph\nSelecting Graphs in the control figure displays the graphs figure. The temporal\nevolution of any of the statistics described in Section 2.2 can be plotted versus\nthe step number. Figure 2.11 shows an example of the standard deviation of\nparticle locations plotted versus step number. Clicking on the ordinate axis label\ndisplays an axis figure that allows the user to change the ordinate scale.\n2.3.6 Summary\nNumerical values of statistics can be displayed in the summary figure as shown\nin Figure 2.12\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.10: Histogram of particle locations after a 100 step random walk for the same\nparameters as shown in Figure 2.7 and for the initial locations of particles shown in\nFigure 2.8. The histogram is for the particle locations shown in Figure 2.9.\nFigure 2.11: Standard deviation of particle location versus step number for the same\nparameters as shown in Figure 2.7 and for the initial locations of particles shown in\nFigure 2.8.\nFigure 2.12: Numerical summary of statistics\nafter a 100 step random walk for the same\nparameters as shown in Figure 2.7 and for\nthe initial locations of particles shown in Fig\nure 2.8.\n\n2.4. PROBLEMS\n2.3.7 Miscellaneous issues\nTime taken for random walks\nAll of the figures can be displayed simultaneously as the random walks are exe\ncuted for two independent simulations. However, the display of each additional\nfigure slows down the simulation. Increasing the number of particles also slows\ndown the simulation.\nColor coding of regions\nRegion #1 is indicated in blue in both the parameters figure and the particles\nfigure; magenta is used for region #2 and green for region #3.\n2.4 Problems\nProblem 2.1 This problem deals with random walks of particles that begin from\nthe same horizontal location.\na. Use the default simulation parameters with a pulsatile initial distribution\nof particles but set the step size to 2 and 4 for Simulations #1 and #2, re\nspectively. Run the simulation for 100 steps. Note that the parameters of\nSimulation #1 and #2 differ only in step size. Examine graphs of the aver\nage and the standard deviation of the horizontal locations of the particles\nversus step number.\ni. Explain quantitatively the differences in the graphs in terms of the\ndifference in step size of the two simulations.\nii. Why does the slope of the standard deviation decrease with step num\nber? What type of dependence on step number do you expect? Explain.\nb. Now set the step size to 2 for both simulations and decrease the number\nof particles in the pulsatile initial distribution for one of the simulations\nto 25. Rerun the simulation. How does the number of particles affect the\ndependence of average location and standard deviation on step number?\nc. Set all the parameters at their default values and then set the step size\nfor both Simulation #1 and #2 to 2. For simulation #1 set the right step\nprobability to 0.75, the left step probability to 0.25, place an impulse of 50\nparticles at location 100. For simulation #2 set the right step probability\nto 0.25, the left step probability to 0.75, place an impulse of 50 particles at\nlocation 300. Run the simulation for at least 100 steps. Examine graphs of\nthe average and the standard deviation of the horizontal locations of the\nparticles versus step number. Explain these results quantitatively.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nProblem 2.2 This problem deals with the steady-state distribution of particles in\nthe presence of a source and sink for both unbiased and biased random walks.\nFor all parts of this problem set the parameters for both Simulation #1 and #2\nas follows: make the size of Region #1 400; the step size 20; and make the initial\ndistribution of particles empty. Also place a source at location 0 and a sink at\nlocation 400 and make the histogram bin size 20.\na. Make the random walks for both Simulation #1 and #2 unbiased with a right\nstep probability of 0.5. For simulation #1 make a source that generates 1\nparticle every 2 steps and for Simulation #2 make a source that generates\n1 particle every 1 step. Make the particle lifetime infinite for both simula\ntions. Now run the simulation. In the steady-state, by definition the particle\ndistribution will not depend upon step number.\ni. Before you run the simulation, estimate the form of the steady-state\nparticle distribution. Is it uniform, exponential, pulsatile, linear, Gaus\nsian, or none of these?\nii. Using the statistics available, determine a criterion for estimating when\nthe particle distribution is in steady state.\niii. Now run the simulation until your criterion for steady state is met.\nWhat is the steady-state particle distribution? Does it fit with your\ninitial expectation?\niv. How can you explain the difference in steady-state distribution for the\ntwo simulations?\nv. Show that the steady-state particle distribution you have found for the\nrandom walks is consistent with Fick's laws.\nb. Use the same parameters for Simulation #2 as in part a, but change those\nof Simulation #1 so that the source rate is also 1 particle every 1 step; and\nso that the probability of a right step is 0.55. Run the simulation until it\nhas reached a steady state.\ni. Compare the steady-state distributions for the biased and unbiased\nrandom walks. How do they differ?\nii. What is the shape of the steady-state distribution for the biased walk?\niii. How would you modify Fick's first law to account for not only diffusion\nof particles but a steady drift of particles of velocity v ? What steady-\nstate distribution of particles is predicted from Fick's laws and the\ncontinuity equation in the presence of this steady drift of particles? Is\nthis consistent with the simulation results you obtained?\nc. Keep the parameters of Simulation #1 and #2 the same as in part b, but\nchange the right step probability of Simulation #2 to 0.48. Explain the dif\nferences in the shapes of the steady-state distributions for the two simula\ntions.\n\n2.4. PROBLEMS\nProblem 2.3 This problem deals with the effect of a finite particle lifetime on the\nstatistics of random walks.\na. Define a simulation with an initial particle distribution that is a uniform\ndistribution of particles in space, but with a finite average particle lifetime.\nRun the simulation until all the particles have expired. Examine a graph of\n# particles versus step number. Explain the shape of this function.\nb. Define another simulation that is identical with the one in part a, but this\ntime with a source of particles. Do you expect a steady state to be reached\nbetween the the source and expirations? Determine a criterion for steady\nstate and check out your intuition.\nc. Design a combination of source rate and lifetime such that the distribu\ntion reaches a steady state. This might correspond, for example, to a drug\nconcentration reaching steady state in the body, as it is both infused and\neliminated.\nd. Design a combination of source rate and lifetime such that most particles\nin the region have expired by the time the source injects the next batch.\nThis might correspond to the drug concentration when the dosing interval\nis longer than the elimination half-life of the drug.\nProblem 2.4 This problem deals with a random walk in three regions. Set up\nthe parameters as shown in Figure 2.13. For both simulations, the two end re\ngions contain uniform concentrations of particles; but the number of particles\ndiffers. There is a concentration difference between the end regions as shown\nin Figure 2.14 for one of the simulations; the other is similar. The center region\ncan be regarded as a membrane that separates the two end regions and contains\nno particles initially. The random walk in the membrane region is unbiased in\none simulation and biased in the other. Run the simulation for several hundred\nsteps.\na. Explain the differences between the distributions of particles for the two\nsimulations.\nb. Quantitatively describe the flux of particles between the two end compart\nments -- both the magnitude and sign of the flux.\nc. What physical process might be represented in Simulation #2?\nProblem 2.5 Design a three region diffusion regime where the center region is\nconsidered to be a membrane. Design membrane characteristics such that the\nmembrane is transparent for particles moving from left to right but purely re\nflecting for particles moving from right to left. Test your design by running the\nsimulation.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.13: Parameters for a random walk in 3 regions (Problem 2.4).\n\n2.4. PROBLEMS\nFigure 2.14: Initial locations of particles for a random walk in 3 regions (Problem 2.4).\nProblem 2.6 Start with two identical simulations with Regions #1 and #2 that\nhave: a region size of 400; a step size of 2; unbiased random walks; no sources\nor sinks; infinite particle lifetimes; and sinusoidal initial particle distributions.\nChoose one simulation with a period of 200 and the other with a period of 50.\nChoose an appropriate bin size for the histograms. Run the simulation.\na. What is the shape of the equilibrium distribution of particles?\nb. Which particle distribution approaches this equilibrium faster?\nc. Experiment with different frequencies and generalize your conclusion from\npart b.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\n\nChapter 3\nMACROSCOPIC DIFFUSION PROCESSES\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\n3.1 Introduction\n3.1.1 Background\nDiffusion is an important transport process in physical, chemical, and biological\nsystems. Two theoretical models of diffusion capture complementary aspects of\nthe phenomenon. The microscopic model describes the probabilistic behavior\nof a population of individual solute particles which execute statistically indepen\ndent, but otherwise identical, random walks. Software dealing with such a mi\ncroscopic model of diffusion is described in Chapter 2. The software described\nin this chapter involves macroscopic diffusion which describes the aggregate be\nhavior of large populations of solute particles.\n3.1.2 Macroscopic model of diffusion\nIn 1855, Adolph Fick proposed a macroscopic model for passive diffusion (Fick,\n1855). By analogy to Fourier's law of heat conduction and Ohm's law for electrical\nconduction, Fick proposed that the flux of solute at a point in space is propor\ntional to the concentration gradient at that point. Mathematically, this relation\nis expressed by Fick's first law, which, in its one-dimensional form, is as follows:\nθc\n(3.1)\n= -Dθx ,\nwhere c(x, t) is the solute concentration and (x, t) is the solute flux. The con\nstant of proportionality, D, is known as the diffusion coefficient. Conservation of\nsolute (in the absence of sources or sinks or of chemical reactions that create or\ndestroy solute) results in a second relation between concentration and flux, the\ncontinuity equation:\nθ\nθc\nθx = -θt .\n(3.2)\nDifferentiating both sides of Equation 3.1 with respect to x and using the continu\nity equation yields Fick's second law, or the one-dimensional diffusion equation:\nθc\nθ2c\nD\n(3.3)\nθt\nθx2\n=\nIn principle, any one-dimensional diffusion process can be modelled by solving\nthis equation subject to the appropriate initial conditions and boundary condi\ntions.\nWe next consider the same problem but with two changes: (1) a body force\nacts uniformly on the solute so that it drifts (migrates) and (2) a chemical reac\ntion occurs that removes solute. The solute flux, (x, t), is now the sum of the\ndiffusive flux, given by Fick's law, and the flux due to drift. Thus, in this case,\nθc\nθx + vc,\n(3.4)\n= -D\n\n3.1. INTRODUCTION\nwhere v is the drift velocity of the solute; i.e., the velocity of the solute in response\nto the body force in the absence of diffusion. If r is the reaction rate at which\nsolute is removed, then the continuity equation becomes\nθ\nθc\nθt -rc.\n(3.5)\nθx = -\nCombining these expressions yields a modified diffusion equation:\nθc\nθ2c\nθc\nDθx2 -v θx -rc.\n(3.6)\nθt =\nThus, solute drift and a chemical reaction that removes solute contribute addi\ntional terms to the diffusion equation.\nIf the initial concentration, c(x, 0) is known in some region of space and if the\nrelation between the concentration and flux is known at each boundary of this\nregion, then a unique solution exists for t > 0. This agrees with intuition. Given\nan initial concentration profile, c(x, 0), Fick's laws govern the unique evolution\nof the concentration profile for all later times.\n3.1.3 Overview of software\nWhile macroscopic diffusion has been successfully modelled by Fick's equations,\nstudying the equations alone provides only limited insight into the behavior of\ndiffusion processes. The goal of this software is to help users gain intuition about\ndiffusion in one dimension. The solutions to the diffusion equation are functions\nof two variables: one spatial variable, x, and time, t. These solutions can be\nplotted either as a function of time at a particular point in space or as a function\nof the spatial variable at a particular instant in time. Such isolated snapshots,\nhowever, do not fully convey the dynamic behavior of diffusion processes. With\nthis software, the user can view a movie of the solute concentration or flux profile,\nas a function of position, as it evolves in time. Thus, the software enables the user\nto gain intuition about the dynamic behavior of macroscopic diffusion processes.\nFurthermore, the software provides an opportunity for users to experiment\nwith the macroscopic diffusion processes. For example, the user can explore\nhow changing the diffusion coefficient affects the time-course of the simulation.\nThe user can also specify transparent or reflecting boundaries and can explore\nhow a body force acting on the solute or a chemical reaction that removes solute\ninfluence the diffusion process. Thus, the software can be used as a tool for in\nvestigating how various parameters and boundary conditions influence diffusion\nprocesses.\nFive options for initial concentration profiles, corresponding to five charac\nteristic diffusion problems, are implemented in the software (Figure 3.1). Four\nof these problems involve diffusion from a specified initial concentration profile\nin a one-dimensional region of space (which may be infinite in extent), while the\nfifth involves diffusion between two finite, well-mixed compartments separated\nby a membrane.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nBath 1 M\nBath 2\nInitial concentration\nImpulse\nSinusoid\nDiscontinuity\nArbitrary\nTwo compartment\nFigure 3.1: Schematic representation of the five\nclasses of initial concentration profiles simulated\nby the software. M designates the membrane.\nPosition\n\n3.2. METHODS OF SOLUTION\nOne-dimensional diffusion\nIn one-dimensional diffusion, the initial concentration can be chosen to be one\nof four options: impulses, sinusoids, discontinuities, and an arbitrary spatial\ndistributions. An impulse of solute concentration is a mathematical idealization\ncorresponding to a finite amount of solute initially concentrated at a single point\nin space. In the impulses option, the user can specify the magnitude and posi\ntion of up to four impulses. This option illustrates diffusion from point sources.\nThe sinusoids option illustrate the spatial frequency response of a system gov\nerned by the diffusion equation, specifically, the low-pass spatial filtering effect\nof diffusion. By superimposing up to four sinusoids, the user can observe the de\npendence of the space-time evolution of concentration on its spatial frequency\ncontent. In the discontinuities option, the initial concentration profile may be\npiecewise-constant but contain discontinuities. The user can specify the magni\ntude and location of up to four such discontinuities. For example, this allows\nsimulation of the diffusion that results from an initial rectangular pulse of so\nlute concentration. The user can also explore the response for more complicated\ninitial conditions which can be specified by drawing an arbitrary initial concen\ntration on the monitor screen with a mouse.\nFor these different initial distributions, the user can specify the boundary\ntype (transparent or reflecting), the value of the drift velocity, and the chemical\nreaction rate at which solute is removed.\nTwo-compartment diffusion through a membrane\nIn the two compartment option, the user can also investigate diffusion between\ntwo well-stirred compartments, or baths, through a membrane which is perme\nable to the solute. Two-compartment diffusion through a membrane is an impor\ntant transport process in biological systems. It can model, for example, diffusion\nbetween the cytoplasm of a cell and the extracellular fluid, across the plasma\nmembrane. The baths are assumed to be well-stirred, so that the concentration\nwithin each bath varies with time but not with position in the bath. The total\namount of solute in the system is assumed to be finite. The user can specify the\nwidth of each bath and of the membrane, the initial concentration of each bath,\nand an arbitrary initial concentration profile in the membrane.\n3.2 Methods of Solution\nFor several of the diffusion problems implemented in the software, exact solu\ntions of the modified diffusion equation (Equation 3.6) are available in a form\nthat makes computation efficient. Such solutions have been used wherever pos\nsible. The remainder of the solutions were obtained by numerical methods. The\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nmethods are described in some detail elsewhere (Berkenblit, 1990); only a brief\nsummary of the methods is given here.\nThe method used to obtain solutions depends upon the type of boundary con\ndition. Two types of boundary conditions for the diffusion problems can be se\nlected by the user: transparent or reflecting boundary conditions. If transparent\nboundaries are specified, then the region over which diffusion occurs is infinite;\nthe spatial limits of the region over which diffusion is displayed are set by the\nuser. At a reflecting boundary, on the other hand, the solute flux is constrained\nto be zero, since no solute particles can cross such a boundary.\n3.2.1 Exact solutions\nExact solutions were used to compute the response for all one-dimensional diffu\nsion problems with transparent boundaries. These are described in this section.\nImpulse response -- Green's function\nNo drift, no chemical reaction. First, we consider the case when the drift ve\nlocity is zero and the chemical reaction rate is zero. Let the initial concentration\nbe a unit impulse located at position x\nβ and delivered at time t\n0,\n=\n=\nc(x, 0) = ω(x - β).\n(3.7)\nThe solution of the diffusion equation (Equation 3.3), called the Green's function\nG(x, t; β, 0), is\ne-(x-β)2/4Dt\nc(x, t) = G(x, t; β, 0) = p\n4γDt\n.\n(3.8)\nThus, the concentration profile is a Gaussian function of the spatial variable.\nThe standard deviation of the concentration,\np\n2Dt, increases with increasing\ntime, but the total area of the concentration remains constant because solute is\nconserved.\nDrift but no chemical reaction. We next consider the same problem but with\na non-zero drift velocity. In this case, the concentration satisfies the modified\ndiffusion equation, Equation 3.6, with r\n0:\n=\nθc\nθ2c\nθc\nDθx2 - v θx ,\n(3.9)\nθt =\nwith the initial condition\nc(x, 0) = ω(x - β).\n(3.10)\nThe solution can be shown to be\nc(x, t) = p\n4γDt e-(x-β-vt)2/4Dt = G(x - vt, t; β, 0).\n(3.11)\n\n3.2. METHODS OF SOLUTION\nThus, the response in this case is a Gaussian function, as before, but the entire\nprofile drifts in the positive x-direction with drift velocity v.\nDrift and chemical reaction. With a non-zero chemical rate, r , and drift velocity,\nv, we need to solve Equation 3.6 which has a solution\nc(x, t) = e-rtG(x - vt, t; β, 0).\n(3.12)\nIn general, if c (x, t) is the solution to Equation 3.3, with a specified initial con-\n≈\ncentration profile and transparent boundaries, then the solution to the modified\nequation, 3.6, satisfying the same initial conditions, is given by\nc(x, t) = e-rtc≈(x - vt, t).\n(3.13)\nSinusoid\nFirst we consider the solution to Equation 3.3 with the initial condition\nc(x, 0) = A (1 + sin(∂x + ))\n(3.14)\nfor some arbitrary constant amplitude, A, spatial radian frequency, ∂, and phase,\n. The solution for t > 0 is given by\nc(x, t) = A 1 + e-D∂2t sin(∂x + ) ,\n(3.15)\nwhich can be verified by substituting this expression into Equation 3.3. Thus,\nan initially sinusoidal concentration profile remains sinusoidal for all later time,\nbut the amplitude decreases exponentially with time. The rate of attenuation is\nproportional to the square of the spatial frequency.\nWith drift and a chemical reaction between solute and solvent, the solution is\nc(x, t) = Ae-rt 1 + e-D∂2t sin ∂(x - vt) +\n,\n(3.16)\nwhere v is the drift velocity and r is the reaction rate.\nDiscontinuous initial profile\nWe next consider the case of an initial profile that is piecewise-constant but con\ntains a jump discontinuity at x\nβ. The initial condition is that\n=\n⎢\ncL,\nx\n\n<\n\nβ\n\nc(x, 0) =\ncR,\nx\n\n>\n\nβ\n,\n\n(3.17)\nwhich can also be written as\n⎨\nc(x, 0) = cL + (cR - cL)\nω(x - x≈) dx .\n(3.18)\n≈\nβ\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFor t > 0, we can integrate the Green's function defined by Equation 3.8 to obtain\nthe solution:\n⎨\nc(x, t)\ncL + (cR -cL)\nG(x, t; x≈, 0) dx≈\n=\nβ\n⎨\ncL + (cR -cL)\nβ\np\n4γDt e-(x-x≈)2/4Dt dx≈\n=\n⎦\n⎦\n\ncL + (cR -cL)\nerfc x -β\n,\n(3.19)\n1 -2\np\nDt\n=\nwhere the complementary error function, erfc(x), is defined by the integral\n⎨\nerfc(x) = pγ\nx\ne-t2 dt.\n(3.20)\nWith a drift velocity, v, and reaction rate, r , the solution is\n⎦\n⎦\n\nrt\nrt\nc(x, t) = cLe-\n+ (cR -cL)e-\n1 - erfc x -vt -β\n.\n(3.21)\np\nDt\n3.2.2 Numerical Solutions\nOne-dimensional problems with reflecting boundaries and the two-compartment\nproblem are solved using numerical methods. To solve a diffusion problem nu\nmerically over some specified spatial region and some specified time interval, the\nposition and time variables are discretized. Denoting the time increment by t\nand the position increment by x, we define\nj\nui = c(xi, tj),\n(3.22)\nwhere\nx0 + ix, i\n1, . . . , N\nxi =\n=\n(3.23)\ntj = t0 + jt,\n1, . . . , M.\nj =\nA general approach to solving partial differential equations numerically is to\nreplace the partial derivatives by finite-difference approximations. The finite-\nj\ndifference expressions involve the ui terms defined above and result in sets of\nalgebraic equations that can be solved by numerical methods for solving ma\ntrix equations. In the software, the equation with no drift term is solved by\nthe implicit Crank-Nicolson algorithm, while for problems with a non-zero drift\nterm, this algorithm is combined with the explicit Two-Step Lax-Wendroff method\n(Press et al., 1988; Gerald and Wheatley, 1989). When a non-zero chemical reac\ntion rate, r , is specified, the computed concentration is multiplied by the atten\nuation factor, e-rt . The Crank-Nicolson and Lax-Wendroff formulas involve the\nparameters τ\nDt/(x)2 and α\nvt/x. The numerical methods give sta\n=\n=\nble solutions provided τ < 0.5 and α| ←1. For the two compartments option,\n|\nthe boundary conditions at the membrane solution interface is that the concen\ntration in the membrane at the interface is equal to the bath concentration.\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nOption\nBoundary Type\nComputational Method\nImpulse\nTransparent\nExact solution\nReflecting\nCrank-Nicolson\nSinusoid\nTransparent\nExact solution\nDiscontinuity Transparent\nExact solution\nReflecting\nCrank-Nicolson\nArbitrary\nReflecting\nCrank-Nicolson\nTwo-Compartment\nCrank-Nicolson\nTable 3.1: Summary of computational methods.\n3.2.3 Summary\nA variety of techniques are used to find exact solutions to one-dimensional dif\nfusion problems with transparent boundaries. The specific methods used in the\nsoftware to solve one-dimensional problems depend on the initial conditions and\nare summarized in Table 3.1. With two reflecting boundaries and in the absence\nof drift, the exact solutions consist of infinite series. Thus it is cumbersome to\ncompute these exact solutions. With two reflecting boundaries and with drift,\nexact solutions are in general not available. Therefore, we have chosen to solve\nthese problems numerically using the Crank-Nicolson and Lax-Wendroff meth\nods. The latter methods are also used to compute the solutions to the two-\ncompartment problem.\n3.3 User's Guide To The Software\nWhen this software package is selected, 4 figures are displayed (in addition to\nMATLAB's command window) -- MD Controls, Initial concentration profile, Plots\nversus position, and Plots versus time. A typical session with the software consists\nof selecting one of five initial concentration profile options, selecting the values\nof parameters, executing a simulation, and analyzing the results.\n3.3.1 MD controls\nThe controls figure controls the macroscopic diffusion software and is shown in\nFigure 3.2. The part of the controls figure below the menubar is divided into six\npanels. The upper left panel controls the display of the initial concentration and\nthe numerics. The upper middle panel controls timing of the simulation. The\nupper right panel (the analysis panel) controls the display of simulation results.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.2: The MD controls figure.\nClicking on a selection box display the appropriate figure; clicking again hides\nit. The next horizontal panel down allows the simulation to be started, paused,\ncontinued, or reset. The log panel contains options for recording log entries\nof the session and is described in Chapter 1. The bottom horizontal panel is a\nmessage window that displays information to the user.\nTiming\nThe user can select the number of steps in time for computing the simulation\nresults and the interpoint integration time. The product gives the duration of\nthe simulation time interval. The end time indicates the projected end of the\nsimulation at any time. This number is updated if the simulation is continued.\nThe time is the present value of the simulation time, it is the elapsed simulation\ntime since the simulation was started. Clicking on 1 Time step results in the\ncomputation of one step of the simulation.\n3.3.2 Initial concentration profile\nThe initial concentration profile figure (Figure 3.3) allows control of the initial\nconcentration and all the parameters of the diffusion process. The four one-\ndimensional diffusion problems and the two-compartment problem are imple\nmented in the software as five options called: Impulses (Figure 3.3), Sinusoids\n(Figure 3.4), Discontinuities (Figure 3.5), Arbitrary (Figure 3.6), and Two Com\npartments (Figure 3.7). For each option, the user can modify the values of the\noption-specific parameters (described in the captions), change the graph param\neters, and run a simulation. To modify the value of a parameter, the user clicks\non the parameter and then types in the new value, followed either by a carriage\nreturn or by selection of another parameter. A change in most parameter values\nrequires that figures be updated to reflect the new value of the initial concentra\ntion profile. Since this update takes some time, it may be helpful to deselect Plots\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure 3.3: Initial concentration figure for impulses. When the software is initiated,\nImpulses is the default initial concentration profile. In general, the magnitudes and po\nsitions of four impulses can be specified. The positions of each impulse can be set only\nif its magnitude is non-zero. The boundary type (transparent or reflecting) is selectable,\nand, if the boundaries are reflecting, the positions of the two reflecting boundaries can\nbe set.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.4: Initial concentration figure for sinusoids. The frequencies and amplitudes\nof the four sinusoids were chosen to correspond to the first four terms in the Fourier\nseries of a square wave. In general, the amplitudes, frequencies, and phases of four\nsinusoids can be specified. The frequency and phase of a sinusoid can be set only if\nits amplitude is non-zero. Only transparent boundaries are available for the sinusoids\noption.\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure 3.5: Initial concentration figure for discontinuities. Two discontinuities were\nused to generate an initial concentration profile that is a rectangular pulse. In general,\nthe magnitude and position of four discontinuities can be specified. The position of a\ndiscontinuity can be set only if its magnitude is non-zero. The boundary type (trans\nparent or reflecting) is selectable, and, if the boundaries are reflecting, the positions of\nthe two boundaries can be set.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.6: Initial concentration figure drawn using the arbitrary option. Only the re\nflecting boundary condition is available for this option, and the positions of the two\nboundaries is specifiable. The initial profile is drawn on the monitor screen by moving\nthe mouse cursor. The details are described in Section 3.3.5.\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure 3.7: Initial concentration figure for the two compartments option. In general,\nspecification can be made for the width and the initial concentration in each bath, the\nmembrane width, and the initial membrane concentration profile, drawn with a mouse\ncursor (as described in Section 3.3.5). The user can also chose how the two baths and\nthe membrane are to be displayed. Selecting the View membrane option displays the\nmembrane and a bit of each bath on each side. Selecting the View baths option displays\nthe membrane and both baths to scale.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.8: The diffusion parameters figure.\nvs. position and Plots vs. time from the MD controls figure. All the parameters\nfor each option can be saved in a file and read from a file.\nDiffusion parameters\nClicking on Diffusion parameters in the Initial concentration profile figure displays\nthe Diffusion parameters figure (Figure 3.8). This figure allows the user to spec\nify the diffusion parameters (diffusion coefficient, drift velocity, and chemical\nreaction rate) for each option independently. For the two compartments option\nthese diffusion parameters apply to the membrane and not to the baths.\nGraph of initial concentration\nThe initial concentration is plotted in the Initial concentration profile figure (Fig\nures 3.3-3.7). A check box in the upper right-hand corner allows display of the\ninitial flux. An axis scale can be changed by clicking on its label to display the\naxis-scale figure which is described in Chapter 1. The new axis limits can be typed\ninto the edit boxes to change the axis. In addition, there are two markers that are\nindicated by two triangles on the abscissa. These markers indicated positions\nat which the concentration and flux can be displayed as a function of time. The\npositions of these markers can be controlled numerically or graphically. Numer\nical control is achieved by typing into the appropriate text edit box. Graphical\ncontrol is achieved by clicking on the abscissa axis. The left marker is controlled\nby clicking the left button on a two-button mouse or by clicking the button on\na single-button mouse. The right marker is controlled by clicking the right but\nton on a two-button (or three-button) mouse or by shift-clicking the button on a\nsingle-button mouse.\n3.3.3 Numerics\nClicking on Numerics in the MD Controls figure displays the Numerics figure (Fig\nure 3.9). The numerics figure controls the spatial resolution of the simulation.\nThe upper portion of this figure deals with those computations that make use\nof exact solutions of the diffusion equation (i.e., all one-dimensional diffusion\nproblems with transparent boundaries). For this case, the user can select the\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure 3.9: The numerics figure.\nnumber of spatial points at which the solution is computed. The larger the num\nber of points, the higher the spatial resolution of the computation and the longer\nit will take to complete the computation. The lower portion of this figure deals\nwith those computations that use numerical integration of the diffusion equation\n(i.e., all one-dimensional diffusion problems with reflecting boundaries and the\ntwo-component diffusion problem). The user can choose to select the number\nof points in space at which the solution is computed. The user has a choice in\nhow the interpoint integration time is to be determined. The numerical method\nis stable provided an inequality that relates the temporal and spatial resolution\nis satisfied. If Auto-link with DELTA_T is selected, the simulation determines\nthe integration time to satisfy the inequality and to guarantee a stable integration\nmethod which results in an accurate solution. If this choice is not selected, the\nuser can choose the temporal resolution (integration time) and spatial resolution\nindependently. However, with this choice there is no guarantee that the solution\nwill be accurate.\n3.3.4 Analysis figures\nThere are two figures that display the solute concentration and flux during a\nsimulation. The Plots versus position figure displays the concentration and/or\nthe flux as a function of position at each instant in time during the simulation\n(Figure 3.10). The current simulation time is displayed near the top of the figure.\nAxes limits can be changed by clicking on the axes labels to display the axis-scale\nfigure. The two green triangular markers mirror the markers shown in the Initial\nconcentration profile figure. With the Two compartments option, the user can\nalso chose how the two baths and the membrane are to be displayed. Selecting\nthe View membrane option displays the membrane and a bit of each bath on each\nside. Selecting the View baths option displays the membrane and both baths to\nscale.\nThe Plots versus time figure (Figure 3.11) displays the concentration and/or\nthe flux as a function of time during the simulation for two positions selected\nby the markers found in both the Initial concentration profile figure and the Plots\nversus position figure (Figure 3.10). The locations of the markers are indicated at\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.10: Plots versus position figure.\nFigure 3.11: Plots versus time figure.\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nthe top of the figure. Axes limits can be changed by clicking on the axes labels\nto display the axis-scale figure.\n3.3.5 Arbitrary concentration profiles\nFor the Arbitrary and Two compartments options, the user can draw an arbitrary\ninitial concentration profile by clicking on the Draw initial profile button and can\nerase an existing profile by selecting the Erase initial profile button. Clicking on\nthe Draw initial profile button will erase the existing profile.\nDrawing a profile consists of generating a list of concentration values at a\ncorresponding array of positions. The user selects these points by moving the\nmouse and clicking any mouse button. As the pointer moves within the plotting\nfield in the Initial concentration profile figure, a line joins the last point which\nwas selected to the current pointer position. There are two modes of action that\nthe user can use to draw the profile:\nClicking a mouse button within the axes of the graph adds a position and\n-\nconcentration value to the coordinate lists and draws a line segment from\nthe previous point to the current point. In this manner, the user can con\nstruct a profile made up of line segments.\nMoving the mouse while a mouse button is held down causes a series of\n-\npoints to be added to the coordinate lists. In this manner, the user can\nconstruct more complicated curves.\nThe two methods can be combined in drawing a single profile. As soon as a\ncomplete profile has been drawn, the drawing routine terminates and stores the\nprofile data.\nThere are some additional rules of operation for drawing initial profiles. When\na button is pressed, the position and concentration that are added to the coordi\nnate arrays depend on the pointer location:\nA button press at a position that does not lie to the right of the previous\n-\npoint is ignored, in order to ensure that the user-drawn concentration pro\nfile is a single-valued function of position.\nIf a button is pressed within the graph axes, then the coordinates of the\n-\npointer location are added to the list.\nIf a button is pressed outside the boundaries of the graph (but still within\n-\nthe graph window), then the point that is added to the list is the point of\nintersection between the graph boundary and a line from the previous point\nto the current position. Thus, while a profile is being drawn, it is constrained\nto lie entirely within the boundaries of the graph.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nBy default in the arbitrary option, the concentration at the left-hand point of\n-\nthe profile is zero. The user can change the first value, however, by making\nthe first button press at the desired vertical location but to the left of the\nconcentration axis. In the two components option, the concentration at the\nleft-hand point of the profile is set equal to the concentration in the left\nbath (bath #1), and the concentration at the right-hand point of the profile\nis set equal to the concentration in the right bath (bath #2).\nClicking outside the Initial concentration profile figure at any time aborts the\ndrawing procedure.\n3.4 Problems\nProblem 3.1 In this problem you will investigate the space-time evolution of so\nlute diffusion from a point source. For all parts of this problem use a single im\npulse and transparent boundaries. Set the impulse strength to 100 moles/cm2,\nplace the impulse at position 0.5 cm, and set the drift velocity and the reaction\nrate to zero. Set the marker positions to 0.55 and 0.6 cm unless indicated other\nwise. Set the diffusion coefficient to 10-5 cm2/s and run the simulation for 1000\nseconds. Obtain a plot of the concentration and flux on appropriate ordinate\nscales. You should obtain the spatial distribution of the concentration and the\nflux at 1000 seconds and both variables as a function of time at the two marker\npositions. Repeat these two steps for a diffusion coefficient of 4 × 10-5 cm2/s.\na. Describe qualitatively the effect of the change in diffusion coefficient on\nthe spatial distribution of concentration. Be brief.\nb. For both values of the diffusion coefficient, determine the maximum am\nplitude of the concentration versus position and the width of the spatial\ndistribution of concentration at an amplitude that is e-1 of its peak value.\nExplain the numerical values of all four measurements. Be brief and precise;\nstate your assumptions explicitly.\nc. For the diffusion coefficient at 10-5 cm2/s, examine the concentration ver\nsus time at the two positions 0.55 and 0.6 cm. Describe qualitatively the\ndifferences in concentration versus time at the two positions. Be brief.\nd. For the diffusion coefficient at 10-5 cm2/s, measure the maximum concen\ntration as a function of time at the two positions and the time of occurrence\nof this maximum. Explain the values of all four measurements. Be brief and\nprecise; state your assumptions explicitly.\ne. Explain the shape of the spatial distribution of flux for a diffusion coeffi\ncient of 10-5 cm2/s.\n\n3.4. PROBLEMS\nf. Explain the relation between the flux and concentration versus time at lo\ncation 0.55 cm for a diffusion coefficient of 10-5 cm2/s.\ng. Rerun the simulation for a diffusion coefficient of 10-5 cm2/s at positions\n0.45 and 0.55 cm. Explain the differences in the flux as a function of time\nfor these two locations.\nProblem 3.2 This problem deals with the solution from a point source in the\npresence of drift. Set the impulse strength to 100 moles/cm2; place the impulse\nat position 0.5 cm; set the diffusion coefficient to 10-5 cm2/s, and the reaction\nrate to zero. Set the marker positions to 0.75 and 0.9 cm unless indicated other\nwise. The parts of this problem that deal with reflecting boundaries are solved\nnumerically. To decrease the time taken for these computations, consider de\ncreasing the spatial resolution of the computation to 10 points.\na. Set the boundary conditions to transparent and the drift velocity to zero\nand run the simulation for 1000 s. Now set the drift velocity to 10-4 cm/s\nand run the simulation again for 1000 s. Describe the effect of the drift\non the spatial distribution of concentration. Account quantitatively for the\nposition of the peak of the spatial distribution at 1000 s.\nb. Set the boundary conditions to reflecting and the drift velocity to zero. Run\nthe simulation until the spatial distribution is no longer a function of time.\nThis is the equilibrium distribution. What is the spatial distribution at equi\nlibrium? Explain your answer.\nc. Set the boundary conditions to reflecting, the drift velocity to 10-4 cm/s,\nand run the simulation. Describe the effect of drift on the spatial distribu\ntion of concentration. Illustrate your description with printed copies of the\ndistribution at characteristic times.\nd. With the boundary conditions still set to reflecting and the drift velocity\n10-4 cm/s, determine the equilibrium spatial distribution of concentration.\nAccount quantitatively for this distribution.\ne. It is known that the density of air decreases exponentially with distance\nabove the earth's surface. Explain this phenomenon.\nProblem 3.3 As shown elsewhere (Weiss, 1996a, Chapter 3), two-compartment\ndiffusion is based on 4 assumptions:\n1. The two compartments are well-mixed so that the concentrations of solute\nn are uniform and have values at time t of c1\nn(t).\nn(t) and c2\n2. Solute particles are conserved, e.g., there is no chemical reaction present\nthat either creates or destroys particles.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\n3. The membrane is sufficiently thin and the number of solute particles con\ntained in the membrane at any time is negligibly small.\n4. The membrane is sufficiently thin that at each instant in time the concen\ntration profile in the membrane is in steady state.\nThis problem concerns the conditions for the validity of assumptions 3 and 4.\nSpecifically, you will explore the effect of bath dimensions on two-compartment\ndiffusion without making these two assumptions.\nIn all parts of the problem, use the Two compartments option of the software.\nSet the membrane width to 0.01 cm, and the concentration of bath #1 to 70 and\nbath #2 to 10 mol/cm3. Leave the drift velocity and reaction rate at 0 and the dif\nfusion coefficient at 10-5 cm2/s. Set the parameters of the plot of concentration\nversus position so that the membrane and a little of each bath are visible on the\nscreen -- select membrane view. Note that the left edge of the membrane is at a\nposition of 0 cm. Draw some initial concentration in the membrane. Make sure\nall ordinate scales on all plots are 0 to 100 mol/cm3. Keep these parameters fixed\nthroughout this problem. To reduce the time taken for the computation reduce\nthe spatial resolution in the membrane to 10 points in space. The software will\ndetermine the time increment (DELTA_T). Initially set the number of steps so that\nthe end time is 5 s.\nFor each of the pairs of bath widths -- Bath #1 = 1 cm, Bath #2 = 1 cm; Bath #1\n= 0.1 cm, Bath #2 = 0.1 cm; Bath #1 = 0.01 cm, Bath #2 = 0.01 cm; Bath #1 = 0.01\ncm, Bath #2 = 0.05 cm; Bath #1 = 0.001 cm, Bath #2 = 0.001 cm; -- answer the\nfollowing questions.\na. Assess the validity of assumption 4.\ni. Make rough estimates of both the steady-state (ss ) and equilibrium\n(eq ) time constants from the computations.\nii. Estimate the same two time constants based on theoretical considera\ntions (Weiss, 1996a, Chapter 3).\niii. What is your conclusion based on your computations and your esti\nmates of time constants?\nb. Assess the validity of assumption 3.\ni. Before you do the computation, make an estimate of the final concen\ntration in each bath. Then do the computation, and check your initial\nestimates against the computed values\nii. If they differ, explain the basis of the difference.\niii. How good is the assumption that the quantity of solute in the mem\nbrane is negligible? If you decide that the quantity of solute in the\nmembrane is not negligible, design a simulation experiment to test\nyour conclusion.\n\n3.4. PROBLEMS\ne. Are the bath concentrations exponential functions of time? Explain.\nProblem 3.4 Some problems in diffusion with a reflecting boundary can be solved\nby using the solution for a transparent boundary and the method of images to\nmatch the reflecting boundary condition. This problem explores the successes\nand pitfalls of this method. In all parts of this problem, set the drift velocity to\nzero, the reaction rate to zero, and the diffusion coefficient to 10-5 cm2/s unless\nstate otherwise. The parts of this problem that deal with reflecting boundaries\nare solved numerically. To decrease the time taken for these computations, con\nsider decreasing the spatial resolution of the computation to 10 points.\na. Use reflecting boundaries, and an initial impulse of concentration of strength\n100 moles/cm2 located at 0.2 cm. Run the simulation for 1000 s and obtain\na print of the spatial distribution of concentration at time 1000 s and the\nconcentration versus time at locations 0 and 0.3 cm.\nb. At a reflecting boundary, the flux must be zero. Change the boundary con\ndition to transparent and determine the parameters of two impulses: one\nto match the left boundary condition and another to independently match\nthe right boundary condition. Run the simulation again and compare with\nthe results in part a. Does this \"method of images\" work exactly? Explain.\nProblem 3.5 Diffusion from an initial sinusoidal concentration distribution gives\nimportant insights into the space-time evolution of diffusion processes. In all\nparts of this problem, use a drift velocity of zero, a reaction rate of zero, and a\ndiffusion coefficient of 10-5 cm2/s unless state otherwise.\na. Use an initial concentration that is sinusoidal with amplitude 50 moles/cm2\nand a spatial frequency of 1 cycle/cm. Run the simulation for 1000 s and\nprint the spatial distribution of concentration at 1000 s and the concentra\ntion versus time at 0.25 and 0.75 cm. Repeat this procedure for sinusoids\nwith the same amplitudes but the following spatial frequencies: 3, 5, and 7\ncycles/cm. Summarize your results both qualitatively (in words) and then\nquantitatively (with suitable calculations).\nb. Construct a periodic waveform from four sinusoids with the following am\nplitudes (moles/cm2) and spatial frequencies (cycles/cm): 105, 1; 35, 3; 21,\n5; 15, 7. Run the simulation and observe the spatial distribution of concen\ntration. Summarize your results and relate them to results of part a.\nc. Switch to the arbitrary initial distribution option and set the boundary con\nditions to reflecting. Using the mouse draw an arbitrary, preferably jagged,\ninitial profile. This part of this problem uses a numerical solution method\nthat is time consuming. To decrease the time taken for these computa\ntions, consider decreasing the spatial resolution of the computation to 10\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\npoints. Run the simulation and watch the spatial distribution of concentra\ntion change. Summarize your results. What is the effect of diffusion on the\nspatial distribution?\n\nChapter 4\nCARRIER-MEDIATED TRANSPORT\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\n4.1 Introduction\nTransport of many solutes including important metabolites (e.g. monosaccha\nrides, amino acids, mononucleotides, phosphates, uric acid, etc.) through cel\nlular membranes is accomplished by membrane-bound carrier molecules that\ncombine with the solute molecule on one face of the membrane, then translo\ncate in the membrane and uncombine at the other face. Thus, transport involves\nchemical reactions in which the solute binds and unbinds with a carrier. This\ntype of transport is called carrier-mediated transport. Carrier-mediated trans\nport has distinctive properties. For example, the relation of flux to concentration\nsaturates, i.e., it does not obey Fick's law for membranes. In addition, differ\nent molecules compete for the carrier. For example, glucose and sorbose (two\nmonosaccharides) compete for the sugar carrier. Hence, transport of one sugar\ncan inhibit transport of another simply by occupying a site to which both can\nbind.\nThere are canonical models of carrier-mediated transport that capture impor\ntant properties of the transport of metabolites through cellular membranes. It\nis important to understand these canonical models in order to understand how\nmetabolites are transported across these membranes. Derivations of predictions\nof these models are not particularly difficult to follow; the individual steps are\nsimple. However, the models typically result in messy algebraic expressions that\nrelate flux to concentration and transport parameters. Thus, it is easy to get lost\nin algebraic manipulation as well as in a sea of parameters so that an intuitive\ngrasp of the models becomes illusive. The intent of this software is to allow the\nuser to develop intuition for these models.\n4.2 Description Of The Models\nDescriptions of carrier-mediated transport as well as models of such transport\nprocesses can be found elsewhere (Stein, 1986; Weiss, 1996a). Here we consider\nthree models and list both the assumptions and the important results. First, we\nconsider the steady-state behavior of a simple, four-state carrier that binds one\nsolute Then, we consider the steady-state behavior of a simple, six-state carrier\nthat binds two solutes with different affinities. Finally, we consider both the\ntransient and the steady-state behavior of a general, four-state carrier model that\nbinds one solute.\n\nc\n4.2. MODELS\nMembrane\nE\ni\nnE\nno\nE\nKi\nS\nKo\nS\nτES\nαES\nτE\nEi\nEo\nESi\nESo\nSi\n+ So\n+\nExtracellular\nFigure 4.1: Kinetic diagram of\nthe simple, four-state carrier\nthat binds one solute.\nIntracellular\ni\nS\no\nS\nc\nαE\ni\no\nnES\nS\nES\nnES\n=\n4.2.1 Steady-state behavior of a simple, four-state carrier that\nbinds one solute\nAssume that the membrane contains NET moles of carrier per unit area of mem-\nbrane.1 Each of these carriers exist in one of four states labeled ESi , ESo , Ei, and\nEo (Figure 4.1). In the ES states, the solute S is bound to the carrier E; in the\nE state the carrier is unbound. In the ESi and Ei states, the carrier, bound and\nunbound, communicates with the solution on the inner side of the membrane.\nIn the ESo and Eo states, the carrier, bound and unbound, communicates with\nthe solution on the outer side of the membrane. The densities of carrier in the\ni\no\no\nfour states are nES, nES , nE\ni , and nE moles per unit area of membrane. The fluxes\nof bound and unbound carrier are ES and E and the flux of solute is S . The\nflux is defined as positive when the flux is in the outward direction; the units\nare in moles per unit area per second. The model is defined by the following\nassumptions:\nThe total amount of carrier, bound and unbound, is constant, i.e. the sum\n-\nof the carrier density over all of its states equals the total density of carrier\nin the membrane\nNET\ni\no\ni\no\n(4.1)\n= nES + nES + nE + nE.\nSince the carrier resides permanently in the membrane, the total flux of\n-\ncarrier must be zero, i.e.\nES + E = 0.\n(4.2)\nThe only time the solute crosses the membrane is when it is bound to the\n-\ncarrier; ESo is assumed to undergo a reversible change in conformation to\nthe form ESi. The unbound carrier is assumed to undergo a similar reaction\n1Because the kinetic equations for binding of the carrier to the solute are analogous to those\nof the binding of an enzyme to its substrate, the carrier is denote by E which stands for enzyme.\n\n3 2\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nbetween the two conformations Ei and Eo. These two reactions are assumed\nto be first-order reactions with forward and reverse rate constants, τE, τES,\nαE, and αES , so that the fluxes are defined as follows:\nES,\n(4.3)\nES = S\nτESnES\ni - αESno\n=\nτEnE\ni - αEno\nE\nE.\n(4.4)\n=\nIn the simple model, the binding reactions at the membrane interfaces are\n-\nassumed to be so rapid, compared to the rate of transport of solute across\nthe membrane, that the membrane interface reactions are assumed to be at\nequilibrium, i.e.,\nco\no\ni\ni\nS and cSnE\nKi\nSnE\nKo\nS,\n(4.5)\nno\nES\n=\nnES\ni\n=\nwhere Ko and Ki\nS\nS are the dissociation constants on the two membrane in\nterfaces.\nThese equations can be solved to determine the n's in terms of the concentra\ntions and transport parameters. Equations 4.3 and 4.4 can be used to determine\nthe 's. Combining Equations 4.2, 4.3, and 4.4 yields\n(τESnES\ni - αESno\nES) + (τEnE\ni - αEno\n0.\n(4.6)\nE) =\nEquations 4.1, 4.5, and 4.6 can be expressed as a matrix equation as follows:\ni\nKi\nS\ni\n-c\nn\nS\nES\n666⎤\n666⎤\n⎪⎪⎪⎣\n⎪⎪⎪⎣ =\n666⎤\n⎪⎪⎪⎣\nKo\nS\n-co\nS\n-αE\nno\nES\nn i\nE\n.\n(4.7)\nτES -αES τE\nno\nE\nNET\nThe first two rows correspond to the two relations in Equation 4.5. The third row\nresults from Equation 4.6, and the fourth row corresponds to Equation 4.1. This\nset of simultaneous equations has the following solutions (Weiss, 1996a):\ni\ncS(αEKo\nS)\ni\nD1\n,\n(4.8)\nnES = NET\nS + αESco\ni\nS(τEKi\nno\nES = NET\nco\nS + τEScS),\n(4.9)\nD1\nS(αEKo\nKi\nS + αESco\ni\nnE = NET\nD1\nS),\n(4.10)\ni\nS(τEKi\nKo\nS + τEScS)\nno\nE = NET\nD1\n,\n(4.11)\nwhere\ni\ni\nD1 = (αEKo\nS)(Ki\nS + τEScS)(Ko\nS).\n(4.12)\nS + αESco\nS + cS) + (τEKi\nS + co\n\nc\nc\n4.2. MODELS\nMembrane\ni\nS\nES\no\nni\nE\nno\nE\nnES\nnES\nKi\nS\nKo\nS\nτES\nαES\nτE\nαE\nE\n=\nEi\nEo\nESi\nESo\nKi\nR\nKo\nR\nτER\nERi\nERo\ni\no\nc\nS\nS\nExtracellular\nFigure 4.2: Kinetic diagram of a simple,\nsix-state carrier that binds two solutes (S\nand R).\nIntracellular\nSi\nSo\n+\n+\nRi\nRo\ni\no\nc\nR\nR\ni\nαER\no\nnER\nnER\nR = ER\nS and E can be obtained from Equations 4.3 and 4.4.\nThe flux of solute can also be expressed in terms of the uni-directional fluxes\nas\nS =\n≤\nS -\n�\nS ,\nwhere\n≤\nS = τES ni\nES and\n�\nS = αES no\nES .\n4.2.2 Steady-state behavior of a simple, six-state carrier that binds\ntwo solutes\nThe simple, four-state carrier shown in Figure 4.1 can be extended to account for\nthe binding of two solutes that compete competitively for binding sites on the\ncarrier (Figure 4.2). In this scheme, solutes S and R combine with carrier E but\nwith different affinities. The binding to solute S has dissociation constants Ki\nS\nand Ko\nR and Ko\nS and the binding to R has dissociation constants Ki\nR.\nThe kinetic equations are analogous to those derived for the simple, four-state\ncarrier except that the carrier now has 6 states:\nThe total amount of carrier, bound and unbound, is constant, i.e. the sum\n-\nof the carrier density over all of its six states equals the total density of\ncarrier in the membrane\nNET\nnES\ni + no\ni\nES + nER + no\ni\nE,\n(4.13)\nER + nE + no\n=\n\n3 2\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nwhere NET is the total density of carrier in the membrane.\nSince the carrier remains in the membrane, the net flux of carrier must be\n-\nzero\nES + ER + E = 0.\n(4.14)\nThe fluxes are related to the carrier densities so that\n-\n(τESnES\ni - αESno\nES = S\nES).\n(4.15)\n=\n(τERnER\ni - αERno\nER = R\nER).\n(4.16)\n=\no\nE\n(τEnE\ni - αEnE).\n(4.17)\n=\nIn the simple model, the reactions at the membrane interfaces are assumed\n-\nto take place so rapidly, compared to the rate of transport of solute across\nthe membrane, that the membrane interface reactions are assumed to be at\nequilibrium, i.e.,\nSno\ni\ni\nco\ni\nE\nKi\nco\nE\nKo cSnE\nKi\nRno\nKo cRni\nno\nS,\ni\nS and no\nE\nR,\nR,\n(4.18)\nES\n=\nnES\n=\nER\n=\nnER\ni\n=\nwhere Ko\nS , Ko\nR are the dissociation constants for solutes S and R,\nS , Ki\nR and Ki\nrespectively at the two membrane interfaces.\nCombining Equations 4.14 and 4.15, 4.16, and 4.17 yields\nES) + (τERnER\ni - αERno\n(τESnES\ni - αESno\nER) + (τEnE\ni - αEno\n0.\n(4.19)\nE) =\nIt is of interest to obtain the flux of solutes S and R as a function of both con\ncentrations and the transport parameters Ki\nS , Ki\nR, τES , τER, τE, αES , αER,\nS , Ko\nR, Ko\nαE, and NET . Therefore, it is useful to regard the system of algebraic equations\ngiven by Equations 4.14 through 4.19 as a set of 6 equations in the 6 unknowns\ni\nES , nER, no\ni\nnES , no\ni\nER, nE, and no\nE. These can be written in matrix form as follows:\ni\nKi\nS\ni\n-c\nn\nS\nES\n6666666⎤\n6666666⎤\n⎪⎪⎪⎪⎪⎪⎪⎣\n⎪⎪⎪⎪⎪⎪⎪⎣\n=\n6666666⎤\n⎪⎪⎪⎪⎪⎪⎪⎣\nKo\nS\n-co\nS\nno\nES\ni\nKi\nR\ni\nER\n-c\nn\nR\n.\n(4.20)\nKo\nR\n-co\nR\n-αE\nno\nER\ni\nE\nτES -αES τER -αER τE\nn\nno\nE\nNET\nThe first four rows correspond to the four relations in Equation 4.18. The fifth\nrow results from Equation 4.19, and the sixth row corresponds to Equation 4.13.\nThis set of simultaneous equations has solutions (Weiss, 1996a):\ni\nnES\nNET\nR(αEKo\nR + αESco\nR + αERKo\nR)\ni\ncSKi\nSKo\nSKo\nSco\n,\n(4.21)\n=\nD2\n\n4.2. MODELS\ni\ni\nES\nNET\nco\nR(τEKi\nR + τEScSKi\nScR)\nSKo\nSKi\nR + τERKi\nno\n,\n(4.22)\n=\nD2\nKi\ni\nSKo\nSKo\nSco\nnER = NET\nScR(αEKo\nR + αESco\nR + αERKo\nR)\ni\n,\n(4.23)\nD2\ni\ni\nER = NET\nco\nS(τEKi\nR + τEScSKi\nScR)\nRKo\nSKi\nR + τERKi\nno\n,\n(4.24)\nD2\nSKi\nSKo\nSKo\nSco\nnE = NET\nKi\nR(αEKo\nR + αESco\nR + αERKo\nR)\ni\n,\n(4.25)\nD2\ni\ni\nE = NET\nKo\nR(τEKi\nR + τEScSKi\nScR)\nSKo\nSKi\nR + τERKi\nno\n,\n(4.26)\nD2\nwhere\nD2\nS(ci\nRτE)(Ko\nR + co\nR + Ko\nR) +\nKi\nRτER + Ki\nSKo\nSKo\nSco\n=\ni\ni\nS(co\nRαE)(Ki\nR + cSKi\nScR) +\ni\nKo\nRαER + Ko\nSKi\nR + Ki\ncSKi\nSKo\nSKo\nSco\nRτES(Ko\nR + co\nR + Ko\nR) +\ni\ni\nSKo\nSKi\nR + Ki\nco\nRαES(Ki\nR + cSKi\nScR).\n(4.27)\nThe fluxes can be computed using Equations 4.15-4.17.\nThe solute fluxes can also be expressed in terms of the uni-directional fluxes\nas\nS\n≤\nS -\n�\nS,\n=\nR\n≤\nR -\n�\nR,\n=\nwhere\n≤\nS\nτESnES\ni and\n�\nS = αESno\nES,\n=\no\n≤\nR\nτERnER\ni\nand\n�\nR= αERnER.\n=\n4.2.3 Transient and steady-state behavior of a general, four-state\ncarrier that binds one solute\nTransient solution\nSuppose that in the simple, four-state carrier model shown in Figure 4.1, the as\nsumption that the interfacial binding reactions are fast is dropped. The model\nwhich results is called the general, four-state carrier model and the kinetic dia\ngram for this model is shown in Figure 4.3.\nThis model is defined by the following assumptions:\n\n3 2\nc\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nMembrane\ni\nE\no\nnE\nnE\n+ Ei\nEo\nESi\nESo\nai\nao\nbi\ngi\ngo\nhi\nho\nSi\n+ So\nExtracellular\nFigure 4.3: Kinetic diagram of a general,\nfour-state carrier model that binds one so\nlute.\nIntracellular\ni\nS\no\nS\nc\nbo\ni\no\nnES\nnES\nS\nES\n=\nThe total amount of carrier, bound and unbound, is constant, i.e. at each\n-\ninstant in time the sum of the densities of carrier over all of its states equals\nthe total density of carrier\nES(t) + nE\ni (t) + no\nNET\nnES\ni (t) + no\nE(t).\n(4.28)\n=\nSince both transient and steady-state values will be considered, the notation\nwill be to specify a variable that changes in time as, for example, nES\ni (t) and\nits steady-state value as nES\ni (1).\nSince the carrier resides permanently in the membrane, the total flux of\n-\ncarrier must be zero, i.e.\nES(t) + E(t) = 0.\n(4.29)\nThe only time the solute crosses the membrane is when it is bound to the\n-\ncarrier; ESo is assumed to undergo a reversible change in conformation to\nthe form ESi. The unbound carrier is assumed to undergo a similar reaction\nbetween the two conformations Ei and Eo . The kinetic equations for the\ngeneral, four-state carrier model can be written for the rate of change of\ncarrier in each of the four states by a matrix differential equation which is\ni\nE(t)\ni\nS\ni\nE(t)\n-ai - hic\nai\nn\nao\ngi\nn\n666⎤\n⎪⎪⎪⎣ =\n666⎤\n666⎤\n⎪⎪⎪⎣\n⎪⎪⎪⎣\nd\ndt\nno\nE(t)\n-ao - hoco\nS\nno\nE(t)\ngo\n.\ni\nES(t)\ni\nS\ni\nES(t)\nhic\n-bi - gi\nbo\nbi\nn\nn\nno\nES(t)\nhoco\nS\nno\nES(t)\n-bo - go\n(4.30)\nThe binding reactions are not assumed to be arbitrarily fast. Since the bind\ning reactions are assumed to be second-order kinetic equations, the solute\nconcentrations enter the binding reactions.\n\n3 2\n3 2\n3 2\n4.2. MODELS\nThe four kinetic equations are not independent; e.g., the fourth can be derived\nfrom the first three equations. Thus, the fourth equation can be eliminated and\nno\nES(t) can be eliminated using the conservation of carrier relation,\nES(t) = NET - nE\ni (t) - no\nno\nE(t) - nES\ni (t),\n(4.31)\nto yield the matrix equation\ni\nE(t)\ni\nS\ni\nE(t)\n-ai - hic\nn\nao\ngi\nn\nd 6⎤\n⎪⎣\n6⎤\n6⎤\n⎪⎣\n⎪⎣ 6⎤ go\nno\nE(t)\nS\n-ao - go - hoco\nno\nE(t)\nNET.\nai - go\ni\nES(t)\ni\n-go\n+\ndt\n=\ni\nES(t)\nS - bo\n-bo\n-bi - gi - bo\n(4.32)\nThis matrix equation can be solved for the three carrier densities and Equa\ntion 4.31 can be used to solve for the fourth density. The solution for each\nof the carrier densities has the form\nnj(t) = Aj1eφ1t + Aj2eφ2t + Aj3eφ3t,\n(4.33)\nwhere the nj 's are the four carrier densities, the φ's are the three non-zero eigen\nvalues of the system, and the A's are the residues. This solution is valid when\nthe eigenvalues are distinct. All 4 carrier densities have the same 3 eigenvalues,\nbut in general, the residues differ. Since the rate constants and concentrations\nare all positive quantities, it can be shown that all the eigenvalues have negative\nreal parts. Both the eigenvalues and residues are functions of the rate constants\nand the solute concentrations. Hence, the solutions yield the carrier densities\nES(t), nE\ni (t), and no\n(nES\ni (t), no\nE(t)) as functions of time for any values of the con\ncentrations of solute S and of the transport parameters ai, ao, bi, bo, gi, go, hi,\nho, and NET .\nSteady-state solution\nIn the steady state, the density of carrier in each of its four states is constant and\nthe derivative terms on the left-hand side of Equation 4.30 are zero. As noted\npreviously, the four equations are not independent. Thus, one of the equations\ncan be eliminated. However, conservation of carrier leads to an independent\nconstraint which can be added to the three independent steady-state equations\nto yield the following four steady-state equations\nhic\nbo\nn\nn\ni\nS)\ni\n-(ai + hic\nai\nE(1)\nno\nE(1)\nao\ngi\nn\n666⎤\n666⎤\n⎪⎪⎪⎣\n⎪⎪⎪⎣\n666⎤\n⎪⎪⎪⎣\n-(ao + hoco\nS)\ngo\n.\n(4.34)\ni\nS\ni\nhic\n-(bi + gi) bo\nES(1)\nno\nES(1)\nNET\n=\nn\nThe solutions (Weiss, 1996a) are ratios of sums of products of rate constants\ni\nMo\nE\nE(1)\nMo nES\ni (1)\nMi\nno\nnE(1)\nMi no\nD\nE ,\nES\nES(1)\nES\nNET\n= D , NET\n=\nNET\n= D ,\nNET\n= D ,\n(4.35)\n⎪⎣\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nwhere\nMi\nS,\nE\naobigo + aogigo + aobogi + bogihoco\n=\nMo\ni\nE\naibigo + aigigo + aibogi + bigohicS,\n=\ni\ni\nMi\naibohoco\ni\nS,\n(4.36)\nES\nS + aogohicS + aobohicS + bohihocSco\n=\nS + aigihoco\ni\ni\nMo\naibihoco\nS + aobihicS + bihihocSco\nES\nS,\n=\nD\nMi\nE + Mi\nE + Mo\nES + Mo\nES.\n=\nThe steady-state flux is found elsewhere and equals (Weiss, 1996a)\ni\nSno\n-E(1) = S(1) = ES(1) = bigohicSnE\ni (1) - bogihoco\nE(1).\n(4.37)\nbigo + bogi + gigo\nThese equations yield the values of the n(1)'s and the (1)'s in steady state as\na function of the concentrations of solute S and of the transport parameters ai,\nao, bi, bo, gi, go, hi, ho, and NET .\nThe flux of solute can also be expressed in terms of the uni-directional fluxes\nas\n≤\nS(1) = S (1)-\n�\nS (1),\nwhere\nbigohicSnE\ni (1)\ni\n≤\nS (1) = bigo + bogi + gigo\n,\no\no\nbogihocSnE(1) .\n�\nS (1) = bigo + bogi + gigo\n4.3 Numerical Methods And Parameters\n4.3.1 Numerical methods\nThe steady-state values of the carrier densities and the carrier fluxes are alge\nbraic functions of the solute concentrations and of the parameters. They could\nhave been computed directly from the steady-state matrix equations for each\ncarrier model. However, it proved to be faster to compute these quantities di\nrectly from the solutions of these matrix equations which are: Equations 4.3-4.4\nand Equations 4.8-4.11 for the simple, four-state carrier, Equations 4.15-4.17 and\nEquations 4.21-4.26 for the simple, six-state carrier, and Equations 4.35-4.37 for\nthe general, four-state carrier.\nThe transient solution for the general, four-state carrier was obtained by solv\ning Equation 4.32 numerically using MATLAB's ode15s routine for solving sets of\nordinary differential equations. The solution for 3 of the 4 carrier densities were\ncomputed; the fourth was computed from Equation 4.31. Eigenvalues of the ma\ntrix of rate constants (Equation 4.32) were computed to aid the user in choosing a\ntime scale for displaying transient responses. Eigenvalues were computed using\nMATLAB's eig function.\n\n4.4. USER'S GUIDE\n4.3.2 Choice of numerical parameters\nSimple models\nThe software enables the user to compute the n's and 's for any values of the\nparameters, the τ's, α's, K's, NET , and the concentrations of solute, the c's. The\nsoftware is initiated with default parameters chosen to approximate hexose trans\nport in human erythrocytes (Carruthers, 1984; Stein, 1986) assuming a symmet\nric transport scheme. The density of carriers was set to NET\n10 pmoles/cm2.\n=\nThe dissociation constant of solute S was set to approximate that of D-glucose,\nKi\nKo\n2 μmoles/cm2, and that of R was set to that of a solute to which\nS\nS\n=\n=\nthe carrier binds with lower affinity, approximating that of D-xylose, so that\nKi\nKo\n200 μmoles/cm2. All the rate constants were set equal with a value\nR\nR\n=\n=\nthat made the maximum flux 100 pmoles/cm2-s so that τES\nαES\nτER\n=\n=\n=\nαER = τE = αE = 20 s-1. The concentrations of solute were chosen arbitrarily as\ni\nfollows: cS\n2, c0\n1, ci\nR = 2, co\n1 μmoles/cm3.\nS\n=\n=\nR =\nGeneral model\n[To be written]\n4.4 User's Guide\nWhen the program is selected, 3 figures are displayed (in addition to MATLAB's\ncommand window): Controls, Parameters, and State. The controls figure controls\nthe software. The remaining figures are for steady-state interactive analysis of the\nsimple, four-state carrier. In the interactive mode, any parameter of the carrier\nmodel can be changed and the resulting steady-state values of carrier densities\nand fluxes are displayed immediately. The same steady-state interactive analysis\nis available in all three models: the simple symmetric, four-state carrier; the sim\nple symmetric, six-state carrier; and the general, four-state carrier. Additional\nmodes of analysis allow plotting the steady-state values of carrier densities and\nfluxes as continuous functions of a user-specified model parameter. In addi\ntion, for the general, four-state carrier, the user can observe transient changes\nin carrier densities in response to a change in parameters. All of these modes of\nanalysis are selected using the controls figure.\n4.4.1 CMT controls\nThe part of the controls figure (Figure 4.4) below the menubar is divided into\nfive panels. The model panel allows the user to choose a particular model for\nanalysis. The analysis panel allows the user to choose among the various modes\nof analysis available in the software by clicking on the appropriate button. The\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.4: Controls figure.\nFigure 4.5: Units of all variables\nin the carrier models.\nmiscellaneous panel allows the user to display the units for all variables used by\nthe software (Figure 4.5). The log panel contains options for recording log entries\nof the session and is described in Chapter 1. The message panel at the bottom\nof the controls figure is used to send messages to the user.\n4.4.2 Model\nClicking on model in the controls figure allows selection of three models of\ncarrier-mediated transport. Selecting a different model will initiate the steady-\nstate, interactive analysis for that model. The models are listed below.\nSimple, four-state: refers to the simple, four-state carrier that binds one solute.\nThis is the default model that is displayed when the software is initialized.\nThe parameters and state figures associated with this model are shown in\nFigure 4.6.\nSimple, six state: refers to the simple, six-state carrier that binds two solutes\nshown in Figure 4.7.\nGeneral, four-state: refers to the general, four-state carrier that binds one solute\nshown in Figure 4.8.\n\n4.4. USER'S GUIDE\nFigure 4.6: Parameters and state\nfigures for the simple, four-state\ncarrier model that binds one so\nlute.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.7: Parameters and state\nfigures for the simple, six-state\ncarrier that binds two solutes.\n\n4.4. USER'S GUIDE\nFigure 4.8: Parameters and state\nfigures for the general, four-state\ncarrier that binds one solute.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nSimple\nSimple\nGeneral\nfour state\nsix state\nfour state\nTotal carrier density\nNET\nNET\nNET\nRate constants\nτE , αE ,\nτE , αE , τES , αES , ai, ao, bi, bo\nSolute concentrations\nDissociation constants\nτES , αES\nci\nS , co\nS\nKi\nS , Ko\nS\nτER, αER\nci\nS , co\nS , ci\nR, co\nR\nKi\nS , Ko\nS , Ki\nR , Ko\nR\ngi, go, hi, ho\nci\nS , co\nS\nTable 4.1: Modifiable parameters of the carrier models -- the independent variables.\n4.4.3 Steady-state interactive analysis\nInteractive, steady-state analysis involves two figures -- the parameters and the\nstate figures. Any parameter (independent variable) can be changed in the pa\nrameters figure and the resulting changes in the steady-state values of the car\nrier state densities and carrier fluxes (dependent variables) are displayed in the\nstate figure. The parameters for all three carrier models are listed in Table 4.1.\nIn both the parameters and state figures, clicking on any variable (parameter,\ncarrier density, or carrier flux) displays information about that variable in the\nmessage window of the figure.\nParameters\nThe numerical value of each parameter is displayed in the button located either\nabove or below each parameter. Parameter values can be changed en masse by\nclicking the appropriate buttons in the lower right part of the parameters figure.\nParameters can be restored to their default values or read from a file. Parameters\nmay also be saved to a file.\nParameters may be changed individually in three ways.\nA value may be changed arbitrarily by clicking on the button for each pa\n-\nrameter. The button is changed to a text-edit box which allows editing the\nparameter value. After typing RETURN, the new values of carrier densities\nand carrier fluxes are computed and displayed in the state figure. A non\nnumeric entry or a negative entry is not accepted and the prior value is\nrestored.\nA parameter, selected by clicking on its button, may be incremented or\n-\ndecremented by clicking on + or - in the lower left of the parameters fig\nure. The magnitude of the increment can be selected by typing in the text\n\n4.4. USER'S GUIDE\nedit box in the lower left part of the parameters figure. The state figure is\nupdated with each incremental change in the parameter.\nA parameter, selected by clicking on its button, may be incremented or\n-\ndecremented repeatedly by clicking on the repeat button to the right of the\n+ or to the left of the -, respectively. The state figure is updated with each\nincremental change in the parameter. Clicking on the repeat button again\nstops the repetitive process.\nIn the general, four-state carrier, passive transport of solute (also called the\nprinciple of detailed balance) requires that (Weiss, 1996a)\naihobogi = aohibigo.\nWhen this condition is violated, a warning messages is displayed in the message\nwindow of the parameters figure, and the ratio\naohibigo\nr = aihobogi\nis displayed.\nState\nThe steady-state values of carrier densities and carrier fluxes are displayed below\neach quantity for the particular set of parameters shown in the parameters figure.\nThese quantities are also displayed graphically. Carrier densities are displayed\nwith bar graphs that represent the relative densities of carrier in each states. Both\ni\nE , nES , and no\nfour-state carriers display nE\ni , no\nES . The six-state carrier displays nE\ni ,\nno\ni\nE , nES , no\ni\nES , nER , and no\nER . The carrier fluxes are displayed with thick arrows\nin the center of the figure. No arrow is displayed when the flux is zero . The\ndirection of the arrow indicates the direction of the flux. The color of the arrow\nindicates the relative magnitude of the carrier flux; a small magnitude flux has a\nblack arrow, a large magnitude flux has a bright red arrow.\n4.4.4 Steady-state graphic analysis\nSelection of graphic analysis in the controls figure, displays the steady-state\ngraphic analysis figure (Figure 4.9). This figure allows the user to plot any vari\nable versus any of the parameters of the carrier-mediated transport model. Use\nof this figure is described in detail in Chapter 1. The variables are listed as: flux E\ni\nS .\nfor E , flux ES for ES , n E i for nE , . . . , efflux S for\n≤\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.9: The steady-state graphic analysis figure showing a plot of fluxes and carrier\ndensities versus c\non linear ordinate and abscissa scales.\ni\nS\n\n4.4. USER'S GUIDE\nFigure 4.10: The transient analysis figure showing the transient response to the change\nin parameters shown in Figure 4.11 and using the numerical data shown in Figure 4.12.\n4.4.5 Transient analysis\nTransient analysis is available only for the generalized, four-state carrier by click\ning on transient in the controls figure. This action displays the transient analysis\nfigure (Figure 4.10). Use of the transient analysis figure is described in detail in\nChapter 1. Differences occur only in the control of transient analysis panel shown\nin the upper left panel of the figure. We describe this panel only.\nSet up transients. Clicking on this item displays the set up transients figure shown\nin Figure 4.11. The first column of this figure shows all the 11 independent\nvariables for the general, four-state carrier. The initial values are shown in\nthe second column and the final values are shown in the fourth column.\nThe initial values can be changed individually by typing in the new value\nin the appropriate text edit box. The third column gives several options\nfor changing any particular variable. Several independent variables can be\nchanged. Clicking on Done terminates selection of variables to be changed.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.11: The set up transients figure.\n\n4.5. PROBLEMS\nFigure 4.12: The transient nu\nmerics figure.\nThe bottom of the figure gives several additional options for changing vari\nables that are explained by positioning the mouse cursor over the option.\nGraph n's. Clicking on this item displays the carrier densities as a function of\ntime.\nNumerics. Clicking on this item displays the transient numerics figure which\ngives information to the user and allows for control of the time scale of\nthe transient response (Figure 4.12). The transient numerics figure displays\nthe eigenvalues of the transient response at the top. These eigenvalues can\nbe computed for the initial or the final values of all parameters by clicking\non the appropriate button in this figure. The final value of the time in the\nplot is determined by the information in the maximum time for transient\nresponse panel.\nAbsolute scale. Selecting this item displays plots of all carrier densities on the\nsame absolute scale.\nRelative scale. Selecting this item displays plots of all carrier densities on indi\nvidual scales so that all the carrier densities are discernible.\nClear plotting axes. Selecting this item clears the plot field.\n4.5 Problems\nProblem 4.1 This problem is intended to develop your intuition for the steady-\nstate behavior of the simple, four-state carrier model for a single solute. You will\nobserve the effects of changes in parameters on both the flux and the carrier den\nsities. Use the simple, four-state carrier model and start with all the parameters\nat their default values.\na. What is the relation of S and E ? Explain.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nb. What is the relation of the direction of S to the sign of cS - co\ni\nS ? Explain.\nc. How does the state of the carrier depend on solute concentration?\ni\ni\ni. Do changes in cS change nES\ni\nand nE ? If so, how? If not, why not?\nii. Do changes in cS change no\nE ? If so, how? If not, why not?\ni\nES and no\nS change nES\ni\nand nE ? If so, how? If not, why not?\niii. Do changes in co\ni\niv. Do changes in co\nES and no\nS change no\nE ? If so, how? If not, why not?\nReset all the parameters to their default values, except set τES\n100 s-1.\n=\nd. What is the relation of the direction of S to the sign of cS - co\ni\nS ? Explain.\nReset all the parameters to their default values, except set τE\nαE\n0 s-1.\n=\n=\ne. What is the relation of S to cS - co\ni\nS ? Explain.\nProblem 4.2 This problem is designed to explore the functional relation between\nflux and solute concentration when expressed in different coordinates. Use the\nsimple, four-state carrier model and start with all the parameters at their default\nvalues, except set co\n0. In parts a through c your job is to estimate the values\nS =\nof (S)max and Ki from the graphs specified, where (S)max is the maximum\nS\nflux of S with co\n0.\nS =\ni\na. Obtain a graph of S versus cS in linear coordinates.\ni\nb. Obtain a graph of S versus cS in double logarithmic coordinates.\nc. Obtain a graph of 1/S versus 1/ci\nS .\nd. Determine the values of (S)max and Ki\nS from the model parameters.\ne. Compare the 4 sets of values you have obtained for (S)max and Ki\nS .\nProblem 4.3 Use the simple, four-state carrier model and start with all the pa\nrameters at their default values, except set co\n0. Obtain a graph of all four\nS\ni\n=\ncarrier states as a function of cS . Some of the these n's increase, others de\ncrease, while others remain constant. Summarize and explain the results you\nfound.\nProblem 4.4 Use the simple, six-state carrier model and start with all the param\neters at their default values. Set the solute concentrations of S and R to zero on\nboth sides of the membrane.\na. Explain the initial carrier states and flux values.\n\n4.5. PROBLEMS\ni\nb. Increase cS and observe both the carrier states and the flux. What is the\ni\nrelation of the flux of S to cS ?\ni\ni\nc. Now set cS\n10 and increase cR. How do the fluxes of S and R depend\ni\n=\nupon cR?\ni\ni\nd. Set cS\n10 and co\n5. Now increase cR from an initial value of 0. How\nS\n=\n=\ni\ndo the fluxes of S and R depend upon cR? Pay particular attention to the\ndirection of the flux of S.\nProblem 4.5 The transient response shown in Figure 4.10 appears to show that\nthe carrier densities change discontinuously at t\n0 in response to the change\n=\nin parameter shown in Figure 4.11. Reproduce this result.\na. On the basis of the theoretical development given in Section 4.2, can the car\nrier densities change discontinuously in response to a discontinuous change\nin any of the parameters? Explain.\nb. By experimenting with the transient response, explain the results shown in\nFigure 4.10. Make your explanation as quantitative as possible.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\n\nChapter 5\nHODGKIN-HUXLEY MODEL\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n5.1 Introduction\n5.1.1 Background\nElectrically excitable cells produce action potentials which are important for\ntransmission of information in neurons, for contraction of muscle cells, and for\nsecretion of chemical substances by neurosecretory cells (Aidley, 1989; Hodgkin,\n1964; Katz, 1966; Kandel et al., 1991; Keynes and Aidley, 1991; Nicholls et al.,\n1992; Weiss, 1996b). The macroscopic mechanisms of production of action po\ntentials can be understood in terms of the nonlinear electrical characteristics of\ncellular membranes first described by Hodgkin and Huxley for the membrane\nof the giant axon of the squid (Hodgkin and Huxley, 1952). Since the nonlinear\nproperties of the membranes of electrically excitable cells are controlled by the\nmembrane potential, it is relatively simple to understand these mechanisms when\nthe membrane potential is constant, but vastly more difficult when the membrane\npotential is not constant such as occurs during an action potential. Of course,\nit is the properties of electrically-excitable cells under the latter conditions that\nare the most important for the function of these cells.\n5.1.2 Overview of the software\nThe purpose of this software is to allow users to enhance their comprehension\nof the Hodgkin-Huxley model by providing a complete simulation of the model\nunder space clamped conditions. Any of the parameters of the Hodgkin-Huxley\nmodel can be changed by the user and simulation experiments can be done to\nexamine the consequences of the parameter changes. Extensive graphics utilities\nallow the user to plot any variable versus any other variable in the model. Since\nthe model is built on a block diagram language (SIMULINK), the user can also\nmake changes in the model structure.\n5.2 Description Of The Model\nDescriptions of the Hodgkin-Huxley model are available elsewhere (Aidley, 1989;\nHodgkin, 1964; Katz, 1966; Plonsey and Barr, 1988; Johnston and Wu, 1995;\nWeiss, 1996b). A summary of this model is given in this section. The model\nthat is the basis of this software is a one-compartment model that represents a\nspace-clamped axon stimulated by means of two electrodes so that the membrane\ncurrent density and membrane potential are uniform along the length of the axon.\n\n5.2. DESCRIPTION OF THE MODEL\n+\n-\nJm(t)\nVm(t)\nJm(t)\nFigure 5.1: Schematic di\nagram and circuit model\nJC\n-\n+\n-\n+\n-\n+\n-\nJK\nJNa\nJL\nGK(Vm, t)\nGNa(Vm, t)\nGL\nVK\nVNa\nVL\nof a space-clamped axon\nin the voltage-clamp con\nfiguration.\n+\nCm\nVm(t)\n+\n-\nJm(t)\nVm(t)\n+\n-\nVm(t)\n+\n-\n+\n-\n+\n-\nJK\nJNa\nJL\nGK(Vm, t)\nGNa(Vm, t)\nGL\nVK\nVNa\nVL\nFigure 5.2: Schematic di-\nJC\nagram and circuit model\nof a space-clamped axon\nin the current-clamp con-\nJm(t)\nfiguration.\nCm\n5.2.1 Voltage-clamp and current-clamp configurations\nTwo simple and mutually exclusive stimulus configurations can be used to in\nvestigate the model: the voltage-clamp and current-clamp configurations. In the\nvoltage-clamp configuration (Figure 5.1), the simulated space-clamped axon is\ndriven by a voltage source and the membrane current density is computed. In\nthe current-clamp configuration, the simulated space-clamped axon is driven by\na current source and the membrane potential is computed.\n5.2.2 The membrane current density components\nThe total membrane current density, Jm, is the sum of the capacitance current\ndensity plus the ionic current density\nJm = JC + Jion,\n(5.1)\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nwhere the capacitance current density is\ndVm(t)\n(5.2)\nJC\nCm\ndt\n,\n=\nand Vm is the membrane potential. The ionic current density can be expressed\nin terms of its components\nJion = JNa + JK + JL,\n(5.3)\nwhere the ionic current densities due to sodium, potassium and leakage are\nJNa\nGNa(Vm, t)(Vm(t) - VNa),\n(5.4)\n=\nJK\nGK(Vm, t)(Vm(t) - VK),\n(5.5)\n=\nJL\nGL(Vm(t) - VL),\n(5.6)\n=\nand where the Nernst equilibrium potential for the nth ion is defined in terms of\nthe concentrations as follows\n⎦\n\nRT\nco\nn\nVn = znF ln\ni\n,\n(5.7)\ncn\nwhere R is the molar gas constant, T is absolute temperature, F is Faraday's\nconstant, and zn, co and ci are the valence, outside, and inside concentrations\nn\nn\nof ion n, respectively. For a univalent ion, the Nernst equilibrium potential is\nexpressed as\n⎦\n\nco\nn\nVn = 0.08616 (Tc + 273.16) ln\n(mV),\n(5.8)\ni\ncn\nwhere Tc is the temperature in Centigrade.\n5.2.3 The membrane conductances\nThe sodium and potassium conductances are defined as\n\nGNa(Vm, t)\nGNam3(Vm, t)h(Vm, t),\n(5.9)\n=\n\nGK(Vm, t)\nGKn4(Vm, t).\n(5.10)\n=\n5.2.4 The activation and inactivation factors\nThe first-order kinetic equations for the activation and inactivation factors are\nwritten in terms of the rate constants as follows:\ndm\nτm - m(τm + αm),\n(5.11)\ndt\n=\ndh\nτh - h(τh + αh),\n(5.12)\ndt\n=\ndn\nτn - n(τn + αn),\n(5.13)\ndt\n=\nwhere the τ's and α's depend upon Vm.\n\n!\n!\n5.2. DESCRIPTION OF THE MODEL\n5.2.5 The rate constants\nThe dependence of the rate constants on membrane potential has been gener\nalized from the original Hodgkin-Huxley model to allow control of the potential\ndependence of individual rate constants and to represent approximately the ef\nfects of changes in calcium concentration and temperature.\nThe rate constants are\nτm\nαm\n=\n=\n-0.1(35 + Vm + VCa + Vτm)\ne-0.1(35+Vm+VCa+Vτm) - 1\nKT Km,\n4e-(Vm+VCa +Vαm +60)/18 KT Km,\n(5.14)\n(5.15)\nτh = 0.07e-0.05(Vm +VCa+Vτh+60) KT Kh,\n(5.16)\nαh\nτn\nαn\n=\n=\n=\n1 + e-0.1(Vm+VCa+Vαh+30) KT Kh,\n-0.01(Vm + VCa + Vτn + 50)\ne-0.1(Vm +VCa+Vτn+50) - 1\nKT Kn,\n0.125e-0.0125(Vm +VCa+Vαn +60) KT Kn,\n(5.17)\n(5.18)\n(5.19)\nwhere KT is a temperature factor, that is defined as\n3(T c -6.3)/10\nKT\n.\n(5.20)\n=\nKT multiplies all the rate constants; this effect approximates the effect of tem\nperature on the electrical properties of the membrane of the squid giant axon\n(Huxley, 1959). The factors Km, Kh and Kn have been added to the original\nHodgkin-Huxley model to allow changes to be made in the individual rate con\nstants of m, h, and n. The factor VCa is used to approximate the dependence\nof rate constants on calcium concentration and is\nco\nVCa = 0.03335 (Tc + 273.16) ln\nCa\n- 12.995\n(mV).\n(5.21)\ni\ncCa\nAt the normal calcium concentration, the potential VCa has the value 0. For cal\ncium concentration ratios that differ from the normal value, VCa differs from 0\nand the dependence of the rate constants on the membrane potential is shifted\nby a term that is proportional to the calcium equilibrium potential. This ap\nproximates the effect of a change in calcium concentration on the parameters of\nsquid giant axon membrane (Frankenhaeuser and Hodgkin, 1957). The potentials\nVτm, Vαm, Vτh, Vαh, Vτn, and Vαn have the value 0 in the original Hodgkin-Huxley\nmodel. These potentials can be used to shift the dependence of individual rate\nconstants on membrane potential.\n5.2.6 Time constants and equilibrium values of activation and\ninactivation factors\nEquations 5.11-5.13 are expressed in terms of rate factors, but it is also useful\nto express these equations in terms of time constants and equilibrium values, as\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nfollows\ndm\nm1 -m,\ndt\n=\nm\ndh\nh1 -h,\n(5.22)\ndt\n=\nh\ndn\nn1 -n.\ndt\n=\nn\nThe time constants and equilibrium values can be defined in terms of the rate\nconstants by comparing Equations 5.11-5.13 to Equation 5.22.\nτm\nm = τm + αm\nand\nm1\n= τm + αm\n,\nτh\nh = τh + αh\nand\nh1\n= τh + αh\n,\n(5.23)\nτn\nn\nand\nn\n.\n= τn + αn\n= τn + αn\n5.3 Numerical Methods\n5.3.1 Background\nIn order to compute the membrane potential for a given set of parameters, the\nequations describing the Hodgkin-Huxley model (listed in Section 5.2) must be\napproximated in a form that is appropriate for numerical solution on a digital\ncomputer. A variety of methods exist for the numerical integration of a set of\ncoupled differential equations (Press et al., 1986). The simplest method, called\nthe Euler method, is to approximate all derivatives by first differences, and to\nsolve the resulting collection of algebraic equations at a series of discrete times\nseparated by a time increment t. Although simple in concept, the Euler method\nis not a particularly accurate or efficient method. Because the Hodgkin-Huxley\nsoftware is built on MATLAB/SIMULINK which includes a variety of methods of\nnumerical integration, the user can choose the method of integration from a num\nber of choices. The default method of integration used in the Hodgkin-Huxley\nsimulation is called the fifth-order Runge-Kutta method.\n5.3.2 Choice of integration step t\nThe accuracy of all numerical methods is dependent on the choice of the integra\ntion step t. Simulation users will need to concern themselves with the choice of\nt. If t is decreased, the accuracy of a single step increases but the time it takes\nto compute the solution increases. Furthermore, if computations are continued\nfor a large number of steps, the accumulation of round-off errors, due to the lim\nited precision for representing numbers in a computer, can become appreciable.\n\n5.3. NUMERICAL METHODS\nConversely, if t is increased, the accuracy of the computation decreases and\nthe solution may even diverge. This divergence can lead to spurious phenomena\nthat may mistakenly be attributed to the Hodgkin-Huxley model when they are\nreally artifacts of the numerical methods. A plausible empirical test of whether\nor not a solution is sufficiently accurate is to test the sensitivity of the solution\nto changes in t. If increasing the value of t does not appreciably change the\nsolution, then the value of t used initially is too small and time was wasted\nin performing the computation. If decreasing the value of t does not appre\nciably change the computational result, then the larger value is preferable. The\nsimulation of the Hodgkin-Huxley model is set initially with default numerical pa\nrameters. For changes in parameters of the model that do not appreciably change\nthe various time constants of the model, the default numerical parameters are\nadequate. However, if changing a model parameter (such as the temperature,\nmembrane capacitance, etc.) appreciably decreases some time constant of the\nsystem, then a smaller value of t should be used. Therefore, it is advisable to\nexplore briefly the effects of varying t on simulation results.\n5.3.3 Method for computing solutions\nIn the voltage clamp simulation, the solution is obtained as follows: Suppose the\nsolution is known at time tp - t and the solution at time tp is desired. The value\nof the membrane potential Vm(tp) at tp is determined from specification of the\nstimulus (see Equations 5.24 and 5.25 on Page 97). This value is substituted into\nEquations 5.14 and 5.19 to determine the rate constants at tp . Using these rate\nconstants, and given the values of m, h, and n at time tp - t, the values of m,\nh, and n are determined at tp by solving Equations 5.11-5.13 by an integration\nmethod; the default method is the fifth-order Runge-Kutta method. The values\nof these factors are used to compute the values of the conductances and current\ndensities from Equations 5.1-5.6. The computation is begun with initial values of\nm, h, and n that are determined from Equation 5.23 for a membrane potential\nequal to the source voltage for t < 0.\nIn the current clamp simulation, the initial values of m, h, n, and Vm are\ncomputed first. This is done by using MATLAB's trim function to solve the set\nof Equations 5.1, 5.3-5.21 and a specification of the source current (Equation 5.24\non Page 97) with the derivatives of all the variables set to zero. Starting with these\ninitial values, the time-varying equations are solved numerically by an integration\nmethod that can be chosen by the user. The default method is the fifth-order\nRunge-Kutta method.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.3: The controls figure af\nter the software is initiated.\n5.4 User's Guide To The Software\nWhen this software is selected, 3 figures are displayed (in addition to MATLAB's\ncommand window): controls, parameters, stimulus. The controls figure controls\nthe software (Figure 5.3). The parameters figure allows the user to change any\nof the parameters of the model. The stimulus figure allows the user to specify\nthe stimulus. Once the parameters and the stimulus are specified, selecting Start\nsimulation results in the computation of the response as a function of time. Upon\ncompletion of the computation, the software is in the analysis mode to allow the\nuser to examine the results graphically and numerically.\n5.4.1 Controls\nThe part of the controls figure (Figure 5.3) below the menubar is divided into six\npanels. The left side of the top panel allows the user to choose the model.1 The\nright side allows the user to choose between voltage-clamp and current-clamp\nconfigurations. In the next panel down, the simulation is started by clicking\non the button Start simulation. The setup panel allows the user to select the\nparameters figure (which is used to specify the parameters), the stimulus figure\n(which is used to specify the stimulus as a function of time), the numerics figure\n(which control the numerical methods and numerical parameters), and the block\ndiagram figure (which gives the user access to a block diagram of the system in\nthe SIMULINK language). The analysis panel becomes active after the simulation\nis completed and allows the user to select three options for analysis of the results.\nThe first option allows the user to plot any model variable as a function of time.\nThis figure is displayed automatically at the completion of a simulation. The\nsecond option displays a numerical summary of simulation results. The third\noption allows the user to access a quite general plotting facility that not only\nplots any of the model variables versus any other model variable, but allows\nplotting results stored in files. The message panel is used to send messages to\n1At the present time only the default HH model is available.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.4: The controls figure af\nter the software is initiated.\nthe user. The log panel contains options for recording log entries of the session\nand is described in Chapter 1.\n5.4.2 Setup\nParameters\nSelecting parameters in the controls figure displays the Parameters figure (Fig\nure 5.4) which is used to view parameters and to change parameters.\nChanging parameter values. The Parameters figure contains three columns for\neach parameter: the first column identifies the parameter, the second gives its\ndefault value, and the third column shows the value of the parameter if it is\nmodified from its default value. Clicking on the parameter name displays the\ndefinition as well as the units of the parameter in the message panel. Parameters\nare selected for modification by clicking the button in the third column of the\nparameter field. When a parameter is selected, its third column button will be\nreplaced by an edit box. Clicking any mouse button inside the edit box allows the\nparameter to be changed. The new value of the parameter is entered from the\nkeyboard; < RETURN > terminates the parameter entry. If the new value differs\nfrom the default value, then the new value will appear in the third column. With\nthis method of display, the parameter list can be scanned quickly to indicate\nwhich parameters differ from their default values.\nThere are some restrictions on the numerical values of parameters; G's 0,\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nCm 0, c's > 0, K's > 0, and the temperature must be above absolute zero. The\nderived parameters cannot be changed but are derived from the other parameters\nand are displayed for the convenience of the user. For example, the sodium\nequilibrium potential VNa cannot be changed directly by the user, but changes\nautomatically when the sodium concentrations or temperature are changed.\nReading and saving parameters in files. Near the bottom of the parameters\nfigure there are options that allow parameters to be read from a file or saved to\na file.\nViewing the voltage dependent parameters. The Hodgkin-Huxley model con\ntains several parameters that are instantaneous functions of the membrane po\ntential. Plots of parameters are available as a function of Vm for the following:\nτm(Vm), αm(Vm), m1(Vm), m(Vm), τh(Vm), αh(Vm), h1(Vm), h(Vm), τn(Vm),\nαn(Vm), n1(Vm), n(Vm). These can be accessed by clicking on Plot parame\nters versus voltage which displays a new figure (Figure 5.5). This figure makes\nuse of the graphics package described in Chapter 1 with a few differences that\nare described here. Since the independent variable for these plots is the mem\nbrane potential, only the dependent variables can be chosen by clicking on select\ny which displays the select y figure (Figure 5.6). The select y figure allows selec\ntion of multiple dependent variables which determine the ordinates of the plot.\nIdentification. The lower right-hand corner of the parameters figure contains\nroom for a text string of the user's choice. This is intended to identify the param\neters figure. The user might consider entering the date and time, a run number,\nor other identification. Clicking in that area displays a text edit box into which\nthe user types the identification.\nStimulus\nSelecting Stimulus in the controls figure displays the Stimulus figure as shown in\nFigure 5.7. The stimulus is the membrane potential in the voltage-clamp config\nuration and the membrane current density in the current-clamp configuration.\nUse of stimulus m-files. By default, the stimulus is generated by the MATLAB\nm-file hhstim.m which uses the parameters listed in the lower part of the stim\nulus figure. This specification of the stimulus is quite rich, as will become clear\nbelow. However, a user who wishes to define a stimulus that differs from the one\nprovided can write a MATLAB m-file to generate that stimulus. That file can then\nbe selected in the stimulus figure, and the stimulus it generates will be displayed\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.5: The parameters versus membrane potential figure after selection of param\neters as in Figure 5.6.\nFigure 5.6: The select y figure that was used\nto produce the plot shown in Figure 5.5.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.7: Stimulus figure with the default stimulus waveform for a current-clamp\nconfiguration.\n\n>\n<\n>\n:\n5.4. USER'S GUIDE TO THE SOFTWARE\nin the stimulus figure. The script for the available m-files can be used to define\nnew user-specified m-files.\nUse of the m-file hhstim.m The default m-file, hhstim.m, uses the numerical\nparameters in the stimulus figure. The stimulus is the sum of a constant plus\ntwo independently specifiable pulses. Each pulse can be a rectangular pulse, a\nramp pulse or an exponential pulse or a combination of these. If the slope and\nthe time constant are set to zero, then the remaining parameters specify the\namplitude, duration and onset time of a rectangular pulse. If the slope has a\nnon-zero value, a ramp of that slope is added to the rectangular pulse for the\nduration of the pulse. Similarly, if the time constant has a non-zero value, then\nan exponential pulse with the selected time constant is added to the waveform.\nThe time constant can be positive or negative.\nThe stimulus, s(t), is defined as follows\ns(t) = so + s1(t) + s2(t),\n(5.24)\nwhere so is a constant and s1(t) and s2(t) are independently specifiable pulses.\nEach pulse has the form\ns i(t) =\no) + Aie-(t-ti\nmi(t - ti\no)/i\nif to\nt\n←\n← to + tdur,\n(5.25)\notherwise,\nwhere pulse i (i\n1 or 2) starts at to and has a duration tdur . The amplitude of\n=\nthe pulse is Ai , the slope is mi , and the time constant is i . With this specification,\na rich variety of stimuli can be produced; an example is shown in Figure 5.8.\nThe stimulus parameters can be read from or saved to a file by selecting the\nappropriate button at the bottom of the stimulus figure.\nIdentification. The upper right-hand corner of the stimulus figure also contains\nroom for a text string of the user's choice for identifying the stimulus. This works\nidentically to the identification of the parameters figure.\nNumerics\nSelecting Numerics in the controls figure displays the numerics figure (Figure 5.9).\nThis figure allows selection of the numerical method used to solve the ordinary\ndifferential equations (or ode solver) as well as the numerical parameters of the\nsimulation. The dialog-box that appears at the top allows direct selection of\none of seven ode solvers: Euler, Third Order Runge-Kutta, Fifth Order Runge-\nKutta, Adams, Gear, a hybrid Adams/Gear, Linsim. The MATLAB manuals or\nMATLAB's help facility should be consulted for further information about these\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.8: Example of a stimulus current waveform consisting of a constant plus two\npulses: the first pulse is a ramp plus rectangular pulse; the second is an exponential\npulse.\nFigure 5.9: The numerics fig\nure.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nmethods. More detailed descriptions are available elsewhere (Shampine and Re\nichelt, 1997). By default, the software uses the fifth-order Runge-Kutta method of\nintegration with a variable integration step size (t). The integration methods re\nquire that the following parameters be defined: Minimum step-size, Maximum\nstep-size, Tolerance. The tolerance is an estimate of the accuracy of the so\nlution, i.e., a tolerance of 0.001 implies that the error in the solution is less than\n0.1% of the correct value. Decreasing the tolerance will increase the accuracy of\nthe solution, but will increase the computation time.\nBlock diagram\nThe Hodgkin-Huxley model is simulated in SIMULINK which is a block diagram\nlanguage addition to MATLAB. The model simulation consists of a nested set\nof block diagrams.2 Although the software can be run without reference to the\nblock diagram, convenient access to the block diagram has been provided for\nthe interested user. Since the block diagrams are easily edited, the user has the\noption of modifying many aspects of the model. However, modification of the\nblock diagrams should be done with some caution.\nSelecting Block diagram in the controls figure results in the display of the\nblock diagram shown in Figure 5.10. Double clicking on the block labelled Cur\nrent clamped displays a block diagram of this block as shown in Figure 5.11.\nEach of the blocks in Figure 5.11 can be double-clicked and each of the resulting\nblock diagrams can also be revealed by double clicking. In addition, the controls,\nparameters, and stimulus figures can be accessed from this block diagram by\ndouble clicking on the appropriate block.\nAn example of customization of the software. A simple example of the usage\nof SIMULINK to customize the software is described here. Suppose for a par\nticular investigation of the model, it is desirable to plot some variable (e.g., the\nsodium conductance) in the Hodgkin-Huxley model as a function of time during\nthe simulation. This is easily done with SIMULINK. Double clicking on the G(V )\nblock in Figure 5.11 displays a block diagram of the conductance computation.\nTo obtain a plot of the sodium conductance during a computation, an oscillo\nscope is attached to the sodium conductance. Typing simulink in the MATLAB\ncommand window displays the SIMULINK elements (Figure 5.12). Double clicking\non sinks displays the sinks available in SIMULINK which includes an oscilloscope\nor Scope (Figure 5.13). To attach the oscilloscope to the sodium conductance,\nclick on the oscilloscope and drag the oscilloscope to the appropriate place in\nthe block diagram and connect it to the sodium conductance by clicking and\n2It is important to keep in mind that the block diagrams in SIMULINK reflect not just the flow\nof signals in the Hodgkin-Huxley model, but some of the idiosyncratic properties of linking the\nblock diagram description to MATLAB.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.10: The block diagram figure after the block diagram option is selected in the\ncontrols figure. This block diagram is for the current-clamp configuration.\nFigure 5.11: Expansion of the current clamped block in Figure 5.10.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.12:\nThe simulink\nfigure obtained by typing\nsimulink at the MATLAB\nprompt.\nFigure 5.13: The sink figure obtained after double clicking\non sinks in the simulink figure (Figure 5.12).\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.14: Block diagram with oscilloscope attached to the sodium conductance signal.\nThis block diagram is obtained by double clicking on the G(V ) block in Figure 5.11.\ndragging between the terminals. This results in a new block diagram with the os\ncilloscope attached as shown in Figure 5.14. Double clicking on the oscilloscope\ndisplays the oscilloscope screen (Figure 5.15). The horizontal and vertical gains\nmust be specified by the user. Starting the simulation now displays the sodium\nconductance on the oscilloscope screen as the computation proceeds.\n5.4.3 Analysis\nThe software provides one numeric and two graphic displays of simulation re\nsults. These three displays are selected and deselected in the controls figure.\nAnalysis is available after a simulation has been run if the parameters have not\nbeen changed after the simulation was run.\nPlots versus time\nSelecting this item in the controls figure displays the plots versus time figure as\nshown in Figure 5.16. This figure provides a simple and rapid means of plot\nting any of the simulation variables versus time on fixed scales. The variable\nis selected by clicking on the dropdown menu at the top of the figure and then\ndragging the mouse to the variable of interest.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.15: The oscilloscope screen showing\na plot of the sodium conductance which is dis\nplayed as the computation proceeds.\nFigure 5.16: The plot\nversus\ntime\nfigure\nwith Vm chosen for\nplotting.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.17: The variable summary figure af\nter the simulation has been completed using\nthe default parameters for a current-clamp\nconfiguration.\nVariable summary\nSelecting this item in the controls figure displays the variable summary figure\nas shown in Figure 5.17. This figure contains four columns of text. The first\ncolumn identifies the simulation variable. The second contains the initial value of\nthe variable. The third and fourth columns contain the minimum and maximum\nvalues of the variables during the course of the simulation.\nComparison\nSelecting this item in the controls figure displays the comparison figure as shown\nin Figure 5.18. This flexible graphic resource is described more fully in Chapter 1.\nBriefly, this figure allows plotting any result of the simulation against any other\nin coordinates chosen by the user. Several dependent variables can be plotted\nsimultaneously. In addition, results saved in files can be plotted so that results\nfor different parameters can be compared. In addition, results of consecutive\nsimulations can be overlayed. We give a few examples of the types of graphics\nthat are readily available with this resource.\nAs shown in Figure 5.19, parametric plots of one variable versus another with\ntime as the parameter are easily obtained. Figure 5.20 shows the membrane\npotential obtained at several different temperatures. This figure was obtained by\noverlaying successive computations. It could also have been created by saving\nthe results of simulations performed for different temperatures in files and then\nplotting the results from these files.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.18: Comparison figure showing the membrane potential and ionic conduc\ntance obtained from a simulation with model parameters and the stimulus defined in\nFigures 5.4 and 5.7.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.19: Phase-plane plot of membrane conductances versus membrane potential\nduring an action potential. All the parameters were the default parameters shown in\nFigure 5.4 and the stimulus was the same as shown in Figure 5.7 except that the duration\nwas increased to 20 ms.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.20: Membrane potential obtained at different temperatures. All the parameters\nwere the default parameters shown in Figure 5.4 except for the temperature and the\nstimulus was the same as shown in Figure 5.7.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n5.4.4 Scripting\nAs mentioned in the Introductory chapter, some of the software packages lend\nthemselves to user written scripts that automate a sequence of computations.\nThe following is an example of a script used to perform current clamp simulations\nat different temperatures.\n%A Hodgkin-Huxley script demonstration\n%(contents are in HHDEMO1.M)\n%This script can be used to generate simulation data using the\n%current-clamped configuration.\nThe temperature is varied while\n%all other parameters remain unchanged.\n%With each setting of the temperature, the simulation is run\n%and the resulting data are saved to data files which can then be\n%used to display the results in the Comparison figure.\n%Before using the script, make sure that the Hodgkin-Huxley\n%biophysics software has been started.\n%If it hasn't been started, start the software using SOFTCELL.M\n%\nsoftcell('hh');\n%hhscr('set') will list the parameters that can be changed\n%The parameter names are case-sensitive, so make sure that\n%you type them exactly as shown.\n%Insure that the current clamped configuration is being used.\nhhscr('set','Configuration','Current clamped');\n%Since a lot of files will be created, it is best to store\n%them in a separate folder.\nfoldername = pwd;\n%Examples of foldername are\n%foldername = 'C:\\data\\temp';\n%foldername = '/user/tsb/data/temp';\n%Make sure that a separator character ends the pathname\npathname = tfname(foldername);\n%Set up a loop that samples through a temperature range.\n%In this case, we use the range T = [0 10 20 30] Celsius\nfor temp = 0:10:30\n\n5.5. PROBLEMS\n%set the model's temperature parameter\nnewtemp = hhscr('set','T_C',temp);\n%perform simulation\nhhscr('start');\n%give yourself a note: indicate in the console what the\n%settings are\ndisp(['Temperature is set to ' num2str(newtemp)]);\n%create a unique filename that contains the simulation data\nfilename = ['temp' num2str(temp) '.mat'];\n%save the simulation data to the file\nhhscr('save','simulation',filename,pathname);\nend\n%That's it -- all the data have been saved.\n%Now, put up all the data simultaneously by following these steps:\n%1. call up the \"Comparison plots\" figure,\n%2. insure that the \"Use data files\" radiobutton is on,\n%3. using \"Select x,y\", select whichever variable(s) to plot,\n%4. use \"Graph x,y\" in the \"Comparison plots\" figure to view all\n%\nthe data.\n5.5 Problems\nProblem 5.1 Use the default parameters of the Hodgkin-Huxley model under\nvoltage-clamp conditions to complete the following problems. You may change\nonly the stimulus parameters.\na. The potassium conductance\ni. Find the amplitude and duration of a rectangular pulse of membrane\npotential such that the potassium conductance reaches its final of\nGK(Vm, 1) = 9 ± 0.2 mS/cm2.\nii. What is the value of the time constant of n, n, during this pulse?\nb. The sodium conductance\ni. Find the amplitude and duration of a rectangular pulse of membrane\npotential such that the peak sodium conductance is 15 ± 0.2 mS/cm2.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nMake sure that the pulse duration is sufficient so that there is a peak\nin the sodium conductance before the pulse terminates.\nii. What are the values of m and h at the time of the peak value of the\nsodium conductance?\niii. Increase the amplitude of the pulse 20 mV from the value you found\nabove and determine the peak sodium conductance and the values of\nm and h at the time of the peak value of the sodium conductance.\niv. Decrease the amplitude of the pulse 20 mV from the value you found\nabove and determine the peak sodium conductance and the values of\nm and h at the time of the peak value of the sodium conductance.\nProblem 5.2 This problem deals with the differences in time dependence of the\n[in]activation factors in voltage-clamp and current-clamp experiments.\na. Run the simulation in the voltage-clamp configuration using the default\nparameters, except delay the onset of the pulse of voltage by 1 ms to make\nthe on and off transients more readily visible. Examine the results of the\nsimulation and answer the following questions.\ni. Describe and explain the dependence on time of m, m1, and m.\nii. Describe and explain the dependence on time of h, h1, and h.\niii. Describe and explain the dependence on time of n, n1, and n.\niv. Plot the voltage dependence of m, h, n, m1, h1, and n . Check the\nnumerical values of these variables against those obtained in parts i,\nii, and iv.\nb. Run the simulation in the current-clamp configuration using the default\nparameters. Examine the results of the simulation and answer the following\nquestions.\ni. Describe and explain the dependence on time of m, m1, and m.\nii. Describe and explain the dependence on time of h, h1, and h.\niii. Describe and explain the dependence on time of n, n1, and n.\nc. Succinctly summarize the differences in the time dependence of all these\nvariables in voltage-clamp and current-clamp configurations.\nProblem 5.3 In this problem we illustrate another useful aspect of performing\nsimulation experiments on the model; the model can be used to test ideas con\ncerning proposed measurements on cells.\nAssume that the membrane of neuron X has voltage-current characteristics\nas described by the Hodgkin-Huxley model except that the voltage dependences\n\n1.\n5.5. PROBLEMS\nof the parameters of the factors n, m, and h are unknown. In this problem you\nare asked to develop methods to estimate the voltage dependence of some of\nthese parameters and to assess the accuracy of your methods. To make the sim\nulations realistic, in all parts of the problem you may only change the following\nparameters: the concentrations of sodium, potassium, and calcium either inside\nor outside the cell, and the temperature. You may use either voltage-clamp exper\niments or current clamp experiments. You can choose any stimulus waveform\nthat you can construct with the simulation. However, you must base your estima\ntion method on the membrane current in voltage clamp experiments and/or on\nthe membrane potential in current-clamp experiments. For example, you cannot\nbase your estimation method on a direct measurement of m(t).\na. Develop a method to estimate the voltage dependence of m1. Use the sim\nulation to assess the accuracy of your method by comparing the results of\nyour estimation of m1 with a direct computation of m\nb. Develop a method to estimate the voltage dependence of h . Use the sim\nulation to assess the accuracy of your method as in part a.\nProblem 5.4 By changing the amplitude of the stimulus pulse, while keeping all\nother parameters at their default values, determine the threshold of the action\npotential to a precision of 4 significant digits.\na. Describe the changes in action potential waveform as a function of current\namplitude.\nb. Does the change in waveform of the action potential as a function of stim\nulus amplitude violate the all-or-none principal? Explain.\nc. Investigate the basis of the change in waveform of the action potential by\nexamining the behavior of variables in addition to the membrane potential\nas the current amplitude is varied.\nProblem 5.5 Examine the refractory properties of the model by applying two\ncurrent pulses, each of amplitude 30 μA/cm2 and duration 0.5 ms and separated\nby 12 ms in time. Set the simulation duration to 20 ms. Run the simulation. You\nshould observe two action potentials. Reduce the inter-pulse interval to 10 ms.\nWhat happens? Now change the amplitude of the second pulse to 50 μA/cm2\nand observe the response. Change the inter-pulse interval to 5 ms and observe\nthe outcome.\na. Have you observed properties of the absolute or the relative refractory pe\nriod?\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nb. By examining the behavior of the factors m, n, and h during these two-\npulse simulations, determine which of these factors are most influential in\nrefractory properties.\nProblem 5.6 Observe the phenomena of repetitive activity and depolarization\nblock by performing a sequence of simulations with the following parameters.\nUse a single current pulse of duration 40 ms, a simulation duration of 50 ms,\nand stimulus amplitudes of 10, 25, 50, 100, and 200 μA/cm2.\na. Note that both the number of action potentials and their amplitudes vary\nwith the current amplitude. Sketch the relation between the number of\naction potentials and current amplitude and between action potential am\nplitude and current amplitude.\nb. By examining the behavior of the factors m, n, and h determine which of\nthese factors are most influential in determining repetitive activity. Explain\nyour reasoning.\nProblem 5.7 The phenomenon of anode-break excitation can be demonstrated\nby applying a pulse of current of duration 20 ms and amplitude -20 μA/cm2.\nUse a simulation duration of 40 ms.\na. Why is this phenomenon called anode-break excitation?\nb. By exploring the model variables explain this phenomenon.\nProblem 5.8 The phenomenon of accommodation can be illustrated by applying\na ramp of current of slope 0.4 μA/(cm2 ms) starting at an amplitude of 0 for a\n·\nduration of 6 seconds (also set the simulation duration to 6 seconds). The model\n\ndoes not show accommodation for the default value of GNa\n120 mS/cm2 but\n=\ndoes for a value of 80 mS/cm2. When the simulation is completed, plot the\nsodium, potassium and membrane current versus the membrane potential.\na. Perhaps no action potential has occurred in response to the ramp of cur\nrent because the reduced value of the sodium conductance prevents action\npotential from being generated for any stimulus. Test this hypothesis.\nb. Explain the underlying basis of accommodation.\nc. What does the phenomenon of accommodation suggest about the notion of\nthe threshold for eliciting an action potential?\nProblem 5.9 Sub-threshold oscillations can be observed by using the default pa\nrameters with current pulses of 50 ms duration and simulation durations of 100\nms. Use current amplitudes of .01, .1, 1, 2, and 2.5 μA/cm2.\n\n5.5. PROBLEMS\na. Describe your observations.\nb. Can the response of the model to a step of current be represented by the\nresponse of a network consisting of a constant resistance in parallel with a\nconstant capacitance. Explain.\nc. If your answer to part b was no, then devise a current stimulus such that\nthe model's response will approximate that of a network consisting of a\nconstant resistance in parallel with a constant capacitance. Explain your\nmethod.\nProblem 5.10 Determine the threshold current amplitudes (to three significant\nfigures) for eliciting action potentials for current pulses of duration 0.01, 0.05,\n0.1, 0.5, 1, 2, 5, 10, and 20 ms.\na. How does the threshold depend on current duration for low durations?\nExplain this behavior.\nb. How does the threshold depend on current duration for long durations?\nExplain this behavior.\nProblem 5.11 The Hodgkin-Huxley model with the default parameters stimu\nlated by a pulse of membrane current of amplitude 20 μA/cm2 and of duration\n0.5 ms produces an action potential as shown in Figure 5.21. In each of the\nfollowing computations, one membrane parameter only differs from the default\nparameters, and for each of these computations no action potential occurs. The\nparameter changes are:\ni. A change in the temperature from 6.3 C to 35 C blocks the action potential\nas shown in Figure 5.21.\nii. A change in the maximum potassium conductance from 36 to 72 mS/cm2\nblocks the action potential. [Results not shown.]\niii. A change in the internal calcium concentration from 0.0001 to 0.0002 mmole/l\nblocks the action potential. [Results not shown.]\niv. A change in the membrane capacitance from 1 μF/cm2 to 20 μF/cm2 blocks\nthe action potential as shown in Figure 5.21.\nv. A change in the external calcium concentration from 44 mmole/l to 22\nmmole/l blocks the action potential. [Results not shown.]\nExamination of the results for the above computations (e.g., Figure 5.21) re\nveals that there is no large change in membrane potential, i.e., no action potential\nhas occurred. For each of the computations:\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.21: Results of simulation with all model parameters at their default val\nues except where indicated. The curve labelled default was obtained with the de\nfault parameters. The curve labeled temp35 was obtained with the temperature set\nto 35 C. The curve labeled cm20 was obtained with the membrane capacitance set to\n20 μF/cm2.\nCm =\n\n5.6. PROJECTS\na. Explain why no action potential occurred. You may wish to base your ex\nplanation on the results obtained with each of the above computations. For\nexample, you may wish to examine the membrane currents, conductances,\nand activation variables that occurred for each computation. You may also\nwish to perform additional computations using different model parameters.\nFor example, to see why no action potential occurs for a large temperature\nchange, it might be instructive to examine the effects produced by smaller\nchanges in temperature. Since for many of the parts of this problem, there\nare large changes in parameters you may wish to explore the role of the\nnumerical methods in arriving at the solutions.\nb. Determine a set of parameters so as to produce an action potential with a\nwaveform that is identical, except for a change in time scale and a change\nin resting potential, to the action potential obtained with the default pa\nrameters. However, for each of the above parts, you may not change the\nparameter that differs from its default value. For example, for computation\nin part i, you may not change the temperature. Your task is to change some\nother parameter or group of parameters such that the action potential is\nrestored. For computation in part ii, you may not change the maximum\npotassium conductance. For computations in parts iii and v, you may not\nchange either the internal or the external calcium concentration, etc. RE\nMEMBER -- the objective is not just to produce an action potential, that\nis too easy, but to obtain an action potential whose waveform is identi\ncal to that obtained with the default parameters. To determine whether\nor not the action potential is identical to that obtained with the default\nparameters, you can superimpose plots and/or look at the variables sum\nmary figures from the responses. You should use the computer as a tool\nto check your ideas and not as a substitute for thinking. You should avoid\na strictly trial-and-error approach. There are simply too many parameters\nin the Hodgkin-Huxley model for you to explore them all randomly. When\nyou have arrived at a satisfactory solution, print a hard copy of the model\nparameters figure showing the parameters you used to solve the problem\nand include this with your solution. Explain why your parameter change\nproduces the desired result. [HINT: simulations are not required to solve\nthese problems, but they are helpful for checking ideas quickly.]\n5.6 PROJECTS\nThe simulation software lends itself to more extensive study than that included\nin the Problems. These more extensive studies are called Projects and these are\ndescribed here.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n5.6.1 Practical considerations in the choice of a topic\nProjects can involve almost any of the properties of the Hodgkin-Huxley model.\nHowever, to avoid projects whose aims are vague (e.g., \"I would like to under\nstand how the Hodgkin-Huxley model works\") the proposed project should be in\nthe form of a specific and testable hypothesis. Projects that involve months of\ncomputation should obviously be avoided. Experience should indicate the dura\ntion required to run simulations of the Hodgkin-Huxley model. These durations\nshould be taken into account explicitly in planning a project. For example, any\nproject that involves measuring the threshold of occurrence of an action poten\ntial for many different parameter values is bound to be very time consuming,\nbecause determining the threshold for a single set of parameters itself involves\nmany computations. The task is to choose a physiological property of the ex\ncitation of the action potential that is of interest, and then to define a specific,\nfeasible project.\n5.6.2 Choice of topics\nTopics can involve comparing predictions of the Hodgkin-Huxley model with\nmeasurements on cells. For example, the effects of changes in sodium ion con\ncentration on the action potential have been measured (Hodgkin and Katz, 1949a;\nBaker et al., 1961). A project might involve reading the original papers that de\nscribe such measurements (some were made before the Hodgkin-Huxley model\nwas formulated), and testing the hypothesis that these measurements are (or\nare not) consistent with the Hodgkin-Huxley model. Similarly, a project might in\nvolve examining the effect of some pharmacological substance on measurements\nof the action potential and testing the hypothesis that the substance produces its\neffect by changing one or another parameter of the model. These projects will re\nquire some reading of original literature which is often difficult and usually time\nconsuming. However, such a project can lead to a very rewarding educational\nexperience. Alternatively, the project might involve a purely theoretical topic\nin which some property of the model is explained in terms of the underlying\nstructure of the model. This type of project does not necessarily involve reading\nthe original literature. To make the process of project definition more tangible,\nwe shall discuss one property of the Hodgkin-Huxley model of a space-clamped\naxon, the shape of the action potential, and suggest some appropriate projects\nbased on this property.\nBackground\nThe waveform of the action potential is different in different types of electrically-\nexcitable cells. As demonstrated in Figure 5.22, while the action potential wave\nform has a peak-to-peak amplitude of about 100 mV, the duration and time course\nvary greatly. It is also known that the action potential waveform of a cell can\n\n5.6. PROJECTS\n+50\nSquid giant\naxon\nElectric eel\nelectroplaque\n+50\n-50\n-50\n-100\n-100\nTime (ms)\nTime (ms)\n+50\nMembrane potential (mV)\nCat\nmotoneuron\nFrog sartorius\nmuscle fiber\n+50\n-50\n-50\n-100\nTime (ms)\n+50\n-50\n-100\n-100\n\nTime (ms)\n+50\n-50\n-100\nCat myelinated\nfiber\nSheep purkinje\nfiber\n0.5\n1.5\nTime (ms)\nTime (s)\nFigure 5.22: Examples of action potentials measured in a variety of cell types (Keynes\nand Aidley, 1991, adapted from Figure 2.4).\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n20.2\n32.5\n13.3\n9.8\n6.3\n3.6\nV m (t) - V m o (mV)\nTime (ms)\nFigure 5.23: Dependence of the action potential on temperature for measurements ob\ntained from a giant axon of the squid (Hodgkin and Katz, 1949b).\n-40\n-80\nMembrane potential (mV)\nTime (ms)\nFigure 5.24: Effect of extracellular sodium concentration on the membrane potential of\na giant axon of a squid (Hodgkin and Katz, 1949a, adapted from Figure 4). Traces 1 and\n3 are the action potentials obtained in normal sea water before and after trace 2 which\nwas obtained in sea water with 50% sodium content. Isotonic solutions were obtained\nby using mixtures of sea water and a glucose solution.\nbe changed by changing a number of experimental variables. For example, in\ncreasing the temperature tends to decrease the duration of the action potential\n(Figure 5.23), and reducing the external sodium concentration reduces the am\nplitude and increases the duration of the action potential (Figure 5.24). Since\naction-potential waveforms vary from cell to cell and vary for one cell if environ\nmental variables are changed, this raises a question -- To what extent are changes\nin action-potential waveforms seen in different cells due to inherent differences in\nthe membrane mechanisms rather than to differences in membrane parameters\nwith identical membrane mechanisms? For example, the action potentials of the\nsquid axon and the frog and rat nodes of Ranvier shown in Figure 5.22 were\nmeasured at different temperatures. In fact, the briefest action potentials were\nobtained at the highest temperatures. Since Figure 5.23 indicates that the dura\ntion of the action potential does become shorter at higher temperatures in squid\naxon, it may be that the temperature differences in the measurements could ex\nplain the differences in the waveforms of the action potentials of these three\npreparations. It is clear that temperature changes alone cannot explain all the\n\n5.6. PROJECTS\nvariations seen in Figure 5.22 since the long-duration action potential of frog car\ndiac muscle was obtained at a higher temperature than was the action potential\nof the squid giant axon. However, perhaps some combination of changes of pa\nrameters in addition to temperature (e.g., ion concentrations, ion conductances,\nmembrane capacitance, etc.) might explain the long-duration action potential of\ncardiac muscle.\nExamples of hypotheses\nThe list of projects given below includes a number that deal with the waveform\nof the action potential generated by the Hodgkin-Huxley model as well as a few\nthat deal with other topics.\n1. Hypothesis -- The difference in waveform of the action potential of a frog\nnode of Ranvier and of a squid giant axon (Figure 5.22) can be reproduced by\nthe Hodgkin-Huxley model of a squid giant axon by a change in temperature.\n2. Hypothesis -- The membrane capacitance determines the time course of the\nrising phase of the action potential. Increasing the membrane capacitance\ndecreases the rate of increase of the rising phase of the action potential.\n3. Hypothesis -- The falling phase of the action potential (repolarization) can\noccur in the absence of a change in potassium conductance.\n4. Hypothesis -- Increasing the temperature sufficiently blocks the occurrence\nof the action potential because the membrane time constant limits the rate\nat which the membrane variables can change and prevents the difference in\ntime course of the sodium and potassium activation which is responsible\nfor initiation of the action potential.\n5. Hypothesis -- The initiation of the action potential is independent of the\npotassium conductance.\n6. Hypothesis -- The prolonged plateau of the cardiac muscle action poten\ntial can be accounted for by the Hodgkin-Huxley model with a potassium\nconductance that has a slow activation.\n7. Hypothesis -- The effect of tetraethylammonium chloride (TEA) on the ac\ntion potential of the squid giant axon can be modelled with the Hodgkin-\nHuxley model by decreasing Kn and increasing Kh. Articles in the literature\nshould be consulted for this project (Armstrong, 1966; Armstrong and Bin-\nstock, 1965; Tasaki and Hagiwara, 1957).\n8. Hypothesis -- The shape of the action potential in the presence of tetraethy\nlammonium chloride (TEA) can be accounted for by the Hodgkin-Huxley\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nmodel with a reduced maximum value of the potassium conductance. Arti\ncles in the literature should be consulted for this project (Armstrong, 1966;\nArmstrong and Binstock, 1965; Tasaki and Hagiwara, 1957).\n9. Hypothesis -- Increasing the external calcium concentration will block the\noccurrence of the action potential because this will reduce the difference in\nthe time constant of sodium and potassium activation which is responsible\nfor the initiation of the action potential.\n10. Hypothesis -- Increasing the external concentration of potassium will de\ncrease the refractory period; decreasing this concentration will lengthen the\nrefractory period.\n11. Hypothesis -- Increasing the external concentration of sodium will decrease\nthe refractory period; decreasing this concentration will lengthen the refrac\ntory period.\n12. Hypothesis -- Absolute and relative refractory periods are decreased by\nincreasing the rate constants for sodium inactivation and for potassium\nactivation.\n13. Hypothesis -- Repolarization cannot occur if the potassium activation rate\nconstant is zero.\n14. Hypothesis -- The threshold of the action potential to a brief pulse of cur\nrent decreases as the external potassium current is increased.\n15. The Hodgkin-Huxley model with default parameters does not exhibit ac\ncommodation (Weiss, 1996b). Hypothesis -- Accommodation occurs if the\nleakage conductance is increased.\n16. The Hodgkin-Huxley model with default parameters does not exhibit ac\ncommodation (Weiss, 1996b). Hypothesis -- Accommodation occurs if the\npotassium conductance is increased.\n17. Hypothesis -- Increasing the leakage equilibrium potential will block the\naction potential.\n18. Hypothesis -- The effect of the changes in concentration of sodium ions on\nthe action potential of the giant axon of the squid can be accounted for by\nthe Hodgkin-Huxley model. Articles in the literature should be consulted\nfor this project (Hodgkin and Katz, 1949a; Baker et al., 1961).\n19. Hypothesis -- In response to rectangular pulses of current, the rheobase of\nthe strength-duration relation increases as temperature increases.\n20. Hypothesis -- An increase in temperature results in a decrease in the dura\ntion of the refractory period.\n\n5.6. PROJECTS\n21. Hypothesis -- The threshold membrane potential at which the Hodgkin-\nHuxley model produces an action potential in response to a brief pulse\nof current is equal to the membrane potential for which the linearized\nHodgkin-Huxley equations have unstable eigenvalues.\n22. Application of a long-duration constant current to the Hodgkin-Huxley model\nproduces a train of action potentials. Hypothesis -- The frequency of the\naction potentials increases with increasing current amplitude.\n23. Application of a long-duration constant current to the Hodgkin-Huxley model\nproduces a train action potentials. Hypothesis -- The frequency of action\npotential increases as the parameter Kn is increased.\n24. Application of a long-duration constant current to the Hodgkin-Huxley model\nproduces a train action potentials. Hypothesis -- The frequency of action\npotential increases as the temperature is increased.\n25. Hypothesis -- An increase in the external concentration of potassium in\ncreases the threshold potential at which an action potential is elicited.\n26. Hypothesis -- Increasing Kh will result in an increase in the steepness of\nthe repolarization phase of the action potential.\nAny of these (or other) hypotheses can be the starting point for a project.\nMost of the hypotheses given above are simplistic, and a careful investigation\nwill reveal their shortcomings. The Hodgkin-Huxley model is sufficiently complex\nthat investigation of any of the hypotheses will most likely lead to unexpected\nresults. You should pursue these unexpected results and try to understand their\nbases. For example, you may find that in pursuing some hypothesis you choose\nto change some parameter of the model that you expect to result in some change\nin action potential waveform. The resulting computation might reveal, much to\nyour surprise and chagrin, that no action potential has occurred. Determine why\nno action potential occurred. The explanation will usually be instructive. Your\naim should be not simply to reject or accept the hypothesis but to delve into the\ntopic in sufficient depth so as to a deepen your understanding of the model. One\noutcome of the project might be to restate your original hypothesis in a new and\nmore sophisticated form.\nBeginning with the proposal and extending through the project, you should\nkeep clearly in mind that you are not investigating nerve membrane. You are\ninvestigating the Hodgkin-Huxley model for the membrane of the squid giant\naxon. Your explanations of all phenomena must be in terms of the primitive\nconcepts of this model -- the ionic conductances, ionic concentrations, ionic\ncurrents, the capacitance, and the variables m, n, and h. Explanations in terms\nof molecular channel mechanisms or electrodiffusion of ions in the membrane or\nion pumps are irrelevant in so far as they are not contained in the Hodgkin-Huxley\nmodel!\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n5.6.3 The proposal\nThe proposal should contain a brief statement of the hypothesis you propose to\ntest, as well as your proposed method of procedure. Include a list of the compu\ntations you will perform and the measurements you plan to make. Indicate how\nthe measurements will be used to help you come to a conclusion. The proposal\nshould be written on one 8 1/2 × 11 sheet of paper. A sample proposal is shown\nin Figure 5.25.\n5.6.4 The computations\nAfter carefully defining the computations needed to determine the validity of\nyour hypothesis, you should perform the necessary computations. You should\nkeep careful track of the computations you perform by entering relevant informa\ntion in a notebook. The notebook should indicate the date of each computational\nsession as well as the identity of the computer you used (make and model). Keep\nan accurate record of each computation so that you can reconstruct what you\ndid at a later date. Save your results in files. Make composite plots to summa\nrize a series of measurements. For example, to show the effect on the action\npotential of some parameter, plot the action potentials for selected values of the\nparameter on one set of axes. Arrange you work so that you have time for some\nfinal computations after you begin writing the report. You may find that new\nquestions will arise as you write the report. If you leave adequate time, you may\nbe able to resolve these questions.\n5.6.5 The report\nThe report is an opportunity for you to work on your ability to express yourself\nsuccinctly. Your report should contain text, figures, tables, etc. whatever you\nneed to make your point most effectively. Assume that the background of your\nreaders is that of the students and faculty in your class.\nYour report should contain several sections.\nHypothesis\nBriefly restate your original hypothesis.\nRationale\nBriefly explain your approach to testing your hypothesis. In broad terms, explain\nwhat you did to test your hypothesis and why you did it.\n\n5.6. PROJECTS\nPROPOSAL: HODGKIN-HUXLEY MODEL PROJECT\nName: Hy I.Q. Student\n-\nEmail address: hiqstudent\n-\nHypothesis: The difference in observed action potential shape between\n-\nthe giant axon of the squid and the node of Ranvier of the rat is due to a\ndifference in temperature.\nBackground: The rate constants that determine the variables m, n, and\n-\nh in the Hodgkin-Huxley model increase as the temperature is increased.\nHence, I would expect that with increased temperature the time course of\nthe action potential would be briefer. The observed action potential of the\nrat node of Ranvier measured at 37C. is briefer than the action potential of\nthe squid giant axon measured at 16C. Hence, I will determine whether this\ndifference in temperature is adequate to explain the difference in action-\npotential waveform. In this study, I will assume that the Hodgkin-Huxley\nmodel accounts for action potentials in both preparations. Since the intra\ncellular and extracellular ionic concentrations of sodium, potassium and\ncalcium also differ in these two preparations, if time permits I will also\ninvestigate the effect of this difference.\nProcedure: I will obtain the intracellular and extracellular concentrations of\n-\nsodium and potassium ions for the rat node of Ranvier from the literature. I\nwill perform a series of simulation studies with a single pulse of membrane\ncurrent whose amplitude will be set at a constant suprathreshold value. I\npropose the following series of simulations\n# Temp.\nIon Concentrations\nC\ndefault values for squid giant axon\ndefault values for squid giant axon\nvalues found for rat node\nvalues found for rat node\nThe waveforms of the action potentials obtained under the various condi\ntions will be compared on the graphics display and the summary statistics\nfor each condition will be examined. If condition 4 yields an action poten\ntial that resembles that which is measured on the rat node of Ranvier, then\nthe hypothesis will be supported by these calculations. If they differ, then\nI will investigate the bases of the differences.\nFigure 5.25: Sample proposal for a project.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nMethods and procedures\nIn this section you should explain any methodological or procedural issues. For\nexample, if you measured the time of the peak of the action potential as a function\nof some parameter, explain how you measured the time of the peak and how you\ndefined when an action potential occurred, i.e., how did you separate the action\npotential from the local response.\nResults\nDescribe your computational results and provide documentation such as that\nshown in Figures 5.18-5.20, as well as summary plots and tables. This section\nshould be organized to lead the reader through a logical sequence of results that\nterminates inexorably in a conclusion. Your objective is to construct an airtight\ncase for some conclusion whether or not it supports or rejects your original hy\npothesis. This is not the place to interpret or to discuss your results.\nConclusions and Discussion\nState your conclusions concisely and point out how your results support your\nconclusions. You might also suggest additional computations to further test\nyour hypothesis. Your conclusions and discussion should be focussed on the\nrelation between your results and your hypothesis.\nGrade\nYour grade on this report will be determined largely by the extent to which you\nfollow the above directions, avoid extraneous and irrelevant discussion, and ex\npress your thoughts clearly.\n\nChapter 6\nVOLTAGE-GATED ION CHANNELS\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\n6.1 Introduction\n6.1.1 Historical background\nPassive transport of ions through cellular membranes is mediated by membrane-\nbound channel proteins that form selectively permeable ion channels. Although\ntheir existence was long suspected, the first direct physiological evidence for\nthese channels became available in 1976 (Neher and Sakmann, 1976). Subse\nquently, many different types of channels have been identified (Hille, 1992).\nChannels can be categorized on the basis of the physical/chemical variable that\nopens or gates the channel. For example, the channels that underlie the prop\nerties of electrically excitable cells are gated by the membrane potential and are\ncalled voltage-gated channels. These channels are opened by a change in mem\nbrane potential. Other channels are gated by the binding of specific chemical\nsubstances, mechanical deformation of the membrane, etc. In all of these cases,\nthe channels behave as if they have a discrete number of states, of which a few\n(usually only one) are conducting or open states and the others (usually more\nthan one) are non-conducting or closed states. The channel switches rapidly and\nrandomly among its allowable states, and the probability that a transition occurs\nat a particular time depends on the value of the gating variable.\nModels of the gating of single ion channels were developed almost immedi\nately after single-channel data were obtained (Colquhoun and Hawkes, 1977).\nDescriptions of these models can be found elsewhere (Colquhoun and Hawkes,\n1995a; Weiss, 1996b).\n6.1.2 Overview of software\nThis software package enables users to enhance their understanding of models\nof the gating of single voltage-gated ion channels. The software allows the user\nto design a channel by choosing the number of states, the voltage dependence\nof transitions between states, the conductance and gating charge of each state,\nand the equilibrium potential for the channel. After the channel is designed, the\nuser can analyze the behavior of the channel to a change in membrane potential.\nAny of the variables associated with the channel can be displayed including the\nstate occupancy probability, conductance, ionic current, gating charge, and gating\ncurrent. Both random variables and their expected values can be displayed as a\nfunction of time. The software is sufficiently powerful and flexible to allow users\nto synthesize realistic, state-of-the-art models for the gating of voltage-gated ion\nchannels.\n\n6.2. DESCRIPTION OF THE MODEL\n6.2 Description Of The Model\nA brief description of the channel model is given here; a more complete descrip\ntion is given elsewhere (Weiss, 1996b). We assume that a channel has N states\nand that at each instant in time t, the channel is found in one of its states (Fig\nure 6.1). The states are enumerated as {S1, S2, S3, . . . SN }. Each state has state at-\nS1\nS2\nS3\nS4\nS5\n(r)12\n(r)23\n(r)34\n(r)45\n(r)51\n(r)21\n(r)32\n(r)43\n(r)54\n(r)15\n°1, Q1\n°2, Q2\n°3, Q3\n°4, Q4\n°5, Q5\nFigure 6.1: Kinetic diagram of a channel that has 5 states. The states are shown linked\nby rate constants for transitions between states, where τij is the rate of transition from\nstate i to state j. When the channel is in state j the conductance of the channel is γj\nand the gating charge of the channel is Qj .\ntributes: the state conductance and the state gating charge. The state attributes\nfor these states are denoted as {γ1, γ2, γ3, . . . γN } for the state conductances and\n{Q1, Q2, Q3, . . . QN } for the state gating charges. Given the membrane potential Vm\nand the equilibrium potential Veq, the state ionic currents are {I1, 2, 3, . . . N }.\nI\nI\nI\nThus, when the channel is in state Sj , the state conductance is γj, the state ionic\ncurrent is j\nγj(Vm - Veq), and the state gating charge is Qj . Gating currents\nI =\noccur at the transitions of the gating charge.\nThe temporal evolution of the electrical properties of a channel depend upon\nthe state occupancy probabilities which we discuss briefly. Define the probability\nthat the channel is in state j at time t as xj(t), and the transition probability that\nthe channel is in state j at time t + t given that it was in state i at time t as\nyij(t + t). The fundamental assumption of the model for state transitions is\nthat the transition probabilities depend on the present state of the channel and\nnot on previous states. Such a probabilistic process is called a Markov process.\nFormally, we assume that\nyij(t + t) = τijt + o(t) ,\nwhere o(t) has the property that limt≤0 o(t)/t\n0 and τij is a rate con\n=\nstant for transitions from state i to state j. The first term is the probability of\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\noccurrence of a single transition in the interval of duration t when this interval\nis short and the rate of transitions is τij . The second term takes into account the\nprobability of the occurrence of multiple transitions in the interval. For intervals\nt that are sufficiently small so that no more than one transition is likely to oc\ncur in the interval, the o(t) term is negligible; we will ignore this term in the\ndevelopment that follows. The probability that the channel is in state j at time\nt + t and in state i at time t is yij(t + t)xi(t) √ τijxit.\nThe increase in probability that the channel is in state j in the time interval\n(t, t + t) is xj(t + t) - xj(t). In this time interval, this probability increases\nas a result of transitions from states i into state j and decreases as a result of\ntransitions from state j into state i. By collecting all such terms we obtain,\nN\n⎩\nN\nxj(t + t) -xj(t) √\nτijxi(t)t -\nτjixk(t)t ,\ni 1,i\ni 1,i\n=\n→=j\n=\n→=j\nwhere the first summation is due to transitions into state j and the second sum-\n⎩\nj\nmation is due to transitions out of state\nIf we rearrange the terms and take\n.\nthe limit as t ≤ 0, we obtain the differential equation\nN\n⎩\ndt\n=\ni 1,i\n=\n→=j\nN\n⎩\nτijxi(t) -\nτjixj(t).\n(6.1)\ni\ndxj(t)\n1,i→=j\n=\nThis equation can be written in matrix form by defining the matrix of transition\nprobabilities to be\n66666666⎤\nτ11\nτ12\nτ1N\n· · ·\nτ21\nτ22\nτ2N\n· · ·\n· · · · · · · · · · · ·\nτN1 τN 2\nτNN\n· · ·\n⎪⎪⎪⎪⎪⎪⎪⎪⎣\n.\n=\nwhere τij is the transition rate from state i to state j when i →= j, and τii is\nPN\nchosen so that\ni 1 τij\n0. The state occupancy probability satisfies the matrix\n=\n=\ndifferential equation\ndx(t)\nx(t),\n(6.2)\ndt\n=\nwhere x(t) is a row matrix of state occupancy probabilities. In addition, since\nthe channel is in one of its N states at each instant in time,\nN\n⎩\nxj(t) = 1 .\nj=\nThe equilibrium state occupancy probability can be obtained directly from Equa\ntion 6.2 by setting dx(t)/dt = 0 to yield\nx(1),\n(6.3)\n=\n\n>\n<\n>\n:\n6.2. DESCRIPTION OF THE MODEL\nto obtain the equilibrium state occupancy probability x(1).\nIf the matrix is constant, then the solution to the matrix equation for the\nstate occupancy probability is (Colquhoun and Hawkes, 1995a)\nx(t) = x(0)et,\nwhere x(0) is the matrix of the initial value of x(t). Evaluation of the exponential\nmatrix yields the result\nN\nx(t) = x(0)\nSjeφjt,\n(6.4)\nj=\nwhere φj is the jth eigenvalue of and Sj is the jth spectral matrix of . Therefore,\nwe see that the state occupancy probabilities are weighted sums of exponentials\nwhose exponents are the eigenvalues of the transition rate matrix. Because the\nmatrix is singular, one eigenvalue has value zero. All other eigenvalues have\nnegative real parts (Cox and Miller, 1965). Thus, the non-zero eigenvalues lead\n⎩\nto solution exponentials that decay with time.\nFor a voltage-gated channel, the transition rates depend explicitly on the mem\nbrane potential which in turn may vary with time. If the rate constants are\nassumed to satisfy the theory of absolute reaction rates (Weiss, 1996a; Weiss,\n1996b), then they depend exponentially on the membrane potential,\nτij(Vm) =\nAijeaijVm\nif i j,\nif i = j,\nwhere Aij is a rate factor and aij is an exponential factor. τij(Vm) depends on\nthe membrane potential which in turn depends upon time. Therefore, the rate\nconstants will in general depend upon time.\nDuring intervals of time when the membrane potential is a constant, Equa\ntion 6.2 is a linear, first-order matrix differential equation with constant coeffi\ncients. The solution determines the state occupancy probabilities, the {xj(t)}s.\nThe expected values of the channel conductance, channel current, and gating\ncharge are computed directly from the state occupancy probabilities. If the con\nductance of the channel is γj when the channel is in state j, then the expected\nvalue of the conductance of the channel, g(t), is\nN\n⎩\ng(t) =\nγjxj(t).\n(6.5)\nj=\nIf we assume that the current through the channel when the channel is in state j\nis γj(Vm - Veq), the expected value of the single-channel current, i(t), is\nN\n⎩\ni(t) =\nγjxj(t)(Vm - Veq) = g(t)(Vm - Veq).\n(6.6)\nj=\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nSimilarly, if the gating charge of the channel when the channel is in state j is Qj ,\nthe expected value of the single-channel gating charge, qg(t), is\nN\n⎩\nqg(t) =\nQjxj(t).\n(6.7)\nj=\nThe expected value of the single-channel gating current, ig(t), is\nig(t) = dqg(t) .\n(6.8)\ndt\n6.3 Numerical Methods\n6.3.1 Integration step\nThe differential equation for the state occupancy probability (Equation 6.2) is\nsolved numerically using methods described elsewhere (Colquhoun and Hawkes,\n1995b). The accuracy and efficiency of the numerical solution depends upon the\nvalue of the integration step, t. The value of t needs to be chosen small enough\nso that the time rate of change in the occupancy probabilities can be resolved ac\ncurately and so that the random variables are represented accurately. The choice\nof an adequate value of t depends upon the eigenvalues of the state transi\ntion rate matrix. Typically, t should be chosen so that t\n1/ φmax , where\n*\n|\nφmax is the eigenvalue with the largest magnitude. The smaller\n|\nt is chosen\nthe more accurate the integration in any one step, but the longer the computa\ntion will take. In addition, long computations can result in the accumulation of\nround-off errors. Thus, the choice of t is a compromise between the speed and\naccuracy of the simulation. Solution of the matrix equation (Equation 6.4) deter\nmines the occupancy probabilities of each state. From these probabilities, the\nexpected values of the conductances, currents and gating charge are computed\nusing Equations 6.5-6.8.\nRandom variables are computed from state transition probabilities. Transi\ntions probabilities from state i to state j are computed from the relation yij(t +\nt) √ τij t at each instant in time. The time interval for computing random\nvariables is set equal to the integration step t. The occurrence of a transition\nis determined by a random number generator. The sequence of state transi\ntions determines the sequence of conductance values and gating charges since\neach state has a unique conductance and gating charge. The conductance values\ndetermines the current since this current is determined by specifying the con\nductance, the membrane potential, and the channel equilibrium potential. The\ngating current random variable is represented by impulses at the times of tran\nsition of the gating charge and whose areas equal the discontinuities in gating\ncharge.\n\n6.4. USER'S GUIDE\n0.2\n0.1\n0.05\n0.02\n0.01\n0.005\n(φt)\nFigure 6.2: The probability of occurrence of\nmore than 1 event in an interval t where\nthe rate of events is φ and the events are dis\ntributed according to a Poisson distribution.\n0.1\n0.2\n0.5\nφt\nIn order to accurately represent the random variables, the time interval must\nbe chosen sufficiently brief that the probability of occurrence of more than 1\nchange in state in the interval is negligible. The probability of occurrence of k\nevents in an interval t with an average rate of events of φ is given by the Poisson\ndistribution\nPr(k, φt) = (φt)k\ne-φt.\n(6.9)\nk!\nHence, the probability of occurrence of more than 1 event in an interval is\n(φt) = 1 - Pr(0, φt) - Pr(1, φt) = 1 - (1 + φt)e-φt.\n(6.10)\nThe probability of more than one event in an interval (φt) is shown plotted\nversus φt in Figure 6.2. Note that for φt ← 0.2, (φt) ← 0.018.\n6.3.2 Initial conditions\nIn order to obtain a solution to Equation 6.2, initial conditions must be specified.\nThere are several plausible choices for the initial conditions, i.e., the initial states\nof the channel. One choice is simply to specify the initial state deterministically.\nA second choice is to choose the most probable state as the initial state. The\nmost probable state can be obtained by solving Equation 6.3 and choosing the\ninitial state as the one with the highest probability. A third choice is to choose\nthe initial state probabilistically according to the equilibrium probability for state\noccupancy as determined by Equation 6.3. All three choices are implemented in\nthe software.\n6.4 User's Guide To The Software\nWhen this package is selected, 2 figures are displayed (in addition to MATLAB's\ncommand window): controls and channel parameters. The controls figure con\ntrols the software (Figure 6.3). The channel parameters figure allows the user to\ndesign a single channel. Once the channel is designed, the membrane potential is\nspecified as a function of time, and the numerical variables chosen, the software\nallows the user to analyze the statistical properties of the channel variables as a\nfunction of time.\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nFigure 6.3: The controls figure af\nter the software is initiated.\n6.4.1 Controls\nThe portion of the controls figure (Figure 6.3) below the menubar is divided into\nfive panels. The setup panel allows the user to select the channel parameters\nfigure (which is used to design the channel), the membrane potential figure (which\nis used to specify the membrane potential as a function of time), and the numerics\nfigure (which is used to specify the initial conditions and the integration step\nof the solution). A panel just below the setup panel controls the simulation.\nThe simulation can be started, stopped, paused, or continued. The analysis panel\nallows display of a variety of the results of a simulation. The log panel contains\noptions for recording log entries of the session and is described in Chapter 1.\nThis message panel is used to send messages to the user.\n6.4.2 Channel parameters\nAfter the program is initiated, the channel parameters figure displays the default\nchannel kinetic diagram as shown in Figure 6.4. In general, the user constructs\na channel model by editing the default channel model. Editing entails adding\nnew states, adding or modifying rate constants that link the states, assigning\nionic conductances and gating charges to states, and assigning an equilibrium\npotential to the channel model.\nEach box in the channel parameters figure (Figure 6.4) represents a particular\nstate of the channel and is given a number from 1 to 8 (a maximum of 8 states\nis possible). The arrows connecting these states depict the transition rates be\ntween states. Each box also contains the ionic conductance of the channel when\nthe channel is in that state; the ionic conductance can be changed by clicking on\nit's value and typing the new value into the edit box. The ionic conductance is\nexpressed in picosiemens (pS). A value of zero denotes a non-conducting state.\nEach box also contains the gating charge valence z of the channel when the chan\nnel is in that state; the gating charge valence can be changed by clicking on it's\n\n6.4. USER'S GUIDE\nFigure 6.4: The channel parameters figure. The rate constant τ12 has already been\ndefined and is displayed in the message panel at the bottom of the figure.\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nFigure 6.5:\nAppearance of\nthe display after the user has\nclicked on the forward rate con\nstant in Figure 6.4 and changed\nthe parameters of the the rate\nconstant.\nvalue and typing the new value into the edit box. The gating charge valence\ncan be positive or negative and need not be an integer. The gating charge is ze,\nwhere e\n1.602 × 10-19 C. The value of the channel equilibrium potential can be\n=\nchanged by clicking in the text edit box at the bottom of the channel parameters\nfigure and typing the new value.\nAdd new state\nA new state can be added to the diagram by clicking on Add New State. A new\nstate will be created and positioned in the upper left corner of the field. A new\nstate or any existing state can be repositioned in the window by clicking on the\ngrey region at the top of the state boxes and dragging the state box to a new\nposition. To delete a state the user clicks on the red delete box in the upper\nleft-hand portion of the state box.\nAdd rate constant\nRate constants are defined in the rate constant figure. Two cases arise both of\nwhich result in the display of the rate constant figure: (1) the user wishes to\nmodify an existing rate constant and (2) the user wishes to define a new rate\nconstant linking two states. To modify an existing rate constant the user simply\npoints to the desired rate constant arrow between two states and clicks the mouse\nto obtain the rate constant figure (Figure 6.5). To add a rate constant linking state\n\n6.4. USER'S GUIDE\nFigure 6.6:\nView rate con\nstant figure after both the for\nward (τ12) and reverse (τ21)\nrate constants have been de\nfined.\nIn this simulation,\n2.5e0.01Vm\nτ12\n(1/ms) and\n=\n3e-0.04Vm\nτ21\n(1/ms), where\n=\nVm is in mV.\ni to state j, the user first clicks on Add Rate Constant, then clicks in the state\nbox for state i, and then clicks in the state box for state j. During this operation,\nthe cursor becomes a +. The rate constant figure is displayed either when a\nrate constant is added or when an existing rate constant is selected. To modify\nthe voltage dependence of the rate constant, the user can either type numerical\nvalues into the text edit boxes in the lower left-hand corner of the rate-constant\nwindow or use the mouse to enter the voltage dependence of the rate constant\ngraphically. Clicking on two locations in the plot of rate constant versus potential\nputs an exponential function through those two points. The parameters of this\nexponential function of membrane potential are displayed in the text edit boxes.\nClicking on Update Rate Constant sets the voltage dependence of the selected\nrate constant which is then displayed in the message window at the bottom of\nthe channel parameters figure (Figure 6.4). To view the voltage dependence of\nseveral rate constants, choose View Rate Constants. A figure is displayed which\nallows rate constants to be plotted (Figure 6.6). Clicking and dragging on any of\nthe menu items allows the rate constant to be selected.\nMiscellaneous features\nIf Reset Diagram is selected the current channel kinetic diagram is erased and\nthe default channel kinetic diagram is drawn. A previously stored diagram can\nbe retrieved by selecting Get an old diagram. The current diagram can be saved\nto a file by selecting Save this diagram.\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nFigure 6.7: Membrane potential\nfigure after selection of a pulse\nof potential.\nFigure 6.8: Numerics figure appropriate for rate constants shown in Figure 6.6 and\nmembrane potential shown in Figure 6.7.\n6.4.3 Membrane potential\nSelection of Membrane Potential in the controls figure displays the membrane\npotential figure (Figure 6.7). The membrane potential can be a rectangular pulse\nof potential superimposed on a steady holding potential. The user can select the\nholding potential, the duration of the stimulus, the onset time of the pulse starts,\nthe pulse duration, and pulse amplitude.\n6.4.4 Numerics\nThe numerics figure (Figure 6.8) controls the choice of the integration step and\ninitial conditions for the simulation. The figure consists of four panels. The two\nupper panels deal with integration steps for the two allowable membrane poten\n\n6.4. USER'S GUIDE\ntial levels. The next panel down deals with choice of initial conditions (initial\nstates). The final panel is a message window that includes an estimate of the\ntime it will take to complete the simulation for the chosen parameters.\nIntegration step\nFor a given choice of membrane potential and voltage-dependent rate constants,\nthe software computes the eigenvalues of the transition rate matrix and displays\nthese results to the user. The smallest time constant is computed from the fastest\neigenvalue and the user can choose, by editing the text edit box, to make the\nintegration step a fraction (or a multiple) of this smallest time constant. Alter\nnatively, the user can choose a fixed integration time. The integration time that\nresults from the user's choice is displayed as is the probability of more than one\ntransition during an interval of time that equals the integration step.\nInitial state\nThe initial state for a simulation can be chosen deterministically to be any of\nthe allowable states or the most probable state for the given initial values of the\nmembrane potential. By default, the initial state is chosen probabilistically by\ncomputing the state occupancy probabilities for the chosen initial value of the\nmembrane potential and choosing the initial state randomly using these proba\nbilities.\n6.4.5 Analysis\nClicking on the analysis panel of the controls figure allows access to a variety of\ndisplays of simulation results including such variables as: the state occupancy,\nthe state occupancy probability, the ionic conductance, the ionic current, the\ngating charge, and the gating current. Both the random variables and their ex\npected values can be displayed. Ten channels with similar characteristics can\nbe examined simultaneously to allow users to relate macroscopic to microscopic\nvariables. Results of multiple simulations can also be plotted on a single set of\naxes for the sake of direct comparison.\nThree different types of graphs are available. The first type allows plotting a\nsingle variable as a function of time in fixed coordinates. An example is the state\noccupancy figure shown in Figure 6.9. The top panel shows the simulation for 10\nindependent channels, the middle panel shows the results for channel 1 alone,\nand the bottom panel shows the state occupancy probabilities for both states of\nthe channel. A second example of this type of graph is the ionic current shown in\nFigure 6.10. Both the ionic current random variable and its expected value have\nbeen selected for plotting. In addition, the average ionic current of 10 identically\ndistributed but statistically independent channels can also be displayed. Similar\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nFigure 6.9: State occupancy figure with all variables selected for display.\n\n6.4. USER'S GUIDE\nFigure 6.10: Single channel ionic current showing the relation between the random\nvariable and its expected value.\nplots are available for the ionic conductance, gating charge, and gating current.\nThese displays are helpful for relating macroscopic to microscopic variables and\nrandom variables to their expected values.\nA second type of graph is the summary graph which allows comparison of\nthe time dependence of channel variables to each other in fixed coordinates (Fig\nure 6.11). Most of the variables are self-evident from the display. However, the\nrepresentation of the gating current random variable requires some comment.\nThe gating charge random variable is a random rectangular wave. Hence, the\ngating current random variable, which is defined as the derivative of the gating\ncharge random variable, is a random impulse train (train of Dirac delta functions).\nWe represent these impulses with lollipops. The time of occurrence of a lollipop\nequals the time of occurrence of an impulse and the height of the lollipop equals\nthe area of the impulse. On the scale of visibility of the gating current random\nvariable, the expected value is often too small to see. Hence, in the plot of the\ngating current, deselecting the random variable will allow its expected value to\nbe observed. Clicking on the radio button for Cross line displays a vertical line\nthat tracks the position of the mouse cursor. The values of the intersection of\nthe line with each variable is displayed.\nThe third type of graph allows comparison of results obtained in different\nsimulations in coordinates defined by the user. Clicking on Comparisons in the\ncontrol figure displays the comparisons figure (Figure 6.12). This figure makes\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nFigure 6.11: Summary figure with all variables selected for display.\n\n6.4. USER'S GUIDE\nFigure 6.12: Comparison figure showing the expected value of the ionic current and of\nthe gating charge for the channel defined in Figures 6.4-6.7.\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nuse of the graphics package described in detail in Chapter 1.\n6.5 Problems\nProblem 6.1 This problem deals with a channel that has one two-state gate (which\nwe refer to as a two-state channel) whose rate constants are not a function of\nmembrane potential; this channel is not voltage-gated. Define a two-state chan\nnel for which state 1 is closed (nonconducting) and state 2 is open (conducting),\nτ\n2 .\nz\nτ\nUse rate constants that are constant (independent of membrane potential). In all\nparts of this problem use rate constants such that τ12 + τ21 = 10 ms-1.\na. Determine opening and closing rate constants such that the channel is\nequally likely to be in state 1 or state 2.\nb. Determine opening and closing rate constants such that the channel is three\ntimes as likely to be in state 2 than in state 1.\nc. Use the same rate constants as in part b. Set the membrane potential so\nthat it is -50 mV for t < 0.5 ms and +50 mV for t > 0.5 ms. The objective\nof this part is to design a channel that has a single-channel current when\nthe channel is open ( ) of -1.2 pA when the membrane potential is -50 mV\nI\nand +0.8 pA when it is +50 mV.\ni. Determine the equilibrium potential and single-channel conductance\nwhen the channel is open (γ). Check your answer by running the simu\nlation using the values of the equilibrium potential and single-channel\nconductance you determined.\nii. What is the average single-channel current (i) for t < 0.5 ms? What is\nthe average single-channel current for t > 0.5 ms?\nProblem 6.2 This problem deals with a two-state channel whose rate constants\nare functions of membrane potential; the channel is voltage-gated. Define a two-\nstate channel for which state 1 is closed (nonconducting) and state 2 is open\n(conducting),\nz\nτ\nτ\n2 .\nSet the membrane potential to -60 mV for t < 0.2 ms and to +40 mV for t > 0.2\nms.\na. Determine voltage-dependent rate constants such that: the channel is closed\n(with probability > 0.8) for t < 0.2 ms; the channel is open (with probability\n> 0.8) for t\n0.2 ms; and the channel opens with a time constant of about\n⇒\n0.2 ms.\n\n6.5. PROBLEMS\nb. Determine parameters of the channel such that when the channel is open,\nthe single-channel current ( ) is +0.5 pA at a membrane potential of +40\nI\nmV and is zero when the membrane potential is -10 mV.\nc. Is this an activation gate or an inactivation gate?\nd. Change the equilibrium potential to -70 mV. Repeat the simulation. Could\nthis channel describe the kinetics of the potassium channel in the Hodgkin-\nHuxley model? In what ways does it resemble the potassium channel? In\nwhat ways does it differ from the potassium channel?\ne. Change the equilibrium potential to +50 mV. Repeat the simulation.\ni. Is the average channel conductance a continuous function of time?\nExplain!\nii. Is the average channel current a continuous function of time? Explain!\niii. Could this channel describe the kinetics of the sodium channel in the\nHodgkin-Huxley model? In what ways does it resemble the sodium\nchannel? In what ways does it differ from the sodium channel?\nProblem 6.3 In this problem you will investigate two channels that each have\ntwo states with the same kinetic diagram, namely\nτ12\nz\nτ21\n2 ,\nwhere the rate constants are\nτ12 = 4e0.04Vm\n2e-0.01Vm\nand τ21 =\n.\nEach channel is subject to a membrane potential profile that is -60 mV from\nt\n0 to t\n1 ms after which the membrane potential is +10 mV for 2 ms. The\n=\n=\nequilibrium potential for each channel is +40 mV. The channels differ only in\nthe conductance assigned to each state. Channel 2 has γ1\n0 and γ2\n20 pS;\n=\n=\nChannel 2 has γ1 = 20 pS and γ2 = 0.\na. Which channel opens in response to a depolarization? Explain.\nb. Which channel closes in response to a depolarization? Explain.\nc. Does the time-dependence of the probability that the channel is in state 1\ndiffer for these two channels? Explain.\nProblem 6.4 This problem deals with a three-state channel whose rate constants\nare not a function of membrane potential; this channel is not voltage-gated. De\nfine a three-state channel with the following kinetic scheme\nτ12\nz\nτ21\nτ23\nz\nτ32\n3 ,\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\nwhere states 1 and 2 are closed and state 3 is open. In all parts of this prob\nlem, make the rate constants independent of membrane potential, and use rate\nconstants in the range 0.1-10 ms-1.\na. Determine a set of rate constants such that the channel is equally likely to\nbe in any one of its three states.\nb. Try a set of rate constants such that τij\nτji. What are the probabilities\n=\nof occupying each state? Try another such set having this property. What\nare the probabilities of occupying each state with this new set? What can\nyou conclude about this case?\nc. Determine a set of rate constants such that the probabilities that the channel\nis in states 1:2:3 are approximately 0:0.5:0.5.\nd. Determine a set of rate constants such that the probabilities that the channel\nis in states 1:2:3 are approximately 0:0.25:0.75.\ne. Determine a set of rate constants such that the probabilities that the channel\nis in states 1:2:3 are approximately 0.2:0.3:0.5.\nProblem 6.5 In this problem you will examine the properties of voltage-gated\nchannels with two, three, and four states. Assume that the equilibrium potential\nof each channel is 40 mV and that the membrane potential starts at -60 mV and\nswitches to +10 mV at 1 ms and is maintained at this value for 2 ms. The three\nchannels are defined as follows:\nThe two-state voltage-gated channel has a kinetic diagram\n-\nτ12\nz\nτ21\n2 ,\nwhere the rate constants are\n2e-0.01Vm\nτ12 = 4e0.04Vm and τ21 =\n.\nThe three-state voltage-gated channel has a kinetic diagram\n-\nτ12\nz\nτ21\nτ23\nz\nτ32\n3 ,\nwhere the rate constants are\n2e-0.01Vm\nτ12 = τ23 = 4e0.04Vm and τ21 = τ32 =\n.\nThe four-state voltage-gated channel has a kinetic diagram\n-\nτ12\nz\nτ21\nτ23\nz\nτ32\nτ34\nz\nτ43\n4 ,\nwhere the rate constants are\n2e-0.01Vm\nτ12 = τ23 = τ34 = 4e0.04Vm and τ21 = τ32 = τ43 =\n.\n\n6.5. PROBLEMS\nIn exploring the following issues, it is instructive to examine graphs that show\nthe membrane potential as well as both the random variables and mean values or\nprobabilities associated with the record of state occupancies, the conductance,\nand the current through the channel.\na. For each of the channels, make the last state (the state with the highest\nstate number) the conducting state with a conductance of 20 pS and make\nall other states non-conducting. Compare the mean conductance of the two-\nstate, the three-state, and the four-state channels. What can you say about\nthe effect on channel conductance of increasing the number of closed states\nthat precede the open state?\nb. Now consider the four-state channel. Compute the mean conductance when\nstate 1 has a conductance of 20 pS and all other states are nonconducting.\nRepeat this computation except make state 2 the conducting state with all\nothers nonconducting. Repeat again with state 3 and then state 4. Com\npare the mean conductance for these four conditions. Which of these con\nductances most closely resembles the sodium conductance of squid axon?\nExplain.\nProblem 6.6 Design a three-state channel that activates and then inactivates. The\nchannel activates at about 0 mV at a rate that is three times as fast as it inactivates.\na. Consider a channel that must open before it inactivates, e.g.\nτ12\nz\nτ21\nτ23\nz\nτ32\n3 ,\nwhere both states 1 and 3 are closed and state 2 is open.\nb. Consider a channel that need not open before it inactivates.\n\nCHAPTER 6. VOLTAGE-GATED ION CHANNELS\n\nBibliography\nAidley, D. J. (1989). The Physiology of Excitable Cells. Cambridge University\nPress, Cambridge, Great Britain.\nArmstrong, C. M. (1966). Time course of tea+-induced anomalous rectification\nin squid giant axons. J. Gen. Physiol., 50:491-503.\nArmstrong, C. M. and Binstock, L. (1965). Anomalous rectification in the squid\ngiant axon injected with tetraethylammonium chloride. J. Gen. Physiol., 48:859-\n872.\nAthena (1990a). Computation and Educational Community: A Background Pa\nper. Committee on Academic Computation for the 1990s and Beyond, Mas\nsachusetts Institute of Technology.\nAthena (1990b). Computing for Education at MIT: Final Report. Committee on\nAcademic Computation for the 1990s and Beyond, Massachusetts Institute of\nTechnology.\nBaker, P. F., Hodgkin, A. L., and Shaw, T. I. (1961). Replacement of the protoplasm\nof a giant nerve fibre with artificial solutions. Nature, 190:885-887.\nBalestri, D. (1988). Ivory towers, silicon basements. Infor. Tech. Quaterly, 7:5-17.\nBerkenblit, S. I. (1990). Design of a software diffusion simulator and analysis of a\nproblem in two-compartment diffusion. Master's thesis, Massachusetts Institute\nof Technology, Cambridge, MA.\nCarruthers, A. (1984). Sugar transport in animal cells: The passive hexose trans\nfer system. Prog. Biophys. Mol. Biol., 43:33-69.\nColquhoun, D. and Hawkes, A. G. (1977). Relaxation and fluctuations of mem\nbrane currents that flow through drug-operated channels. Proc. R. Soc. London,\nSer. B, 199:231-262.\nColquhoun, D. and Hawkes, A. G. (1995a). The principles of the stochastic in\nterpretation of ion-channel mechanisms. In Sakmann, B. and Neher, E., editors,\nSingle-Channel Recording, pages 397-482. Plenum Press, New York, NY.\n\nBIBLIOGRAPHY\nColquhoun, D. and Hawkes, A. G. (1995b). A Q-matrix cookbook. How to write\nonly one program to calculate the single-channel and macroscopic predictions\nfor any kinetic mechanism. In Sakmann, B. and Neher, E., editors, Single-Channel\nRecording, pages 589-633. Plenum Press, New York, NY.\nCox, D. R. and Miller, H. D. (1965). The Theory of Stochastic Processes. John Wiley\nand Sons, New York, NY.\nEinstein, A. (1906). Sur theorie der brownschen bewegung. Ann. Physik, 19:371-\n381. [For translation see Einstein (1956)].\nEinstein, A. (1956). Investigations on the Theory of the Brownian Movement.\nDover Publications. R. Furthe and A. D. Cowper, eds. [Translation of original\npublications].\nFick, A. (1855). On liquid diffusion. Philos. Mag., 10:30-39.\nFrankenhaeuser, B. and Hodgkin, A. L. (1957). The action of calcium on the\nelectrical properties of squid axons. J. Physiol., 137:218-244.\nGerald, C. F. and Wheatley, P. O. (1989). Applied Numerical Analysis. Addison-\nWesley, Reading, MA.\nHanselman and Littlefield (1996). Mastering MATLAB. Prentice-Hall, Englewood\nHills, NJ.\nHille, B. (1992). Ionic Channels of Excitable Membranes. Sinauer Associates Inc.,\nSunderland, MA.\nHodgkin, A. L. (1964). The Conduction of the Nervous Impulse. Charles C.\nThomas, Springfield, IL.\nHodgkin, A. L. and Huxley, A. F. (1952). A quantitative description of membrane\ncurrent and its application to conduction and excitation in nerve. J. Physiol.,\n117:500-544.\nHodgkin, A. L. and Katz, B. (1949a). The effect of sodium ions on the electrical\nactivity of the giant axon of the squid. J. Physiol., 108:37-77.\nHodgkin, A. L. and Katz, B. (1949b). The effect of temperature on the electrical\nactivity of the giant axon of the squid. J. Physiol., 109:240-249.\nHuxley, A. F. (1959). Ion movements during nerve activity. Ann. N.Y. Acad. Sci.,\n81:221-246.\nJohnston, D. and Wu, S. M. S. (1995). Foundations of Cellular Neurophysiology.\nMIT Press, Cambridge, MA.\n\nBIBLIOGRAPHY\nKandel, E. R., Schwartz, J. H., and Jessell, T. M. (1991). Principles of Neural\nScience. Elsevier, New York, NY.\nKatz, B. (1966). Nerve, Muscle and Synapse. McGraw-Hill Inc., New York, NY.\nKeynes, R. D. and Aidley, D. J. (1991). Nerve and Muscle. Cambridge University\nPress, Cambridge, Great Britain.\nKulik, C. C. and Kulik, J. A. (1986). Effectiveness of computer-based education\nin colleges. AEDS J., pages 81-108.\nNeher, E. and Sakmann, B. (1976). Single-channel currents recorded from mem\nbrane of denervated frog muscle fibres. Nature, 260:799-802.\nNicholls, J. G., Martin, A. R., and Wallace, B. G. (1992). From Neuron to Brain: A\nCellular and Molecular Approach to the Function of the Nervous System. Sinauer\nAssociates, Sunderland, MA.\nPlonsey, R. and Barr, R. C. (1988). Bioelectricity, A Quantitative Approach. Plenum\nPress, New York, NY.\nPress, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T. (1986). Nu\nmerical Recipes. The Art of Scientific Computing. Cambridge University Press,\nCambridge, Great Britain.\nPress, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T. (1988). Numer\nical Recipes in C. The Art of Scientific Computing. Cambridge University Press,\nCambridge, Massachusetts.\nShah, D. M. (1990). Computer simulation of the random walk model of diffusion.\nBachelor's thesis, Massachusetts Institute of Technology, Cambridge, MA.\nShampine, L. F. and Reichelt, M. W. (1997). The MATLAB ODE suite. SIAM J. Sci.\nComput., 18:1-22.\nStein, W. D. (1986). Transport and Diffusion Across Cell Membranes. Academic\nPress, New York, NY.\nTasaki, I. and Hagiwara, S. (1957). Demonstration of two stable potential states\nin the squid giant axon under tetraethylammonium chloride. J. Gen. Physiol.,\n40:859-885.\nWeiss, T. F. (1996a). Cellular Biophysics. Volume 1: Transport. MIT Press, Cam\nbridge, MA.\nWeiss, T. F. (1996b). Cellular Biophysics. Volume 2: Electrical Properties. MIT\nPress, Cambridge, MA.\n\nBIBLIOGRAPHY\nWeiss, T. F., Trevisan, G., Doering, E. B., Shah, D. M., Huang, D., and Berkenblit,\nS. I. (1992). Software for teaching physiology and biophysics. J. Sci. Ed. Tech.,\n1:259-274.\nWilson, J. M. and Redish, E. F. (1989). Using computers in teaching physics.\nPhysics Today, pages 34-41."
    },
    {
      "category": "Resource",
      "title": "manual5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-021j-quantitative-physiology-cells-and-tissues-fall-2004/b4b87eb17edb319471646bd01bbbdddc_manual5.pdf",
      "content": "CELLULAR BIOPHYSICS:\nTEACHING AND LEARNING\nWITH COMPUTER SIMULATIONS\nBy\nThomas Fischer Weiss\nwith the assistance of\nScott I. Berkenblit, Tanmaya S. Bhatnagar, Elana B. Doering,\nDavid Huang, David Koehler, Tommy Ng, Leela Obilichetti,\nStephanie Peek, Devang M. Shah, Giancarlo Trevisan\nDepartment of Electrical Engineering and Computer Science\nMassachusetts Institute of Technology\nFALL 2000\nDate of last modification: August 28, 2000\n\nii\n\niii\nPreface\nHistorical perspective\nDuring the 1980's the use of computers and information technologies began to\nhave an impact on higher education (Kulik and Kulik, 1986; Balestri, 1988; Wil-\nson and Redish, 1989; Athena, 1990a; Athena, 1990b). As an integral part of\nthis trend, in 1983 MIT in partnership with the Digital Equipment Corporation\nand the IBM Corporation launched Project Athena which was designed to make\ncomputation available to undergraduate students through a network of com-\nputers located in public clusters on the MIT campus (Athena, 1990a; Athena,\n1990b). A major objective of Project Athena was to improve undergraduate ed-\nucation through the use of computation and information technologies. Faculty\nwere encouraged to participate, and support for faculty software developers was\nprovided on a competitive basis.\nI had been involved in teaching cellular biophysics at MIT since the 1960's.\nThe possibility of using software as a pedagogical aid was intriguing. With sup-\nport from Project Athena, a software package on the Hodgkin-Huxley model for\nnerve excitation was developed as part of an undergraduate thesis (by David\nHuang), and was first used to teach cellular biophysics in the Fall 1984 semester.\nThe software was designed to be easy to use so that a student's attention would\nbe focussed on the Hodgkin-Huxley model and not on the computer. Informal\ndiscussions with students and a survey of student views showed that the soft-\nware was an enormous success.\nDuring the first semester, the software was\nused primarily in lecture demonstrations and as the basis for student projects.\nBoth pedagogic methods were found to be effective. The use of the software\nin lecture was very effective in motivating and engaging students. The student\nprojects were effective in allowing students to pursue a research project of their\nchoice with staffassistance. For many students this was their first experience\nwith a research project. The use of these projects, developed in the first year,\nwas so successful that it has been used ever since.\nThe initial results with the Hodgkin-Huxley software were so successful ed-\nucationally, that several other software development projects involving student\nprogrammers were launched.\nDuring this phase of software development, 5\nsoftware packages were developed and, in one form or another, have been used\nevery year to teach the subject. All of these packages were revised extensively in\nresponse to suggestions from students and staff. The original software runs on\nUNIX workstations under MIT's Project Athena and is available to the MIT com-\nmunity on a network of about 1000 UNIX workstations located in public clusters\non the MIT campus as well as in some living groups. All this software was written\nin C and XWindows and was based on a library of graphic user interface subrou-\ntines written by one of the students (Giancarlo Trevisan). The software has been\nused in lectures, in recitations held in an electronic classroom in which each\n\niv\nstudent uses a workstation, in homework assignments, and in student projects.\nVarious modes of use of the software in teaching were developed and are de-\nscribed briefly elsewhere (Weiss et al., 1992) and more extensively in the last\nchapter of this text. The software has become an integral part of the subject,\nand it is difficult to imagine teaching the subject without the software.\nSeveral problems became apparent in the development and utilization of the\nsoftware.\nFirst, it was very expensive, in time and in money, to develop the\nsoftware with the software tools available in the late 1980's. Much of the time\nwas expended in the development of graphic user interfaces that make the soft-\nware easy for the user but which are tedious for the programmers to specify.\nThese graphic user interfaces had to be written in a low-level language (XWin-\ndows). After 1991, funds from corporate sponsors were no longer available to\nsupport the development of new software which slowed considerably. Second,\nmaintenance of the software became a major headache. It became difficult for\na single faculty member with research, teaching, and other academic commit-\nments to maintain a library of software in the face of changes in the operating\nsystems. Third, as word spread about the existence of the software, educators\nand students outside of MIT requested the software. These requests accelerated\ndramatically after one of the software packages entitled Hodgkin-Huxley Model\nwon the 1990 EDUCOM/NCRIPTAL Higher Education Software award for Best En-\ngineering Software. However, almost all of the requests came from students and\nfaculty with access to Macintosh or PC computers and not to UNIX workstations.\nThus, when these people were informed that the software ran only on UNIX\nworkstations, they invariably lost interest. At the time the software was written,\nthe computational power of workstations so exceeded that of personal comput-\ners (PCs) that it was simply not possible to provide the type of performance on\nPCs that was achieved on the workstations. Furthermore, MIT's Project Athena\nwas committed to a network of UNIX workstations. Thus, for both software and\nhardware considerations, it did not make sense to port the existing software to\nPCs. The high cost of software development and maintenance did not justify\nfurther development of educational software on UNIX workstations alone, and\nthe development of new software was terminated in 1991.\nBy 1995, a number of developments made it feasible to address the prob-\nlems described above and to develop software for teaching cellular biophysics\nin a manner that would make it easier to maintain, easier to modify, and widely\navailable. Thus, all the software was rewritten to operate under MATLAB, which\nis a software package produced by The MathWorks, Inc., for the following rea-\nsons:\n- MATLAB is a powerful interpretive computational and visualization soft-\nware package with a large number of higher-level built-in functions. Thus,\nit is suitable for the development of educational software packages.\n- MATLAB is available for most computer platforms. The vendor supports\n\nv\nchanges in MATLAB that are required as changes in computer platforms\noccur. With the use of software built on MATLAB, this major maintenance\njob is transferred from individual faculty members to the vendor who has\nboth the financial incentive and expertise to maintain the vendor software.\n- Large improvements in performance of PCs have made the development\nof computationally intensive educational software feasible on these plat-\nforms.\n- MATLAB has provided increasingly sophisticated tools for building graphic\nuser interfaces (GUIs). These GUIs are essential for building user-friendly\neducational software packages.\n- MATLAB has rapidly become the de facto leader in supporting educational\ncomputational subjects at MIT and elsewhere. Thus, students are exposed\nto MATLAB in other subjects and the different exposures are mutually re-\ninforcing.\nHere, we describe this MATLAB-based version of the software which now con-\nstitutes 6 packages. The most recent addition to the library of packages is one\ndevoted to the propagated action potential along an unmyelinated nerve fiber.\nAlthough the software is not linked directly to any textbook, it was developed\nin parallel with textbooks in cellular biophysics (Weiss, 1996a; Weiss, 1996b).\nAcknowledgement\nA number of people contributed to the success of the development of this soft-\nware. We thank Project Athena, especially its two directors Steven Lerman and\nEarll Murman, for their support. In addition Gerald Wilson, Joel Moses, Richard\nAdler, Paul Penfield, and Jeffrey Shapiro were unfailingly supportive of this ef-\nfort.\nA number of students were involved in this effort.\nFor many students\nthe software project constituted a portion of their undergraduate thesis require-\nment; others (as norws) used the software projects to satisfy SM thesis require-\nments. David Huang wrote the first version of the Hodgkin-Huxley model pack-\nage.\nDavid Koehler also contributed to this package.\nDevang M. Shah wrote\nthe first version of the random-walk model package which was also revised by\nElana B. Doering. Chapter 2 is based heavily on Devang's thesis (Shah, 1990).\nScott I. Berkenblit wrote the first version of the macroscopic diffusion package.\nChapter 3 is based heavily on Scott's Master of Science thesis (Berkenblit, 1990).\nStephanie Peek and Leela Obilichetti helped to develop the carrier-mediated\ntransport package. Giancarlo Trevisan was a major contributor to all the pack-\nages. He wrote the first version of the voltage-gated ion channel package. He\nlater rewrote the Hodgkin-Huxley package and the carrier-mediated transport\npackage. He wrote all the graphic user interface routines that were ultimately\nused by all the packages. Generations of students benefited from his efforts. The\n\nvi\nrecipients of the 1990 EDUCOM/NCRIPTAL Higher Education Software Award for\nBest Engineering Software for the Hodgkin-Huxley package were Thomas Weiss,\nGiancarlo Trevisan, and David Huang. More than 15 generations of the students\nwho took the subject helped to find flaws in the software and made valuable\nsuggestions for its improvements. Tanmaya S. Bhatnagar ported all the original\nfive software packages to MATLAB, adding new features and improving many of\nthem substantially. His sense of esthetics marks all the packages. Tommy Ng\nwrote the elegant propagated action potential package described in Chapter 6\nwhich constituted his Master of Engineering thesis project. The chapter is based\nheavily on Tommy's thesis.\nBesides the support from Project Athena, the development of the software\nwas supported by the Howard Hughes Medical Institute for which we are grate-\nful. I was supported in part by the Thomas and Gerd Perkins professorship. The\nporting of the software to MATLAB was supported for 3 years by the National\nScience Foundation (NSF), Division of Undergraduate Education. We would par-\nticularly like to thank Dr. Herbert Levitan, Section Head of Course and Curricu-\nlum Development of NSF. Dr. Karen C. Cohen has been helpful in the evaluation\nof the software. Subsequent work has been supported by the MIT Class of '51\nFund for Excellence in Education, the MIT Class of '55 Fund for Excellence in\nTeaching, and the MIT Class of '72 Fund for Educational Innovation, and by a\nJohn F. and Virginia B. Taplin Faculty Fellowship.\nContact information\nInformation on cellular biophysics texts, errata, changes, etc. can be found in\nthe study materials section.\n\nContents\nINTRODUCTION\n1.1\nMotivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nOverview Of Software Packages . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nBrief Introduction To MATLAB\n. . . . . . . . . . . . . . . . . . . . . . .\n1.3.1\nJargon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3.2\nHelp\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4\nGeneral Operation Of The Software\n. . . . . . . . . . . . . . . . . . . .\n1.4.1\nDirectory structure . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.2\nStarting the software . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.3\nQuitting the software . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.4\nPrinting a figure . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.5\nReading from and saving to a file\n. . . . . . . . . . . . . . . . .\nRANDOM WALK MODEL OF DIFFUSION\n2.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.1\nHistorical background\n. . . . . . . . . . . . . . . . . . . . . . . .\n2.1.2\nMacroscopic and microscopic models . . . . . . . . . . . . . . .\n2.1.3\nOverview of software . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2\nDescription Of The Random-Walk Model . . . . . . . . . . . . . . . . .\n2.2.1\nParticle parameters within a region . . . . . . . . . . . . . . . .\n2.2.2\nBoundary conditions . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3\nUser's Guide To The Software . . . . . . . . . . . . . . . . . . . . . . . .\n2.3.1\nRW Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3.2\nRW Particle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.4\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nMACROSCOPIC DIFFUSION PROCESSES\n3.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.1\nBackground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.2\nMacroscopic model of diffusion\n. . . . . . . . . . . . . . . . . .\n3.1.3\nOverview of software . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2\nMethods of Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2.1\nAnalytic solutions . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2.2\nNumerical Solutions . . . . . . . . . . . . . . . . . . . . . . . . . .\nvii\n\nviii\nCONTENTS\n3.2.3\nSummary\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.3\nUser's Guide To The Software . . . . . . . . . . . . . . . . . . . . . . . .\n3.3.1\nMD Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.3.2\nMD Initial concentration profile\n. . . . . . . . . . . . . . . . . .\n3.3.3\nNumerics\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.3.4\nSimulation results figures . . . . . . . . . . . . . . . . . . . . . .\n3.3.5\nArbitrary concentration profiles . . . . . . . . . . . . . . . . . .\n3.4\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nCARRIER-MEDIATED TRANSPORT\n4.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2\nModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2.1\nSteady-state behavior of a simple, four-state carrier that binds\none solute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2.2\nSteady-state behavior of a simple, six-state carrier that binds\ntwo solutes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2.3\nTransient and steady-state behavior of a general, four-state\ncarrier that binds one solute\n. . . . . . . . . . . . . . . . . . . .\n4.3\nNumerical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.3.1\nNumerical methods . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.3.2\nChoice of numerical parameters . . . . . . . . . . . . . . . . . .\n4.4\nUser's Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.4.1\nCMT Control\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.4.2\nModel\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.4.3\nSteady-state interactive analysis . . . . . . . . . . . . . . . . . .\n4.4.4\nSteady-state graphic analysis . . . . . . . . . . . . . . . . . . . .\n4.4.5\nTransient analysis . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.5\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nHODGKIN-HUXLEY MODEL\n5.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.1.1\nBackground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.1.2\nOverview of the software\n. . . . . . . . . . . . . . . . . . . . . .\n5.2\nDescription Of The Model . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.2.1\nVoltage-clamp and current-clamp configurations . . . . . . . .\n5.2.2\nThe membrane current density components\n. . . . . . . . . .\n5.2.3\nThe membrane conductances . . . . . . . . . . . . . . . . . . . .\n5.2.4\nThe activation and inactivation factors . . . . . . . . . . . . . .\n5.2.5\nThe rate constants . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.2.6\nTime constants and equilibrium values of activation and in-\nactivation factors\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.2.7\nDefault values of parameters . . . . . . . . . . . . . . . . . . . .\n5.3\nNumerical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.3.1\nBackground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nCONTENTS\nix\n5.3.2\nChoice of integration step ∆t . . . . . . . . . . . . . . . . . . . .\n5.3.3\nMethod for computing solutions . . . . . . . . . . . . . . . . . .\n5.4\nUser's Guide To The Software . . . . . . . . . . . . . . . . . . . . . . . .\n5.4.1\nHH Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.4.2\nHH Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.4.3\nHH Stimulus\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.4.4\nNumerics\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.4.5\nAnalysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.4.6\nScripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.5\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.6\nPROJECTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.6.1\nPractical considerations in the choice of a topic\n. . . . . . . .\n5.6.2\nChoice of topics . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nPROPAGATED ACTION POTENTIAL\n6.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.1.1\nBackground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.1.2\nOverview of the software\n. . . . . . . . . . . . . . . . . . . . . .\n6.2\nTheory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.2.1\nCore conductor equations . . . . . . . . . . . . . . . . . . . . . .\n6.2.2\nRepresentation of stimulating electrodes\n. . . . . . . . . . . .\n6.2.3\nLongitudinal currents . . . . . . . . . . . . . . . . . . . . . . . . .\n6.2.4\nIntracellular and extracellular potential differences . . . . . .\n6.2.5\nThe membrane current density . . . . . . . . . . . . . . . . . . .\n6.2.6\nThe membrane conductances . . . . . . . . . . . . . . . . . . . .\n6.2.7\nDefault values of parameters . . . . . . . . . . . . . . . . . . . .\n6.3\nNumerical Method of Solution\n. . . . . . . . . . . . . . . . . . . . . . .\n6.3.1\nForward Euler method . . . . . . . . . . . . . . . . . . . . . . . .\n6.3.2\nBackward Euler method\n. . . . . . . . . . . . . . . . . . . . . . .\n6.3.3\nCrank-Nicolson method\n. . . . . . . . . . . . . . . . . . . . . . .\n6.3.4\nStaggered increment Crank-Nicolson method . . . . . . . . . .\n6.4\nUser's Guide to the Software\n. . . . . . . . . . . . . . . . . . . . . . . .\n6.4.1\nPAP Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.2\nPAP Workspace . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.3\nPAP Parameters\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.4\nPAP Stimulus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.5\nPAP Numerics\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.6\nPAP Voltage-Recorder . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.7\nPAP Variable Summary . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.8\nPAP Space-Time Evolution . . . . . . . . . . . . . . . . . . . . . .\n6.4.9\nPAP 3D Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4.10 PAP Comparison Plots\n. . . . . . . . . . . . . . . . . . . . . . . .\n6.4.11 Step-by-step Guide To Setting Up A Customized Simulation .\n6.5\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nx\nCONTENTS\n6.6\nPROJECTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nVOLTAGE-GATED ION CHANNELS\n7.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.1.1\nHistorical background\n. . . . . . . . . . . . . . . . . . . . . . . .\n7.1.2\nOverview of software . . . . . . . . . . . . . . . . . . . . . . . . .\n7.2\nDescription Of The Model . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.3\nNumerical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.3.1\nIntegration step\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.3.2\nInitial conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.4\nUser's Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.4.1\nIC Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.4.2\nIC Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.4.3\nMembrane potential . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.4.4\nNumerics\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.4.5\nAnalysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.5\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nPEDAGOGICAL METHODS\n8.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.2\nUses Of The Software . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.2.1\nLectures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.2.2\nElectronic classroom and homework problems . . . . . . . . .\n8.2.3\nProjects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.3\nAssessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.3.1\nCost of development . . . . . . . . . . . . . . . . . . . . . . . . .\n8.3.2\nExtent of software usage . . . . . . . . . . . . . . . . . . . . . . .\n8.3.3\nInformal assessment of impact on learning . . . . . . . . . . .\n8.3.4\nSurveys and focus groups . . . . . . . . . . . . . . . . . . . . . .\n8.3.5\nImpact on teaching . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.4\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.4.1\nPedagogical matters . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.4.2\nPractical matters . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.4.3\nBottom line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nList of Figures\n1.1\nCellular biophysics software figure showing the available software\npackages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nSave figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1\nDefinition of grid of particle locations\n. . . . . . . . . . . . . . . . . .\n2.2\nDefinition of simulation field, regions, and boundaries . . . . . . . .\n2.3\nMotion of a particle in a homogeneous region . . . . . . . . . . . . . .\n2.4\nMotion of a particle at a vertical perimeter boundary . . . . . . . . .\n2.5\nMotion of a particle at an internal vertical boundary . . . . . . . . . .\n2.6\nThe RW Control figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.7\nRW Particles figure showing the initial locations of particles . . . . .\n2.8\nRW Particles figure showing the locations of particles after a 100\nstep random walk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.9\nRW Parameters figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.10 RW Summary figure showing a numerical summary of statistics af-\nter a 100 step random walk . . . . . . . . . . . . . . . . . . . . . . . . .\n2.11 RW Histogram figure showing a histogram of particle locations af-\nter a 100 step random walk . . . . . . . . . . . . . . . . . . . . . . . . .\n2.12 RW Axis figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.13 RW Graph figures showing the mean and standard deviation of par-\nticle location versus step number\n. . . . . . . . . . . . . . . . . . . . .\n2.14 Parameters for a random walk in 3 regions\n. . . . . . . . . . . . . . .\n2.15 Initial locations of particles for a random walk in 3 regions . . . . .\n3.1\nClasses of initial concentration profiles simulated by the software .\n3.2\nThe MD Control figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.3\nInitial concentration profile for impulses . . . . . . . . . . . . . . . . .\n3.4\nMD Axis scale figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.5\nInitial concentration profile for sinusoids\n. . . . . . . . . . . . . . . .\n3.6\nInitial concentration profile for discontinuities . . . . . . . . . . . . .\n3.7\nInitial concentration using the arbitrary option . . . . . . . . . . . . .\n3.8\nInitial concentration for the two compartments option . . . . . . . .\n3.9\nThe MD Analytic parameters and MD Numeric parameters figures .\n3.10 MD Plots vs. position figure . . . . . . . . . . . . . . . . . . . . . . . . .\n3.11 MD Plots vs. time figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\nxi\n\nxii\nLIST OF FIGURES\n4.1\nKinetic diagram of the simple, four-state carrier . . . . . . . . . . . .\n4.2\nKinetic diagram of a simple, six-state carrier that binds two solutes\n4.3\nKinetic diagram of a general, four-state carrier model . . . . . . . . .\n4.4\nCMT Control figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.5\nCMT Units figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.6\nThe CMT Parameters and CMT State figures for the simple, four-\nstate carrier model\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.7\nThe CMT Parameters and CMT State figures for the simple, six-state\ncarrier model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.8\nThe CMT Parameters and CMT State figures for the general, four-\nstate carrier model\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.9\nThe CMT Steady state plot figure . . . . . . . . . . . . . . . . . . . . . .\n4.10 CMT Setup steady state plot figure . . . . . . . . . . . . . . . . . . . . .\n4.11 The Axis scale figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.12 Modify line properties figure\n. . . . . . . . . . . . . . . . . . . . . . . .\n4.13 The CMT Transient plot figure\n. . . . . . . . . . . . . . . . . . . . . . .\n4.14 The CMT Setup transient plot figure . . . . . . . . . . . . . . . . . . . .\n4.15 The CMT Transients numerics figure\n. . . . . . . . . . . . . . . . . . .\n5.1\nVoltage-clamp configuration . . . . . . . . . . . . . . . . . . . . . . . . .\n5.2\nCurrent-clamp configuration\n. . . . . . . . . . . . . . . . . . . . . . . .\n5.3\nThe HH Control figure after the software is initiated . . . . . . . . . .\n5.4\nThe HH Parameters figure after the software is initiated\n. . . . . . .\n5.5\nHH parameters vs. potential figure . . . . . . . . . . . . . . . . . . . . .\n5.6\nHH Setup parameters vs. potential plot figure . . . . . . . . . . . . . .\n5.7\nHH parameters vs. potential figure showing the effect of calcium\nconcentration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.8\nAxis scale figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.9\nModify line properties figure\n. . . . . . . . . . . . . . . . . . . . . . . .\n5.10 HH Stimulus figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.11 HH Stimulus figure showing an example of a stimulus waveform . .\n5.12 HH Stimulus figure showing an example of the use of an m-file to\ngenerate a sinusoidal stimulus . . . . . . . . . . . . . . . . . . . . . . .\n5.13 HH Numerics figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.14 HH Plots vs. time figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.15 HH Variable summary figure. . . . . . . . . . . . . . . . . . . . . . . . .\n5.16 HH Graphics figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.17 HH Setup plot figure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.18 HH Graphics figure showing a parametric plot of membrane con-\nductance versus membrane potential . . . . . . . . . . . . . . . . . . .\n5.19 HH Graphics figure showing the membrane potential obtained at\ndifferent temperatures . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.20 Simulation results for different parameters that block the action\npotential (Problem 5.11)\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nLIST OF FIGURES\nxiii\n5.21 Examples of action potentials . . . . . . . . . . . . . . . . . . . . . . . .\n5.22 Dependence of the action potential on temperature . . . . . . . . . .\n5.23 Effect of extracellular sodium concentration on the action potential 120\n6.1\nEquivalent network model of incremental sections of an unmyeli-\nnated nerve fiber . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.2\nRelation of stimulus electrodes to a fiber . . . . . . . . . . . . . . . . .\n6.3\nThe PAP Control figure when the software is initiated.\n. . . . . . . .\n6.4\nThe PAP Workspace figure.\n. . . . . . . . . . . . . . . . . . . . . . . . .\n6.5\nSnapshots of a propagating action potential shown using Color\nSpace-Time Evolution in the PAP Workspace figure.\n. . . . . . . . . .\n6.6\nThe PAP Parameters figure.\n. . . . . . . . . . . . . . . . . . . . . . . . .\n6.7\nThe PAP Parameters vs. Potential figure. . . . . . . . . . . . . . . . . .\n6.8\nThe PAP Stimulus figure.\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n6.9\nThe PAP Stimulus figure showing a stimulus that consists of two\npulses: the first pulse is an exponential pulse and the second is a\nramp plus a rectangular pulse. . . . . . . . . . . . . . . . . . . . . . . .\n6.10 The PAP Numerics figure.\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n6.11 The PAP Voltage-Recorder figure.\n. . . . . . . . . . . . . . . . . . . . .\n6.12 The PAP Variable Summary figure.\n. . . . . . . . . . . . . . . . . . . .\n6.13 The PAP Space-Time Evolution figure showing a snapshot of a prop-\nagating action potential. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.14 The PAP 3D Plots figure showing a propagating action potential.\nTop: a surface plot. Bottom: a mesh plot.\n. . . . . . . . . . . . . . . .\n6.15 The Setup PAP Comparison Plot figure showing the variables used\nto setup Figure 6.16.).\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.16 The PAP Comparison Plots figure showing a fixed-space plot of the\nmembrane potential, Vm, and the ionic conductances, GNa and GK,\nwith model parameters and the stimulus defined in Figures 6.6 and\n6.8.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.17 The PAP Comparison Plots figure showing a fixed-time plot of the\nmembrane potential, Vm, and the activation factors, m and h, ob-\ntained from a simulation with model parameters and the stimulus\ndefined in Figures 6.6 and 6.8. . . . . . . . . . . . . . . . . . . . . . . .\n6.18 The PAP Axis Scale figure. . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.19 The Modify Line Properties figure. . . . . . . . . . . . . . . . . . . . . .\n7.1\nKinetic diagram of a channel that has 5 states\n. . . . . . . . . . . . .\n7.2\nThe probability of occurrence of more than 1 event in an interval ∆t 179\n7.3\nThe IC Control figure after the software is initiated . . . . . . . . . .\n7.4\nIC Parameters figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.5\nIC Specify rate constants figure . . . . . . . . . . . . . . . . . . . . . . .\n7.6\nIC View rate constant figure . . . . . . . . . . . . . . . . . . . . . . . . .\n7.7\nIC Setup view rate constant figure . . . . . . . . . . . . . . . . . . . . .\n\nxiv\nLIST OF FIGURES\n7.8\nIC Membrane potential figure . . . . . . . . . . . . . . . . . . . . . . . .\n7.9\nIC Numerics figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.10 IC State occupancy figure\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n7.11 IC Ionic current figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.12 IC Summary figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.13 IC Graphics figure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.14 IC Setup graphics figure\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.15 IC Graphics figure showing the state occupancy probabilities for a\nfour-state channel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.16 IC Graphics figure showing the ionic conductances of a two-state,\nthree-state, and a four-state channel . . . . . . . . . . . . . . . . . . . .\n8.1\nRandom walk in two regions\n. . . . . . . . . . . . . . . . . . . . . . . .\n8.2\nSteady-state distribution . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.3\nTime constants in two-compartment diffusion\n. . . . . . . . . . . . .\n8.4\nThe threshold for eliciting an action potential in the Hodgkin-Huxley\nmodel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8.5\nSample project proposal . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nList of Tables\n2.1\nThe macroscopic laws of diffusion . . . . . . . . . . . . . . . . . . . . .\n3.1\nSummary of computational methods.\n. . . . . . . . . . . . . . . . . .\n3.2\nConcentration well -- Problem 3.7 . . . . . . . . . . . . . . . . . . . . .\n4.1\nModifiable parameters of the carrier models . . . . . . . . . . . . . . .\nxv\n\nxvi\nLIST OF TABLES\n\nChapter 1\nINTRODUCTION\n\nCHAPTER 1. INTRODUCTION\n1.1\nMotivation\nI have been engaged in teaching cellular biophysics since 1965. Computer sim-\nulations were first used to teach this material in 1984 and have been used ever\nsince. There is no question in my mind that the use of the software has deepened\nstudents understanding of the subject material. All faculty who have taught the\nsubject, even those who started as skeptics, have been convinced of the ed-\nucational efficacy of the software described here.\nStudents have no basis of\ncomparison of the subject before and after use of the software, but generally\nenjoy using the software and feel that it is helpful, and sometimes crucial, for\nunderstanding the concepts. This book provides a complete description of the\nsoftware including some background material for each topic.\nThe first chapter introduces the software packages and MATLAB, on which\nthe packages are based. The subsequent 6 chapters each describe one of the\nsoftware packages in some detail complete with problems and projects. The last\nchapter is devoted to describing the pedagogical methods we have used to teach\ncellular biophysics using computer simulation. It is aimed at faculty interested\nin using the software for teaching but may be useful for students as well.\n1.2\nOverview Of Software Packages\nThe software for cellular biophysics consists of 6 software packages. The titles\nof the software packages, with acronyms in parentheses, are described briefly\nbelow.\nRandom Walk Model of Diffusion (RW) allows users to select parameters of the\nrandom walks of particles in a field and to observe the resulting space-\ntime evolution of particle location. This package is intended to link the\nmacroscopic laws of diffusion to its probabilistic, microscopic basis.\nMacroscopic Diffusion Processes (MD) allows users to select the initial spatial\ndistribution of solute concentration, the diffusion parameters, and to ob-\nserve the resulting space-time evolution of solute concentration and flux.\nThis package is intended to give users intuition about macroscopic diffu-\nsion processes.\nCarrier-Mediated Transport (CMT) allows users to examine simple models of\ncarrier-mediated transport through cellular membranes. For each of three\nmodels, the user can change any parameter and can instantly see the effect\non the state of the carrier-model.\nThis interactive mode is intended to\nbuild intuition about these models. In addition, there is a graphic mode\nthat allows display of steady-state and transient responses to changes in\nany parameter.\n\n1.3. BRIEF INTRODUCTION TO MATLAB\nHodgkin-Huxley Model -- Space Clamped (HH) allows users to investigate the\nspace-independent Hodgkin-Huxley model. Users can change parameters\nof the Hodgkin-Huxley model of the space-clamped giant axon of the squid,\nand perform simulation experiments in either the voltage-clamp or the\ncurrent-clamp configuration.\nHodgkin-Huxley Model -- Propagated Action Potential (PAP) allows users to in-\nvestigate the space-dependent Hodgkin-Huxley model. Users can change\nparameters of the Hodgkin-Huxley model of the giant axon of the squid,\nand examine propagation of the action potential and of sub-threshold po-\ntentials as a function of space and time.\nVoltage-Gated Ion Channels (IC) allows users to design a voltage-gated ion chan-\nnel. The user selects the number of states, the conductance and gating\ncharge associated with each state, the voltage-dependence of state transi-\ntion rates, and the membrane potential. The user can then perform simu-\nlation experiments on the channel model.\nThese packages are all designed to enhance comprehension of topics in cellular\nbiophysics by providing pedagogic tools that can be used as a basis for lecture\ndemonstration, open-ended problems that lend themselves to classes held in an\nelectronic classroom in which students have access to computers, homework\nproblems, and research projects. Although independent of any textbook, this\nsuite of software packages was developed in parallel with textbooks in cellular\nbiophysics (Weiss, 1996a; Weiss, 1996b).\n1.3\nBrief Introduction To MATLAB\nAll the software packages are written in MATLAB which is an interactive pro-\ngramming environment for numerical and symbolic computations and for visu-\nalization of computational results. Because MATLAB runs on most of the major\ncomputer platforms, the cellular biophysics software operates on all platforms\nsupported by MATLAB. The present version of the software is written on MAT-\nLAB version 5.3 which is available under Windows and UNIX but not under Ma-\ncOS. MATLAB version 5.3 is required to operate this software.1\nThe MATLAB environment is interpretive. That is, commands can be entered\nat a prompt and interpreted within the scope of a MATLAB session. Thus, com-\nputational results generated by a simulation are available to the user for further\nanalysis. The software is designed to perform all the simulations with minimal\ntyped commands. The graphical user interface allows navigation through the\n1Although not tested extensively, the software should run on the Student Version of MAT-\nLAB. However, it may be that parameters can be chosen for these packages which will not\nsatisfy the limitations of the Student Version.\n\nCHAPTER 1. INTRODUCTION\nsoftware using a sequence of mouse events (e.g., clicking the mouse, pulling\ndown a menu, dragging the mouse).\nUsers of the software do not need to learn MATLAB to use the software. How-\never, knowledge of MATLAB can enhance user's usage of the software. A number\nof texts on MATLAB are available (Hanselman and Littlefield, 1997). In addition,\nMATLAB manuals can be ordered directly from MathWorks. Section 1.3.1 is a\nglossary of some useful terms in the MATLAB vocabulary. Section 1.3.2 men-\ntions resources that can provide on-line help with MATLAB.\n1.3.1\nJargon\nThe following terms are useful in navigating in the MATLAB environment.\naxes The area in a figure containing plots and annotation.\nSee the MATLAB\ncommand axes.\nbuttons Rectangular regions allowing a sequence of commands to be executed\nwhen they are clicked, selected, or edited.\nSee the MATLAB command\nuicontrol.\ncommand window The window that appears when MATLAB is started. Com-\nmands entered at the MATLAB prompt (>>) in this window are evaluated in\nthe workspace.\nfigure A rectangular window containing graphical objects, such as axes, buttons,\nand menu items. See the MATLAB command figure.\nMAT-file A binary data file containing MATLAB variables. Each software package\nuses and stores a different set of variables.\nmenubar A bar at the top of a figure (Windows and UNIX implementations) or at\nthe top of the monitor screen (in some implementations) associated with\nthe currently selected figure. When selected, the menu item expands to\nshow its related submenu items.\nSubmenu items marked with a check-\nmark are currently active selections.\nM-file A text file containing a sequence of commands to be evaluated in the\nMATLAB workspace. The software contains a collection of m-files which\ncan be recognized by the extension .m.\nparameters Numeric values that define each model.\npopup-menu A rectangular region showing the current popup-menu selection.\nWhen clicked, the menu is expanded to show all the options. See the MAT-\nLAB command uicontrol.\n\n1.4. GENERAL OPERATION OF THE SOFTWARE\nvariables Numeric values of independent variables set by the user or of depen-\ndent variables calculated from the model.\nworkspace A collection of variables in the current session of MATLAB. When\nMATLAB is started, the workspace is empty. Variables appear in the workspace\nas they are defined.\n1.3.2\nHelp\nHelp on MATLAB is available through the command window using the following\ncommands at the MATLAB prompt (>>)\nwho lists the variables in the current workspace.\nhelp function provides some help on the command function.\nhelp help provides help on getting started using help.\nlookfor word finds functions that involve word.\nAdditional help is available in the descriptions of individual software packages.\n1.4\nGeneral Operation Of The Software\n1.4.1\nDirectory structure\nThe software is designed to be run from a directory that includes the following\nfiles/directories:\ncmt is a directory that contains the carrier-mediated transport software.\nhh is a directory that contains the Hodgkin-Huxley model of a space-clamped\naxon software.\nic is a directory that contains the voltage-gated ion channel software.\nmd is a directory that contains the macroscopic diffusion processes software.\npap is a directory that contains the Hodgkin-Huxley model of a propagating\naction potential software.\nrw is a directory that contains the random walk model software.\nsoftcell.m is a MATLAB m-file that initializes the software and allows the user\nto choose software packages from a menu.\nstartup.m is a MATLAB m-file that may be used to startup the software auto-\nmatically.\n\nCHAPTER 1. INTRODUCTION\nFigure 1.1: This Cellular biophysics\nsoftware figure is displayed when\nthe software is started and shows\nthe\navailable\nsoftware\npackages.\nThe appearance of the menu bar\nnear the top of the figure varies\nsomewhat for the different plat-\nforms. This figure was obtained us-\ning Windows 2000 and MATLAB ver-\nsion 5.3.\ntlib is a directory that contains a library of software routines used by all the\npackages.\n1.4.2\nStarting the software\nThe software is accessible through MATLAB via a menu that allows selection\nof the software packages and initializes all packages. The startup procedure is\ngiven for the different platforms.\nWindows, UNIX, and other operating systems that support MATLAB. Initialize\nMATLAB, and type the following instruction (in the MATLAB window) at the\nMATLAB prompt (>>)\n>> cd directory\nwhere directory is the name of the directory (folder) that houses the cel-\nlular biophysics software.2 Then type\n>> softcell\nThis command displays the Cellular biophysics software figure shown in\nFigure 1.1. Clicking on any package, initializes that package and hides the\nCellular biophysics software figure.\nUNIX workstation on Project Athena at MIT. From the dashboard at the top of\nthe monitor select\nCourseware ⇒\nElectrical Engineering and Computer Science ⇒\n6.021J/6.521J Quantitative Physiology ⇒\nNew MATLAB v5 Software\nThis procedure displays the Cellular biophysics software figure shown in\nFigure 1.1. Clicking on any package, initializes that package and hides the\nCellular biophysics software figure.\n2To verify that the directory is the right one, either type pwd to indicate the name of the\npresent directory or type ls to list the contents of the directory. It should contain the file\nsoftcell.m. If it does not contain this file then either the selected directory is wrong or the\ncellular biophysics software is not installed on your computer.\n\n1.4. GENERAL OPERATION OF THE SOFTWARE\nIf a software package is selected, a number of figures are displayed includ-\ning the XX Control figure, where XX is the acronym of the software package\n(RW, MD, CMT, HH, IC). Clicking on the × in the upper right-hand corner of the\nmenubar, deletes any figure. Clicking on the × in the upper right-hand corner of\nthe menubar of the XX Control figure exits from the software package and results\nin the display of the Cellular biophysics software figure shown in Figure 1.1.\n1.4.3\nQuitting the software\nClicking on the × in the upper right-hand corner of the menubar of the Cellular\nbiophysics software figure exits the cellular biophysics software. Clicking on the\n× in the upper right-hand corner of the menubar of the MATLAB Command\nwindow exits MATLAB.\n1.4.4\nPrinting a figure\nEach figure associated with each package contains a Print button which if pressed\nbrings up a print figure that allows the user to print on any printer on the net-\nwork to which the computer is connected or to store a postscript file of the\nfigure.\n1.4.5\nReading from and saving to a file\nA variety of information about the software can be saved in MAT-files using the\nstandard MATLAB binary file format (see MATLAB's save and load commands).\nFor example, all the packages allow storage of simulation parameters to allow a\nsimulation to be repeated at a later time. In addition, results of simulations can\nalso be saved in files for later retrieval. However, the information stored varies\nfor different software packages, and the individual descriptions of the packages\nshould be consulted for more detailed information.\nA file can be read by pushing the Open button in a figure. A file can be stored\nby pushing the Save button. Pushing either button displays a figure (Figure 1.2)\nthat allows the user to navigate to the desired directory to either read or save a\nfile.\n\nCHAPTER 1. INTRODUCTION\nFigure 1.2:\nSave figure opened\nfrom the HH package using Win-\ndows 2000 and MATLAB 5.3.\n\nChapter 2\nRANDOM WALK MODEL OF\nDIFFUSION\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\n\n2.1. INTRODUCTION\n2.1\nIntroduction\n2.1.1\nHistorical background\nA bolus of soluble material will gradually spread out in its solvent until a uniform\nsolution results. This diffusion process must have been familiar to humans in\nantiquity. However, a mathematical description of these macroscopic changes in\nconcentration was not available until the 1850s (Fick, 1855), and a microscopic\nor particle-level model, not until the turn of this century (Einstein, 1906).\nDiffusion plays an important role in such a wide range of disciplines, that it is\nimportant for students of science and engineering to develop an understanding\nof the macroscopic laws of diffusion and their microscopic basis. We will review\nsome important characteristics of the macroscopic laws of diffusion and their\nrelation to random-walk models. A fuller treatment is available elsewhere (Weiss,\n1996a).\n2.1.2\nMacroscopic and microscopic models\nMacroscopic laws of diffusion\nThe macroscopic laws of diffusion for the simple case when the particles are not\nsubject to a body force, the medium does not convect the particles, the diffusion\ncoefficient is a constant, and the particles are conserved are summarized in one\nand three dimensions in Table 2.1. These equations relate the flux of particles\nEquation\nOne Dimension\nThree Dimensions\nFick's first law\nφ = -D ∂c\n∂x\n\nφ = -D∇c\nContinuity equation\n∂φ\n∂x = -∂c\n∂t\n∇·\nφ = -∂c\n∂t\nDiffusion equation\n∂c\n∂t = D ∂2c\n∂x2\n∂c\n∂t = D∇2c\nTable 2.1: The macroscopic laws of diffusion for a concentration of particles diffusing\nin a homogeneous region with a constant diffusion coefficient D, in the absence of a\nbody force on the particles or convection of the medium, and where the particles are\nconserved.\n(φ), which is the number of moles of particles transported through a unit area in\na unit time, to the concentration of particles (c), which is the number of moles of\nparticles per unit volume. Fick's first law relates flux to particle concentration;\nit is analogous to other laws that relate a flow to a force such as Ohm's law of\nelectric conduction, Darcy's law of convection, and Fourier's law of heat flow.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFick's first law implies that a solute concentration gradient causes a solute flux\nin a direction to reduce the concentration gradient.\nThe continuity equation\nfollows from conservation of particles, and the diffusion equation is obtained by\ncombining Fick's first law with the continuity equation.\nMicroscopic basis of diffusion\nAn important notion in understanding diffusion processes is to relate the macro-\nscopic laws of diffusion to microscopic models of diffusing particles. The sim-\nplest microscopic model that captures the essence of diffusion is the discrete-\ntime, discrete-space random walk. In a one-dimensional random walk in a ho-\nmogeneous region of space, we assume a particle moves along the x-axis in a\nseries of statistically independent steps of length +l or -l, where the time be-\ntween steps is τ. In an unbiased walk, positive and negative steps are equally\nlikely, i.e., each has probability 1/2. It can be shown that statistical averages of\nproperties of a population of particles obey the macroscopic laws of diffusion.\nIn particular, this simple model can be shown (Weiss, 1996a) to yield Fick's first\nlaw with a diffusion coefficient,\nD = l2\n2τ .\nTherefore, the connection between the random walk of a particle and the laws of\nmacroscopic diffusion can be made clear if the motion of a number of particles\n(on the order of 50) can be visualized for a number of steps.\n2.1.3\nOverview of software\nThe software described here is intended to allow users to investigate the prop-\nerties of the simplest microscopic model that captures the essence of diffusion:\nthe discrete-time, discrete-space random-walk model.\nIn the discrete-time, discrete space random walk model described here, there\nis a population of particles which execute statistically-independent, but other-\nwise identical two-dimensional random walks in a rectangular field. The field\ncan be divided into one, two, or three homogeneous regions whose widths are\nspecifiable, and whose properties may differ.\nEach particle undergoes a ran-\ndom walk with parameters that include: the probability that the particle takes\na step to the left or right, and the step size. These parameters can be set in-\ndependently in the three regions. The particles can be set to have a specifiable\nlifetime. One source and one sink of particles can be placed in the field and the\ninitial concentration of particles can be specified in each of the three regions.\nCharacteristics of the boundary conditions between regions can also be speci-\nfied. With this software package it is possible: to visualize the spatial evolution\nof particle concentration from a variety of initial distributions selectable by the\nuser; to examine the evolution of particle concentration from a source and in the\n\n2.2. DESCRIPTION OF THE RANDOM-WALK MODEL\ni\ni +1 i +2\ni -1\ni -2\nj\nj +1\nj +2\nj -1\nj -2\n1 unit\nFigure 2.1: Definition of grid of particle locations. A particle\nis shown at the grid location (i, j). The distance between\nadjacent grid locations, in both the horizontal and vertical\ndirections, is the unit distance.\npresence of a sink; to examine diffusion in regions of differing diffusion coeffi-\ncients; to simulate diffusion of particles subjected to a body force; to simulate\ndiffusion between two compartments separated by a membrane; to investigate\nthe effects of chemical reactions or recombination which consume particles at\na fixed rate; and to investigate the effects of different boundary conditions be-\ntween regions. Two diffusion regimes can be run and displayed simultaneously\nto allow direct comparison between the space-time evolution of two different\ndiffusion processes. In addition, a variety of statistics of the spatial distribution\nof particles can also be displayed.\nBy watching the particles move and by comparing simulation results to ex-\npectations, the user can develop an intuition for the way in which the random\nmotions of particles lead to their diffusive spread.\n2.2\nDescription Of The Random-Walk Model\nIn this simulation, the discrete-time, discrete-space random walk takes place on\na finite two-dimensional grid of locations accessible to the particles and called\nthe field. The location of each particle is specified by giving its coordinates on\nthis grid (i, j) where i is the horizontal coordinate and ranges from 0 to 399 and\nj is the vertical coordinate and ranges from 0 to 99 (Figure 2.1). The horizontal\ndistance between adjacent grid locations is 1 unit of distance and all spatial\ndimensions of the random walk are expressed as multiples of this unit distance.\nThe location of the particle in the grid can change probabilistically at each step\nof the random walk. Thus, successive steps represent successive times that are\nseparated by a unit time interval. All times are expressed in terms of the number\nof steps of the random walk.\nThe field can be divided into one, two or three homogeneous regions (Fig-\nure 2.2). Certain parameters of the simulation are defined for the entire field,\nothers at boundaries between regions, and still others are defined independently\nfor each region. The latter parameters will be described first and include: region\nsize, particle step size, directional probabilities, and initial particle distribution.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nRegion 1\nRegion 2\nRegion 2\nRegion 1 size\nvertical internal\nboundaries\nperimeter boundary:\nvertical\nhorizontal\nFigure 2.2: Definition of simulation field, regions, and boundaries. Solid lines delimit\nthe perimeter boundaries of the field; dashed lines indicate the internal vertical bound-\naries that separate the regions.\n2.2.1\nParticle parameters within a region\nThe parameters that define the random walk are identical at each location within\na region -- each region is homogeneous. These parameters are described below.\nRegion size\nThe width of each region can be specified, but the sum of the widths cannot\nexceed 400. This allows a variety of diffusion regimes to be defined. For exam-\nple, if Region 1 has width of 400 then the other two regions must have width 0\nand the random walk is defined for one homogeneous region. By specifying two\nregions with non-zero widths, it is possible to define a diffusion process with\ndifferent initial conditions in the two regions. This allows a rich variety of initial\ndistributions to be defined. Three non-zero width regions allows simulation of\ndiffusion between two regions separated by a third region with different proper-\nties. This might be used to investigate diffusion between two baths separated by\na membrane.\nStep size\nThe step size defines the distance, in multiples of unit distances, that particles\nmay move in each step of time.\nVarying the step size simulates varying the\ndiffusion coefficient. The size of a region is always set to a multiple of the step\nsize in that region; all particles in a region are located at integer multiples of\nthe step size starting from the left boundary of the region. This ensures that\nparticles at a boundary fall on the boundary and simplifies the specification of\nparticle motion at a boundary.\n\n2.2. DESCRIPTION OF THE RANDOM-WALK MODEL\nstep size\nstep size\nupper left\nupper right\nlower left\nlower right\nexpired\nFigure 2.3: Schematic diagram of motion of a particle in a homogeneous region. The\ngrid of possible particle locations, separated by unit distances, are indicated by + sym-\nbols. A particle is shown in the center of the figure at one instant in time. One time\nstep later the particle either stays in the same location or moves to one of 4 possible\nlocations (indicated by the shaded particle) or it expires (is removed from the field). If\nthe particle moves, it translates one step size (here shown as 2 units of distance) in\nboth the vertical and the horizontal direction.\nParticle motion -- directional probabilities\nAt each instant in time, a particle is at some location in the region. The dis-\nposition of the particle at the next instant in time is determined by one of six\nmutually exclusive and collectively exhaustive possibilities as illustrated in Fig-\nure 2.3. The particle can move one step size to the upper left, upper right, lower\nleft, or lower right; stay in the same location (center); or be eliminated (expire).\nThe probabilities for each of the six outcomes is as follows:\nP[expired]\n=\n1/L ,\nP[center]\n=\n(1 -1/L) (1 -p -q) ,\nP[upper left]\n=\n0.5 (1 -1/L) q ,\nP[upper right]\n=\n0.5 (1 -1/L) p ,\n(2.1)\nP[lower left]\n=\n0.5 (1 -1/L) q ,\nP[lower right]\n=\n0.5 (1 -1/L) p ,\nwhere L is the average lifetime of the particle, i.e. the average number of time\nsteps to expiration; p is the conditional probability that the particle moves to\nthe right given that it has not expired; q is the conditional probability that the\nparticle moves to the left given that it has not expired.\nNote that while the\nprobability of moving to the left and to the right can differ, the probability of\nmoving up or down is always the same. Because the six probabilities define all\nthe possible outcomes at each instant in time, they sum to unity.\nDifferent types of random walks are described by changing the directional\nprobabilities. The random walk defined by assuming p = q = 1/2 is the simple,\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nunbiased random walk described in Section 2.1. In general, if p = q the random\nwalk is unbiased; there is no statistical tendency for particles to move preferen-\ntially in either horizontal direction. However, if p =q, the random walk is biased\nso that there is a tendency for particles to move in one horizontal direction. For\na step size of S, the mean distance E[m] that the particle moves to the right in\nn units of time is\nE[m] = Sn(1 -1/L)(p -q) .\n2.2.2\nBoundary conditions\nThe field contains three different types of boundaries (Figure 2.2) which are, in\norder of increasing complexity, horizontal perimeter boundaries at the top and\nbottom of the field, vertical perimeter boundaries at the left and right ends of\nthe field, and vertical internal boundaries that separate regions.\nHorizontal perimeter boundaries\nHorizontal perimeter boundaries act as perfectly reflecting walls. If a particle\nis located within one step size of such a boundary and takes a step toward\nthe boundary then the new vertical location of the particle is determined in the\nfollowing manner: the vertical distance the particle travels to reach the wall plus\nthe vertical distance the particle travels after reflecting from the wall must sum\nto the step size. This relation determines the new location given the old location\nand the value of the step size.\nVertical perimeter boundaries\nThe vertical perimeter boundaries are also reflecting walls. Because the prob-\nabilities of stepping to the left and right need not be the same, we found that\npurely reflecting wall of the type described for the horizontal perimeter bound-\naries created undesirable artefacts especially when the conditional probabilities\nof moving to the left and right were not equal (p =q). Therefore, we modi-\nfied the boundary condition so that a particle that would have crossed a vertical\nperimeter boundary at a given step was placed on the boundary and then subject\nto the following boundary condition which is illustrated for the left boundary in\nFigure 2.4 and whose directional probabilities are:\nP[expired]\n=\n1/L ,\nP[center]\n=\n(1 -1/L) (1 -p) ,\n(2.2)\nP[upper right]\n=\n0.5 (1 -1/L) p ,\nP[lower right]\n=\n0.5 (1 -1/L) p ,\ni.e. the particle cannot move to the left.\n\n2.2. DESCRIPTION OF THE RANDOM-WALK MODEL\nstep size\nstep size\nupper right\nlower right\nexpired\nleft vertical\nperimeter\nboundary\nFigure 2.4:\nSchematic diagram of mo-\ntion of a particle at a vertical perimeter\nboundary.\nFor purposes of illustration\nthe particle motion at the left boundary\nis shown. Conditions at the right bound-\nary are the mirror-image of those shown\nhere.\nstep size in\nright region\nstep size in\nleft region\nstep size in\nright region\nupper left\nupper right\nlower left\nlower right\nexpired\nleft region\nright region\ninternal vertical\nboundary\nFigure 2.5: Schematic diagram of mo-\ntion of a particle at an internal vertical\nboundary between two regions.\nThe\nstep size is 1 to the left of the bound-\nary and 2 to the right of the boundary.\nVertical internal boundaries\nThe motion of particles at a vertical internal boundary is similar to that within\na homogenous region. The differences are that: the step sizes in the two ad-\njacent regions may differ; and special directional probabilities, specified by the\nuser, apply at the boundary. These have been provided to allow users to explore\nthe consequences of a rich variety of boundary conditions. To simplify boundary\nconditions, the software ensures that particles do not cross this boundary in one\ntime step but rather they land on the boundary. This is guaranteed by forcing\nthe width of boundaries, initial particle locations, locations of sources and sinks\nto be commensurate with the step size. Given this restriction, the possible out-\ncomes for a particle on a boundary are shown schematically in Figure 2.5. The\ndirectional probabilities are identical to those in a homogeneous (region given\nabove) except that the conditional probability of moving to the left and to the\nright given that the particle did not expire (p and q in the homogeneous region)\nare independently specified at each internal boundary. The step size to the left\nis equal to the step size in the region to the left of the boundary; the step size\nto the right is equal to the step size in the region to the right of the boundary.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.6: The RW Control figure.\n2.3\nUser's Guide To The Software\nWhen this software package is selected, 2 figures are displayed (in addition to\nMATLAB's command window) -- RW Control and RW Particle set #1.\n2.3.1\nRW Control\nThe RW Control figure controls the random walk software and is shown in Fig-\nure 2.6. The part of the RW Control figure below the menubar is divided into two\npanels. The left panel indicates which of the two independent simulations are to\nbe displayed -- the choices are Particle Set #1 and/or Particle Set #2. When RW\nis selected, Particle Set #1 is selected by default.\nThe right panel allows the simulation to be started, paused, continued, or\nreset. If Reset is chosen, the step counter is set to 0 and the particle locations\nare reset to their initial locations. The # steps in the random walk before the\nsimulation pauses can be entered in the text edit box. Clicking 1-step executes\none step of the random walk. A counter for the current number of steps in the\nrandom walk is displayed.\n2.3.2\nRW Particle\nThe RW Particle figure shows the locations of particles in the field as shown for\nan initial distribution of particles in Figure 2.7. When the simulation is started\nby clicking the Start button in the RW Control figure, the random walks of the\nparticles are exhibited in the RW Particle figure. A step counter indicates the\nnumber of steps taken in the random walks.\nAfter 100 steps of the random\nwalks of particles, the RW Particle figure is as shown in Figure 2.8.\nSeveral options are provided in the RW Particle figure. The user can select\nParam to change the parameters of the random walk, Summ to obtain a numer-\nical summary of statistics of the random walk, Hist to obtain a histogram of\nparticle positions, and Graphs to obtain plots of statistics versus step number.\nThese options are described in detail below. The RW Particle figure also has op-\ntions to Open a file that contains a particle distribution, Save the current particle\ndistribution in a file, and Print the current figure. Clicking on Save saves the fol-\nlowing: the current state of all the particles including the expected locations of\nparticles, the histogram binwidth, the step #, and all the parameters.\n\n2.3. USER'S GUIDE TO THE SOFTWARE\nFigure 2.7: RW Particles figure showing the initial locations of particles. Initially there\nare 50 particles located at position 200 and spread randomly with a uniform distribu-\ntion in the vertical direction.\nFigure 2.8: RW Particles figure showing the locations of particles after a 100 step ran-\ndom walk for the initial locations of particles shown in Figure 2.7.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.9: RW Parameters figure showing the parameters used to define the simula-\ntions whose particle distributions are shown in Figures 2.7 and 2.8.\nRW Parameters\nChoosing Param in the RW Particles figure displays the RW Parameters figure,\nshown in Figure 2.9, which allows selection of the parameters of the simulation.\nRegion #1 is indicated in blue in both the RW Parameters figure and in the RW\nParticle figure; magenta is used for region #2 and green for region #3. After new\nparameters are chosen, clicking on Update resets the initial distribution to the\nnewly selected one and activates all the new parameters. The parameters are\ndescribed below. In addition, the parameters (alone) can be saved in a file (by\nclicking on Save) or read from a file (by clicking on Open).\n- Region Size. The user may define up to three regions, whose combined\nwidth may not exceed 400. To eliminate a region, enter 0 for the region\nsize. Regions can also be of size k(stepsize) where k = 3, 4, 5, .... That is,\nregions of size stepsize and 2(stepsize) are not allowed.\n- Step Size. The step size can be specified independently in each region.\n- Initial Distribution Of Particles. The initial distribution of particles can\nbe specified independently in the three regions. Particles start at locations\nthat are integral multiples of the step size in each region.\nParticles are\ndistributed randomly (with a uniform distribution) in the vertical direction\nand have the selected distribution in the horizontal direction. The initial\ndistribution of particles can be selected to be one of the following.\n\n2.3. USER'S GUIDE TO THE SOFTWARE\n- Empty implies that initially there are no particles in the region.\n- Pulsatile implies that a specified number of particles are placed at\na specified horizontal location in the region and spaced randomly in\nthe vertical direction. Figure 2.7 shows an initial distribution that is\npulsatile.\n- Linear implies that a linear concentration profile is generated whose\nslope and number of particles are specified. A uniform distribution of\nparticles is obtained if the slope is set to zero. Negative concentrations\nare not allowed: if the parameters are chosen such that the concentra-\ntion would become negative at some point in the region, these putative\nnegative concentrations are set to zero.\n- Sinusoidal implies that the spatial distribution is sinusoidal with a\nspecified period and number of particles.\n- Right Step Prob. The conditional probability of a step to the right given\nthat the particle has not expired can be specified independently in each\nregion.\n- Left Step Prob. The conditional probability of a step to the left given that\nthe particle has not expired cannot be specified. It is set automatically so\nthat in each region, the sum of the probabilities of all possible outcomes is\none.\n- Stay Prob. The conditional probability that the particle stays in the same\nlocation given that the particle has not expired can be specified indepen-\ndently in each region.\n- Probabilities at Boundaries.\nThe perimeter boundaries of the field act\nas reflecting boundaries; the boundaries between regions are characterized\nby user-defined boundary conditions. Boundary conditions are defined as\nshown in Figure 2.9: left-step-probability L, stay probability S , and right-\nstep-probability R at the boundary between regions. For example, if the\nRegion #1-#2 has the set of probabilities (L, S, R) = (0, 0, 1) then particles\nat the boundary may only step to the right. Therefore, to a particle from Re-\ngion #2, this looks like a reflecting boundary, whereas all particles reaching\nthe boundary from Region #1 will cross into Region #2. As with the direc-\ntional probabilities within a region, the user selects the conditional (on not\nexpiring) probability of a step to the right and the conditional probability\nof no step; the conditional probability of a step to the left is then computed\nso that probabilities of all possible outcomes sum to one.\n- Source. One source can be placed at a horizontal location in the field and\ncovers the entire vertical height of the field. The source must be located at\nan integer multiple of the step size from the left boundary of each region\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.10:\nRW Summary figure\nshowing a numerical summary of\nstatistics after a 100 step random\nwalk for the same parameters as\nshown in Figure 2.9 and for the ini-\ntial locations of particles shown in\nFigure 2.7.\nin which it is located. The rate of generation of particles is specified by\ngiving the number of particles (specified as a two-digit number) produced\nin some number of time steps (specified as a two-digit number). Thus the\nrate of generation of particles can be a rational number.\nThe particles\nare generated at the horizontal location of the source and are distributed\nrandomly along the vertical direction using a uniform distribution. When\nthe source is turned on, a small + is placed at the horizontal location of\nthe source just above the field.\n- Sink. A sink can be placed at a horizontal location in the field and covers\nthe entire vertical height of the field.\nThe sink is located at an integer\nmultiple of the step size from the left boundary of each region in which it\nis located. Particles that land on the sink are absorbed; hence the number\nof particles at the sink is always zero. When the sink is turned on, a small\n-is placed at the horizontal location of the sink just above the field.\n- Average Lifetime. The user may define the average particle lifetime de-\nfined as the number of steps it takes, on average, for the particle to expire.\nRW Summary\nChoosing Summ in the RW Particles figure pauses the simulation and displays\nnumerical values of statistics in the RW Summary figure as shown in Figure 2.10.\nTwo sets of computations are performed simultaneously during a simulation:\nstatistics based on the actual locations of particle and statistics based on the\nexpected locations of particles. Given a particle location at one step and a set\nof directional probabilities, a random number generator is used to determine\nwhich of the possible new locations occurs at the next step. These sequence\nof locations determines the locations of the particles on the screen and all the\nstatistics labelled actual. However, given a particle location at one time and the\n\n2.3. USER'S GUIDE TO THE SOFTWARE\nsame directional probabilities, an expected location of the particle in the next\nstep is also computed.\nThus, during a simulation both the set of actual and\nexpected locations for the particles are computed and can be displayed.\nThe available statistics (both actual and expected) are as follows.\n- Mean is the mean location of the particles in the entire field.\n- Standard Deviation is the standard deviation of particle location in the\nentire field.\n- #Generated is the cumulative number of particles generated by the source\nsince the beginning of the simulation.\n- #Absorbed is the cumulative number of particles absorbed by the sink\nsince the beginning of the simulation.\n- #Expired is the cumulative number of particles lost (due to their finite\nlifetimes) since the beginning of the simulation.\n- Total #Particles is the total number of particles in the entire field at each\nstep number.\n- Region 1 #Particles is the total number of particles in Region 1 at each\nstep number.\n- Region 2 #Particles is the total number of particles in Region 2 at each step\nnumber. For this total only, the particles located at the boundary between\nRegion 1 and Region 2 are counted as belonging to Region 2.\n- Region 3 #Particles is the total number of particles in Region 3 at each step\nnumber. For this total only, the particles located at the boundary between\nRegion 2 and Region 3 are counted as belonging to Region 3.\nRW Histogram\nChoosing Hist in the RW Particles figure pauses the simulation and displays the\nRW Histogram figure (Figure 2.11).\nHistograms summarize the spatial distri-\nbution of particle locations; both the actual and the expected distribution of\nparticle locations are shown. Each histogram consists of a set of bins that spans\nthe field in the horizontal direction; the number of bins depends upon the spec-\nification of the bin size. With a bin size of 16, there are 25 bins that span the\nentire field of 400 locations. The histogram shows the number of particles in\neach bin as a function of bin location. Choice of bin size is important. A small\nbin size depicts the particle distribution with high spatial resolution. However,\na small bin size implies that each bin will contain relatively few particles and the\nnumber of particles will fluctuate randomly from bin to bin. Conversely, a large\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.11: RW Histogram figure showing a histogram of particle locations after a 100\nstep random walk for the same parameters as shown in Figure 2.9 and for the initial\nlocations of particles shown in Figure 2.7. The histogram is for the particle locations\nshown in Figure 2.8.\nFigure 2.12: RW Axis figure showing options\nfor changing axis properties.\nbin size gives a histogram with poor spatial resolution but a larger amount of\nstatistical averaging of the spatial distribution of particles.\nThe shape of the histogram is sensitive to the choice of bin size and can lead\nto confusing patterns. For example, suppose the bin size is five and the step\nsize is two. Suppose further that particles are located uniformly in the field; one\nparticle per accessible location. However, the step size constrains the possible\nlocations that a particle may occupy to be separated by 2. Therefore, with a bin\nsize of five, successive bins in the histogram alternate between 2 and 3 particles.\nThus the histogram will not appear uniform, but oscillatory. This problem is\ncured if the bin size is an integral multiple of the step size. If the step sizes\ndiffer in the three regions, then the bin size should be set equal to the least\ncommon multiple of the three step sizes.\nClicking on either the ordinate or the abscissa axis label displays the RW Axis\nfigure (Figure 2.12) that allows the user to change the axis scale. The scale is\nindicated by a vector [min max] in which min represents the minimum value and\nmax represents the maximum value of the range. Clicking on Log makes the axis\nscale logarithmic.\n\n2.3. USER'S GUIDE TO THE SOFTWARE\nFigure 2.13: RW Graph figures showing the mean (above) and the standard deviation\n(below) of particle location versus step number for the same parameters as shown in\nFigure 2.9 and for the initial locations of particles shown in Figure 2.7.\nRW Graph\nChoosing Graphs in the RW Particles figure pauses the simulation and displays\nthe RW Graph figure. The temporal evolution of any of the summary statistics\nshown in Figure 2.10 can be plotted versus the step number. Figure 2.13 shows\nan example of both the mean and the standard deviation of particle locations\nplotted versus step number. Clicking on either the ordinate or the abscissa axis\nlabel displays the RW Axis figure that allows the user to change the axis scale (as\nin Figure 2.12).\nThese statistics allow a quantitative evaluation of simulation results. We give\na number of examples of the use of these statistics.\nA systematic change in\nthe mean location of the particles as a function of step number demonstrates a\ndrift or migration of the particles as can be achieved by a bias in the directional\nprobabilities. A difference in the standard deviation of two distributions can\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nbe achieved by changing the step size. The dependence on step number of the\nnumber of particles in the field, in a region, generated, absorbed, or expired can\nbe used to assess whether a particle distribution has reached steady state. The\nchange in the total number of particles in each region can be used to estimate\nthe rate of transport of particles between regions.\n2.4\nProblems\nProblem 2.1 The purpose of this problem is to explore random walks from an\ninitial distribution where all particles begin from the same horizontal location.\na. Use the default simulation parameters with a pulsatile initial distribution\nof particles but set the step size to 2 and 4 for Particle Sets #1 and #2,\nrespectively. The parameters of Particle Sets #1 and #2 should differ only\nin step size.\nRun the simulation for 100 steps.\nExamine graphs of the\nmean and the standard deviation of the horizontal locations of the particles\nversus step number.\ni. Explain quantitatively the differences in the graphs in terms of the\ndifference in step size of the two simulations.\nii. Why does the slope of the standard deviation decrease with step num-\nber? What type of dependence on step number do you expect? Explain.\n[Hint -- You may wish to replot the graph in different coordinates to\ncheck out your expectations.]\nb. Now set the step size to 2 for both simulations and decrease the number\nof particles in the pulsatile initial distribution for one of the simulations\nto 25. Rerun the simulation. Describe how the number of particles affects\nthe dependence of mean location and standard deviation on step number?\nExplain your results.\nc. Set all the parameters at their default values and then set the step size\nfor both Particle Sets #1 and #2 to 2. For Particle Set #1 set the right step\nprobability to 0.75, the left step probability to 0.25, place an impulse of 50\nparticles at location 100. For Particle Set #2 set the right step probability\nto 0.25, the left step probability to 0.75, place an impulse of 50 particles\nat location 300. Run the simulation for at least 100 steps. Examine graphs\nof the mean and the standard deviation of the horizontal locations of the\nparticles versus step number. Explain your results quantitatively.\nProblem 2.2 The purpose of this problem is to explore the steady-state distribu-\ntion of particles in the presence of a source and sink for both unbiased and biased\nrandom walks. For all parts of this problem set the parameters for both Particle\n\n2.4. PROBLEMS\nSets #1 and #2 as follows: make the size of Region #1 400; the step size 20; and\nmake the initial distribution of particles empty. Also place a source at location\n0 and a sink at location 400 and make the histogram bin size 20.\na. Make the random walks for both Particle Sets #1 and #2 unbiased with a\nright step probability of 0.5. For Particle Set #1 make a source that gen-\nerates 1 particle every 2 steps and for Particle Set #2 make a source that\ngenerates 1 particle every 1 step. Make the particle lifetime infinite for both\nsimulations. Now run the simulation. In the steady-state, by definition the\nparticle distribution will not depend upon step number.\ni. Before you run the simulation, estimate the form of the steady-state\nparticle distribution. Will it be uniform, exponential, pulsatile, linear,\nGaussian, or none of these?\nii. Using the available statistics, determine a criterion for estimating when\nthe particle distribution is in steady state.\niii. Now run the simulation until your criterion for steady state is met.\nLook at the histograms of particle location. What is the steady-state\nparticle distribution? Does it fit with your initial expectation? There\nare differences between the actual and expected histograms. Explain\nthese differences.\niv. How can you explain the difference in steady-state distribution for\nParticle Sets #1 and #2?\nv. Show that the steady-state particle distribution you have found for the\nrandom walks is consistent with Fick's laws.\nb. Use the same parameters for Particle Set #2 as in part a, but change those\nof Particle Set #1 so that the source rate is also 1 particle every 1 step; and\nso that the probability of a right step is 0.55. Run the simulation until it\nhas reached a steady state.\ni. Compare the steady-state distributions for the biased and unbiased\nrandom walks. How do they differ?\nii. Describe the shape of the steady-state distribution for the biased ran-\ndom walk?\niii. Modify Fick's first law to account for not only diffusion of particles but\na steady drift of particles of velocity v. Determine the steady-state\ndistribution of particles predicted from Fick's laws and the continu-\nity equation in the presence of this steady drift of particles. Is this\ndistribution consistent with the simulation results you obtained?\nc. Keep the parameters of Particle Sets #1 and #2 the same as in part b, but\nchange the right step probability of Particle Set #2 to 0.48.\nExplain the\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\ndifferences in the shapes of the steady-state distributions for the two sim-\nulations.\nProblem 2.3 The purpose of this problem is to explore the effect of a finite particle\nlifetime on the statistics of a random walk.\na. Define a simulation with an initial particle distribution that is uniformly\ndistributed in space.\nSet the average particle lifetime to be finite.\nRun\nthe simulation until all the particles have expired. Examine a graph of #\nparticles versus step number. Explain the shape of this function.\nb. Define another simulation that is identical with the one in part a, but this\ntime with a source of particles. Do you expect a steady state to be reached\nbetween the the source and expirations? Determine a criterion for steady\nstate and check out your intuition.\nc. Design a combination of source rate and lifetime such that the distribution\nreaches a steady state.\nThis might correspond, for example, to a drug\nconcentration reaching steady state in the body, as it is both infused and\neliminated.\nd. Design a combination of source rate and lifetime such that most particles\nin the region have expired by the time the source injects the next batch.\nThis might correspond to the drug concentration when the dosing interval\nis longer than the elimination half-life of the drug.\nProblem 2.4 The purpose of this problem is to explore random walks in three\nregions which simulates diffusion through a membrane that separates two baths.\nSet up the parameters as shown in Figure 2.14. For both simulations, the two end\nregions contain uniform concentrations of particles; but the number of particles\ndiffers. There is a concentration difference between the end regions as shown\nin Figure 2.15 for one of the simulations; the other is similar. The center region\ncan be regarded as a membrane that separates the two end regions and initially\ncontains no particles. The random walk in the membrane region is unbiased in\none simulation and biased in the other. Run the simulation for several hundred\nsteps.\na. Explain the differences between the distributions of particles for the two\nsimulations.\nb. Quantitatively describe the flux of particles between the two end compart-\nments -- both the magnitude and sign of the flux.\nc. What physical process might be represented in the simulation with Particle\nSet #2?\n\n2.4. PROBLEMS\nFigure 2.14: Parameters for a random walk in 3 regions (Problem 2.4).\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\nFigure 2.15: Initial locations of particles for a random walk in 3 regions (Problem 2.4).\nProblem 2.5 The purpose of this problem is to explore random walks in three\nregions which simulates diffusion through a membrane that separates two baths.\nDesign a three region diffusion regime where the center region is considered\nto be a membrane. Design membrane characteristics such that the membrane\nis transparent for particles moving from left to right but purely reflecting for\nparticles moving from right to left. Test your design by running the simulation.\nProblem 2.6 The purpose of this problem is to examine the steady-state particle\ndistribution that results in the presence of sources and sinks. Start with two iden-\ntical simulations with Regions #1 and #2 that have: a region size of 400; a step\nsize of 2; unbiased random walks; no sources or sinks; infinite particle lifetimes;\nand sinusoidal initial particle distributions. Choose one simulation with a period\nof 200 and the other with a period of 50. Choose an appropriate bin size for the\nhistograms. Run the simulation.\na. What is the shape of the equilibrium distribution of particles?\nb. Which particle distribution approaches this equilibrium faster?\nc. Experiment with different frequencies and generalize your conclusion from\npart b.\nProblem 2.7 The purpose of this problem is to examine the factors that influence\nthe equilibrium distribution of particles and the time to reach equilibrium. This\nproblem deals with a random walk in two regions. Make the size of Regions #1\nand #2 each 50 steps wide and set the step size to 5 in each region. Let the initial\ndistribution of particles in Region #1 be 50 particles distributed uniformly and\n\n2.4. PROBLEMS\nlet the initial distribution of particles in Region #2 be empty. Run the simulation\nuntil equilibrium is reached. Plot the number of particles in Regions #1 and #2\nas a function of step number.\na. Estimate the initial Ni and final Nf values of the number of particles in\neach region and explain these values.\nb. Define the \"equilibrium time\" τ as the time taken for the number of parti-\ncles to change from 0.1|Nf -Ni| to 0.9|Nf -Ni| and estimate the value of\nτ for both Regions #1 and #2.\nc. The region size affects the time course of particle number in each region.\nRun simulations with the size of Regions #1 and #2 set to 25 steps and to\n100 steps and measure Ni, Nf, and τ for each value of region size. How\ndo Ni, Nf, and τ depend upon regions size for the three sizes used in your\nsimulations? Explain.\nd. Assume that the probabilities for steps are unchanged, which other RW\nparameters will affect the time course of particle number in each region?\nIndicate how the parameter will affect the time course and test your sug-\ngestion by performing appropriate simulations and measuring Ni, Nf, and\nτ.\n\nCHAPTER 2. RANDOM WALK MODEL OF DIFFUSION\n\nChapter 3\nMACROSCOPIC DIFFUSION PROCESSES\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\n3.1\nIntroduction\n3.1.1\nBackground\nDiffusion is an important transport process in physical, chemical, and biolog-\nical systems. Two theoretical models of diffusion capture complementary as-\npects of the phenomenon. The microscopic model describes the probabilistic\nbehavior of a population of individual solute particles which execute statisti-\ncally independent, but otherwise identical, random walks. Software dealing with\nsuch a microscopic model of diffusion is described in Chapter 2. The software\ndescribed in this chapter involves macroscopic diffusion which describes the\naggregate behavior of large populations of solute particles.\n3.1.2\nMacroscopic model of diffusion\nIn 1855, Adolph Fick proposed a macroscopic model for passive diffusion (Fick,\n1855). By analogy to Fourier's law of heat conduction and Ohm's law for elec-\ntrical conduction, Fick proposed that the flux of solute at a point in space is\nproportional to the concentration gradient at that point. Mathematically, this\nrelation is expressed by Fick's first law, which, in its one-dimensional form, is as\nfollows:\nφ = -D ∂c\n∂x ,\n(3.1)\nwhere c(x, t) is the solute concentration and φ(x, t) is the solute flux.\nThe\nconstant of proportionality, D, is known as the diffusion coefficient. Conservation\nof solute (in the absence of sources or sinks or of chemical reactions that create\nor destroy solute) results in a second relation between concentration and flux,\nthe continuity equation:\n∂φ\n∂x = -∂c\n∂t .\n(3.2)\nDifferentiating both sides of Equation 3.1 with respect to x and using the con-\ntinuity equation yields Fick's second law, or the one-dimensional diffusion equa-\ntion:\n∂c\n∂t = D ∂2c\n∂x2\n(3.3)\nIn principle, any one-dimensional diffusion process can be modelled by solving\nthis equation subject to the appropriate initial conditions and boundary condi-\ntions.\nWe next consider the same problem but with two changes: (1) a body force\nacts uniformly on the solute so that it drifts (migrates) and (2) a chemical reac-\ntion occurs that removes solute. The solute flux, φ(x, t), is now the sum of the\ndiffusive flux, given by Fick's law, and the flux due to drift. Thus, in this case,\nφ = -D ∂c\n∂x + vc,\n(3.4)\n\n3.1. INTRODUCTION\nwhere v is the drift velocity of the solute; i.e., the velocity of the solute in re-\nsponse to the body force in the absence of diffusion. If r is the reaction rate at\nwhich solute is removed, then the continuity equation becomes\n∂φ\n∂x = -∂c\n∂t -rc.\n(3.5)\nCombining these expressions yields a modified diffusion equation:\n∂c\n∂t = D ∂2c\n∂x2 -v ∂c\n∂x -rc.\n(3.6)\nThus, solute drift and a chemical reaction that removes solute contribute addi-\ntional terms to the diffusion equation.\nIf the initial concentration, c(x, 0) is known in some region of space and if the\nrelation between the concentration and flux is known at each boundary of this\nregion, then a unique solution exists for t > 0. Given an initial concentration\nprofile, c(x, 0), Fick's laws govern the unique evolution of the concentration\nprofile for all later times.\n3.1.3\nOverview of software\nWhile macroscopic diffusion has been successfully modelled by Fick's equations,\nstudying the equations alone provides only limited insight into the behavior of\ndiffusion processes.\nThe goal of this software is to help users gain intuition\nabout diffusion in one dimension. The solutions to the diffusion equation are\nfunctions of two variables: one spatial variable, x, and time, t. These solutions\ncan be plotted either as a function of time at a particular point in space or as a\nfunction of the spatial variable at a particular instant in time. Such isolated snap-\nshots, however, do not fully convey the dynamic behavior of diffusion processes.\nWith this software, the user can view the temporal evolution of the solute con-\ncentration and solute flux as a function of position. Thus, the software enables\nthe user to gain intuition about the dynamic behavior of macroscopic diffusion\nprocesses.\nFurthermore, the software provides an opportunity for users to experiment\nwith the macroscopic diffusion processes. For example, the user can explore\nhow changing the diffusion coefficient affects the time-course of the simulation.\nThe user can also specify transparent or reflecting boundaries and can explore\nhow a body force acting on the solute or a chemical reaction that removes solute\ninfluence the diffusion process. Thus, the software can be used as a tool for in-\nvestigating how various parameters and boundary conditions influence diffusion\nprocesses.\nFive options for initial concentration profiles, corresponding to five charac-\nteristic diffusion problems, are implemented in the software (Figure 3.1). Four\nof these problems involve diffusion from a specified initial concentration profile\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nInitial concentration\nImpulse\nSinusoid\nDiscontinuity\nArbitrary\nBath 1 M\nBath 2\nPosition\nPosition\nTwo compartment\nFigure 3.1: Schematic representation of the five classes of initial concentration profiles\nsimulated by the software. M designates the membrane.\nin a one-dimensional region of space (which may be infinite in extent), while the\nfifth involves diffusion between two finite, well-mixed compartments separated\nby a membrane.\nOne-dimensional diffusion\nIn one-dimensional diffusion, the initial concentration can be chosen to be one\nof four options: impulses, sinusoids, discontinuities, and an arbitrary spatial\ndistributions. An impulse of solute concentration is a mathematical idealization\ncorresponding to a finite amount of solute initially concentrated at a single point\nin space. In the impulses option, the user can specify the magnitude and posi-\ntion of up to four impulses. This option illustrates diffusion from point sources.\nThe sinusoids option illustrate the spatial frequency response of a system gov-\nerned by the diffusion equation, specifically, the low-pass spatial filtering effect\nof diffusion. By superimposing up to four sinusoids, the user can observe the de-\npendence of the space-time evolution of concentration on its spatial frequency\ncontent. In the discontinuities option, the initial concentration profile may be\npiecewise-constant but contain discontinuities. The user can specify the magni-\ntude and location of up to four such discontinuities. For example, this allows\nsimulation of the diffusion that results from an initial rectangular pulse of so-\nlute concentration. The user can also explore the response for more complicated\ninitial conditions which can be specified by drawing an arbitrary initial concen-\ntration on the monitor screen with a mouse.\n\n3.2. METHODS OF SOLUTION\nFor these different initial distributions, the user can specify the boundary\ntype (transparent or reflecting), the value of the drift velocity, and the chemical\nreaction rate at which solute is removed.\nTwo-compartment diffusion through a membrane\nThe baths are assumed to be well-stirred, so that the concentration within each\nbath varies with time but not with position in the bath. The total amount of\nsolute in the system is assumed to be finite. The user can specify the width of\neach bath and of the membrane, the initial concentration of each bath, and an\narbitrary initial concentration profile in the membrane.\n3.2\nMethods of Solution\nFor several of the diffusion problems implemented in the software, analytic so-\nlutions of the modified diffusion equation (Equation 3.6) are available in a form\nthat makes computation efficient. Such solutions have been used wherever pos-\nsible. The remainder of the solutions were obtained by numerical methods. The\nmethods are described in some detail elsewhere (Berkenblit, 1990); only a brief\nsummary of the methods is given here.\nThe method used to obtain solutions depends upon the type of boundary\ncondition. Two types of boundary conditions for the diffusion problems can be\nselected by the user: transparent\nor reflecting boundary conditions. If trans-\nparent boundaries are specified, then the region over which diffusion occurs is\ninfinite; the spatial limits of the region over which diffusion is displayed are\nset by the user. At a reflecting boundary, on the other hand, the solute flux is\nconstrained to be zero, since no solute particles can cross such a boundary.\n3.2.1\nAnalytic solutions\nAnalytic solutions were used to compute the response for all one-dimensional\ndiffusion problems with transparent boundaries.\nThese are described in this\nsection.\nImpulse response -- Green's function\nNo drift, no chemical reaction.\nFirst, we consider the case when the drift ve-\nlocity is zero and the chemical reaction rate is zero. Let the initial concentration\nbe a unit impulse located at position x = ξ and delivered at time t = 0,\nc(x, 0) = δ(x -ξ).\n(3.7)\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nThe solution of the diffusion equation (Equation 3.3), called the Green's function\nG(x, t; ξ, 0), is\nc(x, t) = G(x, t; ξ, 0) =\n√\n4πDt e-(x-ξ)2/4Dt.\n(3.8)\nThus, the concentration profile is a Gaussian function of the spatial variable.\nThe standard deviation of the concentration,\n√\n2Dt, increases with increasing\ntime, but the total area of the concentration remains constant because solute is\nconserved.\nDrift but no chemical reaction.\nWe next consider the same problem but with\na non-zero drift velocity. In this case, the concentration satisfies the modified\ndiffusion equation, Equation 3.6, with r = 0:\n∂c\n∂t = D ∂2c\n∂x2 -v ∂c\n∂x ,\n(3.9)\nwith the initial condition\nc(x, 0) = δ(x -ξ).\n(3.10)\nThe solution can be shown to be\nc(x, t) =\n√\n4πDt e-(x-ξ-vt)2/4Dt = G(x -vt, t; ξ, 0).\n(3.11)\nThus, the response in this case is a Gaussian function, as before, but the entire\nprofile drifts in the positive x-direction with drift velocity v.\nDrift and chemical reaction.\nWith a non-zero chemical rate, r, and drift veloc-\nity, v, we need to solve Equation 3.6 which has a solution\nc(x, t) = e-rtG(x -vt, t; ξ, 0).\n(3.12)\nIn general, if c′(x, t) is the solution to Equation 3.3, with a specified initial con-\ncentration profile and transparent boundaries, then the solution to the modified\nequation, 3.6, satisfying the same initial conditions, is given by\nc(x, t) = e-rtc′(x -vt, t).\n(3.13)\nSinusoid\nFirst we consider the solution to Equation 3.3 with the initial condition\nc(x, 0) = A (1 + sin(ωx + θ))\n(3.14)\n\n3.2. METHODS OF SOLUTION\nfor some arbitrary constant amplitude, A, spatial radian frequency, ω, and phase\nangle, θ. The solution for t > 0 is given by\nc(x, t) = A\n\n1 + e-Dω2t sin(ωx + θ)\n\n,\n(3.15)\nwhich can be verified by substituting this expression into Equation 3.3. Thus,\nan initially sinusoidal concentration profile remains sinusoidal for all later time,\nbut the amplitude decreases exponentially with time. The rate of attenuation is\nproportional to the square of the spatial frequency.\nWith drift and a chemical reaction between solute and solvent, the solution\nis\nc(x, t) = Ae-rt\n1 + e-Dω2t sin\n\nω(x -vt) + θ\n\n,\n(3.16)\nwhere v is the drift velocity and r is the reaction rate.\nDiscontinuous initial profile\nWe next consider the case of an initial profile that is piecewise-constant but\ncontains a jump discontinuity at x = ξ. The initial condition is that\nc(x, 0) =\n\ncL,\nx < ξ\ncR,\nx > ξ ,\n(3.17)\nwhich can also be written as\nc(x, 0) = cL + (cR -cL)\ninf\nξ\nδ(x -x′) dx′.\n(3.18)\nFor t > 0, we can integrate the Green's function defined by Equation 3.8 to obtain\nthe solution:\nc(x, t)\n=\ncL + (cR -cL)\ninf\nξ\nG(x, t; x′, 0) dx′\n=\ncL + (cR -cL)\ninf\nξ\n√\n4πDt e-(x-x′)2/4Dt dx′\n=\ncL + (cR -cL)\n\n1 -1\n2erfc\nx -ξ\n√\nDt\n\n,\n(3.19)\nwhere the complementary error function, erfc(x), is defined by the integral\nerfc(x) =\n√π\ninf\nx\ne-t2 dt.\n(3.20)\nWith a drift velocity, v, and reaction rate, r, the solution is\nc(x, t) = cLe-rt + (cR -cL)e-rt\n\n1 -1\n2erfc\nx -vt -ξ\n√\nDt\n\n.\n(3.21)\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\n3.2.2\nNumerical Solutions\nOne-dimensional problems with reflecting boundaries and the two-compartment\nproblem are solved using numerical methods. To solve a diffusion problem nu-\nmerically over some specified spatial region and some specified time interval,\nthe position and time variables are discretized. Denoting the time increment by\n∆t and the position increment by ∆x,\nwe define\nu\nj\ni = c(xi, tj),\n(3.22)\nwhere\nxi = x0 + i∆x,\ni = 1, . . . , N\ntj = t0 + j∆t,\nj = 1, . . . , M.\n(3.23)\nA general approach to solving partial differential equations numerically is to\nreplace the partial derivatives by finite-difference approximations. The finite-\ndifference expressions involve the u\nj\ni terms defined above and result in sets\nof algebraic equations that can be solved by numerical methods for solving\nmatrix equations.\nIn the software, the equation with no drift term is solved\nby the implicit Crank-Nicolson algorithm, while for problems with a non-zero\ndrift term, this algorithm is combined with the explicit Two-Step Lax-Wendroff\nmethod (Press et al., 1988; Gerald and Wheatley, 1989). When a non-zero chem-\nical reaction rate, r, is specified, the computed concentration is multiplied by\nthe attenuation factor, e-rt. The Crank-Nicolson and Lax-Wendroffformulas in-\nvolve the parameters α = D∆t/(∆x)2 and β = v∆t/∆x. The numerical methods\ngive stable solutions provided α < 0.5 and |β| ≤1. For the two compartments\noption, the boundary conditions at the membrane solution interface is that the\nconcentration in the membrane at the interface is equal to the bath concentra-\ntion.\n3.2.3\nSummary\nA variety of techniques are used to find analytic solutions to one-dimensional\ndiffusion problems with transparent boundaries. The specific methods used in\nthe software to solve one-dimensional problems depend on the initial condi-\ntions and are summarized in Table 3.1. With two reflecting boundaries and in\nthe absence of drift, the analytic solutions consist of infinite series. Thus it is\ncumbersome to compute these analytic solutions. With two reflecting bound-\naries and with drift, analytic solutions are in general not available. Therefore,\nwe have chosen to solve these problems numerically using the Crank-Nicolson\nand Lax-Wendroffmethods. The latter methods are also used to compute the\nsolutions to the two-compartment problem.\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nOption\nBoundary Type\nComputational Method\nImpulse\nTransparent\nAnalytic solution\nReflecting\nCrank-Nicolson\nSinusoid\nTransparent\nAnalytic solution\nDiscontinuity\nTransparent\nAnalytic solution\nReflecting\nCrank-Nicolson\nArbitrary\nReflecting\nCrank-Nicolson\nTwo-Compartment\nCrank-Nicolson\nTable 3.1: Summary of computational methods.\nFigure 3.2:\nThe MD Control\nfigure.\n3.3\nUser's Guide To The Software\nWhen this software package is selected, 4 figures are displayed (in addition to\nMATLAB's command window) -- MD Control, MD Initial concentration profile,\nMD Plots vs. position, and MD Plots vs. time. A typical session with the software\nconsists of selecting one of five initial concentration profile options, selecting\nthe values of parameters, executing a simulation, and viewing the simulation\nresults.\n3.3.1\nMD Control\nThe MD Control figure controls the macroscopic diffusion software and is shown\nin Figure 3.2. The part of the MD Control figure below the menubar is divided\ninto three panels. The left panel controls the display of the initial concentration\nand the numerical parameters of the simulation abbreviated as numerics. The\nmiddle panel controls calculation of the simulation, and allows the simulation to\nbe started, paused, continued, or reset. The user can select the number of steps\nin time for computing the simulation results. The interpoint time is adjustable\nin the numerics figures (described later). The Time is the elapsed simulation\ntime since the simulation was started. Clicking on 1-step results in the com-\nputation of one step of the simulation. The simulation results and parameters\ncan be saved to a file and read from a file. Clicking on Save saves the follow-\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\ning items in a file: all the initial profile parameters, the numerical parameters,\nconcentration and flux versus position and versus time. Clicking on Open reads\nthese same quantities from a file. The right panel (the Simulation results panel)\ncontrols the display of simulation results. Clicking on a selection box displays\nthe appropriate figure; clicking again hides it.\n3.3.2\nMD Initial concentration profile\nThe MD Initial concentration profile figure allows control of the initial concentra-\ntion and all the parameters of the diffusion process. The four one-dimensional\ndiffusion problems and the two-compartment problem are implemented in the\nsoftware as five options called: Impulses (Figures 3.3), Sinusoids (Figures 3.5),\nDiscontinuities (Figures 3.6), Arbitrary (Figures 3.7), and Two Compartments\n(Figures 3.8). To change the profile type, the user clicks on the profile push-\nbutton in the MD Initial concentration profile figure. Each pushbutton has an\nicon suggesting the initial profile type. Parameters can be viewed by clicking on\nParameters in the same figure which results in the display of the appropriate\nparameters figure. Parameters can be changed by typing in the text edit box.\nTo activate the new parameters, the user must click on Update either in the MD\nParameters figure or in the MD Initial concentration profile figure; these actions\nare equivalent. Information about the initial profile and parameters (alone) can\nbe saved in a file by clicking on Save or read from a file by clicking on Open.\nThese actions can be done either in the MD Parameters figure or in the MD Ini-\ntial concentration profile figure; they are equivalent.\nFeatures of initial profiles and parameters common to all options\nVariables.\nThe initial concentration is plotted in the MD Initial concentration\nprofile figure (Figures 3.3, 3.5, 3.6, 3.7, and 3.8). Check boxes in the upper left-\nhand and the upper right-hand corners allow display of the initial concentration\nand/or the initial flux.\nAxes scales.\nAn axis scale can be changed by clicking on its label to display the\nAxis-scale figure Figure 3.4. The new axis limits can be typed into the edit boxes\nto change the axis.\nMarkers.\nThere are two markers that are indicated by two green triangles on\nthe abscissa of both the MD Initial concentration profile figure and the MD Plots\nvs. position figure. These markers indicated positions at which the concentration\nand flux can be displayed as a function of time in the MD Plots vs. time figure.\nThe positions of these markers can be controlled numerically or graphically. Nu-\nmerical control is achieved by typing into the appropriate text edit box in the pa-\nrameters figure (Figures 3.3, 3.5, 3.6, 3.7, and 3.8). Graphical control is achieved\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure\n3.3:\nInitial\ncon-\ncentration profile for im-\npulses;\nMD\nInitial\ncon-\ncentration\nprofile\nfigure\n(above), MD Impulse pro-\nfile parameters figure for\nimpulses (below).\nA sin-\ngle impulse located at po-\nsition 0.5 cm of area 10 is\nspecified.\nFigure 3.4: MD Axis scale figure when the\nabscissa is chosen in the MD Initial concen-\ntration profile figure.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nby clicking just below the abscissa axis in the MD Initial concentration profile\nfigure. The left marker is controlled by clicking the left button on a two-button\nmouse or by clicking the button on a single-button mouse. The right marker is\ncontrolled by clicking the right button on a two-button (or three-button) mouse\nor by shift-clicking the button on a single-button mouse.\nParameters.\nIn the MD parameters figure for each option, the user can select a\nparameter by clicking on it and then modify that parameter by typing the new\nvalue in the text edit box. This modification is terminated by a carriage return or\nby selection of another parameter. One panel displays the Diffusion parameters\n-- diffusion coefficient, drift velocity, and chemical reaction rate -- which are set\nindependently for each option. For the two compartments option these diffusion\nparameters apply to the membrane and not to the baths.\nAfter all the parameters in the figure have been changed, the user must press\nUpdate before the new parameters are reflected in both the MD Initial concen-\ntration profile figure and the MD Plots vs. position figure. All the parameters for\neach option can be saved in a file and read from a file.\nDescriptions of the five options\nFor each option, the user can modify the values of parameters, change all graph\nparameters, and run a simulation.\nImpulses.\nWhen the software is initiated, Impulses is the default initial con-\ncentration profile and the MD Initial concentration profile figure is shown in Fig-\nure 3.3. The areas and positions of 4 impulses can be specified by the user as\nshown in the parameters figure so that the initial concentration has the form\nA1δ(x -x1) + A2δ(x -x2) + A3δ(x -x3) + A4δ(x -x4),\nwhere δ(x) is the unit impulse located at x = 0, Aj and xj are the area and\nposition of the jth impulse. The positions of each impulse can be set only if\nits area is non-zero. Since the initial flux is the spatial derivative of the initial\nconcentration, if the concentration contains an impulse δ(x -xo) at x = xo then\nthe flux contains a doublet δ(x-xo) at x = xo which is signified by a two-headed\narrow. Either transparent boundaries or reflecting boundaries can be chosen and\nthe locations of right (R) and left (L) reflecting boundaries can be specified.\nSinusoid.\nIn the Sinusoid option, the amplitudes, spatial frequencies, and phase\nangles of four sinusoids can be specified (Figure 3.5) so that the initial concen-\ntration has the form\nA1(1 + sin(2πf1x + θ1)) + A2(1 + sin(2πf2x + θ2)) +\nA3(1 + sin(2πf3x + θ3)) + A4(1 + sin(2πf4x + θ4)),\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure 3.5:\nInitial\nconcentration pro-\nfile\nfor\nsinusoids;\nMD\nInitial\ncon-\ncentration\nprofile\nfigure (above), MD\nSinusoid\nprofile\nparameters\nfigure\n(below). The spatial\nfrequencies\nand\namplitudes of four\nsinusoids\nwere\nchosen\nto\ncorre-\nspond to the first\nfour terms in the\nFourier series of a\nsquare wave.\nwhere Aj, fj, and θj are the amplitude, spatial frequency, and phase of the\njth sinusoid.\nThe spatial frequency and phase of a sinusoid can be set only\nif its amplitude is non-zero. Only transparent boundaries are available for the\nsinusoid option.\nDiscontinuity.\nIn the Discontinuity option, the magnitude and position of four\ndiscontinuities can be specified (Figure 3.6) so that the initial concentration has\nthe form\nA1u(x -x1) + A2u(x -x2) + A3u(x -x3) + A4u(x -x4),\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.6:\nInitial con-\ncentration\nprofile\nfor\ndiscontinuities;\nMD\nInitial\nconcentration\nprofile\nfigure\n(above),\nMD Discontinuity pro-\nfile\nparameters\nfigure\n(below).\nTwo discon-\ntinuities\nwere\nused\nto\ngenerate\nan\ninitial\nconcentration\nprofile\nthat\nis\na\nrectangular\npulse.\nwhere u(x) is the unit step function defined as\nu(x) =\n\nif x > 0,\nif x < 0,\nand Aj and xj are the amplitude and position of the jth step. The position of a\nstep can be set only if its magnitude is non-zero. The boundary type (transparent\nor reflecting) is selectable, and, if the boundaries are reflecting, the positions of\nthe two boundaries can be set.\nArbitrary.\nIn the Arbitrary option, the initial profile is drawn on the monitor\nscreen by moving the mouse cursor. The details are described in Section 3.3.5.\nOnly reflecting boundary conditions are available for this option, and the posi-\ntions of the two boundaries are specifiable by the user (Figure 3.7).\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure\n3.7:\nInitial\ncon-\ncentration using the arbi-\ntrary\noption;\nMD\nInitial\nconcentration profile fig-\nure (above), MD Arbitrary\nprofile parameters figure\n(below).\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nTwo-compartment.\nIn the Two compartment option, specification can be made\nfor the width and the initial concentration in each bath, the membrane width,\nand the initial membrane concentration.\nThe initial membrane concentration\nprofile is drawn with a mouse cursor (as described in Section 3.3.5). The user can\nalso choose how the two baths and the membrane are to be displayed. Selecting\nthe View bath option (Figure 3.8) displays the membrane and both baths to scale.\nThe left boundary of the membrane is located at x = 0. Hence, the left bath is\nlocated for x < 0 and if the width of the membrane is W, the right bath is located\nat x > W. Selecting the View membrane option displays the membrane and a\nsmall portion of each bath on each side.\n3.3.3\nNumerics\nClicking on Analytic parameters or Numeric parameters in the MD Control fig-\nure displays the appropriate numerics figure (Figure 3.9). The numerics figures\ncontrol the spatial and temporal resolution of the simulation.\nThe MD Analytic\nparameters figure deals with those computations that make use of analytic solu-\ntions of the diffusion equation (i.e., all one-dimensional diffusion problems with\ntransparent boundaries). For this case, the user can select the number of spatial\npoints at which the solution is computed. The larger the number of points, the\nhigher the spatial resolution of the computation and the longer it will take to\ncomplete the computation. The user can also specify the temporal resolution of\nthe computation by selecting the time between samples (integration time).\nThe MD Numeric parameters figure deals with those computations that use\nnumerical integration of the diffusion equation (i.e., all one-dimensional diffu-\nsion problems with reflecting boundaries and the two-component diffusion prob-\nlem). The user can choose to select the number of points in space at which the\nsolution is computed. The user has a choice in how the temporal resolution is\nto be determined. The numerical method is stable provided an inequality that\nrelates the temporal and spatial resolutions is satisfied. If Link is selected, the\nsimulation determines the integration time to satisfy the inequality and to guar-\nantee a stable integration method which results in an accurate solution. If this\nchoice is not selected, the user can choose the temporal resolution (integration\ntime) and spatial resolution independently. However, with this choice there is\nno guarantee that the solution will be accurate.\n3.3.4\nSimulation results figures\nThere are two figures that display the solute concentration and flux during a\nsimulation. The MD Plots vs. position figure displays the concentration and/or\nthe flux as a function of position at each instant in time during the simulation\n(Figure 3.10). The current simulation Time is displayed in the upper left part\nof the figure. Axes limits can be changed by clicking on the axes labels to dis-\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure\n3.8:\nInitial\ncon-\ncentration\nfor\nthe\ntwo\ncompartments\noption;\nMD\nInitial\nconcentration\nprofile figure for the two\ncompartments option for\nthe bath view (top) and the\nmembrane\nview\n(center),\nMD\nTwo-compartment\nprofile parameters figure\n(bottom).\nThe bath view\nshows\nthe\nleft\nbath\nlo-\ncated between -1 and 0\ncm, the membrane located\nbetween 0 and 1 cm, and\nright bath located between\n1 and 3 cm.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nFigure 3.9: The MD Analytic parameters and MD Numeric parameters figures.\nFigure 3.10: MD Plots vs. position figure.\n\n3.3. USER'S GUIDE TO THE SOFTWARE\nFigure 3.11: MD Plots vs. time figure.\nplay the Axis-scale figure. The two green triangular markers mirror the markers\nshown in the MD Initial concentration profile figure. With the Two compartments\noption, the user can also chose how the two baths and the membrane are to be\ndisplayed in the MD Plots vs. position figure. Selecting the View membrane op-\ntion displays the membrane and a bit of each bath on each side. Selecting the\nView baths option displays the membrane and both baths to scale.\nThe MD Plots vs. time figure (Figure 3.11) displays the concentration and/or\nthe flux as a function of time during the simulation for two positions selected by\nthe markers found in both the MD Initial concentration profile figure and the MD\nPlots vs. position figure (Figure 3.10). The locations of the markers are indicated\nat the top of the figure. Axes limits can be changed by clicking on the axes labels\nto display the Axis-scale figure.\n3.3.5\nArbitrary concentration profiles\nFor the MD Arbitrary and MD Two compartment options, the user can draw\nan arbitrary initial concentration profile by clicking on the Reset/Draw button\nwhich will also erase an existing profile. Drawing a profile consists of generating\na list of concentration values at a corresponding array of positions. The user\nselects these points by moving the mouse and clicking any mouse button. After\nthe first point is selected by the user, the word Incomplete is displayed over the\nprofile indicating that the profile is incomplete and does not span the horizontal\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\ndimension of the plotting field. As the pointer moves within the plotting field in\nthe MD Initial concentration profile figure, a line joins the last point which was\nselected to the current pointer position. When a button is pressed, the position\nand concentration that are added to the coordinate arrays depend on the pointer\nlocation:\n1. If a mouse button is pressed within the graph axes and to the right of the\nprevious point, then the coordinates of the pointer location are added to\nthe list.\n2. A mouse button pressed at a position that does not lie to the right of the\nprevious point is ignored, in order to ensure that the user-drawn concen-\ntration profile is a single-valued function of position.\n3. If a mouse button is pressed outside the boundaries of the graph (but still\nwithin MD Initial concentration profile figure), then the point that is added\nto the list is the point of intersection between the graph boundary and a\nline from the previous point to the current position. Thus, while a profile\nis being drawn, it is constrained to lie entirely within the boundaries of the\ngraph.\n4. In the arbitrary initial profile, the concentration at the left-hand point of\nthe profile is set to a default value. The user can change the value of this\npoint by pressing the mouse button for first point at the desired vertical\nlocation but to the left of the concentration axis. In the two components\noption, the concentration at the left-hand point of the profile is set equal\nto the concentration in the left bath (bath #1), and the concentration at the\nright-hand point of the profile is set equal to the concentration in the right\nbath (bath #2).\n5. If the mouse button is pressed outside the MD Initial concentration profile\nfigure, e.g., on another figure, then the profile is incomplete.\n6. An incomplete profile can be completed by pressing Update. In the arbi-\ntrary initial profile, a horizontal line segment is drawn from the last cho-\nsen point to the right boundary. In the two-compartment option, the last\nchosen point is connected to the concentration in the right bath.\n7. An incomplete profile can be completed by clicking the mouse button with\nthe cursor located just to the right of the right boundary of the region. Item\n3 (above) gives the rule that indicates the location of the right boundary\npoint.\nClicking on Update after completion of the profile, activates the initial profile.\n\n3.4. PROBLEMS\n3.4\nProblems\nProblem 3.1 The purpose of this problem is to explore the relation between molar\nsolute concentration and molar solute flux. The diffusion coefficient is D = 10-5\ncm2/s.\na. For an initial, spatial sinusoidal solute concentration with an amplitude\nof 10 μmol/cm2 and a frequency of 1 cm-1, determine the initial spatial\ndistribution of the molar solute flux.\nb. Determine an initial spatial distribution of molar solute concentration such\nthat the initial spatial distribution of molar flux is a constant of value 1\nμmol/(cm2·s).\nProblem 3.2 The purpose of this problem is to explore the space-time evolution of\nsolute diffusion from a point source. For all parts of this problem use a single im-\npulse and transparent boundaries. Set the impulse strength to 100 moles/cm2,\nplace the impulse at position 0.5 cm, and set the drift velocity and the reaction\nrate to zero. Set the marker positions to 0.55 and 0.6 cm unless indicated other-\nwise. Set the diffusion coefficient to 10-5 cm2/s and run the simulation for 1000\nseconds. Obtain a plot of the concentration and flux on appropriate ordinate\nscales. You should obtain the spatial distribution of the concentration and the\nflux at 1000 seconds and both variables as a function of time at the two marker\npositions. Repeat these two steps for a diffusion coefficient of 4 × 10-5 cm2/s.\na. Briefly describe qualitatively the effect of the change in diffusion coefficient\non the spatial distribution of concentration.\nb. For both values of the diffusion coefficient, determine the maximum am-\nplitude of the concentration versus position and the width of the spatial\ndistribution of concentration at an amplitude that is e-1 of its peak value.\nExplain the numerical values of all four measurements. Be brief and pre-\ncise; state your assumptions explicitly.\nc. For the diffusion coefficient at 10-5 cm2/s, examine the concentration ver-\nsus time at the two positions 0.55 and 0.6 cm. Briefly describe, in a qual-\nitatively manner, the differences in concentration versus time at the two\npositions.\nd. For the diffusion coefficient at 10-5 cm2/s, measure the maximum concen-\ntration as a function of time at the two positions and the time of occurrence\nof this maximum. Explain the values of all four measurements. Be brief and\nprecise; state your assumptions explicitly.\ne. Explain the shape of the spatial distribution of flux for a diffusion coeffi-\ncient of 10-5 cm2/s.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nf. Explain the relation between the flux and concentration versus time at lo-\ncation 0.55 cm for a diffusion coefficient of 10-5 cm2/s.\ng. Rerun the simulation for a diffusion coefficient of 10-5 cm2/s at positions\n0.45 and 0.55 cm. Explain the differences in the flux as a function of time\nfor these two locations.\nProblem 3.3 The purpose of this problem is to explore the space-time evolution\nof solute diffusion from a point source in the presence of drift. Set the impulse\nstrength to 100 moles/cm2; place the impulse at position 0.5 cm; set the dif-\nfusion coefficient to 10-5 cm2/s, and the reaction rate to zero. Set the marker\npositions to 0.75 and 0.9 cm unless indicated otherwise. The parts of this prob-\nlem that deal with reflecting boundaries are solved numerically. To decrease the\ntime taken for these computations, consider decreasing the spatial resolution of\nthe computation to 10 points.\na. Set the boundary conditions to transparent and the drift velocity to zero\nand run the simulation for 1000 s. Now set the drift velocity to 10-4 cm/s\nand run the simulation again for 1000 s. Describe the effect of the drift\non the spatial distribution of concentration. Account quantitatively for the\nposition of the peak of the spatial distribution at 1000 s.\nb. Set the boundary conditions to reflecting and the drift velocity to zero.\nRun the simulation until the spatial distribution is no longer a function of\ntime. This is the equilibrium distribution. What is the spatial distribution\nat equilibrium? Explain your answer.\nc. Set the boundary conditions to reflecting, the drift velocity to 10-4 cm/s,\nand run the simulation. Describe the effect of drift on the spatial distribu-\ntion of concentration. Illustrate your description with printed copies of the\ndistribution at characteristic times.\nd. With the boundary conditions still set to reflecting and the drift velocity\n10-4 cm/s, determine the equilibrium spatial distribution of concentration.\nAccount quantitatively for this distribution.\ne. It is known that the density of air decreases exponentially with distance\nabove the earth's surface. Explain this phenomenon, taking the above sim-\nulation results into account.\nProblem 3.4 The purpose of this problem is to explore some of the assumptions\nthat underlie two-compartment diffusion.\nAs shown elsewhere (Weiss, 1996a,\nChapter 3), two-compartment diffusion is based on 4 assumptions:\n1. The two compartments are well-mixed so that the concentrations of solute\nn are uniform and have values at time t of c1\nn(t) and c2\nn(t).\n\n3.4. PROBLEMS\n2. Solute particles are conserved, e.g., there is no chemical reaction present\nthat either creates or destroys particles.\n3. The membrane is sufficiently thin and the number of solute particles con-\ntained in the membrane at any time is negligibly small.\n4. The membrane is sufficiently thin that at each instant in time the concen-\ntration profile in the membrane is in steady state.\nThis problem concerns the conditions for the validity of assumptions 3 and 4.\nSpecifically, you will explore the effect of bath dimensions on two-compartment\ndiffusion without making these two assumptions.\nIn all parts of the problem, use the Two compartments option of the software.\nSet the membrane width to 0.01 cm, and the concentration of bath #1 to 70 and\nbath #2 to 10 mol/cm3. Leave the drift velocity and reaction rate at 0 and the\ndiffusion coefficient at 10-5 cm2/s. Set the parameters of the plot of concentra-\ntion versus position so that the membrane and a little of each bath are visible on\nthe screen -- select membrane view. Note that the left edge of the membrane is\nat a position of 0 cm. Draw some initial concentration in the membrane. Make\nsure all ordinate scales on all plots are 0 to 100 mol/cm3. Keep these parameters\nfixed throughout this problem. To reduce the time taken for the computation re-\nduce the spatial resolution in the membrane to 10 points in space. The software\nwill determine the time increment (DELTA_T). Initially set the number of steps so\nthat the end time is 5 s.\nFor each of the pairs of bath widths -- Bath #1 = 1 cm, Bath #2 = 1 cm; Bath #1\n= 0.1 cm, Bath #2 = 0.1 cm; Bath #1 = 0.01 cm, Bath #2 = 0.01 cm; Bath #1 = 0.01\ncm, Bath #2 = 0.05 cm; Bath #1 = 0.001 cm, Bath #2 = 0.001 cm; -- answer the\nfollowing questions.\na. Assess the validity of assumption 4.\ni. Make rough estimates of both the steady-state (τss) and equilibrium\n(τeq) time constants from the computations.\nii. Estimate the same two time constants based on theoretical considera-\ntions (Weiss, 1996a, Chapter 3).\niii. What is your conclusion based on your computations and your esti-\nmates of time constants?\nb. Assess the validity of assumption 3.\ni. Before you do the computation, make an estimate of the final concen-\ntration in each bath. Then do the computation, and check your initial\nestimates against the computed values\nii. If they differ, explain the basis of the difference.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\niii. How good is the assumption that the quantity of solute in the mem-\nbrane is negligible? If you decide that the quantity of solute in the\nmembrane is not negligible, design a simulation experiment to test\nyour conclusion.\ne. Are the bath concentrations exponential functions of time? Explain.\nProblem 3.5 The purpose of this problem is to explore the successes and pitfalls of\nthe method of images for solving diffusion problems in the presence of a reflecting\nboundary. Some problems in diffusion with a reflecting boundary can be solved\nby using the solution for a transparent boundary and the method of images to\nmatch the reflecting boundary condition.\nIn all parts of this problem, set the drift velocity to zero, the reaction rate\nto zero, and the diffusion coefficient to 10-5 cm2/s unless state otherwise. The\nparts of this problem that deal with reflecting boundaries are solved numeri-\ncally. To decrease the time taken for these computations, consider decreasing\nthe spatial resolution of the computation to 10 points.\na. Use reflecting boundaries, and an initial impulse of concentration of strength\n100 moles/cm2 located at 0.2 cm. Run the simulation for 1000 s and obtain\na print of the spatial distribution of concentration at time 1000 s and the\nconcentration versus time at locations 0 and 0.3 cm.\nb. At a reflecting boundary, the flux must be zero.\nChange the boundary\ncondition to transparent and determine the parameters of two impulses:\none to match the left boundary condition and another to independently\nmatch the right boundary condition. Run the simulation again and compare\nwith the results in part a.\nDoes this \"method of images\" work exactly?\nExplain.\nProblem 3.6 The purpose of this problem is to explore the space-time evolution of\ndiffusion from an initial sinusoidal concentration profile. Diffusion from an initial\nsinusoidal concentration distribution gives important insights into the space-\ntime evolution of diffusion processes. In all parts of this problem, use a drift\nvelocity of zero, a reaction rate of zero, and a diffusion coefficient of 10-5 cm2/s\nunless state otherwise.\na. Use an initial concentration that is sinusoidal with amplitude 50 moles/cm2\nand a spatial frequency of 1 cycle/cm. Run the simulation for 1000 s and\nprint the spatial distribution of concentration at 1000 s and the concentra-\ntion versus time at 0.25 and 0.75 cm. Repeat this procedure for sinusoids\nwith the same amplitudes but the following spatial frequencies: 3, 5, and 7\ncycles/cm. Summarize your results both qualitatively (in words) and then\nquantitatively (with suitable calculations).\n\n3.4. PROBLEMS\nAmplitude\nPosition\n(μmol/cm2)\n(cm)\n-100\n-10\n0.4\n0.6\n-10\nTable 3.2: Concentration well -- Problem 3.7.\nb. Construct a periodic waveform from four sinusoids with the following am-\nplitudes (moles/cm2) and spatial frequencies (cycles/cm): 105, 1; 35, 3;\n21, 5; 15, 7. Run the simulation and observe the spatial distribution of\nconcentration. Summarize your results and relate them to results of part\na.\nc. Switch to the arbitrary initial distribution option and set the boundary con-\nditions to reflecting. Using the mouse draw an arbitrary, preferably jagged,\ninitial profile. This part of this problem uses a numerical solution method\nthat is time consuming. To decrease the time taken for these computa-\ntions, consider decreasing the spatial resolution of the computation to 10\npoints. Run the simulation and watch the spatial distribution of concentra-\ntion change. Summarize your results. What is the effect of diffusion on the\nspatial distribution?\nProblem 3.7 The purpose of this problem is to explore the time it takes for diffu-\nsion to take place in a concentration well. We examine the following two estimates\nof diffusion time.\n1. A crude estimate of the time t1 it takes for 1/2 the particles to diffuse over\na distance x is t1 = x2/D (Weiss, 1996a, Sections 3.2 and 3.3).\n2. The time for equilibration of a slab of dimensions 2a so that the average\nconcentration in the slab is half its final value corresponds to the condition\nDt2/a2 = 0.21 (Weiss, 1996a, Figure 3.18).\nDefine a concentration well as shown in Table 3.2 and let the diffusion coefficient\nbe D = 10-5 cm2/s.\na. Run the software and measure the concentration in the center of the well\nas a function of time. Estimate the time t3 it takes for this concentration to\nreach 1/2 its final value.\nb. Quantitatively compare the estimates t1, t2, and t3.\n\nCHAPTER 3. MACROSCOPIC DIFFUSION PROCESSES\nc. Briefly discuss the bases of the differences you found between these three\nestimates.\nc. Suggest a new method to estimate an equilibration time that will be close to\nt2 using the concentration well defined in Table 3.2. Test your suggestion\nby performing the computations and making the comparison.\nd. Why are there discontinuities in the well at ±100? What effect do they have\non the estimates of equilibration time.\n\nChapter 4\nCARRIER-MEDIATED TRANSPORT\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\n4.1\nIntroduction\nTransport of many solutes including important metabolites (e.g. monosaccha-\nrides, amino acids, mononucleotides, phosphates, uric acid, etc.) through cel-\nlular membranes is accomplished by membrane-bound carrier molecules that\ncombine with the solute molecule on one face of the membrane, then translo-\ncate in the membrane and uncombine at the other face. Thus, transport involves\nchemical reactions in which the solute binds and unbinds with a carrier. This\ntype of transport is called carrier-mediated transport. Carrier-mediated trans-\nport has distinctive properties. For example, the relation of flux to concentra-\ntion saturates, i.e., it does not obey Fick's law for membranes. In addition, dif-\nferent molecules compete for the carrier. For example, glucose and sorbose (two\nmonosaccharides) compete for the sugar carrier. Hence, transport of one sugar\ncan inhibit transport of another simply by occupying a site to which both can\nbind.\nThere are canonical models of carrier-mediated transport that capture impor-\ntant properties of the transport of metabolites through cellular membranes. It\nis important to understand these canonical models in order to understand how\nmetabolites are transported across these membranes. Derivations of predictions\nof these models are not particularly difficult to follow; the individual steps are\nsimple. However, the models typically result in messy algebraic expressions that\nrelate flux to concentration and transport parameters. Thus, it is easy to get lost\nin algebraic manipulation as well as in a sea of parameters so that an intuitive\ngrasp of the models becomes illusive. The intent of this software is to allow the\nuser to develop intuition for these models.\n4.2\nDescription Of The Models\nDescriptions of carrier-mediated transport as well as models of such transport\nprocesses can be found elsewhere (Stein, 1986; Weiss, 1996a). Here we consider\nthree models and list both the assumptions and the important results. First,\nwe consider the steady-state behavior of a simple, four-state carrier that binds\none solute Then, we consider the steady-state behavior of a simple, six-state\ncarrier that binds two solutes with different affinities. Finally, we consider both\nthe transient and the steady-state behavior of a general, four-state carrier model\nthat binds one solute.\n\n4.2. MODELS\nni\nE\nno\nE\nni\nES\nno\nES\nci\nS\nco\nS\nKi\nS\nKo\nS\nαES\nβES\nαE\nβE\nφE\nφS = φES\nSi +\nEi\nEo\n+ So\nESi\nESo\nMembrane\nIntracellular\nExtracellular\nFigure 4.1: Kinetic diagram of\nthe simple, four-state carrier\nthat binds one solute.\n4.2.1\nSteady-state behavior of a simple, four-state carrier that\nbinds one solute\nAssume that the membrane contains NET moles of carrier per unit area of mem-\nbrane.1 Each of these carriers exist in one of four states labeled ESi, ESo, Ei, and\nEo (Figure 4.1). In the ES states, the solute S is bound to the carrier E; in the\nE state the carrier is unbound. In the ESi and Ei states, the carrier, bound and\nunbound, communicates with the solution on the inner side of the membrane.\nIn the ESo and Eo states, the carrier, bound and unbound, communicates with\nthe solution on the outer side of the membrane. The densities of carrier in the\nfour states are ni\nES, no\nES, ni\nE, and no\nE moles per unit area of membrane. The fluxes\nof bound and unbound carrier are φES and φE and the flux of solute is φS. The\nflux is defined as positive when the flux is in the outward direction; the units\nare in moles per unit area per second. The model is defined by the following\nassumptions:\n- The total amount of carrier, bound and unbound, is constant, i.e. the sum\nof the carrier density over all of its states equals the total density of carrier\nin the membrane\nNET = ni\nES + no\nES + ni\nE + no\nE.\n(4.1)\n- Since the carrier resides permanently in the membrane, the total flux of\ncarrier must be zero, i.e.\nφES + φE = 0.\n(4.2)\n- The only time the solute crosses the membrane is when it is bound to the\ncarrier; ESo is assumed to undergo a reversible change in conformation to\n1Because the kinetic equations for binding of the carrier to the solute are analogous to\nthose of the binding of an enzyme to its substrate, the carrier is denote by E which stands for\nenzyme.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nthe form ESi. The unbound carrier is assumed to undergo a similar reac-\ntion between the two conformations Ei and Eo. These two reactions are as-\nsumed to be first-order reactions with forward and reverse rate constants,\nαE, αES, βE, and βES, so that the fluxes are defined as follows:\nφES = φS\n=\nαESni\nES -βESno\nES,\n(4.3)\nφE\n=\nαEni\nE -βEno\nE.\n(4.4)\n- In the simple model, the binding reactions at the membrane interfaces are\nassumed to be so rapid, compared to the rate of transport of solute across\nthe membrane, that the membrane interface reactions are assumed to be\nat equilibrium, i.e.,\nco\nSno\nE\nno\nES\n= Ko\nS and ci\nSni\nE\nni\nES\n= Ki\nS,\n(4.5)\nwhere Ko\nS and Ki\nS are the dissociation constants on the two membrane in-\nterfaces.\nThese equations can be solved to determine the n's in terms of the concentra-\ntions and transport parameters. Equations 4.3 and 4.4 can be used to determine\nthe φ's. Combining Equations 4.2, 4.3, and 4.4 yields\n(αESni\nES -βESno\nES) + (αEni\nE -βEno\nE) = 0.\n(4.6)\nEquations 4.1, 4.5, and 4.6 can be expressed as a matrix equation as follows:\n\nKi\nS\nαES\nKo\nS\n-βES\n-ci\nS\nαE\n-co\nS\n-βE\n\nni\nES\nno\nES\nni\nE\nno\nE\n\n=\n\nNET\n\n.\n(4.7)\nThe first two rows correspond to the two relations in Equation 4.5. The third\nrow results from Equation 4.6, and the fourth row corresponds to Equation 4.1.\nThis set of simultaneous equations has the following solutions (Weiss, 1996a):\nni\nES = NET\nci\nS(βEKo\nS + βESco\nS)\nD1\n,\n(4.8)\nno\nES = NET\nco\nS(αEKi\nS + αESci\nS)\nD1\n,\n(4.9)\nni\nE = NET\nKi\nS(βEKo\nS + βESco\nS)\nD1\n,\n(4.10)\nno\nE = NET\nKo\nS(αEKi\nS + αESci\nS)\nD1\n,\n(4.11)\n\n4.2. MODELS\nni\nE\nno\nE\nni\nES\nno\nES\nci\nS\nco\nS\nKi\nS\nKo\nS\nαES\nβES\nαE\nβE\nφE\nφS = φES\n+\nEi\nEo\n+\nESi\nESo\nKi\nR\nKo\nR\nαER\nβER\nSi\nSo\nRi\nRo\nERi\nERo\nni\nER\nno\nER\nφR = φER\nMembrane\nIntracellular\nExtracellular\nci\nR\nco\nR\nFigure 4.2:\nKinetic diagram of a simple,\nsix-state carrier that binds two solutes (S\nand R).\nwhere\nD1 = (βEKo\nS + βESco\nS)(Ki\nS + ci\nS) + (αEKi\nS + αESci\nS)(Ko\nS + co\nS).\n(4.12)\nφS and φE can be obtained from Equations 4.3 and 4.4.\nThe flux of solute can also be expressed in terms of the uni-directional fluxes\nas\nφS =\n→\nφS -\n←\nφS,\nwhere\n→\nφS= αESni\nES and\n←\nφS= βESno\nES.\n4.2.2\nSteady-state behavior of a simple, six-state carrier that binds\ntwo solutes\nThe simple, four-state carrier shown in Figure 4.1 can be extended to account\nfor the binding of two solutes that compete for binding sites on the carrier (Fig-\nure 4.2). In this scheme, solutes S and R combine with carrier E but with different\naffinities. The binding to solute S has dissociation constants Ki\nS and Ko\nS and the\nbinding to R has dissociation constants Ki\nR and Ko\nR.\nThe kinetic equations are analogous to those derived for the simple, four-\nstate carrier except that the carrier now has 6 states:\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\n- The total amount of carrier, bound and unbound, is constant, i.e. the sum\nof the carrier density over all of its six states equals the total density of\ncarrier in the membrane\nNET = ni\nES + no\nES + ni\nER + no\nER + ni\nE + no\nE,\n(4.13)\nwhere NET is the total density of carrier in the membrane.\n- Since the carrier remains in the membrane, the net flux of carrier must be\nzero\nφES + φER + φE = 0.\n(4.14)\n- The fluxes are related to the carrier densities so that\nφES = φS\n=\n(αESni\nES -βESno\nES).\n(4.15)\nφER = φR\n=\n(αERni\nER -βERno\nER).\n(4.16)\nφE\n=\n(αEni\nE -βEno\nE).\n(4.17)\n- In the simple model, the reactions at the membrane interfaces are assumed\nto take place so rapidly, compared to the rate of transport of solute across\nthe membrane, that the membrane interface reactions are assumed to be\nat equilibrium, i.e.,\nco\nSno\nE\nno\nES\n= Ko\nS, ci\nSni\nE\nni\nES\n= Ki\nS and co\nRno\nE\nno\nER\n= Ko\nR, ci\nRni\nE\nni\nER\n= Ki\nR,\n(4.18)\nwhere Ko\nS, Ki\nS, Ko\nR and Ki\nR are the dissociation constants for solutes S and\nR, respectively at the two membrane interfaces.\nCombining Equations 4.14 and 4.15, 4.16, and 4.17 yields\n(αESni\nES -βESno\nES) + (αERni\nER -βERno\nER) + (αEni\nE -βEno\nE) = 0.\n(4.19)\nIt is of interest to obtain the flux of solutes S and R as a function of both con-\ncentrations and the transport parameters Ki\nS, Ko\nS, Ki\nR, Ko\nR, αES, αER, αE, βES, βER,\nβE, and NET. Therefore, it is useful to regard the system of algebraic equations\ngiven by Equations 4.14 through 4.19 as a set of 6 equations in the 6 unknowns\nni\nES, no\nES, ni\nER, no\nER, ni\nE, and no\nE. These can be written in matrix form as follows:\n\nKi\nS\nαES\nKo\nS\n-βES\nKi\nR\nαER\nKo\nR\n-βER\n-ci\nS\n-ci\nR\nαE\n-co\nS\n-co\nR\n-βE\n\nni\nES\nno\nES\nni\nER\nno\nER\nni\nE\nno\nE\n\n=\n\nNET\n\n.\n(4.20)\n\n4.2. MODELS\nThe first four rows correspond to the four relations in Equation 4.18. The fifth\nrow results from Equation 4.19, and the sixth row corresponds to Equation 4.13.\nThis set of simultaneous equations has solutions (Weiss, 1996a):\nni\nES = NET\nci\nSKi\nR(βEKo\nSKo\nR + βESco\nSKo\nR + βERKo\nSco\nR)\nD2\n,\n(4.21)\nno\nES = NET\nco\nSKo\nR(αEKi\nSKi\nR + αESci\nSKi\nR + αERKi\nSci\nR)\nD2\n,\n(4.22)\nni\nER = NET\nKi\nSci\nR(βEKo\nSKo\nR + βESco\nSKo\nR + βERKo\nSco\nR)\nD2\n,\n(4.23)\nno\nER = NET\nco\nRKo\nS(αEKi\nSKi\nR + αESci\nSKi\nR + αERKi\nSci\nR)\nD2\n,\n(4.24)\nni\nE = NET\nKi\nSKi\nR(βEKo\nSKo\nR + βESco\nSKo\nR + βERKo\nSco\nR)\nD2\n,\n(4.25)\nno\nE = NET\nKo\nSKo\nR(αEKi\nSKi\nR + αESci\nSKi\nR + αERKi\nSci\nR)\nD2\n,\n(4.26)\nwhere\nD2\n=\nKi\nS(ci\nRαER + Ki\nRαE)(Ko\nSKo\nR + co\nSKo\nR + Ko\nSco\nR) +\nKo\nS(co\nRβER + Ko\nRβE)(Ki\nSKi\nR + ci\nSKi\nR + Ki\nSci\nR) +\nci\nSKi\nRαES(Ko\nSKo\nR + co\nSKo\nR + Ko\nSco\nR) +\nco\nSKo\nRβES(Ki\nSKi\nR + ci\nSKi\nR + Ki\nSci\nR).\n(4.27)\nThe fluxes can be computed using Equations 4.15-4.17.\nThe solute fluxes can also be expressed in terms of the uni-directional fluxes\nas\nφS\n=\n→\nφS -\n←\nφS,\nφR\n=\n→\nφR -\n←\nφR,\nwhere\n→\nφS\n=\nαESni\nES and\n←\nφS= βESno\nES,\n→\nφR\n=\nαERni\nER and\n←\nφR= βERno\nER.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nni\nE\nno\nE\nni\nES\nno\nES\nci\nS\nco\nS\nφE\nφS = φES\nSi +\nEi\nEo\n+ So\nESi\nESo\nai\nao\nbi\nbo\ngi\ngo\nhi\nho\nMembrane\nIntracellular\nExtracellular\nFigure 4.3: Kinetic diagram of a general,\nfour-state carrier model that binds one so-\nlute.\n4.2.3\nTransient and steady-state behavior of a general, four-state\ncarrier that binds one solute\nTransient solution\nSuppose that in the simple, four-state carrier model shown in Figure 4.1, the as-\nsumption that the interfacial binding reactions are fast is dropped. The model\nwhich results is called the general, four-state carrier model and the kinetic dia-\ngram for this model is shown in Figure 4.3.\nThis model is defined by the following assumptions:\n- The total amount of carrier, bound and unbound, is constant, i.e. at each\ninstant in time the sum of the densities of carrier over all of its states\nequals the total density of carrier\nNET = ni\nES(t) + no\nES(t) + ni\nE(t) + no\nE(t).\n(4.28)\nSince both transient and steady-state values will be considered, the nota-\ntion will be to specify a variable that changes in time as, for example, ni\nES(t)\nand its steady-state value as ni\nES(inf).\n- Since the carrier resides permanently in the membrane, the total flux of\ncarrier must be zero, i.e.\nφES(t) + φE(t) = 0.\n(4.29)\n- The only time the solute crosses the membrane is when it is bound to the\ncarrier; ESo is assumed to undergo a reversible change in conformation to\nthe form ESi. The unbound carrier is assumed to undergo a similar reac-\ntion between the two conformations Ei and Eo. The kinetic equations for\nthe general, four-state carrier model can be written for the rate of change\n\n4.2. MODELS\nof carrier in each of the four states by a matrix differential equation which\nis\nd\ndt\n\nni\nE(t)\nno\nE(t)\nni\nES(t)\nno\nES(t)\n\n=\n\n-ai -hici\nS\nai\nhici\nS\nao\n-ao -hoco\nS\nhoco\nS\ngi\n-bi -gi\nbi\ngo\nbo\n-bo -go\n\nni\nE(t)\nno\nE(t)\nni\nES(t)\nno\nES(t)\n\n. (4.30)\nThe binding reactions are not assumed to be arbitrarily fast.\nSince the\nbinding reactions are assumed to be second-order kinetic equations, the\nsolute concentrations enter the binding reactions.\nThe four kinetic equations are not independent; e.g., the fourth can be derived\nfrom the first three equations. Thus, the fourth equation can be eliminated and\nno\nES(t) can be eliminated using the conservation of carrier relation,\nno\nES(t) = NET -ni\nE(t) -no\nE(t) -ni\nES(t),\n(4.31)\nto yield the matrix equation\nd\ndt\n\nni\nE(t)\nno\nE(t)\nni\nES(t)\n\n=\n\n-ai -hici\nS\nai -go\nhici\nS -bo\nao\n-ao -go -hoco\nS\n-bo\ngi\n-go\n-bi -gi -bo\n\nni\nE(t)\nno\nE(t)\nni\nES(t)\n\n+\n(4.32)\n\ngo\nbo\n\nNET.\n(4.33)\nThis matrix equation can be solved for the three carrier densities and Equa-\ntion 4.31 can be used to solve for the fourth density. The solution for each of\nthe carrier densities has the form\nnj(t) = Aj1eλ1t + Aj2eλ2t + Aj3eλ3t,\n(4.34)\nwhere the nj's are the four carrier densities, the λ's are the three non-zero eigen-\nvalues of the system, and the A's are the residues. This solution is valid when\nthe eigenvalues are distinct. All 4 carrier densities have the same 3 eigenvalues,\nbut in general, the residues differ. Since the rate constants and concentrations\nare all positive quantities, it can be shown that all the eigenvalues have negative\nreal parts. Both the eigenvalues and residues are functions of the rate constants\nand the solute concentrations. Hence, the solutions yield the carrier densities\n(ni\nES(t), no\nES(t), ni\nE(t), and no\nE(t)) as functions of time for any values of the con-\ncentrations of solute S and of the transport parameters ai, ao, bi, bo, gi, go, hi,\nho, and NET.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nSteady-state solution\nIn the steady state, the density of carrier in each of its four states is constant and\nthe derivative terms on the left-hand side of Equation 4.30 are zero. As noted\npreviously, the four equations are not independent. Thus, one of the equations\ncan be eliminated.\nHowever, conservation of carrier leads to an independent\nconstraint which can be added to the three independent steady-state equations\nto yield the following four steady-state equations\n\n-(ai + hici\nS)\nai\nhici\nS\nao\n-(ao + hoco\nS)\ngi\n-(bi + gi)\ngo\nbo\n\nni\nE(inf)\nno\nE(inf)\nni\nES(inf)\nno\nES(inf)\n\n=\n\nNET\n\n.\n(4.35)\nThe solutions (Weiss, 1996a) are ratios of sums of products of rate constants\nni\nE(inf)\nNET\n= Mi\nE\nD , no\nE(inf)\nNET\n= Mo\nE\nD , ni\nES(inf)\nNET\n= Mi\nES\nD , no\nES(inf)\nNET\n= Mo\nES\nD ,\n(4.36)\nwhere\nMi\nE\n=\naobigo + aogigo + aobogi + bogihoco\nS,\nMo\nE\n=\naibigo + aigigo + aibogi + bigohici\nS,\nMi\nES\n=\naibohoco\nS + aogohici\nS + aobohici\nS + bohihoci\nSco\nS,\n(4.37)\nMo\nES\n=\naibihoco\nS + aigihoco\nS + aobihici\nS + bihihoci\nSco\nS,\nD\n=\nMi\nE + Mo\nE + Mi\nES + Mo\nES.\nThe steady-state flux is found elsewhere and equals (Weiss, 1996a)\n-φE(inf) = φS(inf) = φES(inf) = bigohici\nSni\nE(inf) -bogihoco\nSno\nE(inf)\nbigo + bogi + gigo\n.\n(4.38)\nThese equations yield the values of the n(inf)'s and the φ(inf)'s in steady state as\na function of the concentrations of solute S and of the transport parameters ai,\nao, bi, bo, gi, go, hi, ho, and NET.\nThe flux of solute can also be expressed in terms of the uni-directional fluxes\nas\nφS(inf) =\n→\nφS (inf)-\n←\nφS (inf),\nwhere\n→\nφS (inf)\n=\nbigohici\nSni\nE(inf)\nbigo + bogi + gigo\n,\n←\nφS (inf)\n=\nbogihoco\nSno\nE(inf)\nbigo + bogi + gigo\n.\n\n4.3. NUMERICAL METHODS\n4.3\nNumerical Methods And Parameters\n4.3.1\nNumerical methods\nThe steady-state values of the carrier densities and the carrier fluxes are alge-\nbraic functions of the solute concentrations and of the parameters. They could\nhave been computed directly from the steady-state matrix equations for each\ncarrier model. However, it proved to be faster to compute these quantities di-\nrectly from the solutions of these matrix equations which are: Equations 4.3-4.4\nand Equations 4.8-4.11 for the simple, four-state carrier, Equations 4.15-4.17 and\nEquations 4.21-4.26 for the simple, six-state carrier, and Equations 4.36-4.38 for\nthe general, four-state carrier.\nThe transient solution for the general, four-state carrier was obtained by solv-\ning Equation 4.33 numerically using MATLAB's ode15s routine for solving sets\nof ordinary differential equations. The solution for 3 of the 4 carrier densities\nwere computed; the fourth was computed from Equation 4.31. Eigenvalues of\nthe matrix of rate constants (Equation 4.33) were computed to aid the user in\nchoosing a time scale for displaying transient responses. Eigenvalues were com-\nputed using MATLAB's eig function.\n4.3.2\nChoice of numerical parameters\nThe software enables the user to compute the n's and φ's for any values of the\nparameters, the α's, β's, K's, NET, and the concentrations of solute, the c's. For\nthe simple models, the software is initiated with default parameters chosen to\napproximate hexose transport in human erythrocytes (Carruthers, 1984; Stein,\n1986) assuming a symmetric transport scheme. The density of carriers was set\nto NET = 10 pmoles/cm2. The dissociation constant of solute S was set to ap-\nproximate that of D-glucose, Ki\nS = Ko\nS = 2 μmoles/cm2, and that of R was set\nto that of a solute to which the carrier binds with lower affinity, approximating\nthat of D-xylose, so that Ki\nR = Ko\nR = 200 μmoles/cm2. All the rate constants\nwere set equal with a value that made the maximum flux 100 pmoles/cm2-s so\nthat αES = βES = αER = βER = αE = βE = 20 s-1. For the general model, the pa-\nrameters were chosen somewhat arbitrarily except that rate constants of binding\nreaction were chosen to be much greater than those of translocation reactions.\nAll the parameters were chosen to be approximately consistent with the simple\nmodels. The concentrations of solute were chosen arbitrarily as follows: ci\nS = 2,\nc0\nS = 1, ci\nR = 2, co\nR = 1 μmoles/cm3.\n4.4\nUser's Guide\nWhen the program is selected, 3 figures are displayed (in addition to MATLAB's\ncommand window): CMT Control, CMT Parameters, and CMT State. The CMT\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.4: CMT Control figure.\nFigure 4.5: CMT Units figure showing the\nunits of all the variables in the carrier mod-\nels.\nControl figure controls the software. The remaining figures are for steady-state\ninteractive analysis of the simple, four-state carrier. In the interactive mode, any\nparameter of the carrier model can be changed and the resulting steady-state val-\nues of carrier densities and fluxes are displayed immediately. The same steady-\nstate interactive analysis is available in all three models: the simple symmetric,\nfour-state carrier; the simple symmetric, six-state carrier; and the general, four-\nstate carrier. Additional modes of analysis allow plotting the steady-state values\nof carrier densities and fluxes as functions of a user-specified model parameter.\nIn addition, for the general, four-state carrier, the user can observe transient\nchanges in carrier densities in response to a change in parameters. All of these\nmodes of analysis are selected using the CMT Control figure.\n4.4.1\nCMT Control\nThe part of the CMT Control figure (Figure 4.4) below the menubar is divided\ninto three panels. The Model panel allows the user to choose a particular model\nfor analysis. The Analysis panel allows the user to choose among the available\nmodes of analysis in the software by clicking on the appropriate button. The\nmiscellaneous panel allows the user to display the units for all variables used by\nthe software (Figure 4.5).\n\n4.4. USER'S GUIDE\nFigure 4.6: The CMT Parameters figure (left) and CMT State figure (right) for the simple,\nfour-state carrier model that binds one solute.\n4.4.2\nModel\nThe CMT Control figure allows selection of three models of carrier-mediated\ntransport. Selecting a different model will initiate the steady-state, interactive\nanalysis for that model. The models are:\nSimple, four-state: refers to the simple, four-state carrier that binds one solute.\nThis is the default model that is displayed when the software is initialized.\nThe parameters and state figures associated with this model are shown in\nFigure 4.6.\nSimple, six state: refers to the simple, six-state carrier that binds two solutes\nshown in Figure 4.7.\nGeneral, four-state: refers to the general, four-state carrier that binds one solute\nshown in Figure 4.8.\n4.4.3\nSteady-state interactive analysis\nInteractive, steady-state analysis involves two figures -- the CMT Parameters and\nthe CMT State figures. Any parameter (independent variable) can be changed in\nthe CMT Parameters figure and the resulting changes in the steady-state values\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.7: The CMT Parameters figure (left) and CMT State figure (right) for the simple,\nsix-state carrier model that binds two solutes.\n\n4.4. USER'S GUIDE\nFigure 4.8: The CMT Parameters figure (left) and CMT State figure (right) for the general,\nfour-state carrier model that binds one solute.\nof the carrier state densities and carrier fluxes (dependent variables) are dis-\nplayed in the CMT State figure. The parameters for all three carrier models are\nlisted in Table 4.1. In both the CMT Parameters and CMT State figures, clicking\non any variable (parameter, carrier density, or carrier flux) displays information\nabout that variable.\nCMT Parameters\nThe numerical value of each parameter is displayed in the button located either\nabove or below each parameter.\nParameter values can be changed en masse\nby clicking the appropriate buttons in the upper part of the parameters figure.\nParameters can be Reset to their default values or read from a file. Parameters\nmay also be saved to a file.\nParameters may be changed individually in three ways.\n- A value may be changed arbitrarily by clicking on the button for each pa-\nrameter. The button is changed to a text-edit box which allows editing the\nparameter value. After typing RETURN, the new values of carrier densities\nand carrier fluxes are computed and displayed in the CMT State figure. A\nnon-numeric entry or a negative entry is not accepted and the prior value\nis restored.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nSimple\nSimple\nGeneral\nfour state\nsix state\nfour state\nTotal carrier density\nNET\nNET\nNET\nRate constants\nαE, βE,\nαE, βE, αES, βES,\nai, ao, bi, bo\nαES, βES\nαER, βER\ngi, go, hi, ho\nSolute concentrations\nci\nS, co\nS\nci\nS, co\nS, ci\nR, co\nR\nci\nS, co\nS\nDissociation constants\nKi\nS, Ko\nS\nKi\nS, Ko\nS, Ki\nR, Ko\nR\nTable 4.1: Modifiable parameters of the carrier models -- the independent variables.\n- A parameter, selected by clicking on its button, may be incremented or\ndecremented by clicking on\nor\nin the upper right in the CMT Parameters\nfigure. The state figure is updated with each incremental change in the\nparameter.\n- A parameter, selected by clicking on its button, may be incremented or\ndecremented repeatedly by clicking on\nor to the left of the\n, respec-\ntively. The CMT State figure is updated with each incremental change in\nthe parameter. Clicking on a repeat button again stops the repetitive pro-\ncess.\nIn the general, four-state carrier, passive transport of solute (also called the\nprinciple of detailed balance) requires that (Weiss, 1996a)\naihobogi = aohibigo.\nWhen this condition is violated, a warning messages is displayed in the CMT\nParameters figure, and the ratio\nr = aohibigo\naihobogi\nis displayed. To avoid warning messages for small differences in r caused by the\nlimited precision with which parameters are specified, messages are displayed\nonly if r differs from 1 by more than 5%.\nCMT State\nThe steady-state values of carrier densities and carrier fluxes are displayed in\nthe CMT State figure below each quantity for the particular set of parameters\n\n4.4. USER'S GUIDE\nshown in the CMT Parameters figure. These quantities are also displayed graph-\nically. Carrier densities are displayed with bar graphs that represent the relative\ndensities of carrier in each states. Both four-state carriers display ni\nE, no\nE, ni\nES,\nand no\nES. The six-state carrier displays ni\nE, no\nE, ni\nES, no\nES, ni\nER, and no\nER. The car-\nrier fluxes are displayed with thick arrows in the center of the figure. No arrow\nis displayed when the flux is zero. The direction of the arrow indicates the di-\nrection of the flux. The color of the arrow indicates the relative magnitude of\nthe carrier flux; a small magnitude flux has a black arrow, a large magnitude flux\nhas a bright red arrow. The color coding is irrelevant for the four-state models\nsince there are only two fluxes and they must have the same magnitude, but is\nuseful for the six-state model.\n4.4.4\nSteady-state graphic analysis\nSelection of Graphic analysis in the CMT Control figure, displays the CMT Steady\nstate plot figure (Figure 4.9).\nThis figure allows the user to plot any variable\nversus any of the parameters of the carrier-mediated transport model.\nThis\nfigure contains a number of panels.\nPlot control. The panel in the upper left corner controls plotting in the manner\ndescribed below.\nSetup. Clicking on Setup results in the display of the CMT Setup steady\nstate plot figure (Figure 4.10) which allows selection of one indepen-\ndent variable which determines the abscissa of the plot and multiple\ndependent variables which determine the ordinates.\nVariables. Clicking on an independent variable selects it for the ab-\nscissa (X) variable and deselects a previously selected variable.\nClicking on an unselected dependent (Y) variable adds it to the\ncollection of selected variables. Clicking on a selected dependent\nvariable deselects it. A maximum of four types of dependent vari-\nables can be selected for plotting. The range over which the in-\ndependent variable is swept can be selected in the text edit box.\nValues of parameters of the model (those not being changed) can\nbe selected from a file or taken from the interactive environment\nby clicking on the appropriate button in the upper left panel of\nthe figure.\nGraph. Clicking on Graph results in a plot of the selected data. The\nnew plot replaces the old plot.\nOverlay. Clicking on Overlay results in the next plot being overlayed\nover the current plot.\nOpen. Clicking this button allows plotting of results stored in a file.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.9: The CMT Steady state plot figure showing a plot of carrier densities versus\nci\nS on linear ordinate and abscissa scales.\nFigure 4.10: CMT Setup steady\nstate plot figure showing a plot\nof fluxes and carrier densities\nversus ci\nS\non linear ordinate\nand abscissa scales.Note that ci\nS\n(which is highlighted in blue)\nwas selected as the indepen-\ndent variable that defines the\nabscissa (horizontal axis) in the\nplot. The variables ni\nE, no\nE, ni\nES,\nand no\nES were selected as the de-\npendent variables and plotted\nas the ordinates (vertical axis).\n\n4.4. USER'S GUIDE\nFigure 4.11: The Axis scale figure after the\nabscissa was selected in Figure 4.9.\nSave. Clicking this button allows the information in the plot to be saved in\na file. All lines, labels, and annotations are saved.\nPrint. Clicking on Print prints the figure.\nCross-line. Clicking on\ndisplays a vertical line, the cross line, in the plot\nfield at the location of the pointer cursor. The line follows the cursor\nas it moves across the plot field. The values of all plotted variables at\nthe intersection with the cross line are displayed in the legend. Click-\ning on cross-line button again removes the cross-line values from the\nlegend and removes the cross line from the plotting field.\nAnnotate. Clicking on A and then on a desired location in the plot area\ndisplays a text edit box at that location. Click in the text edit box, type\nthe annotation followed by a <RETURN> when the annotation is com-\npleted. Clicking on the annotation and dragging the mouse moves the\nannotation to a desired location in the plot field. The text string can\nbe formatted into mathematical notation by using a LATEX like notation,\ne.g., to get ni\nES type n_{ES}ˆi.\nZoom. Clicking on\n+\nallows the user to magnify a region of the plotting\nfield by clicking on it. Additional magnification can be achieved by\nzooming again.\nUnzoom. Clicking on\n-\nundoes the effects of all prior zooms.\nAxes control. The plot axes can be changed by clicking on any of the axis labels\n-- either the abscissa or any of the ordinates -- which results in the display\nof the CMT axis scale figure (Figure 4.11). The axis scale can be chosen to\nbe linear, logarithmic, and/or reciprocal. If none of the options is chosen,\nthe scale is linear. If log scale is chosen, the scale is the logarithm of the\nmagnitude of the variable. If invert is chosen then the reciprocal of the\nabscissa variable is plotted either on a linear or on a logarithmic scale.\nClicking on Apply results in a change in the axis. The title of the axis label\ncan also be edited and the plot range can be changed.\nLegend. The legend panel records a list of all data plotted. The following are\nrecorded.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.12: Modify line properties\nfigure.\nThe user can select the line\ncolor, style, and the marker.\nLine properties. The color, line style, and symbol type are used to encode\na particular variable; this marker is shown in the legend. Clicking on\nthe marker displays a figure that allows the user to edit all the line\nand marker properties (Figure 4.12).\nVariable name. The name of the variable that was plotted is shown. Click-\ning on the variable name alternately displays and hides the curve as-\nsociated with this entry. When variables are added or deleted, the axis\nis auto-scaled if that option is selected -- it is selected by default -- in\nthe axis figure.\nCross-line If the cross-line is used the cross-line values are displayed.\nData-set. The time when the curves were generated are indicated. Click-\ning on the time stamp alternately displays and hides all the curves\nassociated with this legend item.\n4.4.5\nTransient analysis\nTransient analysis is available only for the generalized, four-state carrier by\nclicking on Transient in the CMT Control figure. This action displays the CMT\nTransient plot figure (Figure 4.9). The display control features of this figure are\nsimilar to those of the CMT Graphics Figure described above (Figure 4.9). We\ndescribe the differences only.\nSetup. Clicking on Setup displays the CMT Setup transient plot figure shown in\nFigure 4.14. The first column of this figure shows all the 11 independent\nvariables for the general, four-state carrier. The initial values are shown in\nthe second column and the final values are shown in the fourth column.\nThe initial values can be changed individually by typing in the new value\nin the appropriate text edit box. The third column gives several options\nfor changing any particular variable. Several independent variables can be\nchanged at once. The transient parameters can be saved in a file and read\nfrom a file. The bottom of the figure gives several additional options for\nchanging variables.\nNumerics. Clicking on this item displays the CMT Transients numerics figure\nwhich gives information to the user and allows for control of the time scale\n\n4.4. USER'S GUIDE\nFigure 4.13: The CMT Transient plot figure showing the transient response to the\nchange in parameters shown in Figure 4.14 and using the numerical data shown in\nFigure 4.15.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nFigure 4.14: The CMT Setup transient plot fig-\nure.\nof the transient response (Figure 4.15). The CMT Transients numerics fig-\nure displays the eigenvalues (as rate constants or time constants) of the\ntransient response. These eigenvalues can be computed for the initial or\nthe final values of all parameters by clicking on the appropriate button in\nthis figure. The eigenvalues have the dimensions of rate constants (RC).\nBut the software allows the equivalent time constants (TC = -1/RC) to be\ndisplayed. In addition, the user can choose to show the absolute value of\neither the rate constant or the time constant. The final value of the time in\nthe plot is determined by the bottom panel which has several options.\nFigure 4.15: The CMT Transients numerics figure.\n\n4.5. PROBLEMS\nAbsolute scale. Selecting this item displays plots of all carrier densities on the\nsame absolute scale.\nRelative scale.\nSelecting this item displays plots of all carrier densities on indi-\nvidual scales so that all the carrier densities are discernible.\n4.5\nProblems\nProblem 4.1 The purpose of this problem is to explore the steady-state behavior\nof the simple, symmetric, four-state carrier model. You will observe the effects of\nchanges in parameters on both the flux and the carrier densities. Use the simple,\nfour-state carrier model and start with all the parameters at their default values.\na. What is the relation of φS and φE? Explain.\nb. What is the relation of the direction of φS to the sign of ci\nS -co\nS? Explain.\nc. How does the state of the carrier depend on solute concentration?\ni. Do changes in ci\nS change ni\nES and ni\nE? If so, how? If not, why not?\nii. Do changes in ci\nS change no\nES and no\nE? If so, how? If not, why not?\niii. Do changes in co\nS change ni\nES and ni\nE? If so, how? If not, why not?\niv. Do changes in co\nS change no\nES and no\nE? If so, how? If not, why not?\nProblem 4.2 The purpose of this problem is to explore the effect of asymmetry of\nthe parameters of the simple, four-state carrier model on the relation between flux\nand concentration difference across the membrane. Use the simple, four-state\ncarrier model and start with all the parameters at their default values. Note the\nsymmetry of the default parameters, i.e., αE = αES, βE = βES, and Ki\nS = Ko\nS.\na. Using the default parameters, plot φS versus ci\nS.\ni. Determine the value of ci\nS at which the sign of φS changes. Explain\nthis sign change.\nii. On this plot indicate the region for which ci\nS -co\nS > 0. Is φS > 0 for\nthis range?\niii. On this plot indicate the region for which ci\nS -co\nS < 0. Is φS < 0 for\nthis range?\niv. What can you conclude from parts i-iii?\nb. Use the interactive environment, and change βES from its default value\nof 20 s-1 to 60 s-1.\nAt these values what is the relation of the solute\nconcentration gradient to the flux of solute?\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nc. Use the default parameters except that βES = 60 s-1. Plot φS versus ci\nS.\ni. Determine the value of ci\nS at which the sign of φS changes. Explain\nthis sign change.\nii. On this plot indicate the region for which ci\nS -co\nS > 0. Is φS > 0 for\nthis range?\niii. On this plot indicate the region for which ci\nS -co\nS < 0. Is φS < 0 for\nthis range?\niv. What can you conclude from parts i-iii?\nd. In part c is the flux always down the chemical potential gradient of the\nsolute?\nIf not, from where does the energy for transporting the solute\ncome?\nProblem 4.3 The purpose of this problem is to explore the effect of asymmetry\nof the parameters of the simple, four-state carrier model on the relation between\nunidirectional flux and concentration.\na. Use the simple, four-state carrier model and start with all the parameters\nat their default values. Note the symmetry of the default parameters, i.e.,\nαE = αES, βE = βES, and Ki\nS = Ko\nS.\ni. Plot 1/\n→\nφS versus 1/ci\nS. [The unidirectional efflux\n→\nφS is called effluxS\nin the software.]\nii. Plot 1/\n←\nφS versus 1/co\nS. [The unidirectional influx\n←\nφS is called influxS\nin the software.]\niii. To make direct comparisons between results you may wish to overlay\nthe plots. What do you conclude from parts i and ii? Explain these\nresults.\nb. Use the simple, four-state carrier model with all the parameters at their\ndefault values except change Ki\nS from its default value of 2 to 4 μmol/cm3.\nNote that the parameters are no longer symmetric.\ni. Plot 1/\n→\nφS versus 1/ci\nS. [The unidirectional efflux\n→\nφS is called effluxS\nin the software.]\nii. Plot 1/\n←\nφS versus 1/co\nS. [The unidirectional influx\n←\nφS is called influxS\nin the software.]\niii. To make direct comparisons between results you may wish to overlay\nthe plots. What do you conclude from parts i and ii? Explain these\nresults.\n\n4.5. PROBLEMS\nc. Compare the results in part a with those obtained in part b. What can you\nconclude from these results?\nProblem 4.4 The purpose of this problem is to explore the functional relation\nbetween solute flux and solute concentration when expressed in different coordi-\nnates. Use the simple, four-state carrier model and start with all the parameters\nat their default values, except set co\nS = 0. In parts a through c your job is to esti-\nmate the values of (φS)max and Ki\nS from the graphs specified, where (φS)max is\nthe maximum flux of S with co\nS = 0.\na. Obtain a graph of φS versus ci\nS in linear coordinates.\nb. Obtain a graph of φS versus ci\nS in double logarithmic coordinates.\nc. Obtain a graph of 1/φS versus 1/ci\nS.\nd. Determine the values of (φS)max and Ki\nS from the model parameters.\ne. Compare the 4 sets of values you have obtained for (φS)max and Ki\nS.\nProblem 4.5 The purpose of this problem is to explore the effect of solute concen-\ntration on carrier state. Use the simple, four-state carrier model and start with\nall the parameters at their default values, except set co\nS = 0. Obtain a graph of\nall four carrier states as a function of ci\nS. Some of the these n's increase, others\ndecrease, while others remain constant. Summarize and explain the results you\nfound.\nProblem 4.6 The purpose of this problem is to explore some of the conditions\nfor which a plot of flux versus concentration in reciprocal coordinates results in\na straight line. Use the simple, four-state carrier model and start with all the\nparameters at their default values.\na. Set co\nS = 0 and plot 1/φS versus 1/ci\nS.\nb. Set co\nS to its default value, co\nS = 1 μmol/cm3, and plot 1/φS versus 1/ci\nS.\nc. Compare the results in parts a and b and explain the differences.\nd. With co\nS = 1 μmol/cm3, plot 1/\n→\nφS versus 1/ci\nS. [The unidirectional efflux\n→\nφS is called effluxS in the software.] Compare the results of parts b and d\nand explain the difference.\nProblem 4.7 The purpose of this problem is to explore the process of exchange\ndiffusion. Use the simple, four-state carrier model and start with all the parame-\nters at their default values.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\na. In the interactive environment, set αE = βE = 0. Explain the values of the\nvariables in the state diagram.\nb. In the graphics environment, plot φS versus ci\nS. What do you conclude?\nc. In the graphics environment, plot 1/\n→\nφS and 1/\n←\nφS versus 1/ci\nS. What do\nyou conclude?\nd. Reconcile the results of parts b and c.\ne. The process defined in this problem has been called exchange diffusion.\nCritique this choice of name for this process. Why is this name appropri-\nate? Why is this name inappropriate?\nProblem 4.8 The purpose of this problem is to compare properties of simple and\ngeneral, four-state carriers.\na. Use the simple, four-state carrier model and start with all the parameters\nat their default values. For both co\nS = 1 and co\nS = 10 μmol/cm3, plot 1/\n→\nφS\nversus 1/ci\nS. [The unidirectional efflux\n→\nφS is called effluxS in the software.]\nYou may wish to overlay the plots to compare the results directly.\nb. Use the general, four-state carrier model and start with all the parameters\nat their default values. For both co\nS = 1 and co\nS = 10 μmol/cm3, plot 1/\n→\nφS\nversus 1/ci\nS. [The unidirectional efflux\n→\nφS is called effluxS in the software.]\nYou may wish to overlay the plots to compare the results directly.\nc. What do you conclude from parts a and b.\nProblem 4.9 The purpose of this problem is to explore properties of six-state car-\nriers. Use the simple, six-state carrier model and start with all the parameters\nat their default values. Set the solute concentrations of S and R to zero on both\nsides of the membrane.\na. Explain the initial carrier states and flux values.\nb. Increase ci\nS and observe both the carrier states and the flux. What is the\nrelation of the flux of S to ci\nS?\nc. Now set ci\nS = 10 μmol/cm3 and increase ci\nR. How do the fluxes of S and R\ndepend upon ci\nR?\nd. Set ci\nS = 10 and co\nS = 5 μmol/cm3. Now increase ci\nR from an initial value of\n0. How do the fluxes of S and R depend upon ci\nR? Pay particular attention\nto the direction of the flux of S.\n\n4.5. PROBLEMS\nProblem 4.10 The purpose of this problem is to explore properties of the simple,\nsix-state carrier model; in particular, the relation between the solute flux and\nthe parameters of the model. Use the simple, six-state carrier model and start\nwith all the parameters at their default values. Choose any parameter of the\nmodel (a rate constant or a dissociation constant). Try to think of a change in\nthat parameter that will lead to an increase in φS.\nChange the value of this\nparameter accordingly and determine if this change results in an increase in φS.\nIf φS does not change the way you predicted, find out why. If it does change\nas you predicted, then try another parameter and repeat the process. Do this\nfor at least 5 parameters to make sure that you have developed some intuition.\nDescribe what you did and the outcome.\nProblem 4.11 The purpose of this problem is to explore elementary properties of\nthe transient response of the general, four-state carrier. Use the general, four-\nstate carrier model and start with all the parameters at their default values.\na. In the interactive environment, record the values of all states of the carrier\n-- ni\nE, ni\nES, no\nE, and no\nES. Now change ci\nS from its default value of 2 to 20\nμmol/cm3 and record the values of all the states of the carrier.\nb. Switch to the transient environment and compute the transient response\nas ci\nS is stepped from its default value of 2 to 20 μmol/cm3.\ni. Determine the initial and final values of the transient response and\ncompare these results with the results obtained in part a.\nii. From plots of the transient response, estimate the time it takes the\nresponse to go from its initial value to 0.63 of its final value.\nc. Examine the CMT Transients numerics figure.\ni. Explain why there are multiple time constants listed?\nii. Do the time constants listed in this figure explain the transient re-\nsponse seen in part b? Explain.\nProblem 4.12 The purpose of this problem is to explore eigenvalues of the gen-\neral, four-state carrier model. Use the general, four-state carrier model and start\nwith all the parameters at their default values. Switch to the transient response\nand click on Setup in the CMT Transient plot figure.\nThis displays the CMT\nSetup transient plot figure. Select Numerics in the latter plot to display the CMT\nTransient numerics figure. Make sure that the eigenvalues are calculated from\nthe final parameter values and that rate constants are displayed instead of time\nconstants. In this problem, you will change the final values and calculate the\neigenvalues expressed as rate constants.\na. Record the eigenvalues (as rate constants) for the default settings.\n\nCHAPTER 4. CARRIER-MEDIATED TRANSPORT\nb. Change the value of ci\nS from its default value of 2 to 20 μmol/cm3. Record\nthe eigenvalues (as rate constants) corresponding to ci\nS = 20 μmol/cm3.\nc. Compare the eigenvalues (as rate constants) for ci\nS = 2 to that for ci\nS = 20\nμmol/cm3.\nd. Explain why the eigenvalues (as rate constants) depend upon the concen-\ntration.\ne. Suppose you regard the general, four-state carrier as a system that relates\nthe solute concentrations (as inputs) to the fluxes (as outputs).\nIs that\nsystem linear?\nProblem 4.13 The purpose of this problem is to explore the eigenvalues of the\ngeneral, four-state carrier model. Use the general, four-state carrier model and\nstart with all the parameters at their default values.\nSwitch to the transient\nresponse and click on Setup in the CMT Transient plot figure. This displays the\nCMT Setup transient plot figure. Select Numerics in the latter plot to display the\nCMT Transient numerics figure. Make sure that the eigenvalues are calculated\nfrom the final parameter values and are expressed as time constants. In this\nproblem, you will change the final values and calculate the eigenvalues (as time\nconstants).\na. Record the eigenvalues (as time constants) for the default settings.\nb. For each of the values given below, plot the transient response and record\nthe eigenvalues (as time constants).\ni. Change the binding/unbinding rate constants gi, go, hi, ho to 0.1 of\ntheir default values.\nii. Change the binding/unbinding rate constants gi, go, hi, ho to 0.01 of\ntheir default values.\niii. Change the binding/unbinding rate constants gi, go, hi, ho to 0.001 of\ntheir default values.\niv. Change the binding/unbinding rate constants gi, go, hi, ho to 0.0001\nof their default values.\nc. Plot the locations of the eigenvalues (as time constants) versus the factor\nby which the binding/unbinding rate constants were multiplied in double\nlogarithmic coordinates.\nd. Examine the transient responses and the results of part c.\nDiscuss the\nimplication of these results.\n\nChapter 5\nHODGKIN-HUXLEY MODEL -- SPACE\nCLAMPED\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n5.1\nIntroduction\n5.1.1\nBackground\nElectrically excitable cells produce action potentials which are important for\ntransmission of information in neurons, for contraction of muscle cells, and for\nsecretion of chemical substances by neurosecretory cells (Aidley, 1989; Hodgkin,\n1964; Katz, 1966; Kandel et al., 1991; Keynes and Aidley, 1991; Nicholls et al.,\n1992; Weiss, 1996b). The macroscopic mechanisms of production of action po-\ntentials can be understood in terms of the nonlinear electrical characteristics of\ncellular membranes first described by Hodgkin and Huxley for the membrane\nof the giant axon of the squid (Hodgkin and Huxley, 1952). Since the nonlin-\near properties of the membranes of electrically excitable cells are controlled by\nthe membrane potential, it is relatively simple to understand these mechanisms\nwhen the membrane potential is constant, but vastly more difficult when the\nmembrane potential is not constant such as occurs during an action potential.\nOf course, it is the properties of electrically-excitable cells under the latter con-\nditions that are the most important for the function of these cells.\n5.1.2\nOverview of the software\nThe purpose of this software package is to allow users to enhance their com-\nprehension of the Hodgkin-Huxley model by providing a complete simulation of\nthe model under space clamped conditions. Thus, this software package allows\nusers to explore the dependence on time of the space-independent Hodgkin-\nHuxley model.\nThis software package is complementary to the the software\npackage described in Chapter 6 which examines the dependence of the Hodgkin-\nHuxley model on space and on time. In the software described in the current\nchapter, the user can specify the mode of stimulation (either voltage or current\nclamp), model parameters (such as the membrane capacitance, the maximum\nmembrane conductances for membrane ionic channels, kinetic parameters for\neach of these membrane conductances, the concentrations of all relevant ions,\nthe temperature, etc.), run the simulation, and display the results (such as the\nmembrane potential, membrane-current components, membrane-conductance\ncomponents, and channel activation and inactivation variables).\nThe results\ncan be saved in files, and the contents of multiple files can be plotted on the\nsame axes. Hence, any of the parameters of the Hodgkin-Huxley model can be\nchanged by the user and simulation experiments can be done to examine the\nconsequences of the parameter changes. Extensive graphics utilities allow the\nuser to plot any variable versus any other variable in the model, to zoom on any\npart of the plot, to annotate the plot, and to determine the coordinates of any\npoint on a plot using a mouse-driven cursor.\n\n5.2. DESCRIPTION OF THE MODEL\n+\n-\nJm(t)\nVm(t)\n+\n-\nJm(t)\nVm(t)\n+\n-\n+\n-\n+\n-\nJC\nJK\nJNa\nJL\nGK(Vm, t)\nGNa(Vm, t)\nGL\nVK\nVNa\nVL\nCm\nFigure 5.1: Schematic di-\nagram and circuit model\nof a space-clamped axon\nin the voltage-clamp con-\nfiguration.\n5.2\nDescription Of The Model\nDescriptions of the Hodgkin-Huxley model are available elsewhere (Aidley, 1989;\nHodgkin, 1964; Katz, 1966; Plonsey and Barr, 1988; Johnston and Wu, 1995;\nWeiss, 1996b). A summary of this model is given in this section. The model that\nis the basis of this software is a one-compartment model that represents a space-\nclamped axon stimulated by means of two electrodes so that the membrane\ncurrent density and membrane potential are uniform along the length of the\naxon.\n5.2.1\nVoltage-clamp and current-clamp configurations\nTwo simple and mutually exclusive stimulus configurations can be used to in-\nvestigate the model: the voltage-clamp and current-clamp configurations. In the\nvoltage-clamp configuration (Figure 5.1), the simulated space-clamped axon is\ndriven by a voltage source and the membrane current density is computed. In\nthe current-clamp configuration, the simulated space-clamped axon is driven by\na current source and the membrane potential is computed.\n5.2.2\nThe membrane current density components\nThe total membrane current density, Jm, is the sum of the capacitance current\ndensity plus the ionic current density\nJm = JC + Jion,\n(5.1)\nwhere the capacitance current density is\nJC = Cm\ndVm(t)\ndt\n,\n(5.2)\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n+\n-\nJm(t)\nJm(t)\nVm(t)\n+\n-\nVm(t)\n+\n-\n+\n-\n+\n-\nJC\nJK\nJNa\nJL\nGK(Vm, t)\nGNa(Vm, t)\nGL\nVK\nVNa\nVL\nCm\nFigure 5.2: Schematic di-\nagram and circuit model\nof a space-clamped axon\nin the current-clamp con-\nfiguration.\nwhere Cm is the capacitance of a unit area of membrane and Vm is the membrane\npotential. The ionic current density can be expressed in terms of its components\nJion = JNa + JK + JL,\n(5.3)\nwhere the ionic current densities due to sodium, potassium and leakage are\nJNa\n=\nGNa(Vm, t)(Vm(t) -VNa),\n(5.4)\nJK\n=\nGK(Vm, t)(Vm(t) -VK),\n(5.5)\nJL\n=\nGL(Vm(t) -VL),\n(5.6)\nand where the Nernst equilibrium potential for the nth ion is defined in terms of\nthe concentrations as follows\nVn = RT\nznF ln\n\nco\nn\ncin\n\n,\n(5.7)\nwhere R is the molar gas constant, T is absolute temperature, F is Faraday's\nconstant, and zn, co\nn and ci\nn are the valence, outside, and inside concentrations\nof ion n, respectively. For a univalent ion, the Nernst equilibrium potential is\nexpressed as\nVn = 0.08616 (Tc + 273.16) ln\n\nco\nn\ncin\n\n(mV),\n(5.8)\nwhere Tc is the temperature in Centigrade.\n5.2.3\nThe membrane conductances\nThe sodium and potassium conductances are defined as\nGNa(Vm, t)\n=\nGNam3(Vm, t)h(Vm, t),\n(5.9)\nGK(Vm, t)\n=\nGKn4(Vm, t).\n(5.10)\n\n5.2. DESCRIPTION OF THE MODEL\n5.2.4\nThe activation and inactivation factors\nThe first-order kinetic equations for the activation and inactivation factors are\nwritten in terms of the rate constants as follows:\ndm\ndt\n=\nαm -m(αm + βm),\n(5.11)\ndh\ndt\n=\nαh -h(αh + βh),\n(5.12)\ndn\ndt\n=\nαn -n(αn + βn),\n(5.13)\nwhere the α's and β's depend upon Vm.\n5.2.5\nThe rate constants\nThe dependence of the rate constants on membrane potential has been gener-\nalized from the original Hodgkin-Huxley model to allow control of the potential\ndependence of individual rate constants and to represent approximately the ef-\nfects of changes in calcium concentration and temperature.\nThe rate constants are\nαm\n=\n-0.1(35 + Vm + ∆VCa + Vαm)\ne-0.1(35+Vm+∆VCa+Vαm) -1\nKTKm,\n(5.14)\nβm\n=\n4e-(Vm+∆VCa+Vβm+60)/18 KTKm,\n(5.15)\nαh\n=\n0.07e-0.05(Vm+∆VCa+Vαh+60) KTKh,\n(5.16)\nβh\n=\n1 + e-0.1(Vm+∆VCa+Vβh+30) KTKh,\n(5.17)\nαn\n=\n-0.01(Vm + ∆VCa + Vαn + 50)\ne-0.1(Vm+∆VCa+Vαn+50) -1\nKTKn,\n(5.18)\nβn\n=\n0.125e-0.0125(Vm+∆VCa+Vβn+60) KTKn,\n(5.19)\nwhere KT is a temperature factor, that is defined as\nKT = 3(T c-6.3)/10.\n(5.20)\nKT multiplies all the rate constants; this effect approximates the effect of tem-\nperature on the electrical properties of the membrane of the squid giant axon\n(Huxley, 1959).\nThe factors Km, Kh and Kn have been added to the original\nHodgkin-Huxley model to allow changes to be made in the individual rate con-\nstants of m, h, and n. The factor ∆VCa is used to approximate the dependence\nof rate constants on calcium concentration and is\n∆VCa = 0.03335 (Tc + 273.16)\n\nln\n\nco\nCa\nci\nCa\n\n-12.995\n\n(mV).\n(5.21)\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nAt the normal calcium concentration, the potential ∆VCa has the value 0. For cal-\ncium concentration ratios that differ from the normal value, ∆VCa differs from 0\nand the dependence of the rate constants on the membrane potential is shifted\nby a term that is proportional to the calcium equilibrium potential. This approxi-\nmates the effect of a change in calcium concentration on the parameters of squid\ngiant axon membrane (Frankenhaeuser and Hodgkin, 1957). The potentials Vαm,\nVβm, Vαh, Vβh, Vαn, and Vβn have the value 0 in the original Hodgkin-Huxley\nmodel. These potentials can be used to shift the dependence of individual rate\nconstants on membrane potential.\n5.2.6\nTime constants and equilibrium values of activation and\ninactivation factors\nEquations 5.11-5.13 are expressed in terms of rate factors, but it is also useful\nto express these equations in terms of time constants and equilibrium values, as\nfollows\ndm\ndt\n=\nminf-m\nτm\n,\ndh\ndt\n=\nhinf-h\nτh\n,\ndn\ndt\n=\nninf-n\nτn\n.\n(5.22)\nThe time constants and equilibrium values can be defined in terms of the rate\nconstants by comparing Equations 5.11-5.13 to Equation 5.22.\nτm\n=\nαm + βm\nand\nminf\n=\nαm\nαm + βm\n,\nτh\n=\nαh + βh\nand\nhinf\n=\nαh\nαh + βh\n,\nτn\n=\nαn + βn\nand\nninf\n=\nαn\nαn + βn\n.\n(5.23)\n5.2.7\nDefault values of parameters\nThe default numerical values for the Hodgkin-Huxley model are: GNa = 120,\nGK = 36, and GL = 0.3 mS/cm2; Cm = 1 μF/cm2; co\nNa = 491, ci\nNa = 50, co\nK =\n20.11, ci\nK = 400, co\nCa = 44, ci\nCa = 0.00011 mmol/L; VL = -49 mV; temperature is\n6.3*C.\n\n5.3. NUMERICAL METHODS\n5.3\nNumerical Methods\n5.3.1\nBackground\nIn order to compute the membrane potential for a given set of parameters, the\nequations describing the Hodgkin-Huxley model (listed in Section 5.2) must be\napproximated in a form that is appropriate for numerical solution on a digital\ncomputer. A variety of methods exist for the numerical integration of a set of\ncoupled differential equations (Press et al., 1986). The simplest methods, called\nthe forward and backward Euler methods, is to approximate all derivatives by\nfirst differences, and to solve the resulting collection of algebraic equations at\na series of discrete times separated by a time increment ∆t. Although simple\nin concept, the Euler methods are not particularly accurate or efficient. Because\nthe Hodgkin-Huxley software is built on MATLAB which includes a variety of\nmethods of numerical integration, the user can choose the method of integration\nfrom a number of choices.\n5.3.2\nChoice of integration step ∆t\nThe accuracy of all numerical methods is dependent on the choice of the integra-\ntion step ∆t.\nSimulation users will need to concern themselves with the choice\nof ∆t. If ∆t is decreased, the accuracy of a single step increases but the time it\ntakes to compute the solution increases. Furthermore, if computations are con-\ntinued for a large number of steps, the accumulation of round-offerrors, due\nto the limited precision for representing numbers in a computer, can become\nappreciable.\nConversely, if ∆t is increased, the accuracy of the computation\ndecreases and the solution may even diverge. This divergence can lead to spuri-\nous phenomena that may mistakenly be attributed to the Hodgkin-Huxley model\nwhen they are really artifacts of the numerical methods. A plausible empirical\ntest of whether or not a solution is sufficiently accurate is to test the sensitivity\nof the solution to changes in ∆t. If increasing the value of ∆t does not appre-\nciably change the solution, then the value of ∆t used initially is too small and\ntime was wasted in performing the computation. If decreasing the value of ∆t\ndoes not appreciably change the computational result, then the larger value is\npreferable. The simulation of the Hodgkin-Huxley model is set initially with de-\nfault numerical parameters. For changes in parameters of the model that do not\nappreciably change the various time constants of the model, the default numer-\nical parameters are adequate. However, if changing a model parameter (such as\nthe temperature, membrane capacitance, etc.) appreciably decreases some time\nconstant of the system, then a smaller value of ∆t should be used. Therefore, it\nis advisable to explore briefly the effects of varying ∆t on simulation results.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.3: The HH Control figure\nafter the software is initiated.\n5.3.3\nMethod for computing solutions\nIn the voltage clamp simulation, the solution is obtained as follows: Suppose the\nsolution is known at time tp-∆t and the solution at time tp is desired. The value\nof the membrane potential Vm(tp) at tp is determined from specification of the\nstimulus (see Equations 6.23 and 6.24 on Page 149). This value is substituted\ninto Equations 5.14 and 5.19 to determine the rate constants at tp. Using these\nrate constants, and given the values of m, h, and n at time tp -∆t, the values of\nm, h, and n are determined at tp by solving Equations 5.11-5.13 numerically by\nan integration method that can be chosen by the user. The values of these factors\nare used to compute the values of the conductances and current densities from\nEquations 5.1-5.6. The computation is begun with initial values of m, h, and n\nthat are determined from Equation 5.23 for a membrane potential equal to the\nsource voltage for t < 0.\nIn the current clamp simulation, the initial values of m, h, n, and Vm are com-\nputed first. This is done by using MATLAB's fzero function to solve the set of\nEquations 5.1, 5.3-5.21 and a specification of the source current (Equation 6.23\non Page 149) with the derivatives of all the variables set to zero. Starting with\nthese initial values, the time-varying equations are solved numerically by an in-\ntegration method that can be chosen by the user.\n5.4\nUser's Guide To The Software\nWhen this software is selected, 3 figures are displayed (in addition to MATLAB's\ncommand window): HH Control, HH Parameters, HH Stimulus. The HH Control\nfigure controls the software (Figure 5.3). The HH Parameters figure allows the\nuser to change any of the parameters of the model.\nThe HH Stimulus figure\nallows the user to specify the stimulus. Once the parameters and the stimulus\nare specified, clicking the Start pushbutton results in the computation of the\nresponse as a function of time. A variable is plotted as a function of time during\nthe computation. Upon completion of the computation, the user can examine\nthe results graphically and numerically.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\n5.4.1\nHH Control\nThe part of the HH Control figure (Figure 5.3) immediately below the menubar\nallows the user to choose between voltage-clamp and current-clamp configura-\ntions. Below this choice of configuration, there are three panels. In the left panel,\nthe user can choose to view the HH Parameters figure (which is used to specify\nthe parameters), the HH Stimulus figure (which is used to specify the stimulus as\na function of time), and/or the HH Numerics figure (which control the numerical\nmethods and numerical parameters). In the center panel, the user can start the\nsimulation by clicking on the Start button. The user can also save the simula-\ntion (including a specification of all the model and numerical parameters, the\nstimulus, and simulation results) in a file and open a previously stored file (that\nincludes a specification of all the model and numerical parameters, the stimu-\nlus, and simulation results). The right (analysis) panel becomes active after the\nsimulation is completed and allows the user to select three options for analysis\nof the results. The first option allows the user to plot any model variable as a\nfunction of time. This figure is displayed automatically as the computation pro-\nceeds. The second option displays a numerical summary of simulation variables.\nThe third option allows the user to access a quite general plotting facility that\nnot only plots any of the model variables versus any other model variable, but\nallows plotting results stored in files.\n5.4.2\nHH Parameters\nChanging parameter values\nThe HH Parameters figure contains three columns for each parameter: the first\ncolumn identifies the parameter, the second gives its default value, and the third\ncolumn shows the value of the parameter if it is modified from its default value.\nParameters are selected for modification by clicking on the entry in the third\ncolumn of the parameter field. When a parameter is selected, its third column\nentry is replaced by an edit box. Clicking any mouse button inside the edit box\nallows the parameter to be changed. The new value of the parameter is entered\nfrom the keyboard; < RETURN > terminates the parameter entry.\nIf the new\nvalue differs from the default value, then the new value will appear in the third\ncolumn. With this method of display, the parameter list can be scanned quickly\nto indicate which parameters differ from their default values.\nThere are some restrictions on the numerical values of parameters; G's ≥0,\nCm ≥0, c's > 0, K's > 0, and the temperature must be above absolute zero. The\nderived parameters cannot be changed but are derived from the other parame-\nters and are displayed for the convenience of the user. For example, the sodium\nequilibrium potential VNa cannot be changed directly by the user, but changes\nautomatically when the sodium concentrations or temperature are changed.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.4: The HH Parameters figure after\nthe software is initiated.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nReading, saving, printing, reseting the parameters\nParameters (only) can be read from a file by clicking on Open and can be saved\nby clicking on Save. Saving and reading in the HH Parameters figure deals only\nwith the model parameters; e.g., simulation results are not read or saved. The HH\nParameters figure can be printed by clicking the Print button. The parameters\ncan be reset to default values by clicking on Reset.\nViewing the voltage dependent parameters\nThe Hodgkin-Huxley model contains several parameters that are instantaneous\nfunctions of the membrane potential. Plots of these parameters are available\nas a function of Vm for the following: αm(Vm), βm(Vm), minf(Vm), τm(Vm),\nαh(Vm), βh(Vm), hinf(Vm), τh(Vm), αn(Vm), βn(Vm), ninf(Vm), τn(Vm) (see Sec-\ntions 5.2.5 and 5.2.6). These can be accessed by clicking on the button marked\nα, β, τ, h, m, n which results in the display of the HH parameters vs.\npoten-\ntialfigure (Figure 5.5). This figure contains a number of panels.\nPlot control. The panel in the upper left corner controls plotting in the manner\ndescribed below.\nSetup. Clicking on Setup results in the display of the HH Setup parame-\nters vs. potential plot figure (Figure 5.6) which allows selection of the\nvoltage-dependent parameters as a function of the membrane poten-\ntial.\nVariables. The abscissa is the membrane potential. Clicking on any\nvariable adds it to the collection of selected ordinate variables.\nClicking on it again deselects it.\nValues of parameters of the\nmodel can be selected from a file or taken from the parameters\nby clicking on the appropriate button in the upper right panel of\nthe figure.\nGraph. Clicking on Graph results in a plot of the selected data. The\nnew plot replaces the old plot.\nOverlay. Clicking on Overlay results in the next plot being overlayed\nover the current plot.\nSince the voltage-dependent parameters\ndepend upon additional parameters and variables, overlaying the\nplots allows a display of the effect of these additional parameters\nand variables on the voltage dependence parameters. For exam-\nple, a plot of minfversus Vm for different calcium concentrations\nreveals the effects of calcium concentration on the voltage depen-\ndence of sodium activation (Figure 5.7).\nOpen. Clicking this button allows plotting of results stored in a file.\nSave. Clicking this button allows the information in the plot to be saved in\na file. All lines, labels, and annotations are saved.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.5: The HH parameters vs. potential figure after selection of parameters as in\nFigure 5.6.\nFigure 5.6: The HH Setup pa-\nrameters vs.\npotential plot\nfigure that was used to pro-\nduce the plot shown in Fig-\nure 5.5.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.7: The HH parameters vs. potential figure showing the effect of calcium con-\ncentration on the voltage dependence of the sodium activation parameter minf. The\ncalcium concentration was varied from 0.000011 to 0.11 mmol/L by factors of 10.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.8: The Axis scale figure.\nPrint. Clicking on Print prints the figure.\nCross-line. Clicking on\ndisplays a vertical line, the cross line, in the plot\nfield at the location of the pointer cursor. The line follows the cursor\nas it moves across the plot field. The values of all plotted variables at\nthe intersection with the cross line are displayed in the legend. Click-\ning on cross-line button again removes the cross-line values from the\nlegend and removes the cross line from the plotting field.\nAnnotate. Clicking on A and then on a desired location in the plot area\ndisplays a text edit box at that location. Click in the text edit box, type\nthe annotation followed by a <RETURN> when the annotation is com-\npleted. Clicking on the annotation and dragging the mouse moves the\nannotation to a desired location in the plot field. The text string can\nbe formatted into mathematical notation by using a LATEX like notation,\ne.g., to get minftype m_{\\infty}.\nZoom. Clicking on\n+\nallows the user to magnify a region of the plotting\nfield by clicking on it. Additional magnification can be achieved by\nzooming again.\nUnzoom. Clicking on\n-\nundoes the effects of all prior zooms.\nAxes control. The plot axes can be changed by clicking on any of the axis labels\n-- either the abscissa or any of the ordinates -- which results in the display\nof a figure that allows changing the axis (Figure 5.8). The axis scale can be\nchosen to be linear, logarithmic, and/or reciprocal. If neither the Log nor\nthe Inverse (1/) options is chosen, the scale is linear. If Log is chosen, the\nscale is the logarithm of the magnitude of the variable. If Inverse (1/) is\nchosen then the reciprocal of the variable is plotted either on a linear or on\na logarithmic scale. Clicking on Apply results in a change in the axis. The\nplot range can be changed, but the axis labels cannot be edited.\nLegend. The legend panel records a list of all data plotted. The following are\nrecorded.\nLine properties. The color, line style, and symbol type are used to encode a\nparticular variable; this marker is shown in the legend. Clicking on the\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.9: The Modify line proper-\nties figure.\nFigure 5.10:\nHH Stimu-\nlus\nfigure\nwith\nthe\nde-\nfault\nstimulus\nwaveform\nfor a current-clamp config-\nuration.\nmarker allows the user to edit the attributes of the plot line/symbol\n(Figure 5.9).\nVariable name. The name of the variable that was plotted is shown. Click-\ning on the variable name alternately displays and hides the curve as-\nsociated with this entry. When variables are added or deleted, the axis\nis auto-scaled if that option is selected -- it is selected by default -- in\nthe axis figure.\nCross-line If the cross-line is used the cross-line values are displayed.\nData-set. The time when the curves were generated are indicated. Click-\ning on the time stamp alternately displays and hides all the curves\nassociated with this legend item.\n5.4.3\nHH Stimulus\nSelecting Stimulus in the controls figure displays the HH Stimulus figure as shown\nin Figure 5.10. The stimulus is the membrane potential in the voltage-clamp con-\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nfiguration and the membrane current density in the current-clamp configuration.\nThe duration of the stimulus can be set and, as described below, the user can\nalso select a file that will define the stimulus arbitrarily.\nUse of the m-file hhpulse.m\nBy default, the stimulus is generated by the MATLAB m-file hhpulse.m which\nuses the parameters listed in the lower part of the stimulus figure. The stim-\nulus is the sum of a constant plus two independently specifiable pulses. Each\npulse can be a rectangular pulse, a ramp pulse or an exponential pulse or a com-\nbination of these. If the slope and the time constant are set to zero, then the\nremaining parameters specify the amplitude, duration and onset time of a rect-\nangular pulse. If the slope has a non-zero value, a ramp of that slope is added to\nthe rectangular pulse for the duration of the pulse. Similarly, if the time constant\nhas a non-zero value, then an exponential pulse with the selected time constant\nis added to the waveform. The time constant can be positive or negative.\nThe stimulus, s(t), is defined as follows\ns(t) = so + s1(t) + s2(t),\n(5.24)\nwhere so is a constant and s1(t) and s2(t) are independently specifiable pulses.\nEach pulse has the form\nsi(t) =\n\nmi(t -ti\no) + Aie-(t-tio)/τi\nif to ≤t ≤to + tdur,\notherwise,\n(5.25)\nwhere pulse i (i = 1 or 2) starts at to and has a duration tdur. The amplitude\nof the pulse is Ai, the slope is mi, and the time constant is τi. With this spec-\nification, a rich variety of stimuli can be produced; an example is shown in Fig-\nure 5.11.\nThe stimulus parameters alone can be read from or saved to a file by selecting\neither Open or Save in the HH Stimulus figure.\nUse of stimulus m-files\nThis specification of the stimulus by hhpulse.m is quite rich. However, a user\nwho wishes to define a stimulus that differs from the one provided can write a\nMATLAB m-file to generate that stimulus. That file can then be selected in the\nHH Stimulus figure, and the stimulus it generates will be displayed in the figure.\nHowever, the parameters will have to be set by the user in the m-file. The script\nfor the available m-files can be used as templates to define new user-specified m-\nfiles. For example, the simple m-file shown in Figure 5.12 generates a sinusoidal\nstimulus.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.11: HH Stimulus\nfigure showing an exam-\nple of a stimulus current\nwaveform consisting of a\nconstant plus two pulses:\nthe first pulse is a ramp\nplus rectangular pulse; the\nsecond is an exponential\npulse.\nFigure 5.12: HH Stimulus\nfigure showing an example\nof the use of an m-file to\ngenerate a sinusoidal stim-\nulus.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.13: HH Numerics figure.\n5.4.4\nNumerics\nSelecting Numerics in the controls figure displays the HH Numerics figure (Fig-\nure 5.13). This figure allows selection of the numerical method used to solve\nthe ordinary differential equations (or ode solver) as well as the numerical pa-\nrameters of the simulation. The dialog-box that appears at the top allows direct\nselection of one of seven ode solvers called: ode45, ode23, ode113, ode23t,\node15s, ode23s, and ode23tb. The MATLAB manuals or MATLAB's help facility\nshould be consulted for further information about these methods. For exam-\nple, to learn about ode15s type Help ode15s at MATLAB's command line in\nthe MATLAB Command Window. More detailed descriptions are available else-\nwhere (Shampine and Reichelt, 1997). By default, the software uses the ode15s\node solver. The integration methods require that the following parameters be\ndefined: Initial step-size, Maximum step-size, Relative Tolerance.\nThe relative tolerance is an estimate of the accuracy of the solution, i.e., a tol-\nerance of 0.001 implies that the error in the solution is less than 0.1% of the\ncorrect value. Decreasing the tolerance will increase the accuracy of the solu-\ntion, but will increase the computation time.\nThe numerical parameters alone can be saved in a file or read from a file by\nclicking on Save or Open, respectively, in the HH Numerics figure.\n5.4.5\nAnalysis\nThe software provides one numeric and two graphic displays of simulation re-\nsults. These three displays are selected and deselected in the controls figure.\nAnalysis is available after a simulation has been run if the parameters have not\nbeen changed after the simulation was run.\nPlots versus time\nSelecting Plots vs. time in the Analysis panel of the HH Control figure displays\nthe HH Plots vs. time figure as shown in Figure 5.14. During a computation, this\nfigure displays the following variables: Vm in current clamp configuration and\nm in voltage-clamp configuration. When the computation is completed, any vari-\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.14:\nThe\nHH\nPlots\nvs.\ntime\nfigure\nwith\nVm\nchosen\nfor\nplotting.\nFigure 5.15: The HH Variable\nsummary figure after the sim-\nulation has been completed\nusing the default parameters\nfor a current-clamp configu-\nration.\nable can be selected by clicking on the dropdown menu at the top of the figure\nand then dragging the mouse to the variable of interest. This figure provides a\nsimple and rapid means of plotting any of the simulation variables versus time.\nClicking on an axis label displays the Axis scale figure (see Figure 5.8) which\nallows the axis to be changed.\nVariable summary\nSelecting Variable summary in the HH Control figure displays the HH Variable\nsummary figure as shown in Figure 5.15. This figure contains five columns of\ntext.\nThe first column identifies the simulation variable.\nThe second shows\nthe units for the variable. The third contains the initial value of the variable.\nThe fourth and fifth columns contain the minimum and maximum values of the\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.16: HH Graphics figure showing the membrane potential and ionic conduc-\ntance obtained from a simulation with model parameters and the stimulus defined in\nFigures 5.4 and 5.10.\nvariables during the course of the simulation.\nThe dropdown menus located\nbelow the menubar allow the user to control the precision and formatting of the\nnumerical values.\nGraphics\nSelecting Graphics in the HH Control figure displays the HH Graphics figure as\nshown in Figure 5.16. This figure allows plotting any result of the simulation\nagainst any other in coordinates chosen by the user. The control of this figure is\nvirtually identical to that for the HH Parameters vs. potential figure (Figure 5.5).\nHence, we describe only the differences. The main difference occurs if Setup is\nselected in the HH Graphics figure which results in display of the HH Setup plot\nfigure (Figure 5.17). Several dependent variables can be plotted simultaneously.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.17: HH Setup plot fig-\nure showing the variables used\nto setup Figure 5.16.\nIn addition, results saved in files can be plotted so that results for different\nparameters can be compared.\nIn addition, results of consecutive simulations\ncan be overlayed.\nWe give a few examples of the types of graphics that are\nreadily available with the HH Graphics figure.\nAs shown in Figure 5.18, parametric plots of one variable versus another\nwith time as the parameter are easily obtained. Figure 5.19 shows the membrane\npotential obtained at several different temperatures. This figure was obtained by\noverlaying successive computations. It could also have been created by saving\nthe results of simulations performed for different temperatures in files and then\nplotting the results from these files.\n5.4.6\nScripts\nScripting commands alleviate the burden of being present while repetitive, time\nconsuming simulations are computed. The set of commands available to the\nsoftware user can be found by issuing the command help hhscr.\nAlthough the set of scripting commands is not exhaustive enough to allow\noperating all aspects of the software from the command-line, it is sufficient to\ncarry out some of the time-consuming elements of the simulation.\nThe following is an example of a script used to perform current clamp simu-\nlations at different temperatures.\n%A Hodgkin-Huxley script demonstration\n%(contents are in HHDEMO1.M)\n%This script can be used to generate simulation data using the\n%current-clamped configuration.\nThe temperature is varied while\n%all other parameters remain unchanged.\n%For each value of the temperature, the simulation is run\n%and the resulting data are saved to data files which can then\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.18: HH Graphics figure showing a parametric plot of membrane conductances\nversus membrane potential during an action potential. All the parameters were the\ndefault parameters shown in Figure 5.4 and the stimulus was the same as shown in\nFigure 5.10 except that the duration was increased to 20 ms.\n\n5.4. USER'S GUIDE TO THE SOFTWARE\nFigure 5.19: HH Graphics figure showing the membrane potential obtained at different\ntemperatures.\nAll the parameters were the default parameters shown in Figure 5.4\nexcept for the temperature and the stimulus was the same as shown in Figure 5.10.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n%be used to display the results in the Graphics figure.\n%Before using the script, make sure that the Hodgkin-Huxley\n%software has been started.\n%If it hasn't been started, start the software using SOFTCELL.M\n%as follows softcell('hh');\n%hhscr('set') will list the parameters that can be changed\n%The parameter names are case-sensitive, so make sure that\n%you type them exactly as shown.\n%Insure that the current clamped configuration is being used.\nhhscr('set','Configuration','Current clamped');\n%Since a lot of files will be created, it is best to store them\n%in a separate folder.\nExamples of foldername are\n%foldername = 'C:\\data\\temp'; %Windows\n%foldername = '/user/tsb/data/temp'; %UNIX\nfoldername = pwd;\n%Set up a loop that increments through a temperature range.\n%In this case, we use the range T = [0 10 20 30] Celsius\nfor temp = 0:10:30\n%set the model's temperature parameter\nnewtemp = hhscr('set','T_C',temp);\n%perform simulation\nhhscr('start');\n%For feedback, display the temperature in the console\ndisp(['Temperature is set to ' num2str(newtemp)]);\n%create a unique filename that contains the simulation data\nfilename = ['temp' num2str(temp) '.mat'];\n%save the simulation data to the file\nhhscr('save','simulation',foldername,filename);\nend\n%That's it -- all the data have been saved.\n%Now, display the data simultaneously by following these steps:\n\n5.5. PROBLEMS\n%1. call up the \"Graphics\" figure,\n%2. using \"Setup\", select which variable(s) to plot,\n%3. still inside \"HH Setup plot\" figure, select the source of \"Get\n%\nvalues from\" to be the \"Files with parameters\".\n% 3a. using \"Select files\", add the files to the list \"Use these\n%\nfiles\".\n% 3b. select \"Overlay\" to view the selected variable(s) in all\n%\nthe datafiles.\nScripting can also be used to create customized plots of variables. For exam-\nple, after running a simulation, the time dependance of the sodium conductance\ncan be plotted on a separate figure using the following commands:\nu_gna = hhscr('get','G\\{ Na\\}'); %get the sodium conductance vector\nu_time = hhscr('get','t'); %get the vector of sampled time values\nfigure; %create a new figure\nplot(u_time,u_gna); %plot sodium conductance vs. time\nOnce the values of these variables are so obtained, they can be manipulated,\nmodified, and saved to files.\n5.5\nProblems\nProblem 5.1 The purpose of this problem is to explore the Hodgkin-Huxley model\nin the voltage-clamp configuration. Use the default parameters of the Hodgkin-\nHuxley model under voltage-clamp conditions to complete the following prob-\nlems. You may change only the stimulus parameters.\na. The potassium conductance\ni. Find the amplitude and duration of a rectangular pulse of membrane\npotential such that the potassium conductance reaches its final of\nGK(Vm, inf) = 9 ± 0.2 mS/cm2.\nii. What is the value of the time constant of n, τn, during this pulse?\nb. The sodium conductance\ni. Find the amplitude and duration of a rectangular pulse of membrane\npotential such that the peak sodium conductance is 15 ± 0.2 mS/cm2.\nMake sure that the pulse duration is sufficient so that there is a peak\nin the sodium conductance before the pulse terminates.\nii. What are the values of m and h at the time of the peak value of the\nsodium conductance?\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\niii. Increase the amplitude of the pulse 20 mV from the value you found\nabove and determine the peak sodium conductance and the values of\nm and h at the time of the peak value of the sodium conductance.\niv. Decrease the amplitude of the pulse 20 mV from the value you found\nabove and determine the peak sodium conductance and the values of\nm and h at the time of the peak value of the sodium conductance.\nProblem 5.2 The purpose of this problem is to explore the differences in time\ndependence of the [in]activation factors in voltage-clamp and current-clamp ex-\nperiments.\na. Run the simulation in the voltage-clamp configuration using the default\nparameters, except delay the onset of the pulse of voltage by 1 ms to make\nthe on and offtransients more readily visible. Examine the results of the\nsimulation and answer the following questions.\ni. Describe and explain the dependence on time of τm, minf, and m.\nii. Describe and explain the dependence on time of τh, hinf, and h.\niii. Describe and explain the dependence on time of τn, ninf, and n.\niv. Plot the voltage dependence of τm, τh, τn, minf, hinf, and ninf. Check the\nnumerical values of these variables against those obtained in parts i,\nii, and iv.\nb. Run the simulation in the current-clamp configuration using the default pa-\nrameters. Examine the results of the simulation and answer the following\nquestions.\ni. Describe and explain the dependence on time of τm, minf, and m.\nii. Describe and explain the dependence on time of τh, hinf, and h.\niii. Describe and explain the dependence on time of τn, ninf, and n.\nc. Succinctly summarize the differences in the time dependence of all these\nvariables in voltage-clamp and current-clamp configurations.\nProblem 5.3 The purpose of this problem is to explore a useful aspect of per-\nforming simulation experiments on a model; the model can be used to test ideas\nconcerning proposed measurements on cells.\nAssume that the membrane of neuron X has voltage-current characteristics\nas described by the Hodgkin-Huxley model except that the voltage dependences\nof the parameters of the factors n, m, and h are unknown.\nIn this problem\nyou are asked to develop methods to estimate the voltage dependence of some\nof these parameters and to assess the accuracy of your methods. To make the\n\n5.5. PROBLEMS\nsimulations realistic, in all parts of the problem you may only change the follow-\ning parameters: the concentrations of sodium, potassium, and calcium either\ninside or outside the cell, and the temperature.\nYou may use either voltage-\nclamp experiments or current clamp experiments. You can choose any stimulus\nwaveform that you can construct with the simulation. However, you must base\nyour estimation method on the membrane current in voltage clamp experiments\nand/or on the membrane potential in current-clamp experiments. For example,\nyou cannot base your estimation method on a direct measurement of m(t).\na. Develop a method to estimate the voltage dependence of minf.\nUse the\nsimulation to assess the accuracy of your method by comparing the results\nof your estimation of minfwith a direct computation of minf.\nb. Develop a method to estimate the voltage dependence of hinf. Use the sim-\nulation to assess the accuracy of your method as in part a.\nProblem 5.4 The purpose of this problem is to explore the threshold for elicit-\ning an action potential for a model of a space-clamped axon. By changing the\namplitude of the stimulus pulse, while keeping all other parameters at their de-\nfault values, determine the thresholdof the action potential to a precision of 4\nsignificant digits.\na. Describe the changes in action potential waveform as a function of current\namplitude.\nb. Does the change in waveform of the action potential as a function of stim-\nulus amplitude violate the all-or-none principal? Explain.\nc. Investigate the basis of the change in waveform of the action potential by\nexamining the behavior of variables in addition to the membrane potential\nas the current amplitude is varied.\nProblem 5.5 The purpose of this problem is to explore the refractory properties\nof the Hodgkin-Huxley model.\nApply two current pulses, each of amplitude 30\nμA/cm2 and duration 0.5 ms, separated by 12 ms in time. Set the simulation\nduration to 20 ms. Run the simulation. You should observe two action poten-\ntials. Reduce the inter-pulse interval to 10 ms. What happens? Now change the\namplitude of the second pulse to 50 μA/cm2 and observe the response. Change\nthe inter-pulse interval to 5 ms and observe the outcome.\na. Have you observed properties of the absolute or the relative refractory pe-\nriod?\nb. By examining the behavior of the factors m, n, and h during these two-\npulse simulations, determine which of these factors are most influential in\nrefractory properties.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nProblem 5.6 The purpose of this problem is to explore the phenomena of repet-\nitive activity\nand depolarization block\nof the Hodgkin-Huxley model. Perform\na sequence of simulations with the following parameters. Use a single current\npulse of duration 40 ms, a simulation duration of 50 ms, and stimulus ampli-\ntudes of 10, 25, 50, 100, and 200 μA/cm2.\na. Note that both the number of action potentials and their amplitudes vary\nwith the current amplitude.\nSketch the relation between the number of\naction potentials and current amplitude and between action potential am-\nplitude and current amplitude.\nb. By examining the behavior of the factors m, n, and h determine which of\nthese factors are most influential in determining repetitive activity. Explain\nyour reasoning.\nProblem 5.7 The purpose of this problem is to explore the phenomenon of anode-\nbreak excitation.\nThe phenomenon can be demonstrated by applying a pulse\nof current of duration 20 ms and amplitude -20 μA/cm2.\nUse a simulation\nduration of 40 ms.\na. Why is this phenomenon called anode-break excitation?\nb. By exploring the model variables explain this phenomenon.\nProblem 5.8 The purpose of this problem is to explore the phenomenon of accom-\nmodation. Accommodation can be illustrated by applying a ramp of current of\nslope 0.4 μA/(cm2 · ms) starting at an amplitude of 0 for a duration of 6 sec-\nonds (also set the simulation duration to 6 seconds). The model does not show\naccommodation for the default value of\nGNa = 120 mS/cm2 but does for a value\nof 80 mS/cm2. When the simulation is completed, plot the sodium, potassium\nand membrane current versus the membrane potential.\na. Perhaps no action potential has occurred in response to the ramp of cur-\nrent because the reduced value of the sodium conductance prevents action\npotential from being generated for any stimulus. Test this hypothesis.\nb. Explain the underlying basis of accommodation.\nc. What does the phenomenon of accommodation suggest about the notion\nof the threshold for eliciting an action potential?\nProblem 5.9 The purpose of this problem is to explore sub-threshold oscillations\nin the Hodgkin-Huxley model. Sub-threshold oscillations can be observed by us-\ning the default parameters with current pulses of 50 ms duration and simulation\ndurations of 100 ms. Use current amplitudes of .01, .1, 1, 2, and 2.5 μA/cm2.\n\n5.5. PROBLEMS\na. Describe your observations.\nb. Can the response of the model to a step of current be represented by the\nresponse of a network consisting of a constant resistance in parallel with a\nconstant capacitance. Explain.\nc. If your answer to part b was no, then devise a current stimulus such that\nthe model's response will approximate that of a network consisting of a\nconstant resistance in parallel with a constant capacitance. Explain your\nmethod.\nProblem 5.10 The purpose of this problem is to explore the strength-duration re-\nlation of the Hodgkin-Huxley model. Determine the threshold current amplitudes\n(to three significant figures) for eliciting action potentials for current pulses of\nduration 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, and 20 ms.\na. How does the threshold depend on current duration for low durations?\nExplain this behavior.\nb. How does the threshold depend on current duration for long durations?\nExplain this behavior.\nProblem 5.11 The purpose of this problem is to explore the interplay of factors\nthat determine the excitation of an action potential in the Hodgkin-Huxley model.\nThe Hodgkin-Huxley model with the default parameters stimulated by a pulse of\nmembrane current of amplitude 20 μA/cm2 and of duration 0.5 ms produces an\naction potential as shown in Figure 5.20. In each of the following computations,\none membrane parameter only differs from the default parameters, and for each\nof these computations no action potential occurs. The parameter changes are:\ni. A change in the temperature from 6.3*C to 35*C blocks the action potential\nas shown in Figure 5.20.\nii. A change in the maximum potassium conductance from 36 to 72 mS/cm2\nblocks the action potential. [Results not shown.]\niii. A change in the internal calcium concentration from 0.0001 to 0.0002\nmmol/l blocks the action potential. [Results not shown.]\niv. A change in the membrane capacitance from 1 μF/cm2 to 20 μF/cm2 blocks\nthe action potential as shown in Figure 5.20.\nv. A change in the external calcium concentration from 44 mmol/l to 22\nmmol/l blocks the action potential. [Results not shown.]\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nFigure 5.20: Results of simulation with all model parameters at their default values\nexcept where indicated (Problem 5.11). The curve labelled Default was obtained with\nthe default parameters. The curve labeled Tc = 35 was obtained with the default pa-\nrameters except that the temperature was set to 35*C. The curve labeled Cm = 20 was\nobtained with the default parameters except that the membrane capacitance was set to\n20 μF/cm2.\n\n5.5. PROBLEMS\nExamination of the results for the above computations (e.g., Figure 5.20) re-\nveals that there is no large change in membrane potential, i.e., no action potential\nhas occurred. For each of the computations:\na. Explain why no action potential occurred. You may wish to base your ex-\nplanation on the results obtained with each of the above computations. For\nexample, you may wish to examine the membrane currents, conductances,\nand activation variables that occurred for each computation. You may also\nwish to perform additional computations using different model parame-\nters. For example, to see why no action potential occurs for a large temper-\nature change, it might be instructive to examine the effects produced by\nsmaller changes in temperature. Since for many of the parts of this prob-\nlem, there are large changes in parameters you may wish to explore the\nrole of the numerical methods in arriving at the solutions.\nb. Determine a set of parameters so as to produce an action potential with a\nwaveform that is identical, except for a change in time scale and a change\nin resting potential, to the action potential obtained with the default pa-\nrameters. However, for each of the above parts, you may not change the\nparameter that differs from its default value. For example, for computation\nin part i, you may not change the temperature. Your task is to change some\nother parameter or group of parameters such that the action potential is\nrestored. For computation in part ii, you may not change the maximum\npotassium conductance. For computations in parts iii and v, you may not\nchange either the internal or the external calcium concentration, etc. RE-\nMEMBER -- the objective is not just to produce an action potential, that\nis too easy, but to obtain an action potential whose waveform is identi-\ncal to that obtained with the default parameters. To determine whether\nor not the action potential is identical to that obtained with the default\nparameters, you can superimpose plots and/or look at the variables sum-\nmary figures from the responses. You should use the computer as a tool\nto check your ideas and not as a substitute for thinking. You should avoid\na strictly trial-and-error approach. There are simply too many parameters\nin the Hodgkin-Huxley model for you to explore them all randomly. When\nyou have arrived at a satisfactory solution, print a hard copy of the model\nparameters figure showing the parameters you used to solve the problem\nand include this with your solution. Explain why your parameter change\nproduces the desired result. [HINT: simulations are not required to solve\nthese problems, but they are helpful for checking ideas quickly.]\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n5.6\nPROJECTS\nThe simulation software lends itself to more extensive study than that included\nin the Problems. These more extensive studies are called Projects and these are\ndescribed here.\n5.6.1\nPractical considerations in the choice of a topic\nProjects can involve almost any of the properties of the Hodgkin-Huxley model.\nHowever, to avoid projects whose aims are vague (e.g., \"I would like to under-\nstand how the Hodgkin-Huxley model works\") the proposed project should be in\nthe form of a specific and testable hypothesis. Projects that involve months of\ncomputation should obviously be avoided. Experience should indicate the dura-\ntion required to run simulations of the Hodgkin-Huxley model. These durations\nshould be taken into account explicitly in planning a project. For example, any\nproject that involves measuring the threshold of occurrence of an action poten-\ntial for many different parameter values is bound to be very time consuming,\nbecause determining the threshold for a single set of parameters itself involves\nmany computations. The task is to choose a physiological property of the ex-\ncitation of the action potential that is of interest, and then to define a specific,\nfeasible project.\n5.6.2\nChoice of topics\nTopics can involve comparing predictions of the Hodgkin-Huxley model with\nmeasurements on cells.\nFor example, the effects of changes in sodium ion\nconcentration on the action potential have been measured (Hodgkin and Katz,\n1949a; Baker et al., 1961). A project might involve reading the original papers\nthat describe such measurements (some were made before the Hodgkin-Huxley\nmodel was formulated), and testing the hypothesis that these measurements\nare (or are not) consistent with the Hodgkin-Huxley model. Similarly, a project\nmight involve examining the effect of some pharmacological substance on mea-\nsurements of the action potential and testing the hypothesis that the substance\nproduces its effect by changing one or another parameter of the model. These\nprojects will require some reading of original literature which is often difficult\nand usually time consuming. However, such a project can lead to a very reward-\ning educational experience.\nAlternatively, the project might involve a purely\ntheoretical topic in which some property of the model is explained in terms of\nthe underlying structure of the model. This type of project does not necessarily\ninvolve reading the original literature. To make the process of project defini-\ntion more tangible, we shall discuss one property of the Hodgkin-Huxley model\nof a space-clamped axon, the shape of the action potential, and suggest some\nappropriate projects based on this property.\n\n5.6. PROJECTS\nMembrane potential (mV)\nTime (ms)\nCat\nmotoneuron\n+50\n-50\n-100\nCat myelinated\nfiber\nTime (ms)\nFrog sartorius\nmuscle fiber\n+50\n-50\n-100\nSquid giant\naxon\nTime (ms)\n+50\n-50\n-100\nTime (ms)\nElectric eel\nelectroplaque\n+50\n-50\n-100\nTime (s)\n0.5\n1.5\nSheep purkinje\nfiber\n+50\n-50\n-100\n+50\n-50\n-100\nTime (ms)\nFigure 5.21: Examples of action potentials measured in a variety of cell types (Keynes\nand Aidley, 1991, adapted from Figure 2.4).\nBackground\nThe waveform of the action potential is different in different types of electrically-\nexcitable cells. As demonstrated in Figure 5.21, while the action potential wave-\nform has a peak-to-peak amplitude of about 100 mV, the duration and time\ncourse vary greatly. It is also known that the action potential waveform of a\ncell can be changed by changing a number of experimental variables. For ex-\nample, increasing the temperature tends to decrease the duration of the action\npotential (Figure 5.22), and reducing the external sodium concentration reduces\nthe amplitude and increases the duration of the action potential (Figure 5.23).\nSince action-potential waveforms vary from cell to cell and vary for one cell if\nenvironmental variables are changed, this raises a question -- To what extent\nare changes in action-potential waveforms seen in different cells due to inherent\ndifferences in the membrane mechanisms rather than to differences in membrane\nparameters with identical membrane mechanisms? For example, the action po-\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n20.2\n32.5\n13.3\n9.8\n6.3\n3.6\nVm(t) - Vmo (mV)\nTime (ms)\nFigure 5.22: Dependence of the action potential on temperature for measurements\nobtained from a giant axon of the squid (Hodgkin and Katz, 1949b).\n-40\n-80\nMembrane potential (mV)\nTime (ms)\nFigure 5.23: Effect of extracellular sodium concentration on the membrane potential of\na giant axon of a squid (Hodgkin and Katz, 1949a, adapted from Figure 4). Traces 1 and\n3 are the action potentials obtained in normal sea water before and after trace 2 which\nwas obtained in sea water with 50% sodium content. Isotonic solutions were obtained\nby using mixtures of sea water and a glucose solution.\n\n5.6. PROJECTS\ntentials of the squid axon and the frog and rat nodes of Ranvier shown in Fig-\nure 5.21 were measured at different temperatures. In fact, the briefest action po-\ntentials were obtained at the highest temperatures. Since Figure 5.22 indicates\nthat the duration of the action potential does become shorter at higher temper-\natures in squid axon, it may be that the temperature differences in the measure-\nments could explain the differences in the waveforms of the action potentials\nof these three preparations. It is clear that temperature changes alone cannot\nexplain all the variations seen in Figure 5.21 since the long-duration action po-\ntential of frog cardiac muscle was obtained at a higher temperature than was the\naction potential of the squid giant axon. However, perhaps some combination\nof changes of parameters in addition to temperature (e.g., ion concentrations,\nion conductances, membrane capacitance, etc.) might explain the long-duration\naction potential of cardiac muscle.\nExamples of hypotheses\nThe list of projects given below includes a number that deal with the waveform\nof the action potential generated by the Hodgkin-Huxley model as well as a few\nthat deal with other topics.\n1. Hypothesis -- The difference in waveform of the action potential of a frog\nnode of Ranvier and of a squid giant axon (Figure 5.21) can be reproduced\nby the Hodgkin-Huxley model of a squid giant axon by a change in temper-\nature.\n2. Hypothesis -- The membrane capacitance determines the time course of\nthe rising phase of the action potential. Increasing the membrane capaci-\ntance decreases the rate of increase of the rising phase of the action poten-\ntial.\n3. Hypothesis -- The falling phase of the action potential (repolarization) can\noccur in the absence of a change in potassium conductance.\n4. Hypothesis -- Increasing the temperature sufficiently blocks the occur-\nrence of the action potential because the membrane time constant limits\nthe rate at which the membrane variables can change and prevents the dif-\nference in time course of the sodium and potassium activation which is\nresponsible for initiation of the action potential.\n5. Hypothesis -- The initiation of the action potential is independent of the\npotassium conductance.\n6. Hypothesis -- The prolonged plateau of the cardiac muscle action poten-\ntial can be accounted for by the Hodgkin-Huxley model with a potassium\nconductance that has a slow activation.\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\n7. Hypothesis -- The effect of tetraethylammonium chloride (TEA) on the ac-\ntion potential of the squid giant axon can be modelled with the Hodgkin-\nHuxley model by decreasing Kn and increasing Kh. Articles in the literature\nshould be consulted for this project (Armstrong, 1966; Armstrong and Bin-\nstock, 1965; Tasaki and Hagiwara, 1957).\n8. Hypothesis -- The shape of the action potential in the presence of tetraethy-\nlammonium chloride (TEA) can be accounted for by the Hodgkin-Huxley\nmodel with a reduced maximum value of the potassium conductance. Arti-\ncles in the literature should be consulted for this project (Armstrong, 1966;\nArmstrong and Binstock, 1965; Tasaki and Hagiwara, 1957).\n9. Hypothesis -- Increasing the external calcium concentration will block the\noccurrence of the action potential because this will reduce the difference in\nthe time constant of sodium and potassium activation which is responsible\nfor the initiation of the action potential.\n10. Hypothesis -- Increasing the external concentration of potassium will de-\ncrease the refractory period; decreasing this concentration will lengthen\nthe refractory period.\n11. Hypothesis -- Increasing the external concentration of sodium will de-\ncrease the refractory period; decreasing this concentration will lengthen\nthe refractory period.\n12. Hypothesis -- Absolute and relative refractory periods are decreased by\nincreasing the rate constants for sodium inactivation and for potassium\nactivation.\n13. Hypothesis -- Repolarization cannot occur if the potassium activation rate\nconstant is zero.\n14. Hypothesis -- The threshold of the action potential to a brief pulse of cur-\nrent decreases as the external potassium current is increased.\n15. The Hodgkin-Huxley model with default parameters does not exhibit ac-\ncommodation (Weiss, 1996b). Hypothesis -- Accommodation occurs if the\nleakage conductance is increased.\n16. The Hodgkin-Huxley model with default parameters does not exhibit ac-\ncommodation (Weiss, 1996b). Hypothesis -- Accommodation occurs if the\npotassium conductance is increased.\n17. Hypothesis -- Increasing the leakage equilibrium potential will block the\naction potential.\n\n5.6. PROJECTS\n18. Hypothesis -- The effect of the changes in concentration of sodium ions on\nthe action potential of the giant axon of the squid can be accounted for by\nthe Hodgkin-Huxley model. Articles in the literature should be consulted\nfor this project (Hodgkin and Katz, 1949a; Baker et al., 1961).\n19. Hypothesis -- In response to rectangular pulses of current, the rheobase of\nthe strength-duration relation increases as temperature increases.\n20. Hypothesis -- An increase in temperature results in a decrease in the du-\nration of the refractory period.\n21. Hypothesis -- The threshold membrane potential at which the Hodgkin-\nHuxley model produces an action potential in response to a brief pulse\nof current is equal to the membrane potential for which the linearized\nHodgkin-Huxley equations have unstable eigenvalues.\n22. Application of a long-duration constant current to the Hodgkin-Huxley\nmodel produces a train of action potentials. Hypothesis -- The frequency\nof the action potentials increases with increasing current amplitude.\n23. Application of a long-duration constant current to the Hodgkin-Huxley\nmodel produces a train of action potentials. Hypothesis -- The frequency\nof action potential increases as the parameter Kn is increased.\n24. Application of a long-duration constant current to the Hodgkin-Huxley\nmodel produces a train of action potentials. Hypothesis -- The frequency\nof action potential increases as the temperature is increased.\n25. Hypothesis -- An increase in the external concentration of potassium in-\ncreases the threshold potential at which an action potential is elicited.\n26. Hypothesis -- Increasing Kh will result in an increase in the steepness of\nthe repolarization phase of the action potential.\nCaveats\nAny of these (or other) hypotheses can be the starting point for a project. Most\nof the hypotheses given above are simplistic, and a careful investigation will\nreveal their shortcomings. The Hodgkin-Huxley model is sufficiently complex\nthat investigation of any of the hypotheses will most likely lead to unexpected\nresults. It is informative to pursue these unexpected results and to try to under-\nstand their bases. For example, you may find that in pursuing some hypothesis\nyou choose to change some parameter of the model that you expect to result\nin some change in action potential waveform. The resulting computation might\nreveal, much to your surprise and chagrin, that no action potential has occurred\n\nCHAPTER 5. HODGKIN-HUXLEY MODEL\nor that multiple action potentials occur. Investigation of these unexpected find-\nings will usually be instructive. The aim should be not simply to reject or accept\nthe hypothesis but to delve into the topic in sufficient depth so as to a deepen\nunderstanding of the model. One outcome of the project might be to restate the\noriginal hypothesis in a new and more sophisticated form.\nIn pursuing these projects, it is important to keep in mind that it is not nerve\nmembrane that is being investigated but rather a model of nerve membrane; in\nfact, a very specific model -- the Hodgkin-Huxley model for the membrane of\nthe squid giant axon. Explanations of all phenomena seen with the model must\ninvolve the primitive concepts of this model -- e.g., the ionic conductances, ionic\nconcentrations, ionic currents, the capacitance, and the variables m, n, and h.\nExplanations in terms of molecular channel mechanisms or electrodiffusion of\nions in the membrane or ion pumps are irrelevant in so far as they are not con-\ntained in the Hodgkin-Huxley model! Finally, it is important to remember that\nthe software performs a numerical integration of the Hodgkin-Huxley equations.\nThus, the user will have to contend with the inherent approximations involved\nin numerical solutions of equations.\n\nChapter 6\nHODGKIN HUXLEY MODEL --\nPROPAGATED ACTION POTENTIAL\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\n6.1\nIntroduction\n6.1.1\nBackground\nAn electrically excitable cell produces a difference of potential across its cell\nmembrane, called an action potential. The difference in membrane potential is\naccompanied by a flow of current longitudinally through the intracellular and\nextracellular media, as well as current flow across the cell membrane along its\nentire length.\nThe spatial coupling of current flow through neighboring seg-\nments of the membrane results in the propagation of the action potential along\nthe cell surface.\nIn the 1950s, Hodgkin and Huxley derived a partial differential equation that\neffectively describes the electrical properties of the giant axon of the squid\n(Hodgkin and Huxley, 1952). This partial differential equation consists of the\ncore conductor equations, that describe the relation of current and voltage for\nan electrical cable, plus a characterization of the electrical properties of the cell\nmembrane. The cell is assumed to be cylindrical and the inner and outer conduc-\ntors are assumed to be equipotentials at each longitudinal position. Numerical\nsolutions to the partial differential equation were originally computed tediously\nby hand (Hodgkin, 1977; Huxley, 1964). With the introduction of the digital com-\nputer in the 1950s, solutions to these equations were computed more rapidly\n(Fitzhugh and Antosiewicz, 1959). By the 1960's computer speeds had increased\nto allow the first comprehensive study of the solutions to the partial differential\nequations (Cooley and Dodge, 1966). Further increases in computer speeds and\nthe development of improved numerical methods (Moore et al., 1975; Joyner\net al., 1978; Hines, 1984), have allowed solutions to be obtained on personal\ncomputers. The software package described here yields numerical solutions of\nthe partial differential equation that describe the propagation of the action po-\ntential along a model of the squid giant axon.\n6.1.2\nOverview of the software\nThis software deals with the time and space dependent Hodgkin-Huxley model\nand is complementary to the software described in Chapter 5.\nThe software\ndescribed in the current chapter is comprised of a number of setup and anal-\nysis figures that are launched from a main control figure. Using the setup fig-\nures, the user can specify the physical characteristics of the axon (length, radius,\netc.) and parameters of the membrane (capacitance, conductances of membrane\nionic channels, kinetic parameters, etc.) and bath (concentration of all relevant\nions, temperature, etc.).\nA stimulus source can be customized to the user's\nspecifications, and graphic icons of a pair of stimulus electrodes can be visu-\nally placed along a schematic representation of an axon. In addition, graphic\nicons representing a pair of recording electrodes can be placed along the axon\n\n6.2. THEORY\nschematic to compute and display the difference in potential. When a simula-\ntion is started, solutions are calculated using one of four user selectable numer-\nical methods, and the time-evolution of the membrane potential is shown color\ncoded to convey the space-time evolution of potentials on the axon schematic.\nAfter a simulation is completed, the user can display any of the computed so-\nlution variables (such as membrane potential, membrane-current components,\nmembrane-conductance components, channel activation and inactivation vari-\nables, etc.) using different interactive analysis figures which include: a figure\nthat displays the space-time evolution of any solution variable, a figure that gen-\nerates three-dimensional plots to show the dependence on time and on space of\nany solution variable, and a figure that generates comparison plots between the\nsolution variables at fixed times or at fixed positions.\n6.2\nTheory\nThe theory of the propagation of an action potential along an unmyelinated axon\nwas first described for the squid giant axon (Hodgkin and Huxley, 1952). We\nbriefly review this theory here; a more detailed description is available elsewhere\n(Weiss, 1996b).\n6.2.1\nCore conductor equations\nAn incremental portion of the core conductor model of a cylindrical unmyeli-\nnated nerve fiber is shown in Figure 6.1. Kirchhoff's laws relate the variables of\nthis incremental model. The core conductor equations result (Weiss, 1996b) if\nthe limit of these equations is taken as the incremental length of the fiber goes\nto zero, ∆z →0,\n∂Ii(z, t)\n∂z\n=\nKei(z, t) -Km(z, t),\n(6.1)\n∂Io(z, t)\n∂z\n=\nKm(z, t) -Keo(z, t),\n(6.2)\n∂Vi(z, t)\n∂z\n=\n-riIi(z, t),\n(6.3)\n∂Vo(z, t)\n∂z\n=\n-roIo(z, t),\n(6.4)\nVm(z, t)\n=\nVi(z, t) -Vo(z, t),\n(6.5)\n∂Vm(z, t)\n∂z\n=\n-riIi(z, t) + roIo(z, t).\n(6.6)\nThese equations can be combined to obtain a relation between the membrane\npotential Vm and the membrane current density Jm at time t and location z along\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nInner conductor\nOuter conductor\nMembrane\n+\n-\nz\n+\n-\nIi(z, t)\nIo(z, t)\nVi(z, t)\nVo(z, t)\nVm(z, t)\nIi(z+∆z, t)\nIo(z+∆z, t)\nVi(z+∆z, t)\nVo(z+∆z, t)\nVm(z+∆z, t)\nri∆z\nri∆z\nri∆z\nro∆z\nro∆z\nro∆z\nKm(z+∆z, t)∆z\nKm(z, t)∆z\nz + ∆z\nKei(z, t)∆z\nKei(z+∆z, t)∆z\nKeo(z, t)∆z\nKeo(z+∆z, t)∆z\nFigure 6.1: Equivalent network model of incremental sections of an unmyelinated nerve\nfiber showing the reference directions for all the voltage and current variables. The Ks\nare currents per unit length of the fiber: Km is the membrane current; Keo and Kei are\nextrinsic currents applied (by electrodes) externally and internally, respectively. Ii and\nIo are the internal and external longitudinal currents. Vm is the potential across the\nmembrane and Vi and Vo are the internal and external potentials,\nrespectively. The\ninternal and external resistance per unit length of the fiber are ri and ro.\na cylindrical, unmyelinated nerve fiber, often called the core-conductor equation\n2πa(ro + ri)\n∂2Vm(z, t)\n∂z2\n= Jm(z, t) -\n2πa(ro + ri)(roKeo(z, t) + riKei(z, t)),\nwhere a is the radius of the cylindrical cell and Km = 2πaJm, where Jm is the\nmembrane current per unit area. In addition, the resistance per unit length of\ncytoplasm can be expressed in terms of the resistivity as follows\nri =\nρi\n4πa2\nwhere ρi is the resistivity of cytoplasm.\n6.2.2\nRepresentation of stimulating electrodes\nAn arrangement of stimulating electrodes is shown in Figure 6.2. From Kirch-\nhoff's current law we have that at any position along the fiber\nIi(z, t) + Io(z, t) + Is(z, t) = 0,\n(6.7)\n\n6.2. THEORY\nExtracelllular\nExtracellular\nIntracellular\nz11\nz12\nz21\nz22\nI1(t)\nI2(t)\nFigure 6.2:\nThe relation of two\npairs of stimulus electrodes to a\nfiber is shown. The stimulus elec-\ntrodes are shown as extracellular\nbut any of the electrodes can be\nintracellular or extracellular.\nwhere Is(z, t) is the stimulus current in the positive z-direction which can be\nwritten as\nIs(z, t) = I1(t)\n\nu(z -z11) -u(z -z12)\n\n+ I2(t)\n\nu(z -z21) -u(z -z22)\n\n,\n(6.8)\nwhere u(z) is the unit step function defined as\nu(z) =\n\nif z > 0,\nif z < 0.\nThe electrode configuration shown in Figure 6.2 also imparts current compo-\nnents to Equations 6.1 and 6.2. With all the electrodes external, the currents per\nunit length are as follows\nKeo(z, t)\n=\nI1(t)\n\nδ(z -z11) -δ(z -z12)\n\n+ I2(t)\n\nδ(z -z21) -δ(z -z22)\n\n,\nKei(z, t)\n=\n0,\nwhere δ(z) is the unit impulse function.\nIf all four of the electrodes were intracellular then the currents per unit length\nwould be\nKeo(z, t)\n=\n0,\nKei(z, t)\n=\n-I1(t)\n\nδ(z -z11) -δ(z -z12)\n\n-I2(t)\n\nδ(z -z21) -δ(z -z22)\n\n,\nWith careful attention to signs, any combination of intracellular and extracellular\nstimulating electrodes can be accommodated. The algorithm is that extracellular\nelectrodes supply positive impulses at the cathode and negative impulses at\nthe anode; intracellular electrodes supply negative impulses at the cathode and\npositive impulses at the anode.\n6.2.3\nLongitudinal currents\nBy using the core conductor equations (Equation 6.6) and the KCL equation for\nthe current (Equation 6.7), we can solve for the longitudinal currents as follows\nIi(z, t)\n=\n-\nri + ro\n∂Vm(z, t)\n∂z\n-\nro\nri + ro\nIs(z, t),\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nIo(z, t)\n=\nri + ro\n∂Vm(z, t)\n∂z\n-\nri\nri + ro\nIs(z, t).\n6.2.4\nIntracellular and extracellular potential differences\nThe expressions for the longitudinal currents can be combined with Equations 6.3\nand 6.4 and the result integrated on z to yield the potential differences of a\nrecording electrode at zr2 minus that at zr1 as follows\nVi(zr2, t) -Vi(zr1, t)\n=\nri\nri + ro\n(Vm(zr2, t) -Vm(zr1, t))\n+ riro\nri + ro\nzr2\nzr1\nIs(z, t) dz,\nVo(zr2, t) -Vo(zr1, t)\n=\n-\nro\nri + ro\n(Vm(zr2, t) -Vm(zr1, t))\n+ riro\nri + ro\nzr2\nzr1\nIs(z, t) dz,\nwhere use of Equation 6.8 results in\nzr2\nzr1\nIs(z, t) dz\n=\nI1(t)\n\n(z -z11)u(z -z11) -(z -z12)u(z -z12)\n\n+I2(t)\n\n(z -z21)u(z -z21) -(z -z22)u(z -z22)\n\n.\n6.2.5\nThe membrane current density\nThe membrane current density consists of a capacitance current density and an\nionic current density Jion as follows,\nJm(z, t) = Cm\n∂Vm(z, t)\n∂t\n+ Jion(z, t),\nwhere Cm is the specific membrane capacitance, i.e., the capacitance of a unit\narea of membrane. For purposes of numerical solution of the core conductor\nequation, it is helpful to combine the ionic current density with the external\ncurrents so that\nJ(z, t) = Jion(z, t) -\n2πa(ro + ri)(roKeo(z, t) + riKei(z, t)),\n(6.9)\nand, therefore, the core conductor equation can be expressed as\n2πa(ro + ri)\n∂2Vm(z, t)\n∂z2\n= Cm\n∂Vm(z, t)\n∂t\n+ J(z, t).\n(6.10)\nThe ionic current density can be expressed in terms of its ionic components\nJion(z, t) = GK(Vm, t)(Vm -VK) + GNa(Vm, t)(Vm -VNa) + GL(Vm -VL), (6.11)\n\n6.3. NUMERICAL METHOD OF SOLUTION\nwhere Vn is the Nernst equilibrium potential of ion n\nVn = RT\nznF ln\n\nco\nn\ncin\n\n,\nwhere R is the molar gas constant, T is absolute temperature, F is Faraday's\nconstant, and zn, co\nn and ci\nn are the valence, outside, and inside concentrations\nof ion n, respectively. For a univalent ion, the Nernst equilibrium potential is\nexpressed as\nVn = 0.08616 (Tc + 273.16) ln\n\nco\nn\ncin\n\n(mV),\nwhere Tc is the temperature in Centigrade.\n6.2.6\nThe membrane conductances\nA full description of the Hodgkin-Huxley model of the ionic conductances is\ngiven beginning with Section 5.2.3.\n6.2.7\nDefault values of parameters\nThe default numerical values for the Hodgkin-Huxley model are: GNa = 120,\nGK = 36, and GL = 0.3 mS/cm2; Cm = 1 μF/cm2; co\nNa = 491, ci\nNa = 50, co\nK =\n20.11, ci\nK = 400, co\nCa = 44, ci\nCa = 0.00011 mmol/L; VL = -49 mV; external\nresistance per unit length, ro = 0 Ohm/cm; resistivity of axoplasm, ρi = 35.4\nOhm·cm; axon radius, a = 238 μm; temperature is 6.3*C.\n6.3\nNumerical Method of Solution\nThere are several ways to obtain a numerical solution to the equations describ-\ning the membrane potential in a cylindrical cell. In the finite-element method, the\ncylindrical axon is segmented into small cylinders over each of which the mem-\nbrane potential is assumed to be constant. Ordinary differential equations (with\ntime as the independent variable) can be written to describe the membrane po-\ntential and membrane current for each segment and the set of ordinary differen-\ntial equations can be solved numerically with appropriate boundary conditions\nlinking the electrical variables in adjoining segments.\nIn the finite-difference\nmethod, the partial differential equations are discretized directly by discretizing\nthe membrane potential and membrane current and approximating the spatial\nand temporal derivatives with finite differences.\nWe use the second method\nwhich is described in a number of texts on numerical methods of solution of\npartial differential equations (Smith, 1985; Press et al., 1986; Gerald and Wheat-\nley, 1989) and in research papers on the solution of the Hodgkin-Huxley model\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\n(Hines, 1984; Hines and Carnevale, 1998; Mascagni and Sherman, 1998; Pearl-\nmutter and Zador, 1999).\nThe first step is to discretize the membrane potential and current density\nvariables as follows,\nV n\ni\n=\nVm(i∆z, n∆t) = Vm(z, t)|z=i∆z,t=n∆t ,\nJn\ni\n=\nJ(i∆z, n∆t) = J(z, t)|z=i∆z,t=n∆t ,\nwhere ∆z and ∆t are the increments in z and t.\nThe second spatial derivative\nis approximated by the centered difference (also known as the method of lines),\n∂2Vm(z, t)\n∂z2\n≈V n\ni+1 -2V n\ni + V n\ni-1\n(∆z)2\n.\nAll of the numerical methods implemented use the above centered difference\napproximation to the second spatial derivative. The methods differ only in the\napproximation of the temporal derivative. There are two simple ways to approx-\nimate the temporal derivative at time t. In the forward Euler approximation,\n∂Vm(z, t)\n∂t\n≈V n+1\ni\n-V n\ni\n∆t\n,\nwhereas in the backward Euler approximation\n∂Vm(z, t)\n∂t\n≈V n\ni -V n-1\ni\n∆t\n.\nThe temporal approximation used in the Crank-Nicolson method essentially av-\nerages the forward Euler and the backward Euler approximations. The staggered\nincrement Crank-Nicolson method is a variant of the Crank-Nicolson method\nwith desirable numerical characteristics.\n6.3.1\nForward Euler method\nWith the forward Euler approximation, the discretized core conductor equation\n(Equation 6.10) is\n2πa(ro + ri)\n\nV n\ni+1 -2V n\ni + V n\ni-1\n(∆z)2\n\n= Cm\n\nV n+1\ni\n-V n\ni\n∆t\n\n+ Jn\ni .\n(6.12)\nBy collecting terms, the forward Euler approximation leads to the following dif-\nference equations\nV n+1\ni\n= ηV n\ni+1 + (1 -2η)V n\ni + ηV n\ni-1 -ξJn\ni ,\nwhere\nη =\n∆t\n2πa(ro + ri)(∆z)2Cm\nand ξ = ∆t\nCm\n.\n\n6.3. NUMERICAL METHOD OF SOLUTION\nNote that the forward Euler approximation results in an explicit method of solu-\ntion since it gives an explicit formula for computing the V n+1\ni\ngiven both V n\ni and\nJn\ni , i.e., the values of variables at time n + 1 are computed directly from their\nvalues at at time n.\nIn order to solve the equations numerically, we require initial conditions\nalong the length of the fiber plus boundary conditions at the two ends of the\nfiber. Initial conditions are simply that the membrane potential is at its resting\nvalue and that the membrane current is zero. The method for computing the\nresting potential is described in Section 5.3.3. A variety of boundary conditions\nare plausible. We shall use the boundary condition that the fiber is closed at\nboth ends so that the longitudinal current is zero at the two ends of the fiber.\nEquation 6.12 essentially expresses Kirchhoff's current law which can be modi-\nfied at the closed end to set the appropriate longitudinal current to zero. Using\nthis method for i = 1 and setting the longitudinal current from node 0 to node\n1 to zero yields\n2πa(ro + ri)\nV n\n2 -V n\n(∆z)2\n\n= Cm\n\nV n+1\n-V n\n∆t\n\n+ Jn\n1 ,\nwhich, after collecting terms, results in the difference equation\nV n+1\n= ηV n\n2 + (1 -η)V n\n1 -ξJn\n1 .\nA similar equation results at the other end of the fiber model so that the matrix\nequation can be written as\n\nV n+1\nV n+1\nV n+1\n...\nV n+1\nI-1\nV n+1\nI\n\n=\n\n1 -η\nη\n· · ·\nη\n1 -2η\nη\n· · ·\nη\n1 -2η\n· · ·\nη\n· · ·\n...\n...\n...\n...\n...\n...\n...\n· · ·\n1 -2η\nη\n· · ·\nη\n1 -2η\nη\n· · ·\nη\n1 -η\n\nV n\nV n\nV n\n...\nV n\nI-1\nV n\nI\n\n-ξ\n\nJn\nJn\nJn\n...\nJn\nI-1\nJn\nI\n\n.\nThe matrix equation can be written compactly as\nVn+1 = AFEVn -ξJn.\nTo obtain a solution, we need to compute Jn\ni . This current is linked to the\nionic currents (Equation 6.9) which themselves depend upon factors that are\nsolutions to differential equations (Equations 5.11-5.13). Let x stand for m, n,\nand h then we have\ndx\ndt = αm -x(αm + βm),\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nwhere α and β are instantaneous functions of membrane potential.\nWe dis-\ncretize this equation with the forward Euler algorithm as follows\nxn\ni -xn-1\ni\n∆t\n= αx\n\nV n-1\ni\n\n-xn-1\ni\n\nαx\n\nV n-1\ni\n\n+ βx\n\nV n-1\ni\n\n,\nand collect terms to obtain\nxn\ni = xn-1\ni\n\n1 -∆t\n\nαx\n\nV n-1\ni\n\n+ βx\n\nV n-1\ni\n\n+ ∆tαx\n\nV n-1\ni\n\n.\n(6.13)\nWith the factors m, n, and h substituted for x, the ionic current can be com-\nputed as follows\n(Jion)n\ni =\nGK(nn\ni )4(V n\ni -VK) +\nGNa(mn\ni )3hn\ni (V n\ni -VNa) + GL(V n\ni -VL),\nwhere each of the factors mn\ni , nn\ni , and hn\ni are computed according to Equa-\ntion 6.13. The total current is\nJn\ni = (Jion)n\ni -ro(Keo)n\ni + ri(Kei)n\ni\n2πa(ro + ri)\n.\nAlthough the Forward Euler method is relatively easy to understand, it's nu-\nmerical properties are undesirable. The forward Euler method is stable provided\nη ≤0.5 which implies that to achieve stable solutions, the discretization in space\nand in time cannot be chosen independently. Specifically, a stable solution re-\nquires ∆t ≤πa(ro + ri)(∆z)2Cm (Mascagni and Sherman, 1998). Thus, a choice\nof ∆x limits the choice of ∆t required to achieve stable solutions. If ∆t is too\nlarge, the solution will diverge. Thus, for example, the forward Euler algorithm\ncannot be used to efficiently compute the response for large values of ∆t such as\nwould be desirable to determine steady-state responses. Furthermore, the error\nresulting from temporal and spatial discretization behaves as O(∆t)+O((∆x)2).\nThus, although the method of solution using the forward Euler algorithm is sim-\nple to understand, the numerical properties of the method are not desirable.\n6.3.2\nBackward Euler method\nWith the backward Euler approximation (advanced one point in time), the dis-\ncretized core conductor equation is\n2πa(ro + ri)\n\nV n+1\ni+1 -2V n+1\ni\n+ V n+1\ni-1\n(∆z)2\n\n= Cm\n\nV n+1\ni\n-V n\ni\n∆t\n\n+ Jn+1\ni\n,\n(6.14)\nwhich, after collecting terms and changing signs, yields the difference equation\n-ηV n+1\ni+1 + (1 + 2η)V n+1\ni\n-ηV n+1\ni-1 = V n\ni -ξJn+1\ni\n.\n\n6.3. NUMERICAL METHOD OF SOLUTION\nNote that the backward Euler method is an implicit method of solution since it\ngives an implicit formula for computing the V n+1\ni\ngiven both V n\ni and Jn\ni . Thus,\nthe solution can only be obtained by solving a set of coupled algebraic equations.\nWe use the same initial and boundary conditions as for the forward Euler\nalgorithm. By modifying Equation 6.14 with a closed end condition at i = 1 and\ncollecting terms, the difference equation is\n-ηV n+1\n+ (1 + η)V n+1\n= V n\n1 -ξJn\n1 .\nA similar equation results at the other end of the fiber model so that the incor-\nporation of the closed-end boundary conditions results in the following matrix\nequation\n\n1 + η\n-η\n· · ·\n-η\n1 + 2η\n-η\n· · ·\n-η\n1 + 2η\n· · ·\n-η\n· · ·\n...\n...\n...\n...\n...\n...\n...\n· · ·\n1 + 2η\n-η\n· · ·\n-η\n1 + 2η\n-η\n· · ·\n-η\n1 + η\n\nV n+1\nV n+1\nV n+1\n...\nV n+1\nI-1\nV n+1\nI\n\n=\n\nV n\nV n\nV n\n...\nV n\nI-1\nV n\nI\n\n-ξ\n\nJn+1\nJn+1\nJn+1\n...\nJn+1\nI-1\nJn+1\nI\n\n.\nThe matrix equation can be written compactly as\nABE · Vn+1 = Vn -ξJn+1,\nwhich has the solution\nVn+1 = ABE\n-1 ·\n\nVn -ξJn+1\n.\n(6.15)\nSimilar to the procedure with the forward Euler algorithm, Jn+1\ni\ncan be com-\nputed from the factors that determine the ionic conductances. Once again, we\nlet x stand for m, n, and h, and we discretize this equation, this time with the\nbackward Euler algorithm as follows\nxn+1\ni\n-xn\ni\n∆t\n= αx\n\nV n+1\ni\n\n-xn+1\ni\n\nαx\n\nV n+1\ni\n\n+ βx\n\nV n+1\ni\n\n,\nand collect terms to obtain\nxn+1\ni\n=\nxn\ni + ∆tαx\n\nV n+1\ni\n\n1 + ∆t\n\nαx\n\nV n+1\ni\n\n+ βx\n\nV n+1\ni\n.\n(6.16)\nWith the factors m, n, and h substituted for x, the ionic current can be com-\nputed as follows\n(Jion)n+1\ni\n=\nGK(nn+1\ni\n)4(V n\ni -VK) +\nGNa(mn+1\ni\n)3hn+1\ni\n(V n\ni -VNa) + GL(V n\ni -VL),\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nwhere each of the factors mn+1\ni\n, nn+1\ni\n, and hn+1\ni\nare computed according to Equa-\ntion 6.16. The total current is\nJn+1\ni\n= (Jion)n+1\ni\n-ro(Keo)n+1\ni\n+ ri(Kei)n+1\ni\n2πa(ro + ri)\n.\nOne difference is that the factor xn+1\ni\ndepends upon the potential V n+1\ni\nso\nthat the four equations -- Equation 6.15 and three equations (one for each of\nthe factors m, n, and h) of the form of Equation 6.16 -- need to be solved simul-\ntaneously. To obtain accurate solutions, the set of 4 equations are iterated until\nthe 4 variables V n+1, mn+1\ni\n, nn+1\ni\n, and hn+1\ni\nconverge to within some specified\nlimit. For example, Equation 6.15 can be solved for the value of V n+1 using the\nvalues of the factors at time increment n to compute new values of the factors.\nThese are then used to compute the new value of V n+1 which is used to compute\nnew values of the factors, etc.\nThe backward Euler algorithm is stable for all values of ∆t and ∆x. Thus ∆t\nand ∆z can be chosen independently. Large values of ∆t can be used to deter-\nmine approximate steady-state values of the solution. Just as for the forward\nEuler algorithm, the error resulting from temporal and spatial discretization us-\ning the backward Euler algorithm behaves as O(∆t) + O((∆x)2).\n6.3.3\nCrank-Nicolson method\nIn the Crank-Nicolson method, the forward Euler and backward Euler approxi-\nmations are averaged to yield the following difference equation\n4πa(ro + ri)\n\nV n+1\ni+1 -2V n+1\ni\n+ V n+1\ni-1\n(∆z)2\n+ V n\ni+1 -2V n\ni + V n\ni-1\n(∆z)2\n\n=\nCm\n\nV n+1\ni\n-V n\ni\n∆t\n\n+ 1\n2(Jn\ni + Jn+1\ni\n).\n(6.17)\nAlternatively, this equation can be regarded as satisfying the partial differential\nequation at the discrete time n + 1\n2 with central differences used for all deriva-\ntives. This interpretation is exploited in the next section on the Staggered incre-\nment Crank-Nicolson method.\nEquation 6.17 can be rearranged and simplified so that all the voltage vari-\nables evaluated at time step n + 1 are on the left and all those at time step n are\non the right as follows\n-η\n2V n+1\ni+1 + (1 + η)V n+1\ni\n-η\n2V n+1\ni-1 = η\n2V n\ni+1 + (1 -η)V n\ni + η\n2V n\ni-1 -ξ Jn+1\ni\n+ Jn\ni\n.\nAs can be seen from the above equations, the Crank-Nicolson method is also an\nimplicit method.\n\n6.3. NUMERICAL METHOD OF SOLUTION\nWe use the same initial and boundary conditions as for the forward and back-\nward Euler algorithms. By modifying Equation 6.17 at the closed end at i = 1\nand collecting terms, the difference equation is\n-η\n2V n+1\n+ (1 + η\n2)V n+1\n= η\n2V n\n2 + (1 -η\n2)V n\n1 -1\n2ξ(Jn\n1 + Jn+1\n).\nA similar equation results at the other end of the fiber model so that with the\nincorporation of the closed-end boundary conditions, the matrix equation for\nthe Crank-Nicolson method is\n\n1 + η\n-η\n· · ·\n-η\n1 + η\n-η\n· · ·\n-η\n1 + η\n· · ·\n-η\n· · ·\n...\n...\n...\n...\n...\n...\n...\n· · ·\n1 + η\n-η\n· · ·\n-η\n1 + η\n-η\n· · ·\n-η\n1 + η\n\nV n+1\nV n+1\nV n+1\n...\nV n+1\nI-1\nV n+1\nI\n\n=\n\n1 -η\nη\n· · ·\nη\n1 -η\nη\n· · ·\nη\n1 -η\n· · ·\nη\n· · ·\n...\n...\n...\n...\n...\n...\n...\n· · ·\n1 -η\nη\n· · ·\nη\n1 -η\nη\n· · ·\nη\n1 -η\n\nV n\nV n\nV n\n...\nV n\nI-1\nV n\nI\n\n-ξ\n\nJn\nJn\nJn\n...\nJn\nI-1\nJn\nI\n\n+\n\nJn+1\nJn+1\nJn+1\n...\nJn+1\nI-1\nJn+1\nI\n\n.\nThe matrix equation can be written as\nACN1 · Vn+1 = ACN2 · Vn -ξ\n\nJn + Jn+1\n,\nwhich has the solution\nVn+1 = ACN1\n-1 · ACN2 · Vn -ξ\n2ACN1\n-1 ·\n\nJn + Jn+1\n.\nSimilar to the procedure with the forward and backward Euler algorithms,\nwe need to compute Jn\ni from the factors that determine the ionic conductances.\nOnce again, we let x stand for m, n, and h, and we discretize this equation, this\ntime with the trapezoidal rule, so as to preserve the O((∆t)2) error in time, as\nfollows\nxn+1\ni\n-xn\ni\n∆t\n=\nαx\n\nV\nn+ 1\ni\n\n-xn+1\ni\n\nαx\n\nV\nn+ 1\ni\n\n+ βx\n\nV\nn+ 1\ni\n\n+\nαx\n\nV\nn+ 1\ni\n\n-xn\ni\n\nαx\n\nV\nn+ 1\ni\n\n+ βx\n\nV\nn+ 1\ni\n\n,\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nand collect terms to obtain\nxn+1\ni\n=\n∆t\n2 αx\n\nV\nn+ 1\ni\n\n1 + ∆t\n\nαx\n\nV\nn+ 1\ni\n\n+ βx\n\nV\nn+ 1\ni\n\n+xn\ni\n1 -∆t\n\nαx\n\nV\nn+ 1\ni\n\n+ βx\n\nV\nn+ 1\ni\n\n1 + ∆t\n\nαx\n\nV\nn+ 1\ni\n\n+ βx\n\nV\nn+ 1\ni\n\n(6.18)\nWith the factors m, n, and h substituted for x, the ionic current can be com-\nputed as follows\n(Jion)n+1\ni\n=\nGK(nn+1\ni\n)4(V n\ni -VK) +\nGNa(mn+1\ni\n)3hn+1\ni\n(V n\ni -VNa) + GL(V n\ni -VL),\nwhere each of the factors mn+1\ni\n, nn+1\ni\n, and hn+1\ni\nare computed according to Equa-\ntion 6.16. The total current is\nJn+1\ni\n= (Jion)n+1\ni\n-ro(Keo)n+1\ni\n+ ri(Kei)n+1\ni\n2πa(ro + ri)\n.\nAs with the backward Euler algorithm, the factor xn+1\ni\ndepends upon the po-\ntential V\nn+ 1\ni\nthrough the parameters α and β so that iteration must be used to\narrive at a solution of the 4 simultaneous equations.\nFor linear, parabolic partial differential equations, the Crank-Nicolson method\nyields stable solutions although not as stable as the backward Euler method,\ni.e., spurious bounded amplitude oscillations may appear for large values of in-\ncrements. In contrast to both the forward and backward Euler algorithms, the\nerror resulting from temporal and spatial discretization for the Crank-Nicolson\nmethod behaves as O((∆t)2) + O((∆x)2) provided appropriate boundary con-\nditions (such as those shown above) are used. Thus, with the Crank-Nicolson\nmethod it is possible to achieve more accurate solutions for large time intervals\nthan for the backward Euler method.\n6.3.4\nStaggered increment Crank-Nicolson method\nA computationally efficient method (Hines, 1984) that avoids iteration of the so-\nlution is based on the observation that the Crank-Nicolson differencing scheme\nsatisfies the partial differential equation at the discrete time n+ 1\n2. This property\ncan be seen by writing out the expression as follows\n2πa(ro + ri)\n\nV\nn+ 1\ni+1 -2V\nn+ 1\ni\n+ V\nn+ 1\ni-1\n(∆z)2\n\n= 2Cm\n\nV\nn+ 1\ni\n-V n\ni\n∆t\n\n+ J\nn+ 1\ni\n,\n(6.19)\n\n6.3. NUMERICAL METHOD OF SOLUTION\nwhich results in the following difference equation\n-η\n2V\nn+ 1\ni+1 + (1 + η)V\nn+ 1\ni\n-η\n2V\nn+ 1\ni-1\n= V n\ni -ξ\n2J\nn+ 1\ni\n.\nNote that starting with the membrane potential at discrete time n, the difference\nequation computes (by an implicit method) the potential at n + 1\n2.\nThen the\npotential at discrete time n + 1 is computed by the explicit method\nV n+1\ni\n= 2V\nn+ 1\ni\n-V n\ni .\n(6.20)\nWe use the same initial and boundary conditions as for the other algorithms.\nBy modifying Equation 6.19 at the closed end at i = 1 and collecting terms, the\ndifference equation is\n-η\n2V\nn+ 1\n+ (1 + η\n2)V\nn+ 1\n= V n\n1 -ξ\n2(J\nn+ 1\n.\nA similar equation results at the other end of the fiber model so that the matrix\nequation is\n\n1 + η\n-η\n· · ·\n-η\n1 + η\n-η\n· · ·\n-η\n1 + η\n· · ·\n-η\n· · ·\n...\n...\n...\n...\n...\n...\n...\n· · ·\n1 + η\n-η\n· · ·\n-η\n1 + η\n-η\n· · ·\n-η\n1 + η\n\nV\nn+ 1\nV\nn+ 1\nV\nn+ 1\n...\nV\nn+ 1\nI-1\nV\nn+ 1\nI\n\n=\n\nV n\nV n\nV n\n...\nV n\nI-1\nV n\nI\n\n-ξ\n\nJ\nn+ 1\nJ\nn+ 1\nJ\nn+ 1\n...\nJ\nn+ 1\nI-1\nJ\nn+ 1\nI\n\n.\nThe matrix equation can be written as\nACN · Vn+ 1\n2 = Vn -ξ\n2Jn+ 1\n2 ,\nwhich has the solution\nVn+ 1\n2 = ACN\n-1 ·\n\nVn -ξ\n2Jn+ 1\n\n.\n(6.21)\nThis scheme requires that the current be evaluated at the time n + 1\n2 which\ncan be done by iteration as described previously or by having two computing\ntime grids staggered by\n2 units of time.\nTo maintain the error due to time\nquantization at O((∆t)2), we need to compute the factors with second-order\naccuracy by a centered difference as follows\nx\nn+ 1\ni\n-x\nn-1\ni\n∆t\n=\nαx\n\nV n\ni\n\n-\n\nαx\n\nV n\ni\n\n+ βx\n\nV n\ni\nx\nn+ 1\ni\n+ x\nn-1\ni\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nand collect terms to obtain\nx\nn+ 1\ni\n=\n∆tαx\n\nV n\ni\n\n1 + ∆t\n\nαx\n\nV n\ni\n\n+ βx\n\nV n\ni\n+ x\nn-1\ni\n1 -∆t\n\nαx\n\nV n\ni\n\n+ βx\n\nV n\ni\n\n1 + ∆t\n\nαx\n\nV n\ni\n\n+ βx\n\nV n\ni\n\n(6.22)\nWith the factors m, n, and h substituted for x, the ionic current can be com-\nputed as follows\n(Jion)\nn+ 1\ni\n=\nGK(n\nn+ 1\ni\n)4(V n\ni -VK) +\nGNa(m\nn+ 1\ni\n)3h\nn+ 1\ni\n(V n\ni -VNa) + GL(V n\ni -VL),\nwhere each of the factors m\nn+ 1\ni\n, n\nn+ 1\ni\n, and h\nn+ 1\ni\nare computed according to\nEquation 6.22. The total current is\nJ\nn+ 1\ni\n= (Jion)\nn+ 1\ni\n-ro(Keo)\nn+ 1\ni\n+ ri(Kei)\nn+ 1\ni\n2πa(ro + ri)\n.\nThe method is outlined as follows:\n- Start with the value of V n\ni and the value of x\nn-1\ni\nwhich allows a computa-\ntion of J\nn-1\ni\n;\n- Compute x\nn+ 1\ni\nusing Equation 6.22 which then allows a computation of\nJ\nn+ 1\ni\n;\n- Compute V\nn+ 1\ni\nusing Equation 6.21;\n- Compute V n+1\ni\nusing Equation 6.20;\n- The solution has now been advanced to V n+1\ni\nand the value of x\nn+ 1\ni\n.\nThe process can be initiated by calculating either Vi or xi for a\n2 time step\nincrement to stagger the variables.\n6.4\nUser's Guide to the Software\nWhen the software is selected from the Softcell menu, two figures are displayed\n(in addition to MATLAB's command window): PAP Control, and PAP Workspace;\nthe PAP Workspace is distinct from MATLAB's workspace. The PAP Control fig-\nure allows the user to display other figures for setup and analysis, and to start\na simulation. The PAP Workspace figure is (as the name suggests) a workspace\nwhere a schematic representation of an axon, a stimulus source, and a voltage\nrecorder are displayed. In the PAP Workspace figure, the user can choose to dis-\nplay the stimulus setup figure (PAP Stimulus), the parameter setup figure (PAP\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.3: The PAP Control figure when the software is\ninitiated.\nParameters), the voltage recorder figure (PAP Voltage-Recorder), and place the\nelectrodes of the stimulus source and recorder using the mouse cursor on the\naxon schematic. Clicking on the Start pushbutton in the PAP Control figure re-\nsults in the computation of the response as a function of time and space. Upon\ncompletion of the computation, the user can choose to view the space-time evo-\nlution of the membrane potential (which is one of the computed solution vari-\nables) by means of a color code along the axon schematic in the PAP Workspace\nfigure. The user can also examine the space-time evolution of other response\nsolution-variables to gain insight to the model's dynamic behavior or use 3D and\ncomparison plots for static analyses of the model's behavior.\n6.4.1\nPAP Control\nThere are three panels in the PAP Control figure (Figure 6.3). With the left panel,\nthe user can display the PAP Workspace figure (See Section 6.4.2) and the PAP\nNumerics (See Section 6.4.5). In the center (Simulation) panel, the user can spec-\nify the simulation duration and start the simulation by clicking on the Start\npushbutton. The right (Analysis) panel allows the user to do post simulation\nanalysis of the results. The first (Variable summary) option allows the user to\ndisplay a numerical summary of all the solution variables. The second (Space-\ntime evolution) option allows the user to view the dynamics of a solution vari-\nable (such as membrane potential, membrane current-components, etc.)\nas a\nfunction of space with running time. The third (3D plots) option allows the user\nto view three-dimensional graphs of any solution variable as a function of time\nand space. The fourth (Comparison plots) option allows the user to compare\nmultiple solution variables as a function of a solution variable of choice (or as a\nfunction of time or space) in two different modes: fixed-time or fixed-space.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nStarting, pausing, and stopping a simulation\nClicking on the Start pushbutton starts the computation of the solution vari-\nables. While a computation is in progress, the status-bar located along the bot-\ntom of the figure shows the name of the numerical method being used and the\npercentage of completion. The Start pushbutton changes to a Pause pushbut-\nton. Clicking on the Pause pushbutton pauses the computation and causes the\nstatus-bar to display Paused. When the simulation is paused, the Pause push-\nbutton changes to a Continue pushbutton. Clicking on the Continue pushbutton\nresumes the computation and the two states (pause/continue) toggle with each\nclick of the pushbutton until the computation is completed. Upon completion,\nthe pushbutton changes back to Start and the status-bar acknowledges success-\nful completion along with a time stamp. Next to Start is the Stop pushbutton\nwhich allows the user to abort a computation that is currently in progress or\npaused. Clicking on the Stop pushbutton causes the status-bar to display Simu-\nlation Aborted.\nLoading, saving, and re-initializing\nThe user can save all simulation parameters and results in a file as well as load\na previously saved file by clicking on the Save and Open button, respectively.\nThe data stored includes the parameter values of the axon, the membrane, the\nbath, the stimulus, the configuration of the electrodes, and solution variables.\nWhen a file is loaded, the filename (along with it's directory path) is shown in\nthis figure's status-bar as well as in the status-bar of other setup figures such\nas PAP Parameters, PAP stimulus, and PAP numerics. This is useful for keeping\ntrack of the source of the parameter values used during a session.\nWhen the software is launched, the figure's status-bar displays Ready. This\nindicates that no simulation has been run and that there are no results. This is\nthe initial state of the software and all parameters are set to their default values.\nAfter parameters have been changed they can be reset to their default values by\nclicking on the Default pushbutton.\n6.4.2\nPAP Workspace\nSelecting Workspace in the PAP Control figure displays the PAP Workspace figure\n(Figure 6.4). The PAP Workspace figure consists of a window and a control re-\ngion. The window contains from top to bottom: a ruler, an interactive display\narea (showing a schematic of an axon, a stimulus-source icon, and a voltage-\nrecorder icon), another ruler, a status-bar, and a horizontal scrollbar. The de-\nfault length of the axon is three centimeters and fits in the window's display\narea. The schematic representation of a longer axon model stretches beyond\nthe display area's right edge. The user can use the horizontal scrollbar to scroll\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.4: The PAP Workspace figure.\nto the hidden portion. By default the top ruler is set to show number of dis-\ncretized segments, and the bottom ruler is set to show distance in centimeters.\nClicking on either ruler will toggle its unit of measurement between number of\ndiscretized segments and distance. The status-bar shows the simulation time.\nClicking on the Help button located in the lower right corner of the PAP\nWorkspace figure displays the PAP Workspace Help figure.\nThis figure shows\na step-by-step guide to setting up a customized simulation as described in Sec-\ntion 6.4.11.\nPositioning electrodes\nStimulus electrodes (yellow) are located above the axon schematic and voltage-\nrecorder electrodes (grey) are located below the axon schematic. The user can\ncontrol the position of an electrode either by pointing and clicking near the\nelectrode or by clicking and typing in the Electrode Positions panel.\nTo change electrode locations by the point-and-click method, first select the\nelectrode by clicking on the appropriate radiobutton in the Electrode Positions\npanel. Note that the positive and negative electrodes of the stimulus (S+ and\nS-) are selected independently from the positive and negative electrodes of the\nrecorder (R+ and R-). After the appropriate radiobutton is selected, clicking\nanywhere outside of the axon schematic within the interactive display area (e.g.,\nthe black region) sets the electrode's longitudinal position to the mouse-click lo-\ncation. Clicking in the black region above the axon schematic moves the stimulus\nelectrodes, and clicking in the black region below the axon schematic moves the\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nrecorder electrodes. Both stimulus and recording electrode positions can also be\nchanged by typing in the relevant text edit boxesin the Electrode Positions panel.\nClicking on an electrode will toggle the electrode position between intracellular\nand extracellular. Clicking on the check boxes in the Electrode Positions panel\nalso allows control of the intracellular/extracellular locations of electrodes. The\ncheck box on the right part of the Electrode Positions panel controls the display of\nthe voltage recorder and its electrodes. Distances between stimulus electrodes\nand between voltage recording electrodes are indicated below the lower ruler.\nDisplaying other setup figures\nClicking on the stimulus-source icon (yellow) will bring up the PAP Stimulus fig-\nure where the user can specify the characteristics of the desired stimulus (See\nSection 6.4.4). Clicking on the voltage-recorder icon (green and grey) will dis-\nplay the PAP Voltage-Recorder figure where a real-time potential curve is plotted\nduring a simulation run (See Section 6.4.6). Clicking on the axon schematic will\ndisplay the PAP Parameters figure where the user can change the parameters of\nthe axon, the membrane, and the bath (See Section 6.4.3).\nShowing discretization and color-coded space-time evolution\nThe option (Show discretization) to the right of the Color Space-Time Evolution\npanel allows the user to toggle on/offthe spatial discretization display on the\naxon schematic.\nIn the Color Space-Time Evolution panel, the pushbutton Start\nallows the user to playback the space-time evolution of the membrane potential\non the axon schematic by using a color code to convey the range of potential\nlevels. The playback can be stopped using the Stop button. During playback,\nthe Start becomes a Pause button which allows the user to pause the playback.\nThe speed of the playback can be adjusted in the Speed field located under the\npushbutton. For example, if the simulation data contains membrane potential\nvalues for every 0.01 ms, changing the field value to ten will playback simulation\ndata of every 0.1 ms.\nNote that a voltage curve is plotted in the Voltage-Recorder figure during\nplayback (See Section 6.4.6). Figure 6.5 shows a series of snapshots taken from\na time-evolution color code visualization of the membrane potential of a three-\ncentimeters long axon model.\n6.4.3\nPAP Parameters\nClicking on the axon schematic in the PAP Workspace figure displays the PAP\nParameters figure (Figure 6.6). The PAP Parameters figure is divided into three\nsections: Membrane Characteristics, Bath Characteristics, and Axon Characteris-\ntics. In each section, there are three columns for each parameter: the first col-\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.5: Snapshots of a propagating action potential shown\nusing Color Space-Time Evolution in the PAP Workspace figure.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nFigure 6.6: The PAP Parameters figure.\n\n6.4. USER'S GUIDE TO THE SOFTWARE\numn identifies the parameter, the second gives its default value, and the third\ncolumn shows the value of the parameter if it is modified from its default value\n(Note that the PAP Parameters figure data entry method is based on that of the\nHH Parameters figure).\nChanging parameter values\nParameters can be modified by clicking on the entry in the third column of the\nparameter field. When the parameter is selected, its third column entry is re-\nplaced by an edit box. Clicking any mouse button inside the edit box allows the\nparameter to be changed. The new value of the parameter is entered from the\nkeyboard; < RETURN > terminates the parameter entry. If the new value differs\nfrom the default value, then the new value will appear in the third column. With\nthis method of display, the parameter list can be scanned quickly to indicate\nwhich parameters differ from their default values.\nThere are some restrictions on the numerical values of parameters; G's ≥0,\nCm ≥0, c's > 0, K's > 0, ρi ≥0, ro ≥0 (ro cannot be zero when ρi = 0),\nthe axon's radius and length must be greater than zero, and the temperature\nmust be above absolute zero. The derived parameters cannot be changed but\nare derived from the other parameters and are displayed for the convenience of\nthe user. For example, the sodium equilibrium potential VNa cannot be changed\ndirectly by the user, but changes automatically when the sodium concentrations\nor temperature are changed.\nLoading, saving, resetting, and printing\nThe parameters can be loaded from a file by clicking on Open and can be saved\nby clicking on Save. Saving and loading in the PAP Parameters figure deals only\nwith the model's axon, membrane and bath parameters; e.g., simulation results\nare not loaded or saved. When a parameters file is loaded, the status-bar of the\nPAP Parameters figure displays the filename (with the directory path) and the\nparameter values loaded from the file become the default values. For example,\nif the user changes the temperature value and clicks the Reset pushbutton, the\ntemperature value resets to the value stored in the loaded file.\nTo reset the\nparameter values to their software-default values, use the Default pushbutton in\nthe PAP Control figure. If no file is loaded, clicking the Reset pushbutton resets\nthe parameter values to the software-default values. The PAP Parameters figure\ncan be printed using the Print button.\nViewing the voltage dependent parameters\nThe Hodgkin-Huxley model of a propagated action potential as well as the Hodgkin-\nHuxley model of a membrane action potential of a space-clamped axon contains\nseveral parameters that are instantaneous functions of the membrane potential.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nPlots of these parameters are available as a function of Vm for the following:\nαm(Vm), βm(Vm), minf(Vm), τm(Vm), αh(Vm), βh(Vm), hinf(Vm), τh(Vm), αn(Vm),\nβn(Vm), ninf(Vm), τn(Vm) (see Section 5.2.3). These can be accessed by clicking\non the button marked α, β, τ, h, m, n which results in the display of the PAP\nParameters vs. Potential figure (Figure 6.7).\nFigure 6.7: The PAP Parameters vs. Potential figure.\nNote that the PAP Parameters vs. Potential figure is similar to the PAP Com-\nparison Plots figure described in Section 6.4.10. Please refer to that section for\nmore information about the available plot manipulation functions. The PAP Pa-\nrameters vs. Potential figure has its own setup figure which differs from the one\nof the PAP Comparison Plots . Clicking on the Setup button displays this setup\nfigure.\nThe user can select one or more variables and click on either Graph\nor Overlay to make the plot. The Graph and Overlay buttons are described in\nSection 6.4.10.\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.8: The PAP Stimulus figure.\n6.4.4\nPAP Stimulus\nClicking on the stimulus-source icon (yellow) in the PAP Workspace figure dis-\nplays the PAP Stimulus figure (Figure 6.8). Note that the layout of the PAP Stim-\nulus figure is similar to that of the HH Stimulus figure. The upper-half of the\nfigure shows a graph of the stimulus pulse(s) specified in the parameter-entry\ncolumns: Pulse 1 and Pulse 2. The duration of the stimulus depends on the du-\nration of the simulation specified in the PAP Control figure. For example, if the\nsimulation duration is four milliseconds, then the abscissa of the stimulus graph\nis also of length four milliseconds.\nSpecifying a pulse\nA maximum of two pulses can be defined using a set of parameters for each\npulse. In addition, a holding DC current can be specified in the Holding current\nfield.\nThus, the overall stimulus is the sum of a constant plus two indepen-\ndently specifiable pulses. In mathematical terms, the stimulus, s(t), is defined\nas follows\ns(t) = so + s1(t) + s2(t),\n(6.23)\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nwhere so is a constant and s1(t) and s2(t) are independently specifiable pulses.\nEach pulse has the form\nsi(t) =\n\nmi(t -ti\no) + Aie-(t-tio)/τi\nif to ≤t ≤to + tdur,\notherwise,\n(6.24)\nwhere pulse i (i = 1 or 2) starts at to and has a duration tdur. The amplitude\nof the pulse is Ai, the slope is mi, and the time constant is τi. If the slope and\nthe time constant are set to zero, then the remaining parameters specify the\namplitude, duration and onset time of a rectangular pulse. If the slope has a\nnon-zero value, a ramp of that slope is added to the rectangular pulse for the\nduration of the pulse. Similarly, if the time constant has a non-zero value, then\nan exponential pulse with the selected time constant is added to the waveform.\nThe time constant can be positive or negative.\nThe variables ti\no, ti\ndur, Ai, mi, and τi that defines a pulse in the form of Equa-\ntion 6.24 are specified in the PAP Stimulus figure by the parameter fields Start,\nDuration, Amplitude, Slope, and Time constant in the Pulse i column, respec-\ntively. By adjusting these parameters, the user can generate rectangular pulses,\nramp pulses, exponential pulses or a combination of these. An example is shown\nin Figure 6.9.\nLoading, saving, and resetting\nThe parameters can be loaded from a file by clicking on Open and can be saved\nby clicking on Save. Saving and loading in the PAP Stimulus figure deals only with\nthe stimulus parameters; e.g., simulation results are not loaded or saved. When\na file with stimulus parameters is loaded, the status-bar of the PAP Stimulus\nfigure displays the filename (with the directory path) and the parameter values\nloaded from the file become the default values. For example, if the user changes\nthe holding current value and clicks the Reset pushbutton, the holding current\nvalue resets to the value stored in the loaded file. To reset the parameter values\nto their software-default values, use the Default pushbutton in the PAP Control\nfigure. If no file is loaded, clicking the Reset pushbutton resets the parameter\nvalues to the software-default values.\n6.4.5\nPAP Numerics\nSelecting Numerics in the PAP Control figure displays the PAP Numerics figure\n(Figure 6.10). The PAP Numerics figure allows the user to select the numerical\nmethod used to solve the partial differential equations described in Section 6.2.\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.9: The PAP Stimulus figure showing a stimulus\nthat consists of two pulses: the first pulse is an expo-\nnential pulse and the second is a ramp plus a rectangular\npulse.\nChoosing a numerical method and specifying discretization parameters\nThe list-box located at the top of the figure allows the user to select one of four\navailable numerical methods: forward Euler, backward Euler, Crank-Nicolson,\nand staggered Crank-Nicholson (staggered C-N). These numerical methods are\ndescribed in detail in Section 6.3. By default, the software uses the staggered C-N\nnumerical method. All numerical methods employ the finite difference method\nwhich requires two discretization parameters: a time step, ∆t, and a spatial\nstep, ∆z.\nDecreasing the time step produces a smoother time evolution of the\nsolution variables (for example, a smoother action potential propagation), but\ncomputation time and memory usage increases. Decreasing the space step pro-\nduces an axon schematic with more discrete elements - hence a smoother spatial\nFigure 6.10: The PAP Numerics figure.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nevolution of the solution variables (for example, a smoother membrane-potential\ncurve as a function of space when viewed in a snapshot), but computation time\nand memory usage increases. In order to obtain a reasonably accurate solution\nusing a particular numerical method, the discretization parameters have to be\nchosen appropriately.\nLoading, saving, resetting, and printing\nThe parameters can be loaded from a file by clicking on Open and can be saved by\nclicking on Save. Saving and loading in the PAP Numerics figure deals only with\nthe numerics parameters; e.g., simulation results are not loaded or saved. When\na numerics parameters file is loaded, the status-bar of the PAP Numerics figure\ndisplays the filename (with the directory path) and the parameter values loaded\nfrom the file become the default values. For example, if the user changes the time\nstep and clicks the Reset pushbutton, the time step resets to the value stored in\nthe loaded file. To reset the parameter values to their software-default values,\nuse the Default pushbutton in the PAP Control figure. If no file is loaded, clicking\nthe Reset pushbutton resets the parameter values to the software-default values.\nThe PAP Numerics figure can be printed using the Print button.\n6.4.6\nPAP Voltage-Recorder\nClicking on the voltage-recorder icon (grey and green) in the PAP Workspace\nfigure displays the PAP Voltage-Recorder figure (Figure 6.11). The PAP Voltage-\nRecorder figure shows a graphing region where a voltage curve is plotted when\nthe user clicks on the Start button located in the PAP Workspace figure. When\nplotting a curve, the graphing area can display only a portion 3 ms long.\nIf\nthe plot extends beyond 3 ms, the scrollbar under the graphing area becomes\nactive, so the user can scroll to see any section of the curve. Also, a Show entire\nplot option is enabled, so the user can choose to display the whole curve on\nthe graphing area. For example, shrink the abscissa to fit the entire plot in the\ngraphing region.\nThe voltage plot corresponds to the voltage recorded at the location of the\nrecording electrodes located beneath the axon schematic.\nThe user can re-\nposition the recording electrodes as described in Section 6.4.2 and click on Start\nto obtain the corresponding voltage plot. Clicking on the Grid option displays a\ngrid on the graphing region.\nMarkers can be set to measure the times of occurrence of features in the\nwaveform. Clicking on the t1 marker and clicking on the plot, results in a red,\nvertical line; clicking again fixes the time of occurrence of that line. The same\ncan be done with the t2 marker. The time of occurrence of each of the markers\nand the difference in time between the two markers are displayed at the top of\nthe figure.\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure\n6.11:\nThe\nPAP\nVolt-\nage-Recorder figure.\n6.4.7\nPAP Variable Summary\nSelecting Variable summary in the Analysis panel of the PAP Control figure dis-\nplays the PAP Variable Summary figure as shown in Figure 6.12.\nThis figure\nallows the user to display the initial, minimum, and maximum value of any solu-\ntion variable. The user can either select to view these summary values obtained\nfrom the spatial dimension at a specified time, or from the temporal dimension\nat a specified location. The time and location are specified in units of millisec-\nonds and centimeters, respectively. The largest valid time value is equal to the\nsimulation duration, and the largest valid location value is equal to the length of\nthe axon model.\n6.4.8\nPAP Space-Time Evolution\nSelecting Space-time evolution in the Analysis panel of the PAP Control figure\ndisplays the PAP Space-Time Evolution figure as shown in Figure 6.13. This figure\nonly appears if there are simulation results (i.e. after a simulation has been run).\nThe PAP Space-Time Evolution figure provides a means of viewing the dynamics\nof any solution variable along the axon as time changes.\nViewing the space-time evolution of a solution variable\nWhen the figure is first displayed, Vm (membrane potential) is selected in the\nlist-box located at the top of the figure. Use the list-box to view any desired\nsolution variable. After a selection is made, the graph under the list-box shows\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nFigure 6.12: The PAP Variable Summary figure.\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.13: The PAP Space-Time Evolution figure showing\na snapshot of a propagating action potential.\nthe selected solution variable as a function of space at time = 0 ms. To view\nthe selected solution variable as a function of space at progressing time starting\nfrom 0 ms, click on the Start pushbutton.\nThe process can be stopped and\npaused using the appropriate buttons.\nThe Start button changes to a Pause\nbutton when a process is running. Clicking on an axis label displays the Axis\nconfiguration figure (Figure 6.18) which allows the user to change the properties\nof the axis.\n6.4.9\nPAP 3D Plots\nSelecting 3D plots in the Analysis panel of the PAP Control figure displays the\nPAP 3D Plots figure (Figure 6.14). This figure only appears if there are simulation\nresults (i.e. after a simulation has been run). The PAP 3D Plots figure provides a\nmeans of visualizing the space-time dependence of any solution variable.\nViewing a 3D plot of a solution variable\nWhen the figure is first displayed, Vm (membrane potential) is selected in the\nlist-box located at the top of the figure. Use the list-box to view any desired\nsolution variable. After a selection is made, the surface plot beneath the list-\nbox shows the selected solution variable as a function of space and time. The\ncolorbar on the right indicates the magnitude of the colored surface plot. To\nchange the view angle use the horizontal scrollbar located at the bottom and the\nvertical scrollbar located on the left of the plot. The vertical scrollbar controls\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nthe viewing elevation (i.e.\nrotates the plot up and down), and the horizontal\nscrollbar controls the viewing azimuth (i.e. rotates the plot left and right). In\naddition, the user can switch between mesh and surface plot by toggling the\nmesh option on/off. Since the mesh plot samples the surface of the variable as\na function of space and time, care must be taken with evaluating 3D mesh plots\nof discontinuous functions.\nClicking on the box option toggles on/offan axes-bounding box. Clicking on\na solution variable's axis label displays the Axis configuration figure (Figure 6.18)\nwhich allows the user to change the properties of that axis.\n6.4.10\nPAP Comparison Plots\nSelecting Comparison plots in the Analysis panel of the PAP Control figure dis-\nplays the PAP Comparison Plots figure as shown in Figure 6.16. The PAP Compar-\nison Plots figure allows the user to plot any solution variable against any other.\nThe figure displays a group of pushbuttons on the upper-left corner, a legend\npanel on the upper-right corner, and a graphing region.\nUsing the Comparison Plots Setup figure to generate plots\nClicking on the Setup button in the PAP Comparison Plots figure displays the\nComparison Plots Setup figure (See Figure 6.15) where the user can choose: fixed-\nspace plots (Figure 6.16) or fixed-time plots (Figure 6.17).\nFixed-space plots\nrequire the user to specify a longitudinal location of the axon, zo, in units of\ncentimeters. The user can use this mode to generate solution-variable-A vs. solu-\ntion variable-B at location, zo, plots. Fixed-time plots require the user to specify a\ntime, to, in units of milliseconds. This mode is used to generate solution-variable-\nA vs. solution-variable-B at time, to, plots.\nFollow these steps to make a plot:\n- Choose a plotting mode: fixed-space plots or fixed-time plots.\n- For fixed-space plots specify the Distance parameter: enter a value in units\nof centimeters. Note that the maximum allowable value is the length of the\naxon model. Multiple distance values can also be entered in MATLAB array\nformat (i.e.\n[1.0 1.5 3.5], [1.0 : 0.05 : 2.0]).\nPlease refer to the MATLAB\nuser's manual for more information.\n- For fixed-time plots specify the Time parameter: enter a value in units\nof milliseconds. Note that the maximum allowable value is equal to the\nsimulation duration. Multiple time values can also be entered in MATLAB\narray format.\n- Choose a solution variable in the X-Variable panel: this is the independent\nvariable and it corresponds to the the values along the abscissa.\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.14: The PAP 3D Plots figure showing a propagat-\ning action potential. Top: a surface plot. Bottom: a mesh\nplot.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nFigure 6.15: The Setup PAP Comparison Plot figure show-\ning the variables used to setup Figure 6.16.).\n- Choose one or more solution variables in the Y-Variable panel: multiple\ndependent variables can be plotted for comparison. They are all plotted as\na function of the solution variable selected in the X-Variable panel. Depen-\ndent variables that have same unit of measurements share one ordinate\naxis. Both sides of the plotting area may show distinct ordinate axes to ac-\ncomodate distinct units of the variables selected. For example, the user can\nchoose to plot the membrane potential, Vm, and the sodium conductance,\nGNa, both as a function of time, t. In this case, the user would select t in\nthe X-Variable panel, and both Vm and GNa in the Y-Variable panel. Since\nVm is in units of millivolts and GNa is in units of mS/cm2, the plot should\nshow two ordinate axes. The abscissa, in this case, should be in units of\nmilliseconds.\n- Click on Graph to graph the selections on a cleared plotting region. The\nGraph pushbutton clears all previous plots. Click on Overlay to graph the\nselection on the plotting region without clearing any previous plots. This\nfeature allows the user to overlay the solutions obtained from different\nsimulations. For example, suppose the user wants to plot the membrane\npotential, Vm, as a function of time, t, at the axon longitudinal location,\nzo = 2 cm, for temperature values of 6.5*, 18*, and 20*Celsius. The user\nwould need to run a simulation with the temperature parameter set to 6.5,\nplot Vm vs. t at zo = 2 using the Graph button. Then do the subsequent\nsimulation runs with the the other two temperature values and plot using\nthe Overlay button so that all three plots are retained in the plotting region.\nIn addition, the user can make plots using data stored in files. To do this,\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.16: The PAP Comparison Plots figure showing a\nfixed-space plot of the membrane potential, Vm, and the\nionic conductances, GNa and GK, with model parameters\nand the stimulus defined in Figures 6.6 and 6.8.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nFigure 6.17: The PAP Comparison Plots figure showing a\nfixed-time plot of the membrane potential, Vm, and the ac-\ntivation factors, m and h, obtained from a simulation with\nmodel parameters and the stimulus defined in Figures 6.6\nand 6.8.\n\n6.4. USER'S GUIDE TO THE SOFTWARE\nFigure 6.18: The PAP Axis Scale figure.\nselect the Files with Parameters option and click on the Select files pushbutton.\nA file-loading dialog box appears which allows the user to select the data file(s).\nThe user can then plot the loaded solution variables.\nAnnotating, zooming, and other functions\nThe PAP Comparison Plots figure has a few functions that facilitates the analysis\nof the plots.\n- Clicking on the Cross-line pushbutton\ndisplays a vertical line in the plot\nregion at the location of the pointer cursor. The line follows the cursor as\nit moves across the plot region. The values of all plotted variables at the\nintersection with the cross-line are displayed in the Legend panel, under\nthe column labeled Cross-line .\nClicking on the Cross-line\nbutton again\nremoves the cross-line values from the legend and removes the cross line\nfrom the plotting region.\n- Clicking on the A button allows the user to make annotations on the plot.\nWith this button set to on, click on a desired location in the plot to dis-\nplay a text edit box at that location. Click in the text edit box, type the\nannotation followed by a <RETURN>\nwhen the annotation is completed.\nClicking on the annotation and dragging the mouse moves the annotation\nto a desired location in the plot field. The text string can be formatted into\nmathematical notation by using a LATEX like notation, e.g., to get minftype\nm_{\\infty}.\n- Clicking on the\n+\nbutton next to the annotation button allows the user\nto magnify a region of the plotting region by clicking on it. Clicking again\ncauses further magnification. Clicking on the\n-\nbutton causes the plot to\nchange to its original magnification.\n- In the plotting region, clicking on any of the axis labels (i.e.\neither the\nabscissa or any of the ordinates) displays an axis scale figure (Figure 6.18)\nwhich allows the user to change parameters of the chosen axis. The range\nof the axis can be specified in MATLAB array format (i.e. [-200 200]) in the\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nFigure 6.19:\nThe Modify Line\nProperties figure.\nRange field. The range is set to rescale automatically by default. To inhibit\nauto-scaling, unselect the Auto option. Selecting the Log option changes\nthe axis scale to a logarithmic scale (i.e. the logarithm of the magnitude\nof the variable is plotted). Selecting the Inverse [1/]\noption produces a\nreciprocal scale axis. (i.e. the reciprocal of the magnitude of the variable is\nplotted). A combination of the two is allowed.\n- In the Legend panel, clicking on any entry under the column labeled Marker\ndisplays a modify line properties figure (Figure 6.19) which allows the user\nto customize the color, line style, line width, marker type, and marker size\nof the selected plot curve. The color field is specified in RGB values in a\nMATLAB array (i.e. to specify the primary color, red, use [1 0 0]).\n- In the Legend panel, clicking on any entry under the column labeled Name\ncauses the curve associated with that entry's variable to alternately display\nand hide. Hiding and displaying curves causes the axes to rescale automat-\nically unless the auto-scaling function of the particular axis is disabled by\nmeans of the axis scale figure described above.\nLoading, saving, and printing\nThe user can save the plots by clicking on the Save pushbutton. All lines, axis\nscale and annotations are saved. The Open pushbuttons loads a previously saved\nfile. The plots can be printed using the Print button.\n6.4.11\nStep-by-step Guide To Setting Up A Customized Simula-\ntion\nLaunch the software from the Softcell menu. Once the application has started,\ntwo figures will be displayed: the PAP Control figure, and the PAP Workspace\nfigure. All model parameters are started in their default values. To start setting\nup a simulation with customized parameter values, complete all or any of the\nfollowing steps:\n\n6.5. PROBLEMS\n1. Change the membrane, axon, and bath parameter values: in the PAP Workspace\nfigure, click on the axon schematic. The PAP Parameters figure is displayed.\nAdjust any parameter as described in Section 6.4.2. Clicking on the axon\nschematic again closes the PAP Parameters figure.\n2. Change the stimulus-pulse parameter values: in the PAP Workspace figure,\nclick on the stimulus-source icon (yellow filled-circle with an arrow inside).\nThe PAP Stimulus figure is displayed. Adjust any parameter as described\nin Section 6.4.4. Clicking on the stimulus-source icon again closes the PAP\nStimulus figure.\n3. Position the stimulus electrodes: in the PAP Workspace figure, select the ap-\npropriate radiobutton in the Electrode Positions panel (i.e. cathode/anode-\nelectrode). To position the selected electrode longitudinally along the axon\nschematic, click on the black region between the top ruler and the schematic.\nThe desired electrode moves to the position of the mouse cursor. Click on\nthe electrode to toggle its position between intracellular and extracellular.\nNote that the icon of an intracellular electrode touches the axon schematic,\nwhereas an extracellular electrode does not.\n4. Position the voltage-recording electrodes: in the PAP Workspace figure, se-\nlect the appropriate radiobutton in the Position Electrode panel. Click on\nthe black region between the bottom ruler and the axon schematic to move\nthe desired electrode to the position of the mouse cursor. Click on the\nelectrode to toggle its position between intracellular and extracellular.\n5. Change the numerics values: in the PAP Control figure, click on the Numer-\nics option. The PAP Numerics figure is displayed. Adjust any parameter as\ndescribed in Section 6.4.5.\n6. Change the simulation duration: in the PAP Control figure, enter the simu-\nlation duration in milliseconds.\n7. Start simulation: in the PAP Control figure, click on the pushbutton Start.\nNote that when a simulation has started, the Start pushbutton changes to\na Pause pushbutton. Clicking on Pause pauses the simulation. Click on\nContinue to resume. Click on the Stop pushbutton anytime to abort.\n6.5\nProblems\nProblem 6.1 The purpose of this problem is to estimate the conduction velocity of\nthe action potential. Using the default parameters of the Hodgkin-Huxley model,\ndevise a method to estimate the conduction velocity of the action potential. De-\nscribe your method carefully and give a numerical estimate of the conduction\nvelocity for the default parameters.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nProblem 6.2 The purpose of this problem is to investigate the dependence of the\npropagated action potential on resistance per unit length of the inner and outer\nconductors and the relation of these results to the notion of a space clamp.\na. Run the simulation using the default parameters. Examine the membrane\npotential as a function of space and time. You may wish to use the three-\ndimensional plots or to use the comparison plots to plot the membrane\npotential as a function of time for locations from 0.5 cm to 2.5 cm every\n0.2 cm.\nb. Reduce the resistivity of the intracellular conductor ρi to 10 Ohm·cm. Run\nthe simulation again and examine the membrane potential as a function of\nspace and time.\nc. Reduce the resistivity of the intracellular conductor ρi to 1 Ohm·cm. Run\nthe simulation again and examine the membrane potential as a function of\nspace and time.\nd. Reduce the resistivity of the intracellular conductor ρi to 0.1 Ohm·cm. Run\nthe simulation again and examine the membrane potential as a function of\nspace and time.\ne. Keep the resistivity of the intracellular conductor ρi to 0.1 Ohm·cm but\nincrease the resistance per unit length of the outer conductor ro to 10,000\nOhm/cm. Run the simulation again and examine the membrane potential\nas a function of space and time.\nf. What do you conclude about the dependence of the membrane potential on\nspace and on time as the internal and external resistance per unit length\nare decreased?\ng. How are these results related to the notion of a space clamp? How are these\nresults related to the notion of an electrically large cell and an electrically\nsmall cell.\nh. Explain how you could reduce the effective resistivity of the inner conduc-\ntor ρi in an experiment on an axon.\nProblem 6.3 The purpose of this problem is to investigate the step response of\nthe Hodgkin-Huxley model with the nonlinear elements removed.\nDetermine the\nstimulus and numerical parameters required to examine the step response of\nthe Hodgkin-Huxley model when stimulated at z = 1.5 cm with the nonlinear\nelements removed, i.e., set GNa = GK = 0. Perform simulations with ρi = 35.4\nOhm·cm and for ρi = 0.001 Ohm·cm. Save the results in files. In the various\nparts of this problem, you will examine the solutions that you have already com-\nputed and saved.\n\n6.5. PROBLEMS\na. For ρi = 35.4 Ohm·cm, examine the dependence of the membrane poten-\ntial on space at various times by plotting Vm versus z at different times.\nDescribe the results as precisely as possible.\nb. For ρi = 0.001 Ohm·cm, examine the dependence of the membrane poten-\ntial on space at various times by plotting Vm versus z at different times.\nDescribe the results as precisely as possible. Compare these results with\nthose of part a.\nc. For ρi = 35.4 Ohm·cm, examine the dependence of the membrane potential\non time at various positions by plotting Vm versus t at different positions.\nDescribe the results as precisely as possible.\nd. For ρi = 0.001 Ohm·cm, examine the dependence of the membrane po-\ntential on time at various positions by plotting Vm versus t at different\npositions. Describe the results as precisely as possible. Compare these\nresults with those of part c.\nProblem 6.4 The purpose of this problem is to investigate the relations among the\nmembrane potential, the intracellular potential, and the extracellular potential.\na. Run the simulation with the default parameters.\ni. Examine the space-time evolution of Vm, Vi, and Vo. Describe the rela-\ntion among these three variables. Explain these results.\nii. Using the comparison plots, plot Vm, Vi, and Vo versus position at the\ntime t = 0.4 ms and at the time t = 1 ms. Describe the relation among\nthese three variables at the two times and explain these results.\nb. Set ro to equal the default value of ri and repeat part a.\nc. Compare the results in parts a and b and explain the differences.\nProblem 6.5 The purpose of this problem in to relate the membrane potential\nas a function of space to the membrane potential as a function of time during a\npropagated action potential.\na. Run the simulation using the default parameters. Compare the membrane\npotential as a function of time at 2 cm with the membrane potential as a\nfunction of position at 1 ms. Determine the relation between these two\nwaveforms.\nb. Move the electrode S+ (keeping it intracellular) to position 2.9 cm and run\nthe simulation again. Once again compare the membrane potential as a\nfunction of time at 2 cm with the membrane potential as a function of\nposition at 1 ms. Determine the relation between these two waveforms.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nc. The relation between the membrane potential as a function of time and of\nposition for part a differs from that in part b. Explain the difference.\nProblem 6.6 The purpose of this problem in to examine the relation between the\nmembrane potential as a function of time and the longitudinal current as a func-\ntion of time during a propagated action potential.\na. Run the simulation using the default parameters.\ni. Compare the membrane potential as a function of time with the exter-\nnal longitudinal current Io as a function of time at the position 2 cm.\nDetermine the relation between these two waveforms.\nii. Compare the external longitudinal current Io as a function of time with\nthe internal longitudinal current Ii as a function of time. Pay particular\nattention to t < 0.5 ms and to t > 0.5 ms. What is the relation of these\ntwo variables in these two time ranges. Explain these results.\nb. Move the intracellular electrode (S+) to position 2.9 cm and run the simu-\nlation again.\ni. Once again compare the membrane potential as a function of time\nwith the external longitudinal current as a function of time at the po-\nsition 2 cm. Determine the relation between these two waveforms.\nii. Compare the results of parts a-i and b-i. Explain the differences.\nProblem 6.7 The purpose of this problem in to examine the relation among the\nmembrane potential, the longitudinal currents, the membrane current density\nand the capacitance current all as functions of time during a propagated action\npotential.\nRun the simulation using the default parameters.\na. Using the comparison plots, compare Vm and Ii as a function of time at a\nlocation of 1.5 cm. What is the relation and why?\nb. Using the comparison plots, compare Vm and JC as a function of time at a\nlocation of 1.5 cm. What is the relation and why?\nc. Using the comparison plots, compare Ii and JC as a function of time at a\nlocation of 1.5 cm. What is the relation and why?\nd. Using the comparison plots, compare Ii and Jm as a function of time at a\nlocation of 1.5 cm. What is the relation and why?\ne. Using the comparison plots, compare Vm and Jm as a function of time at a\nlocation of 1.5 cm. What is the relation and why?\n\n6.5. PROBLEMS\nf. Using the comparison plots, compare Ii and Io as a function of time at a\nlocation of 1.5 cm. What is the relation and why?\nProblem 6.8 The purpose of this problem is to examine the waveform of the prop-\nagated action potential at various locations along the axon. Use the default pa-\nrameters of the model except arrange the stimulating electrodes as follows: S-\nis extracellular and located at position 1 (discrete segment 1 located at 0 cm)\nand S+ is intracellular and located at position 20 (1 cm). The stimulus current\nprovided by the current source (which can be seen by clicking on the current\nsource) flows from S-to S+ and is 0.05 mA with a duration of 0.5 ms. Run the\nsimulation and compare Vm at the locations 1, 1.5, 2, 2.5 cm by plotting all 4\ntraces on one axis using the Comparison Plots.\na. Does the all-or-none principal apply at all the positions along the axon?\nb. Explain the differences in waveshape at the different locations along the\naxon. You may wish to plot additional variables on your plot of Vm.\nProblem 6.9 This problem concerns the direction of a current stimulus that elicits\na propagating action potential. The parameters of the model are the default val-\nues as indicated. Throughout this problem, the stimulus electrodes are located\nas follows: S-is located at position 1 (discrete segment 1) and S+ is located at\nposition 30.\na. Simulations with one intracellular and one extracellular electrode.\ni. Set S-to be extracellular and S+ to be intracellular.\nThe stimulus\ncurrent provided by the current source (which can be seen by clicking\non the current source) flows from S-to S+ and is 0.05 mA with a\nduration of 0.5 ms.\nRun the simulation and determine whether an\naction potential occurs and, if so, at which electrode(s) it arises.\nii. With all other parameters the same as in part a-i, make S-intracellular\nand S+ extracellular. Run the simulation and determine whether an\naction potential occurs and, if so, at which electrode(s) it arises.\niii. Draw a diagram of current flow about the axon and through the cur-\nrent source for the two cases considered in parts a-i and a-ii. Describe\nthe conditions for the occurrence of an action potential and explain\nthe polarity of Vm when an action potential does not occur.\nb. Simulations with two extracellular electrodes.\ni. Set the stimulating electrodes and the stimulating current identical\nto that in part a-i except make both current electrodes extracellular.\nRun the simulation and determine whether an action potential occurs\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\nand, if so, at which electrode(s) it arises. Examine the two longitudinal\ncurrents Ii and Io and and the membrane current Jm and explain these\nresults.\nii. With the default settings in part b-i, ro = 0 which crudely simulates\nan axon in a large volume of sea water. This assumption is reasonable\nfor computing whether or not an action potential occurs since only\nthe sum ro + ri occurs in these equations and for an axon in a large\nvolume of sea water ro ≪ri.\nBut assuming that ro = 0 does not\ngive a good approximation for determining longitudinal currents, for\nexample. Therefore, in this part of the problem, increase ro to 20,000\nOhm/cm so that it is roughly comparable to ri. This value of ro can be\nachieved experimentally by putting an axon in an insulating medium\n(oil, air, deionized sucrose) so that only a thin layer of sea water clings\nto the axon.\nRun the simulation and determine whether an action\npotential occurs and, if so, at which electrode(s) it arises. Examine Ii,\nIo, and Jm. What do you conclude?\niii. Keep all the stimulus parameters the same as in b-ii except make both\nstimulating electrodes intracellular. Run the simulation and determine\nwhether an action potential occurs and, if so, at which electrode(s) it\narises.\niv. Return to the conditions of part b-ii except reverse the polarity of the\nstimulus current, i.e., make its amplitude -0.05 mA. Run the simula-\ntion and determine whether an action potential occurs and, if so, at\nwhich electrode(s) it arises.\nc. Integrate the results you have obtained in parts a and b to come to a general\nconclusion about the key properties of an electric current stimulus that\nelicits an action potential.\nProblem 6.10 The purpose of this problem is to investigate what happens when\ntwo action potentials travelling in opposite directions collide.\na. Start with the default parameters, and adjust the stimulus electrodes so\nthat an action potential is produced both at 0 cm and at 3 cm. You will need\nto understand the direction of a current stimulus that elicits and action\npotential. You may wish to explore Problem 6.9 to aid you to understand\nthis matter. [HINT: Note also that the default value for ro = 0 so that little\nof the stimulus current from an extracellular electrode enters the axon.\nTherefore, you may wish to adjust the value of ro.]\nb. By plotting the results using the various plotting tools, determine what has\nhappened. Did the action potentials pass through each other or did they\nannihilate each other? Suggest an explanation for your results.\n\n6.5. PROBLEMS\nProblem 6.11 The purpose of this problem is to explore the bases of the sub-\nthreshold oscillatory response of the model to a step of current.\nStart with the\ndefault parameters except as follows: set the duration of the current pulse to\n10 ms and its amplitude to 0.0001 mA. Set the duration of the simulation to\n10 ms in the PAP Control figure. Run the simulation and examine the results.\nYou should find that the membrane potential contains a highly damped slow\noscillation at the onset which constitutes the step response. The purpose of this\nproblem is to determine the basis of the oscillation.\na. Devise an experiment to determine whether the relation of the stimulus\ncurrent to the membrane potential is a linear relation for current stimulus\nparameters near those given above. What do you find?\nb. Investigate whether the variation in membrane potential with position is\nsomehow responsible for the shape of the step response, in particular, the\npresence of the oscillations.\ni. Devise a simulation experiment that will eliminate the spatial variation\nof the membrane potential and run a simulation.\nii. Demonstrate that the spatial variation you set out to eliminate is in\nfact eliminated.\niii. Are the oscillations eliminated?\niv. Which aspects of the step response are changed and why?\nc. If oscillations are still present in the step response, devise simulation ex-\nperiments to determine their origin.\nd. Discuss how the results you have obtained in the previous parts are related\nto the cable model of an axon?\nProblem 6.12 The purpose of this problem is to explore the variables associated\nwith a propagated action potential near the end of the model axon.\nUse the\ndefault parameters to compute the propagated action potential.\na. Using the comparison plots, plot Ii and Io versus time at positions of 2.9\nand 3 cm. Explain the differences in longitudinal currents with position.\nb. Using the comparison plots, plot Jm versus time at positions of 2.9 and 3\ncm. Explain the differences in membrane current densities with position.\nProblem 6.13 The purpose of this problem is to investigate the space constant of\nthe Hodgkin-Huxley model of the giant axon of the squid.\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\na. Design a simulation experiment in order to estimate the space constant of\nthe Hodgkin-Huxley model of the giant axon of the squid for the default\nparameters. Determine the value of the space constant.\nb. Keeping all other parameters the same, set the radius of the axon to 0.0952\ncm and repeat part a.\nc. Compare the estimated space constants in parts a and b and explain the\ndifference.\n6.6\nPROJECTS\nThis simulation software lends itself to more extensive study than that included\nin the Problems. These more extensive studies are called Projects. A description\nof the practical considerations in the choice of a project are contained in Sec-\ntion 5.6. Specific topics for projects with the software described in this Chapter\nare listed here.\n1. Hypothesis -- The effect of temperature on the conduction velocity of the\nsquid giant axon can be fit by the Hodgkin-Huxley model. Articles in the\nliterature should be consulted for this project (Chapman, 1967; Easton and\nSwenberg, 1975).\n2. Hypothesis -- When two action potentials are elicited, the velocity of the\nsecond is slower than the velocity of the first action potential. This phe-\nnomenon is predicted by the Hodgkin-Huxley model. Articles in the litera-\nture should be consulted for this project (George et al., 1984).\n3. Hypothesis -- The threshold current for eliciting an action potential with an\nintracellular electrode is higher for a space-clamped than for an unclamped\nmodel of an axon.\n4. Hypothesis -- Increasing the membrane capacitance will decrease the con-\nduction velocity.\n5. Hypothesis -- Increasing the membrane conductance (by scaling all the\nionic conductances) will increase the conduction velocity.\n6. Hypothesis -- Increasing the external concentration of sodium will increase\nthe conduction velocity.\n7. Hypothesis -- Increasing the external concentration of potassium will in-\ncrease the conduction velocity.\n\n6.6. PROJECTS\n8. Hypothesis -- Increasing the external concentration of calcium will increase\nthe conduction velocity.\n9. Hypothesis -- Increasing the temperature will increase the conduction ve-\nlocity.\n10. Hypothesis -- The solution using the forward Euler method is stable pro-\nvided ∆t ≤πa(ro + ri)(∆z)2Cm.\n11. Hypothesis -- The backward Euler algorithm is stable for all values of ∆t\nand ∆x.\n12. Hypothesis -- The Crank-Nicolson method and the staggered increment\nCrank-Nicolson method are stable for all values of ∆t and ∆x.\n13. Hypothesis -- Using the forward Euler approximation, the error resulting\nfrom temporal and spatial discretization behaves as O(∆t) + O((∆x)2).\n14. Hypothesis -- Using the backward Euler approximation, the error resulting\nfrom temporal and spatial discretization behaves as O(∆t) + O((∆x)2).\n15. Hypothesis -- Using the Crank-Nicolson method and the staggered incre-\nment Crank-Nicolson method, the error resulting from temporal and spa-\ntial discretization behaves as O((∆t)2) + O((∆x)2).\n\nCHAPTER 6. PROPAGATED ACTION POTENTIAL\n\nChapter 7\nVOLTAGE-GATED ION CHANNELS\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\n7.1\nIntroduction\n7.1.1\nHistorical background\nPassive transport of ions through cellular membranes is mediated by membrane-\nbound channel proteins that form selectively permeable ion channels. Although\ntheir existence was long suspected, the first direct physiological evidence for\nthese channels became available in 1976 (Neher and Sakmann, 1976). Subse-\nquently, many different types of channels have been identified (Hille, 1992).\nChannels can be categorized on the basis of the physical/chemical variable that\nopens or gates the channel. For example, the channels that underlie the prop-\nerties of electrically excitable cells are gated by the membrane potential and are\ncalled voltage-gated channels. These channels are opened by a change in mem-\nbrane potential. Other channels are gated by the binding of specific chemical\nsubstances, mechanical deformation of the membrane, etc. In all of these cases,\nthe channels behave as if they have a discrete number of states, of which a few\n(usually only one) are conducting or open states and the others (usually more\nthan one) are non-conducting or closed states. The channel switches rapidly and\nrandomly among its allowable states, and the probability that a transition occurs\nat a particular time depends on the value of the gating variable.\nModels of the gating of single ion channels were developed almost immedi-\nately after single-channel data were obtained (Colquhoun and Hawkes, 1977).\nDescriptions of these models can be found elsewhere (Colquhoun and Hawkes,\n1995a; Weiss, 1996b).\n7.1.2\nOverview of software\nThis software package enables users to enhance their understanding of models\nof the gating of single voltage-gated ion channels. The software allows the user\nto design a channel by choosing the number of states, the voltage dependence\nof transitions between states, the conductance and gating charge of each state,\nand the equilibrium potential for the channel. After the channel is designed, the\nuser can analyze the behavior of the channel to a change in membrane poten-\ntial. Any of the variables associated with the channel can be displayed including\nthe state occupancy probability, ionic conductance, ionic current, gating charge,\nand gating current. Both random variables and their expected values can be dis-\nplayed as a function of time. The software is sufficiently powerful and flexible\nto allow users to synthesize realistic, state-of-the-art models for the gating of\nvoltage-gated ion channels.\n\n7.2. DESCRIPTION OF THE MODEL\n7.2\nDescription Of The Model\nA brief description of the channel model is given here; a more complete descrip-\ntion is given elsewhere (Weiss, 1996b). We assume that a channel has N states\nand that at each instant in time t, the channel is found in one of its states (Fig-\nure 7.1). The states are enumerated as {S1, S2, S3, . . . SN}. Each state has state at-\nS1\nS2\nS3\nS4\nS5\nα12\nα23\nα34\nα45\nα51\nα21\nα32\nα43\nα54\nα15\nγ1, Q1\nγ2, Q2\nγ3, Q3\nγ4, Q4\nγ5, Q5\nFigure 7.1: Kinetic diagram of a channel that has 5 states. The states are shown linked\nby rate constants for transitions between states, where αij is the rate of transition from\nstate i to state j. When the channel is in state j the conductance of the channel is γj\nand the gating charge of the channel is Qj.\ntributes: the state conductance and the state gating charge. The state attributes\nfor these states are denoted as {γ1, γ2, γ3, . . . γN} for the state conductances and\n{Q1, Q2, Q3, . . . QN} for the state gating charges. Given the membrane potential Vm\nand the equilibrium potential Veq, the state ionic currents are {I1, I2, I3, . . . IN}.\nThus, when the channel is in state Sj, the state conductance is γj, the state ionic\ncurrent is Ij = γj(Vm -Veq), and the state gating charge is Qj. Gating currents\noccur at the transitions of the gating charge.\nThe temporal evolution of the electrical properties of a channel depend upon\nthe state occupancy probabilities which we discuss briefly. Define the probability\nthat the channel is in state j at time t as xj(t), and the transition probability that\nthe channel is in state j at time t + ∆t given that it was in state i at time t as\nyij(t + ∆t). The fundamental assumption of the model for state transitions is\nthat the transition probabilities depend on the present state of the channel and\nnot on previous states. Such a probabilistic process is called a Markov process.\nFormally, we assume that\nyij(t + ∆t) = αij∆t + o(∆t) ,\nwhere o(∆t) has the property that lim∆t→0 o(∆t)/∆t = 0 and αij is a rate con-\nstant for transitions from state i to state j. The first term is the probability of\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\noccurrence of a single transition in the interval of duration ∆t when this interval\nis short and the rate of transitions is αij. The second term takes into account\nthe probability of the occurrence of multiple transitions in the interval. For in-\ntervals ∆t that are sufficiently small so that no more than one transition is likely\nto occur in the interval, the o(∆t) term is negligible; we will ignore this term in\nthe development that follows. The probability that the channel is in state j at\ntime t + ∆t and in state i at time t is yij(t + ∆t)xi(t) ≈αijxi∆t.\nThe increase in probability that the channel is in state j in the time interval\n(t, t + ∆t) is xj(t + ∆t) -xj(t). In this time interval, this probability increases\nas a result of transitions from states i into state j and decreases as a result of\ntransitions from state j into state i. By collecting all such terms we obtain,\nxj(t + ∆t) -xj(t) ≈\nN\n\ni=1,i=j\nαijxi(t)∆t -\nN\n\ni=1,i=j\nαjixk(t)∆t ,\nwhere the first summation is due to transitions into state j and the second sum-\nmation is due to transitions out of state j. If we rearrange the terms and take\nthe limit as ∆t →0, we obtain the differential equation\ndxj(t)\ndt\n=\nN\n\ni=1,i=j\nαijxi(t) -\nN\n\ni=1,i=j\nαjixj(t).\n(7.1)\nThis equation can be written in matrix form by defining the matrix of transition\nprobabilities to be\nα =\n\nα11\nα12\n· · ·\nα1N\nα21\nα22\n· · ·\nα2N\n· · ·\n· · ·\n· · ·\n· · ·\nαN1\nαN2\n· · ·\nαNN\n\n.\nwhere αij is the transition rate from state i to state j when i = j, and αii is\nchosen so that\nN\ni=1 αij = 0. The state occupancy probability satisfies the matrix\ndifferential equation\ndx(t)\ndt\n= x(t)α,\n(7.2)\nwhere x(t) is a row matrix of state occupancy probabilities. In addition, since\nthe channel is in one of its N states at each instant in time,\nN\n\nj=1\nxj(t) = 1 .\nThe equilibrium state occupancy probability can be obtained directly from Equa-\ntion 7.2 by setting dx(t)/dt = 0 to yield\n0 = x(inf)α,\n(7.3)\n\n7.2. DESCRIPTION OF THE MODEL\nto obtain the equilibrium state occupancy probability x(inf).\nIf the matrix α is constant, then the solution to the matrix equation for the\nstate occupancy probability is (Colquhoun and Hawkes, 1995a)\nx(t) = x(0)eαt,\nwhere x(0) is the matrix of the initial value of x(t). Evaluation of the exponential\nmatrix yields the result\nx(t) = x(0)\nN\n\nj=1\nSjeλjt,\n(7.4)\nwhere λj is the jth eigenvalue of and Sj is the jth spectral matrix of α. There-\nfore, we see that the state occupancy probabilities are weighted sums of ex-\nponentials whose exponents are the eigenvalues of the transition rate matrix.\nBecause the α matrix is singular, one eigenvalue has value zero. All other eigen-\nvalues have negative real parts (Cox and Miller, 1965). Thus, the non-zero eigen-\nvalues lead to solution exponentials that decay with time.\nFor a voltage-gated channel, the transition rates depend explicitly on the\nmembrane potential which in turn may vary with time. If the rate constants are\nassumed to satisfy the theory of absolute reaction rates (Weiss, 1996a; Weiss,\n1996b), then they depend exponentially on the membrane potential,\nαij(Vm) =\n\nAijeaijVm\nif i =j,\nif i = j,\nwhere Aij is a rate factor and aij is an exponential factor.\nαij(Vm) depends\non the membrane potential which in turn depends upon time. Therefore, the\nrate constants will in general depend upon time. A more physical representation\nfollows by linking the rate constants to the state gating charges. In this formu-\nlation, the rate constants that link states i and j (where i =j) can be written\nas\nαij(Vm)\n=\nAe(0.5+ξ)\nQj-Qi\n\n(Vm-Vij)/kT,\nαji(Vm)\n=\nAe(0.5-ξ)\nQi-Qj\n\n(Vm-Vji)/kT,\nwhere k is Boltzmann's constant, T is the absolute temperature, ξ is an asym-\nmetry factor, Qi and Qj are the state gating charges in states i and j, Vij and Vji\nare the membrane potentials at which the rate constants equal A.\nDuring intervals of time when the membrane potential is a constant, Equa-\ntion 7.2 is a linear, first-order matrix differential equation with constant coeffi-\ncients. The solution determines the state occupancy probabilities, the {xj(t)}s.\nThe expected values of the channel conductance, channel current, and gating\ncharge are computed directly from the state occupancy probabilities. If the con-\nductance of the channel is γj when the channel is in state j, then the expected\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nvalue of the conductance of the channel, g(t), is\ng(t) =\nN\n\nj=1\nγjxj(t).\n(7.5)\nIf we assume that the current through the channel when the channel is in state\nj is γj(Vm -Veq), the expected value of the single-channel current, i(t), is\ni(t) =\nN\n\nj=1\nγjxj(t)(Vm -Veq) = g(t)(Vm -Veq).\n(7.6)\nSimilarly, if the gating charge of the channel when the channel is in state j is Qj,\nthe expected value of the single-channel gating charge, qg(t), is\nqg(t) =\nN\n\nj=1\nQjxj(t).\n(7.7)\nThe expected value of the single-channel gating current, ig(t), is\nig(t) = dqg(t)\ndt\n.\n(7.8)\n7.3\nNumerical Methods\n7.3.1\nIntegration step\nThe differential equation for the state occupancy probability (Equation 7.2) is\nsolved numerically using methods described elsewhere (Colquhoun and Hawkes,\n1995b). The accuracy and efficiency of the numerical solution depends upon the\nvalue of the integration step, ∆t.\nThe value of ∆t needs to be chosen small\nenough so that the time rate of change in the occupancy probabilities can be re-\nsolved accurately and so that the random variables are represented accurately.\nThe choice of an adequate value of ∆t depends upon the eigenvalues of the state\ntransition rate matrix. Typically, ∆t should be chosen so that ∆t ≪1/|λmax|,\nwhere λmax is the eigenvalue with the largest magnitude. The smaller ∆t is cho-\nsen the more accurate the integration in any one step, but the longer the compu-\ntation will take. In addition, long computations can result in the accumulation of\nround-offerrors. Thus, the choice of ∆t is a compromise between the speed and\naccuracy of the simulation. Solution of the matrix equation (Equation 7.4) deter-\nmines the occupancy probabilities of each state. From these probabilities, the\nexpected values of the conductances, currents and gating charge are computed\nusing Equations 7.5-7.8.\n\n7.3. NUMERICAL METHODS\n0.1\n0.2\n0.5\n0.01\n0.02\n0.05\n0.005\n0.1\n0.2\nε(λ∆t)\nλ∆t\nFigure 7.2: The probability of occurrence of\nmore than 1 event in an interval ∆t where\nthe rate of events is λ and the events are dis-\ntributed according to a Poisson distribution.\nRandom variables are computed from state transition probabilities.\nTran-\nsitions probabilities from state i to state j are computed from the relation\nyij(t + ∆t) ≈αij∆t at each instant in time. The time interval for computing\nrandom variables is set equal to the integration step ∆t. The occurrence of a\ntransition is determined by a random number generator. The sequence of state\ntransitions determines the sequence of conductance values and gating charges\nsince each state has a unique conductance and gating charge. The conductance\nvalues determines the current since this current is determined by specifying the\nconductance, the membrane potential, and the channel equilibrium potential.\nThe gating current random variable is represented by impulses at the times of\ntransition of the gating charge and whose areas equal the discontinuities in gat-\ning charge.\nIn order to accurately represent the random variables, the time interval must\nbe chosen sufficiently brief that the probability of occurrence of more than 1\nchange in state in the interval is negligible. The probability of occurrence of\nk events in an interval ∆t with an average rate of events of λ is given by the\nPoisson distribution\nPr(k, λ∆t) = (λ∆t)k\nk!\ne-λ∆t.\n(7.9)\nHence, the probability of occurrence of more than 1 event in an interval is\nε(λ∆t) = 1 -Pr(0, λ∆t) -Pr(1, λ∆t) = 1 -(1 + λ∆t)e-λ∆t.\n(7.10)\nThe probability of more than one event in an interval ε(λ∆t) is shown plotted\nversus λ∆t in Figure 7.2. Note that for λ∆t ≤0.2, ε(λ∆t) ≤0.018.\n7.3.2\nInitial conditions\nIn order to obtain a solution to Equation 7.2, initial conditions must be speci-\nfied. There are several plausible choices for the initial conditions, i.e., the initial\nstates of the channel. One choice is simply to specify the initial state determinis-\ntically. A second choice is to choose the most probable state as the initial state.\nThe most probable state can be obtained by solving Equation 7.3 and choos-\ning the initial state as the one with the highest probability. A third choice is\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nFigure 7.3: The IC Control figure after the software is initi-\nated.\nto choose the initial state probabilistically according to the equilibrium proba-\nbility for state occupancy as determined by Equation 7.3. All three choices are\nimplemented in the software.\n7.4\nUser's Guide To The Software\nWhen the software is initiated, 2 figures are displayed (in addition to MATLAB's\ncommand window): the IC Control and the IC Parameters figures. The IC Control\nfigure controls the software (Figure 7.3). The IC Parameters figure allows the\nuser to design a single channel. Once the channel is designed, the membrane\npotential is specified as a function of time, and the numerical variables chosen,\nthe simulation can be run, and the statistical properties of the channel variables\ncan be analyzed.\n7.4.1\nIC Control\nThe portion of the IC Control figure (Figure 7.3) below the menubar is divided\ninto three panels. The setup panel allows the user to: select Channel parame-\nters which is used to design the channel, Membrane potential which is used to\nspecify the membrane potential as a function of time, and Numerics which is\nused to specify the initial conditions and the integration of the computation. A\npanel just below the setup panel controls the simulation. The simulation can\nbe started, stopped, paused, or continued. Clicking on Open allows results saved\nin files to be read. Clicking on Save allows the user to save the results of the\nsimulation in a file; all parameters of the channel design are saved as well as the\n\n7.4. USER'S GUIDE\nFigure 7.4: The IC Parameters figure.\nsimulation results. The analysis panel allows display of the results of a simula-\ntion.\n7.4.2\nIC Parameters\nThe IC Parameters figure displays the default channel kinetic diagram as shown\nin Figure 7.4. The user can either read a previously stored channel model from\na file or construct a channel model by editing the default channel model. Edit-\ning entails adding new states, adding or modifying rate constants that link the\nstates, assigning ionic conductances and gating charges to states, and assigning\nan equilibrium potential to the channel model.\nEach box in the channel parameters figure (Figure 7.4) represents a particular\nstate of the channel and is given a number from 1 to 8 (a maximum of 8 states is\npossible). The arrows connecting these states depict the transition rates between\nstates. Each box also contains the ionic conductance of the channel when the\nchannel is in that state, i.e., the state ionic conductance. The ionic conductance\ncan be changed by clicking on it's value and typing the new value into the text\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nedit box. The ionic conductance is expressed in picosiemens (pS). A value of\nzero denotes a non-conducting state. Each box also contains the gating charge\nvalence z of the channel when the channel is in that state; the gating charge\nvalence can be changed by clicking on it's value and typing the new value into\nthe edit box. The gating charge valence can be positive or negative and need not\nbe an integer. The gating charge is ze, where e = 1.602 × 10-19 C. The value of\nthe channel equilibrium potential can be changed by clicking in the text edit box\nin the upper right hand corner of the IC Parameters figure and typing the new\nvalue in the text edit box. A single click on a rate constants displays its voltage\ndependence in the IC Parameters figure.\nAdd new state\nA new state can be added to the diagram by clicking on New. A new state will be\ncreated and positioned in the upper left corner of the field. A new state or any\nexisting state can be repositioned in the window by clicking on the grey region\nat the top of the state boxes and dragging the state box to a new position. To\ndelete a state the user clicks on the red delete box in the upper left-hand portion\nof the state box.\nAdd rate constant\nTo add rate constants linking state i to state j, the user first clicks on Add in the\nIC Parameters figure, then clicks in the state box for state i, and then clicks in\nthe state box for state j. During this operation, the cursor becomes a cross hair.\nA pair of default rate constants is added to link these two states.\nIC Specify rate constants\nTo modify the rate constants that link two states, the user double clicks on the\nselected rate constants to obtain the IC Specify rate constants figure (Figure 7.5).\nThe user selects which rate constant to modify or to create by clicking on the\nappropriate pushbutton. The voltage dependence of the rate constant, can be\nspecified numerically by typing numbers into the appropriate text edit boxes or\ngraphically by using the mouse. Clicking on two locations in the plot of rate con-\nstant versus potential puts an exponential function through those two points. A\nformula for the dependence of the rate constant on membrane potential is dis-\nplayed in the lower left-hand corner of the IC Parameters figure. This formula is\nalso displayed by clicking on a rate constant in the IC Parameters figure.\nClicking on Delete deletes the pair of rate constant from the IC Parameters\nfigure. Clicking on the two curved linked arrows exchanges the two rate con-\nstants. Clicking on Revert resets the rate constant to the previously stored value.\n\n7.4. USER'S GUIDE\nFigure 7.5: The IC Specify rate constants figure after the user has double clicked on the\nrate constants linking states 1 and 2 in Figure 7.4 and changed the parameters of the\nthe rate constant so that α12 = 2.5e0.01Vm (1/ms) and α21 = 3e-0.04Vm (1/ms), where\nVm is in mV..\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nFigure 7.6: IC View rate constant figure after the rate constants have been defined as in\nFigure 7.5.\nMiscellaneous features\nIf Reset Diagram is selected the current channel kinetic diagram is erased and\nthe default channel kinetic diagram is drawn. A previously stored diagram can\nbe retrieved by selecting Open. The current diagram can be saved to a file by se-\nlecting Save. Clicking on Save in the IC Parameters figure saves all the channels\nparameters but not the simulation results.\nViewing the voltage dependent parameters\nThe voltage dependent rate constants can be displayed by clicking on the button\nmarked ViewRC in the IC Parameters figure which results in the display of\nthe IC View rate constants figure (Figure 7.6). This figure contains a number of\npanels.\n\n7.4. USER'S GUIDE\nFigure 7.7: The IC Setup view rate constant figure.\nPlot control. The panel in the upper left corner controls plotting in the manner\ndescribed below.\nSetup. Clicking on Setup in the IC View rate constants figure displays the\nIC Setup view rate constants figure (Figure 7.7) which allows selection\nof the voltage-dependent parameters as a function of the membrane\npotential.\nVariables. The abscissa is the membrane potential. Shift clicking on\nany variable adds it to the collection of selected ordinate vari-\nables. Clicking on any variable, selects that variable and deselects\nall others.\nThe variables associated with each pair of rate con-\nstants are: αij, αji, τij = 1/(αij + αji), xij = αij/(αij + αji), and\nxji = αji/(αij + αji). τij is the time constant for transition be-\ntween states i and j provided there are only two states; if there\nare more than two states, then τij has no particular significance.\nSimilarly, xij is the probability that the channel will be in state j at\nequilibrium provided there are only two states; if there are more\nthan two states, then xij has no particular significance.\nGraph. Clicking on Graph results in a plot of the selected data. The\nnew plot replaces the old plot.\nOpen. Clicking this button allows plotting of results stored in a file.\nSave. Clicking this button allows the information in the plot to be saved in\na file. All lines, labels, and annotations are saved.\nPrint. Clicking on Print prints the figure.\nCross-line. Clicking on\ndisplays a vertical line, the cross line, in the plot\nfield at the location of the pointer cursor. The line follows the cursor\nas it moves across the plot field. The values of all plotted variables at\nthe intersection with the cross line are displayed in the legend. Click-\ning on cross-line button again removes the cross-line values from the\nlegend and removes the cross line from the plotting field.\nAnnotate. Clicking on A and then on a desired location in the plot area\ndisplays a text edit box at that location. Click in the text edit box, type\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nthe annotation followed by a <RETURN> when the annotation is com-\npleted. Clicking on the annotation and dragging the mouse moves the\nannotation to a desired location in the plot field. The text string can\nbe formatted into mathematical notation by using a LATEX like notation,\ne.g., to get α12 type \\alpha_{12}.\nZoom. Clicking on\n+\nallows the user to magnify a region of the plotting\nfield by clicking on it. Additional magnification can be achieved by\nzooming again.\nUnzoom. Clicking on\n-\nundoes the effects of all prior zooms.\nAxes control. The plot axes can be changed by clicking on any of the axis labels\n-- either the abscissa or any of the ordinates -- which results in the display\nof a figure that allows changing the axis (see Figure 5.8). The axis scale can\nbe chosen to be linear, logarithmic, and/or reciprocal. If neither the Log\nnor the Inverse (1/) options is chosen, the scale is linear. If Log is chosen,\nthe scale is the logarithm of the magnitude of the variable. If Inverse (1/) is\nchosen then the reciprocal of the variable is plotted either on a linear or on\na logarithmic scale. Clicking on Apply results in a change in the axis. The\nplot range can be changed, but the axis labels cannot be edited.\nLegend. The legend panel records a list of all data plotted. The following are\nrecorded.\nLine properties. The color, line style, and symbol type are used to encode a\nparticular variable; this marker is shown in the legend. Clicking on the\nmarker allows the user to edit the attributes of the plot line/symbol\n(see Figure 5.9).\nVariable name. The name of the variable that was plotted is shown. Click-\ning on the variable name alternately displays and hides the curve as-\nsociated with this entry. When variables are added or deleted, the axis\nis auto-scaled if that option is selected -- it is selected by default -- in\nthe axis figure.\nCross-line If the cross-line is used the cross-line values are displayed.\nData-set. The time when the curves were generated are indicated. Click-\ning on the time stamp alternately displays and hides all the curves\nassociated with this legend item.\n7.4.3\nMembrane potential\nSelection of Membrane Potential in the controls figure displays the IC Membrane\npotential figure (Figure 7.8). The membrane potential can be a rectangular pulse\nof potential superimposed on a steady holding potential. The user can select\n\n7.4. USER'S GUIDE\nFigure 7.8: IC Membrane poten-\ntial figure after selection of a\npulse of potential.\nFigure 7.9:\nIC Numer-\nics figure appropriate for\nrate constants shown in\nFigure 7.6 and membrane\npotential shown in Fig-\nure 7.8.\nthe holding potential, the duration of the stimulus, the onset time of the pulse\nstarts, the pulse duration, and pulse amplitude. The parameters of the mem-\nbrane potential can be read from and saved to a file.\n7.4.4\nNumerics\nThe IC Numerics figure (Figure 7.9) controls the choice of the integration step\nand initial conditions for the simulation. The figure consists of five panels. The\ntwo upper panels deal with the eigenvalues of the transition rate matrix. The\nmiddle panes deal with the method for choosing the integration step size. The\nbottom panel deals with the choice of initial conditions (initial states).\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nEigenvalues\nFor a given choice of membrane potential and voltage-dependent rate constants,\nthe software computes the eigenvalues of the transition rate matrix and dis-\nplays these results to the user. These eigenvalues have the dimensions of rate\nconstants (RC). The user can also choose to display the time constants (TC =\n-1/RC) corresponding to these eigenvalues. In addition, the absolute value of\nthese rate and time constants can also be displayed.\nIntegration step\nThe smallest time constant is computed from the fastest eigenvalue and the user\ncan choose, by editing the text edit box, to make the integration step a fraction\n(or a multiple) of this smallest time constant. Alternatively, the user can choose\na fixed integration time. The integration time that results from the user's choice\nis displayed as is the probability of more than one transition during an interval\nof time that equals the integration step.\nInitial state\nThe initial state for a simulation can be chosen deterministically to be any of\nthe allowable states or the most probable state for the given initial values of the\nmembrane potential. By default, the initial state is chosen probabilistically by\ncomputing the state occupancy probabilities for the chosen initial value of the\nmembrane potential and choosing the initial state randomly using these proba-\nbilities.\n7.4.5\nAnalysis\nClicking on the analysis panel of the IC Control figure allows access to a variety\nof displays of simulation results including such variables as: the state occu-\npancy, the state occupancy probability, the ionic conductance, the ionic current,\nthe gating charge, and the gating current. Both the random variables and their\nexpected values can be displayed. Ten channels with similar characteristics can\nbe examined simultaneously to allow users to relate macroscopic to microscopic\nvariables. Results of multiple simulations can also be plotted on a single set of\naxes for the sake of direct comparison.\nThree different types of graphs are available. The first type allows plotting\na single variable as a function of time in fixed coordinates. An example is the\nIC State occupancy figure shown in Figure 7.10. The top panel shows the sim-\nulation for 10 independent channels, the middle panel shows the results for\nchannel 1 alone, and the bottom panel shows the state occupancy probabilities\nfor both states of the channel. A second example of this type of graph is the\nIC Ionic current figure shown in Figure 7.11. Selected for plotting are the ionic\n\n7.4. USER'S GUIDE\nFigure 7.10: IC State occupancy figure with all variables selected for display.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nFigure 7.11: IC Ionic current figure showing the relation between the random variable\nand its expected value of the ionic current.\ncurrent random variable, its expected value, and the average ionic current of 10\nidentically distributed but statistically independent channels. Similar plots are\navailable for the ionic conductance, gating charge, and gating current. These dis-\nplays are helpful for relating macroscopic to microscopic variables and random\nvariables to their expected values.\nA second type of graph is the IC Summary figure which allows comparison\nof the time dependence of channel variables to each other in fixed coordinates\n(Figure 7.12). Most of the variables are self-evident from the display. However,\nthe representation of the gating current random variable requires some com-\nment. The gating charge random variable is a random rectangular wave. Hence,\nthe gating current random variable, which is defined as the derivative of the\ngating charge random variable, is a random impulse train (train of Dirac delta\nfunctions). We represent these impulses with vertical arrows. The time of occur-\nrence of an arrow equals the time of occurrence of an impulse and the height of\nthe arrow equals the area of the impulse. On the scale of visibility of the gating\ncurrent random variable, the expected value is often too small to see. Hence, in\nthe plot of the gating current, deselecting the random variable will allow its ex-\npected value to be observed. Clicking on the radio button for Cross line displays\na vertical line that tracks the position of the mouse cursor. The values of the\nintersection of the line with each variable is displayed.\nThe above graphs have limited capability for control of scales. The ordinate\n\n7.4. USER'S GUIDE\nFigure 7.12: IC Summary figure with all variables selected for display.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nFigure 7.13: IC Graphics figure showing the expected value of the ionic current and of\nthe gating charge for the channel defined in Figures 7.4-7.8.\nscale is autoscaled automatically. This is convenient but can be misleading in\nthat errors inherent in numerical calculations become autoscaled and can ap-\npear large if the scale is not read. For example, if for some set of parameters\nsome current variable is in principle zero, its numerical value may be limited\nby the numerical accuracy of the computations to be 10-23 pA, a small current.\nHowever, if autoscaled in the above graphs, this current may appear large. The\ntype of graph described below yields more control over plotting scales and can\nhelp the user to interpret such small currents.\nThe third type of graph allows comparison of results obtained in different\nsimulations in coordinates defined by the user. Clicking on Graphics in the em\nIC Control figure displays the IC Graphics figure (Figure 7.13).\nThis figure allows plotting most of the results of the simulation; the random\nvariables are not plotted with the IC Graphics figure but all the expected values\nand probabilities of all variables are plotted. For the allowable variables, any\n\n7.4. USER'S GUIDE\nFigure 7.14: The IC Setup graph-\nics figure showing the variables\nused to setup Figure 7.13.\nvariable can be plotted against any other in coordinates chosen by the user. The\ncontrol of this figure is virtually identical to that for the IC View rate constants\nfigure (Figure 7.6). Hence, we describe only the differences. The main difference\noccurs if Setup is selected in the IC Graphics figure which results in display\nof the IC Setup graphics figure (Figure 7.14). Several dependent variables can\nbe plotted simultaneously. In addition, results saved in files can be plotted so\nthat results for different parameters can be compared. In addition, results of\nconsecutive simulations can be overlayed. We give two examples of the type\nof graphics that are readily available with the IC Graphics figure. Figure 7.15\nshows the state occupancy probabilities of all four states as a function of time.\nFigure 7.16 shows the ionic conductances of three different channel models -- a\ntwo-state, a three-state, and a four-state model.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nFigure 7.15:\nIC Graphics figure showing the state occupancy probabilities for a\nfour-state channel whose successive states are linked by rate constant such that\nα12 = α23 = α34 and α21 = α32 = α43 where α12 and α21 are identical to those in\nFigure 7.5.\n\n7.4. USER'S GUIDE\nFigure 7.16:\nIC Graphics figure showing the ionic conductances of a two-state,\nthree-state,\nand\na\nfour-state\nchannel\nwhere\nthe\nlast\nstate\nin\neach\nof\nthese\nthree channel models is a conducting channel with a conductance of 20 pS.\nα12 = α23 = α34 = 4e0.04Vm and α21 = α32 = α43 = 0.2e-0.05Vm (ms-1). The mem-\nbrane potential had at a holding potential of -80 mV and stepped to +40 mV.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\n7.5\nProblems\nProblem 7.1 The purpose of this problem is to explore the properties of a channel\nthat has one two-state gate that is not voltage gated. This two-state channel has\nrate constants that are not a function of membrane potential; this channel is not\nvoltage-gated. Define a two-state channel for which state 1 is closed (noncon-\nducting) and state 2 is open (conducting),\nα12\n⇋\nα21\n2 .\nUse rate constants that are constant (independent of membrane potential). In all\nparts of this problem use rate constants such that α12 + α21 = 10 ms-1.\na. Determine opening and closing rate constants such that the channel is\nequally likely to be in state 1 or state 2.\nb. Determine opening and closing rate constants such that the channel is\nthree times as likely to be in state 2 than in state 1.\nc. Use the same rate constants as in part b. Set the membrane potential so\nthat it is -50 mV for t < 0.5 ms and +50 mV for t > 0.5 ms. The objective\nof this part is to design a channel that has a single-channel current when\nthe channel is open (I) of -1.2 pA when the membrane potential is -50\nmV and +0.8 pA when it is +50 mV.\ni. Determine the equilibrium potential and single-channel conductance\nwhen the channel is open (γ). Check your answer by running the simu-\nlation using the values of the equilibrium potential and single-channel\nconductance you determined.\nii. What is the average single-channel current (i) for t < 0.5 ms? What is\nthe average single-channel current for t > 0.5 ms?\nProblem 7.2 The purpose of this problem is to explore the properties of a chan-\nnel that has a two-state gate that is voltage gated. This two-state channel has\nrate constants that are functions of membrane potential; the channel is voltage-\ngated. Define a two-state channel for which state 1 is closed (nonconducting)\nand state 2 is open (conducting),\nα12\n⇋\nα21\n2 .\nSet the membrane potential to -60 mV for t < 0.2 ms and to +40 mV for t > 0.2\nms.\n\n7.5. PROBLEMS\na. Determine voltage-dependent rate constants such that: the channel is closed\n(with probability > 0.8) for t < 0.2 ms; the channel is open (with probabil-\nity > 0.8) for t ≫0.2 ms; and the channel opens with a time constant of\nabout 0.2 ms.\nb. Determine parameters of the channel such that when the channel is open,\nthe single-channel current (I) is +0.5 pA at a membrane potential of +40\nmV and is zero when the membrane potential is -10 mV.\nc. Is this an activation gate or an inactivation gate?\nd. Change the equilibrium potential to -70 mV. Repeat the simulation. Could\nthis channel describe the kinetics of the potassium channel in the Hodgkin-\nHuxley model? In what ways does it resemble the potassium channel? In\nwhat ways does it differ from the potassium channel?\ne. Change the equilibrium potential to +50 mV. Repeat the simulation.\ni. Is the average channel conductance a continuous function of time?\nExplain!\nii. Is the average channel current a continuous function of time? Explain!\niii. Could this channel describe the kinetics of the sodium channel in the\nHodgkin-Huxley model? In what ways does it resemble the sodium\nchannel? In what ways does it differ from the sodium channel?\nProblem 7.3 The purpose of this problem is to explore the properties of two two-\nstate voltage-gated channels that differ only in their state conductances.\nThis\nproblem deals with two channels that each have two states with the same kinetic\ndiagram, namely\nα12\n⇋\nα21\n2 ,\nwhere the rate constants are\nα12 = 4e0.04Vm and α21 = 2e-0.01Vm .\nEach channel is subject to a membrane potential profile that is -60 mV from\nt = 0 to t = 1 ms after which the membrane potential is +10 mV for 2 ms. The\nequilibrium potential for each channel is +40 mV. The channels differ only in\nthe conductance assigned to each state. Channel 2 has γ1 = 0 and γ2 = 20 pS;\nChannel 2 has γ1 = 20 pS and γ2 = 0.\na. Which channel opens in response to a depolarization? Explain.\nb. Which channel closes in response to a depolarization? Explain.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\nc. Does the time-dependence of the probability that the channel is in state 1\ndiffer for these two channels? Explain.\nProblem 7.4 The purpose of this problem is to explore the effect of scaling the\nrate constants on the kinetic properties of a channel. The kinetic diagram has the\nform\nα12\n⇋\nα21\n2 .\nThe membrane potential is -60 mV from t = 0 to t = 1 ms and +10 mV for 2\nms. The equilibrium potential is +40 mV. The channel conductances are γ1 = 0\nand γ2 = 20 pS.\na. Set the voltage dependence of the rate constants as\nα12 = 4e0.04Vm and α21 = 2e-0.01Vm ,\nand run the simulation.\nPlot the ionic conductance and ionic current.\nRecord the values of eigenvalues.\nb. Next double the rate constants so that the voltage dependence of the rate\nconstants becomes\nα12 = 8e0.04Vm and α21 = 4e-0.01Vm .\nRun the simulation again. Plot the ionic conductance and ionic current.\nRecord the values of eigenvalues.\nc. Next halve the rate constants so that the voltage dependence of the rate\nconstants becomes\nα12 = 2e0.04Vm and α21 = 1e-0.01Vm .\nRun the simulation again. Plot the ionic conductance and ionic current.\nRecord the values of eigenvalues.\nd. Examine the results and draw conclusions about the effect of scaling the\nrate constants without otherwise changing their voltage dependence. Focus\nboth on the random variables and on the expected values of both the ionic\nconductance and the ionic currents. Be as quantitative as possible.\nProblem 7.5 The purpose of this problem is to explore the effect of the choice of\ninitial state on the properties of a channel with a simple, two-state gate.\na. Start the simulation with the default parameters. Examine the Summary\nplot and the State occupancy plot.\n\n7.5. PROBLEMS\nb. Now display the IC Numerics figure. Note that the default initial state is\nRandom. Now change the initial state to be state 1. Start the simulation.\ni. Describe the differences between the results obtained with a random\ninitial state and an initial state of 1. What accounts for this difference.\nii. Carefully display the time course of the state occupancy probability\nusing the Graphics figure and determine the time constant of the time\ncourse of the state occupancy probability.\niii. Compare the time constant you estimated in part ii with the eigenvalue\n(expressed as a time constant) from the Numerics figure.\nProblem 7.6 The purpose of this problem is to explore the gating charge of a\nchannel that has one two-state gate. The rate constants of the channel are α12 = 1\nand α21 = 2 ms-1. The gating charge of state 1 is 0 and that of state 2 is 2eC.\na. Run the simulation and determine the expected value of the gating charge.\nExplain its value.\nb. Without changing any other parameter, determine a value of α12 such that\nthe expected value of the gating charge is 1eC.\nc. Set both α12 = α21 = 2 ms-1 and set the gating charge of both state 1 and 2\nto 2eC. Run the simulation. Explain the expected value of the gating charge.\n[Hint -- you may find it convenient to use the Graphics plots (which you\ncan select from the IC Control figure. This option allows a great deal of\ncontrol over axes scales which may be important to interpret the results.]\nProblem 7.7 The purpose of this problem is to explore the relation among ionic\nconductance, ionic current, gating charge, and gating current for a channel that\nhas one two-state gate. The rate constants are α12 = 1 and α21 = 2 ms-1. The\ngating charge of state 1 is 0 and that of state 2 is 2eC. The ionic conductance\nof state 1 is 0 and that of state 2 is 20 pS. Run the simulation.\n[Hint -- for\nsome parts of this problem, you may find it convenient to use the Graphics plots\n(which you can select from the IC Control figure). This option allows a great deal\nof control over axes scales which may be important to interpret the results. The\nother plots have autoscaled axes in which small errors, inherent in numerical\ncalculations, are autoscaled to appear large.]\na. Examine the expected value of the ionic conductance.\ni. Describe the ionic conductance.\nii. Explain its value.\nb. Examine the expected value of the ionic current.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\ni. Describe the ionic current.\nii. Explain its values.\nc. Examine the expected value of the gating charge.\ni. Describe the gating charge.\nii. Explain its value.\nd. Examine the expected value of the ionic current.\ni. Describe the ionic current.\nii. Explain its value.\ne. Note that the expected value of the ionic conductance and gating charge are\nnon-zero constants, the expected value of the gating current is zero, and\nthe expected value of ionic current is not constant. Explain these results.\nProblem 7.8 The purpose of this problem is to explore the physical properties of\nthe gating charge. The kinetic diagram for the channel has the form\nα12\n⇋\nα21\n2,\nwhere\nα12 = 4e0.04Vm and α21 = 2e-0.01Vm ,\nThe membrane potential is -60 mV from t = 0 to t = 1 ms and +10 mV for 2\nms. The stimulus duration is 3 ms. The equilibrium potential is +40 mV. The\nchannel conductances are γ1 = 0 and γ2 = 20 pS.\na. Perform simulations using the following state gating charges. Plot both the\nexpected value of the gating charge and the expected value of the gating\ncurrent.\ni. Q1 = 0 and Q2 = 2eC.\nii. Q1 = 0 and Q2 = -2eC.\niii. Q1 = 2eC and Q2 = 0.\niv. Q1 = -2eC and Q2 = 0.\nb. Give a quantitative account of the key properties of the gating charge and\ngating current waveforms -- the initial values, final values, and time con-\nstants.\nc. Of the results obtained in part a, which are physically plausible results.\nExplain.\n\n7.5. PROBLEMS\nProblem 7.9 The purpose of this problem is to explore the eigenvalues of channel\nmodels.\na. Consider a two-state channel with the rate constants α12 = 1 and α21 = 2\n(ms-1) and the default membrane potential shown in Figure 7.8.\ni. What are the eigenvalues for the two values of the membrane poten-\ntial?\nii. Why are the eigenvalues at the two membrane potentials the same?\nCheck your explanation by changing the membrane potential and de-\ntermining the eigenvalues.\niii. What is the relation of the eigenvalue to the rate constants? Check\nyour relation by changing the rate constants and determining the eigen-\nvalue.\niv. Design a simulation experiment that computes the temporal change\nof some variable of the two-state model to reveal the significance of\nthe eigenvalue.\nb. Consider a two-state channel with the rate constants α12 = 1.6818e0.008664Vm\nand α21 = 2 (ms-1) where Vm is in mV and the default membrane potential\nis shown in Figure 7.8.\ni. What are the eigenvalues for the two values of the membrane poten-\ntial?\nii. Why are the eigenvalues at the two membrane potentials different?\nCheck your explanation by changing the membrane potential and de-\ntermining the eigenvalues.\niii. What is the relation of the eigenvalues to the rate constants? Check\nyour relation by changing the rate constants and determining the eigen-\nvalue.\niv. Design a simulation experiment that computes the temporal change\nof some variable of the two-state model to reveal the significance of\nthe eigenvalue. Which eigenvalue determines the temporal response?\nc. Consider a three-state channel with the default rate constants α12 = 1,\nα21 = 2, α23 = 2, and α32 = 1 (ms-1) and the default membrane potential\nshown in Figure 7.8.\ni. What are the eigenvalues for the two values of the membrane poten-\ntial?\nii. Why are the eigenvalues at the two membrane potentials the same?\nCheck your explanation by changing the membrane potential and de-\ntermining the eigenvalues.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\niii. Determine a relation that computes the eigenvalues from the rate con-\nstants? Check your relation by changing the rate constants and deter-\nmining the eigenvalues.\nProblem 7.10 The purpose of this problem is to explore the properties of a three-\nstate channel whose rate constants are not a function of membrane potential; this\nchannel is not voltage-gated.\nDefine a three-state channel with the following\nkinetic scheme\nα12\n⇋\nα21\nα23\n⇋\nα32\n3 ,\nwhere states 1 and 2 are closed and state 3 is open. In all parts of this prob-\nlem, make the rate constants independent of membrane potential, and use rate\nconstants in the range 0.1-10 ms-1.\na. Determine a set of rate constants such that the channel is equally likely to\nbe in any one of its three states.\nb. Try a set of rate constants such that αij = αji. What are the probabilities\nof occupying each state? Try another such set having this property. What\nare the probabilities of occupying each state with this new set? What can\nyou conclude about this case?\nc. Determine a set of rate constants such that the probabilities that the chan-\nnel is in states 1:2:3 are approximately 0:0.5:0.5.\nd. Determine a set of rate constants such that the probabilities that the chan-\nnel is in states 1:2:3 are approximately 0:0.25:0.75.\ne. Determine a set of rate constants such that the probabilities that the chan-\nnel is in states 1:2:3 are approximately 0.2:0.3:0.5.\nProblem 7.11 The purpose of this problem is to explore the properties of voltage-\ngated channels with two, three, and four states.\nAssume that the equilibrium\npotential of each channel is 40 mV and that the membrane potential starts at\n-60 mV and switches to +10 mV at 1 ms and is maintained at this value for 2\nms. The three channels are defined as follows:\n- The two-state voltage-gated channel has a kinetic diagram\nα12\n⇋\nα21\n2 ,\nwhere the rate constants are\nα12 = 4e0.04Vm and α21 = 2e-0.01Vm .\n\n7.5. PROBLEMS\n- The three-state voltage-gated channel has a kinetic diagram\nα12\n⇋\nα21\nα23\n⇋\nα32\n3 ,\nwhere the rate constants are\nα12 = α23 = 4e0.04Vm and α21 = α32 = 2e-0.01Vm .\n- The four-state voltage-gated channel has a kinetic diagram\nα12\n⇋\nα21\nα23\n⇋\nα32\nα34\n⇋\nα43\n4 ,\nwhere the rate constants are\nα12 = α23 = α34 = 4e0.04Vm and α21 = α32 = α43 = 2e-0.01Vm .\nIn exploring the following issues, it is instructive to examine graphs that show\nthe membrane potential as well as both the random variables and mean values or\nprobabilities associated with the record of state occupancies, the conductance,\nand the current through the channel.\na. For each of the channels, make the last state (the state with the highest\nstate number) the conducting state with a conductance of 20 pS and make\nall other states non-conducting.\nCompare the mean conductance of the\ntwo-state, the three-state, and the four-state channels. What can you say\nabout the effect on channel conductance of increasing the number of closed\nstates that precede the open state?\nb. Now consider the four-state channel.\nCompute the mean conductance\nwhen state 1 has a conductance of 20 pS and all other states are non-\nconducting. Repeat this computation except make state 2 the conducting\nstate with all others nonconducting. Repeat again with state 3 and then\nstate 4. Compare the mean conductance for these four conditions. Which\nof these conductances most closely resembles the sodium conductance of\nsquid axon? Explain.\nProblem 7.12 The purpose of this problem is to design a three-state channel that\nactivates and then inactivates. The channel activates at about 0 mV at a rate that\nis three times as fast as it inactivates.\na. Consider a channel that must open before it inactivates, e.g.\nα12\n⇋\nα21\nα23\n⇋\nα32\n3 ,\nwhere both states 1 and 3 are closed and state 2 is open.\nb. Consider a channel that need not open before it inactivates.\n\nCHAPTER 7. VOLTAGE-GATED ION CHANNELS\n\nChapter 8\nPEDAGOGICAL METHODS\n\nCHAPTER 8. PEDAGOGICAL METHODS\n8.1\nIntroduction\nThis chapter describes the pedagogical methods that were developed to teach\ncellular biophysics using the software described in this text.\nThe chapter is\naimed primarily at instructors who wish to use this material in teaching although\nstudents may find the material helpful. The description given here expands that\navailable previously (Weiss et al., 1992).\n8.2\nUses Of The Software\nThe software has become an integral part of teaching cellular biophysics. It is\nused throughout the subject, wherever it can be didactically effective. The soft-\nware is used in lecture to motivate, engage, and inform students. The software is\nhelpful to visualize and to intuit dynamic processes. Use of the software in spe-\ncial classes held in an electronic classroom is an effective way to get students\naway from solving problems by pattern recognition (Mazur, 1997) and forcing\nthem to confront the material in a different way. Use of the software in projects\ncan deepen students understanding of the subject material and can be used to\nteach students how to go about a research project.\n8.2.1\nLectures\nWe have used a lecture room with a large screen (13.6'×18') for projecting a\ncomputer monitor screen. Thus, students are able to see all the interactions of\nthe lecturer with the computer. We have used the software in a variety of ways:\nto help students to visualize concepts, to build intuition, to motivate, and to\nengage the students' intellect. We illustrate some of these techniques.\nSome concepts are grasped instantly when presented graphically. The intu-\nition that results is complementary to that which results from a mathematical\nexposition. The combination of an intuitive, visual grasp of a concept and the\nprecise, abstract mathematical description is powerful. Computer simulations\ncan be especially helpful with building intuition.\nExample 8.1 In the random-walk model of diffusion with an unbi-\nased random walk, each particle moves one step to the left or to the\nright with equal probability; the particle has no preferred direction of\nmotion. Yet a population of diffusing particles tends to move down\nthe particle concentration gradient. Thus, there is an apparent para-\ndox between the undirected motion of individual particles and the\ndirected motion of a population of particles. This apparent paradox\nis resolved in an instant by viewing a population of particles under-\ngoing random walks (Figure 8.1). By watching the simulation, the user\n\n8.2. USES OF THE SOFTWARE\nFigure 8.1: Random walk in two regions. The initial distribution of particles (upper left)\nshows 50 particles in the left region and none in the right region. After 35001 steps,\nthe particles have been dispersed in the two regions (upper right).\nThe number of\nparticles in the right region (lower) zero when the step number is zero and approaches\n25 at a large step number. The rate of increase of particles in the right region is a\nmeasure of the flux of particles from the left to the right regions. This simulation also\ndemonstrates how long it takes for the two regions to come to equilibrium.\n\nCHAPTER 8. PEDAGOGICAL METHODS\ndevelops an intuition for the way in which the random motions of par-\nticles lead to their diffusive spread. Furthermore, this demonstration\nsets the stage for a precise derivation of Fick's first law (which relates\nparticle flux to concentration gradient) starting from a random-walk\nmodel of diffusion (Weiss, 1996a, Section 3.2.1).\nSome models of biological phenomena are difficult to teach not because the\nmathematics is difficult, but because the mathematics is messy with a large num-\nber of parameters. Thus, students can get lost in the notation and in the messi-\nness of the description.\nA software package that allows manipulation of the\nmodel parameters can cut through the messy description and build intuition\nvery quickly to expose the inherent simplicity of the underlying model.\nExample 8.2 Even the simplest models of carrier-mediated transport\ninvolve a number of parameters and several physical processes. In\nour experience in teaching this topic, there is a great tendency for\nstudents to get lost. The derivations of the relations of flux to con-\ncentration are simple, but take some time and do not give a great deal\nof insight into the workings of this class of models. We have found\nthat time spent in lecture using the carrier-mediated transport pack-\nage gives students an immediate intuition into the workings of these\nmodels. Students are then motivated to follow the derivations and to\nappreciate the precise description that results.\nSimulations are especially helpful to motivate students to grapple with con-\ncepts that may be difficult and to foster a sense of intellectual engagement. Prop-\nerly used in lecture, the simulations promote an active participation in learning\nrather than the more passive participation that comes from simply listening to\na lecture (Mazur, 1997). Asking students question in lecture gets them to partic-\nipate intellectually.\nExample 8.3 The simplest diffusion processes result when both par-\nticle flux and concentration are time independent. To motivate stu-\ndents to think about such processes it is helpful to ask them to pre-\ndict the steady-state spatial distribution of particles when the flux is\na constant in space and time. Is the distribution constant? Is it expo-\nnential? Is it Gaussian? After the students have made their guesses\n-- and perhaps after a tally of all the guesses has been made -- the\nsimulation of the random-walk model can be begun with a constant\nsource of particles at one end of a rectangular field and a sink at the\nother. The derivation of the steady-state distribution can proceed on\nthe blackboard while the simulation is in progress. The parameters\nof the simulation can be chosen so that the spatial distribution of\nparticles approaches its steady-state distribution in about the time it\n\n8.2. USES OF THE SOFTWARE\nFigure 8.2: Steady-state distribution for random walks in a single compartment. The\ncompartment was initially empty as shown in the upper left panel and the step size was\nset to 5. There was a source at 0 and a sink at 195. One particle per step was generated\nby the source. After 4001 steps, the particles were distributed as shown in the upper\nright panel with the histogram shown in the lower left panel. Except right near the\nsource, the spatial distribution is linear.\nThe number of particles is plotted versus\nstep number in the lower right panel. The results show that the number of particles is\napproaching a constant for this number of steps indicating that the distribution is near\nits steady-state distribution.\ntakes to complete the derivation. From time to time during the deriva-\ntion, the lecturer can check the progress of the simulation by exam-\nining the dependence of the number of particles in the field on time.\nThis number approaches an asymptotic steady-state value.\nHence,\nthis plot gives a quantitative estimate of whether the spatial distribu-\ntion has reached its steady state (Figure 8.2). When the derivation is\ncomplete and the simulation is complete the two can be compared.\nThis usage of the computer is fun and motivates students to follow\nthe derivation which solves this problem rigorously.\nExample 8.4 Diffusion between two finite compartments through a\nseparating membrane is an important transport process in biological\nsystems. It can model, for example, diffusion between the cytoplasm\nof a cell and the extracellular fluid, across the plasma membrane.\nThere are two important time scales for two-compartment diffusion\nthrough a membrane: the time for the concentration in the membrane\nto reach its steady-state distribution and the time for equilibration of\nthe two compartments. For thin membranes, the spatial distribution\n\nCHAPTER 8. PEDAGOGICAL METHODS\nof concentration in the membrane reaches its steady-state distribu-\ntion much more rapidly than the time it takes the two compartments\nto equilibrate. Thus, it is adequate to relate flux and concentration\nby a steady-state relation even though concentrations in the two com-\npartments are changing in time; a point that can be somewhat tricky\nfor students to understand. This conceptual difficulty is removed if\nthe solution to the two-compartment diffusion problem can be dis-\nplayed for a membrane of arbitrary thickness.\nSimulation experi-\nments make these two time scales clear (Figure 8.3).\nFurthermore,\nthere is a general lesson to be learned about the nature of approxima-\ntions to be made for a system with many kinetic processes, but where\none process is rate-limiting.\nExample 8.5 A defining characteristic of electrically excitable cells is\ntheir sharp threshold for excitation.\nSub-threshold current stimuli\nproduce no action potential; super-threshold currents do. The differ-\nence in current level between sub- and super-threshold stimuli can\nbe very small.\nThe Hodgkin-Huxley model possesses such a sharp\nthreshold which can be demonstrated (Figure 8.4) by showing that a\nsmall increase in a subthreshold stimulus current can result in an ac-\ntion potential. The mathematical basis for the threshold is subtle. We\nhave found that demonstrating the sharp threshold in the Hodgkin-\nHuxley model in a dramatic fashion will motivate students to exam-\nine the mathematical basis of sharp thresholds in such differential\nequations (Weiss, 1996b, Section 4.4.1). By preparing in advance, the\nthreshold can be bracketed so that an increase of one unit in the\nleast significant digit changes a sub-threshold stimulus to a supra-\nthreshold stimulus. This raises the student's curiosity about the na-\nture of a threshold in a differential equation and motivates them to\nfollow the lecture devoted to this property.\nAnother use of computers in lecture is to perform \"What if\" experiments as\na way to build intuition. A typical and obvious use is to ask the class to pre-\ndict what will happen if some system under study is perturbed in some way.\nThis type of \"audience participation\" breaks the formality of the lecture, puts\nstudents at ease, and engages their intellect. A simulation can be run and the\noutcome of the experiment can be obtained instantly. There is then an opportu-\nnity to discuss the relation between the outcome of the simulation experiment\nand the students' expectations. Changing almost any parameter of any of the\nsimulations can lead to valuable discussions and deeper insights.\nExample 8.6 Suppose we have two solutes that can bind to a trans-\nporter in a chemically-mediated transport mechanism. What if ... we\nchange the dissociation constant for the second solute on the inside\n\n8.2. USES OF THE SOFTWARE\nFigure 8.3: Time constants in two-compartment diffusion. The left bath initial concen-\ntration was 10 μmol/cm3 with a width of 0.5 cm; the right bath initial concentration\nwas 5 μmol/cm3 with a width of 1 cm; the membrane width was 0.01 cm and the ini-\ntial concentration was drawn as shown in the upper left plot. The upper three plots\nshow the spatial distribution of concentration (membrane view with a bit of each bath\non each side) at three times: 0, which shows the initial distribution; 15 seconds, which\nshows the distribution is linear in the membrane but the two baths are not equilibrated;\n3705 seconds, which shows the baths and membrane near equilibration. The lower two\nplots show the concentration as a function of time. The left plot vs. time shows the\nconcentration as a function of time in the left bath and for a point in the membrane.\nThe concentration in the membrane has not changed appreciably over a time span for\nwhich the concentration in the membrane has nearly reached steady-state. The right\nplot shows the concentration as a function of time in the two baths over a time scale\nthat shows the concentration equilibrating.\n\nCHAPTER 8. PEDAGOGICAL METHODS\nFigure 8.4:\nThe threshold for\neliciting\nan\naction\npotential\nin the Hodgkin-Huxley model.\nThe stimulus is a current pulse\nof 1 ms duration;\nthe sub-\nthreshold amplitude is 14.3820\nand the suprathreshold ampli-\ntude is 14.3821 μA/cm2.\nof the membrane?\nHow will the fluxes of the first and second so-\nlutes change? How will the fraction of transporters bound to the first\nand second solutes on the inside of the membrane change? How will\nthe fraction of transporters bound to the first and second solutes on\nthe outside of the membrane change? Such questions are answered\nquickly by use of the chemically-mediated transport package and the\nanswers invite further discussion.\nAs will be described in further detail below, lectures can also be used to\nperform a research project live with audience participation. Thus, the lecturer\nand the students are working on the project together. This lends a quite different\natmosphere to lectures.\nThe uses of computation described above have become integral, and now\nessential, parts of lectures and are performed live in the lecture room. It has\nproved both an effective and an enjoyable part of teaching and learning.\n8.2.2\nElectronic classroom and homework problems\nWe hold several classes in an \"electronic classroom\" in which each student has\naccess to a computer workstation and is free to work either from prepared home-\nwork problems or in a self-directed manner. We have found that most students\nprefer to work on the homework problems and only a few will work indepen-\ndently. Some students finish that portion of the homework assignment in the\nsession in the electronic classroom.\nOthers start on the problems and finish\nthem at a later date.\n\n8.2. USES OF THE SOFTWARE\nStudents and staffmembers work together in this setting. The objective is\nfor everyone to arrive at the solution to the problems, each of which is chosen\nto illustrate some important issue in the subject matter. This mode of work is\nnoncompetitive, cooperative, and self-paced. It also provides a good opportunity\nfor students and staffto interact in a more informal setting than is possible in a\nlecture or a recitation.\nSome of the problems we have frequently assigned for homework and used\nsuccessfully in an electronic classroom are described below.\nExample 8.7 In connection with two-compartment diffusion, we use\nProblem 3.4 to make sure students understand the difference between\nthe time constant to reach steady state in a membrane and the time\nconstant to reach equilibrium between the two baths that are sepa-\nrated by the membrane (see Example 8.4).\nExample 8.8 We often assign Problem 4.1 to give students some feel-\ning for the relation between flux and concentrations for the simple,\nsymmetric, four-state carrier model. This is the simplest of the mod-\nels for carrier-mediated transport through membranes and it is a\nstepping stone for understanding more complex models.\nExample 8.9 The Hodgkin-Huxley model is difficult for undergrad-\nuate students to comprehend.\nTherefore, we start students think-\ning about the model in the voltage-clamp configuration by assigning\nProblem 5.1. Part a is straightforward but part b requires that stu-\ndents perform simulations iteratively to arrive at a solution.\nThey\nlearn about the interaction of activation and inactivation to yield the\nsodium conductance in a voltage-clamp configuration.\nExample 8.10 We usually assign one part of Problem 5.11 to get stu-\ndents thinking about the Hodgkin-Huxley model in the current-clamp\nconfiguration. The assignment is in the form of a puzzle. Students\nenjoy the challenge of figuring out the puzzle. With a set of default\nmodel parameters and stimulus current parameters, the Hodgkin-\nHuxley model gives rise to an action potential. A change in one of\nmany different parameters of this model leads to no action potential\nin response to the same current stimulus. Students are given prob-\nlems in each of which one parameter (e.g., temperature, membrane\ncapacitance, an ion conductance, and ion concentration) has been\nchanged to block the occurrence of the action potential. Students are\nasked to find a compensatory change in parameters that will restore\nthe action potential to be identical (within certain bounds) to that\nobtained with the default parameters. This type of problem forces\nstudents to examine the interactions of internal model variables in a\ncritical manner.\n\nCHAPTER 8. PEDAGOGICAL METHODS\nExample 8.11 Understanding the kinetic behavior of single channels\nis challenging for students.\nWe usually assign Problem 7.1, which\ndeals with a two-state channel that is not voltage gated, and Prob-\nlem 7.2, which deals with a two-state channel that is voltage gated.\nBoth of these problems ask students to design a channel that opens\nat a particular value of the membrane potential and has prescribed ki-\nnetic properties. Students learn about the differences between voltage-\ngated and ungated channels. Also, these problems exercise the stu-\ndents' intellect in a very different manner than do the traditional\nproblem sets that are a routine part of homework assignments. In\na traditional homework assignment, students are asked to analyze\nproblems that are completely defined. The software problems can be\nless well defined so that the definition of the problem is part of the\nassignment.\n8.2.3\nProjects\nWe have found it educationally effective to require that students complete a\nproject of their choice using the Hodgkin-Huxley model software. The exercise\naffords students an opportunity to formulate a hypothesis about a theoretical\ntopic, to write a proposal, to test the hypothesis, to reach a conclusion, and\nto communicate their results in writing. Although these projects can be quite\ntime consuming (for both students and faculty), they have been very popular\nwith the vast majority of students. For many of the students, this is the first\nlearning activity that has the flavor of a research project.\nTo emphasize the\nimportance of this educational activity, performance on the project is graded\nand accounts for 15% of the grade in the subject, a percentage that is comparable\nto the importance of one of the examinations in the subject.\nDuring one semester when enrollment in the subject was unusually high, it\nwas necessary to pair up students to make the management of projects accept-\nable.1 Perhaps not surprisingly, we found that the quality of the work seemed\nto improve. Thus, we have asked students to work in teams of two ever since\nalthough we do not require it.\nWe also found that as the years went by, reports got longer and longer. Thus,\nto encourage the students to be concise we placed limits on the lengths of report.\nWe give the following instructions to students about the rules for the project.\n\"Students may do projects individually or in pairs. If a pair of stu-\ndents collaborate on a project they should submit a single proposal\nand a single report which identifies both members of the team and\ngives both email addresses.\nProposals will be returned as soon as\n1Interacting with students to help them write acceptable proposals and to conduct these\nprojects takes considerable time. Assessing a single final project report takes over one hour.\n\n8.2. USES OF THE SOFTWARE\npossible so that students may revise them. Only the final, accepted\nproposal will be given a grade.\nThe demonstration project performed in lecture cannot be the basis\nof a student project. The report should be at most 10 pages of text\nand at most 10 figures and tables.\"\nWe describe the steps involved in the project in detail.\nThe proposal\nStudents are required to write a proposal, which must be approved before they\nstart the project. Sometimes students write as many as 4 proposals before an\nadequate project is defined. Interestingly, the impetus for rewriting proposals\ncomes as often from the student wanting to get it right as it does from the in-\nstructor. The main task for the instructor is to help students to define a project\nthat is challenging but still feasible taking into account the student's interests\nand knowledge. The project involves formulating and testing a hypothesis about\nsome property of the Hodgkin-Huxley model, preferably one that has physiologi-\ncal significance. It is desirable, although not necessary, that students read papers\nin the literature concerning their topic.\nStudents are given the following instructions:\n\"The proposal should contain a brief statement of the hypothesis you\npropose to test, as well as your proposed method of procedure. In-\nclude a list of the computations you will perform and the measure-\nments you plan to make. Indicate how the measurements will be used\nto help you come to a conclusion. The proposal should be written on\none 8 1/2 × 11 sheet of paper. A sample proposal is shown in Fig-\nure 8.5.\"\nDemonstration project\nWe have found it helpful to give a one-hour lecture on how to do a research\nproject, by doing a project live in the lecture room. An acceptable proposal for\nthe project is distributed at the beginning of the lecture (such as the one in Fig-\nure 8.5). The lecture involves two members of the instructional staffwho act as\na student pair working on a project. To make it run smoothly, the staffmem-\nbers rehearse briefly. Simulations are performed in front of the class and the\ntwo instructors argue about what is to be done next and on how to interpret the\nresults. They worry out loud about their grade on the project, etc. The project\nis chosen so that results obtained in an initial range of parameters are plausible\nand simple to interpret, but something unexpected happens when the parameter\nis outside this range. One project that has been used successfully is based on\n\nCHAPTER 8. PEDAGOGICAL METHODS\nPROPOSAL: HODGKIN-HUXLEY MODEL PROJECT\n- Name: Hy I.Q. Student\n- Email address: hiqstudent\n- Hypothesis: The difference in observed action potential shape between\nthe giant axon of the squid and the node of Ranvier of the rat is due to a\ndifference in temperature.\n- Background: The rate constants that determine the variables m, n, and\nh in the Hodgkin-Huxley model increase as the temperature is increased.\nHence, I would expect that with increased temperature the time course\nof the action potential would be briefer.\nThe observed action potential\nof the rat node of Ranvier measured at 37*C. is briefer than the action\npotential of the squid giant axon measured at 16*C. Hence, I will determine\nwhether this difference in temperature is adequate to explain the difference\nin action-potential waveform. In this study, I will assume that the Hodgkin-\nHuxley model accounts for action potentials in both preparations. Since the\nintracellular and extracellular ionic concentrations of sodium, potassium\nand calcium also differ in these two preparations, if time permits I will also\ninvestigate the effect of this difference.\n- Procedure: I will obtain the intracellular and extracellular concentrations\nof sodium and potassium ions for the rat node of Ranvier from the liter-\nature. I will perform a series of simulation studies with a single pulse of\nmembrane current whose amplitude will be set at a constant suprathresh-\nold value. I propose the following series of simulations\n#\nTemp.\nIon Concentrations\n*C\ndefault values for squid giant axon\ndefault values for squid giant axon\nvalues found for rat node\nvalues found for rat node\nThe waveforms of the action potentials obtained under the various condi-\ntions will be compared on the graphics display and the summary statistics\nfor each condition will be examined. If condition 4 yields an action poten-\ntial that resembles that which is measured on the rat node of Ranvier, then\nthe hypothesis will be supported by these calculations. If they differ, then\nI will investigate the bases of the differences.\nFigure 8.5: Sample proposal for a project.\n\n8.2. USES OF THE SOFTWARE\nthe hypothesis \"Increasing the temperature increases the rate of change of the\naction potential at its onset.\" Simulations are performed first for a range of tem-\nperature that support this hypothesis. Using the blackboard, one member of the\nstaffplots the maximum rate of change of the potential (obtained conveniently\nby measuring the peak of the capacitance current) for each temperature after\neach simulation is performed. However, at a sufficiently high temperature, the\naction potential is blocked. The staffmembers argue about whether to ignore\nthis effect or to go on and to confront this unexpected finding. They consider the\npossibility that they have found a bug in the software or that this phenomenon\nresults from problems of numerical integration. By performing further simula-\ntion experiments, it is made clear that these explanations are not plausible. The\ninstructors propose various circular arguments of the type students frequently\npropose. \"The action potential is blocked because the sodium conductance is\nsmall.\" Of course, the sodium conductance depends upon the membrane poten-\ntial. Hence, the sodium conductance is small because the membrane potential\nis small. Pursuit of this circular argument (on which some students get stuck\neach year in their own projects) can have the class in hysterics. In any case, the\nanalysis of the basis of thermal block now becomes the focus of the project.\nSimulation experiments performed for small changes in temperature below the\ntemperature at which the action potential is blocked, reveals the interplay of\nkinetic processes that result in thermal block. Since these same processes are\ninvolved in the excitation of the action potential, the analysis can give great\ninsight into the mechanism of initiation of an action potential (Weiss, 1996b,\nSection 4.4.8).\nThe computations\nStudents are given the following instructions on how to perform the computa-\ntions.\n\"After carefully defining the computations needed to determine the\nvalidity of your hypothesis, you should perform the necessary com-\nputations. You should keep careful track of the computations you\nperform by entering relevant information in a notebook. The note-\nbook should indicate the date of each computational session as well\nas the identity of the computer you used (make and model). Keep\nan accurate record of each computation so that you can reconstruct\nwhat you did at a later date. Save your results in files. Make com-\nposite plots to summarize a series of measurements. For example, to\nshow the effect on the action potential of some parameter, plot the\naction potentials for selected values of the parameter on one set of\naxes. Arrange you work so that you have time for some final com-\nputations after you begin writing the report. You may find that new\nquestions will arise as you write the report. If you leave adequate\n\nCHAPTER 8. PEDAGOGICAL METHODS\ntime, you may be able to resolve these questions.\"\nThe report\nMany undergraduate students have never read a scientific paper and do not\nknow how to write a project report. Hence, we devised the following descrip-\ntion of the report.\n\"The Project Report is an opportunity for you to work on your ability\nto express yourself concisely. Do not repeat material that is easily\nreferenced. For example, there is no need to reproduce any figure\nfrom readily-available texts: simply refer to it. Technical writing is\nnecessarily directed at some particular intended audience. Write the\nProject Report as though it were to be published in a journal that is\nread primarily by students who have taken this subject. Thus, you\nmay assume that your audience has some working knowledge about\nthe subject matter, but no detailed knowledge of your specific project.\nThe Project Report should contain the following sections.\nCover Page. On the cover page include the title of the project and the\nauthor's/authors' names, and the date.\nAbstract. The abstract is a one paragraph (< 100 words) summary\nof the report including the hypothesis investigated, the methods\nused, and the principal results and conclusions.\nThis section\nshould be written last.\nIntroduction. This is a brief section (about 1 page) designed to mo-\ntivate the reader to read your report. Include background infor-\nmation on the problem, hypotheses to be tested, significance of\nthe work, etc. You may give citations to texts where appropri-\nate. The introduction should be directly relevant to your report\nand should not discuss neurophysiology or the brain in general\nterms.\nMethods. Explain any methodological or procedural issues that are\nnot obvious. For example, if you measured the time of the peak\nof the action potential as a function of some parameter, explain\nhow you measured the time of the peak and how you defined\nwhen an action potential occurred, i.e., how did you separate the\naction potential from the local response.\nResults. Describe your computational results (whether or not they fit\nwith expectations) in the results section. Generally, results can\nbe communicated more efficiently and accurately with pictures,\ngraphs, and tables than with words alone (e.g., see Figures 5.16,\n5.18, 5.19, and 8.4).\nHowever, a collection of printed graphs\n\n8.2. USES OF THE SOFTWARE\nwithout a written description of their relevance is unacceptable\nas a Results section. Students frequently err on the side of in-\ncluding a large number of graphs and little description of their\nrelevance. The Results section should be organized to lead the\nreader through a logical sequence of results that terminates inex-\norably in a conclusion. Your objective is to construct an airtight\ncase for some conclusion whether or not it supports or rejects\nyour original hypothesis. This is not the place to interpret or to\ndiscuss the results.\nDiscussion and conclusions. State your conclusions concisely and point\nout how your results support your conclusions. You might also\nsuggest additional computations to further test your hypothesis.\nYour conclusions and discussion should be focussed on the re-\nlation between your results and your hypothesis. The discussion\nsection can include relevant speculations.\nAppendix. The appendix should include a copy of the protocol taken\nduring the computational sessions.\"\nGrade for the project\nGrading of the project reports has evolved since its inception in 1984. After\nusing these project for a few years, we noted that many, but still less than a\nmajority, of the projects focussed on a relatively small number of topics. The\nquality of these reports also improved markedly with time.\nWe felt that the\ngraded reports from previous years were available through student archives. To\nencourage students to choose new topics and to reward originality we added\nan assessment for originality. In addition, we found that a hard deadline for\naccepting reports was hard to enforce so we made the deadline somewhat soft\nassessing a numerical penalty for lateness by a formula that the students knew\nahead of time. The following grading scheme has emerged by trial and error and\nis satisfactory.\n\"The grade will not depend on whether the project was an individual\nor a team project. Both members of the team will get the same grade\non the project. The grade for the computer project will be based on\nthe proposal and on the report using the following criteria:\nProposal (10%) The proposal should be concise and clearly define the\nproject in the form of a hypothesis.\nIt should include a brief\ndescription of the methods to be employed. A late proposal will\nget a grade of 0.\nReport Structure (15%) All the sections of the report should be present\nand each should contain the relevant information.\n\nCHAPTER 8. PEDAGOGICAL METHODS\nClarity/Conciseness (20%) A good report is easy to read. The con-\ntent of each paragraph and each graph should be clear. Every-\nthing included in the report should be there for a reason. Points\nwill be deducted for extraneous material such as a large number\nof graphs without explanation in the text.\nConceptual Correctness (30%) Correctness will be judged by the an-\nswers to several questions. Are there clear conceptual errors?\nAre the results confused? Are the results (i.e. which follow di-\nrectly from the simulations) confused with the interpretations\n(which rely on information other than the simulations)?\nOriginality (25%) This grade will assess the degree of difficulty, nov-\nelty, and imagination of the project. The simpler projects, such\nas many of those suggested in Section 5.6 and used by many\nstudents in the past, will receive ≤10%, more intellectually chal-\nlenging, novel projects will receive 25%.\nReports that are not turned in on time will be penalized by the follow-\ning formula -- the grade of the report will be multiplied by a lateness\nfactor L, where L = 0.3e-t/4 + 0.7e-t/72 and t is the number of hours\nlate.\"\nElectronic interactions\nStudents are invited to interact with the teaching staffvia electronic mail. This\nhas been an increasingly effective means of teaching and learning. For example,\nsome students prefer to submit proposals for projects electronically. The staff\nresponds to these electronically, sometimes within minutes but certainly by the\nnext morning. The rapid turnaround time between submission, critique, and re-\nsubmission can make writing an acceptable proposal, which some students find\nchallenging, more efficient. Students use electronic messages to seek help on\nindependent projects as they are conducting them. They send queries electron-\nically and receive responses electronically.\nThis type of interaction, in which\nthe individuals involved may be located at opposite ends of the campus, is an\neffective way to achieve individualized instruction.\n8.3\nAssessment\n8.3.1\nCost of development\nWe estimate that it has taken about 5 person-years to develop the software.\nAlthough harder to estimate, it has taken perhaps an additional person year of\nfaculty time to design software packages, thoroughly test each software package,\n\n8.3. ASSESSMENT\ndesign problems and projects, write documentation, and to investigate pedagog-\nical methods.\n8.3.2\nExtent of software usage\nOur use of the software in teaching has increased over the years. Our current\nusage is summarized as follows: There are 37 lectures (classes attended by all\nthe students simultaneously) in the subject and the software is used in about\n8-10 lectures. There are 24 recitations (classes attended by students in groups\nof about 25) and the software has not been used in any of these; in part due\nto the lack of availability of appropriate classrooms with network connections\nin the past. This has now been rectified and we expect in the future to use the\nsoftware routinely in recitation classes. Several recitations devoted to using the\nsoftware are held in electronic classrooms. Typically, there are 13 problem sets\nassigned during a semester; five or six problem sets include parts that involve\nthe software. There is one laboratory session, which requires a formal laboratory\nreport but does not involve the software. There is one project that involves the\nsoftware which requires a formal report. There are about 9 short quizzes and\ntwo long examinations; none use the software.\nThis assessment shows that use of the software represents a small but appre-\nciable fraction of the teaching and learning in this subject. Since we have found\nthat use of the software is labor intensive both for the staffand the students, we\nhave been reluctant to increase the use of the software.\n8.3.3\nInformal assessment of impact on learning\nWe have not conducted a careful experiment with controlled groups to test ob-\njectively the effectiveness of the software in promoting students' comprehen-\nsion of the material. Subjectively, it was clear at the outset that the students\nenjoyed using the software and that the stafffelt that use of the software was\npedagogically effective.\nThus, it did not seem fair to exclude some students\nfrom the software for the sake of conducting a scientific experiment. Surveys of\nstudent opinions on the efficacy of the software have been predominantly very\npositive with opinions ranging from those who thought we should develop soft-\nware packages for every topic in the subject to a few who found the software\nconfusing. Each year, several students make valuable suggestions on software\nimprovements or on methods for software use. These student inputs have been\nimportant for the evolution of the software. This subject matter was taught for\n20 years before the software became available and for 15 years after it became\navailable. The staffhas little doubt that students learn the material more effi-\nciently and to a greater depth with the use of the software than they had before\nthe software became available.\n\nCHAPTER 8. PEDAGOGICAL METHODS\nThere are other signs of student interest in the software. Students clearly\nenjoy working on the software, especially on their own projects, despite the\ngreat effort that is required. The impressions of the staffare that while most\nstudents get some benefit from using the software, the very best students have\nan experience that most resembles a small research project. This can be seen\nin the reports students write to complete their projects. Some of these reports\nresemble undergraduate theses in scope and in content. Another indication of\nstudent interest is that several students have written software on their personal\ncomputers to emulate some of the software we have provided. This was done\njust for their own interest. There is a final and most important indication of\nstudent interest.\nAs a result of using the software in this subject, students\nhave been interested to work on the development of educational software. Since\n1984, nine undergraduate and three graduate students have been involved in\nthis effort. They have written all the software packages.\n8.3.4\nSurveys and focus groups\nSince 1984, surveys of students who have used the software have been con-\nducted routinely. Sometimes these surveys were done at the end of the semester\nand sometimes immediately after students completed an assignment that in-\nvolved the software. Surveys were done by having students fill out forms as well\nas via email. In recent years, an independent evaluator conducted the surveys\nand ran focus groups. The feedback we have received has been valuable and\nhas helped us focus on problems students were having with the software. In\ngeneral, assessments of student have been very positive. Most students find the\nsoftware pedagogically effective and some find the software critical to under-\nstanding complex topics such as the Hodgkin-Huxley model. Students felt they\nreceived the most educational benefit from those software packages with which\nthey spent the most time. In particular, the projects were universally praised as\neducationally effective.\n8.3.5\nImpact on teaching\nIt has often been assumed that one benefit of the use of computers in teaching\nis to conserve faculty time, and that a cost was isolation of students from each\nother and from the faculty.\nIn our experience, neither the presumed benefit\nnor the cost have materialized. Our use of computers in teaching has increased\ncontact between students and faculty and among students. The main benefit has\nbeen more effective teaching and learning. The main cost has been an increased\nwork load for both students and faculty.\n\n8.4. CONCLUSIONS\n8.4\nConclusions\nWe have used computers to teach biophysics and physiology since 1984. Our use\nhas been exclusively to develop software that simulates some physical, chemi-\ncal, and biological process that is reasonably well understood. We have invented\nno new models, but we have explored extant models that underlie our under-\nstanding of transport and electrical processes in cells. In teaching this material,\nwe have learned some lessons -- both pedagogical and practical -- which are\nsummarized below.\n8.4.1\nPedagogical matters\nDevelopment of educational software must be driven by pedagogy\nWe have evolved a simple strategy for educational software development. We\nidentify important topics in biophysics and physiology that pose some concep-\ntual difficulties for students and examine whether comprehension could be im-\nproved by the use of computational methods. Once we identify such topics, we\ndesign and then implement the software.\nSoftware complements other pedagogical vehicles\nSoftware cannot replace a good lecturer or an incisive derivation in a lucid text-\nbook. A simulated experiment cannot replace a real laboratory experience. How-\never, software represents an additional pedagogic vehicle that can, if appropri-\nately used, complement other vehicles.\nStudents should have access to the software\nWhile lecture demonstrations can be pedagogically effective, the potential for\nlearning is greatly enhanced when students use the software themselves. The\neducational benefits of student usage of the software as opposed to exposure to\nit in lecture are similar to the benefits derived when students solve problems in\nhomework as opposed to watching a problem solved in class.\nThe software must be integrated into the subject\nThe software should be an integral part of lectures, recitations and homework\nand used only where it enhances learning and never used simply because it is\navailable and because the staffhas invested a great effort in its production. Soft-\nware homework and projects must be assigned and graded with the grade con-\ntributing to the student's grade in the subject. If the grades on software assign-\nments do not count toward the student's final grade in the subject, the student\n\nCHAPTER 8. PEDAGOGICAL METHODS\nwill correctly conclude that the software is secondary in importance to those\nassignments that do count toward the final grade.\nThe software should have layers of complexity\nStudents approach the software with different levels of sophistication in their\nunderstanding of the subject matter. It is essential to devise the software so\nthat all students can receive some educational benefit. This requires that the\nsoftware be simple to use at the outset but contain sufficient depth to challenge\nthe more sophisticated students and even the staff.\n8.4.2\nPractical matters\nEven slightly flawed software should be avoided\nThe software must aid students to learn the material and should not impede\nthat objective. Software with flaws, even minor flaws, is a distraction. Students\nwill remember even a minor flaw in the software and will forget the point of the\ndemonstration. Undergraduate students, in particular, will lose confidence in an\nassignment that involves software with even inconsequential flaws. Since they\nare quite busy, it is easy to rationalize avoiding a difficult assignment by report-\ning that the software doesn't work even if the flaws should not distract them\nfrom the main point of the assignment. The more mature graduate students\nseem more tolerant of minor flaws and are willing to endure them to derive ed-\nucational benefit. But bugs, no matter how minor, should be avoided so that\nstudents can concentrate fully on the didactic material.\nExpect some complications\nA computer in the classroom increases the range of pedagogical tools available\nto the instructor. But it also complicates the instructor's task. If the instructor\nis prepared and competent and both a blackboard and chalk are available, not\nmuch can go wrong with a lecture. With a computer in the classroom, things can\ngo wrong although the number of episodes has actually been extremely low. It\nis necessary to be prepared for the possibility of a computer problem so that\nvaluable class time is not lost. The availability of overhead transparencies that\ncover the relevant material that would have been covered with the computer is a\ngood backup strategy.\nDesign of the user interface is critical\nMost of our time spent in software development is devoted to the design of user\ninterfaces that allow students to focus on the subject material and avoid arcane\n\"computerese\". A great deal of the students' time can be conserved if the user\n\n8.4. CONCLUSIONS\ninterface is graphic, intuitive, and common to all the software. The user interface\ncannot be too transparent!\nGood documentation is important\nWe have placed a great deal of emphasis on writing comprehensive documenta-\ntion for all the software. The documentation gives some background informa-\ntion on the subject matter and contains a detailed user's manual for the software\nplus a list of suggested problems and projects. Remarkably, some students learn\nto use the software by reading the manual; others experiment with the software.\nThere are different learning styles for using software.\nTo reach a maximum\nnumber of students, a variety of modalities are helpful.\nDevelopment of good educational software is time-consuming and iterative\nAll our successful packages have been rewritten many times in response to staff\nand student input. There is no shortcut to the development of good educational\nsoftware.\nUse of educational software increases contact with students\nEarly advocates of the use of computers in teaching suggested that one benefit\nwas a saving in faculty time. Effective use of computers could replace faculty\nin certain tasks. Some educational theorists worried about the isolation of stu-\ndent from faculty resulting from this use of computers. Our experience with\nour method of use of computers has given the opposite result. It has greatly in-\ncreased contact with students to the mutual advantage of students and faculty;\nthe interactions have been very rewarding.\nMaintenance of software\nChanges in operating systems or in higher level languages on which the soft-\nware is based will continue to require some maintenance. In addition, student\nsuggestions can help to improve the software if the resources for maintenance\nare available.\nProjection systems\nProjection systems for use of computers in the classroom have until quite re-\ncently been only marginally adequate.\nHowever, the technology is improving\nrapidly and the cost is decreasing rapidly as well. However, this is not a place\nto skimp. An inadequate display system, where the students cannot really see\nwhat is being depicted, defeats all the effort required to develop the software.\n\nCHAPTER 8. PEDAGOGICAL METHODS\n8.4.3\nBottom line\nOur experience indicates that the development, usage, and maintenance of a suc-\ncessful educational software package is a difficult and time-consuming process\n-- several iterations have been required to bring our most successful packages to\ntheir current level of performance. However, we have also found that computers\nare a powerful vehicle for teaching. They can be used to: engage the student's\nintellect, to motivate learning, to allow students to test their understanding of\na topic, to make learning self-paced and fun. With the aid of software, students\ntake intellectual ownership of a topic rather than experiencing it vicariously.\nOnce effective software has been used in teaching and learning, it becomes an\nindispensable tool.\n\nBibliography\nAidley, D. J. (1989). The Physiology of Excitable Cells. Cambridge University\nPress, Cambridge, Great Britain.\nArmstrong, C. M. (1966). Time course of TEA+-induced anomalous rectification\nin squid giant axons. J. Gen. Physiol., 50:491-503.\nArmstrong, C. M. and Binstock, L. (1965). Anomalous rectification in the squid\ngiant axon injected with tetraethylammonium chloride. J. Gen. Physiol., 48:859-\n872.\nAthena (1990a). Computation and Educational Community: A Background Pa-\nper.\nCommittee on Academic Computation for the 1990s and Beyond, Mas-\nsachusetts Institute of Technology.\nAthena (1990b). Computing for Education at MIT: Final Report. Committee on\nAcademic Computation for the 1990s and Beyond, Massachusetts Institute of\nTechnology.\nBaker, P. F., Hodgkin, A. L., and Shaw, T. I. (1961). Replacement of the proto-\nplasm of a giant nerve fibre with artificial solutions. Nature, 190:885-887.\nBalestri, D. (1988). Ivory towers, silicon basements. Infor. Tech. Quaterly, 7:5-\n17.\nBerkenblit, S. I. (1990). Design of a software diffusion simulator and analysis\nof a problem in two-compartment diffusion.\nMaster's thesis, Massachusetts\nInstitute of Technology, Cambridge, MA.\nCarruthers, A. (1984). Sugar transport in animal cells: The passive hexose trans-\nfer system. Prog. Biophys. Mol. Biol., 43:33-69.\nChapman, R. A. (1967). Dependence on temperature of the conduction velocity\nof the action potential of the squid giant axon. J. Physiol., 213:1143-1144.\nColquhoun, D. and Hawkes, A. G. (1977). Relaxation and fluctuations of mem-\nbrane currents that flow through drug-operated channels. Proc. R. Soc. London,\nSer. B, 199:231-262.\n\nBIBLIOGRAPHY\nColquhoun, D. and Hawkes, A. G. (1995a). The principles of the stochastic in-\nterpretation of ion-channel mechanisms. In Sakmann, B. and Neher, E., editors,\nSingle-Channel Recording, pages 397-482. Plenum Press, New York, NY.\nColquhoun, D. and Hawkes, A. G. (1995b). A Q-matrix cookbook. How to write\nonly one program to calculate the single-channel and macroscopic predictions\nfor any kinetic mechanism.\nIn Sakmann, B. and Neher, E., editors, Single-\nChannel Recording, pages 589-633. Plenum Press, New York, NY.\nCooley, J. W. and Dodge, F. A. (1966). Digital computer solutions for excitation\nand propagation of the nerve impulse. Biophys. J., 6:583-599.\nCox, D. R. and Miller, H. D. (1965). The Theory of Stochastic Processes. John\nWiley and Sons, New York, NY.\nEaston, D. M. and Swenberg, C. E. (1975). Temperature and impulse velocity in\ngiant axon of squid loligo pealei. Am. J. Physiol., 229:1249-1253.\nEinstein, A. (1906). Sur theorie der brownschen bewegung. Ann. Physik, 19:371-\n381. [For translation see Einstein (1956)].\nEinstein, A. (1956).\nInvestigations on the Theory of the Brownian Movement.\nDover Publications. R. Furthe and A. D. Cowper, eds. [Translation of original\npublications].\nFick, A. (1855). On liquid diffusion. Philos. Mag., 10:30-39.\nFitzhugh, R. and Antosiewicz, H. A. (1959). Automatic computation of nerve\nexcitation -- detailed corrections and additions.\nJ. Soc. Indust. Appl. Math.,\n7:447-458.\nFrankenhaeuser, B. and Hodgkin, A. L. (1957). The action of calcium on the\nelectrical properties of squid axons. J. Physiol., 137:218-244.\nGeorge, S. A., Mastronarde, D. N., and Dubin, M. W. (1984). Prior activity in-\nfluences the velocity of impulses in frog and cat optic nerve fibers. Brain Res,\n304:121-126.\nGerald, C. F. and Wheatley, P. O. (1989). Applied Numerical Analysis. Addison-\nWesley, Reading, MA.\nHanselman and Littlefield (1997). Mastering MATLAB 5: A Comprehensive Tu-\ntorial and Reference. Prentice-Hall, Englewood Hills, NJ.\nHille, B. (1992). Ionic Channels of Excitable Membranes. Sinauer Associates Inc.,\nSunderland, MA.\n\nBIBLIOGRAPHY\nHines, M. (1984).\nEfficient computation of branched nerve equations.\nInt. J.\nBio-Med. Comput., 15:69-76.\nHines, M. and Carnevale, N. T. (1998). Computer modeling mehtods for neurons.\nIn Arbib, M. A., editor, The Handbook of Brain Theory and Neural Networks,\npages 226-230. MIT Press, Cambridge, MA.\nHodgkin, A. L. (1964).\nThe Conduction of the Nervous Impulse.\nCharles C.\nThomas, Springfield, IL.\nHodgkin, A. L. (1977). Chance and design in electrophysiology: An informal\naccount of certain experiments on nerve carried out between 1934 and 1952.\nIn The Pursuit of Nature, pages 1-21. Cambridge University Press, Cambridge,\nEngland.\nHodgkin, A. L. and Huxley, A. F. (1952). A quantitative description of membrane\ncurrent and its application to conduction and excitation in nerve. J. Physiol.,\n117:500-544.\nHodgkin, A. L. and Katz, B. (1949a). The effect of sodium ions on the electrical\nactivity of the giant axon of the squid. J. Physiol., 108:37-77.\nHodgkin, A. L. and Katz, B. (1949b). The effect of temperature on the electrical\nactivity of the giant axon of the squid. J. Physiol., 109:240-249.\nHuxley, A. F. (1959). Ion movements during nerve activity. Ann. N.Y. Acad. Sci.,\n81:221-246.\nHuxley, A. F. (1964). Excitation and conduction in nerve: Quantitative analysis.\nSci., 145:1154-1159.\nJohnston, D. and Wu, S. M. S. (1995). Foundations of Cellular Neurophysiology.\nMIT Press, Cambridge, MA.\nJoyner, R. W., Westerfield, M., Moore, J. W., and Stockbridge, N. (1978). A nu-\nmerical method to model excitable cells. Biophys. J., 22:155-170.\nKandel, E. R., Schwartz, J. H., and Jessell, T. M. (1991).\nPrinciples of Neural\nScience. Elsevier, New York, NY.\nKatz, B. (1966). Nerve, Muscle and Synapse. McGraw-Hill Inc., New York, NY.\nKeynes, R. D. and Aidley, D. J. (1991). Nerve and Muscle. Cambridge University\nPress, Cambridge, Great Britain.\nKulik, C. C. and Kulik, J. A. (1986). Effectiveness of computer-based education\nin colleges. AEDS J., pages 81-108.\n\nBIBLIOGRAPHY\nMascagni, M. V. and Sherman, A. S. (1998). Numerical methods and neuronal\nmodeling.\nIn Koch, C. and Segev, I., editors, Methods in Neuronal Modeling,\npages 569-606. MIT Press, Cambridge, MA.\nMazur, E. (1997). Peer Instruction: A User's Manual. Prentice Hall, Upper Saddle\nRiver, NJ.\nMoore, J. W., Ramon, F., and Joyner, R. W. (1975). Axon voltage-clamp simula-\ntions. Biophys. J., pages 11-24.\nNeher, E. and Sakmann, B. (1976). Single-channel currents recorded from mem-\nbrane of denervated frog muscle fibres. Nature, 260:799-802.\nNicholls, J. G., Martin, A. R., and Wallace, B. G. (1992). From Neuron to Brain: A\nCellular and Molecular Approach to the Function of the Nervous System. Sinauer\nAssociates, Sunderland, MA.\nPearlmutter, B. A. and Zador, A. (1999). Sparse matrix methods for modeling\nsingle neurons. In Koch, C., editor, Biophysics of Computation, pages 487-502.\nOxford Univ. Press, New York, NY.\nPlonsey, R. and Barr, R. C. (1988).\nBioelectricity, A Quantitative Approach.\nPlenum Press, New York, NY.\nPress, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T. (1986). Nu-\nmerical Recipes. The Art of Scientific Computing. Cambridge University Press,\nCambridge, Great Britain.\nPress, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T. (1988). Nu-\nmerical Recipes in C. The Art of Scientific Computing.\nCambridge University\nPress, Cambridge, Massachusetts.\nShah, D. M. (1990). Computer simulation of the random walk model of diffusion.\nBachelor's thesis, Massachusetts Institute of Technology, Cambridge, MA.\nShampine, L. F. and Reichelt, M. W. (1997). The MATLAB ODE suite. SIAM J. Sci.\nComput., 18:1-22.\nSmith, G. D. (1985). Numerical Solution of Partial Differential Equations: Finite\nDifference Methods. Clarendon Press, Oxford, Great Britain.\nStein, W. D. (1986). Transport and Diffusion Across Cell Membranes. Academic\nPress, New York, NY.\nTasaki, I. and Hagiwara, S. (1957). Demonstration of two stable potential states\nin the squid giant axon under tetraethylammonium chloride. J. Gen. Physiol.,\n40:859-885.\n\nBIBLIOGRAPHY\nWeiss, T. F. (1996a). Cellular Biophysics. Volume 1: Transport. MIT Press, Cam-\nbridge, MA.\nWeiss, T. F. (1996b). Cellular Biophysics. Volume 2: Electrical Properties. MIT\nPress, Cambridge, MA.\nWeiss, T. F., Trevisan, G., Doering, E. B., Shah, D. M., Huang, D., and Berkenblit,\nS. I. (1992). Software for teaching physiology and biophysics. J. Sci. Ed. Tech.,\n1:259-274.\nWilson, J. M. and Redish, E. F. (1989). Using computers in teaching physics.\nPhysics Today, pages 34-41.\n\nIndex\nAbsolute reaction rate, 177\nAbsolute temperature, 90, 131\nAccommodation, 114\nAction potentials\neffect of sodium concentration, 120\neffect of temperature, 120\nelectrically excitable cells, 88, 126\nexamples, 119\nActivation factor, 91\nAll-or-none principal, 113\nAnalytic solutions, 37, 40, 48\nAnode, 129\nAnode-break excitation, 114\nBackward Euler approximation, 93, 132,\n134-136, 171\nBinding reaction, 61-63, 66, 67, 86\nBoundary conditions, 135, 137, 139\nHodgkin-Huxley model, 133, 169\nrandom walk model, 13, 16-17,\nreflecting, 37, 40, 48, 54, 56\ntransparent, 37, 40, 48, 54\nCable properties, 164\nCapacitance current density, 89, 130,\nCarrier-mediated transport\naxis scale, 77\nbinding reaction, 61-63, 66, 67,\ncarrier density, 61\nchemical reaction, 60\nCMT Control figure, 69, 70, 70\nCMT Parameters figure, 69, 71, 71-\n73, 73-74\nCMT Setup steady state plot fig-\nure, 76\nCMT Setup transient plot figure,\nCMT State figure, 69, 71, 71-73,\n74-75\nCMT Steady state plot figure, 76\nCMT Transient plot figure, 79\nCMT Transients numerics figure,\nCMT Units figure, 70\ncomparison of simple and general\ncarriers, 84\ncompetitive inhibition, 63\ndissociation constant, 62, 63\neigenvalues, 67, 69, 80, 85, 86\nexchange diffusion, 83\nfile handling, 73, 75, 78\nflux, 61, 63, 65, 68\nflux arrows, 75\ngeneral, four-state carrier, 66-68,\nschematic diagram, 66\nsteady-state equations, 68\ntransient equations, 67\ntransient response, 85, 86\nintereactive steady-state analysis,\nkinetic equations, 61, 63, 66\nmatrix differential equation, 67\nmatrix equation, 62, 64, 68\nmodifiable parameters, 74\nModify line properties figure, 78\nnumerical solutions, 69\noverview, 2\nparameter values, 69\n\nINDEX\nprinciple of detailed balance, 74\nproblems, 81-86\nproperties, 60\nsimple, four-state carrier, 61-63,\n71, 81-84\neffect of asymmetry, 81, 82\nflux vs. concentration, 83\nschematic diagram, 61\nsteady-state equations, 62\nsimple, six-state carrier, 63-65, 71\ndependence of flux on concen-\ntrations, 84\ndependence of flux on parame-\nters, 85\nschematic diagram, 63\nsteady-state equations, 64\nuser's guide, 69-81\nCathode, 129\nCell radius, 128\nCentered difference, 132\nChemical reaction, 35, 38-40, 44, 60\nCMT, see Carrier-mediated transport\nCollision of action potentials, 168\nCompetitive binding, 63\nComplementary error function, 39\nConcentration, 11, 34, 90, 131\nConductance, 175, 178\nConduction velocity, 163, 170, 171\nContinuity relation, 12, 34\nControl figure\nCMT, 69\nHH, 94\nIC, 180\nMD, 41\nPAP, 140\nRW, 18\nCore conductor equations, 126\nCore conductor model, 127-128\nCrank-Nicolson algorithm, 40, 136-\n138, 171\nCurrent clamp, 89, 95, 112\nCurrent per unit length, 128\nCytoplasm resistivity, 128\nDarcy's law, 11\nDepolarization block, 114\nDiffusion, see Random walk model of\ndiffusion, see Macroscopic dif-\nfusion processes\nconcentration, 11, 34\ncontinuity, 34\nequilibration time, 57-58\nequilibrium, 30, 54\nequilibrium time constant, 55\nFick's first law, 11, 34\nflux, 11, 34\nmacroscopic laws, 11, 12\nmicroscopic laws, 12\nsteady state distribution, 26, 55\nsteady state time constant, 55\ntwo compartments, 28, 30, 37, 54-\nDiffusion coefficient, 11, 13, 34, 44,\nDiffusion equation, 34\nDiffusion in a well, 57\nDirac delta function, see Unit impulse\nfunction\nDirectional probabilities, 15\nDiscretization, 131, 132\nDissociation constant, 62, 63\nDrift velocity, 34, 38, 39, 44, 54\nEDUCOM/NCRIPTAL, iv, v\nEigenvalues, 67, 69, 80, 85, 86, 177,\n188, 201\nElectrically excitable cells, 88, 126\nEquilibration time, 57-58\nEquilibrium, 54, 213\nEquilibrium potential, 175, 181, 196,\nEquilibrium time constant, 55, 209\nExchange diffusion, 83\nExpected value, 174, 177, 178, 188,\n190, 192, 198, 199\nExplicit method, 133\nExternal potential, 128, 130\nExternal resistance, 128\n\nINDEX\nExtracellular potential, 165\nFaraday's constant, 90, 131\nFick's first law, 11, 34, 208\nFile handling, 7, 18, 20, 41, 42, 44,\n73, 75, 78, 95, 97, 102, 104,\n107, 142, 147, 150, 152, 180,\n181, 184, 185, 187, 193\nFinite differences, 40\nFinite-difference method, 131\nFinite-element method, 131\nFlux\ncarrier mediated, 61, 63, 65, 68\ndiffusive, 11, 34\nForward Euler approximation, 93, 132-\n134, 171\nFourier's law, 11\nGating charge, 174, 175, 177, 178,\n182, 188, 199\nGating current, 174, 175, 178, 188,\n199, 200\nGating variable, 174\nGaussian function, 38\nGeneral, four-state carrier, see Carrier-\nmediated transport\nGiant axon of the squid, 88, 126\nGreen's function, 38, 39\nHH, see Hodgkin-Huxley model -- space\nclamped\nHistogram, 23\nHodgkin-Huxley model\naccommodation, 114\nactivation factor, 91\nall-or-none principal, 113\nanode-break excitation, 114\ncable properties, 164\ncalcium concentration, 115\ncapacitance current density, 89,\n130, 166\ncollision of action potentials, 168\nconduction velocity, 163, 170, 171\nconfiguration\ncurrent clamp, 89, 94, 95\nrelation of voltage to current clamp,\nspace clamp, 89\nvoltage clamp, 89, 94, 95, 111-\ndefault parameters, 92, 131\ndepolarization block, 114\neffect of calcium concentration, 91\nequilibrium values, 92\nextracellular potential, 165\ninactivation factor, 91\nion concentrations, 90\nionic current density, 89, 130\nkinetic equations, 91\nleakage current density, 90\nlocal response, 167\nlongitudinal current, 166\nmeasurement method, 112-113\nmembrane capacitance, 90, 115,\nmembrane current density, 89, 130,\nmembrane potential, 90, 128, 165\nNernst equilibrium potential, 90,\npolarity of excitatory current, 167\npotassium conductance, 90, 115\npotassium current density, 90\nrate constants, 91\nrefractory period, 113\nrepetitive activity, 114\nsodium conductance, 90\nsodium current density, 90\nspace and time waveforms, 165\nspace clamp, 164\nspace constant, 169\nstep response, 164\nstrength-duration relation, 115\nsub-threshold oscillations, 114, 169\ntemperature, 90, 91, 95, 107, 113,\n115-117, 119, 121, 123, 147,\n170, 171\n\nINDEX\ntemperature factor, 91\nthreshold, 115, 122, 123, 210\ntime constants, 92\nvalence, 90\nvoltage dependent parameters, 91,\n97-101, 147-148\nHodgkin-Huxley model -- propagated\naction potential\nbackward Euler approximation, 132,\n134-136, 171\nboundary conditions, 169\ncapacitance current density, 166\ncell radius, 128\ncolor-coded space-time evolution,\nconduction velocity, 163, 170, 171\ncore conductor equations, 126-128\nCrank-Nicolson algorithm, 136-138,\ncurrent per unit length, 128\nderived parameters, 147\nexternal potential, 128, 130\nexternal resistance, 128\nextracellular potential, 165\nfile handling, 142, 147, 150, 152\nforward Euler approximation, 132-\n134, 171\nhistory, 126\ninternal potential, 128, 130\ninternal resistance, 128\nlongitudinal current, 128, 129, 166\nmembrane current density, 166\nmembrane potential, 165\nnumerical solution, 131-140\noverview, 3, 126-127\nPAP 3D Plots figure, 155-156\nPAP Comparison Plots figure, 156-\nPAP Control figure, 140-142\nPAP Numerics figure, 141, 150-\nPAP Parameters figure, 144\nPAP parameters vs. potential fig-\nure, 147-148\nPAP Space-Time evolution figure,\n153-155\nPAP Stimulus figure, 149-150\nPAP Variable summary figure, 153\nPAP Voltage recorder figure, 152\nPAP Workspace figure, 140, 142-\npositioning electrodes, 143\nproblems, 163-170\nprojects, 170-171\nresistivity of cytoplasm, 128\nrestrictions on parameters, 147\nspace constant, 169\nspatial resolution, 132, 144, 151\nspecifying numerics, 151\nstaggered increment Crank-Nicolson\nalgorithm, 138-140, 171\nstimulating electrodes, 128-129\nsub-threshold oscillations, 169\ntemperature, 171\ntemporal resolution, 132, 151\nuser's guide, 140-163\nHodgkin-Huxley model -- space clamped\naccommodation, 114\naction potential waveform, 113\nanode-break excitation, 114\naxis scale, 100, 105\ncalcium concentration, 115\ndefault parameters, 95\ndepolarization block, 114\nderived parameters, 95\nfile handling, 95, 97, 102, 104,\nHH Axis figure, 100\nHH Control figure, 94-95\nHH Graphics figure, 106-107\nHH Numerics figure, 95\nHH Parameters figure, 94-95\nHH Parameters vs. potential fig-\nure, 97-101\nHH Plots vs. time figure, 104-105\n\nINDEX\nHH Stimulus figure, 94, 101-102\nHH Variable summary figure, 105-\nmembrane capacitance, 115\nmodel description, 89-92\nnumerical solution, 93-94\noverview, 3, 88\npotassium conductance, 115\nproblems, 111-117\nprojects, 118-124\nrefractory period, 113\nrepetitive activity, 114\nscripts, 107-111\nsoftware history, iii\nstrength-duration relation, 115\nsub-threshold oscillations, 114\ntemperature, 115-117\ntemporal resolution, 93, 104\nthreshold, 113-115\nuser's guide, 94-107\nIC, see Voltage-gated ion channels\nImplicit method, 135\nInactivation factor, 91\nInactivation gates, 203\nInitial conditions, 133, 135, 137, 139\nIntegration time, 48, 93, 178, 187, 188\nInternal potential, 128, 130\nInternal resistance, 128\nIon concentration, 90, 131\nIonic conductance, 174, 181, 188, 193,\n198, 199\nIonic current, 174, 175, 178, 188, 190,\n198, 199\nIonic current density, 89, 130\nKinetic equations, 61, 63, 66, 91\nKirchhoff's laws, 127, 128, 133\nLeakage current density, 90\nLongitudinal current, 128, 129, 166\nMacroscopic diffuision processes\nsteady state, 213\nMacroscopic diffusion processes\naxis scale, 43, 51\nbath view, 51\nboundary conditions\nreflecting, 37, 40, 48, 54, 56\ntransparent, 37, 40, 48, 54\nchemical reaction, 35, 38-40, 44\nconcentration, 34\ncontinuity relation, 34\ndiffusion coefficient, 34, 53\ndiffusion equation, 34, 44\ndiffusion parameters, 44\ndrift velocity, 34, 38, 39, 44, 54\nequilibration time, 57-58\nequilibrium, 54\nequilibrium time constant, 55, 209\nFick's first law, 11, 34, 208\nfile handling, 41, 42, 44\nflux, 34\nGreen's function, 38, 39\ninitial distribution\narbitrary, 36, 46, 51-52\ndiscontinuity, 36, 39, 45-46\nimpulse, 36-38, 44, 53-54\nsinusoid, 36, 38-39, 44-45, 53,\n56-57\nmarkers, 42, 51\nMD Analytic parameters figure, 48\nMD Control figure, 41-42\nMD Initial concentration profile,\n41-42\nMD Numeric parameters figure, 48\nMD Parameters figure, 44\nMD Plots vs. position figure, 41,\nMD Plots vs. time figure, 41, 51\nmembrane view, 51\nmethod of images, 56\nmodified diffusion equation, 35\nnumerical solutions, 40, 48\nanalyic parameters, 48\nnumeric parameters, 48\noverview, 2, 35-37\nproblems, 53-58\n\nINDEX\nreaction rate, 35\nspatial resolution, 40, 48\nsteady state distribution, 55\nsteady state time constant, 55, 209\ntemporal resolution, 40, 48\ntwo compartments, 37, 48, 51, 54-\n56, 209-210\nuser's guide, 41-52\nMarkov process, 175\nMATLAB, iv, v, 3-5\nMatrix differential equation, 67, 176\nMatrix equation, 62, 64, 68\nMD, see Macroscopic diffusion pro-\ncesses\nMean, 23\nMembrane capacitance, 90, 115, 130\nMembrane current density, 89, 130,\nMembrane potential, 90, 128, 175, 177,\n182, 185, 186, 201\nMethod of images, 56\nModified diffusion equation, 35\nMolar gas constant, 90, 131\nMultiple-state gates, 202\nNational Science Foundation, vi\nNernst equilibrium potential, 90, 131\nNumerical solutions, 37, 40, 48, 69,\n93-94, 131-140, 178-179, 187-\nOhm's law, 11\nPAP, see Hodgkin-Huxley model -- prop-\nagated action potential\nParticle lifetime, 15\nPedagogy\naudience participation, 210\nextent of software usage, 221\nimpact on learning, 221\nimpact on teaching, 222\nintellectual engagement, 208\nintuition, 206, 210\nlessons learned, 223-226\nmotivation, 210\nresearch project, 212\nsurveys, 222\nvisualization, 206\nwhat-if experiments, 210\nPlotting\nannotate, 77, 100, 161, 185\naxis scale, 24, 43, 51, 77, 100,\n105, 186\ncross-line, 78, 100, 101, 161, 186\ncustomized plots, 111\nlegend, 77\nline properties, 78, 101, 186\noverlay, 75, 97, 107\nspecific software\nCMT, 75-81\nHH, 97-101, 104-107\nIC, 184-186, 188-193\nMD, 48-51\nPAP, 147-148\nRW, 23-26\nzoom, 77, 100, 186\nzooom, 161\nPotassium conductance, 90\nPotassium current density, 90\nPrinciple of detailed balance, 74\nProject Athena, iii-v\nProjects, 118-124, 170-171, 214-220\ndemonstration, 215-217\nelectronic interactions, 220\ngrade, 219-220\nhypotheses, 118, 121-123, 170-\nproposals, 215\nreport, 218-219\nteams, 214\nRandom variable, 174, 179, 188, 190,\n198, 203\nRandom walk model of diffusion\naxis scale, 24\nboundary conditions, 16-17, 21\ndiffusive spread, 208\ndirectional probabilities, 15, 21\n\nINDEX\nequilibrium, 30\nFick's first law, 208\nfield, 13\nfile handling, 18, 20\ngrid, 13\ninitial distribution, 20\noverview, 2, 12-13\nparticle lifetime, 15, 22, 28\nproblems, 26-31\nregion, 13\nregion size, 14, 20\nRW Control figure, 18\nRW Graph figure, 25-26\nRW Histogram figure, 23-24\nRW Parameters figure, 20-22\nRW Particle figure, 18\nRW Summary figure, 22-23\nsink, 22\nsinusoidal, 30\nsource, 21-22\nstatistics, 25\nsteady state, 208\nsteady state distribution, 26\nstep size, 14, 20\nthree regions, 28, 30\nunbiased random walk, 16\nuser's guide, 18-26\nRate constants, 91\nRate-limiting processes, 210\nRefractory period, 113\nRepetitive activity, 114\nResistivity of cytoplasm, 128\nRW, see Random walk model of dif-\nfusion\nScripts, 107-111\nSimple, four-state carrier, see Carrier-\nmediated transport\nSimple, six-state carrier, see Carrier-\nmediated transport\nSodium conductance, 90\nSodium current density, 90\nSoftware\ndirectories, 5\nfile handling, 7\nprinting, 7\nstartup, 6-7\nSoftware history, iii\nSoftware overview\nCarrier-mediated transport, 2\nHodgkin-Huxley model -- propa-\ngated action potential, 3, 126-\nHodgkin-Huxley model -- space\nclamped, 3, 88\nMacroscopic diffusion processes,\n2, 35-37\nRandom walk model of diffusion,\n2, 12-13\nVoltage-gated ion channels, 3, 174\nSoftware usage\nelectronic classroom, 212-214\nlectures, iii, 206-212\nproblems, 26-31, 53-58, 81-86,\n111-117, 163-170, 196-203,\nprojects, iii, 118-124, 170-171, 214-\nSpace clamp, 89, 164\nSpace constant, 169\nSpatial frequency, 44\nSpatial radian frequency, 39\nSpatial resolution, 40, 48, 132, 144,\nStaggered increment Crank-Nicolson\nalgorithm, 138-140, 171\nStandard deviation, 23, 38\nState, 174, 175, 181\nSteady state, 26, 55, 208, 213\nSteady state time constant, 55, 209\nSub-threshold oscillations, 114, 169\nTemperature, 90, 91, 95, 107, 113,\n115-117, 119, 121, 123, 147,\n170, 171\nTemperature factor, 91\nTemporal resolution, 40, 48, 93, 104,\n132, 151, 178, 187\n\nINDEX\nThin membrane approximation, 55,\nThree-state gates, 202\nThreshold, 113-115, 122, 123, 210\nTrapezoidal rule, 137\nTwo-state gates, 196-201\nUnit impulse function, 37, 44, 129\nUnit step function, 46, 129\nUser's guide\ncarrier-mediated transport, 69-81\nHodgkin-Huxley model -- prop-\nagated action potential, 140-\nHodgkin-Huxley model -- space\nclamped, 94-107\nmacroscopic diffusion processes,\n41-52\nrandom walk model of diffusion,\n18-26\nvoltage-gated ion channels, 180-\nValence, 90, 131\nVoltage clamp, 89, 95, 111-112\nVoltage-gated ion channels\nabsolute reaction rate, 177\naxis scale, 186\nconductance, 178\neigenvalues, 177, 188, 199, 201\nequilibrium potential, 175, 181,\n196, 197\nequilibrium state occupancy prob-\nability, 176\nexpected value, 174, 177, 178, 188,\n190, 192, 198, 199\nfile handling, 180, 181, 184, 185,\n187, 193\ngating charge, 174, 177, 178, 182,\n188, 199\ngating current, 174, 175, 178, 188,\ngating variable, 174\nIC Control figure, 180-181\nIC Graphics figure, 192\nIC Ionic current figure, 190\nIC Membrane potential figure, 187,\nIC Parameters figure, 180-182\nIC Specify rate constants figure,\nIC State occupancy figure, 189\nIC Summary figure, 191\nIC View rate constants figure, 184-\ninactivation gates, 203\ninitial conditions, 179-180\ninitial state, 188, 198\nintegration time, 178, 188\nionic conductance, 174, 181, 188,\n193, 198, 199\nionic current, 174, 175, 178, 188,\n198, 199\nline properties, 186\nMarkov process, 175\nmatrix differential equation, 176\nmembrane potential, 175, 177, 182,\n185, 186, 201\nmodel description, 175-178\nmultiple-state gates, 202\nnumerical solutions, 178-179, 187-\noverview, 3, 174\nproblems, 196-203\nrandom variable, 174, 179, 188,\n190, 198, 203\nstate, 174, 175, 181\nstate conductance, 175\nstate gating charge, 175\nstate ionic current, 175\nstate occupancy probability, 175\ntemporal resolution, 178, 187\nthree-state gates, 202\ntransition probability, 175\ntwo-state gates, 196-201\nactivation and inactivation gate,\n\nINDEX\neffect of scaling rates, 198\ngating charge, 199\ngating current, 200\nrelation of ionic and gating vari-\nables, 199\nungated, 196, 199\nuser's guide, 180-193"
    }
  ]
}