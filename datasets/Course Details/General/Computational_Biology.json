{
  "course_name": "Computational Biology",
  "course_description": "This course covers the algorithmic and machine learning foundations of computational biology combining theory with practice. We cover both foundational topics in computational biology, and current research frontiers. We study fundamental techniques, recent advances in the field, and work directly with current large-scale biological datasets.",
  "topics": [
    "Engineering",
    "Biological Engineering",
    "Computational Biology",
    "Engineering",
    "Biological Engineering",
    "Computational Biology"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hour / session\n\nPrerequisites\n\n6.006 Introductions to Algorithms\n\n6.041SC Probabilistic Systems Analysis and Applied Probability\n\n7.01SC Fundamentals of Biology\n\nDescription\n\nThis course covers the algorithmic and machine learning foundations of computational biology combining theory with practice. We cover both foundational topics in computational biology, and current research frontiers. We study fundamental techniques, recent advances in the field, and work directly with current large-scale biological datasets.\n\nGenomes:\nBiological sequence analysis, hidden Markov models, gene finding, comparative genomics, RNA structure, sequence alignment, hashing\n\nNetworks:\nGene expression, clustering / classification, EM / Gibbs sampling, motifs, Bayesian networks, microRNAs, regulatory genomics, epigenomics\n\nEvolution:\nGene / species trees, phylogenomics, coalescent, personal genomics, population genomics, human ancestry, recent selection, disease mapping\n\nIn addition to the technical material in the course, the term project provides practical experience doing these things:\n\nWriting an National Institutes of Health (NIH)-style research proposal\n\nReviewing peer proposals\n\nPlanning and carrying out independent research\n\nPresenting research results orally in a conference setting\n\nWriting results in a journal-style scientific paper\n\nGrading\n\nACTIVITIES\n\nPERCENTAGES\n\nProblem sets\n\n30%\n\nQuiz\n\n20%\n\nFinal Project\n\n40%\n\nScribing\n\n10%\n\nProblem Sets\n\nThere will be five problem sets during the semester, each including 3-5 problems for all students and a lab problem which is optional for undergraduate students. The problem sets will include both theoretical and programming problems. For programming problems, we provide skeleton code in Python, but you are welcome to write solutions in any language.\n\nQuiz\n\nThere will be one quiz, in class, which will cover all material covered up to that point. There will be no final exam. The quiz will include true / false questions, short answer questions, practical problems using algorithms covered in class, and one or two problems extending ideas seen in class.\n\nFinal Project\n\nStudents will work on a final project with deliverables due at several milestones during the term as marked on the course schedule. The first part of the term will be spent identifying a topic relevant to the course materials, planning the project, writing an NIH-style proposal, and reviewing the proposals of your peers. The second part of the term will be focused on completing the project, writing the report, and presenting the results. Details of what is expected by each milestone will be posted on the course website.\n\nYou may either work alone or with one partner; however, teams and graduate students will be expected to undertake more ambitious projects. Part of the final project grade will depend on the challenge and originality of your project.\n\nWe anticipate projects of a few types:\n\nIdentify a biological problem, gather relevant datasets, design and implement new algorithms, apply the methods, and interpret the results.\n\nRigorously compare several algorithms which solve the same biological problem in terms of their performance and the quality of their outputs on synthetic and real data sets.\n\nScribing\n\nEach student will contribute to the scribe notes, which are chapters of the course textbook. Several students may be assigned to work together on a single lecture / chapter depending on course enrollment. As a scribe, you are expected to do the following:\n\nBefore the lecture, familiarize yourself with the materials.\n\nDuring the lecture take note of ideas covered in lecture which are missing or explained poorly in the text, questions asked in lecture which are not answered in the text, digressions from the lecture material which are worth elaborating on, figures / illustrations which are confusing or missing important elements, etc.\n\nAfter the lecture, edit the text to address the points you identify.\n\nTextbooks\n\nThe course textbook is the compiled scribe notes. The entire course textbook is available in the\nreadings\nsection.\n\nYou may also find the following optional texts helpful:\n\nDurbin, Richard, Sean R. Eddy, Anders Krogh, et al.\nBiological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids\n. Cambridge University Press, 1998.\n\nJones, Neil C., and Pavel Pevzner.\nAn Introduction to Bioinformatics Algorithms\n. MIT Press, 2004. ISBN: 9780262101066. [Preview on\nGoogle Books\n]\n\nDuda, Richard O., Peter E. Hart, and David G. Stork.\nPattern Classification\n. John Wiley & Sons, 2003. ISBN: 9789814126021.\n\nRecitations\n\nRecitations will be held on Fridays, during which we will both review the lecture material and discuss additional aspects of it. Since there is only one recitation section, we will not be able to accommodate all scheduling conflicts. Therefore, attendance is not mandatory. Material in the recitation notes may appear on the quiz.\n\nCollaboration Policy\n\nYou are welcome to collaborate on problem sets and the final project. However:\n\nYou must work independently on each problem before you discuss it with others.\n\nYou must write the solutions on your own.\n\nYou must acknowledge outside sources and collaborators.",
  "files": [
    {
      "category": "Assignment",
      "title": "MIT6_047F15_pset1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/d18f54f8fbd2cbd981cda1b385f0f188_MIT6_047F15_pset1.pdf",
      "content": "6.047/6.878/HST.507\nFall 2015 Problem Set 1: Aligning and Modeling Genomes\nDue: Wednesday, September 30 at 8pm (submit on the course website)\nWhen you submit this pset, please turn in the following files in a zip file:\n- Your answers to the problem set questions in a pdf file\n- A directory named \"code\" with all the code you are submitting\n- A directory named \"data\" with all other results you are submitting\nIn your answers to the questions please refer to the appropriate file name where your results/code for that problem\nare located.\n1. Evolutionary distances of orthologs and paralogs\nIn this problem, you will implement the Needleman-Wunsch algorithm for pairwise sequence alignment,\napply it to the protein-coding sequences of related genes from several mammalian genomes, and use the\nresults to learn about their evolution.\n(a) On the class web site, we have provided a python skeleton program ps1-seqalign.py, which you\nwill complete. We provide a traceback routine, but you will write the code to fill in the score and\ntraceback matrices. The skeleton program specifies a substitution matrix and gap penalty. If you so\nchoose, you may rewrite the program in any programming language. Please submit (1) the portion of\nthe code that you wrote; (2) an optimal alignment of the two sequences CTAAGTACT and CATTA, and\nthe corresponding score matrix F with the optimal path indicated; and (3) the score of the alignment\nof the human and mouse HoxA13 genes, which we also provide on the web site.\nThe command to run the program is:\npython ps1-seqalign.py <FASTA 1> <FASTA 2>\nThe Hox cluster is a set of genes that are crucial in determining body plan formation during embryo\ndevelopment. They are found in all bilateral animals, in species as distant as the fruit fly. The fruit fly\nhas one Hox cluster, while most vertebrates have four. It is thought that vertebrates have undergone two\nrounds of whole-genome duplication, giving rise to four Hox clusters from the ancestral one, although the\nhypothesis remains controversial.\nIn the remainder of this problem, you will use your Needleman-Wunsch alignment program to analyze\nthe sequences of several Hox genes, and estimate the date of the most recent vertebrate whole-genome\nduplication. In particular, we are interested in using the N-W alignment score as a distance metric between\ntwo sequences.\n(b) Make minor adjustments to your alignment program so that the score it computes can be interpreted\nas a distance metric. That is, the score of a sequence aligned with itself should be zero, all scores\nshould be non-negative, and sequences that are more dissimilar should be given a score with a greater\nmagnitude. Describe the changes you made in your handin; no code is necessary.\n(c) Apply your modified program to compute a distance between the human HoxA13 gene and the mouse\nHoxA13 gene.\n(d) The modern mammalian genes HoxA13 and HoxD13 arose from a single ancestral gene by whole-\ngenome duplication, long before the human-mouse divergence. We provide the sequences of the\nhuman and mouse HoxD13 genes on the web site. Given that the fossil record shows that human and\nmouse diverged about 70 million years ago, use your distance metric and your results from part (c) to\nestimate the date of the whole-genome duplication that gave rise to HoxA13 and HoxD13. Make sure\nto state the assumptions underlying your estimate.\n\n6.047/6.878/HST.507 Fall 2015\nProblem Set 1\n2. Sequence hashing and dotplot visualization\nAs you have seen in problem 1, sequence alignment is a quadratic time algorithm. Full sequence alignment\nis therefore only feasible for sequences near the length of a single gene. To align larger regions of a\ngenome, heuristic approximations are typically used. In this problem, you will use hashing techniques to\nguide the alignment of a 1 megabase (1 million nucleotides) region surrounding the HoxA cluster in human\n(human-hoxa-region.fa) and mouse (mouse-hoxa-region.fa). You will use dotplots to visualize the\nperformance of various hashing methodologies.\nThe code provided (ps1-dotplot.py) finds all 30-mers in the human that also appear in mouse. On a\ndotplot, each of these matches is represented as a single dot at (x, y), where x is a coordinate for the\nbeginning of a 30-mer in human and y is a coordinate for the beginning of a matching 30-mer in mouse.\nWe provide a plotting function that will produce dotplot images. The format of the image is determined\nby the file extension (*.ps, *.png, *.jpg). There is also code for heuristically judging the specificity of the\nmatches (the fraction of matches that occur near the diagonal of the dotplot).\n(a) Run the script unchanged to generate a dotplot for all exact matching 30-mers. It must be run in the\nsame directory where it is located, since it also requires utils.py and plotting.py. This script also\nrequires gnuplot which is available on athena.\nBefore running the script, do:\nathena% add gnu\nThe command to run the program is:\nathena% python ps1-dotplot.py <FASTA 1> <FASTA 2> <PLOT FILE (*.ps, *.png, *.jpg)\nAlternatively, you can run on your own machine if you have gnuplot installed.\nDescribe what you see. How many hits are there and what percentage fall near the diagonal? Do\nyou observe any structure in the off-diagonal hits? What types of genomic elements could cause such\na pattern? Why are matches that are close to the diagonal more likely than off-diagonal matches to\nrepresent \"correct\", or orthologous, alignments?\n(b) Make the following modifications to the script and report how the plot changes qualitatively and\nquantatively (how many hits, what percentage are near the diagonal). Also briefly describe how you\nimplemented each change.\ni. Modify the script to find all exact matching 100-mers\nii. Modify the script to find all 60-mers that match every other base\niii. Modify the script to find all 90-mers that match every third base\niv. Modify the script to find all 120-mers that match every fourth base\nv. Modify the script to find all 100-mers that allow at most two mismatches in each contiguous\nblock of six bases. Instead of producing a plot, focus on describing how you would implement this\nmodification.\n(c) Although parts a, b.ii, b.iii, and b.iv require the same number of matching bases (30 = 60/2 = 90/3 =\n120/4), one of them is more specific to the diagonal. Explain why this might be so.\n(d) Explain the trade-off you see between number of hits near the diagonal (sensitivity) and the percentage\nof hits near the diagonal (specificity). How is the trade-off affected by the hashing parameters?\n(e) Modify the script to also detect inversions. An inversion occurs when a stretch of DNA is spliced out\nand reinserted in reverse orientation. For example,\nCGT[GATT]AGA\n⇓\nAthena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\n6.047/6.878/HST.507 Fall 2015\nProblem Set 1\nCGT[AATC]AGA\nThe human-hoxa-region-modified.fa file contains a version of the Hox region with an artificial\ninversion. Use the dotplot to locate the inversion in human. (Note: ignore the sensitivity measure,\nand only test all sizes necessary to detect the inversion.)\n3. HMMs for GC-rich regions: State durations and limitations\nAn important use of HMMs is to decode or parse a genome into its biological components: exons, introns,\nregulatory regions, etc. In this problem, we will examine how the accuracy of HMM predictions is affected\nby certain inherent properties of the model.\nIn this problem, we will use GC content (the fraction of letters that are a C or a G) to classify the genome\ninto high-GC regions (on average 60% G or C) and Low-GC regions (on average 60% A or T). These have\ndifferent melting temperatures, different replication times across the cell cycle, and different gene density.\nThey have also been hypothesized to have different evolutionary origins (see isochores), but this hypothesis\nremains controversial.\nOur simple model requires only two states. We have provided a program, viterbi.py, which you will\ncomplete and use to decode several artificial genomes, and then compare the resulting predictions of High-\nGC and Low-GC regions to a provided (correct) annotation. More details about this program are included\nat the end of the problem.\n(a) In most HMMs, the self-loop transition probabilities akk are large, while the transition probabilities\nbetween different states akl are small. Once a Markov chain with these transition probabilities enters\nstate k, it tends to stay in state k for a while. The state duration is the total number of consecutive\nsteps at which the Markov chain stays in the same state, before switching to another state (e.g.\ntransitioning into state k and then transitioning out to a different state is a state duration of 1). What\nis the expected (mean) state duration of state k as a function of the transition probability akk? What\nis the distribution of state durations P (Dk = d)?\n(b) Complete the implementation of the Viterbi algorithm in viterbi.py. Based on the HMM parameters\nhard-coded into the program, what are the expected state durations for High-GC and Low-GC regions?\nApply the finished program to the data file hmmgen, which was generated using the same HMM, and\nverify that your program achieves ∼83% accuracy.\n(c) Now apply your program to the files mystery1, mystery2, and mystery3. How do the (correct)\nstate duration distributions in the mystery sequences differ and what do they have in common? What\naccuracy levels does your HMM achieve on these sequences? How does each Viterbi-predicted state\nduration distribution differ from the correct distribution? (You do not need to include the plots in your\nsolutions.)\n(d) Would re-training the HMM parameters according to the procedure described in lecture, using the\ncorrect annotations as training data, improve the accuracy of the Viterbi annotation for the mystery\nsequences? Why or why not?\n(Extra credit) Try to make the decoder perform better by adjusting the hard-coded model parameters.\nIf you succeed, can you explain why?\n(e) As you are now aware, the length distribution of genomic elements can strongly affect the predictive\naccuracy of an HMM used to decode them. Unfortunately, most elements in real genomes do not follow\nthe length distribution you derived in part (a). By reading the following paper (or any other sources),\ndescribe how the gene finder GENSCAN addresses this issue. How is it possible, algorithmically, to\nuse state duration distributions that differ from the one you derived in part (a)?\nBurge C, Karlin S. Prediction of complete gene structures in human genomic DNA. J Mol Bio\n268(1):78-94, 1997.\nDetails about viterbi.py\n\n6.047/6.878/HST.507 Fall 2015\nProblem Set 1\nNote that like in problem set 1, the plotting portion of this code relies on gnuplot. Therefore, you should\nrun this on athena after running \"add gnu\" if you want plotting to work.\nThe nearly complete program viterbi.py performs the following:\n- Reads in a data file containing a DNA sequence and an authoritative (correct) annotation, consisting\nof a string of pluses and minuses, specifying where the High-GC and Low-GC regions are, respectively.\n- Calculates the base composition of the High-GC and Low-GC regions, calculates the mean length of\nHigh-GC and Low-GC regions, and plots a histogram of the lengths of the High-GC and Low-GC\nregions. (All with respect to the authoritative annotation.)\n- Performs Viterbi decoding on the DNA sequence, using a hard-coded HMM designed to detect High-GC\nand Low-GC regions. (This is the part you will complete.)\n- Calculates the base composition of the High-GC and Low-GC regions, calculates the mean length of\nHigh-GC and Low-GC regions, and plots a histogram of the lengths of the High-GC and Low-GC\nregions. (All with respect to the Viterbi annotation.)\n- Calculates the accuracy of the Viterbi decoding, defined as the percentage of predicted plus and minus\nstates that match the authoritative annotation.\n4. Final project preparation This course aims to both introduce you to the field of computational biology,\nand to enable you to become active members of its research community. This involves being able to plan,\nset up, carry out, and report your independent research, which will be the goal of the final project. While the\nbulk of the work for the final project will be carried out during the second half of the term, it is important\nto begin thinking about possible projects early on.\nTo begin the process of identifying a good project that matches your background and your interest, this\npart of the first problem set asks you to begin that process by writing a paragraph or two on each of the\nfollowing questions:\n(a) Skill set: Detail your academic background, and in particular, your computational/algorithmic training\nand your biological knowledge/experience. We encourage you to select a project that matches your\nskills, and benefits from your strengths. Certainly, you will learn new areas and new applications of\nyour skills, but you are more likely to accomplish a successful project if you think carefully about your\nstrengths, and perhaps identify partners that complement your background early on.\n(b) Research experience: Outline your previous research experience, if any. This can be in any field\nand can be either independent research or class-related research. Think back at the projects you have\naccomplished over the years, list them here, and give a brief description of the kind of skills that you\ngained in accomplishing them.\n(c) Interests: What areas of computational biology do you find the most interesting for your own research?\nRead ahead on the syllabus, and find the lecture topics that seem most interesting to you for a final\nproject. You can find more information about each of these topics on the web, or by pulling up the\nslides for these lectures from previous years. Stepping back and taking a look at the whole term ahead\nof time will help you pick a topic without biasing yourself to only consider early lectures.\n(d) Project types: Think ahead about the type of project you might prefer, for example: algorithmic,\ntheoretical, tool-building, analysis, or method development. This can help you identify areas that are\nmore inclined to the type of project that youre looking for, and also pair up with partners that share\nsimilar interests, or complementary interests on the same topic.\nA unique aspect of computational biology is how collaborative the field is. In order to learn more about\nyour classmates, identify potential partners for the final project, and potentially even collaborators that\nwill come in handy for the longer term, we ask you to fill out the information above (or an abbre\nviated version thereof) in an MS Word document and upload it with your homework. We have pro\nvided a template StudentProfileTemplate.doc. Note that these summaries will be shared among\nAthena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\n6.047/6.878/HST.507 Fall 2015\nProblem Set 1\nyour classmates (if you are uncomfortable with this, please contact the course staff). Name your pro\nfile LastnameFirstname Profile.doc. There will be more files that complement this through the term,\nso maintaining a consistent naming scheme is important.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "MIT6_047F15_pset2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/c4b06c5b42571455f3a22c97039ebd9b_MIT6_047F15_pset2.pdf",
      "content": "6.047/6.878/HSPH IMI.231/HST.507 Fall 2015\nProblem Set 2: Clustering and Classification\nDue Tuesday, October 13 at 8pm (submit on the course website)\nSubmit a zip file of a directory named Lastname Firstname containing:\n- A PDF file named Lastname Firstname.pdf with your written answers\n- A directory named code with all code you are submitting\n- A directory named data with all other results you are submitting\nIn your answers to the questions please refer to the appropriate file name where your results/code for that\nproblem are located. Unless skeleton code has been provided, feel free to use any programming language you\nare comfortable with, as long as you structure and comment your code to make it concise and legible.\nNaive Bayes Classification\nIn this problem, we will use a Naive Bayes classifier to label fragments of the genome based on sequence properties.\n(a) Suppose we want to classify sequence fragments into categories (represented by random variable Y): genes,\nregulatory motifs, or repetitive elements. We want to use the following features: length X1, GC content\n(proportion of bases which are G or C) X2, and complexity X3 (intuitively, what fraction of possible k-mers\nare observed).\nDoes the naive Bayes assumption hold in this setting? Explain why or why not.\n(b) Regardless of whether the naive Bayes assumption holds, we can still build a classifier. (Surprisingly, naive\nBayes classifiers perform well in many applications where this assumption does not hold.) To simplify, we\nwill discretize each of the features.\nGiven the training set below, write down the maximum likelihood estimates (recall these are relative fre\nquencies) of each of the conditional probability distributions P(Xi | Y) and the prior probability distribution\nP(Y).\nGC Content\nLength\nComplexity\nClass\nLow\nLong\nHigh\nGene\nLow\nLong\nLow\nGene\nHigh\nLong\nHigh\nRepeat\nMedium\nShort\nHigh\nMotif\nMedium\nShort\nLow\nMotif\nHigh\nLong\nLow\nRepeat\nHigh\nShort\nHigh\nMotif\nMedium\nLong\nHigh\nGene\nHigh\nLong\nLow\nRepeat\nHigh\nShort\nHigh\nMotif\n(c) Given the model, compute the maximum a posteriori estimate of the class of the new observation below.\nGC Content\nLength\nComplexity\nMedium\nLong\nLow\n\nClassification of conserved regions\nIn this problem, we will use simulation to study the problem of classifying conserved sequence fragments given\nmultiple alignments of four species. Submit all code you write.\n(a) To simplify our classification problem, we will consider alignment scores at each position. We define the\nalignment score of a column of a multiple alignment to be the number of unique pairs that share the same\nsymbol. An example multiple alignment and the score for each column is given below:\nGACTA\nTACTA\nAGTTA\nCTTAA\nConsider two models C for conserved regions and N for unconserved regions. Assuming the alignment score\nat every position is independent, the conditional probability of observing a particular score in a column given\neach model is tabulated below:\nScore\nN\nC\n0.1\n0.05\n0.35\n0.15\n0.25\n0.2\n0.2\n0.3\n0.1\n0.3\nCompute the conditional probabilities of observing each of the following alignments given each of the models:\nACGACGACTA\nCAGACGCTGA\nTTCCTCTGAT\nAGATGTGACT\nACAACGAGTA\nAAAACGAATA\nTCATCGAGTT\nACATCTAACT\n(b) Simulate 10,000 sequences S of alignment scores of length 10 from N. How often is P(S | C) > P(S | N)?\n(c) Simulate 10,000 sequences S of alignment scores of length 10 from C. How often is P(S | N) > P(S | C)?\n(d) How could we reduce the rate of classification errors on these short fragments? What about for much longer\nsequences?\nK-means clustering\nIn this problem, you will implement k-means clustering on the expression profiles of two genes across a set of\nbreast cancer patients. We have collected expression data from a pair of tissue types from the same set of 700\npatients. We now wish to find clusters in this data that correspond to different breast cancer subtypes.\nTo run the code in this problem, you will have to either install R on your computer (visit https://cran.\nr-project.org/) or run the command add R if you are running the code on Athena. The kmeans zipped\nfolder available\ncourse website contains the following files:\n- kmeans.py, which contains skeleton functions you will have to implement\n- kmeans plot.R, which plots the k-means clusters at each iteration of the algorithm (don't mess with this\ncode unless you know your way around R and want to make your plots look prettier)\n\nAthena is MIT's UNIX-based computing environment. OCW does not provide access to it.\non the\n\n- a set of tissue∗ data.txt files, which contain gene expression data from 700 patients on a series of tissues\n(a) Your first task is to add code to kmeans.py to implement the k-means algorithm. To do this, you will have\nto complete the assignPoints and recalculateCtrs functions, and then add calls to these functions to the\nmain() function in kmeans.py where indicated. Submit your version of kmeans.py.\n(b) Run your code on tissue1 using the command python kmeans.py tissue1. If your implementation is\ncorrect, the algorithm will converge in four steps. Submit the plots generated by the code.\n(c) Now run your code on tissue2 (your algorithm should converge in six steps this time). What went wrong?\nWhat strategy would you employ to find the settings of the algorithm so that it identifies the most obvious\nclusters, assuming you couldn't see the clusters ahead of time?\nExperiment with the code in main() to try different approaches. Use insights from your strategy to make\ncorresponding changes to the main() function in kmeans.py (you should only have to tinker with one line).\nRun the algorithm again, and describe how your solution addressed the problem using some of the output\nplots for reference.\nHand in your write-up, with the figures in the same document if possible.\n(d) Describe how you would implement fuzzy k-means clustering using the above set of functions. You can\neither submit another version of kmeans.py with your changes, or submit pseudocode that has the same\nstructure. Don't worry about running the fuzzy k-means or generating any more plots. (Bonus: Describe\nhow you would visualize the steps of fuzzy k-means, showing the cluster(s) each point has been assigned to\nand each of the centroids as above.)\n4 Final project preparation\n(a) Before reading further, summarize each of your top three project ideas in a few sentences. You do not need\nto submit these.\n(b) Evaluate previous proposals. We have made proposals from previous years available on the course website.\nFind the two proposals most closely related to your research interests. What do you find most exciting about\nthe proposal? What would you do differently for that proposal? What aspects of the area did the proposal\nleave unaddressed, and how would you address them?\nWe expect your projects to be independent of these past projects; however, thinking critically about related\nwork will help guide your own projects.\n(c) Evaluate scientific papers. Find two papers published in the last several years closely related to your\nresearch interests. What do you find most exciting about them? What questions have they left open?\nWhat details did they not address, and how would you address them?\nWe suggest looking at journals such as Nature Genetics, Nature Biotechnology, PLoS Computational Bi\nology, PLoS Genetics, Bioinformatics, and BMC Bioinformatics. We don't expect your projects to be\nsubmission-ready immediately upon completion, but critically reading the literature will give you a better\nsense of open problems in your area of interest and prior work you can build upon.\n(d) Write up a project idea. Return to the ideas you wrote down in (a) in light of what you have read in\nprevious proposals and the literature. Write up at least one of your ideas in detail (several paragraphs).\nHow you would execute the idea? What challenges do you anticipate? What resources do you need to\ngather to succeed?\n(e) Find a partner. Read through the student profiles (available on the course website) to find potential\npartners with similar interests and/or complementary skills. List the three people you are most likely to\ncontact in order to form a team.\nYou don't have to contact them in advance, or get their approval for listing them here. We encourage you\nto contact potential collaborators early.\n\nHidden Markov Model classification of CpG islands (6.878 only)\nIn this problem, we will implement the eight-state Hidden Markov model described in lecture to annotate regions\nas CpG islands, or regions with high CpG dinucleotide frequency. Recall the model has states A+, C+, G+, T +\nwhich emit nucleotides within CpG islands and states A-, C-, G-, T - which emit nucleotides outside CpG islands.\nSubmit all code you write.\n(a) Train the model by computing the maximum likelihood estimates of the model parameters (recall these are\nrelative frequencies). Describe and justify how you handle zeroes in the estimated parameters. Estimate\nthe initial state distribution and justify the method you used to do so.\nSubmit plain text files containing the transition probability matrix (space-separated entries, one row per\nline), the emission probability matrix (one row per state, one column per nucleotide; space-separated entries,\none row per line) and the initial state distribution (one entry per line).\nThe training data is the sequence of human chromosome 21 and an existing CpG island annotation which\nwe will use as ground truth (available at the URLs below):\nftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr21.fa.gz\nftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/cpgIslandExt.txt.gz\nThe schema for the CpG island annotation database table is available at the URL given below. You will\nonly need columns 2-4 (\"chrom\", \"chromStart\", \"chromEnd\").\nftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/cpgIslandExt.sql\n(b) Use the Viterbi algorithm to annotate CpG islands in the region surrounding the SRY (sex determining\nregion Y)-box 10 gene (SOX10). We are interested in the region between positions 38,000,000-39,000,000\nof human chromosome 22. The reference sequence of chromosome 22 is available at the URL below:\nftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr22.fa.gz\nSubmit a BED file with your annotated regions. You only need to include chromosome and position\ninformation. The BED file format specification is available at the URL below:\nhttps://genome.ucsc.edu/FAQ/FAQformat.html#format1\n(c) Evaluate the performance of the model by computing its false positive and false negative rates on the test\ndata against the ground truth annotation. Define a true positive to be a predicted CpG island of which at\nleast 50% overlaps a true CpG island.\nAre these two rates equal? If not, what causes this bias?\n(d) Could we improve the performance of the model by tuning parameters? If so, describe how you would do\nso (you do not have to implement your suggestions). If not, describe and justify some modifications to the\nmodel which could reduce its error rate.\n(e) One alternative approach to improve the quality of annotations is combining multiple lines of evidence.\nDescribe and justify some biological criteria for filtering the output of a sequence-based CpG island classifier\nto improve its performance.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 Computational Biology\nFall 2015\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "MIT6_047F15_pset3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/2ff13b04d66a29bb1dbfbe6a348e135e_MIT6_047F15_pset3.pdf",
      "content": "6.047/6.878/HSPH IMI.231/HST.507 Fall 2015\nProblem Set 3: Motifs and RNA Structures\nDue Tuesday, October 27 at 8pm (submit on the course website)\nSubmit a zip file of a directory named Lastname Firstname containing:\n- A PDF file named Lastname Firstname.pdf with your written answers\n- A directory named code with all code you are submitting\n- A directory named data with all other results you are submitting\nIn your answers to the questions please refer to the appropriate file name where your results/code for that\nproblem are located. Unless\n\nskeleton\n\ncode has been provided, feel free to use any programming language you\nare comfortable with, as long as you structure and comment your code to make it concise and legible.\n1 Gibbs sampling for motif discovery\nIn this problem, you will implement a Gibbs sampler to discover sequence motifs. We have provided a Python\nskeleton gibbs.py. Submit all code you write.\n(a) Recall the Gibbs sampling algorithm for this problem: Initialize the motif position in each sequence. Until\nconvergence: re-estimate the position weight matrix (PWM) from all the motifs except one, score ev\nery position in the excluded sequence, and sample a k-mer from the excluded sequence with probability\nproportional to the score.\nWe have intentionally not specified many of the implementation details. Describe and justify the design\ndecisions you made in your implementation. For example, how do you choose the sequence to exclude when\nrecomputing the position weight matrix?\n(b) We have provided four test cases. data1 is a synthetic data set where the motif is identical across the\nsequences. data2 is a synthetic data set with a degenerate motif. data3 and data4 are yeast transcription\nfactor binding sites of ACE2 and MBP1, respectively.\nRun your Gibbs sampler on the test data to discover motifs of length 10. You will need to repeat this\nprocedure several times on each data set due to the stochastic nature of Gibbs sampling.\nSubmit plain text files containing the most consistently found PWM for each sequence. Use Weblogo1 to\ncreate a sequence logo from each PWM and include them in your writeup.\n2 Evolutionary signatures of motifs\nIn this problem, you will search for enriched (over-represented) k-mers in regions conserved across the yeast clade\nSaccharomyces. Submit all code you write.\n(a) We have provided the sequence of all intergenic regions in S. cerevisiae in the file allinter. We have also\nprovided an annotation of conservation in the file allintercons. Each position marked with ∗ corresponds\nto a conserved nucleotide. For simplicity, we will look for motifs which are non-degenerate, exact matches.\nCompute the frequency and conservation of all 6-mers. Submit a plain text file with the 50 most frequently\noccurring and 50 most conserved motifs (those with the highest proportion of conserved instances).\n1http://weblogo.threeplusone.com/create.cgi\n\n(b) Compare frequently occurring motifs to highly conserved motifs. Are there biases in the sequence properties\nof either class? If so, where does this bias come from?\nWhich of the two lists should we use to direct further inquiry into yeast transcription factor binding sites?\nWe have provided an annotation of known yeast motifs yeast motifs.txt. Which known motifs does\nyour scan of 6-mers find?\nRNA secondary structure\nIn this problem we will explore the output of the Nussinov algorithm on random RNA sequences. Submit all code\nyou write.\n(a) Implement the Nussinov algorithm, scoring A-U, G-U, and C-G pairs as -1 and all other pairs as 0.\n(b) Generate 1000 RNA sequences of length 100 where each base is drawn uniformly at random. What is the\naverage score for these sequences?\n(c) How does the score vary as a function of length? (You will need to repeat (b) for various lengths.)\n(d) How does the score vary as a function of GC content? Is this function symmetric around GC content equal\nto 0.5? Why or why not? (You will need to repeat (b) for different distributions from which you draw\nbases.)\n(e) Given an RNA transcript of interest, how should you interpret the score output by the Nussinov algorithm\nwith respect to your observations about its dependence on length and sequence composition? Is there a\nbetter way to estimate the effect of these biases on the score?\nUpcoming project milestones\nThis is a reminder of upcoming project milestones:\nProject proposal: Tuesday, 10/20 Refer to the handout on the course website.\nProject proposal presentations and feedback: Friday 10/23, 4PM, 32D-507 Prepare a short presentation\n(no more than 3 slides) describing your team, project, goals, and deliverables and submit it before the\nmeeting in PDF or Powerpoint format on the course website\nSubmit a presentation even if you are unable to attend the meeting. Attending is optional but we strongly\nencourage you to do so not just to receive feedback on the feasibility and challenge of your project but also\nto hear the feedback your classmates receive.\n\n5 Probabilistic model for transcription factor binding sites (6.878 only)\nIn this problem we will derive the probabilistic model underlying position weight matrices (PWMs) and use it\nto study CCCTC-binding factor (CTCF ) binding sites. CTCF is a conserved zinc-finger protein which binds to\nthousands of locations in the human genome and acts as an insulator/repressor.\nThe data provided for this problem comes from Kim et al. \"Analysis of the Vertebrate Insulator Protein CTCF-\nBinding Sites in the Human Genome.\" Cell. 2007 Mar 23;128(6):1231-45. Submit all code you write.\n(a) Explain how to estimate the motif model M = [mij] where mij = P(position i = nucleotide j).\n(b) Describe and justify an algorithm to estimate the background model B. What assumptions does your model\nmake? What are some of its weaknesses?\n(c) Recall that a PWM gives the log odds of observing a particular nucleotide at a particular position in the\nmotif model against in the background distribution.\nUse your algorithm from (a) to estimate M from ctcf binding site sequences.txt and your algorithm\nfrom (b) to estimate B from chr11 region.fa. Include these distributions in your writeup.\nEstimate a PWM for CTCF using M and B and include it in your writeup.\n(d) An alternative visual representation of transcription factor binding sites is a sequence logo which gives\nthe information content at every position (intuitively, how important each position is for protein binding\naffinity).\nUse WebLogo2 to generate a sequence logo for ctcf binding site sequences.txt. Include it in your\nwriteup.\n(e) Compare your sequence logo to the published logo ctcf motif.jpg. What could account for any differ\nences?\n(f) Discuss the limitations of PWMs as a representation of transcription factor binding sites. What assumptions\nare made? Do they hold in general?\n(g) Because the entries of a PWM are log odds scores, we can score a k-mer by simply adding up the appropriate\nentries of the PWM.\nConvert the published Position Frequency Matrix (PFM) ctcf pwm.txt to a PWM and use it to scan for\nCTCF binding sites in chr11 region.fa. This region flanks the gene insulin-like growth factor 2 (IGF2 ).\nPlot the scores at every position for each strand and include the plots in your writeup.\n(h) Recall that short k-mers frequently occur by chance throughout the genome. Estimate the probability\ndistribution of scores by randomly sampling 1 million 20-mers from chromosome 11 and scoring them using\nthe published PWM. You may want to use the full sequence of chromosome 11 rather than the region we\nhave provided . Plot a histogram of this distribution.\nA simple way to use this null distribution to filter out hits that occurred by chance is to only keep hits with\nP(score > threshold) < 10-5 . Based on the distribution you estimated, what is the threshold?\nIn a plain text file, report the location, score, and sequence (be sure to account for strand orientation) of\neach 20-mer which meets the threshold.\n(i) Discuss some limitations of filtering PWM matches in this manner. Does the method by which we sample\n20-mers matter? How will the sequence properties of randomly chosen genomic regions affect the answer?\nCan we choose regions in a more principled way to account for sequence properties? Is it possible to estimate\nthe probability of a PWM match occurring by chance without sampling?\n2http://weblogo.threeplusone.com/create.cgi\n3ftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr11.fa.gz\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "MIT6_047F15_pset4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/72775e0c2d958874120657973764ba08_MIT6_047F15_pset4.pdf",
      "content": "6.047/6.878/HSPH IMI.231/HST.507 Fall 2015\nProblem Set 4: Alleles and Arrays\nDue Thursday, November 12 at 8pm (submit on the course website)\nSubmit a zip file of a directory named Lastname Firstname containing:\n- A PDF file named Lastname Firstname.pdf with your written answers, which should include all plots you\nare referencing.\n- A directory named code with all the code you are submitting\nIn your answers to the questions please refer to the appropriate file name where your code for that problem is\nlocated. Unless skeleton code has been provided, feel free to use any programming language you are\ncomfortable with, as long as you structure and comment your code to make it concise and legible.\n1 Generalized suffix trees (10pts)\nIn this problem, we will study some generalizations of suffix trees which allow searching multiple strings and\napproximate string matching.\n(a) Describe a modification to the suffix tree data structure which will allow queries on multiple strings. For\nexample, we may want to search for occurrences of a particular query sequence in multiple reference genomes.\n(b) Recall that in the case of a suffix tree on one string, we can construct an equivalent suffix array which will\nrequire less space to store. Can your generalized suffix tree be transformed into a suffix array? If so, give\nan algorithm to do so. Is it possible to directly use a suffix array to solve this problem?\n(c) Suppose we are instead interested in allowing only certain mismatches in certain positions (e.g., looking\nfor motif instances). Describe how to build a suffix tree which can handle these queries. Can this tree be\ntransformed into a suffix array?\n(d) Suppose we want to search for approximate occurrences of a query string within Hamming distance k\n(number of mismatches at most k). Describe an algorithm to perform this query on a suffix tree.\nExtra credit: Describe an algorithm to perform this query on a suffix array.\n2 Finding eQTLs (20pts)\nIn this problem, we will examine the sources of variation in gene expression that partition a population into sub-\npopulations. You will find the datasets used in this question in the eQTLs folder available though the problem set\nfolder on the course website.\n(a) In the file ExpData.txt, you will find log-normalized RNA-seq expression data from our population of 1000\nsamples, with 5000 genes profiled for each sample. Do a principal components analysis on this dataset to\nfind the clusters of samples that have similar patters of gene expression. Plot the output of your analysis,\nand describe the patterns that you observe. What is the structure inherent in this population?\nFor PCA, we recommend you use the princomp function in the stats package available by default in R.\nHowever, many other languages such as MATLAB and python have analogous functions; you should use\nwhatever you are most comfortable with. In your plots, be sure the axes are labeled with the components you\nare displaying in each plot. Also make sure that at least one of your plots colours the points corresponding\n\nto the samples with the sub-population that you think they should belong to. (Hint: You can re-use your\nk-means code from Pset 3 to find these sub-populations!).\nHand in your write-up and the code you used for plotting and assigning samples to sub-populations.\n(b) In the file SnpData.txt, you will find genotyping data for the same 1000 samples across 500 SNPs. Each\nSNP's genotype has been called with reference to the same reference genotype; \"0\" thus represents the\nreference allele, \"2\" represents the non-reference allele, and \"1\" represents a different allele on each strand.\nYou will find that some of the SNPs (more than 5, less than 100) are eQTLs, that is, they have an effect\non the expression of one or more of the genes we collected expression data for. Using whatever model you\nsee fit, search for these eQTLs using the genotyping data and the expression data. You may not have the\ncomputational resources to test all combinations of SNPs and genes, so you should think about smart ways\nto choose subsets of each to find some eQTLs - you don't have to find all of them!\nFor three of the eQTLs you found, present the evidence you have for why you think it is an eQTL, and not\njust associated with the expression of a gene by chance alone. Be sure to include plots in your analysis to\nsupport your hypothesis, and to thoroughly explain the method you used to find eQTLs. You can assume\nthat the association between genotype and expression is linear for eQTLs. Don't forget that you should be\ncorrecting for the fact that you are performing multiple significance tests.\nHand in your write-up as well as the code you used to look for eQTLs in the two datasets provided.\n(c) In the above analysis, we were forced to consider all pairs of SNPs and genes to identify eQTLs. What\nsources of data that have not been provided as part of this problem would have been useful in constraining\nthe amount of such pairs you had to test? For at least two sources, give a description of what the dataset\nwould look like (what are the rows and columns of the data matrix? what kinds of values are stored in the\nmatrix?) and explain how you would use it to filter out pairs of SNPs and genes that are unlikely to be\nassociated with one another.\n\n3 Coalescent simulation (6.878 only, 10pts)\nIn this problem, we will simulate the coalescent process. Recall this is the time-reverse of the Wright-Fisher\nprocess.\n(a) Write a program to simulate the coalescent process on a population of N alleles. Track the times of\ncoalescent events starting from the initial generation until all alleles coalesce to a single ancestor. If we are\ntracking k lineages, you should report k - 1 coalescent events.\nRecall that the Wright-Fisher process assumes each allele in the next generation is sampled independently\nfrom all alleles in the current generation. We are now interested in the reverse, so we instead need to sample\nparents in the previous generation uniformly at random with replacement. Note we are interested in the\nidentities of the parents and not their ancestral alleles.\nRun 1,000 trials with a population size of N = 500. Report the mean and standard deviation of the number\nof generations between coalescent events of k = 2, 3, and 4 lineages.\n(b) Recall the waiting time between coalescent events is approximately exponentially distributed with parameter\nλ. For each value of k, what is the value of λ given N = 500?\nGiven this distribution, the mean waiting time and its standard deviation are both 1/λ. How do these\nexpected values compare to your observed values? If your observed values are different, give an explanation\nof what could have caused the differences.\n(c) Extend your simulator to model sexual reproduction.\nAssume a fixed number of females F (and therefore M = N - F males) in each generation and that each\nchromosome in the next generation is selected in the following way: sample a male and female to mate\nuniformly at random, then sample one of the two alleles uniformly at random. Your simulation should do\nthe reverse: sample a father and mother and then pick one at random as the ancestor for each allele.\nRun 1,000 trials with F = 100 and M = 400. Do your results agree with the coalescent approximation?\nJustify your answer as in (b).\nCan you extend the coalescent approximation to more accurately reflect this model of sexual reproduction?\nDo your results agree with this new approximation?\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "MIT6_047F15_pset5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/6678e7e5640f7b4374ea6d3c10b8b494_MIT6_047F15_pset5.pdf",
      "content": "6.047/6.878/HSPH IMI.231/HST.507 Fall 2015\nProblem Set 5: Clustering Phylogenetic Trees\nDue Thursday, December 3 at 8pm (submit on the course website)\nSubmit a zip file of a directory named Lastname Firstname containing:\n- A PDF file named Lastname Firstname.pdf with your written answers, which should include all plots you\nare referencing.\n- A directory named code with all the code you are submitting\nIn your answers to the questions please refer to the appropriate file name where your code for that problem is\nlocated. Unless skeleton code has been provided, feel free to use any programming language you are\ncomfortable with, as long as you\n\nstructure and comment your code to make it concise and legible.\nWe've seen that phylogenetic tree algorithms can construct many different \"good\" putative evolutionary histories.\nAn important and challenging problem is that of reducing a large number of trees to a smaller number of\nrepresentative solutions. The objective of this assignment is to explore techniques for dealing with large sets\nof different phylogenetic trees for the same data. This assignment is inspired by the paper \"Statistically based\npostprocessing of phylogenetic analysis by clustering\" by Cara Stockham, Li-San Wang, and Tandy Warnow\n(Bioinformatics, Vol 18, Suppl. 1, 2002, pp. S285-S293).\nIn Part 1, you will implement the Robinson-Foulds distance metric. In Part 2, you will use a clustering algorithm\nto partition distinct phylogenetic trees into clusters of trees where the trees in a given cluster are similar with\nrespect to Robinson-Foulds distance. In Part 3, you'll implement a general consensus algorithm that will allow\nyou to find a consensus tree for each cluster and measure the quality of the cluster by its \"specificity\" - how close\nit is to being a binary tree.\nThis problem is due to Ran Libeskind-Hadas. The full details are available at the URL below:\nhttp://www.cs.hmc.edu/~hadas/mitcompbio/treedistance.html\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 11 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/aeb3d9cfd4ab318d37ac032d7bd500c4_MIT6_047F15_Lecture11.pdf",
      "content": "Lecture 11 - Epigenomics\nread mapping - peak calling - multivariate HMMs\n6.047/6.878/HST.507\nComputational Biology: Genomes, Networks, Evolution\n\nModule III: Epigenomics and gene regulation\n- Computational Foundations\n- L10: Gibbs Sampling: between EM and Viterbi training\n- L11: Rapid linear-time sub-string matching\n- L11: Multivariate HMMs\n- L12: Post-transcriptional regulation\n- Biological frontiers:\n- L10: Regulatory motif discovery, TF binding\n- L11: Epigenomics, chromatin states, differentiation\n- L12: Post-transcriptional regulation\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nOne Genome - Many Cell Types\n\nACCAGTTACGACGGTCA\nGGGTACTGATACCCCAA\nACCGTTGACCGCATTTA\nCAGACGGGGTTTGGGTT\nTTGCCCCACACAGGTAC\nGTTAGCTACTGGTTTAG\nCAATTTACCGTTACAAC\nGTTTACAGGGTTACGGT\nTGGGATTTGAAAAAAAG\nTTTGAGTTGGTTTTTTC\nACGGTAGAACGTACCGT\nTACCAGTA\nImage Source wikipedia\nImages of skin, heart, a red blood cell, and a human\nbrain removed due to copyright restrictions.\n\nDNA packaging\n- Why packaging\n- DNA is very long\n- Cell is very small\n- Compression\n- Chromosome is 50,000\ntimes shorter than\nextended DNA\n- Using the DNA\n- Before a piece of DNA\nis used for anything,\nthis compact structure\nmust open locally\n- Now emerging:\n- Role of accessibility\n- State in chromatin itself\n- Role of 3D interactions\n(c) Garland Science. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Alberts, Bruce et al. \"Molecular Biology of the Cell.\" (2014).\n\nThree types of epigenetic modifications\nImage source: http://nihroadmap.nih.gov/epigenomics/\nCourtesy of National Institutes of Health. Image in the public domain.\n\n100s of histone tail modifications\n\n- 100+ different histone modifications\n- Histone protein H3/H4/H2A/H2B\n- AA residue Lysine4(K4)/K36...\n- Chemical modification Met/Pho/Ubi\n- Number Me-Me-Me(me3)\n- Shorthand: H3K4me3, H2BK5ac\n- In addition:\n- DNA modifications\n- Methyl-C in CpG / Methyl-Adenosine\n- Nucleosome positioning\n- DNA accessibility\n- The constant struggle of gene regulation\n- TF/histone/nucleo/GFs/Chrom compete\nDNA wrapped around\nhistone proteins\nHistone tails\nmodifications\n(c) source unknown. All rights reserved. This\ncontent is excluded from our Creative\nCommons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\n\nCombinations of marks encode epigenomic state\n- 100s of known modifications, many new still emerging\n- Systematic mapping using ChIP-, Bisulfite-, DNase-Seq\n- H3K4me3\n- H3K9ac\n- DNase\n- H3K36me3\n- H3K79me2\n- H4K20me1\n- H3K4me1\n- H3K27ac\n- DNase\n- H3K9me3\n- H3K27me3\n- DNAmethyl\n- H3K4me3\n- H3K4me1\n- H3K27ac\n- H3K36me3\n- H4K20me1\n- H3K79me3\n- H3K27me3\n- H3K9me3\n- H3K9ac\n- H3K18ac\nEnhancers\nPromoters\nTranscribed\nRepressed\n(c) source unknown. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\nCourtesy of Broad Communications. Used with permission.\n\nDiverse tissues and cells:\n1.Adult tissues and cells (brain, muscle, heart, digestive, skin, adipose, lung, blood...)\n2.Fetal tissues (brain, skeletal muscle, heart, digestive, lung, cord blood...)\n3.ES cells, iPS, differentiated cells (meso/endo/ectoderm, neural, mesench, trophobl)\nEpigenomics Roadmap across 100+ tissues/cell types\nDiverse epigenomic assays:\n1. Histone modifications\n- H3K4me3, H3K4me1\n- H3K36me3\n- H3K27me3, H3K9me3\n- H3K27/9ac, +20 more\n2. Open chromatin:\n- DNase\n3. DNA methylation:\n- WGBS, RRBS, MRE/MeDIP\n4. Gene expression\n- RNA-seq, Exon Arrays\nArt: Rae Senarighi, Richard Sandstrom\nCourtesy of NIH Roadmap Epigenomics Mapping Consortium. Used with permission.\n\nOngoing epigenomic mapping projects\n\n- Mapping multiple modifications\n- In multiple cell types\n- In multiple individuals\n- In multiple species\n- In multiple conditions\n- With multiple antibodies\n- Across the whole genome\n-First wave published\n-Lots more in pipeline\n-Time for analysis!\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nBar-coded multiplexed sequencing\nChIP-seq review\n(Chromatin immunoprecipitation followed by sequencing)\nantibody\n(c) Illumina, Inc. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\nSource: Lefrancois, Philippe et al. \"Efficient yeast ChIP-Seq using multiplex\nshort-read DNA sequencing.\" BMC genomics 10, no. 1 (2009): 1.\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Park, Peter J. \"ChIP-seq: advantages and challenges of a maturing\ntechnology.\" Nature Reviews Genetics 10, no. 10 (2009): 669-680.\n\nChIP-chip and ChIP-Seq technology overview\nImage adapted from Wikipedia\nor modification\nModification-specific antibodies Chromatin Immuno-Precipitation\nfollowed by: ChIP-chip: array hybridization\n\nChIP-Seq: Massively Parallel Next-gen Sequencing\n\nChIP-Seq Histone Modifications: What the\nraw data looks like\n- Each sequence tag is 30 base pairs long\n- Tags are mapped to unique positions in the ~3 billion\nbase reference genome\n- Number of reads depends on sequencing depth.\nTypically on the order of 10 million mapped reads.\n\nSummarize multiple marks into chromatin states\nChromHMM: multi-variate hidden Markov model\nWashU Epigenome Browser\n30+ epigenomics marks\nChromatin state track summary\n(c) WashU Epigenome Browser. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMapping millions of short reads\nto the genome\nTraditional Hashing Schemes\nBurrows-Wheeler Transform (BWT)\n\nMapping Reads to the Genome\n- Assign reads to best matching location in reference genome\n- 10,000,000s of reads, ~30 bases long\n- Example: CAGGGCTGATTGAGGACATTCATCACG\n- Allow mismatches: sequencing errors, or SNPs\n- Algorithmic and memory efficiency is critical\n...ATAGTCTTCCTGCATAGTCCTTTCTGCCAGACGGTAATTACAACCTTTTGTTATAAAAATAGAGAAGACTTAAAATTCTGCAGTAGGAGTGTCTGTATTCCTCCG\nCAATCACTTCAATGTGTCTATTTTTGTGATCTAAAAATAACGGCTCCTGCAGATAAACTCGGATATGAGAGTTTCATAATGACAACTAGCATATATTTGTCCAGAG\nTTATTAAAACGGTCTAGACGAGACTATCATTTTCCTAAAATACCAAAGATTAAGTCACACGGAAGACTCAGAAAAACACCTACAGAGACCTCACAGAAGTTTCTAG\nTTTAAAGTATGTGAGTGTGCACACTTTCATCTTAGTCTAAGCATCAGGGGGAACGTTGGGTAAACATTACTAAAGCTGAAACAGTGCCACGATGCCAGATATTAGG\nTCATAAATATGAACTTTTTTTTTTTGAGATGGAGTCTTGCTCTGTTGCCCAGGCTGCAGTGCAGTGGCACAATCTCAGCTCACTGCAGCCTCCGCCTCCCAGGCTC\nAAGCAATTCTCCTGCCTCAGCCTCCTGAGTAGCTAGGATTACAGATACCCACCACCATGCCCGGCTAATTTTTGTATTTTTAGTAGAGACAGGGTTTCACCATGTT\nGGCCAGGCTGGTCTCGAACTCCTGGCCTTAAGTGATCTGCCCACCTCTGCCTTCCAAAGTGCTGGGATTACAGGCCTGAGCCATCGCGCCTGGCTATAAGTATGAA\nCTTTTAAGAATCTAGAAATGAGGCCCTCCAAAAAGAGATGAGCTGGTAACAGAGCCGAACACACAGAAAATAGTTTCAGGAAGGGCCTGGGCAGAGGAAGGCCTAA\nTAAGCAAGGAAGCCACAAACATGTAGCCCAGCAATACACACACACAAACAATTCCTACATGCAGAGCCCTTTAGGAATGGCAGACCTTTGTTTCTACAACAGATGA\nAGCTGTGAATAGCCTAAAGAACACTTGCTCCTGGGGGTGGCCTGTAGAGTGTCATAAAAGTCTGAATAAAACGGGCTGGGTGGAGCTGGATGATCACGTGTGTGGT\nTCCACAGGGTGAAGACAGCATCCGGTTCACAGTCACAGGTTCGTGTGTAAGGCGTGCATGTGGAGAAACGCCTTTGAGGAAAAGGCGTGTGAAAGGGTCTTTGGGG\nGGGACGGGCTAGACACAGGCTCAGAGAAGTGGATGGTTCTCAGGATGCAGATGAGTGTGGTAACTGGAGTCTAAATCCAGTGGTAAGACTGTGCTGTCAAGAGACA\nCTGGGGTGACACAGGGCAAATGGAGGCAGAAGAGCAGGTCCCACCTGAAGAAGGGCTCAGGGGCTGGAATCTAGGGCAGGAACTAGCCTGAGAGCCTGCCACAGGC\nTGGTATGGTGCCATCTTAAGCAGGAAGAACTCGCACAAGCCCCTACCCAGGGGTGGAGTGCTGTGGTGACTGTGGGCACCCAGAGACACCCCAGGGAGGATTGGCT\nGAGGGGGAAAGGAGGAGATTCACTGGACCTGATACCCCTCCGCCTAAGATGGGGGGCTCTACTGGATGGACTCTGAAGCTAGGATGGGATCCTAAAGTGGCTCTGT\nTTGCCCCGTGCCACCCTGTCCTAACATGGGACCTACAAGCGGGCCCTGCCCTGCCCAGGGCCCAGGAAGCTCTCCCCGCTCCTATGTCTGTTTCCCTCCCAGGTCC\nACTCACCCCCATGAGACTCAAAGGCCCTTTCAGGACAAAGACAATCGCTTCACCATTTCTTCTTCAACTCCTGGCACAGAGTCTGGCCACTGGGAGACACCCAGCC\nAATAAGGCAAGGGAGAGAGGACTGAGGAGGGAAGGGGGCAGATCAAGTGATGAGAAGATCCCTCTTTAGAATCAGGTGGGGGCCTCGCACAGAAAGGGCGGCCTCC\nCCCACAGGAACCCCAGGGCAGGTCCAGAGCAGCAGGAAGGAGGAGGCGGCCAATGGGAAGGCAACCGAGCCCCAGGGACACACTGCGTCCATCGTGGCTCCTGAGG\nGATGGGCCACCCACTTCCGACCCCGGCCACTAGAACCTGCTTTCAGTTTGTTTATGCTCCTGAGCACTGGGGGTCCTCAGCCCCTCTCTTCCCTCAAGGAGGCTGT\nTGTCTCTTGGTTCCTGCTGTGGGGCAGCTATGAATTTACGATGCCAGGGCTGATTGAGGACATTCATCAGGATATCGGGGAAAAGAATGGAGAATCAAAACAGTAA\nGAAAAAAGTCTGAAATACCTTCCAAGTCTATTTCATAGCCTTGGAAAACATAACAATAAATTTACTTTATGTCTACCTTTGAAAATTATCTTAACATAGATGCCAA\nTTTCAAACCCTCCCAGTACTGGGAGACAAATGGCATACTGGTTTCTCACAAGCCTCCTTCATTCATCTGCTAACTGTGAAGGCCTCATCTCTGAACGCCCAGGGCC\nGGGCACCGTGCCTGGATCAGGCAGGATGCTCAATACGCGGTTGTGAGATGAGTAACAGGCAGACACCGTAGAACCAGCACTTGATGAGGCCTGCTGATT...\n\nHow would you do it:\n- L2: Sequence alignment: O(m*n)\n- L3: Hashing / BLAST: O(m+n)\n- Solution until 2008 (e.g. MAQ, Li et al, GR 2008)\n- Other advanced algorithms:\n- Linear-time string matching: O(m+n). L3 addendum\n- Suffix trees and suffix arrays: O(m). L13 addendum\n- Challenge: memory requirements\n- Hash table, suffix tree/array require O(m*n) space\n- Today: Burrows-Wheeler transformation O(m)\n- Ultrafast/memory efficient. New norm since 2009.\n- Introduced in: Bowtie (Langmead GB 2009).\n\nSecond Generation Mappers have Leveraged the\nBurrows Wheeler Transformation\n\"...35 times faster than Maq and 300 times\nfaster than SOAP under the same conditions\"\n(c) Various copyright holders. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nHashing vs. Burrows Wheeler Transform\n\nMulti-seed\nhashing\nBWT\nBurrows-\nWheeler\nTransform\nToday: How does the BW\ntransform actually work?\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Trapnell, Cole and Steven L. Salzberg. \"How to map billions of short\nreads onto genomes.\" Nature Biotechnology 27, no. 5 (2009): 455.\n\nBurrows-Wheeler Transform (BWT)\n\n- Transform: ^BANANA@ INTO: BNN^AA@A\n\n- Reversible\n\nfunction inverseBWT (string s)\ncreate empty table\nrepeat length(s) times\ninsert s as a column of table before first column of the table // first insert creates first column\nsort rows of the table alphabetically\nreturn (row that ends with the 'EOF' character)\nfunction BWT (string s)\ncreate a table, rows are all possible rotations of s\nsort rows alphabetically\nreturn (last column of the table)\nlast\n1st\ncol\npairs\n2nd\ncol\ntriples\n3rd\ncol\n4mers 4thcol 5mers\n5thcol 6-mers\n6thcol\n7-mers\n7thcol\n8-mers\nFull matrix\nLast column only suffices to reconstruct entire matrix, and thus recover original string\nhttp://www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-124.pdf\n\nP is the input substring\nC[c] - is how many characters occur\nbefore c lexographically in the\ngenome\nOcc(c,k) is the number of\noccurrence of the character c before\nindex k in the far right column\nSearching for an Exact Match\n\ne.g. Searching for OLIS\nIn MANOLISKELLIS\nFor simplicity (here):\n- only exact matches\n- Show entire matrix\nIn practice: only pointers\n1. $MANOLISKELLIS\n2. ANOLISKELLIS$M\n3. ELLIS$MANOLISK\n4. IS$MANOLISKELL\n5. ISKELLIS$MANOL\n6. LIS$MANOLISKEL\n7. LISKELLIS$MANO\n8. LLIS$MANOLISKE\n9. KELLIS$MANOLIS\n10.MANOLISKELLIS$\n11.NOLISKELLIS$MA\n12.OLISKELLIS$MAN\n13.S$MANOLISKELLI\n14.SKELLIS$MANOLI\n\nPseudocode from Langmead et al, 2009. Example by Jason Ernst.\n1. $MANOLISKELLIS\n2. ANOLISKELLIS$M\n3. ELLIS$MANOLISK\n4. IS$MANOLISKELL\n5. ISKELLIS$MANOL\n6. LIS$MANOLISKEL\n7. LISKELLIS$MANO\n8. LLIS$MANOLISKE\n9. KELLIS$MANOLIS\n10.MANOLISKELLIS$\n11.NOLISKELLIS$MA\n12.OLISKELLIS$MAN\n13.S$MANOLISKELLI\n14.SKELLIS$MANOLI\n\n1. $MANOLISKELLIS\n2. ANOLISKELLIS$M\n3. ELLIS$MANOLISK\n4. IS$MANOLISKELL\n5. ISKELLIS$MANOL\n6. LIS$MANOLISKEL\n7. LISKELLIS$MANO\n8. LLIS$MANOLISKE\n9. KELLIS$MANOLIS\n10.MANOLISKELLIS$\n11.NOLISKELLIS$MA\n12.OLISKELLIS$MAN\n13.S$MANOLISKELLI\n14.SKELLIS$MANOLI\n\n1. $MANOLISKELLIS\n2. ANOLISKELLIS$M\n3. ELLIS$MANOLISK\n4. IS$MANOLISKELL\n5. ISKELLIS$MANOL\n6. LIS$MANOLISKEL\n7. LISKELLIS$MANO\n8. LLIS$MANOLISKE\n9. KELLIS$MANOLIS\n10.MANOLISKELLIS$\n11.NOLISKELLIS$MA\n12.OLISKELLIS$MAN\n13.S$MANOLISKELLI\n14.SKELLIS$MANOLI\n\nOLIS\nOLIS\nOLIS\nOLIS\n\nHashing vs. Burrows Wheeler Transform\n\nMulti-seed\nhashing\nBWT\nBurrows-\nWheeler\nTransform\nToday: How does the BW\ntransform actually work?\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Trapnell, Cole and Steven L. Salzberg. \"How to map billions of short\nreads onto genomes.\" Nature Biotechnology 27, no. 5 (2009): 455.\n\nKey properties of Burrows-Wheeler Transform\n- Very little memory usage. Same as input (or less)\n- Don't represent matrix, or strings, just pointers\n- Encode: Simply sort pointers. Decode: follow pointers\n- Original application: string compression (bZip2)\n- Runs of letters compressed into (letter, runlength) pairs\n- Bioinformatics applications: substring searching\n- Achieve similar run time as hash tables, suffix trees\n- But: very memory efficient practical speed gains\n- Mapping 100,000s of reads: only transform once\n- Pre-process once; read counts in transformed space.\n- Reverse transform once, map counts to genome coords\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nQuality control metrics\nChIP vs. Input DNA\nRead quality\nMappability\nLibrary complexity\n\nSignal Generation\n(read extension and mappability correction)\nMotif Discovery\nUniform Peak Calling Pipeline\nMapped reads\nSegmentation\nSelf Organising Maps\nChromHMM/Segway\nENCODE uniform processing pipeline)\nSignal Aggregation\nover elements\nCo-association\nanalysis\nPoor reproducibility\nGood reproducibility\nRep1\nRep2\nIDR Processing, Quality control and Blacklist Filtering\n(c) sources unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nQC1: Use of input DNA as control dataset\n- Challenge:\n- Even without antibody: Reads are not uniformly scattered\n- Sources of bias in input dataset scatter:\n- Non-uniform fragmentation of the genome\n- Open chromatin fragmented more easily than closed regions\n- Repetitive sequences over-collapsed in the assembled genome.\n- How to control for these biases:\n- Remove portion of DNA sample before ChIP step\n- Carry out control experiment without an antibody (input DNA)\n- Fragment input DNA, sequence reads, map, use as background\nsignal\nbackground\n(c) sources unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nQC2: Read-level sequencing quality score Q>10\nRead quality histograms\n-\nEach column is a color-coded\nhistogram\n-\nEncodes fraction of all mapped\nreads that have base score Q\n(y-axis) at each position (x-\naxis)\n-\nDarker blue = higher density\n\n-\nRead quality tends to drop\ntowards the ends of reads\n-\nLow average per base score\nimplies greater probabilty of\nmismappings.\n\n-\nTypically, reject reads whose\naverage score Q < 10\naverage base score\nper position\nHigh quality reads\nLow quality reads\n\nQC3: Fraction of short reads mapped >50%\nReads can map to:\n-\nexactly one location (uniquely mapping)\n-\nmultiple locations (repetitive or multi-mapping)\n-\nno locations (unmappable)\n\nDealing with multiply-mapping reads:\n-\nConservative approach: do not assign to any location\n-\nProbabilistic approach: assign fractionally to all locations\n-\nSampling approach: pick one location at random, averages across many reads\n-\nEM approach: map according to density, estimated from unambiguous reads\n-\nPair-end approach: use paired end read to resolve ambiguities in repeat reads\n\nAbsence of reads in a region could be due to:\n-\nNo assembly coverage in that region (e.g. peri-centromeric region)\n-\nToo many reads mapping to this location (e.g. repetitive element)\n-\nNo activity observed in this location (e.g. inactive / quiescent / dead regions)\n\nDealing with mappability biases:\n-\n'Black-listed' regions, promiscuous across many datasets\n-\n'White-listed' regions, for which at least some dataset has unique reads\n-\nTreat unmappable regions as missing data, distinguish from 'empty' regions\nGACTACCTTTACCT\nACCT\nGACT\nTTTT\nunique\nmultiple\nnone\n\nQC4: Library complexity: non-redundant fraction\nLibrary complexity\nHow many distinct uniquely mapping read? How many duplicates?\nIf your sample does not contain sufficient DNA and/or you over-sequence, you\nwill simply be repeatedly sequencing PCR duplicates of a restricted pool of\ndistinct DNA fragments. This is known a low-complexity library and is not\ndesirable.\n\n-\nHistogram of no. of duplicates\n-\nNon-redundant fraction (NRF) = No. of 'distinct' unique-mapping reads\nNo. of unique-mapping reads\n-\nNRF should be > 0.8 when 10M < #reads < 80M unique-mapping reads\nNo. of duplicates\nNo. of distinct reads\nM1/M2 should be large\nM1\nM2\n(c) sources unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nCross-correlation analysis\nExploiting forward and reverse reads\nFragment-length peak\nPhantom read-length peak\n\nChIP-seq: exploiting forward and reverse reads\n(Chromatin immunoprecipitation followed by sequencing)\nMultiple IP fragments are obtained\ncorresponding to each binding event\n\nEnds of the fragments are sequenced i.e.\n\"Short-reads/tags\"\n- Typically ~36 bp, 50 bp, 76 bp or 101 bp\n\nSingle-end (SE) sequencing\n- Randomly sequence one of the ends of\neach fragment\n\nPaired-end (PE) sequencing\n- sequence both ends of each fragment\n\nCanonical \"stranded mirror distribution of\nshort-reads\" after mapping reads to genome\n- Heaps of reads on the + strand and - strand\nseparated by a distance ~= fragment length\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Park, Peter J. \"ChIP-seq: advantages and challenges of a\nmaturing technology.\" Nature Reviews Genetics 10, no. 10 (2009):\n669-680.\n\n(b)\ns = f/2 + f/2\n(c)\n(d)\nStrand cross-correlation (CC) analysis\nstrand shift (s)\nf\nf\n(a)\ncross-correlation\nf = fragment length\na\nb\nc\nd\n1. Calculate forward and reverse strand signals\n2. Shift both by specified offset towards each other\n3. Calculate correlation of two signals at that shift\n4. Correlation peaks at fragment length offset f\n\nf is the length at which ChIP DNA is fragmented\n\nCross-correlation at read vs. fragment length\nstrand shift (s)\ncross-correlation (CC)\nCCf\nmin(CC)\nCCr\nf = fragment length\nr = read length\nread\nfragment\n- Sign of a good dataset:\n- High absolute cross-correlation at fragment length (NSC)\n- High fragment length CC relative to read length CC (RSC)\n\n- Input dataset (no ChIP) shows 'phantom' peak at read length only\n- Due to read mappability:\n- If position 'x' is uniquely mappable on + strand\n- Then position 'x+r-1' is uniquely mappable on - strand\n- Fragment-length peak should always dominate the read-length peak\nx\nx+r-1\nWhere does read cross-correlation come from?\nMappable\nregion\nUnmappable\nUnmappable\n\nExample of good, medium, bad CC datasets\nFor highly enriched datasets, fragment length cross-correlation peak should be\nable to beat read-length phantom peak\nCCf\nCCr\nmin(CC)\nstrand shift\nstrand shift\nstrand shift\ncross-correlation\nHighly quality\nMedium quality\nLow quality\nRSC should be > 1\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nPeak Calling\nContinuous signal Intervals\n\nPeak calling: detect regions of enrichment\nGoal: Transform read counts into normalized intensity signal\nSteps:\n1. Estimate fragment-length f using strand cross-correlation analysis\n2. Extend each read from 5' to 3' direction to fragment length f\n3. Sum intensity for each base in 'extended reads' from both strands\n4. Perform same operation on input-DNA control data (correct for\nsequencing depth differences)\n5. Calculate enrichment ratio value for every position in the genome\nResult: Enrichment fold difference for ChIP / control signal\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nPeak calling: identify discrete intervals\nCourtesy of the authors. License: CC BY.\nSource: Wilbanks, Elizabeth G. and Marc T. Facciotti. \"Evaluation of algorithm\nperformance in ChIP-seq peak detection.\" PLOS ONE 5, no. 7 (2010): e11471.\n\nPeak calling thresholds\nPoisson p-value thresholds\n-\nRead count model: Locally-adjusted' Poisson distribution\nPcount= x= λlocal\nx\nexp -λlocal\nx!\n\n-\nλlocal = max(λBG, [λ1k,] λ5k, λ10k) estimated from control data\n-\nPoisson p-value = Pcount≥x\n-\nq-value : Multiple hypothesis correction\n\nPeaks: Genomic locations that pass a user-defined p-value (e.g. 1e-5)\nor q-value (e.g. 0.01) threshold\n\nEmpirical False discovery rates\n-\nSwap ChIP and input-DNA tracks\n-\nRecomputep-values\n-\nAt each p-value, eFDR = Number of control peaks / Number of ChIPpeaks\n-\nUse an FDR threshold to call peaks\n\nIssues with peak calling thresholds\nCannot set a universal threshold for empirical\nFDRs and p-values\n-\nDepends on ChIP and input sequencing\ndepth\n-\nDepends on binding ubiquity of factor\n-\nStronger antibodies get an advantage\n\nFDRs quite unstable\n-\nSmall changes in threshold => massive\nchanges in peak numbers\n\nDifficult to compare results across peak callers\nwith a fixed threshold\n-\nDifferent methods to compute eFDR or q-\nvalues\n# peaks called by SPP\n# peaks called by MACS\n(at FDR = 1% cutoff)\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nSelecting meaningful peaks using\nreproducibility\nUse peak ranks in replicate experiments\nIDR: Irreproducible Discovery Rate\nA. Kundaje, Q. Li , B. Brown, J. Rozowsky, S. Wilder, M. Gerstein, I. Dunham, E. Birney, P. Bickel\nhttp://anshul.kundaje.net/projects/idr\n\nHow to combine two replicates\n- Challenge:\n- Replicates show small differences in peak heights\n- Many peaks in common, but many are unique\n- Problem with simple solutions:\n- Union: too lenient, keeps garbage from both\n- Intersection: too stringent, throws away good peaks\n- Sum: does not exploit independence of two datasets\nReplicate 1\nReplicate 2\n\nIDR idea: Exploit peak rank similarity in replicates\n-\nKey idea: True peaks will be highly ranked in both replicates\n-\nKeep going down rank list, until ranks are no longer\ncorrelated\n-\nThis cutoff could be different for the two replicates\n-\nThe actual peaks included may differ between replicates\n-\nAdaptively learn optimal peak calling threshold\n-\nFDR threshold of 10% 10% of peaks are false (widely\nused)\n-\nIDR threshold of 10% 10% of peaks are not reproducible\nIDR Cutoff\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nThe IDR model: A two component\nmixture model\n- Looking only at ranks means that the\nmarginals are uniform, so all the information\nis encoded in the joint distribution.\n- Model the joint distribution of ranks as\nthough it came from a two component\nGaussian mixture model:\n\n- This can be fit via an EM-like algorithm.\n)\n0,1,1,0,0\n(\n)\n1(\n)\n,\n,\n,\n,\n(\n~\n)\n,\n(\nN\np\npN\ny\nx\n\nFDR = False Discovery Rate\n# peaks called by SPP\n# peaks called by MACS\nIDR = Irreproducible Discovery Rate\n# peaks called by SPP\n# peaks called by MACS\nIDR leads to higher consistence between peak callers\n-\nCompare number of peaks found by two different peak callers\n-\nIDR thresholds are far more robust and comparable than FDR\n-\nFDR only relies on enrichment over input, IDR exploits replicates\n(at IDR = 1% cutoff)\n(at FDR = 1% cutoff)\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nWhat if we don't have good replicates?\n-\nIDR pipeline uses replicates when they are available\n-\nIDR pipeline also evaluates each replicate individually\n-\nPooling strategy to generate pseudo-replicates\nCan pin-point 'bad' replicates that may lead to low reproducibility\nCan estimate IDR thresholds when replicates are not available\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nOnly one good replicate: Pseudo-replicates\n- IDR pipeline can be used to rescue datasets with only\none good replicate (using pseudo-replicates)\n- IDR pipeline can also be used to call optimal thresholds\non a dataset with a single replicate (e.g. when there\nisn't enough material to perform multiple reps)\nRescued\ndatasets\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nChromatin signatures for genome annotation\n- Challenges\n- Dozens of marks\n- Complex combinatorics\n- Diversity and dynamics\n- Histone code hypothesis\n- Distinct function for distinct\ncombinations of marks?\n- Both additive and\ncombinatorial effects\n- How do we find biologically\nrelevant ones?\n-\nUnsupervised approach\n-\nProbabilistic model\n-\nExplicit combinatorics\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Qiu, Jane. \"Epigenetics: Unfinished Symphony.\" Nature\n441, no. 7090 (2006): 143-145.\n\nSummarize multiple marks into chromatin states\nChromHMM: multi-variate hidden Markov model\nWashU Epigenome Browser\n30+ epigenomics marks\nChromatin state track summary\n(c) WashU Epigenome Browser. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMultivariate HMM for Chromatin States\nTranscription\nStart Site\n\nEnhancer\nDNA\nObserved\nchromatin\nmarks. Called\nbased on a\npoisson\ndistribution\nMost likely\nHidden State\nTranscribed Region\n1:\n3:\n4:\n5:\n6:\nHigh Probability Chromatin Marks in State\n2:\n0.8\n0.9\n0.9\n0.8\n0.7\n0.9\n200bp\nintervals\nAll probabilities are\nlearned from the data\nK4me3\nK36me3\nK36me3\nK36me3 K36me3\nK4me1\nK4me3\nK4me1\nK27ac\n0.8\nK4me1\nK36me3\nK27ac\nK4me1\nK4me3\nK4me3\nK4me1\nK4me1\nErnst and Kellis\nNature Biotech 2010\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nDesign Choice\n- How to model the emission distribution\n- Model the signal directly\n- Locally binarize the data\n- For M input marks each state k has a vector of\n(pk1,...,pkM) of parameters for independent\nBernoulli random variables which determine\nthe emission probability for an observed\ncombination of marks\n\nData Binarization\n- Leads to biologically interpretable models that can be\nrobustly learned\n- Let cij be the number of reads for mark i. mapping to\nbin j. λi be the average number of reads mapping to a\nbin for modification i. The input for feature i becomes\n'1' if\nP(X>cij)<10-4\nwhere X is a Poisson random variable with mean λi\n\nEmission Parameter Matrix ek( xi )\nErnst and Kellis\nNature Biotech 2010\n- Multi-variate HMM\nemits vector of\nvalues, not just\none value\n- Can emit real\nvalues (SegWay)\nor binary presence\n/absence values\n(ChromHMM)\n- Use to learn mark\ncombinations\n\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nTransition matrix akl\n- Learns spatial\nrelationships\nbetween\nneighboring\nstates\n- Reveals distinct\nsub-groups of\nstates\n- Reveals\ntransitions\nbetween different\ngroups\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nExample Chromatin State Annotation\n- Use Baum\nWelch to learn\nhidden states\nand their\nannotations\n- Learned states\ncorrespond to\nknown\nfunctional\nelements\n- De novo\ndiscovery of\nmajor types of\nchromatin\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nModel complexity matches that of genome\n- Handful of\nrepressed states\ncapture vast\nmajority of\ngenome\n\n- Only 1% of\ngenome split\nin 14\npromoter\nstates\n- Modeling power\nwell distributed\nwhere needed\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nApply genome wide to classify chromatin states de novo\nX\nY\nNow what? Interpret these states biologically\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nChromatin state characterization: Functional/positional enrichment\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nState definitions State Enrichments\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nFunctional enrichments enable annotation of 51 distinct states\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nApplication of ChromHMM to 41 chromatin marks in CD4+ T-cells (Barski'07, Wang'08)\nPromoter states\nTranscribed states\nActive Intergenic\nRepressed\nRepetitive\n\nZNF repressed state recovery\nState 28: 112-fold ZNF enrich\nFunctional properties of discovered chromatin states\nGO Category State 3 State 4 State 5\nState 6\nState 7\nState 8\nCell Cycle\nPhase\n2.10\n(2x10-7)\n0.57\n(1)\n1.61\n(0.001)\n1.45\n(1)\n1.15 (1)\n1.51 (1)\nEmbryonic\nDevelopment 1.24 (1)\n2.82\n(9x10-23) 1.07 (1)\n0.85 (1)\n0.54 (1)\n1.00 (1)\nChromatin\n1.20 (1) 0.48 (1)\n2.2\n(1.4x10-7) 1.64 (1)\n0.85 (1)\n0.85 (1)\nResponse to\nDNA Damage\nStimulus\n1.20 (1) 0.35 (1)\n1.55\n(0.074)\n2.13\n(6.5x10-11)\n1.97\n(1.0x10-4)\n0.84 (1)\nRNA\nProcessing 0.49 (1) 0.26 (1) 1.31 (1)\n1.91\n(4.2x10-11)\n2.64\n(8.7x10-24)\n2.45\n(3.0x10-4)\nT cell\nActivation\n0.77 (1) 0.88 (1) 1.27 (1)\n0.70 (1)\n0.79 (1)\n4.72\n(2x10-7)\nPromoter state gene GO function\n\"The achievement of the repressed\nstate by wild-type KAP1 involves\ndecreased recruitment of RNA\npolymerase II, reduced levels of\nhistone H3 K9 acteylation and\nH3K4 methylation, an increase in\nhistone occupancy, enrichment of\ntrimethyl histone H3K9, H3K36,\nand histone H4K20 ...\" MCB 2006.\nTranscription End State\nState 27\nPromoter vs. enhancer regulation\n\nTF binding\nMotif enrichment\nenhancers\npromoters\nState 10kb away predictive of expr.\nState 30\nDistinct types of repression\n- Chrom bands / HDAC resp\n- Repeat family / composition\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nApplications to genome annotation\nNew protein-coding genes\nIn promoter(short)/low-expr states\nChromatin signature:\npromoter / transcribed\nEvolutionary signature:\nnot protein-coding\nlincRNAs\nKnown coding\nEvolutionary CSF score\nLong intergenic non-coding RNAs/lincRNAs\nAssign candidate functions to intergenic SNPs\nfrom genome-wide association studies\nNew developmental enhancer regions\nBing Ren, Eddy Rubin\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nTSS\nFalse Positive Rate\nFalse Positive Rate\nTrue Positive Rate\n- Significantly outperforms single-marks\n- Similar power to supervised learning approach\n- CAGE experiments give possible upper bound\nDiscovery power for promoters, transcripts\nTranscribed genes\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nCapturing dependencies. State-conditional mark independence\n-\nSelecting the number of states, selecting number of marks\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nState-conditional mark independence\nDo hidden states actually capture\ndependencies between marks?\n\nPairwise Expected vs. Observed Mark Co-Occurence\nEach point = one pair of chromatin marks\n41x41 pairs plotted\nX-axis: F(mark1)*F(mark2)\nY-axis: F(mark1 & mark2)\nDiagonal: independence\nOff-diag: dependence\nk\nPi\npj\nMulti-variate HMM emits entire vector of marks at a time\nModel assumes mark independence *conditional* upon state\nIn fact, it specifically seeks to *capture* these dependencies\nTest each\npair of\nchromatin\nmarks\nqi,j=pi*pj\n?\npi emission prob\nfor mark i\nqi,j freq w/ which\nmarks i and j\nco-occur\nMarks become\nconditionally\nindependent\nModel captures\ndependencies\n\nTest conditional independence for each state\nPromoter states\nTranscribed states\n\nNon-independence reveals cases of model violation\n- Repetitive states show more dependencies\n- Conditional independence does not hold\n\nAs more states are added, dependencies captured\n- With only 5 states\nin HMM, not enough\npower to\ndistinguish\ndifferent properties\nDependencies\nremain\n- As model\ncomplexity\nincreases, states\nlearned become\nmore precise\nDependencies\ncaptured\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nCapturing dependencies. State-conditional mark independence\n-\nSelecting the number of states, selecting number of marks\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nComparison of BIC Score vs. Number of States for Random and Nested Initialization\nStep 1: Learn a larger model that captures 'all' relevant states\nStep 2: Prune down model greedily eliminating least informative states\nStep 3: Select arbitrary cutoff\nbased on biological interpretation\nResult: a 51-state model that captures most biology in least complexity\n- Standard model selection criteria fail due to genome complexity: more states always preferred\n- Instead: Start w/complex model, keep informative states, prune redundant states. Pick cutoff\n\nRecovery of 79-state model in random vs. nested initialization\nRandom Initialization\nNested Initialization\nSelected 51-state model\n(states appear & disappear)\n(states consistly recoverd)\nNested initialization approach:\n- First pass: learn models of increasing complexity\n- Second pass: form nested set of emission parameter initializations\nby greedily removing states from best BIC model found\nNested models criteria:\n- Maximize sum of correlation of emission vectors with nested model\n- Models learned in parallel\n\nFunctional recovery with increasing numbers of states\n-\nRed: Maximum fold functional enrichment for corresponding biological category\n-\nBlue: Percent of that functional category that overlaps regions annotated to this state\n-\nTop plot: Correlation of emission parameter vector for that state to closest state\n\nZinc Finger state\nSimple Repeat state\nTranscription End State\n\nChromatin state recovery with increasing numbers of marks\nState Inferred with all 41 marks\nRecovery of states with increasing\nnumber of marks\nIncreasing numbers of marks (greedy)\nState Inferred with subset of marks\nState confusion matrix with 11 ENCODE marks\nState Inferred with all 41 marks\nPrecisely what mistakes are made?\n(for a given subset of 11 ENCODE marks)\nWhich states are well-recovered?\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nENCODE: Study nine marks in nine human cell lines\n9 human cell types\n9 marks\nH3K4me1\nH3K4me2\nH3K4me3\nH3K27ac\nH3K9ac\nH3K27me3\nH4K20me1\nH3K36me3\nCTCF\n+WCE\n+RNA\nHUVEC\nUmbilical vein endothelial\nNHEK\nKeratinocytes\nGM12878\nLymphoblastoid\nK562\nMyelogenous leukemia\nHepG2\nLiver carcinoma\nNHLF\nNormal human lung fibroblast\nHMEC\nMammary epithelial cell\nHSMM\nSkeletal muscle myoblasts\nH1\nEmbryonic\nx\n81 Chromatin Mark Tracks\n(281 combinations)\nErnst et al, Nature 2011\nBrad Bernstein ENCODE Chromatin Group\nHow to learn\nsingle set of\nchromatin states?\n(c) Brad Bernstein. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nSolution 1: Learn independent models and cluster\nInsulator\nCandidate\nenhancer\nPromoter\nTranscribed\nRepressive\nRepetitive\nBasic approach:\na) Train a k-state model in\neach cell type\nindependently\nb) Cluster models\nlearned independently\nc) Merge clusters and re-\napply to each cell type\n\nHow to cluster\na) Using emission probability\nmatrix: most similar\ndefinitions\nb) Using genome annotation:\nposterior probability\ndecoding\n\nJoint learning of states across multiple cell types\nSolution 2: Stacking\n- Learns each combination of\nactivity as a separate state\n- Ex: ES-specific enhancers:\nenhancer marks in ES, no\nmarks in other cell types\nCell type 1\nCell type 2\nCell type 3\nCell type 4\nCell type 5\nCell type 6\nCell type 7\nCell type 8\nCell type 9\nCell type 1\nCell type 2\nCell type 9\n(...)\nSolution 3: Concatenation\n- Requires that profiled marks\nare the same (or treat as\nmissing data)\n- Ensures common state\ndefinitions across cell types\n\nJoint learning with different subsets of marks (Solution 3)\nOption (a) Treat missing tracks as missing data\n- EM framework allows for unspecified data points\n- As long as pairwise relationship observed in some cell type\n\nOption (b) Chromatin mark imputation\n- Explicitly predict max-likelihood chromatin track for missing data\n- Less powerful if ultimate goal is chromatin state learning\nCell type 1\nCell type 2\nCell type 9\n(...)\nMissing\nMissing\nMissing\nMissing\n\nENCODE: Study nine marks in nine human cell lines\n9 human cell types\n9 marks\nH3K4me1\nH3K4me2\nH3K4me3\nH3K27ac\nH3K9ac\nH3K27me3\nH4K20me1\nH3K36me3\nCTCF\n+WCE\n+RNA\nHUVEC\nUmbilical vein endothelial\nNHEK\nKeratinocytes\nGM12878\nLymphoblastoid\nK562\nMyelogenous leukemia\nHepG2\nLiver carcinoma\nNHLF\nNormal human lung fibroblast\nHMEC\nMammary epithelial cell\nHSMM\nSkeletal muscle myoblasts\nH1\nEmbryonic\nx\n81 Chromatin Mark Tracks\n(281 combinations)\nErnst et al, Nature 201\nBrad Bernstein ENCODE Chromatin Group\nConcatenation\napproach:\n- Learned jointly\nacross cell types\n- State definitions\nare common\n- State locations\nare dynamic\n(c) Brad Bernstein. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n\nChromatin states dynamics across nine cell types\n- Single annotation track for each cell type\n- Summarize cell-type activity at a glance\n- Can study 9-cell activity pattern across\nCorrelated\nactivity\nPredicted\nlinking\n(c) Brad Bernstein. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nAdult tissues and cells (brain, muscle, heart,\ndigestive, skin, adipose, lung, blood...)\nFetal tissues (brain, skeletal muscle, heart,\ndigestive, lung, cord blood...)\nES cells, iPS, differentiated cells\n(meso/endo/ectoderm, neural, mesench...)\nEpigenomic mapping across 100+ tissues/cell types\nHistone modifications\n- H3K4me3, H3K4me1, H3K36me3\n- H3K27me3, H3K9me3, H3K27/9ac\n- +20 more\nOpen chromatin:\n- DNA accessibility\nDNA methylation:\n- WGBS, RRBS, MRE/MeDIP\nGene expression\n- RNA-seq, Exon Arrays\nDiverse tissues and cells\nDiverse epigenomic assays\nx\nCourtesy of NIH Roadmap Epigenomics Mapping Consortium. Used with permission.\nCourtesy of Broad Communications. Used with permission.\n\nStates show distinct mCpG, DNase, Tx, Ac profiles\nTssA vs. TssBiv: diff. activity, both open, both unmethylated!\nEnh vs. ReprPC: diff. activity, both intermediate DNase/Methyl\nTx: Methylated, closed, actively transcribed\nDistinct modes of repression: H3K27me3 vs. DNAme vs. Het\nDNA methylation\nDNA accessibility\n0%\n100%\n(DNaseI, 53 epigenomes\n(WGBS, 37 epigenomes)\nAli Moussavi\nClosed\nOpen\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nChromosomal 'domains' from chromatin state usage\n- State usage gene density, lamina, cytogenetic bands\n- Quies/ZNF/het | gene rich/poor, each active/repressed\n\nMisha Bilenky\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nH3K4me1 phylogeny reveals common biology\n-\nGrouping of ES, immune, brain, muscle, heart, smooth muscle, fetal\nWouter Meuleman\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nCells/Tissues at extremes of epigenomic variation\n- ES/Immune/IMR90 most extreme\n- ES: Biv, Enh/Tx/TssFlnk/PCwk\n- Immune: TssA, TxWk\n- IMR90: ReprPC, Quies\nMisha Bilenky, Wouter Meuleman\nH3K4me1 MDS\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nChromatin state annotations across 127 epigenomes\nReveal epigenomic variability: enh/prom/tx/repr/het\nAnshul Kundaje\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nState switching: active/inactive, mostly keep identity\n- Most variable: Enhancers. Least: TssA/Tx/Quies\n- State switching: Active (1-7)Inactive (10-15)\n- Exception: Dyadic regions: enhancerpromoter\nAnshul Kundaje / Wouter Meuleman\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nChromatin state changes during differentiation\n- Epigenomic features can predict directionality: AUC 78%\n- TSS-proximal: (1) Loss of Het/ZNF. (2) Gain of TxWk, Quies\n- TSS-distal: Bivalent, PCrepressed Enhancer, Tx, TssFlnk\nForward\nBackward\nTSS-proximal\nTSS-distal\nClassify cells\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nEpigenome imputation by exploiting mark correlations\n- Two types of features\n- Other marks + context in same tissue\n- Same mark in 'closest' tissues\n- Impute missing datasets\n- Predict DNase, marks @ 25bp res\n- Predict RNA-Seq @ 25 bp res\n- Predict DNA methylation @ 1bp res\nJason Ernst\nObserved\nImputed\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\n5. Correlation-based links of enhancer networks\nRegulators Enhancers Target genes\n\nChromatin state annotations across 127 epigenomes\nReveal epigenomic variability: enh/prom/tx/repr/het\nAnshul Kundaje\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human epigenomes.\" Nature 518, no. 7539\n(2015): 317-330.\n\n2.3M enhancer regions only ~200 activity patterns\n\nWouter Meuleman\nimmune\ndev/morph\nmorph\nlearning\nmuscle\n<3\nsmooth\nmuscle\nkidney\nliver\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nLink enhancers to target genes\nIntroducing multi-cell activity profiles\nHUVEC\nNHEK\nGM12878\nK562\nHepG2\nNHLF\nHMEC\nHSMM\nH1\nGene\nexpression\nChromatin\nStates\nActive TF motif\nenrichment\nON\nOFF\nActive enhancer\nRepressed\nMotif enrichment\nMotif depletion\nTF regulator\nexpression\nTF On\nTF Off\nDip-aligned\nmotif biases\nMotif aligned\nFlat profile\n\nFinding correct target of enhancer in divergently transcribed genes\nHMEC state\nIRF6\nexpression\nC1orf107\nexpression\n-1.6\n4.2\n3.7\n-1.6\n0.9\n-1.7\n-1.6\n-1.7\n-0.7\n0.1\n0.4\n0.3\n-0.1\n0.5\n-1.3\n0.0\n1.2\n-1.1\nH3K27ac signal\nCompute correlations between gene expression levels and\nenhancer associated histone modification signals\n?\n?\nActivity-based linking of enhancers to target genes\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nVisualizing 10,000s predicted enhancer-gene links\n- Overlapping regulatory units, both few and many\n- Both upstream and downstream elements linked\n- Enhancers correlate with sequence constraint\n\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nChromatin dynamics: linking enhancer networks\nTFs enhancers target genes\n\nLink TFs to target enhancers\nPredict activators vs. repressors\nIntroducing multi-cell activity profiles\nHUVEC\nNHEK\nGM12878\nK562\nHepG2\nNHLF\nHMEC\nHSMM\nH1\nGene\nexpression\nChromatin\nStates\nActive TF motif\nenrichment\nON\nOFF\nActive enhancer\nRepressed\nMotif enrichment\nMotif depletion\nTF regulator\nexpression\nTF On\nTF Off\nDip-aligned\nmotif biases\nMotif aligned\nFlat profile\n\nEx2: Gfi1 repressor of\nK562/GM cells\nEx1: Oct4 predicted activator\nof embryonic stem (ES) cells\nCoordinated activity reveals activators/repressors\n- Enhancer networks: Regulator enhancer target gene\nActivity signatures for each TF\nEnhancer activity\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Ernst, Jason et al. \"Mapping and analysis of chromatin state\ndynamics in nine human cell types.\" Nature 473, no.7345 (2011): 43-49.\n\nRegulatory motifs predicted to drive enhancer modules\n- Activator and repressor motifs consistent with tissues\nPouya Kheradpour\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nCausal motifs supported by dips & enhancer assays\nDip evidence of TF binding\n(nucleosome displacement)\nEnhancer activity halved\nby single-motif disruption\nMotifs bound by TF, contribute to enhancers\nTarjei Mikkelsen\nPredicted causal HNF motifs\n(that also showed dips)\nin HepG2 enhancers\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Ernst, Jason et al. \"Mapping and analysis of chromatin state\ndynamics in nine human cell types.\" Nature 473, no.7345 (2011): 43-49.\n\nGoals for today: Computational Epigenomics\n1.\nIntroduction to Epigenomics\n-\nOverview of epigenomics, Diversity of Chromatin modifications\n-\nAntibodies, ChIP-Seq, data generation projects, raw data\n2.\nPrimary data processing: Read mapping, Peak calling\n-\nRead mapping: Hashing, Suffix Trees, Burrows-Wheeler Transform\n-\nQuality Control, Cross-correlation, Peak calling, IDR (similar to FDR)\n3.\nDiscovery and characterization of chromatin states\n-\nA multi-variate HMM for chromatin combinatorics\n-\nPromoter, transcribed, intergenic, repressed, repetitive states\n4.\nModel complexity: selecting the number of states/marks\n-\nSelecting the number of states, selecting number of marks\n-\nCapturing dependencies and state-conditional mark independence\n5.\nLearning chromatin states jointly across multiple cell types\n-\nStacking vs. concatenation approach for joint multi-cell type learning\n-\nDefining activity profiles for linking enhancer regulatory networks\n(Future: Chromatin states to interpret disease-associated variants)\n\nGenotype\nDisease\nGWAS\nInterpret variants using reference states\n- Chromatin states: Enhancers, promoters, motifs\n- Enrichment in individual loci, across 1000s of SNPs in T1D\nInterpreting disease-association signals\nCATGACTG\nCATGCCTG\nEpigenome changes in disease\n- Molecular phenotypic changes in patients vs. controls\n- Small variation in brain methylomes, mostly genotype-driven\n- 1000s of brain-specific enhancers increase methylation in Alzheimer's\nmQTLs\nMWAS\nEpigenome\n\nGWAS hits in enhancers of relevant cell types\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human\nepigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n\nT cells\nB cells\nDigestive\nBrain\nES\nLiver\nHeart\nLinking traits to their relevant cell/tissue types\n\nHaploReg: systematic mining of GWAS variants\n-\nStart with any list of SNPs or select a GWA study\n- Mine ENCODE and Roadmap epigenomics data for hits\n- Hundreds of assays, dozens of cells, conservation, motifs\n- Report significant overlaps and link to info/browser\n-\nTry it out: http://compbio.mit.edu/HaploReg Ward, Kellis NAR 2011\nCourtesy of the authors. License: CC BY-NC.\nSource: Ward, Lucas D. and Manolis Kellis. \"HaploReg: a resource for exploring chromatin states, conservation, and regulatory\nmotif alterations within sets of genetically linked variants.\" Nucleic Acids Research 40, no. D1 (2012): D930-D934.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 1 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/67001fcd838c877dabf796f143a032fc_MIT6_047F15_Lecture01.pdf",
      "content": "(c) Various sources. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComputational Biology:\nGenomes, Networks, Evolution\n\nMIT 6.047 / 6.878\nHSPH IMI.231\nHST.507\n\nI. Administrivia\n\n!\n\"#\n$\n\nIntroductions\n% !\n& '\n()*+ ,-.+-/\n& .\n\n,0 ++10+\n1, +\"\n. +\n\nCourse Information\n% *\n& , &$9\n%\n& :7.$,\n& ()<)\" #/\n%\n& :+,3 䇾;98?* 䇿\n@;98?A\n>\n- All handouts, lectures, notes, etc will be posted here.\n\nGoals for the term\n% ,3.\n& 7 ,3 ,3.\n&\n<\n\nB6.\n&\n6 0, ,\n& Chow\n\n% 3.\n\n& \"3 B\n\n& \"\n\n5D, <\n& 7,# D,\n,, .,\n\n,6 6 6 (+/\n;\n\nCourse content\n?\n\nComputation & Biology | Foundations & Frontiers\n%\n2.E(D5D/ ,-.\n& $%&%'(\n,3 ,3\n&\n\nB+, ,\n%\n2.E(.5D/77\n&\n& 56,3 +\n\n& 䇺\n䇻6\n& )\n& 5,\n,D+ ,3 +,B\n& 3\nB\n& ,,# +\n\nF\n\nCourse organized around bio/comp modules\n% 1\n, 06\n\n& )*&')#'+'%,\n%-\n& )\").#/0%'%\n& 1)')2'%\"%%.\n& 3)4)%- (% (%5\"!\n& )2&)\n('(%&('%6,%(\n& 7))\n+,%1,'%\n%8(\n% 7\n& 2. , +\n+\n\n++1+\n33) ,++6 +7 +\n)G+7+D57 +,\n. +<\n, +0. +=)+ ,,\n% 7\n)\n& 10.+ ,.+ H+H\n6 .+1, +\n\n.+\n+\n3.+$2\nI\n\nTextbook / class notes / resources\n\n(Optional) Books for the Course\n,%2(%' %\n9%\n&:\n03.-C,+ (JK895;9/\n\n-C13\n,%-%8\n(c) Cambridge University Press. All rights reserved.This\n\n(c) Wiley-Interscience. All rights reserved. This\ncontent is excluded from our Creative Commons license.\n\ncontent is excluded from our Creative Commons\nFor more information, see http://ocw.mit.edu/help/faq- !\"!#$$%&'(\n\nlicense. For more information, see http://ocw.mit\nfair-use/.\n.edu/help/faq-fair-use/.\nCourtesy of The MIT Press. Used with permission.\n\nNew this year!! Book for the Course\n03.:\"27\n*;'()\n%.%2&\n\n;98?<;F?F\n\nL3 ,\n.\n<(=\n3..M\nL .+ .M\n$\n\nLectures and Scribing\n% 1\n\n0 3\n\n& \", 36\n\n,\n% -6 ,0.\n& 03 3\n% ,66 336,0\n& C䇻\n6 ,0.(\n/\n% 766 3;.6\n& N,\n,0 6\n,0. ,\n% ) , 3\n% ) 35.\n# 3\n& 16+6 +.+ +M\n\nScribing details - DropBox 6047_book LaTex\n\n>\n\nSign up here if you haven't already\n;\n\nOnline material from last year\n)+++ ' >\n?\n\nLecture feedback:\nN\n0, 5>\n\n.,5>\n$ !.6,\n&\n!.65>\n&\n6.6D,5>\n&\nC66 5>\n&\n=BB.5>\n8 \"\n&\n266 .6\n.5#\n\n&\n6 05#\n\n&\n\" 6\n5#\n> ,\n(6\n, /\n&\nQ9R+9589R+895;9R+;95F9R+SF9R\n\nF\n\nHomeworks and quiz\nI\n\nDetails on Problem sets\n% 1\n,3 ,\n(/\n& \" ,3 D,\nB+\n++ ..+,\n.+33\n06,3 <\n\n&\n,3 ,<,,+D,\n<\n<\n, <,\n\n(., .0 ,3 6;F?F/\n% 2.F,\n& *, .6D3+06\n\n& 6\n+, +\nD., .+D ,,\n% )3\n\n& H36.䇻00\n+.\n\n.< 0<\n\nDetails on the in-class quiz\n% 䇻 +䇻6D\n& 䇻B+6.+6++ +6.\n% 2 .6\n& C., ,\n\n& C30\n,\n& 3.,,.0, ,3\n% .,6B\n& 'B<7#6.+ ,\n\n& 2,B\n\n& \" ,3\n\n,\n\n& 2,3 (/< 6\n+\n+\n\nFinal Project\n\nFinal Project: Original Research in Comp Bio\n% #, 6\n,,.6\n\n,3.\n& 7 3 ,3 ,.\n&\n& )0\n+\n\n& ,\n3 .\n% 3.,.\n\n& 6\n,,(6\n,</\n& = 6 , .\n& 0,,,+66+ ,0\n& 063 0.,,\n& =,. 6 ,,6\n& \"\n% ,# D,\n,\n$\n\nIt's a team project\n% \" 66 .,M\n% 7 .\n, .D,\n\nFinal Project at a Glance\n\n?'\n\n?@\n\n73 䇻\n>\n\nDetails on the final project\n% 66 ,<63\n& )5,6,#\n.\n& , .\n& ,.䇻,# + ,,\n& \",3\n+03+D,\n& ,+,+\n+6\n% \"\n& ), 0.\n& ,\n+ +63\n& \"50\n.3,,,+ 0\n63 <+, B+#\n% 5D, +\n& <6\n,,,+,0+..,+\n3 <66+ 3+,,+0\n;\n\nFinding a research mentor / research advisor\n%\n6 .<-<0\n&\n\n& , ,, 0\n\n& 1D,(/\n,0 +(/\nH+($/ 3 +(8/ ,,+\n+0 .(66 /\n%\n,\n& : + H+. 6++\n, +,\n. (\n/\n&\n,\n,-,\n% N,\nD,\n& 3+\n& 0\n+6\n& 0+3\n\n?\n\nPutting it all together\nF\n\nCourse Grading\n%\n\n% 8,3\n& 1\n,3 ?59R+ 0$58 + $58,3\n&\n,3 , (\")/\n& 0 ,3\n\n% 7,#\n&\n,3.(?M/\n& ,50H5.,,\n% !\n& 5 B(H0>/H6D\n% 3, .\n& 3+3.\n% =,.\n,3 36\n% =.\n% 3H\n\n1A\n\n?3A\nA\n8A\nI\n\nWhy Computational Biology ?\n$9\n\nWhy Computational Biology: Last year䇻䇻s answers\n%\n*6(T6/\n%\n\n%\n\"6\n䇻\n%\nall 3\n%\n3.0\n%\n) + ,\n,\n%\nU06.(\n.,\n6/\n%\n\",\n<\n.D,30\n%\nH< 3603\n%\n166 .( D, , 0/\n%\n6 6 (3. 3/\n%\n+\n\n,\n%\n. 6\n.,\n\n%\n*66C\n$\n\nTATTGAATTTTCAAAAATTCTTACTTTTTTTTTGGATGGACGCAAAGAAGTTTAATAATCATATTACATGGCATTACCACCATATA\nATCCATATCTAATCTTACTTATATGTTGTGGAAATGTAAAGAGCCCCATTATCTTAGCCTAAAAAAACCTTCTCTTTGGAACTTTC\nAATACGCTTAACTGCTCATTGCTATATTGAAGTACGGATTAGAAGCCGCCGAGCGGGCGACAGCCCTCCGACGGAAGACTCTCCTC\nGCGTCCTCGTCTTCACCGGTCGCGTTCCTGAAACGCAGATGTGCCTCGCGCCGCACTGCTCCGAACAATAAAGATTCTACAATACT\nTTTTATGGTTATGAAGAGGAAAAATTGGCAGTAACCTGGCCCCACAAACCTTCAAATTAACGAATCAAATTAACAACCATAGGATG\nATGCGATTAGTTTTTTAGCCTTATTTCTGGGGTAATTAATCAGCGAAGCGATGATTTTTGATCTATTAACAGATATATAAATGGAA\nCTGCATAACCACTTTAACTAATACTTTCAACATTTTCAGTTTGTATTACTTCTTATTCAAATGTCATAAAAGTATCAACAAAAAAT\nTAATATACCTCTATACTTTAACGTCAAGGAGAAAAAACTATAATGACTAAATCTCATTCAGAAGAAGTGATTGTACCTGAGTTCAA\nTAGCGCAAAGGAATTACCAAGACCATTGGCCGAAAAGTGCCCGAGCATAATTAAGAAATTTATAAGCGCTTATGATGCTAAACCGG\nTTGTTGCTAGATCGCCTGGTAGAGTCAATCTAATTGGTGAACATATTGATTATTGTGACTTCTCGGTTTTACCTTTAGCTATTGAT\nGATATGCTTTGCGCCGTCAAAGTTTTGAACGAGAAAAATCCATCCATTACCTTAATAAATGCTGATCCCAAATTTGCTCAAAGGAA\nCGATTTGCCGTTGGACGGTTCTTATGTCACAATTGATCCTTCTGTGTCGGACTGGTCTAATTACTTTAAATGTGGTCTCCATGTTG\nACTCTTTTCTAAAGAAACTTGCACCGGAAAGGTTTGCCAGTGCTCCTCTGGCCGGGCTGCAAGTCTTCTGTGAGGGTGATGTACCA\nGGCAGTGGATTGTCTTCTTCGGCCGCATTCATTTGTGCCGTTGCTTTAGCTGTTGTTAAAGCGAATATGGGCCCTGGTTATCATAT\nCAAGCAAAATTTAATGCGTATTACGGTCGTTGCAGAACATTATGTTGGTGTTAACAATGGCGGTATGGATCAGGCTGCCTCTGTTT\nGTGAGGAAGATCATGCTCTATACGTTGAGTTCAAACCGCAGTTGAAGGCTACTCCGTTTAAATTTCCGCAATTAAAAAACCATGAA\nAGCTTTGTTATTGCGAACACCCTTGTTGTATCTAACAAGTTTGAAACCGCCCCAACCAACTATAATTTAAGAGTGGTAGAAGTCAC\nAGCTGCAAATGTTTTAGCTGCCACGTACGGTGTTGTTTTACTTTCTGGAAAAGAAGGATCGAGCACGAATAAAGGTAATCTAAGAG\nTCATGAACGTTTATTATGCCAGATATCACAACATTTCCACACCCTGGAACGGCGATATTGAATCCGGCATCGAACGGTTAACAAAG\nCTAGTACTAGTTGAAGAGTCTCTCGCCAATAAGAAACAGGGCTTTAGTGTTGACGATGTCGCACAATCCTTGAATTGTTCTCGCGA\nATTCACAAGAGACTACTTAACAACATCTCCAGTGAGATTTCAAGTCTTAAAGCTATATCAGAGGGCTAAGCATGTGTATTCTGAAT\nTAAGAGTCTTGAAGGCTGTGAAATTAATGACTACAGCGAGCTTTACTGCCGACGAAGACTTTTTCAAGCAATTTGGTGCCTTGATG\nGAGTCTCAAGCTTCTTGCGATAAACTTTACGAATGTTCTTGTCCAGAGATTGACAAAATTTGTTCCATTGCTTTGTCAAATGGATC\nTGGTTCCCGTTTGACCGGAGCTGGCTGGGGTGGTTGTACTGTTCACTTGGTTCCAGGGGGCCCAAATGGCAACATAGAAAAGGTAA\nAAGCCCTTGCCAATGAGTTCTACAAGGTCAAGTACCCTAAGATCACTGATGCTGAGCTAGAAAATGCTATCATCGTCTCTAAACCA\nTTGGGCAGCTGTCTATATGAATTATAAGTATACTTCTTTTTTTTACTTTGTTCAGAACAACTTCTCATTTTTTTCTACTCATAACT\nGCATCACAAAATACGCAATAATAACGAGTAGTAACACTTTTATAGTTCATACATGCTTCAACTACTTAATAAATGATTGTATGATA\nTTTTCAATGTAAGAGATTTCGATTATCCACAAACTTTAAAACACAGGGACAAAATTCTTGATATGCTTTCAACCGCTGCGTTTTGG\nCCTATTCTTGACATGATATGACTACCATTTTGTTATTGTACGTGGGGCAGTTGACGTCTTATCATATGTCAAAGTCATTTGCGAAG\nTTGGCAAGTTGCCAACTGACGAGATGCAGTAAAAAGAGATTGCCGTCTTGAAACTTTTTGTCCTTTTTTTTTTCCGGGGACTCTAC\nAACCCTTTGTCCTACTGATTAATTTTGTACTGAATTTGGACAATTCAGATTTTAGTAGACAAGCGCGAGGAGGAAAAGAAATGACA\nAAATTCCGATGGACAAGAAGATAGGAAAAAAAAAAAGCTTTCACCGATTTCCTAGACCGGAAAAAAGTCGTATGACATCAGAATGA\nATTTTCAAGTTAGACAAGGACAAAATCAGGACAAATTGTAAAGATATAATAAACTATTTGATTCAGCGCCAATTTGCCCTTTTCCA\nTCCATTAAATCTCTGTTCTCTCTTACTTATATGATGATTAGGTATCATCTGTATAAAACTCCTTTCTTAATTTCACTCTAAAGCAT\nCCATAGAGAAGATCTTTCGGTTCGAAGACATTCCTACGCATAATAAGAATAGGAGGGAATAATGCCAGACAATCTATCATTACATT\nGCGGCTCTTCAAAAAGATTGAACTCTCGCCAACTTATGGAATCTTCCAATGAGACCTTTGCGCCAAATAATGTGGATTTGGAAAAA\nTATAAGTCATCTCAGAGTAATATAACTACCGAAGTTTATGAGGCATCGAGCTTTGAAGAAAAAGTAAGCTCAGAAAAACCTCAATA\nCTCATTCTGGAAGAAAATCTATTATGAATATGTGGTCGTTGACAAATCAATCTTGGGTGTTTCTATTCTGGATTCATTTATGTACA\nAGGACTTGAAGCCCGTCGAAAAAGAAAGGCGGGTTTGGTCCTGGTACAATTATTGTTACTTCTGGCTTGCTGAATGTTTCAATATC\nACTTGGCAAATTGCAGCTACAGGTCTACAACTGGGTCTAAATTGGTGGCAGTGTTGGATAACAATTTGGATTGGGTACGGTTTCGT\nTGCTTTTGTTGTTTTGGCCTCTAGAGTTGGATCTGCTTATCATTTGTCATTCCCTATATCATCTAGAGCATCATTCGGTATTTTCT\n$\n\nTATTGAATTTTCAAAAATTCTTACTTTTTTTTTGGATGGACGCAAAGAAGTTTAATAATCATATTACATGGCATTACCACCATATA\nATCCATATCTAATCTTACTTATATGTTGTGGAAATGTAAAGAGCCCCATTATCTTAGCCTAAAAAAACCTTCTCTTTGGAACTTTC\nAATACGCTTAACTGCTCATTGCTATATTGAAGTACGGATTAGAAGCCGCCGAGCGGGCGACAGCCCTCCGACGGAAGACTCTCCTC\nGCGTCCTCGTCTTCACCGGTCGCGTTCCTGAAACGCAGATGTGCCTCGCGCCGCACTGCTCCGAACAATAAAGATTCTACAATACT\nTTTTATGGTTATGAAGAGGAAAAATTGGCAGTAACCTGGCCCCACAAACCTTCAAATTAACGAATCAAATTAACAACCATAGGATG\nATGCGATTAGTTTTTTAGCCTTATTTCTGGGGTAATTAATCAGCGAAGCGATGATTTTTGATCTATTAACAGATATATAAATGGAA\nCTGCATAACCACTTTAACTAATACTTTCAACATTTTCAGTTTGTATTACTTCTTATTCAAATGTCATAAAAGTATCAACAAAAAAT\nTAATATACCTCTATACTTTAACGTCAAGGAGAAAAAACTATAATGACTAAATCTCATTCAGAAGAAGTGATTGTACCTGAGTTCAA\nTAGCGCAAAGGAATTACCAAGACCATTGGCCGAAAAGTGCCCGAGCATAATTAAGAAATTTATAAGCGCTTATGATGCTAAACCGG\nTTGTTGCTAGATCGCCTGGTAGAGTCAATCTAATTGGTGAACATATTGATTATTGTGACTTCTCGGTTTTACCTTTAGCTATTGAT\nGATATGCTTTGCGCCGTCAAAGTTTTGAACGAGAAAAATCCATCCATTACCTTAATAAATGCTGATCCCAAATTTGCTCAAAGGAA\nCGATTTGCCGTTGGACGGTTCTTATGTCACAATTGATCCTTCTGTGTCGGACTGGTCTAATTACTTTAAATGTGGTCTCCATGTTG\nACTCTTTTCTAAAGAAACTTGCACCGGAAAGGTTTGCCAGTGCTCCTCTGGCCGGGCTGCAAGTCTTCTGTGAGGGTGATGTACCA\nGGCAGTGGATTGTCTTCTTCGGCCGCATTCATTTGTGCCGTTGCTTTAGCTGTTGTTAAAGCGAATATGGGCCCTGGTTATCATAT\nCAAGCAAAATTTAATGCGTATTACGGTCGTTGCAGAACATTATGTTGGTGTTAACAATGGCGGTATGGATCAGGCTGCCTCTGTTT\nGTGAGGAAGATCATGCTCTATACGTTGAGTTCAAACCGCAGTTGAAGGCTACTCCGTTTAAATTTCCGCAATTAAAAAACCATGAA\nAGCTTTGTTATTGCGAACACCCTTGTTGTATCTAACAAGTTTGAAACCGCCCCAACCAACTATAATTTAAGAGTGGTAGAAGTCAC\nAGCTGCAAATGTTTTAGCTGCCACGTACGGTGTTGTTTTACTTTCTGGAAAAGAAGGATCGAGCACGAATAAAGGTAATCTAAGAG\nTCATGAACGTTTATTATGCCAGATATCACAACATTTCCACACCCTGGAACGGCGATATTGAATCCGGCATCGAACGGTTAACAAAG\nCTAGTACTAGTTGAAGAGTCTCTCGCCAATAAGAAACAGGGCTTTAGTGTTGACGATGTCGCACAATCCTTGAATTGTTCTCGCGA\nATTCACAAGAGACTACTTAACAACATCTCCAGTGAGATTTCAAGTCTTAAAGCTATATCAGAGGGCTAAGCATGTGTATTCTGAAT\nTAAGAGTCTTGAAGGCTGTGAAATTAATGACTACAGCGAGCTTTACTGCCGACGAAGACTTTTTCAAGCAATTTGGTGCCTTGATG\nGAGTCTCAAGCTTCTTGCGATAAACTTTACGAATGTTCTTGTCCAGAGATTGACAAAATTTGTTCCATTGCTTTGTCAAATGGATC\nTGGTTCCCGTTTGACCGGAGCTGGCTGGGGTGGTTGTACTGTTCACTTGGTTCCAGGGGGCCCAAATGGCAACATAGAAAAGGTAA\nAAGCCCTTGCCAATGAGTTCTACAAGGTCAAGTACCCTAAGATCACTGATGCTGAGCTAGAAAATGCTATCATCGTCTCTAAACCA\nTTGGGCAGCTGTCTATATGAATTATAAGTATACTTCTTTTTTTTACTTTGTTCAGAACAACTTCTCATTTTTTTCTACTCATAACT\nGCATCACAAAATACGCAATAATAACGAGTAGTAACACTTTTATAGTTCATACATGCTTCAACTACTTAATAAATGATTGTATGATA\nTTTTCAATGTAAGAGATTTCGATTATCCACAAACTTTAAAACACAGGGACAAAATTCTTGATATGCTTTCAACCGCTGCGTTTTGG\nCCTATTCTTGACATGATATGACTACCATTTTGTTATTGTACGTGGGGCAGTTGACGTCTTATCATATGTCAAAGTCATTTGCGAAG\nTTGGCAAGTTGCCAACTGACGAGATGCAGTAAAAAGAGATTGCCGTCTTGAAACTTTTTGTCCTTTTTTTTTTCCGGGGACTCTAC\nAACCCTTTGTCCTACTGATTAATTTTGTACTGAATTTGGACAATTCAGATTTTAGTAGACAAGCGCGAGGAGGAAAAGAAATGACA\nAAATTCCGATGGACAAGAAGATAGGAAAAAAAAAAAGCTTTCACCGATTTCCTAGACCGGAAAAAAGTCGTATGACATCAGAATGA\nATTTTCAAGTTAGACAAGGACAAAATCAGGACAAATTGTAAAGATATAATAAACTATTTGATTCAGCGCCAATTTGCCCTTTTCCA\nTCCATTAAATCTCTGTTCTCTCTTACTTATATGATGATTAGGTATCATCTGTATAAAACTCCTTTCTTAATTTCACTCTAAAGCAT\nCCATAGAGAAGATCTTTCGGTTCGAAGACATTCCTACGCATAATAAGAATAGGAGGGAATAATGCCAGACAATCTATCATTACATT\nGCGGCTCTTCAAAAAGATTGAACTCTCGCCAACTTATGGAATCTTCCAATGAGACCTTTGCGCCAAATAATGTGGATTTGGAAAAA\nTATAAGTCATCTCAGAGTAATATAACTACCGAAGTTTATGAGGCATCGAGCTTTGAAGAAAAAGTAAGCTCAGAAAAACCTCAATA\nCTCATTCTGGAAGAAAATCTATTATGAATATGTGGTCGTTGACAAATCAATCTTGGGTGTTTCTATTCTGGATTCATTTATGTACA\nAGGACTTGAAGCCCGTCGAAAAAGAAAGGCGGGTTTGGTCCTGGTACAATTATTGTTACTTCTGGCTTGCTGAATGTTTCAATATC\nACTTGGCAAATTGCAGCTACAGGTCTACAACTGGGTCTAAATTGGTGGCAGTGTTGGATAACAATTTGGATTGGGTACGGTTTCGT\nTGCTTTTGTTGTTTTGGCCTCTAGAGTTGGATCTGCTTATCATTTGTCATTCCCTATATCATCTAGAGCATCATTCGGTATTTTCT\n\n,\n. 6\n\nD,\n$$\n\nTATTGAATTTTCAAAAATTCTTACTTTTTTTTTGGATGGACGCAAAGAAGTTTAATAATCATATTACATGGCATTACCACCATATA\nATCCATATCTAATCTTACTTATATGTTGTGGAAATGTAAAGAGCCCCATTATCTTAGCCTAAAAAAACCTTCTCTTTGGAACTTTC\nAATACGCTTAACTGCTCATTGCTATATTGAAGTACGGATTAGAAGCCGCCGAGCGGGCGACAGCCCTCCGACGGAAGACTCTCCTC\nGCGTCCTCGTCTTCACCGGTCGCGTTCCTGAAACGCAGATGTGCCTCGCGCCGCACTGCTCCGAACAATAAAGATTCTACAATACT\nTTTTATGGTTATGAAGAGGAAAAATTGGCAGTAACCTGGCCCCACAAACCTTCAAATTAACGAATCAAATTAACAACCATAGGATG\nATGCGATTAGTTTTTTAGCCTTATTTCTGGGGTAATTAATCAGCGAAGCGATGATTTTTGATCTATTAACAGATATATAAATGGAA\nCTGCATAACCACTTTAACTAATACTTTCAACATTTTCAGTTTGTATTACTTCTTATTCAAATGTCATAAAAGTATCAACAAAAAAT\nTAATATACCTCTATACTTTAACGTCAAGGAGAAAAAACTATAATGACTAAATCTCATTCAGAAGAAGTGATTGTACCTGAGTTCAA\nTAGCGCAAAGGAATTACCAAGACCATTGGCCGAAAAGTGCCCGAGCATAATTAAGAAATTTATAAGCGCTTATGATGCTAAACCGG\nTTGTTGCTAGATCGCCTGGTAGAGTCAATCTAATTGGTGAACATATTGATTATTGTGACTTCTCGGTTTTACCTTTAGCTATTGAT\nGATATGCTTTGCGCCGTCAAAGTTTTGAACGAGAAAAATCCATCCATTACCTTAATAAATGCTGATCCCAAATTTGCTCAAAGGAA\nCGATTTGCCGTTGGACGGTTCTTATGTCACAATTGATCCTTCTGTGTCGGACTGGTCTAATTACTTTAAATGTGGTCTCCATGTTG\nACTCTTTTCTAAAGAAACTTGCACCGGAAAGGTTTGCCAGTGCTCCTCTGGCCGGGCTGCAAGTCTTCTGTGAGGGTGATGTACCA\nGGCAGTGGATTGTCTTCTTCGGCCGCATTCATTTGTGCCGTTGCTTTAGCTGTTGTTAAAGCGAATATGGGCCCTGGTTATCATAT\nCAAGCAAAATTTAATGCGTATTACGGTCGTTGCAGAACATTATGTTGGTGTTAACAATGGCGGTATGGATCAGGCTGCCTCTGTTT\nGTGAGGAAGATCATGCTCTATACGTTGAGTTCAAACCGCAGTTGAAGGCTACTCCGTTTAAATTTCCGCAATTAAAAAACCATGAA\nAGCTTTGTTATTGCGAACACCCTTGTTGTATCTAACAAGTTTGAAACCGCCCCAACCAACTATAATTTAAGAGTGGTAGAAGTCAC\nAGCTGCAAATGTTTTAGCTGCCACGTACGGTGTTGTTTTACTTTCTGGAAAAGAAGGATCGAGCACGAATAAAGGTAATCTAAGAG\nTCATGAACGTTTATTATGCCAGATATCACAACATTTCCACACCCTGGAACGGCGATATTGAATCCGGCATCGAACGGTTAACAAAG\nCTAGTACTAGTTGAAGAGTCTCTCGCCAATAAGAAACAGGGCTTTAGTGTTGACGATGTCGCACAATCCTTGAATTGTTCTCGCGA\nATTCACAAGAGACTACTTAACAACATCTCCAGTGAGATTTCAAGTCTTAAAGCTATATCAGAGGGCTAAGCATGTGTATTCTGAAT\nTAAGAGTCTTGAAGGCTGTGAAATTAATGACTACAGCGAGCTTTACTGCCGACGAAGACTTTTTCAAGCAATTTGGTGCCTTGATG\nGAGTCTCAAGCTTCTTGCGATAAACTTTACGAATGTTCTTGTCCAGAGATTGACAAAATTTGTTCCATTGCTTTGTCAAATGGATC\nTGGTTCCCGTTTGACCGGAGCTGGCTGGGGTGGTTGTACTGTTCACTTGGTTCCAGGGGGCCCAAATGGCAACATAGAAAAGGTAA\nAAGCCCTTGCCAATGAGTTCTACAAGGTCAAGTACCCTAAGATCACTGATGCTGAGCTAGAAAATGCTATCATCGTCTCTAAACCA\nTTGGGCAGCTGTCTATATGAATTATAAGTATACTTCTTTTTTTTACTTTGTTCAGAACAACTTCTCATTTTTTTCTACTCATAACT\nGCATCACAAAATACGCAATAATAACGAGTAGTAACACTTTTATAGTTCATACATGCTTCAACTACTTAATAAATGATTGTATGATA\nTTTTCAATGTAAGAGATTTCGATTATCCACAAACTTTAAAACACAGGGACAAAATTCTTGATATGCTTTCAACCGCTGCGTTTTGG\nCCTATTCTTGACATGATATGACTACCATTTTGTTATTGTACGTGGGGCAGTTGACGTCTTATCATATGTCAAAGTCATTTGCGAAG\nTTGGCAAGTTGCCAACTGACGAGATGCAGTAAAAAGAGATTGCCGTCTTGAAACTTTTTGTCCTTTTTTTTTTCCGGGGACTCTAC\nAACCCTTTGTCCTACTGATTAATTTTGTACTGAATTTGGACAATTCAGATTTTAGTAGACAAGCGCGAGGAGGAAAAGAAATGACA\nAAATTCCGATGGACAAGAAGATAGGAAAAAAAAAAAGCTTTCACCGATTTCCTAGACCGGAAAAAAGTCGTATGACATCAGAATGA\nATTTTCAAGTTAGACAAGGACAAAATCAGGACAAATTGTAAAGATATAATAAACTATTTGATTCAGCGCCAATTTGCCCTTTTCCA\nTCCATTAAATCTCTGTTCTCTCTTACTTATATGATGATTAGGTATCATCTGTATAAAACTCCTTTCTTAATTTCACTCTAAAGCAT\nCCATAGAGAAGATCTTTCGGTTCGAAGACATTCCTACGCATAATAAGAATAGGAGGGAATAATGCCAGACAATCTATCATTACATT\nGCGGCTCTTCAAAAAGATTGAACTCTCGCCAACTTATGGAATCTTCCAATGAGACCTTTGCGCCAAATAATGTGGATTTGGAAAAA\nTATAAGTCATCTCAGAGTAATATAACTACCGAAGTTTATGAGGCATCGAGCTTTGAAGAAAAAGTAAGCTCAGAAAAACCTCAATA\nCTCATTCTGGAAGAAAATCTATTATGAATATGTGGTCGTTGACAAATCAATCTTGGGTGTTTCTATTCTGGATTCATTTATGTACA\nAGGACTTGAAGCCCGTCGAAAAAGAAAGGCGGGTTTGGTCCTGGTACAATTATTGTTACTTCTGGCTTGCTGAATGTTTCAATATC\nACTTGGCAAATTGCAGCTACAGGTCTACAACTGGGTCTAAATTGGTGGCAGTGTTGGATAACAATTTGGATTGGGTACGGTTTCGT\nTGCTTTTGTTGTTTTGGCCTCTAGAGTTGGATCTGCTTATCATTTGTCATTCCCTATATCATCTAGAGCATCATTCGGTATTTTCT\n$8\n\nTATTGAATTTTCAAAAATTCTTACTTTTTTTTTGGATGGACGCAAAGAAGTTTAATAATCATATTACATGGCATTACCACCATATA\nATCCATATCTAATCTTACTTATATGTTGTGGAAATGTAAAGAGCCCCATTATCTTAGCCTAAAAAAACCTTCTCTTTGGAACTTTC\nAATACGCTTAACTGCTCATTGCTATATTGAAGTACGGATTAGAAGCCGCCGAGCGGGCGACAGCCCTCCGACGGAAGACTCTCCTC\nGCGTCCTCGTCTTCACCGGTCGCGTTCCTGAAACGCAGATGTGCCTCGCGCCGCACTGCTCCGAACAATAAAGATTCTACAATACT\nTTTTATGGTTATGAAGAGGAAAAATTGGCAGTAACCTGGCCCCACAAACCTTCAAATTAACGAATCAAATTAACAACCATAGGATG\nATGCGATTAGTTTTTTAGCCTTATTTCTGGGGTAATTAATCAGCGAAGCGATGATTTTTGATCTATTAACAGATATATAAATGGAA\nCTGCATAACCACTTTAACTAATACTTTCAACATTTTCAGTTTGTATTACTTCTTATTCAAATGTCATAAAAGTATCAACAAAAAAT\nTAATATACCTCTATACTTTAACGTCAAGGAGAAAAAACTATAATGACTAAATCTCATTCAGAAGAAGTGATTGTACCTGAGTTCAA\nTAGCGCAAAGGAATTACCAAGACCATTGGCCGAAAAGTGCCCGAGCATAATTAAGAAATTTATAAGCGCTTATGATGCTAAACCGG\nTTGTTGCTAGATCGCCTGGTAGAGTCAATCTAATTGGTGAACATATTGATTATTGTGACTTCTCGGTTTTACCTTTAGCTATTGAT\nGATATGCTTTGCGCCGTCAAAGTTTTGAACGAGAAAAATCCATCCATTACCTTAATAAATGCTGATCCCAAATTTGCTCAAAGGAA\nCGATTTGCCGTTGGACGGTTCTTATGTCACAATTGATCCTTCTGTGTCGGACTGGTCTAATTACTTTAAATGTGGTCTCCATGTTG\nACTCTTTTCTAAAGAAACTTGCACCGGAAAGGTTTGCCAGTGCTCCTCTGGCCGGGCTGCAAGTCTTCTGTGAGGGTGATGTACCA\nGGCAGTGGATTGTCTTCTTCGGCCGCATTCATTTGTGCCGTTGCTTTAGCTGTTGTTAAAGCGAATATGGGCCCTGGTTATCATAT\nCAAGCAAAATTTAATGCGTATTACGGTCGTTGCAGAACATTATGTTGGTGTTAACAATGGCGGTATGGATCAGGCTGCCTCTGTTT\nGTGAGGAAGATCATGCTCTATACGTTGAGTTCAAACCGCAGTTGAAGGCTACTCCGTTTAAATTTCCGCAATTAAAAAACCATGAA\nAGCTTTGTTATTGCGAACACCCTTGTTGTATCTAACAAGTTTGAAACCGCCCCAACCAACTATAATTTAAGAGTGGTAGAAGTCAC\nAGCTGCAAATGTTTTAGCTGCCACGTACGGTGTTGTTTTACTTTCTGGAAAAGAAGGATCGAGCACGAATAAAGGTAATCTAAGAG\nTCATGAACGTTTATTATGCCAGATATCACAACATTTCCACACCCTGGAACGGCGATATTGAATCCGGCATCGAACGGTTAACAAAG\nCTAGTACTAGTTGAAGAGTCTCTCGCCAATAAGAAACAGGGCTTTAGTGTTGACGATGTCGCACAATCCTTGAATTGTTCTCGCGA\nATTCACAAGAGACTACTTAACAACATCTCCAGTGAGATTTCAAGTCTTAAAGCTATATCAGAGGGCTAAGCATGTGTATTCTGAAT\nTAAGAGTCTTGAAGGCTGTGAAATTAATGACTACAGCGAGCTTTACTGCCGACGAAGACTTTTTCAAGCAATTTGGTGCCTTGATG\nGAGTCTCAAGCTTCTTGCGATAAACTTTACGAATGTTCTTGTCCAGAGATTGACAAAATTTGTTCCATTGCTTTGTCAAATGGATC\nTGGTTCCCGTTTGACCGGAGCTGGCTGGGGTGGTTGTACTGTTCACTTGGTTCCAGGGGGCCCAAATGGCAACATAGAAAAGGTAA\nAAGCCCTTGCCAATGAGTTCTACAAGGTCAAGTACCCTAAGATCACTGATGCTGAGCTAGAAAATGCTATCATCGTCTCTAAACCA\nTTGGGCAGCTGTCTATATGAATTATAAGTATACTTCTTTTTTTTACTTTGTTCAGAACAACTTCTCATTTTTTTCTACTCATAACT\nGCATCACAAAATACGCAATAATAACGAGTAGTAACACTTTTATAGTTCATACATGCTTCAACTACTTAATAAATGATTGTATGATA\nTTTTCAATGTAAGAGATTTCGATTATCCACAAACTTTAAAACACAGGGACAAAATTCTTGATATGCTTTCAACCGCTGCGTTTTGG\nCCTATTCTTGACATGATATGACTACCATTTTGTTATTGTACGTGGGGCAGTTGACGTCTTATCATATGTCAAAGTCATTTGCGAAG\nTTGGCAAGTTGCCAACTGACGAGATGCAGTAAAAAGAGATTGCCGTCTTGAAACTTTTTGTCCTTTTTTTTTTCCGGGGACTCTAC\nAACCCTTTGTCCTACTGATTAATTTTGTACTGAATTTGGACAATTCAGATTTTAGTAGACAAGCGCGAGGAGGAAAAGAAATGACA\nAAATTCCGATGGACAAGAAGATAGGAAAAAAAAAAAGCTTTCACCGATTTCCTAGACCGGAAAAAAGTCGTATGACATCAGAATGA\nATTTTCAAGTTAGACAAGGACAAAATCAGGACAAATTGTAAAGATATAATAAACTATTTGATTCAGCGCCAATTTGCCCTTTTCCA\nTCCATTAAATCTCTGTTCTCTCTTACTTATATGATGATTAGGTATCATCTGTATAAAACTCCTTTCTTAATTTCACTCTAAAGCAT\nCCATAGAGAAGATCTTTCGGTTCGAAGACATTCCTACGCATAATAAGAATAGGAGGGAATAATGCCAGACAATCTATCATTACATT\nGCGGCTCTTCAAAAAGATTGAACTCTCGCCAACTTATGGAATCTTCCAATGAGACCTTTGCGCCAAATAATGTGGATTTGGAAAAA\nTATAAGTCATCTCAGAGTAATATAACTACCGAAGTTTATGAGGCATCGAGCTTTGAAGAAAAAGTAAGCTCAGAAAAACCTCAATA\nCTCATTCTGGAAGAAAATCTATTATGAATATGTGGTCGTTGACAAATCAATCTTGGGTGTTTCTATTCTGGATTCATTTATGTACA\nAGGACTTGAAGCCCGTCGAAAAAGAAAGGCGGGTTTGGTCCTGGTACAATTATTGTTACTTCTGGCTTGCTGAATGTTTCAATATC\nACTTGGCAAATTGCAGCTACAGGTCTACAACTGGGTCTAAATTGGTGGCAGTGTTGGATAACAATTTGGATTGGGTACGGTTTCGT\nTGCTTTTGTTGTTTTGGCCTCTAGAGTTGGATCTGCTTATCATTTGTCATTCCCTATATCATCTAGAGCATCATTCGGTATTTTCT\n1D 6\n$>\n\nThe components of genomes and gene regulation\n)#(/&'''')\n%\n\n,+< + 3.\n%\n\n\"5 D++5 H+H6\n%\n\n\" +\n++\n\n%\n\n. 6+\n\n5 3. ,\n%\n\n,6 +\n6+\n%\n\n.\n,3 .,+ 0,\n%\n\n+\n\"5B+ 0.\n%\n\n7< 6< 3+, 0\n%\n0 0.+,, + ,\n%\n10\"\n. +,\n. + +\n.\n%\n=)<!* 0 < ,\n.,\n%\n2\"(,/ +,\n+.\n3.\n$;\n\n$?\n\nCoupling each topic with foundational CS tools\nLect\nFundamental\nprobl\nbio\nem\nFoundational\ntool\ncomp.\n\n)B\n2. ,\n$\n\n8+>\n<<*<1\n;+?\n, .\n<1\nF+I\n.\n,\n\n+, .\n. 6\n6 <33) ,<1\n\n1,\n6 <\n$5; \",\n) 6\nF5I ,\n\"\n. <-.6\n$F\n\nOverview of the 5 modules\n$I\n\nChallenges in Computational Biology\n2H\n8 3.\n> . 6 0.\n23,\n$\nD,.\nF\nH ,\n)B\n\n10.\n.\n?\nTCATGCTAT\nTCGTGATAA\nTGAGGATAT\nTTATCATAT\nTTATGATTT\n0.\nI\n33 ,\n\".\n\n,0\n;\n1 ,,\n$\n\nModule 1: Aligning and Modeling Genomes\n%\n& 7 ,\n<3 ,\n& 7*0, +,B+\n\n& 2.6\n3 ,3 <6\nB\n% )B\n& * <3 6 500.0\n& 23\n.\n0 .\n% 0\n& 0(/)\n& 2 +0+,+\n+\n\nDynamic Programming Algorithms: Align, HMMs\n% )B\n[ಹಹಹಹಹಹಹಹಹಹ[0\n\\ಹಹಹಹಹಹಹಹಹಹ\\1\n[[[ಹಹಹಹಹಹಹಹಹಹಹಹಹಹಹ[1\n6WDWH\n\n.\nG(/\n% 0\n% 2\" ,\nB\n& \"00 , + ,3.\n& 7.D,D,\n, ,. M\n& .\n+3 5 +0\n& ), B :, 3\n& 7 ++,\n..+ +,,L\n\nModule II: Gene expression analysis and transcripts\n% ,6\n& C,0*1D, D\n& ),00< 0\n& ,,+6 +, ,\n\n% - 6\n& \") 0+ +,\n& *;<*? ,\n& *FD,. <\n& *I. 6 0.1+33 ,+6\n8$\n\n&\n䇺䇻\nH,, <\n\n*'\n*'\n) .,\n) .53\n0,6\n&' &\n\n*\n\n*\n\n+H99\n\n+H999\n\")\n(\n\n*\n\n+\n\n(011\n'1(12331\n\n(\n*(\n(\n75)8$\n9;#$$#<0%93%=\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Alizadeh, Ash A., Michael B. Eisen, R. Eric Davis, Chi Ma, Izidore S.Lossos, Andreas\nRosenwald, Jennifer C. Boldrick et al. \"Distinct types of diffuse large B-cell lymphoma\nidentified by gene expression profiling.\" Nature 403, no. 6769 (2000): 503-511.\n\n636 6 .,\n6.\n6.66,\n.\n\n'\n@''\n\n:'\n*\n*\n+H99\n\n\")\n(\n\n+H999\n*\n\n+\n\n(011\n'1(12331\nSource: Armstrong, Scott A. et al. \"MLL translocations specify\na distinct gene expression profile that distinguishes a unique\nleukemia.\" Nature Genetics 30, no. 1 (2002): 41-47.\n8>\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Alizadeh, Ash A., Michael B. Eisen, R. Eric Davis, Chi Ma, Izidore S.Lossos, Andreas\nRosenwald, Jennifer C. Boldrick et al. \"Distinct types of diffuse large B-cell lymphoma\nidentified by gene expression profiling.\" Nature 403, no. 6769 (2000): 503-511.\n\nModule III: Epigenomics and gene regulation\n% ,7\n& 0(/)\n& 2 +0+,+\n+\n& C,0*1D, D\n& ),00< 0\n% - 6\n& \") 0+ +,\n& *;<*? ,\n& *FD,. <\n& *I. 6 0.1+33 ,+6 8;\n\nMotifs summarize TF sequence specificity\n%\n)\n\n%\n.\n,\n\n%\n\n%\n0 6\n\n%\n,\n& ,\n& 7D,\n\n8?\n\nStarting positions\nMotif matrix\nsequence positions\nA\nC\nG\nT\n0.1\n0.1\n0.6\n0.2\n%\n0B . ,,6 D\n0.1\n0.5\n0.2\n0.2 0.3\n0.2\n0.2\n0.3\n0.2\n0.1\n0.5\n0.2 0.1\n0.1\n0.6\n0.2\n0.3\n0.2\n0.1\n0.4\n0.1\n0.1\n0.7\n0.1\n0.3\n0.2\n0.2\n0.3\nshared motif\n\ngiven profile matrix\n\n%\neasy to find starting position probabilities\n()$&' %'&\n(\nB' &) 'C\n8F\n\nMultivaria\nTrt\nanscription\ne HMM for Chromatin States\nStart Site\n\nEnhancer\nDNA\nObserved\nchromatin\nmarks. Called\nbased on a\npoisson\ndistribution\nMost likely\nHidden State\nTranscribed Region\n1:\n3:\n4:\n5:\n6:\nHigh Probability Chromatin Marks in State\n2:\n0.8\n0.9\n0.9\n0.8\n0.7\n0.9\n200bp\nintervals\nAll probabilities are\nlearned from the data\n'8 $\n'$; $\n'$; $\n'$; $ '$; $\n'8\n'8 $\n'8\n'?\n0.8\n'8\n'$; $\n'?\n'8\n'8 $\n'8 $\n'8\n'8\n.;\n8I\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\" Nature Biotechnology 28, no. 8 (2010): 817-825.\n\nModules IV and V: Evolution/phylogeny/populations\n% \"\n. <\"\n.\n& \"\n. 10. +3+\"\n.6\n& \"\n. <, + + +,,\n% \",\n& *,,\n.6 (20\n/\n& ) ,,,,(2./\n&\n,,(\")3/\n&\n\n3. 5 (N01\n/\n%\n䇻M*,H0+5 BH0\n& H38M\n6,# +\n0+7\n>9\n\nCharacterizing sub-threshold variants in heart arrhythmia\nTrait: QRS/QT interval\n(c) source unknown. All rights reserved. This content\nis excluded from our Creative Commons license. For\nmore information, see http://ocw.mit.edu/help/faq-\nfair-use/.\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Arking, Dan E. et al. \"Genetic association study of QT interval highlights role for calcium\nsignaling pathways in myocardial repolarization.\" Nature Genetics 46, no. 8 (2014): 826-836.\nFocus on sub-threshold variants\n(e.g. rs1743292 P=10-4.2)\n(1) Large cohorts, (2) many known hits\n(3) well-characterized tissue drivers\n>\n\nF\n-\n1H17*:=\nH\n\nEvidence of Neanderthal\n\nHuman gene flow\n\",,\nJ$>9.\n\nH\n\nF\n-\nH:\n1H17*:=\nG11\n\nJ>99.\n\nH56\nJF>.\nJ99.\nCourtesy of Luna04 on wikipedia.\nLicense: CC BY.\n\nCourtesy of Luna04 on wikipedia.\nLicense: CC BY.\n>\n\n% )3\n,0\n,, D\n% *, 6 0.\n\n,5\n\n%\n6 3\n0 ,.3\n303,\nQC 6\n\nQN 6\n\n, 6.666 3+\n\n,336.0\nStructure of genetic code\nevolutionary signatures\n\"\n'\n*\n\n+\n\n(011\n'1(12331\n>$\n\nDistance matrix Phylogenetic tree\nHum\nMou\nRat\nDog\nCat\nHuman\n>\n?\n;\nMouse\n\n.\n$\nF\n>\nRat\n\n.\n\nI\n?\nDog\n\nD\n.D\n.D\n\nCat\n\nD\n.D\n.D\n\nD\n\n.\n\n, .330 53\n, 2#\n\n,\nD\n#\n#(2#5#/\n>8\n\n'Peeling' algorithm for P(D|B,T) term\nsites j evolve independently\n\nbranch independence+ ,\n1D,#,33.,6\"(DVD,+/\n:.\"(D5/ +,+3 6B\n$ =\n,P(xi|xparent(i),ti)66D,\n263.B (O+'\"+'N+ /\n1. 6.0 6\n8 0marginalize\n) 0,306<\n*DU+L+D5,B65\n>>\n\nTwo types of gene-tree species-tree reconciliation\n\n-\n\n-\n\nCoalescence\nDuplication & Loss\n% Coalescent models of alleles in populations\nDeal with 1-to-1 orthologs\nEstimate divergence times, pop sizes, etc\nModels move backward in time\nCannot cope with duplication and loss\n\n;\n#\n*\n;\n#\n*\n% DL models of genes in species\nDeal with paralogous families\nEstimate birth death rates\nModels move forward in time\nCannot cope with incomplete\nlineage sorting\n,!*\n>;\n\n>?\n\nBiology primer\n! 3.\n6 6\n\n>F\n\n,.#\n.#\n\n䇾Central dogma䇿 of Molecular Biology\n>I\n\nDNA: The double helix\n\nDNA strands, shown both flat and twisted into a double helix.\nImage by MIT OpenCourseWare.\n\nDNA: the molecule of heredity\n%\n)65 , . 36\n.\n&\n'+ ,6\n\n&\n䇾\n,\n\n, 6 ,\n0, .\n,3 ,.\n䇿=W +I>$Chemical structure of DNA, still in double helix shape.\nDNA repres\nentation\nshowing do\nuble helix with\ncolored cyl\ninder\ns represent\ning base pair\ns.\nAt\nom\nic\ns\npa\nce\n-filling represe\nntatio\nn\nof\nD\nNA\nd\no\nu\nb l e\n\nh e\nl\ni\nx\n.\nImage by MIT OpenCourseWare.\n\nDNA: chemical details\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\n1䇻\n2䇻\n3䇻\n4䇻\n5䇻\nT\n%\n-\n\nA\n%\n\"\n-\n\n,\n\nW\n3 3\neak hydrogen bonds hold the\n\ntwo strands together\n-\nThis allows low-energy opening\nC\nand re-closing of two strands\nG\n-\nAnti-parallel strands\n-\nExtension 5䇻3䇻tri-\nT\nphosphate coming from\nA\nnewly added nucleotide\nThe only parings are:\nC\n-\nA with T\nG\n-\nC with G\n;\n\nDNA: the four bases\n\"\n\"\n\".\n\".\n=\n=\n)\n)\n\n'\n'\n;$\n\nAlignment: all species/genes share common ancestry\n) )6 -\n(c) Various sources. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\n;8\n\n(c) Neal Olander. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n;>\n\nTree of life\n\n(c) Neal Olander. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n;;\n\nExtinctions part of life\nPhylogenetic tree showing archosaurs, dinosaurs, birds, etc. through geologic time removed due to copyright restrictions.\n;?\n\nPhylogenetics\n\n)\n6 , .6\n6䇺?䇻3\n䇺䇻\n\n䇺J?䇻)), +\n+.,+2+\n+*+7\n+\n+\n).\n\n䇺\"䇻\nMammal family tree removed due to copyright restrictions.\n),\n+ +\nD,+73+ 6+L\n\n-&)7+ ,+\n6 0+䇺06䇻+\nB 6D , +,+\n\n\"()\"\n..D,\n'(,<\n<\n/\n;F\n\n,.#\n.#\n\n䇾Central dogma䇿 of Molecular Biology\n2'\n;I\n\nChromosomes inside the cell\nDrawing of\na prokaryotic and eukaryotic cell.\nFigures by MIT OpenCourseWare.\n\nDNA packaging\n% =\n.,\n& 2H0.\n& 0.\n% ,\n&\n>9+999\n\nImage removed due to copyright restrictions.\nPlease see: Figure 8-10 from Alberts, Bruce, and Martin Raff.\nD2H\nEssential Cell Biology. New York, NY: Garland Publishing Inc.,\n1997. ISBN: 0815320450.\n% C\n2H\n& -6, 62H\n6.\n+\n\n,\n, .\n% H\n& 6 3.\n& )\n& 6$2\n?\n\n20, 6\nCourtesy of the National Institutes of Health; in the public domain.\n\n,<<\n,\n0<, <\n? ˆˆ\n\nDiversity of epigenetic modifications\n%99U66\n%,$<8<<-\n%*.8('8/<'$;L\n%\n\n<\"\n<C3\n%H 355( $/\n%)\n\n$'8 $+-'>\n%\n%2H 6\n%\n.5,<\n.5\n2H,,\n\n,\n%H ,\n(c) source unknown. All rights reserved. This content\nis excluded from our Creative Commons license. For\n%2H 3.\nmore information, see http://ocw.mit.edu/help/faq-\nfair-use/\n%\n%7<\n< <7<\n,?$\n\nDiverse tissues and cells:\nEpigenomics Roadmap across 100+ tissues/cell types\nDiverse epigenomic assays:\n1.Adult tissues and cells (brain, muscle, heart, digestive, skin, adipose, lung, blood...)\n2.Fetal tissues (brain, skeletal muscle, heart, digestive, lung, cord blood...)\n3.ES cells, iPS, differentiated cells (meso/endo/ectoderm, neural, mesench, trophobl)\n1. Histone modifications\n% H3K4me3, H3K4me1\n% H3K36me3\nArt: Rae Senarighi, Richard Sandstrom\n% H3K27me3, H3K9me3\n% H3K27/9ac, +20 more\n2. Open chromatin:\n% DNase\nCourtesy of Macmillan Publishers Limited. Used with permission.\n3. DNA methylation:\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111\nreference human epigenomes.\" Nature 518, no. 7539 (2015): 317-330.\n% WGBS, RRBS, MRE/MeDIP\n4. Gene expression\n% RNA-seq, Exon Arrays\n?8\n\nDeep sampling of 9 reference epigenomes (e.g. IMR90)\n\nCourtesy of Ting Wang. Used with permission.\nUWash Epigenome Browser, Ting Wang\nChromatin state+RNA+DNAse+28 histone marks+WGBS+Hi-C ?>\n\n,\n% 996 6 + .\n% ). ,,\n\"5+-65+2H5)B\n% H3K4me3\n% H3K9ac\n% DNase\n% H3K36me3\n% H3K79me2\n% H4K20me1\n% H3K4me1\n% H3K27ac\n% DNase\n%H3K9me3\n%H3K27me3\n%DNAmethyl\n% H3K4me3\n% H3K4me1\n% H3K27ac\n% H3K36me3\n% H4K20me1\n% H3K79me3\n% H3K27me3\n% H3K9me3\n% H3K9ac\n% H3K18ac\nEnhancers\nPromoters\nTranscribed\nRepressed\n(c) source unknown. All rights reserved.\nThis contentis excluded from our Creative\nCommons license. Formore information,\nCourtesy of Broad Communications. Used with permission.\nsee http://ocw.mit.edu/help/faq-fair-use/.\n?;\n\nChromatin state annotations across 127 epigenomes\nReveal epigenomic variability: enh/prom/tx/repr/het\nAnshul Kundaj\nCourtesy of Anshul Kundaje. Used with permission.\ne\n??\n\n,.#\n.#\n\n䇾Central dogma䇿 of Molecular Biology\n?F\n\nGenes control the making of cell parts\n%\n6 6\n\n& 1\n2H 9+999U\n& 6 (䇾,䇿6\n\n./\n& 10. 䇾,䇿 +\n,\n% , H+,+3, ,\n% H ,. ,.\n&\n6, 6 6\n\n2H6 ,.\n,5\n.\nH\n&\n,+\n,\n& 1\nH. 36\n?I\n\nmRNA: The messenger\n% 6\n\n& 03\n& 30D.3\nA T T A C G G T A C C G T\nU A A U G C C A U G G C A\n& ,335,\n\n.3Cartoon of the progression from DNA to RNA to protein.\n\n.3\nImage by MIT OpenCourseWare.\nF9\nCar\ntoon of the p\nrogression\nfrom DNA to\nRN\nA to protein.\n\nFrom DNA to RNA: Transcription\nImage removed due to copyright restrictions.Please see: Figure 7-9 from Alberts, Bruce, and Martin Raff.\nEssential Cell Biology. New York, NY: Garland Publishing Inc., 1997. ISBN: 0815320450.\nF\n\nFrom pre-mRNA to mRNA: Splicing\n%\n1.+0.,6\n& 7 D,3.5\n& 2,5 H +,\n&\n+, . , 39;3,\nImage removed due to copyright restrictions.\nPlease see: Figure 7-16 from Alberts, Bruce, and Martin Raff. Essential Cell Biology.\nNew York, NY: Garland Publishing Inc., 1997. ISBN: 0815320450.\n& 0, .66D36\n+\n\n66,,\nF\n\nRNA can be functional\n% )) ,D\n& )65 , .6\n\n&\n5 6 .6H\n% 7.,6H\n& H 6 6\n& H 55 , 6 .\n& H 6\n& H,\n% 3 L\n& =䇻 H\n& : , +362H,+H\nF$\n\nRNA structure: 2ndary and 3rdary\nCourtesy of SStructView\nF8\n\nSplicing machinery made of RNA\nImage removed due to copyright restrictions.\nPlease see: Figure 7-16 from Alberts, Bruce, and Martin Raff. Essential Cell Biology.\nNew York, NY: Garland Publishing Inc., 1997. ISBN: 0815320450.\nF>\n\n,.#\n.#\n\n䇾Central dogma䇿 of Molecular Biology\nF;\n\nProteins carry out the cell䇻s chemistry\n%\n,D,.\n& H\n& \"\n090.\n& 1\n\n, 6 ,,\nCa\nr\ntoo\nn of the pr\nogression fro\nm DNA to RN\nA t\no protein.\n)B ) 7\n&\nB\n\n5 66,\n&\n,䇻6 .,\n\n$2\n%\n\",.0\n& .+3+ ++\n,+ 3\nF?\nImage by MIT OpenCourseWare.\n\nProtein structure\nAlpha-beta horseshoe\nBeta-barrel\nthis placental ribonuclease inhibitor is a\nHelix-turn-helix\nSome antiparallel b-sheet\ncytosolic protein that binds extremely\ndomains are better described as\nstrongly to any ribonuclease that may leak\nCommon motif for\nb-barrels rather than b-\ninto the cytosol. 17-stranded parallel b\nDNA-binding proteins\nsandwiches, for example\nsheet curved into an open horseshoe shape,\nthat often play a\nstreptavadin and porin. Note\nwith 16 a-helices packed against the outer\nregulatory role as\nthat some structures are\nsurface. It doesn't form a barrel although it\nmRNA level\nlooks as though it should. The strands are\ntranscription factors\nintermediate between the\nonly very slightly slanted, being nearly\nextreme barrel and sandwich\nparallel to the central `axis'.\narrangements.\nDrawing o\nf h\nelix-turn-helix\nprotein\ns\nt\nr\nucture.Drawing of beta-barrel protein structure.Drawing of alpha-beta horseshoe protein structure.\nFF\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\n\nProtein building blocks\n%\n\nFI\n\nFrom RNA to protein: Translation\n-tRNA\nImage by MIT OpenCourseWare.\nI9\nDr a\nw\nin g\n\no f\na\nri\nb o s\no m e\n.\n\nThe Genetic Code\nC0. ,,,\n,. 0,5\nI\n\nSummary: The Central Dogma\n2H H \"\nImage by MIT OpenCourseWare.\nICartoon of the progression from DNA to RNA to protein.\nCartoon of\nthe prog\nression f\nrom\nDNA to RNA t\no protein.\n\n,.#\n.#\n\nCellular dynamics and regulation\nHow cells move through this Central Dogma\n\n'\nI$\n\nAnimal/Human gene regulation:\nOne genome Many cell types\n\nACCAGTTACGACGGTCA\nGGGTACTGATACCCCAA\nACCGTTGACCGCATTTA\nCAGACGGGGTTTGGGTT\nTTGCCCCACACAGGTAC\nGTTAGCTACTGGTTTAG\nCAATTTACCGTTACAAC\nGTTTACAGGGTTACGGT\nTGGGATTTGAAAAAAAG\nTTTGAGTTGGTTTTTTC\nACGGTAGAACGTACCGT\nTACCAGTA\nImages of a heart, red blood cell, and a brain\nremoved due to copyright restrictions.\nImage in the public domain.\n) ,\nI8\n\nEukaryotic Gene Regulation\nCartoon depicting eukaryotic gene regulation removed due to copyright restrictions.\nI>\n\nDiverse roles for regulatory non-coding RNAs\n% Small RNA pathways (18-21 nt)\n& H\n% ,3.\n$䇻C3. , .\n% 235H\n\n% .6,\n& ,H\n% ,,3\n& H\n& C5H\n% Long non-coding RNAs (1000s nt, many exons)\n& ) 666,<73\n& ) 666$2 6H\nI;\n\nRegulation of Gene Expression\n%\nC, 6\npromoter\n%\n, B\nmotifs\n%\nTranscription factors (7/\n3 6\n%\n7 RNA polymerase\n%\n,\n\n\";'8\n\n1D ,\n.#\n\"\n\n(\nI?\n\nPredicted motif drivers\nof enhancer modules\n% Activator and\nrepressor motifs\nconsistent with\ntissues\nPouya Kheradpour\nCourtesy of Macmillan Publishers Limited. Used with permission.\n\nNetwork components reveal functional modules\n% 756,0, ,\n% ,6 W\n(c) Cold Spring Harbor Laboratory Press. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Zeitlinger, Julia et al. \"Whole-genome ChIP-chip analysis of Dorsal, Twist, and Snail\nsuggests integration of diverse patterning pr\ncesses in the Drosophila embryo.\" Genes &\nDevelopment 21, no. 4 (2007): 385-390.\nK'et al%<,&L II\n\n3MB@%@C\nKheradpour et al Genome Research 2013\nSystematic motif dissection in 2000 enhancers:\n5 activators and 2 repressors in 2 cell lines\nFigure 1: selection of activator and repressor motifs removed due to copyright restrictions.\nSource: Kheradpour, Pouya et al. \"Systematic dissection of regulatory motifs in 2000\npredicted human enhancers using a massively parallel reporter assay.\" Genome Research\n23, no. 5 (2013): 800-811.\n\nEmerging properties of regulatory networks\nFigures removed due to copyright restrictions.\n%\n06.\n& ) 363 5,\n% ), 6 < 63 3. H\n& 67 H 5\n\nFrom Systems Biology to Synthetic Biology\n9*\n).\n\n.H\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n% ,\n\n,,\n\n% 33\n.\n\n\"\n\n<, ,\n% ,\n\n).\n\n% ).3\n0W\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Benner, Steven A. and A. Michael Sismour. \"Synthetic\nbiology.\" Nature Reviews Genetics 6, no. 7 (2005): 533-543.\n#\n9('\n\nOver-express a single microRNA leads to new wing\n%\n2 0.6<5 H\n%\n.\n0, ,\n%\n-.05D,( H/\n\n%\n=,\n\n).3\n\n<3\n\n#\n6\"\n.)*%,%2'\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n8et al%<,&L\n9$\n\nBrief intro to Human Genetics\n\n,.#\n.#\n\nThe role of genetic alterations\n\n9>\n\nBrief intro to human genetics\n% -'$-+ ,+$\n+\n9+J$ )H\"+J>99\n,.,3\nFigure in the public domain. Created by Darryl Leja and Teri Manolio, NHGRI;\nTony Burdett, Dani Welter, and Helen Parkinson, EBI.\n9;\nwww.genome.gov/GWAStudies\nwww.ebi.ac.uk/fgpt/gwas/\n\nThe power and challenge of disease-association studies\n% Large associated blocks with many variants: Fine-mapping challenge\n% No information on cell type/mechanism, most variants non-coding\nEpigenomic annotations help find relevant cell types / nucleotides\nSlide credit: Luke Ward, Mark Daly\n\n\"\n'\n*\n\n9?\n\n+\n\n(011\n'1(12331\n\nrs11209026 A\nG\n\nI?;\n\n;F\nI$\n* /0N3 %NL1@/L\n*$ . ,3666 5\nThe power of GWAS: reveal new disease genes\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Cho, Judy H. \"The genetics and immunopathogenesis of\ninflammatory bowel disease.\" Nature Reviews Immunology 8, no.\n6 (2008): 458-466.\n(c) ADAM, Inc. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n9F\n\nGenomewide association in schizophrenia\nwith 40,000 cases\n\n99 6\n\n,\nMMM\n\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Ripke, Stephan et al. \"Biological insights from 108 schizophrenia-associated genetic loci.\" Nature 511, no. 7510 (2014): 421.\n9I\n\nDD\n%\nDisease-associated SNPs enriched for enhancers in relevant cell types\n%\nE.g. lupus SNP in GM enhancer disrupts Ets1 predicted activator\nInterpreting non-\ncoding variants\n\"\n'\n*\n\n+\n\n(011\n'1(12331\n\nMechanistic predictions for top disease-associated SNPs\nDisrupt activator Ets-1 motif\n\nLoss of GM-specific activation\nLoss of enhancer function\nLoss of HLA-DRB1 expression\n2( ( ( 7\n!( (\nCreation of repressor Gfi1 motif\nGain K562-specific repression\nLoss of enhancer function\nLoss of CCDC162 exp\nFigures removed due to copyright restrictions.\nression\n\nChromatin state annotations across 127 epigenomes\nFigures removed due to copyright restrictions.\nReveal epigenomic variability: enh/prom/tx/repr/het\nAnshul Kundaje\n\nCharacterizing sub-threshold variants in heart arrhythmia\nTrait: QRS/QT interval\n(c) source unknown. All rights reserved.This content\nis excluded from our Creative Commons license. For\nmore information, see http://ocw.mit.edu/help/faq-\nfair-use/.\nFocus on sub-threshold variants\n(e.g. rs1743292 P=10-4.2)\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Arking, Dan E. et al. \"Genetic association study of QT interval highlights role for calcium\nsignaling pathways in myocardial repolarization.\" Nature Genetics 46, no. 8 (2014): 826-836.\n(1) Large cohorts, (2) many known hits\n(3) well-characterized tissue drivers\n$\n\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Roadmap Epigenomics Consortium et al. \"Integrative analysis of 111 reference human epigenomes.\" Nature 518, no. 7539 (2015): 317-330. 8\n\nLinking traits to their relevant cell/tissue types\nES\nLiver\nBrain\nDigestive\nHeart\nT cells\nB cells\n\"\n'\n*\n\n+\n\n(011\n'1(12331\n>\n\nMethylation differences a causal component of AD\nAD predictive power reduced\nafter removing meQTL effect\nMethylation probes altered in AD\nare enriched in AD-associated SNPs\nG M D\n\nG M D\n\nG D\nM\n\"\n'\n\n*\n\n+\n\n(011\n'1(12331\n\"\n'\n*\n\n+\n\n(011\n'1(12331\nSet-wise causality testing\n;\n\nUncovering the molecular basis of top obesity gene\nObese\nC-to-T motif rescue\n(anti-obesity phenotypes)\nT-to-C motif disruption\n(pro-obesity phenotypes)\nLean\nIRX3, IRX5 knock-down\n(anti-obesity phenotypes)\nIRX3, IRX5 overexpression\n(pro-obesity phenotypes)\nARID5B KD\n(obesity)\nARID5B OE\n(anti-obesity)\n\"\n'\n*\n\n+\n\n(011\n'1(12331\n\nModel: beige\nwhite adipocyte development\n\"\n'\n*\n\n+\n\n(011\n'1(12331\nShift therapeutic focus from brain to adipocytes\nF\n\nChallenges in Computational Biology\n2H\n8 3.\n> . 6 0.\n23,\n$\nD,.\nF\nH ,\n)B\n\n10.\n.\n?\nTCATGCTAT\nTCGTGATAA\nTGAGGATAT\nTTATCATAT\nTTATGATTT\n0.\nI\n33 ,\n\".\n\n,0\n;\n1 ,,\n$\nI\n\n:,=\n\n,<<\n;98?<;F?F<)>9? ,-.\n79>\n76 3\n6C+0\n,<< <"
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 10 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/e67b1adfae82aed4851a6b635f55d247_MIT6_047F15_Lecture10.pdf",
      "content": "Lecture 10\nRegulatory motif discovery\nand target identification\n6.047/6.878\nComputational Biology: Genomes, Networks, Evolution\n\nModule III: Epigenomics and gene regulation\n- Computational Foundations\n- L10: Gibbs Sampling: between EM and Viterbi training\n- L11: Rapid linear-time sub-string matching\n- L11: Multivariate HMMs\n- L12: Post-transcriptional regulation\n- Biological frontiers:\n- L10: Regulatory motif discovery, TF binding\n- L11: Epigenomics, chromatin states, differentiation\n- L12: Post-transcriptional regulation\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nATGACTAAATCTCATTCAGAAGAA\nRegulatory motif discovery\nGAL1\nCCCCW\nCGG\nCCG\nGal4\nMig1\nCGG\nCCG\nGal4\n-\nRegulatory motifs\n- Genes are turned on / off in response to changing environments\n- No direct addressing: subroutines (genes) contain sequence tags (motifs)\n- Specialized proteins (transcription factors) recognize these tags\n\n-\nWhat makes motif discovery hard?\n- Motifs are short (6-8 bp), sometimes degenerate\n- Can contain any set of nucleotides (no ATG or other rules)\n- Act at variable distances upstream (or downstream) of target gene\n\nThe regulatory code: All about regulatory motifs\n-\nThe parts list: ~20-30k genes\n- Protein-coding genes, RNA genes (tRNA, microRNA, snRNA)\n-\nThe circuitry: constructs controlling gene usage\n- Enhancers, promoters, splicing, post-transcriptional motifs\n-\nThe regulatory code, complications:\n- Combinatorial coding of 'unique tags'\n- Data-centric encoding of addresses\n- Overlaid with 'memory' marks\n- Large-scale on/off states\n- Modulation of the large-scale coding\n- Post-transcriptional and post-translational information\n-\nToday: discovering motifs in co-regulated promoters and de novo\nmotif discovery & target identification\nEnhancer regions\n5'-UTR\nPromoter motifs\n3'-UTR\nWhere in the body?\nWhen in time?\nWhich variants?\nSplicing signals\nWhich subsets?\nMotifs at RNA level\n\nTFs use DNA-binding domains to recognize\nspecific DNA sequences in the genome\nDNA-binding domain of\nEngrailed\n\"Logo\" or \"motif\"\nTAATTA\nCACGTG\nAGATAAGA\nTCATTA\nCourtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission.\nSource: Berger, Michael F. et al. \"Variation in homeodomain DNA binding revealed by\nhigh-resolution analysis of sequence preferences.\" Cell 133, no. 7 (2008): 1266-1276.\n\nDisrupted motif at the heart of FTO obesity locus\nObese\nLean\nStrongest association\nwith obesity\nC-to-T disruption of AT-rich\nregulatory motif\nRestoring motif restores thermogenesis\nCourtesy of Manolis Kellis. Used with permission.\n\nRegulator structure recognized motifs\n-\nProteins 'feel' DNA\n-\nRead chemical properties of bases\n-\nDo NOT open DNA (no base\ncomplementarity)\n\n-\n3D Topology dictates specificity\n-\nFully constrained positions:\nevery atom matters\n-\n\"Ambiguous / degenerate\" positions\nloosely contacted\n\n-\nOther types of recognition\n-\nMicroRNAs: complementarity\n-\nNucleosomes: GC content\n-\nRNAs: structure/seqn combination\n(c) Garland Publishing. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMotifs summarize TF sequence specificity\n-\nSummarize\ninformation\n\n-\nIntegrate many\npositions\n\n-\nMeasure of\ninformation\n\n-\nDistinguish motif\nvs. motif instance\n\n-\nAssumptions:\n- Independence\n- Fixed spacing\n\nExperimental factor-centric discovery of motifs\nSELEX (Systematic\nEvolution of Ligands by\nExponential Enrichment;\nKlug & Famulok, 1994)\nDIP-Chip (DNA-\nimmunoprecipitatio\nn with microarray\ndetection; Liu et al.,\n2005)\nPBMs (Protein binding\nmicroarrays; Mukherjee,\n2004)\nDouble stranded DNA\narrays\nCourtesy of the authors. Used with permission.\nSource: Ray, Partha, and Rebekah R. White. \"Aptamers\nFor targeted drug delivery.\" Pharmaceuticals 3, no. 6\n(2010): 1761-1778.\n\n(c) Cold Spring Harbor Laboratory Press. All rights\nreserved. This content is excluded from our Creative\nCommons license. For more information, see http://\nocw.mit.edu/help/faq-fair-use/.\nSource: Liu, Xiao et al. \"DIP-chip: rapid and accurate\ndetermination of DNA-binding specificity.\" Genome\nResearch 15, no. 3 (2005): 421-427.\n\n(c) source unknown. All rights reserved.\nThis content is excluded from our\nCreative Commons license. For more\ninformation, see http://ocw.mit.edu/\nhelp/faq-fair-use/.\n\nApproaches to regulatory motif discovery\n- Expectation Maximization (e.g. MEME)\n- Iteratively refine positions / motif profile\n- Gibbs Sampling (e.g. AlignACE)\n- Iteratively sample positions / motif profile\n- Enumeration with wildcards (e.g. Weeder)\n- Allows global enrichment/background score\n- Peak-height correlation (e.g. MatrixREDUCE)\n- Alternative to cutoff-based approach\n\n- Conservation-based discovery (e.g. MCS)\n- Genome-wide score, up-/down-stream bias\n\n- Protein Domains (e.g. PBMs, SELEX)\n- In vitro motif identification, seq-/array-based\nRegion-\nbased\nmotif\ndiscovery\nGenome-\nwide\nIn vitro /\ntrans\n\nMotifs are not limited to DNA sequences\n- Splicing Signals at the RNA level\n- Splice junctions\n- Exonic Splicing Enhancers (ESE)\n- Exonic Splicing Surpressors (ESS)\n- Domains and epitopes at the Protein level\n- Glycosylation sites\n- Kinase targets\n- Targetting signals\n- MHC binding specificities\n- Recurring patterns at the physiological level\n- Expression patterns during the cell cycle\n- Heart beat patterns predicting cardiac arrest\n- Final project in previous year, now used in Boston hospitals!\n- Any probabilistic recurring pattern\n\nRegulator\nTF/miRNA\nMotif\nSequence\nspecificity\nTFs: Selex, DIP-Chip, Protein-Binding-Microarrays\nmiRNAs: Evolutionary/structural signatures\nmiRNAs: Experimental cloning of 5'-ends\nTFs: Mass Spec (difficult)\nTFs: ChIP-Chip/ChIP-Seq\nTFs/miRs: Perturbation response\nTFs/miRNAs: Evolutionary signatures**\nmiRNAs: Composition/folding\nTFs: Enrichment in\nco-regulated genes/\nbound regions **\nTFs: Homology to TFs/domains\nmiRNAs: Evolutionary signatures\nmiRNAs: Experimental cloning\nTFs/miRNAs: De novo\ncomparative discovery**\n* = Covered in today's lecture\nNetwork analysis\n(upcoming lecture)\nChallenges in regulatory genomics\nTargets\nFunctional instances\nEvolutionary footprints\nDNase footprints\nChromatin 'dips'\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nEnrichment-based discovery methods\nGiven a set of co-regulated/functionally related genes,\nfind common motifs in their promoter regions\n- Align the promoters to each other using local alignment\n- Use expert knowledge for what motifs should look like\n- Find 'median' string by enumeration (motif/sample driven)\n- Start with conserved blocks in the upstream regions\n\nStarting positions Motif matrix\nsequence positions\nA\nC\nG\nT\n0.1\n0.1\n0.6\n0.2\n-\ngiven aligned sequences easy to compute profile matrix\n0.1\n0.5\n0.2\n0.2 0.3\n0.2\n0.2\n0.3\n0.2\n0.1\n0.5\n0.2 0.1\n0.1\n0.6\n0.2\n0.3\n0.2\n0.1\n0.4\n0.1\n0.1\n0.7\n0.1\n0.3\n0.2\n0.2\n0.3\nshared motif\n\ngiven profile matrix\n\n-\neasy to find starting position probabilities\nKey idea: Iterative procedure for estimating both, given\nuncertainty\n(learning problem with hidden variables: the starting positions)\n\nBasic Iterative Approach\nGiven: length parameter W, training set of sequences\nset initial values for motif\ndo\nre-estimate starting-positions from motif\nre-estimate motif from starting-positions\nuntil convergence (change < ε)\nreturn: motif, starting-positions\n\nRepresenting Motif M(k,c) and Background B(c)\n-\nAssume motif has fixed width, W\n-\nMotif represented by matrix of probabilities: M(k,c)\n\nthe probability of character c in column k\n1 2 3\nA 0.1 0.5 0.2\nC 0.4 0.2 0.1\nG 0.3 0.1 0.6\nT 0.2 0.2 0.1\n\nM\n\nA 0.26\nC 0.24\nG 0.23\nT 0.27\n\nB\n-\nBackground represented by B(c), frequency of each\nbase\n(near uniform)\n(~CAG)\n(see also: di-nucleotide etc)\n\nRepresenting the starting position probabilities (Zij)\n-\nthe element of the matrix represents the\nprobability that the motif starts in position j in sequence i\nZ\n1 2 3 4\nseq1 0.1 0.1 0.2 0.6\nseq2 0.4 0.2 0.1 0.3\nseq3 0.3 0.1 0.5 0.1\nseq4 0.1 0.5 0.1 0.3\n\nZ\nij\nZ\nZ1\nuniform\none big\nwinner\ntwo\ncandidates\nno clear\nwinner\nZ2\nZ3\nZ4\nSome examples:\n\nStarting positions (Zij) Motif matrix M(k,c)\n-\nZij: Probability that on sequence i, motif start at position j\n-\nM(k,c): Probability that kth character of motif is letter c\nc=A\nc=C\nc=G\nc=T\nk=1 k=2 k=3 k=4 k=5 k=6 k=7 k=8\n0.1\n0.1\n0.6\n0.2\n0.1\n0.5\n0.2\n0.2 0.3\n0.2\n0.2\n0.3\n0.2\n0.1\n0.5\n0.2 0.1\n0.1\n0.6\n0.2\n0.3\n0.2\n0.1\n0.4\n0.1\n0.1\n0.7\n0.1\n0.3\n0.2\n0.2\n0.3\n-\nThree variations for re-computing motif M(k,c) from Zij matrix\n-\nExpectation maximization\nAll starts weighted by Zij prob distribution\n-\nGibbs sampling\nSingle start for each seq Xi by sampling Zij\n-\nGreedy approach\nBest start for each seq Xi by maximum Zij\nM-step\nE-step\nX1\nX2\nX3\n...\nXi\n...\nXn\nMotif: M(k,c)\nStarting positions: Zij\n-\nComputing Zij matrix from M(k,c) is straightforward\n-\nAt each position, evaluate start probability by multiplying across the matrix\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nE-step:\nEstimate Zij positions from matrix\nc=A\nc=C\nc=G\nc=T\nk=1\nk=2\nk=3\nk=4\nk=5\nk=6\nk=7\nk=8\n0.1\n0.1\n0.6\n0.2\n0.1\n0.5\n0.2\n0.2 0.3\n0.2\n0.2\n0.3\n0.2\n0.1\n0.5\n0.2 0.1\n0.1\n0.6\n0.2\n0.3\n0.2\n0.1\n0.4\n0.1\n0.1\n0.7\n0.1\n0.3\n0.2\n0.2\n0.3\nE-step\nX1\nX2\nX3\n...\nXi\n...\nXn\nMotif: M(k,c)\nStarting positions: Zij\n\nThree examples for Greedy, Gibbs Sampling, EM\nuniform\none big\nwinner\ntwo\ncandidates\nZ1\nZ2\nZ3\nAll methods agree\nGreedy always picks maximum\nGibbs sampling picks one at random\n(or)\nEM uses both in estimating motif\n(and)\nGreedy ignores most of the probability\nEM averages over the entire sequence (slow/no convergence)\nGibbs sampling rapidly converges to some choice\n\nCalculating P(Xi) when motif position is known\n-\nProbability of training sequence Xi, given hypothesized start position j\n\nL\nW\nj\nk\nk\ni\nW\nj\nj\nk\nk\ni\nj\nk\nk\ni\nij\ni\nX\nB\nX\nj\nk\nM\nX\nB\nB\nM\nZ\nX\n)\n(\n)\n,1\n(\n)\n(\n)\n,\n,1\n|\nPr(\n,\n,\n,\nbefore motif\nmotif\nafter motif\n\nA 0.25\nC 0.25\nG 0.25\nT 0.25\n\nM\nG C T G T A G\n\ni\nX\n-\nExample:\n\nB\n0.25\n\n0.25\n1.0\n1.0\n2.0\n0.25\n\n0.25\n\n)\n(\n)\n(\n)\n,3\n(\n)\n,2\n(\n)\n,1(\n)\n(\nB(G)\n\n)\n,\n,1\n|\nPr(\n\nG\nB\nA\nB\nT\nM\nG\nM\nT\nM\nC\nB\nB\nM\nZ\nX\ni\ni\n1 2 3\nA 0.1 0.5 0.2\nC 0.4 0.2 0.1\nG 0.3 0.1 0.6\nT 0.2 0.2 0.1\n\nCalculating the Z vector ( using M )\n-\nAt iteration t, calculate Zij\n(t) based on M(t)\n- We just saw how to calculate Pr(Xi | Zij=1,M(t))\n- To obtain total probability Pr(Xi), sum over all starting positions\n\n)\n(\n)\n(\n)\n(\n)1\nPr(\n)\n,1\n|\nPr(\n)1\nPr(\n)\n,1\n|\nPr(\nW\nL\nk\nik\nt\nik\ni\nij\nt\nij\ni\nt\nij\nZ\nM\nZ\nX\nZ\nM\nZ\nX\nZ\n-\nTo estimate the starting positions in Z at step t\n(Bayes' rule)\n-\nAssume uniform priors (motif eq likely to start at any position)\nposterior\nevidence\nlikelihood\nprior\n)\nPr(\n)1\nPr(\n)\n,1\n|\nPr(\n)\n,\n|1\nPr(\n)\n(\n)\n(\n)\n(\ni\nij\nt\nij\ni\nt\ni\nij\nt\nij\nX\nZ\nM\nZ\nX\nM\nX\nZ\nZ\n\nCalculating the Z vector: Example\n.0\n.0\n.0\n.0\n1.0\n2.0\n3.0\n\niZ\n.0\n.0\n.0\n6.0\n2.0\n4.0\n.0\n\niZ\n-\nthen normalize so that\n\nW\nL\nj\nij\nZ\n...\n0 1 2 3\nA 0.25 0.1 0.5 0.2\nC 0.25 0.4 0.2 0.1\nG 0.25 0.3 0.1 0.6\nT 0.25 0.2 0.2 0.1\n\np\nG C T G T A G\n\ni\nX\n\nAside: Simplifying P(Xi)\n-\nProbability of training sequence Xi, given hypothesized start position j\n\nL\nk\nk\ni\nW\nj\nj\nk\nk\ni\nk\ni\nX\nB\nX\nB\nX\nj\nk\nM\n,\n,\n,\n)\n(\n)\n(\n)\n,1\n(\nconstant for\neach sequence\ncan be stored in\na matrix\n\nL\nW\nj\nk\nk\ni\nW\nj\nj\nk\nk\ni\nj\nk\nk\ni\nij\ni\nX\nB\nX\nj\nk\nM\nX\nB\nB\nM\nZ\nX\n)\n(\n)\n,1\n(\n)\n(\n)\n,\n,1\n|\nPr(\n,\n,\n,\nbefore motif\nmotif\nafter motif\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nM-step:\nMax-likelih motif from Zij positions\nc=A\nc=C\nc=G\nc=T\nk=1\nk=2\nk=3\nk=4\nk=5\nk=6\nk=7\nk=8\n0.1\n0.1\n0.6\n0.2\n0.1\n0.5\n0.2\n0.2 0.3\n0.2\n0.2\n0.3\n0.2\n0.1\n0.5\n0.2 0.1\n0.1\n0.6\n0.2\n0.3\n0.2\n0.1\n0.4\n0.1\n0.1\n0.7\n0.1\n0.3\n0.2\n0.2\n0.3\nM-step\nX1\nX2\nX3\n...\nXi\n...\nXn\nMotif: M(k,c)\nStarting positions: Zij\n\nThe M-step: Estimating the motif M\n\nc\nc\nk\nc\nk\nt\nd\nn\nd\nn\nc\nk\nM\n)\n(\n)\n,\n(\n,\n,\n)\n(\n\ni\nc\nX\nj\nij\nk\nc\nk\nj\ni\nZ\nn\n}\n|\n{\n,\n,\npseudo-counts\ntotal # of c's\nin data set\n-\nrecall represents the probability of character c in\nposition k ; stores values for the background\n)\n,\n(\nc\nk\nM\nwhere\n)\n(c\nB\n\nW\nj\nc\nj\nc\nc\nn\nn\nn\n,\n,0\n\nc\nc\nc\nt\nd\nn\nd\nn\nc\nB\n)\n(\n)\n(\n,0\n,0\n)\n(\nwhere\n\nM-step example: Estimating M(k,c) from Zij\nA G G C A G\nA C A G C A\nT C A G T C\n\n...\n\n)\n,1(\n,3\n3,3\n,1\n1,1\n3,3\n1,2\n3,1\n1,1\n\nZ\nZ\nZ\nZ\nZ\nZ\nZ\nZ\nA\nM\nZ1 = 0.1 0.7 0.1 0.1\nZ2 = 0.4 0.1 0.1 0.4\nZ3 = 0.2 0.6 0.1 0.1\nX1 =\nX2 =\nX3 =\n-\nEM: sum over full probability\n- n1,A= 0.1+0.1+0.4+0.1 = 0.7\n- n1,C= 0.7+0.4+0.6 = 1.7\n- n1,G= 0.1+0.1+0.1+0.1= 0.4\n- n1,T= 0.2 = 0.2\n- Total: T=0.7+1.7+0.4+0.2 = 3.0\n\n-\nNormalize and add pseudo-counts\n- M(1,A) = (0.7+1)/(T+4) = 1.7/7=0.24\n- M(1,C) = (1.7+1)/(T+4) = 2.7/7=0.39\n- M(1,G) = (0.4+1)/(T+4) = 1.4/7=0.2\n- M(1,T) = (0.2+1)/(T+4) = 1.2/7=0.17\n\n-\nM(k,c) =\nA\n0.24\n0.39\n0.21\nC\n0.39\n0.21\n0.18\nG\n0.2\n0.24\n0.44\nT\n0.17\n0.16\n0.16\nEm approach:\nAvg'em all\nGibbs sampling: Sample one\nGreedy:\nSelect max\n\nThe EM Algorithm\n-\nEM converges to a local maximum in the likelihood of the\ndata given the model:\n\ni\ni\nB\nM\nX\n)\n,\n|\nPr(\n- Deterministic iterations max direction of ascent\n- Usually converges in a small number of iterations\n- Sensitive to initial starting point (i.e. values in M)\n\nP(Seq|Model) Landscape\nP(Sequences|params1,params2)\nEM searches for parameters to increase P(seqs|parameters)\nUseful to think of\nP(seqs|parameters)\nas a function of parameters\nEM starts at an initial set of\nparameters\nAnd then \"climbs uphill\" until it\nreaches a local maximum\nWhere EM starts can make a big difference\n(c) source unknown. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n\nOne solution: Search from Many Different Starts\nP(Sequences|params1,params2)\nTo minimize the effects of local maxima, you should search\nmultiple times from different starting points\nMEME uses this idea\n\nStart at many points\n\nRun for one iteration\n\nChoose starting point that got\nthe \"highest\" and continue\n(c) source unknown. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nThree options for assigning points, and\ntheir parallels across K-means, HMMs, Motifs\nUpdate\nassignments\n(E step)\nEstimate hidden\nlabels\nAlgorithm implementing E step\nin each of the three settings\nUpdate\nmodel\nparameters\n(M step)\nmax\nlikelihood\nExpression\nclustering\nHMM\nlearning\nMotif\ndiscovery\nThe hidden label is:\nCluster labels\nState path π\nMotif positions\nAssign each point\nto best label\nK-means:\nAssign each\npoint to nearest\ncluster\nViterbi\ntraining: label\nsequence with\nbest path\nGreedy: Find\nbest motif match\nin each sequence\nAverage of\nthose points\nassigned to\nlabel\nAssign each point\nto all labels,\nprobabilistically\nFuzzy K-\nmeans: Assign\nto all clusters,\nweighted by\nproximity\nBaum-Welch\ntraining: label\nsequence w all\npaths (posterior\ndecoding)\nMEME: Use all\npositions as a\nmotif occurrence\nweighed by motif\nmatch score\nAverage of all\npoints,\nweighted by\nmembership\nPick one label at\nrandom, based on\ntheir relative\nprobability\nN/A: Assign to\na random\ncluster, sample\nby proximity\nN/A: Sample a\nsingle label for\neach position,\naccording to\nposterior prob.\nGibbs sampling:\nUse one position\nfor the motif, by\nsampling from the\nmatch scores\nAverage of\nthose points\nassigned to\nlabel(a\nsample)\nUpdate rule\nPick a best\nAverage all\nSample one\n\nThree examples of Greedy, Gibbs Sampling, EM\nuniform\none big\nwinner\ntwo\ncandidates\nZ1\nZ2\nZ3\nAll methods agree\nGreedy always picks maximum\nGibbs sampling picks one at random\n(or)\nEM uses both in estimating motif\n(and)\nGreedy ignores most of the probability\nEM averages over the entire sequence (no preference)\nGibbs sampling rapidly converges to some choice\n\nGibbs Sampling\n-\nA general procedure for sampling from the joint distribution of a set\nof random variables by iteratively sampling from\nfor each j\n-\nUseful when it's hard to explicitly express means, stdevs,\ncovariances across the multiple dimensions\n-\nUseful for supervised, unsupervised, semi-supervised learning\n- Specify variables that are known, sample over all other variables\n-\nApproximate:\n- Joint distribution: the samples drawn\n- Marginal distributions: examine samples for subset of variables\n- Expected value: average over samples\n-\nExample of Markov-Chain Monte Carlo (MCMC)\n- The sample approximates an unknown distribution\n- Stationary distribution of sample (only start counting after burn-in)\n- Assume independence of samples (only consider every 100)\n-\nSpecial case of Metropolis-Hastings\n- In its basic implementation of sampling step\n- But it's a more general sampling framework\n)\n\n...\n,\n\n...\n|\nPr(\nn\nj\nj\nj\nU\nU\nU\nU\nU\n\n)\n\n...\nPr(\nn\nU\nU\n\nGibbs Sampling for motif discovery\ngiven: length parameter W, training set of sequences\nchoose random positions for a\ndo\npick a sequence Xi\nestimate p given current motif positions a (update step)\n(using all sequences but Xi)\nsample a new motif position ai for Xi (sampling step)\nuntil convergence\nreturn: p, a\n-\nFirst application to motif finding: Lawrence et al 1993\n-\nCan view as a stochastic analog of EM for motif discovery task\n-\nLess susceptible to local minima than EM\n-\nEM maintains distribution Zi over the starting points for each seq\n-\nGibbs sampling selects specific starting point ai for each seq\nbut keeps resampling these starting points\n\nPopular implementation: AlignACE, BioProspector\nAlignACE: first statistical motif finder\nBioProspector: improved version of AlignACE\n\nBoth use basic Gibbs Sampling algorithm:\n1.\nInitialization:\na.\nSelect random locations in sequences X1, ..., XN\nb.\nCompute an initial model M from these locations\n2.\nSampling Iterations:\na.\nRemove one sequence Xi\nb.\nRecalculate model\nc.\nPick a new location of motif in Xi according to probability\nthe location is a motif occurrence\n\nIn practice, run algorithm from multiple random initializations:\n1.\nInitialize\n2.\nRun until convergence\n3.\nRepeat 1,2 several times, report common motifs\n\nGibbs Sampling (AlignACE)\n-\nGiven:\n- X1, ..., XN,\n- motif length W,\n- background B,\n\n-\nFind:\n- Model M\n- Locations a1,..., aN in X1, ..., XN\n\nMaximizing log-odds likelihood ratio\n\nThis is the same as the EM objective (notice log and notation\nchange)\n)\n(\n)\n,\n(\nlog\n,\n,\nk\na\ni\nk\na\ni\nN\ni\nW\nk\ni\ni\nX\nB\nX\nk\nM\n\nGibbs Sampling (AlignACE)\nPredictive Update:\n\n-\nSelect a sequence xi\n-\nRemove xi, recompute model:\n\nd\nN\nc\nX\nd\nc\nk\nM\ni\ns\nk\na\ns\ns\n)1\n(\n)\n(\n)\n,\n(\n,\n\nwhere d is a pseudocount to avoid 0s\nM\n\nSampling New Motif Positions\n-\nfor each possible starting position, ai=j, compute a weight\n\n-\nrandomly select a new starting position ai according to these weights\n(normalizing across the sequence, again like with MEME)\n\n-\nNote, this is equivalent to using the likelihood from MEME because:\n\n)\n,1\n|\nPr(\np\nZ\nX\nA\nij\ni\nj\n\n,\n,\n)\n(\n)\n,1\n(\nW\nj\nj\nk\nk\ni\nk\ni\nj\nX\nB\nX\nj\nk\nM\nA\n|x|\nProb\n\nAdvantages / Disadvantages\n-\nVery similar to EM\n\nAdvantages:\n-\nEasier to implement\n-\nLess dependent on initial parameters\n-\nMore versatile, easier to enhance with heuristics\n\nDisadvantages:\n-\nMore dependent on all sequences to exhibit the motif\n-\nLess systematic search of initial parameter space\n\nGibbs Sampling and Climbing\nP(Sequences|params1,params2)\nBecause gibbs sampling does always choose the best new location\nit can move to another place not directly uphill\nIn theory, Gibbs Sampling less likely to get stuck a local maxima\n(c) source unknown. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nMotivation for de novo genome-wide motif discovery\n- Both TF and region centric approaches are not\ncomprehensive and are biased\n- TF centric approaches generally require\ntranscription factor (or antibody to factor)\n- Lots of time and money\n- Also have computational challenges\n- De novo discovery using conservation is unbiased\nbut can't match motif to factor and require multiple\ngenomes\n\nEvolutionary signatures for regulatory motifs\n-Start by looking at known motif instances\n-Individual motif instances are preferentially conserved\n-Can we just take conservation islands and call them\nmotifs?\n- No. Many conservation islands are due to chance or perhaps due\nto non-motif conservation\nKellis el al, Nature 2003\nXie et al. Nature 2005\nStark et al, Nature 2007\nD.mel CAGCT--AGCC-AACTCTCTAATTAGCGACTAAGTC-CAAGTC\nD.sim CAGCT--AGCC-AACTCTCTAATTAGCGACTAAGTC-CAAGTC\nD.sec CAGCT--AGCC-AACTCTCTAATTAGCGACTAAGTC-CAAGTC\nD.yak CAGC--TAGCC-AACTCTCTAATTAGCGACTAAGTC-CAAGTC\nD.ere CAGCGGTCGCCAAACTCTCTAATTAGCGACCAAGTC-CAAGTC\nD.ana CACTAGTTCCTAGGCACTCTAATTAGCAAGTTAGTCTCTAGAG\n** * * *********** * **** * **\nD.mel\nKnown engrailed binding site\n\nConservation islands overlap known motifs\nScer TATCCATATCTAATCTTACTTATATGTTGT-GGAAAT-GTAAAGAGCCCCATTATCTTAGCCTAAAAAAACC--TTCTCTTTGGAACTTTCAGTAATACG\nSpar TATCCATATCTAGTCTTACTTATATGTTGT-GAGAGT-GTTGATAACCCCAGTATCTTAACCCAAGAAAGCC--TT-TCTATGAAACTTGAACTG-TACG\nSmik TACCGATGTCTAGTCTTACTTATATGTTAC-GGGAATTGTTGGTAATCCCAGTCTCCCAGATCAAAAAAGGT--CTTTCTATGGAGCTTTG-CTA-TATG\nSbay TAGATATTTCTGATCTTTCTTATATATTATAGAGAGATGCCAATAAACGTGCTACCTCGAACAAAAGAAGGGGATTTTCTGTAGGGCTTTCCCTATTTTG\n** ** *** **** ******* ** * * * * * * * ** ** * *** * *** * * *\n\nScer CTTAACTGCTCATTGC-----TATATTGAAGTACGGATTAGAAGCCGCCGAGCGGGCGACAGCCCTCCGACGGAAGACTCTCCTCCGTGCGTCCTCGTCT\nSpar CTAAACTGCTCATTGC-----AATATTGAAGTACGGATCAGAAGCCGCCGAGCGGACGACAGCCCTCCGACGGAATATTCCCCTCCGTGCGTCGCCGTCT\nSmik TTTAGCTGTTCAAG--------ATATTGAAATACGGATGAGAAGCCGCCGAACGGACGACAATTCCCCGACGGAACATTCTCCTCCGCGCGGCGTCCTCT\nSbay TCTTATTGTCCATTACTTCGCAATGTTGAAATACGGATCAGAAGCTGCCGACCGGATGACAGTACTCCGGCGGAAAACTGTCCTCCGTGCGAAGTCGTCT\n** ** ** ***** ******* ****** ***** *** **** * *** ***** * * ****** *** * ***\n\nScer TCACCGG-TCGCGTTCCTGAAACGCAGATGTGCCTCGCGCCGCACTGCTCCGAACAATAAAGATTCTACAA-----TACTAGCTTTT--ATGGTTATGAA\nSpar TCGTCGGGTTGTGTCCCTTAA-CATCGATGTACCTCGCGCCGCCCTGCTCCGAACAATAAGGATTCTACAAGAAA-TACTTGTTTTTTTATGGTTATGAC\nSmik ACGTTGG-TCGCGTCCCTGAA-CATAGGTACGGCTCGCACCACCGTGGTCCGAACTATAATACTGGCATAAAGAGGTACTAATTTCT--ACGGTGATGCC\nSbay GTG-CGGATCACGTCCCTGAT-TACTGAAGCGTCTCGCCCCGCCATACCCCGAACAATGCAAATGCAAGAACAAA-TGCCTGTAGTG--GCAGTTATGGT\n** * ** *** * * ***** ** * * ****** ** * * ** * * ** ***\n\nScer GAGGA-AAAATTGGCAGTAA----CCTGGCCCCACAAACCTT-CAAATTAACGAATCAAATTAACAACCATA-GGATGATAATGCGA------TTAG--T\nSpar AGGAACAAAATAAGCAGCCC----ACTGACCCCATATACCTTTCAAACTATTGAATCAAATTGGCCAGCATA-TGGTAATAGTACAG------TTAG--G\nSmik CAACGCAAAATAAACAGTCC----CCCGGCCCCACATACCTT-CAAATCGATGCGTAAAACTGGCTAGCATA-GAATTTTGGTAGCAA-AATATTAG--G\nSbay GAACGTGAAATGACAATTCCTTGCCCCT-CCCCAATATACTTTGTTCCGTGTACAGCACACTGGATAGAACAATGATGGGGTTGCGGTCAAGCCTACTCG\n**** * * ***** *** * * * * * * * * **\n\nScer TTTTTAGCCTTATTTCTGGGGTAATTAATCAGCGAAGCG--ATGATTTTT-GATCTATTAACAGATATATAAATGGAAAAGCTGCATAACCAC-----TT\nSpar GTTTT--TCTTATTCCTGAGACAATTCATCCGCAAAAAATAATGGTTTTT-GGTCTATTAGCAAACATATAAATGCAAAAGTTGCATAGCCAC-----TT\nSmik TTCTCA--CCTTTCTCTGTGATAATTCATCACCGAAATG--ATGGTTTA--GGACTATTAGCAAACATATAAATGCAAAAGTCGCAGAGATCA-----AT\nSbay TTTTCCGTTTTACTTCTGTAGTGGCTCAT--GCAGAAAGTAATGGTTTTCTGTTCCTTTTGCAAACATATAAATATGAAAGTAAGATCGCCTCAATTGTA\n* * * *** * ** * * *** *** * * ** ** * ******** **** *\n\nScer TAACTAATACTTTCAACATTTTCAGT--TTGTATTACTT-CTTATTCAAAT----GTCATAAAAGTATCAACA-AAAAATTGTTAATATAC\nSpar TAAATAC-ATTTGCTCCTCCAAGATT--TTTAATTTCGT-TTTGTTTTATT----GTCATGGAAATATTAACA-ACAAGTAGTTAATATAC\nSmik TCATTCC-ATTCGAACCTTTGAGACTAATTATATTTAGTACTAGTTTTCTTTGGAGTTATAGAAATACCAAAA-AAAAATAGTCAGTATCT\nSbay TAGTTTTTCTTTATTCCGTTTGTACTTCTTAGATTTGTTATTTCCGGTTTTACTTTGTCTCCAATTATCAAAACATCAATAACAAGTATTC\n* * * * * * ** *** * * * * ** ** ** * * * * * ***\n\nGAL1\nTBP\nGAL4\nGAL4\nGAL4\nGAL4\nMIG1\nTBP\nMIG1\nTranscription factor binding\nConservation island\nGAL4\nIncrease power by testing conservation in many regions\nATGACTA\n\nGenome-wide conservation\nEvaluate conservation within:\nGal4\nControls\n13% : 3%\n2% : 7%\n\n(2) Intergenic : coding\n12:0\n1:1\n\n(3) Upstream : downstream\nA signature for regulatory motifs\n13%\n2%\n\n(1) All intergenic regions\nSpar\nSmik\nSbay\nScer\n\nTest 1: Intergenic conservation\nTotal count\nConserved count\nCGG-11-CCG\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nTest 2: Intergenic vs. Coding\nCoding Conservation\nIntergenic Conservation\nCGG-11-CCG\nHigher Conservation in Genes\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nTest 3: Upstream vs. Downstream\nCGG-11-CCG\nDownstream motifs?\nMost\nPatterns\nDownstream Conservation\nUpstream Conservation\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nConservation for TF motif discovery\n\n1. Enumerate motif seeds\n\n- Six non-degenerate characters with variable size gap in the\nmiddle\n2. Score seed motifs\n- Use a conservation ratio corrected for composition and\nsmall counts to rank seed motifs\n3. Expand seed motifs\n\n- Use expanded nucleotide IUPAC alphabet to fill unspecified\nbases around seed using hill climbing\n4. Cluster to remove redundancy\n- Using sequence similarity\nG\nT\nC\nA G\nT\nR\nR\nY\ngap\nS\nW\nG\nT\nC\nA G\nT\ngap\nKellis, Nature 2003\n\nLearning motif degeneracy\nusing evolution\n- Record frequency with\nwhich one sequence is\n\"replaced\" by another in\nevolution\n- Use this to find clusters\nof k-mers that\ncorrespond to a single\nmotif\nTanay, Genome Research 2004\n(c) Cold Spring Harbor Laboratory Press. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Tanay, Amos et al. \"A global view of the selection forces in the evolution of yeast\ncis-regulation.\" Genome Research 14, no. 5 (2004): 829-834.\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nValidation of the discovered motifs\n- Because genome-wide motif discovery is de novo, we\ncan use functional datasets for validation\n- Enrichment in co-regulated genes\n- Overlap with TF binding experiments\n- Enrichment in genes from the same complex\n- Positional biases with respect to transcription start\n- Upstream vs. downstream / inter vs. intra-genic bias\n- Similarity to known transcription factor motifs\n- Each of these metrics can also be used for discovery\n- In general, split metrics into discovery vs. validation\n- As long as they are independent !\n- Strategies that combine them all lose ability to validate\n- Directed experimental validation approaches are then needed\n\nSimilarity to known motifs\n- If discovered motifs are real, we\nexpect them to match motifs in large\ndatabases of known motifs\n- We find this (significantly higher than\nwith random motifs)\n- Why not perfect agreement?\n- Many known motifs are not\nconserved\n- Known motifs are biased; may have\nmissed real motifs\nMCS\nDiscovered motif\nKnown\nFactor\n46.8\nGGGCGGR\nSP-1\n34.7\nGCCATnTTg\nYY1\n32.7\nCACGTG\nMYC\n31.2\nGATTGGY\nNF-Y\n30.8\nTGAnTCA\nAP-1\n29.7\nGGGAGGRR\nMAZ\n29.5\nTGACGTMR\nCREB\n26.0\nCGGCCATYK\nNF-MUE1\n25.0\nTGACCTTG\nERR\n22.6\nCCGGAARY\nELK-1\n19.8\nSCGGAAGY\nGABP\n17.9\nCATTTCCK\nSTAT1\nMCS\nDiscovered motif\nKnown\nFactor\n65.6\nCTAATTAAA\nen\n57.3\nTTKCAATTAA\nrepo\n54.9\nWATTRATTK\nara\n54.4\nAAATTTATGC\nK\nprd\nGCAATAAA\nvvl\n46.7\nDTAATTTRYN\nR\nUbx\n45.7\nTGATTAAT\nap\n43.1\nYMATTAAAA\nabd-A\n41.2\nAAACNNGTT\n\nRATTKAATT\n\n39.5\nGCACGTGT\nftz\n38.8\nAACASCTG\nbr-Z3\n70/174 mammalian motifs\n35/145 fly motifs\nStark, Nature 2007\nXie, Nature 2005\n\nPositional bias of motif matches\n- Motifs are involved in initiation of transcription\nMotif matches biased versus TSS\n- 10% of fly motifs\n- 34% of mammalian motifs\nDepletion of TF motifs in coding sequence\n- 57% of fly motifs\nClustering of motif matches\n- 19% of fly motifs\n\nMotifs have functional enrichments\nFor both fly (top) and\nmammals (bottom),\nmotifs are enriched in\ngenes expressed in\nspecific tissues\n\nReveals modules of\ncooperating motifs\nTissues\nMotifs\n1. Most motifs avoided in\nubiquitously expressed genes\n2. Functional clusters emerge\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMotif instance identification\nHow do we determine the functional\nbinding sites of regulators?\nKheradpour, Stark, Roy, Kellis, Genome Research 2007\nTF1\nmicroRNA1\nTF2\n\nExperimental target\nidentification:\nChIP-chip/seq\nLimitations :\n- Antibody availability\n- Restricted to specific\nstages/tissues\n- Biological functionality of\nmost binding sites\nunknown\n- Resolution can be limited\n(can't usually identify the\nprecise base pairs)\nRen et al., 2000; Iyer et al., 2001 (ChIP-chip)\nRobertson et al., 2007 (ChIP-seq)\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComputational target identification\n- Single genome approaches using motif\nclustering (e.g. Berman 2002; Schroeder 2004;\nPhilippakis 2006)\n- Requires set of specific factors that act\ntogether\n- Miss instances of motifs that may occur alone\n- Multi-genome approaches (phylogentic\nfootprinting) (e.g. Moses 2004; Blanchette and\nTompa 2002; Etwiller 2005; Lewis 2003)\n- Tend to either require absolute conservation\nor have a strict model of evolution\n\nChallenges in target identification\n- Simple case\n- Instance fully conserved in orthologous position near genes\n- Motif turn-around/movement\n- Motif instance is not found in orthologous place due to birth/death or\nalignment errors\n- Distal/missing matches\n- Due to sequencing/assembly errors or turnover\n- Distal instances can be difficult to assign to gene\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComputing Branch Length Score (BLS)\nCTCF\nBLS = 2.23sps (78%)\nAllows for:\n1. Mutations permitted by motif\ndegeneracy\n2. Misalignment/movement of motifs within\nwindow (up to hundreds of nucleotides)\n3. Missing motif in dense species tree\nmutations\nmissing short\nbranches\nmovement\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nBranch Length Score Confidence\n1. Evaluate chance likelihood of a given score\n-\nSequence could also be conserved due to overlap\nwith un-annotated element (e.g. non-coding RNA)\n2. Account for differences in motif composition and\nlength\n-\nFor example, short motif more likely to be\nconserved by chance\n\nBranch Length Score Confidence\n1. Use motif-specific shuffled control motifs determine the expected\nnumber of instances at each BLS by chance alone or due to non-\nmotif conservation\n2. Compute Confidence Score as fraction of instances over noise at a\ngiven BLS (=1 - false discovery rate)\n\nProducing control motifs\nWhen evaluating the conservation,\nenrichment, etc, of motifs, it is useful\nto have a set of \"control motifs\"\nProduce 100 shuffles of our original motif\nFilter motifs, requiring they match the genome\nwith about (+/- 20%) of our original motif\nSort potential control motifs based on their\nsimilarity to other known motifs\nCluster potential control motifs and take at\nmost one from each cluster, in increasing\norder of similarity to known motifs\nOriginal motif\nGenome sequence\nKnown motifs\n\nComputing enrichments: background vs. foreground\n-\nBackground vs. forgeround\n- co-regulated promoters vs. all genes\n- Bound by TF vs. other intergenic regions\n-\nEnrichment: fraction of motif\ninstances in foreground vs. fraction\nof bases in foreground\n\n-\nCorrect for composition/conservation\nlevel: compute enrichmt w/control motifs\n- Fraction of motif instances can be\ncompared to fraction of control motif\ninstances in foreground\n- A hypergeometric p-value can be\ncomputed (similar to χ2, but better for\nsmall numbers)\n\n-\nFractions can be made more\nconservative using a binomial\nconfidence interval\n\nForeground (e.g. TF bound):\nBackground (e.g. Intergenic):\nbackground\n\nof\n\nsize\nforeground\n\nof\n\nsize\nbackground\nin\n#\nforeground\nin\n#\n\nbackground\nin\n\ncontrol\n#\nforeground\nin\n\ncontrol\n#\nbackground\nin\n#\nforeground\nin\n#\n\n0.0\n1.0\nfraction\nbinomial confidence interval\nuse this\n\nConfidence selects for functional instances\nTranscription factor motifs\nPromoter\n5'UTR\nCDS\nIntron\n3'UTR\nMicroRNA motifs\nPromoter\n5'UTR\nCDS\nIntron\n3'UTR\n1. Confidence selects for transcription factor motif\ninstances in promoters and miRNA motifs in 3' UTRs\n\nValidation of discovered motif instances\nUse independent experimental evidence\nLook for functional biases / enrichments\n\nConfidence selects for functional instances\n1. Confidence selects for transcription factor motif\ninstances in promoters and miRNA motifs in 3' UTRs\n2. miRNA motifs are found preferentially on the plus strand,\nwhereas no such preference is found for TF motifs\nStrand Bias\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nIncreased sensitivity using BLS\nFigure 3 B removed due to copyright restrictions.\nSource: Kheradpour, Pouya et al. \"Reliable prediction of regulator targets using\n12 Drosophila genomes.\" Genome Research 17, no. 12 (2007): 1919-1931.\n\nIntersection with CTCF ChIP-Seq regions\nChIP-Seq and ChIP-Chip technologies\nallow for identifying binding sites of a\nmotif experimentally\n-\nConserved CTCF motif instances highly\nenriched in ChIP-Seq sites\n-\nHigh enrichment does not require low\nsensitivity\n-\nMany motif instances are verified\n≥ 50% of regions with a motif\n50% motifs verified\n50% confidence\nChIP data from Barski, et al., Cell (2007)\n\nEnrichment found for many factors\n\nBarski, et al., Cell (2007)\nOdom, et al., Nature Genetics (2007)\nLim, et al., Molecular Cell (2007)\nWei, et al., Cell (2006)\nZeller, et al., PNAS (2006)\nLin, et al., PLoS Genetics (2007)\nRobertson, et al., Nature Methods (2006)\nMammals\nAbrams and Andrew, Devel (2005) (Not ChIP)\nSandmann, et al., Devel Cell (2006)\nZeitlinger, et al., Genes & Devel (2007)\nSandmann, et al., Genes & Devel (2007)\nFlies\n\nEnrichment increases in conserved bound regions\nHuman: Barski, et al., Cell (2007)\nMouse: Bernstein, unpublished\n1. ChIP bound regions may not be conserved\n2. For CTCF we also have binding data in mouse\n3. Enrichment in intersection is dramatically higher\n\nMore enrichment when binding\nconserved\nHuman: Barski, et al., Cell (2007)\nMouse: Bernstein, unpublished\nOdom, et al., Nature Genetics (2007)\n1. ChIP bound regions may not be conserved\n2. For CTCF we also have binding data in mouse\n3. Enrichment in intersection is dramatically higher\n4. Trend persists for other factors where we have\nmulti-species ChIP data\n\n1. Motifs at 60% confidence and ChIP have similar enrichments\n(depletion for the repressor Snail) in the functional promoters\n2. Enrichments persist even when you look at non-overlapping subsets\n3. Intersection of two regions has strongest signal\n4. Evolutionary and experimental evidence is complementary\n-\nChIP includes species specific regions and differentiate tissues\n-\nConserved instances include binding sites not seen in tissues surveyed\n\nChIP data from: Zeitlinger, et al., G&D (2007); Sandmann, et al,. G&D (2007); Sandmann, et al., Dev Cell (2006)\nComparing ChIP to Conservation\n\nTFs:\n67 of 83 (81%)\n46k instances\n\nmiRNAs:\n49 of 67 (86%)\n4k instances\n\nSeveral connections confirmed by literature (directly or indirectly)\nGlobal view of instances allows us to make network level observations:\n-\n46% of targets were co-expressed with their factor in at least one tissue (P < 2 x 10-3)\n-\nTFs were more targeted by TFs (P < 10-20) and by miRNAs (P < 5 x 10-5)\n-\nTF in-degree associated with miRNA in-degree (high-high: P < 10-4; low-low P < 10-6)\nFly regulatory network at 60% confidence\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nRegulator\nTF/miRNA\nMotif\nSequence\nspecificity\nTFs: Selex, DIP-Chip, Protein-Binding-Microarrays\nmiRNAs: Evolutionary/structural signatures\nmiRNAs: Experimental cloning of 5'-ends\nTFs: Mass Spec (difficult)\nTFs: ChIP-Chip/ChIP-Seq\nTFs/miRs: Perturbation response\nTFs/miRNAs: Evolutionary signatures**\nmiRNAs: Composition/folding\nTFs: Enrichment in\nco-regulated genes/\nbound regions **\nTFs: Homology to TFs/domains\nmiRNAs: Evolutionary signatures\nmiRNAs: Experimental cloning\nTFs/miRNAs: De novo\ncomparative discovery**\n* = Covered in today's lecture\nNetwork analysis\n(next lecture)\nChallenges in regulatory genomics\nTargets\nFunctional instances\n\nRecitation tomorrow: in vitro motif identification\nSELEX (Systematic\nEvolution of\nLigands by\nExponential\nEnrichment; Klug\n& Famulok, 1994)\nPBMs (Protein\nbinding\nmicroarrays;\nMukherjee, 2004)\nDouble stranded\nDNA arrays\n-\nPBMs: Protein binding\nmicroarrays\n-\nSELEX: Selection-\nbased motif\nidentiifcation\n\n-\nDe Bruijn graphs to\ngenerate PBM probes\n-\nFrom k-mers to motifs\n-\nGapped motifs\n\n-\nDegenerate motifs and\nDNA bending (DNA\nshape)\n\n-\nRelaxing\nindependence\nassumptions in PWMs\nCourtesy of the authors. Used with permission. (c) s\nSource: Ray, Partha, and Rebekah R. White.\nThis\n\"Aptamers for targeted drug delivery.\"\nource unknown. All rights reserved.\ncontent is excluded from our Creative\nCommons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\nPharmaceuticals 3, no. 6 (2010): 1761-1778.\n\nMotif discovery overview\n1. Introduction to regulatory motifs / gene regulation\n-\nTwo settings: co-regulated genes (EM,Gibbs), de novo\n2. Expectation maximization: Motif matrixpositions\n-\nE step: Estimate motif positions Zij from motif matrix\n-\nM step: Find max-likelihood motif from all positions Zij\n3. Gibbs Sampling: Sample from joint (M,Zij) distribution\n-\nSampling motif positions based on the Z vector\n-\nMore likely to find global maximum, easy to implement\n4. Evolutionary signatures for de novo motif discovery\n-\nGenome-wide conservation scores, motif extension\n-\nValidation of discovered motifs: functional datasets\n5. Evolutionary signatures for instance identification\n-\nPhylogenies, Branch length score Confidence score\n-\nForeground vs. background. Real vs. control motifs.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 17 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/ced9b183e19e78e8a22e1ad64ae25736_MIT6_047F15_Lecture17.pdf",
      "content": "Lecture 17\n\nComparative genomics I:\n\nGenome annotation using\nevolutionary signatures\n6.047/6.878/HST.507\nComputational Biology: Genomes, Networks, Evolution\n\nModule V: Comparative genomics and evolution\n- Today: Whole-genome comparative genomics\n- Evolutionary signatures for systematic genome annotation\n- Next week: Phylogenetics and Phylogenomics\n- Distance-based and model-based phylogenetics approaches\n- Gene trees and species trees, reconciliation, coalescence\n- Computational foundations:\n- Evolutionary rates and models of evolution\n- Dynamic programming on two-dimensional tree structures\n- Synteny-based alignment, genome assembly\n\nKey goal: Evolution preserves functional elements\nScer TTATATTGAATTTTCAAAAATTCTTACTTTTTTTTTGGATGGACGCAAAGAAGTTTAATAATCATATTACATGGCATTACCACCATATACA\nSpar CTATGTTGATCTTTTCAGAATTTTT-CACTATATTAAGATGGGTGCAAAGAAGTGTGATTATTATATTACATCGCTTTCCTATCATACACA\nSmik GTATATTGAATTTTTCAGTTTTTTTTCACTATCTTCAAGGTTATGTAAAAAA-TGTCAAGATAATATTACATTTCGTTACTATCATACACA\nSbay TTTTTTTGATTTCTTTAGTTTTCTTTCTTTAACTTCAAAATTATAAAAGAAAGTGTAGTCACATCATGCTATCT-GTCACTATCACATATA\n* * **** * * * ** ** * * ** ** ** * * * ** ** * * * ** * * *\n\nScer TATCCATATCTAATCTTACTTATATGTTGT-GGAAAT-GTAAAGAGCCCCATTATCTTAGCCTAAAAAAACC--TTCTCTTTGGAACTTTCAGTAATACG\nSpar TATCCATATCTAGTCTTACTTATATGTTGT-GAGAGT-GTTGATAACCCCAGTATCTTAACCCAAGAAAGCC--TT-TCTATGAAACTTGAACTG-TACG\nSmik TACCGATGTCTAGTCTTACTTATATGTTAC-GGGAATTGTTGGTAATCCCAGTCTCCCAGATCAAAAAAGGT--CTTTCTATGGAGCTTTG-CTA-TATG\nSbay TAGATATTTCTGATCTTTCTTATATATTATAGAGAGATGCCAATAAACGTGCTACCTCGAACAAAAGAAGGGGATTTTCTGTAGGGCTTTCCCTATTTTG\n** ** *** **** ******* ** * * * * * * * ** ** * *** * *** * * *\n\nScer CTTAACTGCTCATTGC-----TATATTGAAGTACGGATTAGAAGCCGCCGAGCGGGCGACAGCCCTCCGACGGAAGACTCTCCTCCGTGCGTCCTCGTCT\nSpar CTAAACTGCTCATTGC-----AATATTGAAGTACGGATCAGAAGCCGCCGAGCGGACGACAGCCCTCCGACGGAATATTCCCCTCCGTGCGTCGCCGTCT\nSmik TTTAGCTGTTCAAG--------ATATTGAAATACGGATGAGAAGCCGCCGAACGGACGACAATTCCCCGACGGAACATTCTCCTCCGCGCGGCGTCCTCT\nSbay TCTTATTGTCCATTACTTCGCAATGTTGAAATACGGATCAGAAGCTGCCGACCGGATGACAGTACTCCGGCGGAAAACTGTCCTCCGTGCGAAGTCGTCT\n** ** ** ***** ******* ****** ***** *** **** * *** ***** * * ****** *** * ***\n\nScer TCACCGG-TCGCGTTCCTGAAACGCAGATGTGCCTCGCGCCGCACTGCTCCGAACAATAAAGATTCTACAA-----TACTAGCTTTT--ATGGTTATGAA\nSpar TCGTCGGGTTGTGTCCCTTAA-CATCGATGTACCTCGCGCCGCCCTGCTCCGAACAATAAGGATTCTACAAGAAA-TACTTGTTTTTTTATGGTTATGAC\nSmik ACGTTGG-TCGCGTCCCTGAA-CATAGGTACGGCTCGCACCACCGTGGTCCGAACTATAATACTGGCATAAAGAGGTACTAATTTCT--ACGGTGATGCC\nSbay GTG-CGGATCACGTCCCTGAT-TACTGAAGCGTCTCGCCCCGCCATACCCCGAACAATGCAAATGCAAGAACAAA-TGCCTGTAGTG--GCAGTTATGGT\n** * ** *** * * ***** ** * * ****** ** * * ** * * ** ***\n\nScer GAGGA-AAAATTGGCAGTAA----CCTGGCCCCACAAACCTT-CAAATTAACGAATCAAATTAACAACCATA-GGATGATAATGCGA------TTAG--T\nSpar AGGAACAAAATAAGCAGCCC----ACTGACCCCATATACCTTTCAAACTATTGAATCAAATTGGCCAGCATA-TGGTAATAGTACAG------TTAG--G\nSmik CAACGCAAAATAAACAGTCC----CCCGGCCCCACATACCTT-CAAATCGATGCGTAAAACTGGCTAGCATA-GAATTTTGGTAGCAA-AATATTAG--G\nSbay GAACGTGAAATGACAATTCCTTGCCCCT-CCCCAATATACTTTGTTCCGTGTACAGCACACTGGATAGAACAATGATGGGGTTGCGGTCAAGCCTACTCG\n**** * * ***** *** * * * * * * * * **\n\nScer TTTTTAGCCTTATTTCTGGGGTAATTAATCAGCGAAGCG--ATGATTTTT-GATCTATTAACAGATATATAAATGGAAAAGCTGCATAACCAC-----TT\nSpar GTTTT--TCTTATTCCTGAGACAATTCATCCGCAAAAAATAATGGTTTTT-GGTCTATTAGCAAACATATAAATGCAAAAGTTGCATAGCCAC-----TT\nSmik TTCTCA--CCTTTCTCTGTGATAATTCATCACCGAAATG--ATGGTTTA--GGACTATTAGCAAACATATAAATGCAAAAGTCGCAGAGATCA-----AT\nSbay TTTTCCGTTTTACTTCTGTAGTGGCTCAT--GCAGAAAGTAATGGTTTTCTGTTCCTTTTGCAAACATATAAATATGAAAGTAAGATCGCCTCAATTGTA\n* * * *** * ** * * *** *** * * ** ** * ******** **** *\n\nScer TAACTAATACTTTCAACATTTTCAGT--TTGTATTACTT-CTTATTCAAAT----GTCATAAAAGTATCAACA-AAAAATTGTTAATATACCTCTATACT\nSpar TAAATAC-ATTTGCTCCTCCAAGATT--TTTAATTTCGT-TTTGTTTTATT----GTCATGGAAATATTAACA-ACAAGTAGTTAATATACATCTATACT\nSmik TCATTCC-ATTCGAACCTTTGAGACTAATTATATTTAGTACTAGTTTTCTTTGGAGTTATAGAAATACCAAAA-AAAAATAGTCAGTATCTATACATACA\nSbay TAGTTTTTCTTTATTCCGTTTGTACTTCTTAGATTTGTTATTTCCGGTTTTACTTTGTCTCCAATTATCAAAACATCAATAACAAGTATTCAACATTTGT\n* * * * * * ** *** * * * * ** ** ** * * * * * *** *\n\nScer TTAA-CGTCAAGGA---GAAAAAACTATA\nSpar TTAT-CGTCAAGGAAA-GAACAAACTATA\nSmik TCGTTCATCAAGAA----AAAAAACTA..\nSbay TTATCCCAAAAAAACAACAACAACATATA\n* * ** * ** ** **\nGal10\nGal1\nGal4\nGAL10\nGAL1\nTBP\nGAL4\nGAL4\nGAL4\nGAL4\nMIG1\nTBP\nMIG1\nFactor footprint\nConservation island\nWe can 'read' evolution to reveal functional elements\nYeast (Kellis et al, Nature 2003), Mammals (Xie, Nature 2005), Fly (Stark et al, Nature 07)\n\nEvolution\nGenomics\nUsing evolution to study genomes\nUsing genomics to study evolution\nComparative Genomics\nLectures 18-19\n(Thursday):\nLecture 17\n(Today):\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n- Measuring selection within the human lineage\n\nComparative genomics for genome annotation\n- Compare related species to discover functional elmts\n- Evolution process: random mutation, natural selection\n- Non-functional regions: accumulate mutations, kept\n- Functional regions: accumulate mutations, decrease fitness\n- Evolutionary time: less fit organisms & their genes thin out\n8 Candida\n9 Yeasts\nPost-duplication\nDiploid\nHaploid\nPre-dup\nP\nP\nP\nP\nP\nP\n29 mammals\n17 fungi\n12 flies\nN\nN\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nPower of many closely related: total branch length\n- More branch length more events more power\n- Goal: functional vs. non-functional based on # of mutations\n- Very close distances: no mutations in either region\n- Sufficient distance: ability to distinguish increases\n- Very far distances: functional regions no longer conserved\n- Many closely related species >> few distantly related\n- For same total branch length: prefer many close species\n- Functional regions conserved for each pair of species\n- Non-functional regions accumulate noise independently\n- Analogy: recording a concert with multiple microphones\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nGenome-wide alignments reveal orthologous segments\n- Genome-wide alignments span entire genome\n- Comparative identification of functional elements\n100 genes\nCourtesy of Don Gilbert. Used with permission.\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics and evolutionary signatures\n-\nComparative genomics can reveal functional elements\n- For example: exons are deeply conserved to mouse, chicken, fish\n- Many other elements are also strongly conserved: exons / regulatory?\n-\nDevelop methods for estimating the level of constraint\n- Count the number of edit operations, number of substitutions and gaps\n- Estimate the number of mutations (including estimate of back-mutations)\n- Incorporate information about neighborhood: conservation 'windows'\n- Estimate the probability of a constrained 'hidden state': HMMs next week\n- Use phylogeny to estimate tree mutation rate, or 'rejected substitutions'\n- Allow different portions of the tree to have different rates: phylogenetics 10\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nDetecting rates and patterns of selection (ω/π)\nConstrained sequence\nEstimating intensity of constraint ():\n- Probabilistic model of substitution rate\n- Maximum Likelihood (ML) estimation of\n- Report rate ω\n- Report log odds score that non-neutral\n- Window-based vs. sitewise application\nManuel Garber, Or Zuk, Xiaohui Xie\nNeutral sequence\nDecreased rate ω\n0 0 0.8 0.5 0.6 3.2 0 0\nDetect unusual substitution pattern (π):\n-Probabilistic model of stationary distribution\nthat is different from background.\n-ML estimator () of this vector\n- Report PWM for each k-mer in genome.\n- Report log odds score that non-neutral\nUnusual patterns π\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/. 11\n\nMeasuring constraint at individual nucleotides\n- Reveal individual transcription factor binding sites\n- Within motif instances reveal position-specific bias\n- More species: motif consensus directly revealed\nNRSF\nmotif\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nDetect SNPs that disrupt conserved regulatory motifs\n- Functionally-associated SNPs enriched in states, constraint\n- Prioritize candidates, increase resolution, disrupted motifs\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nEstimating portion of the genome under constraint\n4 mammals\n29 mammals\n\nConstraint calculated over a 50mer\nOr Zuk, Manuel Garber\n5% FDR\n0.6%\ndetectable\n5% FDR\n1.8%\ndetectable\n4 mammals\n21 mammals\nConstraint calculated over a 12mer\n5% FDR\nno signal\n5% FDR\n1.1%\ndetectable\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nEstimating total fraction under constraint\n- Actual distribution of conservation scores (Signal) vs. expected\ndistribution if no constraint (Background).\n- At any cutoff: true positives (TP) and false predictions (FP)\n- Can't detect all constrained elements since curves overlap\n- But we can estimate the total amount of excess constraint by\nintegrating over entire area between the two curves\nConservation\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nDetection of evolutionarily constrained elements\nExcess positive/purifying selection Distribution of constraint\nHighest enrichment\nfor coding transcripts\nMost new elements in\nintronic/intergenic\nregions\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nCoverage depth higher in functional regions\nChallenges of low-coverage genomes: varying aligment depth\nEvidence of selection against deletions in functional regions\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nIncrease in power from HMRD to 29 mammals\nManuel Garber, Or Zuk\nπ log-odds\n(12mers)\nπ log-odds\n(50mers)\nω\n(12mers)\nω\n(50mers)\n29 mammals\n\n7.1/1.5/4.6\n\n6.8/1.8/4.1 5.7/ 1.1/3.8\n\n5.7/1.8/3.0\n\n(HMRD) Human\nMouse Rat Dog\n4.2/0.0/0.0 5.3/0.1/0.3\n4.5/0.0/0.0\n5.1/0.6/1.7\nEstimated / kmers detectable at 5% FDR / base pairs detectable at 5% FDR\nSmall increase in estimate of genome percentage under constraint\nDramatic increase in power to detect small constrained elements\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nComparative genomics and evolutionary signatures\n-\nComparative genomics can reveal functional elements\n- For example: exons are deeply conserved to mouse, chicken, fish\n- Many other elements are also strongly conserved: exons / regulatory?\n\n-\nCan we also pinpoint specific functions of each region? Yes!\n- Patterns of change distinguish different types of functional elements\n- Specific function Selective pressures Patterns of mutation/inse/del\n\n-\nDevelop evolutionary signatures characteristic of each function\nStark et al, Nature 2007\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nEvolutionary signatures for diverse functions\nProtein-coding genes\n- Codon Substitution Frequencies\n- Reading Frame Conservation\nRNA structures\n- Compensatory changes\n- Silent G-U substitutions\nmicroRNAs\n- Shape of conservation profile\n- Structural features: loops, pairs\n- Relationship with 3'UTR motifs\nRegulatory motifs\n- Mutations preserve consensus\n- Increased Branch Length Score\n- Genome-wide conservation\nStark et al, Nature 2007\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Stark, Alexander et al. \"Discovery of functional elements in 12 Drosophila\ngenomes using evolutionary signatures.\" Nature 450, no. 7167 (2007): 219-232.\n\nImplications for genome annotation / regulation\nNovel protein-coding genes\nRevised gene annotations\nUnusual gene structures\nNovel structural families\nTargeting, editing, stability\nRiboswitches in mammals\nNovel/expanded miR families\nmiR/miR* arm cooperation\nSense/anti-sense miR switches\nNovel regulatory motifs\nRegulatory motif instances\nTF/miRNA regulatory networks\nSingle binding site resolution\nStark et al, Nature 2007 23\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Stark, Alexander et al. \"Discovery of functional elements in 12 Drosophila\ngenomes using evolutionary signatures.\" Nature 450, no. 7167 (2007): 219-232.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nEvolutionary signatures for protein-coding genes\nDmel TGTTCATAAATAAA-----TTTACAACAGTTAGCTG-GTTAGCCAGGCGGAGTGTCTGCGCCCATTACCGTGCGGACGAGCATGT---GGCTCCAGCATCTTC\nDsec TGTCCATAAATAAA-----TTTACAACAGTTAGCTG-GTTAGCCAGGCGGAGTGTCTGCGCCCATTACCGTGCGGACGAGCATGT---GGCTCCAGCATCTTC\nDsim TGTCCATAAATAAA-----TTTACAACAGTTAGCTG-GTTAGCCAGGCGGAGTGTCTGCGCCCATTACCGTGCGGACGAGCATGT---GGCTCCAGCATCTTC\nDyak TGTCCATAAATAAA-----TTTACAACAGTTAGCTG-GTTAGCCAGGCGGAGTGCCTTCTACCATTACCGTGCGGACGAGCATGT---GGCTCCAGCATCTTC\nDere TGTCCATAAATAAA-----TTTACAACAGTTAGCTG-CTTAGCCATGCGGAGTGCCTCCTGCCATTGCCGTGCGGGCGAGCATGT---GGCTCCAGCATCTTT\nDana TGTCCATAAATAAA-----TCTACAACATTTAGCTG-GTTAGCCAGGCGGAGTGTCTGCGACCGTTCATG------CGGCCGTGA---GGCTCCATCATCTTA\nDpse TGTCCATAAATGAA-----TTTACAACATTTAGCTG-CTTAGCCAGGCGGAATGGCGCCGTCCGTTCCCGTGCATACGCCCGTGG---GGCTCCATCATTTTC\nDper TGTCCATAAATGAA-----TTTACAACATTTAGCTG-CTTAGCCAGGCGGAATGCCGCCGTCCGTTCCCGTGCATACGCCCGTGG---GGCTCCATTATTTTC\nDwil TGTTCATAAATGAA-----TTTACAACACTTAACTGAGTTAGCCAAGCCGAGTGCCGCCGGCCATTAGTATGCAAACGACCATGG---GGTTCCATTATCTTC\nDmoj TGATTATAAACGTAATGCTTTTATAACAATTAGCTG-GTTAGCCAAGCCGAGTGGCGCC------TGCCGTGCGTACGCCCCTGTCCCGGCTCCATCAGCTTT\nDvir TGTTTATAAAATTAATTCTTTTAAAACAATTAGCTG-GTTAGCCAGGCGGAATGGCGCC------GTCCGTGCGTGCGGCTCTGGCCCGGCTCCATCAGCTTC\nDgri TGTCTATAAAAATAATTCTTTTATGACACTTAACTG-ATTAGCCAGGCAGAGTGTCGCC------TGCCATGGGCACGACCCTGGCCGGGTTCCATCAGCTTT\n***** * * ** *** *** *** ******* ** ** ** * * ** * ** ** ** ** **** * **\n-\nSame conservation levels, distinct patterns of divergence\n- Gaps are multiples of three (preserve amino acid translation)\n- Mutations are largely 3-periodic (silent codon substitutions)\n- Specific triplets exchanged more frequently (conservative substs.)\n- Conservation boundaries are sharp (pinpoint individual splicing signals)\nSplice\nFrame-shifting indels\nPeriodic mutations\nSynonymous substs.\nEvolutionary signatures of protein-coding selection\n\nEvolutionary signatures of protein-coding genes\nSome point mutations to the DNA\nsequence do not change its protein\ntranslation at all.\nNatural selection tends to tolerate mutations with little/no effect on the protein.\nDNA insertions and deletions can either\ninsert/remove AAs, or totally mangle the\nremainder of the protein (frameshift).\nthe fat cat sat\nΔ1 the atc ats at\nΔ2 the tca tsa t\nΔ3 the cat sat\n\nProtein-coding sequences tolerate distinctive types of change\nprotein-coding exon\nconserved non-coding\nsequence\nsynonymous\nconservative\nframe-shifted\nnon-conservative\nthree stop codons\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nKnown genes stand out\nSubstitution typical of protein-coding regions\nSubstitution typical of intergenic regions\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nSignature 1: Reading frame conservation\n30%\n1.3%\n0.14%\n58%\n14%\n10.2%\nGenes\nIntergenic\nMutations\nGaps\nFrameshifts\nSeparation\n2-fold\n10-fold\n75-fold\n\n100%\n100%\n100%\n100%\n100%\n100%\n100%\n100%\n100%\n60%\n55%\n90%\n40%\n60%\n100%\n20%\n30%\n40%\n100%\n60%\nRFC\nRFC\n\n100%\n100%\n100%\n100%\n100%\n100%\n100%\n100%\n100%\n60%\n60%\n90%\n40%\n60%\n100%\n30%\n30%\n30%\n56%\n100%\nReading Frame Conservation Test\n\nScer CTTCTAGATTTTCATCTT-GTCGATGTTCAAACAACGTGTTA-----TCAGAGAAACAGCTCTATGAGAAATCAGCTGATG\n\nSpar TATTCATA-TCTCATCTTCATCAATGTTCAAACAGCGTGTTACAGACACAGAGAAACAGCTTC-TGAGAAGTCAGCCGGTG\n\nScer CTTCTAGATTTTCATCTT-GTCGATGTTCAAACAACGTGTTA-----TCAGAGAAACAGCTCTATGAGAAATCAGCTGATG\nScer_f1 123123123123123123-12312312312312312312312-----3123123123123123123123123123123123\n\nSpar TATTCATA-TCTCATCTTCATCAATGTTCAAACAGCGTGTTACAGACACAGAGAAACAGCTTC-TGAGAAGTCAGCCGGTG\nSpar_f1 12312312-312312312312312312312312312312312312312312312312312312-31231231231231231\nSpar_f2 23123123-123123123123123123123123123123123123123123123123123123-12312312312312312\nSpar_f3 31231231-231231231231231231231231231231231231231231231231231231-23123123123123123\n\nScer CTTCTAGATTTTCATCTT-GTCGATGTTCAAACAACGTGTTA-----TCAGAGAAACAGCTCTATGAGAAATCAGCTGATG\nScer_f1 123123123123123123-12312312312312312312312-----3123123123123123123123123123123123\n\nSpar TATTCATA-TCTCATCTTCATCAATGTTCAAACAGCGTGTTACAGACACAGAGAAACAGCTTC-TGAGAAGTCAGCCGGTG\nSpar_f1 12312312-312312312312312312312312312312312312312312312312312312-31231231231231231\nSpar_f2 23123123-123123123123123123123123123123123123123123123123123123-12312312312312312\nSpar_f3 31231231-231231231231231231231231231231231231231231231231231231-23123123123123123\n\nScer CTTCTAGATTTTCATCTT-GTCGATGTTCAAACAACGTGTTA-----TCAGAGAAACAGCTCTATGAGAAATCAGCTGATG\nScer_f1 123123123123123123-12312312312312312312312-----3123123123123123123123123123123123\n\nSpar TATTCATA-TCTCATCTTCATCAATGTTCAAACAGCGTGTTACAGACACAGAGAAACAGCTTC-TGAGAAGTCAGCCGGTG RFC\nSpar_f1 12312312-312312312312312312312312312312312312312312312312312312-31231231231231231 43%\nSpar_f2 23123123-123123123123123123123123123123123123123123123123123123-12312312312312312 34%\nSpar_f3 31231231-231231231231231231231231231231231231231231231231231231-23123123123123123 23%\n\nF1\nF2\nF1\nF2\nF3\n\nRevisiting gene content with RFC test\nAccept\nReject\n~4000 named genes\n99.9%\n0.1%\n~300 intergenic regions\n1%\n99%\nAccept\nReject\n~4000 named genes\n~300 intergenic regions\nExample of a rejected ORF\nAccept\nReject\n~4000 named genes\n~300 intergenic regions\nAccept\nReject\n~4000 named genes\n99.9%\n0.1%\n~300 intergenic regions\n1%\n99%\n2000 Hypothetical\nORFs\nHigh sensitivity and specificity\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nA method to distinguish these evolutionary signatures should:\n\n-Quantify the distinctiveness of all 642 possible codon substitutions\n-Synonymous: very frequent in protein-coding sequences\n-Nonsense: much more frequent in non-coding than coding regions\n-Model the phylogenetic relationship among the species\n-Multiple apparent substitutions may be explained by one evolutionary event\n-Tolerate uncertainty in the input\n-Unknown ancestral sequences\n-Alignment gaps, missing data\n-Report the [un]certainty of the result\n-Quantify confidence that given alignment is protein-coding\n-Units: p-value, bits, decibans, etc.\nprotein-coding exon\nconserved non-coding sequence\n\nCodon evolution can be modeled as a Bayesian network\nATT\nATT\nGTT\nATA\ndmel\ndsim\ndsec\ndyak\na\nb\nEach site (codon alignment\ncolumn) is treated\nindependently.\n\nGiven the topology and CPDs,\nwe can simulate evolution of an\nancestral sequence.\n\nAdditionally given extant (leaf)\nsequences, the ancestral\nsequences can be inferred.\n\nFor L leaves, CPDs total about\n\nparameters.\n\nConditional probability distribution (CPD) giving,\nfor all codons a & b,\n\nWe can obtain maximum likelihood estimates of\nparameters using EM in training data.\nThe Bayes net is parameterized as a continuous-time Markov process\nRate matrix (Q)\nBranch lengths t\nEach CPD is determined by a rate matrix shared throughout the tree\nand a branch-specific 'time' (branch length):\nIntuition: The branch lengths specify how much 'time' passed between any two nodes. The\nrate matrix describes the relative frequencies of codon substitutions per unit branch length.\nSynonymous substitutions have high rates and nonsense substitutions have low rates.\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n\nExample nucleotide (4x4) rate & substitution matrices\nA\nG\nC\nT\nA G C T\nQ =\nis the solution to the system of differential equations describing the Markov process\nmodel of evolution.\nAnalogy:\nsolves the differential equation\nSide note: Jukes-Cantor and Kimura models are\nset up so that the entries of eQt have closed-form\nsolutions.\n\n-\nCollect many alignments of known protein-coding sequences (training\ndata)\n-\nConsider the probability of the training data as a function of Q\n\n-\nChoose the Q that maximizes that probability:\n\n-\nMaximization strategies: expectation-maximization; gradient ascent;\nsimulated annealing; spectral decomposition; others\n-\nBranch lengths can also be optimized in the same way (simultaneously)\n-\nNon-coding model estimated similarly, with random non-coding regions\nas training data.\nThe hairy math: how do we estimate Q?\nStill computed using Felsenstein algorithm\nNote: Q represents thousands of parameters\n\nRate matrix (Q)\nBranch lengths t\nGiven this generative model\nof codon evolution:\nWe can compute the probability of any given alignment, marginalizing over all\npossible ancestral sequences, using Felsenstein's pruning algorithm.\nprotein-coding exon\nconserved non-coding sequence\nIf I simulate alignments randomly according to the model, I'll get this\nexact alignment once every 10117 samples\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n\nNow suppose we've estimated\ntwo rate matrices:\nQC estimated from known\ncoding regions\nQN estimated from non-\ncoding regions\nThese specify different rates of codon substitution, which in turn lead to different\nprobabilities of any given alignment:\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nThis alignment is 1035 times more probable under the coding model than the non-coding model.\nThis alignment is 1021 times less probable under the coding model than the non-coding model.\nThis likelihood ratio\nis our measure of confidence that\nthe alignment is protein-coding.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nEvolutionary signatures can predict new genes and\nexons\nProtein-Coding\nEvolutionary Signatures\nTargeted validation\nfull-length cDNA\nEvolutionary signatures built\ninto a semi-Markov conditional\nrandom field to predict protein-\ncoding exons\nSMCRF Viterbi decoding\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Stark, Alexander et al. \"Discovery of functional elements in 12 Drosophila\ngenomes using evolutionary signatures.\" Nature 450, no. 7167 (2007): 219-232.\n\nNew protein-coding genes\nNew genes supported by Illumina BodyAtlas transcripts\nSubmitted to GENCODE for validation / manual curation\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nTranslational read-through in flies and mammals\n- New mechanism of post-transcriptional regulation?\n- Conserved in both mammals (4 candidates) and flies (350 candidates)\n- Strongly enriched for neurotransmitters, brain-expressed proteins, TF regulators\n- After correcting for gene length: TF enrichment remains\n- Evidence suggestive of regulatory control\n- Read-through stop codon perfectly conserved in 93% of cases (24% at bkgrnd)\n- Upstream bases show increased conservation. Downstream is TGAC.\n- GCA triplet repeats\n- Increased RNA secondary structure\nProtein-coding\nconservation\nContinued protein-coding\nconservation\nNo more\nconservation\nStop codon\nread through\n2nd stop\ncodon\nLin et al, Genome Research 2007\nJungreis et al, in preparation\nOne of four novel candidates in the human genome: OPRL1 neurotransmitter\n\nDiscover of translational readthrough genes\nDiscovery of 4 readthrough genes,\nabundant in many animal genomes\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nOverlapping selection in protein-coding exons\nrhombomere 2 expr.\n(Tumpel PNAS 2008)\nrhombomere 4 expression\n(Lampe et al., NAR 2008)\n10,000 overlapping synonymous constrained elements\nRoles in splicing, translation, regulation\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nCodon-specific measures of positive selection\nGene-wide vs. punctate regions of exons positive selection\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nNew RNA structures and families\nEx: new struct in XIST long non-coding RNA\nKnown function in X-chromosome inactivation\nPossible functional domain of XIST?\nNew structs fall in families, supported by evolut/energy\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nRNA families: orthologous/paralogous conservation\nExample of new structural 3'UTR family in MAT2A gene\nlikely role in detecting S-adeosyl-methionic (SAM) level\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\n760,355\nmiRNA-like hairpins\n60-100\ntrue miRNAs\nComputational challenge of miRNA discovery\nA false positive rate of 0.5% 3800 spurious hairpins.\nNeed 99.99% specificity (>5,000-fold enrichment)\n\nEvolutionary signatures for microRNA genes\nmiRNAs show characteristic conservation properties\n(1) Conservation\n\nprofile\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nDistinguishing true miRNAs from random hairpins\nCombination of features:\n> 4,500-fold enrichment\nEvolutionary features\nFeature performance\nEnrichment\nTotal\nStructural features\n(4)\n(5)\n(6)\n(1)\n(2)\n(3)\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nmiRNA detection using many decision trees\n- For each tree:\n- Randomly select:\n- Subset of features to base classification on\n- Subset of +/- training examples\n- Remainder of testing examples\n- Use to train a decision tree classifier:\n- Select a feature and cutoff at each level\n- Continue with feature/cutoff at next level\n- (...)\n- Evaluate performance on test set:\n- Push each element down the decision tree\n- Leaf label gives classification decision\nMFE<3?\nyes\nno\nProfileCorr<8\nyes\nno\nStrConsIndx>3\nyes\nno\nNOT\nmiRNA\nNOT\nStability>4\nyes\nno\nNOT\nyes\nno\n#Loops>2\n#Loops<5\nyes\nno\nmiRNA\nNOT\nNOT\n- To combine trees:\n- Average prediction class across trees\n- Report class with maximum # of votes\n\nRandom Forests: Combine many decision trees\n- Many decision trees:\n- Each can select cutoffs and direction of cutoff\n- Each feature can be reused multiple times\n- Used serially (AND) and in parallel (OR)\n- Ensemble classifier\n- Bagging: model averaging, combines predictions\n- Can take median of predictions\n- Advantages: Robustness, Feature importance\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nEvidence 1: Novel miRNAs match sequencing reads\nRuby, Bartel, Lai\n348 reads\n16 reads\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nEvidence 2: Genomic properties typical of miRNAs\n- Genomic clustering with novel / known miRNAs\n- Same family, common origin / same precursor\n- Novel miRNAs in introns of known genes\n- Preference for + strand, transcription factors\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nTwo novel miRNAs overlap exons (5'UTR and coding!)\nTwo 'dubious' protein-coding genes are in fact miRNAs\n-\nBoth CG31044 and CG33311 were independently rejected as dubious\nbased on their non-protein-coding conservation patterns (Lin et al.)\n-\nNovel miRNA genes provide explanation for their transcripts, as\ntheir precursor miRNA\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n\nSurprise 1: microRNA & microRNA* function\n-\nBoth hairpin arms of a microRNA can be functional\n- High scores, abundant processing, conserved targets\n- Hox miRNAs miR-10 and miR-iab-4 as master Hox regulators\nStark et al, Genome Research 2007\nDrosophila Hox\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nEvidence of miR-iab-4 anti-sense (AS) function\n-\nA single miRNA locus transcribed from both strands\n-\nThe two transcripts show distinct expression domains (mutually exclusive)\n-\nBoth processed to mature miRNAs: mir-iab-4, miR-iab-4AS (anti-sense)\nsense\nanti-\nsense\nStark et al, Genes&Development 2008\nHighly conserved Hox targets\n(c) Cold Spring Harbor Laboratory Press. All rights reserved. This content is excluded from our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\nSource: Stark, Alexander et al. \"A single Hox locus in Drosophila produces functional microRNAs from opposite DNA strands.\" Genes & development\n22, no. 1 (2008): 8-13.\n\nmiR-iab-4AS leads to homeotic transformations\n-\nMis-expression of mir-iab-4S & AS:\naltereswings homeotic transform.\n-\nStronger phenotype for AS miRNA\n-\nSense/anti-sense pairs as general\nbuilding blocks for miRNA regulation\n-\n10 sense/anti-sense miRNAs in mouse\nhaltere\nwing\nwing\nhaltere\nSensory bristles\nwing\nw/bristles\nsense\nAntisense\nWT\nNote: C,D,E same magnification\nStark et al, Genes&Development 2008\n(c) Cold Spring Harbor Laboratory Press. All rights reserved. This content is excluded from our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\nSource: Stark, Alexander et al. \"A single Hox locus in Drosophila produces functional microRNAs from opposite DNA strands.\" Genes & development\n22, no. 1 (2008): 8-13.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n- Measuring selection within the human lineage\n\nMammalian constraint matches Human SNPs\nHuman SNPs match mammalian-wide twofold constraint\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMammalian constraint matches Human SNPs\nGenome-wide agreement of selection and polymorphisms\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nHuman constraint outside conserved regions\n- Non-conserved regions:\n- ENCODE-active regions\nshow reduced diversity\nLineage-specific constraint in\nbiochemically-active regions\n- Conserved regions:\n- Non-ENCODE regions\nshow increased diversity\nLoss of constraint in human\nwhen biochemically-inactive\nAverage\ndiversity\n(heterozygosity)\n\nAggregate over\nthe genome\nActive regions\n(c) Source unknown. All rights reserved.\nThis content is excluded from our Creative\nCommons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\n\nStrongest: motifs, short RNA, Dnase, ChIP, lncRNA\n- Significant derived allele depletion in active features\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nBound motifs show increased human constraint\nPosition-specific reduction in bound motif heterozygosity\nAggregate across thousands of CTCF motif instances\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMost constrained human-specific enhancer functions\nRegulatory genes: Transcription, Chromatin, Signaling.\nDevelopmental enhancers: embryo, nerve growth\nTranscription initiation from Pol2 promoter\nTranscription coactivator activity\nTranscription factor binding\nChromatin binding\nNegative regulation of transcription, DNA-dependent\nTranscription factor complex\nProtein complex\nProtein kinase activity\nNerve growth factor receptor signaling pathway\nSignal transducer activity\nProtein serine/threonine kinase activity\nNegative regulation of transcription from Pol2 prom\nProtein tyrosine kinase activity\nIn utero embryonic development (c) Source unknown. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics I: Evolutionary signatures\n- Nucleotide conservation: evolutionary constraint\n- Purifying selection, neutral branch length, discovery power\n- Detect constrained elements: nucleotides, windows, HMM\n- Estimate fraction constrained: signal vs. background\n- Evolutionary signatures: focus on pattern of change\n- Different functions Characteristic patterns of evolution\n- Signatures of protein-coding genes\n- Reading-frame conservation, codon-substitution frequency\n- Likelihood ratio framework: Estimating QCQN, scoring\n- Revise genes, read-through, excess constraint regions\n- Signatures of microRNA genes\n- Structural and evolutionary features of microRNAs\n- Combining features: decision trees, random forests\n- Sense/anti-sense miRNAs, mature/star arm cooperation\n- Measuring selection within the human lineage\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 18 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/07bfcb2cbf5320a271925b8ff7c5646a_MIT6_047F15_Lecture18.pdf",
      "content": "Lecture 18\nMolecular Evolution and Phylogenetics\n6.047/6.878 - Computational Biology: Genomes, Networks, Evolution\nSomewhere, something went wrong...\nPatrick Winston's 6.034\n\nChallenges in Computational Biology\nDNA\n4 Genome Assembly\n1 Gene Finding\n5 Regulatory motif discovery\nDatabase lookup\nGene expression analysis\nRNA transcript\nSequence alignment\nEvolutionary Theory\nTCATGCTAT\nTCGTGATAA\nTGAGGATAT\nTTATCATAT\nTTATGATTT\nCluster discovery\nGibbs sampling\nProtein network analysis\n12 Metabolic modelling\nComparative Genomics\nEmerging network properties\n\nConcepts of Darwinian Evolution\nSelection\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nImage in the public domain.\nCourtesy of Yuri Wolf; slide in the public domain.\n\nConcepts of Darwinian Evolution\nCharles Darwin 1859. Origin of Species [one and only\nillustration]: \"descent with modification\"\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nImage in the public domain.\nCourtesy of Yuri Wolf; slide in the public domain.\n\nTree of Life\nImage in the public domain.\n(c) Neal Olander. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see http://ocw.mit.\nedu/help/faq-fair-use/.\n\nGoals for today: Phylogenetics\n-\nBasics of phylogeny: Introduction and definitions\n-\nCharacters, traits, nodes, branches, lineages, topology, lengths\n-\nGene trees, species trees, cladograms, chronograms, phylograms\n1. From alignments to distances: Modeling sequence evolution\n-\nTurning pairwise sequence alignment data into pairwise distances\n-\nProbabilistic models of divergence: Jukes Cantor/Kimura/hierarchy\n2. From distances to trees: Tree-building algorithms\n-\nTree types: Ultrametric, Additive, General Distances\n-\nAlgorithms: UPGMA, Neighbor Joining, guarantees and limitations\n-\nOptimality: Least-squared error, minimum evolution (require search)\n3. From alignments to trees: Alignment scoring given a tree\n-\nParsimony: greedy (union/intersection) vs. DP (summing cost)\n-\nML/MAP (includes back-mutations, lengths): peeling algorithm (DP)\n4. Tree of Life in Genomic Era\n-\nThe prokaryotic problem (no real taxa and HGT)\n-\nInterpreting the forest of life\n\nIntroduction: Basics and Definitions\nCharacters, traits, gene/species trees\n\nAncestral Node\nor ROOT of\nthe Tree\nInternal Nodes or\nDivergence Points\n(represent hypothetical\nancestors of the taxa)\nBranches or\nLineages\nTerminal Nodes\nA\nB\nC\nD\nE\nRepresent the\nTAXA (genes,\npopulations,\nspecies, etc.)\nused to infer\nthe phylogeny\nCommon Phylogenetic Tree Terminology\n\nExtinctions part of life\nPhylogenetic tree showing archosaurs, dinosaurs, birds, etc. through geologic time removed due to copyright restrictions.\n\nPhylogenetics\nGeneral Problem:\nInfer complete ancestry of\na set of 'objects' based on\nknowledge of their 'traits'\n\n'Objects' can be: Species,\nGenes, Cell types, Diseases,\nCancers, Languages, Faiths,\nCars, Architectural Styles\n\n'Traits' can be: Morphological, molecular,\ngene expression, TF binding, motifs, words...\n\nHistorical record varies: Fossils, imprints,\ntiming of geological events, 'living fossils',\nsequencing of extinct species, paintings, stories.\n\nToday: Phylogenies using only extant species data\ngene trees (paralog / ortholog / homolog trees)\nMammal family tree removed due to copyright restrictions.\n\nInferring Phylogenies: Traits and Characters\nTrees can be inferred by several criteria:\n- Traditional traits: Morphology data\n\n- Modern traits: Molecular data\n\nKangaroo\nACAGTGACGCCCCAAACGT\n\nElephant\nACAGTGACGCTACAAACGT\n\nDog\nCCTGTGACGTAACAAACGA\n\nMouse\nCCTGTGACGTAGCAAACGA\n\nHuman\nCCTGTGACGTAGCAAACGA\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nFrom physiological traits to DNA characters\n- Traditional phylogenetics\n- Building species trees\n- Small number of traits\n- Hoofs, nails, teeth, horns\n- Well-behaved traits, each arose once\n- Parsimony principle, Occam's razor\n\n- Modern phylogenetics\n- Building gene trees and species trees\n- Very large number of traits\n- Every DNA base and every protein residue\n- Frequently ill-behaved traits\n- Back-mutations are frequent (convergent evolution)\n- Small number of letters, arise many times independently\n\nTaxon A\nTaxon B\nTaxon C\nTaxon D\nTaxon A\nTaxon B\nTaxon C\nTaxon D\nTaxon A\nTaxon B\nTaxon C\nTaxon D\nThree types of trees\nCladogram\nChronogram\n\nPhylogram\nTopology only\nTopology +\nDivergence times\nTopology +\nDivergence times +\nDivergence rates\nt1\nt3\nt2\n\nInferring a tree from nucleotides/peptides\nMolecular\nphylogenetic\nmethods\nSequence data:\n-Nucleotide alignments\n-Peptide alignments\nEvolutionary history\nrepresented as a\nbinary tree\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nTwo basic approaches for phylogenetic inference\nDistance based\nCharacter based\nFrom alignments\nTo phylogenies\nFrom Sequences\nTo Distances\nTree building\nalgorithms\nPair-wise distance matrix\nSequence alignment\nSequence alignment\nOutput tree\nOutput tree\nCouple to\ntree proposal\nand scoring\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoals for today: Phylogenetics\n-\nBasics of phylogeny: Introduction and definitions\n-\nCharacters, traits, nodes, branches, lineages, topology, lengths\n-\nGene trees, species trees, cladograms, chronograms, phylograms\n1. From alignments to distances: Modeling sequence evolution\n-\nTurning pairwise sequence alignment data into pairwise distances\n-\nProbabilistic models of divergence: Jukes Cantor/Kimura/hierarchy\n2. From distances to trees: Tree-building algorithms\n-\nTree types: Ultrametric, Additive, General Distances\n-\nAlgorithms: UPGMA, Neighbor Joining, guarantees and limitations\n-\nOptimality: Least-squared error, minimum evolution (require search)\n3. From alignments to trees: Alignment scoring given a tree\n-\nParsimony: greedy (union/intersection) vs. DP (summing cost)\n-\nML/MAP (includes back-mutations, lengths): peeling algorithm (DP)\n4. Tree of Life in Genomic Era\n-\nThe prokaryotic problem (no real taxa and HGT)\n-\nInterpreting the forest of life\n\n1. From alignments to distances\nModeling evolutionary rates\nDistance estimation\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMeasuring evolutionary rates\n-\nNucleotide divergence\n- Uniform rate. Overall percent identity.\n-\nTransitions and transversions\n- Two-parameter model. A-G, C-T more frequent.\n-\nSynonymous and non-synonymous substitutions\n- Ka/Ks rates. Amino-acid changing substitutions\n-\nNactual mutations > N observed substitutions\n- Some fraction of \"conserved\" positions mutated twice\nA\nC\nG\nT\nA\nC\nG\nT\n.1\n.1\n.2\n.6\n.6\n.1\n.2 .1\n\n'Evolving' a nucleotide under random model\nA\nG\nC\nT\n.1\n.1\n.1\n.1\n.1\n.1\n.7\n.7\n.7\n.7\n-\nAt time step 0, start with letter A\n-\nAt time step 1:\n- Remain A with probability 0.7\n- Change to C,G,T with prob. 0.1 each\n-\nAt time step 2:\n- In state A with probability 0.52\n- Remain A with probability 0.7 * 0.7\n- Go back to A from C,G,T with 0.1*0.1 each\n- In states C,G,T with prob. 0.16 each\nt=1\nt=2\nt=3\nt=4\nt=5\nA\n0.7\n0.52\n0.412\n0.3472\nC\n0.1\n0.16\n0.196\n0.2176\nG\n0.1\n0.16\n0.196\n0.2176\nT\n0.1\n0.16\n0.196\n0.2176\n\nModeling Nucleotide Evolution\nDuring infinitesimal time t, there is not enough time for two\nsubstitutions to happen on the same nucleotide\n\nSo we can estimate P(x | y, t), for x, y {A, C, G, T}\n\nThen let\n\nP(A|A, t) ...... P(A|T, t)\nS(t) =\n...\n\n...\n\nP(T|A, t) ...... P(T|T, t)\n\nModeling Nucleotide Evolution\nReasonable assumption: multiplicative\n\n(implying a stationary Markov process)\n\nS(t+t') = S(t)S(t')\n\nThat is, P(x | y, t+t') = z P(x | z, t) P(z | y, t')\n\nJukes-Cantor: constant rate of evolution\n\n1 - 3\n\nFor short time , S() =\n\n1 - 3\n\n1 - 3\n\n1 - 3\n\nModeling Nucleotide Evolution\nJukes-Cantor:\n\nFor longer times,\n\nr(t)\ns(t)\ns(t)\ns(t)\nS(t) = s(t)\nr(t)\ns(t)\ns(t)\n\ns(t)\ns(t)\nr(t)\ns(t)\n\ns(t)\ns(t)\ns(t)\nr(t)\n\nWhere we can derive:\n\nr(t) = 1⁄4 (1 + 3 e-4t)\n\ns(t) = 1⁄4 (1 - e-4t)\nA\nG\nC\nT\nA\nother\n1-3\n\n1-\n\nGeometric asymptote to 1/4\n\nModeling Nucleotide Evolution\nKimura:\n\nTransitions: A/G, C/T\nTransversions: A/T, A/C, G/T, C/G\n\nTransitions (rate ) are much more likely than transversions (rate )\n\nr(t)\ns(t)\nu(t)\nu(t)\nS(t) =\ns(t)\nr(t)\nu(t)\nu(t)\n\nu(t)\nu(t)\nr(t)\ns(t)\n\nu(t)\nu(t)\ns(t)\nr(t)\n\nWhere\n\ns(t) = 1⁄4 (1 - e-4t)\n\nu(t) = 1⁄4 (1 + e-4t - e-2(+)t)\n\nr(t) = 1 - 2s(t) - u(t)\nA\nG\nC\nT\nA\nG\nC\nT\n\nDistance between two sequences\nGiven (well-aligned portion of) sequences xi, xj,\n\nDefine\ndij = distance between the two sequences\n\nOne possible definition:\ndij = fraction f of sites u where xi[u] xj[u]\n\nBetter model (Jukes-Cantor):\ndij = - 3⁄4 log(1 - 4f / 3)\nr(t) = 1⁄4 (1 + 3 e-4t)\ns(t) = 1⁄4 (1 - e-4t)\nObserved F = [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\nActual D = [0.11, 0.23, 0.38, 0.57, 0.82, 1.21, 2.03]\n\nMany nucleotide models have been developed\nVarying levels of complexity (parameters)\nModels also exist for peptides and codons\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoals for today: Phylogenetics\n-\nBasics of phylogeny: Introduction and definitions\n-\nCharacters, traits, nodes, branches, lineages, topology, lengths\n-\nGene trees, species trees, cladograms, chronograms, phylograms\n1. From alignments to distances: Modeling sequence evolution\n-\nTurning pairwise sequence alignment data into pairwise distances\n-\nProbabilistic models of divergence: Jukes Cantor/Kimura/hierarchy\n2. From distances to trees: Tree-building algorithms\n-\nTree types: Ultrametric, Additive, General Distances\n-\nAlgorithms: UPGMA, Neighbor Joining, guarantees and limitations\n-\nOptimality: Least-squared error, minimum evolution (require search)\n3. From alignments to trees: Alignment scoring given a tree\n-\nParsimony: greedy (union/intersection) vs. DP (summing cost)\n-\nML/MAP (includes back-mutations, lengths): peeling algorithm (DP)\n4. Tree of Life in Genomic Era\n-\nThe prokaryotic problem (no real taxa and HGT)\n-\nInterpreting the forest of life\n\n2. Distance-based tree-building algorithms\nMapping a distance matrix to a tree\nUPGMA, NJ,\nLSE, ME\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nDistance matrix Phylogenetic tree\nHum\nMou\nRat\nDog\nCat\nHuman\nMouse\nh.y.m\nRat\nh.y.r\nm.r\nDog\nh.z.x.d\nm.y.z.x.d\nr.y.z.x.d\nCat\nh.z.x.c\nm.y.z.x.c\nr.y.z.x.c\nd.c\nHuman\nDog\nCat\nMouse\nRat\nd\nc\nx\nh\nz\nm\ny\nr\nGoal:\nMinimize discrepancy between observed distances and tree-based distances\nMap distances Dij\nto a tree\nTree implies\na distance matrix\nMij\nmin ij (Dij-Mij)2\n\nUltrametric distances & 3 Point Condition\n- For all points i, j, k\n- two distances are equal and third is smaller\nd(i,j) <= d(i,k) = d(j,k)\na+a <= a+b = a+b\n\na\na\nb\ni\nj\nk\nwhere a <= b\n- Result:\n- All paths from leaves are equidistant to the root\n- Rooted tree with uniform rates of evolution\n\nUltrametric trees\nA B C\nA 0 3 3\nB 3 0 2\nC 3 2 0\nSymmetric 0-diagonal\nmatrix of divergence\ntimes\nA B C\nA 0 6 6\nB 6 0 4\nC 6 4 0\nFor now imagine that these\nare just the number of substitutions\nbetween pairs:\n\nA : G CCCAA CT A\nB : G TTTCC CT C\nTaken from Ran Libeskind-Hadas, Lecture Slides, Fall, 2013\n\nUltrametric Trees\n-\nGiven a symmetric n x n 0-diagonal matrix D, an ultrametric tree T for\nthat matrix is one in which:\n- There are n leaves, one for each row (column) of D\n- Each internal node is labeled by a time in D and has exactly two\nchildren\n- Along any path from the root to a leaf, the (divergence) times at the\ninternal nodes strictly decrease\n- For any two leaves i, j of T, the LCA of i, j is labeled with time D(i, j)\n\nA B C\nA\n0 3 3\nB 3 0 2\nC 3 2 0\nA\nB\nC\nTaken from Ran Libeskind-Hadas, Lecture Slides, Fall, 2013\n\nUltrametric Matrix Construction\nA B C D E\nA 0 5 2 5 7\nB 5 0 5 3 7\nC 2 5 0 5 7\nD 5 3 5 0 7\nE 7 7 7 7 0\nA B C D E\nA 0 5 2 5 7\nB 5 0 4 3 7\nC 2 4 0 5 7\nD 5 3 5 0 7\nE 7 7 7 7 0\n- Algorithms exist for \"ultrametrifying\" matrices.\n\nTaken from Ran Libeskind-Hadas, Lecture Slides, Fall, 2013\n\nMinimum Spanning Tree (MST)\n- There is a unique path between any two vertices in a\nspanning tree\n- Adding an edge to a spanning tree creates a cycle\n- Any edge on that cycle can be removed and we'll still\nhave a spanning tree\n- MST is found using Prim's Algorithm (graph traversal)\nTaken from Ran Libeskind-Hadas, Lecture Slides, Fall, 2013\n\nThe \"Ultrametrification\" Algorithm\nGiven n x n symmetric 0-diagonal matrix D that is not\nultrametric\n1.Construct a completely connected graph with n\nvertices, one per row of A. The edge weight from\nvertex i to vertex j is D(i, j).\n2.Find a minimum spanning tree (MST) of this graph.\n3.Build a new matrix D' such that D'(i, j) is the largest\nweight on the unique path from i to j in the MST.\n\nTaken from Ran Libeskind-Hadas, Lecture Slides, Fall, 2013\n\nDistances: (b) Additive distances\n- All distances satisfy the four-point condition\n- Any quartet can be labeled i,j,k,l such that:\n- d(i,j) + d(k,l) <= d(i,k) + d(j,l) = d(i,l) + d(j,k)\n- (a+b)+(c+d) <= (a+m+c)+(b+m+d) = (a+m+d)+(b+m+c)\n\n- Result:\n- All pairwise distances obtained by traversing a tree\na\nb\nm\ni\nj\nk\nl\nc\nd\n\nDistances: (c) General distances\n-\nIn practice, a distance matrix is neither ultrametric nor additive\n- Noise\n- Measured distances are not exact\n- Evolutionary model is not exact\n- Fluctuations\n- Regions used to measure distances not representative of the species\ntree\n- Gene replacement (gene conversion), lateral transfer\n- Varying rates of mutation can lead to discrepancies\n\n-\nIn the general case, tree-building algorithms must handle noisy\ndistance matrices\n- Such a tree can be obtained by\n- Enumeration and scoring of all trees (too expensive)\n- Neighbor-Joining (typically gives a good tree)\n- UPGMA (typically gives a poor tree)\n\nAlgorithms: (a) UPGMA (aka Hierarchical Clustering)\nInitialization:\n\nAssign each xi into its own cluster Ci\n\nDefine one leaf per sequence, height 0\n\nIteration:\n\nFind two clusters Ci, Cj s.t. dij is min\n\nLet Ck = Ci Cj\n\nDefine node connecting Ci, Cj,\n\n& place it at height dij/2\n\nDelete Ci, Cj\n\nTermination:\n\nWhen two clusters i, j remain,\n\nplace root at height dij/2\n(Unweighted Pair Group Method with Arithmetic mean)\n\nUltrametric Distances & UPGMA\nUPGMA is guaranteed to build the correct tree if distance is\nultrametric\n\nProof:\n1.\nThe tree topology is unique, given that the tree is binary\n2.\nUPGMA constructs a tree obeying the pairwise distances\n\nWeakness of UPGMA\nMolecular clock assumption:\n\nimplies time is constant for all species\n\nHowever, certain species (e.g., mouse, rat) evolve much faster\n\nExample where UPGMA messes up:\nCorrect tree\nUPGMA\n\nAlgorithms: (b) Neighbor-Joining\n-\nGuaranteed to produce the correct tree if distance is additive\n-\nMay produce a good tree even when distance is not additive\n\nStep 1: Finding neighboring leaves\n\nDefine\n\nDij = dij - (ri + rj)\n\nWhere\n\nri = -----k dik\n\n|L| - 2\n\nClaim: The above \"magic trick\" ensures that Dij is minimal iff i, j are neighbors\nProof: Beyond the scope of this lecture (Durbin book, p. 189)\n0.1\n0.1\n0.1\n0.4\n0.4\n\nAlgorithm: Neighbor-joining\nInitialization:\n\nDefine T to be the set of leaf nodes, one per sequence\n\nLet L = T\n\nIteration:\n\nPick i, j s.t. Dij is minimal\n\nDefine a new node k, and set dkm = 1⁄2 (dim + djm - dij) for all m L\n\nAdd k to T, with edges of lengths dik = 1⁄2 (dij + ri - rj)\n\nRemove i, j from L;\n\nAdd k to L\n\nTermination:\n\nWhen L consists of two nodes, i, j, and the edge between them of length dij\n\nCOMPUTATIONAL METHOD\nClustering algorithm\nOptimality criterion\nDATA TYPE\nCharacters\nDistances\nPARSIMONY\n\nMAXIMUM LIKELIHOOD\nUPGMA\n\nNEIGHBOR-JOINING\nMINIMUM EVOLUTION\n\nLEAST SQUARES\nAlgorithms: (c) Distance-fitting algoriths\n- With distance-based algorithms, we can also aim to\ndirectly minimize discrepancy between original\ndistance matrix and tree-based distance matrix\n\nDistance matrix Phylogenetic tree\nHum\nMou\nRat\nDog\nCat\nHuman\nMouse\nh.y.m\nRat\nh.y.r\nm.r\nDog\nh.z.x.d\nm.y.z.x.d\nr.y.z.x.d\nCat\nh.z.x.c\nm.y.z.x.c\nr.y.z.x.c\nd.c\nHuman\nDog\nCat\nMouse\nRat\nd\nc\nx\nh\nz\nm\ny\nr\nGoal:\nMinimize discrepancy between observed distances and tree-based distances\nMap distances Dij\nto a tree\nTree implies\na distance matrix\nMij\nmin ij (Dij-Mij)2\n\nAside: Alternative to Molecular clock?\nDivergence between orthologous sequences is proportional to time\nseparating the species.\nDifferent genes evolve at specific, roughly constant rates.\nZuckerkandl & Pauling 1962\ndivergence time\ndistance\ntime\nrate\nsampling\nerror\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nMolecular Clock\nUnder MC all individual gene trees are ultrametric (up to a sampling error)\nand identical to the species tree up to a scaling factor (evolution rate).\nA\nB\nC\nD\nE\nF\nG\nH\ntime\nA\nB\nC\nD\nE\nF\nG\nH\ndistance\nA\nB\nC\nD\nE\nF\nG\nH\ndistance\nspecies\ntree\ngene 1\ngene 2\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nAre these really ultrametric?\nCourtesy of Yuri Wolf; slide in the public domain.\n\nMolecular Clock\nMost of the real phylogenetic trees are far from being ultrametric.\nMolecular clock is substantially overdispersed.\ntime\nrate\n0.2\nideal\nexpected based\non sampling error\nobserved\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nRelaxed Molecular Clock\nRelaxed molecular clock models allows for rate variation.\nRates are sampled from prior distributions with limited variance,\nindependently or in autocorrelated manner.\nGenes are either analyzed individually, or as concatenated alignments\n(implying evolution as a single unit).\ntime\nrate\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nUniversal Pacemaker\nUniversal Pacemaker model assumes that evolutionary time runs at\ndifferent pace in each lineage.\nUnder the UPM, species trees are intrinsically non-ultrametric.\nA\nB\nC\nD\nE\nF\nG\nH\nA\nB\nC\nD\nE\nF\nG\nH\ntime\npacemaker\nticks\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nPacemaker vs Clock\nBoth overdispersed MC and UPM models predict that individual gene\ntrees would deviate from ultrametricity.\nUnder MC these deviations are expected to be uncorrelated.\nUnder UPM these deviations are expected to be correlated, so there\nexists a non-ultrametric pacemaker tree that can significantly reduce\nvariance of observed rates.\nA testable hypothesis!\n\n2,300 trees of 100 prokaryotic species;\n7,000 trees of 6 Drosophila species\n1,000 trees of 9 yeast species\n5,700 trees of 8 mammalian species\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nPacemaker vs Clock\n2,300 trees of 100 prokaryotic species;\n7,000 trees of 6 Drosophila species\n1,000 trees of 9 yeast species\n5,700 trees of 8 mammalian species\nAll show an overwhelming support to UPM model.\n\nSnir 2012; work in progress at NCBI (NIH)\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nGoals for today: Phylogenetics\n-\nBasics of phylogeny: Introduction and definitions\n-\nCharacters, traits, nodes, branches, lineages, topology, lengths\n-\nGene trees, species trees, cladograms, chronograms, phylograms\n1. From alignments to distances: Modeling sequence evolution\n-\nTurning pairwise sequence alignment data into pairwise distances\n-\nProbabilistic models of divergence: Jukes Cantor/Kimura/hierarchy\n2. From distances to trees: Tree-building algorithms\n-\nTree types: Ultrametric, Additive, General Distances\n-\nAlgorithms: UPGMA, Neighbor Joining, guarantees and limitations\n-\nOptimality: Least-squared error, minimum evolution (require search)\n3. From alignments to trees: Alignment scoring given a tree\n-\nParsimony: greedy (union/intersection) vs. DP (summing cost)\n-\nML/MAP (includes back-mutations, lengths): peeling algorithm (DP)\n4. Tree of Life in Genomic Era\n-\nThe prokaryotic problem (no real taxa and HGT)\n-\nInterpreting the forest of life\n\n3. Character-based tree-scoring algorithms\n3a: Parsimony (set-based)\n3b: Parsimony (Dyn. Prog.)\n3c: Maximum Likelihood\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nBasic algorithms of phylogenetic methods\nDistance based\nCharacter based\nFrom alignments\nTo phylogenies\nFrom Sequences\nTo Distances\nTree building\nalgorithms\nPair-wise distance matrix\nSequence alignment\nSequence alignment\nOutput tree\nOutput tree\nCouple to\ntree proposal\nand scoring\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nCharacter-based phylogenetic inference\n- Really about tree scoring techniques, not tree\nfinding techniques\n- Couple them with tree proposal and update and you\nhave an algorithm (part 4 of the lecture)\n- Two approaches exist, all use same architecture:\n- Minimize events: Parsimony (union/intersection)\n- Probabilistic: Max Likelihood / MAP\n\nParsimony scoring (a): Union and intersection\nA\nB\nA\nB\n{A, B}\nC+=1\n{A, B}\nC+=1\n{A}\n{A}\n{B}\n{A}\n{B}\nGiven a tree, and an alignment column\n\nLabel internal nodes to minimize the\nnumber of required substitutions\n\nInitialization:\n\nSet cost C = 0; k = 2N - 1\n\nIteration:\n\nIf k is a leaf, set Rk = { xk[u] }\n\nIf k is not a leaf,\n\nLet i, j be the daughter nodes;\n\nSet Rk = Ri Rj if intersection is\nnonempty\n\nSet Rk = Ri Rj, and C += 1, if\nintersection is empty\n\nTermination:\n\nMinimal cost of tree for column u, = C\n\nParsimony traceback to find ancestral nucleotides\nA\nB A\nB\n{A, B}\n{A, B}\n{A}\n{A}\n{B} {A} {B}\nA\nB A\nB\nA\nA\nA\nx\nx\nA\nB A\nB\nA\nB\nA\nx\nx\nA\nB A\nB\nB\nB\nB\nx\nx\nAccessible to traceback\nStill optimal, but\nnot found by traceback\nTraceback:\n1. Choose an arbitrary nucleotide from R2N - 1 for the root\n\n2. Having chosen nucleotide r for parent k,\nIf r Ri choose r for daughter i\nElse, choose arbitrary nucleotide from Ri\n\nEasy to see that this traceback produces some assignment of cost C\n\nParsimony Scoring (b): Dynamic programming\nM\nR\nB1\nH\nB2\nD\nB3\nA\nC\nG\nT\n-\nEach cell (N,C) represents the\nmin cost of the subtree rooted at\nN, if the label at N is C.\n-\nUpdate table by walking up the\ntree from the leaves to the root,\nremembering max choices.\n-\nTraceback from root to leaves to\nconstruct a min cost assignment\nA\nG\nA\nG\nMouse\nRat\nHuman\nDog\nB1\nB2\nB3\n\nGoals for today: Phylogenetics\n-\nBasics of phylogeny: Introduction and definitions\n-\nCharacters, traits, nodes, branches, lineages, topology, lengths\n-\nGene trees, species trees, cladograms, chronograms, phylograms\n1. From alignments to distances: Modeling sequence evolution\n-\nTurning pairwise sequence alignment data into pairwise distances\n-\nProbabilistic models of divergence: Jukes Cantor/Kimura/hierarchy\n2. From distances to trees: Tree-building algorithms\n-\nTree types: Ultrametric, Additive, General Distances\n-\nAlgorithms: UPGMA, Neighbor Joining, guarantees and limitations\n-\nOptimality: Least-squared error, minimum evolution (require search)\n3. From alignments to trees: Alignment scoring given a tree\n-\nParsimony: greedy (union/intersection) vs. DP (summing cost)\n-\nML/MAP (includes back-mutations, lengths): peeling algorithm (DP)\n4. Tree of Life in Genomic Era\n-\nThe prokaryotic problem (no real taxa and HGT)\n-\nInterpreting the forest of life\n\nCompute\nrecursively\nusing DP\nScoring (c) Maximum Likelihood & Max-a-Posteriori\nInput: Sequence alignment\nOutput: tree with maximum likelihood / max a posteriori prob.\nSearch: Heuristic search for max likelihood tree.\n\nP(D|B,T) is the likelihood of data given model\nUse seq evolution model: JC,K2P,HKY.\nP(B,T) is a prior on trees/branch lengths\nUse Yule process, Birth-Death process to model\nMaximum Likelihood (ML)\nB^,T^ = argmaxB,T P(D|B,T)\nMaximum a Posteriori (MAP)\nB^,T^ = argmaxB,T P(B,T|D)\n= argmaxB,T P(B,T,D) / P(D)\n= argmaxB,T P(B,T,D)\n= argmaxB,T P(D|B,T)P(B,T)\nD = seq. alignment data\nB = branch lengths\nT = topology\nlikelihood\nlikelihood\n\n'Peeling' algorithm for P(D|B,T) term\n1. Assume sites j evolve independently.\nTreat each column of the alignment in isolation\n2. Assume branch independence, conditioned on parent\nExpand total joint probability into prod of P(xi|xparent,ti)\nOnly P(x2n-1) remains, root prior, background nucl. freq.\n3. We know how to compute P(xi|xparent(i),ti) for fixed pair\nDefined by our sequence model (JC, K2P, HKY, etc)\nEasily calculate for any given assignment of internal nodes\n4. As internal node values are not known marginalize\nSum over all possible values of all internal/root nodes\nLet xn+1,...,x2n-1 represent seqs of n-1 internal nodes\n\n1. Site evolution over single branch\nA\nG\nC\nT\n\nJC is a Continuous-Time\nMarkov Chain (CTMC)\n- Defines instantaneous\nrates of transition between\nstates (bases)\nUse JC to define single site evolution:\n\"A\"\n\"C\"\nt\nP(a=\"C\"|b=\"A\", t) = S(t)ba\nRemember: Jukes-Cantor (JC)\nDiscrete MC version\n- Given time t, we define a discrete MC with transition\nmatrix is S(t), also called a substitution probability matrix.\n- Gives the probability of seeing base a given initial base b\nafter duration time t.\n\n2. Sequence evolution over single branch\n- Assume site independence\n- P(xi|xk, ti) = Πj P(b=xij|a=xkj, ti)\nUse product to define sequence evolution:\nxk = \"AAACTG\"\nxi = \"CAAGTC\"\nti\nP(xi|xk, ti)\n\n3. Sequence evolution over entire tree\n- Assume branch independence\n- P(x1, ...xn, ..., x2n-1|T, t) = P(x2n-1)Πi P(xi|xparent(i), ti)\n- Assume prior on root sequence, e.g.\n- P(x2n-1) = P(x2n-1,j) = (1/4)^m for sequence length m\nUse product and prior to define sequence evolution over tree:\nx9 = \"AAACTG\"\nx1\nx2\nx3 x4\nx5\nx7\nx6\nx8\nt1\nt2\nt3\nt6\nt7\nt4\nt5\nt8\nP(x1, ...xn, ..., x2n-1|T, t)\n\n4. Integrate (marginalize) over hidden ancestral seqs!\n- Notice, all sequences are needed, both internal nodes and leaves\n- P(x1, ...xn, ..., x2n-1|T, t)\n- But, only leaves are given: x1, ...xn\n- Therefore, need to marginalize (sum) over unknowns: xn+1, ..., x2n-1\n\n- This looks expensive!\n- P(x1, ...xn|T, t) = Σxn+1, ..., Σ x2n-1 P(x1, ...xn, ..., x2n-1|T, t)\n- Don't worry, dynamic programming\ncan do it efficiently.\n\nx9 = \"AAACTG\"\nx1\nx2\nx3 x4\nx5\nx7\nx6\nx8\nt1\nt2\nt3\nt6\nt7\nt4\nt5\nt8\n\nBasic trick to efficient marginalization\nP(x1,x2,x3,x4|T, t) = Σx5Σx6Σx7 P(x1,x2,x3,x4,x5,x6,x7|T, t)\n\n= Σx5Σx6Σx7 P(x1|x5,t1) P(x2|x5,t1)\n\nP(x3|x6,t3) P(x4|x6,t4)\n\nP(x5|x7,t5) P(x6|x7,t6) P(x7)\n= Σx7 P(x7)\n[Σx5 P(x5|x7,t5) P(x1|x5,t1) P(x2|x5,t1)]\n[Σx6 P(x6|x7,t6) P(x3|x6,t3) P(x4|x6,t4)]\nx5\nx1\nx2\nt1\nt2\nx6\nx3\nx4\nt3\nt4\nx7\nt5\nt6\nApply factorization trick to every internal node in the tree.\n- L(i,j,a) is the DP table.\n- Each entry contains the probability\nof seeing the leaf data below node i,\ngiven that node i has base a at site j.\n- The leaves of the table are initialized\nbased on the observed sequence.\nEntries populated in post-order traversal.\n- Runtime: O(2n * k^2)\nPeeling algorithm\n\nUse DP to compute argmax P(D|B,T) efficiently\n- If we know the branch lengths tleft & tright.\n- And we already have the likelihood tables\nLj&Lk of left and right subtrees\n(for each possible ending character at b, c)\nFill in likelihood table Li for each char a at i\nLj[b]\nLi\nLj\nLk\nA\nC\nP(.|'C\n')\nG\nT\nLi[a] = Σb{ACGT} Σc{ACGT} ( P(b|a,tleft)*Lleft[b] * P(c|a,tright)*Lright[c] )\nChar a at node i\nb at j\nProb(ab)\ntleft\ntright\nLk[c]\nLi[a]\nProb(ac)\nc at j\n\nInitialization and Termination\n- Characters at the leaves are already known\n- Their likelihood is 1 or 0, indicating the known char\n- Fill in internal node likelihood vectors iteratively\n- Once we reach the root, multiply by the base freqs\n- Maximization over Topologies and Lengths\nNumerical: gradient descent, Newton's method\n2n-1\n...\n...\n...\ni\nj\nk\n...\nn+1\nn\n...\nA\nC\nG\nT\nRoot\nLeaves\nInternal Nodes\n\nAdvantages/disadvantages of ML/MAP methods\n- Advantages:\n- Inherently statistical and evolutionary model-based.\n- Usually the most 'consistent' of the methods available.\n- Used for both character and rate analyses\n- Can be used to infer the sequences of the extinct ancestors.\n- Account for branch-length effects in unbalanced trees.\n- Nucleotide or amino acid sequences, other types of data.\n\n- Disadvantages:\n- Not as intuitive as parsimony (e.g. may choose more events\nif they're more likely in our probabilistic model)\n- Computationally intense (Iimits num taxa, sequence length).\n- Like parsimony, can be fooled by high levels of homoplasy.\n- Violations of model assumptions can lead to incorrect trees.\n\nTree reliability: Bootstrapping\n1.\nRe-sample alignments:\n-\nRandomly sample alignment columns\nwith replacement\n-\nCreate many alignments of equal size.\n2.\nBuild a phylogenetic tree\nfor each sample\n3.\nRepeat (1) and (2) many times\n-\n1000s of times\n4.\nOutput summary tree\n-\nTree constructed most frequently\n-\nConsensus tree (even if not most freq)\n-\nOther options\n5.\nReport observation frequency\nof each branch\n-\nEach branch is a binary split\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.69\n\nGoals for today: Phylogenetics\n-\nBasics of phylogeny: Introduction and definitions\n-\nCharacters, traits, nodes, branches, lineages, topology, lengths\n-\nGene trees, species trees, cladograms, chronograms, phylograms\n1. From alignments to distances: Modeling sequence evolution\n-\nTurning pairwise sequence alignment data into pairwise distances\n-\nProbabilistic models of divergence: Jukes Cantor/Kimura/hierarchy\n2. From distances to trees: Tree-building algorithms\n-\nTree types: Ultrametric, Additive, General Distances\n-\nAlgorithms: UPGMA, Neighbor Joining, guarantees and limitations\n-\nOptimality: Least-squared error, minimum evolution (require search)\n3. From alignments to trees: Alignment scoring given a tree\n-\nParsimony: greedy (union/intersection) vs. DP (summing cost)\n-\nML/MAP (includes back-mutations, lengths): peeling algorithm (DP)\n4. Tree of Life in Genomic Era\n-\nThe prokaryotic problem (no real taxa and HGT)\n-\nInterpreting the forest of life\n\nGenomic era - growing frustration with discrepancies between the trees\nreconstructed for individual genes and heroic efforts to overcome the\nnoise. Role of horizontal gene transfer in the evolution of prokaryotic\ngenomes is established.\n\nMajor lines of approach:\n\n- gene repertoire and gene order\n- distribution of distances between orthologs\n- concatenated alignments of \"non-transferable\" gene cores\n- consensus trees and supertrees\nCiccarelli 2006. Towards automatic reconstruction of a highly\nresolved tree of life. Science 311, 1283-1287 [Figure 2]\nTree of Life in Genomic Era\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nImage in the public domain.\nCourtesy of Yuri Wolf; slide in the public domain.\n\nDoolittle 2000. Uprooting the tree of life. Sci. Am. 282, 90-95 [modified]\nTree of Life, Rejected\nBacteria\nArchaea\nEukaryotes\nBacteria\nArchaea\nEukaryotes\nTroubled times - \"uprooting\" of TOL for prokaryotes.\n\n- horizontal gene transfer is rampant; no gene is exempt\n- histories of individual genes are non-coherent with each other\n- vertical signal is completely lost (or never existed at all)\n- there are no species (or other taxa) in prokaryotes\n- a consistent signal we observe is created by biases in HGT\n\"Standard Model\"\n\"Net of Life\"\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\n(c) Scientific American, Inc. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Doolittle, W. Ford. \"Uprooting the tree of life.\" Scientific American 282, no. 2 (2000): 90.\nCourtesy of Yuri Wolf; slide in the public domain.\n\nForest of Life - Methods\nSource data and basic analysis methods:\n\n- 100 hand-picked microbial genomes (41 archaea and 59 bacteria)\nrepresenting a \"fair\" sample of prokaryote diversity (as known in 2008)\n- clusters of orthologous genes (NCBI COGs and EMBL EggNOGs)\n- multiple protein sequence alignments → index orthologs → ML\nphylogenetic trees\n- 6901 trees cover 4-100 species; of them 102 cover 90-100 species\n(Nearly Universal Trees)\n- direct tree comparison (distances between trees)\n- quartet decomposition; analysis of quartet spectra\n- simulation evolutionary models\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nForest of Life - Analysis\n0.5\nCOG0541\nCOG0532\nCOG0092\nCOG0100\nCOG0090\nCOG0528\nCOG0096\nCOG0525\nCOG0051\nCOG0452\nCOG0495\nCOG0172\nCOG0089\nCOG0522\nCOG0124\nCOG0185\nCOG0094\nCOG0126\nCOG0519\nCOG0540\nCOG0149\nCOG0198\nCOG0177\nCOG0057\nCOG0009\nCOG0537\nIS\nNUTs\nNUTs are much closer to each\nother than expected by chance\nrandom\nNUTs form a tightly connected\nnetwork when clustered by similarity\nNUTs don't form clusters\n(random scatter around center)\nNUTs are connected to the rest of\nthe forest\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nCourtesy of Yuri Wolf; slide in the public domain.\n\nForest of Life - Analysis\nNUTs are dominated by tree-like\ndescent\nNUTs\nFOL\n0.63 +/- 0.35\n0.39 +/- 0.31\n\"Tree-like\" vs \"Net-like\" components of the trees (how many quartets\nagree/disagree with the consensus tree).\nOverall the forest of life is\ndominated by network-like\nrelationships (HGT)\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nCourtesy of Yuri Wolf; slide in the public domain.\n\nForest of Life - Analysis\nSimulated example of 16 trees for 10 organisms:\nNo two trees are the same; each contains 2 random deviations from the\nconsensus tree. Common statistical trend is visible.\nTaken from Yuri Wolf, Lecture Slides, Feb. 2014\nCourtesy of Yuri Wolf; slide in the public domain.\n\nModule V: Evolution/phylogeny/populations\n- Phylogenetics / Phylogenomics\n- Phylogenetics: Evolutionary models, Tree building, Phylo inference\n- Phylogenomics: gene/species trees, reconciliation, coalescent, pops\n- Population genomics:\n- Learning population history from genetic data\n- Assembling and getting information on genomes\n- Recitation about suffix arrays used in genome mapping and\nassembly\n-\nNext Pset due on Nov 1st\n- Don't wait until the last week to start it!\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 2 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/2eddab6441d8092607e1259aafceb280_MIT6_047F15_Lecture02.pdf",
      "content": "Lecture 2\n\nSequence Alignment\nand Dynamic Programming\n6.047/6.878/HST.507\nComputational Biology: Genomes, Networks, Evolution\n\nModule 1: Aligning and modeling genomes\n- Module 1: Computational foundations\n- Dynamic programming: exploring exponential spaces in poly-time\n- Introduce Hidden Markov Models (HMMs): Central tool in CS\n- HMM algorithms: Decoding, evaluation, parsing, likelihood, scoring\n- This week: Sequence alignment / comparative genomics\n- Local/global alignment: infer nucleotide-level evolutionary events\n- Database search: scan for regions that may have common ancestry\n- Next week: Modeling genomes / exon / CpG island finding\n- Modeling class of elements, recognizing members of a class\n- Application to gene finding, conservation islands, CpG islands\n\nGenome-wide alignments reveal orthologous segments\n- Genome-wide alignments span entire genome\n- Comparative identification of functional elements\n100 genes\nCourtesy of Don Gilbert. Used with permission.\n(c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComparative genomics reveals conserved regions\n-\nComparative genomics can reveal functional elements\n- For example: exons are deeply conserved to mouse, chicken, fish\n- Many other elements are also strongly conserved: exons / regulatory?\n-\nDevelop methods for estimating the level of constraint\n- Count the number of edit operations, number of substitutions and gaps\n- Estimate the number of mutations (including estimate of back-mutations)\n- Incorporate information about neighborhood: conservation 'windows'\n- Estimate the probability of a constrained 'hidden state': HMMs next week\n- Use phylogeny to estimate tree mutation rate, or 'rejected substitutions'\n- Allow different portions of the tree to have different rates: phylogenetics\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nEvolutionary signatures for diverse functions\nProtein-coding genes\n- Codon Substitution Frequencies\n- Reading Frame Conservation\nRNA structures\n- Compensatory changes\n- Silent G-U substitutions\nmicroRNAs\n- Shape of conservation profile\n- Structural features: loops, pairs\n- Relationship with 3'UTR motifs\nRegulatory motifs\n- Mutations preserve consensus\n- Increased Branch Length Score\n- Genome-wide conservation\nStark et al, Nature 2007\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Stark, Alexander et al. \"Discovery of functional elements in 12 Drosophila\ngenomes using evolutionary signatures.\" Nature 450, no. 7167 (2007): 219-232.\n\nAlignment: Evolution preserves functional elements!\nScer TTATATTGAATTTTCAAAAATTCTTACTTTTTTTTTGGATGGACGCAAAGAAGTTTAATAATCATATTACATGGCATTACCACCATATACA\nSpar CTATGTTGATCTTTTCAGAATTTTT-CACTATATTAAGATGGGTGCAAAGAAGTGTGATTATTATATTACATCGCTTTCCTATCATACACA\nSmik GTATATTGAATTTTTCAGTTTTTTTTCACTATCTTCAAGGTTATGTAAAAAA-TGTCAAGATAATATTACATTTCGTTACTATCATACACA\nSbay TTTTTTTGATTTCTTTAGTTTTCTTTCTTTAACTTCAAAATTATAAAAGAAAGTGTAGTCACATCATGCTATCT-GTCACTATCACATATA\n* * **** * * * ** ** * * ** ** ** * * * ** ** * * * ** * * *\n\nScer TATCCATATCTAATCTTACTTATATGTTGT-GGAAAT-GTAAAGAGCCCCATTATCTTAGCCTAAAAAAACC--TTCTCTTTGGAACTTTCAGTAATACG\nSpar TATCCATATCTAGTCTTACTTATATGTTGT-GAGAGT-GTTGATAACCCCAGTATCTTAACCCAAGAAAGCC--TT-TCTATGAAACTTGAACTG-TACG\nSmik TACCGATGTCTAGTCTTACTTATATGTTAC-GGGAATTGTTGGTAATCCCAGTCTCCCAGATCAAAAAAGGT--CTTTCTATGGAGCTTTG-CTA-TATG\nSbay TAGATATTTCTGATCTTTCTTATATATTATAGAGAGATGCCAATAAACGTGCTACCTCGAACAAAAGAAGGGGATTTTCTGTAGGGCTTTCCCTATTTTG\n** ** *** **** ******* ** * * * * * * * ** ** * *** * *** * * *\n\nScer CTTAACTGCTCATTGC-----TATATTGAAGTACGGATTAGAAGCCGCCGAGCGGGCGACAGCCCTCCGACGGAAGACTCTCCTCCGTGCGTCCTCGTCT\nSpar CTAAACTGCTCATTGC-----AATATTGAAGTACGGATCAGAAGCCGCCGAGCGGACGACAGCCCTCCGACGGAATATTCCCCTCCGTGCGTCGCCGTCT\nSmik TTTAGCTGTTCAAG--------ATATTGAAATACGGATGAGAAGCCGCCGAACGGACGACAATTCCCCGACGGAACATTCTCCTCCGCGCGGCGTCCTCT\nSbay TCTTATTGTCCATTACTTCGCAATGTTGAAATACGGATCAGAAGCTGCCGACCGGATGACAGTACTCCGGCGGAAAACTGTCCTCCGTGCGAAGTCGTCT\n** ** ** ***** ******* ****** ***** *** **** * *** ***** * * ****** *** * ***\n\nScer TCACCGG-TCGCGTTCCTGAAACGCAGATGTGCCTCGCGCCGCACTGCTCCGAACAATAAAGATTCTACAA-----TACTAGCTTTT--ATGGTTATGAA\nSpar TCGTCGGGTTGTGTCCCTTAA-CATCGATGTACCTCGCGCCGCCCTGCTCCGAACAATAAGGATTCTACAAGAAA-TACTTGTTTTTTTATGGTTATGAC\nSmik ACGTTGG-TCGCGTCCCTGAA-CATAGGTACGGCTCGCACCACCGTGGTCCGAACTATAATACTGGCATAAAGAGGTACTAATTTCT--ACGGTGATGCC\nSbay GTG-CGGATCACGTCCCTGAT-TACTGAAGCGTCTCGCCCCGCCATACCCCGAACAATGCAAATGCAAGAACAAA-TGCCTGTAGTG--GCAGTTATGGT\n** * ** *** * * ***** ** * * ****** ** * * ** * * ** ***\n\nScer GAGGA-AAAATTGGCAGTAA----CCTGGCCCCACAAACCTT-CAAATTAACGAATCAAATTAACAACCATA-GGATGATAATGCGA------TTAG--T\nSpar AGGAACAAAATAAGCAGCCC----ACTGACCCCATATACCTTTCAAACTATTGAATCAAATTGGCCAGCATA-TGGTAATAGTACAG------TTAG--G\nSmik CAACGCAAAATAAACAGTCC----CCCGGCCCCACATACCTT-CAAATCGATGCGTAAAACTGGCTAGCATA-GAATTTTGGTAGCAA-AATATTAG--G\nSbay GAACGTGAAATGACAATTCCTTGCCCCT-CCCCAATATACTTTGTTCCGTGTACAGCACACTGGATAGAACAATGATGGGGTTGCGGTCAAGCCTACTCG\n**** * * ***** *** * * * * * * * * **\n\nScer TTTTTAGCCTTATTTCTGGGGTAATTAATCAGCGAAGCG--ATGATTTTT-GATCTATTAACAGATATATAAATGGAAAAGCTGCATAACCAC-----TT\nSpar GTTTT--TCTTATTCCTGAGACAATTCATCCGCAAAAAATAATGGTTTTT-GGTCTATTAGCAAACATATAAATGCAAAAGTTGCATAGCCAC-----TT\nSmik TTCTCA--CCTTTCTCTGTGATAATTCATCACCGAAATG--ATGGTTTA--GGACTATTAGCAAACATATAAATGCAAAAGTCGCAGAGATCA-----AT\nSbay TTTTCCGTTTTACTTCTGTAGTGGCTCAT--GCAGAAAGTAATGGTTTTCTGTTCCTTTTGCAAACATATAAATATGAAAGTAAGATCGCCTCAATTGTA\n* * * *** * ** * * *** *** * * ** ** * ******** **** *\n\nScer TAACTAATACTTTCAACATTTTCAGT--TTGTATTACTT-CTTATTCAAAT----GTCATAAAAGTATCAACA-AAAAATTGTTAATATACCTCTATACT\nSpar TAAATAC-ATTTGCTCCTCCAAGATT--TTTAATTTCGT-TTTGTTTTATT----GTCATGGAAATATTAACA-ACAAGTAGTTAATATACATCTATACT\nSmik TCATTCC-ATTCGAACCTTTGAGACTAATTATATTTAGTACTAGTTTTCTTTGGAGTTATAGAAATACCAAAA-AAAAATAGTCAGTATCTATACATACA\nSbay TAGTTTTTCTTTATTCCGTTTGTACTTCTTAGATTTGTTATTTCCGGTTTTACTTTGTCTCCAATTATCAAAACATCAATAACAAGTATTCAACATTTGT\n* * * * * * ** *** * * * * ** ** ** * * * * * *** *\n\nScer TTAA-CGTCAAGGA---GAAAAAACTATA\nSpar TTAT-CGTCAAGGAAA-GAACAAACTATA\nSmik TCGTTCATCAAGAA----AAAAAACTA..\nSbay TTATCCCAAAAAAACAACAACAACATATA\n* * ** * ** ** **\nGal10\nGal1\nGal4\nGAL10\nGAL1\nTBP\nGAL4\nGAL4\nGAL4\nGAL4\nMIG1\nTBP\nMIG1\nFactor footprint\nConservation island\nWe can 'read' evolution to reveal functional elements\nYeast (Kellis et al, Nature 2003), Mammals (Xie, Nature 2005), Fly (Stark et al, Nature 07) 6\n\nToday's goal:\n\nHow do we actually align two genes?\n\nGoal: Sequence Alignment / Dynamic Programming\n1. Introduction to sequence alignment\n- Comparative genomics and molecular evolution\n- From Bio to CS: Problem formulation\n- Why it's hard: Exponential number of alignments\n2. Introduction to principles of dynamic programming\n- Computing Fibonacci numbers: Top-down vs. bottom-up\n- Repeated sub-problems, ordering compute, table lookup\n- DP recipe: (1) Parameterization, (2) sub-problem space,\n(3) traversal order, (4) recursion formula, (5) trace-back\n3. DP for sequence alignment\n- Additive score, building up a solution from smaller parts\n- Prefix matrix: finite subproblems, exponential paths\n- Duality: each entryprefix alignment score; pathaligmnt\n4. Advanced topics: Dynamic Programming variants\n- Linear-time bounded DP(heuristic). Linear-space DP. Gaps\n- Importance of parameterization: 2-D vs. 4-D decomposition\n\nGenomes change over time\nA C G T C A T C A\nA C G T G A T C A\nmutation\nA\nG T G\nT C A\nA G T G T C A\ndeletion\nA G T G T C A\nT\nbegin\nend\nA G T G T C A\nT\ninsertion\n\nGoal of alignment: Infer edit operations\nA C G T C A T C A\nA G T G T C A\nT\nbegin\nend\n?\n\nFrom Bio to CS: Formalizing the problem\n-\nDefine set of evolutionary operations (insertion, deletion, mutation)\n- Symmetric operations allow time reversibility (part of design choice)\n\n(Exception: methylated CpG dinucleotides TpG/CpA non-symmetric)\nHuman\nMouse\nMany possible transformations\nMinimum cost transformation(s)\n- Define optimality criterion (min number, min cost)\n-Impossible to infer exact series of operations (Occam's razor: find min)\n-\nDesign algorithm that achieves that optimality (or approximates it)\n-Tractability of solution depends on assumptions in the formulation\nHuman\nMouse\nHuman\nMouse\nHuman\nMouse\nx\ny\nx\ny\nx+y\nBio\nCS\nRelevance\nAssumptions\nSpecial cases\nTractability\nTradeoffs\nComputability\nAlgorithms\nImplementation\nPredictability\nCorrectness\nNote: Not all decisions are conflicting (some are both relevant and tractable)\n(e.g. Pevzner vs. Sankoff and directionality in chromosomal inversions)\n\nFormulation 1: Longest common substring\n-\nGiven two possibly related strings S1 and S2\n- What is the longest common substring? (no gaps)\n\nA C G T C A T C A\nT A G T G T C A\nS1\nS2\nA C G T C A T C A\nS1\nS2\nT A G T G T C A\noffset: +1\nA C G T C A T C A\nS1\nS2\nT A G T G T C A\noffset: -2\n\nFormulation 2: Longest common subsequence\n- Given two possibly related strings S1 and S2\n- What is the longest common subsequence? (gaps allowed)\nA C G T C A T C A\nT A G T G T C A\nS1\nS2\nA C G T C A T C A\nT A\nG T G\nT C A\nS1\nS2\nA C G T C A T C A\nT A\nG T G\nT C A\nS1\nS2\nA\nG T\nT C A\nLCSS\nRelated to:\nEdit distance:\n- Number of changes\nneeded for S1S2\n- Uniform scoring\nfunction\n\nFormulation 3: Sequence alignment\n- Allow gaps (fixed penalty)\n- Insertion & deletion operations\n- Unit cost for each character inserted or deleted\n- Varying penalties for edit operations\n- Transitions (PyrimidinePyrimidine, PurinePurine)\n- Transversions (Purine Pyrimidine changes)\n- Polymerase confuses Aw/G and Cw/T more often\nA\nG\nT\nC\nA +1 -1⁄2 -1\n-1\nG -1⁄2 +1 -1\n-1\nT\n-1\n-1 +1 -1⁄2\nC\n-1\n-1 -1⁄2 +1\nScoring function:\nMatch(x,x) = +1\nMismatch(A,G)= -1⁄2\nMismatch(C,T)= -1⁄2\nMismatch(x,y) = -1\nTransitions:\nAG, CT common\n(lower penalty)\nTransversions:\nAll other operations\npurine\npyrimid.\n\nFormulation 4: Varying gap cost models\n1. Linear gap penalty\n-\nSame as before\n2. Affine gap penalty\n-\nBig initial cost for starting or ending a gap\n-\nSmall incremental cost for each additional character\n3. General gap penalty\n-\nAny cost function\n-\nNo longer computable using the same model\n4. Frame-aware gap penalty\n-\nMultiples of 3 disrupt coding regions\n5. Seek duplicated regions, rearrangements, ...\n-\nEtc\n\nHow many alignments are there?\n- Longest 'non-boring' alignment: n+m entries\n- Otherwise a gap will be aligned to a gapcondense\n- Alignment is equivalent to gap placement\n- (n+m choose n) ways to choose S1 placement\n- At each position yes/no answer of placing character\n- Exponential number of possible placements\n- Exponential number of sequence alignment\n- Enumerating and scoring each of them not an option\n- Need faster solution for finding best alignment\nA C\nG\nT C\nA\nT\nC A\nG\nT C A\nS1\nS2\nG T\nA\nT\nNeed polynomial algorithm to find best alignment\namongst an exponential number of possible alignments!\nDP\n\nGoal: Sequence Alignment / Dynamic Programming\n1. Introduction to sequence alignment\n- Comparative genomics and molecular evolution\n- From Bio to CS: Problem formulation\n- Why it's hard: Exponential number of alignments\n2. Introduction to principles of dynamic programming\n- Computing Fibonacci numbers: Top-down vs. bottom-up\n- Repeated sub-problems, ordering compute, table lookup\n- DP recipe: (1) Parameterization, (2) sub-problem space,\n(3) traversal order, (4) recursion formula, (5) trace-back\n3. DP for sequence alignment\n- Additive score, building up a solution from smaller parts\n- Prefix matrix: finite subproblems, exponential paths\n- Duality: each entryprefix alignment score; pathaligmnt\n4. Advanced topics: Dynamic Programming variants\n- Linear-time bounded DP(heuristic). Linear-space DP. Gaps\n- Importance of parameterization: 2-D vs. 4-D decomposition\n\nA simple introduction to the principles of\nDynamic Programming\nTurning exponentials into polynomials\n\nComputing Fibonacci Numbers\n- Fibonacci numbers\nF6=F5+F4=(F4+F3)+(F3+F2))=....=(3+2)+(2+1)=5+3=8\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nFibonacci numbers are ubiquitous in nature\nRabbits per generation\nLeaves per height\nRomanesque spirals\nNautilus size\nConeflower spirals Leaf ordering\nLeonardo Pisano\nFibonacci\n(c) sources unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nComputing Fibonacci numbers: Top down\n-\nFibonacci numbers are defined recursively:\n-\nPython code\n\ndef fibonacci(n):\nif n==1 or n==2: return 1\nreturn fibonacci(n-1) + fibonacci(n-2)\n\n-\nGoal: Compute nth Fibonacci number.\n-\nF(0)=1, F(1)=1, F(n)=F(n-1)+F(n-2)\n-\n1,1,2,3,5,8,13,21,34,55,89,144,233,377,...\n-\nAnalysis:\n-\nT(n) = T(n-1) + T(n-2) = (...) = O(2n)\n\nComputing Fibonacci numbers: Bottom up\n-\nBottom up approach\n- Python code\n\n- Analysis: T(n) = O(n)\ndef fibonacci(n):\n\nfib_table[1] = 1\n\nfib_table[2] = 1\n\nfor i in range(3,n+1):\nfib_table[i] = fib_table[i-1]+fib_table[i-2]\n\nreturn fib_table[n]\n?\nF[12]\nF[11]\nF[10]\nF[9]\nF[8]\nF[7]\nF[6]\nF[5]\nF[4]\nF[3]\nF[2]\nF[1]\nfib_table\n\nLessons from iterative Fibonacci algorithm\n- What did the iterative solution do?\n- Reveal identical sub-problems\n- Order computation to enable result reuse\n- Systematically filled-in table of results\n- Expressed larger problems from their subparts\n- Ordering of computations matters\n- Naive top-down approach very slow\n- results of smaller problems not available\n- repeated work\n- Systematic bottom-up approach successful\n- Systematically solve each sub-problem\n- Fill-in table of sub-problem results in order.\n- Look up solutions instead of recomputing\n\n?\nF[12]\nF[11]\nF[10]\nF[9]\nF[8]\nF[7]\nF[6]\nF[5]\nF[4]\nF[3]\nF[2]\nF[1]\nfib_table\n\nDynamic Programming in Theory\n- Hallmarks of Dynamic Programming\n- Optimal substructure: Optimal solution to problem\n(instance) contains optimal solutions to sub-problems\n- Overlapping subproblems: Limited number of distinct\nsubproblems, repeated many many times\n- Typically for optimization problems (unlike Fib example)\n- Optimal choice made locally: max( subsolution score)\n- Score is typically added through the search space\n- Traceback common, find optimal path from indiv. choices\n- Middle of the road in range of difficulty\n- Easier: greedy choice possible at each step\n- DynProg: requires a traceback to find that optimal path\n- Harder: no opt. substr., e.g. subproblem dependencies\n\nHallmarks of optimization problems\n1. Optimal substructure\nAn optimal solution to a problem (instance)\ncontains optimal solutions to subproblems.\n2. Overlapping subproblems\nA recursive solution contains a \"small\" number\nof distinct subproblems repeated many times.\n3. Greedy choice property\nLocally optimal choices lead\nto globally optimal solution\nGreedy algorithms\nDynamic Programming\nGreedy Choice is not possible\nGlobally optimal solution requires\ntrace back through many choices\n\nDynamic Programming in Practice\n-\nSetting up dynamic programming\n1. Find 'matrix' parameterization (# dimensions, variables)\n2. Make sure sub-problem space is finite! (not exponential)\n-\nIf not all subproblems are used, better off using memoization\n-\nIf reuse not extensive, perhaps DynProg is not right solution!\n3. Traversal order: sub-results ready when you need them\n-\nComputation order matters! (bottom-up, but not always\nobvious)\n4. Recursion formula: larger problems = F(subparts)\n5. Remember choices: typically F() includes min() or max()\n-\nNeed representation for storing pointers, is this polynomial !\n-\nThen start computing\n1. Systematically fill in table of results, find optimal score\n2. Trace-back from optimal score, find optimal solution\n\nGoal: Sequence Alignment / Dynamic Programming\n1. Introduction to sequence alignment\n- Comparative genomics and molecular evolution\n- From Bio to CS: Problem formulation\n- Why it's hard: Exponential number of alignments\n2. Introduction to principles of dynamic programming\n- Computing Fibonacci numbers: Top-down vs. bottom-up\n- Repeated sub-problems, ordering compute, table lookup\n- DP recipe: (1) Parameterization, (2) sub-problem space,\n(3) traversal order, (4) recursion formula, (5) trace-back\n3. DP for sequence alignment\n- Additive score, building up a solution from smaller parts\n- Prefix matrix: finite subproblems, exponential paths\n- Duality: each entryprefix alignment score; pathaligmnt\n4. Advanced topics: Dynamic Programming variants\n- Linear-time bounded DP(heuristic). Linear-space DP. Gaps\n- Importance of parameterization: 2-D vs. 4-D decomposition\n\n(3) How do we apply dynamic programming\n\nto sequence alignment ?\n\nKey insight #1: Score is additive, smaller to larger\n- Compute best alignment recursively\n- For a given aligned pair (i, j), the best alignment is:\n- Best alignment of S1[1..i] and S2[1..j]\n- + Best alignment of S1[ i..n] and S2[ j..m]\n- Proof: cut-and-paste argument (see 6.046)\nA C G T C A T C A\nT A G T G T C A\nS1\nS2\ni\nj\nA C G\nT C A T C A\nT A G T G\nT C A\nS1\nS2\ni\nj\ni\nj\n\nThis allows a single recursion (top-left to bottom-right) instead of\ntwo recursions (middle-to-outside top-down)\n\nKey insight #2: compute scores recursively\nA C G T C A T C A\nT A G T G T C A\nS1\nS2\nA\nC G T\nT A G\nT G\nS1\nS2\nA C G T\nC A T C A\nT A G T G\nT C A\nS1\nS2\nCompute alignment of CGT vs. TG exactly once\n\nKey insight #3: sub-problems are repeated reuse!\nA C G T C A T C A\nT A G T G T C A\nS1\nS2\nA\nC G T\nT A G\nT G\nS1\nS2\nA C G T C A T C A\nT A G T G T C A\nS1\nS2\nS2\nA C G T\nC A T C A\nT A G T G\nT C A\nS1\nS2\nA\nC G T C A T C A\nT A G\nT G T C A\nS1\nC G T\nC A T C A\nT G\nT C A\nS1\nS2\nIdentical sub-problems! We can reuse our work!\n\nSolution #1 - Memoization\n- Create a big dictionary, indexed by aligned seqs\n- When you encounter a new pair of sequences\n- If it is in the dictionary:\n- Look up the solution\n- If it is not in the dictionary\n- Compute the solution\n- Insert the solution in the dictionary\n- Ensures that there is no duplicated work\n- Only need to compute each sub-alignment once!\n\nTop down approach\n\nSolution #2 - Dynamic programming\n- Create a big table, indexed by (i,j)\n- Fill it in from the beginning all the way till the end\n- You know that you'll need every subpart\n- Guaranteed to explore entire search space\n- Ensures that there is no duplicated work\n- Only need to compute each sub-alignment once!\n- Very simple computationally!\nBottom up approach\n\nKey insight #4: Optimal prefix almt score Matrix entry\nS1[1..i]\ni\nS1[i..n]\n\nS2[1..j]\nj\nS\n\nS2[ j..m]\n\nKey insight #5: Optimal alignment Matrix path\nA C G T C A T C A\nT\nA\nG\nT\nG\nT\nC\nA\nS1\nS2\nA C G T C A T C A\nT A\nG T G\nT C A\nA\nG\nT\nC/G\nT\nC\nA\nGoal:\nFind best path\nthrough the matrix\nBest alignment Best path through the matrix\n\nDP approach: iteratively grow best alignment soltn\n- Compute all alignment scores from the bottom up\n- Define M[i,j] prefix alignment score of S1[1..i] and S2[1..j]\n- Fill up table recursively from smaller to bigger alignments\n- Express alignment of S1[1..i+1] and S2[1..j+1] M[i+1,j+1]\n- One of three possibilities: (1) extend alignment from M[i,j]\n(2) extend from M[i-1,j], or (3) extend from M[i,j-1]\n- Only a local computation, takes O(1) time!\n- Proof of correctness (cut-and-paste argument from 6.006)\n- Best alignment of S1[1..i+1] and S2[1..j+1] must be\ncomposed of best alignments of smaller prefix\n- Proof: otherwise could replace sub and get better overall\nA C G\nT C A T C A\nT A G T G\nT C A\nS1\nS2\ni\nj\n\nComputing alignments recursively: M[i,j]=F(smaller)\n- Local update rules, only look at neighboring cells:\n- Compute next alignment based on previous alignment\n- Just like Fibonacci numbers: F[i] = F[i-1] + F[i-2]\n- Table lookup avoids repeated computation\n- Computing the score of a cell from smaller neighbors\n\nM( i-1, j ) - gap\n- M(i,j) = max{ M( i-1, j-1) + score }\n\nM( i , j-1) - gap\n- Only three possibilities for extending by one nucleotide:\na gap in one species, a gap in the other, a (mis)match\n- Compute scores for prefixes of increasing length\n- Start with prefixes of length 1, extend by one each time,\nuntil all prefixes have been computed\n- When you reach bottom right, alignment score of\nS1[1..m] and S2[1..n] is alignment of full S1 and full S2\n- (Can then trace back to construct optimal path to it)\n(i,j)\ni-1\ni\nj-1\nj\n\nDynamic Programming for sequence alignment\n-\nSetting up dynamic programming\n1. Find 'matrix' parameterization\n-\nPrefix parameterization. Score(S1[1..i],S2[1..j]) M(i,j)\n-\n(i,j) only prefixes vs. (i,j,k,l) all substrings simpler 2-d matrix\n2. Make sure sub-problem space is finite! (not exponential)\n-\nIt's just n2, quadratic (which is polynomial, not exponential)\n3. Traversal order: sub-results ready when you need them\n\n4. Recursion formula: larger problems = Func(subparts)\n- Need formula for computing M[i,j] as function of previous results\n- Single increment at a time, only look at M[i-1,j], M[i,j-1], M[i-1,j-1]\ncorresponding to 3 options: gap in S1, gap in S2, char in both\n- Score in each case depends on gap/match/mismatch penalties\n5. Remember choice: F() typically includes min() or max()\n-\nRemember which of three cells (top,left,diag) led to maximum\nCols\nLR\nRows\ntopbot\nDiags\ntopRbotL\n\nStep 1: Setting up the scoring matrix M[i,j]\n-\nA\nG\nT\nA\nA\nG\nC\n-\nInitialization:\n- Top left: 0\nUpdate Rule:\nM(i,j)=max{\n\n}\nTermination:\n- Bottom right\n\nStep 2: Filling in the optimal scores from top left\n-\nA\nG\nT\nA\nA\nG\nC\n-\n-2\n-2\n-1\n-1\n-4\n-6\n-1\n-3\n-4\n-2\n-6\n-3\n-8\n-5\n-2\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\nInitialization:\n- Top left: 0\nUpdate Rule:\nM(i,j)=max{\n- M(i-1 , j ) - 2\n- M( i , j-1) - 2\n- M(i-1 , j-1) -1\n- M(i-1 , j-1)+1\n}\nTermination:\n- Bottom right\nmismatch\nmatch\ngap\ngap\nPath segment that lead to the optimal choice\n\nStep 3: Trace back pointers to construct alignment\n-\nA\nG\nT\nA\nA\nG\nC\n-\n-2\n-4\n-6\n-2\n-1\n-3\n-4\n-1\n-2\n-6\n-3\n-1\n-8\n-5\n-2\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\n-1\nInitialization:\n- Top left: 0\nUpdate Rule:\nM(i,j)=max{\n- M(i-1 , j ) - 2\n- M( i , j-1) - 2\n- M(i-1 , j-1) -1\n- M(i-1 , j-1)+1\n}\nTermination:\n- Bottom right\nmismatch\nmatch\ngap\ngap\nPath segments that lead to the globally optimal solution\nPath segments that lead to locally optimal choices\n\nGenome alignment in an excel spreadsheet\n\nK15\nK34\nK53\nAD53\nAD34\nAD15\nK15\nK34\nK53\nAD53\nAD34\nAD15\nLocal score of matching\ncharacters S1[i] and S2[j]\nMax alignment score of\naligning prefix S1[1..i]\nand prefix S2[1..j]\nIs the max alignment score\ncoming from the top (\"|\"),\nfrom the left (\"--\") or from\nthe diagonal up (\"\\\")\n(show all of them, cuz we can)\nIs the [i,j] part of an optimal\npath? (i.e. are chars S1[i]\nand S2[j] aligned to each\nother in an optimal path)\n(also count number of\noptimal paths/alignment\nthrough [i.j], cuz we can)\nConstruct the optimal alignment for sequence S1 by\nadding in characters or gaps to increasingly large suffixes\n(and arbitrarily choose one path when multiple using nested if's)\nConstruct the optimal alignment for sequence S2 similarly to S1\nGenome alignment\nin an excel\nspreadsheet\n\nWhat is missing? (5) Returning the actual path!\n- We know how to compute the best score\n- Simply the number at the bottom right entry\n- But we need to remember where it came from\n- Pointer to the choice we made at each step\n- Retrace path through the matrix\n- Need to remember all the pointers\n\nTime needed: O(m*n)\nSpace needed: O(m*n)\n\nx1 .............................. xM\ny1 .............................. yN\n\nGoal: Sequence Alignment / Dynamic Programming\n1. Introduction to sequence alignment\n- Comparative genomics and molecular evolution\n- From Bio to CS: Problem formulation\n- Why it's hard: Exponential number of alignments\n2. Introduction to principles of dynamic programming\n- Computing Fibonacci numbers: Top-down vs. bottom-up\n- Repeated sub-problems, ordering compute, table lookup\n- DP recipe: (1) Parameterization, (2) sub-problem space,\n(3) traversal order, (4) recursion formula, (5) trace-back\n3. DP for sequence alignment\n- Additive score, building up a solution from smaller parts\n- Prefix matrix: finite subproblems, exponential paths\n- Duality: each entryprefix alignment score; pathaligmnt\n4. Advanced topics: Dynamic Programming variants\n- Linear-time bounded DP(heuristic). Linear-space DP. Gaps\n- Importance of parameterization: 2-D vs. 4-D decomposition\n\nIf time permits...\n\n(4) Extensions to basic DP solution\n\nBounded Dynamic Programming\nInitialization:\n\nF(i,0), F(0,j) undefined for i, j > k\n\nIteration:\nFor i = 1...M\nFor j = max(1, i - k)...min(N, i+k)\n\nF(i - 1, j - 1)+ s(xi, yj)\n\nF(i, j) = max F(i, j - 1) - d, if j > i - k(N)\n\nF(i - 1, j) - d, if j < i + k(N)\n\nTermination:\nsame\nx1 .............................. xM\ny1 .............................. yN\nk(N)\nSlides credit: Serafim Batzoglou\n\nCan we do better than O(n2)in the general case?\n- Reduced Orthogonal Vectors to PATTERN\n- Reduced PATTERN to EDIT DISTANCE\n- Proved EDIT DISTANCE is a SETH-hard problem\n- Faster edit dist. algorithm probably not a good term project\nAbstract removed due to copyright restrictions.\nSource: Backurs, Arturs, and Piotr Indyk. \"Edit Distance Cannot Be Computed in Strongly Subquadratic Time (unless SETH is false).\"\nIn Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, pp. 51-58. ACM, 2015.\n\nF(i,j)\nLinear space alignment\nIt is easy to compute F(M, N) in linear space\nAllocate ( column[1] )\nAllocate ( column[2] )\n\nFor i = 1....M\n\nIf\ni > 1, then:\n\nFree( column[i - 2] )\n\nAllocate( column[ i ] )\n\nFor j = 1...N\n\nF(i, j) = ...\n\nWhat about the pointers?\n\nFinding the best back-pointer for current column\n-\nNow, using 2 columns of space, we can compute\n\nfor k = 1...M, F(M/2, k), Fr(M/2, N-k)\n\nPLUS the backpointers\n\nBest forward-pointer for current column\n-\nNow, we can find k* maximizing F(M/2, k) + Fr(M/2, N-k)\n-\nAlso, we can trace the path exiting column M/2 from k*\nk*\nk*\n\nRecursively find midpoint for left & right\n- Iterate this procedure to the left and right!\nN-k*\nM/2\nM/2\nk*\n\nTotal time cost of linear-space alignment\nTotal Time: cMN + cMN/2 + cMN/4 + ..... = 2cMN = O(MN)\n\nTotal Space: O(N) for computation,\n\nO(N+M) to store the optimal alignment\nN-k*\nM/2\nM/2\nk*\n\nGoal: Sequence Alignment / Dynamic Programming\n1. Introduction to sequence alignment\n- Comparative genomics and molecular evolution\n- From Bio to CS: Problem formulation\n- Why it's hard: Exponential number of alignments\n2. Introduction to principles of dynamic programming\n- Computing Fibonacci numbers: Top-down vs. bottom-up\n- Repeated sub-problems, ordering compute, table lookup\n- DP recipe: (1) Parameterization, (2) sub-problem space,\n(3) traversal order, (4) recursion formula, (5) trace-back\n3. DP for sequence alignment\n- Additive score, building up a solution from smaller parts\n- Prefix matrix: finite subproblems, exponential paths\n- Duality: each entryprefix alignment score; pathaligmnt\n4. Advanced topics: Dynamic Programming variants\n- Linear-time bounded DP(heuristic). Linear-space DP. Gaps\n- Importance of parameterization: 2-D vs. 4-D decomposition\n\nAdditional insights\nWhy the 2-dimentional parameterization worked\n\nSummary\n- Dynamic programming\n- Reuse of computation\n- Order sub-problems. Fill table of sub-problem results\n- Read table instead of repeating work (ex: Fibonacci)\n- Sequence alignment\n- Edit distance and scoring functions\n- Dynamic programming matrix\n- Matrix traversal path Optimal alignment\n- Thursday: Variations on sequence alignment\n- Local/global alignment, affine gaps, algo speed-ups\n- Semi-numerical alignment, hashing, database lookup\n- Recitation:\n- Dynamic programming applications\n- Probabilistic derivations of alignment scores\n\nGoal: Sequence Alignment / Dynamic Programming\n1. Introduction to sequence alignment\n- Comparative genomics and molecular evolution\n- From Bio to CS: Problem formulation\n- Why it's hard: Exponential number of alignments\n2. Introduction to principles of dynamic programming\n- Computing Fibonacci numbers: Top-down vs. bottom-up\n- Repeated sub-problems, ordering compute, table lookup\n- DP recipe: (1) Parameterization, (2) sub-problem space,\n(3) traversal order, (4) recursion formula, (5) trace-back\n3. DP for sequence alignment\n- Additive score, building up a solution from smaller parts\n- Prefix matrix: finite subproblems, exponential paths\n- Duality: each entryprefix alignment score; pathaligmnt\n4. Advanced topics: Dynamic Programming variants\n- Linear-time bounded DP(heuristic). Linear-space DP. Gaps\n- Importance of parameterization: 2-D vs. 4-D decomposition\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 20 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/e53dd96c18a69deb025a25f8be7a683d_MIT6_047F15_Lecture20.pdf",
      "content": "MIT 6.047/6.878/HST.507 - Computational Biology: Genomes, Networks, Evolution\nLecture 20\nPersonal genomics, disease epigenomics,\nsystems approaches to disease\nPredictive Medicine\nMolecular Epidemiology\nMendelian Randomization\nPolygenic Risk Prediction Models\n\nPersonal genomics today: 23 and We\nce\nRecombination breakpoints\nan\nt\nri\ne\nInh\nFamily\nMe vs.\nmy brother\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nMy dad\nDad's mom\nMom's dad\nHuman ancestry\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nDisease risk\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nGenomics: Regions\n\nmechanisms\ndrugs\nSystems: genes\ncombinations\npathways\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\nCalculating functional enrichments for GWAS loci\nolecular epidemiology\nmeQTLs: Genotype-Epigenome association (cis-/trans-)\nEWAS: Epigenome-Disease association\nesolving Causality\nStatistical: Mendelian Randomization\nApplication to genotype + methylation in AD\nystems Genomics and Epigenomics of disease\nBeyond single loci: polygenic risk prediction models\n-\n3. M\n-\n-\n4. R\n-\n-\n5. S\n-\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nD\nX\nG\nE\neffects\ncauses\ngenome\nepigenome\nbiomarkers\nenvironment\ndisease\nS\nsymptoms\nsyndrome\nC\nconfounders\nEpidemiology\nThe study of the\npatterns, causes, and effects\nof health and disease conditions\nin defined populations\n\nEpidemiology: Definitions and terms\n- Morbidity level: how sick an individual is\n- Incidence: # of new cases / # people / time period\n- Prevalence: Total # of cases in population\n- Attributable risk: rate in exposed vs. not exposed\n- Population burden: yrs of potential life lost (YPLL),\nquality-/disability-adjusted life year (QALY/DALY)\n- Syndrome: Co-occurring signs (observed), symptomes\n(reported), and other phenomena; (often hard to\nestablish causality / risk factors)\n- Prevention challenge: Determine disease, cause,\nunderstand whether, when, and how to intervene\n\nDetermining disease causes: study design\n- Principles of experimental design\n- Control: comparison to baseline, placebo effect\n- Randomization: Difficult to achieve, ensure mixing\n- Replication: control variability in initial sample\n- Grouping: understand variation between subgroups\n- Orthogonality: all combinations of factors/treatments\n- Combinatorics: factorial design n x n x n x < x n table\n- Challenge of human subjects\n- Legal and ethical constraints, Review boards\n- Randomization by instrumental variables\n- Clinical trials: blind (patient), double-blind (doctor too)\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\n- Calculating functional enrichments for GWAS loci\n3. Molecular epidemiology\n- meQTLs: Genotype-Epigenome association (cis-/trans-)\n- EWAS: Epigenome-Disease association\n4. Resolving Causality\n- Statistical: Mendelian Randomization\n- Application to genotype + methylation in AD\n5. Systems Genomics and Epigenomics of disease\n- Beyond single loci: polygenic risk prediction models\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nconfounders\nenvironment\nD\nX\nG\neffects\ncauses\ngenome\nepigenome\nbiomarkers\ndisease\nS\nsymptoms\n\nC\nE\nGenetic Epidemiology\nGenetic factors contributing to disease\n\nGenome-wide association studies (GWAS)\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Mccarthy, M. I., Abecasis, G. R., Cardon, L. R., Goldstein, D. B., Little, J., Ioannidis, J. P., & Hirschhorn,\nJ. N. (2008). \"Genome-wide association studies for complex traits: Consensus, uncertainty and challenges.\" Nat\nRev Genet Nature Reviews Genetics, 9(5), 356-369.\n- Iden\n\nRisk allele G more frequent in patients, A in controls\nBut: large regions co-inherited find causal variant\nGenetics does not specify cell type or process\ntify regions that co-vary with the disease\n-\n-\n-\n\nAll disease-associated genotypes from GWAS\n- 1000s of studies, each with 1000s of individuals\n- Increasing power, meta-analyses reveal additional loci\n- More loci expected, only fraction of heritability explained\nCourtesy of Burdett T (EBI), Hall PN (NHGRI), Hastings E (EBI), Hindorff LA (NHGRI), Junkins HA (NHGRI),\nKlemm AK (NHGRI), MacArthur J (EBI), Manolio TA (NHGRI), Morales J (EBI), Parkinson H (EBI) and\nWelter D (EBI).The NHGRI-EBI Catalog of published genome-wide association studies.\nAvailable at: www.ebi.ac.uk/gwas. Used with Permission.\n\nMore loci on the way: GWAS growth continues\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- When to design custom chip: continuously update\n- http://www.genome.gov/admin/gwascatalog.txt\n\nDecreasing cost of whole-genome sequencing\nImage by Wetterstrand KA. DNA Sequencing Costs: Data from the NHGRI Genome Sequencing\nProgram ( GSP) Available at: www.genome.gov/sequencingcosts. Image in the public domain.\n\n- Simply genotype all known variants at >0.1% freq\n- Or: sequence complete diploid genome of everyone\n\nGenetic epidemiology: What to test\n- Family risk alleles, inherited with common trait\n- Specific genes, specific variants, family history\nMonogenic, actionable, protein-coding mutations\n- Most understood, highest impact, easiest to interpret\nAll coding SNPs with known disease association\n- What if not druggable / treatable? Want/need know?\nAll coding/non-coding associations from GWAS\n- Thousands of significant associations (1350 on 6/2012)\nAll common SNPs, regardless of association\n- HapMap and 1000 Genomes capture common variants\n-\n-\n-\n-\n- Genome: all SNPs, CNVs, rare/private mutations\n\nPredictive medicine: When to screen\n- Diagnostic testing: after symptoms, confirm a hypothesis,\nistinguish between possibilities\nredictive risk: before symptoms even manifest\newborn: heel pick, store, for early treatment\nre-natal testing: ulstrasound, maternal serum vs.\needles, probes, chorionic villus sampling\nre-conception testing: common/rare disorders\narrier testing: specific mutation in family history\nenetics vs. biomarkers : cause vs. consequence?\nd\n- P\n- N\n- P\nn\n- P\n- C\n- G\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\nenetic Epidemiology:\nGenetic basis: GWAS and screening\nInterpreting GWAS with functional genomics\nCalculating functional enrichments for GWAS loci\nolecular epidemiology\nmeQTLs: Genotype-Epigenome association (cis-/trans-)\nEWAS: Epigenome-Disease association\nesolving Causality\nStatistical: Mendelian Randomization\nApplication to genotype + methylation in AD\nystems Genomics and Epigenomics of disease\nBeyond single loci: polygenic risk prediction models\n2. G\n-\n-\n-\n3. M\n-\n-\n4. R\n-\n-\n5. S\n-\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nInterpreting disease associations\nFunctional genomics of GWAS\n\nGWAS\nCATGACTG\nCATGCCTG\nenotype\nDisease\nmQTLs Epigenome\nMWAS\n\nInterpreting disease-association signals\n(1) Interpret variants using Epigenomics\n- Chromatin states: Enhancers, promoters, motifs\n- Enrichment in individual loci, across 1000s of SNPs in T1D\nG\n(2) Epigenome changes in disease\n- Intermediate molecular phenotypes associated with disease\n- Variation in brain methylomes of Alzheimer's patients\n\nComplex disease: strong non-coding component\nMonogenic /\nPolygenic / Complex\nMendelian Disease\nDisease\nCoding\nNon-coding\nHuman Genetic Mutation Database\nCatalog of GWAS studies\nApril 2010 release\nHindorff et al. PNAS 2009\nSlide credit: Benjamin Raby\n\nGenomic medicine: challenge and promises\n1. The promise of genetics\n- Disease mechanism\n- New target genes\n- New therapeutics\n- Personalized medicine\nThe challenge\n- 90+% disease hits non-coding\n- Cell type of action not known\n- Causal variant not known\n- Mechanism not known\n2.\nHillmer Nature Genetics 2008\nGWAS: simple χ2 statistical test\nCourtesy of Macmillan Publishers Limited. Used with permission\nSource: Hillmer, A. M., Brockschmidt, F. F., Hanneken, S., Eigelshoven, S.,\nSteffens, M., Flaquer, A., . . . Nothen, M. M. (2008). \"Susceptibility variants\nfor male-pattern baldness on chromosome 20p11.\" Nature Genetics Nat Genet,\n40(11), 1279-1281. doi:10.1038/ng.228\n\nGenomic medicine: challenge and promises\n3. The remedy\nnnotation of non-coding\nenome (ENCODE/Roadmap)\ninking of enhancers to\negulators and target genes\new methods for utilizing them\n\nThe deliverables\n- Relevant cell type\n- Target genes\n- Causal variant\n- Upstream regulator\n- Relevant pathways\n- A\ng\n- L\nr\n- N\nRoadmap Epigenomics, Nature 2015\n4.\n- Intermediate phenotypes\nErnst, Nature 2011\nCourtesy of NIH Roadmap Epigenomics Mapping\nConsortium. Used with permission.\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Ernst, J. et al. (2011). Mapping and analysis of chromatin\nstate dynamics in nine human cell types. Nature, 473(7345), 43-49.\n\nThis talk: From loci to mechanisms\nBuilding a reference map of the regulatory genome\nRegions:\nEnhancers, promoters, transcribed, repressed\nEnhancers\nPromoters\nTranscribed\nRepressed\nCell types:\nPredict tissues and cell types of epigenomic act\n\nivity\nTarget genes: Link variants to their target genes using eQTLs, activity, Hi-C\nNucleotides: Regulatory consequence of mutation: Conservation, PWMs\nRegulators:\nUpstream regulators whose activity is disrupted by mutation\nApplication to GWAS, hidden heritability, and Cancer\nGWAS\n\nCATGCCTG\n- 93% top hits non-coding\nMechanism? Cell type?\nhits\nCGTGTCTA\n- Lie in haplotype blocks\nCausal variant(s)?\n'Hidden'\n\nCATGCCTG\n- Many variants, small effects\nPathway-level burden/load\nheritability\nCGTGTCTA\n- Many false positives\nPrioritize w/ regulatory annotations\nCancer\n\nCATGCCTG\n- Loss of function\nProtein-coding variants, convergence\nmutations\nCATCCCTG\n- Gain of function Regulatory variants, heterogeneity\n\nDissecting non-coding genetic associations\n3. Causal nucleotide(s)\n2. Target gene(s)\n1. Tissue/cell type(s)\n4. Upstream regulator(s)\nTF\nTF\nTF\n5. Cellular phenotypes\n6. Organismal phenotypes\nGWAS region\nSNPs\n1. Establish relevant tissue/cell type\n2. Establish downstream target gene(s)\n3. Establishing causal nucleotide variant\n4. Establish upstream regulator causality\n5. Establish cellular phenotypic consequences\n6. Establish organismal phenotypic consequences\n\nUsing epigenomic maps\nto predict disease-relevant tissues\n\nStem C\nImmun\nHeart\nLiver\nRegion of association\nIndividual SNPs\nHeight\nType 1 Diabetes\nBlood Pressure\nCholesterol\n\nIdentifying disease-relevant cell types\nells\ne\nStem Cell\nImmune\nHeart\nLiver\nEnhancers\nEnhancers\nEnhancers\nEnhancers\n- For every trait in the GWAS catalog:\n- Identify all associated regions at P-value threshold\n- Consider all SNPs in credible interval (R2≥;8)\n- Evaluate overlap with tissue-specific enhancers\n- Keep tissues showing significant enrichment (P<0.001)\nRepeat for all traits (rows) and all cell types (columns)\n-\n\nGWAS hits in enhancers of relevant cell types\n\nT cells\nB cells\nDigestive\nBrain\nES\nLiver\nHeart\n\nLinking traits to their relevant cell/tissue types\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nImmune activation + neural repression in human + mouse\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Gjoneska, E., Pfenning, A. R., Mathys, H., Quon, G.,Kundaje, A., Tsai, L., & Kellis, M. (2015). \"\n\nConserved Epigenomic signals in\nmice and humans reveal immune basis of Alzheimer's disease.\" Nature, 518 (7539), 365-369. doi:10.1038/nature14252\n\nSample mouse brain\nepigenomics during\nTwo contrasting signatures of\nneurodegeneration\nimmune activation vs. neural repression\nIs inflammation simply a consequence of neuronal loss?\n\nGenetic evidence for immune vs. neuronal components\nIncreasing\nDecreasing\n(immune)\n(neuronal)\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Gjoneska, E., Pfenning, A. R., Mathys, H., Quon, G., Kundaje, A., Tsai, L., & Kellis, M. (2015). \"Conserved\nEpigenomic signals in mice and humans reveal immune basis of Alzheimer's disease.\" Nature, 518(7539), 365-369.\ndoi:10.1038/nature14252\nOnly increasing (immune) enhancers\nNeuronal cell types are depleted\nenriched in AD-associated SNPs\nfor AD-associated SNPs\nIndicates immune cell dysregulation is causal component\nMicroglial cells: resident immune cells of adult brain\nMacrophages: infiltrate brain in neurodegeneration\n\nUsing epigenomic annotations\nfor fine-mapping disease regions\n\nLD: both a\nblessing &\na curse\nObservation: LD\nblocks in which\nthere is no\nevidence for\nhistorical\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nrecombination\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nCausal variant not known in most GWAS regions\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Smemo, S., Tena, J. J., Kim, K., Gamazon, E. R., Sakabe, N. J.,Gomez-Marin, C., . . .\nNobrega, M. A. (2014). \"Obesity-associated variants within FTO form long-range functional\nconnections with IRX3.\" Nature, 507(7492), 371-375. doi:10.1038/nature13138\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nLD (Linkage disequilibrium): large regions co-inherited in blocks\nBlessing for initial mapping (few tags), curse for fine-mapping\nUse functional annotations to predict causal variant(s)\n\nMultiple lines of evidence for fine-mapping\nCourtesy of Macmillan Publishers Limited. Used with permission. Ward, L. D., & Kellis, M. (2012). Interpreting noncoding genetic variation in complex\n\ntraits and human disease. Nat Biotechnol Nature Biotechnology, 30(11), 1095-1106. doi:10.1038/nbt.2422. Used with permission.\nWard and Kellis, Nature Biotechnology 2012\n- Epigenomic information: enhancers & linking (target genes)\n- Motif information: causal variants & upstream regulators\n- Evolutionary conservation: causal variants & conserved motifs\n\nDetect SNPs that disrupt conserved regulatory motifs\nCourtesy of Macmillan Publishers Limited. Used with permission.\nSource: Lindblad-Toh, Kerstin, Manuel Garber, Or Zuk, Michael F. Lin, Brian J.\n\nParker,\nSte fan Washietl, Po uya Kh eradpou r, et al. \"A Hi gh-Resolu t ion\nMap o\nf Human Ev olutionary\n\nConstraint Using 29 Mammals.\" Nature 478, no. 7370 (2011): 476-82.do\ni:10.1038/nature10530.\n- Functionally-associated SNPs enriched in states, constraint\n\nAllele-specific chromatin marks: cis-vs-trans effects\n(c) source unknown. All ri\nghts reserved. This content i s excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- Maternal and paternal GM12878 genomes sequenced\n- Map reads to phased genome, handle SNPs indels\n- Correlate activity changes with sequence differences 35\n\nPredict effect of common, rare, somatic mutations\nAll: Regulatory and epigenomic annotations\nRare/somatic: Predict TF binding disruption\nRichard Sallari\nCommon: allelic activity in heterozygous lines\nXinchen Wang\n\nHaploReg: public resource for dissecting GWAS\nCourtesy of the authors. License: CC BY-NC.\nSource: Ward, Lucas D. and Manolis Kellis. \"HaploReg: a resource for exploring chromatin states, conservation, and regulatory\n\nmotif alterations within sets of genetically linked variants.\" Nucleic Acids Research 40, no. D1 (2012): D930-D934.\n\n- Start with any list of SNPs or select a GWA study\n\n- Mine ENCODE and Roadmap epigenomics data for hits\n\n- Hundreds of assays, dozens of cells, conservation, motifs\n- Report significant overlaps and link to info/browser\n- Try it out: http://compbio.mit.edu/HaploReg\n\nWard, Kellis NAR 2011\n\nPredicting target genes\n\nThree lines of linking evidence\ntic\nPhysical\nFunctional\nGene\n\n(c) source unknown. All ri\nghts reserved. This content\nCourtesy of Macmillan Pu\n\nblishers Limited. Used with permission. Ward, L. D., & Kellis, M. (2012).\nis excluded from our Creative Commons license.\nInterpreting noncoding genetic variation in complex traits and human disease. Nat Biotechnol\nFor more information, see http://ocw.mit.edu/help/\n\nNature Biotechnology, 30(11), 1095-1106. doi:10.1038/nbt.2422. Used with permission.\nfaq-fair-use/.\nHi-C: Physical\nEnhancer-gene\neQTL evidence: SNP\nproximity in 3D\nactivity correlation\neffect on expression\n\nTargets: 3D folding and expr. genetics indicate IRX3+IRX5\nCohort of 20 homozygous risk and\n18 homozygous non\n\n-risk individuals:\nGenotype-dependent expression?\nDixon, Nature 2012\nTopological domains span 2.5Mb\neQTL targets: IRX3 and IRX5\nImplicate 8 candidate genes\n\nRisk allele: increased expression\n(gain-of-function)\n(c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n(c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\n- Calculating functional enrichments for GWAS loci\n3. Molecular epidemiology\n- meQTLs: Genotype-Epigenome association (cis-/trans-)\n- EWAS: Epigenome-Disease association\n4. Resolving Causality\n- Statistical: Mendelian Randomization\n- Application to genotype + methylation in AD\n5. Systems Genomics and Epigenomics of disease\n- Beyond single loci: polygenic risk prediction models\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nInterpreting disease-association signals\n(1) Interpret variants using Epigenomics\n- Chromatin states: Enhancers, promoters, motifs\n- Enrichment in individual loci, across 1000s of SNPs in T1D\nGWAS\nCATGACTG\nCATGCCTG\nGenotype\nDisease\nmQTLs Epigenome\nMWAS\n(2) Epigenome changes in disease\n- Intermediate molecular phenotypes associated with disease\n- Variation in brain methylomes of Alzheimer's patients\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\nGenetic Epidemiology:\nGenetic basis: GWAS and screening\nInterpreting GWAS with functional genomics\nCalculating functional enrichments for GWAS loci\nMolecular epidemiology\nmeQTLs: Genotype-Epigenome association (cis-/trans-)\nEWAS: Epigenome-Disease association\nResolving Causality\nStatistical: Mendelian Randomization\nApplication to genotype + methylation in AD\nSystems Genomics and Epigenomics of disease\nBeyond single loci: polygenic risk prediction models\nSub-threshold loci and somatic heterogeneity in cancer\n2.\n-\n-\n-\n3.\n-\n-\n4.\n-\n-\n5.\n-\n-\n\nD\nX\nG\neffects\ncauses\ngenome\nepigenome\nbiomarkers\ndisease\nS\nsymptoms\n\nC\nE\nconfounders\nenvironment\nMolecular Epidemiology\nMolecular Biomarkers of disease state:\nGene expression, DNA methylation,\nchromatin in specific cell types\n\nchr2\nmeQTL-linked CpG r^2\nmeQTL SNP r^2\nSNP AAF\nGenotype\nBRN.MID.FRNTL E073\nBRN.ANG.GYR E067\nBRN.ANT.CAUD E068\nBRN.CING.GYR E069\nBRN.HIPP.MID E071\nBRN.INF.TMP E072\nBRN.SUB.NIG E074\nLIV.ADLT E066\nBLD.CD14.PC E029\nBLD.CD4.MPC E037\nBLD.CD4.CD25M.CD45RA.NPC E039\nLNG.IMR90 E017\nGI.STMC.MUS E111\nSKIN.PEN.FRSK.FIB.01 E055\nMUS.TRNK.FET E089\nBONE.OSTEO E129\nGenes(+)\nGenes(-)\nMean Methylation\nNormalized Methylation\nMethylation StdDev\nmeQTL-linked CpG r^2\n241,400,000\n241,500,000\n241,600,000\n241,700,000\n241,800,000\n241,900,000\n242,000,000\n242,100,000\n242,200,000\n242,300,000\n3'\n241,400,000\n241,500,000\n241,600,000\n241,700,000\n241,800,000\n241,900,000\n242,000,000\n242,100,000\n242,200,000\n242,300,000\n5'\n\nGenetic and epigenetic data in 750 Alzheimer's patients/controls\nMAP Memory and Aging Project\n+ ROS Religious Order Study\nDorsolateral PFC\n.\n.\nReference\nChromatin\nstates\n(Bernstein)\nGenotype\n(1M SNPs\nx700 ind.)\n(De Jager)\nBrain\nLiver\nBlood\nLung\nGI\nSkin\nMuscle\nBone\nMethylation\n(450k probes\nx 700 ind)\n(De Jager)\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n750 subjects, initially cognitively normal, Alzheimer's diagnosed by pathology. (Bennett) 45\n\nData Matrices - An example scenario\nn=750 individuals\nn=750 individuals\nn=750 individuals\nn=750 individuals\nGenotype\ng=12,000,000\nMethylation\nm=450,000\ne=15\n\"Environment\"\np=\nPhenotype\n(Disease)\nM - Illumina Methylation 450k array,\n450,000 probes targeting CpGs\ngenome-wide.\nG - Affy SNP arrays, imputed against\nCEU thousand genomes reference\npanel, yielding 12m SNPs.\nE - Clinical covariates that might mask\nthe variation due to our\nphenotype, e.g. gender, smoking,\nage or sample batch.\nP - Phenotype of interest, sometimes\nmeasured with multiple markers\n(clinical Alz. diagnosis vs. pathology\nAlz. diagnosis vs. count of neuritic\nplaques).\nn -> number of individuals in cohort.\nE\nenvironment\ncause\nD\nG\nM\nAlzheimer\ngenotype\nmethylation effects\ndisease\n\nEWAS: Capturing variability in the Epigenome\nattributable to disease\nD\nX\nEpigenome\nDNA methylation\nPhenotype\n!lzheimer's Disease\nE\nEnvironment\nAge, Education\nGender, etc.\nKnown variable\ncorrection\nC\nExperimental, Technical\nCell type mixtures,\nBatch effects, Other\nUnknown Confounders\nKnown & ICA\ninferred variable\ncorrection\nEWAS\nHundreds of AD\nassociated loci,\nenriched in enhancers\nand relevant\npathways\nG\nmeQTL\nGenotype\n(~60K\n5M Common\nCpGs)\nVariants\n\nExcluding discovered and known covariates\n(c) source unknown. All ri\nghts reserved. This content is excluded from our Creative\n\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nInfer covariates using ICA,\ncompare to known,\nexclude both.\nStrongest effects:\n- Plate (batch)\n- Cell mixture\n- Bisulfite conversion\n- Gender\n- Age\nVariance explained:\n- Known: 25%\n- Inferred: 35%\n- Together: 40%\n\nC\nE\nconfounders\nenvironment\nD\nM\nG\neffects\ncause\ngenotype\nmethylation\nDisease\nGenotypeMethylation\nDiscovering mQTLs\nMethylation Quantitative Trait Loci\n\ncis-meQTLs\nM\nn=750\nn=750 Use linear models to identify cis-meQTLs w/in some genomic window.\n=450,000\n000,\nG\nm\n12,\ng=\nFor methyl mark mi and SNP gj:\nmi = β0 + β1(gj) + ε\n- Given several predictors: is additional predictor increasing\naccuracy more than complexity introduced?\n- Likelihood ratio testing paradigm: predict methylation with\nand without genotype (only works for nested models)\n- Null hypothesis H0: β1=0: Additional model complexity\n't explain a significant portion of variation in response\nLM1: mi = β0 + ε\nLM2: mi = β0 + β1(gj) + ε\nr term.\n2) / (q - p) ) / ( RSSLM2 / (n - q) )\n, n-q) degrees of freedom\nis p-value is what we report in a meQTL study\nSSLM2 too small vs. increase in model complexity\ndoesn\nTest using F statistic:\n- p is the number of parameters in LM1\n- q is the number of parameters in LM2\n- n is the sample size\n- RSS: Residual sum of squares\n- β: parameters to learn. ε: residual erro\nUnder null hypothesis: ( (RSSLM1 - RSSLM\nIs distributed as F distribution with (q-p\nIf F statistic significant: reject null: Th\nOtherwise, no meQTL: i.e. RSSLM1 - R\n\ncis-meQTLs\nM\nn\nn\n=450,000\n000,\nG\nm\n12,\ng=\nAlternative methods of detection:\nPermutation:\n- Correlate methylation and genotype.\n- For i in 1\n\n-> nperm:\n- Permute genotypes\n- Correlate methylation and genotype\n- Generate empirical p-value from permuted\ncorrelations\nLMM: Linear mixed models.\n-\n-\n\n0.0\n0.5\n1.0\n1.5\n2.0\n0.2\n0.4\n0.6\nAdjusted MA Dosage\nAdjusted Methylation\n-0.5\n0.5\n1.5\n0.65\n0.75\n0.85\nAdjusted MA Dosage\nAdjusted Methylation\n-0.5\n0.5\n1.5\n0.60\n0.64\n0.68\n0.72\nrs17836662 cg10853533 -44352\nAdjusted MA Dosage\nAdjusted Methylation\n-0.5\n0.5\n1.5\n0.10\n0.20\n0.30\nrs7924341 cg20132549 -1847\nAdjusted MA Dosage\nAdjusted Methylation\nMost epigenomic variability is genotype-driven\nManhattan plot of 450,000 methylation probes\nP)\nlog\n-(\nvalue\n-\nP\nChromosome and genomic position\nGenome-wide significance at p<3x10-10\n.\nPrune for probes disrupted by SNP.\n-\n-\n140,000 CpGs associated with genotype at 1% FDR\n\n55,000 at Bonferroni-corrected P-value of 10-2\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nScaling of discovery power with individuals\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- Number of meQTLs continues to increase linearly\n- Weak-effect meQTLs: median R2<0.1 after 400 indiv.\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\n- Calculating functional enrichments for GWAS loci\n3. Molecular epidemiology\n- meQTLs: Genotype-Epigenome association (cis-/trans-)\n- EWAS: Epigenome-Disease association\n4. Resolving Causality\n- Statistical: Mendelian Randomization\n- Application to genotype + methylation in AD\n5. Systems Genomics and Epigenomics of disease\n- Beyond single loci: polygenic risk prediction models\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nconfounders\nD\nM\nG\neffects\ncause\ngenotype\nmethylation\nenvironment\nDisease\n\nC\nE\nMethylationDisease\nEWAS\nEpigenome-wide association study\n\neWAS\nMethylation\nn\nn\nPhenotype\ne=\n(Disease)\n=450,000\nm\nLink methylationphenotype (~cis-eQTLs):\nlinear models and hypothesis testing\nPredict phenotype using methylation\n-\n-\nLM1: pi\nLM2: p = β0 + β1(m ) + ε\n= β0 + ε\ni\nj\n\neWAS\nn\nn\nMethylation\nm=450,000\nPhenotype\n(Disease)\np=10\nn\n\"Environment\"\ne=15\nLM1: AD = β0 + β2(gender) + ε\nLM2: AD = β0 + β1(mj) + β2(gender) ε\nLink methylationphenotype (~cis-eQTLs):\n- linear models and hypothesis testing\n- Predict phenotype using methylation\n\nProblem:\nvariance due to phenotype probably very\nsmall (unless your phenotype is cancer)\nNeedle in a haystack\n\nControl for other sources of variance\nto make the variance due to the\nphenotype stand out.\n\nIf phenotype is !lzheimer's (!D),\ngender incorporates more variance\ninto your M matrix than does AD.\n\neWAS\nMethylation\nPhenotype\n(Disease)\nn\nn\nm=450,000\np=10\n\"Environment\"\nn\ne=15\nMight have many environmental\nvariables to control for.\nLM1: AD = β0 + β2(gender) + β3(age) + β4(education) + < + ε\nLM2: AD = β0 + β1(mj) + β2(gender) + β3(age) + β4(education) + < + ε\n\neWAS\nNeed to account for variance due to genotype as well.\nMethylation\nPhenotype\n(Disease)\nn\nn\nm=450,000\np=10\n\"Environment\"\nn\ne=15\nGenotype\nn\ng=12,000,000\n\nRole of enhancers vs. promoters in\n!lzheimer's disease association\n\nEnhancers are hemi-methylated and highly variable\nEnhancers show\nmost variable\nmethylation\nPromoters show\nleast variable\nmethylation\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- Highly distinct signatures for\npromoters vs. enhancers\n- Enhancers hemi-methylated\nMethylation level\nMethylation level\nin each person (not bimodal)\n\nSNP-associated CpGs in enhancers, not promoters\n- Promoter methylation less affected by genetics\n- Enhancer methylation highly genotype-driven\n*\n*\n*\n*\n*\n* *\n*\n*\n*\n*\n* * *\n\nTSS flanking\nEnhancers\nRepressed\nEnrichment for meQTLs\n.5\nTranscribed\nPromoters\nTxEnh\n- TSS-flanking and repressed regions also genetic\n\nAD-associated probes in distal enhancers\nPer state: (Obs - Exp) / Total\nEnhancers\nPromoters\n(c) source unknown. All ri\nghts reserved. This content is excluded from our Creative\n\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- After cleaning with known and inferred covariates.\n- Distal and transcribed enhancers enriched.\nProximal regulators (promoters) depleted.\n-\n\nICA covariate correction cleans up enhancer signal\nBefore:\nOrange: Enrichment of\nenhancer probes for\nassociation with the\nreal phenotype.\nGrey: Enrichment of\nenhancer probes for a\nscrambled phenotype.\nAfter:\n(After conditioning on 7\nsurrogate variables\ndiscovered with ICA.)\nEmpirical p=0.06\nEmpirical p<.0001\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nAD predictive power highest in enhancers\nAPO\nE\nenhancers\nmethylome\npromoters\nAll SNPs\nTop predictive\nfeatures are:\n- Enhancer\nethylation\nll me\n\nthyl.\nSS, Het\nenetics\nincl. APOE)\nausality?\nommon\nathways?\nm\n- A\n- T\n- G\n(\n- C\n- C\np\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nNRSF\nELK1\nAll probes, ranked by AD assoc. P-value\nNon-significant pathways\nSignificant pathways\n0.60\n0.65\n0.70\n0.75\nAUC using pathway feature selection; p= 1.922e-11\nAD prediction reveals likely biological pathways\nAll probes, ranked by AD assoc. P-value\nCTCF\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nEnriched regulatory motifs\nsuggest potential pathway\ns\nHEB/Tcf12: proliferating neural and progenitor cells\nGATA: cell growth, blood, cell development\n\nTLX1/NFIC: Neuronal cell fates\nMouse AD models 66\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\n- Calculating functional enrichments for GWAS loci\n3. Molecular epidemiology\n- meQTLs: Genotype-Epigenome association (cis-/trans-)\n- EWAS: Epigenome-Disease association\n4. Resolving Causality\n- Statistical: Mendelian Randomization\n- Application to genotype + methylation in AD\n5. Systems Genomics and Epigenomics of disease\n- Beyond single loci: polygenic risk prediction models\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nins\nC\nE\nconfounders\nenvironment\nRisk factor causality w/ instrumental variables\nIf XY are correlated,\npossible scenarios are:\n- XY\n-\n\ncauses\nX\nY\nG\nY\n- XU\nY\n\nX\ntrument\nrisk factor\noutcome To distinguish, need\neffects\ncontrolled random experiment\nIs risk factor X causing disease Y (or a consequence)?\n- E.g. alcohol addiction, smoking, blood cholesterol, fever, stress\nRandomized experiment, with and without X: feasibility? ethics?\nG randomized experiment (e.g. random Mendelian\ninheritance), as only some subjects have genotype\nG (i.v.)must be correlated with Y but only through X\ni.e. if X known, G gives no additional information about Y\n-\n-\n-\n\nIn silico thought experiment\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\np=2.946466e-35\nn\noi\nat\nyl\nh\net\nM\nSubjects\nAD\nnonAD\n\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\np=3.847832e-05\nn\noi\nat\nyl\nh\net\nM\nSubjects\nAD\nnonAD\nSame effect due to Alz,\nbut with larger effect due\nto genotype.\nCC\nSmall but significant\neffect due to Alz\nCA\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nHemi-methylation associated with meQTL\nyields a p-value that's 30 orders of\nmagnitude lower for the AD phenotype.\n\nM\nG\nE\nP\n+\n+\n=\nG\nE\nP\n+\n=\nFrom G, include probe-specific\nterms for cis-meQTLs, as well as\nincluding trans-meQTLs in all\ncomparisons.\nVS\n\nMendelian randomization approach\nAccount for variance due to genotype, how much does methylation add?\nWith variability\ndue to\ngenotype and\nenvironmental\ncovariates\nremoved, the\neffect due to\nphenotype\nshould become\nmore\nprevalent.\n\nCausality testing\n\nModeling complex Human diseases\n- Three possible models:\n1. Independent Associations\nD\nM\nG\nX\n2. Causal Pathway Model\n3. Interaction Model\nD\nG\nM\nGenotype\nD\nG\nM\nD\nM\nG\nMethylation\nDisease\n\n(1) Independent Associations\nD\nM\nG\nX\n- Association between Factor A and Disease\n- Association between Factor B and Disease\n- No association between Factor A and Factor B\nG\nFactor A\n- Example: 2 independent risk genes\nX\nFactor B\nY\nDisease D\n\n(2) Causal Pathway Models\n- Is the a direct link between risk factor (A) and disease (D)?\nD\nA\n- Does the risk factor's (!) effect on disease (D) depend on an\nintermediate step (B)?\nD\nA\nB\n- To test:\n- A is associated with B and D\n- B is associated with D\n- A is not associated with D when controlling for\n\n- Note: A MUST come before B temporally\nB\nD\nG\nX\nFactor A\nFactor B\nDisease D\n\n(2) Causal Pathway Models\n- In reality its a little of both; !'s affect on D is partially\nmediated through B\nA\nD\nB\n- To test:\n- A is associated with B and D\n- B is associated with D\n- The effect size of A on D is decreased when con\n\n- Note: A MUST come before B temporally\n\n- Example: CR1 effect on cognitive decline\ntrolling for B\nA\nFactor A\n\nFactor B\n\nDisease D\nD\nB\n\n(3) Interaction Models\n- Factor B's effect on D is different depending on value for factor !\nB\n(A = Aa)\nB\n(A = AA)\nD\nB\n(A = aa)\n- To test:\n- A + B + A*B D, if estimate for A*B is significant then\n- Stratify by levels of A\n\n- Example:\n- ! drug's effect is different depending on genotype\n- More to come<\n\nGene\nlocus\nreference\nPublished\nAD\nAD\nNP\nBIN1\nCD2AP\nCD33\nrs744373\nrs9349407\nrs3865444\nSeshadri 2010\nNaj 2011/Hollingsworth 2011\nNaj 2011/Hollingsworth 2012\n1.6x10-11\n8.6x10-9\n1.6x10-9\n0.204\n0.445\n0.133\n0.480\n0.221\n0.123\nABCA7\nrs3764650\nHollingsworth 2010\n5.0x10-21\n0.747\n0.187\nAPOE\nAny ε4\n1.2x10-13\n1.8x10-23\nCLU\nrs11136000\nLambert 2009/Harold 2009\n7.5x10-9\n0.762\n0.649\nCR1\nrs6656401\nLambert 2009\n3.7x10-9\n0.0009\n0.057\nEPHA1\nrs11767557\nNaj 2011/Hollingsworth 2011\n6.0x10-10\n0.562\n0.391\nMS4A4A\nrs4938933\nNaj 2011\n1.7x10-9\n0.792\n0.567\nMS4A6A\nrs610932\nHollingsworth 2010\n1.2x10-16\n0.534\n0.820\nMTHFD1L\nrs11754661\nNaj 2010\n1.9x10-10\n0.126\n0.934\nPICALM\nrs3851179\nHarold 2009\n1.9x10-8\n0.382\n0.171\nApplication to 12 AD GWAS loci\n\nTangles\n\nCR1: Causal pathway model\nRisk Factors\nPathology\nClinical\nDisease\nAlzheimer's\ndisease\nGenetic\nCR1\nCognitive\nDecline\nAD specific\nNeuritic Plaque\nNeurofibulary\n?\n- CR1 first associated with AD in 2009\n- Original associated variant is in an intron, no clear function\n- Unclear how CR1 locus influences AD susceptibility mechanistically\n-\n\nQuestions:\n- Is the effect only on AD?\n- Is there a broader effect on cognitive decline?\n- Is there an association with AD pathology?\n- Does it go through pathology to have an effect of cognitive decline?\n\nCR1 (rs6656401)\nCR1 Pathology\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\nNeuritic Plaque\nNeurofibillary Tangles\nTT\nAT/AA (risk allele)\nCR1 Global Cognitive\nDecline\np=0.0008\np=0.008\np=0.10\nPathology Global Cognitive Decline\np < 0.0001\ntime\n\nEpigenome\n\nGenetic + Epigenetic variation in !lzheimer's\nRelate to genotype and AD variation\n723 AD patients & controls\nMethylation variation in\nGenome\nmeQTL\nPhenotype\nClassification\nEpigenome\nMWAS\n(c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\nMethylation >> SNPs\nEstimate causal M roles: regression\nEnhancers >> promoters\nof meQTL effects reduces MD\n(c) source unknown. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\n- Calculating functional enrichments for GWAS loci\n3. Molecular epidemiology\n- meQTLs: Genotype-Epigenome association (cis-/trans-)\n- EWAS: Epigenome-Disease association\n4. Resolving Causality\n- Statistical: Mendelian Randomization\n- Application to genotype + methylation in AD\n5. Systems Genomics and Epigenomics of disease\n- Beyond single loci: polygenic risk prediction models\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nBeyond top-scoring hits:\n1000s of variants of weak effect\ncluster in cell type specific enhancers\n\nRank-based functional testing of weak associations\nEnrichment peaks at 10,000s of SNPs\ndown the rank list, even after LD pruning!\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- Rank all SNPs based on GWAS signal strength\n- Functional enrichment for cell types and states\n\nWeak-effect T1D hits in 50k T-cell enhancers\nenhancers\nCD4+ T-cells\nT-cells\nB-cells\nOther cell types\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- LD-pruning (CEU r2>.2): 50k 41k independ. loci\n\nCell type specificity stronger for enhancers\nenhancers\npromoters\ntranscribed\nCD4+ T-cells\nT-cells\nB-cells\nOther cell types\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- T/B-cells also enriched for promoters, transcribed\n- Enhancer enrichment much more cell type specific\n\nT1D/RA-enriched enhancers spread across genome\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw. mit.edu/help/faq-fair-use/.\n- High concentration of loci in MHC, high overlap\n- Yet: many distinct regions, 1000s of distinct loci\n\nImplications for genetic predisposition:\npolygenic models for risk prediction\n\n1:\n\nBasic setup of polygenic risk prediction studies\nCase-control cohort w/\ngenotype + phenotype\nTraining cohort\nTesting cohort\nSelection of SNPs\nEstimation of effects\nRanking\nApply predictor\nEvaluate accuracy\nApply predictor w/\nestimated confidence\nTarget cohort:\ngenotyped individuals\n(no phenotypes)\n(power matters)\n(power matters)\n(power limited to one\nindividual at a time)\n- Applications 1 (testing cohort)\n- Understand total heritability captured in common variants\n- Understand disease \"architecture\": number of SNPs\n- Recognize functional classes associated with weak genetic associations\n- Applications 2:\n2 (new individuals)\n- Provide health recommendations at the individual level\n- Prioritize high-risk individuals for subsequent testing at population level\n\nHow many SNPs to include in model?\n\nscore\nc\nni\nge\nly\npo\nhe\nof t\nue\n-val\nP\ncted\npe\nex\nDudridge PLoS Genetics 2013\npi0:Proportion of markers with no effect Purcell Nature 2009\nSchizophrenia risk prediction\n'only 5% matter'\n'only 10% matter'\n(but still can't tell\nWhich ones until 'all matter'\nFull rank list)\ninclusion threshold\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n- It depends on:\n- Architecture: Fraction of SNPs that are estimated to be functional\n- Power: Number of individuals in cohort, i.e. ability to rank correctly\nIt only peaks at 5% (≈1-pi0) when sufficient power to rank\n- Large fraction of associated markers are hidden within non-significant SNPs\n-\n- For pi0=0.90, still need to include all SNPs to maximize predictive power\n\nApplication to pleiotropy and common risk\nTrait 1 (schizophrenia)\nCase-control cohort w/\ngenotype + phenotype\nSelection of SNPs\nEstimation of effects\nRanking\nApply predictor\nEvaluate accuracy\nTrait 2 (bipolar disorder)\nCase-control cohort w/\ngenotype + phenotype\n- Ability to assess common genetic risk\nAre the highly-ranked SNPs for one study relevant to a different study?\nIs there a shared genetic architecture between seemingly unrelated traits?\nirst use showed schizophrenia and bipolar disorder common risk\nSchizophrenia-ranked SNPs in one cohort<\n< are predictive of bipolar disorder diagnosis\n< but not predictive of unrelated (cardiovascular) traits\n-\n-\n- F\n-\n-\n-\n\nImportant points/caveats for risk prediction\n- Always limited by genetic component\n- Environment, random effects play big role for most traits\n- Mendelian=deterministic vs. common variants=prob.ic\n- Only a first screen for individuals at risk\n- Limited by discovery power\n- Cohort size limits discriminative power and ranking ability\n- Limited by genotyped SNPvs vs. all SNPs\n- Selection pushes fitness-reducing variants to lower freq\n- Genotyped SNPs selected to be common\n- Even if SNPs are correctly id\nentified, their effects are not\n- Winner's curse: over-estimate above-threshold true effect\n- Training and testing cohort non-independence\n- Relatives, cryptic relatedness, population stratification inflate est.\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\n- Calculating functional enrichments for GWAS loci\n3. Molecular epidemiology\n- meQTLs: Genotype-Epigenome association (cis-/trans-)\n- EWAS: Epigenome-Disease association\n4. Resolving Causality\n- Statistical: Mendelian Randomization\n- Application to genotype + methylation in AD\n5. Systems Genomics and Epigenomics of disease\n- Beyond single loci: polygenic risk prediction models\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nThis talk: From loci to mechanisms\nBuilding a reference map of the regulatory genome\nEnhancers\nPromoters\nTranscribed\nRepressed\nRegions:\nEnhancers, promoters, transcribed, repressed\nCell types:\nPredict tissues and cell types of epigenomic act\n\nivity\nTarget genes: Link variants to their target genes using eQTLs, activity, Hi-C\nNucleotides: Regulatory consequence of mutation: Conservation, PWMs\nRegulators:\nUpstream regulators whose activity is disrupted by mutation\nApplication to GWAS, hidden heritability, and Cancer\nGWAS\nCATGCCTG\n- 93% top hits non-coding Mechanism? Cell type?\nhits\nCGTGTCTA\n- Lie in haplotype blocks\nCausal variant(s)?\n'Hidden'\n\nCATGCCTG\n- Many variants, small effects\nPathway-level burden/load\nheritability\nCGTGTCTA\n- Many false positives\nPrioritize w/ regulatory annotations\nCancer\n-\ns of function\nCATGCCTG\nLos\nProtein-coding variants, convergence\nmutations\nCATCCCTG\n- Gain of function Regulatory variants, heterogeneity\n\nCharacterizing sub-threshold variants in heart arrhythmia\n(c) source unknown. All rights reserved.This\ncontent is excluded from our Creative\nCommons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\nFocus on sub-threshold variants\n(e.g. rs1743292 P=10-4.2)\nTrait: QRS/QT interval\n\n(1) Large cohorts, (2) many known hits\n\n(3) well-characterized tissue drivers\nFrom Arking, D. E., Pulit, S. L., Crotti, L., Harst, P. V., Munroe, P. B.,\nKoopmann, T. T., . . . Newton-Cheh, C. (2014). Genetic association\nstudy of QT interval highlights role for calcium myocardial repolarization.\nNature Genetics Nat Genet, 46(8), 826-836. Used with permission.\n\nEnhancers overlapping GWAS loci share functional properties\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nTrain machine learning model to prioritize sub-threshold loci\n\nFunctional evidence for sub-threshold target genes\nZebrafish phenotypes\nHuman genetics\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nMouse phenotypes\n\nExperimental validation of 11 sub-threshold loci\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n9 of 11 tested loci show allelic activity, chromatin interactions\n\nFunctional evidence for rs1743292 causality (P=10-4.2)\nEnhancer 4C links to target gene promoters\nHeart enhancer activity\nMotif disruption\nAllelic DNase in multiple individuals\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nAllelic enha-\nncer activity\n\nTarget gene impact on heart conduction\nOptical voltage mapping\nzebrafish embryo hearts\nvoltage-sensitive fluorescent dye\nventricle\natrium\ntransmembrane voltage\n(ventricle)\n(c) source unknown. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\nDetection and validation of a new cardiac locus\n\nWhat would we need to discover rs1743292 without epigenomics?\nrs1743292\nMinor allele frequency: 0.134\nEffect size: -0.5773 +/- 0.17 msec\nWith 68,900 individuals: 12.8% power to discover at p<5x10-8\n- rs1743292 has similar effect sizes as many genome-wide significant variants\n- Many GWAS variants discovered due to winner's curse: often only have 5-\n20% power to discover\n- Combining epigenomics and GWAS can:\n1. Confirm existing GWAS loci are real\n2. Discover new sub-threshold loci with weak effect sizes, low power\nTo reach 80% power to discover rs1743292 at p<5x10-8 ,\nwe need 146,700 individuals!\n\nGoal: Personalized and Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\nenetic Epidemiology:\nGenetic basis: GWAS and screening\nInterpreting GWAS with functional genomics\nCalculating functional enrichments for GWAS loci\nolecular epidemiology\nmeQTLs: Genotype-Epigenome association (cis-/trans-)\nEWAS: Epigenome-Disease association\nesolving Causality\nStatistical: Mendelian Randomization\nApplication to genotype + methylation in AD\nystems Genomics and Epigenomics of disease\nBeyond single loci: polygenic risk prediction models\nSub-threshold loci and somatic heterogeneity in cancer\n2. G\n-\n-\n-\n3. M\n-\n-\n4. R\n-\n-\n5. S\n-\n-\n\nThis talk: From loci to mechanisms\nBuilding a reference map of the regulatory genome\nEnhancers\nPromoters\nTranscribed\nRepressed\nRegions:\nEnhancers, promoters, transcribed, repressed\nCell types:\nPredict tissues and cell types of epigenomic act\n\nivity\nTarget genes: Link variants to their target genes using eQTLs, activity, Hi-C\nNucleotides: Regulatory consequence of mutation: Conservation, PWMs\nRegulators:\nUpstream regulators whose activity is disrupted by mutation\nApplication to GWAS, hidden heritability, and Cancer\nGWAS\nCATGCCTG\n- 93% top hits non-coding Mechanism? Cell type?\nhits\nCGTGTCTA\n- Lie in haplotype blocks\nCausal variant(s)?\n'Hidden'\nCATGCCTG\n- Many variants, small effects Pathway-level burden/load\nheritability\nCGTGTCTA\n- Many false positives\nPrioritize w/ regulatory annotations\nCancer\n\nfunction\nCATGCCTG\n- Loss of\nProtein-coding variants, convergence\nmutations\nCATCCCTG\n- Gain of function Regulatory variants, heterogeneity\n\nRegulatory convergence of dispersed driver mutations\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nCommon mutations in regulatory plexus of each gene\nRichard Sallari 103\n\nCancer genes are more likely to be up-regulated\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nRichard Sallari 104\n\nDysregulated genes show dispersed non-coding mutations\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nDysregulated genes are enriched for plexus mutations at all distances.\nRichard Sallari 105\n\nNon-coding mutations enriched in promoters /\nenhancers active in other cell types\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nDisruptive mutations in 'low' elements are\nenriched in enhancers and promoters in other tissues\nRichard Sallari 106\n\nStatistical model for excess of rare/somatic variants\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n-Correct for region-, state-, tumor-specific rate variation\n\nConvergence in immune, signaling, mitoch. functions\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n-Pathway-level convergence, hierarchical model\n\nNon-coding drivers of prostate cancer dysregulation\nRegulatory mutations reveal\nConvergence in immune, signaling,\nnew cancer driver genes\nmitochondrial functions\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\nConvergence in inositol phosphate metabolism\nPLCB4 overexpression in PC3 prostate cancer\nadjacent to PTEN, PIK3CA, known cancer genes reduces Erk/Akt activity, synergistic with PTEN\n\nPersonal genomics tomorrow:\nAlready 100,000s of complete genomes\n- Health, disease, quantitative traits:\n- Genomics regions disease mechanism, drug targets\n- Protein-coding cracking regulatory code, variation\n- Single genes systems, gene interactions, pathways\n- Human ancestry:\n- Resolve all of human ancestral relationships\n- Complete history of all migrations, selective events\n- Resolve common inheritance vs. trait association\n- What's missing is the computation\n- New algorithms, machine learning, dimensionality reduction\n- Individualized treatment from 1000s genes, genome\n- Understand missing heritability\n- Reveal co-evolution between genes/elements\n- Correct for modulating effects in GWAS\n\nChallenge ahead: From research to clinic\n1. Systematic medical genotyping / sequencing\n- Currently a curiosity, future: medical practice\n2. Systematic medical molecular profiling\n- Functional genomics in relevant cell types\n3. Systematic perturbation studies for validation\n- 1000s of regulatory predictions x 100s cell types\n4. Systematic repurposing of approved drugs\n- Systems-biology view of drug response\n5. Genomics of drug response in cli\n\nnical trials\n- Personalized drug prescription and combinations\n6. Partnerships: academia, industry, hospitals\n- Interdisciplinary training in each of the instituttions\n\nSummary: Personalized & Predictive Medicine\n1. Intro to Epidemiology: basis of human disease\n2. Genetic Epidemiology:\n- Genetic basis: GWAS and screening\n- Interpreting GWAS with functional genomics\n- Calculating functional enrichments for GWAS loci\n3. Molecular epidemiology\n- meQTLs: Genotype-Epigenome association (cis-/trans-)\n- EWAS: Epigenome-Disease association\n4. Resolving Causality\n- Statistical: Mendelian Randomization\n- Application to genotype + methylation in AD\n5. Systems Genomics and Epigenomics of disease\n- Beyond single loci: polygenic risk prediction models\n- Sub-threshold loci and somatic heterogeneity in cancer\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 3 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/318809f1420dc08eac795206c14bbebd_MIT6_047F15_Lecture03.pdf",
      "content": "Lecture 3\nSequence Alignment II\nDatabase search\nGlobal vs. Local alignment\nExact string matching and Karp-Rabin\nDatabase search and BLAST\nDeterministic linear-time string matching\n6.047/6.878/HST.507\nComputational Biology: Genomes, Networks, Evolution\n\nModule 1: Aligning and modeling genomes\n- Module 1: Computational foundations\n- Dynamic programming: exploring exponential spaces in poly-time\n- Introduce Hidden Markov Models (HMMs): Central tool in CS\n- HMM algorithms: Decoding, evaluation, parsing, likelihood, scoring\n- This week: Sequence alignment / comparative genomics\n- Local/global alignment: infer nucleotide-level evolutionary events\n- Database search: scan for regions that may have common ancestry\n- Next week: Modeling genomes / exon / CpG island finding\n- Modeling class of elements, recognizing members of a class\n- Application to gene finding, conservation islands, CpG islands\n\nRemember Lecture 2\nSequence alignment\nand\nDynamic programming\n\nDuality: seq. alignment path through the matrix\nS1[1..i]\ni\nS1[i..n]\n\nS2[1..j]\nj\nS\n\nS2[ j..m]\nBest alignment Best path\nthrough the matrix\nA C G T C A T C A\nT A\nG T G\nT C A\nA C G T C A T C A\nT\nA\nG\nT\nG\nT\nC\nA\nS1\nS2\nA\nG\nT\nC/G\nT\nC\nA\nM[i,j] stores max score of prefix\nalignment of S1[1..i] and S2[1..j]\nAlignments\nPaths\nPrefix alignmt\nscore M[i,j]\n\nComputing alignments recursively: M[i,j]=F(smaller)\n- Local update rules, only look at neighboring cells:\n- Compute next alignment based on previous alignment\n- Just like Fibonacci numbers: F[i] = F[i-1] + F[i-2]\n- Table lookup avoids repeated computation\n- Computing the score of a cell from smaller neighbors\n\nM( i-1, j ) - gap\n- M(i,j) = max{ M( i-1, j-1) + score }\n\nM( i , j-1) - gap\n- Only three possibilities for extending by one nucleotide:\na gap in one species, a gap in the other, a (mis)match\n- Compute scores for prefixes of increasing length\n- Start with prefixes of length 1, extend by one each time,\nuntil all prefixes have been computed\n- When you reach bottom right, alignment score of\nS1[1..m] and S2[1..n] is alignment of full S1 and full S2\n- (Can then trace back to construct optimal path to it)\n(i,j)\ni-1\ni\nj-1\nj\n\nDynamic Programming for sequence alignment\n-\nSetting up dynamic programming\n1. Find 'matrix' parameterization\n-\nPrefix parameterization. Score(S1[1..i],S2[1..j]) M(i,j)\n-\n(i,j) only prefixes vs. (i,j,k,l) all substrings simpler 2-d matrix\n2. Make sure sub-problem space is finite! (not exponential)\n-\nIt's just n2, quadratic (which is polynomial, not exponential)\n3. Traversal order: sub-results ready when you need them\n\n4. Recursion formula: larger problems = Func(subparts)\n- Need formula for computing M[i,j] as function of previous results\n- Single increment at a time, only look at M[i-1,j], M[i,j-1], M[i-1,j-1]\ncorresponding to 3 options: gap in S1, gap in S2, char in both\n- Score in each case depends on gap/match/mismatch penalties\n5. Remember choice: F() typically includes min() or max()\n-\nRemember which of three cells (top,left,diag) led to maximum\n-\nTrace-back from max score to identify path leading to it\nCols\nLR\nRows\ntopbot\nDiags\ntopRbotL\n\nAlgorithmic variations (save time and/or space)\n-\nSave time: Bounded-space computation\n- Space: O(k*m)\n- Time: O(k*m), where k = radius explored\n- Heuristic\n- Not guaranteed optimal answer\n- Works very well in practice\n- Practical interest\n\n-\nSave space: Linear-space computation\n- Save only one col / row / diag at a time\n- Computes optimal score easily\n- Theoretical interest\n- Effective running time slower\n- Optimal answer guaranteed\n- Recursive call modification allows traceback\n\nAGTGCCCTGGAACCCTGACGGTGGGTCACAAAACTTCTGGA\nAGTGACCTGGGAAGACCCTGACCCTGGGTCACAAAACTC\nAGTGCCCTGGAACCCTGACGGTGGGTCACAAAACTTCTGGA\nAGTGACCTGGGAAGACCCTGACCCTGGGTCACAAAACTC\n\nFinding optimal path using only linear space\nMax F(M/2, k) + Fr(M/2, N-k)\nk*\nk*\nFr(M/2, N-k)\nF(M/2, k)\nN-k*\nM/2\nM/2\nk*\nIterate procedure in corner quadrants\nN-k*\nM/2\nM/2\nk*\nTotal cost MN(1+1⁄2+1⁄4+1⁄8+...)≤2MN\nIncoming scores Outgoing scores\nSum the two best transition\n\nGenome alignment in an excel spreadsheet\n\nK15\nK34\nK53\nAD53\nAD34\nAD15\nK15\nK34\nK53\nAD53\nAD34\nAD15\nLocal score of matching\ncharacters S1[i] and S2[j]\nMax alignment score of\naligning prefix S1[1..i]\nand prefix S2[1..j]\nIs the max alignment score\ncoming from the top (\"|\"),\nfrom the left (\"--\") or from\nthe diagonal up (\"\\\")\n(show all of them, cuz we can)\nIs the [i,j] part of an optimal\npath? (i.e. are chars S1[i]\nand S2[j] aligned to each\nother in an optimal path)\n(also count number of\noptimal paths/alignment\nthrough [i.j], cuz we can)\nConstruct the optimal alignment for sequence S1 by\nadding in characters or gaps to increasingly large suffixes\n(and arbitrarily choose one path when multiple using nested if's)\nConstruct the optimal alignment for sequence S2 similarly to S1\nGenome alignment\nin an excel\nspreadsheet\n\nToday's Goal: Diving deeper into alignments\n1.\nGlobal alignment vs. Local alignment\n-\nVariations on initialization, termination, update rule\n-\nVarying gap penalties, algorithmic speedups\n2. Linear-time exact string matching (expected)\n-\nKarp-Rabin algorithm and semi-numerical methods\n-\nHash functions and randomized algorithms\n3. The BLAST algorithm and inexact matching\n-\nHashing with neighborhood search\n-\nTwo-hit blast and hashing with combs\n4. Deterministic linear-time exact string matching\n-\nKey insight: gather more info from each comparison\n-\nPre-processing, Z-algorithm, Boyer-More, KMP\n\nToday's Goal: Diving deeper into alignments\n1.\nGlobal alignment vs. Local alignment\n-\nVariations on initialization, termination, update rule\n-\nVarying gap penalties, algorithmic speedups\n2.\nLinear-time exact string matching (expected)\n-\nKarp-Rabin algorithm and semi-numerical methods\n-\nHash functions and randomized algorithms\n3.\nThe BLAST algorithm and inexact matching\n-\nHashing with neighborhood search\n-\nTwo-hit blast and hashing with combs\n4.\nProbabilistic foundations of sequence alignment\n-\nMismatch penalties, BLOSUM and PAM matrices\n-\nStatistical significance of an alignment score\n\nIntro to Local Alignments\n-\nStatement of the problem\n- A local alignment of strings s and t\n\nis an alignment of a substring of s\n\nwith a substring of t\n-\nWhy local alignments?\n- Small domains of a gene may be only conserved portions\n- Looking for a small gene in a large chromosome (search)\n- Large segments often undergo rearrangements\nt\ns\nAGTGCCCTGGAACCCTGACGGTGGGTCACAAAACTTCTGGA\nAGTGACCTGGGAAGACCCTGACCCTGGGTCACAAAACTC\nGlobal alignment\nAGTGCCCTGGAACCCTGACGGTGGGTCACAAAACTTCTGGA\nAGTGACCTGGGAAGACCCTGACCCTGGGTCACAAAACTC\nLocal alignment\nB\nD\nA\nC\nB\nD\nA\nC\nA\nB\nC\nD\nA\nB\nC\nD\n\nGlobal Alignment\nvs. Local alignment\nInitialization:\nF(0, 0) = 0\n\nIteration:\n\nF(i - 1, j) - d\nF(i, j) = max\nF(i, j - 1) - d\n\nF(i - 1, j - 1) + s(xi, yj)\n\nTermination:\nBottom right\n\nInitialization:\nF(0, j) = F(i, 0) = 0\n\nIteration:\n\nF(i, j) = max\nF(i - 1, j) - d\n\nF(i, j - 1) - d\n\nF(i - 1, j - 1) + s(xi, yj)\n\nTermination:\nAnywhere\nNeedleman-Wunsch algorithm\nSmith-Waterman algorithm\n\nMore variations on the theme: semi-global alignment\n- Sequence alignment variations\nGlobal\nLocal\nSemi-global\nInitialization\nIteration:max\nTermination\nTop left\nTop row/left col.\nTop row or\nleft column\nAnywhere\nBottom right\nF(i - 1, j) - d\nF(i, j - 1) - d\nF(i - 1, j - 1) + s(xi, yj)\nF(i - 1, j) - d\nF(i, j - 1) - d\nF(i - 1, j - 1) + s(xi, yj)\nF(i - 1, j) - d\nF(i, j - 1) - d\nF(i - 1, j - 1) + s(xi, yj)\nBottom row\nor right column\nComplete alignment\nStretches of similarity\nNo end-gap penalty\n\nSequence alignment with generalized gap penalties\nInitialization:\nsame\n\nIteration:\n\nF(i-1, j-1) + s(xi, yj)\nF(i, j)\n= max maxk=0...i-1F(k,j) - (i-k)\n\nmaxk=0...j-1F(i,k) - (j-k)\n\nTermination:\nsame\n\nF(i,j)\nRunning Time: O(N2M) (cubic)\nSpace:\nO(NM)\nDo we have to be\nso general?\n-\nImplementing a generalized gap penalty function F(gap_length)\n\nAlgorithmic trade-offs of varying gap penalty functions\n\nLinear gap penalty: w(k) = k*p\n- State: Current index tells if in a gap or not\n- Achievable using quadratic algorithm (even w/ linear space)\n\nQuadratic: w(k) = p+q*k+rk2.\n- State: needs to encode the length of the gap, which can be O(n)\n- To encode it we need O(log n) bits of information. Not feasible\n\nAffine gap penalty: w(k) = p + q*k, where q<p\n- State: add binary value for each sequence: starting a gap or not\n- Implementation: add second matrix for already-in-gap (recitation)\n\nLength (mod 3) gap penalty for protein-coding regions\n- Gaps of length divisible by 3 are penalized less: conserve frame\n- This is feasible, but requires more possible states\n- Possible states are: starting, mod 3=1, mod 3=2, mod 3=0\n(n)\n(n)\n(n)\nd\ne\n(n)\n\nToday's Goal: Diving deeper into alignments\n1. Global alignment vs. Local alignment\n-\nVariations on initialization, termination, update rule\n-\nVarying gap penalties, algorithmic speedups\n2. Linear-time exact string matching (expected)\n-\nKarp-Rabin algorithm and semi-numerical methods\n-\nHash functions and randomized algorithms\n3. The BLAST algorithm and inexact matching\n-\nHashing with neighborhood search\n-\nTwo-hit blast and hashing with combs\n4. Deterministic linear-time exact string matching\n-\nKey insight: gather more info from each comparison\n-\nPre-processing, Z-algorithm, Boyer-More, KMP\n\nLinear-time string matching\n- When looking for exact matches of a pattern (no gaps)\n\n- Karp-Rabin algorithm (probabilistic linear time):\n- Interpret String numerically\n- Start with 'broken' version of the algorithm\n- Progressively fix it to make it work\n- Deterministicc linear-time solutions exist (not this term):\n- Z-algorithm / fundamental pre-processing, Gusfield\n- Boyer-Moore and Knuth-Morris-Pratt algorithms\nare earliest instantiations, similar in spirit\n- Suffix trees: beautiful algorithms, many different variations\nand applications, limited use in CompBio\n- Suffix arrays: practical variation, Gene Myers\n\nKarp-Rabin algorithm\n-\nKey idea:\n- Interpret strings as numbers: fast comparison\n\n.\n2 3 5 9 0 2 3 1 4 1 5 2 6 7 3 9 9 2 1\nT=\n3 1 4 1 5\nx = 31,415\nP=\ny1 = 23,590\ny2 = 35,902\ncompute x\nfor i in [1..n]:\n\ncompute yi\n\nif x == yi:\n\nprint \"match at S[i]\"\ny3 = 59,023\ny7 = 31,415\nx=y7 P=T[7..11]\n(this does not actually work)\n\ncompute x (mod p)\nfor i in [1..n]:\n\ncompute yi (mod p) (using yi-1)\n\nif x == yi:\n\nif P==S[i..]:\n\nprint \"match at S[i]\"\n\nelse:\n\n(spurious hit)\nKarp-Rabin algorithm\n-\nKey idea:\n- Interpret strings as numbers: fast comparison\n-\nTo make it work:\n(a) Compute next number based on previous one O(1)\n(b) Hashing (mod p) keep the numbers small O(1)\n(c) Deal with spurious hits due to hashing collisions\n2 3 5 9 0 2 3 1 4 1 5 2 6 7 3 9 9 2 1\nT=\n3 1 4 1 5\nx = 31,415\nP=\ny1 = 23,590\ny2 = 35,902\ncompute x (mod p)\nfor i in [1..n]:\n\ncompute yi (using yi-1)\n\nif x == yi:\n\nif P==S[i..]:\n\nprint \"match at S[i]\"\n\nelse:\n\n(spurious hit)\ncompute x (mod p)\nfor i in [1..n]:\n\ncompute yi (mod p) (using yi-1)\n\nif x == yi:\n\nprint \"match at S[i]\"\n\ny3 = 59,023\ny7 = 31,415\n(this actually works)\ncompute x (mod p)\nfor i in [1..n]:\n\ncompute yi (mod p) (using yi-1)\n\nif x == yi:\n\nif P==S[i..]:\n\nprint \"match at S[i]\"\n\nelse:\n\n(spurious hit)\n\n31,415\n14,152\n31,415\n14,152\n31,415\n14,152\n(a) Computing ts+1 based on ts in constant time\n3 1 4 1 5 2\n14,152 = (31,415 - 3 * 10,000) * 10 + 2\nold high-order bit\nleft shift\nnew low-order\ndigit\n-\nMiddle digits of the number are already computed\n\nShift them to the left\n-\nRemove the high-order bit\n-\nAdd the low-order bit\n14,152 =? function (31,415)\n-\nGeneral case:\n\nts=T[s+1]2m-1+T[s+2]2m-2+...+T[s+m]20\n\nts+1=T[s+2]2m-1+T[s+3]2m-2+...+T[s+m+1]20\n\n14,152 = (31,415 - 3 * 10,000) * 10 + 2 (mod 13)\n\n= (7-3*3)*10+2 (mod 13)\n= 8 (mod 13)\n(b) Dealing with long numbers in constant time\n3 1 4 1 5 2\n7 8\nold high-order bit\nleft shift\nnew low-order\ndigit\nProblem:\n- To get O(n) time, need to perform each operation in O(1) time\n- But if arguments are m-bit long (2m range), can take O(m) time\n- Need to reduce number range to something more manageable\nSolution:\n- Hashing: Mapping keys k from large universe U (of strings/numbers)\n\ninto the 'hash' of each key h(k), in smaller space [1..m]\n- Many hash functions possible, w/ theoretical & practical properties:\n- Reproducibility: x=yh(x)=h(y) (hash of x always the same)\n- Uniform output distrib: x=yP(h(x)=h(y))=1/m, for any input dist\n14,152 = (31,415 - 3 * 10,000) * 10 + 2\n\nNew problem: Collisions\n\n(c) Dealing with collisions, due to hashing\n- Consequences of (mod p) 'hashing'\n- Good: Enable fast computation (use small numbers)\n- Bad: Leads to spurious hits (collisions)\n- Dealing with the bad:\n1.\nVerify that a hit correspond to valid match\n\nre-compute equality for entire string (not just hash)\n2.\nAvoid worst-case behavior of many collisions w/ bad m\n\nChoose random m\n- Algorithm and its analysis becomes more complex:\n1.\nCompute expected run time, include expected cost of verification\n2.\nShow probability of spurious hits is small, expected run time is linear\n2 3 5 9 0 2 3 1 4 1 5 2 6 7 3 9 9 2 1\nT=\n7 8 4 5 10 11 7 9 11\n8 9 3 11 0 1\nspurious hit\nvalid match\n\ncompute x (mod p)\nfor i in [1..n]:\n\ncompute yi (mod p) (using yi-1)\n\nif x == yi:\n\nif P==S[i..]:\n\nprint \"match at S[i]\"\n\nelse:\n\n(spurious hit)\nKarp-Rabin algorithm: Putting it all together\n-\nKey idea: Semi-numerical computation\n- Idea: Interpret strings as numbers => fast comparison\n\n(other semi-numerical methods: Fast Fourier Transform, Shift-And)\n-\nTo make it work:\n(a) Compute next number based on previous one O(1)\n(b) Hashing (mod p) keep the numbers small O(1)\n(c) Dealing with collisions Randomized p, expected run time O(1) exp\n2 3 5 9 0 2 3 1 4 1 5 2 6 7 3 9 9 2 1\nT=\n3 1 4 1 5\nx = 31,415\nP=\ny1 = 23,590\ny2 = 35,902\ny3 = 59,023\ny7 = 31,415\n(this actually works)\n\nToday's Goal: Diving deeper into alignments\n1. Global alignment vs. Local alignment\n-\nNeedleman-Wunsch and Smith-Waterman\n-\nVarying gap penalties and algorithmic speedups\n2. Linear-time exact string matching (expected)\n-\nKarp-Rabin algorithm and semi-numerical methods\n-\nHash functions and randomized algorithms\n3. The BLAST algorithm and inexact matching\n-\nHashing with neighborhood search\n-\nTwo-hit blast and hashing with combs\n4. Deterministic linear-time exact string matching\n-\nKey insight: gather more info from each comparison\n-\nPre-processing, Z-algorithm, Boyer-More, KMP\n\nSequence Alignment vs. Sequence Database Search\n- Sequence Alignment\n- Assumes sequences have some common ancestry\n- Finding the \"right\" alignment between two sequences\n- Evolutionary interpretation: min # events, min cost\n- Sequence Database Search\n- Given a query (new seq), and target (many old seqs),\nask: which sequences (if any) are related to the query\n- Individual alignments need not be perfect: Once initial\nmatches are reported, we can fine-tune them later\n- Query must be very fast for a new sequence\n- Most sequences will be completely unrelated to query\n- Exploit distinct nature of database search problem\n\nSpeeding up your searches in dB setting\n- Exploit nature of the problem (many spurious hits)\n- If you're going to reject any match with idperc <= 90,\nthen why bother even looking at sequences which\ndon't have a stretch of 10 nucleotides in a row.\n- Pre-screen sequences for common long stretches\n- Put the speed where you need it (pre-processing)\n- Pre-processing the database is off-line.\n- Once the query arrives, must act fast\n- Solution: content-based indexing and BLAST\n- Example: index 10-mers.\n- Only one 10-mer in 410 will match, one in a million\n(even with 500 k-mers, only 1 in 2000 will match).\n- Additional speedups are possible\n\nBLAST\n- Two key insights:\n- Hashing:\n- Like Karp-Rabin, semi-numerical string matching\n- Neighborhood search:\n- Can find hits even when no exact k-mer matches\nBLAST citations per year\nPSI-BLAST & Gapped Blast\n\nBlast Algorithm Overview\n-\nReceive query\n1. Split query into overlapping words of length W\n2. Find neighborhood words for each word until threshold T\n3. Look in table where these neighbor words occur: seeds S\n4. Extend seeds S until score drops off under X\n-\nReport significance and alignment of each match\nPMG\nW-mer\nDatabase\n2. Expand word\nneighborhood\n3. Search database for\nneighborhood matches\n1. Split query into words\n4. Extend each hit into alignment\nT\n\nWhy BLAST works(1): Pigeonhole and W-mers\n-\nPigeonholing mis-matches\n- Two sequences, each 9 amino-acids, with 7 identities\n- There is a stretch of 3 amino-acids perfectly conserved\n-\nIn general:\n- Sequence length: n\n- Identities: t\n- Can use W-mers for W= [n/(n-t+1)]\nRKI WGD PRS\nRKI VGD RRS\n- Pigeonhole principle\n- If you have 2 pigeons and 3 holes, there must be\nat least one hole with no pigeon\n\nExtensions to the basic algorithm\n-\nIdeas beyond W-mer indexing? Desirata:\n-\nFaster\n-\nBetter sensitivity (fewer false negatives)\n1) Filtering: Low complexity regions cause spurious hits\n-\nFilter out low complexity in your query\n-\nFilter most over-represented items in your database\n2) Two-hit BLAST\n-\nTwo smaller W-mers are more likely than one longer one\n-\nTherefore it's a more sensitive searching method to look for two hits\ninstead of one, with the same speed.\n-\nImproves sensitivity for any speed, speed for any sensitivity\n3) Beyond W-mers, hashing with non-consecutive k-mers (combs)\n-\nNext slide\n\nExtension 3: Combs and Random Projections\n-\nNo reason to use only consecutive symbols\n-\nInstead, we could use combs, e.g.,\nRGIKW R*IK* , RG**W, ...\n-\nIndexing same as for W-mers:\n- For each comb, store the list of positions in the database where it occurs\n- Perform lookups to answer the query\n-\nHow to choose the combs? At random\n- Random projections: Califano-Rigoutsos'93, Buhler'01, Indyk-Motwani'98\n- Choose the positions of * at random\n- Analyze false positives and false negatives\nKey idea:\n-\nAssume we select k positions, which do not\ncontain *, at random with replacement\n-\nWhat is the probability of a false negative ?\n- At most: 1-idperck\n- In our case: 1-(7/9)4 =0.63...\n-\nWhat is we repeat the process l times,\nindependently ?\n- Miss prob. = 0.63l\n- For l=5, it is less than 10%\n\nQuery: RKIWGDPRS\nDatab.: RKIVGDRRS\nQuery: *KI*G***S\nDatab.: *KI*G***S\nk=4\nPerformance Analysis:\n\nToday's Goal: Diving deeper into alignments\n1. Global alignment vs. Local alignment\n-\nNeedleman-Wunsch and Smith-Waterman\n-\nVarying gap penalties and algorithmic speedups\n2. Linear-time exact string matching (expected)\n-\nKarp-Rabin algorithm and semi-numerical methods\n-\nHash functions and randomized algorithms\n3. The BLAST algorithm and inexact matching\n-\nHashing with neighborhood search\n-\nTwo-hit blast and hashing with combs\n4. Deterministic linear-time exact string matching\n-\nKey insight: gather more info from each comparison\n-\nPre-processing, Z-algorithm, Boyer-More, KMP\n\nThe exact matching problem\n- Inputs:\n- a string P, called the pattern\n- a longer string T, called the text\n- Output:\n- Find all occurrences, if any, of pattern P in text T\n\n- Example\nb a a b a c a b a b a d\nT=\na b a\nP=\n\nBasic string definitions\n- A string S\n- Ordered list of characters\n- Written contiguously from left to write\n- A substring S[i..j]\n- all contiguous characters from i to j\n- Example: S[3..7] = abaxa\n- A prefix is a substring starting at 1\n- A suffix is a substring ending at |S|\n- |S| denotes the number of characters in string S\nb a a b a c a b a b a d\nS=\n\nThe naive string-matching algorithm\n- NAIVE STRING MATCHING\n- n length[T]\n- m length[P]\n- for shift 0 to n\n- do if P[1..m] == T[shift+1 .. shift+m]\n- then print \"Pattern occurs with shift\" shift\n\n- Where the test operation in line 4:\n- Tests each position in turn\n- If match, continue testing\n- else: stop\n- Running time ~ number of comparisons\nnumber of shifts (with one comparison each)\n+ number of successful character comparisons\nO(n)\nO(m)\nRunning time:\n\nComparisons made with naive algorithm\n- Worst case running time:\n- Test every position\n- P=aaaa, T=aaaaaaaaaaa\n- Best case running time:\n- Test only first position\n- P=bbbb, T=aaaaaaaaaaa\nb a a b a c a b\na b a\ns=0\nb a a b a c a b\na b a\ns=1\nb a a b a c a b\na b a\ns=2\nb a a b a c a b\na b a\ns=3\nb a a b a c a b\na b a\ns=4\nb a a b a c a b\na b a\ns=5\nCan we do better?\n\nKey insight: make bigger shifts!\n- If all characters in the pattern are the same:\n? ? ? ? ? ? ? ?\na a a a\n? ?\na a x ? ? ? ? ?\na a a a\n? ?\n? ? ? x ? ? ? ?\na a a a\n? ?\n? ? ? ? a a a a\na a a a\n? ?\n? ? ? ? ? ? a a\na a a a\na ?\nKnowledge of the\ninternal structure of P\nInformation gathered\nat every comparison\nNumber of comparisons: O(n)\n\nKey insight: make bigger shifts!\n- If all characters in the pattern are different:\n? ? ? ? ? ? ? ?\na b c d\n? ?\na b c d ? ? ? ?\na b c d\n? ?\n? ? ? ? ? ? ? ?\na b c d\n? ?\nNumber of comparisons:\n-At most n matching comparisons\n-At most n non-matching comparisons\n\nNumber of comparisons: O(n)\n\nKey insight: make bigger shifts!\n- Special case:\n- If all characters in the pattern are the same: O(n)\n- If all characters in the pattern are different: O(n)\n- General case:\n- Learn internal redundancy structure of the pattern\n- Pattern pre-processing step\n- Methods:\n- Fundamental pre-processing\n- Knuth-Morris-Pratt\n- Finite State Machine\n\nFundamental pre-processing\na a b c a a b x a a a\na a\na a\na a\na\na\na a b\na a b\na a\na a\n- Zi = length of longest prefix in common for S[i..] and S\n(Length of the longest prefix of S[i..] that's also a prefix of S)\nS =\nZ =\n- Learning the redundancy structure of a string S\n\nFundamental pre-processing\n- Learning the redundancy structure of a string S\na a b c a a b x a a a\nS =\nZ =\nZ-box = a a b c a a b x a a a\nr = a a b c a a b x a a a\nl =\na a b c a a b x a a a\na a b c a a b x a a a\nk\nleft\nright\nCan we compute Z, r, l\nin linear time O(|S|)?\nZ1\nZ2\nZ3\n...\nZk-1 Zk\n\nComputing Zk given Z1 .. Zk-1\na\nk'\n-\nCase 1: k is outside a Z-box: simply compute Zk\nk\nS\nl\nr\na\n-\nCase 2: k is inside a Z-box: Look up Zk'\nk\nS\nl\nr\nZk\nZk\nZk\nZk\nZk'\nCase 2a: Zk' < r-k\nCase 2b: Zk' >= r-k\n\nComputing Zk given Z1 .. Zk-1\na\nk'\nk\nS\nl\nr\na\nZk\nZk\nZk'\nCase 2a: Zk' < r-k\nCase 2b: Zk' >= r-k\nk'\nk\nS\nl\nr\nZk\nZk\nZk'\na\na\nSet Zk = Zk'\n? ? ?\n? ?\n?\nExplicitly compare starting at r+1\n\nPutting it all together\n- FUNDAMENTAL-PREPROCESSING(S):\nZ2,l,r = explicitly compare S[1..] with S[2..]\nfor k in 2..n:\nif k > r: Zk,l,r = explicitly compare S[1..] with S[k..]\nif k <= r:\nif Zk'<(r-k): Zk = Zk'\nelse:\nZk = explicitly compare S[r+1..] with S[(r-k)+1..]\nl = k\nr = l+Zk\n\nCorrectness of Z computation\nCase 1: k is outside a Z-box: explicitly compute Zk\nk\nS\nl\nr\nZk\nZk\na\nk'\nk\nS\nl\nr\na\nZk\nZk\nZk'\nCase 2a: Inside Z-box and Zk' < r-k: set Zk = Zk'\nCase 2b: Inside Z-box and Zk' >= r-k: explicitly compute starting at r+1\nk'\nk\nS\nl\nr\nZk\nZk\nZk'\na\na\n? ? ?\n? ?\n?\n\nRunning time of Z computation\nCase 1: k is outside a Z-box: explicitly compute Zk\nk\nS\nl\nr\nZk\nZk\na\nk'\nk\nS\nl\nr\na\nZk\nZk\nZk'\nCase 2a: Inside Z-box and Zk' < r-k: set Zk = Zk'\nCase 2b: Inside Z-box and Zk' >= r-k: explicitly compute starting at r+1\nk'\nk\nS\nl\nr\nZk\nZk\nZk'\na\na\n? ? ?\n? ?\n?\n\nWhat's so fundamental about Z?\na a b c a a b x a a a\na a b\na a b\nS =\nZ =\n- Learning the redundancy structure of a string S\n- Zi = fundamental property of internal redundancy structure\n- Most pre-processings can be expressed in terms of Z\n- Length of the longest prefix starting/ending at position i\n- Length of the longest suffix starting/ending at position i\n\nBack to string matching\n- Given the fundamental pre-processing of pattern P\n- Compare pattern P to text T\n- Shift P by larger intervals based on values of Z\n- Three algorithms based on these ideas\n- Knuth-Morris-Pratt algorithm\n- Boyer-Moore algorithm\n- Z algorithm\nb a a b a c a b a b a d\nT=\na b a\nP=\nb a\n\nKnuth-Morris-Pratt algorithm\n-\nPre-processing:\n-\nSpi(P) = length of longest proper suffix of P[1..i] that\nmatches a prefix of P\na b c f\na b c d e\nP=\na b c f\na b c d e\nT=\na b c f\na b c d e\nP=\na b c\na b c\n- No other than the right-hand-side of the Z-boxes\n\nKnuth-Morris-Pratt running time\n-\nNumber of comparisons bounded by characters in T\n-\nEvery comparison starts at text position where last\ncomparison ended\n-\nEvery shift results in at most one extra comparison\n-\nAt most |T| shifts Running time bounded by 2*|T|\na b c f\na b c d e\nP=\na b c f\na b c d e\nT=\n\nBoyer-Moore algorithm\n-\nThree fundamental ideas:\n1. Right-to-left comparison\n2. Alphabet-based shift rule\n3. Preprocessing-based shift rule\n-\nResults in:\n-\nVery good algorithm in practice\n-\nRule 2 results in large shifts and sub-linear time\n-\nfor larger alphabets, ex: English text\n-\nRule 3 ensures worst-case linear behavior\n-\neven in small alphabets, ex: DNA sequences\nb a a b x c a b a b a d\nT=\na b a\nP=\nb x\n\nThe Z algorithm\n- The Z algorithm\n- Concatenate P + '$' + T\n- Compute fundamental pre-processing O(m+n)\n- Report all starting positions i for which Zi=|P|\nb a a b a c a b a b a d\na b a\nP+T=\nb a $\n\nToday's Goal: Diving deeper into alignments\n1. Global alignment vs. Local alignment\n-\nNeedleman-Wunsch and Smith-Waterman\n-\nVarying gap penalties and algorithmic speedups\n2. Linear-time exact string matching (expected)\n-\nKarp-Rabin algorithm and semi-numerical methods\n-\nHash functions and randomized algorithms\n3. The BLAST algorithm and inexact matching\n-\nHashing with neighborhood search\n-\nTwo-hit blast and hashing with combs\n4. Deterministic linear-time exact string matching\n-\nKey insight: gather more info from each comparison\n-\nPre-processing, Z-algorithm, Boyer-More, KMP\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 4 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/aabc42b3391c9bbc2809c0926921c5c9_MIT6_047F15_Lecture04.pdf",
      "content": "Lecture 4\n\nModeling Biological Sequences\nusing Hidden Markov Models\n6.047/6.878/HST.507\nComputational Biology: Genomes, Networks, Evolution\n\nModule 1: Aligning and modeling genomes\n- Module 1: Computational foundations\n- Dynamic programming: exploring exponential spaces in poly-time\n- Linear-time string matching, Hashing, Content-based indexing\n- Hidden Markov Models: decoding, evaluation, parsing, learning\n- Last week: Sequence alignment / comparative genomics\n- Local/global alignment: infer nucleotide-level evolutionary events\n- Database search: scan for regions that may have common ancestry\n- This week: Modeling genomes / exon / CpG island finding\n- Modeling class of elements, recognizing members of a class\n- Application to gene finding, conservation islands, CpG islands\n\nWe have learned how to align sequences to other sequences\n- L2: Sequence alignment\n- Dynamic programming, duality path alignment\n- Global / local alignment, general gap penalties\n- L3: Rapid string search\n- Exact string match, semi-numerical matching\n- Database search: Hashing, BLAST, variations\n- L15:Comparative genomics: evolutionary signatures\n- Tell me how you evolve, I'll tell you what you are\n- Identifying conserved elements through evolution\n- L16: Whole-genome assembly/alignment/duplication:\n- Finding all common substrings within/across species\n- Contigs/scaffolds, string graphs, glocal alignmt paths\n- Problem set 1, project planning, Problem set 2 out\n\nToday: apply these ideas to model DNA sequences\n- What to do with a completely new piece of DNA\n- Align it to things we know about (database search)\n- Align it to things we don't know about (assembly)\n- Stare at it\n- Non-standard nucleotide composition?\n- Interesting k-mer frequencies?\n- Recurrent patterns?\n- Model it\n- Make some hypotheses about it\n- Build a 'generative model' to describe it\n- Find sequences of similar type\nHow do we model DNA sequences?\n...GTACTCACCGGGTTACAGGATTATGGGTTACAGGTAACCGTT...\n\nModeling biological sequences with HMMs\n(a.k.a. What to do with big unlabelled chunks of DNA)\n-\nAbility to emit DNA sequences of a certain type\n- Not exact alignment to previously known gene\n- Preserving 'properties' of type, not identical sequence\n-\nAbility to recognize DNA sequences of a certain type (state)\n- What (hidden) state is most likely to have generated observations\n- Find set of states and transitions that generated a long sequence\n-\nAbility to learn distinguishing characteristics of each state\n- Training our generative models on large datasets\n- Learn to classify unlabelled data\nIntergenic\n\nCpG\nisland\nPromoter\n\nFirst\nexon\nIntron\n\nOther\nexon\nIntron\n\nTTACAGGATTATGGGTTACAGGTAACCGTTGTACTCACCGGGTTACAGGATTATGGGTTACAGGTAACCGGTACTCACCGGGTTACAGGATTATGGTAACGGTACTCACCGGGTTACAGGATTGTTACA\nGG\n\nWhy Probabilistic Sequence Modeling?\n-\nBiological data is noisy\n\n-\nProbability provides a calculus for manipulating models\n\n-\nNot limited to yes/no answers - can provide \"degrees of\nbelief\"\n\n-\nMany common computational tools based on probabilistic\nmodels\n\n-\nOur tools:\n\n- Markov Chains and Hidden Markov Models (HMMs)\n\nMarkov Chains and Hidden Markov Models\n\nAndrey Markov (1856-1922)\nImage in the public domain.\n\nPredicting tomorrow's weather\n-\nWhat you see is what you get:\nnext state only depends on\ncurrent state (no memory)\n- Markov Chain\n- Hidden Markov Model\nSun\nRain\nClouds\nSnow\n-\nHidden state of the world (e.g.\nstorm system) determines\nemission probabilities\n-\nState transitions governed by a\nMarkov chain\nhidden\nobserved\nAll observed\nSummer\nFall\nWinter Spring\nTransitions\nEmissions\nTransitions\n\nHMM nomenclature for this course\n- Vector x = Sequence of observations\n- Vector π = Hidden path (sequence of hidden states)\n- Transition matrix A=akl=probability of kl state transition\n- Emission vector E=ek(xi) = prob. of observing xi from state k\n- Bayes's rule: Use P(xi|πi=k) to estimate P(πi=k|xi)\nFall\nWinter Spring\nEmissions: ek(xi)=P(xi|pi=k)\nTransitions: akl=P(πi=l|πi-1=k)\nSummer\nπ=\nx=\nπi\nxi\nTransition probability\nfrom state k to state l\nEmission probability of\nsymbol xi from state k\n\nComponents of a Markov Chain\nDefinition: A Markov chain is a triplet (Q, p, A), where:\nQ is a finite set of states. Each state corresponds to a symbol in the\nalphabet Σ\np is the initial state probabilities.\nA is the state transition probabilities, denoted by ast for each s, t in Q.\nFor each s, t in Q the transition probability is: ast ≡ P(xi = t|xi-1 = s)\nProperty: The probability of each symbol xi depends only on\nthe value of the preceding symbol xi-1 : P (xi | xi-1,..., x1) = P (xi | xi-1)\nFormula: The probability of the sequence:\nP(x) = P(xL,xL-1,..., x1) = P (xL | xL-1) P (xL-1 | xL-2)... P (x2 | x1) P(x1)\nOutput: The output of the model is the set of states at each\ninstant time => the set of states are observable\nSlide credit: Serafim Batzoglou\n\nComponents of an HMM (Hidden Markov Model)\nDefinition: An HMM is a 5-tuple (Q, V, p, A, E), where:\nQ is a finite set of states, |Q|=N\nV is a finite set of observation symbols per state, |V|=M\np is the initial state probabilities.\nA is the state transition probabilities, denoted by ast for each s, t in Q.\nFor each s, t in Q the transition probability is: ast ≡ P(xi = t|xi-1 = s)\nE is a probability emission matrix, esk ≡ P (vk at time t | qt = s)\nProperty: Emissions and transitions are dependent on the current state\nonly and not on the past.\nOutput: Only emitted symbols are observable by the system but not the\nunderlying random walk between states -> \"hidden\"\nSlide credit: Serafim Batzoglou\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\nThe six algorithmic settings for HMMs\n\nExamples of HMMs\nThe dishonest casino\nThe dishonest genome\n... and many more\n\nExample: The Dishonest Casino\n\nA casino has two dice:\n-\nFair die\n\nP(1) = P(2) = P(3) = P(5) = P(6) = 1/6\n-\nLoaded die\n\nP(1) = P(2) = P(3) = P(4) = P(5) = 1/10\n\nP(6) = 1/2\nCasino player switches between fair and loaded\ndie on average once every 20 turns\n\nGame:\n1.\nYou bet $1\n2.\nYou roll (always with a fair die)\n3.\nCasino player rolls (maybe with fair die,\nmaybe with loaded die)\n4.\nHighest number wins $2\nSlide credit: Serafim Batzoglou\n\nThe dishonest casino model\nFair\nLoaded\n0.05\n0.05\n0.95\n0.95\nP(1|Fair) = 1/6\nP(2|Fair) = 1/6\nP(3|Fair) = 1/6\nP(4|Fair) = 1/6\nP(5|Fair) = 1/6\nP(6|Fair) = 1/6\nP(1|L) = 1/10\nP(2|L) = 1/10\nP(3|L) = 1/10\nP(4|L) = 1/10\nP(5|L) = 1/10\nP(6|L) = 1/2\nObserved\n(world)\nHidden\n(model)\nSlide credit: Serafim Batzoglou\n\nThe dishonest genome model\nVirus\n\"Self\"\n0.85\n0.05\n0.95\n0.15\nP(A|Virus) = 1/6\nP(T|Virus) = 1/6\nP(C|Virus) = 1/3\nP(G|Virus) = 1/3\nP(A|Self) = 1/4\nP(T|Self) = 1/4\nP(C|Self) = 1/4\nP(G|Self) = 1/4\nObserved\n(world)\nHidden\n(model)\nSlide credit: Serafim Batzoglou\n\nExamples of HMMs for genome annotation\nApplication\nDetection\nof GC-rich\nregions\nDetection\nof\nconserved\nregions\nDetection\nof protein-\ncoding\nexons\nDetection\nof protein-\ncoding\nconservatio\nn\nDetection\nof protein-\ncoding\ngene\nstructures\nDetection\nof\nchromatin\nstates\nTopology /\nTransitions\n2 states,\ndifferent\nnucleotide\ncomposition\n2 states,\ndifferent\nconservation\nlevels\n2 states,\ndifferent tri-\nnucleotide\ncomposition\n2 states,\ndifferent\nevolutionary\nsignatures\n~20 states,\ndifferent\ncomposition/\nconservation\n, specific\nstructure\n40 states,\ndifferent\nchromatin\nmark\ncombination\ns\nHidden\nStates /\nAnnotation\nGC-rich / AT-\nrich\nConserved /\nnon-\nconserved\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nFirst/last/mid\ndle coding\nexon,UTRs,\nintron1/2/3,\nintergenic,\n*(+/- strand)\nEnhancer /\npromoter /\ntranscribed /\nrepressed /\nrepetitive\nEmissions /\nObservatio\nns\nNucleotides\nLevel of\nconservation\nTriplets of\nnucleotides\nNucleotide\ntriplets,\nconservation\nlevels\nCodons,\nnucleotides,\nsplice sites,\nstart/stop\ncodons\nVector of\nchromatin\nmark\nfrequencies\n\nRunning the model: Probability of a sequence\nWhat is the joint probability of observing x and a specific path π:\n\nπ = Fair, Fair, Fair, Fair, Fair, Fair, Fair, Fair, Fair, Fair\nand rolls\n\nx = 1 , 2, 1, 5, 6, 2, 1, 6, 2, 4\nJoined probability P(x,π)=P(x|π)P(π)=P(emissions|path)*P(path)\n\nemission transition emission transition emission\np = 1⁄2 P(1 | Fair) P(Fairi+1 | Fairi) P(2 | Fair) P(Fair | Fair) ... P(4 | Fair)\n= 1⁄2 (1/6)10 (0.95)9\n= 5.2 10-9\n1/2\nF\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\nWhy is p so small?\nSlide credit: Serafim Batzoglou\n\nRunning the model: Probability of a sequence\nWhat is the likelihood of\n\nπ = Load, Load, Load, Load, Load, Load, Load, Load, Load, Loaded\nand rolls\n\nx = 1 , 2, 1, 5, 6, 2, 1, 6, 2, 4\n\nemission transition emission transition emission\np = 1⁄2 P(1 | Load) P(Loadi+1 | Loadi) P(2 | Load) P(Load|Load) ... P(4 | Fair)\n= 1⁄2 (1/10)8 (1/2)2 (0.95)9\n= 7.9 10-10\n1/2\n1/10\nL .95\n1/10\nL .95\n1/10\nL .95\n1/10\nL .95\n1/2\nL .95\n1/10\nL .95\n1/10\nL .95\n1/2\nL .95\n1/10\nL .95\nF\nF\nF\nF\nF\nF\nF\nF\nF\nF\n1/10\nL\nCompare the two!\nSlide credit: Serafim Batzoglou\n\nComparing the two paths\nTwo sequence paths:\n\nP( x, all-Fair ) = 5.2 10-9 (very small)\n\nP( x, all-Loaded ) = 7.9 10-10 (very very small)\n\nLikelihood ratio:\n\nP( x, all-Fair ) is 6.59 times more likely than P( x, all-Loaded )\n\nIt is 6.59 times more likely that the die is fair all the way, than loaded all the way.\n\n1/2\n1/10\nL .95\n1/10\nL .95\n1/10\nL .95\n1/10\nL .95\n1/2\nL .95\n1/10\nL .95\n1/10\nL .95\n1/2\nL .95\n1/10\nL .95\n1/10\nL\n1/2\nF .95 F .95 F .95 F .95 F .95 F .95 F .95 F .95 F .95 F\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\nSlide credit: Serafim Batzoglou\n\nWhat about partial runs and die switching\nWhat is the likelihood of\n\nπ = Fair, Fair, Fair, Fair, Load, Load, Load, Load, Fair, Fair\nand rolls\n\nx = 1 , 2, 1, 5, 6, 2, 1, 6, 2, 4\nemission transition emission transition emission\np = 1⁄2 P(1 | Fair) P(Fairi+1 | Fairi) P(2 | Fair) P(Fair | Fair) ... P(4 | Fair)\n= 1⁄2 (1/10)2 (1/2)2 (1/6)5 (0.95)7 (0.05)2\n= 2.8 10-10\n1/2\nF\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.95 F\n1/6\nL\n.05\nF\n1/2\nL .95\nF\n1/10\nL .95\nF\n1/10\nL .95\nF\n1/2\nL .05\nF\n1/6\nL\n.95 F\n1/6\nL\nMuch less likely, due to high cost of transitions\n\nModel comparison\nLet the sequence of rolls be:\n\nx = 1, 6, 6, 5, 6, 2, 6, 6, 3, 6\n\nNow, what is the likelihood = F, F, ..., F?\n\n1⁄2 (1/6)10 (0.95)9 = 0.5 10-9, same as before\n\nWhat is the likelihood = L, L, ..., L?\n\n1⁄2 (1/10)4 (1/2)6 (0.95)9 = 0.5 10-7\n\nSo, it is 100 times more likely the die is loaded\nModel evaluation\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\nThe six algorithmic settings for HMMs\n\n3. DECODING:\nWhat was the sequence of hidden states?\nGiven:\nModel parameters ei(.), aij\nGiven:\nSequence of emissions x\n\nFind:\nSequence of hidden states π\n\nFinding the optimal path\n-\nWe can now evaluate any path through hidden states, given\nthe emitted sequences\n\n-\nHow do we find the best path?\n\n-\nOptimal substructure! Best path through a given state is:\n- Best path to previous state\n- Best transition from previous state to this state\n- Best path to the end state\n\nViterbi algortithm\n- Define Vk(i) = Probability of the most likely path through state i=k\n- Compute Vk(i+1) as a function of maxk' { Vk'(i) }\n\n- Vk(i+1) = ek(xi+1) * maxj ajk Vj(i)\nDynamic Programming\n\nPhotograph of Andrew J. Viterbi removed due to copyright restrictions.\n\nFinding the most likely path\nK\n...\nK\n...\nK\n...\n...\n...\n...\nK\n...\nx2\nx3\nxN\nK\nx1\n- Find path * that maximizes total joint probability P[ x, ]\n- P(x,) = a01 * Πi ei(xi) aii+1\nstart\nemission transition\nSlide credit: Serafim Batzoglou\n\nCalculate maximum P(x,) recursively\n- Assume we know Vj for the previous time step (i-1)\n\n- Calculate Vk(i) = ek(xi) * maxj ( Vj(i-1) ajk )\nxi\nek\nk\nj\najk\n...\n...\nxi-1\n...\nVj(i-1)\nVk(i)\nhidden\nstates\nobservations\nthis emission\nTransition\nfrom state j\nmax ending\nin state j at step i\nall possible previous states j\ncurrent max\nSlide credit: Serafim Batzoglou\n\nThe Viterbi Algorithm\nx1 x2 x3 ...............................................xN\nInput: x = x1......xN\n\nInitialization:\n\nV0(0)=1, Vk(0) = 0, for all k > 0\n\nIteration:\n\nVk(i) = eK(xi) maxj ajk Vj(i-1)\n\nTermination:\n\nP(x, *) = maxk Vk(N)\nTraceback:\n\nFollow max pointers back\n\nSimilar to aligning states to seq\n\nIn practice:\n\nUse log scores for computation\n\nRunning time and space:\n\nTime: O(K2N)\n\nSpace: O(KN)\nState 1\nK\nVk(i)\nSlide credit: Serafim Batzoglou\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\nThe six algorithmic settings for HMMs\n\n2. EVALUATION\n(how well does our model capture the world)\nGiven: Model parameters ei(.), aij\nGiven: Sequence of emissions x\n\nFind:\nP(x|M), summed over all possible paths π\n\nSimple: Given the model, generate some sequence x\nGiven a HMM, we can generate a sequence of length n as follows:\n1.\nStart at state 1 according to prob a01\n2.\nEmit letter x1 according to prob e1(x1)\n3.\nGo to state 2 according to prob a12\n4.\n... until emitting xn\n\nWe have some sequence x that can be emitted by p. Can calculate its likelihood.\nHowever, in general, many different paths may emit this same sequence x.\nHow do we find the total probability of generating a given x, over any path?\nK\n...\nK\n...\nK\n...\n...\n...\n...\nK\n...\nx1\nx2\nx3\nxn\nK\ne2(x1)\na02\nSlide credit: Serafim Batzoglou\n\nComplex: Given x, was it generated by the model?\nGiven a sequence x,\nWhat is the probability that x was generated by the model\n(using any path)?\n- P(x) = Σπ P(x,π) = Σπ P(x|π) P(π)\n- (weighted average of conditional probability, summed\nover all paths, weighted by each path's probability)\n- Challenge: exponential number of paths\nK\n...\nK\n...\nK\n...\n...\n...\n...\nK\n...\nx1\nx2\nx3\nxn\nK\ne2(x1)\na02\nSlide credit: Serafim Batzoglou\n\nCalculate probability of emission over all paths\n- Each path has associated probability\n- Some paths are likely, others unlikely: sum them all up\nReturn total probability that emissions are observed,\nsummed over all paths\n- Viterbi path is the most likely one\n- How much 'probability mass' does it contain?\n- (cheap) alternative:\n- Calculate probability over maximum (Viterbi) path π*\n- Good approximation if Viterbi has highest density\n- BUT: incorrect\n- (real) solution\n- Calculate the exact sum iteratively\n- P(x) = Σπ P(x,π)\n- Can use dynamic programming\nSlide credit: Serafim Batzoglou\n\nThe Forward Algorithm - derivation\nDefine the forward probability:\n\nfl(i) = P(x1...xi, i = l)\n\n= 1...i-1 P(x1...xi-1, 1,..., i-2, i-1, i = l) el(xi)\n\n= k 1...i-2 P(x1...xi-1, 1,..., i-2, i-1=k) akl el(xi)\n\n= k fk(i-1) akl el(xi)\n\n= el(xi) k fk(i-1) akl\n\nSlide credit: Serafim Batzoglou\n\nCalculate total probability Σπ P(x,) recursively\n- Assume we know fj for the previous time step (i-1)\n\n- Calculate fk(i) = ek(xi) * sumj ( fj(i-1) ajk )\nxi\nek\nk\nj\najk\n...\n...\nxi-1\n...\nfj(i-1)\nfk(i)\nhidden\nstates\nobservations\nthis emission\ntransition\nfrom state j\nsum ending\nin state j at step i\nevery possible previous state j\nupdated sum\nSlide credit: Serafim Batzoglou\n\nThe Forward Algorithm\nx1 x2 x3 ...............................................xN\nInput: x = x1......xN\n\nInitialization:\n\nf0(0)=1, fk(0) = 0, for all k > 0\n\nIteration:\n\nfk(i) = eK(xi) sumj ajk fj(i-1)\n\nTermination:\n\nP(x, *) = sumk fk(N)\nIn practice:\n\nSum of log scores is difficult\n\napproximate exp(1+p+q)\n\nscaling of probabilities\n\nRunning time and space:\n\nTime: O(K2N)\n\nSpace: O(KN)\nState 1\nK\nfk(i)\nSlide credit: Serafim Batzoglou\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\nThe six algorithmic settings for HMMs\n\nExamples of HMMs for genome annotation\nApplication\nDetection\nof GC-rich\nregions\nDetection\nof\nconserved\nregions\nDetection\nof protein-\ncoding\nexons\nDetection\nof protein-\ncoding\nconservatio\nn\nDetection\nof protein-\ncoding\ngene\nstructures\nDetection\nof\nchromatin\nstates\nTopology /\nTransitions\n2 states,\ndifferent\nnucleotide\ncomposition\n2 states,\ndifferent\nconservation\nlevels\n2 states,\ndifferent tri-\nnucleotide\ncomposition\n2 states,\ndifferent\nevolutionary\nsignatures\n~20 states,\ndifferent\ncomposition/\nconservation\n, specific\nstructure\n40 states,\ndifferent\nchromatin\nmark\ncombination\ns\nHidden\nStates /\nAnnotation\nGC-rich / AT-\nrich\nConserved /\nnon-\nconserved\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nFirst/last/mid\ndle coding\nexon,UTRs,\nintron1/2/3,\nintergenic,\n*(+/- strand)\nEnhancer /\npromoter /\ntranscribed /\nrepressed /\nrepetitive\nEmissions /\nObservatio\nns\nNucleotides\nLevel of\nconservation\nTriplets of\nnucleotides\n64x64 matrix\nof codon\nsubstitution\nfrequencies\nCodons,\nnucleotides,\nsplice sites,\nstart/stop\ncodons\nVector of\nchromatin\nmark\nfrequencies\n\nWhat have we learned ?\n-\nModeling sequential data\n- Recognize a type of sequence, genomic, oral, verbal, visual, etc...\n-\nDefinitions\n- Markov Chains\n- Hidden Markov Models (HMMs)\n-\nExamples of HMMs\n- Recognizing GC-rich regions, preferentially-conserved elements, coding\nexons, protein-coding gene structures, chromatin states\n-\nOur first computations\n- Running the model: know model generate sequence of a 'type'\n- Evaluation: know model, emissions, states p?\n- Viterbi: know model, emissions find optimal path\n- Forward: know model, emissions total p over all paths\n-\nNext time:\n- Posterior decoding\n- Supervised learning\n- Unsupervised learning: Baum-Welch, Viterbi training\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "6.047 Computational Biology, Lecture 5 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/7756eb0ac75a84efd66131eb7ed7f210_MIT6_047F15_Lecture05.pdf",
      "content": "Lecture 05\n\nHidden Markov Models\nPart II\n6.047/6.878/HST.507\nComputational Biology: Genomes, Networks, Evolution\n\nModule 1: Aligning and modeling genomes\n- Module 1: Computational foundations\n- Dynamic programming: exploring exponential spaces in poly-time\n- Introduce Hidden Markov Models (HMMs): Central tool in CS\n- HMM algorithms: Decoding, evaluation, parsing, likelihood, scoring\n- This week: Sequence alignment / comparative genomics\n- Local/global alignment: infer nucleotide-level evolutionary events\n- Database search: scan for regions that may have common ancestry\n- Next week: Modeling genomes / exon / CpG island finding\n- Modeling class of elements, recognizing members of a class\n- Application to gene finding, conservation islands, CpG islands\n\nGoals for today: HMMs, part II\n1. Review: Basics and three algorithms from last time\n- Markov Chains and Hidden Markov Models\n- Calculating likelihoods P(x,π) (algorithm 1)\n- Viterbi algorithm: Find π* = argmaxπ P(x,π) (alg 3)\n- Forward algorithm: Find P(x), over all paths (alg 2)\n2. Increasing the 'state' space / adding memory\n- Finding GC-rich regions vs. finding CpG islands\n- Gene structures (GENSCAN), chromatin (ChromHMM)\n3. Posterior decoding: Another way of 'parsing'\n- Find most likely state πi, sum over all possible paths\n4. Learning (ML training, Baum-Welch, Viterbi training)\n- Supervised: Find ei(.) and aij given labeled sequence\n- Unsupervised: given only x annotation + params\n\nMarkov chains and Hidden Markov Models (HMMs)\n-\nWhat you see is what you get:\nnext state only depends on\ncurrent state (no memory)\nSun\nRain\nClouds\nSnow\n-\nHidden state of the world determines\nemission probabilities\n-\nState transitions are a Markov chain\nhidden\nobserved\nAll observed\nSummer\nFall\nWinter Spring\nTransitions\nEmissions\nTransitions\n-\nMarkov Chain\n- Q: states\n- p: initial state probabilities\n- A: transition probabilities\n-\nHMM\n- Q: states, p: initial, A: transitions\n- V: observations\n- E: emission probabilities\n\nHMM nomenclature for this course\n- Vector x = Sequence of observations\n- Vector π = Hidden path (sequence of hidden states)\n- Transition matrix A=akl=probability of kl state transition\n- Emission vector E=ek(xi) = prob. of observing xi from state k\n- Bayes's rule: Use P(xi|πi=k) to estimate P(πi=k|xi)\nFall\nWinter\nSpring\nEmissions: ek(xi)=P(xi|πi=k)\nTransitions: akl=P(πi=l|πi-1=k)\nSummer\nπ=\nx=\nπi\nxi\nTransition probability\nfrom state k to state l\nEmission probability of\nsymbol xi from state k\n\nExample: The Dishonest Casino\n\nA casino has two dice:\n-\nFair die\n\nP(1) = P(2) = P(3) = P(5) = P(6) = 1/6\n-\nLoaded die\n\nP(1) = P(2) = P(3) = P(4) = P(5) = 1/10\n\nP(6) = 1/2\nCasino player switches between fair and loaded\ndie on average once every 20 turns\n\nGame:\n1.\nYou bet $1\n2.\nYou roll (always with a fair die)\n3.\nCasino player rolls (maybe with fair die,\nmaybe with loaded die)\n4.\nHighest number wins $2\nSlide credit: Serafim Batzoglou\n\nExamples of HMMs for genome annotation\nApplication\nDetection\nof GC-rich\nregions\nDetection\nof\nconserved\nregions\nDetection\nof protein-\ncoding\nexons\nDetection\nof protein-\ncoding\nconservatio\nn\nDetection\nof protein-\ncoding\ngene\nstructures\nDetection\nof\nchromatin\nstates\nTopology /\nTransitions\n2 states,\ndifferent\nnucleotide\ncomposition\n2 states,\ndifferent\nconservation\nlevels\n2 states,\ndifferent tri-\nnucleotide\ncomposition\n2 states,\ndifferent\nevolutionary\nsignatures\n~20 states,\ndifferent\ncomposition/\nconservation\n, specific\nstructure\n40 states,\ndifferent\nchromatin\nmark\ncombination\ns\nHidden\nStates /\nAnnotation\nGC-rich / AT-\nrich\nConserved /\nnon-\nconserved\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nFirst/last/mid\ndle coding\nexon,UTRs,\nintron1/2/3,\nintergenic,\n*(+/- strand)\nEnhancer /\npromoter /\ntranscribed /\nrepressed /\nrepetitive\nEmissions /\nObservatio\nns\nNucleotides\nLevel of\nconservation\nTriplets of\nnucleotides\nNucleotide\ntriplets,\nconservation\nlevels\nCodons,\nnucleotides,\nsplice sites,\nstart/stop\ncodons\nVector of\nchromatin\nmark\nfrequencies\n\nSCORING\nPARSING\nLEARNING\nThe main questions on HMMs\n1. Scoring x, one path = Joint probability of a sequence and a path, given the model\n-\nGIVEN\na HMM M,\na path ,\nand a sequence x,\n\n-\nFIND\nProb[ x, | M ]\n\n\"Running the model\", simply multiply emission and transition probabilities\n\nApplication: \"all promoter\" vs. \"all backgorund\" comparisons\n2. Scoring x, all paths = total probability of a sequence, summed across all paths\n-\nGIVEN a HMM M,\na sequence x\n-\nFIND\nthe total probability P[x | M] summed across all paths\nForward algorithm, sum score over all paths (same result as backward)\n3. Viterbi decoding = parsing a sequence into the optimal series of hidden states\n-\nGIVEN\na HMM M,\nand a sequence x,\n-\nFIND\nthe sequence * of states that maximizes P[ x, | M ]\nViterbi algorithm, dynamic programming, max score over all paths, trace pointers find path\n4. Posterior decoding = total prob that emission xi came from state k, across all paths\n-\nGIVEN a HMM M,\na sequence x\n-\nFIND\nthe total probability P[i = k | x, M)\nPosterior decoding: run forward & backward algorithms to & from state I =k\n5. Supervised learning = optimize parameters of a model given training data\n-\nGIVEN\na HMM M, with unspecified transition/emission probs., labeled sequence x,\n-\nFIND\nparameters = (ei, aij) that maximize P[ x | ]\n\nSimply count frequency of each emission and transition observed in the training data\n6. Unsupervised learning = optimize parameters of a model given training data\n-\nGIVEN\na HMM M, with unspecified transition/emission probs., unlabeled sequence x,\n-\nFIND\nparameters = (ei, aij) that maximize P[ x | ]\n\nViterbi training: guess parameters, find optimal Viterbi path (#2), update parameters (#5), iterate\n\nBaum-Welch training: guess, sum over all emissions/transitions (#4), update (#5), iterate\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\nProbability of given path p, emissions x\nK\n...\nK\n...\nK\n...\n...\n...\n...\nK\n...\nx2\nx3\nxK\nK\nx1\n- P(x,) = a01 * Πi ei(xi) aii+1\nstart\nemission transition\nx is the\n(observed)\nsequence\nπ is the\n(hidden) path\nes(xi)\nast\nCourtesy of Serafim Batzoglou. Used with permission.\n\nExample: One particular P vs. B assignment\nP\nB\nP\nB\nP\nB\nB\nP\nB\nB\nP\nB\nP\nB\nG\nC\nA\nA\nA\nT\nG\nC\nL:\nS:\nP\nP\n(\n|\n) (\n|\n) (\n|\n) (\n|\n) (\n|\n) (\n|\n)... (\n|\n)\n(0.85)\n(0.25)\n(0.75)\n(0.42)\n0.30 0.15\n6.7 10\nP\nP G B P B\nB P C B P B\nB P A B P P B\nP C B\n\nB\nB\nB\nB\nB\n0.85\n0.25\n0.85\n0.15\n0.25\n0.25\n0.25\n0.42\n0.42\n0.30\n0.25\n0.25\n0.85\nP\nP\nP\n0.75\n0.75\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\nFinding the most likely path\nK\n...\nK\n...\nK\n...\n...\n...\n...\nK\n...\nx2\nx3\nxK\nK\nx1\n- Find path * that maximizes total joint probability P[ x, ]\n- argmaxπP(x,) =argmaxπ a01 * Πi ei(xi) aii+1\nstart\nemission transition\n\nCalculate maximum P(x,) recursively\n- Assume we know Vj for the previous time step (i-1)\n\n- Calculate Vk(i) = ek(xi) * maxj ( Vj(i-1) ajk )\nxi\nek\nk\nj\najk\n...\n...\nxi-1\n...\nVj(i-1)\nVk(i)\nhidden\nstates\nobservations\nthis emission\nTransition\nfrom state j\nmax ending\nin state j at step i\nall possible previous states j\ncurrent max\nViterbi algortithm\nDefine Vk(i) = Probability of the most likely path through state i=k\nCompute Vk(i+1) recursively, as a function of maxk' { Vk'(i) }\n\nThe Viterbi Algorithm\nx1 x2 x3 ...............................................xN\nInput: x = x1......xN\n\nInitialization:\n\nV0(0)=1, Vk(0) = 0, for all k > 0\n\nIteration:\n\nVk(i) = eK(xi) maxj ajk Vj(i-1)\n\nTermination:\n\nP(x, *) = maxk Vk(N)\nTraceback:\n\nFollow max pointers back\n\nIn practice:\n\nUse log scores for computation\n\nRunning time and space:\n\nTime: O(K2N)\n\nSpace: O(KN)\nState 1\nK\nVk(i)\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\nP(x) Prob that model emits x, sum over all paths\nGiven a sequence x,\nWhat is the probability that x was generated by the model (using any path)?\n- P(x) = Σπ P(x,π)\n-\nChallenge: exponential number of paths\n- Sum over all paths, weighing the path probability, and the emission probs\n- Prob of emitting sequence: use individual emission probs from each state\n- Prob of path: use both emission and transition prob, based on previous path\nK\n...\nK\n...\nK\n...\n...\n...\n...\nK\n...\nx1\nx2\nx3\nxn\nK\ne2(x1)\na02\n- P(x) = Σπ a01 * Πi ei(xi) aii+1\nstart\nemission transition\n\nCalculate total probability Σπ P(x,) recursively\n- Assume we know fj for the previous time step (i-1)\n\n- Calculate fk(i) = ek(xi) * sumj ( fj(i-1) ajk )\nxi\nek\nk\nj\najk\n...\n...\nxi-1\n...\nfj(i-1)\nfk(i)\nhidden\nstates\nobservations\nthis emission\ntransition\nfrom state j\nsum ending\nin state j at step i\nSum over all previous states j\ncurrent sum\n\nThe Forward Algorithm\nx1 x2 x3 ...............................................xN\nInput: x = x1......xN\n\nInitialization:\n\nf0(0)=1, fk(0) = 0, for all k > 0\n\nIteration:\n\nfk(i) = eK(xi) sumj ajk fj(i-1)\n\nTermination:\n\nP(x, *) = sumk fk(N)\nIn practice:\n\nSum of log scores is difficult\n\napproximate exp(1+p+q)\n\nscaling of probabilities\n\nRunning time and space:\n\nTime: O(K2N)\n\nSpace: O(K)\nState 1\nK\nfk(i)\n\nGoals for today: HMMs, part II\n1. Review: Basics and three algorithms from last time\n- Markov Chains and Hidden Markov Models\n- Calculating likelihoods P(x,π) (algorithm 1)\n- Viterbi algorithm: Find π* = argmaxπ P(x,π) (alg 3)\n- Forward algorithm: Find P(x), over all paths (alg 2)\n2. Increasing the 'state' space / adding memory\n- Finding GC-rich regions vs. finding CpG islands\n- Gene structures GENSCAN, chromatin ChromHMM\n3. Posterior decoding: Another way of 'parsing'\n- Find most likely state πi, sum over all possible paths\n4. Learning (ML training, Baum-Welch, Viterbi training)\n- Supervised: Find ei(.) and aij given labeled sequence\n- Unsupervised: given only x annotation + params\n\nIncreasing the state space\n(remembering more)\nHMM1: Promoters = only Cs and Gs matter\nHMM2: Promoters = it's actually CpGs that matter\n(di-nucleotides, remember previous nucleotide)\n\nIncreasing the state of the system (looking back)\n- Markov Models are memory-less\n- In other words, all memory is encoded in the states\n- To remember additional information, augment state\n- A two-state HMM has minimal memory\n- Two states: GC-rich vs. equal probability\n- State, emissions, only depend on current state\n- Current state only encodes one previous nucleotide\n- How do you count di-nucleotide frequencies?\n- CpG islands: di-nucleotides\n- Codon triplets: tri-nucleotides\n- Di-codon frequencies: six nucleotides\nExpanding the number of states\n+\n-\nA: .2\nC: .3\nG: .3\nT: .2\nA: 1/4\nC: 1/4\nG: 1/4\nT: 1/4\na++\na--\na+-\na-+\n\nRemember previous nucleotide: expand both states\nA+\nT+\nG+\nC+\nA: 0\nC: 0\nG: 1\nT: 0\nA: 1\nC: 0\nG: 0\nT: 0\nA: 0\nC: 1\nG: 0\nT: 0\nA: 0\nC: 0\nG: 0\nT: 1\nCpG+ CpG-\nA: .1\nC: .3\nG: .4\nT: .2\nA: 1/4\nC: 1/4\nG: 1/4\nT: 1/4\naPP\naBB\naPB\naBP\nA+\nT+\nG+\nC+\nA: 0\nC: 0\nG: 1\nT: 0\nA: 1\nC: 0\nG: 0\nT: 0\nA: 0\nC: 1\nG: 0\nT: 0\nA: 0\nC: 0\nG: 0\nT: 1\n\"Memory\" of previous\nnucleotide is encoded\nin the current state.\n\nGC-rich: 4 states\nBackground: 4 states\n\nHMM for CpG islands\n-\nA single model combines two Markov\nchains, each of four nucleotides:\n- '+' states: A+, C+, G+, T+\n- Emit symbols: A, C, G, T in CpG islands\n- '-' states: A-, C-, G-, T-\n- Emit symbols: A, C, G, T in non-islands\n-\nEmission probabilities distinct for the '+'\nand the '-' states\n- Infer most likely set of states, giving rise\nto observed emissions\n'Paint' the sequence with + and - states\nA+\nT+\nG+\nC+\nA-\nT-\nG-\nC-\nA: 0\nC: 0\nG: 1\nT: 0\nA: 1\nC: 0\nG: 0\nT: 0\nA: 0\nC: 1\nG: 0\nT: 0\nA: 0\nC: 0\nG: 0\nT: 1\nA: 0\nC: 0\nG: 1\nT: 0\nA: 1\nC: 0\nG: 0\nT: 0\nA: 0\nC: 1\nG: 0\nT: 0\nA: 0\nC: 0\nG: 0\nT: 1\nWhy we need so many states...\nIn our simple GC-content example, we only had 2 states (+|-)\nWhy do we need 8 states here: 4 CpG+ / 4 CpG- ?\nEncode 'memory' of previous state: nucleotide transitions\n\nTraining emission parameters for CpG+/CpG- states\n-\nCount di-nucleotide frequencies:\n- 16 possible di-nucleotides. 16 transition parameters.\n- Alternative: 16 states, each emitting di-nucleotide\n-\nDerive two Markov chain models:\n- '+' model: from the CpG islands\n- '-' model: from the remainder of sequence\n-\nTransition probabilities for each model:\n- Encode differences in di-nucleotide frequencies\n\n+\nA\nC\nG\nT\nA\n.180\n.274\n.426\n.120\nC\n.171\n.368\n.274\n.188\nG\n.161\n.339\n.375\n.125\nT\n.079\n.355\n.384\n.182\nA\nT\nG\nC\naGT\naAC\naGC\naAT\n-\nA\nC\nG\nT\nA\n.300\n.205\n.285\n.210\nC\n.322\n.298\n.078\n.302\nG\n.248\n.246\n.298\n.208\nT\n.177\n.239\n.292\n.292\n\nExamples of HMMs for genome annotation\nDetection\nof GC-rich\nregions\nDetection\nof CpG-rich\nregions\nDetection\nof\nconserved\nregions\nDetection\nof protein-\ncoding\nexons\nDetection\nof protein-\ncoding\nconservatio\nn\nDetection\nof protein-\ncoding\ngene\nstructures\nDetection\nof\nchromatin\nstates\n2 states,\ndifferent\nnucleotide\ncomposition\n8 states,\n4 each +/-,\ndifferent\ntransition\nprobabilities\n2 states,\ndifferent\nconservation\nlevels\n2 states,\ndifferent tri-\nnucleotide\ncomposition\n2 states,\ndifferent\nevolutionary\nsignatures\n~20 states,\ndifferent\ncomposition/\nconservation\n, specific\nstructure\n40 states,\ndifferent\nchromatin\nmark\ncombination\ns\nGC-rich / AT-\nrich\nCpG-rich /\nCpG-poor\nConserved /\nnon-\nconserved\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nFirst/last/mid\ndle coding\nexon,UTRs,\nintron1/2/3,\nintergenic,\n*(+/- strand)\nEnhancer /\npromoter /\ntranscribed /\nrepressed /\nrepetitive\nNucleotides\nDi-\nNucleotides\nLevel of\nconservation\nTriplets of\nnucleotides\n64x64 matrix\nof codon\nsubstitution\nfrequencies\nCodons,\nnucleotides,\nsplice sites,\nstart/stop\ncodons\nVector of\nchromatin\nmark\nfrequencies\n\nHMM architecture matters: Protein-coding genes\n- Gene vs. Intergenic\n- Start & Stop in/out\n- UTR: 5' and 3' end\n- Exons, Introns\n- Remembering frame\n- E0,E1,E2\n- I0,I1,I2\n- Sequence patterns\nto transition between\nstates:\n- ATG, TAG,\nAcceptor/Donor,\nTATA, AATAA\n(c) Bill Majoros / GeneZilla. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nChromatin State: Emission & Transition Matrices\nErnst and Kellis, Nature Biotech 2010, Nature 2011, Nature Methods 2012\n- Emission matrix:\n- Multi-variate HMM\n- Emits vector of values\n- Transition matrix:\n- Learn spatial relationships\n- No a-priori 'gene' structure\n(c) Macmillan Publishers Limited. All rights reserved. This content is excluded from our Creative\nCommons license. For more information,see http://ocw.mit.edu/help/faq-fair-use/.\nSource: Ernst, Jason and Manolis Kellis. \"Discovery and characterization of chromatin states for\nsystematic annotation of the human genome.\"\nNature Biotechnology 28, no. 8 (2010): 817-825.\n\nGoals for today: HMMs, part II\n1. Review: Basics and three algorithms from last time\n- Markov Chains and Hidden Markov Models\n- Calculating likelihoods P(x,π) (algorithm 1)\n- Viterbi algorithm: Find π* = argmaxπ P(x,π) (alg 3)\n- Forward algorithm: Find P(x), over all paths (alg 2)\n2. Increasing the 'state' space / adding memory\n- Finding GC-rich regions vs. finding CpG islands\n- Gene structures GENSCAN, chromatin ChromHMM\n3. Posterior decoding: Another way of 'parsing'\n- Find most likely state πi, sum over all possible paths\n4. Learning (ML training, Baum-Welch, Viterbi training)\n- Supervised: Find ei(.) and aij given labeled sequence\n- Unsupervised: given only x annotation + params\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\n4. Decoding, all paths\nFind the likelihood an emission xi is\ngenerated by a state\n\nCalculate most probable label at a single position\n- Calculate most probable label, L*\ni , at each position i\n- Do this for all N positions gives us {L*\n1, L*\n2, L*\n3.... L*\nN}\n- How much information have we observed? Three settings:\n- Observed nothing: Use prior information\n- Observed only character at position i: Prior + emission probability\n- Observed entire sequence: Posterior decoding\nP\nB\nP\nB\nP\nB\nB\nP\nB\nB\nP\nB\nP\nB\nG\nC\nA\nA\nA\nT\nG\nC\nπ:\nx:\nP\nP\nP\nB\nP\nB\nP\nB\nB\nP\nB\nB\nP\nB\nP\nB\nP\nP\nSum over all paths\nP(Labeli=B|x)\n\nCalculate P(π7= CpG+ | x7=G)\n- With no knowledge (no characters)\n- Simply time spent in markov chain states\n- P( πi=k ) = most likely state (prior)\n\n- With very little knowledge (just that character)\n- Time spent, adjusted for different emission probs.\n- Use Bayes rule to change inference directionality\n- P( πi=k | xi=G ) = P(πι=κ) * P(xi=G|πi=k) / P(xi=G)\n\n- With knowledge of entire sequence (all characters)\n- P( πi=k | x=AGCGCG...GATTATCGTCGTA)\n- Sum over all paths that emit 'G' at position 7\nPosterior decoding\n\nMotivation for the Backward Algorithm\nWe want to compute\n\nP(i = k | x), the probability distribution on the ith position, given x\n\nWe start by computing\n\nP(i = k, x) = P(x1...xi, i = k, xi+1...xN)\n\n= P(x1...xi, i = k) P(xi+1...xN | x1...xi, i = k)\n\n= P(x1...xi, i = k) P(xi+1...xN | i = k)\nForward, fk(i)\nBackward, bk(i)\n\nThe Backward Algorithm - derivation\nDefine the backward probability:\n\nbk(i) = P(xi+1...xN | i = k)\n\n= i+1...N P(xi+1,xi+2, ..., xN, i+1, ..., N | i = k)\n\n= l i+1...N P(xi+1,xi+2, ..., xN, i+1 = l, i+2, ..., N | i = k)\n\n= l el(xi+1) akl i+1...N P(xi+2, ..., xN, i+2, ..., N | i+1 = l)\n\n= l el(xi+1) akl bl(i+1)\n\nCalculate total end probability recursively\n- Assume we know bl for the next time step (i+1)\n\n- Calculate bk(i) = suml ( el(xi+1) akl bl(i+1) )\nxi+1\nel\nl\nk\nakl\n...\n...\nxi\n...\nbk(i)\nbl(i+1)\nhidden\nstates\nobservations\nnext\nemission\ntransition\nto next state\nprob sum from\nstate l to end\nsum over all possible next states\ncurrent max\n\nThe Backward Algorithm\nx1 x2 x3 ...............................................xN\nInput: x = x1......xN\n\nInitialization:\n\nbk(N) = ak0, for all k\n\nIteration:\n\nbk(i) = l el(xi+1) akl bl(i+1)\n\nTermination:\n\nP(x) = l a0l el(x1) bl(1)\nIn practice:\n\nSum of log scores is difficult\n\napproximate exp(1+p+q)\n\nscaling of probabilities\n\nRunning time and space:\n\nTime: O(K2N)\n\nSpace: O(K)\nState 1\nK\nbk(i)\n\nPutting it all together: Posterior decoding\n-\nP(k) = P( πi=k | x ) = fk(i)*bk(i) / P(x)\n- Probability that ith state is k, given all emissions x\n-\nPosterior decoding\n- Find the most likely state at position i over all possible hidden paths\ngiven the observed sequence x\n- ^\ni = argmaxk P(i = k | x)\n-\nPosterior decoding 'path' ^\ni\n- For classification, more informative than Viterbi path *\n- More refined measure of \"which hidden states\" generated x\n- However, it may give an invalid sequence of states\n- Not all jk transitions may be possible\nx1 x2 x3 ...............................................xN\nState 1\nK\nP(k)\n\nGoals for today: HMMs, part II\n1. Review: Basics and three algorithms from last time\n- Markov Chains and Hidden Markov Models\n- Calculating likelihoods P(x,π) (algorithm 1)\n- Viterbi algorithm: Find π* = argmaxπ P(x,π) (alg 3)\n- Forward algorithm: Find P(x), over all paths (alg 2)\n2. Increasing the 'state' space / adding memory\n- Finding GC-rich regions vs. finding CpG islands\n- Gene structures GENSCAN, chromatin ChromHMM\n3. Posterior decoding: Another way of 'parsing'\n- Find most likely state πi, sum over all possible paths\n4. Learning (ML training, Baum-Welch, Viterbi training)\n- Supervised: Find ei(.) and aij given labeled sequence\n- Unsupervised: given only x annotation + params\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\nLearning: How to train an HMM\nTransition probabilities\ne.g. P(Pi+1|Bi) - the\nprobability of entering a\npathogenicity island from\nbackground DNA\n\nEmission probabilities\ni.e. the nucleotide\nfrequencies for\nbackground DNA and\npathogenicity islands\nB\nP\nP(S|P)\nP(S|B)\nP(Li+1|Li)\n\nTwo learning scenarios\nCase 1. Estimation when the \"right answer\" is known\n\nExamples:\n\nGIVEN:\na genomic region x = x1...x1,000,000 where we have good\n\n(experimental) annotations of the CpG islands\n\nCase 2. Estimation when the \"right answer\" is unknown\n\nExamples:\n\nGIVEN:\nthe porcupine genome; we don't know how frequent are the\n\nCpG islands there, neither do we know their composition\n\nQUESTION:\nUpdate the parameters of the model to maximize P(x|)\n\nTwo types of learning: Supervised / Unsupervised\n5. Supervised learning\n\ninfer model parameters given labeled training data\n-\nGIVEN:\n-\na HMM M, with unspecified transition/emission probs.\n-\nlabeled sequence x,\n-\nFIND:\n-\nparameters = (Ei, Aij) that maximize P[ x | ]\nSimply count frequency of each emission and transition,\n\nas observed in the training data\n6. Unsupervised learning\n\ninfer model parameters given unlabelled training data\n-\nGIVEN:\n-\na HMM M, with unspecified transition/emission probs.\n-\nunlabeled sequence x,\n-\nFIND:\n-\nparameters = (Ei, Aij) that maximize P[ x | ]\nViterbi training:\nguess parameters, find optimal Viterbi path (#2), update parameters (#5), iterate\nBaum-Welch training:\nguess parameters, sum over all paths (#4), update parameters (#5), iterate\n\n5: Supervised learning\nEstimate model parameters\nbased on labeled training data\n\nCase 1.\nWhen the right answer is known\nGiven x = x1...xN\nfor which the true = 1...N is known,\n\nDefine:\n\nAkl\n= # times kl transition occurs in\n\nEk(b)\n= # times state k in emits b in x\n\nWe can show that the maximum likelihood parameters are:\n\nAkl\n\nEk(b)\n\nakl = -----\nek(b) = -------\n\ni Aki\n\nc Ek(c)\n\nLearning From Labelled Data\nP\nB\nP\nB\nP\nB\nB\nP\nB\nB\nP\nB\nP\nB\nG\nC\nA\nA\nA\nT\nG\nC\nL:\nS:\nIf we have a sequence that has islands marked, we can simply count\nA:\nT:\nG:\nC:\nA: 1/5\nT: 0\nG: 2/5\nC: 2/5\nP(S|P)\nP(S|B)\nP(Li+1|Li)\nBi+1 Pi+1 End\nBi\n3/5\n1/5\n1/5\nPi\n1/3\n2/3\nStart\nEnd\nstart\nP\nB\nB\nB\nB\nB\nP\nETC..\nMaximum Likelihood Estimation\n!\n\nCase 1.\nWhen the right answer is known\nIntuition: When we know the underlying states,\n\nBest estimate is the average frequency of\n\ntransitions & emissions that occur in the training data\n\nDrawback:\n\nGiven little data, there may be overfitting:\n\nP(x|) is maximized, but is unreasonable\n\n0 probabilities - VERY BAD\n\nExample:\n\nGiven 10 nucleotides, we observe\n\nx = C, A, G, G, T, C, C, A, T, C\n\n= P, P, P, p, p, P, P, P, P, P\n\nThen:\n\naPP = 1; aPB = 0\n\neP(A) = .2;\n\neP(C) = .4;\n\neP(G) = .2;\n\neP(T) =.2\n\nPseudocounts\nSolution for small training sets:\n\nAdd pseudocounts\n\nAkl\n= # times kl transition occurs in + rkl\n\nEk(b)\n= # times state k in emits b in x\n+ rk(b)\n\nrkl, rk(b) are pseudocounts representing our prior belief\n\nLarger pseudocounts Strong priof belief\n\nSmall pseudocounts ( < 1): just to avoid 0 probabilities\n\nExample: Training Markov Chains for CpG islands\n-\nTraining Set:\n- set of DNA sequences w/ known CpG islands\n-\nDerive two Markov chain models:\n- '+' model: from the CpG islands\n- '-' model: from the remainder of sequence\n-\nTransition probabilities for each model:\n\nt'\nst'\nst\nst\nc\nc\na\n\nst\nc\nis the number of times\nletter t followed letter s\ninside the CpG islands\n+\nA\nC\nG\nT\nA\n.180\n.274\n.426\n.120\nC\n.171\n.368\n.274\n.188\nG\n.161\n.339\n.375\n.125\nT\n.079\n.355\n.384\n.182\nA\nT\nG\nC\naG\nT\naA\nC\naGC\naAT\n\nt'\nst'\nst\nst\nc\nc\na\n\nst\nc\nis the number of times\nletter t followed letter s\noutside the CpG islands\n-\nA\nC\nG\nT\nA\n.300\n.205\n.285\n.210\nC\n.322\n.298\n.078\n.302\nG\n.248\n.246\n.298\n.208\nT\n.177\n.239\n.292\n.292\n\n6: Unsupervised learning\nEstimate model parameters\nbased on unlabeled training data\n\nUnlabelled Data\nP\nB\nP\nB\nP\nB\nB\nP\nB\nB\nP\nB\nP\nB\nG\nC\nA\nA\nA\nT\nG\nC\nL:\nS:\nHow do we know how to count?\nA:\nT:\nG:\nC:\nA:\nT:\nG:\nC:\nP(S|P)\nP(S|B)\nP(Li+1|Li)\nBi+1 Pi+1 End\nBi\nPi\n?\nStart\nEnd\nstart\nP\nP\n?\n\nUnlabeled Data\nAn idea:\n1. Imagine we start with some parameters\n2. We could calculate the most likely path,\nP*, given those parameters and S\n3. We could then use P* to update our\nparameters by maximum likelihood\n4. And iterate (to convergence)\nP\nB\nP\nB\nP\nB\nB\nP\nB\nB\nP\nB\nP\nB\nG\nC\nA\nA\nA\nT\nG\nC\nL:\nS:\nP(S|P)0\nP(S|B)0\nP(Li+1|Li)0\nEnd\nstart\nP\nP\nP(S|P)1\nP(S|B)1\nP(Li+1|Li)1\nP(S|P)2\nP(S|B)2\nP(Li+1|Li)2\nP(S|P)K\nP(S|B)K\nP(Li+1|Li)K\n...\nB\nB\nB\nB\nB\nB\nB\nB\nB\nB\nB\nB\nB\nP\nP\nP\n\nLearning case 2.\nWhen the right answer is unknown\nWe don't know the true Akl, Ek(b)\n\nIdea:\n- We estimate our \"best guess\" on what Akl, Ek(b) are\n(M step, maximum-likelihood estimation)\n- We update the probabilistic parse of our sequence,\nbased on these parameters (E step, expected\nprobability of being in each state given parameters)\n- We repeat\n\nTwo settings:\n- Simple: Viterbi training (best guest = best path)\n- Correct: Expectation maximization (all paths, weighted)\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n7. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\nSimple casae: Viterbi Training\nInitialization:\nPick the best-guess for model parameters\n\n(or arbitrary)\nIteration:\n1. Perform Viterbi, to find *\n2. Calculate Akl, Ek(b) according to * + pseudocounts\n3. Calculate the new parameters akl, ek(b)\nUntil convergence\nNotes:\n-\nConvergence to local maximum guaranteed. Why?\n-\nDoes not maximize P(x | )\n-\nIn general, worse performance than Baum-Welch\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\nExpectation Maximization (EM)\nEM pervasive in computational biology\nRec 3 (SiPhy), Lec 8 (Kmeans), Lec 9 (motifs)\nThe basic idea is the same:\n\n1.Use model to estimate missing data (E step)\n2.Use estimate to update model (M step)\n3.Repeat until convergence\n\nEM is a general approach for learning models\n(ML estimation) when there is \"missing data\"\nWidely used in computational biology\n\n1. Initialize parameters randomly\n\n2. E Step Estimate expected probability of hidden labels, Q, given current\n(latest) parameters and observed (unchanging) sequence\n\n3. M Step Choose new maximum likelihood parameters over\nprobability distribution Q, given current probabilistic label assignments\n\n4. Iterate\nExpectation Maximization (EM)\n(\n| ,\n)1\nQ P Labels S paramst\n\nargmax\nlog ( ,\n|\n)\nt\nt\nQ\nparams\nparams\nE\nP S labels params\n\nP(S|Model) guaranteed to increase each iteration\n\nCase 2.\nWhen the right answer is unknown\nStarting with our best guess of a model M, parameters :\n\nGiven x = x1...xN\n\nfor which the true = 1...N is unknown,\n\nWe can get to a provably more likely parameter set\n\nPrinciple: EXPECTATION MAXIMIZATION\n\n1. Estimate probabilistic parse based on parameters (E step)\n2. Update parameters Akl, Ek based on probabilistic parse (M step)\n3. Repeat 1 & 2, until convergence\n\nEstimating probabilistic parse given params (E step)\nTo estimate Akl:\n\nAt each position i:\n\nFind probability transition kl is used:\n\nP(i = k, i+1 = l | x) = [1/P(x)] P(i = k, i+1 = l, x1...xN) = Q/P(x)\n\nwhere Q = P(x1...xi, i = k, i+1 = l, xi+1...xN) =\n\n= P(i+1 = l, xi+1...xN | i = k) P(x1...xi, i = k) =\n\n= P(i+1 = l, xi+1xi+2...xN | i = k) fk(i) =\n\n= P(xi+2...xN | i+1 = l) P(xi+1 | i+1 = l) P(i+1 = l | i = k) fk(i) =\n\n= bl(i+1) el(xi+1) akl fk(i)\n\nfk(i) akl el(xi+1) bl(i+1)\nSo:\nP(i = k, i+1 = l | x, ) = ------------------\n\nP(x | )\n(For one such transition, at time step ii+1)\nP\nB\nP\nB\nP\nB\nB\nP\nB\nB\nP\nB\nP\nB\nG\nC\nA\nA\nA\nT\nG\nC\nL:\nS:\nEnd\nstart\nP\nP\nB\nP\nK\nL\ni\nj\n\nNew parameters given probabilistic parse (M step)\nSo,\n\nfk(i) akl el(xi+1) bl(i+1)\nAkl = i P(i = k, i+1 = l | x, ) = i -----------------\n\nP(x | )\n\nSimilarly,\n\nEk(b) = [1/P(x)] {i | xi = b} fk(i) bk(i)\n(Sum over all kl transitions, at any time step i)\n\nDealing with multiple training sequences\n(Sum over all training seqs, all kl transitions, all time steps i)\nIf we have several training sequences, x1, ..., xM, each of length N,\n\nfk(i) akl el(xi+1) bl(i+1)\nAkl = x i P(i = k, i+1 = l | x, ) = x i ----------------\n\nP(x | )\n\nSimilarly,\n\nEk(b) = x (1/P(x)) {i | xi = b} fk(i) bk(i)\n\nThe Baum-Welch Algorithm\nInitialization:\n\nPick the best-guess for model parameters\n\n(or arbitrary)\n\nIteration:\n1.\nForward\n2.\nBackward\n3.\nCalculate new log-likelihood P(x | ) (E step)\n4.\nCalculate Akl, Ek(b)\n5.\nCalculate new model parameters akl, ek(b) (M step)\n\nGUARANTEED TO BE HIGHER BY EXPECTATION-MAXIMIZATION\n\nUntil P(x | ) does not change much\n\nThe Baum-Welch Algorithm - comments\nTime Complexity:\n\n# iterations O(K2N)\n\n- Guaranteed to increase the log likelihood of the model\n\nP( | x) = P(x, ) / P(x) = P(x | ) / ( P(x) P() )\n\n- Not guaranteed to find globally best parameters\n\nConverges to local optimum, depending on initial conditions\n\n- Too many parameters / too large model:\nOvertraining\n\n1. Scoring x, one path\n\nP(x,π)\n\nProb of a path, emissions\n\n2. Scoring x, all paths\n\nP(x) = Σπ P(x,π)\n\nProb of emissions, over all paths\n3. Viterbi decoding\n\nπ* = argmaxπ P(x,π)\n\nMost likely path\n4. Posterior decoding\n\nπ^ = {πi | πi=argmaxk ΣπP(πi=k|x)}\n\nPath containing the most likely\nstate at any time point.\nOne path\nAll paths\nDecoding\nScoring\nLearning\n5. Supervised learning, given π\n\nΛ* = argmaxΛ P(x,π|Λ)\n6. Unsupervised learning.\n\nΛ* = argmaxΛ maxπP(x,π|Λ)\n\nViterbi training, best path\n6. Unsupervised learning\n\nΛ* = argmaxΛ ΣπP(x,π|Λ)\n\nBaum-Welch training, over all paths\n\nExamples of HMMs for genome annotation\nDetection\nof GC-rich\nregions\nDetection\nof CpG-rich\nregions\nDetection\nof\nconserved\nregions\nDetection\nof protein-\ncoding\nexons\nDetection\nof protein-\ncoding\nconservatio\nn\nDetection\nof protein-\ncoding\ngene\nstructures\nDetection\nof\nchromatin\nstates\n2 states,\ndifferent\nnucleotide\ncomposition\n8 states,\n4 each +/-,\ndifferent\ntransition\nprobabilities\n2 states,\ndifferent\nconservation\nlevels\n2 states,\ndifferent tri-\nnucleotide\ncomposition\n2 states,\ndifferent\nevolutionary\nsignatures\n~20 states,\ndifferent\ncomposition/\nconservation\n, specific\nstructure\n40 states,\ndifferent\nchromatin\nmark\ncombination\ns\nGC-rich / AT-\nrich\nCpG-rich /\nCpG-poor\nConserved /\nnon-\nconserved\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nCoding exon\n/ non-coding\n(intron or\nintergenic)\nFirst/last/mid\ndle coding\nexon,UTRs,\nintron1/2/3,\nintergenic,\n*(+/- strand)\nEnhancer /\npromoter /\ntranscribed /\nrepressed /\nrepetitive\nNucleotides\nDi-\nNucleotides\nLevel of\nconservation\nTriplets of\nnucleotides\n64x64 matrix\nof codon\nsubstitution\nfrequencies\nCodons,\nnucleotides,\nsplice sites,\nstart/stop\ncodons\nVector of\nchromatin\nmark\nfrequencies\n\nWhat have we learned ?\n- Generative model. Hidden states, observed emissions.\n- Generate a random sequence\n- Choose random transition, choose random emission (#0)\n- Scoring: Finding the likelihood of a given sequence\n- Calculate likelihood of annotated path and sequence\n- Multiply emission and transition probabilities (#1)\n- Without specifying a path, total probability of generating x\n- Sum probabilities over all paths\n- Forward algorithm (#3)\n- Decoding: Finding the most likely path, given a sequence\n- What is the most likely path generating entire sequence?\n- Viterbi algorithm (#2)\n- What is the most probable state at each time step?\n- Forward + backward algorithms, posterior decoding (#4)\n- Learning: Estimating HMM parameters from training data\n- When state sequence is known\n- Simply compute maximum likelihood A and E (#5a)\n- When state sequence is not known\n- Viterbi training: Iterative estimation of best path / frequencies (#5b)\n- Baum-Welch: Iterative estimation over all paths / frequencies (#6)\n\nGoals for today: HMMs, part II\n1. Review: Basics and three algorithms from last time\n- Markov Chains and Hidden Markov Models\n- Calculating likelihoods P(x,π) (algorithm 1)\n- Viterbi algorithm: Find π* = argmaxπ P(x,π) (alg 3)\n- Forward algorithm: Find P(x), over all paths (alg 2)\n2. Increasing the 'state' space / adding memory\n- Finding GC-rich regions vs. finding CpG islands\n- Gene structures GENSCAN, chromatin ChromHMM\n3. Posterior decoding: Another way of 'parsing'\n- Find most likely state πi, sum over all possible paths\n4. Learning (ML training, Baum-Welch, Viterbi training)\n- Supervised: Find ei(.) and aij given labeled sequence\n- Unsupervised: given only x annotation + params\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "6.047 Computational Biology, Scribing Guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-047-computational-biology-fall-2015/dffa778a716dadc0a794a1983abb7d15_MIT6_047F15_scribingguide.pdf",
      "content": "6.047/6.878/HST.507 Scribing Guide\nMichal Grzadkowski (2015)∗\nScribing lectures is an essential part of the course as your contributions are incorporated into the course textbook\neach year. While the current text is quite mature in some sections, needing only minor edits, other sections may\nrequire more extensive work or may be missing altogether as the course contents change.\nRequirements\nEach of you will scribe one lecture which corresponds roughly to one chapter of the textbook. You will edit\nsource files in a Dropbox directory which we will share with you to complete your task. The specifics will depend\non the state of the current notes. Your goal is to make the notes a more useful resource both for your current\nclassmates and for future students.\nBy 10PM, 6 days after the lecture you scribed, submit a short response on\ndetailing:\n1. What changes did you make to the notes from previous years?\n2. What did you spend the most time on?\n3. What materials did you use as sources of information (slides/audio/transcripts/recitation notes/outside\nreferences)?\n4. If there were multiple scribes, how did you divide up the work?\nGuidelines\n2.1\nBefore the lecture\nBefore the lecture, contact the course staff to get access to the book source code on Dropbox. You should\ncarefully review the chapter that you will be improving, as well as past lecture slides and audiovisual material.\nSome questions to think about are:\n- Is the background and motivation for the problem we are studying clearly conveyed?\n- Do the sections divide the material into logical parts?\n- Does the text flow and build up ideas in a logical order?\n- Are figures and legends clear? Are equations and notation properly defined?\n- Is current research, if mentioned, properly cited?\n- Are there items marked TODO?\n∗ adapted from material by Anna Shcherbina (2011), Rachel Sealfon (2012), Max Wolf (2013), and Abhishek Sarkar (2014)\nthe course website\n\n2.2\nDuring the lecture\nAs you attend lecture, you should pay particular attention to issues that the slides and existing notes don't\nconvey well, and to new material that is not covered in the existing notes. Some questions to think about are:\n- Is any material in the lecture not covered in the notes?\n- Were equations/algorithms more clearly explained during lecture than in the notes?\n- Are there assumptions or exceptions to a statement that were not clear in the notes?\n- Were there insightful questions or interesting digressions in the lecture?\n- Were there any common misunderstandings or points of confusion?\nNote that some of the material for a chapter may be covered in recitation rather than in lectures.\n2.3\nAfter the lecture\nAdd to or edit the text to address the issues you noted before the lecture and points you noted during the\nlecture as described below.\nYou should make sure to include in your scribe notes any new lecture material that the notes do not cover (you\nmay want to check other chapters of the book to be sure that the material is not covered elsewhere). You\nshould also be sure that all material in the lecture is clearly explained in your final draft, and add to the chapter\nany particularly insightful questions and responses that come up in lecture.\nYou may also decide to rework sections of the chapter for clarity, restructure the chapter to improve its flow,\nimprove figures to make them clearer and more visually appealing, rework and expand figure legends, create or\nsuggest additional tables or figures for the chapter, or add infoboxes containing worked example problems or\nsummaries of recent publications.\nIf you are writing a new chapter, we will provide the following outline:\n1. Introduction\n2. (Sections for the main points of the lecture, at your discretion)\n3. Current Research Directions\n4. Further Reading\n5. Tools and Techniques\n6. Current Research Directions\n7. What Have We Learned?\nWe expect the introduction, main points of the lecture, and \"What Have We Learned?\" to be covered, and\nrelevant figures from the lecture slides included. You are welcome to write other sections, especially if you have\nprior knowledge or more interest in the topic.\nHow to format your scribe notes using LATEX\nThere are many online resources for learning LATEX. We recommend http://en.wikibooks.org/wiki/LaTeX\nas a starting point.\n\n3.1\nLayout of the book source directory\nThe Dropbox directory contains two subdirectories. templates/ contains macros which you do not need to\nmodify. The 2015 directory contains one subdirectory per lecture, for example Lecture01 IntroAndOverview.\nEach contains the text, figures, and references for that chapter of the book. In this case, the text for the chapter\nis in Lecture01 IntroAndOverview.tex, the references are in Lecture01 IntroAndOverview.bib, and the\nfigures are in the directory images/. Lecture01 IntroAndOverview standalone.tex and a Makefile are\nprovided for testing purposes. Other files (if any) are auxiliary files generated during the compilation of the\nbook.\n3.2\nMacros you should use\nWe provide several pre-defined macros which you should use as appropriate.\n\\mainword This boldfaces the most important word in the paragraph. Please use this tag to mark the most\nimportant word in each paragraph. For example:\n\\mainword{important word}\nproduces:\nimportant word\n\\todo This macro denotes tasks for the scribe and/or other students. The format is as follows:\n\\todo[Who should do this task (optional)]{Type of task (see below)}{Your instructions about what needs\nto be done}.\nThe second argument, \"type of task\", should be one of the following:\n1. missing: Information that is missing from the scribe notes.\n2. expand: Add more information about a certain topic. Fill in an empty/ incomplete section of the\nnotes.\n3. clarify: Indicates that something in the scribe notes is confusing.\n4. reference: Add a reference to the bibliography, citing the source of a piece of information.\n5. incorrect: Point out erroneous/out-dated information in the scribe notes.\n6. editing: Indicates a typo or a problem with formatting.\nFor example:\n\\todo[MyName]{Reference}{What is the source of this information?}\nproduces:\nTODO: Reference @MyName: What is the source of this information?\nAnd the more generic form:\n\\todo{Reference}{What is the source of this information?}\nproduces:\nTODO: Reference @scribe: What is the source of this information?\n\n\\sidenote This macro should be used to hold side-notes and digressions that were presented in lecture.\nFor example:\n\\sidenote{ This is an example of a sidenote }\nproduces:\nDid You Know?\n.\nThis is an example of a sidenote\n\\faq This macro should be used to hold questions and answers that came up during lecture.\nFor example:\n\\faq{What does the acronym DNA represent?}{ DNA refers to deoxyribonucleic acid}\nproduces:\nFAQ\nQ: What does the acronym DNA represent?\nA: DNA refers to deoxyribonucleic acid\n\\hilight This macro is used to highlight text for emphasis.\nFor example:\n\\hilight{important text!!}\nproduces:\nimportant text!!\n\\keyword This macro is used to point out a key word, which will be used in creating an index.\nFor example:\n\\keyword{Dynamic Programming}\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.047 / 6.878 / HST.507 Computational Biology\nFall 2015\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}