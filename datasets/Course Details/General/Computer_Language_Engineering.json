{
  "course_name": "Computer Language Engineering",
  "course_description": "This course analyzes issues associated with the implementation of higher-level programming languages. Topics covered include: fundamental concepts, functions, and structures of compilers, the interaction of theory and practice, and using tools in building software. The course includes a multi-person project on compiler design and implementation.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Programming Languages",
    "Software Design and Engineering",
    "Engineering",
    "Computer Science",
    "Programming Languages",
    "Software Design and Engineering"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: up to 4 sessions / week, 1 hour / session\n\nCourse Description\n\nThis course analyzes issues associated with the implementation of higher-level programming languages. Topics covered include: fundamental concepts, functions, and structures of compilers, the interaction of theory and practice, and using tools in building software. The course includes a multi-person project on compiler design and implementation.\n\nPrerequisites\n\n6.170 and proficiency in Java\n\nTextbooks\n\nThere are no required texts. Optional references:\n\nAppel, Andrew.\nModern Compiler Implementations in Java (Tiger Book)\n. 2nd ed. New York, NY: Cambridge University Press, 2002. ISBN: 9780521820608.\n\nMuchnick, Steven.\nAdvanced Compiler Design and Implementation (Whale Book)\n. San Francisco, CA: Morgan Kaufmann, 1997. ISBN: 9781558603202.\n\nCalendar\n\nThe calendar below includes lectures (L), recitations (R), projects (P), and quizzes (Q).\n\nSA = Prof. Saman Amarasinghe\n\nMR = Prof. Martin Rinard\n\nWEEK #\n\nDAY 1\n\nDAY 2\n\nDAY 3\n\nDAY 4\n\nL1: Course administration, information and overview (SA)\n\nL2: Regular expressions, language specification by formal grammars (MR)\n\nP1: Scanner/parser project assigned\n\nR1: Project information session\n\nL3: Bottom-up parsing (MR)\n\nL4: Top-down parsing (MR)\n\nL5: Intermediate representations (MR)\n\nL6: Semantic analysis (SA)\n\nP1: Scanner/parser project due\n\nP2: Semantic checker project assigned\n\nR2: Project information session\n\nP2: Semantic checker project due\n\nP3: Code generator project assigned\n\nL7: Unoptimized code generation (MR)\n\nR3: Project information session\n\nL8: Unoptimized code generation (MR)\n\nQ1: In-class quiz\n\nP3: Code generator project design due\n\nP3: Code generator project due\n\nP4: Data-flow analysis project assigned\n\nL9: Introduction to program analysis (MR)\n\nR4: Project information session\n\nL10: Data-flow analysis (MR)\n\nL11: Data-flow optimizations (MR)\n\nL12: Foundations of data-flow analysis (MR)\n\nP4: Data-flow analysis project due\n\nP5: Optimizer project assigned\n\nQ2: In-class quiz\n\nL13: Introduction to code optimization (SA)\n\nL14: Instruction scheduling (SA)\n\nR5: Project information session\n\nL15: Instruction optimization (SA)\n\nL16: Register allocation (SA)\n\nL17: Parallelization (SA)\n\nL18: Loop optimization (SA)\n\nP5: Optimizer project design due\n\nL19: Putting it all together (SA)\n\nL20: Discussion of research topics in compilers (SA/MR)\n\nP5: Optimizer project checkpoint due\n\nQ3: In-class quiz\n\nP5: Optimizer project due\n\nL21: Compiler derby (SA)",
  "files": [
    {
      "category": "Exam",
      "title": "MIT6_035S10_quiz01.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/1f4a25b1b92e47b9233add2bea19c8e2_MIT6_035S10_quiz01.pdf",
      "content": "6.035 Practice Quiz 1\n1. Give a Regular Expression and DFA for:\nL = {x ∈{0, 1}∗ | x ends with 1 and does not contain the substring 00}\n2. Give a RE for: L = {0i1j | i is even and j is odd }\n3. Given the NFA for below for 0∗(01)∗0∗, construct a DFA:\nε\nε\nA\nB\nD\nC\n4. Give a RE and a DFA/NFA for the language of all strings over {0, 1}∗ that do not end\nin 01.\n5. Give a RE and a CFG for:\nL = {x ∈{0, 1}∗ | x starts and ends with different symbols }\n6. Give a CFG for:\nL = {x ∈{0, 1}∗ | symbol at position i is same as symbol at position i+2 and | x |≥ 2}\n7. Give a CFG for the language of all non-palindromes over {0, 1}∗.\n8. Give a CFG for:\nL = {0i1j 0k | j > i + k} So, 001111100 is in the string. Hint, the concatenation of two\n(or more) context-free languages is context-free.\n9. Eliminate left recursion from:\nS\nAa\nb\n→\n|\nA\nAc\nSd ε\n→\n|\n|\n10. Give a CFG for L = {aibici | i ≥ 1}.\n11. Is this grammar ambiguous? If so, prove it and construct a non-ambiguous grammar\nthat derives the same language.\nS\naS aSbS c\n→\n|\n|\n\n12. Assume that we have added a pointer type to decaf that can point to integers and\nbooleans. We want to extend our type system (our attributed grammar) to handle\nthese types. We have added a pointer(t) type to the type system to denote a pointer of\ntype t. Complete the semantic action that propagates the type attribute for a pointer\ndeference expression: E →∗E1\n{: E.type = ???? :}\nAnswers\n1. (1 | 01)+\n0,1\n2. (00)∗1(11)∗\n3. DFA:\n0,1\nABCD\nBD\nCD\nD\nABD\n4. ε | 0 | 1 | (0 | 1)∗(11 | 00 | 10)\n\n5. [a(a | b)∗b]|[b(a | b)∗a]\nS\naAb bAa\n→\n|\nA\naA\nbA\nε\n→\n|\n|\n6. S\nA\nB\nC\nD\n→\n|\n|\n|\nA\n00A 00\n→\n|\nB\n11B 11\n→\n|\nC\n10C 10\n→\n|\nD\n01D 01\n→\n|\n7. S\n0S0\n1S1 D\n→\n|\n|\nD\n1A0\n0A1\n→\n|\nA\nε 0A 1A\n→ |\n|\n8. S\nABC\n→\nA\n0A1 ε\n→\n|\nB\n1B 1\n→\n|\nC\n1C0 ε\n→\n|\nL is a concatenation of L1L2L3 where L1 = {0i1i | i ≥ 0}, L2 = {1m | m > 0}, and\nL3 = {1k0k | k ≥ 0}.\n9. S\nAa\nb\n→\n|\nA\nbdA1 A1\nA1\n→\n|\n→ cA1 | adA1|ε\n10. Trick question, the language is not context-free. Sorry!\n11. It is ambiguous! aacbc has two parse trees (not pictured, but you have to show the\ntwo parse trees to prove it is ambiguous).\n\nUnambiguous grammar:\nS\nT\nU\n→\n|\nT\naTbT c\n→\n|\nU\naS aT bU\n→\n|\n12. E →∗E1 {E.type := if E1.type = pointer(t) then t else type error;}\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "MIT6_035S10_quiz02_2006.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/76adde99717349aeedc81df448d49c65_MIT6_035S10_quiz02_2006.pdf",
      "content": "j\nj\n\nj\n\n!\"#$%!\n\"&''''''''''''''''''''''''''''''''''''''''''\n*( &'''''''''''''''''''''''''''''''''\n\n!\n!\n\"#\n$ ! % % %\nE\n\n&\n%'&\n\n! &&\n\n()\n\n)\n\n*\n\n+\n+\n\n,\n\n,\n\n,\n%\n\n))\n,\n\n*\n\n,\n)\n\n))\n\n)\n)\n\n)\n\n)+\n\n)\nj\n\n*Athena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\nj\n\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n\nj\njjjj\n\n)\n-\n#\n\nj j\n\njjj\n\njjjjj jjjj^÷jjjjjj\nj j÷jj jjjj\njj\n\nj j\njj\n\n% !\njj\njj\nj\n\nj\n\nj\njj\n\nj\nVj\njj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\njj\njj\nj\n\nj\n\nj\njj\n\nj\nVj\nj j\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\njj\njj\nj\n\nj\n\nj\njj\n\nj\nVj\nj!j\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\njj\njj\nj\n\nj\n\nj\njj\n\nj\nVj\nj\"j\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\njj\njj\nj\n\nj\n\nj\njj\n\nj\nVj\nj#j\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n\nj\nj$jjj\nj\n\nj\nj\n\nj\nj\n\n./\n\n*\n\nj\nj j\n\nj%j\n0A$10A0 11\n& jj jj 'j\nj\n\n!& &!\n\n! &\n! *\n+\n!\n\n&\n\n�\n�\n\n�\n�\n\n�\n�\n\n��\n\n�\n�\n\n�\n�\n\nj\nj(jjj\n\nj\nj\nj\n2 )\n0)1\n$2\n2 3 $ 01\n0+1\n2 3 $ 01\n0)1\n2 3\n0%1\n$2 3 $ 0,1\n2 3\n0*1\n2 3 0)1\n2 3 ) 0))1\n2 3 $ 0)1\n\n0)+1\n(\n\n)&0\n\n))!7\n$ 1\n\n+\n\nj jj\nj\nj jV!)*jjj\njV)jj\n\nj\njj jjjjj j jjjj\nj\n+ j\njjj!jjjj jjjjj\nj\n+ j\nj jj!jjjj jjjjj\nj\n+ j\nj\"jj#jjjj jjjjj\nj\n+ j\nj#jj)jjjj jjjjj\nj\n\nj\nj,jjj\nj\n\n(#\n$9\n\n,\n\n& j%jj\n\njj jjj jj\nj\"jj)jj\n,\n%\n!!\n\n,\nj\n.j j j/jj j\n.j\nj\nj\nj\nj\nj\n.j j .j\nj\nj\nj\nj\nj\n\n,\n\njjj0j\nj\nj\n\njj\"j!j#\njj j!)*jj)j÷j j\nj\n\njj\njjj\njj\njj%1jjj\n& &\n\n!\n\n,\n\nj\nj\nj\nj j\nj j\nj j\nj\nj\nj\nj\nj\nj\nVj j Vj\nj\nV$j\nj\nV,j\nj\nj\nj\nj\nj\nj\nj\nVj j Vj\nj\nVj\nj\nVj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n\n+\n-\n\n,\n\n& jj j jjj jjj jj\nj\"jj)jj\n\n!\n\n%\n!!\n\n, &\n\nV-j\nVj\nVj\n\nj\njjjj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj j\nj\n\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n\n%\n:\n\n))\n\njjj2 j\"j\nj\n\njj!jjj j!)*jj)jj\njjjj\njjj\njj j3jj j'\nj!)*jj)jj\n& &\n\n,\n\nj\nj Vj\nj\nj\nj j V-j j\nj\nj Vj\nj\nj\nj\nj V-j j\nj\nj Vj\nj\nj\nj\nj Vj j\nj\nj Vj\nj\nj\nj\nj Vj j\nj\nj Vj\nj\nj\nj j Vj j\nj\nj Vj\nj\n\n,\n:\n\nj jj!jjjj4j÷jjj\nj\n÷j!j\n÷j\"j!j#\nj\nj1j!jjjj\nj\nj\njjjjj jj!jjj\n& &\n\nj\n\n*\n.$9\n\n,\n\njjj\n\nj#%j\nj\n\njj!j%j#\nj\nj\nj j!)*jj)j÷j j%jjj\nj\nj j3jj j'\nj!)*jjj)jj\n- &\n\n!\n,\n\n.\n!\n\n%/01\n.j j V$j\nj\nj\n.j j Vj\nj\n.j j Vj\nj\nj\n.j j Vj\nj\n.j j Vj\nj\nj\n.j j Vj j\n\nj\njjjj\nj\nj\nj\nj\nj\nj\nj\nj\n\nj\n;\nj\nj\n\nj\nj\nj\nj\nj\nj\nμ\nμ\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n)\n)\n\n)\n\n%\n;\n\n)\n\n:\n\n& jj j\n\njjjj\nj\nj\n/ %\n\njjj\n+ jjj\n\nj\njjjjjj1jj\n)\n\n%\n+\n;\n;\n;\n;\n;\n<!=\n<!)=\n<)!=\nj j\n<!=\n<)!)=\n<!=\n<)!=\n<!)=\n/\n\n;\n/)\n)\n;\nj\n<!=\n\nj\njjjj\nj\nj\nj\nj\nj\nj\nj\nj\n\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n&j jjjjjjj\"j\n\nj +1j+ jjjj j +jj\nj\nj jjj÷j jjjjj1jj)j%\nj\n\n+ j\njj\n\njj j +jjjjj\"÷j52jj1j\n\nj j jjj\nj jjjj1j+ j%jj jj\ni j jjjj j j jj\njj jjj j\njj÷j jj j\n\njj\ni j jjjjj j\nj jjj ÷j jj%j j j jj\nj\nj j jjjjj\ni j jjjjj j\nj jjj\n÷j jj j j jj\njj\njj j jjjjj\njj2÷j jjjjjj2jjj÷j j\njj2jjjjjjjjj j\n1j\n&j jj jj\nj j jjjj jj3jj\n\njj1j\n+ jjjj j\njj j\njjj1jjjjjj\n\nj j\n%j1j&j jjjj j0 j\nj jj\n\nj jjjj j\nj\njj j\njj jj1jj&j\njjj j\njj jj j%'\nj\njjj jjj\njjj +1j\n+ j j0 j\njjjj\nj\n1j\n\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n\nj\njjjj\n\n))\n\n)\n\n&jj\njj jj\nj\njjj\n1jjj j'\nj\n÷jj j\nj÷jj jjjjj\njjj\n1jj\"j j\njjj j\n\nj\njjj\nj\n1j\n\n)\n\n&jj\njj jj\nj\nj1jjjjjj j\nj\njjjjj\n%'÷j jj j\nj\njj j6 ,÷j j ,jj j\nj%j1jjj jj\njj\njj ,1j\nj\nj\n6%j7jj\n\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\nj\n\nj\nj-jjj\n\n)\n\njjjj jjjjVjj3jjjjjj\nj\njj j\njj j\nj\n1jj)jjj\n÷jjjjj jj\n\njjjj j58+j\n1÷\n5j\njj\nj j jj\njj jj\njj\nj 1jj\n)j jj÷jj\nP2jjj\n& jj jjjjj jj\njj\njj.2jj j\njj\n\nj.$\n/\n&\n)V58+6jj7jV58+6÷j.2j\n)V58+6jj7jV.$÷jV58+6÷j.2j\n)V58+6jj7jV58+6÷j.2j'j.$j\n)V58+6jj7jV.2÷jV58+6÷j.$j\n)V58+6jj7j.$j9j.2j.j58+6j\n\n)+\n0>\n1?\n\n÷jj jj\njj\njjj\nj\n1jj*jj\nj j\n\nj\nj÷j jj j\njVjjjj\n/\n&\n\nO\ny\na\n< (\n\nj\n\nj\njjjj\n2)\n0)1\n$2\n23$ 01\n0+1\n23$ 01\n0)1\n23 0%1\n$23$ 0,1\n0*1\n23 0)1\n23) 0))1\n23$ 0)1\n\n0)+1\n(\n\n)jj\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "MIT6_035S10_quiz02_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/0be6a79d895d91160095f733b98bd905_MIT6_035S10_quiz02_sol.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.035, Fall 2006\nPractice Quiz 2 and Solutions\nSaturday, November 4\n1. For the basic block:\nq = 3\nr = 10\ns = q + r\nt = 2*r+s\nt = q\nu = q + r\nv = q + t\nw = 3 + x\nState for each of the basic blocks on the following page which optimization was performed on\nthe above:\n- Constant Propagation/Folding\n- Copy Propagation\n- Common Subexpression Elimination\n- Dead Code Elimination.\n\nName:\n(a) q = 3\nr = 10\ns = q + r\nt1 = s\nt = 2*r+s\nt = q\nu = t1\nv = q + t\nw = 3 + x\nCSE\n(b) q = 3\nr = 10\ns = q + r\nt = 2*r+s\nt = q\nu = q + r\nv = q + q\nw = 3 + x\nCopy Propagation\n(c) q = 3\nr = 10\ns = 13\nt = 33\nt = 3\nu = 13\nv = 36\nw = 3 + x\nConstant Propagation\n(d) q = 3\nr = 10\ns = q + r\nt = q\nu = q + r\nv = q + t\nw = 3 + x\nDead Code Elimination\n\nName:\n2. In class we discussed available expression dataflow analysis. Recall that an expression e is\navailable at point p if:\n- Every path from the initial node to p evaluates e before reaching p, and\n- There are no assignments to any operand of e after evaluation but before p.\nIn the table below, fill in the final values of IN obtained after performing available expression\nanalysis on the CFG of Figure 1 (next page). A '1' should indicate the expression is available\non entry to the block.\nB1\nB2\nB3\nB4\nB5\nB6\nB7\na + b\nc * d\ne / f\n\nName:\nEntry\nB1:\nq = a + b\nB2:\nr = e / f\nB3:\nB4:\ne = 2\nB5:\nf = 3\nt = c * d\nw = a + b\nB6:\nx = c * d\ny = e / f\na = 1\ns = e / f\nB7:\nz = e / f\nExit\nFigure 1: CFG for problem 2.\n\nName:\n3. Recall from lecture that a variable v is live at point p if:\n- v is used along some path starting at p, and\n- There is no definition of v along p before its use.\nIn the table below, fill in the final values of OUT obtained after performing liveness analysis\non the CFG of Figure 2 (next page). A '1' should indicate the variable is live on exit from\nthe block. Assume all variables are visible outside the procedure.\nb\nc\nB1\nB2\nB3\nB4\nB5\nB6\nB7\na\n\nName:\nEntry\nB1:\nc = 4\nB2:\na = b + c\nB3:\nc = a + b\nB4:\na = 5\na = 1\nB5:\nB6:\nb = 3\nb = 2\nB7:\nc = a + b\nExit\nFigure 2: CFG for problem 3.\n\nName:\n4. A compiler hacker writes an analysis to compute values of integer variables in a program. The\nhacker's analysis maintains a set for each variable at each program point, the set contains\nthe possible values for that variable. The hacker uses set union to combine values at the\ncontrol-flow join points.\nThe hacker tests the analysis on several acyclic control flow graphs and it is shipped in the\ncompiler. One of the customers tries to compile a program that contains a loop, and the\nanalysis fails to terminate. What is the problem?\nThe issue is that the lattice has infinite ascending chains and lacks a top element. (IE. We\ncan construct the chain of sets 0, 0,1, 0,1,2, 0,1,2,3....)\nDescribe the changes that the compiler hacker must make to fix the analysis.\nThe compiler hacker uses a widening operation to truncate the infinite ascending chains. This\nwould be done by bounding the sizes of the sets, and widening any sets over this size to the\ntop element.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "MIT6_035S10_quiz02.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/dc3257dfb73b9c4ada6f21b6ccb40c85_MIT6_035S10_quiz02.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.035, Fall 2006\nPractice Quiz 2\nSaturday, November 04\n1. For the basic block:\nq = 3\nr = 10\ns = q + r\nt = 2*r+s\nt = q\nu = q + r\nv = q + t\nw = 3 + x\nState for each of the basic blocks on the following page which optimization was performed on\nthe above:\n- Constant Propagation/Folding\n- Copy Propagation\n- Common Subexpression Elimination\n- Dead Code Elimination.\n\nName:\n(a) q = 3\nr = 10\ns = q + r\nt1 = s\nt = 2*r+s\nt = q\nu = t1\nv = q + t\nw = 3 + x\n(b) q = 3\nr = 10\ns = q + r\nt = 2*r+s\nt = q\nu = q + r\nv = q + q\nw = 3 + x\n(c) q = 3\nr = 10\ns = 13\nt = 33\nt = 3\nu = 13\nv = 36\nw = 3 + x\n(d) q = 3\nr = 10\ns = q + r\nt = q\nu = q + r\nv = q + t\nw = 3 + x\n\nName:\n2. In class we discussed available expression dataflow analysis. Recall that an expression e is\navailable at point p if:\n- Every path from the initial node to p evaluates e before reaching p, and\n- There are no assignments to any operand of e after evaluation but before p.\nIn the table below, fill in the final values of IN obtained after performing available expression\nanalysis on the CFG of Figure 1 (next page). A '1' should indicate the expression is available\non entry to the block.\na + b\nc * d\ne / f\nB1\nB2\nB3\nB4\nB5\nB6\nB7\n\nName:\nEntry\nB1:\nq = a + b\nB2:\nr = e / f\nB3:\nB4:\ne = 2\nB5:\nf = 3\nt = c * d\nw = a + b\nB6:\nx = c * d\ny = e / f\na = 1\ns = e / f\nB7:\nz = e / f\nExit\nFigure 1: CFG for problem 2.\n\nName:\n3. Recall from lecture that a variable v is live at point p if:\n- v is used along some path starting at p, and\n- There is no definition of v along p before its use.\nIn the table below, fill in the final values of OUT obtained after performing liveness analysis\non the CFG of Figure 2 (next page). A '1' should indicate the variable is live on exit from\nthe block. Assume all variables are visible outside the procedure.\na\nb\nc\nB1\nB2\nB3\nB4\nB5\nB6\nB7\n\nName:\nEntry\nB1:\nc = 4\nB2:\na = b + c\nB3:\nc = a + b\nB4:\na = 5\na = 1\nB5:\nB6:\nb = 3\nb = 2\nB7:\nc = a + b\nExit\nFigure 2: CFG for problem 3.\n\nName:\n4. A compiler hacker writes an analysis to compute values of integer variables in a program. The\nhacker's analysis maintains a set for each variable at each program point, the set contains\nthe possible values for that variable. The hacker uses set union to combine values at the\ncontrol-flow join points.\nThe hacker tests the analysis on several acyclic control flow graphs and it is shipped in the\ncompiler. One of the customers tries to compile a program that contains a loop, and the\nanalysis fails to terminate. What is the problem?\nDescribe the changes that the compiler hacker must make to fix the analysis.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "MIT6_035S10_quiz03_2009.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/8cc05fc001e42b4b4e50ef68ff8a4dbc_MIT6_035S10_quiz03_2009.pdf",
      "content": "Massachusetts Institute of Technology\n6.035 Computer Language Engineering\nSpring 2009\nQuiz 3\nThursday, April 30th, 2009\nName: __________________________________________\nThis quiz is open book, open notes. You have 55 minutes to complete it. It contains 17 questions in 9 pages\n(including this one), totaling 100 points. Before you start, please check your copy to make sure it is complete.\nPlease write neatly; we cannot give credit for what we cannot read.\nGood luck!\nof 4\nof 4\nof 4\nof 10\nof 6\nof 8\nof 4\nof 6\nof 4\nof 4\nof 6\nof 4\nof 4\nof 6\nof 8\nof 14\nof 4\nof 100\n\n6.035 Quiz 3\nPage 2 of 9\nConsider the following code for Questions 1 and 2.\nint c = 5;\nint d = 0;\nint e = 2;\nint f = 14;\nfor i=0 to N {\nint t = 0;\nfor j = 0 to N {\nt = t + c;\nx = t + e;\ny = c * e + 25;\nA[x] = y + j;\n}\nc = c + d;\nd = d + 2;\ne = 3 * d + f + 1;\n}\nQuestion 1.\nInduction Variables\n(4 Points)\nIdentify the basic and dependent induction variables for the inner loop.\nQuestion 2.\nInduction Variables\n(4 Points)\nIdentify the basic and dependent induction variables for the outer loop.\n\n6.035 Quiz 3\nPage 3 of 9\nConsider the following loop for Questions 3 and 4:\nmov $20, %rax\nmov A, %r15\nmov B, %r16\nmov C, %r17\nloop:\nmov (%r15, %rax), %r10\n# r10 = A[rax]\nimul %r17, %r10\n# r10 = r10*C\nmov (%r16, %rax), %r11\n# r11 = B[rax]\nadd %r11, %r10\n# r10 = r11 + r10\nmov %r10, (%r15, %rax)\n# A[rax] = r10\nsub $4, %rax\n# rax = rax - 4\njz loop\nAssume our target schedules instructions in-order and does not perform register renaming. It has one\nmemory unit and two ALU units. Assume that a mov is either a load or a store (neglect address\ncalculation). All three units are fully-pipelined. Instruction latencies:\nMemory:\nALU1 and ALU2:\nload = 2 cycles\nadd/sub/jz = 2 cycles\nstore = 2 cycles\nimul = 3 cycles\nQuestion 3.\nCycles\n(4 Points)\nHow many cycles are required for each iteration of the above loop?\nQuestion 4.\nUnrolling and Scheduling\n(10 Points)\nCreate a more efficient version of the loop by unrolling the loop once, removing any unnecessary\ndependencies, and rescheduling the instructions.\n\n6.035 Quiz 3\nPage 4 of 9\nConsider the following CFG for Questions 5-7:\nQuestion 5.\nWebs\n(6 Points)\nWe want to create the maximum number of webs for each variable in the code above. How many\nwebs can we create for each variable? Denote your webs on the code above by adding subscripts to\nall variable defs and uses. Use the same subscript for defs and uses in the same web.\na has _____ webs.\nb has _____ webs.\nc has _____ webs.\n\n6.035 Quiz 3\nPage 5 of 9\nQuestion 6.\nInterference Graph\n(8 Points)\nDraw the interference graph for the webs you defined in Question 5. Label the nodes of your graph\nwith the subscripted variable that the web represents.\nQuestion 7.\nColors\n(4 Points)\nWhat is the minimum number of colors needed to color your interference graph using the coloring\nheuristic given in class?\n\n6.035 Quiz 3\nPage 6 of 9\nj\nConsider the following loop nest for Questions 8 - 14.\nfor i=1 to n\nfor j=1 to n\nA[i, j] = A[i+1, j-1] + A[i-1, j]\nQuestion 8.\nDependences\n(6 Points)\nDraw the dependences between A[i, j] and A[i+1, j-1].\n...\ni\n.\n.\n.\nQuestion 9.\nDependence Type\n(4 Points)\nWhat is the type of dependence between A[i, j] and A[i+1, j-1]?\nTRUE\nANTI\nOUTPUT\nQuestion 10. Dependence Vector\n(4 Points)\nWhat is the dependence vector A[i, j] and A[i+1, j-1]?\n\n6.035 Quiz 3\nPage 7 of 9\nj\nQuestion 11. Dependences\n(6 Points)\nDraw the dependences between A[i, j] and A[i-1, j].\n...\ni\n.\n.\n.\nQuestion 12. Dependence Type\n(4 Points)\nWhat is the type of dependence between A[i, j] and A[i-1, j]?\nTRUE\nANTI\nOUTPUT\nQuestion 13. Dependence Vector\n(4 Points)\nWhat is the dependence vector A[i, j] and A[i-1, j]?\nQuestion 14. Parallelization\n(6 Points)\nSelect one:\na. Neither loop is parallelizable.\nb. The i loop is parallelizable.\nc. The j loop is parallelizable.\nd. Both loops are parallelizable.\n\n6.035 Quiz 3\nPage 8 of 9\nConsider the following code for Questions 15 - 17.\nint pow = 1;\nint tmp;\nint A[N];\n...\nfor I = 0 to N-1 {\ntmp = I * pow;\nA[I] = tmp + A[I+1];\npow = pow * 2;\n}\nQuestion 15. Parallelization\n(8 Points)\nExplain all the reasons why this loop is not parallelizable.\nQuestion 16. Parallelization\n(14 Points)\nRewrite the code so that a parallelizing compiler can efficiently compile the code to a multicore. You\ncan introduce new variables and code, but the values of the variables must be the same after the code\nexecutes. Mark the regions of your code that the parallelizing compiler will parallelize.\n\n6.035 Quiz 3\nPage 9 of 9\nQuestion 17. Parallelization\n(4 Points)\nIf you execute your modified loop on a single core machine, will it run faster or slower than the\noriginal loop? Why?\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec01.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/8dc4035e5495150d4c45b150c9196c01_MIT6_035S10_lec01.pdf",
      "content": "Spring 2010\nLecture 1: Introduction\nLecture 1: Introduction\nIntro. to Computer Language Engineering\nCourse Administration info\nCourse Administration info.\n\nOutline\nOutline\n- Course Administration Information\n- Course Administration Information\n- Introduction to computer language engineering\n- Why do we need a compiler?\n- What are compilers?\n- Anatomy of a compiler\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nCourse Administration\nCourse Administration\n- Staff\n- Staff\n- Optional Text\n- Course Outline\n- The Project\nj\n- Project Groups\n- Grading\nGrading\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nReference Textbooks\nReference Textbooks\n-\nModern Compiler Implementation in Java (Tiger book)\nA.W. Appel\nCambridge University Press, 1998\nA textbook tutorial on compiler\nimplementation, including\ntechniques for many language\nCambridge University Press, 1998\nISBN 0-52158-388-8\n-\nAdvanced Compiler Design and Implementation (Whale book)\nSteven Muchnick\ntechniques for many language\nfeatures\nEssentially a recipe book of\nti\ni\nti\nl t\nd\nSteven Muchnick\nMorgan Kaufman Publishers, 1997\nISBN 1-55860-320-4\n-\nCompilers: Principles Techniques and Tools (Dragon book)\noptimizations; very complete and\nsuited for industrial practitioners\nand researchers.\nTh\nl\ni\nil\nt\ntb\nk\n-\nCompilers: Principles, Techniques and Tools (Dragon book)\nAho, Lam, Sethi and Ullman\nAddison-Wesley, 2006\nISBN 0321486811\nThe classic compilers textbook,\nalthough its front-end emphasis\nreflects its age. New edition has\nmore optimization material.\n-\nEngineering a Compiler (Ark book)\nKeith D. Cooper, Linda Torczon\nMorgan Kaufman Publishers, 2003\nISBN 1 55860 698 X\nA modern classroom textbook,\nwith increased emphasis on the\nback-end and implementation\ntechniques\nISBN 1-55860-698-X\n-\nOptimizing Compilers for Modern Architectures\nRandy Allen and Ken Kennedy\ntechniques.\nA modern textbook that focuses\non optimizations including\nMor g an Kaufman Publishers, 2001\nISBN 1-55860-286-0\nparallelization and memory\nhierarchy optimization\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nThe Project: The Five Segments\nThe Project: The Five Segments\nLexical and Syntax Analysis\nLexical and Syntax Analysis\nSemantic Analysis\nCode Generation\nData-flow Analysis\nData flow Analysis\nOptimizations\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEach Segment...\nEach Segment...\n- Segment Start\n- Project Description\n- Lectures\n- 2 to 5 lectures\n- Project Time\n- (Design Document)\n(Design Document)\n- (Project Checkpoint)\n- Project Due\n- Project Due\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nProject Groups\nProject Groups\n- 1st project is an individual project\nproject is an individual project\n- Projects 2 to 5 are group projects consists of\n3 to 4 students\n- Grading\nAll\nb\n(\nl )\nh\nd\n- All group members (mostly) get the same grade\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nGrades\nGrades\n- Compiler project\n70%\n- Compiler project\n70%\n- In-class Quizzes\n30% (10% each)\n- In-class mini-quizzes\n10% (0.5% each)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nGrades for the Project\nGrades for the Project\n- Scanner/Parser\n5%\nS\nti Ch\nki\n7 5%\n- Semantic Checking\n7.5%\n- Code Generation\n10%\nD\nfl\nA\nl\ni\n7 5%\n- Data-flow Analysis\n7.5%\n- Optimizations\n30%\n60%\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\n-\nOptimization Segment\nOptimization Segment\n- Making programs run fast\nMaking programs run fast\n- We provide a test set of applications\n- Figure-out what will make them run fast\n- Prioritize and implement the optimizations\nPrioritize and implement the optimizations\n- Compiler derby at the end\n- A \"similar\" application to the test set is provided the day before\n- The compiler that produced the fastest code is the winner\nThe compiler that produced the fastest code is the winner\n- Do any optimizations you choose\n- Including parallelization for multicores\n- Grade is divided into:\n- Documentation\n6%\n- Justify your optimizations and the selection process\ny y\np\np\n- Optimization Implementation\n12%\n- Producing correct code\n- Derby performance\n12%\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nDerby performance\n12%\n30%\n\nThe Quiz\nThe Quiz\n- Three Quizzes\n- Three Quizzes\n- In-Class Quiz\n- 50 Minutes (be on time!)\n- Open book, open notes\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nMini Quizzes\nMini Quizzes\n- You already got one\n- You already got one.\n- Given at the beginning of the class; Collected at\nth\nd\nthe end\n- Collaboration is OK\n- This is in lieu of time consuming problem sets\nThis is in lieu of time consuming problem sets\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nOutline\nOutline\n- Course Administration Information\n- Course Administration Information\n- Introduction to computer language engineering\n- What are compilers?\n- Why should we learn about them?\n- Anatomy of a compiler\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nWhy Study Compilers?\nWhy Study Compilers?\n- Compilers enable programming at a high level\n- Compilers enable programming at a high level\nlanguage instead of machine instructions.\nMalleability Portability Modularity Simplicity\n- Malleability, Portability, Modularity, Simplicity,\nProgrammer Productivity\nAlso Efficiency and Performance\nAlso Efficiency and Performance\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCompilers Construction touches\nt\ni\ni\nC\nt\nS i\nmany topics in Computer Science\n- Theory\nFi i\nS\nA\nG\nd P\ni\nd\nfl\n- Finite State Automata, Grammars and Parsing, data-flow\n- Algorithms\n- Graph manipulation, dynamic programming\n- Data structures\n- Symbol tables, abstract syntax trees\n-\nSystems\nSystems\n- Allocation and naming, multi-pass systems, compiler construction\n- Computer Architecture\nM\nhi\nh\ni\nt\nti\nl\nti\ni t\nl\nk\nd l t\ni\nll li\n- Memory hierarchy, instruction selection, interlocks and latencies, parallelism\n-\nSecurity\n\n- Detection of and Protection against vulnerabilities\n- Software Engineering\n- Software development environments, debugging\n- Artificial Intelligence\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nArtificial Intelligence\n- Heuristic based search for best optimizations\n\nPower of a Language\nPower of a Language\n- Can use to describe any action\n- Can use to describe any action\n- Not tied to a \"context\"\nM\nt\nd\nib\nth\nti\n- Many ways to describe the same action\n- Flexible\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nHow to instruct a computer\nHow to instruct a computer\n- How about natural languages?\nHow about natural languages?\n- English??\n- \"Open the pod bay doors, Hal.\"\n\"I\nI\nf\nid I\nt d\nth t\"\n- \"I am sorry Dave, I am afraid I cannot do that\"\n- We are not there yet!!\n- Natural Languages:\n- Powerful, but...\n- Ambiguous\n- Same expression describes many possible actions\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nProgramming Languages\nProgramming Languages\n- Properties\n- need to be precise\n- need to be concise\n- need to be expressive\n- need to be at a high-level (lot of abstractions)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nHigh-level Abstract Description\nL\nl\nl I\nl\ni\nD\nil\nto Low-level Implementation Details\nPresident\nPresident\nGeneral\nSergeant\nSaman Amarasinghe\nFigure of a president, general, sergeant, and foot soldier.\n6.035\n(c)MIT Fall 1998\nFoot Soldier\nFigure by MIT OpenCourseWare.\nMy poll ratings are low,\nMy poll ratings are low,\nlets invade a small nation\nCross the river and take\ndefensive\npositions\ndefensive\npositions\nForward march turn\nleft\nForward march, turn left\nStop!, Shoot\n\n1. How to instruct the computer\n1. How to instruct the computer\n- Write a program using a programming language\n- Write a program using a programming language\n- High-level Abstract Description\n- Microprocessors talk in assembly language\n- Low-level Implementation Details\nProgram\nCompiler\nAssembly\nLanguage\nProgram\nwritten\nin a\np\nTranslation\nProgramming\nLanguages\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n1. How to instruct the computer\n1. How to instruct the computer\n- Input: High level programming language\n- Input: High-level programming language\n- Output: Low-level assembly instructions\n- Compiler does the translation:\np\n- Read and understand the program\n- Precisely determine what actions it require\ny\nq\n- Figure-out how to faithfully carry-out those actions\n- Instruct the computer to carry out those actions\nInstruct the computer to carry out those actions\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nInput to the Compiler\nInput to the Compiler\n- Standard imperative language (Java C C++)\n- Standard imperative language (Java, C, C++)\n- State\n- Variables\n- Variables,\n- Structures,\n- Arrays\ny\n- Computation\n- Expressions (arithmetic, logical, etc.)\n- Assignment statements\n- Control flow (conditionals, loops)\nP\nd\n- Procedures\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nOutput of the Compiler\nOutput of the Compiler\n- State\n- State\n- Registers\nM\nith Fl t Add\nS\n- Memory with Flat Address Space\n- Machine code - load/store architecture\n- Load, store instructions\n- Arithmetic, logical operations on registers\n- Branch instructions\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n=\nExample (input program)\nExample (input program)\nint sumcalc(int a, int b, int N)\n{\nint i, x, y;\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nfor(i\n0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*y;\n}\nreturn x;\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nu\n%ed\n0 e\n\nExample (Output assembly code)\nsumcalc:\npushq\n%rbp\nmovq\n%rsp, %rbp\nmovl\n%edi, -4(%rbp)\n.size\nsumcalc, .-sumcalc\n.section\n.Lframe1:\n.long\n.LECIE1-.LSCIE1\nmovl\n%esi, -8(%rbp)\nmovl\n%edx, -12(%rbp)\nmovl\n$0, -20(%rbp)\nmovl\n$0, -24(%rbp)\nmovl\n$0, -16(%rbp)\n.L2:\nmovl\n-16(%rbp), %eax\nl\n12(% b )\n%\n.LSCIE1:.long\n0x0\n.byte\n0x1\n.string \"\"\n.uleb128 0x1\n.sleb128 -8\n.byte\n0x10\nb t\ncmpl\n-12(%rbp), %eax\njg\n.L3\nmovl\n-4(%rbp), %eax\nleal\n0(,%rax,4), %edx\nleaq\n-8(%rbp), %rax\nmovq\n%rax, -40(%rbp)\nmovl\n%edx\n%eax\n.byte\n0xc\n.uleb128 0x7\n.uleb128 0x8\n.byte\n0x90\n.uleb128 0x1\n.align\nLECIE1: long\nLEFDE1- LASFDE1\nmovl\n%edx, %eax\nmovq\n-40(%rbp), %rcx\ncltd\nidivl\n(%rcx)\nmovl\n%eax, -28(%rbp)\nmovl\n-28(%rbp), %edx\nimull\n-16(%rbp), %edx\n.LECIE1:.long\n.LEFDE1 .LASFDE1\n.long\n.LASFDE1-.Lframe1\n.quad\n.LFB2\n.quad\n.LFE2-.LFB2\n.byte\n0x4\n.long\n.LCFI0-.LFB2\n.byte\n0xe\n6(% bp),\nmovl\n-16(%rbp), %eax\nincl\n%eax\nimull\n%eax, %eax\naddl\n%eax, %edx\nleaq\n-20(%rbp), %rax\naddl\n%edx, (%rax)\n.byte\n.uleb128 0x10\n.byte\n0x86\n.uleb128 0x2\n.byte\n0x4\n.long\n.LCFI1-.LCFI0\n.byte\n0xd\nmovl\n-8(%rbp), %eax\nmovl\n%eax, %edx\nimull\n-24(%rbp), %edx\nleaq\n-20(%rbp), %rax\naddl\n%edx, (%rax)\nleaq\n-16(%rbp), %rax\ni\nl\n(%\n)\n.uleb128 0x6\n.align\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nincl\n(%rax)\njmp\n.L2\n.L3:\nmovl\n-20(%rbp), %eax\nleave\nret\n\nMapping Time Continuum\nC\nil\ni\nI\ni\nCompilation to Interpretation\n- Compile time\n- Compile time\n- Ex: C compiler\nLi k ti\n- Link time\n- Ex: Binary layout optimizer\n- Load time\n- Ex: JIT compiler\n- Run time\n- Ex: Java Interpreter\nEx: Java Interpreter\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAnatomy of a Computer\nAnatomy of a Computer\nProgram\nProgram\nwritten\nin a\nAssembly\nLanguage\nCompiler\nProgramming\nLanguages\nTranslation\np\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nL\ni\nl A\nl\n(S\n)\nLexical Analyzer (Scanner)\nAnatomy of a Computer\nProgram (character stream)\nL\ni\nl A\nl\n(S\n)\nProgram (character stream)\nToken Stream\nLexical Analyzer (Scanner)\nToken Stream\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nLexical Analyzer (Scanner)\nLexical Analyzer (Scanner)\n2 3 4\n*\n( 1 1\n+ -\n2 2 )\nNum(234) mul_op lpar_op Num(11) add_op\nrpar_op\nNum(-22)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nLexical Analyzer (Scanner)\nLexical Analyzer (Scanner)\n2 3 4\n*\n( 1 1\n+ -\n2 2 )\nNum(234) mul_op lpar_op Num(11) add_op\nrpar_op\nNum(-22)\n18..23 + val#ue\nV i bl\nt h\n'#' h\nt\nNot a number\nVariable names cannot have '#' character\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAnatomy of a Computer\nL\ni\nl A\nl\n(S\n)\nProgram (character stream)\nLexical Analyzer (Scanner)\nSyntax Analyzer (Parser)\nToken Stream\nSyntax Analyzer (Parser)\nToken Stream\nSyntax Analyzer (Parser)\nParse Tree\nSyntax Analyzer (Parser)\nParse Tree\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nSyntax Analyzer (Parser)\nSyntax Analyzer (Parser)\n'*' '('\n' '\n')'\nnum '*' '(' num '+' num ')'\n<expr>\n<expr>\n<expr>\n<op>\n(\n)\n*\nnum\n<expr>\n(\n)\n<expr>\n<expr>\n<op>\nnum\nnum\n+\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nnum\nnum\n+\n\nSyntax Analyzer (Parser)\nSyntax Analyzer (Parser)\nint * foo(i, j, k))\nint i;\nint i;\nint j;\nExtra parentheses\n{\nfor(i=0; i j) {\nfi(i>j)\nreturn j;\nMissing increment\nNot an expression\n}\nNot an expression\nNot a keyword\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAnatomy of a Computer\nL\ni\nl A\nl\n(S\n)\nProgram (character stream)\nLexical Analyzer (Scanner)\nSyntax Analyzer (Parser)\nToken Stream\nSemantic Analyzer\nSyntax Analyzer (Parser)\nParse Tree\nSemantic Analyzer\nParse Tree\nIntermediate Representation\nSemantic Analyzer\nIntermediate Representation\nSemantic Analyzer\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nSemantic Analyzer\nSemantic Analyzer\nint * foo(i, j, k)\nint i;\nint i;\nint j;\nType not declared\n{\nint x;\nMismatched return type\nx = x + j + N;\nreturn j;\nMismatched return type\nUninitialized variable used\n}\nUndeclared variable\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAnatomy of a Computer\nL\ni\nl A\nl\n(S\n)\nProgram (character stream)\nLexical Analyzer (Scanner)\nSyntax Analyzer (Parser)\nToken Stream\nSemantic Analyzer\nSyntax Analyzer (Parser)\nParse Tree\nCode Optimizer\nIntermediate Representation\nSemantic Analyzer\nCode Optimizer\nIntermediate Representation\nCode Optimizer\nOptimized Intermediate Representation\nCode Optimizer\nOptimized Intermediate Representation\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nOptimizer\nOptimizer\nint sumcalc(int a, int b, int N)\n{\nint sumcalc(int a, int b, int N)\n{\nint i;\nint x, t, u, v;\nx = 0;\nu = ((a<<2)/b);\n{\nint i;\nint x, y;\nv = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + v + t*t;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nv = v + u;\n}\nreturn x;\n}\nx = x+4*a/b*i+(i+1)*(i+1);\nx = x + b*y;\n}\nreturn x;\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAnatomy of a Computer\nL\ni\nl A\nl\n(S\n)\nProgram (character stream)\nLexical Analyzer (Scanner)\nSyntax Analyzer (Parser)\nToken Stream\nSemantic Analyzer\nSyntax Analyzer (Parser)\nParse Tree\nCode Optimizer\nIntermediate Representation\nSemantic Analyzer\nCode Optimizer\nCode Generator\nOptimized Intermediate Representation\nCode Generator\nOptimized Intermediate Representation\nCode Generator\nAssembly code\nCode Generator\nAssembly code\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCode Generator\nCode Generator\nsumcalc:\nxorl\n%r8d, %r8d\nxorl\n%ecx\n%ecx\nint sumcalc(int a, int b, int N)\n{\nxorl\n%ecx, %ecx\nmovl\n%edx, %r9d\ncmpl\n%edx, %r8d\njg\n.L7\nsall\n$2, %edi\n.L5:\nmovl\n%edi, %eax\n{\nint i;\nint x, t, u, v;\nx = 0;\n((\n2)/b)\n,\ncltd\nidivl\n%esi\nleal\n1(%rcx), %edx\nmovl\n%eax, %r10d\nimull\n%ecx, %r10d\nu = ((a<<2)/b);\nv = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nmovl\n%edx, %ecx\nimull\n%edx, %ecx\nleal\n(%r10,%rcx), %eax\nmovl\n%edx, %ecx\naddl\n%eax, %r8d\n;\nx = x + v + t*t;\nv = v + u;\n}\nt\ncmpl\n%r9d, %edx\njle\n.L5\n.L7:\nmovl\n%r8d, %eax\nret\nreturn x;\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nProgram Translation\nProgram Translation\n- Correct\n- Correct\n- The actions requested by the program has to be\nfaithfully executed\nfaithfully executed\nEfficient\n- Efficient\n- Intelligently and efficiently use the available resources to\ncarry out the requests\ncarry out the requests\n- (the word optimization is used loosely in the compiler\ncommunity - Optimizing compilers are never optimal)\ncommunity\nOptimizing compilers are never optimal)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEfficient Execution\nEfficient Execution\nCross the river and take\nGeneral\nCross the river and take\ndefensive positions\nSergeant\nSergeant\nFoot Soldier\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998 General issues an order to cross the river and take defensive positions.\nFigure by MIT OpenCourseWare.\n\nEfficient Execution\nEfficient Execution\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nFigure by MIT OpenCourseWare.Sergeant considers how to implement the general's order.\nGeneral\nSergeant\nSergeant\nFoot Soldier\nCross the river and take\nCross the river and take\ndefensive positions\nWhere to cross the river? Use the\nbridge upstream or surprise the enemy\nbridge upstream or surprise the enemy\nby crossing downstream?\nHow do I minimize the casualties??\n\nEfficient Execution\nEfficient Execution\nPresident\nPresident\nGeneral\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998 Similarly, the general considers how to handle an order from the president.\nFigure by MIT OpenCourseWare.\nMy poll ratings are low,\nMy poll ratings are low,\nlets invade a small nation\nRussia or Bermuda?\nOr just stall for his poll\nOr just stall for his poll\nnumbers to go up?\n\nEfficient Execution\nEfficient Execution\n- Mapping from High to Low\n- Mapping from High to Low\n- Simple mapping of a program to assembly language\nproduces inefficient execution\nproduces inefficient execution\n- Higher the level of abstraction more inefficiency\nIf not efficient\n- If not efficient\n- High-level abstractions are useless\n- Need to:\n- provide a high level abstraction\n- with performance of giving low-level instructions\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEfficient Execution help\ni\nh\nl\nl\nf\nb\ni\nincrease the level of abstraction\n- Programming languages\n- Programming languages\n- From C to OO-languages\nwith garbage collection\nwith garbage collection\n- Even more abstract\ndefinitions\ndefinitions\n- Microprocessor\nFrom simple CISC to RISC to\n- From simple CISC to RISC to\nVLIW to ....\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nThe Multicore Dilemma\nThe Multicore Dilemma\n- Superscalars\n- Multicores\n- Superscalars\n- Multicores\nHigh Level Language\nHigh Level Language\ng\ng\ng\nm\ner\nHigh Level Language\nSimple von Neumann Machine\nCo\npile\nomp\ner??\nSimple von Neumann Machine\nCo\nile\nHard\nware\nMultiple exposed cores\nrd\nre\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nH\nw\nHar\nwar\n\nThe Multicore Dilemma\nThe Multicore Dilemma\n- Superscalars\n- Multicores\n- Superscalars\n- Multicores\nHigh Level Language\ng\ng\ng\nm\ner\nParallel Language\nSimple von Neumann Machine\nCo\npile\nParallel Language\nm\nr\nSimple von Neumann Machine\nCom\npiler\nHard\nware\nMultiple exposed cores\nrd\nre\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nH\nw\nHar\nwar\n\n=\nOptimization Example\nOptimization Example\nint sumcalc(int a, int b, int N)\n{\nint i;\nint x, y;\nint x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nfor(i\n0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*y;\n}\nreturn x;\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\npushq\n%rbp\nmovq\n%rsp, %rbp\nmovl\n%edi, -4(%rbp)\nmovl\n%esi, -8(%rbp)\n%\n12 %\nmovl\n%edx, -12(%rbp)\nmovl\n$0, -20(%rbp)\nmovl\n$0, -24(%rbp)\nmovl\n$0, -16(%rbp)\n.L2:\nmovl\n-16(%rbp), %eax\ncmpl\n12(%rbp)\n%eax\ncmpl\n-\n12(%rbp), %eax\njg\n.L3\nmovl\n-4(%rbp), %eax\nleal\n0(,%rax,4), %edx\nleaq\n-8(%rbp), %rax\nmovq\n%rax\n-40(%rbp)\nmovq\n%rax, 40(%rbp)\nmovl\n%edx, %eax\nmovq\n-40(%rbp), %rcx\ncltd\nidivl\n(%rcx)\nmovl\n%eax, -28(%rbp)\n,\n(\np)\nmovl\n-28(%rbp), %edx\nimull\n-16(%rbp), %edx\nmovl\n-16(%rbp), %eax\nincl\n%eax\nimull\n%eax, %eax\naddl\n%eax, %edx\nleaq\n-20(%rbp), %rax\naddl\n%edx, (%rax)\nmovl\n-8(%rbp), %eax\nmovl\n%eax, %edx\ni\nll\n24(% b )\n% d\nimull\n-\n24(%rbp), %edx\nleaq\n-20(%rbp), %rax\naddl\n%edx, (%rax)\nleaq\n-16(%rbp), %rax\nincl\n(%rax)\njmp\nL2\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\njmp\n.\nL2\n.L3:\nmovl\n-20(%rbp), %eax\nleave\nret\n\nLets Optimize...\nLets Optimize...\nint sumcalc(int a, int b, int N)\n{\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\no (\n;\n;\n) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*y;\n}\nreturn x;\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nConstant Propagation\nConstant Propagation\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*y;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nConstant Propagation\nConstant Propagation\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*y;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nConstant Propagation\nConstant Propagation\ni\ni\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*0;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAlgebraic Simplification\nAlgebraic Simplification\ni\ni\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*0;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAlgebraic Simplification\nAlgebraic Simplification\ni\ni\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x + b*0;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nAlgebraic Simplification\nAlgebraic Simplification\ni\ni\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCopy Propagation\nCopy Propagation\ni\ni\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCopy Propagation\nCopy Propagation\ni\ni\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\nx = x;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCopy Propagation\nCopy Propagation\ni\ni\nint i, x, y;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n=\nCommon Subexpression Elimination\nCommon Subexpression Elimination\nint i\nx\ny;\nint i, x, y;\nx = 0;\ny = 0;\ny\n0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n=\nCommon Subexpression Elimination\nCommon Subexpression Elimination\nint i\nx\ny;\nint i, x, y;\nx = 0;\ny = 0;\ny\n0;\nfor(i = 0; i <= N; i++) {\nx = x + (4*a/b)*i + (i+1)*(i+1);\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCommon Subexpression Elimination\nCommon Subexpression Elimination\ni\ni\nint i, x, y, t;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + (4*a/b)*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDead Code Elimination\nDead Code Elimination\ni\ni\nint i, x, y, t;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + (4*a/b)*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDead Code Elimination\nDead Code Elimination\ni\ni\nint i, x, y, t;\nx = 0;\ny = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + (4*a/b)*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDead Code Elimination\nDead Code Elimination\ni\ni\nint i, x, t;\nx = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + (4*a/b)*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nLoop Invariant Removal\nLoop Invariant Removal\ni\ni\nint i, x, t;\nx = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + (4*a/b)*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nLoop Invariant Removal\nLoop Invariant Removal\ni\ni\nint i, x, t;\nx = 0;\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + (4*a/b)*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nLoop Invariant Removal\nLoop Invariant Removal\ni\ni\nint i, x, t, u;\nx = 0;\n/\nu = (4*a/b);\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + u*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nStrength Reduction\nStrength Reduction\ni\ni\nint i, x, t, u;\nx = 0;\n/\nu = (4*a/b);\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + u*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nStrength Reduction\nStrength Reduction\ni\ni\nint i, x, t, u;\nx = 0;\n/\nu = (4*a/b);\nfor(i = 0; i <= N; i++) {\nt = i+1;\nx = x + u*i + t*t;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n=\nStrength Reduction\nStrength Reduction\nint i\nx\nt\nu\nv;\nint i, x, t, u, v;\nx = 0;\nu = ((a<<2)/b);\nu\n((a<<2)/b);\nv = 0;\nfor(i = 0; i <= N; i++) {\nfor(i\n0; i N; i++) {\nt = i+1;\nx = x + v + t*t;\nv = v + u;\n}\nreturn x;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nRegister Allocation\nRegister Allocation\nfp\nfp\nLocal variable X\nLocal variable Y\nLocal variable I\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nRegister Allocation\nRegister Allocation\nfp\nfp\nLocal variable X\nLocal variable Y\nLocal variable I\n$r8d = X\n$r9d = t\n$r10d = u\n$ebx = v\n$ecx = i\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n=\nOptimized Example\nOptimized Example\nint sumcalc(int a, int b, int N)\n{\nint i, x, t, u, v;\nx = 0;\nx\n0;\nu = ((a<<2)/b);\nv = 0;\nfor(i = 0; i <= N; i++) {\nfor(i\n0; i <= N; i++) {\nt = i+1;\nx = x + v + t*t;\n+\nv = v + u;\n}\nreturn x;\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nxorl\n%r8d, %r8d\nxorl\n%ecx, %ecx\nmovl\n%edx, %r9d\npushq\n%rbp\nmovq\n%rsp, %rbp\nmovl\n%edi, -4(%rbp)\nUnoptimized Code\nOptimized Code\nmovl\n%edx, %r9d\ncmpl\n%edx, %r8d\njg\n.L7\nsall\n$2, %edi\n.L5:\nmovl\n%edi, %eax\ncltd\nidivl\n%esi\nleal\n1(%rcx), %edx\nmovl\n%eax\n%r10d\nmovl\n%edi, 4(%rbp)\nmovl\n%esi, -8(%rbp)\nmovl\n%edx, -12(%rbp)\nmovl\n$0, -20(%rbp)\nmovl\n$0, -24(%rbp)\nmovl\n$0, -16(%rbp)\n.L2:\nmovl\n-16(%rbp), %eax\ncmpl\n-12(%rbp), %eax\njg\nL3\nmovl\n%eax, %r10d\nimull\n%ecx, %r10d\nmovl\n%edx, %ecx\nimull\n%edx, %ecx\nleal\n(%r10,%rcx), %eax\nmovl\n%edx, %ecx\naddl\n%eax, %r8d\ncmpl\n%r9d, %edx\njl\nL5\njg\n.L3\nmovl\n-4(%rbp), %eax\nleal\n0(,%rax,4), %edx\nleaq\n-8(%rbp), %rax\nmovq\n%rax, -40(%rbp)\nmovl\n%edx, %eax\nmovq\n-40(%rbp), %rcx\ncltd\nidi l\n(%\n)\njle\n.L5\n.L7:\nmovl\n%r8d, %eax\nret\nidivl\n(%rcx)\nmovl\n%eax, -28(%rbp)\nmovl\n-28(%rbp), %edx\nimull\n-16(%rbp), %edx\nmovl\n-16(%rbp), %eax\nincl\n%eax\nimull\n%eax, %eax\naddl\n%eax, %edx\nleaq\n-20(%rbp), %rax\naddl\n%edx, (%rax)\nmovl\n-8(%rbp), %eax\nmovl\n%eax, %edx\nimull\n-24(%rbp), %edx\nleaq\n-20(%rbp), %rax\naddl\n%edx, (%rax)\nleaq\n-16(%rbp), %rax\nq\n(\np),\nincl\n(%rax)\njmp\n.L2\n.L3:\nmovl\n-20(%rbp), %eax\nleave\nret\nInner Loop:\nInner Loop:\n10*mov + 5*lea + 5*add/inc\n+ 4*div/mul + 5*cmp/br/jmp\n29 i\ni\n4*mov + 2*lea + 1*add/inc+\n3*div/mul + 2*cmp/br/jmp\n12 i\ni\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n= 29 instructions\n= 12 instructions\nExecution time = 17 sec\nExecution time = 43 sec\n\n-\nCompilers Optimize Programs for...\nCompilers Optimize Programs for...\n- Performance/Speed\n- Performance/Speed\n- Code Size\n- Power Consumption\n- Fast/Efficient Compilation\np\n- Security/Reliability\n- Debugging\nDebugging\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec02.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/c6ce16f57edc535c1d0e425095be68e9_MIT6_035S10_lec02.pdf",
      "content": "MIT 6.035\nSpecifying Languages with Regular\nExpressions and Context-Free Grammars\np\nMartin Rinard\nLaboratory for Computer Science\nMassachusetts Institute of Technology\n\nt\nt\nt\ns\n-\ng\np\ng\n( p\nLanguage Definition Problem\n- How to precisely define language\nL\nd\nf l\nd fi i i\n- Layered structure of language definition\n- Start with a set of letters in language\nLexical tructure\nidentifies \"words\" in language\nLexical structure - identifies words in language\n(each word is a sequence of letters)\n- Syntactic structure - identifies \"sentences\" in\nSyntactic structure identifies sentences in\nlanguage (each sentence is a sequence of words)\n- Semantics - meaning of program (specifies what\nresult should be for each input)\n- Today's topic: lexical and syntactic structures\n\n(\nl\ni\n)\nc\none\nSpecifying Formal Languages\n- Huge Triumph of Computer Science\n- Beautiful Theoretical Results\n- Practical Techniques and Applications\n- Two Dual Notions\n- Generative approach\n(grammar or regular expression)\n- Recognition approach (automaton)\nLots of theorems abo t on erting\napproach\n- Lots of theorems about converting one approach\nautomatically to another\n\nn\ne e\nrom a p a e\n-\n(\n)\nSpecifying Lexical Structure Using\nRegular Expressions\nRegular Expressions\n- Have some alphabet ∑ = set of letters\nR\nl\ni\nb ilt f\n- Regular expressions are built from:\n- ε - empty string\nA y l tt r f\nl h b t ∑\nAny letter from alphabet ∑\n- r1r2 - regular expression r1 followed by r2\n(sequence)\n(sequence)\n- r1| r2 - either regular expression r1 or r2\n(choice)\n- r* - iterated sequence and choice ε | r | rr | ...\n- Parentheses to indicate grouping/precedence\n\na\n(\n|\n)(\n|\n)\n( | )\nConcept of Regular Expression\nGenerating a String\nGenerating a String\nRewrite regular expression until have only a\nsequence of letters (string) left\nsequence of letters (string) left\nExample\nGener l Rules\np\n(0 | 1)*.(0|1)*\n(0 | 1)(0 | 1)*.(0|1)*\nGeneral Rules\n1) r1| r2 →r1\n1(0|1)*.(0|1)*\n1.(0|1)*\n2) r1| r2 →r2\n3) r* →rr*\n1.(0|1)(0|1)*\n1.(0|1)\n)\n4) r* →ε\n1.0\n\n1 (0|1)(0|1)*\n( | )( | )\n( | )\nNondeterminism in Generation\n- Rewriting is similar to equational reasoning\n- But different rule applications may yield different final\nresults\nExample 1\nExample 2\np\n(0|1)*.(0|1)*\n(0|1)(0|1)*.(0|1)*\nExample 2\n(0|1)*.(0|1)*\n(0|1)(0|1)*.(0|1)*\n1(0|1)*.(0|1)*\n1.(0|1)*\n0(0|1)*.(0|1)*\n0.(0|1)*\n1.(0|1)(0|1)*\n1.(0|1)\n1 0\n0.(0|1)(0|1)*\n0.(0|1)\n0 1\n1.0\n0.1\n\n-\nConcept of Language Generated by\nRegular Expressions\nRegular Expressions\n- Set of all strings generated by a regular\nexpression is language of regular expression\nexpression is language of regular expression\n- In general, language may be (countably) infinite\nString in language is often called a token\nString in language is often called a token\n-\n\nt\nw\neven\no\n-\nExamples of Languages and Regular\nExpressions\nExpressions\n- ∑ = { 0, 1, . }\n(0|1)* (0|1)*\nBi\nfl\nti\ni\nb\n- (0|1)*.(0|1)* - Binary floating point numbers\n- (00)* - even-length all-zero strings\n1*(01*01*)*\nstrings\nith\nnumber\nf\n1*(01*01*)* - strings with even number of\nzeros\n- ∑= { a b c 0 1 2 }\n∑\n{ a,b,c, 0, 1, 2 }\n- (a|b|c)(a|b|c|0|1|2)* - alphanumeric\nidentifiers\n- (0|1|2)* - trinary numbers\n\nt\nt t\nt t t\nAlternate Abstraction\nFinite-State Automata\nFinite State Automata\n- Alphabet ∑\nS\nf\nith i iti l\nd\n- Set of states with initial and accept states\n- Transitions between states, labeled with letters\n(0|1)*.(0|1)*\nStart state\n.\nAccept state\n\nIf\nd i\ni\nAutomaton Accepting String\nConceptually, run string through automaton\n- Have current state and current letter in string\n- Start with start state and first letter in string\n- At each step, match current letter against a transition\nwhose label is same as letter\n- Continue until reach end of string or match fails\n- If end in accept state, automaton accepts string\n- Language of automaton is set of strings it accepts\n\nExample\nCurrent state\np\n.\nStart state\n.\nAccept state\n11.0\nCurrent letter\nCurrent letter\n\nExample\np\nCurrent state\n.\nStart state\n.\nAccept state\n11.0\nCurrent letter\nCurrent letter\n\nExample\np\nCurrent state\n.\nStart state\n.\nAccept state\n11.0\nCurrent letter\nCurrent letter\n\nExample\np\nCurrent state\n.\nStart state\n.\nAccept state\n11.0\nCurrent letter\nCurrent letter\n\nExample\np\nCurrent state\n.\nStart state\n.\nAccept state\n11.0\nCurrent letter\nCurrent letter\n\nExample\np\nCurrent state\n.\nStart state\n.\nAccept state\n11.0\nCurrent letter\nString is accepted!\nCurrent letter\n\n-\na\nGenerative Versus Recognition\n- Regular expressions give you a way to generate\nall strings in language\n- Automata give you a way to recognize if a specific\nstring is in language\n- Philosophically very different\n- Theoretically equivalent (for regular\nexpressions\nnd automata)\nexpressions and automata)\n- Standard approach\nUse regular expressions when define language\nUse regular expressions when define language\n- Translated automatically into automata for\nimplementation\nimplementation\n-\n\ns\n-\n-\no c\nc\no\n-\nFrom Regular Expressions to\nAutomata\nAutomata\n- Construction by structural induction\nGi\nbit\nl\ni\n- Given an arbitrary regular expression r\n- Assume we can convert r to an automaton with\nOne tart state\nOne start state\n- One accept state\nShow how\nShow how\nan automaton with\n- One start state\nOne start state\n- One accept state\nto convert all constructors to deliver\n\ns\nBasic Constructs\nAccept tate\nStart state\nε\nε\nAccept state\nε\na\na∈Σ\n\nSequence\nAccept state\nStart state\nAccept state\nr1r2\nr1\nr2\n1 2\n\nSequence\nAccept state\nStart state\nOld accept state\nOld start state\nAccept state\nOld accept state\nr1r2\nr1\nr2\n1 2\n\nSequence\nAccept state\nStart state\nOld accept state\nOld start state\nAccept state\nOld accept state\nr1r2\nr1\nr2\nε\n1 2\n\nSequence\nAccept state\nStart state\nOld accept state\nOld start state\nAccept state\nOld accept state\nr1r2\nε\nr1\nr2\nε\n1 2\n\nSequence\nAccept state\nStart state\nOld accept state\nOld start state\nAccept state\nOld accept state\nr1r2\nε\nr1\nr2\nε\nε\n1 2\n\nChoice\nAccept state\nStart state\nAccept state\nr |r\nr1\nr1|r2\nr2\n\nChoice\nOld accept state\nOld start state\nAccept state\nStart state\nOld accept state\nAccept state\nr |r\nr1\nr1|r2\nr2\n\nChoice\nOld accept state\nOld start state\nAccept state\nStart state\nOld accept state\nAccept state\nr |r\nr1\nε\nr1|r2\nr2\nε\n\nChoice\nOld accept state\nOld start state\nAccept state\nStart state\nOld accept state\nAccept state\nr |r\nr1\nε\nε\nr1|r2\nε\nr2\nε\n\na\ns\ns\nKleene Star\nOld\nccept tate\nOld start state\nAccept tate\nStart state\nOld accept state\nAccept state\nr*\nr\nr*\nr\n\na\ns\ns\nKleene Star\nOld\nccept tate\nOld start state\nAccept tate\nStart state\nOld accept state\nAccept state\nr*\nr\nr*\nr\n\na\ns\ns\nKleene Star\nOld\nccept tate\nOld start state\nAccept tate\nStart state\nOld accept state\nAccept state\nr*\nr\nε\nε\nr*\nr\n\na\ns\ns\nKleene Star\nOld\nccept tate\nOld start state\nAccept tate\nStart state\nε\nOld accept state\nAccept state\nr*\nr\nε\nε\nr*\nr\n\na\ns\ns\nKleene Star\nOld\nccept tate\nOld start state\nAccept tate\nStart state\nε\nOld accept state\nAccept state\nr*\nr\nε\nε\nr*\nr\nε\n\nNFA vs. DFA\n- DFA\n- No ε transitions\n- No ε transitions\n- At most one transition from each state for\neach letter\neach letter\na\na\nOK\nNOT\na\nb\nOK\nNOT\nOK\n- NFA - neither restriction\n\no t\ns\ne\nConversions\n- Our regular expression to automata conversion\nproduces an NFA\nproduces an NFA\n- Would like to have a DFA to make recognition\nalgorithm simpler\na g\np\n- Can convert from NFA to DFA (but DFA may be\nexponentially larger than NFA)\n\n-\nt\nt\nt t t\n-\na\na\n-\na\nstates n\nNFA to DFA Construction\n- DFA has a state for each subset of states in NFA\n- DFA start state corresponds to set of states reachable by following ε\niti\nf\nNFA\ntransitions from NFA start state\n- DFA state is an accept state if an NFA accept state is in its set of NFA\nstates\nTo compute the transition for\ngiven DFA state D and letter\nTo compute the transition for a given DFA state D and letter a\n- Set S to empty set\n- Find the set N of D's NFA states\nFor\nll NFA\nin N\n- For all NFA states n in N\n- Compute set of states N' that the NFA may be in after\nmatching a\nSet S to S union N'\n- Set S to S union N\n- If S is nonempty, there is a transition for a from D to the DFA state\nthat has the set S of NFA states\nOtherwise there is no transition for a from D\nOtherwise, there is no transition for a from D\n-\n\nNFA to DFA Example for (a|b)*.(a|b)*\nε\nε\na\nε\nε\nε\nε\nε\na\nε\nε\nε\n.\nε\nb\nε\nε\nε\nb\nε\nε\na\na\n.\n5,7,2,3,4,8\n13,15,10,11,12,16\na\n.\na\na\na\na\na\n.\n1,2,3,4,8\n6 7 2 3 4 8\n9,10,11,12,16\n14 15 10 11 12 16\nb\n.\nb\na\nb\na\nb\n6,7,2,3,4,8\n14,15,10,11,12,16\n.\nb\nb\n\nLexical Structure in Languages\nEach language typically has several categories of\nwords. In a typical programming language:\nwords. In a typical programming language:\n- Keywords (if, while)\n- Arithmetic Operations (+, -, *, /)\n- Integer numbers (1, 2, 45, 67)\n- Floating point numbers (1.0, .2, 3.337)\n- Identifiers (abc, i, j, ab345)\n- Typically have a lexical category for each\nkeyword and/or each category\nkeyword and/or each category\n- Each lexical category defined by regexp\n\n-\n=\nWill\nl\ni\nl\ni\ni\nl\nl\nLexical Categories Example\n- IfKeyword = if\nWhileKeyword = while\nWhileKeyword\nwhile\n- Operator = +|-|*|/\n- Integer = [0-9] [0-9]*\ntege\n[0 9] [0 9]\n- Float = [0-9]*. [0-9]*\n- Identifier = [a-z]([a-z]|[0-9])*\n- Note that [0-9] = (0|1|2|3|4|5|6|7|8|9)\n[a-z] = (a|b|c|...|y|z)\n- Will use lexical categories in next level\n-\n\n-\np\np\nProgramming Language Syntax\n- Regular languages suboptimal for specifying\nprogramming language syntax\nprogramming language syntax\n- Why? Constructs with nested syntax\n(a+(b-c))*(d-(x-(y-z)))\n(a+(b c)) (d (x (y z)))\n- if (x < y) if (y < z) a = 5 else a = 6 else a = 7\n- Regular languages lack state required to model\nRegular languages lack state required to model\nnesting\n- Canonical example: nested expressions\n- No regular expression for language of\nparenthesized expressions\n-\n\nSolution - Context-Free Grammar\n- Set of terminals\nOp = +|-|*|/\n{ Op, Int, Open, Close }\nEach terminal defined\nb\nl\ni\nInt = [0-9] [0-9]*\nOpen = <\nCl\n>\nby regular expression\n- Set of nonterminals\n{ Start Expr }\nClose = >\n{ Start, Expr }\n- Set of productions\n- Single nonterminal on LHS\nStart →Expr\nExpr →Expr Op Expr\ng\n- Sequence of terminals and\nnonterminals on RHS\np\np\np\np\nExpr →Int\nExpr →Open Expr Close\n\nc oose a\no te\na\ncu e t st\ns\ns n anguage\nProduction Game\nhave a current string\nstart with Start nonterminal\nstart with Start nonterminal\nloop until no more nonterminals\nchoose a nonterminal in current stringg\nchoose a production with nonterminal in LHS\nreplace nonterminal with RHS of production\nsubstitute regular expressions with corresponding\nstrings\ngenerated tring i i\nl\ngenerated string is in language\nNote: different choices produce different strings\nNote: different choices produce different strings\n\n3)\nI t\nSample Derivation\nStart\nE\nOp = +|-|*|/\nInt = [0-9] [0-9]*\nExpr\nExpr Op Expr\nOpen Expr Close Op Expr\nInt\n[0 9] [0 9]\nOpen = <\nClose = >\nOpen Expr Op Expr Close Op Expr\nOpen Int Op Expr Close Op Expr\nOpen Int Op Expr Close Op Int\nOpen Int Op Expr Close Op Int\nOpen Int Op Int Close Op Int\n< 2 - 1 > + 1\n1) Start → Expr\n2) Expr → Expr Op Expr\nE\n3) Expr → Int\n4) Expr → Open Expr Close\n\no\n-\n-\nParse Tree\n- Internal Nodes: Nonterminals\nL\nT\ni\nl\n- Leaves: Terminals\n- Edges:\nFrom Nonterminal\nf LHS of production\nFrom Nonterminal of LHS of production\n- To Nodes from RHS of production\nCaptures derivation of string\nCaptures derivation of string\n\nParse Tree for <2-1>+1\nStart\nExpr\nExpr\nExpr\nO\nExpr\nOp\n+\nOpen\n<\nClose\n>\nExpr\nInt\n<\n>\nOp\nExpr\nExpr\n-\nInt\nInt\n\ng\ny\ng\ng\ny\nAmbiguity in Grammar\nGrammar is ambiguous if there are multiple derivations\n(therefore multiple parse trees) for a single string\nDerivation and parse tree usually reflect semantics of\nthe program\nthe program\nAmbi uity in rammar often reflects ambiguity in\nsemantics of language\n(which is considered undesirable)\ng\ng\n\nE\nAmbiguity Example\nTwo parse trees for 2-1+1\nTree corresponding\nTree corresponding\nStart\nStart\nTree corresponding\nto <2-1>+1\nto 2-<1+1>\nExpr\nExpr\nExpr\nExpr\nOp\n+\nInt\nExpr\nExpr\nOp\n-\nInt\nExpr\nExpr\nOp\n-\nInt\nInt\nInt\nExpr\nExpr\nOp\n+\nInt\nInt\n\np\ny\np\nEliminating Ambiguity\nSolution: hack the grammar\nOriginal Grammar\nStart → Expr\nHacked Grammar\nStart → Expr\nExpr → Expr Op Expr\nExpr → Int\nE\nO\nE\nCl\nExpr → Expr Op Int\nExpr → Int\nE\nO\nE\nCl\nConceptually, makes all operators associate to left\nExpr → Open Expr Close\nExpr → Open Expr Close\n\nOp\n-\nt\nOp\nt\nt\nInt\nt\nParse Trees for Hacked Grammar\nOnly one parse tree for 2-1+1!\nStart\nStart\nValid parse tree\nNo longer valid parse tree\nExpr\nExpr\nExpr\nOp\n+\nInt\nExpr\nExpr\nIn\nExpr Op\n-\nInt\nInt\nExpr\nExpr\n+\nI\nI\nInt\nInt\nIn\n\nt\nPrecedence Violations\n- All operators associate to left\nVi l\nd\nf *\nParse tree for\n2 3*4\n- Violates precedence of * over +\n- 2-3*4 associates like <2-3>*4\nStart\nExpr\n2-3 4\nExpr\nExpr\nOp\nInt\nExpr\nOp\n*\nExpr Op\nInt\nInt\np\np\n-\nInt\nInt\n\n→\n→\nHacking Around Precedence\nOriginal Grammar\nOp = +|-|*|/\nHacked Grammar\nAddOp = +|-\nInt = [0-9] [0-9]*\nOpen = <\nMulOp = *|/\nInt = [0-9] [0-9]*\nClose = >\nStart\nExpr\nOpen = <\nClose = >\nStart\nExpr\nStart → Expr\nExpr → Expr Op Int\nExpr →Int\nStart → Expr\nExpr → Expr AddOp Term\nExpr →Term\nExpr → Int\nExpr → Open Expr Close\nExpr → Term\nTerm → Term MulOp Num\nTerm → Num\nNum → Int\nNum → Open Expr Close\n\nf\n2 3*4\nI\nParse Tree Changes\nOld parse tree\nStart\nNew parse tree\nfor 2-3*4\nStart\nfor 2-3*4\nStart\nExpr\nExpr\nExpr\nOp\nExpr\nAddOp\n-\nTerm\nExpr\nOp\n*\nExpr Op\nInt\nInt\nTerm\nTerm\nMulOp\n*\nNum\nN m\nExpr Op\n-\nInt\nInt\nInt\nNum\nInt\nNum\nInt\n\nt t\nt\nt\nor\n-\n-\nor\na\n-\nGeneral Idea\n- Group Operators into Precedence Levels\n*\nd /\nl\nl bi d\n- * and / are at top level, bind strongest\n- + and - are at next level, bind next strongest\nNonterminal f\neach Precedence Level\nNonterminal for each Precedence Level\n- Term is nonterminal for * and /\nExpr is nonterminal\n+\nExpr is nonterminal\n+\n-\n- Can make operators left or right associative\nwithin each level\nwithin each level\n- Generalizes for arbitrary levels of precedence\nand\nfor\n\ny\nParser\n- Converts program into a parse tree\n- Can be written by hand\n- Or produced automatically by parser generator\n- Accepts a grammar as input\n- Produces a parser as output\n- Practical problem\n- Parse tree for hacked grammar is complicated\n- Would like to start with more intuitive parse tree\n\n-\nt\nt\nt\nt\nt\n\"\nSolution\n- Abstract versus Concrete Syntax\nAb\nd\n\"i\niti\n\"\n- Abstract syntax corresponds to \"intuitive way\nof thinking of structure of program\n- Omits details like superfluous keywords that\nOmits details like superfluous keywords that\nare there to make the language\nunambiguous\n- Abstract syntax may be ambiguous\n- Concrete Syntax corresponds to full grammar\nused to parse the language\n- Parsers are often written to produce abstract\nsyntax trees\nsyntax trees.\n\nt\nt\n-\nAbstract Syntax Trees\n- Start with intuitive but ambiguous grammar\nH\nk\nk\ni\nbi\n- Hack grammar to make it unambiguous\n- Concrete parse trees\nLess intuitive\nLess intuitive\n- Convert concrete parse trees to abstract syntax\ntrees\ntrees\n- Correspond to intuitive grammar for language\n- Simpler for program to manipulate\nSimpler for program to manipulate\n\n=\nSt\nt\nE\nt\nExample\nHacked Unambiguous\nGrammar\nGrammar\nAddOp = +|-\nMulOp = *|/\nInt\n[0 9] [0 9]*\nIntuitive but Ambiguous\nGrammar\nInt\n[0-9] [0-9]\nOpen = <\nClose = >\nOp = *|/|+|-\nInt = [0-9] [0-9]*\nSt\nE\nStart → Expr\nExpr → Expr AddOp Term\nExpr → Term\nStart → Expr\nExpr → Expr Op Expr\nExpr →Int\nTerm → Term MulOp Num\nTerm → Num\nNum → Int\nExpr → Int\nNum → Open Expr Close\n\n-\np\nt\nConcrete parse\ntree\nStart\nAbstract syntax\ntree\ntree\nfor <2-3>*4\nExpr\nExpr\nOp\nExpr\ntree\nfor <2-3>*4\nStart\nExpr\n*\nExpr\nOp\nExpr\nInt\nExpr\nStart\nExpr\n-\nInt\nInt\nExpr\nAddOp\n-\nTerm\n- Uses intuitive\ngrammar\n- Eliminates superfluous\nTerm\nTerm\nMulOp\n*\nNum\nNum\nEliminates superfluous\nterminals\n- Open\nInt\nNum\nInt\nNum\nIn\n- Close\nInt\n\nStart\nAbstract parse tree\nFurther simplified Start\nExpr\nExpr\nAbstract parse tree\nfor <2-3>*4\nFurther simplified\nabstract syntax\ntree\nExpr\nOp\n*\nO\nI\nInt\nI\nExpr\nOp\n*\nExpr\nExpr\nInt\nExpr\nfor <2-3>*4\nOp\n-\nInt\nInt\nExpr\nOp\n-\nInt\nInt\nExpr\nInt\n\n-\nt\nt\na\n-\n-\nSummary\n- Lexical and Syntactic Levels of Structure\nL\ni\nl\nl\ni\nd\n- Lexical - regular expressions and automata\n- Syntactic - grammars\nGrammar\nmbiguities\nGrammar ambiguities\n- Hacked grammars\nAbstract syntax trees\nAbstract syntax trees\n- Generation versus Recognition Approaches\nGeneration more convenient for specification\nGeneration more convenient for specification\n- Recognition required in implementation\n-\n\nHandling If Then Else\nStart → Stat\nStat →if Expr then Stat else Stat\nStat → if Expr then Stat else Stat\nStat → if Expr then Stat\nStat → ...\n\nParse Trees\n- Consider Statement if e1 then if e2 then s1 else s2\n\nStat\nTwo Parse Trees\nif\nExpr\nStat\nif\nExpr\nStat\nelse\ne1\nStat\nthen\ne2\ns1\ns2\nStat\nif\nExpr\nStat\nelse\nStat\nthen\nif Expr\nStat\nelse\ne1\nStat\ns2\nWhich is\ncorrect?\nthen\nif Expr\ne2\ns1\nthen\ne2\n\nAlternative Readings\n- Parse Tree Number 1\nifif e1\nif e2 s1\nGrammar is ambiguous\nelse s2\n- Parse Tree Number 2\nGrammar is ambiguous\nif e1\nif e2 s1\nelse s2\n\n→\nHack ed Gr ammar\nGoal → Stat\nStat →WithElse\nStat → WithElse\nStat → LastElse\nWithElse → if Expr then WithElse else WithElse\nWithElse → <statements without if then or if then else>\nLastElse → if Expr then Stat\nLastElse\nif Expr then WithElse else LastElse\nLastElse → if Expr then WithElse else LastElse\n\nHacked Grammar\n- Basic Idea: control carefully where an if without\nan else can occur\nan else can occur\n- Either at top level of statement\n- Or as very last in a sequence of if then else if\n- Or as very last in a sequence of if then else if\nthen ... statements\n\n-\nt\np\np\np\nGrammar Vocabulary\n- Leftmost derivation\nAl\nd l ft\ni i\n- Always expands leftmost remaining\nnonterminal\n- Similarly for rightmost derivation\nSimilarly for rightmost derivation\n- Sentential form\n- Partially or fully derived string from a step in\nPartially or fully derived string from a step in\nvalid derivation\n- 0 + Expr Op Expr\n- 0 + Expr - 2\n\nDefining a Language\n- Grammar\n- Generative approach\nGenerative approach\n- All strings that grammar generates (How many are\nthere for grammar in previous example?)\n- Automaton\n- Recognition approach\n- All strings that automaton accepts\n- Different flavors of grammars and automata\n- In general, grammars and automata correspond\n\n-\n-\n-\ns\n-\nRegular Languages\n- Automaton Characterization\n(S A F\n)\n- (S,A,F,s0,sF)\n- Finite set of states S\nFinite Alphabet A\nFinite Alphabet A\n- Transition function F : S ×A → S\nStart tate s\nStart state s0\n- Final states sF\n- Lanuage is set of strings accepted by Automaton\nLanuage is set of strings accepted by Automaton\n\no\n-\nRegular Languages\n- Regular Grammar Characterization\n(T NT S P)\n- (T,NT,S,P)\n- Finite set of Terminals T\nFinite set\nf Nonterminals NT\nFinite set of Nonterminals NT\n- Start Nonterminal S (goal symbol, start\nsymbol)\nsymbol)\n- Finite set of Productions P: NT → T U NT U T\nNT\n- Language is set of strings generated by grammar\n\nrammar\ng\nGrammar and Automata\nCorrespondence\nCorrespondence\nGrammar\nRegular\nAutomaton\nFinite State Automaton\nRegular\nContext-Free Grammar\nContext-Sensitive Grammar\nFinite-State Automaton\nPush-Down Automaton\nTuring Machine\nGrammar\n\no\n-\nContext-Free Grammars\n- Grammar Characterization\n(T NT S P)\n- (T,NT,S,P)\n- Finite set of Terminals T\nFinite set\nf Nonterminals NT\nFinite set of Nonterminals NT\n- Start Nonterminal S (goal symbol, start\nsymbol)\nsymbol)\n- Finite set of Productions P: NT → (T | NT)*\n- RHS of production can have any sequence of\nRHS of production can have any sequence of\nterminals or nonterminals\n\n-\n-\n-\ns\n-\nPush-Down Automata\n- DFA Plus a Stack\n(S A V F\n)\n- (S,A,V, F,s0,sF)\n- Finite set of states S\nFinite Input Alphabet A Stack Alphabet V\nFinite Input Alphabet A, Stack Alphabet V\n- Transition relation F : S ×(A U{ε})×V → S × V*\nStart tate s\nStart state s0\n- Final states sF\n- Each configuration consists of a state a stack\nEach configuration consists of a state, a stack,\nand remaining input string\n\nt t\nCFG Versus PDA\n- CFGs and PDAs are of equivalent power\nG\nI\nl\ni\nM\nh\ni\n- Grammar Implementation Mechanism:\n- Translate CFG to PDA, then use PDA to parse\ninput string\ninput string\n- Foundation for bottom-up parser generators\n\n-\nContext-Sensitive Grammars and\nTuring Machines\nTuring Machines\n- Context-Sensitive Grammars Allow Productions to\nUse Context\nUse Context\n- P: (T.NT)+ → (T.NT)*\n- Turing Machines Have\nTuring Machines Have\n- Finite State Control\n- Two-Way Tape Instead of A Stack\nTwo Way Tape Instead of A Stack\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec03.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/5e52815ef894b1842e678e6eb5c0a7b9_MIT6_035S10_lec03.pdf",
      "content": "MIT 6 035\nMIT 6.035\nIntroduction to Shift-Reduce Parsing\nMartin Rinard\nLaboratory for Computer Science\nMassachusetts Institute of Technology\n\nOrientation\n- Specify Syntax Using\nContext-Free Grammar\nExpr →Expr Op Expr\n- Nonterminals\n- Terminals\nExpr → Expr Op Expr\nExpr → (Expr)\nExpr → - Expr\n- Productions\n- Given a grammar, Parser\nGenerator produces a\np\np\nExpr → num\nOp → +\nGenerator produces a\nparser\n- Starts with input string\nOp → -\nOp → *\n- Produces parse tree\n\nt\nw\n-\nToday's Lecture\n- How generated parser works\nH\nd\n- How parser generator produces parser\n- Central mechanism\nPushdown automaton\nhich implements\nPushdown automaton, which implements\n- Shift-reduce parser\n\n-\nC\ni\nf\nShift:\nA\nh\ni\ni\nPushdown Automata\n- Consists of\n- Pushdown stack (can have terminals and nonterminals)\nFinite state automaton control\nFinite state automaton control\n- Can do one of three actions (based on state and input):\n- Shift:\n- Shift current input symbol from input onto stack\n- Reduce:\n- If symbols on top of stack match right hand side of\nsome grammar production NT →β\n- Pop symbols (β) off of the stack\n- Push left hand side nonterminal (NT) onto stack\n- Accept the input string\n-\n\np\n*\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nStack\nOp → -\nOp → *\nInput String\n*\n(\n+\nnum\n)\nnum\nnum\n\np\n*\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nOp → -\nOp → *\n*\n(\n+\nnum\n)\nnum\nnum\n\np\n*\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nOp → -\nOp → *\nFT\nSHIF\n*\n(\n+\nnum\n)\nnum\nnum\n\np\n*\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nnum\nOp → -\nOp → *\nFT\nSHIF\n*\n(\n+\nnum\n)\nnum\n\nShift-Reduce Parser Example\np\nExpr →Expr Op Expr\nExpr →(Expr)\nExpr →- Expr\nExpr →num\nOp →+\nnum\np\nOp →\n-\nOp →*\nUCE\n*\n(\n+\n)\nREDU\n*\n(\n+\nnum\n)\nnum\nR\n\nExpr →num\np\n*\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nOp → -\nOp → *\nExpr\nUCE\nnum\nREDU\n*\n(\n+\nnum\n)\nnum\nR\nExpr →- Expr\nExpr →num\nOp →+\n\np\n*\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nOp → -\nOp → *\nExpr\nFT\nnum\nSHIF\n*\n(\n+\nnum\n)\nnum\n\np\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nOp → -\nOp → *\nExpr\n*\nFT\nnum\nSHIF\n(\n+\nnum\n)\nnum\n\nShift-Reduce Parser Example\np\nExpr →Expr Op Expr\nExpr →(Expr)\nExpr →- Expr\nExpr →num\nOp →+\np\nOp →\n-\nOp →*\nExpr\nOp\nUCE\n(\n+\n)\nnum\nREDU\n*\n(\n+\nnum\n)\nnum\nR\n\np\n(\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\n(\n+\nnum\n)\nnum\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\n(\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\n+\nnum\n)\nnum\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\n(\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\n+\nnum\n)\nnum\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\n(\nnum\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\n+\nnum\n)\n\np\nFT\n)\nSHIF\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nOp → -\nOp → *\nExpr\nOp\nUCE\nnum\n*\nnum\nREDU\n+\nnum\n)\nR\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\nnum\n+\nnum\n)\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\n+\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\nnum\nnum\n)\n\np\nFT\n)\nSHIF\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nOp\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nOp → -\nOp → *\nExpr\nOp\nUCE\nnum\n*\nnum\nREDU\n+\nnum\n)\nR\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nOp\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\nnum\n+\nnum\n)\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nnum\nOp\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nOp → -\nOp → *\nExpr\nOp\nFT\nnum\n*\nSHIF\nnum\n+\n)\n\np\nFT\n)\nSHIF\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nOp\nExpr\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nOp → -\nOp → *\nExpr\nOp\nUCE\nnum\n*\nnum\n+\nREDU\nnum\n)\nR\n\nShift-Reduce Parser Example\np\nExpr →Expr Op Expr\nExpr →(Expr)\nExpr →- Expr\nExpr →num\nOp →+\n(\nExpr\nExpr\nExpr\np\nOp →\n-\nOp →*\nExpr\nOp\nExpr\nOp\nFT\nUCE\n)\nnum\n*\nSHIF\nnum\n+\nREDU\nnum\n)\nR\n\np\n)\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nExpr\nOp → -\nOp → *\nExpr\nOp\nExpr\nOp\nFT\nnum\n*\nSHIF\nnum\n+\nnum\n)\n\np\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\n)\nExpr → - Expr\nExpr → num\nOp → +\n(\nExpr\nExpr\nOp → -\nOp → *\nExpr\nOp\nExpr\nOp\nFT\nnum\n*\nSHIF\nnum\n+\nnum\n\nShift-Reduce Parser Example\np\nExpr →Expr Op Expr\nExpr →(Expr)\nExpr →- Expr\nExpr →num\nOp →+\nE\n)\nExpr\np\nOp →\n-\nOp →*\nExpr\nOp\n(\nOp\nExpr\nExpr\nUCE\nExpr\nREDU\nnum\n*\nnum\n+\nnum\nR\n\np\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nE\n)\nExpr\nOp → -\nOp → *\nExpr\nOp\n(\nOp\nExpr\nExpr\nExpr\nUCE\nExpr\nREDU\nnum\n*\nnum\n+\nnum\nR\n\np\nShift -R e duce P a rser Exam p le\np\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → - Expr\nExpr → num\nOp → +\nE\n)\nExpr\nOp → -\nOp → *\nExpr\nOp\n(\nOp\nExpr\nExpr\nExpr\nEPT!\nExpr\nACCE\nnum\n*\nnum\n+\nnum\nA\n\nt\nt t\nt\ns\nsequences\n-\nBasic Idea\n- Goal: reconstruct parse tree for input string\nR\nd i\nf\nl f\ni h\n- Read input from left to right\n- Build tree in a bottom-up fashion\nUse tack to hold pending\nof terminals\nUse stack to hold pending sequences of terminals\nand nonterminals\n\n-\nt\nt\nt\nt\nPotential Conflicts\n- Reduce/Reduce Conflict\nT\nf h\nk\nh RHS\nf\nl i l\n- Top of the stack may match RHS of multiple\nproductions\n- Which production to use in the reduction?\nWhich production to use in the reduction?\n- Shift/Reduce Conflict\n- Stack may match RHS of production\nStack may match RHS of production\n- But that may not be the right match\n- May need to shift an input and later find a\nMay need to shift an input and later find a\ndifferent reduction\n\n→\nConflicts\n-Original Grammar\n-New Grammar\nExpr → Expr Op Expr\nExpr → ( Expr)\nExpr → Expr Op Expr\nExpr → Expr - Expr\nExpr\n(Expr)\nExpr → - Expr\nExpr → num\nO\nExpr → (Expr )\nExpr → Expr -\nExpr →num\nOp → +\nOp → -\nOp → *\nExpr → num\nOp → +\nOp → -\np\nOp → *\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nExpr → ( Expr )\nExpr → Expr -\nExpr → num\nOp → +\nOp → -\nOp →*\nOp →\n-\nnum\nnum\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nExpr → ( Expr )\nExpr → Expr -\nExpr → num\nOp → +\nOp → -\nOp →*\nFT\nOp →\nSHIF\n-\nnum\nnum\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nExpr → ( Expr )\nExpr → Expr -\nExpr → num\nnum\nOp → +\nOp → -\nOp →*\nFT\nOp →\nSHIF\n-\nnum\n\np\nFT\nSHIF\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nExpr → ( Expr )\nExpr → Expr -\nExpr → num\nExpr\nOp → +\nOp → -\nOp →*\nUCE\nOp →\nREDU\nnum\n-\nnum\nR\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nExpr → ( Expr )\nExpr → Expr -\nExpr → num\nExpr\nOp → +\nOp → -\nOp →*\nFT\nOp →\nSHIF\nnum\n-\nnum\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nExpr → ( Expr )\nExpr → Expr -\nExpr → num\nExpr\n-\nOp → +\nOp → -\nOp →*\nFT\nOp →\nSHIF\nnum\nnum\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nOptions:\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nOptions:\nReduce\nReduce\nExpr\n-\nOp → +\nOp → -\nOp →*\nShift\nOp →\nnum\nnum\n\nShift/Reduce/Reduce Conflict\nExpr →Expr Op Expr\nExpr →Expr - Expr\nWhat Happens if\nExpr →(Expr)\nExpr →Expr -\nExpr →num\nWhat Happens if\nChoose\nReduce\nExpr\n-\np\nOp →+\nOp →\n-\nOp →*\nOp →*\nUCE\nnum\nREDU\nnum\nR\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nOp → +\nOp → -\nOp →*\nExpr\nExpr\nOp →\nT\nnum\n-\nSHIFT\nnum\nS\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nOp → +\nOp → -\nOp →*\nExpr\nnum\nExpr\nOp →\nT\nnum\n-\nSHIFT\nS\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nOp → +\nOp → -\nOp →*\nExpr\nExpr\nExpr\nOp →\nUCE\nnum\n-\nREDU\nnum\nR\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nOp → +\nOp → -\nOp →*\nExpr\nExpr\nExpr\nOp →\nS!\nnum\n-\nFAILS\nnum\nF\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nBoth of These\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nBoth of These\nActions Work\nReduce\nExpr\n-\nOp → +\nOp → -\nOp →*\nShift\nOp →\nnum\nnum\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nExpr\n-\nOp → +\nOp → -\nOp →*\nOp →\nnum\nnum\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nExpr\nOp\nOp → +\nOp → -\nOp →*\nOp →\nUCE\nnum\n-\nREDU\nnum\nR\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nnum\nExpr\nOp\nOp → +\nOp → -\nOp →*\nOp →\nT\nnum\n-\nSHIFT\nS\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nExpr\nExpr\nOp\nOp → +\nOp → -\nOp →*\nOp →\nUCE\nnum\n-\nREDU\nnum\nR\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nOp\nOp → +\nOp → -\nOp →*\nExpr\nExpr\nExpr\nOp →\nUCE\nnum\n-\nREDU\nnum\nR\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nReduce\nOp\nOp → +\nOp → -\nOp →*\nExpr\nExpr\nExpr\nOp →\nEPT\nnum\n-\nACCE\nnum\nA\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nShift\nExpr\n-\nOp → +\nOp → -\nOp →*\nOp →\nFT\nnum\nSHIF\nnum\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nnum\nWhat Happens if\nChoose\nShift\nExpr\n-\nOp → +\nOp → -\nOp →*\nOp →\nFT\nnum\nSHIF\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nExpr\nWhat Happens if\nChoose\nShift\nExpr\n-\nOp → +\nOp → -\nOp →*\nOp →\nUCE\nnum\nREDU\nnum\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nShift\nOp → +\nOp → -\nOp →*\nExpr\nExpr\nExpr\nOp →\nUCE\nnum\n-\nREDU\nnum\n\np\nConflicts\nExpr → Expr Op Expr\nExpr → Expr - Expr\nWhat Happens if\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nWhat Happens if\nChoose\nShift\nOp → +\nOp → -\nOp →*\nExpr\nExpr\nExpr\nOp →\nEPT\nnum\n-\nACCE\nnum\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nThis Shift/Reduce Conflict\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nReflects Ambiguity in\nGrammar\nExpr\n-\nOp → +\nOp → -\nOp →*\nOp →\nnum\nnum\n\n-\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr\nExpr\nThis Shift/Reduce Conflict\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nReflects Ambiguity in\nGrammar\nExpr\n-\nOp → +\nOp → -\nOp →*\nOp →\nEliminate by Hacking\nGrammar\nnum\nGrammar\nnum\n\np\nShift/Reduce/Reduce Conflict\nExpr → Expr Op Expr\nExpr → Expr - Expr\nThis Shift/Reduce\nExpr → (Expr)\nExpr → Expr -\nExpr → num\nConflict Can Be\nEliminated By\nLookahead of One\nExpr\n-\nOp → +\nOp → -\nOp →*\nSymbol\nOp →\nParser Generator Should\nHandle It\nnum\nnum\n\nWhich Production to Reduce\nConstructing a Parser\n- We will construct version with no lookahead\n- Key Decisions\nKey Decisions\n- Shift or Reduce\n- Which Production to Reduce\n- Basic Idea\n- Build a DFA to control shift and reduce actions\n- In effect, convert grammar to pushdown\nautomaton\n- Encode finite state control in parse table\n\nState Stack\nfinite state\nParser State\n- Input Token Sequence ($ for end of input)\n- Current State from Finite State Automaton\nCurrent State from Finite State Automaton\n- Two Stacks\n- State Stack (implements finite state automaton)\n(implements\nautomaton)\n- Symbol Stack (terminals from input and\nnonterminals from reductions)\n\n-\nt t\nt\nt\n-\n-\ns\n-\nIntegrating Finite State Control\n- Actions\nP\nh S\nb l\nd S\nO\nS\nk\n- Push Symbols and States Onto Stacks\n- Reduce According to a Given Production\nAccept\nAccept\n- Selected action is a function of\nCurrent input\nCurrent input\n- Current state of finite state control\n- Each action specifies next state\nEach action specifies next state\n- Implement control using parse table\nsymbol\n\nParse Tables\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Implements finite state control\n- At each step, look up\nT bl [\nf\nk] [ i\nb l]\n- Table[top of state stack] [ input symbol]\n- Then carry out the action\n\nParse Table Example\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nS →X $ (1)\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →( ) (3)\n(())\nX\ns0\nX\ns0\n\nParser Tables\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Shift to sn\n- Push input token into the symbol stack\n- Push sn into state stack\n- Advance to next input symbol\n\nParser Tables\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Reduce (n)\n- Pop both stacks as many times as the number\nf\nb l\nth\nRHS\nf\nl\nof symbols on the RHS of rule n\n- Push LHS of rule n into symbol stack\n\nParser Tables\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Reduce (n) (continued)\n- Look up\nT bl [t\nf th\nt t\nt\nk][t\nf\nb l t\nk]\n- Table[top of the state stack][top of symbol stack]\n- Push that state (in goto part of table) onto state\nstack\nstack\n\nParser Tables\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Accept\n- Stop parsing and report success\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n(())$\nX →( ) (3)\ns0\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n(())$\nX →( ) (3)\ns0\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n())$\ns2\nX →( ) (3)\ns0\n(\ns2\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n())$\ns2\nX →( ) (3)\ns0\n(\ns2\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n))$\ns2\n(\ns2\nX →( ) (3)\ns0\n(\ns2\n(\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n))$\ns2\n(\ns2\nX →( ) (3)\ns0\n(\ns2\n(\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n)$\ns2\n(\ns2\ns5\n)\nX →( ) (3)\ns0\n(\ns2\n(\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nInput\nState Stack\nSymbol Stack\nGrammar\n)$\ns2\n(\ns2\ns5\n)\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\ns0\n(\ns2\n(\nX →( ) (3)\n\nStep One: Pop Stacks\nACTION\nGoto\nState\n(\n)\n$\nX\np\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nInput\nState Stack\nSymbol Stack\nGrammar\n)$\ns2\n(\ns2\ns5\n)\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\ns0\n(\ns2\n(\nX →( ) (3)\n\nStep One: Pop Stacks\nACTION\nGoto\nState\n(\n)\n$\nX\np\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nState Stack\nSymbol Stack\nInput\nGrammar\n)$\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\ns2\nX →( ) (3)\ns0\n(\ns2\n\nStep Two: Push Nonterminal\nACTION\nGoto\nState\n(\n)\n$\nX\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n)$\ns2\nX →( ) (3)\ns0\n(\ns2\n\nStep Two: Push Nonterminal\nACTION\nGoto\nState\n(\n)\n$\nX\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n)$\ns2\nX\nX →( ) (3)\ns0\n(\ns2\nX\n\nStep Three: Use Goto, Push New State\nACTION\nGoto\nState\n(\n)\n$\nX\np\n,\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n)$\ns2\nX\nX →( ) (3)\ns0\n(\ns2\nX\n\nStep Three: Use Goto, Push New State\nACTION\nGoto\nState\n(\n)\n$\nX\np\n,\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n)$\ns2\nX\ns3\nX →( ) (3)\ns0\n(\ns2\nX\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n)$\ns2\nX\ns3\nX →( ) (3)\ns0\n(\ns2\nX\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\ns2\nX\ns3\ns4\n)\nX →( ) (3)\ns0\n(\ns2\nX\n\nParse Table In Action\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\ns2\nX\ns3\ns4\n)\nX →( ) (3)\ns0\n(\ns2\nX\n\nStep One: Pop Stacks\nACTION\nGoto\nState\n(\n)\n$\nX\np\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\ns2\nX\ns3\ns4\n)\nX →( ) (3)\ns0\n(\ns2\nX\n\nStep One: Pop Stacks\nACTION\nGoto\nState\n(\n)\n$\nX\np\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\nX →( ) (3)\ns0\n\nStep Two: Push Nonterminal\nACTION\nGoto\nState\n(\n)\n$\nX\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nState Stack\nSymbol Stack\nInput\nGrammar\n$\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\nX →( ) (3)\ns0\n\nStep Two: Push Nonterminal\nACTION\nGoto\nState\n(\n)\n$\nX\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\nX →( ) (3)\ns0\nX\n\nStep Three: Use Goto, Push New State\nACTION\nGoto\nState\n(\n)\n$\nX\np\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\nX →( ) (3)\ns0\nX\n\nStep Three: Use Goto, Push New State\nACTION\nGoto\nState\n(\n)\n$\nX\np\n,\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\ns1\nX →( ) (3)\ns0\nX\ns1\n\nAccept the String!\nACTION\nGoto\nState\n(\n)\n$\nX\np\ng\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nGrammar\nInput\nState Stack\nSymbol Stack\nS →X $ (1)\nX →(X ) (2)\nX →(\n) (3)\n$\ns1\nX →( ) (3)\ns0\nS\ns1\n\n-\n-\nt\nt t\nt\nc\nparser a\n-\n-\ns\nn\ns\n-\nKey Concepts\n- Pushdown automaton for parsing\nSt\nk Fi i\nl\n- Stack, Finite state control\n- Parse actions: shift, reduce, accept\nParse table for\nParse table for\n- Indexed by parser state and input symbol\nEntries pecify action and\next tate\nEntries specify action and next state\n- Use state stack to help control\n- Parse tree construction\nParse tree construction\n- Reads input from left to right\n- Bottom-up construction of parse tree\nBottom up construction of parse tree\ncontrolling parser actions\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec03b.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/c86c6ebce6973a6f8441f200a3b34fbd_MIT6_035S10_lec03b.pdf",
      "content": "MIT 6 035\nMIT 6.035\nParse Table Construction\nMartin Rinard\nLaboratory for Computer Science\nMassachusetts Institute of Technology\n\nParse Tables (Review)\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Implements finite state control\n- At each step, look up\nT bl [\nf\nk] [ i\nb l]\n- Table[top of state stack] [ input symbol]\n- Then carry out the action\n\nParse Tables (Review)\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Shift to sn\n- Push input token into the symbol stack\n- Push sn into state stack\n- Advance to next input symbol\n\nParse Tables (Review)\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\n\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\nhift t\ns3\nerror\nshift to s4\nerror\ns4\nreduce (2)\nreduce (2)\nreduce (2)\n\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\n- Reduce (n)\n- Pop both stacks as many times as the number\nf\nb l\nth\nRHS\nf\nl\nof symbols on the RHS of rule n\n- Push LHS of rule n into symbol stack\n\nParser Generators and Parse Tables\n- Parser generator (YACC, CUP)\n- Given a grammar\n- Produces a (shift-reduce) parser for that grammar\n- Process grammar to synthesize a DFA\n- Contains states that the parser can be in\n- State transitions for terminals and non-terminals\n- Use DFA to create an parse table\n- Use parse table to generate code for parser\n\n(\n)\n( )\nExample\np\n- The grammar\nS → X $\n(1)\n\nX → (X )\n(2)\nX → ( )\n(3)\n\nDFA States Based on Items\n- We need to capture how much of a given\nproduction we have scanned so far\nproduction we have scanned so far\nX\n(\nX\n)\nX\n→ (\nX\n)\nAre we here? Or here? Or here? Or here?\n\nItems\n- We need to capture how much of a given\nproduction we have scanned so far\nproduction we have scanned so far\nX\n(\nX\n)\n- Production Generates 4 items\nX\n→ (\nX\n)\nProduction Generates 4 items\n- X → - (X )\n- X →\n( - X )\n- X →\n(X - )\n- X →\n(X ) -\n\nX\n(X )\nX →X\nExample of Items\np\n- The grammar\n- Items\nS → X $\nX → (X )\nX →(\n)\nS → - X $\nS → X - $\nX → ( )\nX → - (X )\nX → ( - X )\nX →(X - )\n(\n)\nX → (X ) -\nX → - ( )\nX → ( - )\nX → (\n) -\n\nNotation\n- If write production as A →α c β\n- α is sequence of grammar symbols, can be\nα is sequence of grammar symbols, can be\nterminals and nonterminals in sequence\n- c is terminal\n- β is sequence of grammar symbols, can be\nterminals and nonterminals in sequence\n- If write production as A→α - B β\n- α, β as above\n- B is a single grammar symbol, either terminal or\nnonterminal\n\narser\nto eve\nr\nu\n-\nIf th\nt t\nt i\nth\nit\nS\n$\nParser\nKey idea behind items\n- States correspond to sets of items\n- If the state contains the item A →α - c β\nP\nis expecting\nntually educe\nsing the\nParser is expecting to eventually reduce using the\nproduction A →α c β\n- Parser has already parsed an α\ny p\n- It expects the input may contain c, then β\n- If the state contains the item A →α -\n- Parser has already parsed an α\n- Will reduce using A →α\n- If the state contains the item S →α - $\nand the input buffer is empty\n-\naccepts input\naccepts input\nParser\n\n-\n-\np\np y\nCorrelating Items and Actions\n- If the current state contains the item A →α - c β\nand the current symbol in the input buffer is c\nand the current symbol in the input buffer is c\n- Parser shifts c onto stack\nNext state will contain A →α c - β\nNext state will contain A →α c β\n- If the current state contains the item A →α -\n- Parser reduces using A →α\nParser reduces using A →α\n- If the current state contains the item S →α - $\nand the input buffer is empty\n- Parser accepts input\n-\n\nt\n→\n→\n-\n-\n-\nClosure() of a set of items\n- Closure finds all the items in the same \"state\"\nFi\nd P i\nAl\nith\nf\nCl\n(I)\n- Fixed Point Algorithm for Closure(I)\n- Every item in I is also an item in Closure(I)\nIf A\nB β is in Closure(I) and B\nis\nIf A→ α\nB β is in Closure(I) and B→\nγ is\nan item, then add B→ - γ to Closure(I)\nRepeat until no more new items can be added\nRepeat until no more new items can be added\nto Closure(I)\n-\n\n-\n\nX\n(\n)\nExample of Closure\np\n- Closure({X→ ( - X )})\n- Items\nS → - X $\nS → X - $\nX →- (X )\nX →\n( - X )\nX → - (X )\nX →\n(X )\nX → ( - X )\nX → (X - )\nX → - ( )\nX → (X ) -\nX → - ( )\nX\n(\n)\nX → ( - )\nX → (\n) -\n\n-\n\nX\n(\n)\nAnother Example\np\n- closure({S → - X $})\n- Items\nS→\n- X $\nX → - (X )\nS → - X $\nS → X - $\nX →- (X )\nX → - ( )\nX →\n(X )\nX → ( - X )\nX → (X - )\nX → (X ) -\nX → - ( )\nX\n(\n)\nX → ( - )\nX → (\n) -\n\n-\nβ\nβ\nover\nGoto() of a set of items\n- Goto finds the new state after consuming a\ngrammar symbol while at the current state\ngrammar symbol while at the current state\nAlgorithm for Goto(I X)\nAlgorithm for Goto(I, X)\nwhere I is a set of items\nand X is a grammar symbol\nGoto(I, X) = Closure( { A→ α X - β | A→ α - X β in I })\n- goto is the new set obtained by \"moving\nthe dot\"\nX\nthe dot over X\n-\n\n-\n\nExample of Goto\np\n- Goto ({X → ( - X )}, X )\n- Items\nX → (X - )\nS → - X $\nS → X - $\nX →- (X )\nX →\n(X )\nX → ( - X )\nX → (X - )\nX → (X ) -\nX → - ( )\nX\n(\n)\nX → ( - )\nX → (\n) -\n\n-\n\nX\nAnother Example of Goto\np\n- Goto ({X → -(X )}, ()\n- Items\nS → - X $\nS → X - $\nX →- (X )\nX →\n( - X )\nX → - (X )\nX →\n(X )\nX → ( - X )\nX → (X - )\nX → - ( )\nX → (X ) -\nX → - ( )\nX\n(\n)\nX → ( - )\nX → (\n) -\n\nBuilding the DFA states\n- Start with the item S → - β $\n- Create the first state to be Closure({ S → - β $})\n- Pick a state I\n- for each item A→ α - X β in I\n- find Goto(I, X)\n- if Goto(I, X) is not already a state, make one\n- Add an edge X from state I to Goto(I, X) state\n- Repeat until no more additions possible\n\n→-\nDFA Example\nS → X - $\ns1\nX\nS → - X $\nX → - (X )\nX → - ( )\ns0\nX → ( - X )\nX → ( - )\nX\n(X )\ns2\n(\ns3\n(\nX →\n(X )\nX\n→ - ( )\n(\nX → (X - )\nX\ns3\n)\n)\nS →X $\nX → ( ) -\n)\ns5\nX → (X ) -\ns4\nS → X $\nX → (X )\nX → ( )\n\nConstructing A Parse Engine\n- Build a DFA - DONE\n- Construct a parse table using the DFA\n\nT\niti\nt\nth\nt t\ni\nt\ni\nl i\nt\nCreating the parse tables\n- For each state\n- Transition to another state using a terminal symbol is a\nshift to that state (shift to sn)\n- Transition to another state using a non-terminal is a goto\nto that state (goto sn)\n- If there is an item A →α - in the state\ndo a reduction with that production for all terminals\n(reduce k)\n\nBuilding Parse Table Example\nACTION\nGoto\nState\n(\n)\n$\nX\ns0\nshift to s2\nerror\nerror\ngoto s1\ns1\nerror\nerror\naccept\ns2\nshift to s2\nshift to s5\nerror\ngoto s3\ns3\nerror\nshift to s4\nerror\n\nd\n(2)\nd\n(2)\nd\n(2)\ns4\nreduce (2)\nreduce (2)\nreduce (2)\ns5\nreduce (3)\nreduce (3)\nreduce (3)\n\nS →X - $\ns1\nX\nS →- X $\nX →- (X)\nX →- ( )\ns0\nS →\n$\nX →( - X )\nX →( - )\nX\n(X )\ns2\n(\ns3\n(\nX →- (X )\nX\n→- ( )\n(\nX →(X - )\nX\ns3\n)\n)\nS →X $\nX →( ) -\n)\ns5\nX →(X ) -\n)\ns4\nX →(X )\nX →( )\n\n-\nt\nt t\nt\nCan\nto look ahead\nPotential Problem\n- No lookahead\n- Vulnerable to unnecessary conflicts\n- Shift/Reduce Conflicts (may reduce too soon in\nsome cases)\nReduce/Reduce Conflicts\nReduce/Reduce Conflicts\n- Solution: Lookahead\n- Only for reductions - reduce only when next\nOnly for reductions reduce only when next\nsymbol can occur after nonterminal from\nproduction\nS\nti l\nk h\nd\nlit\nb\nd\n- Systematic lookahead, split states based on next\nsymbol, action is always a function of next symbol\n- Can generalize to look ahead multiple symbols\ngeneralize\nmultiple symbols\n-\n\n-\nt\nt\nReduction-Only Lookahead Parsing\n- If a state contains A→β -\nR d\nb\nA\nβ\nl\nif\ni\nb l\n- Reduce by A→β only if next input symbol can\nfollow A in some derivation\nExample Grammar\nExample Grammar\nS → X $\nX →a\nX →a b\nX →a b\n-\n\nParser Without Lookahead\nACTION\nGoto\nState\na\nb\n$\nX\n$\ns0\nshift to s1\nerror\nerror\ngoto s3\ns1\nreduce(2)\nS/R Conflict reduce(2)\n\ns2\nreduce(3)\nreduce(3)\nreduce(3)\ns2\nreduce(3)\nreduce(3)\nreduce(3)\ns3\nerror\nerror\naccept\n\ns3\nS →- X $\nS →X - $\nX →a b -\ns0\ns3\ns2\nX\nX →- a\nX →- a b\nX →a -\nX →a b -\ns1\na\nb\nS →X $\nX →a - b\na\nX →a\nX →a b\n\n-\nd\nd\ni\ni h h\nd\ni\nh\nh\nCreating parse tables with reduction-\nonly lookahead\nonly lookahead\n- For each state\n- Transition to another state using a terminal symbol is a\nshift to that state (shift to sn) (same as before)\nTransition to another state using a non terminal is a goto\nTransition to another state using a non-terminal is a goto\nthat state (goto sn) (same as before)\n- If there is an item X →α - in the state\ndo a reduction with that production whenever the current\ninput symbol T may follow X in some derivation (more\nprecise than before)\n- Eliminates useless reduce actions\n-\n\nNew Parse Table\nb never follows X in any derivation\nresolve shift/reduce conflict to shift\nACTION\nGoto\nState\na\nb\n$\nX\n/\nState\na\nb\n$\ns0\nshift to s1\nerror\nerror\ngoto s3\ns1\nreduce(2)\nshift to s2\nreduce(2)\n\ns2\nreduce(3)\nreduce(3)\nreduce(3)\ns2\nreduce(3)\nreduce(3)\nreduce(3)\ns3\nerror\nerror\naccept\n\ns3\nS →- X $\nS →X - $\nX →a b -\ns0\ns3\ns2\nX\nX →- a\nX →- a b\nX →a -\nX →a b -\ns1\na\nb\nS →X $\nX →a - b\na\nX →a\nX →a b\n\n-\nMore General Lookahead\n- Items contain potential lookahead information,\nresulting in more states in finite state control\nresulting in more states in finite state control\n- Item of the form [A →α - β T] says\nThe parser has parsed an α\nThe parser has parsed an α\n- If it parses a β and the next symbol is T\n- Then parser should reduce by A →α β\nThen parser should reduce by A →α β\n- In addition to current parser state, all parser\nIn addition to current parser state, all parser\nactions are function of lookahead symbols\n-\n\n-\nTerminology\n- Many different parsing techniques\nEach can handle some set of CFGs\nEach can handle some set of CFGs\n- Categorization of techniques\n-\n\n-\n(\n)\nTerminology\n- Many different parsing techniques\nEach can handle some set of CFGs\nEach can handle some set of CFGs\n- Categorization of techniques\n(\n)\n-\n\n-\n(\n)\nTerminology\n- Many different parsing techniques\nEach can handle some set of CFGs\nEach can handle some set of CFGs\n- Categorization of techniques\n- L - parse from left to right\n- R - parse from right to left\n(\n)\n-\n\n-\n(\n)\nTerminology\n- Many different parsing techniques\nEach can handle some set of CFGs\nEach can handle some set of CFGs\n- Categorization of techniques\n- L - leftmost derivation\n- R - rightmost derivation\n(\n)\n-\n\n-\n(\n)\nTerminology\n- Many different parsing techniques\nEach can handle some set of CFGs\nEach can handle some set of CFGs\n- Categorization of techniques\n- Number of lookahead characters\n(\n)\n-\n\n-\nTerminology\n- Many different parsing techniques\nEach can handle some set of CFGs\nEach can handle some set of CFGs\n- Categorization of techniques\n- Examples: LL(0), LR(1)\n- This lecture\n(\n)\n- LR(0) parser\n- SLR parser - LR(0) parser augmented with\nfollow information\n(\n)\nL R\nk\nfollow information\n-\n\n-\nSummary\n- Parser generators - given a grammar, produce a parser\nStandard technique\nStandard technique\n- Automatically build a pushdown automaton\n- Obtain a shift-reduce parser\n- Finite state control plus push down stack\n- Table driven implementation\nConflicts: Shift/Reduce Reduce/Reduce\nConflicts: Shift/Reduce, Reduce/Reduce\n- Use of lookahead to eliminate conflicts\n- SLR parsing (eliminates useless reduce actions)\n- LR(k) parsing (lookahead throughout parser)\n-\n-\n\n-\nFollow() sets in SLR Parsing\nFollow() sets in SLR Parsing\nFor each non terminal A Follow(A) is the set of\nFor each non terminal A, Follow(A) is the set of\nterminals that can come after A in some derivation\n\nIf A\nB β i\nd\nti\nd β d\ni\nConstraints for Follow()\n- $ ∈Follow(S ), where S is the start symbol\nConstraints for Follow()\n- If A →αB β is a production then First(β) ⊆Follow(B )\n- If A →αB is a production then Follow(A) ⊆Follow(B )\n- If A →αB β is a production and β derives ε\nthen Follow(A) ⊆Follow(B )\n\n=\nhil\nF ll\nt k\nh\ni\np\nAlgorithm for Follow\ng\nfor all nonterminals NT\nFollow(NT) = {}\nFollow(S ) = { $ }\nwhile Follow sets keep changing\nfor all productions A →αB β\nFollow(B ) = Follow(B ) ∪First(β)\nFollow(B )\nFollow(B ) ∪First(β)\nif (β derives ε) Follow(B ) = Follow(B )∪Follow(A )\nfor all productions A →αB\nFollow(B ) = Follow(B )∪Follow(A )\n\n$\nS\n$\n(\n)\n{\n}\nAugmenting Example with Follow\n- Example Grammar for Follow\nS → X $\nX → a\nX → a b\nFollow(S ) = { $ }\nFollow(X ) = { $ }\n\nSLR Eliminates Shift/Reduce Conflict\nACTION\nGoto\nState\na\nb\n$\nX\ns0\nshift to s1\nerror\nerror\ngoto s3\ns1\nreduce(2)\nshift to s2\nreduce(2)\n( )\n( )\ns2\nreduce(3)\nreduce(3)\nreduce(3)\ns3\nerror\nerror\naccept\n\nS\nX $\nS →X - $\ns0\ns3\ns2\nX\nb∈Follow(X)\nS →- X $\nX →- a\nX →- a b\nX →a -\nX →a b -\ns1\nb\nX →a -\nX →a - b\na\nb\n\nt\nBasic Idea Behind LR(1)\n- Split states in LR(0) DFA based on lookahead\nR d\nb\nd\ni\nd l\nk h\nd\n- Reduce based on item and lookahead\n\n-\n-\nLR(1) Items\n( )\n- Items will keep info on\n- production\n- right-hand-side position (the dot)\n- look ahead symbol\nLR(1) item is of the form [A →α - β\nT]\nLR(1) item is of the form [A →α\nβ\nT]\n- A →α β is a production\n- The dot in A →α - β denotes the position\n- T is a terminal or the end marker ($)\n-\n\nMeaning of LR(1) Items\ng\n( )\n- Item [A →α - β\nT] means\n- The parser has parsed an α\n- If it parses a β and the next symbol is T\n- Then parser should reduce by A →α β\n\n-\nX\nX\n[\n$\n$]\n→\n-\nX →\nX\n$\n- The grammar\nS →X $\n- Terminal symbols\n- '('\n')'\nX →(X)\nX →ε\n(\n)\n- End of input symbol\n- '$'\n[S →- X $\n) ]\n\n[S →- X $\n( ]\n\n[X →\n(X -\n) ]\nLR(1) Items\n[S →- X $\n$ ]\n\n[S →X - $\n) ]\n[S →X - $ ( ]\nS\nX\n[X →\n(X - )\n( ]\n[X →\n(X - )\n$ ]\n[X →\n(X) - ) ]\n[X\n(X)\n( ]\n[S →X - $\n$]\n[X →- (X)\n) ]\n\n[X →- (X)\n( ]\n\n[X →- (X)\n$ ]\n[X →\n(X)\n( ]\n[X →\n(X) - $ ]\n[X →\n- ) ]\n[X →\n- ( ]\n[X →\n(X)\n$ ]\n[X →\n( - X)\n) ]\n[X →\n( - X)\n( ]\n\n[X →\n( - X)\n$ ]\n[X →\n( ]\n[X →\n- $ ]\n[\n(\n)\n]\n\nN\nd\nid\nl\ni h\nh\nDFA\nN\nd t\nid\nl\nith\nt\nt\nth\nCreating a LR(1) Parser Engine\ng\n( )\ng\n- Need to define Closure() and Goto() functions for\nLR(1) items\n- Need to provide an algorithm to create the DFA\n- Need to provide an algorithm to create the parse\ntable\n\nClosure algorithm\ng\nClosure(I)\nrepeat\nfor all items [A →α - X β c] in I\nfor any production X → γ\nfor any d ∈First(βc)\nI = I ∪{ [X →- γ d] }\nuntil I does not change\n\n( )\nGoto algorithm\ng\nGoto(I, X)\nJ = { }\nfor any item [A →α - X β c] in I\nJ = J ∪{[A →α X - β c]}\nreturn Closure(J)\n\nBuilding the LR(1) DFA\ng\n( )\n- Start with the item [<S'> →- <S> $ I]\n- I irrelevant because we will never shift $\n- Find the closure of the item and make an state\n- Pick a state I\n- for each item [A→α - X β c] in I\n- find Goto(I, X)\n- if Goto(I, X) is not already a state, make one\n- Add an edge X from state I to Goto(I, X) state\n- Repeat until no more additions possible\n\nCreating the parse tables\ng\np\n- For each LR(1) DFA state\n- Transition to another state using a terminal\nsymbol is a shift to that state (shift to sn)\n- Transition to another state using a non-terminal\nsymbol is a goto that state (goto sn)\n- If there is an item [A → α - a] in the state,\naction for input symbol a is a reduction via the\nproduction A →α (reduce k)\nproduction A → α (reduce k)\n\n-\nLALR(1) Parser\n( )\n- Motivation\n- LR(1) parse engine has a large number of states\n- Simple method to eliminate states\n- If two LR(1) states are identical except for the look\nahead symbol of the items\nThen Merge the states\nThen Merge the states\n- Result is LALR(1) DFA\n- Typically has many fewer states than LR(1)\nTypically has many fewer states than LR(1)\n- May also have more reduce/reduce conflicts\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec04.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/94e807f043d66b1429301fa20e1ba234_MIT6_035S10_lec04.pdf",
      "content": "MIT 6 035\nMIT 6.035\nTop-Down Parsing\nMartin Rinard\nLaboratory for Computer Science\nMassachusetts Institute of Technology\n\n-\nparsers\n-\nOrientation\n- Language specification\n- Lexical structure - regular expressions\n- Syntactic structure - grammar\nThis Lecture\nrecursive descent\nThis Lecture - recursive descent parsers\n- Code parser as set of mutually recursive procedures\n- Structure of program matches structure of grammar\nStructure of program matches structure of grammar\n\n-\nStarting Point\n- Assume lexical analysis has produced a sequence\nof tokens\nof tokens\n- Each token has a type and value\n- Types correspond to terminals\nTypes correspond to terminals\n- Values to contents of token read in\n- Examples\nExamples\n- Int 549 - integer token with value 549 read in\n- if - if keyword, no need for a value\nif if keyword, no need for a value\n- AddOp + - add operator, value +\n\nt\nt\np\ny\np\nBasic Approach\n- Start with Start symbol\nB ild\nl f\nd\ni\nti\n- Build a leftmost derivation\n- If leftmost symbol is nonterminal, choose a\nproduction and apply it\nproduction and apply it\n- If leftmost symbol is terminal, match against\ninput\n- If all terminals match, have found a parse!\n- Key: find correct productions for nonterminals\n\ne\nGraphical Illustration of Leftmost\nDerivation\nDerivation\nSentential Form\nNT1 T1 T2 T3 NT2 NT3\nApply Production\nHer\nNot Here\nHere\n\nor conve\nmay represent\n-\nGrammar for Parsing Example\ng\np\nStart → Expr\n- Set of tokens is\nExpr → Expr + Term\nExpr → Expr - Term\nExpr →Term\nSet of tokens is\n{ +, -, *, /, Int }, where\nInt = [0-9][0-9]*\nF\nnience\nExpr → Term\nTerm → Term * Int\nTerm → Term / Int\nFor convenience, may represent\neach Int n token by n\nTerm → Int\n\nParsing Example\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nSentential Form\nStart\nStart\nCurrent Position in Parse Tree\n\npp\nParsing Example\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nExpr\np\nApplied Production\nExpr\nStart → Expr\nCurrent Position in Parse Tree\n\nParsing Example\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nStart\nExpr\nSentential Form\nExpr - Term\np\nTerm\nExpr\n-\nApplied Production\nExpr Term\nExpr →Expr + Term\npp\nExpr →Expr - Term\nExpr →Expr - Term\nExpr →Term\n\n→\ne\np\npp\nExpr →Term\nParsing Example\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nTerm - Term\nTerm\nExpr\n-\nApplied Production\nTerm Term\nTerm\nExpr → Expr + Term\np\np\nExpr → Expr - Term\nExpr → Term\nExpr → Term\n\np\npp\nParsing Example\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nTerm\nExpr\n-\nInt - Term\nApplied Production\nTerm\nInt Term\nTerm → Int\nInt\n\np\nParsing Example\nStart\nParse\nTree\nRemaining Input\nMatch\nStart\nTree\n2-2*2\nExpr\nMatch\nInput\nToken!\nSentential Form\n2 - Term\nTerm\nExpr\n-\nTerm\nTerm\nInt 2\n\np\nParsing Example\nStart\nParse\nTree\nRemaining Input\nMatch\nStart\nTree\n-2*2\nExpr\nMatch\nInput\nToken!\nSentential Form\n2 - Term\nTerm\nExpr\n-\nTerm\nTerm\nInt 2\n\np\nParsing Example\nStart\nParse\nTree\nRemaining Input\nMatch\nStart\nTree\n2*2\nExpr\nMatch\nInput\nToken!\nSentential Form\n2 - Term\nTerm\nExpr\n-\nTerm\nTerm\nInt 2\n\np\npp\nParsing Example\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2*2\nExpr\nSentential Form\n2 - Term*Int\nTerm\nExpr\n-\nApplied Production\nTerm Int\nTerm Term\nInt\n*\nTerm → Term * Int\nInt 2\n\np\npp\nParsing Example\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2*2\nExpr\nSentential Form\n2 - Int * Int\nTerm\nExpr\n-\nApplied Production\nInt\nInt\nTerm Term\nInt\n*\nTerm → Int\nInt 2 Int\n\np\nParsing Example\nMatch\nStart\nParse\nTree\nRemaining Input\nMatch\nInput\nToken!\nStart\nTree\n2*2\nExpr\nSentential Form\n2 - 2* Int\nTerm\nExpr\n-\nInt\nTerm Term\nInt\n*\nInt 2 Int 2\n\np\nParsing Example\nMatch\nStart\nParse\nTree\nRemaining Input\nMatch\nInput\nToken!\nStart\nTree\n*2\nExpr\nSentential Form\n2 - 2* Int\nTerm\nExpr\n-\nInt\nTerm Term\nInt\n*\nInt 2 Int 2\n\np\nParsing Example\nMatch\nStart\nParse\nTree\nRemaining Input\nMatch\nInput\nToken!\nStart\nTree\nExpr\nSentential Form\n2 - 2* Int\nTerm\nExpr\n-\nInt\nTerm Term\nInt\n*\nInt 2 Int 2\n\np\nParsing Example\nStart\nParse\nTree\nRemaining Input\nParse\nStart\nTree\nExpr\nParse\nComplete!\nSentential Form\n2 - 2*2\nTerm\nExpr\n-\n2 2\nTerm Term\nInt 2\n*\nInt 2 Int 2\n\n-\nt\nt\nt\nSummary\n- Three Actions (Mechanisms)\nA\nl\nd\ni\nd\n- Apply production to expand current\nnonterminal in parse tree\nMatch current terminal (consuming input)\nMatch current terminal (consuming input)\n- Accept the parse as correct\n- Parser generates preorder traversal of parse tree\nParser generates preorder traversal of parse tree\n- visit parents before children\n- visit siblings from left to right\nvisit siblings from left to right\n-\n\np\ny\nPolicy Problem\n- Which production to use for each nonterminal?\n- Classical Separation of Policy and Mechanism\n- One Approach: Backtracking\n- Treat it as a search problem\n- At each choice point, try next alternative\n- If it is clear that current try fails, go back to\nprevious choice and try something different\nprevious choice and try something different\n- General technique for searching\n- Used a lot in classical AI and natural language\ng\ng\nprocessing (parsing, speech recognition)\n\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nSentential Form\nStart\nStart\n\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nExpr\np\nApplied Production\nExpr\nStart → Expr\n\np\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nExpr + Term\nTerm\nExpr\n+\nApplied Production\nExpr\nTerm\nExpr → Expr + Term\n\np\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nTerm + Term\nTerm\nExpr\n+\nApplied Production\nTerm\nTerm\nTerm\nExpr → Term\n\np\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nMatch\nStart\nTree\n2-2*2\nExpr\nMatch\nInput\nToken!\nSentential Form\nInt + Term\nTerm\nExpr\n+\nToken!\nApplied Production\nInt\nTerm\nTerm\nTerm → Int\nInt\n\np\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nCan't\nStart\nTree\n-2*2\nExpr\nCan t\nMatch\nInput\nSentential Form\n2 - Term\nTerm\nExpr\n+\nInput\nToken!\nApplied Production\n2 Term\nTerm\nTerm → Int\nInt 2\n\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nSo\nStart\nTree\n2-2*2\nExpr\nSo\nBacktrack!\nSentential Form\nExpr\np\nApplied Production\nExpr\nStart → Expr\n\np\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nExpr - Term\nTerm\nExpr\n-\nApplied Production\nExpr Term\nExpr → Expr - Term\n\np\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nTerm - Term\nTerm\nExpr\n-\nTerm\nApplied Production\nTerm Term\nExpr → Term\n\np\npp\nBacktracking Example\ng\np\nStart\nParse\nTree\nRemaining Input\nStart\nTree\n2-2*2\nExpr\nSentential Form\nInt - Term\nTerm\nExpr\n-\nTerm\nApplied Production\nInt Term\nTerm → Int\nInt\n\np\nBacktracking Example\nMatch\ng\np\nStart\nParse\nTree\nRemaining Input\nMatch\nInput\nToken!\nStart\nTree\n-2*2\nExpr\nToken!\nSentential Form\n2 - Term\nTerm\nExpr\n-\nTerm\n2 Term\nInt 2\n\np\nBacktracking Example\nMatch\ng\np\nStart\nParse\nTree\nRemaining Input\nMatch\nInput\nToken!\nStart\nTree\n2*2\nExpr\nToken!\nSentential Form\n2 - Term\nTerm\nExpr\n-\nTerm\n2 Term\nInt 2\n\nt\nt\n*\nLeft Recursion + Top-Down Parsing\n= Infinite Loop\nInfinite Loop\n- Example Production: Term → Term*Num\nP t\ni l\ni\n- Potential parsing steps:\nTerm\nNum\nTerm\nTerm\nTerm\nTerm\nNum\nNum\n*\nTerm\nTerm\nNum\n*\nTerm\nNum\n*\n\na\n-\none\nmore\nGeneral Search Issues\n- Three components\n- Search space (parse trees)\nSearch algorithm (parsing\nlgorithm)\nSearch algorithm (parsing algorithm)\n- Goal to find (parse tree for input program)\n- Would like to (but can't always) ensure that\n- Find goal (hopefully quickly) if it exists\n- Search terminates if it does not\n- Handled in various ways in various contexts\nHandled in various ways in various contexts\n- Finite search space makes it easy\n- Exploration strategies for infinite search space\nSometimes\ngoal\nimportant (model checking)\n- Sometimes one goal more important (model checking)\n- For parsing, hack grammar to remove left recursion\n\nnot start\nparse\nβ\nEliminating Left Recursion\n- Start with productions of form\n- A →A α\n- A →β\n- α, β sequences of terminals and nonterminals that\ndo\nith A\ndo not start with A\n- Repeated application of A →A α\nbuilds\ntree like this:\nA\nbuilds parse tree like this:\nα\nA\nα\nA\nα\nβ\n\nα\nR\nEliminating Left Recursion\n- Replacement productions\n- A →A α\nA →β R\nR is a new nonterminal\n- A →β\nR →α R\n-\nR →ε\nNew Parse Tree\nA\nA\nOld Parse Tree\nNew Parse Tree\nA\nα\nA\nβ\nR\nα\nR\nA\nα\nβ\nα\nα\nR\nε\n\nrm →\nt\nrm\nHacked Grammar\nOriginal Grammar\nFragment\nNew Grammar Fragment\nTe\nIn Te\n'\nFragment\nTerm → Term * Int\nTerm → Term / Int\nTerm → Int Term\nTerm' → * Int Term'\nTerm' → / Int Term'\nTerm → Int\nTerm' → ε\n\nParse Tree Comparisons\np\nOriginal Grammar\nNew Grammar\nTerm\nTerm\nOriginal Grammar\nNew Grammar\nTerm\nTerm\nInt\n*\nInt\nTerm'\nInt\n*\nInt\nInt\n*\nTerm'\nInt\n*\nTerm'\nε\n\nt\nt\nt\nup\np\np\n-\nEliminating Left Recursion\n- Changes search space exploration algorithm\nEli\ni\ndi\ni fi i\ni\n- Eliminates direct infinite recursion\n- But grammar less intuitive\nSets things\nfor\nredictive\narsing\nSets things up for predictive parsing\n\n-\nPredictive Parsing\n- Alternative to backtracking\nU\nf l f\ni\nl\nhi h\nb\n- Useful for programming languages, which can be\ndesigned to make parsing easier\n- Basic idea\nBasic idea\n- Look ahead in input stream\n- Decide which production to apply based on\nDecide which production to apply based on\nnext tokens in input stream\n- We will use one token of lookahead\n\nrm →\nrm\nPredictive Parsing Example Grammar\nStart →Expr\nTe\nInt Te\n'\nStart → Expr\nExpr → Term Expr'\nExpr' → + Expr'\nTerm → In t Term\nTerm' → * In t Term'\nTerm' → / In t Term'\nExpr' → - Expr'\nExpr' → ε\nTerm' → ε\n\n-\ne\n→\nt\ne\nChoice Points\n- Assume Term' is current position in parse tree\n- Have three possible productions to apply\nHave three possible productions to apply\nTerm' →* Int Term'\nTerm' →/ Int Term'\n/\nTerm' →ε\n- Use next token to decide\n- If next token is *, apply Term' →* Int Term'\n- If next token is /, apply Term' →/ Int Term'\n- Otherwise apply Term' →ε\nOtherwise, apply Term →ε\n\nβ\nP\nd\nti\nNT\nβ\nNT\nβ\np\npp y\nC\nt\ni\nl i\nβ ( h\nk f\nt\nk\nt\nPredictive Parsing + Hand Coding =\nRecursive Descent Parser\nRecursive Descent Parser\n- One procedure per nonterminal NT\n- Productions NT → β1 , ..., NT → βn\n- Procedure examines the current input symbol T to\ndetermine which production to apply\n- If T∈First(βk)\n- Apply production k\n- Consume terminals in βk (check for correct\nterminal)\n- Recursively call procedures for nonterminals in βk\n- Current input symbol stored in global variable token\n- Procedures return\nif\nd\n- true if parse succeeds\n- false if parse fails\n\nif (t k\nI t\n) t k\nN\ntT k\n()\nt\n(T\nP i\n())\nExample\nBoolean Term()\nif (token = Int n) token = NextToken(); return(TermPrime())\nelse return(false)\nBoolean TermPrime()\nBoolean TermPrime()\nif (token = *)\ntoken = NextToken();\nif (token = Int n) token = NextToken(); return(TermPrime())\nelse return(false)\nelse if (token = /)\ntoken = NextToken();\nif (token = Int n) token = NextToken(); return(TermPrime())\nelse return(false)\nelse return(false)\nelse return(true)\nTerm →Int Term'\nTerm' →* Int Term'\nTerm' →/ Int Term'\nTerm' →ε\n\nparse ree a\n-\nMultiple Productions With Same\nPrefix in RHS\nPrefix in RHS\n- Example Grammar\nNT\nif th\nNT → if then\nNT → if then else\nAssume NT is current position in\nt\nnd\nAssume NT is current position in parse tree, and\nif is the next token\n- Unclear which production to apply\nUnclear which production to apply\n- Multiple k such that T∈First(βk)\n- if ∈First(if then)\nif ∈ First(if then)\n- if ∈ First(if then else)\n\nSolution: Left Factor the Grammar\n- New Grammar Factors Common Prefix Into\nSingle Production\nSingle Production\nNT →if then NT'\nNT' →else\nNT →else\nNT' →ε\n- No choice when next token is if!\nNo choice when next token is if!\n- All choices have been unified in one production.\n\nNT\nNT\nWh t if\nt\n?\nNonterminals\n- What about productions with nonterminals?\nNT → NT1 α1\nNT → NT2 α 2\n- Must choose based on possible first terminals\nthat NT1 and NT2 can generate\nNT\nNT\n- What if NT1 or NT2 can generate ε?\n- Must choose based on α1 and α2\n\nNT\ni\nli\nNT d\ni\nNT derives ε\n- Two rules\n- NT →ε implies NT derives ε\n- NT →NT1 ... NTn and for all 1≤i ≤n NTi\nd\ni\ni\nli\nNT d\ni\nderives ε implies NT derives ε\n\nt\nt\n→\nFixed Point Algorithm for Derives ε\nfor all nonterminals NT\nNT d\ni\nb\nf l\nset NT derives ε to be false\nfor all productions of the form NT →ε\nset NT derives\nto be true\nset NT derives ε to be true\nwhile (some NT derives ε changed in last iteration)\nfor all productions of the form NT\nNT\nNT\nfor all productions of the form NT →NT1 ... NTn\nif (for all 1≤i ≤n NTi derives ε)\nset NT derives ε to be true\nset NT derives ε to be true\n\n⊆\nβ\ni\nt\ni\nl\ni\nt\ni\nl\ni\nFirst(β)\n- T∈ First(β ) if T can appear as the first\nsymbol in a derivation starting from β\nsymbol in a derivation starting from β\n1) T∈First(T )\n2) First(S ) ⊆ First(S β)\n)\n(\n)\n(\n)\n3) NT derives ε implies First(β) ⊆ First(NT β)\n4) NT → S β implies First(S β) ⊆ First(NT )\n- Notation\nT\nNT\nS\n- T is a terminal, NT is a nonterminal, S is a\nterminal or nonterminal, and β is a sequence\nof terminals or nonterminals\n\num erm\nRules + Request Generate System of Subset\nInclusion Constraints\nInclusion Constraints\nGrammar\nTerm' →* Int Term'\nRequest: What is First(Term' )?\nTerm' →/ Int Term'\nTerm' →ε\nConstraints\nFirst(* Num Term' ) ⊆First(Term' )\nFirst(/ Num Term' ) ⊆First(Term' )\nFirst(*) ⊆First(* Num Term' )\nFirst(/) ⊆First(/ N\nT\n' )\nRules\n1) T∈First(T )\nFirst(/) ⊆First(/ Num Term )\n*∈First(*)\n/ ∈First(/)\n)\n(\n)\n2) First(S) ⊆First(S β)\n3) NT derives ε implies\nFirst(β) ⊆First(NT β)\n4) NT →S β implies\nFirst(S β)\nFirst(NT )\nFirst(S β) ⊆First(NT )\n\n=\nConstraint Propagation Algorithm\np g\ng\nConstraints\nSolution\nFirst(* Num Term' ) ⊆ First(Term' )\nFirst(/ Num Term' ) ⊆ First(Term' )\nFirst(*) ⊆First(* Num Term' )\nSolution\nFirst(Term' ) = {}\nFirst(* Num Term' ) = {}\nFirst( ) ⊆ First(\nNum Term )\nFirst(/) ⊆ First(/ Num Term' )\n*∈First(*)\nFirst(/Num T erm' ) = {}\nFirst(*) = {*}\nFirst(/) = {/}\n/ ∈First(/)\nFirst(/)\n{/}\nInitialize Sets to {}\nPropagate Constraints Until\nFixed Point\n\n=\nConstraint Propagation Algorithm\np g\ng\nConstraints\nSolution\nFirst(* Num Term' ) ⊆ First(Term' )\nFirst(/ Num Term' ) ⊆ First(Term' )\nFirst(*) ⊆First(* Num Term' )\nSolution\nFirst(Term' ) = {}\nFirst(* Num Term' ) = {}\nFirst( ) ⊆ First(\nNum Term )\nFirst(/) ⊆ First(/ Num Term' )\n*∈First(*)\nFirst(/Num T erm' ) = {}\nFirst(*) = {*}\nFirst(/) = {/}\n/ ∈First(/)\nFirst(/)\n{/}\nGrammar\nTerm' → * Int Term'\nTerm' → / Int Term'\nTerm' →ε\nTerm → ε\n\n=\nConstraint Propagation Algorithm\np g\ng\nSolution\nConstraints\nSolution\nFirst(Term' ) = {}\nFirst(* Num Term' ) = {*}\nFirst(* Num Term' ) ⊆ First(Term' )\nFirst(/ Num Term' ) ⊆ First(Term' )\nFirst(*) ⊆First(* Num Term' )\nFirst(/Num T erm' ) = {/}\nFirst(*) = {*}\nFirst(/) = {/}\nFirst( ) ⊆ First(\nNum Term )\nFirst(/) ⊆ First(/ Num Term' )\n*∈First(*)\nFirst(/)\n{/}\n/ ∈First(/)\nGrammar\nTerm' → * Int Term'\nTerm' → / Int Term'\nTerm' →ε\nTerm → ε\n\n=\nConstraint Propagation Algorithm\np g\ng\nSolution\nConstraints\nSolution\nFirst(Term' ) = {*,/}\nFirst(* Num Term' ) = {*}\nFirst(* Num Term' ) ⊆ First(Term' )\nFirst(/ Num Term' ) ⊆ First(Term' )\nFirst(*) ⊆First(* Num Term' )\nFirst(/Num T erm' ) = {/}\nFirst(*) = {*}\nFirst(/) = {/}\nFirst( ) ⊆ First(\nNum Term )\nFirst(/) ⊆ First(/ Num Term' )\n*∈First(*)\nFirst(/)\n{/}\n/ ∈First(/)\nGrammar\nTerm' → * Int Term'\nTerm' → / Int Term'\nTerm' →ε\nTerm → ε\n\n=\nConstraint Propagation Algorithm\np g\ng\nSolution\nConstraints\nSolution\nFirst(Term' ) = {*,/}\nFirst(* Num Term' ) = {*}\nFirst(* Num Term' ) ⊆ First(Term' )\nFirst(/ Num Term' ) ⊆ First(Term' )\nFirst(*) ⊆First(* Num Term' )\nFirst(/Num T erm' ) = {/}\nFirst(*) = {*}\nFirst(/) = {/}\nFirst( ) ⊆ First(\nNum Term )\nFirst(/) ⊆ First(/ Num Term' )\n*∈First(*)\nGrammar\nFirst(/)\n{/}\n/ ∈First(/)\nTerm' → * Int Term'\nTerm' → / Int Term'\nTerm' →ε\nTerm → ε\n\nBuilding A Parse Tree\n- Have each procedure return the section of the\nparse tree for the part of the string it parsed\nparse tree for the part of the string it parsed\n- Use exceptions to make code structure clean\n\n;\n();\n(\n)\nBuilding Parse Tree In Example\nTerm()\nif (token = Int n)\noldToken = token; token = NextToken();\nnode = TermPrime();\nif (node == NULL) return oldToken;\nelse return(new TermNode(oldToken node);\nelse return(new TermNode(oldToken, node);\nelse throw SyntaxError\nTermPrime()\nif (token = *) || (token = /)\nfirst = token; next = NextToken();\nif (next = Int n)\ntoken = NextToken();\nreturn(new TermPrimeNode(first, next, TermPrime())\nelse throw SyntaxError\nelse throw SyntaxError\nelse return(NULL)\n\n*\nInt\nParse Tree for 2*3*4\nConcrete\nParse Tree\nDesired\nAbstract\nTerm\nInt\nTerm'\nTerm\nParse Tree\nInt\nTerm\nInt\n*\nTerm'\nTerm\nTerm\nInt\n*\nInt\nTerm\nInt\n*\nTerm'\nInt\n*\nInt\nε\n\n-\na se\ne e ato\n-\no\nzone\n-\np\ny\nWhy Use Hand-Coded Parser?\n- Why not use parser generator?\nWhat do you do if your parser doesn't work?\nWhat do you do if your parser doesn t work?\n- Recursive descent parser - write more code\n- Parser generator\ng\n- Hack grammar\n- But if parser generator doesn't work,\nnothing you can do\n- If you have complicated grammar\nIncrease chance of going\nutside comfort\nIncrease chance of going outside comfort zone\nof parser generator\n- Your parser may NEVER work\n-\n\ny\np\np\np\n-\nmore\n-\np\n-\nBottom Line\n- Recursive descent parser properties\nProbably\nwork\nProbably more work\n- But less risk of a disaster - you can almost always\nmake a recursive descent parser work\n- May have easier time dealing with resulting code\n- Single language system\n- No need to deal with potentially flaky parser\ngenerator\nNo integration issues with automatically\nNo integration issues with automatically\ngenerated code\n- If your parser development time is small compared to\nrest of project, or you have a really complicated\nlanguage, use hand-coded recursive descent parser\n-\n\nt\nt\n-\nSummary\n- Top-Down Parsing\nU\nL\nk h\nd\nA\nid B\nk\nki\n- Use Lookahead to Avoid Backtracking\n- Parser is\nHand Coded\nHand-Coded\n- Set of Mutually Recursive Procedures\n\nMissing left child\nMissing left child\nto be filled in by\ncaller\nDirect Generation of Abstract Tree\n- TermPrime builds an incomplete tree\n- Missing leftmost child\n- Returns root and incomplete node\nReturns root and incomplete node\n- (root, incomplete) = TermPrime()\n- Called with token = *\n- Remaining tokens = 3 * 4\nTerm\nTerm\nInt\n*\nroot\nincomplete\nTerm\nInt\n*\nInt\n*\nincomplete\nMissing Left child\nto be filled in by\ncaller\n\np\n;\nn\n=\nCode for Term\nInput to\nTerm()\nif (token = Int n)\nleftmostInt = token; token = NextToken();\n2*3*4\nparse\n();\n(root, incomplete) = TermPrime();\nif (root == NULL) return leftmostInt;\nincomplete leftChild\nleftmostI t;\nincomplete.leftChild\nleftmostInt;\nreturn root;\nelse throw SyntaxError\nInt\ntoken\n\np\n;\nn\n=\nCode for Term\nInput to\nTerm()\nif (token = Int n)\nleftmostInt = token; token = NextToken();\n2*3*4\nparse\n();\n(root, incomplete) = TermPrime();\nif (root == NULL) return leftmostInt;\nincomplete leftChild\nleftmostI t;\nincomplete.leftChild\nleftmostInt;\nreturn root;\nelse throw SyntaxError\nInt\ntoken\n\np\n;\nn\n=\nCode for Term\nInput to\nTerm()\nif (token = Int n)\nleftmostInt = token; token = NextToken();\n2*3*4\nparse\n();\n(root, incomplete) = TermPrime();\nif (root == NULL) return leftmostInt;\nincomplete leftChild\nleftmostI t;\nincomplete.leftChild\nleftmostInt;\nreturn root;\nelse throw SyntaxError\nInt\ntoken\n\np\n;\nn\n=\nCode for Term\nInput to\nTerm()\nif (token = Int n)\nleftmostInt = token; token = NextToken();\n2*3*4\nparse\n();\n(root, incomplete) = TermPrime();\nif (root == NULL) return leftmostInt;\nincomplete leftChild\nleftmostI t;\nincomplete.leftChild\nleftmostInt;\nreturn root;\nelse throw SyntaxError\nTerm\nroot\nTerm\nInt\n*\nincomplete\nInt\n*\nInt\nleftmostInt\n\np\n;\nn\n=\nCode for Term\nInput to\nTerm()\nif (token = Int n)\nleftmostInt = token; token = NextToken();\n2*3*4\nparse\n();\n(root, incomplete) = TermPrime();\nif (root == NULL) return leftmostInt;\nincomplete leftChild\nleftmostI t;\nincomplete.leftChild\nleftmostInt;\nreturn root;\nelse throw SyntaxError\nTerm\nroot\nTerm\nInt\n*\nincomplete\nInt\n*\nInt\nleftmostInt\n\np\n;\nn\n=\nCode for Term\nInput to\nTerm()\nif (token = Int n)\nleftmostInt = token; token = NextToken();\n2*3*4\nparse\n();\n(root, incomplete) = TermPrime();\nif (root == NULL) return leftmostInt;\nincomplete leftChild\nleftmostI t;\nincomplete.leftChild\nleftmostInt;\nreturn root;\nelse throw SyntaxError\nTerm\nroot\nTerm\nInt\n*\nincomplete\nInt\n*\nInt\nleftmostInt\n\nt k\nt\nN\ntT k\n()\nCode for TermPrime\nTermPrime()\nif (token = *) || (token = /)\nMissing left child\nop = token; next = NextToken();\nif (next = Int n)\ntoken = NextToken();\n(root, incomplete) = TermPrime();\nto be filled in by\ncaller\n(root, incomplete)\nTermPrime();\nif (root == NULL)\nroot = new ExprNode(NULL, op, next);\nreturn (root, root);\nelse\nnewChild = new ExprNode(NULL, op, next);\nincomplete.leftChild = newChild;\nreturn(root, newChild);\nelse throw SyntaxError\nelse throw SyntaxError\nelse return(NULL,NULL)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec05.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/9cf8420476f3f673410b3b11e2bf029b_MIT6_035S10_lec05.pdf",
      "content": "MIT 6.035\nMIT 6.035\nIntermediate Formats\nMartin Rinard\nLaboratory for Computer Science\nMassachusetts Institute of Technology\nMassachusetts Institute of Technology\n\nProgram Representation Goals\ng\np\n- Sequence of Steps\nStructure Translation to Machine Code\n- Enable Program Analyysis and Transformation\n- Semantic Checks, Correctness Checks, Optimizations\n- Structure Translation to Machine Code\nSemantic\nAnalysis\nHigh Level\nLow Level\nParse\nTree\nHigh Level\nIntermediate\nRepresentation\nLow Level\nIntermediate\nRepresentation\nMachine\nCode\nAnalysis\n\nHigh Level IR\ng\n- Preserves Object Structure\n- Preserves Structured Flow of Control\n- Primary Goal: Analyze Program\nLow Level IR\n- Moves Data Model to Flat Address Space\n- Eliminates Structured Control Flow\nEliminates Structured Control Flow\n- Suitable for Low Level Compilation Tasks\nRegister Allocation\n- Register Allocation\n- Instruction Selection\n\nExamples of Object Representation\np\nj\np\nand Program Execution\n(Thi h\nh\n)\n(This happens when program runs)\n\nExample Vector Class\np\nclass vector {\nint v[];\nint v[];\nvoid add(int x) {\nint i;\ni = 0;\nwhile (i < v.length) { v[i] = v[i]+x; i = i+1; }\n}\n}\n\nRepresenting Arrays\n- Items Stored Contiguously In Memory\np\ng\ny\ng\ny\ny\n- Length Stored In First Word\n- Color Code\n- Red - generated by compiler automatically\n- Blue, Yellow, Lavender - program data or code\n- Magenta - executing code or data\n\nRepresenting Vector Objects\np\ng\nj\n- First Word Points to Class Information\n- Method Table, Garbage Collector Data\n- Next Words Have Object Fields\nNext Words Have Object Fields\n- For vectors, Next Word is Reference to Array\nClass Info\n\nInvoking Vector Add Method\ng\nvect.add(1);\n- Create Activation Record\nl\nf\nClass Info\n\nInvoking Vector Add Method\ng\nvect.add(1);\n- Create Activation Record\n- this onto stack\nthis\nthis onto stack\nl\nf\nClass Info\n\nInvoking Vector Add Method\ng\nvect.add(1);\n- Create Activation Record\n- this onto stack\nx\nthis\nthis onto stack\n- parameters onto stack\nl\nf\nClass Info\n\n-\nstack\nstack\nInvoking Vector Add Method\ng\nvect.add(1);\n- Create Activation Record\n- this onto stack\nx\nthis\nthis onto stack\n- parameters onto stack\nspace for locals on\ni\nspace for locals on\nl\nf\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\nvoid add(int x) {\ng\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n)\n+x;\nExecuting Vector Add Method\nvoid add(int x) {\ng\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n)\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+ ;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i] x\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]+x;\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\n+x;\nExecuting Vector Add Method\ng\nvoid add(int x) {\nint i;\ni = 0;\nx\nthis\nwhile (i < v.length)\nv[i] = v[i]\ni\n[ ]\n[ ]\n;\ni = i+1;\n}\nl\nf\n}\nClass Info\n\nWhat does the compiler have to do\nto make all of this work?\n\n-\nCompilation Tasks\np\n- Determine Format of Objects and Arrays\nj\ny\n- Determine Format of Call Stack\nGenerate Code to Read Values\nGenerate Code to Read Values\n- this, parameters, locals, array elements, object fields\nG\nC d\nE\nl\nE\ni\n- Generate Code to Evaluate Expressions\n- Generate Code to Write Values\n- Generate Code for Control Constructs\n-\n\nFurther Complication - Inheritance\np\nObject Extension\n\nInheritance Example - Point Class\np\nclass point {\np\n{\nint c;\nint getColor() { return(c); }\nint getColor() { return(c); }\nint distance() { return(0); }\n}\n\nPoint Subclasses\nclass cartesianPoint extends point{\nint x, y;\nint distance() { return(x*x + y*y); }\ny y\n}\nclass polarPoint extends point {\np\np\n{\nint r, t;\nint distance() { return(r*r); }\nint distance() { return(r r); }\nint angle() { return(t); }\n}\n\nImplementing Object Fields\np\ng\nj\n- Each object is a contigguous ppiece of memoryy\n- Fields from inheritance hierarchy allocated\nsequentially in piece of memory\nsequentially in piece of memory\n- Example: polarPoint object\nClass Info\nl P i\nc\npolarPoint\nc\nr\nt\n\nPoint Objects\nj\nc\nClass Info\npoint\np\nClass Info\nc\nx\ny\ncartesianPoint\ny\nc\nClass Info\nl P i\nc\nr\nt\npolarPoint\n\n-\nCompilation Tasks\np\n- Determine Object Format in Memory\nj\ny\n- Fields from Parent Classes\n- Fields from Current Class\n- Generate Code for Methods\nField Local Variable and Parameter Accesses\nField, Local Variable and Parameter Accesses\n- Method Invocations\n\n-\nSymbol Tables - Key Concept in\nC\nil ti\nCompilation\nCompiler Uses Symbol Tables to Produce\nCompiler Uses Symbol Tables to Produce\n- Object Layout in Memory\nCode to\n- Code to\n- Access Object Fields\nA\nL\nl V i bl\n- Access Local Variables\n- Access Parameters\nk\nh d\n- Invoke Methods\n-\n\nSymbol Tables During Translation\nF\nP\nT\nt IR\nFrom Parse Tree to IR\n- Symbol Tables Map Identifiers (strings) to\n(i\nid\nDescriiptors (infformatiion abbout identifi\nifiers))\n- Basic Operation: Lookup\n- Given A String, find Descriptor\n- Typical Impplementation: Hash Table\nyp\n- Examples\n- Given a class name find class descriptor\nGiven a class name, find class descriptor\n- Given variable name, find descriptor\n- local descriptor, parameter descriptor, field descriptor\nlocal descriptor, parameter descriptor, field descriptor\n\nHierarchy In Symbol Tables\ny\ny\n- Hierarchy Comes From\ny\n- Nested Scopes - Local Scope Inside Field Scope\n- Inheritance - Child Class Inside Parent Class\n- Symbol Table Hierarchy Reflects These\nHierarchies\nHierarchies\n- Lookup Proceeds Up Hierarchy Until\nDescriptor is Found\nDescriptor is Found\n\nHierarchy in vector add Method\ny\nSymbol Table for Fields\nf\nCl\nv\ndescriptor for field v\nof vector Class\nSymbol Table for\nx\nd\ni t\nf\nt\nSymbol Table for\nParameters of add\nx\ndescriptor for parameter x\nSymbol Table for\nthis\ndescriptor for this\ni\ndescriptor for local i\ny\nLocals of add\ni\ndescriptor for local i\n\nLookup In vector Example\np\np\n- v[i] = v[i]+x;\nv\ndescriptor for field v\nx\nd\ni t\nf\nt\nx\ndescriptor for parameter x\nthis\ndescriptor for this\ni\ndescriptor for local i\ni\ndescriptor for local i\n\nLookup i In vector Example\np\np\n- v[i] = v[i]+x;\nv\ndescriptor for field v\nx\nd\ni t\nf\nt\nx\ndescriptor for parameter x\nthis\ndescriptor for this\ni\ndescriptor for local i\ni\ndescriptor for local i\n\nLookup i In vector Example\np\np\n- v[i] = v[i]+x;\nv\ndescriptor for field v\nx\nd\ni t\nf\nt\nx\ndescriptor for parameter x\nthis\ndescriptor for this\ni\ndescriptor for local i\ni\ndescriptor for local i\n\nLookup x In vector Example\np\np\n- v[i] = v[i]+x;\nv\ndescriptor for field v\nx\nd\ni t\nf\nt\nx\ndescriptor for parameter x\nthis\ndescriptor for this\ni\ndescriptor for local i\ni\ndescriptor for local i\n\nLookup x In vector Example\np\np\n- v[i] = v[i]+x;\nv\ndescriptor for field v\nx\nd\ni t\nf\nt\nx\ndescriptor for parameter x\nthis\ndescriptor for this\ni\ndescriptor for local i\ni\ndescriptor for local i\n\nLookup x In vector Example\np\np\n- v[i] = v[i]+x;\nv\ndescriptor for field v\nx\nd\ni t\nf\nt\nx\ndescriptor for parameter x\nthis\ndescriptor for this\ni\ndescriptor for local i\ni\ndescriptor for local i\n\n-\nDescriptors\np\n- What do descriptors contain?\np\n- Information used for code generation and\nsemantic analysis\nsemantic analysis\n- local descriptors - name, type, stack offset\n- field descriptors - name type object offset\nfield descriptors name, type, object offset\n- method descriptors\n- signature (type of return value receiver and parameters)\nsignature (type of return value, receiver, and parameters)\n- reference to local symbol table\n- reference to code for method\n\nProgram Symbol Table\ng\ny\n- Maps class names to class descriptors\np\np\n- Typical Implementation: Hash Table\nvector\npoint\nclass descriptor for vector\nclass descriptor for point\npoint\ncartesianPoint\npolarPoint\nclass descriptor for point\nclass descriptor for cartesianPoint\nclass descriptor for polarPoint\n\nClass Descriptor\np\n- Has Two Symbol Tables\ny\n- Symbol Table for Methods\n- Parent Symbol Table is Symbol Table for Methods of\nParent Class\n- Symbol Table for Fields\n- Parent Symbol Table is Symbol Table for Fields of\nParent Class\nR f\nt D\ni t\nf P\nt Cl\n- Reference to Descriptor of Parent Class\n\nfield descriptor for c\nmethod descriptor\nfor getColor\nClass Descriptors for point and\nt\ni\nP i t\ncartesianPoint\nc\nclass descriptor\nfor point\ngetColor\ndistance\nmethod descriptor\nfor distance\ndistance\ny\nx\nfield descriptor for x\nfield descriptor for y\ndistance\nmethod descriptor\nclass descriptor\nfor distance\nfor cartesianPoint\n\nField, Parameter and Local and\nT\nD\ni t\nType Descriptors\n- Field, Parameter and Local Descriptors Refer to\nType Descriptors\n- Base typ\nype descripptor: int,,boolean\n- Array type descriptor, which contains reference to\ntype descriptor for array elements\n- Class descriptor\n- Relatively Simple Type Descriptors\nRelatively Simple Type Descriptors\n- Base Type Descriptors and Array Descriptors\nStored in Type Symbol Table\nStored in Type Symbol Table\n\nExample Type Symbol Table\np\nyp\ny\nint\nint descriptor\nboolean\nboolean descriptor\nint\nint descriptor\nint []\narray descriptor\nb\nl\n[]\nboolean []\narray descriptor\nvector []\narray descriptor\nclass descriptor\nfor vector\nvector\n\nMethod Descriptors\np\n- Contain Reference to Code for Method\n- Contain Reference to Local Symbol Table for\nLocal Variables of Method\nLocal Variables of Method\n- Parent Symbol Table of Local Symbol Table is\nParameter Symbol Table for Parameters of\nParameter Symbol Table for Parameters of\nMethod\n\nMethod Descriptor for add Method\np\nfield symbol table\nfor vector class\nparameter\nfor vector class\nx\nparameter\nsymbol table\nt\nd\ni t\nthis\nthis descriptor\nl\nl\ni bl\nx\nparameter descriptor\nMethod\ni\nlocal variable\nsymbol table\ndescriptor\nfor add\ni\nlocal descriptor\ncode for add method\ncode for add method\n\n-\nS\nSymbol Table Summary\nP\nS\nb l T bl (Cl\nD\ni\n)\n- Program Symbol Table (Class Descriptors)\n- Class Descriptors\nField Symbol Table (Field Descriptors)\nField Symbol Table (Field Descriptors)\n- Field Symbol Table for SuperClass\n- Method Symbol Table (Method Descriptors)\ny\n(\np\n)\n- Method Symbol Table for Superclass\n- Method Descriptors\n- Local Variable Symbol Table (Local Variable Descriptors)\n- Parameter Symbol Table (Parameter Descriptors)\n- Field Symbol Table of Receiver Class\n- Local, Parameter and Field Descriptors\nType Descriptors in Type Symbol Table or Class Descriptors\n- Type Descriptors in Type Symbol Table or Class Descriptors\n\nv\nfield descriptor\nadd\nthi\nx\nparameter descriptor\nclass descriptor\nadd\nthis\nthis descriptor\nclass descriptor\nfor vector\ni\nlocal descriptor\ncode for add method\ncode for add method\nint\nint descriptor\ni\nclass decl\nboolean\nboolean descriptor\nint []\narray descriptor\nboolean []\narray descriptor\nclass_decl\nvector field_decl\n[]\narray descriptor\nvector []\narray descriptor\nint v []\n\nv\nfield descriptor\nfield symbol table\nadd\nthi\nx\nparameter descriptor\nclass descriptor\nparameter\nsymbol table\nadd\nthis\nthis descriptor\nclass descriptor\nfor vector\nmethod\nmethod\nsymbol table\ni\nlocal descriptor\ncode for add method\nmethod\ndescriptor\nfor add\nlocal symbol table\ncode for add method\nint\nint descriptor\ni\nclass decl\ntype\nsymbol\ntable\nboolean\nboolean descriptor\nint []\narray descriptor\nboolean []\narray descriptor\nclass_decl\nvector field_decl\n[]\narray descriptor\nvector []\narray descriptor\nint v []\n\nTranslating from Abstract Syntax\nT\nt S\nb l T bl\nTrees to Symbol Tables\n\nExample Abstract Syntax Tree\nclass vector {\nint v[];\nvoid add(int x) {\nint i; i = 0;\nclass decl\nwhile (i < v.length) { v[i] = v[i]+x; i = i+1; }\n}\n}\nclass_decl\nvector field_decl method_decl\nstatements\n}\nint v\nadd\nint x\nparam_decl var_decl\nint i\n\nclass_decl\nvector field_decl\nint v\nmethod_decl\nadd param decl\nvar decl\nstatements\nclass symbol\nint v\nadd\nint x\nparam_decl var_decl\nint i\nclass symbol\ntable\n\nclass_decl\nvector field_decl\nint v\nmethod_decl\nadd param decl\nvar decl\nstatements\nvector\nint v\nadd\nint x\nparam_decl var_decl\nint i\nclass symbol\ntable\nclass descriptor\nfor vector\nfor vector\n\nclass_decl\nvector field_decl\nint v\nmethod_decl\nadd param decl\nvar decl\nstatements\nvector\nint v\nadd\nint x\nparam_decl var_decl\nint i\nclass symbol\ntable\nv\nfield descriptor\nclass descriptor\nfor vector\nfor vector\n\nv\nfield descriptor\nclass_decl\nvector field_decl\nint v\nmethod_decl\nadd param decl\nvar decl\nstatements\nvector\nint v\nadd\nint x\nparam_decl var_decl\nint i\nclass symbol\ntable\nadd\nclass descriptor\nfor vector\nthis\nthis descriptor\nfor vector\nMethod\ndescriptor\ndescriptor\nfor add\n\nx\nparameter descriptor\nclass_decl\nvector field_decl\nint v\nmethod_decl\nadd param decl\nvar decl\nstatements\nvector\nint v\nadd\nint x\nparam_decl var_decl\nint i\nclass symbol\ntable\nv\nfield descriptor\nadd\nclass descriptor\nfor vector\nthis\nthis descriptor\nfor vector\nMethod\ndescriptor\ndescriptor\nfor add\n\nclass_decl\nvector field_decl\nint v\nmethod_decl\nadd param decl\nvar decl\nstatements\nvector\nint v\nadd\nint x\nparam_decl var_decl\nint i\nclass symbol\ntable\nv\nfield descriptor\nadd\nclass descriptor\nfor vector\nthis\nthis descriptor\nx\nparameter descriptor\nfor vector\ni\nlocal descriptor\nMethod\ndescriptor\np\ndescriptor\nfor add\n\nRepresenting Code in High-Level\nRepresenting Code in High Level\nIntermediate Representation\n\n-\nBasic Idea\n- Move towards assembly language\ny\ng\ng\n- Preserve high-level structure\n- object format\nobject format\n- structured control flow\ndistinction between parameters locals and fields\ndistinction between parameters, locals and fields\n- High-level abstractions of assembly language\nl\nd\nd\nd\n- load and store nodes\n- access abstract locals, parameters and fields, not\nl\nti\ndi\ntl\nmemory locations directly\n\nRepresenting Expressions\np\ng\np\n- Expression Trees Represent Expressions\n- Internal Nodes - Operations like +, -, etc.\n- Leaves - Load Nodes Represent Variable Accesses\n- Load Nodes\n- ldf node for field accesses - field descriptor\n- (i\nli itl\nthi\nld dd\nf\nt\nd bj\n(implicitly accesses this - could add a reference to accessed object)t)\n- ldl node for local variable accesses - local descriptor\n- ldp node for parameter accesses - parameter descriptor\nparameter descriptor\nldp node for parameter accesses\n- lda node for array accesses\n- expression tree for index\n- expression tree for array\n\nExample\np\nx*x + y*y\n+\ny y\n+\n*\n*\nldf\nldf ldf\nldf\nfield descriptor for x\ni fi ld\nb l t bl\nfield descriptor for y\ni fi ld\nb l t bl\nin field symbol table\nfor cartesianPoint class\nin field symbol table\nfor cartesianPoint class\n\nExample\np\nv[i]+x\n[ ]\nld\n+\nld\nlda\nldp\nldl\nldf\nfield descriptor for v\nlocal descriptor\nf\ni i l\nl\nb l\nparameter descriptor\nfor x in parameter symbol\ntable of vector add\nldl\nldf\np\nin field symbol table\nfor vector class\nfor i in local symbol\ntable of vector add\n\nSpecial Case: Array Length\nO\nt\nOperator\n- len node represents length of array\np\ng\ny\n- expression tree for array\n- Example: v length\nExample: v.length\nlen\nldf\nfield descriptor for v\nin field symbol table\nfor vector class\n\n-\nRepresenting Assignment\nSt t\nt\nStatements\n- Store Nodes\n- stf for stores to fields\nstf for stores to fields\n- field descriptor\n- expression tree for stored value\n- stl for stores to local variables\n- local descriptor\ni\nf\nd\nl\n- expression tree for stored value\n- sta for stores to array elements\n- expression tree for array\nexpression tree for array\n- expression tree for index\n- expression tree for stored value\n\n-\nRepresenting Procedure Calls\np\ng\n- Call statement\n- Refers to method descriptor for invoked method\n- Has list of parameters (this is first parameter)\nHas list of parameters (this is first parameter)\nvect.add(1)\ncall\nmethod descriptor for\nadd in method symbol table\nldl\nconstant\ny\nfor vector class\nlocal descriptor\nfor vect in local symbol\nt bl\nf\nth d\nt i i\nth\ntable of method containing the\ncall statement vect.add(1)\n\nExample\np\nv[i]=v[i]+x\nsta\n+\nldl\nldf\nlda\nldp\nfield descriptor for v\nin field symbol table\nparameter descriptor\nfor x in parameter symbol\nldl\nfor vector class\nlocal descriptor\nfor i in local symbol\ntable of vector add\nfor x in parameter symbol\ntable of vector add\n\n-\nRepresenting Flow of Control\np\ng\n- Statement Nodes\n- sequence node - fifirst statement, next statement\n- if node\n- expression tree ffor condition\ndi i\n- then statement node and else statement node\nhil\nd\n- while node\n- expression tree for condition\n- statement node for loop body\nstatement node for loop body\n- return node\n- expression tree for return value\nexpression tree for return value\n\nExample\np\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nwhile\n<\n+\nsta\nldl\nlen\nlda\n+\nldp\nldl\nldf\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nFrom Abstract Syntax Trees to\ny\nIntermediate Representation\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nfield descriptor for v local descriptor for i parameter descripptor for x\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nldl\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nldl\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nldl\nlen\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\nldl\nlen\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\nldl\nlen\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\nldl\nlen\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\nldl\nlen\nlda\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\nldl\nlen\nlda\nldp\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\n+\nldl\nlen\nlda\n+\nldp\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\n+\nldl\nlen\nlda\n+\nldp\nldf\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\n+\nldl\nlen\nlda\n+\nldp\nldl\nldf\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\n<\n+\nsta\nldl\nlen\nlda\n+\nldp\nldl\nldf\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nwhile\n<\n+\nsta\nldl\nlen\nlda\n+\nldp\nldl\nldf\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nwhile\n<\n+\nsta\nldl\nlen\nlda\n+\nldp\nldl\nldf\nldf\nlocal descriptor for i\nfield descriptor for v\nparameter descriptor for x\nldl\nldf\nldf\np\np\np\np\n\nAbbreviated Notation\nwhile (i < v.length)\ng\nv[i] = v[i]+x;\nwhile\n<\n+\nsta\nldl i len\nlda\n+\nldp x\nldl i\nldf v\nldf v\nldl i\nldf v\nldf v\n\n-\nFrom Abstract Syntax Trees to IR\ny\n- Recursively Traverse Abstract Syntax Tree\ny\ny\n- Build Up Representation Bottom-Up Manner\n- Look Up Variable Identifiers in Symbol Tables\nLook Up Variable Identifiers in Symbol Tables\n- Build Load Nodes to Access Variables\nBuild Expressions Out of Load Nodes and Operator\nBuild Expressions Out of Load Nodes and Operator\nNodes\n- Build Store Nodes for Assignment Statements\nBuild Store Nodes for Assignment Statements\n- Combine Store Nodes with Flow of Control Nodes\n\nSummary\nHigh-Level Intermediate Representation\n- Goal: represent program in an intuitive way that\nGoal: represent program in an intuitive way that\nsupports future compilation tasks\n- Representing program data\np\ng p\ng\n- Symbol tables\n- Hierarchical organization\n- Representing computation\n- Expression trees\n- Various types of load and store nodes\n- Structured flow of control\n- Traverse abstract syntax tree to build IR\n\nDynamic Dispatch\ny\np\nif (x == 0) {\nWhich distance method is\ninvoked?\np = new point();\n} else if (x < 0) {\nt\ni\nP i t()\ninvoked?\n- if p is a point\nreturn(0)\np = new cartesianPoint();\n} else if (x > 0) {\np = new polarPoint();\nreturn(0)\n- if p is a cartesianPoint\nreturn(x*x + y*y)\np\nnew polarPoint();\n}\ny = p.distance();\n(\ny y)\n- if p is a polarPoint\nreturn(r*r)\ny\np\n();\n(\n)\n- Invoked Method Depends\non Type of Receiver!\n\nImplementing Dynamic Dispatch\np\ng\ny\np\n- Basic Mechanism: Method Table\ngetColor method for point\ndistance method for point\nmethod table for\npoint objects\ngetColor method for point\np\nmethod table for\nt\ni\nP i t bj\nt\ndistance method for cartesianPoint\ngetColor method for point\ncartesianPoint objects\nmethod table for\ngetColor method for point\ndistance method for polarPoint\npolarPoint objects\nangle method for polarPoint\n\nInvoking Methods\ng\n- Compiler Numbers Methods In Each\np\nInheritance Hierarchy\n- getColor is Method 0, distance is Method 1,\ng\n,\n,\nangle is Method 2\n- Method Invocation Sites Access Corresponding\np\ng\nEntry in Method Table\n- Works For Single Inheritance Only\nWorks For Single Inheritance Only\n- not for multiple inheritance, multiple dispatch, or\ninterfaces\ninterfaces\n\nHierarchy in Method Symbol Tables\nf\nP i t\nfor Points\ngetColor\nmethod descriptor\ngetColor\nfor getColor\nmethod descriptor\nfor distance\ndistance\nfor distance\nth d d\ni t\ndistance\ndistance\nmethod descriptor\nfor distance\nmethod descriptor\nangle\nmethod descriptor\nfor distance\nmethod descriptor\nfor angle\ng\n\nLookup In Method Symbol Tables\np\ny\n- Starts with method table of declared class of\nreceiver object\n- Goes up class hierarchy until method found\nGoes up class hierarchy until method found\n- point p; p = new point(); p.distance();\n- finds distance in point method symbol table\nfinds distance in point method symbol table\n- point p; p = new cartesianPoint(); p.distance();\n- finds distance in point method symbol table\n- cartesianPoint p; p = new cartesianPoint();\np g\n- finds getColor in point method symbol table\np.getColor();\n\n-\nStatic Versus Dynamic Lookup\ny\np\n- Static lookup done at comppile time for type\np\nyp\nchecking and code generation\n- Dynamic lookup done when program runs to\nDynamic lookup done when program runs to\ndispatch method call\n- Static and dynamic lookup results may differ!\nStatic and dynamic lookup results may differ!\n- point p; p = new cartesianPoint(); p.distance();\n- Static lookup finds distance in point method table\nStatic lookup finds distance in point method table\n- Dynamic lookup invokes distance in cartesianPoint class\n- Dynamic dispatch mechanism used to make this happen\nDynamic dispatch mechanism used to make this happen\n\n-\nStatic and Dynamic Tables\ny\n- Static Method Symbol Table\n- Used to look up method definitions at compile time\nUsed to look up method definitions at compile time\n- Index is method name\nLookup starts at method symbol table determined\nLookup starts at method symbol table determined\nby declared type of receiver object\n- Lookup may traverse multiple symbol tables\nLookup may traverse multiple symbol tables\n- Dynamic Method Table\nU\nd t l\nk\nth d t i\nk\nt\nti\n- Used to look up method to invoke at run time\n- Index is method number\nk\ni\nl\ni\nl\nbl\nl\n- Lookup simply accesses a single table element\n\ngetColor method\nfor point\ndistance method\nmethod descriptor\ngetColor method\nfor point\ngetColor\nmethod descriptor\nfor getColor\nmethod descriptor\nf\ndi t\ndistance\ngetColor method\nfor point\ndistance method\nfor cartesianPoint\nfor distance\nmethod descriptor\nfor distance\nfor cartesianPoint\ngetColor method\nfor point\ndistance\ndistance\nangle\ndistance method\nfor polarPoint\nangle method for\nl\ni\ndistance\nmethod descriptor\nf\ndi\nmethod descriptor\nfor angle\nangle\npolarPoint\nfor distance\n\nclass_decl\nvector field_decl\nint v\nmethod_decl\nadd param decl\nvar decl\nstatements\nvector\nint v\nadd\nint x\nparam_decl var_decl\nint i\nclass symbol\ntable\nv\nfield descriptor\nadd\nclass descriptor\nfor vector\nthis\nthis descriptor\nx\nparameter descriptor\nfor vector\ni\nlocal descriptor\nMethod\ndescriptor\np\ndescriptor\nfor add\ncode for add method\n\n-\nEliminating Parse Tree Construction\ng\n- Parser actions build symbol tables\ny\n- Reduce actions build tables in bottom-up fashion\n- Actions correspond to activities that take place in\np\np\ntop-down fashion in parse tree traversal\n- Eliminates intermediate construction of parse\nEliminates intermediate construction of parse\ntree - improves performance\n- Also less code to write (but code may be harder\nAlso less code to write (but code may be harder\nto write than if just traverse parse tree)\n\nclass vector { int v[]; void add(int x) { int i; ... }}\nclass symbol\ntable\n\nclass vector { int v[]; void add(int x) { int i; ... }}\nfield_decl\nint v\nclass symbol\ntable\nfield descriptor\n\nclass vector { int v[]; void add(int x) { int i; ... }}\nparam decl\nfield_decl\nint x\nparam_decl\nint v\nclass symbol\ntable\nfield descriptor\nparameter descriptor\n\nclass vector { int v[]; void add(int x) { int i; ... }}\nparam decl\nfield_decl\nvar decl\nint x\nparam_decl\nint v\nvar_decl\nint i\nclass symbol\ntable\nfield descriptor\nparameter descriptor\nlocal descriptor\np\n\nclass vector { int v[]; void add(int x) { int i; ... }}\nparam decl\nfield_decl\nvar decl\nstatements\nint x\nparam_decl\nint v\nvar_decl\nint i\nclass symbol\ntable\nfield descriptor\nparameter descriptor\nlocal descriptor\np\ncode for add method\n\nclass vector { int v[]; void add(int x) { int i; ... }}\nparam decl\nfield_decl\nvar decl\nstatements\nmethod_decl\nadd\nint x\nparam_decl\nint v\nvar_decl\nint i\nadd\nclass symbol\ntable\nfield descriptor\nparameter descriptor\nthis\nthis descriptor\nx\nlocal descriptor\ni\nMethod\ndescriptor\np\ncode for add method\ndescriptor\nfor add\n\nclass vector { int v[]; void add(int x) { int i; ... }}\nparam decl\nfield_decl\nvar decl\nstatements\nmethod_decl\nadd\nint x\nparam_decl\nint v\nvar_decl\nint i\nadd\nclass symbol\ntable\nfield descriptor\nv\nparameter descriptor\nthis\nthis descriptor\nx\nadd\nclass descriptor\nfor vector\nlocal descriptor\ni\nMethod\ndescriptor\nfor vector\np\ncode for add method\ndescriptor\nfor add\n\nNested Scopes\np\n- So far, have seen several kinds of nesting\n- Method symbol tables nested inside class symbol\ntables\n- Local symbol tables nesting inside method symbol\ntables\n- Nesting disambiguates potential name clashes\n- Same name used for class field and local variable\n- Name refers to local variable inside method\n\nNested Code Scopes\np\n- Symbol tables can be nested arbitrarily deeply\ny\ny\np y\nwith code nesting:\nclass bar {\nNote: Name clashes\nbaz x;\nint foo(int x) {\ndouble x = 5.0;\nNote: Name clashes\nwith nesting can\nreflect programming\nC\nil\nft\n{ float x = 10.0;\n{ int x = 1; ... x ...}\nx\nerror. Compilers often\ngenerate warning messages\nif it occurs.\n... x ...\n}\n... x ...\n}\n\n-\nWhat is a Parse Tree?\n- Parse Tree Records Results of Parse\n- External nodes are terminals/tokens\n- Internal nodes are non terminals\nInternal nodes are non-terminals\nclass_decl::='class' name '{'field_decl method_decl'}'\nfield_decl::= 'int' name '[];'\nmethod_decl::= 'void' name '(' param_decl ') '\n'{' var_decl stats '}'\n\nAbstract Versus Concrete Trees\n- Remember grammar hacks\ng\n- left factoring, ambuguity elimination, precedence of\nbinary operators\n- Hacks lead to a tree that may not reflect\ncleanest interpretation of program\np\np\ng\n- May be more convenient to work with abstract\nsyntax tree (roughly parse tree from grammar\nsyntax tree (roughly, parse tree from grammar\nbefore hacks)\n\n-\nBuilding IR Alternatives\ng\n- Build concrete parse tree in parser, translate to\np\np\nabstract syntax tree, translate to IR\n- Build abstract syntax tree in parser, translate to\nBuild abstract syntax tree in parser, translate to\nIR\n- Roll IR construction into parsing\nRoll IR construction into parsing\n\nFromAbstract Syntax Trees to\nSymbol Tables\n- Recursively Traverse Tree\ny\n- Build Up Symbol Tables As Traversal Visits\nNodes\nNodes\n\nTraversing Class Declarations\ng\n- Extract Class Name and Superclass Name\n- Create Class Descriptor (field and method symbol\nCreate Class Descriptor (field and method symbol\ntables), Put Descriptor Into Class Symbol Table\n- Put Array Descriptor Into Type Symbol Table\ny\np\nyp\ny\n- Lookup Superclass Name in Class Symbol Table,\nMake Superclass Link in Class Descriptor Point to\np\np\nRetrieved Class Descriptor\n- Traverse Field Declarations to Fill Up Field Symbol\nTable\n- Traverse Method Declarations to Fill Up Method\nSymbol Table\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec06.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/275980aad79ddb35c3872f07019d3278_MIT6_035S10_lec06.pdf",
      "content": "Spring 2010\nSemantic Analysis\nSemantic Analysis\nSaman Amarasinghe\nMassachusetts Institute of Technology\nMassachusetts Institute of Technology\n\nSymbol Table Summary\n- Program Symbol Table (Class Descriptors)\nCl\nD\ni t\n- Class Descriptors\n- Field Symbol Table (Field Descriptors)\n- Pointer to Field Symbol Table for SuperClass\nPointer to Field Symbol Table for SuperClass\n- Method Symbol Table (Method Descriptors)\n- Pointer to Method Symbol Table for Superclass\n- Method Descriptors\n- Local Variable Symbol Table (Local Variable Descriptors)\nP\nt\nS\nb l T bl\n(P\nt\nD\ni t\n)\n- Parameter Symbol Table (Parameter Descriptors)\n- Pointer to Field Symbol Table of Receiver Class\n- Local, Parameter and Field Descriptors\n- Type Descriptors in Type Symbol Table or Class Descriptors\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\na a desc\nto\nclass_decl\nv\nfield descriptor\nfield symbol table\nx\nparameter descriptor\nparameter\nsymbol table\nfield descriptor\nthis\nthis descriptor\nx\nparameter descriptor\nclass descriptor\nfor vector\nadd\nmethod\nsymbol table\ni\nlocal descriptor\nmethod\ndescriptor\nf\ndd\nsymbol table\ncode for add method\ntype\nlocal symbol table\nfor add\nint\nint descriptor\nint []\narray descriptor\nsymbol\ntable\nvector field_decl\nboolean\nboolean descriptor\n[]\ny\np\nboolean []\narray descriptor\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\nint v []\nvector []\narray descriptor\n\nOutline\nOutline\nP\nti\nl I\ni\nI t\ndi t\n- Practical Issues in Intermediate\nRepresentation\nRepresentation\n- What is semantic analysis?\n- Type systems\n- What to check?\n\n=\nHow to Store Statements\nHow to Store Statements\n- Flat Lists\nx\na*b + c\n- Flat Lists\n- Need to represent\nintermediate values\nx = a b + c\nintermediate values\n- In a stack\npush a; push b; mul; push c; add; pop x\n- In single use temporary\ni t\nt1 = mul a, b\nx = add t1 c\nregisters\nx\nadd t1, c\nSt x\n- Trees\n- Intermediate values are\nSt x\nadd\nimplicit in the edges\nmul\nld a\nld b\nld c\n\nHandling Control-Flow\nHandling Control Flow\n- Control Flow Graph\n- Control-Flow Graph\n- Pros: Simple, uniform\nCons: lost the high\nbranch <\nld i\nld\nst i\n+\n- Cons: lost the high\nlevel structure\nld i\nld n\n+\nid i\n- Structured Control\nFlow Graph\nFlow Graph\n- Pros: Help in loop\noptimizations and\nwhile\ni\noptimizations and\nparallelization\n- Cons: Many different\n<\nld i\nld n\nst i\n+\n- Cons: Many different\ntypes of nodes\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\nid i\n\nBasic Blocks\nBasic Blocks\n- Group statements into larger chunks\n- Group statements into larger chunks\n- Helps in the optimization phase\n- Basic Block\n- Single entry point at top\n- Linear collection of statements\n- No control transfer instructions in the middle\n- Only last instruction can be a control transfer\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Blocks\nst i\nBasic Blocks\nst i\n+\nid i\nst x\n+\nld x\nlda\nld A\nld i\nbranch <\nld A\nld i\nld i\nld n\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\nst j\n\nWhat not to do!\nWhat not to do!\n- Keep data in the abstract (in descriptors)\n- Keep data in the abstract (in descriptors)\n- Don't try to do register allocation!\n- No optimizations!\n- Even when they seem sooo easy\nEven when they seem sooo easy\n- Theme:\n- take small steps\np\n- don't try to do too many at once\ndon't try to do anything too early\n- don t try to do anything too early\n- try not to loose any information!\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nOutline\nOutline\nP\nti\nl I\ni\nI t\ndi t\n- Practical Issues in Intermediate\nRepresentation\nRepresentation\n- What is semantic analysis?\n- Type systems\n- What to check?\n\nWhere are we?\nWhere are we?\nLexical Analyzer (Scanner)\nProgram (character stream)\nLexical Analyzer (Scanner)\nS\nt\nA\nl\n(P\n)\nToken Stream\nSyntax Analyzer (Parser)\nParse Tree\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nWhere are we?\nWhere are we?\nLexical Analyzer (Scanner)\nProgram (character stream)\nLexical Analyzer (Scanner)\nS\nt\nA\nl\n(P\n)\nToken Stream\nSyntax Analyzer (Parser)\nParse Tree\nSemantic Analyzer\nIntermediate Code Generator\nIntermediate Representation +\nSymbol Table\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nWhat is the semantics of a\n?\nprogram?\n- Syntax\n- Syntax\n- How a program looks like\n- Textual representation or structure\n- A precise mathematical definition is possible\nA precise mathematical definition is possible\nS\nti\n- Semantics\n- What is the meaning of a program\n- Harder to give a mathematical definition\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n-\nWhy do semantic checking?\nWhy do semantic checking?\n- Make sure the program confirms to the\n- Make sure the program confirms to the\nprogramming language definition\n- Provide meaningful error messages to the user\n- Don't need to do additional work will discover\nDon t need to do additional work, will discover\nin the process of intermediate representation\nti\ngeneration\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nSemantic Checking\nSemantic Checking\n- Static checks vs Dynamic checks\n- Static checks vs. Dynamic checks\n- Static checks\n- Flow-of-control checks\n- Uniqueness checks\nUniqueness checks\n- Type checks\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nFlow of control checks\nFlow of control checks\n- Flow control of the program is context\n- Flow-control of the program is context\nsensitive\n- Examples:\n- Declaration of a variable should be visible at use\nDeclaration of a variable should be visible at use\n(in scope)\nDeclaration of a variable should be before use\n- Declaration of a variable should be before use\n- Each exit path returns a value of the correct type\n- What else?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nUniqueness checks\nUniqueness checks\n- Use and misuse of identifiers\n- Use and misuse of identifiers\n- Cannot represent in a CFG (same token)\n- Examples:\n- No identifier can be used for two different\nNo identifier can be used for two different\ndefinitions in the same scope\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n-\nType checks\nType checks\n- Most extensive semantic checks\nMost extensive semantic checks\n- Examples:\nNumber of arguments matches the number of formals\n- Number of arguments matches the number of formals\nand the corresponding types are equivalent\n- If called as an expression, should return a type\np\n,\nyp\n- Each access of a variable should match the declaration\n(arrays, structures etc.)\n- Identifiers in an expression should be \"evaluatable\"\n- LHS of an assignment should be \"assignable\"\nI\ni\nll h\nf\ni bl\nh d\n- In an expression all the types of variables, method return\ntypes and operators should be \"compatible\"\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nDynamic checks\nDynamic checks\n- Array bounds check\n- Array bounds check\n- Null pointer dereference check\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nOutline\nOutline\nP\nti\nl I\ni\nI t\ndi t\n- Practical Issues in Intermediate\nRepresentation\nRepresentation\n- What is semantic analysis?\n- Type systems\n- What to check?\n\nType Systems\nType Systems\n- A type system is used to for the type\n- A type system is used to for the type\nchecking\n- A type system incorporates\n- syntactic constructs of the language\nsyntactic constructs of the language\n- notion of types\nl\nf\ni\ni\nt\nt\nl\n- rules for assigning types to language\nconstructs\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType expressions\nType expressions\n- A compound type is denoted by a type\n- A compound type is denoted by a type\nexpression\n- A type expression is\n- a basic type\na basic type\n- application of a type constructor to other\ntype expressions\ntype expressions\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Expressions: Basic types\nType Expressions: Basic types\n- Atomic types defined by the language\nAtomic types defined by the language\n- Examples:\nintegers\n- integers\n- booleans\nfloats\n- floats\n- characters\ntype error\n- type_error\n- special type that'll signal an error\nid\n- void\n- basic type denoting \"the absence of a value\"\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Expressions: Names\nType Expressions: Names\n- Since type expressions maybe be named a\n- Since type expressions maybe be named, a\ntype name is a type expression\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Expressions: Products\nType Expressions: Products\n- If T and T are type expressions T T is\n- If T1 and T2 are type expressions T1 T2 is\nalso a type expression\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Expressions: Arrays\nType Expressions: Arrays\n- If T is a type expression an array(T I) is\n- If T is a type expression an array(T, I) is\nalso a type expression\n- I is a integer constant denoting the number of\nelements of type T\n- Example:\nint foo[128];\n[\n];\narray(integer, 128)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Expressions: Method Calls\nType Expressions: Method Calls\n- Mathematically a function maps\n- Mathematically a function maps\n- elements of one set (the domain)\n- to elements of another set (the range)\n- Example\nExample\nint foobar(int a, boolean b, int c)\ninteger\nboolean\ninteger\ninteger\ninteger boolean integer integer\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Expressions: Some others\nType Expressions: Some others\n- Records\n- Records\n- structures and classes\n- Example\nclass { int i; int j;}\ninteger integer\n- Functional Languages\nFunctional Languages\n- functions that take functions and return\nfunctions\nfunctions\n- Example\n(i\ni\n)\ni\n(i\ni\n)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n(integer integer) integer (integer integer)\n\nA simple typed language\nA simple typed language\n- A language that has a sequence of declarations\n- A language that has a sequence of declarations\nfollowed by a single expression\nP D; E\nP D; E\nD D; D | id : T\nT\nh\n|\ni t\n|\n[\n]\nf T\nT char\n| integer | array [ num ] of T\nE literal | num | id | E + E | E [ E ]\nE\nl\nP\n- Example Program\nvar: integer;\n+ 1023\nvar + 1023\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nA simple typed language\nA simple typed language\n- A language that has a sequence of declarations\n- A language that has a sequence of declarations\nfollowed by a single expression\nP D; E\nP D; E\nD D; D | id : T\nT\nh\n|\ni t\n|\n[\n]\nf T\nT char\n| integer | array [ num ] of T\nE literal | num | id | E + E | E [ E ]\nWh\nh\ni\nl\nf hi l\n?\n- What are the semantic rules of this language?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n=\nParser actions\nParser actions\nP\nD; E\nP\nD; E\nD D; D\nD id : T\n{ addtype(id entry T type); }\nD id : T\n{ addtype(id.entry, T.type); }\nT char\n{ T.type = char; }\nT integer\n{ T type\ninteger; }\nT integer\n{ T.type = integer; }\nT array [ num ] of T1\n{ T type = array(T type num val); }\n{ T.type\narray(T1.type, num.val); }\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n=\nParser actions\nParser actions\nE literal\n{ E type = char; }\nE literal\n{ E.type\nchar; }\nE num\n{ E.type = integer; }\nE\nid\n{ E t\nl\nk\nt\n(id\n) }\nE id\n{ E.type = lookup_type(id.name); }\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nParser actions\nParser actions\nE E1 + E2\n{ if E1 type == integer and\nE E1 + E2\n{ if E1.type\ninteger and\nE2 .type == integer then\nE.type = integer\nyp\ng\nelse\nE.type = type_error\nyp\nyp\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n==\n=\nParser actions\nParser actions\nE E [E ]\n{ if E type == integer and\nE E1 [E2 ]\n{ if E2.type\ninteger and\nE1 .type == array(s, t) then\nE type = s\nE.type\ns\nelse\nE type\ntype error\nE.type = type_error\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n-\nType Equivalence\nType Equivalence\n- How do we know if two types are equal?\n- How do we know if two types are equal?\n- Same type entry\n- Example:\nint A[128];\nfoo(A);\nfoo(int B[128]) {\n}\nfoo(int B[128]) { ... }\n- Two different type entries in different symbol tables\nTwo different type entries in different symbol tables\n- But they should be the same\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nStructural Equivalence\nStructural Equivalence\n- If the type expression of two types have\n- If the type expression of two types have\nthe same construction, then they are\nequivalent\n- \"Same construction\"\nSame construction\n- Equivalent base types\nS\nt\nf t\nt\nt\nli d i\n- Same set of type constructors are applied in\nthe same order (i.e. equivalent type tree)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Coercion\nType Coercion\n- Implicit conversion of one type to another\n- Implicit conversion of one type to another\ntype\n- Example\nint A;\nfloat B;\nB = B + A\n- Two types of coercion\nid\ni\ni\n- widening conversions\n- narrowing conversions\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nNarrowing conversions\nNarrowing conversions\n- Conversions that may loose information\n- Conversions that may loose information\n- Examples:\n- integers to chars\n- longs to shorts\nlongs to shorts\n- Rare in languages\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nWidening conversions\nWidening conversions\n- Conversions without loss of information\n- Conversions without loss of information\n- Examples:\n- integers to floats\n- shorts to longs\nshorts to longs\n- What is done in many languages (including\nd\nf)\ndecaf)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nWidening Conversions\nWidening Conversions\n- Basic Principle: Hierarchy of number types\n- Basic Principle: Hierarchy of number types\n- int float double\nAll\ni\nhi\nh\n- All coercions go up hierarchy\n- int to float;\n- int, float to double\n- Result is type of operand highest up in hierarchy\n- int + float is float\n- int + double is double\n- float + double is double\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n=\nType casting\nType casting\n- Explicit conversion from one type to another\n- Explicit conversion from one type to another\n- Both widening and narrowing\n- Example\nint A;\nint A;\nfloat B;\nA = A + (int)B\nA\nA + (int)B\n- Unlimited typecasting can be dangerous\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nQuestion:\nQuestion:\n- Can we assign a single type to all variables\n- Can we assign a single type to all variables,\nfunctions and operators?\n- How about +, what is its type?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n-\nOverloading\nOverloading\n- Some operators may have more than one\nSome operators may have more than one\ntype.\nE\nl\n- Example\nint A, B, C;\nfloat X, Y, Z;\nA = A + B\nX\nX + Y\nX = X + Y\n- Complicates the type system\n- Example\nA = A + X\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n- What is the type of + ?\n\nOutline\nOutline\nP\nti\nl I\ni\nI t\ndi t\n- Practical Issues in Intermediate\nRepresentation\nRepresentation\n- What is semantic analysis?\n- Type systems\n- What to check?\n\nParameter Descriptors\nParameter Descriptors\n- When build parameter descriptor have\n- When build parameter descriptor, have\n- name of type\n- name of parameter\n- What is the check?\nWhat is the check?\n- Is name of type identifies a valid type?\nl\nk\ni\nt\nb l t bl\n- look up name in type symbol table\n- if not there, look up name in program symbol table\n(might be a class type)\n(might be a class type)\n- if not there, fails semantic check\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nLocal Descriptors\nLocal Descriptors\n- When build local descriptor have\n- When build local descriptor, have\n- name of type\n- name of local\n- What is the check?\nWhat is the check?\n- Is name of type identifies a valid type?\nl\nk\ni\nt\nb l t bl\n- look up name in type symbol table\n- if not there, look up name in program symbol table\n(might be a class type)\n(might be a class type)\n- if not there, fails semantic check\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nLocal Symbol Table\nLocal Symbol Table\n- When building the local symbol table have\n- When building the local symbol table, have\na list of local descriptors\n- What to check for?\n- duplicate variable names\nduplicate variable names\n- shadowed variable names\nh\nh\nk?\n- When to check?\n- when insert descriptor into local symbol table\np\ny\n- Parameter and field symbol tables similar\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n-\nClass Descriptor\nClass Descriptor\n- When build class descriptor have\nWhen build class descriptor, have\n- class name and name of superclass\n- field symbol table\nfield symbol table\n- method symbol table\n- What to check?\nWhat to check?\n- Superclass name corresponds to actual class\n- No name clashes between field names of subclass and\nNo name clashes between field names of subclass and\nsuperclasses\n- Overridden methods match parameters and return\nd\nl\ni\nf\nl\ntype declarations of superclass\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nLoad Instruction\nLoad Instruction\n- What does compiler have? Variable name\n- What does compiler have? Variable name.\n- What does it do? Look up variable name.\n- If in local symbol table, reference local descriptor\n- If in parameter symbol table, reference parameter\nd\ni t\ndescriptor\n- If in field symbol table, reference field descriptor\nIf\nf\nd\ni\n- If not found, semantic error\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nLoad Array Instruction\nLoad Array Instruction\n- What does compiler have?\n- What does compiler have?\n- Variable name\nA\ni d\ni\n- Array index expression\n- What does compiler do?\n- Look up variable name (if not there, semantic error)\n- Check type of expression (if not integer, semantic error)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nLoad Array Instruction\nLoad Array Instruction\nWhat else can/should be checked?\nWhat else can/should be checked?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nAdd Operations\nAdd Operations\n- What does compiler have?\n- What does compiler have?\n- two expressions\nWh t\n?\n- What can go wrong?\n- expressions have wrong type\n- must both be integers (for example)\n- So compiler checks type of expressions\n- load instructions record type of accessed variable\n- operations record type of produced expression\n- so just check types, if wrong, semantic error\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nType Inference for Add\nOperations\n- Most languages let you add floats ints doubles\n- Most languages let you add floats, ints, doubles\n- What are issues?\n- Types of result of add operation\n- Coercions on operands of add operation\n- Standard rules usually apply\n- If add an int and a float, coerce the int to a float, do\nthe add with the floats, and the result is a float.\n- If add a float and a double, coerce the float to a\ndouble, do the add with the doubles, result is double\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nStore Instruction\nStore Instruction\n- What does compiler have?\nVariable name\n- Variable name\n- Expression\n- What does it do?\n- Look up variable name\nLook up variable name.\n- If in local symbol table, reference local descriptor\n- If in parameter symbol table, error\np\ny\n,\n- If in field symbol table, reference field descriptor\n- If not found, semantic error\n- Check type of variable name against type of expression\n- If variable type not compatible with expression\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ntype, error\n\na\nete\nbo tab e e o\n-\nStore Array Instruction\nStore Array Instruction\n- What does compiler have?\nWhat does compiler have?\n- Variable name, array index expression\n- Expression\n- What does it do?\n- Look up variable name.\n- If in local symbol table, reference local descriptor\n- If in parameter symbol table, error\npa\nsy\n,\n- If in field symbol table, reference field descriptor\n- If not found, semantic error\nCheck that type of array index expression is integer\nCheck that type of array index expression is integer\n- Check type of variable name against type of expression\n- If variable element type not compatible with expression type,\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\nerror\n\nMethod Invocations\nMethod Invocations\n- What does compiler have?\nWhat does compiler have?\n- method name, receiver expression, actual parameters\n- Checks:\ni\ni\ni\nl\nt\n- receiver expression is class type\n- method name is defined in receiver's class type\nf\nl\nh\nf f\nl\n- types of actual parame ters match types of formal\nparameters\nWhat does match mean?\n- What does match mean?\n- same type?\n- compatible type?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ncompatible type?\n\n-\nReturn Instructions\nReturn Instructions\n- What does compiler have?\nWhat does compiler have?\n- Expression\n- Checks:\nChecks:\n- If the return type matches the expression?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\n-\nConditional Instructions\nConditional Instructions\n- What does compiler have?\nWhat does compiler have?\n- Expression for the if-condition and the\nt t\nt li t\nf th\n(\nd\nl\n) bl\nk\nstatement list of then (and else) blocks\n- Checks:\n- If the conditional expression producing a\nIf the conditional expression producing a\nBoolean value?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nSemantic Check Summary\nSemantic Check Summary\n- Do semantic checks when build IR\n- Do semantic checks when build IR\n- Many correspond to making sure entities are\n- Many correspond to making sure entities are\nthere to build correct IR\n- Others correspond to simple sanity checks\n- Each language has a list that must be checked\n- Can flag many potential errors at compile time\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec07.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/7abb873e5a7174b94cb6370864d0b698_MIT6_035S10_lec07.pdf",
      "content": "U\nti\ni\nd C d\nUnoptimized Code\nGeneration\nFrom the intermediate\nFrom the intermediate\nrepresentation to the machine\ncode\ncode\n\nOutline\n- Introduction\n- Machine Language\n- Overview of a modern processor\n- Memory Layout\n- Procedure Abstraction\nProcedure Abstraction\n- Procedure Linkage\n- Guidelines in Creating a Code Generator\n- Guidelines in Creating a Code Generator\n\nAnatomy of a compiler\nLexical Analyzer (Scanner)\nProgram (character stream)\ny\n(\n)\nSyntax Analyzer (Parser)\nToken Stream\nSemantic Analyzer\ny\ny\n(\n)\nParse Tree\nIntermediate Code Optimizer\ny\nIntermediate Representation\np\nCode Generator\nOptimized Intermediate Representation\nAssembly code\n\nAnatomy of a compiler\nLexical Analyzer (Scanner)\nProgram (character stream)\ny\n(\n)\nSyntax Analyzer (Parser)\nToken Stream\ny\ny\n(\n)\nParse Tree\nSemantic Analyzer\nHigh-level IR\nLow-level IR\ny\nCode Generator\nIntermediate Representation\nLow level IR\nAssembly code\n\nComponents of a High Level\nLanguage\nLanguage\nCODE\nDATA\nProcedures\nGlobal Static Variables\nGlobal Dynamic Data\nControl Flow\nGlobal Dynamic Data\nLocal Variables\nStatements\nTemporaries\nParameter Passing\nData Access\nParameter Passing\nRead-only Data\n\nMachine Code Generator\nShould\nShould...\n- Translate all the instructions in the\nintermediate representation to assembly\nlanguage\nlanguage\n- Allocate space for the variables, arrays etc.\n- Adhere to calling conventions\n- Create the necessary symbolic information\ny y\n\nOutline\n- Introduction\n- Machine Language\n- Overview of a modern processor\n- Memory Layout\n- Procedure Abstraction\nProcedure Abstraction\n- Procedure Linkage\n- Guidelines in Creating a Code Generator\n- Guidelines in Creating a Code Generator\n\nMachines understand...\nLOCATION\nDATA\n8B45FC\n4863F0\n004c\n8B45FC\n004f\n4863D0\n8B45FC\n8B45FC\n8B048500\n005e\n8B149500\n01C2\n8B45FC\n006a\n006c\n89D7\n006e\n033C8500\n8B45FC\n4863C8\n007b\n8B45F8\n007b\n8B45F8\n007e\n8B148500\n\n-\nMachines understand...\nLOCATION\nDATA\nASSEMBLY INSTRUCTION\n8B45FC\nmovl\n-4(%rbp), %eax\n4863F0\nmovslq\n%eax,%rsi\n004c\n8B45FC\nmovl\n-4(%rbp), %eax\n004f\n4863D0\nmovslq\n%eax,%rdx\n8B45FC\nmovl\n-4(%rbp), %eax\n8B45FC\nmovl\n4(%rbp), %eax\ncltq\n8B048500\nmovl\nB(,%rax,4), %eax\n005e\n8B149500\nmovl\nA(,%rdx,4), %edx\n01C2\naddl\n%eax, %edx\n8B45FC\nmovl\n-4(%rbp), %eax\n006a\ncltq\n006c\n89D7\nmovl\n%edx\n, %edi\n,\n006e\n033C8500\naddl\nC(,%rax,4), %edi\n8B45FC\nmovl\n-4(%rbp), %eax\n4863C8\nmovslq\n%eax,%rcx\n007b\n8B45F8\nmovl\n8(%rbp)\n%eax\n007b\n8B45F8\nmovl\n8(%rbp), %eax\n007e\n8B148500\nB(,%rax,4), %edx\n\nProgram (character stream)\nLexical Analyzer (Scanner)\nSyntax Analyzer (Parser)\nToken Stream\nSyntax Analyzer (Parser)\nParse Tree\nIntermediate Code Generator\nHigh-level IR\nLow-level IR\nIntermediate Representation\nCode Generator\nAssembly code\nAssembly code\n\nProgram (character stream)\nLexical Analyzer (Scanner)\nSyntax Analyzer (Parser)\nToken Stream\nSyntax Analyzer (Parser)\nParse Tree\nIntermediate Code Generator\nHigh-level IR\nLow-level IR\nIntermediate Representation\nCode Generator\nAssembly code\nAssembly code\nAssembler & linker\nBinary executable\nProcessor\n\n-\nAssembly language\ny\ng\ng\n- Advantages\nSimplifies code generation due to use of symbolic\n- Simplifies code generation due to use of symbolic\ninstructions and symbolic names\nLogical abstraction layer\nLogical abstraction layer\n- Multiple Architectures can describe by a single\nassembly language\nassembly language\n⇒ can modify the implementation\n- macro assembly instructions\ny\n- Disadvantages\n- Additional process of assembling and linking\nAdditional process of assembling and linking\n- Assembler adds overhead\n\n-\nAssembly language\ny\ng\ng\n- Relocatable machine language (object modules)\n- all locations(addresses) represented by symbols\n- Mapped to memory addresses at link and load time\n- Flexibility of separate compilation\n- Absolute machine language\n- add\nddresses are hhardd-cod d\nded\n- simple and straightforward implementation\ninflexible -- hard to reload generated code\n- Used in interrupt handlers and device drivers\ninflexible\nhard to reload generated code\n\nAssembly example\n.section\n.rodata\nLC0\n.LC0:\n0000 6572726F7200 .string \"error\"\n.text\n.globl fact\nfact:\n0000 55\npushq\n%rbp\np\nq\np\n0001 4889E5\nmovq\n%rsp, %rbp\n0004 4883EC10\nsubq\n$16, %rsp\n0008 897DFC\nmovl\n%edi, -4(%rbp)\n000b 837DFC00\ncmpl\n$0, -4(%rbp)\n000f 7911\njns\n.L2\n0011 BF00000000\nmovl\n$.LC0, %edi\n0011 BF00000000\nmovl\n$.LC0, %edi\n0016 B800000000\nmovl\n$0, %eax\n001b E800000000\ncall\nprintf\n0020 EB22\njmp\n.L3\n.L2:\n0022 837DFC00\ncmpl\n$0, -4(%rbp)\n0026 7509\njne\nL4\n0026 7509\njne\n.\nL4\n0028 C745F801000000\nmovl\n$1, -8(%rbp)\n002f EB13\njmp\n.L3\n.L4:\n0031 8B7DFC\nmovl\n-4(%rbp), %edi\n0034 FFCF\ndecl\n%edi\nll\nf\nt\n0036 E800000000\nca\nll\nfact\n003b 0FAF45FC\nimull\n-4(%rbp), %eax\n003f 8945F8\nmovl\n%eax, -8(%rbp)\n0042 EB00\njmp\n.L1\n.L3:\n0044 8B45F8\n-8(%rbp), %eax\n(\np),\n0047 C9\n0048 C3\n\n-\nComposition of an Object File\np\nj\n- We use the ELF file format\n.file\n\"test2.c\"\n.section\n.rodata\n.LC0:\n- The object file has:\n- Multiple Segments\n- Symbol Information\n.LC0:\n.string \"error %d\"\n.section\n.text\n.globl fact\nfact:\nSymbol Information\n- Relocation Information\n- Segments\npushq\n%rbp\nmovq %rsp, %rbp\nsubq $16, %rsp\nmovl -8(%rbp), %eax\nleave\nret\nSegments\n- Global Offset Table\n- Procedure Linkage Table\n- Text (code)\nret\n.\n.comm\nbar,4,4\n.comm\na,1,1\n.comm\nb,1,1\nText (code)\n- Data\n- Read Only Data\n.section\n.eh_frame,\"a\",@progbits\n.long\n.LECIE1-.LSCIE1\n.long\n0x0\n.byte\n0x1\n.string \"\"\n.uleb128 0x1\n\nOutline\n- Introduction\n- Machine Language\n- Overview of a modern processor\n- Memory Layout\n- Procedure Abstraction\nProcedure Abstraction\n- Procedure Linkage\n- Guidelines in Creating a Code Generator\n- Guidelines in Creating a Code Generator\n\nOverview of a modern\nprocessor\nprocessor\n- ALU\nMemory\n- Control\nMemory\n- Memory\n- Registers\nRegisters\nALU\nRegisters\nControl\n\nArithmetic and Logic Unit\ng\n- Performs most of the data\noperations\nMemory\noperations\n- Has the form:\nOP <oprnd1>, <oprnd2>\n- <oprnd2> = <oprnd1> OP <oprnd2>\nMemory\n<oprnd2> <oprnd1> OP <oprnd2>\nOr\nOP <oprnd1>\nOperands are:\nRegisters\nALU\n- Operands are:\n- Immediate Value\n$25\n- Register\n%rax\nMemory\n4(%rbp)\nControl\n- Memory\n4(%rbp)\n- Operations are:\n- Arithmetic operations (add, sub, imul)\nLogical operations (and sal)\n- Logical operations (and, sal)\n- Unitary operations (inc, dec)\n\nArithmetic and Logic Unit\ng\n- Many arithmetic operations can\ncause an exception\nMemory\n- overflow and underflow\n- Can operate on different data types\nMemory\n- addb 8 bits\n- addw 16 bits\nRegisters\nALU\n- addl 32 bits\n- addq 64 bits (Decaf is all 64 bit)\nsigned and unsigned arithmetic\nControl\n- signed and unsigned arithmetic\n- Floating-point operations\n(separate ALU)\n(\np\n)\n\nControl\n- Handles the instruction sequencing\nMemory\nq\ng\n- Executing instructions\n- All instructions are in memory\nMemory\nAll instructions are in memory\n- Fetch the instruction pointed by the\nPC and execute it\nRegisters\nALU\nPC and execute it\n- For general instructions, increment\nthe PC to point to the next location in\nControl\np\nmemory\n\nControl\n- Unconditional Branches\nF t h th\nt i\nt\nti\nf\nMemory\n- Fetch the next instruction from a\ndifferent location\n- Unconditional jump to an address\nMemory\n- Unconditional jump to an address\njmp .L32\n- Unconditional jump to an address\nRegisters\nALU\nj\np\nin a register\njmp %rax\nT\nh\ndl\nd\nll\nControl\n- To handle procedure calls\ncall fact\ncall %r11\n\nControl\n- All arithmetic operations update the\ncondition codes (rFLAGS)\nMemory\n(\n)\n- Compare explicitly sets the rFLAGS\nMemory\n- cmp $0, %rax\n- Conditional jumps on the rFLAGS\nRegisters\nALU\n- Jxx .L32 Jxx 4(%rbp)\n- Examples:\nJO\nJ\nO\nfl\nControl\n- JO\nJump Overflow\n- JC\nJump Carry\n- JAE\nJump if above or equal\n- JZ\nJump is Zero\n- JNE\nJump if not equal\n\nControl\n- Control transfer in special (rare)\ncases\nMemory\ncases\n- traps and exceptions\nMechanism\nMemory\n- Mechanism\n- Save the next(or current) instruction\nlocation\nRegisters\nALU\n- find the address to jump to (from an\nexception vector)\n- jump to that location\nControl\njump to that location\n\nWhen to use what?\n-\nGive an example where each of the branch\np\ninstructions can be used\n1. jmp L0\nj\np\n2. call L1\n3. jmp %rax\n3. jmp %rax\n4. jz -4(%rbp)\njne L1\n5. jne L1\n\nMemoryy\n- Flat Address Space\nMemory\np\n- composed of words\n- byte addressable\nMemory\ny\n- Need to store\nProgram\nRegisters\nALU\n- Program\n- Local variables\nGlobal variables and data\nControl\n- Global variables and data\n- Stack\nH\n- Heap\n\nMemory\nHeap\nDynamic\np\nDynamic\nStack\n0x800 0000 0000\nGlobals/\nStack\nData\nRead-only data\nProgram\nText\nData\nProgram\nUnmapped\nText\n0x40 0000\npp\n0x0\nMemory\nMemory\nRegisters\nALU\nControl\n\nRegisters\ng\n- Instructions allow only limited memory\nti\nMemory\noperations\n- add -4(%rbp), -8(%rbp)\nadd\n%r10 -8(%rbp)\nMemory\nadd %r10, 8(%rbp)\n- Important for performance\nALU\nRegisters\np\np\n- limited in number\nS\ni l\ni t\nControl\n- Special registers\n- %rbp\nbase pointer\n- %rsp\nstack pointer\n- %rsp\nstack pointer\n\nMoving Data\ng\nd\nMemory\n- mov source dest\n- Moves data\n- from one register to another\nMemory\nfrom one register to another\n- from registers to memory\n- from memory to registers\nALU\nRegisters\n- push source\n- Pushes data into the stack\nControl\n- pop dest\n- Pops data from the stack to dest\n\nOther interactions\n- Other operations\nMemory\np\n- Input/Output\n- Privilege / secure operations\nMemory\ng\np\n- Handling special hardware\n- TLBs, Caches etc.\nALU\nRegisters\n,\n- Mostly via system calls\nControl\nMostly via system calls\n- hand-coded in assembly\ncompiler can treat them as a normal function call\n- compiler can treat them as a normal function call\n\nOutline\n- Introduction\n- Machine Language\n- Overview of a modern processor\n- Memory Layout\n- Procedure Abstraction\nProcedure Abstraction\n- Procedure Linkage\n- Guidelines in Creating a Code Generator\n- Guidelines in Creating a Code Generator\n\nComponents of a High Level\nLanguage\nLanguage\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nMemory Layout\ny\ny\n- Heap management\nHeap\nDynamic\np\ng\n- free lists\np\nDynamic\nStack\n0x800 0000 0000\n- starting location in\nthe text segment\nGlobals/\nR\nd\nl\nStack\nData\ng\nRead-only\ndata\nProgram\nText\nData\nProgram\nUnmapped\nText\n0x40 0000\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\npp\n0x0\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nAllocating Read-Only Data\ng\ny\n-\nAll Read-Only data in the text\nsegment\n.section .text\n.globl main\ng\n-\nIntegers\n- use load immediate\nSt i\n.globl main\nmain:\nenter\n$0, $0\nmovq\n$5, x(%rip)\n-\nStrings\n-\nuse the .string macro\nq\np\npush\nx(%rip)\npush\n$.msg\ncall\nprintf_035\nadd\n$16, %rsp\nleave\nret\n.msg:\n.string \"Five: %d\\n\"\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nGlobal Variables\n-\nAllocation: Use the assembler's\n.comm directive\n.section .text\n.globl main\nmain:\nenter\n$0\n$0\n-\nUse PC relative addressing\n- %rip is the current instruction\naddress\nenter\n$0, $0\nmovq\n$5, x(%rip)\npush\nx(%rip)\ncall\nprintf_035\n- X(%rip) will add the offset from\nthe current instruction location to\nthe space for x in the data\nsegment to %rip\nadd\n$16, %rsp\nleave\nret\nsegment to %rip\n- Creates easily recolatable\nbinaries\n.comm\nx, 8\n.comm name, size, alignment\nTh\ndi\ni\nll\ni\nThe .comm directive allocates storage in\nthe data section. The storage is referenced\nby the identifier name. Size is measured in\nbytes and must be a positive integer.\nName cannot be predefined. Alignment is\ni\nl If\nli\ni\nifi d\nh\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\noptional. If alignment is specified, the\naddress of name is aligned to a multiple of\nalignment\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nOutline\n- Introduction\n- Machine Language\n- Overview of a modern processor\n- Memory Layout\n- Procedure Abstraction\nProcedure Abstraction\n- Procedure Linkage\n- Guidelines in Creating a Code Generator\n- Guidelines in Creating a Code Generator\n\nProcedure Abstraction\n- Requires system-wide compact\n- Broad agreement on memory layout, protection, resource\ng\ny\ny\np\nallocation calling sequences, & error handling\n- Must involve architecture (ISA), OS, & compiler\n- Provides shared access to system wide facilities\n- Provides shared access to system-wide facilities\n- Storage management, flow of control, interrupts\n- Interface to input/output devices, protection facilities, timers,\np\np\n, p\n,\n,\nsynchronization flags, counters, ...\n- Establishes the need for a private context\nC\ni\nf\nh\nd\ni\ni\n- Create private storage for each procedure invocation\n- Encapsulate information about control flow & data\nabstractions\nThe procedure abstraction is a social contract (Rousseau)\n\nProcedure Abstraction\n- In practical terms it leads to...\n- multiple procedures\n- library calls\n- compiled by many compilers, written in different\nlanguages, hand-written assembly\nF\nth\nj\nt\nd t\nb\nt\n- For the project, we need to worry about\n- Parameter passing\nR\ni t\n- Registers\n- Stack\nCalling convention\n- Calling convention\n\nParameter passing disciplines\np\ng\np\n- Many different methods\n- call by reference\n- call by value\n- call by value-result (copy-in/copy-out)\n\nParameter Passing Disciplines\ng\np\nProgram {\nint A;\nfoo(int B) {\nfoo(int B) {\nB = B + 1\nB = B + A\n}\nMain() {\nA = 10;\nfoo(A);\n}\n}\n- Call by value\nA is ???\n- Call by reference\nA is ???\n- Call by value-result\nA is ???\nCall by value result\nA is ???\n\nParameter Passing Disciplines\ng\np\nProgram {\nint A;\nfoo(int B) {\nfoo(int B) {\nB = B + 1\nB = B + A\n}\nMain() {\nA = 10;\nfoo(A);\n}\n}\n- Call by value\nA is 10\n- Call by reference\nA is 22\n- Call by value-result\nA is 21\nCall by value result\nA is 21\n\n-\n-\nParameter passing disciplines\np\ng\np\n- Many different methods\n- call by reference\n- call by value\n- call by value-result\ncall by value result\n- How do you pass the parameters?\n- via. the stack\n- via. the registers\n- or a combination\n- In thhe DDecaffca llilling conventiion, thhe fifirst 66\nparameters are passed in registers.\n- The rest are passed in the stack\nThe rest are passed in the stack\n\nRegisters\ng\n- What to do with live registers across a\ng\nprocedure call?\n- Caller Saved\n- Calliee Saved\n\nQuestion:\n- What are the advantages/disadvantages of:\ng\ng\n- Calliee saving of registers?\n- Caller saving of registers?\ng\ng\n- What registers should be used at the caller\nand calliee if half is caller-saved and the\nand calliee if half is caller saved and the\nother half is calliee-saved?\n\nRegisters\ng\n- What to do with live registers across a procedure\ncall?\ncall?\n- Caller Saved\n- Calliee Saved\n- In this segment, use registers only as short-lived\ntemporaries\ntemporaries\nmov -4(%rbp), %r10\nmov -8(%rbp), %r11\nadd\n%r10, %r11\nadd\n%r10, %r11\nmov %r11, -8(%rbp)\n- Should not be live across procedure calls\n- Will start keeping data in the registers for performance in\nWill start keeping data in the registers for performance in\nSegment V\n\nThe Stack\n- Arguments 0 to 6\nargument n\n8*n+16(%rbp)\nvious\nare in:\n- %rdi, %rsi, %rdx,\n%rcx %r8 and %r9\nReturn address\n...\nargument 7\n8(%rbp)\n16(%rbp)\nPre\n%rcx, %r8 and %r9\nlocal 0\nPrevious %rbp\n0(%rbp)\n-8(%rbp)\nurrent\n0(%rsp)\n...\nlocal m\n-8*m-8(%rbp)\nCu\nVariable size\n\nQuestion:\n- Why use a stack? Why not use the heap or\ny\ny\np\npre-allocated in the data segment?\n\nOutline\n- Introduction\n- Machine Language\n- Overview of a modern processor\n- Memory Layout\n- Procedure Abstraction\nProcedure Abstraction\n- Procedure Linkage\n- Guidelines in Creating a Code Generator\n- Guidelines in Creating a Code Generator\n\n-\nProcedure Linkages\ng\nStandard procedure linkage\np\ng\nprocedure p\nprolog\nprocedure q\nProcedure has\n- standard prolog\nll\nprolog\n- standard epilog\nEach call involves a\npre-call\npost-return\nepilog\nEach call involves a\n- pre-call sequence\n- post-return sequence\nepilog\npost return sequence\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nrbp\nlocal variables\nregisters\n- Calling: Caller\n- Assume %rcx is live and\nis caller save\nstack temporaries\ndynamic area\nll\nd\ni t\n- Call foo(A, B, C, D, E, F, G, H, I)\n- A to I are at -8(%rbp) to -72(%rbp)\nrsp\ncaller saved registers\nargument 9\nargument 8\nargument 7\npush\n%rcx\npush\n-72(%rbp)\npush\n-64(%rbp)\nreturn address\npush\n64(%rbp)\npush\n-56(%rbp)\nmov\n-48(%rbp), %r9\nmov\n-40(%rbp), %r8\nmov\n-32(%rbp), %rcx\nmov\n-24(%rbp), %rdx\nmov\n-16(%rbp), %rsi\n8(% b )\n% di\nmov\n-8(%rbp), %rdi\ncall\nfoo\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nrbp\nlocal variables\nregisters\n- Calling: Calliee\n- Assume %rbx is used in the function\nand is calliee save\nstack temporaries\ndynamic area\nll\nd\ni t\nand is calliee save\n- Assume 40 bytes are required for\nlocals\ncaller saved registers\nargument 9\nargument 8\nargument 7\nfoo:\npush\n%rbp\nprevious frame pointer\nreturn address\npush\n%rbp\nmov\n%rsp, %rbp\nsub\n$48, %rsp\n% b\n8(% b )\nrsp\ncalliee saved\nregisters\nenter\n$48, $0\nmov\n%rbx, -8(%rbp)\nregisters\nlocal variables\nstack temporaries\ndynamic area\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nlocal variables\nregisters\n-\nArguments\n-\nCall foo(A, B, C, D, E, F, G, H, I)\n-\nPassed in by pushing before the call\nstack temporaries\ndynamic area\nll\nd\ni t\npush\n-72(%rbp)\npush\n-64(%rbp)\npush\n-56(%rbp)\nmov\n-48(%rbp), %r9\nmov\n-40(%rbp), %r8\nmov\n-32(%rbp), %rcx\ncaller saved registers\nargument 9\nargument 8\nargument 7\nmov\n-24(%rbp), %rdx\nmov\n-16(%rbp), %rsi\nmov\n-8(%rbp), %rdi\ncall\nfoo\n-\nAccess A to F via registers\nprevious frame pointer\nreturn address\n-\nor put them in local memory\n-\nAccess rest using 16+xx(%rbp)\nmov\n16(%rbp), %rax\nmov\n24(%rbp), %r10\ncalliee saved\nregisters\nrbp\n(\np),\nrsp\nregisters\nlocal variables\nstack temporaries\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\ndynamic area\nrsp\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nlocal variables\nregisters\n- Locals and Temporaries\n- Calculate the size and allocate\nstack temporaries\ndynamic area\nll\nd\ni t\nspace on the stack\nsub\n$48, %rsp\n$48\ncaller saved registers\nargument 9\nargument 8\nargument 7\nor\nenter\n$48, 0\nAccess using 8 xx(%rbp)\nprevious frame pointer\nreturn address\n- Access using -8-xx(%rbp)\nmov\n-28(%rbp), %r10\nmov\n%r11, -20(%rbp)\ncalliee saved\nregisters\nrbp\nrsp\nregisters\nlocal variables\nstack temporaries\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\ndynamic area\nrsp\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nlocal variables\nregisters\n- Returning Calliee\n- Assume the return value is the first\ntemporary\nstack temporaries\ndynamic area\nll\nd\ni t\ntemporary\n- Restore the caller saved register\ncaller saved registers\nargument 9\nargument 8\nargument 7\n- Put the return value in %rax\n- Tear-down the call stack\nprevious frame pointer\nreturn address\nmov\n-8(%rbp), %rbx\nmov\n-16(%rbp), %rax\ncalliee saved\nregisters\nrbp\nmov\n%rbp, %rsp\npop\n%rbp\nret\nrsp\nregisters\nlocal variables\nstack temporaries\nleave\nrsp\ndynamic area\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nrbp\nlocal variables\nregisters\n- Returning Caller\n- Assume the return value goes to the\nfirst temporary\nstack temporaries\ndynamic area\nll\nd\ni t\nfirst temporary\n- Restore the stack to reclaim the\ncaller saved registers\nargument 9\nargument 8\nargument 7\nargument space\n- Restore the caller save registers\nrsp\ncall\nfoo\nCODE\nDATA\nadd\n$24, %rsp\npop\n%rcx\nmov\n%rax, 8(%rbp)\nControl Flow\nProcedures\nStatements\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\nParameter Passing\nTemporaries\np\n...\nData Access\ng\nRead-only Data\n\nQuestion:\n- Do you need the $rbp?\ny\np\n- What are the advantages and disadvantages\nof having $rbp?\nof having $rbp?\n\nOutline\n- Introduction\n- Machine Language\n- Overview of a modern processor\n- Memory Layout\n- Procedure Abstraction\nProcedure Abstraction\n- Procedure Linkage\n- Guidelines in Creating a Code Generator\n- Guidelines in Creating a Code Generator\n\nWhat We Covered Today..\ny\nCODE\nDATA\nProcedures\nGlobal Static Variables\nGlobal Dynamic Data\nControl Flow\nGlobal Dynamic Data\nLocal Variables\nStatements\nTemporaries\nParameter Passing\nData Access\nParameter Passing\nRead-only Data\n\n-\nGuidelines for the code\ngenerator\ngenerator\n- Lower the abstraction level slowly\n- Do many passes, that do few things (or one thing)\n- Easier to break the project down, generate and debug\n- Keep th\nthe abbsttractition llevellcons iisttentt\n- IR should have 'correct' semantics at all time\n- At least you should know the semantics\nAt least you should know the semantics\n- You may want to run some of the optimizations between\nthe passes.\n- Use assertions liberally\n- Use an assertion to check your assumption\n\nGuidelines for the code\ngenerator\ngenerator\n- Do the simplest but dumb thing\n- it is ok to generate 0 + 1*x + 0*y\n- Code is painful to look at, but will help optimizations\n- Make sure you know want can be done at...\nMake sure you know want can be done at...\n- Compile time in the compiler\n- Runtime using generated code\nRuntime using generated code\n\nGuidelines for the code\ngenerator\ngenerator\n- Remember that optimizations will come later\nLet the optimizer do the optimizations\n- Let the optimizer do the optimizations\n- Think about what optimizer will need and structure your\ncode accordingly\n- Example: Register allocation, algebraic simplification,\nconstant propagation\n- Setup a good testing infrastructure\n- regression tests\ng\n- If a input program creates a bug, use it as a regression test\n- Learn good bug hunting procedures\n- Example: binary search\nExample: binary search\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec08.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/d721fd455e62d93610141e7c3f22186a_MIT6_035S10_lec08.pdf",
      "content": "Unoptimized Code Generation\n\n- Last time we left off on the procedure\np\nabstraction ...\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nThe Stack\n- Arguments 0 to 6\nargument n\n8*n+16(%rbp)\nvious\nare in:\n- %rdi, %rsi, %rdx,\n%\n% 8\nd % 9\nReturn address\n...\nargument 7\n8(%rbp)\n16(%rbp)\nPre\n%rcx, %r8 and %r9\n% b\nlocal 0\nPrevious %rbp\n0(%rbp)\n-8(%rbp)\nurrent\n%rbp\n- marks the beginning\nof the current frame\n0(%rsp)\n...\nlocal m\n-8*m-8(%rbp)\nCu\nof the current frame\n%rsp\n- marks the end\nVariable size\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\n\nQuestion:\n- Why use a stack? Wh yy not use the heapp or ppre\nallocated in the data segment?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\n\nt\nProcedure Linkages\ng\nStandard procedure linkage\nPre-call:\n-Save caller-saved registers\np\ng\nprocedure p\nprolog\nprocedure q\nSave caller saved registers\n-Push arguments\nProlog:\nP\nh\nld f\ni\nll\nprolog\n-Push old frame pointer\n-Save calle-saved registers\n-Make room for temporaries\npre-call\npost-return\nepilog\nEpilog:\n-Restore callee-saved\n-Pop old frame pointer\nepilog\nPop old frame pointer\n-Store return value\nPost-return:\nR\nt\nll\nd\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\n-Restore caller-saved\n-Pop arguments\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nrbp\nlocal variables\nregisters\n- Calling: Caller\n- Assume %rcx is live and\nis caller save\nstack temporaries\ndynamic area\nll\nd\ni t\n- Call foo(A, B, C, D, E, F, G, H, I)\n- A to I are at -8(%rbp) to -72(%rbp)\nrsp\ncaller saved registers\nargument 9\nargument 8\nargument 7\npush\n%rcx\npush\n-72(%rbp)\npush\n-64(%rbp)\nreturn address\npush\n64(%rbp)\npush\n-56(%rbp)\nmov\n-48(%rbp), %r9\nmov\n-40(%rbp), %r8\nmov\n-32(%rbp), %rcx\nmov\n-24(%rbp), %rdx\nmov\n-16(%rbp), %rsi\n8(% b )\n% di\nmov\n-8(%rbp), %rdi\ncall\nfoo\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nrbp\nlocal variables\nregisters\n- Calling: Calliee\n- Assume %rbx is used in the function\nd i\nlli\nstack temporaries\ndynamic area\nll\nd\ni t\nand is calliee save\n- Assume 40 bytes are required for locals\ncaller saved registers\nargument 9\nargument 8\nargument 7\nfoo:\npush\n%rbp\nmov\n%rsp\n%rbp\nprevious frame pointer\nreturn address\nmov\n%rsp, %rbp\nsub\n$48, %rsp\nmov\n%rbx, -8(%rbp)\nrsp\ncalliee saved\nregisters\nenter\n$48, $0\nregisters\nlocal variables\nstack temporaries\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\ndynamic area\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nlocal variables\nregisters\n-\nArguments\n-\nCall foo(A, B, C, D, E, F, G, H, I)\n-\nPassed in by pushing before the call\nstack temporaries\ndynamic area\nll\nd\ni t\npush\n-72(%rbp)\npush\n-64(%rbp)\npush\n-56(%rbp)\nmov\n-48(%rbp), %r9\nmov\n-40(%rbp), %r8\nmov\n-32(%rbp), %rcx\ncaller saved registers\nargument 9\nargument 8\nargument 7\nmov\n-24(%rbp), %rdx\nmov\n-16(%rbp), %rsi\nmov\n-8(%rbp), %rdi\ncall\nfoo\n-\nAccess A to F via registers\nprevious frame pointer\nreturn address\n-\nor put them in local memory\n-\nAccess rest using 16+xx(%rbp)\nmov\n16(%rbp), %rax\nmov\n24(%rbp), %r10\ncalliee saved\nregisters\nrbp\n(\np),\nrsp\nregisters\nlocal variables\nstack temporaries\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\ndynamic area\nrsp\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nlocal variables\nregisters\n- Locals and Temporaries\n- Calculate the size and allocate\nstack temporaries\ndynamic area\nll\nd\ni t\nspace on the stack\nsub\n$48, %rsp\n$48\ncaller saved registers\nargument 9\nargument 8\nargument 7\nor\nenter\n$48, 0\nAccess using 8 xx(%rbp)\nprevious frame pointer\nreturn address\n- Access using -8-xx(%rbp)\nmov\n-28(%rbp), %r10\nmov\n%r11, -20(%rbp)\ncalliee saved\nregisters\nrbp\nrsp\nregisters\nlocal variables\nstack temporaries\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\ndynamic area\nrsp\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nlocal variables\nregisters\n- Returning Calliee\n- Assume the return value is the first\nt\nstack temporaries\ndynamic area\nll\nd\ni t\ntemporary\n- Restore the caller saved register\ncaller saved registers\nargument 9\nargument 8\nargument 7\n- Put the return value in %rax\n- Tear-down the call stack\nprevious frame pointer\nreturn address\nmov\n-8(%rbp), %rbx\nmov\n-16(%rbp), %rax\ncalliee saved\nregisters\nrbp\nmov\n%rbp, %rsp\npop\n%rbp\nret\nrsp\nregisters\nlocal variables\nstack temporaries\nleave\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\nrsp\ndynamic area\n\nprevious frame pointer\nreturn address\nStack\ncalliee saved\nrbp\nlocal variables\nregisters\n- Returning Caller\n-\n(Assume the return value goes to the first\nt\n)\nstack temporaries\ndynamic area\nll\nd\ni t\ntemporary)\n- Restore the stack to reclaim the\nargument space\ncaller saved registers\nargument 9\nargument 8\nargument 7\n- Restore the caller save registers\n- Save the return value\nrsp\ncall\nfoo\nCODE\nDATA\nadd\n$24, %rsp\npop\n%rcx\nmov\n%rax, 8(%rbp)\nControl Flow\nProcedures\nStatements\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\nParameter Passing\nTemporaries\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\np\n...\nData Access\ng\nRead-only Data\n\nQuestion:\n- Do you need the $rbpp?\n- What are the advantages and disadvantages of\nhaving $rbp?\nhaving $rbp?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2001\n\nSo far we covered..\nCODE\nDATA\nProcedures\nGlobal Static Variables\nGlobal Dynamic Data\nControl Flow\nGlobal Dynamic Data\nLocal Variables\nStatements\nTemporaries\nParameter Passing\nData Access\nParameter Passing\nRead-only Data\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nOutline\n- Generation of expressions and statements\n- Generation of control flow\n- x86-64 Processor\n- Guidelines in writing a code generator\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nExpressions\np\n- Expressions are represented as trees\np\np\n- Expression may produce a value\n- Or, it may set the condition codes (boolean exprs)\n,\ny\n(\np )\n- How do you map expression trees to the machines?\n- How to arrange the evaluation order?\nWh\nt k\nth i t\ndi t\nl\n?\n- Where to keep the intermediate values?\n- Two approaches\n- Stack Model\n- Flat List Model\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEvaluating expression trees\ng\np\n- Stack model\n- Eval left-sub-tree\nPut the results on the stack\n- Eval right-sub-tree\nPut the results on the stack\nOP\n- Get top two values from the stack\nperform the operation OP\nh\nl\nh\nk\nput the results on the stack\n- Very inefficient!\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEvaluating expression trees\ng\np\n- Flat List Model\n- The idea is to linearize the expression tree\n- Left to Right Depth-First Traversal of the expression tree\nAll\ni\nf\ni\ndi\n( ll h\nd\nf h\n)\n- Allocate temporaries for intermediates (all the nodes of the tree)\n- New temporary for each intermediate\n- All the temporaries on the stack (for now)\n- Each expression is a single 3-addr op\n- x = y op z\n- Code generation for the 3-addr expression\nCode generation for the 3 addr expression\n- Load y into register %r10\n- Load z into register %r11\n- Perform\nop %r10\n%r11\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nPerform op %r10, %r11\n- Store %r11 to x\n\nIssues in Lowering Expressions\ng\np\n- Map intermediates to registers?\n- registers are limited\n- when the tree is large, registers may be insufficient ⇒allocate space\nin the stack\n- No machine instruction is available\n- May need to expand the intermediate operation into multiple\nmachine ops\nmachine ops.\n- Very inefficient\n- too many copies\ny\np\n- don't worry, we'll take care of them in the optimization\npasses\nk\nth\nd\nt\ni\nl\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n- keep the code generator very simple\n\nWhat about statements?\n- Assignment statements are simple\ng\np\n- Generate code for RHS expression\n- Store the resulting value to the LHS address\ng\n- But what about conditionals and loops?\n- But what about conditionals and loops?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nOutline\n- Generation of statements\n- Generation of control flow\n- Guidelines in writing a code ggenerator\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nTwo Approaches\npp\n- Template Matching Approach\np\ng\npp\n- Peephole Optimization\n- Algorithmic Approach\n- Both are based on structural induction\n- Generate a representation for the sub-parts\n- Combine them into a representation for the whole\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nGeneration of control flow:\nT\nl t M t hi\nA\nh\nTemplate Matching Approach\n- Flatten the control structure\n- Now generate the appropriate code\nPut unique labels for control join points\n- use a template\n- Put unique labels for control join points\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nab e d:\nTemplate for conditionals\nif (test)\nb d\n<do the test>\njoper l b t\nfalse_body\ntrue_body\nelse\nfalse body\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nlab_true\n<false_body>\n_\njmp\nlab_end\nlab_true:\n<true_body>\nlab end:\n\nExample Program\nif(ax > bx)\nif(ax > bx)\ndx = ax - bx;\nelse\ndx = bx - ax;\n<do test>\njoper\n.L0\n<FALSE BODY>\nprevious frame pointer\nReturn address\nLocal variable px (10)\nLocal variable py (20)\n<FALSE BODY>\njmp\n.L1\n.L0:\nArgument 9: cx (30)\nArgument 8: bx (20)\nLocal variable py (20)\nLocal variable pz (30)\n<TRUE BODY>\nprevious frame pointer\nReturn address\nrbp\nArgument 7: ax (10)\nLocal variable dx (??)\nL\nl\ni bl d (??)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n.L1:\nrsp\nLocal variable dy (??)\nLocal variable dz (??)\n\nExample Program\nif(ax > bx)\nif(ax > bx)\ndx = ax - bx;\nelse\ndx = bx - ax;\nmovq 16(%rbp), %r10\nmovq 24(%rbp), %r11\ncmpq\n%r10, %r11\ncmpq %r10, %r11\njg .L0\n<FALSE BODY>\nprevious frame pointer\nReturn address\nLocal variable px (10)\nLocal variable py (20)\n<FALSE BODY>\njmp\n.L1\n.L0:\nArgument 9: cx (30)\nArgument 8: bx (20)\nLocal variable py (20)\nLocal variable pz (30)\n<TRUE BODY>\nprevious frame pointer\nReturn address\nrbp\nArgument 7: ax (10)\nLocal variable dx (??)\nL\nl\ni bl d (??)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n.L1:\nrsp\nLocal variable dy (??)\nLocal variable dz (??)\n\nExample Program\nif(ax > bx)\nif(ax > bx)\ndx = ax - bx;\nelse\ndx = bx - ax;\nmovq 16(%rbp), %r10\nmovq 24(%rbp), %r11\ncmpq\n%r10, %r11\ncmpq %r10, %r11\njg .L0\nmovq 24(%rbp), %r10\nmovq 16(%rbp), %r11\nb\n% 10\n% 11\nprevious frame pointer\nReturn address\nLocal variable px (10)\nLocal variable py (20)\nsubq %r10, %r11\nmovq %r11, -8(%rbp)\njmp .L1\n.L0:\nArgument 9: cx (30)\nArgument 8: bx (20)\nLocal variable py (20)\nLocal variable pz (30)\n<TRUE BODY>\nprevious frame pointer\nReturn address\nrbp\nArgument 7: ax (10)\nLocal variable dx (??)\nL\nl\ni bl d (??)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n.L1:\nrsp\nLocal variable dy (??)\nLocal variable dz (??)\n\nExample Program\nif(ax > bx)\nif(ax > bx)\ndx = ax - bx;\nelse\ndx = bx - ax;\nmovq 16(%rbp), %r10\nmovq 24(%rbp), %r11\ncmpq\n%r10, %r11\ncmpq %r10, %r11\njg .L0\nmovq 24(%rbp), %r10\nmovq 16(%rbp), %r11\nb\n% 10\n% 11\nprevious frame pointer\nReturn address\nLocal variable px (10)\nLocal variable py (20)\nsubq %r10, %r11\nmovq %r11, -8(%rbp)\njmp .L1\n.L0:\nArgument 9: cx (30)\nArgument 8: bx (20)\nLocal variable py (20)\nLocal variable pz (30)\nmovq 16(%rbp), %r10\nmovq 24(%rbp), %r11\nsubq %r10, %r11\nmovq\n%r11, -8(%rbp)\nprevious frame pointer\nReturn address\nrbp\nArgument 7: ax (10)\nLocal variable dx (??)\nL\nl\ni bl d (??)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nmovq %r11, 8(%rbp)\n.L1:\nrsp\nLocal variable dy (??)\nLocal variable dz (??)\n\nTemplate for while loops\np\np\nwhile (test)\nb d\nbody\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nTemplate for while loops\np\np\nlab_cont:\nwhile (test)\n<do the test>\nb d\njoper lab_body\njoper lab body\nbody\njmp\nlab_end\nlab_body:\nb d\n<body>\njmp\nlab_cont\nlab_end:\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nTemplate for while loops\np\np\nwhile (test)\nb d\nlab_cont:\n<do the test>\njoper lab body\nbody\njoper lab_body\njmp\nlab_end\nlab_body:\n<b d >\n<body>\njmp\nlab_cont\nlab_end:\n- An optimized template\nlab_cont:\n_\n<do the test>\njoper lab_end\n<body>\nCODE\nDATA\nProcedures\nControl Flow\nGlobal Static Variables\nGlobal Dynamic Data\nLocal Variables\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\ny\njmp\nlab_cont\nlab_end:\nStatements\nData Access\nParameter Passing\nRead-only Data\nTemporaries\n\nQuestion:\nQ\n- What is the template for?\ndo\nbody\nbody\nwhile (test)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nQuestion:\nQ\n- What is the template for?\ndo\nbody\nbody\nwhile (test)\nlab_begin:\n<body>\n<do test>\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\njoper lab_begin\n\nQuestion:\nQ\n- What is a drawback of the template based\napproach?\napproach?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\n-\nControl Flow Graph (CFG)\np (\n)\n- Starting point: high level intermediate format,\ng p\ng\nsymbol tables\n- Target: CFG\nTarget: CFG\n- CFG Nodes are Instruction Nodes\n- CFG Edges Represent Flow of Control\nCFG Edges Represent Flow of Control\n- Forks At Conditional Jump Instructions\nMerges When Flow of Control Can Reach A Point\nMerges When Flow of Control Can Reach A Point\nMultiple Ways\n- Entry and Exit Nodes\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nEntry and Exit Nodes\n\nif (x < y) {\nentry\njl xxx\nif (x < y) {\na = 0;\n} else {\n<\njl xxx\ncmp %r10, %r11\n}\n{\na = 1;\n}\nmov x, %r10 Mov y, %r11\nmov $0, a\nmov $1, a\np\n,\nexit\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nPattern for if then else\n\nShort-Circuit Conditionals\n- In program, conditionals have a condition\nwritten as a boolean expression\n((i < n) && (v[i] != 0)) || i > k)\n- Semantics say should execute only as much as\nrequired to determine condition\n- Evaluate (v[i] != 0) only if (i < n) is true\n- Evaluate i > k only if ((i < n) && (v[i] != 0)) is\nfalse\nfalse\n- Use control-flow graph to represent this short-\ncircuit evaluation\ncircuit evaluation\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nShort-Circuit Conditionals\nwhile (i < n && v[i] != 0) {\ni\ni+1;\nentry\ni = i+1;\n}\n<\njl xxx\n<\ncmp %r10, %r11\njl yyy\nmov %r11 i\n<\ncmp %r10, %r11\nexit\nmov %r11, i\nadd $1, %r11\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nmov i, %r11\n\nMore Short-Circuit Conditionals\nif (a < b || c != 0) {\ni\ni+1;\nentry\ni = i+1;\n}\njl xxx\n<\ncmp %r10, %r11\n<\njne yyy\n<\ncmp %r10, %r11\nmov %r11, i\ndd $1 % 11\nexit\nadd $1, %r11\nmov i, %r11\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nRoutines for Destructuring Program\nR\nt ti\nRepresentation\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nshortcircuit(c, t, f)\ngenerates short-circuit form of conditional represented by c\ngenerates short circuit form of conditional represented by c\nif c is true, control flows to t node\nif c is false, control flows to f node\n,\nreturns b - b is begin node for condition evaluation\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nnew kind of node - nop node\n\nDestructuring Seq Nodes\ng\nq\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nif n is of the form seq x y\nseq\nx\ny\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring Seq Nodes\ng\nq\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nif n is of the form seq x y\n1: (bx,ex) = destruct(x);\nseq\nbx\ne\nx\ny\nex\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring Seq Nodes\ng\nq\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nif n is of the form seq x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\nseq\nbx\ne\nb\nx\ny\nex\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring Seq Nodes\ng\nq\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nif n is of the form seq x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\n3: next(e ) = b ;\n3: next(ex)\nby;\nseq\nbx\ne\nb\nx\ny\nex\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring Seq Nodes\ng\nq\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nif n is of the form seq x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\n3: next(e ) = b ; 4: return (b e );\n3: next(ex)\nby; 4: return (bx, ey);\nseq\nbx\ne\nb\nx\ny\nex\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring If Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\ng\np\ny\nreturns (b,e) - b is begin node, e is end node in destructed form\nif n is of the form if c x y\nifif\nc\ny\nx\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring If Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\ng\np\ny\nreturns (b,e) - b is begin node, e is end node in destructed form\nif n is of the form if c x y\n1: (bx,ex) = destruct(x);\nif\nbx\nex\nif\nc\ny\nx\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring If Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\ng\np\ny\nreturns (b,e) - b is begin node, e is end node in destructed form\nif n is of the form if c x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\nif\nbx\nex\nif\nc\ny\nx\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring If Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\ng\np\ny\nreturns (b,e) - b is begin node, e is end node in destructed form\nif n is of the form if c x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\n3: e = new nop;\nif\nbx\nex\nif\nc\ny\ne\nx\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring If Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\ng\np\ny\nreturns (b,e) - b is begin node, e is end node in destructed form\nif n is of the form if c x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\n3: e = new nop; 4: next(ex) = e; 5: next(ey) = e;\nif\nbx\nex\nif\nc\ny\ne\nx\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring If Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\ng\np\ny\nreturns (b,e) - b is begin node, e is end node in destructed form\nif n is of the form if c x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\n3: e = new nop; 4: next(ex) = e; 5: next(ey) = e;\n6 b\nh\ni\ni (\nb\nb )\n6: bc = shortcircuit(c, bx, by);\nif\nb\nbx\nex\nif\nc\ny\nbc\ne\nx\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring If Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\ng\np\ny\nreturns (b,e) - b is begin node, e is end node in destructed form\nif n is of the form if c x y\n1: (bx,ex) = destruct(x); 2: (by,ey) = destruct(y);\n3: e = new nop; 4: next(ex) = e; 5: next(ey) = e;\n6 b\nh\ni\ni (\nb\nb ) 7\n(b\n)\n6: bc = shortcircuit(c, bx, by); 7: return (bc, e);\nif\nb\nbx\nex\nif\nc\ny\nbc\ne\nx\nby\ney\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring While Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nhil\nif n is of the form while c x\nwhile\nc\nx\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring While Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nhil\nif n is of the form while c x\n1: e = new nop;\nwhile\nc\nx\ne\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nDestructuring While Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nhil\nif n is of the form while c x\n1: e = new nop; 2: (bx,ex) = destruct(x);\nwhile\nc\nx\ne\nbx\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nex\n\nDestructuring While Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nhil\nif n is of the form while c x\n1: e = new nop; 2: (bx,ex) = destruct(x);\n3: b = shortcircuit(c b\ne);\n3: bc\nshortcircuit(c, bx, e);\nwhile\nbc\nc\nx\ne\nbx\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nex\n\nDestructuring While Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nhil\nif n is of the form while c x\n1: e = new nop; 2: (bx,ex) = destruct(x);\n3: b = shortcircuit(c b\ne); 4: next(e ) = b ;\n3: bc\nshortcircuit(c, bx, e); 4: next(ex)\nbc;\nwhile\nbc\nc\nx\ne\nbx\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nex\n\nDestructuring While Nodes\ng\ndestruct(n)\ngenerates lowered form of structured code represented by n\nreturns (b,e) - b is begin node, e is end node in destructed form\nif\ni\nf th f\nhil\nif n is of the form while c x\n1: e = new nop; 2: (bx,ex) = destruct(x);\n3: b = shortcircuit(c b\ne); 4: next(e ) = b ; 5: return (b e);\n3: bc\nshortcircuit(c, bx, e); 4: next(ex)\nbc; 5: return (bc, e);\nwhile\nbc\nc\nx\ne\nbx\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nex\n\nShortcircuiting And Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n&&\nif c is of the form c1 && c2\nc1 && c2\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nShortcircuiting And Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n&&\nif c is of the form c1 && c2\n1: b2 = shortcircuit(c2, t, f);\nc1 && c2\nb\nf\nb2\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nt\n\nShortcircuiting And Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n&&\nif c is of the form c1 && c2\n1: b2 = shortcircuit(c2, t, f); 2: b1 = shortcircuit(c1, b2, f);\nb\nc1 && c2\nb1\nb\nf\nb2\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nt\n\nShortcircuiting And Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n&&\nif c is of the form c1 && c2\n1: b2 = shortcircuit(c2, t, f); 2: b1 = shortcircuit(c1, b2, f);\n3: return (b );\nb\n3: return (b1);\nc1 && c2\nb1\nb\nf\nb2\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nt\n\nShortcircuiting Or Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n||\nif c is of the form c1 || c2\nc1 || c2\n1 ||\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nShortcircuiting Or Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n||\nif c is of the form c1 || c2\n1: b2 = shortcircuit(c2, t, f);\nc1 || c2\nb\n1 ||\nb2\nt\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nf\n\nShortcircuiting Or Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n||\nif c is of the form c1 || c2\n1: b2 = shortcircuit(c2, t, f); 2: b1 = shortcircuit(c1, t, b2);\nb\nc1 || c2\nb1\nb\n1 ||\nb2\nt\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nf\n\nShortcircuiting Or Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n||\nif c is of the form c1 || c2\n1: b2 = shortcircuit(c2, t, f); 2: b1 = shortcircuit(c1, t, b2);\n3: return (b );\nb\n3: return (b1);\nc1 || c2\nb1\nb\n1 ||\nb2\nt\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nf\n\nShortcircuiting Not Conditions\ng\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n!\nif c is of the form ! c1\n1: b = shortcircuit(c1, f, t); return(b);\nb\n! c1\nf\nt\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nComputed Conditions\np\nshortcircuit(c, t, f)\ngenerates shortcircuit form of conditional represented by c\nreturns b - b is begin node of shortcircuit form\nif\ni\nf th f\n<\nif c is of the form e1 < e2\n1: b = new cbr(e1 < e2, t, f); 2: return (b);\ne1 < e2\ncmp\njl\nt\nf\ne1\ne2\ncmp\nt\nf\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nNops In Destructured Representation\np\np\nwhile (i < n && v[i] != 0) {\ni\ni+1;\nentry\ni = i+1;\n}\n<\njl xxx\n<\ncmp %r10, %r11\njl yyy\nnop\nmov %r11 i\n<\ncmp %r10, %r11\nexit\nmov %r11, i\nadd $1, %r11\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nmov i, %r11\n\nEliminating Nops Via Peephole\nO ti i\nti\nOptimization\n...\n...\nnop\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nQuestion:\n- What are the pros and cons of tempplate\nmatching vs. algorithmic approach?\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nOutline\n- Generation of statements\n- Generation of control flow\n- x86-64 Processor\n- Guidelines in writing a code generator\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nGuidelines for the code generator\ng\n- Lower the abstraction level slowly\n- Do many passes, that do few things (or one thing)\n- Easier to break the project down, generate and debug\n- Keep the abstraction level consistent\n- IR should have 'correct' semantics at all time\nIR should have correct semantics at all time\n- At least you should know the semantics\n- You may want to run some of the optimizations\nYou may want to run some of the optimizations\nbetween the passes.\n- Use assertions liberally\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nUse assertions liberally\n- Use an assertion to check your assumption\n\nGuidelines for the code generator\ng\n- Do the simplest but dumb thing\ni i\nk\n1*\n0*\n- it is ok to generate 0 + 1*x + 0*y\n- Code is painful to look at; let optimizations improve it\n- Make sure you know want can be done at...\ny\n- Compile time in the compiler\n- Runtime using generated code\ng g\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nGuidelines for the code generator\ng\n- Remember that optimizations will come later\nLet the optimizer do the optimizations\n- Let the optimizer do the optimizations\n- Think about what optimizer will need and structure your\ncode accordingly\ncode accordingly\n- Example: Register allocation, algebraic simplification,\nconstant propagation\n- Setup a good testing infrastructure\n- regression tests\n- If a input program creates a bug, use it as a regression test\n- Learn good bug hunting procedures\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n- Example: binary search , delta debugging\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "MIT6_035S10_lec09.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/646551e794a46c21a5e504a4a15fe52a_MIT6_035S10_lec09.pdf",
      "content": "Spring 2009\nSpring 2009\nLecture 9: Introduction to\nLecture 9: Introduction to\nProgram Analysis and\nOptimization\nOptimization\n\nead Code\nat o\nOutline\n- Introduction\nIntroduction\n- Basic Blocks\n- Common Subexpression Elimination\nC\nP\nti\n- Copy Propagation\n- Dead Code Elimination\n- Algebraic Simplification\n- Summary\n\nProgram Analysis\ng\ny\n- Compile-time reasoning about run-time behavior\nof program\n- Can discover things that are always true:\n\"\ni\nl\n1 i\nth\nt t\nt\n\"\n- \"x is always 1 in the statement y = x + z\"\n- \"the pointer p always points into array a\"\n- \"the statement return 5 can never execute\"\n- Can infer things that are likely to be true:\n- \"the reference r usually refers to an object of class C\"\n- \"the statement a\nb + c appears to execute more frequently\n- the statement a = b + c appears to execute more frequently\nthan the statement x = y + z\"\n- Distinction between data and control-flow properties\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nTransformations\n- Use analysis results to transform program\n- Overall goal: improve some aspect of program\n- Traditional goals:\nR d\nb\nf\nd i\ni\n- Reduce number of executed instructions\n- Reduce overall code size\n- Other goals emerge as space becomes more complex\nOther goals emerge as space becomes more complex\n- Reduce number of cycles\n- Use vector or DSP instructions\n- Improve instruction or data cache hit rate\n- Reduce power consumption\n- Reduce memory usage\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nReduce memory usage\n\nead Code\nat o\nOutline\n- Introduction\nIntroduction\n- Basic Blocks\n- Common Subexpression Elimination\nC\nP\nti\n- Copy Propagation\n- Dead Code Elimination\n- Algebraic Simplification\n- Summary\n\na\no\na\nu\no\nu\no\nControl Flow Graph\np\n- Nodes Represent Computation\np\np\n- Each Node is a Basic Block\n- Basic Block is a Sequence of Instructions with\nq\n- No Branches Out Of Middle of Basic Block\n- No Branches Into Middle of Basic Block\n- Basic Blocks should be maximal\n- Execution of basic block starts with first\ninstruction\n- Includes all instructions in basic block\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n- Edges Represent Control Flow\n\n=\nControl Flow Graph\ns = 0;\np\ninto add(n, k) {\na = 4;\ni = 0;\nk\ns = 0; a = 4; i = 0;\nif (k == 0)\nb\nk == 0\nb = 1;\nelse\nb = 2;\nb = 1;\nb = 2;\nb\n2;\nwhile (i < n) {\ns = s + a*b;\ni < n\n*b\n;\ni = i + 1;\n}\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nreturn s;\n}\n\n-\nBasic Block Construction\n- Start with instruction control-flow graph\ng\np\n- Visit all edges in graph\n- Merge adjacent nodes if\nMerge adjacent nodes if\n- Only one edge from first node\nOnly one edge into second node\n- Only one edge into second node\ns = 0;\na = 4;\ns = 0;\na = 4;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\nk == 0\nb = 1;\nb = 2;\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\ni = 0;\nk == 0\nk == 0\nb = 1;\nb = 2;\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 2;\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 2;\ni < n\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 2;\ni < n\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\ns = s + a*b;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 2;\ni < n\ni < n\ns = s + a*b;\nreturn s;\ns = s + a*b;\ni = i + 1;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni = i + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 2;\ni < n\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\ns = s + a*b;\ni = i + 1;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 2;\ni < n\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 1;\nb = 2;\ni < n\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 1;\nb = 2;\ni < n\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\ns = 0;\ns = 0;\ns = 0;\na = 4;\na = 4;\ni = 0;\nk == 0\ni = 0;\nk == 0\nk == 0\nk == 0\nb = 1;\nb = 2;\nb = 1;\nb = 2;\ni < n\ni < n\ns = s + a*b;\ni = i + 1;\nreturn s;\ns = s + a*b;\ni = i + 1;\nreturn s;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\ni\ni + 1;\n\nProgram Points, Split and Join\nPoints\nPoints\n- One program point before and after each\nstatement in program\n- Split point has multiple successors - conditional\nbranch statements only split points\n- Merge point has multiple predecessors\n- Each basic block\n- Either starts with a merge point or its\npredecessor ends with a split point\n- Either ends with a split point or its successor\ni h\ni\nstarts with a merge point\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\n-\n-\n\nBasic Block Optimizations\np\n- Common Sub\n- Copy Propagation\nCommon Sub\nExpression Elimination\n- a=(x+y)+z; b=x+y;\nCopy Propagation\n- a=x+y; b=a; c=b+z;\n- a=x+y; b=a; c=a+z;\n(\ny)\ny\n- t=x+y; a=t+z; b=t;\nC\nt\nt P\nti\n- Dead Code Elimination\n- Constant Propagation\n- x=5; b=x+y;\n- x=5; b=5+y;\n- Dead Code Elimination\n- a=x+y; b=a; b=a+z;\n- a=x+y;\nb=a+z\n;\ny;\n- Algebraic Identities\n- Strength Reduction\ni*4\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n- a=x*1;\n- a=x;\n- t=i*4;\n- t=i<<2;\n\nBasic Block Analysis Approach\ny\npp\n- Assume normalized basic block - all statements\nare of the form\n- var = var op var (where op is a binary operator)\n- var = op var (where op is a unary operator)\n- var = var\n- Simulate a symbolic execution of basic block\n- Reason about values of variables (or other\naspects of computation)\n- Derive property of interest\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nodu\nd a\na\no\nu\no\na\nTwo Kinds of Variables\n- Temporaries Introduced By Compiler\np\ny\np\n- Transfer values only within basic block\n- Introduced as part of instruction flattening\np\ng\n- Introduced by optimizations/transformations\n- Typically assigned to only once\nTypically assigned to only once\n- Program Variables\nDeclared in original program\n- Declared in original program\n- May be assigned to multiple times\nM\nt\nf\nl\nb t\nb\ni bl\nk\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n- May transfer values between basic blocks\n\nead Code\nat o\nOutline\n- Introduction\nIntroduction\n- Basic Blocks\n- Common Subexpression Elimination\nC\nP\nti\n- Copy Propagation\n- Dead Code Elimination\n- Algebraic Simplification\n- Summary\n\nS\nu ate e ecut o\no bas c b oc\nValue Numbering\n- Reason about values of variables and expressions\nin the program\n- Simulate execution of basic block\n- Assign virtual value to each variable and expression\n- Disco ered propert\nhich\nariables and e pressions\nDiscovered property: which variables and expressions\nhave the same value\n- Standdardduse:\n- Common subexpression elimination\n- Typically combined with transformation that\nTypically combined with transformation that\n- Saves computed values in temporaries\n- Replaces expressions with temporaries when value\nof expressiion previiouslly computtedd\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nb v5\nOriginal Basic\nNew Basic\nBlock\na = x+y\nb = a+z\na = x+y\nt1 = a\nb\na+z\nBlock\nb\na z\nb = b+y\nc = a+z\nb = a+z\nt2 = b\nb = b+y\nt3\nb\nt3 = b\nVar to Val\nc = t2\nx v1\ny v2\na v3\nv1+v2 v3\nExp to Val\nv1+v2 t1\nExp to Tmp\nb v6\nz v4\nc v5\nv1+v2 v3\nv3+v4 v5\nv1+v2 t1\nv3+v4 t2\nv5+v2 v6\nv5+v2 t6\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nValue Numbering Summary\ng\ny\n- Forward symbolic execution of basic block\n-\n- Each new value assigned to temporary\n- a=x+y; becomes a=x+y; t=a;\nTemporary preserves value for use later in program even\nTemporary preserves value for use later in program even\nif original variable rewritten\n- a=x+y;\na=a+z; b=x+y becomes\n- a=x+y; t=a; a=a+z; b=t;\n- Maps\n- V\nt\nVar to VVall - specifiifies symbbolilic vallue ffor eachhvar iiable\nbl\n- Exp to Val - specifies value of each evaluated expression\n- Exp to Tmp - specifies tmp that holds value of each\nExp to Tmp\nspecifies tmp that holds value of each\nevaluated expression\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n=\nMap Usage\np\ng\n- Var to Val\n- Used to compute symbolic value of y and z when\nprocessing statement of form x = y + z\n- Exp to Tmp\np\np\n- Used to determine which tmp to use if value(y) +\nvalue(z) previously computed when processing\nstatement of form x = y + z\nstatement of form x\ny + z\n- Exp to Val\n- Used to update Var to Val when\n- processing statement of the form x = y + z, and\n- value(y) + value(z) previously computed\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nvalue(y) + value(z) previously computed\n\nInteresting Properties\ng\np\n- Finds common subexpressions even if they use\ndiff\nt\ni bl\ni\ni\ndifferent variables in expressions\n- y=a+b;\nx=b; z=a+x becomes\na b t\nb\nt\n- y=a+b; t=y; x=b; z=t\n- Why? Because computes with symbolic values\n- Finds common subexpressions even if variable\n- Finds common subexpressions even if variable\nthat originally held the value was overwritten\n- y=a+b;\ny=1; z=a+b becomes\ny a+b;\ny 1; z a+b becomes\n- y=a+b; t=y; y=1; z=t\n- Why? Because saves values away in\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\ny\ny\ntemporaries\n\nOne More Interesting Property\ng\np\ny\n- Flattening and CSE combine to capture partial and\narbitrarily complex common subexpressions\nw=(a+b)+c;\nx=b;\ny=(a+x)+c; z=a+b;\n- After flattening:\na+b; w t1+c;\na+x; y t2+c;\nz=a+b;\nt1\nt1=a+b; w=t1+c;\nxx b;\n=b; t2\nt2=a+x; y=t2+c;\nz a+b;\n- CSE algorithm notices that\n- t1+c anddt 22+c compute same vallue\n- In the statement z = a+b, a+b has already been computed so\ngenerated code can reuse the result\nt1=a+b; w=t1+c; t3=w; x=b; t2=t1; y=t3;\nz=t1;\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nProblems I\n- Algorithm has a temporary for each new value\n- a=x+y; t1=a;\n- Introduces\n- lots of temporaries\n- lots of copy statements to temporaries\n- In many cases, temporaries and copy statements\nare unnecessary\nS\nli\ni\nt\nth\nith\nti\nd\n- So we eliminate them with copy propagation and\ndead code elimination\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nProblems II\n- Expressions have to be identical\n- a=x+y+z; b=y+z+x; c=x*2+y+2*z-(x+z)\n- We use canonicalization\n- We use algebraic simplification\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCopy Propagation\npy\np g\n- Once again, simulate execution of program\n- If can, use original variable instead of temporary\n- a=x+y; b=x+y;\n- After CSE becomes a=x+y; t=a; b=t;\n- After CP becomes a=x+y; t=a; b=a;\nAf\nDCE b\nb=a;\n- After DCE becomes a=x+y;\nb\n- Key idea:\nd t\ni\nh\ni i\nl\ni bl\ni NOT\nitt\n- determine when original variable is NOT overwritten\nbetween its assignment statement and the use of the\ncomputed value\n- If not overwritten, use original variable\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nead Code\nat o\nOutline\n- Introduction\nIntroduction\n- Basic Blocks\n- Common Subexpression Elimination\nC\nP\nti\n- Copy Propagation\n- Dead Code Elimination\n- Algebraic Simplification\n- Summary\n\nCopy Propagation Maps\npy\np g\np\n- Maintain two maps\np\n- tmp to var: tells which variable to use instead\nof a given temporary variable\n- var to set: inverse of tmp to var. tells which\ntemps are mapped to a given variable by tmp\nto var\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCopy Propagation Example\npy\np g\np\n- Original\n- After CSE and Copy\na = x+y\na\nx+y\nb = a+z\nPropagation\nc = x+y\na = x+y\na = b\nt1 = a\n- After CSE\nb = a+z\nt2\nb\nt2 = b\na = x+y\nc = a\nt1 = a\na = b\nb = a+z\na\nt2 = b\nc\nt1\nc = t1\na = b\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nCopy Propagation Example\npy\np g\np\nBasic Block\nBasic Block After\nAf\nCSE\nCSE\nCSE and C\nd Copy PProp\nAfter CSE\na = x+y\na = x+y\nt1 = a\nt1\nt1 = a\ntmp to var\ntmp to var\nvar to set\nvar to set\nt1 a\na {t1}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nCopy Propagation Example\npy\np g\np\nBasic Block\nBasic Block After\nAf\nCSE\nCSE\nCSE and C\nd Copy PProp\nAfter CSE\na = x+y\na = x+y\nt1 = a\nt1\nt1 = a\nb = a+z\nb = a+z\nt2 = b\nt2 = b\ntmp to var\ntmp to var\nvar to set\nvar to set\nt1 a\na {t1}\nt2 b\nb {t2}\nt2}\nt2 b\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nCopy Propagation Example\npy\np g\np\nBasic Block\nBasic Block After\nAf\nCSE\nCSE\nCSE and C\nd Copy PProp\nAfter CSE\na = x+y\na = x+y\nt1 = a\nt1\nt1 = a\nb = a+z\nb = a+z\nt2 = b\nt2 = b\nc = t1\ntmp to var\ntmp to var\nvar to set\nvar to set\nt1 a\na {t1}\nt2 b\nb {t2}\nt2}\nt2 b\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nCopy Propagation Example\npy\np g\np\nBasic Block\nBasic Block After\nAf\nCSE\nCSE\nCSE and C\nd Copy PProp\nAfter CSE\na = x+y\na = x+y\nt1 = a\nt1\nt1 = a\nb = a+z\nb = a+z\nt2 = b\nt2 = b\nc = t1\nc = a\ntmp to var\ntmp to var\nvar to set\nvar to set\nt1 a\na {t1}\nt2 b\nb {t2}\nt2}\nt2 b\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nCopy Propagation Example\npy\np g\np\nBasic Block\nBasic Block After\nAf\nCSE\nCSE\nCSE and C\nd Copy PProp\nAfter CSE\na = x+y\na = x+y\nt1 = a\nt1\nt1 = a\nb = a+z\nb = a+z\nt2 = b\nt2 = b\nc = t1\nc = a\na = b\na = b\ntmp to var\ntmp to var\nvar to set\nvar to set\nt1 a\na {t1}\nt2 b\nb {t2}\nt2}\nt2 b\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nCopy Propagation Example\npy\np g\np\nBasic Block\nBasic Block After\nAf\nCSE\nCSE\nCSE and C\nd Copy PProp\nAfter CSE\na = x+y\na = x+y\nt1 = a\nt1\nt1 = a\nb = a+z\nb = a+z\nt2 = b\nt2 = b\nc = t1\nc = a\na = b\na = b\ntmp to var\ntmp to var\nvar to set\nvar to set\nt1 t1\na {}\nt2 b\nb {t2}\nt2}\nt2 b\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nead Code\nat o\nOutline\n- Introduction\nIntroduction\n- Basic Blocks\n- Common Subexpression Elimination\nC\nP\nti\n- Copy Propagation\n- Dead Code Elimination\n- Algebraic Simplification\n- Summary\n\n-\n=\nDead Code Elimination\n- Copy propagation keeps all temps around\npy p\np g\np\np\n- May be temps that are never read\n- Dead Code Elimination removes them\nDead Code Elimination removes them\nBasic Block After\nCSE and CP\nBasic Block After\nCSE CP and DCE\na = x+y\nt1 = a\na = x+y\nb = a+z\nCSE and CP\nCSE, CP and DCE\nt1\na\nb = a+z\nt2 = b\nc\na\nb\na+z\nc = a\na = b\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nc = a\na = b\n\na\na\na\no\na ab\na a\nd d\nDead Code Elimination\n- Basic Idea\n- Process Code In Reverse Execution Order\n- Maintain a set of variables that are needed\nlater in computation\n- If encounter an assignment to a temporary\ng\np\ny\nthat is not needed, remove assignment\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nBasic Block After\na = x+y\nt1\nCSE and Copy Prop\nt1 = a\nb = a+z\nt2 = b\nc = a\na = b\nNeeded Set\n{b}\n{ }\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After\na = x+y\nt1\nCSE and Copy Prop\nt1 = a\nb = a+z\nt2 = b\nc = a\na = b\nNeeded Set\n{a, b}\n{ ,\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After\na = x+y\nt1\nCSE and Copy Prop\nt1 = a\nb = a+z\nt2 = b\nc = a\na = b\nNeeded Set\n{a, b}\n{ ,\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After\na = x+y\nt1\nCSE and Copy Prop\nt1 = a\nb = a+z\nc = a\na = b\nNeeded Set\n{a, b}\n{ ,\n}\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After\na = x+y\nt1\nCSE and Copy Prop\nt1 = a\nb = a+z\nc = a\na = b\nNeeded Set\n{a, b, z}\n{ ,\n, }\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After\na = x+y\nt1\nCSE and Copy Prop\nt1 = a\nb = a+z\nc = a\na = b\nNeeded Set\n{a, b, z}\n{ ,\n, }\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After\na = x+y\nCSE and Copy Prop\nb = a+z\nc = a\na = b\nNeeded Set\n{a, b, z}\n{ ,\n, }\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After , CSE Copy Propagation,\na = x+y\nand Dead Code Elimination\nb = a+z\nc = a\na = b\nNeeded Set\n{a, b, z}\n{ ,\n, }\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nBasic Block After , CSE Copy Propagation,\nand Dead Code Elimination\na = x+y\nb = a+z\nc = a\na = b\nNeeded Set\n{a, b, z}}\n{ ,\n,\nSaman Amarasinghe\n6.035\n(c)MIT Fall 2006\n\nead Code\nat o\nOutline\n- Introduction\nIntroduction\n- Basic Blocks\n- Common Subexpression Elimination\nC\nP\nti\n- Copy Propagation\n- Dead Code Elimination\n- Algebraic Simplification\n- Summary\n\n,\nAlgebraic Simplification\ng\np\n- Applyy our knowledge from alggebra, number\npp\ng\ntheory etc. to simplify expressions\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n,\nAlgebraic Simplification\ng\np\n- Apply our knowledge from algebra, number\npp y\ng\ng\ntheory etc. to simplify expressions\n- Example\nExample\n- a + 0\na\n- a * 1\na\n- a / 1\na\n- a * 0\n- 0 - a\n-a\n- a + (-b)\na - b\n- -(-a)\na\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n( a)\na\n\n,\nAlgebraic Simplification\ng\np\n- Applyy our knowledge from alggebra, number\npp\ng\ntheory etc. to simplify expressions\n- Example\nExample\n- a true\na\n- a false\nfalse\n- a true\ntrue\n- a false\na\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n,\nAlgebraic Simplification\ng\np\n- Applyy our knowledge from alggebra, number\npp\ng\ntheory etc. to simplify expressions\n- Example\nExample\n- a ^ 2\na*a\n- a * 2\na + a\n- a * 8\na << 3\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nOpportunities for\nAlgebraic Simplification\n- After compiler expansion\nPrograms are more readable with full expressions\n- Programmers are lazy to simplify expressions\nIn the code\nAlgebraic Simplification\n- In the code\n- Programs are more readable with full expressions\n- Example: Array read A[8][12] will get expanded to\n- *(Abase + 4*(12 + 8*256)) which can be simplified\n- After other optimizations\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nUsefulness of Algebraic Simplification\ng\np\nR d\nth\nb\nf i\nt\nti\n- Reduces the number of instructions\n- Uses less expensive instructions\n- Enable other optimizations\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nImplementation\np\n- Not a data-flow optimization!\np\n- Find candidates that matches the\nsimplification rules and simplify the\nsimplification rules and simplify the\nexpression trees\n- Candidates may not be obvious\nCandidates may not be obvious\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n-\nImplementation\np\n- Not a data-flow optimization!\np\n- Find candidates that matches the\nsimplification rules and simplify the\nsimplification rules and simplify the\nexpression trees\n- Candidates may not be obvious\nCandidates may not be obvious\n- Example\na + b - a\n+\na + b a\na\n-\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\nb\na\n\n-\nUse knowledge about operators\ng\np\n- Commutative operators\nCommutative operators\n- a op b = b op a\n-\n- Associative operators\n- (a op b) op c = b op (a op c)\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nCanonical Format\n- Put expression trees into a canonical\np\nformat\n- Sum of multiplicands\np\n- Variables/terms in a canonical order\n- Example\nExample\n(a+3)*(a+8)*4 4*a*a+44*a+96\n- Section 12.3.1 of whale book talks about this\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEffects on the Numerical Stability\n- Some algebraic simpplifications mayy pproduce\nincorrect results\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEffects on the Numerical Stability\n- Some algebraic simpplifications mayy pproduce\nincorrect results\n- Example\nExample\n- (a / b)*0 + c\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEffects on the Numerical Stability\n- Some algebraic simpplifications mayy pproduce\nincorrect results\n- Example\nExample\n- (a / b)*0 + c\n- we can simplify this to\nwe can simplify this to cc\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nEffects on the Numerical Stability\n- Some algebraic simpplifications mayy pproduce\nincorrect results\n- Example\nExample\n- (a / b)*0 + c\n- we can simplify this to\nwe can simplify this to cc\n- But what about when b = 0\nshould be a exception but we'll get a result!\nshould be a exception, but we ll get a result!\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nead Code\nat o\nOutline\n- Introduction\nIntroduction\n- Basic Blocks\n- Common Subexpression Elimination\nC\nP\nti\n- Copy Propagation\n- Dead Code Elimination\n- Algebraic Simplification\n- Summary\n\nInteresting Properties\ng\np\n- Analysis and Transformation Algorithms\nS\nb li\nll\nSi\nl t\nE\nti\nf P\nSymbolically Simulate Execution of Program\n- CSE and Copy Propagation go forward\n- Dead Code Elimination goes backwards\nDead Code Elimination goes backwards\n- Transformations stacked\n- Group of basic transformations work together\n- Often, one transformation creates inefficient code that\nis cleaned up by following transformations\nis cleaned up by following transformations\n- Transformations can be useful even if original code\nmay not benefit from transformation\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\n=\n=\nOther Basic Block Transformations\n- Constant Propagation\np g\n- Strength Reduction\n- a<<2 = a*4; a+a+a = 3*a;\na<<2\na 4; a+a+a\n3 a;\n- Do these in unified transformation\nframework not in earlier or later phases\nframework, not in earlier or later phases\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nSummary\n- Basic block analyses and transformations\n- Symbbolilicalllly siimullate executiion offprogram\n- Forward (CSE, copy prop, constant prop)\n- Backward (Dead code elimination)\n- Stacked groups of analyses and transformations that work\ntogether\n- CSE introduces excess temporaries and copy\npystatements\n- Copy propagation often eliminates need to keep temporary\nvariables around\n- Dead code elimination removes useless code\n- Similar in spirit to many analyses and transformations that\noperate across basic blocks\nSaman Amarasinghe\n6.035\n(c)MIT Fall 1998\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT6_035S10_athena.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/f6561f807dd56e928fcfcd3961da42c3_MIT6_035S10_athena.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.035, Spring 2010\nHandout -- Athena, Tools\nTuesday, Feb 2\nThis document describes what you will need to know about Athena and Java tools for 6.035.\nAthena clusters\nIf you don't have an account on Athena, you should register for one immediately. Information can\nbe found at http://web.mit.edu/olh\nYou can work in any of the public Athena clusters. Type cview to see a list of clusters and available\nmachines.\nCommunication\nWe'll make course announcements via electronic mail. If you don't receive a message welcoming\nyou to the class mailing list within a week, tell the TA immediately.\nWe'll answer questions via email. You can mail your TA directly or reach the entire staff.\nFinding course files\nHandouts will be available on the course web site. Project directories, examples, and 6.035 programs\nare stored in /mit/6.035. The Java compiler, library, debugger, and associated programs and\ndocumentation are stored in the Java locker /mit/java.\nYou'll probably want to add these lines to your .environment file:\nadd 6.035\nadd java_v1.6.0_18\nadd gnu\nadd sipb\nadd git\nadd eclipse-sdk\nThese commands attach the lockers and update your execution path to include the course software.\nIf you need to use different versions of java for other classes you can use the -ver switch.\njava -ver 1.6.0\n.....\njavac -ver 1.6.0 .....\netc.\nNote that the -ver must come before any other command line arguments.\n*Athena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\nWorking with Groups\nThe first project should be done individually. When the second project is assigned, the class will\nbe partitioned into groups of 3 or 4 students.\nEach group will be given a group locker that can be used to work on the project. There should be\nenough space in these lockers that you won't have any problems. Only group members and 6.035\nstaff will be able to access each group locker.\nJava Compiler\nWe'll be using Sun's JDK 1.6.0. It is available on the Sun and Linux Athena platforms. You can\nget a free version of the JDK from Sun's web site for other platforms (Windows, Mac). However,\nthe only officially supported platforms for this class are Sun and Linux, so we may not be able to\nhelp you if you run into problems with other platforms. Since Java is platform independent, you\ncan compile your final bytecodes on any platform.\nBelow we describe basic operation of JDK 1.6.0. For detailed information on JDK and Java API\n1.6.0, consult http://java.sun.com/.\nRunning JDK 1.6.0\nCompile the source file(s) using the Java compiler. Use the -g flag to create debuggable bytecodes.\n% javac dummy1.java dummy2.java\nIf compilation succeeds, the compiler creates a .class file (named ClassName.class) for each\npublic class defined. If compilation fails, the compiler lists compilation errors.\nYou must have no more than one public class defined in each of the source files, and the filename\nmust be exactly the same as the class name. You can define several private classes in one file,\nhowever the compiler will still generate a separate .class file for each class.\nIn 6.035 we'll be writing Java applications (not applets). Each Java application must have a public\nclass that contains a public static void main(String[] args) method. To run the program\nsimply type\n% java MyProgram arg1 arg2 arg3\nwhere MyProgram is the name of the class with the main method, and arg1, arg2, arg3 are the\ncommand line arguments. These arguments are passed to the program in the args parameter to\nthe main method, and can be accessed as args[0], args[1], etc.\nJava Debugger\nIf you use the -g flag when you compile your source code, you will be able to debug your program\nusing the JDK debugger. Start the debugger using:\nAthena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\n% java -debug MyClass\nOnce inside the debugger, help will list all available commands. Here is a very limited list of the\nmost useful:\n- run <class> [args] -- Start execution of a loaded Java class\n- print <id> [id(s)] -- Print object or field\n- stop in <class id>.<method> -- Set a breakpoint in a <method>\n- cont -- Continue execution to the next break point.\n- locals -- Print all local variables in current stack frame\n- help -- Displays the list of recognized commands with descriptions\nAnt\nYou are required to use Apache Ant to build your projects, and to provide a build.xml the TA\ncan use to create bytecodes from your source files.\nAnt is a java-based build tool that strives\nto be platform independent.\nAnt is much like the familiar Make tools in that it resolves the\ndependencies necessary to perform a task. However, Ant is not shell-based. Project configuration\nfiles are written in hierarchical xml and Ant is extended by implementing java classes. Please visit\nhttp://ant.apache.org/ for more information on Ant. The handout describing the Scanner and\nParser phase of the project will include a more detailed description of the build system.\nAnt is in the sipb locker on athena: add sipb.\nRevision Control\nYou should use revision control on your projects to help manage changes to your source code base.\nYou'll be writing a lot of code for 6.035, and for many of you this will be the first time you'll be\nworking on a project of sufficient complexity to require source control.\nWe recommend git for revision control. Although the choice of other system (such as svn, bzr, or\nmercurial) is left up to each group.\nMore information on git can be found here: http://git-scm.com/documentation\nIt can be found in the git locker on athena: add git\nEclipse\nYou may also choose to use Eclipse for development. Eclipse is an open-source, extensible devel\nopment platform. Eclipse includes many features that ease Java development and debugging. If\nyou choose to use Eclipse, you should import your base project directory into into Eclipse and use\nthe build file to build your projects.\nPlease visit http://www.eclipse.org/ for more information on Eclipse. The handout describing\nthe Scanner and Parser phase of the project will include instructions for configuring Eclipse. If you\nencounter any difficulties while using Eclipse, please inform the TA.\nEclipse is in the eclipse-sdk locker on athena: add eclipse-sdk\nAthena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\n\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT6_035S10_decaf.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/1b21d612e072d1aad797f040a8bfdb6b_MIT6_035S10_decaf.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.035, Spring 2010\nHandout -- Decaf Language\nTuesday, Feb 2\nThe project for the course is to write a compiler for a language called Decaf. Decaf is a simple\nimperative language similar to C or Pascal.\nLexical Considerations\nAll Decaf keywords are lowercase. Keywords and identifiers are case-sensitive. For example, if is a\nkeyword, but IF is a variable name; foo and Foo are two different names referring to two distinct\nvariables.\nThe reserved words are:\nboolean break callout class continue else false for if int return true void\nNote that Program (see below) is not a keyword, but an identifier with a special meaning in\ncertain circumstances.\nComments are started by // and are terminated by the end of the line.\nWhite space may appear between any lexical tokens. White space is defined as one or more spaces,\ntabs, page and line-breaking characters, and comments.\nKeywords and identifiers must be separated by white space, or a token that is neither a keyword\nnor an identifier. For example, thisfortrue is a single identifier, not three distinct keywords. If a\nsequence begins with an alphabetic character or an underscore, then it, and the longest sequence\nof characters following it forms a token.\nString literals are composed of hcharis enclosed in double quotes. A character literal consists of a\nhchari enclosed in single quotes.\nNumbers in Decaf are 32 bit signed. That is, decimal values between -2147483648 and 2147483647.\nIf a sequence begins with 0x, then these first two characters and the longest sequence of characters\ndrawn from [0-9a-fA-F] form a hexadecimal integer literal. If a sequence begins with a decimal\ndigit (but not 0x), then the longest prefix of decimal digits forms a decimal integer literal. Note\nthat range checking is performed later. A long sequence of digits (e.g. 123456789123456789) is still\nscanned as a single token.\nA hchari is any printable ASCII character (ASCII values between decimal value 32 and 126, or\noctal 40 and 176) other than quote (\"), single quote ('), or backslash (\\), plus the 2-character\nsequences \"\\\"\" to denote quote, \"\\'\" to denote single quote, \"\\\\\" to denote backslash, \"\\t\" to\ndenote a literal tab, or \"\\n\" to denote newline.\n\nh\ni\n\nReference Grammar\nMeta-notation:\nhfooi\nmeans foo is a nonterminal.\nfoo\n(in bold font) means that foo is a terminal\ni.e., a token or a part of a token.\nh i\nx\nmeans zero or one occurrence of x, i.e., x is optional;\nnote that brackets in quotes ′ [ ′ ′ ] ′ are terminals.\nx ∗\nmeans zero or more occurrences of x.\nx + ,\na comma-separated list of one or more x's.\nn o\nlarge braces are used for grouping;\nnote that braces in quotes ′{′ ′}′ are terminals.\n|\nseparates alternatives.\n′\n′\n⟨program⟩\n→\nclass Program\n{ ′\n⟨field decl⟩ ∗ ⟨method decl⟩ ∗\n} ′\n⟨field decl⟩\n→\n⟨type⟩\n⟨id⟩| ⟨id⟩\n′ [ ′ ⟨int literal⟩ ′ ] ′\n+ ,\n;\n\n+\n⟨method decl⟩\n→\n⟨type⟩| void ⟨id⟩ (\n⟨type⟩⟨id⟩\n,\n) ⟨block⟩\n⟨block⟩\n→\n′ { ′\n⟨var decl⟩ ∗ ⟨statement⟩ ∗\n′ } ′\n⟨var decl⟩\n→\n⟨type⟩⟨id⟩+ ,\n;\n⟨type⟩\n→\nint | boolean\n⟨statement⟩\n→\n⟨location⟩⟨assign op⟩⟨expr⟩\n;\n|\n⟨method call⟩\n;\n|\nif ( ⟨expr⟩ ) ⟨block⟩ else ⟨block⟩\n|\nfor ⟨id⟩ = ⟨expr⟩ , ⟨expr⟩⟨block⟩\n|\nreturn ⟨expr⟩\n;\n|\nbreak\n;\n|\ncontinue\n;\n|\n⟨block⟩\n⟨assign op⟩\n→\n=\n|\n+=\n|\n-=\n⟨method call⟩\n→\n⟨method name⟩ (\n⟨expr⟩+ ,\n)\n|\ncallout ( ⟨string literal⟩ , ⟨callout arg⟩+ ,\n)\n⟨method name⟩\n→\n⟨id⟩\n⟨location⟩\n→\n⟨id⟩\n|\n⟨id⟩\n′ [ ′\n⟨expr⟩\n′ ] ′\n\n⟨expr⟩\n→\n⟨location⟩\n|\n⟨method call⟩\n|\n⟨literal⟩\n|\n⟨expr⟩⟨bin op⟩⟨expr⟩\n|\n- ⟨expr⟩\n|\n! ⟨expr⟩\n|\n( ⟨expr⟩ )\n⟨callout arg⟩\n→\n⟨expr⟩| ⟨string literal⟩\n⟨bin op⟩\n→\n⟨arith op⟩| ⟨rel op⟩| ⟨eq op⟩| ⟨cond op⟩\n⟨arith op⟩\n→\n+ | - | * | / | %\n⟨rel op⟩\n→\n< | > | <= | >=\n⟨eq op⟩\n→\n== | !=\n⟨cond op⟩\n→\n&& | ||\n⟨literal⟩\n→\n⟨int literal⟩| ⟨char literal⟩| ⟨bool literal⟩\n⟨id⟩\n→\n⟨alpha⟩⟨alpha num⟩ ∗\n⟨alpha num⟩\n→\n⟨alpha⟩| ⟨digit⟩\n⟨alpha⟩\n→\na | b | ... | z | A | B | ... | Z |\n⟨digit⟩\n→\n0 | 1 | 2 | ... | 9\n⟨hex digit⟩\n→\n⟨digit⟩| a | b | c | d | e | f | A | B | C | D | E | F\n⟨int literal⟩\n→\n⟨decimal literal⟩| ⟨hex literal⟩\n⟨decimal literal⟩\n→\n⟨digit⟩⟨digit⟩ ∗\n⟨hex literal⟩\n→\n0x ⟨hex digit⟩⟨hex digit⟩ ∗\n⟨bool literal⟩\n→\ntrue | false\n⟨char literal⟩\n→\n' ⟨char⟩ '\n⟨string literal⟩\n→\n\" ⟨char⟩ ∗ \"\nSemantics\nA Decaf program consists of a single class declaration for a class called Program. The class decla\nration consists of field declarations and method declarations. Field declarations introduce variables\nthat can be accessed globally by all methods in the program. Method declarations introduce func\ntions/procedures. The program must contain a declaration for a method called main that has no\nparameters. Execution of a Decaf program starts at method main.\n\nTypes\nThere are two basic types in Decaf -- int and boolean. In addition, there are arrays of integers\n(int [ N ]) and arrays of booleans (boolean [ N ]).\nArrays may be declared only in the global (class declaration) scope. All arrays are one-dimensional\nand have a compile-time fixed size. Arrays are indexed from 0 to N -1, where N > 0 is the size\nof the array. The usual bracket notation is used to index arrays. Since arrays have a compile-time\nfixed size and cannot be declared as parameters (or local variables), there is no facility for querying\nthe length of an array variable in Decaf.\nScope Rules\nDecaf has simple and quite restrictive scope rules. All identifiers must be defined (textually) before\nuse. For example:\n- a variable must be declared before it is used.\n- a method can be called only by code appearing after its header. (Note that recursive methods\nare allowed.)\nThere are at least two valid scopes at any point in a Decaf program: the global scope, and the\nmethod scope. The global scope consists of names of fields and methods introduced in the (single)\nProgram class declaration. The method scope consists of names of variables and formal parameters\nintroduced in a method declaration. Additional local scopes exist within each hblocki in the code;\nthese can come after if or for statements, or inserted anywhere a hstatementi is legal. An identifier\nintroduced in a method scope can shadow an identifier from the global scope. Similarly, identifiers\nintroduced in local scopes shadow identifiers in less deeply nested scopes, the method scope, and\nthe global scope.\nVariable names defined in the method scope or a local scope may shadow method names in the\nglobal scope. In this case, the identifier may only be used as a variable until the variable leaves\nscope.\nNo identifier may be defined more than once in the same scope. Thus field and method names must\nall be distinct in the global scope, and local variable names and formal parameters names must be\ndistinct in each local scope.\nLocations\nDecaf has two kinds of locations: local/global scalar variables and (global) array elements. Each\nlocation has a type. Locations of types int and boolean contain integer values and boolean values,\nrespectively. Locations of types int [ N ] and boolean [ N ] denote array elements. Since\narrays are statically sized in Decaf, arrays may be allocated in the static data space of a program\nand need not be allocated on the heap.\nEach location is initialized to a default value when it is declared. Integers have a default value\nof zero, and booleans have a default value of false. Local variables must be initialized when the\ndeclaring scope is entered. Array elements are initialized when the program starts.\n\nAssignment\nAssignment is only permitted for scalar values.\nFor the types int and boolean, Decaf uses\nvalue-copy semantics, and the assignment hlocationi = hexpri copies the value resulting from the\nevaluation of hexpri into hlocationi.\nThe hlocationi += hexpri assignment increments the value\nstored in hlocationi by hexpri, and is only valid for both hlocationi and hexpri of type int. The\nhlocationi -= hexpri assignment decrements the value stored in hlocationi by hexpri, and is only\nvalid for both hlocationi and hexpri of type int.\nThe hlocationi and the hexpri in an assignment must have the same type. For array types, hlocationi\nand hexpri must refer to a single array element which is also a scalar value.\nIt is legal to assign to a formal parameter variable within a method body. Such assignments affect\nonly the method scope.\nMethod Invocation and Return\nMethod invocation involves (1) passing argument values from the caller to the callee, (2) executing\nthe body of the callee, and (3) returning to the caller, possibly with a result.\nArgument passing is defined in terms of assignment: the formal arguments of a method are con\nsidered to be like local variables of the method and are initialized, by assignment, to the values\nresulting from the evaluation of the argument expressions. The arguments are evaluated from left\nto right.\nThe body of the callee is then executed by executing the statements of its method body in sequence.\nA method that has no declared result type can only be called as a statement, i.e., it cannot be\nused in an expression. Such a method returns control to the caller when return is called (no result\nexpression is allowed) or when the textual end of the callee is reached.\nA method that returns a result may be called as part of an expression, in which case the result of\nthe call is the result of evaluating the expression in the return statement when this statement is\nreached. It is illegal for control to reach the textual end of a method that returns a result.\nA method that returns a result may also be called as a statement. In this case, the result is ignored.\nControl Statements\nif\nThe if statement has the usual semantics. First, the hexpri is evaluated. If the result is true, the\ntrue arm is executed. Otherwise, the else arm is executed, if it exists. Since Decaf requires that\nthe true and else arms be enclosed in braces, there is no ambiguity in matching an else arm with\nits corresponding if statement.\nfor\nThe for statement is similar to a do loop in Fortran. The hidi is the loop index variable and it\nshadows a variable of the same name declared in an outer scope if one exists. The loop index\n\nvariable declares an integer variable whose scope is limited to the body of the loop. The first hexpri\nis the initial value of the loop index variable and the second hexpri is the ending value of the loop\nindex variable. Each of these expressions are evaluated once, just prior to reaching the loop for\nthe first time. Each expression must evaluate to an integer value. The loop body is executed if the\ncurrent value of the index variable is less than the ending value. After an execution of the loop\nbody, the index variable in incremented by 1, and the new value is compared to the ending value\nto decide if another iteration should execute.\nExpressions\nExpressions follow the normal rules for evaluation. In the absence of other constraints, operators\nwith the same precedence are evaluated from left to right. Parentheses may be used to override\nnormal precedence.\nA location expression evaluates to the value contained by the location.\nMethod invocation expressions are discussed in Method Invocation and Return. Array operations\nare discussed in Types. I/O related expressions are discussed in Library Callouts.\nInteger literals evaluate to their integer value. Character literals evaluate to their integer ASCII\nvalues, e.g., 'A' represents the integer 65. (The type of a character literal is int.)\nThe arithmetic operators (harith opi and unary minus) have their usual precedence and meaning,\nas do the relational operators (hrel opi). % computes the remainder of dividing its operands.\nRelational operators are used to compare integer expressions. The equality operators, == and !=\nare defined for int and boolean types only, can be used to compare any two expressions having\nthe same type. (== is \"equal\" and != is \"not equal\").\nThe result of a relational operator or equality operator has type boolean.\nThe boolean connectives && and || are interpreted using short circuit evaluation as in Java. The\nside-effects of the second operand are not executed if the result of the first operand determines the\nvalue of the whole expression (i.e., if the result is false for && or true for ||).\nOperator precedence, from highest to lowest:\nOperators\nComments\n-\nunary minus\n!\nlogical not\n* / %\nmultiplication, division, remainder\n+\naddition, subtraction\n< <= >= >\nrelational\n== !=\nequality\n&&\nconditional and\n||\nconditional or\nNote that this precedence is not reflected in the reference grammar.\n\nh\ni\nLibrary Callouts\nDecaf includes a primitive method for calling functions provided in the runtime system, such as the\nstandard C library or user-defined functions.\nThe primitive method for calling functions is:\nint callout (hstring literali,\nhcallout argi+ , ) -- the function named by the initial\nstring literal is called and the arguments supplied are passed to it.\nExpressions of\nboolean or integer type are passed as integers; string literals or expressions with array\ntype are passed as pointers.\nThe return value of the function is passed back as an\ninteger. The user of callout is responsible for ensuring that the arguments given match\nthe signature of the function, and that the return value is only used if the underlying\nlibrary function actually returns a value of appropriate type. Arguments are passed to\nthe function in the system's standard calling convention.\nIn addition to accessing the standard C library using callout, an I/O function can be written in\nC (or any other language), compiled using standard tools, linked with the runtime system, and\naccessed by the callout mechanism.\nSemantic Rules\nThese rules place additional constraints on the set of valid Decaf programs besides the constraints\nimplied by the grammar. A program that is grammatically well-formed and does not violate any\nof the following rules is called a legal program. A robust compiler will explicitly check each of\nthese rules, and will generate an error message describing each violation it is able to find. A robust\ncompiler will generate at least one error message for each illegal program, but will generate no\nerrors for a legal program.\n1. No identifier is declared twice in the same scope.\n2. No identifier is used before it is declared.\n3. The program contains a definition for a method called main that has no parameters (note\nthat since execution starts at method main, any methods defined after main will never be\nexecuted).\n4. The hint literali in an array declaration must be greater than 0.\n5. The number and types of arguments in a method call must be the same as the number and\ntypes of the formals, i.e., the signatures must be identical.\n6. If a method call is used as an expression, the method must return a result.\n7. A return statement must not have a return value unless it appears in the body of a method\nthat is declared to return a value.\n8. The expression in a return statement must have the same type as the declared result type\nof the enclosing method definition.\n\n9. An hidi used as a hlocationi must name a declared local/global variable or formal parameter.\n10. For all locations of the form hidi[hexpri]\n(a) hidi must be an array variable, and\n(b) the type of hexpri must be int.\n11. The hexpri in an if statement must have type boolean.\n12. The operands of harith opis and hrel opis must have type int.\n13. The operands of heq opis must have the same type, either int or boolean.\n14. The operands of hcond opis and the operand of logical not (!) must have type boolean.\n15. The hlocationi and the hexpri in an assignment, hlocationi = hexpri, must have the same type.\n16. The hlocationi and the hexpri in an incrementing/decrementing assignment, hlocationi += hexpri\nand hlocationi -= hexpri, must be of type int.\n17. The initial hexpri and the ending hexpri of for must have type int.\n18. All break and continue statements must be contained within the body of a for.\nRun Time Checking\nIn addition to the constraints described above, which are statically enforced by the compiler's\nsemantic checker, the following constraints are enforced dynamically: the compiler's code generator\nmust emit code to perform these checks; violations are discovered at run-time.\n1. The subscript of an array must be in bounds.\n2. Control must not fall off the end of a method that is declared to return a result.\nWhen a run-time error occurs, an appropriate error message is output to the terminal and the\nprogram terminates. Such error messages should be helpful to the programmer trying to find the\nproblem in the source program.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT6_035S10_overview.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/1739aa9ea1cacbb2fb623e31b15457c0_MIT6_035S10_overview.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.035, Spring 2010\nHandout -- Project Overview\nTuesday, Feb 2\nThis is an overview of the course project and how we'll grade it. You should not expect to un\nderstand all the technical terms, since we haven't yet covered them in class. We're handing it out\ntoday to give you some idea of the kind of project we're assigning, and to let you know the various\ndue dates. Additional handouts will provide the technical details of the project.\nThe first project (Scanner and Parser) will be done individually. Each students is expected to\nsubmit their own code and write-ups.\nFor subsequent projects, the class will be partitioned into groups of three or four students. You\nwill be allowed to choose your own partners as much as possible. Each group will write, in Java,\na compiler for a simple programming language.\nWe expect all groups to complete all phases\nsuccessfully. The start of the class is very fast-paced: do not fall behind!\nImportant Project Dates\nProject Name\nAssigned/Due\nDay\nScanner and Parser\nassigned:\nproject due:\nWednesday, Feb 3\nTuesday, Feb 16\nSemantic Checker\nassigned:\nproject due:\nTuesday, Feb 16\nMonday, Mar 1\nCode Generator\nassigned:\ndesign due:\nproject due:\nMonday, Mar 1\nWednesday, Mar 10\nTuesday, Mar 16\nData-flow Analysis\nassigned:\nproject due:\nTuesday, Mar 16\nThursday, Apr 1\nOptimizer\nassigned:\ndesign due:\ncheckpoint due:\nproject due:\nThursday, Apr 1\nThursday, Apr 15\nWednesday, Apr 28\nWednesday, May 12\nCompiler Derby\nheld on:\nThursday, May 13\nThe Project Segments\nDescriptions of the five parts of the compiler follow in the order that you will build them.\nScanner and Parser\nA Scanner takes a Decaf source file as an input and scans it looking for tokens. A token can be an\noperator (ex: \"*\" or \"[\"), a keyword (if or class), a literal (14 or 'c') a string (\"abc\") or an identifier.\nNon-tokens (such as white spaces or comments) are discarded. Bad tokens must be reported.\n\nA Parser reads a stream of tokens and checks to make sure that they conform to the language\nspecification. In order to pass this check, the input must have all the matching braces, semicolons,\netc. Types, variable names and function names are not verified. The output can be either a user-\ngenerated structure or a simple parse-tree that then needs to be converted to a easier-to-process\nstructure.\nWe will provide you with a grammar of the language, which you will need to separate into a scanner\nspecification and a parser specification. While the grammar given should be pretty close to the\nfinal grammar you use, you will need to make some changes. You will use a tool called ANTLR\nto generate a scanner and a parser. The generated code will automatically perform most error\nchecking and reporting for you.\nSemantic Checker\nThis part checks that various non-context free constraints, e.g., type compatibility, are observed.\nWe'll supply a complete list of the checks. It also builds a symbol table in which the type and\nlocation of each identifier is kept.\nThe experience from past years suggests that many groups\nunderestimate the time required to complete the static semantic checker, so you should pay special\nattention to this deadline.\nIt is important that you build the symbol table, since you won't be able to build the code generator\nwithout it. However, the completeness of the checking will not have a major impact on subsequent\nstages of the project. At the end of this project the front-end of your compiler is complete and you\nhave designed the intermediate representation (IR) that will be used by the rest of the compiler.\nCode Generation\nIn this assignment you will create a working compiler by generating unoptimized x86-64 assembly\ncode from the intermediate format you generated in the previous assignment. Because you have rel\natively little time for this project you should concentrate on correctness and leave any optimization\nhacks out, no matter how simple.\nThe steps of code generation are as follows: first, the rich semantics of Decaf are broken-down into\na simple intermediate representation. For example, constructs such as loops and conditionals are\nexpanded to code segments with simple comparison and branch instructions. Next, the intermediate\nrepresentation is matched with the Application Binary Interface, i.e., the calling convention and\nregister usage. Then, the corresponding x86-64 machine code is generated. Finally, the code, data\nstructures, and storage are laid-out in the assembly format. We will provide a description of the\nobject language. The object code created using this interface will then be run on a testing machine\n(more on the testing machines soon).\nThis phase requires a Project Design Document and a Project Checkpoint, which is due on the\nThursday prior to the deadline (see the Important Project Dates Section). The group has to provide\ntwo parts. First, a design document describing your design. This will be reviewed by the TA and\nfeedback will be provided.\nThis document will also count towards the project grade.\nSecond,\nthe group has to submit a checkpoint of the implementation. The checkpoint exists to strongly\nencourage you to start working on the project early. If you get your project working at the end,\nthe checkpoint will have little effect. However, if your group is unable to complete the project, the\ncheckpoint submission has a critical role in your grade. If we determine that your group did not\ndo a substantial amount of work before the checkpoint, you will be severely penalized.\n\nData Flow Analysis\nThis assignment phase consists of building a data-flow framework to help optimize the code gen\nerated by your compiler. For this phase, you are required to implement the data-flow framework\nand a single data-flow optimization pass to test the framework. This framework will be used in the\nOptimizer project to build data-flow optimization passes.\nWe will provide a description of the framework and the required optimization be implemented in a\nlater handout.\nOptimizer\nThe final project is a substantial open-ended project. In this project your team's task is to generate\noptimized code for programs so that they will be correctly executed in the shortest possible time.\nThere are multitude of different optimizations you can implement to improve the generated code.\nYou can perform data-flow optimizations such as constant propagation, common sub-expression\nelimination, copy propagation, loop invariant code motion, unreachable code elimination, dead\ncode elimination and many others using the framework created in the previous segment.\nYou\ncan also implement instruction scheduling, register allocation, peephole optimizations and even\nparallelization across the cores of the target architecture.\nIn order to identify and prioritize optimizations, you will be provided with a benchmark suite\nof three simple applications. Your task is to analyze these programs, perhaps hand optimizing\nthese programs, to identify which optimizations will have the highest performance impact. Your\nwrite-up needs to clearly describe the process you went through to identify the optimizations you\nimplemented and justify them.\nThe last class will be the \"Compiler Derby\" at which your group will compete against other groups\nto identify the compiler that produces the fastest code. The application used for the Derby will be\nprovided to the groups one day before the Derby. This is done in order for your group to debug\nthe compiler and get it working on this program. However, you are forbidden from adding any\napplication-specific hacks to make this specific program run faster.\nGrading\nMake sure you understand this section so you won't be penalized for trivial oversights. The entire\nproject is worth 60% of your 6.035 grade.\nThe grade is divided between the segments in the\nfollowing breakdown:\nScanner-Parser\n5%\nSemantic Checker\n7.5%\nCode Generator\n10%\nData-flow Analyzer\n7.5%\nOptimizer\n30%\nThe remaining 40% comes from three quizzes, each worth 10%, and 20 mini-quizzes at the beginning\nof every lecture, each worth 0.5%.\nThe first 4 phases of the project (Scanner-Parser, Semantic Checking, Code Generation, and Data\nflow Analysis) will be graded as follows:\n\n- (25%) Design and Documentation (subjective). Your score will be based on the quality of\nyour design, clarity of your design documentation, and incisiveness of your discussion on\ndesign alternatives and issues. Some parts of the project require additional documentation.\nAlways read the What to Hand In section. For the segments that require a Project Design\nDocument, 10% will be assigned to the design document and 15% to the final write-up.\n- (75%) Implementation (objective).\nPoints will be awarded for passing specific test cases.\nEach project will include specific instructions for how your program should execute and what\nthe output should be. If you have good reasons for doing something differently, consult your\nTA first.\n- Public Tests (25%)\n- Hidden Tests (50%)\nThe Optimizer project phase will be graded differently:\n- (20%) Design and Documentation, with particular attention given to your description of the\noptimization selection process.\n- (40%) Implementation. As each group implements different optimizations, the only public test\nis the generation of correct results for the benchmark suite and the Derby program (10%).\nThe hidden tests will check for overtly optimistic optimizations and incorrect handling of\nprograms (30%).\n- (40%) Derby Performance.\nThe formula for translating the running time of the program\ncompiled by your compiler into a grade will be announced later.\nAll members of a group will receive the same grade on each part of the project unless a problem\narises, in which case you should contact your TA as soon as possible.\nWhat To Hand In\nFor each phase, you are required to submit your project write-up, complete sources (including all\nfiles needed to build your project), and a compiled .jar file that the TA can use to run the various\ntests. These sources should be places in a .tar.gz archive.\nThe first project (scanner/parser) should be completed and submitted individually through stellar.\nProjects 2 through 5 will be done in groups. Each group will be given access to shared storage\nspace in the 6.035 course locker on athena. More information about submitting group projects will\nbe provided when the second project is assigned.\nCommand-line Interface\nYour compiler should have the following command line interface.\njavac -jar Compiler.jar [option | filename...]\n*Athena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n*\n\n-o <outname>\nWrite output to <outname>\n-target <stage>\n<stage> is one of scan, parse, inter, or assem\nbly. Compilation should proceed to the given\nstage.\n-opt [optimization...] Perform the listed optimizations.\nall stands for all supported optimizations.\n-<optimization>\nremoves\noptimizations\nfrom the list.\n-debug\nPrint debugging information. If this option is\nnot given, there should be no output to the\nscreen on successful compilation.\nTable 1: Compiler Command-line Arguments\nThe command line arguments you must implement are listed in Table 1. Exactly one filename\nshould be provided, and it should not begin with a '-'. The filename must not be listed after the\n-opt flag, since it will be assumed to be an optimization.\nThe default behavior is to compile as far as the current assignment of the project and produce a\nfile with the extension changed based on either the target or \".out\" if the target is unspecified.\nBy default, no optimizations are performed. The list of optimization names will be provided in the\noptimization assignments.\nWe have provided a class, CLI, which is sufficient to implement this interface. It also returns a\nVector of arguments it did not understand which can be used to add features. The TAs will not\nuse any extra features you add for grading. However, you can tell us which, if any, to use for the\ncompiler derby. You may wish to provide a \"-O\" flag, which turns on the optimizations you like.\nDocumentation / Write-up\nDocumentation should included in your source archive. It should be clear, concise and readable.\nFancy formatting is not necessary; plain text is perfectly acceptable.\nYou are welcome to do\nsomething more extravagant, but it will not help your grade.\nYour documentation must include the following parts:\n1. A brief description of how your group divided the work. This will not affect your grade; it\nwill be used to alert the TAs to any possible problems. (Projects 2 through 5 only.)\n2. A list of any clarifications, assumptions, or additions to the problem assigned. The project\nspecifications are fairly broad and leave many of the decisions to you. This is an aspect of\nreal software engineering. If you think major clarifications are necessary, consult your TA.\n3. An overview of your design, an analysis of design alternatives you considered, and key design\ndecisions.\nBe sure to document and justify all design decisions you make.\nAny decision\n\naccompanied by a convincing argument will be accepted. If you realize there are flaws or\ndeficiencies in your design late in the implementation process, discuss those flaws and how\nyou would have done things differently. Also include any changes you made to previous parts\nand why they were necessary.\n4. A brief description of interesting implementation issues. This should include any non-trivial\nalgorithms, techniques, and data structures. It should also include any insights you discovered\nduring this phase of the project.\n5. Only for scanner and parser: A listing of commented source code relevant to this part of\nthe project. For later stages, the TAs can print out source code if needed. Do not resubmit\nsource code from other parts of the project, even if minor changes have been made.\n6. A list of known problems with your project, and as much as you know about the cause. If\nyour project fails a provided test case, but you are unable to fix the problem, describe your\nunderstanding of the problem. If you discover problems in your project in your own testing\nthat you are unable to fix, but are not exposed by the provided test cases, describe the\nproblem as specifically as possible and as much as you can about its cause. If this causes your\nproject to fail hidden test cases, you may still be able to receive some credit for considering\nthe problem. If this problem is not revealed by the hidden test cases, then you will not be\npenalized for it. It is to your advantage to describe any known problems with your project;\nof course, it is even better to fix them.\nIt is entirely up to you to determine how to test your project. The thoroughness of you testing will\nbe reflected in your performance on the hidden test cases.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT6_035S10_proj01.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/588e86d6822c38812e660fda322a18d4_MIT6_035S10_proj01.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.035, Spring 2010\nHandout -- Scanner-Parser Project\nWednesday, Feb 3\nDUE: Tuesday, Feb 16\nThis project consists of two segments: lexical analysis (scanning) and syntactic analysis (parsing).\nPreliminaries\nIn this section we will describe the infrastructure that is provided for the project. You are encour\naged to use it, but you may also choose to ignore it and design your infrastructure from scratch.\nThe skeleton is located in /mit/6.035/provided/skeleton.\nProvided Infrastructure\nA skeleton compiler infrastructure has been provided that includes a typical compiler directory\norganization, the ANTLR parser and scanner generator, and an Apache Ant build system. The\nJava package name for the sources provided is decaf.\nThe directory structure and the provided files are as follows:\n.\n|-- bin\n|-- build.xml\n|-- lib\n|\n|\n|\n'-- antlr.jar\n'-- src\n|\n|-- decaf\n|\n|\n|\n|-- Lexer.g\n|\n|-- Parser.g\n|\n'-- Main.java\n'-- java6035\n|\n'-- tools\n|\n'-- CLI\n|\n'-- CLI.java\nThe lib directory includes libraries that are needed during a run of your compiler; right now it\ncontains the ANTLR tool.\nThe bin directory contains the tools (executables) needed to com\npile your compiler.\nHowever, since ANTLR uses the same binary as a tool and as a library,\nand we already included it in the lib directory, bin director is empty.\nbuild.xml is the ant\nbuild file for the infrastructure. The src directory contains all your source code for the compiler.\nsrc/decaf/Parser.g is a skeleton parser grammar and src/decaf/Lexer.g is a skeleton scanner\n\ngrammar. src/decaf/Main.java is the skeleton driver and src/java6035/tools/CLI/CLI.java\nis the command-line interface library.\nTo access and build the provided infrastructure, you must add the following lockers to your file\nsystem.\nadd 6.035\nadd java_v1.6.0_18\nadd gnu\nadd sipb\nadd git\nadd eclipse-sdk\nThe eclipse-sdk locker is optional and it adds the eclipse IDE. No changes to your $CLASSPATH vari\nable are required, but due to an interaction between sipb and java v1.6.0 18, we recommend that\nyou set an environment variable JAVA HOME to /afs/athena.mit.edu/software/java v1.6.0 18/;\nall the classes and jar files required for compilation are included by the Ant build file (see next\nSection).\nAnt Build System\nPlease review the Ant build file, build.xml, that is provided. For more information on Ant, please\nvisit:\nhttp://ant.apache.org/\nTo build the system, execute ant from the root directory of the system.\nThe build file includes tasks for running ANTLR on your scanner and parser grammars, compiling\nthe sources, packaging the compiler into a jar file, and cleaning the infrastructure. The default\nrule is for complete compilation and jar creation. The build file creates three directories during\ncompilation: classes, java, and dist. The classes directory contains all .class files created\nduring compilation. The java directory contains all the generated sources for the compiler (from\nscanner and parser grammars). The dist directory contains the jar archive file for the compiler\nand any other runtime libraries that are necessary for running the compiler. A clean will delete\nthese three directories. If you are using revision control, you should not add these directories to\nyour repository.\nGetting Started\nA good place to start would be to create a copy of the provided skeleton and create a git repository\nto track your changes. This can be accomplished with the following commands on athena:\n# initial setup:\nadd 6.035 java_v1.6.0_18 gnu sipb git\ncp -r /mit/6.035/provided/skeleton ~/Private/6.035\ncd ~/Private/6.035\ngit init\n*Athena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\n# save all changes into git repository:\ngit add .\ngit commit -m \"initial commit\"\n# build:\nant\n# run scanner:\njava -jar dist/Compiler.jar -target scan -debug /mit/6.035/provided/scanner/char1\n# run parser:\njava -jar dist/Compiler.jar -target parse -debug /mit/6.035/provided/parser/legal-01\nScanner\nYour scanner must be able to identify tokens of the Decaf language, the simple imperative language\nwe will be compiling in 6.035. The language is described in the Decaf Language Handout. Your\nscanner should note illegal characters, missing quotation marks, and other lexical errors with rea\nsonable error messages. The scanner should find as many lexical errors as possible, and should be\nable to continue scanning after errors are found. The scanner should also filter out comments and\nwhitespace not in string and character literals.\nYou will not be writing the scanner from scratch. Instead, you will generate the scanner using\nANTLR. This program reads in an input specification of regular expression-like syntax (grammar)\nand creates a Java program to scan the specified language. More information on ANTLR (including\nthe manual and examples) can be on the web at:\nhttp://antlr2.org/doc/index.html\nhttp://www.antlr.org/wiki/display/CS652/CS652+Home\nTo get you started, we have provided a template in\n/mit/6.035/provided/skeleton/src/decaf/Lexer.g\nIf you chose to work from this skeleton, you must complete the existing ANTLR rules and add new\nones for your scanner.\nANTLR generated scanners throw exceptions when they encounter an error. Each exception in\ncludes a text of a potential error message, and the provided skeleton driver prints them out. You\nare free to use use the messages provided by ANTLR, if you have verified that they make sense\nand are specific enough.\nANTLR is invoked by the antlr task of the Ant build file. The generated files, DecafLexer.java,\netc, are placed in the java/decaf directory by the task. Note that ANTLR merely generates a\nJava source file for a scanner class; it does not compile or even syntactically check its output. Thus,\ntypos or syntactic errors in the scanner grammar file will be propagated to the output.\n\nAn ANTLR generated scanner produces a string of tokens as its output.\nEach token has the\nfollowing fields:\ntype the integer type of the token\ntext the text of the token\nline the line in which the token appears\ncol\nthe column in which the token appears\nEvery distinguishable terminal in your Decaf grammar will have an automatically generated unique\ninteger associated with it so that the parser can differentiate them. These values are created from\nyour scanner grammar and are stored in the *TokenTypes.java file created by ANTLR.\nParser\nYour parser must be able to correctly parse programs that conform to the grammar of the Decaf\nlanguage. Any program that does not conform to the language grammar must be flagged with at\nleast one error message.\nAs mentioned, we will be using the ANTLR LL(k) parser generator, same tool as for the Scanner.\nYou will need to transform the reference grammar in Decaf Language Handout into a grammar\nexpressed in the ANTLR grammar syntax. Be careful with checking your spelling, as ANTLR does\nmatch rule uses to declarations.\nYour parser does not have to, and should not, recognize context-sensitive errors e.g., using an\ninteger identifier where an array identifier is expected. Such errors will be detected by the static\nsemantic checker. Do not try to detect context-sensitive errors in your parser. However, you might\nneed to create syntactic actions in your parser to check for some context-free errors.\nYou might want to look at Section 3 in the \"Tiger\" book, or Sections 4.3 and 4.8 in the Dragon\nbook for tips on getting rid of shift/reduce and reduce/reduce conflicts from your grammar. You\ncan tell ANTLR to print out the parse states (useful for resolving conflicts) by adding trace=\"yes\"\nto the ANTLR target (please see the build file).\n\nWhat to Hand In\nProjects should be submitted electronically through stellar.\nYou should submit a gzipped tar\nfile named LASTNAME-parser.tar.gz, where LASTNAME is replaced with your last name. The\ncontents of this file should follow the following structure:\nLASTNAME-parser.tar.gz\n|\n'-- LASTNAME-parser\n|\n|-- code\n|\n|\n|\n...\n(full source code, can build by running 'ant')\n|\n|-- doc\n|\n|\n|\n...\n(write-up, described in project overview handout)\n|\n'-- dist\n|\n'-- Compiler.jar\n(compiled output, for automated testing)\nIt is expected that most (or all) students will use Java for their project, and thus should adhere\nto the above format. If you elect to use a language other than Java, you must provide a wrapper\nscript ./run.sh (runnable with bash) in the main directory that calls your code and accepts the\nsame arguments described in the project overview handout.\nAny additional dependencies and\ninstructions to build your code should be included in the documentation.\nScanner output format\nWhen -target scan is specified, the output of your compiler should be a scanned listing of the\nprogram with one row for each token in the input. Each line will contain the following information:\nthe line number (starting at 1) on which the token appears, the type of the token (if applicable), and\nthe token's text. Please print only the following strings as token types (as applicable): CHARLITERAL,\nINTLITERAL, BOOLEANLITERAL, STRINGLITERAL and IDENTIFIER.\nFor STRINGLITERAL and CHARLITERAL, the text of the token should be the text, as appears in the\noriginal program, including the quotes and any escaped characters.\nEach error message should be printed on its own line, before the erroneous token, if any. Such\nmessages should include the file name, line and column number on which the erroneous token\nappears.\nHere is an example table corresponding to print(\"Hello, World!\");:\n1 IDENTIFIER print\n1 (\n1 STRINGLITERAL \"Hello, World!\"\n1 )\n1 ;\nYou are given both a set of test files on which to test your scanner and the expected output for\nthese files (see next Section). The TA requests that the output of your scanner matches\nthe provided output exactly on all files without errors (successful exit status of the diff\ncommand). The TA would like to automate the grading process as much as possible.\n\nParser output format\nWhen -target parse is specified, any syntactically incorrect program should be flagged with at\nleast one error message, and the program should exit with a non-zero value (see System.exit()).\nMultiple error messages may be printed for programs with multiple syntax errors that are amenable\nto error recovery. Given a syntactically valid program, your parser should produce no output, and\nexit with the value zero (success). The exact format for parse error messages is not stipulated.\nProvided Test Cases and Expected Output\nThe provided test cases for scanning and parsing can be found in:\n/mit/6.035/provided/scanner\n/mit/6.035/provided/parser\nThe expected output for each scanner test can be found in:\n/mit/6.035/provided/scanner/output\nWe will test your scanner/parser on these and a set of hidden tests.\nYou will receive points\ndepending on how many of these tests are passed successfully. In order to receive full credit, we\nalso expect you to complete the written portion of the project as described in the Project Overview\nHandout.\n\nA\nWhy we defer integer range checking until the next project\nWhen considering the problem of checking the legality of the input program, there is no fundamental\nseparation between the responsibilities of the scanner, the parser and the semantic checker. Often,\nthe compiler designer has the choice of checking a certain constraint in a particular phase, or even\nof dividing the checking across multiple phases. However, for pragmatic reasons, we have had to\ndivide the complete scan/parse/check unit into two parts simply to fit the course schedule better.\nAs a result, we will have to mandate certain details about your implementations that are not\nnecessarily issues of correctness. For example, one cannot completely check whether integer literals\nare within range without constructing a parse tree.\nConsider the input:\nx+-2147483648\nThis corresponds to a parse tree of:\n+\n/ \\\nx\n\n|\nINT(2147483648)\nWe cannot confirm in the scanner that the integer literal -2147483648 is within range, since it is\nnot a single token. Nor can we do this within the parser, since at this stage we are not constructing\nan abstract syntax tree. Only in the semantic checking phase, when we have an AST, are we able\nto perform this check, since it requires the unary minus operator to modify its argument if it is an\ninteger literal, as follows:\n+\n+\n/ \\\n/ \\\nx\n-\n---->\nx\nINT(-2147483648)\n|\nINT(2147483648)\nOf course, if the integer token was clearly out of range (e.g. 99999999999) the scanner could have\nrejected it, but this check is not required since the semantic phase will need to perform it later\nanyway.\nTherefore, rather than do some checking earlier and some later, we have decided that ALL integer\nrange checking must be deferred until the semantic phase. So, your scanner/parser must not try\nto interpret the strings of decimal or hex digits in an integer token; the token must simply retain\nthe string until the semantic phase.\nWhen printing out the token table from your scanner, do not print the value of an INTLITERAL\ntoken in decimal. Print it exactly as it appears in the source program, whether decimal or hex.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\n\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MIT6_035S10_proj02.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-035-computer-language-engineering-spring-2010/bfb4ef2135e8ca3b6fb5b523f43c974d_MIT6_035S10_proj02.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.035, Spring 2010\nHandout -- Semantic Analysis Project\nTuesday, Feb 16\nDUE: Monday, Mar 1\nExtend your compiler to find, report, and recover from semantic errors in Decaf programs. Most\nsemantic errors can be checked by testing the rules enumerated in the section \"Semantic Rules\" of\nDecaf Spec. These rules are repeated in this handout as well. However, you should read Decaf Spec\nin its entirety to make sure that your compiler catches all semantic errors implied by the language\ndefinition. We have attempted to provide a precise statement of the semantic rules. If you feel some\nsemantic rule in the language definition may have multiple interpretations, you should work with\nthe interpretation that sounds most reasonable to you and clearly list your assumptions in your\nproject documentation\nThis part of the project includes the following tasks:\n1. Create a high-level intermediate representation (IR) tree. You can do this either by instructing\nANTLR to create one for you, adding actions to your grammar to build a tree, or walking a\ngeneric ANTLR tree and building a tree on the way. The problem of designing an IR will be\ndiscussed in the lectures; some hints are given in the final section of this handout.\nWhen running in debug mode, your driver should pretty-print the constructed IR tree in\nsome easily-readable form suitable for debugging.\n2. Build symbol tables for the classes. (A symbol table is an environment, i.e. a mapping from\nidentifiers to semantic objects such as variable declarations. Environments are structured\nhierarchically, in parallel with source-level constructs, such as class-bodies, method-bodies,\nloop-bodies, etc.)\n3. Perform all semantic checks by traversing the IR and accessing the symbol tables. Note: the\nrun-time checks are not required for this assignment.\nWhat to Hand In\nFollow the directions given in project overview handout when writing up your project.\nYour\ndesign documentation should include a description of how your IR and symbol table structures are\norganized, as well as a discussion of your design for performing the semantic checks.\nEach group will be assigned an athena group and shared space in the course locker. Each group\nmust place their completed submission at:\n/mit/6.035/group/GROUP/submit/GROUP-semantics.tar.gz\nGroups may use:\n/mit/6.035/group/GROUP/\nas a place to collaborate and share code. It is recommended that you use revision control and place\nyour repositories in this shared space.\nSubmitted tarballs should have the following structure:\n*Athena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n.\n\nGROUPNAME-semantics.tar.gz\n|\n'-- GROUPNAME-semantics\n|\n|-- AUTHORS\n(list of students in your group, one per line)\n|\n|-- code\n|\n|\n|\n...\n(full source code, can build by running 'ant')\n|\n|-- doc\n|\n|\n|\n...\n(write-up, described in project overview handout)\n|\n'-- dist\n|\n'-- Compiler.jar\n(compiled output, for automated testing)\nYou should be able to run your compiler from the command line with:\njava -jar dist/Compiler.jar -target inter <filename>\nThe resulting output to the terminal should be a report of all errors encountered while compiling\nthe file. Your compiler should give reasonable and specific error messages (with line and column\nnumbers and identifier names) for all errors detected.\nIt should avoid reporting multiple error\nmessages for the same error. For example, if y has not been declared in the assignment statement\n\"x=y+1;\", the compiler should report only one error message for y, rather than one error message\nfor y, another error message for the +, and yet another error message for the assignment.\nAfter you implement the static semantic checker, your compiler should be able to detect and report\nall static (i.e., compile-time) errors in any input Decaf program, including lexical and syntax errors\ndetected by previous phases of the compiler. In addition, your compiler should not report any\nmessages for valid Decaf programs. However, we do not expect you to avoid reporting spurious\nerror messages that get triggered by error recovery. It is possible that your compiler might mistak\nenly report spurious semantic errors in some cases depending on the effectiveness of your parser's\nsyntactic error recovery.\nAs mentioned, your compiler should have a debug mode in which the IR and symbol table data\nstructures constructed by your compiler are printed in some form.\nThis can be run from the\ncommand line by\njava -jar dist/Compiler.jar -target inter -debug <filename>\nTest Cases\nThe test cases provided for this project are in:\n/mit/6.035/provided/semantics/\nRead the comments in the test cases to see what we expect your compiler to do. Points will be\nawarded based on how well your compiler performs on these and hidden tests cases. Complete\ndocumentation is also required for full credit.\n\nGrading Script\nAs with the previous project, we are providing you with the grading script we will use to test your\ncode (except for the write-up). This script only shows you results for the public test cases.\nThe script can be found on athena in the course locker:\n/mit/6.035/provided/gradingscripts/p2grader.py\nThe script takes your tarball as the only arg:\n/mit/6.035/provided/gradingscripts/p2grader.py GROUPNAME-parser.tar.gz\nOr it works on the extracted directory:\n/mit/6.035/provided/gradingscripts/p2grader.py GROUPNAME-parser/\nPlease test your submission against this script. It may help you debug your code and it will help\nmake the grading process go more smoothly.\nSemantic Rules\nThese rules place additional constraints on the set of valid Decaf programs besides the constraints\nimplied by the grammar. A program that is grammatically well-formed and does not violate any\nof the following rules is called a legal program. A robust compiler will explicitly check each of\nthese rules, and will generate an error message describing each violation it is able to find. A robust\ncompiler will generate at least one error message for each illegal program, but will generate no\nerrors for a legal program.\n1. No identifier is declared twice in the same scope.\n2. No identifier is used before it is declared.\n3. The program contains a definition for a method called main that has no parameters (note\nthat since execution starts at method main, any methods defined after main will never be\nexecuted).\n4. The hint literali in an array declaration must be greater than 0.\n5. The number and types of arguments in a method call must be the same as the number and\ntypes of the formals, i.e., the signatures must be identical.\n6. If a method call is used as an expression, the method must return a result.\n7. A return statement must not have a return value unless it appears in the body of a method\nthat is declared to return a value.\n8. The expression in a return statement must have the same type as the declared result type\nof the enclosing method definition.\n9. An hidi used as a hlocationi must name a declared local/global variable or formal parameter.\n\n10. For all locations of the form hidi[hexpri]\n(a) hidi must be an array variable, and\n(b) the type of hexpri must be int.\n11. The hexpri in an if statement must have type boolean.\n12. The operands of harith opis and hrel opis must have type int.\n13. The operands of heq opis must have the same type, either int or boolean.\n14. The operands of hcond opis and the operand of logical not (!) must have type boolean.\n15. The hlocationi and the hexpri in an assignment, hlocationi = hexpri, must have the same type.\n16. The hlocationi and the hexpri in an incrementing/decrementing assignment, hlocationi += hexpri\nand hlocationi -= hexpri, must be of type int.\n17. The initial hexpri and the ending hexpri of for must have type int.\n18. All break and continue statements must be contained within the body of a for.\nImplementation Suggestions\n- You will need to declare classes for each of the nodes in your IR. In many places, the hierarchy\nof IR node classes will resemble the language grammar. For example, a part of your inheritance\ntree might look like this (where indentation represents inheritance):\nabstract class Ir\nabstract class\nIrExpression\nabstract class\nIrLiteral\nclass\nIrIntLiteral\nclass\nIrBooleanLiteral\nclass\nIrCallExpr\nclass\nIrMethodCallExpr\nclass\nIrCalloutExpr\nclass\nIrBinopExpr\nabstract class\nIrStatement\nclass\nIrAssignStmt\nclass\nIrPlusAssignStmt\nclass\nIrBreakStmt\nclass\nIrContinueStmt\nclass\nIrIfStmt\nclass\nIrForStmt\nclass\nIrReturnStmt\nclass\nIrInvokeStmt\nclass\nIrBlock\nclass\nIrClassDecl\nabstract class\nIrMemberDecl\nclass\nIrMethodDecl\nclass\nIrFieldDecl\n.\n\n.\n.\nclass\nIrVarDecl\nclass\nIrType\nClasses such as these implement the abstract syntax tree of the input program. In its simplest\nform, each class is simply a tuple of its subtrees, for example:\npublic class IrBinopExpr extends IrExpression\n{\nprivate final int\noperator;\n|\nprivate final IrExpression lhs;\n+\nprivate final IrExpression rhs;\n/ \\\n}\nlhs\nrhs\nor:\npublic class IrAssignStmt extends IrStatement\n{\n:=\nprivate final IrLocation\nlhs;\n/ \\\nprivate final IrExpression rhs;\nlhs\nrhs\n}\nIn addition, you'll need to define classes for the semantic entities of the program, which\nrepresent abstract properties (e.g.\nexpression types, method signatures, class descriptors,\netc.) and to establish the correspondences between them. Some examples: every expression\nhas a type; every variable declaration introduces a variable; every block defines a scope. Many\nof these properties are derived by recursive traversals over the tree.\nAs far as possible, you should try to make instances of the the symbol classes canonical, so\nthat they may be compared using reference equality. You are strongly advised to design these\nclasses with care, employing good software-engineering practice and documenting them, as\nyou will be living with them for the next few months!\n- All error messages should be accompanied by the filename, line and column number of the\ntoken most relevant to the error message (use your judgement here). This means that, when\nbuilding your abstract-syntax tree (or AST), you must ensure that each IR node contains\nsufficient information for you to determine its line number at some later time.\nIt is not appropriate to throw an exception when encountering an error in the input: doing\nso would lead to a design in which at most one error message is reported for each run of the\ncompiler. A good front-end saves the user time by reporting multiple errors before stopping,\nallowing the programmer to make several corrections before having to restart compilation.\n- Semantic checking should be done top-down. While the type-checking component of seman\ntic checking can be done in bottom-up fashion, other kinds of checks (for example, detecting\nuses of undefined variables) can not.\nThere are two ways of achieving this. The first is to make use of parser actions in the middle\nof productions. This approach may require less code but can be more complex, because more\nwork needs to be done directly within the ANTLR infrastructure.\nA cleaner approach is to invoke your semantic checker on a complete AST after parsing has\nfinished. The pseudocode for block in this approach would resemble this:\n\nvoid checkBlock(EnvStack envs, Block b) {\nenvs.push(new Env());\nforeach s in b.statements\ncheckStatement(envs, s);\nenvs.pop();\n}\nIn this pseudocode, a new environment is created and pushed on the environment stack, the\nbody of the block is then checked in the context of this environment stack, and then the new\nenvironment is discarded when the end of the block is reached.\nThe semantic check can thus be expressed as a visitor (which should be familiar from Design\nPatterns or 6.170) over the AST. (Since code generation, certain optimizations, and pretty\nprinting can also be naturally expressed as visitors, we recommend this approach for a cleaner\nimplementation.)\n- The treatment of negative integer literals requires some care. Recall from the previous hand\nout that negative integer literals are in fact two separate tokens: the positive integer literal\nand a preceding '-'. Whenever your top-down semantic checker finds a unary minus operator,\nit should check if its operand is a positive integer literal, and if so, replace the subtree (both\nnodes) by a single, negative integer literal.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.035 Computer Language Engineering\nSpring 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}