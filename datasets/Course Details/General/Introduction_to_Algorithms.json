{
  "course_name": "Introduction to Algorithms",
  "course_description": "This course provides an introduction to mathematical modeling of computational problems. It covers the common algorithms, algorithmic paradigms, and data structures used to solve these problems. The course emphasizes the relationship between algorithms and programming, and introduces basic performance measures and analysis techniques for these problems.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures",
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1 hour / session\n\nRecitations: 2 sessions / week, 1 hour / session\n\nCourse Description\n\nThis course provides an introduction to mathematical modeling of computational problems. It covers the common algorithms, algorithmic paradigms, and data structures used to solve these problems. The course emphasizes the relationship between algorithms and programming, and introduces basic performance measures and analysis techniques for these problems.\n\nPrerequisites\n\nA firm grasp of Python and a solid background in discrete mathematics are necessary prerequisites to this course. You are expected to have mastered the material presented in\n6.01 Introduction to EECS I\nand\n6.042J Mathematics for Computer Science\n.\n\nIf you have not taken and been successful in each of these subjects, please speak with a TA or professor before enrolling. We do allow students who have equivalent, other experience with the material described above to enroll, but with the firm understanding that mastery of this material is assumed and that course staff will not feel obligated to cover it or to help students who are struggling with it.\n\n6.006 is a 12-unit (4-0-8) subject and serves as a Foundational Computer Science subject under the new curriculum. It is a direct prerequisite for\n6.046 Design and Analysis of Algorithms,\nthe theory header.\n\nTextbooks\n\nRequired\n\nCormen, Thomas, Charles Leiserson, Ronald Rivest, and Clifford Stein.\nIntroduction to Algorithms\n. 3rd ed. MIT Press, 2009. ISBN: 9780262033848.\n\nFor the student who finds books helpful, we also suggest:\n\nMiller, Bradley, and David Ranum.\nProblem Solving with Algorithms and Data Structures Using Python\n. 2nd ed. Franklin, Beedle & Associates, 2011. ISBN: 9781590282571.\n\nSoftware\n\n6.006 programming environment setup\n\nLectures and Recitations\n\nOne-hour lectures are held twice a week. You are responsible for material presented in lectures, including oral comments made by the lecturer (or other information that may not be present in the notes).\n\nOne-hour recitations are held twice a week, one day after the lectures. You are responsible for the material presented in recitation, which may include new material not presented in lectures. Recitation attendance has been well-correlated with quiz performance in past semesters. Recitations also give you a more intimate opportunity to ask questions of and to interact with the course staff. Your recitation instructor is responsible for determining your final grade.\n\nProblem Sets\n\nWe will assign seven problem sets during the course of the semester. Each problem set will consist of a programming assignment, to be completed in Python, and a theory assignment.\n\nIf you collaborate with others in any fashion, you must list their names as collaborators. For details, please see the section on our collaboration policy; we take this very seriously.\n\nLate assignments will be severely penalized. (This penalty is currently a 1% deduction every six minutes or part thereof until the end of the tenth hour after the deadline, after which submissions will receive no credit.)\n\nQuizzes\n\nWe will give two evening quizzes during the semester; these will each be two hours in duration. There will also be a final exam during finals week.\n\nGrading Policy\n\nYour final grade will be determined by the grades you receive on problem sets, on quizzes, and on the final. The particulars of this policy are subject to the discretion of the course staff.\n\nACTIVITIES\n\nPERCENTAGES\n\nProblem sets\n\n30%\n\nQuizzes\n\n20% each\n\nFinal exam\n\n30%\n\nCoding Assignments\n\nThe code that you hand in will be graded based on its correctness, its quality, and the details of the algorithm that it implements.\n\nCorrectness\n\nWe will provide a set of public unit tests with each problem to help you test your work. However, when grading, we will use additional unit tests that will not be available to you; we reserve the right to test any behavior specified by or following from the problem statement. Submissions that run for excessive amounts of time may be scored as incorrect.\n\nTheory\n\nCode should represent an implementation of an appropriately designed algorithm. While we do not necessarily expect you to achieve any lower bounds that may exist for a particular problem, submissions should not be overly inefficient in either time or space.\n\nCopying another student's code is considered cheating. We may use both manual and automated methods to detect cheating.\n\nWritten Assignments\n\nWe expect you to enter proofs using LaTeX math mode directly into Gradetacular. We have a two-step process for grading proofs. First, you'll enter your proof into Gradetacular before the time that the problem set is due. We will provide the solutions 10 hours after the problem set is due, which you will use to find any errors in the proof that you submitted. Your critique will usually be due by the following lecture. Your grade will be based on your solution and your critique.\n\nThe same late policy applies to the grading part of the assignment (1% off every six minutes that the problem set is late). Please note that if you require an extension, we will need to know in advance and you must have a good reason for needing it. In addition, we trust that you will not look at the posted solutions when completing the problem set under an extension. Looking at the solutions under these conditions constitutes a breach of the honor code, and is a serious offense.\n\nThe best responses will be concise, correct, and complete. Failing to answer part of the question, being overly verbose, missing special or edge cases, and answering mistakenly will each reduce your score.\n\nWhen you are called upon to \"give an algorithm,\" you must provide (1) a textual description of the algorithm, and, if helpful, pseudocode; (2) at least one worked example or diagram to illustrate how your algorithm works; (3) a proof (or other indication) of the correctness of the algorithm; and (4) an analysis of the time complexity (and, if relevant, the space complexity) of the algorithm.\n\nRemember that, above all else, your goal is to communicate. After all, if a grader cannot understand your solution, they cannot give you any credit for it.\n\nCollaboration Policy\n\nThe goal of homework is to give you practice in mastering the course material. Consequently, you are encouraged to collaborate on problem sets. In fact, students who form study groups generally do better on exams than do students who work alone. If you do work in a study group, however, you owe it to yourself and your group to be prepared for your study group meeting. Specifically, you should spend at least 30-45 minutes trying to solve each problem beforehand.\n\nYou must write up each problem solution by yourself without assistance, even if you collaborate with others to solve the problem. You are asked on problem sets to identify your collaborators. If you did not work with anyone, you should write that you did not have collaborators. If you obtain a solution through research (e.g., on the web), acknowledge your source, but write up the solution in your own words. It is a violation of this policy to submit a problem solution that you cannot orally explain to a member of the course staff.\n\nCode you submit must also be written by yourself. You may receive help from your classmates during debugging. Don't spend hours trying to debug a problem in your code before asking for help. However, regardless of who is helping you, only you are allowed to make changes to your code. Both manual and automatic mechanisms will be employed to detect plagiarism in code.\n\nNo other 6.006 student may use your solutions; this includes your writing, code, tests, documentation, etc. It is a violation of the 6.006 collaboration policy to permit anyone other than 6.006 staff and yourself to see your solutions to either theory or code questions.\n\nPlagiarism and other anti-intellectual behavior cannot be tolerated in any academic environment that prides itself on individual accomplishment. If you have any questions about the collaboration policy, or if you feel that you may have violated the policy, please talk to one of the course staff. Although the course staff is obligated to deal with cheating appropriately, we often have the ability to be more understanding and lenient if we find out from the transgressor himself or herself rather than from a third party.",
  "files": [
    {
      "category": "Exam",
      "title": "Final Exam",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/c316e062020649db5cda5785036c6fb8_MIT6_006F11_final.pdf",
      "content": "Introduction to Algorithms\nDecember 16, 2011\nMassachusetts Institute of Technology\n6.006 Fall 2011\nProfessors Erik Demaine and Srini Devadas\nFinal Exam\nFinal Exam\n- Do not open this quiz booklet until directed to do so. Read all the instructions on this page.\n- When the quiz begins, write your name on every page of this quiz booklet.\n- You have 180 minutes to earn 180 points. Do not spend too much time on any one problem.\nRead them all first, and attack them in the order that allows you to make the most progress.\n- This quiz is closed book. You may use three 81 ′′ × 11\n′′ or A4 or 6.006 cushions as crib\nsheets (both sides). No calculators or programmable devices are permitted. No cell phones\nor other communications devices are permitted.\n- Write your solutions in the space provided. If you need more space, write on the back of the\nsheet containing the problem. Pages may be separated for grading.\n- Do not waste time and paper rederiving facts that we have studied. It is sufficient to cite\nknown results.\n- When writing an algorithm, a clear description in English will suffice. Pseudo-code is\nnot required.\n- When asked for an algorithm, your algorithm should have the time complexity specified in\nthe problem with a correct analysis. If you cannot find such an algorithm, you will generally\nreceive partial credit for a slower algorithm if you analyze your algorithm correctly.\n- Show your work, as partial credit will be given. You will be graded not only on the correct-\nness of your answer, but also on the clarity with which you express it. Be neat.\nGood luck!\n-\nProblem\nParts\nPoints\nGrade\nGrader\nProblem\nParts\nPoints\nGrade\nGrader\nTotal\nName:\nWed/Fri\nRecitation:\nYing\n10,\n11 AM\nKevin\n11 AM\nSarah\n12,\n1 PM\nYafim\n12 PM\nVictor\n2,\n3 PM\n\n6.006 Final Exam\nName\nProblem 1.\nTrue/False [36 points] (18 parts)\nCircle (T)rue or (F)alse. You don't need to justify your choice.\n(a) T F\n[2 points] Polynomial: good. Exponential: bad.\n(b) T F\n[2 points] Radix sort runs correctly when using any correct sorting algorithm to\nsort each digit.\n(c) T F\n[2 points] Given an array A[1 . . n] of integers, the running time of Counting Sort\nis polynomial in the input size n.\n(d) T F\n[2 points] Given an array A[1 . . n] of integers, the running time of Heap Sort is\npolynomial in the input size n.\n(e) T F\n[2 points] Any n-node unbalanced tree can be balanced using O(log n) rotations.\n(f) T F\n[2 points] If we augment an n-node AVL tree to store the size of every rooted\nsubtree, then in O(log n) we can solve a range query: given two keys x and y,\nhow many keys are in the interval [x, y]?\n(g) T F\n[2 points] AVL trees can be used to implement an optimal comparison-based\nsorting algorithm.\n(h) T F\n[2 points] Given a connected graph G = (V, E), if a vertex v ∈V is visited\nduring level k of a breadth-first search from source vertex s ∈V , then every path\nfrom s to v has length at most k.\n(i) T F\n[2 points] Depth-first search will take Θ(V 2) time on a graph G = (V, E) repre-\nsented as an adjacency matrix.\n\n6.006 Final Exam\nName\n(j) T F\n[2 points] Given an adjacency-list representation of a directed graph G = (V, E),\nit takes O(V ) time to compute the in-degree of every vertex.\n(k) T F\n[2 points] For a dynamic programming algorithm, computing all values in a\nbottom-up fashion is asymptotically faster than using recursion and memoization.\n(l) T F\n[2 points] The running time of a dynamic programming algorithm is always\nΘ(P) where P is the number of subproblems.\n(m) T F [2 points] When a recurrence relation has a cyclic dependency, it is impossible\nto use that recurrence relation (unmodified) in a correct dynamic program.\n(n) T F\n[2 points] For every dynamic program, we can assign weights to edges in the\ndirected acyclic graph of dependences among subproblems, such that finding a\nshortest path in this DAG is equivalent to solving the dynamic program.\n(o) T F\n[2 points] Every problem in NP can be solved in exponential time.\n(p) T F\n[2 points] If a problem X can be reduced to a known NP-hard problem, then X\nmust be NP-hard.\n(q) T F\n[2 points] If P equals NP, then NP equals NP-complete.\n(r) T F\n[2 points] The following problem is in NP: given an integer n = p · q, where p\nand q are N-bit prime numbers, find p or q.\n\n6.006 Final Exam\nName\nProblem 2.\nSorting Scenarios [9 points] (3 parts)\nCircle the number next to the sorting algorithm covered in 6.006 that would be the best (i.e., most\nefficient) for each scenario in order to reduce the expected running time. You do not need to justify\nyour answer.\n(a) [3 points] You are running a library catalog. You know that the books in your col-\nlection are almost in sorted ascending order by title, with the exception of one book\nwhich is in the wrong place. You want the catalog to be completely sorted in ascending\norder.\n1. Insertion Sort\n2. Merge Sort\n3. Radix Sort\n4. Heap Sort\n5. Counting Sort\n(b) [3 points] You are working on an embedded device (an ATM) that only has 4KB\n(4,096 bytes) of free memory, and you wish to sort the 2,000,000 transactions with-\ndrawal history by the amount of money withdrawn (discarding the original order of\ntransactions).\n1. Insertion Sort\n2. Merge Sort\n3. Radix Sort\n4. Heap Sort\n5. Counting Sort\n(c) [3 points] To determine which of your Facebook friends were early adopters, you\ndecide to sort them by their Facebook account ids, which are 64-bit integers. (Recall\nthat you are super popular, so you have very many Facebook friends.)\n1. Insertion Sort\n2. Merge Sort\n3. Radix Sort\n4. Heap Sort\n5. Counting Sort\n\n6.006 Final Exam\nName\nProblem 3.\nHotel California [20 points] (5 parts)\nYou have decided to run off to Los Angeles for the summer and start a new life as a rockstar.\nHowever, things aren't going great, so you're consulting for a hotel on the side. This hotel has N\none-bed rooms, and guests check in and out throughout the day. When a guest checks in, they ask\nfor a room whose number is in the range [l, h].1\nYou want to implement a data structure that supports the following data operations as efficiently as\npossible.\n1. INIT(N): Initialize the data structure for N empty rooms numbered 1, 2, . . . , N, in polyno-\nmial time.\n2. COUNT(l, h): Return the number of available rooms in [l, h], in O(log N) time.\n3. CHECKIN(l, h): In O(log N) time, return the first empty room in [l, h] and mark it occupied,\nor return NIL if all the rooms in [l, h] are occupied.\n4. CHECKOUT(x): Mark room x as not occupied, in O(log N) time.\n(a) [6 points] Describe the data structure that you will use, and any invariants that your\nalgorithms need to maintain. You may use any data structure that was described in a\n6.006 lecture, recitation, or problem set. Don't give algorithms for the operations of\nyour data structure here; write them in parts (b)-(e) below.\n1Conferences often reserve a contiguous block of rooms, and attendees want to stay next to people with similar\ninterests.\n\n6.006 Final Exam\nName\n(b) [3 points] Give an algorithm that implements INIT(N). The running time should be\npolynomial in N.\n(c) [3 points] Give an algorithm that implements COUNT(l, h) in O(log N) time.\n\n6.006 Final Exam\nName\n(d) [5 points] Give an algorithm that implements CHECKIN(l, h) in O(log N) time.\n(e) [3 points] Give an algorithm that implements CHECKOUT(x) in O(log N) time.\n\n6.006 Final Exam\nName\nProblem 4.\nHashing [15 points] (3 parts)\nSuppose you combine open addressing with a limited form of chaining. You build an array with m\nslots that can store two keys in each slot. Suppose that you have already inserted n keys using the\nfollowing algorithm:\n1. Hash (key, probe number) to one of the m slots.\n2. If the slot has less than two keys, insert it there.\n3. Otherwise, increment the probe number and go to step 1.\nGiven the resulting table of n keys, we want to insert another key. We wish to compute the prob-\nability that the first probe will successfully insert this key, i.e., the probability that the first probe\nhits a slot that is either completely empty (no keys stored in it) or half-empty (one key stored in it).\nYou can make the uniform hashing assumption for all the parts of this question.\n(a) [5 points] Assume that there are exactly k slots in the table that are completely full.\nWhat is the probability s(k) that the first probe is successful, given that there are\nexactly k full slots?\n(b) [5 points] Assume that p(k) is the probability that there are exactly k slots in the table\nthat are completely full, given that there are already n keys in the table. What is the\nprobability that the first probe is successful in terms of p(k)?\n(c) [5 points] Give a formula for p(0) in terms of m and n.\n\n6.006 Final Exam\nName\nProblem 5.\nThe Quadratic Method [10 points] (1 parts)\nDescribe how you can use Newton's method to find a root of x2 + 4x + 1 = 0 to d digits of\nprecision. Either reduce the problem to a problem you have already seen how to solve in lecture or\nrecitation, or give the formula for one step of Newton's method.\n\n6.006 Final Exam\nName\nProblem 6.\nThe Wedding Planner [20 points] (2 parts)\nYou are planning the seating arrangement for a wedding given a list of guests, V .\n(a) [10 points] Suppose you are also given a lookup table T where T[u] for u ∈V is\na list of guests that u knows. If u knows v, then v knows u. You are required to\narrange the seating such that any guest at a table knows every other guest sitting at the\nsame table either directly or through some other guests sitting at the same table. For\nexample, if x knows y, and y knows z, then x, y, z can sit at the same table. Describe\nan efficient algorithm that, given V and T, returns the minimum number of tables\nneeded to achieve this requirement. Analyze the running time of your algorithm.\n\n6.006 Final Exam\nName\n(b) [10 points] Now suppose that there are only two tables, and you are given a different\nlookup table S where S[u] for u ∈V is a list of guests who are on bad terms with u.\nIf v is on bad terms with u, then u is on bad terms with v. Your goal is to arrange the\nseating such that no pair of guests sitting at the same table are on bad terms with each\nother. Figure 1 below shows two graphs in which we present each guest as a vertex\nand an edge between two vertices means these two guests are on bad terms with each\nother. Figure 1(a) is an example where we can achieve the goal by having A, C sitting\nat one table and B, E, D sitting at another table. Figure 1(b) is an example where we\ncannot achieve the goal. Describe an efficient algorithm that, given V and S, returns\nTRUE if you can achieve the goal or FALSE otherwise. Analyze the running time of\nyour algorithm.\nA\nB\nC\nD\nE\n(a)\nA\nB\nC\nD\nE\n(b)\nFigure 1: Examples of guest relationships presented as graphs.\n\n6.006 Final Exam\nName\nProblem 7.\nHow Fast Is Your Dynamic Program? [15 points] (5 parts)\nIn the dynamic programs below, assume the input consists of an integer S and a sequence x0, x1, . . . , xn-1\nof integers between 0 and S. Assume that each dynamic program uses subproblems (i, X) for\n0 ≤i < n and 0 ≤X ≤S (just like Knapsack). Assume that the goal is to compute DP(0, S),\nand that the base case is DP(n, X) = 0 for all X. Assume that the dynamic program is a mem-\noized recursive algorithm, so that only needed subproblems get computed. Circle the number\nnext to the correct running time for each dynamic program.\nDP(i + 1, X) + x\n(a)\nDP(i, X) = max\ni,\nDP(i + 1, X -x ) + x2\ni\ni\nif X ≥xi\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nDP(i + 1, S) + x\n(b)\nDP(i, X) = max\ni,\nDP(0, X -x\ni) + xi\nif X ≥xi\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\n\n6.006 Final Exam\nName\nDP(i + 1, 0) + x\n(c)\nDP(i, X) = max\ni,\nDP(0, X -xi) + x2\ni\nif X ≥xi\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nDP(i + 1, X) + x ,\n(d)\nDP(i, X) = max\n\ni\nDP(i + 1, 0) + x2\ni\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nDP(i + 1, X -P S) + (\nS)2\n(e)\nDP(i, X) = max\nfor every subset S ⊆{x0,\nP\nx1, . . . , xn-1}\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\n\n6.006 Final Exam\nName\nProblem 8.\nLongest Alternating Subsequence [20 points] (6 parts)\nCall a sequence y1, y2, . . . , yn alternating if every adjacent triple yi, yi+1, yi+2 has either yi <\nyi+1 > yi+2, or yi > yi+1 < yi+2. In other words, if the sequence increased between yi and yi+1,\nthen it should then decrease between yi+1 and yi+2, and vice versa.\nOur goal is to design a dynamic program that, given a sequence x1, x2, . . . , xn, computes the length\nof the longest alternating subsequence of x1, x2, . . . , xn. The subproblems we will use are prefixes,\naugmented with extra information about whether the longest subsequence ends on a descending\npair or an ascending pair. In other words, the value DP(i, b) should be the length of the longest\nalternating subsequence that ends with xi, and ends in an ascending pair if and only if b is TRUE.\nFor the purposes of this problem, we define a length-one subsequence to be both increasing and\ndecreasing at the end.\nFor example, suppose that we have the following sequence:\nx1 = 13\nx2 = 93\nx3 = 86\nx4 = 50\nx5 = 63\nx6 = 4\nThen DP(5, TRUE) = 4, because the longest possible alternating sequence ending in x5 with an\nincrease at the end is is x1, x2, x4, x5 or x1, x3, x4, x5. However, DP(5, FALSE) = 3, because if the\nsequence has to decrease at the end, then x4 cannot be used.\n(a) [4 points] Compute all values of DP(i, b) for the above sequence. Place your answers\nin the following table:\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5\ni = 6\nb = TRUE\nb = FALSE\n\n6.006 Final Exam\nName\n(b) [4 points] Give a recurrence relation to compute DP(i, b).\n(c) [4 points] Give the base cases of your recurrence relation.\n(d) [3 points] Give a valid ordering of subproblems for a bottom-up computation.\n\n6.006 Final Exam\nName\n(e) [3 points] If you were given the values of DP(i, b) for all 1 ≤i ≤n and all b ∈\n{TRUE, FALSE}, how could you use those values to compute the length of the longest\nalternating subsequence of x1, x2, . . . , xn?\n(f) [2 points] When combined, parts (b) through (e) can be used to write an algorithm\nsuch as the following:\nLONGESTALTERNATINGSUBSEQUENCE(x1, . . . , xn)\ninitialize table T\nfor each subproblem (i, b), in the order given by part (d)\nif (i, b) is a base case\nuse part (c) to compute DP(i, b)\nelse\nuse part (b) to compute DP(i, b)\nstore the computed value of DP(i, b) in the table T\nuse part (e) to find the length of the overall longest subsequence\nAnalyze the running time of this algorithm, given your answers to the questions above.\n\n6.006 Final Exam\nName\nProblem 9.\nParen Puzzle [15 points]\nYour local school newspaper, The TEX, has started publishing puzzles of the following form:\nParenthesize 6 + 0 · 6\nParenthesize 0.1 · 0.1 + 0.1\nto maximize the outcome.\nto maximize the outcome.\nWrong answer: 6 + (0 · 6) = 6 + 0 = 6.\nWrong answer: 0.1 · (0.1 + 0.1) = 0.1 · 0.2 = 0.02.\nRight answer: (6 + 0) · 6 = 6 · 6 = 36.\nRight answer: (0.1 · 0.1) + 0.1 = 0.01 + 0.1 = 0.11.\nTo save yourself from tedium, but still impress your friends, you decide to implement an algorithm\nto solve these puzzles. The input to your algorithm is a sequence x0, o0, x1, o1, . . . , xn-1, on-1, xn\nof n + 1 real numbers x0, x1, . . . , xn and n operators o0, o1, . . . , on\n. Each operator o is either\n-1\ni\naddition (+) or multiplication (·). Give a polynomial-time dynamic program for finding the optimal\n(maximum-outcome) parenthesization of the given expression, and analyze the running time.\n\n6.006 Final Exam\nName\nProblem 10.\nSorting Fluff [20 points] (5 parts)\nIn your latest dream, you find yourself in a prison in the sky. In order to be released, you must\norder N balls of fluff according to their weights. Fluff is really light, so weighing the balls requires\ngreat care. Your prison cell has the following instruments:\n- A magic balance scale with 3 pans. When given 3 balls of fluff, the scale will point out the\nball with the median weight. The scale only works reliably when each pan has exactly 1 ball\nof fluff in it. Let MEDIAN(x, y, z) be the result of weighing balls x, y and z, which is the\nball with the median weight. If MEDIAN(x, y, z) = y, that means that either x < y < z or\nz < y < x.\n- A high-precision classical balance scale. This scale takes 2 balls of fluff, and points out which\nball is lighter; however, because fluff is very light, the scale can only distinguish between the\noverall lightest and the overall heaviest balls of fluff. Comparing any other balls will not\nyield reliable results. Let LIGHTEST(a, b) be the result of weighing balls a and b. If a is the\nlightest ball and b is the heaviest ball, LIGHTEST(a, b) = a. Conversely, if a is the heaviest\nball and b is the lightest ball, LIGHTEST(a, b) = b. Otherwise, LIGHTEST(a, b)'s return value\nis unreliable.\nOn the bright side, you can assume that all N balls have different weights. Naturally, you want to\nsort the balls using as few weighings as possible, so you can escape your dream quickly and wake\nup before 4:30pm!\nTo ponder this challenge, you take a nap and enter a second dream within your first dream. In the\nsecond dream, a fairy shows you the lightest and the heaviest balls of fluff, but she doesn't tell you\nwhich is which.\n(a) [2 points] Give a quick example to argue that you cannot use MEDIAN alone to\ndistinguish between the lightest and the heaviest ball, but that LIGHTEST can let you\ndistinguish.\n\n6.006 Final Exam\nName\n(b) [4 points]\nGiven l, the lightest ball l pointed out by the fairy, use O(1) calls to\nMEDIAN to implement LIGHTER(a, b), which returns TRUE if ball a is lighter than\nball b, and FALSE otherwise.\nAfter waking up from your second dream and returning to the first dream, you realize that there is\nno fairy. Solve the problem parts below without the information that the fairy would have given\nyou.\n(c) [6 points] Give an algorithm that uses O(N) calls to MEDIAN to find the heaviest\nand lightest balls of fluff, without identifying which is the heaviest and which is the\nlightest.\n\n6.006 Final Exam\nName\n(d) [2 points] Explain how the previous parts should be put together to sort the N balls\nof fluff using O(N log N) calls to MEDIAN and O(1) calls to LIGHTEST.\n(e) [6 points] Argue that you need at least Ω(N log N) calls to MEDIAN to sort the N\nfluff balls.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Final Exam Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/6a81686dc8431dbc9e27dbe42eb683d7_MIT6_006F11_final_sol.pdf",
      "content": "Introduction to Algorithms\nDecember 16, 2011\nMassachusetts Institute of Technology\n6.006 Fall 2011\nProfessors Erik Demaine and Srini Devadas\nFinal Exam Solutions\nFinal Exam Solutions\nProblem 1.\nTrue/False [36 points] (18 parts)\nCircle (T)rue or (F)alse. You don't need to justify your choice.\n(a) T F\n[2 points] Polynomial: good. Exponential: bad.\nSolution:\nTrue. This is a general rule-of-thumb mentioned in lecture.\n(b) T F\n[2 points] Radix sort runs correctly when using any correct sorting algorithm to\nsort each digit.\nSolution:\nFalse. It must use a stable sorting algorithm.\n(c) T F\n[2 points] Given an array A[1 . . n] of integers, the running time of Counting Sort\nis polynomial in the input size n.\nSolution:\nFalse. Counting Sort's running time depends on the size of the num-\nbers in the input, so it is pseudo-polynomial.\n(d) T F\n[2 points] Given an array A[1 . . n] of integers, the running time of Heap Sort is\npolynomial in the input size n.\nSolution:\nTrue. Heap Sort runs in O(n log n) time on a RAM machine.\n(e) T F\n[2 points] Any n-node unbalanced tree can be balanced using O(log n) rotations.\nSolution:\nFalse. The worst-case unbalanced tree is a list, and balancing it re-\nquires Ω(n) rotations.\n(f) T F\n[2 points] If we augment an n-node AVL tree to store the size of every rooted\nsubtree, then in O(log n) we can solve a range query: given two keys x and y,\nhow many keys are in the interval [x, y]?\nSolution:\nTrue. The question describes range trees, as implemented in Problem\nSet 3.\n(g) T F\n[2 points] AVL trees can be used to implement an optimal comparison-based\nsorting algorithm.\n\n6.006 Final Exam Solutions\nName\nSolution:\nTrue. AVL trees can be used to sort N numbers in O(N log N) time,\nby inserting all the numbers in the tree, and iteratively calling NEXT-LARGEST\nN times.\n(h) T F\n[2 points] Given a connected graph G = (V, E), if a vertex v ∈V is visited\nduring level k of a breadth-first search from source vertex s ∈V , then every path\nfrom s to v has length at most k.\nSolution:\nFalse. The level of a vertex only provides the length of the shortest\npath from s.\n(i) T F\n[2 points] Depth-first search will take Θ(V 2) time on a graph G = (V, E) repre-\nsented as an adjacency matrix.\nSolution:\nTrue. In this case, finding the neighbors of a vertex takes O(V ) time,\nwhich makes the total running time Θ(V 2).\n\n6.006 Final Exam Solutions\nName\n(j) T F\n[2 points] Given an adjacency-list representation of a directed graph G = (V, E),\nit takes O(V ) time to compute the in-degree of every vertex.\nSolution:\nFalse. The adjacency list structure needs to be traversed to find the\nincoming edges for each vertex. This structure has total size Θ(V + E), so this\ntakes Θ(V + E) time to compute.\n(k) T F\n[2 points] For a dynamic programming algorithm, computing all values in a\nbottom-up fashion is asymptotically faster than using recursion and memoization.\nSolution:\nFalse. A bottom-up implementation must go through all of the sub-\nproblems and spend the time per subproblem for each. Using recursion and mem-\noization only spends time on the subproblems that it needs. In fact, the reverse\nmay be true: using recursion and memoization may be asymptotically faster than\na bottom-up implementation.\n(l) T F\n[2 points] The running time of a dynamic programming algorithm is always\nΘ(P) where P is the number of subproblems.\nSolution:\nFalse. The running time of a dynamic program is the number of\nsubproblems times the time per subproblem. This would only be true if the time\nper subproblem is O(1).\n(m) T F [2 points] When a recurrence relation has a cyclic dependency, it is impossible\nto use that recurrence relation (unmodified) in a correct dynamic program.\nSolution:\nTrue. We need to first perform a modification like the one seen in the\nrecitation notes.\n(n) T F\n[2 points] For every dynamic program, we can assign weights to edges in the\ndirected acyclic graph of dependences among subproblems, such that finding a\nshortest path in this DAG is equivalent to solving the dynamic program.\nSolution:\nFalse. We saw a counter-example where we couldn't do this in the\nmatrix parenthesization problem.\n(o) T F\n[2 points] Every problem in NP can be solved in exponential time.\nSolution:\nTrue. NP is contained in EXP.\n(p) T F\n[2 points] If a problem X can be reduced to a known NP-hard problem, then X\nmust be NP-hard.\n\n6.006 Final Exam Solutions\nName\nSolution:\nFalse. The reverse, however, is true: if a known NP-hard problem\ncan be reduced to X then X must be NP-hard.\n(q) T F\n[2 points] If P equals NP, then NP equals NP-complete.\nSolution:\nTrue. A problem X is NP-hard iff any problem in NP can be reduced\nin polynomial time to X. If P equals NP, then we can reduce any problem in NP\nto any other problem by just solving the original problem.\n(r) T F\n[2 points] The following problem is in NP: given an integer n = p · q, where p\nand q are N-bit prime numbers, find p or q.\nSolution:\nTrue. An answer a to the problem can be checked in polynomial time\nby verifying that n mod a = 0 (and a is not 1 or n). So the factoring problem is\nin NP. Cryptographic systems (e.g. RSA) often assume that factoring is not in P.\nFalse was also accepted because this is not a decision problem.\n\n6.006 Final Exam Solutions\nName\nProblem 2.\nSorting Scenarios [9 points] (3 parts)\nCircle the number next to the sorting algorithm covered in 6.006 that would be the best (i.e., most\nefficient) for each scenario in order to reduce the expected running time. You do not need to justify\nyour answer.\n(a) [3 points] You are running a library catalog. You know that the books in your col-\nlection are almost in sorted ascending order by title, with the exception of one book\nwhich is in the wrong place. You want the catalog to be completely sorted in ascending\norder.\n1. Insertion Sort\n2. Merge Sort\n3. Radix Sort\n4. Heap Sort\n5. Counting Sort\nSolution:\nInsertion sort will run in O(n) time in this setting.\n(b) [3 points] You are working on an embedded device (an ATM) that only has 4KB\n(4,096 bytes) of free memory, and you wish to sort the 2,000,000 transactions with-\ndrawal history by the amount of money withdrawn (discarding the original order of\ntransactions).\n1. Insertion Sort\n2. Merge Sort\n3. Radix Sort\n4. Heap Sort\n5. Counting Sort\nSolution:\nHeap sort, because it is in-place.\n(c) [3 points] To determine which of your Facebook friends were early adopters, you\ndecide to sort them by their Facebook account ids, which are 64-bit integers. (Recall\nthat you are super popular, so you have very many Facebook friends.)\n1. Insertion Sort\n2. Merge Sort\n3. Radix Sort\n4. Heap Sort\n5. Counting Sort\nSolution:\nRadix sort\n\n6.006 Final Exam Solutions\nName\nProblem 3.\nHotel California [20 points] (5 parts)\nYou have decided to run off to Los Angeles for the summer and start a new life as a rockstar.\nHowever, things aren't going great, so you're consulting for a hotel on the side. This hotel has N\none-bed rooms, and guests check in and out throughout the day. When a guest checks in, they ask\nfor a room whose number is in the range [l, h].1\nYou want to implement a data structure that supports the following data operations as efficiently as\npossible.\n1. INIT(N): Initialize the data structure for N empty rooms numbered 1, 2, . . . , N, in polyno-\nmial time.\n2. COUNT(l, h): Return the number of available rooms in [l, h], in O(log N) time.\n3. CHECKIN(l, h): In O(log N) time, return the first empty room in [l, h] and mark it occupied,\nor return NIL if all the rooms in [l, h] are occupied.\n4. CHECKOUT(x): Mark room x as not occupied, in O(log N) time.\n(a) [6 points] Describe the data structure that you will use, and any invariants that your\nalgorithms need to maintain. You may use any data structure that was described in a\n6.006 lecture, recitation, or problem set. Don't give algorithms for the operations of\nyour data structure here; write them in parts (b)-(e) below.\nSolution:\nWe maintain a range tree, where the nodes store the room numbers of the\nrooms that are not occupied.\nRecall from Problem Set 3 that a range tree is a balanced Binary Search Tree, where\neach node is augmented with the size of the node's subtree.\n1Conferences often reserve a contiguous block of rooms, and attendees want to stay next to people with similar\ninterests.\n\n6.006 Final Exam Solutions\nName\n(b) [3 points] Give an algorithm that implements INIT(N). The running time should be\npolynomial in N.\nSolution:\nAll the rooms are initially empty, so all their numbers (1 . . . N) must be\ninserted into the range tree.\nINIT(N)\nfor i ∈1 . . . N\nINSERT(i)\n(c) [3 points] Give an algorithm that implements COUNT(l, h) in O(log N) time.\nSolution:\nThe COUNT method in range trees returns the desired answer. The num-\nber of tree nodes between l and h is exactly the number of unoccupied rooms in the\n[l, h] interval.\n\n6.006 Final Exam Solutions\nName\n(d) [5 points] Give an algorithm that implements CHECKIN(l, h) in O(log N) time.\nSolution:\nFinding the first available room with number ≤l is equivalent to finding\nthe successor of l -1 in the BST. The\nCHECKIN(l, h)\nr = NEXT-LARGEST(l -1)\nif r.key > h\nreturn NIL\nDELETE(r.key)\nreturn r.key\n(e) [3 points] Give an algorithm that implements CHECKOUT(x) in O(log N) time.\nSolution:\nWhen a guest checks out of a room, the room becomes unoccupied, so its\nnumber must be inserted into the range tree.\nCHECKOUT(x)\nINSERT(x)\n\n6.006 Final Exam Solutions\nName\nProblem 4.\nHashing [15 points] (3 parts)\nSuppose you combine open addressing with a limited form of chaining. You build an array with m\nslots that can store two keys in each slot. Suppose that you have already inserted n keys using the\nfollowing algorithm:\n1. Hash (key, probe number) to one of the m slots.\n2. If the slot has less than two keys, insert it there.\n3. Otherwise, increment the probe number and go to step 1.\nGiven the resulting table of n keys, we want to insert another key. We wish to compute the prob-\nability that the first probe will successfully insert this key, i.e., the probability that the first probe\nhits a slot that is either completely empty (no keys stored in it) or half-empty (one key stored in it).\nYou can make the uniform hashing assumption for all the parts of this question.\n(a) [5 points] Assume that there are exactly k slots in the table that are completely full.\nWhat is the probability s(k) that the first probe is successful, given that there are\nexactly k full slots?\nSolution:\nThere are m-k possibilities for a successful landing of the first probe out\nof m total landings. The probability of landing in any slot is\nm. Therefore, success\nprobability is m-k\nm .\n(b) [5 points] Assume that p(k) is the probability that there are exactly k slots in the table\nthat are completely full, given that there are already n keys in the table. What is the\nprobability that the first probe is successful in terms of p(k)?\nSolution:\nX\nn\n(m\nk)\np(k)\n-\nk=0\n·\nm\n(c) [5 points] Give a formula for p(0) in terms of m and n.\nSolution:\np(0) is essentially the probability that no keys collide. The probability\nthat the first element doesn't collide with any previous keys is 1. The probability that\nthe second element doesn't collide with any previous keys is 1 -1/m. In general, the\nprobability that the ith element doesn't collide with any previous keys, conditioned\non the assumption that previous keys did not collide and thus occupy i -1 slots, is\n1 -(i -1)/m. Therefore the overall probability is the product\nY\nn\ni=1\n\ni\n-1\n-\n\nm!\n=\n.\nm\n(m\nn)! ·\n-\nmn\n\n6.006 Final Exam Solutions\nName\nProblem 5.\nThe Quadratic Method [10 points] (1 parts)\nDescribe how you can use Newton's method to find a root of x2 + 4x + 1 = 0 to d digits of\nprecision. Either reduce the problem to a problem you have already seen how to solve in lecture or\nrecitation, or give the formula for one step of Newton's method.\nSolution:\nThere are two solutions to this problem. The first is the direct application of Newton's\nmethod. The second way is to use the formula for the roots of a quadratic equation and compute\n√\n3 to d digits of precision.\nFor the first method, we use Newton's formula:\nf(x\n-\ni)\nxi+1 = xi\nf ′(xi)\nf ′(x) = 2x + 4. We need lg d iterations for convergence.\nFor the second method, we use the formula to find the roots of a quadratic equation. We get:\nx =\n√\n-2 ±\nand then apply Newton's method to find\n√\n3 to d digits of precision. We require lg d iterations.\n\n6.006 Final Exam Solutions\nName\nProblem 6.\nThe Wedding Planner [20 points] (2 parts)\nYou are planning the seating arrangement for a wedding given a list of guests, V .\n(a) [10 points] Suppose you are also given a lookup table T where T[u] for u ∈V is\na list of guests that u knows. If u knows v, then v knows u. You are required to\narrange the seating such that any guest at a table knows every other guest sitting at the\nsame table either directly or through some other guests sitting at the same table. For\nexample, if x knows y, and y knows z, then x, y, z can sit at the same table. Describe\nan efficient algorithm that, given V and T, returns the minimum number of tables\nneeded to achieve this requirement. Analyze the running time of your algorithm.\nSolution:\nWe can construct an undirected graph G = (V, E) with guests as vertices,\nand an edge between two vertices means the two guests know each other. Table T\nrepresents the adjacency lists for the vertices. Two guests can sit at the same table if\nthere is a path between them. If we start from one vertex s and search the graph using\nbreadth-first search (BFS) or depth-first search (DFS), all the guests that are reachable\nfrom s can sit at the same table, and additional tables are needed for vertices that are\nunreachable from s.\nHence, to find the minimum number of tables, we can iterate through s ∈V . If\ns is not visited, increment the number of tables needed and call DFS-VISIT(s, T)\nor BFS(s, T), marking vertices as visited during the traversal. Return the number\nof tables needed after iterating through all the vertices. This problem is equivalent to\nfinding the number of connected components in the graph. The running time is Θ(V +\nE) because every vertex or edge is visted exactly once. Below is the pseudocode.\nNUM-TABLES(V, T)\nvisited = {}\nn = 0\nfor s ∈V\nif s ∈/ visited\nn = n + 1\nadd s to visited\nDFS-VISIT(s, T, visitied)\nreturn n\nDFS-VISIT(u, T, visitied)\nfor v ∈T[u]\nif v ∈/ visited\nadd v to visited\nDFS-VISIT(v, T, visited)\n\n6.006 Final Exam Solutions\nName\n(b) [10 points] Now suppose that there are only two tables, and you are given a different\nlookup table S where S[u] for u ∈V is a list of guests who are on bad terms with u.\nIf v is on bad terms with u, then u is on bad terms with v. Your goal is to arrange the\nseating such that no pair of guests sitting at the same table are on bad terms with each\nother. Figure 1 below shows two graphs in which we present each guest as a vertex\nand an edge between two vertices means these two guests are on bad terms with each\nother. Figure 1(a) is an example where we can achieve the goal by having A, C sitting\nat one table and B, E, D sitting at another table. Figure 1(b) is an example where we\ncannot achieve the goal. Describe an efficient algorithm that, given V and S, returns\nTRUE if you can achieve the goal or FALSE otherwise. Analyze the running time of\nyour algorithm.\nA\nC\nB\nD\nE\n(a)\nA\nC\nD\nB\nE\nconflict\n(b)\nFigure 1: Examples of guest relationships represented as graphs.\nSolution:\nLet G = (V, E) be the undirected graph where V is the set of guests\nand (u, v) ∈E if u and v are on bad terms. S represents the adjacency lists. We\ncan achieve the goal only if there is no cycle with odd length in the graph. We can\nfind out this by iterating through s ∈V . If s is not visited, color it as WHITE, and\ncall DFS-VISTI(s, S) or BFS(s, S). During the traversal, if v is not visited, mark it\nas visited and color it BLACK if its parent is WHITE and vice versa. If v is visited,\nand the color we want to apply is different from its current color, we find a conflict\n(Figure 1(b)), and we can terminate and return FALSE. If there is no conflict after\niterating through all the vertices (Figure 1(a)), return TRUE. The running time is again\nO(V + E). Below is the pseudocode.\nCAN-SEPARATE(V, S)\ncolor = {}\nWHITE = 0\nfor s ∈V\nif s ∈/ color // s is not visited\nif DFS-VISIT(s, S, WHITE, color) == FALSE\nreturn FALSE\nreturn TRUE\n\n6.006 Final Exam Solutions\nName\nDFS-VISIT(u, S, color-to-apply, color)\nif u ∈/ color\ncolor[u] = color-to-apply\nfor v ∈S[u]\nif DFS-VISIT(v, S, 1 -color-to-apply, color) == FALSE\nreturn FALSE\nelse if color[u] = color-to-apply\nreturn FALSE\nreturn TRUE\n\n6.006 Final Exam Solutions\nName\nProblem 7.\nHow Fast Is Your Dynamic Program? [15 points] (5 parts)\nIn the dynamic programs below, assume the input consists of an integer S and a sequence x0, x1, . . . , xn-1\nof integers between 0 and S. Assume that each dynamic program uses subproblems (i, X) for\n0 ≤i < n and 0 ≤X ≤S (just like Knapsack). Assume that the goal is to compute DP(0, S),\nand that the base case is DP(n, X) = 0 for all X. Assume that the dynamic program is a mem-\noized recursive algorithm, so that only needed subproblems get computed. Circle the number\nnext to the correct running time for each dynamic program.\nDP(i + 1, X) + x\n(a)\nDP(i, X) = max\ni,\nDP(i + 1, X -xi) + x2\ni\nif X ≥xi\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nSolution:\nPseudo-polynomial\nDP(i + 1, S) + x\n(b)\nDP(i, X) = max\ni,\nDP(0, X -xi) + x2\ni\nif X ≥xi\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nSolution:\nInfinite\n\n6.006 Final Exam Solutions\nName\nDP(i + 1, 0) + x\n(c)\nDP(i, X) = max\ni,\nDP(0, X -xi) + x2\ni\nif X ≥xi\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nSolution:\nPseudo-polynomial or infinite\nDP(i + 1, X) + x ,\n(d)\nDP(i, X) = max\n\ni\nDP(i + 1, 0) + x2\ni\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nSolution:\nPolynomial\nDP(i + 1, X -P S) + (P S)2\n(e)\nDP(i, X) = max\nfor every subset S ⊆{x0, x1, . . . , xn-1}\n\n1. Exponential\n2. Polynomial\n3. Pseudo-polynomial\n4. Infinite\nSolution:\nExponential\nSolution:\npseudopolynomial\ninfinite\npseudopolynomial\npolynomial\nexponential\n\n6.006 Final Exam Solutions\nName\nProblem 8.\nLongest Alternating Subsequence [20 points] (6 parts)\nCall a sequence y1, y2, . . . , yn alternating if every adjacent triple yi, yi+1, yi+2 has either yi <\nyi+1 > yi+2, or yi > yi+1 < yi+2. In other words, if the sequence increased between yi and yi+1,\nthen it should then decrease between yi+1 and yi+2, and vice versa.\nOur goal is to design a dynamic program that, given a sequence x1, x2, . . . , xn, computes the length\nof the longest alternating subsequence of x1, x2, . . . , xn. The subproblems we will use are prefixes,\naugmented with extra information about whether the longest subsequence ends on a descending\npair or an ascending pair. In other words, the value DP(i, b) should be the length of the longest\nalternating subsequence that ends with xi, and ends in an ascending pair if and only if b is TRUE.\nFor the purposes of this problem, we define a length-one subsequence to be both increasing and\ndecreasing at the end.\nFor example, suppose that we have the following sequence:\nx1 = 13\nx2 = 93\nx3 = 86\nx4 = 50\nx5 = 63\nx6 = 4\nThen DP(5, TRUE) = 4, because the longest possible alternating sequence ending in x5 with an\nincrease at the end is is x1, x2, x4, x5 or x1, x3, x4, x5. However, DP(5, FALSE) = 3, because if the\nsequence has to decrease at the end, then x4 cannot be used.\n(a) [4 points] Compute all values of DP(i, b) for the above sequence. Place your answers\nin the following table:\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5\ni = 6\nb = TRUE\nb = FALSE\nSolution:\nThe following table gives the correct values:\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5\ni = 6\nb = TRUE\nb = FALSE\nThere were several common mistakes on this question. The first mistake was over\nwhether a sequence of length one or two could be alternating. In a length-one or\nlength-two sequence, the number of adjacent triples is zero. As a result, all adjacent\ntriples vacuously satisfy the constraint given. So all length-one and length-two subse-\nquences are alternating.\n\n6.006 Final Exam Solutions\nName\nThe second mistake was over the definition of DP(i, b). In the problem, we explicitly\ndefine DP(i, b) to be the length of the longest subsequence that ends on xi and is\nincreasing iff b is TRUE. As a result, DP(6, TRUE) is equal to 1, not 4, because the\nonly ascending subsequence ending on the value x6 = 4 is the subsequence ⟨x6⟩.\n(b) [4 points] Give a recurrence relation to compute DP(i, b).\nSolution:\nThe following formula computes DP(i, b) as defined in the problem:\nDP(i, TRUE) = 1 +\nmax\nDP(j, FALSE)\n1≤j<i and xi>xj\nDP(i, FALSE) = 1 +\nmax\nDP(j, TRUE)\n1≤j<i and xi<xj\nThe most common mistake for this problem involved confusion over the definition of\nDP(i, b). Many people gave or attempted to give the following recurrence:\nDP(i -1, TRUE)\nDP(i, TRUE) = max\nDP(i -1, FALSE) + 1\nif xi > xi-1\nDP(i\nDP(i, FALSE) = max\n-1, FALSE)\nDP(i -1, TRUE) + 1\nif xi < xi-1\nUnfortunately, this recurrence does not compute the value that we asked for. The value\nDP(i, b) is specifically defined as \"the length of the longest alternating subsequence\nthat ends with xi, and ends in an ascending pair if and only if b is TRUE.\" The above\nrecurrence relation instead computes the length of the longest alternating subsequence\nof x1, . . . , xi, not necessarily ending on xi, that ends in an ascending pair if and only\nif b is TRUE.\n(c) [4 points] Give the base cases of your recurrence relation.\nSolution:\nThe base cases matching the recurrence relation above are:\nDP(i, TRUE) = 1\nif xi = min{x1, . . . , xi}\nDP(i, FALSE) = 1\nif xi = max{x1, . . . , xi}\n(d) [3 points] Give a valid ordering of subproblems for a bottom-up computation.\nSolution:\nThe correct order is to iterate through the values of i in increasing order,\nand compute DP(i, TRUE) and DP(i, FALSE) for each i. The recurrence relation has\nDP(i, b) dependent only on values DP(j, b) for j < i, so increasing order will give us\nwhat we want.\n(e) [3 points] If you were given the values of DP(i, b) for all 1 ≤i ≤n and all b ∈\n{TRUE, FALSE}, how could you use those values to compute the length of the longest\nalternating subsequence of x1, x2, . . . , xn?\n\n6.006 Final Exam Solutions\nName\nSolution:\nThere were multiple acceptable answers here. It's sufficient to either take\nthe maximum of DP(n, TRUE) and DP(n, FALSE), or to take the maximum over all\nvalues in the table.\n(f) [2 points] When combined, parts (b) through (e) can be used to write an algorithm\nsuch as the following:\nLONGESTALTERNATINGSUBSEQUENCE(x1, . . . , xn)\ninitialize table T\nfor each subproblem (i, b), in the order given by part (d)\nif (i, b) is a base case\nuse part (c) to compute DP(i, b)\nelse\nuse part (b) to compute DP(i, b)\nstore the computed value of DP(i, b) in the table T\nuse part (e) to find the length of the overall longest subsequence\nAnalyze the running time of this algorithm, given your answers to the questions above.\nSolution:\nComputing the recurrence for DP(i, b) takes time Θ(i). When we sum\nthis up over the values of i ranging from 1 to n, we get Θ(n2) for our running-time.\nNote, however, that what mattered for this question was correctly analyzing the run-\ntime for the recurrence relation you gave, so answers of O(n2) would be marked wrong\n(asymptotically loose) if the recurrence relation given actually resulted in a runtime of\nΘ(n).\n\n6.006 Final Exam Solutions\nName\nProblem 9.\nParen Puzzle [15 points]\nYour local school newspaper, The TEX, has started publishing puzzles of the following form:\nParenthesize 6 + 0 · 6\nParenthesize 0.1 · 0.1 + 0.1\nto maximize the outcome.\nto maximize the outcome.\nWrong answer: 6 + (0 · 6) = 6 + 0 = 6.\nWrong answer: 0.1 · (0.1 + 0.1) = 0.1 · 0.2 = 0.02.\nRight answer: (6 + 0) · 6 = 6 · 6 = 36.\nRight answer: (0.1 · 0.1) + 0.1 = 0.01 + 0.1 = 0.11.\nTo save yourself from tedium, but still impress your friends, you decide to implement an algorithm\nto solve these puzzles. The input to your algorithm is a sequence x0, o0, x1, o1, . . . , xn-1, on-1, xn\nof n + 1 real numbers x0, x1, . . . , xn and n operators o0, o1, . . . , on-1. Each operator oi is either\naddition (+) or multiplication (·). Give a polynomial-time dynamic program for finding the optimal\n(maximum-outcome) parenthesization of the given expression, and analyze the running time.\nSolution:\nThe following dynamic program is the intended \"correct\" answer, though it ignores a\nsubtle issue detailed below (which only three students identified, and received bonus points for).\nIt is similar to the matrix-multiplication parenthesization dynamic program we saw in lecture, but\nwith a different recurrence.\n1. For subproblems, we use substrings xi, oi, . . . , oj\n1, xj, for each 0\n-\n≤i ≤j ≤n. Thus there are\nΘ(n2) subproblems.\n2. To solve DP[i, j], we guess which operation ok is outermost, where i ≤k < j. There are\nj -i = O(n) choices for this guess.\n3. The resulting recurrence relation is\nj\nDP[i, j] = max\n-1\nDP[i, k] ok DP[k + 1, j]\nk=i\n\n.\nThe base cases are\nDP[i, i] = xi.\nThe running time per subproblem is O(n).\n4. The dynamic program uses either recursion plus memoization, or bottom-up table construction.\nA suitable acyclic order is by increasing length lof substring, i.e.,\nfor l= 0, 1, . . . , n:\nfor i = 0, 1, . . . , n -l:\nj = i + l\n5. The value of the original problem is given by DP[0, n]. To actually reconstruct the parenthe-\nsization, we can remember and follow parent pointers (the argmax in addition to each max). The\noverall running time is\nΘ(n2) · O(n) = O(n3).\n\n6.006 Final Exam Solutions\nName\nThe subtle issue is that this dynamic program assumes that, in order to maximize the sum or product\nof two numbers, we aim to maximize the two arguments. This assumption is true if the numbers\nare all nonnegative, as in the examples. If some numbers can be negative, however, then it is not so\neasy to maximize the product of two numbers. If both of the numbers are negative, so the product is\nnegative, then the goal is to minimize both numbers (i.e., maximizing their absolute values); but if\nexactly one of the numbers is negative, so the product is negative, then maximization is equivalent\nto maximizing the negative number and minimizing the positive number (i.e., minimizing their\nabsolute values).\nTo deal with this issue, we can define two subproblems: DPmax[i, j] is the maximum possible\nvalue for the substring xi, . . . , xj, as above, while DPmin[i, j] is the minimum possible value for\nthe same substring. Instead of working out which of the two subproblems we need, we can simply\nguess among the four possibilities, and choose the best. The recurrence relation thus becomes\nj-1\nDPm[i, j] = m\nm\n\nDPm1[i, k] ok DPm2[k + 1, j] .\nk=i\nm1,m2∈{max,min}\n\nThe running time remains the same, up to constant factors.\n\n6.006 Final Exam Solutions\nName\nProblem 10.\nSorting Fluff [20 points] (5 parts)\nIn your latest dream, you find yourself in a prison in the sky. In order to be released, you must\norder N balls of fluff according to their weights. Fluff is really light, so weighing the balls requires\ngreat care. Your prison cell has the following instruments:\n- A magic balance scale with 3 pans. When given 3 balls of fluff, the scale will point out the\nball with the median weight. The scale only works reliably when each pan has exactly 1 ball\nof fluff in it. Let MEDIAN(x, y, z) be the result of weighing balls x, y and z, which is the\nball with the median weight. If MEDIAN(x, y, z) = y, that means that either x < y < z or\nz < y < x.\n- A high-precision classical balance scale. This scale takes 2 balls of fluff, and points out which\nball is lighter; however, because fluff is very light, the scale can only distinguish between the\noverall lightest and the overall heaviest balls of fluff. Comparing any other balls will not\nyield reliable results. Let LIGHTEST(a, b) be the result of weighing balls a and b. If a is the\nlightest ball and b is the heaviest ball, LIGHTEST(a, b) = a. Conversely, if a is the heaviest\nball and b is the lightest ball, LIGHTEST(a, b) = b. Otherwise, LIGHTEST(a, b)'s return value\nis unreliable.\nOn the bright side, you can assume that all N balls have different weights. Naturally, you want to\nsort the balls using as few weighings as possible, so you can escape your dream quickly and wake\nup before 4:30pm!\nTo ponder this challenge, you take a nap and enter a second dream within your first dream. In the\nsecond dream, a fairy shows you the lightest and the heaviest balls of fluff, but she doesn't tell you\nwhich is which.\n(a) [2 points] Give a quick example to argue that you cannot use MEDIAN alone to\ndistinguish between the lightest and the heaviest ball, but that LIGHTEST can let you\ndistinguish.\nSolution:\nSuppose we have N = 2, so we have 2 balls, a and b. In order to sort\nthem, we need to decide if a < b or a > b. We can't even use MEDIAN because we\ndon't have 3 balls.\n\n6.006 Final Exam Solutions\nName\n(b) [4 points]\nGiven l, the lightest ball l pointed out by the fairy, use O(1) calls to\nMEDIAN to implement LIGHTER(a, b), which returns TRUE if ball a is lighter than\nball b, and FALSE otherwise.\nSolution:\nLIGHTER(a, b)\nif a == l\nreturn a\nif b == l\nreturn b\nif MEDIAN(l, a, b) == a\nreturn a\nelse\nreturn b\nAfter waking up from your second dream and returning to the first dream, you realize that there is\nno fairy. Solve the problem parts below without the information that the fairy would have given\nyou.\n(c) [6 points] Give an algorithm that uses O(N) calls to MEDIAN to find the heaviest\nand lightest balls of fluff, without identifying which is the heaviest and which is the\nlightest.\n\n6.006 Final Exam Solutions\nName\nSolution:\nThe pseudo-code below starts out by weighing the first 3 balls, and repeat-\nedly replaces the median with a new ball, until the balls runs out. The two remaining\nballs must be the extremes, because an extreme will never be a median, and therefore\nwill never be eliminated.\nEXTREMES(b, N)\nx, y = b1, b2\nfor i ∈3 . . . N\nz = bi\nm = MEDIAN(x, y, z)\n// Set x and y to non-median balls\nif x == m\nx, y = y, z\nif y == m\ny = z\nreturn (x, y)\nIt is not sufficient to call MEDIAN on all 3 groups of adjacent balls and hope that it\nwill rule out all the balls except for the two extremes. Example: given 4 balls with\nweights 3471, MEDIAN would point at the 2nd ball twice.\n\n6.006 Final Exam Solutions\nName\n(d) [2 points] Explain how the previous parts should be put together to sort the N balls\nof fluff using O(N log N) calls to MEDIAN and O(1) calls to LIGHTEST.\nSolution:\nCall EXTREMES (the answer to part c) to obtain the lightest and heaviest\nballs, then call LIGHTEST to obtain the lightest ball. Last, use LIGHTER (the answer\nto part b) as the comparison operator in a fast (O(N log N) time) comparison-based\nsorting algorithm.\nOut of the algorithms taught in 6.006, insertion sort with binary search makes the\nfewest comparisons. Other acceptable answers are merge-sort and heap-sort, as they\nall use O(N log N) comparisons.\n(e) [6 points] Argue that you need at least Ω(N log N) calls to MEDIAN to sort the N\nfluff balls.\nSolution:\nThe argument below closely follows the proof of the Ω(N log N) lower\nbound for comparison-based sorting.\nA call to MEDIAN has 3 possible outcomes, so a decision tree based on MEDIAN\ncalls would have a branching factor of 3. There are N! possible ball permutations,\nso the decision tree needs Ω(log3 N!) = Ω(log N!) = Ω(N log N) levels to cover all\npossible N! permutations.\nLOWEST only provides useful information if it is called once, and it reduces the pos-\nsible permutations to N!\n2 . This doesn't change the result above, because the constant\nfactor gets absorbed by the asymptotic notation.\nThe lower bound obtained from comparison-based sorting cannot be used without ar-\ngument, because it is not obvious that this problem is harder than comparison-based\nsorting. To use this bound correctly, a solution would have to prove that comparison-\nbased sorting can be reduced to this problem, by implementing MEDIAN and LIGHTEST\nwith O(1) comparisons each.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/f9f62741d89fcdfa5836f2bf97721798_MIT6_006F11_quiz1.pdf",
      "content": "Introduction to Algorithms\nOctober 18, 2011\nMassachusetts Institute of Technology\n6.006 Fall 2011\nProfessors Erik Demaine and Srini Devadas\nQuiz 1\nQuiz 1\n- Do not open this quiz booklet until directed to do so. Read all the instructions on this page.\n- When the quiz begins, write your name on every page of this quiz booklet.\n- You have 120 minutes to earn 120 points. Do not spend too much time on any one problem.\nRead them all first, and attack them in the order that allows you to make the most progress.\n- This quiz is closed book. You may use one 81 ′′\n×\n′′ or A4 crib sheet (both sides). No\ncalculators or programmable devices are permitted. No cell phones or other communications\ndevices are permitted.\n- Write your solutions in the space provided. If you need more space, write on the back of the\nsheet containing the problem. Pages may be separated for grading.\n- Do not waste time and paper rederiving facts that we have studied. It is sufficient to cite\nknown results.\n- When writing an algorithm, a clear description in English will suffice. Pseudo-code is not\nrequired.\n- When asked for an algorithm, your algorithm should have the time complexity specified in\nthe problem with a correct analysis. If you cannot find such an algorithm, you will generally\nreceive partial credit for a slower algorithm if you analyze your algorithm correctly.\n- Show your work, as partial credit will be given. You will be graded not only on the correct-\nness of your answer, but also on the clarity with which you express it. Be neat.\nGood luck!\n-\nProblem\nParts\nPoints\nGrade\nGrader\nTotal\nName:\nWed/Fri\nYing\nKevin\nSarah\nYafim\nVictor\nRecitation:\n10,\n11 AM\n11 AM\n12,\n1 PM\n12 PM\n2,\n3 PM\n\n6.006 Quiz 1\nName\nProblem 1.\n[2 points] Write your name on top of each page.\nProblem 2.\nAsymptotics & Recurrences [20 points] (3 parts)\n(a) [10 points] Rank the following functions by increasing order of growth. That is, find\nany arrangement g1, g2, g3, g4, g5, g6, g7, g8 of the functions satisfying g1 = O(g2),\ng2 = O(g3), g3 = O(g4), g4 = O(g5), g5 = O(g6), g6 = O(g7), g7 = O(g8).\nπ\nn\nn\n√\nf1(n) = n\nf2(n) = π\nf3(n) =\nn\n\nf\n\n4(n) =\np\nn\nf5(n) =\n\nlog4\n-\n\nf\nn\n5(log n)2\n4 n\n6(n) = 2\nf7(n) = n\nf8(n) = n\nn\n\n(b) [5 points] Find a solution to the recurrence T(n) = T(n) + T(2n) + Θ(n)\n.\n\n6.006 Quiz 1\nName\n(c) [5 points] Find an asymptotic solution of the following recurrence. Express your\nanswer using Θ-notation, and give a brief justification.\nT(n) = log n + T\n√n\n\n6.006 Quiz 1\nName\nProblem 3.\nTrue/False [18 points] (9 parts)\nCircle (T)rue or (F)alse. You don't need to justify your choice.\n(a) T F\n[2 points] Binary insertion sorting (insertion sort that uses binary search to find\neach insertion point) requires O(n log n) total operations.\n(b) T F\n[2 points] In the merge-sort execution tree, roughly the same amount of work is\ndone at each level of the tree.\n(c) T F\n[2 points] In a BST, we can find the next smallest element to a given element in\nO(1) time.\n(d) T F\n[2 points] In an AVL tree, during the insert operation there are at most two\nrotations needed.\n(e) T F\n[2 points] Counting sort is a stable, in-place sorting algorithm.\n(f) T F\n[2 points] In a min-heap, the next largest element of any element can be found\nin O(log n) time.\n(g) T F\n[2 points] The multiplication method satisfies the simple uniform hashing as-\nsumption.\n(h) T F\n[2 points] Double hashing satisfies the uniform hashing assumption.\n(i) T F\n[2 points] Python generators can be used to iterate over potentially infinite count-\nable sets with O(1) memory.\n\n6.006 Quiz 1\nName\nProblem 4.\nPeak Finding (again!) [20 points] (2 parts)\nWhen Alyssa P. Hacker did the first 6.006 problem set this semester, she didn't particularly like\nany of the 2-D peak-finding algorithms. A peak is defined as any location that has a value at least\nas large as all four of its neighbors.\nAlyssa is excited about the following algorithm:\n1. Examine all of the values in the first, middle, and last columns of the matrix to find the\nmaximum location l.\n2. If lis a peak within the current subproblem, return it. Otherwise, it must have a neighbor p\nthat is strictly greater.\n3. If p lies to the left of the central column, restrict the problem matrix to the left half of the ma-\ntrix, including the first and middle columns. If p lies to the right of the central column, restrict\nthe problem matrix to the right half of the matrix, including the middle and last columns.\n4. Repeat steps 1 through 3 looking at the first, middle, and last rows.\n5. Repeat steps 1 through 4 until a peak is found.\nConsider the 5 × 5 example depicted below. On this example, the algorithm initially examines the\nfirst, third, and fifth columns, and finds the maximum in all three. In this case, the maximum is the\nnumber 4. The number 4 is not a peak, due to its neighbor 5.\nThe number 5 is to the left of the middle column, so we restrict our view to just the left half of the\nmatrix. (Note that we include both the first and middle columns.) Because we examined columns\nin the previous step, we now examine the first, middle, and last rows of the submatrix. The largest\nvalue still visible in those rows is 6, which is a peak within the subproblem. Hence, the algorithm\nwill find the peak 6.\n\n6.006 Quiz 1\nName\n(a) [5 points] What is the worst-case runtime of Alyssa's algorithm on an m × n matrix\n(m rows, n columns), in big-Θ notation? Give a brief justification for your answer.\n(b) [15 points] Does Alyssa's algorithm return a peak in all cases? If so, give a short\nproof of correctness. Otherwise, provide a counterexample for the algorithm.\n\n6.006 Quiz 1\nName\nProblem 5.\nWho Let The Zombies Out? [20 points] (2 parts)\nIn an attempt to take over Earth, evil aliens have contaminated certain water supplies with a virus\nthat transforms humans into flesh-craving zombies. To track down the aliens, the Center for Dis-\nease Control needs to determine the epicenters of the outbreak--which water supplies have been\ncontaminated. There are n potentially infected cities C = {c1, c2, . . . , cn}, but the FBI is certain\nthat only k cities have contaminated water supplies.\nUnfortunately, the only known test to determine the contamination of a city's water supply is to\nserve some of that water to a human and see whether they turn ravenous. Several brave volunteers\nhave offered to undergo such an experiment, but they are only willing to try their luck once. Each\nvolunteer is willing to drink a single glass of water that mixes together samples of water from any\nsubset C′ ⊆C of the n cities, which reveals whether at least one city in C′ had contaminated\nwater.\nYour goal is to use the fewest possible experiments (volunteers) in order to determine, for each city\nci, whether its water was contaminated, under the assumption that exactly k cities have contami-\nnated water. You can design each experiment based on the results of all preceding experiments.\n(a) [10 points]\nYou observe that, as in the comparison model, any algorithm can be\nviewed as a decision tree where a node corresponds to an experiment with two out-\ncomes (contaminated or not) and thus two children. Prove a lower bound of Ω(k lg n)\nk\non the number of experiments that must be done to save the world. Assume that\nlg x! ∼x lg x and that lg(n -k) ∼lg n (which is reasonable when k < 0.99n).\n\n6.006 Quiz 1\nName\n(b) [10 points] Save the world by designing an algorithm to determine which k of the n\ncities have contaminated water supplies using O(k lg n) experiments. Describe and\nanalyze your algorithm.\n\n6.006 Quiz 1\nName\nProblem 6.\nShopping Madness [20 points] (3 parts)\nBen Bitdiddle was peer-pressured into signing up for the tryouts in a shopping reality TV show,\nand he needs your help to make it past the first round. In order to qualify, Ben must browse a\nstore's inventory, which has N items with different positive prices P[1], P[2], . . . , P[N], and the\nchallenge is to spend exactly S dollars on exactly K items, where K is a small even integer. Ben\ncan buy the same item multiple times. For example, 3 brooms and 2 wizard hats add up to 5 items.\nIn your solutions below, you may use a subroutine MULTISETS(k, T) which iterates over all the\nk-element multisets (like subsets, except the same elements can show up multiple times) of a set\nT, in time O(k · |T|k), using O(k) total space. Note that if your code holds onto the results of\nMULTISETS, it may end up using more than O(k) space.\n(a) [5 points] Write pseudo-code for a data structure that supports the following two\noperations.\nINIT(N, K, P) -- preprocesses the P[1 . . . N] array of prices, in O(K·N K) expected\ntime, using O(K · N K) space, to be able to answer the query below.\nBAG(S) -- in O(1) expected time, determines whether K of the items have prices\nsumming to S, and if so, returns K indices b1, b\nK\n2, . . . , bK such that S = P\ni=1 P[bi].\n\n6.006 Quiz 1\nName\n(b) [10 points] Write pseudo-code for a function PWN-CONTEST(N, S, K, P) that deter-\nmines whether K of the items have prices summing to S, and if so, returns K indices\nb1, b\nK\n2, . . . , bK such that S = P\ni=1 P[bi]. Unlike part (a), PWN-CONTEST should run\nin O(K · N K/2) and use O(K · N K/2) space.\n\n6.006 Quiz 1\nName\n(c) [5 points] Analyze the running time of your pseudo-code for the previous part.\n\n6.006 Quiz 1\nName\nProblem 7.\nWhen I Was Your Age... [20 points] (2 parts)\nIn order to design a new joke for your standup comedy routine, you've collected n distinct mea-\nsurements into an array A[1 . . . n], where A[i] represents a measurement at time i. Your goal is to\nfind the longest timespan i . . . j, i.e., maximize j -i, such that A[i] < A[j]. 1 Note that the values\nin between A[i] and A[j] do not matter. As an example, consider the following array A[1 . . . 7]:\nA[1] = 14\nA[2] = 6\nA[3] = 8\nA[4] = 1\nA[5] = 12\nA[6] = 7\nA[7] = 5\nYour algorithm should return a span of 4 since A[2] = 6 and A[6] = 7. The next biggest span is\nA[4] = 1 to A[7] = 5.\n(a) [5 points]\nGive an O(n)-time algorithm to compute the minimums of the prefix\nA[1 . . . k] for each k, and store in MA[k]: MA[k] = mink\ni=1 A[i].\n(b) [15 points] Using the MA[i] computed above, give an O(n log n)-time algorithm to\nmaximize j -i subject to A[i] < A[j].\nHint: The MA is a sorted array.\n1The joke could be along these lines: \"You thought time j was bad with A[j]? Back in time i, we only had A[i]!\"\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 1 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/14dca83afa6ba2239ff765bbcf0642a3_MIT6_006F11_quiz1_sol.pdf",
      "content": "Introduction to Algorithms\nOctober 13, 2011\nMassachusetts Institute of Technology\n6.006 Fall 2011\nProfessors Erik Demaine and Srini Devadas\nQuiz 1 Solutions\nQuiz 1 Solutions\nProblem 1.\n[2 points] Write your name on top of each page.\nProblem 2.\nAsymptotics & Recurrences [20 points] (3 parts)\n(a) [10 points] Rank the following functions by increasing order of growth. That is, find\nany arrangement g1, g2, g3, g4, g5, g6, g7, g8 of the functions satisfying g1 = O(g2),\ng2 = O(g3), g3 = O(g4), g4 = O(g5), g5 = O(g6), g6 = O(g7), g7 = O(g8).\nn\n√\nf1(n) = nπ\nf2(n) = πn\nf3(n) =\n\nf4(n) =\n\nn\nn\nn\nf (\nlog\n5 n) =\n\nf6(n) = 2\nn\nf7(n) = n5(log n)\nf8(n) = n4\nn\n\n-4\n\nSolution:\nf1(n), f5(n), f3(n), f8(n), f7(n), f6(n), f4(n), f2(n)\nScoring:\nWe computed the score for this problem as ROUND(10 · L\n)\nN\n-1\n-1 , where N is\nthe number of functions (N = 8 for this instance) and L is the length of the longest\ncommon subsequence between our solution and the student's answer.\nThe intuition behind the longest common subsequence is that we want to cross out as\nfew functions as possible from a student's answer, such that the remaining functions\nwill be correctly ordered. Who said the 6.006 staff isn't nice?\nWe used L-1\nN\n1 to normalize the scores, because a completely wrong answer will still\n-\nshare a common subsequence of length 1 with the correct answer.\nThe longest common subsequence can be computed using Dynamic Programming,\nwhich will be taught in 6.006 towards the end of the term.\n(b) [5 points] Find a solution to the recurrence T(n) = T(n) + T(2n) + Θ(n)\n.\nSolution:\nDraw recursion tree. At each level, do Θ(n) work. Number of levels is\nlog3/2 n = Θ(lg n), so guess T(n) = Θ(n lg n) and use the substitution method to\nverify guess.\n\n6.006 Quiz 1 Solutions\nName\n(c) [5 points] Find an asymptotic solution of the following recurrence. Express your\nanswer using Θ-notation, and give a brief justification.\nT(n) = log n + T √\n\nn\n\nSolution:\nT(n) = Θ(log n).\nTo see this, note that if we expand out T(n) by continually replacing T(n) with its\nformula, we get:\nT(n) = log n + log √n + log\n√n + log\n√n + . . .\n= log n + 1 log n + 1 log\n√n + 1 log\n√n + . . .\n= log n + 1 log n + 1 log n + 1\n\nlog n + . . .\n= Θ(log n)\n\n6.006 Quiz 1 Solutions\nName\nProblem 3.\nTrue/False [18 points] (9 parts)\nCircle (T)rue or (F)alse. You don't need to justify your choice.\n(a) T F\n[2 points] Binary insertion sorting (insertion sort that uses binary search to find\neach insertion point) requires O(n log n) total operations.\nSolution:\nFalse. While binary insertion sorting improves the time it takes to\nfind the right position for the next element being inserted, it may still take O(n)\ntime to perform the swaps necessary to shift it into place. This results in an O(n2)\nrunning time, the same as that of insertion sort.\n(b) T F\n[2 points] In the merge-sort execution tree, roughly the same amount of work is\ndone at each level of the tree.\nSolution:\nTrue. At the top level, roughly n work is done to merge all n ele-\nments. At the next level, there are two branches, each doing roughly n/2 work to\nmerge n/2 elements. In total, roughly n work is done on that level. This pattern\ncontinues on through to the leaves, where a constant amount of work is done on\nn leaves, resulting in roughly n work being done on the leaf level, as well.\n(c) T F\n[2 points] In a BST, we can find the next smallest element to a given element in\nO(1) time.\nSolution:\nFalse. Finding the next smallest element, the predecessor, may re-\nquire traveling down the height of the tree, making the running time O(h).\n(d) T F\n[2 points] In an AVL tree, during the insert operation there are at most two\nrotations needed.\nSolution:\nTrue. The AVL property is restored on every operation. Therefore,\ninserting another item will require at most two rotations to restore the balance.\n(e) T F\n[2 points] Counting sort is a stable, in-place sorting algorithm.\nSolution:\nFalse. Counting sort is stable. It is not in-place, however, since we\nmust make additional space to store the counts of the various elements. This\nspace requirement grows as the size of the input increases. Additionally, we have\nto make a separate output array to produce the answer using counting sort.\n(f) T F\n[2 points] In a min-heap, the next largest element of any element can be found\nin O(log n) time.\n\n6.006 Quiz 1 Solutions\nName\nSolution:\nFalse. A min-heap cannot provide the next largest element in O(log n)\ntime. To find the next largest element, we need to do a linear, O(n), search\nthrough the heap's array.\n(g) T F\n[2 points] The multiplication method satisfies the simple uniform hashing as-\nsumption.\nSolution:\nFalse. We don't really know of hash functions that satisfy the simple\nuniform hashing assumption.\n(h) T F\n[2 points] Double hashing satisfies the uniform hashing assumption.\nSolution:\nFalse. The notes state that double hashing 'comes close.' Double\nhashing only provides n2 permutations, not n!.\n(i) T F\n[2 points] Python generators can be used to iterate over potentially infinite count-\nable sets with O(1) memory.\nSolution:\nTrue. Python generators do not require the whole set to reside in\nmemory to iterate over it, making this assertion true.\n\n6.006 Quiz 1 Solutions\nName\nProblem 4.\nPeak Finding (again!) [20 points] (2 parts)\nWhen Alyssa P. Hacker did the first 6.006 problem set this semester, she didn't particularly like\nany of the 2-D peak-finding algorithms. A peak is defined as any location that has a value at least\nas large as all four of its neighbors.\nAlyssa is excited about the following algorithm:\n1. Examine all of the values in the first, middle, and last columns of the matrix to find the\nmaximum location l.\n2. If lis a peak within the current subproblem, return it. Otherwise, it must have a neighbor p\nthat is strictly greater.\n3. If p lies to the left of the central column, restrict the problem matrix to the left half of the ma-\ntrix, including the first and middle columns. If p lies to the right of the central column, restrict\nthe problem matrix to the right half of the matrix, including the middle and last columns.\n4. Repeat steps 1 through 3 looking at the first, middle, and last rows.\n5. Repeat steps 1 through 4 until a peak is found.\nConsider the 5 × 5 example depicted below. On this example, the algorithm initially examines the\nfirst, third, and fifth columns, and finds the maximum in all three. In this case, the maximum is the\nnumber 4. The number 4 is not a peak, due to its neighbor 5.\nThe number 5 is to the left of the middle column, so we restrict our view to just the left half of the\nmatrix. (Note that we include both the first and middle columns.) Because we examined columns\nin the previous step, we now examine the first, middle, and last rows of the submatrix. The largest\nvalue still visible in those rows is 6, which is a peak within the subproblem. Hence, the algorithm\nwill find the peak 6.\n\n6.006 Quiz 1 Solutions\nName\n(a) [5 points] What is the worst-case runtime of Alyssa's algorithm on an m × n matrix\n(m rows, n columns), in big-Θ notation? Give a brief justification for your answer.\nSolution:\nLet S(m, n) be the runtime of the algorithm when run on an m×n matrix\nstarting with columns. Let T(m, n) be the runtime of the algorithm when run on\nan m × n matrix starting with rows. Then S(m, n) ≤T(m, n/2 + 1) + Θ(m) and\nT(m, n) ≤S(m/2+1, n)+Θ(n). Hence, S(m, n) ≤Θ(m+n)+S(m/2+1, n/2+1).\nWhen we resolve this recurrence relation, we get S(m, n) = O(m + n). In the case\nof a square n × n matrix, we get an asymptotic runtime of Θ(n).\n(b) [15 points] Does Alyssa's algorithm return a peak in all cases? If so, give a short\nproof of correctness. Otherwise, provide a counterexample for the algorithm.\nSolution:\nThe following is an example of a matrix where the algorithm will return\nthe wrong value:\n\n6.006 Quiz 1 Solutions\nName\nProblem 5.\nWho Let The Zombies Out? [20 points] (2 parts)\nIn an attempt to take over Earth, evil aliens have contaminated certain water supplies with a virus\nthat transforms humans into flesh-craving zombies. To track down the aliens, the Center for Dis-\nease Control needs to determine the epicenters of the outbreak--which water supplies have been\ncontaminated. There are n potentially infected cities C = {c1, c2, . . . , cn}, but the FBI is certain\nthat only k cities have contaminated water supplies.\nUnfortunately, the only known test to determine the contamination of a city's water supply is to\nserve some of that water to a human and see whether they turn ravenous. Several brave volunteers\nhave offered to undergo such an experiment, but they are only willing to try their luck once. Each\nvolunteer is willing to drink a single glass of water that mixes together samples of water from any\nsubset C′ ⊆C of the n cities, which reveals whether at least one city in C′ had contaminated\nwater.\nYour goal is to use the fewest possible experiments (volunteers) in order to determine, for each city\nci, whether its water was contaminated, under the assumption that exactly k cities have contami-\nnated water. You can design each experiment based on the results of all preceding experiments.\n(a) [10 points]\nYou observe that, as in the comparison model, any algorithm can be\nviewed as a decision tree where a node corresponds to an experiment with two out-\ncomes (contaminated or not) and thus two children. Prove a lower bound of Ω(k lg n)\nk\non the number of experiments that must be done to save the world. Assume that\nlg x! ∼x lg x and that lg(n -k) ∼lg n (which is reasonable when k < 0.99n).\nSolution:\nThe number of possible outcomes--which cities are contaminated--is\nn\nk\n\n. Thus any decision tree must have at least\nn\nk\nleaves. Because a decision tree\nis binary, it must therefore have height at least\n\nlg\nn\nn!\n= lg\n,\nk\nk!(n -k)!\nwhich by the first assumption is\n∼n lg n -k lg k -(n -k) lg(n -k) = n[lg n -lg(n -k)] + k[lg(n -k) -lg k],\nwhich by the second assumption is\nn\n∼k[lg n -lg k] = k lg\n,\nk\nwhich is our desired lower bound.\n\n6.006 Quiz 1 Solutions\nName\n(b) [10 points] Save the world by designing an algorithm to determine which k of the n\ncities have contaminated water supplies using O(k lg n) experiments. Describe and\nanalyze your algorithm.\nSolution:\nThe algorithm is based on divide and conquer: divide the n cities into two\ngroups of size n/2; test each group for contamination (using two experiments); and\nrecurse into each contaminated group. The recursion tree has exactly k leaves, and the\nheight of the tree is at most lg n, so the number of internal nodes leading to the leaves\nis at most k lg n. Each internal node costs 2, for a total cost of O(k lg n).\nIn fact, it is possible to prove an O(k lg n)\nk bound on the same algorithm. To minimize\nthe number of shared nodes among the k paths from root to leaves, the worst case is\nwhen the recursion tree branches for the first lg k levels (to get enough leaves), and\nthen has k straight paths for the number of levels: lg n\nn\n-lg k = lg n\nk. There are O(k)\nnodes in the top branching, and O(k lg\n)\nk nodes in the bottom paths.\n\n6.006 Quiz 1 Solutions\nName\nProblem 6.\nShopping Madness [20 points] (3 parts)\nBen Bitdiddle was peer-pressured into signing up for the tryouts in a shopping reality TV show,\nand he needs your help to make it past the first round. In order to qualify, Ben must browse a\nstore's inventory, which has N items with different positive prices P[1], P[2], . . . , P[N], and the\nchallenge is to spend exactly S dollars on exactly K items, where K is a small even integer.\nIn your solutions below, you may use a subroutine SUBSETS(k, T) which iterates over all the k-\nelement subsets of a set T, in time O(k · |T|k), using O(k) total space. Note that if your code holds\nonto the results of SUBSETS, it may end up using more than O(k) space.\n(a) [5 points] Write pseudo-code for a data structure that supports the following two\noperations.\nINIT(N, K, P) -- preprocesses the P[1 . . . N] array of prices, in O(K·N K) expected\ntime, using O(K · N K) space, to be able to answer the query below.\nBAG(S) -- in O(1) expected time, determines whether K of the items have prices\nsumming to S, and if so, returns K indices b1, b2, . . . , bK such that S = K\ni=1 P[bi].\nSolution:\nINIT(N, K, p)\nh ←empty hash table\nfor c ←SUBSETS(K, {1 . . . N\nK\n})\ndo s ←\ni=1 Pci\nh[s] ←c\nBAG(S)\nif S ∈h\nthen return h[S]\nelse return NIL\n\n6.006 Quiz 1 Solutions\nName\n(b) [10 points] Write pseudo-code for a function PWN-CONTEST(N, S, K, P) that deter-\nmines whether K of the items have prices summing to S, and if so, returns K indices\nb1, b\nK\n2, . . . , bK such that S =\ni=1 P[bi]. Unlike part (a), PWN-CONTEST should run\nin O(K · N K/2) and use O(K · N K/2) space.\nSolution:\nPWN-CONTEST(N, S, K, p)\nh ←empty hash table\nfor c ←SUBSETS(K/2,\nK/\n{1 . . . N})\ndo s ←\ni=1 Pci\nh[s] ←c\nfor c ←SUBSETS(K/2, {1 . . . N})\ndo s ←S - K/2\ni=1 Pci\nif s ∈h\nthen return c + h[s]\nreturn NIL\n\n6.006 Quiz 1 Solutions\nName\n(c) [5 points] Analyze the running time of your pseudo-code for the previous part.\nSolution:\nThe following table shows a line-by-line analysis of our pseudo-code.\nLine\nTime\nNumber of iterations\nTotal time\nO(1)\nO(1)\nK · N K/2\nK · N K/2\nO(K)\nN K/2\nK N K/2\nO(K)\nN K/2\n·\nK · N K/2\nK · N K/2\nK · N K/2\nO(K)\nN K/2\nK · N K/2\nO(1)\nN K/2\nN K/2\nO(K)\nO(K)\nO(1)\nO(1)\nThe total running time is the maximum in the \"Total time\" column, which is K ·N K/2,\nas requested.\n\n6.006 Quiz 1 Solutions\nName\nProblem 7.\nWhen I Was Your Age... [20 points] (2 parts)\nIn order to design a new joke for your standup comedy routine, you've collected n distinct mea-\nsurements into an array A[1 . . . n], where A[i] represents a measurement at time i. Your goal is to\nfind the longest timespan i . . . j, i.e., maximize j -i, such that A[i] < A[j]. 1 Note that the values\nin between A[i] and A[j] do not matter. As an example, consider the following array A[1 . . . 7]:\nA[1] = 14\nA[2] = 6\nA[3] = 8\nA[4] = 1\nA[5] = 12\nA[6] = 7\nA[7] = 5\nYour algorithm should return a span of 4 since A[2] = 6 and A[6] = 7. The next biggest span is\nA[4] = 1 to A[7] = 5.\n(a) [5 points]\nGive an O(n)-time algorithm to compute the minimums of the prefix\nA[1 . . . k] for each k, and store in MA[k]: MA[k] = mink\ni=1 A[i].\nSolution:\nMA[i] can be computed incrementally. Initially, MA[1] = A[1]. MA[j] =\nmin(A[j], MA[j -1]). This takes O(n) time.\n(b) [15 points] Using the MA[i] computed above, give an O(n log n)-time algorithm to\nmaximize j -i subject to A[i] < A[j].\nHint: The MA is a sorted array.\nSolution:\nConsider a single element A[j]. If we have MA[1 . . . j -1] we want\nto find an index i such that MA[i] < A[j] but MA[i -1] ≥A[j]. This implies that\nMA[i] = A[i] is the unique minimum element of A[1 . . . i]. This gives us an A[i], A[j]\npair and we can compute j -i for this pair.\nWe do a binary search over the indices [1, j-1]. We start with j/2, and we test whether\nMA[j/2] < A[j] or not. If MA[j/2] is less than A[j], we recurse on MA[1 . . . (j/2-\n1)]. If MA[j/2] is larger than A[j], we recurse on MA[j/2 + 1 . . . j -1]. We halve\nthe number of possible indices for i each time, until we find the right i for this j. This\ntakes O(log n) time. We do this for each j - hence the O(n log n). After we have the\nright i, j pairs, we pick the one that maximizes j -i.\n1The joke could be along these lines: \"You thought time j was bad with A[j]? Back in time i, we only had A[i]!\"\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/083becbc6a279bd02d2bef9d606e508c_MIT6_006F11_quiz2.pdf",
      "content": "Introduction to Algorithms\nNovember 17, 2011\nMassachusetts Institute of Technology\n6.006 Fall 2011\nProfessors Erik Demaine and Srini Devadas\nQuiz 2\nQuiz 2\n- Do not open this quiz booklet until directed to do so. Read all the instructions on this page.\n- When the quiz begins, write your name on every page of this quiz booklet.\n- You have 120 minutes to earn 120 points. Do not spend too much time on any one problem.\nRead them all first, and attack them in the order that allows you to make the most progress.\n- This quiz is closed book. You may use two 81 ′′\n2 ×\n′′ or A4 crib sheets (both sides). No\ncalculators or programmable devices are permitted. No cell phones or other communications\ndevices are permitted.\n- Write your solutions in the space provided. If you need more space, write on the back of the\nsheet containing the problem. Pages may be separated for grading.\n- Do not waste time and paper rederiving facts that we have studied. It is sufficient to cite\nknown results.\n- When writing an algorithm, a clear description in English will suffice. Pseudo-code is not\nrequired.\n- When asked for an algorithm, your algorithm should have the time complexity specified in\nthe problem with a correct analysis. If you cannot find such an algorithm, you will generally\nreceive partial credit for a slower algorithm if you analyze your algorithm correctly.\n- Show your work, as partial credit will be given. You will be graded not only on the correct-\nness of your answer, but also on the clarity with which you express it. Be neat.\nGood luck!\n-\nProblem\nParts\nPoints\nGrade\nGrader\nTotal\nName:\nWed/Fri\nYing\nKevin\nSarah\nYafim\nVictor\nRecitation:\n10,\n11 AM\n11 AM\n12,\n1 PM\n12 PM\n2,\n3 PM\n\n6.006 Quiz 2\nName\nProblem 1.\n[1 points] Write your name on top of each page.\nProblem 2.\nTrue/False [28 points] (14 parts)\nCircle (T)rue or (F)alse. You don't need to justify your choice.\n(a) T F\n[2 points] Computing √\n⌊\na⌋for an n-bit positive integer a can be done in O(lg n)\niterations of Newton's method.\n(b) T F\n[2 points] Suppose we want to solve a polynomial equation f(x) = 0. While\nour choice of initial approximation x0 will affect how quickly Newton's method\nconverges, it will always converge eventually.\n(c) T F\n[2 points] Karatsuba's integer multiplication algorithm always runs faster than\nthe grade-school integer multiplication algorithm.\n(d) T F\n[2 points] If we convert an n-digit base-256 number into base 2, the resulting\nnumber of digits is Θ(n2).\n(e) T F\n[2 points] In a weighted undirected graph G = (V, E, w), breadth-first search\nfrom a vertex s finds single-source shortest paths from s (via parent pointers) in\nO(V + E) time.\n(f) T F\n[2 points] In a weighted undirected tree G = (V, E, w), breadth-first search\nfrom a vertex s finds single-source shortest paths from s (via parent pointers) in\nO(V + E) time.\n(g) T F\n[2 points] In a weighted undirected tree G = (V, E, w), depth-first search from\na vertex s finds single-source shortest paths from s (via parent pointers) in O(V +\nE) time.\n(h) T F\n[2 points] If a graph represents tasks and their interdependencies (i.e., an edge\n(u, v) indicates that u must happen before v happens), then the breadth-first\nsearch order of vertices is a valid order in which to tackle the tasks.\n(i) T F\n[2 points] Dijkstra's shortest-path algorithm may relax an edge more than once\nin a graph with a cycle.\n(j) T F\n[2 points] Given a weighted directed graph G = (V, E, w) and a source s ∈V ,\nif G has a negative-weight cycle somewhere, then the Bellman-Ford algorithm\nwill necessarily compute an incorrect result for some δ(s, v).\n(k) T F\n[2 points] In a weighted directed graph G = (V, E, w) containing no zero- or\npositive-weight cycles, Bellman-Ford can find a longest (maximum-weight) path\nfrom vertex s to vertex t.\n(l) T F\n[2 points] In a weighted directed graph G = (V, E, w) containing a negative-\nweight cycle, running the Bellman-Ford algorithm from s will find a shortest\nacyclic path from s to a given destination vertex t.\n(m) T F [2 points] The bidirectional Dijkstra algorithm runs asymptotically faster than\nthe Dijkstra algorithm.\n\n6.006 Quiz 2\nName\n(n) T F\n[2 points] Given a weighted directed graph G = (V, E, w) and a shortest path p\nfrom s to t, if we doubled the weight of every edge to produce G′ = (V, E, w′),\nthen p is also a shortest path in G′.\n\n6.006 Quiz 2\nName\nProblem 3.\nMazeCraft [26 points] (5 parts)\nYou are playing SnowStorm's new video game, MazeCraft. Realizing that you can convert a maze\ninto a graph with vertices representing cells and edges representing passages, you want to use your\nnewly learned graph-search algorithms to navigate the maze. Consider the following converted\ngraph.\nA\nB\nC\nD\nF\nE\nG\nH\nFor the following questions, assume that the graph is represented using adjacency lists, and that all\nadjacency lists are sorted, i.e., the vertices in an adjacency list are always sorted alphabetically.\n(a) [4 points] Suppose that you want to find a path from A to H. If you use breadth-first\nsearch, write down the resulting path as a sequence of vertices.\n(b) [4 points] If you use depth-first search to find a path from A to H, write down the\nresulting path as a sequence of vertices.\n\n6.006 Quiz 2\nName\n(c) [6 points] To determine whether the maze has cycles or multiple paths to the same\ndestination, you decide to use the edge classification of depth-first search. Run depth-\nfirst search on the graph reproduced below, starting from vertex A, and label every\nedge with T if it's a tree edge, B if it's a back edge, F if it's a forward edge, and C if\nit's a cross edge.\nAs a reminder, recall that an edge (u, v) is\n- a tree edge (T) if v was first discovered by exploring edge (u, v) (tree edges form\nthe depth-first forest);\n- a back edge (B) if v is u's ancestor in a depth-first tree;\n- a forward edge (F) if v is u's descendant in a depth-first tree; and\n- a cross edge (C) if none of the above apply.\nA\nB\nC\nD\nF\nE\nG\nH\n\n6.006 Quiz 2\nName\n(d) [6 points] Now suppose that the passages in the maze are directional. Rerun depth-\nfirst search in the directed graph below and label the edges accordingly.\nA\nB\nC\nD\nF\nE\nG\nH\n\n6.006 Quiz 2\nName\n(e) [6 points] Suppose each passage in the maze causes a different amount of damage to\nyou in game. You change the graph to use weights to represent the damage caused by\neach edge. You then use Dijkstra's algorithm to find the path from A to H with the\nlowest possible damage. Write down the order in which vertices get removed from the\npriority queue when running Dijkstra's algorithm.\nA\nB\nC\nD\nF\nE\nG\nH\n\n6.006 Quiz 2\nName\nProblem 4.\nMalfunctioning Calculator [25 points] (5 parts)\nFormer 6.006 student Mallory Funke is at a math competition, but her calculator isn't working. It\nseems to work fine for whole numbers, but the numbers after the decimal point always seem to\nbe the sequence\nrepeated over and over again, making those digits useless. For one of the\nproblems, she has been asked to compute ⌊A3/4⌋for a few different integer values of A. Mal knows\nthat Newton's Method can be used to compute the square root or the cube root of an integer A. So\nas a first step in computing ⌊A3/4⌋, Mal wants to use Newton's Method to compute ⌊A1/4\n⌋. She\nthen plans to use that information to compute ⌊A /4⌋.\n(a) [5 points] Mal decides to use the function f(x) = x4 -A, because it has a root\nat x = A1/4. Use Newton's Method on f(x) to generate a formula for computing\nincreasingly accurate estimates of ⌊A1/4⌋. In other words, give a formula for the\nmore accurate estimate xi+1 in terms of a less accurate estimate xi. The formula you\nconstruct must use only addition, subtraction, multiplication, and division. (You do\nnot need to simplify the formula.)\n\n6.006 Quiz 2\nName\n(b) [5 points] Mal decides to use the technique from part (a) to compute the value B =\n⌊A1/4⌋. She then plans to compute ⌊A3/4⌋by calculating the value C = B3 = B·B·B.\nProvide an explanation of why this technique does not work.\nHint: Define α to be the fractional part of A1/4, so that B = A1/4 -α. What happens\nwhen you compute C = B3?\n(c) [5 points] Mal clearly needs a way to check her answer for ⌊A3/4⌋, using only integers.\nGiven a pair of positive integers A and C, explain how to check whether C ≤A3/4\nusing O(1) additions, subtractions, multiplications, and comparisons.\n(d) [5 points] Explain how to check whether C = ⌊A3/4⌋, again using only O(1) addi-\ntions, subtractions, multiplications, and comparisons.\nHint: Recall how the floor function is defined.\n\n6.006 Quiz 2\nName\n(e) [5 points] Give a brief description of an algorithm that takes as input a d-digit positive\ninteger A and computes ⌊A3/4⌋. The only arithmetic operations you can use are inte-\nger addition, integer subtraction, integer multiplication, integer division, and integer\ncomparison. Your algorithm should use Θ(lg d) arithmetic operations in total, but par-\ntial credit will be awarded for using Θ(d) arithmetic operations. For this question, you\nmay assume that Newton's Method has a quadratic rate of convergence for whatever\nfunction you devise.\n\n6.006 Quiz 2\nName\nProblem 5.\nThe Tourist [15 points]\nYour new startup, Bird Tours, brings people around Boston in a new aviation car that can both drive\nand fly. You've constructed a weighted directed graph G = (V, E, w) representing the best time to\ndrive or fly between various city sites (represented by vertices in V ). You've also written a history\nof Boston, which would be best described by visiting sites v0, v1, . . . , vk in that order.\nYour goal is to find the shortest path in G that visits v0, v1, . . . , vk in order, possibly visiting other\nvertices in between. (The path must have v0, v1, . . . , vk as a subsequence; the path is allowed to\nvisit a vertex more than once. For example, v0, v2, v1, v2, . . . , vk is legal.) To do the computation,\nyou've found an online service, Paths '\nR\nUs, that will compute the shortest path from a given\nsource s to a given target t in a given weighted graph, for the bargain price of $1. You see how to\nsolve the problem by paying $k, calling Paths '\nR\nUs with (v0, v1, G), (v1, v2, G), . . . , (vk-1, vk, G)\nand piecing together the paths. Describe how to solve the problem with only $1 by calling Paths\n'\nR\nUs with (s, t, G′) for a newly constructed graph G′ = (V ′, E′, w′), and converting the resulting\npath into a path in G.\n\n6.006 Quiz 2\nName\nProblem 6.\nFill 'Er Up! [25 points]\nYou are traveling by car from one city to another city. Unfortunately, you have a hole in your\ngas tank, and you have to refill your gas tank to travel across more than two roads. In addition,\nthere is a toll booth on every road that charges you for using that road. Your goal is to find the\nleast-expensive path from your start to your destination.\nYou represent the city network using a directed graph G = (V, E, w) with weights w defined on\nboth edges and vertices. The vertices V represent the cities and the edges E represent the roads.\nThe weight w(e) of an edge e represents the toll amount on that road. The weight w(v) of a vertex\nv is the price of filling your gas tank in that city (which is a fixed price independent of how much\ngas you have left, or infif there is no gas available to purchase). You are allowed (but not obligated)\nto end your journey with an empty tank, and you may assume that you always start your journey\nwith a full tank.\nBelow is an example graph that we will use to answer part (a). One seemingly cheap path from s\nto t is (s, u1, u2, t) at a cost of $8. Unfortunately, this path is not valid, because our leaky gas tank\nwon't permit moving across three edges without refilling our gas tank.\nOne valid path is (s, u3, u2, t) at a cost of $22. (This is a valid path: we begin with a full tank,\ntravel across one edge to a gas station where we refill our tank, and then travel two edges to the\ndestination, arriving with an empty gas tank. Notice that we are unable to continue the journey to\nu5 if we wanted to, because even though there is a gas station there, we have to traverse a third\nedge to get to it.)\nGas:\nFree\nGas:\n$5\nGas:\n$3\nNO\nGAS\nNO\nGAS\nToll: $5\nToll: $7\nToll: $2\nToll: $1\nToll: $2\nToll: $10\nToll: $3\ns\nt\nNO\nGAS\nToll: $1\nu1\nu2\nu3\nu4\nToll: $4\nGas:\n$1\nu5\nToll: $9\nToll: $1\nThere are some extra copies of this graph at the end of the exam (for your convenience).\n\n(a) [5 points] The valid path given in the description above is not the best path. Find a\nleast-expensive path from s to t in the graph above.\n(b) [5 points] Find the least-expensive path from s to u5 in the graph above.\n(c) [15 points] Give an O(V log V +E) algorithm to find, in a given graph G = (V, E, w),\na least-expensive valid path from a city s to a city t, or report that no such path exists.\n\nHere are some extra copies of the graph from Problem 6 (for your convenience).\nGas:\nFree\nGas:\n$5\nGas:\n$3\nNO\nGAS\nNO\nGAS\nToll: $5\nToll: $7\nToll: $2\nToll: $1\nToll: $2\nToll: $10\nToll: $3\ns\nt\nNO\nGAS\nToll: $1\nu1\nu2\nu3\nu4\nToll: $4\nGas:\n$1\nu5\nToll: $9\nToll: $1\nGas:\nFree\nGas:\n$5\nGas:\n$3\nNO\nGAS\nNO\nGAS\nToll: $5\nToll: $7\nToll: $2\nToll: $1\nToll: $2\nToll: $10\nToll: $3\ns\nt\nNO\nGAS\nToll: $1\nu1\nu2\nu3\nu4\nToll: $4\nGas:\n$1\nu5\nToll: $9\nToll: $1\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Quiz 2 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/c9dacb06398e3504b12dc1c28c8c6a3b_MIT6_006F11_quiz2_sol.pdf",
      "content": "Introduction to Algorithms\nNovember 17, 2011\nMassachusetts Institute of Technology\n6.006 Fall 2011\nProfessors Erik Demaine and Srini Devadas\nQuiz 2 Solutions\nQuiz 2 Solutions\nProblem 1.\n[1 points] Write your name on top of each page.\nProblem 2.\nTrue/False [28 points] (14 parts)\nCircle (T)rue or (F)alse. You don't need to justify your choice.\n(a) T F\n[2 points] Computing √\n⌊\na⌋for an n-bit positive integer a can be done in O(lg n)\niterations of Newton's method.\nSolution:\nTrue. This is the bound obtained by Newton's Method's quadratic\nconvergence.\n(b) T F\n[2 points] Suppose we want to solve a polynomial equation f(x) = 0. While\nour choice of initial approximation x0 will affect how quickly Newton's method\nconverges, it will always converge eventually.\nSolution:\nFalse. Take e.g. f(x) = x3 -2x+2 and x0 = 0. Then x2i+1 = 1 and\nx2i = 0 for all i (that is, the approximations alternate between 0 and 1 without\never converging).\n(c) T F\n[2 points] Karatsuba's integer multiplication algorithm always runs faster than\nthe grade-school integer multiplication algorithm.\nSolution:\nFalse. Problem Set 5 has shown that the O(N 2) algorithm runs faster\nfor small numbers.\n(d) T F\n[2 points] If we convert an n-digit base-256 number into base 2, the resulting\nnumber of digits is Θ(n2).\nSolution:\nFalse. log256 n =\nlog2 n = log2 n\nlog 256\n. By converting a base-256 number\nto base 2, the number of digits is\n2 multiplied by 8. For all b1, b2 = 1, converting\na base-b1 number to base-b2 results in a linear increase or decrease in the number\nof digits.\n(e) T F\n[2 points] In a weighted undirected graph G = (V, E, w), breadth-first search\nfrom a vertex s finds single-source shortest paths from s (via parent pointers) in\nO(V + E) time.\nSolution:\nFalse. Only in unweighted graphs.\n(f) T F\n[2 points] In a weighted undirected tree G = (V, E, w), breadth-first search\nfrom a vertex s finds single-source shortest paths from s (via parent pointers) in\nO(V + E) time.\n\n6.006 Quiz 2 Solutions\nName\nSolution:\nTrue. In a tree, there is only one path between two vertices, and\nbreadth-first search finds it.\n(g) T F\n[2 points] In a weighted undirected tree G = (V, E, w), depth-first search from\na vertex s finds single-source shortest paths from s (via parent pointers) in O(V +\nE) time.\nSolution:\nTrue. In a tree, there is only one path between two vertices, and\ndepth-first search finds it.\n(h) T F\n[2 points] If a graph represents tasks and their interdependencies (i.e., an edge\n(u, v) indicates that u must happen before v happens), then the breadth-first\nsearch order of vertices is a valid order in which to tackle the tasks.\nSolution:\nNo, you'd prefer depth-first search, which can easily be used to pro-\nduce a topological sort of the graph, which would correspond to a valid task\norder. BFS can produce incorrect results.\n(i) T F\n[2 points] Dijkstra's shortest-path algorithm may relax an edge more than once\nin a graph with a cycle.\nSolution:\nFalse. Dijkstra's algorithm always visits each node at most once; this\nis why it produces an incorrect result in the presence of negative-weight edges.\n(j) T F\n[2 points] Given a weighted directed graph G = (V, E, w) and a source s ∈V ,\nif G has a negative-weight cycle somewhere, then the Bellman-Ford algorithm\nwill necessarily compute an incorrect result for some δ(s, v).\nSolution:\nFalse. The negative-weight cycle has to be reachable from s.\n(k) T F\n[2 points] In a weighted directed graph G = (V, E, w) containing no zero- or\npositive-weight cycles, Bellman-Ford can find a longest (maximum-weight) path\nfrom vertex s to vertex t.\nSolution:\nTrue. Negate the weights.\n(l) T F\n[2 points] In a weighted directed graph G = (V, E, w) containing a negative-\nweight cycle, running the Bellman-Ford algorithm from s will find a shortest\nacyclic path from s to a given destination vertex t.\nSolution:\nFalse. Bellman-Ford will terminate, and can detect the presence of\nthat negative-weight cycle, but it can't \"route around it.\" (You could always\nremove an edge to break the cycle and try again, though.)\n(m) T F [2 points] The bidirectional Dijkstra algorithm runs asymptotically faster than\nthe Dijkstra algorithm.\n\n6.006 Quiz 2 Solutions\nName\nSolution:\nFalse. The constant factor behind bidirectional Dijkstra is better, but\nthe worst-case running time is the same.\n(n) T F\n[2 points] Given a weighted directed graph G = (V, E, w) and a shortest path p\nfrom s to t, if we doubled the weight of every edge to produce G′ = (V, E, w′),\nthen p is also a shortest path in G′.\nSolution:\nTrue. Multiplying edge weights by any positive constant factor pre-\nserves their relative order, as well as the relative order of any linear combination\nof the weights. All path weights are linear combinations of edge weights, so the\nrelative order of path weights is preserved. This means that a shortest path in G\nwill still be a shortest path in G′.\n\n6.006 Quiz 2 Solutions\nName\nProblem 3.\nMazeCraft [26 points] (5 parts)\nYou are playing SnowStorm's new video game, MazeCraft. Realizing that you can convert a maze\ninto a graph with vertices representing cells and edges representing passages, you want to use your\nnewly learned graph-search algorithms to navigate the maze. Consider the following converted\ngraph.\nA\nB\nC\nD\nF\nE\nG\nH\nFor the following questions, assume that the graph is represented using adjacency lists, and that all\nadjacency lists are sorted, i.e., the vertices in an adjacency list are always sorted alphabetically.\n(a) [4 points] Suppose that you want to find a path from A to H. If you use breadth-first\nsearch, write down the resulting path as a sequence of vertices.\nSolution:\nA, B, D, F, H\nScoring:\nFor Problem 3(a), 3(b), and 3(e), we computed the score as ⌊\nP·L\nMAX(N ,N )⌋,\nwhere P is the total points of the problem, L is the length of the longest common\na\ns\nsubsequence between our solution and the student's answer, Na is the length of the\nstudent's answer, and Ns is the length of our solution.\n(b) [4 points] If you use depth-first search to find a path from A to H, write down the\nresulting path as a sequence of vertices.\nSolution:\nA, B, C, D, E, G, F, H if you use recursion, or A, C, D, F, H if you use\nstack-based implemention. Essentially, the recursion-based implementation will visit\nthe neighbors in alphabetical order, while the stack-based implementation will visit\nthe neighbors in reverse alphabetical order.\n\n6.006 Quiz 2 Solutions\nName\n(c) [6 points] To determine whether the maze has cycles or multiple paths to the same\ndestination, you decide to use the edge classification of depth-first search. Run depth-\nfirst search on the graph reproduced below, starting from vertex A, and label every\nedge with T if it's a tree edge, B if it's a back edge, F if it's a forward edge, and C if\nit's a cross edge.\nAs a reminder, recall that an edge (u, v) is\n- a tree edge (T) if v was first discovered by exploring edge (u, v) (tree edges form\nthe depth-first forest);\n- a back edge (B) if v is u's ancestor in a depth-first tree;\n- a forward edge (F) if v is u's descendant in a depth-first tree; and\n- a cross edge (C) if none of the above apply.\nSolution:\nRecursion-based implementation:\nA\nB\nC\nD\nF\nE\nG\nH\nT\nB\nT\nT\nT\nB\nT\nT\nT\nB\nB\nStack-based implementation:\nD\nT\nT\nB\nB\nF\nT\nB\nB\nT\nB\nT\nA\nC\nE\nG\nH\nT\nT\nScoring:\nFor Problem 3(c) and 3(d), we computed the score as ⌊P -1Nw\n⌋, where\nP is the total points of the problem and Nw is the number of wrong labels.\n\n6.006 Quiz 2 Solutions\nName\n(d) [6 points] Now suppose that the passages in the maze are directional. Rerun depth-\nfirst search in the directed graph below and label the edges accordingly.\nSolution:\nRecursion-based implementation:\nA\nB\nC\nD\nF\nE\nG\nH\nT\nB\nT\nT\nT\nF\nC\nT\nT\nC\nT\nStack-based implementation:\nD\nT\nT\nC\nT\nB\nF\nT\nT\nT\nF\nC\nA\nC\nE\nG\nH\nB\nT\n\n6.006 Quiz 2 Solutions\nName\n(e) [6 points] Suppose each passage in the maze causes a different amount of damage to\nyou in game. You change the graph to use weights to represent the damage caused by\neach edge. You then use Dijkstra's algorithm to find the path from A to H with the\nlowest possible damage. Write down the order in which vertices get removed from the\npriority queue when running Dijkstra's algorithm.\nA\nB\nC\nD\nF\nE\nG\nH\nSolution:\nA, B, D, C, F, E, G, H\n\n6.006 Quiz 2 Solutions\nName\nProblem 4.\nMalfunctioning Calculator [25 points] (5 parts)\nFormer 6.006 student Mallory Funke is at a math competition, but her calculator isn't working. It\nseems to work fine for whole numbers, but the numbers after the decimal point always seem to\nbe the sequence\nrepeated over and over again, making those digits useless. For one of the\nproblems, she has been asked to compute ⌊A3/4⌋for a few different integer values of A. Mal knows\nthat Newton's Method can be used to compute the square root or the cube root of an integer A. So\nas a first step in computing ⌊A3/4⌋, Mal wants to use Newton's Method to compute ⌊A1/4\n⌋. She\nthen plans to use that information to compute ⌊A /4⌋.\n(a) [5 points] Mal decides to use the function f(x) = x4\nA, because it has a root\nat x = A1/4\n-\n. Use Newton's Method on f(x) to generate a formula for computing\nincreasingly accurate estimates of ⌊A1/4⌋. In other words, give a formula for the\nmore accurate estimate xi+1 in terms of a less accurate estimate xi. The formula you\nconstruct must use only addition, subtraction, multiplication, and division. (You do\nnot need to simplify the formula.)\nSolution:\nIf we take the derivative of f(x), we get f ′(x) = 4x3. Hence, Newton's\nMethod says that we have\nx4\ni -A\nxi · xi · xi\nxi+1 = xi -\n= xi\n4x3\n· x\ni\n-\ni -A.\n4 · xi · xi · xi\n\n6.006 Quiz 2 Solutions\nName\n(b) [5 points] Mal decides to use the technique from part (a) to compute the value B =\n⌊A1/4⌋. She then plans to compute ⌊A3/4⌋by calculating the value C = B3 = B·B·B.\nProvide an explanation of why this technique does not work.\nHint: Define α to be the fractional part of A1/4, so that B = A1/4 -α. What happens\nwhen you compute C = B3?\nSolution:\nWhen you expand out the formula for C, you get\nC = B3 = (A1/4 -α)3 = A3/4 -3A2/4α + 3A1/4α2 -α3.\nIf A is large, then γ = 3A2/4α -3A1/4α2 + α3 will be significantly greater than 1,\nand so we'll have C = A3/4 -γ with γ > 1. Hence, C will not be ⌊A3/4⌋.\n(c) [5 points] Mal clearly needs a way to check her answer for ⌊A3/4⌋, using only integers.\nGiven a pair of positive integers A and C, explain how to check whether C ≤A3/4\nusing O(1) additions, subtractions, multiplications, and comparisons.\nSolution:\nThe equation C ≤A3/4 is equivalent to the equation C4 ≤A3, which is\nequivalent to C · C · C · C ≤A · A · A.\n(d) [5 points] Explain how to check whether C = ⌊A3/4⌋, again using only O(1) addi-\ntions, subtractions, multiplications, and comparisons.\nHint: Recall how the floor function is defined.\nSolution:\nIf C = A3/4 , then by the definition of the floor function, we have C\nA3/4\n⌊\n⌋\n≤\nand C + 1 > A3/4. We can check both of these using the technique from part\n(c).\n\n6.006 Quiz 2 Solutions\nName\n(e) [5 points] Give a brief description of an algorithm that takes as input a d-digit positive\ninteger A and computes ⌊A3/4⌋. The only arithmetic operations you can use are inte-\nger addition, integer subtraction, integer multiplication, integer division, and integer\ncomparison. Your algorithm should use Θ(lg d) arithmetic operations in total, but par-\ntial credit will be awarded for using Θ(d) arithmetic operations. For this question, you\nmay assume that Newton's Method has a quadratic rate of convergence for whatever\nfunction you devise.\nSolution:\nΘ(lg d) Solution:\nThe technique from part (b) didn't work because we threw away\ninformation (taking the floor) before performing another operation. Instead, we first\ncalculate B = A3, then compute C = ⌊B1/4⌋using the formula from part (a) to\ncontinually improve our estimate. Because we have a quadratic rate of convergence,\nwe will improve our estimate Θ(log d) times, and each time we will perform a constant\nnumber of arithmetic operations.\nNote: This is equivalent to applying Newton's Method to the function f(x) = x4-A3,\nbut does not require you to rederive the equation for xi+1 in terms of xi.\nΘ(d) Solution:\nUse the comparison method from part (c) to do binary search. This\nrequires us to do Θ(1) operations for each of the bits in the result, for a total of Θ(d)\noperations.\n\n6.006 Quiz 2 Solutions\nName\nProblem 5.\nThe Tourist [15 points]\nYour new startup, Bird Tours, brings people around Boston in a new aviation car that can both drive\nand fly. You've constructed a weighted directed graph G = (V, E, w) representing the best time to\ndrive or fly between various city sites (represented by vertices in V ). You've also written a history\nof Boston, which would be best described by visiting sites v0, v1, . . . , vk in that order.\nYour goal is to find the shortest path in G that visits v0, v1, . . . , vk in order, possibly visiting other\nvertices in between. (The path must have v0, v1, . . . , vk as a subsequence; the path is allowed to\nvisit a vertex more than once. For example, v0, v2, v1, v2, . . . , vk is legal.) To do the computation,\nyou've found an online service, Paths '\nR\nUs, that will compute the shortest path from a given\nsource s to a given target t in a given weighted graph, for the bargain price of $1. You see how to\nsolve the problem by paying $k, calling Paths '\nR\nUs with (v0, v1, G), (v1, v2, G), . . . , (vk\n1, vk, G)\n-\nand piecing together the paths. Describe how to solve the problem with only $1 by calling Paths\n'\nR\nUs with (s, t, G′) for a newly constructed graph G′ = (V ′, E′, w′), and converting the resulting\npath into a path in G.\nSolution:\nTo form the graph G′, we start from the disjoint union of k copies of the given graph G,\nusing superscripts to denote the different copies G1, G2, . . . , Gk. That is, for each vertex v\nV , we make k copies v1, v2, . . . , vk\n∈\nin V ′; and for each edge (u, v) ∈E, we form the edges\n(u1, v1), (u2, v2), . . . , (uk, vk) in E′, each of weight w(u, v). Then we add the edges (v1\n1, v2\n1),\n(v2\n2, v3\n2), . . ., (vk-1\nk\n1, vk\nk\n1), each of weight 0, to complete the graph G′. Finally we set the start\n-\n-\nvertex s = v1\n0 and the target vertex t = vk\nk, and call Paths '\nR\nUs with (s, t, G′).\nIntuitively, the subgraph Gi represents a situation in which the path has visited the Boston sites\nv0, v1, . . . , vi\n1, and is currently aiming to visit vi. Once the path visits v\n-\ni, it can take the zero-\nweight edge (vi\ni, vi+1\ni\n), which represents the fact that vi has been visited. (A path may choose not\nto follow this edge, but it must do so eventually in order to reach the next copy Gi+1 and eventually\nthe target vertex t in Gk.)\nOnce we have a shortest path in G′, we can convert it into the corresponding path in G by simply\nreplacing every vertex ui ∈V ′ with u ∈V , and then removing any loop edges (vi, vi) from the path\n(resulting from the zero-weight edge (vi\ni, vi+1\ni\n)). Intuitively, we just need to flatten the k copies of\nG down to the single copy.\nAnother solution to this problem, found by many students, is to replace the endpoints of the edges\ninstead of using zero-weight edges. For example, after making k copies of the graph G, we can\nreplace each edge (ui, vi) with (ui, vi+1\ni\ni\n). This has the same effect as the zero-weight edges, and\nremoves the need to remove loops at the end.\n\n6.006 Quiz 2 Solutions\nName\nProblem 6.\nFill 'Er Up! [25 points]\nYou are traveling by car from one city to another city. Unfortunately, you have a hole in your\ngas tank, and you have to refill your gas tank to travel across more than two roads. In addition,\nthere is a toll booth on every road that charges you for using that road. Your goal is to find the\nleast-expensive path from your start to your destination.\nYou represent the city network using a directed graph G = (V, E, w) with weights w defined on\nboth edges and vertices. The vertices V represent the cities and the edges E represent the roads.\nThe weight w(e) of an edge e represents the toll amount on that road. The weight w(v) of a vertex\nv is the price of filling your gas tank in that city (which is a fixed price independent of how much\ngas you have left, or infif there is no gas available to purchase). You are allowed (but not obligated)\nto end your journey with an empty tank, and you may assume that you always start your journey\nwith a full tank.\nBelow is an example graph that we will use to answer part (a). One seemingly cheap path from s\nto t is (s, u1, u2, t) at a cost of $8. Unfortunately, this path is not valid, because our leaky gas tank\nwon't permit moving across three edges without refilling our gas tank.\nOne valid path is (s, u3, u2, t) at a cost of $22. (This is a valid path: we begin with a full tank,\ntravel across one edge to a gas station where we refill our tank, and then travel two edges to the\ndestination, arriving with an empty gas tank. Notice that we are unable to continue the journey to\nu5 if we wanted to, because even though there is a gas station there, we have to traverse a third\nedge to get to it.)\nGas:\nFree\nGas:\n$5\nGas:\n$3\nNO\nGAS\nNO\nGAS\nToll: $5\nToll: $7\nToll: $2\nToll: $1\nToll: $2\nToll: $10\nToll: $3\ns\nt\nNO\nGAS\nToll: $1\nu1\nu2\nu3\nu4\nToll: $4\nGas:\n$1\nu5\nToll: $9\nToll: $1\nThere are some extra copies of this graph at the end of the exam (for your convenience).\n\n6.006 Quiz 2 Solutions\nName\n(a) [5 points] The valid path given in the description above is not the best path. Find a\nleast-expensive path from s to t in the graph above.\nSolution:\n(s, u1, u3, u2, t)\n(b) [5 points] Find the least-expensive path from s to u5 in the graph above.\nSolution:\n(s, u1, u3, u2, u4, t, u5)\n(c) [15 points] Give an O(V log V +E) algorithm to find, in a given graph G = (V, E, w),\na least-expensive valid path from a city s to a city t, or report that no such path exists.\nSolution:\nWe will solve this problem by transforming G = (V, E, w), the graph of\ncities, roads, and toll/gas costs, into a new graph G′ = (V ′, E′, w′). We will then use\nDijkstra's algorithm to find the desired path.\nFirst construct the vertex set V ′. For each vertex v ∈V , create three vertices in\nV ′: vf, vh, and ve. These stand for a full tank, a half-full tank, and an empty tank,\nrespectively. This operation takes O(V ) time, since we iterate |V | times and create\nthree new vertices each time.\nNext we will discuss the construction of E′ and w′. For each edge (u, v) = e ∈E,\ncreate edges in E′ as follows. Create edges (uf, vh) and (uh, ve) to represent the\nemptying of half the tank during the move from u to v. The weights on both of these\nedges will be the original weight w(u, v). This operation takes O(E) time, since we\niterate |E| times and insert two new edges into E′ each time.\nFinally, we will represent the cost of fueling up by creating additional edges as follows.\nFor every vertex v ∈V , we check whether there is a gas station there. If there is a\ngas station at this vertex, then we add the edges (ve, vf) and (vh, vf) to E′. Since the\ncost of fueling up is not dependent on the amount of gas that is already in the tank,\nwe assign both of these edges the cost of fueling up at that city. This procedure takes\nO(V ) time, since we iterate over all of the vertices and create a constant number of\nnew edges.\n\n6.006 Quiz 2 Solutions\nName\nWe can now run Dijkstra's algorithm on this graph to find paths from sf to tf, th, and\nte, and we return the shortest of the three. The graph transformation took O(V + E)\ntime and, as the number of vertices and the number of edges increased by a constant\nfactor, running Dijkstra on this graph takes O(V log V + E) time. Therefore, the total\nrunning time is O(V log V + E).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 01: Algorithmic thinking, peak finding",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/c32185c7158955425455159a8455298b_MIT6_006F11_lec01.pdf",
      "content": "Lecture 1\nIntroduction and Peak Finding\n6.006 Fall 2011\nLecture 1: Introduction and Peak Finding\nLecture Overview\n- Administrivia\n- Course Overview\n- \"Peak finding\" problem -- 1D and 2D versions\nCourse Overview\nThis course covers:\n- Efficient procedures for solving problems on large inputs (Ex: U.S. Highway Map,\nHuman Genome)\n- Scalability\n- Classic data structures and elementary algorithms (CLRS text)\n- Real implementations in Python\n- Fun problem sets!\nThe course is divided into 8 modules -- each of which has a motivating problem and problem\nset(s) (except for the last module). Tentative module topics and motivating problems are\nas described below:\n1. Algorithmic Thinking: Peak Finding\n2. Sorting & Trees: Event Simulation\n3. Hashing: Genome Comparison\n4. Numerics: RSA Encryption\n5. Graphs: Rubik's Cube\n6. Shortest Paths: Caltech → MIT\n7. Dynamic Programming: Image Compression\n8. Advanced Topics\n\nLecture 1\nIntroduction and Peak Finding\n6.006 Fall 2011\nPeak Finder\nOne-dimensional Version\nPosition 2 is a peak if and only if b ≥ a and b ≥ c. Position 9 is a peak if i ≥ h.\ng\nf\ni\nb\na\nc\nd\ne\nh\nFigure 1: a-i are numbers\nProblem: Find a peak if it exists (Does it always exist?)\nStraightforward Algorithm\nStart from left\n. . .\nn/2\nn-1 n\nmight be peak\nθ(n) complexity worst case\n. . .\nFigure 2: Look at n/2 elements on average, could look at n elements in the worst case\nWhat if we start in the middle? For the configuration below, we would look at n/2 elements.\nWould we have to ever look at more than n/2 elements if we start in the middle, and choose\na direction based on which neighboring element is larger that the middle element?\nn/2\n\nLecture 1\nIntroduction and Peak Finding\n6.006 Fall 2011\nCan we do better?\n. . .\nn/2\nn-1 n\nlook at n/2 position\n. . .\nn/2 -1\nn/2 +1\nFigure 3: Divide & Conquer\n- If a[n/2] < a[n/2 - 1] then only look at left half 1 . . . n/2 --- 1 to look for peak\n- Else if a[n/2] < a[n/2 + 1] then only look at right half n/2 + 1 . . . n to look for peak\n- Else n/2 position is a peak: WHY?\na[n/2] ≥ a[n/2 - 1]\na[n/2] ≥ a[n/2 + 1]\nWhat is the complexity?\nT (n) = T (n/2) +\nΘ(1)\n= Θ(1) + . . . + Θ(1) (log2(n) times) = Θ(log2(n))\n'-v \"\nto compare a[n/2] to neighbors\nIn order to sum up the Θ(i)'s as we do here, we need to find a constant that works for all.\nIf n = 1000000, Θ(n) algo needs 13 sec in python. If algo is Θ(log n) we only need 0.001 sec.\nArgue that the algorithm is correct.\nTwo-dimensional Version\nc\nb\na\ne\nd\nn rows\nm columns\nFigure 4: Greedy Ascent Algorithm: Θ(nm) complexity, Θ(n 2) algorithm if m = n\na is a 2D-peak iff a ≥ b, a ≥ d, a ≥ c, a ≥ e\n\nLecture 1\nIntroduction and Peak Finding\n6.006 Fall 2011\nFigure 5: Circled value is peak.\nAttempt # 1: Extend 1D Divide and Conquer to 2D\ni\nj = m/2\n- Pick middle column j = m/2.\n- Find a 1D-peak at i, j.\n- Use (i, j) as a start point on row i to find 1D-peak on row i.\nAttempt #1 fails\nProblem: 2D-peak may not exist on row i\nEnd up with 14 which is not a 2D-peak.\n\nLecture 1\nIntroduction and Peak Finding\n6.006 Fall 2011\nAttempt # 2\n- Pick middle column j = m/2\n- Find global maximum on column j at (i, j)\n- Compare (i, j - 1), (i, j), (i, j + 1)\n- Pick left columns of (i, j - 1) > (i, j)\n- Similarly for right\n- (i, j) is a 2D-peak if neither condition holds ← WHY?\n- Solve the new problem with half the number of columns.\n- When you have a single column, find global maximum and you're done.\nExample of Attempt #2\npick this column\n17 global max\nfor this column\npick this column\n19 global max\nfor this column\nfind 21\ngo with\nComplexity of Attempt #2\nIf T (n, m) denotes work required to solve problem with n rows and m columns\nT (n, m)\n= T (n, m/2) + Θ(n) (to find global maximum on a column -- (n rows))\nT (n, m) = Θ(n) + . . . + Θ(n)\n'\n-v\n\"\nlog m\n= Θ(n log m) = Θ(n log n) if m = n\nQuestion: What if we replaced global maximum with 1D-peak in Attempt #2? Would that\nwork?\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 02 Original: Models of computation, Python cost model, document distance",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/976b77eb1187593cabf5f06aaada8bd4_MIT6_006F11_lec02_orig.pdf",
      "content": "http://en.wikipedia.org/wiki/Al-Khwarizmi\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 02: Models of computation, Python cost model, document distance",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/6b9b20992d8c6a0f3f10a34ff7878aa9_MIT6_006F11_lec02.pdf",
      "content": "Lecture 2\n6.006 Fall 2011\nLecture 2: Models of Computation\nLecture Overview\n- What is an algorithm? What is time?\n- Random access machine\n- Pointer machine\n- Python model\n- Document distance: problem & algorithms\nHistory\nAl-Khw arizm ı \"al-kha-raz-mi\" (c. 780-850)\n- \"father of algebra\" with his book \"The Compendious Book on Calculation by Com\npletion & Balancing\"\n- linear & quadratic equation solving: some of the first algorithms\nWhat is an Algorithm?\n- Mathematical abstraction of computer program\n- Computational procedure to solve a problem\nprogramming\nlanguage\npseudocode\ncomputer\nmodel of\ncomputation\nprogram\nalgorithm\nanalog\nbuilt on\ntop of\nFigure 1: Algorithm\nModel of computation specifies\n- what operations an algorithm is allowed\n- cost (time, space, . . . ) of each operation\n- cost of algorithm = sum of operation costs\n\nLecture 2\n6.006 Fall 2011\nRandom Access Machine (RAM)\n.\n.\n.\n.\n.\n.\nword\n}\n- Random Access Memory (RAM) modeled by a big array\n- Θ(1) registers (each 1 word)\n- In Θ(1) time, can\n- load word @ ri into register rj\n- compute (+, -, ∗, /, &, |, ˆ) on registers\n- store register rj into memory @ ri\n- What's a word? w ≥ lg (memory size) bits\n- assume basic objects (e.g., int) fit in word\n- unit 4 in the course deals with big numbers\n- realistic and powerful → implement abstractions\nPointer Machine\n- dynamically allocated objects (namedtuple)\n- object has O(1) fields\n- field = word (e.g., int) or pointer to object/null (a.k.a. reference)\n- weaker than (can be implemented on) RAM\n\nLecture 2\n6.006 Fall 2011\nval\nprev\nnull\nnext\nval\n-1\nprev\nnull\nnext\nPython Model\nPython lets you use either mode of thinking\n1. \"list\" is actually an array → RAM\nL[i] = L[j] + 5 → Θ(1) time\n2. object with O(1) attributes (including references) → pointer machine\nx = x.next → Θ(1) time\nPython has many other operations. To determine their cost, imagine implementation in\nterms of (1) or (2):\n1. list\n(a) L.append(x) → θ(1) time\nobvious if you think of infinite array\nbut how would you have > 1 on RAM?\nvia table doubling [Lecture 9]\n⎫\n(b)\n≡ L = [ ] → θ(1)\n\"\n'L = L1 + L2\nv\n⎪\n\n⎪\n⎪\n⎬\n(θ(1+|L1|+|L2|) time)\n\nfor x in L1:\nθ(|L1|)\nL.append(x) → θ(1)\n\nfor x in L2:\nθ(|L2|)\nL.append(x) → θ(1)\n⎪\n⎪\n\n⎪\n⎪\n⎭\n\nLecture 2\n6.006 Fall 2011\n(c)\nL1.extend(L2) ≡ for x in L2:\n≡ L1+ = L2\nL1.append(x) → θ(1)\nθ(1 + |L2|) time\n(d)\nL2 = L1[i : j] ≡ L2 = []\nfor k in range(i, j):\nθ(j - i + 1) = O(|L|)\nL2.append(L1[i]) → θ(1)\n(e)\nb = x in L\n≡\nfor y in L:\n& L.index(x)\nif x == y:\n& L.find(x)\nb = T rue;\nbreak\nelse\nb = F alse\n⎫\n⎪\n⎬\n⎪\n⎭\nθ(1)\n⎫\n⎪\n\n⎪\n⎪\n⎬\nθ(index of x) = θ(|L|)\n⎪\n\n⎪\n⎭\n(f) len(L) → θ(1) time - list stores its length in a field\n(g) L.sort() → θ(|L| log |L|) - via comparison sort [Lecture 3, 4 & 7)]\n2. tuple, str: similar, (think of as immutable lists)\n3. dict: via hashing [Unit 3 = Lectures 8-10]\nD[key] = val\nθ(1) time w.h.p.\nkey in D\n4. set: similar (think of as dict without vals)\n5. heapq: heappush & heappop - via heaps [Lecture 4] → θ(log(n)) time\n6. long: via Karatsuba algorithm [Lecture 11]\nx + y → O(|x| + |y|) time\nwhere |y| reflects # words\nx ∗ y → O((|x| + |y|)log(3))\n≈ O((|x| + |y|)1.58) time\nDocument Distance Problem -- compute d(D1, D2)\nThe document distance problem has applications in finding similar documents, detecting\nduplicates (Wikipedia mirrors and Google) and plagiarism, and also in web search (D2 =\nquery).\nSome Definitions:\n- Word = sequence of alphanumeric characters\n- Document = sequence of words (ignore space, punctuation, etc.)\nThe idea is to define distance in terms of shared words. Think of document D as a vector:\nD[w] = # occurrences of word W . For example:\n)\n)\n)\n\nLecture 2\n6.006 Fall 2011\ndog\ncat\nD2\nD1\nthe\nFigure 2: D1 = \"the cat\", D2 = \"the dog\"\nAs a first attempt, define document distance as\n\nd/(D1, D2) = D1 · D2 =\nD1[W ] · D2[W ]\nW\nThe problem is that this is not scale invariant. This means that long documents with 99%\nsame words seem farther than short documents with 10% same words.\nThis can be fixed by normalizing by the number of words:\nD1 · D2\nd//(D1, D2) = |D1| · |D2|\nwhere |Di| is the number of words in document i. The geometric (rescaling) interpretation\nof this would be that:\nd(D1, D2) = arccos(d//(D1, D2))\nor the document distance is the angle between the vectors. An angle of 0* means the two\ndocuments are identical whereas an angle of 90* means there are no common words. This\napproach was introduced by [Salton, Wong, Yang 1975].\nDocument Distance Algorithm\n1. split each document into words\n2. count word frequencies (document vectors)\n3. compute dot product (& divide)\n\nLecture 2\n6.006 Fall 2011\n(1) re.findall (r\" w+\", doc) → what cost?\nin general re can be exponential time\n→ for char in doc:\n⎫\n⎪\n⎪\n⎬\nΘ(|doc|)\nif not alphanumeric\nadd previous word\n⎫\n⎪\n⎬ Θ(1) ⎪\n\n⎪\n⎭\n⎪\n⎭\n(if any) to list\nstart new word\n(2) sort word list\n⎫\n⎪\n⎪\n⎪\n⎬\n← O(k log k · |word|) where k is #words\nif same as last word:\n← O(|word|)\nincrement counter\nO( |\n|\nword )\nfor word in list:\n= O(|doc|)\n⎫\n⎪\n⎬\nΘ(1)\nelse:\nadd last word and count to list\nreset counter to 0\n⎪\n\n⎪\n⎪\n⎭\n⎪\n⎪\n⎭\n⎫\n⎪\n⎬\n⎪\n⎭\n⎫\n(3)\nfor word, count1 in doc1:\n← Θ(k1)\nif word, count2 in doc2:\n← Θ(k2)\ntotal += count1 * count2\nΘ(1)\nO(k1 · k2)\n\n(3)'\nstart at first word of each list\nif words equal:\n← O(|word|)\ntotal += count1 * count2\nif word1 ≤ word2: ← O(|word|)\nadvance list1\nelse:\nadvance list2\nrepeat either until list done\nDictionary Approach\n(2)'\ncount = {}\nfor word in doc:\nO(\n|word|) = O(|doc|)\n⎪\n\n⎪\n\n⎪\n⎪\n⎬\n⎪\n⎪\n\n⎪\n⎪\n⎭\n⎫\n⎪\n⎪\n⎬\nif word in count:\n← Θ(|word|) + Θ(1) w.h.p\nΘ(1)\n⎫\n⎪\n⎬\nO(|doc|) w.h.p.\n⎪\n⎪\n⎪\n⎭\ncount[word] += 1\nelse\n⎪\n⎭\ncount[word] = 1\n(3)'\nas above → O(|doc1|) w.h.p.\n\nLecture 2\n6.006 Fall 2011\nCode (lecture2 code.zip & data.zip on website)\nt2.bobsey.txt 268,778 chars/49,785 words/3354 uniq\nt3.lewis.txt 1,031,470 chars/182,355 words/8534 uniq\nseconds on Pentium 4, 2.8 GHz, C-Python 2.62, Linux 2.6.26\n- docdist1: 228.1 -- (1), (2), (3) (with extra sorting)\nwords = words + words on line\n- docdist2: 164.7 -- words += words on line\n- docdist3: 123.1 -- (3)' . . . with insertion sort\n- docdist4: 71.7 -- (2)' but still sort to use (3)'\n- docdist5: 18.3 -- split words via string.translate\n- docdist6: 11.5 -- merge sort (vs. insertion)\n- docdist7: 1.8 -- (3) (full dictionary)\n- docdist8: 0.2 -- whole doc, not line by line\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 03: Insertion sort, merge sort",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/90a37c49b07b105ea7a027abc67eddc6_MIT6_006F11_lec03.pdf",
      "content": "6.006- Introduction to\nAlgorithms\nLecture 3\nCourtesy of MIT Press. Used with permission.\n\nMenu\n- Sorting!\n- Insertion Sort\n- Merge Sort\n- Solving Recurrences\n\nThe problem of sorting\nInput: array A[1...n] of numbers.\nOutput: permutation B[1...n] of A such\nthat B[1] ≤ B[2] ≤ ... ≤ B[n] .\ne.g. A = [7, 2, 5, 5, 9.6] → B = [2, 5, 5, 7, 9.6]\nHow can we do it efficiently ?\n\nWhy Sorting?\n- Obvious applications\n- Organize an MP3 library\n- Maintain a telephone directory\n- Problems that become easy once items are\nin sorted order\n- Find a median, or find closest pairs\n- Binary search, identify statistical outliers\n- Non-obvious applications\n- Data compression: sorting finds duplicates\n- Computer graphics: rendering scenes front to back\n\nInsertion sort\nINSERTION-SORT (A, n) [ A[1 . . n]\nfor j ← 2 to n\ninsert key A[j] into the (already sorted) sub-array A[1 .. j-1].\nby pairwise key-swaps down to its right position\nIllustration of iteration j\ni\nj\nn\nA:\nkey\nsorted\nnew location of key\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\nExample of insertion sort\n\n9 done\nRunning time? Θ(n2) because Θ(n2) compares and Θ(n2) swaps\ne.g. when input is A = [n, n - 1, n - 2, . . . , 2, 1]\n\nBinary Insertion sort\nBINARY-INSERTION-SORT (A, n)\n[ A[1 . . n]\nfor j ← 2 to n\ninsert key A[j] into the (already sorted) sub-array A[1 .. j-1].\nUse binary search to find the right position\nBinary search with take Θ(log n) time.\nHowever, shifting the elements after insertion will\nstill take Θ(n) time.\nComplexity: Θ(n log n) comparisons\n(n2) swaps\n\nMeet Merge Sort\nMERGE-SORT A[1 . . n]\n1. If n = 1, done (nothing to sort).\ndivide and\n2. Otherwise, recursively sort A[ 1 . . n/2 ]\nconquer\nand A[ n/2+1 . . n ] .\n3. \"Merge\" the two sorted sub-arrays.\nKey subroutine: MERGE\n\nMerging two sorted arrays\n20 12\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n\nMerging two sorted arrays\n20 12\n20 12\n13 11\n13 11\n\nMerging two sorted arrays\n20 12\n20 12\n13 11\n13 11\n20 12\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n20 12\n13 11\n\nMerging two sorted arrays\n20 12\n20 12\n13 11\n13 11\n20 12\n13 11\n20 12\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n20 12\n20 12\n13 11\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n20 12\n20 12\n20 12\n13 11\n13 11\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n20 12\n20 12\n20 12\n13 11\n13 11\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n20 12\n20 12\n20 12\n13 11\n13 11\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n20 12\n20 12\n20 12\n13 11\n13 11\n13 11\n\nMerging two sorted arrays\n20 12\n13 11\n20 12\n13 11\n20 12\n20 12\n20 12\n13 11\n13 11\n13 11\nTime = Θ(n) to merge a total\nof n elements (linear time).\n\nAnalyzing merge sort\nMERGE-SORT A[1 . . n]\n1. If n = 1, done.\n2. Recursively sort A[ 1 . . ⎡n/2⎤ ]\nand A[ ⎡n/2⎤+1 . . n ] .\n3. \"Merge\" the two sorted lists\nΘ(1) if n = 1;\nT(n) =\n2T(n/2) + Θ(n) if n > 1.\nT(n) = ?\nT(n)\nΘ(1)\n2T(n/2)\nΘ(n)\n\nRecurrence solving\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\nT(n)\n\nT(n/2)\nT(n/2)\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\n\ncn/2\ncn\ncn/2\nT(n/4)\nT(n/4)\nT(n/4)\nT(n/4)\nRecursion tree\nolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\nS\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\nh = 1 + lg n\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\ncn\nh = 1 + lg n\n\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\ncn\nh = 1 + lg n\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\ncn\n\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\ncn\nh = 1 + lg n\ncn\n...\n\ncn\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\n\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\ncn\ncn\n#leaves = n\nΘ(n)\n...\nh = 1 + lg n\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\ncn\n\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\ncn\ncn\n#leaves = n\nΘ(n)\nTotal ?\n...\nh = 1 + lg n\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\ncn\n\ncn/4\ncn/4\ncn/4\ncn/4\ncn/2\ncn/2\nΘ(1)\n= 1 + lg n\ncn\ncn\n#leaves = n\nΘ(n)\n...\nTotal = Θ(n lg n)\n\nRecursion tree\nSolve T(n) = 2T(n/2) + cn, where c > 0 is constant.\ncn\nh\ncn\nEqual amount of work done at each level\n\n...\n\nc\nc\nc\nc\nc\nc\nΘ(1)\n2c\n4c\n#leaves = n\nΘ(n)\nn/2 c\nh = 1 + lg n\n\nTree for different recurrence\nSolve T(n) = 2T(n/2) + c, where c > 0 is constant.\nc\nc\nNote that 1 + 1⁄2 + 1⁄4 + ... < 2\n= Θ\nTotal\n(n)\nAll the work done at the leaves\n\ncn2/2\nh = 1 + lg n\nΘ(n)\n...\ncn2/16\ncn2/16\ncn2/16\ncn2/16\ncn2/4\ncn2/4\nΘ(1)\n#leaves = n\ncn2/4\n\nTree for yet another recurrence\nSolve T(n) = 2T(n/2) + cn2, c > 0 is constant.\ncn2\ncn2\nNote that 1 + 1⁄2 + 1⁄4 + ... < 2\nTotal = Θ(n2)\nAll the work done at the root\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006\nIntroduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 04: Heaps and heap sort",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/8ebfeb1c645b10b3709919603e7d51be_MIT6_006F11_lec04.pdf",
      "content": "6.006- Introduction to\nAlgorithms\nLecture 4\nCourtesy of MIT Press. Used with permission.\n\nMenu\n- Priority Queues\n- Heaps\n- Heapsort\n\nPriority Queue\nA data structure implementing a set S of elements, each\nassociated with a key, supporting the following operations:\nincrease_key(S, x, k) :\ninsert element x into set S\nreturn element of S with largest key\nreturn element of S with largest key and\nremove it from S\nincrease the value of element x' s key to\nnew value k\n(assumed to be as large as current value)\ninsert(S, x) :\nmax(S) :\nextract_max(S) :\n\nHeap\n- Implementation of a priority queue\n- An array, visualized as a nearly complete binary tree\n- Max Heap Property: The key of a node is ≥ than the keys of\nits children\n(Min Heap defined analogously)\n\nAll my arrays start at index 1\n16 14 10 8 7 9 3 2 4 1\n1 2 3 4 5 6 7 8 9 10\n9 10\n\nHeap as a Tree\nroot of tree: first element in the array, corresponding to i = 1\nparent(i) =i/2: returns index of node's parent\nleft(i)=2i: returns index of node's left child\nright(i)=2i+1: returns index of node's right child\n16 14 10 8 7 9 3 2 4 1\n1 2 3 4 5 6 7 8 9 10\n9 10\nNo pointers required! Height of a binary heap is O(lg n)\n\nOperations with Heaps\ninsert, extract_max, heapsort\nproduce a max-heap from an unordered\narray\ncorrect a single violation of the heap\nproperty in a subtree at its root\nbuild_max_heap :\nmax_heapify :\nHeap Operations\n\nMax_heapify\n- Assume that the trees rooted at left(i) and right(i)\nare max-heaps\n- If element A[i] violates the max-heap property, correct\nviolation by \"trickling\" element A[i] down the tree,\nmaking the subtree rooted at index i a max-heap\n\nMax_heapify (Example)\nNode 10 is the left child of node 5 but is drawn to the right for convenience\n\nMax_heapify (Example)\n\nMax_heapify (Example)\nTime=? O(log n)\n\nMax_Heapify Pseudocode\nl = left(i)\nr = right(i)\nif (l <= heap-size(A) and A[l] > A[i])\nthen largest = l else largest = i\nif (r <= heap-size(A) and A[r] > A[largest])\nthen largest = r\nif largest = i\nthen exchange A[i] and A[largest]\nMax_Heapify(A, largest)\n\nBuild_Max_Heap(A)\nConverts A[1...n] to a max heap\nBuild_Max_Heap(A):\n\nfor i=n/2 downto 1\n\ndo Max_Heapify(A, i)\nTime=?\nO(n log n) via simple analysis\nWhy start at n/2?\n\nBecause elements A[n/2 + 1 ... n] are all leaves of the tree\n2i > n, for i > n/2 + 1\n\nBuild_Max_Heap(A) Analysis\nConverts A[1...n] to a max heap\nBuild_Max_Heap(A):\n\nfor i=n/2 downto 1\n\ndo Max_Heapify(A, i)\nObserve however that Max_Heapify takes O(1) for\ntime for nodes that are one level above the leaves, and\nin general, O(l) for the nodes that are l levels above the\nleaves. We have n/4 nodes with level 1, n/8 with level 2,\nand so on till we have one root node that is lg n levels\nabove the leaves.\n\nBuild_Max_Heap(A) Analysis\nConverts A[1...n] to a max heap\nBuild_Max_Heap(A):\n\nfor i=n/2 downto 1\n\ndo Max_Heapify(A, i)\nTotal amount of work in the for loop can be summed as:\nn/4 (1 c) + n/8 (2 c) + n/16 (3 c) + ... + 1 (lg n c)\nSetting n/4 = 2k and simplifying we get:\nc 2k( 1/20 + 2/21 + 3/22 + ... (k+1)/2k )\nThe term is brackets is bounded by a constant!\n\nThis means that Build_Max_Heap is O(n)\n\nBuild-Max-Heap Demo\n\nBuild-Max-Heap Demo\n\nBuild-Max-Heap\n\nHeap-Sort\nSorting Strategy:\n1. Build Max Heap from unordered array;\n\nHeap-Sort\nSorting Strategy:\n1. Build Max Heap from unordered array;\n2. Find maximum element A[1];\n3. Swap elements A[n] and A[1]:\n\nnow max element is at the end of the array!\n\nHeap-Sort\nSorting Strategy:\n1. Build Max Heap from unordered array;\n2. Find maximum element A[1];\n3. Swap elements A[n] and A[1]:\n\nnow max element is at the end of the array!\n4. Discard node n from heap\n\n(by decrementing heap-size variable)\n\nHeap-Sort\nSorting Strategy:\n1. Build Max Heap from unordered array;\n2. Find maximum element A[1];\n3. Swap elements A[n] and A[1]:\n\nnow max element is at the end of the array!\n4. Discard node n from heap\n\n(by decrementing heap-size variable)\n5. New root may violate max heap property, but its\nchildren are max heaps. Run max_heapify to fix this.\n\nHeap-Sort\nSorting Strategy:\n1. Build Max Heap from unordered array;\n2. Find maximum element A[1];\n3. Swap elements A[n] and A[1]:\n\nnow max element is at the end of the array!\n4. Discard node n from heap\n\n(by decrementing heap-size variable)\n5. New root may violate max heap property, but its\nchildren are max heaps. Run max_heapify to fix this.\n6. Go to Step 2 unless heap is empty.\n\nHeap-Sort Demo\nSwap A[10] and A[1]\nMax_heapify(A,1)\n\nHeap-Sort Demo\nSwap A[9] and A[1]\n\nHeap-Sort Demo\n\nHeap-Sort Demo\nSwap A[8] and A[1]\n\nHeap-Sort\nRunning time:\nafter n iterations the Heap is empty\nevery iteration involves a swap and a max_heapify\noperation; hence it takes O(log n) time\nOverall O(n log n)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006\nIntroduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 05: Binary search trees, BST sort",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/d9c745bbfb610e9e53f6aef4261f3805_MIT6_006F11_lec05.pdf",
      "content": "Lecture 5\nScheduling and Binary Search Trees\n6.006 Fall 2011\nLecture 5: Scheduling and Binary Search\nTrees\nLecture Overview\n- Runway reservation system\n- Definition\n- How to solve with lists\n- Binary Search Trees\n- Operations\nReadings\nCLRS Chapter 10, 12.1-3\nRunway Reservation System\n- Airport with single (very busy) runway (Boston 6 →1)\n- \"Reservations\" for future landings\n- When plane lands, it is removed from set of pending events\n- Reserve req specify \"requested landing time\" t\n- Add t to the set if no other landings are scheduled within k minutes either way.\nAssume that k can vary.\n- else error, don't schedule\nExample\n46 49\ntime (mins)\nnow\nx\nx\nx\nx\nFigure 1: Runway Reservation System Example\nLet R denote the reserved landing times: R = (41, 46, 49, 56) and k = 3\n\nLecture 5\nScheduling and Binary Search Trees\n6.006 Fall 2011\nRequest for time: 44 not allowed (46 ∈R)\n53 OK\n20 not allowed (already past)\n| R |= n\nGoal: Run this system efficiently in O(lg n) time\nAlgorithm\nKeep R as a sorted list.\ninit: R = [ ]\nreq(t): if t < now: return \"error\"\nfor i in range (len(R)):\nif abs(t-R[i]) < k: return \"error\"\nR.append(t)\nR = sorted(R)\nland: t = R[0]\nif (t != now) return error\nR = R[1: ]\n(drop R[0] from R)\nCan we do better?\n- Sorted list: Appending and sorting takes Θ(n lg n) time. However, it is pos-\nsible to insert new time/plane rather than append and sort but insertion takes\nΘ(n) time. A k minute check can be done in O(1) once the insertion point is\nfound.\n- Sorted array: It is possible to do binary search to find place to insert in\nO(lg n) time. Using binary search, we find the smallest i such that R[i] ≥t,\ni.e., the next larger element. We then compare R[i] and R[i -1] against t.\nActual insertion however requires shifting elements which requires Θ(n) time.\n- Unsorted list/array: k minute check takes O(n) time.\n- Min-Heap: It is possible to insert in O(lg n) time. However, the k minute\ncheck will require O(n) time.\n- Dictionary or Python Set: Insertion is O(1) time. k minute check takes\nΩ(n) time\n\nLecture 5\nScheduling and Binary Search Trees\n6.006 Fall 2011\nWhat if times are in whole minutes?\nLarge array indexed by time does the trick.\nThis will not work for arbitrary\nprecision time or verifying width slots for landing.\nKey Lesson: Need fast insertion into sorted list.\n\nLecture 5\nScheduling and Binary Search Trees\n6.006 Fall 2011\nBinary Search Trees (BST)\ninsert 49\ninsert 79\ninsert 46\ninsert 41\ninsert 64\nBST\nBST\nBST\nBST\nroot\nall elements > 49\noff to the right,\nin right subtree\nall elements < 49,\ngo into left subtree\nBST\nNIL\nFigure 2: Binary Search Tree\nProperties\nEach node x in the binary tree has a key key(x). Nodes other than the root have a\nparent p(x). Nodes may have a left child left(x) and/or a right child right(x). These\nare pointers unlike in a heap.\nThe invariant is: for any node x, for all nodes y in the left subtree of x, key(y) ≤\nkey(x). For all nodes y in the right subtree of x key(y) ≥key(x).\nInsertion: insert(val)\nFollow left and right pointers till you find the position (or see the value), as illustrated\nin Figure 2. We can do the \"within k = 3\" check for runway reservation during\ninsertion. If you see on the path from the root an element that is within k = 3 of\nwhat you are inserting, then you interrupt the procedure, and do not insert.\nFinding a value in the BST if it exists: find(val)\nFollow left and right pointers until you find it or hit NIL.\n\nLecture 5\nScheduling and Binary Search Trees\n6.006 Fall 2011\nFinding the minimum element in a BST: findmin()\nKey is to just go left till you cannot go left anymore.\nFigure 3: Delete-Min: finds minimum and eliminates it\nComplexity\nAll operations are O(h) where h is height of the BST.\nFinding the next larger element: next-larger(x)\nNote that x is a node in the BST, not a value.\nnext-larger(x)\nif right child not NIL, return minimum(right)\nelse y = parent(x)\nwhile y not NIL and x = right(y)\nx = y; y = parent(y)\nreturn(y);\nSee Fig. 4 for an example. What would next-larger(find(46)) return?\nFigure 4: next-larger(x)\n\nLecture 5\nScheduling and Binary Search Trees\n6.006 Fall 2011\nNew Requirement\nRank(t): How many planes are scheduled to land at times ≤t? The new requirement\nnecessitates a design amendment.\nCannot solve it efficiently with what we have but can augment the BST structure.\nwhat lands before 79?\nkeep track of size of subtrees,\nduring insert and delete\nFigure 5: Augmenting the BST Structure\nSummarizing from Fig. 5, the algorithm for augmentation is as follows:\n1. Walk down tree to find desired time\n2. Add in nodes that are smaller\n3. Add in subtree sizes to the left\nIn total, this takes O(h) time.\n\nLecture 5\nScheduling and Binary Search Trees\n6.006 Fall 2011\n1 + 2 + 1 + 1 = 5\nsubtree\nsubtree\nFigure 6: Augmentation Algorithm Example\nAll the Python code for the Binary Search Trees discussed here are available at this\nlink\nHave we accomplished anything?\nHeight h of the tree should be O(lg n).\nFigure 7: Insert into BST in sorted order\nThe tree in Fig. 7 looks like a linked list. We have achieved O(n) not O(lg n)!!\nBalanced BSTs to the rescue in the next lecture!\n.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 06 Original: AVL trees, AVL sort",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/ff2c1cde338a7ad7792a3d2a5fafd3c5_MIT6_006F11_lec06_orig.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 06: AVL trees, AVL sort",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/83cdd705cd418d10d9769b741e34a2b8_MIT6_006F11_lec06.pdf",
      "content": "Lecture 6\nBalanced Binary Search Trees\n6.006 Fall 2011\nLecture 6: Balanced Binary Search Trees\nLecture Overview\n- The importance of being balanced\n- AVL trees\n- Definition and balance\n- Rotations\n- Insert\n- Other balanced trees\n- Data structures in general\n- Lower bounds\nRecall: Binary Search Trees (BSTs)\n- rooted binary tree\n- each node has\n- key\n- left pointer\n- right pointer\n- parent pointer\nSee Fig. 1\nFigure 1: Heights of nodes in a BST\n\nLecture 6\nBalanced Binary Search Trees\n6.006 Fall 2011\nx\n≤x\n≥x\nFigure 2: BST property\n- BST property (see Fig. 2).\n- height of node = length (# edges) of longest downward path to a leaf (see CLRS B.5\nfor details).\nThe Importance of Being Balanced:\n- BSTs support insert, delete, min, max, next-larger, next-smaller, etc. in O(h) time,\nwhere h = height of tree (= height of root).\n- h is between lg n and n: Fig. 3.\nvs.\nPerfectly Balanced\nPath\nFigure 3: Balancing BSTs\n- balanced BST maintains h = O(lg n) ⇒all operations run in O(lg n) time.\n\nLecture 6\nBalanced Binary Search Trees\n6.006 Fall 2011\nAVL Trees: Adel'son-Vel'skii & Landis 1962\nFor every node, require heights of left & right children to differ by at most ±1.\n- treat nil tree as height -1\n- each node stores its height (DATA STRUCTURE AUGMENTATION) (like subtree\nsize) (alternatively, can just store difference in heights)\nThis is illustrated in Fig. 4\nk\nk-1\nFigure 4: AVL Tree Concept\nBalance:\nWorst when every node differs by 1 -- let Nh = (min.) # nodes in height-h AVL tree\n=⇒Nh\n=\nNh-1 + Nh-2 + 1\n>\n2Nh-2\n=⇒Nh\n>\n2h/2\n=⇒h\n<\n2 lg Nh\nAlternatively:\nNh > Fh (nth Fibonacci number)\n- In fact Nh = Fn+1 -1 (simple induction)\nφ\n-\nh\n1 +\n√\nFh = √\nrounded to nearest integer where φ =\n≈1.618 (golden ratio)\n- =⇒max. h ≈logφ n ≈1.440 lg n\n\nLecture 6\nBalanced Binary Search Trees\n6.006 Fall 2011\nAVL Insert:\n1. insert as in simple BST\n2. work your way up tree, restoring AVL property (and updating heights as you go).\nEach Step:\n- suppose x is lowest node violating AVL\n- assume x is right-heavy (left case symmetric)\n- if x's right child is right-heavy or balanced: follow steps in Fig. 5\nx\ny\nA\nB\nC\nk+1\nk\nk-1\nk-1\nx\nz\nA\nB\nC\nk+1\nk-1\nLeft-Rotate(x)\nk\nk\ny\nx\nC\nA\nB\nk+1\nk\nk\nk-1\ny\nx\nC\nA\nB\nk\nk\nk-1\nk-1\nLeft-Rotate(x)\nFigure 5: AVL Insert Balancing\n- else: follow steps in Fig. 6\nx\nz\nA\nD\nk+1\nk-1\nLeft-Rotate(x)\nk-1\ny\nx\nA\nB\nk\nk-1\ny\nB\nC\nk\nk-1\nor\nk-2\nRight-Rotate(z)\nz\nC\nD\nk\nk-1\nk+1\nk-1\nor\nk-2\nFigure 6: AVL Insert Balancing\n- then continue up to x's grandparent, greatgrandparent . . .\n\nLecture 6\nBalanced Binary Search Trees\n6.006 Fall 2011\nExample: An example implementation of the AVL Insert process is illustrated in Fig. 7\nInsert(23)\nx = 29: left-left case\nDone\nInsert(55)\n29 0\nx=65: left-right case\n0φ\nDone\nFigure 7: Illustration of AVL Tree Insert Process\nComment 1. In general, process may need several rotations before done with an Insert.\nComment 2. Delete(-min) is similar -- harder but possible.\n\nLecture 6\nBalanced Binary Search Trees\n6.006 Fall 2011\nAVL sort:\n- insert each item into AVL tree\nΘ(n lg n)\nΘ(n)\n- in-order traversal\nΘ(n lg n)\nBalanced Search Trees:\nThere are many balanced search trees.\nAVL Trees\nAdel'son-Velsii and Landis 1962\nB-Trees/2-3-4 Trees\nBayer and McCreight 1972 (see CLRS 18)\nBB[α] Trees\nNievergelt and Reingold 1973\nRed-black Trees\nCLRS Chapter 13\n(A) -- Splay-Trees\nSleator and Tarjan 1985\n(R) -- Skip Lists\nPugh 1989\n(A) -- Scapegoat Trees\nGalperin and Rivest 1993\n(R) -- Treaps\nSeidel and Aragon 1996\n(R) = use random numbers to make decisions fast with high probability\n(A) = \"amortized\": adding up costs for several operations =⇒fast on average\nFor example, Splay Trees are a current research topic -- see 6.854 (Advanced Algorithms)\nand 6.851 (Advanced Data Structures)\nBig Picture:\nAbstract Data Type(ADT): interface spec.\nvs.\nData Structure (DS): algorithm for each op.\nThere are many possible DSs for one ADT. One example that we will discuss much later in\nthe course is the \"heap\" priority queue.\nPriority Queue ADT\nheap\nAVL tree\nQ = new-empty-queue()\nΘ(1)\nΘ(1)\nQ.insert(x)\nΘ(lg n)\nΘ(lg n)\nx = Q.deletemin()\nΘ(lg n)\nΘ(lg n)\nx = Q.findmin()\nΘ(1)\nΘ(lg n) →Θ(1)\n\nLecture 6\nBalanced Binary Search Trees\n6.006 Fall 2011\nPredecessor/Successor ADT\nheap\nAVL tree\nS = new-empty()\nΘ(1)\nΘ(1)\nS.insert(x)\nΘ(lg n)\nΘ(lg n)\nS.delete(x)\nΘ(lg n)\nΘ(lg n)\ny\n=\nS.predecessor(x)\n→\nnext-\nΘ(n)\nΘ(lg n)\nsmaller\ny = S.successor(x) →next-larger\nΘ(n)\nΘ(lg n)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 07 Original: Counting sort, radix sort, lower bounds for sorting and searching",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/47a412008dc74679e9072891be09f351_MIT6_006F11_lec07_orig.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 07: Counting sort, radix sort, lower bounds for sorting and searching",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/bf7d79105762bf79bbc0925438e1468a_MIT6_006F11_lec07.pdf",
      "content": "Lecture 7\nLinear-Time Sorting\n6.006 Fall 2011\nLecture 7: Linear-Time Sorting\nLecture Overview\n- Comparison model\n- Lower bounds\n- searching: Ω(lg n)\n- sorting: Ω(n lg n)\n- O(n) sorting algorithms for small integers\n- counting sort\n- radix sort\ntheorem\nproof\ncounterexample\nLower Bounds\nClaim\n- searching among n preprocessed items requires Ω(lg n) time\n=⇒binary search, AVL tree search optimal\n- sorting n items requires Ω(n lg n)\n=⇒mergesort, heap sort, AVL sort optimal\n. . . in the comparison model\nComparison Model of Computation\n- input items are black boxes (ADTs)\n- only support comparisons (<, >, ≤, etc.)\n- time cost = # comparisons\nDecision Tree\nAny comparison algorithm can be viewed/specified as a tree of all possible comparison\noutcomes & resulting output, for a particular n:\n- example, binary search for n = 3:\n\nLecture 7\nLinear-Time Sorting\n6.006 Fall 2011\nA[1] < x?\nA[0] < x?\nA[2] < x?\nNO\nYES\nNO\nNO\nYES\nYES\nx ≤A[0]\nA[2] < x\nA[0] < x ≤ A[1]\nA[1] < x ≤ A[2]\n- internal node = binary decision\n- leaf = output (algorithm is done)\n- root-to-leaf path = algorithm execution\n- path length (depth) = running time\n- height of tree = worst-case running time\nIn fact, binary decision tree model is more powerful than comparison model, and lower\nbounds extend to it\nSearch Lower Bound\n- # leaves ≥# possible answers ≥n\n(at least 1 per A[i])\n- decision tree is binary\n- =⇒height ≥lg Θ(n) = lg n ±| Θ(1)\nlg\n{z\nΘ(1)\n}\nSorting Lower Bound\n- leaf specifies answer as permutation: A[3] ≤A[1] ≤A[9] ≤. . .\n- all n! are possible answers\n\nLecture 7\nLinear-Time Sorting\n6.006 Fall 2011\n- # leaves ≥n!\n=⇒\nheight\n≥\nlg n!\n=\nlg(1 · 2 · · · (n -1) · n)\n=\nlg 1 + lg 2 + · · · + lg(n -1) + lg n\nn\n=\nX\nlg i\ni=1\nn\n≥\nlg\ni=\nX\ni\nn/2\nn\n≥\ni=\nX\nn\nlg 2\nn/2\n=lg\n|{z}\nn-1\nn\nn\n=\nlg n\n-\n= Ω(n lg n)\n- in fact lg n! = n lg n -O(n) via Sterling's Formula:\nn\n!\n√\nn\nn ∼\n2πn\n\n=⇒lg n! ∼n lg n -(lg e)n + 1\n|\nlg n + 1 lg(2π)\ne\n2 {z\nO(n)\n}\nLinear-time Sorting\nIf n keys are integers (fitting in a word) ∈0, 1, . . . , k -1, can do more than compare them\n- =⇒lower bounds don't apply\n- if k = nO(1), can sort in O(n) time\nOPEN: O(n) time possible for all k?\nCounting Sort\nL = array of k empty lists\nlists\n)\nO(k)\n-- linked or Python\nfor j in range n:\nO(n)\nL[k|ey(A[j])\n{z\n}].append(A[j])\n→O(1)\n\nrandom access using integer key\n\noutput = [ ]\n\nO(P\ni(1 + |L[i]|)) = O(k + n)\nfor i in range k:\noutput.extend(L[i])\n\nLecture 7\nLinear-Time Sorting\n6.006 Fall 2011\nTime: Θ(n + k)\n-- also Θ(n + k) space\nIntuition: Count key occurrences using RAM output <count> copies of each key in order\n. . . but item is more than just a key\nCLRS has cooler implementation of counting sort with counters, no lists -- but time bound\nis the same\nRadix Sort\n- imagine each integer in base b\n=⇒d = logb k digits ∈{0, 1, . . . , b -1}\n- sort (all n items) by least significant digit →can extract in O(1) time\n- · · ·\n- sort by most significant digit →can extract in O(1) time\nsort must be stable: preserve relative order of items with the same key\n=⇒don't mess up previous sorting\nFor example:\nsort\nsorted\nsorted\nsorted\n- use counting sort for digit sort\n- =⇒Θ(n + b) per digit\n- =⇒Θ((n + b)d) = Θ((n + b) logb k) total time\n- minimized when b = n\n- =⇒Θ(n logn k)\n- = O(nc) if k ≤nc\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/dcc62658425ffabc1dc93e9940589a66_MIT6_006F11_ps1.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nSeptember 8, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 1\nProblem Set 1\nBoth theory and programming questions are due Thursday, September 15 at 11:59PM.\nPlease download the .zip archive for this problem set, and refer to the README.txt file for\ninstructions on preparing your solutions. Remember, your goal is to communicate. Full credit will\nbe given only to a correct solution which is described clearly. Convoluted and obtuse descriptions\nmight receive low marks, even when they are correct. Also, aim for concise solutions, as it will\nsave you time spent on write-ups, and also help you conceptualize the key idea of the problem.\nWe will provide the solutions to the problem set 10 hours after the problem set is due, which\nyou will use to find any errors in the proof that you submitted. You will need to submit a critique\nof your solutions by Tuesday, September 20th, 11:59PM. Your grade will be based on both your\nsolutions and your critique of the solutions.\nProblem 1-1.\n[15 points] Asymptotic Practice\nFor each group of functions, sort the functions in increasing order of asymptotic (big-O) complex-\nity:\n(a) [5 points] Group 1:\nf1(n)\n=\nn0.999999 log n\nf2(n)\n=\n10000000n\nf3(n)\n=\n1.000001n\nf (n)\n=\nn2\n(b) [5 points] Group 2:\nf1(n)\n=\nf (n)\n=\nf\n\nn\nn\nf3(n)\n=\n4(n)\n=\nn√n\n(c) [5 points] Group 3:\n√\nf1(n)\n=\nn\nn\nf2(n)\n=\n2n\nf3(n)\n=\nn10 · 2n/2\nn\nf4(n)\n=\nX\n(i + 1)\ni=1\n\nProblem Set 1\nProblem 1-2.\n[15 points] Recurrence Relation Resolution\nFor each of the following recurrence relations, pick the correct asymptotic runtime:\n(a) [5 points] Select the correct asymptotic complexity of an algorithm with runtime\nT(n, n) where\nT(x, c)\n=\nΘ(x)\nfor c ≤2,\nT(c, y)\n=\nΘ(y)\nfor c ≤2, and\nT(x, y)\n=\nΘ(x + y) + T(x/2, y/2).\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\n(b) [5 points] Select the correct asymptotic complexity of an algorithm with runtime\nT(n, n) where\nT(x, c)\n=\nΘ(x)\nfor c ≤2,\nT(c, y)\n=\nΘ(y)\nfor c ≤2, and\nT(x, y)\n=\nΘ(x) + T(x, y/2).\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\n(c) [5 points] Select the correct asymptotic complexity of an algorithm with runtime\nT(n, n) where\nT(x, c)\n=\nΘ(x)\nfor c ≤2,\nT(x, y)\n=\nΘ(x) + S(x, y/2),\nS(c, y)\n=\nΘ(y)\nfor c ≤2, and\nS(x, y)\n=\nΘ(y) + T(x/2, y).\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\n\nProblem Set 1\nPeak-Finding\nIn Lecture 1, you saw the peak-finding problem. As a reminder, a peak in a matrix is a location\nwith the property that its four neighbors (north, south, east, and west) have value less than or equal\nto the value of the peak. We have posted Python code for solving this problem to the website in\na file called ps1.zip. In the file algorithms.py, there are four different algorithms which\nhave been written to solve the peak-finding problem, only some of which are correct. Your goal is\nto figure out which of these algorithms are correct and which are efficient.\nProblem 1-3.\n[16 points] Peak-Finding Correctness\n(a) [4 points] Is algorithm1 correct?\n1. Yes.\n2. No.\n(b) [4 points] Is algorithm2 correct?\n1. Yes.\n2. No.\n(c) [4 points] Is algorithm3 correct?\n1. Yes.\n2. No.\n(d) [4 points] Is algorithm4 correct?\n1. Yes.\n2. No.\nProblem 1-4.\n[16 points] Peak-Finding Efficiency\n(a) [4 points] What is the worst-case runtime of algorithm1 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\n(b) [4 points] What is the worst-case runtime of algorithm2 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n\nProblem Set 1\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\n(c) [4 points] What is the worst-case runtime of algorithm3 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\n(d) [4 points] What is the worst-case runtime of algorithm4 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\nProblem 1-5.\n[19 points] Peak-Finding Proof\nPlease modify the proof below to construct a proof of correctness for the most efficient correct\nalgorithm among algorithm2, algorithm3, and algorithm4.\nThe following is the proof of correctness for algorithm1, which was sketched in Lecture 1.\nWe wish to show that algorithm1 will always return a peak, as long as the problem\nis not empty. To that end, we wish to prove the following two statements:\n1. If the peak problem is not empty, then algorithm1 will always return a lo-\ncation. Say that we start with a problem of size m × n. The recursive subproblem\nexamined by algorithm1 will have dimensions m × ⌊n/2⌋or m × (n -⌊n/2⌋-1).\nTherefore, the number of columns in the problem strictly decreases with each recursive\ncall as long as n > 0. So algorithm1 either returns a location at some point, or even-\ntually examines a subproblem with a non-positive number of columns. The only way for\nthe number of columns to become strictly negative, according to the formulas that de-\ntermine the size of the subproblem, is to have n = 0 at some point. So if algorithm1\ndoesn't return a location, it must eventually examine an empty subproblem.\nWe wish to show that there is no way that this can occur. Assume, to the contrary, that\nalgorithm1 does examine an empty subproblem. Just prior to this, it must examine\n\nProblem Set 1\na subproblem of size m × 1 or m × 2. If the problem is of size m × 1, then calculating\nthe maximum of the central column is equivalent to calculating the maximum of the\nentire problem. Hence, the maximum that the algorithm finds must be a peak, and it\nwill halt and return the location. If the problem has dimensions m × 2, then there are\ntwo possibilities: either the maximum of the central column is a peak (in which case\nthe algorithm will halt and return the location), or it has a strictly better neighbor in the\nother column (in which case the algorithm will recurse on the non-empty subproblem\nwith dimensions m × 1, thus reducing to the previous case). So algorithm1 can\nnever recurse into an empty subproblem, and therefore algorithm1 must eventually\nreturn a location.\n2. If algorithm1 returns a location, it will be a peak in the original problem. If\nalgorithm1 returns a location (r1, c1), then that location must have the best value\nin column c1, and must have been a peak within some recursive subproblem. Assume,\nfor the sake of contradiction, that (r1, c1) is not also a peak within the original problem.\nThen as the location (r1, c1) is passed up the chain of recursive calls, it must eventually\nreach a level where it stops being a peak. At that level, the location (r1, c1) must be\nadjacent to the dividing column c2 (where |c1 -c2| = 1), and the values must satisfy the\ninequality val(r1, c1) < val(r1, c2).\nLet (r2, c2) be the location of the maximum value found by algorithm1 in the divid-\ning column. As a result, it must be that val(r1, c2) ≤val(r2, c2). Because the algorithm\nchose to recurse on the half containing (r1, c1), we know that val(r2, c2) < val(r2, c1).\nHence, we have the following chain of inequalities:\nval(r1, c1) < val(r1, c2) ≤val(r2, c2) < val(r2, c1)\nBut in order for algorithm1 to return (r1, c1) as a peak, the value at (r1, c1) must\nhave been the greatest in its column, making val(r1, c1) ≥val(r2, c1). Hence, we have\na contradiction.\nProblem 1-6.\n[19 points] Peak-Finding Counterexamples\nFor each incorrect algorithm, upload a Python file giving a counterexample (i.e. a matrix for which\nthe algorithm returns a location that is not a peak).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/e19680b53184ce34c80a665a25efc570_MIT6_006F11_ps2.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nSeptember 15, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 2\nProblem Set 2\nBoth theory and programming questions are due Tuesday, September 27 at 11:59PM.\nPlease download the .zip archive for this problem set, and refer to the README.txt file for\ninstructions on preparing your solutions.\nRemember, your goal is to communicate. Full credit will be given only to a correct solution\nwhich is described clearly. Convoluted and obtuse descriptions might receive low marks, even\nwhen they are correct. Also, aim for concise solutions, as it will save you time spent on write-ups,\nand also help you conceptualize the key idea of the problem.\nWe will provide the solutions to the problem set 10 hours after the problem set is due, which\nyou will use to find any errors in the proof that you submitted. You will need to submit a critique of\nyour solutions by Thursday, September 29th, 11:59PM. Your grade will be based on both your\nsolutions and your critique of the solutions.\nProblem 2-1.\n[40 points] Fractal Rendering\nYou landed a consulting gig with Gopple, who is about to introduce a new line of mobile phones\nwith Retina HD displays, which are based on unicorn e-ink and thus have infinite resolution. The\nhigh-level executives heard that fractals have infinite levels of detail, and decreed that the new\nphones' background will be the Koch snowflake (Figure 1).\nFigure 1: The Koch snowflake fractal, rendered at Level of Detail (LoD) 0 through 5.\nUnfortunately, the phone's processor (CPU) and the graphics chip (GPU) powering the display do\nnot have infinite processing power, so the Koch fractal cannot be rendered in infinite detail. Gopple\nengineers will stop the recursion at a fixed depth n in order to cap the processing requirement. For\nexample, at n = 0, the fractal is just a triangle. Because higher depths result in more detailed\ndrawing, this depth is usually called the Level of Detail (LoD).\nThe Koch snowflake at LoD n can be drawn using an algorithm following the sketch below:\n\nProblem Set 2\nSNOWFLAKE(n)\ne1, e2, e3 = edges of an equilateral triangle with side length 1\nSNOWFLAKE-EDGE(e1, n)\nSNOWFLAKE-EDGE(e2, n)\nSNOWFLAKE-EDGE(e3, n)\nSNOWFLAKE-EDGE(edge, n)\nif n == 0\nedge is an edge on the snowflake\nelse\ne1, e2, e3 = split edge in 3 equal parts\nSNOWFLAKE-EDGE(e1, n -1)\nf2, g2 = edges of an equilateral triangle whose 3rd edge is e2, pointing outside the snowflake\n∆(f2, g2, e2) is a triangle on the snowflake's surface\nSNOWFLAKE-EDGE(f2, n -1)\nSNOWFLAKE-EDGE(g2, n -1)\nSNOWFLAKE-EDGE(e3, n -1)\nThe sketch above should be sufficient for solving this problem. If you are curious about the missing\ndetails, you may download and unpack the problem set's .zip archive, and read the CoffeeScript\nimplementation in fractal/src/fractal.coffee.\nIn this problem, you will explore the computational requirements of four different methods for\nrendering the fractal, as a function of the LoD n. For the purpose of the analysis, consider the\nrecursive calls to SNOWFLAKE-EDGE; do not count the main call to SNOWFLAKE as part of the\nrecursion tree. (You can think of it as a super-root node at a special level -1, but it behaves differ-\nently from all other levels, so we do not include it in the tree.) Thus, the recursion tree is actually\na forest of trees, though we still refer to the entire forest as the \"recursion tree\". The root calls to\nSNOWFLAKE-EDGE are all at level 0.\nGopple's engineers have prepared a prototype of the Koch fractal drawing software, which you can\nuse to gain a better understanding of the problem. To use the prototype, download and unpack the\nproblem set's .zip archive, and use Google Chrome to open fractal/bin/fractal.html.\nFirst, in 3D hardware-accelerated rendering (e.g., iPhone), surfaces are broken down into triangles\n(Figure 2). The CPU compiles a list of coordinates for the triangles' vertices, and the GPU is\nresponsible for producing the final image. So, from the CPU's perspective, rendering a triangle\ncosts the same, no matter what its surface area is, and the time for rendering the snowflake fractal\nis proportional to the number of triangles in its decomposition.\n(a) [1 point] What is the height of the recursion tree for rendering a snowflake of LoD n?\n1. log n\n2. n\n\nProblem Set 2\nFigure 2: Koch snowflake drawn with triangles.\n3. 3 n\n4. 4 n\n(b) [2 points] How many nodes are there in the recursion tree at level i, for 0 ≤i ≤n?\n1. 3i\n2. 4i\n3. 4i+1\n4. 3 · 4i\n(c) [1 point] What is the asymptotic rendering time (triangle count) for a node in the\nrecursion tree at level i, for 0 ≤i < n?\n1. 0\n2. Θ(1)\n3.\ni\nΘ(1 )\n4. Θ(1 i)\n(d) [1 point] What is the asymptotic rendering time (triangle count) at each level i of the\nrecursion tree, for 0 ≤i < n?\n1. 0\n2. Θ(4 i)\n3. Θ(3i)\n4. Θ(4i)\n(e) [2 points] What is the total asymptotic cost for the CPU, when rendering a snowflake\nwith LoD n using 3D hardware-accelerated rendering?\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\n\nProblem Set 2\nSecond, when using 2D hardware-accelerated rendering, the surfaces' outlines are broken down\ninto open or closed paths (list of connected line segments). For example, our snowflake is one\nclosed path composed of straight lines. The CPU compiles the list of cooordinates in each path to\nbe drawn, and sends it to the GPU, which renders the final image. This approach is also used for\ntalking to high-end toys such as laser cutters and plotters.\n(f) [1 point] What is the height of the recursion tree for rendering a snowflake of LoD n\nusing 2D hardware-accelerated rendering?\n1. log n\n2. n\n3. 3 n\n4. 4 n\n(g) [1 point] How many nodes are there in the recursion tree at level i, for 0 ≤i ≤n?\n1. 3i\n2. 4i\n3. 4i+1\n4. 3 · 4i\n(h) [1 point] What is the asymptotic rendering time (line segment count) for a node in the\nrecursion tree at level i, for 0 ≤i < n?\n1. 0\n2. Θ(1)\n3. Θ(1 i)\n4. Θ(1 i)\n(i) [1 point] What is the asymptotic rendering time (line segment count) for a node in the\nlast level n of the recursion tree?\n1. 0\n2. Θ(1)\n3.\nn\nΘ(1 )\n4. Θ(1 n)\n(j) [1 point] What is the asymptotic rendering time (line segment count) at each level i\nof the recursion tree, for 0 ≤i < n?\n1. 0\n2. Θ(4 i)\n3. Θ(3i)\n4. Θ(4i)\n(k) [1 point] What is the asymptotic rendering time (line segment count) at the last level\nn in the recursion tree?\n\nProblem Set 2\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\n(l) [1 point] What is the total asymptotic cost for the CPU, when rendering a snowflake\nwith LoD n using 2D hardware-accelerated rendering?\n1. Θ(1)\n2. Θ(n)\n3.\nn\nΘ(4 )\n4. Θ(4n)\nThird, in 2D rendering without a hardware accelerator (also called software rendering), the CPU\ncompiles a list of line segments for each path like in the previous part, but then it is also responsible\nfor \"rasterizing\" each line segment. Rasterizing takes the coordinates of the segment's endpoints\nand computes the coordinates of all the pixels that lie on the line segment. Changing the colors of\nthese pixels effectively draws the line segment on the display. We know an algorithm to rasterize a\nline segment in time proportional to the length of the segment. It is easy to see that this algorithm\nis optimal, because the number of pixels on the segment is proportional to the segment's length.\nThroughout this problem, assume that all line segments have length at least one pixel, so that the\ncost of rasterizing is greater than the cost of compiling the line segments.\nIt might be interesting to note that the cost of 2D software rendering is proportional to the total\nlength of the path, which is also the power required to cut the path with a laser cutter, or the amount\nof ink needed to print the path on paper.\n(m) [1 point] What is the height of the recursion tree for rendering a snowflake of LoD n?\n1. log n\n2. n\n3. 3 n\n4. 4 n\n(n) [1 point] How many nodes are there in the recursion tree at level i, for 0 ≤i ≤n?\n1. 3i\n2. 4i\n3. 4i+1\n4. 3 · 4i\n(o) [1 point] What is the asymptotic rendering time (line segment length) for a node in\nthe recursion tree at level i, for 0 ≤i < n? Assume that the sides of the initial triangle\nhave length 1.\n1. 0\n\nProblem Set 2\n2. Θ(1)\n3. Θ(1 i)\n4. Θ(1 i)\n(p) [1 point] What is the asymptotic rendering time (line segment length) for a node in\nthe last level n of the recursion tree?\n1. 0\n2. Θ(1)\n3. Θ(1 n)\n4. Θ(1 n)\n(q) [1 point] What is the asymptotic rendering time (line segment length) at each level i\nof the recursion tree, for 0 ≤i < n?\n1. 0\n2. Θ(4 i)\n3. Θ(3i)\n4. Θ(4i)\n(r) [1 point] What is the asymptotic rendering time (line segment length) at the last level\nn in the recursion tree?\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\n(s) [1 point] What is the total asymptotic cost for the CPU, when rendering a snowflake\nwith LoD n using 2D software (not hardware-accelerated) rendering?\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\nThe fourth and last case we consider is 3D rendering without hardware acceleration. In this case,\nthe CPU compiles a list of triangles, and then rasterizes each triangle. We know an algorithm to\nrasterize a triangle that runs in time proportional to the triangle's surface area. This algorithm is\noptimal, because the number of pixels inside a triangle is proportional to the triangle's area. For\nthe purpose of this problem, you can assume that the area of a triangle with side length l is Θ(l2).\nWe also assume that the cost of rasterizing is greater than the cost of compiling the line segments.\n(t) [4 points] What is the total asymptotic cost of rendering a snowflake with LoD n?\nAssume that initial triangle's side length is 1.\n\nProblem Set 2\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\n(u) [15 points] Write a succinct proof for your answer using the recursion-tree method.\nProblem 2-2.\n[60 points] Digital Circuit Simulation\nYour 6.006 skills landed you a nice internship at the chip manufacturer AMDtel. Their hardware\nverification team has been complaining that their circuit simulator is slow, and your manager de-\ncided that your algorithmic chops make you the perfect candidate for optimizing the simulator.\nA combinational circuit is made up of gates, which are devices that take Boolean (True / 1 and\nFalse / 0) input signals, and output a signal that is a function of the input signals. Gates take some\ntime to compute their functions, so a gate's output at time τ reflects the gate's inputs at time τ -δ,\nwhere δ is the gate's delay. For the purposes of this simulator, a gate's output transitions between\n0 and 1 instantly. Gates' output terminals are connected to other gates' inputs terminals by wires\nthat propagate the signal instantly without altering it.\nFor example, a 2-input XOR gate with inputs A and B (Figure 3) with a 2 nanosecond (ns) delay\nworks as follows:\nTime (ns)\nInput A\nInput B\nOutput O\nExplanation\nReflects inputs at time -2\nReflects inputs at time -1\n0 XOR 0, given at time 0\n0 XOR 1, given at time 1\n1 XOR 0, given at time 2\n1 XOR 1, given at time 3\nA\nB\nO\nFigure 3: 2-input XOR gate; A and B supply the inputs, and O receives the output.\nThe circuit simulator takes an input file that describes a circuit layout, including gates' delays,\nprobes (indicating the gates that we want to monitor the output), and external inputs. It then\nsimulates the transitions at the output terminals of all the gates as time progresses. It also outputs\ntransitions at the probed gates in the order of the timing of those transitions.\nThis problem will walk you through the best known approach for fixing performance issues in a\nsystem. You will profile the code, find the performance bottleneck, understand the reason behind\nit, and remove the bottleneck by optimizing the code.\n\nProblem Set 2\nTo start working with AMDtel's circuit simulation source code, download and unpack the problem\nset's .zip archive, and go to the circuit/ directory.\nThe circuit simulator is in circuit.py. The AMDtel engineers pointed out that the simulation\ninput in tests/5devadas13.in takes too long to run. We have also provided an automated\ntest suite at test-circuit.py, together with other simulation inputs. You can ignore these\nfiles until you get to the last part of the problem set.\n(a) [8 points] Run the code under the python profiler with the command below, and\nidentify the method that takes up most of the CPU time. If two methods have similar\nCPU usage times, ignore the simpler one.\npython -m cProfile -s time circuit.py < tests/5devadas13.in\nWarning: the command above can take 15-30 minutes to complete, and bring the CPU\nusage to 100% on one of your cores. Plan accordingly.\nWhat is the name of the method with the highest CPU usage?\n(b) [6 points] How many times is the method called?\n(c) [8 points] The class containing the troublesome method is implementing a familiar\ndata structure. What is the tightest asymptotic bound for the worst-case running time\nof the method that contains the bottleneck? Express your answer in terms of n, the\nnumber of elements in the data structure.\n1. O(1).\n2. O(log n).\n3. O(n).\n4. O(n log n).\n5. O(n log2 n).\n6. O(n2).\n(d) [8 points] If the data structure were implemented using the most efficient method\nwe learned in class, what would be the tightest asymptotic bound for the worst-case\nrunning time of the method discussed in the questions above?\n1. O(1).\n2. O(log n).\n3. O(n).\n4. O(n log n).\n5. O(n log2 n).\n6. O(n2).\n(e) [30 points] Rewrite the data structure class using the most efficient method we learned\nin class. Please note that you are not allowed to import any additional Python\nlibraries and our test will check this.\n\nProblem Set 2\nWe have provided a few tests to help you check your code's correctness and speed. The\ntest cases are in the tests/ directory. tests/README.txt explains the syntax\nof the simulator input files. You can use the following command to run all the tests.\npython circuit test.py\nTo work on a single test case, run the simulator on the test case with the following\ncommand.\npython circuit.py < tests/1gate.in > out\nThen compare your output with the correct output for the test case.\ndiff out tests/1gate.gold\nFor Windows, use fc to compare files.\nfc out tests/1gate.gold\nWe have implemented a visualizer for your output, to help you debug your code. To\nuse the visualizer, first produce a simulation trace.\nTRACE=jsonp python circuit.py < tests/1gate.in > circuit.jsonp\nOn Windows, use the following command instead.\ncircuit jsonp.bat < tests/1gate.in > circuit.jsonp\nThen use Google Chrome to open visualizer/bin/visualizer.html\nWe recommend using the small test cases numbered 1 through 4 to check your imple-\nmentation's correctness, and then use test case 5 to check the code's speed.\nWhen your code passes all tests, and runs reasonably fast (the tests should complete\nin less than 30 seconds on any reasonably recent computer), upload your modified\ncircuit.py to the course submission site.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/297bbcd7d2a9a2a71a410b0ae41ba5d7_MIT6_006F11_ps3.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nSeptember 29, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 3\nProblem Set 3\nBoth theory and programming questions are due Thursday, October 6 at 11:59PM. Please\ndownload the .zip archive for this problem set, and refer to the README.txt file for instructions\non preparing your solutions.\nWe will provide the solutions to the problem set 10 hours after the problem set is due, which\nyou will use to find any errors in the proof that you submitted. You will need to submit a critique of\nyour solutions by Friday, October 7th, 11:59PM. Your grade will be based on both your solutions\nand your critique of the solutions.\nProblem 3-1.\n[45 points] Range Queries\nMicroware is preparing to launch a new database product, NoSQL Server, aimed at the real-time\nanalytics market. Web application analytics record information (e.g., the times when users visit\nthe site, or how much does it take the server to produce a HTTP response), and can display the\ninformation using a Pretty GraphTM1, so that CTOs can claim that they're using data to back their\ndecisions.\nNoSQL Server databases will support a special kind of index, called a range index, to speed up the\noperations needed to build a Pretty GraphTM out of data. Microware has interviewed you during\nthe fall Career Fair, and immediately hired you as a consultant and asked you to help the NoSQL\nServer team design the range index.\nThe range index must support fast (sub-linear) insertions, to keep up with Web application traffic.\nThe first step in the Pretty GraphTM algorithm is finding the minimum and maximum values to be\nplotted, to set up the graph's horizontal axis. So the range index must also be able to compute the\nminimum and maximum over all keys quickly (in sub-linear time).\n(a) [1 point] Given the constraints above, what data structure covered in 6.006 lectures\nshould be used for the range index? Microware engineers need to implement range\nindexes, so choose the simplest data struture that meets the requirements.\n1. Min-Heap\n2. Max-Heap\n3. Binary Search Tree (BST)\n4. AVL Trees\n5. B-Trees\n(b) [1 point] How much time will it take to insert a key in the range index?\n1. O(1)\n1U.S. patent pending, no. 9,999,999\n\nProblem Set 3\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n(c) [1 point] How much time will it take to find the minimum key in the range index?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n(d) [1 point] How much time will it take to find the maximum key in the range index?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\nThe main work of the Pretty GraphTM algorithm is drawing the bars in the graph. A bar shows how\nmany data points there are between two values. For example, in order to produce the visitor graph\nthat is the hallmark of Google Analytics, the range index would record each time that someone uses\nthe site, and a bar would count the visiting times between the beginning and the ending of a day.\nTherefore, the range index needs to support a fast (sub-linear time) COUNT(l, h) query that returns\nthe number of keys in the index that are between l and h (formally, keys k such that l ≤k ≤h).\nYour instinct (or 6.006 TA) tells you that COUNT(l, h) can be easily implemented on top of a\nsimpler query, RANK(x), which returns the number of keys in the index that are smaller or equal\nto x (informally, if the keys were listed in ascending order, x's rank would indicate its position in\nthe sorted array).\n(e) [1 point] Assuming l < h, and both l and h exist in the index, COUNT(l, h) is\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\n\nProblem Set 3\n(f) [1 point] Assuming l < h, and h exists in the index, but l does not exist in the index,\nCOUNT(l, h) is\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\n(g) [1 point] Assuming l < h, and l exists in the index, but h does not exist in the index,\nCOUNT(l, h) is\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\n(h) [1 point] Assuming l < h, and neither l nor h exist in the index, COUNT(l, h) is\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\nNow that you know how to reduce a COUNT() query to a constant number of RANK() queries, you\nwant to figure out how to implement RANK() in sub-linear time. None of the tree data structures\nthat you studied in 6.006 supports optimized RANK() out of the box, but you just remembered that\ntree data structures can respond to some queries faster if the nodes are cleverly augmented with\nsome information.\n\nProblem Set 3\n(i) [1 point] In order to respond to RANK() queries in sub-linear time, each node node\nin the tree will be augmented with an extra field, node .γ. Keep in mind that for a\ngood augmentation, the extra information for a node should be computed in O(1)\ntime, based on other properties of the node, and on the extra information stored in the\nnode's subtree. The meaning of node .γ is\n1. the minimum key in the subtree rooted at node\n2. the maximum key in the subtree rooted at node\n3. the height of the subtree rooted at node\n4. the number of nodes in the subtree rooted at node\n5. the rank of node\n6. the sum of keys in the subtree roted at node\n(j) [1 point] How many extra bits of storage per node does the augmentation above\nrequire?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n6. O(N)\nThe following questions refer to the tree below.\nN1\nN2\nN3\nN4\nN5\nN6\nN7\nN8\nN9\nN10\n(k) [1 point] N4 .γ is\n1. 0\n2. 1\n3. 2\n4. the key at N4\n\nProblem Set 3\n(l) [1 point] N3 .γ is\n1. 1\n2. 2\n3. 3\n4. the key at N4\n5. the key at N5\n6. the sum of keys at N3 . . . N5\n(m) [1 point] N2 .γ is\n1. 2\n2. 3\n3. 4\n4. 6\n5. the key at N4\n6. the key at N7\n7. the sum of keys at N3 . . . N5\n(n) [1 point] N1 .γ is\n1. 3\n2. 6\n3. 7\n4. 10\n5. the key at N4\n6. the key at N10\n7. the sum of keys at N1 . . . N10\n(o) [6 points] Which of the following functions need to be modified to update γ? If a\nfunction does not apply to the tree for the range index, it doesn't need to be modified.\n(True / False)\n1. INSERT\n2. DELETE\n3. ROTATE-LEFT\n4. ROTATE-RIGHT\n5. REBALANCE\n6. HEAPIFY\n(p) [1 point] What is the running time of a COUNT() implementation based on RANK()?\n1. O(1)\n2. O(log(log N))\n\nProblem Set 3\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\nAfter the analytics data is plotted using Pretty GraphTM, the CEO can hover the mouse cursor over\none of the bars, and the graph will show a tooltip with the information represented by that bar. To\nsupport this operation, the range index needs to support a LIST(l, h) operation that returns all the\nkeys between l and h as quickly as possible.\nLIST(l, h) cannot be sub-linear in the worst case, because LIST(-inf, +inf) must return all the keys\nin the index, which takes Ω(n) time. However, if LIST only has to return a few elements, we would\nlike it to run in sub-linear time. We formalize this by stating that LIST's running time should be\nT(N) + Θ(L), where L is the length of the list of keys output by LIST, and T(N) is sub-linear.\nInspiration (or your 6.006 TA) strikes again, and you find yourself with the following pseudocode\nfor LIST.\nLIST(tree, l, h)\nlca = LCA(tree, l, h)\nresult = []\nNODE-LIST(lca, l, h, result)\nreturn result\nNODE-LIST(node, l, h, result)\nif node == NIL\nreturn\nif l ≤node .key and node .key ≤h\nADD-KEY(result, node .key)\nif node .key ≥l\nNODE-LIST(node .left, l, h, result)\nif node .key ≤h\nNODE-LIST(node .right, l, h, result)\nLCA(tree, l, h)\nnode = tree .root\nuntil node == NIL or (l ≤node .key and h ≥node .key)\nif l < node .key\nnode = node .left\nelse\nnode = node .right\nreturn node\n\nProblem Set 3\n(q) [1 point] LCA most likely means\n1. last common ancestor\n2. lowest common ancestor\n3. low cost airline\n4. life cycle assessment\n5. logic cell array\n(r) [1 point] The running time of LCA(l, h) for the trees used by the range index is\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n(s) [1 point] Assuming that ADD-KEY runs in O(1) time, and that LIST returns a list of\nL keys, the running time of the NODE-LIST call at line 3 of LIST is\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n6. O(1) + O(L)\n7. O(log(log N)) + O(L)\n8. O(log N) + O(L)\n9. O(log2 N) + O(L)\n10. O(\n√\nN) + O(L)\n(t) [1 point] Assuming that ADD-KEY runs in O(1) time, and that LIST returns a list of\nL keys, the running time of LIST is\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n6. O(1) + O(L)\n7. O(log(log N)) + O(L)\n8. O(log N) + O(L)\n9. O(log2 N) + O(L)\n10. O(\n√\nN) + O(L)\n\nProblem Set 3\n(u) [20 points] Prove that LCA is correct.\nProblem 3-2.\n[55 points] Digital Circuit Layout\nYour AMDtel internship is off to a great start! The optimized circuit simulator cemented your\nreputation as an algorithms whiz. Your manager capitalized on your success, and promised to\ndeliver the Bullfield chip a few months ahead of schedule. Thanks to your simulator optimizations,\nthe engineers have finished the logic-level design, and are currently working on laying out the\ngates on the chip. Unfortunately, the software that verifies the layout is taking too long to run\non the preliminary Bullfield layouts, and this is making the engineers slow and unhappy. Your\nmanager is confident in your abilities to speed it up, and promised that you'll \"do your magic\"\nagain, in \"one week, two weeks tops\".\nA chip consists of logic gates, whose input and output terminals are connected by wires (very\nthin conductive traces on the silicon substrate). AMDtel's high-yield manufacturing process only\nallows for horizontal or vertical wires. Wires must not cross each other, so that the circuit will\nfunction according to its specification. This constraint is checked by the software tool that you\nwill optimize. The topologies required by complex circuits are accomplished by having dozens of\nlayers of wires that do not touch each other, and the tool works on one layer at a time.\n(a) [1 point] Run the code under the python profiler with the command below, and iden-\ntify the method that takes up most of the CPU time. If two methods have similar CPU\nusage times, ignore the simpler one.\npython -m cProfile -s time circuit2.py < tests/10grid s.in\nWarning: the command above can take 15-60 minutes to complete, and bring the\nCPU usage to 100% on one of your cores. Plan accordingly. If you have installed\nPyPy successfully, you can replace python with pypy in the command above for a\nroughly 2x speed improvement.\nWhat is the name of the method with the highest CPU usage?\n(b) [1 point] How many times is the method called?\nThe method that has the performance bottleneck is called from the CrossVerifier class. Upon\nreading the class, it seems that the original author was planning to implement a sweep-line algo-\nrithm, but couldn't figure out the details, and bailed and implemented an inefficient method at the\nlast minute. Fortunately, most of the infrastructure for a fast sweep-line algorithm is still in place.\nFurthermore, you notice that the source code contains a trace of the working sweep-line algorithm,\nin the good trace.jsonp file.\nSweep-line algorithms are popular in computational geometry. Conceptually, such an algorithm\nsweeps a vertical line left to right over the plane containing the input data, and performs operations\nwhen the line \"hits\" point of interest in the input. This is implemented by generating an array\ncontaining all the points of interest, and then sorting them according to their position along the\nhorizontal axis (x coordinate).\n\nProblem Set 3\nRead the source for CrossVerifier to get a feel for how the sweep-line infrastructure is sup-\nposed to work, and look at the good trace in the visualizer that we have provided for you. To see\nthe good trace, copy good trace.jsonp to trace.jsonp\ncp good trace.jsonp trace.jsonp\nOn Windows, use the following command instead.\ncopy good trace.jsonp trace.jsonp\nThen use Google Chrome to open visualizer/bin/visualizer.html\nThe questions below refer to the fast sweep-line algorithm shown in good trace.jsonp, not\nto the slow algorithm hacked together in circuit2.py.\n(c) [5 points] The x coordinates of points of interest in the input are (True / False)\n1. the x coordinates of the left endpoints of horizontal wires\n2. the x coordinates of the right endpoints of horizontal wires\n3. the x coordinates of midpoints of horizontal wires\n4. the x coordinates where horizontal wires cross vertical wires\n5. the x coordinates of vertical wires\n(d) [1 point] When the sweep line hits the x coordinate of the left endpoint of a horizontal\nwire\n1. the wire is added to the range index\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\n(e) [1 point] When the sweep line hits the x coordinate of the right endpoint of a hori-\nzontal wire\n1. the wire is added to the range index\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\n(f) [1 point] When the sweep line hits the x coordinate of the midpoint of a horizontal\nwire\n1. the wire is added to the range index\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\n(g) [1 point] When the sweep line hits the x coordinate of a vertical wire\n1. the wire is added to the range index\n\nProblem Set 3\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\n(h) [1 point] What is a good invariant for the sweep-line algorithm?\n1. the range index holds all the horizontal wires to the left of the sweep line\n2. the range index holds all the horizontal wires \"stabbed\" by the sweep line\n3. the range index holds all the horizontal wires to the right of the sweep line\n4. the range index holds all the wires to the left of the sweep line\n5. the range index holds all the wires to the right of the sweep line\n(i) [1 point] When a wire is added to the range index, what is its corresponding key?\n1. the x coordinate of the wire's midpoint\n2. the y coordinate of the wire's midpoint\n3. the segment's length\n4. the x coordinate of the point of interest that will remove the wire from the index\nModify CrossVerifier in circuit2.py to implement the sweep-line algorithm discussed\nabove. If you maintain the current code structure, you'll be able to use our visualizer to debug your\nimplementation. To use our visualizer, first produce a trace.\nTRACE=jsonp python circuit2.py < tests/5logo.in > trace.jsonp\nOn Windows, run the following command instead.\ncircuit2 jsonp.bat < tests/5logo.in > trace.jsonp\nThen use Google Chrome to open visualizer/bin/visualizer.html\n(j) [1 point] Run your modified code under the python profiler again, using the same test\ncase as before, and identify the method that takes up the most CPU time.\nWhat is the name of the method with the highest CPU usage? If two methods have\nsimilar CPU usage times, ignore the simpler one.\n(k) [1 point] How many times is the method called?\n(l) [40 points] Modify circuit2.py to implement a data structure that has better\nasymptotic running time for the operation above. Keep in mind that the tool has two\nusage scenarios:\n- Every time an engineer submits a change to one of the Bullhorn wire layers,\nthe tool must analyze the layer and report the number of wire crossings. In this\nlate stage of the project, the version control system will automatically reject the\nengineer's change if it causes the number of wire crossings to go up over the\nprevious version.\n\nProblem Set 3\n- Engineers working on the wiring want to see the pairs of wires that intersect, so\nthey know where to focus ther efforts. To activate this detailed output, run the\ntool using the following command.\nTRACE=list python circuit2.py < tests/6list logo.in\nOn Windows, run the following command instead.\ncircuit2 list.bat < tests/6list logo.in\nWhen your code passes all tests, and runs reasonably fast (the tests should complete\nin less than 60 seconds on any reasonably recent computer), upload your modified\ncircuit.py to the course submission site.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/f3c1a127eed4bff7009d08ccae246017_MIT6_006F11_ps4.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\n7 October, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 4\nProblem Set 4\nBoth theory and programming questions are due Friday, 14 October at 11:59PM.\nRemember that for the written response question, your goal is to communicate. Full credit will\nbe given only to a correct solution which is described clearly. Convoluted and obtuse descriptions\nmight receive low marks, even when they are correct. Also, aim for concise solutions, as it will\nsave you time spent on write-ups, and also help you conceptualize the key idea of the problem.\nWe will provide the solutions to the problem set 10 hours after the problem set is due, which\nyou will use to find any errors in the proof that you submitted. You will need to submit a critique\nof your solutions by Thursday, October 20th, 11:59PM. Your grade will be based on both your\nsolutions and your critique of the solutions.\nProblem 4-1.\n[35 points] Hash Functions and Load\n(a) Imagine that an algorithm requires us to hash strings containing English phrases.\nKnowing that strings are stored as sequences of characters, Alyssa P. Hacker decides\nto simply use the sum of those character values (modulo the size of her hash table)\nas the string's hash. Will the performance of her implementation match the expected\nvalue shown in lecture?\n1. Yes, the sum operation will space strings out nicely by length.\n2. Yes, the sum operation will space strings out nicely by the characters they contain.\n3. No, because reordering the words in a string will not produce a different hash.\n4. No, because the independence condition of the simple uniform hashing assump-\ntion is violated.\n(b) Alyssa decides to implement both collision resolution and dynamic resizing for her\nhash table. However, she doesn't want to do more work than necessary, so she wonders\nif she needs both to maintain the correctness and performance she expects. After all,\nif she has dynamic resizing, she can resize to avoid collisions; and if she has collision\nresolution, collisions don't cause correctness issues. Which statement about these two\nproperties true?\n1. Dynamic resizing alone will preserve both properties.\n2. Dynamic resizing alone will preserve correctness, but not performance.\n3. Collision resolution alone will preserve performance, but not correctness.\n4. Both are necessary to maintain performance and correctness.\n\nProblem Set 4\n(c) Suppose that Alyssa decides to implement resizing. If Alyssa is enlarging a table of\nsize m into a table of size m, and the table contains n elements, what is the best time\ncomplexity she can achieve?\n1. Θ(m)\n2. Θ(m′)\n3. Θ(n)\n4. Θ(nm′)\n5. Θ(m + m′)\n6. Θ(m + n)\n7. Θ(m′ + n)\n(d) In lecture, we discussed doubling the size of our hash table. Ivy H. Crimson begins\nto implement this approach (that is, she lets m′ = 2m) but stops when it occurs to\nher that she might be able to avoid wasting half of the memory the table occupies on\nempty space by letting m′ = m+k instead, where k is some constant. Does this work?\nIf so, why do you think we don't do it? There is a good theoretical reason as well as\nseveral additional practical concerns; a complete answer will touch on both points.\nProblem 4-2.\n[10 points] Python Dictionaries\nWe're going to get started by checking out a file from Python's Subversion repository at svn.python.org.\nThe Python project operates a web frontend to their version control system, so we'll be able to do\nthis using a browser.\nVisit http://svn.python.org/projects/python/trunk/Objects/dictnotes.txt.\nThese are actual notes prepared by contributors to the Python project, as they currently exist in the\nPython source tree. (Cool! Actually, this document is a fascinating read--and you should be able\nto understand most of it.) Read over the seven use cases identified at the top of this document.\n(a) Let's examine the \"membership testing\" use case. Which statement accurately de-\nscribes this use case?\n1. Many insertions right after creation, and then mostly lookups.\n2. Many insertions right after creation, and then only lookups.\n3. A workload of evenly-mixed insertions/deletions and lookups.\n4. Alternating rounds of insertions/deletions and lookups.\n(b) Now imagine that you have to pick a hash function, size, collision resolution strategy,\nand so forth (all of the characteristics of a hash table we've seen so far) in order to\nmake a hash table perfectly suited to this use case alone. Pick the statement that best\ndescribes the choices you might make.\n1. A large minimum size and a growth rate of 2.\n2. A small minimum size and a growth rate of 2.\n\nProblem Set 4\n3. A large minimum size and a growth rate of 4.\n4. A small minimum size and a growth rate of 4.\nProblem 4-3.\n[55 points] Matching DNA Sequences\nThe code and data used in this problem are available on the course website. Please take a peek at\nthe README.txt for some instructions.\nBen Bitdiddle has recently moved into the Kendall Square area, which is full of biotechnology\ncompanies and their shiny, window-laden office buildings. While mocking their dorky lab coats\nmakes him feel slightly better about himself, he is secretly jealous, and so he sets out to earn one\nof his very own. To pick up the necessary geek cred, he begins experimenting with DNA-matching\ntechnologies.\nBen would like to create mutants to do his bidding, and to get started, he'd like to know how closely\nrelated the creatures he's collected are. If two sequences contain mostly the same subsequences\nin mostly the same places, then they're likely closely related; if they don't, they probably aren't.\n(This is, of course, a gross oversimplification.)\nFor our purposes, we'll represent a DNA sample as a sequence of characters. (These characters will\nall be upper-case. You can look at the Wikipedia page on nucleotides for a list of code characters\nand their meanings.) These sequences are very long, so comparing subsequences of them quickly\nis important. We've provided code in kfasta.py that reads the .fa files storing this data.\n(a) Let's start with subsequenceHashes, which returns all length-k subsequences\nand their hashes (and perhaps other information, if there's anything else you might\nfind useful).\nHint: There will likely be many of these matches; the DNA sequences are tens of mil-\nlions of nucleotides long. To avoid keeping them all in memory at once, implement\nyour function as a generator. See the Python reference materials available online for\ndetails if you aren't familiar with this important language construct.\n(b) Implement Multidict and verify that your work passes the simple sanity tests pro-\nvided.\nMultidict should behave just like a Python dictionary, except that it can store mul-\ntiple values per key. If no values exist for a key, it returns an empty list; otherwise, it\nreturns the list of associated values. You may (and probably should) use the Python\ndictionary in your implementation.\n(c) Now it's time to implement getExactSubmatches. Ignore the parameter m for\nthe time being; we'll get to that in the next part. Again, implementing this function as\na generator is probably a good idea. (You will probably have many, many matches-\nthink about the combinatorics of the situation briefly.) As a hint, consider that much\nof the work has already been done by Multidict and subsequenceHashes;\nalso take a peek at the RollingHash implementation we've given you. With these\n\nProblem Set 4\nbuilding blocks, your solution probably does not need to be very complex (or more\nthan a few lines).\nThis function should return pairs of offsets into the inputs. A tuple (x, y) being re-\nturned indicates that the k-length subsequence at position x in the first input matches\nthe subsequence at position y in the second input.\nWe've provided a simple sanity test; your solution should be correct at this point (that\nis, dnaseq.py will produce the right output) but it'll probably be too slow to be\nuseful. If you like, you can try running it on the first portion of two inputs; we've\nprovided two such prefixes (the short files in the data directory) that might be helpful.\n(d) The most significant reason why your solution is presently too slow to be useful is\nthat you are hashing and inserting into your hash table tens of millions of elements,\nand then performing tens of millions of lookups into that hash table. Implement\nintervalSubsequenceHashes, which returns the same thing as subsequenceHashes\nexcept that it hashes only one in m subsequences. (A good implementation will not do\nmore work than is necessary.) Modify your implementation of getExactSubmatches\nto honor m only for sequence A. Consider why we still see approximately the same\nresult, and why we can't further improve performance by applying this technique to\nsequence B as well.\n(e) Run comparisons between the two human samples (paternal and maternal) and be-\ntween the paternal sample and each of the animal samples.\nFeel free to take a peek at how the image-generation code works. Conceptually, what\nit's doing is keeping track of how many of your (x, y) match tuples land in each of\na two-dimensional grid of bins, each of which corresponds to a pixel in the output\nimage. At the end, it normalizes the counts so that the highest count observed is\ntotally black and an empty bin is white.\nThink for a second about what a perfect match (e.g., comparing a sequence to itself)\nshould look like. Try comparing the two human samples you have (maternal and pa-\nternal), one of the humans against the chimp sample, and then against the dog sample.\nMake sure your results make sense!\nWe've posted what our reference solution produced for the human-human comparison,\nthe human-chimp comparison, and the human-dog comparison.\nPlease submit the code that you wrote. (You should only have had to modify dnaseq.py,\nso that's all you need to submit.)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/bb0830c9a6ac4e3176f7b0752c948a9d_MIT6_006F11_ps5.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nOctober 24, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 5\nProblem Set 5\nBoth theory and programming questions are due Monday, October 31 at 11:59PM. Please\ndownload the .zip archive for this problem set, and refer to the README.txt file for instructions\non preparing your solutions.\nWe will provide the solutions to the problem set 10 hours after the problem set is due. You will\nhave to read the solutions, and write a brief grading explanation to help your grader understand\nyour write-up. You will need to submit the grading explanation by Thursday, November 3rd,\n11:59PM. Your grade will be based on both your solutions and the grading explanation.\nProblem 5-1.\n[40 points] The Knight's Shield\nThe optimized circuit verifier that you developed on your Amdtel internship was a huge success\nand got you on a sure track to landing a sweet offer. You also got transferred to a research group\nthat is working on the Knight's Shield (KS)1, a high-stakes project to develop a massive multi-core\nchip aimed at the exploding secure cloud computing market.\nThe KS chip packs 16,384 cores in a die that's the same size as a regular CPU die. However, each\ncore is very small, and can only do arithmetic operations using 8-bit or 16-bit unsigned integers\n(see Table 1). Encryption algorithms typically use 2,048-bit integers, so the KS chip will ship with\nsoftware that supports arithmetic on large integers. Your job is to help the KS team assess the\nefficiency of their software.\nOperation\nR1 size\nR2 size\nResult size\nResult\nZERO\n8 / 16\n0 (zero)\nONE\n8 / 16\n1 (one)\nLSB R1\nR1 % 256 (least significant byte)\nMSB R1\nR1 / 256 (most significant byte)\nWORD R1\nR1 (expanded to 16-bits)\nADD R1, R2\n8 / 16\n8 / 16\nR1 + R2\nSUB R1, R2\n8 / 16\n8 / 16\nR1 -R2\nmod 65536\nMUL R1, R2\nR1 · R2\nDIV R1, R2\nR1 ÷ R2\nmod 256\nMOD R1, R2\nR1 % R2\nAND R1, R2\n8 / 16\n8 / 16\n8 / 16\nR1 & R2 (bitwise AND)\nOR R1, R2\n8 / 16\n8 / 16\n8 / 16\nR1 ∥R2 (bitwise OR)\nXOR R1, R2\n8 / 16\n8 / 16\n8 / 16\nR1 ˆ R2 (bitwise XOR)\nTable 1: Arithmetic operations supported by the KS chip. All sizes are in bits.\n1The code name is Amdtel confidential information. Please refrain from leaking to TechCrunch.\n\nProblem Set 5\nThe KS library supports arbitrarily large base-256 numbers. The base was chosen such that each\ndigit is a byte, and two digits make up a 16-bit number. Numbers are stored as a little-endian\nsequence of bytes (the first byte of a number is the least significant digit, for example 65534\n= 0xFFFE would be stored as [0xFE, 0xFF]). For the rest of the problem, assume all the input\nnumbers have N digits.\nConsider the following algorithm for computing A + B, assuming both inputs have N digits.\nADD(A, B, N)\nC = ZERO(N + 1) // ZERO(k) creates a k-digit number, with all digits set to 0s.\ncarry = 0\nfor i = 1 to N\ndigit = WORD(A[i]) + WORD(B[i]) + WORD(carry)\nC[i] = LSB(digit)\ncarry = MSB(digit)\nC[N + 1] = carry\nreturn C\n(a) [1 point] What is the running time of ADD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(b) [1 point] What is the size of ADD's output?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(c) [1 point] ADD's output size suggests an easy lower bound for the subroutine. Does\nthe running time of ADD match this lower bound?\n1. Yes\n\nProblem Set 5\n2. No\nConsider the following brute-force algorithm for computing A · B, assuming both inputs have N\ndigits.\nMULTIPLY(A, B, N)\nC = ZERO(2N)\nfor i = 1 to N\ncarry = 0\nfor j = 1 to N\ndigit = A[i] · B[j] + WORD(C[i + j -1]) + WORD(carry)\nC[i + j -1] = LSB(digit)\ncarry = MSB(digit)\nC[i + N ] = carry\nreturn C\n(d) [1 point] What is the running time of MULTIPLY?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(e) [1 point] What is the size of MULTIPLY's output?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(f) [1 point] MULTIPLY's output size suggests an easy lower bound for the subroutine.\nDoes the running time of MULTIPLY match this lower bound?\n1. Yes\n2. No\n\nProblem Set 5\nConsider the following brute-force algorithm for computing A ÷ B and A mod B, assuming\nboth inputs have N digits. The algorithm uses a procedure COPY(A, N) that creates a copy of an\nN-digit number A, using Θ(N) time.\nDIVMOD(A, B, N)\nQ = ZERO(N) // quotient\nR = COPY(A, N) // remainder\nS0 = COPY(B, N) // Si = B · 2i\ni = 0\nrepeat\ni = i + 1\nSi = ADD(Si-1, Si-1, N)\nuntil Si[N + 1] > 0 or CMP(Si, A, N) == GREATER\nfor j = i -1 downto 0\nQ = ADD(Q, Q, N)\nif CMP(R, Sj, N) != SMALLER\nR = SUBTRACT(R, Sj, N)\nQ[0] = Q[0]∥1 // Faster version of Q = Q + 1\nreturn (Q, R)\n(g) [1 point]\nCMP(A, B, N) returns GREATER if A > B, EQUAL if A = B, and\nSMALLER if A < B, assuming both A and B are N-digit numbers. What is the\nrunning time for an optimal CMP implementation?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(h) [1 point] SUBTRACT(A, B, N) computes A -B, assuming A and B are N-digit\nnumbers. What is the running time for an optimal SUBTRACT implementation?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n\nProblem Set 5\n7. Θ(N log2 6)\n8. Θ(N 3)\n(i) [1 point] What is the running time of DIVMOD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nThe KS library does not use the DIVMOD implementation above. Instead, it uses Newton's method\nto implement DIV(A, B, N) which computes the division quotient A ÷ B, assuming both inputs\nhave N digits. DIV relies on the subroutines defined above. For example, it uses MULTIPLY\nto perform large-number multiplication and ADD for large-number addition. MOD(A, B, N) is\nimplemented using the identity A mod B = A -(A ÷ B) · B.\n(j) [2 points] How many times does DIV call MULTIPLY?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(k) [2 points] What is the running time of MOD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n\nProblem Set 5\nConsider the following brute-force algorithm for computing BE mod M, assuming all the input\nnumbers have N digits.\nPOWMOD(B, E, M, N)\nR = ONE(N) // result\nX = COPY(B, N) // multiplier\nfor i = 1 to N\nmask = 1\nfor bit = 1 to 8\nif E[i] & mask != 0\nR = MOD(MULTIPLY(R, X, N), M, 2N)\nX = MOD(MULTIPLY(X, X, N), M, 2N)\nmask = LSB(mask · 2)\nreturn R\n(l) [2 points] What is the running time for POWMOD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nAssume the KS library swaps out the brute-force MULTIPLY with an implementation of Karat-\nsuba's algorithm.\n(m) [1 point] What will the running time for MULTIPLY be after the optimization?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(n) [2 points] What will the running time for MOD be after the optimization?\n1. Θ(1)\n\nProblem Set 5\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(o) [2 points] What will the running time for POWMOD be after the optimization?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n(p) [20 points] Write pseudo-code for KTHROOT(A, K, N), which computes\n√\n⌊\nK A⌋us-\ning binary search, assuming that A and K are both N-digit numbers. The running\ntime for KTHROOT(A, K, N) should be Θ(N 2+log2 3).\n\nProblem Set 5\nProblem 5-2.\n[18 points] RSA Public-Key Encryption\nThe RSA (Rivest-Shamir-Adelman) public-key cryptosystem is a cornerstone of Internet security.\nIt provides the \"S\" (security) in the HTTPS sessions used for e-commerce and cloud services that\nhandle private information, such as e-mail. RSA secures SSH sessions (used to connect to Athena,\nfor example), and MIT certificates used to log into Stellar. You figure that the KS chip must\nperform RSA efficiently, since RSA plays such an important role in cloud security. This problem\nwill acquaint you with the encryption and decryption algorithms in RSA.\nRSA works as follows. Each user generates two large random primes p and q, and sets his public\nmodulus m = p · q. The user then chooses a small number2 e that is co-prime with (p -1)(q -1),\nand computes d = e-1 mod (p -1)(q -1). The user announces his public key (e, m) to the\nworld, and keeps d private. In order to send an encrypted message to our user, another user would\nencode the message as a number smaller than n, and encrypt it as c = E(n) = ne mod m. Our\nuser would decode the message using D(c) = cd mod m. Assume that keys can be generated\nreasonably fast and that D(E(n)) = n, for all but a negligible fraction of values of n.\n(a) [1 point] What is the running time of an implementation of D(n) that uses the KS li-\nbrary in Problem 1, with the optimized version of MULTIPLY (Karatsuba's algorithm),\nassuming that n, d and m are N-byte numbers?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nYou're thinking of using RSA to encrypt important sensitive images, such as last night's picture of\nyou doing a Keg stand. Formally, a picture has R × C pixels (R rows, C columns), and each pixel\nis represented as 3 bytes that are RGB color space coordinates3. The RSA key is (e, m), where m\nis an N-byte number. An inefficient encryption method would process each row of pixel data as\nfollows:\n1.Break the 3C bytes of pixel data into groups of N -1 bytes\n2.Pad the last group with 0 bytes up to N -1 bytes\n3.Encrypt each group of N -1 bytes to obtain an N-byte output\n4.Concatenate the N-byte outputs\n265,537 is a popular choice nowadays\n3see http://en.wikipedia.org/wiki/RGB_color_space\n*\nAthena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n*\n\nProblem Set 5\n(b) [1 point] How many calls to the RSA encryption function E(n) are necessary to\nencrypt an R × C-pixel image?\n1. Θ(1)\n2. Θ(RC)\n3. Θ(RC)\nN\n4. Θ(RN )\nC\n5. Θ(CN )\nR\n(c) [1 point] What is the running time for decrypting an R × C-pixel image that was en-\ncrypted using the method above, using the KS library in Problem 1, with the optimized\nversion of MULTIPLY (Karatsuba's algorithm)?\n1. Θ(N)\n2. Θ(N 2)\n3. Θ(N 2 log N)\n4. Θ(N log2 3)\n5. Θ(N log2 6)\n6. Θ(RCN)\n7. Θ(RCN 2)\n8. Θ(RCN 2 log N)\n9. Θ(RCN log2 3)\n10. Θ(RCN log2 6)\n11. Θ(RN)\n12. Θ(RN 2)\n13. Θ(RN 2 log N)\n14. Θ(RN log2 3)\n15. Θ(RN log2 6)\n(d) [5 points] A fixed point under RSA is a number n such that E(n) ≡n mod m, so\nRSA does not encrypt the number at all. Which of the following numbers are fixed\npoints under RSA? (True / False)\n1. 0\n2. 1\n3. 2\n4. 3\n5. m -2\n6. m -1\n(e) [5 points] What other weaknesses does the RSA algorithm have? (True / False)\n1. E(-n) ≡-E(n) mod m\n\nProblem Set 5\n2. E(n1) + E(n2) ≡E(n1 + n2) mod m\n3. E(n1) -E(n2) ≡E(n1 -n2) mod m\n4. E(n1) · E(n2) ≡E(n1 · n2) mod m\n5. E(n1)n2 ≡E(nn2\n1 ) mod m\n(f) [5 points] Amdtel plans to use RSA encryption to secretly tell Gopple when its latest\nsmartphone CPU is ready to ship. Amdtel will send one message every day to Gopple,\nusing Gopple's public key (eG, mG). The message will be NO (the number 20079\nwhen using ASCII), until the day the CPU is ready, then the message will change\nto YES (the number 5858675 when using ASCII). You pointed out to your manager\nthat this security scheme is broken, because an attacker could look at the encrypted\nmessages, and know that the CPU is ready when the daily encrypted message changes.\nThis is a problem of deterministic encryption. If E(20079) always takes the same\nvalue, an attacker can distinguish E(20079) from E(5858675). How can the problem\nof deterministic encryption be fixed? (True / False)\n1. Append the same long number (the equivalent of a string such as 'XXXPADDINGXXX')\nto each message, so the messages are bigger.\n2. Append a random number to each message. All random numbers will have the\nsame size, so the receiver can recognize and discard them.\n3. Use a different encryption key to encrypt each message, and use Gopple's public\nexponent and modulus to encrypt the decryption key for each message.\n4. Use an uncommon encoding, such as UTF-7, so that the attacker will not know\nthe contents of the original messages.\n5. Share a \"secret\" key with Gopple, so that the attacker can't use the knowledge on\nGopple's public exponent and modulus.\n\nProblem Set 5\nProblem 5-3.\n[42 points] Image Decryption\nYour manager wants to show off the power of the Knight's Shield chip by decrypting a live video\nstream directly using the RSA public-key crypto-system. RSA is quite resource-intensive, so most\nsystems only use it to encrypt the key of a faster algorithm. Decrypting live video would be an\nimpressive technical feat!\nUnfortunately, the performance of the KS chip on RSA decryption doesn't come even close to\nwhat's needed for streaming video. The hardware engineers said the chip definitely has enough\ncomputing power, and blamed the problem on the RSA implementation. Your new manager has\nheard about your algorithmic chops, and has high hopes that you'll get the project back on track.\nThe software engineers suggested that you benchmark the software using images because, after\nall, video is just a sequence of frames.\nThe code is in the rsa directory in the zip file for this problem set.\n(a) [2 points] Run the code under the python profiler with the command below, and\nidentify the method inside bignum.py that is most suitable for optimization. Look\nat the methods that take up the most CPU time, and choose the first method whose\nrunning time isn't proportional to the size of its output.\npython -m cProfile -s time rsa.py < tests/1verdict 32.in\nWarning: the command above can take 1-10 minutes to complete, and bring the CPU\nusage to 100% on one of your cores. Plan accordingly. If you have installed PyPy\nsuccessfully, you should replace python with pypy in the command above for a\n2-10x speed improvement.\nWhat is the name of the method with the highest CPU usage?\n(b) [1 point] How many times is the method called?\n(c) [1 point] The troublesome method is implementing a familiar arithmetic operation.\nWhat is the tightest asymptotic bound for the worst-case running time of the method\nthat contains the bottleneck? Express your answer in terms of N, the number of digits\nin the input numbers.\n1. Θ(N).\n2. Θ(N log n)\n3. Θ(N log2 n)\n4. Θ(N log2 3)\n5. Θ(N 2)\n6. Θ(N log2 7)\n7. Θ(N 3)\n(d) [1 point] What is the tightest asymptotic bound for the worst-case running time of di-\nvision? Express your answer in terms of N, the number of digits in the input numbers.\n1. Θ(N).\n\nProblem Set 5\n2. Θ(N log n)\n3. Θ(N log2 n)\n4. Θ(N log2 3)\n5. Θ(N 2)\n6. Θ(N log2 7)\n7. Θ(N 3)\ne have implemented a visualizer for your image decryption output, to help you debug your code.\nhe visualizer will also come in handy for answering the question below. To use the visualizer,\nrst produce a trace.\nRACE=jsonp python rsa.py < tests/1verdict 32.in > trace.jsonp\nn Windows, use the following command instead.\nsa jsonp.bat < tests/1verdict 32.in > trace.jsonp\nhen use Google Chrome to open visualizer/bin/visualizer.html\n(e) [6 points] The test cases that we supply highlight the problems of RSA that we dis-\ncussed above. Which of the following is true? (True / False)\n1. Test 1verdict 32 shows that RSA has fixed points.\n2. Test 1verdict 32 shows that RSA is deterministic.\n3. Test 2logo 32 shows that RSA has fixed points.\n4. Test 2logo 32 shows that RSA is deterministic.\n5. Test 5future 1024 shows that RSA has fixed points.\n6. Test 5future 1024 shows that RSA is deterministic.\n(f) [1 point] Read the code in rsa.py. Given a decrypted image of R × C pixels\n(R rows, C columns), where all the pixels are white (all the image data bytes are\n255), how many times will powmod be called during the decryption operation in\ndecrypt image?\n1. Θ(1)\n2. Θ(RC)\n3. Θ(RC)\nN\n4. Θ(RN )\nC\n5. Θ(CN )\nR\n(g) [30 points]\nThe multiplication and division operations in big num.py are im-\nplemented using asymptotically efficient algorithms that we have discussed in class.\nHowever, the sizes of the numbers involved in RSA for typical key sizes aren't suit-\nable for complex algorithms with high constant factors. Add new methods to BigNum\nimplementing multiplication and division using straight-forward algorithms with low\nconstant factors, and modify the main multiplication and division methods to use the\nW\nT\nfi\nT\nO\nr\nT\n\nProblem Set 5\nsimple algorithms if at least one of the inputs has 64 digits (bytes) or less. Please note\nthat you are not allowed to import any additional Python libraries and our test will\ncheck this.\nThe KS software testing team has put together a few tests to help you check your code's cor-\nrectness and speed. big num test.py contains unit tests with small inputs for all BigNum\npublic methods. rsa test.py runs the image decryption code on the test cases in the tests/\ndirectory.\nYou can use the following command to run all the image decryption tests.\npython rsa test.py\nTo work on a single test case, run the simulator on the test case with the following command.\npython rsa.py < tests/1verdict 32.in > out\nThen compare your output with the correct output for the test case.\ndiff out tests/1verdict 32.gold\nFor Windows, use fc to compare files.\nfc out tests/1verdict 32.gold\nWhile debugging your code, you should open a new Terminal window (Command Prompt in\nWindows), and set the KS DEBUG environment variable (export KS DEBUG=true; on Win-\ndows, use set KS DEBUG=true) to use a slower version of our code that has more consistency\nchecks.\nWhen your code passes all tests, and runs reasonably fast (the tests should complete in less than\n90 seconds on any reasonably recent computer using PyPy, or less than 600 seconds when using\nCPython), upload your modified big num.py to the course submission site. Our automated\ngrading code will use our versions of test rsa.py, rsa.py and ks primitives.py /\nks primitives unchecked.py, so please do not modify these files.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 5 Grading Explanation",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/b9b9e66bfa1e2c7c417a8c79deebe73c_MIT6_006F11_ps5e.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nNovember 1, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 5E\nProblem Set 5E\nPlease download the .zip archive for this problem set, and refer to the README.txt file for\ninstructions on preparing your solutions.\nYou will need to submit the grading explanation by Thursday, November 3rd, 11:59PM.\nYour grade for Problem 1(p) in Problem Set 5 will be based on both your solutions and the grading\nexplanation.\nProblem 5E-1.\nPlease write a short explanation of your pseudo-code for Problem 1(p) in Problem\nSet 5. Assume the grader is familiar with the problem and with the staff solution. If your solution\nis very similar to the official solution, please state that, and point out and explain any differences.\nIf your solution is correct, but very different from the official solution, write a brief explanation to\nconvince the grader that your solution is correct. If your solution is partially correct, point out the\nparts that you got right, and explain your mistakes.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\n\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 1 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/15b45f7459ddae99bfe2cb519b6a9f04_MIT6_006F11_ps1_sol.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nSeptember 16, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 1 Solutions\nProblem Set 1 Solutions\nProblem 1-1.\n[15 points] Asymptotic Practice\nFor each group of functions, sort the functions in increasing order of asymptotic (big-O) complex-\nity:\n(a) [5 points] Group 1:\nf1(n)\n=\nn0.999999 log n\nf2(n)\n=\n10000000n\nf3(n)\n=\n1.000001n\nf4(n)\n=\nn2\nSolution: The correct order of these functions is f1(n), f2(n), f4(n), f3(n). To see\nwhy f1(n) grows asymptotically slower than f2(n), recall that for any c > 0, log n is\nO(nc). Therefore we have:\nf (n) = n0.999999\nlog n = O(n .999999 · n0.000001) = O(n) = O(f2(n))\nThe function f2(n) is linear, while the function f4(n) is quadratic, so f2(n) is O(f4(n)).\nFinally, we know that f3(n) is exponential, which grows much faster than quadratic,\nso f4(n) is O(f3(n)).\n(b) [5 points] Group 2:\nf1(n)\n=\nf2(n)\n=\n2100000n\nn\nf3(n)\n=\nf4(n)\n=\n\nn√\n\nn\nSolution: The correct order of these functions is f1(n), f4(n), f3(n), f2(n). The vari-\nable n never appears in the formula for f1(n), so despite the multiple exponentials,\nf1(n) is constant. Hence, it is asymptotically smaller than f4(n), which does grow\nwith n. We may rewrite\n√\n\nthe formula for f4(n) to be f4(n) = n\nn = n1.5. The\nvalue of f3(n) =\nn\nis given by the formula n(n -1)/2, which is Θ(n2). Hence,\nf\n1.5\n4(n) = n\n= O(n ) = O(f3(n)). Finally, f2(n) is exponential, while f3(n) is\nquadratic, meaning that f3(n) is O(f2(n)).\n\nProblem Set 1 Solutions\n(c) [5 points] Group 3:\n√\nf (n)\n=\nn\nn\nf2(n)\n=\n2n\nf3(n)\n=\nn10\nn · 2n/2\nf4(n)\n=\nX\n(i + 1)\ni=1\nSolution: The correct ordering of these functions is f4(n), f1(n), f3(n), f2(n). To see\nwhy, we first use the rules of arithmetic series to derive a simpler formula for f4(n):\nn\nf4(n) =\nX\nn((n + 1) + 2)\nn(n + 3)\n(i + 1) =\n=\n= Θ(n2)\ni=1\n√\nThis is clearly asymptotically smaller than f (n) = n\nn\n. Next, we want to compare\nf1(n), f2(n), and f3(n). To do so, we transform both f1(n) and f3(n) so that they\nlook more like f3(n):\n√\nf1(n)\n=\nn\nn = (2lg n √\n)\nn\n√\n= 2\nn·lg n\nf3(n)\n=\nn10 · 2n/2\n= 2lg(n\n) · 2n/2 = 2n/2+10 lg n\nThe exponent of the 2 in f1(n) is a function that grows more slowly than linear time;\nthe exponent of the 2 in f3(n) is a function that grows linearly with n. Therefore,\nf1(n) = O(f3(n)). Finally, we wish to compare f3(n) with f2(n). Both have a\nlinear function of n in their exponent, so it's tempting to say that they behave the\nsame asymptotically, but they do not. If c is any constant and g(x) is a function, then\n2cg(x) = (2c)g(x). Hence, changing the constant of the function in the exponent is the\nsame as changing the base of the exponent, which does affect the asymptotic running\ntime. Hence, f3(n) is O(f2(n)), but f2(n) is not O(f3(n)).\nProblem 1-2.\n[15 points] Recurrence Relation Resolution\nFor each of the following recurrence relations, pick the correct asymptotic runtime:\n(a) [5 points] Select the correct asymptotic complexity of an algorithm with runtime\nT(n, n) where\nT(x, c)\n=\nΘ(x)\nfor c ≤2,\nT(c, y)\n=\nΘ(y)\nfor c ≤2, and\nT(x, y)\n=\nΘ(x + y) + T(x/2, y/2).\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n\nProblem Set 1 Solutions\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\nSolution: The correct answer is Θ(n). To see why, we rewrite the recurrence relation\nto avoid Θ notation as follows:\nT(x, y) = c(x + y) + T(x/2, y/2).\nWe may then begin to replace T(x/2, y/2) with the recursive formula containing it:\nx + y\nx + y\nx + y\nT(x, y) = c (x + y) + c\n\n+ c\n\n+ c\n\n+ . . .\nThis geometric sequence is bounded from above by 2c(x + y), and is obviously\nbounded from below by c(x + y). Therefore, T(x, y) is Θ(x + y), and so T(n, n)\nis Θ(n).\n(b) [5 points] Select the correct asymptotic complexity of an algorithm with runtime\nT(n, n) where\nT(x, c)\n=\nΘ(x)\nfor c ≤2,\nT(c, y)\n=\nΘ(y)\nfor c ≤2, and\nT(x, y)\n=\nΘ(x) + T(x, y/2).\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\nSolution: The correct answer is Θ(n log n). To see why, we rewrite the recurrence\nrelation to avoid Θ notation as follows:\nT(x, y) = cx + T(x, y/2).\nWe may then begin to replace T(x, y/2) with the recursive formula containing it:\nT(x, y) = cx\n| + cx + cx + . . . + cx .\nΘ(log y) times\nAs a result, T(x, y) is Θ(x log y). When we\n{z\nsubstitute n\n}\nfor x and y, we get that\nT(n, n) is Θ(n log n).\n\nProblem Set 1 Solutions\n(c) [5 points] Select the correct asymptotic complexity of an algorithm with runtime\nT(n, n) where\nT(x, c)\n=\nΘ(x)\nfor c ≤2,\nT(x, y)\n=\nΘ(x) + S(x, y/2),\nS(c, y)\n=\nΘ(y)\nfor c ≤2, and\nS(x, y)\n=\nΘ(y) + T(x/2, y).\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\nSolution: The correct answer here is Θ(n). To see why, we want to first eliminate the\nmutually recursive recurrence relations. To do so, we will replace all references to the\nfunction S(x, y) with the definition of S(x, y). This yields the following recurrence\nrelation for T(x, y):\nT(x, y) = Θ(x) + Θ(y/2) + T(x/2, y/2).\nWe can rewrite this to eliminate the constants and get the recurrence T(x, y) = Θ(x+\ny) + T(x/2, y/2). This is precisely the same recurrence relation as seen in part (a) of\nthis problem, so it must have the same complexity.\nPeak-Finding\nIn Lecture 1, you saw the peak-finding problem. As a reminder, a peak in a matrix is a location\nwith the property that its four neighbors (north, south, east, and west) have value less than or equal\nto the value of the peak. We have posted Python code for solving this problem to the website in\na file called ps1.zip. In the file algorithms.py, there are four different algorithms which\nhave been written to solve the peak-finding problem, only some of which are correct. Your goal is\nto figure out which of these algorithms are correct and which are efficient.\nProblem 1-3.\n[16 points] Peak-Finding Correctness\n(a) [4 points] Is algorithm1 correct?\n1. Yes.\n2. No.\nSolution: Yes. This is the Θ(n log n) algorithm whose proof was sketched in Lecture\n1. A more rigorous version of the proof of correctness was included in this homework.\n\nProblem Set 1 Solutions\n(b) [4 points] Is algorithm2 correct?\n1. Yes.\n2. No.\nSolution: Yes. This is the same as the greedy ascent algorithm presented in Lecture 1.\nThe algorithm will always eventually return a location, because the value of location\nthat it stores strictly increases with each recursive call, and there are only a finite\nnumber of values in the grid. Hence, it will eventually return a value, which is always\na peak.\n(c) [4 points] Is algorithm3 correct?\n1. Yes.\n2. No.\nSolution: No. To see that this is true, try running the algorithm on the counterexample\ngiven in the solutions to Problem 1-6.\n(d) [4 points] Is algorithm4 correct?\n1. Yes.\n2. No.\nSolution: Yes. See Problem 1-5 for a proof of correctness.\nProblem 1-4.\n[16 points] Peak-Finding Efficiency\n(a) [4 points] What is the worst-case runtime of algorithm1 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\nSolution: The worst-case runtime of algorithm1 is Θ(n log n), as explained in\nLecture 1.\n(b) [4 points] What is the worst-case runtime of algorithm2 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n\nProblem Set 1 Solutions\n6. Θ(2n).\nSolution: The worst-case runtime of algorithm2 is Θ(n2), as explained in Lecture\n1.\n(c) [4 points] What is the worst-case runtime of algorithm3 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\nSolution: The worst-case runtime of algorithm3 is Θ(n). To see why, note that a\nsingle call of the function (not counting the cost of the recursive call) does work pro-\nportional m + n, where m is the number of rows and n is the number of columns. The\nrecursive subproblem examined involves roughly half the number of rows and half the\nnumber of columns. Hence, the recurrence relation for this algorithm is approximately\nT(m, n) = Θ(m + n) + T(m/2, n/2). This is precisely the recurrence relation we\nsolved in Problem 1-2(a).\n(d) [4 points] What is the worst-case runtime of algorithm4 on a problem of size\nn × n?\n1. Θ(log n).\n2. Θ(n).\n3. Θ(n log n).\n4. Θ(n log2 n).\n5. Θ(n2).\n6. Θ(2n).\nSolution: The total runtime of the algorithm in the worst case is Θ(n). The algorithm\nalternates between splitting\nProblem 1-5.\n[19 points] Peak-Finding Proof\nPlease modify the proof below to construct a proof of correctness for the most efficient correct\nalgorithm among algorithm2, algorithm3, and algorithm4.\nThe following is the proof of correctness for algorithm1, which was sketched in Lecture 1.\nWe wish to show that algorithm1 will always return a peak, as long as the problem\nis not empty. To that end, we wish to prove the following two statements:\n1. If the peak problem is not empty, then algorithm1 will always return a lo-\ncation. Say that we start with a problem of size m × n. The recursive subproblem\n\nProblem Set 1 Solutions\nexamined by algorithm1 will have dimensions m × ⌊n/2⌋or m × (n -⌊n/2⌋-1).\nTherefore, the number of columns in the problem strictly decreases with each recursive\ncall as long as n > 0. So algorithm1 either returns a location at some point, or even-\ntually examines a subproblem with a non-positive number of columns. The only way for\nthe number of columns to become strictly negative, according to the formulas that de-\ntermine the size of the subproblem, is to have n = 0 at some point. So if algorithm1\ndoesn't return a location, it must eventually examine an empty subproblem.\nWe wish to show that there is no way that this can occur. Assume, to the contrary, that\nalgorithm1 does examine an empty subproblem. Just prior to this, it must examine\na subproblem of size m × 1 or m × 2. If the problem is of size m × 1, then calculating\nthe maximum of the central column is equivalent to calculating the maximum of the\nentire problem. Hence, the maximum that the algorithm finds must be a peak, and it\nwill halt and return the location. If the problem has dimensions m × 2, then there are\ntwo possibilities: either the maximum of the central column is a peak (in which case\nthe algorithm will halt and return the location), or it has a strictly better neighbor in the\nother column (in which case the algorithm will recurse on the non-empty subproblem\nwith dimensions m × 1, thus reducing to the previous case). So algorithm1 can\nnever recurse into an empty subproblem, and therefore algorithm1 must eventually\nreturn a location.\n2. If algorithm1 returns a location, it will be a peak in the original problem. If\nalgorithm1 returns a location (r1, c1), then that location must have the best value\nin column c1, and must have been a peak within some recursive subproblem. Assume,\nfor the sake of contradiction, that (r1, c1) is not also a peak within the original problem.\nThen as the location (r1, c1) is passed up the chain of recursive calls, it must eventually\nreach a level where it stops being a peak. At that level, the location (r1, c1) must be\nadjacent to the dividing column c2 (where |c1 -c2| = 1), and the values must satisfy the\ninequality val(r1, c1) < val(r1, c2).\nLet (r2, c2) be the location of the maximum value found by algorithm1 in the divid-\ning column. As a result, it must be that val(r1, c2) ≤val(r2, c2). Because the algorithm\nchose to recurse on the half containing (r1, c1), we know that val(r2, c2) < val(r2, c1).\nHence, we have the following chain of inequalities:\nval(r1, c1) < val(r1, c2) ≤val(r2, c2) < val(r2, c1)\nBut in order for algorithm1 to return (r1, c1) as a peak, the value at (r1, c1) must\nhave been the greatest in its column, making val(r1, c1) ≥val(r2, c1). Hence, we have\na contradiction.\nSolution: To prove that algorithm4 is correct, we make the following modifications to the\nproof of correctness for algorithm1:\n1. There is more variation in the sizes of the recursive subproblems, because we can split by\nrows as well as by columns.\n\nProblem Set 1 Solutions\n2. Because we can split by rows or columns, it is no longer true that the number of columns\nis always strictly decreasing. With every step, either the number of rows or the number of\ncolumns strictly decreases, as long as both are greater than zero. However, this does still\nmean that the algorithm must either return a location, or examine an empty subproblem.\n3. It is no longer true that the size of the problem just prior to examining an empty subproblem\nis m × 1 or m × 2. If the algorithm splits on rows instead of columns just prior to examining\nan empty subproblem, then the size of the problem must be 1 × n or 2 × n. Even so, the\nanalyses of the two cases (splitting on rows versus splitting on columns) are nearly identical.\n4. The second part of the proof diverges more from the proof given for algorithm1. We no\nlonger know that the value returned by the algorithm is the maximum in some row or column\nof the original problem. Instead, we base our argument about the correctness of the algorithm\non the use of the bestSeen variable, which contains the location of the best value seen so\nfar in the matrix. This lets us know that we will never choose to return a location that looks\nlike a peak within the current subproblem, but is adjacent to some greater value just outside\nthe subproblem.\nThe result of these changes, written more rigorously, is the following proof:\nWe wish to show that the algorithm will always return a peak. To that end, we wish to\nprove the following two statements:\n1. If the peak problem is not empty, then the algorithm will always return a lo-\ncation. Say that we start with a problem of size m × n. Depending on whether the\nalgorithm is splitting the rows or the columns, the recursive subproblem examined by\nthe algorithm will have dimensions ⌊m/2⌋× n, (m -⌊m/2⌋-1) × n, m × ⌊n/2⌋, or\nm × (n -⌊n/2⌋-1). Therefore, with each recursive call, either the number of rows or\nthe number of columns strictly decreases, as long as both are greater than zero. So the\nalgorithm either halts and returns at some point, or eventually examines a subproblem\nwith a non-positive number of rows or columns. The only way for the number of rows\nor columns to become strictly negative, according to the formulas that determine the\nsize of the subproblem, is to have m = 0 or n = 0 at some point. So if the algorithm\ndoes not returns a location, it must eventually examine an empty subproblem.\nWe wish to show that there is no way that this can occur. Assume, to the contrary, that\nthe algorithm does examine an empty subproblem. Without loss of generality, say that\nthe algorithm split the columns just prior to this. Then at that point in the algorithm it\nmust have examined a subproblem of size m × 1 or m × 2. If the problem is of size\nm × 1, then calculating the maximum of the central column is equivalent to calculating\nthe maximum of the entire problem. Hence, the maximum that the algorithm finds must\nbe a peak, and it will halt and return the location. If the problem has dimensions m × 2,\nthen there are two possibilities: either the maximum of the central column is a peak (in\nwhich case the algorithm will return the location), or it has a strictly better neighbor\nin the other column (in which case the algorithm will recurse on the subproblem with\n\nProblem Set 1 Solutions\ndimensions m×1, thereby ensuring that the algorithm will always recurse into the non-\nempty subproblem). So the algorithm can never recurse into an empty subproblem, and\ntherefore the algorithm must return a location.\n2. If the algorithm returns a location, it will be a peak in the original problem. If\nthe algorithm returns a location (r1, c1), then that location must have been a peak within\nsome recursive subproblem. In addition, if (r2, c2) is the location of the best location\nseen during the execution of the algorithm (that is, the location stored in the variable\nbestSeen), it must be that val(r1, c1) ≥val(r2, c2).\nAssume, for the sake of contradiction, that (r1, c1) is not a peak within the original\nproblem. Then as the location (r1, c1) is passed up the chain of recursive calls, it must\neventually reach a level where it stops being a peak. Hence, it must be that the sub-\nproblem considered at that level includes some neighbor (r3, c3) of (r1, c1) with value\nval(r1, c1) < val(r3, c3). In order for (r3, c3) to be adjacent to the recursive subproblem,\nbut not included, it has to have been in the dividing row or dividing column. Therefore,\n(r3, c3) must have been examined during the progression of the algorithm. As a re-\nsult, it must be that val(r3, c3) ≤val(r2, c2). Hence, we have the following chain of\ninequalities:\nval(r1, c1) < val(r3, c3) ≤val(r2, c2) ≤val(r1, c1).\nThis results in a contradiction.\nProblem 1-6.\n[19 points] Peak-Finding Counterexamples\nFor each incorrect algorithm, upload a Python file giving a counterexample (i.e. a matrix for which\nthe algorithm returns a location that is not a peak).\nSolution: The following is a counterexample for algorithm3:\nproblemMatrix = [\n[ 0,\n0,\n9,\n8,\n0,\n0,\n0],\n[ 0,\n0,\n0,\n0,\n0,\n0,\n0],\n[ 0,\n1,\n0,\n0,\n0,\n0,\n0],\n[ 0,\n2,\n0,\n0,\n0,\n0,\n0],\n[ 0,\n0,\n0,\n0,\n0,\n0,\n0],\n[ 0,\n0,\n0,\n0,\n0,\n0,\n0],\n[ 0,\n0,\n0,\n0,\n0,\n0,\n0]\n]\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/9068814f8e3b4cd9d515bc7de4408c61_MIT6_006F11_ps2_sol.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nSeptember 15, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 2\nProblem Set 2\nBoth theory and programming questions are due Tuesday, September 27 at 11:59PM.\nPlease download the .zip archive for this problem set, and refer to the README.txt file for\ninstructions on preparing your solutions.\nRemember, your goal is to communicate. Full credit will be given only to a correct solution\nwhich is described clearly. Convoluted and obtuse descriptions might receive low marks, even\nwhen they are correct. Also, aim for concise solutions, as it will save you time spent on write-ups,\nand also help you conceptualize the key idea of the problem.\nWe will provide the solutions to the problem set 10 hours after the problem set is due, which\nyou will use to find any errors in the proof that you submitted. You will need to submit a critique of\nyour solutions by Thursday, September 29th, 11:59PM. Your grade will be based on both your\nsolutions and your critique of the solutions.\nProblem 2-1.\n[40 points] Fractal Rendering\nYou landed a consulting gig with Gopple, who is about to introduce a new line of mobile phones\nwith Retina HD displays, which are based on unicorn e-ink and thus have infinite resolution. The\nhigh-level executives heard that fractals have infinite levels of detail, and decreed that the new\nphones' background will be the Koch snowflake (Figure 1).\nFigure 1: The Koch snowflake fractal, rendered at Level of Detail (LoD) 0 through 5.\nUnfortunately, the phone's processor (CPU) and the graphics chip (GPU) powering the display do\nnot have infinite processing power, so the Koch fractal cannot be rendered in infinite detail. Gopple\nengineers will stop the recursion at a fixed depth n in order to cap the processing requirement. For\nexample, at n = 0, the fractal is just a triangle. Because higher depths result in more detailed\ndrawing, this depth is usually called the Level of Detail (LoD).\nThe Koch snowflake at LoD n can be drawn using an algorithm following the sketch below:\n\nProblem Set 2\nSNOWFLAKE(n)\ne1, e2, e3 = edges of an equilateral triangle with side length 1\nSNOWFLAKE-EDGE(e1, n)\nSNOWFLAKE-EDGE(e2, n)\nSNOWFLAKE-EDGE(e3, n)\nSNOWFLAKE-EDGE(edge, n)\nif n == 0\nedge is an edge on the snowflake\nelse\ne1, e2, e3 = split edge in 3 equal parts\nSNOWFLAKE-EDGE(e1, n -1)\nf2, g2 = edges of an equilateral triangle whose 3rd edge is e2, pointing outside the snowflake\n∆(f2, g2, e2) is a triangle on the snowflake's surface\nSNOWFLAKE-EDGE(f2, n -1)\nSNOWFLAKE-EDGE(g2, n -1)\nSNOWFLAKE-EDGE(e3, n -1)\nThe sketch above should be sufficient for solving this problem. If you are curious about the missing\ndetails, you may download and unpack the problem set's .zip archive, and read the CoffeeScript\nimplementation in fractal/src/fractal.coffee.\nIn this problem, you will explore the computational requirements of four different methods for\nrendering the fractal, as a function of the LoD n. For the purpose of the analysis, consider the\nrecursive calls to SNOWFLAKE-EDGE; do not count the main call to SNOWFLAKE as part of the\nrecursion tree. (You can think of it as a super-root node at a special level -1, but it behaves differ-\nently from all other levels, so we do not include it in the tree.) Thus, the recursion tree is actually\na forest of trees, though we still refer to the entire forest as the \"recursion tree\". The root calls to\nSNOWFLAKE-EDGE are all at level 0.\nGopple's engineers have prepared a prototype of the Koch fractal drawing software, which you can\nuse to gain a better understanding of the problem. To use the prototype, download and unpack the\nproblem set's .zip archive, and use Google Chrome to open fractal/bin/fractal.html.\nFirst, in 3D hardware-accelerated rendering (e.g., iPhone), surfaces are broken down into triangles\n(Figure 2). The CPU compiles a list of coordinates for the triangles' vertices, and the GPU is\nresponsible for producing the final image. So, from the CPU's perspective, rendering a triangle\ncosts the same, no matter what its surface area is, and the time for rendering the snowflake fractal\nis proportional to the number of triangles in its decomposition.\n(a) [1 point] What is the height of the recursion tree for rendering a snowflake of LoD n?\n1. log n\n2. n\n\nProblem Set 2\nFigure 2: Koch snowflake drawn with triangles.\n3. 3 n\n4. 4 n\nSolution: At level 0, the argument to SNOWFLAKE-EDGE is n. At each level in the\nrecursion tree, the argument decreases by 1. At level n, the argument to SNOWFLAKE-\nEDGE becomes 0, which triggers the termination condition at the beginning of the\nfunction. See the figure below.\nSNOWFLAKE(n)\nSNOWFLAKE-EDGE(n)\nn -1\nn -1\n...\nn -1\nn -1\nSNOWFLAKE-EDGE(n)\n· · ·\nSNOWFLAKE-EDGE(n)\nn -1\nn -1\nn -1\nlevel N\n...\nlevel 1\nlevel 0\nlevel -1\n...\nn -1\n(b) [2 points] How many nodes are there in the recursion tree at level i, for 0 ≤i ≤n?\n1. 3i\n2. 4i\n3. 4i+1\n4. 3 · 4i\nSolution:\nSNOWFLAKE calls SNOWFLAKE-EDGE once for each side of the initial\ntriangle, so there are 3 nodes at level 0. At levels 0 ≤i < n, SNOWFLAKE-EDGE\nmakes 4 calls to itself, so each node at those levels has 4 children. This works out to\n3 · 4i nodes at level i.\n\nProblem Set 2\n(c) [1 point] What is the asymptotic rendering time (triangle count) for a node in the\nrecursion tree at level i, for 0 ≤i < n?\n1. 0\n2. Θ(1)\n3. Θ(1 i)\n4.\n1 i\nΘ(\n)\nSolution: Levels 0 through n -1 draw one triangle (spike) for each side that is split\ninto 4 line segments. So the cost is always Θ(1) / node.\n(d) [1 point] What is the asymptotic rendering time (triangle count) at each level i of the\nrecursion tree, for 0 ≤i < n?\n1. 0\n2. Θ(4 i)\n3. Θ(3i)\n4. Θ(4i)\nSolution: Θ(4i), obtained by multiplying the previous two answers and reducing the\nresult to the simplest form.\n(e) [2 points] What is the total asymptotic cost for the CPU, when rendering a snowflake\nwith LoD n using 3D hardware-accelerated rendering?\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\nSolution: At level n (SNOWFLAKE-EDGE has argument 0), the termination condition\nis triggered, and no triangle is drawn. Summing up over all the other levels of the\nrecursion tree, we obtain\nn-1\nT(n) =\nX\nΘ(4i) = Θ(4n)\ni=0\nThe recursion for one side of the snowflake can be written as\n,\nT n) =\nΘ(1)\nif n = 0,\n(\n4T(n -1) + Θ(1),\nif n ≥1.\nSecond, when using 2D hardware-accelerated rendering, the surfaces' outlines are broken down\ninto open or closed paths (list of connected line segments). For example, our snowflake is one\nclosed path composed of straight lines. The CPU compiles the list of cooordinates in each path to\nbe drawn, and sends it to the GPU, which renders the final image. This approach is also used for\ntalking to high-end toys such as laser cutters and plotters.\n\nProblem Set 2\n(f) [1 point] What is the height of the recursion tree for rendering a snowflake of LoD n\nusing 2D hardware-accelerated rendering?\n1. log n\n2. n\n3. 3 n\n4. 4 n\nSolution: n, because the recursion tree is the same as in the previous part.\n(g) [1 point] How many nodes are there in the recursion tree at level i, for 0 ≤i ≤n?\n1. 3i\n2. 4i\n3. 4i+1\n4. 3 · 4i\nSolution: 3 · 4i, because the recursion tree is the same as in the previous part.\n(h) [1 point] What is the asymptotic rendering time (line segment count) for a node in the\nrecursion tree at level i, for 0 ≤i < n?\n1. 0\n2. Θ(1)\n3. Θ(1 i)\n4. Θ(1 i)\nSolution: Line segments are only rendered at the last level, so the cost is 0 for levels\n0 ≤i < n.\n(i) [1 point] What is the asymptotic rendering time (line segment count) for a node in the\nlast level n of the recursion tree?\n1. 0\n2. Θ(1)\n3.\nn\nΘ(1 )\n4. Θ(1 n)\nSolution:\nAt the last level, each side is turned into one straight line, so the cost is\nΘ(1) / node.\n(j) [1 point] What is the asymptotic rendering time (line segment count) at each level i\nof the recursion tree, for 0 ≤i < n?\n1. 0\n2. Θ(4 i)\n3. Θ(3i)\n\nProblem Set 2\n4. Θ(4i)\nSolution: 0, because all the line segments are rendered at the last level.\n(k) [1 point] What is the asymptotic rendering time (line segment count) at the last level\nn in the recursion tree?\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\nSolution:\nWe multiply two previous answers and reduce the result to the simplest\nform:\n3 · 4n · Θ(1) = Θ(4n).\n(l) [1 point] What is the total asymptotic cost for the CPU, when rendering a snowflake\nwith LoD n using 2D hardware-accelerated rendering?\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\nSolution: The sum of the previous two answers: T(n) = Θ(4n).\nThird, in 2D rendering without a hardware accelerator (also called software rendering), the CPU\ncompiles a list of line segments for each path like in the previous part, but then it is also responsible\nfor \"rasterizing\" each line segment. Rasterizing takes the coordinates of the segment's endpoints\nand computes the coordinates of all the pixels that lie on the line segment. Changing the colors of\nthese pixels effectively draws the line segment on the display. We know an algorithm to rasterize a\nline segment in time proportional to the length of the segment. It is easy to see that this algorithm\nis optimal, because the number of pixels on the segment is proportional to the segment's length.\nThroughout this problem, assume that all line segments have length at least one pixel, so that the\ncost of rasterizing is greater than the cost of compiling the line segments.\nIt might be interesting to note that the cost of 2D software rendering is proportional to the total\nlength of the path, which is also the power required to cut the path with a laser cutter, or the amount\nof ink needed to print the path on paper.\n(m) [1 point] What is the height of the recursion tree for rendering a snowflake of LoD n?\n1. log n\n2. n\n3. 3 n\n4. 4 n\n\nProblem Set 2\nSolution: n, because the recursion tree is the same as in the previous part.\n(n) [1 point] How many nodes are there in the recursion tree at level i, for 0 ≤i ≤n?\n1. 3i\n2. 4i\n3. 4i+1\n4. 3 · 4i\nSolution: 3 · 4i, because the recursion tree is the same as in the previous part.\n(o) [1 point] What is the asymptotic rendering time (line segment length) for a node in\nthe recursion tree at level i, for 0 ≤i < n? Assume that the sides of the initial triangle\nhave length 1.\n1. 0\n2. Θ(1)\n3. Θ(1 i)\n4.\n1 i\nΘ(\n)\nSolution: Line segments are only rendered at the last level, so the cost is 0 for levels\n0 ≤i < n\n(p) [1 point] What is the asymptotic rendering time (line segment length) for a node in\nthe last level n of the recursion tree?\n1. 0\n2. Θ(1)\n3. Θ(1 n)\n4.\n1 n\nΘ(\n)\nSolution: At level 0, each side has length 1. Levels 0 through n -1 split a length-l\nside into 4 length- l\n3 segments. So, at each level 0 ≤i ≤n, the length of a side is 1 i\n3 .\nSpecifically, at level n, each segment has length 1 n\nn\n= Θ(1 )\n.\n(q) [1 point] What is the asymptotic rendering time (line segment length) at each level i\nof the recursion tree, for 0 ≤i < n?\n1. 0\n2. Θ(4 i)\n3. Θ(3i)\n4. Θ(4i)\nSolution: 0, because all the line segments are rendered at the last level.\n(r) [1 point] What is the asymptotic rendering time (line segment length) at the last level\nn in the recursion tree?\n\nProblem Set 2\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\nSolution:\nWe multiply two previous answers and reduce the result to the simplest\nform.\n3 · 4n\n1n\n4n\n· Θ(\n) = Θ(\n)\n(s) [1 point] What is the total asymptotic cost for the CPU, when rendering a snowflake\nwith LoD n using 2D software (not hardware-accelerated) rendering?\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\nSolution: The sum of the previous two answers. T(n) = Θ(4 n)\nThe fourth and last case we consider is 3D rendering without hardware acceleration. In this case,\nthe CPU compiles a list of triangles, and then rasterizes each triangle. We know an algorithm to\nrasterize a triangle that runs in time proportional to the triangle's surface area. This algorithm is\noptimal, because the number of pixels inside a triangle is proportional to the triangle's area. For\nthe purpose of this problem, you can assume that the area of a triangle with side length l is Θ(l2).\nWe also assume that the cost of rasterizing is greater than the cost of compiling the line segments.\n(t) [4 points] What is the total asymptotic cost of rendering a snowflake with LoD n?\nAssume that initial triangle's side length is 1.\n1. Θ(1)\n2. Θ(n)\n3. Θ(4 n)\n4. Θ(4n)\nSolution:\nΘ(1). See the proof below. Also, intuitively, the snowflake does not\noverflow the rectangle in the visualizer (or the phone's screen), so its area must be\nbounded by a constant. The triangles are adjacent and do not overlap, so the sum of\ntheir areas equals the snowflake's area.\n(u) [15 points] Write a succinct proof for your answer using the recursion-tree method.\nSolution:\nThe proof follows the structure suggested by the previous parts of the\nproblem. In the first part (3D hardware rendering), we argued that there are n levels\nin the recursion tree, and for 0 ≤i ≤n, level i has 3 · 4i nodes. Each node at level\n\nProblem Set 2\ni (0 ≤i < n) renders exactly one triangle, and there is no rendering work at level n.\nLevel -1 also renders a triangle (the big triangle that the snowflake is built off of),\nand we account for that at the end of the proof.\nUsing the similar reasoning as for 2D software rendering, the length of a triangle's\nside at level i is (1)i+1\n, for 0 ≤i < n, so the rendering time in each node is (1)i+1\n(the area of a triangle).\nThe total rendering time over all nodes at level i is (3 · 4i) · (1\ni\n)i+1 = 3\n)\n· ( 4\n9i+1 .\nSumming up over all levels of the recursion tree, we obtain\nn-1\ni\nT(n) =\nX\ni=0\n· 9 ·\n\n= Θ(1).\nNote that the base of the geometric series is less than 1, so the sum converges to a\nconstant. There is a triangle with side length 1 rendered at level -1 which takes Θ(1),\nso the total time is still Θ(1).\nProblem 2-2.\n[60 points] Digital Circuit Simulation\nYour 6.006 skills landed you a nice internship at the chip manufacturer AMDtel. Their hardware\nverification team has been complaining that their circuit simulator is slow, and your manager de-\ncided that your algorithmic chops make you the perfect candidate for optimizing the simulator.\nA combinational circuit is made up of gates, which are devices that take Boolean (True / 1 and\nFalse / 0) input signals, and output a signal that is a function of the input signals. Gates take some\ntime to compute their functions, so a gate's output at time τ reflects the gate's inputs at time τ -δ,\nwhere δ is the gate's delay. For the purposes of this simulator, a gate's output transitions between\n0 and 1 instantly. Gates' output terminals are connected to other gates' inputs terminals by wires\nthat propagate the signal instantly without altering it.\nFor example, a 2-input XOR gate with inputs A and B (Figure 3) with a 2 nanosecond (ns) delay\nworks as follows:\nTime (ns)\nInput A\nInput B\nOutput O\nExplanation\nReflects inputs at time -2\nReflects inputs at time -1\n0 XOR 0, given at time 0\n0 XOR 1, given at time 1\n1 XOR 0, given at time 2\n1 XOR 1, given at time 3\nThe circuit simulator takes an input file that describes a circuit layout, including gates' delays,\nprobes (indicating the gates that we want to monitor the output), and external inputs. It then\nsimulates the transitions at the output terminals of all the gates as time progresses. It also outputs\ntransitions at the probed gates in the order of the timing of those transitions.\n\nProblem Set 2\nA\nB\nO\nFigure 3: 2-input XOR gate; A and B supply the inputs, and O receives the output.\nThis problem will walk you through the best known approach for fixing performance issues in a\nsystem. You will profile the code, find the performance bottleneck, understand the reason behind\nit, and remove the bottleneck by optimizing the code.\nTo start working with AMDtel's circuit simulation source code, download and unpack the problem\nset's .zip archive, and go to the circuit/ directory.\nThe circuit simulator is in circuit.py. The AMDtel engineers pointed out that the simulation\ninput in tests/5devadas13.in takes too long to run. We have also provided an automated\ntest suite at test-circuit.py, together with other simulation inputs. You can ignore these\nfiles until you get to the last part of the problem set.\n(a) [8 points] Run the code under the python profiler with the command below, and\nidentify the method that takes up most of the CPU time. If two methods have similar\nCPU usage times, ignore the simpler one.\npython -m cProfile -s time circuit.py < tests/5devadas13.in\nWarning: the command above can take 15-30 minutes to complete, and bring the CPU\nusage to 100% on one of your cores. Plan accordingly.\nWhat is the name of the method with the highest CPU usage?\nSolution: The first line in the profiler output identifies\nfind min as the method\nwith the largest CPU usage.\n(b) [6 points] How many times is the method called?\nSolution:\nThe first line in the profiler output indicates that\nfind min is called\n259964 times.\n(c) [8 points] The class containing the troublesome method is implementing a familiar\ndata structure. What is the tightest asymptotic bound for the worst-case running time\nof the method that contains the bottleneck? Express your answer in terms of n, the\nnumber of elements in the data structure.\n1. O(1).\n2. O(log n).\n3. O(n).\n4. O(n log n).\n5. O(n log2 n).\n6. O(n2).\n\nProblem Set 2\nSolution:\nfind min belongs to the PriorityQueue class, which contains an\narray-based priority queue implementation. Finding the minimum element in an array\ntakes Θ(n) time.\n(d) [8 points] If the data structure were implemented using the most efficient method\nwe learned in class, what would be the tightest asymptotic bound for the worst-case\nrunning time of the method discussed in the questions above?\n1. O(1).\n2. O(log n).\n3. O(n).\n4. O(n log n).\n5. O(n log2 n).\n6. O(n2).\nSolution:\nA priority queue implementation based on a binary min-heap takes Θ(1)\ntime to find the minimum element, since it's at the top of the heap.\n(e) [30 points] Rewrite the data structure class using the most efficient method we learned\nin class. Please note that you are not allowed to import any additional Python\nlibraries and our test will check this.\nWe have provided a few tests to help you check your code's correctness and speed. The\ntest cases are in the tests/ directory. tests/README.txt explains the syntax\nof the simulator input files. You can use the following command to run all the tests.\npython circuit test.py\nTo work on a single test case, run the simulator on the test case with the following\ncommand.\npython circuit.py < tests/1gate.in > out\nThen compare your output with the correct output for the test case.\ndiff out tests/1gate.gold\nFor Windows, use fc to compare files.\nfc out tests/1gate.gold\nWe have implemented a visualizer for your output, to help you debug your code. To\nuse the visualizer, first produce a simulation trace.\nTRACE=jsonp python circuit.py < tests/1gate.in > circuit.jsonp\nOn Windows, use the following command instead.\ncircuit jsonp.bat < tests/1gate.in > circuit.jsonp\nThen use Google Chrome to open visualizer/bin/visualizer.html\nWe recommend using the small test cases numbered 1 through 4 to check your imple-\nmentation's correctness, and then use test case 5 to check the code's speed.\n\nProblem Set 2\nWhen your code passes all tests, and runs reasonably fast (the tests should complete\nin less than 30 seconds on any reasonably recent computer), upload your modified\ncircuit.py to the course submission site.\nSolution:\nThe solution archive on the course Web site contains the staff's solution\nand secret test cases.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/0c6a7b57bb0732a5752198a6e68fa4c6_MIT6_006F11_ps3_sol.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nSeptember 29, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 3\nProblem Set 3\nBoth theory and programming questions are due Thursday, October 6 at 11:59PM. Please\ndownload the .zip archive for this problem set, and refer to the README.txt file for instructions\non preparing your solutions.\nWe will provide the solutions to the problem set 10 hours after the problem set is due, which\nyou will use to find any errors in the proof that you submitted. You will need to submit a critique of\nyour solutions by Friday, October 7th, 11:59PM. Your grade will be based on both your solutions\nand your critique of the solutions.\nProblem 3-1.\n[45 points] Range Queries\nMicroware is preparing to launch a new database product, NoSQL Server, aimed at the real-time\nanalytics market. Web application analytics record information (e.g., the times when users visit\nthe site, or how much does it take the server to produce a HTTP response), and can display the\ninformation using a Pretty GraphTM1, so that CTOs can claim that they're using data to back their\ndecisions.\nNoSQL Server databases will support a special kind of index, called a range index, to speed up the\noperations needed to build a Pretty GraphTM out of data. Microware has interviewed you during\nthe fall Career Fair, and immediately hired you as a consultant and asked you to help the NoSQL\nServer team design the range index.\nThe range index must support fast (sub-linear) insertions, to keep up with Web application traffic.\nThe first step in the Pretty GraphTM algorithm is finding the minimum and maximum values to be\nplotted, to set up the graph's horizontal axis. So the range index must also be able to compute the\nminimum and maximum over all keys quickly (in sub-linear time).\n(a) [1 point] Given the constraints above, what data structure covered in 6.006 lectures\nshould be used for the range index? Microware engineers need to implement range\nindexes, so choose the simplest data struture that meets the requirements.\n1. Min-Heap\n2. Max-Heap\n3. Binary Search Tree (BST)\n4. AVL Trees\n5. B-Trees\nSolution: AVL trees are the only data structure that supports sub-linear insertions, as\nwell as sub-linear minimum and maximum queries.\n1U.S. patent pending, no. 9,999,999\n\nProblem Set 3\n(b) [1 point] How much time will it take to insert a key in the range index?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\nSolution: Inserting a node in an AVL tree takes O(log N) time. See the lecture notes\non AVL trees.\n(c) [1 point] How much time will it take to find the minimum key in the range index?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\nSolution:\nFinding the minimum key in an AVL tree takes O(log N) time. See the\nlecture notes on AVL trees.\n(d) [1 point] How much time will it take to find the maximum key in the range index?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\nSolution:\nFinding the maximum key in an AVL tree takes O(log N) time. See the\nlecture notes on AVL trees.\nThe main work of the Pretty GraphTM algorithm is drawing the bars in the graph. A bar shows how\nmany data points there are between two values. For example, in order to produce the visitor graph\nthat is the hallmark of Google Analytics, the range index would record each time that someone uses\nthe site, and a bar would count the visiting times between the beginning and the ending of a day.\nTherefore, the range index needs to support a fast (sub-linear time) COUNT(l, h) query that returns\nthe number of keys in the index that are between l and h (formally, keys k such that l ≤k ≤h).\nYour instinct (or 6.006 TA) tells you that COUNT(l, h) can be easily implemented on top of a\nsimpler query, RANK(x), which returns the number of keys in the index that are smaller or equal\nto x (informally, if the keys were listed in ascending order, x's rank would indicate its position in\nthe sorted array).\n(e) [1 point] Assuming l < h, and both l and h exist in the index, COUNT(l, h) is\n\nProblem Set 3\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\nSolution:\nRANK(h) -RANK(l) + 1. We want to count all the keys x such that\nl ≤x ≤h, which is equivalent to all the keys x ≤h minus all the keys x < l.\nRANK(h) counts all keys x s.t. x ≤h. RANK(l) counts all keys s.t. x ≤l, and will\ninclude l. So we want RANK(h) -(RANK(l) -1) = RANK(h) -RANK(l) + 1\n(f) [1 point] Assuming l < h, and h exists in the index, but l does not exist in the index,\nCOUNT(l, h) is\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\nSolution: RANK(h)-RANK(l). We want to count all the keys x such that l ≤x ≤h,\nwhich is equivalent to all the keys x ≤h minus all the keys x < l. RANK(h) counts\nall keys x s.t. x ≤h. RANK(l) counts all keys s.t. x ≤l, which is equivalent to all the\nkeys x < l since l is not in the index. So RANK(h) -RANK(l) is the right answer.\n(g) [1 point] Assuming l < h, and l exists in the index, but h does not exist in the index,\nCOUNT(l, h) is\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n\nProblem Set 3\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\nSolution:\nRANK(h) -RANK(l) + 1. We want to count all the keys x such that\nl ≤x ≤h, which is equivalent to all the keys x ≤h minus all the keys x < l.\nRANK(h) counts all keys x s.t. x ≤h. RANK(l) counts all keys s.t. x ≤l, and will\ninclude l. So we want RANK(h) -(RANK(l) -1) = RANK(h) -RANK(l) + 1\n(h) [1 point] Assuming l < h, and neither l nor h exist in the index, COUNT(l, h) is\n1. RANK(l) -RANK(h) -1\n2. RANK(l) -RANK(h)\n3. RANK(l) -RANK(h) + 1\n4. RANK(h) -RANK(l) -1\n5. RANK(h) -RANK(l)\n6. RANK(h) -RANK(l) + 1\n7. RANK(h) + RANK(l) -1\n8. RANK(h) + RANK(l)\n9. RANK(h) + RANK(l) + 1\nSolution: RANK(h)-RANK(l). We want to count all the keys x such that l ≤x ≤h,\nwhich is equivalent to all the keys x ≤h minus all the keys x < l. RANK(h) counts\nall keys x s.t. x ≤h. RANK(l) counts all keys s.t. x ≤l, which is equivalent to all the\nkeys x < l since l is not in the index. So RANK(h) -RANK(l) is the right answer.\nNow that you know how to reduce a COUNT() query to a constant number of RANK() queries, you\nwant to figure out how to implement RANK() in sub-linear time. None of the tree data structures\nthat you studied in 6.006 supports optimized RANK() out of the box, but you just remembered that\ntree data structures can respond to some queries faster if the nodes are cleverly augmented with\nsome information.\n(i) [1 point] In order to respond to RANK() queries in sub-linear time, each node node\nin the tree will be augmented with an extra field, node .γ. Keep in mind that for a\ngood augmentation, the extra information for a node should be computed in O(1)\ntime, based on other properties of the node, and on the extra information stored in the\nnode's subtree. The meaning of node .γ is\n1. the minimum key in the subtree rooted at node\n2. the maximum key in the subtree rooted at node\n3. the height of the subtree rooted at node\n4. the number of nodes in the subtree rooted at node\n5. the rank of node\n\nProblem Set 3\n6. the sum of keys in the subtree roted at node\nSolution: The number of nodes in the subtree rooted at node (also known as subtree\nsize).\nγ cannot be the node's rank, because that cannot be computed solely based on infor-\nmation in the node's subtree. Augmentations that report key information (minimum,\nmaximum, sum) don't reveal any information about a node's rank. A tree's height is\nonly roughly related to the number of nodes in the tree.\n(j) [1 point] How many extra bits of storage per node does the augmentation above\nrequire?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n6. O(N)\nSolution: The number of nodes in a subtree is at most N, so the γ field in each node\nneeds to be O(log N)-bits wide to be able to store numbers between 0 and N.\nThe following questions refer to the tree below.\nN1\nN2\nN3\nN4\nN5\nN6\nN7\nN8\nN9\nN10\n(k) [1 point] N4 .γ is\n1. 0\n2. 1\n3. 2\n4. the key at N4\nSolution: 1. A leaf's subtree has exactly one node.\n\nProblem Set 3\n(l) [1 point] N3 .γ is\n1. 1\n2. 2\n3. 3\n4. the key at N4\n5. the key at N5\n6. the sum of keys at N3 . . . N5\nSolution: 3\n(m) [1 point] N2 .γ is\n1. 2\n2. 3\n3. 4\n4. 6\n5. the key at N4\n6. the key at N7\n7. the sum of keys at N3 . . . N5\nSolution: 6\n(n) [1 point] N1 .γ is\n1. 3\n2. 6\n3. 7\n4. 10\n5. the key at N4\n6. the key at N10\n7. the sum of keys at N1 . . . N10\nSolution: 10. The questions should show the pattern for computing node .γ, which\nis\nnode .γ\n=\n1 + γ(left) + γ(right)\nNIL.γ\n=\n(o) [6 points] Which of the following functions need to be modified to update γ? If a\nfunction does not apply to the tree for the range index, it doesn't need to be modified.\n(True / False)\n1. INSERT\n\nProblem Set 3\n2. DELETE\n3. ROTATE-LEFT\n4. ROTATE-RIGHT\n5. REBALANCE\n6. HEAPIFY\nSolution:\nROTATE-LEFT, ROTATE-RIGHT, and REBALANCE\nγ needs to be updated in the same situations where a node's height is updated. The\nAVL methods that call UPDATE-HEIGHT are ROTATE-LEFT, ROTATE-RIGHT, and RE-\nBALANCE. INSERT and DELETE rely on the rotation methods to update the height.\n(p) [1 point] What is the running time of a COUNT() implementation based on RANK()?\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\nSolution: O(log N), which can be achieved by the algorithm below.\nRANK(tree, k)\nr = 0\nnode = tree .root\nwhile node = NIL\nif k < node .key\nnode = node .left\nelse\nif node .left = NIL\nr = r + 1 + node .left .γ\nelse\nr = r + 1\nif node .key == k\nreturn r\nnode = node .right\nreturn r\nThe structure is very similar to that of FIND - in the worst case, RANK visits all the\nnodes on a path from the root to a leaf, and does a constant amount of computation at\neach node on the path.\nAfter the analytics data is plotted using Pretty GraphTM, the CEO can hover the mouse cursor over\none of the bars, and the graph will show a tooltip with the information represented by that bar. To\n\nProblem Set 3\nsupport this operation, the range index needs to support a LIST(l, h) operation that returns all the\nkeys between l and h as quickly as possible.\nLIST(l, h) cannot be sub-linear in the worst case, because LIST(-inf, +inf) must return all the keys\nin the index, which takes Ω(n) time. However, if LIST only has to return a few elements, we would\nlike it to run in sub-linear time. We formalize this by stating that LIST's running time should be\nT(N) + Θ(L), where L is the length of the list of keys output by LIST, and T(N) is sub-linear.\nInspiration (or your 6.006 TA) strikes again, and you find yourself with the following pseudocode\nfor LIST.\nLIST(tree, l, h)\nlca = LCA(tree, l, h)\nresult = []\nNODE-LIST(lca, l, h, result)\nreturn result\nNODE-LIST(node, l, h, result)\nif node == NIL\nreturn\nif l ≤node .key and node .key ≤h\nADD-KEY(result, node .key)\nif node .key ≥l\nNODE-LIST(node .left, l, h, result)\nif node .key ≤h\nNODE-LIST(node .right, l, h, result)\nLCA(tree, l, h)\nnode = tree .root\nuntil node == NIL or (l ≤node .key and h ≥node .key)\nif l < node .key\nnode = node .left\nelse\nnode = node .right\nreturn node\n(q) [1 point] LCA most likely means\n1. last common ancestor\n2. lowest common ancestor\n3. low cost airline\n4. life cycle assessment\n\nProblem Set 3\n5. logic cell array\nSolution: Visiting the Wikipedia page for LCA shows that \"lowest common ances-\ntor\" is the only computer science-related interpretation of LCA.\n(r) [1 point] The running time of LCA(l, h) for the trees used by the range index is\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\nSolution: O(log N), the height of the tree.\n(s) [1 point] Assuming that ADD-KEY runs in O(1) time, and that LIST returns a list of\nL keys, the running time of the NODE-LIST call at line 3 of LIST is\n1. O(1)\n2. O(log(log N))\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n6. O(1) + O(L)\n7. O(log(log N)) + O(L)\n8. O(log N) + O(L)\n9. O(log2 N) + O(L)\n10. O(\n√\nN) + O(L)\nSolution: O(log N) + O(L).\nThe NODE-LIST call at line 3 performs a pre-order traversal starting at the least com-\nmon ancestor of the nodes containing keys l and h. If the keys l and/or h are not in\nthe BST, we use the positions of imaginary nodes that would be created by inserting l\nand/or h using the BST insertion algorithm (no re-balancing).\nThe traversal ignores some sub-trees. Line 5 prunes the left sub-tree of any node\nwhose key is ≤l because, by the BST invariant, the keys of all the nodes in the sub-\ntree will be smaller than node .key, which is ≤l. In a symmetric fashion, line prunes\nsub-trees where all the nodes' keys are guaranteed to be greater than h.\nNODE-LIST spends O(1) time for each node it visits, so the total running time is\nO(V ), where V is the number of visited nodes. We split up V = L + X, where L\nis the number of nodes returned from LIST, and X is the number of nodes that are\nvisited, but not output (extra nodes, or overhead). We argue that X = O(h), where\nh is the height of the BST. Because the BST is an AVL, we use h = O(log N) to\nconclude that the total running time of the NODE-LIST call in LIST is O(log(N)+L).\n\nProblem Set 3\nWe'll sketch a proof that the extra nodes in the left sub-tree of the LCA node are all\non the path from the LCA to the l node. A symmetric proof covers the right sub-tree\nof the LCA node. The proof refers to the tree below.\nLCA\n...\nx\nxL\ny\n...\nl\nyR\n...\nh\nEvery node on the path from the LCA node to the l node falls under one of the follow-\ning two cases.\n- The node l belongs to the node's right sub-tree. Let x be the node's key, and xL be\nthe node's left sub-tree. Since the l node is in the x node's left sub-tree, it follows\nthat l > x (by theBST invariant), so the xL sub-tree will be pruned by line 5 in\nNODE-LIST. So NODE-LIST will never \"stray\" to the left of the path from the\nLCA node to the l node.\n- The node l belongs to the node's left sub-tree. Let y be the node's key, and\nyR be the node's right sub-tree. Since the l node is in the x node's right sub-\ntree, it follows that l < y (by the BST's invariant). Every node in yR will have\na key greater than y (BST invariant), so all the keys in yR are greater than l.\nFurthermore, because yR is in LCA's left sub-tree, all the keys in yR are smaller\nthan the key in LCA, which is ≤h. It follows that all the nodes in yR belong to\nthe (l, h] interval, and their keys will be returned from NODE-LIST. So, whenever\nNODE-LIST \"strays\" to the right of the path from the LCA node to the l node, it\nwill output all the nodes it encounters.\nThe two cases above show that all the extra nodes (visited but not added to the result) in\nthe LCA node's left sub-tree are on the path from LCA to l, which means X = O(h).\nA symmetric proof can be used to show that all the extra nodes in the LCA node's\nright sub-tree are on the path from LCA to h.\n(t) [1 point] Assuming that ADD-KEY runs in O(1) time, and that LIST returns a list of\nL keys, the running time of LIST is\n1. O(1)\n2. O(log(log N))\n\nProblem Set 3\n3. O(log N)\n4. O(log2 N)\n5. O(\n√\nN)\n6. O(1) + O(L)\n7. O(log(log N)) + O(L)\n8. O(log N) + O(L)\n9. O(log2 N) + O(L)\n10. O(\n√\nN) + O(L)\nSolution:\nO(log N) + O(L).\nAccording to the previous questions, LCA takes\nO(log N) time, and the NODE-LIST call takes O(log N) + O(L) time.\n(u) [20 points] Prove that LCA is correct.\nSolution: We will argue that LCA(l, h) returns the least-common ancestor, defined\nas the root of the smallest sub-tree that contains both l and h. If the keys l and/or h are\nnot in the BST, we augment the tree with the imaginary nodes that would be created\nby inserting l and/or h using the BST insertion algorithm (no re-balancing).\nBased on the definition above, we will prove that LCA is correct in two stages: first\nwe prove that LCA maintains the invariant that l and h belong to the sub-tree rooted\nat node, then we prove that LCA returns the root of the smallest sub-tree that contains\nboth l and h.\nLCA maintains the invariant that l and h belong to the sub-tree rooted at node.\nnode starts out at the tree's root, so the invariant starts out to be true at line 2. The\nloop continues as long as both l and h are smaller than node's key, or l and h are both\nbigger than node's key. If l and h are smaller, then the condition on line 3 will be true,\nso both l and h are in node's left sub-tree, by the BST invariant, so line 4 preserves\nthe invariant. Similarly, if l and h are larger, they're both in node's right sub-tree, so\nline 6 preserves the invariant.\nLCA returns the root of the smallest sub-tree that contains both l and h. Proof by\ncontradiction:\nLet r be the key of the node returned by LCA, and c be the key of the node that is the\ncorrect answer. By the invariant above, l and h are in the sub-tree rooted at the r node,\nso the c node is in the sub-tree rooted at r.\nIf c is in the r node's left sub-tree, it follows that c < r. Since l and h are in the\nsub-tree rooted at the c node, they are in r's left sub-tree, so l < r and h < r by the\nBST invariant. But in that case, the condition on line 2 will be true when idnode is the\nr node, so the r node should not be returned from LCA. Contradiction.\nThe case where c is in the r node's right sub-tree is symmetrical, as both l and h will\nbe in r's sub-tree and l > r, h > r.\n\nProblem Set 3\nProblem 3-2.\n[55 points] Digital Circuit Layout\nYour AMDtel internship is off to a great start! The optimized circuit simulator cemented your\nreputation as an algorithms whiz. Your manager capitalized on your success, and promised to\ndeliver the Bullfield chip a few months ahead of schedule. Thanks to your simulator optimizations,\nthe engineers have finished the logic-level design, and are currently working on laying out the\ngates on the chip. Unfortunately, the software that verifies the layout is taking too long to run\non the preliminary Bullfield layouts, and this is making the engineers slow and unhappy. Your\nmanager is confident in your abilities to speed it up, and promised that you'll \"do your magic\"\nagain, in \"one week, two weeks tops\".\nA chip consists of logic gates, whose input and output terminals are connected by wires (very\nthin conductive traces on the silicon substrate). AMDtel's high-yield manufacturing process only\nallows for horizontal or vertical wires. Wires must not cross each other, so that the circuit will\nfunction according to its specification. This constraint is checked by the software tool that you\nwill optimize. The topologies required by complex circuits are accomplished by having dozens of\nlayers of wires that do not touch each other, and the tool works on one layer at a time.\n(a) [1 point] Run the code under the python profiler with the command below, and iden-\ntify the method that takes up most of the CPU time. If two methods have similar CPU\nusage times, ignore the simpler one.\npython -m cProfile -s time circuit2.py < tests/10grid s.in\nWarning: the command above can take 15-60 minutes to complete, and bring the\nCPU usage to 100% on one of your cores. Plan accordingly. If you have installed\nPyPy successfully, you can replace python with pypy in the command above for a\nroughly 2x speed improvement.\nWhat is the name of the method with the highest CPU usage?\nSolution: The first line in the profiler output identifies intersects as the method\nwith the largest CPU usage.\n(b) [1 point] How many times is the method called?\nSolution: The first line in the profiler output indicates that intersects is called\n187590314 times.\nThe method that has the performance bottleneck is called from the CrossVerifier class. Upon\nreading the class, it seems that the original author was planning to implement a sweep-line algo-\nrithm, but couldn't figure out the details, and bailed and implemented an inefficient method at the\nlast minute. Fortunately, most of the infrastructure for a fast sweep-line algorithm is still in place.\nFurthermore, you notice that the source code contains a trace of the working sweep-line algorithm,\nin the good trace.jsonp file.\nSweep-line algorithms are popular in computational geometry. Conceptually, such an algorithm\nsweeps a vertical line left to right over the plane containing the input data, and performs operations\nwhen the line \"hits\" point of interest in the input. This is implemented by generating an array\n\nProblem Set 3\ncontaining all the points of interest, and then sorting them according to their position along the\nhorizontal axis (x coordinate).\nRead the source for CrossVerifier to get a feel for how the sweep-line infrastructure is sup-\nposed to work, and look at the good trace in the visualizer that we have provided for you. To see\nthe good trace, copy good trace.jsonp to trace.jsonp\ncp good trace.jsonp trace.jsonp\nOn Windows, use the following command instead.\ncopy good trace.jsonp trace.jsonp\nThen use Google Chrome to open visualizer/bin/visualizer.html\nThe questions below refer to the fast sweep-line algorithm shown in good trace.jsonp, not\nto the slow algorithm hacked together in circuit2.py.\n(c) [5 points] The x coordinates of points of interest in the input are (True / False)\n1. the x coordinates of the left endpoints of horizontal wires\n2. the x coordinates of the right endpoints of horizontal wires\n3. the x coordinates of midpoints of horizontal wires\n4. the x coordinates where horizontal wires cross vertical wires\n5. the x coordinates of vertical wires\nSolution:\nThe x coordinates of both endpoints of horizontal wires, and of vertical\nwires. The algoritm doesn't handle wire midpoints specially. Crossing points cannot\npossibly be points of interest, because they are the algorithm's output, not input.\n(d) [1 point] When the sweep line hits the x coordinate of the left endpoint of a horizontal\nwire\n1. the wire is added to the range index\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\nSolution: The wire is added to the range index when the sweep line hits the x coor-\ndinate of the left endpoint.\n(e) [1 point] When the sweep line hits the x coordinate of the right endpoint of a hori-\nzontal wire\n1. the wire is added to the range index\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\n\nProblem Set 3\nSolution: The wire is removed from the range index when the sweep line hits the X\ncoordinate of the right endpoint.\n(f) [1 point] When the sweep line hits the x coordinate of the midpoint of a horizontal\nwire\n1. the wire is added to the range index\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\nSolution: Nothing happens.\n(g) [1 point] When the sweep line hits the x coordinate of a vertical wire\n1. the wire is added to the range index\n2. the wire is removed from the range index\n3. a range index query is performed\n4. nothing happens\nSolution: A range index is performed.\n(h) [1 point] What is a good invariant for the sweep-line algorithm?\n1. the range index holds all the horizontal wires to the left of the sweep line\n2. the range index holds all the horizontal wires \"stabbed\" by the sweep line\n3. the range index holds all the horizontal wires to the right of the sweep line\n4. the range index holds all the wires to the left of the sweep line\n5. the range index holds all the wires to the right of the sweep line\nSolution: The invariant for the sweep-line algorithm is that the range index holds all\nthe horizontal wires \"stabbed\" by the sweep line.\n(i) [1 point] When a wire is added to the range index, what is its corresponding key?\n1. the x coordinate of the wire's midpoint\n2. the y coordinate of the wire's midpoint\n3. the segment's length\n4. the x coordinate of the point of interest that will remove the wire from the index\nSolution:\nThe only correct answer is \"the Y coordinate of the wire's midpoint\".\nOnly horizontal wires are added to the range index, and all their points have the same\nY coordinate.\nModify CrossVerifier in circuit2.py to implement the sweep-line algorithm discussed\nabove. If you maintain the current code structure, you'll be able to use our visualizer to debug your\nimplementation. To use our visualizer, first produce a trace.\n\nProblem Set 3\nTRACE=jsonp python circuit2.py < tests/5logo.in > trace.jsonp\nOn Windows, run the following command instead.\ncircuit2 jsonp.bat < tests/5logo.in > trace.jsonp\nThen use Google Chrome to open visualizer/bin/visualizer.html\n(j) [1 point] Run your modified code under the python profiler again, using the same test\ncase as before, and identify the method that takes up the most CPU time.\nWhat is the name of the method with the highest CPU usage? If two methods have\nsimilar CPU usage times, ignore the simpler one.\nSolution:\nThe first line in the profiler output identifies count as the method with\nthe highest CPU usage.\n(k) [1 point] How many times is the method called?\nSolution:\nThe first line in the profiler output indicates that count is called 20000\ntimes.\n(l) [40 points] Modify circuit2.py to implement a data structure that has better\nasymptotic running time for the operation above. Keep in mind that the tool has two\nusage scenarios:\n- Every time an engineer submits a change to one of the Bullhorn wire layers,\nthe tool must analyze the layer and report the number of wire crossings. In this\nlate stage of the project, the version control system will automatically reject the\nengineer's change if it causes the number of wire crossings to go up over the\nprevious version.\n- Engineers working on the wiring want to see the pairs of wires that intersect, so\nthey know where to focus ther efforts. To activate this detailed output, run the\ntool using the following command.\nTRACE=list python circuit2.py < tests/6list logo.in\nOn Windows, run the following command instead.\ncircuit2 list.bat < tests/6list logo.in\nWhen your code passes all tests, and runs reasonably fast (the tests should complete\nin less than 60 seconds on any reasonably recent computer), upload your modified\ncircuit.py to the course submission site.\nSolution:\nThe solution archive on the course Web site contains the staff's solution\nand secret test cases.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 4 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/418d498452f400c119dd0b6dd2c43f50_MIT6_006F11_ps4_sol.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\n7 October, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 4\nProblem Set 4\nBoth theory and programming questions are due Friday, 14 October at 11:59PM.\nRemember that for the written response question, your goal is to communicate. Full credit will\nbe given only to a correct solution which is described clearly. Convoluted and obtuse descriptions\nmight receive low marks, even when they are correct. Also, aim for concise solutions, as it will\nsave you time spent on write-ups, and also help you conceptualize the key idea of the problem.\nWe will provide the solutions to the problem set 10 hours after the problem set is due, which\nyou will use to find any errors in the proof that you submitted. You will need to submit a critique\nof your solutions by Thursday, October 20th, 11:59PM. Your grade will be based on both your\nsolutions and your critique of the solutions.\nProblem 4-1.\n[35 points] Hash Functions and Load\n(a) Imagine that an algorithm requires us to hash strings containing English phrases.\nKnowing that strings are stored as sequences of characters, Alyssa P. Hacker decides\nto simply use the sum of those character values (modulo the size of her hash table)\nas the string's hash. Will the performance of her implementation match the expected\nvalue shown in lecture?\n1. Yes, the sum operation will space strings out nicely by length.\n2. Yes, the sum operation will space strings out nicely by the characters they contain.\n3. No, because reordering the words in a string will not produce a different hash.\n4. No, because the independence condition of the simple uniform hashing assump-\ntion is violated.\nSolution:\nNo, because reordering the words in a string will not produce a different\nhash.\n(b) Alyssa decides to implement both collision resolution and dynamic resizing for her\nhash table. However, she doesn't want to do more work than necessary, so she wonders\nif she needs both to maintain the correctness and performance she expects. After all,\nif she has dynamic resizing, she can resize to avoid collisions; and if she has collision\nresolution, collisions don't cause correctness issues. Which statement about these two\nproperties true?\n1. Dynamic resizing alone will preserve both properties.\n2. Dynamic resizing alone will preserve correctness, but not performance.\n\nProblem Set 4\n3. Collision resolution alone will preserve performance, but not correctness.\n4. Both are necessary to maintain performance and correctness.\nSolution:\nBoth are necessary to maintain performance and correctness. Without\ncollision resolution, no correctness: could have an actual hash collision, and then no\namount of resizing will let both be entered into the table. Without dynamic resiz-\ning, the load factor will get large, and everything will turn into a linear-time lookup\n(assuming chaining).\n(c) Suppose that Alyssa decides to implement resizing. If Alyssa is enlarging a table of\nsize m into a table of size m′, and the table contains n elements, what is the best time\ncomplexity she can achieve?\n1. Θ(m)\n2. Θ(m′)\n3. Θ(n)\n4. Θ(nm′)\n5. Θ(m + m′)\n6. Θ(m + n)\n7. Θ(m′ + n)\nSolution: Θ(m′ + n). It takes O(m′) time to create a new hash table (allocating the\nmemory can take constant time, but it then needs to be initialized). It takes O(m + n)\ntime to go through each slot in the old table and copy each item. In total, it comes out\nto Θ(m′ + m + n), but since m < m′, the answer is just Θ(m′ + n).\n(d) In lecture, we discussed doubling the size of our hash table. Ivy H. Crimson begins\nto implement this approach (that is, she lets m′ = 2m) but stops when it occurs to\nher that she might be able to avoid wasting half of the memory the table occupies on\nempty space by letting m′ = m+k instead, where k is some constant. Does this work?\nIf so, why do you think we don't do it? There is a good theoretical reason as well as\nseveral additional practical concerns; a complete answer will touch on both points.\nSolution: Theoretically, our cost will now be O(n) even after amortization. Loosely\nspeaking, we were able to achieve O(1) amortized cost because we performed an O(n)\ntime operation every O(n) step. Now, however, we're performing this O(n) operation\nevery O(1) steps. Practically, the computer will play more nicely with operations\nbased around doubling (doubling is a fast operation, allocating memory blocks of\nsizes that are powers of two has plenty of advantages, etc).\nProblem 4-2.\n[10 points] Python Dictionaries\nWe're going to get started by checking out a file from Python's Subversion repository at svn.python.org.\nThe Python project operates a web frontend to their version control system, so we'll be able to do\nthis using a browser.\n\nProblem Set 4\nVisit http://svn.python.org/projects/python/trunk/Objects/dictnotes.txt.\nThese are actual notes prepared by contributors to the Python project, as they currently exist in the\nPython source tree. (Cool! Actually, this document is a fascinating read--and you should be able\nto understand most of it.) Read over the seven use cases identified at the top of this document.\n(a) Let's examine the \"membership testing\" use case. Which statement accurately de-\nscribes this use case?\n1. Many insertions right after creation, and then mostly lookups.\n2. Many insertions right after creation, and then only lookups.\n3. A workload of evenly-mixed insertions/deletions and lookups.\n4. Alternating rounds of insertions/deletions and lookups.\nSolution: Many insertions right after creation, and then mostly lookup.\n(b) Now imagine that you have to pick a hash function, size, collision resolution strategy,\nand so forth (all of the characteristics of a hash table we've seen so far) in order to\nmake a hash table perfectly suited to this use case alone. Pick the statement that best\ndescribes the choices you might make.\n1. A large minimum size and a growth rate of 2.\n2. A small minimum size and a growth rate of 2.\n3. A large minimum size and a growth rate of 4.\n4. A small minimum size and a growth rate of 4.\nSolution: Membership testing can benefit from highly sparse hash tables, so let's set\ngrowth factor to 4. We're going to be inserting a bunch of things up front, so let's start\nwith a larger minimum size.\nProblem 4-3.\n[55 points] Matching DNA Sequences\nThe code and data used in this problem are available on the course website. Please take a peek at\nthe README.txt for some instructions.\nBen Bitdiddle has recently moved into the Kendall Square area, which is full of biotechnology\ncompanies and their shiny, window-laden office buildings. While mocking their dorky lab coats\nmakes him feel slightly better about himself, he is secretly jealous, and so he sets out to earn one\nof his very own. To pick up the necessary geek cred, he begins experimenting with DNA-matching\ntechnologies.\nBen would like to create mutants to do his bidding, and to get started, he'd like to know how closely\nrelated the creatures he's collected are. If two sequences contain mostly the same subsequences\nin mostly the same places, then they're likely closely related; if they don't, they probably aren't.\n(This is, of course, a gross oversimplification.)\nFor our purposes, we'll represent a DNA sample as a sequence of characters. (These characters will\nall be upper-case. You can look at the Wikipedia page on nucleotides for a list of code characters\n\nProblem Set 4\nand their meanings.) These sequences are very long, so comparing subsequences of them quickly\nis important. We've provided code in kfasta.py that reads the .fa files storing this data.\n(a) Let's start with subsequenceHashes, which returns all length-k subsequences\nand their hashes (and perhaps other information, if there's anything else you might\nfind useful).\nHint: There will likely be many of these matches; the DNA sequences are tens of\nmillions of nucleotides long. To avoid keeping them all in memory at once, implement\nyour function as a generator. See the Python reference materials available online for\ndetails if you aren't familiar with this important language construct.\n(b) Implement Multidict and verify that your work passes the simple sanity tests pro-\nvided.\nMultidict should behave just like a Python dictionary, except that it can store mul-\ntiple values per key. If no values exist for a key, it returns an empty list; otherwise, it\nreturns the list of associated values. You may (and probably should) use the Python\ndictionary in your implementation.\n(c) Now it's time to implement getExactSubmatches. Ignore the parameter m for\nthe time being; we'll get to that in the next part. Again, implementing this function as\na generator is probably a good idea. (You will probably have many, many matches-\nthink about the combinatorics of the situation briefly.) As a hint, consider that much\nof the work has already been done by Multidict and subsequenceHashes;\nalso take a peek at the RollingHash implementation we've given you. With these\nbuilding blocks, your solution probably does not need to be very complex (or more\nthan a few lines).\nThis function should return pairs of offsets into the inputs. A tuple (x, y) being re-\nturned indicates that the k-length subsequence at position x in the first input matches\nthe subsequence at position y in the second input.\nWe've provided a simple sanity test; your solution should be correct at this point (that\nis, dnaseq.py will produce the right output) but it'll probably be too slow to be\nuseful. If you like, you can try running it on the first portion of two inputs; we've\nprovided two such prefixes (the short files in the data directory) that might be helpful.\n(d) The most significant reason why your solution is presently too slow to be useful is\nthat you are hashing and inserting into your hash table tens of millions of elements,\nand then performing tens of millions of lookups into that hash table. Implement\nintervalSubsequenceHashes, which returns the same thing as subsequenceHashes\nexcept that it hashes only one in m subsequences. (A good implementation will not do\nmore work than is necessary.) Modify your implementation of getExactSubmatches\nto honor m only for sequence A. Consider why we still see approximately the same\nresult, and why we can't further improve performance by applying this technique to\nsequence B as well.\n\nProblem Set 4\n(e) Run comparisons between the two human samples (paternal and maternal) and be-\ntween the paternal sample and each of the animal samples.\nFeel free to take a peek at how the image-generation code works. Conceptually, what\nit's doing is keeping track of how many of your (x, y) match tuples land in each of\na two-dimensional grid of bins, each of which corresponds to a pixel in the output\nimage. At the end, it normalizes the counts so that the highest count observed is\ntotally black and an empty bin is white.\nThink for a second about what a perfect match (e.g., comparing a sequence to itself)\nshould look like. Try comparing the two human samples you have (maternal and pa-\nternal), one of the humans against the chimp sample, and then against the dog sample.\nMake sure your results make sense!\nWe've posted what our reference solution produced for the human-human comparison,\nthe human-chimp comparison, and the human-dog comparison.\nPlease submit the code that you wrote. (You should only have had to modify dnaseq.py,\nso that's all you need to submit.)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\n\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 5 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/86d0fc7bd86543c73d6158a6711cb216_MIT6_006F11_ps5_sol.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nOctober 24, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 5\nProblem Set 5\nBoth theory and programming questions are due Monday, October 31 at 11:59PM. Please\ndownload the .zip archive for this problem set, and refer to the README.txt file for instructions\non preparing your solutions.\nWe will provide the solutions to the problem set 10 hours after the problem set is due. You will\nhave to read the solutions, and write a brief grading explanation to help your grader understand\nyour write-up. You will need to submit the grading explanation by Thursday, November 3rd,\n11:59PM. Your grade will be based on both your solutions and the grading explanation.\nProblem 5-1.\n[40 points] The Knight's Shield\nThe optimized circuit verifier that you developed on your Amdtel internship was a huge success\nand got you on a sure track to landing a sweet offer. You also got transferred to a research group\nthat is working on the Knight's Shield (KS)1, a high-stakes project to develop a massive multi-core\nchip aimed at the exploding secure cloud computing market.\nThe KS chip packs 16,384 cores in a die that's the same size as a regular CPU die. However, each\ncore is very small, and can only do arithmetic operations using 8-bit or 16-bit unsigned integers\n(see Table 1). Encryption algorithms typically use 2,048-bit integers, so the KS chip will ship with\nsoftware that supports arithmetic on large integers. Your job is to help the KS team assess the\nefficiency of their software.\nOperation\nR1 size\nR2 size\nResult size\nResult\nZERO\n8 / 16\n0 (zero)\nONE\n8 / 16\n1 (one)\nLSB R1\nR1 % 256 (least significant byte)\nMSB R1\nR1 / 256 (most significant byte)\nWORD R1\nR1 (expanded to 16-bits)\nADD R1, R2\n8 / 16\n8 / 16\nR1 + R2\nSUB R1, R2\n8 / 16\n8 / 16\nR1 -R2\nmod 65536\nMUL R1, R2\nR1 · R2\nDIV R1, R2\nR1 ÷ R2\nmod 256\nMOD R1, R2\nR1 % R2\nAND R1, R2\n8 / 16\n8 / 16\n8 / 16\nR1 & R2 (bitwise AND)\nOR R1, R2\n8 / 16\n8 / 16\n8 / 16\nR1 ∥R2 (bitwise OR)\nXOR R1, R2\n8 / 16\n8 / 16\n8 / 16\nR1 ˆ R2 (bitwise XOR)\nTable 1: Arithmetic operations supported by the KS chip. All sizes are in bits.\n1The code name is Amdtel confidential information. Please refrain from leaking to TechCrunch.\n\nProblem Set 5\nThe KS library supports arbitrarily large base-256 numbers. The base was chosen such that each\ndigit is a byte, and two digits make up a 16-bit number. Numbers are stored as a little-endian\nsequence of bytes (the first byte of a number is the least significant digit, for example 65534\n= 0xFFFE would be stored as [0xFE, 0xFF]). For the rest of the problem, assume all the input\nnumbers have N digits.\nConsider the following algorithm for computing A + B, assuming both inputs have N digits.\nADD(A, B, N)\nC = ZERO(N + 1) // ZERO(k) creates a k-digit number, with all digits set to 0s.\ncarry = 0\nfor i = 1 to N\ndigit = WORD(A[i]) + WORD(B[i]) + WORD(carry)\nC[i] = LSB(digit)\ncarry = MSB(digit)\nC[N + 1] = carry\nreturn C\n(a) [1 point] What is the running time of ADD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N), because of the for loop on line 3.\n(b) [1 point] What is the size of ADD's output?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N), because it returns an (N + 1)-digit number.\n\nProblem Set 5\n(c) [1 point] ADD's output size suggests an easy lower bound for the subroutine. Does\nthe running time of ADD match this lower bound?\n1. Yes\n2. No\nSolution: Yes. The running time matches the output size, so the algorithm must be\noptimal.\nConsider the following brute-force algorithm for computing A · B, assuming both inputs have N\ndigits.\nMULTIPLY(A, B, N)\nC = ZERO(2N)\nfor i = 1 to N\ncarry = 0\nfor j = 1 to N\ndigit = A[i] · B[j] + WORD(C[i + j -1]) + WORD(carry)\nC[i + j -1] = LSB(digit)\ncarry = MSB(digit)\nC[i + N ] = carry\nreturn C\n(d) [1 point] What is the running time of MULTIPLY?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N 2), because of the nested for loops on lines 2 and 4.\n(e) [1 point] What is the size of MULTIPLY's output?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n\nProblem Set 5\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N), because it returns a 2N-digit number.\n(f) [1 point] MULTIPLY's output size suggests an easy lower bound for the subroutine.\nDoes the running time of MULTIPLY match this lower bound?\n1. Yes\n2. No\nSolution: No. In fact, we do not know a multiplication algorithm that runs in Θ(N)\ntime, and we don't have a proof for a better lower bound than Θ(N) for multiplica-\ntion.\nConsider the following brute-force algorithm for computing A ÷ B and A mod B, assuming\nboth inputs have N digits. The algorithm uses a procedure COPY(A, N) that creates a copy of an\nN-digit number A, using Θ(N) time.\nDIVMOD(A, B, N)\nQ = ZERO(N) // quotient\nR = COPY(A, N) // remainder\nS0 = COPY(B, N) // Si = B · 2i\ni = 0\nrepeat\ni = i + 1\nSi = ADD(Si-1, Si-1, N)\nuntil Si[N + 1] > 0 or CMP(Si, A, N) == GREATER\nfor j = i -1 downto 0\nQ = ADD(Q, Q, N)\nif CMP(R, Sj, N) != SMALLER\nR = SUBTRACT(R, Sj, N)\nQ[0] = Q[0]∥1 // Faster version of Q = Q + 1\nreturn (Q, R)\n(g) [1 point]\nCMP(A, B, N) returns GREATER if A > B, EQUAL if A = B, and\nSMALLER if A < B, assuming both A and B are N-digit numbers. What is the\nrunning time for an optimal CMP implementation?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n\nProblem Set 5\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution:\nΘ(N) because, in the worst case, it has to look at every digit in both\nnumbers. The following pseudo-code runs in Θ(N) time.\nGREATEREQUAL(A, B, N)\nfor i = 1 to N\nif A[i] = B[i]\nif A[i] > B[i]\nreturn GREATER\nelse return SMALLER\nreturn EQUAL\n(h) [1 point] SUBTRACT(A, B, N) computes A -B, assuming A and B are N-digit\nnumbers. What is the running time for an optimal SUBTRACT implementation?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N). The pseudo-code, run-time analysis, and optimality argument are\nvery similar to those for ADD discussed above.\n(i) [1 point] What is the running time of DIVMOD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\n\nProblem Set 5\nSolution: Θ(N 2). The Repeat . . . Until loop starting on line 5 can increase i up to\n8N, which is achieved using the extreme values B = 1 and A = 28N -1. So, both the\nRepeat . . . Until loop and the for loop starting on line 9 run Θ(N) times. Each loop\nmakes a constant number of calls to ADD, SUBTRACT and CMP, all of which have\nΘ(N) running time when given N-digit long inputs. Therefore, the total running time\nis Θ(N) · Θ(N) = Θ(N 2)\nThe KS library does not use the DIVMOD implementation above. Instead, it uses Newton's method\nto implement DIV(A, B, N) which computes the division quotient A ÷ B, assuming both inputs\nhave N digits. DIV relies on the subroutines defined above. For example, it uses MULTIPLY\nto perform large-number multiplication and ADD for large-number addition. MOD(A, B, N) is\nimplemented using the identity A mod B = A -(A ÷ B) · B.\n(j) [2 points] How many times does DIV call MULTIPLY?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(log N) times, because it converges quadratically, according to the Lec-\nture 12 notes.\n(k) [2 points] What is the running time of MOD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N 2).\nAlthough MULTIPLY is called Θ(log N) times in DIV, the operand sizes are different\neach time, so the total running time for DIV is Θ(N 2). See the Lecture 12 notes for\ndetails.\n\nProblem Set 5\nMOD performs an extra multiplication and subtraction, so it takes Θ(N 2) running time\nin addition to the running time of DIV. The total running time of MOD is Θ(N 2 +\nN 2) = Θ(N 2)\nConsider the following brute-force algorithm for computing BE mod M, assuming all the input\nnumbers have N digits.\nPOWMOD(B, E, M, N)\nR = ONE(N) // result\nX = COPY(B, N) // multiplier\nfor i = 1 to N\nmask = 1\nfor bit = 1 to 8\nif E[i] & mask != 0\nR = MOD(MULTIPLY(R, X, N), M, 2N)\nX = MOD(MULTIPLY(X, X, N), M, 2N)\nmask = LSB(mask · 2)\nreturn R\n(l) [2 points] What is the running time for POWMOD?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution:\nΘ(N 3). The for loop on line 3 runs N times, and the inner for loop on\nline 7 runs 8 times, so MULTIPLY and MOD on lines 7 and 8 are called Θ(N) times.\nThe intermediate multiplication results are always reduced modulo N, so R and X\nwill always have Θ(N) digits, which means that each MOD and MULTIPLY call takes\nΘ(N 2) time.\nAssume the KS library swaps out the brute-force MULTIPLY with an implementation of Karat-\nsuba's algorithm.\n(m) [1 point] What will the running time for MULTIPLY be after the optimization?\n1. Θ(1)\n\nProblem Set 5\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N log2 3), the running time of Karatsuba's algorithm.\n(n) [2 points] What will the running time for MOD be after the optimization?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N log2 3), for the same reason that MOD takes Θ(N 2) time when MUL-\nTIPLY is implemented using the brute-force algorithm.\n(o) [2 points] What will the running time for POWMOD be after the optimization?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution:\nΘ(N log2 6).\nAs argued earlier, POWMOD calls MULTIPLY and MOD\nΘ(N) times with Θ(N)-digit long arguments. So the total running time is Θ(N)\nΘ(N log2 3) = Θ(N 1+log2 3) = Θ(N log2(2·3)) = Θ(N log2 6\n·\n).\n(p) [20 points] Write pseudo-code for KTHROOT(A, K, N), which computes\n√\n⌊\nK A⌋us-\ning binary search, assuming that A and K are both N-digit numbers. The running\ntime for KTHROOT(A, K, N) should be Θ(N 2+log2 3).\nSolution: The pseudo-code below implements a binary search for the answer.\n\nProblem Set 5\nKTHROOT(A, K, N)\nT0 = ONE(N) // Ti = 2i\ni = 0\nrepeat\ni = i + 1\nTi = ADD(Ti-1, Ti-1, N)\nuntil Ti[N + 1] > 0 or POWEXCEEDS(Ti, K, A, N)\nR = ZERO(N)\nfor j = i -1 downto 0\nR′ = ADD(R, Tj)\nunless POWEXCEEDS(R′, K, A, N)\nR = R′\nreturn R\nThe pseudo-code uses a helper subroutine POWEXCEEDS(B, E, A, N), which returns\nTRUE iff BE > A, assuming all input numbers are N-digits long. This solution takes\na non-standard approach to implementing binary search that is worth taking a look at.\nThe regular binary search implementation requires a [low, high] range that contains the\nanswer, and uses a guess g = ⌊low+high\n⌋to narrow the range down to a single number.\nIn contrast, this implementation assumes that the answer is non-negative low = 0, and\ndoes not require a high upper bound on the answer. The repeat-until loop on lines 3-8\ncomputes the upper bound by generating powers of i (Ti is computed to hold 2i inside\nthe loop) and stopping when the answer is smaller than Ti, which means that we can\nuse high = Ti and start the typical binary search algorithm on the [0, Ti] interval. If\nthe answer has n bits, the repeat-until loop runs for n iterations, so having to compute\nthe upper bound doesn't change the asymptotic running time of binary search.\nLine 7 initializes R, which is going to be returned as the result of the binary search.\nR stands for \"result\", but is actually the low variable in regulary binary search. This\nis because we are asked to compute the floor of the kth root of A. The for loop on\nlines 8-11 implements the binary search, by successively computing the bits of R,\nfrom the highest bit to the lowest. The variables map to the classical binary search\nimplementation as follows: low is R, high is R + 2Tj -1, and the guess g is R + Tj.\nThis holds before the loop because R = 0, and we know that the answer is smaller\nthan Ti, so it has to be ≤Ti -1 = 2Ti-1 -1 = 2Tj -1. Convince yourself that the\ninvariant holds throughout the loop, using the fact that Ti = 2Ti-1.\nThis variant of binary search is interesting because the successive values of the guess g\nonly differ by one bit, and it can be implemented solely using bitwise operations (shift-\ning, and bitwise OR), whereas the classical binary search implementation requires ad-\ndition. Note that the division by two in classical binary search can be implemented\nusing a right shift, so the only difference is the need for addition (the + operator).\nThe DIVMOD pseudo-code given in this problemset follows the same binary search\nstrategy for computing the division quotient. Take another look at the pseudo-code\n\nProblem Set 5\nand convince yourself that this is the case. The first result of Googling for double\ndivision should help visualize the divsion algorithm.\nPOWEXCEEDS(B, E, A, N)\nA2 = ZERO(2N) // A, zero-extended to 2N digits\nfor i = 1 to N\nA2[i] = A[i]\nones = 0 // number of set bits in E\nfor i = 1 to N\nmask = 1\nfor bit = 1 to 8\nif E[i] & mask != 0\nones = ones + 1\nmask = LSB(mask · 2)\nR = ONE(N) // result\nX = COPY(B, N) // multiplier\nfor i = 1 to N\nmask = 1\nfor bit = 1 to 8\nif E[i] & mask != 0\nR = MULTIPLY(R, X, N)\nif CMP(R, A2, 2N) == GREATER\nreturn TRUE\n// ones is the number of 1s that haven't yet contributed to R\nones = ones -1\nif ones == 0\nreturn FALSE // R = BE ≤A\nX = MULTIPLY(X, X, N)\nif CMP(X, A2, 2N) == GREATER\nreturn TRUE\nmask = LSB(mask · 2)\nreturn FALSE\nThe POWEXCEEDS implementation is similar to that of POWMOD. Instead of calling\nMOD, lines 18 and 24 return FALSE if the intermediate result is greater than A, so\na modular reduction would occur. If R ever gets greater than A, we know that the\nfinal result will also be greater than A, so it's safe to return FALSE. However, X is\nnot always multiplied by R, so we must take some precaution. This implementation\ncounts the 1 bits in the exponent, and returns as soon as R receives the result of the\nmultiplication corresponding to the most significant exponent bit that is set to 1. This\nmeans that when we square X, we know the value will eventually be multiplied into\nR. Therefore, it is also safe to return FALSE when an intermediate X value exceeds\nA.\n\nProblem Set 5\nBecause of all the precautions above, all the intermediate results in POWEXCEEDS\nare at most 2N digits long, so the subroutine has the same running time as POWMOD,\nΘ(N log2 6).\nNTHROOT performs a binary search, which may use up to 8N trials. So the total\nrunning time of NTHROOT is Θ(N · N log2 6) = Θ(N 1+log2 6) = Θ(N 2+log2 3)\n\nProblem Set 5\nProblem 5-2.\n[18 points] RSA Public-Key Encryption\nThe RSA (Rivest-Shamir-Adelman) public-key cryptosystem is a cornerstone of Internet security.\nIt provides the \"S\" (security) in the HTTPS sessions used for e-commerce and cloud services that\nhandle private information, such as e-mail. RSA secures SSH sessions (used to connect to Athena,*\nfor example), and MIT certificates used to log into Stellar. You figure that the KS chip must\nperform RSA efficiently, since RSA plays such an important role in cloud security. This problem\nwill acquaint you with the encryption and decryption algorithms in RSA.\nRSA works as follows. Each user generates two large random primes p and q, and sets his public\nmodulus m = p · q. The user then chooses a small number2 e that is co-prime with (p -1)(q -1),\nand computes d = e-1 mod (p -1)(q -1). The user announces his public key (e, m) to the\nworld, and keeps d private. In order to send an encrypted message to our user, another user would\nencode the message as a number smaller than n, and encrypt it as c = E(n) = ne mod m. Our\nuser would decode the message using D(c) = cd mod m. Assume that keys can be generated\nreasonably fast and that D(E(n)) = n, for all but a negligible fraction of values of n.\n(a) [1 point] What is the running time of an implementation of D(n) that uses the KS li-\nbrary in Problem 1, with the optimized version of MULTIPLY (Karatsuba's algorithm),\nassuming that n, d and m are N-byte numbers?\n1. Θ(1)\n2. Θ(log N)\n3. Θ(N)\n4. Θ(N 2)\n5. Θ(N 2 log N)\n6. Θ(N log2 3)\n7. Θ(N log2 6)\n8. Θ(N 3)\nSolution: Θ(N log2 6), because D(n) can be computed using a single call to POWMOD.\nYou're thinking of using RSA to encrypt important sensitive images, such as last night's picture of\nyou doing a Keg stand. Formally, a picture has R × C pixels (R rows, C columns), and each pixel\nis represented as 3 bytes that are RGB color space coordinates3. The RSA key is (e, m), where m\nis an N-byte number. An inefficient encryption method would process each row of pixel data as\nfollows:\n1.Break the 3C bytes of pixel data into groups of N -1 bytes\n2.Pad the last group with 0 bytes up to N -1 bytes\n265,537 is a popular choice nowadays\n3see http://en.wikipedia.org/wiki/RGB_color_space\n*Athena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\nProblem Set 5\n3.Encrypt each group of N -1 bytes to obtain an N-byte output\n4.Concatenate the N-byte outputs\n(b) [1 point] How many calls to the RSA encryption function E(n) are necessary to\nencrypt an R × C-pixel image?\n1. Θ(1)\n2. Θ(RC)\n3. Θ(RC)\nN\n4. Θ(RN )\nC\n5. Θ(CN )\nR\nSolution: The exact number is R⌈\nC ⌉, which is Θ(RC)\nN-1\nN .\n(c) [1 point] What is the running time for decrypting an R × C-pixel image that was en-\ncrypted using the method above, using the KS library in Problem 1, with the optimized\nversion of MULTIPLY (Karatsuba's algorithm)?\n1. Θ(N)\n2. Θ(N 2)\n3. Θ(N 2 log N)\n4. Θ(N log2 3)\n5. Θ(N log2 6)\n6. Θ(RCN)\n7. Θ(RCN 2)\n8. Θ(RCN 2 log N)\n9. Θ(RCN log2 3)\n10. Θ(RCN log2 6)\n11. Θ(RN)\n12. Θ(RN 2)\n13. Θ(RN 2 log N)\n14. Θ(RN log2 3)\n15. Θ(RN log2 6)\nSolution: Θ(RCN log2 3)\nThe running time of one decryption operation is Θ(N log2 6), and decrypting the en-\ntire image requires\nlog\nΘ(RC) operations, so the total running time is Θ(RC\nN\n·N\n2 ) =\nN\nΘ(RC·N1+log\n2 ) = Θ(RCN log2 3)\nN\n.\n(d) [5 points] A fixed point under RSA is a number n such that E(n) ≡n mod m, so\nRSA does not encrypt the number at all. Which of the following numbers are fixed\npoints under RSA? (True / False)\n\nProblem Set 5\n1. 0\n2. 1\n3. 2\n4. 3\n5. m -2\n6. m -1\nSolution: 0, 1, and m -1 are fixed points.\n0e = 0 and 1e = 1 for any value of e > 0. m -1 ≡-1 mod m, and we know that\n(-1)e = -1 if e is odd. The other choices can be eliminated by choosing e = 3 and\nm = 35 = 5 · 7. 23 ≡8 mod 35, 33 ≡27 mod 35, and (35 -2)3 ≡(-2)3 ≡-8 ≡\n27 mod 35.\n(e) [5 points] What other weaknesses does the RSA algorithm have? (True / False)\n1. E(-n) ≡-E(n) mod m\n2. E(n1) + E(n2) ≡E(n1 + n2) mod m\n3. E(n1) -E(n2) ≡E(n1 -n2) mod m\n4. E(n1) · E(n2)\nE(n1 n2) mod m\n5. E(n )n2\n≡\n·\n≡E(nn2\n1 ) mod m\nSolution:\nE(-n) ≡-E(n) mod m, E(n1)\nE(n2)\nE(n1\nn2) mod m, and\nE(n )n2 ≡E(nn2\n·\n≡\n·\n1 ) mod m\nThe positive answers can be proven by using algebra on the definition of E(n). E(n1\nn ) ≡(n · n )e ≡(ne\ne\n·\n1) · (n2) ≡E(n1) · E(n2) mod m. Also, E(-n) ≡(-n)e ≡\n-(ne), because e is odd. Last,\n(n\ne)\nE(nn2\n1 ) ≡(nn2 e\ne (\nn2\n1 ) ≡n1\n·\n≡(n1) n2) ≡E(n1)\n.\nThe negative answers can be proven by counter-example. E(1) + E(1) = 2 = 8 =\n23 = E(1 + 1) for n1 = n2 = 1, e = 3 and m = 35. Similarly, E(2) -E(1) =\n23 -1 = 7 = 1 = E(2 -1).\n(f) [5 points] Amdtel plans to use RSA encryption to secretly tell Gopple when its latest\nsmartphone CPU is ready to ship. Amdtel will send one message every day to Gopple,\nusing Gopple's public key (eG, mG). The message will be NO (the number 20079\nwhen using ASCII), until the day the CPU is ready, then the message will change\nto YES (the number 5858675 when using ASCII). You pointed out to your manager\nthat this security scheme is broken, because an attacker could look at the encrypted\nmessages, and know that the CPU is ready when the daily encrypted message changes.\nThis is a problem of deterministic encryption. If E(20079) always takes the same\nvalue, an attacker can distinguish E(20079) from E(5858675). How can the problem\nof deterministic encryption be fixed? (True / False)\n1. Append the same long number (the equivalent of a string such as 'XXXPADDINGXXX')\nto each message, so the messages are bigger.\n\nProblem Set 5\n2. Append a random number to each message. All random numbers will have the\nsame size, so the receiver can recognize and discard them.\n3. Use a different encryption key to encrypt each message, and use Gopple's public\nexponent and modulus to encrypt the decryption key for each message.\n4. Use an uncommon encoding, such as UTF-7, so that the attacker will not know\nthe contents of the original messages.\n5. Share a \"secret\" key with Gopple, so that the attacker can't use the knowledge on\nGopple's public exponent and modulus.\nSolution: Appending a random number and using per-message encryption keys both\nwork, because they make the encryption output non-deterministic. All the other pro-\nposals don't change the fact that a message will always look the same after encryption,\nwhich is what the attacker uses to detect the change from NO to YES.\n\nProblem Set 5\nProblem 5-3.\n[42 points] Image Decryption\nYour manager wants to show off the power of the Knight's Shield chip by decrypting a live video\nstream directly using the RSA public-key crypto-system. RSA is quite resource-intensive, so most\nsystems only use it to encrypt the key of a faster algorithm. Decrypting live video would be an\nimpressive technical feat!\nUnfortunately, the performance of the KS chip on RSA decryption doesn't come even close to\nwhat's needed for streaming video. The hardware engineers said the chip definitely has enough\ncomputing power, and blamed the problem on the RSA implementation. Your new manager has\nheard about your algorithmic chops, and has high hopes that you'll get the project back on track.\nThe software engineers suggested that you benchmark the software using images because, after\nall, video is just a sequence of frames.\nThe code is in the rsa directory in the zip file for this problem set.\n(a) [2 points] Run the code under the python profiler with the command below, and\nidentify the method inside bignum.py that is most suitable for optimization. Look\nat the methods that take up the most CPU time, and choose the first method whose\nrunning time isn't proportional to the size of its output.\npython -m cProfile -s time rsa.py < tests/1verdict 32.in\nWarning: the command above can take 1-10 minutes to complete, and bring the CPU\nusage to 100% on one of your cores. Plan accordingly. If you have installed PyPy\nsuccessfully, you should replace python with pypy in the command above for a\n2-10x speed improvement.\nWhat is the name of the method with the highest CPU usage?\nSolution: fast mul\nThe first line in the profiler output points to\nadd\n, but the addition algorithm is\noptimal (O(N) running time, O(N) output size). The next line points to fast mul.\nPyPy's output may have\ninit\nand normalize above fast mul. These\nmethods are also implemented using optimal algorithms, so they are not good answers\nfor the question.\n(b) [1 point] How many times is the method called?\nSolution: The second line in the profiler output indicates that fast mul is called\n93496 times.\n(c) [1 point] The troublesome method is implementing a familiar arithmetic operation.\nWhat is the tightest asymptotic bound for the worst-case running time of the method\nthat contains the bottleneck? Express your answer in terms of N, the number of digits\nin the input numbers.\n1. Θ(N).\n2. Θ(N log n)\n\nProblem Set 5\n3. Θ(N log2 n)\n4. Θ(N log2 3)\n5. Θ(N 2)\n6. Θ(N log2 7)\n7. Θ(N 3)\nSolution:\nmul\nimplements multiplication using Karatsuba's algorithm. The\nrunning time for this algorithm is Θ(N log2 3).\n(d) [1 point] What is the tightest asymptotic bound for the worst-case running time of di-\nvision? Express your answer in terms of N, the number of digits in the input numbers.\n1. Θ(N).\n2. Θ(N log n)\n3. Θ(N log2 n)\n4. Θ(N log2 3)\n5. Θ(N 2)\n6. Θ(N log2 7)\n7. Θ(N 3)\nSolution:\ndiv\nuses\ndivmod\n, which implements division using New-\nton's algorithm. The asymptotic running time is the same as the running time of the\nunderlying multiplication algorithm which is Θ(N log2 3) in this case.\nWe have implemented a visualizer for your image decryption output, to help you debug your code.\nThe visualizer will also come in handy for answering the question below. To use the visualizer,\nfirst produce a trace.\nTRACE=jsonp python rsa.py < tests/1verdict 32.in > trace.jsonp\nOn Windows, use the following command instead.\nrsa jsonp.bat < tests/1verdict 32.in > trace.jsonp\nThen use Google Chrome to open visualizer/bin/visualizer.html\n(e) [6 points] The test cases that we supply highlight the problems of RSA that we dis-\ncussed above. Which of the following is true? (True / False)\n1. Test 1verdict 32 shows that RSA has fixed points.\n2. Test 1verdict 32 shows that RSA is deterministic.\n3. Test 2logo 32 shows that RSA has fixed points.\n4. Test 2logo 32 shows that RSA is deterministic.\n5. Test 5future 1024 shows that RSA has fixed points.\n6. Test 5future 1024 shows that RSA is deterministic.\n\nProblem Set 5\nSolution:\nTest 1verdict 32 shows both fixed points (the black eyes and mouth\nremain black in the encrypted image) and determinism (the rest of the face looks the\nsame, so we can guess it's the same color). In 4verdict 512, the bigger key size\nhides the fixed points.\nTest 2logo 32 shows fixed points. Although the colors are off, the encrypted image\nclearly represents the MIT logo.\nTest 5future 1024 does not shows fixed points or deterministic encryption, be-\ncause of the noise in the source image. The encrypted image looks like white noise.\n(f) [1 point] Read the code in rsa.py. Given a decrypted image of R × C pixels\n(R rows, C columns), where all the pixels are white (all the image data bytes are\n255), how many times will powmod be called during the decryption operation in\ndecrypt image?\n1. Θ(1)\n2. Θ(RC)\n3. Θ(RC)\nN\n4. Θ(RN )\nC\n5. Θ(CN )\nR\nSolution: Θ(1). RsaKey uses a dictionary to cache decryption results, so powmod\nis called at most twice: once for a \"chunk\" of pixels inside a row, and once for a\n\"chunk\" of pixels at the end of the row, which would be padded with 0s.\n(g) [30 points]\nThe multiplication and division operations in big num.py are im-\nplemented using asymptotically efficient algorithms that we have discussed in class.\nHowever, the sizes of the numbers involved in RSA for typical key sizes aren't suit-\nable for complex algorithms with high constant factors. Add new methods to BigNum\nimplementing multiplication and division using straight-forward algorithms with low\nconstant factors, and modify the main multiplication and division methods to use the\nsimple algorithms if at least one of the inputs has 64 digits (bytes) or less. Please note\nthat you are not allowed to import any additional Python libraries and our test will\ncheck this.\nThe KS software testing team has put together a few tests to help you check your code's cor-\nrectness and speed. big num test.py contains unit tests with small inputs for all BigNum\npublic methods. rsa test.py runs the image decryption code on the test cases in the tests/\ndirectory.\nYou can use the following command to run all the image decryption tests.\npython rsa test.py\nTo work on a single test case, run the simulator on the test case with the following command.\npython rsa.py < tests/1verdict 32.in > out\n\nProblem Set 5\nThen compare your output with the correct output for the test case.\ndiff out tests/1verdict 32.gold\nFor Windows, use fc to compare files.\nfc out tests/1verdict 32.gold\nWhile debugging your code, you should open a new Terminal window (Command Prompt in\nWindows), and set the KS DEBUG environment variable (export KS DEBUG=true; on Win-\ndows, use set KS DEBUG=true) to use a slower version of our code that has more consistency\nchecks.\nWhen your code passes all tests, and runs reasonably fast (the tests should complete in less than\n90 seconds on any reasonably recent computer using PyPy, or less than 600 seconds when using\nCPython), upload your modified big num.py to the course submission site. Our automated\ngrading code will use our versions of test rsa.py, rsa.py and ks primitives.py /\nks primitives unchecked.py, so please do not modify these files.\nSolution: The solution archive on the course Web site contains the staff's solution and secret test\ncases.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 6 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/8a7b5b55f10715f346bf4721878b702e_MIT6_006F11_ps6_sol.pdf",
      "content": "Introduction to Algorithms: 6.006\nMassachusetts Institute of Technology\nNovember 1, 2011\nProfessors Erik Demaine and Srini Devadas\nProblem Set 6\nProblem Set 6\nBoth theory and programming questions are due on Tuesday, November 15 at 11:59PM.\nPlease download the .zip archive for this problem set, and refer to the README.txt file for\ninstructions on preparing your solutions.\nWe will provide the solutions to the problem set 10 hours after the problem set is due. You will\nhave to read the solutions, and write a brief grading explanation to help your grader understand\nyour write-up. You will need to submit the grading guide by Tuesday, November 22, 11:59PM.\nYour grade will be based on both your solutions and the grading explanation.\nProblem 6-1.\n[30 points] I Can Haz Moar Frendz?\nAlyssa P. Hacker is interning at RenBook (人书/ 人書in Chinese), a burgeoning social network\nwebsite. She needs to implement a new friend suggestion feature. For two friends u and v (friend-\nship is undirected), the EdgeRank ER(u, v) can be computed in constant time based on the interest\nu shows in v (for example, how frequently u views v's profile or comments on v's wall). Assume\nthat EdgeRank is directional and asymmetric, and that its value falls in the range (0, 1). A user\nu is connected to a user v if they are connected through some mutual friends, i.e., u = u0 has a\nfriend u1, who has a friend u2, ..., who has a friend uk = v. The integer k is the vagueness of the\nconnection. Define the strength of such a connection to be\nk\nS(p) =\nY\nER(ui\n.\n-1, ui)\ni=1\nFor a given user s, Alyssa wants to have a way to rank potential friend suggestions according to\nthe strength of the connections s has with them. In addition, the vagueness of those connections\nshould not be more than k, a value Alyssa will decide later.\nHelp Alyssa by designing an algorithm that computes the strength of the strongest connection\nbetween a given user s and every other user v to whom s is connected with vagueness at most\nk, in O(kE + V ) time (i.e., for every pair of s and v for v ∈V \\{s}, compute the strength of the\nstrongest connection between them with vagueness at most k). Assume that the network has |V |\nusers and |E| friend pairs. Analyze the running time of your algorithm. For partial credit, give a\nslower but correct algorithm. You can describe your algorithm in words, pseudocode or both.\nSolution: For each v, wePwant to maximize S(p) for all p from s to v. This is equivalent to\nmaximizing\nP\nlog S(p) = Plog ER(ui\n1, ui), which is in turn equivalent to minimizing w(p) =\n-\n-\nlog ER(ui\n1, ui) =\nlog\n(u, v)\n-\nER(ui-1,ui). So for each edge\n, we can assign its weight as\nlog\nER(u,v) which is nonnegative. Then the problem is converted to finding the shortest path from\ns to v for all v ∈V for paths with length less than or equal to k.\n\nProblem Set 6\nTo do this, we use the modified Bellman-Ford algorithm with k iterations (see the pseudocode\nKLENGTH-BELLMAN-FORD below). During each iteration, we first check which edges need to\nbe relaxed (line 6 - 8), but only update the distances after checking all the edges (line 9 - 10). This\nensures that relaxation is only based on the distances from the previous iteration. This means after\niteration i, v .d = min{w(p) : |p| ≤i}.\nKLENGTH-BELLMAN-FORD(G, s, k)\nfor each node v ∈G .V\nv .d = inf\ns .d = 0\nfor i = 1 to k\nT = {}\nfor each edge (u, v) ∈G .E\nif v .d > u .d + w(u, v)\nT[v] = u .d + w(u, v)\nfor each v ∈T\nv .d = T[v]\nTime analysis: Initialization takes O(V ) time. Both checking and updating take O(E) time, and\nthere are k iterations. So total time is O(kE + V ).\nNote that simply using unmodified BELLMAN-FORD algorithm with k iterations does not work be-\ncause certain edge relaxation orders will find shortest paths with length greater than k in fewer than\nk iterations or even in 1 iteration. For example, in the graph below, suppose we want to find short-\nest paths with length at most 2. If we relax the edges in this order: (s, B), (B, A), (s, A), (A, t),\nafter the 1st iteration, the shortest path to t is ⟨s, B, A, t⟩which has length 3.\nSimilarly, using BFS with k iterations does not work either. Considering the same example above,\nin the second interation, B and A are in the frontier. If we check B's neighbors first and update A\nwith weight 2, when we check A's neighbors, we will update t with weight 4 but the length of this\npath is 3. The key is we need to use the distance values from the previous iteration instead of the\nnew values in the current interaiton for update.\ns\nA\nt\nB\nSimply modifying BELLMAN-FORD to keep track of the length of the current path from s to v\nand avoid relaxation if the length is greater than k does not work either. Consider the graph above\nagain, and we want to find shortest pahths with length at most 2. If we relax the edges in this\norder: (s, B), (B, A), (s, A), (A, t) and keep track of the path lengths, we will not find a path to\n\nProblem Set 6\nt. When we try to relax edge (A, t), the shortest path to A is ⟨s, B, A⟩which has length 2. The\nalgorithm will avoid update t.d because its shortest path would have length 3. So t .d remains to\nbe inf. However, the correct algorithm should return t.d = 5 through path ⟨s, A, t⟩with length 2.\nProblem 6-2.\n[30 points] RenBook Competitor\nHaving experienced RenBook and its alternatives, you've come to the conclusion that the social\nnetworking websites currently out there lack focus. You've decided to create a social network that\ncaters specifically to the algorithms-in-Python crowd. Excited about this idea, you've pitched to\nvarious investors, a few of whom have traded you a check in return for convertible debt. You're\nready to go! Now you have to implement your idea.\nThe first step is to rent a machine on the web, a task which you've easily accomplished using your\nnewly-acquired funding. The next step, however, is harder to complete: you must install a web\nserver library and all of its dependencies. Each library that you wish to install can depend on a\nnumber of other libraries, which you will have to install first. Each of those libraries can in turn\nhave its own dependencies.\nYou can try to install the libraries one-by-one and resolve the dependencies by hand, but you'd like\nto write a script that will do the work for you. Fortunately, having studied graphs in 6.006, you're\nconfident that you will be able to accomplish this task. You will need to determine which libraries\nneed to be installed and then generate the order in which the libraries will be installed so that there\nwill be no dependency problems.\nExamining the software library repository, you see that there are V total libraries, which together\nhave a total of E dependencies. The repositories enforces the rule that dependencies cannot be\ncyclic. Libraries rarely all depend on one another, so you can safely assume that E ≪V 2.\n(a) An installation order is an ordering of all the libraries such that each library's depen-\ndencies appear prior to it in the sequence. If we install each library in this sequence\nin order, we are guaranteed to avoid dependency problems. Describe in detail how to\ngenerate an installation order for the entire repository in O(V + E) time.\nSolution: Each library is represented as a vertext. For each pair of dependency such\nthat library u depends on library v, add a directed edge (u, v) in G. As G is directed\nand acyclic, we can to topological sort on G (i.e., return the vertices in increasing\norder of their finishing times in DFS) to produce the installation order. Constructing\nG takes O(V + E) time and topological sort (DFS) takes O(V + E) time. So overall\nthe running time is O(V + E).\nWe wish to install a web server library along with its dependencies. Suppose that some libraries\nare already installed on your system, and that only P libraries remain to be installed (you can\ndetermine whether a library has already been installed by performing a dictionary lookup in O(1)\ntime). Assume that the maximum number of dependencies for any given library is D.\n(b) Give pseudocode for an algorithm that generates an installation order for the non-\ninstalled libraries that are needed for installing the web server library in O(P + PD)\n\nProblem Set 6\ntime. Describe your algorithm. You may use any routine given in CLRS as a subrou-\ntine in your pseudocode, and you can use a textual description, a clarifying example,\nor a correctness proof for the description.\nSolution: Suppose that you have an unweighted graph of G = (V, E) that represents\nthe dependencies. Each vertex v ∈V represents a software library, and each edge\n(u, v) ∈E represents a dependency (v must be installed before u). Let the web server\nlibrary be called s. Perform a breadth-first search starting at s through the dependency\ngraph. At each iteration of BFS, perform a lookup in constant time to check whether\nthe nodes currently under consideration have already been installed. If you discover\nthat a node has been installed, cut the edge leading to it. You can safely do this\nbecause you know that since a library has been installed, all of its dependencies have\nalso been installed. This takes O(PD) time because we only visit vertices that are\nnot installed. We can now perform a topological sort on this new, smaller, graph. The\nonly vertices that remain (V ′) in this graph are the packages that need to be installed\n(P), and the number of edges (E′) at each node is at most D, so the running time is\nO(V ′ + E′) = O(P + PD).\nYou can also omit the BFS and do a modified topological sort that does not consider\nthe installed vertices. Below is the pseudocode.\nINSTALL-ORDER(G, s)\norder = []\nvisited = {s}\nDFS-VISIT(G, s, order, visited)\nreturn order\nDFS-VISIT(G, v, order, visited)\nfor n ∈G .adj[v]\nif n is not installed and not in visited\nAdd n to visited\nDFS-VISIT(G, n, order, visited)\nappend v to order\nProblem 6-3.\n[30 points] Rubik's Cube\nIn this problem, you will develop algorithms for solving the 2 × 2 × 2 Rubik's Cube, known as the\nPocket Cube. Call a configuration of the cube \"k levels from the solved position\" if it can reach\nthe solved configuration in exactly k twists, but cannot reach the solved configuration in any fewer\ntwists.\nThe rubik directory in the problem set package contains the Rubik's Cube library and a graphical\nuser interface to visualize your algorithm.\nWe will solve the Rubik's Cube puzzle by finding the shortest path between two configurations\n(the start and goal) using BFS.\n\nProblem Set 6\nA BFS that goes as deep as 14 levels (the diameter of the pocket cube) will take a few minutes (not\nto mention the memory needed). A few minutes is too slow for us: we want to solve the cube very\nquickly!\nInstead, we will take advantage of a fact that we saw in lecture: the number of nodes at level 7\n(half the diameter) is much smaller than half the total number of nodes.\nWith this in mind, we can instead do a two-way BFS, starting from each end at the same time, and\nmeeting in the middle. At each step, expand one level from the start position, and one level from\nthe end position, and then check to see whether any of the new nodes have been discovered in both\nsearches. If there is such a node, we can read off parent pointers (in the correct order) to return the\nshortest path.\nWrite a function shortest path in solver.py that takes two positions, and returns a list of\nmoves that is a shortest path between the two positions.\nTest your code using test solver.py. Check that your code runs in less than 5 seconds.\nSolution: The solution archive on the course Web site contains the staff's solution.\nProblem 6-4.\n[30 points] From Berklee to Berkeley\nJack Florey and his fellow hackers are planning to put a TARDIS1 on Berkeley's most symbolic\ntower. However, the company responsible for transporting the construction material mistook the\ndestination as Berklee College of Music. In order to save the extra cost of transportation back to\nBerkeley, Jack wants to help them to find the fastest route from Berklee to Berkeley. He down-\nloaded the data from the National Highway Planning Network (NHPN)2. However, as he did not\ntake 6.006 and does not know how to implement the Dijkstra's algoritm, he turns to you for help.\nThe partial code is in the dijkstra directory in the zip file for this problem set. It contains\na data directory which includes node and link text files from the NHPN. Open nhpn.nod\nand nhpn.lnk in a text editor to get a sense of how the data is stored (datadict.txt and\nformat.txt have more precise descriptions of the data fields and their meanings). The Python\nmodule nhpn.py provided contains code to load the text files into Node and Link objects. Read\nnhpn.py to understand the format of the Node and Link objects.\nIn dijkstra.py, the PathFinder object contains a source node, a destination node, and a\nNetwork object which represents the highway network with a list of Node objects. For each\nnode, node.adj contains a list of all nodes adjacent to node.\nYour task is implementing the method\nPathFinder.dijkstra(weight, nodes, source, destination)\nusing Dijkstra's algorithm. It is given a function weight(node1, node2) that returns the\nweight of the link between node1 and node2, a list of all the nodes, a source node and a\ndestination node in the network. The method should return a tuple of the shortest path from\n1Doctor Who's Time And Relative Dimension In Space\n2http://www.fhwa.dot.gov/planning/nhpn/\n\nProblem Set 6\nthe source to the destination as a list of nodes, and the number of nodes visited during\nthe execution of the algorithm. A node is visited if the shortest path of it from the source is\ncomputed. You should stop the search as soon as the shortest path to the destination is found.\nFunction distance(node1, node2) is a weight function used by the main program to\ncall the dijkstra method. It returns the distance between two NHPN nodes. Nodes come with\nlatitude and longitude (in millionths of degrees). For simplicity, we treat these as (x, y) coordinates\non a flat surface, where the distance between two points can be calculated using the Pythagorean\nTheorem.\nThe NodeDistancePair object wraps a given node and its distance which can be used as a key\nin the priority queue.\nThe Python module priority queue.py contains a min-heap based implementation of prior-\nity queue. It is augmented with a map of keys to their indices in the heap, so that the decrease key(key)\nmethod takes O(1) time to lookup the key in the priority queue.\nAfter implementing PathFinder.dijkstra(), you can run\npython dijkstra.py < tests/0boston berkeley.in\nto see the shortest distance from Boston, MA to Berkeley, CA.\nTo visualize the result, you can run the following command.\nTRACE=kml python dijkstra.py < tests/0boston berkeley.in\nOn Windows, use the following command instead:\ndijkstra kml.bat < tests/0boston berkeley.in\nThis will create two files, path flat.kml and path curved.kml. Both should be paths\nfrom Boston, MA to Berkeley, CA. path flat.kml is created using the distance function de-\nscribed earlier, and path curved.kml is created using a distance function that does not assume\nthat the Earth is flat. .kml files can be viewed using Google Maps, by putting the file in a web-\naccessible location (such as your Athena*Public directory), going to http://maps.google.\ncom and putting the URL (http://...) in the search box. Try asking Google Maps for driving\ndirections from Berklee to Berkeley to get a sense of how similar their answer is. Two sample\n.kml files path flat sol.kml and path curved sol.kml are provided in the same\ndirectory and you can check your results against the samples.\nYou can use the following command to run all the tests on your Dijkstra's implementation:\npython dijkstra test.py\nWhen your code passes all the tests and runs reasonably fast (the tests should complete in less\nthan 40s when using CPython), upload your modified dijkstra.py to the course submission\nsite. Our automated grading code will use our versions of dijkstra test.py, nhpn.py, and\npriority queue.py, so please do not modify these files.\nSolution: The solution archive on the course Web site contains the staff's solution and secret test\ncases.\n*Athena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\n\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Recitation 1 Notes: Asymptotic Complexity, Peak Finding",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/ce8348ec64dce3841ced6a9d0c9e48f2_MIT6_006F11_rec01.pdf",
      "content": "6.006 Intro to Algorithms\nRecitation 1\nSeptember 9, 2011\nAsymptotic Complexity\nThese notes aim to help you build an intuitive understanding of asymptotic notation. They are a\nsupplement to the material in the textbook, not a replacement for it.\nInformally, asymptotic notation takes a 10,000 feet view of the function's growth. For example,\nlet's look at f1(x) = x2 and f2(x) = 1.1x2 + (x1.9 + 10) sin(10x + 1.5) + 30. f2 looks a lot more\ncomplex than f1. For small values of x, the functions' graphs also look very different. However,\nif we increase the scale by 1000 times, we get a very different picture. It looks like, in the bigger\npicture of things, f1 and f2 aren't so different after all.\nf(x)\nx\nx ** 2\n1.1 * x ** 2 + (x ** 1.5 + 10) * sin(x * 10 + 1.5) + 30\n2e+07\n4e+07\n6e+07\n8e+07\n1e+08\n1.2e+08\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\nf(x)\nx\nx ** 2\n1.1 * x ** 2 + (x ** 1.5 + 10) * sin(x * 10 + 1.5) + 30\nAsymptotic notation, also known as \"big-Oh\" notation, uses the symbols O, Θ and Ω. The\nnotation, f2(x) = Θ(x2), is really misleading, because it makes it seem like Θ(x2) is a function.\nf(x) = Θ(x2) implies both a lower bound and an upper bound, as the graph below shows. The\ngraph shows a visual proof that f\n2(x) = Θ(x ), by showing that it's bounded from above by 1.2x ,\nand that it is bounded from below by 0.9x2. These two functions only differ from the function\ninside the Θ by a constant factor.\n2e+07\n4e+07\n6e+07\n8e+07\n1e+08\n1.2e+08\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\nf(x)\nx\n0.9 * x ** 2\n1.2 * x ** 2\n1.1 * x ** 2 + (x ** 1.5 + 10) * sin(x * 10 + 1.5) + 30\nΘ \"constrains\" a function both from above and from below. O only makes a statement about\nthe upper bound of a function, and Ωonly makes a statement about the function's lower bound.\nThe left graph below plots g(x) = (1 + sin( x + 1.5))x2 + x1.5 + 10\n, and proves visually that\ng(x) = O(x2). Note that we cannot say g(x) = Θ(x2), because the coefficient of x2 becomes 0\nfor some values of x, so g(x) is only bounded from below by x1.5 (g(x) = Ω(x1.5)).\n\n6.006 Intro to Algorithms\nRecitation 1\nSeptember 9, 2011\n5e+07\n1e+08\n1.5e+08\n2e+08\n2.5e+08\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\nf(x)\nx\n2.1 * x ** 2\n(1 + sin(x / 200 + 1.5)) * x ** 2 + x ** 1.5 + 10\n1e+06\n1.5e+06\n2e+06\n2.5e+06\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\nf(x)\nx\nx ** 1.4\n(1 + sin(x / 200)) * x ** 1.5 + x ** 1.4 + 10\nThe right graph above shows h(x) = (1 + sin( x + 1.5))x1.5 + x1.4 + 10\n, and proves visually\nthat h(x) = Ω(x1.4). h(x) = Θ(x1.4) because, for most values of x, the coefficient of x1.5 is\npositive, so the x1.5 term dominates the function's value.\nAsymptotic Drowning\nIn asymptotic notation, we can reduce complex functions involving logarithms, using the following\nrules.\n- log(n100) = 100 log(n) = Θ(log(n)) - constant exponents don't matter\n- log\n(n) = log(n)\nlog(5)\n= Θ(log(n))\nlog(5)\n- constant bases don't matter\nDon't confuse an exponential inside a logarithm with a logarithm inside an exponential. For\nexample:\n- nlog(5) cannot be simplified; we can get some loose bounds for it by observing that log(5) ≈\n2.3219 . . ., so n2 ≤nlog(5) ≤n3\nThe rules were extracted from the textbook, which also contains useful rules for other functions\nthat we'll meet in 6.006, such as polynomials.\nExercises\nCompute simple, tight asymptotic bounds for f(n), where f(n) is the following:\n- 1080 (the number of atoms in the universe)\n- logln 5(loglog 100 n)\n- (20n)7\n- 5log(3)n3 + 1080n2 + log(3)n3.1 + 6006\n- log\nn\nn\n\n(hint: use Stirling's approximation, n!\n√\n2πn\n)\n≈\n(N )N\ne\n\n6.006 Intro to Algorithms\nRecitation 1\nSeptember 9, 2011\nSolutions\n- 1080 (the number of atoms in the universe) is Θ(1) because there is no n in it, so it's a\nconstant (although a mighty big one)\n- logln 5(loglog 100 n) is Θ(log(log(n))) after applying the properties of logarithms\n- (20n)7 is Θ(n7), because (20n)7 = 207 × n7 = Θ(n7) (207 is a big constant factor)\n- 5log(3)n3 + 1080n2 + log(3)n3.1 + 6006 is Θ(n3.1). Eliminate the constant factors to obtain\nΘ(n3) + Θ(n2) + Θ(n3.1) + Θ(1), then observe that Θ(n3.1) dominates the sum.\n- log\nn\nn\n\nis O(n). Use the binomial identity to obtain\nn\nn\n=\nn!\n( n!)2, then apply Stirling's\napproximation\nand the logarithm properties.\n\nRecurrences\nRecurrences show up when trying to analyze the running time of divide-and-conquer algorithms.\nIn a nutshell, divide-and-conquer is a general approach that suggests breaking down big problems\ninto many smaller sub-problems that are manageable to solve, and then combining the solutions\nfor the small sub-problems to obtain the solution to the bigger problem.\n1. Divide Break a problem into smaller sub-problems\n2. Conquer Really small subproblems are easy\n3. Profit Combine answers to sub-problems\nSample Recurrence\nBinary search is the canonical example of divide and conquer. If I would be looking for the word\n\"algorithms\" in a physical dictionary (we'll need to stop using this example when e-books rule\nthe world), I would open the book right in the middle, see that the first word on the left page is\n\"minotaur\", and conclude that it's safe to ignore the right half of the book. Then I would split the\nleft half of the dictionary into two, and perhaps I would see the word \"gargantuan\". Again, I know\nI can ignore all the pages to the right of \"gargantuan\", so I'd focus on the left half of the pages.\nEventually, I will find my word, and my search will take much less time than it would if I would\ngo through each page individually.\nBinary search maps to the divide-and-conquer paradigm as follows. Suppose I am looking for\na number x in a sorted array of numbers A[1 . . . n]\n1. Divide Compare A[n]\nx\nx < A[ n]\n2 with\n. If the numbers are equal, report success. If\n2 , recurse\n(repeat the process focusing) on A[1 . . . n\n2 -1]. Otherwise, recurse on A[n + 1 . . . n]\n.\n2. Conquer If the array A is empty, x cannot be in it, so I can report failure.\n\n6.006 Intro to Algorithms\nRecitation 1\nSeptember 9, 2011\n3. Profit If I have found x, the problem is obviously solved. However, if I have not found x in\nthe half of the array that I recursed on, I need to convince myself that I'm not missing out\nby ignoring the other half of the array, and declare that x is not in A, despite the fact that I\ncompletely ignored half of its elements.\nLet T(n) be the time it takes to find x in A[1 . . . n], or give up. For simplicity, let's focus on\nthe case where x does not exist in A. Convince yourself that this uncovers the worst-case runnning\ntime for binary search.\nAssuming that making a guess takes a constant amount of time, we can write the following\nrecurrence for T(n).\nn\nT(n)\n=\nT( ) + Θ(1)\nT(1)\n=\nΘ(1)\nRemember, from the section on asymptotics, that any constant is Θ(1), so we could have used\nmore base cases, if that would have been convenient for us. We could even say that T(1) up to\nT(1000) are Θ(1), and our recurrence only works for n > 1000.\nLet's aim to guess the closed form formula for T(n). Since we're making a guess, we'll be a bit\nsloppy. Θ(1) is a constant, so we can rewrite the recurrence as T(n) = T(n) + c\n. The advantage\nof using c is that we can resist the urge of adding up the Θ(1) terms. Then we'll expand it a few\ntimes:\nn\nT(n)\n=\nT( ) + c\n2n\nT(n)\n=\nT( ) + c + c\n4n\nT(n)\n=\nT( ) + c + c + c\n8n\nT(n)\n=\nT(\n) + c + c + c + c\n...\nn\nT(n)\n=\nT(\n) + i × c\n2i\nWe can stop expanding when we hit a base case, so we want to set i such that n\n2i = 1, so that\nT( n ) = Θ(1)\nT(n) = Θ(1) + iΘ(1)\ni = log(n)\nT(n) = Θ(log(n))\n2i\n. we get\n. Using\nwe obtain\n.\nRecurrence Traps\nOne potential pitfall in a proof involving big-O notation is the fact that the notation hides infor-\nmation about the constants involved. To illustrate this problem, we shall prove that the function\nf(n) = n is O(1). The proof is by induction, with n = 1 as the base case. Clearly, f(1) = 1\nis a constant, so we can say that f(1) = O(1). The inductive step quickly follows: assume\nf(x) = O(1) for all x < n.\n\n6.006 Intro to Algorithms\nRecitation 1\nSeptember 9, 2011\nf(n)\n=\nn\n=\nn -1 + 1\n=\nf(n -1) + 1\n=\nO(1) + 1\n=\nO(1)\nWhat went wrong here?\nThe problem here occurred in the inductive step. By definition, f(n)\nis O(1) if and only if there exists some constant c such that for sufficiently large values of n,\nf(n) < c. This constant c must be the same for all values of n. When we assume that f(n -1)\nis O(1), the constant used is not the same as the constant used when we prove that that f(n) is\nO(1). The big-O notation hides the fact that the constant increases with every step of the inductive\nprocess, and is therefore not actually constant.\nTo avoid this trap, it is generally a good idea to avoid the use of big-O notation in proofs by\ninduction. It is usually a good policy to replace all uses of big-O and big-Ωwith their definitions,\npicking fixed variables to represent the constants involved. If we attempt to do this in the proof that\nf(n) is O(1), our inductive assumption becomes f(x) < c for all x < n. Therefore, the attempted\nproof that f(n) < c becomes:\nf(n)\n=\nn\n=\nn -1 + 1\n=\nf(n -1) + 1\n<\nc + 1.\nThis lets us avoid the error.\n2-D Peak Finding: Algorithm 5\nAfter class, several students asked about a variant of the peak-finding algorithm presented in Lec-\nture 1. In Lecture 1, the basic algorithm is:\n1. Find the location (r, c) that has the maximum value of in the middle column.\n2. Look at the values at locations (r, c -1) and (r, c + 1). If neither value is greater than\nthe value at (r, c), then it is a peak, so return it. Otherwise, recurse into one of the halves\ncontaining a greater value.\nThe suggested modification to the algorithm is:\n1. Treat the middle column as a one-dimensional peak problem, and find a one-dimensional\npeak (r, c) using the algorithm given in lecture.\n\n6.006 Intro to Algorithms\nRecitation 1\nSeptember 9, 2011\n2. Look at the values at locations (r, c -1) and (r, c + 1). If neither value is greater than\nthe value at (r, c), then it is a peak, so return it. Otherwise, recurse into one of the halves\ncontaining a greater value.\nThis algorithm has been implemented in the same framework as the existing algorithms. The\nimplementation can be found in the support files for this recitation, and can be run in much the\nsame way. You are encouraged to try it out on your own.\nWe begin by analyzing the efficiency of the new algorithm. Let T(m, n) denote the runtime of\nthe algorithm when run on a matrix with m rows and n columns. The number of elements in the\nmiddle column is m, so the time required to find a one-dimensional peak is O(log m). Checking\nthe two-dimensional neighbors of the one-dimensional peak requires O(1) time. The recursive\ncall reduces the number of columns to at most ⌊n/2⌋, but does not change the number of rows.\nTherefore, we may write the following recurrence relation for the runtime of the algorithm:\nT(m, n) = O(1) + O(log m) + T(m, ⌊n/2⌋).\nIntuitively, the number of rows in the problem does not change over time, so the cost per\nrecursive call is always O(1) + O(log m). The number of columns n is halved at every step, so the\nnumber of recursive calls is at most O(1 + log n). So we may guess a bound of O((1 + log m)(1 +\nlog n)). To show this bound more formally, we must first rewrite the recurrence relation using\nconstants c1, c2 > 0, instead of big-O notation:\nT(m, n) ≤c1 + c2 log m + T(m, ⌊n/2⌋).\nWe now want to show that T(m, n) ≤c3(1+log m)(1+log n). We will show this by induction.\nAssume that this is true for all n < k. We wish to show that this is also true for n = k. We may\nperform the following substitution:\nT(m, k) ≤c1 + c2 log m + T(m, ⌊k/2⌋)\n≤c1 + c2 log m + c3(1 + log m)(1 + log⌊k/2⌋)\n≤c1 + c2 log m + c3(1 + log m)(1 + log k -log 2)\n≤c1 + c2 log m + c3(1 + log m)(1 + log k) -c3(1 + log m) log 2\n≤c3(1 + log m)(1 + log k) + (c1 + c2 log m -c3(1 + log m) log 2)\nSo as long as it is possible to set c3 sufficiently high to make (c1+c2 log m-c3(1+log m) log 2) ≤\n0, we know that we will have proved the inductive step. To ensure that this is true, it is sufficient\nto set c3 = (c1 + c2)/ log 2, resulting in the following inequality:\nc1 + c2 log m -c3(1 + log m) log 2 = c1 + c2 log m -((c1 + c2)/ log 2) · (1 + log m) log 2\n= c1 + c2 log m -(c1 + c2)(1 + log m)\n= c1 + c2 log m -c1 -c1 log m -c2 -c2 log m\n= -c1 log m -c2\n≤0\n\n6.006 Intro to Algorithms\nRecitation 1\nSeptember 9, 2011\nHence, the runtime of the algorithm is O((1 + log m)(1 + log n)). This is faster than the algorithm\nseen in Lecture 1, but is it also correct?\nIf the algorithm were incorrect, how would we find a counterexample for it? We might begin\nby looking at the differences between the algorithm presented in Lecture 1, which is known to\nbe correct, and the algorithm that we are studying. In the first step, both algorithms look at the\ncentral column; one finds the maximum, and one finds a peak. A good technique for constructing\na counterexample would be to begin with a matrix in which the 1D peak found by the algorithm\nwould not be the maximum of the central column. To that end, we will start with a 5 × 5 matrix\nwith a central column satisfying that property:\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\nThe one-dimensional peak-finding algorithm will examine the very center of the matrix, and will\nrecurse on the upper half (because its neighbor to the south is strictly smaller). Therefore, it will\nfind the one-dimensional peak 2. If 2 is a two-dimensional peak, the algorithm will (correctly)\nreturn it. So if we want to construct a counterexample, 2 must have a neighbor that is strictly\ngreater. The algorithm must pick a half to recurse on; for simplicity, we force it to recurse on the\nleft:\n?\n?\n?\n?\n?\n?\n?\n?\n?\nThis will cause the algorithm to examine only the two left-most columns of the matrix. Is it possible\nto ensure that there are no peaks in those columns? Because there is a large value adjacent to this\nregion, it is:\nHence, we have an example where the algorithm will recurse into a subproblem that does not\ncontain any two-dimensional peaks. As a result, the algorithm cannot return a peak, and must\ntherefore be incorrect. This counterexample may be found in the file counter.py in the code\ndistributed with these recitation notes.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Recitation 2 Handout: Python Cost Model, Document Distance",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/fee8841bcb2074fe82d50b209444cc7f_MIT6_006F11_rec02_handout.pdf",
      "content": "6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndocdist1\ndef main():\nif len(sys.argv) != 3:\nprint \"Usage: docdist1.py filename_1 filename_2\"\nelse:\nfilename_1 = sys.argv[1]\nfilename_2 = sys.argv[2]\nsorted_word_list_1 = word_frequencies_for_file(filename_1)\nsorted_word_list_2 = word_frequencies_for_file(filename_2)\ndistance = vector_angle(sorted_word_list_1,sorted_word_list_2)\nprint \"The distance between the documents is: %0.6f (radians)\" %\ndistance\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\nreturn freq_mapping\ndef get_words_from_line_list(L):\nword_list = []\nfor line in L:\nwords_in_line = get_words_from_string(line)\nword_list = word_list + words_in_line\nreturn word_list\ndef get_words_from_string(line):\nword_list = []\ncharacter_list = []\nfor c in line:\nif c.isalnum():\ncharacter_list.append(c)\nelif len(character_list)>0:\nword = \"\".join(character_list)\nword = word.lower()\nword_list.append(word)\ncharacter_list = []\nif len(character_list)>0:\nword = \"\".join(character_list)\nword = word.lower()\nword_list.append(word)\nreturn word_list\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndef count_frequency(word_list):\nL = []\nfor new_word in word_list:\nfor entry in L:\nif new_word == entry[0]:\nentry[1] = entry[1] + 1\nbreak\nelse:\nL.append([new_word,1])\nreturn L\ndef vector_angle(L1,L2):\nnumerator = inner_product(L1,L2)\ndenominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\nreturn math.acos(numerator/denominator)\ndef inner_product(L1,L2):\nsum = 0.0\nfor word1, count1 in L1:\nfor word2, count2 in L2:\nif word1 == word2:\nsum += count1 * count2\nreturn sum\ndocdist2\nif __name__ == \"__main__\":\nimport cProfile\ncProfile.run(\"main()\")\ndef get_words_from_line_list(L):\nword_list = []\nfor line in L:\nwords_in_line = get_words_from_string(line)\nword_list.extend(words_in_line)\nreturn word_list\ndocdist3\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\ninsertion_sort(freq_mapping)\nreturn freq_mapping\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndef insertion_sort(A):\nfor j in range(len(A)):\nkey = A[j]\ni = j-1\nwhile i>-1 and A[i]>key:\nA[i+1] = A[i]\ni = i-1\nA[i+1] = key\nreturn A\ndef inner_product(L1,L2):\nsum = 0.0\ni = 0\nj = 0\nwhile i<len(L1) and j<len(L2):\n# L1[i:] and L2[j:] yet to be processed\nif L1[i][0] == L2[j][0]:\n# both vectors have this word\nsum += L1[i][1] * L2[j][1]\ni += 1\nj += 1\nelif L1[i][0] < L2[j][0]:\n# word L1[i][0] is in L1 but not L2\ni += 1\nelse:\n# word L2[j][0] is in L2 but not L1\nj += 1\nreturn sum\ndocdist4\ndef count_frequency(word_list):\nD = {}\nfor new_word in word_list:\nif new_word in D:\nD[new_word] = D[new_word]+1\nelse:\nD[new_word] = 1\nreturn D.items()\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndocdist5\ntranslation_table = string.maketrans(string.punctuation+string.\nuppercase,\n\" \"*len(string.punctuation)+string.lowercase)\ndef get_words_from_string(line):\nline = line.translate(translation_table)\nword_list = line.split()\nreturn word_list\ndocdist6\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\nfreq_mapping = merge_sort(freq_mapping)\nreturn freq_mapping\ndef merge_sort(A):\nn = len(A)\nif n==1:\nreturn A\nmid = n//2\nL = merge_sort(A[:mid])\nR = merge_sort(A[mid:])\nreturn merge(L,R)\ndef merge(L,R):\ni = 0\nj = 0\nanswer = []\nwhile i<len(L) and j<len(R):\nif L[i]<R[j]:\nanswer.append(L[i])\ni += 1\nelse:\nanswer.append(R[j])\nj += 1\nif i<len(L):\nanswer.extend(L[i:])\nif j<len(R):\nanswer.extend(R[j:])\nreturn answer\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndocdist7\ndef count_frequency(word_list):\nD = {}\nfor new_word in word_list:\nif new_word in D:\nD[new_word] = D[new_word]+1\nelse:\nD[new_word] = 1\nreturn D\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\nreturn freq_mapping\ndef inner_product(D1,D2):\nsum = 0.0\nfor key in D1:\nif key in D2:\nsum += D1[key] * D2[key]\nreturn sum\ndocdist8\ndef get_words_from_text(text):\ntext = text.translate(translation_table)\nword_list = text.split()\nreturn word_list\ndef word_frequencies_for_file(filename):\ntext = read_file(filename)\nword_list = get_words_from_text(text)\nfreq_mapping = count_frequency(word_list)\nreturn freq_mapping\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Recitation 2 Notes: Python Cost Model, Document Distance",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/53f8498e2a33f72ce2147d88e34fe760_MIT6_006F11_rec02.pdf",
      "content": "6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\nPython Cost Model\nOperators in Erik's notes, minus what was covered in lecture:\n1. list operations:\n(a) L1.extend(L2)\n(b) L2 = L1[i:j]\n(c) b = (x in L) or L.index(x) or L.find(x)\n2. tuple and str\n3. set\n4. heapq\nOther points of interest:\n1. equality checking (e.g. list1 == list2)\n2. lists versus generators\nReference: Python Cost Model . The Web site has runtime interpolation for various Python\noperations. The running times for various-sized inputs were measured, and then a least-square fit\nwas used to find the coefficient for the highest order term in the running time.\nDifference between generators and lists. A good explanation is here: http://wiki.python.\norg/moin/Generators\nDocument Distance\ndocdist1.py is a straightforward solution to the document distance problem, and docdist{2-8}.py\nshow algorithmic optimizations that improve the running time.\nWe start out by understanding the structure of the straightforward implementation, and then\nwe'll look at the changes in each of the successive versions.\ndocdist1\nWe first look at main to get a high-level view of what's going on in the program.\ndef main():\nif len(sys.argv) != 3:\nprint \"Usage: docdist1.py filename_1 filename_2\"\nelse:\nfilename_1 = sys.argv[1]\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\nfilename_2 = sys.argv[2]\nsorted_word_list_1 = word_frequencies_for_file(filename_1)\nsorted_word_list_2 = word_frequencies_for_file(filename_2)\ndistance = vector_angle(sorted_word_list_1,sorted_word_list_2)\nprint \"The distance between the documents is: %0.6f (radians)\"%distance\nThe method processes the command-line arguments, and calls word frequencies for file\nfor each document, then calls vector angle on the resulting lists. How do these methods\nmatch up with the three operations outlined in lecture? It seems like word frequencies for file\nis responsible for operation 1 (split each document into words) and operation 2 (count word fre-\nquencies), and then vector angle is responsible for operation 3 (compute dot product).\nNext up, we'll take a look at word frequencies for file.\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\nreturn freq_mapping\nThe method first calls read file, which returns a list of lines in the input file. We'll omit\nthe method code, because it is not particularly interesting, and we'll assume that read file's\nrunning time is proportional to the size of the input file. The input from read line is given\nto get words from line list, which computes operation 1 (split each document into\nwords). After that, count frequency turns the list of words into a document vector (operation\n2).\ndef get_words_from_line_list(L):\nword_list = []\nfor line in L:\nwords_in_line = get_words_from_string(line)\nword_list = word_list + words_in_line\nreturn word_list\ndef get_words_from_string(line):\nword_list = []\ncharacter_list = []\nfor c in line:\nif c.isalnum():\ncharacter_list.append(c)\nelif len(character_list)>0:\nword = \"\".join(character_list)\nword = word.lower()\nword_list.append(word)\ncharacter_list = []\nif len(character_list)>0:\nword = \"\".join(character_list)\nword = word.lower()\nword_list.append(word)\nreturn word_list\nget words from string takes one line in the input file and breaks it up into a list of\nwords. TODO: line-by-line analysis. The running time is O(k), where k is the length of the line.\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\nget words from line list calls get words from string for each line and\ncombines the lists into one big list. Line 5 looks innocent but is a big performance killer, because\nusing\nto combine W lists of length\nis\nW 2\n+\nk\nO(\n)\nk\nk\n.\nThe output of get words from line list is a list of words, like ['a', 'cat',\n'in', 'a', 'bag']. word frequencies from file passes this output to count frequency,\nwhich turns it into a document vector that counts the number of occurrences of each word, and\nlooks like [['a', 2], ['cat', 1], ['in', 1], ['bag', 1]].\ndef count_frequency(word_list):\nL = []\nfor new_word in word_list:\nfor entry in L:\nif new_word == entry[0]:\nentry[1] = entry[1] + 1\nbreak\nelse:\nL.append([new_word,1])\nreturn L\nThe implementation above builds the document vector by takes each word in the input list and\nlooking it up in the list representing the under-construction document vector. In the worst case of\na document with all different words, this takes O(W 2 × l) time, where W is the number of words\nin the document, and l is the average word length.\ncount frequency is the last function call in word frequencies for file. Next\nup, main calls vector angle, which performs operation 3, computing the distance metric.\ndef vector_angle(L1,L2):\nnumerator = inner_product(L1,L2)\ndenominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\nreturn math.acos(numerator/denominator)\nThe method is a somewhat straightforward implementation of the distance metric\narccos\nL1 · L2\n|L1||L2|\n\nL\n= arccos\n\n1 · L2\n(L1 · L1)(L2 · L2)\n!\n,\nand delegates to inner product for the hard work\np\nof computing cross products.\ndef inner_product(L1,L2):\nsum = 0.0\nfor word1, count1 in L1:\nfor word2, count2 in L2:\nif word1 == word2:\nsum += count1 * count2\nreturn sum\ninner product is a straightforward inner-product implementation that checks each each\nword in the first list against the entire second list. The nested loops at lines 3 and 4 give the\nalgorithm its running time of Θ(L1L2), where L1 and L2 are the lengths of the documents' vectors\n(the number of unique words in each document).\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndocdist1 Performance Scorecard\nMethod\nTime\nO(W 2\nget words from line list\n) = O(W 2)\nk\ncount frequency\nO(WL)\nword frequencies for file\nO(W 2)\ninner product\nO(L1L2)\nvector angle\nO(L1L2 + L2\n1 + L2\n2) = O(L2\n1 + L2\n2)\nmain\nO(W 2 + W 2)\nWe assume that k (number of words per line) is a constant, because the documents will need\nto fit on screens or paper sheets with a finite length. W (the number of words in a document)\nis ≥L (the number of unique words in a document). L2\n1 + L2\n2 + L\n1L2 = O(L1 + L2\n2) because\nL2\n1 + L2\n2 ≥L1L2. Proof (assuming L1, L2 ≥0):\n(L\n1 -L2)\n≥\nL2\n1 + L2\n2 -2L1L2\n≥\nL2\n1 + L2\n≥\n2L1L2\nL2\n1 + L2\n≥\nL1L2\ndocdist2\nThe document distance code invokes the Python profiler to identify the code that takes up the most\nCPU time. This ensures that we get the biggest returns on our optimization efforts.\nif __name__ == \"__main__\":\nimport cProfile\ncProfile.run(\"main()\")\nYou can profile existing programs without changing them by adding -m cProfile -s\nTime to Python's command line. For example, the command below will run and profile program.py.\npython -m cProfile -s time program.py\nThe profiler output for docdist1 shows that the biggest time drain is get words from line list.\nThe problem is that when the + operator is used to concatenate lists, it needs to create a new list\nand copy the elements of both its operands. Replacing + with extend yields a 30% runtime\nimprovement.\ndef get_words_from_line_list(L):\nword_list = []\nfor line in L:\nwords_in_line = get_words_from_string(line)\nword_list.extend(words_in_line)\nreturn word_list\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\nextend adds all the elements of an m-element list to an n-element list in Θ(1+m), as opposed\nto +, which needs to createP\na new list, and therefore takes Θ(1 + n + m) time. So concatenating\nW\nW lists of k elements takes\nk k = Θ(W)\nk\ntime.\ndocdist2 Performance Scorecard\nMethod\nTime\nget words from line list\nO(W)\ncount frequency\nO(WL)\nword frequencies for file\nO(WL)\ninner product\nO(L1L2)\nvector angle\nO(L2\n1 + L2\n2)\nmain\nO(W1L1 + W2L2)\ndocdist3\nProfiling docdist2 points to count frequency and inner product as good targets for op-\ntimizations. We'll speed up inner product by switching to a fast algorithm. However, the\nalgorithm assumes that the words in the document vectors are sorted. For example, [['a', 2],\n['cat', 1], ['in', 1], ['bag', 1]] needs to become [['a', 2], ['bag', 1],\n['cat', 1], ['in', 1]].\nFirst off, we add a step to word frequencies for file that sorts the document vector\nproduced by count frequency.\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\ninsertion_sort(freq_mapping)\nreturn freq_mapping\nThen we implement insertion sort using the algorithm in the textbook.\ndef insertion_sort(A):\nfor j in range(len(A)):\nkey = A[j]\ni = j-1\nwhile i>-1 and A[i]>key:\nA[i+1] = A[i]\ni = i-1\nA[i+1] = key\nreturn A\nInsertion sort runs in O(L2) time, where L is the length of the document vector to be sorted.\nFinally, inner product is re-implemented using a similar algorithm to the merging step in\nMerge Sort.\ndef inner_product(L1,L2):\nsum = 0.0\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ni = 0\nj = 0\nwhile i<len(L1) and j<len(L2):\n# L1[i:] and L2[j:] yet to be processed\nif L1[i][0] == L2[j][0]:\n# both vectors have this word\nsum += L1[i][1] * L2[j][1]\ni += 1\nj += 1\nelif L1[i][0] < L2[j][0]:\n# word L1[i][0] is in L1 but not L2\ni += 1\nelse:\n# word L2[j][0] is in L2 but not L1\nj += 1\nreturn sum\nThe new implementation runs in Θ(L1 + L2), where L1 and L2 are the lengths of the two\ndocument vectors. We observe that the running time for inner product (and therefore for\nvector angle) is asymptotically optimal, because any algorithm that computes the inner prod-\nuct will have to read the two vectors, and reading will take Ω(L1 + L2) time.\ndocdist3 Performance Scorecard\nMethod\nTime\nget words from line list\nO(W)\ncount frequency\nO(WL)\ninsertion sort\nO(L2)\nword frequencies for file\nO(WL + L2) = O(WL)\ninner product\nO(L1 + L2)\nvector angle\nO(L1 + L2)\nmain\nO(W1L1 + W2L2)\ndocdist4\nThe next iteration addresses count frequency, which is the biggest time consumer at the\nmoment.\ndef count_frequency(word_list):\nD = {}\nfor new_word in word_list:\nif new_word in D:\nD[new_word] = D[new_word]+1\nelse:\nD[new_word] = 1\nreturn D.items()\nThe new implementation uses Python dictionaries. The dictionaries are implemented using\nhash tables, which will be presented in a future lecture. The salient feature of hash tables is that\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ninserting an element using dictionary[key] = value and looking up an element using\ndictionary[key] both run in O(1) expected time.\nInstead of storing the document vector under construction in a list, the new implementation\nuses a dictionary. The keys are the words in the document, and the value are the number of times\neach word appears in the document. Since both insertion (line 5) and lookup (line 7) take O(1)\ntime, building a document vector out of W words takes O(W) time.\ndocdist4 Performance Scorecard\nMethod\nTime\nget words from line list\nO(W)\ncount frequency\nO(W)\ninsertion sort\nO(L2)\nword frequencies for file\nO(W + L2) = O(L2)\ninner product\nO(L1 + L2)\nvector angle\nO(L1 + L2)\nmain\nO(L2\n1 + L2)\ndocdist5\nThis iteration simplifies get words from string that breaks up lines into words. First off,\nthe standard library function string.translate is used for converting uppercase characters\nto lowercase, and for converting punctuation to spaces. Second, the split method on strings is\nused to break up a line into words.\ntranslation_table = string.maketrans(string.punctuation+string.uppercase,\n\" \"*len(string.punctuation)+string.lowercase)\ndef get_words_from_string(line):\nline = line.translate(translation_table)\nword_list = line.split()\nreturn word_list\nThe main benefit of this change is that 23 lines of code are replaced with 5 lines of code.\nThis makes the implementation easier to analyze. A side benefit is that many functions in the\nPython standard library are implemented in directly in C (a low-level programming language that\nis very close to machine code), which gives them better performance. Although the running time is\nasymptotically the same, the hidden constants are much better for the C code than for our Python\ncode presented in docdist1.\ndocdist5 Performance Scorecard\nIdentical to the docdist4 scorecard.\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndocdist6\nNow that all the distractions are out of the way, it's time to tackle insertion sort, which is\ntakes up the most CPU time, by far, in the profiler output for docdist5.\nThe advantages of insertion sort are that it sorts in place, and it is simple to implement.\nHowever, its worst-case running time is O(N 2) for an N-element array. We'll replace insertion\nsort with a better algorithm, merge sort. Merge sort is not in place, so we'll need to modify\nword frequencies for file.\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\nfreq_mapping = merge_sort(freq_mapping)\nreturn freq_mapping\nThe merge sort implementation closely follows the pseudocode in the textbook.\ndef merge_sort(A):\nn = len(A)\nif n==1:\nreturn A\nmid = n//2\nL = merge_sort(A[:mid])\nR = merge_sort(A[mid:])\nreturn merge(L,R)\ndef merge(L,R):\ni = 0\nj = 0\nanswer = []\nwhile i<len(L) and j<len(R):\nif L[i]<R[j]:\nanswer.append(L[i])\ni += 1\nelse:\nanswer.append(R[j])\nj += 1\nif i<len(L):\nanswer.extend(L[i:])\nif j<len(R):\nanswer.extend(R[j:])\nreturn answer\nThe textbook proves that merge sort runs in Θ(n log n) time. You should apply your\nknowledge of the Python cost model to convince yourself that the implementation above also runs\nin Θ(n log n) time.\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndocdist6 Performance Scorecard\nMethod\nTime\nget words from line list\nO(W)\ncount frequency\nO(W)\nmerge sort\nO(L log L)\nword frequencies for file\nO(W + L log L) = O(L log L)\ninner product\nO(L1 + L2)\nvector angle\nO(L1 + L2)\nmain\nO(L1 log L1 + L2 log L2)\ndocdist7\nSwitching to merge sort improved the running time dramatically. However, if we look at docdist6's\nprofiler output, we notice that merge is the function with the biggest runtime footprint. Merge\nsort's performance in practice is great, so it seems that the only way to make our code faster is to\nget rid of sorting altogether.\nThis iteration switches away from the sorted list representation of document vectors, and in-\nstead uses the Python dictionary representation that was introduced in docdist4. count frequency\nalready used that representation internally, so we only need to remove the code that converted the\nPython dictionary to a list.\ndef count_frequency(word_list):\nD = {}\nfor new_word in word_list:\nif new_word in D:\nD[new_word] = D[new_word]+1\nelse:\nD[new_word] = 1\nreturn D\nThis method still takes O(W) time to process a W-word document.\nword frequencies for file does not call merge sort anymore, and instead re-\nturns the dictionary built by count frequency.\ndef word_frequencies_for_file(filename):\nline_list = read_file(filename)\nword_list = get_words_from_line_list(line_list)\nfreq_mapping = count_frequency(word_list)\nreturn freq_mapping\nNext up, inner product makes uses dictionary lookups instead of merging sorted lists.\ndef inner_product(D1,D2):\nsum = 0.0\nfor key in D1:\nif key in D2:\nsum += D1[key] * D2[key]\nreturn sum\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\nThe logic is quite similar to the straightforward inner product in docdist1. Each word\nin the first document vector is looked up in the second document vector. However, because the\ndocument vectors are dictionaries, each takes O(1) time, and inner product runs in O(L1)\ntime, where L1 is the length of the first document's vector.\ndocdist7 Performance Scorecard\nMethod\nTime\nget words from line list\nO(W)\ncount frequency\nO(W)\nword frequencies for file\nO(W)\ninner product\nO(L1 + L2)\nvector angle\nO(L1 + L2)\nmain\nO(W1 + W2)\ndocdist8\nAt this point, all the algorithms in our solution are asymptotically optimal. We can easily prove\nthis, by noting that each of the 3 main operations runs in time proportional to its input size, and\neach operation needs to read all its input to produce its output. However, there is still room for\noptimizing and simplifying the code.\nThere is no reason to read each document line by line, and then break up each line into words.\nThe last iteration processes reads each document into one large string, and breaks up the entire\ndocument into words at once.\nFirst off, read file is modified to return a single string, instead of an array of strings. Then,\nget words from line list is renamed to get words from file, and is simplified,\nbecause it doesn't need to iterate over a list of lines anymore. Last, word frequencies for file\nis updated to reflect the renaming.\ndef get_words_from_text(text):\ntext = text.translate(translation_table)\nword_list = text.split()\nreturn word_list\ndef word_frequencies_for_file(filename):\ntext = read_file(filename)\nword_list = get_words_from_text(text)\nfreq_mapping = count_frequency(word_list)\nreturn freq_mapping\n\n6.006 Intro to Algorithms\nRecitation 2\nSeptember 14, 2011\ndocdist8 Performance Scorecard\nMethod\nTime\nget words from text\nO(W)\ncount frequency\nword frequencies for\ninner product\nO(W)\nfile\nO(W)\nO(L1 + L2)\nvector\nmain\nangle\nO(L1 + L2)\nO(W1 + W2)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Recitation 5 Handout: Recursion Trees, Binary Search Trees",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/fd8aa3260640466bd402536f41dab9ee_MIT6_006F11_rec05_handout.pdf",
      "content": "6.006 Intro to Algorithms\nRecitations 5\nSeptember 23, 2011\nBSTNode\nclass BSTNode(object):\n\"\"\"A node in the vanilla BST tree.\"\"\"\ndef __init__(self, parent, k):\n\"\"\"Creates a node.\nArgs:\nparent: The node's parent.\nk: The key of the node.\n\"\"\"\nself.key = k\nself.parent = parent\nself.left = None\nself.right = None\ndef find(self, k):\n\"\"\"Finds and returns the node with key k from the subtree\nrooted at this\nnode.\nArgs:\nk: The key of the node we want to find.\n\"\"\"\nif k == self.key:\nreturn self\nelif k < self.key:\nif self.left is None:\nreturn None\nelse:\nreturn self.left.find(k)\nelse:\nif self.right is None:\nreturn None\nelse:\nreturn self.right.find(k)\ndef find_min(self):\n\"\"\"Finds the node with the minimum key in the subtree rooted\nat this\nnode.\nReturns:\nThe node with the minimum key.\n\"\"\"\ncurrent = self\nwhile current.left is not None:\ncurrent = current.left\nreturn current\n\n6.006 Intro to Algorithms\nRecitations 5\nSeptember 23, 2011\ndef next_larger(self):\n\"\"\"Returns the node with the next larger key (the successor)\nin the BST.\n\"\"\"\nif self.right is not None:\nreturn self.right.find_min()\ncurrent = self\nwhile current.parent is not None and current is current.\nparent.right:\ncurrent = current.parent\nreturn current.parent\ndef insert(self, node):\n\"\"\"Inserts a node into the subtree rooted at this node.\nArgs:\nnode: The node to be inserted.\n\"\"\"\nif node is None:\nreturn\nif node.key < self.key:\nif self.left is None:\nnode.parent = self\nself.left = node\nelse:\nself.left.insert(node)\nelse:\nif self.right is None:\nnode.parent = self\nself.right = node\nelse:\nself.right.insert(node)\ndef delete(self):\n\"\"\"Deletes and returns this node from the BST.\"\"\"\nif self.left is None or self.right is None:\nif self is self.parent.left:\nself.parent.left = self.left or self.right\nif self.parent.left is not None:\nself.parent.left.parent = self.parent\nelse:\nself.parent.right = self.left or self.right\nif self.parent.right is not None:\nself.parent.right.parent = self.parent\nreturn self\nelse:\ns = self.next_larger()\nself.key, s.key = s.key, self.key\nreturn s.delete()\n\n6.006 Intro to Algorithms\nRecitations 5\nSeptember 23, 2011\nBST\nclass BST(object):\ndef __init__(self):\nself.root = None\ndef find(self, k):\nreturn selft.root and self.root.find(k)\ndef find_min(self):\n\"\"\"Returns the minimum node of this BST.\"\"\"\nreturn self.root and self.root.find_min()\ndef insert(self, k):\nnode = BSTNode(None, k)\nif self.root is None:\n# The root's parent is None.\nself.root = node\nelse:\nself.root.insert(node)\ndef delete(self, k):\n\"\"\"Deletes and returns a node with key k if it exists from\nthe BST.\nArgs:\nk: The key of the node that we want to delete.\n\"\"\"\nnode = self.find(k)\nif node is None:\nreturn None\nif node is self.root:\npseudoroot = BSTNode(None, 0)\npseudoroot.left = self.root\nself.root.parent = pseudoroot\ndeleted = self.root.delete()\nself.root = pseudoroot.left\nif self.root is not None:\nself.root.parent = None\nreturn deleted\nelse:\nreturn node.delete()\n\n6.006 Intro to Algorithms\nRecitations 5\nSeptember 23, 2011\ndef next_larger(self, k):\n\"\"\"Returns the node that contains the next larger (the\nsuccessor) key in\nthe BST in relation to the node with key k.\nArgs:\nk: The key of the node of which the successor is to be\nfound.\nReturns:\nThe successor node.\n\"\"\"\nnode = self.find(k)\nreturn node and node.next_larger()\nMinBSTNode\nclass MinBSTNode(BSTNode):\n\"\"\"A node in BST which is augmented to keep track of the node\nwith the\nminimum key in the subtree rooted at this node.\n\"\"\"\ndef __init__(self, parent, key):\nsuper(MinBSTNode, self).__init__(parent, key)\nself.min = self\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Recitation 5 Notes: Recursion Trees, Binary Search Trees",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/e84514204c189e45134a69289da6a40a_MIT6_006F11_rec05.pdf",
      "content": "6.006 Intro to Algorithms\nRecitation 5\nSeptember 23, 2011\nSidebar: Data Structures\nA data structure is a collection of algorithms for storing and retrieving information. The oper-\nations that store information are called updates, and the operations that retrieve information are\ncalled queries. For example, a sorted array supports the following operations:\n1. Queries: MIN(), MAX(), SEARCH(x)\n2. Updates: INSERT(x), DELETE(x)\nThe salient property of a data structure is its representation invariant (RI), which specifies\nhow information is stored. Formally, the representation invariant is a predicate which must always\nbe true for the data structure to function propertly. The query operations offered by the data struc-\nture are guaranteed to produce the correct result, as long as the representation invariant holds (is\ntrue). Update operations are guaranteed to preserve the representation invariant (if the RI holds\nbefore the update, it will also hold after the update).\nFor example, a sorted array's representation invariant is that it stores keys in an array, and the\narray must always be sorted. SEARCH is implemented using the binary search algorithm, which\ntakes O(log(N)) time. SEARCH is guaranteed to be correct if the RI holds (the array is sorted). On\nthe other hand, INSERT must preserve the RI and its running time is O(N). INSERT's worst-case\ninput is a key that is smaller than all the keys in the array, as it will require shifting all the elements\nin the array to the right.\nWhen implementing (and debugging) a data structure, it is useful to write a check ri method\nthat checks whether the representation invariant is met, and raises an exception if that is not the\ncase. While debugging the data structure, every operation that modifies the data structure would\ncall check ri right before completing. This helps you find a bug in your implementation as soon\nas it happens, as opposed to having to track it down based on incorrect query results. Because it is\nonly used during debugging, check ri can be slower than the data structure's main operations.\nFor example, checking a binary heap's representation invariant takes O(N) time, whereas the usual\nquery (MIN) and update operations (INSERT, UPDATE, EXTRACT-MIN) take O(log(N)) time.\nWhen building a software system, you should stop and think for a bit about the data structures\nthat can perform each task efficiently. Once you have some data structures in mind, you can design\nthe API (interface) between the module implementing the task and the rest of the system, in a way\nthat would allow the module to be implemented using any of the efficient data structures. Once the\nAPI is in place, you should initially choose the data structure with the simplest implementation, to\nminimize development time. If you need to optimize your system later, you will be able to switch\nin a more efficient data structure easily, because you thought of that possibility in advance, when\ndesigning the module's API.\nBinary Search Tree\nA binary search tree is a data structure that allows for key lookup, insertion, and deletion. It is a\nbinary tree, meaning every node x of the tree has at most two child nodes, a left child and a right\nchild. Each node of the tree holds the following information:\n\n6.006 Intro to Algorithms\nRecitation 5\nSeptember 23, 2011\n- x.key - Value stored in node x.\n- x.left- Pointer to the left child of node x. NIL if x has no left child.\n- x.right - Pointer to the right child of node x. NIL if x has no right child.\n- x.parent - Pointer to the parent node of node x. NIL if x has no parent, i.e. x is the root of\nthe tree.\nBinary search tree has the following invariants:\n- For each node x, every key found in the left subtree of x is less than or equal to the key found\nin x.\n- For each node x, every key found in the right subtree of x is greater than or equal to the key\nfound in x.\n\n6.006 Intro to Algorithms\nRecitation 5\nSeptember 23, 2011\nBST Operations\nThere are operations of a binary search tree that take advantage of the properties above to search\nfor keys. There are other operations that manipulate the tree to insert new keys or remove old ones\nwhile maintaining these two invariants.\nIn the lecture, we saw find(k), insert(x), find min() and find max(). They\nall have O(h) running time where h is the height of the tree. Today, we will look at two more\noperations.\nnext larger() and next smaller()\nDescription: Returns the node that contains the next larger (the successor) or next smaller (the\npredecessor) key in the binary search tree in relation to the key at node x.\nCase 1: x has a right sub-tree where all keys are larger than x.key. The next larger key will be\nthe minimum key of x's right sub-tree.\nCase 2: x has no right sub-tree. We can find the next larger key by traversing up x's ancestry\nuntil we reach a node that's a left child. That node's parent will contain the next larger key.\ndef next_larger(self):\n# Case 1:\nif self.right is not None:\nreturn self.right.find_min()\n# Case 2:\ncurrent = self\nwhile current.parent is not None and current is current.parent.right:\ncurrent = current.parent\nreturn current.parent\nAnalysis: In the worst case, next larger goes through the longest branch of the tree if x is\nthe root. Since find min can take O(h) time, next larger could also take O(h) time where\nh is the height of the tree.\n\n6.006 Intro to Algorithms\nRecitation 5\nSeptember 23, 2011\ndelete()\nDescription: Removes the node x from the binary search tree, making the necessary adjustments\nto the binary search tree to maintain its invariants. (Note that this operation removes a specified\nnode from the tree. If you wanted to delete a key k from the tree, you would have to first call\nfind(k) to find the node with key k and then call delete to remove that node.)\nCase 1: x has no children. Just delete it (i.e. change its parent node so that it doesn't point to\nx).\nCase 2: x has one child. Splice out x by linking x's parent to x's child.\nCase 3: x has two children. Splice out x's successor and replace x with x's successor.\ndef delete(self):\n\"\"\"Deletes and returns this node from the BST.\"\"\"\n# Case 1 & 2:\nif self.left is None or self.right is None:\nif self is self.parent.left:\nself.parent.left = self.left or self.right\nif self.parent.left is not None:\nself.parent.left.parent = self.parent\nelse:\nself.parent.right = self.left or self.right\nif self.parent.right is not None:\nself.parent.right.parent = self.parent\nreturn self\n# Case 3:\nelse:\ns = self.next_larger()\nself.key, s.key = s.key, self.key\nreturn s.delete()\n\n6.006 Intro to Algorithms\nRecitation 5\nSeptember 23, 2011\nAnalysis: In case 3, delete calls next larger, which takes O(h) time. At worst case,\ndelete takes O(h) time where h is the height of the tree.\nAugmented BSTs\nThe BST data structure can be easily augmented to implement new features without reinventing\nthe wheel. In the lecutre, we have seen an example of augmenting BST to find the rank of a node.\nHere, we will look at another example.\nThe find min() and find max() operations of a vanilla BST takes O(h) time. This is\nnot as good as a heap where these operations are constant time. Can we augment BST to do better?\nFor every node x, we can add a field x.min to keep track of the node with the minimum\nkey in the subtree rooted at x. So find min() just returns root.min which is constant time.\nHowever, to maintain the invariant of x.min, we need to change insert(x) and delete()\nas well.\nFor insertion, if the key of the node to be inserted is smaller than the current node's mininum,\nwe need to update the current node's minimum. Line 7 and 8 are the only addition and the cost is\nconstant time. So insertion is still O(h).\ndef insert(self, node):\nif node is None:\nreturn\nif node.key < self.key:\n# Updates the min of this node if the inserted node has a smaller\n# key.\nif node.key < self.min.key:\nself.min = node\nif self.left is None:\nnode.parent = self\nself.left = node\n\n6.006 Intro to Algorithms\nRecitation 5\nSeptember 23, 2011\nelse:\nself.left.insert(node)\nelse:\nif self.right is None:\nnode.parent = self\nself.right = node\nelse:\nself.right.insert(node)\nFor deletion, whenever a node's left child is changed, this node's minimum maybe changed\ntoo. This is because the minimum is always in the left subtree, and in the case that there's no left\nsubtree, the minimum is the node itself.\nLet x be the node to be deleted and x is a left child of its parent, then there are 2 cases:\nCase 1: after removing x, x.parent has a new left child, then x.parent.min = x.parent.left.min.\nCase 2: after remving x, x.parent has no left child, then x.parent.min = x.parent.\nAre we done? No. We need to propogate this min update up to all the parents until we reach a\nnode that is a right child because in this case its min does not affect its parent. In the worst case,\nthe propagation takes O(h) time, so deletion is still O(h).\ndef delete(self):\nif self.left is None or self.right is None:\nif self is self.parent.left:\nself.parent.left = self.left or self.right\n# Case: 1\nif self.parent.left is not None:\nself.parent.left.parent = self.parent\nself.parent.min = self.parent.left.min\n# Case: 2\nelse:\nself.parent.min = self.parent\n# Propagates the changes upwards.\ncurrent\n= self.parent\nwhile current.parent is not None and current is current.parent.left:\ncurrent.parent.min = current.min\ncurrent = current.parent\nelse:\nself.parent.right = self.left or self.right\nif self.parent.right is not None:\nself.parent.right.parent = self.parent\nreturn self\nelse:\ns = self.next_larger()\nself.key, s.key = s.key, self.key\nreturn s.delete()\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Recitation 6 Notes: AVL Trees",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/f71168c033e4cb0bd989345e478934aa_MIT6_006F11_rec06.pdf",
      "content": "6.006 Intro to Algorithms\nRecitation 6\nSeptember 28, 2011\nAVL Trees\nRecall the operations (e.g. find, insert, delete) of a binary search tree. The runtime of\nthese operations were all O(h) where h represents the height of the tree, defined as the length of\nthe longest branch. In the worst case, all the nodes of a tree could be on the same branch. In this\ncase, h = n, so the runtime of these binary search tree operations are O(n). However, we can\nmaintain a much better upper bound on the height of the tree if we make efforts to balance the tree\nand even out the length of all branches. An AVL trees is a binary search tree that balances itself\nevery time an element is inserted or deleted. In addition to the invariants of a BST, each node of\nan AVL tree has the invariant property that the heights of the sub-tree rooted at its children\ndiffer by at most one, i.e.:\n|height(node.left) -height(node.right)| ≤1\n(1)\nHeight Augmentation\nIn AVL trees, we augment each node to keep track of the node's height.\ndef height(node):\nif node is None:\nreturn -1\nelse:\nreturn node.height\ndef update_height(node):\nnode.height = max(height(node.left), height(node.right)) + 1\nEvery time we insert or delete a node, we need to update the height all the way up the ancestry\nuntil the height of a node doesn't change.\nAVL Insertion, Deletion and Rebalance\nWe can insert a node into or delete a node from a AVL tree like we do in a BST. But after this, the\nheight invariant (1) of the AVL tree may not be satisfied any more.\nFor insertion, there are 2 cases where the invariant will be violated:\n1. The left child of node x is heavier than the right child. Inserting into the left child may\nimbalance the AVL tree.\n2. The right child of node x is heavier than the left child. Inserting into the right child may\nimbalance the AVL tree.\nFor deletion, the cases are analogous.\nSo we need to reblance the tree to maintain the invariant, starting from the node inserted or the\nparent of the deleted node, and continue up.\nThere are two operations needed to help balance an AVL tree: a left rotation and a right rotation.\nRotations simply re-arrange the nodes of a tree to shift around the heights while maintaining the\n\n6.006 Intro to Algorithms\nRecitation 6\nSeptember 28, 2011\norder of its elements. Making a rotation requires re-assigning left, right, and parent of\na few nodes, and updating their heights, but nothing more than that. Rotations are O(1) time\noperations.\ndef rebalance(self, node):\nwhile node is not None:\nupdate_height(node)\nif height(node.left) >= 2 + height(node.right):\nif height(node.left.left) >= height(node.left.right):\nself.right_rotate(node)\nelse:\nself.left_rotate(node.left)\nself.right_rotate(node)\nelif height(node.right) >= 2 + height(node.left):\nif height(node.right.right) >= height(node.right.left):\nself.left_rotate(node)\nelse:\nself.right_rotate(node.right)\nself.left_rotate(node)\nnode = node.parent\nNote that rebalance includes upate height as well.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Recitation 7 Notes: Comparison Sort, Counting and Radix Sort",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/cb7df5fee9cb62e0810616491cdd1194_MIT6_006F11_rec07.pdf",
      "content": "6.006 Introduction to Algorithms\nRecitation 7\nSeptember 30, 2011\nSort Stability\nA sorting algorithm is stable if elements with the same key appear in the output array in the same\norder as they do in the input array. That is, it breaks ties between two elements by the rule that\nwhichever element appears first in the input array appears first in the output array. Normally, the\nproperty of stability is important when satellite data are carried around with the element being\nsorted. For example, in order for radix sort to work correctly, the digit sorts must be stable.\nCounting Sort\nCounting sort is an algorithm that takes an array A of n elements with keys in the range {1, 2, ...,\nk} and sorts the array in O(n + k) time. It is a stable sort.\nIn the lecture, we have seen one implementation of counting sort. Here we will show another\none mentioned in the text book (CLRS).\nIntuition: Count key occurrences using an auxiliary array C with k elements, all initialized\nto 0. We make one pass through the input array A, and for each element i in A that we see, we\nincrement C[i] by 1. After we iterate through the n elements of A and update C, the value at\nindex j of C corresponds to how many times j appeared in A. This step takes O(n) time to iterate\nthrough A.\nOnce we have C, we can construct the sorted version of A by iterating through C and inserting\neach element j a total of C[j] times into a new list (or A itself). Iterating through C takes O(k)\ntime.\nThe end result is a sorted A and in total it took O(n + k) time to do so.\nHowever this does not permute the elements in A into a sorted list and is not stable yet. If A\nhad two 3s for example, there's no distinction which 3 mapped to which 3 in the sorted result. We\njust counted two 3s and arbitrarily stuck two 3s in the sorted list. This is perfectly fine in many\ncases, but you'll see later on in radix sort why in some cases it is preferable to be able to provide a\npermutation that transforms A into a sorted version of itself.\nMake it stable:\nWe continue from the point where C is an array where C[j] refers to how\nmany times j appears in A. We transform C to an array where C[j] refers to how many elements\nare ≤j. We do this by iterating through C and adding the value at the previous index to the value\nat the current index, since the number of elements ≤j is equal to the number of elements ≤j -1\n(i.e. the value at the previous index) plus the number of elements = j (i.e. the value at the current\nindex). The final result is an array C where the value of C[j] is the number of elements ≤j in A.\n\n6.006 Introduction to Algorithms\nRecitation 7\nSeptember 30, 2011\nNow we iterate through A backwards starting from the last element of A. For each element i\nwe see, we check C[i] to find out how many elements are there ≤i. From this information, we\nknow exactly where we can put i in the sorted array. Once we insert i into the sorted array, we\ndecrement C[i] so that if we see a duplicate element, we know that we have to insert it right before\nthe previous i. Once we finish iterating through A, we will get a sorted list as before. This time, we\nprovided a mapping from each element A to the sorted list. Note that since we iterated through A\nbackwards and decrement C[i] every time we see i. we preserve the order of duplicates in A. That\nis, if there are two 3s in A, we map the first 3 to an index before the second 3. This now makes\ncounting sort stable. We will need the stability of counting sort when we use radix sort.\nIterating through C to change C[j] from being the number of times j is found in A to being\nthe number of times an element ≤j is found in A takes O(k) time. Iterating through A to map\nthe elements of A to the sorted list takes O(n) time. Since filling up C to begin with also took\nO(n) time, the total runtime of this stable version of counting sort is O(n + k + n) = O(2n + k) =\nO(n + k).\nRadix Sort\nExample\n\n6.006 Introduction to Algorithms\nRecitation 7\nSeptember 30, 2011\nIs Heap Sort Stable?\nNo. An example of heap sorting {2, 1, 2} can illustrate the point.\nIs Merge Sort Stable?\nMerge sort can be stable as long as the merge operaion is implemented properly.\nIs the merge sort in docdist6 stable?\ndef merge_sort(A):\nn = len(A)\nif n==1:\nreturn A\nmid = n//2\nL = merge_sort(A[:mid])\nR = merge_sort(A[mid:])\nreturn merge(L,R)\ndef merge(L,R):\ni = 0\nj = 0\nanswer = []\nwhile i<len(L) and j<len(R):\nif L[i]<R[j]:\nanswer.append(L[i])\ni += 1\nelse:\nanswer.append(R[j])\nj += 1\nif i<len(L):\nanswer.extend(L[i:])\nif j<len(R):\nanswer.extend(R[j:])\nreturn answer\nNo, due to the comparison at line 15. If two elements are equal, the element on the right will be\nput first in the merged array which changes the original ordering. If we change it to L[i]≤R[j],\nit will be stable.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n6.006 Introduction to Algorithms\nFall 2011\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}