{
  "course_name": "Multithreaded Parallelism: Languages and Compilers",
  "course_description": "The topics covered in this course include:\n\nLanguages and compilers to exploit multithreaded parallelism\nImplicit parallel programming using functional languages and their extensions\nHigher-order functions, non-strictness, and polymorphism\nExplicit parallel programming and nondeterminism\nThe lambda calculus and its variants\nTerm rewriting and operational semantics\nCompiling multithreaded code for symmetric multiprocessors and clusters\nStatic analysis and compiler optimizations\n\nThis course is worth 4 Engineering Design Points.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Programming Languages",
    "Software Design and Engineering",
    "Theory of Computation",
    "Engineering",
    "Computer Science",
    "Programming Languages",
    "Software Design and Engineering",
    "Theory of Computation"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nOverview\n\nHere is a brief list of topics that will be covered in the course:\n\nLanguages and compilers to exploit multithreaded parallelism.\n\nImplicit parallel programming using functional languages and their extensions.\n\nHigher-order functions, non-strictness, and polymorphism.\n\nExplicit parallel programming and nondeterminism.\n\nThe lambda calculus and its variants.\n\nTerm rewriting and operational semantics.\n\nCompiling multithreaded code for symmetric multiprocessors and clusters.\n\nStatic analysis and compiler optimizations.\n\nGrading\n\nThere are three items that contribute to the final grade: problem sets, a midterm examination, and a course project. Each of them will be counted in according to the following table:\n\nProblem Sets 50%\n\nMidterm Exam 25%\n\nCourse Project 25%\n\nHomework\n\nYour grade will be based entirely on homework assignments. We expect to hand out 4 problem sets, and you'll have 1.5 to 2 weeks to complete each one. Homework problems will be graded by students. Each student in the class will be responsible for grading two problems of a problem set during the term (extra problems will be graded by the TAs). The grader for a particular problem will automatically receive maximum credit for that problem. Graders for a problem set will be selected shortly before that problem set is due. If you wish to grade a particular problem set problem, send email to the TA's a week in advance of the due date. The grader for a problem will be chosen at random from among the volunteers. If no one volunteers for a particular problem, a student who hasn't graded yet will be randomly chosen. As a grader, you are responsible for setting up a meeting with the TA's within a day or two after the problem set due date. You'll go over the problem with them in detail and receive the stack of student solutions. Then, one week after the problem set is due you will be responsible for returning the graded problem sets to the TAs along with a solution and a grade tabulation. The TA's will explain this process in more detail when you meet with them. To facilitate the grading process, we ask that each numbered homework problem be turned in as a separate packet. Most problems will have several lettered parts. Each part will receive a check (correct and satisfactory), a check plus (outstanding), a check minus (unsatisfactory), or a zero (not turned in or indecipherable).\n\nCollaboration and Academic Honesty Policy\n\nFor problem sets, students are encouraged to collaborate in groups of up to 3 people. A group needs to hand in only one copy of the solution to a problem set. Groups need not remain the same throughout the course. We only need to know the names of the people who worked together on a particular problem set submission. Students in different groups are not allowed to collaborate on a problem set. Furthermore, it is explicitly forbidden to refer to previous years' problem sets and solutions (course bibles).\n\nCourse Reading Materials\n\nNikhil, Rishiyur S., and Arvind.\nImplicit Parallel Programming in pH\n. 1st ed. Boston, MA: Morgan-Kaufmann, 2001. ISBN: 1558606440.\n\nFacilities\n\nProgramming assignments for the course will be implemented in two programming languages: pH (parallel Haskell) and Hugs.",
  "files": [
    {
      "category": "Resource",
      "title": "ps1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/49cf4e3b6bdb1f95d78639a5076a7030_ps1.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.827\nMultithreaded Parallelism: Languages and Compilers\nProblem Set 1\nPlease Remember: 1) You can work in groups of up to three people; include the names of all\ngroup members on all problems. 2) Turn in the answer to each problem as a separate packet. 3)\nComment your code carefully and include output from sample runs.\nProblem 1\nNumerical Integration\nThis problem is intended to make you comfortable programming in functional languages, namely\nHaskell. The choice of the programming environment is entirely up to you - you can take a look at\nhttp://www.haskell.org/implementations.html\nand choose whatever you like. We recommend that you download and install The Haskell Interpreter\nHugs available from\nhttp://www.haskell.org/hugs/\nIn order to make sure things work correctly, type the following excerpt as seen in Lecture 2 and\nsave it as test.hs in your home directory:\napply_n f n x = if n==0 then x\nelse apply_n f (n-1) (f x)\nplus a b = apply_n ((+) 1) b a\nmult a b = apply_n ((+) a) b 0\nexpon a b = apply_n ((*) a) b 1\nthen run hugs and load the file by typing\n:load test.hs\n\n6.827\nProblem Set 1\nYou can now call one of the functions you have just specified by typing\nplus 3 4\n(Obviously, you should obtain 7).\nNow, back to the problem set. In this first problem, we examine two simple algorithms for numerical\nintegration based on Simpson's rule.\nPart a:\nGiven a function f and an interval [a, b], Simpson's rule says that the integral can be approximated\nas follows:\nI = h\n3 [f (a) + 4f (a + h) + f (a + 2h)]\nwhere\nh = b - a\nFor better accuracy, the interval of integration [a, b] is divided into several smaller subintervals.\nSimpson's rule is applied to each of the subintervals and the results are added to give the total\nintegral. If the subintervals of [a, b] are all of the same size p, where p = 2h, then we have the\nComposite Strategy for integration.\nWrite a Haskell program containing a function\ncomposite_strategy f a b n\nwhere\nf is the function to integrate\na,b are the endpoints of the integration interval\nn is the number of subintervals such that h = (b - a)/2n\nIntegrate some simple functions and try different values for n.\nPart b:\nIf the subintervals of the integration are not all equal and can be changed as required, then we obtain\nan Adaptive Strategy for integration. A simple adaptive integration algorithm can be described as\nfollows:\n1. Approximate the integral using Simpson's rule over the entire interval [a, b]. Call this approx\nimation old approx.\n\n6.827\nProblem Set 1\n2. Compute the midpoint x of the interval: x = (b + a)/2.\n3. Approximate a new interval by applying Simpson's rule to the subintervals [a, x] and [x, b]\nand add the two results. Call this approximation new approx.\n4. If the absolute value of the difference between new approx and old approx is within some limit\nsigma then return new approx.\n5. Otherwise, apply the adaptive strategy recursively to each of the subintervals, add the two\nresults, and return the sum as the answer.\nWrite a Haskell program that contains the function\nadaptive_strategy f a b sigma\nMake sure adaptive strategy takes advantage of the parallelism available in the algorithm. Try\nintegrating several functions while varying the sigma parameter.\nPart c:\nHow do the algorithms vary in complexity? Compare the accuracy of the answers. What factors\naffect the execution time and efficiency of the two strategies?\nProblem 2\nUsing λ combinators\nThe next two problems on this problem set focus on the pure λ-calculus. We recommend that you\ntake a look at the pH Book, Appendix A, before you move on with this problem set. The idea is\nto become comfortable with the reduction rules used, and with the important differences between\nsome of the reduction strategies which can be used when applying those rules.\nIn this problem, we shall write a few combinators in the pure λ-calculus to get familiar with the\nrules of λ-calculus. Here are the definitions of some useful combinators.\nTRUE\n=\nFALSE =\nCOND\n=\nFST\n=\nSND\n=\nPAIR\n=\nn\n=\nSUC\n=\nPLUS\n=\nMUL\n=\nλx.λy.x\nλx.λy.y\nλx.λy.λz.x y z\nλf.f TRUE\nλf.f FALSE\nλx.λy.λf.f x y\nλf.λx.(f n x)\nλn.λa.λb.a (n a b)\nλm.λn.m SUC n\nλm.λn.m (PLUS n) 0\nNow, write the λ-terms corresponding to the following functions.\n- The boolean AND function.\n\n6.827\nProblem Set 1\n- The boolean OR function.\n- The boolean NOT function.\n- The exponentiation function (EXP). You should write two expressions, one using MUL and\nthe other without MUL (note: don't eliminate MUL by substituting the body of the MUL\ncombinator into your first definition--MUL only \"stands for\" its definition in the first place,\nso you've done nothing).\n- The function ONE? which tests whether the given number is 1. (Hint: use the data structure\ncombinators. Don't try to construct a lambda term from whole cloth.)\n- The function PRED which subtracts 1 from the given number. You may decide what to do\nwhen 0 is passed as an argument to PRED. (Extra credit: can you come up with a term T\nfor which (SUC T) reduces to 0? If so, give the term; if not, explain why.)\nIn addition to the given combinators, you are free to define any others which you think would be\nuseful.\nProblem 3\nEvaluation strategies for the λ calculus\nIn lecture, Prof. Arvind discussed interpreters for the λ calculus, and gave two examples: call-by-\nname, written cn(E), and call-by-value, written cv(E). We consider both of these interpreters to\nbe finished when they return an answer in Weak Head Normal Form. In this problem, we're going\nto look at similar interpreters which yield answers in β normal form--that is, an expression which\ncannot possibly be β-reduced anymore.\nPart a:\nFirst, consider the applicative order λ-calculus. Here, we pursue a leftmost innermost strategy\n(choose the leftmost redex, or the innermost such redex if the leftmost redex contains a redex).\nReduce the following term, step by step, using this strategy. You will probably want to parenthesize\nthe term fully before you decide which redex is innermost (remember if two redexes are equally far\n\"in\" when fully parenthesized, you must choose the leftmost one).\n(λx.λy.x) (λz.(λx.λy.x) z ((λx.z x)(λx.z x)))\nPart b:\nWrite an interpreter, li(E), for the applicative order λ-calculus. Your answer should be similar to\nthe call-by-value interpreter from class.\nPart c:\nNow consider the normal order λ-calculus. It should yield answers in normal form by using a\nleftmost outermost strategy (choose the leftmost redex, making sure it's the outermost if several\n\n6.827\nProblem Set 1\nredexes are nested). Using this strategy, reduce the following term:\n(λx.λy.x) (λz.(λx.λy.x) z ((λx.x x)(λx.x x)))\nPart d:\nWrite a normal order interpreter lo(E). Your answer should work in a manner similar to the call-by-\nname interpreter from class, though it will require a more elaborate set of rules. Hint: you'll prob\nably want to use two slightly different sets of mutually recursive reduction rules. If you're having\ntrouble, figure out what your interpreter does with the term (λy.λz.y ((λx.x x)(λx.x x))) (λx.λy.y).\nPart e:\nWhat happens when you run li on the term from part c? Is the applicative order λ-calculus strongly\nnormalizing?\nProblem 4\nRecursion and confluence in λ and λlet\nConsider the following very simple term in the λ calculus with let bindings:\nlet g = λx. g (g x);\nin g (λx. x)\nThis term uses binding to set up a simple recursive function definition. In this problem we will\nexamine how such a term might be represented in λ calculus. In doing so, we'd like to develop an\nintuition about why non-confluence might break down in let-bound calculi.\nPart a:\nUsing instantiation, give two reductions of the above term which are not confluent--that is, they\ncan never be brought back together. Argue why they must always remain distinct.\nPart b:\nWe can translate the above term into λ calculus, yielding the following term; note how the subterms\nof the original term are kept intact:\n(λg. g (λx. x)) ((λg. (λx. g (x x)) (λx. g (x x))) (λg. λx. g (g x)))\nGive a translation for the two terms in the previous exercise, again preserving the right-hand sides\nof let bindings and the \"in\" part of the block.\nPart c:\nCan the above translation of the initial term be reduced to your translation of either of the other\ntwo terms in the λ calculus without let binding? If so, give the reduction. If it cannot, argue why\n\n6.827\nProblem Set 1\nsuch a translation should not be possible or give an alternative translation for which it will be\npossible.\nPart d:\nCan the translation of your two terms be brought together in the λ calculus? If so, show the reduc\ntions for each term. If not, explain why it would be impossible or give an alternative translation\nfor which it is possible."
    },
    {
      "category": "Resource",
      "title": "ps2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/0493da886fbcd7c6b1cb9283f8e561ad_ps2.pdf",
      "content": "--\n--\nMassachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.827\nMultithreaded Parallelism: Languages and Compilers\nProblem Set 2\nIn this problem set you will be making use of the pH compiler in order to run some simple pH\ncode. Because the pH compiler produces standalone executables, however, you're going to need\nto provide a main function which will be executed when the program starts up. Here's a simple\nexample:\nFile fact.hs (.hs is the standard Haskell suffix):\na Haskell factorial program\nfact :: Integer -> Integer\nfact 0 = 1\nfact n = n * fact (n - 1)\nThe main function designates what the program will output.\nmain = print (fact 5) >>\nprint (fact 15) >>\nprint (fact 27)\nYou can print arbitrary numbers of lines of output by separating them using the (>>) operator as\nshown above. Many of the problems will ask you to turn in working code which uses a standard\nmain function so that we can automate testing; in the mean time, however, you are welcome to\nuse any main function you like to test and debug your code. Note that you can only print values\nwhich are printable; in particular, functions can't be printed, and types declared with a data\ndeclaration will only be printable if you include a deriving (Text) declaration at the end of the\ndata declaration. See the Haskell manual in your reading packet for more details, but note that\nthe classes Read and Show are bundled together into Text in the pH compiler (due, ironically, to\nthe compiler-dependent nature of the deriving construct).\nLater on you may discover that you'd like to get at intermediate results in your code to ensure that\nthey're correct. There's no officially-defined way to do this; however, every Haskell implementation\nprovides a Trace construct, and pH is no exception:\ntrace :: String -> a -> a\nWhen invoked, trace prints its first argument and returns its second argument. You can use\nshow to convert printable objects into strings for trace. The dollar sign operator $ represents\nright-associative function application (that's backwards from the usual application) and provides a\nhandy way to insert traces unobtrusively:\nfact 0 = 1\nfact n = trace (\"fact invoked at \"++show n) $\nn * fact (n - 1)\n\n6.827\nProblem Set 2\nIn order to invoke the pH compiler, you'll need to use the makefile contained in /mit/6.827/ps\ndata/Makefile-pH. To do that, you first need to add lockers 6.827 and gnu. Thus, if the above\nexample were in a file named fact.hs, we'd invoke the compiler as follows:\ngmake -f /mit/6.827/ps-data/Makefile-pH fact\nThe 6.827 locker contains a script called phc which will run this command; alternatively, it should\nbe easy to set up an alias for it in your Athena dotfiles. The above makefile will build a .c file and\nthen compile that to a .o file, then produce an executable.\nThe pH compiler on Athena is only built for Sun workstations and can be slow to compile and run,\nso we suggest you do your work on Sun Ultras. If the slowness becomes a real problem, you have\nthe option of using the Hugs and HBC Haskell compilers, which are installed in the 6.827 locker\n(and available from www.haskell.org). This will only work for the simple problems on this problem\nset which are just to get you familiar with programming in Haskell. Later problem sets will require\npH mechanisms which you cannot get with Hugs or HBC.\nFinally, if you edit your Haskell programs in Emacs, you may find the elisp files in\n/mit/6.827/emacs-files/ to be helpful. They define Haskell modes which help you format your\nprograms by tabbing over the right amounts and matching parentheses for you. These files are also\nlinked from the course home page under \"Support Files.\" To use a module, add a line like this to\nyour .emacs file:\n;; Haskell\n(load \"/afs/athena/course/6/6.827/emacs-files/glasgow-haskell-mode.el\")\nPlease Remember: 1) You can work in groups of up to three people; include the names of all\ngroup members on all problems. 2) Turn in the answer to each problem as a separate packet. 3)\nComment your code carefully and include output from sample runs.\nProblem 1\nBasic Hindley-Milner typechecking\nThis problem focuses on basic Hindley-Milner typechecking, without overloading. We begin with a\nfew \"finger exercises\", where you're asked to find the types of some simple little programs. We then\ngo on to try and demonstrate what Hindley-Milner typing cannot do. Finally, there are function\ntypes for which only a few possible functions can be defined. We show you a few such types, and\nask you to come up with corresponding functions.\nSome things to remember as you go along:\n- → is right-associative; that means you read a → b → c as a → (b → c).\n- Tuples typecheck analogously to →.\n- We read types in their most general form; thus when we write a → b we really mean\n∀a.∀b.a → b.\n\n6.827\nProblem Set 2\n- Watch out for non-generic type variables! If we write a type scheme with all its ∀'s in place,\nnon-generic type variables are not quantified. This is why you're asked to indicate them\nspecially in Part a.\nPart a:\nGive the Hindley-Milner types for the following functions. Assume for the moment that all arith\nmetic operations take arguments of type Int and that all comparisons return results of type Bool.\nIn the last part, give types for result and n_again as well--but distinguish the generic and non-\ngeneric type variables:\ndet a b c = (b * b) - 4 * a * c\nstep (a,b) = (b,b+1)\nloopy x = loopy x\nrepeat n f x =\nif (n==0) then\nx\nelse\nrepeat (n-1) f (f x)\nsum f n =\nif (n<0) then\nelse\nsum f (n-1) + f n\nsumSum f n = sum (sum f) n\ndecrement n =\nlet (result, n_again) = repeat n step (-1,0)\nin\nresult\nPart b:\nHere are some simple terms which do not typecheck. Explain why.\nf x = if x then x+3 else x*2\nr g x y = if (g x) then\ng y\nelse\n2+(g y)\ns g =\nlet h x = g (g x)\nin\nh (h 3, h 4)\n\n6.827\nProblem Set 2\nfix f =\nlet func x = f (x x)\nin func func\nPart c:\nGiven a function type, there are often only a few functions we can define which have that type.\nFor example, we can only write one function which has the type a → a:\nident x = x\nNotice that there is another function, loopy, which actually has a more general type (which you\nfound in the last exercise):\nloopy x = loopy x\nTry to come up with functions which have the following types. Be careful not to give functions\nwhose types are too general! A few of them have several possible answers; you only need to give\none.\n1. a → Int\n2. (a, b) → (b, a)\n3. a → b → a\n4. a → b → b\n5. (b → c) → (a → b) → a → c\n6. (a → b → c) → b → a → c\n7. (a → b → c) → (a, b) → c\n8. (a → c) → (b → d) → (a, b) → (c, d)\nProblem 2\nTypechecking using the class system\nNow that you understand Hindley-Milner typechecking, it's time to add overloading. Some of the\n\"finger exercises\" use the same code; your answers will be different in the presence of overloading,\nhowever.\nYou should assume the following declarations (which are a subset of Haskell's functionality). Actual\ncode for the operations has been omitted for brevity (and because they're all primitives anyhow).\n\n6.827\nProblem Set 2\nclass Eq a where\n(==) :: a -> a -> Bool\nclass (Eq a) => Num a where\n(+), (-), (*) :: a -> a -> a\nclass Bounded a where\nminBound, maxBound :: a\ninstance Eq Bool\n...\ninstance Eq Int\n...\ninstance Eq Float\n...\ninstance Num Int\n...\ninstance Num Float\n...\ninstance Bounded Bool\n...\ninstance Bounded Int\n...\nNote that in Haskell numeric constants are overloaded; for the purposes of this exercise, assume\nwhole number constants such as 5 can have any numeric type (so 5 :: (Num a) => a), and floating-\npoint constants have type Float. (The real situation is a bit more complicated in both cases.) Make\nthe contexts you write as small as possible; the context (Eq a, Num a) is equivalent to the smaller\n(Num a). Finally, don't eliminate a context like (Num a, Bounded a) by rewriting a as Int; you\nshould assume other members of these classes exist (they do).\nPart a:\nGive Haskell types for the following functions.\ndet a b c = (b * b) - 4 * a * c\nrepeat17 n f =\nif (n==0) then\n\n6.827\nProblem Set 2\nelse\nf (repeat (n-1) f)\nspin x y = if x==y then 5\nelse 2.7\nalleq a b c = if a==b then a==c\nelse False\nsimilar a b c = if a==b then a==c\nelse c\nr g x y = if (g x) then\nx==3\nelse\ny*2==minBound\nPart b:\nHere are some simple terms which do not typecheck. Explain why.\nd a b = (a + minBound) * 0.5\nf x = if minBound==maxBound then x else x+3\nProblem 3\nProgramming with Maps and Folds\nHigher order functions are one of the key features of Haskell and pH, and they permit writing very\nconcise programs. In this problem, you are to write all your solutions using a combination of the\nfunctions map, foldl, and foldr, plus some of your own functions. This style of programming may\nbe foreign to some of you, so don't be afraid to ask questions!\nThere is boilerplate code for problem 3 in /mit/6.827/ps-data/ps2-3.hs. You should turn in\nyour code using the boilerplate (and it should run without error when you do so). Naturally, you\nmay use other main functions as you go in order to debug your work.\nPart a:\nWrite a function remdups to remove adjacent duplicate elements from a list. For example,\nremdups [1,2,2,3,3,3,1,1] = [1,2,3,1]\nUse foldl or foldr to define remdups.\nPart b:\nWrite a function squaresum to compute the sum of the squares of the integers from 1 to n. For\nexample,\n\nX\n6.827\nProblem Set 2\nsquaresum 3 = 14\nPart c:\nWrite a function capitalize which capitalizes the first character of every word in a string. Re-\nmember a String in Haskell and pH is simply a type synonym for [Char]. Assume the strings you\nwill be given consist of letters, spaces, and punctuation marks. Note that if you import Char at\nthe top of your program you can use the Haskell functions isUpper, isLower, and toUpper.\ncapitalize \"hello, there\" = \"Hello, There\"\nPart d:\nThe mathematical constant e is defined by:\ne =\nn!\nn≥0\nWrite down an expression that can be used to evaluate e to some reasonable accuracy.\nNote: Parts of this problem can be found in Richard Bird and Philip Wadler, \"Introduction to\nFunctional Programming\".\nProblem 4\nPolynomials\nIn this problem, we'll be looking at operations on polynomials of one variable. A polynomial will be\nrepresented as a list of tuples such that each tuple represents a term. The first element of each tuple\nis the coefficient of the term and the second element is the exponent. For example, the polynomial\n1 - 6x 5 + 4x\nis represented with the list:\n[(1,0),(-6,5),(4,9)]\nNotice that the elements of the list are sorted in order of increasing exponent. Throughout this\nproblem, your functions should maintain this invariant. Use the following type synonym to simplify\nyour code:\ntype Poly = [(Int,Int)]\nThere's boilerplate in /mit/6.827/ps-data/ps2-4.hs.\nPart a:\nImplement a function addPoly that sums two polynomials. Here's a template for addPoly:\n\n6.827\nProblem Set 2\naddPoly :: Poly -> Poly -> Poly\naddPoly p1 p2 = <your code here>\nThe type inference algorithm can deduce the type of addPoly without the type declaration. Still,\nadding explicit type signatures is a sound software-engineering technique.\nPart b:\nImplement the function mulPoly that multiplies two polynomials. Make sure to remove terms\ncontaining zero coefficients and make sure to maintain the sorted order invariant.\nPart c:\nImplement a function evalPoly ::\nPoly -> Int -> Int that evaluates a polynomial at a par\nticular value. You'll probably want to use the ^ exponentiation operator.\nProblem 5\nList Comprehensions\nPart a:\nTo get you started with list comprehensions, we'll work on the example in Section 6.4.2 of the pH\nbook. This section presents an interesting application of list comprehensions as a database query\nlanguage, similar to SQL (Structured Query Language).\nWrite a query that finds the names of all strongmen who toppled someone of the other side.\nWrite a function predecessor using list comprehensions that, given a strongman's codename,\nreturns the codename of the strongman he toppled.\nUse predecessor to write predecessors: a function that, given a strongman's codename, returns\na list of all the strongmen that came before him.\nPart b:\nThe classic Eight Queens chess puzzle is the focus of this part of the problem. Given a chessboard\nand eight queens, the goal is to place the queens on the board so that no two queens are in check.\nSince queens can move arbitrarily along rows, columns, and diagonals, this implies that no two\nqueens can share a row, column, or diagonal. The following is a valid solution to the Eight Queens\nproblem:\n\n6.827\nProblem Set 2\n+-------------------------------+\n|\n|\n|\n|\n|\n| Q |\n|\n|\n|-------------------------------|\n|\n|\n|\n|\n|\n|\n|\n| Q |\n|-------------------------------|\n|\n| Q |\n|\n|\n|\n|\n|\n|\n|-------------------------------|\n|\n|\n|\n| Q |\n|\n|\n|\n|\n|-------------------------------|\n| Q |\n|\n|\n|\n|\n|\n|\n|\n|-------------------------------|\n|\n|\n|\n|\n|\n|\n| Q |\n|\n|-------------------------------|\n|\n|\n|\n|\n| Q |\n|\n|\n|\n|-------------------------------|\n|\n|\n| Q |\n|\n|\n|\n|\n|\n+-------------------------------+\nYour goal is to design a function queens that takes a single argument n which is both the size\nof the board and the number of queens to place on it. For the Eight Queens case, your function\nshould be invoked as queens 8. Your function is to return a list of chess boards showing all the\nlegal queen positions, and it should make use of list comprehensions as much as possible.\nTo represent a chess board, use a list of Int's where each entry in the list corresponds to the row\nposition of a queen. The board pictured above can be represented as: [4,6,1,5,2,8,3,7]. The\nfourth entry in this list, for example, is 5 since a queen is placed in the fifth row of the fourth\ncolumn in this configuration.\nYou are also to design a function displayBoard which takes a board configuration and returns a\n\"printable\" version as a String, following the format given above. You needn't worry about 0x0\nboards!\nIn addition to your code, your write-up for this problem will include sample configurations generated\nby your displayBoard routine as well as the total count of solutions for the Eight Queens problem.\nThe boilerplate code in /mit/6.827/ps-data/ps2-5.hs will do this for you.\nHint: There are 92 legal queen configurations for a board of size 8. The program should not take\nmore than a minute or so to run.\nProblem 6\nText Justification\nEditors (like emacs) and word-processors implement two important functions for making rag-tag\nlines of text look like neat paragraphs: filling and justification. A filling function takes a piece of\ntext like:\nIn the chronicles of the ancient\n\n6.827\nProblem Set 2\ndynasty of the Sassanidae,\nwho reigned\nfor\nabout\nfour hundred years, from Persia to the borders\nof China, beyond the great river\nGanges itself, we read the praises\nof\none of the kings of this race, who\nwas said to be the best\nmonarch of his time.\nand transforms it into\nIn the chronicles of the ancient dynasty of the Sassanidae, who\nreigned for about four hundred years, from Persia to the borders of\nChina, beyond the great river Ganges itself, we read the praises of\none of the kings of this race, who was said to be the best monarch of\nhis time.\nA justification function adds spaces between the words to align the right-hand sides of all lines,\nexcept the last.\nIn the\nchronicles\nof the\nancient dynasty\nof the\nSassanidae,\nwho\nreigned for about\nfour hundred years, from Persia\nto the\nborders of\nChina,\nbeyond the great\nriver Ganges itself, we\nread the praises of\none of the kings of this race, who was said\nto be the best monarch of\nhis time.\nWe define the input to this problem as a single string at the top-level of the Haskell program\n(boilerplate to be found in /mit/6.827/ps-data/ps2-6.hs):\nmyText = \"... the ancient \\n\ndynasty of the Sassanidae, ...\"\nThe first step in processing the text is to split an input string into words while discarding white\nspace. Words can then be arranged into lines of a desired width, and these lines can then be\njustified to align their right-hand sides.\nPart a:\nWe define a word as a sequence of characters that does not contain spaces, tabs, or newlines.\nHaskell provides a function isSpace in the Char library which indicates whether a given character\nis whitespace.\nWrite a function splitWord ::\nString -> (Word,String) that returns the first word in a string\nand the remainder of the string. If the string begins with a whitespace character, the first word is\nthe empty string. For example,\nsplitWord \" beyond the\" = (\"\", \" beyond the\")\nsplitWord \"kings of \"\n= (\"kings\",\" of \")\n\n6.827\nProblem Set 2\nGiven the type synonym\ntype Word = String\nwrite a function splitWords ::\nString -> [Word] that splits a string into words, using\nsplitWord.\nPart b:\nNow we need to break a list of words into lines. We define\ntype Line = [Word]\nand your job is to write a function splitLine ::\nInt -> [Word] -> (Line,[Word]). The first\nargument to splitLine is the length of the line to be formed. Assume that this length is at least\nas long as the longest word in the text. The second argument is the list of words we derived from\nthe input string.\nTo conclude this part, write splitLines ::\nInt -> [Word] -> [Line], a function that returns\na list of \"filled\" lines given a line width parameter and a list of words.\nPart c:\nTo put it all together, write the functions\nfill :: Int -> String -> [Lines]\njoinLines :: [Line] -> String\nfill takes a line width and a string and returns a list of filled lines. joinLines takes the filled lines\nand puts them together into a single string. Lines are separated in the string by newline ('\\n')\ncharacters.\nPart d:\nModify joinLines to justify lines by adding the appropriate number of interword spaces. You\nare free to choose where to add spaces in the line. Name the resulting functions justify and\njustifyLines:\njustify :: Int -> String -> [Lines]\njustifyLines :: [Line] -> String\nNote: This problem is adapted from Simon Thompson, \"Haskell: The Craft of Functional Pro\ngramming\". We use the greedy filling algorithm here, which minimizes the shortfall on each line;\nbetter systems try to minimize the squared shortfall on each line to give a more uniform margin.\nThis is why Meta-Q in emacs often reformats a properly-filled paragraph, for example. Good \"listy\"\nalgorithms for optimal filling have been derived in several papers."
    },
    {
      "category": "Resource",
      "title": "ps3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/6469940f04a09fa72cc7f173b7b6ec46_ps3.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.827 Multithreaded Parallelism: Languages and Compilers\nProblem Set 3\nPlease Remember: 1) You can work in groups of up to three people; include the names of all\ngroup members on all problems. 2) Turn in the answer to each problem as a separate packet. 3)\nComment your code carefully and include output from sample runs.\nWe believe this problem set is rather challenging, but you should have no serious difficulties if you\nstart early! We'll continue to use pH to write some larger functional programs than in Problem Set\n2. The first problem asks you to implement the Huffman coding algorithm to compress files. This\nproblem combines algebraic types, arrays, and a bit of I/O. In the second problem, we explore the\nconcept of generalized arrays and make extensive use of the Haskell/pH array data type. In the\nfinal two problems, we implement an applicative interpreter and a basic type-checker for a \"core\"\nversion of pH. We have provided basic templates to get you started on these problems in the files\n/mit/6.827/ps-data/ps3-n.hs.\nProblem 1\nHuffman Codes\nHuffman codes are variable-length codes used to compress data. Fixed-length codes like ASCII\nuse a fixed number of bits to represent characters. Huffman codes use a variable number of bits to\nrepresent characters, and the encoding is chosen according to the frequency of occurrences of the\ncharacters in the data.\nHuffman codes are often depicted as trees. Suppose we have an alphabet containing only the three\nsymbols a, b, c and that our algorithm has produced the encoding shown in the figure. The\nencoding of a character according to this particular Huffman code is the path followed to reach the\ncharacter from the root of the tree. For example, the code for a is L since we go down the left\nsubtree from the root to reach a. Similarly, the codes for b and c are RL and RR respectively.\na\nL\nR\nL\nR\nb\nc\nFigure 1: Tree.\nThroughout this problem, you should assume that alphabets contain at least two symbols and that\ndata to be encoded uses at least two different symbols.\nPart a:\nIn this first part, we'll look at the process of encoding and decoding data using a Huffman code.\nWe define the following data types for this purpose:\n\n6.827 Problem Set 3\ndata Bit\n= L | R\nderiving Show\ntype HCode = [Bit]\ntype Table = Array Char HCode\ndata Tree = Left Char Int | Node Int Tree Tree\nderiving (Read,Show)\nThe Bit data type represents the components of the route down the encoding tree, and the HCode\ndata type represents the encoding of a particular character or characters.1 Next, the Table data\ntype defines a mapping from characters to Huffman encodings via an array. Finally, the Tree data\nstructure is used to map codes to characters; ignore the Int field in each disjunct for now. In our\nexample, the code corresponds to the following Tree and Table objects.\nencoding = array ('a','c') [('a',[L]),('b',[R,L]),('c',[R,R])]\ndecoding = Node 0 (Leaf 'a' 0) (Node 0 (Leaf 'b' 0) (Leaf 'c' 0))\nWrite the functions\nencodeData :: Table -> String -> HCode\ndecodeData :: Tree -> HCode -> String\nthat encode and decode data. Try these out using the encoding and decoding objects give\nabove.\nPart b:\nNow we consider the problem of building Huffman coding trees and encoding tables. We give the\nalgorithm in several steps:\n1. The first step in this process is to build a histogram of the number of occurrences of each\nsymbol in the data to be encoded. Write a function\ncountChars :: String -> Array Char Int\nthat creates the histogram. Assume that the alphabet is composed of all characters in the\nHaskell/pH Char data type. Characters can be represented using single quotes as in 'a' or\nthey can be created using the integers 0-255 and the toEnum method of the Enum typeclass,\na class that has Char as one of its members. For the message aabcccaba, the counts\nfor characters a, b, and c are 4, 2, and 3, respectively. Your job will be much easier if\nyou use Haskell's accumulator comprehension accumArray (which is implemented using\nM-structures as shown in lecture).\n2. Given the character counts, we build a separate coding tree, containing only a leaf node,\nfor each character that occurs at least once in the input. As you may have guessed by\nnow, the count for a character is entered into the Int field we ignored above. For the data\naabcccaba, the set of encoding trees can be represented as the list (sorted by increasing\ncount):\n1Huffman codes are prefix codes so parsing is unambiguous.\n\n6.827 Problem Set 3\n[ Leaf 'b' 2 , Leaf 'c' 3 , Leaf 'a' 4 ]\n3. We then start combining the two trees with the lowest counts into a new tree by making the\ntwo trees subtrees of a new Node. The character count field for the new node is the sum of\nthe counts of its subtrees. The process continues until a single tree results. In the example\nabove, the set of trees resulting from the first combination, again sorted by count, would be:\n[ Leaf 'a' 4, Node 5 (Leaf 'b' 2) (Leaf 'c' 3) ]\nAnd the final tree would be:\nNode 9 (Leaf 'a' 4) (Node 5 (Leaf 'b' 2) (Leaf 'c' 3))\nWrite a function\nmakeCodingTree :: Array Char Int -> Tree\nthat takes as input the frequency histogram of the characters in the file and produces a single\ncoding tree.\nAs you can see, the key to the Huffman coding algorithm is that characters that occur most\noften in the input data are pushed to the top of the encoding tree. In this way, their encoding\nwill require fewer bits. Less frequent characters are pushed to deeper levels in the tree and\nwill require more bits to encode.\n4. Finally, write a function\nmakeCodeTable :: Tree -> Table\nthat converts an encoding tree into an encoding table suitable for the encodeData routine.\nIf a particular character does not appear in an input file, make sure that its entry in the Table\nis [].\nPart c:\nNow that we've got the tools to create encodings from inputs, we need a way to represent encoded\nmessages (lists of Bits) as real bit streams. Such a representation will allows us to output encoded\ndata compactly to files. The idea is to divide a list of Bits into chunks of eight Bits; to convert\neach chunk into an integer; and then to use the integer with toEnum to create a Char. Assume\nthe L constructor represents a 0 bit while R represents a 1 bit. Write a function\nhCodeToString :: HCode -> String\nto perform the conversion.\nWhat happens if the length of the Huffman encoding of your input data (the list of Bits) is not a\nmultiple of eight? Make sure you handle this case properly so that you can write the function\nstringToHCode :: String -> HCode\n\n6.827 Problem Set 3\nto perform the inverse operation of hCodeToString. The function stringToHCode takes a\nstring (a list of Char) and decodes it into an HCode (a list of Bits). Assume that all the inputs\nto stringToHCode have been generated using your version of hCodeToString. In other\nwords, hCodeToString and stringToHCode must agree on a way to handle encodings with\nlengths that are not multiples of eight bits.\nPart d:\nWrite two functions\nencode :: String -> (Tree,String)\ndecode :: (Tree,String) -> String\nto serve as the top-level interface to your Huffman coding routines. The encode function takes\na string as input, encodes it, and returns the encoding tree and the encoded string. The decode\nfunction takes an encoding tree and an encoded string and produces a decoded string as output.\nThese functions are called by\nencodeFile :: FilePath -> FilePath -> IO ()\ndecodeFile :: FilePath -> FilePath -> IO ()\nwhich we have provided for you. The parameters to encodeFile and decodeFile are the\nname of an input file and the name of an output file (both are strings).\nTry encoding and decoding several files, including the sample files (ps3-sample{1-3}) in the\n/mit/6.827/ps-data directory. However, don't try to encode or decode very large files as\npH will run out memory (Why?).\nHow much compression do you get? All the sample files contain the same information, but\nps3-sample2 and ps3-sample3 have been preprocessed in special ways. Can you guess\nhow?\nProblem 2\nGeneralized Arrays\nDr. Bunsen Honeydew2 of Jee-whiz Projects Laboratories (JPL) grabs you in the hallway one\nmorning... the conversation goes something like this:\nHey, your name here, you're a pH wizard, but I think pH is terrible... and I'll tell\nyou why. I need to compute some Fourier transforms--sometimes of a vector, some-\ntimes of a matrix, sometimes even of a cube or an object with still more dimensions!\nFurthermore, in some cases I need to use an entire vector--row or column--and some-\ntimes I need to use only part of a vector. In pH, I need to write a bunch of Fast Fourier\nTransforms (FFT's), one for each of these cases.\nEven FORTRAN handles all my FFT needs with one routine because it allows me\nto treat rows and columns of matrices as vectors, and it even allows me to select pieces\nof vectors.\nHummmph....\n2All names have been altered to protect the innocent.\n\n~\n~\n~\n6.827 Problem Set 3\nAt this point, Dr. Honeydew walks off mumbling something about the evils of functional program\nming...\nIn a flash of inspiration, you remember generalized arrays (see the pH book), and you think \"hey,\nthese would do the trick!\" The algorithms to do these transformations all use the basic 1D FFT,\nsometimes on rows, sometimes on columns. You realize that if you implement the 1D FFT algo\nrithm using generalized arrays, the doctor will be able to use it to compute 2D and 3D FFTs.\nThe 1D FFT of an N-vector x of complex numbers is the vector y = FN x, where FN is\n\n. . .\n\nω\nω2\n. . .\nωN -1\n\nω2\nω4\n. . .\nω2(N -1)\n\nω3\nω6\n. . .\nω3(N -1)\n\n.\n.\n.\n. . .\n.\n\n.\n.\n.\n. . .\n.\n\n1 ωN -1 ω2(N -1)\nω(N -1)(N -1)\n. . .\nIn general, the (i, j)th entry of the matrix is ωij , 0 ≤ i, j ≤ N - 1, where ω = ωN is a principal\nNth root of unity, wN = 1 and for 0 < j < N, wj 6= 1. For this problem, we will assume that N\nis a power of 2.\nThough the FFT transformation is expressed as a matrix multiply, we can design a much more\nefficient algorithm using a divide-and-conquer strategy. This algorithm works by dividing the\ninput array into two equal parts, applying itself recursively and finally combining the results of the\ntwo halves to yield the FFT of the original array.\nA pH implementation of this algorithm is given in the file /mit/6.827/ps-data/ps3-2.hs.\nThis implementation uses ordinary arrays. Your task is to write the same algorithm using two\ndifferent generalized array representations: the first is the one given in the pH book, and second is\ndeveloped below.\nPart a:\nWrite the function fft which takes two arguments:\n- The input array (in generalized form).\n- The roots of unity array roU.\nand returns the FFT in a normal array (you needn't generalize the result).\nYour function should do the following steps:\n- If the size of the input array is 4, it computes the FFT directly.\n- If not, it solves the problem recursively:\n\n6.827 Problem Set 3\n- It shuffles the input generalized array into two generalized arrays of half the size,\none consisting of odd elements v left and the other consisting of even elements\nv right.\n- Arrays fft left, fft right are computed using recursive calls to fft.\n- The final result is returned using the function combine which combines these arrays.\nPart b:\nYou show your solution to the doctor, and he spots an efficiency problem with generalized arrays.\nHe points out that a single access of an array element at the bottom of the recursion takes many\n(how many?) function applications to yield the value of that array element. You want to improve\nthe efficiency of the program by making sure that the number of applications needed to access an\narray element is bounded by a constant (irrespective of the input array size). You think hard and\ncome up with a more general vector representation which achieves this goal. Re-implement your\nFFT functions using this new representation and measure the reduction count. Are we doing better\nthan before? How do we compare with the array copying version of FFT? Which implementation\nis the best?\nHint: The new generalized array is of the form (low,n,stride,f). The array has n elements\nand is accessed by array indices 1 through n. The first element is (f l). What is stride?\nPart c:\nYou might also notice that the fft function requires a lot of storage, as the FFT array is computed\nand discarded at each stage of the recursion. We will need to make a tradeoff between parallelism\nand storage use in order to use machine resources effectively. We can circumvent this problem\nin several ways, but the simplest is to use an IVector. Rewrite the FFT code so that only a single\nIVector is allocated to hold the result of the transform.\nProblem 3\nCore pH: Type Checker\nIn this problem, you will implement the type-checking algorithm described in class. This process\nis somewhat long, but it will be broken down into small steps. Debugging your program will be\nmuch easier if you have a thorough understanding of the algorithm. You should work out the\nalgorithm by hand on several examples before trying to program it. However, you need to submit\nonly your program with its test cases.\nTypes in our language are represented as follows. Types are either type variables, type constants\nor function types.\ndata Type = TVar TIdent | TConst BaseType | Arrow Type Type\nderiving (Eq,Show)\ndata TIdent = TName Int\nderiving (Eq,Show)\ndata BaseType = IntType | BoolType\nderiving (Eq,Show)\n\n6.827 Problem Set 3\nType schemes are generalized types. The type is generalized with respect to the variables in the\nlist.\ndata TScheme = TScheme [TIdent] Type\nderiving (Eq,Show)\nA type environment is a list of (variable,type) scheme pairs. In our algorithm, we use the environ\nment to store types of variables seen \"before\" in the program.\ntype TEnv = [(Ident,TScheme)]\nA substitution is a list of (type-variable, type) pairs. The substitution is actually applied on a type\nin the reverse order, i.e. the substitution last in the list is the one which is applied first.\ntype Subst = [(TIdent,Type)]\nPart a:\nThe first step in writing the type-checking algorithm is to write functions to manipulate environ\nments. We need two functions:\nextendEnv :: TEnv -> Ident -> TScheme -> TEnv\n-- This function extends the environment with the\n-- (variable, type scheme) pair.\ngetEnv :: TEnv -> Ident -> TScheme\n-- This function looks up the environment for the variable, generates\n-- an error if it is not present.\nPart b:\nThat was easy! Next, we need functions to manipulate type variables. In particular, we will be\ndealing with sets of type variables. For this, you will want to use the List library which provides\nfunctions to treat lists as sets. Write the following functions:\nfreeVars :: Type -> [TIdent]\n-- Returns free variables of a type.\nfreeVarsScheme :: TScheme -> [TIdent]\n-- Returns free variables of a type scheme.\nfreeVarsEnv :: TEnv -> [TIdent]\n-- Returns free variables of a type environment.\nnewTypeVar :: NameSupply -> TIdent\n-- Generates a new type variable, not used anywhere before.\nNote that you will need to provide a \"name supply\" for your code--a means of generating new\ntype variables. It is up to you how you choose to implement this.\nPart c:\nNow, we will write functions to apply substitutions on the various entities in the type system.\nYou need to write the following functions. Note that these type signatures omit any mention of\na NameSupply--you should add arguments and results to deal with this \"plumbing\" where it is\nnecessary. Later on we will discuss nice ways of encapsulating such plumbing.\n\n6.827 Problem Set 3\napplySubToT :: Type -> Subst -> Type\n-- Apply a substitution to a type.\napplySubToScheme :: TScheme -> Subst -> TScheme\n-- Apply a substitution to a type scheme. Be careful to avoid\n-- variable capture!\napplySubToEnv :: TEnv -> Subst -> TEnv\n-- Apply a substitution to a type environment.\ncombine :: Subst -> Subst -> Subst\n-- Combine two substitutions. Note that (combine s2 s1)\n-- is the substitution which applies s1 first and then s2.\nPart d:\nNext, we write functions which convert type schemes to types and vice versa.\ninstantiate :: TScheme -> Type\n-- This function instantiates the type scheme, i.e. it replaces\n-- the generalized type variables by new type variables.\ngeneralize :: TEnv -> Type -> TScheme\n-- This function generalizes (or closes) a type to generate a type\n-- scheme.\nPart e:\nThe next step in the algorithm is to write the unification procedure.\nunify :: Type -> Type -> Subst\n-- This function returns a substitution which unifies the argument\n-- types. If the types are not unifiable, it generates an error.\nPart f:\nFinally, we are ready to write the type inference algorithm w.\nw :: TEnv -> Exp -> (Subst,Type)\n-- This implements the inference algorithm.\nIn addition to these functions given above, you can write \"glue\" functions to make your program\nmore readable. You'll want to use the features of the List library and the prelude extensively\nin your code; functions like foldr, foldl, map, lookup etc. are very helpful in writing\nconcise programs.\nTest out your type inference function on the following inputs:\nlet\nk = \\x -> \\y -> x\nin\nk 1 (k True 2)\n\n6.827 Problem Set 3\n\\k -> k 1 (k True 2)\n\\k ->\nlet\nk1 = k\nin\nk1 1 (k1 True 2)\n\\x -> \\y -> plus x y\nYou do not need to parse these functions, just convert them by hand to the expression representation\n(Exp) used by your program. Feel free to include any other test cases."
    },
    {
      "category": "Resource",
      "title": "ps4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/ca0ae097fa08962e908acc7dacdc7e26_ps4.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.827 Multithreaded Parallelism: Languages and Compilers\nProblem Set 4\nProblem 1\nCore pH: Applicative Interpreter\nThe following data types are used to represent a simple functional language. Our language con\nsists of constants (integers and booleans), variables, applications, abstractions and let-blocks. The\nlanguage syntax is very similar to that of λC ; the main difference is that we distinguish various\nkinds of constants, and we use a list to represent all the bindings in a let (with the understanding\nthat the order of list elements doesn't matter).\ndata Exp = IntConst Int\n| BoolConst Bool\n| Var Ident\n| App Exp Exp\n| Func Ident Exp\n| Cond Exp Exp Exp\n| Prim PrimId [Exp]\n| Let [(Ident, Exp)] Exp\nderiving (Eq,Show)\ndata Ident = Varid Int deriving (Eq,Show)\ndata PrimId = Add | Sub | Mul | Div | Eq | Less | Greater\nderiving (Eq,Show)\nYour task in this problem will be to write a simple applicative-order (call-by-value) interpreter for\nthis small language.\nPart a:\nYou should begin by writing a version of your interpreter for the pure λ calculus. This means your\ninterpreter need only handle the Func, Var, and App disjuncts in the grammar given above. You\nshould use the applicative interpreter discussed in lecture as a guide (this means you will need to\ncome up with some sort of representation of substitution, or carry around an environment). You\nshould evaluate terms to Weak Head Normal Form.\nTranslate the following term into a data structure (this is straightforward to do by hand) and show\nwhat your interpreter returns as a result when given this input:\n(\\a b -> b a) ((\\x y -> x (x y)) (\\u v -> v)) (\\z -> z)\nPart b:\nNow add constants, primitives, and conditionals to your interpreter. Try it out on the following\nexample:\n\n6.827 Problem Set 4\n(\\ a -> if (a*3 == 9) then (\\b c -> b) else (\\b c -> c)) 14 False True\nPart c:\nFinally, add recursive let-bindings to your interpreter. This is the most difficult part; it's very\nimportant that you be careful about the scoping of names. The crucial test of this will be whether\nmutually recursive functions are actually mutually recursive. If you are using environments for\nevaluation (and it's nearly impossible to do let-blocks without such a notion) you might find it\neasiest to create an extended environment with bindings for all the new values in a block, and\nevaluate each of those bindings non-strictly in the extended environment. Try this example:\nlet odd = \\x -> if x==1 then oddresult else even (x - 1)\neven = \\x -> if x==0 then evenresult else odd (x - 1)\noddresult = 17 + 13 * evenresult\nevenresult = 43\nin odd 327\nProblem 2\nImplementing Queues with M-Structures\nIn this problem, we will define a queue abstraction using M-Structures. A queue is represented as\na product type consisting of fields for front, qsize, buflen, buffer. The front, qsize,\nand buffer fields are represented as M-Structures so that they can be mutated as the queue\nchanges.\ndata MQueue a = MQueue (MCell Int)\n-- front\n(MCell Int)\n-- qsize\nInt\n-- buflen\n(MArray Int a)\n-- buffer\nThe field buflen contains the length of the queue buffer, qsize contains the number of elements\nin the queue, and front contains the offset of the next element to be dequeued. We enqueue\nelements by \"putting\" them at offset (front + qsize) modulo buflen and increasing the\nqsize, and we dequeue elements by \"taking\" the element at offset front, increasing front by\none (modulo buflen) and decreasing qsize by one.\nThe syntax for M-Structure fields in algebraic types is different in the compiler than in the pH\nbook. As a reminder, for the current Linux compiler, there are extensive language notes in\n/mit/6.827/phc-new/phc/docs/language\nPart a:\nWrite a function makeQueue which takes one parameter, buflen, and returns an empty\nMQueue with a buffer of appropriate size.\nPart b:\nWrite a function enqueue which takes an MQueue and an object and places the object in the\n\n6.827 Problem Set 4\nqueue. Analyze your function carefully to make sure that there are no race conditions1 or deadlock\npossibilities! Also, be sure to generate an error if an attempt is made to enqueue an element into a\nqueue that is already full.\nTest your implementation of enqueue by writing another function, testEnqueue, that per-\nforms some number of enqueue operations in parallel (that is, there should be no barriers or data\ndependencies between them).\nPart c:\nIn this part, you are to write the definition of dequeue, which takes a queue and returns the\nelement pointed to by the queue's front, increments the queue's front and decrements the\nqsize. dequeue also takes in a default value to be returned in case the queue is empty.\nWrite an additional function, testDequeue, to test your implementation of dequeue.\nPart d:\nWrite a function testEnqueueDequeue that takes two parameters, a queue and a number n,\nand performs n enqueues and dequeues in parallel.\n1A race condition exists in a program when there is the opportunity that a particular ordering of events might lead\nto incorrect behavior."
    },
    {
      "category": "Exam",
      "title": "quiz.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/ef81db5665312176dfa2f06d48529179_quiz.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of E lectrical E ngineering and Computer Science\n6.827\nM ultithreaded P arallelism: L anguages and C ompilers\nLecture 12\n6.827 Mid-Term Quiz\nProfessor Arvind\nN ame\nE mail\nRemember to write your name on every page!\nT his is a closed book quiz.\nAccess to lecture notes is permitted.\n1hr 30min\n11 Pages\nP roblem 1\n30 P oints\nP roblem 2\n20 P oints\nP roblem 3\n32 P oints\nP roblem 4\n18 P oints\nT otal\n100 P oints\n\n|\n{z\n}\n|\n{z\n}\n6.827\nQuiz\nName\nProblem 1\nReduction\nTo make the expressions in this problem easier to view, we have used braces to underline terms\nwhich are contained between matching parentheses.\nPart 1-1: (10 points)\nReduce the following λ-calculus expression, in any order you choose, until there are no more redexes\nin the expression. Give all the intermediate steps.\nλz. ((λx. λz. z (x z)) (λf. z f )) (λx. x)\n|\n{z\n} | {z }\n| {z }\n\n|\n{z\n}\n|\n{z\n}\n6.827\nQuiz\nName\nPart 1-2: (10 points)\nReduce the following expression to normal form using the normal order reduction strategy. Give\nall the intermediate steps in the reduction. If you discover that the reduction will not terminate,\nstop and indicate as much.\n(λx. λy. x (λg. (g x) (g y)) (λx. x)) (λx. λy. x y)\n| {z }\n|\n{z\n}\n| {z } | {z }\n\n|\n{z\n}\n|\n{z\n}\n6.827\nQuiz\nName\nPart 1-3: (10 points)\nReduce the following expression to normal form using the applicative order reduction strat\negy. Give all the intermediate steps in the reduction. If you discover that the reduction will not\nterminate, stop and indicate as much.\n(λx. λy. x) (λz. (λx. λy. x) z ((λx. z x) (λx. z x)))\n|\n{z\n}\n|\n{z\n}\n|\n{z\n} |\n{z\n}\n\n6.827\nQuiz\nName\nProblem 2\nRecursion\nIn class, we defined a fixed-point operator Y which produces the least fixed-point of a recursive\ndefinition. That is, it solves the equation:\nY F = F (Y F)\n(1)\nThis equation simply says that if we apply the reduction rules to the expression (Y F), we can\nreduce it to the expression F (Y F).\nPart 2-1: (10 points)\nWe said that the combinator which satisfies this condition is:\nY = (λf. (λx. f (x x)) (λx. f (x x)))\nHowever, there are many other equally valid definitions for this combinator. Consider the following\ndefinition:\nY0 = (λx. λy. y (x x y)) (λx. λy. y (x x y))\nShow that Y0 is a least fixed-point operator by showing that it satisfies equation (1).\n\n6.827\nQuiz\nName\nPart 2-2: (10 points)\nGiven the following recursive definition:\nlength l = case l of\n[] -> 0\n(x:xs) -> 1 + length xs\nconstruct a non-recursive expression for length using the fixed-point operator Y.\n\n6.827\nQuiz\nName\nProblem 3\nHindley Milner Types\nGive the Hindley-Milner types for the following functions. Be sure to give the most general type\nfor any functions which are polymorphic. Assume that there is no overloading, that all arithmetic\nfunctions operate on values of type Int, and that all comparisons return results of type Bool.\nSome functions may not type, but instead produce a type error. In those cases, indicate that the\nexpression is not type correct and explain why.\n3-1: (3 points)\ncurry f x y\n=\nf (x,y)\n3-2: (3 points)\nrepeat x\n=\nlet\nxs = (x:xs)\nin\nxs\n3-3: (6 points)\nf x y\n=\nf x y\ng x y\n=\ng y x\nh x y\n=\nif (x == 0) then f x y\nelse g y x\n\n6.827\nQuiz\nName\n3-4: (4 points)\nmax1 f n m\n=\nlet\na = f n\nb = f m\nd = a > b\nin\nif (f d) then a\nelse b\n3-5: (4 points)\nmax2 n m\n=\nlet\nf x = x\na\n= f n\nb\n= f m\nd\n= (a > b)\nin\nif (f d) then a\nelse b\n\n6.827\nQuiz\nName\n3-6: (8 points)\nGiven the following types for map, (&&) (the boolean AND operator), and (.) (an infix operator\nwhich composes functions), determine the types of the other three functions:\nmap\n:: (a -> b) -> [a] -> [b]\n(&&) :: Bool -> Bool -> Bool\n(.)\n:: (b -> a) -> (c -> b) -> c -> a\nfoldr f z l\n=\ncase l of\n[] -> z\n(x:xs) -> f x (foldr f z xs)\nand\n=\nfoldr (&&) True\nall p\n=\nand . map p\n3-7: (4 points)\nunzip\n=\nlet\nf (a,b) (as,bs) = ((a:as),(b:bs))\nin\nfoldr f ([],[])\n\n6.827\nQuiz\nName\nProblem 4\nTypechecking Using the Class System\nThis problem is the same as the previous problem, except that we have added overloading to our\nlanguage with the following type classes:\nclass\nEq a\nwhere\n(==), (/=)\n:: a -> a -> Bool\nclass\n(Eq a) => Num a\nwhere\n(+), (-), (*)\n:: a -> a -> a\nnegate\n:: a -> a\nfromInteger\n:: Integer -> a\nclass\n(Num a) => Fractional a\nwhere\n(/)\n:: a -> a -> a\nrecip\n:: a -> a\nclass\n(Num a) => Integral a\nwhere\ndiv, mod\n:: a -> a -> a\nIn addition to the types Bool and Int from the previous problem, we also have the types Float\nand Char. There is an instance of the Eq class for all four types. The Num class is instanced for the\nnumeric types Int and Float. The only instance of the Fractional class is for type Float and\nthe only instance of the Integral class is for type Int.\nRemember that the function fromInteger in the Num class allows us to overload whole-number\nconstants (so 5 :: (Num a) => a). However, floating-point constants have the type Float.\nIdentify the type of each of the following expressions or indictate that the expression does not type\ncheck (and explain why):\n4-1: (4 points)\ny_intercept a b\n=\n(negate b) / a\n\n6.827\nQuiz\nName\n4-2: (4 points)\nquadratic a b c\n=\n((b * b) - 4 * a * c) / (2 * a)\n4-3: (5 points)\nones_digit n\n=\nmod n 10.0\n4-4: (5 points)\ngcd x y\n=\nif (y == 0) then x\nelse gcd y (mod x y)"
    },
    {
      "category": "Exam",
      "title": "quiztopics.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/f610e91772671b0c8388a5687968b395_quiztopics.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.827 Multithreaded Parallelism: Languages and Compilers\nMidterm Topics\nLecture 11\nPlease Remember: The Midterm Exam will happen in class on Lecture 12 date. You\nare allowed to use lecture notes (this is an open-notes test), but the problem sets and the textbook\nare not permitted.\nTopics\nWe have listed these topics below and enumerated the important subtopics that you should know.\nThe stars next to the Hindley-Milner type rules and inference algorithm indicate that we are not\nrequiring you to be intimately familiar with the rules or to mechanically apply them. You are,\nhowever, required to be able to identify the type of any expression you are given or indicate that\nthe expression is type incorrect. We recommend you to look at problems in the pH Book in order\nto get the feel for the quiz. Those include the problems in Chapters 2, 3, 4, and Appendix A.\n1. Lambda-calculus. (pH Book: Chapter 2, Appendix A)\n- free and bound variables in an expression\n- beta-substitution\n- alpha and eta rules\n- reducing a lambda-calculus expression\n- renaming variable to avoid capture\n- recursion, fixed points, the Y combinator\n- confluence (Church-Rosser) property\n2. Interpreters. (pH Book: Chapter 4)\n- normal form, head normal form, weak normal form\n- reduction strategies\n- applicative order\n- normal order\n- normalizing property of an interpreter or reduction strategy\n- call-by-name interpreter, call-by-value interpreter\n3. Lambda-calculus with constants and let-blocks. (pH Book: Chapter 4)\n- projection functions and constructors\n\n6.827 Midterm Topics\n- new reduction rules\n- alpha and beta rules\n- instantation of let-bound variables\n- liftening and flattening rules for let-blocks\n4. Types. (pH Book: Chapter 3, Appendix A)\n- polymorphism\n- in let-blocks versus lambda-abstractions\n- type inference/reconstruction (*)\n- Hindley-Milner typing rules and inference algorithm (*)\n- generalization (*)\n- unification (*)\n- types versus type schemes\n5. Overloading. (pH Book: Chapter 3)\n- contrast with polymorphism\n- type classes\n- ambiguity in overloading resolution"
    },
    {
      "category": "Resource",
      "title": "L01Introduction.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/96e07c20ead6f5409a7054e4883e6442_L01Introduction.pdf",
      "content": "L1- 1\nExpressing Parallel Computation\nArvind\nLaboratory for Computer Science\nM.I.T.\nLecture 1\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-2\nArvind\n-\nsymmetric multiprocessors (SMP's)\nMain St r eam Par allel Com put ing\nMost \"server\" class machines these days are\n- PC class SMP's\n- 2 to 4 processors\n- cheap\n- run Windows & Linux\n- track technology\n- Delux SMP's\n- 8 to 64 processors\n- expensive (16-way SMP costs >> 4 x 4-way SMPs)\n- Applications\n- databases, OLTP, Web servers, Internet commerce...\n- potential applications: EDA tools, technical computing,...\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-3\nArvind\n-\nprocessors are build as clusters of SMP's\nLar ge Scale Par allel Com put ing\nMost parallel machines with hundreds of\n- usually custom built with government funding\n- expensive: $10M to $100M\n- are treated as a national or international resource\n- Total sales are a tiny fraction of \"server\" sales\n- hard time tracking technology\n- Applications\n- weather and climate modeling\n- drug design\n- code breaking (NSA, CIA, ...)\n- basic scientific research\n- weapons development\nFew independent software developers;\nProgrammed by very smart people\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-4\nArvind\nPaucit y of Par allel Applicat ions\n- Applications follow cost-effective hardware\nwhich has become available only since 1996\n- Important applications are hand crafted\n(usually from their sequential versions) to run\non parallel machines\n- explicit, coarse-grain multithreading on SMP's\n- most business applications\n- explicit, coarse-grain message passing on large clusters\n- most technical/scientific applications\n- Technical reasons:\n- automatic parallelization is difficult\n- parallel programming is difficult\n- parallel programs run poorly on sequential machines\nCan the entry cost of parallel programming be lowered?\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-5\nArvind\nWhy not use sequent ial languages ?\nAlgorithm with parallelism\nencode\nProgram with sequential semantics\ndetect parallelism\nParallel code\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-6\nArvind\nMat r ix Mult iply\nC = A x B\nCi,j = k\nAi,k Bk,j\nAll Ci,j's can be computed in parallel.\nIn fact, all multiplications can be done in parallel!\nFortran\ndo i = 1,n\ndo j = 1,n\ndo k = 1,n\ns = s + A(i,k)*B(k,j)\ncontinue\nC(i,j) = s\ncontinue\ncontinue\nParallelism?\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-7\nArvind\nPar allelizing Com piler s\nAfter 30 years of intensive research\n- only limited success in parallelism detection\nand program transformations\n- instruction-level parallelism at the basic-block level can\nbe detected\n- parallelism in nested for-loops containing arrays with\nsimple index expressions can be analyzed\n- analysis techniques, such as data dependence analysis,\npointer analysis, flow sensitive analysis, abstract\ninterpretation, ... when applied across procedure\nboundaries often take far too long and tend to be fragile,\ni.e., can break down after small changes in the\nprogram.\n- instead of training compilers to recognize\nparallelism, people have been trained to\nwrite programs that parallelize\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-8\nArvind\nPar allel Pr ogr am m ing Models\nIf parallelism can't be detected in sequential\nprograms automatically then design new parallel\nprogramming models ...\n- High-level\n- Data parallel: Fortran 90, HPF, ...\n- Multithreaded: Cid, Cilk,...\nId, pH, Sisal, ...\n- Low-level\n- Message passing: PVM, MPI, ...\n- Threads & synchronization:\nFutures, Forks, Semaphores, ...\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-9\nArvind\nPr oper t ies of Models\nDeterminacy - is the behavior of a program\nrepeatable?\nCompositionality - can independently created\nsubprograms be combined in a meaningful way?\nExpressiveness - can all sorts of parallelism\nbe expressed?\nImplementability - can a compiler generate\nefficient code for a variety of architectures?\nhttp://www.csg.lcs.mit.edu/6.827\n\n?\nL1-10\nArvind\nSafer Way s of Expr essing Par allelism\nData parallel: Fortran 90, HPF, ...\n- sources of parallelism: vector operators, forall\n- communication is specified by shift operations.\nImplicit Parallel Programming: Id, pH, Sisal, ...\n- functional and logic languages specify only a partial\norder on operations.\nDeterminacy of programs is guaranteed\n???????????????????????????????????????????\n⇒?easier debugging !!!\nProgramming is independent of machine\nconfiguration.\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-11\nArvind\nDat a Par allel Pr ogr am m ing Model\nAll data structures are assigned to a\n-\ncommunicate\ngrid of virtual processors.\n- Generally the owner processor computes\nthe data elements assigned to it.\n(global)\ncompute\n- Global communication primitives allow\nprocessors to exchange data.\n(local)\ncommunicate\n- Implicit global barrier after each\ncommunication.\n- All processors execute the same program .\ncompute\n(global)\n(local)\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-12\nArvind\nDat a Par allel Mat r ix Mult iply\nReal Array(N,N) :: A, B, C\nLayout A(:NEWS, :NEWS), B(:NEWS, :NEWS)\neach element is on a\nvirtual processor of\n2D grid\na\nC(:NEWS, :NEWS)\n... set up the initial distribution of data elements ...\nDo i = 1,N-1\n!Shift rows left and columns up\nA = CShift(A, Dim=2, Shift=1)\nB = CShift(B, Dim=1, Shift=1)\nC = C + A * B\ncommunication\nEnd Do\ndata parallel\noperations\nConnection\nMachine\nFortran\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-13\nArvind\n+ Good implementations\navailable\n- Difficult to write programs\n+ Easy to debug programs\nbecause of a single thread\n+ Implicit synchronization\nand communication\n- Limited compositionality!\ncommunicate\ncompute\ncommunicate\ncompute\n?\nare\nData Parallel Model\nFor general-purpose programming, which has more\nunstructured parallelism, we need more flexibility in\nscheduling.\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-14\nArvind\nFully Par allel, Mult it hr eaded Model\nTree of\nGlobal Heap of\nShared Objects\nActivation\nFrames\nh:\ng:\nf:\nloop\nthreads\nasynchronous\nat all levels\nactive\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-15\nArvind\nExplicit vs I m plicit Mult it hr eading\nExplicit:\n- C + forks + joins + locks\nmultithreaded C: Cid, Cilk, ...\n- easy path for exploiting coarse-grain parallelism\nin existing codes\nerror-prone if locks are used\nImplicit:\n- languages that specify only a partial order on\noperations\nfunctional languages: Id, pH, ...\n- safe, high-level, but difficult to implement\nefficiently without shared memory & ...\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-16\nArvind\nExplicitly Parallel Matrix Multiply\ncilk void\nmatrix_multiply(int** A, int** B, int** C,\nint n)\n{\n...\n...\nfor (i = 0; i < n; i++)\nfor (j = 0; j < n; j++)\nC[i][j] = spawn IP(A, B, i, j, n);\nsync;\n...\n...\n}\nint IP( ... ) { ... }\nCilk program\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-17\nArvind\nI m plicit ly Par allel Mat r ix Mult iply\nmake_matrix ((1,1),(n,n)) f\nwhere f is the filling function\n\\(i,j).(IP (row i A) (column j B))\nmake_matrix does not specify the order in which\nthe matrix is to be filled!\nno implication regarding the distribution of\ncomputation and data over a machine.\npH program\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-18\nArvind\nI m plicit ly Par allel Languages\nExpose all types of parallelism,\npermit very high level programming\nbut\nmay be difficult to implement efficiently\nWhy?\n- some inherent property of the language?\n- lack of maturity in the compiler?\n- the run-time system?\n- the architecture?\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-19\nArvind\nFuture\nId\nmultithreaded intermediate language\nHPF\nCilk\npH\nnotebooks\nSMPs\nMPPs\nFreshman will be taught sequential programming\nas a special case of parallel programming\nhttp://www.csg.lcs.mit.edu/6.827\n\nL1-20\nArvind\n6.827\nMultithreaded Languages and Compilers\nThis subject is about\n- implicit parallel programming in pH\n- functional languages and the λ calculus\nbecause they form the foundation of pH\n- multithreaded implementation of pH aimed\nat SMP's\n- some miscellaneous topics from functional\nlanguages, e.g., abstract implementation,\nconfluence, semantics, TRS...\nThis term I also plan to give 6 to 8 lectures on Bluespec,\na new language for designing hardware. Bluespec also\nboroughs heavily from functional languages but has a\ncompletely different execution model.\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L02pH_FunctionalPrint.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/83f7842206da5f513f6d36d76815dbb8_L02pH_FunctionalPrint.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL2\nArvind\nLaboratory for Computer Science\nM.I.T.\nImplicitly Parallel Programming\nin pH: Functions and Types\nSeptember 9, 2002\n- 1\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2\nArvind\nExplicitly Parallel Fibonacci\ncilk\n{if (n < 2)\nreturn n;\nelse\n{\nx = spawn fib(n-1);\ny = spawn fib(n-2);\nsync;\nreturn x + y;\n}\n}\n{if (n < 2)\nreturn n;\nelse\nreturn\nfib(n-1)+fib(n-2);\n}\n}\nC code\nCilk code\nC dictates that fib(n-1) be executed before fib(n-2)\n⇒ annotations (spawns and sync) for parallelism\nAlternative: declarative languages\n-2\nint fib (int n)\nint x, y;\nint fib (int n)\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2\nArvind\nWhy Declarative Programming?\n- Implicit Parallelism\n- language only specifies a partial order on operations\n- Powerful programming idioms and efficient\ncode reuse\n- Clear and relatively small programs\n- Declarative language semantics have good\nalgebraic properties\n- Compiler optimizations go farther than in imperative\nlanguages\n-3\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2\nArvind\npH is Implicitly Parallel and\na Layered Language\ncleaner semantics\nmore expressive power\nNon-Deterministic Extensions\n-\nstructures\nDeterministic Extensions\n- I -structures\nPurely Functional\n- higher order\n- non strict\n- strongly typed + polymorphic\n-4\nM-\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2\nArvind\nFunction Execution by Substitution\nplus x y = x + y\n1.\nplus 2 3\n2 + 3\n2.\nplus (2*3) (plus 4 5)\n-5\nL2-6\nArvind\nConfluence\nAll Functional pH programs (right or wrong)\nhave repeatable behavior\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2\nArvind\nBlocks\nlet\nx = a * a\ny = b * b\nin\n(x - y)/(x + y)\n- a variable can have at most one definition\nin a block\n- ordering of bindings does not matter\n-7\nL2-8\nArvind\nLayout Convention\nThis convention allows us to omit many delimiters\nlet\nx = a * a\ny = b * b\nin\n(x - y)/(x + y)\nis the same as\nlet\n{ x = a * a ;\ny = b * b ;}\nin\n(x - y)/(x + y)\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2\nArvind\nLexical Scoping\nlet\ny = 2 * 2\nx = 3 + 4\nz = let\nx = 5 * 5\nw = x + y * x\nin\nw\nin\nx + y + z\nLexically closest definition of a variable prevails.\n-9\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-10\nArvind\nRenaming Bound Identifiers\n( α-renaming)\nlet\ny = 2 * 2\nx = 3 + 4\nz = let\nx = 5 * 5\nw = x + y * x\nin\nw\nin\nx + y + z\nlet\ny = 2 * 2\nx = 3 + 4\nz = let\nx' = 5 * 5\nw = x' + y * x'\nin\nw\nin\nx + y + z\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-11\nArvind\nLexical Scoping and α-renaming\nplus x y = x + y\nplus' a b = a + b\nplus and plus'are the same because plus'\ncan be obtained by systematic renaming of\nbound identifiers of plus\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-12\nArvind\nCapture of Free Variables\nf x = . . .\ng x = . . .\nfoo f x = f (g x)\nSuppose we rename the bound identifier f to g\nin the definition of foo\nfoo' g x = g (g x)\nfoo\nfoo'\n?\nWhile renaming, entirely new names should be\nintroduced!\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-13\nArvind\nCurried functions\nplus x y = x + y\nlet\nf = plus 1\nin\nf 3\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-14\nArvind\nRecursion\nintegrate dx a b f =\n(sum dx b f (a+dx/2) 0) * dx\nsum dx b f x tot =\nif x > b then tot\nelse sum dx b f (x+dx) (tot+(f x))\nf(x)\na\nb\nx\ndx\nIntegral(a,b) = (f(a + dx/2) + f(a + 3dx/2) + ...) ?dx\nintegrate f(x)\nfrom a to b\nusing\ntrapezoidal\nrule\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-15\nArvind\nLocal Function Definitions\nImprove modularity and reduce clutter.\nintegrate dx a b f =\n(sum dx b f (a+dx/2) 0) * dx\nsum dx b f x tot =\nif x > b then tot\nelse sum dx b f (x+dx) (tot+(f x))\nintegrate dx a b f =\nlet\nsum x tot =\nif x > b then tot\nelse sum (x+dx) (tot+(f x))\nin\nsum (a+dx/2) 0\nFree\nvariables\nof sum\n?\nL2-16\nArvind\nLoops (Tail Recursion)\n- Loops or tail recursion is a restricted form of\nrecursion but it is adequate to represent a\nlarge class of common programs.\n- Special syntax can make loops easier to read and write\n- Loops can often be implemented with greater efficiency\nintegrate dx a b f =\nlet\nx = a + dx/2\ntot = 0\nin\n(while x <= b do\nnext\nx = x + dx\nnext tot = tot + (f x)\nfinally tot) * dx\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-17\nArvind\nHigher-Order Computation Structures\napply_n f n x = if (n == 0) then x\nelse apply_n f (n-1) (f x)\nsucc x = x + 1\napply_n succ b a\n?\nsucc can be written as ((+) 1)also because of\nthe syntactic convention:\nx + y\n(+) x y\napply_n ((+) 1) b a\nmult a b = apply_n\n?\nL2-18\nArvind\nTypes\nAll expressions in pH have a type\n23 :: Int\n\" 23 belongs to the set of integers\"\n\"The type of 23 is Int\"\ntrue :: Bool\n\"hello\" :: String\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-19\nArvind\nType of an expression\n(sq 529) :: Int\nsq\n\" sq is a function, which when applied to an integer\nproduces an integer.\"\n\" Int -> Int is the set of functions which when\napplied to an integer produce an integer.\"\n\"The type of sq is Int -> Int.\"\n:: Int -> Int\nL2-20\nArvind\nType of a Curried Function\nplus x y = x + y\n(plus 1) 3\n:: Int\n(plus 1)\n:: Int -> Int\nplus\n::\n?\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-21\nArvind\nλ-Abstraction\nLambda notation makes it explicit that a value\ncan be a function. Thus,\n(plus 1) can be written as \\y -> (1 + y)\nplus x y = x + y\ncan be written as\nplus = \\x -> \\y -> (x + y)\nor as\nplus = \\x y -> (x + y)\n( \\x is a syntactic approximation of x in Haskell)\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-22\nArvind\nParentheses Convention\nf e1 e2\n((f e1) e2)\nf e1 e2 e3\n(((f e1) e2) e3)\napplication is left associative\nInt -> (Int -> Int)\nInt -> Int\ntype constructor \"\n\" is right associative\n-> Int\n->\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-23\nArvind\nType of a Block\n(let\nx1 = e1\n.\n.\n.\nxn\n= en\nin\ne )\n::\nt\nprovided\ne\n::\nt\nL2-24\nArvind\nType of a Conditional\n(if e then e1 else e2 ) :: t\nprovided\ne\ne\ne\n::\nBool\n::\nt\n::\nt\nThe type of expressions in both branches\nof conditional must be the same.\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-25\nArvind\nPolymorphism\ntwice f x = f (f x)\n1. twice (plus 3) 4\ntwice ::\n?\n2. twice (appendR \"two\") \"Desmond\"\ntwice ::\n?\nwhere appendR \"\n\"\n\"foobaz\"\nbaz\" \"foo\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-26\nArvind\nDeducing Types\n1. Assign types to every subexpression\nx :: t0\nf :: t1\nf x :: t2\nf (f x) :: t3\ntwice :: t1\n> t3)\ntwice f x = f (f x)\nWhat is the most \"general type\" for twice?\n2. Set up the constraints\nt1 = t0 -> t2\nbecause of (f x)\nt1 = t2 -> t3\nbecause of f (f x)\n3. Resolve the constraints\nt0 -> t2 = t2 -> t3\nt0 = t2 and t2 = t3\nt0 = t2 = t3\ntwice :: (t0\n(t0 -> t0)\n-> (t0 -\n-> t0) ->\n\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL2-27\nArvind\nAnother Example: Compose\ncompose f g x = f (g x)\nWhat is the type of compose ?\n1. Assign types to every subexpression\nx :: t0\nf :: t1\ng :: t2\ng x :: t3\nf (g x) :: t4\ncompose ::\nL2-28\nArvind\nHindley-Milner Type System\npH and most modern functional languages follow\nthe Hindley-Milner type system.\nThe main source of polymorphism in this system\nis the Let block.\nThe type of a variable can be instantiated\ndifferently within its lexical scope.\nmuch more on this later ...\nSeptember 9, 2002\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L03LambdaCalculusPrint.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/7814103283d8bfe5bb35ecc8fb552124_L03LambdaCalculusPrint.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL3\nArvind\nLaboratory for Computer Science\nM.I.T.\nλ-calculus:\nA Basis for Functional Languages\nSeptember 11, 2002\n- 1\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3\nArvind\nFunctions\nf may be viewed as\n- a set of ordered pairs < d , r > where d ε D\nand r ε R\n- a method of computing value r corresponding\nto argument d\nsome important notations\n- λ-calculus (Church)\n- Turing machines (Turing)\n- Partial recursive functions\n...\n.\n.\n.\nDomain\nRange\nf : D →?R\n-2\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3\nArvind\nThe λ-calculus:\na simple type-free language\n- to express all computable functions\n- to directly express higher-order functions\n- to study evaluation orders, termination,\nuniqueness of answers...\n- to study various typing systems\n- to serve as a kernel language for functional\nlanguages\n- However, λ-calculus extended with constants and let-\nblocks is more suitable\n-3\nL3-4\nArvind\nλ-notation\n- a way of writing and applying functions\nwithout having to give them names\n- a syntax for making a function expression\nfrom any other expression\n- the syntax distinguishes between the\ninteger \"2\" and the function \"always_two\"\nwhich when applied to any integer returns 2\nalways_two x = 2;\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3\nArvind\nPure λ-calculus: Syntax\nvariable abstraction\napplication\nE = x | λx.E | E E\n1. application\nE1 E2\nfunction\nargument\n- application is left associative\nE1 E2 E3 E4 ≡ ((( E1 E2 ) E3 ) E4 )\n2. abstraction\nλx.E\nbound variable\nbody\nor formal parameter\n- the scope of the dot in an abstraction extends as\nfar to the right as possible\nλx.x y ≡ λx.(x y) ≡?(λx.(x y)) ≡ ( λx.x y) ?=λx.x) y\n-5\n??\n(\nL3-6\nArvind\nFree and Bound Variables\n-\nλ-calculus follows lexical scoping rules\n- Free variables of an expression\nFV(x)\n= {x}\nFV(E1 E2) = FV(E1) U FV(E2)\nFV(λx.E) = FV(E) - {x}\n- A variable occurrence which is not free in an\nexpression is said to be a bound variable of\nthe expression\n- combinator: a λ-expression without free\nvariables,\naka closed λ-expression\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3\nArvind\nß-substitution\n( λx.E) Ea → E[Ea /x]\nreplace all free occurrences of x in E with Ea\nE[A/x] is defined as follows by case on E:\nvariable\ny[Ea/x]= Ea\nif x ≡ y\ny[Ea/x]= y\notherwise\napplication\n(E1 E2 )[Ea/x] = (E1[Ea/x] E2[Ea/x])\nabstraction\n( λy.E1)[Ea/x] = λy.E1\nif x ≡ y\n( λy.E1)[Ea/x] = ?λz.((E1[z/y])[Ea/x]) otherwise\nwhere z ∈?FV(E1) U FV(Ea) U FV(x)\n-7\nL3-8\nArvind\nß-substitution: an example\n( λp.p (p q)) [(a p b) / q]\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3\nArvind\nλ-Calculus as a Reduction System\nSyntax\nE = x |?λx.E | E E\nReduction Rule\nα?-rule: λx.E → λy.E [y/x]\nif y ∈ FV(E)\nβ?-rule: ( λx.E) Ea → ?E [Ea/x]\nη rule: ( λx.E x) → E\nif x ∈ FV(E)\nRedex\n( λx.E) Ea\nNormal Form\nAn expression without redexes\n-9\nL3-10\nArvind\nα and η Rules\nα -rule says that the bound variables can be\nrenamed systematically:\n(λx.x (λx.a x)) b ≡ (λy.y (λx.a x)) b\nη-rule can turn any expression, including a\nconstant, into a function:\nλx.a x\n→η\na\nη -rule does not work in the presence of types\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-11\nArvind\nA Sample Reduction\nC\nx.λy.λf.f x y\nH ≡ λf.f (λx.λy. x)\nT ≡ λf.f (λx.λy. y)\nWhat is H (C a b)\n?\n≡ λ\nL3-12\nArvind\nIntegers: Church's Representation\n0 ≡ λx.λy. y\n1 ≡ λx.λy. x y\n2 ≡ λx.λy. x (x y)\n...\nn ≡ λx.λy. x (x...(x y)...)\nsucc ?\nIf n is an integer, then (n a b) gives n\nnested a's followed by b\n⇒\nthe successor of n should be a (n a b)\nsucc\n≡ λn.λa.λb.a (n a b)\nplus\n≡ λm.λn.m succ n\nmul\n≡\n?\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-13\nArvind\nBooleans and Conditionals\nTrue\nx.λy.x\nFalse\nx.λy.y\nzero?\n≡ λn. n (λy.False) True\nzero? 0\n?\nzero? 1\n?\ncond\nb.λx.λy. b x y\ncond True\nE1 E2\n?\ncond False E1 E2\n?\n≡ λ\n≡ λ\n≡λ\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-14\nArvind\nRecursion ?\n- Assuming suitable combinators, fact can\nbe rewritten as:\nfact = λn. cond (zero? n) 1 (mul n (fact (sub n 1)))\n- How do we get rid of the fact on the RHS?\nfact n = if (n == 0) then 1\nelse n * fact (n-1)\n\n------\n------\n------\n------\n------\n-----------\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-15\nArvind\nChoosing Redexes\n1. ((λx.M) A) ((λx.N) B)\nρ1\nρ2\n2. ((λx.M) ((λy.N)B))\n------ ρ2\n------------- ρ1\nDoes ρ1 followed by ρ2?produce the same\nexpression as ρ2 followed by ρ1?\nNotice in the second example ρ1 can destroy\nor duplicate ρ2 .\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-16\nArvind\nChurch-Rosser Property\nA reduction system is said to have the\nChurch-Rosser property, if E\nE1 and\nE\nE2 then there exits a E3 such that\nE1\nE3 and E2\nE3.\nE\nE1\nE2\nE3\nalso known as CR or Confluence\nTheorem: The λ-calculus is CR.\n(Martin-Lof & Tate)\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-17\nArvind\nInterpreters\nAn interpreter for the λ-calculus is a program to\nreduce λ-expressions to \"answers\".\nIt requires:\n- the definition of an answer\n- a reduction strategy\n- a method to choose redexes in an expression\n- a criterion for terminating the reduction\nprocess\nL3-18\nArvind\nDefinitions of \"Answers\"\n- Normal form (NF): an expression without redexes\n- Head normal form (HNF):\nx is HNF\n( λx.E) is in HNF if E is in HNF\n(x E1 ... En) is in HNF\nSemantically most interesting- represents the\ninformation content of an expression\n- Weak head normal form (WHNF):\nAn expression in which the left most application is not a\nredex.\nx is in WHNF\n( λx.E) is in WHNF\n(x E1 ... En) is in WHNF\nPractically most interesting ⇒?\"Printable Answers\"\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\n------\n------------\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-19\nArvind\nReduction Strategies\nThere are many methods of choosing redexes\nin an expression\n((λx.M) ((λy.N)B))\n------ ρ2\n-------------- ρ1\n- applicative order: left most innermost redex\n- would reduce ρ2 before ρ1\n- normal order: left most (outermost) redex\n- would reduce ρ1 before ρ2\nL3-20\nArvind\nFacts\n1. Every λ-expression does not have an answer\ni.e., a NF or HNF or WHNF\n( λx. x x) (λx. x x) = Ω\nΩ →\n2. CR implies that if NF exists it is unique\n3. Even if an expression has an answer, not all\nreduction strategies may produce it\n( λx.λy. y) Ω\nleftmost redex:\n( λx.λy. y) Ω → λy. y\ninnermost redex: ( λx.λy. y) Ω →\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-21\nArvind\nNormalizing Strategy\nA reduction strategy is said to be normalizing\nif it terminates and produces an answer of an\nexpression whenever the expression has an\nanswer.\naka the standard reduction\nTheorem: Normal order (left most) reduction\nstrategy is normalizing for the?λ-calculus.\nL3-22\nArvind\nA Call-by-name Interpreter\nAnswers:\nWHNF\nStrategy:\nleftmost redex\ncn(E):\nDefinition by cases on E\nE = x | ?λx. E | E E\ncn(x)\n= x\ncn( λx.E) = λx.E\ncn(E1 E2) = let f = cn(E1)\nin\ncase f of\nλx. E3 = cn(E3[E2/x])\n_\n= (f E2)\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL3-23\nArvind\nA Call-by-value Interpreter\nAnswers:\nWHNF\nStrategy:\nleftmost-innermost redex but not\ninside a λ-abstraction\ncv(E):\nDefinition by cases on E\nE = x | ?λx. E | E E\ncv(x)\n= x\ncv( λx.E) = λx.E\ncv( E1 E2 ) = let f = cv(E1)\na = cv(E2)\nin\ncase f of\nλx. E3 = cv(E3[a/x])\n_\n= (f a)\nL3-24\nArvind\nMore Facts\nFor computing WHNF\nthe call-by-name interpreter is normalizing\nbut the call-by-value interpreter is not\ne.g.\n( λx.y) (( λx.x x) ( λx.x x))\nSeptember 11, 2002\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L04LambdaLetPrint.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/3fc2219b2a501484afc77fb7b7be1103_L04LambdaLetPrint.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL3\nArvind\nLaboratory for Computer Science\nM.I.T.\nA λ-calculus with Constants and\nLet-blocks\nSeptember 16, 2002\n- 1\nL4-2\nArvind\nInterpreters\nAn interpreter for the λ-calculus is a program to\nreduce λ-expressions to \"answers\".\nTwo common strategies\n- applicative order: left-most innermost redex\naka call by value evaluation\n- normal order: left-most (outermost) redex\naka call by name evaluation\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4\nArvind\nA Call-by-value Interpreter\nAnswers:\nWHNF\nStrategy:\nleftmost-innermost redex but not\ninside a λ-abstraction\ncv(E):\nDefinition by cases on E\nE = x | ?λx.E | E E\ncv(x)\n= x\ncv( λx.E) = λx.E\ncv( E1 E2 ) = let f = cv(E1)\na = cv(E2)\nin\ncase f of\nλx.E3 = cv(E3[a/x])\n_\n= (f a)\n-3\nL4-4\nArvind\nA Call-by-name Interpreter\nAnswers:\nWHNF\nStrategy:\nleftmost redex\ncn(E):\nDefinition by cases on E\nE = x | ?λx.E | E E\ncn(x)\n= x\ncn( λx.E) = λx.E\ncn(E1 E2) = let f = cn(E1)\nin\ncase f of\nλx.E3\n= cn(E3[E2/x])\n_\n= (f E2)\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4\nArvind\nNormalizing Strategy\nA reduction strategy is said to be normalizing\nif it terminates and produces an answer of an\nexpression whenever the expression has an\nanswer.\naka the standard reduction\nTheorem: Normal order (left most) reduction\nstrategy is normalizing for the?λ-calculus.\n-5\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4\nArvind\nExample\nFor computing WHNF\nthe call-by name interpreter is normalizing\nbut the call-by-value interpreter is not\n( λx.y) (( λx.x x) ( λx.x x))\ncall by value\nreduction\ncall by name\nreduction\n-6\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4\nArvind\nλ-calculus with Constants\nE ::= x | λx.E | E E\n| Cond (E, E, E)\n| PFk(E1,...,Ek)\n| CN0\n| CNk(E1,...,Ek)\nPF1 ::= negate | not | ... | Prj1| Prj2 | ...\nPF2 ::= + | ...\nCN0 ::= Number | Boolean\nCN2 ::= cons | ...\nIt is possible to define integers, booleans, and\nfunctions on them in the pure λ-Calculus but the\nλ-calculus extended with constants is more\nuseful as a programming language\n-7\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4\nArvind\nPrimitive Functions and Constructors\nδ-rules\n+( n, m ) →\nn+m\n...\nCondrules\nCond(True, e1, e2 )\n→ e1?\nCond(False, e1, e2 )\n→ e2\nProjection rules\nPrji(CNk (e1,...,ek ))\n→ ei\nλ-calculus with constants is confluent provided\nthe new reduction rules are confluent\n-8\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4\nArvind\nConstants and the η-rule\n-\nη-rule no longer works for all expressions:\n3 = λx.(3 x)\none cannot treat an integer as a function !\n-\nη-rule is not useful if does not apply to all\nexpressions because it is trivially true for λ-\nabstractions\nassuming x ∈ FV(λy.M), is\nλx.(λy.M x) = λy.M\n?\nλx.(λy.M x)\n→\n-9\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-10\nArvind\nRecursion\n- fact can be rewritten as:\nfact = λn. Cond (Zero? n) 1 (Mul n (fact (Sub n 1)))\n- How to get rid of the fact on the RHS?\nfact n = if (n == 0) then 1\nelse n * fact (n-1)\nIdea: pass fact as an argument to itself\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-11\nArvind\nSelf-application and Paradoxes\nSelf application, i.e., (x x) is dangerous.\nSuppose:\nu ≡ λy. if (y y) = a then b else a\nWhat is (u u) ?\nL4-12\nArvind\nRecursion and Fixed Point Equations\nRecursive functions can be thought of as\nsolutions of fixed point equations:\nfact = λn. Cond (Zero? n) 1 (Mul n (fact (Sub n 1)))\nSuppose\nH\n= λf.λn.Cond (Zero? n) 1 (Mul n (f (Sub n 1)))\nthen\nfact = H fact\nfact is a fixed point of function H!\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-13\nArvind\nFixed Point Equations\nf : D →?D\nA fixed point equation has the form\nf(x) = x\nIts solutions are called the fixed points of f\nbecause if xp is a solution then\nxp = f(xp) = f(f(xp)) = f(f(f(xp))) = ...\nExamples: f: Int →?Int\nSolutions\nf(x) = x2 - 2\nf(x) = x2 + x + 1\nf(x) = x\nL4-14\nArvind\nLeast Fixed Point\nConsider\nf n = if n=0 then 1\nelse ( if n=1 then f 3 else f (n-2))\nH = λf.λn.Cond(n=0 , 1, Cond(n=1, f 3, f (n-2))\nIs there an f such that f = H f ?\np\np\np\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-15\nArvind\nY : A Fixed Point Operator\nNotice\nY F\n→ λx.F (x x)) (λx.F (x x))\n→\nY ≡ λf.(λx. (f (x x))) (λx.(f (x x)))\n?(\nL4-16\nArvind\nMutual Recursion\nodd n = if n==0 then False else even (n-1)\neven n = if n==0 then True else odd (n-1)\nodd\n= H1 even\neven\n= H2 odd\nwhere\nH\nH1 = λf.λn.Cond(n=0, False, f(n-1))\n2 = λf.λn.Cond(n=0, True, f(n-1))\nsubstituting \"H2 odd\" for even\nodd\n= H1 (H2 odd)\n= H odd\nwhere H =\n⇒ ?odd\n= Y H\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-17\nArvind\nλ-calculus with Combinator Y\nRecursive programs can be translated into the\nλ-calculus with constants and Y combinator.\nHowever,\n- Y combinator violates every type discipline\n- translation is messy in case of mutually\nrecursive functions\n⇒\nextend the λ-calculus with recursive let\nblocks.\nL4-18\nArvind\nλlet: A λ-calculus with Letrec\nExpressions\nE ::= x | λx.E | E E | let S in E\nStatements\nS ::= ε | x = E | S; S\n\" ; \" is associative and commutative\nS\nS1 ; S2 ≡ S2 ; S1\n1 ; (S2 ; S3) ≡ (S1 ; S2 ) ; S3\nε ; S ≡?S\nlet ε in E ≡ E\nVariables on the LHS in a let expression must\nbe pairwise distinct\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-19\nArvind\nα Renaming\nNeeded to avoid the capture of free variables.\nAssuming t is a new variable\nλx.e\n≡ λt.(e[t/x])\nlet x = e ; S in e0\n≡ let t = e[t/x] ; S[t/x] in e0[t/x]\nwhere S[t/x] is defined as follows:\nε[t/x]\n=\nε\n(y = e)[t/x]=\n?(y = e[t/x])\n(S1; S2)[t/x]=?\n(S1[t/x]; S2[t/x])\n( let S in e)[t/x]\n( let S in e)\nif x ∈ FV(let S in e)\n( let S[t/x] in e[t/x]) if x ∈ FV(let S in e)\n= ?\nL4-20\nArvind\nThe β-rule\nThe normal β-rule\n( λx.e) ea → ? e [ea/x]\nis replaced the following β-rule\n( λx.e) ea → ? let t = ea in e[t/x]\nwhere t is a new variable\nand the Instantiation rules which are used for\nsubstitution\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-21\nArvind\nλlet Instantiation Rules\nA free variable in an expression can be instantiated\nby a simple expression\nV ::= λx.E\nvalues\nSE ::= x | V\nsimple expression\n(x = a ; SC[x]) → (x = a ; SC'[a])\nx = a\n→ x = C'[C[x]]\nwhere a = C[x]\nsimple expression\nfree occurrence\nof x in some\ncontext C\nrenamed C[ ] to\navoid free-\nvariable capture\nInstantiation rules\nlet x = a ; S in C[x] →\nlet x = a ; S in C'[a]\nL4-22\nArvind\nLifting Rules: Motivation\nlet\nf = let S1 in λx.e1\ny = f a\nin\n((let S2 in λx.e2) e3)\nHow do we juxtapose\n( λx.e1) a\nor\n( λx.e2) e3\n?\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-23\nArvind\nLifting Rules\nIn the following rules (let S' in e') is the α?-\nrenaming of (let S in e) to avoid name conflicts\nx = let S in e\n→\nx = e'; S'\nlet S1 in ( let S in e) →\nlet S1; S' in e'\n( let S in e) e1\n→\nlet S' in e' e1\nCond((let S in e), e1, e2)\n→ let S' in Cond(e', e1, e2)\nPFk (e1,...,(let S in e),...,ek )\n→ let S' in PFk (e1,...,e',...,ek)\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-24\nArvind\nDatastructure Rules\nCNk(e1,...,ek )\n→ let t 1 = e1; ... ; t k = ek in CNk(t1,...,t k )\nPrji( CNk(a1,...,ak ))\n→ ai\n\nL4-25\nArvind\nConfluenence and Letrecs\nodd\n= λn.Cond(n=0, False, even (n-1))\n(M)\neven = λn.Cond(n=0, True, odd (n-1))\nsubstitute for even (n-1) in M\nodd\n= λn.Cond(n=0, False,\nCond(n-1 = 0 , True, odd ((n 1)-1)))\n(M1)\neven = λn.Cond(n=0, True, odd (n 1))\nsubstitute for odd (n-1) in M\nodd\n= λn.Cond(n=0, False, even (n-1))\n(M2)\neven = λn.Cond(n=0, True,\nCond( n-1 = 0 , False, even ((n-1)-1)))\nM1 and M2 cannot be reduced to the same expression!\nProposition: λlet is not confluent.\nAriola & Klop 1994\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nSeptember 16, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL4-26\nArvind\nContexts for Expressions\nExpression Context for an expression\nC[] ::= []\n| λx.C[]\n| C[] E | E C[]\n| let S in C[]\n| let SC[] in E\nStatement Context for an expression\nSC[] ::= x = C[]\n| SC[] ; S | S; SC[]"
    },
    {
      "category": "Resource",
      "title": "L05LambdaLet2Print.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/9921f4e50b3d1fc57c36aaf07adffdad_L05LambdaLet2Print.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL5\nArvind\nLaboratory for Computer Science\nM.I.T.\nA λ-calculus with Let-blocks\n(continued)\nSeptember 18, 2002\n- 1\nL5-2\nArvind\nOutline\n- The λlet Calculus\n- Some properties of the λlet Calculus\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5\nArvind\nλ-calculus with Letrec\nE ::= x | λx.E | E E\n| Cond (E, E, E)\n| PFk(E1,...,Ek)\n| CN0\n| CNk(E1,...,Ek) | CNk(SE1,...,SEk)\n| let S in E\nPF1 ::= negate | not | ... | Prj1| Prj2 | ...\nPF2 ::= + | ...\nCN0 ::= Number | Boolean\nCN2 ::= cons | ...\nStatements\nS ::= ε | x = E | S; S\nVariables on the LHS in a let expression must be\npairwise distinct\nnot in\ninitial\nterms\n-3\nL5-4\nArvind\nLet-block Statements\n\" ; \" is associative and commutative\nS\nS1 ; S2\n≡ S2 ; S1\n1 ; (S2 ; S3)\n≡ (S1 ; S2 ) ; S3\nε ; S\n≡?S\nlet ε in E\n≡ E\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5\nArvind\nFree Variables of an Expression\nFV(x)\n= {x}\nFV(E1 E2)\n= FV(E1) U FV(E2)\nFV(λx.E)\n= FV(E) - {x}\nFV(let S in E) = FVS(S) U FV(E) - BVS(S)\nFVS(ε)\n= {}\nFVS(x = E; S)= FV(E) U FVS(S)\nBVS(ε)\n= {}\nBVS(x = E; S)= {x} U BVS(S)\n-5\nL5-6\nArvind\nα -Renaming (to avoid free variable capture)\nAssuming t is a new variable, rename x to t :\nλx.e\n≡ λt.(e[t/x])\nlet x = e ; S in e0\n≡ let t = e[t/x] ; S[t/x] in e0[t/x]\nwhere [t/x] is defined as follows:\nx[t/x]\n= t\ny[t/x]\n= y\nif x = y\n(E1 E2 )[t/x]\n= (E1[t/x] E2[t/x])\n( λx.E)[t/x]\n= λx.E\n( λy.E)[t/x]\n= ?λy.E[t/x]\nif x = y\n( let S in E)[t/x]\n= ?\n( let S in E)\nif x ∈ FV(let S in E)\n( let S[t/x] in E[t/x]) if x ∈ FV(let S in E)\nε[t/x]\n=\nε\n(y = E)[t/x]\n=\n?(y = E[t/x])\n(S1; S2)[t/x] = ?\n(S1[t/x]; S2[t/x])\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5\nArvind\nPrimitive Functions and\nDatastructures\nδ-rules\n+( n, m )\n→\nn+m\n...\nCondrules\nCond(True, e1, e2 )\n→ e1?\nCond(False, e1, e2 )\n→ e2\nData-structures\nCNk (e1,...,ek )\n→\nlet t 1 = e1; ... ; t k = ek\nin CNk(t1,...,t k )\nPrji( CNk (a1,...,ak ))\n→ ai\n-7\nL5-8\nArvind\nThe β-rule\nThe normal β-rule\n( λx.e) ea → ?e [ea/x]\nis replaced the following β-rule\n( λx.e) ea → ?let t = ea in e[t/x]\nwhere t is a new variable\nand the Instantiation rules which are used to\nrefer to the value of a variable\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5\nArvind\nValues and Simple Expressions\nValues\nV ::= λx.E | CN0 | CNk(SE1,...,SEk )\nSimple expressions\nSE ::= x | V\n-9\nL5-10\nArvind\nContexts for Expressions\nA context is an expression (or statement) with a\n\"hole\" such that if an expression is plugged in\nthe hole the context becomes a legitimate\nexpression:\nC[] ::= []\n| λx.C[]\n| C[] E | E C[]\n| let S in C[]\n| let SC[] in E\nStatement Context for an expression\nSC[] ::= x = C[]\n| SC[] ; S | S; SC[]\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-11\nArvind\nλlet Instantiation Rules\nA free variable in an expression can be instantiated\nby a simple expression\nInstantiation rule 2\n(x = a ; SC[x]) → (x = a ; SC'[a])\nsimple expression\nfree occurrence\nof x in some\ncontext C\nrenamed C[ ] to\navoid free-\nvariable capture\nInstantiation rule 1\n( let x = a ; S in C[x]) → ( let x = a ; S in C'[a])\nInstantiation rule 3\nx = a\n→ x = C'[C[x]]\nwhere a = C[x]\nL5-12\nArvind\nLifting Rules: Motivation\nlet\nf = let S1 in λx.e1\ny = f a\nin\n((let S2 in λx.e2) e3)\nHow do we juxtapose\n( λx.e1) a\nor\n( λx.e2) e3\n?\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-13\nArvind\nLifting Rules\n( let S' in e') is the α?-renamed ( let S in e) to\navoid name conflicts in the following rules:\nx = let S in e\n→\nx = e'; S'\nlet S1 in ( let S in e) →\nlet S1; S' in e'\n( let S in e) e1\n→\nlet S' in e' e1\nCond((let S in e), e1, e2)\n→ let S' in Cond(e', e1, e2)\nPFk (e1,...,(let S in e),...,ek )\n→ let S' in PFk (e1,...,e',...,ek)\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-14\nArvind\nOutline\n- The λlet Calculus\n- Some properties of the λlet Calculus\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-15\nArvind\nConfluenence and Letrecs\nodd\n= λn.Cond(n=0, False, even (n 1))\n(M)\neven = λn.Cond(n=0, True, odd (n 1))\nsubstitute for even (n1) in M\nodd\n= λn.Cond(n=0, False,\nCond(n-1 = 0 , True, odd ((n 1)-1)))\n(M1)\neven = λn.Cond(n=0, True, odd (n 1))\nsubstitute for odd (n1) in M\nodd\n= λn.Cond(n=0, False, even (n 1))\n(M2)\neven = λn.Cond(n=0, True,\nCond( n 1 = 0 , False, even ((n 1)-1)))\nCan odd in M1 and M2 be reduced to the same expression ?\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-16\nArvind\nλ versus λlet Calculus\nTerms of the λlet calculus can be translated into\nterms of the λ calculus by systematically\neliminating the let blocks. Let T be such a\ntranslation.\nSuppose e\ne1 in λlet then does there exist a\nreduction such that T[[e]]\nT[[e1]] in λ ?\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-17\nArvind\nInstantaneous Information\n\"Instantaneous information\" (info) of a term is\ndefined as a (finite) trees\nTP\n::=\n| λ?| CN0 | CNk (TP1,...,TPk)\nInfo:\nE → TP\nInfo[{S in E}]\n= Info [E]\nInfo[λx.E]\n= λ\nInfo[CN0]\n= CN0\nInfo[CNk(a1,...,ak)]\n= CNk(Info[a1],...,Info[ak ])\nInfo[E]\n=\notherwise\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nProposition Reduction is monotonic wrt Info:\nIf e\ne1 then Info[e] ≤ Info[e1].\nProposition Confluence wrt Info:\nIf e\ne1 and e\ne2 then\n∃ e3 s.t. e1\ne3 and Info[e2] ≤ Info[e3].\nL5-18\nArvind\nReduction and Info\nTerms can be compared by their Info value\n⊥\n≤\nt\n(bottom)\nt\n≤\nt\n(reflexive)\nCNk(v1,...,v ,...,vk) ≤ CNk(v1,...,v' ,...,vk)\ni\ni\nif vi ≤?v'i\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-19\nArvind\nPrint: Unwinding of a term\nPrint :\nE → {TP}\nUnwind a term as much as possible using the\nfollowing instantiation rule (Inst):\n( let x = v; S in C[x]) → ?(let x = v; S in C[v])\nand keep track of all the unwindings\nPrint[e] = {Info[e1] | e\ne1 using the Inst rule} ?\nTerms with infinite unwindings lead to infinite sets.\nL5-20\nArvind\nGarbage Collection\nLet-blocks often contain bindings that are not\nreachable from the return expression, e.g.,\nlet x = e in 5\nSuch bindings can be deleted without affecting\nthe \"meaning\" of the term.\nGC-rule\n( let SG; S in e) → ( let S in e)\nprovided ∀ x.(x ∈ (FV(e) U FVS(S))\n⇒ x ∈ BVS(SG)\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL5-21\nArvind\nUnrestricted Instantiation\nλlet instantiation rules allow only values & variables\nto be substituted. Let λ0 be a calculus that permits\nsubstitution of arbitrary expressions:\nUnrestricted Instantiation Rules of λ0\nlet x = e; S in C[x]\n→ let x = e; S in C'[e]\n(x = e; SC[x])\n→ (x = e; SC'[e])\nx = e\n→ x = C'[e]\nwhere e ≡ C[x]\nIs λ0 more expressive than λlet ?\nL5-22\nArvind\nSemantic Equivalence\n- What does it mean to say that two terms\nare equivalent?\n- Do any of the following equalities imply\nsemantic equivalence of e1 and e2\nSyntactic equality of α-convertability: e1 = e2\nPrint equality:\nPrint(e1) = Print(e2)\nNo observable difference in any context:\nSeptember 18, 2002\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L06HindleyMilnerPrint.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/d1b3ee33fab681428c7980b94cb11ffd_L06HindleyMilnerPrint.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL6\nArvind\nLaboratory for Computer Science\nM.I.T.\nThe Hindley-Milner Type System\nSeptember 25, 2002\n- 1\nL6-2\nArvind\nOutline\n- General issues\n- Type instances\n- Type Unification\n- Type Generalization\n- A formal type system\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6\nArvind\nWhat are Types?\n- A method of classifying objects (values) in\na language\nx :: τ?\nsays object x has type τ??or object x\nbelongs to a type τ?\n-\nτ denotes a set of values.\nThis notion of types is different from languages\nlike C, where a type is a storage class specifier.\n-3\nL6-4\nArvind\nType Correctness\n- If x :: τ, then only those operations that are\nappropriate to set τ may be performed on x.\n- A program is type correct if it never performs\na wrong operation on an object.\n- Add an Int and a Bool\n- Head of an Int\n- Square root of a list\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6\nArvind\nType Safety\n- A language is type safe if only type\ncorrect programs can be written in that\nlanguage.\n- Most languages are not type safe, i.e.,\nhave \"holes\" in their type systems.\nFortran: Equivalence, Parameter passing\nPascal: Variant records, files\nC, C++: Pointers, type casting\nHowever, Java, CLU, Ada, ML, Id, Haskell, pH\netc. are type safe.\n-5\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6\nArvind\nType Declaration vs Reconstruction\n- Languages where the user must declare the types\n- CLU, Pascal, Ada, C, C++, Fortran, Java\n- Languages where type declarations are not needed\nand the types are reconstructed at run time\n- Scheme, Lisp\n- Languages where type declarations are generally not\nneeded but allowed, and types are reconstructed at\ncompile time\n- ML, Id, Haskell, pH\nA language is said to be statically typed if type-checking\nis done at compile time\n-6\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6\nArvind\nPolymorphism\n- In a monomorphic language like Pascal,\none defines a different length function for\neach type of list\n- In a polymorphic language like ML, one\ndefines a polymorphic type (list t), where t\nis a type variable, and a single function\nfor computing the length\n- pH and most modern functional languages\nhave polymorphic objects and follow the\nHindley-Milner type system.\n-7\nL6-8\nArvind\nType Instances\nThe type of a variable can be instantiated\ndifferently within its lexical scope.\nlet\nid = \\x.x\nin\n((id1 5), (id2 True))\nid1 ::\n?\nid2 ::\n?\nBoth id1 and id2 can be regarded as instances of type\n?\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6\nArvind\nType Instances: another example\ntwice1 ::\n?\ntwice2 ::\n?\nlet\ntwice :: (t -> t) -> t -> t\ntwice f x = f (f x)\nin\ntwice1 twice2(plus 3) 4\n-9\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-10\nArvind\nType Instantiation:\nλ-bound vs Let-bound Variables\nOnly let-bound identifiers can be instantiated\ndifferently.\nlet\ntwice f x = f (f x)\nin\ntwice twice (plus 3) 4\nvs.\nlet\ntwice f x = f (f x)\nfoo g = (g g (plus 3)) 4\nin\nfoo twice\nGeneric vs. Non-generic type variables\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-11\nArvind\nA mini Language\nto study Hindley-Milner Types\n- There are no types in the syntax of the language!\n- The type of each subexpression is derived by the\nHindley-Milner type inference algorithm.\nExpressions\nE ::= c\nconstant\n| x\nvariable\n| ??\nλx. E\nabstraction\n| (E1 E2)\napplication\n| let x = E1 in E2\nlet-block\nTypes\nτ ::= ι\nbase types (Int, Bool ..)\n| t\ntype variables\n| τ1 ? --> τ2\nFunction types\nL6-12\nArvind\nType Inference Issues\n- What does it mean for two types τa ?and τb to be equal?\n- Structural Equality\nSuppose τ =\n--> τ2\nτ\na\nτ1\nb =\n--> τ4\nτ3 ?\nIs τ = τb ?\na\n- Can two types be made equal by choosing appropriate\nsubstitutions for their type variables?\n- Robinson's unification algorithm\nSuppose τ\n--> Bool\nτ\na = t 1\nb = Int ? --> t2\nAre τ and τb unifiable ?\na\nSuppose τ = t 1--> Bool\nτ\na\nb = Int ? --> Int\nAre τ and τb unifiable ?\na\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-13\nArvind\nSimple Type Substitutions\nA substitution is a map\nS : Type Variables --> Types\nS = [τ?/ t1,..., τn ?/ t n]\nτ' = S τ\nτ' is a Substitution Instance of τ\nExample:\nS = [(t --> Bool) / t1]\nS( t1 --> t1) =\n?\nTypes\nτ ::= ι\nbase types (Int, Bool ..)\n| t\ntype variables\n| τ1 ? --> τ2\nFunction types\nSubstitutions can be composed, i.e., S2 S1\nExample:\nS1 = [(t --> Bool) / t1] ; S2 = [Int / t]\nS2 S1 ( t1 --> t1) =\n?\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\ndef Unify(τ1, τ2) =\ncase ( τ1, τ2) of\n( τ1, t2) = [τ1 / t2]\n(t1, τ2) = [τ2 / t1]\n( ι1, ι2) = if ( eq? ι1 ι2) then [ ]\nelse fail\n( τ11 --> τ12, τ21 --> τ22)\n= let\nS1=Unify(τ11, τ21)\nS2=Unify(S1( τ12), S1( τ22))\nin S2 S1\notherwise = fail\nDoes the order\nmatter?\nL6-14\nArvind\nUnification\nAn essential subroutine for type inference\nUnify(τ1, τ2) tries to unify τ1 and τ2 and returns a\nsubstitution if successful\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-15\nArvind\nInferring Polymorphic Types\nConstraints:\nlet\nid = λx. x\nin\n... (id True) ... (id 1) ...\nid :: t1\n--> t1\nid :: Int --> t2\nid :: Bool --> t3\nid :: ∀1. t1 --> t1\nDifferent uses of a generalized type variable\nmay be instantiated differently\nid2 : Bool --> Bool\nid1 : Int --> Int\nSolution: Generalize the type variable:\n??\nt\nGeneralization is Restricted\nL6-16\nArvind\nf = λg. ...(g True) ... (g 1) ...\nCan we generalize the type of g to ?\n∀t 1 t 2. t1 --> t2\n?\nThere will be restrictions on g from the\nenvironment, the place of use, which may\nmake this deduction unsound (incorrect)\nOnly generalize \"new\" type variables, the\nvariables on which all the restrictions are\nvisible.\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-17\nArvind\nA Formal Type System\nNote, all the ∀'s occur in the beginning of a type scheme,\ni.e., a type τ cannot contain a type scheme σ\nA type τ?is said to be polymorphic if it contains a type\nvariable\nTypes\nτ? ::= ι\nbase types\n| t\ntype variables\n| τ\n?? --> τ2\nFunction types\nType Schemes\nσ ::= τ?\n| ∀ t. σ?\nType Environments\nTE ::= Identifiers --> Type Schemes\n{ + :: Int --> Int --> Int,\nf\n:: ∀ t. t --> t --> Bool }\nExample TE\nL6-18\nArvind\nFree and Bound Variables\nσ = ?∀t 1..t . τ\nn\nBV(σ)\n= { t1,..., t }\nn\nFV(σ)\n= {type variables of τ} - { t1,..., t }\nn\nThe definitions extend to Type Environments in an\nobvious way\nExample:\nσ ? = ∀?t 1. (t1 --> t2)\nFV(σ) =\nBV(σ) =\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-19\nArvind\nType Substitutions\nA substitution is a map\nS : Type Variables --> Types\nS = [τ?/ t1?????????\n,..., τn ?/ t n]\nτ' = S τ\nτ' is a Substitution Instance of τ\nσ' = S σ\nApplied only to FV(σ), with renaming of BV(σ)\nas necessary\nsimilarly for Type Environments\nExamples:\nS = [(t2 --> Bool) / t1]\nS( t1 --> t1)\n= ( t2 --> Bool) --> ( t2 --> Bool)\nS( ∀t 1.t1 --> t2) =\n?\nS( ∀t 2.t1 --> t2) =\n?\nSubstitutions can be composed, i.e., S2 S1\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-20\nArvind\nInstantiations\n- Type scheme σ can be instantiated into a type τ' by\nsubstituting types for BV(σ), that is,\nτ' = S τ\nfor some S s.t. Dom(S) ⊆ BV(σ)\n-?τ' is said to be an instance of σ ( σ > τ')\n- τ' is said to be a generic instance of σ?when S\nmaps variables to new variables.\nσ = ∀ t 1..t n. τ\nExample:\nσ = ∀ t 1. t1 --> t2\na generic instance of σ?is\n?\n\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL6-21\nArvind\nGeneralization aka Closing\n- Generalization introduces polymorphism\n- Quantify type variables that are free in τ?\nbut not free in the type environment (TE)\n- Captures the notion of new type variables\nof τ\nGen(TE,τ) = ∀ t 1..t n. τ\nwhere { t1...t n } = FV(τ) - FV(TE)\nL6-22\nArvind\nType Inference\n- Type inference is typically presented in two\ndifferent forms:\n- Type inference rules: Rules define the type of each\nexpression\n- Needed for showing that the type system is sound\n- Type inference algorithm: Needed by the compiler\nwriter to deduce the type of each subexpression or to\ndeduce that the expression is ill typed.\n- Often it is nontrivial to derive an inference\nalgorithm for a given set of rules. There can be\nmany different algorithms for a set of typing rules.\nnext lecture ...\nSeptember 25, 2002\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L07HindleyMilner2Print.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/a981df4e1fd91ddf5cf7c1a15c5d1b03_L07HindleyMilner2Print.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL7\nArvind\nLaboratory for Computer Science\nM.I.T.\nThe Hindley-Milner Type System\n( Continued)\nSeptember 30, 2002\n- 1\nL7-2\nArvind\nOutline\n- Hindley-Milner Type inference rules\n- Type inference algorithm\n- Overloading\n- Type classes\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7\nArvind\nA mini Language\nto study Hindley-Milner Types\n- There are no types in the syntax of the language!\n- The type of each subexpression is derived by the\nHindley-Milner type inference algorithm.\nExpressions\nE ::= c\nconstant\n| x\nvariable\n| λx. E\nabstraction\n| (E1 E2)\napplication\n| let x = E1 in E2\nlet-block\n-3\nNote, all the ∀'s occur in the beginning of a type scheme,\ni.e., a type τ cannot contain a type scheme σ\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-4\nArvind\nA Formal Type System\nTypes\nτ ::= ι\n| t\n| τ--> τ2\nbase types\ntype variables\nFunction types\n??\nType Schemes\nσ ::= τ\n| ∀t. σ?\nType Environments\nTE ::= Identifiers --> Type Schemes\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7\nArvind\nUnification\nAn essential subroutine for type inference\ndef Unify(τ1, τ2) =\ncase ( τ1, τ2) of\n( τ1, t2) = [τ1 / t2]\n(t1, τ2) = [τ2 / t1]\n( ι1, ι2) = if ( eq? ι1 ι2) then [ ]\nelse fail\n( τ11 --> τ12, τ21 --> τ22)\n= let\nS1=Unify(τ11, τ21)\nS2=Unify(S1( τ12), S1( τ22))\nin S2 S1\notherwise = fail\nUnify(τ1, τ2) tries to unify τ1 and τ2 and returns a\nsubstitution if successful\nOrder in which sub-expressions\nare unified does not matter.\n-5\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7\nArvind\nInstantiations\n- Type scheme σ can be instantiated into a type τ' by\nsubstituting types for the bound variables of σ, i.e.,\nτ' = S τ\nfor some S s.t. Dom(S) ⊆ BV(σ)\n- τ' is said to be an instance of σ ( σ > τ')\n- τ' is said to be a generic instance of σ when S\nmaps variables to new variables.\nσ = ∀t 1...t n. τ\nExample:\nσ = ∀t 1. t1 --> t2\nt 3 --> t2 is a generic instance of σ\nInt --> t2 is a non generic instance of σ\n-6\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7\nArvind\nGeneralization aka Closing\n- Generalization introduces polymorphism\n- Quantify type variables that are free in τ\nbut not free in the type environment (TE)\n- Captures the notion of new type variables\nof τ\nGen(TE,τ) = ∀ t 1...t n. τ\nwhere { t1...t n } = FV(τ) - FV(TE)\n-7\nL7-8\nArvind\nType Inference\n- Type inference is typically presented in two\ndifferent forms:\n- Type inference rules: Rules define the type of each\nexpression\n- Needed for showing that the type system is sound\n- Type inference algorithm: Needed by the compiler\nwriter to deduce the type of each subexpression or to\ndeduce that the expression is ill typed.\n- Often it is nontrivial to derive an inference\nalgorithm for a given set of rules. There can be\nmany different algorithms for a set of typing rules.\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\n--\n--\n'\n--\n--\n--\n'\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7\nArvind\nType Inference Rules\nTyping:\nTE |-\ne : τ\nSuppose we want to assert (prove) that give some type\nenvironment TE, the expression (e1 e2) has the type τ' .\nThen it must be the case that the same TE implies that e1\nhas type τ--> τ' and e2 has the type τ .\n-9\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-10\nArvind\nType Inference Rules\nTyping:\nTE |-\ne : τ\n(App)\nTE |-- e1 : τ--> τ'\nTE |-- e2 : τ\n?\nTE |-- (e1 e2) : τ'\n(Abs)\nTE |\nλx.e : τ > τ\n( Var)\nTE |\nx : τ\n(Const)\nTE |\nc : τ\n(Let)\nTE |\n( let x = e1 in e2) : τ\n\n--\n-- e1:\n-- e2:\n--\n'\n--\n--\n-- e1\n-- e2\n--\n'\nL\nA\nGeneralization is restricted!\n7-11\nrvind\n( Var)\n(x : σ) ε TE\nσ ≥ τ\nTE |\nx : τ\n(Let)\nTE+{x:τ} |\nτ\nTE+{x:Gen(TE,τ)} |\nτ'\nTE |\n( let x = e1 in e2) : τ\n(Gen)\nTE |\ne : τ\nt ∈ FV(TE)\nTE |\ne : ∀t.τ\n(Spec)\nTE |-- e : ∀t.τ\nTE |-- e : τ [t'/t]\n( Var)\n(x : τ) ε TE\nTE |-- x : τ\n(Let)\nTE+{x:τ} |\n: τ\nTE+{x:τ} |\n: τ'\nTE |\n( let x = e1 in e2) : τ\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nContrast:\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-12\nArvind\nSoundness\n- The proposed type system is sound, i.e.\nif e : τ then e indeed evaluates to a\nvalue in τ.\n- A method of proving soundness:\n- The semantics of the language is defined in\nterms of a value space that has integer\nvalues, Boolean values etc. as subspaces.\n- Any expression with a type error evaluates to\na special value \"wrong\".\n- There is no type expression that denotes the\nsubspace \"wrong\".\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-13\nArvind\nInference Algorithm\nW(TE, e) returns (S,τ) such that S (TE) |-- e : τ\nThe type environment TE records the most\ngeneral type of each identifier while the\nsubstitution S records the changes in the type\nvariables\nDef W(TE, e) =\nCase e of\nx\n=\n...\nλx.e\n=\n...\n(e1 e2)\n=\n...\nlet x = e1 in e2 =\n...\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-14\nArvind\nInference Algorithm (cont.)\nDef W(TE, e) =\nCase e of\nx\n=\nif (x ∈?Dom(TE)) then Fail\nelse let ∀t 1...t n.τ = TE(x);\nin ( { }, [ui / t i] τ)\nλx.e\n=\nlet (S1, τ1) = W(TE + { x : u }, e);\nin (S1, S1(u) --> τ1)\n(e1 e2)\n= ...\nlet x = e1 in e2\n= ...\nu's\nrepresent\nnew type\nvariables\n\nL7-15\nArvind\nInference Algorithm (cont.)\nDef W(TE, e) =\nCase e of\nx\n=\n...\nλx.e\n=\n...\n(e1 e2)\n=\nu's\nlet\n(S1, τ1) = W(TE, e1);\nrepresent\n(S2, τ2) = W(S1(TE), e2)\nnew type\nS3 = Unify(S2( τ1), τ2 --> u); variables\nin\n(S3 S2 S1, S3(u))\nlet x = e1 in e2 =\nlet\n(S1, τ1) = W(TE + {x : u}, e1);\nS2?= Unify(S1(u), τ1);\nσ?= Gen(S2 S1(TE), S2( τ1) );\n(S3, τ2) = W(S2 S1(TE) + {x : σ}, e2);\nin\n(S3 S2 S1, τ2)\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-16\nArvind\nProperties of HM Type Inference\n- It is sound with respect to the type system.\nAn inferred type is verifiable.\n- It generates most general types of expressions.\nAny verifiable type is inferred.\n- Complexity\nPSPACE-Hard\nDEXPTIME-Complete\nNested let blocks\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-17\nArvind\nExtensions\n- Type Declarations\nSanity check; can relax restrictions\n- Incremental Type checking\nThe whole program is not given at the same\ntime, sound inferencing when types of some\nfunctions are not known\n- Typing references to mutable objects\nHindley-Milner system is unsound for a\nlanguage with refs (mutable locations)\n- Overloading Resolution\nL7-18\nArvind\nOverloading ad hoc polymorphism\nA symbol can represent multiple values each with a\ndifferent type. For example:\n+ represents\nplusInt\n:: Int -> Int -> Int\nplusFloat :: Float -> Float -> Float\nThe context determines which value is denoted.\nThe overloading of an identifier is resolved when\nthe unique value associated with the symbol in that\ncontext can be determined.\nCompiler tries to resolve overloading but sometimes\ncan't. The user must declare the type explicitly in\nsuch cases.\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-19\nArvind\nOverloading vs. Polymorphism\nBoth allow a single identifier to be used for\nmultiple types.\nHowever, two concepts are very different:\n1. All specific types of a polymorphic identifier\nare instances of a most general type.\n2. A polymorphic identifier represents a\nsingle function semantically.\nL7-20\nArvind\nThe Most General Type\nThe most general type of twice is\n∀t.(t -> t) -> (t -> t)\nAny type can be substituted for t to get an instance\nof twice:\n(Int-> Int)\n-> (Int -> Int)\n(String -> String) -> (String -> String)\nOverloaded + does not have a most general type.\nAn overloaded function may perform semantically\nunrelated operations in different contexts.\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-21\nArvind\nOverloading in Haskell\nHaskell has one of the most sophisticated\noverloading mechanism called type classes\nType classes allow overloading of user defined\nsymbols\nsqr x = x * x\nIs the type of sqr intSqr or FloatSqr ?\nintSqr\nfloatSqr\n:: Float -> Float\nIn Haskell sqrcan be overloaded and resolved\nbased on its use.\n:: Int -> Int\nL7-22\nArvind\nType Classes\nmaking overloading less ad hoc\nOften a collection of related functions (e.g., +, -,\n*) need a common overloading mechanism and\nthere is a collection of types (e.g., Int, Float) over\nwhich these functions need to be overloaded.\nType classes bring these two concepts together\nclass Num a where\n(==), (/=)\n::\na -> a -> Bool\n(+), (-), (*)\n::\na -> a -> a\nnegate\n::\na -> a\n...\ninstance Num Int where\nx == y\n= integer_eq x y\nx + y\n= integer_add x y\n...\ninstance Num Float where ...\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-23\nArvind\nOverloaded Constants\n(Num t) is read as a predicate\n\"t is an instance of class Num\"\nsqr :: (Num a) => a -> a\nsqr x = x * x\nWhat about constants? Consider\nplus1 x = x + 1\nIf 1 is treated as an integer then plus1cannot be\noverloaded. In pH numeric literals are overloaded\nand considered a short hand for\n(fromInteger the_integer_1_value)\nwhere\nfromInteger :: (Num a) => Integer -> a\nL7-24\nArvind\nThe Equality Operator\nEquality is an overloaded and not a polymorphic\nfunction\nclassEq a where\n(==)\n::\na -> a -> Bool\n(/=)\n::\na -> a -> Bool\nThus equality needs to be defined for each type of\ninterest.\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-25\nArvind\nRead and Show Functions\nThe raw input from a key board or output to the\nscreen or file is usually a string. However, different\nprograms interpret the string differently depending\nupon their type signature.\nA program to calculate monthly mortgage payments\nmay assign the following signatures:\nread :: String -> Int\n- principal, duration\nread :: String -> Float - rate\nshow :: Float -> String monthly payments\nwhat is the type of read and show ?\nread :: String\nshow :: a\n-> String\nPolymorphic ?\n-> a\nL7-26\nArvind\nOverloaded Read and Show\nHaskell has a type class Read of \"readable\" types\nand a type class Show of \"showable\" types\nread :: Read a => String -> a\nshow :: Show a => a\n-> String\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL7-27\nArvind\nAmbiguous Overloading\nidentity :: String -> String\nidentity x = show (read x)\nWhat is the type of (read x) ?\nCannot be resolved ! Many different types would do.\nCompiler requires type declarations in such cases.\nidentity :: String -> String\nidentity x = show ((read x) :: Int)\nL7-28\nArvind\nImplementation\nHow does sqr find the correct function for * ?\nsqr :: (Num a) => a -> a\nsqr x = x * x\nAn overloaded function is compiled assuming\nan extra \"dictionary\" argument.\nsqr' = \\class_inst x ->\n(class_inst.(*)) x x\nThen (sqr 23) will be compiled as\nsqr' IntClassInstance 23\nMost dictionaries can be eliminated at compile\ntime by function specialization.\nSeptember 30, 2002\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L08ListsPrint.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/a1b1d06c63ed2cbe8dd4acfc9eb83b0a_L08ListsPrint.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL8\nArvind\nLaboratory for Computer Science\nM.I.T.\nLists and Algebraic Types\nOctober 2, 2002\n- 1\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8\nArvind\nAlgebraic types\n- Algebraic types are tagged unions of products\n- Example\ndata Shape = Line\nPnt Pnt\n| Triangle Pnt Pnt Pnt\n| Quad\nPnt Pnt Pnt Pnt\nkeyword\nnew type\n- new \"constructors\" (a.k.a. \"tags\", \"disjuncts\", \"summands\")\n- a kary constructor is applied to k type expressions\n\"union\"\n\"products\" (fields)\n-2\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8\nArvind\nConstructors are functions\n- Constructors can be used as functions to\ncreate values of the type\nlet\nl1 :: Shape\nl1 = Line e1 e2\nt1 :: Shape = Triangle e3 e4 e5\nq1 :: Shape = Quad e6 e7 e8 e9\nin\n...\nwhere each \"eJ\" is an expression of type \"Pnt\"\n-3\nL8-4\nArvind\nPattern-matching on algebraic types\n- Pattern-matching is used to examine values\nof an algebraic type\nanchorPnt :: Shape -> Pnt\nanchorPnt s = case s of\nLine\np1 p2\n-> p1\nTriangle p3 p4 p5\n-> p3\nQuad\np6 p7 p8 p9 -> p6\n- A pattern-match has two roles:\n- A test: \"does the given value match this pattern?\"\n- Binding (\"if the given value matches the pattern, bind\nthe variables in the pattern to the corresponding parts\nof the value\")\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8\nArvind\nPattern-matching scope & don't cares\n- Each clause starts a new scope: can re\nuse bound variables\n- Can use \"don't cares\" for bound variables\nanchorPnt s = case s of\nLine\np1 _\n-> p1\nTriangle p1 _ _\n-> p1\nQuad\np1 _ _ _ -> p1\n-5\nanchorPnt :: Shape -> Pnt\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8\nArvind\nPattern-matching more syntax\n- Functions can be defined directly using\npattern-matching\n- Pattern-matching can be used in list\ncomprehensions (later)\nanchorPnt (Line\np1 _)\n= p1\nanchorPnt (Triangle p1 _ _)\n= p1\nanchorPnt (Quad\np1 _ _ _) = p1\n(Line p1 p2) <- shapes\n-6\nanchorPnt :: Shape -> Pnt\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8\nArvind\nPattern-matching Type safety\n- Given a \"Line\" object, it is impossible to\nread \"the field corresponding to the third\npoint in a Triangle object\" because:\n- all unions are tagged unions\n- fields of an algebraic type can only be examined\nvia pattern-matching\n-7\nL8-8\nArvind\nSpecial syntax\n- Function type constructor\nInt -> Bool\nConceptually:\nFunction Int Bool\ni.e., the arrow is an \"infix\" type constructor\n- Tuple type constructor\n(Int, Bool)\nConceptually:\nTuple2 Int Bool\nSimilarly for Tuple3, ...\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8\nArvind\nType Synonyms\ndata\nversus\ntype\n,Int)\nType Synonyms do not create new types. It is just a\nconvenience to improve readability.\nmove :: Point -\n,\n-> Point\n)\nversus\n)\n-9\nPoint = Point Int Int\nPoint = (Int\n> (Int Int)\nmove (Point x y) (sx,sy) =\nPoint (x + sx) (y + sy\nmove (x,y) (sx,sy) =\n(x + sx, y + sy\nL8-10\nArvind\nAbstract Types\nA rational number is a pair of integers but suppose we want\nto express it in the reduced form only. Such a restriction\ncannot be enforced using an algebraic type.\nmodule Rationalpackage\n(Rational,rational,rationalParts) where\ndata Rational = RatCons Int Int\nrational :: Int -> Int -> Rational\nrational x y = let\nd = gcd x y\nin RatCons (x/d) (y/d)\nrationalParts :: Rational -> (Int,Int)\nrationalParts (RatCons x y)= (x,y)\nNo pattern matching on abstract data types\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-11\nArvind\nExamples of Algebraic types\ndata Bool = False | True\ndata Day = Sun | Mon | Tue | Wed | Thu | Fri | Sat\ndata Maybe a = Nothing | Just a\ndata List a = Nil | Cons a (List a)\ndata Tree a = Leaf a | Node (Tree a) (Tree a)\ndata Tree' a b = Leaf' a\n| Nonleaf' b (Tree' a b) (Tree' a b)\ndata Course = Course String Int String (List Course)\nname number description pre reqs\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-12\nArvind\nLists\nA list data type can be constructed in two\ndifferent ways:\nan empty list\nNil\nor a non-empty list\nCons x xs\n- All elements of a list have the same type\n- The list type is recursive and polymorphic\nthe first element\nthe rest of\nthe elements\ndata List t = Nil | Cons t (List t)\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-13\nArvind\nInfix notation\nCons x xs\nThis list may be visualized as follows:\n2:3:6:Nil\n2:(3:(6:Nil))\n[2,3,6]\nx:xs\nL8-14\nArvind\nSimple List Programs\nSum of numbers in a list\nsum []\n= 0\nsum (x:xs)\n=\n?\nLast element in a list\nlast []\n= x\nlast (x:xs)\n=\n?\nAll but the last element in a list\ninit []\n= []\ninit (x:xs)\n=\n?\nWhat do the following do?\ninit (a:xs)\n(a:(init xs))\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-15\nArvind\nExample: Split a list\ndata\nSplit a list of tokens into two lists a list words\nand a list of numbers.\nsplit :: (List Token)->\nsplit []\n= ([],[])\n?\nToken = Word String | Number Int\n((List String),(List Int))\nsplit (t:ts) =\nL8-16\nArvind\nHigher-order List abstractions\nmap f []\n= []\nmap f (x:xs)\n=\n?\nfoldl f z []\n= z\nfoldl f z (x:xs) =\n?\nfoldr f z []\n= z\nfoldr f z (x:xs) =\n?\nfilter p []\n= []\nfilter p (x:xs)\n=\n?\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-17\nArvind\nUsing maps and folds\n1. Write sum in terms of fold\n2. Write split using foldr\nsplit :: (List Token) -\n3. What does function fy do?\nsecond (x,y) = y\n> ((List String),(List Int))\nfy xys = map second xys\nfy ::\nL8-18\nArvind\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nFlattening a List of Lists\nflatten :: (List (List t)) -> (List t)\nflatten []\n= []\n:\n(concat xss)\nappend :: (List t) -> (List t) -> (List t)\n= ys\n) ys\nflatten (xs xss) = append xs\nappend [] ys\nappend (x:xs\n= (x:(append xs ys))\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-19\nArvind\nZipping two lists\n= []\n?\n-\n-\n->\n->\n-\n)\nWhat does f do?\nSuppose xs is:\nx0 , x1 , x2 , ... , xn\nzipWith f [] []\nzipWith f (x:xs) (y:ys) =\nzipWith :: (tx > ty > tz)\n(List tx)\n(List ty) > (List tz\nf xs = zipWith append xs (init ([]:xs))\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-20\nArvind\nArithmetic Sequences: Special Lists\n[1 .. 4]\n[1,2,3,4]\n[1,3 .. 10]\n[1,3,5,7,9]\n[5,4 .. 1]\n[5,4,3,2,1]\n[5,5 .. 10]\n?\n[5 .. ]\n?\n[5,5,5,...]\n[5,6,7,...]\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-21\nArvind\nList Comprehensions\na convenient syntax\n[ e |\nExamples\n[ f x | x <- xs ]\nmeans map f xs\n[ x | x <- xs, (p x)]\nmeans\n[ f x y | x <-\n- ys ]\nmeans the list\nwhich is defined by\nflatten (map (\\ x -> (map (\\ y -\n)\ngen, gen, ...]\nfilter p xs\nxs, y <\n[(f x1 y1),...(f x1 yn),\n(f x2 y1),......(f xm yn)]\n> e) ys\nxs))\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-22\nArvind\nThree-Partitions\nGenerate a list containing all three-partitions\n(nc1, nc2, nc3) of a number m, such that\n- nc1 < nc2 < nc3\n- nc1 + nc2 + nc3 = m\nthree_partitions m =\n[ (nc1,nc2,nc3) | nc1 <- [0..m],\nnc2 <- [0..m],\n?\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-23\nArvind\nEfficient Three-Partitions\nthree_partitions m =\n[ (nc1,nc2,nc3) | nc1 <- [0..floor(m/3)],\nnc2 <\n?\nL8-24\nArvind\nThe Power of List Comprehensions\n[ (i,j) | i <- [1..n], j <- [1..m] ]\nusing map\npoint i j\n= (i,j)\npoints i\n= map (point i) [1..m]\nall_points\n= map points [1..n]\n?\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL8-25\nArvind\nInfinite Data Structures\n1. ints_from i = i:(\nif n == 1 then x\nelse nth (n -\n>\n?\n2. ones = 1:ones\nnth 50 ones -->\n?\n3. xs = [ f x | x <-\n]\n-->\n?\nThese are well defined but deadly programs in\npH. You will get an answer but the program may\nnot terminate.\nints_from (i+1))\nnth n (x:xs) =\n1) xs\nnth 50 (ints_from 1) --\na:xs\nnth 10 xs\nL8-26\nArvind\nPrimes: The Sieve of Eratosthenes\nprimes = sieve [2..]\nsieve (x:xs) = x:(sieve (filter (p x) xs))\np x y = (y mod x) = 0\nnth 100 primes\nOctober 2, 2002\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L09Lists2Print.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/7027c7bda9a17b3e3ea595db997672cb_L09Lists2Print.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL9\nArvind\nLaboratory for Computer Science\nM.I.T.\nDesugaring List Comprehensions\nand\nPattern Matching\nOctober 7, 2002\n- 1\nL9-2\nArvind\nInfinite Data Structures\n1. ints_from i = i:(ints_from (i+1))\nnth n (x:xs) = if n == 1 then x\nelse nth (n - 1) xs\nnth 50 (ints_from 1) -->\n?\n2. ones = 1:ones\nnth 50 ones -->\n?\n3. xs = [ f x | x <- a:xs]\nnth 10 xs -->\n?\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9\nArvind\nPrimes: The Sieve of Eratosthenes\nprimes = sieve [2..]\np x y = (y mod x) = 0\nnth 100 primes\n-3\nsieve (x:xs) = x:(sieve (filter (p x) xs))\nL9-4\nArvind\nDesugaring!\n- Most high-level languages have constructs whose\nmeaning is difficult to express precisely in a\ndirect way\n- Compilers often translate (\"desugar\") high-level\nconstructs into a simpler language\n- Two examples:\n- List comprehensions: eliminate List\ncompressions usings maps etc.\n- Pattern Matching: eliminate complex pattern\nmatching using simple case-expressions\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9\nArvind\nList Comprehensions\n-5\nL9-6\nArvind\nList Comprehensions: Syntax\n[ e | Q ] where e is an expression and Q is a list of\ngenerators and predicates\nThere are three cases on Q\n1. First element of Q is a generator\n[ e | x <- L, Q' ]\n2. First element of Q is a predicate\n[ e | B, Q' ]\n3. Q is empty\n[ e | ]\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9\nArvind\nList Comprehensions Semantics\nRule 1.1\n[ e | x <- [], Q ]\nRule 1.2\n[e | x <- (ex : exs ), Q ]\nRule 2.1\n[ e | False, Q ]\nRule 2.2\n[ e | True , Q ]\nRule 3\n[ e | ]\n-7\nL9-8\nArvind\nDesugering: First Attempt\nTE[[[ e | ]]]\n= e :[]\nTE[[[ e | B, Q]]]\n=\nif B then TE[[[e | Q]]] else []\nTE[[ [ e | x <- L, Q] ]] =\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9\nArvind\nEliminating Generators\n[ e | x <- xs]\nmap (\n[ e | x <- xs, y <- ys]\n[ e | x <- xs, y <- ys, z <- zs]\nwhere concatflattens a list:\nconcat[]\n= []\nconcat (xs\n) = xs ++ (concat xss)\n-9\n\\x-> e) xs\n:xss\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-10\nArvind\nA More General Solution\n- Flatten the list after each map.\n- Start the process by turning the expression\ninto a one element list\n[ e | x <-\nconcat (map (\nxs)\n[ e | x <- xs, y <- ys]\nconcat (map (\n[ e | x <- xs, y <- ys, z <- zs]\nconcat (map (\nxs]\n\\x-> [e])\n\\x->\n\\x->\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-11\nArvind\nEliminate the intermediate list\n[ e | x <-\nconcat (map (\n)\nNotice map creates a list which is immediately\nconsumed by concat. This intermediate list is\navoided by concatMap\n= []\n)\n[ e | x <-\nconcatMap\n[ e | x <-\n-\nconcatMap\n[ e | x <-\n-\n-\nconcatMap\nxs]\n\\x-> [e]) xs\nconcatMap f []\nconcatMap f (x:xs) = (f x) ++ (concatMap f xs\nxs]\n(\\x-> [e]) xs\nxs, y <\nys]\n(\\x->\nxs, y <\nys, z <\nzs]\n(\\x->\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-12\nArvind\nList Comprehensions with Predicates\n[ e | x <- xs, p ]\n(map (\n> e) (filter (\nxs)\nconcatMap\n> if p then [e] else []) xs\n[ e | x <- xs, p, y <- ys]\nconcatMap\n> if p then\n\\x-\n\\x-> p)\n(\\x-\n(\\x-\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-13\nArvind\nList Comprehensions:\nFirst Functional Implementation- Wadler\nTE[[[ e | x <- L, Q]]] =\nconcatMap\nTE[[[e | Q]]]) L\nTE[[[ e | B, Q]]]\n=\nif B then TE[[[e | Q]]] else []\nTE[[[ e | ]]]\n= e :[]\nCan we avoid concatenation altogether?\n(\\x->\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-14\nArvind\nBuilding the output from right-to-left\n[ e | x <- xs, y <- ys]\nconcat (map (\nys\n)\n[ e | x <- xs, y <- ys]\nlet f []\n= []\n) =\nlet g []\ng (y:ys'\n)\nin\n)\nin\n(f xs)\nversus\n\\x-> map (\\y-> e)\n) xs\nf (x:xs'\n= f xs'\n) = e:(g ys'\n(g ys\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-15\nArvind\nList Comprehensions:\nSecond Functional Implementation-Wadler\nTE[[[ e | Q]]]\n= TQ[[[e | Q] ++ []]]\nTQ[[[ e | x <\n1, Q] ++ L ]] =\nlet f []\n= L\nf (x:\nTQ[[[ e | Q] ++ (f xs)]]\nin\n(f L1)\nTQ[[[ e | B, Q] ++ L ]] =\nif B then TQ[[[ e | Q] ++ L ]]\nelse L\nTQ[[ [ e | ] ++ L ]]\n= e : L\nThis translation is efficient because it never flattens.\nThe list is built right-to-left, consumed left-to-right.\n- L\nxs) =\nL9-16\nArvind\nThe Correctness Issue\nHow do we decide if a translation is correct?\n- if it produces the same answer as some\nreference translation, or\n- if it obeys some other high-level laws\nIn the case of comprehensions one may want\nto prove that a translation satisfies the\ncomprehension rewrite rules.\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-17\nArvind\nPattern Matching\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-18\nArvind\nDesugaring Function Definitions\nFunction def\nλ-expression + Case\nmap f []\n= []\nmap f (x:xs) = (f x):(map f xs)\nWe compile the pattern matching using a tuple.\nmap = (\\t1 t2 ->\ncase (t1,t2) of\n(f, [])\n-> []\n(f,(x:xs)) -> (f x):(map f xs)\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-19\nArvind\nComplex to Simple Patterns\nlast []\n= e1\nlast [x]\n= e2\nlast (x1:(x2:xs)) = e3\nt\ncase t of\n[]\n-> e1\n(t1:t2)\nlast = \\\n->\n->\nL9-20\nArvind\nPattern Matching and Strictness\npH uses top-to-bottom, left-to-right order in\npattern matching. This still does not specify if\nthe pattern matching should force the evaluation\nof an expression\ncase (e1,e2) of\n([]\n, y) -> eb1\n((x:xs), z) -> eb2\nShould we valuate e2?\nIf not then the above expression is the same as\npH tries to evaluate minimum number of arguments.\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-21\nArvind\nOrder of Evaluation and Strictness\nIs there a minimum possible evaluation of an\nexpression for pattern matching?\ncase (x,y,z) of\ncase (z,y,x) of\n(x,y,1) -> e1\n(1,y,x) -> e1\n(1,y,0) -> e2\nvs\n(0,y,1) -> e2\n(0,1,0) -> e3\n(0,1,0) -> e3\nVery subtle differences programmer should write\norder-insensitive, disjoint patterns.\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nThe rewriting rules for a case may be stated as\nfollows:\n(case e of P -> e1, C)\ne1\nif match(P,e)\nif ~match(P,e)\n(case e of P -> e1)\ne1\nif match(P,e)\nif ~match(P,e)\nL9-22\nArvind\nPattern Matching: Syntax & Semantics\nLet us represent a case as (case e of C)\nwhere C is\nC = P -> e | (P -> e) , C\nP = x | CN0 | CNk(P1, ...,Pk)\n\nL9-23\nArvind\nThe match Function\nP = x | CN0 | CNk(P1, ...,Pk)\nmatch[[x, t]]\n= True\nmatch[[CN0, t]]\n= CN0 == tag(t)\nmatch[[CNk(P1, ...,Pk), t]] =\nif tag(t) == CNk\nthen\n(match[[P1, proj1(t)]] &&\n.\n.\n.\nmatch[[Pk, projk(t)]])\nelse\nFalse\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\npH Pattern Matching\nL9-24\nArvind\nTE[[(case e of C)]]\n=\n(let t = e in TC[[t, C]])\nTC[[t, (P -> e)]]\n=\nif match[[P, t]],\nthen (let bind[[P, t]] in e)\nelse error \"match failure\"\nTC[[t, ((P -> e),C)]] =\nif match[[P, t]]\nthen (let bind[[P, t]] in e)\nelse TC[[t, C]]\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\n\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827\nL9-25\nArvind\nPattern Matching: bind Function\nbind[[x, t]]\n= x = t\nbind[[CN0 , t]] =\nbind[[CNk(P1, ...,Pk) , t]] =\nbind[[ P1, proj1(t) ]] ;\n.\n.\n.\nbind[[ Pk, projk(t) ]]\nL9-26\nArvind\nRefutable vs Irrefutable Patterns\nPatterns are used in binding for destructuring an\nexpression---but what if a pattern fails to match?\nlet (x1, x2)\n= e1\nx : xs\n= e2\ny1: y2 : ys = e3\nin\ne\nwhat if e2 evaluates to [] ?\ne3 to a one-element list ?\nShould we disallow refutable patterns in bindings?\nToo inconvenient!\nTurn each binding into a case expression\nOctober 7, 2002\nhttp://www.csg.lcs.mit.edu/6.827"
    },
    {
      "category": "Resource",
      "title": "L10pH_ArraysPrint.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/b91101c65a8cd6406c288a7d1ad588bd_L10pH_ArraysPrint.pdf",
      "content": "http://www.csg.lcs.mit.edu/6.827\nL10- 1\nArvind\nLaboratory for Computer Science\nM.I.T.\nProgramming with Arrays\nLecture 10\nhttp://www.csg.lcs.mit.edu/6.827\nL10-2\nArvind\nPattern Matching\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-3\nArvind\nPattern Matching: Syntax & Semantics\nLet us represent a case as (case e of C)\nwhere C is\nC = P -> e\n-> e) , C\nP = x | CN0 | CNk(P1, ...,Pk)\nThe rewriting rules for a case may be stated as\nfollows:\n(case e of P -> e1, C)\ne1\nif match(P,e)\nif ~match(P,e)\n(case e of P -> e1)\ne1\nif match(P,e)\nif ~match(P,e)\n| (P\nhttp://www.csg.lcs.mit.edu/6.827\nL10-4\nArvind\nThe match Function\nmatch[[x, t]]\n= True\nmatch[[CN0, t]]\n= CN0 == tag(t)\nmatch[[CNk(P1, ...,Pk), t]] =\nif tag(t) == CNk\nthen\n(match[[P1, proj1(t)]] &&\n.\n.\n.\nmatch[[Pk, projk(t)]])\nelse\nFalse\nP = x | CN0 | CNk(P1, ...,Pk)\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-5\nArvind\npH Pattern Matching\nTE[[(case e of C)]]\n=\n(let t = e in TC[[t, C]])\nTC[[t, (P -> e)]]\n=\nif match[[P, t]]\nthen (let bind[[P, t]] in e)\nelse error \"match failure\"\nTC[[t, ((P -> e),C)]] =\nif match[[P, t]]\nthen (let bind[[P, t]] in e)\nelse TC[[t, C]]\nhttp://www.csg.lcs.mit.edu/6.827\nL10-6\nArvind\nPattern Matching: bind Function\nbind[[x, t]]\nx = t\nbind[[CN0 , t]] =\nbind[[CNk(P1, ...,Pk) , t]] =\nbind[[ P1, proj1(t) ]] ;\n.\n.\n.\nbind[[ Pk, projk(t) ]]\n=\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-7\nArvind\nRefutable vs Irrefutable Patterns\nPatterns are used in binding for destructuring an\nexpression---but what if a pattern fails to match?\nlet (x1, x2)\nx : xs\n= e2\ny1: y2 : ys = e3\nin\ne\nwhat if e2 evaluates to [] ?\ne3 to a one-element list ?\nShould we disallow refutable patterns in bindings?\nToo inconvenient!\nTurn each binding into a case expression\n= e1\nhttp://www.csg.lcs.mit.edu/6.827\nL10-8\nArvind\nArrays\nCache for function values on a regular subdomain\nx = mkArray (1, n) f\n(f i)\nmeans x!i = (f i)\n1 < i < n\nn\nSelection: x!ireturns the value of the ith slot\nBounds: (bounds x) returns the tuple containing\nthe bounds\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-9\nArvind\nEfficiency is the Motivation\nfor Arrays\n(f i)is computed once and stored\nx!i is simply a fetch of a precomputed value\nand should take constant time\nn\n(f i)\nhttp://www.csg.lcs.mit.edu/6.827\nL10-10\nArvind\nA Simple Example\nx = mkArray (1,10)\nType\nx\nArrayI t)\nassuming\nf :: Int -> t\n(plus 5)\n(\n::\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-11\nArvind\nArray: An Abstract Data Type\nmodule ArrayI (ArrayI, mkArray, (!), bounds)\nwhere\ninfix 9 (!)\ndata ArrayI t\nmkArray ::(Int,Int) -> (Int-> t) -> (ArrayI t)\n(!)\n::(ArrayI t) -> Int -> t\nbounds\n::(ArrayI t) -> (Int,Int)\nSelection:\nx!i returns the value of the ith slot\nBounds:\n(bounds x) returns the tuple containing\nthe bounds\nhttp://www.csg.lcs.mit.edu/6.827\nL10-12\nArvind\nVector Sum\nvs a b = let\nesum i = a!i + b!i\nin\nmkArray (bounds a) esum\n+\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-13\nArvind\nVector Sum - Error Behavior\nvs a b\nlet\nesum i = a!i + b!i\nin\nmkArray (bounds a) esum\nSuppose\nb\na\n1.\nb\n2.\nb\n3.\n=\nhttp://www.csg.lcs.mit.edu/6.827\nL10-14\nArvind\nMap Array\nmapArray f a = let\ng i = f (a!i)\nin\nmkArray (bounds a) g\n.\n.\n.\na\nb\nf f\nf\nExample:\nsuch that bi = s * ai\nvscale a s = mapArray\na\n?\n((*) s)\n.\n.\n.\n.\n.\n.\nscale a vector, that is, produce b\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-15\nArvind\nDragging a Shape\nMove a k-sided polygon in an n-dimensional\nspace by distance delta\nas\ndelta\nbs\nhttp://www.csg.lcs.mit.edu/6.827\nL10-16\nArvind\nk-sided polygon: An array of points\nA point in n-dimensional space\ndistance delta in n-dimensional space\nn\n.\nn\n.\n.\nk\n. . .\n. .\nas\ndelta\nbs\nn\n.\nmove_shape as delta =\nmapArray\nas\n?\n(scale delta)\n.\n.\n.\n.\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-17\nArvind\nHigh-level Programming\nmapArray2 f\nlet\nelem i = f (a!i) (b!i)\nin\nmkArray (bounds a) elem\nf\nvs\n= mapArray2\nvvs = mapArray2 vs\nvvvs = mapArray2 vvs\n...\nb =\na\n(+)\nhttp://www.csg.lcs.mit.edu/6.827\nL10-18\nArvind\nFold Array\nfoldArray a f so =\nlet (l,u) = bounds a\none fold s i =\nif i > u then s\nelse one_fold (f s (a!i)) (i+1)\nin\none_fold so l\nf\nf\nf\na\nso\n.\nsn\nfoldArray a\nfoldArray a\n.\n.\n(+)\ninfinity\nmin\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-19\nArvind\nInner Product: Σ ai bi\nvp a\nlet\nelem i = a!i * b!i\nin\nmkArray (bounds a) elem\nip a\nfoldArray (vp a b) (+) 0\n=\nb\n=\nb\nhttp://www.csg.lcs.mit.edu/6.827\nL10-20\nArvind\nIndex Type Class\npH allows arrays to be indexed by any type\nthat can be regarded as having a contiguous\nenumerable range\nrange: Returns the list of index elements between a\nlower and an upper bound\nindex : Given a range and an index, it returns an\ninteger specifying the position of the index in the\nrange based on 0\ninRange : Tests if an index is in the range\nclass Ix a where\nrange\n:: (a,a) -> [a]\nindex\n:: (a,a) -> a -> Int\ninRange :: (a,a) -> a -> Bool\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-21\nArvind\nExamples of Index Type\ndata Day = Sun | Mon | Tue | Wed | Thu | Fri | Sat\nAn index function may be defined as follows:\nindex (Sun,Sat) Wed = 3\nindex (Sun,Sat) Sat = 6\n...\nA two dimentional space may be indexed as followed:\nindex ((li,lj), (ui,uj)) (i,j) =\n(i-li)*((uj-lj)+1) + j - lj\nThis indexing function enumerates the space in the\nrow major order\nhttp://www.csg.lcs.mit.edu/6.827\nL10-22\nArvind\nArrays With Other Index Types\nmodule Array (Array, mkArray, (!), bounds)\nwhere\ninfix 9 (!)\ndata (Ix a) => Array a t\nmkArray :: (Ix a) => (a,a) -> (a->t) ->\n(Array a t)\n(!)\n:: (Ix a) => (Array a t) -> a -> t\nbounds\n:: (Ix a) => (Array a t) -> (a,a)\nThus,\ntype ArrayI t = Array Int t\ntype MatrixI t = Array (Int,Int) t\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-23\nArvind\nHigher Dimensional Arrays\nx = mkArray ((l1,l2),(u1,u2)) f\nmeans\nx!(i,j) = f (i,j)\nl1 < i < u1\nl2 < j < u2\nType\nx :: (Array (Int,Int) t)\nAssuming\nf :: (Int,Int) -> t\nmkArray will work for higher dimensional matrices\nas well.\nhttp://www.csg.lcs.mit.edu/6.827\nL10-24\nArvind\nArray of Arrays\n(Array a (Array a t))\n(Array (a,a) t)\nThis allows flexibility in the implementation of\nhigher dimensional arrays.\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-25\nArvind\nMatrices\nadd\nmkArray ((1,1),(n,n))\n?\ni\nj\ni + j\n(i,j) =\nadd\nhttp://www.csg.lcs.mit.edu/6.827\nL10-26\nArvind\nTranspose\ntranspose a =\nlet\n((l1,l2),(u1,u2)) = bounds a\nf (i,j) =\n?\nin\nmkArray\nf\n(j,i)\n((l2,l1),(u2,ui))\n\nhttp://www.csg.lcs.mit.edu/6.827\nL10-27\nArvind\nThe Wavefront Example\nx = mkArray ((1,1),(n,n)) (f x)\nf x (i, j) = if i == 1 then 1\nelse if j == l then 1\nelse x!(i-1,j) + x!(i,j-1)\nxi,j = xi-1,j + xi,j-1\n1 1 1 1 1 1 1 1\nhttp://www.csg.lcs.mit.edu/6.827\nL10-28\nArvind\nCompute the least fix point.\n1 1 1 1 1 1 1 1\nx = mkArray ((1,1),(n,n)) (f x)\nf x (i, j) = if i == 1 then 1\nelse if j == l then 1\nelse x!(i-1,j) + x!(i,j-1)"
    },
    {
      "category": "Resource",
      "title": "suggestions.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-827-multithreaded-parallelism-languages-and-compilers-fall-2002/73f9da6599916825e376a143e3248e69_suggestions.pdf",
      "content": "Massachusetts Institute of Technology\nDepartment of Electrical Engineering and Computer Science\n6.827 Multithreaded Parallelism: Languages and Compilers\nProject Suggestions\nLecture 13\nPlease Remember:\n- The course project is worth 25% of the grade.\n- We recommend that you work in groups of up to two people.\n- Project presentations are due.\nProject Suggestions\n1 Grammars\nGiven a grammar lie the following grammar\ndata Exp = IntConst Int\n| BoolConst Bool\n| Var Ident\n| App Exp Exp\n| Func Ident Exp\n| Cond Exp Exp Exp\n| Prim PrimId [Exp]\n| Let [(Ident, Exp)] Exp\nderiving (Eq,Text)\ndata Ident = Varid Int deriving (Eq,Text)\ndata PrimId = Add | Sub | Mul | Div | Eq | Less | Greater\nderiving (Eq,Text)\nWrite a program to compute the Normal Form of an expression in the presence of free variables.\n2 The \"Nine 9s\" Problem\nWrite a program to determine the smallest positive integer that cannot be expressed as an expres\nsion composed of maximum of nine 9s and a small number of the operators +, -, *, /.\nHints:\n\n6.827 Project Suggestions\nPrefix\nData\n7.14.*.*\nA\n7.14.7.3\nB\n10.18.200.* C\n10.18.200.5 D\n5.*.*.*\nE\n*\nF\nTable 1: Example Table.\n- The answer isn't zero. You can express zero like this: (9 - 9) * (9 + 9 + 9 + 9 + 9 + 9 + 9)\nAlso, zero isn't a positive integer.\n- The answer isn't one. You can express one like this: 9 - (9 * 9 - 9)/9 + 9 - 9 + 9 - 9\n- It's not a trick question.\n- Be sure to handle parentheses correctly.\nNotes:\n- You cannot exponentiate.\n- You cannot concatenate (for example, put two 9s together to make 99).\n- The - operator can be used in either its binary or unary form.\n- Assume base 10.\n3 The IP Lookup Problem\nWe suggest that you implement fast IP lookup in BlueSpec. The data structure for with this problem\nis an IP lookup table, which contains IP prefixes and associated data. The problem, hence, is to\nreturn the data associated with the longest prefix match (\"LPM\") for a given IP address (Tables 1\nand 2).\nTable representation issues:\n- LPM is used for CIDR (Classless Inter-Domain Routing)\n- Number of memory accesses for an LPM?\n- Too many → difficult to do LPMs at line rate\n\n6.827 Project Suggestions\nIP Address\nResult\n7.13.7.3\nF\n10.7.12.15\nF\n10.18.201.5 F\n7.14.7.2\n?\n5.13.7.2\n?\n8.0.0.0\n?\n10.18.200.7 ?\nTable 2: Example Lookups.\nIP Address\nResult M Ref\n7.13.7.3\nF\n10.18.201.5 F\n7.14.7.2\nA\n?\n5.13.7.2\nE\n?\n10.18.200.7 C\n?\nTable 3: Memory references when traversing the tree.\n- Table size?\n- Too big → bigger SRAM → more latency, cost, power\n- Control-plane issues\n- incremental table update\n- size, speed of table maintenance software\nFigure 1 shows an example of a sparse tree representation for a lookup table given in Table 1. Table\n3 depicts the number of memory references when traversing this sparse tree.\n\n6.827 Project Suggestions\nC\nF\nF\nF\nD\nC\nF\nF\nF\nA\nA\nF\nF\nB\nE\nA\nA\nF\nF\nFigure 1: Sparse tree representation."
    }
  ]
}