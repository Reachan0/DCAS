{
  "course_name": "Combinatorial Optimization",
  "course_description": "No description found.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures",
    "Theory of Computation",
    "Systems Engineering",
    "Systems Optimization",
    "Mathematics",
    "Computation",
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures",
    "Theory of Computation",
    "Systems Engineering",
    "Systems Optimization",
    "Mathematics",
    "Computation"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nPrerequisite\n\n18.06\nLinear Algebra or 18.700 Linear Algebra.\n\nDescription\n\nThe course will present a thorough introduction to the fundamental algorithmic techniques of Discrete Mathematics - Linear and Convex Programming, Flow & Matching Theory, Randomization, and Approximation. We will tackle a variety of optimization problems by applying these techniques to find efficient algorithms.\n\nTopics include\n\nHow fast can a maximum matching be found in a graph?\n\nWhy is the maximum flow equal to the minimum cut?\n\nWhat is duality and how to make use of it?\n\nIs optimization reducible to random sampling?\n\nIs there a strongly polynomial-time algorithm for linear programming?\n\nHow to find a short traveling salesman tour?\n\nHow to find disjoint flow paths?\n\nFormat\n\nIn addition to 3 hours of lectures each week, students will have regular assignments, and two in-class exams. There will also be a course project which can be either theoretical (e.g. write a report, solve an open problem) or practical (e.g. evaluate an algorithm).\n\nProject\n\nFor the course project you will:\n\nWork on a problem and/or experimentally evaluate an algorithm;\n\nWrite a short report and present your findings to class.\n\nStudents can work individually or in pairs.\n\nProjects should be set up by the day after session #5.\n\nGrading\n\nACTIVITY\n\nPERCENTAGE\n\nExam I\n\n25%\n\nExam II\n\n25%\n\nProject (20% for Research + 6% for Presentation)\n\n26%\n\nAssignments\n\n24%",
  "files": [
    {
      "category": "Resource",
      "title": "a1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/8a32ae5d5e6910b21150a8e0457ddbbf_a1.pdf",
      "content": "!\n\n\"\n\n#\n\n$%\n&\n\n'\n$%\n(\n\n$%\n\n)\n\n*\n\n(\n\n*\n+\n\n,\n-\n\n$\n\"\n\n\"\n\n.\n%\n\nÆ\n\n/\n\n\"\n\n&\n\n\"\n\n&\n\n2'\n$\n\n%\n$%\n(\n\n$%\n(\n\n3 \"\n\"\n\n$%\n(\n\n* \"\n\"\n\n#\n\n.\n\n\"\n\n-\n\"\n\n\"\n\n\"\n\n:\n$\n\n%\n\n#\n\n\"\n\n-\n\n$%\n:\n\n$%\n:\n\n$%\n:\n\n$%\n:\n\n$%\n;\n\n$%\n:\n\n:\n\n$%\n;\n\n$%\n\n<\n\n+\n\n<\n\n\"\n\n<\n\n$%\n\n\"\n\n$%\n\n=\n-\n\n$%\n(\n\n:\n$\n\n%\n$%\n)"
    },
    {
      "category": "Resource",
      "title": "a2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/f49766574ae33bf5e6c61b252607de98_a2.pdf",
      "content": "!\n\n\"\n\n#\n\n$\n\nÆ\n\n%\n\n&\n'\n\n(\n\n)\n\n\"\n\n#\n\n)\n\n*\n\n#\n\n+\n\n,\n\n-\n(\n\n.\n\n)\n)\n.\n\n/\n\n$"
    },
    {
      "category": "Resource",
      "title": "a3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/8d981f515b376fb285aeb80b70f65f40_a3.pdf",
      "content": "!\n\n!\n\n\"\n\n!\n\n#\n\n$\n\n\"\n\n%\n\n!\n#\n\n&\n\n'\n\n&\n\n'\n\n(\n(\n(\n\n(\n(\n()\n\n(\n(\n(*\n+\n\n,-\n\n%\n\n!\n\n.\n\n!\n\n/,\n\n#\n\n,\n\n#\n\n.0\n\n!\n\n,\n\n,\n\n!\n\n!\n#\n\n!\n\n!\n\n,\n\n&\n\n,\n'\n\n/\n#\n\n#\n\n-\n\n!\n\n&\n\n,\n\n'\n$\n\n&'\n&9\n'\n\n,\n\n,\n&\n&'\n'\n/\n#\n\n,\n\n&'\n\n&\n'\n\n&'\n\n!\n\n&'\n&'\n\n!\n\n,\n\n/\n#\n\n!\n\n&\n\n' &'\n#\n\n!\n\n:\n.\n\n&\n\n'\n#\n\n#\n\n!\n\n!\n\n%\n\n!\n\n&'\n.\n\n&'\n;,\n\n,\n/\n#"
    },
    {
      "category": "Resource",
      "title": "a4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/d987017bd1bb2791bf5faf8251457054_a4.pdf",
      "content": "18.433 Combinatorial Optimization\nDue: December 2\nAssignment 4: Approximation Algorithms\nLecturer: Santosh Vempala\n1. In the Bin Packing problem, we are given a set S = {s1, · · · , sn} where each\nsi ∈[0, 1] and asked to \"pack\" elements of S into the minimum possible number\nof unit size bins. Design a 2-approximation algorithm for this problem, i.e. an\nalgorithm which uses at most twice as many bins as the minimum possible.\n2. Given an undirected graph G = (V, E) a subgraph G′ = (V, E′) such that E′ ⊆E\nis called a 2-edge connected spanning subgraph if it has the property that there\nare at least two edge-disjoint paths in G′ between any pair of vertices.\n(a) Show that the problem of finding a minimum 2-edge connected spanning sub-\ngraph is NP-hard.\n(b) Give an efficient 2-approximation for the problem, i.e.\nan algorithm that\nis guaranteed to find a solution with at most twice as many edges as the\nminimum.\n3. Given a directed graph, an acyclic subgraph is a collection of edges E′ ⊆E that\ncontain no directed cycles.\n(a) Give a polynomial-time algorithm that finds an acyclic subgraph with at least\nhalf as many edges as the maximum.\n(b) Give an integer program, with a variable for each edge, to find the maximum\ncardinality acyclic subgraph in G.\n(c) Relax the integrality constraints to obtain an LP. How large can the integrality\ngap of the LP be? (In this case the integrality gap is defined as the ratio of\nthe LP optimum to the the integer optimum.)\n(d) Give a polynomial-time separation oracle to solve the LP."
    },
    {
      "category": "Resource",
      "title": "l4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/b450b5da9e3d8510993558d620244fb3_l4.pdf",
      "content": "!\"!\n\n#\n\n$\n\n\"\n%\n!$\n\n&!\n'\n\n#\n\n(\n\n)\n*\n\n+\n\n+\n\n\"\n\n!\n*\n\n!\n\"\n!\n\n\"\n!\n\n(\n\n,\n\n#\n\n-#\n\n.\n\n!\n\n\"\n!\n\n$\nÆ\n\n!\n\n*\n\n#\n/\n+\n\n.\n\n!\n\n+\n\n#\n\n\"\n\n!\n\n#\n\n/\n\n!\n\na\nb\nxa\nxb\nsolution\nset\n.\n\n+\n\n\"!\n!\"\n\n\"\"\n\n+\n#\n\n#\n\n#\n-#\n\n#\n\n*\n\n#)\n\n)\n.\n\n&\n\n-#\n\n(\n+\n\n-#\n\n+\n\n!\"\"\n\"\"!\n\"!\"\n\n#\n\nÆ\n\n+\n\n!\n\nÆ\n\n+\n\n\"\n\n$\n\n+\n\n)\n\n+\n\n,\n\nÆ\n\n+ )\n\n(\n\n#\n\n,\n+\n#\n\n+ )\n\n&6\n\n#\n+\n\n(\n+\n\n%\n\nÆ\n\nÆ\n\n+\n\n/\n\n+\n\n/\n.\n\n#\n\nÆ\n\n#\n\n(\n+\n\n#\n\n$\n\n(\n+\n\n#\n\n\"\n\n+\n\n%\n\n!\n\n!\n\n\"\n\n#\n\n#\n\n(\n\n*\n\n# #\n\n%\n\n(\n+\n\n%\n\n+\n\n%\n\n)\n\n+\n\n!\n\n\"\n\n!\n*\n\n(\n\n#\n+\n\n!\n\n(\n\n-#\n\n-#\n\n-#\n\n+\n\n#3\n\n#+\n\n(\n\n-#\n\n-#\n\n+3\n\n$\n\n*\n\n#-#\n#\n\n(\n\n-#\n\n-#\n\n#+\n\n%\n\n(\n\n#+\n\n-#\n\n-#\n\nÆ\n\n#\n\n*\n-#\n\n#\n+\n\n-#\n(\n\n#\n\n\"\n\n!\n\n#\n\n&\n\n#\n+\n\n,\n\n(\n\n#\n\n#\n\n#\n\n:\n\n+\n\n#\n+\n\n+\n\n#%\n\n!\n\n!\n\n!\n\n&\n\n$\n:\n#\n\n%\n\n;\n\n<\n\n=\n\n;\n\n:\n\n+\n\n#\n+\n\n+\n\n#\n+\n\n!\n\n#\n\n$\n\n$\n\n#\n+\n\n&\n\n#/\n\n#\n\n$\n\n$\n\n$\n*\n\n;\n$\n\n$\n\n&\n\n&\n\n.\n\n&\n\n;\n<\n\n!\n\n>\n\n&\n\n&\n;\n>\n\n+\n*\n\n#\n+\n\n;\n?\n$\"\n\n;\n<\n;\n<\n!$\n?\n\n!$\n&\"\n$\"\n\n#\n\n;\n\n?\n!$\n<\n\n#\n\n>\n\n$\"\n&\"\n!$\n\n#\n\n#\n\n<\n\n#-#\n\n>\n#\n\n;"
    },
    {
      "category": "Resource",
      "title": "l5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/c17fffb9e0d47d41ef84f9b922ca18e3_l5.pdf",
      "content": "Æ\n\n!\n\"\n\n#\n\n$\n\n%\n&'\n\n&\n\n$\n\n\"\n\n(\n\n\"\n\n#\n\n%\n)\"'\n\n*\n\n'\n\n#\n\n'\n\n)\n\n\"\n\n#\n+\n\n,\n\n,\n\n$\n\n\"\n\n#\n\n\"\n&\n\n\"\n\n\"\n\n\"\n\n-\n\n\"\n\n#\n\n.\n\n-\n\n\"\n\n%\n\n$\n\n'\n\n&\n\n\"$\n\n\"\n\n/\n\n\"0\n\n+\n\n)\n\n\"\n\n\"\n\n\"\n\n)\n\n\"\n\n$\n\n$\n\n\"\n\n\"\n\n\"\n\n)\n\n\"\n\n\"\n\n*\n\n*\n\n\"\n\n*\n\"\n\n&\n\n\"\n\n.\n\n\"\n\n$\n\n\"$\n\n\"\n\n!\n\n'\n\n\"\n\n*\n\n%\nÆ\n\n)\n.\n\n)\n\n+\n\n.\n\n!\n\n\"\n\n.\n\n\"\n\n\"\n\n$\n\n)\n.\n\nÆ\n\n)\n\"\n\n,\n7\"\n\n$\n\n$\n\n.\n\nÆ\n\nÆ\n\nÆ\n\n.\n\n$\n\n$\n\n)\n\n\"\n\n\"\n\n)\n\n$\n\n$\n$\n\n)\n\n7\"\n\n)\n\n\"\n\n#\n\n)\n+\n\n\"\n\n\"\n\n$\n\n\"\n\n!\n\n&\n\n\"\n\n$\n\n&\n\n\"\n\n\"\n\n,\n\n$\n\n,\n\n\"\n\n$\n\n&\n\n\"\n\n,\n\n$\n\n\"\n\n$\n\n$\n\n\"\n\n(\n\n$\n\n/\n\n$\n\n$\n\n$\n\n\"\n\n)\n\n\"\n\n\"\n\n$\n\n$\n\n$\n\n\"\n\n$\n\n)\n\"\n\n+\n\n*\n\"\n\n\"\n\n*\n\"\n$\n\n,\n\n%\n!\n\"\n\n\"\n$\n\n&\n\n$\n\n2$"
    },
    {
      "category": "Resource",
      "title": "l6.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/31b7e2a99bb19001d24d44a36198b6fe_l6.pdf",
      "content": "Æ\n\n!\n\n!\n\n\"\n\n#\n\n$\n\n$\n%\n\n&\n\n'\n(\n\n!\n\n!\n\n)!\n\n!\n\nÆ\n\n$\n\n*\n\n)\n\n!\n\n!\n\n!\n\n+\n,\n!\n\n!\n\n-\n\n!\n\n!\n\n!\n\n!\n\n+\n\n+\n.\n\n/\n\n+\n\n!\n\n+\n\n$\n\n!\n\n$\n\n&\n\n*\n\n#\n\n%\n\n!\n\n*\n\n%\n\n-\n\n!\n\n!\n\n!\n\n!\n\n!\n\n+\n\n!\n\n!\n\n!\n\n!\n\n!\n\n+\n\n(\n\n!\n\n!\n\n#\n\n.\n\n*\n\n+\n\n+!\n\n\"\n\n!\n\n*\n\n+\n\n+\n\n,\n\n&\n\n$\n\n$\n*\n\n$\n\nÆ\n\nÆ\n\n-\n\n!\n\n$\n\n#\n\n!\n\n!\n\nÆ\n\n-\n\n*\n\n!\n\n(\n\n*\n\n#\n\n*\n!\n\n!\n\n%\n\n-\n\n#\n\n!\n\n*\n\n!\n\n!\n\n!\n\n!\n\n*\n\n!\n\n!\n\n!\n\n*!\n\n#\n\n!\n\n%\n\n+\n%\n\n+\n\n!\n\n%\n\nÆ\n\n#\n\nÆ\n\n%\n\n#\n\n%\n\n!\n\n*\n-\n\n*\n\n(\n\n#\n\n*\n\nÆ\n\nÆ\n\n%\n\n!\n\n.!\n\n!"
    },
    {
      "category": "Resource",
      "title": "l9.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/fb68f7366b5af4c92c072fb898201450_l9.pdf",
      "content": "!\n\n\"\n\n#\n$\n\"#\n\n$\n\n%\n\n&\n\n'\n\n\"\n\n(\n\n\"\n\n$\n\n'\n\n!\n\n)\n\n'\n\n)\n\n*\n\n+\n\n,\n\n\"\n\n(\n\n-\n\n'\n\n(\n\n.\n\n-\n\n/\n\n&\n\n)\n\n'\n\n'\n\n&\n\n-\n\n&\n\n%\n\n'\n\n/\n\n'\n\n&\n\n.\n\n&\n\n&\n\n/"
    },
    {
      "category": "Resource",
      "title": "l12.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/fe457253e3b86967a7f3bfbdfea810ea_l12.pdf",
      "content": "!\n\n\"\n!\n\n#\n\n$\n\n%\n\n#\n\n&\n\n&\n\n&\n\n'\n\n!\n\n(!\n\n)\n\n\"\n\n$\n\n\"\n\n\"\n\n!\n\n$\n\n*\n\n*\n\n*\n+\n\n!!\n*\n\n\"\n\n,\n\n,\n\n,\n\n$\n\n\"\n\n-\n\n$\n%\n\n'\n\n#\n\n(!\n\n!\n'\n\n!\n\n.\n\n/\n\n%0\n\n!\n\n#\n\n21.\n//\n'\n)\n\n4!\n\n&\n\n&\n\n&\n\n-\n\n-\n\n&\n\n*\n*\n&\n\n&\n\n&\n\n+\n\n&\n+\n\n&\n\n$\n)\n#\n\n!\n\n!\n\n$\n$\n*\n$\n\n+\n*\n*\n*\n\n*6\n+\n\n\"\n\n!\n\n!)\n\n'\n\n!\n\n(!\n\n!\n\n)\n#\n\n+\n\n!\n\n#\n\n+6\n\n&\n\n&\n\n&\n5$\n\n+:6\n\n%\n\n!\n\n#\n\n\"-\n&\n\n&\n\n&\n\n+:6\n\n!\n-\n\n+:6\n\n!\n\n!\n\n#\n!!\n+\n!\n\"\n\n-\n&\n\n&\n;\n\n&\n\n-\n\n#\n\n-\n-\n\n<\n\n$\n\n*-\n+-\n!\n\"\n\n&\n\n&\n\n&\n\n&\n+\n\n&\n\n&\n\n&\n\n&\n&\n&\n\n&\n\n&\n\n!\n\n!\n!\n\n!\n\n&\n\n&\n\n&\n+\n\n*\n\n&\n\n&\n\n&\n\n$\n\n&\n\n&\n\n\"-\n\n!\n\n!\n\n!\n\n&\n\n&\n\n!\n\n\"\n\n$\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n-\n\n!\n\n$\n\n\"\n!\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n$\n\n.\n\n-\n\n$\n\n$\n\n=\n\n>\n%\n>>\n\n=\n\n-\n\n-\n\n\"\n\n$\n;\n%\n\n#\n\n;\n\n#\n\n?\n\n21.\n\n!\n-\n\n!"
    },
    {
      "category": "Resource",
      "title": "l15.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/92c255b407a6ad7d75c9ea55de2fdf33_l15.pdf",
      "content": "18.433 Combinatorial Optimization\nThe Primal-dual Algorithm\nOctober 28\nLecturer: Santosh Vempala\nIn this lecture, we introduce the complementary slackness conditions and use them to obtain\na primal-dual method for solving linear programming.\nComplementary Slackness\nAs we have seen before, using strong duality, we know that the optimum value for the\nfollowing two linear programming are equal, i.e. u = w, if they are both feasible.\nu = max{cT x : Ax ≤b, x ≥0}\n(P)\nw = min{bTy : AT y ≥c, y ≥0}\n(D)\nUsing the above result, we can check the optimality of a primal and/or a dual solution.\nTheorem 1. Suppose x and y are feasible solutions to (P) and (D). Then x and y are\noptimal if and only if the following conditions are satisfied:\n∀i (bi -\n\nj\naijxj)yi = 0;\n∀j (\n\ni\naijyi -cj)xj = 0.\nProof. First, we note that since x and y are feasible (bi -\nj aijxj)yi ≥0 and (\ni aijyi -\ncj)xj ≥0. By summing over i and j, we have:\n\ni\n(bi -\n\nj\naijxj)yi ≥0\n(1)\n\nj\n(\n\ni\naijyi -cj)xj ≥0\n(2)\nBy adding 1 and 2 and using the strong duality theorem\n\ni\nbiyi -\n\ni,j\naijxjyi +\n\nj,i\naijyixj -\n\nj\ncjxj =\n\ni\nbiyi -\n\nj\ncjxj = 0.\nTherefore, all our inequalities must be equalities and we obtain the desired result.\n\nPrimal-dual algorithm\nThe main implication of Theorem 1 is that if x and y are feasible and satisfy the comple-\nmentary slackness conditions, then they are optimal. This result leads us to the primal-dual\nalgorithm in which we start with a feasible solution x and y and try to satisfy the conditions\nmore and more.\nFor the sake of convenience, we consider the primal and dual programs as follows:\nmin{cTx : Ax = b, x ≥0}\n(P)\nmax{bTy : AT y ≤c}\n(D)\nIn this form, the complementary slackness conditions that we need to satisfy are reduced\nto:\n∀j (cj -\n\ni\naijyi)xj = 0.\n(3)\nThe steps of the primal-dual algorithm are as follows:\n1. Start with a feasible solution y for (D). Obtaining such feasible solution y is easier\nthan solving the linear program in many cases.\nLet J = {j :\ni aijyi = cj}.\nNow using 3, we need to obtain a solution x for (P) such that ∀j ∈J, xj = 0. So the\nquestion is whether there is a feasible solution x with this property.\n2. Formulate the restricted primal (RP) as follows:\nmin\nm\n\ni=1\nXi\n∀i\n\nj∈J\naijxj + Xi = bi\nXi, xj ≥0\n∀j ∈J, xj = 0\nIn fact, (RP) formulates the problem of finding feasible solution x with the afore-\nmentioned property. Here variables Xi's are artificial variables and if min m\ni=1 Xi is\nequal to zero, then xj's are optimal solutions to (P).\n\n3. If Opt(RP) = 0 then x and y are optimal. Otherwise Opt(RP) > 0 and we write the\ndual of (RP), namely (DRP), for which we get solution y.\nmax\nm\n\ni=1\nbiyi\n∀j ∈J\n\ni\naijyi ≤0\nyi ≤1\n4. Improve the solution to (D) by setting y′ = y + εy. Here we determine ε such that\ny′ is feasible and\ni biy′\ni >\ni biyi. For feasibility, we must satisfy the condition\n∀j\ni aijy′\ni ≤cj. For j ∈J, we must have\ni aijyi + ε\ni aijyi ≤cj. Since ∀j ∈\nJ\ni aijyi ≤0, ε can be arbitrary positive for j ∈J.\nThus by taking\nε = min{j∈J s.t. P\ni aijyi>0}\ncj -\ni aijyi\n\ni aijyi\nwe obtain our ε > 0 such that y′ is feasible.\nAlso since Opt(DRP) = Opt(RP) > 0 and ε > 0,\n\ni\nbiy′\ni =\n\ni\nbiyi + ε\n\ni\nbiyi >\n\ni\nbiyi.\nWe note that in the above primal-dual algorithm, solving (DRP) is usually easier than\nsolving (P) or (D).\nIn fact, in this approach, programs (P) and (RP) are temporary\nprograms and we want to solve (D). To this end, we first solve (DRP) and then use the\nsolution to improve y iteratively.\n2.1\nExample\nConsider the following formulation of the max-flow problem:\n\nmax f\n\nj\nxsj -\n\nj\nxjs -f ≤0\nf -\n\nj\nxjt +\n\nj\nxtj ≤0\n∀i = s, t\n\nj\nxij -\n\nj\nxji ≤0\nxij ≤uij\n-xij ≤0\nIt is worth mentioning that in the original max-flow formulation, the first three sets of\nconstraints are equalities. However in our new formulation by summing these three sets of\ninequalities, we get 0 ≤0 and thus these weaker sets of inequalities imply the equalities.\nNow, we consider the above formulation as (D). One feasible solution to (D) can be obtained\nby taking x as a zero vector. Now if we go directly to (DRP) we have:\nmaxf\n\nj\nxsj -\n\nj\nxjs -f ≤0\nf -\n\nj\nxjt +\n\nj\nxtj ≤0\n∀i = s, t\n\nj\nxij -\n\nj\nxji ≤0\nxij ≤0 ∀i, j where xij = uij in (D)\n-xij ≤0 ∀i, j where xij = 0 in (D)\nxij ≤1\nf ≤1\nWe can observe that (DRP) has the following interpretation. Find a path from s to t (with\na flow of value 1) that uses only the following arcs in the following ways: saturated arcs in\nthe backward direction; arcs with zero flow in the forward direction; and other arcs in either\ndirection. In other words, we need to find a path in the residual graph. This observation\nshows that the max-flow algorithm is in fact a primal-dual algorithm.\n\nFinally, we note that primal-dual algorithms do not have polynomial running time guaran-\ntees."
    },
    {
      "category": "Resource",
      "title": "l18.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/0935ec8ab80afec78f89ffaf0eb2861c_l18.pdf",
      "content": "!\n\n\"\n\n#\n\n$\n\n%\n&\n\n'\n\n(\n\n&\n\n'\n\n)\n\n%\n#\n\n(\n\n$\n\n%\n*\n\n%\n+\n\n,\n\n$\n\n$\n\n*\n\n+\n*\n*\n\n-\n\n(\n\n(\n\n.\n\n(\n\n+\n\n*\n\n(\n\n,\n\n(\n\n#\n-\n+\n\n*\n\n&\n\n*'\n\n(\n\n(\n\n%\n\n-\n\n&\n\n'\n\n-\n\n*\n\n*\n\n(\n\n$\n\n(\n\n&\n\n'\n\n-\n\nÆ\n\n.\n\n(\n\n+\n\n*\n\n&'\n\n&'\n\n&\n&'\n\n'\n)\n\n&'\n\n&'\n\n&\n\n&\n\n''\n\n)\n\n&'\n\n&\n\n&\n\n'\n\n&''\n\n$\n\n%\n&\n\n'\n\n(\n\n&/'\n\n$\n\n&\n\n'\n\n*\n\n+\n*\n\n(\n\n&)/'\n$\n\n&\n\n'\n\n*\n+\n\n*\n\n& '\n&!\n'\n\n& '\n%\n\n!\n\n*1\n\n&!\n'\n%\n*\n\n(\n\n)\n\n\"\n\n$\n\n&\n\n'\n\n*\n\n\"\n\n\"\n\n*\n+\n\n*\n\n&\n\n(\n\n(\n'\n)\n\n-\n\n#\n\n%\n*\n\n&\n\n'\n\n,\n\n\"\n\n#\n\n*\n\n%\n&\n\n%\n\n'\n\n(\n\n(\n\n(\n\n(\n\n.\n\n&\n\n'\n\n&\n\n'\n\n&\n\n'"
    },
    {
      "category": "Resource",
      "title": "l20.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/0174bd8254153827d2ccaf345a0fd0e4_l20.pdf",
      "content": "18.433 Combinatorial Optimization\nNP-completeness\nNovember 18\nLecturer: Santosh Vempala\nUp to now, we have found many efficient algorithms for problems in Matchings, Flows,\nLinear Programs, and Convex Programming. All of these are polynomial-time algorithms.\nBut there are also problems for which we have found no polynomial-time algorithms. The\ntheory of NP-completeness unifies these failures. Roughly speaking, an NP-complete prob-\nlem is one that is as hard as any problem in a large class of problems. For example, the\nTraveling Salesman Problem (TSP), Integer Programming (IP), the Longest Cycle, and\nSatisfiability (SAT) are all hard problems. NP-completeness tells us that they are all, in a\nprecise sense, equally hard. Let's look at each problem in a little more detail.\n1. The Traveling Salesman Problem\nLet's say that there exist a salesman that has to visit n cities and there exists a\ndistance wi,j between cities i and j. He wants to make sure to minimize his traveling\ntime by visiting every city exactly once. In other words, there is a complete graph\nG = (V, E) with lengths wi,j between nodes i and j. The question we must ask is:\nWhat is the shortest cycle that visits every node exactly once?\n2. Integer Linear Programming\nSuppose that you have a linear program such as the following:\nmin cT x\nAx ≤b for xi ≥0\nThis is your typical linear program. Now, if you decide to add an integrality constraint\non xi such that it is forced to be a positive integer, then you have an Integer Linear\nProgram (ILP).\n3. Boolean Satisfiability\nThe satisfiability problem (SAT) uses boolean expressions such as the following\nf = (x1 ∨x2 ∨x4) ∧(x3 ∨ x4)....\n\nwith xi = {True,False} and using well known boolean identities.\nDoes F have a\nsatisfying assignment? Can we find values of xi such that every clause in F is equal\n1?\n4. Longest Cycles\nGiven a graph G = (V, E), find the longest cycle.\n5. Cliques\nA clique is a complete subgraph. Given a graph G = (V, E), find a clique of maximum\ncardinality (vertices).\nAs different as these examples might seem, they have two main properties in common:\nA) None of them is known to have a polytime algorithm.\nB) If any one of them has a polytime algorithm, then they all do.\nOptimization vs Decision\nWhile property A seems trivial to us all by the inspection of each problem, property B is\nnot as easy to see. To understand this property, we first formulate the decision versions of\nthese optimization problems.\nFind the optimum among a set of feasible solutions F with cost function c\nvs\nIs there a feasible solution of cost ≤L?\nIf the Optimal (OPT) is solved, then the Decision (DEC) is also solved. Namely, DEC\nreduces to OPT. Now, is OPT reducible to DEC? Well, using the TSP as an example, we\nask: Is there a tour ≤L? Then, we proceed to do a binary search in order to find the\nlength of the shortest tour, say S. But, we still don't know what the tour is. One way to\nfigure this out is to use the following algorithm:\nTake out an edge e.\nAsk if the same graph still has a tour ≤S.\nIf it does, then we don't need that edge and can delete it.\n\nIf it doesn't, then we keep that edge because it will be part of our tour.\nRepeat this algorithm for all the edges.\nIn the ILP example, we can ask: Is there an x of cost ≤L? Well, one way to do this would\nbe to set xi = 0 and if optimum stays the same, then we can fix that particular xi to 0.\nFor the maximum cliques problem, the OPT problem would be: Find the largest clique,\nwhile the DEC problem would be: Is there a clique of size ≤k? To find the optimal size\nk∗, again we do a binary search. We then consider the graph with vi and all its neighbors.\nIf the optimum in this graph remains the same, then save that vertex, then we can delete\nall other vertices. Else, delete vi because it is not in the max clique.\nP and NP\n2.1\nDefinitions\nP : Class of decision problems that can be solved in polytime.\nNP : Decision problems that have a short proof (certificate) for YES answers. The proof\nhas length bounded by a polynomial in the size of the input, and its correctness can be\nverified in polytime.\nNote that problems in P have short proofs for both YES and NO answers. This means that\nP ⊆NP. Let's look at a problem in P:\nLinear Programming: Is the minimum less than some c?\nYES: Give a feasible solution ≤c\nNO: Use the Dual of the problem to give a lower bound.\nNow, let's look at the following examples of NP problems:\n1. TSP, Is there a tour ≤L?\nYES: Give a tour\nNO: ?\n2. SAT, Does there exist a satisfying assignment?\nYES: Give a satifying assignment\n\nNO: ?\n3. Min ILP, Is the minimum ≤c?\nYES: Give a feasible solution that is ≤c\nNO: ?\nThis leads to the question: Is P = NP?\n2.2\nReductions\nA reduction from a problem A to a problem B is a function f : A →B such that for all\ninstances x\nx ∈A ⇔f(x) ∈B.\nIf the function f can be computed in polynomial time, then it is called a polynomial-time\nreduction. An implication of this is the following:\nIf there exists a polytime algorithm for B, then there exists one for A.\nA problem B is NP-hard if every problem in NP has a polytime reduction to B. If, in\naddition, B is in NP, then it is NP-complete.\nThus if A is NP-complete, and it has a reduction to another problem B in NP, then B is\nalso NP-complete.\n2.3\nExamples of Reduction\nSAT is NP-complete (we will not prove this in class).\n1. ILP is NP-complete Let's take the following SAT problem and see if it can be solved\nby an ILP.\nF = (x1 ∨x2 ∨... ∨ xi) ∧(x4 ∨ x5) ∧... ∧(xa ∨xb ∨... ∨xc)\nThis SAT problem can also be written in the following way\nx1 + x2 + ... + xi ≥1\nx4 + x5 ≥1\nxa + xb + ... + xc ≥1\n\nX2 + X3 + X4 + X5\nX2 + X4\nX4, 1\nX5, 3\nX3, 3\nX1, 3\nX3, 1\nX1 + X3 + X5\nX2, 1\nX2, 2\nX4, 2\nX5, 1\nFigure 1: clique is NP-complete\n...\nxi =\n\n1,\nthen true\n0,\nthen false\nSince SAT can be reduced to an ILP, ILP is NP-complete.\n2. Clique is NP-complete\nSAT can be reduced to clique by the following construction.\nSuppose we have a\nformula F with m clauses.\n1) Vertices are going to be of the form < xa, i > where xa is a literal that occurs in\nclause Ci\n2) Edges are going to be of the form {< xa, i >, < xb, j >} for all xa = xb and i = j.\nBy defining the vertices and edges this way, we ensure that all the connected vertices\nare compatible, since their truth values won't overlap. If we find a clique of size m in\nthis graph, F is satisfiable. Refer to Fig. 1."
    },
    {
      "category": "Resource",
      "title": "l78.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/4b4c870ffce7acfcc3f1d1dc1e757e98_l78.pdf",
      "content": "!\n\n!\n\n!\n\n!\n\n\"#$\n\n%\n\n&\n\n&\n\n'\n\n\"\n\n#\n\n$\n\n%\n\n&\n\n'\n\n!\n\n!\n\n#\n\n!\n\n#\n\n#\n\n!\n\n(\n\n#\n\n)\n\n*\n\n&\n)\n\n+\n\n,\n\n-\n\n-\n\n$\n\n-\n\n#\n\n!\n\n!\n\n.\n\n/\n\n%\n\n!\n\n(\n\n'\n)\n\n!\n\n'\n\n%\n\n%\n\n%\n\n.\n\n!\n\n!\n\n!\n\n$\n\n!\n\n!\n\n!\n\n!\n\n$\n\n-\n\n$\n\n$\n\n/\n+\n\n-\n\n-\n\n&\n)\n\n+\n$\n\n+\n\n$\n\n%\n\n.\n$\n\n&*\n\n-\n\n-\n\n)\n\n+\n\n.\n%\n\n-\n\n$\n\n$\n\n%\n\n.\n\n!\n\n+\n\n'\n\n&\n\n'\n\n!\n\n!\n\n'\n\n%\n\n+\n,*\n-\n)\n+\n\n.\n\n'\n\nalpha\nalpha\n1+alpha\nalpha\nalpha + alpha\n)&\n\nÆ\n\n.\n\n-\n\n$\n\n)\n-\n\n-\n\n)\n\n)\n\n)\n\n-\n\n%\n\n+\n%\n\n$\n\n.\n\n-\n\n$\n\n,\n\n-\n\n$\n\n)\n\n:\n\ns\nt\n0+alpha = alpha\n1-alpha = alpha\nalpha\nalpha\n+&\n\nC\nf\nCi,j\nCi,j - f\nC\n+ f\ni,j\ni,j\ni,j\nj,i\nj,i\n5&\n\n-\n\n%\n\n;\n\n*\n\n.\n\n$\n\n\"\n\n$\n\n-\n\n<\n\n)\n\n+\n\n(\n\n*\n\n-\n\n%\n\n)\n\n/\n\n/'\n\n$\n\n'\n\n%\n\n-\n\n+\n\n%\n\n+\n\n+\n\n%\n\n!\n\n%\n\n=\n\n)\n'\n\n-\n\n+\n\n'\n\n'\n\n)\n\n)\n\n(\n\n&\n\n(\n\n'\n\n'\n\n>\n\n)\n\n'\n\n)\n(\n\n+\n\n,\n\n-\n\n?"
    },
    {
      "category": "Resource",
      "title": "l123.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-433-combinatorial-optimization-fall-2003/63d6329fa5c61156536693b24ecdbd6b_l123.pdf",
      "content": "!\n\n\"\n\n#\n\n$\n\n%\n\n&\n'\n$\n(\n\n)\n\n$\n\n(\n\n&\n%\n\n'\n\n*\n\n*\n\n+\n\n$\n\n+\n\n+\n\n,\n\n-\n\n+\n\n./\n\n-\n\n+\n\n%\n\n(\n\n-\n\n'\n-\n\n+\n\n(\n\n+\n\n. /\n&\n\n-\n\n(\n\n)\n\n(\n\n%\n\n\"\n\n)\n-\n\n\"\n\n-\n\n+\n\n)\n\n(\n\n(\n\n!\n\n+\n\n&\n\n+\n\n&\n\n(\n\n-\n\n-\n\n-\n\n-\n\n-\n\n+\n\n-\n\n+\n\n-\n\n+\n\n'\n$\n(\n\n&\n\n+\n\n\"\n\n+\n\n-\n\n)\n\n+\n\n(\n\n*\n\n+\n\n)\n\n(\n\n%\n\n!\n\n(\n\n+\n\n(\n\n:\n\n!\n\n!\"#\n$\n%\n&\n\n'\n\n&\n\n;\n\n+\n\n!\n\n<=\n>\n\n!(\n\n)*\n$\n\n+\n\n;\n\n)\n\n;\n\n)\n\n;\n\n%\n\n(\n\n;\n\n+\n\n;\n\n?\n\n-\n\n(\n\n+\n\n-\n\n-\n\n\"\n\n-\n\n+\n\n'\n\n%\n\n&\n\n@\n$\n%\n\n(\n\n&\n\n@\n$\n\n+\n\n+\n\n&\n@\n$\n\n(\n\n!\n$\n\n!\n$'\n\n:\nA\n\n+\n\nB>\n\n-\n\n!,+\n-$\n\n(\n\n).\n\n!\n\n$\n\n,\n\n+\n\n%\n\n+\n\n!\n\n!\n\n*\n&\n\n(\n\n(\n\n0\"\n\n*\n\n*\n\n%\n\n(\n\n%\n\n*\n\n+\n\n-\n\n!\n\n*\n\n+\n\n*\n\n+\n\nC\n\n%\n\n$\n\n-\n\n&\n\n\"\n\n\"\n\n*\n\n!\n\n+\n\n-\n\n(\n\n%\n\n-\n\n+\n\n+\n\n%\n\n:\n\n(\n\n+\n\n!\n\n&\n\n&\n\n/\n\n\"\n\n)\n\n-\n\n!\n\n+\n\nB>\n\n#\n\n+\n\n)&\n\n+\n\nD\n\n+\n\n'\n\n>\n\n!\n\nÆ\n\nB>\n\nE\n\n%\n\n>\n\n'\n\n(\n\n:\n\n.F\n\n+\n\n!\n\n/\n\nB\n\n-\n\nG"
    }
  ]
}