{
  "course_name": "Microeconomic Theory and Public Policy",
  "course_description": "This course applies microeconomic theory to analysis of public policy. It builds from the microeconomic model of consumer behavior and extends to operation of single and multiple markets and analysis of why markets sometimes fail. We will study empirical examples to evaluate theory, focusing on the casual effects of policy interventions on economic outcomes. Topics include minimum wages and employment, food stamps and consumer welfare, economics of risk and safety regulation, the value of education, and gains from international trade.\nMITx Online Version\nThis course is part of the Micromaster’s Program in Data, Economics, and Design of Policy through MITx Online. The course is entirely free to audit, though learners have the option to pay a fee, which is based on the learner’s ability to pay, to take the proctored exam, and earn a course certificate. To access the course, create an MITx Online account and enroll in the course 14.003x Microeconomic Theory and Public Policy.",
  "topics": [
    "Social Science",
    "Economics",
    "Microeconomics",
    "Public Administration",
    "Public Policy",
    "Social Science",
    "Economics",
    "Microeconomics",
    "Public Administration",
    "Public Policy"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hour / session\n\nPrerequisites\n\n14.01SC Principles of Microeconomics\nor permission of instructor.\n\nRecommended Books\n\nFor for the first time ever, I'm pleased to include two new texts on the syllabus. Both are lucid, bull-shit free, and occasionally amusing, and available in paperback.\n\nBanerjee, Samiran.\nIntermediate Microeconomics: A Tool-Building Approach\n. 1st ed. Routledge, 2014. ISBN: 9780415870054. [Preview with\nGoogle Books\n]\n\nAngrist, Joshua D., and Jorn-Steffen Pischke.\nMastering 'Metrics: The Path from Cause to Effect\n. Princeton University Press, 2014. ISBN: 9780691152844. [Preview with\nGoogle Books\n]\n\nRequired Readings\n\nEach lecture has an associated set of readings. These readings will feature in lectures, quizzes, exams and problem sets. If a reading is marked required, you are responsible for preparing the paper prior to class. This means reading the Abstract, Introduction and Conclusions (not necessarily the body of the paper) to answer the following questions:\n\nWhat is the paper's research question?\n\nWhat methodology is used to answer the question (e.g., an experiment, a quasi-experiment, a set of correlations, etc.)?\n\nWhat are the key findings?\n\nWhat is the economic interpretation of these findings?\n\nI do not expect you to master the technical details of a paper prior to class. But I do expect you to come to class prepared to discuss the paper.\n\nRecommended Readings\n\nYou will find a number of recommended readings on the syllabus for your education and entertainment. These papers should be useful--and in many cases fun--but you will not be tested on their content.\n\nClass Attendance\n\n14.03 / 14.003 is not a by-the-book micro-theory class. Fully one-third of the class will focus on applications from empirical and theoretical papers from leading journals that we will discuss in class. It will be difficult to master this material unless you attend lectures.\n\nMoreover, there will be approximately six unannounced short quizzes given at the start of the lecture at various points in the term. These cannot be made up. If you take another class that meets at the same time as 14.03 / 14.003, you will have to live with the consequences.\n\nLaptop / Tablet / Phone Use During Class\n\nI strongly discourage you against texting, tweeting, emailing, blogging, posting, browsing, Instagramming, Googling, shopping, etc., during class. It wastes your class-time--since you won't learn anything during lecture if you're distracted. And it's frequently distracting to your classmates. I'm sympathetic to your desire to use your laptop or tablet to view the online lecture notes and take notes of your own. I would encourage you instead to print out the online lecture notes the night before class, and to write your notes directly on the paper lecture notes. In my experience, it's still faster and more accurate to take notes in class using paper and pen than to mark up a PDF file on your device. Of course, you may be faster with a tablet than I am. When I walk around the class during lecture, I will see what's on your screen. If I notice that you are engaging in distracting technology use, I will ask you to close it down or take it elsewhere.\n\nGrading\n\nThe class is not graded on a curve per se. It's possible for everyone to do well, and I'd be happy to have a reason to assign mostly A's. That said, if you make minimal effort, you will probably receive a C or worse. If I think you are headed for a D or F, I will try to warn you before drop date.\n\nACTIVITES\n\nPERCENTAGES\n\nBest five out of six problem set grades\n\n30%\n\nThree exams\n\n60%\n\nBest five of six in-class quizzes\n\n5%\n\nClass participation\n\n5%",
  "files": [
    {
      "category": "Exam",
      "title": "14.03 Exam 1 2009",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/bc8ffdce9620b4515ab2a44245ddcdf6_MIT14_03F16_exam1_09.pdf",
      "content": "! \" #\n$ \"\n%\n\n&\n' % %\n( )*+, -$).,\n!\n/ #\n% %\n% 0\n\n(( 0 1 % ! #\n((( 0 1 %\n\n( / \" / 2 %\n!-% 3 \" 45 #\n6 7 8\n\"\n/ %\n\" 8 \" \"\n%\n\" \" % !) % 9 : % 9 0\n\n:# - 9 %0 \"\n00 8 \"\n\n6 7 -\n% / ;%<9 = >\n> 9% % 9 \" & !/# !/# ) \"\n\" 9 !/# \" ? %\n6 7 * % 0\n\n% 0/\n\n* %\n% 9\n:\n@%0\n\n% 0 * % % * %\n\n6 7 -\n, :\nA: B> 0 (\" \" : \" ,\n\n/ -=\n\" ,\n\"\n3 6 7 8 %\n\nC0 9D 90 <\n0/ 9\n? -\"\n0/ % 9/ \"\n\" 9 > \"\n% 9\n% 9\n%\n4 6 7 0 0 E & CC E=\n\n\" CC\n\n(( '\n!1 15\n#\n'\n% \"\n\n% \" 0\n\n=\n\n6$& (\" 0 : % /\nD % % % % \"\n\"\n64 7\n= \"/\n\n64 7 .\n= *: !\n#\n\"<\n\nF\n64 7 .\n= G !\n#\n\n\"\n\nF\n64 7 . 0 \"\n\n\"\n\"F !& 0 \"<\n\n0 0 \"\n\n\" \" 0 9\n\n\"\n0 \"\n\n#\n3 64 7 8 \"\n\n<\n\n0 \"\n9F\n\n8 \"\n\n0 \"\n9F !&\n\n\"\n\n9 <\n9 > \"\n\n#\n\n((( ' (\" !15 #\n*:?\nG( 90\n1 9: !\n# ) 9:\n!8#/ % %: \"%& G(\n9:\n/ G(\n\"\n\n63 7 8 % \" 9 0\n%0 90 \"\nG( 9 % % 8 E % % 8\n> 9\n<> 9% 9: 0\n\" \" 9 90\n@ 1 0 9: 0 \" G( %\n0 8 @ 1 0 9: 0 \" G(\n% 0 8 \" \"\n> \" 8 G( 9: 0 \"&\n\n9 95 9\n\n63 7\n/ *:?= \"\n/\n8 89 8/\n) G(\n0 % 9 \" 0 9: \"\n\n' 0 ) G( 0\n\n' 0 ( 0\n/ 0 8\n! 9# B\n8 8 : 9:\n0 0\n8 8 &\n\n1 > 0 9: 0 9% %\n0 ! 0 0 <\n0 0 # ) \"\n%\n\" > \" 8 9:\n0 8 9 9 F (\" / %\n\n!\n/ 0/\n#/ %F\n\n63 7 *:\" 0\n\n9 9\n\" 89\n<\n/ \"\n\n/ % %\n\n/ % % % \"\n*:? % : % 8 >\n!# \" 9 ) \"%0 ; <=\n&\n) G(\n\n-0 0/ <\n9 0/\n1 9: 0 \"\n\"\n!\n#\n( 0\n/ 0 0\n\n1 < \" \" 9: 0 \"\n\n)/\n\"\n\n\"\n\n\"\n\n!-\n\n0 :% % 90 <\n9: \" % 0#\nB\nG / 1 9: 0 \" !\n\n# 0\n\n' \"%0\n>\n\n/ > 9: 0 9% <\n\n63 7 E :%0 \"\n/ % %\n\n!\n/ 0/\n/\n#/\n%F *% %\n!\n/ 0/\n/\n\n#/ %F\n\n% \" \"%0\n\n9 8 8 /\n\" /\n/ % % % \" 0\n!#\n% 1\n3 63 7 ) % 8 ! /\n9 9:# %\n\n\"\n\n9: \" G( 0\n\" 6\n\n/ % 9: \"\n\n% 9: \" G(\n0 7\n4 63 7 ) % 9: 8 !\n# % 9 % : 9 > \"\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "14.03 Exam 3 2009",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/a3607de45d0f8224bd680ade60cba9a1_MIT14_03F16_exam3_09.pdf",
      "content": "!\n\"\n#\n$\n\" \"\n\n% \"\n\n& '\n( &\n\n\"\n\n\"\n\n)\n\n*\n+\n,\n\n-\n.\n\n\" '\n/\n\n\"0\n\n**\n\n,\n\n-\n\n.\n\" '\n/\n\n\"0\n!\" !! #\n$%\n\n*) 1 2\") 2\" 3 & + 4 +\n\n#\n, 5\n\n'0\n\n-:\n\n;, &\n,\n,\n<\n-\n=\n\n.\n\n-, .\n\n0 -\n\n&\n\n;, &\n,\n,\n<\n* >\n\n. 0, \"\n\n&\n\n0 \"\n.\" \" ?\n. @ *\n\n,\n\nA\n, 0 @\n\nB\n\n& , 2&\n\n&\n\n,\n\n& ) &\n\n\"\n\n&# *\n\n&\n\n\"\n\n& 0, C, C3, ! #,\n\n2&9\nD1E, , &\n6 .\n0, \",\n,\n\n#@\n\n3 F0\n:\n&\n\n. & 0\", 50\n\n=\n0\" .\n. & G .91\n\n2&\n*\n\n.'\n\n\"\n&\"0\n\" 0\n&\n,\n\n- .\n0 . 0, \"\n\n.\n\"\n\n6 &\n\n.\n\n.=\nH &\n0\" 0 G\n#@\n\n+ $\n\n, 5\n0.\n\n0 +3\n\nH\n&\n\n* \" -\", \",\n\n\"\n0 6 &\n\n$\n\n.=\nH\n&\n\n@\n\n5 4 I) F\nJ- &\nD(5 F\nA $ &\"0 )\n2) &\nB) \" .\n. , \" .\n.\n$) &\n8) \" .\n. , \" .\n.\n2 H .\" 2\nB\nH .\" $\n\nH .\" 2\n$ .\" B\n8#\n;+ < * 2 -9\n, -9\n-90@\n\n;! < 2 \" &\"0 \" )\n\" .\n. , \" .\n. ;()\n\nB<\n\" .\n. , \" .\n.\n6 2 & , & , . H .\" \",\n\"\n\n@\n\n;! < 2 \" &\"0 \" )\n7) &\nK) \" .\n. , \" .\n. , \" .\n. ,\n\" .\n.\n6 2 & 7 K, & K 7, . H .\" \",\n\"\n\n@\n\n;! < 2 \" &\"0 \" )\n*) &\nL) \" .\n. , \" .\n.\n6 2 & * L, & L *, . H .\" \"\n;K)\n\n\"\n<\n\n5 4 I) 2 1\n- &\nMEN\n\" &\n)\n\n\"\n\n.\n\n2 ,\n, \"\n.\n\n&\n&\n\n&\n\n-\n,\n\" .\n\n.\n,\n\n\"\n\n&\n\"0\n\n;3 < 6\n\" . &\n\n& \" & &9\n\n.\n'\n@\n;3 < 6\n\" . &\n\n& . -\" \"\n\n\"\n\n@\n;3 < 2 \"\n.\n&\n\n1 -\"\n\" &\n\" 6\n\" .\n- &\n@\n\n;3 < (\"\n\n# $\n\n.\n&\n\n\" .\n-\n&\n!\n\n3 ;3 < $\n\n2-& * H\n\"\n\n\"\n\n\"\n\n\" &\n\n\" . \"0\n\n@ ;K) B\n\n&\n\n\" \"0\n\n,\n\n\" \" . \"0\n\n<\n+ ;3 < 2-& *\nK\" \"\n&@\nK\" \" &@\n\n5 4 I) 6\n: J- 6@\n;%\n\n& '<\nL\n-9\n, D(5 F\nA, \" & \"\n\n'\n)\n\n8: \"\n\n&\n\n& 0 L: \"\n\n&\n-\n\n;+ < 6\n8:\n'\n& \"\nO\n, \"\n\"\n\"\n\n\" 8\n\n- .@\n;+ < K\n,\nL\n\n8# &\n\n& 0 6\n\"\n'\n& \"\n.@ ;(\n'P\n\n\"\n\" .<\n;+ < 8 H\nL\n.\n- & 0 8 \"\n\nL *& 8 , L\n\nF\n\n0)\n8: \"\n\" '\n\n\"\n\nL: \"\n\" '\n\n,\n\"\n\n& 0\n\"\n\n0 &\n&\n\" . L\n\n0@\n;+ < 6\n\n\" . L\n\"0\n- .\n@\n\n\"\n3 ;+ < 6\n\n0 .\n0@\n\n+\n5 4 I) L. 5\n- 10\n\n\" & \"-\n. &, \"\n. E\"#\n\n. K0# \"-, \" &\n& K0 \"- 2 \"- -\" *&\nK0 \"-\n.\n=\n&\n,\nE\"\n\"- &\n, \" *&\n\"- &\n\n.\n\"- &\n=, &\n\"- \"- & ?\n\n,\n\n& \" Q\n\n=\n.\n. &\n\"- ,\n\n& =,\n& \"\n. =\n\n=\n- &\n\"- & '\n\n& .\n\n\"-: \"\n\n\"- &\n\n=\n\n\"-\n. A '.\n;+ < 6\n\"\n= \"0 H\n& \"-@\n1 & \"\n\n&\nP =\n\"\n-\"\n\"-:\n. K0\n. \"-\nH & \"\n. \"-\n\n& \"0 K0\n. \"-\n\n& \"\n0 &\n\" )\n\n\" \"\n. \"-\n&)\n\n0 & \"-:\nH .\n\nH \"9.0 $\n\n=\n&\n=\n; < \"\n\n&\n0 '. \" .\n& \"- \"\n& 0 @\n; < \"\n\n&\n\n0 '. \" 0\n\"- \"\n& 0\n\" \"- \"\n\n\"\n& 0 #@\n\nC\n5 4 I3)\n0 /\n'\n( # =\n& F1\n\n20 2# %\n. 2\n- 0\n\n& 0 1\n=\n;\n& '\n=\n, . 0\n\n<\n\" &\n\n0, , .\"\n, \"\n/\n/ 5\n\n. ,\n0 =\n)\n\n&\n\n&\n\n0 /\n0, 0\n\n0 1\n0, \" - -\n$\n0 / .\n. 5\n\n0 /\n0 \", . -\"\n0 1\n\n/\n\n0 % A\n,\n'\n, \"\n\n& 0 1\n\n.\n\" 0 1\n\n&\n/\nE '\n\n&\n,\n\n0 / &\n\n(c) ENERGY STAR. All rights reserved. This content is excluded from our Creative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-\nuse/\n\n!\n;+ < %\n\n\"\n\n&\n\n1=\n)\n,\n\n\"\n\n&\n\"\n\n& 0\n& 0 1\n=\n\n.\n\n& 0\n& 0\n=\n,\n\"@\n;+ < 8\n\"\n\" 0 / # A\n\n#\n\n\" .\"\n&)\n# 0 1\n\n- 0\nP\n# 0 1\n\n- 0\n\n;+ < K\" \"\n\n,\n, & 0\n& 0 1\n=\n@ F0\n\n,\n\n' &\n.\n\n& 0\n0 H %\n&\n\n#\n;+ < 2\n\n%\n\n, 0 1\n0 \"\n&\n\"\n* \", & 0 1\n0.\n0 1\n\n0 *\n, -\n\n,\n&\n0 1\n0 &\n\n#@\n\n3 ;+ <\n\"\n\n& 0 9\n\n, , & 0\n& 0 1\n=\n\n& @ ;K) - & 0 1\n=\n\n:=\n0:\n\n.\n. & 0\n0 1\n- & <\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 1 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/f26552d656495d9234bd86df601c30b0_MIT14_03F16_lec1.pdf",
      "content": "Lecture 1 -- Introduction and a First Application: The\nMinimum Wage Debate\nDavid Autor, MIT Department of Economics\n14.03/14.003 Microeconomic Theory and Public Policy, Fall 2016\n\n1 Introduction to 14.03/14.003\nThis is an intermediate course in microeconomic theory and its application to real world policy\nproblems. The class assumes proficiency with economic theory at the 14.01 level as well as mul\ntivariate calculus. It is also quite helpful if you have taken some statistics or econometrics. For\nthose who have not, the Teaching Assistants, will provide a primer on some key statistical\nand mathematical concepts during the initial recitation. In addition,\nthe\nhandout\nMath Tools for 14.03/003 (on the class website), offers a review of some mathematical\nconcepts that you'll be using in lectures, problem sets, exams. I also recommend the brief but helpful\nMathematical Appendix of the required text by Samiran Banerjee, Intermediate Microeconomics: A\nTool-Building Approach.\nThis class is organized around three themes:\n1. Economic theory: Where does it come from, what does it predict, and in what ways is it\nuseful?\n2. Causality: What is it, and how do we measure or estimate causal effects?\n3. Empirical applications: Economic theory is a way of organizing facts and interpreting and\npatterns in the world. This class will use data to test theory and use theory to interpret\ndata. We will analyze numerous randomized experiments and quasi-experiments in the light\nof economic theory.\nDefinition 1. Randomized experiment (also frequently called a Randomized Controlled Trial or\nRCT). In the statistical theory of design of experiments, randomization involves randomly allocating\nthe experimental units across the treatment groups. (Source: Wikipedia, http://en.wikipedia.\norg/wiki/Randomized_experiment).\nExample: If an experiment compares a new drug against a proven existing drug, patients would\nbe allocated to either the new drug or to the existing drug using randomization. A comparison\nof outcomes among patients allocated the new drug and those allocated the existing drug would\nprovide an estimate of the causal effect of the new drug relative to the existing drug. (Note, it would\nnot provide an estimate of the causal effect of the new drug relative to no treatment unless there\nwas also a placebo group in the experiment.)\nDefinition 2. Quasi-experiment. An event that unintentionally creates conditions similar to a\nrandomized experiment.\nExample: One million people buy one lottery ticket each and one hundred of them win. This\nquasi-experiment could be used to evaluate the effect of unanticipated wealth increases on happiness,\nhealth, marital dissolution, obesity. (Indeed a recent high profile paper did just this!)\nThere is an impressive diversity of experiments and quasi-experiments that economists have\napplied to analyze important questions in social science. You may ask, why would a researcher\n\nuse a quasi-experiment instead of an RCT? In reality, RCTs are the gold standard of evidence and\neconomists use them frequently. Indeed, we will study multiple RCTs during the semester. It's also\nthe case that many key economic questions center either around major life choices and outcomes\nsuch as health, wealth, education, and risk, or 'macro-scale' treatments such as international trade,\ncivil war, or epidemic disease. For both ethical and practical reasons, these outcomes are often not\nsuitable for randomized experimentation. In such cases, we look for chance events in the real world\nthat approximate the experiment we would conduct if it were ethically or practically feasible.\nA first application: The minimum wage and employment\nRather than start the class with a discussion of economic methodology, we'll start with an application\nand return to the big picture when that is complete (sometime in the second lecture). The application\nwe'll consider is the impact of the minimum wage on wages and employment. The costs and benefits\nof legislated minimum wages are a central policy topic in economics--an area of ongoing controversy\nand active policymaking (e.g., President Obama would like to raise the national minimum wage from\n$7.25 to $10.10 per hour, a substantial increase, and to increase it further to $12.00/hr by 2020.\nThe Republican party vehemently opposes this change). Here's a mini-outline of what we'll cover\non this topic in the first two lectures:\n1. Textbook model of competitive labor market\n(a) Impact of minimum wage on employment in the textbook model\n(b) Assumptions behind this model\n2. What happens when we relax a key assumption: price-taking by firms\n(a) Impact of minimum wage on employment when employers have market power\n3. Testing the textbook model and alternatives\n4. Economic experiments\n(a) The Fundamental Problem of Causal Inference (FPCI)\n(b) Overcoming the Fundamental Problem\n(c) Notation for causal inference\n(d) Estimating causal effects using \"Differences-in-Differences\" (DD)\n5. The Card and Krueger minimum wage study\n(a) Interpretation and discussion\n\n3 Textbook model of wages and employment\nDefinition 3. Labor supply curve. All potential workers in the labor market, arranged from low\ntop high according to their \"reservation wage,\" (the lowest hourly wage at which they are willing to\nwork)\nDefinition 4. Labor demand curve. All potential employers in labor market, arranged according\nto their willingness to pay (hourly) for a worker\n- Q: What is the key outcome variable in this model: the wage or the number of employed\nworkers? A: Neither. They are simultaneously determined. Another way to say this is that\nthese outcomes are endogenous.\n- In the example above, the demand and supply curves are exogenous. The equilibrium wage\nand employment levels are endogenous.\nDefinition 5. Endogenous. Internally determined. An effect rather than a cause.\nDefinition 6. Exogenous. Externally determined. A causing or forcing variable.\nWhat happens when we impose a minimum wage in this labor market?\n\n- Wages:\n∗\nwmin > w\nEmployment:\nQmin < Q ∗\n- If this model is right why would a policymaker ever want to impose a minimum wage?\n- One possible answer: A binding minimum wage could raise total worker earnings even if it\nreduced employment\n∗ Q ∗\nwminQmin ? w\nTotal worker earnings may increase even if employment falls.\n- What does this depend on? The elasticity of demand:\n∂Q w\nη =\n? -1\nQ ∂w\nIf the proportional increase in wages is larger than the (induced) proportional decline in em\nployment =⇒ wage-bill increases. Specifically, if η > -1 (i.e., |η| < 1), then a 1% rise in wages\nreduces employment by less than 1%, so total wages paid (wages × workers) rises.\nDefinition 7. Elasticity. The ratio of the proportional change in a variable Y caused by a given\nproportional change in a variable X. So for example, if the elasticity of Y with respect to X is 2,\nthen a 1% increase in X causes a 2% increase in Y.\n\n3.1\nWhy do minimum wages reduce employment? Revisiting the theory\n- What is the primary assumption in the textbook model that yields the prediction that (binding)\nminimum wages always and everywhere reduce employment?\n- The answer is price-taking behavior, both in labor and product markets. That is, the price of\nthe good the firm is producing does not fall if the firm makes a few more, and the prevailing\nwage the firm faces does not rise if it hires a few more workers. Formally, product demand\nand labor supply are both perfectly elastic as the far as the firm is concerned.\n- We say \"as far as the firm is concerned\" because each firm is infinitesimal relative to the size\nof the market, meaning that its own labor demand cannot affect the wage level, though of\ncourse, the aggregate demand of all firms in the market does affect the wage level.\nIndividual \"price-taking\" firm\n- MRPL = Marginal Revenue Product of Labor =⇒ \"What the marginal worker produces.\"\n- We normally assume that at any given firm, MRPL is decreasing in employment due to decreas\ning returns in the production function. All else equal, the next worker produces marginally\nless than the prior hire. This could be because the most important tasks are always done first,\nso adding more workers means that some less important tasks are also accomplished.\n- You learned in 14.01 that the firm equates the Marginal Revenue Product with the wage:\nWhere did that come from?\n∗\nMRP L = w .\n\n- Recall the firm's profit maximization problem, which is to maximize the difference between\nrevenues and costs (i.e, profits). Assume that the firm's only input is labor. Denote the first\nderivative of a function f (·) by f' (·) and the second by f'' (·). The firm's problem is:\nmax π = p · f (L) - w(L) · L,\nwhere p is the product price, w(L) is the wage necessary to \"call forth\" L workers, and f (L)\nis the amount of output produced.\n- We assume that f' (·) > 0 and f'' (·) < 0, so an additional worker always raises output, but\nmarginal productivity declines as we add workers. Note that p is not a function of L, meaning\nwe assume that the price of output is taken as given for this problem (it's exogenous).\n- Differentiate this expression with respect to L and set it equal to zero. (Why zero? At the\noptimum, this derivative must equal zero. If not, the firm would want to adjust L further.\nIf the marginal profit were positive, the firm would want to hire more labor. If the marginal\nprofit were negative, the firm would want to hire less labor.)\n∂π\n∂f (L)\n∂w(L)\n= p ·\n- w(L) -\n· L = 0\n∂L\n∂L\n∂L\nRearranging:\npf' (L) = w(L) + w' (L)L\nwhere:\n- pf' (L) is the marginal revenue product of labor (MRP L)\n- w(L) is the equilibrium wage, also equal to the hourly cost of the last worker hired\n- w' (L)L is the additional increment to total labor costs incurred by hiring one more worker\n(excluding the payments to that one last worker). This increment is equal to the product\nof the the marginal wage increase and the size of the firm's entire work force.\n- This third term is potentially important. It says that each additional worker hired (each\n\"marginal\" worker) could potentially raise the cost of all of the previous workers hired (\"infra\nmarginal\" workers). Why? If all workers are paid a single wage (w (L)), and calling forth an\nadditional worker raises that wage, then the cost of the additional worker is not simply w but\nw + w' (L) L.\n- Contrast to the key assumption of the benchmark competitive model:\nw' (L) = 0 ⇐⇒ Price taking firms\nNo firm is large enough to raise the market wage simply by hiring a few more workers.\n\n- If the firm is a price taker in the labor market, it chooses employment so that:\n∗\npf ' (L) = w ,\n∗\nwhere w is the market wage, which the firm takes as given. In other words w = MRP L\n- How does firm choose employment when it is not price taker? According to the FOC above:\npf ' (L) = w(L) + w ' (L)L\nIf w ' (L) = 0\nthen a firm must pay all of its workers a higher wage as it hires each additional\nworker.\n- Here's one convenient way to express this result\npf ' (L) = w(L) + w ' (L)L\n∂w\nMRP L = w +\nL\n∂L\nMRPL\n∂w L\n= 1 +\nw\n∂L w\nMRP L\n= 1 +\nw\nη\nMRP L\nw = 1 + η\nwhere η is the elasticity of labor supply (the percent change in labor supply for a 1 percent\nchange in the wage) as experienced by the single firm. For a price-taking firm, η →inf, meaning\nthat 1/η → 0. So, if a firm is a price taker, the wage is exactly equal to MRPL (since the\ndenominator of the above expression is equal to one). If the firm is not a price taker in the\nlabor market, then the wage it pays is strictly less than MRPL.\n- Why less than the MRPL? As we'll show below, the conditions above imply that the marginal\ncost of labor exceeds the wage because each marginal hire raises the cost of all prior (AKA\ninframarginal) hires: MCL > w. The profit maximizing firm that has market power will\nchoose MCL = MRP L. But since MCL > w, this implies that w < MRPL. Details below.\n3.2\nConventional case: Individual Price Taking Firm\nLet's return to the conventional case of individual price taking firms.\n\n- Notice that the labor supply curve is upward-sloping at the market level, but it is flat as\nperceived by the single firm.\n- If we imposed a binding minimum wage in this market (wmin > w ∗), each firm in this market\nwould reduce its quantity of workers demanded.\n3.3\nMonopsonistic employer\nDefinition 8. Monopsony. \"One buyer, many sellers.\" More generally, monopsony is a case where\nan agent (firm or consumer) is not a price taker in a market in which it is a buyer. Its own demand\naffects the price it pays. (Conversely, monopoly is a case where a firm is not a price taker in a\nmarket in which it is a seller. Its own supply affects the price it commands in the market.)\n- The labor supply curve for a monopsonist is upward sloping. To obtain one more worker, the\nmonopsonist must raise the wage by a small amount.\n- Assuming that all workers receive the same pay (i.e., the late-comers don't get paid more),\nthe marginal cost of the next worker is not simply her wage but also the wage increase given\nto all of the other inframarginal workers.\n- Thus, the marginal cost of labor curve for a monopsonistic firm is even more upward sloping\nthan its labor supply curve. The additional cost for each worker is given by the higher wage\nof that worker and by the increase in wage given to the entire pool of workers.\n\n- What happens if we impose a binding minimum wage on a monopsonistic employer?\n- One case is illustrated above. In this example, implementation of a binding minimum wage\nraises wages and employment:\nwmin > wm\nQmin > Qm\n- Why does that happen? The firm is now a price-taker for labor at wmin. That is, there are\nan unlimited number of workers available (as far as any one firm is concerned) at the going\nwage--so, labor supply to the firm is perfectly elastic at the minimum wage, just as in the\nstandard competitive case (without a minimum wage). The firm chooses\nw = MRP L\nbecause its choice of the quantity of labor has no impact on the wage level. Thus, paradoxically,\nraising the minimum wage can raise both wages and employment in a monopsonistic labor\nmarket.\n- Does raising minimum wage to monopsonists always increase wages and employment? Defi\nnitely not.\n\n1. wmin 1 - Introduction of minimum wage wmin 1 has no effect because the minimum wage\nis below wm and hence doesn't bind\n2. wmin 2 - Introduction of minimum wage wmin 2 raises wages and employment\n3. wmin 3 - Introduction of minimum wage wmin 3 raises wages but reduces employment\n- So, this bit of simple theory presents an interesting possibility. It is conceivable--though not\nnecessarily likely--that a mandated minimum wage could raise both earnings and employment.\nIf so, this is a policy that many policymakers would support (though not most businesses; this\nis a redistribution of wealth from firms and their customers to workers).\nTesting for monopsony in the labor market\nIf monopsony were present in the labor market, where would you expect to find it? (Remember the\ncriterion: the firm's own labor demand changes the market wage.)\n- \"Company towns\" such as old mining towns, where the mining company was the only employer\n- Cases where skills are very specific, e.g. Tesla automobile technicians\n- \"Captive\" labor markets, e.g., spouses of soldiers at rural military bases or in remote island\nlocations.\n- Fast food restaurants located in nearby towns in New Jersey and Pennsylvania? [Clearly, this\nsetting is the least likely place to find monopsony, which makes it an interesting place to look.]\n\n4.1\nTesting for monopsony in the labor market\n- How do we go about testing the monopsony vs competitive model of the labor market?\n- Focus on the key empirical implication that distinguishes these models:\n- In the competitive model, an increase in the minimum wage always reduces employment:\nW ↑→ L ↓\n- In the monopsonistic model, an increase in the minimum wage (may) raise employment:\nW ↑→ L ↑\n- How do you test this implication?\n- We could look across different states and ask ourselves the following question: Is employment\nhigher in states where wages are higher?\n- Let's suppose you find the following pattern:\nWould this convince you that higher wage levels caused higher employment? I hope not!\n- What's the problem with the wage here? We don't know why the wage differs across states.\nFor example, there might be different demand and supply schedules in each state (after all,\nwe don't think the labor market for fast food workers is a nationwide one; presumably, people\nwon't move cross-country for a job at McDonalds).\n\nSince both employment and wages are endogenous outcomes--determined by both supply and\ndemand--this picture tells us essentially nothing about the impact of minimum wages on\nemployment.\n- A further problem: While we may believe in the existence of supply and demand curves as\nan outcome of market processes, we do not ever see these curves. What we observe is the\nequilibrium wage level and the quantity employed. Thus, we cannot directly see whether or\nnot individual firms face upward sloping labor supply (as would occur if they had monopsony\npower).\n- How do we overcome this problem? We need an experiment, specifically, one in which wages\nare raised exogenously. (Why not an experiment that shifts supply inward so that fewer\nworkers are willing to work at any given wage? Consider the empirical implications in both\nthe monopsonistic and competitive cases.)\n- If we could exogenously manipulate the minimum wage, we could study its impact on employ\nment to infer the slope of the relationship between wages and employment (downward sloping\n→ competitive market, upward sloping → monopsony)\n\n4.2\nAn idea: New Jersey's 1993 minimum wage change\n- Notice that the conditions under which the introduction of a minimum wage raises employment\nin a monopsonistic market are only locally satisfied--that is, raising the minimum wage by\n\"too much\" will reduce employment even in the monopsonistic setting. Thus, if we find that\nan increase in the minimum wage raises employment, this is sufficient but not necessary to\nestablish the existence of monopsony.\n- By studying the pre/post change in employment following the adoption of the minimum wage,\nwe can explore whether employment rises (monopsony) or falls (competitive market).\n- Before we explore this relationship empirically, we need to take a moment (okay, a half hour)\nto discuss causal inference.\nA word on 14.03/003 class requirements and expectations\n1. Readings--About one-third of lecture time will be devoted to discussing important published\n(and sometimes unpublished) papers in economics in some detail. If a reading is marked with\na +, you are responsible for preparing the paper prior to class. I do not expect mean that you\nwill memorize and digest the entire article. I do expect you to read the Abstract, Introduction\nand Conclusion so that you can answer the following questions: what is the research question;\nhow did the authors go about answering the question (i.e., what was the research design);\nwhat conclusions did they reach?\n2. Class participation and cumulative in-class quizzes each count for 5% of your grade.\n\n3. There will be 6 problem sets, with your lowest score dropped automatically. The other 5 p-sets\neach count for 6 percent of your grade. Most are due at 5pm on the designated date, though\nthe second p-set is due at 9am at 10/3/2016 (there's a scheduling reason for this). No late\nproblem sets are accepted--that's what the automatic drop rule is for. (Recommendation:\ndon't waste your freebie early in the semester.) Problem sets are a mixture of formal problems\nand questions based on the readings and lectures. All assignments must be electronically\nsubmitted via the class website. (This ensures that everything is submitted on time and nothing\ngets lost.)\n4. There will be about a half-dozen in class quizzes (again, one is dropped). These quizzes will\nbe brief, non-technical checkups on your knowledge of what's going on in the class (readings,\nlectures, problem sets). I also cold call in class to help overcome your natural shyness (and\nequally natural sleepiness).\n5. There will be two in-class exams and one final exam, each 20 percent of your grade. I do not\nre-test the same material on subsequent exams. Thus, each exam roughly covers one third of\nthe material in the class. Of course, much of this material is cumulative, so I would not advise\nyou to willfully forget each third of the class after the corresponding exam.\n6. On attending class. This class is meant to be participatory. The two excellent recommended\ntextbooks (Banerjee and Angrist and Pischke) are meant to serve as references and do not\ncover most of the in class material. The lecture notes fill in more of the picture, but they\nare also not a complete guide to what happens in class. If you don't regularly attend class,\nyou will likely have difficulty on problem sets and exams (and you will be marked down for\nmissing quizzes and for not participating in class). If you were planning to only show up in\n14.03/14.003 for exams, I recommend against taking the class.\n7. The class is not graded on a strict curve. Everyone can do well (or badly). In general, students\nreceive A's, B's, and C's in the class.\n8. If you do only the minimal amount of work in 14.03/14.003, you'll probably get a C. If I think\nyou are heading for a D, I will contact you to recommend that you drop the class. I cannot\nhelp you if your grades plummet after the MIT drop date, however.\n9. Support outside of class:\n- Two recitations are held every Friday, one hour apart. During the recitation, your TAs\nwill clarify class material, help to prep for exams, and review the problem sets. The\nfirst two recitations--including the 1st Friday--will review statistical concepts used in\n14.03/14.003. Unless you have taken a class on probability and multivariate statistics\n(e.g., regression) such as 14.32, it's likely that some of this material will be unfamiliar to\nyou. I'll be using these tools in class but I won't be covering them in detail.\n\n- There are two TA office hours, and one instructor office hour per week (each 90 minutes).\nTAs will try to meet with you by appointment if you are unable to make office hours.\nBut the office hours should be your first recourse.\n- Questions on class topics and problem sets. Use the class web site/Wiki, which we'll\nmonitor.\n- Please do not email us with substantive, class material related questions; these are the for\nthe web site. Of course, personal issues should be handled by email or in person (not on\nthe Wiki).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 10 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/e45ec68f98dcb7bcd7529866c0c44dc6_MIT14_03F16_lec10.pdf",
      "content": "Lecture Note 10: General Equilibrium in a Pure\nExchange Economy\nDavid Autor, MIT and NBER\n\nMotivation\nSo far in 14.03/003, we have discussed one market at a time: labor, sugar, rental properties, etc.\nBut this one-market-at-a-time approach is a convenient fiction--not always a badly misleading\nfiction, but it is still a fiction. Markets are always interrelated: Reducing sugar tariffs reduces\nsugar prices; this reduces employment of sugar cane workers in the U.S.; cane workers apply for\nother farm jobs reducing wages (slightly) among farm workers generally; arable land is freed\nfor other uses; new crops are planted; the price of other farm products fall; real consumer\nincomes rise; rising consumer income increases demand for sweets; the dessert market grows\nand the cafe sector booms, etc. Literally, there is no end to this chain of events. But this raises\nthe question: is there a general equilibrium where all of these connected markets equilibrate\nsimultaneously?\nThe answer is yes, and that's the topic we turn to now.\nAll changes in\nquantities or prices ultimately feed back into the demand and/or supply for all other goods\nthrough several channels:\n- Changes in the abundance/scarcity of resources\n- Substitutability/complementarity of goods whose prices rise/fall\n- Income effects: Changes in the real costs of goods also affect consumer wealth, which\nthen affects uncompensated demand for other goods and services\nTo understand this richer story, we need a model that can accommodate the interactions of all\nmarkets simultaneously and allows us to determine the properties of the grand equilibrium. In\nother words, we need a general equilibrium (GE) model, in contrast to the partial equilibrium\n(PE) models we have used thus far this term.\nThe Edgeworth Box\nTo make the general equilibrium problem tractable, we want to reduce the dimensionality of the\n\"all markets\" problem to something manageable without sacrificing the essence of the problem.\nThe eponymous Edgeworth box (after Francis Ysidro Edgeworth, 1845 - 1926) provides the tool\nwe need. As it turns out, we require only two goods and two people to capture the essence\nof General Equilibrium. The Edgeworth box visually demonstrates the gains in welfare that\nmay accrue from pure exchange of goods, and it perfectly expresses the economic concept of\nopportunity costs. Simple though it is, the Edgeworth Box allows us to intuitively demonstrate\n\n(though not rigorously prove) two of the most fundamental results in economics: the First and\nSecond Welfare Theorems.\n[Note: We will not model or analyze the production of goods in this model, only pure\nexchange. The extension of the GE model to production is fascinating in its own right and well\nworth studying. I have regretfully concluded that 14.03/14.003 simply has too many important\ntopics to cover to leave room for GE with production. If you would like to explore the rudiments\nof this topic on your own, please ask for my GE lecture notes from 14.03/14.003 Spring 2003\nor consult a textbook (Nicholson and Snyder \"Microeconomic Theory: Basic Principles and\nExtensions\" is reasonably good on this).]\n2.1\nEdgeworth box, pure exchange: Setup\n- There are two goods: call them food F and shelter S.\n- There are two agents: call them A and B.\n- The initial endowment is:\nE\n=\n(EF\nS\nA\nA, EA)\nEB\n=\n(EF\nB, ES\nB)\n- The consumption of A and B are denoted as:\nXA\n=\n(XF\nA, XS\nA)\nX\n=\n(XF\nS\nB\nB, XB)\n- Without trade between agents A and B, their consumption bundles will equal their en-\ndowments:\nXA\n=\nEA\nXB\n=\nEB\n- With trade, many exchanges between A and B become feasible, but the following equalities\nmust always hold:\nXF\nA + XF\nB\n=\nEF\nA + EF\nB\n\nXS\nA + XS\nB\n=\nES\nA + ES\nB\nThat is, total consumption of each good is equal to the total endowment of each good.\n- The figure above is called an Edgeworth box. It simultaneously depicts the preferences\nand consumption of two agents. The left and bottom edges of the figure frame the single\nconsumer's consumption bundles and preferences (i.e. the familiar figures from Lecture 3\nand 4). The top and right edges of the figure show the rotated version of the same figure\nfor consumer B (i.e. the familiar figure rotate 180 degrees).\n- Note the elements of this figure:\n- All resources in the economy are represented -the x axis is EA + EB\ns\ns and the y axis\nis EA\nF + EB\nF\n- The preferences of both parties are represented.\n- The notion of opportunity costs is clearly visible.\n2.2\nMarket conditions\nWe assume that any trade that takes place between A and B satisfies the following four condi-\ntions:\n\n(C1)\nNo transaction costs. That is, neither F or S is consumed merely through the act of\ntrading.\n(C2)\nNo market power. Although A and B are the only two agents in this market, we\nassume that each takes price as given and announces his demand for each good\naccordingly. That is, neither one strategically \"withholds\" his goods from the market\nto raise prices, nor does he anticipate that buying more of one good or another may\nraise its price. Although it seems a bit contrived for the agents in a two-person\neconomy to act as price-takers, this assumption is realistic in an economy with many\nagents. Here, we impose the price-taking assumption because we don't actually want\nto add another 100 agents to the model.\n(C3)\nNo externalities. A′s utility depends only on his own consumption of F and S, and\nsimilarly for B. There is no sense in which A′s consumption of F or S indirectly\naffects B or vice versa (e.g., through pollution, jealously, etc.)\n(C4)\nFull information. Both A and B are fully informed about the goods available for\ntrade. This rules out the possibility that B sells A rotten food or A sells B shelter\nthat happens to have a leaky roof.\n2.3\nWhat happens when A and B trade?\n- Starting from point E, the initial endowment, where will both parties end up if they are\nallowed to trade?\n- It is not fully clear because either or both could be made somewhat better offwithout\nmaking either worse off--that is, there are many Pareto-improving allocations that\nare feasible. But it's clear that they need to be somewhere in the lens shaped region\nbetween U 0\nA and U 0\nB.\n- How do we know this?\n- Because all of these points Pareto dominate E : One or both parties could be\nmade better offwithout making the other worse off.\n- In other words, there are potential gains from trade: A would prefer more food and\nless shelter, B would prefer less food and more shelter.\n\n- So hypothetically\nA gives up ES\nA -XS\nA\nA gains XF\nA -EF\nA\nB gives up XF\nF\nA -EA\nB gains ES\nA -XS\nA\n- All points in the lens region are not equally beneficial. We use the concept of Pareto\nefficient to determine the point where the agents have the largest gains from trade.\n- Q: What needs to be true at a Pareto efficient allocation?\n- A: The indifference curves of A, B are tangent. Otherwise, we could draw another\nlens.\n- So trading should continue until a Pareto efficient allocation is reached.\n2.4\nPareto efficient allocations\n1. At a Pareto efficient allocation, it is not possible to make one person better offwithout\nmaking at least one other person worse off\n2. At a Pareto efficient allocation, all gains from trade are exhausted\nHow can you see a Pareto efficient allocation in the Edgeworth box? At a Pareto efficient\nallocation, the indifference curves of A, B will be tangent.1\nThe set of points that satisfy\nthis criterion comprise the Contract Curve (CC). All Pareto efficient allocations lie along this\ncurve. Hence, after trade has occurred, the final allocation will lie somewhere on CC that passes\nthrough the lens defined by the points interior to U 0\nA and U 0\nB.\nNote: In some examples, the Edgeworth box will not have a contract curve. That's because,\nfor problems that yield a corner solution, there will likely be no points of tangency between the\nindifference curves of the two trading parties. But there may still be a set of Pareto efficient\npoints (on the edges) that dominate the initial allocation. For example, if A values good X but\nnot good Y and vice versa for B, there will be no tangency points and the only Pareto efficient\nallocation will involve giving the entire endowment of X to A and the entire endowment of Y\nto B.\n1Except in the case of a corner solution. Imagine if A didn't like shelter and B didn't like food. There is\nonly one Pareto efficient allocation in this case, and it is at a corner.\n\n2.5\nHow do we get from E to a point on the contract curve?\nFamous analogy: Auctioneer (Leon Walras →Walrasian auctioneer).\n1. In the initial endowment, the market clears (that is, all goods are consumed) but the\nallocation is not Pareto efficient.\n2. So, an auctioneer could announce some prices and then both parties could trade what\nthey have for what they preferred at these prices.\n3. Problem: Choices would then be Pareto efficient but would not necessarily clear the mar-\nket.\n4. It's possible there would be extra F and not enough S or vice versa.\n5. So, must re-auction at new prices...\nAt proposed prices:\n- A wants to reduce consumption of shelter and increase consumption of food\n- B wants to increase consumption of shelter and decrease consumption of food\n- But, A wants to increase consumption of food more than B wants to decrease\n\n- A wants to decrease consumption of shelter more than B wants to increase\n- So:\nXF\nA + XF\nB\n>\nEF\nA + EF\nB ⇒Excess demand\nXS\nA + XS\nB\n<\nES\nA + ES\nB ⇒Excess supply\n- What should the auctioneer do? Raise PF/PS.\n- When the auctioneer gets the price ratio correct, the market clears. No excess demand\nor supply for any good.\nThis is a market equilibrium (also known as a competitive\nequilibrium or a Walrasian equilibrium). In this equilibrium:\n- Each consumer chooses his most preferred bundle given prices and his initial endow-\nment.\n- All choices are compatible so that demand equals supply.\n- There is Pareto efficient consumption (i.e. 'Allocative Efficiency'):\n∂U/∂F\n∂U/∂S\n!\nA\n=\n∂U/∂F\n∂U/∂S\n!\nB\n- How do we know Allocative Efficiency will be satisfied?\n- Because both A, B face the same prices PF/PS.\n- Each person's optimal choice will therefore be the highest indifference curve that is\ntangent to her budget set given by the line with the slope PF/PS that intersects E.\n- Because these choice sets (for A, B) are separated by the price ratio, we know they\nwill be tangent to one another but will not intersect. (If we consider an economy with\nmany goods, we can think of the equilibrium goods prices as forming a 'separating\nhyperplane'--which is a generalization of a plane to more than two dimensions--that\ndivides the indifference maps of consumers to create the desired tangency condition\nacross all goods).\n- This equilibrium price ratio will exist provided that:\n- Each consumer has convex preferences (diminishing marginal rate of substitution)\nas we assumed during consumer theory.\n\n- Or, each consumer is small relative to the aggregate size of the market so that\naggregate demand is continuous even if individual preferences are not.\n(This is\nobviously not relevant in the two person case represented by the Edgeworth box.)\n2.6\nAside: How do we know that both (all) markets clear simultane-\nously?\nHow do we know that both (all) markets clear simultaneously?\n- Consider two goods X, Y and two individuals A, B.\n- As above, label A′s demand and supply (endowment) of each good as XA\nx , XA\ny , EA\nx , EA\ny\nand similarly for consumer B.\n- Consumer A′s budget constraint can be written as:\nPxXA\nx + PyXA\ny\n=\nP\nA\nxEx + PyEA\ny ,\nP (XA -EA) + P (XA -EA\nx\nx\nx\ny\ny\ny )\n=\n0,\nPxZA\nx + PyZA\ny\n=\n0,\nwhere ZA\nx is A′s excess demand for good X. ZA\nx = XA\nx -EA\nx .\n- The excess demand is the amount of good x that comsumer A would like to consume\nrelative to her current endowment.\n- Excess demands can be positive or negative (so more precisely, there is either excess\ndemand or excess supply).\n- The above equation (PxZA\nx + PyZA\ny = 0) states that given an initial supply (endowment)\nof goods and a set of prices, an individual's total excess demand for goods is zero. Simply\nput, a consumer cannot buy more than the value of the goods she holds, since the value\nof these goods is her budget constraint.\n- A similar budget holds for consumer B:\nPxZB\nx + PyZB\ny = 0.\n\n- Putting these excess demand functions together gives,\nPx(ZA\nx + ZB\nx ) + Py(ZA\ny + ZB\ny )\n=\nPxZx + PyZy = 0.\nIf, as we have established above, PxZx = 0, this immediately implies that PyZx = 0.\nWhich is to say, that there cannot be either excess demand or excess supply for all goods\nsimultaneously.\n- This observation--that total excess demand must equal zero--is called Walras' Law (after\nLeon Walras). If there are n goods, and there is no excess demand for n -1 of these\ngoods, then there is also no excess demand for the nth good.\n- Intuitively, we get the nth solution for free because we have one more linear equations\nthan we have unknowns (one more goods than we have price ratios). In this example, we\nhave good X, good Y , and one price ratio px/py. Since it is only the price ratio--not\nthe absolute price level--that matters (reflecting the idea that all costs are opportunity\ncosts), then with n goods, the matrix of demands has rank n -1. So, if we solve for the\nmarket clearing prices of n -1 goods, we have also obtained the market clearing price of\nthe nth good.\n- In our two-good exchange economy above, this proves that if the market for food clears\nwith no excess demand or excess supply, then the market for shelter clears simultaneously.\nHow are equilibrium prices set? The First Welfare The-\norem\nYou do not need the auctioneer.\n- Leon Walras loosely proved that the market can reach this equilibrium without assistance\nfrom a central planner, that is, without an auctioneer (okay, Walras asserted this and\ncouldn't actually prove it, but his conjecture was correct). This result--the existence\nof general equilibrium as a self-organizing outcome of the market--is fundamental. The\ndescription that Walras used was that the economy would reach equilibrium through a\nprocess of Tattonment (literally, \"groping\"). (See Nicholson and Snyder chapter 13 for a\nmini proof sketch using Brouwer's fixed point theorem.)\n- This equilibrium is a result of:\n\n1. Endowments of all consumers\n2. Preferences/tastes of all consumers (stemming from utility functions)\n3. In a model with production: technologies for turning factors (land, labor, capital)\ninto goods\n- Notice that we previously said in the partial equilibrium model of consumer choice that\nthe consumer's optimal consumption bundle is a function of three things:\n1. The consumer's preferences\n2. The market price ratio\n3. The consumer's budget\n- In the General Equilibrium model, these three items each have a direct mapping:\n1. Preferences are a primitive in both models\n2. The price ratio in the PE model is an emergent property of the GE model stemming\nfrom preferences, endowments and technologies. That is, while the PE model prices\nare exogenous, in the GE model, they are endogenous.\n3. The budget in the PE model corresponds to the endowment in the GE model. How-\never, there is an important difference between the two models. In the PE model,\nthe consumer's budget set is taken as given. In the GE model, the budget is de-\ntermined by the interaction between preferences and endowments. So, although the\nconsumer has an exogenous endowment in the GE model, the corresponding budget\nset--that is, the bundles that the endowment can be traded for--is determined by\nthe equilibrium of the model.\nEfficiency\n4.1\nFirst Welfare Theorem: A free market, in equilibrium, is Pareto\nefficient\nWhat Walras showed, and what is clear from the Edgeworth box, is that a competitive market\nwill exhaust all of the gains from trade. That is, it will be Pareto efficient.\nNote that the following stringent conditions must be satisfied for this result to hold:\n\n(C1)\nNo externalities\n(C2)\nPerfect competition\n(C3)\nNo transaction costs\n(C4)\nFull information\nUnder these conditions, the First Welfare Theorem guarantees that the market equilibrium will\nbe Pareto efficient. A bit later in the semester, we will begin to examine what happens to market\nequilibria and market efficiency when these conditions are not satisfied. We will particularly\nfocus on the market maladies that stem from externalities and imperfect information.\n4.2\nAnother take on the First Welfare Theorem\n- We can think of the General Equilibrium problem as a utility maximization subject to\nthree constraints:\n1. No actor is worse offin the market equilibrium than in the initial allocation. This\nwill always hold because an agent could always refuse to trade and consume her\noriginal endowment. Thus, no party can be made worse offby trade relative to her\ninitial endowment.\n2. In equilibrium, no party can be made better offwithout making another party worse\noff(otherwise there are non-exhausted gains from trade).\n3. No more goods can be demanded/consumed than the economy is endowed with (a\nresource constraint).\n3a No goods are left unconsumed--that is, there is no excess supply. This is not truly\na constraint--it's simply a property of any equilibrium, which follows from non-\nsatiation.\n- The First Welfare Theorem says that the free market equilibrium is the solution to the\nabove problem. Simply by allowing unfettered trade among atomistic market actors, the\nmarket solution--that is, the price vector and resulting equilibrium choices--will satisfy\nthe three constraints above.\n- This is an important and non-obvious result. It implies that the decentralized market con-\ntinually \"solves\" a complex, multi-person, multi-good maximization problem that would\n\nbe difficult for any individual (or large government agency) to solve by itself due to the\ninformation requirements.\n- Of course, markets are not always (or necessarily ever) \"in equilibrium,\" and conditions\n(C1) - (C4) for efficiency are not always (or necessarily ever) satisfied. So, the market\nsolution may not be perfect. But one should also ask: would a \"central planner\" generally\ndo better? We will discuss this question at various points throughout the semester.\n4.3\nSecond Welfare Theorem\n- Q: Does the First Welfare Theorem guarantee that the market allocation will be \"fair\" or\nequitable? Of course not! The First Welfare Theorem simply says that the market will\nenlarge the pie as much as possible; it has nothing to say about who gets what share. If,\nfor example, the initial endowment had A consuming all goods and B consuming nothing,\nand assuming that A had standard preferences, then the initial allocation would be Pareto\nefficient; there are no further gains from trade available to A and B. Here, the Pareto\nefficient market allocation would also be maximally inequitable.\n- This raises a fundamental question: Is there a trade-offbetween enlarging and dividing\nthe pie--that is, between efficiency and equality?\n- Stated rigorously, given a Pareto efficient allocation of resources, will there exist prices\nand an initial endowment such that this allocation is also an equilibrium? Concretely,\ncan any Pareto efficient allocation be supported as a competitive equilibrium?\n- If the answer to the above questions is yes, then there is no intrinsic trade-offbetween\nefficiency and equality. If the answer is no, then clearly there is a trade-off.\n- The Second Welfare Theorem says that the answer to these questions is yes.\nSecond Welfare Theorem: Providing that preferences are convex and conditions C1-C4 are\nsatisfied, any Pareto efficient allocation can be supported as a market equilibrium.\nThe reasons are self-evident in the Edgeworth diagram (though this is a far from a proof):\n- Along the contract curve, every point represents the tangency point of two indifference\ncurves\n- This tangency point corresponds to a price ratio that separates the two tangent indiffer-\nence curves\n\n- This price ratio clearly must exist if the indifference curves are tangent and each is convex\n(so they don't recross at some later point)\n- This price ratio is therefore the market price vector that will support that particular\nPareto efficient allocation.\nHence, it is immediate from the Edgeworth box that all Pareto efficient distributions--that\nis, all points on the Contract Curve--are feasible as market equilibria. As long as the as-\nsumptions above are met, a competitive equilibrium will exist merely because each person is\nself-interestedly maximizing her own well-being.\nThe Second Welfare Theorem therefore implies that there is no intrinsic trade-offbetween\nequity and efficiency.\n[Notice that the converse is also generally true: non-Pareto efficient\nallocations cannot be attained in equilibrium.]\nWhen we discussed partial equilibrium welfare analysis (as in case of the U.S. Sugar Program\nor the market for real estate brokers), we implicitly assumed that it was justifiable to maximize\nthe sum of producer and consumer surplus, rather than worrying about their division. The\nSecond Welfare Theorem is the result that justifies that approach.\n4.4\nIf we don't like the distribution of wealth in the market equilib-\nrium, how do we change it?\nHow do we get from one Pareto efficient allocation to another? It would seem that there are\ntwo tools available: lump-sum redistribution (i.e., where I reallocate food and shelter from A\nto B) and taxation to change the price ratio so that a different equilibrium obtains.\nBut these tools are not equivalent. What happens when we change the price ratio (by fiat)\nin this model to achieve some alternative equilibrium? The answer is clear from studying the\nEdgeworth box.\nInterpreting the Fundamental Welfare Theorems\nThe fundamental welfare theorems provide some very basic policy guidance:\n- The function of the price mechanism is to ensure that all resources are consumed in a\nPareto efficient fashion--that is, all gains from trade are exhausted.\n- Under assumptions C1 through C4, this occurs automatically as prices adjust to clear the\nmarket.\n\n- Distorting the price system to achieve equity is generally not a good idea (as you will\nexplore in Pset #4). Such distortions generally do create a trade-offbetween efficiency\nand equity--which is exactly what the Welfare theorems say we do not need to do.\n- This does not mean we should ignore equity, however. We can achieve whatever equitable\nallocations of resources is desired through lump-sum distributions.\n5.1\nIs this dictum--don't distort prices--always correct?\n- No. Because the strong assumptions underlying the Welfare Theorems are not always--or\nperhaps ever--satisfied.\n- But the first and second welfare theorems do build a prima facie case that free market\noutcomes may be efficient--or at least hard to improve upon.\n- When there is a case to be made for intervening in market outcomes (and there often is),\nthis case should depend upon:\n- A reasoned diagnosis as to why the market allocation is not optimal.\n- A policy prescription that builds on an analysis of how a specific intervention will\nremedy this fault.\n- A careful accounting of the likely distortions (deadweight losses) that will result from\ntampering with the price system.\n- Improving on market outcomes generally benefits from a rigorous analysis of why these\noutcomes are not desirable and, preferably, a proposed correction that harnesses the useful\nproperties of markets to improve the outcome.\n5.2\nAre the welfare theorems non-obvious?\nMIT economist and Nobel laureate Paul Samuelson once said, \"There are few things in eco-\nnomics that are both universally true and non-obvious.\" The fundamental welfare theorems are\narguably one of those exceptional things. Why would anyone assume that prices are anything\nother than arbitrary social creations? This insight--that the free market system generates a\nPareto efficient equilibrium through the endogenous emergence of prices--is one of the great\ninsights of classical economics. Economic theory suggests that market equilibria (and prices\n\nthemselves) have a fundamental logic that is an emergent property of the rational, atomistic\nactions of market participants.\nThe key insight: Blind pursuit of self-interest by autonomous actors in a market setting\nyields collectively welfare maximizing behavior. Under certain (strong) assumptions, this equi-\nlibrium cannot be improved upon without making at least one person worse off(Pareto effi-\nciency).\nAdam Smith published The Wealth of Nations in 1776. It's clear that Smith intuitively\nunderstood the First Welfare Theorem when he wrote:\n\"It is not from the benevolence of the butcher, the brewer, or the baker, that we\nexpect our dinner, but from their regard to their own interest. We address ourselves,\nnot to their humanity but to their self-love, and never talk to them of our necessities\nbut of their advantages...\"\n\"Every individual necessarily labors to render the annual revenue of the society as\ngreat as he can. He generally indeed neither intends to promote the public interest,\nnor knows how much he is promoting it. ... He intends only his own gain, and he\nis in this, as in many other cases, led by an invisible hand to promote an end which\nwas no part of his intention. ... By pursuing his own interest he frequently promotes\nthat of the society more effectually than when he really intends to promote it. I\nhave never known much good done by those who affected to trade for the public\ngood.\"\nSmith had apparently convinced himself of the first welfare theorem, though it's not clear that\nhe thought of the second. But it was 150 years until either welfare theorem was proved.\n- Pareto and Barone proposed the 1st and 2nd welfare theorems formally in the 1930s.\n- These theorems were proved graphically in 1934 by Abba Lerner.\n- They were proved mathematically by Oskar Lange in 1942 and Maurice Allais in 1943\n(for which Allais won the Nobel Prize in 1988).\n- It was not until 1954 that papers by Lionel McKenzie and, independently, by Kenneth\nArrow and Gerard Debrau, proved the existence of general equilibrium in a market econ-\nomy.\nPrior to Adam Smith--and long afterward--market behavior has been viewed with great suspi-\ncion. An example from Helibroner (1953), The Worldly Philosophers (New York: Touchstone).\n\nIn 1639 in Boston, the respected merchant Robert Keayne was charged with a\ncrime: He had made over sixpence profit on the shilling, an outrageous gain. The\nBoston court debated whether to excommunicate him for his sin. In view of his\nspotless past, the court instead fined him 200 pounds (a huge sum!). Keayne was\nso distraught over his sin that he prostrated himself before the church elders and\n\"with tears acknowledges his covetous and corrupt heart.\"\nThe minister of Boston could not resist the opportunity to make an example of\nKeayne. In his Sunday sermon, he used the example of Keayne's avarice to denounce\n\"some false principles of trade:\"\nThat a man might sell as dear as he can, and buy as cheap as he can. [Buying\nlow, selling high.]\nIf a man loses by casualty of sea, etc., in some of his commodities, he may raise\nthe price of the rest. [A reduction in supply may increase the market price.]\nThat he may sell as he bought, though he paid too dear. [Selling at a price that\nthe market will bear.]\nThat free markets may produce socially desirable outcomes is a fundamental insight of eco-\nnomics. Two-hundred and thirty years after Smith wrote The Wealth of Nations, this idea is\nnot widely understood outside of the economics profession, though it has had a profound effect\non the organization of modern economies.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 11 Example Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/7201a9c19145a0d7bfb78ab1bb32a331_MIT14_03F16_lec11a.pdf",
      "content": "Example -- Taxation Versus Lump Sum Transfers in the\nEdgeworth Box\nDavid Autor, MIT and NBER\n14.03/14.003, Microeconomic Theory and Public Policy, Fall 2016\n\nSetting\nConsider an economy with two goods, X and Y , and two consumers A and B. These consumers\nhave identical preferences:\nUA (X, Y ) = XAYA, UB (X, Y ) = XBYB\nInitial allocations are EA (X, Y ) = (1, 2) and EB (X, Y ) = (1, 0). Hence, the total endowment\nof the economy is E (X, Y ) = (2, 2) and A is wealthier than B. With these specific preferences,\nthe contract curve of the economy runs through the center of the Edgeworth box (that is, it a\nline connecting the southwest and northeast vertices). You can confirm for yourself that from\nany initial endowment, A and B will trade at a price ratio p = pX/pY = 1 until they reach\nthe contract curve. (Of course, if they are initially on the contract curve, then there will be\nno further trade). With these initial allocations, the equilibrium of this economy will have the\nfollowing consumption bundles: dA (XA, YA) = (1.5, 1.5) and dB (XB, YB) = (0.5, 0.5) .\nAside: Deriving the equilibrium in this economy\nHow did we derive that? Here's one way. First, solve for the Marshallian demands of both\nconsumers, which are:\ndX\nIA\nA = 2PX\ndY\nIA\nA = 2PY\ndX\nIB\nB = 2PX\ndY\nIB\nB = 2PY\nNotice that IA and IB are determined by the initial endowments and the price ratio. Since\nit is the price ratio (not the level of both prices) that determines consumption choices, we\ncan normalize PX = 1 while using PY as our price variable (we could instead have normalized\nPY = 1 and used PX as our price variable). Applying this normalization, we have:\nIA = 1 + 2PY , IB = 1 + 0PY .\n\nWe can substitute these income levels back into the demand functions to obtain:\ndX\n1 + 2PY\nA =\n, dY\nA = 1 + PY .\n2PY\ndX\nB = 2, dY\nB =\n2PY\nFinally, we can find the price PY that clears the market, respecting the economy's endowment\nof each good (2X and 2Y ):\ndX\nA + dX\nB = 2 = 2 + 1 + 2PY\n.\n⇒PY = 1\nBy Walras law, this same PY should clear the market for good X. Does it?\ndY\nY\nA + dY\n1 + 2P\nB = 2 =\n2PY\n+\nP\n2PY\n⇒\nY = 1.\nYes it does.\nIt's also useful to note the properties of the MRS with these utility functions.\n∂U/∂X\nMRSxy = ∂U/∂Y = -Y\n-X = Y ,\nX\nwhich is true for both consumers since they have identical utility functions.\nThis MRS is\ncompatible with many price ratios; it simply says that the more X that the consumer has\nrelative to Y the more she is willing to pay for Y at the margin. However, if consumers A and\nB are trading with one another, and they are on the contract curve (and not at a corner where\neither A or B possesses the entire endowment, it must be that\nMRSA\nxy = MRSB\nxy.\nThis will only be true if YA\nXA = YB\nXB . Thus, the contract curve in this particular case will have the\nproperty that if A is consuming (XA, YA) then B will be consuming (XB, YB) = (αXA, αYA),\nwhere α is a positive constant on the open interval between 0 and infinity. (Note again that\nthis reasoning does not apply at the corners since the MRS of this particular utility function\nis undefined at X = Y = 0.) The contract curve will therefore be a line that extends from the\nsouthwest to northeast corners of the Edgeworth box with slope equal to the ratio of Y to X\nin the economy. In our example here, the economy is endowed with 2 units each of X and Y ,\nwhich implies that the slope of the contract curve is 1.\n\nRedistribution\nA hypothetical government in this two-person economy might that the final allocation is unde-\nsirable (inequitable) since A is consuming three times as much of each good as B. Let's say that\nthis government decides that a preferable final consumption bundle would be: d\n′\nA (XA, YA) =\n(1.25, 1.25) and d\n′\nB (XB, YB) = (0.75, 0.75) . Notice that this bundle is on the contract curve,\nhence, by the Second Welfare Theorem, it can be supported as a competitive equilibrium.\nHowever, this bundle is not attainable as a market equilibrium from the initial endowment.\nWe know this because agent A would be worse offunder the government's preferred allocation\nthan under his initial endowment: UA (1, 2) = 2, UA(1.25, 1.25) = 1.56. Thus, A would never\nvoluntarily move from EA to d\n′\nA. How could the government attain its preferred outcome? Let's\nconsider two options.\nAltering prices\nOne option is for the government to announce a price ratio other than the market price ratio to\nchange the final consumption equilibrium. If, for example, the government were to announce\nthat PY = 1/3, the new price ratio would trace a ray that extends through both the initial\nendowment point and the point on the contract curve that corresponds to the government's\npreferred outcomes. You can see this as follows: with prices PX = 1 and PY = 1/3, A′s bundle\nwould have value IA\n′ = 1 + 2\n3 = 5\n3, which would provide the purchasing power required to buy\n1.25 each of good X and Y . Similarly, B′s bundle would be worth 1, which would allow B to\npurchase 0.75 each of goods X and Y . This price ratio would therefore be compatible with A\nand B each consuming the government's preferred bundles d\n′\nA and d\n′\nB.\nBut would A and B choose these bundles? We can answer this question by calculating their\ndemands at these prices:\ndX\n1 + 2/3\n′\nA =\n= 0.83\ndY\n1 + 2/3\n′\nA =\n= 2.5\n2/3\ndX\n′\nB = 2\ndY ′\nB = 3.\nThe answer is no, A and B would not choose the government's preferred bundles, even though\nboth would be feasible given the government's mandated price ratio and A′s and B′s endow-\nments. With the price of Y depressed below its equilibrium level, there would be excess demand\n\nfor Y (dY ′\nY ′\nX′\nX′\nA + dB = 3.25) and insufficient demand for X (dA + dB = 1.23). In fact, there is no\nprice ratio other than p = PY = 1\nPX\nthat would clear the market given consumers' preferences\nand the economy's total endowment of X and Y . At any announced price ratio, consumers A\nand B will have Marshallian demands that are privately optimal given their preferences; that\nis, if these demands are feasible, we would have ∂U/∂Y\n∂U/∂X = PY\nA\nPX for both\nand B. But if p = 1,\nthese demands will not be feasible because there will be excess supply of one good and excess\ndemand for the other.\nOne could concoct more elaborate policies, of course. For example, the government could\ncharge different prices (or price ratios) to A and B. Given the preferences specified above and\nthe economy's total endowment of X and Y , however, there is exactly one price ratio that\nextends from the initial endowment through the contract curve and crosses that curve at a\nslope that is tangent to the indifference curves of both consumers. The only price ratio that\nwill put both A and B on the contract curve is p = 1. (Of course, there are an infinite number\nof rays that extend from the endowment to the contract curve and an infinite number of rays\nthat cross the contract curve at a slope tangent to both A′s and B′s indifference curves at the\npoint of intersection. But there is only one ray that satisfies both criteria.)\nWhat this example indicates is that manipulating prices will not simultaneously solve the\nefficiency and equality problems (the equality problem being the government's objective of\ngenerating a more equal distribution of consumption). The market will solve the efficiency\nproblem on its own through the emergence of prices that allow consumers to move from EA, EB\nonto the contract curve. Thus, the price ratio is the market's solution to the efficiency problem.\nIf the price ratio is instead used by the government to solve a different problem, it will not\nlikely also solve the efficiency problem simultaneously (unless the government desires the market\noutcome).\nLump sum redistribution\nDoes this mean that the government is out of options? Nope. The Second Welfare Theorem\nsays that any Pareto efficient allocation--any allocation on the contract curve--is supportable\nas a market equilibrium. The question is how we get from EA, EB to that equilibrium. If\nmanipulating the price ratio is not a feasible solution, then there's another free parameter that\nwe can work, which is the endowment itself. (We assume that the government cannot directly\nmanipulate preferences, though some would disagree.) The government could potentially per-\nform lump sum transfers to redistribute goods from A to B or vice versa. This lump sum\nredistribution is different from directly altering the price ratio because after redistribution has\n\noccurred, the price ratio would still be allowed to adjust freely to find the market equilibrium.\nHow would the government accomplish its objective through lump sum transfers? One way\nis for the government simply to move the endowment to the desired location: E\n′\nA (XA, YA) =\n(1.25, 1.25) and E\n′\nB (XB, YB) = (0.75, 0.75) . Because this location is on the contract curve, A\nand B would remain at this location if placed there. But in fact, there are many allocations\nthat would serve this purpose. Given that the price ratio will always be p = 1 in this economy\ngiven A′s and B′s preferences and the economy's total endowment of X and Y , any endowment\nthat has the following form will lead to the same consumption choices:\nEX\nY\nA + EA = 2.5,\n(which further implies that EX\nB + EY\nB = 1.5 due to the adding up constraint). Restating, any\npoint on a line that is perpendicular to the contract curve at the government's desired location\nd\n′\nA, d\n′\nB will yield an equilibrium consumption set that is equal to d\n′\nA, d\n′\nB.\n(Note that this\nlinear/perpendicular solution is not a general result for all preferences. It derives specifically\nfrom the preferences of A and B and the endowment of this economy, all specified above.)\nWhat's the lesson here?\nThe point of this analysis is a simple but general one. Prices serve a fundamental function\nin a competitive economy, which is to move the economy from the initial endowment to a\nPareto efficient allocation that clears the market (no excess demand or supply) and leaves no\nconsumer worse offthan she was at the initial endowment. (Note: competitive means that\nall of the strong preconditions for the First Welfare Theorem are met). Altering prices in a\ncompetitive economy either by fiat--i.e., announcing that the new price ratio is PZ--or by\ntaxing one price and subsidizing another will thwart the allocative function of market prices.\nThis will generally lead to a set of undesirable distortions, manifest in the presence of excess\ndemands and supplies of various goods. At regulated (non-market) prices, consumers will not\nbe able to obtain all of the goods that they're seeking at regulated prices; simultaneously, other\ngoods will go unconsumed.\nIn broadest terms, altering prices (typically through taxation) is a distortionary mechanism\nfor achieving redistribution because it generates Pareto inefficient consumption. A potentially\nmore efficient way to achieve similar objectives is to perform lump sum redistribution while still\nallowing prices to clear the market. Lump sum transfers (or lump sum taxation), unlike direct\nadjustments to prices, do not distort consumer decisions at the margin. Once transfers are\ncomplete, the market will generate equilibrium prices that accurately reflect the opportunity\n\ncosts of goods that consumers wish to trade and thus move consumption to Pareto efficiency.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 11 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/74375e26b6abc29bc92b9677fe2be867_MIT14_03F16_lec11.pdf",
      "content": "Lecture Note 11 -- Applying the GE Framework to\nConsumer Markets: Fishing in the state of Kerala, India\nDavid Autor, MIT and NBER\n14.03/14.003, Microeconomic Theory and Public Policy, Fall 2016\n\nApplying the GE Framework to Consumer Markets: Fishing\nin Kerala (\"The Digital Provide,\" Robert Jensen, 2007)\nWe will discuss the empirical details of the \"Digital Provide\" paper in class. There are three\nsubstantive points related to the paper that I explore in these lecture notes:\n1. How do we illustrate the gains from trade in Kerala using the Edgeworth box?\n2. How can we be sure that the integration of markets in Kerala is welfare enhancing?\n3. What is \"the law of one price\" and why is it relevant here?\nGains from trade in Kerala in the Edgeworth box\nConsider the Edgeworth box below with two consumers, A and B, who have two sources of\nnourishment, rice and fish. Each day, A and B harvest a fixed quantity of rice, depicted in the\nfigure by the dashed line, and they also go fishing. On some days, the fish schools are primarily\nin A's fishing area and on some days, the fish schools are primarily in B's fishing area. Let's\nassume for simplicity that their total catch (the sum of their two catches) is identical on each\nday. That is, their catches are inversely correlated so that when A has a big catch, B has a\nsmall catch and vice versa.\nIn this diagram, the curve connecting the vertices is the Contract Curve, i.e., the set of\nPareto efficient allocations. In autarky (that is, no trade), A and B each consume their own\nendowments each day. This is clearly not Pareto efficient. The lens shaped regions extending\nfrom the two different endowments (big catches for A and B, respectively) show the unexploited\ngains from trade.\nIf A and B could trade fish for rice on any day, this would improve the welfare for both\nparties under both sets of circumstances (i.e., A or B has a big day). Even though A is relatively\nwealthy in one state and B is relatively wealthy in the other, both benefit from the opportunity\nto trade on either occasion. The reason is that neither party prefers to consume either a lot of\nfish or a little fish with the average daily allotment of rice. On a day when A has a big catch,\nhe'd prefer to trade some of that catch for additional rice; on a day when A has a small catch,\nhe'd prefer to trade some of his rice for additional fish--and vice versa for B. Thus, there are\npotential gains from trade no matter which endowment prevails on a given day.\n\nFurther gains from market integration when endowments\nvary: consumption smoothing\nWhen we first discussed the Edgeworth box, we gave each person a fixed endowment. In this\nsetting, however, people's endowments vary from one day to the next. If fish were storable,\nthis distinction theoretically wouldn't matter: A could simply pool (pun intended) her catch\nacross good and bad days. This would give her the option to consume the same amount of fish\neach day. Of course, B could do similarly. Yet fish are not storable in a setting with no giant\nfreezers (don't test this), so consumers' endowments do vary over time in this setting. With an\nintegrated market, A and B could agree to share their fish so that on any given day, they pool\nand split their catch.\nThe possibility of pooling the catch is illustrated in the diagram above as the midpoint\nbetween the two possible endowments (corresponding to good days for A and and good days\nfor B). Notice that even at this mid-point, A and B would want to trade further to reach the\ncontract curve. This reflects differences in their preferences. Starting from identical endowments\n\n(the point in the middle), A would happily give up fish for a little more rice and B would happily\ngive up rice for a little more fish.\nWould A and B prefer to \"pool\" their fish catch each day and then trade, or would they\nprefer to trade from their randomly drawn, more volatile endowments?\nOr is the answer\nindeterminate? In a world of risk and uncertainty, in which A or B could have lots of \"bad\" days\nin a row, this question is actually difficult to address using the tools currently at our disposal.\nWe'll come back to the question later in the semester when we study risk and insurance. We\ncan, however, address a slightly simpler question right now: would A and B prefer to alternate\n\"good\" and \"bad\" days or keep the same consumption every day?\nWe'll use a simple parametric example (i.e. an example with specific functional forms) to\nanswer this question, but the lesson is in fact a general one. You can put away the Edgeworth\nbox for a few minutes, and pretend that A and B have a constant amount of wealth each day\nbut don't have any alternative suppliers of fish. Assume that both A and B have standard\npreferences that satisfy our five axioms, and that their Marshallian demand curves for fish\nare unambiguously downward sloping. Assume that fish is a small part of their consumption\nbundles, so that income effects can be ignored (Hicksian and Marshallian demand don't differ\nby much).\nHolding wealth and the price of all other goods constant, assume that both A and B have\npersonal demand curves of the form:1\nQ = 60 -P.\nFor example, if the price of fish is 20, A and B would each buy 60 -20 = 40 fish.\nOn a good day, A catches 40 fish, and on a bad day, she catches 20. B′s catches are just\nthe opposite: when A has a good day, B catches only 20 fish, and when A has a bad day, B\ncatches 40 fish.\nWould A and B prefer to consume 40 and 20 fish each on alternating dates, or would they\nprefer to consume 30 every day? To answer this question, we need to calculate the utility A gets\nfrom these bundles. Although we cannot answer this question in terms of \"utils,\" we can answer\nit in terms of surplus, which is simply the area under the demand curve. (While surplus isn't\nexactly the same as welfare, we know that situations with more surplus for a given consumer\nalso produce more welfare for that consumer.)\nInverting the demand curve above gives us the price that A and B would be willing to pay\n1Our substantive conclusions do not depend on their demand curves being identical. They just need to be\ndownward sloping.\n\nfor fish as a function of quantity:\nP = 60 -Q.\nThey are willing to pay $59 for the first fish, $58 for the second, etc. So, how much are they\nwilling to pay for a bundle of Q fish? The answer is the area under the demand curve:\nWTP (Q)\n=\nˆ Q\nP (Q) dQ\n=\nˆ Q\n(60\n-Q) dQ\nQ2\n=\n60Q -\nQ\n+ c\n\nHence, on high and low days, their total WTP for the bundle\n\nof fish they consume is:\nQ2\nWTP (40)\n=\n60Q -\n+ c\n\n= 2400\n-800 + c\n-c = 1, 600\nWTP (20)\n=\n\n-200 = 1\n\n, 000.\nHence, total WTP across the two days is 2, 600 and average WTP is 1, 300.\nNow, if A and B split their catch each day, they'd each get 30 fish. How much would they\nbe willing to pay to consume this quantity daily?\nWTP (30) = 1800 -450 = 1, 350.\nIn this case, total WTP across two days is 2, 700 and average WTP is 1, 350. So A and B would\nprefer to split their catch every day rather than eat more fish on high days and less fish on low\ndays (that is, 2 × WTP (30) > WTP (40) + WTP (20)).\nWe can also illustrate this result graphically. Consider the diagram below\n\nThe three regions of this figure correspond to A or B′s willingness to pay for the first 20,\nnext 10, and subsequent 10 fish. Call these areas a, b and c. To consume 40 fish one day and\n20 the next, A or B′s total willingness to pay is:\nWTP (40) + WTP (20) = a + (a + b + c) = 2a + b + c\nTo instead consume 30 fish on both days, A or B′s total WTP would be:\n2 × WTP (30) = 2a + 2b\nSince area b is greater than area c, the consumer prefers to consume a consistent quantity\nrather than experiencing feast and famine. This idea of evening out consumption swings is\noften referred to as \"consumption smoothing\".\nWhile we used a specific example here, this general principal follows directly from con-\nsumers' diminishing marginal rate of substitution. If the marginal utility of fish is declining\nin consumption, the consumer obtains less utility from consuming two extreme bundles (one\nhigh in fish, one low in fish) than from consuming the average of these two bundles twice.\n\nNotice that this result would not necessarily hold absent diminishing MRS for fish. In that\ncase, the demand curve for fish would be perfectly elastic (meaning a straight horizontal line\nat a fixed height), and the consumer would be indifferent between the average bundle and the\ntwo extreme bundles.\nReturning to the gains from trade, this example suggests that A and B can improve welfare\nnot merely by trading from their autarkic position each day but also from trading over time to\npool resources (you can envision this as a new Edgeworth box for each discrete time period).\nAlthough A and B cannot store fish, they could agree to a binding contract to share their\ncatches, which would have the effect of reducing the swings in consumption over time for each\nparty.\nApplying \"the law of one price\"\nNow let's return to our standard Edgeworth box, and discuss the law of one price. The law\nof one price states that in competitive equilibrium, prices for a given commodity should be\nequalized across markets. This is a necessary condition for Pareto efficiency: if prices differ\nacross consumers for the same commodity, consumers will not be able to buy and sell until\nthey equate MRS's across goods. Their psychic rates of tradeoffwill differ at the margin, which\nleaves unexploited gains from trade. A situation with unexploited gains from trade is often\ncalled an arbitrage opportunity.\nDefinition 1 Arbitrage. (1) Taking advantage of a price difference between two or more mar-\nkets. (2) Striking a combination of matching deals that capitalize upon the imbalance between\nprices.\nThe law of one price implies that arbitrage opportunities should not exist in equilibrium.\nYou may ask: who enforces this \"law\"?\nLet's say that you observe that rice sells at one price in Northern China and another price\nin Southern China. Is there any limit on how much we might expect these prices to differ? Yes.\nIf rice can be transported between North and South--and if buyers and sellers are aware of\nthis price difference--then the price difference between markets should not be greater than the\ntransport cost. If the price difference were greater than the transport cost, a trader would find\nit profitable to transport rice between North and South to arbitrage the price difference. This\nwould lower the price in the more expensive market (by increasing supply) and raising it in the\nless expensive market (by reducing supply). This trade would be expected to continue until\nprices in these markets differ by no more than the transport cost. At this point, there would be\n\nno further arbitrage opportunities. In short, arbitrage enforces the law of one price. You may\nhear of similar scenarios in finance, where professionals are constantly looking for opportunities\nto \"buy low\" in one market and \"sell high\" in another.\nJensen tests the Law of One Price in Table VII of the \"Digital Provide\".Does the law of one\nprice hold across fish markets in Kerala? The answer appears to be that before the introduction\nof cell phones, it did not. After the introduction of cell phones, the law of one price appears to\nhold almost all of the time. This example highlights that for arbitrage to function effectively,\ntwo preconditions are needed: (1) There is a cost-effective means to transport fish between local\nmarkets in Kerala; (2) There is a mechanism (cell phones) that allows sellers to learn about\nthe price differentials across markets. Accurate and inexpensive information is crucial to the\nefficient operation of markets.\nTo test your understanding a bit: assume now that fishermen and consumers are not the\nsame people. In particular, fisherman C and fisherman D face the demand curves above from\nA and B. On alternating days, C catches 20 fish and D catches 40 fish (and vice versa). C\nand D can choose to pool their catches and sell 30 fish each to A and B each day. Or, they\ncan keep their catches separate and sell 20 and 40 fish to consumers A and B, respectively, on\nalternating days. (For simplicity, assume that C sells to A exclusively and that D sells to B\nexclusively.) Which approach is profit maximizing for C and D? Which consumer surplus for A\nand B? Which maximizes social welfare (producer plus consumer surplus)? Let's say that each\nfisherman recognized that he was 'large' relative to the market (since each seller faces exactly\none buyer) and could effect the market price by restricting the quantity of fish available. How\nwould the market equilibrium look different in this case?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 12 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/f7ab6f0d4401677d17e4de87f8d11234_MIT14_03F16_lec12.pdf",
      "content": "Lecture Note 12 - International Trade and the Principle\nof Comparative Advantage\nDavid Autor, MIT and NBER\n\nInternational Trade and the Principle of Comparative\nAdvantage\nWe now want to add international trade to our study of general equilibrium, Pareto efficiency,\nand social welfare. Our objective is to answer the following questions:\n1. Are the gains from international trade necessarily positive in aggregate? Or does the\nanswer depend upon which country we are trading with?\n2. What are the underlying economic factors that give rise to gains from trade?\n3. Why is it only differences in the price ratio across countries that matter for trade,\nrather than differences in the absolute level of prices?\n4. If the gains from (international) trade are necessarily positive in aggregate, why is\ntrade so often strongly opposed?\nIn the notes below, we use word trade somewhat differently than in our previous discussion\nof the Edgeworth box. Here, we will distinguish between trade meaning international trade,\nand autarky, meaning trade only among citizens of a given country. In both cases, citizens\nengage in trade, but under autarky, this trade does not cross borders.\n1.1\nTrade in the General Equilibrium Diagram\n- As discussed in Lecture Note 10, we can think of the General Equilibrium problem as\na utility maximization subject to three constraints:\n1. No actor is worse offin the market equilibrium than in the initial allocation. This\nis satisfied because a person could always refuse to trade and consume her original\nendowment instead.\n2. In equilibrium, no party can be made better offwithout making another party\nworse off(otherwise there are un-exhausted gains from trade).\n3. No more goods can be demanded/consumed than the economy is endowed with.\nThat is, sum of the consumption of both parties cannot exceed the total endow-\nment.\n- Now, we want to analyze how opening to international trade affects utility in the\npreviously closed economy.\n\n- A critical thing to notice here is that opening to International trade relaxes the 3rd\nconstraint. Countries that are trading can potentially swap part (or all) of their en-\ndowments with their trading partners.\nIn an equilibrium with international trade,\nresidents of a country may consume more of certain goods than it's original endow-\nment (e.g., it could trade some food for shelter and hence consume more shelter than\nit could possibly produce). That doesn't mean it can buy anything it wants; it has to\nbe able to afford the goods it desires by trading the goods it has. But the budget set\nof residents in this country can now extend beyond the borders of the country-level\nEdgeworth box (but remember that nobody can consume less than zero of any good).\n- To illustrate this point, let's draw the Production Possibilities Frontier (PPF) for an\nentire country. I'll spend a number of subsequent bullet points walking you through\nthis figure.\n- The initial consumption possibilities for the country called Home under autarky (no\ntrade) is depicted by the Production Possibility Frontier (PPF) for Food and Shelter\n(F and S).\n\n- The PPF represents the set of bundles that the country Home could create using its\ninitial endowment. The concavity of this PPF stems from an underlying assumption\nthat as Home devotes more and more of its resources to either food or shelter, it ex-\nperiences diminishing marginal returns to the expanding sector. For example, if Home\ndoubles the resources used to produce food, it gets less than double the output. Why\nwould this be true? It's likely that the suitability of land for farming in Home varies\nacross locations--some areas offer flat fertile fields, others rocky hilltops. Similarly,\nit's likely that some heavily wooded areas are suitable for shelter production whereas\nothers offer mostly tall grasses.1 Efficient resource utilization implies that Home will\ndevote the best farming land to farming and the best shelter land to construction of\nshelter. If Home were to produce exclusively food, it would have to place low quality\ngrowing land into production, leading to diminishing marginal returns. Conversely, if\nit devoted all land to shelter production, shelter output per acre of land would also\nfall. [Even if all land in Home were identical, it is still likely that Home would have\na concave PPF for another reason: variation in the suitability of labor (i.e., skills) for\nfarming versus shelter construction. Specifically, workers trained as carpenters don't\nnecessarily make productive farmers and vice versa.]\n- We call UA the \"community indifference curve\", which represents the preferences of a\ncountry. There are whole sub-fields of economics studying the extent to which we can\nmodel a country's \"preferences\" like we model an individual person's preferences, and\nyou'll learn all about the exciting technical details if you enroll in an Economics PhD\nprogram. In this lecture, we want to show how trade can open up new opportunities\nfor large groups of people, so we won't sweat the technical definition of what it means\nfor a country to have preferences: just think of this as the preferences of a country's\nresidents in a broad sense.\n- Assume for simplicity that\n\nPS\n= 1\nF\n. Hence, the slope of the PPF\nP\nat the point of\nA\ntangency with UA is equal to 1\n\n. This won't affect our main results and will simplify\nnotation.\n- In the world before trade, production/consumption of F and S are given by FA and\nSA.\n- Now imagine this country Home opens to world trade.For simplicity, take the case\nwhere Home is small relative to the rest of the world: Home's consumption has no\n1Houses made out of sod (tall grasses) were commonplace in the American prairie in the 19th century\nand earlier. When railroads began to provide a relatively inexpensive supply of lumber to the prairie, sod\nhouses were quickly displaced by wood frame houses.\n\neffect on World prices (i.e. it is a price taker). This means that the World price ratio\n\nPS\nPF\n\nis constant from Home's perspective: no matter how much F, S it buys/sells\nW\non world markets, the world price will be the same.\n- How will Home's production, consumption, and utility be affected by the option to\nengage in international trade?\n- Provided that\n\nPS\nPF\n\nA =\n\nPS\nPF\n\nW , the movement from autarky to free trade effectively\nexpands the domain of Home's budget set. Aggregate utility must rise.To see this,\ndraw a ray with slope\n\nPS\nP\nPF\ntangent to the\nPF . Denote the points SP, FP as the\nW\nquantities of S, F that corresp\n\nond to this tangency point. The subscript P refers to\nProduction. These points are the quantities of F, S produced.\n- This ray is the new budget set for Home, IH.\nWhy?\nBecause as far as Home is\nconcerned, the world endowment of SP, FP available to them is any bundle satisfying:\nIH = SPP w\nS + FPP w\nF ,\nAll combinations of P, S that lie on this set are now feasible.\n- Except for the single point of tangency, the new budget set lies strictly above the\noriginal PPF at every point. Home will necessarily achieve a higher level of aggregate\nutility, represented in the figure by UT. Home can produce one bundle, represented by\nSP, FP and consume any other bundle on the new budget set. In this case, this new\nbundle is given by SC, FC where the subscript C denotes consumption.\n- Notice that for each good, the quantity produced differs from the quantity consumed.\nHence, there will be imports and exports. In particular\nExports\n=\nSP -SC,\nImports\n=\nFC -FP.\n- Will there be a trade imbalance? Bundles (SC, FC) and (SP, FP) lie on the same budget\nline, so they must cost the same:\nSPP w\nS + FPP w\nF\n=\nSCP w\nS + FCP w\nF ,\nP w\nS (SC -SP) + P w\nF (FC -FP)\n=\n0.\nThere is no trade imbalance.\n\n- This is an important observation because many policy discussions confuse the question\nof trade balance with trade itself. Trade itself is beneficial in aggregate--and of course\nthere is no aggregate trade imbalance summing over all countries (every import is\nsomeone else's export). For a given country, a trade imbalance may be harmful or\nbeneficial--but this is a distinct and separable question.\n- So to summarize:\n- Home still produces on the original PPF.\n- But Home consumes above its original PPF.\n- This gap between production and consumption indicates that Home gained from\ntrade.\n- Note also that it is not an accident which good Home is importing and which good it\nis exporting. Because\nPS\nPF\n\nW\n>\nPS\n,\nPF\n\nA\nHome holds a comparative advantage in producing shelter. It can produce S relative\nto F at comparatively low cost relative to the rest of the world.\n- Accordingly, as Home opens to trade, it increases its production of S and decreases its\nproduction of F.\n- Notably, after trade opening, Home's total consumption of S has fallen and its total\nconsumption of F has risen. Why? Because, when choosing consumption, Home faces\nthe world price of these goods. Why not its original autarky price\n\nPS\nPF\n? Because\nA\nHome can now sell S, F at the world prices, the opportunity cost of consuming\n\nthem at\nHome is the price they could have fetched on the world market. The rise in consumption\nof F follows from its lower price on the world market. (Note that it is also possible for\nconsumption of S to rise somewhat due to the income effect, if S is a normal good and\nthe gains from trade are sufficiently large.)\n- This last observation (i.e., the decline in consumption of S) explains why, for example,\nColombians usually drink pretty bad coffee, despite the fact that Colombia is one of\nthe world's leading coffee growers. Because consumers worldwide are willing to pay a\nrelatively steep price for Colombian coffee, its opportunity cost of consumption--even\nin Colombia--is high in terms of foregone earnings.\n\nWhere do the gains from trade come from?\n- The first thing to notice is that if\n\nPF\nPS\n\nA =\n\nPF\nPS\n\n, there will be no gains from trade.\nW\n- This is a crucial observation: Gains from trade come entirely from differences between\ncountries. If there were truly \"a level playing field\" among trading partners--as many\npoliticians demand as a condition for trade--then there would be no point in trading.\nThe gains from trade come precisely from the fact that relative prices differ between\nHome and World. Hence, both countries will want to (and be able to) consume bundles\nthat would not be feasible under their initial endowments (e.g., consuming more coffee\nthan was previously feasible while giving up some sushi).\n- This observation immediately raises two further questions:\n1. Why do relative prices differ among countries?\n2. Why is it relative not absolute prices that matter?\n- Let's take these in turn.\n2.1\nWhy do relative prices differ among countries?\n- Based on our analysis of General Equilibrium price setting, there are three underlying\nfactors that affect prices: tastes, technologies, and endowments:\n1. Tastes: Two otherwise identical countries might have different prices for the same\ngoods if for example (facing the same prices) consumer's in Country A prefer\nsushi to coffee and consumer's in Country B prefer coffee to sushi. There would\nbe gains from trade because A would export coffee and import sushi and vice\nversa for B.\n2. Technology: If countries A, B have different technologies but are otherwise identi-\ncal, they will have different relative prices. So, if country A has better sushi chefs\nand country B has better baristas, then A will export sushi and B will export\ncoffee, even if tastes are identical.\n3. Endowments: If countries A, B have different endowments but are otherwise iden-\ntical, there will also be gains from trade. For example, if consumers in A, B have\nthe same taste for coffee and sushi but A has a hot climate suitable for coffee grow-\ning and B has abundant coastal waters for fishing, then A will be an exporter of\ncoffee and B an exporter of sushi.\n\n- As these examples show, any or all of these factors--tastes, technology, endowments--may\ngive one country a comparative advantage in selling sushi relative to coffee or vice versa.\nThese differences make trade beneficial. In general, the larger the differences, the more\ntrade permits countries to consume bundles that are desired but otherwise infeasible\nunder their initial endowments.\n2.2\nWhy do only relative prices matter for trade?\nComparative\nversus absolute advantage\n- We have noted that it's only the relative price of F versus S in Home versus World\nthat determines what the gains are from trade. But doesn't the absolute level of prices\nmatter? Put more concretely, it's easy to see that the U.S. would benefit from trade\nwith China since China makes just about everything cheaper than the U.S. does. It has\nan absolute advantage in that all goods are cheaper to produce in China.But doesn't\nthat mean that China will not benefit from trade with the U.S. since everything the\nU.S. makes is too expensive for China (i.e., the U.S. has an absolute disadvantage in all\ngoods production)? Is free trade with China good for the U.S. but bad for the Chinese\n(or v.v.)?\n- This is a profoundly important question to which the answer is no. As long as relative\nprices differ between China and the U.S., both countries experience gains from trade.\n- The explanation is the principle of Comparative Advantage, which is one of the most\nfundamental--and least widely understood--ideas in economics.\n- We said that for an equilibrium to be Pareto efficient, the Marginal Rate of Substitution\namong goods for all consumers must be equated (How? By the price ratio.). Otherwise,\nthere are gains from trade. This same idea extends naturally to trade among countries.\nIf two countries in autarky (no trade) have different marginal rates of substitution\namong goods (due to tastes, technologies, or endowments), then trade between these\ncountries will potentially make both countries better off(i.e., by equating their MRS's\nand thereby realizing gains from trade).\n- Comparative Advantage is closely analogous to the trade that goes on in the Edgeworth\nbox. It is immediately apparent in the Edgeworth box that, relative to the initial\nendowment, no party can be harmed by trade and generally both parties benefit--\nthat is, no one expects the consumer with the smaller endowment to be \"exploited\" by\n\ntrade with the consumer with the larger endowment. This is also true for trade among\ncountries.\n- Note that the principle of comparative advantage follows directly from the notion of\nopportunity costs.In Home under Autarky, the opportunity cost of making one more\nunit of shelter at the margin is\n\nPS\nPF\n, which is the amount of food the economy is\nA\nforegoing at the margin to produce shelter\n\ninstead. Notice that we can use the price\nratio to express this value because the price ratio is equal to the slope of the PPF at\nthe equilibrium production mix.\n- Similarly, in World (excluding Home), the opportunity cost of making one more unit of\nshelter at the margin is simply\n\nPS\n,\nPF\n\nthe amount of food one must forego to obtain\nW\nshelter instead.\n- So, if it is the case that\nPS\nPF\n\nW\n>\nPS\n,\nPF\n\nA\nthen the opportunity of shelter relative to food is relatively higher in the rest of the\nWorld relative to home.\n- If so, Home should specialize further in shelter and buy more of its food from World,\nwhich is exactly what is shown in Figure 1: Home reallocates production from F to S\nuntil its opportunity cost of F relative to S is identical to that in the rest of the World.\n- The key point is that trade allows Home to specialize in production of the good in\nwhich it is has comparative advantage relative to the rest of the world. If Home has a\nlower internal cost of producing shelter relative to the rest of the world, then consumer\nutility will rise in Home if it produces more shelter and less food and then trades shelter\nfor food on world markets. The converse is also true for the rest of the world.\n- This conclusion in no way depends on whether both F and S prices are in absolute\nterms higher or lower in the World than they are at Home. All that matters is that\nHome's cost of producing shelter relative to its cost of producing food is less than\nWorld's cost of producing shelter relative to World's cost of producing food.\n2.3\nA Concrete Example\n- When I (Prof Autor) was a graduate student, I coauthored a research paper with my\nthesis advisor, Lawrence Katz. The paper involved both theory and empirical work.\nI did most of the empirical work and my thesis advisor did most of the theoretical\n\nwork. I initially thought that this division of labor was due to the fact that my advisor\nrecognized that I (a 2nd year graduate student) was already a world-class empirical\nresearcher. But I eventually realized that this was not quite what Katz had in mind.\nNot long into the project, I made the rude discovery that Katz was much faster than\nI at empirical work--and also far better at theoretical work.\nHe had an absolute\nadvantage in both activities.\n- So the question: Why did Katz bother to coauthor with me if he could do the entire\npaper faster or better by himself? The answer is comparative advantage. Katz, as it\nturned out, was about twenty-five times as good at empirical work but several hundred\ntimes as good at theoretical work (perhaps even infinite, since I knew squat about\ntheory at the time). By arranging for me to do the empirical work, Katz freed his time\nto do the theoretical work, where his comparative advantage lay.\n- Let's make this example explicit. Say that writing a research paper has two components\nE and T (Empirical and Theoretical) and the only input into both activities is labor.\n- The value of a completed paper is $10, 000 for a solo authored paper. If we coauthor\nthe paper, it's worth $5, 000 to each of us.\n- My advisor, Katz, can do E in 75 hours and T in 25 hours. Were he writing the paper\nhimself, it would take him 100 hours.\n- His internal rate of conversion of time into output is the following:\nPE\nPT\n\nK\n= 75 = 3.\nOne way to look at this \"price ratio\" is that the opportunity cost of one hour is 1/75th\nof the empirical part of a paper or 1/25th of the theory part of the paper.\n- Let's say that I (as a graduate student) could do E in 2, 000 hours and T in 8, 000\nhours. So, it would take me 10, 000 hours to write the paper.\nPE\nPT\n\nA\n= 2, 000 = 0.25.\n8, 000\n- These price ratios, expressed as opportunity costs of each of our time, indicate that\nour internal trade-offs differ. In particular\nPE\nPT\n\nK\n>\nPE\n,\nPT\n\nA\n\nKatz's opportunity cost of doing Empirical work is implicitly higher than Autor's\nopportunity cost of doing empirical work. So, there should be gains from trade.\n- Note, however that P K < P A\nK\nE\nE and PT < P A\nT . That is, Katz has a lower time cost (an\nabsolute advantage) in doing either activity.\n- Consider the following production possibilities\nTime E\nTime T\nTime Katz\nTime Autor\n$/hr Katz\n$/hr Autor\nKatz\n$100\nAutor\n2, 000\n8, 000\n10, 000\n$1.00\nKatz: E\n8, 000\n8, 000\n$66.67\n$0.63\nAutor: T\nKatz: T\n2, 000\n2, 000\n$200\n$2.50\nAutor: E\nConsider Katz's choices:\n1. If Katz does the paper himself, he spends 100 hours. Hence, his effective wage is $100\nper hour for the solo-authored paper.\n2. If Katz does E and Autor does T, Katz spends 75 hours. Katz earns $66.67 per hour\nfor the joint-authored paper. He is better offto solo-author the paper.\n3. If Katz does T and Autor does E, Katz spends 25 hours. His effective wage is $200\nper hour for the joint paper.\nConsider Autor's choice:\n1. If Autor does the paper solo (not likely!), he spends 10, 000 hours and earns $1 per\nhour, consistent with the terms of his graduate stipend.\n2. If Autor does T and Katz does E, Autor spends 8, 000 hours, and his effective wage\nis $0.63 per hour for the joint-authored paper.\nNotice that even though Autor is\nabsolutely worse at both activities than Katz, Autor is worse offstill coauthoring with\nKatz than writing the paper solo. [Intuition might suggest that Autor would be better\noffto coauthor with Katz regardless of the allocation of tasks, simply because Katz\nhas an absolute advantage in writing papers. Clearly, this is not so when Autor and\nKatz must split the benefits from writing the paper.]\n\n3. If Autor does E and Katz does T, Autor spends 2, 000 hours, and his effective wage is\n$2.50 per hour for the joint-authored paper (which is pretty much offthe charts for a\ngraduate student).\n- So, although Katz has an absolute advantage in both activities, both Katz and Autor\ngain from joining forces to have Autor do E and Katz do T. This is because Katz's\ncomparative advantage is in T and Autor's comparative advantage is in E. Conversely,\nif each does the task in which they comparative disadvantage (Katz does E, Autor\ndoes T), they are both worse offthan not collaborating (at least if they must split\nthe proceeds of the paper). This is true despite the fact that Katz has an absolute\nadvantage at both activities.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 13 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/0f7ffdf98f7dc053c20b02dbda223d14_MIT14_03F16_lec13.pdf",
      "content": "Lecture Note 13 - The Gains from International Trade:\nEmpirical Evidence Using the Method of Instrumental\nVariables\nDavid Autor, MIT and NBER\n14.03/14.003 Microeconomic Theory and Public Policy, Fall 2016\n\nIntroduction: Measuring the Causal Effect of Trade on\nGDP (James Feyrer, 2009)\nUsing data from the Penn World Tables, Figure 5 of James Feyrer's 2009 paper, \"Trade and\nIncome--Exploiting Time Series in Geography\" shows that countries that experienced rising\ntrade volumes between 1960 and 1995 also experienced rising GDP. Is this relationship causal,\nor does it simply stem from rich countries trading more? As 14.03/003 students understand,\neconomic theory clearly predicts that trade increases national income, since it expands the\nset of goods and services a country can consume. (Note that \"income\" in this discussion\nrefers to real income - the purchasing power of residents in a country - rather than nominal\nincome in terms of local currency.) But this theoretical prediction is difficult to test because\nit's hard to conduct a credible experiment. We cannot readily manipulate the trade flows of\nvarious countries to study the impact this has on their national incomes.\nFigure 5: Average Per Capita GDP Growth versus Trade Growth 1960-1995\nARG\nAUS\nBEN\nBGD\nBRA\nBRB\nCAN\nCHL\nCHN\nCIV\nCMR\nCOL\nCRI\nCYP\nDNK\nDOM\nECU\nEGY\nESP\nFIN\nFJI\nFRA\nGBR\nGHA\nGIN\nGMB\nGNB\nGNQ\nGRC\nGTM\nGUY\nHND\nIDN\nIND\nIRL\nISL\nISR\nITA\nJAM\nJOR\nJPN\nKEN\nKOR\nLKA\nMAR\nMDG\nMEX\nMOZ\nMRT\nMUS\nMYS\nNAM\nNIC\nNLD\nNOR\nNZL\nPAK\nPAN\nPER\nPHL\nPNG\nPRT\nROM\nSEN\nSGP\nSLV\nSWE\nSYC\nSYR\nTGO\nTHA\nTUR\nTZA\nURY\nUSA\nZAF\n-4\n-2\nAverage per capita GDP growth 1960-1995\nAverage trade growth 1960-1995\nsource: Penn World Tables 6.2, IMF Direction of Trade database.\nLet's formalize this point. Applying our familiar causal framework, we would like to\nmeasure the causal effect of trade on country j as follows:\nγj = Y T\nj -Y A\nj ,\nwhere γj is the causal effect of trade on Y in country j ( γ stands for \"gain from trade\")\nwhile Y T and Y A signify counterfactual national income according to some income measure\n(e.g., income per capita) under Autarky and Trade, respectively. Note that the T and A\nsuperscripts here denote counterfactuals, so they serve the role of the 0 and 1 subscripts\nCourtesy of James Feyrer. Used with permission.\n\nwhich we used in the first few lectures of class. The Fundamental Problem of Causal Inference\nsays that we can never directly observe γj: we cannot observe income per capita for country\nj under both Autarky and free trade simultaneously.\nTo uncover the true γj, one standard solution would be to contrast incomes of trading\nand non-trading countries. We could form\nγˆ = E\n\nY T|T = 1\n\n-E\nwhere T\n0, 1\ndenotes whether or not a country\n\nY A|T = 0\n\n,\n∈{\n}\nis open to free trade and hats denote\nthat we are using our data to estimate expectations (taking sample means).\nAs you all learned when you studied for the first midterm, γˆ is an unbiased estimate of\nγ only if the following holds:\nE\n\nY T|T = 1\n\n=\nE\n\nY T|\nE\n\nT = 0 ,\nY A|T = 1\n\n=\nE Y A|T = 0\n\n.\nThat is, the autarkic economies would have the same income\n\nper capita as the trading\ncountries if they opened to trade, and vice-versa for the trading countries if they became\nautarkic. (As we discussed earlier in the semester, a good shorthand term for this assumption\nis exchangeability: if the experimenter had exchanged the treatment and control groups prior\nto performing the experiment, she would have have obtained the same causal effect estimate.)\nAre these assumptions plausible? Would countries that trade a lot be similar to countries\nthat trade very little, absent these differences in trading? Probably not. The extent to which\na country trades is an endogenous outcome that is very likely correlated with other factors\nthat directly affect income per capita. A few possible factors:\n1. Countries that are rich for other reasons might trade more because they can afford to\nimport more goods from overseas.\n2. Countries that pursue sound economic policies (that raise income) may also choose to\npursue trade (another sound economic policy).\n3. Countries that are rich in natural resources may trade because there is high world\ndemand for their goods, but these countries might have been rich due to their copious\nendowments even in the absence of any trade.\nOne should therefore be very skeptical of any \"causal inference\" that naively compares the\nincomes of trading and non-trading countries. In point of fact, countries that trade more are\non average wealthier, but this correlation need not be causal.\n\nUsing the method of Instrumental Variables (IV) to\nmeasure causal effects\n2.1\nLooking for experiments in strange places\nWhat we need is an \"experiment\" that exogenously raises or lowers trade in some group of\ncountries. In past class examples, we've used both \"natural\" or \"quasi-\" experiments (e.g.\nthe NJ minimum wage change, the rollout of cell phones in Kerala, India) and random-\nized experiments (e.g. the Jensen-Miller rice subsidy) to isolate exogenous variation in the\ntreatment variable of interest.\nIn the case of free trade, such experiments are difficult to find. Even policy changes that\nopen or close a country to trade (for example, war, natural disaster, revolutionary overthrow)\nare potentially suspect: they are quite likely to induce other economic and policy shocks\nin addition to trade shocks that also directly raise or lower real income. This means that\neven a difference-in-differences design - the \"gold standard\" from our first few lectures - fails\nto meet the \"parallel trends\" assumption that we discussed, and therefore fails to give us a\nreliable estimate of γj. (Refresher: Recall that a DD identifies the effect of a policy under the\nassumption that the treatment and control groups' outcomes would have evolved in parallel\nabsent the policy change. If a war closes offtrade but also destroys the national economy\nof country j, then we suspect that country j would have evolved very differently from it's\nneighbors even absent the closure of trade).\nWe need a new - and even cooler - technique to uncover causal effects in this setting.\nThis subtle and powerful approach to identify causal effects is the method of Instrumental\nVariables (IV). IV is frequently referred to by the name of the statistical procedure conven-\ntionally used to implement it, Two Stage Least Squares (2SLS), and in this class we will use\nthese two terms synonymously.\nHere's the idea: we are interested in measuring the effect of trade on income. Since trade\nis endogenous, we are reluctant to draw any causal inferences from the observed correlation\nbetween trade and income. And we haven't yet found a difference-in-differences design that\npasses the smell test for parallel trends.\n- Assume now that there is some third, exogenously assigned variable, Z ∈{0, 1} that\naffects the extent to which countries trade.\n- Assume further that we have reason to believe that Z has no effect on national income,\nexcept potentially through its effect on trade.\n- Under these assumptions, Z may serve as an \"instrument\" that exogenously manipu-\n\nlates trade, allowing us to study trade's effect on income. Economists would say that\nZ is a valid instrumental variable for analyzing the causal effect of trade on income.\n2.2\nThe Feyrer strategy\nJames Feyrer's 2009 paper, \"Trade and Income: Exploiting Time Series in Geography,\"\nproposes an ingenious IV approach for analyzing the causal effect of trade on national per\ncapita income. His insight is that, historically, most trade between non-contiguous countries\noccurred by sea. As the cost of air freight fell over the last four decades, a substantially\nlarger share of trade was transported by airplane rather than ship.\nThe impact of this\ncost reduction was not uniform across different pairs of trading partners. For country pairs\nconnected by a direct sea route (e.g., Spain and Brazil), the declining cost of air freight is\nnot particularly important: it reduces transport time but not necessarily transport cost. For\ncountry pairs that are connected by a highly indirect sea route however (e.g., Japan and\nthe Western Europe), the reduction in the cost of air freight means that traded goods will\npotentially have to travel a much shorter distance by air than sea. This makes trade much\ncheaper for these country pairs.\nThis insight underlies Feyrer's empirical approach: As air freight gets cheaper, countries\nthat have a high value of their \"Air-Sea Distance Difference\" (ASDD)--that is, the air\ndistance to their trading partners relative to their sea distance to their trading partners--will\nexperience a large increase in trade volumes. By contrast, trade flows among countries that\nhave small or zero ASDDs will not be greatly affected.\nHere's how ASDD is defined. Let DS\njk be the sea distance between countries j and k\nand DA\njk be the air distance. Let ASDD\nS\nA\njk = Djk -Djk. If country j and k have nothing\nbetween them but water, then their sea and air distances will be the same, meaning that\nASDDjk = 0. If they are separated by land masses that a cargo ship must circumnavigate,\nthen ASDDjk > 0.\nNow, define the average ASDD for each country j as the trade-volume weighted ASDDjk\nfor all of its trading partners k. Specifically,\nD\nASDDj =\nP\nk\nS\njk -DA\njk\n\n× Tjk\nP\n,\nTjk\nk\nwhere Tjk is the trade volume between j and k (in dollars, for example) in 1960. Note that\nTjk\nP Tjk captures the historical importance of country k relative to other countries in country\nk\nj's historical trading patterns. So ASDDj measures the overall change in trading costs for\n\ncountry j thanks to the advent of the airplane, assuming country j followed it's historical\ntrading patterns.\nIf Feyrer's hypothesis is correct, then trade flows will rise differentially between countries\nwith relatively high ASDDjk as air freight gets cheaper. Moreover, if ASDDjk exclusively\naffects a country's economy via its effect on trade, then cross-country variation in ASDDj\nprovides a kind of natural experiment for studying the causal effect of trade on income: as\nthe cost of air freight falls, countries with high ASDDj should begin to trade more than\ncountries with low ASDDj, which will in turn allow us to study the effect of trade on national\nincomes.\nYou may object: ASDD is not the only determinant of changing trading patterns. For\nexample, the U.S. began trading extensively with China in the 1990s but was trading ex-\ntensively with Japan decades earlier. Clearly, the ASDD gap between the US-China and\nUS-Japan ASDD is trivial, so the falling cost of air freight cannot be the cause of rising\nChina trade. That's correct! But that's not a problem for the IV approach. ASDD need\nnot be the only determinant of trade. What we need is:\n1. ASDD has a measurable, direct causal effect on trade. This is called the first stage.\nThis is directly testable.\n2. ASDD does not plausibly affect national income through any other channel but trade.\nRestated, trade is the exclusive channel by which ASDD affects national incomes (if\nat all). This is called the exclusion restriction. The exclusion restriction is not directly\ntestable. Thus it deserves extra scrutiny whenever we are designing or evaluating an\nIV strategy.\n2.3\nSetting the stage for IV\nFigure 1 of Feyrer (2009) shows that air freight came to encompass a substantial share\nof U.S. trade between 1965 and 2005, while Figure 3 documents that countries' trading\nvolumes became substantially more sensitive to air distance between 1960 and 1995 and,\nsimultaneously, substantially less sensitive to sea distance.\n\nFigure 1: Air Freight Share of US Trade Value (excluding North America)\nAir Freight Share of Trade Value\nyear\nImports\nExports\nFigure 3: The Change in Elasticity of Trade with Respect to Sea and Air Distance\nover Time\n-1.0\n-0.5\n0.0\n-1.5\n0.5\nSea\nAir\nHow can we use this information about the changing relationship between ASDD and\ntrade volumes to find the causal effect of trade on income? That's where the subtlety comes\nin. The validity of our approach will rest on three pillars, which we will discuss in turn:\n1. Balance of treatment and control groups: Observations with different values for the\ninstrumental variable have similar counterfactual outcomes..\n2. First stage relationship: There is a causal effect of the instrumental variable on the\nendogenous variable\nCourtesy of James Feyrer. Used with permission.\nCourtesy of James Feyrer. Used with permission.\n\n3. Exclusion restriction: It is plausible that the instrumental variable affects the outcome\nvariable only through its effect on the endogenous variable\nNow, imagine that we have a set of potentially comparable countries that differ according\nto whether they have High ASSD (A = 1) or Low ASDD (A = 0). (Note that A take\nthe place of Z on pages 4-5.) In our example: a) the endogenous variable of interest is a\ncountry's trading volume; b) the instrumental variable is the country's ASDD; and c) the\noutcome variable is the country's GDP.\n2.3.1\nCondition 1: Balance of treatment and control groups\nAs with our previous techniques for causal inference, our treatment and control groups be\ncomparable--that is, they must have have balanced counterfactual outcomes.\n- Let Yjt equal the GDP of country j in time t.\n- Imagine that there are two time periods, t = {0, 1}, and that in the early period\n(t = 0), traded goods travel exclusively by sea, whereas in the latter (t = 1), traded\ngoods can travel by air or by sea.\n- Let ∆Yj equal the change in GDP in country j between t = 0 and t = 1. Note that\nthis paper focuses on how changes in trade affect changes in income, rather than how\nlevels of trade affect levels of income. Theoretically, both designs could uncover the\neffect of trade on income.\n- For each country, imagine two potential outcomes\n∆Yj ∈\n∆Y 1\nj , ∆Y 0\nj\n,\nwhere ∆Y 1\nj is the change in GDP in j if\n\nA = 1 and\n\n∆Y 0\nj is the change in GDP in j if\nA = 0.\n- Of course, each country j is either one type or the other (ASDD is either High or Low,\nA = 1 or A = 0). So, we will never observe both ∆Y 1 and ∆Y 0\nj\nj (i.e., the fundamental\nproblem of causal inference, FPCI). Thus ∆Y 1 and ∆Y 0\nj\nj are counterfactuals of one\nanother.\n- Assuming balance of the treatment and control groups means that we believe in ex-\n\nchangeability:\nE\n\n∆Y 1\nj |A = 1\n\n=\nE\n\n∆Y 1\nj |\n\nA = 0\nE ∆Y 0\nj |A = 1\n=\nE ∆Y 0\nj |A = 0\n\n.\nIf the countries with high ASDD were somehow assigned low ASDD, their GDP\ngrowth would be the same as the the countries that actually have low ASDD, and vice\nversa if the low ASDD countries were somehow assigned to have high ASDD. We\ncan't completely prove exchangeability by looking at data, but by comparing observable\ncharacteristics of countries with A = 0 and countries with A = 1 we can make a\nplausible case that exchangeability is reasonable.\n2.3.2\nCondition 2: There is a causal effect of the instrumental variable on the\nendogenous variable\nFor our proposed Instrumental Variables approach to be valid, it must be the case that\nASDD has a causal effect on the amount that countries trade. This is called the \"first stage\"\nrelationship by econometricians. The existence of a first stage relationship is verifiable as a\nstatistical matter. (Though as always, correlation does not imply causality. More on this\nbelow.)\n- Write Tjt as the trade volume (in dollar terms, for example) of country j in year t.\n- Again, imagine two counterfactual states for each country j, one in which it has Low\nASDD (A = 0) and the other if it has High ASDD (A = 1).\n- We know that between 1965 and 1995, air transport got considerably less expensive\noverall and simultaneously the air volume of U.S. trade increased considerably (Figure\n1).\n- Define the counterfactual change in trade volume between 1965 and 2005 in each coun-\ntry under ASDD ∈{0, 1} as\n∆Tj ∈\n\n∆T 1\nj , ∆T 0\nj\n\n- We require the following:\n∆T 1\nj ≥∆T 0\nj ∀j,\nIn words, country j′s trade volume must increase by more between time 0 and 1 if\nASDD is High than if ASDD is low.\n\n- Due to FPCI, this assumption is also not testable.\nWe only see countries in one\nstate--ASDD is High or Low--or another.\n- However, we can test one necessary but not sufficient condition for the validity of this\nrelationship, which is:\nE [∆Tj|A = 1] > E [∆Tj|A = 0] .\nThat is, the average growth in trade in the A = 1 countries must be greater than in\nthe A = 0 countries.\n- We can check this empirically by verifying that:\n∆\nnA=1\n×\nj\nX\nTj >\n,A=1\n,\nn\n×\nj\nA=0\nj\nX\n∆T\n,A=0\nwhere nA=1 is the number of countries with A = 1 and similarly for nA=0\n- Figure 6 of Feyrer suggests that this relationship holds in the data.\n2.3.3\nCondition 3: Exclusion restriction\n- A valid instrumental variable must also satisfy an \"Exclusion Restriction.\" The exclu-\nsion restriction says that the instrumental variable (here ASDD) must only affect the\noutcome variable of interest (here GDP) indirectly through its effect on the interme-\ndiating endogenous variable of interest (here, Trade).\n- If we do not find it plausible that ASDD only affects national income through its\nimpact on trade, we cannot rely on any measured relationship between distance and\nincome to help us uncover the causal effect of trade on income.\n- Conversely, if we find it plausible that ASDD only affects national income through\nits impact on trade, we can interpret the measured relationship between distance and\nincome as reflecting (though not identical to) the causal effect of trade on income.\n- The exclusion restriction can be expressed formally as follows:\nE [∆Yj|∆Tj = k, A = 1] = E [∆Yj|∆Tj = k, A = 0] ,\nwhere k is some constant.\n- This equation says that if were were to hold trade in country j constant at a given level\nk, ASDD would have no effect on GDP--since its entire effect operates through influ-\n\nencing trade. Holding country j′s trade constant at level k, GDP of j is independent\nof ASDD.\n- The exclusion restriction must be plausible or the IV strategy is a non-starter. How-\never, this postulate is not testable. We cannot directly manipulate ASDD for a given\ncountry.\nMoreover, if we could, this manipulation would also affect Tj (under our\nhypothesis above). Thus, we cannot verify that ASDD only affects a country's GDP\nthrough its effect on trade.\n- If we believe that ASDD affects GDP through some other mechanism (e.g., ASDD\nincreases a country's air traffic, and the smell of burning jet fuel makes citizens happier\nand more productive, raising GDP), then using ASDD as an instrumental variable for\ntrade will not allow us to isolate the causal effect of trade on GDP.\n2.3.4\nThe smell test for our conditions\nIf we tentatively accept the conditions above, the empirical analysis proceeds as follows:\n1. We check that trade grows by more in ASDD = 1 than ASDD = 0 countries between\ntimes t = 0 and t = 1:\nˆE [∆Tj|\nˆ\nA = 1] > E [∆Tj|A = 0]\nor, the same expression written differently:\n∆\nnA=1\n×\nj\nX\nTj >\n,A=1\n∆\nnA=0\n×\nj\nX\nTj\n,A=0\nIf this inequality is satisfied, then A is a candidate instrument for T. If this inequality\nis not satisfied, then our assumption that [∆Tj|A = 1] > [∆Tj|A = 0] ∀j is false.\nVerifying the inequality above does not prove that the assumption is true. But rejecting\nit would demonstrate that the assumption is false, and therefore we will not want to\nuse our proposed IV strategy.\n2. If we pass this test, we can next test whether GDP rises by more over time (between\ntime t = 0 and t = 1) in ASDD = 1 versus ASDD = 0 countries. The hypothesis\nthat trade raises income implies that\nE [∆Yj|A = 1] > E [∆Yj|A = 0] .\nIf trade raises GDP, then the fact that trade rises by more in A = 1 than A = 0\ncountries implies that GDP also rises by more in A = 1 than A = 0 countries.\n\nIf both of these relationships are verified in the data, we may be correct to conclude that\ntrade has a positive causal effect on national income. But we would not yet have an estimate\nof the size of this effect. Instead, we would have an estimate of the causal effect of ASDD\non trade, and another estimate of the causal effect of ASDD on income. That's close, but\nnot quite what we're after. We need to take one more step.\n2.4\nEstimating the causal relationship using the method of Instru-\nmental Variables\n2.4.1\nThe parameters we can grab from the data\n- Our goal is to estimate the causal effect of trade volumes on GDP. Let's write this as:\nE [∆Y |∆T] = α + γ∆T,\n(1)\nwhere γ denotes the causal effect of trade on GDP. This is the parameter we'd like to\nestimate.\n- We found that ASDD is correlated with the change between 1960 and 1995 in the\nextent that a country trades, and given our balance assumptions above, we view this\ncorrelation as causal:\nπ1 = E [∆T|A = 1] -E [∆T|A = 0] > 0\n- We compare the change in the incomes of ASDD High and Low countries.\nπ2 = E [∆Y |A = 1] -E [∆Y |A = 0] .\nHere, π2 is the causal effect of ASDD (not trade) on GDP.\n- That's a start, but we have not yet estimated γ, the causal effect of trade on GDP.\nIf we had exogenous (as good as randomly assigned) variation in the change in trade\nthat countries experienced, we could simply estimate equation (1) above, and γˆ would\nbe our causal effect estimate.\n- We cannot do that because the variation in trade that we observe is endogenous.\nNaively regressing ∆GDP on ∆T will tell us about the correlation between trade and\nGDP, but it will not provide an unbiased estimate of γ.\n\n- It turns out that we can infer this causal relationship using the observed causal rela-\ntionships between (1) ASDD and ∆T, and (2) ASDD and ∆Y .\n2.4.2\nUsing those parameters to construct a causal estimate\nPutting the pieces together:\n- Causal effect of ASDD on Trade:\nE [∆T|A = 1]\n=\nα1 + π1\n(2)\nE [∆T|A = 0]\n=\nα1\nE [∆T|A = 1] -E [∆T|A = 0]\n=\nπ1\n- Causal effect of ASDD on GDP growth:\nE [∆Y |A = 1]\n=\nα2 + π2\n(3)\nE [∆Y |A = 0]\n=\nα2\nE [∆Y |A = 1] -E [∆Y |A = 0]\n=\nπ2\n- Substituting (2) and (3) into (1) gives us the expression for the causal effect of ASDD\non GDP growth:\nE [∆Y |A = 1] -E [∆Y |A = 0]\n=\nπ2\n=\nγ (E [∆T|A = 1] -E [∆T|A = 0])\n=\nγ × π1\nBy implication\nπ2 = γ × π1.\n- Thus, our estimate of π2 is closely related to the causal effect of trade on GDP (γ) in\nequation (1) above. They only differ by a scalar: π2 = γ × π1.\n- Combining our two causal effects , π1 and π2, we can estimate the causal effect of trade\non income:\nE [∆Y |A = 1] -E [∆Y |A = 0]\nπ2\n=\nE [∆T|A = 1] -E [∆T|A = 0]\nπ1\n= π1 × γ = γ\nπ1\n- We thus estimate the causal effect of trade on income by taking the ratio of the two\ncausal effects: the causal effect of ASDD on GDP growth (πˆ2) and the causal effect of\n\nASDD on trade growth (πˆ1) . This ratio gives us γˆ, our Instrumental Variables (IV)\nestimate of the causal effect of trade on GDP.\n- Intuitively, we are comparing incomes among potentially similar countries that have\ndifferent ASDD′s. This comparison gives us the causal effect of ASDD on income\ngrowth (πˆ2 = γ × π1). We convert this relationship into an estimate of the causal\neffect of trade on income by re-scaling the GDP growth difference between high and\nlow ASDD countries by the causal effect of ASDD on trade growth.\n- [A bit of history: The IV method was developed in 1928 by the economist, P.G. Wright,\nwho wanted to measure the causal effect of supply changes on the price of flaxseed.\nHe used weather shocks as an exogenous source of variation in supply of flaxseed.\nInstrumental Variables has become central to causal empirical analysis in economics\nwithin the last two decades.]\nFindings\nThe main figures in the Feyrer paper tell the story. You should understand how each of\nthese figures contribute to the empirical case. See figures in the following order:\n1. Figure 1: Air freight shares to the U.S.\n2. Figure 3: Change in elasticity of trade with respect to Sea and Air distance over time\n3. Figure 2: Air imports to the US versus 1960 GDP per capita\n4. Figure 6 panel B (right-hand side): Air and Sea Distance Differential (ASDD) versus\nAverage Trade Growth 1960-1995\n5. Figure 7 panel B (right-hand side): ASDD and per capita GDP growth, 1960-1995\n\nAGO\nARG\nAUS\nAUS\nAUT\nBDI\nBEL\nBEN\nBFA\nBGD\nBOL\nBRA\nBRB\nBWA\nCAF\nCAN\nCHE\nCHL\nCHN\nCIVCMR\nCOL\nCOM\nCPV\nCRI\nCYP\nDNK\nDOM\nECU\nEGY\nESP\nETH\nFIN\nFJI\nFRA\nGAB\nGBR\nGHA\nGIN\nGMB\nGNB\nGRC\nGTM\nGUY\nHKG\nHND\nIDN\nIND\nIRL\nIRN\nISL\nISR\nITA\nJAM\nJOR\nJPN\nKEN\nKOR\nLKA\nLSO\nLUX\nMAR\nMDG\nMEX\nMLI\nMOZ\nMRT\nMUS\nMWI\nMYS\nNAM\nNER\nNGA\nNIC\nNLD\nNOR\nNPL\nNZL\nPAK\nPAN\nPER\nPHL\nPNG\nPRT\nPRY\nROM\nRWA\nSEN\nSGP\nSLV\nSWE\nSYC\nSYR\nTCD\nTGO\nTHA\nTTO\nTUR\nTWN\nTZA\nUGA\nURY\nVEN\nZAF\nZMB\nZWE\n.2\n.4\n.6\n.8\nProportion of Exports to US by Air 2001\nln(real GDP per worker 1960)\nFigure 2: 2001 Air Imports to the US versus 1960 GDP per capita\nARG\nAUS\nBEN\nBGD\nBRA\nBRB\nCAN\nCHL\nCHN\nCIV\nCMR\nCOL\nCRI\nCYP\nDNK\nDOM\nECU\nEGY\nESP\nFIN\nFJI\nFRA\nGBR\nGHA\nGIN\nGMB\nGNB\nGNQ\nGRC\nGTM\nGUY\nHND\nIDN\nIND\nIRL\nISL\nISR\nITA\nJAM\nJOR\nJPN\nKEN\nKOR\nLKA\nMAR\nMDG\nMEX\nMOZ\nMRT\nMUS\nMYS\nNAM\nNIC\nNLD\nNOR\nNZL\nPAK\nPAN\nPER\nPHL\nPNG\nPRT\nROM\nSEN\nSGP\nSLV\nSWE\nSYC\nSYR\nTGO\nTHA\nTUR\nTZA\nURY\nUSA\nZAF\nAverage trade growth 1960-1995\n3.8\n4.2\n4.4\n4.6\nAir and Sea Distance Difference\nFigure 6: First Stage: Actual Trade Growth 1960-1995 versus Instruments\nCourtesy of James Feyrer. Used with permission.\nCourtesy of James Feyrer. Used with permission.\n\nARG\nAUS\nBEN\nBGD\nBRA\nBRB\nCAN\nCHL\nCHN\nCIV\nCMR\nCOL\nCRI\nCYP\nDNK\nDOM\nECU\nEGY\nESP\nFIN\nFJI\nFRA\nGBR\nGHA\nGIN\nGMB\nGNB\nGNQ\nGRC\nGTM\nGUY\nHND\nIDN\nIND\nIRL\nISL\nISR\nITA\nJAM\nJOR\nJPN\nKEN\nKOR\nLKA\nMAR\nMDG\nMEX\nMOZ\nMRT\nMUS\nMYS\nNAM\nNIC\nNLD\nNOR\nNZL\nPAK\nPAN\nPER\nPHL\nPNG\nPRT\nROM\nSEN\nSGP\nSLV\nSWE\nSYC\nSYR\nTGO\nTHA\nTUR\nTZA\nURY\nUSA\nZAF\n-4\n-2\nAverage per capita GDP growth 1960-1995\n3.8\n4.2\n4.4\n4.6\nAir and Sea Distance Difference\nFigure 7: Reduced Form: Average Per Capita GDP Growth 1960-1995 versus In-\nstruments\nJim Feyrer was kind enough to make a special table exclusively for 14.03/14.003 that\nshows the key results in a format that complements the analytic tools presented above.\nInstrumental\nOLS\nFirst Stage\nReduced Form\nVariables\n(1)\n(2)\n(3)\n(4)\nDependent Variable\nGDP Growth\nTrade Growth\nGDP Growth\nGDP Growth\nTrade Growth\n0.55\n0.75\n[0.070]**\n[0.16]**\nAir Sea Distance Difference\n5.30\n4.00\n[1.35]**\n[1.04]**\nConstant\n-‐0.50\n-‐17.71\n-‐14.72\n-‐1.37\n[0.35]\n[5.65]**\n[4.37]**\n[0.74]~\nObservations\nR-‐squared\n0.464\n0.142\n0.12\n0.407\nRobust standard errors in brackets\n+ significant at 10%; * significant at 5%; ** significant at 1%\nThe Effect of Trade Growth on Per Capita GDP Growth, 1960 -‐ 1995\n- The first column shows the Ordinary Least Squares (OLS) relationship between the\nchange in GDP and the change in trade at the country level during 1960 - 1995 for 76\nCourtesy of James Feyrer. Used with permission.\nCourtesy of James Feyrer. Used with permission.\n\ncountries:\nColumn (1) : ∆ln GDPj,60-95 = α + β1∆ln Tradej,60\n+ e .\n-95\nj\nThe point estimate of 0.55 implies that a 1% rise in trade is associated with a 0.55%\nrise in GDP (an elasticity of 0.55). You should not view this relationship as causal.\n- The second and third column show the relationship between ASDD and trade growth\n(column 2) and GDP growth (column 3).\nColumn (2) : ∆ln Tradej,60-95 = α′ + π1ASDDj + e′\nj,\nwhere Feyrer estimates that πˆ1 = 5.30\n- And\nColumn (3) : ∆ln GDPj,60\n95 = α′′ + π2ASDDj + e′′\nj,\n-\nwhere πˆ2 = 4.00.\n- Recall that πˆ2 = γ × π1. Hence, we can calculate the causal effect of trade on GDP as:\nπ1\nγ\nγˆ =\n×\nπˆ2\n=\nπ1\nˆπ1\n= 4.00 = 0.75\n5.30\n- This is exactly what Feyrer obtains in Column 4:\nColumn (4) : ∆ln GDPj,60-95 = α′′′ + γ∆Tj\n∗+ e′′′\nj ,\nwhere γˆ = 0.75. I've denoted the change in trade in this equation with an asterisk\n(∆Tj\n∗) because this is not the endogenous trade variable available in the data. Rather,\nit is the exogenous component due to ASDD, which is found in column 2 of the Feyrer\ntable.\n- Thus, our causal estimate of the effect of trade on GDP is that a one percent rise in\ntrade raises GDP per capita by three-quarters of a percentage point.\n- We'll talk further about this evidence (both its strengths and limitations) in class.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 14 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/cc6a0cc902b3546724034e50529671ab_MIT14_03F16_lec14.pdf",
      "content": "Lecture Note 14 - Why is Free Trade Controversial?\nTheory and Evidence\nDavid Autor, MIT and NBER\n14.03/14.003 Microeconomic Theory and Public Policy, Fall 2016\n\nWhy is Free Trade Controversial?\nTheory and evidence suggest that when countries choose to trade with one another, the gains\nfrom trade are positive. Moreover, in contrast to popular perceptions, trade is not a Robin\nHood operation that takes from rich countries to give to poor countries, or vice versa. Even\nvery rich countries can gain from trading with very poor countries. See for example the NY\nTimes editorial \"Let Them Sweat\" by Nicholas Kristof (on the class website).\nThis raises a puzzle: If trade is so terrific, why isn't everyone in favor of it? Here are two\npotential explanations:\n1. Politicians and lay people just don't get it. Like much of economics, the principle of\nComparative Advantage is simple and yet not immediately intuitive. Once you under-\nstand the principle of Comparative Advantage, you start to ask, how could anyone else\nthink differently?\nBut in fact there is a long tradition of thinking differently. An influential school of\nthought called Mercantilism believes that trade is a zero-sum game; if a foreign country\nbuys my goods, I win and it loses. And vice versa if I buy its goods. This view is\nspelled out in Paul Krugman's paper on your reading list, \"Ricardo's Difficult Idea.\"\n(Ricardo was the economist who first formally articulated the principle of Comparative\nAdvantage.)\n2. But it's also possible that there is something potentially troubling about trade that\npeople do recognize, and which our very simple models above don't capture. This thing,\nalso implied by the model, is that although trade improves aggregate consumer surplus,\nit typically creates winners and losers within a country. This is because international\ntrade maximizes the pie and changes the sizes of the slices.\nIn the absence of an\nextremely flexible system of taxes and transfers, it is quite possible for trade to improve\naggregate consumer surplus while leaving certain groups distinctly worse offthan they\nwould have been in Autarky, i.e. domestic trade alone. Here is why...\nRefer to the following figure, where we consider what happens to two people (A and B) who\nboth live in Home when it opens up to trade:\n\n- In this economy:\n- E is the initial endowment.\n- The two goods are F and S (food and shelter) on the X and Y axes respectively.\n- A′s consumption is increasing as we move from the lower-left corner to the upper-\nright corner, and vice versa for consumer B.\n- The subscripts NT and T refer to \"No International Trade\" and \"International\nTrade.\" (We assume that trade among consumers within the Home economy al-\nways occurs.)\n- First, consider the equilibrium under no trade (NT).\n- The equilibrium price ratio that clears the market is -(ps/pf)NT and consumption\nis at point Z on the Contract Curve (CC).\n- The markets for Food and Shelter both clear.\n- Consumers A and B are both better offrelative to their initial indifference curves\n(those intersecting point E). Point Z represents a Pareto improvement relative\nto point E.\n\n- Now consider what would have occurred had Home opened itself to international trade\ninstead starting from the initial endowment, E.\n- Assume that the world price ratio is given by (ps/pf)T . This ratio places a higher\nrelative value on shelter than the home price ratio: (ps/pf)T > (ps/pf)NT .\n- Now, the equilibrium looks quite different:\n- The price ratio rotates clockwise to -(ps/pf)T.\n- Although both A and B′s chosen bundles are tangent to the world price ratio,\nthey are not tangent to one another. That is ZT,A and ZT,B both lie along the\nbudget set -(ps/pf)T, but they are not the same point.\n- Consumer A is now consuming much more food than under the NT equilibrium\nand slightly less shelter.\n- Consumer B is now consuming more food than under the NT equilibrium and\nmuch less shelter.\n- Home is now a net exporter of shelter and a net importer of food. This is reflected\nin the figure: the sum of A and B's food with trade is far higher than their\ncountries' total endowment (the height of the Edgeworth box), while the sum\nof their consumption of shelter is less than their endowment (the length of the\nEdgeworth box). Home's chosen consumption bundle would not have been feasible\nabsent trade.\nA welfare analysis in three parts\n1.1\nIs the equilibrium under free trade Pareto superior to the initial\nallocation, E?\nYes. Comparing the indifference curves at the endowment and along with free trade price\nratio, we see that both A and B prefer ZT,A and ZT,B (respectively) to E.\nMoreover, there is no way that trade could make them worse offthan they were at E\nsince either party could always choose to consume his or her initial endowment rather than\ntrade.\nFree trade is Pareto improving relative to the initial allocation.\n\n1.2\nIs the equilibrium under free trade Pareto superior to the equi-\nlibrium under Autarky (only within-country trade)?\nInterestingly, the answer is no.\nYou can see that party A is much better offat ZT,A than Z and party B is considerably\nworse offat ZT,B than Z.\nWhy did this happen? Recall that trade raised the relative price of shelter and lowered\nthe relative price of food. According to their initial endowments, consumer A was relatively\nrich in shelter and consumer B was relatively rich in food. So, trade increased the value of\nA′s bundle and decreased the value of B′s bundle.\nMoreover, trade affects consumer welfare only by altering prices. Conversely, if trade\ndoes not change prices, it does not affect consumer welfare. Trade raises aggregate consumer\nsurplus by allowing consumers as a whole to consume bundles that were not previously feasi-\nble, given the country's original endowment and prices. But it also devalues the endowments\nof consumers within a country who specialize in goods whose relative price has fallen. So,\nif you were a food producer, and your country opened to trade with a country that had a\nrelatively abundant supply of food, you may effectively be made poorer by the trade-opening.\nYou still have a hefty endowment of food, but this endowment cannot buy as much shelter\nas it could under the Autarky equilibrium.\nDoes trade necessarily make one party worse off? Actually, the answer is no, not neces-\nsarily. Although rotating the price ratio through the initial endowment E has the effect of\nraising the value of food relative to shelter or vice versa--thus worsening the terms of trade for\nthe agent who is relatively more endowed in the good whose relative price is falling--opening\nto trade has a second effect that potentially benefits both agents. Namely, trade makes it\nfeasible for agents A and B to consume bundles that do not lie within the feasible set under\nAutarky. This is reflected in a property of this Edgeworth box that we have not seen before:\nalthough their indifference curves still need to be tangent to the price ratio in equilibrium,\nunder trade their indifference curves no longer need to be tangent to one another. Since\nwe've eliminated a key restriction that we have in the Edgeworth box under autarky, we\nshould expect that trade can be Pareto improving. By playing with the diagram above, you\ncan demonstrate to yourself that small changes in the price ratio from the initial Autarkic\nprice ratio can in some cases make both parties better offrelative to the point they would\nhave attained on the contract curve under autarky.\nBottom line: International trade raises total consumption but may or may not yield a\nPareto improvement relative to the Autarkic setting. Often, some parties within a country\nwill be better offwith trade relative to autarky while other parties within a country will be\n\nworse off.\n1.3\nIs there always a potential Pareto improvement from opening\nto international trade?\nNow let's return to the case where there are distinct winners and losers from trade. Are the\ngains from trade large enough that we could make consumer A better offwithout making\nB worse offby redistributing the gains from trade?\nIf yes, there is a potential Pareto\nimprovement here, and trade could be (at least weakly) good for everyone.\nKeeping B as well offas he was at point Z requires that he consume on the same\nindifference curve on which point Z lies.\nConsider moving the endowment from point E to point E′. That is, we redistribute some\nshelter from A to B with a lump-sum transfer.\nNow, starting from point E′, the same world price ratio prevails: (ps/pf)T. Remember\nthat Home is a price-taker on world markets, so consumers A and B pay this relative price\nno matter how much they produce and consumer in equilibrium.\nIf we draw the ray with slope -(ps/pf)T extending from point E′, this ray is tangent\nto B′s indifference curve intersecting Z. Therefore, B is indifferent between trade under\nautarky and world trade with redistribution from E to E′.\nCrucially, A is unambiguously better off. He can still consume on a higher indifference\ncurve.\nAs we suspect from studying the Second Welfare Theorem (and noting that this market is\ncompetitive by assumption), there is no trade-offbetween equality and efficiency. Through an\nappropriate set of transfers, we can both exhaust all gains from trade and achieve any Pareto\nefficient allocation desired. The aggregate gains from trade do not necessarily come at the\nexpense of equity--a potential Pareto improvement (sometimes called a Kaldor improvement)\nis always feasible. International trade does not overturn the 1st and 2nd welfare theorems.\nHow do we know that the Kaldor criterion will always be satisfied--that is, that the gains\nfrom trade are necessarily large enough to potentially make both parties better off? The an-\nswer is that international trade is equivalent to relaxing one constraint in our Edgeworth box.\nIn the Autarkic Edgeworth box, the equilibrium required both that consumption was Pareto\nefficient (MRS equated among consumers) and that the sum of demands of all consumers\nwas equal to the aggregate economy wide endowment. Trade relaxes the second constraint.\nAlthough the MRS of all consumers is equated to the price ratio under international trade,\nit no longer has to be the case that a country consumes only what it produces. So long as\nanother country is willing to trade with it, its consumption may exceed its endowment in\n\nsome goods (though not all goods--since this would imply a trade imbalance).\nIn sum: International trade necessarily improves national welfare (crudely, GDP), by\nallowing countries to consume a different bundle than what they produce. But international\ntrade does not necessarily raise welfare of all citizens. Indeed, it will typically make some\nworse off. The analysis above says that equity does not have to suffer due to trade. Gains\nfrom trade are inherently large enough to fully compensate the losers and still produce\nsome winners. But trade often will produce both winners and losers unless governments\nimplement redistributive policies to prevent this from occurring.\nRelevance\nThe principle of comparative advantage is a fundamental economic insight of great relevance\nand generality. This principle explains why, almost to a person, economists support free\ntrade everywhere and always.\nThe argument is as fundamental as the general welfare theorems, and closely analogous.\nThe welfare theorems (as seen in the Edgeworth box) demonstrate that allowing individuals\nto trade freely with one another until all gains from trade are exhausted necessarily benefits\nall parties. The principle of comparative advantage says that allowing countries to trade\nalways raises welfare in both countries.\nBut there is a key difference between these two conclusions. International trade does not\nnecessarily benefit every individual. It's likely to create winners and losers (relative to trade\namong individuals in autarky). By contrast, free trade among individuals always generates\nPareto improvements.\nThe principle of comparative advantage combined with the 1st and 2nd welfare theorems\nillustrates that it is possible to make each citizen better offthrough trade than under autarky,\nwhen trade is combined with lump-sum transfers. Whether this occurs depends upon the\npolitically feasibility of implementing redistributive policies to counteract the redistribution\naccompanying trade liberalization. Little in the vast sweep of history suggests that the gains\nfrom trade are typically redistributed so that the losers are compensated.\nAs we discussed when reading the Feyrer paper, there is compelling causal evidence that\ntrade increases GDP in both developing and developed economies. But trade between the\ndeveloped and less-developed countries (LDCs) will generally tend to lower the wages of\nless-educated workers in developed countries.\nThis is because developed economies have\ncomparative advantage (relative to most other countries) in technology- and skill-intensive\nproducts and services. So, opening of developed countries to trade with LDCs generally raises\nthe wages of highly skilled workers in developed economies and reduces the wages of less\n\nskilled workers in these economies. The 2013 American Economic Review paper by Autor,\nDorn and Hanson presents evidence that this is more than just a theoretical possibility.\nBy the same token, however, trade raises the earnings of less-educated workers in LDCs\nbecause LDCs hold a comparative advantage in low-skill, labor-intensive production such as\nagriculture and mass production. (Another example: India has an enormous comparative\nadvantage in low-income workers who speak English well. It's no coincidence that you often\nspeak with an Indian worker when you call help desks for major American companies.)\nThe Second Welfare theorem says that we could compensate less-educated workers in\ndeveloped countries for their losses and still make everyone else better off. But the political\nreality is that this is quite unlikely to happen. Perhaps as a consequence, trade unions and\nnon-college workers are generally strongly opposed to international trade. These interest\ngroups are probably neither sinister or foolish; they do not oppose Pareto improvements\nin general. They may, however, understand that international trade without accompanying\nredistribution makes them worse off. Politically, opening to trade is comparatively easy.\nRedistributing gains from winners to losers is politically extremely difficult. Permitting the\nfirst without pursuing the second may have strong redistributive consequences--and the\nredistribution induced by trade in industrialized economies is typically (though not always)\nfrom less affluent to more affluent workers.\nEvidence on Trade, Employment and Earnings in Local\nLabor Markets (Autor, Dorn and Hanson AER 2013)\nWe have built a theoretical and empirical case that trade raises national income. We have\nalso established a theoretical case that trade opening can be redistributive--that is, it need\nnot be Pareto improving for all citizens in an economy. We'll now examine some recent\nempirical evidence on this point, specifically, how rising import competition from China\nappears to affect employment and earnings in local U.S. labor markets. For this evidence,\nwe'll turn to the recent paper by Autor, Dorn and Hanson (AER 2013, ADH hereafter).\nThe challenge in analyzing how rising Chinese import competition affects U.S. labor\nmarkets is two-fold. First the rise in Chinese imports is endogenous--it's driven both by\nimproving productivity in China (a supply shock from the perspective of U.S. producers) and\nalso by rising consumer demand for various goods, some of which happen to be produced in\nChina. Both supply and demand shocks will increase Chinese imports, but only the former\nis analogous to a unilateral, trade-driven price change in our conceptual model of a country\nopening to trade. The latter, by contrast, is probably capturing a rise in consumer wealth,\n\nwhich would be expected to increase demand for both domestic and imported goods. That\nmay in itself be an interesting object for study, but it is not the subject of our inquiry here:\nwe want to understand how exogenous changes in domestic prices induced by international\ntrade affects employment and wages of domestic workers who produce import-competing\ngoods.\nADH propose to address this problem by using an instrumental variables strategy. The\ngoal of their strategy is to identify plausibly exogenous variation in Chinese import compe-\ntition facing the U.S. Their basic approach is as follows:\n- Using data on imports and exports of 450 manufactured goods in the U.S. and eight\nother non-U.S., high-income countries, they instrument for (i.e., use instrumental vari-\nables) rising imports to the U.S. from China using the contemporaneous change in\nChinese imports (by product category) in these eight other economies.\n- The idea underlying this approach is that if these eight countries and the U.S. simulta-\nneously increase their imports of Chinese goods in a certain detailed product category,\nthis is likely due to rising Chinese competitiveness (i.e., falling Chinese prices) in this\nproduct category rather than a sudden cross-national surge in demand for goods from\nthis category that happen to be produced in China. For example, if over the course\nof a 10 year period, we see that the U.S. and all other high-income countries begin\nimporting luggage from China rather than from Mexico, we infer that this is because\nChinese luggage is getting cheaper and not because consumers in these countries have\ndeveloped a preference for Chinese over Mexican-made luggage.\n- To develop notation, consider two categories of imported manufacturing goods, ma-\nchine tools and luggage, respectively, denoted by k ∈{0, 1}.\n- Assume, plausibly, that imports of luggage from China are rising rapidly in high-income\neconomies due to rising Chinese productivity (and hence falling Chinese prices) in these\ngoods whereas imports of machine tools from China are relatively stagnant because\nthese are goods in which high-income countries have strong comparative advantage.\n- We would thus expect that\n∆IUS,1\n=\nα1 + π1∆IEU,1,\n∆IUS,0\n=\nα1,\n∆IUS,k\n=\nπ1∆IEU,k\n\nwhere I denotes imports (in dollars), the subscript EU denotes the European Union,\nand we expect that π1 > 0.\n- Note that we do not directly observe the change in the price of Chinese luggage relative\nto Chinese machine tools. But we infer that this price change is the force that causes\nimports of Chinese luggage to surge simultaneously in the EU and US (and of course\nif they did not rise in tandem, we would have πˆ1 = 0). For shorthand, we will say that\nπ1 is the causal effect of the change in Chinese prices on US imports from China.\nThe second empirical challenge for the paper is identifying which labor markets are poten-\ntially affected by trade with China. It would be unproductive to study the impact of rising\ncompetition from China on the U.S. \"in its entirety\" since this approach would leave us lack-\ning an appropriate comparison group. As in Card & Krueger's New Jersey/Pennsylvania\nstudy, we want to compare trade-exposed U.S. regions to non-trade-exposed regions over\ntime in a DD, since general trends in the U.S. may be driven by a wide variety of factors.\nLuckily for our study, although luggage is consumed in every state, city and suburb of the\nU.S., it is only produced in a few locations. (In general, manufacturing is geographically\nconcentrated. Furniture, luggage, footwear and textiles tend to be made in the East-South-\nCentral U.S. Machine tools and heavy industries are found much more in the mid-West.\nHigh technology industries like computers and pharmaceuticals are more commonplace on\nthe two coasts, and are particularly clustered near to leading research universities.)\nThis set of observations motivates the ADH's approach of identifying labor markets that\nare potentially affected by imports in each good category according to whether or not each\ngood was produced in that labor market at the start of the time period of study (1980).\nLet's again develop some notation.\n- Let j index local labor markets, and let Z be an indicator variable that is equal to 1\nif labor market j produces good k and 0 otherwise. Thus Zjk ∈{0, 1} is a matrix that\ndenotes which labor markets produce what goods.\n- Concretely, imagine we have two labor markets, Raleigh NC and Pittsburgh PA. Both\nare manufacturing centers, but Raleigh produces luggage and Pittsburgh produces\nmachine tools. Let j = 0 denote Pittsburgh and j = 1 denote Raleigh. Then, we have\nthe following values of Z:\nTools\nLuggage\nZjk = Pittsburgh\nRaleigh\n\n- More generally, we'll have many labor markets j and many goods k (to be precise, in\nADH j ∈[1, 722] and k ∈[1, 450]). So, for each labor market k, we can calculate a\nweighted average causal effect of Chinese prices on competing imports faced by that\nlabor market:\nK\nˆ\n∆Ij =\nX Zjk × πˆ1∆IEU,k\nk=1\nK\n= ˆπ1 ×\nK\nX\nk=1\nZjk × ∆IEU,k .\nK\nWe are at last ready to estimate the causal effect of interest.\n- Let's say the causal relationship between import competition and labor market out-\ncomes can be written as\n∆Yj = δ + γ∆Ij\n∗+ ej,\nwhere ∆Ij\n∗is the exogenous import supply shock due to falling import prices and ∆Y\nis a labor market outcome such as employment, unemployment, or wages.\n- We cannot estimate this causal relationship using the correlation between imports and\noutcomes (∆Yj = δ\n′ + γ\n′∆Ij + e\n′\nj) since the observed change in imports (∆Ij) includes\nboth supply and demand shocks. Instead we use our Instrumental Variables toolkit.\n- Write the reduced form relationship as:\n∆Yj = α2 + π2 ×\nX\nK Zjk∆IEU,k\nk=1\n.\nK\n!\n- As above, the first-stage relationship is\nˆ\nX\nK Z\n×\njk × ∆IEU,k\n∆Ij = πˆ1\nk=1\n.\nK\n- And of course\nπ2 = γ × π1.\n- Hence, our IV estimate is\nπˆ2\nγˆ =\n.\nπˆ1\nWe'll discuss the findings of the ADH paper during lecture.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 16 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/15fdaedd7b74ae967403129c3d063492_MIT14_03F16_lec16.pdf",
      "content": "Lecture Note 16: Uncertainty, Risk Preference, and\nExpected Utility Theory\nDavid Autor, MIT and NBER\n14.03/14.003, Microeconomic Theory and Public Policy, Fall 2016\n\nRisk Aversion and Insurance: Introduction\n- A significant hole in our theory of consumer choice developed in 14.03/14.003 to date is that\nwe have only modeled choices that are devoid of uncertainty: everything is known in advance.\nThat's convenient, but not particularly plausible.\n- Prices change\n- Income fluctuates\n- Bad stuffhappens\n- Most decisions are forward-looking: these decisions depend on our beliefs about what is\nthe optimal plan for present and future. Inevitably, such choices are made in a context of\nuncertainty. There is a risk (in fact, a likelihood) that not all scenarios we hoped for will\nbe borne out. In making plans, we should take these contingencies and probabilities into\naccount--and there is no doubt that people do take these things into account. If we want a\nrealistic model of choice, we need to model how uncertainty affects choice and well-being.\n- This model should help to explain:\n- How do people choose among \"bundles\" that have uncertain payoffs, e.g., whether to fly\non an airplane, whom to marry?\n- Insurance: Why do people want to buy it?\n- How (and why) the market for risk operates? (Markets for risk include life insurance,\nauto insurance, gambling, futures markets, warranties, bonds, etc.)\n1.1\nA few motivating examples\n1. People don't seem to want to play actuarially fair games. Such a game is one in which the\ncost of entry is equal to the expected payoff:\nE(X) = Pwin · [Payoff|Win] + Plose · [Payoff|Lose] .\n- Most people would not enter into a $1, 000 dollar heads/tails fair coin flip.\n2. People won't necessarily play actuarially favorable games:\n- You are offered a gamble. We'll flip a coin. If it's heads, I'll give you $10 million dollars.\nIf it's tails, you owe me $9.8 million.\n\nIts expected monetary value is :\n2 · 10 -1\n2 · 9.8 = $0.\nmillion($100, 000)\nWant to play?\n3. People won't pay large amounts of money to play games with huge upside potential. Example\n\"St. Petersburg Paradox.\"\n- Flip a coin. I'll pay you in dollars 2n, where n is the number of tosses until you get a\nhead:\nX1 = $2, X2 = $4, X3 = $8, ...Xn = 2n.\n- What is the expected value of this game?\nE(X) = 22 + 1\n44 + 1\n88 + ... 1 2n =\n2n\ninf.\n- How much would you be willing to pay to play this game? [People generally do not\nappear willing to pay more than a few dollars to play this game.]\n- What is the variance of this gamble? V (X) = inf.\n- The fact that a gamble with infinite expected monetary value has (apparently) limited utility\nvalue suggests something pervasive and important about human behavior: As a general rule,\nuncertain prospects are worth less in utility terms than certain ones, even when expected\ntangible payoffs are the same.\n- To have a coherent model of choice under uncertainty, we need to be able to say how people\nmake choices when:\n- Consumers value outcomes (as we have modeled all along) and\n- Consumers have feelings/preferences about the riskiness of those outcomes\nWe'll introduce the notion of risk aversion, insurance, and insurance markets in several steps. First,\nI'll review some basic probability theory, which will likely already be familiar. Next, I'll provide\nan optional formal development of so-called Von Neumann-Morgenstern expected utility theory\n(AKA, Expected Utility Theory). You don't have to spend time with the formal development,\nbut you are welcome to do so. Third, I'll provide an informal discussion of the Expected Utility\nproperty. Following that, I'll show how preferences that satisfy the Expected Utility property\ncan be used to formalize notions of risk preference--specifically, risk averse, risk neutral, and risk\n\nseeking preferences. From there, we will use these tools to understand how and why insurance\nmarkets work, and why risk is a good (or bad) that consumers will want to trade.\nHere's a noteworthy feature of markets for risk that you should contemplate as you study\nthis material: in settings with risk, there may be gains from trade--that is, potential Pareto\nimprovements--even when all consumers have identical preferences and endowments.\nIt is also important to note before we launch in that the models we are going to develop in this\nlecture note incorporate uncertainty in a very particular way. While we will will explore uncertainty\nin the probability of certain outcomes occurring, we are going to maintain the assumption that\nconsumers know two important things:\n1. They know the set of possible outcomes\n2. They know the probabilities of each of the outcomes\nThese are strong assumptions, but probably not unreasonable for certain important settings.\nFive Simple Statistical Notions\nDefinition 1. Probability distribution\nDefine states of the world 1, 2...n with probability of occurrence π1, π2...πn.\nA valid probability distribution satisfies:\nX\nn\ninf\nπi = 1, or\ni=1\nZ\nf(x)∂x = 1 and f(x) ≥0 ∀x.\n-inf\nIn this equation f (x) is the 'probability density function' (PDF) of the continuous random variable\nx, meaning that f (x) is essentially the probability of randomly drawing the given value x (so, f (x)\nis just like the πi in the discreet case). [Note that the probability of drawing any specific value\nfrom a continuous distribution is zero since there are an infinite number of possibilities. Depending\non the distribution, however, some ranges of values will be much more likely than others.]\n-\nDefinition 2. Expected value or \"expectation\"\nThe mean of a random variable (a notion that we've used all semester).\nSay each state i has payoffxi. Then\nn\nE(x) =\nX\nπixi or E(x) =\ni=1\nZ inf\nxf(x)∂x.\n-inf\n\nExample: Expected value of a fair dice roll is E(x) = P6\ni=1 πii = 1\n6 · 21 = 7.\n2 We've been using\nexpectations throughout the semester, so no doubt this is familiar.\n-\nDefinition 3. Variance (dispersion)\nGambles with the same expected value may have different dispersion.\nWe'll measure dispersion with variance.\nn\ninf\nV (x) =\nX\nπi (xi -E(x))2 or V (x) =\nZ\n(x -E(x))2 f(x)∂x.\ni=1\n-inf\nIn dice example, V (x) = Pn\ni=1 πi\ni -\n2 = 2.\n.\n-\nDefinition 4. Independence.\nA case in which the probabilities of two (or multiple) outcomes do not depend upon one an-\nother. If events A and B are independent, then Pr (A and B) = Pr (A) · Pr (B), and similarly,\nE [A · B] = E [A] · E [B] .\nExample: The probability of flipping two sequential heads with a fair coin is Pr (H and H) =\nPr (H) · Pr (H) = 0.25. These probabilities are independent, meaning that if you flipped heads the\nfirst time, you are no more or less likely to flip heads the second time.\nExample: The probabilities of seeing lightning and hearing thunder in an afternoon are not inde-\npendent of one another. If you see lightning, you're reasonably likely to hear thunder, and vice\nversa.\n-\nDefinition 5. Law of Large Numbers\nIn repeated, independent trials with the same probability p of success in each trial, the chance that\nthe percentage of successes differs from the probability p by more than a fixed positive amount\ne > 0 converges to zero as number of trials n goes to infinity for every positive e.\nExample: If you flip a fair coin 100 times, the probability of getting heads more than ≥51%\nof the time (that is, 51 or more times) is reasonably high. If you flip a fair coin 100,000 times,\nthe probability of getting heads more than ≥51% of the time (that is, 510,00 or more times) is\nvanishingly small.\n\n-\nDispersion and risk are closely related notions. Holding constant the expectation of X,\nmore dispersion means that the outcome is \"riskier\"--it has both more upside and more downside\npotential.\nConsider four gambles:\n1. $0.50 for sure. V (L1) = 0.\n2. Heads you receive $1.00, tails you receive 0.\nV (L2) = 1 × [0.5 × (1 -.5)2 + 0.50 × (0 -.5)2] = 0.25\n3. 4 independent flips of a coin, you receive $0.25 on each head.\nV (L3) = 4 ×\n2(0.25 -0.125)2 + 1\n2 × (0 -0.125)2\n) = 0.0625\n4. 100 independent flips of a coin, you receive $0.01 on each head.\nV (L4) = 100 ×\n2(0.01 -0.005)2 + 1(0 -0.005)2 = 0.0025\nAll four of these \"lotteries\" have same expected value (\n\n50 cents), but they have different levels of\nrisk.\nA key statistical result, which I will not prove here, is that the variance of n identical inde-\npendent gambles is 1\nn times the variance of one of the gambles. What this means in practice is\nthat pooling a large number of independent, identical gambles reduces the aggregate riskiness of\nthose gambles. This is closely related to the previous example of flipping a coin 100 versus 100,000\ntimes. The more independent gambles in the pool--the more flips of a fair coin--the greater the\ncertainty with which you can forecast the mean outcome.\n2.1\nLottery Details\n- The basic building block of our theory is the concept of a lottery.\nDefinition 6. A simple lottery L is a list L = (p1, ...pN) with pn ≥0 for all n and Σnpn = 1,\nwhere pn is interpreted as the probability of outcome n occurring.\n- In a simple lottery, the outcomes that may result are certain.\n- A more general variant of a lottery, known as a compound lottery, allows the outcomes of a\nlottery to themselves be simple lotteries.\nDefinition 7. Given K simple lotteries Lk =\npk\n1, ...pk\nN , k = 1..., K, and probabilities\nαk ≥0 with Σkαk = 1, the compound lottery (L\n1, ...LK; α\n\n1, ...αK) , is the risky alternative\nthat yields the simple lottery Lk with probability αk for k = 1, ..., K.\n\n- For any compound lottery (L1, ...LK; α1, ...αK), we can calculate a corresponding reduced\nlottery as the simple lottery L = (p1, ...pN) that generates the same ultimate distribution\nover outcomes. So, the probability of outcome n in the reduced lottery is:\npn = α1p1\nn + α2p2\nn + ... + αkpk\nn.\nThat is, we simply add up the probabilities, pk\nn, of each outcome n in all lotteries k, multi-\nplying each pk\nn by the probability αk of facing each lottery k.\n- We now study the decision maker's preferences over lotteries.\n- The basic premise of the model that follows is what philosophers would call a 'consequential-\nist' viewpoint: for any risky alternative, the decision maker cares only about the outcomes\nand their associated probabilities, or in technical terms, the reduced lottery over final out-\ncomes. By assumption, the decision maker is indifferent to the (possibly many) compound\nlotteries underlying these reduced lotteries.\n- This compound lottery assumption states that the 'frame' or order of lotteries is unimportant.\nSo consider the following two stage lottery:\n- Stage 1: You flip a coin: heads or tails.\n- Stage 2:\nIf the Stage 1 flip drew heads, you flip the coin again. Heads yields $1.00, tails yields\n$0.75.\nIf the Stage 1 flip drew tails, you roll a dice with payoffs $0.10, $0.20, ...$0.60 corre-\nsponding to outcomes 1 -6.\n- Now consider a single state lottery, where:\n- We spin a pointer on a wheel with 8 areas, 2 areas of 900 representing $1.00, and $0.75,\nand 6 areas of 300 each, representing $0.10, $0.20, ...$0.60 each.\n- This single stage lottery has the same payouts at the same odds as the 2-stage lottery.\n- The 'compound lottery' axiom says the consumer is indifferent between these two.\n- Counterexamples? [This is not an innocuous set of assumptions.]\n- [Is this realistic? Hard to develop intuition on this point, but research shows that this\nassumption is often violated.]\n\n- Implicitly, we are assuming that what enters into the decision maker's utility function is the\nfinal outcomes of these lotteries--the actual bundles consumed--not the probabilities along\nthe way. If that assumption is correct from a utility perspective, then compound lotteries\ncan be collapsed into simple lotteries so long as both the compound and simple lottery give\nrise to the identical set of consumption bundles with identical probabilities of consumption.\n(Another way to say this: the consumer does not consume the probabilities, only the realized\noutcomes.)\n[Optional] Risk preference and expected utility theory1\n[This section derives the Expected Utility Theorem. I will not cover this material in\nclass and I will not hold you responsible for the technical details.]\n3.1\nPreferences over lotteries\n- Consider the set of alternatives the decision maker faces, denoted by £ to be the set of all\nsimple lotteries over possible outcomes N.\n- We assume the consumer has a rational preference relation ≿on £, a complete and transi-\ntive relation allowing comparison among any pair of simple lotteries (I highlight the terms\ncomplete and transitive to remind you that they have specific meaning from axiomatic utility\ntheory, given at the beginning of the semester). [This could also be called an axiom--or even\ntwo axioms!]\n- Axiom 1.\nContinuity. Small changes in probabilities do not change the nature of the\nordering of two lotteries. This can be made concrete here (I won't use formal notation b/c\nit's a mess). If a \"bowl of miso soup\" is preferable to a \"cup of Kenyan coffee,\" then a mixture\nof the outcome \"bowl of miso soup\" and a sufficiently small but positive probability of \"death\nby sushi knife\" is still preferred to \"cup of Kenyan coffee.\"\n- Continuity rules out \"lexicographic\" preferences for alternatives, such as \"safety first.\" Safety\nfirst is a lexicographic preference rule because it does not trade-offbetween safety and\ncompeting alternatives (fun) but rather simply requires safety to be held at a fixed value for\nany positive utility to be attained.\n1This section draws on Mas-Colell, Andreu, Michael D. Winston and Jerry R. Green, Microeconomic Theory,\nNew York: Oxford University Press, 1995, chapter 6. For those of you considering Ph.D. study in economics, MWG\nis the only text that covers almost the entire corpus of modern microeconomic theory. It is the Oxford English\nDictionary of modern economic theory. Most economists keep it on hand for reference; few read it for pleasure.\n\n- The second key building block of our theory about preferences over lotteries is the so-called\nIndependence Axiom.\n- Axiom 2. Independence. The preference relation ≿on the space of simple lotteries £\nsatisfies the independence axiom if for all L, L′, L′′ ∈£ and α ∈(0, 1), we have\nL ≿L′ if and only if αL + (1 -α) L′′ ≿αL′ + (1 -α) L′′.\n- In words, when we mix each of two lotteries with a third one, then the preference ordering\nof the two resulting mixtures does not depend on (is independent of ) the particular third\nlottery used.\n- Example: If a bowl of miso soup is preferred to cup of Peets coffee, then the lottery (bowl\nof miso soup with 50% probability, steak dinner with 50% probability) is preferred to the\nlottery (cup of Peets coffee with 50% probability, steak dinner with 50% probability).\n3.2\nExpected utility theory\n- We now want to define a class of utility functions over risky choices that have the \"expected\nutility form.\" We will then prove that if a utility function satisfies the definitions above for\ncontinuity and independence in preferences over lotteries, then the utility function has the\nexpected utility form.\n- It's important to clarify now that \"expected utility theory\" does not replace consumer theory,\nwhich we've been developing all semester. Expected utility theory extends the model of\nconsumer theory to choices over risky outcomes. Standard consumer theory continues to\ndescribe the utility of consumption of specific bundles. Expected utility theory describes\nhow a consumer might select among risky bundles. [This paragraph will be repeated below\nin the non-optional section of the lecture note.]\nDefinition 8. The utility function U : £ →R has an expected utility form if there is\nan assignment of numbers (u1, ...uN) to the N outcomes such that for every simple lottery\nL = (p1, ..., pN) ∈£ we have that\nU (L) = u1p1 + ... + uNpN.\n- A utility function with the expected utility form is called a Von Neumann-Morgenstern\n(VNM) expected utility function.\n\n- The term expected utility is appropriate because with the VNM form, the utility of a lottery\ncan be thought of as the expected value of the utilities un of the N outcomes.\n- In other words, a utility function has the expected utility form if and only if:\nU\nX\nK\nk=1αkLk\n\n=\nX\nK\nk=1αkU (Lk)\nfor any K lotteries Lk ∈£, k = 1, ..., K, and probabilities (α1, ..., αK) ≥0, Σkαk = 1.\n- Intuitively, a utility function has the expected utility property if the utility of a lottery is\nsimply the (probability) weighted average of the utility of each of the outcomes.\n- A person with a utility function with the expected utility property flips a coin to gain or lose\none dollar. The utility of that lottery is\nU (L) = 0.5U (w + 1) + 0.5U (w -1) ,\nwhere w is initial wealth.\n- Q: Does that mean that\nU (L) = 0.5 (w + 1) + 0.5 (w -1) = w?\nNo. We haven't actually defined the utility of an outcome, and we certainly don't want to\nassume that U (w) = w.\n3.3\nProof of expected utility property\nProposition. (Expected utility theory) Suppose that the rational preference relation ≿on the\nspace of lotteries £ satisfies the continuity and independence axioms. Then ≿admits a utility\nrepresentation of the expected utility form. That is, we can assign a number un to each outcome\nn = 1, ..., N in such a manner that for any two lotteries L = (p1, ...PN) and L′ = (p′\n1, ...PN\n′ ) , we\nhave L ≿L′ if and only if\nX\nN\nN\nupn\nunp′\nn\nn=1\n≥\nX\nn=1\nProof. Expected Utility Property (in five steps)\nAssume that there are best and worst lotteries in £, L and L.\n1. If L ≻L′ and α ∈(0, 1) , then L ≻αL + (1 -α) L′ ≻L′. This follows immediately from the\nindependence axiom.\n\n2. Let α, β ∈[0, 1] . Then\n\nβL + (1 -β)L≻\n\nαL + (1 -α)L if and only if β > α. This follows\nfrom the prior step.\n3. For any L ∈\n\n£, there is a unique αL such that\n\nαLL + (1 -αL) L\nUniqueness\n\n∼L. Existence follows\nfrom continuity.\nfollows from the prior step.\n4. The function U : £ →R that assigns U (L) = αL for all L ∈£ represents the preference\nrelation ≿.\nObserve by Step 3 that, for any two lotteries L, L′ ∈£, we have\nL ≿L′ if and only if\n\nαLL + (1 -αL) L\n\n≿\n\nαL′ L + (1 -αL′) L\nand\n\n.\nThus L ≿L′ if\nonly if αL ≥αL′.\n5. The utility function U (·) that assigns U (L) = αl for all L ∈£ is linear and therefore has\nthe expected utility form.\nWe want to show that for any L, L′ ∈£, and β [0, 1] , we have U (βL + (1 -β) L′) =\nβU (L) + (1 -β) U ′ (L) .\nBy step (3) above, we have\n\nL\n∼\nU (L) L + (1 -U (L)) L = αL L + (1 -αL) L\nL′\n∼\nU (L′) L + (1 -U (L′)) L = α′\nL L + (1 -α′\nL) L.\nBy the Independence Axiom,\nβL + (1 -β) L′ ∼β\n\nU (L) L + (1 -U (L)) L\n\n+ (1 -β)\n\nU (L′) L + (1 -U (L′)) L\ne\n\n.\nRearranging terms, we hav\nβL + (1 -β) L′\n∼\n[βU (L) + (1 -\n\nβ) U (L′)] L +\n\nβ (1 -U (L)) + (1 -β)\n1 -U (L)′\nL\n=\n[βU (L) + (1 -β) U (L′)] L + [1 -βU (L) + (β -1) U (L′)] L.\nBy step (4), this expression can be written as\n[βαL + (1 -\n\nβ) αL′] L + [1 -βαL + (β -1) αL\n′ ] L\n=\nβ\nαL L + (1 -αL) L\n\n+ (1 -β)\nαL′ L + (1 -α′\nL) L\n=\nβU (L) + (1 -β) U (L′) .\n\nThis establishes that a utility function that satisfies continuity and the Independence Axiom,\n\nhas the expected utility property: U (βL + (1 -β) L′) = βU (L) + (1 -β) U (L′)\n[End of optional self-study section.]\nThe Expected Utility property\n- The key to our model of risk preference is the assumption that preferences over risk can\nbe described by the so-called Von Neumann-Morgenstern (VNM) Expected Utility Property\n(derived formally in the optional material above).\n- Preferences that satisfy VNM Expected Utility theory have the property:\nU (βL + (1 -β) L′) = βU (L) + (1 -β) U (L′) ,\nwhere L and L′ are bundles with L = L′ and β ∈(0, 1).\n- This equation says that for a person with VNM preferences, the utility of consuming two\nbundles L and L′ with probabilities β and (1 -β) , respectively, is equal to β times the\nutility of consuming bundle L plus (1 -β) times the utility of consuming bundle L′. Thus,\nthe utility function is linear in probabilities though not necessarily linear in preferences over\nthe bundles. [Note: VNM does not imply that U (2L) = 2 × U (L). As we'll see below, that\nequation would only hold for risk neutral preferences.]\n- A person who has VNM EU preferences over lotteries will act as if she is maximizing expected\nutility--a weighted average of utilities of each state, where weights equal probabilities.\n- If this model is correct, then we don't need to know exactly how people feel about risk per\nse to make strong predictions about how they will optimize over risky choices.\n- [If the model is not entirely correct--which it surely is not--it may still provide a useful\ndescription of the world and/or a normative guide to how one should analytically structure\nchoices over risky alternatives.]\n- To use this model, two ingredients are needed:\n1. First, a utility function that assigns bundles an ordinal utility ranking.\nNote that\nsuch functions are defined up to an affine (i.e., positive linear) transformation. This\nmeans they are required to have more structure (i.e., are more restrictive) than standard\nconsumer utility functions, which are only defined up to a monotone transformation.\n\n- These utility functions will capture consumer preferences for risk as well as consumer\npreferences for bundles.\n2. Second, the VNM assumptions. These make strong predictions about the maximizing\nchoices consumers will take when facing risky choices (i.e., probabilistic outcomes) over\nbundles, which are of course ranked by this utility function.\n- These assumptions are discussed at length above, but these assumptions guarantee\nthat consumers have well behaved preferences over lotteries, similarly to how the\naxioms of consumer choice guaranteed that consumers have well-defined preferences\nover bundles of good. Specifically, we assume that consumer preferences over lotter-\nies are continuous (i.e. small changes in probabilities do not change the ordering of\npreferences) and independent (i.e. if we mix each of two lotteries with a third one,\nthen the preference ordering of the two resulting mixed lotteries does not depend\non (is independent of ) the particular third lottery used)\n- It's important to clarify now that expected utility theory does not replace consumer theory,\nwhich we've been developing all semester. Expected utility theory extends the model of\nconsumer theory to choices over risky outcomes. Standard consumer theory continues to\ndescribe the utility of consumption of specific bundles. Expected utility theory describes\nhow a consumer might select among risky bundles.\nExpected Utility Theory and Risk Aversion\n- We started offto explain risk aversion. What we have done to far is lay out expected utility\ntheory, which is a set of (relatively restrictive) axioms about how consumers make choices\namong risky bundles.\n- Where does risk aversion come in? It is going to come in with the specification of the utility\nfunction\n- Consider the following three utility functions characterizing three different expected utility\nmaximizers:\n-\nu1(w) = w\n\n-\nu2(w) = w2\n-\nu3(w) =√w\n\n- Consider a lottery where the consumer faces 50/50 odds of either receiving two dollars or\nzero dollars. The expected monetary value of this lottery is $1.\n- How do these three consumers differ in their risk preference?\n- First notice that u1(1) = u2(1) = u3(1) = 1. That is, they all value one dollar with certainty\nequally.\n- Now consider the Certainty Equivalent for a lottery L that is a 50/50 gamble over $2 versus\n$0. The certainty equivalent is the amount of cash that the consumer would be willing to\naccept with certainty in lieu of facing lottery L.\n- Step 1: What is the expected utility value?\n1. u1(L) = .5 · u1(0) + .5 · u1(2) = 0 + .5 · 2 = 1\n2. u2(L) = .5 · u2(0) + .5 · u2(2) = 0 + .5 · 22 = 2\n3. u3(L) = .5 · u3(0) + .5 · u3(2) = 0 + .5 · 2.5 = .71\n- Step 2: What is the \"Certainty Equivalent\" of lottery L for these three utility func-\ntions--that is, the cash value that the consumer would take in lieu of facing these\nlotteries? To find this, we calculate the dollar value that gives the consumer the same\nutility as the lottery.\n\n1. CE1(L) = U -1\n1 (1) = $1.00\n2. CE2(L) = U2\n-1(2) = 2.5 = $1.41\n3. CE3(L) = U -1\n3 (0.71) = 0.712 = $0.51\n- Depending on the utility function, a person would pay $1, $1.41, or $0.51 dollars to participate\nin this lottery.\n- Although the expected monetary value E(V ) of the lottery is $1.00, the three utility functions\nvalue it differently:\n1. The person with U1 is risk neutral: CE = $1.00 = E(V alue) ⇒Risk neutral\n2. The person with U2 is risk loving: CE = $1.41 > E(V alue) ⇒Risk loving\n3. The person with U3 is risk averse: CE = $0.50 < E(V alue) ⇒Risk averse\n- What gives rise to these inequalities is the shape of the utility function. Risk preference comes\nfrom the concavity/convexity of the utility function:\nN\n- Expected utility of wealth: E(U(w)) =\ni\nP piU(wi)\n=1\nN\n- Utility of expected wealth: U(E(w)) = U\n\ni\nP piwi\n=1\n\n- Jensen's inequality:\n- E(U(w)) = U(E(w)) ⇒Risk neutral\n- E(U(w)) > U(E(w)) ⇒Risk loving\n- E(U(w)) < U(E(w)) ⇒Risk averse\n- So, the core insight of expected utility theory is this: For a risk averse consumer facing an\nuncertain set of possible wealth levels, the expected utility of wealth is less than the\nutility of expected wealth.\n\n- The reason this is so:\n- If wealth has diminishing marginal utility (as is true if U (w) = w1/2), losses cost more\nutility than equivalent monetary gains provide. This can be seen in the concave shape\nof the utility function - for lower levels of wealth, the utility function has a steeper slope.\n- Consequently, a risk averse consumer is better offreceiving a given amount of wealth\nwith certainty than the same amount of wealth on average but with variance around\nthis quantity.\nConclusions\nYou may be thinking that we have used a lot of machinery to build a pretty modest conceptual\nwidget. So far, you would be right. But the tool of Expected Utility Theory will prove quite\npowerful in the lectures to follow. We will first use VNM EU Theory to formally model people's\nwillingness to pay to defray (avoid/reduce) risk. We will then analyze markets for risk, and glimpse\nthe potential for insurance markets to generate Pareto-improving trades among economic agents\nwho each possess identical bundles, preferences, and technologies. We will also analyze implicit\nmarkets for risk, as seen in the case of speed limits and the so-called value of a statistical life\n(VSL). Risk and insurance will then prove foundational in our study of imperfect information in\nmarkets, which is the final broad topic of the semester.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 17 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/52fb22da4549f122296baafbf35a512d_MIT14_03F16_lec17.pdf",
      "content": "Lecture Note 17: The Market for Risk\nDavid Autor, MIT and NBER\n14.03/14.003, Microeconomic Theory and Public Policy, Fall 2016\n\nIntroduction\nIn the previous lecture note, we developed a model for risk preference. Now we're going to put it\nto work. We will first consider what individuals will be willing to pay to defray (avoid or reduce)\nrisk. We will next consider how markets for risk (AKA insurance markets) work in practice.\nRisk aversion and insurance\n- Consider insurance that is actuarially fair, meaning that the premium is equal to expected\nclaims: Premium = p·A where p is the expected probability of a claim, and A is the amount\nthat the insurance company will pay in the event of an accident.\n- How much insurance will a risk averse person buy?\n- Consider a person with an initial endowment consisting of three things: A level of wealth\nw0; a probability of an accident of p; and the amount of the loss, L (in dollars) should a loss\noccur:\nPr(1 -p)\n:\nU (·) = U(wo),\nPr(p)\n:\nU (·) = U(wo -L)\n- If insured, the endowment is (incorporating the premium pA, the claim paid A if a claim is\nmade,and the loss L):\nPr(1 -p)\n:\nU (·) = U(wo -pA),\nPr(p)\n:\nU (·) = U(wo -pA + A -L)\n- Expected utility if uninsured is:\nE(U|I = 0) = (1 -p)U(w0) + pU(wo -L).\n- Expected utility if insured is:\nE(U|I = 1) = (1 -p)U(w0 -pA) + pU(wo -L + A -pA).\n(1)\n- How much insurance would this person wish to buy (assuming they can buy up to their total\nwealth, w0-pL, at actuarially fair prices)? To solve for the optimal amount of insurance that\n\nthe consumer should purchase, maximize their utility with respect to the insurance policy:\nmax E(U)\n=\n(1\nA\n-p)U(w0 -pA) + pU(wo -L + A -pA)\n∂E (U)\n=\np\nA\n-p(1\n∂\n-)U ′(w0 -pA) + p(1 -p)U ′(wo -L + A -pA) = 0.\n⇒\nU ′(w0 -pA) = U ′(wo -L + A -pA),\n⇒\nA = L,\nwhich implies that wealth is w0 -L in both states of the world (insurance claim or no claim).\n- A risk averse person will optimally buy full insurance if the insurance is actuarially fair.\n- Is the person better offfor buying this insurance? Absolutely. You can verify that expected\nutility rises with the purchase of insurance although expected wealth is unchanged.\n- You could solve for how much the consumer would be willing to pay for a given insurance\npolicy. Since insurance increases the consumer's welfare, s/he will be willing to pay some\npositive price in excess of the actuarially fair premium to defray risk.\n- What is the intuition for why consumers want full insurance?\n- The consumer is seeking to equate the marginal utility of wealth across states.\n- Why? For a risk averse consumer, the utility of average wealth is greater than the\naverage utility of wealth.\n- The consumer therefore wants to distribute wealth evenly across states of the world,\nrather than concentrate wealth in one state.\n- The consumer will attempt to maintain wealth at the same level in all states of the\nworld, assuming she can costlessly transfer wealth between states of the world (which\nis what actuarially fair insurance allows the consumer to do).\n- This is exactly analogous to convex indifference curves over consumption bundles.\n- Diminishing marginal rate of substitution across goods (which comes from diminishing\nmarginal utility of consumption) causes consumer's to want to diversify across goods\nrather than specialize in single goods.\n- Similarly, diminishing marginal utility of wealth causes consumers to wish to diversify\nwealth across possible states of the world rather than concentrate it in one state.\n- Q: How would the answer to the insurance problem change if the consumer were risk loving?\n\n- A: They would want to be at a corner solution where all risk is transferred to the least\nprobable state of the world, again holding constant expected wealth.\n2.1\nOperation of insurance: State contingent commodities\n- To see how risk preference generates demand for insurance, it is useful to think of insurance\nas a 'state contingent commodity,' a good that you buy in advance but only consume if a\nspecific state of the world arises.\n- Insurance is a state contingent commodity: when you buy insurance, you are buying a claim\non $1.00. This insurance is purchased before the state of the world is known. You can only\nmake the claim for the payout if the relevant state arises. Thus, you pay the insurance\ncompany regardless of whether or not you make a claim. The insurance company pays you\nonly if a bad outcome is realized (e.g., you have a car accident).\n- Previously, we've drawn indifference maps across goods X, Y . Now we will draw indifference\nmaps across states of the world: Good, Bad. You can equivalently think of Good and Bad\nas corresponding to no-accident and accident, respectively.\n- Consumers can use their endowment (equivalent to budget set) to shift wealth across states\nof the world via insurance, just like the budget set can be used to shift consumption across\ngoods X, Y .\n- Example: Two states of world, good and bad, with w0 = 120, p = 0.25, L = 80.\nwg\n=\nwb\n=\n120 -80\nPr(g)\n=\n(1 -p) = 0.75\nPr(b)\n=\np = 0.25\nE(w)\n=\n0.75(120) + .25(40) = 100\nE(u(w))\n<\nu(E(w)) if consumer is risk averse.\n\n- Let's say that this consumer can buy actuarially fair insurance. What will it sell for?\nDefinition 1. Actuarially fair insurance:\nThe price of the insurance policy exactly equals the expected monetary losses.\n- If you want $1.00 in Good state, this will sell at $0.75 prior to the state being revealed. The\nreason is that the good state will occur with 75% probability.\n- If you want $1.00 in Bad state, this will sell for $0.25 prior to the state being revealed because\nthe bad state will occur with 25% probability.\n- Note again that these prices reflect expected probabilities of making the claim. So, a risk\nneutral firm (say a central bank) could sell you insurance against bad states at a price of\n$0.25 on the dollar and insurance again good states (assuming you wanted to buy it) at a\nprice of $0.75 on the dollar.\n- The price ratio of payments in the Good state relative payments in the Bad state is therefore\nPg\nPb\n=\np\n= 3.\n(1 -p)\n- The set of fair trades among these states can be viewed as a 'budget set' and the slope of\nwhich is -\nP\n(1-P), and which passes through the initial endowment. Note that this slope is\nthe relatively probabilities of two states.\n\n- Now we need indifference curves\n- Recall that the utility of this lottery (the endowment) is:\nu(L) = pu(wg) + (1 -p)u(wb).\n- Along an indifference curve\ndU\n=\n0 = pu′(wg)dwg + (1 -p)u′(wb)dwb,\ndwb\npu′(w\n=\ndwg\n-\ng)\n< 0.\n(1 -p)u′(wb)\n- Provided that u() is concave, these indifference curves are bowed away from the origin in\nprobability space. [It can readily be proven that indifference curves are convex to origin by\ntaking second derivatives, but the intuition is straightforward.]\n- Flat indifference curves would indicate risk neutrality--because for risk neutral con-\nsumers, expected utility is linear in expected wealth.\n- Convex indifference curves mean that you must be compensated to bear risk.\n- i.e., if I gave you $133.33 in good state and 0 in bad state, you are strictly worse off\nthan getting $100 in each state, even though your expected wealth is\nE(w) = 0.75 · 133.33 + 0.25 · 0 = 100.\n- So, I would need to give you more than $133.33 in the good state to compensate for\nthis risk.\n- Bearing risk is psychically costly, so the consumer must be compensated to hold the\nmake them indifferent. (That is why the indifference curves are bowed away from the\norigin.)\n- Note that this implies that there are potential welfare improvements available from\nreducing risk if there were an inexpensive way to reduce it.\n- In the figure above, the movement from the lower (closer to the origin) to the upper indif-\nference curve is the gain from shedding risk.\n- Notice from the figure that, along the 450 line, wg = wb.\n\n- But if wg = wb, this implies that\ndwb\npu′(w\n=\ndwg\n-\ng)\np\n=\n(1 -p)u′(wb)\nPg\n=\n(1 -p)\n.\nPb\n- Hence, the indifference curve will be tangent to the budget set at exactly the point where\nwealth is equated across states. [This is an alternative way of demonstrating the results\nabove that a risk averse consumer will always fully insure if insurance is actuarially fair.]\n- This is a very strong restriction that is imposed by the expected utility property: The slope\nof the indifference curves in expected utility space must be tangent to the odds ratio.\nThe Market for Insurance\nNow consider how the market for insurance operates. If everyone is risk averse (and it's pretty safe\nto assume that most are), how can insurance exist at all? Who would sell it? There are actually\nthree distinct mechanisms by which insurance can operate: risk pooling, risk spreading and risk\ntransfer.\n3.1\nRisk pooling\nRisk pooling is the main mechanism underlying most private insurance markets. It applies the\nLaw of Large Numbers to defray risk--which is to say that it makes risk disappear.\n- As noted above, for any number of tosses n of a fair coin, the expected fraction of heads H\nis E(H) = 0.5n\nn\n= 0.5. But the variance around this expectation (equal to p(1-p))\nn\nis declining\nin the number of tosses:\nV (1)\n=\n0.25\nV (2)\n=\n0.125\nV (10)\n=\n0.025\nV (1, 000)\n=\n0.00025\n- We cannot predict the share of heads in one coin toss with any precision, but we can predict\nthe share of heads in 10, 000 coin tosses with considerable confidence. It will be vanishingly\nclose to 0.5.\n- Therefore, by pooling many independent risks, insurance companies can treat uncertain out-\ncomes as almost known.\n\n- So, \"risk pooling\" is a mechanism for providing insurance. It defrays the risk across indepen-\ndent events by exploiting the law of large numbers - making risk effectively disappear.\n3.1.1\nExample\n- Let's say that each year, there is a 1/250 chance that my house will burn down. If it does, I\nlose the entire $250, 000 house. The expected cost of a fire in my house each year is therefore\nabout $1, 000.\n- Given my risk aversion, it is costly in expected utility terms for me to bear this risk (i.e.,\nmuch more costly than simply reducing my wealth by $1, 000).\n- If 100, 000 owners of $250, 000 homes all put $1, 000 into the pool, this pool will collect $100\nmillion.\n- In expectation, 400 of us will lose our houses\n100,000 = 400\n\n.\n- The pool will therefore pay out approximately 250, 000·400 = $100 million and approximately\nbreak even.\n- Everyone who participated in this pool is better offto be relieved of the risk, though most\nwill pay $1, 000 the insurance premium and not lose their house.\n- However, there is still some risk that the pool will face a larger loss than the expected 1/400\nof the insured.\n- The law of large numbers says this variance gets vanishingly small if the pool is large and\nthe risks are independent. How small?\nPLoss(1\n)\nV Loss)\n=\n-PLoss\n(\n100, 000\n0.004(1 -0.004)\n= 3.984 × 10-8\nSD(Loss)\n=\n√\n3.984 × 10-8 = 0.0002\n- Using the fact that the binomial distribution is approximately normally distributed when n\nis large, this implies that:\nPr[Loss ∈(0.004 ± 1.96 · 0.0002)] = 0.95\n- So, there is a 95% chance that there will be somewhere between 361 and 439 losses, yielding\na cost per policy holder in 95% of cases of $924.50 to $1, 075.50.\n\n- Most of the risk is defrayed in this pool of 100, 000 policies.\n- And as n →inf, this risk entirely vanishes.\n- So, risk pooling generates a Pareto improvement (assuming we establish the insurance mech-\nanism before we know whose house will burn down). Everyone in this example is better off\nbuying the insurance.\n- In class, I will also show a numerical example based on simulation. Here, I've drawn in-\ndependent boolean variables, each with probability 1/250 of equalling one (representing a\nloss). I plot the frequency distribution of these draws for 1, 000 replications, while varying\nthe sample size (number of draws): 1, 000, 10, 000, 100, 000, 1, 000, 000, and 10, 000, 000.\n- This simulation shows that as the number of independent risks gets large (that is, the sample\nsize grows), the odds that the number of losses will be more than a few percentage points\nfrom the mean contracts dramatically.\n- With sample size 10, 000, 000, there is virtually no chance that the number of losses would\nexceed 1/250·N by more than a few percent. Hence, pooling of independent risks effectively\neliminates these risks - a Pareto improvement.\n\n3.2\nRisk spreading\n- Q: When does this 'pooling' mechanism above not work? When risks are not independent.\nPossible examples:\n- Earthquakes\n\n- Floods\n- Epidemics\n- When a catastrophic event is likely to affect many people simultaneously, it is (to some\nextent) non-diversifiable. This is why many catastrophes such as floods, nuclear war, etc.,\nare specifically not covered by insurance policies.\n- But does this mean there is no way to insured against these correlated risks?\n- Actually, we can still 'spread' risk providing that there are some people likely to be unaffected.\n- The basic idea here is that because of the concavity of the (risk averse) utility function,\ntaking a little bit of money away from each person incurs lower social costs than taking a lot\nof money from a few people.\n- Many risks cannot be covered by insurance companies, but the government can intercede by\ntransferring money among parties. Many examples:\n- Victims compensation fund for World Trade Center.\n- Medicaid and other types of catastrophic health insurance.\n- All kinds of disaster relief.\n- Many of these insurance \"policies\" are not even written until the disaster occurs--there was\nno market. But the government can still spread the risk to increase social welfare. Why\nis there no market? Because only those who are going to be affected are going to buy the\ninsurance, meaning that the private market cannot spread the risk. However, the government\ncan spread the risk, as people don't have to \"buy into\" the government transfer.\n- For example, imagine 10, 000 people, each with VNM utility function U(w) = ln (w) and\nwealth 100,000. Imagine that one of them experiences a loss of 50, 000. His utility loss is\nL = U (50, 000) -U (100, 000) = -0.693.\n- Now, instead consider if we took this loss and distributed it over the entire population:\nL = 10, 000 · [ln (99, 995) -ln (100, 000)] = -0.500.\nThe aggregate loss of -0.500 is considerably smaller than the individual loss of -0.693. This\ncomes from the concavity of the utility function.\n\n- Hence, risk spreading may improve social welfare, even if it does not defray the total amount\nof risk faced by society.\n- Does risk spreading offer a Pareto improvement? No, because we must take from some to\ngive to others.\n3.3\nRisk transfer\n- Third idea: if utility cost of risk is declining in wealth (constant absolute risk aversion for\nexample implies declining relative risk aversion), this means that less wealthy people could\npay more wealthy people to bear their risks and both parties would be better off.\n- Again, take the case where U (w) = ln (w). Imagine that an individual faces a 50 percent\nchance of losing $100, 000. What would this person pay to eliminate this risk? It will depend\non his or her initial wealth.\n- Assume that initial wealth is 200, 000. Hence, expected utility is\nU (L) = 0.5 ln 200, 000 + 0.5 ln 100, 000 = 11.86\nExpected wealth is $150, 000.\nThe certainty equivalent of this lottery is exp [11.86] =\n$141, 421. Hence, the consumer would be willing to pay up to $8, 579 to defray this risk.\nIn other words, she would be indifferent between having $141, 421 for sure and a 50/50\nchance of having either $200K or $100K.\n- Now consider a person with the identical utility function and facing the same possibility of\na $100K loss but who is much wealthier. Say her wealth is 2, 000, 000. Expected utility is\nu (L) = 0.5 ln 2, 000, 000 + 0.5 ln 1, 900, 000 = 14.45.\nExpected wealth is $1, 950, 000.\nThe certainty equivalent of this lottery is exp [14.45] =\n$1, 949, 359. Hence, this consumer would be willing to pay only $641 to avoid the lottery.\n- The wealthy consumer could fully insure the poor consumer at psychic cost $641 while the\npoor consumer would be willing to pay $8, 579 for this insurance. Any price that they can\nagree between ($641, $8, 579) represents a pure Pareto improvement.\n- Why does this form of risk transfer work? Because the logarithmic utility function exhibits\ndeclining absolute risk aversion--the wealthier someone is, the lower their psychic cost of\nbearing a fixed monetary amount of risk. Is this realistic? Quite likely. When you're a\n\nteenager and $20 falls out of a hole in your pocket and is gone for good, you feel completely\ncrushed. When you're an adult and $20 falls out of a hole in your Gucci briefcase, you think:\n\"Hey, it's only a transfer. And that reminds me: I've been meaning to buy a new Gucci\nbriefcase.\"\n- Example: Lloyds of London used to perform this risk transfer role:\n- It took on large, idiosyncratic risks: satellite launches, oil tanker transport, the Titanic.\n- These risks were not diversifiable in any meaningful sense.\n- But companies and individuals are willing to pay a great deal to defray them.\n- Lloyds pooled the wealth of British nobility and gentry ('names') to create a super-rich\nconsumer that in aggregate was much more risk tolerant than even the largest company.\n- For over a century, this idea generated large, steady inflows of cash for the 'names' that\nunderwrote the Lloyds' policies.\n- Then Lloyds took on asbestos liability...\n- [For a fascinating account of how Lloyds bankrupted the British nobility, have a look at\nthe 1993 New Yorker article by Julian Barnes, \"The Deficit Millionaires.\" This article\ndoesn't have much economic content, but it's gripping.]\nInsurance markets: Conclusion\nInsurance is potentially an extremely beneficial financial/economic institution, which can make\npeople better offat low or even zero aggregate cost (in the case of risk pooling). We'll discuss\nshortly why insurance markets do not work as well in reality as they might in theory. But they\nstill create enormous social value in the aggregate despite their imperfections.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.03/14.003 Fall 2016 Lecture 18 Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/cb7e0bce433fcd4bb79340c40fca89f6_MIT14_03F16_lec18.pdf",
      "content": "Lecture Note 18 - Two Applications of Risk and Safety\nRegulation: Airplane Seats for Infants and the Value of\na Statistical Life\nDavid Autor, MIT and NBER\nEstimating the Value of a Statistical Human Life: Ashen-\nfelter & Greenstone (2004 JPE)\n- The value of a statistical life (VSL) is a topic that makes non-economists uncomfortable.\nBut for policy analysis, there is no way around it. How much should society spend, at\nthe margin, to save a 'statistical life?'\n- A statistical life is a probabilistic concept. When we save a statistical life, we reduce\nthe number of deaths by one in expectation. The value of a statistical life (V SL) is\nclearly very different from what we would spend to save a specific individual who was in\ngrave danger of death. [And it is emphatically not the answer to the question, \"What\nwould I have to pay you to kill you?\" or \"What should we spend to save baby James\nwho was fallen down the well?\"]\n- It is critical to have some benchmark number for the Value of a Statistical Life (VSL)\nbecause we must frequently make societal decisions about how much risk we should\ntolerate, how much we should spend in tax revenue to avert risk, and how much we\nshould curtail freedom of choice to abate risk.\n- In general, economic reasoning suggests that society should undertake safety improve-\nments that cost less than the V SL per life saved and should not undertake safety\nprojects improvements cost more than the V SL per life saved.\n- But what is the correct VSL? There is no correct answer to the value of a statistical\nlife.\n\n- How do we get a credible estimate of the V SL? Not easy. Asking people will not\nbe very informative (plus they'll be horrified). But economic reasoning says that we\ncan observe the V SL from the trade-offs that people (or governments) actually make\nbetween cost and safety. The idea of measuring values by the observed trade-offs people\nmake, rather than by surveying them, is called revealed preference.\n- One reasonable approach is to ask how much money people are willing to pay in order\nto mitigate risk for themselves. Suppose that there is a 1% chance that the BU bridge\nwill collapse each year, killing all of the people currently driving, biking, or walking\nacross it. Assume that there are 100,000 people who use the bridge each year, and each\nwould be willing to pay $10 to reduce the probability of collapse each year from 1% to\nzero. It would be at least reasonable to assert that the government should reinforce the\nbridge if and only if the project costs less than $1 million (10, 000×$10). Otherwise, the\ngovernment is spending more in tax money on a project than its intended beneficiaries\nwould be willing to pay.\n- Speed limits are one place where this set of tradeoffs is most apparent. The faster\npeople drive, the less time they spend getting from place to place. Since time has\nvalue, going slower is costly in foregone opportunities. However, going faster increases\nthe probability of death.\n- (Side note: In some scenarios, people could value every extra minute they save at the\nexact same dollar amount for every speed. Setting risk aside, they might be indifferent\namong all speeds, so which speed they happened to pick doesn't tell us much about\ntheir preferences. In this particular scenario, however, Newtonian principles suggest\nthat they should still have a preferred rate of travel. Because the kinetic energy of a\nmoving body is E = 1\n2 × Mass × Velocity2, the expected fatality risk of an accident\nincreases quadratically with velocity whereas the time savings is linear in velocity.\nMoreover, accident risk per mile travel also increases with velocity. So if the value of\ntime is roughly constant on a per hour basis, then there's probably a unique solution\nwhere the cost of going 1 mph faster barely outweighs the benefit of doing so.)\n1.1\nContext of Ashenfelter & Greenstone (2004)\n- Prior to 1973, speed limits in the U.S. were set by states. There was no national speed\nlimit.\n- With the oil crisis in 1973, the federal government imposed a national speed limit of\n55 MPH.\n\n- Although this was probably not the intention, highway fatalities fell 15 percent the\nfollowing year (a reduction of nearly 10, 000 fatalities!).\n- (Side note: Fatalities were also trending downward before and after 1973. This in large\npart reflect advances in auto safety. Fatalities per 100 million miles in the U.S. are now\ntrending upward steeply. A moment's introspection will probably give you a strong\nhunch for why this is happening. Hint: you could look it up on your smartphone.)\n- In 1987, with oil prices low, the federal government allowed states to raise their speed\nlimits to 65 MPH if they wished to.\n- 37 states raised their speed limits in 1987 and 3 more did so in 1988.\n1.2\nResearch design\n- Though there is considerable technical material in this paper, the research design is\nstraightforward. The authors' goal is to estimate the public's willingness to pay for\nextra safety based on state legislatures' decisions on whether or not to adopt a higher\nspeed limit. If state governments act according to their constituents' preferences, then\nthe willingness of state governments to save drivers time but risk safety will reveal the\npublic's willingness to pay for reduced risk, which gives us a reasonable V SL.\n- The plan:\n1. Contrast the change in fatalities in adopting versus non-adopting states.\n2. Contrast the change in actual speeds traveled in adopting versus non-adopting\nstates.\n3. Use these two contrasts to develop an estimate of the hours saved in driving time\nper statistical life lost.\n4. Now, multiply time saved by some monetary value per hour to obtain an estimate\nof the V SL that state legislatures must have implicitly had in mind to justify\ntheir choices. To create a measure in dollars, Ashenfelter and Greenstone use the\nstate mean wage as the value of an hour saved. We can discuss whether this is\nappropriate.\n- A&G refer to their approach as an 'instrumental variables' estimation, and this is one\nvalid way to interpret it. After all, the adoption of the higher speed limit raises speed\n(the endogenous variable) and raises fatalities (the outcome variable) by raising speed\n\nbut probably does not affect fatalities through any channel other than speed. However,\nit's not a typical IV paper since the ultimate goal is not to find the effect of speed\non fatalities. Moreover, it is unlike our usual IV setup because the decision to 'take-\nup' the higher speed-limit is chosen by states--it is not randomly assigned as it is in\nconventional IV. So this research design does smell like an IV, but it offers a slight twist\non our regular IV approach.\n- The fact that states choose whether to adopt the higher speed limit is crucial for\ninterpreting the results through the lens of Revealed Preference. Revealed Preference\nallows us to say that any state that chose to take up the higher speed limit must have\nvalued the time savings at greater than or equal to the lives lost (otherwise, by Revealed\nPreference, it would not have made this choice). If this time savings was $1 million per\nlife lost, then the V SL could be no higher than $1 million.\n- For this design, it's actually important that not every state raised the limit... If\nthey had, we would be able to say that states are certainly willing to trade more\nrisk for more time, but we would not know whether states were barely willing to\ngive up safety for extra time, or very anxious to give up safety for extra time\n(and would raise the limit more if they could). Graphically, we could say that\nindifference curves between safety and time were pretty steep, but we could not\nactually pinpoint how steep they are (see Theoretical Framework below).\n- The notion of Revealed Preference was introduced and formalized by MIT faculty mem-\nber (now deceased) and Nobel laureate Paul Samuelson. Revealed preference says, in\nessence, that an agent A faces a choice between actions (or bundles) X and Y and\nshe chooses Y , then Y is revealed preferred to X for agent A. Though this argument\nappears both innocuous and trivial, it turns out to be neither.\n- There is also an important discussion in the paper of whether political decision mak-\ning about speed limits is efficient--that is, representative of constituents' preferences.\nIf the politics of raising the speed limit does not represent the preferences of con-\nstituents--perhaps it is determined by lobbying, or legislators are ignorant of the costs\nand benefits of raising speed limits-- then the decision tells us very little about con-\nstituents' revealed VSL. It's crucial to the interpretation to know whether:\n- Legislators roughly understood the trade-offs between time-savings and safety\nwhen deciding on the speed limit.\n\n- Legislators' choices roughly represent the preferences of 'typical' citizens (\"the me-\ndian voter\") rather than of some interest group that has very different preferences\nabout the V SL.\n- Why isn't it enough to assume that individuals optimally choose their speed as a\nfunction of time savings and safety?\n1.3\nTheoretical framework\n- States face a Production Possibility Frontier in Time Saved-Lives Saved space. They\nwant to choose their preferred point on this frontier. See the figures from class.\n- If the speed limit is capped at 55 MPH, states may not be able to select their optimal\npoint on the PPF. The 1987 law expands the feasible choice set.\n- For states that choose to move to the new location on the PPF, we can say that this\npoint is Revealed Preferred to the old location.\n- We can observe the gains they make in time savings and the loss of life as they make\nthis movement. That forms the basis for our calculations.\n1.4\nResults\nSee the attached slide deck for results.\nShould Infant Seats be Required on Airplanes?1\nThe U.S. National Transportation Safety Board (NTSB) has for many years been considering\na regulation whereby all children younger than two old would be required to travel in child\nsafety restraint systems (CSR) on airplanes. This rule would require adults to purchase seats\nspecifically for children younger than two years instead rather than allowing these children\nto travel in an adult's lap for free (which is the current regulation).\nConsider first: Assume that parents have full information about the risks of traveling with\ntheir babies on their laps. Is it socially efficient to allow parents to make a decision to buy a\nseat for their babies or should the government make it mandatory? That is, will parents made\n1This section draws on Newman, Thomas B., Brian D. Johnson and David C. Grossman. 2003. \"Effects\nand Costs of Requiring Child-Restraint Systems for Young Children Traveling on Commercial Airplanes.\"\nArchive of Pediatric & Adolescent Medicine, 137, October, 969-974. This article is posted on the 14.03/14.003\nweb site.\n\n'good' decisions, or is there a public policy argument for overruling their decisions through\nmandatory safety regulations? (Yet another way of saying this: is there a 'market' failure\nthat causes parents or airlines to provide a suboptimal amount of safety in the absence of a\nCSR mandate?)\nLet's for the moment assume that parents do not consider this risk for their children\n(e.g., perhaps they have no information about these risks). Our first goal is to assess whether\nmandating CSRs is worth the cost.\n- The NTSB calculates that there are 6.5 million 'enplanements' (plane trips) per year\nby children younger than age two.\n- It also calculates that the expected number of child fatalities averted per year by use\nof CSR is 0.4. Assume the price of an airline ticket for a child of $200 (and ignoring\nthe direct cost of the CSR).\n- What is the total cost per child airline fatality averted? Answer:\n(6, 500, 000 × $200) /0.4 = $3.25 billion per life saved\nSo, from a pure cost-benefit perspective, this does not appear attractive. If you believe\nthat saving one life is worth $3.25 billion, consider that you could save many more\nlives by spending $3.25 billion elsewhere, for example, by improving drinking water\nquality in the developing world or by building fences around backyard swimming pools\n(many more children die each year from accidental backyard drownings than from plane\ncrashes).\nHowever, this is not the end of the story. While CSRs may not be the most efficient way\nto save lives, at least they do save some lives, right? Actually, maybe not. CSRs may both\ncost a lot and kill people indirectly. Notice that the proposed CSR rule would also change\nincentives by making it more costly for parents with children to travel by air. How would\nyou expect families to respond?\n- Consider that some families will switch from air to car travel or vice versa depending\non the relative costs of the two. Newman et al. (2003) estimate that:\n- Approximately 6% of families with infants will choose to drive rather than pay\n$200 for a child seat on the plane. (This seems a conservative estimate.)\n- The average net increase in car travel per enplanement for families switching from\nplanes to cars is 300 miles.\n\n- The average vehicle occupancy for extra trips is 2.4.\n- Recent estimates of motor vehicle safety put the risk of auto deaths at 0.5 fatalities\nper 100 million vehicle miles traveled.\n- From these numbers, the estimated annual effect of the seat mandate on motor vehicle\ndeaths is:\n6, 500, 000 × 0.06 × 2.4\n\n× 0.\n+1\n!\n=\n.40 deaths\n, 000, 000\nIn words, the estimated number of additional motor vehicle deaths induced by the air\nsafety policy is roughly three and a half times as large as the number of airplane deaths\naverted. If we assume that more than 6% of families switch from plane to cars, the\npolicy looks even worse.\n- Now, if we want to consider total lives saved/lost from the CSR mandate, we need\nto also account for the deaths averted due to families not traveling by air. Recent\nestimates of the fatality risk from air travel (not car-seat avertible) are 117 deaths per\nbillion passenger journeys. So, the lives saved due to averted air travel (crash-related\n+ car-seat related) deaths are:\n-0.4 + 6, 500, 000 × 0.06 × 2.4 ×\n\n-\n!\n=\n51 deaths\n, 000, 000,\n-0.\n- In sum, this policy would be expected to increase total travel related fatalities by ap-\nproximately 0.9 per year at a cost of about 3 billion dollars. For this reason, the Federal\nAviation Administration [FAA] has so far resisted the NTSB's regulatory recommen-\ndation.\n- Not all supporters of the NTSB policy find this type of argument compelling. For\nexample, Ralph Nader and Wesley Clark in their 1994 book, Collision Course: The\nTruth about Airline Safety, write\n\"The argument in support of the FAA's resistance to the NTSB [National Transporta-\ntion Safety Board] recommended rule mandating child safety seats is unreasonable on\nits face, and ridiculous in its justification. It protects theoretical children driving in cars\nat the expense of real flesh-and-blood infants whose safety is unquestionably compro-\nmised when flown as a lap-baby [italics by Autor, not by authors].\"\n\n- A high ranking regulatory official in the Food and Drug Administration said of the\nchild seat policy and the statistics above that,\n\"It identifies a classic regulator's dilemma of which risks to protect against.\nWhile\nthe NTSB may well recognize that there could be more auto fatalities if they require\ncar seats, those fatalities will not be blamed on them. Assuming the study above is\naccurate, if the NTSB does the right thing from the point of view of mitigating \"total\nrisk,\" they face the prospect of getting all of the blame for allowing child fatalities on\naircraft and none of the credit for preventing child fatalities on the road. Of course,\nif the airlines wanted to provide seats for kids under age two at a nominal cost, they\nmight at least break even financially because parents would fly more and kids could fly\nsafely.\"\n- The attorney above recommends that airlines should subsidize infant tickets rather\nthan charge for them. For example, imagine that the FAA paid the $200 per seat so\nthat parents incurred no additional cost to travel with infants in CSR's. Would this\nmake the policy any more attractive from a cost-benefit perspective? It would still cost\n$3.25 billion per life saved. However, it would reduce the likelihood that parents of\ninfants would substitute towards auto travel, so it would at least eliminate the perverse\neffects of the policy.\n- Finally, just to flex our mental muscles a bit more, consider a policy where the FAA\ninstead paid parents $200 to travel with their children on their laps instead of driving\nin their cars? This policy appears perverse: it would surely increase the number of\ninfants killed in aircraft accidents! What would Ralph Nader say?\n- But, if this policy were feasible, it would be more efficient from a lives-saved-per-dollar\nperspective.\n- As we know, the chance of a carseat-avertable airplane fatality for an infant is\n0.4/6, 500, 000 per enplanement\n- The chance of an auto-fatality is 0.5/100, 000, 000 per mile.\n- The chance of an air-related fatality is 117 per billion enplanements.\n- We assume that there are 2.4 members of a family traveling together.\n- The crossover point where an airplane trips is safer than a car-trip (inclusive of\n\nnon-buckled infant deaths) is:\nM × 2.4 × 0.5\n100, 000, 000 >\n0.4\n6, 500, 500 +\n2.4 × 117\n⇒M >\n.5\n, 000, 000, 000\n- This means (very roughly) that any trip over roughly 30 miles, it is safer for a\nfamily with a lap child (without a CSR) to travel by air than by car. So, if we\nwant to minimize travel fatalities, we should pay people to fly rather than drive.\n- Finally, note that requiring CSRs on airplanes would still be a waste of money\nunder such a policy. We'd get more safety for the dollar by using that money to\nsubsidize more people to fly rather than drive.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "14.03 F16 Recitation 3 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/d4e4584aa59f983115c3f25cac411e6e_MIT14_03F16_Recitation3.pdf",
      "content": "Recitation 3: Consumer Theory and Food\nStamps\nChristina Patterson\n\nOutline For Recitation\n1. Review of Income and and Substitution effects and demand\ncurves\n2. Example Problem: In-Kind Transfers\n. Simple Problem: Choosing food expenditure subject to budget\nconstraint.\n. Policy 1: A tax credit for each unit of food\n. Policy 2: Food Stamps\n\nReview of Income and Substitution Effects and\nDemand Curves\nA\nC\nB\nx1\nx2\npo\npn\ndemand\nx1\nuo\nun\nBn\nBo\nA\nC\nB\nx1\nx2\npo\npn\ndemand\nx1\nuo\nun\nBn\nBo\nA\nC\nB\nx1\nx2\npo\npn\ndemand\nx1\nuo\nun\nBn\nBo\nA '\nC'\nB'\nA '\nB'\nC'\nC'\nB'\nA '\nA to B: substitution effect (SE)\nB to C: income effect (IE)\nA to C: price effect (PE)\nIE > 0\nIE < 0, PE = SE + IE > 0\nIE < 0, PE = SE + IE < 0\nDECOMPOSITION OF PRICE EFFECT INTO INCOME AND SUBSTITUTION EFFECTS\n$\n$\n$\n\nExample Problem - Setup\n- 2 \"goods\": Food (F ) and all other spending (G)\n- Income: $90\n- Price of Food = $1 per unit\n- Price of all of goods: $2 per unit\n- Consumer preferences are Cobb-Douglas and given by:\nU(F , G) = F 3\n1 G\n- How much F and G will the agent consume?\n\nPrimal Problem: Choosing F and G to maximize utility,\nsubject to Budget Constraint\n- Budget Constraint: PGG + PF F = I or F + 2G = 90.\n- Lagrangian is:\nL = F 3\n1 G 3\n2 + λ(I - PF F - PGG)\n- Handy Trick - apply monotone transformation (i.e. take logs).\n- 3 first order conditions (with respect to F , G and λ)\n∂L\n=\n- PF λ = 0\n∂F\n3F\n∂L\n=\n- PGλ = 0\n∂G\n3G\n∂L = I - PF F - PGG = 0\n∂λ\nI\n2I\n∗\n→ F =\n= 30\nG∗ =\n= 30\n3PF\n3PG\n- These are the Marshallian demands\n\nIndirect Utility and the \"Dual\" Problem\n- Indirect Utility: Utility consumer can attain given a budget and\nprices\n\n∗\nU(F , G∗ ) =\n= 30\n- The dual is to minimize expenditure in order to attain a given\nutility level\n\nL = PF F + PGG + λ 30 - F 3\n1 G\n- 3 first order conditions (with respect to F , G and λ)\n∂L\nλ\n= PF -\n= 0 → λ = 3FPF\n∂F\n3F\n∂L\n2λ\n3GPG\nGPG\n= PG -\n= 0 → λ =\n→ F =\n∂G\n3G\n2PF\n∂L = 30 - F 3\n1 G 3\n2 = 0\n∂λ\n\nPG\n2PF\n∗\nG∗\n→ Fh = 30\n2PF\n= 30\nh = 30\nPG\n= 30\n\nPolicy 1: Tax subsidy for Food Spending\n- A subsidy of 0.50 for each dollar spent on food for these\nhouseholds.\n- Budget constraint becomes:\n1 -\nF + 2G = 90\n- Two questions:\n1. What are they going to consume now?\nWhat change comes from the substitution effect?\nWhat change comes from the income effect?\n2. What lump sum of income could we have given them such that they\nare indifferent between the lump sum and this subsidy?\n\nPrimal Problem: What are they going to consume\nnow?\n- Lagrangian is:\nL = F\n3 G\n2 + λ 90 - F - 2G\n- FOCs are:\n∂L\n=\n- λ = 0\n∂F\n3F\n∂L\n=\n- 2λ = 0\n∂G\n3G\n∂L\n= 90 - F - 2G = 0\n∂λ\n∗\n→ F = 60\nG∗ = 30\nτ\nτ\n\nPrimal Problem: What part of this change comes from\nthe substitution effect?\n- Note that we just moved along the Marshallian (uncompensated)\ndemand curve above.\n- The substitution effect comes from moving along the Hicksian\n(compensated) demand curve.\n∗\nFτ,SE only = 30\nPG\n2PF\n= 47.6\nG∗\nτ,SE only = 30 2PF\nPG\n= 23.8\n- The different between the two answers is the income effect! It\nincrease your consumption of both.\n\nDual Problem: What lump-sum transfer could we give\nthem so that they are indifferent?\n- What utility level do they achieve with the tax subsidy?\n∗\nU(Fτ , G∗ ) = 60\n1 × 30\n2 ≈ 37.8\nτ\n- So, now we want to find the income they would need to get this\nutility at the pre-subsidy prices. We can do this using the indirect\nutility function:\nIlump sum\nIlump sum\nU(1, 2, I) =\n= 37.8\n→ Ilump sum = 113.4\n- Therefore, they need 113.4 - 90 = $23.4 to make them\nindifferent.\n- With the subsidy, the government paid 0.50 ∗ 60 = 30 > 23.4!\n\nWhy is the lump-sum transfer cheaper?\n- Why do you have to give them less? Because they have\ndiminishing MRS!\n113.4\n∗\nF\n=\n= 37.8\nlump sum\n113.4\nG∗\n=\n= 37.8\nlump sum\n\nPolicy 2: Food Stamps\n- What does the budget constraint look like with food stamps?\n- Who is indifferent between food stamps and a lump-sum\ntransfer?\n- Who prefers a lump sum transfer to food stamps?\n- Who prefers food stamps to a lump sum transfer?\n- What would the budget set look like if you could sell food stamps\non the black market for half their value?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "14.03 F16 Recitation 5: General Equilibrium Practice Problem",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/427890084831bb4697177e2eb4d4cfe5_MIT14_03F16_Recitation5a.pdf",
      "content": "14.03/14.003 Recitation 5: General Equilibrium Practice\nProblem\nOctober 21, 2016\nConsider an economy with two goods - X and Y - and two agents - Ann and Bob. Ann\nand Bob wish to trade with one another in order to maximize their individual utilities.\nWe will consider how their trading decisions depend on the initial endowments of X and\nY and on their utility functions.\nSuppose Ann is endowed with one unit of X and half a unit of Y i.e. eAnn = (1, 1\n2)\nand Bob is endowed with 1 unit of X and 1.5 units of Y i.e. eBob = (1, 3\n2) . Additionally,\nsuppose their utility functions are given by:\nUAnn(X, Y ) = XY\nUBob(X, Y ) = Y + 2X\nDraw an Edgeworth box indicating the endowment and pref\nerences of this problem. A square with multiple diagonal lines, called an Edgeworth box that has two goods x and y and two agents, Ann and Bob.\nA sq\nu\na\nre\nwit\nh\n\nmult\ni\np\nle\ndia\ng\nona\nl lines, called an Edgeworth box that has two goods x and y and two agents, Ann and Bob.\nImage by MIT OpenCourseWare.\n\nFind the set of Pareto Optimal Allocations in this economy\nand depict these in the Edgeworth box. What is this set of\npoints called?\n- The contract curve is the set of points such that by moving away from these allocations, at least\none of the individuals are made worse off.\n- Visually, this is given by the set of tangencies of the consumer utility functions. The these\ntangencies, the consumers have the same MRS between X and Y .\n- The MRS is defined as ∂U/∂X . For Ann, this is Y . For Bob, this is 2. Therefore, the set of all\n∂U/∂Y\nX\npoints where the MRS are equal are given by\nYAnn = 2 → YAnn = 2XAnn\nXAnn\n- Note, however, that in this economy, there are only 2 units of X and 2 units of Y , therefore, this\nequation cannot hold when XAnn > 1. When XAnn > 1, the contract curve is just going to be\non the top edge of the box. A square with multiple diagonal lines, called an Edgeworth box that has two goods x and y and two agents, Ann and Bob.\nFind the equilibrium consumption of X and Y by Ann and\nBob in this economy and determine the price ratio that sup\nports this equilibrium\n- The competitive equilibrium allocation in this economy will satisfy 2 conditions:\n1. Both Ann and Bob are maximizing their utility subject to their budget constraint\n2. The final allocations of X and Y satisfy the resource constraint (i.e. they do not add up to\nmore than 2)\nA square\nwith\nmul\ntip\nle\ndiag\no\nn\nal\nlin\ne\ns\n,\n\nc\nall\ned an Edgeworth box that has two goods x and y and two agents, Ann and Bob.\nImage by MIT OpenCourseWare.\n\n- We begin with the first condition, that the individuals maximize their utility subject to their\nbudget constraint. Note that in this case, their budget constraint is given not by their exogenously\ndetermined income I but rather by the combination of their endowment and the prices. In other\nwords, their income is determined by the amount they would have if they sold their entire\nendowment at the given prices. Note that this means that their income changes as the price\nchanges. The Lagrangian for Ann's problem is therefore given by:\nEAnn + PY EAnn\nL = XAnnYAnn + λ(Px\nX\nY\n- PxXAnn - PyYAnn)\nL = XAnnYAnn + λ(Px + PY\n- PxXAnn - PyYAnn)\n- All that matters in this setting is the relative price (NOT the price level). Therefore, it is going\nto be very helpful to normalize one of the prices to 1. Let's choose PX = 1. The solution to this\nLagrangian will yield Ann's marshallian demands for good X and Y .\n∂L\n= YAnn - λ = 0\n∂XAnn\n∂L\n= XAnn - λPY = 0\n∂YAnn\n∂L\n= 1 + PY\n- XAnn - PY YAnn = 0\n∂λ\n- Solving these three equations for YAnn and XAnn, we get:\n2 + PY\nXAnn =\n2 + PY\nYAnn = 4PY\n- Similarly for Bob, we have\nEBob + PY EBob\nL = YBob + 2XBob + λ(Px\nX\nY\n- PxXBob - PY YBob)\nor\nL = YBob + 2XBob + λ(1 + PY\n- XBob - PY YBob)\n∂L\n= 2 - λ = 0\n∂XBob\n∂L\n= 1 - λPY = 0\n∂YBob\n∂L\n= 1 + PY\n- XBob - PY YBob = 0\n∂λ\nSolving these, we get:\nPY = 2\nand\nXBob + PY YBob = 1 + PY\n\n- Lastly, we use the second equilibrium condition (i.e. the resource constraints) to pin down the\nconsumption bundles and the relative prices.\nXAnn + XBob = 2\nYAnn + YBob = 2\n- Plugging all this in, we finally get:\nPY\n=\nPX\nXAnn =\n, YAnn =\nXBob =\n, YBob =\n- Note, that PY (which is the relative price of good Y and X) clears both the market for X and\nthe market for Y. This result is called Walras' law, which stipulates that if n-1 markets clear,\nthe other market will definitely clear as well.\n4 Will this equilibrium allocation be Pareto Efficient?\n- Yes, and we can show this two ways. First, we can show that it is on the contract curve. Note\nthat we found in part 2 that the contract curve is defined by\nYAnn = 2XAnn\nand 5 ∗2 = 10 . We can also show this without any math using the first welfare theorem. The first\nwelfare theorem states that as long as certain conditions are satisfied, a competitive equilibrium\nis pareto efficient. The conditions are:\n- No transaction costs\n- No market power\n- No externalities\n- Full information\n- Since the problem assumes that these assumptions are satisfied in our setting, we can conclude\nthat the competitive equilibrium allocation is pareto efficient.\n5 Show that there are gains from trade in this setting. From\nwhat endowment point would there not be gains from trade?\n- There are gains from trade when the individuals are able to achieve higher utility levels after the\ntrade than before the trade. We can easily see this in the figure, and we can also calculate the\nutility for each consumer at their endowment point and their equilibrium point.\nUAnn(eX , eY ) =\n, UAnn(XAnn, YAnn) =\nUBob(eX , eY ) =\n, UBob(XBob, YBob) =\n=\nNote that in this scenario, Ann benefits from the trade and Bob is indifferent. This is because\nof the shape of his indifference curve!\n\n6 Suppose that instead of the preferences above, UB(X, Y ) =\nX2Y 2 . How does this change the equilibrium consumption\nthat you found in part 3? What is the intuition for this?\n- In this case, Bob's Lagrangian becomes\nL = 2log(XBob) + 2log(YBob) + λ(1 + PY\n- XBob - PY YBob)\n∂L\n=\n- λ = 0\n∂XBob\nXBob\n∂L\n=\n- λPY = 0\n∂YBob\nYBob\n∂L\n= 1 + PY\n- XBob - PY YBob = 0\n∂λ\nThis yields the following Marshallian demands:\n1 + 3\n2PY\nYBob =\n2PY\n1 + 3\n2PY\nXBob =\nPlugging these into the resource constraint, we get:\n1 + 3\n2PY\n2 + PY\nYAnn + YBob = 2 →\n+\n= 2\n2PY\n4PY\nPY = 1\nPlugging this in, we get:\nXAnn = 4 , YAnn = 4\nXBob = 4 , YBob = 4\n- Note that in this case, the allocations are equal! Why? Because they both have the same\npreferences and value X and Y equally. What will the contract curve be in this picture? It will\nbe the 45 degree line.\n- In the previous case, Bob had a really strong preference for X relative to Y and therefore, Y is\nrelatively cheap (in the previous case, PY , which is the relative price of Y , is 1\n2, but in this case,\nthe relative price of Y is 1.\nGo back to the original preferences of the problem. Suppose\nthe government decides that the competitive equilibrium is\nnot a good allocation and they would prefer for Ann to con\nsume (3 , ) and Bob to consume (5 , ). Is this a competitive\nequilibrium? Is it attainable from the initial endowment?\nWhy or why not?\n- This is a competitive equilibrium as long as it is on the contract curve. We derived above that\nthe contract curve is defined by YAnn = 2XAnn and we can see that this is the case with this\nallocation. Therefore, it is a competitive equilibrium.\n\n- If we compare the utilities the Ann and Bob get at this allocation to the utilities that they get\nat their initial endowments, we can see that Ann is better off and Bob is worse off.\n3 3\nUAnn(eX , ey ) =\n<\n= UAnn( , )\n4 2\n5 1\nUBob(eX , ey ) =\n< 3 = UBob( , )\n4 2\n- However, this equilibrium is not attainable from this original endowment. At the equilibrium\nprices (PY = 1\n2), Ann cannot afford to consume this bundle. Her endowment is worth 5 but the\ndesired bundle costs 6\n4.\nSuppose that the government can announce that PY =\n.\nWould this achieve the government's desired bundle?\n- No, this would not. At the price PY = 1\n4, Ann is now able to afford the bundle that the\ngovernment wants her to consume, since at this price, the new bundle costs 3\n= 9 and her\n+\nendowment is also worth 1 +\n= .\n- However, this will not be supported in equilibrium. This is because at these prices, Ann and Bob\nwill not want to consume this bundle. We can see this by looking at their demand functions and\nplugging in PY = 1\n4.\n2 + PY\nXAnn =\n=\n2 + PY\nYAnn =\n=\n4PY\n- Bob is going to be at the corner of the box - the first order conditions that determine his demand\nare not satisfied when PY = 1\n4 and therefore, he is going to go to a cornder at the box. Now that\ngood Y is so cheap, his demand for it is insatiable, so he will demand as much of it as he can\n(and he will go to the cornder with YBob = 2. Then, the amount of X he can get is determined\nby his budget constraint, yielding XBob = 7\nCould the government achieve its objectives through lump\nsum redistribution? If so, how should it redistribute to achieve\nits desired bundle?\n- Yes! The government can achieve this allocation through lump sum redistribution. We showed\nbefore that all of the points on the contract curve were pareto efficient allocations, and we also\nshowed that this is a bundle on the contract curve. Therefore, the second welfare theorem says\nthat this can be achieved beginning at some endowment.\n- What should they redistribute? One possibility is for them to directly redistribute so that the\nagents start at the desired bundle. They are on the contract curve at this point, so even when\nthey are allowed to trade, they will not (because there are no mutually beneficial trades left).\nHowever, you could also move them to any other point on the line that goes through the desired\npoint on the contract curve and has a slope of 1\n2 (i.e. the market equilibrium price)\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "14.03 F16 Recitation Practice Problems",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/f482ae7a0e5872cd03aa91f3a12c47e8_MIT14_03F16_RecProb.pdf",
      "content": "Recitation Practice Problems: Solutions\nChristina Patterson\nTheory of Insurance Markets\nThe houses in the mountain-top town of Conway are at constant risk of lightning strike. Each of the\n100 residents of Conway has a 1 in 100 chance of having his or her house ever struck by lightening. Each\nlightening strike does $50,000 in damage. Lightening strikes are independent events, and lightening\nonly damages the houses it directly hits. Each resident of Conway is a risk averse expected utility\nmaximizer, with utility of wealth U (W ) = ln W . In addition to his or her $50,000 house, each resident\nhas $100,000 in wealth.\n1. Without insurance, what is the expected wealth of residents in Conway? What is the certainty\nequivalent of wealth for the residents of Conway?\n- The expected wealth of the residents in Conway is given by:\nE[w] = 0.99(150, 000) + 0.01(100, 000) = 149, 500\n- The expected utility of the residents in Conway is given by:\nE[u(w)] = 0.99ln(150, 000) + 0.01ln(100, 000) = 11.9143\n- The certainty equivalent is the amount of guaranteed wealth that makes the consumer indifference\nbetween the current risky situation and the certain income. This is given by\n11.91 = ln(CE) → CE = 149, 393\n- Note that since the residents of Conway are risk averse, the CE is below the expected wealth.\n1. Suppose that 2 of the residents of Conway are in one family, and they decide to form a mutual\ninsurance company. They agree to fully share the cost of rebuilding each house struck by light\nning. Are the members of this family better off as a result of this plan? What insurance principle\nis operative?\n- If n residents join the mutual insurance company, they will each pay 50,000k , where k is the\nn\nnumber of houses that are struck.\n- If 1 of their houses are struck, they will pay 50,000 = 25, 000. If 2 houses are struck, they will\neach pay 50, 000\n- Each person in the co-op has a 1% change of being struck, so there is a 100 ∗\n∗\n= 0.01\npercent change that they both get struck, a 100 ∗\n∗\n∗ 2 = 1.98 percent chance that one of\nthe two get struck, and a 100 ∗ ( 99 )2 =98.01% chance that none of them get struck\n\n- Each family member, therefore, has an expected wealth of:\nE[w] = 0.9801(150, 000) + .0198(125000) + 0.0001(100, 000) = 149500\n- Each family member has an expected utility of\nE[U] = 0.9801ln(150, 000) + .0198ln(125000) + 0.0001ln(100, 000) = 11.9147\n- The certainty equivalent of this gamble is 149, 453, which is slightly more than in autarky. So\nthey weakly prefer this, even with only 2 people!\n1. Should the family open up the mutual insurance plan to all other residents in the village?\n- Suppose now that everyone in the village could buy the insurance - in this case, each member\nwould pay 50,000k , where k is the number of houses that are struck. If 1 house is struck, they will\npay $500, if 2 are struck, they will pay $1, 000, etc.\n)100\n- The probability that no houses are struck is ( 99\n= 0.366. The chance that only 1 house is\n)99( 1\nstruck is ( 99\n) ∗ 100 = 0.369, in which case you pay $500. The probability that 2 houses\n)98( 1\nare struck is ( 99\n)2 ∗ 4950 = 0.1848, in which case you pay $1000. The probability that 3\n)98( 1\nhouses are struck is ( 99\n)2 ∗ 161700 = 0.0609, and so on....\n- You can see here that there is a significant chance that you have to pay something higher than\n$500, but there is a very tiny chance you have to pay the full loss yourself.\n- The expected wealth of the arrangement is\nE[w] = 0.366∗150000+0.369∗149500+0.1848∗149000+0.0609∗148500+...+10-20∗100000 = 149500\n(take my word for it!)\n- However, since the utility function is concave, this is going to yield a higher utility than the\n2-person insurance scheme. This is the power of risk-pooling - you increase the probability you\nhave to pay something to decrease the probability you have to pay a lot.\n1. State Farm insurance decides to offer actuarily fair insurance to the residents of Conway. What\nprice do they charge for the insurance? Would the residents of Conway prefer to buy the State\nFarm insurance (i.e. do they prefer it to their mutual insurance company)?\n- Actuarily fair insurance is priced at the probability that each individual house is struck,\ntimes the loss if it is struck, which in this case is $500.\n- This is very similar to the case above, except that there is now a 0 probability that you\nhave to pay anything higher than $500 and a 100 percent change that you have to pay $500.\nThese is NO risk in this case.\n- The expected wealth is\nE[w] = 149500\n- Since there is no risk, and they are risk averse, they prefer this!\n- This is an example of risk transfer (from the town to the insurance company)\n2. Consider, instead, the case where there is a 1% change that a really bad storm will come and\nstrike all of the houses in Conway at once. Will the mutual insurance plan in part (3) be welfare\nimproving in this case?\n- No, they can no longer pool risk because they are all facing exactly the same aggregate risk.\n\nRegression Discontinuity\nA key policy question is whether the benefits of additional medical expenditures exceed their costs. The\ntendency for patients in worse health to receive more medical inputs complicates empirical estimation\nof the returns to medical expenditures Almond, Dyle, Kowalski, and Williams (2010) study this by\nlooking at the health outcomes for newborn babies. Hospitals classify babies as \"very low birth weight\"\nwhen they are just under 1500 g, and use the classification to trigger additional treatment (NICU\nstays, diagnostic ultrasounds, etc.). They are able to see a baby's birth weight as well as whether\nthey lived through their first year. They would like to know what the causal effect of this additional\ntreatment is on health outcomes.\n1. How would you set up a regression discontinuity design in this setting?\n- You would look at the health outcomes (i.e. survival probabilities) of babies with birth weights\naround the cutoff. Right around the cutoff of 1,500 grams, babis should differ only in their\nprobabilities of receiving additional health treatments and not in their underlying health.\n2. Doctors tell you that a baby's survival probability is increasing in its birth weight (i.e. babies\nborn at 4 pounds are more likely to survive than babies born at 3.7 pounds, regardless of the\nmedical treatment they receive). Is this a problem for your design?\n- In this case, it is going to be important to control for the birth weight of the baby, but it is\nnot a problem for the research design. In fact, we can even allow for there to be a different\nslope (i.e. relationship between birth weight and health outcomes) on either side of the line.\n- If we did not take this trend into account, we would be underestimating the effect of the\nmedical treatment. Babies on the left of the threshold are more likely to die in their first\nyear in the absence of the treatment (call this effect x). If we didn't separately control for\nthat effect, we would estimate y = z + x, where z is the true treatment. Since x is negative,\ny would be less than z.\n3. Nurses know about the additional procedures conducted when the baby just under 1,500 grams.\nWould it be a problem if some nurses mis-recorded some babies' birth weights to get them just\ninto the \"very low birth weight\" category?\n- Yes, this could be a problem for us. We are making the assumption that babies on the left and\nright side of the threshold are the same other than the medical treatment that they receive\nin the first year. If, for example, nurses are more likely to do this when the parents are very\ninformed and agressive, and aggressive and informed parents also are better and following\nup on other care within the first year (i.e. taking medications, bringing them in for follow\nup visits, etc.), then the babies on the left of the threshold would differ from the babies on\nthe right of the threshold in more ways than just their treatment. This would invalidate the\ndesign.\n- Note that if the mis-recording was entirely random, that would be okay.\n4. Suppose you find that being just classified as \"very low birth weight\" causally increases the\nbaby's medical costs increase $4000 and increases the probability that she lives by 1%. You\nconclude, given reasonable estimates of the VSL for this population, that the benefit to this\nadditional spending outweighs the cost. Should you recommend that hospitals give all babies\nthis additional medical treatment?\n- Note that the RD estimate is a local estimate, meaning that it s the causal estimate of\nmedical treatment for babies at a birth weight of 1,500 grams. It is likely in this case the\ncausal effect of this medical treatment is lower for babies with a higher birth weight (for\nexample, precautionary ultrasounds are less likely to catch things in healthier birth weight\n\nbabies). Therefore, you sould not generalize your estimated causal effect to the general\npopulation.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "14.03 Fall 2016 Recitation 1 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/1821d52b5dcdbf9a755422d837072483_MIT14_03F16_Recitation1.pdf",
      "content": "Recitation 1: Regression Review\nChristina Patterson\n\nOutline For Recitation\n1. Statistics\n. Bias, sampling variance and hypothesis testing.\n. Two important statistical theorems: Law of large numbers (LLN)\nand Central Limit Theorem (CLT)\n2. Simple Regression\n. The mechanics of Ordinary Least Squares (OLS) regression:\ncoefficients, and standard errors\n3. Multiple Regression\n. The mechanics of multiple regression: interpretations and dummy\nvariables.\n\nStatistics: Distribution of Wage and Salary Earnings\n.005\n.01\n.015\n.02\nFreequency\nAnnual Wage and Salary ($1000)\n\nStatistics: Basic Definitions\n- Population mean: E[xi ]\n. We cannot observe this\n. this is called a parameter\nN\nx\n- Sample mean:\n= N\ni=1 xi\n. We can calculate this: $34, 945\n. this is called a sample statistic and it is an estimator of E[xi ]\n- A statistic is unbiased when E[\nE\n] = [ ]\nx\nxi\n\nStatistics: Variance\n- It's important to distinguish between two types of variance:\n1. Population Variance: Underlying variation in earnings in the\npopulation\n\nVar (xi ) = E (xi - E[xi ])2 = σx\n2. Sampling Variance: The variance of the sample mean (i.e. if I kept\ndrawing samples, how much would the sample mean vary?)\n\nN\nN\nσ2\nx\nVar(x ) = Var\nxi\n=\nN\nn\ni=1\n- Note that as n → inf, the sampling variance goes to 0\n- This is the result of the Law of Large Numbers, which is a\ntheorem that states that in sufficiently large samples, the sample\naverage converges to the expected value.\n\nStatistics: Hypothesis Testing\n- Suppose you want to test the hypothesis that the average\nearnings in the population are 40, 000 , i.e. E[x] = 40, 000.\n- The idea is that if you had thousands of different samples of\nindividual and you calculated the mean earnings in each of those\nsamples, those means would be normally distributed even if the\ndistribution of incomes in the population is very non-normal\n(which in fact it is)\n\nThe Power of the Central Limit Theorem (1 draw)\n.2\n.4\n.6\n.8\nFreequency\nAnnual Wage and Salary ($1000)\n\nThe Power of the Central Limit Theorem (10 draws)\n.1\n.2\n.3\n.4\n.5\nFreequency\nAnnual Wage and Salary ($1000)\n\nThe Power of the Central Limit Theorem (100 draws)\n.2\n.4\n.6\nFreequency\nAnnual Wage and Salary ($1000)\n\nThe Power of the Central Limit Theorem (5000 draws)\n.1\n.2\n.3\n.4\n.5\nFreequency\nAnnual Wage and Salary ($1000)\n\nASIDE: The Normal Distribution\n\nStatistics: The Power of the Central Limit Theorem\n- In practice, we construct a t-statistic:\nx - 40, 000\nt40,000 =\nVar(x )\n- The t-statistic is far above 2 or below -2 when the observed\naverage is sufficiently far from our hypothesized value.\n- In this case:\n34.945 - 40\nt40,000 =\n= -14.2\n.356\n\nSimple Regression\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\n\nTwo Variables: Mechanics of OLS Regression\nincome = 3.47 + 2.77 * educ\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\n\nTwo Variables: Mechanics of OLS Regression\nAnnual Wage and Salary ($1000)\nYears of Education\nFitted Values\n-50\nAnnual Wage and Salary ($1000)\nYears of Education\nResiduals\nˆ\n= aˆ + ˆ\n- Fitted values (left plot): incomei\nbeduci\nˆ\n- Residuals (right plot): ei = incomei - incomei\n\nTwo Variables: OLS standard errors\n- Suppose I want to test the hypothesis that income increases with\neducation (i.e. β > 0)\n- This involves calculating the standard error of the estimated\ncoefficient βˆ:\nσe 1\nS.e.(βˆ) = √ n σx\n. Increasing in the variance of the residuals (σe).\n. Decreasing in sample size (n)\n. Decreasing in the variance of the regressor (σx ).\n\nOLS standard errors are increasing in the varaince of\nthe residuals\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\n\nOLS standard errors are decreasing in the variance of\nthe regressor\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\n\nOLS standard errors are decreasing in the number of\nobservations\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\n\nHypothesis Testing\n- Like in the one variable case, we can construct a t-statistic:\nˆβ - 0\nt0 =\ns.e.(βˆ)\n(1)\nwage\nYears of School (b)\nConstant (a)\n2.772**\n(1.135)\n3.469\n(13.80)\nObservations\nR-squared\n0.024\nStandard errors in parentheses\n*** p<0.01, ** p<0.05, * p<0.1\n\nMultivariate Regression\n- Supposed we want to add another variable - whether the worker\nis self-employed.\n(1)\nwage\nYears of School (b1)\nSelf Employed (b2)\nConstant (a)\n3.278***\n(1.009)\n-28.01***\n(3.426)\n5.364\n(12.25)\nObservations\nR-squared\n0.235\nStandard errors in parentheses\n*** p<0.01, ** p<0.05, * p<0.1\n\nMultivariate Regression\nAnnual Wage and Salary ($1000)\nYears of Education\nWages of Male Construction Workers vs. Education\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "14.03 Fall 2016 Recitation 2 Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-03-microeconomic-theory-and-public-policy-fall-2016/cf5cd26b66620645d43d97cbba8513ad_MIT14_03F16_Recitation2.pdf",
      "content": "Recitation 2: Merging Counterfactuals and Regressions\nColin Gray\n14.03/14.003, Fall 2016\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n1 / 25\n\nOutline\nTreatment Effects\nDifference-in-Differences (DD)\nTreatment Effects in a Regression\n4 DD in a Regression\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n2 / 25\n\nTreatment Effects\nOutline\nTreatment Effects\nDifference-in-Differences (DD)\nTreatment Effects in a Regression\n4 DD in a Regression\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n3/ 25\n\nTreatment Effects\nSo what's the deal with all these subscripts?\nSubscript i denotes a unit of observation (individual, household, zip\ncode, state, etc)\nDefine Yi1 as the outcome Y if unit i received \"treatment\", and Yi0\nas the outcome Y if unit i did not receive treatment.\nThis has nothing to do with whether unit i actually did receive the\ntreatment! It's a counterfactual.\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n4 / 25\n\nTreatment Effects\nWhat we can see, and what we can't see.\nIt turns out that expectations and averages are really mathematically\nconvenient. We sometimes use other properties of the data (e.g.\nmedians).\nWhat does E [Yi0|Xi = 1] mean?\nWhat about E [Yi0|Xi = 0], E [Yi1|Xi = 0], or E [Yi1|Xi = 1]? Which\ncan we estimate from the data with no further assumptions?\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n5/ 25\n\nTreatment Effects\nThe problem with \"naive\" observation.\nWe often want to know E[Yi1 - Yi0|Xi = 1]. Why?\nOne natural first try is to estimate expectations E [] by calculating\naverages, and then plugging them into the following expression:\nE [Yi1|Xi = 1] - E [Yi0|Xi = 0]\n\n= E [Yi1|Xi = 1] - E [Yi0|Xi = 1]\n\n+ E [Yi0|Xi = 1] - E [Yi0|Xi = 0]\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n6 / 25\n\nTreatment Effects\nHow to get around bias.\nWe can randomize. What does that do?\nE [Yi0|Xi = 1] = E [Yi0|Xi = 0]\n⇒ E[Yi1|Xi = 1] - E [Yi0|Xi = 0] = E [Yi1 - Yi0|Xi = 1]\nWhen we can't randomize, we look for a control group in which we\nbelieve that E [Yi0|Xi = 1] = E [Yi0|Xi = 0].\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n7 / 25\n\nDifference-in-Differences (DD)\nOutline\nTreatment Effects\nDifference-in-Differences (DD)\nTreatment Effects in a Regression\n4 DD in a Regression\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n8 / 25\n\nDifference-in-Differences (DD)\nWhen we can't observe everything about a group.\nIt's often infeasible to randomize and unreasonable to think that our\ncontrol group and treatment group are really that similar, so we\nprobably don't believe that\nE [Yi0|Xi = 0] = E [Yi1|Xi = 0]\nWhat if we instead assume that our treatment and control groups\ndon't have the same E [Yi0], but do follow the same counterfactual\ntrends?\nNow we add the time dimension, so Yi0 turns into Yit0. We express\nour new assumption as:\nE [Yi10|Xi = 1] - E [Yi00|Xi = 1] = E [Yi10|Xi = 0] - E [Yi00|Xi = 0]\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n9 / 25\n\nDifference-in-Differences (DD)\nDD to the rescue!\nNow we want the effect of the treatment in period 1:\nE [Yi11|Xi = 1] - E [Yi10|Xi = 1]\nCheck this out...\nE [Yi11|Xi = 1] - E [Yi00|Xi = 1] -\nE [Yi10|Xi = 0] - E [Yi00|Xi = 0]\n= E [Yi11|Xi = 1] - E [Yi00|Xi = 1] -\nE [Yi10|Xi = 1] - E [Yi00|Xi = 1]\n= E [Yi11|Xi = 1] - E [Yi10|Xi = 1]\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n10 / 25\n\nDifference-in-Differences (DD)\nWoah! What just happened?!?!\nWe call this a difference-in-differences (DD) estimator.\nTo actually estimate this, we can replace every E [] we see with a\nsample average. However, a more flexible method is to use a\nregression.\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n11/ 25\n\nTreatment Effects in a Regression\nOutline\nTreatment Effects\nDifference-in-Differences (DD)\nTreatment Effects in a Regression\nDD in a Regression\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n12 / 25\n\nTreatment Effects in a Regression\nOperationalizing counterfactuals with a regression\nWe just went over how a clever choice of which expectations we\nestimate allows us to uncover treatment effects under reasonably\nweak assumptions.\nNow I'll show you that we shouldn't actually be calculating a bunch\nof expectations in turn... Regressions can do the same thing with\nsome very useful perks!\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n13 / 25\n\nTreatment Effects in a Regression\nLet's consider an example.\nA couple years ago, there was some hearty debate over whether the\nAffordable Care Act (ACA) would lower the wages of employees at\nsmall businesses, since small firms now needed to purchase health\ninsurance for workers while large firms (usually) already offered health\ninsurance.\nSuppose we wanted to run a regression of employees at small firms\n(100-500 employees) vs. employees at large firms (500+ employees)\nin 2014:\nEarni1 = β0 + β1Smalli1 + ei1\nLet's work through this example using data I downloaded from the\nCurrent Population Survey\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n14 / 25\n\nTreatment Effects in a Regression\nWhat a single-variable regression is doing.\nLet Y stand for earnings and X stand for treatment (being at a small\nfirm). Let's drop t until we get to the DD again, since we're\nconsidering only the post-ACA world (2014, otherwise known as\nt = 1).\nRegressions mechanically give us an estimate of\nβ1 = E [Yi1|Xi = 1] - E [Yi0|Xi = 0]. If you need proof, check out\nwhat happens when I compare a t-test (which explicitly compares the\ndifference in these sample means) against a regression.\nA t-test...\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\nColin Gray (14.03/14.003, Fall 2016)\n15 / 25\n\nTreatment Effects in a Regression\nWhat's the problem here?\nSo the β1 in our regression is giving us\nE [Yi1|Xi = 1] - E [Yi0|Xi = 0]. Let's imagine why that might not be\nthe treatment effect we are looking for...\nRecall our term for bias:\nE [Yi0|Xi = 1] - E[Yi0|Xi = 0]\n¡3-¿ What if we think that college-educated workers often work at\nlarge firms, and that college-educated workers make more money\nregardless of the regulations surrounding firms of different sizes?\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n16 / 25\n\nTreatment Effects in a Regression\nWhat it means to \"control\" for a variable.\nUnlike comparing sample means directly, a regression also gives us a\nnatural way to take out the effect of these omitted variables and\ntherefore reduce the bias in our estimate of the treatment effect.\nSuppose we estimate the effect of college on the likelihood of working\nat a small firm (X ):\nThen we took the movements in X that seem unrelated to college,\nand regress that variable on earnings:\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n17 / 25\n\nTreatment Effects in a Regression\nWhat it means to \"control\" for a variable (2).\nThis measures the relationship between working at a small firm and\nearnings without the effects of education. To do this quickly, we can\nactually put all of these variables right into the same regression:\nNow we understand how to make direct comparisons of means with a\nregression, and how regression allows us to easily include omitted\nvariables to reduce bias!\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n18/ 25\n\nDD in a Regression\nOutline\nTreatment Effects\nDifference-in-Differences (DD)\nTreatment Effects in a Regression\nDD in a Regression\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n19 / 25\n\nDD in a Regression\nThe Grand Finale\nOf course, you probably think that workers at small and large firms\nhave different earnings for a whole host of reasons, not just\nregulations and not just college educations. We can't just randomize\nwhere people apply for jobs, and we can't see all these differences\nbetween our groups. So...\nTIME FOR A DD!\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n20 / 25\n\nDD in a Regression\nThe Grand Finale\nConsider the following regression. Now the observation is at the\nperson-time (so (i, t)) level:\nEarnit = β0 + β1Smalli + β2Post2014it + β3Smalli Post2014it + uit\nOr in our alternative notation:\nYit = β0 + β1Xi + β21[t = 1]it + β3Xi 1[t = 1]it + uit\nFYI, the notation 1[condition] stands for a variable that equals 1\nwhen the condition is true and 0 otherwise. Sometimes we call this a\ndummy variable.\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n21 / 25\n\nDD in a Regression\nThe Grand Finale\nFor now, just trust me that E [uit |Xi ] = 0 when we fit this kind of\nregression (but not necessarily all kinds of regressions!).\nUsing our previous notation, E [Yi11|Xi = 1] = β0 + β1 + β2 + β3\nE [Yi00|Xi = 1] = β0 + β1\nE [Yi10|Xi = 0] = β0 + β2\nE [Yi00|Xi = 0] = β0\nTherefore our DD estimator is\nE [Yi11|Xi = 1] - E [Yi00|Xi = 1] -\nE [Yi10|Xi = 0] - E [Yi00|Xi = 0]\n= β3\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n22/ 25\n\nDD in a Regression\nThe Grand Finale\nSo for our purposes, a regression does all computational work for us!\nPlus, it lets us do a whole bunch of other cool things that we'll\ncontinue to see throughout the semester.\nWhen we do the DD in our example, we see no significant effects on\nwages for small business workers after the ACA (although this design\nis far from perfect).\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n23 / 25\n\nDD in a Regression\nA visual interpretation\nAverage Earnings\nYear\nLarge Firms\nSmall Firms\nSmall Firms and the ACA Mandate\nWhat a DD Does\nColin Gray (14.03/14.003, Fall 2016)\nRecitation 2: Merging Counterfactuals and Regressions September 14, 2016\n24 / 25\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.03 / 14.003 Microeconomic Theory and Public Policy\nFall 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    }
  ]
}