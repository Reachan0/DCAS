{
  "course_name": "Ethics and the Law on the Electronic Frontier",
  "course_description": "This course considers the interaction between law, policy, and technology as they relate to the evolving controversies over control of the Internet. In addition, there will be an in-depth treatment of privacy and the notion of “transparency” – regulations and technologies that govern the use of information, as well as access to information. Topics explored will include:\n\nLegal Background for Regulation of the Internet\nFourth Amendment Law and Electronic Surveillance\nProfiling, Data Mining, and the U.S. PATRIOT Act\nTechnologies for Anonymity and Transparency\nThe Policy-Aware Web",
  "topics": [
    "Engineering",
    "Computer Science",
    "Data Mining",
    "Humanities",
    "Philosophy",
    "Ethics",
    "Social Science",
    "Communication",
    "Legal Studies",
    "Public Administration",
    "Science and Technology Policy",
    "Engineering",
    "Computer Science",
    "Data Mining",
    "Humanities",
    "Philosophy",
    "Ethics",
    "Social Science",
    "Communication",
    "Legal Studies",
    "Public Administration",
    "Science and Technology Policy"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: One session / week, 3 hours / session\n\nInstructors\n\nHal Abelson\n\nProfessor of Computer Science and Engineering, MIT\n\nDanny Weitzner\n\nDirector for Technology and Society, World Wide Web Consortium\n\nMike Fischer\n\nProfessor of Anthropology and Sci. Tech. Studies, MIT\n\nPrerequisites and Enrolling\n\nMIT course 6 students may count this subject as one of the general engineering concentration subjects required for the S.B. or M.Eng. programs, or use this subject for HASS elective credit (but not both). Students wishing engineering concentration credit should enroll under the subject number 6.805, and students wishing HASS credit should enroll under the number STS.085. Graduate credit can be granted through STS (not Course 6), although this will require making special arrangements with Mike Fischer for extra work.\n\nThere are no formal prerequisites for this subject, but students should be prepared to do extensive independent research, involving both technology and policy analysis. In selecting participants for the class, we will be looking for people with appropriate backgrounds, such as knowledge of\n6.033\n. Also, due to the importance of class participation, class attendance is mandatory.\n\nImportant: There are class readings, and also a writing assignment due before the first class\n. These must be completed and the writing assignment turned in by email before 5PM on the day before the first lecture. No one will be admitted to the first class without having completed this assignment. See the description of the pre-semester assignment in the\nassignments\nsection.\n\nReadings\n\nThe class will have many readings, mostly short. Most of these can be found in the\nreadings\nsection. There are also two books that you'll be reading as the semester progresses:\n\nBrin, David.\nThe Transparent Society: Will Technology Force Us to Choose Between Privacy and Freedom?\nNew York, NY: Perseus Books, 1999. ISBN: 0738201448.\n\nO'Harrow, Robert.\nNo Place to Hide: Behind the Scenes of Our Emerging Surveillance Society\n. New York, NY: Simon and Schuster, 2005. ISBN: 0743254805.\n\nYou should get copies of both of these (or borrow copies, or whatever).\n\nGrading and Required Work\n\nGrades will be based on\n\nClass Participation: We expect you to participate actively in class discussions, contributing your own ideas and commenting on the ideas of others. The readings assigned each week should be done before class. In class, we will call on you and ask you to answer questions about the readings and to contribute to the discussion. The quality of class participation will be a factor in grades. If you are the type who \"does not like to talk in class,\" you should consider whether you really want to take this class. Class attendance is mandatory.\n\nShort Writing Assignments: There will be weekly short writing assignments, that use a system called the writing rotisserie. Most weeks' assignments will have two parts: (1) writing your own paper (due Sunday evening); and (2) commenting on other students' paper (due Wednesday). All assignments will be provided on the course server for everyone in the class to read. See the description of the writing rotisserie in the\nassignments\nsection for details.\n\nTerm Project: You will be required to do a term project, leading to a final paper. You can make this an individual project, or work with a partner. This will be a major project, and you should expect to devote a lot of time to it throughout the semester. The project can be purely a research paper, or it can involve design and implementation (but this still requires a paper). Papers may be selected for inclusion in the class archive of student papers on the Web. You should browse through the paper selections to get an idea of the scale of work expected.\n\nOral Presentation: At least once during the semester, you will be required to make an oral presentation on your project, either a final report or a progress report.\n\nMidterm Exam: There will be an in-class midterm exam.\n\nFinal Exam (not): There is no final exam.",
  "files": [
    {
      "category": "Resource",
      "title": "plenary_cort_sta.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/9b1bfd2989baf222f1fc68d51acdf0f2_plenary_cort_sta.pdf",
      "content": "CFP96 Plenary Session\nBefore the Court: Can the US Government Criminalize\nUnauthorized Encryption?\nAPPENDIX\nThe Cryptography Control Act of 1995\n[Pertinent Provisions Only]\nSection 1. Congressional Findings.\nIt is the findings of the Congress that: (a) the acquisition and interpretation of oral, written, and data\ncommunications over telecommunications networks, and information stored in written and digital media,\nare tools which have been historically used for domestic law enforcement and national security\npurposes, and, whether transmitted or not, affect national and global communications and therefore\ninterstate and foreign commerce; (b) that advances in encryption technology pose a serious threat to the\ncontinued ability of law enforcement and national security agencies to make effective use of such tools;\nand (c) that the inability of such agencies to use such tools in the future would pose an unacceptable risk\nto the domestic tranquility and to the national security of the United States.\nSection 2. Definitions\nFor the purposes of this Act, the following definitions apply:\n(a) \"Encryption\" means a cryptographic system, whether implemented or not, designed for the purpose\nof encoding information in a manner which (a) enables any person having the key to that cryptographic\nsystem, as used to encode such information, to decode such information; and (b) prevents any person not\nhaving such key from decodingsuch information.\n(b) \"Information\" means any data, or string of digits, numbers, or characters, (1) whether oral, written,\nrecorded, or electronic, (2) whether in digital, analog, or other format, and (3) whether or not such\ninformation is useful or understandable to the person possessing, using, transmitting, maintaining, or\n\nencoding it, or to any law enforcement or national security agency\n(c) \"Bit\" means a single digit, either a zero or a one, used by a telecommunications or computer device\nto store, process, transmit, encode or decode information.\n(d) \"Key\" means a code used to decode or interpret information which has been encoded using an\nencryption algorithm or technique.\n(e) \"Key Length\" means the number of bits in a key; if more than one technique, device, or algorithm\nhas been used to encode the same information, then the term includes the sum of the number of bits of\nall the keys necessary to decode the information.\n(f) Authorized Key Escrow Agency means either an agency of the U.S. Department of Justice,\ndesignated as such by the Attorney General, or the U.S. Department of State, designated as such by the\nSecretary of State.\n(g) Authorized Key Escrow Designate means a domestic entity, private or commercial, designated by\nthe Attorney General pursuant to rules to be promulgated by the Attorney General.\nSection 10. Criminal Prohibitions.\n(a) Whoever knowingly encodes information using an encryption technique, device, or algorithm having\na key in excess of 64 bits, and which key has not been registered with an authorized key escrow agency,\nshall be subject to a term of imprisonment of not more than five years, a fine of not more than two\nhundred fifty thousand dollars, or both.\n(b) Whoever knowingly and intentionally possesses, maintains, transmits, distributes, uses, or controls\ninformation which has been encoded using an encryption technique, device, or algorithm having a key in\nexcess of 64 bits, and which key has not been registered with an authorized key escrow agency or\ndesignate, shall be subject to a term of imprisonment of not more than five years, a fine of not more than\ntwo hundred fifty thousand dollars, or both.\n(c) Whoever knowingly and intentionally manufactures, creates, designs, distributes, sells, transmits, or\npossesses with the intent to distribute, sell, or transmit any encryption technique, device, or algorithm\nhaving a key in excess of 64 bits, and which key has not been registered with an authorized key escrow\nagency or designate, shall be subject to a term of imprisonment of not more than ten years, a fine of not\nmore than five hundred thousand dollars, or both.\n(d) Whoever knowingly and intentionally distributes, sells, or transmits, outside of the boundaries of the\nUnited States, or possesses with the intent to distribute, sell, or transmit outside of the boundaries of the\nUnited States, any encryption technique, device, or algorithm having a key in excess or 64 bits, and\nwhich key has not been registered with an authorized key escrow agency designate, shall be subject to\n\n(1) a term of imprisonment of not less than one year but not more than ten years, and (2) a fine of not\nmore than one million dollars, or (3) both."
    },
    {
      "category": "Resource",
      "title": "privacy_sites.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/e96905687c6f7f3a530b1e957ebc590c_privacy_sites.pdf",
      "content": "6.805, Ethics and the Law on the Electronic Frontier\nPrivacy Lecture Sites\n\n-\nWebcam at GWU. For demo, control the camera, use the preset for university\nyard, and move the camera around. Here is an alternate at University of\nPittsburg to use if the GWU camera isn't working, but this one isn't as good.\n-\nGo to the Crimson article on the medical records.\n-\nGo to apply for a discover card\n\n-\nGo to Google and search under \"resume ssn site:.edu\". Then add \"william\njason wood\" to the search, which should get you to. Resume\n\n-\nGo to Google and search for \"grades ssn digits\". Here's an example of what\nyou can find: Grades.\n\n-\nSearch the Social Security Death Index.\n\n-\nGet the 1997 Edgar filing that has social security numbers in it.\n\n-\nGo to the Edgar database\no\nGo to \"search for company filings\"\no\nThen \"Companies and other filers\"\n\n-\nFair information practices"
    },
    {
      "category": "Resource",
      "title": "rotisserie.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/8e97e4d705754b29d8733fbb06da0d79_rotisserie.pdf",
      "content": "Massachusetts Institute of Technology\nFall Semester, 2005\nMIT 6.805/6.806/STS085: Ethics and Law on the Electronic\nFrontier (3-0-9)\nPolicy and Technology of Copyright Control\nWeekly writing rotisserie\nOnce the semester starts, the weekly writing assignments use a system called the\nwriting rotisserie developed and maintained at Harvard Law School's Berkman Center\nfor Law and Technology. Here's how it works:\n1. There will be an assignment posted each Friday at 11:00 AM.\n2. You must log in to the rotisserie and post your answer before Sunday at 11:00\nPM. Post plain text answers only. No attachments, no HTML formatting. At\nmidnight on Sunday, the system will make all answers visible.\n3. Once all answers are visible, you should log in to the rotisserie again. The\nrotisserie will pick at random another student's response for you to comment\non. Your comments are due before Wednesday at noon. All comments will be\nmade visible on Wednesday at 1:00 PM.\nIf you do not post your results by the deadlines, you will not receive credit for the\nassignment. The due dates and times are constrained by the rotisserie program, so\nplease don't ask us for extensions. We can't grant them. (You might think it's sneaky\nof us to blame the program for our inflexible policy. Think of this as a \"code as law\"\nphenomenon, just like the ones we will be studying this semester.)\nFor more information, see the description of the rotisserie system at h2o.law.\nharvard.edu.\nRegistering for the rotisserie\nBefore you can use the rotisserie, you must register for the rotisserie system, and join\n\nthe project called MIT 6.085, Fall 2005. Do this as soon as possible after the first class\non September 8, when you know you are admitted to the class. The first assignment\nwill be posted on Friday morning, September 9.\n1. Go to the rotisserie page at h2o.law.harvard.edu and register. Please\nuse your real name and actual email address. Keep your browser page open,\nand read your email.\n2. The system will email you a confirmation key. Use this key to pick a password\nand activate your registration.\n3. Go to the main rotisserie page and request to join the project named MIT 6.805,\nFall 2005. You will receive mail when you have been added as a project\nparticipant.\n4. You should now be able to participate in the project, as described above."
    },
    {
      "category": "Resource",
      "title": "sample_brief.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/70d0386008945ac16d5a2790ce8fe411_sample_brief.pdf",
      "content": "Massachusetts Institute of Technology\nSpring Semester, 2005\nMIT 6.805/6.806/STS085: Ethics and Law on the Electronic\nFrontier\nSample case brief\nCubby v. Compuserve, 776 F.Supp 135 (SDNY, 1991)\nIn common law systems (such as the United States and Great Britain), courts decide\ncases both in order to determine the just result of a particular dispute, and also to\nprovide an evolving articulation of legal rules applicable to classes of controversies.\nJudges write legal opinions in a manner that explains the dispute before the court, and\nalso to serve as a record of how the legal system understands the type of dispute in the\ncase before the court. Lawyers read judicial opinions to understand the application of\nthe law, and to use the arguments presented by judges in earlier cases in order to\nconstruct arguments about new cases.\nWhen reading cases for this purpose, it is necessary to extract 5 key elements from the\nopinion. This style or reading and summarizing a judicial opinion is called briefing a\ncase. Here's how you do it:\nKey elements of a judicial opinion to include in a case brief:\n● Issue: what is the legal question to be decided\n● Procedural History:\n❍ Who are the Parties to the dispute?\n❍ Procedural Posture; what has happened in the court system before the\ncase arrived at this court for decision?\n● Facts: what are the key facts that the court finds as true and relevant to applying\nthe legal rules to the dispute? (Resist the temptation to recite ALL facts. Instead,\nthink about which facts are really important to the holding.\n● Holding: What is the result of the case -- an answer to question posed by the\n'Issue' relative to the 'Parties'.\n● Reasoning: Why did the court 'hold' as it did?\n\n● Dissent: If there is a dissenting opinion (minority of judges who disagree with\nthe result supported by the court), be sure to indicate resoning behind the\ndissent.\nBriefing Cubby\nCubby v. Compuserve is an an important early case dealing with the legal standards\ngoverning the liability of Internet Service Providers for defamation. (If you don't\nknow the meaning of legal terms like \"liability\" and \"defamation\" you should look\nthem up. www.legal-definitions.com can be a useful resource here.)\n● Issue: Can Compuserve (CIS) be held liable for the defamatory statements\nmade in an online forum by an independent entity under contract with CIS?\n● Procedural History\n❍ Parties:\n■ Plaintiff: Cubby (Skuttlebutt)\n■ Defendants: Compuserve, Don Fitzpatrick\n❍ Procedural Posture: Defendant Compuserve's motion for summary\njudgment\n● Facts\n❍ Journalism Forum:\n■ operated by CCI, subcontracted by CCI to DFA\n■ CCI contracted to \"create, edit, etc. content\"\n■ CIS gains no revenue for access to CCI as opposed to any other\nforum\n■ CIS has no practical control over content given volume\n■ content created by CCI is made available to subscribers\n'instantaneously'\n■ CIS has no employment relationship with CCI or DFA\n❍ Skuttlebutt = competing service\n● Holding: CIS not liable as a publisher -- only responsible for defamatory\nmaterial which it knew about or had reason to know about.\n● Reasoning\n1. Legal standard/rule: An online service is only responsible for the\ndefamatory content about which it knows or has reason to know\n2. Facts: There is no evidence that CIS knew of defamatory content given\ninstantaneous upload, contract terms, large volume, overall lack of\neditorial control.\n\n3. Policy argument: Traditional First Amendment protections for\ninformation distributors should apply here. If a heavier burden for\npolicing content is put on online distributors, then the First Amendment\nrights of online speakers and authors would suffer.\nReading the case\nNow read the full opinion in Cubby. Is the brief a useful guideline to reading the\nopinion? Think about how you could have started with the opinion and produced the\nbrief.\nLocating judicial opinions\nThe link to Cubby above is to the archive maintained by EPIC, the The Electronic\nPrivacy Information Center. Some of the cases we'll be looking at this semester - like\nthis one -- are available online from many sources and you can find them with Google.\nAs an example, try Googling \"cubby compuserve\" to what's available.\nOther times, you'll need a more complete source of legal opinions and legal research.\nFor this, you can use Lexis-Nexus Academic Universe, which is a non-public\ncommercial, to which MIT has a license. You'll need to either be on campus, or have\nan MIT certificate in order to access it. For practice that will be useful throughout the\nsemester, try finding the Cubby opinion now on Lexis-Nexus:\n1. Go to MIT's Vera site for electronic journals,\nYou'll want to bookmark this. MIT has an extensive collection of online\njournals, and you'll find Vera indispensable for pretty much any research you'll\nbe doing in your MIT courses.\n2. Use Vera to search for \"Lexis\", and then select \"Lexis-Nexis Academic\". At\nthis point might be asked to accept the MIT site certificate, and you might be\nasked to provide your MIT certificate. This will bring you to the Lexis search\nform.\n3. Search by the party names \"Cubby\" and \"Compuserve\" and you should find the\nopinion.\n4. Go back to the Lexis search page and search for the same case by its legal\ncitation, \"776 F. Supp. 135\". We'll explain the format of these citations in\nclass.\n5. Go back again to the search Lexis page and select \"Legal Research\" from the\nmenu on the left, and then select \"Law Reviews\". This should bring you to the\n\nlaw review search page. Fill in \"cubby compuserve\" under keywords, and set\nthe drop-down menu to \"all available dates\". You should find more than a\ndozen law review articles that mention this case. This is an example of how\nyou can do research for your papers over the semester.\n6. Go back to the search page and search under the keywords \"defamation and\nliability\" with the additional search term \"internet service provider\". You\nshould find almost 600 articles. The point of this exercise is not that you should\nread all (or any) of these now, but to help you appreciate that there are a lot of\nresources available to support your work this semester. When you write papers\nfor the course, we expect you to take the initiative to locate resources and use\nthem appropriately."
    },
    {
      "category": "Resource",
      "title": "sample_midterm.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/9c7f51e11e0152e84a8aaa8eec2bf773_sample_midterm.pdf",
      "content": "Sample midterm\nThe midterm will be held in class on Thursday, October 27.\nThe material on this page is not the midterm -- it is a midterm that we gave in this course\na few years ago. We're including it here as an example, so you'll have some idea of what\nto expect.\nSample Midterm Exam\nThis is an open-book exam. You can use any reference material you like, so long as you\nwork alone (e.g., no messaging with anyone during the exam).\nInstructions\nIn discussing the issues raised by each scenario, be sure to state the legal principles that\nyou believe are relevant and also discuss how those principles would apply to the\nquestion you are addressing. You are encouraged to cite case names and specific statutes,\nbut you should not provide long, verbatim quotations. You will probably need to use\nmore than one exam booklet. Be sure to number the booklets and write your name on\neach booklet. Note on using laptops: You may use a laptop to compose your answers,\nalthough we suggest that you use the exam booklets instead. If you do use a laptop, you\nmust turn in your answers to the staff within 15 minutes after the exam ends: no\nexceptions. You can save your answers on a floppy and hand them to us, or you can send\nthem by email to 6.805-staff. If you do use a laptop, you accept all responsibility and all\nconsequences for anything that goes wrong (losing your work in a system crash, writing\nan unreadable floppy, lossage in the email system, crash of the global Internet, etc.). This\nis called \"liability\".\nSuggestions: Take time to outline your answers before diving into the writing. Pay\ncareful attention to the facts presented in each question, but don't automatically assume\nthat every fact mentioned is legally relevant.\nGrading\nQuestions A and B below carry equal weight and you should answer them both. Be sure\nto allow adequate time to respond to each question. Credit will be awarded primarily for\nthe quality of your analysis, more so than reaching the correct conclusion. In some cases,\nthere are clearly correct legal conclusions to be drawn, while in some cases, a variety of\nlegal arguments could be correct. A well-reasoned but incorrect conclusion is worth more\nthan a poorly reasoned discussion that asserts the correct answer.\n\nQuestion A - Mobile Video Spam Protection Act\nBackground\nAdvances in mobile phone technology in 2004 and early 2005 have brought the wonders\nof full-motion video conferencing and messaging to all mobile phone users. Federal\nbudget pressures have also lead to a sudden decision by the Federal Communications\nCommission to put all radio spectrum previously allocated to High Definition Televison\nup for auction. With abundant bandwidth and cheap, high-powered mobile phones in the\nhands of the vast majority of customers, including over 70% of kids over age 10, the\nmobile phone environment had reached a new plateau of capability and ubiquity. With\nthis success, unfortunately, also came a growing social problem: video spam. By mid-\n2004, digital video editing is increasingly easy and transport over both wireless and wired\nnetworks of all sorts is effectively free. Worse yet, the spam problems that plagued\nSMTP email in earlier years have only multiplied given the increasing complexity of the\nmobile phone operating system software. Video spam is everywhere and through a\nvariety of possible hacks can appear on the users screen without warning (know as\n'autopopup spam'). A recent study by the National Academy of Sciences estimated that\nmobile video spam has the following characteristics:\n-\n80% commercial, 20% non-commercial\n-\nadvertising: 45%, sexually-explicit: 25%, political advocacy: 20%, personal\nappeals: 10%\n-\ntargetted to all ages: 83%, targetted to children: 17%\n-\ndelivered to inbox: 58%, autopopup: 42%\nOn 9 June 2005 the United States Congress passed legislation entitled the Mobile Video\nSpam Protection Act (MVSPA), which President Schwarzenegger signed into law the\nfollowing week. The Act provides:\n1. criminal penalties for anyone who sends mobile video spam (MVS)\n2. a defense against prosecution if the sender provides an opt-out mechanism for\nusers\n3. a private right of action whereby recipients of MVS may sue senders of MVS for\nnot more than $10,000 per message received\n4. the following definition of mobile video spam:\nMobile Video Spam is any video message sent to the subscriber of a video-\nmessage-capable mobile phone where:\n(a) the sender has no prior business or personal relationship with the recipient;\n(b) the message is sent either by being directly addressed to the recipient or\nreaches the recipient through sender's use of fraudulent routing and/or addressing\ninformation; and,\n\n(c) the message is either commercial or non-commercial in nature\n-\na severability clause whereby if any provision of the Act is found\nunconstitutional, the remaining provisions of the Act shall remain in operation.\nAfter hearings in both the Senate and House, the MVSPA passed 90-10 in the Senate and\n434-1 in the House. The Act was welcomed by many mobile phone users who have been\ndeluged by unsolicited video streams. However, free speech advocates and others are\nnow considering challenging the Act. As Staff Counsel to the Live Internet VIDeo\nFoundation (LIVID), a pro-civil liberties advocacy group, you are asked to write a memo\nassessing the constitutionality of MVSPA and making recommendations on steps that\nLIVID could take to challenge the Act. Your memo should address the constitutionality\nof the various provisions of the Act based on the case law studied in class. If you believe\nthere are issues not covered by the cases we read, note those issues as unresolved.\nQuestion B - Indianapolis v. Edmond & the Terrorism\nInformation Awareness Program\nYou are legislative counsel to the Senate Judiciary Committee. In reviewing the US\nDepartment of Defense's reply to questions posed by your committee regarding privacy\nproblems posed by the proposed Terrorism Information Awareness Program, you recall a\nrecent Fourth Amendment case, CITY OF INDIANAPOLIS et al. v. EDMOND et al. 531\nU.S. 32 (2000). Read the majority opinion in case (attached). Write a memo to your boss\nSenator Hatch regarding the relevance of that case and any others we have studied you\nbelieve relevant to the Genisys system as described in the DARPA report to your\nCommittee. For purposes of this question, assume that Genisys includes publicly\navailable data and the following:\n-\nall EZPass toll records\n-\nRFID transactions from the top ten supermarket chains\n-\nVisa & Mastercard charge transactions.\nWhat Fourth Amendment issues are raised? Does the Fourth Amendment analysis change\ndepending on the which of the above information stores are included? Assume that all\ndata is collected pursuant to proper legal requirements."
    },
    {
      "category": "Resource",
      "title": "l6_crypto.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/ff32215ac6498e653a6f4f1d7ddce63c_l6_crypto.pdf",
      "content": "FNNC ZESDQMNNM !\nSghr kdbstqd hr\nzants dmbqxoshnm\n\nOct. 13 2005\nOutline\n- Part 1: Cryptography, pre-1970\n- A lot of the history of pre-internet cryptography is\nrelevant for today\n- Part 2: Public-key cryptography\n- A major technological breakthrough\n- Part 3: The crypto policy debate 1990-2000\n- A case study for policy stresses caused by\ntechnology\n\nOct. 13 2005\nSecurity needs on networks\n-\nConfidentiality: Only authorized people - e.g., the sender and\nrecipient of a message, and not any eavesdroppers - can know\nthe message.\n-\nAuthentication: When Bob receives a message that purports to\nbe sent by Alice, Bob can be sure that the message was really\nsent by Alice.\n-\nIntegrity: When Bob receives a message, he can be sure that it\nwas not modified en route after Alice sent it.\n-\nNon-repudiation: Alice cannot later deny that the message was\nsent. Bob cannot later deny that the message was received.\nImplemented using encryption\n\nOct. 13 2005\nCryptography, ca. 1900BC\n=\n=\n=\n\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\nt\nt\nt\nt\nt\nt\nt\nt\nt\ne\nt\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\nt\nt\nt\nt\nt\nt\nt\nt\nt\nt\ne\nh\nh\nh\nh\nh\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\nt\nt\nt\nt\nt\nt\nt\nt\nt\nt\ne\nh\nh\nh\nh\nh\no\no\no\no\no\no\no\no\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\nt\nt\nt\nt\nt\nt\nt\nt\nt\nt\ne\nh\nh\nh\nh\nh\no\no\no\no\no\no\no\no\ni\ns\ni\ni\ni\ni\ns\ns\ni\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\nt\nt\nt\nt\nt\nt\nt\nt\nt\nt\nh\ne\nh\nh\nh\nh\no\no\no\no\no\no\no\no\ni\ns\ni\ni\ni\ni\ns\ns\ni\nr\nr\nr\nr\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\ne\nt\nt\nt\nt\nt\nt\nt\nt\nt\nt\nh\ne\nh\nh\nh\no\no\no\no\no\no\no\no\ni\ns\ni\ni\ni\ni\ns\ns\ni\nr\nr\nr\nr\nh\nf\na\na b\na b\nl\nl\nf\nv\nn\nn\nn\nn\nn\nf\nc\nu\nq\nd\nm\nGeoffrey Chaucer, Treatise on the Astrolabe, 1391\n\nOct. 13 2005\nSubstitution cipher\n- Replace each character of the message by\nanother character, according to some rule\n- Simple or monoalphabetic substitution: All\noccurrences of a given character in the\nmessage are replaced by the same character\n- In general\n- Original message is called the plaintext\n- Encrypted result is called the ciphertext\n\nOct. 13 2005\nCaesar cipher\n- Replace each letter by the letter that comes some\nfixed distance before or after it in the alphabet.\na b c d e f g h i\nj k l m n o p q r s t u v w x y z\nX Y Z A B C D E F G H I J K L M N O P Q R S T U V W\nShift = 3\nOmnia Gallia in tres partes divisa est\nLJKF XDXI IFXF KQOB PMXO QBPA FSFP XBPQ\n\nFNNC ZESDQMNNM !\nSghr kdbstqd hr\nzants dmbqxoshnm\n\nOct. 13 2005\nSolving simple substitution ciphers\n- Frequency analysis has\nbeen known since the 9th\ncentury.\n- Al Kindi's Manuscript on\nDeciphering Cryptographic\nMessages\nYaqub Ibn Ishaq al-Kindi (801-873)\n\nOct. 13 2005\n\n- Russian\nmonoalphabetic\nsubstitution key,\nrecovered by\nEngland's\nDecyphering\nBranch, 1728\n-\nFrom David Kahn, The\nCodebreakers\n\nOct. 13 2005\n2nd Maxim of the Day\n- Throughout history, people continued to use\ninsecure encryption methods -long after\nthese methods have been broken - because\nof ignorance, laziness or force of habit.\n- Today also, people use insecure encryption\n(or no encryption at all). Many technology\ncompanies market encryption products that\nuse methods that are insecure, or outright\nbogus.\n\nOct. 13 2005\nVigenere Encryption\n- Use several\nCesar\nsubstitutions\nand cycle\nthrough them\n- Sequence of\nsubstitutions\ndetermined\nby a secret\nkey\nLeon Battista Alberti (1404-1472)\nBlaise de Vigenere (1523-1596)\n\na\nb c\nd e\nf\ng h\ni\nj\nk\nl\nm n o p q\nr\ns\nt\nu v\nw x\ny\nz\nS T U V W X Y Z A B C D\nE F G H I\nJ\nK L M N O P Q R\nO P Q R S T U V W X Y\nZ\nA B C D E F G H I\nJ\nK L M N\nN O P Q R S T U V W X Y\nZ A B C D E F G H I\nJ\nK L M\nG H I\nJ\nK L M N O P Q R\nS T U V W X Y Z A B C D E F\nB C D E F G H I\nJ\nK L M N O P Q R S T U V W X Y Z A\nI\nJ\nK L M N O P Q R S\nT\nU V W X Y Z A B C D E F G H\nR S T U V W X Y Z A B C\nD E F G H I\nJ\nK L M N O P Q\nD E F G H I\nJ\nK L M N O\nP Q R S T U V W X Y Z A B C\nFight fiercely, Harvard! Fight! Fight! Fight!\nXWTNU NZ H JQRR ZPRU NOEJ GQXK LTVM IBWL YVG\n\nOct. 13 2005\nBreaking Vigenere - (1)\n- If the key has length K, then the ciphertext letters K\npositions apart are specified by the same character\nin the key ...\n- And thus is the result of a simple substitution\n- And thus can be attacked by frequency analysis\n- Example: Suppose the key length is three:\nDJBK FJWO VJSW FKDS GFJD RKEM CNEJ JKSJ FKDJ SJSS\nSo the decryption reduces to doing frequency\nanalysis K times - provided we know K\n\nOct. 13 2005\nBreaking Vigenere - (2)\n- To find the length of the key:\n- Try different values for K, looking at every Kth letter\nof the ciphertext, and pick the one for which the\nfrequency distribution looks like the frequency\ndistribution for English.\n- Clever methods to do this by hand:\n- Babbage, Kasiski: counting double letters (1850s, 1860s)\n- Friedman: Index of Coincidence (1920s)\n- With computers, we don't need to be clever: Can do\nbrute-force statistics\n\nOct. 13 2005\n\nOct. 13 2005\nBut suppose the key is as long as the\nmessage?\n- Then the decryption method breaks down\n- A key that is as long as the message is called\na one-time pad.\n- One-time pad encryption is completely\nsecure, provided that\n- the pad is random\n- the pad is used only once\n\nOct. 13 2005\nClaude Shannon (1916-2001)\nA Mathematical Theory of Communication (1948)\nQuickTimeTM and a\nTIFF (Uncompressed) decompressor\nare needed to see this picture.\n\n- Shannon:\n\"Communication\nTheory of Secrecy\nSystems\", 1949\n- Based on classified\nwork done in 1946\n\nOct. 13 2005\n\"Perfect Secrecy\" (Shannon, 1949)\n- Definition: An encryption system has perfect\nsecrecy if knowing the ciphertext tells you no\ninformation at all about the plaintext\n- Result 1: In order to have perfect secrecy, the\nkey must be as long as the message\n- Result 2: A one-time pad system can have\nperfect secrecy if the pad is truly random\n\nOct. 13 2005\nEncrypting with computers\n- Want to encrypt bits (text, music, images, ...),\nnot just letters.\n- Rather than shifting letters around, use bit\noperations like XOR ...\n\nOct. 13 2005\nExclusive OR (XOR), a⊕b\n- Definition: for two bits, a and b\n- a⊕b = 0 if a and b are the same (both 0 or both 1)\n- a⊕b = 1 if a and b are different\n- Combine data bitwise, using XOR\n- Example:\n01000010 ⊕01010011 = 00010001\n\nOct. 13 2005\nXOR encryption (Bit analog of Vigenere)\nkey\nSECRET\nmessage\nBill Gates's SSN is 539-60-5125\nRepeat key\nSECRETSECRETSECRETSECRETSECRETSE\nmessage in ASCII\nB i l l 5\n01000010 01101001 01101100 01101100 ..... 00110101\nRepeated key in ASCII\nS E C R E\n01010011 01000101 01000011 01010010 ..... 01000101\nBit-wise xor\n00010001 00101100 00101111 00111110 ..... 01110000\n\nOct. 13 2005\nEncryption methods today\n- Insecure methods\n- Lots of them around\n- From hobbyists\n- \"Security\" startup companies\n- Established companies, as well\n- Secure methods\n- One-time pad is the only provably secure method\n- But this requires securely transmitting the pad\n- Many other algorithms that have withstood years\nof analysis and attempted attacks.\n\nOct. 13 2005\nData Encryption Standard (DES)\n- Designed by IBM in 1975, with help from NSA\n- Encrypts 64-bit blocks, based on a 56-bit key\nSubstitute bit patterns for other bit\npatterns, based on the key\nShuffle the bits\n\nOct. 13 2005\nSecurity of DES\n-\nNo shortcuts, as far as anyone knows\n- You essentially have to try all possible keys\n- Keys are 56 bits long, so there are 256 keys\n- 256 is a big number, but not that big. In August 1998, the Electronic\nFrontier Foundation demonstrated that a special-purpose machine\nbuilt from standard parts at a cost of $200,000 could break DES in\n56 hours.\n-\nBig governments have a lot more than $200,000 to spend on\ncryptanalysis.\n-\nEach time you add a bit to the key length, you double the time\nrequired to break the system.\n-\nNIST adopted a new Advanced Encryption Standard in 2001\n(the Rijndael algorithm, 128-bit keys). DES is still widely used.\n\nOct. 13 2005\nCryptosystems\nATTACKER\nkey\nencrypt\nplaintext\nmessage\nretreat at\ndawn\nkey\ndecrypt\nciphertext\nplaintext\nmessage\nretreat at\ndawn\nSENDER\nciphertext\nsb%6x*cmf\nRECEIVER\nSome types of attacks\n-ciphertext only\n-known plaintext\n-chosen plaintext\n-chosen ciphertext\n-rubber hose\n\nOct. 13 2005\nKerkhoffs's Principle\n- Auguste Kerkhoffs, La Cryptographie\nMilitaire, 1883\n- Cryptographic systems should be designed in\nsuch a way that they are not compromised if\nthe opponent learns the technique being\nused. In other words, the security should\nreside in the choice of key rather than in\nobscure design features.\n- from Ross Anderson \"How to Cheat at the Lottery\"\n(1999)\n\nOct. 13 2005\nSchneier quote\n- If the strength of your new cryptosystem relies on the\nfact that the attacker does not know the algorithm's\ninner workings, you're sunk. If you believe that\nkeeping the algorithm's insides secret improves the\nsecurity of your cryptosystem more than letting the\nacademic community analyze it, you're wrong. And if\nyou think that someone won't disassemble your code\nand reverse-engineer your algorithm, you're naive.\n- Bruce Schneier; Applied Cryptography (Second\nEdition, 1996)\n\nOct. 13 2005\nNone of this is adequate for Internet\napplications\n- In order to communicate, Alice and Bob must share a\nsecret key\n- Doesn't work well on a large scale\n- Doesn't work with parties who haven't made a secure prior\narrangement\n- But there is a great idea:\n- Alice and Bob can create a shared secret key, even if\nthey have never met before and have made no prior\narrangements, and even if everyone can eavesdrop\non all their communications ...\n- ... including eavesdropping on the communications\nthey use to establish the key!\n\nEnd of Part 1\nto be continued ...\n\nOct. 13 2005\nNone of this is adequate for Internet\napplications\n- In order to communicate, Alice and Bob must share a\nsecret key\n- Doesn't work well on a large scale\n- Doesn't work with parties who haven't made a secure prior\narrangement\n- But there is a great idea:\n- Alice and Bob can create a shared secret key, even if\nthey have never met before and have made no prior\narrangements, and even if everyone can eavesdrop\non all their communications ...\n- ... including eavesdropping on the communications\nthey use to establish the key!\n\nOct. 13 2005\nPublic-Key Cryptography\nPhotos removed due to copyright reasons.\n\nOct. 13 2005\nThe basic idea of Diffie-Hellman-Merkle\nkey agreement\n- Arrange things so that\n- Alice computes a number based on secret information that\nonly Alice knows\n- Bob computes a number based on secret information that\nonly Bob knows\n- Alice and Bob will somehow manage to compute the same\nnumber, even though they don't know each other's secret\ninformation\n- No one else can compute this number without knowing\nAlice's secret information or Bob's secret information\n- Sounds impossible ...\n\nOct. 13 2005\nMath Quiz\n2 x 6 =\nmod 11\n2 x 6 x 5 =\nmod 11\n23 =\nmod 7\n2300 =\nmod 7\n\nOct. 13 2005\nThere's a shortcut for computing powers\n- Problem: Given a and p and x, find y such that\nax = y (mod p)\n- Method 1: multiply a by itself x times\n- Requires x multiplications\n- Method 2: use successive squaring\n- Requires about lg x multiplications\n- Same idea works for multiplication modulo p\n- Example: If x is a 500-digit number, we can compute\nax (mod p) in about 1700 (= lg 10500) steps.\n\nOct. 13 2005\nThere's no shortcut for computing\nlogarithms mod p\n- Problem: Given a and p and y, find x such that\nax = y (mod p)\n- As far as anyone knows, there are no shortcuts.\n- The only way to do this is essentially by brute-\nforce search among all possibilities for x.\n-\nExample: If p is a 500-digit number, finding x so that\nax = y (mod p)\nrequires about 10500 steps.\n\nOct. 13 2005\nThe math behind DHM key agreement\n- Given a and p, and an equation of the form\nax = y (mod p)\n- Then it is exponentially harder to compute x\ngiven y, than it is to compute y given x.\n- For 500-digit numbers, we're talking about a\ncomputing effort of 1700 steps vs. 10500\nsteps.\n\nDiffie-Hellman-Merkle Key Agreement\nStart with public, standard values of p and a\nPick a secret number SA\np\na\nP\nB\nS\nB\nmod\n=\nCompute\nShout out PA\nCompute\np\nP\nA\nS\nB\nmod\nCompute\np\nP\nB\nS\nA\nmod\nMain point: Alice and Bob have computed the same number, because\n(\n)\np\nP\na\na\na\nP\nB\nB\nA\nA\nB\nA\nB\nA\nS\nA\nS\nS\nS\nS\nS\nS\nS\nB\nmod\n)\n(\n)\n(\n=\n=\n=\n=\nEve\nAlice and Bob can now use this number as a shared key for encrypted communication\nShout out PB\nPick a secret number SB\nBob\nAlice\nPA\nPB\np\na\nP\nA\nS\nA\nmod\n=\nCompute\nEavesdroppers know\nand\np\na\nP\nA\nS\nA\nmod\n=\np\na\nP\nB\nS\nB\nmod\n=\nBut going from these to\np\na\nB\nAS\nS\nmod\nrequires computing logarithms mod p,\nas far as anyone knows\n\nOct. 13 2005\nConfidential Email with\n\"Offline Diffie-Hellman-Merkle\"\nAlice\nAlice picks a secret key SA, computes the\ncorresponding public key PA (using the D-H\nformula) and publishes PA in a directory\nBob\nTo send Alice a message,\nLooks up Alice's public key, picks a random number to\nplay the role of SB, for this message, and computes\nthe corresponding PB (using the D-H formula)\nUses SB and Alice's public key to create an encryption\nkey for this message (using the D-H formula)\nSends the encrypted message to Alice, along with PB\nAlice\nUses her secret key and the PB she\nreceived from Bob to compute the key\nand decrypt the message\n\nOct. 13 2005\nBut there's a problem...\n- How can Bob know that the listing in the\ndirectory is really Alice's secret key?\nEve\nTampers with the directory and inserts her\nown key under Alice's name\nAlice\nAlice picks a secret key SA, computes the\ncorresponding public key PA and publishes PA in a\ndirectory\nBob\nObliviously uses \"Alice's\" public key from\nthe directory, but is in reality sending\nmessages that Eve can decrypt.\n\nOct. 13 2005\nDigital signature algorithms\n- Given a secret key, the corresponding public key,\nand a message, generate a number SIG such that\n- SIG is easy to compute if you know the secret key and the\nmessage\n- SIG is infeasible to compute if you don't know the secret key\n- SIG is easy to \"check\" by anyone who knows the message\nand the public key. That is, a certain condition involving the\nmessage and SIG and the public key must be valid\n- Digital signature algorithms are a lot like the Diffie-\nHellman-Merkle algorithm\n- RSA (Rivest-Shamir-Adleman) was the first practical\nsystem to do digital signatures, and it also did public-\nkey encryption\n\nOct. 13 2005\nUsing digital signatures\n- To sign a message, you computes SIG using\nyour secret key. Anyone can check SIG\nusing your public key.\n- If the message was tampered with, the\nsignature won't check. [integrity]\n- No one other than you could have produced\nSIG, since producing SIG requires knowing\nyour secret key. [authentication and non-\nrepudiation]\n\nCertificates and Certifying Authorities*\nPublic Key Infrastructures (PKI)\n- How do we know that \"Alice's public key\" actually\nbelongs to Alice?\n- Alice goes to a Certification Authority (CA), demonstrates\nher identity, and shows her public key. The CA digitally\nsigns Alice's public key, producing a certificate. Anyone can\ncheck the validity of the certificate by using the CA's public\nkey.\n- How do we know the CA's public key is really the\nCA's public key?\n- 1. The CA also has a certificate, signed by some well-known\nand trusted authority like the US Post Office (chain of trust);\nand/or\n- 2. Lots of people we trust have vouched for it (web of trust)\n*Loren M Kohnfelder. Towards a Practical Public-key\nCryptosystem. Bachelor's thesis, EECS Dept., Massachusetts\nInstitute of Technology, May, 1978.\n\nOct. 13 2005\nBasic Transport Layer Security Protocol\n(old name: SSL)\nClient: hello\nServer\nClient\nServer: hello, here's my certificate\nClient: Here's my certificate\nAgree on a session key\nEncrypted communication\n\nEnd of Part 2\nto be continued ...\n\nOct. 13 2005\nThere is a very real and critical\ndanger that unrestrained public\ndiscussion of cryptologic matters\nwill seriously damage the ability of\nthis government to conduct signals\nintelligence and the ability of this\ngovernment to carry out its mission\nof protecting national security\ninformation from hostile\nexploitation.\n-- Admiral Bobby Ray Inman\n(Director of the NSA, 1979)\n\nOct. 13 2005\nUnless the issue of encryption is\nresolved soon, criminal conversations\nover the telephone and other\ncommunications devices will become\nindecipherable by law enforcement.\nThis, as much as any issue,\njeopardizes the public safety and\nnational security of this country. Drug\ncartels, terrorists, and kidnappers will\nuse telephones and other\ncommunications media with impunity\nknowing that their conversations are\nimmune from our most valued\ninvestigative technique.\nFBI Director Louis Freeh,\nCongressional testimony\nMarch 30, 1995\n\nOct. 13 2005\nCALEA, October 1994\n... a telecommunications carrier ... shall ensure that its\nequipment, facilities, or services ... are capable of ...\nexpeditiously isolating and enabling the government,\npursuant to a court order or other lawful authorization,\nto intercept ... all wire and electronic communications\ncarried by the carrier within a service area to or from\nequipment, facilities, or services of a subscriber of\nsuch carrier concurrently with their transmission to or\nfrom the subscriber's equipment, facility, or service, or\nat such later time as may be acceptable to the\ngovernment ...\n\nOct. 13 2005\n\nOct. 13 2005\n\nOct. 13 2005\nClipper\n-\nDesigned by the NSA: \"For telephones only\"\n-\nAuthorized by classified Clinton directive in April 1993 (publicly\nannounced only that they were evaluating it). Standards\nreleased in Feb. 1994\n-\n\"Voluntary\" (but government will buy only Clipper phones)\n-\nBuilt-in (\"back door\") key that is split: each half held by a\ndifferent government agency (\"key escrow\")\n-\nEncryption algorithm classified: Clipper chips must be\ntamperproof and therefore expensive\n-\nClipper phones do not interoperate with non-Clipper phones\n-\n\"Capstone\" chip for computer data and communications\n\nOct. 13 2005\nThe key escrow wars\n- Dramatis Personae\n- Industry\n- Law enforcement\n- National security\n- Civil libertarian groups\n\nOct. 13 2005\nGovernment's big hammer:\nCrypto export controls\n-\nPre-1995: Encryption technology classified by State Department\nas a munition\n- Illegal to export hardware, software, technical information, unless\nyou register as an arms dealer and adhere to stringent regulations\n- Illegal to provide material or technical assistance to non-US\npersonnel, including posting on the internet to be available outside\nthe US\n-\n1995: Bernstein v. US Dept. of State, et. al., suit filed\nchallenging the Constitutionality of export regulations\n-\n1996: Jurisdiction for crypto exports transferred to Commerce\nDepartment, but restrictions remain.\n-\n1996-2001: Crypto regulations modified and relaxed, but still\nexist (e.g., can't export to the CIILNKSS countries)\n-\n2003: Bernstein case still in the courts\n\nOct. 13 2005\nIndustry claims and issues (1995)\n- Customers want security for electronic commerce, for\nprotecting remote access, for confidentiality of\nbusiness information.\n- Export restrictions are a pain in the butt.\n- There is plausible commercial demand for\n\"exceptional access\" to stored encrypted data (e.g., is\nsomeone loses a key); but little demand for access to\nencrypted communications, and no commercial\ndemand for surreptitious access.\n\nOct. 13 2005\nLaw enforcement claims and issues\n(1995)\n-\nWiretapping is a critical law-enforcement tool.\n-\nWiretaps are conducted on specific, identified targets under\nlawful authority.\n-\nFor wiretapping, access to escrowed keys must occur without\nknowledge of the keyholders.\n-\nMany criminals are often sloppy and/or stupid: They won't use\nencryption unless it becomes ubiquitous. Some criminals are\nfar from sloppy or stupid: They will use encryption if it is\navailable.\n-\nEvidence obtained from decryption must hold up in court.\n-\nThere is a need for international cooperation in law\nenforcement.\n\nOct. 13 2005\nNational security establishment claims\nand issues (1995)\n-\nWe can't tell you, but they are really serious.\n-\nNSA \"is rumored to be\" carrying out blanket interceptions of\ncommunications on a massive scale, using computers to filter\nout the interesting traffic.\n\nEUROPEAN PARLIAMENT\n\nSession document\n11 July 2001\nFINAL REPORT\non the existence of a global system for the interception of\nprivate and commercial communications (ECHELON\ninterception system)\n\nOct. 13 2005\nCivil libertarian claims and issues (1995)\n- As computer communication technology becomes\nmore pervasive, allowing government access to\ncommunications becomes much more than traditional\nwiretapping of phone conversations.\n- How do we guard against abuse of the system?\n- If we make wiretapping easy, then what are the\nchecks on its increasing use?\n- There are other tools (bugging, data mining, DNA\nmatching) that can assist law enforcement. People\nhave less privacy than previously, even without\nwiretapping.\n\nOct. 13 2005\nNIST meetings with industry, Fall 95\n-\nAllow export of hardware and software with up to 56-bit\nalgorithms, provided the keys are escrowed with government\napproved \"escrow agents\"\n-\nBut\n- no interoperability between escrowed and non-escrowed systems\n- escrow cannot be disabled\n- escrow agents must be certified by US government or by foreign\ngovernments with whom US has formal agreements\n- Talks broke down\n\nOct. 13 2005\nInteragency working group draft, May 96\n-\nIndustry and government must partner in the development of a\npublic key-based key management infrastructure and attendant\nproducts that will assure participants can transmit and receive\ninformation electronically with confidence in the information's\nintegrity, authenticity, and origin and which will assure timely\nlawful government access.\n-\nEscrow is the price of certification (CA might be also function as\nan EA)\n\nOct. 13 2005\nCourting industry, Fall 96 - ...\n-\nShift jurisdiction of crypto exports from State to Commerce\n-\nAllow export of any strength, so long as it has key escrow (now\nknown as \"key recovery\" - KR)\n-\nImmediate approval of export for 56-bit DES, provided company\nfiles a plan for installing KR in new 56-products within two years\n-\nIncreased granting of export licenses for restricted applications\n(e..g, financial transactions)\n\nOct. 13 2005\nLegislation, 1997\n- Bills introduced all over the map, ranging from\nelimination of export controls to bills that would\nmandate key recovery for domestic use.\n\n-\nHal Abelson\n-\nRoss Anderson\n-\nSteven M. Bellovin\n-\nJosh Benaloh\n-\nMatt Blaze\n-\nWhitfield Diffie\n-\nJohn Gilmore\n-\nPeter G. Neumann\n-\nRonald L. Rivest\n-\nJeffrey I. Schiller\n-\nBruce Schneier\n\nOct. 13 2005\nSome technical observations\n-\nIf Alice and Bob can authenticate to each other, then they can\nuse Diffie-Hellman to establish a shared key for communications\n-\nThe security requirements for CAs are very different from those\nfor escrow agents\n-\nImplementing basic crypto is cheap, adding a key recovery\ninfrastructure is not.\n-\nCrypto is necessary not only for electronic commerce, but to\nprotect the information infrastructure. But key escrow may make\nthings less secure, not more:\n- Repositories of escrowed keys could be irresistible targets of attack\nby criminals\n- If thousands of law enforcement personnel can quickly get access\nto escrowed keys, then who else can??\n\nOct. 13 2005\nMore recently ...\n-\nJan, 2000: Commerce Department issues new export\nregulations on encryption, relaxing restrictions\n-\nSept. 13, 2001: Sen. Judd Gregg (New Hampshire) calls for\nencryption regulations, saying encryption makers \"have as much\nat risk as we have at risk as a nation, and they should\nunderstand that as a matter of citizenship, they have an\nobligation\" to include decryption methods for government\nagents.\n-\nBy Oct., Gregg had changed his mind about introducing\nlegislation.\nQuestion: Why was 2001 so different from 1997?\n\nOct. 13 2005\nEND"
    },
    {
      "category": "Resource",
      "title": "l9_privacy.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/008e193109483f5fcfc9b2909c604b77_l9_privacy.pdf",
      "content": "Four vignettes\n- Everyone can snoop\n- What they have on you\n- Getting sensitive information from public data\n- Do-it-yourself identity theft\n\nFour vignettes\n- Everyone can snoop\n- What they have on you\n- Getting sensitive information from public data\n- Do-it-yourself identity theft\n\nGlobal Disk Storage per Person\nLatanya\nSweeney\n\nField name\nChild's first name\nChild's middle name (sometimes or initial)\nChild's last name\nDay, month and year of birth\nCity and/or County of birth (sometimes hospital)\nFather's name\nMother's name (including maiden name)\nPlace of birth (address and town/city)\nMother's age and address\nMother's birthplace (town/city, state, county)\nMother's occupation\nMother, number of previous children\nFather's age and address\nFather's birthplace (town/city, state, county)\nFather's occupation\nTypical Birth Certificate Fields, post 1925\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 1-15\nField#\nSize\nField name\n1 File Status\n50 Baby's First Name\n50 Baby's Middle Name\n50 Baby's Last Name\n1 Baby's Suffix Code\n3 Baby's Suffix Text\n8 Baby's Date of Birth\n5 Baby's Time of Birth\n1 AM/PM Indicator\n1 Baby's Sex\n3 Blood Type\n1 Born Here?\n40 Place of Birth\n1 Facility Type\n\nField#\nSize\nField name\n20 County of Birth\n6 Certifier's Code\n30 Certifier's Name\n1 Certifier's Title\n30 Attendant's Name\n1 Attendant's Title\n23 Attendant's Address\n19 Attendant's City\n2 Attendant's State\n10 Attendant's Zip Code\n50 Mother's First Name\n50 Mother's Middle Name\n50 Mother's Last Name\n9 Mother's Social Security Number\n8 Mother's Date of Birth\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 16-30\n\nfield#\nSize\nField name\n3 Mother's State of Birth\n7 Mother's Residence Address\n2 Mother's Residence Direction\n20 Residence Street Address\n10 Residence Type\n2 Residence Extension\n10 Residence Apartment #\n20 Mother's Town of Residence\n1 Mother's Residence in City Limits\n14 Mother's County of Residence\n3 Mother's State of Residence\n10 Mother's Residence Zip Code\n38 Mother's Mailing Address\n19 Mother's Mailing City\n2 Mother's Mailing State\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 31-45\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 46-60\nField#\nSize\nField name\n10 Mother's Mailing Zip Code\n1 Mother Married?\n50 Father's First Name\n50 Father's Middle Name\n50 Father's Last Name\n1 Father's Suffix Code\n9 Father's Suffix Text\n9 Father's Social Security Number\n8 Father's Date of Birth\n3 Father's State of Birth\n14 Mother's Origin\n14 Mother's Race\n2 Mother's Elementary Education\n2 Mother's College Education\n11 Mother's Occupation\n\nField#\nSize\nField name\n11 Mother's Industry\n14 Father's Origin\n14 Father's Race\n2 Father's Elementary Education\n2 Father's College Education\n11 Father's Occupation\n11 Father's Industry\n1 Plurality\n1 Birth Order\n2 Live Births Still Living\n2 Live Births Now Dead\n4 Month/Year Last Live Birth\n2 Number of Terminations\n4 Month/Year Last Termination\n1 Baby's Weight Unit\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 61-75\n\nField#\nSize\nField name\n5 Baby's Weight\n6 Date of Last Normal Menses\n1 Month Prenatal Care Began\n2 Total Number of Visits\n2 Apgar Score - 1 Minute\n2 Apgar Score - 5 Minute\n2 Estimate of Gestation\n6 Date of Blood Test\n22 Laboratory\n1 Mother Transferred In\n30 Facility Mother Transferred From\n1 Baby Transferred Out\n30 Facility Baby Transferred To\n1 Tobacco Use During Pregnancy\n3 Number of Cigarettes/Day\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 76-90\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 91-105\nField#\nSize\nField name\n1 Alcohol Use During Pregnancy\n3 Number of Drinks/Week\n3 Mother's Weight Gain\n1 Release Info For SSN\n6 Operator Code\n12 Hospital ID\n1 Sent to Romans\n1 Sent to APORS\n16 Other Certifier Specify\n12 Temporary Audit Number\n16 Other Facility Specify\n16 Other Attendant Specify\n1 Mother's Race\n1 Father's Race\n2 Mother's Origin\n\nField#\nSize\nField name\n2 Father's Origin\n1 Attendant Same YN\n1 Mailing Address Same YN\n1 Capture Father's Info YN\n2 Mother's Age\n2 Father's Age\n12 Baby's Hospital Med. Rec.\n1 High Risk Pregnancy YN\n1 Care Giver (For Chicago)\n1 Record Selected For Download\n1 Downloaded\n1 Printed\n12 Form Number\nMEDICAL RISK FACTORS\n1 Anemia\n1 Cardiac Disease\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 106-120\n\nField#\nSize\nField name\n1 Acute/Chronic Lung Disease\n1 Diabetes\n1 Genital Herpes\n1 Hydramnios/Oligohydramnios\n1 Hemoglobinopathy\n1 Hypertension, Chronic\n1 Hypertension, Preg. Assoc.\n1 Eclampsia\n1 Incompetent Cervix\n1 Previous Infant 4000+ Grams\n1 Previous Preterm or SGA Infant\n1 Renal Disease\n1 Rh Sensitization\n1 Uterine Bleeding\n1 No Medical Risk Factors\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 121-135\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 136-150\nField#\nSize\nField name\n40 Other Medical Risk Factors\nOBSTETRIC PROCEDURES\n1 Amniocentesis\n1 Electronic Fetal Monitoring\n1 Induction of Labor\n1 Stimulation of Labor\n1 Tocolysis\n1 Ultrasound\n1 No Obstetric Procedures\n40 Other Obstetric Procedures\nCOMPLICATIONS OF LABOR & D\n1 Febrile (>100 or 38C)\n1 Meconium Moderate, Heavy\n1 Premature Rupture (>12 Hrs)\n1 Abruptio Placenta\n1 Placenta Previa\n1 Other Excessive Bleeding\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 151-165\nField#\nSize\nField name\n1 Seizures During Labor\n1 Precipitous Labor (<3 Hrs)\n1 Prolonged Labor (>20 Hrs)\n1 Dysfunctional Labor\n1 Breech/Malpresentation\n1 Cephalopelvic Disproportion\n1 Cord Prolapse\n1 Anesthetic Complications\n1 Fetal Distress\n1 No Complications of L&D\n40 Other Complications of L&D\nMETHOD OF DELIVERY\n1 Vaginal\n1 Vaginal After Previous C-Section\n1 Primary C-Section\n1 Repeat C-Section\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 166-180\nField#\nSize Field name\n1 Forceps\n1 Vacuum\nABNORMAL CONDITIONS OF NEWBO\n1 Anemia\n1 Birth Injury\n1 Fetal Alcohol Syndrome\n1 Hyaline Membrane Disease/RDS\n1 Meconium Aspiration Syndrome\n1 Assisted Ventilation <30\n1 Assisted Ventilation >30\n1 Seizures\n1 No Abnormal Conditions of Newborn\n40 Other Abnormal Condition of Newborn\nCONGENITAL ANOMALIES OF CHILD\n1 Anencephalus\n1 Spina Bifida/Meningocele\n1 Hydrocephalus\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 181-195\nField#\nSize\nField name\n1 Microcephalus\n40 Other CNS Anomalies\n1 Heart Malformations\n40 Other Circ./Resp. Anomalies\n1 Rectal Atresia/Stenosis\n1 Tracheo-Esophageal Fistula/Esophag\n1 Omphalocele/Gastroschisis\n40 Other Gastrointestinal Ano.\n1 Malformed Genitalia\n1 Renal Agenesis\n40 Other Urogenital Anomalies\n1 Cleft Lip/Palate\n1 Polydactyly/Syndactyly/Adactyly\n1 Club Foot\n1 Diaphragmatic Hernia\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 196-210\nField#\nSize\nField name\n40 Other Musculoskeletal/Integumental A\n1 Down's Syndrome\n40 Other Chromosomal Anomalies\n1 No Congenital Anomalies\n40 Other Congenital Anomalies\nCODE STRIP\n1 Record Complete YN\n1 Record Type\n4 Facility ID\n4 City of Birth\n3 County of Birth\n2 Mother's State of Birth\n2 Mother's State of Residence\n4 Mother's Town of Residence\n3 Mother's County of Residence\n2 Father's State of Birth\n\nTypical Electronic Birth Certificate Fields\nin 1999 -starting fields 211-226.\nField#\nSize\nField name\n14 Certifier's License Number\n6 Laboratory ID Number\n4 Mother Xfer Code\n3 Mother Xfer County Code\n4 Baby Xfer Code\n3 Baby Xfer County Code\n4 Year of Birth\n7 Certificate #\n1 Unique Code\n8 File Date\n2 Community Area\n4 Census Tract\n2 Century of Last Live Birth\n2 Century of Last Termination\n2 Century of Last Menses\n2 Century of Blood Test\n\nFour vignettes\n- Everyone can snoop\n- What they have on you\n- Getting sensitive information from public data\n- Do-it-yourself identity theft\n\nDe-identified records\n\nTwo separate data bases\nDe-identified medical research database\nVoter registration list\n\nRe-identification\nFind records with\nthe same values\nin the overlapping\nfields\n\n{date of birth, gender, 5-digit ZIP}\nuniquely identifies 87.1% of USA pop.\n\nArkansas Juvenile Offender Records\nWhite, Female,\nDOB 1979, April 9\n\nFour vignettes\n- Everyone can snoop\n- What they have on you\n- Getting sensitive information from public data\n- Do-it-yourself identity theft\n\nStudent\napplication\nBasic\ninformation\nand School\nInformation\n\nBasic Information Necessary\nFor a Credit Card Application\n- Name\n- Social Security number\n- Address\n- Date of birth\n- Mother's maiden name\nDo these\nfirst.\nIf one can identify these fields for a person, they have\nthe basic information needed to acquire a credit card in\nthat person's name.\n\nHistorical Highlights of the SSN\n- 1935 Social Security Act\nSSNs only to be used for the social security program.\n- 1943 Executive Order 9397\nRequired federal agencies to use SSNs in new record systems\n- 1961 IRS began using SSN\nAs taxpayer identification number\n- 1974 Privacy Act\nGovernment agencies use of SSN required authorization\nand disclosures (exempt agencies already using SSN)\n- 1976 Tax Reform Act\nGranted authority to State and local governments to use\nSSNs: state and local taxes, motor vehicle agencies\n-Over 400 million different numbers have been issued.\nSource: Social Security Administration, http://www.ssa.gov/history/hfaq.html\n\nQuality of the SSN Assignment\nAbility to acquire the number and use it falsely grows\nas more copies of the number are stored for different\npurposes while possible benefits of misuse have\nrewards (even if illegal).\nA Social Security number is almost always specific to\none person and one person typically has a unique\nSSN. There are exceptions.\n\nUnusual case of SSN 078-05-1120\nUsed by thousands of People\nIn 1938, a wallet manufacturer provided a sample SSN\ncard, inserted in each new wallet.\nThe company's Vice President used the actual SSN of his\nsecretary, Mrs. Hilda Schrader Whitcher.\nThe wallet was sold by Woolworth and other stores. Even\nthough it had the word \"specimen\" written across the face,\nmany purchasers of the wallet adopted the SSN as their\nown. In the peak year of 1943, 5,755 people were using it.\nSSA voided the number. (Mrs. Whitcher was given a new\nnumber.) In total, over 40,000 people reported this as their\nSSN. As late as 1977, 12 people were still using it.\nSource: Social Security Administration, http://www.ssa.gov/history/ssn/misused.html\n\nSSNs are Encoded Numbers\nThe encoding is based on how the numbers are\nissued. They typically situate the recipient in a\ngeographical area within a time range. They\nmay also reveal whether the person is an\nimmigrant, an alien, or a worker on the railroad.\nFormat: AAA-GG-NNNN\nAAA is area code\nGG is group code\nNNNN is serially assigned number\n\nFirst 3 digits Provide the State of\nIssuance, 1\n001-003 New Hampshire\n004-007 Maine\n008-009 Vermont\n010-034 Massachusetts\n035-039 Rhode Island\n040-049 Connecticut\n050-134 New York\n135-158 New Jersey\n159-211 Pennsylvania\n212-220 Maryland\n221-222 Delaware\n223-231 Virginia\n691-699*\n232-236 West Virginia\n232 North Carolina\n237-246\n681-690\n247-251 South Carolina\n654-658\n252-260 Georgia\n667-675\n261-267 Florida\n589-595\n766-772\n268-302 Ohio\n303-317 Indiana\nSource: Social Security Administration, http://www.ssa.gov/foia/stateweb.html\n\nFirst 3 digits Provide the State of\nIssuance, 2\n318-361 Illinois\n362-386 Michigan\n387-399 Wisconsin\n400-407 Kentucky\n408-415 Tennessee\n756-763*\n416-424 Alabama\n425-428 Mississippi\n587-588\n752-755*\n429-432 Arkansas\n676-679\n433-439 Louisiana\n659-665\n440-448 Oklahoma\n449-467 Texas\n627-645\n468-477 Minnesota\n478-485 Iowa\n486-500 Missouri\n501-502 North Dakota\n503-504 South Dakota\n505-508 Nebraska\n509-515 Kansas\nSource: Social Security Administration, http://www.ssa.gov/foia/stateweb.html\n\nFirst 3 digits Provide the State of\nIssuance, 3\n516-517 Montana\n518-519 Idaho\n520 Wyoming\n521-524 Colorado\n650-653\n525,585 New Mexico\n648-649\n526-527 Arizona\n600-601\n764-765\n528-529 Utah\n646-647\n530 Nevada\n531-539 Washington\n540-544 Oregon\n545-573 California\n602-626\n574 Alaska\n575-576 Hawaii\n750-751*\n577-579 District of Columbia\n580 Virgin Islands\nSource: Social Security Administration, http://www.ssa.gov/foia/stateweb.html\n\nFirst 3 digits Provide the State of\nIssuance, 4\n580-584 Puerto Rico\n596-599\n586 Guam\n586 American Samoa\n586 Philippine Islands\n700-728 Railroad Board**\n* Some states may share the same area by transfer or split.\n** Railroad employees, discontinued July 1, 1963.\n000 will NEVER start a valid SSN.\nSource: Social Security Administration, http://www.ssa.gov/foia/stateweb.html\n\nSSNs are Encoded Numbers\nFormat: AAA-GG-NNNN\nThe encoding is based on how the numbers are\nissued. They typically situate the recipient in a\ngeographical area within a time range. They\nmay also reveal whether the person is an\nimmigrant, an alien, or a worker on the railroad.\nAAA is area code\nGG is group code\nNNNN is serially assigned number\n\nDigits 4 and 5, Order of Issuance\nCalled the Group numbers. Not assigned\nsequentially, but in the following order:\nODD - 01, 03, 05, 07, 09\nEVEN - 10 to 98\nAfter all in 98 are assigned, then\nEVEN - 02, 04, 06, 08\nODD - 11 to 99\nSource: Social Security Administration, http://www.ssa.gov/foia/ssnweb.html\n\nResult\nKnowing where the SSN was assigned\ntells you the digits 1-3\nKnowing when the SSN was assigned\ntells you digits 4-5\nSource: Social Security Administration, http://www.ssa.gov/foia/ssnweb.html\n\nQuiz\n- Name a problem with the SSN as an identifier\n\nOne Approach is to Buy an SSN\nhttp://socialsecuritypeoplesearch.com/index.asp\n\nOne Approach is to Buy an SSN\nhttp://socialsecuritypeoplesearch.com/index.asp\n\nReportedly Permissible Purposes for\nPurchasing an SSN On-line, 1\nhttp://socialsecuritypeoplesearch.com/index.asp\nLocating Missing Persons\nChild Support Enforcement\nSkip Tracing\nCollections\nPeople Locator Service\nLocating Alumni\nOther Legal, Normal Business Use\nJudgement on Subject\nApprehending Criminals\nLaw Firm -Fiduciary Interest\n\nReportedly Permissible Purposes for\nPurchasing an SSN On-line, 2\nhttp://socialsecuritypeoplesearch.com/index.asp\nLegal Process Service\nLegal Research\nFinding Owners of Unclaimed Goods\nFraud and Loss Prevention\nGovernment Agency\nInsurance Claims Investigations\nInvestigation of Civil Litigation\nJournalistic Endeavors\nLaw Enforcement\nLicensed PI\n\nReportedly Permissible Purposes for\nPurchasing an SSN On-line, 3\nhttp://socialsecuritypeoplesearch.com/index.asp\nLocate Former Patients (Medical Industry Only)\nLocating Beneficiaries and Heirs\nLocating Existing Customers\nLocating Former Customers\nLocating Former Employees\nLocating Fraud Victims\nLocating Pension Fund Beneficiaries\nNecessary to Complete Transaction\nPermission from Subject\nProduct Recalls\n\nReportedly Permissible Purposes for\nPurchasing an SSN On-line, 4\nhttp://socialsecuritypeoplesearch.com/index.asp\nResolve Customer Disputes\nSearch on Myself\nTo give to a Court of Law\nWitness and Victim Locating\nAsset Identification\nCourt Related\n\nAnother approach is to use Google\n- People posting their own SSNs\n- Professors posting their students SSNs\nhttp://socialsecuritypeoplesearch.com/index.asp\n\nStudent\napplication\nBasic\ninformation\nand School\nInformation\n\nPublicly Available Birth Records\nNot all states, but many consider birth records,\nthe kind of information included on a person's\nbirth certificate in the United States, as publicly\navailable information.\nA few states have gone further to provide this\ninformation on-line.\nIn the United States, birth certificate information\ntends to include the mother's maiden name!\n\nCalifornia on-line Birth Records\nResults of search on 'Jones'\nSource: http://www.vitalsearch-ca.com/gen/_nonmembers/ca/_vitals/cabirths-nopsm.htm\n\nStudent\napplication\nBasic\ninformation\nand School\nInformation"
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec10.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/810b81fecfcb9f06167fc322b2812c5f_6805_lec10.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 9: Personal Information on the Web\n\nLecturer: Hal Abelson\n\nPersonal Information on the Web\n1. Everyone can snoop\n2. What they have on you\n3. Having sensitive information about you\n4. Identity theft\n\nGeorge Washington Camera exercise\n\nWe are sort of in the middle as it relates to privacy. It hasn't quite gelled yet, and\nyou can put up cameras and put it up and run it through face recognition programs\nand put it on the Web.\n\nA. How many people used to think that it was creepy to go on the Internet and\nfind the map of your house?\n1. This was about 10 years or so ago.\n2. Hal did this to someone with information found about her neighbors\nand honors on the Internet. She was totally freaked.\n3. As long as you stay away from medical records and TV video rental\nrecords. These are protected. This is very different from the policies\nin Europe.\n\nB. How many people believe MIT should put up web cams?\n1. Is there a benefit? Maybe. Maybe not. Just to show that it's cool, say\nfor advertising that you should consider coming to a particular school.\n2. Some students don't see a problem with using just one web camera,\nbut sees privacy issues when you have several because then you can\ntrack an individual's everyday movement.\n3. The problem comes in with asymmetric use. Say when you don't know\nthat you are being watched. Transparency issues.\n4. Another problem is how is the video capture or web cam being used.\n5. Also the issue of integrity issue. For instance delaying the feed and\nmanipulating the images.\n\nA. Desktop Spyware\n1. Desktop Snooper - www.snooperspyware.com\n2. Desktop spyware issues\ni. hidden camera that looks at any computer you choose\nii. marketing says that this type of software is about\nprotecting your children\n3. Latest news is SONY software that limits the number of copies and\nSony didn't tell you that this is what was being done. The software is\nalso very difficult to remove.\n\nC. Global Storage per person (graph)\n1. Latonya Sweeney, MIT grad, went on to document the amount of\nStorage needed to document a person's activities, etc.\n\n2. In 2000, Basically enough storage around the world to store\ninformation every 3.5 minute about a person.\n3. MA - Fields on an electronic birth certificate now (1999)\na. Also lists things like \"number of birth terminations\"\nb. Up to 226 fields recorded for every birth in Massachusetts\n\nD. O'Harra's book\n\n1. ChoicePoint\n\n2. Axciom - does thing to help employers?\n\nD. Harvard News\n1. The way that Harvard bills for medicine is by your student ID. The\ncompany that used the student IDs also recorded the drugs they\nordered from Harvard medical service.\n2. Student organization had a survey which linked the names and IDs.\n3. The company actually put up the ID information on a public server.\nClaimed they didn't do anything wrong because they were de-\nidentified.\n\nE. De-Indentification\n1. Confidential information - birthdate, sex, ethnicity\na. we don't want this information to get out, so we remove the\nnames\n2. De-identified records with zip code information or overlapping fields\nactually narrow down the possibilities of the particular individual\nmaking it easier to identify.\n3. Uniquely identifying individuals\na. Latonya Sweeney research\nb. Date of birth, gender, and 5-digit zip code uniquely identifies\nalmost 90% of the USA population\n4. Arkansas Juvenile Offender Records\na. The encoding used can significantly narrow down your\nselection of possible individuals.\n\nF. Identity Theft\n1. Exercise - Applying for a SSN\n2. Was created originally to use only for social security program (1935)\n3. Later the SSN became a \"unique\" identifier\na. first 3 numbers tell the state you were born in\n-\n000 will never start a valid SSN number\nb. digits 4 and 5 are known as group codes - this tells you when\nthe SSN was assigned\nc. Name a problem with the SSN identifier\n-\nallows you to falsify one easily\n-\nyou can buy a SSN (socialsecuritypeoplesearch.com).\nHowever you must have a valid reason for locating the\nSSN of the person.\n-\nUse Google. People post their own SSNs on the web.\n-\nProfessors publish the last 6 digits of a student's SSN\nwith their respective grades. Bad idea.\n-\nEDGAR database\n-\nSEC database - Turned out to be very easy to find SSN\nof rich people including Bill Gates\n\n4. Are birth records public?\na. On Vital Search in CA, you can look up birth records that\ninclude the mother's maiden name\n\nG. Social Security Death Index\n1. Turns out that dead people really don't have any rights\n\nThe above items are all on public records and can be used to examine identity\ntheft.\n\nH. People don't get how their personal information spreads. There is a difference\nbetween the friendly, neighborhood pharmacist and the large databases.\nI. There is a transition that the government needs to make and consumers need\nto enforce in finding a more secure system for identifying individuals. The\ncurrent system of SSNs and personal information is not secure enough.\n\nFor the rest of the class, we will have a Presidential Commission that will convene a\nsummit to rectify the SSN problem.\n\nExercise: World Summit on Identity Theft\n\nHow should we fix the identity problem?\n\nPanel 1: Consumers Union, ACLU, etc.\n1. Very difficult to prove that you are not the alleged impersonator, and it is\nvery difficult to correct false information in a database.\n2. Problems stem from 70-year old system and reuse of SSNs.\n3. Propose unique issue of SSN-like identifier (10 digits) that accompanies\npresent SSN. Numbers will be randomly generated, linked to biometric data\nand not associated with personal info.\n4. For information to be released, the individual must give consent. Any\norganization or company that doesn't comply, will be fined $1000 for each\nform of personal information.\n\nPanel 2: Massachusetts State Police, Federal Trade Commission, etc.\n1. Problem that confounds law enforcement agencies and poses threat to\ninterstate commerce\n2. USB key that will be given with the license registration\n3. This will be better for identifying individuals\n4. If key is lost, there is a 24-hour hotline to call. This will be no more expensive\nthan operating a credit card customer service.\n5. To retrieve a new USB key, then you must go to DMV and present 3 forms of\nID.\n\nPanel 3: VISA, and other financial ad insurance industries\n1. Integral part of nation's commerce\n2. Need access to certain information to provide services accurately (credit\nreport, birth date, etc.)\n3. Propose centralized database with limited information, keeping competition\nopen.\n\n4. Goal of database is to use as a reference and correctly verify that a person is\nwho they say they are.\n5. Another party will maintain the database.\n\nPanel 4: eBay, Amazon, WalMart and other private sectors\n1. New unique identifier system needs to be cheap. We don't want to pay for\nthem and the consumer shouldn't have to pay for them.\n2. Those that issue the identifier should pay for it.\n3. We don't want restrictive laws about how we can share data.\n4. More or less, the system is fine as is. Any new solution should not hurt the\nconsumer's purchasing power and our profits.\n\nPanel 5: Equifax, Experian, Acxiom, and other background-check and employment\nrecords industry\n1. Every individual has a cryptographic card that has a personal identifier where\nthey are required to sign\n2. Two layers of security. (1) No one knows the personal identifier in the card,\nand (2) if the card is stolen, then you have to answer a secret question\n3. The government will issue the cards. Must have 3 separate forms of ID\n(similar to receiving driving license.)\n4. Helps with accuracy and security of information.\n5. Willing to lose some money in order to gain security.\n\nOther concerns\n1. Name changes but no identity theft\n2. Changes in physical identity\n\nDeliberations of committee occurs."
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec11.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/99abe8c25714373878d1e3412939361f_6805_lec11.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 11: Origins of Broadcast Regulation\n\nLecturer: Hal Abelson\n\nSex, Drugs, and Rock and Roll (How Metaphor becomes law: the origins of\nbroadcast regulation)\n\nThis lecture is mostly about the history and regulation of communication and\nthe metaphors that have shaped the law and technology behind it.\n\nI.\nDrugs\nA. \"Puff the Magic Dragon\" - do not playlist in 1971\nB. FCC went after popular music for promoting drugs and then\nwent out to the \"experts\" (US Army)\nC. 27 songs ended up on do not playlist\n1. Colleges (newspapers, organizations) were asked not to\nplay these songs on the playlist\n2. Yale sued and lost\nII.\nMedia that are regulated\nA. Broadcast and TV\nB. Books and Newspapers\nC. Uncle Fester\n1. Don't remember real name\n2. Wrote about how to manufacture methamphetamine\nand published his books - bad stuff\nD. Government tried to figure out where the Internet should fit\n1. New technology usually introduces new laws, so\nmetaphors are what eventually end up becoming law\n2. From 1995-2001 the metaphor changed from weapons\nto protecting from credit card fraud and encryption\ntechnology\nIII.\nThe Power of Metaphor in Broadcast Regulation\n-\nthink about the real policy and parallels of how\ntechnology and laws evolve\nA. Titantic sinking (April 15, 1912)\n1. Beginning of radio. The Navy was using radio to send\ncommunication\n2. Navy was pretty upset because of hackers and also Marcony\ncompany\n3. Marcony - commercial interest of wireless telegraphy.\nCompany complained that business was being hurt by\noutside unregulated stations\n4. As Titantic sunk, one radio room survived intact\n5. Carpathia ship was 10 miles away from Titantic, but the\nradio operators were not required to keep radio on all the\ntime\n\nB. Congress acts\n1. Alignment of military and commercial interests\n2. Huge Public interest\n3. Hearings were run by William Alden Smith and decided that\nthe real disaster was in the lack of radio communication\n4. Smith suggested that Congress enact radio regulations and\nhelped enact the Radio Act of 1912\nC. Radio Act of 1912\n1. Used Titantic disaster to saturate air waves\n2. no one could broadcast without license\n3. permissible frequencies\n4. military got excellent frequencies\n5. commercial shipping and commercial use\n6. amateurs were banned from \"useful\" frequencies and\nregulated to technological unusable frequencies\n7. Metaphor - Congress regulates where shipping lanes or\nfrequencies are\nD. Post Radio Act\n1. 1914 - 1918 considered Golden Years\n2. 1919 - ran radio as govt-sanctioned monopoly\n3. Hoover became interested in broadcasting and make a band\nfor commercial broadcasting\n4. 1920 - broadcast of Presidential Election\n5. 1921 - broadcast of World Series. There were 5 broadcast\nstations in the U.S.\n6. 1922 - There were 576 broadcast stations and the\nbroadband space was full so Hoover expanded it.\n7. Intercity Radio sued because license was denied and Hoover\nlost\n8. Courts ruled that only had the power to regulate shipping\nlanes not choose who could use, so band was expanded it\nagain\nE. Broadcasting Spectrum\n1. Hoover spoke of it as a \"great national asset\" and \"public\ninterest to say who is to do the broadcasting.\"\n2. Zenith and GE frequency dispute\na. Companies switched to Canadian frequency but were\nfined\nb. Sued and won\n3. 1926 - Court came down hard on Hoover about regulating\npower\n4. 1927 - Radio chaos. Hoover was out of the regulation\nbusiness\nF. Radio Act of 1927\n1. Congress passes their own regulation and a reversal in\nprinciple\n2. Spectrum is now owned by the public and is in the public\ninterest. Licensed by FRC (Federal Radio Commission)\n\n3. successor was the Communications Act of 1934 and FRC\nbecame FCC\n4. Act was a consequence of avoiding interference since the\nspectrum was a scare resource. So government impounds\nradio broadcasting\n5. Public Interest Standard - although strong regulation, will\nnot interfere with free speech and no offensive content to be\nbroadcast\n\nIV. Sex\nG. John Romulus Brinkley\n1. bought a medical degree from a university in Kansas\n2. opened up practice and observed frisky goats\n3. Brinkley transplanted goat testicle into patient with erectile\ndysfunction\n4. 1923 - starts Radio Station KFKB (Kansas First, Kansas Best)\na. Broadcasts goat gland transplants and offers medical\nadvice\nb. Was most popular station in 1930 (4 times as\npopular)\nc. American Medical Society was unhappy at popularity\nof station\n5. In 1930, Brinkley lost medical license and broadcast license\nfrom FCC\n6. Court rules against him and FCC states that since the\nfrequencies are limited, the character and quality of the\nservice rendered must be considered Æ Hence license was\nrevoked\n7. Traveled to Mexico to practice and ran for governor of\nKansas\n8. This was the genesis of broadcast regulation and the court\ncase NBC vs. U.S.\nH. NBC vs. U.S.\n1. Stricter regulation of broadcast since it is limited and is\nunlike other modes of expression like books and print since a\nresponse may also be limited\n2. Red Lion Broadcasting v. FCC\na. Equal response time\n3. spectrum not large enough to accommodate everybody -\nlater proven to be false\nI. Land\n1. national resource that the government owns - National Parks\nSystem\n2. metaphor - radio and broadcast regulation sprung up and is\nsimilar to government regulation of Parks system\nJ. Internet\n1. making the different modes of media communication collide\nto the same thing\n\nK. Hedy Lamaar\n1. born in 1914 and was child actor\n2. at the age of 19, was first woman to appear nude in a\nfeature film Ectasy\n3. she was to be the hostess for Mandl's parties in Vienna and\nentertain his business friends.\n4. husband Mandl was extremely jealous; later fled to London\nand divorced Mandl\n5. Louis Mayer and Hollywood\na. meets her in London and takes her to Hollywood. He\nwas stunned with her beauty\nL. George Antheil\n1. child prodigy and patron was Chris Bach (?)\n2. became pretty famous composor in the 1920s\n3. most famous composition - compromised of player pianos\nand airplane propellers\n4. wrote scores for John Wang movies and others\n5. In Hollywood, he copyrighted \"See-Note\" system of musical\nnotation\n6. also really interested in endocrinology and glands\nM. Lamaar and Antheil meet\n1. in 1940 at a dinner party in Hollywood\n2. Lamaar asks about hormones and breast enlargement\n3. Lamaar wants to quit Hollywood and wants to offer services\nto National Inventor's Council\n4. Both were very patriotic and wanted to help the war effort.\nLamaar wanted to know more about torpedoes\n5. Torpedoes were controlled by frequencies and ships would\nlisten to see if they could jam the enemy's torpedoes\n6. Lamaar had an idea of shifting frequencies to prevent\ntorpedo jamming\n7. Antheil had the solution of using piano keys to control\nfrequency jumps\nN. Fate of the Invention\n1. Lamar and Antheil give patent to Navy but never implements\nit probably because they were thinking you need to put\nplayer pianos on torpedoes\n2. In 1950, electronic control became possible\n3. Heavily used in Cuban Missile Crisis (1962)\n4. In 1997, Lamaar and Antheil were recognized with Pioneer\nAward for their work\nO. Corel Draw contest\n1. winning entry was an image created using Corel 8 and of\nLamaar\n2. She sued for $15M but received $5M\n\nAll the history and inventions are based on metaphors. Now we take it\nas commonplace, but the metaphors are not real. We are busy\ninventing and reinventing these metaphors with the Internet and new\ntechnology.\n\nWe have the opportunity to look beyond the metaphors and create\nnew metaphors."
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec12.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/caf492383b0882fe80cbfbe4374abe55_6805_lec12.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 12: Semantic Web Public Policy Challenges\n\nLecturer: Danny Weitzner\n\nSemantic Web Public Policy Challenges: Privacy, Provenance, Property and\nPersonhood\n\nToday we will spend time discussing the work that Hal and Danny have been\ninvolved in and topics we have been discussing in this course. Also look at public\npolicy perspective on Internet Infrastructure and how this has affected the design of\nWWW.\n\nI.\nOverview\nA. Privacy issues\nB. Property\nC. Provenance - where information comes from and if we should trust it\nor not\n(Diagram on slide 4)\n\nII.\nPersonal philosophy\nA. Technology is a mess\nB. General view - law needs to catch up to technology\n\nIII.\nLaws\nA. We just understand what to do (like languages) that we mostly follow\nmost of the time and do the right thing without these laws being right\nin front of our face.\nB. The web is kinda weird with respect to laws\ni. We buy and sell without knowing the parties and don't easily\nknow the privacy and the protection affording us\nii. The nature of the web does not make it easy for us to know the\nlaws\niii. The technology is helping the environments to adapt so we can\nknow what to do and what not to do\niv. Lot of what people have tried to do is \"ex ante policy\nenforcement barriers\" to prevent people from doing activities or\nto enforce certain rules\nv. The focus should be to communicate to the users how to\ncomply to rules as opposed to prevent us from not complying\nIV.\nPrivacy Shifts\nA. Most intrusions that we should be concerned about should be based on\nthe inferences drawn after the fact not from the practices and\ninformation collected and done at the time\nB. Examples\ni. Credit card transactions Æ profiling\nii. Web logs Æ web search patterns\n(people are becoming more concerned about how people use\ntheir logs and look at how we search the web, think Google)\niii. instantaneous location Æ travel paterns\nC. there are very few collection barriers in the U.S., but more focus on\nputting rules in place as to how we will use the data and a usage\n\ndescription with accountability. We actually haven't decided on the\nnature\ni. RIAA - \"after the fact\" rules for music downloads\n\nV.\nProvenance\nA. Centralized Approach - Since modern press, have centralized\nmechanisms for how we share the information and editorial\ni. Newspaper - upfront filter for things posted in the news\nii. Google - search algorithm\na. has really impacted how we view the world\nb. probably no other centralized institution or organization\nhas impacted the world more other than religion\nB. Decentralized Approach - Online news\ni. Allow you to see structured data and metadata\nii. Can apply a trust filter in order to filter information\niii. Some browsers allow you to collect a collection of data and\nthen filter through it (vs. New York Times)\niv. Del.icio.us\n- decentralized approach to sharing search results\n- can choose which individual's view you'd like to see or trust\ndata from\nSo there is a departure from centralized filters to filters that happen in a much more\ndispersed way.\n\nVI.\nProperty\nA. New notions about how to protect intellectual property whether\ntechnically or legally\nB. New model is appearing for content production\ni.\nfrom Hollywood content (centralized production)\nnow to decentralized content we use (Flikr,\nWeblogs, etc.)\nii. Creative commons - open description of licensing\nterms in the hopes that people will follow those\nrules. Now Google and Yahoo allow you to use\nCreative Commons license to filter through their\ndata\niii. Once again a shift from enforcement barriers to\nopen information and sharing on Web\n\nVII.\n2 Models of Personhood\n- Big gaps in Internet Technology is Identity Management\nA. Liberty Alliance & Sun Microsystems have tried to put together a\nreliable trusted identity system\n1.\nmultiple ID info bundles so they can be the \"trusted\" 3RD party\n2.\nvery complicated and hard to know if it will ever work\nB. Decentralized approach\n1. De-referencerable 2nd parties\n\nVIII.\nConclusion\nA. shift from centralized systems to more decentralized approaches\nB. think that the rules in the environment will become more clear to\npeople, thus resulting in more people following the rules\n\nC. need more transparency of the rules and the ability to catch those who\nbreak the rules"
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/683bd6a56b84e82933bf108120b73f65_6805_lec2.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 2: The Internet meets the U.S. Constitution\n\n1994 - Senator Exon introduced a piece of legislator (Section 223)\nSection 223 covered Dial Let services (Sable Communications Act) and\nindecent material and telecommunications services. The Act died down.\n\n1995 - Exon reintroduced act; also announced he was retiring\nExon also a key vote on Senate Budget committee and felt he was entitled to\na retirement present. Clinton's agenda\n\nSenator Exon's agenda came at a time where other agenda's were involved.\n\nThose concerned with CDA:\n1. ACCU, EFT, Planned Parenthood, ALA, ISP, Software/Hardware companies\n\nSupporting Bill:\n1. Christian Coalition\n2. Socially conservative groups\n3. FRC\n4. AFA\n\nThe vote in the senate lasted 1 hour on the floor and the vote was 84-16. The\nstriking thing was that 16 voted against protecting kids against pornography.\n\nNetscape went public in 1995.\n\nSimultaneously in the House: Chris Cox (R-CA) and Ron Wyden (D-Port, OR)\n\nNewt Gingrich told Chris Cox to find a different way to handle the problem.\n\nIFFEA (Internet Family and Freedom Education Act) was introduced.\na. Policy - take regulatory approach, user empowerment\nb. Findings - democratic potential, decentralized"
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/008ba173b6577dc2da32ea73fd2ab6b8_6805_lec4.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 4: Fourth Amendment Foundations and the First\nCentury of Electronic Surveillance\n\nLecturer: Danny Weitzner\n\nFourth Amendment\n\nOver the next few weeks, we will focus on how technical change and technology has\nmanifested itself. We will look at the basics of the 4th Amendment and the\nCommunications Act. We will also examine private activity and a debate over\nencryption technology.\n\nThe 4th Amendment is an enormous body of law. At most law schools, this topic is\ncovered in one or several courses that deal with criminal law.\n\nI.\nHistorical Background\nA. Judicial disputes used to be resolved by the king or queen, but this\nbecame too taxing for the king and queen\nB. Then disputes were delegated to the courts.\nC. Semayne's Case (old English case, 1604) - Jist of story: There was no\nprocess. The bailiff must have some type of notice. (Today this is\ncalled a warrant.) The notice must establish a given reason (probable\ncause). The reason must be announced as to why the search will\noccur.\n\nII.\nFourth Amendment (4A)\n-\nnotice (warrant)\n-\nreason (probable cause)\n-\nannounce (knock and announce)\n-\nproperty (this only extends to your own home or property)\n-------------\n-\ngeneral search or secret\n-------------------------------\n- \"detached and neutral magistrate\"\n\nThe British were always concerned about a secret search going on aimed towards the\ntarget of the search. Wiretapping is an interesting topic because putting the above\nmechanisms in place will jeopardize evidence.\n\nThis announce and knock clause was to the benefit of the person being asked to\nhave his property searched. It is assumed that the person will open his door\nvoluntarily.\n\nThese fundamental things form the basis of the 4th Amendment, which is the law of\nsearch and seizure.\n\nReal action in this case refers to real property.\n\nCommunications Privacy\n\nWe will look at how this extends to Communications Privacy.\n\nCommunications Privacy -\n1. distinct from search and seizure law\n2. also distinct from information data policy\n\n*Note: This is about communications privacy and does not extend to information\npolicy. This is a narrow focus.\n\nAs we work through the evolution of law, hopefully you will see how law enforcement\nand the judicial system use these methods.\n\nOlmstead vs. United States\n\nThe 5th Amendment process crosses the 4th Amendment line in the Boyd case. Chief\nJustice Taft ends the discussion with the case ex party Jackson. Telephones didn't\nhave the constitutional status like the mail did at this time. In Jackson, the mail was\nconsidered your property or documents, and it was expected that this mail property\nwould be protected. The expectation was created, so Jackson stated this was\ncovered by your 4th Amendment rights.\n\nprotect\ntech\ncrime\nmetaphors/talismans\n4A\n1928 -\n\nbootlegging\nproperty, trespass\nyes\n1967-68\nPhone\ncause-\nmass market\nTitle III (1968)\nGambling\n\norganized crime\npersons not places\n\n-subjective expectation\n\n-objective expectation\nprobable\n1984-86\nECPA\nemail/elect. Comm.\nstore & forward\n-----\n1st class mail\n\ntransactional\nrecord\nterroism\nreas. artic. susp.\nCALEA\n\nTaft was trying to create an argument that he had hoped would be a progressive\nview of the boundaries of the 4th amendment.\n\nThe dissent:\nJustice Brandeis says this a constitution we are expanding as opposed to the law.\n\nWhat are Brandeis' arguments about the telephone?\nThere is no difference between the telephone and the sealed letter and uses the\nsame cases that Taft cites.\n\nIn the modern court, the majority opinion reserves the right to include the\ndissenter's opinion.\n\nKatz vs. United States\nThis was a case surrounding organized crime.\n\nJ. Edgar Hoover was director of the FBI, but taped lots of people's phones and was\nthought to influence the political process. As a result, since Hoover all FBI directors\nwere judges (except the current director).\n\nGeneral requirement of a \"detached and neutral magistrate\": To get the warrant,\nyou must prove probable cause to a detached, neutral magistrate. Their job is to\naccess whether the need for a warrant is valid.\n\nEven though there is a subjective expectation of privacy, there may be other factors\nthat overrule this expectation. The objective expectation can overrule the subjective\nbecause of the laws of society. Subjective - how they feel, and objective - how far\nthe society is willing to grant permissions. Potter Stuart wrote this opinion.\n\nThe Supreme Court has really changed the whole way that the courts look at the 4th\nAmendment.\n\nPotter Stuart's opinion is pretty accepted but also heavily criticized.\n\nThose that are associated with someone expected of criminal activity also had their\nprivacy violated. So the civil liberties union was opposed to wire tapping.\n\nTitle III sets out a careful set of rules that ultimately end at creating a level of\nprotection beyond the 4th Amendment rights.\n\nTitle III sets out regulations for using wiretapping, which include when other\ninvestigative methods are not working. Other judicial officials must approve the\nwiretaps besides the FBI.\n\nPart of the procedures specify that there are 2 teams that review the discussions of\nwiretap. This is done in real time and procedural safeguards are put into place to\nprotect those that are not the target of the investigation. (i.e. discussion of golf as\nopposed to criminal activity)\n\nThe 4th amendment can be preempted by extensis evidence. Meaning the evidence\nwill vanish or someone will be murdered so must act quickly.\n\nTitle III- Inventory requirement, provision that you will get account of what's going\non either before or after the wiretapping\n\nTitle III was originally authorized for only specified types of crimes- gambling,\nracketeering.\n\nThe process of wiretapping has become cheaper but the wiretaps have gone up.\nHowever, there appears to be only a few wiretap requests that have been rejected.\n\nThe vast majority of wiretapping cases in the 90s were for drug-related criminal\ncases.\n\nIn order to tap a phone there has to be either a Title III court order or FISA court\norder.\n\nThe 4th Amendment applies to U.S. citizens and is regulated within our country.\n\nElectronics Communications Privacy Act\n\nBy the mid 80's, electronic services were becoming popular.\n\nThe communications in the mid 80s were considered store and forward\ncommunications, not wired communications. This application to the 4th Amendment\nlooked questionable.\n\nThe email/electronic communications was treated like 1st class mail and the statute\nECPA was created. This statute is more complicated than the Title III law.\n\nThe technology industry was proactive during this process. There was a trend from a\nsmall number of providers to a much larger number of service providers.\n\nECPA was created because Congress thought that they were following Brandeis'\nprecedence.\n\nThe Electronics Communications Privacy Act (ECPA) applies to mail in transit, or mail\nthat has not yet been received by the addressee.\n\nDoing electronic surveillance is now a lot cheaper than the way it used to be because\nyou are dealing with an electronic data stream. The low cost of storage has changed\nthe dynamics of companies who now choose to keep lots of electronic\ncommunications as opposed to deleting it and figuring out where the data is located.\n\nThe ECPA worked for about 10 years and there was little dispute during the time.\n\nThe cordless phones were oddly left out of Title III and ECPA originally. CALEA closed\nthat gap and addressed a new artifact in internet and digital communication. The\ntransactional record was not being protected in Title III or ECPA.\n\nThe transactional records consisted of the log files (who sent what to whom) as\nopposed to the content. These records consist of the date, time, and some subject\ninformation. The transactional records were subject to a greater access requirement\nthan toll records.\n\nThe Terry vs. Ohio case\n\nSerial window shoppers so this would be considered suspicious. The police officer had\nenough experience (35 years) to have reasonable articulable suspicion that a crime\nmight be taking place or about to take place.\n\nThere is a procedure that law enforcement has to follow in order to intrude on a\nperson's rights and privacy under the 4th amendment.\n\nThe court orders that use this metaphor from Terry vs. Ohio must do so ex parte."
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/157ba780cd36359897fcec12de547195_6805_lec5.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 5: International Issues\n\nLecturer: Mike Fischer\n\nprivacyinternational.org - does a survey of court cases that come up and is an\ninteresting way to chart things\n\nUK - has been narrowing the international differences\n\nCreating an environment for the internet, there are 4 unique tools:\n1. Market\n2. Code or architecture\n3. law\n4. Norms or standards\n\nThe norms are what we will focus on:\n\nIn China, they try to use the code/architecture to exercise control. (International\nDiagram here)\n\nSingapore is one of the most technologically advanced in the world and has the\nappropriate infrastructure to set up appropriate laws and regulations.\n\nCompuServe case in Munich\n-\nprosecution for transmitting pornography\n\nAkamai - various servers located throughout world in various geographical locations\n-\nthis makes removing content offensive to specific countries accessible and\neasily identifiable\n\nCan you block off some parts of the Internet to certain countries?\n\nThree components of moral rights: attribution, no false attribution or authorship,\nprevent others from modifying, destroying, or interfering with the integrity of the\nwork\n\nMoral rights - inalienable rights and deal with human rights laws\nCase: Waiting for Godo\n\nCultural rights - access\n-\nMawry vs. Lego case\n-\nHarminozation makes sure that Lego wins in this kinds of cases. Also free\ntrade agreements.\n\nIn this class, the legal system can be thought of in terms of a Venn diagram.\n\n#######\nSnapshots of different parts of the world to look at their struggles around digital\ncommons and the Internet:\n(Guest lecturers)\n\nPresentation: Anita Chan\n\nLatin America: free software development in Latin American countries. The struggle\nis also around the citizenship and society is demanding that countries provide or\nmandate free software use from administration\n\nReasons governmnet will cite for implementing free software:\n-\nfree software has financial incentive - is cheaper and more sustainable in\nLatin American countries.\n-\nCan lock in with single service provider\n-\nNo longer exorbant rates\n-\nPromote digital literacy\n-\nLocal industry can be strengthened\n\nCases site that consumer has a right to access to information and privacy.\n\nScandals around voting fraud happen on a semi -regular basis.\n\nIn many of these countries, there is free software in use, but who has access to\nthese tools is the real question and how to legislate it.\n\nGov. training programs also have to do with training. Free software movements can\nbe traced as a rise to the liberal policy. Free software programmers see themselves\nas having a part in the digitization of the world.\n\nSoftware development across institutions will hopefully be sahred.\n\nConstant PC project was launched. Lots of development within Brazilian universities.\n\nThere are lots of bodies working around the development of free software. However\ncitizens that are free software users and developers are most important in pushing\nthis forward.\nSovereignty rights - citizens accountability by and access to training (Brazilian\nexample)\n\n#######\nKelty & Punt Culture - What are the norms between culture and legality?\n\nWhat are the creative common licenses? There are various levels of licenses that you\ncan choose to associate with your work or property. There are about 12 different\nmodes.\n\nWhere do the ideas of the different licenses come from? Brown describes this result\nof licenses as the outcome of discussions from different groups he spoke with. He\nand Chris Kelty argue that they are \"operationalizing culture\" in terms of copyright.\nThis is somewhat enforceable.\n\nPresentation:\n\nIndia\nOpenSource Sharing on Proprietary Software\n\nThere is an idea of middle space between commercial property and government\nproperty. The split makes up civil society.\n\nFocus on the structural split and how the practices of architecture and software have\naffected the city of Bombay.\n\nCRIT (Collective Resources Interactive Toolkit) ?\n\nSoftware industry - there is a small elite group that have the software and those\nbecome the pirates because others are priced out. This is also similar in architecture\nas well.\n\nThe citizens don't have the information so they end up having to pay for it.\n\nfreemap.in : website to review\n\nThe laws in India are much more porous and are not as serious.\n\nTop down things don't work in India, that's what the independence was about. This\nis also the difference in architecture between China and India. Top-down approach\nvs. bottom-up approach.\n\n#####\n\nGuest Presentation:\n\nIran:\n\nIran has been going through a whole series of revolutionary acts to get the\ngovernment to a diplomacy. In the late 1970's, there were revolutions to usurp the\nmonarchy that had taken over the citizen's rights.\n\nThe politics of Iran are still stuck in a dual power structure. Since the revolution, we\nare now up to the 7th Parliament.\n\nThe Quoran is not used to derive at the legal structure of the Iranian society. There\nis a split struggle between appeals to an Islamic religion and to the historical views\nof the constitution.\n\nThe gov. does things extra-legally. There are periods when consecutive newspapers\nget shut down.\n\nCyberlaws and Hacking\n\nThere is a need for regulatory laws on hacking and content on the Internet\n(pornography, etc.)\n\nThere are 3 bills being deliberated in the Iranian Parliament. All deliberations have\nto be public.\n\n1. cyber crime bill - presented to Parliament 2 months ago, but has not been\ndiscussed\n\n- deals with hacking, access to classified information, age distinction on the\nprovision of inappropriate content to certain groups (ie. minors); libel and\ndiscredit person's character\n2. freedom of information - strong promoter of VP Affairs\n- idea to promote democracy and transparency; citizens have access to\ninformation with being questioned and is free to criticize gov. behavior with\npenalty\n3. privacy protection - surveillance\n-\nevery kind of search and seizure; illegal to wire tap and track without warrant\n\nIran is also supporting its own filtering software material"
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec6.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/5c95ab96eed727930653535a6596f21f_6805_lec6.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 6: Technology-driven Public-Private\nBoundary Shifts\n\nLecturer: Hal Abelson\n\nEncryption\n\nReview of how encryption technology works. We will discuss the period of 1980 -\n2001 really transformed a military, weapons technology to an everyday\ncommonplace use. Really think about encryption as a policy stresses that are related\nto introduces new technology.\n\nPitfalls of tech and policy\n\n-The word \"privacy\" has certain associations you make to it, none of them has the\ninternet really associated with it.\n\n-\nAbout 10 yrs. ago the word \"electronic mail\" had no real meaning because no\none really used it.\n-\nThe image of a trusted mail carrier is not the image that we have when we\nspeak of electronic mail and encryption\n\nConfidentiality - you care about only the intended recipient receives the message\nAuthentication\nIntegrity - how do you know that someone didn't intercept the message and\nNon-repudiation - can't later deny that you received the message\n\nThis is a review for those that took encryption.\n\nThese are referred to as digital signatures\n\n1. Pre-historic cryptography (pre 1970s):\n2. Public key\n3. Policy of cryptography\n\nCryptography ca 1900 BC\n\nThis is the earliest believed formed of cryptography that people have found--\nheiroglyphics.\n\nGeoffrey Chaucer was a poet and astronomer. Also wrote the first scientific manual\nin English Treatise on the Astrolabe. In part of this book, he encrypted. (class\nexercise)\n\nChaucer used a format called the substitution cipher. Simple or monoalphabetic\nsubstitution occurs when you always replace in the same way.\n\nJulius Ceasar used substitution cipher where you shift everything by the same length\nto substitute.\n\nIn the 9th century, Yaqub wrote a book now know as Frequency analysis. (Graph of\naverage frequency of letters in English.)\n\nThis is a technique since the 9th century.\n\nA thousand years later, this form of encryption was still being used which is amazing.\nPeople still use insecure methods of encryption. If you go on the Internet (less than\n5 years ago), some companies are still marketing insecure or bad encryption\nproducts.\n\n*Vigenere Encryption\n\nVigenere popularized this type of encryption, but it was actually created by Alberti.\n\nThe blue letters are the key. \"a\" goes to \"S\", b goes to \"O\"....and you cycle through\neach substitution.\n\nThis turned out to be a major breakthrough in encryption for 500 years, and was\nconsidered to be the unbreakable encryption scheme. In fact, it was broken in the\nmiddle of the 19th century.\n\n*Breaking Vigenere\nTurn this into n-different frequency distribution problems since the English language\nhas a natural length.\n\nThe hard part is finding the length of the key.\n\nAt the end of the 1920's, most countries had black-jammers that were math\nchambers to break encryption.\n\nFriedman invented the Index of Coincidence to break the encryption. Nobody knew\nthat Babbage had actually broken the Vigenere code until the 1920s since he didn't\nannounce that he broke it.\n\nMany people that do the work actually don't get the credit because their work ends\nup being classified.\n\nKey is as long as the message - one time pad\n\nOnly proven secure encryption is the one-time pad, provided that you choose the key\nrandomly and use it only once. But work is being done currently to find something\nmore secure.\n\nThe Venona Project originated in 1943. Lots of examples of the one-time pad.\n\nClaude Shannon - hero of information theory\nShannon invented the word the \"bit.\"\n\nShannon also made the first formal definition of what it means to be secure, or\nencryption.\n\nResults of \"Perfect Secrecy\" from Shannon's 1949 paper.\n\nThe really classified things right now are the ways and methods to generate random\npads. It's actually hard to make really good one-time pads.\n\nThere's now a stream encryption that we use today that is the bit analog of\nVigenere.\n\nDES (Data Encryption Standard) is now becoming obsolete. The NSA tweaked the\nalgorithm to make it more secure. For DES, you break the message into blocks of\n64-bits and then do an S-box transformation (based on a 56-bit key) and then put it\nback together. This is pretty efficient since it is just scrambling and can be easily be\ndecoded. Nicely designed so easy to undo.\n\nSecurity of DES:\nThe only way to crack it is basically brute force. Try all the keys! In 1965, 2^56 was\na pretty large number of keys. Not so much now.\n\nThe gov. was strong-arming people to discouraging using anything other than DES.\nNIST (National Institute of Standards and Technology).\n\nKerkhoffs's Principle:\nArticulated by Belgium linguist that wrote a guidebook on the good properties of\ncryptographic systems. One of the principles is design the system so that only a tiny\nbit of information that needs to be secure, then this is a better design. The security\nshould reside in the choice of key rather than in obscure design features.\n\nAndrew \"Bunnie\" Huang - broke the encryption on the XBox. Digital Millenium\nCopyright Act prevents people from publishing or disseminating information about\ncopyrightable material.\n\nThese early encryption principles don't work well for the internet.\n\nGreat Idea: Can create a shared key with people that have never met before or\nnever communicated and made no prior arrangements.\n\nCryptosystems\nVarious types of attacks:\nChosen plaintext- 300 of the same character\nRubber hose - beat people with the rubber hose\n\nNone of this is adequate for Internet applications because you have to meet to\nexchange the key.\n\nDiffie was an MIT undergrad and met up with Marty Hellman, who was working at\nStanford. Ralph Merkle was a grad student at Berkeley. Merkle was probably the\nperson with the idea behind public-key encryption, but Hellman and Diffie wrote the\nalgorithm. They published the absolute break-through paper in 1976.\n\nOnly about 8 years ago, it was discovered that in 1973-74 Clifford Cocks and\nMalcolm Williamson were doing secret work in the British Intelligence.\n\nBasic Idea of Diffie-Hellman-Merkle:\n\nIdea: How can you exchange secret information even if everyone can hear what you\nsay to one another?\n\nAlice will compute secret information on only what she knows\nBob will compute secret information only on what he knows.\nAt the end, there will be a secret number that only Alice and Bob will know.\n\nGeneral Approach is to use a one-way function.\n\nOn one side of the coin you have a problem that you can do on any small calculator\nand on the other side, you have an intensively computational problem.\n\nBy the law of exponents, Bob and Alice end up computing the same number so they\ncan use this as a shared key for encryption communication. For any eavesdroppers,\nthis requires solving the discrete log problem (fast).\n\nDigital Signature:\nThere is a thing that you can produce the signing that anyone can check but is hard\nto produce. Produce authentication and non-repudiation.\n\nCertificates and Certifying Authorities\nYou finally get to a chain for a certification authority that is well know in order to\ncertify authentication.\n\nBasic Transport Layer Security Protocol (used to be known as SSL):\nIn this case, there is a client-side certificate that also verifies that you are who you\nsay you are.\n\nDiffie and Hellman didn't produce a practical method with public-key encryption.\nLater the RSA algorithm was produced. RSA could be used for both public-key and\ndigital signatures. MIT and Stanford also sought patents. RSA was a good patent,\nbut public-key was a weak patent. MIT and Stanford formed Public Key Partners and\nformed a cartel. They refused to license the public-key patent to others unless they\nalso used the RSA patent. The public-key was locked up until 2001. Now there are\nlots of public-key encryptions floating around now.\n\nEnd of 1970s and Bobby Ray, Director of NSA, became really nervous.\n\nEncryption really was, and still is, a military weapon. The NSA began to speak up\nabout this stuff getting out in public.\n\nThere was a meeting that ensued with MIT and NSA. MIT has been really reluctant\nto keep any work secret on campus. As a courtesy, they will send papers and\ninformation to NSA and other agencies along with colleagues.\n\nLouis Freeh made this the top priority in the FBI. In 1994, encryption was an alien\nform of technology since it was feared to be used by criminals and terrorists.\n\nClipper\nThe public didn't want to use encrypted phones.\nThe clipper chip was designed by the NSA and people could do encrypted\ncommunications and it has a \"built-in\" back door.\n\nSo what do you think of this clipper phone? The telephone industry rejected it. A\ntamperproof chip would drive up costs.\n\nThe Key Escrow Wars\n-\nconsisted of complicated policy wars going back and forth\n-\nagencies pushing to get their agendas adopted by Congress\n\nAnswer is Export Control.\n\nIf you were in the business of selling cryptographic software and products, you were\nregistered as an arms dealer. Prior to 1995, encryption technology was classified by\nthe State Dept. as ammunition.\n\nCIILNKSS - Syria, Sudan, Libya countries excluded\n\nThere were rumors in 1995 that the NSA had a project that was listening in on all\ncommunications projects going on. This secret project that nobody else was\nspeaking about was exactly what was happening.\n\nProject Echelon listens to lots of communications around the world.\n\nEventually all of the talks and NIST meetings broke down. Building these systems is\nextremely cheap that most consumers don't realize.\n\nMay 1996\n\nOk, you guys can have your encryption but you have to register your key with an\nescrow. We're going to marry the idea of encryption and electronic commerce. The\nWhite House decided the price of certification and allowing electronic commerce was\nto escrow the key.\n\nLegislation, 1997\n\nThere was a penalty for building electronics without an escrow key and a bill that\nforbade Congress from eliminated export of products.\n\nIn \"The Risks of Key Recovery...\" paper, it was decided that there would be no\ndiscussion on civil liberties. The structure of the paper is to address the risks of\nstopping crime and then investigate a technical analysis of their viewpoints.\n\nTechnical Observations:\nWho else can get a hold of escrowed keys that government officials have quick\naccess to.\n\nAround 2000, the cryptography laws became liberalized. In 1994, every person or\ninstitution using the software must have a crypto license. This is a result of\nelectronic commerce overtaking the industry.\n\nThen came Sept. 2001...\nSen. Judd Gregg (NH) stands up in Congress and says we have to do something\nabout encryption. It's essentially the legislation that was built into the 1997\nlegislation. The potential was now gone since the reality had hit. Not one other\n\nsenator agrees to co-sponsor this legislation. So by Oct, Sen. Gregg had backed off\nabout introducing the legislation.\n\nWhat has changed?\n\nIn 1995, the association with encryption and electronic mail was something different.\nNow encryption means protecting your credit cards, etc. Encryption has now become\na consumer thing.\n\nIt's the meaning of words that has now shaped our technology and policy today. But\nthis is probably not over yet.\n\nNow we have to make another adjustment around the security around the phone.\nWhat kind of wiretapping authority should the gov. have? What about Internet\napplications like Skype? Do you have to comply with CALEA regulations?\n\nOver the next couple of years, we will see more changes and maybe regulations\nabout applications on the Internet."
    },
    {
      "category": "Lecture Notes",
      "title": "6805_lec7.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/c3016eaa9f58efed5d70205bd32a2793_6805_lec7.pdf",
      "content": "6.805/6.806/STS.085, Ethics and Law on the Electronic Frontier\nLecture 7: Profiling and Datamining\n\nLecturer: Danny Weitzner\n\nCars and Planes :\nProfiling and Data-mining, post 9/11\n\nDiscussion - Midterm Logistics\nDistinguish between the facts of the case and how the law applies to the facts. Keep\nfacts and law separate.\n\nDiscussion - Term Paper and schedule\n\nCARS\n\nWe've moved pretty far from where we were in England to modern day in the United\nStates to having a clearer understanding of when a 4th amendment intrusion was\nhappening.\n\nWhat we see in the evolution of the 4th amendment, is now there is no longer a clear\nboundary for when the government has crossed over the line. The court has spent a\nlot of time trying to reconstruct that line.\n\nThe world is now a much more complicated place and people use other means\n(planes, cars) and technology to create other crimes. But there are also realms that\nmake law enforcement work much easier.\n\nCars- increase people's power and the ability to increase crime and get away quicker.\nLots of 4th amendment consideration with regards to how and when people use cars.\n\nCity of Indianapolis vs. Edmond\n\nHow does it work? Stop and standard search. Law enforcement stops every nth car\nat the checkpoint. Officer does external visual search of the car. Dogs are used to\nsniff around the car.\n\nThe idea that the cop can make you stop for this brief period of time is considered a\npersonal seizure of property for the moment.\n\n4A\n-\nsearch/seizure\n-\nwarrantless\n-\n-reasonable\n-\nSuspicitionless\no\nSpecial needs & nexus \"immediacy\"\no\nStandards (can't stop random cars based on suspicion)\n\nJustice O'Conner makes the case that this a reasonable search and that a large\nnumber of cars are stopped. This is not random. In addition, there is no reason to\nbelieve that the cars stopped are suspicious.\nChief Justice Rheinquist says in his dissent that there has to be some kind of\nbalancing, but Justice O'Conner doesn't agree.\n\nJustice O'Conner believes there has must be special needs that must occur in order\nfor a reasonable search such as this to occur. O'Conner wants to go in a more\nnarrow direction with the special needs test. Some examples are drug testing, drunk\ndriving.\n\nBased on the standard of not stopping random cars based on suspicion, Justice\nO'Conner is trying to protect personal rights.\n\nThe courts realized that they don't really know what's going on in the mind of an\nofficer who stops a vehicle.\n\nThe key thing about the sobriety checkpoints is that if you find someone driving\nwhile intoxicated on the road then you take the off the road immediately because of\nsafety concerns. However using the same reasoning to eliminate drugs was not\nenough for the courts.\n\nNot long after this case was decided, September 11th happened and the Patriot Act\nwas passed.\n\nPatriot Act - extended the rights of law enforcement to retrieve more information on\nextremists.\n\nNational security letters - equivalent to subpoena but doesn't come from the court.\nInstead it comes from the Foreign Intelligence Surveillance Court (secret court for\nforeign intelligence)\n\nThe courts can apply the standards set by FISA in a court.\n\nWhat are the standards for the FISA court?\nPre-patriot - agents of a foreign power\nPost-patriot - extended to cover domestic terrorist activity\n\nCan the FISA court tap the phones of two American citizens that are terrorists? YES,\nthe post-Patriot act extends to domestic terrorism.\n\nOther changes in Patriot Act:\n-\none judge within 20 miles of DC\n-\nsneak and peak warrants for broader terms\nTest for sneak and peak: advance knowledge that something will occur\n-\nroving wire tap became a little bit easier to use: allows a tap on a person\nin the geographic vicinity\n\nThe constituency that largely opposed the Patriot Act and was surprising was the\nlibrarians because of the business records. The delayed notification applied to the\nbusiness records at libraries as well.\n\nPrior to the Patriot Act, there was a wall between the Foreign Intelligence context\nand Criminal Investigation. In the immediate aftermath of 911, this wall was\nconsidered responsible for the FBI's failure in their response. As a result, the wall\nhas been significantly reduced.\n\nForeign Intelligence | Criminal Investigation\n\nThere was concern that elimination of the wall would result in a violation of 4th\nAmendment rights. The commission wants to encourage sharing across the line, but\nwants to make sure that rights are protected and not abused.\n\nDissemination event - moving information received outside the jurisdiction of a\nparticular judge\n\nAs a result of terrorism, the wall was eliminated because of the nature of it.\nTerrorism just doesn't occur in what region.\n\nForeign Intelligence NCTC (responsible for the wall)\n-\nCIA\n-\nNSA\n-\nDIA\n-\nNGA\n\nCriminal Investigation\n-\nFBI\n-\nDEA\n-\nDHS\n\nSept. 11th also rearranged the National Intelligence community. Agencies have\ndifferent responsibilities than what they had before.\n\nFrom the commission's investigation, the coordination that should be happening to\nshare information and identify threats just isn't happening yet.\n\nOne piece of prime homeland security strategy that has resulted since 9/11 is a shift\nfrom investigation to prevention. So the task to the larger law enforcement\ncommunity has been to find out who these people are and prevent the crime from\nhappening.\n\nPLANES\n\nSince 9/11\nThe first thing we want to prevent is bad guys from getting on airplanes.\n\nNow skipping over to the creation of the Department of Homeland Security...\n\nWe now a significant part of the U.S. government who is responsible for making\ndecisions on who can get on an aircraft or searched. They do this by profiling.\n\nPNR (passenger name records from the airline)\nProfiling\n\nCommercial 3rd party\nWatch List\n\nCAPPS II -\nPersonal records are published in the Federal Registry.\nTwo steps involved:\n- Authentication\n\n- Risk assessment - placing individuals in categories by checking against a\nwatch list\n- matching\n\nRoutine use: arrest/warrant check\n\nFor what purpose are these records being used?\nOne of the routine uses is to make the information available to agencies where\npeople have outstanding crimes. This is a purpose in additional to the core purpose\nof passenger safety.\n\nCAPPS II was never implemented and made operational.\n\nSecure Flight\n\nUnder this system, the public has a chance to comment on the proposal of the\nsystem of records.\n\nWhat changed between CAPPS II and Secure Flight?\nSecure Flight was a proposal to test the system. They were testing based on one\nmonth's of data.\n\nThe airlines had the data in June 2004.\nSystem of Records notice published in September 2004\nThe test was done in March 2005.\n\nThe notice to the public came after the data was collected.\nWhen it came to Secure Flight, they eliminated the use of outstanding arrests and\nwarrants.\n\nProcedural transparency - this whole process is vindication of the laws that have\nbeen there since 1974. The process that is being developed has some kind of\ntransparency associated with it.\n\nThis particular gov. agency was very forthcoming about their faults and the\nprocedure being implemented.\n\nNow let's focus on the various profiling that happens in these database queries. Is\nthere any 4th Amendment violation in this query process?\n\nWhat is the search that occurs when a bunch of databases get queried that have\nyour personal information in it? It's a suspicionless search. Everyone who travels by\nplane goes through this search.\n\nOn what basis does the government get access to these records?\n\nWe are in a situation where there is some kind of seizure like this.\n\nThe TSA wants the data of the PNR from the airlines. The airlines don't want all of\ntheir marketing information in the hands of the federal government. The airlines in\nsome ways feel the need to be the protectors of their consumer's information from\nthe federal government.\n\nEdmonds said that there was some kind of immediacy and a nexus between the\ncollection of the data and the analysis of it.\n\nOnce we have enough information derived from a suspicitionless search then we\nproceed to a Terry search.\n\nStandards\nEdmonds argued that standards consisted of a process that was consistently used.\n\nIf we find that there is no search and seizure, then the government can make policy\nfreely in this area.\n\nReporter's Committee case\nConviction records are public information. A group of reporters tried to get large\ngroups of information about conviction records and the courts ruled that this large\nscale collection may be an invasion of privacy.\n\nAfter the midterm, we will look at areas where the 4th Amendment is unclear and\nhow this relates to transparency."
    },
    {
      "category": "Resource",
      "title": "bflag.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/c47ca7919c591ec8490fc3df5a97682a_bflag.pdf",
      "content": "Underlying Motivations in the Broadcast Flag Debate\nRoshan Baliga\nDeb Dasgupta\nAnna Dreyer\nAllan Friedman\nMassachusetts Institute of Technology\n6.806, Fall 2002\n\nAbstract\nThe MPAA (Movie Picture Association of America) claims that the broadcast\nflagging scheme will protect its constituents' content when broadcast free over the air on\ndigital terrestrial television. We begin this paper with a description of the broadcast flag,\nand examine the MPAA's claim with a formal threat model analysis to determine that the\nbroadcast flag, while not successfully keeping content off the Internet, will offer the\nMPAA several other concrete benefits, quite different from the one publicly stated.\nHaving determined the role of the broadcast flag, we turn our attention to the full range of\nplayers, including consumer electronics companies, broadcasters, the major television\nnetworks, consumer groups, cable providers, the FCC, and Congress, and use a cost-\nbenefit analysis to unpack the motivations and incentives each player has for supporting\nor opposing the flag. We then compare our analysis with the public statements by each\nof the players regarding the flag, to evaluate the sincerity of their claims and affirm our\nanalysis. Ultimately, it appears that the underlying motivations of key players in the\nbroadcast flag debate are quite different from the stated goals of the broadcast flag, and\nrelate far more to DTV in general than digital content protection. We conclude that\nsupport for the broadcast flag is based on ulterior motives. If this costly policy is to be\nimplemented, we feel a more accountable case should be made prior to acceptance.\n\nTable of Contents\n1.\nIntroduction\n2.\nHistory of Digital Television (DTV) and the Broadcast Flag\n3.\nThreat Analysis\n3.1\nGoal 1: To Eliminate Illegal Distribution of Movies on the Internet\n3.1.1 Adversary 1: Average Consumers\n3.1.2 Adversary 2: Nefarious Infringers\n3.1.3 Adversary 3: Organized Crime\n3.2\nGoal 2: To Restrict Personal Recording of Movies for Time-Shifting or\nLibrary Building\n3.2.1 Adversary 1: Independent Individuals\n3.2.2 Adversary 2: Consumer Electronics Companies\n3.2.3 Adversary 3: Malintentioned Groups\n3.2.4 Goal 3: To Reverse Societal Norms of Copyright Infringement\nAcceptance\n3.2.5 Adversary 1: Average\n3.2.6 Adversary 2: Congress\n3.3\nGoal 4: To Move Content Control to Copyright Holder\n3.3.1 Adversary 1: FCC/Congress\n3.4\nThreat Analysis Conclusion\n4.\nCost-Benefit Analysis\n4.1\nContent Owners\n4.1.1 MPAA\n4.1.2 Major Networks\n4.2\nConsumer Electronics Manufacturers\n4.2.1 5C Corporations\n4.2.2 Non-5C Firms\n4.3\nConsumers\n4.4\nBroadcasters\n4.5\nCable Companies\n4.6\nGovernmental Actors\n4.6.1 FCC\n4.6.2 Congress\n4.7.\nCost-Benefit Analysis Conclusion\n5.\nConclusion\nAppendices\nA1.\nStandards\nA2.\nHistory of DTV\nA2.1 ACATS\nA2.2. Simulcast\nA.2.2.1\nAnalogy to Britain's Switch to Color Television 35\nA.2.2.2\nFirst Digital Simulcast\nA2.3 ATSC\nA2.4 Timetable for Implementation\nA2.5 HDTV vs. SDTV\n\nA.2.5.1\n\nFCC 4th and 5th Orders Regarding SDTV and\nHDTV\nA.2.5.2\nHDTV and SDTV Standards Defined\nA.2.5.3\nDTV Savings over Analog\nA.2.6 FCC Timeline for Adoption\nA.2.7 Slow Adoption of DTV\nA3.\nThe MPAA and the Broadcast Flag\nA4.\nCompliant Devices\nA4.1 DTCP and HDCP\nA4.2 Types of Copying Allowed under DTCP\nA4.3 5C and Broadcast Flag Interaction\nA5.\nCongressional Legislation\nA5.1 Touzin Bill\nA5.2 Hollings Bill and Letter\nA5.3 Lofgren Bill\nBibliography\n\n1.\nIntroduction\nDigital content protection has grown into a huge issue over the past 10 years, as\nthe ability to make and distribute perfect copies of digital content becomes ubiquitous\nand cheap. Content owners fear that the wide spread dissemination of their copyrighted\nmaterials over the Internet, particularly over peer-to-peer systems that have proven hard\nto shut down. The advent of Digital Television offers yet another benefit of the digital\ninformation age, but also threatens to open other means of digital infringement if users\ncan freely capture and distribute broadcast TV shows and movies. One of the main\ndrives behind Digital Television is the release of Hollywood movies, yet Hollywood\ncompanies, represented by the Motion Picture Association of America (MPAA), are\nreluctant to release their content without some sort of protection.\nThe resulting proposal, after working with various interested actors, is the\nbroadcast flag. This flag, attached to a digital broadcast signal, would control to how the\ncontent could be used: to which devices it could be sent and how many times it could be\ncopied. The MPAA claims that this scheme will protect their content and, if it is\nimplemented into the DTV infrastructure, they will freely release their content.\nImplementation requires the support of a variety of other actors, each of whom claims to\nsupport the flag as well.\nThis paper proposes to examine the veracity and robustness of the MPAA's\nclaims, as well as the claims of other key actors in the debate. Each interested group has\na stated motivation for supporting the broadcast flag, and has used that motivation to\npush for the implementation of a broadcast flag regime. We find that, while the\nbroadcast flag does offer significant benefits to many of the key players, these benefits\nare seldom directly related to the stated motivation, and often have little to do with the\nbroadcast flag at all.\nWe begin this paper with a description of the broadcast flag, paying particular\nattention to the benefits purported by the MPAA itself in section two. Since the MPAA\nclaims that the flag will effectively stop unauthorized Internet distribution, we evaluate\nthe robustness of the flag with a formal threat model analysis in section three. We also\nexamine other possible benefits of the broadcast flag under this framework, and\ndetermine that, while not successfully keeping the content in question off the Internet, it\nwill offer the MPAA several other concrete benefits, quite different from the one publicly\nstated . In section four, we turn our attention to the full range of players, including\nconsumer electronics companies, broadcasters, the major television networks, consumer\ngroups, cable providers, the FCC, and Congress, and use a cost-benefit analysis to unpack\nthe motivations and incentives each player has for supporting or opposing the flag. We\nthen compare our analysis with the public statements by each of the players regarding the\nflag, to evaluate the sincerity of their claims and affirm our analysis. Ultimately, it\nappears that the underlying motivations of key players in the broadcast flag debate are\n\nquite different from the stated goals of the broadcast flag, and relate far more to DTV in\ngeneral than digital content protection. We conclude that support for the broadcast flag is\nbased on ulterior motives. If this costly policy is to be implemented, we feel a more\naccountable case should be made prior to acceptance.\n2.\nHistory of Digital Television (DTV) and the Broadcast Flag\nThe broadcast flag was suggested as a consequence of the emergence of digital\ntelevision. Digital television offers many benefits over analog television, including\nimproved picture and sound, while requiring less bandwidth for broadcast transmission.\nFollowing the FCC creation of the Advanced Television Systems Committee in 1995,\nwhich was mandated to develop standards for digital television, broadcaster began\nimplementing the switch to digital television. While maintaining analog broadcasts,\ndigital broadcasts began using additional spectrum granted by the FCC. By late 1998, the\n26 TV station in the country's most populous cities would begin broadcasting the using\nthe Grand Alliance DTV system. This initial broadcast would reach 30% of U.S.\ntelevision households. By 1999, that number would expand to 40 stations and by 2000,\nthat number would reach 120 stations. By 2006, every station would be expected to\ntransmit all content digitally for fear of losing the FCC license1.\nSince digital television offers an enormous amount of compression compared to\nwhat is possible in the analog domain, when the transition to DTV is complete, the FCC\nwill regain the old spectrum and license it for different uses. Seeing the tremendous\nreductions in spectrum use, the government would like to encourage investment in digital\ntelevision. They would like to regain and resell the original NTSC spectrum granted to\nFCC licensed broadcasters in exchange for DTV spectrum with the same bandwidth.\nBy 2001, adoption of digital television had been slow. The Consumer Electronics\nAssociation stated that after more than two years of availability, HDTV shipments totaled\nonly 625,000 in 2000 compared with 25 million TVs overall2. Networks attempted to\nencourage HDTV subscriptions through new hit series such as \"The Sopranos\" in high\ndefinition format. However, the lackluster adoption gave broadcasters little reason to\nbroadcast in HDTV format, and gave consumers little reason to invest thousands of\ndollars for digital television sets3.\nCongress attributed the slow adoption of digital television to the lack of quality\ncontent on terrestrial television, and looked to the MPAA (Movie Picture Association of\nAmerica) to provide that content on digital television. However, the MPAA had stated\nthat it would not release content without copyright protection enforcement. Unlike\nDVDs and cable, which are either decrypted when played or broadcast encrypted, digital\n1Whittaker, Jerry. \"Broadcast History: Milestones in the Evolution of Technology .\" Retrieved November\n22, 2002, from http://www.tvhandbook.com/History/History.htm.\n2 Ibid.\n3 Goroch, Antonette. \"HD in the Clouds? DBS seek to stay ahead, despite slow growth in HDTV.\"\nJanuary 22, 2001. Retrieved November 21, 2002, from\nhttp://www.broadbandweek.com/news/010122/010122_wireless_hdtv.htm.\n\nbroadcasting must be delivered unencrypted. In fact, the FCC requires that this terrestrial\nbroadcast television be sent \"in the clear\". The MPAA fears delivering high-quality,\nunencrypted content digitally, because viewers could record shows and later make them\navailable on the Internet. The MPAA feels that their refusal to deliver content without\nprotection is justified, and that such protection should be supported via the DMCA\n(Digital Millennium Copyright Act) that made circumventing copy protection measures\nillegal and that provided corporations with a legal tool to protect their intellectual\nproperty.\nThe Copy Protection Technical Working Group (CPTWG), composed of\nrepresentatives from entertainment, information technology and consumer electronics\nindustries, formed the Broadcast Protection Discussion Group (BPDG) to develop\nguidelines for copy protection of content provided by parties such as the MPAA over\ndigital terrestrial television. The goals of the group include:\n- To provide a technical specification for the broadcast flag\n- To provide secure handling of content marked with the Broadcast Flag4\n- To recommend the implementation of the Broadcast Flag5\nIn addition, a drafting committee was formed to provide documentation for\n\"Broadcast Flag Compliance and Robustness Rules\". The group met from December\n2001 to June 2002 to draft the standards for implementing the broadcast flag. In June of\n2002, the BPDG proposed that the digital TV signal has broadcast flag imbedded and that\nall digital devices would be forced to recognize the flag. This flag, they presumed, would\nassuage the copyright holder's fear that the content will be distributed on the Internet.\nThe BPDG was been quoted as saying that \"the proposed technical solution does not\ninterfere with the ability of the consumers to make copies of the DTV content, and to\nexchange such content among devices connected within a digital home network.\"6 .\nThe MPAA has released several technical details about the broadcast flag, whose\ngoal is to prevent redistribution of copyrighted material over the Internet. The MPAA\nhas specifically stated that it is only concerned with redistribution and not with digital\ncopying of content7. MPAA has also stated that not all programs will be flagged, and that\nthe broadcast flag will be set to \"on\" or \"off\" depending on private conceptual\nagreements between content providers and broadcasters. In addition, the MPAA claims\nthat PVRs (Personal Video Recorder)8 with no digital outputs, such as TiVo will be\n4 A proposed measure to prevent illegal distribution of digital content over the Internet. The details of the\nflag are described below and in the Appendix.\n5 \"-----.\" \"April 25, 2002 CONTENT PROTECTION STATUS REPORT.\" Retrieved November 15, 2002,\nfrom http://judiciary.senate.gov/special/content_protection.pdf.\n6 Wiley, Lauren. \"BPDG Proposes Broadcast Flag to Protect DTV Broadcasts.\" Retrieved November 15,\n2002, from http://www.emedialive.com/r10/2002/news0802_02.html.\n7 \"-----.\" \"Broadcast Flag Frequenty Asked Questions.\" Retrieved November 22, 2002, from\nhttp://www.mpaa.org/Press/Broadcast_Flag_QA.htm.\n8 A set-top-box capable of recording broadcast or cable television programs for later viewing.\n\npermitted to record broadcast digital programs9. However, those personal computers\nusing PVR software will need to be equipped with digital TV tuner cards to prevent\nunauthorized redistribution of the programs to the Internet. With this technology, the\nMPAA has states that it is possible to record a movie or television show, provided that\nthe broadcast flag allows this, store the show on a hard drive (but one that does not allow\nthe hard drive to have an Internet connection), parse it, and ship it to a bedroom TV, for\nexample. One possibility, however, is that the technology will prevent people from\nwatching a recorded movie at the house of a friend10. In general, the BPDG, on behalf of\nthe MPAA has stated that it wants to design all devices interfaced with DTV to \"frustrate\nuser-end modifications11.\" With similar efforts in mind, the BPDG has proposed a ban\non all open source software such that no software is written to interact with DTV signals\nto prevent users from modifying receivers to circumvent broadcast flag restrictions.\n3.\nThreat Analysis\nHow effective will the broadcast flag be at doing what it is supposed to do? The\nMPAA claims that the broadcast flag is designed only to prevent \"unauthorized\nredistribution of copyrighted content, not prohibit digital copying12.\" However, the\nMPAA also states that \"copies made by future digital recorders that comply with the\nbroadcast flag will not be playable on legacy playback devices and consumers will still be\nable to tape the digital broadcasts for traditional time-shifting uses with analog recorders\nsuch as VHS13.\" While the MPAA is clear that it means only to prevent movies from\nbeing traded on the Internet, the broadcast flag has other effects that may also be hidden\ngoals of the MPAA. In the threat analysis, we examine the effectiveness of the broadcast\nflag in accomplishing the stated goal of the MPAA, in addition to other possible motives.\nIn doing so, we examine all possible threats to the broadcast flag, and the parties that may\naccomplish these threats. We conclude that the broadcast flag is not an effective means\nof preventing digital content distribution over the Internet, but will be successful in\npromoting other possible, although unstated, goals of the MPAA.\nThe threat analysis uses two assumptions. The first assumption is that the\nbroadcast flag, as part of digital television, is commonplace. The FCC has convinced\nconsumers to switch to digital television, and has discontinued analog broadcasts. Almost\nall homes have replaced their legacy televisions with digital televisions.\nThe second assumption is key and states the following: the analog output from all\ndigital television tuners has been restricted. This is, in effect, plugging the so-called\n'analog hole14.' The justification for this assumption is that if the analog hole is not\n9 Whittaker, Jerry. \"Broadcast History: Milestones in the Evolution of Technology .\" Retrieved November\n22, 2002, from http://www.tvhandbook.com/History/History.htm.\n10 King, Brad. \"HDTV Battle Wages On.\" Retrieved November 22, 2002, from\nhttp://www.wired.com/news/digiwood/0,1412,53835,00.html.\n11 Doctorow, Cory. \"Understanding the Broadcast Flag.\" Retrieved November 15, 2002, from\nhttp://www.techtv.com.\n\"-----.\" \"Broadcast Flag Frequenty Asked Questions.\" Retrieved November 22, 2002, from\nhttp://www.mpaa.org/Press/Broadcast_Flag_QA.htm.\n13 Ibid.\n14 The \"Analog Hole\" is discussed in the Appendix.\n\nblocked, then the broadcast flag will have no effect in preventing the Internet\nredistribution of movies, since it is trivial to redigitize an analog video stream. By trivial,\nthis analysis does not imply that the average consumer will redigitize his own movies.\nHowever, the analysis does assume that since redigitization from the analog output is\nrelatively prevalent under an NTSC paradigm, it will continue to be so in the future if the\nanalog output is not restricted. We are not alone in realizing that the analog hole poses a\nserious problem to the success of the broadcast flag; as mentioned in the Appendix. In\nOctober 2002 Representative Billy Tauzin (R-LA) introduced legislation on the broadcast\nflag that included a proposal to remove all analog outputs from digital devices that\ninteracted with broadcast DTV signals.15\nFor the purposes of the threat analysis, we identify four main goals of the MPAA\nin proposing the broadcast flag: to eliminate the illegal distribution of movies on the\nInternet; to restrict the personal recordings of movies for time shifting or library building;\nto reverse the societal norms allowing copyright infringement; and to put the control of\ncontent into the hands of the copyright holder. These four goals have not all been\npublicly identified as being goals that the MPAA wishes to accomplish by passing\nbroadcast flag legislation. Rather they are goals that seem reasonable in light of what the\nbroadcast flag makes possible. The following chart summarizes the four potential goals\nof the MPAA, the agents that pose a threat to those goals, and categorizes the threat that\nthese agents pose:\nGoal\nAdversaries\nThreat\nPrevent Distribution of\nMovies on the Internet\nAverage Consumers\nlow\nNefarious Infringer\nhigh\nOrganized Crime\nlow\nRestrict Personal\nRecording of Movies for\nTime-Shifting or Library\nBuilding\nIndependent Individuals\nlow\nConsumer Electronic Companies\nmedium\nMalintentioned Groups\nlow\nReverse Societal Norms of\nCopyright Infringement\nAcceptance\nAverage Consumers\nlow\nCongress\nmedium\nMove Content Control to\nCopyright Holder\nFCC / Congress\nhigh\nEach of these goals and consequent threats to the goals are examined below.\n15 \"-----.\" \"Draft TV Mandate Bill Freezes Innovation.\" Electronic Frontier Foundation. Retrieved\nDecember 7, 2002, from http://www.eff.org/IP/Video/HDTV/20020919_eff_pr.html\n\n3.1\nGoal 1: To Eliminate Illegal Distribution of Movies on the Internet\nThe MPAA's stated goal of the broadcast flag is to prevent the illegal distribution\nof movies over the Internet. According to the MPAA, the broadcast flag \"signals that the\nprogram must be protected from unauthorized redistribution.\" It is plainly seen that the\nunauthorized distribution the MPAA is referring to is Internet distribution; \"If\nunauthorized copies of programs are widely available on the Internet they cannot be sold\nin ancillary markets and the owners cannot cover the costs of production16.\" MPAA\nconstituents may fear a loss of revenue through this unauthorized distribution chain, and\nmay wish to prevent this problem before it escalates. Currently most consumers do not\nhave the bandwidth to download full-length movies in a reasonable amount of time. For\nexample, a 2-hour movie encoded using the DivX codec takes about 10 hours to\ndownload over a cable modem, compared to 2 minutes for the average song encoded in\nthe MP3 format. While illegal copies of movies are not as prevalent as MP3 music files\non the Internet, it is possible that future advances in bandwidth will give rise to a movie\ntrading community, perhaps over peer-to-peer networks. Regardless of the motivations\nof the MPAA, it has made this goal clear.\nFor the purposes of this threat model, we assume that the attack has been\nsuccessful if even one person manages to release a movie on the Internet. Since this\nassumption has important repercussions for the threat analysis, it is valuable to justify this\nassumption.\nWith the birth of peer-to-peer networks in 2000, it became very easy to share and\ndownload digital media over the Internet. Decentralized networks, such as Gnutella and\nLimewire, have proven resistant to attempts to shut them down, either by technical means\nor through legal action17. In these peer-to-peer networks, if users are searching for a file,\nthe availability of the file grows exponentially as users download the file, since there are\na growing number of hosts from which to download the file. Therefore, in a peer-to-peer\nnetwork, if the original source of a file is not stopped prior to sharing of the file, it is\nimpossible to prevent the spread of the file, provided the file is in demand. We do not\nanalyze the financial repercussions of Internet redistribution of movies because the\nMPAA focuses only on limiting Internet redistribution as a goal of the broadcast flag.\nAnother assumption made is that the MPAA is only concerned with the\ndistribution of HDTV-quality movies. For the purposes of this threat analysis, we will\nignore the Internet distribution of movies that are \"ripped\" from DVDs, rather than\nbroadcast HDTV. Since the DVD encryption system has already been broken, as long as\nDVDs continue to be sold, movies of SDTV quality will be distributed on the Internet.\nThere are many threats to the goal of preventing unauthorized distribution of\nmovies on the Internet. We distinguish between three capable adversaries to meeting the\n16 \"-----.\" \"Broadcast Flag Frequenty Asked Questions.\" Retrieved November 22, 2002, from\nhttp://www.mpaa.org/Press/Broadcast_Flag_QA.htm.\n17 Von Lohmann, Fred. (2001) \"Peer-to-Peer File Sharing and Copyright Law after Napster.\" Retrieved\nDecember 7, 2002, from http://www.eff.org/IP/P2P/20010227_p2p_copyright_white_paper.html\n\ngoal of preventing Internet distribution of digital content, whom we label as follows:\naverage consumers, nefarious infringers, and groups with resources.\n3.1.1 Adversary 1: Average Consumers\nThe average consumer may wish to distribute movies on the Internet to share\nthem with friends, or simply to share them to anyone. Movies may be distributed in their\nentirety, or as short clips. Since we assume the analog output would be disabled,\ndigitization of content is not an option. Consumers will somehow have to work around\nthe broadcast flag to disseminate movies over the Internet since the broadcast flag is\ndesigned explicitly to prevent movies from being moved to computers.\nTo analyze the threat that the average consumer poses to meeting the goal of\npreventing Internet distribution, it is useful to understand the likelihood that the average\nconsumer will use a circumvention device. While the broadcast flag is not currently in\nuse, comparisons can be made to older copy protection methods, such as the CSS\nencryption used in DVDs. CSS encryption was broken in 2000, and DVD decryption\nsoftware is widely available on the Internet. However, it is the belief of the authors that\nthe average consumer is apathetic towards this, and most consumers have never ever\nconsidered the possibility of making their own DivX encoded movies to trade on the\nInternet.\nSince consumers today may be dissuaded from trading movies because of\nbandwidth limitations, it is helpful to inspect the trading of MP3s on the Internet. MP3s\nhave become commonplace, and many groups of consumers (especially college students)\nhave extensive collections of music in MP3 format. However, rather than creating their\nown MP3s, most consumers get MP3s from friends or from anonymous computers on\nnetworks such as Kazaa and Gnutella. A search for \"mp3\" on Download.com reveals\nthat the most popular download is Kazaa, with 161 million downloads. For comparison,\nfirst search result that actually encodes mp3 is MusicMatch Jukebox, twelfth in\npopularity, with only 3 million downloads. Assuming these alternate sources continue to\nexist, we can expect future consumer action to remain similar to this.\nUsing evidence from MP3 trading and current movie trading, we claim that even\nif consumers are given the tools to circumvent the broadcast flag and distribute movies on\nthe Internet, they usually will not actively copy movies and post them for public\ndistribution. Therefore, the average consumer does not pose a serious threat to the\nbroadcast flag's primary goal.\n3.1.2 Adversary 2: Nefarious Infringers\nThe techno-savvy infringer is very different from the average consumer as a threat\nof the stated goal of the MPAA in preventing Internet distribution of its digital content.\nThis \"nefarious infringer\" has some technical knowledge, and is willing to expend energy\nin learning how to circumvent copy protection mechanisms. This group may distribute\nmovies on the Internet for monetary compensation, but the more likely reason is that they\nsimply enjoy distributing movies. Monetary compensation is unlikely to be a driving\nforce of nefarious users because of the difficulty in receiving payment for the sale of\n\nillegal merchandise without getting caught. To continue the prior comparisons, this is the\ngroup that converts songs to the MP3 format for Internet distribution, and compresses\ndecrypted DVD content for distribution.\nTo distribute HDTV-quality movies on the Internet, this group must circumvent\nthe broadcast flag. Circumvention of the broadcast flag means that individuals will have\nto develop such techniques themselves, or they will learn these techniques from other\nindividuals in this group. The threat posed by this group depends on the robustness of the\nbroadcast flag. A complete discussion of the robustness of the flag is beyond the scope of\nthis paper; however, we have attempted to make a brief analysis here for the purposes of\nthe threat model.\nIt is the belief of the authors of this paper that the broadcast flag is not a reliable\ntechnical solution to prevent copyright infringement. Rather, it is a legal solution,\ndepending heavily on legislation mandating the compliance of all digital devices. Due to\nFCC regulations, all digital television signals must be sent in the clear, preventing\nbroadcasters from employing proprietary encryption as is used in digital satellite and\ndigital cable. The broadcast flag is simply a tag that marks copyrighted content, and\nlegislation is the only way to ensure that consumer electronic devices respect the\nbroadcast flag.\nTo prevent these users from hacking DTV tuners, the BPDG has released a set of\nrobustness requirements for consumer electronics. These include various requirements,\nsuch as ensuring that all busses are encrypted, and that all integrated circuits are soldered,\nnot socketed, to boards. The requirements even go as far as naming screwdrivers in a list\nof tools that should not be able to be used to defeat the copy protection system in DTV\nproducts.18 These countermeasures are likely to deter many people from finding\nweaknesses in DTV systems. However, the cost of consumer electronics must be kept\nlow. The BPDG realizes this, and has decided to forgo any countermeasures that would\ndeter hackers using more sophisticated tools, such as logic analyzers. Herein lies a sticky\nproblem pointing to the weakness in the broadcast flag implementation: the system\nshould be secure when distributed to millions of people, but should also be cheap.\nThe BPDG may feel that adversaries with logic analyzers do not pose a\nsignificant risk because of the limited number of people with both access to logic\nanalyzers and the technical knowledge with which to hack DTV systems. However, one\nperson who defeats copy protection on a DTV device may be able to share enough\ninformation about the method for others to circumvent copy protection on identical\ndevices. Indeed, a similar situation existed with Microsoft's X-Box game system, which\nwas designed to execute only Microsoft-authorized (signed) code. In 2002 MIT graduate\nstudent Andrew Huang, having spent many hours in a well-equipped lab, successfully\ncrafted a method to run unsigned code on the X-Box. While not everybody has access to\n18 \"-----.\" BPDG Compliance and Robustness Rules (n.d.). Retrieved December 1, 2002, from\nhttp://www.eff.org/IP/Video/HDTV/20020414_bpdg_compliance_rules.pdf\n\nlogic analyzers, the directions and information Mr. Huang provided helped others to run\nunsigned code on their X-Box.19\nDeveloping a workaround for the copy protection on a broadcast flag-compliant\ndevice is not the only way to move movies to a computer. Another method, which may be\nmuch easier, is to use a DTV receiver that simply ignores the broadcast flag. Legislation\nwill obviously make it illegal to import these devices from overseas, but US law cannot\nprevent their manufacture overseas. The harsh reality is that since DTV broadcasts will\nnot be encrypted, it will be almost trivial for a company to make a DTV tuner that\ndemodulates the digital signal while ignoring the broadcast flag. If these devices are\navailable overseas, then it is very likely that a nefarious user will successfully bring one\ninto the United States for the explicit purpose of distributing movies online.\nThe BPDG is taking care to deter nefarious users from hacking broadcast flag-\ncompliant devices by having robustness rules for compliant devices. However, the fact\nthat the broadcast is unencrypted means that it is very likely that devices will be available\nwhich do not respect the broadcast flag, despite legislation making such devices illegal\nfor sale in the United States. The threat of nefarious users making content available on\nthe Internet is very high.\n3.1.3. Adversary 3: Organized Crime\nWe now examine a third adversary to MPAA's goal of stopping Internet\ndistribution of its digital content with the broadcast flag: organized crime. While most\nnefarious users do not have monetary gain as motivation to distribute movies on the\nInternet, there are groups whose motivation is of a monetary nature. These groups are\nanalogous to the groups that currently copy movies and sell them on VHS tapes or DVDs\non city streets, often based in off-shore operations. Since these groups have more\nfinancial resources than individual consumers, it stands to reason that they will be more\nlikely to succeed in an attack on breaking the copy protection on DTV devices.\nAny group with resources is more likely to have the technology necessary to\ncircumvent the copy protection mechanism on DTV devices. However, their motivation\nof profit affects the likelihood that a group will actually distribute movies over the\nInternet. In order to make money selling illegal Internet copies of movies (a risky\nbusiness model anyway), the groups will be giving up their anonymity. This lack of\nanonymity would lead to prosecution in the United States, or in many other countries\n(including the E.U. member nations) for copyright infringement. For fear of prosecution,\nit is unlikely that groups with resources pose a serious threat to the broadcast flag's\nattempt to keep movies off the Internet.\n19 \"-----.\" \"Hackers Play with the Xbox.\" (n.d.). BBC News. Retrieved December 7, 2002, from\nhttp://news.bbc.co.uk/1/hi/sci/tech/2067045.stm\n\n3.2\nGoal 2: To Restrict Personal Recording of Movies for Time-Shifting or\nLibrary Building\nWe now examine a possible, although unstated goal of the MPAA in desiring to\nimplement the broadcast flag, and conclude that this goal of restricting personal recording\nof movies for time-shifting purposes or library building will likely be met.\nTime-Shifting and Library Building privileges go back to the Sony vs. Universal\nStudios Supreme Count decision. However, the Sony case did not establish these as rights,\nrather it upheld time shifting as legal within the scope of copyright law, protected under\nthe fair use doctrine. The advent of the broadcast flag affords the MPAA a great\nopportunity to effectively reverse the Sony decision. While this is not a stated goal of the\nMPAA, it follows as a direct repercussion of the broadcast flag. This section examines\nthe likelihood that the broadcast flag will be successful in restricting \"fair use\" copying.\nWithout an analog output on DTV tuners, the only way consumers will be able to record\nbroadcasts is via the copy protected digital output. By creating the standards for broadcast\nflag compliance, the MPAA (through the BPDG) will be able to set restrictions on\nrecording for time shifting or library building. Additionally, under the Digital Millenium\nCopyright Act, it will be illegal to circumvent any copy protection afforded by broadcast\nflag compliant devices, locking these new restrictions into current law.\n3.2.1 Adversary 1: Independent Individuals\nIndividuals working alone pose a threat to this goal if they are successful in\ncircumventing the copy protection system in a DTV system. This group is motivated by\nthe desire to have the same capabilities in the new DTV world as in the analog TV world.\nTo be successful these individuals would have to reverse engineer a DTV tuner and/or\ndigital recorder, which will probably be difficult without specialized equipment.\nRegardless, their effect will be limited if they are not able to share this knowledge with\nothers; the overall system still restricts copying for most of its users. Thus, independent\nindividuals will not be successful in deterring the broadcast flag from restricting personal\nrecording of movies for time-shifting and library building purposes.\n3.2.2. Adversary 2: Consumer Electronics Companies\nA consumer electronics company shipping a defective product, or one without a\nrobust copy protection system, poses a large threat to the goal of restricting the copying\nof broadcast television. Unlike the other threats, the CE will not intentionally attempt act\nas a threat to the goals of the MPAA. It is actually in CE manufacturers best interests to\nship products that adhere closely to the copy protection specifications, as shipping a\ndefective product may be against the law under broadcast flag legislation, and because of\nthe strict requirements that CE devices must pass to be approved devices.\nThere are a few different ways that CE manufacturers may be threats to MPAA's\ngoal. One way is to ship a product that does not adhere to the copy protection guidelines\nat all. This threat is very unlikely, as products will have to be approved as broadcast flag\ncompliant before allowed to be imported (or sold) in the United States. Another way of\nacting as a threat to the MPAA's goal of restricting time-shifting and library building by\nCE manufacturers is to ship a product that is easily altered by consumers to ignore the\n\nbroadcast flag. This threat is also unlikely because of the robustness rules issued by the\nBPDG. However, though it is unlikely, since CE units ship on the order of millions, a\nflaw would allow many consumers unrestricted recording ability. Thus, consumer\nelectronic groups provide a medium risk to the MPAA in accomplishing its unstated,\nalthough quite possible, goal of restricting time-shifting and library building via the\nbroadcast flag.\n3.2.3. Adversary 3: Malintentioned Groups\nIndividuals who work in groups pose a larger threat than do independent\nindividuals. Groups are thus inherently different than individual circumventers because\nof the difference in motivation and actions. Malintentioned groups with infringement in\nmind have as a goal circumventing copy protection in a way that is easy for others to\nreplicate. Additionally, groups allow more widespread sharing of information than\nindividuals. Another motivation may be monetary gain, if the group wants to sell\nmodifications that disable copy protection. This would be similar to chip modifications of\nSony Playstation video game consoles, allowing the modified systems to play games\ncopied to CD-R discs. However, actions that would accomplish circumventing the\nMPAA's second potential goal violate the DMCA, so it may be risky to run such a\nbusiness. It may also be difficult to create chip modifications that work across systems.\nUnlike Playstation consoles, every model DTV tuner may be different.\nSince consumers are not likely to take action by themselves to defeat copy\nprotection, the larger threat is that someone will sell a service of modification to a DTV\ndevice to defeat copy protection. However, this threat is also not very significant because\nof the problem of charging for such a service. Under the DMCA this service is illegal,\nand the people involved in such businesses could be prosecuted. (Chip modifications to\nPlaystations occurred prior to the DMCA.) Thus, the treat of malintentioned cooperative\ngroups in acting as a threat to MPAA's goal of restricting time-shifting and library\nbuilding via the broadcast flag is low, similar to the threat posed by independent\nindividuals.\n3.3\nGoal 3: To Reverse Societal Norms of Copyright Infringement Acceptance\nThis section examines reversing societal norms of copyright infringement\nacceptance as a possible goal of the MPAA in seeking to implement the broadcast flag.\nWe find that of the two possible adversaries to this goal, the average consumer poses a\nlow risk, and Congress poses a medium risk.\nCurrently, several societal norms exist regarding copyright infringement\nacceptance that the MPAA may wish to reverse. The Sony vs. Universal Studios case\nkept VCRs on the market, but even without VCRs copyright infringement would happen.\nToday, it is commonplace, and widely condoned to make a copy of a tape or a CD for a\nfriend, or make mix tapes of songs from friends. Many people have made CD-R copies of\nmusic CDs, or mix CDs for friends. While there are certain copyright violations that\nactually fall under fair use, such as making a tape for one's own use of a CD one owns,\ndistributing unauthorized copies of audio CDs to friends is actually a copyright violation,\n\nthough most people think nothing of it.20 This section examines the possibility that the\nbroadcast flag will reverse these societal norms regarding copyright violations.\nHowever, the attitude of general acceptance of copyright infringement has spread\neven further than CDs. This lax attitude towards copyright infringement has continued\ninto the Internet era, where many people download MP3s of songs they do not own,\nwhile maintaining a clear conscience. This has frustrated record labels, which have gone\nto such lengths as printing full-page ads in the New York Times with quotes from famous\nartists explaining that downloading MP3s is actually wrong, despite public perception.\nWhile copyright infringement over movies is not as widespread as infringement\nover music21, it is fair to say that the average American also thinks nothing of copying a\nmovie for a friend. The main reason for this societal acceptance of copyright\ninfringement is that historically copyright law has not been applied to individual people.22\nThis meant that some copyright infringement, like copying a movie for a friend, was\ntolerated. To reverse these societal norms, the broadcast flag would have to create a\ndigital world in which personal copying was limited, and make this limited copying the\nnew baseline for acceptance. This reversal faces two threats, one in the form of social\nbacklash by consumers, and another in the form of Congressional legislation that codifies\nfair use rights.\n3.3.1. Adversary 1: Average Consumers\nAt the end of the day, the companies represented by the MPAA are answerable to\nits customers: the average consumers who actually buy Hollywood products. Without the\nfinancial support of the average consumer, the MPAA member companies cannot exist.\nThese consumers pose a threat to the MPAA's attempt to change the social perceptions\non copyright infringement. If consumers were to speak out against the MPAA, or\norganize a boycott of movies because they were unhappy with restrictions on copying\nbroadcast television, then the companies represented by the MPAA would be forced to\nanswer. Unfortunately, even with organizations like the EFF and the HRRC, this threat is\nnot large. These organizations rarely enact social change directly; rather they lobby\npoliticians and work through the legislature. Without leadership, the average consumer is\nnot likely to be organized enough to mount a worthwhile attack against the MPAA\nregarding its goal of reversing societal norms of copyright infringement acceptance.\n3.3.2. Adversary 2: Congress\nUnlike their European counterparts, residents of the United States do not enjoy\ncodified fair use rights. Rather, fair use is a defense against copyright infringement, and\nfair uses are not guaranteed rights under law. Congress poses a threat to the MPAA's\nattempt to reverse societal perceptions because it may pass legislation codifying fair use\nrights. Congressional motivations may include pressure from groups such as the EFF, and\na desire to remove individuals from the mess of copyright law. Congress has passed\nsimilar legislation before, such as the Audio Home Recording Act of 1992, which\n20 Litman, Jessica. Digital Copyright. Amherst, NY: Prometheus Books, 2001. pp 161-162.\n21 Litman, Jessica. Digital Copyright. Amherst, NY: Prometheus Books, 2001. pp 169.\n22 Litman, Jessica. Digital Copyright. Amherst, NY: Prometheus Books, 2001. pp 18-19.\n\nexempted consumers from lawsuits for copyright violation in specific cases in return for\nmandating certain copy protection mechanisms in home audio recording equipment. It is\ndifficult to gauge the risk that Congress poses due to its fickle nature. The AHRA was\npassed with the support of consumer electronics groups, and it is not clear whether they\nwould mobilize sufficiently to overcome the MPAA and fight for these carved out rights.\nOverall, the authors of this paper predict that Congress poses a medium threat in\npreventing the MPAA goal of reversing societal acceptance of copyright infringement.\n3.4.\nGoal 4: To Move Content Control to Copyright Holder\nThis section examines whether the two adversaries of the MPAA's goal of\nmoving content control to the copyright holder, FCC and Congress, presents a viable\nthreat to this goal. The analysis concludes that the FCC and Congress jointly present a\nhigh, and extremely viable, threat to this potential goal.\nIf the broadcast flag legislation is passed, it will mark the first time that the\ncontent creator and copyright holder (MPAA constituents) both dictate how the content\ncan be used, and architect the technological framework to enforce those decisions. To\ndate, the copyright holder has not been able to prevent infringement. Instead, the\ncopyright holder sues after infringement has occurred. Using the broadcast flag movie\nstudios will proactively be able to restrict the use of their content, which is obviously\nself-beneficial. In the case that broadcast flag legislation is passed, only two groups pose\na threat to the movie studios' goal of putting themselves in charge of every use of their\ncontent. These two groups are the FCC and Congress.\n3.4.1 Adversary 1: FCC / Congress\nSince the FCC has authority over the public airwaves, it may pass a mandate\nspecifying the encoding rules for broadcast DTV. This could force the MPAA to allow a\ncertain number of copies, or allow some other fair use copying. The FCC would be\ninterested in doing this to placate consumers unhappy about the DTV transition.\nIn a similar vein, Congress could pass legislation specifying the encoding rules\nfor broadcast DTV. Congress may do this to uphold consumer rights or as a compromise\nwith the passing of the broadcast flag legislation. The threats posed by the FCC and\nCongress are hard to determine. The risk from the FCC is probably minimal, because the\nFCC will likely defer responsibility to Congress, as it appears to be doing with the\nbroadcast flag legislation. The threat from Congress is serious, as there is already\nproposed legislation requiring digital fair use. This legislation, the \"Digital Choice and\nFreedom Act of 2002\" was introduced in October 2002 by Zoe Lofgren (D-Ca) 23.\n3.5.\nThreat Analysis Conclusion\nAs shown through the above threat analysis, the broadcast flag does not provide a\nrobust technical solution to the problem of Internet redistribution of movies. Rather, it\nprovides a legal solution which is ultimately not likely to successfully keep unauthorized\nmovies off the Internet. The nature of existing online distribution chains such as peer-to-\n23 \"-----.\" \"Electronic Frontier Foundation Supports Digital Media Bills\" Electronic Frontier Foundation.\nRetrieved December 7, 2002, from http://www.eff.org/IP/DMCA/20021003_eff_pr.html\n\npeer networks allow a \"break once, run anywhere\" model, permitting a few advanced\nusers to crack the broadcast flag protection and then allowing others to share with\nimpunity. However, the threat model does show that the broadcast flag has the potential\nto prevent consumers from enjoying uses of content previously considered as \"fair uses\"\nin the analog realm, and to give MPAA control over the use of its content. Though its\nstates goals are not met, the MPAA and its constituents would derive considerable\nbenefits from the broadcast flag regime.\n4.\nCost-Benefit Analysis\nHaving determined the role of the broadcast flag, we now turn our attention to the\nfull range of players, including consumer electronics companies, broadcasters, the major\ntelevision networks, consumer groups, cable providers, the FCC, and Congress, and use a\ncost-benefit analysis to unpack the motivations and incentives each player has for\nsupporting or opposing the flag. In the sections that follow, we additionally compare our\nanalysis with the public statements by each of the players regarding the flag, to evaluate\nthe sincerity of their claims and affirm our analysis. Ultimately, it appears that the\nunderlying motivations of key players in the broadcast flag debate are quite different\nfrom the stated goals of the broadcast flag, and relate far more to DTV in general than\ndigital content protection.\nEmbroiled in the question of the broadcast flag are several key groups\nrepresenting specific interests. Each group will be affected in different ways by an\nimplementation of the flag, incurring some costs and deriving some benefits; a cost-\nbenefit analysis allows us to isolate predicted motivations for each actor. We look at\ncosts and benefits incurred throughout the process, both in the development and\ndeployment of the flag, seeking to isolate out as much as possible the effects the of\nBPDG proposal. Potential benefits or risked costs count towards the real benefits or costs,\nsince their expected value can be computed as the product of their probability times their\nexpected harm or benefit. We find that, in cases, where the benefits exceed the costs,\nmany of the benefits are derived from exogenous factors not directly related to the\nquestion of the broadcast flag itself.\n\nThe following table summarizes the analysis and conclusions that follow in section four:\nAgent\nContent Owners\nMPAA\nMajor Networks\nConsumer Electronics\nManufacturers\n5C\nNon-5C\nConsumers\nBroadcasters\nCable Companies\nGovernmental Actors\nFCC\nCongress\nSupports/Opposes\nGeneral Support\nSupport\nSupport and\nAmbivalence\nSupport and Oppose\nSupport\nOppose\nOppose\nSupport\nSupport\nSupport and Oppose\nSupports\nSupports and\nOpposes\nReasons for Support and/or\nOpposition\n-See threat analysis\n-FOX invented broadcast flag\n-Networks broadcast without\nbroadcast flag\n-Licensing proceeds\n-Increased sales\n-Create barriers to entry\n-Licensing fees\n-Increased sales\n-Costs of transition\n-Heavy investment already\n-Quality content may help gain\nmarket share\n-Increased market share due to high\ncosts of DTV transition\n-Expand scope of authority\n-Possible faster adoption of DTV\ndue to flag\n-Avoid offending industry\n-Avoid offending consumers\n-Possible delay in adoption of DTV\nand delay in return of spectrum\n4.1.\nContent Owners\nThe following subsection examines the costs and benefits of content owners\n(namely the MPAA member companies and major networks) with respect to the\nbroadcast flag. The analysis finds that MPAA member companies have an incentive to\nsupport the flag for reasons mentioned in the threat analysis and that major networks will\nbe ambivalent to the broadcast flag, because it does not directly impact their distribution\nchain.\nThe premium content industry--most notably represented by the MPAA--has\nbeen the principal driver behind the broadcast flag, providing the original impetus for its\ncreation. As discussed above, their strongest case for the flag centers on protecting their\npremium content over unencrypted terrestrial broadcast. However, a strong threat model\nanalysis suggests that the flag is not a highly robust protection against the dissemination\n\nof content over the internet, and highly robust it would have to be to keep a small number\nof users from distributing content to many others using peer-to-peer systems and other\nhard-to-monitor channels. The question then stands: what does the MPAA stand to gain\nfrom the flag?\n4.1.1. MPAA\nThe Association has spent some resources on the creation of the broadcast flag\nsystem. As a chief sponsor of the CPTWG and the BPDG, the MPAA expended enough\nenergy to shift the development discussion on matters from backwards compatibility to\nthe language of Robustness Requirements in the final BPDG Report24. On top of that, the\ntrade association has spent considerable efforts on lobbying various actors in Washington\nfor the general promotion of the flag. Finally, the member companies of the MPAA\nwould be responsible for maintaining and updating permissions on the content they\nlicense to broadcasters for distribution, a small but real expense. The MPAA, and by\nproxy its member companies, have not expended a huge sum on the flag, nor do they\nstand to lose any of their current market share under a broadcast flag implementation.\nThat is, any shift in their business model will be purely endogenous with the wide-spread\nacceptance of the flag, rather than caused by the flag itself.\nThe alleged primary benefit of the flag is that MPAA members will release their\nmassive libraries of premium content once the broadcast channels are protected against\nthe threat of unauthorized distribution. The threat of unauthorized distribution is\ndiscussed above; what about the idea of newer, better content on the airwaves? The\nauthors of this paper do not claim expertise in the entertainment industry, but it is not\naltogether clear where in the current distribution chain the free (advertiser-sponsored)\ndistribution of premium HDTV content will occur. Hollywood movies are currently\nbroadcast over NTSC television standards,25 but these occur at the very end of the\ndistribution chain. Movies are released to different media to extract the maximum value\nfrom them, going from the theatres to VHS/DVD sale and rental to pay-per-view, through\nthe premium movie channels before finally being made available on network TV.26 Until\nthis last stage, the consumer is willing to pay a premium to access the movie; in order for\nthe market to shift, content-owners must believe they can extract greater rents from the\nadvertising-sponsored broadcasts than they can from other sources. While this may be\npossible due to the fantastic image quality of HDTV, it is not assured. If the MPAA does\nnot stand to gain a new market, at least they will preserve an old one.\nWhat else does the content industry get? As discussed in the threat analysis above,\nshaping the debate can be a very powerful force. Indeed, further reflection may bring one\n24 \" -----\". \"Final Report of the Co-Chairs of the Broadcast Protection Discussion Subgroup to the Copy\nProtection Technical Working Group, June 3, 2002.\" Retrieved December 9, 2002, from\nhttp://www.cptwg.org/Assets/BPDG/BPDG%20Report.DOC.\n25 See, e.g. TV Guide Nov. 16-22 2002, p.82: Local Boston ABC affiliate broadcasts The Sixth Sense\n(1999)\n26 \" -----\". \"The anatomy of a monster\" from Frontline, The Monster that Ate Hollywood. Retrieved\nDecember 9, 2002, from\nhttp://www.pbs.org/wgbh/pages/frontline/shows/hollywood/business/windows.html.\n\nto wonder why such a small part of the current broadcast television market27 is setting\nsuch a large part of the current agenda. The MPAA benefits greatly from precisely that\nagenda-setting role. As technology threatens the traditional content-owner's business\nmodel, the MPAA is devoted to ensuring that new technological and regulatory advances\ntake into account their member companies. By establishing the precedent of privileging\ntheir own interests, and framing the debate around those interests as being common\ninterests, the MPAA can have a lasting impact on the long-run debate over digital\ncopyright. By defining fair-use technically, rather than legally, the content-owners can\nedge around sticky issues of fair use, for example, by simply asserting that their own\nrights should be protected in the system. The MPAA gains a huge benefit, simply by\ndefining the debate.\nComparing the costs and the benefits, we see that the Motion Picture Association\npays fairly little for the benefits of securing its distribution channels, and the large benefit\nof controlling the discussion over digital copyright. We see that the issue here is not\ndirectly related to the broadcast flag, but to the long-term solvency of an entire industry.\nThe MPAA is using the flag as a tool to assert its role as a primary actor in defining\ndigital copyright issues.\n4.1.2. Major Networks\nThe major networks can be seen as content providers as well, since they primarily\ncreate and disseminate broadcasting content to their affiliates. They do not, however,\nhave the same interests as the MPAA. The primary output for their content is advertiser-\nsponsored open broadcast, and the value of that is the first release as a primetime\nbroadcast, as well as resale for syndication. Those broadcasts differentiate their network\nfrom others, and allow them to control the costs. Under a broadcast flag regime, much\nmore content would be available, claims the MPAA, and the market may well demand its\nbroadcast. The networks would have to pay for these movies, but would not retain the\nrights for syndication and resale. Furthermore, the occasional hit TV show offers\nopportunities for external marketing and licensing, such as The Simpson's Happy Meals,\nor the Touched by an Angel Christmas Album. By spending resources on Hollywood's\nmovies, rather than their own productions, networks may miss these synergistic\nmarketing opportunities. Finally, networks derive a fair amount of prestige for creating\ntheir own programming, and competing for awards like the Emmys; this too would\ndiminish with a rise in Hollywood movies on network TV.\nOn the other hand, one could question just how large the separation is between\nHollywood and the networks. Mergers and acquisitions have left Disney owning ABC.\nFox produces movies as well as television shows. Revenue would be lost by one division,\nbut gained by another in a parent company. Still, the primary benefit for the networks\nwould be the same as the stated claims of the MPAA, namely to protect broadcast content.\nYet the networks do not seem to fear lost digital content as they currently\nbroadcast primetime content. Television shows do not have as long a distribution chain,\nand thus can not extract as much value from an episode of a hit TV show as a studio can\n27 Major network affiliates do not typically broadcast an incredible amount of Hollywood movie content.\n\nfrom a hit movie. Conversely, a 21 minute TV show is much easier to disseminate across\nthe net with reasonable quality than a 100 minute feature-length movie. Since the MPAA\ncounts each instance of unauthorized viewing as lost revenue, why don't the networks? It\ncomes down to a business model, where after the first prime-time viewing of a TV show,\nits value for syndication does not diminish with multiple digital copies around the\nInternet. While the networks have not actively campaigned against the flag, they have\nnot actively supported it either. In fact, 17 of CBS's 21 weekly prime time programming\nhours are currently simulcast in HDTV where available28. Eight prime time hours are\ndigital for ABC29. Seven of 21 prime time programming hours are in digital for NBC30.\nMajor networks are currently broadcasting their content today without any sort of copy\nprotection, as evidence that they do not think the broadcast flag is necessary. These\nactions validate the conclusions of the analysis that the major networks are ambivalent\ntoward the broadcast flag.\n4.2.\nConsumer Electronics Manufacturers\nThe following subsection examines the costs and benefits of 5C and non-5C\ncorporations with respect to the broadcast flag. The analysis finds that 5C firms have an\nincentive to support the flag due to licensing proceeds, increased sales of DTV related\nequipment and to create a barrier to entry for other consumer electronic manufacturers.\nOur analysis also finds that non-5C firms will oppose the broadcast flag due to licensing\ncosts imposed by the 5C firms, but will be interested in DTV rollout in hopes of\nincreased sales of related equipment.\n4.2.1. 5C Corporations\nThe consumer electronics industry has a large role in the broadcast flag debate\nsince all consumption of broadcast content will involve manufactured electronics. The\n5C corporations (discussed extensively in the Appendix) bear considerable costs in the\nactual development of the flag-compliant devices. The rather complex standard\ndiscussed above requires the cooperation and coordination of 5 disparate firms, and the\nlegal costs alone of securing an equitable intellectual property mechanism must have\nbeen quite substantial. While the full costs of the standard creation are not known, going\nfrom protocol design to baked silicone entails an extensive procedure. The BPDG set the\nrequired level of robustness rather high; in order to be compliant a device must\n\"effectively frustrate\" attempts to circumvent it. This efficacy requirement is a high\nbarrier that represents a high cost of compliance. The added expense of broadcast flag\ncompatibility will raise the price of the product, and result in a corresponding decrease in\nthe amount purchased. Moreover, the increased cost of manufacturing could affect the\nrevenue streams of an industry where cheap electronics have already dramatically shrunk\n28 \" -----\". \"Primetime Schedule with HDTV.\" Retrieved November 20, 2002, from\nhttp://www.cbs.com/info/hdtv/.\n29 \" -----\". \"Fall 2002.\" Retrieved November 26, 2002, from\nhttp://www.abc.abcnews.go.com/primetime/schedule/index.html. Information was calculated by looking at\nthe web site of each individual show that is linked from this site to see if it is broadcast in HDTV where\navailable.\n30 \" -----\". \"Frequently Asked Questions.\" Retrieved November 20, 2002, from\nhttp://www.nbc.com/nbc/footer/FAQ.shtml.\n\nprofit margins to razor-thin levels31. 5C corporations face the costs of development,\ntogether with threats to their current profitability. Finally, if home recording is going to\nbe substantially more difficult, we can envision a similar substantial reduction in the\nnumber of VCRs bought.\nDespite the costs, these corporations stand to gain two large benefits. First, as\ncommented on above, consumers will have to update their entire home-theatre system,\nwhich gives the CE manufacturers a vast new market. The leading edge is already under\nway, and current digital televisions, although not necessarily flag-compliant, sell at large\nmark-ups for gadget-hungry early-adopters. Soon, every household that wishes to watch\nbroadcast television will be forced to upgrade its television, as well as any peripherals\nthat go with it. This portends millions of dollars in sales in consumer electronics. Yet\nwith the advent of digital and high-definition television, many consumers would\nvoluntarily upgrade, at least purchasing a set-top box tuner when the standard analog\nchannels go dark. Much of the added benefit does not require the implementation of the\nbroadcast flag per se. Rather, the flag affords a second, less obvious benefit to 5C\ncorporations. The consortium collectively owns the standard necessary for compliance,\nand thus all other consumer manufacturers will be forced to license this standard to\ncompete in the television market. At best, this offers the 5C firms a chance to extract\nrents from their intellectual property. At worst, it erects a barrier of entry into the market\nof DTV sets and peripherals, and creates the potential for a cartel to maintain artificially\nhigh prices.\nThe 5C firms stand to make a significant profit from their investment in the 5C\nstandards, a profit that comes at the expense of their competitors and the consumers.\nAgain, we see that this net benefit comes with the broadcast flag but in no way relates to\nthe initial idea driving the public policy. This analysis is affirmed by the general support\nof the 5C industry in furthering the broadcast flag, as evidenced by their commitment to\nmake 5C chips for compliant devices.\n4.2.2. Non 5C CE Firms\nThose CE firms not party to the 5C standard do not, of course, have to directly\nworry about paying for the standard development, but they must pay to license the flag-\ncompliance technology should they wish to continue selling televisions. These fees could\nbe rather high, and offset the benefits of a larger market, since that market might now be\ndominated by 5C firms. If non-5C firms expect to lose market share due to the added\nexpenses they would face, we would expect them to be speaking out against the strict flag\nregime. In fact, they are doing just that, which helps lend credence to our theories about\ndiscriminatory licensing of 5C technology. While supporting Digital Television in\ngeneral, non-5C consumer electronic manufacturers have no incentive to support the\nbroadcast flag itself.\nThe consumer electronics manufacturers can be represented by the Consumer\nElectronics Association (CEA), a group that represents companies involved in the design\nEther, Thomas and Friel, Thomas. Executive Strategy Reports. Retrieved December 9, 2002, from\nhttp://www-1.ibm.com/services/strategy/e_strategy/strat_sucs2.html.\n\nand manufacture of electronics for consumers. The CEA has a close relationship with the\nHome Recording Rights Coalition (HRRC) and consequently shares many views with\nthat organization that seeks to protect the ability of consumers to make recordings in their\nhomes for noncommercial uses. The more than 1000 members of the CEA account for\nmore than $80 billion in sales of consumer electronics each year32. Since consumers will\nhave to buy some form of electronics in order to watch television in the future, these\nconsumer electronics companies, which hold a large share of the market, are a major\nfactor in the broadcast flag debate.\nAs predicted in the analysis, the CEA has taken a firm stance in favor of the\nconsumer's right to record in their home. They say, \"Copyright owners must resist the\ntemptation to restrict technology. If successful, restrictions will deprive the public of\nequal and fair access to information, entertainment and education\"33. This opinion places\nthem firmly in opposition to the implementation of the broadcast flag. However, as also\npredicted by the analysis, the CEA does support digital television in general, as\nevidenced by the creation of \"Digital Television Zones\" throughout the United States34.\nThese DTV Zones are designed to educate the American public about digital television\nand expose them to its better picture and sound quality, in the hopes that this will\nmotivate them to transition to a digital television set. We see that the quotes of non-5C\nCEs support the above cost-benefit analysis in predicting that non-5C CE firms will not\nsupport the broadcast flag, but will be interested in DTV rollout in hopes of increased\nsales.\n4.3.\nConsumers\nThe following subsection examines the costs and benefits of consumers (and\nindirectly consumer advocacy groups) with respect to the broadcast flag. The analysis\nfinds that consumers and consumer advocacy groups will oppose the broadcast flag due\nto the flag imposing additional costs on the DTV transition.\nIt is the consumers, in theory, for whom the broadcast flag is being set up. They\nare, by definition, the ones who will consume the content broadcast under the digital\ntelevision regime. Yet they bear considerable costs. For one, everyone watching digital\ntelevision will have to buy a new television. This is an enormous expense, to be borne\nacross a huge range of incomes, interests, etc, and must be tempered with a few caveats.\nFirst, we must separate the cost of the digital receiver from the high-definition screen,\nitself a very large expense. This leaves the question of where the receiver must live. In\norder for the broadcast flag to have a hope of working, an implementation must close the\nanalog hole. This means that every digital tuner must live inside a 5C compliant device\n32 Joseph, Jeff and Miller, Jenny. \"CEA Reports Record-Setting October DTV Sales.\" Retrieved\nNovember 26, 2002, from http://www.ce.org/press_room/press_release_detail.asp?id=10106.\n33 \" -----\". \"Consumer Home Recording Rights/Copyright Protection.\" Retrieved November 26, 2002,\nfrom\nhttp://www.ce.org/about_cea/cea_initiatives/viewInitiativesOverview.asp?title=Consumer%20Home%20R\necording%20Rights/Copyright%20Protection&name=253.\n34 \" -----\". \"All About Digital TV Zone.\" Retrieved November 26, 2002, from\nhttp://www.digitaltvzone.com/info/about_dtvzone.html.\n\nwhich, of course, must be purchased new, since there are no legacy 5C devices. This\neliminates the possibility of a cheap set-top-box connecting to one's current television set,\nbecause those sets take an un-secured input. So the actual cost to the consumer would be\nthe cost of a new, 5C-compliant television, less the cost of the STB that consumer would\notherwise have to buy to use un-flagged DTV with his or her existing set. These STBs35\nwould essentially be a mass-produced handful of decoders and decrypters, and would\nthus cost much less than a full television set. This still represents a considerable expense.\nThe consumer must not only have a compliant television, however. All peripheries that\ntouch the content, including home recorders and projectors, must be upgraded. There is\nno reason why the price of these compliant devices would go down from their non-\ncompliant brethren, so at a bare minimum, a consumer would have to pay the current\nretail price of each component he or she wishes to continue using.\nBeyond the immediate fiscal cost, all consumers face an encroachment on fair use,\nas is much discussed on consumer and copyright activist forums such as Electronic\nFrontier Foundation (EFF) and DigitalConsumer.org. The authors of this paper do not\nwish to wade into that debate, often filled with hyperbole, but do wish to note that a\nregime designed to protect fair use would not include a 'copy-never' flag at the broadcast\nlevel.36 We would further note the fair-use concerns of the Consumer Group Copyright\nProject, notably the question of who will determine what acceptable fair use is.37\nConsumers face considerable real fiscal costs and a threat of diminished rights over what\nthey can do with publicly broadcast content; what benefits do they derive?\nAt first blush, consumers can claim to get more content and better content over\nbroadcast television. A closer look at where people get their content from shows a\ndifferent story. Almost 70% of American households subscribe to cable, with another\n15% getting extra content from satellite services such as DirecTV38. Assume that very\nfew have both cable and satellite leaves only 15% of American households that will\ndirectly benefit from the increase in network-carried, advertiser-sponsored movies.\nPutting aside the previous discussion of where content is likely to be released, we can see\nthat most TV viewers already have access to some premium content. The subscription-\nbased services use their own encryption, and thus have no need for the broadcast flag.\nThus, if we assume that the current must-carry rules forcing cable companies to transmit\nthe local television stations will at least be voluntarily enforced to carry the new\nHollywood content broadcast under the DTV regime, the flag will affect a very small\nsegment of the viewing audience. The rest can still view movies over other subscription-\nbased services, even if the absence of the flag would force the MPAA members to\nwithhold their movies over DTV. Without exact figures on the demographics to non-\ncable subscribers, we can still surmise that they are either towards the lower end of the\neconomic spectrum or are individuals who simply do not wish to spend heavily on TV\n35 Set-top-box\n36 \" -----\". \"Cablevision in New York City,\" San Jose Mercury News, September 18, 2002.\n37 \" -----\". \"Consumer Policy Questions and Issues Regarding the BPDG Proposal for Protecting DTV\nContent\" by Center for Democracy & Technology, Consumers Union and Public Knowledge. Retrieved\nDecember 9, 2002, from http://www.cdt.org/copyright/020719bpdg.pdf.\n38 \" -----\". \"Cable TV extends its reach\" Lansing State Journal, July 17, 2002. Retrieved on December 9,\n2002, from http://www.lsj.com/things/hughes/020717_cable_1d.html.\n\ncontent. From a social perspective, these are not people who should bear the cost of the\nbroadcast flag.\nAll consumers will have to bear the costs of compliance, however. Even if cable\nsubscribers do not need to immediately rush out to replace their equipment, legislated\ncompliance will raise the price of all TV-related components. Thus, for minimal benefits,\nconsumers across the board will face considerable costs, both real and potential. The\n15% who do rely on broadcast television will face considerable upgrade costs when they\ncould be quite minimal for a STB (Set Top Box), and may not get that much content in\nexchange.\nNot surprisingly, no consumer group supports the broadcast flag. Consumer\nadvocacy groups such as the Electronic Frontier Foundation (EFF) and\nDigitalConsumer.org cite reasons like, \"the biggest problem with the BPDG [who created\nthe standard] is that it strips citizens of their fair use rights\"39 In reference to recent\nCongressional legislation attempting to expedite the broadcast flag process, consumer\ngroups state that the legislature \"asserts that fair-use will be protected while at the same\ntime providing content providers with bulletproof piracy protection. But no such\ntechnology exists to meet both of these goals\"40.\n4.4.\nBroadcasters\nThe following subsection examines the costs and benefits of broadcasters with\nrespect to the broadcast flag. The analysis finds that broadcasters will support the flag\nbecause of sunk costs related to the DTV transition, and in hopes of gaining increased\nmarket share after the DTV transition.\nThe broadcasters are a key actor, understandably, since they will broadcast the\nsignal carrying the flag itself. They bear the head-end costs of inserting the flag, but\nmuch of that is arranged by the content owner. Since they have invested considerable\nexpense in upgrading their traditional NTSC broadcast arrays to handle the new DTV\nstandards, any compliance costs of the flag is fairly small in comparison. Since\nbroadcasters are required by FCC mandate to upgrade their facilities to be capable of\ndigital broadcast, the stations are primarily interested in having consumers ready as soon\nas possible. In the event that the broadcast flag regime slows consumers in their adoption\nof DTV-capable hardware, the DTV market grows more slowly and thus any added\nadvertising revenue would grow more slowly as well. Broadcasters need this revenue to\nrecompense their DTV expenses. Thus the principle cost borne by broadcasters from the\nbroadcast flag would be a delay in DTV diffusion. To minimize their costs, the\nbroadcasters have no interest in blocking the flag itself, merely in preventing the flag\nfrom becoming a stumbling block for DTV rollout. According to Michael Fiorile, the\nTelevision Chair of the National Association of Broadcasters, \"Broadcasters have\n39 \" -----\". \"Frequently Asked Questions.\" Retrieved November 26, 2002, from\nhttp://www.digitalconsumer.org/faq4.html.\n40 Walia, Melissa. \"DigitalConsumer.org Statement on Tauzin Bill Draft.\" Retrieved November 26, 2002,\nfrom http://www.digitalconsumer.org/press-release-2002-09-19.html.\n\ninvested billions of dollars to bring digital television to all American consumers.\"41 As\nevidence of the progress of the transition, 621 stations are currently broadcasting in\ndigital in addition to their normal analog transmissions42. In addition, 94% of homes in\nAmerica are in a market with at least one station broadcasting in digital, and 62% of\nAmerican households are in a market with at least five digital stations43. Because of this,\nNAB president Edward O. Fritts says, regarding the digital transition, that \"there is no\n]\nturning back\"44[48 .\nSince the National Association of Broadcasters has not fought the FCC in\nplanning the new Digital Television regime (indeed, it has lobbied hard for it) we can\nassume they believe that the broadcasters will benefit from it. What is the added\nmarginal benefit of the broadcast flag for NAB constituents? If the MPAA members do\nindeed release more content for broadcast television, this will increase the desirability of\nthe broadcasters' content, helping them gain back some of the market share lost to cable\nover the past 25 years. This market share translates into advertising revenue. Discussion\nabove takes some wind out of the argument that Hollywood content will flood the\nairwaves under a flag regime. The broadcasters merely want DTV out quick and, just as\nimportant, they need to appear as cooperative players to the FCC and other regulators.\nWhy are appearances important? The broadcasters currently control two large chunks of\nelectromagnetic spectrum used for broadcasting: the old analog bands and the newly\nlicensed bandwidth for DTV. They were given the DTV spectrum as a loan, under an\narrangement that would involve them handing over the old spectrum once the full digital\ntransition is completed. Yet recent developments show that the broadcasters have more\nto gain as spectrum controllers. The FCC recently agreed to allow 21 broadcasting\ncompanies to sell off their old UHF spectrum to wireless electronics interests, and keep\nthe full proceeds, \"to clear the band for use by the booming wireless industry.\"45 One\nfirm, Paxson Communications Corp., is likely to receive $1 billion for 17 stations. It is\nvery likely that NAB members feel they will be in a good position to reap similar rewards.\nHence, there is a general reluctance in the broadcasting community to in any way\nobfuscate the DTV transition, including attacking the flag. The broadcasters seek a fast\ndiffusion of digital television, and thus will support the broadcast flag, and they do as\nshown through their statements above, despite the cost-benefit analysis having little to do\nwith the merits of the broadcast flag.\n41 Fiorile, Michael J. \"Testimony of Michael J. Fiorile, President & CEO, Dispatch Broadcast Group,\nNational Association of Broadcasters, Before the House Subcommittee on Telecommunications, September\n25, 2002.\" Retrieved November 26, 2002, from\nhttp://www.nab.org/Newsroom/PressRel/testimonies/Fiorile092502.pdf.\n42 \" -----\". \"DTV Stations in Operation.\" Retrieved November 26, 2002, from\nhttp://www.nab.org/Newsroom/issues/digitaltv/DTVStations.asp.\n43 Wharton, Dennis. \"44 New Stations make DTV Transition.\" Retrieved November 26, 2002, from\nhttp://www.nab.org/Newsroom/PressRel/Releases/dtvlatest.htm.\n44 Fritts, Edward. \"Broadcasters Moving Forward on DTV.\" Retrieved November 26, 2002, from\nhttp://www.nab.org/Newsroom/PressRel/speeches/051502.htm.\n45 Ornstein, Norman and Calabrese, Michael. \"While Nation Distracted by Sept. 11th, FCC Chairman\nAnnounces Corporate Giveaway of UHF Channel Revenues.\" Washington Post, October 14, 2001.\nRetrieved December 9, 2002 from, http://www.webcom.com/hrin/magazine/fcc.html.\n\n4.5.\nCable Companies\nThe following subsection examines the costs and benefits of cable companies\nwith respect to the broadcast flag. The analysis finds that cable companies will support\nthe broadcast flag in hopes of gaining market share from current terrestrial TV viewers\nwho will not want to make the heavy investment in the DTV transition.\nThe chief cost of the cable industry, apart from flag development costs they\nshared, is the threat of lost market. The broadcast industry, after all, hopes that the DTV\nupgrades will draw more viewers, some of whom might be drawn from cable content\nviewers. At the very least, it would mean that more viewers would return to the network\nstations, rather than the cable content stations. As discussed above, users will have to\ninvest significantly to watch this DTV new content. According to the NCTA, the\nNational Cable and Telecommunications Association, a trade association of the cable\nindustries that provides service to over 90% of the households in America with cable\ntelevision46, and represents many cable programming networks as well as equipment\nsuppliers and service providers47, the average consumer will have to spend between\n$1,000 and $3,000 purchasing new digital equipment for the DTV transition.48 As we\nmentioned in our discussion on consumers, a great deal of this expense comes from the\ncompliance requirements of the broadcast flag. Having invested this expense, some\nconsumers might feel that the new HDTV content and Hollywood content meets their\nneeds, and cancel their cable subscription.\nThis high cost of transition applies to those who want to receive DTV content\nfrom the on-air broadcast, however. Thus, cable companies might see the DTV switch as\na chance to improve their market share. There are 35 million households in America\nwithout a cable or satellite subscription49. An average digital cable package from AT&T\ncosts between $50 and $90 month, and analog cable is significantly less.50 Switching\nfrom broadcast to digital cable may be a way for consumers to lower the costs of the\ndigital transition in the short term. They will still be able to receive any content sent over\nthe relevant broadcast frequencies, since one expects the must-carry rule to be at least\nvoluntarily enforced to access the new Hollywood content. Instead of making the large\ninvestment to stay with broadcast television, consumers may switch to digital cable,\nresulting in increased revenue for cable providers. The flag raises the expense of the\ntransition, which in turn makes the cable transition more attractive.\n\"-----.\" About the Industry. Retrieved December 7, 2002, from\nhttp://www.ncta.com/industry_overview/aboutIND.cfm?indOverviewID=1.\n47 Ibid.\n48 Ibid.\n49 Ibid.\n50 \"-----.\" \"AT&T Digital Cable: Packages and Pricing.\" Retrieved December 7, 2002, from\nhttp://www.attbroadband.com/services/pricing/PricingDigitalVideo.jhtml?_requestid=119113.\n\nCable companies have no direct gain from copy protection schemes that apply\nalmost exclusively to broadcast content, and in fact could lose market share, at least in\nterms of which station viewers tune to. However, the fashion in which the broadcast flag\nwill shift the cost structure of the upgrade makes cable television an attractive option for\nnon-subscribers looking for the least expensive way to make the DTV transition.\nIn actuality, the Cable Companies are taking a position in favor of the broadcast\nflag. Robert Sachs, President and CEO of the NCTA has said that his organization is\nworking hard to \"assure that broadcast flag or watermarking mechanisms work\nseamlessly with cable technology.\"51 As a technical solution, the NCTA has said that,\n\"The cable industry supports the proposed 5C technology as an effective way to provide\ncopy protection\"52 In fact, they participated in the CPTWG development process, with a\nspecial eye on cable integration. They have also supported simply including the set top\nbox inside the DTV set, thus eliminating an output that can be used to steal content.\nHowever, cable companies are currently providing programming in HDTV without copy\nprotection on the output from the set top box. For example, \"Time Warner is providing\nHD programming to subscribers in 35 markets.\"53 Other providers are following suit by\nbeginning to provide HDTV programming in other markets. Our analysis indicates that\nthe cable companies' support of the flag could signal that they do not see it as a threat to\nmarket share, and that they, in fact, anticipate an increased market share from current\nterrestrial television watchers who will find cable subscription a smaller investment than\ndigital terrestrial television.\n4.6.\nGovernmental Actors\nThe following subsection examines the costs and benefits of government actors\n(namely the FCC and Congress) with respect to the broadcast flag. The analysis finds\nthat the FCC will support the broadcast flag due to increased authority and expedited\nadoption rate of DTV. The analysis also finds that Congress will both support and\noppose the broadcast flag because it will seek to appease both supporters and opponents\nof the broadcast flag debate.\n4.6.1. FCC\nThe FCC will be responsible for overseeing the multiple regulatory issues under\nthe broadcast flag regime. They have pressed strongly for the entire Digital television\nrollout. In the event that consumer reluctance to purchase new technology slows DTV\nadoption, the FCC would fail to achieve its stated goals. Given the rapid transition\nschedule, the FCC would suffer an image failure as a regulatory agency if it failed to\nproduce a successful and timely transition. The flag could expose the Commission to risk\nhere, if consumers are reluctant to quickly upgrade their home entertainment systems\n51 Sachs, Robert. \"Samuel Morse Did Not Invent the Telegraph.\" Retrieved December 7, 2002, from\nhttp://www.ncta.com/press/press.cfm?prID=243&showArticles=ok.\n52 Willner, Michael. \"Digital Television: A Private Sector Perspective on the Transition.\" Retrieved\nDecember 7, 2002, from http://www.ncta.com/press/press.cfm?prID=103&showArticles=ok.\n53 \"-----.\" \"The Transition to Digital Television.\" Retrieved December 7, 2002 from\nhttp://www.ncta.com/legislative/legAffairs.cfm?legRegID=15.\n\nbecause of the specific increased expenses of the flag. Moreover, as the oversight body\nfor the broadcast flag regime, it would be the focal point for both internal and external\nconflicts. Resources would have to be stretched to evaluate competing claims, such as\ncomplaints about compliance or improper usage. Both the public and Congress would\nlook to the FCC to solve these issues and hold the body responsible for failures.\nMembers of Congress often have favored industries, and would pressure the Commission\nto rule in their favor, threatening funding or legislative delay should the ruling be averse\nto their interests. In sum, the broadcast has a potential to embroil the FCC in a mess that\nit might not want.\nThe flag does offer several benefits, however. The risk of delayed rollout is offset\nby the hope of faster adoption due to more premium content. Moreover, what might be\nlumped as a \"headache\" under costs, would be considered a benefit by many political\nscientists. William Niskanen describes bureaucracies that constantly seek to expand their\nmission, jurisdiction and funding, and certainly the FCC could be seen as belonging in\nthis category.54 Commissioners can increase their power and influence by touching on\nthis very au courante subject of digital copyright, lending their expertise to the debate\nand acquiring a larger role. By vocally supporting the claims of the MPAA and the\ncontent industry, the FCC gains an ally in future fights and the support of a key player\nthat might help reign in many of its regulatees, the broadcasters. Thus, the FCC derives a\nnet benefit from supporting the broadcast flag regime, despite the fact that its expected\nbenefits have little to do with the flag itself. This analysis is verified through the general\nsupport of the broadcast flag in documents commenting on the concept and architecture55.\nIn addition, statements that the FCC has made that indicate that the FCC is concerned\nabout the DTV switch rather than the merits of the broadcast flag. For example:\n\"the current lack of digital broadcast copy protection may be a key impediment to\nthe DTV transition is progress. Without a digital copy protection scheme that\nprevents the unauthorized copying and redistribution of digital media,\nprogramming content providers assert that they will not permit the digital\nbroadcast of high quality programming. Without such programming, consumers\nmay be reluctant to buy DTV receivers and equipment, thereby delaying the DTV\ntransition.\"\nThese statements show that the analysis is correct in predicting that the FCC has motives\nother than copy protection in supporting the broadcast flag.\n4.6.2. Congress\nCongress faces similar costs and benefits as the FCC. If we put aside speculation\nabout whether Congress will ultimately get spectrum auction revenue, a delay in DTV\nadoption will result in a delay in congress getting the auction proceeds (likewise, faster\nadoption means faster money). Congress must also handle the ultimate legislative\nassignments, and must avoid offending any industry, and the representatives that defend\nNiskanen, W. \"Bureaucrats and Politicians,\" Journal of Law and Economics 18 (1975), 617-643.\n55 \"-----.\" \"April 25, 2002 CONTENT PROTECTION STATUS REPORT.\" Retrieved November 15,\n2002, from http://judiciary.senate.gov/special/content_protection.pdf\n\nthose industries. Finally, as the closest and most direct link to consumers, individual\nmembers are the lightening-rods for constituent discontent about unpopular policies.\nCongressmen thus risk being assigned responsibility for a bungled transition, and being\npunished at the ballot box. Television may be important enough in daily lives to be a\nvoting issue.\nLike the FCC, Congress as a whole might be interested in the support of the\nMPAA, particularly in the realm of funding. More important than $3.4 million in MPAA\nPAC money,56 is the idea of avoiding future copyright battles. While political conflict\noften produces the best policies, major players can benefit from producing policy outside\nthe limelight of active congressional debate and in the shadows of precedent and natural\nexpansion.57 By establishing a firm grounding on how IT and copyright interface in the\nrealm of digital TV, Congress has a precedent to refer to when addressing other questions\nof digital rights management. This allows the legislature to address key issues and yet\nnot be forced to line up against the same interest groups that can seek to alter the issues\nfor the next round of debate.\nAs predicted by the analysis, Congress is currently entertaining proposed\nbills that support both sides of the issue. Some bills align themselves with what the\nbroadcast flag supporters are currently saying, while others echo the concerns of those\nopposed to use of the broadcast flag. These bills are not being actively debated in\nCongress now, and it is unclear which ones will actually reach Congress and which ones\nwill be passed.\nAn example of a proposed bill that supports the broadcast flag is the one that has\nbeen proposed by Senate Commerce Committee Chairman Fritz Hollings, as described in\nthe Appendix. This bill would prohibit the sale of any technology that does not adhere to\ncopy protection standards to be determined by the government58. Another bill that\nsupports implementation of the broadcast flag is the one by Representative Billy Tauzin,\nwhich would require that consumer electronics react to the broadcast flag in some way. It\nmay also eliminate analog output from devices.59 Both of these bills, if passed, would\nforce consumers to abide by the broadcast flag and only use compliant devices. They\nwould consequently prevent consumers from practicing the fair use to which they are\naccustomed.\nAn example of a bill that tries to negate the effects of the broadcast flag is the one\nby Representatives Boucher and Doolittle, which is called the Digital Media Consumer\nRights Act. This bill would codify certain fair uses as affirmative rights, and it would\n56[60] Ju, Anne. \"Who's buying into copy controls?\" PC World, June 18, 2002. Retrieved December 9,\n2002, from, http://www.pcworld.com/resource/printable/article/0,aid,101988,00.asp.\n57[61] See, e.g. C. Howard, The Hidden Welfare State. Princeton: Princeton University Press, 1999\n58[62] McCullagh, Declan. \"What Hollings' Bill Would Do.\" Retrieved November 26, 2002, from\nhttp://www.wired.com/news/politics/0,1283,51275,00.html.\n59[63] Schoen, Seth. \"Draft Tauzin Bill Has Broadcast Flag Mandate.\" Retrieved November 26, 2002, from\nhttp://bpdg.blogs.eff.org/archives/000169.html.\n\nalso allow for the circumvention of copy protection measures for non-infringing uses60.\nIf this bill passed, it would still allow consumers to record in the manner that they are\naccustomed to now, whether or not the content they are trying to record is flagged. A\nvery similar bill has been proposed by Representative Zoe Lofgren. These comments\naffirm the analysis by showing that Congress both supports and opposes the broadcast\nflag, although the motivation does not clearly revolve around copy protection.\n4.7\nCost-Benefit Analysis Conclusion\nBy isolating each actor, and then further isolating specific costs and benefits the\nbroadcast flag would impose on that actor, we can get a better picture of who is shaping\nthis policy and why. By then comparing the projected actions of each actor with the\nactual actions and statements of that actor regarding the broadcast flag, we can reaffirm\nthe correctness of our analysis. The costs to consumers overwhelm the projected benefits,\nand they thus stand against it. The TV networks analysis shows to be a wash, and they\nthus have been relatively silent on the topic while broadcasting their digital content\nunprotected. The remaining actors have all pegged their support of the flag onto the\nMPAA's claims that the flag will enable Hollywood content to be broadcast without fear\nof unauthorized content distribution, yet earlier analysis shows this to be an unrealistic\nclaim. Yet each of the remaining actors continues to support the broadcast flag?\nProbing further into the benefits show that each actor may extract considerable\ngain from issues not directly related the flag or DTV content protection. Content owners\ngain the intangible benefits of being able to control the digital copyright debate\noverwhelm their costs. The 5C manufacturers can leverage their market position as\nowners of compliance technology. Broadcasters get a stronger claim over controlling\nhow their current spectrum holdings are sold. The FCC gets a larger mission statement\nand more power, while congress can dispose of a sticky political question.\nThe debate over the broadcast flag, then, is shaped by actors all party to the\nquestion of content protection over the airwaves, but few of them are acting based on\nconcerns directly related to this matter. Since the flag is nominally aimed at DTV, the\ndeciding factors of policy questions are not inspired by the policy problem it is designed\nto solve.\n5.\nConclusion\nThe broadcast flag is a mechanism designed to prevent the illegal redistribution of\ncopyrighted content over the Internet. The MPAA has stated that this is its major reason\nfor supporting the broadcast flag. There are also other ulterior goals of the MPAA,\noutlined in section three, that are further reasons for their support. However, the threat\nanalysis of that section shows that the broadcast flag will not be successful in protecting\ncontent from Internet redistribution. On the other hand, it may help to achieve the other\nsmaller, more incidental, goals of the MPAA, including restricting consumer 'fair use'\ncopying of broadcast television.\n60 Grebb, Michael. \"Bill: Copyright Power to People.\" Retrieved November 26, 2002, from\nhttp://www.wired.com/news/politics/0,1283,55569,00.html.\n\nMany of the influential actors in the situation explicitly support the broadcast flag,\nsaying that it will properly protect copyrighted content, even though section three showed\nthis is not the case. We then take a closer look at each of these key players, including the\nMPAA, consumer electronics companies, broadcasters, the major television networks,\nconsumer groups, cable providers, the FCC, and Congress. We examine each in turn and\nexplore the answer to four issues: what they say about the flag, what they have done with\nrespect to the flag, what they would gain and what they would lose under a broadcast flag\nregime.\nThis cost-benefit analysis shows that the motivations of each of the broadcast flag\nproponents may not be entirely pure. In other words, their reasons for supporting the\nbroadcast flag do not center on concerns for digital copyright or content protection.\nInstead, their support of the broadcast flag often rests on some ancillary benefit, often\ngleaned from another party's reaction to the flag.\nWhen deciding about mandating adoption of the broadcast flag, one must be\ncareful to separate these issues. Decisions must be made in light of the fact that,\naccording to the analysis presented in this paper, the broadcast flag does not achieve its\nmajor stated goal of protecting copyrighted content from redistribution on the Internet.\nAt the same time, it results in great costs to consumers, by both forcing them to buy much\nnew equipment and by eliminating the 'fair uses' to which they have grown accustomed.\nTherefore, the broadcast flag, if implemented, will not serve its intended purpose, while\nat the same time costing consumers and some consumer electronics companies greatly.\nThe decision on whether or not to mandate the broadcast flag must be based on reasons\ndirectly related to the flag. The question of policy should be decided on its merits. In\nother words, the active players should seek direct methods of achieving their goals rather\nthan realizing them indirectly through the broadcast flag. Digital content protection is a\nlarge problem, and requires innovative solutions. It should not come at an inordinate and\ninescapable expense to consumers, however, and should not be used as a vehicle for\ncontent owners to accrue side benefits completely tangential to the policy at hand.\nIt is reasonable to expect that, prior to the widespread adoption of a policy, some\nmotivation should be offered to the public. We show in this paper that the stated\nmotivations by many of the players involved in pushing the broadcast flag are of\ndoubtable veracity at best, and outright insincerity at worst. Before moving forward and\nthreatening greater expense to both themselves and consumers, the key players should re-\nevaluate their goals in the broadcast flag. Since it is usually difficult to hide underlying\nmotivations, especially in a market like this, let them come clean and make their case.\nThe problems of unauthorized distribution can be very real, and if those at risk want the\ncooperation of other players and the general public, let them be honest and make their\ncase directly. Public policy based on subterfuge and misdirection is poor policy.\n\nAppendices\nAppendix 1 - Standards\nThe broadcast flag was suggested following the emergence of digital television.\nAlthough, digital television has only recently begun to obtain subscribers, its roots go\nback to 1984. At that time, digital equipment was already available, but arguments\nregarding how digital television could best serve the interests of the public hindered its\nadvancement. The argument hinged around whether to adopt a system compatible with\nthe then current analog standard (NTSC) or to adopt a simulcast system requiring\nadditional spectrum.61\nNTSC stands for the National Television Standards Committee and is the video\nstandard in North America and other parts of the world for broadcasting video into the\nhome and recording the video on tape. NTSC broadcasts 30 interlaced frames per second\n(60 half frames per second). The signals include an audio FM frequency and an MTS\nsignal for stereo. The signal is a composite of red, green and blue. NTSC is used\nthroughout outside of the United States in countries such as Canada, Japan, South Korea\nand several Central and South American countries62.\nThe European standard for video is PAL, or Phase Alternating Line. PAL was a\ncolor standard developed in Germany and broadcasts 25 interlaced frames per second (50\nhalf frames per second) at 625 lines of resolution. Brazil uses PAL M, which broadcasts\n30 frames per second. Because PAL's color signals are maintained automatically, the TV\nset does not have a user-adjustable hue control. Europe, China as well as various African,\nSouth American and Middle Eastern Countries use PAL. France and Russia and many\nAfrican, Eastern European and Middle Eastern countries use a color TV standard called\nSECAM, or Systeme En Couleaur Avec Memoire. It broadcasts 25 interlaced frames per\nsecond (50 half frames per second) at 625 lines of resolution63.\n61 Whittaker, Jerry. \"Broadcast History: Milestones in the Evolution of Technology .\" Retrieved\nNovember 22, 2002, from http://www.tvhandbook.com/History/History.htm.\n62 \" -----\". \"DTV/HDTV/Flatscreen Specifications.\" Retrieved November 22, 2002, from\nhttp://www.dtvcity.com/resources/tv5.html.\n63 \" -----\". \"DTV/HDTV/Flatscreen Specifications.\" Retrieved November 22, 2002, from\nhttp://www.dtvcity.com/resources/tv5.html.\n\nAppendix 2 - History of DTV\nA2.1. ACATS\nConcrete plans for digital television began in 1987 with FCC establishment of the\nAdvisory Committee on Advanced Television Service (ACATS), an organization whose\nresponsibility would include recommending a broadcasting standard. At the time of the\ninception of the ACATS, it was generally believed that digital could not be broadcast\nusing the 6 MHz standard of analog terrestrial television. Initial reports filed in 1988\nsuggested several standards, ranging from enhancing the current standard to full quality\nhigh definition digital television, using 6 MHz, 9 MHz and 12 MHz. Proponents of the\n12 MHz standard suggested a simulcast option, with one 6 MHz channel utilized to\ntransmit analog terrestrial television, and the other channel containing a high definition\ntelevision (HDTV) signal. However, the report also stated that \"based on current\nbandwidth-compression techniques, it appears that full HDTV will require greater\nspectrum than 6 MHz\"3.\nA2.2. Simulcast\nA frenzy of research began in developing a digital broadcast. As a consequence\nof the research proposals, experts assumed that consumers would be able to purchase\nHDTV for home use as early as 199264. However, the divergent system proponents and\nhardware development delays made meeting such a stringent deadline impossible. A\nserious setback was the adjacent channel interference problem present in VHF and UHF-\nTV bands, which required one non-broadcasting channel interspersed between two active\nchannels. Initial testing began in 1990, using an FCC favored approach employing a\nsimulcast broadcast of one 6 MHz channel for conventional (NTSC) transmission, and\nanother 6 MHz channel for high definition programs to be broadcast on existing VHF and\nUHF channels, but requiring compressing due to the 6 MHz bandwidth requirement.\nA2.2.1. Analogy to Britain's Switch to Color Television\nThe simulcast policy resembled a policy similarly employed during Great\nBritain's transition to color television. Such a policy required monochrome transmission\nfor 20 years after 625-line PAL color transmission began. Monochrome receiver owners\nbenefited, as they were not required to invest in new color receivers, while industry began\ndeveloping a color transmission standard. Eventually, Great Britain reallocated the\nspectrum used for monochrome transmission, as all television is now on UHF,\nreassigning VHF channels to other radio services. The FCC desired to similarly not\ninconvenience viewers with NTSC receivers who would be able to receive the 525-line\nstandard without having to purchase new HDTV receivers. Although not explicitly stated,\n64 Whittaker, Jerry. \"Broadcast History: Milestones in the Evolution of Technology .\" Retrieved\nNovember 22, 2002, from http://www.tvhandbook.com/History/History.htm.\n\nthe FCC presumed the must-carry provision65 stating that broadcasters transmitting the\nHDTV standard would carry programs offered on the NTSC standard.\nA2.2.2. First Digital Simulcast\nDespite FCC announcements regarding the feasibility of HDTV transmission,\nmost consumers considered the technology to be in the early stages of development.\nHowever, in 1990, General Instrument was the first company to announce an all-digital\nsystem. MIT, Philips-Thomson-Sarnoff consortium and Zenith-AT&T followed suit\nshortly thereafter. After and ACATS recommendation of surround sound audio and\nadaptive data-allocation capability, proposals were limited to only those by the four\ninitial developers. Although all systems exhibited impressive results, the Advisory\nCommittee strove to unify these proposals under a \"best system\". Such was the reason\nbehind the formation of the Digital HDTV Grand Alliance. By 1994, final HDTV\nproposals were placed on the table with such features as digital video compression,\npacketized data, audio, modulation and scanning formats. The proposal included the\nfollowing features:\n- Support of two fundamental arrays of pixels (picture elements): 1920 x 1080 and\n1280 x 720. Each of these pixel formats supported a wide-screen 16:9 aspect ratio\nand square pixels, important for computer interoperability. Frame rates of 60, 30,\nand 24 Hz were supported, yielding a total of six different possible scanning\nformats--two different pixel arrays, each having three frame rates. The 60 and 30\nHz frame rates were important for video source material and 24 Hz for film. A\nkey feature of the system was the Grand Alliance's commitment to using\nprogressive scanning, also widely used in computer displays. Entertainment\ntelevision traditionally had used interlaced scanning, which was efficient but\nsubject to various unwanted artifacts. Of the six video formats, progressive\nscanning was used in all three 720-line formats and in the 30 and 24 Hz 1080-line\nformats. The sixth video format was a 60 Hz 1080-line scheme. It was neither\ntechnically or economically feasible to initially provide this as a progressive\nformat, although it was a longer-term goal for the Grand Alliance. The 1080-line,\n60-Hz format was handled in the initial standard by using interlaced rather than\nprogressive scanning.\n- Video compression: Utilizing the MPEG-2 (Moving Picture Experts Group)-\nproposed international standard allowed HDTV receivers to interoperate with\nMPEG-2 and MPEG-1 computer, multimedia, and other media applications.\n- Packetized data transport: Also based on MPEG-2, this feature provided for the\nflexible transmission of virtually any combination of video, audio, and data.\n- Compact-disc-quality digital audio: This feature was provided in the form of the\n5.1-channel Dolby AC-3 surround sound system.\n65 The must-carry provision contained in the Cable Television Consumer Protection and Competition Act of\n1992 was upheld by the Supreme Court on March 31, 1997 in Turner Broadcasting System, Inc. v. FCC.\nWith this decision, the Court emphasized the benefits of free, over-the-air broadcast television and the\nimportance of widespread dissemination of information from multiple sources. This case did not\nspecifically address the issue of must -carry of digital television signals.\n\n- 8-VSB (8-level vestigial sideband): The modulation system selected for\ntransmission provided maximum coverage area for terrestrial digital broadcasting.\nSource: HDTV History66\nA2.3. ATSC\nField and laboratory testing of the Grand Alliance standard indicated that the\ndigital transmission standard would provide better performance then the current analog\nsystem. The ACATS recommended the new standard to the FCC in 1995. Due to\nobjections from the motion picture industry regarding the wide-screen aspect ration and\nthe computer industry's objections regarding interlaced scanning, the 60 Hz scan rate and\nsquare pixels, the FCC adopted a standard without a single digital television video format.\nThis lack of format was expected to encourage competition between personal computer\nmanufacturers whose products would compete within the sharp picture and consumer-\nfeature specific arena. Later that year, the FCC created the Advanced Television Systems\nCommittee of the DTV standard. This group was composed of 160 member corporations,\nstandards bodies, educational institutions, research laboratories, and industry associations.\nThis group would develop voluntary standards for the entire range of advance television\nsystems, including computers, television sets and consumer video devices, in cooperation\nwith the Consumer Electronics Manufacturers Association.\nA2.4. Timetable for Implementation\nWith the standard set, broadcasters were faced with a timetable for\nimplementation. By late 1998, the 26 TV station in the country's most populous cities\nwould begin broadcasting the using the Grand Alliance DTV system. This initial\nbroadcast would reach 30% of U.S. television households. By 1999, that number would\nexpand to 40 and by 2000, that number would reach 120 stations. By 2006, every station\nwould be expected to transmit all content digitally for fear of losing the FCC license.\nThe first digital broadcast occurred on October 29, 1998 with the launch of John Glenn\nback into space, with transmission by ABC, CBS, Fox, NBC and PBS affiliates.67\nBroadcasting cities included Washington, D.C., New York, Atlanta, Chicago, Los\nAngeles, and transmission was free to any broadcaster who could receive the signal. The\nlaunch was filmed using HD cameras, but on occasion, the director would switch\nbetween standard-definition and high-definition, allowing viewers to witness the\ndifference in the image. By January of 2001, there were 177 stations broadcasting DTV\nsignals to 61 markets covering 67% of U.S. TV households, according to an NAB\nsurvey.\n66 \" -----\". \"DTV/HDTV/Flatscreen Specifications.\" Retrieved November 22, 2002, from\nhttp://www.dtvcity.com/resources/tv5.html.\n67 \" -----.\" \"DTV/HDTV/Flatscreen Specifications.\" Retrieved November 22, 2002, from\nhttp://www.dtvcity.com/resources/tv5.html.\n68 \"-----.\" \"TV Today\". Retrieved November 15, 2002, from http://www.nab.org.\n\nA2.5. HDTV vs. SDTV\nThere are two different standards for digital television. Although during the\nsimulcast period the FCC did not mandate a standard on to a broadcaster, it did mandate\nthat the resolution of the free broadcasting be better than what is currently available via\nanalog. The FCC allowed the broadcaster to use his discretion regarding whether to\nprovide high definition television or to simulcast the NTSC stream on DTV. In addition,\nthe FCC did not mandate what and how many ancillary and supplemental services to\nprovide69. The ancillary and supplemental services could include subscription television\nprogramming, computer software distribution, data transmissions, teletext, interactive\nservices, audio signals, and any other services that do not interfere with the required free\nservice. By allowing broadcasters the flexibility to decide the format of services and the\nservices to provide, the FCC felt that the broadcasters will provide services and best suit\nconsumer demand, increasing broadcasters' profits, and will promote consumer\nacceptance of digital television.\nA2.5.1. FCC 4th and 5th Orders Regarding SDTV and HDTV\nIn addition, the fourth Report and Order by the FCC allowed broadcasters to offer\nseveral digital programs by multicasting. Multicasting allows a content provider to offer\nup to seven SDTV programs in the space occupied by one HDTV program on DTV. In\nits fifth Report and Order, the FCC stated that the standard also allowed broadcast of CD-\nquality audio and transmission of voice video and data simultaneously. The switching\nbetween these venues can be done dynamically, allowing a broadcaster to transmit a\n\"news program consisting of four separate SDTV programs for local news, national news,\nweather and sports; while interrupting that programming with a single high definition\ntelevision commercial with embedded data about the product; or transmit a motion\npicture in a high definition format, while simultaneously using the excess capacity for\ntransmission of data unrelated to the movie\"70.\nA2.5.2. HDTV and SDTV Standards Defined\nDigital televisions refers to any television containing a receiver device that can\naccept and display DTV broadcasts. Such DTV-ready televisions require a set-top\ndecoder box to decode the incoming digital broadcast. The broadcast can either be\nSDTV, standard definition TV, or HDTV, high definition TV. An SDTV compatible\ntelevision allows the viewer to connect the component video inputs to the unit for\nviewing standard broadcasts in either 480i or 480p formats. This set-up requires a DTV\nset top box and possibly an air antenna. High definition television refers to those devices\nthat can display the highest resolution as defined by the ATSC standard. This resolution\ntranslates to 1,080 vertical lines and 1,920 horizontal pixels, or 720 vertical lines and\n1,280 horizontal pixels. This device has a wide screen with a 16:9 aspect ratio. Like\nSDTV, this set-up requires a set-top box and possibly an antenna. An HDTV device may\nbe compatible with the cable system in the future.\n69 \"-----.\" 1997 FCC 5th Report and Order (FCC 97-16). Adopted April 3, 1997.\n70 \"-----.\" 1997 FCC 5th Report and Order (FCC 97-16). Adopted April 3, 1997.\n\nA2.5.3. DTV Savings over Analog\nDigital offers an enormous amount of compression compared to what is possible\nin the analog domain. Tremendously better picture, sound and quality are possible in the\noriginal 6 MHz bandwidth per channel than what is possible with analog signals in 9\nMHz71. Even greater savings comes from the elimination of a blank channel between\nevery active channel on the air, as needed with analog. Seeing the tremendous reductions,\nthe government would like to encourage investment in digital television. They would\nlike to regain and resell the original NTSC spectrum granted to FCC licensed\nbroadcasters in exchange for DTV spectrum with the same bandwidth.\nA2.6\nFCC Timeline for Adoption\nThe FCC has set up a stringent timeline for adoption of DTV, and released the\nimplementation schedule in April of 1997. The following timeline was obtained from the\noriginal FCC docket entitled the FCC 5th Report and Order.\nDTV Simulcast Schedule\nThe following information was derived, in part, from the FCC 5th Report & Order\nYear\nPercentage of Content Simulcast\nSimulcast Deadlines\n50%\nApril 3, 2003\n75%\nApril 3, 2004\n100%\nApril 3, 2005\nSource: Analysis provided by Fedele & Associates - A technical advisory group\nAfter the 100% of content is broadcast in digital, the FCC will terminate and reallocate\nthe analog spectrum. The FCC has targeted 2006 for the cessation of the analog service.\nHowever, the 1996 Act requires that the commission allow licenses to those who offer\nancillary or supplementary services on a subscription basis and with a fee72.\nA2.7. Slow Adoption of DTV\nBy 2001, adoption of digital television had been slow. The Consumer Electronics\nAssociation stated that after more than two years of availability, HDTV shipments totaled\nonly 625,000 in 2000 compared with 25 million TVs overall. Networks attempted to\n71 Kane, Joe, and Gary Reber. \"Implementing HDTV.\" Retrieved November 21, 2002, from\nhttp://www.widescreenreview.com/attractions/insdhdtv.html.\n72 \"-----.\" 1997 FCC 5th Report and Order (FCC 97-16). Adopted April 3, 1997.\n\nencourage HDTV subscriptions through new hit series such as \"The Sopranos\" in high\ndefinition format. However, the lackluster adoption gave broadcasters little reason to\nbroadcast in HDTV format, and gave consumers little reason to invest thousands of\ndollars for digital television sets73.\n73 Goroch, Antonette. \"HD in the Clouds? DBS seek to stay ahead, despite slow growth in HDTV.\"\nJanuary 22, 2001. Retrieved November 21, 2002, from\nhttp://www.broadbandweek.com/news/010122/010122_wireless_hdtv.htm.\n\nAppendix 3 - The MPAA and the Broadcast Flag\nCongress attributed the slow adoption of digital television to the lack of quality\ncontent on terrestrial television, and looked to the MPAA (Movie Picture Association of\nAmerica) to provide that content on digital television. However, the MPAA had stated\nthat it would not release content without copyright protection enforcement. Unlike\nDVDs and cable, which are delivered encrypted to the viewer, digital broadcasting must\nbe delivered unencrypted. In fact, the FCC requires that this terrestrial broadcast\ntelevision be sent \"in the clear\". The MPAA fears delivering high-quality, unencrypted\ncontent digitally, because viewers could record shows and later make them available on\nthe Internet. The MPAA feels that their refusal to deliver content without protection is\njustified, and that such protection should be supported via the DMCA (Digital\nMillennium Copyright Act) that made circumventing copy protection measures illegal\nand that provided corporations with a legal tool to protect their intellectual property.\nThe Motion Picture Association of America is the trade association of the\nAmerican film industry. They represent many major producers and distributors of\nmotion picture and television programs in the United States, including Walt Disney\nCompany, Sony Pictures Entertainment, Metro-Goldwyn-Mayer, Paramount Pictures\nCorporation, Twentieth Century Fox Film Corp., Universal Studios, and Warner Bros74.\nThe MPAA represents the interests of its members by lobbying in Washington D.C. The\nmembers of the MPAA grossed over $8.4 billion in box office sales in 200175. The sheer\neconomic size of the MPAA makes it a very powerful lobbying group. The MPAA is\nalso an influential member of the CPTWG and the BPDG, which were described above.\n74 \" -----\". \"About MPA, MPAA.\" Retrieved November 26, 2002, from\nhttp://www.mpaa.org/about/index.htm.\n75 MPAA Research Department. \"2001 U.S. Economic Review.\" Retrieved November 26, 2002, from\nhttp://www.mpaa.org/useconomicreview/2001Economic/sld002.htm.\n\nAppendix 4 - Compliant Devices\nA4.1. DTCP and HDCP\nCompliant devices are needed to mandate adherence to broadcast flag proposals.\nCopy-control schemes for digital audio, called DTCP (Digital Transmission Content\nProtection), have been devised by five companies, including Sony, Hitachi, Intel,\nMatsushita, and Toshiba called the 5C consortium. This scheme encrypts video\ntransmitted over a digital cuss called IEEE 1394, or FireWire. A similar copy control\nscheme called HDCP, High-bandwidth Digital Content Protection, encrypts video\ntransmitted over a video-specific bus called DVI, Digital Video Interface. This was\ndesigned by the 4C companies, which are IBM, Intel, Matsushita and Toshiba. The\nHDCP process consists of authentication, encryption and renewal. Authentication occurs\nwhen a source device and a display device authenticate each other. Once the party\nestablishes a sense of trust for the other, the source encrypts the content and transports the\ncontent to the display. The display then decrypts the content. Renewal occurs every two\nto three seconds during HDCP. While the high definition stream is playing, the device\nre-authenticates every two to three seconds. Should either party fail during renewal, the\nsession is abandoned and the stream ceases playing. The Digital Content Protection LLC\ncan send source devices messages regarding a list of devices that are no longer authorized\nto play HD content. If such a device attempts to interact with a compliant device,\nencryption of content will be prevented from occurring.\nThe HDCP and DVI combination does not allow for recording, only transmission.\nHowever, the 5C consortium through the DTCP, the leading candidate to enable this\nfunctionality through a FireWire interface. This interface permits recording in addition to\nbi-directional flow and networking capabilities. 1394 does not have the bandwidth to\ntransport uncompressed high definition content76, as does DVI, and must compress\ncontent before transmission. Compression would occur with algorithms such as MPEG-2\nwhose impact on picture quality is negligible.77 Once installed a 1394 device will\ninteract with a TV or a set-top box automatically, unlike the current TV/VCR interaction.\nWithout the DTCP standard, the 1394 protocol does not address security. In fact,\nthe protocol increases to risk of theft above that of DVI, simply because the transmission\nis more difficult to protect. However, DTCP performs authentication, encryption and\nrenewal (similar to HDCP) to protect the content from piracy. The major difference\nbetween the two protocols is DTCP's functionality to conduct two authentication modes,\na restricted mode and a full mode. Full authentication occurs when the protocol prevents\nrecording in compliant devices such as set-top boxes. However, this symmetric\nauthentication mechanism requires extensive processing and memory, and restricted\nauthentication is used when copying is permitted or when content is being transferred\nfrom one device to another. This method of authentication is less robust than the\nformer.78 Like HDMI, DTCP allows for System Renewability Messages (SRMs) to be\n76 1394 can only transmit up to 400 Mbps.\n77 deCarmo, Linden. \"Changing of the Guard.\" Retrieved Nov 15, 2002, from\nhttp://www.emedialive.com/r5/2002/decarmo11_02.html.\n78 Ibid.\n\nsent to compliant devices warning them of unauthorized devices authenticating as\ncompliant. However, because the 5C devices can be networked, they have the ability to\npass on the list to other compliant devices on the network.\nA4.2. Types of Copying Allowed under DTCP\nBoth these mechanisms are activated only when a copy protection is requested,\nvia insertion of a Copy Control Information flag into the MPEG-2 stream. Settings for\nthe Flag are Copy Free, Copy Once, Copy No More and Copy Never. If the content's\nflag is set to copy free, the content owner places no restriction on copying of the content\ndisplayed by compliant devices. On the contrary, a Copy Never CCI setting requires full\nauthentication and no copies are permitted of the stream. Copy Once permits a user to\nmake one backup copy. The mechanism first attempts full authentication, and if that fails\ndue to limited memory, it reverts back to restricted authentication. However, the analog\ncomponent of the content is down-sampled. A Copy No More prevents other devices on\nthe network from making further copies of the original broadcast. The functionality of\nCopy No More is similar to Copy Never, with the exception that Copy No More content\nmay be played back on devices that support full or restricted authentication whereas copy\nnever content only operates on devices requiring full authentication.\nA4.3. 5C and Broadcast Flag Interaction\nIn the realm of digital television, the digital broadcast flag functions as the CCI\nflag. It is placed in the basic MPEG transport stream, when the stream is first created.\nHowever, adoption of new compliant devices and mandating that only those compliant\ndevices will be able to receive quality programming obsoletes millions of current devices,\nstates the CEA. The Consumer Electronics Association worries that the 30 million DVD\nplayers sold will not be able to play DVD's that contain broadcast flag protected digital\nprograms. Hollywood has stated that it does wish to exclude the current tens of millions\nof existing products from adhering to broadcast flag protection, by enacting grandfather\nclauses in legislation. Hollywood fears this type of Internet distribution by current\nelectronics.\n\nAppendix 5 - Congressional Legislation\nA5.1.\nTauzin Bill\nThe support of the broadcast flag by certain members of congress is evident\nthrough recent legislation that has come up on the congressional floor. Republican Billy\nTauzin has proposed a measure for broadcast flag adoption and the ending on analog\ntelevision capability, and increased cable interoperability. Tauzin sees the need for the\nlatter due to \"the lack of progress in private, inter-industry negotiations and the number of\noutstanding FCC rulemakings [which] has led to uncertainty in the marketplace, and\nmakes it very difficult for businesses to make solid plans for the future\".79 Mandating\nthat no analog ports be added to digital devices would make VCR's and other analog\nmedia obsolete. In addition, Tauzin's bill states the \"television broadcasters would be\nrequired to cease analog television service by December 21, 2006\" and that devices\nwould have to recognize the broadcast flag by January 1, 2006 in order to prevent\nunauthorized distribution of content over the Internet.\nA5.2.\nHollings Bill and Letter\nIn another congressional proposal, Senator Hollings, chairman of the senate\ncommerce committee, urged Chairman Powell to move quickly to implement the\nbroadcast flag mandate, without additional legislation in a letter to the Chairman. In his\nletter, Hollings suggested that 47 USC 336(b)(4) and (b)(5) already give Powell the\nauthority to impose such regulations. Hollings states that it is \"beyond dispute that the\npublic interest would be served\" by this mandate. In addition, Hollings also proposed the\nSecurity System Standards and Certification Act (SSCA), which makes production or\nsale of devices without \"certified security technologies\" a civil offense. This legislation\nhas not yet been formerly introduced, however, it is known that it would impose criminal\npenalties to persons altering or disabling current copy protection schemes.\nA5.3\nLofgren Bill\nIn October 2002 Congresswoman Zoe Lofgren (D-CA) introduced the \"Digital\nChoice and Freedom Act of 2002.\" The bill, which has not yet been passed, clarifies that\nthe principles of fair use as outlined in Section 107 of the Copyright Act do apply to\ndigital transmissions, and protects the rights of consumers to make copies of digital\nworks for personal use, as has been allowed with analog works for years.\nLofgren's bill, which has the backing of the EFF and numerous other consumer advocacy\ngroups, limits the extent to which copyright holders can dictate how their content is used.\nAccording to the bill, consumers will be able to reformat copies of digital works to play\non devices of their choice, and will be able to sell or give away their digital copy of a\nwork. Lofgren's bill also changes the law as amended by the DMCA to allow consumers\nto circumvent technological restrictions on copying for the purpose of making fair use of\na legally acquired work.\n79 King, Brad. \"New Bill: More Digital TV Limits.\" Retrieved November 15, 2002, from\nhttp://www.wired.com/news/print/0,1294,55276,00.html.\n\nBibliography\n\"-----.\" 1997 FCC 5th Report and Order (FCC 97-16). Adopted April 3, 1997.\n\"-----.\" About the Industry. Retrieved December 7, 2002, from\nhttp://www.ncta.com/industry_overview/aboutIND.cfm?indOverviewID=1.\n\"-----.\" \"About MPA, MPAA.\" Retrieved November 26, 2002, from\n\nhttp://www.mpaa.org/about/index.htm.\n\"-----.\" \"All About Digital TV Zone.\" Retrieved November 26, 2002, from\n\nhttp://www.digitaltvzone.com/info/about_dtvzone.html.\n\"-----.\" \"The Anatomy of a Monster\" from Frontline, The Monster that Ate Hollywood.\nRetrieved December 9, 2002, from\nhttp://www.pbs.org/wgbh/pages/frontline/shows/hollywood/business/windows.html.\n\"-----.\" \"April 25, 2002 CONTENT PROTECTION STATUS REPORT.\" Retrieved\nNovember 15, 2002, from\n\nhttp://judiciary.senate.gov/special/content_protection.pdf.\n\"-----.\" \"BPDG Compliance and Robustness Rules draft.\" Retrieved December 1, 2002\n\nfrom http://www.eff.org/IP/Video/HDTV/20020414_bpdg_compliance_rules.pdf.\n\"-----.\" \"Broadcast Flag Frequently Asked Questions.\" Retrieved December 9, 2002,\n\nfrom http://www.mpaa.org/Press/Broadcast_Flag_QA.htm.\n\"-----.\" \"Cable TV extends its reach\" Lansing State Journal, July 17, 2002. Retrieved\non December 9, 2002, from\n\nhttp://www.lsj.com/things/hughes/020717_cable_1d.html.\n\"-----.\" \"Cablevision in New York City,\" San Jose Mercury News, September 18, 2002.\n\"-----.\" \"Consumer Home Recording Rights/Copyright Protection.\" Retrieved\nNovember 26, 2002, from\n\nhttp://www.ce.org/about_cea/cea_initiatives/viewInitiativesOverview.asp?title=\n\nConsumer%20Home%20Recording%20Rights/Copyright%20Protection&name=\n253.\n\"-----.\" \"Consumer Policy Questions and Issues Regarding the BPDG Proposal for\nProtecting DTV Content\" by Center for Democracy & Technology, Consumers\nUnion and Public Knowledge. Retrieved December 9, 2002, from\n\nhttp://www.cdt.org/copyright/020719bpdg.pdf.\n\"-----.\" \"Draft TV Mandate Bill Freezes Innovation.\" Electronic Frontier Foundation.\nRetrieved December 7, 2002, from\n\nhttp://www.eff.org/IP/Video/HDTV/20020919_eff_pr.html\n\n\"-----.\" \"DTV/HDTV/Flatscreen Specifications.\" Retrieved November 22, 2002, from\n\nhttp://www.dtvcity.com/resources/tv5.html.\n\"-----.\" \"DTV Stations in Operation.\" Retrieved November 26, 2002, from\n\nhttp://www.nab.org/Newsroom/issues/digitaltv/DTVStations.asp.\n\"-----.\" \"Electronic Frontier Foundation Supports Digital Media Bills\" Electronic\nFrontier Foundation. Retrieved December 7, 2002, from\nhttp://www.eff.org/IP/DMCA/20021003_eff_pr.html\n\" -----.\" \"Fall 2002.\" Retrieved November 26, 2002, from\n\nhttp://www.abc.abcnews.go.com/primetime/schedule/index.html\n\"-----.\" \"Final Report of the Co-Chairs of the Broadcast Protection Discussion Subgroup\nto the Copy Protection Technical Working Group, June 3, 2002.\" Retrieved\nDecember 9, 2002, from\n\nhttp://www.cptwg.org/Assets/BPDG/BPDG%20Report.DOC.\n\"-----.\" \"Frequently Asked Questions.\" Retrieved November 26, 2002, from\n\nhttp://www.digitalconsumer.org/faq4.html.\n\"-----.\" \"Frequently Asked Questions.\" Retrieved November 20, 2002, from\n\nhttp://www.nbc.com/nbc/footer/FAQ.shtml.\n\"-----.\" \"Hackers Play with the Xbox.\" (n.d.). BBC News. Retrieved December 7, 2002,\n\nfrom http://news.bbc.co.uk/1/hi/sci/tech/2067045.stm\n\"-----.\" \"Primetime Schedule with HDTV.\" Retrieved November 20, 2002, from\nhttp://www.cbs.com/info/hdtv/.\n\"-----.\" \"The Transition to Digital Television.\" Retrieved December 7, 2002 from\n\nhttp://www.ncta.com/legislative/legAffairs.cfm?legRegID=15.\n\"-----.\" TV Guide Nov. 16-22 2002, p.82: Local Boston ABC affiliate broadcasts The\n\nSixth Sense (1999)\n\"-----.\" \"TV Today.\" Retrieved November 15, 2002, from http://www.nab.org.\nAT&T Digital Cable: Packages and Pricing. Retrieved December 7, 2002, from\n\nhttp://www.attbroadband.com/services/pricing/PricingDigitalVideo.jhtml?_reques\ntid=119113.\ndeCarmo, Linden. \"Changing of the Guard.\" Retrieved Nov 15, 2002, from\n\nhttp://www.emedialive.com/r5/2002/decarmo11_02.html.\nDoctorow, Cory. \"Understanding the Broadcast Flag.\" Retrieved November 15, 2002,\n\nfrom http://www.techtv.com.\nEther, Thomas and Friel, Thomas. Executive Strategy Reports. Retrieved December 9,\n\n2002, from http://www-1.ibm.com/services/strategy/e_strategy/strat_sucs2.html.\nFiorile, Michael J. \"Testimony of Michael J. Fiorile, President & CEO, Dispatch\nBroadcast Group, National Association of Broadcasters, Before the House\nSubcommittee on Telecommunications, September 25, 2002.\" Retrieved\nNovember 26, 2002, from\n\nhttp://www.nab.org/Newsroom/PressRel/testimonies/Fiorile092502.pdf.\nFritts, Edward. \"Broadcasters Moving Forward on DTV.\" Retrieved November 26,\n\n2002, from http://www.nab.org/Newsroom/PressRel/speeches/051502.htm.\nGoroch, Antonette. \"HD in the Clouds? DBS Seek to Stay Ahead, Despite Slow Growth\nin HDTV.\" January 22, 2001. Retrieved November 21, 2002, from\nhttp://www.broadbandweek.com/news/010122/010122_wireless_hdtv.htm.\nGrebb, Michael. \"Bill: Copyright Power to People.\" Retrieved November 26, 2002,\nfrom http://www.wired.com/news/politics/0,1283,55569,00.html.\nHoward, C. The Hidden Welfare State. Princeton: Princeton University Press, 1999\nJoseph, Jeff and Miller, Jenny. \"CEA Reports Record-Setting October DTV Sales.\"\nRetrieved November 26, 2002, from\nhttp://www.ce.org/press_room/press_release_detail.asp?id=10106.\nJu, Anne. \"Who's buying into copy controls?\" PC World, June 18, 2002. Retrieved\nDecember 9, 2002, from,\n\nhttp://www.pcworld.com/resource/printable/article/0,aid,101988,00.asp.\nKane, Joe, and Gary Reber. \"Implementing HDTV.\" Retrieved November 21, 2002,\n\nfrom http://www.widescreenreview.com/attractions/insdhdtv.html.\nKing, Brad. \"HDTV Battle Wages On.\" Retrieved November 22, 2002, from\n\nhttp://www.wired.com/news/digiwood/0,1412,53835,00.html.\nKing, Brad. \"New Bill: More Digital TV Limits.\" Retrieved November 15, 2002, from\n\nhttp://www.wired.com/news/print/0,1294,55276,00.html.\nLitman, Jessica. Digital Copyright. Amherst, NY: Prometheus Books, 2001.\nMcCullagh, Declan. \"What Hollings' Bill Would Do.\" Retrieved November 26, 2002,\n\nfrom http://www.wired.com/news/politics/0,1283,51275,00.html.\nMPAA Research Department. \"2001 U.S. Economic Review.\" Retrieved November 26,\n\n2002, from http://www.mpaa.org/useconomicreview/2001Economic/sld002.htm.\n\nNiskanen, W. \"Bureaucrats and Politicians,\" Journal of Law and Economics 18 (1975),\n617-643.\nOrnstein, Norman and Calabrese, Michael. \"While Nation Distracted by Sept. 11th, FCC\nChairman Announces Corporate Giveaway of UHF Channel Revenues.\"\nWashington Post, October 14, 2001. Retrieved December 9, 2002 from,\n\nhttp://www.webcom.com/hrin/magazine/fcc.html.\nSachs, Robert. \"Samuel Morse Did Not Invent the Telegraph\". Retrieved December 7,\n\n2002, from http://www.ncta.com/press/press.cfm?prID=243&showArticles=ok.\nSchoen, Seth. \"Draft Tauzin Bill Has Broadcast Flag Mandate.\" Retrieved November\n26, 2002, from http://bpdg.blogs.eff.org/archives/000169.html.\nVon Lohmann, Fred. (2001) \"Peer-to-Peer File Sharing and Copyright Law after\nNapster.\" Retrieved December 7, 2002, from\n\nhttp://www.eff.org/IP/P2P/20010227_p2p_copyright_white_paper.html\nWalia, Melissa. \"DigitalConsumer.org Statement on Tauzin Bill Draft.\" Retrieved\nNovember 26, 2002, from http://www.digitalconsumer.org/press-release-2002-09-\n\n19.html.\nWharton, Dennis. \"44 New Stations make DTV Transition.\" Retrieved November 26,\n\n2002, from http://www.nab.org/Newsroom/PressRel/Releases/dtvlatest.htm.\nWhittaker, Jerry. \"Broadcast History: Milestones in the Evolution of Technology .\"\nRetrieved November 22, 2002, from\n\nhttp://www.tvhandbook.com/History/History_dtv.htm.\nWillner, Michael. \"Digital Television: A Private Sector Perspective on the Transition.\"\nRetrieved December 7, 2002, from\n\nhttp://www.ncta.com/press/press.cfm?prID=103&showArticles=ok.\nWiley, Lauren. \"BPDG Proposes Broadcast Flag to Protect DTV Broadcasts.\" Retrieved\nNovember 15, 2002, from\n\nhttp://www.emedialive.com/r10/2002/news0802_02.html."
    },
    {
      "category": "Resource",
      "title": "caps.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/4ca7556dd68519dad56ab89801ad502c_caps.pdf",
      "content": "Carnival Booth: An Algorithm for Defeating the\nComputer-Assisted Passenger Screening System\n\nSamidh Chakrabarti\nAaron Strauss\n\n6.806: Law and Ethics on the Electronic Frontier\nMay 16, 2002\n\n- 1 -\n\nAbstract\n\nTo improve the efficiency of airport security screening, the FAA deployed the Computer Assisted\nPassenger Screening system (CAPS) in 1999. CAPS attempts to identify potential terrorists\nthrough the use of profiles so that security personnel can focus the bulk of their attention on high-\nrisk individuals. In this paper, we show that since CAPS uses profiles to select passengers for\nincreased scrutiny, it is actually less secure than systems that employ random searches. In\nparticular, we present an algorithm called Carnival Booth that demonstrates how a terrorist cell\ncan defeat the CAPS system. Using a combination of statistical analysis and computer simulation,\nwe evaluate the efficacy of Carnival Booth and illustrate that CAPS is an ineffective security\nmeasure. Based on these findings, we argue that CAPS should not be legally permissible since it\ndoes not satisfy court-interpreted exemptions to the Fourth Amendment. Finally, based both on\nour analysis of CAPS and historical case studies, we provide policy recommendations on how to\nimprove air security.\n\n- 2 -\n\nTable of Contents\n\n1 Introduction..................................................................................................................... 4\n2 Defining CAPS ............................................................................................................... 7\n2.1 Government Guidelines ............................................................................................ 7\n2.2 CAPS Architecture.................................................................................................... 8\n2.3 Special Treatment ................................................................................................... 10\n3 Defeating CAPS............................................................................................................ 10\n3.1 Carnival Booth Algorithm ...................................................................................... 11\n3.2 Cells vs. Individuals................................................................................................ 12\n3.3 Algorithm Assumptions.......................................................................................... 13\n4 Evaluating Carnival Booth............................................................................................ 15\n4.1 Probabilistic Analysis ............................................................................................. 15\n4.2 Computer Simulation.............................................................................................. 19\n5 Case Studies.................................................................................................................. 21\n5.1 Ressam's 1999 Terrorist Attempt.......................................................................... 22\n5.2 The El Al Standard................................................................................................. 23\n6 Legal Implications ........................................................................................................ 25\n6.1 Administrative Search Exception ........................................................................... 26\n6.2 Stop-and-Frisk Exception ....................................................................................... 27\n7 Policy Recommendations.............................................................................................. 28\n\n- 3 -\n\n1 Introduction\n\nOn the morning of September 11, 2001, nineteen terrorists boarded four separate\ncommercial airplanes across the northeastern seaboard of the United States. Moments after\ntakeoff, they made their moves. Using the cardboard box cutters and razor blades they had\nsmuggled through airport security checkpoints, the terrorists, working in teams of four or five,\nstarted slashing the throats of flight attendants and passengers in order to lure the pilots out of the\ncockpits. Before long, the terrorists had commandeered the controls of the aircraft, transforming\ntheir vehicles from passenger jets to guided missiles laden with sixty thousand pounds of\nexplosive fuel each. By midmorning, the operation was complete. A field in rural Pennsylvania\nbellowed smoke. An entire facade of the Pentagon in Washington, DC lay in shambles. And the\nTwin Towers of the World Trade Center tumbled from the Manhattan skyline. In all, thousands of\npeople perished on that morning. America, President Bush vowed, would never be the same.1\n\nAlmost immediately, the finger pointing began between federal agencies over who was\nresponsible for not thwarting this attack--the most destructive ever carried out on the United\nStates mainland. Some blamed the Central Intelligence Agency (CIA), calling it the largest\nintelligence failure since Pearl Harbor. Others assailed the Immigration and Naturalization\nService (INS) for letting such dangerous individuals enter the country in the first place. But the\none agency the public most criticized was the Federal Aviation Administration (FAA). How is it\nthat they let nineteen people armed with knives slip right through security checkpoints? The\ngrainy security camera pictures of Mohammed Atta, the terrorist ringleader, clearing security at\nthe airport in Providence, RI, on September 11 now haunt America's consciousness. If only the\nmetal detectors had been more sensitive, if only the security personnel had been more alert, if\nonly Atta had aroused more suspicion, then perhaps this tragedy would never have happened.\n\n1 September 11, 2001 may have been the most widely covered American news story ever. For a more\nthorough treatment of the events of that day, see: http://www.time.com/time/911/\n\n- 4 -\n\nWith the vulnerabilities of the nation's air transportation infrastructure made painfully\nclear, the FAA had a new sense of urgency in plugging the holes in a security system that was\nwidely recognized as being as porous as a sieve. But the challenges in doing so were, and still are,\ndaunting. Over 639 million passengers pass through airports annually in the USA.2 Given this\ntremendous volume in traffic, unparalleled by any other nation, time-consuming security\nscreening of every passenger is unfeasible. Since the number of security personnel available in\nairports is resource constrained, it would simply take too long to search everyone as meticulously\nas airports are able to in some other countries, such as Israel. While Americans love to fly, they\nalso hate to wait.\n\nTo address these vexing security problems, the FAA has been trying in recent years to\nemploy information technology to boost the overall efficiency of security screening. The kernel\nidea behind their approach is to be more intelligent about which passengers are selected for\nrigorous inspections. Intuitively, the FAA argues, if you only have the ability to scrutinize a small\npercentage of passengers, it seems best to spend the bulk of time carefully searching those who\nare likely to be terrorists and not waste much time searching those who have a small chance of\nposing harm. Why frisk Eleanor, the 80-year-old grandmother from Texas when you can stop\nOmar, the 22-year-old student fresh from Libya? If you can develop a profile describing who is\nlikely to be a terrorist, then those are the people upon whom you should concentrate your security\nefforts.\n\nDrawing from these intuitive underpinnings, the crown jewel of the FAA's information\ntechnology efforts is a system called the Computer Assisted Passenger Screening system (CAPS).\nThe FAA contends that since CAPS uses profiles to pinpoint potential terrorists for closer\ninspection, it will not only result in the apprehension of more criminals, but will also make\nsecurity screening more expedient for well-meaning citizens. Though in place since 1999, CAPS\n\n2 \"Airport Activity Statistics of Certificated Air Carriers: Summary Tables,\" U.S. Department of\nTransportation. Washington, DC: 2001.\n\n- 5 -\n\nhas gained much more attention as a promising counter-terrorism tool in the wake of September\n11. The FAA already augmented the system in January, and plans for further expansion are\nunderway.3\n\nIn our paper, we show that although these intuitive foundations might be compelling,\ntheir implementation in CAPS is flawed. That is to say that any CAPS-like airport security system\nthat uses profiles to select passengers for increased scrutiny is bound to be less secure than\nsystems that randomly select passengers for thorough inspection. Using mathematical models and\ncomputer simulation, we show how a terrorist cell can increase their chances of mounting a\nsuccessful attack under the CAPS system as opposed to a security system that uses only random\nsearches. Instinct may suggest that CAPS strengthens security, but it in fact introduces a gaping\nsecurity hole easily exploitable by terrorist cells. It should be noted that CAPS has also received\nimmense criticism from privacy advocates and civil libertarians4, but in this paper we restrict our\ndiscussion to a purely technical perspective and the legal and policy implications of such an\nanalysis.\n\nIn Section 2, we better define how the CAPS system operates. In Section 3, we present\nour algorithm for defeating CAPS. To evaluate the algorithm's efficacy, in Section 4 we present\nthe results of a probabilistic analysis and computer simulation of airport security. In Section 5, we\ndiscuss a few case studies to understand what security techniques have been effective historically.\nIn Section 6, we discuss the legal implications of our finding that CAPS performs worse than\nrandom search. And finally, we conclude in Section 7 with policy recommendations for how to\nimprove air security.\n\n3 O'Harrow, Robert, Jr. \"Intricate Screening Of Fliers In Works Database Raises Privacy Concerns.\"\nWashington Post. February 1, 2002. Page A01.\n4 Nojeim, Gregory. \"Civil Liberties Implications Of Airport Security Measures.\" Statement to the White\nHouse Commission on Aviation Safety and Security. September 5, 1996. Available at:\nhttp://www.epic.org/privacy/faa/aclu_testimony.html\n\n- 6 -\n\n2 Defining CAPS\n2.1 Government Guidelines\n\nDuring the second term of his administration, President Clinton convened a panel to\ndevelop a set of recommendations to improve air transportation security. The resulting White\nHouse Commission on Aviation Safety and Security (chaired by Vice-President Gore) published\nits final report5 in February of 1997, giving the federal seal of approval to automated passenger\nprofiling. \"Based on information that is already in computer databases,\" the Gore Commission\nwrote, \"passengers could be separated into a very large majority who present little or no risk, and\na small minority who merit additional attention.\" This statement also serves to articulate the\nfederally supported two-stage architecture behind passenger profiling systems. First, the system\nshould develop a secret profile describing characteristics of high-risk individuals (profile\ndevelopment). And then security manpower should be focused on those individuals who, based\non available data, match the profile (profile evaluation). Such passengers are referred to as\nselectees.\n\nThe Gore Commission was cognizant of the constitutional fragility of such a system, so\nthey invited testimony from civil liberty groups who were concerned that the derived profile\nmight violate Fourteenth Amendment equal protection. To pacify these fears, the Commission\ndictated that \"No profile should contain or be based on material of a constitutionally suspect\nnature.\" The Commission also insisted that the FAA should periodically consult the Department\nof Justice \"to ensure that selection is not impermissibly based on national origin, racial, ethnic,\nreligious or gender characteristics.\" Finally, to ensure that no one group is singled out, the\nCommission recommended that passenger profiling systems also choose random people who do\nnot fit the profile as selectees.6\n\n5 \"Final Report to President Clinton.\" White House Commission on Aviation Safety and Security. February\n17, 1997. Available at: http://www.airportnet.org/depts/regulatory/gorecom.htm\n6 Ibid.\n\n- 7 -\n\n2.2 CAPS Architecture\n\nUsing the guidelines set forth by the Gore Commission, the FAA and Northwest Airlines\njointly completed development of the first version of CAPS in 1998. The federal government\nclosely guards the details of how the system operates, citing a compelling national security\ninterest-- if the specifications were to be released, it would be trivial for potential criminals to\ndefeat the system. But drawing from an assortment of news articles7, interviews with airport\npersonnel, the Gore Commission report8, leaks captured on the congressional record,9 and\nprototypes written by software companies bidding to develop future versions10, a cohesive if not\ncomprehensive understanding of CAPS can be painted.\n\nCAPS operates according to the same two-stage model described in the Gore\nCommission report: profile development followed by profile evaluation. First, based on a\nhistorical record of data pertaining to known terrorist activities, the software attempts to detect\nsubtle patterns in the data that correlate with prior terrorist plots and anti-correlate with the\nactivities of non-criminals. For instance, the software might find that those people who bought\none-way tickets in cash and traveled abroad frequently had an elevated chance of being terrorists.\nCAPS then assembles these patterns into a secret profile suitable for inspection by the\nDepartment of Justice. Since the DOJ certification is only held periodically, the derived master\nprofile is presumably static for long periods of time.\n\nOn a more technical level, CAPS likely accomplishes pattern detection through the use of\na three-layer neural network. The first layer of the network contains hundreds if not thousands of\nnodes, the third layer contains a single output node, and the second layer contains an intermediate\nnumber of nodes. Each field of data available for profile development is fed into a separate node\n\n7 O'Harrow, Op. cit.\n8 \"Final Report to President Clinton.\" White House Commission on Aviation Safety and Security. February\n17, 1997. Available at: http://www.airportnet.org/depts/regulatory/gorecom.htm\n9 \"Hearing on Aviation Security with a Focus on Passenger Profiling.\" United States Congress\nSubcommittee on Aviation. February 27, 2002. Available at:\nhttp://www.house.gov/transportation/aviation/02-27-02/02-27-02memo.html\n10 For more information, see HNC Software's website: http://www.hnc.com\n\n- 8 -\n\nof the first layer. Using a standard training procedure, such as back propagation, the weights of\neach connection are set such that when data from a terrorist is fed into the network, the output\nlayer returns a value close to one. But when data from a non-criminal is fed into the network, the\noutput layer returns a value close to zero. If training of the network is successful, the matrix of\nconnection weights serves as the profile.\n\nThe CAPS system installed in 1999 and currently in use is only capable of doing profile\ndevelopment over data pertaining to the history of ticket purchases. Future versions of CAPS,\nhowever, will be able to incorporate a richer set of data, including driving history, credit card\npurchases, telephone call logs, and criminal records, among other information. Though allowing\nCAPS to access some of this data would require changes in privacy legislation, Congress,\nfollowing on the heels of the PATRIOT act, is poised to facilitate.11\n\nOnce CAPS crafts a profile, it is incorporated into software that is accessible from every\nairline check-in counter nationwide. When a passenger checks in, the ticket agent enters the\npassenger's name into the CAPS console. Data mining software linked to government databases\nthen scours for information about the passenger, retrieving data relevant to the profile. The\nsoftware compares the similarity of the acquired data to the profile and computes a \"threat index\"\nassessing how much potential risk that passenger may pose.12 In the technical scenario outlined\nabove, the computed threat index would simply be the product of the profile matrix with the\npassenger's mined data vector.\n\nIf the passenger has one of the top 3-8% of threat indices relative to the other people on\nhis flight, then CAPS flags him for \"special treatment.\" To protect the integrity of the CAPS\nsystem, the precise percentage of people flagged by CAPS is unpublished, but it is known to be in\nthat range.13 To comply with the Gore Commission guidelines, a small percentage of people on\n\n11 O'Harrow, Op. cit.\n12 Ibid.\n13 \"Computer-Assisted Passenger Screening and Positive Passenger-Bag Matching.\" Assessment of\nTechnologies to Improve Airport Security: First Report. The National Academy Press: 2000.\n\n- 9 -\n\neach flight are randomly flagged as well. In all, the total number of people flagged by CAPS is\nlimited by the security personnel resources available at each particular airport.\n2.3 Special Treatment\n\nWhat exactly do these \"special treatment\" flags entail? Before September 11, CAPS flags\nwere only tied to the passenger's checked baggage, which were scanned using costly explosives-\ndetection equipment. This represented the conventional wisdom of the time that a terrorist would\ntry to smuggle explosives only in his checked luggage14. But now, the FAA is tying CAPS flags\nto individuals. Someone flagged by CAPS may have her carryon bags specially inspected, she\nmay be subject to questioning, she may be asked to stand in a separate line, she may be asked to\ncomply with a search of her body, or a guard may even escort her directly to the gate.15\n\nIn an article in Slate magazine, Microsoft Chief Architect Charles Simonyi related his\nexperience of being flagged by CAPS.16 During a routine business trip, security personnel insisted\non completely unpacking and repacking all of his carryon bags. This happened time after time.\n\"Then it hit me,\" Simonyi writes. \"It was not that security was especially tight: It was only me\nthey wanted. The label my friendly hometown airline had affixed to my bags had unexpectedly\nmade me a marked man, someone selected for some unknown special treatment.\" The bottom line\nis that if CAPS flag you, you'll be treated differently, and you'll know it.\n\n3 Defeating CAPS\n\nThis transparency is the Achilles' Heel of CAPS; the fact that individuals know their\nCAPS status enables the system to be reverse engineered. You, like Simonyi, know if you're\ncarryons have been manually inspected. You know if you've been questioned. You know if\n\n14 On September 11, the version of CAPS in place failed to flag the luggage of 10 of the 19 hijackers. This\nunderscores how easy it is for a terrorist to evade the CAPS profile.\n15 O'Harrow, Op. cit.\n16 Simonyi, Charles. \"I Fit the Profile.\" Slate Magazine. May 25, 1997. See: http://slate.msn.com/?id=2058\n\n- 10 -\n\nyou're asked to stand in a special line. You know if you've been frisked. All of this open scrutiny\nmakes it possible to learn an anti-profile to defeat CAPS, even if the profile itself is always kept\nsecret. We call this the \"Carnival Booth Effect\" since, like a carnie, it entices terrorists to \"Step\nRight Up! See if you're a winner!\" In this case, the terrorist can step right up and see if he's been\nflagged.\n3.1 Carnival Booth Algorithm\n\nWe will now present an algorithm that a terrorist cell can employ to increase their\nprobability of mounting a successful attack under the CAPS system as opposed to an airport\nsecurity system that employs only random searches. The key idea is that a terrorist cell can probe\nthe security system to ascertain which of their members have low CAPS scores. Then they can\nsend these members on destructive missions. Since security manpower is disproportionately spent\non people with high CAPS scores, and the operative has a low score, he will most likely face\nreduced scrutiny.\n\nThe algorithm, which we call Carnival Booth, then is as follows: (1) Probe the system by\nsending an operative on a flight. The operative has no intent of causing harm. He has no\nexplosives. He has no weapons. He has nothing. He simply takes the flight and notes whether or\nnot CAPS flags him. (2) If he is flagged, then send another operative in the same manner. (3)\nRepeat this process until a member who consistently eludes CAPS flags is found. (4) Now send\nthis operative on a mission with intent to harm, complete with weapons or explosives. Since\nCAPS didn't flag him last time, he likely won't be flagged this time, so he incurs much less risk\nof special scrutiny.\n\nTo better understand how a terrorist cell using this algorithm stands a better chance of\nsuccess under CAPS than under a random system, let's consider the numerical example illustrated\nin Figure 1. Suppose an airport only has the personnel resources to give 8% of people special\nscrutiny; the other 92% undergo standard screening through a metal detector. Under a system\n\n- 11 -\n\nwhere people are selected at random, this airport can afford to flag 8% randomly. This means that\nevery time a terrorist attempts to go through security, he stands an 8% chance of increased\nscrutiny. This will be true no matter what tactic or algorithm the terrorist uses.\n\n(Random)\n8%\n(Metal Detectors)\n92%\nRandom System\n\n(Metal Detectors)\n92%\n(CAPS)\n2%\n6%\nCAPS System\n(Random)\n\nTerrorist Activity\nIncreased Scrutiny\n\nNo Terrorist Activity\nStandard Scrutiny\n\nFigure 1: Regions of Terrorist Activity under CAPS and a Random System\n\nNow compare this to the same airport using a CAPS system, which may for example flag the 6%\nof passengers with the highest threat indices and 2% randomly in order to equal their personnel-\nconstrained 8% limit. By employing the algorithm described above, the terrorist cell knows that\nsince their operative has previously probed the system without a flag, CAPS likely will not flag\nhim again. In essence, the terrorist cell is able to relegate its harmful activities outside of the 6%\nCAPS flag zone. Now, their operative only has a 2% chance of calling up a thorough inspection.\nCompare this to the 8% chance the terrorist would incur under the random system. It's clear that\nterrorist cells would therefore prefer airports fortified by CAPS.\n3.2 Cells vs. Individuals\n\nUpon reading this analysis, it's natural to feel uneasy. How is it that such an intuitive\nsystem can actually weaken security? For clarity, it is useful to draw a distinction between\nindividual terrorists and the coordinated activities of an entire terrorist cell. It is entirely probable\n\n- 12 -\n\nthat even a rudimentary CAPS profile can flag many individual terrorists, shrinking the viable\npool of recruits that a terrorist cell can send on a mission. But so long as the cell as a unit can\nidentify those members who slip through CAPS, even if they are few in number, it has an\nenhanced probability of mounting a successful attack. It only takes one person to do harm.\nCarnival Booth makes the process of identifying such a person simple.\n\nEvolutionary biology validates this perspective. The most famous example is the\npeppered moths of London. In the 1950s, Dr. H.B.D. Kettlewell, a physician, noticed that the\npeppered moth population living near industrialized areas of London started to change in color\nfrom light gray to dark gray. Through a series of experiments, Kettlewell showed that dark\ncolored moths were more apt to survive near industrialized areas because, by matching the color\nof the smokestack soot that coated the ground, they could evade predators.17 Individual light gray\nmoths were eliminated from the gene pool, but since the population had a few dark gray moths\n(maybe only one), the species survived and proliferated. Even in nature, a non-conscious species\ncan subvert static environmental conditions that expose them to danger. Conscious terrorists, one\nwould expect, can likewise circumvent a profile.\n3.3 Algorithm Assumptions\n\nTerrorists, of course, are not moths. In fact, the evolutionary biology example points to\nseveral assumptions we must make in order to claim the effectiveness of our CAPS\ncircumvention algorithm. Unlike a natural species, terrorists do not have, for example, infinite\nvariation and boundless evolutionary time. This leads to three key questions: Do terrorist cells\nhave a diverse enough membership to successfully use this algorithm? Do they have the money,\npatience, and planning skill to execute it? And above all, are they smart enough to know to use it?\nUsing findings from our nation's \"War on Terror\" as a case study, we claim that it is safe to\nassume that the answers to all of these questions are affirmative.\n\n17 Ricklefs, Robert. Ecology. W H Freeman & Co. 1990.\n\n- 13 -\n\nThe terrorists revealed in recent months are strikingly diverse. Most famously, John\nWalker Lindh-- the \"American Taliban\"18-- is a nineteen-year-old Caucasian boy from Marin\nCounty, the yuppie capital of California. He was fighting on the front lines for the Taliban in\nAfghanistan against American soldiers. If he had never been discovered, would it have been\ndifficult for Al Qaeda to send him back to the United States on a terrorist mission? Then there is\n\"shoe bomber\" Richard Reid, accused of trying to detonate explosives in his sneakers during a\ntransatlantic flight.19 He is a British citizen with an English mother and Jamaican father. And just\nlast week the FBI apprehended Lucas Helder, a 21-year-old art major at the University of\nWisconsin-Stout.20 Helder allegedly planted 18 pipe bombs in mailboxes in five different states to\nform a \"smiley face\" pattern. And who can forget Ted Kaczynski and Timothy McVeigh?\nTerrorists clearly have no shortage of diversity.\n\nAs the hijackers of September 11 showed, they also have no shortage of money, patience,\nand planning acumen. Mohammed Atta planned the attack years in advance, studying diagrams of\nthe World Trade Center, going to flight school, and analyzing airplane specifications on the\nInternet. The money trail funding Atta's operation weaves through anonymous bank accounts in\nmultiple countries. It is so intricate that the FBI still does not completely understand it. Terrorist\ncells like Al Qaeda have demonstrated that they have the resources required in terms of money,\npatience, and planning to use the algorithm.\n\nWhat may be more alarming is that evidence from the September 11 investigation shows\nthat Atta already knew the kernel idea behind this algorithm. Newsweek reported21 that in the\nweeks before September 11, Atta and his conspirators practiced their attack by boarding the exact\nsame target flights they intended to later hijack (same planes, same times, same origins and\n\n18 Tyrangiel, Josh. \"The Taliban Next Door.\" Time. December 9, 2001.\n19 Canedy, Dana, et al. \"Passenger With Shoe Bombs First Raised Only Eyebrows.\" New York Times.\nDecember 27, 2001.\n20 Eggen, Dan. \"Pipe Bomb Suspect Arrested.\" Washington Post. May 8, 2002. Page A01.\n21 Reported in several issues during October 2001. See: http://www.msnbc.com/news/NW-\nattackonamerica_Front.asp?cp1=1\n\n- 14 -\n\ndestinations). They wanted to ensure that they didn't raise any suspicions or red flags. This is a\nclear demonstration of Atta's cleverness. Like Atta, terrorists are smart. They already know this\nalgorithm. And they are already using it.\n\n4 Evaluating Carnival Booth\n\nA combination of a probabilistic analysis and results from a computer simulation\ndemonstrate in more concrete terms if it is possible for a terrorist cell to use Carnival Booth to\ndefeat the CAPS system. In particular, we wanted to find out under what conditions CAPS\noutperforms or underperforms random search, and we wanted to quantitatively determine how\nmuch a terrorist cell could benefit from using the algorithm. To accomplish this, we compared\nthree systems: (1) the CAPS system, (2) a system where passengers are randomly selected, and\n(3) a random system with more advanced administrative searching. The results are clear. The less\na system relies on profiling and the more advanced its administrative searching, the more\nterrorists it will catch.\n\nThe analysis makes two reasonable assumptions. First, a terrorist must bring a weapon or\nbomb onboard the airplane to cause damage. Modifications to cockpit doors, sky marshals, and\nheightened passenger awareness after September 11th have forced potential terrorists to use more\nthan cardboard cutters to gain control of a plane. Second, a future terrorist that is flying with no\nweapons and no criminal intent will not be apprehended by law enforcement. Even if this person\nhas the highest threat index possible, there would be no reason to apprehend him or her (barring\nan outstanding warrant or alleged connection to a previous terrorist act).\n4.1 Probabilistic Analysis\n\nWe model all three flavors of airport security with a two-stage architecture. The first\nstage is administrative screening, which includes the usage of metal detectors and basic\nquestioning about luggage contents. All passengers are subjected to this level of screening. The\n\n- 15 -\n\nsecond stage is increased screening for those who are either flagged by CAPS or randomly\nselected.\n\nUsing probability theory, we developed a generalized function for these two-stage\nsystems that determines the probability that a terrorist will be caught. First, the total probability of\nthe terrorist being arrested is the sum of whether the terrorist is arrested during a 2nd level search\nprompted randomly, a 2nd level search prompted by a CAPS flag, or a 1st level administrative\nsearch:\n\nPr(Terrorist Arrested) =\n\nPr(Terrorist Arrested During Randomly-flagged 2nd Level Search)\n\n+ Pr(Terrorist Arrested During CAPS-flagged 2nd Level Search)\n\n+ Pr(Terrorist Arrested During Administrative 1st Level Search)\n\nIntroducing some notation, let A be whether the terrorist is arrested, R be whether the terrorist is\nrandomly chosen for 2nd level screening, and C be whether the terrorist is selected by CAPS for\n2nd level screening. Since the probability that the terrorist will undergo administrative search is\nequal to the probability that the he is not flagged for 2nd level search either by a CAPS flag or a\nrandom flag, the full equation becomes:\n\nPr(A) =\n\nPr(A | R) * Pr(R)\n\n+ Pr(A | C) * Pr(C)\n\n+ Pr(A | ¬(R U C)) * Pr(¬(R U C))\n\nTo analyze the dynamics of this equation, there are several constraints we can impose on\nthese probabilities. First observe that the probability that 2nd level interrogation results in an\n\n- 16 -\n\narrest should be the same whether the terrorist is flagged by the CAPS profile or randomly.\nHence, Pr(A | R) must be the same as Pr(A | C). Also, since the 2nd level searches are more\nthorough than 1st level searches, logic dictates that Pr(A | ¬(R U C)) be lower than either Pr(A |\nR) or Pr(A | C). Finally, in all the simulations, the number of passengers that will be subjected to\nheightened security will be the same.\n\nAlthough information about the CAPS system is limited, the total percentage of people\nflagged by CAPS, either through a profile or randomly, is reported to be between 2-8%.\nAccordingly, we choose Pr(R) to be 2% under CAPS, and 8% under a random system where all\npersonnel resources can be devoted to random inspections. Since second level searches are\npresumably more effective than first level searches, our system arbitrarily sets Pr(A | R) at 75%\nand Pr(A | ¬ (R U C)) at 25% for the first two systems. For the third system employing better\nadministrative searches, Pr(A | ¬(R U C)) is set to 40%. We can begin to compare the systems\nnow that all values except Pr(C) are now known:\n\n(CAPS system)\nPr(A) = 0.75 * 0.02 +\n\n0.75 * Pr(C) +\n\n0.25 * (1 - 0.02 - Pr(C))\n\n(Random system)\n\nPr(A) = 0.75 * 0.08 +\n\n0.75 * 0 +\n\n0.25 * 0.92\n\n= 29%\n\n(Random w/ admin+) Pr(A) = 0.75 * 0.08 +\n\n0.75 * 0 +\n\n0.40 * 0.92\n\n= 42.8%\n\n- 17 -\n\nThe critical value Pr(C) depends on the effectiveness of the CAPS profile and whether\nterrorist cells are strategically using agents with low threat indices. If Pr(C) is greater than 6%,\nthen the CAPS system will be more successful than a random system. If the probability a terrorist\nwill be flagged by CAPS is less than 6%, then law enforcement should randomly select\npassengers for increased scrutiny. (The third equation demonstrates how effective even modest\nimprovements in administrative searches can be. We will return to this topic later in our\ndiscussion.)\n\nClearly, we claim in this paper that by using our algorithm, a terrorist cell can push Pr(C)\nunder 6%. This probability heavily depends on how many probes an agent completes before that\nterrorist cell sends the agent on a mission. Imagine that a terrorist cell sends a new recruit to\nprobe a domestic flight. On average there could be 74 other passengers on that flight with him.22\nWatching the other passengers closely at security checkpoints, the agent notices that he has not\nbeen flagged. Although the cell can correctly conclude that 6% of his peers on the flight\n(approximately 6 passengers) had threat indices higher than his, this is no guarantee that on the\nnext flight, the agent will still be in the bottom 94% of threat indices. Thus, the terrorist cell\nremains unsure whether they can \"safely\" send the agent on a mission. However, the more probes\nthat the agent returns from without attracting a CAPS flag, the more confidence the cell has in\nthis agent's ability to get through the system undetected.\n\nWith an infinite number of probes, the CAPS system will perform worse than a random\nsystem. If an agent has passed through security unflagged an infinite number of times, then the\nprobability the agent will be flagged on his mission, Pr(C), becomes 0. Thus the overall\nprobability of such an operative being apprehended is:\n\n(CAPS System) limit Pr(A) = 0.75 * 0.02 + 0.75 * 0 + 0.25 * 0.98 = 26%\nProbes -> Inf\n\n22 \"Airport Activity Statistics of Certificated Air Carriers: Summary Tables,\" U.S. Department of\nTransportation. Washington, DC: 2001.\n\n- 18 -\n\nThis is four percentage points inferior to the random system. Obviously, a terrorist cell cannot\nlaunch an infinite number of probes. The chief question then becomes how many probes must a\nterrorist cell launch before they can be sure that their operative stands a smaller chance of\napprehension than under a random system?\n4.2 Computer Simulation\n\nWe developed a computer simulation to shed light on how much more confident the cell\ncan be after each additional probe. Unfortunately, to definitively answer this question one would\nneed the distribution of CAPS scores for both terrorists and the public at large. These\ndistributions are, of course, confidential. Hence we ran our simulation several times using a wide\nvariety of distributions, hoping that the real distributions are bounded by our models.\n\nIn crafting these distributions, we made a few general assumptions. The first is that\nterrorists, on average, have a higher CAPS index than the average airline flier. It would be\nunreasonable for the FBI to advocate a profiling-based system if this assumption were false. The\nsecond assumption is that the terrorist and general public distributions are Gaussian. This\nassumption stems from the fact that CAPS scores are generated from thousands of boolean tests.\nA combination of many random factors will usually create the bell-shaped Gaussian distribution\ncurve. While the actual distributions probably exhibit non-zero skewness and kurtosis, we do not\nclaim to know in which directions these statistical moments would manifest themselves; we\ntherefore assume they are zero.\n\nAs for the more significant moments of mean and standard deviation, we varied these\nvalues in an attempt to cover many of the potential cases. Some distributions represented\nmoderately effective profiles with a mean CAPS score of 50 out of 100 for terrorists and 30/100\nfor non-terrorists and standard deviations of 20. Other distributions modeled highly tuned profiles\n\n- 19 -\n\nwith a mean CAPS score of 70/100 for terrorists and 20/100 for non-terrorists and standard\ndeviations of 20.\n\nFor each distribution, and for each number of probes, 7,000 attacks were simulated. The\ncomputer tracked a simulated terrorist cell as it used the Carnival Booth algorithm to recruit new\nmembers and probe the system with each neophyte. During a probe, the computer randomly\ngenerated 75 other non-terrorist passengers. After finding a member that passed through the\nrequisite number of such probes unflagged, it sent that agent on a mission. On that mission, the\nterrorist could either be flagged by CAPS, randomly selected, or neither, depending on the CAPS\nscore probability distribution being tested. The percentage of terrorists arrested was then\nrecorded.\nComparing the CAPS System to a Random Selection System\nResults when Varying CAPS Distributions\n25%\n27%\n29%\n31%\n33%\nNumber of Unflagged Probes Before Terrorist Attack\nPercent Terrorists\nCaught\nDifferent CAPS\nSystems\nRandom System\nBaseline\nLimit as Probes\nGo to Infinity\n\nFigure 2: Number of Probes Required to Defeat CAPS for Varying Score Distributions\n\nAs shown in Figure 2, changes in the mean and standard deviation values make little\ndifference in the end result. If a terrorist cell requires four unflagged probes prior to launching an\nattack, the CAPS model becomes worse than random. At six probes, the threat index becomes an\nentirely useless means of identifying terrorists. This immunity to the characteristics of the CAPS\n\n- 20 -\n\ndistribution is a striking result-- it means that even if CAPS utilized highly accurate profiles, a\nterrorist operative need only launch a few successful probes before he can beat the system.23\n\nIf CAPS is not a viable means of strengthening security, the question remains how to\nmake our airports safer. With a random system, the paramount equation is:\n\n(Random System)\nPr(A) = Pr(A | R) * Pr(R) + Pr(A | ¬R) * Pr(¬R)\n\nThe most effective security measure would be one that increases the percentage of people\nreceiving second level searches. But given that passengers would object to the prohibitive waiting\ntimes, the government has decided to inconvenience only 8 percent of airline passengers with\nincreased screening. Thus, we consider Pr(R) fixed at 8% and Pr(¬R) fixed at 92%. The only two\nvariables left to manipulate are the probability of catching a terrorist during administrative\nscreening and the probability of catching a terrorist during heightened scrutiny. To maximize the\nequation, the term multiplying Pr(¬R) is the most advantageous to increase. This term\ncorresponds to the administrative search accuracy. Since administrative searches cover everyone,\ninvestment in technologies used in those searches will return more bang for the buck.\n5 Case Studies\n\nTwo detailed case studies buttress the proposal that investments should be diverted from\nprofiling to administrative searches. First, we examine the failed attempt to bomb Los Angeles\nInternational Airport just before the millennium. Then, the security system of El Al is analyzed\nand used as a benchmark for great security. The net result of these case studies points both to\nflaws in the CAPS profiling system and the strengths of administrative searching.\n\n23 In the parlance of game theory, a terrorist cell using this algorithm would be said to have a dominant\nstrategy. The Nash equilibrium would fall in favor of the terrorist cell.\n\n- 21 -\n\n5.1 Ressam's 1999 Terrorist Attempt\n\nIn August 1999, Ahmed Ressam began to plot a terrorist attack against the United States\nfrom his home in Montreal. Ressam decided to target Los Angeles International Airport since he\nhad sensed lax security when he had flown through the airport in February 1999. By September,\nRessam had found an accomplice who funded the project, which enabled him to begin to procure\nchemicals and timing devices. His plan was to plant an explosive in a suitcase, put the suitcase in\nan inconspicuous luggage cart, set the timing device, and leave the scene. With everything\nprepared, Ressam flew to Vancouver and then left for the United States in a rental car on\nDecember 14th. 24\n\nAt approximately 6pm, Ressam boarded the ferryboat Coho in Victoria, British\nColumbia, which would take him to Port Angeles, Washington. Before being allowed to board\nthe Coho, Ressam, like all other passengers, was required to pass through a U.S. customs pre-\nscreening checkpoint. Ressam presented the customs official with a fake ID; he used the alias\nBenni Antoine Noris.25 Even though Ressam was wanted by French and Canadian law\nenforcement, a background check on the name Noris cleared since it was not one of Ressam's\nknown aliases.26 Ressam even presented (in addition to a photo ID) a Costco card in the name of\nNoris.27 Thus, Customs let Ressam board the ferry.\n\nUpon arriving in Port Angeles, Ressam was the last person to drive his car off of the\nferry.28 A Custom's agent, Diana Dean, approached Ressam's car and began questioning him.\nDean recalled, \"I noticed during routine questioning that Ressam was acting in a nervous and\nstrange manner while answering routine questions. I decided to perform a more thorough\n\n24 \"Ahmad Ressam's Millennium Plot,\" Public Broadcasting Service. Available at:\nhttp://judiciary.senate.gov/oldsite/21020dd.htm\n25 United States of America V. Ahmed Ressam, Magistrate's Docket No. Case No. 99-547m, Complaint For\nViolation (1999)\n26 \"Ahmad Ressam's Millennium Plot,\" Public Broadcasting Service. Available at:\nhttp://judiciary.senate.gov/oldsite/21020dd.htm\n27 United States of America V. Ahmed Ressam, Magistrate's Docket No. Case No. 99-547m, Complaint For\nViolation (1999)\n28 Ibid.\n\n- 22 -\n\nsecondary examination.\"29 The \"secondary examination\" required that Ressam exit his vehicle\nand that the car be fully searched. Ressam initially refused to cooperate with the search and only\nreluctantly exited his car. When he saw the officials had found his explosives, which were hidden\nin the trunk, Ressam ran.30 Customs officials chased Ressam for several blocks before\napprehending him.\n\nRessam's use of an alias demonstrates a weakness in profiling. Since the standard\nidentification in the United States is a state-issued driver's license, there are fifty different sets of\nrules. Terrorists can attack the weakest link. For instance, in preparation for the September 11th\nattacks, seven of the nineteen hijackers abused Virginia's relaxed standards to obtain false\nlicenses. Even if America adopts a national ID, potential terrorists can acquire falsified papers in\nother countries, as Ressam did.31\n\nSaving the day in this case were the security standards of the US Customs Department\nand the professionalism of Diana Dean. No profile could have prevented Ressam from entering\nthe country--all his papers appeared to be in order. The experience of Dean to perceive Ressam's\nuneasiness and the searching procedures that found the explosives concealed in the spare tire well\nof the truck prevented disaster from striking one of America's largest airports.\n5.2 The El Al Standard\n\nEl Al is Israel's airline, and while it receives daily threats, they have not experienced a\nterrorist incident in over thirty years. Its success is mainly due to its tight on-site security. Each\npassenger each time he or she flies is psychologically evaluated. Carryon bags are checked\nmultiple times. In essence, El Al's security system works from the assumption that every\npassenger is a threat, and treats him or her accordingly.\n\n29 Dean, Diana. \"Statement Before Senate Judiciary Committee.\" February 10, 2000. Available at:\nhttp://judiciary.senate.gov/oldsite/21020dd.htm\n30 United States of America V. Mokhtar Haouari, S4 00 Cr. 15. Testimony Available at:\nhttp://www.pbs.org/wgbh/pages/frontline/shows/trail/inside/testimony.html\n31 Ressam had a Canadian passport and Quebec driver's license, both under the name Noris.\n\n- 23 -\n\nEvery car that enters Ben Gurion International Airport in Tel Aviv is examined. Plain-\nclothed guards help secure each airport building.32 As El Al's president, David Hermesh, stated,\n\"If you're a passenger on El Al, most likely you will be observed from the minute that you left\nyour car or you have been dropped off.\"33\n\nUpon entering the airport, a passenger is asked a series of specific questions including\n\"Who paid for your ticket?\" \"What is the purpose of your travels?\" and \"When did you book the\nflight?\"34 The questions are specifically designed to evoke an observable reaction. As passengers\nanswer the questions, the officer carefully scrutinizes tone of voice, body language, and quickness\nof response. If the answers are unsatisfactory, a different officer will ask the ticket holder a\ndifferent set of questions. Security personnel also might separate flight companions, making sure\ntheir stories match.35 A psychological evaluation of the passenger is combined with information\nabout the passenger previously obtained by El Al and Interpol.36\n\nOn the baggage side of the equation, El Al is just as strict. All luggage goes through a\ndecompression chamber designed to trick bombs that are set to go off when the barometric\npressure indicates that the plane is in the sky.37 Sophisticated X-ray technology is used to detect\nliquid explosives.38 Security personnel handle and examine every piece of carryon luggage. Every\npiece of luggage is also matched to its owner. And on layover stops, passengers must reclaim\ntheir luggage.39\n\n32 Perman, Stacy. \"The El Al Approach: A look at the Israeli airline's security procedures,\" Business 2.0.\nNovember 2001. Available at: http://www.business2.com/articles/mag/0,1640,17508,FF.html\n33 \"Model for air travel security may be El Al,\" CNN. September 26, 2001. Available at:\nhttp://www.cnn.com/2001/WORLD/meast/09/26/rec.el.al.security/\n34 Ibid.\n35 Perman, Op. cit.\n36 \"Israeli-style security might have averted hijackings.\" USA TODAY. September 13, 2001. Avaiable at:\nhttp://www.usatoday.com/news/world/2001/09/12/israelisecurity.htm\n37 Ibid.\n38 Perman, Op. cit.\n39 Ibid.\n\n- 24 -\n\nWhile El Al does keep a database of individuals' nationalities, genders, criminal records\nand flight histories, this tracking should not be confused with the a CAPS-like profile.40 Unlike\nCAPS, El Al's system only makes a determination of the risk of a passenger after a security agent\nhas questioned him or her.41 CAPS, on the other hand, is a prior system focused on predicting\nwho will become a terrorist. El Al, through its system of psychological analysis and advanced\nbaggage screening, has found success in determining who is a terrorist.\n\n6 Legal Implications\n\nOur analytic result that CAPS-based airport searches are less effective than random\nsearches has important legal implications. While metal detectors and security checkpoints at\nairports may seem routine to us today, it was not always so. It was only after an extensive history\nof litigation that such searches were deemed permissible42.\n\nInitially, in light of the Fourth Amendment of the Constitution, it may not even be clear\nwhy any airport searches are authorized. The Fourth Amendment protects \"the right of people to\nbe secure in their persons, papers, and effects against unreasonable searches and seizures.\" The\nkeyword is \"unreasonable.\" Courts have generally recognized searches as being reasonable if they\nproperly balance the degree of intrusiveness, the magnitude and frequency of the threat, and the\nefficacy of alternatives to the search.43 Through all of the litigation, courts have established two\nmajor exceptions to the Fourth Amendment in relation to airport security: the administrative\nsearch exception and the stop-and-frisk exception. Any new security technique implemented at\nairports must conform to one of these two principles.\n\n40 Ibid.\n41 \"Model for air travel security may be El Al,\" CNN. September 26, 2001. Available at:\nhttp://www.cnn.com/2001/WORLD/meast/09/26/rec.el.al.security/\n42 Most often the court cases were brought on by drug smugglers seeking to challenge the validity of airport\nsearches that discovered their contraband.\n43\"Legal Issues.\" Assessment of Technologies to Improve Airport Security: First Report. The National\nAcademy Press: 2000.\n\n- 25 -\n\n6.1 Administrative Search Exception\n\nFor a search to qualify for the administrative search exception, it must serve a societal\npurpose, be minimally intrusive, and all persons must be searched equally no matter what level of\nsuspicion they may arouse.44 An assortment of court cases establishes these criteria, but United\nStates v. Martinez-Fuerte45 (1976) provides the most direct example. In Martinez-Fuerte, the\nSupreme Court upheld the practice of border control agents stopping vehicles at checkpoints.\nFirst, the Court recognized that governmental interests may in some situations trump Fourth\nAmendment protections. The Court wrote, \"Government or public interest in making such stops\noutweighs the constitutionally protected interest of the private citizen.\" Furthermore, the Court's\nopinion relied on the fact that the search was brief in duration, usually consisting of only a couple\nof questions and visual inspection. Since it did not greatly impede the flow of traffic or consume\ntoo much of the traveler's time, the Court ruled that the search was minimal in its intrusiveness\ngiven the government's compelling interest in border control. Finally, the Court held \"that the\nstops and questioning at issue may be made in the absence of any individualized suspicion.\" Most\nimportantly, what made the border control stops permissible was that everyone, regardless of\nsuspicion, was democratically screened.46\n\nMetal detectors at airports are therefore justified under the administrative search\nexception. By deterring people from bringing weapons onboard aircraft, they serve a societal\npurpose. They are also minimally intrusive. And security personnel require every passenger to go\nthrough them. CAPS-based screening, on the other hand, does not fit all of the administrative\nsearch exception criteria. In particular, the use of a profile to select particular individuals for\nscrutiny violates the requirement that the search be equally applied to all individuals regardless of\nsuspicion.\n\n44 Ibid.\n45 United States v. Martinez-Fuerte, 428 U.S. 543 (1976)\n46 Ibid\n\n- 26 -\n\n6.2 Stop-and-Frisk Exception\n\nThe second type of exception under which an airport security technique may qualify is\nthe stop-and-frisk exception. Under this type of exception, if security personnel have a minimal\nlevel of justification that a person may pose danger, they may conduct, without a warrant, a\nlimited search of that person for the presence of weapons. Like the administrative search\nexception, the stop-and-frisk exception also has a complex history of precedent. Terry v. Ohio47\n(1968) is the case that perhaps best defines this standard. In this case, a Cleveland police officer\npatrolling his downtown beat observed two individuals stare into a storefront window a total of\n24 times. Suspecting that they might be preparing to rob the store, the officer confronted the two\nmen and frisked them for weapons and found each of them carrying a revolver. The Supreme\nCourt was asked to decide whether the officer should have been permitted to frisk the two men\nsince he did not have a warrant. The Court decided that although the officer had not established\nprobable cause, his objective observations of the men's suspicious behavior provided enough\njustification.48\n\nSubsequent court cases have further clarified what exactly constitutes a minimal level of\nobjective justification. In United States v. Cortez49 (1981), the Supreme Court decided that the\n\"totality of circumstances\" may be considered in determining if suspicion exists. Security\npersonnel need more than a hunch to conduct a stop-and-frisk search, but they need not establish\nprobable cause. More precisely, given all of the circumstances, the suspicion must be based upon\nan enhanced \"likelihood\" that the person poses harm.50\n\nOn the surface, CAPS-based security screening appears to qualify for the stop-and-frisk\nexception. By targeting people fitting a suspicious profile, the FAA would argue that CAPS\nestablishes sufficient objective justification. However, based on our analysis of CAPS, we reach\n\n47 Terry v. Ohio, 392 U.S. 1 (1968)\n48 Ibid\n49 United States v. Cortez, 449 U.S. 411 (1981)\n50 Ibid.\n\n- 27 -\n\nthe opposite conclusion. We showed that under the CAPS system a terrorist can reduce his chance\nof arrest to a level lower than a system that uses random search. This means that when security\npersonnel conduct their second level search of passengers flagged by CAPS, they actually have a\nreduced probability of apprehending a terrorist carrying weapons or explosives. Since random\nsearches can catch more terrorists, airport security cannot therefore legitimately establish that\nthose passengers flagged by CAPS have an enhanced likelihood of harm. Consequently, CAPS\nfails to meet the standards of the stop-and-frisk exception.\n\nWould it be possible to convince a judge that CAPS as currently implemented is not\npermissible for use in airports since it does not qualify for either the administrative search or the\nstop-and-frisk Fourth Amendment exceptions? Our analytic results fight an uphill battle against\nintuition. Although it is not certain that a judge would strike down CAPS as being\nunconstitutional, we hope that our analysis will encourage the judge to ask the FAA to be more\nconvincing about why CAPS is constitutional.\n\n7 Policy Recommendations\n\nAs the evidence has shown, the most efficient approach to reducing terrorism is to catch a\nterrorist in the midst of a mission. Attempting to determine who might become a terrorist in the\nfuture or who acts like a terrorist is error-prone and easy to defeat. As mathematically\ndemonstrated in Section 4.1, the focus of the FAA's efforts to tighten airport security should be\naugmenting administrative searches that affect everyone that boards a flight.\n\nThe questions that airline employees or security personnel ask passengers must evoke\nmore of a response. Currently, the standard questions are \"Has your luggage been in your\npossession at all times?\" and \"Has anyone given you anything or asked you to carry on or check\nany items for them?\" For the experienced traveler, these questions induce the reflex answers of\n\"yes\" and \"no.\" By asking questions that require a slightly longer response, security personnel\n\n- 28 -\n\nwould be able to gather information from body language and tone of voice. This strategy also\nrequires the monetary investment to train the questioners so they know what signs to look for.\n\nTechniques for screening checked and carryon luggage have the advantage that they are\nhard to probe. It is difficult to know whether an explosive will evade security unless one brings an\nexplosive through airport security. If a terrorist is unsuccessful during a probe of such a system,\nthey will be arrested for the weapons they are carrying. Thus, a terrorist cell cannot probe\nadministrative searches of bags and persons. Increasing the effectiveness of object searching,\nperhaps through new X-ray technology, should be a top priority.\n\nIf the US government is determined to keep the CAPS system, then it is imperative that\nin the future terrorists are prevented from defeating the system. Any new versions of CAPS must\nreduce the Carnival Booth effect. In essence, it must be non-obvious if a passenger has been\nflagged.\n\nFor checked luggage this veil is easy to create since the passenger is unaware of what\noccurs below the concourse. Bags that belong to individuals not considered flight risks could be\nscanned with normal \"medium x-ray\" technology. On the other hand, the luggage of flagged\npassengers could be scanned with a slower, more detailed, and more costly \"computer\ntomography\" scanner.51\n\nDisguising the two-level process when screening carryon bags and the passengers\nthemselves is much more difficult. One possible solution could be to merge the new X-ray\ntechnology for screening individuals (such as America Science and Engineering, Inc.'s \"Body\nSearch\"52) and the standard metal detectors into one device. This device could be a dual metal\ndetector and X-ray scanner. Similar to the checked baggage system, for each ticket holder a\nsecurity officer would discreetly turn on or off the X-ray scanner. Thus, only \"flight risks\" would\nbe intrusively screened with the more costly X-ray scanner.\n\n51 Tyson, Jeff. \"How Airport Security Works: Check Your Bags: CT Scanners.\" Marshall Brain's How\nStuff Works. Available at: http://www.howstuffworks.com/airport-security4.htm.\n52 More information is available at American Science and Engineering's website: http://www.as-e.com/\n\n- 29 -\n\nBarring such sophisticated technology, CAPS must be dismantled. The carnival booth\neffect prevents CAPS from being an effective deterrent against terrorism. Effective deterrents are\nbetter-trained security personnel, more effective questioning, and more advanced administrative\nscreening. To truly make our airways safer, these policies need to be applied to all passengers, not\njust the few that get flagged for extra scrutiny. In short, the financial resources our nation\ncommits to counter-terrorism should not support a CAPS-like system, which may appeal to our\nintuitions, but is in fact more amenable to compromise.\n\n[Aaron wrote Sections 4, 5, 7 and wrote the computer simulation.\nSamidh served as the editor of this paper and wrote Sections 1, 2, 3, 6.]\n\n- 30 -"
    },
    {
      "category": "Resource",
      "title": "deora_web.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/d0f8c71516f335f8f588528ba4a6eb02_deora_web.pdf",
      "content": "Massachusetts Institute of Technology\nUpdating Copyright Laws to Address\nConcerns of Google's Cached Page Service\n6.806\nEthics and Law on the Electronic Frontier\nProfessor Hal Abelson\nBy\nParul Deora\nDecember 10, 2003\n\nTable of Contents\n1.0 Introduction............................................................................................1\n2.0 Current Copyright Laws.......................................................................1\n2.1 United States Code Title 17............................................................................... 1\n2.2 The Digital Millennium Copyright Act (DMCA)............................................ 1\n2.3 Online Copyright Infringement Liability Limitation Act (OCILLA) .......... 2\n3.0 Google .....................................................................................................2\n3.1 Google's Goals and Technology........................................................................ 2\n3.1.2 High Precision............................................................................................ 2\n3.1.2 Academic Development.............................................................................. 2\n3.1.3 Usability...................................................................................................... 2\n3.1.4 Support Novel Research............................................................................. 3\n3.2 Cached Page Service.......................................................................................... 3\n3.3 Copyright Concerns........................................................................................... 3\n3.4 Google and Copyright Laws ............................................................................. 4\n3.4.1 Fair Use...................................................................................................... 4\n3.4.1.1 Purpose and Character of the Use.................................................. 4\n3.4.1.2 Nature of the Work.......................................................................... 5\n3.4.1.3 Amount and Substantiality of the Portion Used.............................. 5\n3.4.1.4 Effect of the Use on the Work's Potential Market or Value ........... 5\n3.4.2 Safe Harbors .............................................................................................. 5\n3.4.2.1 Transitory Digital Network Communications................................. 5\n3.4.2.2 System Caching............................................................................... 6\n3.4.2.3 Information Residing on Systems or Networks & Information\nLocation Tools ................................................................................ 6\n4.0 Comparable Issues.................................................................................7\n4.1 Kelly v. Arriba Soft Corporation 336 F.3d 811 (9th Cir. 2003)...................... 7\n4.1.2 Arriba Soft's Legal Challenges ................................................................. 7\n4.1.2 Arriba Soft and Google.............................................................................. 7\n4.2 Internet Archive's Wayback Machine............................................................. 8\n4.2.2 Internet Archive's Legal Challenges......................................................... 8\n4.2.2 Internet Archive and Google ..................................................................... 9\n5.0 Suggested Update of Copyright Law....................................................9\n6.0 Conclusion ............................................................................................10\n7.0 Endnotes ............................................................................................... 12\n\n1.0 Introduction\nThe existence of Google, possibly the world's most valued and preferred search engine,\nmay be threatened due to its susceptibility to copyright infringement charges. As an\nincreasing number of individuals are turning to the Internet as not only their primary\nsource of information, but their only source, we have become more concerned of what\ninformation is available to us and how accessible it is online. One of Google's features\ndesigned to make knowledge easily available is its cached page service. By taking\nsnapshots of web pages in their entirety, and then making those cached copies available\nto users, Google is providing Internet researchers and web-surfers the ability to access\nmaterials that are not currently available or may no longer be online. Google, however, is\nfacing copyright concerns for its cached page service. By copying entire web pages, and\nthen making them available on the Internet to its millions of users, Google may be\nviolating copyright laws that specify reproduction and distribution as the exclusive rights\nof copyright owners.\nThe United States Code Title 17 enumerates what rights belong to copyright owners and\nwhat exemptions can be made for fair use purposes. An analysis of Google and the\nfactors that determine whether an application constitutes fair use have led me to believe\nthat the cached page service does not qualify as fair use and is susceptible to copyright\nlaws. After reviewing the safe harbors enumerated in Section 512 of the Digital\nMillennium Copyright Act, I have concluded that it is ambiguous whether Google's\ncached page service would be protected from copyright charges. Other online services\nsuch as the Internet Archive, which faced similar legal challenges, and the case of Kelly v.\nArriba Soft, 77 F. Supp. 2d 1116 (1999), are unlikely to serve as precedents for Google if\nit is brought to court for copyright infringement. Its means of caching websites to\nprovide users with better performance do not match up with the characteristics of the\nInternet Archive or the aforementioned case. Only by updating digital copyright law to\nprotect online services that cache for the purpose of providing better service, while\nallowing opt-out options for publishers, will we be able to maintain the existence of\nGoogle and its cached page feature.\n2.0 Current Copyright Laws\nComprehending the complexity of current copyright laws is the first step to\nunderstanding copyright infringement and assessing the legality of Google's cached page\nservice. The traditional copyrights and fair use exemptions included in Title 17 of the\nUnited States Code, and the Digital Millennium Copyright Act, specifically its provision\ntitled the Online Copyright Infringement Liability Limitation Act, are the main elements\nof copyright law that need to be understood for this issue. Only by realizing the meaning\nof these components will we be able to properly update the laws to unambiguously\nexempt features such as Google's cached page service from copyright infringement.\n\n2.1 United States Code Title 17\nThe copyright laws in Title 17 of the United States Code enumerate what can be\ncopyrighted, the exclusive rights belonging to copyright owners, and the fair use\nlimitations on those exclusive rights. Of importance in this report are the latter two\ncategories: the exclusive rights and the fair use limitations. Section 106 of Chapter 1\nstates the following as what the copyright owner has the exclusive right to do and\nauthorize: (1) reproduce, (2) prepare derivative works based upon the copyrighted\nmaterial, (3) distribute, and in some cases (4) perform or display the copyrighted work. [1]\nWhat further complicates the copyright laws are the exceptions to these rights, the fair\nuse limitations.\nIndividuals may exercise what is normally considered an exclusive right, without the\npermission of the copyright owner, if the work is being used for purposes such as\n\"criticism, comment, news reporting, teaching (including multiple copies for classroom\nuse), scholarship, or research.\" [2] The factors that determine whether the employment of\na copyrighted work is fair use include the following:\n(1) The purpose and character of the use, including whether such use is\nof a commercial nature or is for nonprofit educational purposes;\n(2) The nature of the copyrighted work;\n(3) The amount and substantiality of the portion used in relation to the\ncopyrighted work as a whole; and\n(4) The effect of the use upon the potential market for or value of the\n]\ncopyrighted work. [3\nBack when making a copy required a deliberate effort, it was much easier to identify\ncopyright infringement. The vast developments in technology since Title 17 was initially\nput into effect, however, have obscured what constitutes fair use and have led to\nprogressive updates in copyright law.\n2.2 The Digital Millennium Copyright Act (DMCA)\nThe Digital Millennium Copyright Act of 1998, the DMCA, is an update to copyright law\ndue to the increasing availability of the Internet and \"the ease with which digital works\ncan be copied and distributed worldwide virtually instantaneously.\" [4] Copyright owners\nsought protection against the substantial piracy that could take place if they published\ntheir works on the Internet. The DMCA is the result of content providers advocating\nbetter protection of their \"copyrights in the digital world.\" [5]\nNot fully satisfied, online service providers lobbied for further protection from claims of\ncopyright infringement, leading to additional provisions for the DMCA.\n\n2.3 Online Copyright Infringement Liability Limitation Act (OCILLA)\nOne of the provisions added to the DMCA was Section 512, the Online Copyright\nInfringement Liability Limitation Act (OCILLA). Online service providers received four\nsafe harbors to limit their liability for copyright infringement. Though not a\ncomprehensive list of all defenses available to online service providers, Congress\nprovided the following four safe harbors:\n(a) Transitory digital network communications\n(b) System caching\n(c) Information residing on systems or networks at the direction of users\n]\n(d) Information location tools [6\nWhile the safe harbors do not free service providers from copyright infringement liability,\nthey do limit the monetary penalty one would pay if found guilty of infringement.\nService providers can qualify for the aforementioned limitations by: (1) adopting and\nreasonably implementing \"a policy of terminating in appropriate circumstances the\naccounts of subscribers who are repeat infringers;\" [7] and (2) accommodating and not\ninterfering with standard technical measures as defined in the text of Section 512.\nThe copyright laws detailed in the previous sections do not make it clear whether\nGoogle's cached page service would be exempt from copyright liability. A background\non Google and an understanding of its cache feature will clarify why this is so.\n3.0 Google\nSergey Brin and Larry Page launched Google in the Fall of 1998 with one specific\nmission: \"to organize the world's information and make it universally accessible and\nuseful.\" [8] By 2003, Wired Magazine stated that Google.com entertained more than 28\nmillion visitors each month, and that four out of five web searches occurred on Google or\nother sites that license its technology. [9] Google currently receives more than 200 million\nsearch queries per day, more than half which come from outside of the United States. [10]\nThe great popularity of Google is attributable to PageRankTM, its system that ranks web\npages. [11] In addition to this unique feature, however, Google offers many more services\nand tools to its users. One such technology is its cached page service. By crawling the\nweb and taking snapshots of web pages, Google is able to offer users links to cached sites\nin case the original website is unavailable. Despite its many benefits, Google is facing\npossible copyright concerns for its cache technology. By gathering snapshots of web\npages in their entirety, and then making them available to its millions of users on the\nInternet, Google may be violating copyright laws that specify reproduction and\ndistribution as the exclusive rights of copyright owners. An assessment of Google's\ncache technology, its potential copyright concerns, and its relation to current copyright\nlaws, will help us better understand its legality.\n\n3.1 Google's Goals and Technology\nIn a document written by the founders of Google themselves, back when they were first\nintroducing it, Brin and Page specified their four intended goals. [12]\n3.1.2 High Precision\nTheir primary goal was to improve the quality of web search engines. As the number of\npages on the Internet increase, while the number of search results users view remains\nrelatively constant, high precision becomes extremely important. Google differentiates\nitself from other search engines that mostly rely on manually maintained lists of popular\ntopics or keyword matching, by utilizing the \"additional structure present in hypertext to\nprovide much higher quality search results.\" [13] At the heart of Google's software is its\nPageRankTM algorithm. Brin and Page defined a web page's PageRank as an \"objective\nmeasure of its citation importance that corresponds well with people's subjective idea of\nimportance.\" [14] This system allows search results to be prioritized to the query's\nkeyword searches, allowing for greater precision.\n3.1.2 Academic Development\nWhen Google was first launched, there was still very little academic research on search\nengines available. Brin and Page were the first to publish a detailed description of a\nlarge-scale web search engine. They hoped that Google would provide a greater push for\nmore development and academic understanding of search engines.\n3.1.3 Usability\nAnother key goal was to build a search engine that many people could actually use. This\nnot only included ease of use, but also the issue of scalability. As the Internet expands to\ninclude millions upon millions of web pages, search engines must be capable of scaling\nto the increasing number of resources available on the web. Google's index is currently\n]\ncomprised of more than three billion web pages, [15 and is surely scalable to many more.\n3.1.4 Support Novel Research\nBrin and Page's final goal was to support novel research activities on large-scale web-\nbased information. Google pursues this goal by storing the Internet's data in a\ncompressed form so that researchers can quickly process a large amount of online data,\nand produce results that would have otherwise been much more difficult to generate.\nOften times during research or general web searching, however, users encounter links\nthat lead them to \"Page Not Found\" sites. The web pages are no longer online or their\nsite's servers are unavailable. Google provides users the ability to still access such links\nvia their cached page service.\n3.2 Cached Page Service\nGoogle's cached page service enables users to view snapshots of web pages from their\ncache, appearing as they looked when they were crawled by the system for indexing.\n\nWhile crawling the web, Google downloads each and every page and analyzes it to\ndetermine the page's relevance for its PageRankTM feature. By taking a snapshot of the\npage, Google captures the state of the site at that moment in time. While many programs,\nsuch as browsers, cache recently accessed sites to minimize retrieval times in the near\nfuture, Google makes backups of every page, before it has even been requested. It then\nmakes these snapshots available to users as cached links when that site is returned as the\nresult of a search query. The cached page can be accessed by clicking on the \"Cached\"\nhyperlink near each search result, as indicated in Figure 1.\nFigure 1: Cached Link. The cached page of a website can be accessed by clicking on\nthe \"Cached\" hyperlink located near the bottom of most sites returned as search results.\nSuch a service is useful to users when: (1) the original site is unavailable, (2) they want\nto narrow in on the part of the page relevant to their search query, and (3) they lose the\ncode to their own web pages. When an original site is unavailable due to Internet\ncongestion or server problems, the user can still view the page's data via the cached link.\nSuch a feature is very useful in regards to retrieving outdated online magazine articles\nthat no longer exist. This allows users to continue their research or web surfing in a more\ntime-efficient manner. An additional benefit, as a Google spokesman noted, the cached\npages have the search query terms highlighted \"to make it easier for users to find relevant\ninformation.\" [16] There have been several documented cases where website publishers\naccidentally deleted their own code or index files off their computers and used Google's\ncache to retrieve their web page. Dylan Tweney discovered Google's web page recovery\nservice when he accidentally deleted his index.html file by mistake, causing his home\npage to appear as a bare list of files. When he realized he did not have a local copy, and\nsearching for a backup would have taken ages, he Googled his home page's URL and\nfound the cached old home page. By viewing the source of the cached version, he was\nable to find the original code, paste it into a new document, and restore his original home\npage without starting from scratch. [17]\nDespite the many benefits of Google's cache technology, it has a few snags too. Though\nweb pages that are unavailable can be viewed through the cached link, the cached page\nmay not have the most up-to-date information.\nThe executive producer for\nABCNews.com, Randy Stearns, is concerned that readers may access information that is\nnot up-to-date, and may include errors that had been fixed on the original site, but were\nnot on the archived pages. [18] Michael Godwin, staff counsel for the Electronic Frontier\nFoundation, believes those are risks publishers take when placing information on the\nInternet. \"By putting something on the Web, you're authorizing the world to look at it.\n]\nBy taking it down, you're taking the risk that someone might use the old data.\" [19\nGoogle, however, took the safer route; they have a header appear at the top of every\ncached page to remind users that it may not be the most recent version of the page. This\nway, users are made aware that they may not be viewing the most current information\nand are not deceived into mistakenly collecting inaccurate data. Additionally, the cached\n\npage is likely to contain very useful information, and is, thus, still a better option than the\nuser not being able to access the information at all. Other potential drawbacks of\nGoogle's cache fall in the category of copyright infringement.\n3.3 Copyright Concerns\nBy taking snapshots of entire web pages and then making links to those snapshots\navailable to users without the permission of the copyright owners, Google has been\ntreading the fine line of copyright infringement. Though users have been enjoying the\nservice for years, recent copyright complaints by web publishers have brought the\nlegality of Google's cached page service into question. In March of 2003, Microsoft\nCorporation submitted an official takedown notice to Google due to their product key\nbeing available on a site in Google's cache. [20] Similarly, in August of 2003, CNET\nsubmitted an official notice and takedown request regarding Google's copying and use of\n]\ncopyrighted content available from CNET's website. [21 Though Google ultimately\nremoved the copyrighted materials from their cache, who's responsibility is it to assure\nthat such copyrights are not infringed? Should copyright owners be forced to police the\nInternet to assure that their rights are not being infringed, or is it Google's responsibility\nto not involve itself in copyright violations? Above all else, is Google's method of\ncopying and providing information truly even copyright infringement?\nOriginally, the purpose of copyright law was to protect those who invent or develop\ntangible works, so to ultimately promote the sciences and useful arts. This would imply\nthat the protection of works is the primary goal, and that copyright owners should have\nthe choice to share their exclusive rights rather than be forced to go about protecting them.\nIn the reasoning in Whelan v. Jaslow, 797 F.2d 1222 (1986), the judge stated that, \"We\nmust remember that the purpose of the copyright law is to create the most efficient and\nproductive balance between protection (incentive) and dissemination of information, to\npromote learning, culture, and development.\" [22]\nAs technologies have developed,\nhowever, it has become increasingly difficult to balance the benefits of new technological\nservices with the protection of copyrights. Godwin believes that once an individual puts\ninformation up on the Web he or she is implicitly authorizing its reproduction, since the\nInternet functions by the use of copies. [23] Publishers, however, are likely to disagree and\nwould prefer an opt-in policy, where they choose to be included in Google's cache or not.\nSince Google's technology automatically caches every web page though, seeking\npermission from individual sites that contain copyrighted information is not possible.\nSacrificing Google's cache feature in the name of copyright protection, however, would\neliminate the several advantages of the tool described in Section 3.2.\nThere are, however, several opt-out options available to publishers who do not want their\nsites cached. They may notify Google of the infringement activity, and Google will\nremove the link as requested, as in the aforementioned cases of Microsoft and CNET's\ncomplaints. Additionally, Google respects the several mechanisms available through\nHTTP that disable a site's ability to be cached. Webmasters can prevent the caching of\ntheir sites by placing a \"noarchive\" meta in the header of each page. By encoding the\nrobots.txt file into one's website, a publisher can be assured that Google's robots will not\nbe able to crawl and cache their site.\n\nPublishers who may be especially interested in utilizing opt-out options are registration-\nonly sites such as many online newspapers. Why would individuals pay to access online\nnews articles when they could read them for free off of Google's cache instead? This\ncomplicates the entire matter because now the cache is negatively affecting the site's\nmarket value. Google, however, is more than willing to work with such site owners to\naddress the issue. Christine Mohan, a spokeswoman at the publisher of NYTimes.com,\nannounced that, \"We are working with Google to fix that problem--we're going to close\nit so when you click on a link it will take you to a registration page. We have established\nthese archived links and want to maintain a consistency across all these access points.\" [24]\nThe available opt-out options and Google's openness to work with publishers have\nprevented the eruption of any major lawsuits so far, but some believe it is only a matter of\ntime. Danny Sullivan, editor of Search Engine Watch, states that \"It's very much an\nissue that has yet to be tested, and I fully expect that it will be.\" [25]\nA closer look at Google's cached page service reveals a serious legal dilemma: Is\nGoogle allowed to make copies of web pages and then make those copies available to the\npublic without the copyright owners' permission?\n3.4 Google and Copyright Laws\nFred von Lohman, an attorney at the Electronic Frontier Foundation stated that, \"Many of\nus copyright lawyers have been waiting for this issue to come up: Google is making\ncopies of all the Web sites they index and they're not asking permission. From a strict\ncopyright standpoint, it violates copyright.\" [26] A Google spokesman, however, disagrees\nand stated, \"We've evaluated this from a legal perspective, including copyright law, and\n]\nhave determined that Google's cached page service complies with the law.\" [27 Google\n]\ndeclined my request for further comment on how it complies with copyright law, [28 and\nafter analyzing the copyright laws detailed in Section 2.0 myself, I concluded that it is\nambiguous whether current copyright laws would protect Google's cached page service.\nGoogle clearly violates two of the four exclusive rights outlined in Section 2.1, a\ncopyright owner's right to reproduction and distribution of the copyrighted work. By\ncrawling the Internet and taking full snapshots of each web page, it is reproducing the\ncopyrighted work. By then making that cached page available to search engine users via\na link on the search results page, Google is distributing the copyrighted work. The only\nway Google could exercise these otherwise exclusive rights is if it qualifies as fair use, or\nis otherwise exempt due to the DMCA safe harbors.\n3.4.1 Fair Use\nSection 2.1 outlines the following as the factors that determine whether an act constitutes\nfair use: (1) the purpose and character of the use, (2) the nature of the work, (3) the\namount and substantiality of the portion used, and (4) the effect of the use on the work's\nmarket or value.\n\n3.4.1.1 Purpose and Character of the Use\nCampbell v. Acuff-Rose Music, 510 U.S. 569, 579 (1994), states that the purpose and\ncharacter of the use involves a consideration of whether\n\"the new work merely supersedes the objects of the original creation, or\ninstead adds something new, with a further purpose or different\ncharacter, altering the first with new expression, meaning, or message;\nit asks, in other words, whether and to what extent the new work is\ntransformative.\" The more transformative the new work, the less will\nbe the significance of other factors, like commercialism, that may\n]\nweight against a finding of fair use.\"[29\nThe founders of Google claimed many noble design goals for their search engine, such as\nresearch and academic development as detailed in Section 3.1. While maintaining their\nmission of collecting the world's information and making it easily available, Brin and\nPage have rejected deals with great monetary benefit for the sake of Google's integrity.\n[30] Nonetheless, on the highest level, Google is a business and the commercial nature of\nits cached page service works against its ability to be considered fair use. Though some\ncould argue that the cache's purpose has an educational element due to its promotion of\nresearch, this aspect of its intent is unlikely to outweigh its overriding commercial\nfunction. Jason Schultz, staff attorney at the Electronic Frontier Foundation, agrees,\n\"Many of the pages in Google's cache are wholesale copies of the original pages. Google\nis clearly using these pages to boost its business. And many sites offer archives for\n]\nsubscribers only. These factors could weigh against Google in a law suit.\" [31\nAccording to Campbell v. Acuff-Rose Music, 510 U.S. 569, 579 (1994), above, however,\nthe transformative element of the use's character weighs more heavily than its\ncommercialistic purpose. Unfortunately for Google, its cache adds little, if any, new\nexpression, meaning, or message to its cached web pages. By simply taking snapshots of\nthe original sites and making those very snapshots available to the public, it is simply\nreproducing and redistributing the original copyrighted work with no additional\ninformation in or analysis of the actual content on the page. Therefore, both the purpose\nand character of Google's cached page service weigh against a finding of fair use.\n3.4.1.2 Nature of the Work\nDetermining fair use requires an assessment of the nature of the original work,\nacknowledging \"that some works are closer to the core of intended copyright protection\nthan others, with the consequence that fair use is more difficult to establish when the\nformer works are copied.\" [32] Google's cache takes snapshots of all web pages that\ncontain a variety of copyrighted original works. Such content could range from factual\nreports and biographies to artistic poems, stories, and photos; published or unpublished.\nAccording to June M. Besek, author of \"Copyright: What Makes a Use 'Fair',\" \"In\ngeneral, the law is more sympathetic to copying a fact-based work--a history or\nbiography, for example--than it is to copying a fanciful work such as the latest Harry\n]\nPotter book.\" [33\nTherefore, the artistic works are closer to that core of intended\nprotection. Since Google's cache copies both the factual and artistic materials in their\nentirety anyways, the nature of the cache factors unambiguously against fair use.\n\n3.4.1.3 Amount and Substantiality of the Portion Used\nGoogle's cached page service requires that the content of web pages be copied in their\nentirety for the purpose of the tool to be achieved. Besek says \"Generally, the more that\n]\nis taken, the less likely it is to be fair use...\" [34\nNonetheless, if the cached links are\nmade available so that the information can still be accessed when the original site is down,\nthey must contain the entire site's contents to be of use. If only a small portion of an\narticle was viewable in the cached link, for example, one would still need to access the\noriginal site to read the entire article and understand it to completion. The cache would\nbe useless at that point since the user would still need to wait for the original site to be\nonline again. Hence, the amount copied is reasonable in relation to the purpose for\ncopying. In Section 3.4.1.1, however, the purpose for copying itself was found to weigh\nagainst fair use. We can therefore infer that the amount and substantiality of the portion\nused also factors against fair use.\n3.4.1.4 Effect of the Use on the Work's Potential Market or Value\nFor the cached page service to negatively effect a site's potential market or value, users\nmust be accessing the page via the cached link more often than they are viewing the page\nvia the original site. Google, however, has admitted that there are very few clicks on the\ncached links, and that most users go directly to the original sites linked in their search\nresult pages. For those that do access the cached link, Google includes a header that\nstates the URL to the page's original site and encourages users to go to that site for the\nmost up-to-date information. Sites who would be adversely affected by the cache can\nalso utilize the opt-out options mentioned in Section 3.3. Judith Jennison, the defense\nlawyer for a search engine titled Arriba Soft, says the following about Google, \"The fact\nthat the search site has an opt-out program would likely illustrate that the market for\noriginal copyrighted works can be protected, which is a significant factor in fair-use\nanalysis.\" [35] Additionally, as shown in Figure 1, the link to the cached page is very\ndiscrete, so users would be drawn to the original site's link first. Therefore, Google's\ncached page service has little effect on the original site's market or value, and thus favors\nfair use.\nWith the fourth factor being the only one that supports fair use, Google's cached page\nservice does not qualify for fair use based solely on United States Code Title 17. An\nassessment of the DMCA and its safe harbors may provide the answer to whether\nGoogle's cache is legal or not.\n3.4.2 Safe Harbors\nSection 512 of the DMCA, described in Section 2.3 above, lists four safe harbors that\napply to online service providers: (1) transitory digital network communications, (2)\nsystem caching, (3) information residing on systems or networks at the direction of users,\nand (4) information location tools. Whether these safe harbors apply to Google depends\non whether the search engine can be defined as a service provider according to the\nDMCA. Section 512 defines a server provider as\n\n\"an entity offering transmission, routing, or providing connections for\ndigital online communications, between or among points specified by a\nuser, of material of the user's choosing, without modification to the\ncontent of the material as sent or received\" or \"a provider of online\n]\nservices or network access, or the operator of facilities thereof.\" [36\nSome interpret this definition to apply only to Internet service providers (ISPs), such as\nAOL, who offer people access to the Internet without modifying the actual content on the\nweb. According to Jonathan Bick, Professor of Internet Law at Pace Law School and\nRutgers Law School, search engines may register with the Copyright Office as an ISP. [37]\nMy inquiry to Google's Help Team regarding whether they consider themselves an ISP\nreceived the following response: \"Thank you for your note. We are not an internet\nservice provider as we do not offer any hosting or email services. We are a search engine\nonly.\"[38] Therefore, according to this interpretation, the DMCA safe harbors do not\napply to Google. Others, however, believe Section 512's definition of a service provider\napplies more broadly to include \"Internet service providers (ISPs), search engines,\nbulletin board system operators, and even auction web sites.\"[39] With such an\ninterpretation, the safe harbors have the potential to apply to Google's cached page\nservice.\nAssuming search engines, and therefore Google, do qualify as service providers, whether\nits cached page service qualifies as one of the four safe harbors requires a separate\nassessment.\n3.4.2.1 Transitory Digital Network Communications\nWhen the provider acts as a data conduit, transmitting digital information from one point\non a network to another at someone else's request; the transmission, routing, or providing\nof connections for the information, including transient copies that are made automatically\nin the operation of the network, are covered by the first safe harbor. [40] Google could be\nconsidered to behave as a data conduit since it transmits links as results to users who\nrequest sites related to specific search query terms. Its cached pages are the copies that\n\"are made automatically in the operation of the network,\" since all pages are backed-up\nwith no discrimination of the page's contents.\nThe Copyright Office Summary of Section 512 of the DMCA lists several conditions the\nprovider must meet to qualify for this safe harbor. The first requirement is that a person\nother than the provider must initiate the transmission. From the perspective of Google as\na search engine, this condition is met because the cached links are only transmitted if a\nuser queries terms related to the contents of that page. From the perspective of the\ncached page service, however, this condition is not met because the system automatically\ncrawls and caches every page, before a user has even requested them. According to the\nexecutive summary of the DMCA by the law offices of Lutzker & Lutzker LLP, the\nservice provider cannot place material online.[41] Google's cached page service, however,\nmakes their copies available online via their cached links. The second requirement is that\nthe transmission, routing, provision of connections, or copying must be executed by an\nautomatic process without selection of material by the service provider. Both Google and\nits cached page service meet the copying aspect of this requirement since pages are\n\nautomatically copies regardless of their content. Which links are actually outputted to\nusers as search results, however, are determined by Google's PageRankTM system, which\ncould be considered to be a \"selection of material by the service provider.\" Google and\nits cache service meet the third requirement that the provider cannot determine the\nrecipients of the material since they must output results to any user of the search engine.\nIt is ambiguous whether the cached page service meets the fourth requirement that states\nthat any intermediate copies must not be retained for longer than reasonably necessary.\nWhat time span constitutes \"reasonably necessary\" is not defined. The cached page\nservice maintains copies of pages anywhere from a few days to a few months depending\non when the system crawls that site again. Schultz believes it is ambiguous whether such\ndurations are considered reasonably necessary. \"The DMCA safe harbor might protect\nGoogle, although caching has to be \"intermediate\" and temporary\", so there's some\nquestion as to whether they meet that standard\".[42] Google and its cached page service\nboth satisfy the last condition requiring that no modification is made to the content. The\npages are simply backed-up in their entirety, and distributed in their entirety; the content\nis not edited or modified in any way to potentially change the gist of the content.\nThe analysis of the different requirements above leads us to conclude that it is uncertain\nwhether Google's cached page service would be protected by the limitation for transitory\ncommunications.\n3.4.2.2 System Caching\nThe safe harbor for system caching limits the liability of service providers who retain\ncopies of material for a limited time so that they can be quickly retrieved the next time\nthey are requested by the user. Though Google and its cached page service do abide by\nmany of the system caching limitation's requirements, such as not modifying the retained\nmaterial and removing pages they have been notified to eliminate, they do not qualify for\nthe system caching limitation.\nThe wording of the limitation implies that its core is to protect providers such as browsers\nwho cache pages recently visited by web-surfers so that they can quickly reload that page\nwhen requested by the user again. Google's cached page service, however, is not caching\nfor that reason. Its cache serves to provide users with cached links of pages if the original\nsite is unavailable. The Legal Protection of Digital Information specifies that the\n\"Section 512 provides safe harbors only to service providers, and then only when the\nalleged infringing material is not supplied or used by the service provider or its\n]\nemployees.\"[43\nIn this case, however, Google, the supposed service provider, is both\nsupplying and using the copies it makes as a service to users, in addition to its core\nbusiness as a search engine. Nevertheless, Godwin stated that since the DMCA does not\nmake a distinction between browser caches and search engine caches as its written, it is\nunlikely that a judge would find a search engine cache illegal.[44] Conversely, Congress\ndid not specify applying the caching exemption to search engines, and may have had a\ndifferent intent in mind.\nEven if one believed that Google did achieve this limitation's core goal, it still would not\nqualify for protection under this safe harbor because it does not meet at least two of the\n\nlimitation's requirements. To meet this limitation, the \"provider must limit users' access\nto the material in accordance with conditions on access (e.g. password protection)\nimposed by the person who posted the material.\" [45] According to the Legal Protection\nof Digital Information, \"A cache should not provide a way of bypassing an access control\nsystem for the material.\"[46] As proven by the NYTimes.com situation described in\nSection 2.3, where users were able to view cached versions of articles that were supposed\nto be available only to subscribers who had paid for the service, Google is not limiting\nusers' retrieval to the proper access conditions required by the site owners. Secondly,\nGoogle is not abiding by the requirement that the \"provider must comply with rules about\n\"refreshing\" material--replacing retained copies of material with material form the\noriginal location...\"[47] When a user is viewing one of Google's cached pages and\nattempts to refresh the page, the user is not directed to the material's original location, the\nsame cached page is reloaded instead.\nAn analysis of the conditions required for the system caching limitation leads us to\nconclude that Google's cached page service would unlikely qualify for the system\ncaching safe harbor. Attorney von Lohman agrees and stated that, \"Most people agree\nthat the caching exception in the DMCA is obsolete. I don't think it would cover\nGoogle's cache.\"[48]\n3.4.2.3 Information Residing on Systems or Networks & Information Location Tools\nThese safe harbors intend to limit the liability service providers could face for infringing\nmaterial that exists on their servers or that their links point to, respectively. A limitation\nthat allows the caching of sites to benefit users by making the information available when\nthe original site is down is what Google needs. These safe harbors, however, protect\nservice providers who are worried about being liable for material that they host on their\nsystems or link to without knowing whether that content is legal or not. Google's cached\npage service could not be exempt from copyright law due to these limitations since these\nsafe harbors are addressing different issues.\nAfter analyzing the current copyright laws, both the Title 17 fair use exemptions and the\nDMCA's safe harbors, it is still ambiguous whether Google's cached page service would\nbe ruled legal if brought to court.\n4.0 Comparable Issues\nOthers have faced similar legal challenges, but it is unclear whether the decisions made in\nthose cases would be the same as in Google's situation.\nIn Kelly v. Arriba Soft\nCorporation, 336 F.3d 811 (9th Cir. 2003), a search engine's reproduction and display of\nthumbnail images was found to be fair use, but its display of full-sized images has yet to\nbe decided. An organization called the Internet Archive faced legal challenges similar to\nGoogle since it copies web pages with the aim of creating an online library of all web\npages, but it received full exemption from the Copyright Office.\n\n4.1 Kelly v. Arriba Soft Corporation 336 F.3d 811 (9th Cir. 2003)\nWhen Leslie Kelly, a professional photographer, found reproductions of his images being\ndisplayed as thumbnail and full-sized images on Arriba Soft's results page, he charged\nthe search engine with copyright infringement. The United States District Court for the\nCentral District of California ruled that though Kelly had sufficiently proven that Arriba\nhad made unauthorized reproductions and displays of his works, those reproductions and\ndisplays constituted fair use under Section 107 of the Copyright Act. Upon appeal, the\nUnited States Court of Appeals for the 9th Circuit affirmed in part, reversed in part, and\nremanded in part the district court's ruling. The Court of Appeals found the search\nengine's use of thumbnails to be fair use, but remanded the decision regarding the full-\nimage displays to further proceedings since the district court was not to have ruled on that\nissue.\n4.1.2 Arriba Soft's Legal Challenges\nArriba Soft was a search engine unlike most others; rather than outputting text, the results\nappeared in the form of small images. From July 1999 to near August 2000, two links\naccompanied the thumbnails in the results page: Source and Details. Clicking on the\nSource link, or the thumbnail itself, two new windows would pop up. While one of these\ntwo windows was the home page of the images original site, the other was a full-sized\nversion of the original image.\nLeslie Kelly filed copyright infringement charges against Arriba Soft when he discovered\nthat the search engine was reproducing and displaying his images as thumbnails. Arriba\nconceded to the violation of reproduction and display rights for the thumbnails only, and\nthus, argued that the thumbnail images constituted fair use.\nThe district court, however, ruled on both the thumbnails and the full-sized images, and\nfound Arriba's use of the photos to be fair use. This decision broadened the scope of\nKelly's original motion to include the full-sized images, and it also extended Arriba's\nconcession to cover the full-sized images. The court found Arriba's use of the images to\nbe sufficiently transformative and harmless to the value of Kelly's works, and therefore,\nfair use of Kelly's images.\nKelly appealed the decision to the United States Court of Appeals for the 9th Circuit. The\nresulting holding was that the district court ruled correctly in finding the search engine's\nuse of the thumbnail images to be fair use. The district courts ruling regarding the full-\nsized images, however, was reversed and remanded since \"neither party moved for\nsummary judgment as to the full-size images and Arriba's response to Kelly's summary\njudgment motion did not concede the prima facie case for infringement as to those\nimages.\"[49]\n\n4.1.2 Arriba Soft and Google\nAs one of the few cases involving a search engine's copyright liability, Kelly v. Arriba\nSoft Corporation, 336 F.3d 811 (9th Cir. 2003), may provide insight into what Google can\nor cannot do. Analyzing the reasoning behind why Arriba Soft constitutes fair use will\nallow us to determine whether this case would serve as a solid precedent for Google's\ncached page service.\nThe circuit court found that the purpose and character of Arriba Soft's use of the images\nas thumbnails weighed in favor of fair use. Though the search engine clearly had a\ncommercial purpose, it was not using Kelly's images to promote its website, nor was it\ntrying to sell the images. \"Instead, Kelly's images were among thousands of images in\nArriba's search engine data-base. Because the use of Kelly's images was not highly\nexploitative, the commercial nature of the use weighs only slightly against a finding of\nfair use.\"[50] I agree with this reasoning because a user cannot simply save a thumbnail\nimage instead of buying the actual one. Attempts to enlarge the thumbnail image would\ndiminish its quality, and become worthless to the user. If similar reasoning were applied\nto Google's cache, it too would have only a slight weighing against fair use because,\nthough it is also of a commercial purpose, each of its snapshots are among millions of\ncached copies automatically downloaded into Google's database. Regarding the\ncharacter of the search engine, Arriba Soft was found to be sufficiently transformative.\n\"Arriba's use of Kelly's images in the thumbnails is unrelated to any aesthetic purpose.\nArriba's search engine functions as a tool to help index and improve access to images on\n]\nthe internet and their related web sites.\"[51 The factor of purpose and character was\nfound to favor Arriba \"due to the public benefit of the search engine and the minimal\nloss of integrity to Kelly's images.\"[52] This analysis does not apply to Google because its\ncached page service actually takes snapshots of entire web pages, and displays the entire\nweb page. Users could actually view the cached link and never need to see the original\nsite; individuals who wanted an image, however, would still need to retrieve a full-sized\nimage if they wanted to use it, the thumbnail would not suffice. Google, therefore, is of a\nless transformative nature than Arriba Soft, and its purpose and character of use would\nfactor against fair use. This analysis coincides with my conclusion in Section 3.4.1.1.\nRegarding the fair use factor of the nature of Arriba Soft, the circuit court found it to\nslightly favor Kelly due to the artistic nature of the images, and since many of them were\npublished prior to appearing on the search engine's result pages. Google's cached pages\nconsist of many artistic and published works so the court's finding in Arriba Soft would\nimply a weighing against fair use for Google, as reasoned in Section 3.4.1.2.\nThe circuit court found the factor of amount and substantiality of use to favor neither\nparty. The reasoning was that Arriba Soft had reproduced and displayed the entire work,\nbut that amount was reasonable according to its purpose of use. Had the search engine\nonly displayed a portion of the image, the photo would be harder to identify, and the\nresults page would be useless. In Section 3.4.1.3, I had rationalized that Google needed\nto copy the web page in its entirety to serve the cache's purpose of making the page\navailable even if the site is down. Had Google only copied and displayed a portion of the\npage, the user would still need to access the original site to view the remaining portions.\n\nAt the point where the user would still have to wait for the original site to come back\nonline, the benefits of the cached page service are lost. The difference between Arriba\nSoft and Google, however, is that Arriba's purpose was found to be legitimate, whereas I\nhad determined that Google's purpose factored against fair use. Therefore, even though\nthe amount Google copied is reasonable for its objective, since its purpose weighs against\nfair use, its nature factors against fair use too.\nThe final factor for determining fair use, market effect, was found to favor Arriba Soft.\nSince the thumbnail images included the original sites address, interested buyers were\nactually being driven to Kelly's site rather than away from it. Even if users only wanted\nmore information regarding the photo, or wanted to see a full-sized image of the photo,\nthey would go to the original site. The market or values of Kelly's images were not being\nnegatively impacted by Arriba Soft's search engine. Though Google's cached link pages\nalso include the original sites URL, the same need to visit the original site does not exist\nas with Arriba Soft. Had the court been ruling on Arriba Soft's display of full-sized\nimages, there would be more of a similarity to Google's situation. In Section 3.4.1.4, I\nhad concluded that the market effect favors fair use for Google, but Arriba Soft's case\ndoes not set a precedent for why that is true for the cached page service.\nJennison, Arriba Soft's defense lawyer, believes this case could serve as a precedent for\nGoogle. \"In Google's case, the result would likely be the same, because the temporary\ncaching for indexing purposes would be fair use per Kelly v. Arriba soft.\"[53] I disagree,\nhowever, because Google goes beyond simply temporarily \"caching for indexing\npurposes.\" Google's cached page service may hold backup copies anywhere from days\nto months, whereas Arriba Soft only holds it for 24 hours. Additionally, Google's feature\nis not meant for indexing, but is presented as an alternative to viewing the original site,\nespecially when the original website is unavailable. The full-sized images would be more\ncomparable to the snapshots of pages taken by Google's crawler because both contain the\nwork in its entirety. With the focus of Kelly v. Arriba Soft Corporation, 336 F.3d 811 (9th\nCir. 2003), being on the thumbnail images rather than the full-sized images, it does not\nserve as a proper precedent for Google's cached page service.\n4.2 Internet Archive's Wayback Machine\nBrewster Kahle, inventor of the Wide Area Information Servers (WAIS) system, founder\nof WAIS Inc., and 1982 MIT graduate, founded the Internet Archive in 1996. His goal\nwas to construct a digital library that would preserve the Internet's contents.[54] To\ncollect the web's information, the organization programmed computers to crawl the\nInternet by downloading a web page, and then downloading the graphics and other pages\nit links to. As the process continues throughout each page, more and more of the Web\ngets stored into the Internet Archive's databases. To serve as a library, the organization\ndeveloped the Wayback Machine, a program that \"organizes the billions of pages and\nallows anyone online to look up the contents of the archive.\"[55] Kahle told CNET\nNews.com that his archive is often used for patent research, and by designers and\nstudents who wish to understand the evolution of the Web's design and display.\n\n4.2.2 Internet Archive's Legal Challenges\nA program that copies web pages to archive them and make them available to others is\nsurely going to face legal challenges, and the Internet Archive confronted several. Aside\nfrom the legal and social issues involving privacy, import/export restrictions, and\n]\npossession of social property,[56 the Internet Archive's greatest legal challenge was\ncopyright protection. Certain provisions of the DMCA, such as Section 1201 that\nprohibits the circumvention of access controls, threatened the Internet Archive's ability to\narchive software titles. Kahle, therefore, petitioned the Copyright Office for an\nexemption from Section 1201 to be granted for \"Literary and audiovisual works\nembodied in software whose access control systems prohibit access to replicas of the\n]\nworks.\"[57 In late October of 2003, the Internet Archive was granted exemptions to\nreproducing the following four categories of works:\n(1) Compilations consisting of lists of Internet locations blocked by commercially marketed filtering\nsoftware applications that are intended to prevent access to domains, websites or portions of\nwebsites, but not including lists of Internet locations blocked by software applications that operate\nexclusively to protect against damage to a computer or computer network or lists of Internet\nlocations blocked by software applications that operate exclusively to prevent receipt of email.\n(2) Computer programs protected by dongles that prevent access due to malfunction or damage and\nwhich are obsolete.\n(3) Computer programs and video games distributed in formats that have become obsolete and which\nrequire the original media or hardware as a condition of access.\n(4) Literary works distributed in ebook format when all existing ebook editions of the work (including\ndigital text editions made available by authorized entities) contain access controls that prevent the\nenabling of the ebook's read-aloud function and that prevent the enabling of screen readers to render\n]\nthe text into a specialized format.[58\nThough these exemptions will only last for three years, at which time the Internet\nArchive will need to petition once again, they will aid the organization with achieving its\ngoal until then.\n4.2.2 Internet Archive and Google\nThe Internet Archive's technological process is similar to that of Google's cached page\nservice. Both download copies of pages while crawling the web, and later make those\ncopies available to users. The key distinction, however, is that the Wayback Machine\nwas built for non-profit, preservation purposes, whereas Google's cache is a commercial\ntool meant for the convenience of web surfers. This difference is sufficient reason for\nwhy the Internet Archive's legal challenges would not set precedence for Google because\nSection 108 and 117 of the Copyright Act, which govern archiving, specifically exempt\nthe Internet Archive's reproduction of web pages. Even without these sections, copying\nfor archival purposes is protected by fair use exemptions. As the House of\nRepresentatives reported when passing the Copyright Act of 1976,\n\"The efforts of the Library of Congress, the American Film Institute, and other organizations to rescue\nand preserve this irreplaceable contribution to our cultural life are to be applauded, and the making of\n]\nduplicate copies for purposes of archival preservation certainly falls within the scope of 'fair use.'\"[59\n\nWith Google specifically saying that its \"cache feature does not attempt to create a\npermanent historical record of the Web,\"[60] it would not qualify for fair use under\nSection 108 or 117, or by any exemptions received by the Internet Archive.\n5.0 Suggested Update of Copyright Law\nAll the analysis thus far indicates that if Google were currently brought to court with\ncopyright infringement charges against its cached page service, it is unclear whether they\nwould be liable or not.\nTo promote the availability of research and ensure the\npreservation of Google's cached page service despite potential copyright charges, it is\nvital that the copyright laws be updated to allow for such features.\nChapter 4 of the Digital Dilemma outlines several reasons that could justify updating\ncopyright law to cover Google's cached page service, specifically seven categories \"into\nwhich exceptions and limitations to copyright owners' rights seem generally to fall.\"[61]\nGoogle's cached page service could fall into three of those categories: (1) those that are\nbased on public interest grounds, (2) those that promote flexible adaptation of the law to\nnew circumstances, and (3) those that cover situations in which uses or copying of\nprotected works are incidental to otherwise legitimate activities, or implicitly lawful\ngiven the totality of circumstances.[62] Laws that permit libraries and archives to make\ncopies for preservation purposes are examples of exceptions that fall into the first\ncategory. One could argue that the value Google's cache feature adds to research and the\nproliferation of information is of public interest, and should consequently also be exempt.\nAs technologies rapidly change, the courts must often apply copyright laws to situations\nthat were never intended by the original writers of the law. Such a case includes Sony v.\nUniversal City Studios, 464 U.S. 417, 104 S. Ct. 774, 78 L. Ed. 2d 574 (1984), where the\nhome taping of television programs for time-shifting purposes was ruled as fair use.\nEventually, however, the copyright laws themselves must be adjusted to accommodate\nthe changes in society. The DMCA was written around the same time that Google began\nits services on the Internet. The writers of the DMCA were most likely not taking\nGoogle's cached page feature into consideration when determining what qualifies as an\nexemption, since they were not even familiar with it at the time. An update to copyright\nlaw that unambiguously legalizes search engine caching could be justified by the need to\nadapt laws to new circumstances. Lastly, the overall look at Google's cached page tool\nin Section 3.4.1 has already concluded that the service has little if any adverse affects on\nother markets, and can be of great value to users. Since the end result of providing users\naccess to pages whose original sites are down is a legitimate activity, the third category\nmay also justify exempting the incidental use and copying of protected works that may\noccur. Some could turn this into a means versus ends debate, but ultimately, it is just one\nof many justifications for updating copyright law.\nAn additional provision should be added to the DMCA that protects search engines that\ncache for the purpose of providing better service to users. Inspired by existing copyright\nlaw, the following is a suggested provision to be added to Section 512 of the DMCA.\n\nLimitations on cached page services for search engines\n(1) LIMITATION ON LIABILITY. -- A search engine shall not be liable for monetary relief, or for injunctive or\nother equitable relief, for infringement of copyright by reason of the caching and display on a system or\nnetwork controlled or operated by or for the search engine in a case in which --\n(A)\nthe caching is carried out through an automatic technical process without selection of the\nmaterial by the search engine for the purpose of making the material available to users of the\nsystem or network\n(B)\nthe search engine does not select the recipients of the material except as an automatic response\nto the request or query of that user\n(C)\nno copy of the material made by the search engine in the course of such storage is maintained\non the system or network in a manner ordinarily accessible to anyone other than anticipated\nrecipients\n(D)\nthe material is transmitted through the system or network without modification of its content\n(E)\nthe address of the original website is clearly indicated on the cached page\n(F)\nthe cached page indicates that it may not be the most up-to-date version\n(G)\nthe link to the original website is more predominantly visible on search result pages than the\ncached page link, and\n(H)\nthe search engine does not receive a financial benefit directly attributable to the cached material,\nin a case in which the search engine has the right and ability to control such activity\n(2) CONDITIONS. -- The conditions required are that --\n(A)\nif the cached website has in effect a condition that a person must meet prior to having access to\nthe material, such as a condition based on payment of a fee or provision of a password or other\ninformation, the search engine permits access to the stored material in significant part only to\nusers of its system or network that have met those conditions and only in accordance with those\nconditions; and\n(B)\nif the owner of a copyrighted work requests for the removal of his or her work form the cache, the\nsearch engine must respond expeditiously to remove, or disable access to, that material upon\nnotification as described in subsection (3).\n(3) DESIGNATED AGENT. -- The limitations on liability established in this subsection apply to a search\nengine only if the it has designated an agent to receive notifications of requests for material removal\ndescribed in subsection (2)(B), by making available through its service, including on its website in a location\naccessible to the public, and by providing to the Copyright Office, substantially the following information:\n(A) the name, address, phone number, and electronic mail address of the agent.\n(B) other contact information which the Register of Copyrights may deem appropriate.\nThe Register of Copyrights shall maintain a current directory of agents available to the public for inspection,\nincluding through the Internet, in both electronic and hard copy formats, and may require payment of a fee\nby the search engines to cover the costs of maintaining the directory.\n(4) ELEMENTS OF NOTIFICATION. --\nTo be effective under this subsection, a request for material removal must be a written communication\nprovided to the designated agent of a search engine that includes substantially the following:\n(A) a physical or electronic signature of a person authorized to act on behalf of the material's owner.\n(B) identification of the material that is to be removed, and information reasonably sufficient to permit\nthe search engine to locate the material.\n\n(C) information reasonably sufficient to permit the search engine to contact the complaining party, such\nas an address, telephone number, and, if available, an electronic mail address at which the\ncomplaining party may be contacted.\n(D) a statement that the complaining party has a good faith belief that use of the material in the manner\ncomplained of is not authorized by the copyright owner, its agent, or the law.\n(5) CONDITIONS FOR ELIGIBILITY. --\nACCOMMODATION OF TECHNOLOGY. -- The limitations on liability established by this section shall\napply to a search engine only if it accommodates and does not interfere with standard technical\nmeasures for publishers to opt-out of caching such as robots.txt files and meta tags.\nDEFINITION. -- As used in this subsection, the term \"standard technical measures\" means technical\nmeasures that --\n(A) have been developed pursuant to a broad consensus of copyright owners and service providers in\nan open, fair, voluntary, multi-industry standards process;\n(B) are available to any person on reasonable and nondiscriminatory terms; and\n(C) do not impose substantial costs on search engines or substantial burdens on their systems or\nnetworks.\n(6) DEFINITIONS. --\n(A) SEARCH ENGINE. -- As used in this limitation, the term \"search engine\" means a computer\nprogram that retrieves documents, files, or other information from a database or network, or the\noperator of such a program.\n(B) MONETARY RELIEF. -- As used in this section, the term \"monetary relief\" means damages, costs,\nattorneys' fees, and any other form of monetary payment.\nThe aforementioned suggested update to copyright law would allow Google to continue\noperation of its cached page service liability free, while still allowing publishers the\noption of not being copied or of requesting their material to be removed from the cache.\n6.0 Conclusion\nWith the Internet expanding at phenomenal rates, Google's cached page service holds\ngreat values for those turning to the Web for information. The recently raised copyright\nconcerns have stirred debate on the legality of Google's cache. Current copyright laws\ndo not exempt the cache as fair use, and it is ambiguous whether it would be protected by\nthe DMCA safe harbors. There is confusion whether the limitations apply to search\nengines, and even if they do, it is unclear whether they would specifically cover Google's\ncached page service. There are few examples to turn to for insight on what would happen\nif Google were brought to court. One of the few known cases of a search engine charged\nwith copyright infringement does not serve as a solid precedent since the case involved\nthumbnail images, whereas Google's cache returns web pages in their entirety. That\nsame case, however, will soon have a proceeding regarding the search engine's display of\nfull-sized images, which may be more comparable to Google's cache. Other\n\norganizations that also reproduce and display web pages in their entirety are often times\nnot analogous because they conduct such activities for archival purposes, which are\nexempt from copyright law. Only by adding a provision to the DMCA that protects\nsearch engines who partake in cached page services, while still allowing publishers opt-\nout options, can we bring copyright law up to par with the rapid changes in technology\nand preserve a most valued service.\n7.0 Endnotes\n[1] 17 U.S.C.S. § 106 (2003).\n[2] US Code Collection, \"Sec. 107. - Limitations on exclusive rights: Fair use;\" available from\nhttp://www4.law.cornell.edu/uscode/17/107.html; Internet; accessed November 22, 2003\n[3] 17 U.S.C.S. § 107 (2003).\n[4] Legal Protection of Digital Information, \"Chapter 3: Copyright of Digital Information;\" available from\nhttp://www.digital-law-online.com/lpdi1.0/treatise33.html; Internet; accessed November 29, 2003\n[5] Ibid.\n[6] Ibid.\n[7] \"The Digital Millennium Copyright Act of 1998: U.S. Copyright Office Summary,\" December 1998,\nPage 9\n[8] Google's Corporate Information, \"Google History;\" available from\nhttp://www.google.com/corporate/history.html; Internet; accessed December 4, 2003\n[9] Wired Magazine, \"Google vs. Evil;\" available from\nhttp://www.wired.com/wired/archive/11.01/google_pr.html; Internet; December 4, 2003\n[10] Google Press Center, \"Google Fun Facts;\" available from http://www.google.com/press/funfacts.html;\nInternet, accessed December 5, 2003\n[11] Google Technology, available from http://www.google.com/technology/index.html; Internet; accessed\nDecember 4, 2003\n[12] The Anatomy of a Large-Scale Hypertextual Web Search Engine;\" Brin, Sergey; Page, Lawrence;\navailable from http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm; Internet; accessed\nDecember 4, 2003\n[13] Ibid.\n[14] Ibid.\n[15] Google Press Center, \"Google Fun Facts;\" Olsen, Stefanie; July 9, 2003; available from\nhttp://www.google.com/press/funfacts.html; Internet, accessed December 5, 2003\n[16] CNET News.com, \"Google Cache Raises Copyright Concerns;\" available from\nhttp://news.com.com/2100-1032_3-1024234.html; Internet; accessed November 5, 2003\n\n[17] Microdoc News, \"Google Cache as Friend;\" Tweney, Dylan; April 18, 2003, available from\nhttp://microdoc-news.info/home/2003/04/22.html; Internet; accessed December 5, 2003\n[18] CNET News.com, \"Google Cache Raises Copyright Concerns;\" 2003\n[19] Electronic Frontier Foundation Staff Counsel Michael Godwin, interviewed by Parul Deora, 8\nDecember 2003, phone\n[20] Chilling Effects, \"Microsoft Complains of Product Key in Google Cache;\" March 12, 2003; available\nfrom http://www.chillingeffects.org/dmca512/notice.cgi?NoticeID=586; Internet; accessed November 22,\n[21] \"CNET Complains of WinPro in Google Cache;\" August 28, 2003; available from\nhttp://www.chillingeffects.org/dmca512/notice.cgi?NoticeID=845; Internet; accessed November 22,\n[22] Whelan v. Jaslow, 797 F.2d 1222 (1986).\n[23] Electronic Frontier Foundation Staff Counsel Michael Godwin, interviewed by Parul Deora, 8\nDecember 2003, phone\n[24] CNET News.com, \"Google Cache Raises Copyright Concerns;\" 2003\n[25] Ibid.\n[26] Ibid.\n[27] Ibid.\n[28] The following is Google Team's response to my inquiry into their copyright concerns. Response\nreceived December 8, 2003, Re: [#5294358] Questions for MIT Paper, from google to pdeora\nHi Parul,\nThank you for your note. We apologize for our delayed response. At this time,\nthe information you've read is all of the information that's publicly available.\nAs you may imagine, because Google is a privately held company, there is\nsome information that we're unable to provide to the public at this time.\nWe hope that your class assignment went well, and we'd love to field any other\nquestions you may have in the future.\nRegards,\nThe Google Team\n[29] Campbell v. Acuff-Rose Music, 510 U.S. 569, 579 (1994).\n[30] \"In May, Anita Roddick, the outspoken British founder of the Body Shop, blasted Google in her blog for\nyanking a text ad for her site. Google's explanation: Roddick had called actor John Malkovich a\n\"vomitous worm\" in her blog, violating a Google policy against accepting ads for sites that are \"anti-\"\nanything. After Roddick protested, Google offered to reinstate the ad in exchange for a promise from\nRoddick that she would remove the Malkovich reference from the first page of her site. When she\nrefused, Brin had a decision to make: Should he give in and accept Roddick's money, or stand by his\nprinciples? He chose his principles.\"\nWired Magazine, \"Google vs. Evil;\" available from\nhttp://www.wired.com/wired/archive/11.01/google_pr.html; Internet; December 4, 2003\n\n[31] Electronic Frontier Foundation Staff Attorney Jason Schultz, interviewed by Parul Deora, 4 December\n2003, phone\n[32] Campbell v. Acuff-Rose Music, Inc., 510 U.S. 569, 579, 127 L. Ed. 2d 500, 114 S. Ct. 1164 (1994).\n[1[33]] Educause Review, \"Copyright: What Makes a Use 'Fair'?\" Besek, June M.; November/December\n2003; available from https://www.educause.edu/ir/library/pdf/erm0368.pdf; Internet; accessed December\n8, 2003\n[34] Ibid.\n[35] CNET News.com, \"Google Cache Raises Copyright Concerns;\" 2003\n[36] 17 U.S.C. § 512\n[37] New Jersey Law Journal, \"Exploitation of Trademarks on the Internet;\" Bick, Jonathan; December 8, 2003;\navailable from http://web.lexis-nexis.com/universe/document?_m=49f26a9782e72323b352d099df6\n632fc&_docnum= 1&wchp =dGLbVzz-zSkVA&_md5=3df59410dfd4ae94a7156dda0454b2a0; Internet;\naccessed December 9, 2003\n[38] Google Help Team, questioned by Parul Deora, 9 December 2003, email\n[39] Chilling Effects, \"What defines a service provider under Section 512 of the DMCA?\" available from\nhttp://www.chillingeffects.org/dmca512/notice.cgi?NoticeID=586#QID127; Internet; accessed\nNovember 22, 2003\n[40] \"The Digital Millennium Copyright Act of 1998: U.S. Copyright Office Summary,\" December 1998,\nPage 10\n[41] Lutzker & Lutzker LLP, \"The Digital Millennium Copyright Act;\" available from\nhttp://www.arl.org/info/frn/copy/osp.html; Internet; accessed November 5, 2003\n[42] Electronic Frontier Foundation Staff Attorney Jason Schultz, interviewed by Parul Deora, 4 December\n2003, phone\n[43] Legal Protection of Digital Information, \"Digital Law Online: Caching;\" available from\nhttp://www.digital-law-online.com/lpdi1.0/treatise36.html; Internet; accessed November 29, 2003\n[44] Electronic Frontier Foundation Staff Counsel Michael Godwin, interviewed by Parul Deora, 8\nDecember 2003, phone\n[45] \"The Digital Millennium Copyright Act of 1998: U.S. Copyright Office Summary,\" Page 11\n[46] Legal Protection of Digital Information, \"Digital Law Online: Caching;\" available from\nhttp://www.digital-law-online.com/lpdi1.0/treatise36.html; Internet; accessed November 29, 2003\n[47] \"The Digital Millennium Copyright Act of 1998: U.S. Copyright Office Summary,\" Page 11\n[48] CNET News.com, \"Google Cache Raises Copyright Concerns;\" 2003\n[49] Kelly v. Arriba Soft Corporation, 336 F.3d 811 (9th Cir. 2003).\n[50] Ibid.\n[51] Ibid.\n\n[52] Ibid.\n[53] CNET News.com, \"Google Cache Raises Copyright Concerns;\" 2003\n[54] Internet Archive, \"Archiving the Internet;\" Scientific American; November 4, 1996; available from\nhttp://www.archive.org/sciam_article.html; Internet; accessed November 29, 2003\n[55] Business Week Online, \"A Library as Big as the World;\" Green, Heather; February 28, 2002; available\nfrom http://www.businessweek.com/technology/content/feb2002/tc20020228_1080.htm; Internet;\naccessed November 25, 2003\n[56] Internet Archive, 2003\n[57] Kahle, Brewster; Macgillivray, Alexander; Lessig, Lawrence; Seltzer, Wendy; \"Rm 2002-4 - 17 USC §\n1201 Exemptions Notice of Inquiry,\" December 18, 2002\n[58] \"Statement of the Librarian of Congress Relating to Section 1201 Rulemaking;\" available from\nhttp://www.copyright.gov/1201/docs/librarian_statement_01.html; Internet; accessed December 7, 2003\n[59] H.R. REP. NO. 94-1476, at 73 (1976).\n[60] CNET News.com, \"Google Cache Raises Copyright Concerns;\" 2003\n[61] Digital Dilemma, \"Chapter 4: Individual Behavior, Private Use, and Fair Use;\" available from\nhttp://www.nap.edu/html/digital_dilemma/ch4.html; Internet; accessed November 22, 2003\n[62] Ibid."
    },
    {
      "category": "Resource",
      "title": "digital_balance.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/7d3fe827d7f5a3227eb06f6934242b90_digital_balance.pdf",
      "content": "Digital Balance\nAu, Tin Lun (Bruce)\nMay 16, 2002\n\nMassachusetts Institute of Technology\nHarvard Law School\nSpring Semester, 2002\nMIT 6.805/6.806/STS085: Ethics and Law on the Electronic Frontier\n\nAdvisors\nJoe Pato\nHal Abelson\n\nTable of Contents\n\nAcknowledgements......................................................................... 3\nAbstract........................................................................................... 3\nThesis Statement............................................................................. 4\nIntroduction .................................................................................... 4\nI. The Future and its Problem ......................................................... 5\nII. The Solution............................................................................... 6\nII.1 Overview............................................................................................... 6\nII.2 System Administration ......................................................................... 8\nII.2a Decision-making Process ................................................................................... 8\nII.2b Criteria of Certification...................................................................................... 9\nII.3 Technical Infrastructure...................................................................... 12\nII.3a Cryptographic Protocol - SSL .......................................................................... 12\nII.3b Certification Procedure and Revocation .......................................................... 13\nII.3c Confidentiality of the Application Process....................................................... 14\nIII. System Evaluation .................................................................. 15\nIII.1 Law.................................................................................................... 15\nIII.2 Architecture - Hardware and Software Industry .............................. 17\nIII.3 Market................................................................................................ 19\nIII.4 Norm - Consumers............................................................................ 20\nIV. Weaknesses ............................................................................ 22\nIV.1 Overview........................................................................................... 22\nIV.2 Content Providers Do Not Participate............................................... 22\nIV.3 Software Companies Do Not Participate .......................................... 23\nIV.4 Technology Is Not Yet Ready........................................................... 24\nV. Trends ...................................................................................... 25\nV.1 Overview ............................................................................................ 25\nV.2 Decentralized File-sharing System and Digital Millennium Copyright\nAct ............................................................................................................. 25\nConclusion.................................................................................... 28\n\nTable of Figures\nFigure 1: High-level Overview........................................................................................ 5\nFigure 2: This is an example of a successful application of the Digital Balance\nCertificate. The Copyright Office can reject the applications by issuing a rejection at\nany point in the course of the application process................................................ 7\nFigure 3: The process of certifying an applicant's software. The Copyright Office sends\nthe signed binary of the DB Certificate to the successful applicant ....................... 14\n\nAcknowledgements\n\nI would like to thank my advisors Joe Pato and Hal Abelson for their guidance. I\nwould also like to thank Butler Lampson, Mike Godwin, Jonathan Zittrain, Tim Gorton\nand Jane Jung for their generous input.\n\nAbstract\n\nThis paper predicts that the widespread use of digital rights management systems\nin the future will empower copyright owners to refuse delivering digital content to their\nsubscribers if some software that are in operations on their subscribers' computing\nenvironments are unknown to them. Therefore, digital content providers will not leave\nroom for non-infringing uses of their copyrighted work and effectively expand the scope\nof their exclusive rights beyond the boundary set forth in the Copyright Law. I propose\nthat the Copyright Office should establish itself as a Certificate Authority (CA) and\ncertify software applications it deems compliant with the Copyright Law. Some content\nproviders will choose to honor the Copyright Office's digital certificates, or as I will term\n\"Digital Balance (DB) Certificates,\" in order to attract subscribers, and deliver content to\ntheir subscribers' computers in the presence of the certified software. Since the DB\nCertificate is voluntary, the content providers retain their right to charge the Copyright\nOffice's decision in courts. The office's certification is not a legal judgment; instead it\nopens room for the non-infringing uses opportunities of copyrighted work.\n\nThesis Statement\n\nThe U.S. Copyright Office should establish itself as a Certificate Authority (CA)\nand issue Digital Balance (DB) Certificates to software applications or systems it deems\ncompliant with the U.S. Copyright Law. The market force should compel the content\nproviders to honor the DB Certificates. As a result, the delicate balance between the\ncopyright owners' exclusive right to their work and the promotion of arts and science in\nthe public domain would be restored.\n\nIntroduction\n\nSection 8 of Article I of the U.S. Constitution empowers Congress \"to promote\nthe progress of science and useful arts, by securing for limited times to authors and\ninventors the exclusive right to their respective writings and discoveries.\" The intent of\nthe Copyright Law is to maintain the delicate balance between the authors' exclusive\nright to their work and the progress of science and arts in the public domain. This paper\npresents a solution to restore this balance. In the past, the development of a decentralized\nfile-sharing system in the Internet made it very hard for authors to protect their exclusive\nrights of their digital content, but the imminent introduction of the digital right\nmanagement system will change the landscape drastically and enable the authors to\nexpand the scope of their exclusive rights beyond the limit defined under 17 USC 1. I\npropose that the Copyright Office should issue Digital Balance (DB) Certificates to re-\nopen the door for non-infringing uses of digital copyrighted work. See Figure 1 for a\npictorial representation of the idea presented above.\n\nIn this paper, I propose a solution to this future problem. Part I states the future\nthat I foresee and its potential problem. Part II outlines the administrative and technical\nimplementations of my proposed solution, namely the establishment of the U.S.\nCopyright Office as a Certificate Authority that certifies software applications or systems\nwhich it considers compliant with the U.S. Copyright Law. Part III evaluates, and\ndemonstrates the viability and effectiveness of the proposed system by arguing that the\nlaw, the architecture, the market and the norm are mostly in favor of the proposed\nsolution. It addresses some concerns of various stakeholders: the copyright owners, the\n\nhardware and software industry, the government and the consumers. Part IV discusses the\nweaknesses of the system and compares the proposed solution with some alternative\ndesigns. Part V explains the reasons why the future problem that I foresee in Part I is\nprobable.\n\nLevel of Copyright Holders'\nEnforceable Exclusive Rights\n\nFigure 1: High-level Overview. The Imaginary Balance is the balance between the authors'\nexclusive right to their work and the progress of science and arts in the public domain\n\nI. The Future and its Problem\n\nDigital content providers will have the technical means as well as legal support to\npreclude any functions other than those they determine, from being performed on their\ndigital contents. In practical terms, their subscribers will not receive any copyrighted\nmaterials from content providers if their computing environments contain software\napplications that are not certified by the providers. Software applications have to\nauthenticate themselves to a digital rights management system before being loaded to the\ncomputing environment. Since this is so, the digital rights management system is able to\nTime\nImaginary\nBalance\nInternet\nDecentralized\nFile-sharing\nSystem\nDigital Rights\nManagement\nSystems\nDigital\nBalance\nCertificate\nWe are\nhere\nI propose\n\nreport the status of the computing environment to the content providers and let them\ndecide whether copyrighted work should be delivered. (I will discuss why the content\nproviders' will acquire such technical means and legal support to prevent any non-\ninfringing uses of their work through decentralized file-sharing systems in Part V.)\nTherefore, copyright owners will have the power to effectively expand the scope of their\nexclusive rights beyond the limitations defined under 17 USC 1, because they can among\nother things, effectively eliminate any possibilities for fair use of their copyrighted work\nfor purposes such as criticism, comment, news reporting, teaching (including multiple\ncopies for classroom use), scholarship, or research, defined under 17 USC 107.\n\nIf we put Sony Corporation of America v. Universal City Studios, the definitive\nSupreme Court case regarding copyright into this future, Universal City Studios would be\nable to detect whether Sony's video tape recorders, Betamax is hooked up to their\nsubscribers' TV's or not, before deciding whether they still want to deliver them the TV\nprogramming. Hence, the Sony v. Universal Studios case would not have existed. The\ncreation of Digital Balance (DB) Certificates proposed in this paper is to prevent content\nproviders from having too much control over their copyrighted work.\n\nII. The Solution\nII.1 Overview\n\nThe U.S. Copyright Office would issue digital certificates called Digital Balance\n(DB) to software applications that it considers compliant with the Copyright Law. It\nsigned the DB Certificates with its private key. Some content providers would decide to\nhonor the DB Certificates and deliver their copyrighted materials to their subscribers'\ncomputers in the presence of DB certified software applications. The process of securely\nauthenticating the DB certified programs by the content providers will be discussed in\nPart III.2.\n\nIn order to obtain a DB Certificate from the Copyright Office, a software\ndeveloper would have to submit its software functions description and technical\nspecifications to the Copyright Office for examination with an application fee. A Digital\n\nBalance Division within the Copyright Office would be responsible for evaluating the\ndocuments based on the Copyright Law and related Supreme Court cases such as Sony v.\nUniversal City Studios. After the Copyright Office concludes that the software program\nor system does not allow infringing uses of copyrighted content, it would issue the\nsoftware developer a preliminary DB Certificate that includes items such as the\ncertificate's ID, date of publication and name of the application, the version of the\napplication, the date of expiration and a list of functionalities provided by the software\napplication. The software developer would employ a third party to test the software and\nproduce a quality control report that evaluates the adherence of the actual software to its\nspecifications within on average 9 months after the software is released. The Copyright\nOffice would decide whether a software application's DB Certificate should be renewed\nbased on the quality control report and the actual program. The Copyright Office can\nreject the applications by issuing a rejection at any point in the course of the application\nprocess. Figure 2 summarizes a successful DB Certificate application process. Again, the\nexecution environment that supports this system will be described in Part III.2.\n\nTime\nCopyright\n\nFigure 2: This is an example of a successful application of the Digital Balance Certificate. The\nCopyright Office can reject the applications by issuing a rejection at any point in the course of the\napplication process.\n\nSoftware function description\nTechnical specifications\nOffice\nSoftware\n\nDevelopers\n\n(Lawyers)\nPreliminary Digital Balance\nCertificate (short life-span)\nQuality control report\nActual program\nDigital Balance Certificate\n(long life-span)\n\nSome content providers may honor the DB Certificates and deliver their digital\ncontents to their subscribers while DB certified software applications are present on\nsubscribers' computing environments. Some may not. Naturally, content providers would\nretain their rights to challenge the DB software applications in courts when for example;\nthey deem the software developers liable for contributory and vicarious copyright\ninfringement.\n\nII.2 System Administration\n\nThe Copyright Office would create a new division to entertain all of the\napplications. With the division, the panel that has the authority to approve the software\napplications would be predominately composed of copyright lawyers, and includes\nrepresentatives from the content providers, software companies and consumer groups.\nThe division also would have staff for administration and technical maintenance. This\nsection explains in detail the decision-making process and the criteria of the certification.\n\nII.2a Decision-making Process\n\nThe software developers, hereafter referred to as applicants would have to identify\nthemselves and submit two documents - the software function description and technical\nspecifications - in order to apply for the Digital Balance Certificates. The software\nfunction description exhausts the list of functions that can be performed by the software\nand gives arguments on why the applicant's software does not constitute copyright\ninfringement. The technical specifications would be stored in the Copyright Office for\nfuture reference when the applicant submits its quality control report.\n\nWith this information in hand, the panel would attempt to mimic the courts'\nrulings as much as possible when they are evaluating the legitimacy of the software.\nAlthough content providers would be likely to charge software developers for\ncontributory and/or vicarious copyright infringement, instead of direct infringement, the\ncopyright owners have to prove, among other things, that there has been a direct\n\ninfringement by someone1. Therefore, the primary question the panel has to ask before\nthey would issue a preliminary Digital Balance Certificate to an applicant is whether the\nuse of copyrighted work enabled by the software application constitute direct copyright\ninfringement or not. They would do so by referring primarily to the Copyright Law,\nespecially 17 USC 107 - fair use and the precedence set by previous Supreme Court\ncases. The criteria of certification will be discussed in the next section.\nThere are two\nreasons for issuing a preliminary DB Certificate. First, it would enable applicants to\ndevelop their new software with higher confidence of them being certified. Second, it\nwould allow applicants to release their software without significant delay so that they can\nbe responsive to the market as much as possible. This reduces the amount of otherwise\nunbearable overhead on the applicants' part.\n\nIn order to receive a DB Certificate of longer long-span, applicants would have to\nemploy a third party that has no conflict with interest in the subject to create a quality\ncontrol report. The report would evaluate the accuracy of the software function\nspecifications in describing the actual functioning of the program as well as the\ndiscrepancy between the functions stated in the specifications and the functions that can\nbe performed by the actual program. Common security evaluation standard such as\nUnited Kingdom Information Technology Security Evaluation and Certification Scheme\n(UK ITSEC) takes 6 months to a year to evaluate a software application. Therefore, the\napplicants would have just enough time to submit their quality control report in around 9\nmonths after the first date of releases of their software. The panel would then base its\nfinal decision on its direct experience in manipulating copyrighted work with the\nsoftware and the recommendations of the quality control report. The procedure for\nissuing DB Certificates will be discussed with more detail in Part II.3b.\n\nII.2b Criteria of Certification\n\nThis section proposes the criteria of certification that guides the panel's decision.\nThe major criteria are that the functions of the software do not exceed the boundary of\n\n1 See Fred von Lohmann, IAAL: Peer-to-Peer File Sharing and Copyright Law after Napster, Berkeley\nCenter for Law & Technology, 2001\n\nfair use defined under 17 USC 107 - limitations on exclusive rights: fair use and 17 USC\n1201 - circumvention of copyright protection systems. I will suggest a list of software\napplications that should successfully be DB certified at the end of the section. However,\nsince non-infringing uses of copyrighted work by definition cannot be pre-determined;\nmy list of software is by no means exhaustive or definitive.\n\n17 USC 107 states that\n\n\"the fair use of a copyrighted work, including such use by reproduction in copies or phonorecords\nor by any other means specified by that section, for purposes such as criticism, comment, news reporting,\nteaching (including multiple copies for classroom use), scholarship, or research, is not an infringement of\ncopyright.\"\n\nThe Panel would consider the four factors defined under 17 USC 107 when\ndetermining whether the functions enabled by the software applications are non-\ninfringing or not. The four factors are\n\n(1) the purpose and character of the use, including whether such use is of a commercial nature or\n\nis for nonprofit educational purposes;\n\n(2) the nature of the copyrighted work;\n\n(3) the amount and substantiality of the portion used in relation to the copyrighted work as a\n\nwhole; and\n\n(4) the effect of the use upon the potential market for or value of the copyrighted work.\n\nThe fact that a work is unpublished shall not itself bar a finding of fair use if such finding is made\n\nupon consideration of all the above factors\n\n17 USC 1201 states that\n\n(1) No person shall circumvent a technological measure that effectively controls access to a work\n\nprotected under this title.\n\n(2) No person shall manufacture, import, offer to the public, provide, or otherwise traffic in any\n\ntechnology, product, service, device, component, or part thereof, that -\n\n(A) is primarily designed or produced for the purpose of circumventing a technological measure\n\nthat effectively controls access to a work protected under this title;\n\n(B) has only limited commercially significant purpose or use other than to circumvent a\n\ntechnological measure that effectively controls access to a work protected under this title; or\n\n(C) is marketed by that person or another acting in concert with that person with that person's\n\nknowledge for use in circumventing a technological measure that effectively controls access to a\n\nwork protected under this title.\n\nThe panel would also draw references from relevant Supreme Court cases such as\nSony Corporation of America v. Universal City Studios in which, the Supreme Court\n\ndecided that the use of Betamax video tape recorders (VTR's) to record some copyrighted\nworks which had been exhibited on commercially sponsored television by the content\nproviders a non-infringing use and therefore judged that Sony was not liable for\ncontributory copyright infringement. Justice Stevens, in the course of his delivery of the\nCourt's opinion gives another guideline that may not be immediately apparent from the\nfour factors mentioned above: the existence of some meaningful likelihood of future\nharm on the potential market for the copyrighted work is sufficient to challenge a\nnoncommercial use of that copyrighted work.\n\n\"A challenge to a noncommercial use of a copyrighted work requires proof either that the\nparticular use is harmful, or that if it should become widespread, it would adversely affect the potential\nmarket for the copyrighted work. Actual present harm need not be shown; such a requirement would leave\nthe copyright holder with no defense against predictable damage. Nor is it necessary to show with certainty\nthat future harm will result. What is necessary is a showing by a preponderance of the evidence that some\nmeaningful likelihood of future harm exists. If the intended use is for commercial gain, that likelihood may\nbe presumed. But if it is for a noncommercial purpose, the likelihood must be demonstrated.\"\n\nThis guideline is very relevant to today's situation where the use of Internet is\npervasive. One piece of software that enables noncommercial use of a copyrighted work\ncan be widely available to the public and hence be likely to cause future harm on the\npotential market for the copyrighted work.\n\nThe Court also gives another guideline in the event that the content providers can\nnot demonstrate that the use of certain articles of commerce induce future harm on the\npotential market of their copyrighted work. The guideline for this particular case is that\nthe copyright holders have no power over the distribution of that particular article of\ncommerce if it is capable of commercially significant non-infringing use. Justice Stevens\nclaimed that\n\n\"...the sale of copying equipment, like the sale of other articles of commerce, does not constitute\ncontributory infringement if the product is widely used for legitimate, unobjectionable purposes. Indeed, it\nneed merely be capable of substantial noninfringing uses.\"\n\nIn summary, the panel certifies software applications that it deems safe from\ndirect copyright infringement in order to safeguard room for non-infringing uses of\ncopyrighted work. There would have been a direct infringement by someone to make\n\nsoftware developers liable for contributory and/or vicarious copyright infringement.\nTherefore, the Copyright Office's certification has no legal power and its sole purpose is\nto protect content providers' copyrighted work from being abused in the era of Internet.\nHence, the content providers can disagree with the Copyright Office and charge any\nsoftware developers and consumers for indirect copyright infringement and direct\ninfringement respectively in courts.\n\nThe following list of imaginary software applications demonstrates some\nfunctions that content providers may not allow to be performed on their copyrighted\nwork, but are likely to be considered non-infringing uses by the Copyright Office:.\n1. Allows users to record an online TV show or radio broadcast onto their\nmachines;\nprohibits them from forwarding the content over the network but;\nallows them to replay the content on the same machine for an unlimited\namount.\n2. Allows users to mark, paint and make changes to digital images but;\ndisallows them to send the derivative work to elsewhere over the network or\nprint it out.\n3. Allows users to make a clip of a digital movie or a digital song;\nallows them to replace the sound track of a digital movie with another song\nor insert new clips into the movie but;\ndisallows them from sending the derivative work to a third party.\n4. Allows users to type up notes while reading an expensive company research\nreport in digital form on the screen;\ndisallows users from printing or forwarding the report but;\nallows user to print out or foward the notes that are typed up to a third party in\nthat session.\n\nII.3 Technical Infrastructure\n\nThis section describes the cryptographic protocol that the applicants and the\nCopyright Office would use, the procedure of certifying and revoking a software\napplication, the contents of a Digital Balance Certificate and the confidentiality of the\nsystem.\n\nII.3a Cryptographic Protocol - SSL\n\nApplicants and the Copyright Office would communicate over the Internet\nthrough an improved version 3 of the secure socket layer (SSL) protocol that prevents\n\ntwo known attacks: version-rollback attack and ChangeCipher attack.2 The proposed\nsystem also requires the applicants to use a 128-bit key size to protect the key against\nbrute force attack. As SSL is already a widely used cryptographic protocol, it has been\nsubject to a significant amount of on-field testing. Therefore, the proposed system\nchooses SSL for both its popularity and security.\n\nII.3b Certification Procedure and Revocation\n\nA DB Certificate would certify a software application that the Copyright Office\ndeems free from direct copyright infringement. It would include items such as the\ncertificate's ID, date of publication and name of the application, the version of the\napplication, the date of expiration and a list of services, or properties, provided by the\napplication, i.e., content type handled, whether it saves content to disk, etc. The language\nused to express functionalities of the application must be consistent with the standard\nadopted by the future digital right management system. The Copyright Office then signs\nthe binary of the DB Certificate with its private key. The Copyright Office changes its\nasymmetric key pairs annually to enhance security. Figure 3 illustrates the process of\ncertification. The Copyright Office's signed DB Certificate is critical for the software to\nsuccessfully authenticate itself to a digital right management system. This authentication\nprocess will be discussed in more detail in Part III.2.\n\n2 See Saltzer, J. H., and Kaashoek, M. F., Topics in the Engineering of Computer Systems, MIT 6.033 class\nnotes, draft release, version of January 27, 2002, 6-86 ('Version 3 of SSL accepts connection requests from\nversion 2 of SSL. This opens a version-rollback attack, in which an attacker convinces the server to use\nversion of 2 of the protocol, which has a number of well-documented vulnerabilities, such as the cipher\nsubstitution attack. Version 3 appears to be carefully designed to withstand such attacks, but the\nspecification doesn't forbid implementations of version 2 to resume connections that were started with\nversion 3 of the protocol. The security implications of this design are unclear. One curious aspect of version\n3 of the SSL protocol is that the MAC in the Finished message does not include the ChangeCipher\nmessage. As pointed out by Wagner and Schneier, an active attacker can intercept the ChangeCipher\nmessage and delete it, so that the server and client don't update their current cipher suite. Since messages\nduring the handshake are not sealed and authenticated, this can open a serious security hole. Wagner and\nSchneier describe an attractive attack that exploits this observation. Currently, widely used\nimplementations of SSL 3.0 protect against this attack by accepting a Finished message only after\nreceiving a ChangeCipher message. The best solution, of course, would be to include the ChangeCipher\nmessage in the MAC of the Finished message, but that would require a change in the specification of the\nprotocol.')\n\nDigital Balance Certificate\n\nCertificate ID\nName of application\nVersion of application\nDate of issue\nExpiration Date\nFunctionalities\nSign the binary with\nCopyright Office's\nprivate key.\nBinary\nSuccessful\nApplicant\n\nFigure 3: The process of certifying an applicant's software. The Copyright Office sends the\nsigned binary of the DB Certificate to the successful applicant.\n\nThe Copyright Office would revoke a certificate by making the certificate's ID\npublic, so that the digital right manage system can disregard it by adding the ID to their\nown certificate revocation list. The DB Certificates also have expiration dates, so they are\nautomatically revoked when they expire. The Copyright Office would normally set the\nexpiration date to be one year from the date of issue, but it may employ a more\ncomplicated scheme to enhance the system's efficiency. For instance, the Copyright\nOffice could set a longer expiration period for software that applies for renewal and set a\nshorter expiration period for software whose candidacies are more controversial.\n\nII.3c Confidentiality of the Application Process\n\nAn applicant cannot apply for a DB certificate anonymously, but the Copyright\nOffice also can not reveal any of the information submitted by an applicant, the\napplicant's identity, or the status of his application to any third party except the courts.\n\nThe Copyright Office would maintain a record of all the submitted materials in a secure\nstorage for future reference.\n\nIII. System Evaluation\n\nThis section evaluates, and demonstrates the viability and effectiveness of the\nproposed solution: establishing the Copyright Office to certify software applications that\nit considers compliant with the Copyright Law. The copyright owners, the hardware and\nsoftware industry, the government and the consumers are various stakeholders of the\nsystem and they all fall under one of the four main forces that shape a behavior in today's\nsociety: law, architecture, market and norm3.\n\nIII.1 Law\n\nThis section illustrates why the proposed solution is compliant with the Copyright\nLaw, which it aims at safeguarding. The focus of the analysis is on the proposed\nsolution's compliance with the anti-circumvention provisions and the concept of fair use\ndefined in the Digital Millennium Copyright Act (DMCA). This section also argues that\nthe Copyright Office is responsible for and is capable of executing the proposed solution.\n\nIII.1a U.S. Copyright Law\n\nThe proposed system is voluntary and does not require any. Copyright holders\nand content providers have no obligation to recognize the Digital Balance Certificates\nissued by the Copyright Office. Although I will argue below that content providers are\nlikely to be compelled to recognize the DB Certificates due to the market pressure, the\nvoluntary nature of the system can be considered a weakness and will be discussed in\nmore detail in Part IV. Nevertheless, this voluntary nature frees the system from running\nafoul of the provisions in the U.S. Copyright Law. DB Certificates do not legitimize the\nuse of copyrighted work performed by software applications. The Copyright Office\nsimply makes a judgment on whether software enables non-infringing or infringing uses\nof copyrighted work. Content providers, whether they honor the DB Certificates or not,\n\n3 See Larry Lessig, The Law of the Horse: What Cyberlaw Might Teach, Harvard Law Review (Draft, Fall\n1999), P. 506-7\n\ncontinue to have the right to challenge the software developers of the applications under\nsuspicions for violating the Copyright Law in court.\n\nI in my analysis take one step further and assume that Congress has passed an Act\nthat mandates all digital content distributors to participate in the system and honor the DB\nCertificates. The content distributors still have their right to challenge the software\ndevelopers in courts. I argue that the Act will still be compliant with the law because the\nCopyright Office still only allows the opportunities for non-infringing uses of\ncopyrighted work. The Copyright Office will become an independent United States\ngovernment agency that regulates the copyright system regarding digital work, similar to\nthe Federal Communications Commission (FCC) that regulates interstate and foreign\ncommunications by wire or radio.4 If some certified software applications provide\nfunctions that constitute copyright infringement or circumvent technological means that\nprotects copyrighted work and the court rules that the software developers violate\ncontributory or vicarious copyright infringement, the copyright holders will still receive\nlegal remedies from them. The copyright holders are also entitled to charge any direct\noffenders such as consumers. Essentially, this Act does not widen the spectrum of fair use\nand access control circumvention, but only attempts to restore the balance between the\nrights of copyright owners and public in the use of copyrighted works by allowing the\npossibilities of infringing uses.\n\nU.S. Copyright Office\n\nThe mission of the Copyright Office is to promote creativity by administering and\nsustaining an effective national copyright system.5 If the content providers eliminate all\npossibilities for non-infringing uses of their copyrighted digital work, the Copyright\nOffice is responsible for reestablishing a balance between the public's interest and the\ncopyright owners' exclusive right in the digital media. In addition, the Copyright Office\nis publicly funded, so it is ideal to act as an impartial Certificate Authority to issue DB\nCertificates. The Copyright Office is also capable of executing the proposed system, as it\n\n4 See Section 1, Communication Act of 1934\n5 See U.S. Copyright Office, Strategic Plan 2002-2006, Part 1 - The Mission and Function of the U.S.\nCopyright Office, February 2002\n\nhas positioned itself to make a fundamental transformation in its public services from\npaper and hard copy-based processing to primarily electronic processing. It also plans to\nchange its processes from traditional manual capabilities to IT-enabled functions.6 Lastly,\nas the Copyright Office currently does not advise on possible copyright violations7, it\nemploys or contracts copyright lawyers to make the decision in the process of issuing DB\nCertificates.\n\nNon-infringing uses of copyrighted work cannot be pre-determined by definition.\nThe Copyright Office simply allows opportunities for the public, especially software\ndevelopers, to perform non-infringing uses but does not define them. Therefore, it does\nnot impact any jurisdiction the courts currently enjoy. The Copyright Office screens the\nsoftware applications primarily because it makes the proposed system more reasonable\nand credible for content providers to take part in, in light of the widespread use of\ndecentralized file-sharing systems in the Internet. The effect of decentralized file-sharing\nsystems on content providers will be discussed in more detail in Part V.\n\nIII.2 Architecture - Hardware and Software Industry\n\nCode is the architecture that shapes the proposed system. This section explains the\nexecution environment for the DB certified programs and also evaluates the security level\nof the proposed system.\n\nBoth hardware and software companies have to be involved in order to create an\nexecution environment that enables the functioning of the proposed system and they have\nalready been striving towards creating such a computing environment. More than 150\nhardware and software companies have joined the Trusted Computing Platform Alliance\n(TCPA) since the spring of 19998. They envision building a solid foundation for\nimproved trust in the PC over time and agree that the specification for the trusted\ncomputing PC platform should focus on two areas - ensuring privacy and enhancing\n\n6 See U.S. Copyright Office, Strategic Plan 2002-2006, Part 3 - Copyright Office Strategic Initiatives,\nFebruary 2002\n7 See U.S. Copyright Office's Web site at http://www.copyright.gov/fls/fairuse.html\n8 See http://www.trustedpc.org/home/home.htm\n\nsecurity.9 They have created a specification for a Subsystem that enhances access\ncontrols on information stored on a trusted platform. Among other things, a Trusted\nPlatform enables an entity to determine the state of the software environment in that\nplatform and to seal data to a particular software environment in that platform.10\n\nMoreover, Microsoft Corporation has already obtained a United States patent\n(6,330,670) for a Digital Rights Management Operating System (DRMOS), which\nresembles closely to the vision set forth by the TCPA and provides an example of\nexecution environment that supports the proposed system. This is the abstract of the\ninvention:\n\n\"A digital rights management operating system protects rights-managed data, such as downloaded\ncontent, from access by untrusted programs while the data is loaded into memory or on a page file as a\nresult of the execution of a trusted application that accesses the memory. To protect the rights-managed\ndata resident in memory, the digital rights management operating system refuses to load an untrusted\nprogram into memory while the trusted application is executing or removes the data from memory before\nloading the untrusted program. If the untrusted program executes at the operating system level, such as a\ndebugger, the digital rights management operating system renounces a trusted identity created for it by the\ncomputer processor when the computer was booted. To protect the rights-managed data on the page file,\nthe digital rights management operating system prohibits raw access to the page file, or erases the data from\nthe page file before allowing such access. Alternatively, the digital rights management operating system\ncan encrypt the rights-managed data prior to writing it to the page file. The digital rights management\noperating system also limits the functions the user can perform on the rights-managed data and the trusted\napplication, and can provide a trusted clock used in place of the standard computer clock.\"\n\nThe DRMOS described in the patent requires certain configurations of the central\nprocessing unit (CPU) in a PC11, but hardware companies are likely to support the\nchanges considering the participation of Intel Corporation, one of the main CPU\nproducers in the TCPA. The DRMOS, among other things, ensures two requirements:\nfirst, trusted applications must be identified in some fashion, and, second, the DRMOS\nmust prevent non-trusted applications from gaining access to the content when it is\nstored, either permanently or temporarily, on the subscriber computer.12 In one of the\ninvention's embodiment, the DRMOS identifies an application through a certificate. That\n\n9 See the Trusted Computing Platform Alliance (TCPA), Building a Foundation of Trust for the PC,\nJanuary 2000, P.1\n10 See the Trusted Computing Platform Alliance (TCPA), TCPA Main Specification Version 1.1a, 2001, P.\n11 See Microsoft Corporation, United States Patent 6,330, 670, Hardware and Operating Environment\n12 See Microsoft Corporation, United States Patent 6,330, 670, System Level Overview\n\nis where DB Certificates come into play and help content providers trust applications. All\nin all, the technology for an effective digital right management system that mandates\nsoftware to authenticate themselves using digital certificates already exists.\n\nIII.3 Market\n\nThe proposed system is a voluntary program where content providers are not\nforced to participate. Therefore, the market is the major force that compels content\nproviders to give room for non-infringing uses of their digital work. I argue that\nsubscribing digital content online is an untouched and competitive market that will push\ncontent distributors to honor Digital Balance Certificates in order to open as well as win\nthe market. This is also a profitable business perceived by content providers.\n\nDigital content providers bear little cost to store, reproduce and distribute their\ncopyrighted work, compared to the traditional physical content providers. For example,\nas far as online music goes, apart from the cost, research from companies show that the\nmarket is lucrative. Webnoize states that over half of U.S. college students are willing to\npay $10 or more per month to use Napster, suggesting the college market alone could\ngenerate over $400 million per year in revenues for the service.13 In Europe alone, the\nonline market for music is expected to soar in value from 333 million euros last year to\nmore than 2 billion euros by the end of 2006, according to research from Jupiter\nMMXI.14 It is hard to argue that a certain market is profitable, but I can try to show that\nsubscribing digital content online is perceived as profitable by companies. For instance,\nSecure Digital Music Initiative (SDMI) is a forum for industries to develop a voluntary,\nopen framework for playing, storing, and distributing digital music necessary to enable a\nnew market to emerge.15 It has 147 participating companies in October, 2000 and the\nmembership fee is $20,000 per year.16\n\n13 See BBC News, Poor outlook for paid-for online music, September 2001, at\nhttp://news.bbc.co.uk/hi/english/sci/tech/newsid_1556000/1556097.stm\n14 See BBC News, Online Music Bonanza, April 2001, at\nhttp://news.bbc.co.uk/hi/english/business/newsid_1300000/1300489.stm\n\n15 See Secure Digital Music Initiative at http://www.sdmi.org/who_we_are.htm\n16 See Secure Digital Music Initiative at http://www.sdmi.org/participant_list.htm\n\nWhat is certain is that online digital content subscription is an untouched market.\nApart from online digital music mentioned above, there is an array of digital contents\nsuch as movies, expensive documents and images, TV and radio broadcasts that can be\ndistributed in digital format to the Internet population.\n\nCongress passed the Sherman Antitrust Act in 1890 to maintain economic liberty\nand eliminate restraints on trade and competition. Antitrust Law is a strong protection\nagainst a monopoly on the digital content distribution industry. Moreover, in the case of\nonline music, Congressmen have taken initiative to create a fair ground for competition.\nRick Boucher and Chris Cannon introduced the Music Online Competition Act in August\n2001 that aims at removing obstacles for the Internet music services such as facilitating\nthem to locate and notify all of the publishers of a particular musical composition and\nallows them to produce multiple copies of a song in different transmission speeds and\ndifferent media formats.17 \"The Music Online Competition Act will ensure that\nconsumers have Internet access to legal high-quality music, that creators get paid rapidly,\nand that competition - rather than lawsuits - will drive this marketplace forward,\" said\nJonathan Potter, executive director of Digital Media Association (DiMA).18\n\nIn summary, providing digital content online is an untouched and large market\nthat is perceived as lucrative by content providers. In order to compete with each other,\nsome content providers will choose to honor the Digital Balance Certificates to boost\ntheir reputation.\n\nIII.4 Norm - Consumers\n\nThere are yet any major educational campaigns that teach the public about the\ncurrent statute of the Copyright Law, but there are already companies that advocate the\nFair Use Right to make copies of digital content for personal use, not mentioning\n\n17 Statement of Congressman Rick Boucher, Introduction of Music Online Competition Act, August 3,\n18 See DiMA Applauds Legislation that Supports Consumers, Creators and Competition\nat http://www.digmedia.org/whatsnew/brief.cfm?file=ACF79FE.htm\n\nconsumer groups. For example, Gateway Computer bought a one-minute television spot\nthat promotes the message of \"Gateway supports your right to enjoy digital music\nlegally\". This is the summary of the TV advertisement provided by a Wired News article\non April 11th 200219:\n\nA man slides a CD into his truck's stereo. Music fills the cabin. The camera pulls back, revealing\nGateway CEO Ted Waitt sitting next to a cow. As Elwood's cover of \"Sundown\" starts, Waitt and the cow\nbegin lip-synching the song.\n\nBlack-screen messages pop up.\n\n\"Like this song?\"\n\n\"Download it from Gateway.com.\"\n\n\"Burn it to a CD....\"\n\n\"Or load it on an MP3 Player.\"\n\nOn top of the idea that making copies for personal use is legal, a generation of\nInternet users grows up with the idea that swapping files online is legal. The average\n\nnumber of simultaneous users of Napster was 1.57 million in February 200120. A National\nLaw Journal study done by DecisionQuest found that 41.5 percent of 1,000 potential\njurors believe that copyrighted music should be freely traded for personal use21. The\npublic norm is likely to oppose the notion that a digital rights management system should\nbe ale to dictate all possible uses of digital content.\n\nOn the far end of the spectrum of interpreting the fair use doctrine, there are\nvarious groups that advocate a broader interpretation of \"fair use\". The current statute of\nthe doctrine is that fair use is a defense against copyright infringement, but organization\nlike Digitalconsumer.org advocates changing the statute to give consumers the right to\n\n19 See Brad King, Are Ads a Gateway to Illegal CDs?, at\nhttp://www.wired.com/news/mp3/0,1285,51719,00.html\n20 See Michael Mahoney, Report: Napster Downloads Fall 87 Percent Since February, E-Commerce\nTimes, June 6, 2001, at http://www.ecommercetimes.com/perl/story/10298.html\n21 See Dick Kelsey, Jury Pool Survey - Napster's Chances Good, Newsbytes, Oct. 10, 2000, at\nhttp://www.newsbytes.com/pubNews/00/156450.html\n\n\"fair use\". They propose the Consumer Technology Bill of Rights22, which gives users\nthe right to\n1. \"time-shift\" content that they have legally acquired.\n2. \"space-shift\" content that they have legally acquired.\n3. make backup copies of their content.\n4. use legally acquired content on the platform of their choice.\n5. translate legally acquired content into comparable formats.\n6. use technology in order to achieve the rights previously mentioned.\n\nIn summary, the public is likely to have a more liberal interpretation of the fair\nuse doctrine than the content providers do, let alone the content providers' financial\ninterest. Therefore, content providers who recognize the Digital Balance Certificates can\nclaim that they support consumers' \"right\" to perform non-infringing uses of digital\ncontent and are likely to gain reputation as well as subscriptions from them.\n\nIV. Weaknesses\nIV.1 Overview\n\nThe proposed solution to establish the Copyright Office as a Certificate Authority\nis a voluntary program and does not force content providers to participate. Content\nproviders have no legal obligation to honor the Digital Balance Certificates issued by the\nCopyright Office, and are able to determine all the possible uses of their copyrighted\nmaterials by themselves. Software companies may not find the business of innovating\nsoftware applications that respect copyright lucrative and may not take part in the\nproposed system as well. Lastly, the technology that supports the DB Certificates may\nalso be flawed.\n\nIV.2 Content Providers Do Not Participate\n\nI argue in Part III.3 that the untouched and competitive market of online\nsubscription of digital content will compel content providers to leave room for the public\nto decide what constitute non-infringing uses of their work. However, the music industry\ntoday does regard making a mixed CD of favorite music on computers a piracy practice.\nThe Recording Industry Association of America (RIAA) defines, on their Web site one\n\n22 See http://www.digitalconsumer.org/bill.html\n\ntype of piracy recordings as \"the unauthorized duplication of only the sound of legitimate\nrecordings, as opposed to all the packaging, i.e. the original art, label, title, sequencing,\ncombination of titles etc. This includes mixed tapes and compilation CDs featuring one or\nmore artists.\" Therefore, there are reasons to believe that other digital content providers\nmay follow the music industry's strong stance on interpreting the fair use doctrine and\ndisregard the Digital Balance Certificates. Nevertheless, one can counter-argue that the\ncontent providers would learn a lesson from the Sony Corporation of America v.\nUniversal City Studios case, as movie companies receive substantial revenue from movie\nvideo today. Unknown fair usage of copyrighted work has the potential to benefit\ncopyright owners.\n\nThe proposed solution is essentially an attempt to restore the balance between\nproviding copyright holders' incentives to create and promoting arts and science in the\npublic domain with as little intervention as possible. If the content providers choose other\n\nmeans to gain market share, rather than allowing room for the opportunities of non-\ninfringing uses of their digital work by recognizing Digital Balance Certificates, the\nproposed solution will fail. However, the proposed system will at least put the\ngovernment in a better position for introducing stricter regulations if necessary while\nintroducing new regulation on the market is usually a political nonstarter. Dan L. Burk\nand Julie E. Cohen presented thorough analysis on the legality of introducing stricter\nregulation such as mandating content providers to recognize Digital Balance Certificates\nin Fair Use Infrastructure for Rights Management Systems23.\n\nIV.3 Software Companies Do Not Participate\n\nIn order to make the proposed solution successful, software companies must\ninnovate new types of software that respect copyright. One may argue that the overhead\nof applying for Digital Balance Certificates will hinder the growth of this business.\nHowever, the introduction of Digital Balance Certificates also creates a new business\n\n23 See Dan L. Burk and Julie E. Cohen, Fair Use Infrastructure for Right Management Systems, Harvard\nJournal of Law & Technology, Harvard Law School, fall 2001.\n\nmodel for software development, despite the fact that the application process certainly\ntakes time and effort from the developers' part. A software company can choose to work\nfor content providers and develop software that complies with content providers'\nspecifications, but the introduction of DB Certificates opens room for them to innovate\nnew applications that were never conceived before. Video tape recorder is a\ncommonplace nowadays but it was a stunning invention at the time it was first\nintroduced. Moreover, the issuing of preliminary DB Certificates to software developers\nwho have only submitted their software function description and technical specifications\nspeeds up the application process in an attempt to allow software developers to release\ntheir products to the market on time. In addition, educational institutes can also be\nanother driving force behind the development of the next generation of software that\nrespects copyright.\n\nIV.4 Technology Is Not Yet Ready\n\nThe proposed solution also makes the assumption that a certain computing\nenvironment, as described in Part III.3, will be in place to support the Digital Balance\nCertificates. If the technology for building such a computing environment does not\nemerge, the proposed system will not be able to be put into practice. However, if such\ntechnology does not emerge, there will be no digital rights management system and the\nproblem of content providers having too much control over their copyrighted work will\nno longer exist as well.\n\nRegarding the technology of issuing digital certificates, there is also concern that\nit may be subject to malicious attacks. Most security errors are due to implementation and\nmanagement errors.24 The Copyright Office may have its private key compromised\nbecause their employees do not follow closely the security procedure; there is no clear\nsecurity procedure in place and they do not have enough resources and expertise to\nmaintain the proposed electronic system. The employees within the Copyright Office\nmay also feel uncomfortable about using a new technology and may make mistakes due\n\n24 See Ross Anderson, Why Cryptosystems Fail, University Computer Laboratory, Cambridge, Britain,\n\nto a lack of understanding of the technology. As a result, the Copyright Office is advised\nto implement the proposed system to accept a limited amount of applications first so as to\ndevelop a clear and effective security procedure, before scaling up the system.\n\nV. Trends\n\nIn the future, it will be impossible for the public to conduct non-infringing uses of\ncopyrighted digital content. This section explains this trend by analyzing how the\ndecentralized file-sharing system on the Internet, the new technology of digital rights\nmanagement system and the Digital Millennium Copyright Act (DMCA) of 1998 lead to\nthis result.\n\nV.1 Overview\n\nThe combination of the digital technology and the widespread use of\ndecentralized file-sharing system over the Internet enable the public to not only duplicate\ncopyrighted digital work at practically no cost, but also distribute them over the Internet\neasily and quickly. Hence, it is hard for content providers to enforce their exclusive rights\non their copyrighted work. They thus demand more protection of their content before\nthey are willing to deliver it to their consumers. This demand of higher security on the\nInternet motivates software and hardware companies to develop digital rights\nmanagement system. In 1998, Congress also passes DMCA, which criminalizes\ncircumvention of technical means that control access to copyrighted work. As a result,\ncontent providers in the near future are likely to have the technological means as well as\nthe legal support to determine all possible uses of their copyrighted work and eliminate\nany chances for the public to perform non-infringing uses with their work.\n\nV.2 Decentralized File-sharing System and Digital Millennium Copyright Act\n\nU.S. Court of Appeal for the Ninth Circuit, in the A&M Records, Inc. v. Napster,\nInc. case ruled that Napster may be liable for contributory and vicarious copyright\ninfringement. Napster used to be a free file-sharing service provider that allowed its users\nto swap files over the Internet. It is now in the process of changing its free service to a\n\nsubscription-base service.25 This seems to be a manifestation of how the law has helped\nthe content providers to enforce their exclusive right on their digital content. However, I\nargue that the content providers will still resort to technological means to guarantee the\nenforcement of their exclusive rights because of the introduction of decentralized file-\nsharing system, as compared to Napster's centralized one. Gnutella and Freenet are two\nexamples of decentralized file-sharing system and while they allow users to swap files,\nyet they also have strong arguments against being charged for indirect copyright\ninfringement.\n\nGnutella is a piece of open-source software that users can download free of\ncharge from the Web. Gnutella forms a network, which overlays on top of the Internet\nand there is no central entity that owns the Gnutella network. When users swap files with\nother users, they do it without passing through any central entity. Gnutella's architecture\nis different from Napster's where a Napster user swaps a file with another user through a\ncentral server owned by Napster. As a result, although this Gnutella network may assist\ndirect copyright infringement, content providers have no entities to sue for either\ncontributory or vicarious infringement. The content providers can choose to go after the\ndirect infringers - consumers, but that will be a public relations nightmare.\n\nFreenet is also a piece of open-source software that users can download free of\ncharge from the Web. It forms a distributed information storage and retrieval system,\nwhich makes enforcing copyright law impossible if some users obtain a piece of\ncopyrighted work illegally and store it in the system. First, Freenet is designed to provide\na high level of anonymity for producers and consumers of the stored information. It does\nso by restricting the knowledge of one user or a node in the system to its immediate\nneighbor.26 Therefore, it is extremely hard for the content providers to find out who may\nbe the direct and indirect infringers. Second, Freenet seals all the information it stores.27\n\n25 See John Borland, Napster reaches settlement with publishers, CNET News.com, September 24, 2001 at\nhttp://news.com.com/2100-1023-273394.html?legacy=cnet\n26 See Ian Clarke, Freenet: A Distributed Anonymous Information Storage and Retrieval System, December\n2000 at http://freenetproject.org/cgi-bin/twiki/view/Main/ICSI\n27 See Ian Clarke, Freenet: A Distributed Anonymous Information Storage and Retrieval System, December\n2000 at http://freenetproject.org/cgi-bin/twiki/view/Main/ICSI\n\nBeing unable to determine the content they store, Freenet users have strong defenses\nagainst indirect copyright infringement.28 Third, Freenet propagates information it stores\nto some unknown nodes in the system every time someone requests that information29.\nHence, if a piece of copyrighted work is illegally shared in the system, content holders\nwill be unlikely to succeed in taking it out of the system and stop possible infringing\nuses. Forth, Freenet places all the functionalities of the system on the end users, so no\ncentral authority can shut down the system unless it occupies all the end nodes.30 As a\nresult, Freenet provides a technical infrastructure that prevents copyright holders to\neffectively enforce their exclusive rights.\n\nAll in all, decentralized file-sharing architecture such as Gnutella and Freenet\ncompels content providers to look for a technical solution to enforce their exclusive right,\nrather than solely relying on the law. Although the Copyright Law may not be\n\n28 For more discussion, see Damien A. Riehl, Electronic Commerce in the 21st Century: Article peer-to-\npeer distribution systems: Will Napster, Gnutella, and Freenet create a copyright nirvana or gehenna? ,\nWilliam Mitchell Law Review, 2001\n\"Being able to deny any knowledge of the contents of one's machine might provide Freenet users with at\nleast two defenses under [*1784] the Digital Millennium Copyright Act (\"DMCA\"). n142 In the DMCA,\nservice providers are provided a \"safe harbor\" under which they are not held responsible for transitory\ndigital network communications n143 and system caching. n144\nFreenet users would likely fall under the \"transitory digital network communications\" category since the\ntransmission was initiated by someone other than the user, the transmission was automated, the user does\nnot select the recipients, and the material is not modified during the transmission. n145 There may be a\nquestion as to whether section 512(a)(4), which requires that the information not be \"ordinarily accessible\nto anyone other than anticipated recipients,\" n146 is satisfied since others would subsequently be able to\naccess the material.\nAn equally strong argument is that the mirroring of the information on a user's machine would constitute\n\"system caching\" under section 512(b). Freenet users also fall under this category since the users\nthemselves are not accessing the information, but its location on their machines merely serves a caching\nfunction for other users. n147 One question is whether Freenet users adhere to Section 512(b)(2)(B)'s\nrequirement that a user \"complies with rules concerning the refreshing, reloading, or other updating of the\nmaterial when specified by the person making the material available online in accordance with a generally\naccepted industry standard data communications protocol.\" n148 This may, however, be mitigated since\nsuch a protocol does not yet exist. n149\nLike service providers, it is unlikely that Freenet users would be required to constantly police their systems\nfor infringing content. Even more than service providers, Freenet users have the additionally high burden of\ndecoding encryption to even determine whether the information on their system infringes upon a copyright.\nSince it is very difficult for users to determine the nature of the information stored on their systems, how\ncan they be held responsible for its content and potential infringement?\"\n29 See Ian Clarke, Freenet: A Distributed Anonymous Information Storage and Retrieval System, December\n2000 at http://freenetproject.org/cgi-bin/twiki/view/Main/ICSI\n30 See Ian Clarke, Freenet: A Distributed Anonymous Information Storage and Retrieval System, December\n2000 at http://freenetproject.org/cgi-bin/twiki/view/Main/ICSI\n\nenforceable, law can still assist the content providers to secure their exclusive right by\ntechnological means and the Digital Millennium Copyright Act (DMCA) is an example.\n\nCongress passed the DMCA in 1998, which mandates that no person shall\ncircumvent a technological measure that effectively controls access to a work protected\nunder 17 USC 1201. It provides content providers a legal support to criminalize entities\nwho circumvent their protection technology that control access of their copyrighted work\nas well as entities who manufacture and offer to the public a device that is solely\ndesigned for circumvention of such technology. Hence, DMCA backs up content\nproviders with legal power to employ a secure digital rights management system. Refer to\nPart III.2 for the details of a technical solution that is available for the content providers.\n\nIn summary, it is rational for content providers to look for a technological solution\nto protect their exclusive rights in light of the developments of digital technology and\ndecentralized file-sharing system. Moreover, thanks to both the technology industry and\nthe introduction of DMCA by Congress, they will have both the architecture as well as\nthe law to employ strong digital rights management systems that protect their exclusive\nrights in the near future.\n\nConclusion\n\nThe widespread use of decentralized file-sharing systems compels digital content\nproviders to demand a technical infrastructure that protects their exclusive rights. The\nintroduction of DMCA further creates a legal framework for such technology. Software\nand hardware companies are also in line with the content providers in this endeavor and\nMicrosoft Corporation has already obtained a U.S. patent on a digital rights management\noperating system that is able to identify software applications before loading them. This\noperating system therefore empowers the content providers to refuse delivering any\ncopyrighted digital contents to their subscribers until the absence of software that the\ncontent providers dislike. As a result, the content providers are empowered to practically\neliminate all possibilities for non-infringing uses of their digital work and effectively\nexpand their exclusive right beyond the boundary defined in the Copyright Law. The\n\nCopyright Office therefore should establish itself as a Certificate Authority who issues\nDigital Balance (DB) Certificates to software applications it deems compliant with the\nCopyright Law in order to re-open the door for the exercise of non-infringing uses of\ncopyrighted work. Although the content providers have no legal obligation to honor the\nDB Certificates, the untouched and competitive market of online subscription and the\nnorm of more liberal uses of digital content are likely to force them to do so. If the\ncontent providers instead of recognizing DB Certificates, choose other means to gain\ntheir market share, the introduction of DB Certificates still puts the government in a\nbetter position to create stricter regulation to limit the scope of copyright in the future.\nThe introduction of Digital Balance Certificates creates a middle ground for both the\ncopyright owners and the public to enjoy the benefits of the emerging digital era."
    },
    {
      "category": "Resource",
      "title": "employee.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/d8b0dfb1ae86257f7212ad4ce2799ad4_employee.pdf",
      "content": "MIT Privacy Protection of Job Applicant and Employee Information\n6.805\nth\nDecember 14 , 2005\nJacqueline Tio\n\"MIT, MIT, let me in...\" \"Not by the hair of my chinny chin chin...\"\n\nINTRODUCTION\nHe huffed, and he puffed, and he blew the house down. Such were the fabled actions\ntaken against the pig who did not build a house out of bricks. These actions may also be taken\nagainst those who ignore the full implications of the Internet and its effect on the privacy of job\napplicant and employee information. The Internet has not only created new modes of\ninformation access, but has also prompted rapid shifts toward using webbased systems and\nelectronic databases to collect, process, and store job applicant and employee information. If\nthese changes occur too carelessly, however, the unchecked dangers resulting from identity theft,\ninformation sharing, and fraud may create a gale force too mighty for these information systems\nto handle.\nThe technology and policies in place for job applicants and employees at MIT provide a\nsolid case study for determining the credibility of these concerns. Currently, almost all\ntransactions involving employee information are in some way connected to the Internet. Job\napplicant and employee information are funneled through webbased systems such as Webhire\nand SAPweb. Inhouse processing of information in the Human Resources Department (HR) and\nInformation Services and Technology (IS&T) also rely heavily on electronic communication. A\nreview of MIT systems and of the policies of MIT, Harvard, the European Union, the United\nStates, commercial job databases, and Hewlett Packard indicates that the current house\nsafeguarding job applicant and employee information at MIT needs renovation. A set of\nrecommendations based on this review proposes that privacy cannot be adequately protected\nunless significant measures are taken to change MIT policies. This includes explicitly protecting\njob applicant information, setting minimum standards for the electronic handling of job applicant\nand employee information, and increasing awareness among job applicants and employees of the\nfate and distribution of these types of information. Unless these recommendations are taken\nseriously, at present, MIT may have its bricks, but it still lacks the mortar needed to build a\nhouse that adequately safeguards both job applicant and employee information.\n\nTHE STAKES\nPrivacy Concerns of Job Applicant and Employee Information\nNumerous resume databases have made it easier than ever to search and apply for jobs.\nAt the same time, the privacy of information posted online has become more vulnerable to both\nfraudulent and criminal behavior. Applicant information gleaned from resumes can be\nparticularly invasive because of the types of information it provides such as home addresses,\nsocial security numbers, telephone numbers, and educational background. According to Pam\nDixon, the executive director of the World Privacy Forum, resumes of midcareer professionals\nare particularly attractive to identity thieves because of the depth of information they provide.\nSome criminals have even gone so far as to post fake job positions online to solicit more\npersonal information from their victims. Others have infiltrated job databases and amassed as\nmuch as 20,000 resumes before any red flags were raised. Although no case of job applicant\ninformation leakage has made headlines at MIT, the implications of these cases are chilling: a\nsupply and demand for job applicant information has cultured a new black market, and the\nInternet in all its glory has empowered criminals to enter it with little or no detection.\nCompounding privacy concerns of job applicant information are that of employee\ninformation. In this regard, MIT has faced its own crisis with the accidental leakage of\nconfidential employee information. In 2004, an MIT alumnus found the ID and social security\nnumbers of over 11,000 MIT employees through Google. This information had accidentally\nbeen posted in a public directory for six months, and five employees suspected that they had\nbeen the victims of identity theft. In January 2005, Harvard also faced an information leakage\nnightmare after realizing that confidential drug procurement and contact information of students\nand employees were accessible through a loophole in the PharmaCare website. It is unclear\nwhether this breach of protected information violated federal law, but concern arose over the\npotential violation of the Family Educational Rights and Privacy Act (FERPA), which grants\ncertain students security protection, and the Health Insurance Portability and Accountability Act\n1 \"Online Resumes Turn Risky.\" San Francisco Chronicle. 4 July 2005.\n2 Dixon, Pam. \"Resume Database Nightmare: Job Seeker Privacy at Risk.\" Privacy Rights Clearinghouse. 19\nFebruary 2003. Online. 11 November 2005. Available: http://www.privacyrights.org/ar/DixonJobPrivacyRpt.htm\n3 Lugovskaya, Tatyana. \"MIT Employees' Social Security Numbers Found in Public File.\" The Tech. 16 April 2004.\nOnline. Available: http://wwwtech.mit.edu/V124/N20/20ssn.20n.html\n\n(HIPAA), which protects medical information. Although only the latter would apply to\nemployee information, this incident suggests that the lack of protection of employee information\nis as dependent on general information practices as it is on employee information practices.\nThus far, however, MIT and Harvard should count themselves lucky. At least the\nproblems were accidental and investigative, not deliberate. Just this year in the course of only a\nfew weeks, confidential information of roughly 180,000 people from Berkeley, Northwestern,\nand California State University were purposely breached by hackers and thieves. In light of this\ntrend, the privacy of job applicant and employee information at MIT deserves a thorough review\nbefore an even bigger, meaner wolf decides to come and blow our house down.\nElectronic Information inside the House\nSince the mid1970s, the MIT Human Resources department has been using electronic\ndatabases to store employee information. Today, the reliance on technology has progressed to\nthe point where almost all campus employee information is handled electronically. Even\nresumes and documents submitted in paper form are scanned into electronic form by means of an\nelectronic imaging system. Because of the reliance on electronic databases to enter, maintain,\nand update employee information, the HR department has established a closely working\nrelationship with different departments and vendors to maintain employee information. This\nincludes working with other parts of the Institute, such as Information Services and Technology,\nand contracting out to external vendors to maintain databases.\nElectronically storing information through the Internet, however, increases vulnerability\nto theft by faceless thieves. Webbased systems, such as Webhire and SAPweb, now maintain\njob applicant and employee information. Employee transactions, for instance, depend on filling\nout HTML forms and sending it to a general mailing list. Inhouse processing of documents,\nmemorandums, and paperwork also rely extensively on the Internet through the use of electronic\nmail. A review of Webhire, SAPweb, and inhouse processing of information reveals that the\n4 Russel, J. H; Theodore, E.S. \"Drug Records, Confidential Data Vulnerable.\" The Harvard Crimson. 1 January\n2005. Online. Available: http://www.thecrimson.harvard.edu/printerfriendly.aspx?ref=505402\n5 Zeller, Jr., Tom. \"Some Colleges Falling Short in Security of Computers.\" New York Times. 4 April 2005.\n6 Correspondence with Claire Paulding, Senior Manager of Human Resources Information Services. 16 November\n2005.\n7 Paulding, Claire, Senior Manager of HRIS. Interview. 18 November 2005.\n\nthreats to privacy continue to exist in the use of these webbased systems and in the lack of\ndetailed policies regarding the distribution of these types of information.\nBRICKS WITH NO MORTAR\nWebhire\nAround 1993, the HR department began to use Restrac, an earlier version of Webhire, as\na means to process and track job applicant data electronically. In the summer of 2000, an\nApplicant Tracking Team was assigned to review this applicant tracking system for future\nadoption on a larger scale. Although acknowledging, but not going into further detail, that\ndisadvantages of using Webhire included its lack of security, the team decided that these\ndisadvantages were outweighed by the needs of hiring managers who were receiving insufficient\nsupport in the recruitment process. Ultimately, the team endorsed Webhire but flagged several\npolicy issues for consideration such as the definition of an actual job applicant, the use of\ninformation from job applicant pools, and the lifetime of a resume in a job applicant pool.\nIn January 2002, the Restrac applicant tracking system was formally upgraded to\nWebhire, accessible online through Staffing Services on the HR website.\nThrough Webhire,\nresumes and job applicant data are now collected and stored offcampus. Information from this\ndatabase is made available to the HR department, which houses its own recruiting office trained\nto work with the Webhire system. In transferring data, moreover, Webhire uses Secure Sockets\nLayer (SSL) software to encrypt transactions between their database and an end user's web\nbrowser.\nThe upgrade to Webhire was characterized as an advantageous move that allowed\ninstantaneous access to resumes and applications, improved database searching capabilities, and\nimproved ability to track Equal Employment Opportunity and Affirmative Action Program\n8 Correspondence with Wendy Williams, Director of HR Staffing Services. 30 November 2005.\n9 Applicant Tracking Team Final Report. HR Department. July 2002. Online. Available:\nhttp://web.mit.edu/ist/delivery/hrpayroll/pdf/finalrpt_aptrack.pdf\n10 Williams, Wendy. Staffing Services, Report to the President 20022003. Online. Available:\nhttp://web.mit.edu/annualreports/pres03/\n11 \"Webhire Recruiter Architecture and Security.\" Webhire. 2 December 2005. Document acquired from Webhire\nRepresentative.\n\ninformation.\nThese advantages, however, should not obscure the threats to privacy that linger\nin its shadow. When a job applicant applies online, the information is either automatically sent\nby email to the hiring manager, automatically sent by email to the hiring manager after a pre\nscreening process, reviewed by Staffing Services, or reviewed by a Data Link Control (DLC) HR\nrepresentative who then sends it by email to a hiring manager. When the Webhire system\ntransfers information through email, it uses SSL encryption to protect the transmitted\ninformation.\nThe problem, however, may arise in the transfer of information within MIT once\nit is received from Webhire. Although some MIT employees may be protected from interception\nof their emails with SSL enabled secure outbound SMTP authentication, the use of SSL to\nencrypt sent messages is not required. The use of email to transfer data without SSL encryption,\ntherefore, occurs at the risk of having this information stolen by a clever thief or perhaps by an\neven cleverer computer virus.\nPrivacy is also threatened by the electronic storage of information. The application\nprocedures on the Staffing Services website state that \"the system [WebHire] allows us to store\nthe resumes we receive in a searchable database so you may be considered for any position\nwhere there might be a match between the requirements of the job and your qualifications.14\"\nThis pool of job applicant information grows bigger everyday. The HR department currently has\non hand four years of job applicant data, and each year the pool increases by roughly 32,000\nresumes. Although the HR department has considered archiving older data, there has been no\nmention of deleting it. By request, Staffing Services can delete a job applicant's information.\nHowever, few, if any, job applicants are aware that their information is still stored in MIT's\ndatabase.\nJob applicants, thus, are preemptively handicapped from protecting their privacy.\nAlthough MIT states that job applications are stored in a searchable database, they give job\napplicants no choice for opting out and give no warning to job applicants that their information is\nstored indefinitely.\nFinally, although the HR department works hard to ensure the confidentiality of job\napplicant information, when job applicant data is sent to a hiring manager, the confidentiality of\n12 Williams, op. cit. 8.\n13 Correspondence with Webhire Technical Support. 8 December 2005.\n14 Staffing Services. \"Job Search for External Candidates.\" Human Resources at MIT. Online. Internet. 21\nNovember 2005. Available: http://sh.webhire.com/Public/631/\n15 Williams, op. cit. 8.\n\nthat information is passed into the hands of the department of that hiring manager.\nHR has no\noversight mechanism to ensure the confidentiality of information past this point, and the\ncomputers in these departments are not held to any minimum security standard.\nSAPWeb and SAP R/3\nApart from the system used to handle job applicant information, a separate system exists\nto handle employee information. In 2001, MIT Human Resources began to use the SAPweb\nSelfService system that allowed employees to select their benefit options. Over the next few\nyears, SAPweb SelfService grew into a system that is now used by employees and by Data Link\nControl (DLC) administrators to maintain employee information. SAPweb operates as the front\nend web interface of the SAP R/3 system, where employee information is actually stored.\nSAP\nR/3 is MIT's financial system of record that was adopted in 1996. This system houses an\nenormous amount of information and is maintained by IS&T.\nThe flow of employee information through SAPweb is protected by MIT personal\ncertificates. No employee information is sent through email. Instead, a Hypertest Transfer\nProtocol over Secure Socket Later (HTTP over SSL) is used in communicating between users'\nweb browsers and SAPweb. Moreover, all communications between the SAP webserver, the\nSAP Internet Transaction Server, and SAP R/3 are protected by a network that uses MIT\nKerberos credentials. All transactions are also recorded by a log that tracks any changes made to\nemployee information. Information updates and changes within SAPweb, therefore, are\nrelatively secure and can be tracked.\nAccess to SAP R/3 through SAPweb is usually given to all administrative officers and\npersonal administrators. It is also granted through departmental authorizations that are\ndistributed separately for education data, emergency contact information, ethnic and military\ninformation, and telephone directory information. The employee information available to any\ndepartment, however, is limited to employees of that department. To track this hierarchy of\ninformation access, a separate database is used to monitor and to control access to employee\n16 Ibid.\n17 Correspondence with Diana Hughes. IS&T Communications Administrator. 1 December 2005.\n18 \"Implementation History.\" SAP for MIT. Online. 1 December 2005. Available:\nhttp://web.mit.edu/sapr3/history.html\n\ninformation.\nAlthough information stored in SAP R/3 can be distributed outside of HR and\nIS&T departments, no oversight or standard guidelines currently exist to manage the handling of\ninformation once it is retrieved from SAP.\nFinally, similar to Webhire, SAP R/3 has never deleted any employee information.\nCurrently, MIT has approximately 10,000 employees, all who have at least home or work\naddresses stored in SAP R/3.\nAlthough this information is stored in SAP R/3 and not formally\ntransmitted through email as in Webhire, the information pool continues to grow, and the\npotential for accidentally leaking an increasing larger pool of information remains an ever\npresent danger for HR and IS&T.\nPervasive Privacy Concerns\nEven with the most secure Webhire and SAP systems, there is still a significant threat to\nprivacy that arises from normal, human behavior. According to Jeff Schiller, the network\nmanager for MIT, the problem is not \"mail in flight,\" but \"data at rest.21\" Policies that too\nseverely lockdown access to information trigger a splatter effect. When employees finally\nreceive requested confidential information, they often leave it on their desktops to avoid having\nto go through the tortuous process of acquiring that information again. The splatter effect occurs\nwhen they share this information by email with other colleagues who are looking for quick and\neasy access. Given that most employees use an SSL enabled secure outbound SMTP\nauthentication to protect their email, the security problems arise not with data transmission but\nwith data storage on desktop computers that are currently subject to no security requirements.\nInformation can be easily extracted from desktops that lack the necessary software and\nencryption packages to protect stored confidential information from unauthorized access. At\npresent, no policy exists to require the use of such a package, but considerations for creating a\ndesktop encryption package are on the table.\nAnother pervasive concern in the handling of job applicant and employee information is\nthe lack of training, education, and understanding of technology that characterize some\nemployees who routinely use and transfer confidential information. Indeed, some employees\n19 Hughes, op. cit.\n20 Ibid.\n21 Schiller, Jeff. Interview, MIT Network Manager. 1 December 2005.\n\nmay unknowingly transfer confidential data through email on a routine basis. In one instance,\nan employee sent a DAT file attachment to another employee without realizing that in addition to\nthe three fields of information that were being used for the task at hand, roughly 100 MB of\nadditional personal information was also contained in that file. Viruses have also been found to\nbe capable of extracting random files, some of which have been confidential, and transferring\nthem to others through email.\nAlthough the destination of confidential information may seem\nsecure, the carelessness in sending hidden confidential information imposes an unnecessary risk\non employee privacy and an unnecessary liability risk on MIT.\nThe carelessness of using confidential information also raises another issue: the\nunnecessary use of certain confidential information for identification purposes. Social security\nnumbers, for instance, do not need to be used if there is no statutory information. Yet before the\n2004 incident at MIT, they had been used internally within the HR department in some employee\nidentification practices that did not require the use of social security numbers.\nSince the 2004\nincident, the HR department has begun to use MIT ID numbers in lieu of social security numbers\nto identify employees.\nAlthough the unnecessary use of confidential information has been\nmitigated, in the absence of a formal institutewide policy encouraging this practice, the use of\nconfidential information by other departments who receive information from the HR department\nremains to be a blackbox.\nMIT POLICIES ON INFORMATION AND PROTECTION OF PRIVACY\nMany of the problems that arise in the handling of job applicant and employee\ninformation can be alleviated through changes in MIT policy. Since the 2004 incident, there\nhave been no official policy changes to MIT Policies and Procedures or the HR Personnel\nManual with regard to the handling of confidential information.\n22 Ibid.\n23 Ibid.\n24 Paulding, op. cit. 7.\n\nPolicies Concerning Job Applicant Information\nThe beginning of MIT Policy on Privacy of Information (Section 11.2 of MIT Policies\nand Procedures) states:\n\"Recognizing that specific items of information about current (as well as former)\nindividual students, faculty, and staff must be maintained for educational, research, and other\ninstitutional purposes, it is MIT policy that such information be collected, maintained, and used\nby the Institute only for appropriate, necessary, and clearly defined purposes, and that such\ninformation be controlled and safeguarded in order to ensure the protection of personal privacy\nto the extent permitted by law. 25\"\nThis statement specifically addresses student, faculty, and staff, but makes no mention of\na job applicant. This, therefore, has implications in other parts of MIT policy that use this\ndefinition. For instance, MIT Policy on the Use of Information Technology (Section 13.2.2)\nstates:\n\"Individuals who manage or use the information and computing resources required by the\nInstitute to carry out its mission must protect them from unauthorized modification, disclosure,\nand destruction... Protection shall be commensurate with the risk of exposure and with the value\nof the information and of the computing resources.\"\nAccording to this policy, individuals managing or using information are required to\nprotect that information, yet the level of protection is measured by the risk of exposure and value\nof the information. Since the value of job applicant information is not explicitly stated, this at\nmost implies minimal levels of protection for job applicant data, if any. Additionally, in light of\nthe increasing number of job applications processed through the web, the federal government,\nwhich requires tracking race, national origin, and gender for all job applicants, has already issued\nnew guidelines defining a job applicant.\nMIT actually uses job applicant data to meet these\n25 MIT Policy and Procedures. 1997. Online. 15 November 2005. Available: http://web.mit.edu/policies/index.html\n26 Pitney Hardin LLP. \"EEOC Guidelines Require Tracking Some Internet Applicants.\" New Jersey Employment\nLaw Letter. April 2004. Online. Lexisnexis.\n\nrequirements, but despite cooperating with the federal government's efforts to adapt to the\neffects of webbased job databases, it has taken no moves toward protecting the privacy of such\ninformation through policy.\nPolicies Concerning Employee Information\nInformally, MIT policies concerning employee information within the HR department\nhave changed since the information leak in 2004. Instead of using social security numbers, MIT\nID numbers are now used to identify employees.\nFormal policies, however, have not changed.\nThis includes MIT Policies and Procedures (Sections 11.1, 11.2, 13.2, 13.3, 13.4) and the Human\nResources Personnel Manual.\nAlthough a listing of protected employee information is not explicitly given, MIT Policy\non Privacy of Information (Section 11.2) does give a listing of unprotected, standard personnel\ninformation, such as MIT employment, job title, department, and telephone number. This\nimplies that information not on this list is considered protected and cannot be released without\nindividual consent or a court order and/or legal process. This definition of protected information\nis taken seriously by those in the HR department who consider information not listed to be\nprotected.\nThis, however, does not guarantee that a uniform definition of confidential\ninformation has been agreed upon throughout the department or even the institute.\nIn addition, the flavor of the words MIT uses in advising people to handle confidential\ninformation is passive rather than active. For example, MIT Policy on Privacy of Information\n(Section 11.2) states:\n\"Persons with responsibility for records containing personal information should exercise\ncare to ensure accuracy and completeness. Safeguards should be provided to protect personal\ninformation against accidental or intentional misuse or improper disclosure within or outside\nMIT.\"\n27 Paulding, op. cit. 7.\n28 Paulding, op. cit. 7.\n\nThis section advises people handling confidential information to use safeguards to protect\nagainst accidental or intentional misuse of personal information.\nThe operative word, however,\nis should rather than must, and the overall policy does not mandate that necessary security\nmeasures be taken in handling confidential information. To be fair, the word must does surface\nin MIT Policy on the Use of Information Technology (Section 13.2), which states:\n\"The privacy of individuals must be protected, regardless of the form or the location in\nwhich the information about them is stored, including computer media. Access to personal\ninformation must be limited to authorized users for approved purposes. Such information must be\nsafeguarded from unauthorized access. 30\"\nAlthough stronger language is used in mandating the existence of safeguards to protect\npersonal information, the definition of a safeguard is left openended. The level and types of\nsafeguards are not specified and, therefore, may vary from department to department.\nThe HR Personnel Manual also describes using and collecting employee information. It\nspecifically outlines the duties of the HR Department to maintain employee records and outlines\nthe information that is kept within each employee record, the people that can access these records,\nand how changes in these records are to be made.\nThe manual, however, provides no\nadditional guidance on the handling or storing of such information once it is in the hands of an\nauthorized user. Similar to the policy on the use of information technology, the electronic means\nby which confidential information is handled is left to the discretion of each individual accessing\nthat information.\nHARVARD POLICIES ON INFORMATION AND PROTECTION OF PRIVACY\nTo provide a basis of comparison, Harvard's policies concerning the protection of job\napplicant and employee information was also evaluated. A brief overview of the architecture of\nits job applicant and employee information systems is provided in the Appendix.\n29 MIT Policies and Procedures, op. cit.\n30 Ibid.\n31 \"HR Personnel Policy Manual.\" MIT Human Resources. Online. 2005. http://web.mit.edu/hr/policy/11.html\n\nPolicies on Job Applicant Information\nHarvard policy on information security and privacy of confidential data addresses the\nsame issues outlined in MIT Policies and Procedures on the protection of privacy and use of\ninformation technology.\nSimilar to MIT, it does not explicitly mention the protection of job\napplicant information. Job applicant information submitted to Harvard is collected through a\nwebbased system known as HIRES. According to the job application website, resumes of\noutside job applicants are also eventually merged into a larger searchable database. The privacy\nof job applicant information, therefore, is a valid consideration. Yet Harvard policy only stresses\nthe importance of protecting \"confidential data,\" which is defined as \"personally identifiable\ninformation about Harvard people (from core Harvard databases)... \" Job applicants,\npresumably not yet Harvard people, are not included in this definition, and privacy policies\nafford little, if any protection to them.\nPolicies Concerning Employee Information\nEmployee information, in contrast to job applicant information, does fall into the\ndefinition of confidential data which is protected by Harvard policy. Moreover, its policy on\ninformation security and privacy of confidential data is much more specific than that of MIT.\nHarvard requires confidential data to be encrypted when transferred. It requires employees who\naccess confidential data to sign a confidentiality agreement. It requires all data network\ncomputers to be uptodate on security patches and to follow \"normal good computer security\npractices.\" It also requires outside vendors who handle its confidential data to sign a contract\nagreeing to protect confidential data before doing work for the university.\nSimilar to MIT, however, several other key policies remain passive rather than active.\nFor instance, the Harvard policy on Information Security and Privacy states:\n32 \"Harvard University Information Security and Privacy.\" Online. 2005. Available:\nhttp://www.security.harvard.edu/tech_security/\n33 Ibid.\n34 Ibid.\n\n\"Confidential Data stored on an individual's personal computer at Harvard should be\nencrypted. Confidential Data stored on a laptop computer, or any personal computer not located\nat Harvard must be encrypted.\"\nSimilarly, for target computers most vulnerable to security breaches, Harvard policy\nstates:\n\"Access to these computers should be limited to local console access or authenticated and\nencrypted networkbased access.\nThe use of smart cards for user authentication of system administrators is encouraged\nwhere computers contain particularly sensitive information or provide core university\nservices.35\"\nThe first policy differentiates between using the word should and must for encryption\npractices oncampus and offcampus. Curiously, for desktop storage of sensitive information on\ncampus, the policy takes the passive stance. The use of the words should and encourage in the\nlatter policy indicates that though Harvard may be keen on protecting information in flight, its\npolicy is still weak at the seams for information in storage. The real vulnerabilities, such as\ninformation stored on desktops that are subject to unauthorized access, are protected through\nguidelines rather than requirements. Yet in years past, email privacy violations reported to the\nDean of Harvard College primarily consisted of internal problems concerning information in\nstorage not external, technical problems concerning information in flight. These internal\nproblems involved behavioral issues of handling stored information, such as the sharing of\npasswords.\nDespite the apparent contradiction between policy and reality, however, at least\nHarvard has formally provided more specific warnings where MIT has not, such as warnings\nabout potential problems and security issues that need to be considered in handling confidential\ndata through computerbased technology.\nHarvard's Personnel Manual is also more detailed and extensive than MIT's Personnel\nManual in the handling of confidential information. Not only are different levels of confidential\n35 Ibid.\n36 Lewis, Harry R. Phone Interview by Jacqueline Tio. 6 December 2005.\n\ninformation and distribution described, but a detailed guideline of how this information should\nbe accessed by those who are authorized to access it is also provided under a heavy note of\ncaution. The manual also explicitly states an expectation of employees to use the \"current best\npractices\" in maintaining the security of their computer systems and lists ways to meet this\nguideline, such as using antivirus software, ensuring remote access network security, handling\njunk mail, and listening to various directives issued by the department or other parts of the\ninstitute. Curiously, access to this personnel manual is protected by Harvard PIN authentication\nwhereas MIT offers open access to its HR Personnel Manual.\nUNITED STATES POLICY IN RELATION TO EUROPE\nOutside of MIT or Harvard, a complex network of federal and state law requires\nemployee recordkeeping for employees under laws such as wage and hour law, equal\nopportunity employment law, and occupational safety and health law. The Occupational Safety\nand Health Act, for instance, mandates that employers keep employee medical records for thirty\nyears past the period of an employee's employment. Very little federal legislation, however,\nactually exists to protect the privacy of this employee information. Under U.S. law, employer\ncomputerized recordkeeping and electronically stored employee information are not treated any\ndifferently from paper recordkeeping. The only distinction with regard to electronic\ninformation is made in Section 2702 of the Electronic Communications Privacy Act which\n\"prohibits an entity providing electronic communication service to the public from divulging the\ncontents of a communication while in electronic storage or, for a provider of remote computing\nservices to the public, from divulging the contents of any communication carried on the service,\nsubject to express exceptions.\" This, however, does not address privacy issues for electronic\ndatabases that are not connected to electronic communications. Additionally, there is no specific\nreference to employee records. Only a handful of states, such as Massachusetts and California,\nhave taken steps toward directly protecting privacy through state laws or charters, but even these\nare generic.\nMassachusetts's law, for instance, states that \"...a person shall have a right against\nFinkin, Matthew W. \"Information Technology and Workers' Privacy.\" 23 Comp. Lab. L. & Pol'y l 471 (2002).\nLexisnexis.\n\nunreasonable, substantial or serious interference with his privacy.38\" The shape and form of\nprivacy remains unspecified and open to interpretation.\nOnly employee information related to disability or health information is currently\nprotected under U.S. law under the American Disabilities Act (ADA) and HIPAA. This stands\nin stark contrast to the stance taken by the European Union on the privacy of personally\nidentifiable information. In the mid1990s, the EU closely analyzed the implications of\ntechnology on privacy, a right that is viewed as fundamental. Through the EU Privacy Directive\nof 1995, EU member states comprehensively and proactively adopted measures to protect\nelectronic employee information, specifically described as being processed entirely or in part\nthrough automatic means. Through this directive, employees now have the rights to be informed\nabout information collecting methods, to access and correct their personal information, and in\nspecial circumstances to prohibit the collection of their information.\nIn addition, European personal data collection companies must post privacy policies, give\nreasons for data collection, allow customers to review and change data, allow customers to opt\nout of information collection, disclose with whom the data will be shared, protect the data with\nsecurity measures, and restrict information sharing to countries that have adopted similar\npolicies.\nThe list may seem long, but the reality has proven that such specifications can be\nfeasibly met regarding the use of personal information.\nLEGAL IMPLICATIONS FOR PRIVACY VIOLATIONS\nMIT Liability for Privacy Violations\nAlthough the U.S. does not have much legislation protecting job applicant or employee\ninformation, it does have laws regarding employer liability for crimes committed by its\nemployees. The progress made in computer technology has been accompanied by an increase in\ninternet crimes that have significant implications on employer liability for injuries from crimes\n38 General Law of Massachusetts. \"Chapter 214: Section 1B Right of Privacy.\" Online. 2005. Available:\nhttp://www.mass.gov/legis/laws/mgl/2141b.htm\n39 Lasprogata, G; King, N.J.; Pillay, S. \"Regulation of Electronic Employee Monitoring.\" 2004 Stan. Tech. L. Rev. 4\n(2004). Lexisnexis.\n40 Kohel, Matthew. \"Australian Government's Substandard to Attempt to Allay Privacy concerns and Regulate\nInternet Privacy in the Private Sector.\" 27 Brooklyn J. Int'l L. 703 (2002). Lexisnexis.\n\nand wrongful acts committed by its employees.\nThis implies that for any breach of privacy\nunder laws such as the ADA, HIPAA, and FERPA, MIT may be held liable in the court of law.\nAs early as 1909, the United States Supreme Court ruled that a company can be held\ncriminally liable for the acts of their employees that occur under the authority conferred upon the\nemployee by the company and that involve knowledge and purpose that are attributable to the\ncorporation. In this case, the U.S. Supreme Court ruled that the Hudson River Railroad\nCompany was held liable for the acts of its traffic manager, who had unlawfully regulated\ncommerce by giving rebates to customers in order to encourage the use of Hudson River\ntransportation services. Despite the railroad company's arguments that stockholders were being\nunfairly punished without due process, the Supreme Court charged that imposing such liability\non the company was necessary to prevent the granting of a blanket immunity from punishment to\nany and all businesses involved in interstate commerce.\nSince this ruling, the standards used by courts to measure an employer's liability have\nincluded respondeat superior and negligent retention. According to respondeat superior, the\nemployer is held liable for any wrongful action of its employee if the act occurred within the\n\"scope of the employment\"or if it was foreseeable by the employer. The \"scope of employment\"\nhas been defined as conduct that is the kind an employee is employed to perform, that occurs\nwithin authorized time and space limits, that occurs in some part to serve the employer, and, in\ncases where force was used, could have been foreseeable by the employer. According to\nnegligent retention, an employer who puts an \"unfit person in an employment situation involving\nan unreasonable risk of harm to others\" is held responsible for the actions of that employee.\nRelevant court cases have continued to expand employer liability in a number of instances,\nranging from securities fraud to sexrelated crimes to wrongful deaths. If a company provides\nemployees with the electronic means to commit egregious crimes, clear policies must be iterated\nto minimize the risks of criminal or wrongful act liability that accompany computer\ntechnology.\nFor MIT, this implies that empowering employees with the means to invade or\nexpose thousands of people's privacy places a responsibility on MIT to protect this information\n41 Davis, Erin M. \"The Doctrine of Respondeat Superior: An Application to Employers' Liability for the Computer\nor Internet Crimes Committed by Their Employees.\" 12 Alb. L.J. Sci. & Tech. 683 (2002). Lexisnexis.\n42 New York Cent. & H. R.R. Co. v. U.S., 212 U.S. 481 (1909)\n43 Davis, op. cit.\n\nif not out of concern for its job applicants and employees, then out of concern for a potentially\nexpensive liability suit in the court of law.\nExpectation of Privacy for Email\nThe legal opinion on the privacy of employees' email messages may also affect the\nprivacy of job applicant and employee information that are transferred through email. Several\ncourt decisions have repeatedly ruled that employees have no reasonable expectation of privacy\nto contents in their email. In one case, two employees were fired after investigation into a\nsexual harassment complaint that uncovered inappropriate email messages. The employees\ncharged that the investigation of their email messages by their employer had wrongfully invaded\ntheir privacy and violated a Massachusetts statute that prohibited interception of wired\ncommunication. The U.S. District Court for Massachusetts, however, ruled that the two\nemployees lacked any reasonable expectation of privacy. The District Court pointed out that\nreading email after it had been transmitted did not constitute interception of wired\ncommunication. The court, moreover, cited several cases that negated a reasonable expectation\nof privacy for email based on the use and transmission of email information.\nIn 1999, for\ninstance, an employee sued Microsoft for invading the privacy of his information and email\nmessages stored in personal folders on his computer. In this case, the Court of Appeals for the\nFifth District of Texas decided that email messages stored in \"personal folders\" but \"were first\ntransmitted over the network and were at some point accessible by a third party\" lacked any\nreasonable expectation of privacy, even if those files were password protected by the\nemployee.\nThese legal precedents imply that there exists the potential for confidential data to be\naccessed by users who are authorized to monitor email messages but not authorized to access\nconfidential data, such as employee information. The implications of allowing unauthorized\nusers to access confidential data have already become hot buttons of debate at Harvard.\nAlthough Harvard's Personnel Manual mentions that information should only be accessible by\nthose who have authority to do so, the implied hierarchical chain of authority is left open\n44 Garrity v. John Hancock, Civil Action no. 0012143, 2002 U.S. Dist. LEXIS 8343, (D. Ma. May 7, 2002)\n45 McLaren v. Microsoft, 1999 Tex. App. LEXIS 4103, 1999 WL 339015\n\nended.\nOne question that may surface is whether those authorized to monitor employee email\nare also authorized to view confidential information. If not, unnecessary desktop accumulation\nof such information may needlessly expose sensitive data to those who are not authorized to\nview or access confidential information. In these instances, the accidental peeping Tom may be\ntrusted to ignore the confidential data or to notify his supervisors. The fact remains, however,\nthat these actions would be taken after the opening of a potential Pandora's Box of confidential\ninformation, not before.\nCOMMERCIAL JOB DATABASE POLICIES: MONSTER, CAREERBUILDER.COM\nThe legal implications involved in privacy violations are also very important issues for\nmany commercial job databases. Both Monster and Careerbuilder.com, two major commercial\njob databases, have already been victims of fraudulent attempts to access their pool of personal\ninformation.\nThe privacy statements of these websites are, therefore, very thorough and have\nadopted many of the guidelines put forth by the EU Directive. Monster, for instance, informs job\napplicants of how applicant information is used, distributed, and collected. Information is not\ndistributed to third parties unless consent is given or the government makes a request. In\naddition, job applicants are told that their information is kept indefinitely, that they can at any\ntime delete Internetaccessible information, and that they have the power to opt out of having\ntheir information placed in a searchable database.\nCareerbuilder.com generally delivers the\nsame privacy statement as Monster, but it does not inform job applicants of how long their\ninformation is stored. Careerbuilder.com, moreover, uniquely differentiates itself from Monster\nby specifically giving suggestions on how to identify email and online fraud pertaining to their\nwebsite and by allowing job applicants to post information anonymously.\n46 Lewis, op. cit.\n47 Kirby, Carrie. \"Online Resumes Turn Risky.\" San Francisco Chronicle Times. 4 July 2005.\n48 \"MonsterTRAK Privacy Statement.\" Online. 2003. Available:\nhttp://www.monstertrak.monster.com/intro/privacy.html\n49 \"Protect Your Privacy and Safety.\" Careerbuilder.com. Online. 2005. Available:\nhttp://www.careerbuilder.com/JobSeeker/Info/Privacy.aspx\n\nHEWLETT PACKARD PRIVACY POLICIES\nProtecting privacy has also been large concern for U.S. companies that frequently traffic\nthe information superhighway, especially those with global connections. Hewlett Packard, in\nparticular, has taken a leading role in creating privacy policies that comprehensively protect the\nprivacy of customer, employee, and job applicant information. In fact, in January 2001, HP\nbecame the first hightech company in the United States to become certified by the U.S.\nDepartment of Commerce under the Safe Harbor framework. The Safe Harbor framework was\ncreated between the U.S. Department of Commerce and the European Commission to facilitate\nU.S. business operations abroad without violating the EU Privacy Directive concerning data\nprotection. Safe Harbor certification essentially ensures the EU that a certified company\nprovides \"adequate\" privacy protection for personal data.\nThe privacy policies in place at HP are extensive. The overarching HP policy is the\nGlobal Master Privacy Policy, which addresses the use and storage of customer and employee\ninformation. In addition to this policy is the Global Employee Data Privacy Policy which HP\nexplicitly states addresses employee and job applicant information. Although the details of this\npolicy are not publicly available, HP's general online privacy statement informs individuals of\nthe use of their information, how they can change their information, and the security of their\ninformation. The seriousness HP takes to protect the privacy of its customers and employees,\nmoreover, is substantiated by the existence of an HP Chief Privacy Office that handles the\nprivacy issues of both customers and employees. The different mechanisms used by this office\nto ensure compliance with privacy policies are unique to HP in comparison to MIT and Harvard.\nAll employees are required to have privacy training, and those handling confidential information\nmust go through additional training. To increase awareness and compliance with these issues,\nPrivacy Impact Assessments are used by employees in each project or sales and marketing\nprogram to make sure privacy policies are being upheld. Information Technology Application\nDevelopment Questionnaires are used to evaluate whether or not privacy policies for Information\nTechnology systems handling employee information are upheld. Moreover, HP operates an\n50 Statement of Barbara Lawler, Chief Privacy Officer of Hewlett Packard. United States. Cong. Senate. Commerce,\nScience, and Transportation Committee. Federal Privacy Legislation. 107th Cong., 2nd sess. Washington: GPA, 2002.\nOnline. 8 December 2005. http://commerce.senate.gov/hearings/042502lawler.pdf\n51 \"Safe Harbor.\" U.S. Department of Commerce. Online. 11 December 2005. http://www.export.gov/safeharbor/\n\ninternal privacy auditing system to review and to evaluate compliance with privacy policies.\nDespite there being little indication of the effectiveness of such measures, these privacy\nprotection mechanisms distinctly reflect a more proactive approach to protecting privacy by HP\nthan by MIT or Harvard.\nRECOMMENDATIONS FOR HANDLING OF JOB APPLICANT AND EMPLOYEE INFORMATION\nIn light of the privacy policies of Harvard, the European Union, the United States,\ncommercial job databases, and Hewlett Packard, several steps can be taken to shore up the\nprivacy holes that currently exist in the collecting and managing of job applicant and employee\ninformation at MIT.\nRecommendations for Handling of Job Applicant Information\nJob applicant information is unique in that no provisions for even protecting the privacy of\nthis type of information exist at MIT, Harvard, or in federal or state law. The dangers associated\nwith the leakage of this information, however, have already made headlines and should not deter\nMIT from preventing foreseeable information leakage. In policies specific to job applicant\ninformation collected through Webhire, MIT should post a privacy statement on the Staffing\nServices webpage that:\n- Informs job applicants of the fate of their personal information and resumes\n- Informs job applicants of the security measures taken to protect their information\n- Allows job applicants to opt out of being put into a larger searchable database\n- Allows job applicants to delete their personal information\nIn MIT Policies and Procedures, MIT should:\n52 \"HP Approach.\" Hewlett Packard. 2005. Online. 8 December 2005.\nhttp://www.hp.com/hpinfo/globalcitizenship/gcreport/privacy/privapproach.html\n\n- Include job applicant information under the definition of protected personal information\nin MIT Policy on Privacy of Information (Section 11.2)\nRecommendations for Handling of Employee Information\nCompared to job applicant information, employee information is explicitly mentioned in\nseveral MIT policies. These policies, however, should be updated to accommodate the\nimplications of using modern computerbased technology in transferring and storing employee\ninformation. With regard to employee information handled through SAPweb, MIT should:\n- Provide a privacy statement on SAPweb detailing how information is used and protected\nWith regard to employee information described in the HR Personnel Manual, MIT should\nincorporate new statements and changes that:\n- Increase awareness among employees of the vulnerability of data sharing through\nelectronic communication\n- Increase awareness among employees of the vulnerability of data storage on desktops\n- Clarify what is considered confidential information, including job applicant and\nemployee information\n- Require employees working with confidential information to either sign a\nconfidentiality awareness statement or undergo privacy training\n- Educate employees by providing examples and descriptions of how information can be\naccidentally leaked, e.g. viruses, DAT files, passwords, etc.\n- Restrict the use of confidential information from being used unnecessarily\nRecommendations for Handling of Both Job Applicant and Employee Information\nFinally, for the handling of both job applicant and employee information, in MIT Policies\nand Procedures, MIT should proactively:\n\n- Require using SSL enabled secure outbound SMTP authentication on all computers\nhandling confidential information, including job applicant or employee information\n- Require encryption of confidential information stored on computers in HR, IS&T, and all\nother departments to which confidential information is distributed and stored\n- Require privacy training for employees and more indepth privacy training for those\nworking with confidential information, including job applicant and employee information\nCONCLUSIONS\nBy implementing policy changes that primarily deal with redefining protected\ninformation, ensuring the security of the transmission and storage of protected information, and\nincreasing the awareness of these issues, MIT will be in a better position to avoid information\nleakages that have been the nemesis of many other universities and information systems.\nAlthough this Institute may be perceived as a paragon of electronic infallibility, the construction\nof electronic information systems must give weight to the increased responsibility of protecting\ninformation channels that have or will soon be opened. Instead of taking a reactionary approach\nto the protection of job applicant and employee information, MIT should proactively step\nforward and avoid looming dangers by making small, incremental changes to the house that has\nbeen chosen to accommodate a continuously growing pool of job applicant and employee\ninformation.\n\nAPPENDIX\nHARVARD JOB APPLICANT AND EMPLOYEE INFORMATION DATABASES\nHIRES, the Job Applicant Tracking System\nCompared to MIT, the resources in place to handle job applicant and employee\ninformation at Harvard are quite decentralized. Although an Office of Human Resources exists\nfor the entire university, most of the human resources work is done in each of fourteen different\nhuman resources offices that exist for a particular department and/or employment sector.\nIn\n1998, the Office of Human Resources was considering the adoption of an applicant tracking\nsystem that would connect many of these human resource offices and make collecting job\napplicant data more efficient.\nBy September 2003, Harvard followed through with this idea\nand began to only accept job applications and resumes through HIRES, a webbased applicant\ntracking system that handled the bulk of job applicant submissions.\nBased on the information available from the job application website, Harvard does not\ngive job applicants the option of deleting their information or opting out of having their\ninformation placed in a larger searchable database. According to the website, \"if you have not\nbeen contacted for the specific position to which you applied, for a period of time your resume\nalso becomes available to recruiters seeking to fill other University positions.56\" Although the\nwebsite implies that job applicant information is available to recruiters for a period of time, no\nindication is given to job applicants of how long the information is stored in the HIRES system.\nHARVie and PeopleSoft\nThe portal used to access databases housing employee information at Harvard is an\nintranet employee system known as HARVie. This system was launched in early 2004 and\n53 \"Hiring @ Harvard.\" 2005. Online. 11 December 2005.\nhttp://www.employment.harvard.edu/careers/hiring/localhr.shtml\n54 \"Highlights of EEO Practices at Harvard.\" Harvard University Gazette. 16 April 1998. Online. 6 December 2005.\nhttp://www.news.harvard.edu/gazette/1998/04.16/HighlightsofEEO.html\n55 \"In Brief.\" Harvard University Gazette. 18 September 2003. Online. 6 December 2005.\nhttp://www.hno.harvard.edu/gazette/2003/09.18/06notes.html\n56 \"Hiring FAQs @ Harvard.\" 2005. Online. 6 December 2005.\nhttp://employment.harvard.edu/careers/hiring/faq.shtml\n\nprovides access to tools regarding employee benefits and services, the reporting of time and\nlabor, general announcements, and the PeopleSoft Human Resources Management System\n(HRMS).\nPeopleSoft is a webintegrated system that appears to be the Harvard equivalent of\nMIT's SAPweb system. PeopleSoft differs from SAPweb, however, in that the applicant\ntracking system HIRES feeds into the PeopleSoft system.58,59 In order to access HARVie and\nother proprietary information, including Harvard employee policies, Harvard Personal\nIdentification Number (PIN) authentication is required.\n57 \"HARVie set to Launch on Feb. 18.\" Harvard University Gazette. 12 February 2004. Online. 6 December 2005.\nhttp://www.news.harvard.edu/gazette/2004/02.12/11harvie.html\n58 \"Welcome to the Online Help for ESS.\" A Better Learning Environment, Harvard University. Online. 2005.\nhttp://able.harvard.edu/hress/\n59 \"Welcome to the Online Help for Hiring and Personnel Actions.\" A Bette Learning Environment, Harvard\nUniversity. Online. 2005. http://able.harvard.edu/hrhiring/\n\nACKNOWLEDGEMENTS\nThis research would not have been possible without the help and encouragement of several\npeople and departments to whom I would like to extend my warmest thanks:\nHal Abelson\nMike Fischer\nDanny Weitzner\nKeith Weinstein\nHarry Lewis\nMIT Human Resources\nMIT Information Services and Technology"
    },
    {
      "category": "Resource",
      "title": "facebook.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/14013ffdf1a7a3f892821a918fada9a0_facebook.pdf",
      "content": "Facebook: Threats to Privacy\nHarvey Jones, Jos e Hiram Soltren\nDecember 14, 2005\nAbstract\nEnd-users share a wide variety of information on Facebook, but a discussion of the privacy\nimplications of doing so has yet to emerge. We examined how Facebook affects privacy, and\nfound serious flaws in the system. Privacy on Facebook is undermined by three principal factors:\nusers disclose too much, Facebook does not take adequate steps to protect user privacy, and\nthird parties are actively seeking out end-user information using Facebook. We based our end-\nuser findings on a survey of MIT students and statistical analysis of Facebook data from MIT,\nHarvard, NYU, and the University of Oklahoma. We analyzed the Facebook system in terms of\nFair Information Practices as recommended by the Federal Trade Commission. In light of the\ninformation available and the system that protects it, we used a threat model to analyze specific\nprivacy risks. Specifically, university administrators are using Facebook for disciplinary purposes,\nfirms are using it for marketing purposes, and intruders are exploiting security holes. For each\nthreat, we analyze the efficacy of the current protection, and where solutions are inadequate,\nwe make recommendations on how to address the issue.\n\nContents\n1 Introduction\n2 Background\n2.1 Social Networking and Facebook . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2 Information that Facebook stores . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3 Previous Work\n4 Principles and Methods of Research\n4.1 Usage patterns of interest.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2 User surveys . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.3 Direct data collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.4 Obscuring personal data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.5 A brief technical description of Facebook from a user perspective . . . . . . . . . . . 10\n4.6 Statistical significance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n5 End-Users' Interaction with Facebook\n5.1 Major trends . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n5.2 Facebook is ubiquitous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n5.3 Users put time and effort into profiles . . . . . . . . . . . . . . . . . . . . . . . . . 15\n5.4 Students join Facebook before arriving on campus . . . . . . . . . . . . . . . . . . . 15\n5.5 A substantial proportion of students share identifiable information . . . . . . . . . . 16\n5.6 The most active users disclose the most . . . . . . . . . . . . . . . . . . . . . . . . 16\n5.7 Undergraduates share the most, and classes keep sharing more . . . . . . . . . . . . 18\n5.8 Differences among universities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n5.9 Even more students share commercially valuable information . . . . . . . . . . . . . 20\n5.10 Users are not guarded about who sees their information . . . . . . . . . . . . . . . . 20\n5.11 Users Are Not Fully Informed About Privacy . . . . . . . . . . . . . . . . . . . . . . 20\n5.12 As Facebook Expands, More Risks Are Presented . . . . . . . . . . . . . . . . . . . 21\n5.13 Women self-censor their data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n5.14 Men talk less about themselves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n5.15 General Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n6 Facebook and \"Fair Information Practices\"\n6.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n6.2 Notice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n6.3 Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n6.4 Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n6.5 Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n6.6 Redress . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n7 Threat Model\n7.1 Security Breach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n7.2 Commercial Datamining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n7.3 Database Reverse-Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n7.4 Password Interception . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n7.5 Incomplete Access Controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n7.6 University Surveillance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n7.7 Disclosure to Advertisers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n7.8 Lack of User Control of Information . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n7.9 Summary and Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n8 Conclusion\n8.1 Postscript: What the Facebook does right . . . . . . . . . . . . . . . . . . . . . . . 34\n8.2 Final Thoughts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n8.3 College Newspaper Articles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n9 Acknowledgements\n9.1 Interview subjects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nA Facebook Privacy Policy\nB Facebook Terms Of Service\nC Facebook \"Spider\" Code: Acquisition and Processing\nC.1 Data Downloading BASH Shell Script . . . . . . . . . . . . . . . . . . . . . . . . . 46\nC.2 Facebook Profile to Tab Separated Variable Python Script . . . . . . . . . . . . . . 46\nC.3 Data Analysis Scripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\nD Supplemental Data\nE Selected Survey Comments\nE.1 User Feedback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\nF Paper Survey\n\nIntroduction\nFacebook1 (www.facebook.com) is one of the foremost social networking websites, with over 8\nmillion users spanning 2,000 college campuses. [4] With this much detailed information arranged\nuniformly and aggregated into one place, there are bound to be risks to privacy. University ad\nministrators or police officers may search the site for evidence of students breaking their school's\nregulations. Users may submit their data without being aware that it may be shared with advertisers.\nThird parties may build a database of Facebook data to sell. Intruders may steal passwords, or entire\ndatabases, from Facebook. We undertook several steps to investigate these privacy risks. Our goal\nwas to first analyze the extent of disclosure of data, then to analyze the steps that the system took\nto protect that data. Finally, we conducted a \"threat model\" analysis to investigate ways in which\nthese factors could produce unwanted disclosure of private data. Our analysis found that Facebook\nwas firmly entrenched in college students' lives, but users had not restricted who had access to this\nportion of their life. We discovered questionable information practices with Facebook, and found\nthat third parties were actively seeking out information.\nTo analyze the extent of user disclosure, we constructed a spider that \"crawls\" and indexes\nFacebook, attempting to download every single profile at a given school. Using this tool, we\nindexed the entire Facebook accessible to a typical user at Massachusetts Institute of Technology\n(MIT), Harvard, New York University (NYU), and the University of Oklahoma. To supplement this\ndata, we surveyed the MIT student body to ascertain the level of use of certain Facebook features.\nOur study found that upwards of 80% of matriculating freshmen join Facebook before even arriving\nfor Orientation, and that these users share significant amounts of personal information. We also\nfound that Facebook's privacy measures are not utilized by the majority of college students. To\nanalyze the Facebook system we investigated the facets of the website, and of the terms of use\nand compared them against the current standards of \"Fair Information Practices\" as defined by\nthe Federal Trade Commission, as well as the standards set by competing sites. Although many\nFacebook features empower users to control their private information, there are still significant\nshortcomings. Finally, we took the perspective of a third party acting in a self-interested manner,\nlooking either for financial gain or for assistance in the enforcement of university policy. We surveyed\nnews articles on the consequences of Facebook information disclosure, and interviewed students that\nharvested data, as well as students who were punished for disclosing too much. Given the existing\nthreats to security, we constructed a threat model that attempted to address all possible categories\nof privacy failures. From a systems perspective, there are a number of changes that can be made,\nboth to give the user a reasonable perception of the level of privacy protection available, and to\nprotect against disclosure to intruders. For each threat, we make recommendations for Facebook, its\n1\"Facebook\", as opposed to \"the Facebook\", is how the site's literature refers to itself. We adopt that terminology\nthroughout the paper.\n\nusers, and college administrators. These include eliminating the consecutive profile IDs, using SSL\nfor login, extending \"My Privacy\" to cover photos, and educating end-users about privacy concerns.\nBackground\n2.1\nSocial Networking and Facebook\nUsers share a variety of information about themselves on their Facebook profiles, including photos,\ncontact information, and tastes in movies and books. They list their \"friends\", including friends at\nother schools. Users can also specify what courses they are taking and join a variety of \"groups\" of\npeople with similar interests (\"Red Sox Nation\", \"Northern California\"). The site is often used to\nobtain contact information, to match names to faces, and to browse for entertainment. [4]\nFacebook was founded in 2004 by Mark Zuckerburg, then a Harvard undergraduate. The site\nis unique among social networking sites in that it is focused around universities - \"Facebook\" is\nactually a collection of sites, each focused on one of 2,000 individual colleges. Users need an\n@college.edu email address to sign up for a particular college's account, and their privileges on the\nsite are largely limited to browsing the profiles of students of that college.\nOver the last two years, Facebook has become fixture at campuses nationwide, and Facebook\nevolved from a hobby to a full-time job for Zuckerburg and his friends. In May 2005, Facebook\nreceived $13 million dollars in venture funding. Facebook sells targeted advertising to users of its\nsite, and parters with firms such as Apple and JetBlue to assist in marketing their products to college\nstudents. [14]\n2.2\nInformation that Facebook stores\nFirst-party information All data fields on Facebook may be left blank, aside from name, e-mail\naddress, and user status (one of: Alumnus/Alumna, Faculty, Grad Student, Staff, Student, and\nSummer Student). A minimal Facebook profile will only tell a user's name, date of joining, school,\nstatus, and e-mail address. Any information posted beyond these basic fields is posted by the will of\nthe end user. Although the required amount of information for a Facebook account is minimal, the\ntotal amount of information a user can post is quite large. User-configurable setting on Facebook\ncan be divided into eight basic categories: profile, friends, photos, groups, events, messages, account\nsettings, and privacy settings. For the purposes of this paper, we will investigate profiles, friends,\nand privacy settings.\nProfile information is divided into six basic categories: Basic, Contact Info, Personal, Profes\nsional, Courses, and Picture. All six of these categories allow a user to post personally identifiable\ninformation to the service. Users can enter information about their home towns, their current\nresidences and other contact information, personal interests, job information, and a descriptive pho\n\ntograph. We will investigate the amount and kind of information a typical user at a given school is\nable to see, and look for trends. A major goal of Facebook is to allow users to interact with each\nother online. Users define each other as friends through the service, creating a visible connection.\nMy Profile\nContains \"Account Info\", \"Basic Info\", \"Contact Info\"\n\"Personal Info\", \"My Groups\", and a list of friends\nThe Wall\nAllows other users to post notes in a space on one's profile\nMy Photos\nAllows users to upload photographs and label who is in each one.\nIf a friend lists me as being in a photograph, there is a link added from\nmy profile to that photograph\nMy Groups\nUsers can form groups with other like-minded users to show\nsupport for a cause, use the available message boards, or find people\nwith similar interests.\nTable 1: Facebook Features\nThird-party information Two current features of Facebook have to do with third parties associ\nating information with a user's profile. The \"Wall\" allows other users a bulletin board of sorts on a\nuser's profile page. Other users can leave notes, birthday wishes, and personal messages. The \"My\nPhotos\" service allows users to upload, store and view photos. Users can append metadata to the\nphotographs that allows other users to see who is in the photographs, and where in the photograph\nthey are located. These tags can be cross-linked to user profiles, and searched from a search dialog.\nThe only recourse a user has against an unwelcome Facebook photo posted by someone else, aside\nfrom asking them to remove it, is to manually remove the metadata tag of their name, individually,\nfrom each photograph. Users may disable others' access to their Wall, but not to the Photos feature.\n\"My Privacy\" Facebook's privacy features give users a good deal of flexibility in who is allowed to\nsee their information. By default, all other users at a user's school are allowed to see any information\na user posts to the service. The privacy settings page allows a user to specify who can see them in\nsearches, who can see their profile, who can see their contact info, and which fields other users can\nsee. In addition, the privacy settings page allows users to block specific people from seeing their\nprofile. As per the usage agreement, a user can request Facebook to not share information with\nthird parties, though the method of specifying this is not located on the privacy settings page.\nPrevious Work\nNo previous academic work specific to Facebook was found on the Lexis databases, Google's database\nfor scholarly papers, the Social Science Research Network, or for \"facebook AND journal AND arti\n\nRestricted\nVisibility to Search?\nEveryone\nProfile Visibility\nEveryone at school\nFriends of friends at school\nJust friends\nContact Info Visibility\nEveryone at school\nFriends of friends at school\nJust friends\nProfile also shows...\nMy friends\nMy last login\nMy upcoming events\nMy courses\nMy wall\nGroups that a lot of my friends are in\nTable 2: \"My Privacy\" settings (defaults in bold)\ncle\" and numerous other terms in a general web query. Although no journal articles exist, there are\nmany news articles that have been published about the emergence of Facebook, its incorporation\nand subsequent venture funding, and recently, the consequences of third parties discovering infor\nmation that users have made public[14][20][21]. In related fields, the Federal Trade Commission\nhas done research into the area of online privacy practices, and has published several reports on\nthe matter, including the 1998 report to Congress entitled \"Privacy Online.\" [6] Previous work in\nsocial networking has included a thorough investigation of \"Club Nexus\", a site similar to Facebook\nlocated at Stanford University[1].\nPrinciples and Methods of Research\nIn order to investigate the ways in which Facebook is used, we closely investigated the usage patterns\nof Facebook. We employ two methods of data collection to learn more about the way users interact\nwith Facebook. First, we conducted a survey of MIT students on the use of Facebook's features.\nSecond, we harvested data from the Facebook site directly.\n4.1\nUsage patterns of interest.\nOur main objective in gathering and analyzing Facebook user data was to make statements and\ngeneralizations regarding the way users use their Facebook accounts. We investigated when users\ncreate their accounts, and which kinds of users create accounts. Though the friending service is of\n\nFigure 1: A sample Facebook page. Note the layout, accessible fields, and formation of URL used\nto retrieve this page.\nA Sample Facebook Page.\nImage removed due to copyright restrictions.\n\ngreat interest to social network research, for the purposes of our paper, we primarily investigated\nthe number of friends users have on the service as an indicator of use, and look for trends.\n4.2\nUser surveys\nOur direct user data collection procedure employed both paper surveys and Web based forms to ask\nindividual users questions concerning their Facebook practices.\nIn designing our survey, we aimed for a minimum number of straightforward, multiple choice\nquestions which would serve to reveal usage patterns, familiarity with various aspects of the service,\nand opinions on the quality of the service. The questions asked about the subject's gender, residence,\nand status, their date of joining Facebook and utilization thereof. It also asked about their knowledge\nof Facebook's Terms of Service, Privacy Policy, and privacy features, as well as their familiarity with\nFacebook's practices. We designed the survey such that it would fit on one printed page, and\ntake approximately three minutes to complete. The complete text of our survey is included as an\nappendix.\nIn order to diversify the survey results, we gathered data through four routes. We set up a table\nin the MIT Student Center, offering students a chocolate-based incentive for completing surveys.\nWe asked classmates in Public Policy, MIT course 17.30J/11.002J, to complete the survey. Via\ne-mail, we asked the residents of the East Campus, Burton-Conner, Simmons Hall, and Random\nHall dormitories to complete the surveys. Finally, we asked all survey takers to notify others of the\nsurvey.\n4.3\nDirect data collection\nOur collection of data directly from Facebook served two principles. It served as a proof of concept,\nto demonstrate that it is possible for an individual to automatically gather large amounts of data\nfrom Facebook. The collection of data was not entirely trivial, but we were able to produce the\nscripts necessary to do so within 48 hours. Also, the collection of data from Facebook will provide\nus with a large, nearly exhaustive and statistically significant data set, from which we can draw\nvaluable conclusions on usage trends.\n4.4\nObscuring personal data\nBefore analyzing data, we aggregated it into a spreadsheet. When we considered sets of more than\none record, we obscured data we deemed to be personally identifiable - Name, Phone Number, AOL\nScreenname, High School, and Dormitory. These fields were unchanged if left blank by the user,\nand replaced by \"OBSCURED\"2 .\n2Before we developed the software to obscure the data, we did do enough analysis to discover that 48 Facebook\nusers at the schools we studied have the phone number 867-5309\n\n4.5\nA brief technical description of Facebook from a user perspective\nFacebook uses server-side Hypertext Preprocesser (PHP) scripts and applications to host and format\nthe content available on the service. Content is stored centrally on Facebook servers. Scripts and\napplications at Facebook get, process, and filter information on demand, and deliver it to users in\nreal time, to a Web browser over the Internet. Users begin their Facebook session at the service's\ntop level site, http://www.facebook.com/.\nAt the main Facebook page, a user can log in to the service, or browse the small amount of\ninformation available to the general public. The main page of the service is spartan, and does not\nprovide any personally identifiable information or technical insight. Facebook does require a school\ne-mail address to use their service.\nTo log in to Facebook, users enter their username and password into the appropriate fields on\nthe page, and click Login. This sends a special URL to the service:\nhttp : //www.f acebook.com/login.php?email = U SERN AM E@SCHOOL.edu&pass = P ASSW ORD\n(1)\nNote that this URL contains a user's login credentials in clear text. This information is vulnerable\nto detection by a third party. No secure socket layer (SSL) or other encryption is used in logging in\ntot he service.\nDuring the login process, the service provides the user's web browser with some information,\nwhich is stored in the form of a cookie. Some of this information, such as the user's e-mail address,\nis written to a file so the user does not have to enter his or her e-mail at the next login. Facebook's\nservice creates and gives a user a unique checksum at every login, which the browser stores as a\nsession cookie and generally does not write to a file. This checksum varies from login to login, but\nother parameters do not.\nOnce logged in to the service, a user is free to interact with Facebook. The user may edit their\nprofile, look at others' profiles, add or change their friends lost or personally identifiable information,\nand explore the service.\nThe majority of features on Facebook are requested via simple, human-readable URLs. For\nexample, profile URLs are retrieved by requesting a URL of the form:\nhttp : //SCHOOL.f acebook.com/prof ile.php?id = U SERID\n(2)\nFacebook will read the school and user ID, and give the user either the requested user's profile page,\nfiltered for privacy by the user's request before being delivered, or return the user's home page if\nthe profile he requested is blocked or does not exist. The first user at every school is called \"The\nCreator.\" This profile's USERID is the lowest userid at any given school. The date of its creation is\nthe date which Facebook was opened to that school. User Ids continue to be assigned sequentially\nfrom the first valid number, created at the time of creation of each new account.\n\nFacebook's human-readable URLs and regularly formatted HTML make automated acquisition,\nparsing, and analysis relatively easy. We discuss how we and others have done this in the next\nsection.\nEach separate school has its own Facebook \"server\" for its content. Users with a school\ne-mail address @SCHOOL.edu will go through http://SCHOOL.facebook.com/. For the most\npart, many of these \"servers\" redirect to the same machine. For example, harvard.facebook.com,\nmit.facebook.com, nyu.facebook.com, and ou.facebook.com all redirect to 204.15.20.25. This ar\nchitecture allows Facebook to easily move different schools to different servers if necessary.\nBy default, a new user's profile and all information are fully visible to all other users at the same\nschool, but not visible to anyone at another school. Many users do not change their default settings,\nmaking their information accessible.\nWhen a user logs out of Facebook or closes their web browser, the session cookies are lost. This\ngenerally means that once a user exits the service, they must enter at least their password to use\nthe service again.\n4.5.1\nData acquisition\nWe are not the first to download user profiles from Facebook in large numbers. In the past, others\nhave utilized Facebook's use of predictable, easy to understand URLs to automatically request\ninformation and save user information for further analysis. Our approach used the incremental\nprofile identifier to download information in large quantities.\nThe algorithm we used to gather this data is very straightforward:\n1. Log in to Facebook and save session cookies.\n2. Load your home page and note the USERID of the page.\n3. Decrease the USERID until you find the ID of \"The Creator,\" the first profile at a given school.\nSave this number as USERID-LOW.\n4. Increase the USERID until you find the ID of a user who joined recently, i.e. within the past\nday. Save this number as USERID-HIGH.\n5. For every profile from USERID-LOW to USERID-HIGH at a given school SCHOOL: Get the\nprofile, using URL\nhttp : //SCHOOL.f acebook.com/prof ile.php?id = U SERID\n(3)\n, and save the profile as a file.\nTo implement our algorithm, we used wget, \"the non-interactive network downloader.\" In\naddition to implementing the above algorithm, we made wget pretend to be another web browser\n\nby changing its user agent (to avoid potential suspicion at using wget to log in to Facebook). We\nalso had wget randomly insert a delay between requests, to keep load off of Facebook's servers and\nmake our requests less difficult to detect. We took advantage of the fact that logins and passwords\nare not encrypted, and can be sent as part of the login URL as an email and password pair.\nThe final application we used to download profiles was a short (five line!) BASH shell script,\nwhich we include in the appendix.\nWe ran this script four times: once for Harvard, MIT, the University of Oklahoma (OU), and\nNew York University (NYU).\n4.6\nStatistical significance\nSurvey data Over the course of the two weeks we ran the survey, 419 MIT students responded\nto the questions asked. The users answering our profile questions came from all of campus, with\nstrong concentrations in dorms where we e-mailed the survey. The respondents were mostly un\ndergraduates (90%). There were 224 female respondents and 195 male respondents. Reflecting\nan MIT student population of 4,000 undergraduates and 6,000 graduate students, we can find the\nstatistical significance of our findings using the results of confidence levels and confidence intervals\nfrom statistics.\nThe sample size of a survey group is related to the confidence value, the percentage picking a\nchoice, and the confidence interval by the formula\nZ2p(1 - p)\nS =\n(4)\nc2\nWhere S is our sample size, Z is a value proportional to the confidence level (1.96 for a 95%\nconfidence interval), p is the percentage picking a choice, expressed as a decimal (with a worst case\nvalue of 0.5), and c is the confidence interval, expressed as a decimal (i.e. 0.04 ± 0.04). For small\npopulations, we use the correction\nS\nS0 =\n(5)\n1 + S-1\nP\nWhere S is our original sample size, S 0 is our new sample size, and P is our sample population. [17]\nOur survey results are good enough to make coarse extrapolations to the MIT community in\ngeneral. At a confidence level of 95%, and a sample size of 419 applying to an MIT student popula\ntion of 10,000 total undergraduates and graduate students, and a worst case answer uncertainty of\n50%, we find our confidence interval to be 4.68%. In other words, we can be 95% certain that our\nsurvey responses fall within 4.68% of the true values. At a confidence level of 99%, our uncertainty\nincreases to 6.17%.\nCollected Facebook data In general, we were able to collect large numbers of user profiles\nfrom Facebook using our information collection system. We exhaustively downloaded every profile\n\navailable at our four subject schools, so there is no sampling uncertainty, as long as we limit our\nconclusions to generalizations about the population of students with accessible Facebook profiles.\nWe will attempt to statistically correlate certain variables to prove hypotheses, and at other points\nwe will show raw data when we want to indicate a trend. The following table summarizes our success\nin downloading information.\nMIT\n79.71%\n66.16%\n70.54%\nNYU\n77.41%\n72.28%\nSuccess Rates In Downloading Profiles\nSchool\nNumber Profiles\nNumber Downloaded\nPercentage\nHarvard\nOklahoma U.\nTotal\nAggregate Statistics We established a \"disclosure score\" to quantitatively rank the amount of\nPII disclosed by different colleges, classes, and genders. The overall score is the sum of the percent\nage disclosure of (Gender, Major, Dorm, High School, AIM Screenname, Mobile Phone, Interests,\nClubs, Music, Movies, and Books). From there, we created two sub-scores, one to reflect contact\ninformation that could conceivably be used to contact or locate users (Dorm, AIM Screenname, Mo\nbile Phone, and Clubs/Jobs), as well as a sub-score reflecting disclosure of user interests (Interests,\nClubs/Jobs, Music, Movies, and Books).\nEnd-Users' Interaction with Facebook\n5.1\nMajor trends\nAfter processing the results of our user survey and downloaded Facebook profiles, we found some\ngeneral trends in Facebook usage. Facebook is ubiquitous at the schools where it has been estab\nlished. Users put real time and effort into their profiles. Students tend to join as soon as possible,\noften before arriving on campus. Users share lots of information but do not guard it. Users give\nimperfect explicit consent to the distribution and sharing of their information. Privacy concerns\ndiffer across genders.\nIn the following pages, we analyze the collected data along numerous lines, and statistically\njustify our findings. Our full numerical findings are included in the appendix.\n\nFigure 2: Number of Profiles identifying as a class divided by students in that class\n5.2\nFacebook is ubiquitous\nPossession of a Facebook account Survey results indicated that large majority of MIT students\nhave Facebook profiles. Of 413 respondents, 374 (91%) claimed to have Facebook accounts, while\nonly 39 (9%) did not. Indexing the Facebook seemed to indicate a similar result; the vast majority\nof undergraduates have Facebook accounts. Although fake accounts could bloat the number of\naccounts, the fact that the Facebook user base is quite similar to the MIT undergraduate population\npoint to the fact that a large percentage of Facebook users are genuine. There are 948, 1016, and 921\naccounts that provide the class years of 2007, 2008, and 2009, respectively, compared to a class size\nof roughly 1,000. As shown below, the majority of Facebook accounts are updated at least monthly,\nwhich fits the profile of large numbers of users updating information about themselves. Aside from\nher romantic attachments perhaps, a Paris Hilton account3 would not need to be constantly updated.\nAt NYU, where potential pranksters are limited to two e-mail addresses[18], the number of accounts\nfor the classes of 2007-2009 (3850, 4012, 4076) correspond closely to the class sizes of 4,250. [16]\n3Until recently, the Facebook FAQ warned against creating fake accounts, telling users that \"Everyone knows that\nyou're not Paris Hilton\"\n\nMonth\nThree Months\nSix Months\nOne Year\n53%\n82%\n92%\n98%\nF igure 3: V irtually all users update pro les often\n5. 3\nU sers put time and e ort into pro les\nT he vast majority of users update their accounts frequently, with over half updating in November\n20054. T his indicates that not only do the majority of undergraduates have Facebook accounts, the\nmajority of them also keep them constantly updated.\n5. 4\nS tudents join F acebook before arriving on campus\nWe looked at the distributions of pro le creating dates of members of the classes of 2008, and 2009.\nT he class of 2008 enrolled at M IT admission and had access to M IT server by M ay of 2004,\nwhereas the class of 2009, the current freshman class, had MIT server accounts by May of 20055.\nNote that M IT admits classes of approximately 1,000 freshmen.\nM embers of the M IT class of 2008 tended to create their pro les as soon as they heard about\nFacebook, which was generally over the summer or during orientation. T he majority of the class of\n2008 joined Facebook from J une 2004 to August 2004. In this time, 699 members of the class of\n2008 created their pro les. Approximately 100 created their pro les in M ay of 2004 (i. e. as soon as\nthey could), and the remainder created their pro les at later times, dropping to approximately 10\nper month. We were able to access 1016 members of the class of 2008 with Facebook pro les6.\nT he class of 2009 had an even more pronounced spike at matriculation time, indicating the\nextraordinary draw of the Facebook. During M ay and J une of 2005, 538 members of the class of\n2009 created Facebook accounts. At present, 921 members of the class of 2009 have unrestricted\nFacebook accounts.\nAt other schools, users exhibit similar behavior in creating their Facebook pro les. S trikingly,\nover 948 (roughly 60%) Harvard Class of 2009 freshmen created their accounts within a month\nof getting their email address. Freshmen create their accounts as soon as they can. T he Harvard\ntrends are even more pronounced as we can see from the graph, with most 2008 freshmen signing up\n419% of Harvard pro les, 15% of M IT F acebook pro les, 10% of NY U pro les, and 6% of O klahoma pro les do\nnot have an update timestamp. B ecause no update timestamps exist before J une 2004, it is probable that the feature\nwas implemented at that point, and all unstamped pro les were last updated before that point. T his hypothesis is\nsubstantiated by the fact that the number of blank update elds at a school is proportional to the length of time\nbefore J une 2004 F acebook was available at that school. Given the exponential tail-o of the last update times, it is\nalso likely that this 15% compose users who signed up right at the launch of F acebook for their school and did not\nupdate their accounts afterwards.\n5 Our experience is that M IT sends out M IT S erver coupons around this time\n6 Note that these numbers may be skewed by accounts for ctional people or celebrities.\n\nFigure 4: Freshmen create accounts sooner and sooner after matriculation\nover a three-month period, while the class of 2009 obtained their Facebook accounts immediately.\n5.5\nA substantial proportion of students share identifiable information\nFacebook users at MIT tend to give a large amount of personal information, and tend not to restrict\naccess to it. Furthermore, Facebook users are more wary of some kinds of personal information than\nothers. Users were most willing to indicate their high school, and became increasingly protective of\ntheir information regarding residence hall, interests, screen name, music interests, favorite movies,\nfavorite books, clubs and jobs, and mobile telephone number.\n5.6\nThe most active users disclose the most\nUsers who frequently update their profiles tend to be even more open. Of the 5279 MIT profiles\nupdated on or after September 1, 2005, we found that, although the general trends of relative\ndisclosure did not change, the relative willingness to disclose all information increased.\nUsing another heuristic for determining active users, users with lots of friends tend to be much\nmore forthcoming with their personal information, particularly that which might be valuable to\nadvertisers.\nFacebook has grown extremely rapidly, establishing a user base of 8,000,000 users, and close to\n100% penetration at certain schools. If Facebook continues to grow in popularity, the average user\nwill likely become more and more like the \"well-connected\" user. If this trend continues, the level\n\nFigure 5: Users disclose personally identifiable information\nFigure 6: Recent users disclose even more\n\nAll Schools: Disclosure of PII\nClubs\n300+ Friends\n81.0%\nAll Users\n51.5%\nDifference\n29.4%\nInterests\n85.3%\n64.1%\n21.2%\nMovies\n81.7%\n62.7%\n19.0%\nMusic\n82.9%\n64.0%\n18.9%\nBooks\n76.6%\n59.1%\n17.4%\nGender\nMobile\n92.8%\n25.6%\n82.8%\n17.1%\n10.1%\n8.5%\nFigure 7: Connected users disclose more personal information, especially commercially valuable\ninformation\nof information disclosure will keep increasing correspondingly.\n5.7\nUndergraduates share the most, and classes keep sharing more\nAs shown in the table below, undergraduates share much more data than average, in almost every\ncase. As the majority of new registrants for Facebook each year are going to be undergraduates,\nand the undergraduates most likely to disclose information no less, this is another indication that\nmore and more data will become available on Facebook.\nDifference between classes In order to determine if there is a statistically significant difference\nbetween courses, we attempted to correlate disclosure scores to class years. We ran a regression\nof number of years in attendance at the college7 against the disclosure index, and the contact and\ninterest subscores. We did this at all four schools, and the result was that all disclosure scores were\nweakly correlated to class year (r = -.496 for the overall score, r = -.151 for the contact score, and\n-.187 for the interest score.). This means that there is a correlation between being in a younger\nclass and disclosing more information.\n5.8\nDifferences among universities\nAmong the four universities we investigated, we found subtle differences in the way student interact\nwith Facebook. Of the universities, Harvard provided us with the lowest percentage of visible profiles\nfrom existing profiles (66%), whereas MIT provided the highest (79%). Students at the University\nof Oklahoma were much less likely to share contact information (such as residence, screen name,\nand mobile phone number) than students from any other university in our study. On the other hand,\nstudents at Oklahoma were the most forthcoming about their tastes in books, movies, and music.\nThe differences we found really speak to the notion that Facebook is different at every school it\nsupports. The differences we noted are probably a function of many variables specific to the school,\nsuch as the social atmospheres at the school, policies on information sharing, administrative advice\non Facebook usage, and so on. Such topics are outside the scope of this paper.\n70, 1, 2 for the Classes of 2009, 2008, and 2007, respectively.\n\nDifference in Disclosure\nMIT\nGender\n22%\n17%\n-6%\n23%\n30%\n23%\n23%\n4%\n32%\n18%\nAIM\n26%\n18%\nMobile\n3%\n10%\nInterests\n29%\n16%\nClubs/Jobs\n17%\n23%\nMusic\n33%\n18%\nMovies\n31%\n19%\n31%\n17%\nHarvard\nMajor\nDorm\nRoom?\nHigh School\nBooks\nFigure 8: Difference between Class of 2009 exposure and all users\nMIT\nOK\nNYU\n81%\n64%\n91%\n79%\n96%\n94%\n85%\n89%\nAIM\n71%\n72%\n62%\n76%\nMobile\n24%\n27%\n17%\n15%\nInterests\n78%\n81%\n89%\n81%\nClubs/Jobs\n49%\n58%\n76%\n50%\nMusic\n77%\n82%\n93%\n84%\nMovies\n74%\n80%\n90%\n82%\n74%\n80%\n81%\n77%\nHarvard\nMajor\nDorm\nBooks\nFigure 9: Disclosure rates of the Class of 2009\n\n5.9\nEven more students share commercially valuable information\nThe information most relevant to advertisers would likely be demographic data (age, gender, loca\ntion), as paired with interests. In general, over 70% of users are willing to disclose both categories of\ninformation, making the Facebook a valuable trove of demographic data for marketers. In addition,\nthis database of interests could easily be cross-referenced by a database from a third-party ven\ndor, matching the details about users' interests and current location to addresses, phone numbers,\nand social security numbers. As shown above, dedicated users have a tendency to disclose this\ninformation much more often, which may be a leading indicator of even greater disclosure.\n5.10\nUsers are not guarded about who sees their information\nKnowledge and use of \"My Privacy\" feature As a whole, users are familiar with the privacy\nfeatures Facebook offers, and choose not to use them. Of 389 users indicating familiarity with \"My\nPrivacy\", 289 (74%) say they are familiar with \"My Privacy,\" while 100 (26%) say they are not.\nAt the same time, of the 380 users who gave information regarding their use of \"My Privacy,\" 234\n(62%) said they use the feature, while 146 (38%) said they do not. Actively choosing to not use\n\"My Privacy\" indicates that users believe there is a benefit to providing information and allowing\nothers to see it.\nConcerns about Facebook privacy As a whole, survey respondents expressly indicated low con\ncern for Facebook's privacy policies. Of 329 respondents, 76 (23%) are not concerned with Facebook\nprivacy, 117 (35.5%) are barely concerned, 104 (31.6%) are somewhat concerned, 20 (6.1%) are\nquite concerned, and 12 (3.6%) are very concerned.\nLikelihood of \"friending\" strangers. Facebook users at MIT tend to friend people they know,\ndoing so almost exclusively. Of the 383 respondents to this question, 243 people (63.45%) never\nfriend strangers, 110 people (28.72%) friend strangers on occasion, and 30 (7.83%) claim to friend\nstrangers. Although this seems like an intuitive notion, it merits further attention. Only allowing\npeople whom users know in real life to access their information is a good Facebook security strategy\nwhen combined with other privacy features and selective posting. This tendency of users is further\nevidence that Facebook use is more characteristic of physical relationships than that of an exclusively\nonline community, a powerful metaphor that is at the heart of the way users share their information\non Facebook. Women and men are equally unlikely to add a stranger to their list of friends.\n5.11\nUsers Are Not Fully Informed About Privacy\nFamiliarity with the TOS and the Privacy Policy We asked Facebook users if they had read\nFacebook's policies regarding their use of the service. Of 389 respondents, 353 (91%) had not read\n\nthe Terms of Service. Of 390 respondents, 347 (89%) had never read the Privacy Policy.\nUnderstanding of Privacy Policy We asked users to guess whether or not Facebook can share\nyour information with other companies. Of 374 respondents, 174 (47%) believed Facebook could\nnot do this, while 200 (53%) believed Facebook could. Facebook can indeed share your information\nwith other companies for advertising or other purposes, as indicated in their privacy policy8 .\n5.12\nAs Facebook Expands, More Risks Are Presented\nFamiliarity with \"My Photos\" feature The overwhelming majority of Facebook users are familiar\nwith the \"My Photo\" feature. Of 389 respondents, some 342 (87.9%) were familiar with the\nfeature. Furthermore, although most users are familiar with the feature, few seem to worry about\nits potential implications. When asked if users have any control over the \"My Photo\" content of\nothers, specifically, on restricting access to photos posted on the service, 196 users of 416 respondents\n(47%) said yes, 139 users (33%) said no, and some 84 (20%) did not know, or did not provide an\nanswer.\n5.13\nWomen self-censor their data\nIn addition to the above analysis, we compared the trends of male and female users. Women are more\nlikely to log into Facebook, have more friends, and have a higher percentage of friends from MIT.\nBoth genders are equally unfamiliar with Facebook's Terms of Service and Privacy Policy. Women\nwere more likely to use Facebook's \"My Privacy\" feature in our survey, but not to a statistically\nsignificant level. Women definitely self-censor their Facebook data more than men do. This is\npronounced in the number of mobile phone numbers made available to the public, as shown in the\ntable9 .\nIn addition, we calculated the correlation between self-reported gender percentages at the dif\nferent universities, and correlated these to the contact information index. We found that schools\nwith more women share proportionately less contact information, with a correlation coefficient r =\n-.462.\n8The FAQ and Privacy Policy are actually in direct contradiction on this point. The FAQ states that \"We don't\ndistribute your user information to third parties.\" The Privacy Policy, on the other hand, states that \"we may share\nyour information with third parties, including responsible companies with which we have a relationship.\" The Facebook\nthen lists reasons that they may share information, including legal requests and \"facilitating their business.\" Although\nthe policy could be construed to imply they will not share information, it is certainly not clearly stated, and a strict\nreading would imply that Facebook can share information with third parties.\n9The correlation coefficient of male to female mobile phone disclosure is .992, indicating an extremely strong link\nbetween the behavior of the genders at any particular school.\n\nDisclosure of phone number, by gender\nMale\n33%\n26.5%\nMIT\n29.7%\n20.5%\nNYU\n22.2%\n11.6%\nOklahoma\n21%\n8%\nFemale\nHarvard\nFigure 10: Women self-censor the information they share\n5.14\nMen talk less about themselves\nIn contrast, we compared gender ratios to the interest data index (the extent to which users share\ntheir interests, clubs, and favorite books, etc.). Here we found that the male-dominated schools\ntended to share less information, which may indicate that women are more likely to share information\nabout themselves which will not lead to phone calls or unwanted visits. The correlation coefficient\nbetween self-reported female percentage and the interest index was r=.625.\n5.15\nGeneral Conclusions\nFacebook is an institution at the colleges we surveyed. As time goes on, it is becoming even more\nentrenched in college life. Although they tend to self-censor, especially women, users still share a\nlot of personal information that could be valuable to many parties. As Facebook becomes more\nentrenched, disclosure rates are likely to rise, until Facebook changes the parameters of their system,\nor there are enough newsworthy privacy stories to change users' perceptions.\nFacebook and \"Fair Information Practices\"\n6.1\nOverview\nIn 1998, the Federal Trade Commission published Privacy Online, a report to Congress assessing\nthe state of privacy on the Internet. This report identified the five \"widely accepted fair information\npractices\": Notice, Choice, Access, Security, and Redress. These areas cover the basic principles of\nonline privacy, areas Facebook needs to address if they are to protect the privacy of its users. [6]\n6.2\nNotice\nNotice is the first and most important requirement of fair information practices. Customers must\nbe aware of information collection and their rights regarding that collection before they can exercise\nthem. The basic \"notice\" requirements are a clear statement given to the consumer, before data is\ncollected, including, among other things:\n\n- Identification of the entity collecting the data, the uses to which the data will be put, and any\npotential recipients of the data.\n- The nature of the data collected and the means by which it is collected if not obvious (pas\nsively, by means of electronic monitoring, or actively, by asking the consumer to provide the\ninformation).\n- Whether the provision of the requested data is voluntary or required, and the consequences\nof a refusal to provide the requested information.\n- The steps taken by the data collector to ensure the confidentiality, integrity and quality of the\ndata. [6]\nThe Facebook Privacy Policy aims to fulfill this requirement. It specifies Facebook as the entity\ncollecting the data, and does a good job of identifying which data will be collected in most cases,\nincluding non-obvious data such as session data and IP addresses. Parts of the policy are vague,\nhowever, and some are seemingly contradictory and confusing, such as \"Facebook also collects\ninformation about you from other sources, such as newspapers and instant messaging services. This\ninformation is gathered regardless of your use of the Web Site. We use the information about\nyou that we have collected from other sources to supplement your profile unless you specify in your\nprivacy settings that you do not want this to be done.\" This passage is either inaccurate or outdated,\nas no setting related to this information is available in the \"My Privacy\" feature.\nEven though Facebook accurately addresses what information they will be including on the whole,\ntheir Privacy Policy falls short in other areas. The identification of the uses to which the data will\nbe put are nonexistent, and the identification of the targets of potential disclosure is anybody\nFacebook deems appropriate, including marketing partners. Facebook has close relationships with\nseveral corporations, integrating their marketing efforts seamlessly into the site via giving them\nspecial \"Groups\" for interested students. This disclosure is certainly legal, and users are receiving\nthe use of an extremely useful and popular site for free in exchange for it. Unfortunately, not all\nusers understand the terms of the bargain; our survey showed that 46% of Facebook users believed\nthat Facebook could not share their information with third parties.\n6.3\nChoice\n\"At its simplest, choice means giving consumers options as to how any personal information collected\nfrom them may be used. Specifically, choice relates to secondary uses of information - i.e., uses\nbeyond those necessary to complete the contemplated transaction.\" [6]\nClearly, it is necessary to enter some personal information if one wishes to participate in a social\nnetworking website. However, there is large amounts of additional disclosure going on. The two\ntypes of disclosure are disclosure to other users of the site, and disclosure to third parties, primarily\n\nadvertisers. The privacy features provided by Facebook, to a large extent, allow the interested user\nto easily control what other users of the site can see about their profile data.\nThe issue here is that there are virtually no controls on what Facebook can expose to advertisers.\nThe blanket statement regarding disclosure allows Facebook to disclose any personal data to adver\ntisers. It also allows advertisers to set cookies that are not governed by the privacy policy. There is\nway to request that Facebook not share your information with others, but it is not transparent and\nthere is no evidence that one's request is actually honored. See later in the paper for more details.\n6.4\nAccess\n\"[Access] refers to an individual's ability both to access data about him or herself - i.e., to view the\ndata in an entity's files - and to contest that data's accuracy and completeness. Both are essential\nto ensuring that data are accurate and complete.\" [6]\nThis attribute is more targeted at credit agencies and other organizations which maintain files on\nusers which they may not want to disclose. Because Facebook is based on the sharing of information,\nand because Facebook provides users with the ability to control this information, Facebook follows\nthis principle fairly well.\n6.5\nSecurity\nSecurity is the process that ensures data integrity and restricts access to those who have been\ngranted it legitimately. Privacy Online states in part \"To assure data integrity, collectors must take\nreasonable steps, such as using only reputable sources of data and cross-referencing data against\nmultiple sources, providing consumer access to data, and destroying untimely data or converting it\nto anonymous form.\"\nAlthough Facebook is certainly vague about the uses to which the data will be put, it gives users\ncontrol over the existence of information about themselves in the Facebook database. Their terms\nof service clearly state that \"You may remove your Member Content from the site at any time. If\nyou choose to remove your Member Content, the license granted above (that permits Facebook to\nuse the data) will automatically expire.\"\n\"Security measures include encryption in the transmission and storage of data; use of passwords;\nand the storage of data on secure servers or computers that are inaccessible by modem.\"\nBy this standard, Facebook falls short. Although Facebook uses passwords to protect accounts\nand a MD5 hash as authorization, their use of encryption is nonexistent. All authorization informa\ntion is sent in the clear, including the account passwords, making them exceedingly easy to sniff off\nof a public network. This is clearly inferior to the current best practices for password protection.\nThe \"My Photos\" feature seems to run counter to the Security principle, as third parties can\nupload pictures and associate them with one's account, without any checks on the accuracy or\n\nappropriateness of the data. Users have no way of preventing pictures of them from being uploaded.\nEven if users seek to disassociate themselves with any photos, the most they can do is remove\nthe tag that links the photo directly to the user's profile. In addition, there are absolutely no user\ncontrols akin to \"My Privacy\" relating to photos at all. We have found that any Facebook picture\nis accessible from any Facebook account, with no regard for privacy settings, or even the default\nFacebook per-university controls. One can ask to see all of the pictures of \"Michael Smith\" at\nStanford and view them, even if one is logged into the MIT facebook.\n6.6\nRedress\n\"To be effective, self-regulatory regimes should include both mechanisms to ensure compliance\n(enforcement) and appropriate means of recourse by injured parties (redress).\"\nMuch like the other privacy principles, Redress requires that customers be aware of ways in\nwhich they may be harmed. In the case of security breaches, there is no policy for notification of\ncustomers. In light of holes such as the \"advanced search\" hole described below, a clear policy on\nthis matter would have been beneficial for users.\nIn addition, redress should entail acknowledgment of user requests and transparency in follow-\nthrough on them. The \"prevent my information from being transmitted to third parties\" request\nwould be much improved if one could track the ramifications of that request.\nThreat Model\n7.1\nSecurity Breach\nThreat and Feasibility\nA security breach at Facebook, either from an outsider locating vulnerability or from a disgruntled\ninsider, would potentially put all 8,000,000 Facebook records at risk. This is not a risk that can\nbe eliminated; no site is perfectly secure. The fear of a security breach is certainly a reasonable\none, as large data warehouses are often targets of intruders. For example, ChoicePoint's databases\nwere breached and 145,000 records were compromised. [3] While a Facebook breach would not be\nsufficient to start performing identity theft, a trove of so much personal information would contain\nmuch information that people would not want to make public.\nMySpace: A Comparison\nMySpace has several clauses in its Privacy policy that deal directly with contingencies that are\nnot pleasant for the company to admit. The company tells users that security breaches can never\n\nbe completely prevented, even if \"reasonable\" steps are taken to prevent security breaches. This\nensures that an unreasonable expectation of data security is not established[10].\nIn addition, MySpace confronts the possibility that they will be acquired, and notifies its users\nthat their new owners could be less than scrupulous about using personal data. Their notification\nrequirements regarding changes to their privacy policy appear to be aimed at this contingency.\nUnfortunately, MySpace does not have a notice requirement in the case of security breaches.\nRecommendation for Facebook: Security Disclosures Facebook should have a policy regarding\ndisclosures of private information due to security breaches or unethical employees. A clearly stated\nrequirement in their terms of service that they notify end-users whose privacy was violated would\nempower end-users.\n7.2\nCommercial Datamining\nThreat\nCompanies such as ChoicePoint, Inc. have built billion-dollar business on selling databases of per\nsonal information. Facebook has a database on 8 million college students that is far more accurate\nthan the usual commercial data, as users have an incentive to make information accurate. Profiles\nused for social networking are likely to be 100% accurate, as they are maintained by their subjects.\nThis is in marked contrast to the accuracy of databases such as those maintained by ChoicePoint\nand Acxiom, which have records of dubious accuracy[15].\nFeasibility\nUsing our code, attached as an appendix, we were able to crawl Facebook for four schools, creating\na comprehensive data-set spanning all accessible profiles. Thus, we can conclude that it is possible\nto harvest data from the site. The fact that we (two students) were able to data-mine the Facebook\nin a week, using the time allotted to us for one class is evidence that data-mining the Facebook is\nevidence that it is not only possible, but easy.\nCurrent Precaution\nFacebook's Terms of Service state that using the site for data-harvesting purposes is forbidden.\nThis statement offers no protection, however, if it is possible to use the site for these purposes,\nand there is no recourse against those who may seek to do so. Our data collection violates the\nTerms of Service for Facebook, which states that \"You further agree not to harvest or collect email\naddresses or other contact information of members ... for the purposes of sending unsolicited emails\nor other unsolicited communications. Additionally, you agree not to use automated scripts to collect\ninformation from the Web site or for any other purpose.\" \"Clickwrap\" licenses like the terms of\n\nservice have generally been upheld by courts10, but the danger posed to a person breaching this\ncontract is uncertain at best. There are no provisions for the violation of the Terms of Service, and\nthe termination of the offending account would not be a sufficient deterrent for those determined\nto obtain and use this information.\nRecommendations To Facebook: Better URL System Because of the method by which Face-\nbook assigns User IDs, one can easily download all accessible profiles. A better system would be to\nmake the profile number space 10 times the number of people eligible for accounts at the university,\nand assign user IDs randomly out of that. Then, when invalid UIDs are accessed, those IPs/accounts\ncould be monitored for signs of abuse.\n7.3\nDatabase Reverse-Engineering\nThreat and Feasibility\nFacebook's \"advanced search\" allows one to query the database of users using any of the fields in\na profile. For example, one can search for sophomore males at Duke that enjoy Kurt Vonnegut.\nThe problem is that when people hide their profile page, they expect the information on it to\nremain private. An MIT student could write \"getting drunk\" as an interest and set their profile\nso that only their friends could see their profile, expecting that this information is secure. This\ninformation is not actually secure unless they also exclude their profile from searches. An advanced\nsearch for \"getting drunk\" would still associate the students' name with this string.\nThe problem was compounded by a security hole that multiple people have discovered. Normally,\nperforming a query at a certain college requires that one be logged in from an @thatcollege.edu\naccount. A high school student at an MIT summer program discovered that by changing the server\nin the query URL from \"mit.facebook.com\" to \"school.facebook.com\", he could perform the query\non any school without having a valid account for that school. He also discovered that most fields\nare indexed by ID number, so he was able to systematically query who lived in dorm \"101\", \"102\",\netc, until he had a comprehensive list of where everyone said they lived in their profiles. He was\nonly interested in using data on MIT students in an aggregated manner, but with that knowledge,\none could easily reconstruct all Facebook profiles regardless of privacy preferences.\nFurther research found a student that actually employed this strategy to create a database of at\nother local schools. Up until November 10, 2005, he was able to systematically build up a database\nfrom queries on Facebook's database. Over the course of a month, he compiled information on over\n82,000 students at 8 Boston-area schools.\n10 ProCD v. Zeidenberg, referenced in [19]\n\nCurrent Facebook Precaution\nFacebook blocks Advanced Search, except at one's school, which limits the scope of the problem.\nThe \"Exclude my name from searches\" preference in the \"My Privacy\" section actually solves the\nproblem. Because an intuitive leap is needed to see how to use the Advanced Search for data-mining,\nhowever, it takes the same intuitive leap for users to see the risk and protect themselves from it.\nRecommendation to Facebook: Restricting Search When users set their profile to be friends-\nonly, all information save their name should be withheld from being searched by \"Advanced Search.\"\n7.4\nPassword Interception\nThreat\nThe fact that the username and password were sent in cleartext is a security vulnerability. An\nadversary could read Facebook user names and passwords off of the Ethernet or unencrypted wireless\ntraffic, obtaining access to users' Facebook passwords, as well as any additional accounts they use\nthose passwords for. Because of the ethical and legal implications of doing so, we did not attempt\nto steal passwords. It should be noted, however, that MIT cited password theft as a real problem\nwhen they maintained telnet servers that had login data sent as cleartext. The University of New\nMexico cited this as the main reason they chose to disable Facebook access from their network.\nBecause many many users use their university email passwords as their Facebook passwords, UNM\nviews Facebook as a security liability for their network.\nCurrent Facebook Precaution\nFacebook currently takes no steps to protect user passwords in transit.\nRecommendation to Facebook: Encrypt the Passwords Using SSL for login is the industry\nbest practice for protecting passwords on login. It is used by Google Mail, eBay, MIT WebMail, and\ncountless other sites to protect sensitive information as it is being transferred. It is a simple, cheap\nsolution that would close a major security hole.\n7.5\nIncomplete Access Controls\nThreat and Feasibility\nIn searching for user photos on Facebook, the service uses a variant of this URL:\nhttp : //mit.f acebook.com/photo search.php&name = J ohn\n(6)\n\nThere is nothing inherently wrong with allowing users to search for photos, but there are no restric\ntions akin to \"My Privacy\" for photographs. In addition, the usual access controls do not apply to\n\"My Photos,\" anyone from any university can search for and see any other photograph by editing\nthe query URL.\nThe ability of users to upload and tag photographs easily, and the difficulty for a user to de-tag\nlarge numbers of photographs, makes it easy for others to find photographs with few restrictions.\nCurrent Facebook Precaution\nFacebook limits photograph searches by profile in the same way they limit regular searches; the\nproblem lies in the additional unrestricted method of searching all photos by name.\nRecommendation to Facebook: Restrictions on Pictures Search This is weaker than any\nother access controls on the site; by default, users are unable to view others' profiles on other\nwebsites, but they can view all pictures. \"My Privacy\" should extend to the \"My Photos\" feature\nas well, and the search by name should be disabled.\n7.6\nUniversity Surveillance\nThreat\nStudents in many cases are unaware of the complex interactions between university policy and the\ninformation they are making available online. Administrators are using Facebook to learn about\ntheir students... and their students' activities. Recent months have seen a rash of incidents coming\nfrom students disclosing information that they never thought would end up in deans' offices, but\nhas. These problems are not limited to technical schools like MIT, they exist all over the nation.\nFeasibility\nMIT MIT has not had any high-profile Facebook-related cases yet, but there have been smaller\nincidents, and a growing realization of the importance of Facebook in a college environment. Dean\nof Residential Life Programs Andrew Ryder has stated that MIT is not actively monitoring Facebook\nfor rule infractions. He did say, however, that if public or quasi-public Facebook information was\nbrought to his attention, he would have to act on it. It is also his personal belief that Facebook\ndata would be admissible in Committee on Discipline hearings. Without detailing specific cases,\nhe alluded to the fact that Facebook incidents that MIT has had to deal with so far have related\nto a student posting unflattering or untrue information about another student, which generated a\ncomplaint to the Department for Student Life. The one other MIT case involved a freshman in the\nclass of 2008 advertising a party in his soon-to-be dorm room on Facebook before he even arrived\non campus.\n\nCameron Walker and Fisher College In October of 2005, Cameron Walker, then a second year\nstudent at Fisher College in Boston, MA, was expelled from the school and barred from the campus.\nThe reason for this action given by Fisher College was Walker's creation of a Facebook group\ncommitted to the dismissal of a campus security officer believed to regularly overstep the limits of\nhis line of duty. School officials who monitored Facebook, pressured Walker to remove the group,\nand ultimately canceled Fisher's student status.\nMr. Walker's expulsion could set a dangerous precedent for university officials. Students believe\nthat the information they post to Facebook should be protected as correspondence, while school\nofficials, particularly at schools with strict codes of discipline, will use evidence posted on Facebook\nto bring formal disciplinary charges against students. This is the first incident of a student being\nexpelled for actions on Facebook. We conducted a phone interview with Walker in mid-Novemnber.\nHe was a sophomore in the class of 2008 in October 2005, when the events leading to his expulsion\noccurred. His expulsion demonstrates the issues that can arise from the interactions of Internet\npublication and \"unclear, ambiguous, and vague\" (Walker's words) student codes of conduct, es\npecially as they pertain to harassment. Walker claims that his expulsion was an example of a \"few\nadministrators doing whatever they wanted\", and that he \"was naive about Facebook, because it\nwasn't affiliated with a university.\"\nNews at Other Schools In recent weeks, there has been an explosion of articles in college newspa\npers relating to the privacy concerns of Facebook. The recent expulsion of Cameron Walker may have\ncreated a concrete example of the harm that can come from Facebook activity; it is the one case that\nmany news articles mention. Since November 1, cautionary articles have appeared in the newspapers\nof Emory[21], Georgia College[22], Dartmouth[23], the University of Oregon[24], Trinity College[25],\nMacalester[26], Syracuse[27], Brown[28], GW, University of Tennessee at Chattanooga[29], UNC\nGreensboro[30], and UPenn[31].\nCurrent Facebook Precaution\nThe Facebook currently does not take steps to prevent this type of disclosure.\nRecommendation to Universities: From a student perspective, Facebook has been an area\nrelatively free of administrative interference until now. University policies are two-fold; there is\nthe letter of the law, and what is actually enforced. The wealth of new information available to\nadministrators pushes the enforceability much closer to the literal readings of school policies, which\ncould have many unintended consequences. On the other hand, administrators are not free to set\nwhatever policies they see fit, and in an age of litigation, they cannot afford to selectively enforce\npolicies. To do so would be to make the university vulnerable to lawsuits in cases where forbidden\nbehavior goes too far undetected.\n\nIn addition, Facebook is becoming a key component of college life, and college administrators\nwould not be doing their jobs if they didn't understand and explore how a large portion of their\nstudent body was using their spare time and interacting with each other.\nBecause of this complex interaction, and the differing goals that administrators have, colleges\nshould look at their primary interaction with Facebook an educational one. Students can only claim\nthat they have been treated unfairly if they can establish an expectation of privacy. If universities\nare going to use this information, they should tell their students this up-front.\nRecommendation to Universities: Educate Students The university's most important role,\nhowever, is that of education. To fulfill this mission, universities should educate their students\nabout the dangers that online disclosure of information can pose. Because students are getting\naccounts earlier and earlier, a program during Orientation would help students from running afoul\nof university policy or being harassed.\nRecommendation to Facebook: Warnings Page In an environment of growing misuse of in\nformation made public by Facebook, Facebook would do its users a great service to explain the\ndangers of security breaches and outside monitoring. Until the societal norms regarding this new\nuse of computers become well-established, Facebook could clearly state that they could provide\nno guarantees regarding the security of their data, and that if users make their profiles public, all\ninformation contained therein may be viewed by job interviewers and college administrators.\nRecommendation to Facebook: Opt-Out Privacy In a world where a minority of users change\nsoftware preferences, privacy protection cannot be an \"opt-in\" option. Facebook faces a tough\nchoice here: their business model is based on many ad views, which requires extended browsing\nsessions, which requires a relatively open network. Yet, opt-out protection is far more effective, as\ndemonstrated by Shah and Sandvig in \"Software Defaults as De Facto Regulation.\" Their study\nfound that if encryption on WAPs is set by default, 96% of users employ it, 3.4 times the number\nthat do when it is not set by default.\nRecommendation to Facebook: Merge \"My Privacy\" Facebook is unique, however, in that\nusers are expected to return often and update their \"preferences\" (who their friends are, their\nprofile information). Thus, Facebook could leverage this culture by merging the functions of profile\nupdating and privacy settings. One page could contain fields regarding basic profile information as\nwell as privacy settings, thereby greatly increasing the number of views the privacy settings get daily.\n\n7.7\nDisclosure to Advertisers\nThreat and Feasibility\nFacebook has a relationship with several companies currently. Apple and JetBlue, among others,\nhave their own \"groups\" that interested users can join, to show their brand loyalty, or for a chance\nat giveaways. Facebook's privacy policy explicitly says that they may disclose profile information to\nthird parties, so the prospect of them doing so is clearly realistic.\nCurrent Facebook Precautions\nFacebook offers an \"opt out\" link on their Privacy Policy page, which, if clicked, means that one\ncan \"submit a request\" to Facebook to not share information with third parties. They say that\nthey \"will make every effort to implement any choice you make as soon as possible.\" Offering the\nuser choice in this matter is clearly to the user's benefit. However, the feature has no followup or\nfeedback, and is couched in language that does not actually imply any sort of binding agreement.\nOther Services' Precautions\nFriendster Friendster's privacy policy is indicative of a more mature service, with narrower goals,\ndealing with smaller amounts of personal information than Facebook. Friendster only collects the\ndata you enter into your profile, your name, e-mail address, IP address, and user agent. Unlike\nFacebook, Friendster agrees to never share your information with any outside agency, unless expressly\nrequired to do so by law.\nMySpace MySpace also has a much more explicit and user-oriented disclosure policy. The scope\nof disclosure to third parties is much more explicitly dealt with, and limited to:\n- Disclosure to advertisers whom users have \"explicitly requested\" to receive information from11 .\n- The use of cookies by advertisers. 12\n- Disclosures required to enforce their TOS, to protect them legally, or to protect the safety of\nthe public13 .\n11 Users may be asked to provide personal information including name, email address or home address or to answer\nquestions in order to participate. We may transfer personal information to certain ad partners that you have explicitly\nrequested to receive information from. It will be clear at the point of collection who is collecting the personal\ninformation and whose privacy statement will apply.\n12 \"A User is bound by any minor changes to the policy when she or he uses the site after those changes have been\nposted If, however, we are going to use users' personally identifiable information in a manner materially different from\nthat stated at the time of collection we will notify by posting a notice on our Web site for 30 days.\"\n13 \"Except as otherwise described in this privacy statement, MySpace will not disclose personal information to any\n\nRecommendation to Facebook: Accountability and Accessibility for Third-Party Opt-Out\nAn opt-out feature that guaranteed that the user's information would not be disclosed in the future\nwould allow users much more control over their privacy. If the process is complex, then a method\nfor tracking one's request would increase the transparency of the process. In addition, the link is\nburied in the privacy policy, which is a legal agreement; users who want to take action would look\nto \"My Privacy.\" To actually make the option effective, it should be located in \"My Privacy.\"\nRecommendation to Facebook: Privacy Policy Improvements Facebook's privacy policy is\nvague and subject to change at the whim of the owners of the website. The Facebook policy allows\nany disclosure of information to third parties that Facebook feels is appropriate. Facebook should\nseek to emulate MySpace in this manner, and perhaps even go farther.\nA user-centered Terms of Service would clearly delineate which information is shared with which\npartners, depending on whether a user clicked on a third party's ad or joined a third party's group.\nA notice period announcing a change in the Terms of Service is another change that would improve\nthe user experience.\n7.8\nLack of User Control of Information\nThreat\nOther users can upload and associate information to one's Facebook account. The most prominent\nfeature of this type is the \"My Photos\" feature, which allows users to upload photos and tag them\nwith the names of the people in the pictures. This functionality has already resulted in trouble for\nan underage student at University of Missouri-Columbia when college administrators found a picture\nof her duct-taped to a chair while another student poured beer in her mouth. This was a matter of\nconsiderable embarassment as she had just been elected student body vice president. The university\nis currently considering removing her from that role.\nCurrent Facebook Precaution\nFacebook allows users to de-associate themselves from unwanted data, but in the case of pho\ntographs, the data remains on the server. This is also an \"opt-in\" function that requires constant\nmonitoring of the system.\nthird party unless we believe that disclosure is necessary: (1) to conform to legal requirements or to respond to a\nsubpoena, search warrant or other legal process received by MySpace.com, whether or not a response is required by\napplicable law; (2) to enforce the MySpace.com Terms of Use Agreement or to protect our rights; or (3) to protect\nthe safety of members of the public and users of the service.\"\n\nRecommendation to Facebook: Better Restrictions on Third-Party Information Third par\nties' ability to submit and associate information about users violates one of the key principles of\ninformation practices: the idea that users should have the ability to control and correct the informa\ntion about them in a particular database. Although Facebook allows users to delete Wall postings\nand de-associate themselves with photographs, this is an \"opt-in\" mechanism that requires constant\nmonitoring. Modifying the \"My Privacy\" feature to allow a blanket disabling of these features for\na particular user would help users control their information.\nRecommendation to Users: Exercise Caution Users should be aware that there are effectively\nno access controls on pictures, and that they should only upload the pictures that they would feel\ncomfortable having anybody on the Facebook viewing.\nIn addition, realize that the photos that you upload of other people may be viewed by their high\nschool friends or their family. Don't post anything of them doing anything that you wouldn't want\nyour parents to see you doing.\n7.9\nSummary and Conclusion\nUltimately, lasting change in online privacy will only come from a gradual development of common\nsense regarding what is appropriate to post in social networking forums. Unfortunately, this is not\nan easy fix. Until users view alluding to underage drinking or drug use on their profiles as risky,\nmistakes regarding privacy will continue to occur. Revealing this sort of information needs to be\nviewed as the equivalent of going alone to the apartment of a person one met on the Internet.\nIt is vital that Facebook users everywhere appreciate the potential for use of the system by\nadministrators. We strongly advise all Facebook users to restrict access to their profiles, to not\npost information of illegal or policy-violating actions to their profiles, and to be cautious with the\ninformation they make available.\nThis lasting change will only come with time and understanding. Nobody can fault Facebook for\nstudents making questionable decisions, but the environment that Facebook creates should be one\nthat fosters good decision-making. Privacy should be the default, encryption should be the norm,\nand Facebook should take strides to inform users of their rights and responsibilities.\nConclusion\n8.1\nPostscript: What the Facebook does right\nA paper that analyzes the threats to privacy a system poses will inevitably adopt a negative tone\nabout the target of its examination. Although Facebook has flaws, there are also areas in which it is\na leader among social networking sites. The fact that each university Facebook is effectively its own\n\nsite virtually firewalled off from the rest of the network is a much more private-by-default system\nthan Friendster or MySpace, which explicitly notes that there is no way to restrict profile information.\nThis system makes data harvesting much harder, though not impossible. The requirement of having\na school email account to sign up is largely effective in preventing fake accounts and what could\notherwise be a problem of Facebook \"identity theft.\"\nThe \"My Privacy\" settings model is fundamentally sound. The current model would be close to\nideal if the defaults and behaviors of settings were changed, which would not require a substantial\nengineering effort.\nAlthough the flaws with \"My Photos\" are pronounced, the existing security model is robust\nenough to solve most of the problems associated with it. If the name search for photos followed\n\"My Privacy\" rules, it would be allow users to control their data very easily.\n8.2\nFinal Thoughts\nFacebook is used by over 8 million college students, but no academic study has been done of its\neffect on end-users. As with any emerging technology, the common sense regarding its proper use\nhas lagged behind what technology has made possible. Although the Internet has made it possible\nto publish personal information online for a decade, social networking sites are unique in that they\nstandardize, centralize, and encourage the publication of personal data to an unprecedented extent.\nThe consequences of excessive disclosure of personal information and false senses of security are just\nbeginning to emerge. Although no national attention has been devoted to the issue, more stories\nof students being disciplined because of Facebook appear in college newspapers every week. As\ninformation retrieval and analysis tools become more powerful, the public needs to develop common\nsense about accepted practices on these sites. Much as it is now common sense to not meet\npeople online without taking significant precautions, a body of common knowledge about disclosing\ninformation online would protect the public. This research aims to begin that dialogue. From a\ntechnological perspective, there has been little dialogue about investigating the protections put in\nplace at one of the most-visited sites on the internet, which contains detailed files on more than 8\nmillion young adults. Security by obscurity is not the best practice for any system, let alone one used\nby so many. The user community of this site and future sites will benefit from increased attention\nto these issues.\nReferences\n[1] Adamic, Lada A., Buyukkotken, Orkut, and Adar, Eytan. 2002. \"A Social Network Caught In\nThe Web.\" http://www.hpl.hp.com/research/idl/papers/social/social.pdf\n\n[2] Sandvig, C. & Shah, R. (2005). Defaults as De Facto Regulation: The Case of Wireless Access\nPoints. Paper presented at the 33rd Telecommunications Policy Research Conference (TPRC)\non Communication, Information, and Internet Policy, Arlington, Virginia, USA.\n[3] Konrad, Rachel. Associated Press. February 24, 2005, \"Burned by ChoicePoint breach, potential\nID theft victims face a lifetime of vigilance.\"\n[4] Terremark Worldwide, Inc. \"Facebook Expands Operations at Terremark's NAP West Facility\"\nTuesday November 1, 8:30 am ET.\n[5] Newitz,\nAnnalee.\n\"Dangerous\nTerms:\nA\nUser's\nGuide\nto\nEULAs.\"\nhttp://www.eff.org/wp/eula.php. Loaded December 14, 2005.\n[6] Federal Trade Commission, Privacy Online: Report to Congress, 1999.\n[7] Facebook Privacy Policy, available online at http://www.facebook.com/policy.php.\n[8] Facebook Terms of Service, available online at http://www.facebook.com/terms.php.\n[9] MySpace Terms of Service, available online at http://viewmorepics.myspace.com/misc/terms.html.\n[10] MySpace Privacy Policy, available online at http://viewmorepics.myspace.com/misc/privacy.html.\n[11] Friendster Terms of Service, available online at http://www.friendster.com/info/tos.php.\n[12] Friendster Privacy Policy, available online at http://www.friendster.com/info/privacy.php.\n[13] New York Times, August 28, 2005. \"Do You MySpace?\" By Alex Williams.\n[14] Marshall, Matt and Anna Tong. \"Palo Alto, Calif.-based Facebook brings social networking\nonline.\" San Jose Mercury News, August 29, 2005.\n[15] Data Aggregators: A Study of Data Quality and Responsiveness. Pierce, Deborah and Linda\nAckerman. May 19, 2005 http://www.privacyactivism.org/docs/DataAggregatorsStudy.html\n[16] New York University Admissions, \"Fast Facts\", http://admissions.nyu.edu/fast facts/\n[17] Sample Size Calculator, http://www.surveysystem.com/sscalc.htm\n[18] Phone Interview, Daniel Dedap\n[19] Contracts, Copyright, and Confusion: Revisiting the Enforceability of 'Shrinkwrap' Licenses.\nHeath, Steven. Chicago-Kent Intellectual Property Law Society Journal of Intellectual Property.\n\n8.3\nCollege Newspaper Articles\n[20] Sealy, Will. \"What facebook doesnt tell you.\" The Flat Hat, student newspaper of The College\nof William and Mary. http://flathat.wm.edu/story.php?issue=2005-11-04&type=2&aid=3.\nLoaded December 14, 2005.\n[21] Zelkowitz,\nRachel.\n\"\n'Wasted'\nFacebook\ngroup\ncauses\ncon\ntroversy.\"\nThe\nEmory\nWheel\nOnline,\nNovember\n22,\n2005.\nhttp://www.emorywheel.com/vnews/display.v/ART/2005/11/22/43829c13eb4d8.\nLoaded\nDecember 14, 2005.\n[22] \"Public\nSafety\nconsiders\nFacebook\na\nvaluable\ntool\nfor\nparty\nbusts.\"\nThe\nColonnade,\nGeorgia\nCollege\nand\nState\nUniversity.\nNovember\n4,\n2005.\nhttp://www.gcsunade.com/media/paper299/news/2005/11/04/CampusNews/\nPublic.Safety.Considers.Facebook.A.Valuable.Tool.For.Party.Busts-1046210.shtmlLoaded\nDecember 14, 2005.\n[23] Paquin, Christine. \"Administrators advise caution in Facebook postings\" The Dartmouth,\nNovember 21, 2005. http://www.thedartmouth.com/article.php?aid=2005112101070. Loaded\nDecember 14, 2005.\n[24] \"Facebook could invite more than your friends.\" Oregon Daily Emerald, November\n28, 2005. http://www.dailyemerald.com/vnews/display.v/ART/2005/11/28/438aca3122ba8.\nLoaded December 14, 2005.\n[25] Montermini, Fabrizio. \"Facebook Raises Privacy Concerns.\" The Trinity Tripod, Novem\nber 29,\n2005.\nhttp://www.trinitytripod.com/media/paper520/news/2005/11/29/News/\nFacebook.Raises.Privacy.Concerns-1115345.shtml. Loaded December 14, 2005.\n[26] Martucci, Brian. \"As Facebook grows, more than just friends are watching.\" The Mac Weekly,\nDecember 9, 2005. http://www.themacweekly.com/article.php?arid=133. Loaded December\n14, 2005.\n[27] Shoffel,\nJessical.\n\"SUNY-ESF\nwarns\nstudents\nof\nFacebook\ncontent\nvi\nolating\nconduct\ncodes.\"\nThe\nDaily\nOrange,\nDecember\n2,\n2005.\nhttp://www.dailyorange.com/media/paper522/news/2005/12/02/News/\nSunyEsf.Warns.Students.Of.Facebook.Content.Violating.Conduct.Codes-1119079.shtml.\nLoaded December 14, 2005.\n[28] Woo, Stu. \"The Facebook: not just for students.\" The Brown Daily Herald, November 3, 2005.\nhttp://www.browndailyherald.com/media/paper472/news/2005/11/03/CampusWatch/ The-\nFacebook.Not.Just.For.Students-1044229.shtml. Loaded December 14, 2005.\n\n[29] Walker, Rachel. \"UTC cops check Facebook for underage drinkers.\" The Echo online, Novem\nber 10, 2005. http://www.utcecho.com/media/paper483/news/2005/11/10/Culture/Utc-\nCops.Check.Facebook.For.Underage.Drinkers-1053481.shtml. Loaded December 14, 2005.\n[30] McIntyre,\nLuke.\n\"FAILURE\nTO\nCOMMUNICATE:\nDon't\nlet\nFace-\nbook\nland\nyou\nin\njail.\"\nThe\nCarolinian\nOnline,\nNovember\n8,\n2005.\nhttp://www.carolinianonline.com/media/paper301/news/2005/11/08/Opinions/\nFailure.To.Communicate.Dont.Let.Facebook.Land.You.In.Jail-1048102.shtml.\nLoaded\nDe\ncember 14, 2005.\n[31] Kramer, Melody Joy. \"Forfeiting privacy, one post at a time.\" The Daily Pennsylvanian, Novem\nber 30,\n2005. http://www.dailypennsylvanian.com/vnews/display.v/ART/438d34a676ff6.\nLoaded December 14, 2005.\n[32] Wang, Jiao. \"Facebook Profiles Become Handy Tool for Recruiters.\" The Tech, December 13,\n2005. http://www-tech.mit.edu/V125/N61/facebook.html. Loaded December 14, 2005.\nAcknowledgements\nHarvey and Jose would like to thank Hal Abelson, Danny Weitzner, Keith Winstein, and Les Perelman\nfor being available to answer questions and edit a 40-page paper multiple times. We would also like\nto thank the students that took our survey, and the numerous students that took time to discuss\nthe Facebook with us. We would also like to thank Laura Martini and the rest of EC Second West\nfor putting up with us, and the TEPs who gave us feedback. Without Dan Dedap and Sheeva\nAzma, this project would not have happened. Finally interviews we conducted provided invaluable\nbackground and insight.\n9.1\nInterview subjects\n- Andrew Ryder, Assistant Dean, MIT Residential Life Programs\n- Sharon Snaggs, Residential Life Associate, MIT\n- Christopher Varenhorst, MIT Undergraduate\n- Facebook scraper (name withheld)\n- Jeff Gassaway, University of New Mexico Security Administrator\n- Cameron Walker, Fisher College student\n- Daniel Dedap, NYU alumnus, class of 2005\n\nA\nFacebook Privacy Policy\n[7] This policy is effective as of June 28, 2005.\nIntroduction The Facebook Privacy Policy is designed to assist you in understanding how we\ncollect and use the personal information that you provide to us and to assist you in making informed\ndecisions when using the Facebook web site located at www.facebook.com (the \"Web Site\").\nThe Information We Collect When you visit the Web Site you may provide us with two types of\ninformation: personal information you knowingly choose to disclose that is collected by us and Web\nSite use information collected by us on an aggregate basis as you and others browse our Web Site.\nWhen you register on the Web Site, you provide us with certain personal information, such as\nyour name, your email address, your telephone number, your address, your gender, schools attended\nand any other personal or preference information that you provide to us.\nWhen you enter our Web Site, we collect the user's browser type and IP address. This information\nis gathered for all users to the Web Site. In addition, we store certain information from your browser\nusing \"cookies.\" A cookie is a piece of data stored on the user's computer tied to information about\nthe user. We use session ID cookies to confirm that users are logged in. These cookies terminate\nonce the users close the browser. We do not use cookies to collect private information from any\nuser.\nFacebook also collects information about you from other sources, such as newspapers and instant\nmessaging services. This information is gathered regardless of your use of the Web Site.\nChildren Under Age 13 Facebook does not knowingly collect or solicit personal information from\nanyone under the age of 13 or allow such persons to register. If you are under 13, please do not\nsend any information about yourself to us - including information like your name, address, telephone\nnumber, or e-mail address. No one under age 13 is allowed to provide any personal information or\nuse our public forums. In the event that we learn that we have collected personal information from\na child under age 13 without verification of parental consent, we will delete that information as\nquickly as possible. If you believe that we might have any information from or about a child under\n13, please contact us at: info@facebook.com.\nChildren Between the Ages of 13 and 18 We recommend that minors over the age of 13 ask\ntheir parents for permission before sending any information about themselves to anyone over the\nInternet.\nUse of Information Obtained by Facebook When you register on the Web Site, you create your\nown profile and privacy settings. Your profile information, as well as your name, email and photo,\n\nare displayed to people in the groups specified in your privacy settings to support the function of the\nWeb Site. In addition, we may use your name and email address to send you notifications regarding\nthe Web Site and, occasionally, new services we think you may find valuable.\nNo personal information that you submit to Facebook will be available to any user of the Web\nSite who does not belong to at least one of the groups specified by you in your privacy settings.\nWe use the information about you that we have collected from other sources to supplement your\nprofile unless you specify in your privacy settings that you do not want this to be done.\nSharing Your Information with Third Parties We may share your information with third parties,\nincluding responsible companies with which we have a relationship. For example:\n- We may provide information to service providers to help us bring you the services we offer.\nSpecifically, we may use third parties to facilitate our business, such as to send email solici\ntations. In connection with these offerings and business operations, our service providers may\nhave access to your personal information for use in connection with these business activities.\n- We may be required to disclose customer information pursuant to lawful requests, such as\nsubpoenas or court orders, or in compliance with applicable laws. Additionally, we may share\naccount or other information when we believe it is necessary to comply with law or to protect\nour interests or property. This may include sharing information with other companies, lawyers,\nagents or government agencies.\n- If the ownership of all or substantially all of the Facebook business were to change, your\nuser information would likely be transferred to the new owner.\nIf you do not want to\nreceive promotional email from Facebook and/or do not want us to share your informa\ntion with third parties for marketing purposes, please submit a request by clicking here\nhttp://mit.facebook.com/help.php?add=1.\nWe will make every effort to implement any\nchoice you make as soon as possible.\nLinks This site may contain links to other websites. Facebook is not responsible for the privacy\npractices of other web sites. We encourage our users to be aware when they leave our site and to read\nthe privacy statements of each and every web site that collects personally identifiable information.\nThis privacy statement applies solely to information collected by Facebook Web Site.\nThird Party Advertising Advertisements that appear on the Web Site are delivered to users by our\nadvertising partners. Our advertising partners may download cookies to your computer. Doing this\nallows the advertising network to recognize your computer each time they send you an advertisement.\nIn this way, they may compile information about where you, or others who are using your computer,\nsaw their advertisements and determine which advertisements are clicked. This information allows\n\nan advertising network to deliver targeted advertisements that they believe will be of most interest\nto you. Facebook does not have access to or control of the cookies that may be placed by the third\nparty advertisers.\nThis privacy statement covers the use of cookies by Facebook and does not cover the use of\ncookies by any of its advertisers.\nChanging or Removing Information Facebook users may modify or remove any of their personal\ninformation at any time by logging into their account. Information will be updated immediately.\nSecurity Facebook takes appropriate precautions to protect our users' information. Your account\ninformation is located on a secured server behind a firewall. Because email is not recognized as a\nsecure medium of communication, we request that you do not send private information to us by\nemail. If you have any questions about the security of Facebook Web Site, please visit our Help\npage http://mit.facebook.com/help.php for more information..\nChanges in Our Privacy Policy We reserve the right to change our privacy policy at any time.\nIf we do this, we will post the changes to this policy on this page and will indicate at the top of this\npage the policy's effective date. We therefore encourage you to refer to this policy on an ongoing\nbasis so that you understand our current privacy policy.\nContacting the Web Site If you have any questions about this privacy policy, please visit our\nHelp page http://mit.facebook.com/help.php for more information.\nB\nFacebook Terms Of Service\n[8] These Terms of Use are effective as of October 3, 2005.\nIntroduction Welcome to the Facebook, an online directory that connects people through net\nworks of academic and geographic centers. The Facebook service is operated by the Facebook\nnetwork (\"Facebook\"). By using the Facebook web site (the \"Web site\") you signify that you have\nread, understand and agree to be bound by these Terms of Use (this \"Agreement\"). We reserve\nthe right, at our sole discretion, to change, modify, add, or delete portions of these Terms of Use at\nany time without further notice. If we do this, we will post the changes to these Terms of Use on\nthis page and will indicate at the top of this page the Terms of Use's effective date. Your continued\nuse of the Web site after any such changes constitutes your acceptance of the new Terms of Use.\nIf you do not agree to abide by these or any future Terms of Use, please do not use or access Web\nsite. It is your responsibility to regularly review these Terms of Use.\n\nEligibility You must be thirteen years of age or older to register as a member of Facebook or use\nthe Web site. If you are under the age of 13, you are not allowed to register and become a member\nof Facebook or access Facebook content, features and services on the Web Site. Membership in the\nService is void where prohibited. By using the Web site, you represent and warrant that you agree\nto and to abide by all of the terms and conditions of this Agreement. Facebook may terminate your\nmembership for any reason, at any time.\nMember Conduct You understand that the Web site is available for your personal, non-commercial\nuse only. You agree that no materials of any kind submitted through your account will violate or\ninfringe upon the rights of any third party, including copyright, trademark, privacy or other personal\nor proprietary rights; or contain libelous, defamatory or otherwise unlawful material. You further\nagree not to harvest or collect email addresses or other contact information of members from the\nWeb site by electronic or other means for the purposes of sending unsolicited emails or other unso\nlicited communications. Additionally, you agree not to use automated scripts to collect information\nfrom the Web site or for any other purpose. You further agree that you may not use Web site in\nany unlawful manner or in any other manner that could damage, disable, overburden or impair Web\nsite. In addition, you agree not to use the Web site to:\n- upload, post, email, transmit or otherwise make available any content that we deem to be\nharmful, threatening, abusive, harassing, vulgar, obscene, hateful, or racially, ethnically or\notherwise objectionable;\n- impersonate any person or entity, or falsely state or otherwise misrepresent yourself or your\naffiliation with any person or entity;\n- upload, post, email, transmit or otherwise make available any unsolicited or unauthorized\nadvertising, promotional materials, \"junk mail,\" \"spam,\" \"chain letters,\" \"pyramid schemes,\"\nor any other form of solicitation;\n- upload, post, email, transmit or otherwise make available any material that contains software\nviruses or any other computer code, files or programs designed to interrupt, destroy or limit\nthe functionality of any computer software or hardware or telecommunications equipment;\n- intimidate or harass another;\n- use or attempt to use another's account, service or system without authorization from Web\nsite, or create a false identity on this website.\nProprietary Rights in Content on Facebook All content on Web site, including but not limited\nto design, text, graphics, other files, and their selection and arrangement (the \"Content\"), are\n\nthe proprietary property of Facebook or its licensors. All rights reserved. The Content may not\nbe modified, copied, distributed, framed, reproduced, republished, downloaded, displayed, posted,\ntransmitted, or sold in any form or by any means, in whole or in part, without Web site's prior\nwritten permission. You may download or print a copy of any portion of the Content solely for\nyour personal, non-commercial use, provided that you keep all copyright or other proprietary notices\nintact. You may not republish Content on any Internet, Intranet or Extranet site or incorporate the\ninformation in any other database or compilation. Any other use of the Content is strictly prohibited.\nAll trademarks, logos, trade dress and service marks on the Web site are either trademarks or\nregistered trademarks of Facebook or its licensors and may not be copied, imitated, or used, in\nwhole or in part, without the prior written permission of Facebook.\nMember Content Posted on the Site You are solely responsible for the content, photos or\nprofiles Content that you publish or display (hereinafter, \"post\") on the Service, or transmit to\nother Members (collectively the \"Member Content\"). You understand and agree that Facebook\nmay review and delete or remove any Member Content that in the sole judgment of Facebook\nviolate this Agreement or which might be offensive, illegal, or that might violate the rights, harm,\nor threaten the safety of Members.\nBy posting Member Content to any part of the Web site, you automatically grant, and you\nrepresent and warrant that you have the right to grant, to Facebook an irrevocable, perpetual,\nnon-exclusive, transferable, fully paid, worldwide license (with the right to sublicense) to use, copy,\nperform, display, reformat, translate, excerpt (in whole or in part) and distribute such information\nand content and to prepare derivative works of, or incorporate into other works, such information\nand content, and to grant and authorize sublicenses of the foregoing.\nYou may remove your Member Content from the site at any time. If you choose to remove your\nMember Content, the license granted above will automatically expire.\nCopyright Policy Facebook respects the intellectual property rights of others. If you believe your\nwork has been copied in a way that constitutes copyright infringement or are aware of any infringing\nmaterial on the Web site, please contact us at copyright@facebook.com and provide us with the\nfollowing information: an electronic or physical signature of the person authorized to act on behalf\nof the owner of the copyright interest; a description of the copyrighted work that you claim has been\ninfringed; a description of where the material that you claim is infringing is located on the Web site;\nyour address, telephone number, and email address; a written statement by you that you have a\ngood faith belief that the disputed use is not authorized by the copyright owner, its agent, or the\nlaw; a statement by you, made under penalty of perjury, that the above information in your notice is\naccurate and that you are the copyright owner or authorized to act on the copyright owner's behalf.\n\nLinks to other websites The Web site contains links to other web sites. Facebook is not re\nsponsible for the content, accuracy or opinions express in such web sites, and such web sites are\nnot investigated, monitored or checked for accuracy or completeness by us. Inclusion of any linked\nweb site on Facebook Web site does not imply approval or endorsement of the linked web site by\nFacebook. If you decide to leave Facebook Web site and access these third-party sites, you do so\nat your own risk.\nMember Disputes You are solely responsible for your interactions with other Facebook Members.\nFacebook reserves the right, but has no obligation, to monitor disputes between you and other\nMembers.\nPrivacy Facebook cares about the privacy of its members. Click here to view the Web site's\nPrivacy Policy.\nDisclaimers Facebook is not responsible for any incorrect or inaccurate Content posted on the\nWeb site or in connection with the Service, whether caused by users of the Web site, Members or\nby any of the equipment or programming associated with or utilized in the Service. Facebook is\nnot responsible for the conduct, whether online or offline, of any user of the Web site or Member\nof the Service. The Service may be temporarily unavailable from time to time for maintenance or\nother reasons. Facebook assumes no responsibility for any error, omission, interruption, deletion,\ndefect, delay in operation or transmission, communications line failure, theft or destruction or unau\nthorized access to, or alteration of, user or Member communications. Facebook is not responsible\nfor any problems or technical malfunction of any telephone network or lines, computer online sys\ntems, servers or providers, computer equipment, software, failure of email or players on account of\ntechnical problems or traffic congestion on the Internet or at any web site or combination thereof,\nincluding injury or damage to users and/or Members or to any other person's computer related\nto or resulting from participating or downloading materials in connection with the Web and/or in\nconnection with the Service. Under no circumstances will Facebook be responsible for any loss\nor damage, including personal injury or death, resulting from anyone's use of the Web site or the\nService, any Content posted on the Web site or transmitted to Members, or any interactions be\ntween users of the Web site, whether online or offline. THE WEB SITE, THE SERVICE AND\nTHE CONTENT ARE PROVIDED \"AS-IS\" AND FACEBOOK DISCLAIMS ANY AND ALL WAR\nRANTIES, WHETHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION IMPLIED\nWARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE OR\nNON-INFRINGEMENT. FACEBOOK CANNOT GUARANTEE AND DOES NOT PROMISE ANY\nSPECIFIC RESULTS FROM USE OF THE WEB SITE AND/OR THE SERVICE.\n\nLimitation on Liability EXCEPT IN JURISDICTIONS WHERE SUCH PROVISIONS ARE RE\nSTRICTED, IN NO EVENT WILL FACEBOOK BE LIABLE TO YOU OR ANY THIRD PERSON\nFOR ANY INDIRECT, CONSEQUENTIAL, EXEMPLARY, INCIDENTAL, SPECIAL OR PUNITIVE\nDAMAGES, INCLUDING ALSO LOST PROFITS ARISING FROM YOUR USE OF THE WEB SITE\nOR THE SERVICE, EVEN IF FACEBOOK HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH\nDAMAGES. NOTWITHSTANDING ANYTHING TO THE CONTRARY CONTAINED HEREIN,\nFACEBOOK'S LIABILITY TO YOU FOR ANY CAUSE WHATSOEVER, AND REGARDLESS OF\nTHE FORM OF THE ACTION, WILL AT ALL TIMES BE LIMITED TO THE AMOUNT PAID, IF\nANY, BY YOU TO FACEBOOK FOR THE SERVICE DURING THE TERM OF MEMBERSHIP.\nGoverning Law and Venue If there is any dispute about or involving the Web site and/or the\nService, you agree that the dispute will be governed by the laws of the State of California without\nregard to its conflict of law provisions. You also agree to the exclusive jurisdiction and venue of\nthe courts of the state and federal courts of Santa Clara County, California and waive all defenses\nof lack of personal jurisdiction and forum non conveniens. Any cause of action by you with respect\nto the Web site and/or the Service must be instituted within one (1) year after the cause of action\narose or be forever waived and barred.\nIndemnity You agree to indemnify and hold Facebook, its subsidiaries, affiliates, officers, agents,\nand other partners and employees, harmless from any loss, liability, claim, or demand, including\nreasonable attorney's fees, made by any third party due to or arising out of your use of the Service\nin violation of this Agreement or your violation of any law or the rights of a third party.\nOther These Terms of Use constitute the entire agreement between you and Facebook regarding\nthe use of the Web site and/or the Service, superseding any prior agreements between you and\nFacebook relating to your use of the Web site or the Service. The failure of Facebook to exercise\nor enforce any right or provision of these Terms of Use shall not constitute a waiver of such right or\nprovision. If any provision of this Agreement is held invalid, the remainder of this Agreement shall\ncontinue in full force and effect.\nQuestions Please visit our Help page for more information.\nC\nFacebook \"Spider\" Code: Acquisition and Processing\nThe following code extracts all Facebook accounts from a given school that are accessible given the\nuser account provided.\n\nC.1\nData Downloading BASH Shell Script\nwget --cookies=on --user-agent='Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US;\nrv:1.7.12) Gecko/20050915 Firefox/1.0.7' --save-cookies=cookies.txt\n--keep-session-cookies --load-cookies=cookies.txt\n'http://www.facebook.com/login.php?email=LOGIN&pass=PASS'\nfor (( COUNT = USERID_LOW ; COUNT <= USERID_HIGH; COUNT++ ))\ndo\nwget --cookies=on --wait=12 --random-wait --user-agent='Mozilla/5.0 (Windows;\nU; Windows NT 5.1; en-US; rv:1.7.12) Gecko/20050915 Firefox/1.0.7'\n--save-cookies=cookies.txt --keep-session-cookies --load-cookies=cookies.txt\nhttp://SCHOOL.facebook.com/profile.php?id=$COUNT\ndone\nC.2\nFacebook Profile to Tab Separated Variable Python Script\nimport string\nimport sys\nimport re\nimport os\nhtmltag = re.compile('<.*?>')\ndef make_search(str):\nlam = lambda data: re.search(\".*%s\\:.*\" % str, data)\nreturn lam\ndef strip_html(data):\nreturn htmltag.sub(\"\", data)\nattrib=[\"Name\", \"Member Since\", \"Last Update\", \"School\", \"Status\", \"Sex\",\n\"Concentration\", \"Residence\", \"Mailbox\", \"Hometown\", \"High School\",\n\"Screenname\", \"Mobile\", \"Site\", \"Interests\", \"Clubs and Jobs\", \"Favorite\nMusic\", \"Favorite Movies\", \"Favorite Books\"]\n\nlambdas = map(make_search, attrib)\ndef process(fname):\nf = open(fname, \"r\")\ndata = f.read()\ndbak = data\ntry:\nfriendstr = string.split(data, \"category_id=2\")[1]\nfriends = string.split(friendstr, \" \")[0][2:]\nexcept IndexError:\nfriends= \"\"\ntry:\ndata = string.split(data, \"<h2>Information</h2>\")[1]\ndata = string.split(data, \"<!-- userprofile -->\")[0]\nexcept IndexError:\nsys.stderr.write(\"Error! %s\" % fname)\ndata = dbak\nif len(string.split(data, \"Groups\")) == 2:\ndata = string.split(data, \"Groups\")[0]\ndata = string.split(data, \"\\n\")\ndata = map(strip_html, data)\nfields=[\"\"]*len(attrib)\nfor x in range(len(attrib)):\nfield = filter(lambdas[x], data)\nif field == []:\nfields[x] = \"\"\nelse:\nfields[x] = string.split(field[0], \":\")[1]\nif attrib[x] == \"Name\":\nfields[x] = string.split(fields[x], \"&\")[0]\nfor f in fields:\n\nprint f, \"\\t\",\nprint friends\nfor f in os.listdir(sys.argv[1]):\nif f[:5] == \"profi\":\nprocess(sys.argv[1]+\"/\"+ f)\nC.3\nData Analysis Scripts\nC.3.1\nThe after date script.\nimport string\nimport sys\n# usage: python afterdate.py col val\n# afterdate prints all records whose column #col is after val\n# val is of the form yyyymmdd\ncol = int(sys.argv[1])\nval = string.strip(sys.argv[2])\ns = \"foo\"\nmonth={\"January\":\"01\",\n\"February\":\"02\",\n\"March\":\"03\",\n\"April\":\"04\",\n\"May\":\"05\",\n\"June\":\"06\",\n\"July\":\"07\",\n\"August\":\"08\",\n\"September\":\"09\",\n\"October\":\"10\",\n\"November\":\"11\",\n\"December\":\"12\",}\nwhile True:\n\ntry:\ns = raw_input()\nexcept EOFError:\nbreak\ntry:\nfield = string.strip(string.split(s, \"\\t\")[col])\nexcept IndexError:\nsys.stderr.write(\"PROCESS ERROR\\n\")\ncontinue\nfs = string.split(field)\nif len(field) > 2:\ndate = int(\"%s%s%02i\" % (fs[2], month[fs[0]], int(fs[1][:-1])))\nif date> int(sys.argv[2]):\nprint s\nC.3.2\nThe bin count script.\nimport string\nimport os\nimport sys\nvals=[0]*150\ncol = int(sys.argv[1])\nbin = int(sys.argv[2])\ns = \"foo\"\nwhile True:\ntry:\ns = raw_input()\nexcept EOFError:\nbreak\ntry:\n\nfield = string.split(s, \"\\t\")[col]\nexcept IndexError:\nprint \"PROCESS ERROR\"\ncontinue\nif field == \"one\":\nfield = \"1\"\nif field == \"\":\ncontinue\ntry:\nfval = int(field)\nexcept ValueError:\nprint \"ERROR:\", field\ntry:\nvals[fval/10] += 1\nexcept IndexError:\nprint len(vals)\nprint \"ERROR:\" + str(fval)\nif int(sys.argv[2]) == 1:\nfor k in vals:\nprint k\nC.3.3\nThe bin date script.\nimport string\nimport sys\n# usage: bindate col\n# col = number of column to use MUST BE A DATE COLUMN\n# bindate prints the number of records where\n# column #col = January 2004, then February 2004, etc.\ncol = int(sys.argv[1])\n\ns = \"foo\"\nmonth={\"January\":\"01\",\n\"February\":\"02\",\n\"March\":\"03\",\n\"April\":\"04\",\n\"May\":\"05\",\n\"June\":\"06\",\n\"July\":\"07\",\n\"August\":\"08\",\n\"September\":\"09\",\n\"October\":\"10\",\n\"November\":\"11\",\n\"December\":\"12\",}\nyear={\n\"2004\": 0,\n\"2005\": 1}\nbins=[0]*24\nwhile True:\ntry:\ns = raw_input()\nexcept EOFError:\nbreak\ntry:\nfield = string.strip(string.split(s, \"\\t\")[col])\nexcept IndexError:\nsys.stderr.write(\"PROCESS ERROR\\n\")\ncontinue\nfs = string.split(field)\nif len(field) > 2:\nbins[year[fs[2]]*12 + int(month[fs[0]])-1] += 1\n\nfor x in range(len(bins)):\ny = str(2004 + x/12)\nm = str((x % 12) + 1)\nprint bins[x]\n#\nprint \"%s/%s\\t%i\" % (m, y, bins[x])\nC.3.4\nThe count number script.\nimport string\nimport os\nimport sys\n# countnumber col printall\n# Countnumber reads from stdin and generates a histogram of the column\n# col = the column to read from\n# printall = whether to print each individual value\nvals={}\ncol = int(sys.argv[1])\ns = \"foo\"\nn = 0\nwhile True:\ntry:\ns = raw_input()\nexcept EOFError:\nbreak\ntry:\nfield = string.split(s, \"\\t\")[col]\nexcept IndexError:\nprint \"PROCESS ERROR\"\ncontinue\n\nif n % 500 == 0:\nprint field\nif field in vals.keys():\nvals[field]+=1\nelse:\nvals[field] = 1\nn += 1\nif int(sys.argv[2]) == 1:\nfor k in vals.keys():\nprint k, \"\\t\", vals[k]\nif \" \" in vals.keys():\nprint \"BLANK : \", vals[\" \"]\nprint \"NOTBLANK : \", n - vals[\" \"]\nprint \"TOTAL : \", n\nC.3.5\nThe filter field script.\nimport string\nimport sys\n# usage: python filterfield.py col val\n# if col is equal to val, print this record\n# otherwise, do nothing\ncol = int(sys.argv[1])\nval = string.strip(sys.argv[2])\ns = \"foo\"\nwhile True:\ntry:\ns = raw_input()\nexcept EOFError:\nbreak\n\ntry:\nfield = string.strip(string.split(s, \"\\t\")[col])\nexcept IndexError:\nsys.stderr.write(\"PROCESS ERROR\\n\")\ncontinue\nif field == val:\nprint s\nC.3.6\nThe greater than script.\nimport string\nimport os\nimport sys\nvals=[0]*150\ncol = int(sys.argv[1])\nval = int(sys.argv[2])\ns = \"foo\"\nwhile True:\ntry:\ns = raw_input()\nexcept EOFError:\nbreak\ntry:\nfield = string.split(s, \"\\t\")[col]\nexcept IndexError:\nprint \"PROCESS ERROR\"\ncontinue\nif field == \"one\":\nfield = \"1\"\nif field == \"\":\n\ncontinue\ntry:\nfval = int(field)\nexcept ValueError:\nprint \"ERROR:\", field\ntry:\nif fval > val:\nprint s\nexcept IndexError:\nprint len(vals)\nprint \"ERROR:\" + str(fval)\n\nWhich gender describes you best? n=419\n3%\nMale\n44%\n53%\nNumber\nPercentage\nNo Response\nFemale\nFigure 11: Gender of survey takers\nD\nSupplemental Data\nIn this section, we included the numerical results of the numerous analyses we performed on the\ndata we collected from users and directly from Facebook. We referred to many, but not all, of these\nfigures earlier. This data is useful alone in looking for trends and correlations that did not find their\nway into this paper.\n\nWhich best describes your living arrangements? n=419\nHouse\n10.74%\n0.24%\n0.24%\n0.95%\n0.95%\n0.24%\n0.48%\n20.76%\n0.48%\n25.54%\n0.24%\n0.48%\n0.48%\n2.15%\n0.48%\n0.72%\n0.95%\n0.24%\n0.48%\n0.24%\n0.24%\n0.24%\n0.24%\n10.02%\n1.43%\n0.24%\n0.24%\n0.24%\n0.24%\n0.24%\n15.04%\n1.67%\n0.24%\nWILG\n2.39%\n0.24%\nNumber Responding\nPercentage\nNo Response\nAlpha Chi Omega\nAlpha Epsilon Phi\nAlpha Phi\nBaker House\nBeta Theta Pi\nBexley Hall\nBurton Conner House\nChi Phi\nEast Campus\nKappa Alpha Theta\nKappa Sigma\nLambda Chi Alpha\nMacGregor House\nMcCormick Hall\nNew House\nNext House\nNo. 6\nPhi Delta Theta\nPhi Kappa Sigma\nPhi Kappa Theta\nPi Lambda Phi\nPika\nRandom Hall\nSenior House\nSidney-Pacific\nSigma Alpha Epsilon\nSigma Chi\nSigma Kappa\nSigma Nu\nSimmons Hall\nTau Epsilon Phi\nTheta Xi\nZeta Beta Tau\nFigure 12: Chart of survey takers over dorms and ILGs.\n\nFigure 13: Distribution of survey takers over dorms and ILGs.\nWhat is your student status? n=419\n2.39%\nUndergrad\n90.69%\n3.1%\nAlumnus\n3.34%\nNumber\nPercentage\nNo Answer\nGrad Student\nFigure 14: Status of survey takers\n\nFacebook Logins Per Week n=371\n37.47%\n25.61%\n17.25%\n10.78%\n8.89%\nNumber\nPercentage\nNumber Male\nNumber Female\n1 to 3\n4 to 8\n9 to 15\n20 to 30\n31 or more\nFigure 15: Logins per week\n\nNumber of friends n=378\nMales\n1.32%\n14.81%\n30.95%\n37.83%\n12.96%\n2.12%\nNumber\nPercentage\nFemales\n1 to 10\n11 to 50\n51 to 100\n101 to 200\n201 to 349\n350 or more\nFigure 16: Number of Friends at MIT\n\nPercentage of friends from MIT n=372\nMales\n1-15%\n1.34%\n16-33%\n11.56%\n34-50%\n28.76%\n51-75%\n46.77%\n76-100%\n11.56%\nNumber\nPercentage\nFemales\nFigure 17: Percentage of Friends from MIT\n\nNumber Allowing Strangers To Friend n=383\nMales\nNo\n63.45%\n7.83%\nSometimes\n28.72%\nNumber\nPercentage\nFemales\nYes\nFigure 18: Analysis of users friending strangers on Facebook\n\nFacebook and My Privacy: Familiarity and Utilization n=419\nMales\nMales\nNo\nNumber Familiar\nFemales\nNumber Using\nFemales\nNo Answer\nYes\nFigure 19: My Privacy, and knoweldge and utilization thereof\n\nHow concerned are you about Facebook and privacy? n=329\nMales\n23.1%\n35.56%\nSomewhat\n31.61%\nQuite\n6.08%\n3.65%\nNumber\nPercentage\nFemales\nNot at all\nBarely\nVery Concerned\nFigure 20: Concern for Facebook Privacy\n\nReading of Facebook Terms of Service and Privacy Policy n=419\nNo\nRead TOS?\nPercentage\nRead PP?\nPercentage\nNo Answer\n7.16 %\n6.92 %\n84.25 %\n82.82 %\nYes\n8.59 %\n10.26 %\nFigure 21: Most users do not read the policies that regulate their Facebook use.\n\nPercentage\n10.74 %\n41.53 %\n47.73 %\nCan Facebook Share Information? n=419\nNumber Responding\nNo Answer\nNo\nYes\nFigure 22: Users are split on whether or not Facebook can share your information with other\ncompanies, indicating a guess.\nFamiliarity with \"My Photo\" feature and policies. n=419\nFamiliar\nNo Answer\nNo\nYes\nPercentage\n7.16%\n11.22%\n81.62%\nCan you restrict access?\nPercentage\n20.05%\n33.17%\n46.78%\nFigure 23: Are you familiar with \"My Photo?\" Can you restrict access to it?\n\nDoes Facebook do an adequate job in protecting your privacy? n=419\nMales\n24.34%\nNo\n33.17%\n42.24%\nNumber\nPercentage\nFemales\nNo Answer\nYes\nFigure 24: Users show indifference and approval for Facebook's security practices.\n\nDistributions Of Facebook User Categories At Four Universities\nMIT\nOklahoma\nNYU\nSize\nNumber Reporting Gender: Distribution\nMales\n48.21%\n44.52%\n35.18%\nFemales\n30.95%\n44.27%\n49.07%\nClass Distribution: Graduating class of year indicated, self reported.\nOther\n2.36%\n6.72%\n9.5%\n10.94%\n11.82%\n12.66%\n11.48%\n1.16%\n33.37%\n0.39%\n3.16%\n11.17%\n14.83%\n15.26%\n15.83%\n13.51%\n0.81%\n25.03%\n0.81%\n3.89%\n10.7%\n13.58%\n15.59%\n16.25%\n16.5%\n0.24%\n22.44%\nHarvard\n42.03%\n33.46%\n4.94%\n7.61%\n9.04%\n9.34%\n9.63%\n10.06%\n8.92%\n0.74%\n39.72%\nUser Distribution: Kinds of Users at each school. (\"Undergraduate\" unique to OU.)\nAlumnus/Alumna\nFaculty\nGrad Student\nStaff\nStudent\nSummer Student\nUndergraduate\n-\n27.75%\n0.95%\n10.53%\n2.01%\n58.61%\n0.12%\n-\n13.37%\n0.41%\n6.59%\n0.94%\n52.27%\n0.02%\n26.31%\n-\n19.15%\n0.74%\n6.12%\n0.76%\n73.11%\n0.11%\n-\n39.49%\n1.17%\n10.89%\n2.47%\n45.55%\n0.15%\n-\n-\nFigure 25: Summary of Facebook usage statistics at four schools: the Massachusetts Institute of\nTechnology, University of Oklahoma, New York University, and Harvard University.\n\nMIT\nOklahoma\nNYU\nResidence\nMobile\nInterests\nClubs/Jobs\nMusic\nMovies\nGender\nMIT\nOklahoma\nNYU\nResidence\nMobile\nInterests\nClubs/Jobs\nMusic\nMovies\nGender\nWillingness to Share Personal Information at each school.\nAll Students\nHarvard\n64.46 %\n36.11 %\n46.9 %\n24 %\nHigh School\n65.46 %\n81.03 %\n74.34 %\n40.96 %\nScreen Name\n54.11 %\n54.55 %\n65.42 %\n46.12 %\n21.19 %\n13.24 %\n13.94 %\n48.35 %\n55.5 %\n75.84 %\n66.7 %\n48.49 %\n42.38 %\n66.15 %\n50.32 %\n49.34 %\n52.8 %\n78.39 %\n66.69 %\n51.36 %\n50.9 %\n76.62 %\n65.67 %\n60.25 %\nBooks\n49.31 %\n68.44 %\n62.47 %\n63.5 %\n79.16 %\n88.78 %\n84.25 %\n75.5 %\nAfter 10/1/05\nHarvard\n80.71 %\n40.48 %\n58.59 %\n79.5 %\nHigh School\n83.73 %\n88.71 %\n87.51 %\n81.07 %\nScreen Name\n70.49 %\n60.22 %\n77.05 %\n63.52 %\n28.27 %\n14.28 %\n16.46 %\n33.01 %\n73.07 %\n83.8 %\n79.62 %\n70.93 %\n57.88 %\n74.1 %\n60.04 %\n58.06 %\n70.59 %\n86.93 %\n79.89 %\n68.76 %\n68.49 %\n84.93 %\n100 %\n67.03 %\nBooks\n66.1 %\n75.93 %\n74.55 %\n67.01 %\n93.1 %\n95.53 %\n94.46 %\n90.48 %\nTotal\n100 %\n100 %\n100 %\n100 %\nFigure 26: Willingness of Facebook users to disclose personal information on the service, at four\nschools, showing all users and only those who have updated their profiles on or after October 1,\n2005.\n\nMales\nMIT\nOklahoma\nNYU\nResidence\nMobile\nInterests\nClubs/Jobs\nMusic\nMovies\nGender\nMIT\nOklahoma\nNYU\nResidence\nMobile\nInterests\nClubs/Jobs\nMusic\nMovies\nGender\nWillingness to Share Personal Information at each school, by gender.\nHarvard\n77.69 %\n38.1 %\n52.2 %\n77.79 %\nHigh School\n77.02 %\n86.44 %\n81.32 %\n73.44 %\nScreen Name\n64.99 %\n59.9 %\n73.36 %\n56.61 %\n29.65 %\n20.97 %\n22.21 %\n32.98 %\n66.7 %\n88.99 %\n74.44 %\n62.73 %\n50.18 %\n69.59 %\n56.36 %\n50.53 %\n63.86 %\n84.29 %\n74.96 %\n61.28 %\n60.37 %\n81.5 %\n73.3 %\n59.5 %\nBooks\n58.01 %\n72.41 %\n68.59 %\n59.11 %\n100 %\n100 %\n100 %\n100 %\nFemales\nHarvard\n80.67 %\n40.95 %\n55.59 %\n81.68 %\nHigh School\n83.89 %\n90.36 %\n87.73 %\n77.05 %\nScreen Name\n67.14 %\n59 %\n75.12 %\n58.48 %\n20.54 %\n8.06 %\n11.61 %\n26.55 %\n66.89 %\n81.81 %\n76.55 %\n63.35 %\n53.36 %\n73.71 %\n58.03 %\n51.58 %\n64.24 %\n85.55 %\n76.65 %\n61.01 %\n64.2 %\n84.49 %\n76.19 %\n60.59 %\nBooks\n62.42 %\n75.94 %\n73 %\n61.2 %\n100 %\n100 %\n100 %\n100 %\nFigure 27: Willingness of Facebook users to disclose personal information on the service, at four\nschools, by gender.\n\nJoin\nWhen Users Join And Update Facebook at MIT\nMonth Of\nUpdate\n2007 Join\n2008 Join\n2009 Join\nMar 1, 04\n13.55 %\n0 %\n33.76 %\n0.3 %\n0 %\nApr 1, 04\n10.96 %\n0 %\n20.57 %\n0.89 %\n0 %\nMay 1, 04\n7.49 %\n0 %\n8.76 %\n9.65 %\n0 %\nJun 1, 04\n4.1 %\n0 %\n2.22 %\n14.07 %\n0.11 %\nJul 1, 04\n4.24 %\n0.26 %\n1.9 %\n19.49 %\n0.43 %\nAug 1, 04\n4.89 %\n0.32 %\n3.9 %\n19.29 %\n0.22 %\nSep 1, 04\n5.02 %\n0.57 %\n2.85 %\n16.24 %\n0.11 %\nOct 1, 04\n3.42 %\n0.75 %\n2.74 %\n6.3 %\n0.11 %\nNov 1, 04\n2.99 %\n0.88 %\n2.11 %\n2.95 %\n0 %\nDec 1, 04\n2.87 %\n0.98 %\n2.22 %\n2.07 %\n0.33 %\nJan 1, 05\n3.05 %\n0.91 %\n2.85 %\n0.49 %\n0.22 %\nFeb 1, 05\n2.82 %\n1.45 %\n2.22 %\n0.98 %\n0.11 %\nMar 1, 05\n2.44 %\n1.38 %\n1.48 %\n0.89 %\n0.11 %\nApr 1, 05\n2.29 %\n1.48 %\n1.27 %\n1.08 %\n0.54 %\nMay 1, 05\n6.42 %\n2.71 %\n1.37 %\n0.69 %\n34.96 %\nJun 1, 05\n4.99 %\n3.67 %\n1.58 %\n0.49 %\n22.91 %\nJul 1, 05\n4.19 %\n3.7 %\n1.16 %\n0.2 %\n15.42 %\nAug 1, 05\n4.71 %\n7.07 %\n1.27 %\n1.38 %\n16.83 %\nSep 1, 05\n4.18 %\n13.3 %\n2.53 %\n1.57 %\n4.78 %\nOct 1, 05\n3.55 %\n24.02 %\n2.22 %\n0.69 %\n2.39 %\nNov 1, 05\n1.82 %\n36.55 %\n1.05 %\n0.3 %\n0.43 %\nTotal\n100 %\n85.03 %\n11.82 %\n12.67 %\n11.48 %\nFigure 28: Facebook usage data for the Massachusetts Institute of Technology.\n\nJoin\nWhen Users Join And Update Facebook at U. Oklahoma\nMonth Of\nUpdate\n2007 Join\n2008 Join\n2009 Join\nAug 1, 04\n0.01 %\n0 %\n0.03 %\n0 %\n0 %\nSep 1, 04\n2.25 %\n0.03 %\n4.64 %\n4.16 %\n0.11 %\nOct 1, 04\n4.86 %\n0.02 %\n8.36 %\n10.03 %\n0.11 %\nNov 1, 04\n19.65 %\n0.2 %\n26.75 %\n34.56 %\n0.89 %\nDec 1, 04\n13.69 %\n0.42 %\n15.07 %\n13.71 %\n0.78 %\nJan 1, 05\n6.98 %\n0.36 %\n7.17 %\n5.97 %\n0.89 %\nFeb 1, 05\n7.09 %\n0.51 %\n6.84 %\n5.81 %\n1.49 %\nMar 1, 05\n4.2 %\n0.65 %\n3.52 %\n2.73 %\n1.38 %\nApr 1, 05\n5.07 %\n0.81 %\n4.01 %\n3.46 %\n3.61 %\nMay 1, 05\n4.33 %\n1.19 %\n3.39 %\n2.63 %\n7.29 %\nJun 1, 05\n4.55 %\n0.96 %\n2.34 %\n2.25 %\n15.39 %\nJul 1, 05\n5.62 %\n1.47 %\n2.47 %\n2.32 %\n24.16 %\nAug 1, 05\n8.2 %\n3.02 %\n4.18 %\n4.16 %\n29.93 %\nSep 1, 05\n6.22 %\n6.65 %\n5.73 %\n4.25 %\n9.63 %\nOct 1, 05\n5.44 %\n17.82 %\n4.28 %\n3.14 %\n3.57 %\nNov 1, 05\n1.85 %\n65.89 %\n1.22 %\n0.83 %\n0.78 %\nTotal\n100 %\n93.92 %\n15.28 %\n15.84 %\n13.52 %\nFigure 29: Facebook usage data for the University of Oklahoma.\n\nWhen Users Join And Update Facebook at NYU\nMonth Of\nJoin\nMar 1, 04\n2.7 %\nApr 1, 04\n13.57 %\nMay 1, 04\n7.56 %\nJun 1, 04\n3.18 %\nJul 1, 04\n3.92 %\nAug 1, 04\n6.11 %\nSep 1, 04\n6.77 %\nOct 1, 04\n5.65 %\nNov 1, 04\n5.01 %\nDec 1, 04\n3.88 %\nJan 1, 05\n3.29 %\nFeb 1, 05\n2.8 %\nMar 1, 05\n3.11 %\nApr 1, 05\n4.13 %\nMay 1, 05\n6.03 %\nJun 1, 05\n5.34 %\nJul 1, 05\n5.05 %\nAug 1, 05\n4.81 %\nSep 1, 05\n3.87 %\nOct 1, 05\n2.69 %\nNov 1, 05\n0.53 %\nTotal\n100 %\nUpdate\n0 %\n0 %\n0 %\n0.01 %\n0.08 %\n0.11 %\n0.24 %\n0.44 %\n0.64 %\n0.72 %\n0.76 %\n0.8 %\n1 %\n1.25 %\n2.15 %\n2.16 %\n2.37 %\n4.49 %\n8.66 %\n21.5 %\n52.61 %\n89.95 %\n2007 Join\n2008 Join\n2009 Join\n9.04 %\n33.43 %\n8.78 %\n1.95 %\n1.87 %\n3.58 %\n5.95 %\n5.64 %\n3.69 %\n2.88 %\n3.43 %\n2.13 %\n1.64 %\n1.9 %\n2.31 %\n2.05 %\n1.56 %\n2.75 %\n3.3 %\n1.84 %\n0.29 %\n15.59 %\n0.07 %\n0 %\n0.45 %\n0.12 %\n5.43 %\n0.07 %\n5.73 %\n0.02 %\n14.11 %\n0.02 %\n23.85 %\n0.07 %\n18.34 %\n0.02 %\n9.52 %\n0.07 %\n5.21 %\n0.1 %\n2.39 %\n0.07 %\n1.72 %\n0.05 %\n1.45 %\n0 %\n1.15 %\n4.39 %\n1.3 %\n10.53 %\n2.04 %\n20.58 %\n1.5 %\n20.85 %\n1.27 %\n19.63 %\n1.77 %\n15.24 %\n1.62 %\n6.16 %\n0.9 %\n1.69 %\n0.17 %\n0.29 %\n16.25 %\n16.51 %\nFigure 30: Facebook usage data for New York University.\nE\nSelected Survey Comments\nThe paper and web form survey we gave to users provided space for user feedback. The feedback\nwe received was insightful. Of 441 respondents, 129 (29%) found the need to tell us their thoughts.\nWe strongly recommend that Facebook read and consider this valuable user feedback.\nAll included feedback results are as entered by the users.\nE.1\nUser Feedback\n- Facebook doesn't really secure your data... but then again you're putting it up for the world\nto see.\n- give me a break. all of this information is readily available to anyone will to put 15 minutes\ninto stalking a person. Facebook is not a tool of big brother.\n- I don't give them much personal data anyway.\n\nWhen Users Join And Update Facebook at Harvard\nMonth Of\nJoin\nMar 1, 04\n32.18 %\nApr 1, 04\n7.83 %\nMay 1, 04\n3.94 %\nJun 1, 04\n4.8 %\nJul 1, 04\n2.77 %\nAug 1, 04\n2.32 %\nSep 1, 04\n4.02 %\nOct 1, 04\n3.14 %\nNov 1, 04\n2.19 %\nDec 1, 04\n2.23 %\nJan 1, 05\n2.15 %\nFeb 1, 05\n2.36 %\nMar 1, 05\n2.27 %\nApr 1, 05\n1.83 %\nMay 1, 05\n1.61 %\nJun 1, 05\n1.95 %\nJul 1, 05\n7.12 %\nAug 1, 05\n3.36 %\nSep 1, 05\n3.5 %\nOct 1, 05\n3.59 %\nNov 1, 05\n3.04 %\nDec 1, 05\n1.8 %\nTotal\n100 %\nUpdate\n0 %\n0 %\n0 %\n0 %\n0.01 %\n0.21 %\n0.36 %\n0.49 %\n0.77 %\n1.01 %\n0.96 %\n1.21 %\n1.34 %\n1.46 %\n1.65 %\n2.67 %\n3.35 %\n3.22 %\n5.86 %\n9.9 %\n20.15 %\n45.81 %\n81.29 %\n2007 Join\n2008 Join\n2009 Join\n62.28 %\n4.68 %\n4.15 %\n1.81 %\n0.94 %\n0.58 %\n2.22 %\n1.93 %\n1.87 %\n1.87 %\n1.52 %\n1.11 %\n1.64 %\n0.64 %\n0.76 %\n1.05 %\n1.87 %\n1.23 %\n2.11 %\n2.05 %\n2.16 %\n1.52 %\n9.66 %\n1.18 %\n0.57 %\n0.78 %\n0.25 %\n0.5 %\n0 %\n16.69 %\n0.44 %\n11.54 %\n0.19 %\n11.43 %\n0.25 %\n24.15 %\n0.25 %\n10.92 %\n0.06 %\n2.86 %\n0.06 %\n1.51 %\n0 %\n1.06 %\n0.25 %\n1.23 %\n0.32 %\n0.84 %\n0.19 %\n1.06 %\n0.13 %\n0.78 %\n0.13 %\n1.34 %\n0.38 %\n1.74 %\n58.75 %\n1.4 %\n16.11 %\n2.63 %\n12.44 %\n3.98 %\n7.26 %\n2.07 %\n1.39 %\n0.28 %\n0.57 %\n10.08 %\n8.94 %\nFigure 31: Facebook usage data for Harvard University.\n- I dont really care about my privacy on the facebook because i lie in my profile a lot\n- I set the option that prevents non-friends from seeing my cell phone number.\n- I think people need to be aware that anything they put on Facebook is public domain. Even\nthough I'm not sure of the legalities, I don't put information up that is too personal (phone\nnumbers, etc.)\n- I think that it is primarily the users' responsibility to be careful what is placed up on the\nfacebook; not the other way around.\n- I think you should have to approve a tagged pictured before it goes up rather than having to\ncheck periodically to see if any pictures are not something you want up, having to untag it\nand possibly report it.\n- I wish I could automatically block all photo \"tags\"\n\n- it is hard to tell whether ppl take facebook seriously or goof off with it, the my photo is nice\nbut needs a seurity on it as well - asking permission of the people in it ahead of time etc.\n- Since you willingly submit information to Facebook - such as your name, age, gender, etc.\n- you should be fully aware that practically anyone from your school can view your personal\ninformation if you do not change your privacy settings; that Facebook can share your infor\nmation with third-party companies is somewhat alarming, but there is an option to request\nthat your information is not shared with third-parties.\n- the photo feature is highly questionable, especially since users other than yourself can \"tag\"\nyou in their photos.\n- There are appropriate options, but only if you take advantage/know about them\n- They need to support SSL.\n- To clarify my privacy concerns, I treat Facebook like any other open internet forum, and filter\nthings through the concern that anyone may view the information. Since my peers have such\neasy access to the data and can be sure it actually belongs to me, I am even more careful\nabout posting information (such as my sexuality) that I might not want acquaintances from\nhigh school asking about. Basically, I put the burden of protecting my privacy on myself via\nposting responsibly, not on Facebook via restricting access to what I choose to post.\n- what i think is interesting is that third parties can post photos of you and link them to you\nand it is unclear to me if you have any control over that or who can view those.\n- When I place information on thefacebook, I do so specifically because I want it to be in the\npublic domain. There is obviously information that I would like to keep private, but I don't\nplace it on thefacebook.\nF\nPaper Survey\nThe paper survey follows. The web form survey asked the same questions, plus an additional\nquestion: \" How concerned are you about the privacy of your data on the Facebook?\" Possible\nanswers here were: N/A, Not, Barely, Somewhat, Quite, Very.\n\nFacebook Privacy Study: Survey\nFR E E C A N D Y\nI s r c i ns: Please circle your answ ers honestly.You m ay skip any question you do not\nn t u t o\nw ish to answ er.Please D O N O T w rite nam e,e-m ail,or other contact inform ation on this\nform .\n1. W hich gender describes you best? (please circle one)...........M A LE\nFE M A LE\n2. W hich category describes you best? (circle one)\nU N D E R G R A D U A TE\nG R A D STU D E N T\nPO STD O C\nFA C U LTY\nSTA FF\nO TH E R\n3. W hich best describes your current living situation?\nD O R M ITO R Y: (please specify)\nFSILG : (please specify)\nO FF C A M PU S /N O N -M IT H O U SIN G\nO TH E R\n4. D o you currently have a Facebook account on w w w .facebook.com ?\nN O - D id you ever?\nN O\nYE S\nYE S - W hen did you create your account?\nD O N 'T K N O W /FO R G O T\nJA N\nFE B\nM A R\nA PR\nM A Y\nJU N\nJU L\nA U G\nSE P\nO C T\nN O V\nD E C\n5. A pproxim ately how m any tim es a w eek do you log in to the Facebook?\n1-3\n4-8\n9-15\n20-30\n31+\nD O N 'T K N O W\n6. A pproxim ately how m any Facebook friends do you have from M IT?\n1-10 11-50 51-100\n101-200\n200-350\n> 350\n7. A pproxim ately w hat percentage ofallofyour friends are from M IT?\n0-15%\n16-33%\n34-50%\n50-75%\n75-100%\n8. D o you ever friend people w hom you have never m et in person?\nN E V E R\nSO M E TIM E S\nA LW A YS\n9. A re you fam iliar w ith Facebook's \"M y Privacy\" feature,that lets you controlw ho m ay\nview your profile?..... ... ... ... ... ... ... .................................\nN O\nYE S\n10.D o you use the \"M y Privacy\" feature to controlw ho m ay view your profile?\nN O\nYE S\n11.H ave you ever read Facebook's Term s ofService in full?.............. N O\nYE S\n12.H ave you ever read Facebook's Privacy Policy in full?.................. N O\nYE S\n13.C an Facebook share your inform ation w ith other com panies?....... N O\nYE S\n14.A re you fam iliar w ith Facebook's \"M y Photo\" feature?................. N O\nYE S\n15.C an you prevent other Facebook users from seeing your photos?...N O\nYE S\n16.D oes Facebook do an adequate job in securing your personaldata?N O\nYE S\nPlease use the back ofthis form to m ake any additionalcom m ents you m ay have.\nTH A N K YO U !"
    },
    {
      "category": "Resource",
      "title": "foia.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/2870554b75b971a5c131ffc26b92f81b_foia.pdf",
      "content": "The Freedom of Information Act:\nHolding Government Accountable\nDaniel Peng\nDecember 15, 2005\n\nContents\n1 Introduction\n2 The Fiction of FOIA Accountability\n3 The Problem: Legal basis and empirical evidence\n3.1 Delay . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2 Improperly withheld and redacted records . . . . . . . . . . . . . . . . . . .\n3.3 Administrative Accountability . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.4 Government Motivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4 The Solution: Imposing consequences and accountability\n4.1 Delay . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2 Tracking and computerization . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.3 Improperly withheld and redacted records . . . . . . . . . . . . . . . . . . .\n5 Conclusion\nIntroduction\nA democracy works best when the people have all the information that the security\nof the nation permits. No one should be able to pull curtains of secrecy around\ndecisions which can be revealed without injury to the public interest.\n-- President Lyndon B. Johnson, signing FOIA into law.\nConcerned citizens have long hailed FOIA as a cornerstone of government transparency;\nhowever, the reality is that FOIA's implementation doesn't live up to this promise. First,\nlegal loopholes mean that government agencies are not responsible for responding to FOIA\nrequests on time, so requesters experience interminable delays in trying to access government\nrecords. Secondly, if the records are politically sensitive or reveal administrative wrongdoing,\ngovernment agencies will seldom give them up without a fight; ironically, this is where FOIA\n\ncould be most valuable and where FOIA fails most. The problem is that the law fails to\nhold government agencies accountable for their compliance with FOIA.\nFor FOIA to fulfill its promise, it must hold government agencies accountable. The\nproposed CornynLeahy OPEN Government Act of 2005 would impose consequences on\nagencies for tardiness and create a FOIA ombudsman to audit, review, and mediate FOIA\nrequests. Although the effectiveness of the ombudsman is uncertain, the act's consequences\nfor tardiness would create real accountability for FOIA deadlines and thereby strengthen\nFOIA considerably.\nThe Fiction of FOIA Accountability\nIn an idealized world, a requester would obtain a government record under FOIA in the\nfollowing fashion. He submits his request. The agency searches for relevant records and then\nreviews the records to determine what to redact and what to disclose. Within 20 working\ndays, the agency makes a determination about whether to comply with the request. Within\na reasonable time thereafter, the agency delivers the documents to the requester.1\nIf the requester is dissatisfied with the completeness or the timeliness of the response, he\nfiles an administrative appeal with the head of the agency. The agency must respond to the\nappeal within 20 working days.\nIf the requester is dissatisfied with the administrative appeal, he files a lawsuit to compel\ndisclosure. If the court finds that the requester \"substantially prevails,\" then it \"may assess\n1FOIA actually does not specify any timeframe, but \"within a reasonable time\" is the judicial interpre\ntation.\n\nagainst the United States reasonable attorney fees and other litigation costs reasonably\nincurred.\"\nThe Problem: Legal basis and empirical evidence\nThis is a beautiful picture. Unfortunately, this is not how FOIA works in practice. First,\nagencies delay responding because they are not responsible for the deadlines under the Open\nAmerica decision. Secondly, the difficulty of filing suit means that agencies rarely worry\nabout this possibility in deciding to withhold or redact records. Thus, if the records are\npolitically sensitive or reveal government wrongdoing, government agencies are strongly\ndisinclined to disclose them in response to FOIA requests. I will address each problem in\nturn.\n3.1\nDelay\nWe first witness this lack of accountability in agencies' habitually late responses to FOIA\nrequests. FOIA imposes a deadline of 20 working days, but an influential 1976 D.C. circuit\ndecision eliminated all respect for that deadline in Open American v. Watergate Special\nProsecution Task Force, 547 F.2d 605. Open America sought access to FBI files on the role\nof the Acting FBI Director, L. Grey Peterson, in the Watergate affair. After the FBI missed\nthe statutory deadlines for the request and the subsequent appeal, Open America filed suit\nto compel disclosure, arguing that the plain meaning of the statute required that the FBI\nobserve the statutory time limits. In 1974, these limits gave the FBI 10 working days to\n\nrespond (with a 10workingday extension under one of three \"unusual circumstances\") and\n20 working days to make a determination on administrative appeal. Even with the (dubiously\napplicable) \"unusual circumstances\" extension, the FBI had missed all the deadlines.\nInstead, the court found relief for the FBI under the \"exceptional circumstances\" provi\nsion of 5 USC 552(a)(6)(C):\n§\nIf the Government can show exceptional circumstances exist and that the agency\nis exercising due diligence in responding to the request, the court may retain\njurisdiction and allow the agency additional time to complete its review of the\nrecords.\nThe court ruled that the unanticipatedly large FOIA backlogs constituted \"exceptional cir\ncumstances.\" Consequently, so long as the agency was exercising \"due diligence\" in respond\ning to the request, the court could grant additional time to disclose the records. In this case,\n191 FBI employees were processing FOIA requests in the order they were received, and this\nconstituted due diligence. Thus, habitual agency delay in responding to requests found legal\nvalidation in Open America; the court effectively nullified the 20day statutory limit.\nWe see this delay empirically. In 2001, the GAO analyzed the 1999 FOIA annual reports\nof 25 agencies that processed 1.9 million requests.[10] These 25 agencies handled 97% of the\nfedoral governments' FOIA requests; they are the 24 agencies identified in the Chief Financial\nOfficers Act, plus the CIA. These annual reports give the number of requests handled and\nthe median processing time in working days, so we cannot identify the median processing\ntime across the entire government. Nevertheless, we do see that the agencies with median\nprocessing times of 20 days or less handled 1.6 million, or 84%, of the requests. (See Figure\n3.1.) Observe that this doesn't mean that 84% of the requests took 20 days or less, since\n\n1,117,898\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n90,000\n100,000\n110,000\n120,000\n130,000\n2,337\nMedian Days\n20-Day Determination Period\nDistribution of Requests Processed by Median Days\n89% of requests\nNote: Except for the end points (1 and 2,337), only medians with over 1,000 requests are included in the graph; data from 23 agencies\na Actual value; bar scaled down to better illustrate the lower values\nRequests Processed\nSource: FOIA annual reports for fiscal year 1999 (self-reported data).\na\nFigure 1: 2001 GAO analysis of 1999 FOIA response times\nthis is just the median; we know that at least half of these requests (42%) took less than 20\ndays, but we can't say anything about the other half.\nThis sounds faintly reasonable, but the picture starts looking gloomy when we realize\nthat this data is weighted heavily by the Department of Veterans Affairs, which fields dis\nproportionately many requests for veterans' medical records. This department handled 1.1\nmillion requests with a median response time of 12 days. If we discount this department,\nthen the departments with median response time of 20 days or less handled merely 500,000\nCourtesy of Government Accountability Office.\n\nout of the remaining 800,000 requests, a fairly demoralizing 60%.\nIndividual agencies also show some disconcertingly long processing times. The Immigra\ntion and Naturalization Service handled 81,000 \"complex\" requests with median processing\ntime of 21 days.2 The Department of Defense handled 79,000 \"simple\" requests with a me\ndian processing time of 20 days and 17,000 \"complex\" requests with a median processing\ntime of 66 days. About 20,000 requests were handled by agencies with median processing\ntimes of 104 working days (EOUSA), 187 working days (CIA), 228 working days (FBI) , and\n308 working days (State). Somewhat egregiously, the FBI finished 30 expedited requests in\n1999 with a median processing time of 2,337 days.\nIt is even more sobering that in 1996, the Electronic FOIA Amendments increased the\nstatutory time limit from 10 days to 20 days, in order to reduce the apparent violations of\nFOIA. Agencies should have been aiming at 10 days, not 20. With no legal accountability,\nagencies just worked diligently through their backlog of requests with little regard for how\nlong that would take. This is the legacy of Open America.\n3.2\nImproperly withheld and redacted records\nThe FOIA grants administrators broad discretion to withhold and redact records. In practice,\nadministrators extend this discretion past the bounds of the law; they can effectively withhold\nand redact however they see fit, with little or no accountability. These abuses are possible\nbecause FOIA provides no effective mechanisms for holding administrators accountable for\nthose decisions. Thus, if the records are politically sensitive or reveal government wrong\n2Along with 78,000 \"simple\" requests with a median processing time of 10 days.\n\ndoing, government agencies are strongly disinclined to disclose them in response to FOIA\nrequests.\nWithin the limits of the law, the Freedom of Information Act already grants administra\ntors broad leeway in withholding and redacting records, with scant accountability for these\ndecisions. First, administrators have broad leeway in deciding whether a record is exempt\nfrom disclosure; then, since the exemptions are discretionary, they also have complete free\ndom to decide whether to withhold the record. As early as 1978, the Government Accounting\nOffice recognized how much discretion administrators have in withholding records and hence,\nhow important agency attitudes are in making FOIA work:\nInterviews with several analysts and agents revealed different attitudes on how\nthe exemptions were to be applied. . . . Attitudes can make the difference as to\nhow many pages, paragraphs, lines, or even words are excised. This is because\nthe excising process consists of a linebyline review, and officials must constantly\nmake subjective decisions as to whether a certain paragraph or line would disclose\nthe identity of an informant or constitute an unwarranted invasion of privacy.[15]\nSince administrators have so much discretion in applying FOIA exemptions, agency attitudes\nessentially determine the completeness of records that requesters receive.\nEven beyond the limits of the law, the lack of accountability for FOIA leaves administra\ntors free to protect their own interests. When records are improperly withheld or redacted,\nthe only remedies available to the requester are an administrative appeal and a lawsuit. Only\nthe rare requester with time, money, and knowledge can avail themselves of these remedies,\nso these remedies are generally ineffective for holding agencies accountable. First of all,\nit is often impossible for requesters to tell when records have been improperly withheld or\nredacted. Requesters face an overwhelming imbalance of information; only the agency knows\n\nprecisely what records are relevant and what text has been redacted. Second, even when\nthe requester knows that the agency erred, the process for compelling disclosure is time\nconsuming and expensive. After a generally ineffectual administrative appeal, the requester\nmust file a lawsuit to compel disclosure. The only consolation is that if the court finds that\nthe requester \"substantially prevailed,\" then it can award the requester attorneys' fees.\nThus, FOIA enforcement depends heavily on private lawsuits, and only organizations and\nthe rare individual have the resources to pursue these lawsuits. As a consequence, agencies\nhardly worry about the remote possibility of a lawsuit when they decide to withhold or redact\nrecords. Indeed, a 1980 Senate report discovered that agencies had learned to distinguish\nbetween requests that could be credibly backed by a lawsuit; they found that companies and\nwealthy nonprofits often received preferential FOIA treatment over individual citizens, since\nindividual citizens were unlikely to file suit.[7] Each year, out of millions of FOIA requests\nand tens of thousands of appeals, we see only hundreds of FOIA lawsuits, and agencies realize\nthis.\nThe average requester is left with very little idea of whether records have been improperly\nwithheld or redacted and very little recourse even if he knows. Administrators realize this and\nfreely withhold records as they see fit. Thus, FOIA fails to live up to its promise of enabling\nordinary citizens to access any government record, however embarrassing or condemning the\nrecord may be.\n\n3.3\nAdministrative Accountability\nBesides private mechanisms for enforcement, the FOIA provides three administrative mech\nanisms to hold agencies accountable for their FOIA actions. Unfortunately, none of these\nhave had much effect, and their existence is poor consolation to the denied FOIA requester.\nFirst, each agency publishes an annual report with statistics on FOIA requests, appeals,\nbacklogs, fees, staffing, and timeliness. Unfortunately, yearly variations in agency reporting\nmake it difficult to analyze trends over time, and variations in data from agency to agency\nmake it difficult to compare agency practices. For example, many agencies report the median\nprocessing times of each of their divisions, and the divisions change over time. Some agencies\nmeasure processing time from the day when requests are \"perfected,\" while others measure\nfrom the day they are received. Some agencies include Privacy Act requests, while some\nagencies do not. The GAO struggles valiantly every year to assemble a coherent analysis of\nthese inconsistent reports. In any case, these reports receive negligible political attention,\nso agencies have little incentive to improve their statistics.\nNext, the Department of Justice has the authority to withhold counsel from agencies sued\nunder FOIA. Since agencies lack the authority to retain outside counsel, Justice can use this\nauthority to coerce FOIA compliance. In practice, Justice very rarely threatens to withhold\ncounsel.[26] Especially in recent years, Justice has simply used its authority implicitly to\nprovide FOIA guidance and training, rather than explicitly to coerce compliance. A com\nponent of Justice -- the Office of Information and Privacy -- issues a biweekly newsletter\ncalled FOIA Post, and it provides additional educational materials for employees.\n\nThe most explicit use of Justice's authority is the memo that incoming Attorneys General\nissue outlining new Presidents' FOIA policy; however, even these broad statements of policy\n(backed by explicit threats of withholding counsel) cause little change in agency practice.\nFor example, under the Clinton administration, Janet Reno promulgated a very permissive\nFOIA policy with a \"presumption of disclosure\" and a promise to defend the withholding of\nrecords only if disclosure could cause \"foreseeable harm:\"\nThe Department will no longer defend an agency's withholding of information\nmerely because there is a \"substantial legal basis\" for doing so. Rather, in de\ntermining whether or not to defend a nondisclosure decision, we will apply a\npresumption of disclosure. . . . In short, it shall be the policy of the Department\nof Justice to defend the assertion of a FOIA exemption only in those cases where\nthe agency reasonably foresees that disclosure would be harmful to an interest\nprotected by that exemption.[4]\nIn sharp contrast, under the following Bush administration, John Ashcroft promulgated a\nmuch more restrictive FOIA policy; his memo replaced the presumption of disclosure with\na new policy of careful consideration of all the possible interests that could be implicated\nby disclosure. Ashcroft's memo promised to defend the withholding of records in essentially\nany legally defensible situation:\nAny discretionary decision by your agency to disclose information protected under\nthe FOIA should be made only after full and deliberate consideration of the\ninstitutional, commercial, and personal privacy interests that could be implicated\nby disclosure of the information.. . . When you carefully consider FOIA requests\nand decide to withhold records, in whole or in part, you can be assured that the\nDepartment of Justice will defend your decisions unless they lack a sound legal\nbasis or present an unwarranted risk of adverse impact on the ability of other\nagencies to protect other important records.[5]\nThese two memos seem to reflect diametrically opposite philosophies about government\n\ntransparency, and they threaten to place the full force of the Justice Department behind\nthose philosophies. However, in reality, these memos had little effect on agency practices\noutside the defense establishment. The National Security Archive found in a 2003 study that\nmost federal agencies \"indicated little change in regulations, guidance, or training materials\nreflecting\" Ashcroft's FOIA memo.[3] If such a drastic change in stated Justice policy pro\nduced such minor change in agency practice, we can only conclude that the Department of\nJustice exercises little power in enforcing FOIA. Thus, the Department of Justice essentially\nprovides only FOIA guidance and training. Though this may promote FOIA compliance\noverall, it again gives little consolation to the frustrated requester.\nFOIA's final mechanism for public accountability is a promise to discipline arbitrary\nand capricious employees (§552(4)(F), but not a single employee has ever been disciplined\nunder this paragraph. Here is how the process should work: if the court rules that \"agency\npersonnel acted arbitrarily or capriciously with respect to the withholding\" of records under\nFOIA, then the US Office of Special Counsel should initiate a proceeding against the officer or\nemployee primarily responsible for the withholding to determine whether disciplinary action\nis warranted. The Special Counsel should submit his findings and recommendations to the\nagency's administrative authority, which should take the recommended corrective action.\nIn practice, no agency personnel have ever been disciplined under FOIA. Only twice has\na court ever referred findings to the Special Counsel.[26] In the first case, the request and all\nsubsequent appeals were completely ignored by the agency; nevertheless, the Special Counsel\nfound no fault with agency personnel in a mindbogglingly technical reading of its imperative\n\nunder FOIA \"to determine whether disciplinary action is warranted against the officer or\nemployee who was primarily responsible for the withholding:\"\nAll of these officials had management responsibilities in connection with the FOIA\nand, to some degree, the extensive delays involved in furnishing records to Mr.\nHolly as promised can be laid to mismanagement. However, the Act limits our\nauthority to proceed against those who are \"primarily responsible\" for a failure\nto produce. On the basis of the evidence before me, I cannot find that any of the\npersons mentioned fall into that category. (Accordingly), it is the conclusion of\nthis office that disciplinary action is not warranted.3\nThat is, since many officials were jointly responsible for the withholding, they could not\nidentify any single employee who was primarily responsible for the withholding. The second\ncase referred to the Special Counsel was closed without any public findings.4 Clearly, this\nsystem was not working. In 1978, frustrated with this state of affairs, Congress authorized\nthe Special Counsel of the new Merit Systems Protection Board to initiate investigations\nof FOIA violations even without judicial referral, but this Special Counsel has never issued\nfindings under this authority. 5\nThus, none of FOIA's three mechanisms for administrative accountability are effective.\nNobody cares about FOIA statistics, the Department of Justice only provides guidance and\ntraining, and no agency personnel have ever been disciplined under FOIA. We must look\nbeyond these administrative remedies to find better ways to enforce FOIA.\n3Holly v. Acree, 72 F.R.D. 115 (D.D.C. 1976). Quoted in 1980 Senate Report.[7]\n4Long v. Internal Revenue Service, Order No. C7640V (D.C. Wash. 1981).\n5At least not until 1989, when the Special Counsel became an independent executive branch. This\nconclusion is based on a review of all 23 Merit Systems Protection Board decisions containing the term\n\"FOIA,\" retrieved from its website at http://www.mspb.gov/mspbdecisionspage.html on December 5,\n2005.\n\n3.4\nGovernment Motivations\nWe've seen the legal loopholes in FOIA that lead to a lack of accountability; we've seen the\nempirical evidence of the results. Without accountability, we can only ask administrators\nto apply their best, impartial judgment and trust that they do their job well. This actually\nworks well in many other circumstances; we trust that government employees will do their\njob correctly when they, say, renew our drivers' licenses or audit our tax returns. However,\nunlike most government functions, FOIA reveals how employees do their jobs, so FOIA\nadministrators cannot be impartial in the same way as the person renewing our drivers'\nlicenses our auditing our tax returns. Especially considering the unusual amount of discretion\nin complying with FOIA, we cannot expect employees to impartially comply with FOIA out\nof sheer good will. The motivations provided by the law and government simply fail to align\nemployees with the goals of FOIA.\nFor example, the law imposes personal liability on administrators for improperly dis\nclosing information; since we have seen that FOIA utterly fails to discipline employees for\nimproperly withholding information, legal selfinterest predisposes administrators towards\nwithholding. Naturally, disclosing classified information can result in up to 10 years in prison\n(18 U.S.C. 798), but liability for disclosure extends far beyond just classified information.\n§\nFor example, if a government employee discloses trade secrets or confidential financial infor\nmation, 18 U.S.C. 1905 can send him to jail for up to a year. Harrison Wellford illustrates\n§\nthe conflict with an ironic anecdote:\nThe OEO suspended Rudy Frank, one of its employees, for allegedly releasing\nconfidential information on the salaries of teachers at a daycare center operated\n\nby a private corporation under contract to the OEO. Frank then sued the OEO\nunder the Freedom of Information Act to force the OEO to make the daycare\nsalaries public. Faced with the lawsuit, the OEO gave the \"secret\" data to Frank\nbut refused to lift his suspension.[28]\nThis certainly shows the double standards of liability for withholding and release. With the\nrisk of job loss, civil liability, and even criminal penalties, it is small wonder that adminis\ntrators tend to err on the side of withholding rather than disclosure.\nIn other circumstances, government employees have records that impugn their own be\nhavior, contradict agency policy, or reveal inconvenient political connections. Without ac\ncountability, administrators are naturally predisposed to withhold these records.\nI spoke with a staffmember in a governor's office who handled FOIA requests to under\nstand exactly how this mixture of misaligned motivations and lack of accountability results\nin poor treatment of FOIA requests. She reported that it was regular practice to suppress\ndocuments when politically expedient. An agency head would come around one day, saying,\n\"So, do you have that document? Let me know before you release it.\" The next day, he\nwould intimate, \"Remember that document? Why don't we forget about it for now?\" After\nall, the requester will not notice that the document is missing, and even if he does, he will\nnot sue.\nAs for response time, the staffmember reported that the requests are treated with little\nurgency, and the office pays little attention to the statutory time limit; if the office is busy or\nif the person responsible for the records is traveling or sick, then the request will simply sit on\na desk somewhere, regardless of the statutory deadline. For politically sensitive requests, it\nis also common practice to delay responding, to provide more time to spin the disclosure and\n\nlimit its newsworthiness. Unfortunately, FOIA thus fails where it would be most valuable\n-- in guaranteeing the right of access to politically sensitive information.\nThe staffmember gave the motivations starkly. The odds of any repercussions for with\nholding records and delaying are so slim that they are barely considered. The FOIA requester\nwould have to file a lawsuit and prove wrongdoing in court, and few requesters have the re\nsources for a lawsuit. So, why not sit on a request, wait for a while, and figure out how to\nspin it to minimize its political impact?\nHarrison Wellers also extensively analyzes the motivations of the government employee\nunder FOIA in None of your Business: Government Secrecy in America. He concludes that\npoliticallyappointed agency heads fear that they will be embarrassed or \"secondguessed\"\nif information is made public, and agency staff fear for their job security and advancement\nif information they release leads to embarrassment. For example, the FDA made major\nstrides in FOIA compliance under the leadership of Peter Hutt from 1971 to 1975, but Hutt\nexplains that agency heads initially feared that public disclosure would enable endless debate\nand secondguessing of their decisions:\nRather than risk the expenditure of substantial resources in public debate of this\nnature, with possible attendant increase in public confusion and loss of Food and\nDrug Administration prestige, it was easier to maintain the confidentiality of the\nunderlying information and simply avoid the debate.\nIndeed, this fear is somewhat wellfounded; with great reluctance, the FDA released food\nsafety data on sodium nitrite in 1972 to a Stanford graduate student, who came back with\na 78page analysis detailing the FDA's errors. Similarly, lowerechelon agency staff worry\nthat disclosing information will endanger their careers if that information contradicts agency\n\npolicy or embarrasses supervisors. We see this attitude all the time when agency staff refuse\nto be interviewed alone or when agency staff insist on anonymity, even for the most trivial\nof matters. Finally, agency employees are not immune to the natural feeling that the files\nin their desks should be their own, private files. Unlike any other setting, FOIA forces\nemployees to open potentially every file in their desk to public scrutiny, and we should not\nbe surprised to find resistance to this scrutiny.\nThus, we see that the lack of FOIA accountability permits agencies to delay and withhold\nrecords however they wish. We cannot count on government good will to deliver complete\nand timely records, particularly since FOIA would be most valuable when administrators\nwant to hide. FOIA needs accountability to reach its fullest potential.\nThe Solution: Imposing consequences and account\nability\nLack of accountability is the basic flaw in today's FOIA. We need to hold agencies accountable\nfor both the timeliness and the completeness of FOIA responses. With this understanding,\nwe will evaluate Senator Cornyn and Senator Leahy's proposal to reform FOIA: the Cornyn\nLeahy OPEN Government Act of 2005 (S.394), and we will propose some changes of our\nown. The OPEN Government Act would effectively solve the agency timeliness problem by\ncreating real consequences for tardiness. These consequences would so strongly incentivize\nagencies to respond on time that FOIA requesters would have a reasonable assurance of\n\na timely response. This single provision would be the OPEN Government Act's greatest\nsuccess, since it imposes simple and enforceable consequences.\nHolding agencies accountable for the completeness of their responses is a more difficult\nproblem. The OPEN Government Act tries to address this problem by creating a FOIA\nombudsman. The ombudsman would audit and review agency FOIA performance and me\ndiate between requesters and agencies. Unfortunately, only experience will tell how well this\nworks, and comparing this proposal with the Canadian ombudsman system already raises\nsome doubts. The OPEN Government Act declines to fix FOIA's disciplinary mechanisms;\ninstead, it merely demands some reports about these disciplinary mechanisms from various\nresponsible government agencies.\nFinally, a uniform FOIA request submission and tracking system across the entire fed\neral government would foster communication between requesters and agencies and thereby\nimprove the perception of accountability under FOIA. It would also enforce a uniformity of\naccounting across the government, so the GAO could dependably identify trends in FOIA.\nThe OPEN Government Act hints at this sort of system, but it doesn't realize the possibilities\nthat this could offer.\n4.1\nDelay\nThe CornynLeahy OPEN Government Act of 2005 would establish consequences for agency\ntardiness; the resulting improvements in agency timeliness would change the entire character\nof FOIA in this country.\n\nThe central provision of this act disqualifies an agency from exempting a record from\ndisclosure if it misses the 20day statutory limit for responding to the request:\n(G) (i) If an agency fails to comply with the applicable time limit provisions of\nthis paragraph with respect to a request, the agency may not assert any\nexemption under subsection (b) to that request, unless disclosure--\n(I) would endanger the national security of the United States;\n(II) would disclose personal private information protected by section\n552a or proprietary information; or\n(III) is otherwise prohibited by law.\n(ii) A court may waive the application of clause (i) if the agency demon\nstrates by clear and convincing evidence that there was good cause for\nthe failure to comply with the applicable time limit provisions.'.\nThis presents a strong incentive for agencies to comply with the time limit. If the agency\nwants to withhold records under any FOIA exemption, it will need to respond in a timely\nfashion to the request. Experience in Texas suggests that this is highly effective.[20]\nAdmittedly, this provision is, of course, enforceable only by lawsuit; however, if the\nagency missed the deadline but still withheld records, the requester would have a clear (and\npresumably inexpensive) case. The court would also award the requester attorney's fees\nfor \"substantially prevailing.\" The OPEN Government Act further strengthens this remedy\nby granting the requester attorney's fees if the pursuit of the suit was the \"catalyst\" for\nthe release of records. That is, if the agency refused to release records but released them\nupon filing of the lawsuit to render the case moot, the requester would still be entitled to\nattorney's fees. (This tactic of stalling and then releasing records to render the case moot\ncontinues to be a common agency practice.)\nThis provision would strongly encourage agencies to respond within 20 days. Filing a\n\nFOIA request with this sort of likelihood is unprecedented in the history of FOIA. This\nwould revitalize FOIA and substantially improve the transparency of our government.\n4.2\nTracking and computerization\nWe could make major improvements in FOIA administration by mandating the use of a\nsingle governmentwide FOIA computer system like FOIAXpress.6 This system accepts\nrequests, tracks progress, and delivers responses over the Internet. It provides computerized\nsystems for record redaction and fee payment. It automatically collects FOIA statistics\nand generates the appropriate reports. Twentyfive different agencies are already using\nFOIAXpress internally to track and service FOIA requests, though none of them appear to\nbe using the Public module to accept requests and deliver responses over the Internet.7\nSuch a system would provide a uniform way for citizens to access government records.\nMoreover, one unified system would yield consistency in data reporting between agencies\nand across years, allowing the GAO to perform truly meaningful analysis of trends in FOIA\nsatisfaction. The computerized redaction would also permit a level of audit and analysis\nthat was never possible on paper. The GAO could analyze, for example, the number of lines\nredacted under each exemption or the variation between agencies or even between individual\nadministrators. This would be a truly promising path to explore.\nUnfortunately, it would require at least several tens of millions of dollars; although this is a\ntruly trivial sum of money, the need to appropriate money makes this unlikely to make it into\n6http://www.foiaxpress.com/. I mean to use this as an example. I don't mean to endorse it, though I\nadmit I am not aware of any comparable software.\n7http://www.foiaxpress.com/Clients.html.\n\nthe OPEN Government Act. Instead, the OPEN Government Act simply requires agencies to\nissue a tracking number and estimated completion date for each request. Requesters would be\nable to track requests online and by phone. The estimated completion date and the tracking\nsystem would improve requesters' experience with FOIA, but they won't substantially change\nFOIA.\n4.3\nImproperly withheld and redacted records\nWe would also like to hold agencies accountable for the completeness of FOIA responses.\nUnfortunately, this problem is more difficult than the timeliness problem, and the OPEN\nGovernment Act does not present a clear solution.\nThe OPEN Government Act barely even attempts to discipline employees who arbitrarily\nand capriciously withhold records. It would have the Attorney General notify the Special\nCounsel of any court finding that employees deserved disciplinary action, but this is a fairly\nuseless change. As discussed above, courts have found only twice that employees deserved\ndisciplinary action, and in neither case did the Special Counsel take any disciplinary action.\nInstead of actually solving the problem, the OPEN Government Act asks for annual reports\nfrom the Special Counsel and the Attorney General, and it asks the Office of Personnel\nManagement to assemble some recommendations about motivating employees to comply\nwith FOIA. It ought to be a simple matter to impose civil liability or disciplinary action on\nemployees who illegal withhold records, but the OPEN Government Act basically punts on\nthis problem.\n\nThe other major provision of the OPEN Government Act creates a FOIA ombudsman\n\"to review agency policies and procedures, audit agency performance, recommend policy\nchanges, and mediate disputes between FOIA requesters and agencies.\"8 This ombudsman\nwould oversee the entire FOIA process. It is important to note that requesters could file suit\nwith or without seeking the ombudsman's mediation, and they could even file suit and seek\nmediation simultaneously. The ombudsman thus would not impose any further delays on\nenforcement. The ombudsman may well improve the average citizen's access to government\nrecords. For the average citizen without the time and money to sue, the ombudsman provides\na mechanism for him to seek redress without the expense and time of a lawsuit. Even\nthough the ombudsman has no formal powers to force compliance, it may solve conflicts as\na privileged mediator that individual citizens cannot.\nCanada also enforces its Access to Information Act with an ombudsman, in the form of\nthe Information Commissioner. Unlike the OPEN Government Act's proposed ombudsman,\nthe Canadian requester can only file suit in court after the Information Commissioner has\nreviewed the case. Like the OPEN Government Act's proposed ombudsman, the Information\nCommissioner has no formal powers to enforce compliance. Alasdair Roberts has made a\ncareer of studying the Canadian system, and he finds the Canadian ombudsman system far\nsuperior to the American internal review/judicial review system. \"Ordinary folks\" cannot\nafford the time and expense of a lawsuit, so an ombudsman/commissioner is much easier to\nhandle.[2] On the other hand, he does note some flaws with the Canadian system. Specifically,\nthe ombudsman's lack of any formal authority makes it difficult for the ombudsman to engage\n8http://cornyn.senate.gov/FOIA/files/OPEN_Gov_Act_sect_by_sect.pdf.\n\nconstructively with reticent government agencies. Without the power to monitor or order\ncompliance, the Canadian ombudsman can only fall back on subpoenas and public advocacy,\nwhich create hostile and ineffective relationships between the ombudsman and government\nagencies.[23]\nUndoubtedly, the success of the ombudsman would depend heavily on good implementa\ntion by the administration. Though it is not entirely clear how successful the ombudsman\nwould be, this would definitely represent a significant positive step in making the government\nrecords accessible. The success of the ombudsman really depends on its administration and\nits relationship to the other agencies. Only experience will reveal how effective it will be.\nConclusion\nGovernment transparency is an integral part of a democratic society. Citizens should be\nable to peer into their governments' darkest corners and look for things that are wrong. For\nonly when citizens know their government can they participate effectively in its operation.\nFOIA has served us well over the last decades, but lawsuits followed by more lawsuits have\nbeen necessary to keep the dark corners lit. These dark corners are just where FOIA is\nmost valuable, and it is just where FOIA stumbles -- in the delays, in the withholdings,\nand in the redactions -- because agencies are most wary of exposing the darkest corners of\ntheir administration. Without accountability, we cannot ensure that FOIA keeps these dark\ncorners lit.\nThe CornynLeahy OPEN Government Act takes one big step in making agencies ac\n\ncountable for their tardiness in responding to FOIA requests; it takes an uncertain forward\nstep in creating a FOIA ombudsman. It takes small steps in many other directions, but\nwe need to look farther ahead and find ways to hold agencies accountable for the complete\nness of their FOIA responses. An enforceable FOIA would go a long way towards making\ngovernment accountable to the people.\nReferences\n[1] Interview with an anonymous staffmember in a government office, Nov 20, 2005.\n[2] Private email with Alasdair Roberts, Nov 17, 2005.\n[3] National Security Archive. \"THE ASHCROFT MEMO: 'Drastic' Change or 'More\nThunder Than Lightning' ?\"\nPhase 1, March 14, 2003. http://www.gwu.edu/\n~nsarchiv/NSAEBB/NSAEBB84/findingsag.htm.\n[4] Janet Reno, FOIA Memorandum, FOIA Update, Vol. XIV, No. 3, 1993. http://www.\nusdoj.gov/oip/foia_updates/Vol_XIV_3/page3.htm.\n[5] John Ashcroft, FOIA Memorandum, FOIA Post, October 15, 2001. http://www.\nusdoj.gov/oip/foiapost/2001foiapost19.htm.\n[6] Information Policy in the 21st Century: A Review of the Freedom of Information\nAct: Hearing before the Subcommittee on Government Management, Finance, and\nAccountability of the Committee on Government Reform, 109th Cong., 1d Sess.,\nSerial No. 10946, May 11, 2005. http://www.access.gpo.gov/congress/house/\npdf/109hrg/22705.pdf.\n[7] Staff of Subcommittee on Administrative Practices and Procedure of the Senate Com\nmittee on the Judiciary, 95th Congress, 2d Session, Agency Implementation of the\n1974 Amendments to the Freedom of Information Act (1980).\n[8] Staff of House Committee on Government Operations, 92d Congress, 2d Session,\nAdministration of the Freedom of Information Act, H.R. Rep. No. 1419, (1972). http:\n//www.eecs.harvard.edu/~dpeng/foia1972.pdf.\n[9] U.S. General Accounting Office. Information Management: Update on Implementa\ntion of the 1996 Electronic Freedom of Information Act Amendments. GAO02493.\n(August 2002).\n\n[10] U.S. General Accounting Office. Information Management: Progress in Implemen\ntating the 1996 Electronic Freedom of Information Act Amendments. GAO01378.\n(March 2001).\n[11] U.S. General Accounting Office. Freedom of Information Act Operations at Six De\npartment of Justice Units. GAO/GGD8364. (May 23, 1983).\n[12] U.S. General Accounting Office. Update on Previous GAO Findings, Observations,\nand Recommendations Concerning the Freedom of Information Act. LCD80103.\n(August 13, 1980).\n[13] U.S. General Accounting Office. An Informed Public Assures that Federal Agencies\nWill Better Comply with Federal Information/Privacy Laws. LCD808. (October 24,\n1979).\n[14] U.S. General Accounting Office. Government Field Offices Should Better Implement\nthe Freedom of Information Act. LCD78120. (July 25, 1978).\n[15] U.S. General Accounting Office. Timeliness and Completeness of FBI Responses to\nRequests Under Freedom of Information and Privacy Acts Have Improved. GAO78\n51. (April 10, 1978).\n[16] Freedom of Information Act, 5 U.S.C. §552 (2002).\n[17] Freedom of Information Act Amendments of 1974, P.L. 93502, 88 Stat. 1561 (1974).\n[18] Senator John Cornyn. OPEN Government Act. http://cornyn.senate.gov/FOIA/.\n[19] Pending Senate Bill. OPEN Government Act. S.394 (Feb 16 2005).\n[20] Openness in Government and Freedom of Information: Examining the Open Gov\nernment Act of 2005: Hearing before the Subcommittee on Terrorism, Technology,\nand Homeland Security, of the Committee on the Judiciary, 109th Cong., 1d Sess.,\nS. Hrg. 10969, Serial No. J1097, March 15, 2005. http://frwebgate.access.gpo.\ngov/cgibin/getdoc.cgi?dbname=109_senate_hearings&docid=f:22471.pdf.\n[21] US Department of Justice. FOIA Law Review Articles. http://www.usdoj.gov/\nfoia/lawrevart.pdf.\n[22] Herbert N. Foerstel. Freedom of Information and the Right to Know. Westport, CT:\nGreenwood Press, 1999.\n[23] Alasdair S. Roberts. New strategies for enforcement of the Access to Information\nAct, Queen's Law Journal, 27 (Winter 2002), 647683. http://faculty.maxwell.\nsyr.edu/asroberts/documents/journal/Roberts_QLJ_2002.pdf.\n\n[24] Alasdair S. Roberts. Dashed Expectations: Governmental Adaptation to Trans\nparency Rules, In C. Hood and D. Held, eds., Transparency, British Academy,\nforthcoming\n2006.\nhttp://faculty.maxwell.syr.edu/asroberts/documents/\nchapters/Roberts_Academy_Oc12_05.pdf.\n[25] Robert L. Saloschin, Administering the Freedom of Information Act: An Insider's\nView. In None of Your Business: Government Secrecy in America, Dorsen and Gillers,\neditors. New York, NY: The Viking Press (1974).\n[26] Jeffrey M. Sellers, Note, Public Enforcement of the Freedom of Information Act, 2\nYale L. & Pol'y Rev. 78 (1983).\n[27] Eric J. Sinrod, Freedom of Information Act Response Deadlines: Bridging the Gap\nBetween Legislative Intent and Economic Reality, 43 Am. U. L. Rev. 325 (1994).\n[28] Harrison Wellford, Rights of People: The Freedom of Information Act. In None of\nYour Business: Government Secrecy in America, Dorsen and Gillers, editors. New\nYork, NY: The Viking Press (1974).\n[29] Charles J. Wichmann III, Ridding FOIA of those \"Unanticipated Consequences:\"\nRepaving a Necessary Road to Freedom, 47 Duke L. J. 1213 (1998)."
    },
    {
      "category": "Resource",
      "title": "google.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/1da69199e47326e25927351ccdb63e9e_google.pdf",
      "content": "Get to Know Google...\nBecause They Know You\nEthics and Law on the Electronic Frontier, 6.805\nBy\nStefanie Alki Delichatsios and Temitope Sonuyi\nDecember 14, 2005\n\nTable of Contents\n1.0 Introduction\n2.0 Personal Data Collection by Google Services\n2.1 Google's Search Engine\n2.1.1\nHow Google Search Works\n2.1.2\nInformation Google Records with Google Search\n2.1.2.1\nCookies\n2.1.2.2\nIP Address\n2.1.2.3\nBrowser Configuration, Date and Time, Search Content\n2.1.2.4\nLinks\n2.2 AdSense\n2.2.1\nHow AdSense Works\n2.2.2\nInformation Google Records with AdSense\n2.3 Gmail\n2.3.1\nHow Gmail Works\n2.3.2\nInformation Google Retrieves from Gmail\n2.3.2.1\nGmail Registration\n2.3.2.2\nEmail Content\n2.3.2.3\nServer Logs\n2.4 Synthesizing Collected Information\n2.4.1\nScenario of Data Synthesis\n2.4.1.1\nBob Smith's Google Activity\n2.4.1.2\nData Gathered\n2.4.1.3\nSeparate and Synthesized Data Views\n2.4.1.4\nHypothetical Google profile of \"Bob Smith\"\n2.4.1.5\nImplications of Google Profiling\n3.0 Information Processing and Dissemination\n3.1 Google Activity\n3.1.1\nThe Safe Harbor Program\n3.1.2\nPersonal Information\n3.1.3\nSensitive Information\n3.1.4\nAggregated non-Personal Information\n3.1.5\nInformation Processing and Sharing\n3.1.6\nGoogle's Compliance with the Safe Harbor Program\n3.2 Information Released Outside of Google\n3.2.1\nGovernment Officials Requesting Information\n3.2.2\nPotential Google Acquirers\n4.0 Survey\n4.1 Survey Results\n4.2 Discussion of Survey Results\n5.0 Google-Anon\n5.1 Project Goals\n5.2 Project Description\n5.3 Project Challenges and Issues\n5.3.1\nMaking Users Anonymous\n5.3.2\nGetting Past Google's Cleverness\n6.0 Conclusions\n\n7.0 References\n1.0 Introduction\nGoogle, through its numerous services and popularity, accesses far more information\nabout people than they realize. Though Google explicitly expresses its concern for\nprotecting the vast amount of private user information it collects, that information is\nnonetheless susceptible to fall into the hands of a) government officials seeking\ninformation through warrants, court orders and subpoenas, and b) potential Google\nacquirers. Google users must be made aware of the personal user information Google\ncollects and what does and can happen to that information. While some users may not be\nbothered by Google's data collection, others might feel extremely violated and may\nchoose to behave differently when using Google's services. In either case, Google users\nwho have been made aware of these privacy issues and presented with anonymous\nalternatives, will gravitate towards using these alternatives.\nIn Section 2 of this paper, we examine what exact personal user information Google\ncollects with its three most widespread services, Google Search, AdSense, and Gmail,\nand how this information can combine to create large identifying profiles about its users.\nIn Section 3, we explore Google's explanation for handling this personal information and\nhow it adheres to the Safe Harbor Program. We also present ways in which this private\ninformation can potentially escape the confines of Google's private servers, specifically\nthrough government subpoenas and corporate acquisitions. In Section 4, we discuss the\nresults of a survey we submitted to 60 internet users about their understanding of\nGoogle's privacy issues and their interest in anonymizing themselves from Google.\nFinally, in an effort to help Google users be more conscious about their Google searches,\nwe present a service called Google-Anon in Section 5, allowing users to search Google\nanonymously and compare the differences of search results based on different IP\naddresses and the presence of cookies. With Google-Anon, a user has the option to either\na) search Google anonymously through a routing network as a direct substitute to\nsearching with Google regularly or b) view a comparison of differences, for example, the\nnumber of results returned or the type and language of the ads presented, between a\nsearch made through an anonymized network with no cookies and a search made using a\nuser's specific IP address and Google cookies.\n2.0 Personal Data Collection by Google Services\nGoogle, Inc., formed in 1998 as a simple search engine responding to 10,000 queries per\nday, has transformed into a multinational corporate leader providing over 30 widely used\nservices with a search engine that now answers over 200 million queries per day [1][2].\nBy combining information from its different services through Google cookies and other\nlogging information, Google has the ability to create huge dossiers of personal\ninformation about its individual users. Though some of Google's smaller services, such\n\nas Google Desktop1 and Google Toolbar2 are more obviously penetrating, we choose to\nexamine Google's three most extensive yet unassuming services, Google Search,\nAdSense and Gmail to demonstrate how the information Google collects from these three\nservices can combine to produce an alarmingly large \"profiles\" of its individual users.\n2.1 Google's Search Engine\nGoogle's search engine stemmed from a Stanford PhD project, \"BackRub\" in 1996, and 9\nyears later, is the leading internet search engine over others like Yahoo and MSN,\nanswering over 35 percent of U.S. internet searches and over 65 percent of international\ninternet searches. [5]:\n(a)\n(b)\nFigure 2.1 Google dominates in both the (a) U.S. search market and the (b) international search\nmarket .\nThe success of Google's search engine can be attributed to its uncluttered interface, its\nunobtrusive advertisements, and most importantly, its trademarked ranking system,\nPageRankTM.\n2.1.1 How Google Search Works\nGoogle crawls the web and currently indexes over 9 billion items [6]. Like other search\nengines, Google organizes web pages by their content-- the frequency of words on a\npage, the position of words on the page, and the font size and capitalization of words [7].\nWhen a user makes a request on Google, Google uses content information to match the\nrequest. Google then combines a document's content information with its PageRank to\ndetermine the ordering of the sites returned to the user. The PageRank of website A, is\ndetermined by the number of other websites linked to website A, and the quality and\nPageRank of those linked websites [8].\n1 Google Desktop is a desktop search application giving Google access to information and files on a user's\nhard drive. It also provides a \"sidebar\" for the user to easily view customized personal information, such as\nweather and news, from the web [3].\n2 Google Toolbar is a internet toolbar service with advanced features such as WordTranslator and\nSpellCheck. When a user chooses to enable \"advanced features\", all of the user's internet activity is logged\nby Google [4].\n\n2.1.2 Information Google Records with Google Search\nIt is well-known that behind its simple interface, the Google search engine performs\ncomplicated algorithms on billions of existing websites to maximize the quality of a\nuser's search. However, what people do not realize is that the engine also collects and\nprocesses massive amounts of information about the individual searcher.\nGoogle records a \"server log\" every time a user makes a query with Google's search\nengine. The server log includes the user's cookies, IP address, browser type, browser\nlanguage, data and time of request, and the search content [9].\nA typical server log where the search is for \"dictionary\" may look like this:\n18.127.42.66 - 5/Dec/2005 9:20:46 -\nhttp://www.google.com/search?q= dictionary - Firefox 1.0.7; Windows NT 5.1 -\n740674ce123969\n2.1.2.1 Cookies\nIn the example server log, \"740674ce123969\" refers to the user's cookie. A cookie is a\nunique ID placed on a user's hard disk. Every time a user does a Google search, Google\nplaces a cookie on the user's machine if it does not already have one. If the user already\nhas a Google cookie on his or her machine, Google can read and record the cookie [10].\nGoogle's cookies expire over thirty years from their initial formation [10].\nWhile\ncomputer users have the option to erase their cookies, most do not, allowing Google to\nlink a person's cookie with other information it collects about a user as long as that user\nhas the same computer.\nTo verify Google's cookie management, I erased all my internet cookies and went to\nGoogle.com. Without making a search, Google placed a cookie on my machine with the\nfollowing information:\nFigure 2.2 Google cookie placed on user's machine after visiting Google.com. Notice how the cookie\ndoes not expire until 2038.\nWhenever I clear my cookies and then visit a website anywhere within the google.com\ndomain, a similarly formatted cookie gets placed on my machine.\n\n2.1.2.2 IP Address\nThe number \"18.127.42.66\" is an internet user's internet protocol (IP) address, a 32-bit\nunique number that a computer uses to identify and communicate with other computers\non an IP network, i.e. the internet [11]. A user's IP address is assigned by his/her Internet\nService Provider (ISP). The Internet Assigned Numbers Authority (IANA) assigns local\nregistrations of IP addresses to five Regional Internet Registries (RIRS)3 which are then\nresponsible for allocating IP addresses to ISPs within their region [12] [13]. A user's IP\naddress may or may not change each time the user connects to the internet, but in either\ncase, the IP address reveals location-specific information about the user.\nMany computer networks today are connected to the internet through Network Address\nTranslation (NAT) [14]. With the increase of internet users, especially within home and\nbusiness networks and the way in which sections of the IP address spectrum are blocked\nand reserved for specific purposes, there are simply not enough available IP addresses.\nAs a result, NAT allows for many computers on an internal network to connect to the\ninternet by sharing a single IP address through a router [14]. Again, though a user's\ncomputer may share an IP address with many others, that IP address is still very telling\nabout the user's geography.\nWith the knowledge of a user's IP address, anyone can simply discover location\ninformation about that user. Many websites on the internet exist providing a \"who is\"\nservice, allowing a user to retrieve information about a particular IP address. For\ninstance, if I am surfing the internet from my apartment in Cambridge, I can go to\nwhatismyip.com to determine my computer's IP address. When I do that, I discover my\nIP address is: 141.157.171.230 [15].\nI can then go to \"Whois Source\",\nhttp://www.whois.sc/, to obtain information about my IP [16]:\nFigure 2.3 Doing an IP \"lookup\" on Whois Source reveals user's location and ISP.\nWhois Source provides a detailed description of my IP address, allowing a user to quickly\nand easily detect that I am located in the Boston area and that I use Verizon as my\ninternet service provider. Since Google records a user's IP address as part of its server\nlog, it too can trace the geographic location of an individual user.\nThe five RIRS are AfriNIC (African Network Information Centre, APNIC (Asia Pacific Network\nInformation Centre), ARIN (American Registry for Internet Numbers), LACNIC (Latin American and\nCaribbean IP address Region Registry), and RIPE NCC (Reseaux IP Europeens) [12].\n\n2.1.2.3 Browser Configuration, Date and Time, and Search Content\nFinally, \"Firefox 1.0.7; Windows NT 5.1\" from the server log refers to the user's browser\nand operating system, \"5/Dec/2005 9:20:46\" is the date and time of the search, and\nhttp://www.google.com/search?q= dictionary\" is the requested URL, with the query\n\"dictionary\" included.\n2.1.2.4 Information about Links\nOn Google's \"Search Results\" pages, Google records the fact that a user clicked on a link\nand that link's URL in order to \"determine how often users are satisfied with the first\nresult of a query and how often they proceed to later results\" [9]. Essentially, Google\ntracks \"where\" a user goes after he or she leaves Google's Results Pages.\n2.2 AdSense\nThe AdSense program, a Google service developed in 2003, allows a website to host\ncontextualized advertisements, \"AdWords\", and generate revenue on a cost-per-click\n(CPC) basis [1].\n2.2.1 How Adsense Works\nA website using AdSense integrates a piece of Javascript code into the site's HTML\nwhich allows Google to control the type, placement, and number of advertisements on\nthat particular website [17]. Google uses the content of the website to select appropriate\nadvertisements for the website [17]. Additionally Google factors the language of the site\nand the location of the visitors to enhance the relevancy of the advertisements [18].\nFor example, \"digg.com\" is a technology news website whose source code reveals its use\nof AdSense:\n<div id=\"google-broad\"><div><script type=\"text/javascript\"><!--\ngoogle_ad_client = \"pub-7489042062340760\";\ngoogle_ad_width = 728;\ngoogle_ad_height = 90;\ngoogle_ad_format = \"728x90_as\";\ngoogle_ad_type = \"text\";\ngoogle_ad_channel =\"4567327683\";\ngoogle_color_border = \"F7F8FB\";\ngoogle_color_bg = \"F7F8FB\";\ngoogle_color_link = \"0033CC\";\ngoogle_color_url = \"0066CC\";\ngoogle_color_text = \"666666\";\n//--></script>\n<script type=\"text/javascript\"\nsrc=\"http://pagead2.googlesyndication.com/pagead/show_ads.js\">\n</script>\n\nGoogle programs the type, language, and colors of the advertisements in the javascript\nfile, http://pagead2.googlesyndication.com/pagead/show_ads.js. A piece of the code is shown below:\ngoogle_append_url('dt', date.getTime());\ngoogle_append_url('hl', w.google_language);\nif (w.google_country) {\ngoogle_append_url('gl', w.google_country);\n} else {\ngoogle_append_url('gl', w.google_gl);\n}\ngoogle_append_url('gr', w.google_region);\ngoogle_append_url_esc('gcs', w.google_city);\ngoogle_append_url_esc('hints', w.google_hints);\ngoogle_append_url('adsafe', w.google_safe);\ngoogle_append_url('oe', w.google_encoding);\ngoogle_append_url('lmt', w.google_last_modified_time);\ngoogle_append_url_esc('alternate_ad_url',\nw.google_alternate_ad_url);\ngoogle_append_url('alt_color', w.google_alternate_color);\ngoogle_append_url(\"skip\", w.google_skip);\nGoogle determines the country, region, and city of the user and in doing so, chooses\nappropriate advertisements for the site. When I visit digg.com from my apartment in\nCambridge, MA, the advertisements appear like this:\nFigure 2.4 When user with American IP address visits digg.com, Google Ads are in English.\n\nWhen a user in France visits digg.com, the advertisements appear like so:\nFigure 2.5 When user with French IP address visits digg.com, Google Ads are in French.\nGoogle combines information from the content of the page with information from the\nuser's IP address to target the ads to the individual user.\nAdSense users generate revenue either on a CPC4 (cost-per-click) or CPM5 (cost per\nthousand impressions). Adsense users can also choose to host a Google search bar on\ntheir websites, allowing the the site's users to search Google directly from the website.\nThe AdSense user profits from the search bar by the advertisements shown on the first\nresults page of the query.\n2.2.2 Information Google Retrieves from AdSense\nEach time a user visits a website with AdSense, Google records a server log similar to the\nlog recorded with Google Search. Instead of tracking\nhttp://www.google.com/search?q=dictionary, the log simply records the URL of the\nvisited site.\nGoogle also tracks each time a user clicks on one of the advertisements as part of the\nCPC paying method.\n2.3 Gmail\n4 CPC (cost-per-click) refers to the amount paid by the AdWords user every time someone clicks on his/\nher advertisement. With AdWords, an advertiser choses a maximum CPC from $.01-$100 [19]\n5 CPM (cost per thousand impressions) refers to the amount paid by the AdWords user for each 1000 of\nhis/her ads shown [19].\n\nGmail, released in April 2004, is Google's free search-based webmail service supplying\nits users with over 2.5 gigabytes of storage [20].\n2.3.1 How Gmail Works\nGmail works like any webmail service, but differs in its its powerful search engine and its\nfocus on the virtually unlimited storage it provides. Google encourages its Gmail users to\nperform easy and quick searches instead of creating folders and filing messages [20].\n2.3.2 Information Google Retrieves from Gmail\nWith Gmail, Google retrieves personal user information from account registration and\nemail content. Additionally, as with Google Search and AdSense, Google creates a\nserver log every time a user visits the Gmail website, linking log information such as the\nuser's cookies and IP address with the user's personal Gmail information.\n2.3.2.1 Gmail Registration\nGoogle requires an invite from a current Gmail user in order for a new user to create a\nGmail account. If the new user does not have an invite, the user may request an invite\nthrough a mobile text message. If the user chooses to receive an invite through his\nmobile phone, Google records the user's mobile phone number [22].\nAs part of the user account registration, Google requests the user's first and last names,\nand a secondary email address of the user.\n2.3.2.2 Email Content\nGoogle scans email content, as all email providers do, to provide spam filtering, virus\ndetection, search and other services [22]. Gmail also uses email content to provide\ntarget-based advertisements.\nGmail maintains several backup copies of users' emails to recover messages and restore\naccounts in case of system failure.\nIf a user deletes an email or terminates his Gmail account, Google reflects these actions\nin the user's account view. However, \"residual copies of deleted messages and accounts\nmay take up to 60 days to be deleted from [their] active servers and may remain in\n[their] offline backup systems\". An email that a user intended and expected to be\nerased may in reality remain on Google's servers forever [22].\n2.3.2.3 Server Logs\nGoogle records a server log for Gmail activity just as it does with Google Search and\nAdSense. In addition to the basic log information (i.e. IP address, date and time, etc),\n\nGoogle also logs account activity, such as storage usage and number of log-ins, and data\ndisplayed and clicked on [19].\n2.4 Synthesizing Collected Data\nEvidently, even with its three most basic and unassuming services, Google tracks every\nsingle action made by its users. And though it is unclear what Google does with this\ninformation beyond target-based advertisements, Google can easily link user activity\nacross different services using a user's cookies, IP address, or Gmail account to create\nindividual user profiles.\nWith Google Search, AdSense, and Gmail alone, Google\ncollects and has the capability to interconnect the following information:\nConnected by\nConnected by\nuser's Google\nuser's Google\ncookies, IP\nGoogle Search\ncookies and/or\nGoogle AdSense\naddress, and/or\nGmail\n- User activity on\n-User registration information\nGmail account\n- Searches made\nIP address\nwebsites with AdSense\n- User's first and last\n- Date and time of\nnames\n- Date and time of\nsearches\nactivity\n- User's email address\n- User's browser\n- User's browser\n- User's phone number\nconfiguration\nconfiguration\n- Date and time of Gmail\n- User's IP address\nactivity\n- User's IP address\n- User's browser configuration\n-Links click on by user\n-Advertisements clicked\non Search Results page\n- User's IP address\non by user\n- User's email content\nConnected by\nuser's Google\ncookies, IP\naddress, and/or\nGmail account\nFigure 2.6 Visual representation of collected data from three of Google's services, Google Search,\nAdSense, and Gmail, and how the information can be interlinked by cookies, IP addresses, and/or\nGmail accounts\nIn essence, Google can interconnect a user's name and email address (from Gmail) and\nhis approximate geographic location (from user's IP address) with particular searches he\nmade (from Google Search) or websites he visited (from AdSense) at specific dates and\ntimes.\n2.4.1 Scenario of Data Synthesis\nTo elucidate this idea of data synthesis and its implications, we will present a fictional\nscenario. The scenario will chronicle a typical user's activity with Google Search,\nAdSense, and Gmail. We will present plausible data gathered from the user's activity\nand then provide a synthesized view of the collected data.\n2.4.1.1 Bob Smith's Google Activity\n- Bob Smith, an MIT student, is sitting in his dorm room one day and goes to\nGoogle.com and types in a search for \"marijuana coffee\"\n\n- On the Search Results page, he clicks on \"Amsterdam's Marijuana Cannabis\nCoffee Shop Listing\", www.onlinepot.org/amsterdam/amsterdamlist.htm\n- Bob then logs into his unique Gmail account which he has set up using his real\nname and phone number, and reads some mail\n- A few days later, Bob goes to his home in San Francisco for Thanksgiving break\nand once there, uses his laptop to visits his favorite site digg.com, which has\nGoogleAds on the page\n- He then logs into Gmail and checks his mail\n- After returning to MIT and continuing to check his email on a regular basis, he\ndecides to erase all his cookies\n- Bob then searches for \"wedding rings\" using Google.com\n- Finally Bob again logs into his Gmail account to check mail\n2.4.1.2 Data Gathered\n- When Bob searches for \"marijuana coffee\" a cookie is placed on his machine if it\ndoesn't already exist, and in either case, Google logs his search and the\ncookie/time/date/ip associated with it\n- When Bob clicks on a link from the Google results page, the link he follows is\nlogged, along with the cookie/time/date/ip associated with his click\n- When Bob logs into his Gmail account, his activity is logged, along with the\ncookie that is on his machine at the time. This is done every time Bob logs into\nhis unique Gmail account.\n- When Bob visits digg.com, the GoogleAds section of the site gets the Google\ncookie on Bob's machine and logs what site he has just visited by associating the\npage with the cookie. Google also recognizes that Bob is using a different IP\naddress to access the internet\n2.4.1.3 Separate and Synthesized Data Views\nAfter Bob searches \"marijuana coffee\", he has cookie1 with \"marijuana coffee\" and other\ninfo recorded\nSearch Terms\nDate&Time\nIPAddress\nCookieID\nMarijuana\n11/20/2005\n18.127.42.66\nCookie#1\ncoffee\n09:20:46EST\nAfter Bob follows www.onlinepot.org/amsterdam/amsterdamlist.htm, he has cookie1\nwith site link and other info recorded\nSearch Link Followed\nDate&Time\nIPAddress\nCookieID\nwww.onlinepot.org/amsterdam/amsterdamlist.htm\n11/20/2005\n09:26:46EST\n18.127.42.66 Cookie#1\nAfter Bob goes home to San Francisco and visits digg.com, he has cookie1 and the\nvisited URL recorded\n\nVisited Adsense\nSite\nDate&Time\nIPAddress\nCookieID\nhttp://www.digg.com 11/24/2005\n14:20:46PST\n66.127.42.3\nCookie#1\nAfter Bob logs into Gmail account he has his unique Gmail account (name/content),\ncookie1 and other info recorded\nGmail Account Date&Time\nIPAddress\nCookieID\nMail Content\nID#:334\nName: Bob Smith\n11/24/2005\n22:20:46PST\n66.127.42.3\nCookie#1\nMailbox#:334\nWhen Bob returns to MIT, he makes a new Google search with a new cookie, and\ncookie2 and other info are recorded\nSearch Terms\nDate&Time\nIPAddress\nCookieID\nwedding rings\n11/28/2005\n05:22:36EST\n18.231.4.216\nCookie#2\nBob logs into Gmail again and his Gmail account info and cookie2 with other info are\nrecorded\nGmail Account Date&Time\nIPAddress\nCookieID\nMail Content\nID#:334\nName: Bob\nSmith\n11/28/2005\n6:20:46EST\n18.231.4.216\nCookie#2\nMailbox#:334\n\n2.4.1.4 Hypothetical Google Profile of \"Bob Smith\"\n|\n|\n|\n|\nGmail\nAccount ID#: 334\nName: Bob Smith\nMail Box Content#:334\ncookies\nID: Cookie#1\nID: Cookie#2\nAdSense Site Visit:\nurl: digg.com\ntimedate:\n11/24/2005 14:20:46\nIP: 66.127.42.3\nSearch URL\nFollowed:\nURLl:\nwww.onlinepot.org/am\nsterdam/amsterdamlist.\nhtm\ntimedate:\n11/20/2005 109:26:46\nIP: 18.127.42.66\nSearch Event:\nterm: marijuana coffee\ntimedate:\n11/20/2005 09:20:46\nIP: 18.127.42.66\nSearch Event:\nterm: wedding rings\ntimedate:\n11/28/2005 05:22:36\nIP: 18.231.4.216\nFigure 2.7 Hypothetical Google profile of \"Bob Smith\" links information about searches Bob has\nmade, sites he has visited, what IP address he uses, and his Gmail activity.\nAfter minimal Google activity on Bob's part, Google now has a comprehensive profile on\na man named \"Bob Smith\", including details about his Gmail activity, what searches he's\nmade and what sites he's visited when and from what IP address. Midway through his\nactivity, Bob erases his cookies, but nevertheless, when he signs into his Gmail account,\nhe is re-linked to his previous cookie, and all the information from the two cookies are\ninterconnected. With his changing IP address, Google can also trace \"Bob Smith\"'s\ngeographical movement- logging in from MIT for a couple days, from San Francisco for\nthe next couple of days, and then from MIT again.\nThough Google does not explicitly concede to creating such profiles, the privacy policy\ndoes state that \"we may combine the information you submit under your account with\ninformation from other Google services or third parties in order to provide you with a\nbetter experience and to improve the quality of our services\" [23]. The creation of such a\nprofile is highly realizable.\n2.4.1.5 Implications of Google Profiling\nWhen Bob Smith searches \"marijuana coffee\", visits digg.com, checks his Gmail\naccount, etc, he is not intending nor is he aware that Google logs and possibly\ninterconnects all of his Google activity. Essentially, Google is recording and possibly\nsynthesizing personal data about Bob Smith that did not exist before.\n\nGoogle remembers a user's search long after that user has made that search and forgotten\nit. Google retains emails that a user erases. Some people may not be bothered that\nGoogle records and stores all this personal data.\nHowever, other users may feel\nextremely violated by this data collection, regardless of the possibilities of whose hands\nthis information could fall into.\nKnowing all this information, bothered users may choose to use Google services\ndifferently, either by searching Google anonymously with our proposed anonymizer\nGoogle-Anon, choosing not to use Gmail, erasing cookies on a regular basis, or through\nother methods of preventing Google from collecting personal data. We feel that users\nshould simply be aware that Google collects all this information about its users, and with\nthat knowledge, decide whether or not to change their activity with Google's services.\n3.0 Information Processing and Dissemination\nBeyond simply the collection of personal information, Google users should be aware of\nwhat does and can happen to that information.\n3.1 Google Activity\nGoogle's privacy policy, dated October 14, 2005, is explicit and detailed about the\ndifferent types of information it handles and what sort of analysis it performs on each\ntype of data. Google also states in its policy that it is a registered organization with the\nU.S. Department of Commerce's Safe Harbor program [23].\n3.1.1 The Safe Harbor Program\nThe U.S. Department of Commerce's Safe Harbor program was developed in 2000 in\nresponse to the European Commission's Directive on Data Protection6 to provide U.S.\ncompanies a means to comply with the Directive and avoid facing prosecution by\nEuropean authorities under Europe's strict privacy laws [24]. Companies registered with\nthe Safe Harbor Program are deemed \"adequate\" under the European Directive. In order\nfor a company to register with the Safe Harbor Program, it must comply with the seven\nsafe harbor principles: notice, choice, onward transfer, access, security, data integrity,\nand enforcement [24]. In essence, a company's user must be notified about the purposes\nfor the company's collected personal data, the user must have the opportunity to \"opt\nout\" of providing personal information and \"opt in\" of providing sensitive information,\nthe user must be granted access to any information the company may have about that\nuser, and the user information must be relevant and correct.\nGoogle's privacy policy explains the measures it takes to comply with the Safe Harbor\nProgram. It delves into the types of information it collects and what it does with that\ninformation.\nThe European Commission's Directive on Data Protection, enacted in 1998, prohibited the transfer of\npersonal data to non-European Union nations that did not meet the European \"adequacy\" standard for\nprivacy expectation [25].\n\n3.1.2 Personal Information\nGoogle describes \"personal information\" to be information that personally identifies a\nuser, such as a user's name, email address or billing information [9].\n3.1.3 Sensitive Information\n\"Sensitive personal information\" refers to a user's confidential medical information,\nracial or ethnic origins, political or religious beliefs or sexuality that can be connected to\nthe user's personal information [9].\n3.1.4 Aggregated Non-Personal Information\n\"Aggregated non-personal information\" is information about a user's Google activity that\nis collected into groups and does not reference an individually identifiable user [9].\n3.1.5 Information Processing and Sharing\nGoogle processes a user's \"personal information\" to customize content and advertising\nfor the user, to improve Google's services and to develop new services. Google provides\npersonal information to affiliated companies that process information on Google's behalf\nand are required that they comply with Google's privacy policy. If at any time Google\nwants to share personal data with companies or persons outside of Google, it will notify\nits users and provide an opt-out option [23].\nGoogle never processes or shares \"sensitive information\" without opt-in consent.\nGoogle processes and shares \"aggregated non-personal information\" with companies and\npersons outside of Google. See Google Zeitgeist http://www.google.com/press/zeitgeist.html for\ninteresting analysis Google does with aggregated information about user behavior and\npatterns with the search engine.\n3.1.6 Google's compliance with the Safe Harbor Program\nGoogle's privacy policy is essentially written to reflect its registration with the Safe\nHarbor program with headings such as \"Information Security\", \"Data Integrity\", and\n\"Enforcement\". Even to the extent that Google creates personal user profiles such as\n\"Bob Smith\" from Section 2.4.1.4, Google is in compliance with the Safe Harbor\nProgram and users can somewhat rest assured that their private user information is being\ncarefully managed.\nNonetheless, Google also states that its privacy policy could at any time change yet\ninterestingly, it does not disclose how long it retains the personal user information it\ncollects [23]. If at some point Google decides to change its policy and no longer wishes\nto be a registered member of the Safe Harbor program, Google would still have all of its\n\ncollected personal user information, but could choose not to protect that information in\nthe same way it does now.\n3.2 Information Released Outside of Google\nThough Google is currently dedicated to protecting the vast amount of private personal\ninformation it has about its users, that information could easily end up outside of\nGoogle's servers, namely through government officials or potential Google acquirers.\n3.2.1 Government Officials Requesting Information\nIn its privacy policy, Google explicitly states that it complies with \"valid legal process,\nsuch as search warrants, court orders, or subpoenas seeking personal information\" [9].\nGoogle may have personal and sensitive information about a user that it protects with the\nhighest level of privacy but at any time, a government official with a warrant could easily\ncome to Google and request that sensitive information about a user and Google would\nrelease the information. Furthermore, under Provision 213 of the USA Patriot Act,\ngovernment officials can request information from Google without notifying the Google\nuser until after the search has happened [26].\nIn October 2005, Google searches made by an accused murder were brought and used in\ncourt by the prosecution. The body of Robert Petrick's wife was found in January 2003\nin Falls Lake, North Carolina, and prosecutors discovered Google queries Petrick had\nmade on his computer just prior to his wife's death, including \"neck\", \"snap\", \"break\",\nand the lake levels and water currents of Falls Lake [27]. Though the searches were\nfound on Petrick's hard drive, not through subpoenaed information from Google, this\nscenario nonetheless highlights the type of information Google collects and stores and\nhow it is not protected from government intrusion. At the time he made those queries,\nPetrick did not realize that the information would be stored and released.\n3.2.2 Potential Google Acquirers\nGoogle's dedication to protecting its user's privacy is highly respectable but its policy\nholds only so long as Google is in control of its collected information. In its privacy\npolicy, Google states that in the case of a merger or acquisition, it will \"provide notice\nbefore personal information is transferred and becomes subject to a different privacy\npolicy\" [23]. Google does not and can not guarantee that should a merger or acquisition\noccur, the personal information it stores will be protected in the same way it is now.\nAdditionally, if Google is acquired by a company and privacy rights are violated, Google\ncan not be held liable under the Homeland Security Act [28]. The Homeland Security\nAct protects companies from lawsuits and government prosecution when they turn over\ninformation to a new agency.\n\n4.0 Survey\nIn order to verify how much of the aforementioned information users are actually aware\nof, we conducted an online survey and asked 60 people the following questions:\n1. Is Google your primary search engine? Yes/No. .\n2. Have you read Google's Privacy Policy? Yes/No.\n3. Are you aware that Google keeps records every search you make on your machine?\nYes/No.\n4. Do you have a Gmail account? Yes/No.\n5. Are you aware that when you erase an email, Google retains that email on one of their\nservers? Yes/No.\n6. Do you know that government officials can subpoena information Google collects\nabout its users? Yes/No.\n7. Google can trace and interconnect\na) When and what you searched with Google Search\nb) Certain websites you visit that use AdSense\nc) Your name and secondary email address (provided in Gmail registration)\nd) The content of your Gmail email\ne) When and how many times you log into Gmail\n*the listed items are pieces of information Google collects from its three most pervasive services- Google\nSearch, AdSense, and Gmail. Feel free to ask more about these services\nKnowing this information, do you think you will change your behavior when using\nGoogle's services? Yes/No.\n8. Would you be interested in an anonymizer that allows you to search Google\nanonymously? Yes/No.\nTo see the online version, click on this link:\nhttp://FreeOnlineSurveys.com/rendersurvey.asp?id=134247.\n\n4.1 Survey Results\nWe distributed the survey by email and instant messenger over a span of two days.\nNinety percent of the respondents are students and young professionals ages 20 - 24 and\nthe other ten percent are family members ages 30+.\nQ1\nQ2\nQ3\nQ4\nYes\n98.3%\n3.3%\n26.7%\n71.7%\nNo\n1.7%\n96.7%\n73.3%\n28.3%\nTotal Responses\nQ5\nQ6\nQ7\nQ8\nYes\n30.5%\n25.4 %\n36.7%\n85%\nNo\n69.5%\n74.6%\n63.3%\n15%\nTotal Responses\nTable 4.1 Summary of survey results, listing the total responses, the number of and percent total\n\"yes\" responses, and the number of and percent total \"no\" responses for each question.\nQuestions 1 and 4 highlight the pervasiveness of Google's services:\nFigure 4.1 Results of Questions 1 and 4 of survey.\nOnly one person responded saying Google was not his/her primary search engine and\nover 2/3 of the respondents were registered Gmail users, despite Gmail being a relatively\nnew webmail service.\n\nQuestions 2, 3, 5, and 6 demonstrate how little people know about Google's privacy\npolicies:\nFigure 4.2 Results of Questions 2,3, 5 and 6 of survey.\nIn Question 7, the majority of people said they would not change their internet behavior\nwhen using Google services after realizing what sort of information Google actually\ncollects:\nFigure 4.3 Results of Question 7 of survey.\n\nAt the same time, most of our survey-takers were interested in a service allowing them to\nsearch with Google anonymously:\nFigure 4.4 Results of Question 8 of survey.\n4.2 Discussion of Survey Results\nAs expected, most of the respondents use Google as their primary search engine and over\n2/3 are registered Gmail users. However, it is interesting to note that even among the\nGmail users, hardly any of them have read Google's privacy policy. If people actually\nread Google's privacy policy and responded \"yes\" to question 2, they would also have\nresponded \"yes\" to questions 3, 5, and 6. Google thoroughly reveals all relevant privacy\ninformation (i.e. questions 3, 5, and 6) in its privacy policy but most people simply have\nnot made that step to read Google's policy.\nThough the majority of the survey-takers said they would not change their Google\nbehavior after recognizing Google's personal information collection, over 1/3 still said\nthey would. This statistic highlights the importance of alerting people of Google's data\ncollection. People must be aware of Google's collection of personal user information and\nwith that knowledge, can then decide whether or not to behave differently when using\nGoogle's services.\nDespite the results of question 7, most of the respondents said they would be interested in\na Google anonymizer in question 8. This incongruity reveals that question 7 may have\nbeen somewhat unclear. If instead, we had posed ways in which a user could change his\nor her internet behavior like below:\n\"Knowing this information, do you think you will change your behavior (i.e. erase\ninternet cookies on a regular basis, use anonymizers, disable javascripts for pages\nwith Google Ads, etc.) when using Google's services?\",\nWe expect that the results of question 7 would more closely resemble the results of\nquestion 8.\n4.3 People's Reactions to the Survey\n\nThe most interesting results of the survey were in fact the reactions of survey-takers after\ncompleting the survey. One respondent replied in an email saying,\n\"Your survey is...uh...kinda scary\".\nAnother responded through instant messenger saying,\n\"Are you trying to make me paranoid? Because it's working\".\nYet another responded through instant messenger with,\n\"Is this true? Can I forward this survey to my friends? I've been to Cuba and that's\nillegal! And I use my Gmail account all the time- and I wrote a lot of emails about being in\nCuba!! I'm so scared!\".\nIt seems that most of the paranoid reactions were in response to questions 3, 5 and 6.\nThis paranoia comes as no surprise simply because personal user information that it is out\nof the user's control is a new concept to grasp.\nBefore the advent of the internet, a person's minor actions could not feasibly have been\nrecorded. But with the seemingly unlimited digital memory storage that exists today,\nentities like Google can easily record and store information about a user that the user has\nlong forgotten. Just as Robert Petrick from Section 3.2.1 did not fathom that Google\nsearches he made would one day be used against him in court, people generally do not\nlike the idea that information about them which they have forgotten or deliberately have\ntried to erase (in the case of email) exists without their control.\nDeploying this survey has been extremely useful in showing a) how little people know\nand understand about Google's personal user collection and b) that people are interested\nin a Google anonymizer. In response to the 85% of respondents who said they would be\ninterested in a Google anonymizer, we have developed and present Google-Anon.\n5.0 Google-Anon\nGoogle-Anon is a web-based service we have created and made available for public\nconsumption. This service is a tool that allows users to search Google anonymously and\nto see the differences between using Google Search anonymously and non-anonymously.\nWe feel that it is important that people are cognizant of what they are doing on the web\nand what aspects of their privacy are or are not as private as they may have thought. Our\nfeelings are bolstered by the data garnered from our self-administered survey. Our survey\nclearly indicated that when most users use Google search, they are not aware of the\ninformation that Google tracks about them.\n\n5.1 Project Goals\nOur project was created in support of our thesis and with the following goals:\n- Help people become more aware that Google collects and tracks data about them\n- Demonstrate in real-time, the effects of Google specifying its services using the\ndata it collects on users, specific to Google Search\n- Show people the actual difference between an anonymous Google search\nexperience and a non-anonymous Google search experience\n- Provide an avenue for users to change their Google-service related habits by\noffering them a way to use Google's search engine anonymously\n5.2 Project Description\n\"Google-Anon\" is a fairly complex project that is based on the Python programming\nlanguage, Javascript and HTML. Using some basic web-related development tools and a\nlittle logic we constructed a system that allows users to conduct a search, similar to the\nway they do in Google. Upon the input of a query by a user, our system goes through a\nset of steps in order to return results that are anonymously retrieved from Google search,\nwith respect to the user, and in some cases these results are returned alongside results that\nare non-anonymously retrieved from Google search. In the case of our project, when\nanonymous results are displayed, certain areas of the returned results are emphasized to\nalert the user of information that would have been specifically targeted to their personal\ndata if the search had not been anonymous.\n5.2.1 Providing a User Interface\nThe first major step in our project was providing users with an acceptable user interface\n(UI). We chose to make a UI similar to the one that Google search displays in order to\nkeep users familiar with how they should use our service for searching. At the same time\nwe needed to allow the user to choose whether they wanted to perform a comparison\nsearch where they saw anonymous and non-anonymous results, or simply a lone\nanonymous search. Thus we provided the following components in a box at the top of\nour interface:\n- 2 radio check boxes that allow the user to choose a comparison or solely\nanonymous search\n- A text-input field that allows a user to enter search term(s) they would like to see\nresults of\n- A button that a user can click in order to initiate the search\n\nFigure 5.1 The user decides to \"Compare a Search\" or \"Anonymize a Search\", enters his/her query,\nand then clicks on \"Generate Results\" to initiate Google-Anon.\nBelow these components are simply headers and blank space that will contain the final\nresults of the search when they are returned by the system.\nFigure 5.2 Google-Anon's interface before user makes a query.\n5.2.2 Processing a Google-Anon Search\nAfter choosing a search type and entering search terms, a user clicks the \"Generate\nResults\" button to initiate a search. At this point Google-Anon must process this request\nto return the correct results. The following steps and details entail the processing of this\nrequest by our system:\nFirst, the system grabs the input from the text-field and the radio-buttons. This data is\naccessed using javascript commands that can literally call for the data in those elements\n\nof the page by the following code command:\n- getElementById('nameOfElementDesired');\nUpon getting the data in the necessary fields, the system sends it to the server using an\nasynchronous javascript method. This method is commonly referred to as AJAX and\nallows the user to send data to the server without forcing the search page to reload.\nWhen the server receives the data it creates the following string, which is a link that can\nbe used to access Google's servers and make a search query:\n- http://google.com/search?q=<INPUT TEXT HERE>\nWhen this string is constructed, the server can literally open the url using the following\nmethod call, and request a page of Google search results:\n- urlopen('http://google.com/search?q=<INPUT TEXT\nHERE>');\nBefore this method can be called though, the system needs to ensure that the request will\nbe made anonymously. In order to achieve this two things are done:\n1) an HTTPRequest header, a standard part of most requests made over the HTTP\nprotocol on the internet, is created and attached to the request that will go out to\nGoogle servers.\n2) A proxy server is contacted by the system and asked to request the url string we\nhave created. This proxy server displays its own random IP address to Google\nservers, whilst asking for the search query the system passed to it, along with the\nheader information that was created. In essence the proxy simply forwards our\nHTTPRequest, header, query-string and all.\nThe search initiated by the user has now been anonymously processed by the system and\nthe results are being awaited.\n5.2.3 Returning Anonymous and Regular Query Results\nAt this point in the system, if everything went as planned, the proxy has anonymously\nforwarded our request to Google and Google has returned the results of our request to the\nproxy, who has in turn returned the results to us. The system now has a string of text that\nrepresents the page that Google returned, which includes the results of our anonymous\nsearch. Further processing is now needed in order to return these results to the user as\nplanned.\n5.2.3.1 Anonymous Result Returning\nIn each case, the anonymous set of results is returned from the server back to the client's\nbrowser. Before doing this though, the system formats the results, so that two particular\nparts of the result page are emphasized. First the \"# of results\" section is highlighted with\na green color, then the \"Sponsored Links\" section of the page is also highlighted with a\ngreen color. Both of these highlights are performed by setting properties in the html of\n\nthe page using simple text-parsing techniques.\nOnce the page has been formatted correctly the system returns the page in string form,\nback to the user, where it will be handled by javascript that runs in the user's browser.\nOnce the javascript receives the page, it displays it. Depending on whether the user chose\na comparison search or a lone anonymous search, the javascript will display the\nanonymized results on the first half of the page or the entire page respectively.\n5.2.3.2 Regular, Non-Anonymous Result Returning\nThe non-anonymous result of the user's search is processed and returned only if the user\nchooses to \"Compare a Search\" at the top of the page. Furthermore processing only\noccurs once the anonymous search has come back to the javascript in the user's browser,\nas mentioned above.\nUpon the anonymous page results return, the javascript forces the user's browser to\ndirectly connect to Google's servers and request the search terms entered by the user.\nThis is done by making the user's browser navigate to the same URL string that was\nconstructed for the anonymous search ('http://google.com/searchq?=<INPUT TEXT\nHERE>'). The results of this connect and request are displayed in an IFRAME, also\ncalled inner frame, on the lone page of our service. The IFRAME is a component that\nacts as a browser within the page that our system gives to the user. The IFRAME allows\nits contents to connect to and display any URL that a regular browser would be able to\ndisplay. Our IFRAME lies directly to the right of the anonymous results page that has\nbeen returned and takes up the other half of the page.\nBelow are some images to help clarify what is going on:\nFigure 5.3 Results Page when user does a \"Compare a Search\" query of \"home\". Note the different\nads on the side of each set of results. The ads are geographic-specific to the user.\n\nFigure 5.4 Results page of a \"Compare a Search\" query of \"party time\". Notice the difference in\nnumber of results between the anonymized and unanonymized searches\n\nFigure 5.5 Results Page when user does a \"Compare a Search\" query of \"home\". Again, note the\ndifferent ads on the side of each set of results.\n5.3 Project Challenges and Issues\nIn creating our system, we faced a number of challenging obstacles. On the one hand, we\nwanted to create a service that allows users to make anonymous searches as fast or\ncomparably as fast as Google searches. On the other hand, Google is much more clever\nthan expected by virtue of its brilliant employees, and that being said there are a number\nof things Google does to \"prevent\" people from performing certain \"adverse\" activities\nrelated to their services.\n5.3.1 Making Users Anonymous\nThe heart of our project is making users anonymous. In order to do this we decided that\nwe, not the user would have to make the request from Google for search results that a\nuser wanted.\nOur first attempt at acting as a \"proxy\" resulted in a flat denial right off the bat. When\n\nyou try to simply write a line of code to open up the URL string that gives Google search\nresults, you get a response message like the one below that tells you that you are not able\nto make the request.\nFigure 5.6 When attempting to retrieve Google's Search Results programmatically, Google returns\nthe shown page.\nAfter feeling outwitted by Google, we finally realized that our system would have to\nimitate a browser in order to get Google to acknowledge our search request. In order to\ndo this from within the code we had to set an HTTPRequest header variable when we\nmade our request to Google (as described above). This request header was sent with our\nGoogle query and thus allowed us to get some results back until we hit another\nroadblock.\n5.3.2 Getting Past Google's Cleverness\nOur next challenge would prove to be the largest as we attempted to get past more\nGoogle cleverness and our own inexperience with web-based services.\nIt started when we realized that whilst the user may be anonymous, we as a server were\nnot anonymous and would not return interesting or different results for users as they used\nour service. Furthermore Google might feel that it no longer wanted to service requests\nfrom our system IP address and block us from using the service. This would render us\ncompletely helpless. At this point we decided to use some knowledge given to us by\nMIT's Network Admin Jeff Schiller and use a system called the Tor network. This\n\nsystem was a high-anonymity network that would allow people to make requests from\ncertain pages and return the answers to those requests undetected. The Tor network is\nshort for \"The onion routing\" network and is called so because it uses a multi-hop system\nfor routing and returning network requests. When a user makes a request through the Tor\nsystem, that request is forwarded through three different machines in the Tor network and\nthe response/answer is returned along that same route.\nWe installed the Tor software and began using it as an access point for our searches. All\nseemed well until we began getting some use on the system. We found out two major\nissues that would lead to us abandoning the benefits of the Tor network:\n1) Requests were too slow. Because the request for Google search results had to\ntravel between three different machines that were possibly spread across the\nglobe, and then perform that same trip on returning a response, our response time\nto users was entirely too slow to make it an alternative to using Google search.\n2) The Tor software used the same three-hop route for at least 10 minutes when we\nmade a request. This actually resulted in Google blocking our end-route-IP\naddress when we had light usage on the server because it interpreted all the\nrequests from one IP address as an attack on its system. This made our system\nunusable to more than one person at a time which was unacceptable.\nUnable to use the Tor network, we took a page from that same playbook and decided that\nwe should and would have to use some sort of proxy system when making requests from\nour server. We also reasoned that we could not simply use one proxy for a period of time\nsince that IP would eventually be blocked as it was when we were using Tor network.\nOur solution was to create a system of randomly rotating proxy servers that would be\nused by our server. The plan was that every time a user made a request using Google-\nAnon we would randomly retrieve a proxy from a large list of available proxies, and ask\nthe retrieved proxy to make the request on our behalf. Ironically the hardest part of this\ntask was finding a list of proxy servers that were, public, reliable, and allowed direct\nconnection without physical human presence. The effort of finding a good listing of\npublicly available, programmatically accessible proxy servers is underrated. Since the\nnew system of randomly rotated proxies has been in place, we have not had any major\nproblems with our service.\nThe occasional hiccup may occur in the system, but is quickly fixed by a browser reload.\nWe attribute these minor issues to a beta prototype, as well as a lack of enterprise level\nsoftware for our server.\nWe have put Google-Anon on the MIT network and anticipate that its use will spread via\nword of mouth. We will collect and process data about the site (e.g. how many visitors\nuse Google-Anon, how many use the anonymizer alone, how many use the comparison\nsearch, etc) only to find out if more people are interested in such services. From there,\nperhaps we will create or inspire others to create more anonymizing techniques for other\nGoogle services.\n\n6.0 Conclusions\nThis paper presents a mere glimpse of what kind of information Google collects about its\nusers and what can happen to that information. We discussed Google's most pervasive\nservices, Google Search, AdSense, and Gmail and the type of user profiles Google can\ncreate with the information collected from these services. However, we ignored many of\nGoogle's smaller services, such as Desktop, Toolbar, and Analytics that are gaining\npopularity and further intrude on users' privacy. Factoring in these services, the amount\nof information presented in the \"Bob Smith\" profile of Section 2.4 would be augmented\nto include even more penetrating information, such as Bob Smith's desktop activity and\ncomprehensive internet activity . As these intrusive services grow in popularity, they will\nensure Google's ability to gain an even stronger hold on people's personal information.\nDespite Google's growing hold on users' data, the survey in Section 4 shows that most\nGoogle users remain oblivious to the amount of personal user information Google\ncollects. The survey also shows that when presented with an anonymizing alternative,\npeople will take interest in such an option. People need to recognize what information is\nbeing gathered about them, and with that knowledge decide if and to what extent they\nwant to protect their privacy.\nWhile Google's data management seems daunting, Google is not the first and certainly\nwill not be the last company to acquire and store user data on a major scale. As society\nhurtles toward an era where user data collection is the norm, we must answer an\ninevitable question about privacy: Should we continue to fight for our personal privacy or\nshould we accept this transparency as a natural progression of technology?\nIn order for society to make this decision, people must first recognize the issue and then\nbe presented with the appropriate tools to deal with it. We hope with this paper, the\npresented survey, and Google-Anon, will initiate and bring light to a necessary discussion\nabout Google, its privacy issues, and the general progression of user data transparency.\n\n7.0 References\n[1] http://www.google.com/corporate/history.html (visited December 5, 2005).\n[2] http://www.google.com.au/press/timeline.html (visited December 5, 2005).\n[3] http://desktop.google.com/about.html (visited December 5, 2005).\n[4] http://wwww.google.com/support/toolbar/bin/answer.py?answer=14292&topic=938\n(visited December 5, 2005).\n[5] http://internetstockblog.com/article/4938 (visited December 13, 2005).\n[6] http://www.google.com/search?hl=en&q=the&btnG=Google+Search, Google search\nof \"the\" produced 9.1 billion results, (visited December 5, 2005).\n[7] The Anatomy of a Large-Scale Hypertexual Web Search Engine;\" Brin, Sergey; Page,\nLawrence; http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm; (visited\nDecember 5, 2005).\n[8] http://www.google.com/technology/index.html (visited December 5, 2005).\n[9] http://www.google.com/privacy_faq.html (visited December 5, 2005).\n[10] http://www.thisearly.com/content/view/93/2 (visited December 5, 2005).\n[11] http://en.wikipedia.org/wiki/IP_address (visited December 5, 2005).\n[12] http://www.iana.org/ipaddress/ip-addresses.htm (visited December 5, 2005).\n[13] http://en.wikipedia.org/wiki/Internet_Assigned_Numbers_Authority (visited\nDecember 5, 2005).\n[14] http://computer.howstuffworks.com/nat.htm/printable (visited December 12, 2005).\n[15] http://whatismyip.com (visited December 12, 2005).\n[16] http://www.whois.sc/ (visited December 12, 2005).\n[17] http://www.google.com/services/adsense_tour/page2.html (visited December 5,\n2005).\n[18] https://www.google.com/adsense/new (visited December 5, 2005).\n\n[19] https://adwords.google.com/support/bin/answer.py?answer=6382&hl=en (visited\nDecember 5, 2005).\n[20] http://gmail.google.com (visited December 5, 2005).\n[21] https://www.google.com/accounts/SmsMailSignup1 (visited December 5, 2005).\n[22] http://mail.google.com/mail/help/privacy.html (visited December 5, 2005).\n[23] http://www.google.com/privacypolicy.html (visited December 5, 2005).\n[24] http://www.export.gov/safeharbor/ (visited December 5, 2005).\n[25] http://www.export.gov/safeharbor/sh_overview.html (visited December 5, 2005).\n[26] http://en.wikipedia.org/wiki/Patriot_act (visited December 5, 2005).\n[27] http://www.wral.com/news/5287261/detail.html (visited December 5, 2005).\n[28] http://www.google-watch.org/krane.html (visited December 5, 2005)."
    },
    {
      "category": "Resource",
      "title": "mbtafinal_prvacy.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/b0a38781f15ef5f5d184532389a00f15_mbtafinal_prvacy.pdf",
      "content": "Privacy, SmartCards\nand the\nMBTA\n\nA Policy Analysis of the MBTA's New\nAutomated Fare Collection System\n\nIan Brelinsky\nBrian Myhre\nJennifer Novosad\nChris Suarez\n\n6.805 - December 10, 2004\nMassachusetts Institute of Technology\n\nTable of Contents\n\nAcknowledgements............................................................................................................. 4\nExecutive Summary............................................................................................................ 5\nSection 1 - History of the MBTA....................................................................................... 6\nSection 1.1 - Early Public Stagecoach Service .............................................................. 6\nSection 1.2 - Passenger Comfort and Reliability ........................................................... 7\nSection 1.3 - The First Subway in America ................................................................... 8\nSection 2 - History of RFID............................................................................................. 10\nSection 2.1 - The Commercialization of RFID ............................................................ 10\nSection 2.2 - Mult-Purpose RFID Cards...................................................................... 11\nSection 3 - Benefits to the MBTA.................................................................................... 12\nSection 3.1 - Personnel Cost Savings........................................................................... 12\nSection 3.2 - Maintenance Advantages........................................................................ 13\nSection 3.3 - Financial Benefits ................................................................................... 13\nSection 3.4 - Law Enforcement Considerations........................................................... 16\nSection 4 - Technical Basics............................................................................................. 19\nSection 5 - Cautionary Anecdotes.................................................................................... 20\n5.1 - A story says 1,000 images. .................................................................................. 20\n5.2 - Trust Your Data to People Who Manage Data [Not Trains] ............................... 20\n5.3 - Insider Abuse Has Major Risks ........................................................................... 22\n5.4 - Holey Matrimony................................................................................................. 23\n5.5 - Tracking Customers is Bad Business................................................................... 25\nSection 6 - Case Studies of RFID Smartcards in Transit.................................................. 26\nSection 6.1 - A Foreign Case - Transport for London (Oyster Card) .......................... 26\nSection 6.1.1 - Opt-out Availability for the Oyster Card......................................... 27\nReduced Fares and Student Registration .................................................................. 27\nLimiting Unregistered Card Use Geographically ..................................................... 28\nSection 6.1.2 - Oyster Card Privacy Communications............................................. 28\nAn Alternative to a Privacy Policy - London's Ticketing Data Protection Policy .. 29\nSection 6.2 - Fully Implemented Domestic Cases - The CTA and WMATA ............. 31\nSection 6.2.1 - Chicago Transit Authority (Chicago Card and Chicago Card Plus) 31\nClearly Indicating the Differences between Cards with and without Registration... 31\nMaintaining Fare (Fair) Incentives ........................................................................... 33\nThe CTA's Need for Clearly Defined Privacy Measures......................................... 33\nReleasing Information to Individuals - Security Protections for Registered Cards. 34\nSection 6.2.2 - Washington Metropolitan Area Transit Authority (SmarTrip) ........ 35\nBest Information Practices: Logging Employee Interactions with Data .................. 35\nThe WMATA's Need for Defined Privacy Measures .............................................. 36\nSection 6.3 - A Domestic Case in Development - Metro Transit (Minneapolis/St. Paul,\nMN)............................................................................................................................... 37\nA Blurry Line between Registered and Unregistered Cards..................................... 37\nIntegrating Use Incentives in an RFID System - The Ride to Rewards Program..... 37\nReduced Fares and Registration Requirements Revisited ........................................ 39\nSection 6.4 - Comparing RFID Smartcard Implementations........................................ 40\n\nSection 6.5 - Other Implementations on the Horizon .................................................. 40\nSection 6.6 - General Reflections on Interviews and Case Studies.............................. 41\nSection 6.7 - The MBTA's Privacy Action Plan .......................................................... 42\nSection 7 - Legal Considerations ..................................................................................... 43\nSection 7.1 - Chapter 66A........................................................................................... 44\nSection 7.1.1 - Chapter 66A Requires Reasonably Minimal Data Collection.......... 44\nSection 7.1.2 - Chapter 66A Constrains the feasibility of a Multi-Use CharlieCard 45\nSection 7.1.3 - Chapters 66A Requires Advance Notice of a Subpoena.................. 45\nSection 7.1.4 - Chapter 66A Provides Customers a Right to Access Their Data ..... 46\nSection 7.2 - The Personal Information Protection Act ............................................... 46\nSection 7.3 - A Constitutional Right to Travel Anonymously..................................... 47\nSection 7.4 - The Data Protection Act of 1998 ............................................................ 48\nSection 8 - Our Recommendations ................................................................................... 49\nSection 8.1 - Gaining Citizen Trust ............................................................................. 51\nSection 8.1.1 - Openness........................................................................................... 51\nSection 8.1.1.1 - Example Privacy Statements ......................................................... 53\nSection 8.1.2 Choice .............................................................................................. 55\nSection 8.1.2.1 Functionality not required for an Opt-out Program......................... 56\nSection 8.2 - Providing a Safe, Secure Service............................................................. 57\nSection 8.2.1 Preventing Internal Abuse................................................................ 58\nSection 8.2.1.1 Storing Reasonably Minimal Personal Data.................................... 59\nSection 8.2.1.2 - Data Use Policies........................................................................... 61\nSection 8.2.1.3 Response to Government Request for Data.................................. 63\nSection 8.2.1.4 Accountability............................................................................... 63\nSection 8.2.2 - Preventing External Abuse............................................................... 63\nSection 8.2.2.1 - Encryption ..................................................................................... 64\nSection 8.2.2.2 - Separation from other Networks.................................................... 65\nSection 8.2.2.3 Minimal Storage of Data.............................................................. 65\nSection 8.2.2.4 Evolving with Technology........................................................... 66\nSection 9 - Suggestions Not Included............................................................................... 67\nSection 9.1 Data Quality............................................................................................... 67\nSection 9.2 - Specifying Where Data is Stored and How in the Privacy Policy........... 67\nSection 9.3 - Recommending a Particular Storage Architecture .................................. 68\nSection 9.4 - Including Why Data Use is Acceptable in the Privacy Policy ................ 68\nSection 9.5 - Printing \"RFID Inside\" Whenever RFID Technology is Used................ 68\nAppendix A - Technical Information................................................................................ 70\nA.1 - Overview of RFID System .................................................................................. 70\nA.1.1 What is RFID? ................................................................................................ 70\nA.1.2 What the DOD and Wal-Mart see in RFID..................................................... 70\nA.1.3 Active or Passive............................................................................................ 72\nA.1.4 What's so remarkable about this stuff?........................................................... 73\nA.2.0 Plunging one level deeper (technically).............................................................. 74\nA.2.1 Active vs. Passive revisited............................................................................. 74\nA.2.2 Passive Cards - Inductive vs. RF coupled...................................................... 75\nA.2. How cards are fabricated....................................................................................... 76\nA.3 Pushing the technical limits ................................................................................... 78\n\nA.4 ###%20# hWo eNeds nEcryption? ####^%687#................................................ 78\nA.4.1 128 bit vs. 3DES vs. scrambling letters ......................................................... 80\nA.4.2 What manufactures want you to believe......................................................... 81\nA.4.3 What Encryption experts want you to know................................................... 81\nA.4.4 What should we demand in the future (technically) ....................................... 83\nAppendix B - A Possible Design ...................................................................................... 84\nSection B.1 General Design.......................................................................................... 84\nSection B.1.1 Operation of the Databases ................................................................ 85\nSection B.1.2 Meeting the Specifications................................................................. 86\nSection B.2 Variation 1: Shared Secret (Password)...................................................... 87\nSection B.3 Variation 2: Personal Information............................................................. 87\nSection B.4 A Combination.......................................................................................... 89\nAppendix C - Modifying a Current System to Incorporate our Recommendations ......... 90\nAppendix D - RFID and Transit Smartcard Glossary....................................................... 92\nReference List................................................................................................................... 95\n\nAcknowledgements\n\nWe would like to wholeheartedly thank the following people for their\ncontributions to our project. It would not have been possible without you:\n\nProfessor Hal Abelson\n\nKeith Winstein\n\nDanny Weitzner\n\nSenator Jarett Barrios\n\nDalie Jimenez\n\nDan Michaud\nSteven Berrang\nJosh Martiesian\nLeslie Caplan\nThomas Komola,\nPat Saccoia\nMary Simonowicz\nMarvin Sledge\nAnita Chan\n\nExecutive Summary\n\nThe MBTA aims to provide a safe, available, and inexpensive service to its\ncustomers while respecting its customers' basic rights to privacy. Currently, the\nMBTA is pursuing a plan of automated fare collection that will entail the use of\nRFID smartcards. Other metropolitan areas have implemented or are in the\nprocess of implementing this technology into their public transit systems. To\ndate, however, no public authority has developed or integrated a privacy policy\ndirected towards RFID. A privacy policy developed by the MBTA can serve as a\nmodel for these other systems. In this paper we will outline guiding principles\nfor a privacy policy, including openness, choice, and security. These principles\nare critical to maintaining personal and institutional security while maintaining\nthe trust of citizens; failing to address them could unnecessarily subject riders to\nbreaches of their personal privacy. These include risks of being stalked, profiled,\nor victimized by targeted advertising or theft. We specify what characteristics\nany fare-collection infrastructure would need to meet these policy principles;\nthese include provisions for the collection, access, and storage of data, in addition\nto informing users of these data practices and providing a choice to ride the T at\nthe same cost without providing personal information. We also provide a\npossible technical implementation for fare data collection in accordance with the\nprinciples. Our recommendations will address any privacy issues MBTA\ncustomers may have while enabling the MBTA to fulfill its goals of increased\nefficiency, reduced costs, and improved customer service.\n\nOur original work in several areas served to support our claims. By studying\nother RFID implementations and interviewing several transit officials we were\nable to gain perspective on the choices that are made by outside authorities. By\nreviewing and analyzing the recommendations of privacy organizations such as\nEPIC and CASPIAN, we were able to gain an understanding of the privacy\nprinciples necessary for preserving the public trust. And by meeting with local,\nstate legislative, and MBTA officials, we could relate to the local issues faced by\nthe MBTA and the Massachusetts resident. These broad perspectives gave us a\nbalance of opinions necessary to make well thought-out, realistic\nrecommendations to the MBTA.\n\nSection 1 - History of the MBTA\n\nMassachusetts and the city of Boston have a long and venerable tradition of\nexcellence in providing public transportation. These many systems reflect a\nhistoric commitment to customer service and constant advocacy for progress in\ntheir best interest. Boston is considered the birthplace of mass transportation in\nAmerica, and this pioneering and progressive spirit lives on today with the\ncurrent Massachusetts Bay Transit Authority (MBTA).1\n\nSource: http://www.mbta.com/insidethet/taag_history.asp\nLong before America\ndeclared independence from\nthe British, Bostonians were\nexperimenting with early\nversions of mass\ntransportation. The\nLegislature of\nMassachusetts offered a charter in 1630 for a ferry service from Boston to\nCharlestown, since Boston was a narrow peninsula. Thomas Williams accepted\ntheir offer in 1631 and introduced a water ferry across the Boston Harbor,\nincluding stops in Chelsea, Charlestown, and Boston. This service was family\nowned and operated for most of its history, establishing a continuing precedent\nfor personal attention to the customer and a strong connection to the\nsurrounding community.2\nSection 1.1 - Early Public Stagecoach Service\nFollowing the American Revolution, bridges were constructed to connect the\nBoston peninsula to the mainland, including Cambridge, but the flourishing\ncommonwealth still required more land transportation services to meet the\npersonal and commercial demands of its citizens. Regular stagecoach service\narrived between Boston and Cambridge in 1793, and the system quickly\nexpanded to reach the other numerous outlying areas, traveling over the many\nnew bridges.\n\nWith an ever increasing interest to meet the needs and demands of customers,\nvariations of this traditional form of stagecoach service soon appeared on the\nBoston landscape. The most notable was the daily omnibus service, with the\n\"omni\" meaning \"all.\" Similar to the current network of MBTA buses, the\nomnibuses had several assigned stops along a published route. Seats were\n\n1 \"T History: The Chronicle of the Boston Transit System.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history.asp>.\n2\"T History: The Ferry.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history2.asp>.\n\nlengthwise inside the horse-drawn vehicles, and doors at both ends allowed for\nmuch more rapid and efficient loading and unloading of passengers. They\nrepresented a monumental step forward in acknowledging the necessity for\npublic transportation to increase the scope of its availability and accessibility to\nthe citizens of Boston. If the stagecoaches are analogous to today's taxis, the\nomnibus foreshadows the incredible public promise embodied by the MBTA.3\nSection 1.2 - Passenger Comfort and Reliability\nHaving begun to address the challenge of accommodating large numbers of\npassengers, the mass transportation of Boston then set out to address passenger\ncomfort and the reliability of service. Especially as a result of cold Boston winter,\nthe streets were perpetually marred by ruts and mud, and streets covered by ice\nand snow presented an even more immediate hazard to horse-drawn vehicles.\nBoston turned to an idea New York had experimented with since 1832 of running\nthe horsecars on two parallel metal rails permanently fixed in the streets. This\ncreated a much smoother ride for the passengers, and allowed for operation\nthrough adverse weather conditions. The rails also enabled the much faster\ntransportation more weight as a result of the reduced surface friction on the\nwheels.\n\nThe first horsecar on rails began running March 26, 1856 between Central Square\nand Bowdin Street. The created an atmosphere of healthy competition with the\nrail and omnibus services that brought about even greater levels of customer\nsatisfaction and attention. However, this time period also illustrated the need for\npublic administration of mass transportation, as many routes were largely\noverlapping yet fares varied widely. Laying a foundation for the public-interest\nminded MBTA, the General Court of Massachusetts passed the West End\nConsolidation Act, which formed a single transportation system on the rails\nlining many Boston streets called the West End Street Railway. It was remarkable\naccomplishment as one of the largest such networks in the America at that time.\n\nThe next problem tackled by mass transportation pioneers following these\nsignificant improvements to comfort and reliability was public health. The West\nEnd Company maintained a fleet of 8,000 horses for pulling the street railway\ncars, which were prone to disease and frequently injured from overloaded cars.\nThe combination of sick animals and incredible amounts of waste were\nparticularly a problem in the already crowded city streets of Boston. This\nmotivated the search for alternative means of locomotion for the transit vehicles.4\n\n3 \"T History: The Omnibus.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history3.asp>.\n4 \"T History: Horsecard on Rails and the West End Street Railway Company.\" 2003. MBTA. 11 Nov.\n2004. <http://www.mbta.com/insidethet/taag_history4.asp>.\n\nCable cars had gained popularity and acceptance in other US cities during the\nlate 1800s, and Boston also entertained plans for two cable car lines stretching\nacross the city. However, the West End Company, which was scheduled to\nassume management, had apprehensions about their success in the rough Boston\nweather. In no rush to pursue the cable car plan, the transportation decision-\nmakers decided to visit Richmond, VA and preview another mass transportation\ndesign installed by the Union Passenger Railway Company. These cars ran on\nrails but were powered by electricity supplied from an overhead copper wire.5\n\nSource: http://www.mbta.com/insidethet/taag_history7.asp\nThe West End Railways\nexecutives were amazed at the\nspeeds achieved by the electrified\ncars, but they still questioned the\nability of primitive American\npower systems to handle the load.\nLate one night, Union Passenger\nran the entire fleet of 21 cars\nsimultaneously on the overhead\ncopper wires. The Bostonians\nwere thoroughly convinced and\ntook an incredible step of faith in bringing electrified rail cars to the entire\nmetropolitan area. And once again the citizens of Boston ruled the day.\nDevelopers saw the potential of connecting underdeveloped areas by rail car,\nand soon Massachusetts had more track per square mile than any other US state.\nBoston mass transit was continuing its long tradition of delivering more service\nto more people with greater reliability.6\nSection 1.3 - The First Subway in America\nBoston winters present a challenge to all aspects of life, and as mentioned before,\nestablishing reliable mass transportation is no exception. However, in 1897 an\ninfrastructure addition was unveiled that redefined the ability of city dwellers to\ntravel largely unhindered by Mother Nature and other vehicle traffic. This was\nthe year Boston opened the first subway system in America, and it paved the\nway for similar systems in urban centers across the country.7\n\nThe next half century was especially hard for the mass transportation systems as\nwar, depression, and other economic challenges jeopardized the very existence of\n\n5 \"T History: The Cable Car.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history5.asp>.\n6 \"T History: Electrification.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history6.asp>.\n7 \"T History: The Rapid Transit Commission and the BERY.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history7.asp>.\n\nmany railcar and subway routes. On August 3, 1964, the state of Massachusetts\nacknowledged the imminent situation and responded by forming the current\nMassachusetts Bay Transit Authority (MBTA) as a taxpayer supported public\nservice. The new organization initiated an aggressive and rapid strategy of\nexpansion, extending transportation links far into the suburban communities\naround Boston, including bus service, commuter rail, and subway. The MBTA\nalso contributed by consolidating numerous small, struggling railways into its\nexpanding system, including the Eastern Massachusetts Street Railway on March\n30, 1968 and the Middlesex and Boston Street Railway complex on July 1, 1972.\nThese proactive responses ensured the availability and affordability of affordable\nmass transit to Bostonians for generations to come.8\n\nSource: http://www.mbta.com/insidethet/taag_history11.asp\nToday the MBTA is the 4th\nlargest transit system in\nAmerica, and the letter 'T' has\nspecial meaning for all who\nhave come to know and love\nthis city. Yet despite its rich\nheritage and continual progress,\nthe MBTA finds itself now\nstanding at a critical crossroads.\nThe current token-based fare\ncollection system is 30 years old,\nand most of the associated station infrastructure has become burdensomely\ncostly to maintain. At the same time, law enforcement authorities are eager to\ndevelop frighteningly intrusive and evasive methods of passenger tracking and\ncontrol. Fares only cover a small fraction of operating costs, yet customers are\ngrowing increasingly dissatisfied with the quality of service.9\n\nThe challenges are real and demand immediate attention. This paper will\nhighlight the MBTA's incredible opportunity to step confidently into the future\nwhile preserving the public trust, enhancing customer satisfaction, and\nprotecting the privacy of every citizen. Other urban transportation networks\nhave had similar experiences in upgrading their fare collection technology, but\ntheir responses have largely failed to address these critical issues of customer\nservice, which have long set the MBTA apart as a leader in public transportation.\nThrough this transition process, the MBTA can set an example to be emulated by\nthe rest of the world and reestablish itself as first in mass transportation.\n\n8 \"T History: Public Control and the MTA.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history9.asp>.\n9 \"T History: New MBTA.\" 2003. MBTA. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history11.asp>.\n\nSection 2 - History of RFID\n\nA substantial component of the current MBTA system upgrades is the\nintroduction of RFID technology as part of an Automated Fare Collection system\nto replace the existing antiquated machines. RFID technology allows contact-less\nreading of information stored on a small chip inside a plastic card. The\ntechnology, however, is far from a new idea. In October 1948, Henry Stockman\nwrote what was perhaps the first scholarly paper on RFID, titled\n\"Communication by Means of Reflected Power.\" It appeared in the Proceedings\nof the Institute of Radio Engineers (IRE), a forerunner to the highly respected\nInstitute of Electrical and Electronics Engineers (IEEE). Unfortunately for\nStockman, the technology required to practically build the necessary components,\nincluding the transistor and microprocessor, would not be widely available for\nseveral decades. Even so, less sophisticated implementations of the central ideas\nbehind what we understand as RFID technology were well under development\nin the 1950s. A radio transponder system to identify aircraft as friendly or foe\nwas among these ambitious projects. 10\n\nResearch in the field of RFID gained steam in the 1960s, when a significant\nnumber of scholarly papers established and documented founding principles of\nthe field. Titles from this time period included \"Field measurements using active\nsensors,\" \"Theory of loaded scatters,\" \"Remotely activated radio frequency\npowered devices,\" and \"Interrogator-responder identification system.\"10\nSection 2.1 - The Commercialization of RFID\nThe major commercial interest at this point was theft prevention of expensive\nmerchandise. Two corporations still in existence today that formed in response to\nthis market demand were Sensormatic and Checkpoint. Both companies have\ndiversified greatly since their inception but maintain expertise and a strong\nstanding in the field of RFID enabled asset tracking and supply chain\nmanagement. The equipment was called electronic article surveillance (EAS) and\nsimply detected the presence or absence of a tag in a defined vicinity. 10\n\nThe 1970s witnessed a dramatic increase in attention to RFID technology, with\nmajor development projects at Los Alamos Scientific Laboratory and\nNorthwestern University. Large corporate systems integrators entered the scene\nas well, including Raytheon with its \"Raytag\" and similar efforts by RCA,\nFairchild Semiconductor, General Electric, Westinghouse, Philips, and Glenayre.\n\n10 \"Shrouds of Time: The history of RFID.\" 1 Oct. 2001. The Association for Automatic Identification\nand Data Capture Technologies. 11 Nov. 2004.\n<http://www.aimglobal.org/technologies/rfid/resources/shrouds_of_time.pdf>.\n\nEurope was particularly keen on the idea of tracking animals and industrial\nproducts, while America saw more potential in human and corporate resource\nmanagement. Transportation monitoring was introduced in the Port of New\nYork and New Jersey on large ships, and personnel access control followed in\nline with this application. The Association of American Railroads and Container\nHandling Cooperate Program were leading advocates for these developments.10\n\nThe first RFID implementation to experience true commercial viability and\nsuccess was automated toll collection. Dallas North Turnpike introduced RFID\npayment in 1989, sparking a decade of remarkable progress and proliferation.\nOklahoma opened a toll highway in 1991 that could read from the car's RFID\nunit as it traveled through the toll plaza at full speed. Other states in that region\nimplemented compatible systems, so a single RFID device could interact with\nmultiple reader networks or a single billing agency was responsible for collecting\npayment on behalf of multiple jurisdictions. This latter model was embraced by\nseven northeastern toll collectors who joined together as the E-Z Pass\nInteragency Group.10\nSection 2.2 - Mult-Purpose RFID Cards\nThe RFID card scheduled for release with the MBTA's new Automated Fare\nCollection implementation is named the \"CharlieCard.\" An idea very attractive\nto the MBTA as they progress with CharlieCard implementation is leasing space\non the card. The customers could include other government entities that require\nidentification and record keeping on patrons, such as the public library, or\ncommercial entities where consumers spend money on a regular basis, such as\nStarbucks or Dunkin Donuts. This is a potentially lucrative source of\nsupplementary revenue for the cash-strapped MBTA, and it is embraced as a\ngreat convenience by many customers. In reality, multi-use cards are far from a\nnew idea. The North Dallas Tollway again led the way in this innovation with its\nnovel TollTag(r), a standard vehicle mounted RFID device that could also pay\nparking lot fees and gain access to gated communities.10 A concern with this\narrangement is that personal information is shared among groups subject to\ndifferent regulations, which significantly increases increased risk of data misuse.\n\nToday RFID appears more prevalent in our everyday lives than ever before. The\nFederal Communications Commission (FCC) has aggressively provided more\nbandwidth for RFID applications in the 5.9 GHz range, representing a huge\nopportunity for proponents and those with a commercial interest. Transportation\nsystems and business around the country have had extensive experience and\ngrown comfortable with many forms of RFID technology, and now is the critical\ntime to draw lessons learned and chart the course forward.10\n\nSection 3 - Benefits to the MBTA\n\nThe MBTA has identified a number of tangible customer benefits associated with\nthis overall system upgrade, and particularly with the introduction of RFID\ntechnology. Customer service is prominent among these claims. Most T stations\ncurrently vend tokens primarily from a small, metal booth, staffed by a single\nMBTA employee who collects money, distributes tokens, and returns change to\ncustomers. Some stations also feature mechanical vending machines, but these\nare frequently inoperable and have limited ability to offer change on the\ntransactions. The result of this situation is very lengthy lines to purchase tokens,\nwhich slow down busy travelers and create problematic congestion in station\nentrances. This congestion not only impedes customer movement, but large\ncrowds create a serious law enforcement liability and danger to public safety.\nThis is particularly a problem when large events take place downtown Boston.14\nSection 3.1 - Personnel Cost Savings\nSince such a large number of personnel are required to staff fare vending booths,\nthe MBTA is unable to provide employees in the stations devoted to customer\nservice. With the elimination of human-vended tokens, these Fare Booth\nPersonnel at each station would become Customer Service Agents. The agents\nwould provide assistance with using the RFID card technology, quickly identify\nmalfunctioning technology and immediately notify the maintenance department,\nprovide directions to tourists and other visitors, and give subway riders a greater\npeace of mind regarding their safety when riding the system. It is certainly\npossible for the current Fare Booth Personnel to fulfill many of these functions,\nbut they are less approachable when seated behind bullet proof glass, and the\nfixed booth position greatly limits their view of activity in the station.12\n\nA RFID card-based fare collection system allows the MBTA to easily implement\ncustomer-friendly payment methods and lower the customer transaction cost. A\ncredit card may be linked to the MBTA card, allowing for automatic refill of the\nbalance when it drops below a certain predefined level. Another option is\nautomatic deduction for monthly or other long-term purchase options. This is\nparticularly attractive to those who use the T for transportation to work or school\non a regular basis. The ability to associate personal information with a particular\ncard also enables loss-protection and recovery of remaining card balance if a card\nis lost or stolen, since the customer can now prove his identity and be associated\nwith a particular card. This possibility is a source of great concern for privacy\nadvocates who worry about the potential to track and monitor individual\ncustomers, which will be explored later in great detail.\n\nThe opportunity to introduce online fare purchases and online account\nmonitoring are further benefits of the RFID card-based system. A user can add\ncard value from the comfort of his home or office, before even arriving at the\ntransit station. Further, it might be possible to give a customer limited access\nover the Internet to recent account activity, so he can guard and monitor against\nmalicious or unwanted use and errors in the MBTA collection technology.\nSection 3.2 - Maintenance Advantages\nThe MBTA also identifies a number of maintenance advantages associated with\ninstallation of this new system. The current token turnstiles and magnetic reader\nmachines are old technology, and the represent assets that are increasingly more\ncostly to service and maintain. Replacement parts are hard to come by, and\nfinding entire \"new\" units is an even greater problem.\n\nNew fare collection technology will also enable more rapid identification of\nhardware failures. Since every card reader is linked to a central database and\ncontrol center, remote monitoring stations can work with the Customer Service\nAgents to efficiently dispatch repair team, order replacement parts, and redirect\ncustomer traffic when needed. The current system has limited connectivity\nbetween the individual system units, and debugging almost always includes\nsending maintenance personnel to the site instead of more efficient remote\nmonitoring\nSection 3.3 - Financial Benefits\nWith rising costs and a relatively static fare structure, paramount among the\nbenefits of this system to the MBTA is potential cost savings. At present, farebox\ncollected money only covers around 22% of operating expenses, and the long-\nterm financial concerns are very real.9 The T is almost entirely dependent on\noutside cash flows to maintain its operation, with 20% of state sales taxes and an\nassessment on each jurisdiction it services going directly to MBTA operations.\nThe Authority derives the remainder of its funding from local and federal\ngrants.11 As a result, working to finance the T is an endlessly frustrating task, and\nthe possibility of automated fare collection to increase revenue beyond its cost is\nalone very convincing.\n\nAlthough many of the Fare Collection Personnel will be transformed into\nCustomer Service Agents, the MBTA will likely be able to reduce its overall\nnumber of employees as a result of the new system, and employees currently\nrepresent a huge portion of its operating expenditures. The MBTA will at the\n\n11 Davis, Jonathan. \"Balancing Debt & Pay-As-You-Go Financing.\" 10 Oct. 2002. MBTA. 10 Dec. 2004.\n<http://gulliver.trb.org/conferences/Fin3/Track2_Davis_10-28-02.pdf>.\n\nsame time need to hire skilled personnel to service and administer the automated\nsystem, this is a relatively small number, and they will simply be replacing the\nteams of people currently devoted to working on the current machines.\n\nToken handling, management, and distribution represent another substantial\nand potentially reducible cost to the MBTA. Fleets of armored trucks with\nmultiple agents on board are employed to ferry tokens from subway stations to\nsorting stations and back again. Mechanical counting and sorting technologies\nare required in all these facilities, and a huge number of people are involved in\nthe money and token handling process, as a result of proliferation of passenger\nentry and exit points, including those on the buses and commuter rail vehicles.\nSince so many transactions involve cash and token exchange, this is a massive\nand costly responsibility. Additional law enforcement challenges surrounding\nthese same four concerns are highlighted later in this section. Greatly increased\npayment by credit card, more robust automated vending machines, automatic\ncard refill capabilities, online payment alternatives, and the elimination of tokens\nwill all contribute to substantial savings in this area.12\n\nFare evasion is a major source of lost revenue to the MBTA. A business case\nstudy performed by the MIT Auto-ID sets the amount at 1.5% of total revenue,\nbased on numbers provided by the MBTA.13 MIT Detective Thomas Komola,\nwho served previously as MBTA Chief of Police, estimated based upon his\npersonal experience overseeing station law enforcement and security that a true\nrepresentation of the cost associated with fare evasion is even higher.14 Komola\npointed out that the turnstiles are very easy to circumvent, the accuracy of bus-\nbased fare collection boxes in counting coin payment and identifying invalid\nmonthly passes is very questionable, and especially on the buses, payment is\nentirely dependent on the ability of a single, unarmed driver to enforce the fare\nregulations. Furthermore, unlike most other jurisdictions around the country,\nfare evasion is not an offense subject to arrest in Boston. The MBTA's only\nrecourse in dealing with those who abuse the system in this way is asking them\nto leave. An automated system would eliminate the interaction with a human\noperator, who can be more easily intimidated and manipulated than a machine.\nA report prepared for the Seattle Monorail on fare collection alternatives for their\ngreen line found typical evasion rates between 2% and 6% for inspector verified\npayment systems around the country, including the bus and commuter rail\noperations within the MBTA. In contrast, the number was 1-2% for what they call\n\n12 Berrang, Steven and Josh Martiesian. Interview with Brian Myhre and Chris Suarez, 15 Nov. 2004.\nWritten Notes. Massachusetts Bay Transit Authority.\n13 Bean, Brandon, Robert Dudley, and Hideaki Tomikawa. \"Business Case Study: Auto-ID Fare Collection\nat the MBTA.\" 1 Feb. 2003. MIT Auto-ID Center. 10 Dec. 2004.\n<http://www.autoidcenter.cn/solution/download/Auto-\nID%20Fare%20Collection%20at%20the%20MBTA.pdf>.\n14 Komola, Thomas. Interview with Brian Myhre, 25 Oct. 2004. Written Notes. MIT Police Department.\n\n\"self-verification\" systems such as turnstiles and RFID.15 The advanced card\ntechnology would allow for more sophisticated verification of valid payment,\nand the new turnstiles can be designed to make jumping or otherwise bypassing\nthem much more challenging.\n\nAn automated fare collection system with RFID technology can also process\nlarge volume much more easily and efficiently than is currently possible.\nEliminating the inherent complications associated with people directly vending\nthe tokens is the first potential source of huge consumer benefits. Employees\nexpect a consistent number of working hours each week, which scheduled and\nunscheduled leave thrown in with relative regularity for good measure. They\nneed breaks throughout the work day, and environmental factors greatly hinder\nor enhance their ability to serve customers effectively. Furthermore, most T\nstations are unable to afford more than one fare vending employee because of\nhigh personnel costs. In contrast, machines have substantially lower life-cycle\ncosts than an actual employee. According to an acclaimed study of the current\nMBTA spending patterns \"Labor costs, driven by high pay scales, growing\nheadcounts, antiquated work rules and the state's anti-privatization statute are\nthe T's most serious challenges. To date most of the Authority's significant\nefforts to bring costs under control have been stymied by political resistance.\"16\nWith the automated fare collection system contributing to substantial savings in\nthis area, even small stations should be able to afford multiple card vending\nmachines. The machines have no preference in their working hours, refuse to\ntake coffee breaks, and are designed for optimal speed of operation.\n\nIn addition to daily demand fluctuations, there are particular instances during\nthe year with the rider traffic far outpaces the MBTA's ability to vend individual\nfare. Examples include the downtown Fourth of July festivities and large concert\nevents in the city. In these instances, huge numbers of people simultaneously\nenter a T station and overwhelm the distribution system. In some instances, the\nMBTA will simply unlock all the turnstiles and allow everyone to pass through\nwithout paying the fare, to avoid a potentially very dangerous situation with\nhundreds of tired and perhaps impaired customers clogging the entire entrance\nto buy tokens.13 The CharlieCard first allows people to easily load money in\nadvance, so they can be carrying fare and avoid fare vending lines without the\nneed to keep track of cumbersome, heavy, and easily misplaced tokens. Secondly,\nthe increased vending machine capacity will accommodate more customers\nsimultaneously, and the ability to pay with a credit card at the machines should\nimmediately speed up the fare payment process. Customers will appreciate the\n\n15 \"Green Line Fare Collection Alternatives.\" May 2003. Multisystems, Inc. 10 Dec. 2004.\n<http://www.elevated.org/_downloads/Meetings/05-05-03_Fare_Collection_Alternatives.pdf>.\n16 Tepke, Glen. \"MBTA Capital Spending: Derailed by Expansion.\" Feb. 2002. Pioneer Institute for\nPublic Policy Research. 10 Dec. 2004. <http://www.pioneerinstitute.org/pdf/mbta.pdf>.\n\nconvenience and find themselves more inclined to place additional value on the\ncard.\nSection 3.4 - Law Enforcement Considerations\nThe law enforcement communities connected to the MBTA and the metro-Boston\nregion also see incredible value and potential in the CharlieCard and Automated\nFare Collection. It will be easier to build safe and secure stations, given the\nintroduction of entirely new turnstiles, methods of fare vending, and attitudes on\npaying for transit services. The fare vending booth, a central fixture in every\ncurrent T station, would no longer be a huge customer bottleneck.13 Since the\nsystem will come with new turnstiles, the MBTA has an opportunity to\ncompletely resign the restraint mechanism. The new turnstiles may feature 5' tall\nswinging glass doors, as are already found in the New York City subway.11\n\nOne particularly important and dangerous function of the MBTA police force is\nprotecting, securing, and monitoring the huge amount of cash that passes\nthrough the system every day. The fare booth operator often has tall stacks of\nmoney on his desk, and although he is seated behind a layer of bullet proof glass,\nthe lure is no less real for the criminal mind. Even rolls of tokens have huge cash\nvalue, both inside and outside the legitimate distribution channels. Whenever the\nfare booth operator takes a personal break from his post, steps outside to help a\ncustomer, or responds to an emergency situation, his safety is in great peril\nbecause the open door exposes the money inside the booth. It is not possible for\nan armed law enforcement officer to be present at every station, and even when a\npolice presence does exist, the proximity of innocent bystanders and the\nconstraints of a small maneuvering area hinder his ability to fully respond in a\ntimely manner with appropriate and effective force, should this situation escalate.\nFurthermore, the money must be transported between stations, and this\noperation is conducted by a fleet of armored trucks, as was mentioned earlier.\nThe driver and his assistant hand carry the money from the station to the truck,\nas well as empty out money from the vending machines and other revenue\nsources inside the T station. The money is then trucked off for counting and\ndeposit, under the close supervision of MBTA police and armored transport\npersonnel. However, this is a huge drain on law enforcement resources and\nmaintains significant stress on everyone involved in the process.\n\nThe current challenge comes from the sheer quantity of cash moved around the\nsystem every day. The Automated Fare Collection system enables people to pay\nwith a credit card, which would drastically reduce the human handling of money\nat the many disparate stations throughout the MBTA system. In addition, the\nability to automatically reload a CharlieCard and purchase from on the Internet\nalso reduce the likelihood of a passenger paying with cash. The result is fewer\nlarge money transfers on a schedule less predictable and observable by those\n\nwho would disrupt the system. It is a great financial risk to have so many\nindividual parties handling money with little to no direct supervision.\n\nSimilar to the current situation with large amounts of cash in the system, the\nantiquated tokens also present a huge financial and security liability, since they\nhave a real cash value within the T. The tokens must be trucked around in\narmored vehicles, counted, sorted, rolled for redistribution, replaced when they\nwear out, and handled by many different and loosely connected parties, just like\nthe cash. Despite the nostalgia and classic feel of token payment, the T should be\nexcited to offload this cumbersome and grossly inefficient system.\n\nAnother benefit to the MBTA of Automated Fare Collection is the safety and\nwell-being of its employees who interact directly with customers on a constant\nbasis, particularly the safety and well-being of the bus drivers. There is no\nphysical barrier between the bus drivers and passengers the way it exists with\nthe fare booth personnel and subway drivers. The driver is somehow responsible\nfor ensuring that every passenger pays the correct fare, MBTA rules are properly\nenforced, and emergency situations are quickly addressed, all while safely and\nskillfully maneuvering the huge city bus. Correctly marking and handing out\ntransfer slips when requested is also expected of the bus driver, effectively\nestablishing him as not only a driver, enforcement officer, and emergency first\nresponder, but a fare agent as well. An automated fare collection system would\nwisely move the driver further away from direct interaction with the passenger\nwhile he is paying, which is a time the driver should not need to be closely\ninvolved.\n\nThe train conductors have their own set of unique challenges as a result of the\ncurrent payment arrangement. A passenger boards the train without paying,\nbecause the conductor does not have time to collect fare upon entry. While the\ntrain is in en route, the customer pays with cash or shows a pass. This requires\nthe conductor to make change and carry large amounts of money on his person.\nIt is also relatively easy for a person to pay less than the correct fair or evade the\nfair entirely, since it is not collected until later in the trip. One idea for the new\nautomated system is handheld RFID reads for the conductors to carry, which\nwould facilitate much more efficient and secure fair collection.\n\nThe law enforcement community also finds the ability to identify patterns of\nirregular activity very attractive to its mission. A sudden shift in ridership, either\na significant increase or a significant decrease, can be a valuable signal for law\nenforcement to proceed with particular vigilance and attention to detail.\nDecreased traffic at a certain station might suggest a pervasive source of\nharassment, station equipment particularly prone to failure, or inconsiderate\nMBTA employees. Increased traffic might signal a need for more police\n\npatrolling, heighten awareness of insidious plans among a group of people, and\nprovide information that enables a generally more optimal distribution of law\nenforcement resources in the future.\n\nData collected by people riding the T could also provide critically important\nevidence for criminal proceeding in which it is properly and legitimately\nsubpoenaed. Any data use along these lines would most certainly demand strict\nand closely monitored privacy policy implementation. However, law\nenforcement entities believe they could appropriately manage their use for\npurely legitimate and beneficial purposes.14 Our concerns on law enforcement\nuse of the data are addressed throughout the remainder of this paper.\n\nReturning to financial concerns, another important advantage of the CharlieCard\nis the potential for much greater flexibility in farebox revenue generation. The\nautomated system easily facilitates charging different rates for peak and off-peak\ntravel. The T could increase revenue with higher rates during the always busy\nrush hour period. Another alternative is assessing different fares based upon\ndistance traveled. Washington DC has a system along these lines, and since the\ncard can record the entry location, that could be a determinant in the fare\ncharged to the customer. Confirming and correctly charging reduced fare\ncustomers, including children and seniors, is also much easer with the\nCharlieCard, since the driver is not longer required to discern legitimate reduced\nfare cards and monitor proper payment.\n\nAutomated Fare Collection is a great service to handicapped customers. No\nlonger will they need an assistant to help them make payment and deposit fare,\nbut a simple wave of the plastic card in the direction of the reader will do the\ntrick. These represent a handful of reasons from among the variety offered by the\nMBTA for switching to Automated Fare Collection with the CharlieCard.\n\nSection 4 - Technical Basics\n\nRFID is an automatic identification system which uses tags that communicate\nwirelessly with readers to transfer identifying information that is then used to\nhelp a server make a decision. There are three parts to an RFID system: tags,\nreaders and middleware. Tags are devices that are affiliated with an external,\nmovable object. Middleware is composed of servers and infrastructure that acts\nas the brain and nervous system of the RFID system. Readers are the system's\nmouth and ears - they ask tags questions which allow the server to know what\ntag has been presented. In all, the three devices compose a powerful system\nwhich can manage enormous amounts of data with very little human interaction.\n\nTags come in many flavors. There are \"active\" tags and \"passive\" tags. Active\ntags are like over-caffeinated gifted children - they yell to readers whenever they\nwant, despite a reader's presence. They are capable of doing many things at the\nsame time, such as performing advanced calculations, taking measurements of\ntemperatures, etc. Passive tags, on the other hand, are sluggish and talk back\noften. They do not speak to readers unless asked a direct question and rarely do\nanything other than repeat themselves over and over until they are pulled away\nfrom the reader. Passive tags lack the power to do advanced calculations and\ntypically, they are a buck a dozen (whereas active tags cost more).\n\nHow far a tag can \"yell\" is determined by how much energy it has. Active tags\ncan be \"heard\" much farther away than passive tags and some passive tags can\nbe \"heard\" a bit father away than others. The distance a tag can be read from\ndepends on how much other noise is present and how loud and in what\ndirection the tag \"yells.\" Given a large enough and sensitive enough \"ear\" a tag\ncan be heard much farther away than the specs dictate.\n\nActive tags are safer than passive tags. Active tags can answer intelligently to\nquestions posed to them and (sometimes) know better than to talk to strangers.\nPassive tags learn one saying and will say it to everyone who passes by and says\n\"hello!\" Active tags are surely more trustworthy with secrets, but they cost more,\nwhich is a definite tradeoff.\n\nActive tags are better at word games, since they can do more computations faster.\nGenerally speaking, obfuscating a word or sentence so only the intended listener\nknows the meaning is called Encryption. Tags with more power and bigger\n\"brains\" (i.e. more transistors [which cost more]) can play word games better\nand thus are more secure.\n\nThere is far more to an RFID system than over-caffeinated children and yelling.\nFor a more technical discussion (but hopefully still understandable), please check\nout appendix A, Technical Information.\n\nSection 5 - Cautionary Anecdotes\n5.1 - A story says 1,000 images.\n\nThere is a lot of talk about privacy, especially in this paper, and there are two\nways of viewing the issue. If you consider yourself pragmatic, you most likely\ndeclare that you have nothing to hide and anyone who wants to take the effort to\nwatch you or look at where you go is more than welcome. If you claim to be a\nprivacy advocate, you might think that it's nobody's business where you go or\nwhat you do and there should be laws banning them from doing that.\n\nBoth sides have merit and there are tradeoffs in choosing to enforce one or the\nother. Generally, implementing more secure systems requires more testing and\nthought. Even with a well-thought plan, an implementation might not satisfy the\nneeds of everyone. For example, law enforcement would like ubiquitous access\nto movements of civilians and far more tracking and logging of transit. Society\nhas a need for dangerous and intimidating behavior to stop; however, the\nimportance of creating a safe environment must be weighed against people's\nneed for freedom, and privacy. We do not believe that there is one solution to\nthe problems we mention concerning the MBTA's new automated fare collection\nsystem. We hope through some cautionary anecdotes, we can share our vision\nand worries with you in an illustrative manner. Perhaps, by reading about poor\nCharlie, the ol' sap we place in precarious situations, we can give emotional\nreason to our suggestions and make them seem like the natural decision.\n\nWithout further ado, here's Charlie...\n\n5.2 - Trust Your Data to People Who Manage Data [Not Trains]\n\nCharlie, an old time Boston resident, recently acquired a new RFID card so he\ncould ride the T. Charlie was an average guy; he lived single in a modest\napartment, worked a modest job, traveled to see his family on holidays, and had\na fairly average life. Charlie was a good person; he was honest and expected\nothers to be as well. He never thought twice about the privacy concerns of his\nnew CharlieCard because he figured that if anyone wanted to know what he was\n\nup to, he would tell them - he reasoned that since he had no secrets, if this could\nmake his life easier, let him start living better!\n\nCharlie enjoyed his new card. He never had to worry about buying tokens again.\nHis checking account was linked to the Charlie Account so whenever he was low\non fare, the MBTA would automatically transfer $50 onto the card and he was set\nto go. He loved the ease of use of the card and especially liked not to having to\ntouch the grubby tokens ever again. Life was good for Charlie - for a few\nmonths that is.\n\nCharlie was sitting at work when it happened. He was sitting at his computer\njust as the hacker sat at hers. He typed e-mail after e-mail as she tried a recursive\nbrute force attack on the MBTA's servers. Just as he got up to go get money from\nthe ATM for lunch, she finally cracked into the MBTA's servers and was now\nlogged in as \"administrator.\" She could do anything now.\n\nCharlie was content with his financial state, he had several thousand in the bank\nand was saving for retirement - he was planning to transfer ten thousand to his\nstock portfolio, but didn't have time. Eve, the hacker, was counting on this. She\nwas now logged into the main database - it was beautiful. There, before her eyes,\nlay unencrypted databases with over a million people's checking account\nnumbers, credit card numbers, addresses, \"secret key words,\" and other personal\ninformation. She set the file to download as she, too, grabbed lunch. Then, she\nedited the main access log and wiped her traces. To the naive system\nadministrator, she was never there.\n\nCharlie walked back to his cubicle, oblivious to what had just happened with the\ninformation he thought was safe with the T. He trusted the T with his checking\naccount number, as they promised to only use it to top-off his account. He didn't\ncare if they knew his address and phone number, he even gave his social security\nnumber so he could \"verify\" his identity, a precaution they insisted upon to\nensure that his checking account really belonged to him. All was good.\n\nEve, looking for some cash to buy that new Red Mustang she always wanted,\nfound a buyer for her newly acquired information. Mwambano Mustavuff from\nNigeria was the ex-secretary of the treasury and was looking for some American\nchecking account numbers. He bought the information for $5 a name, $7 if they\nhad socials listed. In all, Eve sold only a small fraction of the names to\nMwambano, but made over $200,000 from the transaction. She got that new\nMustang and had enough cash to live off of for a few years. She was quite happy\n-- she had left no paper trail, and she could not be traced back to the transaction\nfrom the MBTA servers or from the use of the numbers.\n\nTwo months later, Charlie's credit card was denied. He tried another card and it\ntoo was denied. He didn't understand why, as he had plenty of credit, but called\nthe company to inquire. Turns out \"he\" had refinanced his house and bought\nplenty of good stuff on credit in the past month. \"His\" debauchery was now\ncatching up with him - his checking account was empty and his credit cards sky\nhigh in debt. His trusting attitude and the MBTA's poor attempt at maintaining\nsecurity for their customer's data had led to a disastrous situation he would\nnever forget (or recover fully from).\n\nWhat's the moral? The MBTA should not have kept all that data in one place.\nThey shouldn't have put all their faith into a weak system. Redundancy in\nprotection would have stopped Eve. Eve also wouldn't have gotten Charlie's\ninformation had he not given it so trustingly to the MBTA. He won't forget this\nlesson for as long as he lives.\n\n5.3 - Insider Abuse Has Major Risks\n\nCharlie lay on the pavement gagging on his own blood. He had heard a loud\nexplosion and before he could think what happened, he was cold and staring at\nthe sky. The man stood over him, a grimace on his face, shouting something\nabout Charlie deserving what he got. Everything got dark as Charlie took his\nlast breath - the man's shouting was Charlie's last experience.\n\nJust one week earlier, Ryan Marcus, the man who shot Charlie, had learned that\nhis 17 year old daughter had been assaulted by a man named Charlie M. Cardier.\nCharlie M. was not a nice person -- he had just been released from prison and\nwanted to assuage his sexual desires. Miss Marcus was walking alone in an alley;\nCharlie M saw that she was alone and took advantage of her. In the act of\nassulting her, he dropped his credit card and Miss Marcus picked it up before\ngoing to the hospital.\n\nMr. Marcus was understandably angry about his daughter. He fell into a fit of\nrage and promised to get back at Charlie M.\n\nWorking as low level system administrator at the MBTA, Mr. Marcus knew he\nhad access to the travel logs and knew just the way to find Charlie M. He\nsearched the records for \"Charlie Cardier\" and low and behold, one entry came\nup. He did a bit of research and found where Mr. Cardier typically traveled. He\nhad paid for his Charlie account using a CeltCo account (CeltCo was a company\nin Boston) and entered the T at exactly 10:35 every morning at Porter and got off\nat 10:58 at Park Street. Mr. Marcus traveled to Porter to wait for his prey. He\nspotted a man who was wearing a CeltCo polo shirt and followed him onto the\n\ntrain. The man removed his CharlieCard to exit the T and Mr. Marcus noticed\nthat his driver's license said Charlie Cardier on it. Mr. Marcus was in luck - he\nhad located the man, he though, who had raped his daughter.\n\nHe followed Charlie off the T and into the Common. He waited for Charlie to\nget to the middle of a clearing and took out his gun. Charlie didn't see it coming.\n\nSadly for Charlie, his name was Charlie T Cardier, not Charlie M Cardier. He\nhadn't assaulted anyone, nor would ever. Our star had been slain because he\nshared a name with a criminal.\n\nSadly, there have been real cases like this one. In New Hampshire, a woman is\nsuing an ISP for invading her daughter's privacy and enabling a stalker to\nmurder her.17 The court in this case decided that information brokers who store\npersonal data have a responsibility to the person indexed. If the MBTA does not\nimplement safeguards to prevent internal abuse of personal information, they are\nliable and our citizens are at risk.\n\n5.4 - Holey Matrimony\n\nCharlie is an ordinary guy and like any ordinary guy he had some issues. For\nCharlie, it was his sex life - his highly successful wife, Beth, wasn't around\nnearly enough and his love life was running on empty. He tried to take things\ninto his own power, and make due without her, but only loneliness sprung from\nhis attempts. Veronica, the tall, slender blonde from HR was always giving him\ngood vibes and he was desperate.\n\nEvery day after work, Charlie hopped on the Blue Line and rode to Wonderland\nhoping to forget his frustrations. Beth worked late and the kids had soccer\npractice, so nobody noticed that he wasn't home. Charlie and Veronica had fun\ntogether, but it was only for one purpose: recreation.\n\nBeth, noticed that Charlie seemed more relaxed and didn't want sex nearly as\noften as before. She was happy that Charlie was managing his desires, but didn't\ngive him that much credit - she suspected something. On Charlie's birthday,\nBeth decided to come home early to surprise her husband. Four o'clock rolled\naround, five o'clock came, six approached and at six thirty, Charlie ambled into\nthe house pretending that he had just come back from the gym.\n\n17 http://www.courts.state.nh.us/supreme/opinions/2003/remsb017.htm\n\nFrustrated and distraught, Beth filed for Divorce a week later. Her lawyers\nsubpoenaed Charlie's T logs and found that Charlie had been a naughty boy. He\nhad traveled from work to Wonderland and then from Wonderland back home\nevery day. From these logs, the court found that there was enough evidence that\nhe was having an affair. His wife got custody of the kids and also got a nice\nalimony check. Charlie was up the creek.\n\nWhile it was nice for Beth that the travel logs were available, Charlie did not\ncommit a crime. Moreover, the MBTA collected logs on his movements before he\nwas suspected of guilt. Collecting travel logs on people not suspected of crime,\nand using these logs in court, in a sense, makes Charlie guilty until proven\ninnocent.\n\nHe was naive for many reasons, but as far as our story goes, Charlie should have\nknown better than to trust his movements to a huge database at the MBTA. If he\nhad known the precedent of the EZ Pass system, he might have thought twice.\nThe New York Throughway System received 128 subpoenas from 1998 to 2003 -\nthey delivered information on about half of those. Subpoena's ranged from\ndivorce cases (very similar to Charlie's) to murder cases (US Attorney Luna).\nAlso, EZ Pass logs were used to discipline 30 narcotics detectives for claiming\nfalse charges in NY - they were logged driving through tolls where they were\nnot claiming to be working.18\n\nDatabases have changed how Americans live their lives. Our credit record is a\nbig database, as are our transactions from credit cards and banks. Our travel is\nlogged, as in an EZ Pass system and potentially on the T. Our recreation is\nsurely logged, as Blockbuster Video most likely tracks which customers watch\nwhat films, etc. If all these databases were linked in an intelligent form, the\nadministrator of this uber-base would know almost everything. It would be easy\nto see what someone's interests were by seeing what they do for fun. It wouldn't\nbe tough to see what they eat regularly by looking at grocery purchases, it\nwouldn't be tough to search for purchases at a Jewelers to predict whether the\nperson was engaged and a public records search would determine if he or she\nwas married. All in all, information is encroaching on the once sacred private\nsphere of our private lives. As a society, we need to determine what safeguards,\nif any, we wish to place on this information. We need to determine who we want\nto see it, how long it lasts, what can be done with it, and if it even exists. If\nyou're not willing to tell a total stranger your social security number, date of\nbirth, amount of hemorrhoid cream purchased in a year, sexual orientation, and\nyearly salary - you might wish to change your perspective on database access\ncontrols and the lifetime and breadth of data collected about you.\n\n18 AP, Dec 11 2003\n\n5.5 - Tracking Customers is Bad Business\n\nImagine Charlie is a 25 year veteran of the Boston area FBI. Charlie is getting\nready to retire. Since he has been on the job for so long, he is good at what he\ndoes and can accomplish a lot in a day. He recently got into the habit of getting\nhis hair cut and paying his bills and such over lunch - essentially adding half an\nhour to his lunch period. He figured that since he was a pro at his work, he could\nfinish everything he needed and have time to run errands, take a longer lunch\nand leave a few minutes early. He was paid for a 40 hour work week but\nultimately did a 40 hour job in 35.\n\nCharlie knew that he was technically supposed to work five more hours every\nweek, but figured that since he accomplished what he was expected to do he\nneedn't worry about being a stickler for the rules. Perhaps that's why Charlie\nwas so surprised when his boss informed him that he'd been fired for time fraud.\n\nCharlie demanded to know what evidence they had against him and learned that\nhis travel logs on the T had been obtained. The times on this time-card were\ninconsistent with the times that had been predicted based on logged T usage data.\nWhile he claimed to leave at 5:00, he was logged entering the Government Center\nT stop at 4:15. Obviously, he couldn't be in two places at once. The T's records\nwere trusted over his story.\n\nThis is what happened: HR had acquired access to the MBTA's ridership logs,\nwhich contain a rider's personal information (i.e. identifying info) and a list of\nrelevant account information (date and time of entry into a station, etc). They\nwrote a script which compared their employee list and time database to the\nMBTA database. The script checked for matches in name and compared the time\nemployees left work to the time they entered the T. If there were inconsistencies,\nthey would investigate. Unfortunately for Charlie, he was working 35 hours of a\n40 hour week and got caught red handed.\n\nAs a society, we recognize and value people's differences. Charlie happened to\nbe especially good at his job and could finish his work early and effectively. He\nis now paying the price for a database society. If we want a society where people\nmaintain a criminal mindset - constantly wondering if what they are about to do\nis wrong of if they can get away with it - we can easily implement systems which\nwill accomplish that goal. If, on the other hand, we value our freedom and\nrealize that people are only human, we need to impose restrictions on\ntechnologies which could infringe on the very essence of what a free society\nmeans to us.\n\nSection 6 - Case Studies of RFID Smartcards in Transit\n\nThe final goal of this paper is to make policy recommendations to the MBTA\nbased on its proposed RFID smartcard implementation. In making these\nrecommendations, we must examine what other transit authorities using RFID\nsmartcards have already done to combat privacy concerns. In our research, we\nfound that no major transit authority with a full-scale RFID smartcard\nimplementation (London, Chicago, Washington DC) has provided sufficient\nsafeguards for consumer privacy. This section examines each of these three\nauthorities, identifying the key areas where the authority either does an effective\nor ineffective job in addressing privacy concerns. Through a case study of Metro\nTransit in Minneapolis, this section also discusses other issues - reduced fare\nsmartcards and incentive programs - that can potentially provide customers\nwith an incentive to opt-in when they may not have otherwise wanted. The\nissues that are discussed vary by case so as to minimize redundancy of the\nsection. We hope that the MBTA will be able to use the provided information and\nsuggestions to reflect on its own privacy practices, and that, in addition, other\ntransit authorities that currently have or are considering having RFID smartcard\nimplementations will reflect on them in creating or modifying their practices as\nwell. We provide a summary of the practices of these other implementations\nalong with the variables this section considers in Figure 6.4 at the end of this\nsection.\n\nSection 6.1 - A Foreign Case - Transport for London (Oyster\nCard)\n\nTransport for London (TFL, UK) has a major implementation of automated fare\ncollection with an associated smartcard called the \"Oyster Card.\" Although TFL\nhas taken some important measures to address privacy and data use concerns for\nthis card, we found that its policies often neglect consumer privacy. Despite this,\nthe Oyster Card was given a publicly nominated award for its \"world class\nticketing system.\"19Like the CharlieCard, the Oyster Card affords users the\nopportunity to go through turnstiles quickly and easily, is rechargeable, and is\navailable to both adults and students. It records the time, date, and location of\nriders at entry (and sometimes exit) of stations. Finally, there are two options for\nriders: Oyster and Oyster pre-pay.\n\n19 \"Oyster card wins public nominated award\"\nhttp://www.oystercard.com/files/press/Oyster_wins_award_July_04_FINAL.doc\n\nSection 6.1.1 - Opt-out Availability for the Oyster Card\n\nHaving two distinct options (regular and pre-pay) effectively adds an opt-out\nprovision20 to London's RFID implementation. This is because the pre-pay card\nhas an option to be unregistered, whereby the card is not linked to a credit card\nor name. Instead of paying a fare that is automatically reloaded by the credit card,\nriders using pre-pay cards can recharge their cards with cash within London\ntransit stations. They also can be recharged on-line or over the phone using a\ncredit card. Having distinct choices for both those who do and do not want to\nreveal their identity while traveling is a significant step. Nevertheless, this opt-\nout choice is not available for all individuals interested in using some form of the\nOyster Card.\n\nReduced Fares and Student Registration\n\nIt is frustrating that any student who wishes to use an Oyster Card that provides\nstudent discounts must register. Under the current system, students who have a\nvalid \"Student Photocard\" may get reduced rates without having an Oyster Card,\nbut they must wait in lines and purchase their tickets on a per-ride basis. The\nOyster Card alternative allows students to receive these special fares via a 7 day\nor monthly pass, both of which require registration. Given the relative ease of\nusing an RFID smartcard, students will be inclined to want the Oyster Card\nregardless of their privacy concerns. The convenience of the Oyster Card does\nnot necessitate registration for passengers in general; it is thus foolish to apply\nthis double-standard to students. If a student is relies on the discount when\ngoing to class each day, he well may register regardless of the privacy\nimplications or individual concerns. The time saved by not having to wait in line\nmay be the difference between arriving late or on time to a final exam.\n\nOne argument that can be made in support of forced registration for students is\nthat it makes TFL certain that an actual student or senior is receiving the card;\nhowever, this argument neglects that someone can just as feasibly sign up for a\npre-paid card that subtracts discounted rates. Indeed, there can be a screening\nprotocol that students go through before they receive this card, and this may\nrequire the collecting of some personal information. However, screening\ninformation can be gathered and put into a database of students that have received\ncards; this would be totally unrelated to any master databases that may track\nrider movement or associate credit card numbers with riders. This way, cases of\nstudent attempts to receive multiple discounted cards can be prevented, but\n\n20 When referring to an opt-out provision, we specifically reference the ability to opt-out of an RFID\nsmartcard option that associates a customer's name with data collected from using a smartcard.\n\nstudents will be able to opt-out of releasing additional information about both\nthemselves and their future travel patterns. If a student refuses to register, a\nfield that identifies the unique card given to a student can be left blank.\n\nLimiting Unregistered Card Use Geographically\n\nAnother opt-out restriction problem is created outside of London, where TFL\nusers are unable to use the untracked Pre Pay card option on approximately 16\nseparate bus routes. Thus, an individual who travels on these bus routes is only\nable to purchase the standard Oyster card if he expects to use an RFID smartcard\nduring his trip to and from work each day. Less-frequent users of these routes\nare also affected. An individual from London, for example, may have relatives\nwho live near these bus routes. Otherwise not very intent on obtaining a\nregistered card, these individuals may get one anyway to avoid the\ninconvenience of switching from RFID to a standard ticket when making their\ntrips on these bus routes. Therefore, if a transit infrastructure provides an option\nto use a registered card in a given area, it should always provide an option to use\nan unregistered card in that area as well. This will minimize the potential for\ncases like this to occur, where people will be forced to make a difficult choice\nbetween maintaining their privacy and convenience.\n\nSection 6.1.2 - Oyster Card Privacy Communications\n\nThe level of detail of the Oyster Card website is impressive.21 The site allows\nplenty of opportunities for card registration, card recharges, and customer\nservice inquiries. It even has its own internal search engine. Referring to figure\n6.1, we see references to all of these opportunities on the main page of the Oyster\nsite. After initially examining the site, therefore, we were fairly certain that\nsomething in the privacy realm would be mentioned on the site. But upon typing\nthe word \"privacy\" into its search engine, zero results were returned. In a\ncomprehensive eleven page \"Guide to Oyster,\" moreover, no information about\nrider privacy or data collection is mentioned. Someone could easily go to the\nOyster site, register, and have no notion of their privacy or data collection rights.\nMaking a policy that is easy to locate and widely available is undoubtedly in the\npublic interest.\n\n21 The Oyster Card website is located at www.oystercard.com\n\nFigure 6.1. Screenshot of Oystercard Website\n\nAn Alternative to a Privacy Policy - London's Ticketing Data\nProtection Policy\n\nAdmittedly, TFL is unique in that it offers a \"Ticketing Data Protection Policy.22\"\nThis is a very significant adaptation for a transit system, and its existence alone\nshould be commended. Questions answered in the document include what\npersonal information is collected by TFL, what personal data is used for, what is\ndisclosed to third parties, and which third parties information can be disclosed to.\nUnfortunately, however, the data protection statement makes no direct reference\nto the Oyster Card. In fact, the only thing resembling a reference to the card in\nthe entire document is where it states \"we may collect information when you use\nour services.\" But when will they collect that information? What TFL services\ndoes this apply to? Reading the TDDP statement does not fully inform the TFL\nrider.\n\nBesides failing to answer these questions, the TDPP presents a problem to the\nconcerned customer by announcing a fairly liberal data disclosure policy. First,\ninformation can be disclosed to law enforcement and regulatory authorities. This\ncould cause an individual to be implicated in a crime based primarily on\ncircumstantial evidence. The fact that Charlie entered Station X at 1 PM with his\nOyster Card does not necessarily imply that he was a criminal in many\n\n22 Transport for London Ticketing data Protection Statement -\nhttp://www.londontransport.co.uk/tfl/nftt_dataprotection.shtml\n\ncircumstances. What if someone's card is stolen (or found) and a crime is\ncommitted? How would we know if the person who registered the card is lying\nor telling the truth? Circumstantial evidence provided at the level of an RFID\nsmartcard that is so easily lost or stolen can be unreliable. Although we realize\nthat transit authorities can be bound to release their information from a legal\nstandpoint, the amount of information released to law enforcement would\ndecrease dramatically if transit authorities stored the data for very short periods\nof time.\n\nOyster Card information could also be disclosed when it is \"in the public\ninterest.\" This is a very vague and general statement that leaves plenty of room\nfor TFL to determine innovative ways to justify disclosing data. As we will show\nin our discussions of recommended policies, we are not in support of these sorts\nof unclear statements in privacy or data use policies.\n\nIt would seem dangerous to consumers to allow TFL to make such broad\nstatements in its data collection policy or in any other policy. By instead defining\nand clarifying the public interest for consumers in its statement, TFL can fairly\njustify its data collection. And, at the point the justification is defined, the\nconsumer will at least be able to make the decision of whether to opt-in or opt-\nout upon being fully informed. Under the current system, someone who may\ndisagree with one form of data collection that is \"in the public interest\" may have\nopted-in with the assumption that data would not be collected for that case in\nwhich data is actually collected. We do not want riders of the T to experience the\nsame confusion. At a basic level, we think that it would clearly be in the public\ninterest for the public to know the specific instances when data is disclosed (or at,\nminimum, be given a definition that allows people to understand applicable\ninstances of what the public interest could be).\n\nThe TDPP also does not state how long TFL will store information that is\nattached to a particular person's name. Instead, it says that information will be\nretained \"as long as necessary\" to fulfill TFL's purposes. As with disclosing\ninformation that is in the public interest, retaining information as long as\nnecessary presents an ambiguity to the consumer that should be made clearer.\nHow long is it held for exactly? Why does holding the information for this\namount of time necessary to \"fulfill the goals?\" Unless this justification is made\nin the policy, TFL is not doing enough. We also need to ask if the goals of TFL are\nnecessarily legitimate to begin with. Should the TFL, for example, be a law\nenforcement agency? These are all tough questions that will need to be addressed\nin the MBTA's privacy policy. Due to the issues listed above, it is clear that the\nTDPP only represents a reference point for that policy.\n\nSection 6.2 - Fully Implemented Domestic Cases - The CTA and\nWMATA\n\nIn the United States, the Chicago Transit Authority (CTA) and Washington\nMetropolitan Area Transit Authority (WMATA) have instituted their own RFID\nSmartcard transit implementations. Both have fallen far short of the ideal privacy\ngoals we propose. Nevertheless, like London, both have unique practices that\nprotect privacy concerns.\n\nSection 6.2.1 - Chicago Transit Authority (Chicago Card and Chicago\nCard Plus)\n\nChicago's RFID smartcard implementation is in the form of two cards called the\n\"Chicago Card\" and \"Chicago Card Plus.\" The Chicago Card (CC) is the more\nbasic option; customers can add value (up to $100) to a CC by depositing cash\ninto vending machines within stations. Value can be checked at vending\nmachines, and registration is optional. Conversely, the Chicago Card Plus (CCP)\nrequires the use of a credit card to add value, requires registration, and does not\nallow the user to check the card's value at vending machines within stations.\nInstead, customers need to check the amount of value on their CCP online.\nFinally, whereas the CC only allows for a pay-per-use option, the CCP gives\nusers the option to apply 30 day passes to the card as well.\n\nClearly Indicating the Differences between Cards with and without\nRegistration\n\nThe differences between the two cards as explained on the CTA website are\nhighlighted in figure 6.2.23 This figure serves as a good model of what a transit\nauthority could produce that makes a viable comparison between its multiple\nsmartcard options. The figure is color coded to distinguish between the cards,\nand the key differences are clearly stated for the customer. Notably, the\nannouncement is neutral; it does not express any preference for the card that\nrequires registration. This is something that can be posted in a station for\ncustomers to look at as they consider making switches from anonymous\nmagnetic stripe cards (these are also an option in the Chicago system) to RFID\nsmartcards that may or may not be anonymous. We think it is important that\ntransit authorities ensure that their customers understand all available RFID\n\n23 http://chicago-card.com/ - The chart is referenced off of a section on the main page called \"Which Card\nis Right For You?\" The link references a COM file, and a direct link is thus unavailable.\n\nsmartcard options, and diagrams like this posted in stations or on websites serve\nthis purpose well.\n\nFigure 6.2. Comparison of Chicago Card and Chicago Card Plus\n\nIt is unfortunate that users are not told data can be collected and used after the\npoint of sale when we consider that the CTA does indeed collect data on the\ntimes and places the card is used by individuals.24 As with other RFID\nsmartcards, those that are registered can easily be traced back to a particular\nperson using this data. The CTA, as we were told in our interview with them,\ndoes not release this specific information to third parties or outside sources.\nRiders should know that this pertains to both the CC and CCP. They should also\nknow that the data on a particular customer's riding patterns can be subpoenaed\nby appropriate legal authorities. Further, they should know that their rider data\nis stored on one CTA database for 90 days, while it can be held on another for as\nlong as a full year. All of these could be mentioned in a privacy policy and/or\nTDDP.\n\nIn illustrating the differences between smartcard options, moreover, we also\nbelieve that transit authorities should clarify the implications of having a\nregistered versus an unregistered card. In this regard, Figure 2 could be\nimproved. A customer may not necessarily understand that, in addition to\nautomatic fare recovery, \"Registration\" also implies that there will be data\ncollection that is associated with the customer's name while he travels. Thus, we\nadvise transit authorities to do the following when indicating the differences\nbetween their smartcard options:\n\n24 CTA Interview with Marvin Sledge, Customer Service Manager 12/6/2004\n\n1.\nPlace an asterisk next to \"registration\" on a diagram like Figure\n6.2, and indicate that by registering, the transit authority will be\nable to collect travel data and associate with it with the\nindividual who registers.\n2.\nProvide a reference to the appropriate privacy and/or data\ncollection policies (a URL, customer service agent, or brochure\nthat can be looked at)\n\nBy doing this, we feel that customers will be given ample opportunity to\nunderstand the potential for privacy limitation and decide which card they want\nbased on that. That is, they will be able to opt-out. In all likelihood, many people\nwill not be swayed by taking these additional steps. Nevertheless, at the point\nsome people do alter their thought calculi based on these measures, we feel that\nit is the obligation of the transit authority to take them.\n\nMaintaining Fare (Fair) Incentives25\n\nChicago's fares are independent of distance traveled. Thus the time, date, and\nlocation of an access is only recorded at entry. An incentive is provided to use the\nRFID smartcards, as users receive a $1 bonus for every $10 that is added to the\ncard. Both the Chicago Card and the Chicago Card Plus provide riders with the\nbonus. This bonus creates a disincentive to use magnetic stripe cards as a mode\nof transportation. Nevertheless, given the cost-effective nature and efficiency of\nan RFID smartcard implementation, it makes sense to provide incentives to use\nsmartcards. Because the bonuses the CTA gives are uniform for both the Chicago\nCard and Chicago Card Plus, we believe that the bonuses are beneficial. Thus,\nwe encourage transit authorities to have these incentive programs. However, in\ncreating the programs, transit authorities must provide the bonus equally in both\nregistered and unregistered versions of the card.\n\nThe CTA's Need for Clearly Defined Privacy Measures\n\nWe believe that the opt-out choice and privacy provisions of the CTA aren't\ncodified well or specified for RFID smartcards. This problem was shown to exist\nin our discussion of the CTA's chart indicating the differences between its card\noptions. While the differences between the cards were presented well, the\nprivacy-related issues were essentially left on the backburner. The CTA's privacy\npolicy has similar problems. In essence, it is a general statement about website\nprivacy. It specifically states that information may be collected and that cookies\n\n25 \"Chicago Card FAQs Page.\" <http://chicago-card.com/ccplus/faq.aspx>.\n\nmay be used as an individual browses the CTA's web site; that information\ncollected when one purchases a Chicago Card will not be divulged to third party\nbusinesses; and that personal information of children under that age of 13 will\nnot be collected by the authority.\n\nIt may be good that the CTA takes these privacy steps in its policy, but the\nunfortunate reality about the CTA's privacy policy is that it does not mention the\nrelevant privacy concerns that arise when a rider uses a smartcard. The\nintroduction of the CTA's privacy policy states:\n\nThis statement provides the CTA's privacy policy on information that is\ncollected through this web site, and the Chicago CardTM and Chicago Card\nPlusTM programs and the use of that information.26\n\nAfter having said this, one would expect a sustained effort throughout the\ndocument to draw distinctions between the relevant privacy issues that arise\nfrom the smartcard as compared to those from the website. Instead, however, the\nonly major references to Chicago Cards within the policy concern the\ninformation that is collected at points of transaction. Yes, we learn that credit\ncard information, names, and addresses obtained at the point of sale will only be\nused for billing purposes and to fill orders. But there is no indication that, with a\nregistered Chicago Card, data can be collected subsequent to the initial\ntransaction and attached to a customer's name. The CTA, moreover, has no\npolicy like London's TDDP that explains why and how data is used that is\nspecifically collected from usage of the smartcard. Thus, besides adding\nprovisions about the privacy of users who use the smartcards, the CTA may also\nwant to consider creating a policy like the TDPP in the near future.\n\nReleasing Information to Individuals - Security Protections for\nRegistered Cards\n\nA final issue for the CTA is how it deals with the release of information to\ncustomers. Based on the Freedom of Information Act, all customers using\nregistered cards have a right to see their own travel histories. They also have the\nright to examine the personal information held on file by a transit authority to\nensure that it is up to date and accurate. We feel as strongly as anyone else that\nall customers should have the right to view and correct personal information and\nrider histories stored by a transit authority. But, in giving this right, transit\nauthorities must ensure that that information is only released to the actual\n\n26 Chicago Card Privacy Statement - https://www.chicago-card.com/cc/privacy.aspx\n\nperson who registered the card. Otherwise, the rights of the cardholder would\nclearly be infringed upon.\n\nTo this end, we support that the CTA associates PIN numbers with each\nregistered CCP. These 5-digit PIN numbers are chosen by users at the point of\nregistration. An individual should not have the ability to call a customer service\nrepresentative, tell the representative a card number, and receive personal\ninformation of the cardholder or the cardholder's travel history. Having a PIN\nnumber in addition to a standard card number adds an extra layer of security\nthat helps avoid cases of unreasonable data disclosure.\n\nSection 6.2.2 - Washington Metropolitan Area Transit Authority\n(SmarTrip)\n\nThe Washington Metropolitan Area Transit Authority (WMATA, Washington\nD.C.) has another implementation of an RFID smartcard. The WMATA\nimplementation uses a smartcard called the \"SmarTrip,\" and users can store as\nmuch as $300 on the card at any given time. Users have to touch the card to fare-\nboxes upon entry and exit of stations (and only upon entry of buses) because the\nWMATA MetroRail system charges fares based on the distance traveled. There is\nonly one type of SmarTrip card, and it can either be registered or unregistered.\nThe system does not provide any incentives in the form of bonuses or discounted\nfares. Based on this, we feel that the WMATA provides its customers with a\nflexible system that is neutral between registered and non-registered users.\n\nBest Information Practices: Logging Employee Interactions with Data\n\nIn our interview with the WMATA, we were able to gain some insight on other\nrelevant issues. First, we learned that the ride history of individuals is collected\nby the WMATA upon both entry and exit of each station. Like London and the\nCTA, the time, date, and location of a card touch is stored. Data is stored in\ndatabases for a minimum of one year, and the data turnover usually occurs every\ntwo years. The access to the databases is limited to those who work in the\nWMATA's customer service department, along with some upper-level\nmanagement, technical representatives, and treasury department members.\nSignificantly, the WMATA's system logs each time someone accesses data within\ntheir systems. This allows managers to do periodic checks to ensure that their\nemployees are not abusing the system. Ideally, these systems could be designed\nso that unusually high rates of access by employees can be flagged. Managers\ninformed of these flags can then address internal abuse issues quickly and easily.\n\nAt the WMATA, the customer service representatives are also limited in that\nthey are only allowed to view a cardholders name, address and daytime\ntelephone number. The personal information is in a separate database from rider\nhistories, and the customer service representatives are therefore very limited in\ntheir ability to abuse it.27 We also support this idea of isolating personal data\nfrom travel data because it makes associating one's identity with a travel history\nmuch more difficult.\n\nThe WMATA's Need for Defined Privacy Measures\n\nIf we examine the privacy policy of the WMATA, we once again see little\nmention or specifics regarding smartcard privacy.28 Unlike the CTA privacy\npolicy which at least acknowledged the existence of the Chicago Card, the\n\"Metro Privacy and Data Use Policy\" fails to specifically reference the SmarTrip\ncard at all. And meanwhile, like Chicago's policy, it puts primary emphasis on\ninformation stored and collected from websites. The privacy policy explains that\npersonal data is collected \"only if you buy from us online, subscribe to our e-mail\nsubscription service, or apply for a job online.\" While it is true that these are the\nonly instances in which personal information is collected, personal data goes much\nbeyond that. Personal data includes the travel histories of riders, and the fact that\nthe WMATA collects this information should be indicated. The record of a\nparticular individual's travel is as personal as anything else. Just as a name or\naddress helps someone to infer the identity of a particular person, a person's\ntravel history can also be used in determining someone's identity, albeit with\nmore difficulty. Personal data provides the link that allows someone to\ndetermine personal information.\n\nBecause the WMATA does not discuss the SmarTrip card in its privacy policy, it\nis clear that the WMATA does not explain the data that is collected on\nindividuals' as they use the card. It, like the CTA, should consider a TDDP policy.\nOn its privacy policy, the WMATA does say that information it collects can be\nreleased if it is subpoenaed by a court or a grand jury. It should make this fact\nclear to its customers that this is the case for both personal information and travel\nhistories. The WMATA should also explain its other motivations for tracking\nrider entry and exit, and justify why it needs to retain its travel history data for\nsuch a long period of time (1 to 2 years) in the policy.\n\n27 Pat Saccoia, WMATA Representive, Interview 10/18/2004\n28 Metro Privacy and Data Use Policy - http://www.wmata.com/about/datause.cfm\n\nSection 6.3 - A Domestic Case in Development - Metro Transit\n(Minneapolis/St. Paul, MN) 29\n\nIn May 2003, Royal Philips Electronics announced that its MIFARE technology\nwould be implemented by Metro Transit (Minneapolis/St. Paul, MN). This made\nMetro Transit the first transit authority to enter into a contract to use the\nMIFARE card.30 A year and a half later, Metro Transit is currently nearing its\nfinal phases of testing and will soon be ready to launch its RFID smartcard into a\npilot stage. Like the MBTA, Metro Transit has not yet decided its privacy policy\nor finalized its implementation plans. Considering this, and the fact that both\nBoston and Minneapolis will be using the MIFARE implementation, this case\nstudy is particularly relevant to the MBTA's privacy policy.\n\nA Blurry Line between Registered and Unregistered Cards\n\nCurrently, Metro Transit's RFID smartcard system is modeled to be similar to\nexisting systems. The implementation, like the MBTA's and London's, will only\nrequire one physical card. The technological capabilities of the MIFARE card are\nsuch that many different options can be carried out on a single card. Reduced\nfare cards for seniors and youth, 31 day passes, and standard adult fares can all\nbe indicated on separate \"purses\" programmed into the card. Because there is\nonly one physical card, the line between a card that is registered and\nunregistered is more nebulous than in the case of the CTA, where there were two\ndistinctly defined cards. Thus, we recommend that Metro transit be particularly\nvigilant in giving its customers an understanding of the differences between\nchoosing to register and choosing not to. Since this was also the case for London,\nwe recommend this measure for their implementation as well.\n\nIntegrating Use Incentives in an RFID System - The Ride to Rewards\nProgram\n\nMetro Transit currently administers a \"Ride to Rewards\" program. The purpose\nof the program is to encourage transit users in the greater Minneapolis area to\nuse public transit as a consistent alternative to driving. By encouraging the use of\nmore public transportation, the program generates increased tax revenues for\nMinnesotans, and, in addition, reduces local pollution due to auto emissions.\nCurrently, the program is run on the honor system. Customers who ride Metro\n\n29 All specific information discussed in the Minneapolis implementation comes from:\nMary Simonowicz, Transit Store Supervisor (Distribution of Farecards), Interview, 12/7/2004\n30 \"Minneapolis / St. Paul becomes first U.S. transit authority to implement Philips' contactless smart card\ntechnology.\" Smart Card Alliance Industry News. 5/20/2003\n\nTransit at least three times a week are encouraged to sign up for the program.\nThe Ride to Rewards Program webpage tells riders, \"If you already ride transit\nthree or more days a week, enroll and simply keep doing what you're doing!\"\nThe program currently has free registration, and participation has large\nincentives. Those who register can be entered into prize drawings for airline\ntickets, hotel stays, tickets for college and professional sports teams, gift\ncertificates, and more. Providing the program an email address will allow the\ncustomer to receive information about service updates and promotions. 31\n\nIn the context of Metro Transit's Go2Card implementation, the \"Ride to\nRewards\" program could pose a problem. This problem arises because, upon\nlaunch of the Go2Card, Metro Transit may impose a smartcard registration\nrequirement for all \"Ride to Rewards\" program members.\n\nAdmittedly, requiring registration does make some sense. At the point Metro\nTransit is able to track individual riding patterns, it could have the ability to\nmore equitably distribute the rewards given by its program. Instead of having\npeople illegitimately sign up for the program and ride Metro Transit less than\nthree times per week, smartcard registration will verify that participants are\nactually fulfilling the minimum standards to receive a reward. Nevertheless, we\nalso want to maintain a passenger's right to make an informed decision on\nsmartcard registration. When the choice is given to people in a world of unequal\nincentives, we firmly believe that the program inhibits the thought calculus a\nperson undergoes in choosing whether to opt-in or opt-out.\n\nCurrently, the Ride to Rewards program collects information from its\nparticipants in the form of names, addresses, phone numbers, and primary\nroutes used when traveling. All of this information is currently stored in its own\ndatabase. Therefore, post-implementation, Metro Transit can easily maintain a\ndatabase of registered users of the program that is completely independent of a\ndatabase that keeps track of registered users of the smartcard. This alternate\ndatabase can thus be used for Ride to Rewards without limiting privacy.\n\nWe know that the main privacy concern with collecting travel data is that this\ndata generally contains the locations and time stamps of the various travels of a\nparticular customer. However, the ride to rewards program is not trying to\nprovide incentives for traveling to or from certain places at certain times of the\nday. Rather, its intent is to provide incentives for traveling to or from places more\noften. Thus, the Ride to Rewards program (and others like it) can also be run\nwithout requiring smartcard registration.\n\n31 Metro Transit Ride to Rewards Program - http://www.metrotransit.org/riderPrograms/rideToRewards.asp\n\nBecause the MIFARE card can store multiple purses,32 another purse can simply\nbe added to the card that keeps track of the \"number of times traveled.\" If Metro\nTransit wishes to reward passengers who travel more than ten times a month,\nthis purse can be used to verify that this occurred and then be reset to \"0\" on a\nmonthly basis to allow for long-term participation in the program. When a\nperson desires to opt-out of smartcard registration but wishes to participate in\nRide to Rewards, the person's name will only be associated with this purse that\nkeeps track of travel frequency. Additionally, employees working within the Ride\nto Rewards Program headquarters can be restricted to access the travel frequency\ndata only. If someone did not choose to register the smartcard, that person would\nnot be listed as a registered smartcard user within those other portions of\ncustomer service that may have the ability to access travel data (times and\nlocations).\n\nIf either of these measures were to be taken, the rewards program could be\nsuccessful without attributing travel times and locations to persons using the\ncard. Unfortunately, keeping track of travel frequencies may still be undesirable\nfor some people, but the frequency data is necessary to provide the minimum\ninformation required to run the Ride to Rewards program.\n\nReduced Fares and Registration Requirements Revisited\n\nPer our discussion with Metro Transit, one more pertinent issue came up in\nconversation. Specifically, they are still determining whether they would like to\nrequire registration for seniors and students who will be receiving reduced fare\nGo2Cards. Based on our discussion of required student registration in London,\nwe are highly against required registration in these cases. The opposing\nargument we were given was that, if passengers are getting reduced fares, they\nshould do something in return to receive them. That something in return, at least\nfor Metro Transit, is smartcard registration. However, saying that the students\nand seniors need to do something in return is absurd. Transit authorities need to\ntake a step back and look at the principles behind giving reduced fares to\nstudents and seniors in the first place. These principles had nothing to do with\nthe seniors or students giving something in return; rather, they were based on\nthe reality that students and seniors are disadvantaged members of society, who\nneed to be given something in return by the state. Bearing this in mind, we ask\nMetro Transit to consider our proposals suggested to TFL in creating a reduced\nfare option for students and seniors using unregistered smartcards.\n\n32 For the MIFARE card, a \"purse\" is simply a separate area on the card designated for a different purpose.\nA MIFARE card can have separate purses for 30 day passes and cash fares, for example.\n\nSection 6.4 - Comparing RFID Smartcard Implementations\n\nTo give the MBTA and other transit authorities of some idea of the features of\ncurrent RFID smartcard implementations, we have compiled this chart (Fig 6.3)\nsummarizing some of the key points of each major system.\n\nLondon (TFL)\nChicago (CTA)\nWashington D.C. (WMATA)\nMinneapolis (Metro Transit)\nName of Card\nOystercard\nChicago Card/Chicago Card Plus\nSmartrip\nGo2Card\nOpt-out Alternative (for RFID,\nother than magnetic stripe card)\nOystercard (Pre-pay)\nUnregistered Chicago Card\nUnregistered Smartrip Card\nUnregistered Go2Card\nReduced Fares on Smartcard\nYes; Students can receive\ndiscounted farecard\n(registered Oystercard)\nNo discount cards available at this\ntime\nStudent cards are issued\nYes; Will offer reduced fares\nfor students and seniors; not\nyet sure of registration\nrequirement\nMaximum Value on Card\nn/a\n$100\n$300 $200, or two 31 day passes\nPrivacy Policy?\nYes; And have TDDP\nfocused on oystercard\nYes; But no Chicago Card data\ncollection policies discussed\nYes; But not specific mention of\nSmarTrip\nn/a\nTransit Data Protection Policy?\nYes\nNo\nNo\nn/a\nStandalone Website?\nYes; oystercard.com\nYes; chicago-card.com\nNo; will run through main\nWMATA website\nNo; will run through main metro\ntransit website\nData Collection\nTime, Date, and Location of\neach touch\nTime, Date, and Location of each\ntouch\nTime, Date, and Location of each\ntouch\nTime, Date, and possibly\nLocation\nData Retention\nn/a\n90 days-1 year\n1 year-2 years\nNot yet determined\nDirect Access To Data\nCustomer Service and\nManagement\nCustomer Service and\nManagement\nCustomer Service and\nManagement\nCustomer Service and\nManagement\nTimes of Collection (Rail)\nSometimes entry and exit;\nSometimes only entry\nEntry only\nEntry and exit always\nEntry only\nTimes of Collection (Bus)\nEntry only\nEntry only\nEntry only\nEntry only\nBonus for RFID Card Use?\nYes; Users can continue\npaying 2003 fare rates for an\nindefinite period of time\nYes; $1 Bonus for every $10\nadded to Chicago Card\nNone\nBonuses given for all farecards;\nmay apply Ride to Rewards\nOther Amenities/Possible Uses\nNone at this time\nNone\nNone\nUnder Consideration\nFee to obtain card\n3 pounds\n$5\n$5\n$5\nMIFARE Card?\nNo\nNo\nNo\nYes\n\nFigure 6.3. Comparison of London, Chicago, Washington D.C., and Minneapolis\nSmartcard Implementations\n\nSection 6.5 - Other Implementations on the Horizon\n\nThese are some of the other smartcard implementations that are currently in pilot\nor implementation phases. Additional research into these cases should provide\nfurther insight into the approaches that should be taken in an RFID smartcard\nimplementation.\n\n- Bay Area Translink33\no Limited Availability to Bus Users in October, 2004\no Full Implementation in 2005\n- Central Puget Sound Regional Fare Coordination Project34\no Seven agencies will allow linked trips between bus, transit, ferries, and\nrail by 2006\n\n33 O'Connor, Mary Catherine. \"Transit Moves Ahead with RFID.\" RFID Journal. Oct. 27, 2004.\n34 Central Puget Sound Fare Coordination Project -\nhttp://transit.metrokc.gov/prog/smartcard/smartcard.html\n\no Connects Washington, Idaho, and Oregon\n- Los Angeles County Metropolitan Transit Authority35\no To be implemented by Summer, 2005\n- Metropolitan Atlanta Rapid Transit Authority - Breeze36\no First system in the U.S. to deploy a low-cost, limited use smartcard to be\nused for ALL fare purchases\no System will feature 6-foot \"jumper proof\" gates\no Can read any smart card that meets ISO standards (more flexibility)\n\nSection 6.6 - General Reflections on Interviews and Case Studies\n\nCommon themes arose from our conversations with the representatives of the\nvarious transit authorities. Most, for example, seemed shocked that privacy was\neven an issue with smartcards. One representative of the CTA, for example, cited\nthat 96% of CTA riders have chosen the registered version of the CTA's Chicago\nCard.37 She thus seemed compelled to believe that users did not care about their\nprivacy. However, when consumers are not told about the privacy implications\nof registration, why wouldn't they register? If consumers were more informed,\nwe believe that this number would be reduced. Certainly, many transit users\nwouldn't care about the data collection practices of the WMATA or CTA, but we\nneed to acknowledge those who may change their mind based on being more\ninformed.\n\nIn addition to those concerns presented in the body of the case studies, there are\ntwo other points that should be addressed based on the information in figure 6.4.\nFirst, the length of time data is held is generally too great. Holding data for years\nat a time while keeping it associated with a person's name is unnecessary. A\ncross-application to our privacy recommendations in section 7 will help to\nexplain that. We also encourage the maximum value stored on cards to be\nlowered. In the WMATA's case, $300 in value can be stored on the card. Since\ntransit authorities have given users the right to recoup their losses from a\nregistered card if it is lost or stolen, users who see a higher maximum may be\nmore inclined to register it. Although this point is low-impact, and users can just\nput lower amounts of money on the card themselves, it is important to avoid\npractices that may encourage registration.\n\nMost of the transit representatives we talked to knew of no laws that regulated\ntheir RFID data collection practices (besides regulations against selling\n\n35 Metro Short-Range Transportation Plan - http://www.mta.net/projects_plans/shortrange/SRTP.htm\n36 Brenner, Kimberley. \"Atlanta's Transit Authority, MARTA, is taking the Georgia City Contactless.\"\nRFIDNews. February 1, 2003. - Other source http://www.itsmarta.com/\n37 Interview with Leslie Caplan, Chicago Transit Authority, 12/8/2004\n\ninformation to third parties), and acknowledged the new and developing nature\nof the laws in the RFID world. When the transit representatives acknowledged\ntheir general lack of acquaintance with any aspects of law regulating smartcards,\nthey were often willing to make concessions and appreciate some of the\nsuggestions we made. At this point, laws relating to RFID privacy and\ninformation collection practices are only beginning to be filed. Transit authorities\nneed to acknowledge that the potential for these laws is real, and that it is never\ntoo early to begin taking steps to address them. Based on our review of the\ntransit authorities in this section, it is clear that many steps still need to be taken\nto comply with laws that even minimally require transit authorities to explain\nthe privacy implications of RFID smartcards.\n\nSection 6.7 - The MBTA's Privacy Action Plan38\n\nAs London, Chicago, Washington D.C., Minneapolis, and other transit\nauthorities are asked to reflect on the privacy issues relating to their present and\nfuture RFID smartcard endeavors, the MBTA is utilizing a privacy action plan\nthroughout its process of determining an ideal privacy policy. While our paper\nand analysis provide tips and suggestions for creating a privacy policy, we\nencourage all transit authorities to create an action plan of a similar form and do\ntheir own independent analysis. As smartcard implementations change and new\nprivacy issues arise, it is important to remain up to date on any relevant\ninformation.\n\nThe plan, as reprinted in Figure 6.4, includes several useful steps in making a\nprivacy policy. These include researching comparable policies, consulting an\noutside attorney for feedback and guidance on privacy, drafting a new policy,\nutilizing customer focus groups and feedback, and creating a formal \"privacy\nofficer\" position. All of these steps are useful, especially the ones that consider\nconsumer feedback. An attorney is also necessary to ensure that data collection\nand other RFID implementation aspects do not violate local laws. However, this\nlist is not exhaustive. Transit authorities should consider new and innovative\nideas to place in their privacy action plans.\n\n38 Davis, Jonathan R. MBTA Privacy Action Plan to Senator Barrios, October 13, 2004.\n\nFigure 6.4. MBTA Privacy Policy Task List\n\nSection 7 - Legal Considerations\n\nIn this section, we focus on some of the legal discourse that exists regarding\nprivacy and data protection concerns relevant to the MBTA's smartcard\nimplementation. Unfortunately, law that specifically governs the use of RFID\nsmartcard data collection is quite limited, despite the wealth of general privacy\nlaw that exists. We first examine the relevant law in Massachusetts, including\nrecently filed legislation. We will then address an individual's Constitutional\nright to travel anonymously. Finally, we will examine the Data Protection Act of\n1998, the law in Britain that requires entities to abide by strict data protection\npractices. These legal considerations represent the synthesis of what\nimplementers of RFID should be considering\n\nSection 7.1 - Chapter 66A\n\nCurrently, Massachusetts has one statute that restricts the information practices\nof entities in Massachusetts. This law, formally known as the Fair Information\nPractices Act, specifically regulates the use of personal data by entities in\nMassachusetts in Chapter 66. In section 1 of Chapter 66A, \"Personal Data\" is\ndefined as follows:\n\n\"\"Personal data'', any information concerning an individual which,\nbecause of name, identifying number, mark or description can be readily\nassociated with a particular individual; provided, however, that such\ninformation is not contained in a public record, as defined in clause\nTwenty-sixth of section seven of chapter four and shall not include\nintelligence information, evaluative information or criminal offender\nrecord information as defined in section one hundred and sixty-seven of\nchapter six.39\n\nUpon close reading, it is clear that the MBTA's collection of data in its smartcard\nimplementation would fall well within this definition of personal data.\nSpecifically, registered cards can clearly be associated with a particular\nindividual. We know this because all transit authorities with RFID have\nemphasized that registered cards allow individuals to recover their lost or stolen\nfares. And, unless the transit authority knows who holds a particular card, it is\nimpossible to return the fare on a lost or stolen card to its rightful owner.\n\nSection 7.1.1 - Chapter 66A Requires Reasonably Minimal Data\nCollection40\n\nSince registered CharlieCards will be subject to this law, we begin to see that\nsmartcard data collection, in reality, is already quite regulated. In section 2(l) of\nChapter 66A, we are told that \"Every holder maintaining personal data shall not\ncollect or maintain more personal data than are reasonably necessary for the\nperformance of the holder's statutory functions.\" This codifies a\nrecommendation we make relating to the storing of \"reasonably minimal\npersonal data,\" where this law is also mentioned (Sections N.2.1.1, N.2.2.3). The\nMBTA will be required by this law to confirm that it is not exceeding the\nminimum of data to perform its functions. By clearly explaining why the data\n\n39 Mass State Code, Chapter 66A Section 1, Definitions, http://www.mass.gov/legis/laws/mgl/66a-1.htm\n40 Mass State Code, Chapter 66A Section 2, Fair Information Practices,\nhttp://www.mass.gov/legis/laws/mgl/66a-2.htm. This document is referenced in the rest of this section.\n\ncollection is reasonably minimal in its privacy policy, we believe that the MBTA\ncan help itself avoid legal challenges grounded in this section of the law.\n\nSection 7.1.2 - Chapter 66A Constrains the feasibility of a Multi-Use\nCharlieCard\n\nBecause the function of the MBTA is to provide transit services to residents of\nMassachusetts, we do not believe that the MBTA should make the CharlieCard a\nmulti-use card. As mentioned in our history section, there are personal privacy\nissues that could arise if a single card is used for transit, state identification,\nlibrary use, and grabbing a cup of coffee at the local Starbucks. Moreover, we see\nfrom this law that the MBTA cannot centrally administer such a card legally;\notherwise, the MBTA would need to collect data unrelated to its statutory\nfunction. Thus, if the CharlieCard became a multi-use smartcard, each agent that\nprovides card functions will need to maintain an independent database for any\ndata collected beyond the MBTA's statutory functions. From the MBTA's\nstandpoint, this would be a logistical nightmare that is incredibly inefficient. In\nsum, unless the MBTA's statutory functions were expanded to serve a more\ngeneral government purpose, the MBTA is not allowed to collect data that is\nunrelated to riding the T. And, even if its government functions were expanded in\nthis way, the MBTA would not be able to collect data that may be necessary for\nStarbucks' commercial interests.\n\nSection 7.1.3 - Chapters 66A Requires Advance Notice of a Subpoena\n\nEven though the MBTA may sometimes be forced to release data requested via a\nsubpoena, it should do so with complete regard for the customer. Simply put, the\nMBTA should take care in releasing its data to third parties, taking into account\nwhether the customer has been duly notified of any impending release. We\nbelieve in this concept in principle, but it is also established in law. According to\nchapter 66A, section 2(k) of the Massachusetts State Code, personal data should\nnot be made available in response to a subpoena unless a data subject is notified\nin advance and has an opportunity to quash the subpoena. To comply with this\nlaw, we recommend that the MBTA should send a written letter to any registered\nuser of the CharlieCard whose personal data may be involved in a subpoena.\nEach user should be given at least 30 days to respond in some legal form to the\nsubpoena request. Most people don't even understand their right to quash a\nsubpoena; MBTA riders should understand that it is their right to do so.\n\nRequests to quash RIAA41 subpoenas have been moderately successful, and\ncustomers can make compelling arguments to have them quashed. The right to\ntravel anonymously, an issue discussed in a subsequent section, is an example of\nsomething that can provide sound grounds for quashing a subpoena.\n\nSection 7.1.4 - Chapter 66A Provides Customers a Right to Access\nTheir Data\n\nAnother relevant section of Chapter 66A is section 2(j), where the law discusses\nthe rights of individuals to both contest and correct their own personal data. The\nright of receiving a hard-copy of the data, moreover, is also bestowed on\nindividuals by the Freedom of Information Act passed by Congress in 2001.\nThese provisions require the MBTA to set up a framework in which riders will\neasily be able to collect their data if requested. We therefore reaffirm our prior\nsuggestion that people should have secure methods through which they can\nensure that only they themselves are given this opportunity to correct and\ncontest their data. Our suggestion in this area was to associate a PIN number or\npassword with each registered smartcard. Therefore, when Charlie calls MBTA\ncustomer service to obtain Johnnie's personal data, he will promptly be denied\nthe right to view or correct it. If a protection framework is not set up, the MBTA\nmay have instances in which third parties obtain data unlawfully. And, since the\nMBTA has to make its data available to consumers anyway, the time for it to act\nis now.\n\nSection 7.2 - The Personal Information Protection Act\n\nThe implications of Chapter 66A are strong for the MBTA. However, recently\nfiled legislation could provide an even greater impact. This legislation, called the\nPersonal Information Protection Act, would create a new section of law called\nChapter 66B that would add several new provisions that would restrict the\ninformation practices of the MBTA. While chapter 66A more generally covered\npublic records, Chapter 66B specifically references the MBTA. It creates a\ndefinition of \"ridership data\" to demonstrate that the privacy practices in the law\nare to apply to the MBTA as much as any other entity. As defined, ridership data\nis the information that details the time and location at which a rider utilized\nservices. The particular section of interest is section 8, which adds two major\nprovisions that will govern the MBTA.\n\n41 The RIAA is the Recording Industry Association of America. It has issued hundreds of subpoenas\nrequesting information about individuals who download music from the internet illegally.\n\nFirst, the law would require that personal data not be capable of being linked to\nridership data. If this law is passed, it will severely limit the MBTA's flexibility in\nproviding registered cards. The registered card can still be tied to a person under\nthis law, but the MBTA will be constrained in that it would only be able to\nassociate the amount of money on the card with an individual. If registered cards\nwere not tied to personal information at all, the MBTA would be hard-pressed to\nrefund money from lost or stolen cards. Luckily, the law does not restrict\nassociating fare collection data with a person. This law would require the MBTA\nto isolate the databases that keep track of ridership data from those that keep\ntrack of fare deductions. Thus, this law would pose some challenges to the T, but\nwould essentially guarantee full privacy rights for all of its riders.\n\nSection 7.3 - A Constitutional Right to Travel Anonymously\n\n\"The right to travel anonymously through our T system is a right that all\ncustomers have enjoyed throughout the T's history.\"42\n-Massachusetts State Sen. Jarrett Barrios\n\nIf there was a point at which the MBTA, a public provider of transportation\nservices, compelled all individuals to register an RFID smartcard in an all-RFID\ntransit system, it would completely remove this right to travel anonymously.\nThis would set a bad precedent that goes against basic principles of\nConstitutional law and American social norms.\n\nOur team feels very strongly about maintaining this right. A right to travel\nanonymously is grounded in Constitutional Law. This right is based on the\nprecedent established in Griswold v. Connecticut, which provided the first\nexplanation of a basic right to privacy in the United States.43 Referring to Justice\nDouglas' now famous opinion, he told us that \"the First Amendment has a\npenumbra where privacy is protected from governmental intrusion\" (481).\nFurthermore, these penumbras extend to the Bill of Rights more generally. The\nFourth Amendment is also grounded in privacy. It protects against unreasonable\nsearches and seizures of ones papers and effects. In fact, as applied by the Court,\nthe primary focus of Fourth Amendment cases has been to protect privacy.44 And,\nin United States v. Kroll, a Federal court found that \"Compelling the defendant to\nchoose between exercising Fourth Amendment rights and his right to travel\n\n42 Memo from Senator Jarrett Barrios to the MBTA, Automated Fare Collection and Privacy Guidelines,\nDecember 2, 2004.\n43 Griswold v. Connecticut, 381 U.S. 479\n44 Solove, Daniel J., \"Digital Dossiers and the Dissipation of Fourth Amendment Privacy\" Southern\nCalifornia Law Review, Vol. 75, July 2002 http://ssrn.com/abstract=313301\n\nconstitutes coercion.\"45 Another case, McIntyre v. Ohio Elections Commission,\nfurther recognizes one's constitutional right to speak anonymously.46\n\nWhile speaking is not traveling in the literal sense of the word, speech is a\nbroadly defined concept that has been extended to travel. For example, if Charlie\ntraveled on the T to attend a protest rally, he would be exercising his free speech\nrights during his trip. From McIntyre, it would be clear that Charlie had a right to\ntake this trip anonymously. The MBTA shouldn't have the opportunity to\nsuspect and determine that Charlie, a well-known protester, decided he wanted\nto go to the rally based on the record of his departure at \"Park Street.\"\n\nWith respect to travel, the only instance in which government interests have\nforced individuals to reveal their names has been in airline travel, where the\ngovernment argues that a national security interest necessitates knowing the\nidentity of every traveler. Thus, people on the whole understand why the\nTransportation Security Administration checks IDs at airports. Conversely, since\nthere is no compelling national security interest in knowing the identities of all\nriders of urban transit, people would not understand why people should be\nrequired to utilize a card that is linked to a person's identity. Outside of cases in\nwhich there is an unusual justification for limiting privacy, people in our society\nare used to having the ability to travel freely and with all deliberate speed.\n\nSection 7.4 - The Data Protection Act of 1998\n\nIn England, the Data Protection Act of 1998 governs the fair use of data by\ngovernment entities.47 It is the most comprehensive data protection law that\nexists right now, although other laws are sure to follow suit. This law\nnecessitated Transport for London's Ticketing Data Protection Policy.\nSpecifically, it indicates that individuals are entitled to be fully informed about\ndata that is collected by an agency. The law requires that data controllers\ndescribe personal data that is processed, the purposes for which they are being\nprocessed, and the recipients to whom the data may be disclosed. It also allows\nindividuals to submit written requests to receive their own data. The law\ncontains an opt-out provision, and, maybe most significantly, allows individuals\nto take legal recourse and receive \"just compensation\" for any inflicted damages.\n\nA similar law may be useful within the United States. Data collection can be\nconducted in a multitude of ways, and it would be useful to have a standard that\n\n45 United States of America v. Gerald Frank Kroll. 481 F.2d 884; pg. 885\n46 McIntyre v. Ohio Elections Commission. 514 U.S. 334\n47 1998 Data Protection Act (Britain)\n\n<http://www.hmso.gov.uk/acts/acts1998/19980029.htm>\n\nforces entities to clarify what, why, and how data is collected. Currently, people\ndo not understand why so much data is collected. As we move towards an\nInternet enabled society, the necessity for this law increases as we become more\nand more surrounded by information collectors. By establishing a law like the\nData Protection Act of 1998, we feel that collectors will be forced to give more\nthought into their collection of data. After individuals collecting illegitimate data\nare found to have not disclosed their rationales for collecting, they will finally be\nsubject to a law that is clearly defined. Unfortunately, the law has yet to catch up\nin the United States, but, once it does, we will finally be able to confidently say\nthat people will have the opportunity to fully consider the privacy implications\nof the choices they make regarding RFID and data collection.\n\nSection 8 - Our Recommendations\n\nBecause of the possible security risks in the relatively new RFID technology, and\na desire to respect the rights of citizens, the MBTA and other transit systems\nshould work to build community trust, and provide a safe and secure service. To\nreach this goal, we recommend that the MBTA follow the recommendations\ngiven in the outline below.\n\n1. To build community trust\n\n1.1 The MBTA should be open about its data use policies\n\nTo accomplish this, we recommend that the MBTA post within T\nstations and on their web page:\n-\nThat the MBTA collects data about its travelers\n-\nThe specific data that it collects\n-\nHow the data is collected\n-\nThe storage lifetime of the data\n-\nThe kinds of ways this data will be used\n-\nWhen the data can be given to an outside agency\n-\nHow to opt out of providing data\n1.2 The MBTA should offer travelers the choice not to provide personal\ninformation\nTo accomplish this, we recommend that the MBTA create an opt-\nout policy which:\nAllows users to ride the T without providing personal\ninformation\nHas the same fare for travel as the default option\nDoes not physically segregate opt-out passengers from\nothers\nMinimizes additional frustration\nAllows for any discounts offered with the default card such\n\nas senior citizen discounts\n2. To provide a safe and secure service\n\n2.1 The MBTA should take measures to prevent internal abuse\n\nTo accomplish this we recommend that the MBTA\n\n2.1.1 Store a reasonably minimal amount of data\n-\nAcceptable examples include information which is\ndirectly related to system administration or customer\nservice such as name, credit card information, and\nshort travel histories.\n-\nUnacceptable examples include gender, race, and\nsexual orientation. These should not be stored.\n2.1.2 Create data use policies and guidelines specifying\n-\nwhat data uses are acceptable\n-\nwhat data uses are unacceptable\n-\nIncluding sale of personal information and\ntracking people not under investigation.\nwhat to do in the case that a use is not included in\nthe policy\nA policy for automatically recording when\nemployees access data, what data they accessed,\nand for what purpose.\n2.1.3 Create policies for response to a data request from law enforcement\ninform customers in writing if their data is requested by\na law enforcement agency.\ngive the customer 30 days to respond\nrespect the customer's right to quash\n2.1.4 Be able to demonstrate that the MBTA has followed its\nguidelines via yearly audits\n2.2 The MBTA should work to prevent external abuse of data\n\nTo accomplish this we recommend that the MBTA\n\n2.2.1 Actively encrypt all places of data transfer\n-\nIf active encryption is not possible, transferred data\nshould not directly contain personal information, and the\namount of data transferred should be minimal.\n2.2.2 Keep its database separate from other networks\n2.2.3 Store only a reasonably minimal amount of data\n2.2.4 Keep up to date security and have regularly scheduled system\nsecurity checks and updates.\n\nIn the following sections, we elaborate on the reasons for each of the above\nrecommendations. To look for the reasoning on a particular recommendation, go\nto the section with the same number. For example, if you are interested in\nrecommendation 2.2.1, please look at 8.2.2.1.\n\nSection 8.1 - Gaining Citizen Trust\n\n1. The MBTA should work to build community trust\n\n1.1 The MBTA should be open about its data use policies\nTo accomplish this, we recommend that the MBTA post within T stations and on\ntheir web page:\n-\nThat the MBTA collects data about its travelers\n-\nThe specific data that it collects\n-\nHow the data is collected\n-\nThe storage lifetime of the data\n-\nThe kinds of ways this data will be used\n-\nWhen the data can be given to an outside agency\n-\nHow to opt out of providing data\n1.2 The MBTA should offer travelers the choice not to provide personal information\nTo accomplish this, we recommend that the MBTA create an opt-out policy\nwhich:\nAllows users to ride the T without providing personal information\nHas the same fare for travel as the default option\nDoes not physically segregate opt-out passengers from others\nMinimizes additional frustration\nAllows for any discounts offered with the default card such as senior\ncitizen discounts\n\nGaining citizen trust helps to increase the number of people who use the T, and\nreduces the amount of scrutiny aimed at the T.\n\nTo gain the trust of citizens, we recommend that transit systems follow measures\nto be open about their policies of data collection, storage, processing, usage, and\ndistribution48. By being open and clear about polices, consumers have the option\nof knowing what is going on behind the scenes. This knowledge will help create\na feeling of security and trust between the users and the transit system.\n\nTransit systems should also provide a reasonable amount of choice in the\namount of personal data stored and the way that the data is used. There should\nbe an option for users who wish to remain anonymous to still ride the T without\nextra monetary cost or significant additional hassle.\n\nSection 8.1.1 - Openness\n\n1.1 The MBTA should be open about its data use policies\nTo accomplish this, we recommend that the MBTA post within T stations and on\ntheir web page:\n-\nThat the MBTA collects data about its travelers\n-\nThe specific data that it collects\n\n48 1980 Organization for Economic Cooperation and Development Guidelines\n\n-\nHow the data is collected\n-\nThe storage lifetime of the data\n-\nThe kinds of ways this data will be used\n-\nWhen the data can be given to an outside agency\n-\nHow to opt out of providing data\n\nTo maintain trust between the T and its riders, any customer using the T should\nknow how the T uses his or her personal data. This information might comprise a\nprivacy policy or be incorporated into the \"Customer Bill of Rights\" currently on\nthe MBTA webpage. 49\n\nNotifying customers of how the T uses their data will help inform people of what\nimprovements the T is making. This notification will also highlight the efforts the\nT is making to improve service, cost, and safety through use of travel data. It will\nalso give customers a sense of understanding and knowledge about how their\ndata is being used. For openness to be effective the information must be complete\nand widely distributed.\n\nTo ensure that people see information on the T's collection, storage, and use of\ndata, we recommend that this information be posted inside T stations where it\nwill be visible to all users. If posted next to route maps or near ticket vending\nmachines it would not need to take up a large amount of wall space. It is\nimportant that the information is in an area that the majority of customers will\nnotice and have the opportunity to read. Posting this information on the MBTA\nwebsite would be a good supplemental action, but alone would be incomplete to\ndistribute information. Not enough T riders look at the website for posting it on\nthe website to properly distribute the information. T riders should not have to\nactively seek this information out to be informed -- just like the signs about\nproper T etiquette and what individuals are expected to do while riding the T,\nwhat the T is expected to do for users should be widely understood by anyone\nriding the T.\n\nWe propose that all T riders know the following information50,51:\n\n- That the MBTA collects data about its travelers\n- The specific data collected\n- How this data is collected (via Charlie Card, Website, Paper Application, et)\n- The storage lifetime of the data\n- The kinds of ways this data will be used\n- When the data can be given to an outside agency\n- How to Opt-out of Providing Data\n\n49 Reference: http://www.mbta.com/contact_us/customerbill.asp\n50 1977 Privacy Protection Study Commission, \"Personal Privacy in an Information Society\"\n51 \"EPIC\" - http://www.epic.org/privacy/rfid/ftc-comts-070904.pdf\n\nSection 8.1.1.1 - Example Privacy Statements\n\nThese examples are to demonstrate the level of depth we recommend in a transit\nsystem statement of data use. Their purpose is not to recommend an exact\nstatement of intent or policy. While the MBTA's statement of intent should be\nspecific, it does not need to give any implementation details or elaborate on the\nexact uses of the data. A short statement is more likely to be read and\nunderstood.\n\nThe first example would be placed in T stations next to the maps of the T route.\nThe second example52 would be linked from the front page of the MBTA\nwebpage, and the Charlie Card web page if it exists.\n\nMBTA Use of Customer Data\n\nThe MBTA feels strongly about the privacy of its customers. To ensure that your\nprivacy rights are met, we would like you to know the following information.\n\nThe MBTA collects information on its travelers in order to improve customer\nservice, improve transit times, and reduce cost. The data that the T collects\nenables it to provide services such as automatic Charlie Card payment via credit\ncard, reissuing of lost Charlie Cards, and other customer service benefits.\nAggregated travel data also allows the T to reduce delays and coordinate train\nschedules.\n\nTo accomplish these improvements, the T collects some personal and travel\ninformation. Personal information is collected via the website or paper\napplication and includes name, birth date, home address, and credit card\nnumber. The T also logs travel data (time and location of entry and exit) via the\nCharlie Card. This data is stored for one month.\n\nThe MBTA does not sell or otherwise distribute your personal information to any\noutside agencies, except in the case of subpoena or other legal process. Should\nyou wish to not provide your personal data, you can purchase a magnetic stripe\ncard.\n\nIf you have any questions or concerns, please call xxx-xxx-xxxx\n\n52 Example based on \"Oystercard - Explanation of Pre Pay Tickets.\"\n\nCustomer Privacy and Travel\nThe MBTA feels strongly about protecting the privacy of its customers. To ensure that\nyour privacy rights are met, we would like to answer the following questions about our\ncollection and use of customer's personal information.\n\nWhat information do we collect?\nWe collect three kinds of information: identifying information, credit card information,\nand travel information. The identifying information we collect includes your name, birth\ndate, home phone, and home address. We collect your credit card company and credit\ncard number if you elect to pay via credit card. We also collect your travel patterns,\nincluding time of entry, time of exit, and which stations you traveled through.\n\nHow is this data collected?\nPersonal and credit card information is collected via our website or paper application for\na Charlie Card. Travel information is collected when ever a customer enters or leaves a\nstation with a Charlie Card, via an RFID chip inside the card.\n\nHow long is this data stored?\nPersonal and credit card information is stored for two years. Travel information is\nconnected to personal identification for 30 days. Travel information older than 30 days\ncannot be connected to an individual.\n\nWhat do we use the information for?\nInformation we collect is used\n- to improve customer service\n- to reduce travel times\n- to reduce cost\n- to bill customers\n- for administration purposes\n- for statistical analysis including travel patterns\n- in response to legal measures such as subpoena\n\nWill this information be shared with outside agencies?\nWe will provide information to the government in response to subpoena or other legal\nprocedures. We will NOT give your personal information to any other agency.\n\nWe do sell statistical travel information to advertisers buying space within T stations;\nhowever, your personal information is not connected to this data in any way.\n\nDo I have any options?\nThe MBTA provides an opt-out option for users who do not wish to have their personal\ninformation be connected to travel data. These users can ride the T at the same cost by\npurchasing a magnetic stripe card. Users do not need to present any personal\ninformation to buy this card. However, unlike the Charlie Card, the magnetic stripe cards\ndo not have an automatic credit card payment option, nor can they be reissued if lost.\n\nWhere can I find more information on the MBTA's policies?\nIf you have any questions or concerns, please send an email to privacy-help@mbta.com,\nor call xxx-xxxx.\n\nSection 8.1.2\nChoice\n\n1.2 The MBTA should offer travelers the choice not to provide personal information\nTo accomplish this, we recommend that the MBTA create an opt-out policy\nwhich53,54:\nAllows users to ride the T without providing personal information\nHas the same fare for travel as the default option\nDoes not physically segregate opt-out passengers from others\nMinimizes additional frustration\nAllows for any discounts offered with the default card such as senior\ncitizen discounts\n\nA partial opt-out policy enables users to feel that they have control over their\npersonal information and privacy. This feeling of control and choice is critical to\ncreating an atmosphere of trust. As an opt-out choice, most users will probably\nstill choose the default option of providing their personal data. This is not a bad\nthing -- the data will be used to improve T service. What is valuable is that all\nusers feel that they have the option of controlling their information, and that\nthose users with concerns can alleviate them by opting out.\n\nIn order to make users feel that they have choice, they must not feel coerced or\nstrongly encouraged to not opt-out. The choice should also be equally possible\nfor all people, independent of their economic status. For this reason, there should\nbe no monetary incentive to provide personal data. The fare for an opt-out\ncustomer should be exactly the same for a customer who opts in.\n\nIn particular, advantage programs, like senior citizen or student discounts,\nshould have an opt-out option. Because these discounts lower the cost of the fare,\nthey should be available to individuals who do not wish to have personal\ninformation in the MBTA database.\n\nAdditionally, opt-out users should not have to pay penalty in additional time or\nfrustration. The opt-out program should minimize the additional lines or waiting\nthat the opt-out customer must endure. Customer Service representatives should\nhave knowledge of the opt-out program and be able to help confused customers.\nOpt-out customers should in no way be segregated or made to feel inferior.\n\n53 \"EPIC\" - http://www.epic.org/privacy/rfid/ftc-comts-070904.pdf\n54 1973 U.S. Department of Health, Education & Welfare, Secretary's Advisory Committee on Automated\nPersonal Data Systems, Records, Computers, and the Rights of Citizens viii (1973)\n\nSection 8.1.2.1 Functionality not required for an Opt-out Program\n\nIt would be technically complicated, and sometimes impossible, to provide the\nexact same services for an opt-out customer as one who provides personal data.\nFor example, it would be impossible to mail a card to someone who had not\nprovided an address. For this reason, we refer to the opt-out policy as a partial\none. The transportation time, cost, and method should be nearly equivalent\nbetween an opt-out and an opt-in user; however, extra customer service benefits\ndo not need to be offered to opt-out users if they are complicated to implement.\nIn this section, we explicitly cover some of the customer service functionalities\nwhich would not be necessary to implement in an opt-out program.\n\nOne customer service benefit that requires personal information is automatic\nreloading (automatically charging a credit card company when the account\nreaches a minimal balance). An opt-out policy which does not require personal\ninformation could not implement this feature because it requires credit card data\nand personal data to verify ownership of the credit card.\n\nReissuing lost cards is another benefit which might be only offered to customers\nwho provide personal data. Via a login ID and password, it is possible for a user\nwho has provided no personal information to have a lost card reissued.\nHowever, implementing this functionality could require major changes to an\nexisting database, and may require substantial additional efforts on the part of\nthe T's customer service department to implement. Most importantly, this\nfunctionality is not necessary for T users to get the main benefit of the T:\ntransportation. It would be nice if reissuing lost cards was implemented for opt-\nout customers; however, it is not fundamental to protecting customer privacy\nrights, nor fostering trust because it does not pertain to the main service of the T:\ntransporting people in a cost effective and timely manner.\n\nWhile some functionality may not be offered to opt-out customers, an opt-out\noption should exist which provides equal speed of travel, access, and cost. This\nopt-out policy would allow users who are uncomfortable providing personal\ninformation to ride the T, and give all users a sense of control over their personal\ndata.\n\nSection 8.2 - Providing a Safe, Secure Service\n\nFor the MBTA to strive to provide a safe, secure service:\n\n2.1 The MBTA should take measures to prevent internal abuse\n\nTo accomplish this we recommend that the MBTA\n\n2.1.1 Store a reasonably minimal amount of data\n-\nAcceptable examples include information which is directly\nrelated to system administration or customer service such as\nname, credit card information, and short travel histories.\n-\nUnacceptable examples include gender, race, and sexual\norientation. These should not be stored.\n2.1.2 Create data use policies and guidelines specifying\n-\nwhat data uses are acceptable\n-\nwhat data uses are unacceptable\n-\nIncluding sale of personal information and tracking\npeople not under investigation.\nwhat to do in the case that a use is not included in the policy\nA policy for automatically recording when employees access\ndata, what data they accessed, and for what purpose.\n2.1.3 Create policies for response to a data request from law enforcement\n2.1.4 Be able to demonstrate that the MBTA has followed its guidelines via yearly\naudits\n2.2 The MBTA should work to prevent external abuse of data\n\nTo accomplish this we recommend that the MBTA\n\n2.2.1 Actively encrypt all places of data transfer\n-\nIf active encryption is not possible, transferred data should not\ndirectly contain personal information, and the amount of data\ntransferred should be minimal.\n2.2.2 Keep its database separate from other networks\n2.2.3 Store only a reasonably minimal amount of data\n2.2.4 Keep up to date security and have regularly scheduled system security\nchecks and updates.\n\nIn addition to fostering a sense of trust in its customers, the MBTA wants to\nprovide a safe service55. With regard to the RFID cards and databases, our\nrecommendations emphasize creating a secure database, which it is difficult to\nsteal information from, and easy for internal abuses to be tracked and identified.\n\nSome of the possible effects of data abuse are given in Section 5. Misuse of data is\nbecoming more prevalent as more databases are being made of personal\ninformation. A common example of internal abuse is illegal release of medical\nrecords. External abuse of databases includes selling lists of names and social\nsecurity numbers for identity theft. With the growing rate of crime in these areas,\nthe MBTA should take precautions to avoid internal and external abuse of data.\nIn the case that it occurs, the MBTA will be able to show that it made a good\neffort to prevent this crime.\n\n55 Reference: http://www.mbta.com/contact_us/customerbill.asp\n\nSection 8.2.1\nPreventing Internal Abuse\n\n2.1 The MBTA should take measures to prevent internal abuse\n\nTo accomplish this we recommend that the MBTA\n\n2.1.1 Store a reasonably minimal amount of data\n-\nAcceptable examples include information which is directly\nrelated to system administration or customer service such as\nname, credit card information, and short travel histories.\n-\nUnacceptable examples include gender, race, and sexual\norientation. These should not be stored.\n2.1.2 Create data use policies and guidelines specifying\n-\nwhat data uses are acceptable\n-\nwhat data uses are unacceptable\n-\nIncluding sale of personal information and tracking\npeople not under investigation.\nwhat to do in the case that a use is not included in the policy\nA policy for automatically recording when employees access\ndata, what data they accessed, and for what purpose.\n2.1.3 Create policies for response to a data request from law enforcement\n2.1.4 Be able to demonstrate that the MBTA has followed its guidelines via yearly\naudits\n\nPreventing internal abuse of data helps to reduce the chance of stalking or theft\ncaused by a T employee. Internal abuse prevention also helps to ensure that due\nprocess is being carried out, and shows an effort on the part of the T to respect\nthe rights of citizens and ensure their safety.\n\nTo prevent internal abuse of databases, we recommend that the MBTA store a\nminimal amount of data, create policies surrounding acceptable data use, and\ncreate methods to enforce accountability. Storing minimal data will reduce the\npossible damage that can occur from an employee abusing their access to data.\nTo provide organization and clarity, we recommend that the MBTA create\npolicies that outline what uses of data are acceptable, how acceptable uses can be\ncarried out, what data uses are unacceptable, and who can access the data the\ndata. To help locate abuses after they have occurred, we recommend that the\nMBTA store when employees access the database and what portion. Finally, we\nrecommend that the MBTA have some form of yearly audit to demonstrate\naccountability.\n\nSection 8.2.1.1 Storing Reasonably Minimal Personal Data\n\n2.1.1 Store a reasonably minimal amount of data\n-\nAcceptable examples include information which is directly\nrelated to system administration or customer service such as\nname, credit card information, and short travel histories.\n-\nUnacceptable examples include gender, race, and sexual\norientation. These should not be stored.\n\nTo prevent internal abuses of data the MBTA should limit stored data by storing\nreasonably minimal information which is required for system functionality (like\nbilling or travel), not aggregating databases from other sources, and separating\nuser information from identifying information (not reconstructible, or\nreconstructible only via cryptography following a special circumstance like a\ncourt order).\n\nInternal abuses of user data would be impossible if the user data did not exist.\nMoreover, the more data which is stored, the more severe the abuse could be.\nHowever, taking no data eliminates all of its potential uses. A careful balance\nshould be struck between use and security when storing data. As required by Ch.\n66a, section 2 of Massachusetts State Law, government agencies must\n\n\"(l ) not collect or maintain more personal data than are reasonably necessary for the\nperformance of the holder's statutory functions 56\"\n\n.We recommend that a reasonably minimal amount of data (such as travel data)\nbe stored which could be connected to personal information through a unique ID\nnumber. Additionally, we recommend that a reasonably minimal amount of\npersonal data be stored, such as name, contact information, and credit card\ninformation. We take this to mean that data which serves a function can continue\nto be stored; however, data with little or no potential use must be deleted.\n\nFor instance, data concerning a customer's name, home address, credit card, and\nverification information are all useful; however gender, sexual orientation, and\nrace are not necessary for billing or transportation and should not be stored at\nall. Storing excess amounts of data make identity theft easier.\n\nIn addition to reasonably minimal, we strongly recommend that data is not cross\nlinked from other sources. In addition to quality control issues, cross linking data\nposes large risks for abuse via stalking, pre-preemptive legal action, and targeted\nadvertising.\n\nFortunately, the statistical data needed for T usage studies, and even some\n\n56 \"Chapter 66A Section 2, Fair Information Practices.\" Massachusetts State Code.\n\nadvertising purposes does not require any personal information. Travel data for\nstatistical studies remains useful over long periods of time; however, the\nindividual who made that journey is not needed for these studies. The value of\npersonal information being attached to travel information usually dies out over\ntime. Periodically separating travel data from personal information only slightly\nreduces the usefulness of the data, while greatly increasing the security of the\nusers.\n\nFor example, if a data base stores the following information:\n\nRecent Data:\n(John Smith (11-29-2004 SouthStation) (12-1-2004 SouthStation))\n(Abby Flecher (11-28-2004 Wonderland) (12-1-2004 ParkStreet))\n\nOld Travel Data:\n\nThen, after a period of time, the information could be separated:\n\nRecent Data:\n(John Smith )\n(Abby Flecher )\n\nOld Travel Data:\n\n((11-28-2004 Wonderland) (12-1-2004 ParkStreet))\n((11-29-2004 SouthStation) (12-1-2004 SouthStation))\n\nAfter separation, it is still possible to do a statistical usage study of the T;\nhowever, it is not possible to figure out if John or Abby traveled to Wonderland\non November 28th, 2004.\n\nThe amount of personal travel data stored should not allow accurate prediction\nof where an individual will be on a given day of the week at a given time. To\nprevent this, separating personal information from travel data would need to be\ndone at least every two weeks. Data separation of this frequency would mean\nevery day of the week would have at most two records of personal travel data.\nFor travelers who are consistent across days of the week, even this amount of\ndata would be enough to determine movement patterns to a reasonable accuracy.\nHowever, it would be difficult to predict travelers with some variety of travel\ntimes with only two weeks of data.\n\nHowever, data has important uses up to one month, including law enforcement\nand audit reasons. If a crime occurs or a missing person is reported, it is\nreasonable to expect that law enforcement could request data within one month\nof the event. Also, if a traveler wants to dispute a bill, it is reasonable to require\nthat they notice the problem and bring it to the MBTA's attention within a\n\nmonth.\n\nBecause data is still useful within a month's time, we recommend that the MBTA\nseparate personal data from travel data at least monthly57. We would prefer that\nthe seperation occur every two weeks. Note that storing any identifying number\nwith both travel records and personal records will not effectively separate travel\nand personal information because the connection between travel information and\npersonal information can be reconstructed.\n\nIn summary, to prevent internal abuses of data the MBTA should store a minimal\namount of data by not cross linking databases from other sources, storing only\ninformation pertaining to travel and billing, and separating user information\nfrom identifying information.\n\nSection 8.2.1.2 - Data Use Policies\n\n2.1.2 Create data use policies and guidelines specifying\n- what data uses are acceptable\n- what data uses are unacceptable\n- Including sale of personal information and tracking people not under\ninvestigation.\n\nwhat to do in the case that a use is not included in the policy\n\nA policy for automatically recording when employees access data, what\ndata they accessed, and for what purpose.\n\nIn addition to storing a reasonably minimal amount of data, we recommend that\nthe MBTA create guidelines for data access and use. We also recommend that the\nMBTA create logs of when employees access data, what data they accessed, and\nfor what reason. Creating data use policies and logging employee data will help\nthe MBTA explain to employees what practices are acceptable and what are not.\nThe employee logs will provide the MBTA with a method to verify that it has\nfollowed its policy. Finally, the logs will enable the MBTA to do business and\ncustomer service studies to improve its business model.\n\nThe MBTA should create employee user names and passwords to allow\nemployees to access the database. These user names will allow the MBTA to\nrecord when employees access data. In the case of legal dispute, the MBTA could\nreference these logs to demonstrate innocence or to investigate which employee\nviolated company policy. The size of system logs of this kind would be a minor\nin comparison to the size of travel data of T users, and help the T maintain its\npolicies.\n\n57 Also recommended by Michaud, Dan. Interview with Jennifer Novosad. 27 Oct. 2004. MIT Card\nOffice.\n\nThe MBTA should also limit the number of people who have access to the data.\nWith data access requiring a log in name and password, the implementation\nwould be fairly simple. The difficulty would be in deciding which people have\naccess to the data, and how much of it they have access to. Ideally, access to the\nentire database should be restricted to as few people as possible (on the order of\n10)58. Information that is not tied to personal or identifying information could be\navailable to many more people (on the order of 50 to 100), or by request.\nReducing the number of people with access to sensitive information such as\npersonal identifying information reduces the likelihood of internal abuse.\n\nIn order for the MBTA to publish what it uses data for, and for employees to be\nknowledgeable of acceptable data practices, the MBTA should create a policy\nlisting what data uses are acceptable and what are not. Examples of allowable\nuses include\n\nany statistical studies using travel data completely stripped of personal information\nproviding a travel log to the government in response to subpoena\nsystem maintenance or improvement\ncustomer service or billing\ncustomer request to look at their record\n\nImportant examples of unallowable uses include:\n\n-\nSelling personal data (addresses and names, or names and travel information) to companies\nfor advertising or other purposes.\n-\nTracking individuals not suspected of crime.\n\nFor each example of allowable data use, the MBTA should provide a procedure\nor policy by which the data should be accessed for that use. These formal\nprocedures are particularly important when an outside agency such as a police\ndepartment or company wishes to access data for allowed purposes like usage\nstudies.\n\nOf course, it is impossible to predict all possible uses for data in advance. The\nMBTA will also want to create a policy for who will decide if a use is allowable\nor not, should the use under consideration not fall into the written guidelines.\n\n58 Recommended by <Michaud, Dan. Interview with Jennifer Novosad. 27 Oct. 2004. MIT Card Office.>\nbased on his experiences in the card office.\n\nSection 8.2.1.3\nResponse to Government Request for Data\n\n2.1.3 Create policies for response to a data request from law enforcement\n\nOther travel data collection agencies have been asked for information to help in court cases. The\nMBTA should decide on clear guidelines for how to respond to these requests.\n\nWe recommend that the MBTA\n\nInform customers in writing if their data is requested by a law enforcement agency.\n\ngive the customer 30 days to respond\n\nrespect the customer's right to quash\n\nSection 8.2.1.4\nAccountability\n\n2.1.4 Be able to demonstrate that the MBTA has followed its guidelines via yearly audits\n\nWe recommend that the MBTA undergo yearly audits to analyze if the practices\nof MBTA employees are in agreement with the data use policies59. By allowing\nyearly audits, the MBTA will improve internal data security, catch abuses and\nlocate dangers that would otherwise not be found. Audits will also increase\noutside trust in the system. If the audit could be done by an outside agency, it\nwould be more effective in finding errors and increasing system trust. If this is\nnot possible, an internally conducted audit would still be useful. Auditors should\nreceive the system logs about employee data access, and be assisted by an\nemployee with full data access.\n\nSection 8.2.2 - Preventing External Abuse\n\n2.2 The MBTA should work to prevent external abuse of data\n\nTo accomplish this we recommend that the MBTA\n\n2.2.1 Actively encrypt all places of data transfer\n-\nIf active encryption is not possible, transferred data should not\ndirectly contain personal information, and the amount of data\ntransferred should be minimal.\n2.2.2 Keep its database separate from other networks\n2.2.3 Store only a reasonably minimal amount of data\n2.2.4 Keep up to date security and have regularly scheduled system security\nchecks and updates.\n\nWe recommend that strong encryption be used at every point of data transfer or\naccess, that data is difficult to retrieve from remote systems, and that the amount\nof data be reasonably minimal.\n\n59 Recommended by Michaud, Dan. Interview with Jennifer Novosad. 27 Oct. 2004. MIT Card Office.\n\nSection 8.2.2.1 - Encryption\n\n2.2.1 Actively encrypt all places of data transfer\n-\nIf active encryption is not possible, transferred data should not\ndirectly contain personal information, and the amount of data\ntransferred should be minimal.\n\nTo prevent adversaries from accessing data by eavesdropping on\ncommunications between parts of the system, we recommend that data be\nencrypted whenever it is transferred. Examples of transfer points include\nbetween the card and the reader, between the reader and the database, and\nbetween the database and any other computer or network. Sensitive data like\ncredit card numbers should remain encrypted while in storage, using a different\nencryption system. This is a safeguard in the event of security breach.\n\nBecause RFID cards can be read remotely60, it is particularly important that data\non them is actively encrypted (equivalently, the card should send out a variety of\nsignals, rather than just one signal). If the card only sends out one kind of signal,\nand unfriendly agent could read the signal remotely, and then send out that\nsignal to impersonate that card. The unfriendly agent would not need to break\nthe encryption, only be able to read the card. Since handheld readers can be\npurchased or built, cards should be carefully encrypted.\n\nPassively encrypted cards simply emit the same data over and over again with\nthe same encryption applied to it. This is completely ineffective if our fear is\nabout cloning cards; a clone card might have no idea what it is broadcasting, but\ncan access restricted items regardless. For more information, please see\nAppendix A, particularly the subsection concerning encryption.\n\nIf cost prevents cards from being actively encrypted, it is crucial that cards are\nnot rewritable and contain only a number. While this number will relate to\npersonal information in the database, an unfriendly agent with a handheld\nreader could only learn a number from reading cards of passerby. Though this\nnumber can be used to steal money from T rider's accounts, it could not be used\nto impersonate them in any other way, like a name, social security number, or\naddress could.\n\nAdditionally, particularly sensitive information such as credit card numbers may\nneed to have a second layer of encryption for storage. This encryption layer\nshould be particularly difficult to break without the key, such as public key\nencryption. Decryption could occur as the data is needed, such as for billing\npurposes.\n\n60 CNETnews.com - http://news.com.com/RFID+tags+become+hacker+target/2100-1029_3-5287912.html\n\nSection 8.2.2.2 - Separation from other Networks\n\n2.2.2 Keep its database separate from other networks\n\nTo improve security, the number of places data can be accessed from should be\nminimized; equivalently, data should be connected to the smallest network\npossible.\n\nFor example, the server that holds the user data might have a protocol to accept\nincoming information, virus check it, and store it. The server would never\nexecute incoming files, to reduce the possibility of virus attack. However,\nremoving data from the server might require being in physical proximity to the\nserver, or physically connected through a local network.\n\nWe recommend that user information not be accessible from the internet. Rather\nthan attempting to guess a password through internet protocol, a hacker would\nhave to know which physical machines stored the data and hack into them. This\ncreates one more barrier to data access.\n\nKeeping user information off of the internet has the disadvantage that T travelers\ncannot use an online account to view their information or register for a Charlie\nCard. Instead, they would need to mail requests or make them in a physical\nlocation like a T station. We feel that this disadvantage is necessary to protect\nusers from the dangers of data breach such as stalking or credit card theft.\n\nSection 8.2.2.3\nMinimal Storage of Data\n\n2.2.3 Store only a reasonably minimal amount of data\n\nThe value of the data contained in the database will relate to outsiders desire to\nhack in. By storing less data, the value of the database can be decreased to make\nit a less attractive target.\n\nOf course, a certain amount of data will need to be stored for normal functioning\nof the system. Storing a reasonably minimal amount of data would help prevent\nidentify theft, while still allowing for system functionality.\n\nTravel data connected to user profiles should have a limited lifetime. We\nrecommend no more than one month lifetime, and would prefer no more than\ntwo weeks so that data could not be used to create consistent travel pattern\nmodels (See section 8.2.1.1). The purpose of removing the personal information\n\nfrom the travel data is to reduce the possibility of stalking that could occur if an\nunfriendly agent hacked into the data base. Fortunately, travel data can still be\nuseful without a connection to any personal information. Travel information\nwithout personal information can still be used in statistical studies such as T\nstation usage over the day, finding traffic between two stations, and looking at\nstatistical movement patterns. To separate travel data from personal information,\na database would only need to create tables with lists the times and locations of\ntravel of anonymous users to store what movements were made over a month\nlong period.\n\nIn accordance with storing a reasonably minimal amount of data, the data base\nshould not be cross-linked with other data bases or contain unrelated aggregated\ndata. For example, a data base of library records should not be linked with the\nMBTA's database. The combined database would be a larger target, and require\nonly one security breach where before two were needed. Also, with a larger\namount of information available there, and unfriendly agent could create more\ndamage with malicious actions.\n\nSection 8.2.2.4\nEvolving with Technology\n\n2.2.4 Keep up to date security and have regularly scheduled system security\nchecks and updates.\n\nBecause new hacking and virus technologies are constantly being produced, and\nany system can be hacked given enough time, it will be necessary to periodically\nupdate the security software of the architecture to maintain a secure system. We\nrecommend that the MBTA include somewhere in its internal policies a schedule\nfor mandatory evaluation and updates of the current system.\n\nSection 9 - Suggestions Not Included\n\nThere are many recommendations commonly included in other reports which we\nhave decided to leave out. We left these out because they did not pertain to the\nsituation of the MBTA and other transit systems, or because they did not make\nsense given our other recommendations. The recommendations what we did not\ninclude involve data quality, specifying a particular architecture, including\nadditional information in the privacy policy, and printing notices where ever\nRFID is in use. These recommendations are not necessarily bad; we did not feel\nthat they were required.\n\nSection 9.1 Data Quality\n\nMany recommendations for commercial RFID use emphasize the importance of\ndata quality and correction methods61. While data quality in credit card\ninformation will be necessary for billing, it is not vital to system function that\nother personal data and travel data be of high quality. Low quality can be\ntolerated because of the minimal use of this data.\n\nIt will be expensive, time costly, and difficult to verify travel data to assure\nquality. At best, the MBTA could design a web page that allowed travelers to\nlook at their recent travel logs and report errors. However, any architecture that\nmakes it easy for multiple users to access their data and propose modifications\nwould also make it easier to hack into. If data access and modification requires\ngoing to a physical location, T riders would be much less inclined to. So, we do\nnot recommend concern about maintaining high quality data. Instead, we\nrecommend that the MBTA restricts data use to tasks that are not critically\ndependent on data quality.\n\nSection 9.2 - Specifying Where Data is Stored and How in the\nPrivacy Policy\n\nWe did not recommend that the MBTA explain in its privacy policy where data\nis stored and in what fashion. The security risks of this action outweigh the\npotential benefits. The storage architecture matters little to users of the system,\nsince the data can be taken from one architecture and moved to another without\n\n61 \"EPIC\" - http://www.epic.org/privacy/rfid/ftc-comts-070904.pdf lists some documents in which these\nrecommendations were made\n\nmodifying the data contents. Additionally, the data storage doesn't effect what\nprocessing can happen on the data. What data is contained and for how long are\nfar more valuable pieces of information, which can be announced to the world\nwith less security risk.\n\nSection 9.3 - Recommending a Particular Storage Architecture\n\nWhile Appendix B contains a particular architecture, it is meant as an example\nrather than a recommendation. In this situation, there are many architectures\nwhich would meet our recommendations. There is no need to constrain so\nseverely the flexibility of the system.\n\nSection 9.4 - Including Why Data Use is Acceptable in the\nPrivacy Policy\n\nWhile including the reasons behind data usage in a privacy policy could be\nhelpful in building trust, we do not explicitly recommend for two reasons. Firstly,\nthe acceptable uses of data should be fairly self explanatory. If a user does not\nagree with certain data uses, they can elect the opt-out option. Secondly, the\nmore words that the privacy policy contains, the less likely users are to actually\nread it. If no one reads the privacy policy, it does nothing to inform the public\nand build general trust and understanding about the system.\n\nIn cases where use of personal information does not directly benefit the\ncustomers, data users should explain why their use of data is acceptable. For\ninstance, if a company uses personal information to determine the cost of a\nproduct or ensure that the correct amount was paid, the company should\nexplicitly state why use of personal data is acceptable.\n\nAlso, data users should explicitly state why data use is acceptable in cases where\nproviding personal information is mandatory. In the case of the MBTA, we've\nrecommended that the MBTA offer an opt-out policy. However, a government\nagency should explain why data use is fair in cases when providing personal\ndata is mandatory.\n\nSection 9.5 - Printing \"RFID Inside\" Whenever RFID Technology\nis Used\n\nIn the case of a transit system, anyone with prior knowledge of smart cards and\nRFID would know that the contactless cards contain RFID chips. Users who do\n\nnot know what RFID chips are would also benefit little from the announcement,\nexcept being given the incentive to research what the technology is. Other\nmethods of communicating the existence of RFID technologies are available, and\nperhaps superior, such as newspaper articles announcing the change to smart\ncards. Within these other sources, some information could be given on what\nRFID is.\n\nThere are other applications where RFID is not readily apparent, such as inside\nthe paper of dog food bags, where we agree that some warning should be\nprinted. However, contactless smartcards are not stealthy methods of RFID use,\nand the warning label would be unnecessary.\n\nAppendix A - Technical Information\n\nA.1 - Overview of RFID System\n\nA.1.1 What is RFID?\n\nRFID is a term used for a system that uses radio waves as the carrier of a unique\nidentifier or other data that typically, but not always, correlates the \"host-object\"\nto a listing in a central database. RFID technology has been around since the\n1940s - the first real application being WWII airplane identification62. Due to the\ncost of manufacturing small, rugged and power efficient microchip technology, it\nhasn't taken widespread root until recently.\n\nFigure 1\nhttp://www.fouga.net/ - WWII\nTransponder Box\n\nThe system typically\nimplemented for RFID\nconsists of three main\ncomponents: tags, readers,\nand middleware (i.e.\nServers and software)63.\nTags can be powered by a\nbattery or can receive their\nenergy from the reader. They can also be really small or quite big. Readers come\nin many different flavors as well. Most readers are connected to a main database\nwhich contains further information about the item associated with the tag.\nTogether, these components create a robust and quite remarkable system which\nis only now starting to be realized in its finest potential.\n\nA.1.2 What the DOD and Wal-Mart see in RFID\n\nBy January 2005, the United States Department of Defense and super-retailer\nWal-Mart would like their suppliers to embed RFID technology into all products\n\n62 ZDNet UK - RFID Special Report- http://insight.zdnet.co.uk/specials/rfid/0,39026568,39153971,00.htm\n63 Definition of an RFID System: http://www.webopedia.com/TERM/R/RFID.html\n\nshipped to them64. Many sources claim that it is unlikely RFID technology will\nactually make it into every item on the shelves of Wal-Mart by the January date,\nhowever, the request by these big two product-movers sets a tone for\nwidespread implementation of this technology.\n\n2 - http://www.cydome.de/ - RFID Tag on a\nConsumer item\n\nWal-Mart's website claims that RFID\ntechnology will predominantly be used\nat the case and palate level, thus, most\nitems in the store will not be tagged, but\nrather will have the time-tested one-\ndimensional barcode. Items that will\nhave active RFID technology attached will be labeled as such for consumer\nawareness65. Technology such as RFID is being implemented to improve supply-\nchain management. Items such as a box of razors will surely have anti-theft\ndevices enclosed, although RFID technology is probably considered too\nexpensive for the individual item level. The price of tags is the predominant\nhindrance to near-ubiquitous implementation. Currently around $0.30 a piece\nfor the passive tags that Wal-Mart would like to implement, the price would\nneed to drop to around $0.05 a piece and gain a few percentage points in\nreliability before it would be profitable to use them in a more widespread\nfashion66.\n\nThe DoD has been using RFID to cut back inventory processing headaches. RFID\n\"allows the improvement of data quality, items management, asset visibility, and\nmaintenance of materiel,\" says a briefing on the DoD decision. Furthermore,\n\"RFID will allow the Defense Department to improve business functions and\nfacilitate all aspects of its supply chain,\" the brief continues.67 By 1/2005, the\nmilitary would like passive RFID tags on most item-level tracked supplies. Once\nagain, the government and commercial push to RFID will likely speed up\nwidespread adoption, however, chip prices are still too high for ubiquitous\nimplementation.\n\n64 Wired News - http://www.wired.com/news/business/0,1367,61059,00.html\n65 Wal-Mart website - Home Page>Supplier Information > Radio Frequency Identification Usage\n66 Wired News - http://www.wired.com/news/business/0,1367,61059,00.html\n67 DoD implements RFID - http://dc.internet.com/news/article.php/3098561\n\nA.1.3 Active or Passive\n\nA form of RFID which has been around for some time now is the SmartPass or\nEZ-Pass toll paying device. For those unfamiliar with this device, it is a small\nbattery powered box which sits in the rear window of a vehicle. When that\nvehicle drives through a toll equipped with the proper hardware, the toll and the\nbox communicate and deduct the proper toll amount from the proper user's\naccount.68\n\n3 - http://www.notbored.org - EZ Pass lane on a freeway\n\nThe form of RFID being used in this case is far\ndifferent than the RFID being used in Wal-Mart or on\nmass transit systems. The differences mostly stem\nfrom how the device is powered: battery vs.\nharvesting its energy from the reader.\n\nBattery powered RFID devices transmit farther,\nlations, might have sensors embedded on board\nare bigger.\ntypically can do more calcu\nand\ncan\n\n69 Most battery powered devices are called \"active\" RFID devices\nbecause they have power regardless of the presence of a reader. Active devices\nare used in large cargo tracking, most EZ-Pass systems, Exxon Speed pass\nsystems etc. These devices are typically larger - they have a battery on board -\nand they are usually built in a boxy form factor. They can transmit further since\nthey have their own power source and don't simply reflect back waves, but\ngenerate them. A typical RFID transponder used in automotive applications\ntransmit to about 25 feet.70\n\n4 - http://www.port2port.co.il - Container tracking uses\nActive RFID\n\nThe other major category of RFID devices are\ncalled \"passive.\" These devices do not have a\nbattery but rather harvest their energy from the\nreader in some fashion. The best way to think\n\n68 EZ Pass Website- http://www.ezpass.com/static/info/index.shtml\n69 \"RFID Basics\" http://www.savi.com/rfid.shtml\n70 http://www.awid.com/new/Sub-Page/DougCram-Active-vs-passive.pdf\n\nabout passive RFID tags is that they reflect back the energy coming from the\nreader with some changes that carry the sent data71. One of the most common\nform factors of passive devices is the smart card. Because these devices must get\ntheir energy from another device, they lack the power to do computationally\nintensive tasks and thus typically have weak encryption, since good crypto\ntypically requires memory and power.\n\nA.1.4 What's so remarkable about this stuff?\n\nRFID is seeing a lot of attention recently because it has the potential to\nrevolutionize logistics. People who specialize in moving things around the globe\nwould probably benefit greatly from better tracking of assets. UPS has made an\nentire market niche by knowing where things are and how to move them\nquickest. If industry and government didn't have to worry so much about\nmaking sure \"stuff\" got somewhere, business would occur much quicker and\nwith less loss. Commerce could change forever. Imagine that a manufacturer,\nsay Kellogg's, makes Honey Crisps, the hottest cereal around. They make them\nin big tubs and each tub is a homogenous mix of that type of cereal. Boxes are\nfilled by tub and each box contains a small chip and an antenna - an RFID tag,\nessentially. As the boxes are filled, a scanner logs the box and associates it with\nthe huge batch and the location it was made etc. The boxes are sent to the\npacking room where they are bundled into crates and onto palates. They are\nloaded with what appears to be carelessness onto trucks, but a sensor on the\nshipping door queries each and every box on each and every palate and asks it\nfor its serial number. The database then associates a box with a palate with a\ntruck. The trucks are driven to their destinations and the requisite number of\ncrates is removed casually and delivered to the customer, namely a supermarket.\nAn RFID sensor on the back of the truck interrogates the crates as it is pushed off\nand sends the data with a GPS tag to the main database which associates the\nboxes with crates with a truck with a drop-off location. The supermarket,\nassuming they are in the 21st century, also has an RFID sensor connected to this\ndatabase grid. This logs the entry of the boxes into the store and verifies that\nthey all made it to their destination.\n\nA few days later, most of the cereal has been bought. Consumers, as they grab a\nbox, go to the check-out line, an RFID sensor checks the box and now associates\ntheir credit card number with their purchase and can be associated back to the\nbatch and the crate and the van and the warehouses and now, to the buyer.\nPeople go home, chow down on their food and some, unfortunately, experience\nfood poisoning. People get wise to the cereal causing the problem and call\n\n71 http://www.awid.com/new/Sub-Page/DougCram-Active-vs-passive.pdf\n\nKellogg's. Kellogg's gets the number off the box and immediately does a query\non the entire batch and correlates food poisoning reports. The database analysts\nrealize that the common thread is the truck the cereal was shipped on. They\nimmediately check where all the product went and recall those exact boxes -\nnothing more, nothing less. They make a profit, the consumer is safer, their\nproduct is tracked and they lose less money to theft and the like.\n\nOne might look at this example and note that the RF portion of the RFID system\nhad a lot less to do with making this work than the database part. This is\nabsolutely true, however, the architecture lowers the threshold of \"willing to\ninput data into DB\" to near zero, as data is automatically entered passively (to\nthe user) by invisible radio waves and \"smart\" chips.\n\nOne might also look at this example and be scared for the dickens because credit\ncards can be easily linked to products and companies can track how much a\nconsumer uses the bathroom by correlating amount of Charmin with the user\nand dividing by the household size (also in a public database somewhere).\nWell... unfortunately, that is something RFID doesn't really improve upon - it's\na philosophical question of whether that data should ever be linked or even exist\n- some say no, others yes. That discussion will take place in our\nrecommendations section. The important thing to note, however, is that\ntechnology alone is not bad or good, scary or exciting - it's the implementation\nand the administrators who can make or break a system.\n\nA.2.0 Plunging one level deeper (technically)\n\nA.2.1 Active vs. Passive revisited\n\nActive and passive cards are the two main types. Big devices (EZ Pass,\nContainer tracking etc) mostly use active tags. Small devices (consumer goods,\nsmart cards, etc) mostly use passive tags. Active tags literally contain a battery,\npassive tags get their energy from the reader. Good - that's the basics (and close\nto all we really need to know for this discussion); however, for the purpose of\ncontemplating the deep philosophical meaning of \"how far can my card be\nread,\" one might find the intricacies of these implementations quite interesting.\n\nA.2.2 Passive Cards - Inductive vs. RF coupled\n\nPassive cards are powered by the reader. This means that if someone stood on a\nsubway and had a reader, that person could read a Charlie card - provided they\ncould get close enough to give it the juice it needs to send back a response.\n\nThere are two main types of passive cards, Inductively coupled and RF coupled.\nInductively coupled cards get their energy through the near field radiation from\nthe reader. This means, essentially that there is a coil of wire in the reader which\nhas a high frequency current flowing through it. Your card also has a coil of wire.\nWhen two coils of wire (one with a time-varying current flowing through it) get\nclose to each other (horizontally - i.e. in a flat fashion) they can transmit power to\neach other. When the coil in the card is connected or \"loaded\" power is drawn\nfrom the magnetic field created by the reader in the near field (less than a\nwavelength away). If the coil is not connected then much less power is drawn\nfrom the field. This difference can be seen by the reader as a voltage drop (or\nlack thereof) across its coil. Data can be sent by connecting and disconnecting the\ncoil in the card using a transistor. A disconnected coil might indicate a '1' and a\nconnected coil might indicate a '0,' perhaps. 72\n\n5 - http://www.giveaway.com.cn -\nInductor powered toothbrush\n\nImplementations of inductive coupling are used\nquite commonly in electric toothbrushes. Since\npeople wouldn't want the toothbrush to short\nout or zap the user, the entire device is covered\nwith plastic - so how does the electricity get in\nthere to move the bristles? Well, the base has a\ncoil with current flowing through it and the\nbrush has a coil with a storage element attached\nto it. Together, they transfer power as discussed\nabove.73\n\nThe only problem with this technique is that the\ntwo objects must be close to each other (like 1⁄4 the wavelength of the oscillating\ncurrent in the coil) to actually work efficiently. For all intents and purposes, that\nmeans the Charlie Card must be within a few inches of the reader for it to\ntransfer enough power to get the card to respond properly. (Assuming the\nCharlie Card is inductively powered, which it is.)\n\n72 http://www.rfid-handbook.de/rfid/types_of_rfid.html\n73 http://www2.abc.net.au/science/k2/stn/posts/topic179735.shtm\n\nThe other main type of powering mechanism is RF or Backscatter coupling.74\nCards get their energy from the far field of the reader in RF coupling. Essentially,\nthe reader sends out an RF wave which propagates out in a sort-of baloonish\nfashion from the reader. The farther away from the reader, the less power is\ntransferred. The max read distance is determined by how much power is\nemitted from the reader. Some reports say RF coupled devices can be read at 17\nfeet75. This means that the Charlie Could be kept in someone's pocket and read\nfrom a distance without detection. Small movements in user position wouldn't\naffect trying to read the card at this distance for an extended period of time - as\none might do if trying to break an encryption mechanism. Fortunately for the\nMBTA and consumers, the MIFARE standard (what the Charlie Card uses) is\ninductively coupled and isn't as susceptible to this sort of attack.76\n\nAn interesting thing to note is that a simple piece of Aluminum foil folded into\nan envelope (with the card inside) can prevent all RFID from leaking out and\ninto the hands of an evil-doer. If users are afraid their cards will be read\nsurreptitiously, they might consider this cheep \"Faraday Cage\" solution to the\nproblem and rest assured that their waves are safe in the foil - just make sure the\ncard is not visible at all and that all edges are folded over for this to work.77\n\nA.2. How cards are fabricated\n\nRFID tags are made of three components -\nan IC, an antenna and packaging. An IC is\nan integrated circuit - a chip - which has\netched onto it a set of \"instructions\" which\ncommand it to interact with the reader and\ndo something useful. This chip might\ncontain memory, crypto tools, modulation\n& demodulation components, control units, anti-collision and other tools which\nallow it to do more advanced functions. The IC is the brain of the RFID tag -\nwithout it, we'd simply have a theft prevention coil which resonates but does\nnothing.\n\n74 http://www.connect802.com/rfid_facts.htm\n75 http://www.rfidjournal.com/article/articleview/1078/1/1/\n76 http://www.semiconductors.philips.com/markets/identification/products/mifare/\n77 http://en.wikipedia.org/wiki/Faraday_cage\n\nThe Antenna is also key to the RFID tag. The antenna is essentially a coil of wire\nwhich resonates with a certain frequency of radio waves - namely those coming\nout of the reader. The\nantenna can be a coiled\npiece of wire which was at\none point spooled or it\ncould be printed metallic\nink which happens to be\nprinted such that it makes\nan antenna the correct size.\n\n6 - Philips' Schematic for a MiFare card\n\nMost modern, cheep RFID tags use printed or stamped antennas. Some new\ntechniques are actually \"growing\" antennas using chemical deposition\ntechniques which could also solve the age-old problem of strapping an antenna\nonto a chip.78\n\n7 - Microchip under a Microscope - Deloitte\n\nThe last component of the RFID tag\nis the packaging. The packaging\ncan be a sliver of plastic - i.e. a card,\nor it can be a sticky tag which\nadheres to a retail product.\nPackaging can also be a proper\nhousing, or... whatever. The\npackaging is fairly insignificant\naside from holding the tag together.\nPackaging should not be metallic\nor adhered to a metallic object, as metal will block the RF radiation and prevent\nproper functioning of the tag.\n\n78 http://www.rfidjournal.com/article/articleview/975/1/1/\n\nA.3 Pushing the technical limits\n\nRFID cards can do a lot, for sure, but despite manufacturer claims of reading\ndistances and encryption techniques, there are fundamental laws of\nelectromagnetics which must be obeyed. Read distance, for example, arises\nbecause of two things: the data signal and noise. The data signal needs to be\n\"louder\" than the noise or else it becomes as useful as a quiet poetry reading in a\nrock concert. Typically, the best way of reducing noise and boosting signal is to\nstand closer - hence, the read distance concerns with\nRF coupling. There are other techniques, however,\nwhich can enhance read distance.\n\n8 - http://www.paicast-5.rl.ac.uk - a bigger sized aperture for RF\nradiation (used for satellite communications)\n\nAn aperture is essentially a \"hole\" through with\nsignals enter a system. A lens and a satellite dish are\nboth apertures. As demonstrated with the Hubble\nspace telescope, a bigger lens means you can see\nfurther.79 The same goes for RF - a bigger aperture\n(not a bigger antenna, per se) allows one to read\nRFID cards from farther away. The implementations\nof possible \"snooper\" apertures are far beyond this paper, but it is physically\npossible to build systems which can read some cards at much greater distances.\nThe important message here is that one shouldn't rely on physical \"limitations\"\nor manufactures' specs to provide a cloak of privacy, but rather implement\nsecurity mechanisms despite the physics. Every day, we make advances in\nscience and technology, there is nothing stopping someone from making a device\nwhich can read an RFID card from a few hundred feet away as if the two were\nonly a few inches apart.\n\nA.4 ###%20# hWo eNeds nEcryption? ####^%687#\n\nIn the beginning, there were cards and there were readers. Cards emitted a\nsignal and always emitted that signal when readers asked for it. All were happy\nuntil people started poking around. When the technology to read cards became\nless secretive and more widespread among the cracker population, the security\nof this access mechanism was lost. Crackers could interrogate a card and\nreplicate its output. They could fool a reader into thinking their emulator was a\n\n79 http://www.astro-tom.com/telescopes/beginner's_advice.htm\n\nreal card and thus, they could masquerade as someone they were not - without\nthe person being any wiser.\n\nThere's a nifty article about cloning a prox card at\n<http://cryolite.ath.cx/perl/skin/prox> which details a curious engineer's\nendeavors to hack a prox card system. Basically, the author figured out how the\ncards transmitted a signal by looking at the output of a card when blasted with a\nsingle frequency of RF energy. He managed, through some complicated\nprocedures, to replicate that signal on request. By recognizing the method by\nwhich the bits were encoded onto the waveform, he figured out how to turn a\nrandomly read card with the same specs into a cloned card.\n\n9 -\nhttp://cryolite.ath.cx/perl/skin/prox -\nThe setup used\n\nThe author essentially defeated\na trusted prox card system. He\ncould, for instance, have been a\nterrorist wanting to gain access\nto a building protected by prox\ncard access. If he knew where\nworkers got lunch, he could\nstand next to one of them at the check out counter and silently copy someone's\ncard while it remained in that person's wallet. He could then transfer those bits\nto his clone card and replicate the signal, thus gaining entry into the \"secure\"\nbuilding.\n\nBy using some signal processing tricks, he could read the card's data\nsignificantly farther away because the cards simply repeated the same bits over\nand over until removed from the field surrounding a reader. It wouldn't be\ndifficult, he reasoned, to attach a malicious reader device on the opposite side of\na wall from a bank of \"nice\" readers and simply gather data from cards by\nlistening carefully and using some signals tricks.80\n\nLukas Grunwald, a consultant in the security and e-commerce field, developed a\nprogram called RFDump which allows users to edit an RFID tag's contents.81\nThe program could be added to a handheld computer and be used by people\nwho want to alter or correct information on RFID cards in their possession.\nUnfortunately, programs like this could also be used to steal expensive items in a\n\n80 http://cryolite.ath.cx/perl/skin/prox\n81 http://www.rfidgazette.org/2004/07/lukas_grunwalds.html\n\nstore by relabeling them as other, less expensive, items. Attention paid to\nprograms like RFDump and people like the RFID hacker above has foisted\nencryption in RFID systems to the spotlight.82 If RFID tags are not secure when\nused for secure exchanges, they pose a major threat.\n\nA.4.1 128 bit vs. 3DES vs. scrambling letters\n\nNot all forms of encryption are created equal. If I wanted to send you an\n\"encrypted message,\" I would have a wide selection of options available to me. I\ncould convert the text into binary and add some predetermined number to each\ndigit, I could add different numbers to each digit, I could reverse the order of the\nnumbers than multiply each by 13786 and then subtract two... you get the idea.\nIt should be obvious that if I simply add one to each number, it would be trivial\nto crack my cyphertext (encrypted message) - especially if the code cracker has a\ncomputer which can perform over one million operations per second. It would\nbe much more difficult to crack my cypertext if I were to take a phrase, passage\nor encyclopedia, convert it to one's and zeros than add it to my message and\ntruncate what doesn't overlap. We would simply need to exchange what\npassage or set of numbers I used to encrypt the message so you could decrypt it.\n\n10 - http://kingkong.me.berkeley.edu - The DES algorithm\n\nThe important point here is that some encryption is \"better\" than others. Some\nencryption takes a few minutes to crack, other forms take centuries (using the\ncurrent computers we have and operate). Typically older algorithms are less\nsecure and newer algorithms with larger key sizes are more secure, as they\nimplement new discoveries of applications in mathematics. At the end of the\nday, however, some weak encryption is arguably a tad better than no encryption\nat all.\n\n82 http://blog.informationweek.com/001260.html\n\nA.4.2 What manufactures want you to believe\n\nIn the past, there was no encryption. Cards would send bits, readers would read\nbits. Currently, however, there is a push to get more encryption on RFID cards.\nMicrosoft, in a document about RFID privacy, stated encryption as key to\nprevent security liabilities.83 MIFARE, the standard which the MBTA will\nimplement on its RFID Charlie Cards utilizes 3DES.84 \"Triple DES\" is an\nalgorithm which uses an NSA encryption technique called \"Data Encryption\nStandard\" three times on the same data to arrive at a \"secure\" cyphertext.85\n\nDES, the father of 3DES was not secure. In 1998, the Electronic Frontier\nFoundation cracked DES in 56 hours using a supercomputer. Now, DES could\nbe cracked in less than an hour.86\n\n3DES isn't currently considered easily crackable. Reports say it would take\ncenturies to crack.87 Seeing that T users don't stand in the same place for more\nthan 15 minutes, some say encryption is fine as it is.\n\nA.4.3 What Encryption experts want you to know\n\nSince the dawn of time, there have been secrets and there have been people\nwanting to know those secrets. Encryption techniques like the Caesar shift\n(shifting a letter or two up or down) were secure until people learned to crack\nthem.88 The Enigma, the German WWII encryption device, was considered\nuncrackable - now there are websites with applets that let you write and crack\nyour own Enigma codes.89 Encryption experts caution society not to settle,\nbecause given a few years, almost all codes are broken.90\n\nAnother consideration in the encryption debate is when the encryption takes\nplace. If Eve is a spy trying to gain entry into a secret cult and she knows there is\na password, she might try listening to what people speak when they approach\nthe sentry. If the organization implements a form of encryption on their\npassword and then tells their members the encrypted password, Eve will still be\nable to gain entree.\n\n83 http://www.eicar.org/rfid/infomaterial/RFID_privacy1_1.pdf\n84 http://www.siki.com/ips/english/product/MIFARE%20Catalog%2030010.pdf\n85 http://kingkong.me.berkeley.edu/~kenneth/courses/sims250/des.html\n86 http://kingkong.me.berkeley.edu/~kenneth/courses/sims250/des.html\n87 http://www.processor.com/articles/P2608/24p08/24p08chart.pdf?guid=\n88 http://www.simonsingh.net/The_Black_Chamber/caesar.html\n89 http://www.ugrad.cs.jhu.edu/~russell/classes/enigma/\n90 http://www.networkcomputing.com/1006/1006colmoskowitz.html\n\nAn illustration of this issue would probably clear some confusion. Imagine Eve\nlistening in on the conversations at the door. The members of the organization\nsay their name followed by \"Dogfood\" when they approach and are allowed in.\nTo stop Eve from understanding this mechanism, the members speak their name\nbackwards and say an \"encrypted\" version of \"Dogfood.\" This, the organization\nbelieves, will thwart potential spies.\n\nEve stands at the door, listening intently. She hears \"nairb...Foobarg,\" the next\nperson approaches and she hears \"ekim... Foobarg.\" She might have no idea\nwhat the members are saying nor understand that \"ekim\" is Mike backwards,\nbut she can easily approach the door and say \"Ekim...Foobarg\" and (albeit with\nblonde hair and a feminine shape) appear to be a valid member, as she has stated\na members name backwards and said the encrypted password.\n\nRFID experts at the MIT AutoID center (an organization which studies and sets\nstandards for RFID technologies) have expressed concerns about the crypto\ncapabilities on board RFID smart cards91. While industry claims to have on-\nboard crypto and PKI (public key infrastructure)92, it seems unlikely that a small,\nlow-power, inexpensive chipset can perform all these functions.\n\nSteve Weiss, a grad student at the RFID center, writes about the issue far more\nelegantly in his Masters' thesis than I shall, but I'll attempt to express the main\nidea of his arguments. His paper can be found on the Auto ID center website\nand on crypto.csail.mit.edu. Essentially, Steve states that chipsets on RFID cards\ncontain about 2000 gates (devices able to perform a binary computation) which\nare dedicated to security. Hardware implementations of DES, Steve writes, take\nupwards of 10 - 15 times as many gates. If the chips lack the computational\npower and storage space, there is no way the cards can perform active,\nworthwhile encryption.93\n\nPhilips, the maker of the ISO14443 standard MIFARE card, which the MBTA will\nuse for its Charlie Card, claims to have implemented many of these security\nfeatures.94 They claim that MIFARE contains 1KB of EEPROM (memory) and\nperforms active crypto on its fixed 32 bit unique serial number or transmitted\ndata. It is still unfathomable for some to imagine that such complex calculations\ncan be performed on a passive card, but regardless, companies are aware of\nissues in cryptography and are almost surely working to make their technology\nsecure.\n\n91 E-mail interaction with Auto ID ctr grad student Joe Foley\n92 http://www.rfida.com/weblog/2004/06/rfid-smart-cards-oberthur-wins-first.htm\n93 http://crypto.csail.mit.edu/~sweis/masters.pdf\n94 http://www.siki.com/ips/english/product/MIFARE%20Catalog%2030010.pdf\n\nA.4.4 What should we demand in the future (technically)\n\nConsumers and businesses deserver protection from intruders. An RFID\ninfrastructure which provides ample security will have an encryption system\nthat does more than send the same encrypted data every time it is read. There is\na case for active cards, in that they typically can perform many more calculations\nthan passive cards since they have more power available to them, however, it is\nimpractical to think that the MBTA will pay several dollars for each card when\npassive cards are less than a buck and consumers are generally naive to the\ndifferences.\n\nConsumers and businesses need a system where cards cannot be cloned. A\n\"very improbable\" chance of cloning is not acceptable. Unless there is a zero\npercent chance than someone will succeed at cloning another users' card, there\nwill be hackers (MIT students, perhaps) who might accept the challenge and\nsucceed. While MIT students would be trustworthy with this technology, if it\nwere to fall into the wrong hands, the MBTA and consumers could be out quite a\nbit of money. If a company claims that their smart cards do 3DES encryption,\nconsumers have a right to have proof which makes sense to them.\n\nWe have spoken a bit about encryption for cards, but the databases must also\nhave encrypted connections. It is dumb if a criminal can install a tap on the line\nrunning from the card reader to the server and get all the data he wants, despite\nthe actual comms line between the card and reader being encrypted.\n\nCards also should not emit an identifiable signal when interrogated by a non-\nMBTA reader. This requires authentication, which is best accomplished in a PKI\ninfrastructure, but Philips claims it is being implemented. We'll see.\n\nAppendix B - A Possible Design\nThis appendix describes a possible data storage design to meet the following\ngoals:\n\n- using the benefits of RFID to shorten lines and reduce cost\n- storing aggregated travel data for statistical studies\n- storing personal travel data for a limited time\n- allowing users to replace lost cards\n- enabling the MBTA to charge fares based on distance traveled\n- logging access to MBTA databases\n\nThe following design covers the data storage aspect of the MBTAs information\narchetecture. We assume functionality of RFID cards, readers, and networks\nneeded to transfer needed information to the servers. We also assume that RFID\ncards simply store a unique identifying number which correlates to an entry in\nan MBTA database.\n\nThis design involves two databases. The first database contains personal\ninformation and a recent travel log. The second database contains long term\ntravel logs, but no personal information.\nSection B.1 General Design\n\nFigure B.1\nSchematic of Suggested Database Design\n\nThe first database contains the following information:\n\n- Unique ID of each issued Charlie Card\n- Account balance\n- Personal information or a shared secret (traveler's password)\n- A travel log containing entries for each trip with\n- Boarding location and time\n- Disembarking location and time\n- A boolean flag field that is turned switched when a card is reported as stolen\n\nThe second database contains the following data:\n\n- A user's travel history spanning a set period of time. As above, these would\ncontain:\n- Boarding location and time\n- Disembarking location and time\n\nNote that the second database stores no personal information nor correlates with\nany personal information that could be used to link the travel data in the second\ndatabase to personal identifying information in the first. Furthermore, users have\nthe option of storing personal information or storing a password (unique, yet\nenables one-way verification). The advantages and disadvantages of these two\noptions are explained in sections 3 and 4, variations on the general design.\n\nSection B.1.1 Operation of the Databases\n\nDaily T use data is automatically entered into the first database. When a\ncustomer enters a station and swipes his or her card, a record is created with this\nperson's unique ID. The reader logs this ID number in the first database, along\nwith time and location of entry. Using the first database, the system verifies the\nvalidity of this card and ensures proper fare balance. The result of verification\n(accept or reject) is sent to the turnstile (an accept may have the result of opening\na gate, or allowing the turnstile to rotate). Upon successful entry, the location and\ntime is correlated with the user ID and logged in the first database.\n\nWhen the customer leaves from the concluding station, the RFID card is used to\nswipe out. The card reader sends the unique ID to the first database, along with a\ntime and location of exit. The first database records this data in the travel log.\nThe fare that the customer owes is calculated and subtracted from the amount of\nmoney in their account. (If the fare is based on distance traveled, the cost would\nbe variable. If the account does not have adequate funds, the gate can display a\n\nmessage suggesting the user add funding to his or her card at a kiosk located in\nthe station or take any other action deemed appropriate.)\n\nAfter a specified time period, perhaps one or two weeks, travel data will be\ncopied to the second database without the corresponding personally identifying\nfields. This would ensure that the second database contains adequate aggregate\ntravel information yet is stripped of all personal information. All personal data\nolder than this time period will be deleted, ensuring that personal data is not\nlinked to travel data yet statistics about travel are still maintained.\n\nSection B.1.2 Meeting the Specifications\n\nThis database meets the requirements specified above:\n\n- using the benefits of RFID to shorten lines and reduce cost\n- storing aggregated travel data for statistical studies\n- storing personal travel data for a limited time\n- allowing users to replace lost cards\n- enabling the MBTA to charge fares based on distance traveled\n- logging access to MBTA databases\n\nRFID can be used to meet the six requirements above without compromising the\npromise of the new technology.\n\nAn advantage to this proposed architecture is that people who need statistical\ninformation on travel can be given access to the second database without\nincurring the risk of compromising any sensitive information (i.e. the personal\ninformation or passwords in the first database). Because older travel information\nis removed from the personal data and stored without any information to\nconnect it to personal data, this architecture meets the goal of storing personal\ntravel data for a limited period of time.\n\nTo replace lost cards, a customer would provide his or her personal information\nor password and card ID (depending on the variant of the system). The user\nwould be reissued a card with a new ID number, which has the same account\nbalance and travel data as the old card. The first database would be updated so\nthat a new entry is created for the new ID number, with the old travel data,\naccount balance and password or personal data. The first database would also be\nupdated so that the old ID number (associated with the stolen card) would have\na zero balance or some flag which would make it useless to the thief.\n\nAs described above, fare can be calculated based on entry and exit locations,\nshould the system require it.\n\nThis design does not prohibit the server from recording whenever an employee\nlogs on and what data he or she accessed. We did not explicitly include these\ndesign elements in the proposal above because they would needlessly complicate\nthe discussion. The interface which allows employees to access data could be a\nquery which would verify the employee permissions, and record the time, data\naccess, and purpose.\n\nSection B.2 Variation 1: Shared Secret (Password)\n\nIn this variation, the first database stores only a shared secret like a password\nand user ID related to the customer. The database contains no personal\ninformation. This variation has the advantage that all cards are anonymous.\nBecause the system stores no personal data, there is no risk of abuse of personal\ninformation.\n\nWe still recommend that travel data be periodically transferred from the first\ndatabase to the second, because an individual could still be tracked if their ID\nnumber was known. However, this risk is greatly reduced.\n\nThe disadvantage of this variation is that users must remember a password and\nidentification number in order for lost cards to be reissued. This variation also\nlacks some of the advantages of the one presented below.\n\nSection B.3 Variation 2: Personal Information\n\nIn the second variation, the first database stores some personal information\nabout the user, such as name, contact information, credit card number, credit\ncard company, and credit card verification information. (If the customer is\npaying via cash or check rather than credit card, the credit card related data\nwould be left blank).\n\nAs in the recommendations given above, this information should be kept\nreasonably minimal. No piece of information in the database should be stored\nunless is directly leads to additional functionality for the customer. For instance,\nthe customer's religion, sexual orientation, and favorite color are not directly\nneeded for any declared functionality. However, name, contact information, and\n\ncredit card information can be used in the reissuing of lost cards, and automatic\nreloading.\n\nFigure B.2\nSchematic for Variation 2 of the Design\n\nAdditionally, the RFID card should still only store a single number. If the card is\nread illegally by an unauthorized card reader, the information of a card ID\nnumber would be less useful than any personal information.\n\nThe advantages of this system are that it\n\n- allows for an opt-in automatic reloading program\n- allows for card reissuing without forcing the customers to memorize\npasswords (the customer would provide his/her name, and a photo ID, for\ninstance)\n\nHowever, it has the disadvantages that\n\n- If the card has automatic reloading and is lost/stolen, the customer must\nreport it quickly, or risk paying for someone else's T fare for an arbitrary\namount of trips\n- There is personal data in the system which could be subject to internal or\nexternal abuse\n\nTo help make the personal data less at risk for internal abuse, personal data\ncould remain encrypted on the system until needed (to reissue a lost card or\nperform automatic reloading).\n\nSection B.4 A Combination\n\nTo combine the useful customer service benefits of storing personal data with the\nprivacy provided by not storing personal data, a combination of these two\nvariations would be ideal. Users could provide as much personal information as\nthey desired, and leave the other data fields blank.\n\nIn this method, each user has control over the balance they choose between\nprivacy and functionality. For instance, if the credit card information is not\nprovided, the customer would give up the ability to use automatic reloading. If\nno personal information is given, the customer would give up the ability to get a\nlost card reissued. However, in giving up these benefits, the customer would\ngain the level of privacy protection that he/she felt necessary.\n\nFor the system to handle this variation, a special symbol (false, for example)\ncould be used to represent blank fields. In order for automatic reloading to occur,\nthere could not be a blank for any certain fields. Whenever automatic reloading\nmight be used, the system would first check the validity of all the necessary\nfields.\n\nThe disadvantage of this design is in explaining to customers what information\nthey must provide in order to get certain benefits. Customers are at risk of\nbecoming confused if instructions are not clear. However, this system has a big\nadvantage of combining the benefits of the other two variations with customer\nchoice.\n\nAppendix C - Modifying a Current System to Incorporate\nour Recommendations\n\nIn this section, we detail how a current implementation can be extended to\nincorporate our recommendations. We proceed by explaining how to configure\nthe database to separate travel information and personal information at regular\nintervals.\n\nWe treat the current database as a black box. The database needs three\nrequirements: data must be able to enter, data must be able to leave, travel data\nmust have a time stamp, and data must be able to be deleted.\nFigure B.3\nA schematic of how an envelope design can be used to extend a current\nimplementation to separate travel data from user data at regular intervals.\n\nAs in figure B.3, the new design would have three connections to the outside.\nThe first would be a method of putting data into the system in the same manner\nas the original database. The second would be a method of extracting data from\n\nthe system. This method would also be exactly the same as the old method.\nPreserving these interfaces would help ease integration of this new database to\nthe rest of the system by following the same design specifications for\ninput/output as the old system.\n\nThe new system would have an internal clock programmed to separate personal\ninformation from travel data after some amount of time (say, two weeks). We\nwill refer to this component as a Data Purge Clock. Every two weeks, the Data\nPurge Clock receives all of the information from the database. It scans the\ninformation for places where personal information is connected to old travel\ninformation. In these cases, it copies the old travel information into one entry of\nthe old database (an aggregated entry of some kind). It then deletes the travel\ndata from the entry with the personal information.\n\nThe Data Purge Clock should have an override in the event that special\ncircumstances arise in which the separation of travel data from personal data\nshould not occur for a particular customer. E.g. if this customer is currently on\ntrial, and the information in the database is considered evidence, the users name\nshould be entered into the override.\n\nThe Data Purge Clock will be computationally expensive. To minimize the effects\nof this cost, the Data Purge Clock might be designed to check a portion of the\nalphabet each night, or only run at a set time in evening when the T system is not\nrunning. By operating on smaller chunks of the information more often, and\noperating when little other activity is going on, the computational expense will\nnot be a drain on other components of the system.\n\nAppendix D - RFID and Transit Smartcard Glossary95\n\nActive Tag - Any RFID tag which contains a power source, namely a battery.\n\nAntenna - A conductive object that is designed to receive electromagnetic waves\nand carry them into a circuit.\n\nCapacity - The amount of information (bits) that can be stored in a tag. Bits\nmight be user accessible or designed to help establish and maintain a\ncommunications link between the reader and tag.\n\nCapture Window - Balloon shaped volume in front of reader where the tag will\nfunction, given it is designed to work with said reader.\n\nElectromagnetic Coupling - The act of using electromagnetic waves / radiation\nto power or communicate with another device.\n\nElectrostatic Coupling - The act of inducing a voltage on a plate or strip of\nconductor to power a device.\n\nEncryption - Obfuscating a set of data using a reversible algorithm.\n\nError - An operation or set of data which occurs due failure in a part of the\nsystem.\n\nError Rate - # errors / # transactions.\n\nFactory Programmed Tag - A tag that has data imprinted onto it as part of the\nmanufacturing process and cannot, typically, be rewritten.\n\nField Programming - The act of programming a tag after the manufacturing\nprocess -typically performed by an end user for the purpose of encoding relevant\ndata onto the tag. Tags usually have factory programmed data, like a serial\nnumber, written onto them, but can also have user-written data which can be\nrewritten.\n\nFrequency - The rate at which a signal follows the smallest segment of the signal\nwhich, when repeated indefinitely, is exactly the same as the original signal.\n\n95 Portions of Glossary adapted from\n<http://www.aimglobal.org/technologies/rfid/resources/papers/rfid_glossary_of_terms.htm>.\n\nInductive Coupling - The process of using a current induced in a coil to power a\ndevice.\n\nInterrogator - See Reader\n\nMisread- The condition where data read differs from data on the tag.\n\nModulation - The act of \"wrapping\" a signal onto a frequency using various\ntechniques such that many signals can be sent without interfering with one\nanother by using different frequencies.\n\nRegistered Card - An RFID smartcard that is registered with a transit authority.\nThe transit authority can associate the card with the individual who registers it.\n\nOpt-Out - A provision that gives smartcard users the opportunity to choose\nbetween an unregistered and registered card. A good opt-out provision does not\nforce an individual to use a lower-quality product, such as a Magnetic Stripe\nCard as opposed to an RFID Smartcard.\n\nPassive Tags - An RFID tag which does not contain a power source but rather\nobtains its power from the reader.\n\nRFlD - Radio Frequency Identification. The collection of tags, readers and\nmiddleware which together comprise a wireless system that uses stored, semi-\nunique data to accomplish tasks such as performing rapid inventory, automating\nfare collection on transit systems and speeding retail purchases.\n\nRange - The distance at which successful reading / writing can happen.\n\nRead - The interception, decoding, extraction, and interpretation of data sent\nfrom one device to another.\n\nRead Only - See Factory Programmed Tag\n\nReader - A device which is connected to a central database and communicates\nwith an RFID tag.\n\nSeparation - Operational distance between two tags.\n\nSmartcard - A card that contains an embedded RFID chip and can be used for\npractical purposes, such as redeeming a transit fare.\n\nTag - The device which stores data and communicates with readers. Typically, a\ntag is in the form of a credit card shaped device, a small box, or a flat label.\nTransponder is the most accurate term for a tag, however 'tag' is used more\nprevalently and refers almost specifically to an RFID tag when speaking about\nelectronics.\n\nUnregistered Card - A card that is not registered with a transit authority. It\ncannot be associated with a particular person.\n\nReference List\nInterviews\nBarrios, Jared. Interview with Brian Myhre, Jennifer Novosad, and Chris Suarez.\n5 Oct. 2004. The Massachusetts State Capital.\nBerrang, Steven and Josh Martiesian. Interview with Brian Myhre and Chris\nSuarez, 15 Nov. 2004. Massachusetts Bay Transit Authority.\nCaplan, Leslie. Interview with Chris Suarez. 8 Dec. 2004. Chicago Transit\nAuthority.\nJimenez, Dalie. Interview with Brian Myhre and Chris Suarez, 6 Dec. 2004. The\nOffice of Massachusetts State Senator Jared Barrios.\nJimenez, Dalie. Interview with Ian Brelinsky, Anita Chan, Brian Myhre, Jennifer\nNovosad, and Chris Suarez, 22 Sep. 2004. The Office of Massachusetts\nState Senator Jared Barrios.\nKomola, Thomas. Interview with Brian Myhre, 25 Oct. 2004. MIT Police\nDepartment.\nMichaud, Dan. Interview with Jennifer Novosad. 27 Oct. 2004. MIT Card Office.\nSaccoia, Pat. Interview with Chris Suarez. 18 Oct. 2004. Washington\nMetropolitan Area Transit Authority.\nSimonowicz, Mary. Interview with Chris Suarez. 7 Dec. 2004. CTA Transit\nStore.\nSledge, Marvin. Interview with Chris Suarez. 6 Dec. 2004. CTA Customer\nService.\nPrint and Electronic Resources\n\"1998 Data Protection Act.\" United Kingdom.\n<http://www.hmso.gov.uk/acts/acts1998/19980029.htm>.\n\"Activists sue to stop random MBTA bag searches.\" Associated Press. 27 July\n2004. 11 Nov. 2004.\n<http://www.boston.com/news/politics/conventions/articles/2004/07\n/27/activists_sue_to_stop_random_mbta_bag_searches/>.\n\n\"AVI - Passive vs. Active Tags.\" <http://www.awid.com/new/Sub-\nPage/DougCram-Active-vs-passive.pdf>.\nBean, Brandon, Robert Dudley, and Hideaki Tomikawa. \"Business Case Study:\nAuto-ID Fare Collection at the MBTA.\" 1 Feb. 2003. MIT Auto-ID Center.\n10 Dec. 2004. < http://www.autoidcenter.cn/solution/download/Auto-\nID%20Fare%20Collection%20at%20the%20MBTA.pdf>.\nBrenner, Kimberley. \"Atlanta's Transit Authority, MARTA, is taking the Georgia\nCity Contactless.\" RFIDNews. February 1, 2003.\n\"Brief of Amicus Curiae from The Center for Constitutional Rights and Privacy\nActivism in Support of Appellant, John Gilmore.\" Gilmore v. Ashcroft.\nFiled August 19, 2004.\n<http://209.123.170.170/gilmore/_dl/CCR&PA%20Amicus%20Brief.pdf>.\n\"Central Puget Sound Fare Coordination Project.\"\n<http://transit.metrokc.gov/prog/smartcard/smartcard.html>.\n\"Chapter 66A Section 1, Definitions.\" Massachusetts State Code.\n<http://www.mass.gov/legis/laws/mgl/66a-1.htm>.\n\"Chapter 66A Section 2, Fair Information Practices.\" Massachusetts State Code.\n<http://www.mass.gov/legis/laws/mgl/66a-2.htm>.\n\"Chicago Card FAQs Page.\" <http://chicago-card.com/ccplus/faq.aspx>.\n\"Chicago Card Privacy Statement.\" <https://www.chicago-\ncard.com/cc/privacy.aspx>.\n\"Chicago Transit Authority Privacy Policy Statement.\" Online posting. 15 Dec.\n2004. Chicago Transit Authority. 11 Nov. 2004.\n<http://www.transitchicago.com/help/privacy.html>.\n\"Customer Bill of Rights.\" Massachusetts Bay Transit Authority.\n<http://www.mbta.com/contact_us/customerbill.asp >.\nDavis, Jonathan. \"Balancing Debt & Pay-As-You-Go Financing.\" 10 Oct. 2002.\nMBTA. 10 Dec. 2004.\n<http://gulliver.trb.org/conferences/Fin3/Track2_Davis_10-28-02.pdf>\nDavis, Jonathan R. MBTA Privacy Action Plan to Senator Barrios, October 13,\n2004.\n\n\"Definition of an RFID System.\"\n<http://www.webopedia.com/TERM/R/RFID.html>.\n\"DoD implements RFID.\" http://dc.internet.com/news/article.php/3098561\n\"Electric toothbrush charger.\" Self-Service Science Forum.\n<http://www2.abc.net.au/science/k2/stn/posts/topic179735.shtm>.\n\"English Guide to Oyster.\"\n<http://www.oystercard.com/files/lan/English.pdf>.\n\"EPIC\" - http://www.epic.org/privacy/rfid/ftc-comts-070904.pdf\n\"EZ Pass Website.\" http://www.ezpass.com/static/info/index.shtml\n\"Fair Information Practices, Chapter 66A, Section 2.\" Massachusetts State Law.\n<http://www.dmr.state.ma.us/Chapter_66a_Section2.html>.\n\"Faraday cage.\" Wikipedia. <http://en.wikipedia.org/wiki/Faraday_cage>.\nFarber, David. \"[IP] [E-PRV] [RFID] Dave Emory examines EZ Pass\ntransponders.\" 9 Jul. 2004. eList eXpress LLC. 11 Nov. 2004.\n<http://www.interesting-people.org/archives/interesting-\npeople/200407/msg00086.html>.\nFlint, Anthony and Mac Daniel. \"'Charlie' to begin new ride with modern fare\nsystem.\" The Boston Globe. 9 Nov. 2004. 11 Nov. 2004\n<http://www.boston.com/news/local/articles/2004/11/09/charlie_to_b\negin_new_ride_with_modern_fare_system?mode=PF>.\nGilles Deleuze, \"Postscript on the Societies of Control\", from _OCTOBER_ 59,\nWinter 1992, MIT Press, Cambridge, MA, pp. 3-7. Available HTTP:\n<http://www.n5m.org/n5m2/media/texts/deleuze.htm>.\nHeigham, James C. and Leonard H. Freiman. \"Tapping Officials' Secrets:\nMassachusetts.\" 2001. The Reporters Committee for Freedom of the Press.\n11 Nov. 2004. <http://www.rcfp.org/cgi-\nlocal/tapping/index.cgi?key=MA>.\nHeigham, James C. and Leonard H. Freiman. \"Tapping Officials' Secrets: New\nYork.\" 2001. The Reporters Committee for Freedom of the Press. 11 Nov.\n2004. <http://www.rcfp.org/cgi-local/tapping/index.cgi?key=NY>.\n\nJoshua. \"RFID Secutiry Woes.\" 30 Jul. 2004. Geek News. 11 Nov. 2004.\n<http://www.geek.com/news/geeknews/2004Jul/gee20040730026261.ht\nm>.\nKanellos, Michael. \"Under-the-skin ID chips move towards Hospitals.\" 27 Jul.\n2004. 11 Nov. 2004. <http://news.com.com/Under-the-\nskin+ID+chips+move+toward+U.S.+hospitals/2100-7337_3-\n5285815.html?t4ag=st.rn>.\nKent, Stephen T. and Lynette I. Millett \"IDs -- Not That Easy: Questions About\nNationwide Identity Systems.\" Committee on Authentication\nTechnologies and Their Privacy Implications, National Research Council.\n11 Apr. 2002. 11 Nov. 2004.\n<http://www7.nationalacademies.org/cstb/pub_nationwideidentity.htm\nl>.\nLaurant, Cedric and Kenneth Farrall. \"RFID Workshop Comment P049106.\"\nElectronic Privacy Information Center. 21 June 2004. 11 Nov. 2004.\n<http://www.epic.org/privacy/rfid/ftc-comts-070904.pdf>.\nLemos, Robert. \"RFID tags become hacker target.\" 20 Jul. 2004. CNET News.\n11 Nov. 2004.\n<http://news.com.com/RFID+tags+become+hacker+target/2100-1029_3-\n5287912.html>.\n\"MBTA Police - Safety/Crime Prevention.\" Massachusetts Bay Transit\nAuthority. 11 Nov. 2004.\n<http://www.mbtapolice.com/prevention/index.html>.\nMcBride, Gregory B. Letter to Letter to Michael Mulhern. 12 Aug. 2002. 11 Nov.\n2004.\n<http://www.fta.dot.gov/library/legal/buyamer/inltrs/cubic81202.htm\nl>.\nMcIntyre v. Ohio Elections Commission. 514 U.S. 334.\n\"Metro Privacy and Data Use Policy, Washinton D.C.\"\n<http://www.wmata.com/about/datause.cfm>.\n\"Metro privacy and data use policy.\" Online posting. Washington Metropolitan\nArea Transit Authority. 11 Nov. 2004.\n<http://www.wmata.com/about/datause.cfm>.\n\n\"Metro Short-Range Transportation Plan.\"\n<http://www.mta.net/projects_plans/shortrange/SRTP.htm>.\n\"MIFARE - contactless Smart Card Ics.\"\n<http://www.semiconductors.philips.com/markets/identification/prod\nucts/mifare/>.\n\"Minneapolis Metro Transit Ride to Rewards Program.\"\n<http://www.metrotransit.org/riderPrograms/rideToRewards.asp>.\nO'Connor, Mary Catherine. \"Transit Moves Ahead with RFID.\" RFID Journal.\nOct. 27, 2004.\n\"OECD Guidelines on the Protection of Privacy and Transborder Flows of\nPersonal Data.\" 2001. Organization for Economic Co-Operation and\nDevelopment. 11 Nov. 2004. <http://www1.oecd.org/publications/e-\nbook/9302011E.PDF>.\n\"Organization for Economic Cooperation and Development Guidelines.\"\nOrganization for Economic Cooperation and Development. 1980.\n<http://www.oecd.org/home/>.\n\"Oyster card wins public nominated award.\"\n<http://www.oystercard.com/files/press/Oyster_wins_award_July_04_\nFINAL.doc>.\n\"Oystercard - Explanation of Pre Pay Tickets.\"\n<http://www.oystercard.com/buy_1_4.php>.\n\"Passive Tags Track Cars.\"\n<http://www.rfidjournal.com/article/articleview/1078/1/1/>.\n\"Personal Privacy in an Information Society.\" Electronic Privacy Information\nCenter. 1977. <http://www.epic.org/privacy/ppsc1977report/>.\n\"Privacy and Secure Identification Systems White Paper.\" Feb. 2003. Smart Card\nAlliance. 11 Nov. 2004.\n<http://www.smartcardalliance.org/alliance_activities/privacy_report.cf\nm>.\n\"Privacy Policy.\" MIT Card Office. 11 Nov. 2004.\n<http://web.mit.edu/mitcard/privacy.html>.\n\n\"Radio Frequency Identification Usage.\" Wal-Mart.\n<http://www.walmartstores.com>.\n\"Radio Frequency Identification.\"\n<http://www.connect802.com/rfid_facts.htm>.\n\"RFID Basics\" http://www.savi.com/rfid.shtml\n\"RFID Privacy Workshop @ MIT. 15 Nov. 2003. Massachusetts Institute of\nTechnology. 11 Nov. 2004.\n<http://www.rfidprivacy.org/2003/agenda.php>.\n\"RFID Special Report.\" ZDNet UK.\n<http://insight.zdnet.co.uk/specials/rfid/0,39026568,39153971,00.htm>.\n\"Romney Sings the Praises of MBTA's New Automated Fare Collection System.\"\nMBTA News/Events. 8 Nov. 2004. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/press_releases_details.asp?ID=1072>.\nScheidt & Bachmann GmbH. 11 Nov. 2004. <http://www.scheidt-\nbachmann.de/index-e.html>.\n\"Secretary's Advisory Committee on Automated Personal Data Systems,\nRecords, Computers, and the Rights of Citizens viii.\" Electronic Privacy\nInformation Center. 1973.\n<http://www.epic.org/privacy/hew1973report/>.\n\"Shrouds of Time: The history of RFID.\" 1 Oct. 2001. The Association for\nAutomatic Identification and Data Capture Technologies. 11 Nov. 2004.\n<http://www.aimglobal.org/technologies/rfid/resources/shrouds_of_ti\nme.pdf>.\n\"Smart Card Talk: Smart Cards and U.S. Transit Agencies.\" Sept. 2003. Smart\nCard Alliance. 11 Nov. 2004.\n<http://www.smartcardalliance.org/newsletter/september_04/feature_0\n904.html>.\n\"SmarTrip Overview.\" <http://www.wmata.com/riding/smartrip.cfm>.\nSolove, Daniel J. \"Digital Dossiers and the Dissipation of Fourth Amendment\nPrivacy.\" Southern California Law Review, Vol. 75, July 2002.\n<http://ssrn.com/abstract=313301>.\n\nSurden, Harry. \"Unbundling the Privacy Debate: RFID, Privacy and Emerging\nTechnologies.\" Stanford University. 11 Nov. 2004.\n<http://www.stanford.edu/~hsurden/RFID_Privacy_Law.htm>.\n\"The Chronicle of the Boston Transit System.\" 2003. Massachusetts Bay Transit\nAuthority. 11 Nov. 2004.\n<http://www.mbta.com/insidethet/taag_history.asp>.\n\"Transport for London Privacy Policy.\"\n<http://www.londontransport.co.uk/tfl/privacy.shtml>.\n\"Transport for London Ticketing data Protection Statement.\"\n<http://www.londontransport.co.uk/tfl/nftt_dataprotection.shtml>.\n\"Types of RFID.\" RFID Handbook. <http://www.rfid-\nhandbook.de/rfid/types_of_rfid.html>.\nUnited States of America v. Gerald Frank Kroll. 481 F.2d 884;\n\"Wal-Mart, DoD Forcing RFID.\" Wired News.\n<http://www.wired.com/news/business/0,1367,61059,00.html>.\nWeis, Stephen A. \"Cryptography and Information Security Group.\" CASIL MIT.\n11 Nov. 2004 <http://crypto.csail.mit.edu/~sweis/>.\n\"Workshop Proceedings.\" Online posting. RFID Privacy Workshop @ MIT. 15\nNov. 2003. 11 Nov. 2004.\n<http://www.rfidprivacy.org/2003/agenda.php"
    },
    {
      "category": "Resource",
      "title": "mitid_crd_sys.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/16f0d48dab62be89c6935f43f4af0680_mitid_crd_sys.pdf",
      "content": "The MIT ID Card System: Analysis and\nRecommendations\nPriya Agrawal\nNeha Bhargava\nChaitra Chandrasekhar\nAl Dahya\nJ.D. Zamfirescu\nDecember 10, 2004\n\nContents\n-\nList of Figures\n-\nList of Tables\n-\nIntroduction\n-\nMethodology\no Our Research\no What is this report?\n\n-\nHistory\n-\nCurrent Policy Practice & Our Policy Recommendations\no Policy Recommendations Summary\no Introduction\no Tracking\no Locations Tracked\no Access to the Tracking Database\no Card Policy Making and Reviewing Bodies\no Card Advisory and Oversight Board\no Auditing\n\n-\nExisting Access Technologies\n\no Magnetic strip\no Radio Frequency Identification\no Smartcards\n\n-\nThe Current MIT Card Technical System\no The MIT ID Card\no Reader System and Access Control\no Data Management and Network\no Limitations of the Technical System\n\n-\nTechnical Recommendations\no Card and Readers\no Access Control\no Data Management and Network Issues\n\n-\nComparable Systems: Harvard\no The Harvard system\n\n-\nComparable Systems: Stanford\no Data storage\no Access to Data\n\n-\nFeasibility of the Proposed System\n-\nConclusions, Summary of Recommendations, and Contributions\n-\nSurvey\n-\nBibliography\n\nList of Figures\n1. Contact smartcard\n2. Contactless smartcard\n3. Plastic card size and dimensions\n4. Magnetic strip positioning\n5. Type of card from Indala\n\n6. Example broadcast recorded from an MIT Card. [25]\n\nList of Tables\n1. Magnetic Strip Tracks\n2. Contents of Magnetic Strip Tracks\nIntroduction\nThe MIT ID Card serves as a primary form of identification for all members of the MIT\ncommunity. Advances in technology have made it possible to expand the functionality of\nthe MIT ID Card over the years to provide many conveniences, including access to\nvarious facilities and the use of TechCash for purchases. However, these added comforts\nhave come at a price: the security and privacy of MIT Card users. Technical problems -\nsuch as the theft of information on an MIT Card and the ease with which the card can be\nduplicated - have already been demonstrated, and seriously compromise the security of\nthe card. The privacy of individual card-owners is at also a serious concern with the\ncurrent card system, which has the ability to track users by keeping information on every\ntransaction, including entries and exits to and from campus buildings. Our report aims to\nanalyze how these issues affect the MIT ID Card system and the MIT population as a\nwhole. In order to understand the system and the issues and concerns that influence it, we\nconducted interviews with administrators, faculty, lab directors, the police, and relevant\ncommittee members. To ensure student participation in the process, we conducted a\nsurvey of the student body to assess the awareness level, security and privacy concerns,\nand opinions of the current system.\nHaving studied the current system and policies, other available technologies and systems,\nMIT student body opinions, and the facts presented by and the opinions of other players,\nour group has identified several areas for improvement. Our recommendation can be\nbroadly broken into three categories: technology, policy, and oversight. In terms of\ntechnology, we found the encryption offered by the current RFID system to be inadequate,\ntherefore the widespread use of RFID technology should be shelved until the security of\nthe system can be confirmed. Policy-wise, we have found MIT's current method of\nstoring data on all card swipes with no restrictions to be excessive. We also find that the\npolicy is not clearly stated and the cardholders are not appropriately informed. We\nrecommend that entry data be kept only for those labs and dormitories who request it. In\ngeneral, entries to public spaces will not be tracked; however, tracking of these areas may\nbe turned on at the discretion of a committee we describe. Finally, we believe that an\noversight board is required to ensure that access to information resulting from card use is\nregulated by a clear and easily available policy and that this policy is consistently\nenforced. This will ensure the accountability of those who can access the logs and the\nprivacy of users, at the level decided by the oversight board.\n\nIn analyzing the MIT ID Card system we endeavored to follow three guiding principles in\nbuilding a system that is beneficial to all users.E The first of these principles is the\nprotection of privacy for cardholders. To the greatest extent possible, we believe that\nMIT community members should be free to use their card without fear of being tracked.E\nThe second guiding principle we have followed is to maintain campus security. Therefore,\nwhile privacy is important we have also tried to remain cognizant of the fact that entry\nlogging can serve as an important tool to combat crime on campus. Third, we seek to\nensure that the MIT Card is both convenient and able to provide expanded services to\ncardholders. We believe that the expanded functionality currently offered by the MIT\nCard is of real value to the MIT community and should be maintained wherever and\nwhenever possible. In many ways, these three principles are contradictory, with greater\nsecurity often meaning less privacy and reduced convenience; our goal here is to balance\nthe three competing demands and achieve an acceptable and maintainable equilibrium\nbetween privacy, security, and convenience.\nMethodology\nThis section describes in detail 2.1 the methodology of our research into the MIT ID Card\nand its associated privacy implications and 2.2 outlines what this report is meant to\nachieve.\n\nOur Research\nOur main goal in studying the MIT ID Card system was to talk to everyone and get as\nmany first-hand accounts as possible: we gathered opinions from undergraduate and\ngraduate students via a survey, and we interviewed administrators, former administrators,\nthe Card Office, Enterprise Services, MIT Police, lab heads, members of old committees\ncharged with a similar mandate as our own, current members of the Card Advisory\nCouncil, vendors of the current system, a few faculty members, and a few generally\noutspoken members of the community. In addition to our primary sources, we also\nconsulted a number of secondary sources: Tech news articles, system specifications, IS\ndocumentation, internal websites. We used these articles as launching points from which\nwe found a number of faculty members, administrators, and committee members with\nwhom to speak.\nSurvey\nIn order to discover how the student body feels about the MIT ID Card and its associate\npolicies, we conducted a survey over a period of one month beginning November 1. We\nadvertised our survey on the undergraduate dorm mailing lists, which combined reach a\nvery large fraction of undergraduate students and also many graduate students. We also\nadvertised our survey to certain graduate dorm lists, and also one or two ILG lists, but it\nis safe to say that our survey as a whole represents more the opinion of undergraduates\n\nliving in dorms than any other particular group: of 513 respondents, 63 do not live in on-\ncampus dorms, and 403 had not spent any time as graduate students (i.e., were\nundergraduates). The principal reason for this skew in representation is distributionary,\nand unfortunate: neither the Inter-Fraternity Council nor the Graduate Student Council\nreplied to repeated requests to forward our survey to their members.\nOur survey was online, available at http://privacy.mit.edu; it took on average 5-10\nminutes to complete, and consisted of 9 ``main'' survey questions, 4 demographic\nquestions, and a comments box. We offered respondents to leave their username to enter\na drawing for a $20 gift certificate for one respondent, as an incentive for participation.\nWe justified this incentive by realizing that we were more likely to hear from students\nwho did not have a very strong opinion on the matter if we included an external incentive.\nThe default response for all questions was ``decline to respond'' (and an empty box for\nthe one main question that involved text entry). All questions were optional, and 18\nrespondents declined to respond at least one main question. An additional 60 respondents\ndeclined to answer the one main question that involved text entry;1 the other 8 main\nquestions involved only selection from a menu.\nWe were interested to know whether students knew that the MIT ID Card contains an\nRFID chip in it, and whether they were comfortable with it. We were also interested to\nknow how students felt about the current policy of keeping logs of entry data. Finally, we\nwere also interested to know student opinions on some of the policies we were\nconsidering recommending.\nAppendix A contains a full copy of our survey as it was presented, as well as a\ndescription of the distribution of responses for each question. The conclusions we drew\nfrom the results of our survey are spread throughout the rest of the report.\nInterviews\nTo find the opinions of the various groups on campus who might potentially have an\ninterest in the MIT ID Card, and in order to be able to take their thoughts into\nconsideration in our report, we conducted numerous interviews with community leaders:\nCurrent and Former Administrators\nDan Michaud\nHead of the MIT Card Office. Mr. Michaud was very helpful in describing the\ncurrent system; he provided us with many contacts throughout campus who have\ninterests in the MIT Card system. He is also concerned about successors to the\nCard Office and stresses on the importance of an audit process.\nLarry Benedict\nDean for Student Life. We discussed with Dean Benedict issues related to dorm\naccess and the MIT Card. He was unaware of the tracking policy of the MIT Card\nsystem. He felt that MIT gave more autonomy to students than other institutions.\n\nArthur Smith\nFormer Dean for Undergraduate Education and Student Affairs; Former Chair of\nMIT Privacy Committee. Professor Smith was the first chairman of the Privacy\nCommittee which was formed in the wake of the Vietnam War. It was an era of\nchange with the Buckley amendment and co-ed dorms at MIT. This ad-hoc\npresidential committee compiled a report about the handling of information at\nMIT. Policy issues required approval by the Dean (who was also a faculty\nmember). He believes that education and awareness is a very important\ncomponent of a successful system dealing with privacy issues.\nHarry Lewis\nFormer Dean of Harvard College. Professor Lewis was very helpful in providing\nan external viewpoint. At Harvard as Dean, Lewis was the gatekeeper for entry\ndata to the undergraduate dormitories; his thoughts on the Harvard system were\ninvaluable to our analysis of the MIT system.\nJohn McDonald\nAssociate Director, Enterprise Services. Mr. McDonald gave us valuable input on\ndecisions made about the MIT Card. He views the Card Office as a guardian of\nconfidential information similar to the registrar, bursar and HR. He welcomes the\ninvolvement of student and faculty in the process but would like to have\nconsistent involvement over time.E\nFaculty\nIn addition to the faculty mentioned above, we spoke with:\nJoseph Ferreira, Jr.\nProfessor of Urban Studies and Planning; Former Head of MIT Privacy\nCommittee. Prof. Ferreira gave us extended input on the working of the former\ncommittee including the lack of adequate representation from all sectors and the\nreasons for dissolution. He also said that the MIT Card was an example of how\nprogress could be hindered by privacy concerns. He thinks an audit trail should be\ntraceable.\nHal Abelson\nClass of 1922 Professor of Electrical Engineering and Computer Science;\nMember of CSAIL Prox Card Privacy Committee; Professor Abelson pointed us\ntowards great resources and was also an invaluable guide in directing and helping\nus work on our paper.\nLab Directors\nAnthony Garratt-Reed\nPrincipal Research Scientist, Department of Materials Science and Engineering.\nMr. Garratt-Reed stated that they had their own RFID system in place before\nsince they needed localized access control. After the incorporation of RFID in the\nMIT Card and the capability for client access stations, they moved to the MIT\nsystem. He is fairly concerned about the duplication of cards to gain access into\n\nthe labs but he is not significantly concerned about the fraudulent use of other\npeople's cards to gain access to the labs.\nLissa Natkin\nAssistant Director, Computer Science & Artificial Intelligence Lab. Ms. Natkin\nhelped us determine what labs need from the MIT ID Card system, and also\nmentioned the cost savings in using the card. She also mentioned that card\ntracking was not useful during the times when doors were open to everyone and\nthefts happened more frequently.\nGregory Tucker\nDirector of Facilities of the Media Lab. Mr. Tucker mentioned that the main use\nof alternate RFID card systems in the lab was for limited access to hazardous\nregions. They hope to upgrade to the MIT system in the future for convenience\nand ease of administration. Their legacy system stores data for 18 days and used\nonly in the case of theft.\nMIT Police\nJay Perault\nDetective, MIT Campus Police. Detective Perault gave us input about the police's\nperspective on the Card system. He said that the tracking data had been useful in\ninvestigations and should be continued. He also spoke about the Cori Law in\nMassachusetts, which ensured that privacy concerns were considered while\nlooking at government data and similar high standards they set for privacy issues.\nAlbert Pierce, Jr.\nLieutenant, MIT Campus Police. Lieutenant Pierce addressed many of our\nconcerns about the MIT Card. He concurred that the tracking data had been useful\nin the past. He was not able to reveal details about the cases or the number of\ntimes of usage. He said the data used was very case-specific and all requests had\nto be approved by Chief DiFava.E\nSystem Vendors\nMagnaData\nRepresentatives from the firm. The representatives gave useful information about\npossible future systems and what considerations need to be taken into account.\nIndala\nSales representative at the firm.E The representative spoke about the FlexSecur\nsystem but would not go into details about the security. When faced with the\nquestion about the vulnerability shown by Winstein, Roach, & Mandel, he would\nnot give a comment and stated that he had not heard about it.\nCommittee Members\nIn addition to those committee members listed above, we spoke with:\n\nMember of the Card Advisory Council. As the newest member of an infrequently\nmeeting committee, Manisha has only been to one meeting.\nHector Hernandez\nMember of the Card Advisory Council. Hector was very helpful in giving a first-\nhand account of how the Card Advisory Council operates. He spoke about the\nrepresentation, operation, and motivation of the council.\nAmy Bruckman\nMember of the former MIT Privacy Committee. Amy gave us an account of the\ndifferent parties involved with the then Privacy Committee and the committee's\npro-privacy orientation. She also felt that raising awareness was an important\naspect of the problem.\nMembers of the MIT Community\nRichard Stallman\nMr. Stallman is a very vocal critic of governmental tracking and sees MIT as an\nextension of the U.S. government. He also believes MIT, as an academic\ninstitution, should be a model of openness.\nIn addition to the people we spoke with, there are a number of community members we\nwanted to speak with but were unable to: Chief of Campus Police John DiFava; any\nmembers of the former Card Steering Committee; and any members of the former Card\nPrivacy Committee. We were able to find almost no information beyond a single Tech\narticle on the Card Privacy Committee. It is possible that this committee did not exist,\nand was merely proposed, or that it simply produced no discussion or recommendations.\n\nWhat is this report?\nOur report contains three foci: a description of the current system, including limitations\nand flaws; a description of the ideal system; and necessary changes to the current system\nthat can be implemented at low cost. Our recommendations throughout are heavily\ninfluenced by the individuals we spoke with and take into consideration to the greatest\nextent possible the differing views of all parties with interest in the MIT ID Card system.\nThe Current System\nWe present a thorough history of the current MIT ID Card system, as well as a discussion\nof the technical flaws and the questionable practices and policies currently employed.\nThe current system is imperfect in many ways; we identify these ways. We also consider\ninput from as many campus groups as we have spoken with to discover their opinions of\nthe current system and how it might be changed.\nManisha Manmohan\n\nWe also present a recommendation for the ideal future system. Our system addresses as\nmany of the technical flaws of the current system as we believe is possible with currently\navailable technology. Our technical recommendations are heavily influenced by our\npolicy decisions, which we believe will result in a system that is acceptable to as many\nmembers of the MIT community while still within the bounds of implementability and\nwhile being useful to those who require the information available by virtue of having a\ncampus-wide access system.\nNecessary Changes to the Current System\nWe are not blind to the fact that any new implementation will take a substantial amount\nof time, money, and effort. Many of the administrators we spoke with were not optimistic\nabout the likelihood of an entirely new system being implemented from scratch,\nespecially since many of our ``ideal system'' recommendations are not being offered by\nvendors as an off-the-shelf solution. To address this problem, we present a set of changes\nwe believe is it imperative be applied to the current system to address our serious privacy\nconcerns.\nHistory\nHistorically, MIT had used a person's social security number (SSN) as their primary\nidentifying number across MIT systems. In fact, the SSN would be the ID number that\nappeared on an MIT identification card. However, as more records were stored on\ncomputer systems and access to these systems become more widespread, concerns about\nprivacy became more acute. The use of a person's SSN as the common institute\nidentification number was quickly singled out as being both dangerous and unnecessary.\nIn response to these concerns, the Institute began to restrict use of a person's SSN,\ndeclaring it part of a person's personal data and thus protected by the MIT policies on\nprivacy and disclosure of information. In tandem, MIT's Data Administrator, Scott\nThorne, issued the Tech Info document ``People Related Projects: 37707'' to MIT\nInformation Systems on August 17th, 1994. The document outlined the creation of a new\ncommon MIT ID numbering scheme and the system to support the lookup and\nassignment of this ID.23\nAccording to the initial 1994 document, the MIT ID required the following four\nattributes:\nUnique\nEach MIT ID must be unique to only one individual.\nDistinct\nEach person should only have one MIT ID number and that number should be\nused to across the institute to identify the person.\nRandom\nThere should be no implied or derived meaning encoded within the MIT ID. No\npersonal information should be identifiable simply by looking at the MIT ID.\nThe Ideal System\n\nPublic\nThe MIT ID should be considered public data that can be openly and freely used.\nTherefore, the MIT ID alone should not be considered sufficient to authenticate\nan individual.\nIn August 1995 development of the central computer system necessary to support the\nnew MIT ID was completed and over the years this ID system has been adopted by the\nfollowing campus groups:\n-\nAthletics\n-\nProject Athena\n-\nPersonnel\n-\nCard Office\nConcurrently with the developments of the MIT ID, the Institute was also endeavoring to\ncreate a more flexible and useful ID card. On September 29th, 1993, MIT started\nexperimenting with consolidating the functionality of its meal card and ID card. The new\n``student services card'' was to be the first phase in a process that, as then Director of\nHousing and Food Services Lawrence E. Maguire put it, would create a ``one-card\nsystem that [met] the fundamental needs of the Institute as a whole [for] identification,\naccess, and purchasing.'' [5] The process initially went through some growing pains as a\nproper system was fleshed out that would allow ID card, meal plan access, door access,\nand other functionality to exist on one card. In fact, the 1993-1994 academic year almost\nseemed comical to MIT students as they were issued no fewer than three cards over the\ncourse of the year. A column in The Tech perhaps best summarizes the incredulity that\nsome regarded MIT's attempts to create a new card. In columnist Mark P. Hurst's self-\nstyled ``Cards in Review'' he notes that:\nIn September we all affixed our registration stickers to our Old Card, the\nID card we've used since freshman year. Magnetic stripe, photo, and a spot\nfor the athletic sticker.\nThings soon got better when we got the New Card (at this point, the ``Old\nNew Card''). This winner had the notable improvements of not containing\na photo, registration sticker, or athletic sticker. The Old New Card was\nmuch better than the Old Old card, since it could be used for unlocking\nsome doors some of the time (for mine, none of the time) and for buying\nlots of overpriced food on its New Magnetic Stripe. It also had the value\nadded service (for you ARA types, a ``Val-U-Service'') that students could\nuse stolen Old New Cards without that hassle of photo identification.\nJump to the present: the New New Card. It has a New New Magnetic\nStripe, which can be used to open more doors more of the time, and a New\nPhoto, which is really an Old Photo, having been taken from the Old Old\nCard, but no athletic sticker, which is still on the Old Old Card. So if you\nwant to buy an overpriced lunch and then work it off in the gym, you have\nto carry the Old Old Card and the New New Card.\n\n...You may be saying to yourself, ``The real reason we got three cards this\nyear is because we're in a transition period to a new card.'' Could be, but\ncan't we have foresight of more than a week to cut down on new versions\nof the same old magnetic stripe? Besides, next year won't be much\ndifferent. Look at your New New Card. On the front is an expiration date -\nin September. That's right: get ready for the New New New Card next fall.\nThe fun never ends! [15]\nAs Hurst astutely noted, the next installment in the evolving MIT Card was issued\ntowards the end of September 1994. The new card endeavored to combine the various\nfunctionality of the many cards from the previous year. In this case, dormitory access,\nparking access, meal purchases, and library card services were all included in one card. A\nfeature new to this card was the introduction of a declining balance account that allowed\nstudents to make cash purchases using their ID card. This card was used for the entire\nyear and is the first in the line of cards now known at MIT as the MIT Card.\nFrom early in the process it was noted that security and privacy issues would dominate\nthe introduction of this new MIT Card, however for the first few years little was done to\nformally address these issues. On November 3rd, 1993, the Undergraduate Association\n(UA) appointed a task force to investigate privacy, security, and convenience concerns\nsurrounding the introduction of the proposed MIT Card. Also as early as 1993, the\ndifferent offices within MIT that were planning on making use of the new MIT Card\nbegan stating what policies they would be following regarding the usage data that would\nbecome available to them. Assistant Director of Housing and Food Services Kenneth R.\nWisentaner told The Tech that despite having the capability to track student use of card\nreaders to gain access to MIT buildings, there was no intention of actually using this\nfeature. Chief of Police Anne P. Glavin reported that parking lot usage data would be\nrecorded and stored for 2 years for parking and traffic enforcement and for long range\nplanning. Finally, Wisentaner noted that meal transactions would be stored for about one\nacademic year. [6]\nIn this mess of policy declarations and preliminary investigations by the UA, it is very\nstriking that no overarching body was acting to coordinate and oversee the creation and\nimplementation of privacy and usage polices for the new ID card. At the time, no\ncommittee existed whose mandate specifically covered the MIT Card and its associated\npolicies; instead, all privacy issues fell under the purview of the Faculty Committee on\nPrivacy. However, as if to exacerbate the existing problem with lack of oversight, the\nCommittee on Privacy ceased to meet between May 1994 and November 1995 because\nthere was no one to act as chair of the committee. What is more, as observed by Amy S.\nBruckman - then Graduate Student Union (GSU) representative to the Committee on\nPrivacy, the committee itself ``had no authority or resources, and its recommendations\nwere often ignored or laxly enforced.'' [17] This lack of cohesion and oversight is\napparent in an anecdote recounted by Bruckman. According to her, a few months after\nuse of card swipe access to dormitories was activated, a student called the security guard\nof her dormitory to report that her card was not working and had never worked. The\nsecurity guard, in response to this complaint, responded by saying that indeed the card\n\ndid work because it was used to gain access to some building X at a previous time. In the\nend, it turns out that, despite the assertion by the Office of Housing and Food Services\nthat it would not be tracking students, they had forgotten to switch off the tracking feature\non the system.\nDuring the early phases of the introduction of the MIT Card, privacy took a back burner\nto the sheer number of complications that surrounded the implementation of the new ID\nsystem. It was not until 1995 - after the new MIT Card was better established - that\nserious attention was drawn to the security and privacy implications. In September of\n1995 MIT issued yet a new ID card. The new MIT Card's biggest change was that it no\nlonger displayed the student's SSN, instead using a randomly generated ID number\ncreated using the system proposed and implemented by MIT Data Services. This marked\nthe convergence of the programs to develop a more private MIT identification scheme\nand a more functional ID card. Also of important note, this new ID card was, for the first\ntime, issued to MIT employees, thus replacing an older ID issued by the Personnel Office.\nVery shortly after the introducing the new ID card for the 1995-96 school year, Senior\nVice-President William R. Dickinson announced the creation of the MIT Card Steering\nCommittee. The committee had no standing agenda and was instead tasked with\naddressing any issues regarding the MIT Card as they arose. One of the first issues that\ncame to the forefront of attention was the security of data contained on the MIT Card's\nmagnetic strip. It was realized early on that, if someone could gain access to a person's ID\ncard, the information stored on the card could be easily read by any card reader and used\nto steal the person's identity. On March 28th, 1995 Andre DeHon published a paper\nentitled ``Security Assessment of the M.I.T. Card.'' Through the course of this paper,\nDeHon proceeds to make an argument that that ``the level of security provided by the\ncard is laughable.'' His analysis walks through several scenarios in which an ID card\ncould become compromised and ultimately leads to several recommendations that\nessentially suggest that the MIT Card was not sufficiently secure to be trusted for use\nwith financial transactions. [7]\nOn the heels of DeHon's paper and the controversy it caused, the Office of Housing and\nFood Services instructed that the MIT Card should no longer be used as collateral for\nitems loaned to students. This referred to the common practice of requiring a student to\ngive their card away whenever they took items, especially from dormitory desks, on loan.\nWhen the student returned the borrowed item, they were given back their ID. The main\nconcern here was that while a student's card was held as collateral it could be read by a\nrogue reader and its information stolen.4 In possession of information stolen from an ID\ncard, a person could create a new card and make purchases or access restricted areas\nunder this new identity. In response to questions about DeHon's report, Associate\nDirector of Food Services John T. McNeil noted that, ``We [at the Office of Housing and\nFood Services] were certainly aware of the faults that [DeHon] points out. I don't really\nknow of a system that would be foolproof.'' Carrying on, McNeil states that, ``we knew\n[when] putting [the new MIT Card system] together that the system is only as good as the\npeople who use it. We were aware that copying was a possibility, but really it's a felony\nto do that.'' In many ways, McNeil's reaction summarized the sentiment at the time. Yes\n\nthere were legitimate concerns and yes the card system was not perfect; however a lot of\ntime and money had been sunk into the system and, frankly, it would be impossible to\ndevelop a perfectly secure yet convenient and flexible solution for the MIT ID Card.\nTherefore, faced with this reality it seems that the overwhelming choice was to go\nforward with the system on hand and accept the increased risks as the cost of having a\nmore functional card system. [8]\nThis is not to say that no effort was made to improve the security of the MIT Card. In fact,\nthe Office of Housing and Food Services took some of DeHon's recommendations to\nheart and made some of the technology changes he suggested.5 In fact it could be argued\nthat it was DeHon's paper which prompted then Dean for Undergraduate Education and\nStudent Affairs Arthur C. Smith to instruct that a committee be created to oversee the\nMIT Card. It is as a direct result from this request that the MIT Card Steering Committee\nwas formed. However, as time progressed and the new MIT community became more\nfamiliarized and comfortable with new ID card, these questions of security and privacy\nagain fell from the focus of people's attention.6\nFor the next couple years following 1995, few major changes were made to the MIT Card\nand controversy over the card fell to a minimum. At the onset of the 1996-97 academic\nyear uses for the MIT Card included: identification, meal plan access, library book\nborrowing, access to dormitory entrances, entry to parking lots, and access to various\nbuildings across campus. At this point time, Maguire characterized the services offered\nby the MIT Card to be in the ``upper middle'' segment in comparison to those offered by\nother schools; and while other ways to expand the MIT Card were being explored,\nnothing firm was in the pipeline. Also in 1996, MIT changed its policy on the expiration\nof ID cards. Prior to 1996, cards were valid for only one year and were replaced each\nSeptember; however, in order to cut back on printing costs, card expiration was extended\nto a four year period.\nThe 1997-98 academic year occurred without major event for the MIT Card, but in the\nsummer of 1998 a major reorganization of both the Office of Residence and Campus\nActivities and the Department of Housing and Food Services led to the creation of an\nindependent MIT Card Office. The new MIT Card Office reported to the Dean of\nStudents and Undergraduate Education and was to be headed by former director of\nHousing and Food Services Lawrence Maguire. From this point forward, the MIT Card\nOffice became responsible for development and expansion of the MIT Card system,\ndistribution of ID cards, and maintenance of MIT Card infrastructure and software.\nDuring the summer of 1999, the MIT Card office began an upgrade of the MIT Card\nsystem. The upgrade occurred in two parts, the first occurring in the summer of 1999\nwhen the card office installed Diebold Corporation's CS Gold application.7 The next\nphase involved the installation of a Windows NT server and porting over to an Oracle\ndatabase and would actually not be entirely complete until the 2001-2001 academic year.\nWith an estimated price tag of $350,000, this purchase represents the largest change to\nthe MIT Card system since the upgrades it under went from 1993 to 1995. [9]8\n\nIn 2001, the MIT Card office moved again within the Institute to fall under the\nsupervision of Director of Enterprise Services (headed by Steve Immerman) of the Office\nof the Executive Vice President. Along with this move, a three person team was\ncommissioned to study the existing MIT Card Office and MIT Card. Led by Interim MIT\nCard Office Director Kirk Kolenbrander and with Greg Anderson and Matt Brody from\nMIT Information Systems, the team researched practices at MIT and at universities\nacross the United States and concluded that the MIT Card Office was outdated and\nirrelevant to the MIT community. According to the MIT Card Office 2000-2001 report to\nthe President, the team established the following principles to guide the policies and\nstructure of the office:\n-\nOne card will serve as the only card that individuals need to carry for routine\npersonal use, on or off the campus.\n-\nThat card will function as the primary platform for the identification, access,\nindividual purchasing, and Institute services needs for all members of the MIT\ncommunity (students, faculty, staff, and affiliates).\n-\nThe office that administers that single card will be a fully self-supporting business\nenterprise that obtains its revenue stream through card swipe transaction fees,\nreader connect fees, interest earned on debit card balances, and replacement card\nfees.\n-\nThat office will feature fully centralized control of the card platform, hardware,\nand software, but will allow highly decentralized control of the specific business\napplications to the array of business users.\n-\nCard functionality will be built upon a principle of customer service. With a\nparticular focus on the needs of our resident undergraduates, the card will offer\nsuperior, responsive service to individual card users and those services that\nleverage the card. Extended service hours will characterize the effort, with\nreplacement card services at locations across the campus throughout the day and\nnight.\n-\nThrough the proactive leadership of the office director, card services will inspire\nconfidence among the users and will forge productive relationships among users\nand the service providers and vendors. Through the director, the office will\nimplement a rich communications plan to insure service and accuracy of\ninformation.\nThe full set of recommendations made by the team was compiled into a report which was\nthen adopted by the Dean for Student Life, Vice President for Information Systems, the\nDirector of Facilities, and the Director of Enterprise Services. Final approval for the\nrecommendations in the report was given by the Executive Vice President and the\nChancellor. [10]\nThe period of 2002 to present the MIT Card Office has overseen two interrelated efforts\nin addition to the implementation of the recommendations from the report adopted the\nprevious year. These were a push to ``effectively and efficiently absorb some of the\nsmaller, independent card access systems on campus into its campus-wide system;'' and\nto make the jump to proximity access technology for the MIT Card. [10] The effort to\n\nabsorb other card access systems came from both the belief that a single ID card\ncontrolling access to all campus facilities was preferable to multiple disparate systems\nand the successful completion of upgrades to the MIT Card system which gave it the\ncapability to handle an expanded system. To realize this ambition, the Card Office went\nto the various groups on campus and pitched the idea of using the MIT Card for their\naccess requirements. The concept was extremely well received and, according to the\ncurrent Director of the MIT Card Office Dan Michaud, at present the 34 locations have\nMIT Card client stations installed with over 20 to be deployed before next spring.9 As a\nresult of the extremely strong response the MIT Card Office received to this new program,\nit was forced to reevaluate its policies for privacy and security. Acknowledging the wider\nimpact that any decision made by the MIT Card Office would have on the MIT\ncommunity, a special committee, dubbed the MIT Card Advisory Council, was convened\nin 2002 to help develop policies and procedure for the MIT Card. The council is still in\nexistence and is comprised of representatives from the MIT undergraduate and graduate\npopulation as well as key players in the MIT faculty and staff.10\nThe other big initiative for the MIT Card Office was the rolling out of MIT Cards\nequipped with RFID chips. According to Michaud, the addition of RFID technology\ncame largely at the behest of MIT labs who were interested in expanding into this\ntechnology. There are few firm justifications for using this technology except that it is a\nnew and interesting toy. The most compelling reason for RFID technology is that it will\nsave on maintenance costs because readers and cards are less likely to be worn down. The\nnew cards are rolled out in the summer of 2003 and the newly minted STATA center is\nequipped with proximity card readers. The use of RFID technology drew quick outcry\nfrom members of the MIT community who questioned the security of such a system, one\nof the most outspoken of whom is Richard M. Stallman, founder of the GNU project and\nnow resident in building 32.11 Stallman questions both the security of RFID cards against\nrogue readers and the dangers to privacy that could arise from tracking RFID cards.\nDespite the concerns raised by community members, RFID chips are now included\nstandard within all cards issued by the MIT Card Office.\nPerhaps, the final important event that brings us to the present state of affairs is the\nsummer 2002 decision by the MIT Card Office to activate the tracking feature of the MIT\nCard system and keep logs of all card access incidents for a period of two weeks. The\ndecision to start tracking was done without notification to members of the MIT\ncommunity. News of this change in policy was finally released to the MIT community in\na January 29, 2003 article in The Tech. According to both Daniel Michaud and John\nMcDonald, Associate Director of Enterprise Services, the decision to enable tracking was\nmade in response to requests from a large number of labs and departments for such a\nfeature if they were to use the MIT Card system for access control. According to\nMcDonald, when Enterprise Services took a survey of groups across campus on why they\nhad bought their own access systems the three most common replies they received were:\naudit logs, local control over doors and people with access, and the ability to use\nproximity readers. Therefore, the move to enable tracking was part of the larger program\nto attract these groups to use the MIT Card system. At its own discretion, the MIT Card\nOffice implemented its own policy governing access to tracking logs. This policy stated\n\nthat all logged data would be kept for a period of two weeks and would only be\naccessible by written request from MIT Chief of Police John DiFava. To date, logs have\nbeen accessed in only a handful of instances in response to thefts and missing person\ncases.\nThus we arrive at the current state of the MIT Card, MIT Card Office, and all associated\npolicies. The evolution of the technology, vision, and policies guiding the development of\nthe MIT Card has been far from perfect. However, what we now find ourselves with is a\nsystem that provides many conveniences upon which we rely and, in fact, expect. Many\nquestions have been raised over our ID, and perhaps only a handful of these questions\nhave even been answered; however, many people to whom we have spoken view the\ndevelopment of the MIT Card as a tradeoff between the cost of action (lessened privacy,\nsecurity, and identity theft) and the cost of inaction (decentralized and expensive access\ncontrol across campus and few conveniences for cardholders). It is many of these\nunanswered questions that we endeavor to answer in this report and we hope to provide\nreason and guidance for the further evolution of our MIT Card.\n\nCurrent Policy Practice & Our Policy\nRecommendations\nThis section discusses in detail the current policies and procedures concerning the MIT\nID system, our recommendations for changes and improvements, and why these\nrecommendations are optimal. These policies address issues such as the collection of\ntracking data, permissions to access tracking data, situations in which access to tracking\ndata is appropriate, and an auditing process for all policies and procedures.\nThe current policy for the MIT ID Card is a result of multiple policy changes over the\nyears, which were outlined in great detail above. The current system tracks all types of\nentries from all locations on campus, including in the classroom buildings on the main\ncampus, dormitories, and laboratories. The current magnetic stripe system does not\nrecord failed attempts, which will be described in the Tracking section below, to enter a\nbuilding. It should be noted in reference to this blanket tracking policy that according to\nDaniel Michaud, the head of the Card Office, the current technology system of the card\ncan only support tracking all entries at all locations or recording no entries at all locations.\nAll of the data is then stored in the system for viewing by the gatekeeper of the data two\nweeks after recording.\nThe data that is recorded is under the control of the head of the Card Office. There are\nthree other employees of the office that are also able to access the information freely.\nAccording to the MIT ID Card policies that are posted online, the tracking information\nwill only be used for trouble shooting and police investigations. [18]\n\nThe troubleshooting occurs at the Card Office by the employees. As far as police\ninvestigations, the chief of Campus Police, currently Chief John DiFava, must send a\nsigned written request to the head of the Card Office to obtain any tracking information.\nNo other outside group is allowed to request the data.\nWhen an access to this data occurs, then there is a log that is updated to record who\nviewed what data at what time. The current system does include a log that could be used\nfor auditing information. This computer also includes the log files of who has accessed\nthe database. However, it is speculated that Mr. Michaud leaves his account logged into\nhis computer during the day for other employees to use the database system. Aside from\nthe speculation, the log is also useless for auditing the head of the office if he can easily\ndelete any evidence of accesses that he has made of the data.\nThe tracking policy in terms of uses, locations, length of record storage, and who has\naccess to the data is all available online at the card website. There is part of the policy\nthat is not readily available to the public, which is the information regarding the Card\nAdvisory Council. This body meets quarterly to review and advise on current and\npotential policies regarding the MIT ID Card. Current members of the council include\nDan Michaud, Assistant Deans from several different offices, and representatives from\nthe Faculty, Graduate Student Council, the Undergraduate Association, MIT Campus\nPolice, MIT Enterprise Services, Athletics, Human Resources, Registrar's Office, Alumni\nAssociation, and MIT Libraries. Overall, the current policy has its strengths and\nweaknesses that will be discussed in depth below.\nPolicy Recommendations Summary\nThere are several major changes to policy that we recommend for the current and future\nMIT ID Card system. Our most urgent recommendation for the policy surrounding the\ncard is that those recommendations that can be implemented with the current system\ntechnology should be implemented as soon as possible. These recommendations include\nthe implementation of an auditing policy, and changes in who the gatekeepers are for the\naccess log.\nThe policy changes we recommend are:\n1. The creation of a stronger, more permanent Card Advisory and Oversight Board\n2. Approval of accesses to dormitory tracking info is now done by that dorm's\nhousemaster.\n3. Tracking and privacy policies must be made public and well known.\n4. Students are allowed access to their own tracking data, and are provided with a\ncopy of any of their data which is accessed by other parties.\n5. The entire process of accessing tracked data is audited by the MIT Audit Division.\n\nThere are several model laws and paradigms in place at the state and government level\nwhich regulate access to certain records and help to maintain the privacy of the public.\nThese include the Family Educational Rights and Privacy Act (FERPA), a federal statute,\nand the CORI Laws, state laws of the Commonwealth of Massachusetts.\nFERPA, also known as the Buckley Amendment, allows for students above the age of 18\nto access educational records kept by educational institutions. For post-secondary\ninformation, these rights to access are passed solely to the student if he or she is over 18\nyears of age. Students are entitled to view their educational records within 45 days of\nmaking such a request to the institution that keeps these records. Disclosures of\ninformation to third parties by the educational institution can be done only with student\nconsent with some important exceptions. These exceptions include disclosure of\ninformation without student consent to ``court subpoenas, requesting information, federal\naudit requests, law enforcement requests regarding missing students, and requests from\nhealth departmentsEappropriate parties in connection with a health or safety emergency if\nknowledge of the information is necessary to protect the health or safety of the student or\nother individuals.'' [20]\nThe FERPA laws apply to all public institutions and those private institutions which\nreceive public, including MIT. Much of the financial aid that students receive at MIT is\nthrough federal funding, and many of the research programs on campus are also funded\nby the government. According to Professor Arthur C. Smith and Danny Weitzner,\ntracking data that MIT records is considered to be educational data, and is subject to the\nguidelines of FERPA. MIT and the tracking data it maintains are then subject to the rules\nof FERPA because MIT is a partially government funded private educational institution.\nIn our policy recommendations, we will adhere to the guidelines that FERPA lays out for\nthe usage and disclosure of educational information.\nIn addition to the disclosure rules outlined in FERPA, we have strived to adhere to the\nFair Information Principles of the U.S. Department of Health, Education, and Welfare.\nThese five principles that guide the legislation enacted by these departments were\ndeveloped in response to the computerization of medical records and a desire to maintain\nthe privacy of the public in light of new technology. These principles are:\n1. Collection limitation.\no Data should not be collected on systems that are very secret. Students\nmust be aware of what systems are in place to record their educational\ninformation.\n2. Disclosure.\no There must be a way for an individual to find out what information about\nhim is in a record and how it is used. The system should allow for the full\ndisclosure of information to the student.\n3. Secondary usage.\no The individual must have a way to control the usage of his or her\neducational data beyond that of the collecting institution.\n4. Record correction.\nIntroduction\n\no If the information located in the record is incorrect, a student or family\nmember should have the right to have the correct changes made.\n5. Security.\n1. Any organization or other entity that uses data obtained from the MIT\nCard Office must be able to protect that information as well.\n2. One of the pertinent protections that must be offered is the protection\nagainst misuse of the data. This includes the student's rights to\nprivacy. [19] [21]\nThe CORI Laws are state laws intended to protect the privacy of those who have criminal\nrecords when those records are accessed by other parties. These are laws that MIT police\nmust follow when attempting to access anyone's criminal record for investigative\npurposes, and surely serve as a reminder of the kinds of privacy protections that students\nare entitled to in light of the protections guaranteed to those with criminal records. The\npenalty for non-compliance with the CORI laws is a $10,000 fine, or 1 year in prison for\noffending officers, according to Detective Jay Perault and Lieutenant Albert Pierce of the\nMIT Campus Police. The laws set an important and high standard for police actions when\naccessing the personal records of any person including the tracking data of students.\nBased on these principles and laws, it seems that much of the data that is recorded by the\ncurrent system falls subject to FERPA and should be that policy formulations should\nadhere to the Fair Information Principles, as they are national standards for privacy\nprotection. Tracking data is identifiable data in that card swipe data can be traced back to\nthe user of a card given the right records of id numbers. Although the state and federal\nrealms contain many laws concerning the protection of privacy, and accesses to state and\nfederal records, such rigorous processes do not exist within the confines of MIT. The\nfollowing policy and technology recommendations were created by taking the guiding\nprinciples and model laws from the state and federal domain into account. It is our goal\nthat the following recommendations, if adopted, would prevent theft and other crimes\nwhile preserving a high level of privacy protection. An attempt has also been made to\nkeep the policies as straightforward as possible so that they are accepted by the entire\ncommunity as logical and necessary policies and not as cumbersome processes designed\nto make simple tasks relatively difficult.\nTracking\nThe initial planned role of the MIT ID Card was to provide a secure method of restricting\naccess for a building to the correct individuals. When an individual wishes to enter a\nbuilding, he must present reliable identification to prove that he should have access to\nthat location. Access to a building varies on the desired population, as general campus\nareas are accessible to all MIT associated individuals, whereas individual departments\noften limit the access to their own members. Since the device that checks the user's card\nwill have to check the individual's identification to see if they have the correct\npermissions, the system has a choice of saving the information from this transaction.\nSaving this data is tracking at the most basic level. The questions arise of what\n\ninformation to save from a single transaction and at which locations this information\nshould be stored.\nWhen an ID card is scanned by a card reader, one of three things can happen: the reader\nidentifies the card as valid and grants permission to the specific location, the reader\nidentifies the card as valid but denies access to the particular door, or the reader fails to\nidentify the card as authentic. These different scenarios occur depending on the card\nowner's access privileges and if the reader is functioning correctly. If the user does not\nhave permission to enter and the reader is working correctly, the attempt is called a\ndenied entry. The second type of entry, where the reader is not working properly, is a\ntermed a failed attempt and does not depend on the status of the user. If the card owner\nhas permission to enter the building, the reader is working correctly, and the user is\nallowed in, the access is a successful one. These three types of attempts to enter create\nthree different categories of data that could be handled differently in recording.\nDenied Entries\nDenied entry data gives information of which people tried to unsuccessfully gain access\nto a certain location. If this happens, then the individual may be trying to enter where he\nactually should be allowed but the system for whatever reason is not granting access or\nwhere he thinks he should be allowed but does not in reality have permission. In the first\ncase the individual will most probably want to have the problem looked at if it happens\nrepeatedly. To properly analyze the problem, the data stored needs user identification. If\nthe data contains a specific identifier that lets the authorities know who was trying to gain\naccess and at what time, the authorities can look at this information and act accordingly.\nTo meet these motivations, if the database administrator is not able to identify the denied\nentry as belonging to the user, the user is not able to show a problem. If denied entries are\nrecorded into the database, the duration that they remain in the database should be long\nenough to provide ample amount of time to the user to visit the card administration for\nhelp. If the data is used to show problems in the system, then it is not disadvantageous to\nkeep the data for anytime greater than a few days.\nAnother use of recording denied entries is to monitor individuals trying to gain access\nwith ill-natured intentions. Depending upon how the specific tracking data is pinpointed\nin the database, the level of usefulness for crime investigation varies. If the Campus\nPolice are investigating a crime and find numerous denied entries in the record close to\nthe time of occurrence, the data could help the police find a potential suspect. On the\nother hand, if the Campus Police find the information ``accidentally'' while aimlessly\nlooking through data, then this would be a breach of students' privacy rights. According\nto Pierce and Perault of the MIT Campus Police, the data with a user identifier attached\nshould be stored for shorter periods of time to reduce the possibility of ``fishing'' for data.\nAdditionally, shorter periods of time would lessen the ability of the database\nadministrators to browse through data as a past time, since it would be there for less time.\nIf the Campus Police look through denied entry data randomly, the user identifier will\nhurt the privacy rights and a lack of identifier would therefore be preferable. However,\nthe privacy rights can only be upheld if there is an effective database access protocol,\n\nwhich will be discussed in the Database Access Section. If there is proper security of the\ndatabase and the administrators do not use it to ``fish'' for data, then the user identifier on\ndenied data is not a problem. The two cases have one key component that differs: the\nreasons of why the data administrator found the data.\nIn general, if denied entry data is stored with a user identifier, then it should only be\ninvestigated when there is a specific reason, such as a complaint from a card user of a\nsystem failure or a crime investigation. Assuming that the data access is properly\nrestricted, then denied entry data should be recorded at all locations.\nFailed Attempts\nFailed entries occur when a person tries to gain access to a building by using the card\nsystem, but the reader does not recognize the card as one in the system. In this case, the\nreader does not have any other data about the event, except the time and location that\nsome card failed to be read. A failed entry attempt would indicate either a broken reader\nor an outsider trying to gain access.\nIf there is a broken reader, then the record of failed entries would be extremely useful in\nfinding a problem. The system could keep track of the number of failed entries in a\ncertain location over a certain time period. If the number of failures exceeds a certain\nlimit, then a warning could be raised to the database administrator to warn of possible\ncard reader failures. A further discussion of a possible alert system appears in the Data\nAccess section later on.\nThe other possibility is an outsider attempting to break into a building on campus.\nHowever, a large number of failures at the same reader has higher chances of indicating,\nis a hardware system problem rather than an ill intentioned outsider. Regardless of the\ncause, the counter for number of failed entries would still be triggered in the case of an\noutsider and warn the database administrator of a possible problem.\nFailed entry data should be kept for a long enough period to allow the database\nadministrator to discover a problem. Hence, the data must be kept long enough such that\non a normal basis, if a card reader was not working at a certain location, then enough\nfailed attempts would accrue and warn the administrators of the database. Keeping this\ndata for too long does not pose a privacy threat, since it does not have any personal\ninformation identifiers, but rather only a time stamp and location.\nSuccessful Entries\nWhen a successful entry occurs, then the information of who entered what building at\nwhat time can be easily recorded into the database. This information can be very useful\nespecially for the purposes of a crime investigation or analysis of foot traffic through an\narea finding individuals that entered a building at a certain time.\n\nWhile considering solutions for fulfilling the above requirements, a few principles need\nto be kept in mind Ð campus security needs and individuals' privacy rights. The policy\ncreated needs to provide the optimal amount of data for use in a crime investigation. At\nthe same time, the recording of this data could infringe on the privacy rights of students,\nfaculty, and administration. Individuals with access to this data could potentially use it\nfor inappropriate reasons, such as monitoring the number of individuals of a certain\ndemographic that enter a building at a certain time or to track the whereabouts of a\ncertain person.\nDue to the possible contradicting goals, each potential solution will need to be evaluated\nin terms of how well it fits each motivation and in turn how well this fits the needs of the\ncampus. In particular, the policy of the successful entries in the tracking system focuses\non location of tracking and lifetime of records.\nLocations Tracked\nThe policy concerning which locations should be tracked can be in one of three: a\nuniform policy covering all entrances on campus, a blanket policy where nothing is\nrecorded, or only specific places are tracked. On one hand, if tracking data is collected, it\nwould obtain information that can be valuable for the Campus Police during\ninvestigations. On the other hand, if data is collected, there is the possibility of misuse of\nrecords, ``Big Brother'' theories, and overall privacy infringement concerns.\nAccording to Lieutenant Albert Pierce and Detective Jay Perault of the MIT Campus\nPolice, the data currently recorded by readers at building entrances is useful in their work,\nthough how it is used varies by case. In general, they were not able to inform us of how\nthe data is used or how frequently it is used due to the confidentiality of investigations.\nHowever, they did mention that the information is very useful in the cases of missing\nstudents, since the information helps to recreate where and when the individual has\nrecently been. The data garnered from tracking could be useful to prove an alibi of an\nindividual's location or to piece together information about a crime, such as witnesses or\nsuspects. The representatives of the Campus Police did mention that the tracking records\nmerely suggest possibilities, rather than using the data as stand alone evidence, that need\nto be verified in other ways. In relation to the privacy issue, a survey of the student\npopulation indicated that two thirds of the individuals were not opposed to tracking, if the\ndata was kept for a reasonable time period, if they were aware of it beforehand. In\nconclusion, tracking could occur without excessively infringing on privacy rights, if the\nlifetime of the records and access to the records, which will be discussed later, are\nproperly restricted.\nWhile tracking is important to the MIT Campus Police for investigation purposes, it can\npossibly jeopardize individuals' privacy rights. The stored data could be looked at by\nauthorized individuals, but for inappropriate reasons. Authorities could look through the\ndata for entertainment or look specifically at people of a certain demographic. These\npossible misuses hurt the principal of student privacy rights that should be upheld.\nTherefore, tracking at any locations would be possibly harmful to privacy rights.\n\nFurthermore, the tracking data is not always helpful for solving crimes. For example,\ncurrently, according to Lissa Natkin, the Assistant Director of CSAIL, most thefts from\nCSAIL occur during hours when the card is not needed for entrance. This fact indicates\nthat there are problems in the security system of the building and not a result of a\nproblem in the current card system. Therefore the tracking could not have helped solve\nthese crimes. Though this may be a more specialized case, it shows that while the\ntracking records do offer the possibility of greater security and investigative power,\ntracking and investigative power do not always correlate.\nAnother possibility is to track only at specific locations, especially where more expensive\ncrimes can occur and the privacy rights are not as problematic. Laboratory areas with\nexpensive equipment would not have the same sort of privacy rights associated with them\nas more personal spaces such as dormitories. In this way, tracking could vary throughout\nthe campus depending upon need.\nAccording to Lieutenant Pierce and Detective Perault of the MIT Campus Police, theft is\na big problem at MIT since the members of campus are very trusting of others and do not\nalways lock up their possessions. Theft is a bigger problem in dorms, where students\noften leave their doors unlocked, and in labs, where there is very expensive equipment.\nTo this end, tracking could be helpful in assisting in crime investigations and should be\nperformed in dormitories and laboratories.\nAs Former Dean of Harvard College Harry Lewis suggested, this scheme presents a few\nproblems. It would lose some of its potential use and be more complicated than a uniform\npolicy. Professor Lewis pointed out that individuals on campus should be fully aware of\nthe policy and would then be more likely to approve it if it is simple and the same for all\nlocations. However, the proposed policy is simple enough such that individuals can easily\nremember it and if the policy did get more complicated, then some sort of picture icon\ncould be placed next to each reader that tracks the card swipes.\nLifetime of Data Record\nThe data recorded by the system when a card is read can be kept for a variable amount of\ntime Ð never, eternally, or a limited amount. The different lengths of time would provide\ndifferent amount of utility to the police force as an investigative tool and still protect\nprivacy rights. Not recording any data would be the same as tracking at no locations,\nwhich hurts the police from gathering possibly valuable information about future crimes\nbut at the same time protects privacy rights. This issue was evaluated above in the same\nregard as not performing any tracking, which was decided to not be optimal for security\nreasons.\nOn the other hand, if the data is kept eternally in the database, then the police would be\nable to utilize the information maximally. If they needed information on who was at a\ncertain location at a certain day and time, it would be useful to simply look at the records\nas a starting point. The Campus Police expressed the important role that the tracking data\nis able to hold in investigations. For police utilization, the data should be recorded and\n\nkept. However, if the records are kept indefinitely, then the problem of inappropriate\nusage becomes more severe. If authorities have access to unlimited amounts of tracking\ndata, then it is a privacy threat. Individuals may fear that the people holding these records\ncould use it for ``Big Brother'' type of activities. While eternal recording of data could be\nmore useful to police, it threatens to infringe on the privacy rights of individuals.\nIf the record was kept for a limited amount of time, then a balance could be reached such\nthat all of the principles of security and privacy were optimally upheld. The longer time\nperiod allows for better utilization of the records on the part of the Campus Police. But\nthe shorter time period helps protect the students' rights for privacy. Lieutenant Pierce\nand Detective Perault of the MIT Campus Police explained in an interview that the\ncurrent limit of two weeks was set such that it prevented authorities from ``fishing for\ndata'' or monitoring an individual's records without specific reason. Student opinions\nfrom the survey showed that most individuals were comfortable with the current policy of\nholding the data for 2 weeks. It also showed that these one third felt unfavorably towards\ntracking was because of the amount of time that the data would be stored and these\nindividuals were in favor of keeping the data between two and seven days. However, this\nshort of a time period would probably drastically decrease the value of the records to the\nCampus Police. Therefore, the recommendation is to keep the data for a two week period.\nPublic Awareness of Policy\nThe policies regarding tracking can only be fully utilized if these policies are known to\nthe entire campus. The student survey showed that 73% of students were not aware of the\ncurrent tracking policy and this lack of knowledge was one reason that they did not like\nthe policy. This should not be the case, because everybody involved has the right to know\nwhat the policies are and how they work.\nThere are a few ways of implementing the policy such that all of the members of campus\nwill be aware of the policy and be able to find it when necessary. The members of\ncampus should be aware of the policy from the time that they arrive. One way is to give\nout a flier in the welcome packet when a new student, faculty, or administrator joins the\ncampus. This will help make all individuals aware of the policy. However, a person may\nlose it during their years at MIT. For this reason, the policy needs to be available by some\nother route, like the web. The web would make the information easily accessible to\ncampus members at any point in time. Public awareness of the policy is important to help\nprotect privacy rights of people on campus.\n\nAccess to the Tracking Database\nAnother important feature of the tracking database is the process by which tracked door\nentry data is accessed. The entire system is vulnerable, if the two key procedures to keep\ntracking data secure are not met. The data access protocol decides who can access what\ndata and by what procedure. A secure access protocol needs to be strict enough such that\n\nit enforces the policies regarding tracking location and the lifetime of the record, while\nstill allowing for efficient and convenient use for investigative purposes. If a tightly\nsecure access system is not created and implemented, then the privacy rights of\nindividuals are vulnerable and there should be no tracking of entries at all.\nAn efficient access protocol should be created, while still trying to uphold the keystone\nprinciples, particularly, protection of student privacy rights and efficiency of investigative\nsecurity tools. Access paths should be created only when there is a specific reason. If the\ntracking data is accessed by unauthorized individuals, then there could be numerous\nsecurity issues and the privacy of the students would be compromised. Deciding which\nindividuals should have access to which types of information and how they access it\ndepends upon their role on campus.\nAnonymous Data\nTracking data information is useful for numerous reasons, including police criminal\ninvestigation, system checks by the card office, solving individual student card issues,\nand general traffic data. Some of these motivations, specifically some system checks and\ntraffic information, do not require that the analyst be aware of the card holder's identity. It\nwould be useful, however, to know the type of entry, the location, and the time. To\nreiterate, if unneeded identity information is given to the individual that views the data,\nthen it will greatly increase the chance that the data use will infringe upon the card user's\nprivacy rights. Therefore, for those parties for whom anonymous data is adequate, it\nshould be easily accessible.\nFacilities\nThe tracking of ID cards can be useful for facilities to learn about the traffic patterns in\ncertain buildings. This data can be useful for a department to figure out cleaning\nschedules, estimated amounts of traffic, and other such information from data regarding\nthe number of people that accessed a building by using a card reader. This information,\nhowever only requires knowing how many people used the reader and at what time. It\ndoes not require any other sort of demographics, such as sex, race, or class. Any extra\ninformation that is given, but is not pertinent to performing the project at hand, could\nperhaps lead to misuse of data. For this reason, it would be better if this anonymous data\nthat was completely stripped of all identification data was available to facilities.\nOn the other hand, this data could potentially be used for supervisory purposes. For\nexample, suppose a worker is supposed to be at his job at some exact time and other\npeople very rarely enter this building around that time. If the anonymous tracking data is\navailable to the facilities head of a lab and subsequently the boss of the worker, the boss\nmight be able to tell exactly when the employee arrives to the work location. The card\ntracking system should not be used for these purposes. Very precise information\nregarding the number of individuals that entered at a certain location at a certain time is\nunnecessary to the purpose of analyzing traffic data.\n\nYet, this anonymous tracking information could be helpful to the facilities department in\ntheir work. Calculations could be made from this data such that it has lower resolution.\nFor example, one way to lessen the precision of the tracking information is for facilities\nto specify a twelve hour period of the day. The data for this twelve hour period is\naveraged for the last two weeks and then rounded up or down to the nearest integer\nperson per twelve hour period. This type of formula would make it harder for a third\nparty to make stipulations regarding the whereabouts of specific individuals, which\nprotects the privacy rights of the card users, but at the same time, it helps illustrate the\ntraffic patterns in a certain location.\nCard Office\nThe main function of the Card Office is maintenance of the card system, which includes\nproper functioning of all of the readers and successful access to the correct locations for\nindividual card holders. The employees of the office need information to pinpoint broken\nreaders. For example, if a reader is not functioning properly in a certain building, the\nproblem will not be found until the office is alerted by an individual that tries\nunsuccessfully to gain access at this location and calls the office to let them know of the\nfailure. Then one of the Card Office employees that have access to this data can find the\ninformation. Since viewing the information is currently not restricted, the employees\ncould look at other recorded data while looking for something specific. This presents\nanother possible situation of infringement of privacy rights.\nThe worker at the Card Office should be able to use his own computer to check how\nmany failures have occurred or if there have been any successful entries in the past few\nhours. The workers of the Card Office are supposed to make sure that the system is\nrunning properly. This does not necessitate the worker knowing the identification of the\ncard users unless it is in regards to a specific individual card holder. In this case, the\nstudent, faculty, or administrator would be present at the Card Office and could give\npermissions to the employee to view his or her account at the time of trouble shooting.\nMore information on student access rights is in the later Student Access section of\nPersonal Data. The Card Office employees can fulfill this role with regular access to\nanonymous tracking data.\nFurthermore, there are certain card trouble-shooting situations where other solutions\ncould also provide quicker solutions. When a reader to an entry is broken, then\nattempting to use a valid card may result in a failed entry. If the reader remains broken,\nthen more individuals will attempt to use the reader to gain access and more failed\nattempts will occur. The database is already recording these failed attempts, so the\ninformation should be used. An automatic counter is recommended that alerts the\nmaintenance team when a broken reader is suspected. The automatic nature is important\nin that if the system is able to check these possibilities internally, then there is no human\ncontact or possibility of privacy rights infringement. This counter could base its alert\nsystem on the proportion of failed entries versus successful ones or the number of failed\nentries that have occurred over a set period of time. Setting these tolerances at reasonable\nvalues will quicken the process of pinpointing and fixing broken readers, while not\n\nencouraging Card Office employees to casually search through campus members'\npersonal tracking data.\nPersonal Data\nAll data that contains a user identifier in the tracking record is limited to successful and\ndenied entries. The user identifier is the major reason that tracking poses such a huge\nthreat to personal privacy rights. While the personal identifier does pose a threat, it is also\nessential part that allows the tracking data to meet the motivations. This personal data\nhelps to pinpoint any problems regarding an individual campus member's card,\ninvestigate crimes, and allow for easy missing person checks.\nWhile considering these possibilities, only one gatekeeper of certain information should\nbe picked. A second gatekeeper would add a layer of security to the system, but it will\nalso make the system more inefficient. The second gatekeeper would need to be an\nindividual on campus that has student's interests in mind, such as faculty members or\ndeans. Deans, for example, work on a daily basis on confidential student matters.\nHowever, the police may need data quickly for a time sensitive issue and making it\nmandatory that one of these individuals be present for any data access would slow down\nthe process greatly. A quicker and more efficient option is to rely partially on an efficient\nauditing system, designs of which will be further discussed in the Auditing section below.\nIf there is only one gatekeeper and a good auditing system, the security still remains\nintact and efficiency high.\nStudent Access\nStudents may need to demonstrate to the Card Office that they are experiencing a\nparticular problem with the functioning of their card. Currently, when there is a problem\nof this sort, then one of the three employees with access will look up the information and\nact accordingly. With the current recommended architecture all Card Office employees\nexcept for the head have the permissions to only access the anonymous data. With this\nsetup, students should have access to their own information. If the students hold the\nprivileges to their own account, their privacy is protected the best. On the other hand, if\ndesk workers at the Card Office have access to this information, it would be easy to track\na student and follow the student's routes. Furthermore, if the student realizes that they can\naccess their own data and the desk worker cannot, the students will trust the system more\nto uphold their privacy rights. The easiest authentication method for students would be to\nrequire entry of their Kerberos username and password. The Kerberos password is\nalready secure enough to do other transactions that require privacy and it is already in\nplace. The student being able to access their own information is important to protect\nprivacy and maintain any principals that were put into place from all of the other sides of\npolicy.\nOne reason that we have to provide information to students is that it counts as educational\ndata. This kind of information must be provided to students under the Family Education\nRights and Privacy Act (FERPA). There are a few ways to provide this information in an\n\neasily accessible, but in a secure and efficient way. One possibility is to offer it on\nWebsis, where private academic and financial information is stored for students to view.\nThe Websis system is fairly safe and reliable, as the campus trusts it to store their other\npersonal information. It is also easily accessible from anywhere, as long as the user has a\npersonal certificate. However, setting up the system on Websis requires a data system\nthat will update the system regularly and for the entire database to be on the web.\nLimiting the data to one computer in the Card Office will make it more secure and less\neasily obtainable by an outside third party. While having this information on Websis\nwould be a novelty, it is not really necessary. Most students will need this information\nmore often for solving problems associated with the card, for which they would need to\nvisit the Card Office anyways. If students are interested in viewing their records, they\nshould be able to visit the Card Office. Having student records accessible to the\nindividual at the Card Office would ensure security of the information and meet the\nrequirements of FERPA.\nOne of the additional provisions for student privacy protection is that students will be\nprovided with a copy of their data if their data is specifically requested for any reason.\nThis policy has been adopted by Harvard University, and we feel that students should be\nentitled to know when their personal records have been requested. Such a procedure\nfollows in the spirit of disclosure, one of the Fair Use Principals, and the disclosure\nguidelines of FERPA.\nCampus Police\nThe Campus Police find tracking data valuable in investigations, as was noted earlier. If\nthey do not have access to the data, then the security importance of the tracking is not\nfulfilled. Therefore, the Campus Police should definitely have access to tracking data in\nsome way or form. The Campus Police currently gain access to the data by requesting it\nfrom the head of the Card Office and putting it into the case file for storage. This system\nrestricts the power that the police would have if they have full access to the database.\nAccording to Lieutenant Pierce and Detective Perault of the MIT Campus Police, the\ncurrent system is flexible to the time constraints of an investigation, as they are usually\nable to get the data within a day and even sooner if needed. Furthermore, they noted that\nif the Campus Police need the information and the two week storage period is almost\nending, then the Card Office can save it for the police until the paper work is completed.\nOn the other hand, more police power could be useful in cases where there is extreme\ntime sensitivity. The information as an investigative tool is one of the key motivations of\ntracking. Police are supposed to uphold citizen's rights, as according to Pierce and Perault,\nthey face a $10,000 fine and a year of jail time if they violate any of the privacy laws.\nThe police are aware of the consequences of invading an individual's privacy and already\ndeal with this on an everyday basis. Speeding up crime investigation is a strong reason to\nmake the police as the gatekeeper of the data and there is also already infrastructure in\nplace to hold them responsible for upholding privacy rights. However, the police's\ndomain should be limited when it comes to dormitories, which should be part of the\nhousemaster's, as discussed below.\n\nHousemasters\nPolice have the permissions to view student and faculty tracking information. However,\nprivacy rights need to be protected more in the dormitories and for this reason there needs\nto be an extra precaution to protect the dormitory tracking data. Larry Benedict, Dean of\nStudent Life, suggested that the housemaster of a dorm should have access to his or her\ndorm's tracking information. The housemaster of a dorm is supposed to be one of the key\nindividuals involved in a student's life, especially when there are any problems. Current\nMIT policy specifies that housemasters ``should be knowledgeable about the resources\nthat exist at MIT for responding to crises and should be quick to call upon them when\nneeded.'' [24]\nNumerous duties of the housemaster require that the housemaster maintain the student's\nprivacy rights and act in the student's interest, including representing the student in front\nof the Dean's office. For these reasons, the housemaster is a good choice as the\ngatekeeper for their own dormitory records. The housemaster should need to agree to any\npolice accesses of tracking entry data from that housemaster's dormitory.\nHousemasters deal with numerous crises that they need to investigate themselves.\nAccording to Julian Wheatley, the housemaster of East Campus, most housemasters\nprefer keeping these type of investigations internal so that they can still hold control,\nrather than making the information external. For the motivation of internal house\ninvestigations, Wheatley was in favor of housemasters being the gatekeeper for dormitory\ninformation, especially in the case of a possible missing person case. Under this\nrecommendation, housemasters can at any time access data regarding their own\ndormitory at the Card Office, where the data is stored.\nSince the data will be centralized in a certain location and not be placed online, the\nhousemaster will need to visit the office to view data. There should be a secure\nauthentication process for login, for which the Kerberos system can be used. The\nhousemasters have two roles for taking care of student data: they can view the data to\ninvestigate internal house matters and they need to act as the gatekeeper for the data\nanytime someone else wants access to it, especially the Campus Police.\nMiscellaneous\nAny other individual on or off campus should not usually need access to the tracking data.\nAgain, if access to the data is too easy, then the privacy rights of the students and faculty\nare at risk. However, if any other party does need information, such as outside\ngovernment agencies, then they could be directed through the Campus Police. One\npossibility is through the Campus Police, which would make sense due to the hierarchical\nnature of the jurisdictions. The current policy for outside government agencies is that\nthey need a subpoena for any information, according to Pierce and Perault of the MIT\nCampus Police. However, these individuals also mentioned that requests from other\ngroups are usually rejected unless it's a criminal investigation. If any one on campus has a\nreason that they want to access the data, they can go through one of two channels: the\n\nCampus Police or the Housemasters. Which group an individual approaches should\ndepend upon the type of concern.\nLocation of Database\nIt will be easiest to have one central database that holds both the anonymous and personal\ndata. The location of the database is important such that it is central for all of the groups\nthat we are giving access to and such that it does not burden the holder. In terms of\nfrequency of usage, the Card Office employees will use it regularly to troubleshoot the\nsystem, whereas the Campus Police will use it rarely for investigations. However, in\nterms of urgency, the Campus Police will need access as quickly as possible for\ninvestigation. On the plus side, placing the database in the Card Office would add another\nbarrier that would deter the Campus Police from making random accesses of data or\nleaving the computer logged in during the entire day to allow other people to use it. No\nindividual at the Card Office has the permissions to view the private tracking data, so\nCard Office employees browsing aimlessly through data would not be problem. Overall,\nthe best location for the database in accordance with the rest of this policy is in the Card\nOffice. One issue that could arise with the Card Office hosting the database is that it is\nonly open during normal business hours. Yet, there are situations that would require the\ndata as quick as possible, even on the weekends. If the reason is an extreme emergency,\nthe police could potentially gain access to the Card Office, even when it is closed. This\nwould enable necessary accesses to the database to occur, even though the Card Office is\nnot always open.\nCard Policy Making and Reviewing Bodies\nOne of the recommendations of this report is to expand and strengthen the mandate of the\ncurrent Card Advisory Council, and to rename the council the Card Advisory and\nOversight Counsel. In formulating this recommendation, we considered information\ngathered from interviews with current members of the Card Advisory Council, and\nmembers of past versions of the same committee, and combined our findings with our\nown concerns, and those of other users of the MIT ID Card.\nThe Card Advisory Council\nOne of the main functions of the Card Advisory Council is to formulate policy\nrecommendations for the card, devise new uses for the card, and in general to think about\nthe implications of card use for the entire MIT community. Members of the card council\nrepresent the different sub communities within MIT and include those who are directly\ninvolved with the function of the card as well. Current members include representatives\nfrom the Faculty, Graduate Student Council, the Undergraduate Association, MIT\nCampus Police, John McDonald Ð from MIT Enterprise Services, Assistant Deans from\nseveral different offices, representatives from Athletics, Human Resources, Registrar's\nOffice, Alumni Association, and MIT Libraries and Dan Michaud Ð Manager of the MIT\nCard Office and current chairperson of the Card Advisory Council.\n\nOne of the main problems with the current committee is that although there are ostensibly\nmembers from all parts of the MIT community on the council, not everyone is always\npresent at the meetings. Most importantly, undergraduate attendance at these meetings is\nrelatively low, as it is across many institute committees with undergraduate\nrepresentatives. Low attendance by undergraduate representatives is problematic because\nundergraduates make up a large portion of the MIT community and should have\nproportional representation on the committee. If undergraduate representation at the\npolicy reviews meetings is low, then the policy recommendations and reviews will\nprobably not accurately the undergraduate interests as well. As demonstrated by our\nsurvey of the student body, there is widespread ignorance of the card and its policies. For\nsuch a large portion of the community to be completely ignorant of these policies is\nintuitively disturbing.\nThe Council's main function at present is only to review changes and additions to the\nMIT Card policies; it does not currently have any power to make decisions. Herein lies\nanother flaw with the construction of the current council. These policy discussions and\nreviews are nothing if they don't have the power to actually enforce any of those\nrecommendations. One way to understand why the lack of decision making power of the\ncouncil is problematic is to imagine the function and purpose of congress without\nlawmaking powers: Congress would exist to discuss and review the policies and laws of\nthe administration, but would not have any power to change those policies. The actual\nlaws would be completely controlled by the administration, and there would be no way to\nensure that the laws took into account the interests of all the people the law would apply\nto. This is the case with the current council: It meets to discuss policies of the card, and\nhow those policies might affect the MIT community, but they have no power to enforce\nany of those policies, or to make sure that the policies in place really look out for the\ninterests of the groups they represent.\nWhen the tracking function of the MIT ID Card system was turned on in 2002,\nrecommendations of previous card advisory committees were disregarded. Previous\nincarnations of the Card Advisory Council had decided that maintaining records of\nsuccessful card accesses was undesirable. It is unclear how much effort was made to\nmake sure the tracking policy was acceptable to the entire community. From information\ngathered from John McDonald, Associate Director of Enterprise Services, it seems that\nthe change was made to accommodate labs and offices on campus that wanted local\naccess control, access to audit logs, and RFID technology. The accommodation was made\nto help bring more labs and offices under the card office umbrella to improve\nconvenience for the labs.\nIt was assumed that this change in tracking policy was generally desired by the entire\nMIT community when in fact a large portion of the community Ð the student population\nÐ had no knowledge of the feature until an article in The Tech described the launch of\nthe tracking policy some 6 months afterwards. This change in system operation flew in\nthe face of previous policy decisions to not keep record of card access. A policy review\nof the change in tracking was never conducted at this time. This seems to have been a\nmajor breakdown in the way that these processes were ostensibly supposed to work. Such\n\na decision which affects all users on campus should have been approved by the\nrepresentative committeeNthe care advisory council.\nDespite the inabilities of the council to effectively steer policy, the Card Council does\nhave some very important merits. According to Hector Hernandez, a recent addition to\nthe Card Advisory Council, the committee is composed of all the right players.\nDiscussions between members of the council are genuine roundtable discussions in which\nno person's opinion is more important than another member's, and the discussions that\noccur at meetings are fruitful ones in which many important issues are discussed.\nMany of the members are highly cognizant of the implications that the card's functions\nhave for privacy; some members of the council, such as Hector Hernandez, are on the\ncouncil because of a strong interest in the larger privacy and security concerns\nsurrounding the card.\nCard Advisory and Oversight Board\nWe recommend the creation of a new, more powerful council that will serve as a policy\ncreation and oversight board, named the Card Advisory and Oversight Board (CAOB)\nwhich will replace the current Card Advisory Council. They will help to create the\npolicies to be employed by the MIT ID Card system, and also to be responsible for\nenforcing the policies of the system in much the same fashion as other Institute\ncommittees act. As new technologies are developed and new methods of providing ID\nservices are introduced, the policies of how card information is handled will need to be\nchanged. It is important to have a policy-making board with the MIT community's\ninterests in mind in place to handle these changes as they arise. This board must also find\nnew uses and efficiencies for the card in order to use its strengths to provide better\nservice to card users. Policies approved by this council, which will have the same\nrepresentative makeup as the current Card Advisory Council, will be enforced after\napproval by the administration.\nThe CAOB will be in charge of dealing with all other problems that may arise as a result\nof keeping tracking information. One such situation that is likely to arise is when 3rd\nparties subpoena the tracking information, perhaps in relation to a criminal investigation.\nThird parties may want to serve the subpoena to anyone with access to the data. For\nexample, the state police might serve the manager of the card office with a subpoena for\ntracking information. At this point, the card manager has two options according to Hal\nAbelson, a professor at MIT who has previously received a subpoena for information: He\ncan consult directly with MIT general counsel to determine whether or not he must\ncomply with the subpoena and provide the information, or he can pass the subpoena on to\nsome other authority to consult general counsel. Our recommendation in this situation is\nto pass the subpoena up to the card advisory council to handle compliance issues with the\nsubpoena. The CAOB will be in charge of consulting MIT general counsel about whether\nor not they must comply with the subpoena. If general counsel advises the CAOB to\ncomply with the subpoena, then the CAOB will provide the requested data to the party\nserving the subpoena.\n\nIt seems that it is important to at least make the committee carry more weight, and to use\nthis weight to get its proposed policies approved and implemented. One requirement for\nthis is to make the committee more permanent and less easily dissolved. In the past,\nCommittees on Privacy seemed to be formed whenever privacy concerning the card was\na salient issue in the community. By making the Card Advisory and Oversight Council a\nstronger Institute committee, we can ensure the continuity of the committee. Over the\npast several years, card committees, and privacy committees, other various committees\nhave been formed and dissolved. In the process of forming and dissolving committees,\nmuch of the accumulated knowledge seems to have been lost and is difficult to find\nunless one speaks with former members of those committees, who may not remember all\nof the discussions and findings in the desired detail. When interest in the topic died, or\nthe current issues were resolved, the privacy committees disbanded, or discontinued. Our\nrecommendation entails making the Committee a more permanent institute committee so\nthat issues of security, privacy, and the MIT ID Card can be dealt with proactively and\ncounter problems before they become widespread.\nIn the event that dissolution of the CAOB can not be prevented, a process for dissolution\nshould be followed. This process should ensure that the findings and the policies of the\ncommittee are kept intact and archived for future use, when the Council might be\nreincarnated.\n\nAuditing\nThis section describes the auditing mechanism we feel is necessary to protect against\nabuse of data collected by the MIT ID Card system.\nAudit Mechanism\nOne of the most important parts of a policy recommendation is the creation of a\nmechanism for enforcement of the policy. Although the people currently responsible for\nadministering the system and granting access to data are reputable people, there is no way\nto guarantee that future office holders will be as trustworthy. There must be a system in\nplace to monitor accesses and other transactions to ensure proper use, and to also hold\naccountable those who misuse the system. Without the threat of enforcement, the act of\naccessing data logs without authorization would seem like less of an offense. Most people\nwould think that the greater the penalty associated with a particular action, the more\nunacceptable and wrong that action is considered to be.\nPossible misuses of the tracking data include discriminatory, supervisory, and random\ntracking. Discriminatory tracking would entail the distillation of entry/exit data of\ndifferent groups on campus. Supervisory tracking is the tracking of employees by their\nsuperiors to aid in enforcing employment rules and regulations. Random tracking is more\nof a voyeuristic activity that people might engage in just to see whose card is being used\nwhere. Random tracking might also include stalking. Additionally, it is important not to\n\ngive just one party complete access to the data as this party could abuse its power, even\nwith accountability mechanisms in place. Auditing procedures will prevent parties from\nillegally accessing data and/or altering data without proper consent. Auditing also ensures\nthat data is only being used in accordance with the principles under which access data\nwas being collected in the first place.\nIn reality, though the current policy requires that all requests for card tracking data be\napproved by the chief of police, many accesses to the data occur without ever coming to\nthe attention of the MIT Campus police chief. Additionally, there is no written audit\npolicy, nor evidence of a mechanism used to audit the practices of the MIT Card Office,\nand other MIT ID Card activities. It is these unauthorized accesses which we intend to\ncurtail, and nebulous policies that we hope to define more precisely.\nNeeds for Auditing System\nWe recommend a system that creates a log file of all accesses to entry and exit data at the\ncentral Card Office database, as well as a corresponding procedure to review these logs\nand hold accountable those who deviate from the official policy. The entire auditing\nprocess will contain a series of checks and balances that will not burden those who carry\nthe responsibility, but will still provide a high level of privacy protection for members of\nthe MIT community.\nThe technical design of the log of data accesses will be discussed in later sections. Rather\nthan logging accesses to data manually, the new system will log them automatically to\nfurther streamline the audit process. Currently, there is no real system in existence for\nauditing all accesses to the tracking databases. Although the current policy stipulates that\nthe Chief of MIT Campus Police must sign off on all requests to use student data, there\nhave been many instances of accesses to the database that have occurred without the\nproper authorization. Additionally, there seems to be no real record of when such\naccesses have occurred; the closest semblance to a database access log is a manually\nmaintained log of such accesses.\nWhile protecting the privacy of individuals by including an audit process in data access\nprocedure, we would still like to preserve the speed at which data can be accessed when\nnecessary. The purpose of the tracked data is to aid in maintaining security on campus,\nand the auditing process should not impede this goal as much as it should aid in ensuring\nthat this goal is effectively and efficiently achieved.\nInformation Stored for Auditing\nThe information stored in the proposed access logs needs not be extremely detailed. The\nthree main pieces of information that need to be recorded for each access are the identity\nof the user who is accessing the database, when the access occurred, and a description of\nwhat information was accessed. As discussed later in the technical system description,\nthis can be accomplished by recording username, timestamp, and database query\ncommands used.\n\nFirst, record of the username will allow for auditors to know exactly who was responsible\nfor accessing certain data, and who to hold accountable in case of any deviations from\npolicy. Auditors will also need the timestamp and knowledge of what data was accessed\nin order to determination whether or not a violation of policy occurred.\nAuditing and Those With Access\nAccording to Professor Joseph Ferreira, users of the logged data should be aware of the\nexistence of an audit trail. If a person accesses the tracking data at any point, he should\nhave notification or other knowledge that his operations within the database are recorded\nfor auditing purposes. Knowledge of the existence of such a process would be enough of\na deterrence to prevent many from misusing the data, simply from fear of repercussion. If\na party is to access data, that party should also be aware of what sorts of permissions it\nhas to access the data, and why it has those permissions. These disclosures can oftentimes\nbe a deterrent to those who might have unknowingly attempted to access the ID card\ndatabase. Currently, someone can access the tracked data without knowing exactly what\nhis or her level of access permission is. Professor Ferreira also believes that it is\nnecessary for users of the card database to be aware of the different levels of permission,\nthe different rationales regarding the levels, and what level they possess. This awareness\nwill create a sense among users of certain responsibilities they have when accessing such\ndata, and will also act as an enforcement mechanism for policies that are intended to\noptimize privacy and security.\nAlong the same vein of responsibility among users, those who are auditing the system\nshould have a vested interest in providing a quality auditing procedure to ensure that\nauditing is carried out properly. If the auditing process breaks down, then so does the\nintegrity of the privacy protection built into the system.\nOne key question which arises in formulating an auditing policy is the designation of an\nauditing authority. We recognize that auditing the card access procedure with an outside\nauditing source could be costly, and that costs are one of the main limiting factors to the\nMIT ID Card system overall. However, the risks to privacy that misuse of tracking\ninformation poses are so great as to justify the additional costs of auditing the entire\nprocedure. One of the main requirements of our policy, supported by undergraduates and\nother members of the community is that tracking information should only be kept if there\nis an auditing or procedure in place to ensure that the data collected is not misused.\nGuaranteeing that the data is not misused also means that all accesses to the data follow\nthe procedures outline in our policy recommendations. Without such checks and balances\nin place, it would be impossible to prevent misuse of the tracking information from going\nundetected.\nThere are several options for which on or off campus entity should have the authority to\nresponsibly audit card data access logs. This entity should be a trustworthy, on campus\nbody with a vested interest in the card, and with a concern from privacy of card users.\n\nAccording to Professor Arthur C. Smith, one of the first members of the MIT community\nto head a privacy committee at MIT, it is better to keep faculty in charge of many of the\nfunctions of card oversight. The primary reason to do so is that they are by far the most\npermanent members of the MIT community. Students, the MIT police force, and other\noffices on campus have very large rates of turnover, relative to the turnover in faculty.\nBecause of low turnover among faculty, putting a faculty member in charge of auditing\ncreates a position of influence for a faculty member who has an interest in maintaining\nrights on campus, and who will maintain that position for many years; another method of\npreserving institutional memory.\nAuditors\nAuditing of the card access logs is one of the most important procedures in the card\nsystem as it adds a net of accountability to force all those involved with the card to\ncomply with procedure. We have two options for entities who will actually conduct the\naudit. The first option is some combination of faculty, staff, and students, and the second\noption is to give the auditing work to the MIT Audit Office.\nThe first office that comes to mind as a potential auditor is the card office itself. One of\nthe primary reasons for instituting and auditing policy is to ensure that the card office\nfollows the policies and procedures to which it is subject. It is not feasible to allow this\noffice to audit itself, as it would be inclined to find as little fault with its actions as\npossible. Also, audits should be conducted by an outside source that will not be biased in\nits findings.\nAnother option for auditing is to give this responsibility to enterprise services, the office\nwhich oversees the card office. Because this is the office which oversees the function of\nthe card office, it would be one of the more logical choices for an auditing authority.\nAdditionally, because enterprise services is the office in charge of dealings with outside\nvendors, they would also be able to use their access powers to perform system checks,\nand to make sure that the system was performing as promised by the vendor.\nCampus police, which is responsible for approving accesses to student information,\nwould most certainly be responsible in performing audit checks. In conducting criminal\ninvestigations, the MIT police are required to follow strict rules and regulations when\naccessing personal records, as regulated by the CORI laws. However, like the Card\nOffice, the Campus Police would then be auditing many of their own actions.\nThe more practical yet costly solution to auditing is to hire a third-party auditing agency\nto review the access logs to make sure that policies and procedures are being followed by\nparties involved in card data access operations. One such third-party is the MIT Audit\nDivision. MIT's Audit Division is an in-house office that can be used as an auditing\nresource for the tracking data access process. MIT Audit is an internal auditing office that\nperforms audits and reviews for labs, departments, and centers across the Institute. The\nassessments performed by this office include reviews of compliance with Institute,\nfinancial, operational and information technology policies and procedures. Additionally,\n\nMIT Audit will provide follow up assessments of offices they have audited to make sure\nthat any necessary changes that were needed to be made were made and that the changes\nwere effective in remedying the problems they were intended to solve.\n\nExisting Access Technologies\nIn this section, we give an overview of some of the major technology options available\nfor ID card systems. One method of classification of the different technologies is\naccording to whether the card is a contact card or a contactless card. Contact cards\nprimarily in use are magnetic strip cards and contact smartcards. Among contactless\ncards, the two most popular options are contactless smartcards and proximity cards. In\nthe discussion below, the different types of cards are described in detail according to the\ntechnology that they use: Magnetic strip, RFID, or smartcard.\nMagnetic strip\nA magnetic strip is a plastic-like film containing tiny iron-based magnetic particles on the\nback of many transaction and access cards. The strips are written by magnetizing the\nparticles in the required orientation. There are three tracks (each 0.11 inches wide) on the\nstrip. According to the ISO/IEC 7811 standard, the tracks contain information as\ndescribed in table 5.1.\n\nTable 1: The tracks of a magnetic strip\nTrack Bits per inch (bpi)\nNumber of Characters\n79 six-bit plus parity bit (read-only)\n40 four-bit plus parity bit\n107 four-bit plus parity bit\n\nUsually only tracks 1 and 2 are used. On track 1, either of two formats may be used.\nFormat A is proprietary use by the card issuer. Format B is a standard representation as\nshown in table 5.1. Table 5.1 also shows the standard format that is used for Track 2.\n\nStart sentinel\nFormat code=``B''\n-\nPrimary ID number\nless than 20\nless than 20\nSeparator\nCountry code\nName\n2-26\n-\nSeparator\n-\nExpiration date or separator\n4 or 1\n4 or 1\nDiscretionary data\nremaining\n(to add up to 79)\nremaining\n(to add up to 40)\nEnd sentinel\n-\nLongitudinal Redundancy Check (LRC)\n\nMagnetic strip technology is mainly used for transaction processing and access control.\nThe strips come in two main varieties: High Coercivity (HiCo) and Low Coercivity\n(LowCo).12 HiCo provides highest protection against damage by magnetic fields, but it is\nharder to encode due to the higher power required to encode it. Most cards that are used\nfor access control are HiCo, so as to provide greater protection against accidental\nmodification and to survive repeated use.\nRadio Frequency Identification\nRadio frequency identification (RFID) [11] technology comprises two main components:\nthe tag and the reader. The tag acts as the identifier in the system; it contains a microchip\nwith a coiled antenna, and can transmit the information held in its microchip's memory by\nsending radio waves to a reader, which also contains an antenna. The information is\ninterpreted by the reader and relayed to a main computer system. These tags can vary in\nsize, shape and form depending on the needs of the application, but the antenna has to be\nof the specific size required by the transmitting and receiving frequency.\nThe mechanism for communication for a typical RFID system works as follows:\n1. RFID reader transmits a radio wave.\n2. A tag in the vicinity of the reader is powered or activated by the radio wave.\n3. The tag selectively reflects energy back to the reader containing some\nidentification data.\n4. The reader, now acting as a receiver, receives and processes the identification data.\nTable 2: The contents of tracks 1 (if format B is used) and 2 on a magnetic strip\nContent\nChars on Track 1:B Chars on Track 2\n\nThe most common way of categorizing RFID tags is based on the power source,\nclassifying them into three main categories: passive, semi-passive and active.\n1. A passive tag is activated by the reader: the reader sends out radiowaves that\nenergize the tag. Passive tags are the mostly widely used form of RFID due to\ntheir lower cost, but the lower tag cost comes at the expense of computational\nperformance.\n2. A semi-passive tag has a battery built in to the tag for better performance leading\nto an increase in operating range. The battery powers the internal circuitry but is\nnot used for radio wave generation.\n3. An active tag broadcasts its signals to the reader using its own power in the form\nof a battery in the tag. Battery power is used for the entire operation and hence\nactive tags can work and transmit even without the presence of a reader. Active\ntags are usually much bigger than passive tags due to the presence of an internal\npower source.\nThe transmission range of a tag depends on the frequency and power used; different\nantennae are used depending on the required communication frequency. Tags can be\nbroadly categorized into three operating frequency bands: low-frequency tags (20kHz -\n500kHz), high-frequency tags (13.56MHz) and ultra-high-frequency tags (850MHz -\n900MHz). The read ranges vary according to frequency. The low-frequency tags can be\nread from up to about a foot away. High-frequency tags can be read from up to about\nthree feet away. UHF tags can be read from 10 to 20 feet away. The low-end tags have\nvery basic functionality emitting a static 64-to-256-bit identifier, while the higher-end\ntags may have the capability to perform active encryption.\n\nSecurity in RFID systems\nOne of the biggest problems with RFID technology is the lack of security in the system.\nRFID tags have very little computation power: they have a few thousand logic gates and\nno cryptographic functions are available for the passive tags. However, there have been a\nnumber of proposals for providing security. RSA Laboratories has provided two\napproaches: the minimalist cryptography approach [13] and the blocker tag approach [14]\ndescribed further in this section. Other schemes that have been proposed include the Kill\nCommand feature described by the AutoID center, the Hash Lock Scheme and\nRandomized Hash Lock Scheme by MIT, and the Anonymous ID Scheme by NTT\nDoCoMo, Inc.\nMinimalist Cryptography: This approach uses a method of ``pseudonym rotation.'' The\nbasic idea behind this mechanism is that each tag has a list of cryptographically\nunlinkable pseudonyms computed externally by a trusted verifier. This would require\nlimited storage - around 10 pseudonyms; the tag cycles through these pseudonyms. The\npseudonyms are coupled with a throttling mechanism that strengthens the restriction on\nadversarial queries. On the reader end, a valid reader provides new pseudonyms. These\npseudonyms are protected against eavesdropping and tampering using encryption\n\n(readers have enough power to do this even though the tags do not). The pseudonyms are\nencrypted by the interleaving of one-time pads.\nEach of the pseudonyms stored on a tag consist of a list of triplet-values. With the current\nrestrictions on the size of RFID chips, this list would have about 10 entries. Each triplet\ncontains three values\n.\nis sent to the reader by the card on query, and\nis the\nvalue that the reader responds with;\nis the final authentication value sent by the tag. In\nthis protocol, the reader has the capability of updating the triplet values on a tag. The\nupdate is made using one-time pads that have been transmitted across multiple\nauthentication protocols (to prevent malicious reader attacks).\nThis method is based on the fact that RFID adversaries are different from the usual\nadversaries in other systems. An adversary with full system access can easily break the\nsystem. But in the real world, the adversary must have physical proximity to the tag and,\nin this case, a valid reader. An adversary could use an invalid reader but the throttling\nmechanism would prevent them from getting all of the pseudonyms. Also, they would\nneed access to the reader to gain the reader component of the pseudonym. The threat\nmodel for RFID tags supports the hardness of this method; it is not a foolproof\ncryptographic solution, but can be argued to be enough for most security purposes.\nBlocker Tag Approach: A blocker tag simulates all (billions of) possible tag serial\nnumbers. A `tree-walking' protocol for identifying the tags asks the tag what the next bit\nis; a blocker tag always says both 0 and 1. This makes it seem like all possible tags are\npresent and stalls the reader. Blocker tags move can be selective and move tags to privacy\nzones, blocking certain ranges of RFID serial numbers. This type of tag is useful for\nprotecting consumer privacy when RFIDs are placed on many items. After purchase, the\ntags can be transferred to privacy zones. The approach is not very useful for ID card\nsystems that require repeated use and no change of zoning (or moving into privacy zones)\nis required, nor is it useful for authentication, however, it is useful for keeping the data on\nan identifying card secret when the card is not being used.\n\nSmartcards\nA smartcard is a card that has an embedded computer chip which is either a\nmicroprocessor with internal memory in it or a memory chip alone. Due to the presence\nof the embedded microprocessor, smartcards have the ability to store large amounts of\ndata and carry out many functions including encryption and acting as digital signatures.\nThe card connects to a reader in one of 2 ways:\n1. Direct physical contact: Contact smartcards\n2. Through an electromagnetic interface: Contactless smartcards\n\nThe above classification method is based on the means of communication. Another way\nof categorizing smartcards is by the hardware on the card:\n1. Integrated Circuit (IC) Microprocessor Cards: These are cards that have a\nmicroprocessor on them. The microprocessor allows for the addition, deletion,\nand manipulation of information in memory, and for a variety of applications and\ndynamic read/write capabilities. The programmable nature of the processor makes\nit useful for many operations including cryptographic functions.\n2. IC Memory Cards: These cards come with a memory that can store data, but\ncannot perform the additional processes that require a processor. Memory-only\nchips are functionally similar to a small floppy disk. They are less expensive than\nmicroprocessor cards, but they also offer less security due to the lack of\nprocessing capabilities.\n3. Optical Memory Cards: These cards have optical storage and can only store data,\nbut they have a larger memory capacity than IC memory cards.\nThe international standard for smartcards is ISO13 7816. Among their many uses,\nsmartcards are very useful for physical access as ID cards to open doors, gates or other\ncontrols. Many physical security systems today use a protocol called ``Wiegand'' to\ncommunicate with door locks and other security devices.\nContact smartcards\nFigure 1: Contact smartcard\nContact cards14 require insertion into a smartcard reader or card acceptor device (CAD)\nwith a direct connection to a conductive micro-module on the surface of the card. When\nthe contact smartcards are inserted into the reader, the pins attached to the reader make\ncontact with pads on the surface of the card and can read from and store information on\nthe chip via this interface. The ISO 7816 series of standards provides the standard for this\ntype of card. One of the disadvantages of contact cards is that they have been shown to\nsuffer some degree of wear, limiting the life of the card. They are used in a wide variety\nof applications, including network security, vending, meal plans, loyalty cards, electronic\ncash, government IDs, campus IDs, e-commerce, and health cards. They have very strong\nsecurity capabilities.\n\nContactless smartcards\nFigure 2: Contactless smartcard\nContactless smartcards or non-contact smartcards have chips that communicate with the\ncard acceptor device through wireless self-powered induction technology (106-\n424kbits/sec). The card acceptor device is also called a reader. Standards for the\ncontactless protocol are specified by ISO/IEC15 14443 (type A and B) from the year 2001.\nThere are proposals outstanding for ISO 14443 type C, D, E and F that have not yet been\naccepted by the ISO standards committee. An alternative standard for the contactless\nsmartcard is ISO 15693. These standards are focused on microprocessor-based cards.\nThese cards have at least 1 kilobyte of memory.16 The cards need to come within close\nproximity of the reader. Typically the range of operation varies from 2.5 to 3.9 inches\n(63.5 to 99.06 mm) depending on the reader.17 In order to communicate, the cards contain\nan embedded antenna that can be used for reading and writing information.\nThe advantages of contactless smartcards include expanded flexibility, more memory,\nhigher security (than most other options), faster transactions, lower maintenance, and\npublished standards. They provide both convenience and security. All the secure\ncryptographic capabilities that were previously available in contact cards are now\navailable in contactless smartcards. Examples of widely used contactless smartcards are\nHong Kong's Octopus card, Malaysia's Touch 'n Go smartcard (1997), Paris' Calypso\ncard18 (October 2001), and London's Oyster card19 (January 2004). Other areas of\ngrowing use include student identification, electronic passports, vending, parking and\ntolls.\nOther smartcard options\nSmartcards also come in different varieties depending on the combination of required\ncapabilities. Hybrid cards and combination cards are two such varieties. Hybrid cards\ncontain two or more embedded chips - for example, a contactless smart chip with antenna\nand a contact smart chip with contact pads, and/or a prox chip with an antenna. The\ncontactless component would be used for applications with fast transaction times and the\ncontact chip could be used for higher security requirements. The combination cards (also\ncalled ``combi'' cards or dual-interface cards) has one smart chip embedded in the card\nthat can be accessed through either contact pads or an embedded antenna. This type of\n\nsmartcard is growing in popularity because it provides ease-of-use and high security in a\nsingle-card product. Mass transit is one of the growing areas for the combination card.\nHere, the contact chip could be used to add cash to the card and the contactless interface\ncan be used to deduct a fare from the card. An example is Malaysia's multi application\nsmartcard identification called MyKad that uses both contact Proton and contactless\nMifare (ISO 14443A) chips.\nSecurity of Smartcards & Cryptographic Techniques\nThis section gives an overview of the making of a smartcard leading to a discussion of\nthe security. Each chip has an operating system which usually contains a manufacturer\nidentification number (ID), type of component, serial number, profile information, etc.\nThe system area may also contain different security keys, such as a manufacturer key or a\nfabrication key (FK), and a personalization key (PK). All of this information needs to be\nmaintained secret.\nOne of the main benefits of smartcards is the ability for most cards to support on-board\ncryptography. Since the actual cryptography is done on the card, the keys do not have to\nleave their storage place. smartcards have the capability to perform both symmetric and\nasymmetric public/private key cryptography. They provide support for the following:\nSymmetric cryptography is when two parties share a secret key that no one else knows.\nThis key is used to both encrypt and decrypt messages (hence ``symmetric''). If the key is\ncompromised, then the cryptographic method breaks. Asymmetric cryptography works\nusing a pair of a public and private keys. The public key is freely available and can be\nused by anyone to encrypt a message that the owner of that public key later decrypts with\ntheir private key, which is safely stored on the smartcard. Symmetric cryptography is\nmuch faster than asymmetric due to the lesser amount of computation time required.\nCommon symmetric key algorithms are DES (Data Encryption Standard), 3-DES, and\nAES and the most common asymmetric cryptographic technique is public key RSA\n(Rivest-Shamir-Adleman's algorithm). DES, 3-DES and RSA use 56, 168, and 1024 bit\nlong keys, respectively. Often a combination of symmetric and asymmetric cryptography\nis used. A usual method of doing this is as follows: if you want to send a message to user\n, encrypt a new key\n(usually small and fixed-width) using\n's public key. Then\nuse\nto encrypt the message.\nthen finds\nby decrypting it using her own private\nkey (takes time) and then uses\nto decrypt the message (taking less time). The self-\ncontainment of smartcards makes them resistant to attack as they do not need to depend\nupon potentially vulnerable and exploitable external resources. Hence, they are useful for\nstrong security protection and authentication. In order to examine the security of\nsmartcards, we will consider the following four areas:20\n1. Communication\n2. Hardware\n3. Operating System (OS)\n4. Software\n\nCommunication with the outside world: A smartcard and reader communicate via small\ndata packets called APDUs (Application Protocol Data Units). The sophisticated protocol,\nlow bit rate (9600 bits per second), bi-directional transmission line, and the fact that the\ndata only travels in one direction at a time makes it harder to attack the system. A mutual\nactive authentication protocol is used for authentication. The card generates a random\nnumber and sends it to the reader, which encrypts the number with a shared encryption\nkey before returning it to the card. The card then compares the returned result with its\nown encryption. The pair may then perform the operation in reverse. Once\ncommunication is established, each message between the pair is verified through a\nmessage authentication code. This is a number that is calculated based on the data itself,\nan encryption key, and a random number. If data has been altered (for any reason,\nincluding transmission errors) message must be retransmitted. Alternatively, if the chip\nhas sufficient memory and processing power, the data can be verified through a digital\nsignature. Some of the algorithms used on these cards have been found to be breakable.\n[12]\nHardware Security: All data and passwords on a card are stored in the EEPROM\n(electrically erasable programmable read only memory) and can be erased or modified by\nan unusual voltage supply. Therefore some security processors implemented sensors for\nenvironmental changes. However, since it is difficult to find the right level of sensitivity\nand there is a voltage fluctuation when the power is supplied to the card, this method is\nnot widely used. Other successful attacks methods include heating the processor to a high\ntemperature or focusing UV light on the EEPROM, thus removing the security lock.\nInvasive physical attacks are the most destructive when the card is cut and processor\nremoved. Then the layout of the chip can be reverse engineered. Differential Power\nAnalysis (DPA), is a statistical attack on a cryptographic algorithm which compares a\ncalculated guess with a measured outcome and can often extract an encryption key from a\nsmartcard. Simple Power Analysis (SPA), which is the direct analysis of the recorded\npower data to determine actions and data, can also break some smartcards. Several\nsolutions to these problems have been implemented. Technologies that have been\ndeveloped for protection include the following: [12]\n-\nTechnology barrier: Advanced 0.6 micron technology greatly reduces the size and\npower consumption of cards as well as the relative variations in their operating\nparameters. It becomes very hard for external SPA/DPA methods to distinguish\nbetween normal card fluctuations and data-related fluctuations.\n-\nClock fluctuation: This is a special Clock Software Management facility, which\nwhen properly used, results in highly variable software timing when the\nembedded application program is executing to prevent voltage attacks.\n-\nUnpredictable behavior. A built-in timer with interrupt capability and an\nunpredictable number generator is used to impose unpredictable variations on\nsoftware execution behavior, with consequent changes in the pattern of power\nconsumption.\n-\nRobust design: Ensuring that the design is modular, allows for a robust design.\nModularity makes it easier to do hardware variations, including customized\nvariations, thereby allowing fast response to new attack scenarios.\n\n-\nMemory control for multi-applications: An enhanced memory access control\nsystem provides secure operating system support for multi-application cards.\n-\nSecurity mechanisms and firmware functions: An enhanced set of security\nmechanisms and firmware functions allow the application to detect and respond\nappropriately to the occurrence of conditions that might indicate an attack. These\nconditions include invalid operating conditions, bad opcodes, bad addresses and\nviolations of chip integrity; the possible responses include interrupts, program\nreset, immediate erasure of all RAM data and flash programming of the entire\nEEPROM array.21\nOS Security: Data on smartcards is organized in a tree hierarchy. There is one master file\n(MF) which behaves as the root directory. The root contains elementary files (EF) and\ndedicated files (DF). EFs are files and DFs are sub-directories (which can also contain\nmore EFs), similar to any common operating system. The main difference is that DFs can\nalso contain data. DF's, EF's, and MF's headers contains security attributes resembling\nuser permissions associated with a file/directory. Any application can traverse the file\ntree, but it can only move to a node if it has the appropriate rights.\nAttributes (Access Rights): There are five basic levels of access rights to a file (both DF\nand EF). Some OS provide further levels. Basic levels can be categorized, increasingly in\nsecurity, as follows:\nAlways (ALW)\nAccess of the file can be performed without any restriction.\nCard holder verification 1 (CHV1)\nAccess can only be possible when a valid CHV1 value is presented.\nCard holder verification 2 (CHV2)\nAccess can only be possible when a valid CHV2 value is presented.\nAdministrative (ADM)\nAllocation of these levels and the respective requirements for their fulfilment are\nthe responsibility of the appropriate administrative authority.\nNever (NEV)\nAccess of the file is forbidden.\nCHV1 and CHV2 correspond to the two security PINs stored in the card:\nCHV1\nis a common user identification PIN.\nCHV2\nis a specific unblocking PIN pre-stored in the card.\nThe PINs are stored in separate elementary files. When a wrong PIN is entered several\ntimes, the OS blocks the card. The number of times is fixed and depends on the OS. Once\nblocked, the card can only be unblocked with a specific unblocking PIN stored in the card.\nThe unblocking PIN can become blocked in the same way. If this happens, card is said to\nbe in irreversible blockage and may have to be scrapped for security reasons. If the PIN is\n\nblocked, the attribute of every file is changed to require CHV1. After the unblocking PIN\nis presented, the file attributes are returned to normal, the counter for the PIN is set back\nto its maximal value and the counter for the unblocking PIN is decremented. If the latter\ncounter reaches zero, it cannot be used for unblocking the PIN any more. This provides\nadditional security for the card. This PIN structure is used for advanced authentication.\nSoftware Security: Software security is also important. Properly encrypted data and\ntransfers are required which are done using hardware-based or OS-based instructions and\nlibraries supporting advanced cryptographic algorithms.\nMost attacks today are classified as class 3 attacks, which means that either the costs\nassociated to break the system are far more than the cost of the system itself, or that the\ncracker has to spend several or hundred years of computing power to break into a single\ntransaction. Technology is developing faster than cracker methods. Therefore, each new\ngeneration of technology usually prevents attacks that the previous generation was\nvulnerable to.\n\nThe Current MIT Card Technical System\nAs can be seen from the discussion of ID card technologies in sectionrefextech, an ID\ncard system is generally made up of three components:\n-\nThe actual card containing identifying data.\n-\nReaders that read the information on the card and interface with the back-end.\n-\nBack-end databases for storing and correlating the data.\nThe MIT ID Card system has all these three components.\nThe MIT ID Card\nThe current MIT ID Card consists of a double-layered strip of PVC with a magnetic strip\nand an RFID chip. This card will also be referred to as a ``proximity card'' or ``prox card''\nlater in this paper. The front face of the card has the MIT logo and owner's name, MIT ID\nnumber, photograph, and an expiration date. The back face of the card has a magnetic\nstrip, a serial number, the status of the owner (explained below), the MIT logo and\ncontact information for the MIT Card Office, and a disclaimer. There are three types of\ncard based on the status of the owner: student, affiliate (including spouse or partner), and\nalumni. Temporary cards can be issued for residence access, parking access, summer\nconferences, retirees, athletic center access, and other non-picture cards. Specialty cards\ncan also be issued such as those for the Emergency Response Group, for Campus Police,\nand for Facilities. Currently, there are over 27,000 card records in the MIT system. [22]\nThe integration of the card into the existing MIT infrastructure was done by MAC\nSystems of Avon, Massachusetts.\n\nCard Specifications\nIndala Corp. of San Jose, California is the vendor who provided the card technology to\nMIT. It is part of their range of solutions for card systems. The type of card used for the\nMIT ID Card is the FlexISO Proximity Card.22 According to the Indala website, the\nFlexISO card is a credit card-thin identification card that is ISO 7813 compliant. ISO\n7813 is a standard for identification cards that are used as financial transaction cards. The\ncard has a graphics-quality surface on both sides of the card and can contain multiple ID\ntechnologies including a magnetic strip, Wiegand code strip, bar code, a multitude of\nsmart chips, and MIFARE. Currently, all MIT ID Cards has a magnetic strip and an RFID\nchip but some of the newer cards have a bar code also. Information is printed on the card\nusing a dye-sublimation printer. Figures 3 and 423 show the ISO standard specification for\nID cards.\nFigure 3: Plastic card size and dimensions\n\nFigure 4: Magnetic strip positioning\nThe Indala card in particular complies with these specifications. The card has the ability\nto include either a contact smart chip, a prox chip or a contactless smart chip. The MIT\nCard, in particular, contains the 125 kHz proximity antenna and chip, and a 3-track high-\ncoercivity magnetic strip. The magnetic strip follows the standard described in section 5.1.\nFigure 5 shows a typical card from Indala, but this was slightly modified for the MIT ID\nCard when it was seen that excessive use of the magnetic strip led to the wear of the tag\nthat lay directly beneath it. [22]\n\nFigure 5: Type of card from Indala\nThe read range of the card depends on the reader. According to the company\nspecifications, with a mid-range reader (like most of the readers on campus), the read\nrange is up to 12 inches (30.5cm). Informal measurements by members of our group have\nshown that campus readers can read cards from approximately 5-6 inches away. in\nexperiments conducted by Mandel, Roach and Winstein, the cards could be read remotely\nat a distance of several feet.\nEach card has an identifier that is a randomly generated 6-character string that is different\nfrom the owner's MIT ID number. This is the ID number stored on the magnetic strip. A\nnew number is generated for every card, both new cards and replacement cards. This\nsame number is used for the RFID chip on the prox card. The chip is passive and thus has\nno power source. The card is powered by a 125 KHz sine wave. [25] It responds with an\nAM broadcast of bits that can be received with a modified AM radio or with an\noscilloscope. The broadcast contains 224 bits that are repeated. There are 30 zeros, 22\nconstant bits and 172 user bits. Out of the 172 user bits, 32 bits seemed to vary from card\nto card while the others remained constant between cards.\n\nFigure 6: Example broadcast recorded from an MIT Card. [25]\n\nCard Security\nThe security of the card is based on the Indala FlexSecur [26] system. This proprietary\ntechnology performs a type of verification at the reader level before sending data to the\nhost system. In essence, the reader screens out unauthorized cards before sending out its\nprogramming data. This verification enhances security in the following 3 ways:\n1. The data on the card is scrambled prior to the programming of the card. Hence the\ndata stored on the card cannot be decoded to find the actual information on the\ncard.\n2. The information stored on the card is locked and only the reader has the key\nnecessary to unlock the data. The programming data is translated by matching the\nreader key with the lock. This is the mechanism that prevents non-MIT Card data\nfrom being transmitted to the host system.\n3. The reader can be programmed for each site, thus making each site unique for the\nreader as well as the card.\nSince Indala's is a proprietary technology, we were not able to obtain any other\ninformation directly from them. [27]\nProcess for Lost, Stolen or Revoked Cards\nWhen a card owner loses his or her card or has his or her card stolen, he or she reports it\nto the Card Office and the card will be deactivated immediately, though the deactivation\nmake take some time to propagate to all the campus readers. In order to obtain a\nreplacement card, the owner must go in person to the Card Office with another form of\nidentification. A card is revoked if a card holder so requests.\n\nCurrently, the MIT campus has a combination of magnetic strip readers and proximity\nreaders. There are about 700 card readers on campus. [22] The proximity readers are\nbeing incrementally installed around campus. The magnetic strip readers are still used for\npoints of sale. Each reader is connected to a panel that is in turn connected to the\ncentralized MIT Card system database.\n\nReading Mechanism\nWhen a prox card is presented to a prox card reader, some data is received by the reader.\nThe data is verified to be an MIT ID Card by the Indala FlexSecur system, as described in\nsection 6.1.2. This data is then sent to the panel that is connected to that reader. The panel\ncontains all the ID numbers that have access to enter through that door. After verification\nof the ID number, access is granted to the owner.\nSpecifications\nAs mentioned before, the currently installed readers were provided by Indala. The type of\nreader24 is the Mid-Range Arch Reader, using an excitation frequency of 125kHz. The\napproximate read time is 200 ms from read to data output. The reader has a read range of\nup to 12 inches, according to the specifications. In actuality, most cards cannot be read\nbeyond a distance of 7 inches, using this combination of card and reader technology.\nThe panels were provided by SonicWALL, a provider of integrated network security and\nidentity solutions based in Sunnyvale, California.25 They are part of the network\ndescribed in the data management section. The panels can be connected to the MIT Card\nOffice system allowing the card office to control access or they may be controlled by the\ndepartment whose control that panel falls under. On request, the Card Office will help set\nup a client station that gives the department control over access. The department also\nneeds to provide a PC, a network jack, and a lock-box. CS Gold 4.1 by Diebold, Inc. is\nresponsible for the access control at the client stations; the software offers controlled\naccess, electronic payments, and identification. Currently, there are 34 client stations\nspread across the MIT campus. There are plans to deploy over 20 more stations before\nSpring 2005. [22]\nData Management and Network\nThe management of the card data is done through a centralized system. A new card\ncomputer system was set up by Diebold Inc., a provider of integrated delivery and\nsecurity systems based in North Canton, Ohio, in the summer of 1999. The system\nincluded a central server in building E32 operated by the MIT Card Office. For the new\nprox card system, MIT uses technology from SonicWALL. The card system has a virtual\nprivate network (VPN) that is used to transmit secure information from the main\nelectronic card systems to the individual client stations around campus. The network has\ntwo firewall and VPN concentrators (SonicWALL PRO 330s). These are used to manage\nReader System and Access Control\n\nthe main access point of the card system. All the data is stored in the central server in\nbuilding W91 with a backup server in Building E32. In addition to this, 80 appliances\nwere deployed at key client stations and point-of-sale locations in January 2004; 50 more\nwere installed through this year. These appliances are part of the VPN and they transmit\naccess approvals to the central server using a secure, encrypted tunnel on the VPN. The\nsoftware for the back-end system was provided by SoftwareHouse. The front end is\ncustom-built for preparing MIT IDs which hands off the data to the CCURE\nbackend. [28] CCURE is the system provided by SoftwareHouse that is used for making\nthe IDs, entering new user data, configuring the servers, and monitoring the data on the\nservers.\nThe data from the panels are all sent to the centralized server and access logs are made.\nThe access data are stored for a period of two weeks. The two kinds of data stored are\nCard read\nID number, access, and timestamp for when an access is attempted\nDoor state change\nState, and timestamp when a door is locked or unlocked\nBoth normal and denied entry data are stored. In the case of a successful entry, all the\navailable data are stored. In the case of a denied entry, if it was an MIT ID that did not\nhave authorization that information is stored. If it was not an MIT ID, then the ID number\nis not stored. An Oracle database is used on the server.\nAfter the data are stored on the server, they can be accessed by a request that must signed\nby the police. The CCURE system has an audit log so that every time someone runs a\nreport of card usage, the system stores the user as well as the parameters of the report.\nThese requests are maintained on file. [23] Only Dan Michaud of the Card Office has\naccess to the log of changes to the entry log. [22]\n\nLimitations of the Technical System\nThe MIT ID Card is not secure by any stretch of the imagination; both the magnetic strip\nand the RFID tag portions of the current card are vulnerable to identity theft. A 1995\nTech article on a report submitted by Andre DeHon to then-director of Housing and Food\nServices (which is now separated into two different departments) Lawrence E. Maguire\nand several other administrators quotes DeHon as writing ``the level of security provided\nby the card is laughable.'' [8]\nMagnetic Strip Vulnerabilities\nDeHon discovered that anyone with an appropriate magnetic strip card reader can readily\nextract the information from a card and make a copy, onto an old ATM card or the like.\nSays DeHon: ``Equipment to duplicate or synthesize MIT Cards can be readily obtained\nfor less than $500 and requires no technical expertise to operate. The technically inclined\n\ncan put together suitable equipment at a much lower cost.'' [8] As noted in section 6.1.1,\nthe magnetic strip on the card contains the owner's MIT ID number and a 42-bit code\nidentifying the owner.26\nUnfortunately, a magnetic strip does not allow much in the way of flexibility in terms of\nhow data is stored on the card. The data may be encrypted, for instance, but anyone can\nstill copy the card's contents without knowing the key. The best security possible for this\ntype of hardware, then, is ``security through obscurity,'' that is, security by preventing\nothers from gaining physical access of your card and by preventing others from reading\nthe contents of your card while the data is being transferred between the card reader itself\nand the access panel as described in section 6.2.1. While the problem of eavesdropping\non reader-panel communication is more of a physical access issue than a technical\nlimitation, and even so might possibly be solved by encrypting that communication, the\nproblem of preventing others from accessing your card is more difficult.\nOn MIT's campus there is no more universal identification card than the MIT ID Card.\nThe card can now be used to purchase food from campus vendors, is used to enter\nbuildings, as an identification scheme by the Student Services Center and most other MIT\nadministrative groups, as collateral for borrowing videos and keys at student dormitory\ndesks, for parking, and so on. While not all of these uses require that the ID change hands,\nthe use of the MIT ID for collateral does require surrender of the card. While surrendered,\nthe owner has no control over whether the card is copied. And once copied, due to the\nwealth of services available with the card, not only is the owner's identity compromised\nbut he can also lose monetarily. In his report, DeHon suggests not using the card as\ncollateral precisely because the card is so easy to duplicate. In fact, this recommendation\nbecame policy shortly after his report was published, but the policy reverted back to the\noriginal shortly thereafter.\nBecause of its many uses, and because of the tendency for the MIT ID to be given to\nothers for sufficient time for copying as a form of collateral, the security provided by the\nmagnetic strip is not acceptable.\nRFID Vulnerabilities\nUnfortunately, the new MIT ID Cards that contain RFID tags only make the problem\nworse. Because the type of RFID used by the card, so-called ``passive'' RFID, always\ntransmits the same data to the reader, the acquisition of the data sent in a single session\ncan be used to make a duplicate of the card.27 This data can be read by a third party in\ntwo ways:\n1. By reading the waveform emitted by the card when it is activated by one of MIT's\nreaders.\n2. By exciting the card and reading the waveform emitted by it.\n3. By getting access to the contents of the magnetic strip.\n\nMethod 1 above is difficult because the excitation range for card's particular RFID\nimplementation is not very great, and your presence is likely to be noticed. Method 2,\nhowever, is not very difficult to accomplish with a little technical skill or an RFID reader.\nBecause the range of the card's RFID tag is great enough to pass through a wallet or\nbookbag, the extraction of the RFID tag's data can be done without the owner's\nknowledge or even suspicion - affording the attacker a greater likelihood of escaping\nundetected and able to use the information he or she has gleaned.\nMethod 3 relies on the fact that the same information is kept on the magnetic strip as in\nthe RFID tag. According to Dan Michaud, the rationale behind this decision was to avoid\nhaving to upgrade the access panels. Currently, the access panels have room to store\nabout 20,000 identifiers. The card office has issued over 10,000 ID cards. If each card\nhad multiple identifiers there would not be enough space on most access panels to keep\nall of the identifiers. In light of this limitation the card office decided to use the same\nidentifier both on the magnetic strip and in the RFID tag. Unfortunately, this decision led\nto a serious vulnerability as well.\nWhen MIT first contracted with Indala to bring RFID on campus, Indala assured them\nthat the data stored on the cards was ``encrypted,'' however this was not the case. [22] As\nmentioned in section 5.2, only ``active'' cards are capable of real encryption, as real\nencryption relies on being able to perform computationally expensive (relative to the\npower used) tasks. ``Passive'' cards simply rebroadcast the same data each time they are\nactivated, and are not capable of real encryption. This is not to say they are not useful, of\ncourse: in a system where there are no adversaries there is no need for strong encryption.\nIf there is no incentive to spoof the system, there is no need for encryption. If you are\ncounting cattle, the cattle are not going to impersonate each other; there is no need for\nstrong encryption. Members of the MIT population are not cattle; we need strong\nencryption. The Indala system uses passive RFID tags, and thus cannot provide strong\nencryption. Under these circumstances it stands to reason that it would only be a matter\nof time before the ``weak'' encryption scheme were broken.\nKeith Winstein, Austin Roach, and Josh Mandel showed in Spring 2004 that there is a\ntrivial relation between the pattern of bits stored on the RFID tag and the identifier used\non the magnetic strip of the same ID card. Now that this information is public, anyone\nwho has access to the magnetic strip data of an ID card can recreate an RFID tag that\nemits the sequence of bits that the original card would have produced. Thus all of the\nissues surrounding the magnetic strip and its use as collateral apply even more so to the\nRFID portion of the card.\nBut even without this third method of gaining access to the data stored in the RFID tag,\nthe passive tags used by the Indala system are vulnerable to replication and theft of\nidentity simply by recording the signal they emit and playing it back. Winstein, Roach,\nand Mandel did this with $30 worth of hardware available at MIT's introductory electrical\nengineering laboratory. If MIT wishes to continue the use of RFID in the card, other\noptions for secure transations need to be explored such as those mentioned in\nsection 5.2.1.\n\nTechnical Recommendations\nOur main technical recommendations can be broken down into two parts. In addition to\nchanges we feel are required for the current system...\n1. Stop the expansion of RFID readers on campus until a secure RFID technological\ninfrastructure can be implemented.\n2. Change the client stations so that only the most recent hour's worth of data can be\nviewed.\n...we also present what we feel would be an ideal new system for a future\nimplementation:\n1. Use a secure card technology based on challenge-response authentication.\n2. Keep localized access control through client stations (this is already present in the\ncurrent system).\n3. Allow client stations to view only the most recent hour's worth of entry data.\n4. Maintain centralized access logs subject with restricted access enforced by...\n1. ...a two-tiered database that restricts access to sensitive username\ninformation.\n2. ...cryptographic mechanisms that require multiple keys held by distinct\nindividuals to access sensitive data.\n5. Provide a technical infrastructure to facilitate the keeping and reviewing of audit\nlogs.\nThis section is broken down by which part of the system that a given recommendation\naffects.\n1. Cards and Readers\no Insecurity of RFID chip in the ID card\n2. Access Control\no Localized control of access for departments and labs\n3. Data Management and Network Issues\no Maintenance of MIT ID Card access log data\no Protected and audited access to log data\no Automated checks and balances in place to prevent fraud\nCard and Readers\nAs we have already seen, the current implementation of RFID on the MIT ID Card is not\nsecure and magnetic strip technology has fundamental properties that are irreconcilable\nwith present uses of the MIT ID Card.\nTo summarize section 6.4, the two main liabilities of the RFID tag in the MIT ID Card\nare:\n\n1. The encoding provided by Indala can be broken to reveal the contents on the card.\n2. The card uses passive authentication and hence can be copied easily.\nSolutions\nWe discuss here four possible solutions:\n1. Revert back to using magnetic strip for all applications and continue the use of\nexisting cards\n2. Revert back to magnetic strip for all applications and reissue cards with no chip\nfor card-owners with a proximity card\n3. Recall all proximity cards and rewrite them with different IDs for the magnetic\nstrip and RFID chip\n4. Halt the expansion of the RFID readers on campus until such time as a secure\nRFID technology is in place.\n5. Issue new cards with alternate technology that provides both security and\nconvenience\nThe first option is the cheapest and only restricts new deployment of RFID. The main\nadvantage of this option is ease of implementation. Restricting the use of RFID means\nthat, over time, the RFID readers on campus will be replaced with magnetic strip readers;\nany new cards will only have a magnetic strip, and so all members of the MIT\ncommunity will eventually be reissued non-RFID cards. The main disadvantage is that\nsince the RFID tag contains the same information as the magnetic strip, the presence of\nRFID in the card is still a vulnerability, even though it is not used.\nThe second option solves the latter vulnerability by doing away with RFID in the entire\nsystem altogether. This option has the obvious advantage that the added vulnerabilities of\nRFID are not present in the system.\nThe third option is more complex because it requires the replacement of a large number\nof access panels. This option has the advantage that the RFID tags and magnetic strip\ndata are divorced of each other, so that reading one will not tell you anything about the\nother. This can be useful for things like TechCash, which only uses the magnetic strip for\nthe moment: even if an attacker gains access to the RFID tag (easier than the magnetic\nstrip contents, since no physical access of the card is required), he or she will not be able\nto use the victim's TechCash account.\nThe first three options, while relatively inexpensive and implementable over the current\nsystem, still have many of the vulnerabilities that the magnetic strip and RFID tag have\nindividually. Of these three, only the third is likely to be accepted by the MIT community.\nIn our survey of the student body, approximately 41.7% felt that the convenience of\nRFID is worth the security risk. Now that RFID technology has been introduced, it is\nunlikely that (the student body, at least) will respond well to its withdrawal.\n\nThe fourth option is what we recommend for now. The MIT Card Office has already\nexpended considerable effort in implementing the current system of prox card readers;\nstudents, faculty, and lab directors have all voiced the opinion that RFID is a generally\nuseful tool, and they would probably not respond well to a removal of RFID. However, to\neliminate the extra cost of installing a poor RFID system and needing to replace it later,\nwe strongly recommend that expansion of the current RFID system be stopped.\nThe fifth option - the contactless smartcard - is ideal for a new system. The MIT ID\nCard's ``Passive'' RFID's intrinsic vulnerabilities are based on the fact that the tag emits\nthe same data each time it is activated. However, ``active'' tags do not necessarily suffer\nfrom this vulnerability. In fact, ``active'' tags have been in use for authentication\nthroughout the world since 1997, when Hong Kong implemented what is widely regarded\nas the first implementation of ``contactless smartcard'' technology, the ``Octopus Card.''\nThe ``Octopus Card'' can be purchased locally with cash, totally anonymously or with\npersonal information recorded so the card can be revoked if lost. Because of the\nquantities of capital involved, the designers of the Octopus Card needed a system they\nwere confident could not be broken into - imagine having the money in your pocket or\nwallet stolen through the very walls of your pocket or wallet! Clearly an unacceptable\nvulnerability.28\nAt the time when the designers of the Octopus Card were deciding on a system to use for\nauthentication, the most secure mechanism available was the smartcard, a card with a\nlittle chip on it capable of performing strong encryption. When used, the smartcard\nreceives power from the reader it is inserted into and with this power is able to have a\nsecure conversation with the reader. As discussed in Sectionrefsmart above, smartcards\nensure the integrity and privacy of the key data it stores (through various mechanisms)\nand perform challenge-response authentication with a reader.\nPreferring a contactless solution, however, the designers of the Octopus Card designed a\nway to supply a card with enough power via induction coils to allow the card to perform\nstrong encryption. In this manner, the designers were able to produce what is now\ncommonly known as the contactless smartcard. Described in sectionrefclsmart, the\ncontactless smartcard is an ideal solution to the problem that visibility of communications\nbetween a passive RFID tag and a reader leads to the ability of an eavesdropper to\nemulate the tag.\nAccess Control\nThe current system of providing client stations to departments that request it must be\ncontinued because many of them require expedited access control. The important addition\nthat needs to be made to the current system is the option for a lab to request to turn on the\nfeature of access logging. There are some labs that absolutely require tracking due to\nsensitivity of information, high value equipment or protected equipment stored within the\nbuilding. In order to ensure that these labs will always have the option to control what\nhappens to their property, it is important to allow for them to request this option. This\nwould require a change to the existing software as described in the technical discussion of\n\nthe current system. If a new system were to be developed, local access control would\nneed to be a key requirement.\nAnother minor loophole that was identified in the current system, is the possibility of\nsomeone sitting at a client station to be able to see realtime data of entries and exits. This\nis made possible by keeping the client machine's screen turned on with a window of the\naccess entries that are being sent to the central server. The number of entries that can be\nseen with this method depends on the buffer size of the window. The number of days\nworth of data that can be gathered is dependent on the amount that the readers served by\nthat client station are used. The more frequently they are used, the lesser number of days\nworth of data will be shown on the screen. We recommend that this be changed so that\nclient stations only show the most recent hour's worth of data. Our understanding is that\nthis can be implemented easily, and we suggest that it be implemented as soon as possible\nto allay fears that administrators might use this information to track the movements of\nmembers of the MIT community.\nData Management and Network Issues\nMaintenance of MIT ID Card access log data\nThe card access log data would be stored on the server in a similar format as it is now.\nRestrictions on accessing this log are described in section 4.\nIn light of the more frequent need for access the log of general entry and other system\ndata that is not user-specific, as well as the need for accountability regarding access that\nis user-specific, we recommend that the MIT Card Office keep a two-tiered database: the\nfirst level is a relational database with all the columns it already contains, except the\nusername field is replaced with an ID string - unique to each entry in the database - that\nmaps into a second database; the second database is simply a secure mapping between\nusernames and unique IDs that can only be accessed by the parties discussed in\nsection 4.5. The two-tiered nature of the database allows the Card Office to access the\ndata it needs on a daily basis without restriction, but only anonymously or in the presence\nof the individual whose data will be accessed. Of course, in the case of a request from the\nMIT Chief of Police, approved by the dorm housemaster in the case of dorm log data, the\nindividual in question need not be present.\nProtected and audited access to log data\nIn order to enforce accountability of the policies set forth in section 4, we recommend\nkeeping detailed logs of all the accesses made to the entry log data; the information kept\nabout such accesses must include information about who accessed the log, who requested\nthe access, and any other details about due process.\nWe recommend having two separate audit logs - an automated one and a manually\ncreated one. The first log is an automated one that automatically records every access that\n\nis made to the central database. This must be programmed into the system. Every time a\nconnection to the database is initiated, the following details must be recorded:\n-\nUsername of the person accessing the log\n-\nQuery timestamp\n-\nQuery contents\n-\nType of access (whether it was for troubleshooting or for gathering information)\nThis gives an automatic log of events that can be used for audits and corroboration. The\nlog can be accessed by only one user account and the user account would be controlled\nby the Card Access and Oversight Board (CAOB). This would decouple responsibility\nfor policy from the Card Office, ensure independence, and prevent changes to the audit\nlog by unscrupulous elements.29 The second log must be stored at the Police Station and\ncontains physical, documented evidence of requests that were made and granted by the\nChief of Police. Whenever a request goes through the Chief of Police, it must be recorded\nhere. The details of the request must include\n-\nName of the person requesting the data\n-\nTime of request\n-\nResult of request\no Whether the request was approved or denied\no Reason for approval or denial\n-\nRequested Data\no Type of Data\no Data format requested\no Exact fields requested\n-\nReason for request\nThis would provide the more comprehensive log of the request made. The CAOB would\nhave access to these audit logs, but the auditing itself will take place as described in\nsection 4.8.\nComparable Systems: Harvard\nThere are other schools that encounter many of the same privacy and tracking data issues\nthat MIT faces. The closest analogy to MIT is Harvard University, located in Cambridge,\nwhich experiences the same external threats to the students and members of the\ncommunity, as the MIT community does because Harvard is located in the same city and\nthe same urban environment. Actual uses for tracking data have occurred in situations\nand criminal investigations that are very similar to those which have occurred at MIT.\nThese cases have included missing persons, vandalism, theft, and sexual assault. In some\ncases, students have requested their own data to aid in self-conducted investigations, but\nthese requests for information have been denied. The existence of the card swipe logs has\nalso helped to spur students guilty of academic fraud to admit to their crimes.\n\nHarvard University currently operates a magnetic stripe card system similar to the one\npreviously employed by MIT; the university has yet to switch to an RFID system. Like\nthe MIT Card system however, data from card use is kept in logs, which can be accessed\naccording to a policy that has never been formally distributed. This policy is described in\nan article that was first published in the Harvard Crimson Newspaper in 1993. This\narticle is the only record of the policy which was created by student members of the\nHarvard University Civil Liberties Union and the Dean of Harvard College at the time,\nFred Jewett. All of the information in the following sections on the ID card system used\nat Harvard was gathered from the article in the Crimson which described the policy, and\nan interview conducted with former Dean of Harvard College, Harry Lewis. Much of this\ninformation remains otherwise undocumented.\nThe Harvard system\nHarvard's magnetic stripe card system was implemented in 1994, at roughly the same\ntime a similar system was introduced at MIT. The system keeps a record of entries and\nexits to dormitories and other buildings, although the amount of time for which such\nrecords are stored is not well documented among policies and procedures laid out on the\nHarvard University ID services website.\nPolicy in Theory\nHarvard University's policy on access to tracking data is not well documented. The only\nmention of such a policy appeared in The Harvard Crimson in an article published in\n1993. In response to the implementation of the card system, the Civil Liberties Union of\nHarvard (CLUH) objected to the college's ability to track students, and felt that a\nstringent policy regarding the use of such data should be formulated to prevent the\npossible misuse of recorded information. The student leaders of CLUH collaborated with\nFred Jewett, Dean of Harvard College at the time, to develop a policy that was acceptable\nto both the administration and the students. This policy was passed by the Administrative\nboard in early April of 1993.\nAccording to a Former dean of Harvard College, the actual policy has never been\nformally described anywhere although it was officially adopted by the Administrative\nBoard. Upon discovering this fact as a result of inquiries for this report, Former Dean\nLewis has advised his successor's to post the University's policy on card swipe data\naccess on its website.\nThe policy stipulates that information can only be released with permission from the\nDean of the College, or by the student whose information is to be released. Any data that\nis to be released to Harvard University Police will be released only ``under circumstances\nwhen the information is important in the investigation a crime or other incident related to\ncampus security.'' Whenever information is released to any party, a copy of the released\ninformation must also be provided to the student. The CLUH felt that this policy struck\nthe right balance between preserving information because it was useful and preserving\nthe information simply because it was possible.\n\nPolicy In Practice\nSince the policy was adopted, the question of whether it has been strictly followed is\ndebatable. It is certain that the general spirit of the policy was followed, but strict\nenforcement has not occurred. During Dean Lewis' tenure as Dean of the College, all\nrequests for information by the police or any other party were directed to him. The\nHarvard University Police Department (HUPD) knew to contact him whenever it was\nnecessary to request card information. The Dean's jurisdiction, however, was limited to\ninformation of entry and exit from any of the University's dormitories. In one case, where\nthe police requested entry/exit information from the dining hall, the Dean was asked for\npermission even though his jurisdiction did not extend to the dining halls. Those who\nrequested information generally understood that the policy for making such requests\nrequired the permission of the dean. Dean Lewis felt that the provision of requested\ninformation to students was one of the requirements of the policy that was not always\nfollowed.\nThe data access policy only applies to dormitories because most students do not have\naccess to other campus office buildings and labs after about 6 pm. This policy is\nbeginning to change as students require more access to buildings on campus, such as labs\nand computer clusters, to complete work. Once card access is expanded to these areas,\nthe policy for accessing data about students will also change as the data collected will\ninclude students not under the watch of the Dean of Harvard College, such as graduate\nstudents.\nIn most of the cases where card entry data was needed to help solve criminal\ninvestigations, most of the data was corroborated by witness accounts; the card swipe\ndata did not serve as the primary piece of evidence. In these cases, the police requested\nvery specific data from different locations during a fairly narrow time window on the\norder of a couple of hours. One of the provisions of the original policy allowed for\nstudent authorization for the release of data, but it seems that this was largely ignored\nover the years as student requests were often denied by the Dean of the college.\nComparable Systems: Stanford\nAnother system that is similar technologically to MIT's is the Stanford ID card System.\nThe Stanford Campus Card serves as identification, library card, electronic key, and debit\ncard for the StanfordCardPlan, an account system similar to MIT's TechCash. Users can\nactually take out cash from their StanfordCardPlans using their ID cards. The Stanford\nCampus Card also contains both a magnetic stripe, and an RFID chip. Like the MIT\nRFID card, the RFID chip on Stanford's card can be activated within 12 inches of the\nreader, and tracking data can also be stored. Access to campus buildings, elevators, and\ndormitories is granted by the Stanford card. Access control is not technically described in\ntoo much detail on the Stanford Campus Card website. However, the site does say that\naccess can be restricted according to day of the week or time of day, and can be granted\non an individual basis or through departmental and class lists.\n\nData storage\nThe reason for presenting the Stanford Campus Card System here is that although the\ntechnology of the Stanford and MIT systems is extremely similar, the policy surrounding\nthe Stanford system is different from MIT's in one very major way: tracking data is stored\nindefinitely, and in effect, forever. Initially tracking data is stored for one month on the\nactive card database system. Each day, the data is backed up on optical disks as a\nprecaution against system failure. These backup disks are reused every seven days, so 7\nbackup disks with data exist at any given time. After the one month active data period is\nexpired, the data is transferred to optical disks which are then stored indefinitely: they are\nneither destroyed nor erased.\nThe data on these disks is recorded in a proprietary encrypted format, which prevents the\nmisuse of the data therein by parties without access to the encryption methods or the\nCampus Card System Software. This software is apparently the only software that is\ncapable of reading data from the storage disks. Stanford's Card system, much like the\nIndala system at MIT, is a completely proprietary system and the software and hardware\nemployed are completely devoted to card operations. Registration information from the\nStanford Axess system, equivalent to MIT's Websis, is fed into the card system, but all\nother records are kept separately from the card system. No other personally identifying\ninformation is given to the Card system from Axess.\nAccess to Data\nAuthorization for access to the data by people other than the Manager of Campus Card\nServices is also granted differently at Stanford. Whereas the current system at MIT\nallows the police to grant requests for data, Stanford grants access only with student\nconsent, or a subpoena for that information. The Stanford ID services website clearly lists\nthe exceptions to this rule as well. These exceptions include disclosure of information in\ncompliance with regulations imposed by federal law on card issuers and providers, and\ndisclosure without card user consent in the event of a safety or health emergency, or a\ncriminal investigation. There are other exceptions to the rule, however. Computers in\nseveral libraries, the bursar's office, and dining services can also access certain\nunspecified types of data from the card services office. [16]\nFeasibility of the Proposed System\nIn this section we hope to explore the feasibility of our proposed system. The\nrecommendations we make above we have broadly classified as technical and policy\nrecommendations. On the technology side of the card issue, there are three main factors\nto consider: security, convenience, and cost. On the policy side of the issue, the main\nconcerns are privacy and accountability. With the continuation of an access logging\nsystem, the privacy of all members of the MIT community is at stake. Our proposed\n\nrecommendations deal with these two issues by addressing both of them to the greatest\nextent possible and by ensuring that there are as few loopholes in the system as possible.\nOur discussions with John McDonald of Enterprise Services have indicated to us that\nsubstantial changes to the current system are not feasible in the short term. To address\nthis concern, we have ensured that out most important recommendations are inexpensive\nand easy to implement. We hope that the ideal system we have described in this\ndocument will be used as a template for any future system should MIT decide at some\npoint to upgrade its current system to the state of the art.\nSecurity\nSecurity on campus is a very important issue. MIT is an urban campus that has a\ncomparatively open access policy. It is therefore extremely important to ensure that areas\nthat are not as public as others are not made open through a compromise of the access\nmechanism - the MIT Card. Along with the access policies that are in place for private\nand/or restricted areas, we need to make sure that the card itself is secure. The technology\nthat is used should not easy to fake or duplicate. It should also not reveal private\ninformation about the cardholder. Our proposed system is secure. It uses a very secure\ncard technology: contactless smartcards with enhanced cryptographic functionality. The\nalready existing virtual private network ensures that the data is transported securely to the\ncentral database. On the other end of the spectrum, in certain cases, such as on-campus\nthefts, access log data have proven to be useful in the past - so there is an airtight system\nin place to obtain this information for investigative purposes only. The data is stored for\nthe required period of time and is available with due process.\nConvenience\nThe recommended system maintains the convenience of cutting edge technology for card\nsystems. The contactless smartcard works at the same range that the current proximity\ncard does and allows for ease of use without handling at access points.\nCost\nThe changes to the current system that we recommend must be implemented as soon as\npossible. To this end, we have ensured that those particular recommendations have very\nlow cost. In contrast, the construction of an entirely new, secure system is much greater.\nA thorough investigation of the costs of implementing such a system will be necessary\nbefore such a system is implemented, but we do not expect the cost of implementation to\nexceed the cost of the first MIT ID Card system completed in 1995.\nPrivacy\nThe new system has a transparent privacy policy in place along with a representative\ncouncil to review and ensure the updating of the policy as required. The manpower and\nrepresentation required is feasible and, in our opinion, necessary.\n\nAccountability\nOne of the most important new additions to the system will be the auditing procedure.\nAccess to personal tracking data needs to be monitored very carefully. The auditing\nprocedure is in place to ensure that the system is doing what it is supposed to do. This\nwill ensure that all the concerns, especially those related to privacy, are being addressed.\nWe strongly feel that an auditing procedure is worth the added expense.\nConclusions, Summary of\nRecommendations, and Contributions\nWe have presented here:\n-\nA description of the current MIT Card System in nearly as much detail as is\navailable,\n-\nA set of short-term recommendations for the MIT ID Card:\n1. Policy, to be implemented as soon as possible:\n1. The creation of a stronger, more permanent Card Advisory and\nOversight Board\n2. Approval of accesses to dormitory tracking info is to be done by\nthat dorm's housemaster\n3. Tracking and privacy policies must be made public and well\nknown\n4. Students are allowed access to their own tracking data, and are\nprovided with a copy of any of their data which is accessed by\nother parties.\n5. The entire process of accessing tracked data is audited by the MIT\nAudit Division\n2. Technical, to be implemented as soon as possible:\n1. Stop the expansion of RFID readers on campus until a secure\nRFID technological infrastructure can be implemented.\n2. Change the client stations so that only the most recent hour's worth\nof data can be viewed.\n-\nA set of technical recommendations for a future MIT ID Card system:\n1. Use a secure card technology based on challenge-response authentication.\n2. Keep localized access control through client stations (this is already\npresent in the current system).\n3. Allow client stations to view only the most recent hour's worth of entry\ndata.\n4. Maintain centralized access logs subject with restricted access enforced\nby...\n1. ...a two-tiered database that restricts access to sensitive username\ninformation.\n\n2. ...cryptographic mechanisms that require multiple keys held by\ndistinct individuals to access sensitive data.\n5. Provide a technical infrastructure to facilitate the keeping and reviewing of\naudit logs.\nIn order to develop fair and balanced recommendations, we consulted the thoughts and\nconcerns of many different members of the MIT community, including students. To our\nknowledge, this report is the first report on the MIT ID Card to consider input from a\nlarge section of the student body. Considering that the MIT ID Card is almost 10 years\nold, this fact both surprises and concerns us, however, we are happy to announce that it\nhas now been done. In addition to our survey, we have also collected the opinions of the\nmany who have written on this topic before into a comprehensive collection.\nWe hope that our short-term recommendations are implemented in a timely manner, and\nthat our long-term recommendations are seriously considered for any future system.\nAppendix\n\nSurvey\nThis appendix contains our survey questions and available responses, as well as how our\nsurvey respondents answered those questions.\nThe full contents of the survey page are given here, and each possible response is\nfollowed by the total number of respondents who selected that response and what fraction\nof total respondents this total represents (percentages may not sum to 100% due to\nrounding). In total, we received 513 responses.\nThis survey is designed to discover the privacy concerns of MIT students with regard to\nthe MIT ID Card system. Our goal is to propose a system that will address the concerns\nof students and members of the faculty, lab directors, and the MIT campus police.\nWe appreciate your contribution.\n\nThe following questions are to gauge current opinions toward the MIT ID Card system.\n1.\nWere you aware that the MIT ID Card contains an RFID tag in it? (RFID stands\nfor Radio Frequency IDentification; the tags are small, cheap radios-on-a-chip\n\nthat emit identification strings when activated by a reader. The MIT ID uses a\nform of RFID that is entirely passive, and can be read from 2-5 feet away.)\n1. Decline to respond 0 (0%)\n2. Yes 269 (52.4%)\n3. No 244 (48.6%)\n2.\nAre you comfortable with the current level of security offered by the card and\nassociated reader technologies?\n1. Decline to respond 3 (0.6%)\n2. Very comfortable 80 (15.6%)\n3. Somewhat comfortable 171 (33.3%)\n4. Neutral 89 (17.4%)\n5. Somewhat uncomfortable 68 (13.3%)\n6. Very uncomfortable 22 (4.3%)\n7. I was not aware of any security concerns with the current system 80\n(15.6%)\nAt present, the MIT Card Office records when an individual enters a building or lab using\ntheir card and keeps these records for 2 weeks. This policy came into effect in the\nSummer of 2002.\n1.\nWere you aware of this policy?\n1. Decline to respond 2 (0.4%)\n2. Yes 134 (26.1%)\n3. No 377 (73.5%)\n2.\nHow do you feel towards this policy?\n1. Decline to respond 2 (0.4%)\n2. Very favorably 51 (9.9%)\n3. Somewhat favorably 106 (20.7%)\n4. Neutral 189 (36.8%)\n5. Somewhat unfavorably 135 (26.3%)\n6. Very unfavorably 30 (5.9%)\n3.\nIn your opinion, how long should MIT keep these records?\n\n-\nResponses here varied widely. Many students felt that 2 weeks was an\nacceptable amount of time, some thought that the data should be kept for\nmonths, while others preferred days.\nThe current system does not allow for different areas of campus to be treated differently\nfor the purposes of tracking entry. The following questions refer to a hypothetical future\nsystem.\nOne group has suggested a policy of only recording unsuccessful attempts at entry, that is,\nonly record a card swipe when entry to a location is denied.\n1.\nHow would you feel about such a policy?\n1. Decline to respond 6 (1.2%)\n2. Very favorably 27 (5.3%)\n3. Somewhat favorably 113 (22.0%)\n4. Neutral 119 (23.2%)\n5. Somewhat unfavorably 184 (35.9%)\n6. Very unfavorably 64 (12.5%)\nThe current 2 week policy may have been implemented in part because of on-campus\nlabs' desire for increased security. As such, one suggestion is to limit tracking of entry to\nthose areas alone.\n1.\nHow would you feel about a policy that restricts tracking to those labs that\nspecifically request it?\n1. Decline to respond 5 (1.0%)\n2. Very favorably 109 (21.3%)\n3. Somewhat favorably 226 (44.1%)\n4. Neutral 87 (17.0%)\n5. Somewhat unfavorably 71 (13.8%)\n6. Very unfavorably 15 (2.9%)\n2.\nIf such a policy were implemented, how much should lab members' input be\nconsidered in the decision to track entries/exits? (In contrast with letting the\ndecision be up to lab directors alone.)\n1. Decline to respond 8 (1.6%)\n2. Very much 138 (26.9%)\n3. Somewhat 155 (30.2%)\n4. Don't know / Up to the labs 173 (33.7%)\n5. Not much 31 (6.0%)\n\n6. Not at all 8 (1.6%)\nGetting back to RFID, the current system allows cards to be read by a card reader in close\nproximity. This means that, hypothetically, someone can read your ID card's RFID\nidentifier by walking near you with a reader (readers can be quite small). With this ID,\nthey can access wherever you can access, can use your TechCash acount, and can\ndiscover your MIT ID number.\nHowever, many argue that the vastly increased convenience of RFID (not having to take\na card out of a wallet) outweighs the risks associated with reading-at-a-distance.\n1.\nWhat is your opinion on this matter? Is the increased convenience of RFID worth\nthe risk of someone getting your ID number?\n1. Decline to respond 4 (0.8%)\n2. The convenience of RFID is very much worth the risk 32 (6.2%)\n3. The convenience of RFID is worth the risk, but I am concerned 182\n(35.5%)\n4. Neutral / Doesn't make much of a difference 38 (7.4%)\n5. The convenience is not worth the risk, but not by much 116 (22.6%)\n6. The convenience is definitely not worth the risk at all 125 (24.4%)\n7. I don't know 11 (2.1%)\n\nThe following information is for demographic purposes. If you feel comfortable\nproviding this information, we would appreciate it.\n1.\nDo you live on campus?\n1. Decline to respond 7 (1.4%)\n2. Yes 450 (87.7%)\n3. No 56 (10.9%)\n2.\nWhich Living Group do you live in?\n1. Decline to respond 26 (5.1%)\n2. Baker 69 (13.45%)\n3. McCormick 54 (10.53%)\n4. Burton-Conner 38 (7.4%)\n5. MacGregor 3 (0.6%)\n6. New House 25 (4.9%)\n7. Next House 69 (13.5%)\n\n8. Simmons 1 (0.19%)\n9. East Campus 54 (10.5%)\n10. Bexley 19 (3.7%)\n11. Senior House 25 (4.9%)\n12. Random Hall 23 (4.5%)\n13. Ashdown 2 (0.4%)\n14. Eastgate 0 (0%)\n15. Tang 2 (0.39%)\n16. Warehouse 0 (0%)\n17. Sidney-Pacific 53 (10.3%)\n18. Westgate 0 (0%)\n19. Edgerton 1 (0.2%)\n20. Green Hall 0 (0%)\n21. Other / FSILG 49 (9.6%)\n3.\nHow many years have you been at MIT as an undergraduate student?\n-\n139 (27.1%)\n-\n115 (22.4%)\n-\n86 (16.7%)\n-\n90 (17.5%)\n-\n1 (0.2%)\n-\ntotal 431 (84.0%)\n4.\n...as a graduate student?\n-\n29 (5.7%)\n-\n12 (2.34%)\n-\n15 (2.9%)\n-\n8 (1.56%)\n-\n5 (1.0%)\n-\n2 (0.4%)\n-\ntotal 71 (13.8%)\n\nIf you have any comments about this survey or privacy at MIT in general, please share\nthem with us here:\n\nIf you would like to be entered in our drawing for a $20 gift certificate to the\nCambridgeside Galleria, please provide your username for us to contact you. Your\nusername will not be associated with your responses in any way.\n@mit.edu\n\nThank you for participating!\nPriya, Neha, Chaitra, Al, and J.D.\nIf you have any questions, please send e-mail to privacy at MIT.edu\nBibliography\nBy name Year: Publisher.\nJonathan A. Ives, The HIstory of the MIT ID 1998-1999:\nhttp://web.mit.edu/mitid/www/history.html\nMIT Policy and Procedures: Privacy and Disclosure of Information 1997:\nhttp://web.mit.edu/policies/11.0.html\nScott Thorne, People Related Projects 1994:\nhttp://web.mit.edu/mitid/www/t_info.admin-arch.37707.TXT\nCharu Chaudhry, MIT Card Replaces Meal Card, Keys The Tech Vol 113, No 45,\nPg 9, 28 Sep 1993\n\nIfung Lu, MIT Card Raises Issues of Privacy, Security The Tech Vol 113, No 55,\nPg 1, 5 Nov 1993\nAndre DeHon, Security Assessment of the M.I.T. Card 1995:\nhttp://www.ai.mit.edu/people/andre/mit_card/\nsecurity_assessment/security_assessment.html\nJeremy Hylton, MIT Card Security Is ``Laughable'' The Tech, Vol 115, No 16,\nPg 1, 7 Apr 1995\nDana Levine, MIT Card Upgrades Lead to Expansion The Tech, Vol 119, No 47,\n5 Oct 1999\nMIT Reports to the President 2000-2001: Dean for Student Life - MIT Card\nOffice 2001: http://web.mit.edu/annualreports/pres01/07.00.html#card\nS. Hodges and M. Harrison Demystifying RFID: Principles & Practicalities 2003:\nMIT Auto ID Center\nOliver Kommerling and Markus G. Kuhn, Design Principles for Tamper-\nResistant Smartcard Processors 1999:\nhttp://www.cl.cam.ac.uk/ mgk25/sc99-tamper.pdf\nAri Juels, Minimalist Cryptography for Low-Cost RFID Tags October 2003\nAri Juels, Ronald L. Rivest and Michael Szydlo, The Blocker Tag: Selective\nBlocking of RFID Tags for Consumer Privacy 2003: In Proceedings of 10th ACM\nConference on Computer and Communications Security (CCS 2003)\nMark P. Hurst, Deal of Student Service Card Deck Reveals Jokers The Tech\nVol 14, No 12, Pg 5, 8 Mar 1994\nStanford University Information Technology Systems and Servies, Campus Card\nSecurity and Confidentiality 2003:\nhttp://www.stanford.edu/dept/itss/services/campuscard/security.ht\nml\nAmy S. Bruckman, MIT Card Holds Promise and Pitfalls: Questions of Privacy\nand Security MIT Faculty Newsletter Vol 8, No 1, Pg 18, October 1995. Also\navailable at\nhttp://www.ai.mit.edu/people/andre/mit_card/supplemental/asb-fnl-\nv8n1.txt\nMIT Card Office, Privacy Policy http://web.mit.edu/mitcard/privacy.html\nPrivacy Rights Clearinhouse, A Review of the Fair Information Principles: The\nFoundation of Privacy Public Policy 1997-2004:\nhttp://www.privacyrights.org/ar/fairinfo.htm\n\nMassachusetts Bar Association, Mass Law Help: School Records Law\nhttp://www.massbar.org/lawhelp/legal_info/index.php?sw=236&vt=3#s\nchoolrecords\nU.S. Department of Education: Family Educational Rights and Privacy Act\n(FERPA) http://www.ed.gov/policy/gen/guid/fpco/ferpa/index.html\nDan Michaud, head of MIT Card Office, Unpublished Interview and/or Electronic\nCommunication Sep-Dec 2004\nJohn McDonald, Associate Director of Enterprise Services, Unpublished\nElectronic Communication December 2004\nSLP, Housemaster Roles http://web.mit.edu/residence/hm/roles.htm\nJosh Mandel, Austin Roach, Keith Winstein, MIT Proximity Card Vulnerabilities\n2004: http://web.mit.edu/keithw/Public/MIT-Card-Vulnerabilities-\nMarch31.pdf\nIndala, FlexSecur\nhttp://www.indala.com/products/flexpass/flexsecur.html\nUnpublished Conversation with Indala Sales Representative November 2004\nCSAIL Prox Card Privacy Committee http://proxcard.csail.mit.edu/ 2004\nAbout this document ...\nThe MIT ID Card System: Analysis and Recommendations\nThis document was generated using the LaTeX2HTML translator Version 2002-2-1 (1.70)\nCopyright (c) 1993, 1994, 1995, 1996, Nikos Drakos, Computer Based Learning Unit,\nUniversity of Leeds.\nCopyright (c) 1997, 1998, 1999, Ross Moore, Mathematics Department, Macquarie\nUniversity, Sydney.\nThe command line arguments were:\nlatex2html -split 0 mit_id.tex\nThe translation was initiated by J.D. Zamfirescu on 2004-12-11\n\n... entry;1\nThis question was ``In your opinion, how long should MIT keep [entry data]\nrecords?''\n... ID.2\nThis history of the MIT ID is highly indebted to [2], a draft document maintained\nby MIT Information Systems. The MIT policy for protection of personal data can\nbe found in chapter 11 of [3]. The Tech Info document entitled ``People Related\nProjects'' is [4].\n...23\nTaking after the document that outlined its creation, the new database that would\nmanage the new MIT ID system was called the ``People Database.'' This\nrepresented version 1.0 of the MIT ID storage and lookup system. It was not until\nversion 2.0 in the fall of 1997 that the system received its current name, MIT ID\nDatabase.\n... stolen.4\nTo this day, dormitories and some other places on campus require students to\nleave their ID card as collateral for items borrowed. Likewise, it is still the stated\npolicy of the MIT Card Office that students should never agree to leave their card\nas collateral.\n... suggested.5\nDeHon discovered that when a card was reported stolen and a new one reissued to\na student, the only difference between the stolen card and the new card was that a\ncounter encoded on the magnetic stripe was incremented by one. Therefore, it\nwould be trivial for someone to steal a card and use it even after the card was\nreported stolen. To address this issue the counter was replaced with a randomly\ngenerated number.\n... attention.6\n1995 was indeed a focal point in the debate over the MIT Card. It was during this\nyear that most objections to the proposed technology and policies were raised and\nit was during this year that campus-wide interest reached a noticeable peak. The\nnumber of issues raised by member of the MIT community in 1995 are too\nnumerous to be listed in full here. For an excellent synopsis of this early period in\nthe MIT Card's development, see [17].\n... application.7\nCS Gold is Diebold's solution for campus card systems and supports a wide range\nof features from access control to meal plan access. There are many features in\nthe CS Gold application that proved desirable for the MIT Card, particularly its\nY2K compliance and support for an Oracle Database. For a description of the\ncurrent version of CS Gold offered by Diebold, visit the products website at:\nhttp://www.diebold.com/opccsol/Products/CSGold/CSGoldSoftware.htm.\n...levine8\n[9] article makes general reference to some of the changes implemented by the\nCard Office in addition to some of the key benefits. The Card Office itself\nreported its progress towards these upgrades in its annual Reports to the President.\nReports to the President from 1994 to 2003 can be located at:\nhttp://web.mit.edu/annualreports/. One of the key benefits of the 1999\nFootnotes\n\nupgrade outlined by the card office was the ability to connect card readers to the\ncentral computer system via the MIT network. Prior to this ability, a wire had to\nconnect each reader to the server in E32.\n... spring.9\nA client station is the computer system that connects to the MIT Card system to\nauthenticate access. The client system allows for local access policies to be set. A\nfull description of this system and other details necessary for a department or lab\nto setup use of the MIT Card for access control can be found on the MIT Card\nOffice website at: http://web.mit.edu/mitcard/department.html.\n... staff.10\nTo date the MIT Card Advisory Council has made no known recommendations or\nreports. In fact, the council has no web site and minutes from its meeting are not\npublished in any easily accessible location.\n\n... 32.11\nThe details of RFID technologies and the particulars of MIT's implementation are\ndiscussed in section 6.\n... (LowCo).12\nCoercivity is the measurement of the strength of the magnetic field required to\naffect data encoded on the strip.\n... ISO13\nInternational Organization for Standardization\n... cards14\nFor more infromation see\nhttp://www.idedge.com/ID_Card_Learning_Center/Smart_Cards/Contact\n_Smart_Cards.cfm.\n... ISO/IEC15\nInternational Electrotechnical Commission\n... memory.16\nFor more information, see\nhttp://www.biocentricsolutions.com/media/Tokens.pdf.\n... reader.17\nFor more information, see\nhttp://www.idedge.com/ID_Card_Learning_Center/Smart_Cards/Contact\nless_Smart_Cards.cfm.\n... card18\nhttp://www.calypsonet-asso.org\n... card19\nhttp://www.oystercard.com\n... areas:20\nFor more information see\nSmartcard Technology and Security,\nhttp://people.cs.uchicago.edu/~dinoj/smartcard/security.html.\n... array.21\nFor more information, see\nhttp://www.st.com/stonline/press/news/year1998/t138ma.htm.\n\n... Card.22\nFor more information see\nhttp://www.indala.com/pdf/products/FlexISO_Imageable_Card.pdf\n...std223\nFigures are from http://www.varo-\ninform.com/adv_poly_plasticcards_gost_eng.htm\n... reader24\nFor more information, see\nhttp://www.indala.com/pdf/products/Arch_Data_Sheet.pdf.\n... California.25\nFor more information, see\nhttp://www.sonicwall.com/General/DisplayDetails.asp?id=207.\n... owner.26\nUnder earlier versions of the card, this 42-bit code was merely incremented when\na card was reported as lost or stolen - an obvious vulnerability. However, it\nappears that now a random value is assigned for the 42-bit code.\n... card.27\nA brief Google search reveals a number of websites with instructions for how to\ncopy an RFID card.\n... vulnerability.28\nSince the MIT Card can also control monetary assets - in many cases more than\nthe HK$250 that can be stored on an Octopus Card - it is vital that these assets be\nstrongly protected.\n... elements.29\nDan Michaud has discussed with us his concerns about possible his potential\nsuccessors.\n\nJ.D. Zamfirescu 2004-12-11"
    },
    {
      "category": "Resource",
      "title": "acluamicusbrief.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/7e0820af3c6fa557e1aafc520bfab2ce_acluamicusbrief.pdf",
      "content": "In the United States Court of Appeals\nfor the Sixth Circuit\nNo. 94-6648\nNo. 94-6649\n-----------------------\nROBERT ALAN THOMAS\nand\nCARLEEN THOMAS,\nAppellants,\nvs.\nUNITED STATES OF AMERICA,\nAppellee\nAPPEAL FROM THE UNITED STATES DISTRICT COURT\nFOR THE WESTERN DISTRICT OF TENNESSEE\nBRIEF AMICUS CURIAE OF\nTHE AMERICAN CIVIL LIBERTIES UNION FOUNDATION,\nAMERICAN CIVIL LIBERTIES UNION OF NORTHERN CALIFORNIA,\nAMERICAN CIVIL LIBERTIES UNION OF TENNESSEE,\nTHE NATIONAL WRITERS UNION,\nFEMINISTS FOR FREE EXPRESSION,\nAND THE THOMAS JEFFERSON CENTER FOR THE\nPROTECTION OF FREE EXPRESSION\nIN SUPPORT OF APPELLANTS\nChristopher A. Hansen\nMarjorie Heins\nAmerican Civil Liberties Union\nFoundation\n132 West 43rd Street\nNew York, NY 10036\n(212) 944-9800\n[page i]\n\nTABLE OF CONTENTS\nTABLE OF AUTHORITIES . . . . . . . . . . . . . . . . . . . . . ii\nDISCLOSURE OF CORPORATE AFFILIATIONS . . . . . . . . . . . . iii\nINTEREST OF AMICI. . . . . . . . . . . . . . . . . . . . . . . 1\nINTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . 2\nSTATEMENT OF THE CASE. . . . . . . . . . . . . . . . . . . . . 4\nSUMMARY OF ARGUMENT. . . . . . . . . . . . . . . . . . . . . . 8\nARGUMENT . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\nI. THE THOMASES DID NOT VIOLATE 18 U.S.C. Section 1465.. 10\nA. Criminal Laws Should be Strictly Construed, Especially Where First\nAmendment Values Are at Stake 10\nB. Because They Did Not Use a Private Conveyance to Transport a\nTangible Object, the Thomases Did Not Violate the Statute 11\nC. Because They Did Not \"Transport\" Anything, the Thomases Did Not\nViolate the Statute 17\nII. EVEN IF SECTIONS 1465 APPLIED TO THIS CASE, THE DISTRICT\nCOURT\nERRED IN DEFINING THE \"COMMUNITY\" WHOSE STANDARDS DETERMINED\nWHETHER THE\nMATERIAL WAS \"PATENTLY OFFENSIVE\" AND APPEALED TO THE\n\"PRURIENT INTEREST\nCONCLUSION . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n[page ii]\nTABLE OF AUTHORITIES\nCases\nDowling v. United States,\n473 U.S. 207 (1985) . . . . . . . . . . . . . . . . . . . 10\n\nFCC v. Pacifica Foundation,\n438 U.S. 726 (1978) . . . . . . . . . . . . . . . . . . . 30\nJoseph Burstyn, Inc. v. Wilson,\n343 U.S. 495 (1952) . . . . . . . . . . . . . . . . . . . 30\nKeyishian v. Board of Regents,\n385 U.S. 589 (1967) . . . . . . . . . . . . . . . . . . . 11\nLiparota v. United States,\n471 U.S. 419 (1985) . . . . . . . . . . . . . . . . . . . 11\nMiami Herald v. Tornillo,\n418 U.S. 241 (1974) . . . . . . . . . . . . . . . . . . . 30\nMiller v. California,\n413 U.S. 15 (1973). . . . . . . . . . . . . 9, 20, 25, 27-31\nMishkin v. New York,\n383 U.S. 502 (1966) . . . . . . . . . . . . . . . . . . . 20\nParis Adult Theatre I v. Slaton,\n413 U.S. 49 (1973). . . . . . . . . . . . . . . . . . . . 29\nPope v. Illinois,\n481 U.S. 497 (1987) . . . . . . . . . . . . . . . . . . . 31\nRed Lion Broadcasting v. FCC,\n395 U.S. 367 (1969) . . . . . . . . . . . . . . . . . . . 30\nRewis v. United States,\n401 U.S. 808 (1971) . . . . . . . . . . . . . . . . . . . 11\nRowan v. U.S. Post Office Dept.,\n397 U.S. 728 (1970) . . . . . . . . . . . . . . . . . . . 29\nSable Communications v. FCC,\n492 U.S. 115 (1989) . . . . . . . . . . . . . .18, 20, 26-28\nSmith v. United States,\n431 U.S. 291 (1977) . . . . . . . . . . . . . . . . . . . 31\nStanley v. Georgia,\n394 U.S. 557 (1969) . . . . . . . . . . . . . . 9, 10, 27-30\n\n[page iii]\nUnited States v. Carlin Communications,\n815 F.2d 1367 (10th Cir. 1987). . . . . . . . . . .8, 12, 13\nUnited States v. Alpers,\n338 U.S. 680 (1950) . . . . . . . . . . . . . . . . . . . 14\nUnited States v. LaMacchia,\n871 F. Supp. 535 (Mass. 1995) . . . . . . . . . . . . 10, 11\nUnited States v. Olano,\n507 U.S. __, 113 S. Ct. 1770, 123 L.Ed.2d 508 (1993). . . 19\nUnited States v. Orito,\n413 U.S. 139 (1973) . . . . . . . . . . . . . . . 20, 28, 29\nUnited States v. Reidel,\n402 U.S. 351 (1971) . . . . . . . . . . . . . . . . . . . 28\nUnited States v. Wiltberger,\n5 Wheat. 76 (1820). . . . . . . . . . . . . . . . . . . . 10\nStatutes and Rules\n18 U.S. C. Section 1461. . . . . . . . . . . . . . . . . . 11, 14\n18 U.S. C. Section 1463. . . . . . . . . . . . . . . . . . . . 11\n18 U.S.C. Section 1460 . . . . . . . . . . . . . . . . . . . . 11\n18 U.S.C. Section 1462 . . . . . . . . . . . . . . . . .4, 14, 15\n18 U.S.C. Section 1464 . . . . . . . . . . . . . . . . . . . . 11\n18 U.S.C. Section 1465 . . . . . . . . . . . . . . 4, 5, 8-21, 32\n18 U.S.C. Section 2251 . . . . . . . . . . . . . . . . . . 16, 19\n47 U.S.C. Section 223. . . . . . . . . . . . . . . . . 15, 16, 18\nChild Pornography and Obscenity Enforcement Act of 1988, P.L. 100-690,\nSection 7501. . . . . . . . . . . . . . . . . . . . . . . 16\nSection 7511. . . . . . . . . . . . . . . . . . . . . . . 16\nSection 7521. . . . . . . . . . . . . . . . . . . . . . . 16\n\nSection 7524. . . . . . . . . . . . . . . . . . . . . . . 16\nFed. R. Crim. Pro. 52(b) . . . . . . . . . . . . . . . . . . . 19\n[page iv]\nLegislative History\n101 Cong. Rec. A4093 (June 8, 1955). . . . . . . . . . . . . . 15\n101 Cong. Rec. A4051 (April 16, 1955). . . . . . . . . . . . . 15\n131 Cong. Rec. S8241-43 (June 17, 1985). . . . . . . . . . . . 15\n134 Cong. Rec. S13328-29 (Sept. 26, 1988). . . . . . . . . . . 16\nHouse Report 690, 84th Congress (June 1, 1955) . . . . . . . . 14\nSenate Report No. 113, 84th Congress, 1955 U.S. Code Congressional and\nAdministrative News 2210 . . . . . . . . . . . . . . . . . . . 14\nOther Authorities\nAlburty, Stevan, \"It's a Buyer's Marketplace,\"\nNew York Times, March 20, 1995 . . . . . . . . . . . . . . . . 22\n\"Smut Ban Backed for Computer Net,\" New York Times,\nMarch 24, 1995 . . . . . . . . . . . . . . . . . . . . . . . . 19\n\"The Global Information Infrastructure: Agenda for\nCooperation,\" U.S. Information Infrastructure Taskforce,\nFeb. 15, 1995. . . . . . . . . . . . . . . . . . . . . . . 21, 22\nLewis, Peter, \"Computer Jokes and Threats Ignite Debate on Anonymity,\" New\nYork Times, Dec. 31, 1994. . . . . . . . . . . 21\nLockhart, William, \"Escape From The Chill of Uncertainty; Explicit Sex and\nthe First Amendment,\" 9 Georgia L.Rev. 533 (Spring 1975). . . . . . . . .\n. . . . . . . . . . . . . . 31\nMichael I. Meyerson, \"The Right to Speak, the Right to Hear,\nand the Right Not to Hear: The Technological Resolution\nto the Cable/Pornography Debate,\" 21 U. Mich J.L. Ref.\n137 (1988) . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n\nQuittner, Joshua, \"Computers in the 90's,\" Newsday,\nAugust 16, 1994. . . . . . . . . . . . . . . . . . . . . . . . 26\nRheingold, Howard, The Virtual Community\n(Addison-Wesley, 1993) . . . . . . . . . . . . . . . . . . . . 22\nSteingarten, Jeffrey, \"What's Cooking in Cyberspace,\"\nVogue, March, 1995 . . . . . . . . . . . . . . . . . . . . . . 29\n[page 1]\nINTEREST OF AMICI\nThe American Civil Liberties Union (ACLU) is a nationwide,\nnonpartisan organization of nearly 300,000 members dedicated to defending\nthe principles of liberty and equality embodied in the Bill of Rights.\nThe ACLU of Northern California and the ACLU of Tennessee are affiliates\nof the ACLU in those areas.\nThroughout its 75 year history, the ACLU has been particularly\nconcerned with any abridgement of the freedoms guaranteed by the First\nAmendment. The ACLU has, therefore, appeared before the Supreme Court and\nthe Courts of Appeals in numerous cases involving the First Amendment,\nboth as direct counsel and as amicus curiae. Because this case raises an\nimportant First Amendment issue of organizational concern to the ACLU, we\nrespectfully submit this brief as amicus curiae for the Court's\nconsideration.\nThe National Writers Union is the 4,000-strong labor union for\nfreelance writers founded in 1983. Its members include investigative\njournalists, book authors, technical writers, political cartoonists,\npoets, textbook authors, and multimedia contributors. The First Amendment\nis of paramount interest to its members, many of whom use computer\ncommunications extensively in their work.\nFeminists for Free Expression (FFE) is an organization of diverse\nfeminist women who share a commitment both to gender equality and to\npreserving the individual's right and responsibility to read, view, and\nproduce media materials of her\n[page 2]\nor his choice, free from government intervention \"for our own good.\" In\nsupport of those goals, FFE has become active in a variety of litigation,\nlobbying, and educational efforts to oppose censorial measures which, even\nif well-intended, are ultimately counterproductive to the goal of equality\nfor women. In particular, FFE believes that obscenity laws, as applied to\ncensor media materials solely on the basis of erotic content, are an\nanomalous holdover from Victorian times, are essentially inconsistent with\n\nfeminist values, and, indeed, have historically been used to silence\nwomen, from the prosecutions of birth control advocate Margaret Sanger to\naccusations of obscenity against performance artists like Holly Hughes and\nKaren Finley.\nThe Thomas Jefferson Center for the Protection of Free Expression\nis a nonprofit, nonpartisan institution in Charlottesville, Virginia,\nwhose sole mission is the safeguarding of freedoms of expression defined\nin the First Amendment of the United States Constitution. The Center has\npursued its mission in several ways, including testimony before\nlegislative and administrative bodies, public statements, and involvement\nin litigation that may affect free expression. The Center has filed\nbriefs amicus curiae in state and federal courts in a wide variety of\ncases, seeking recognition and affirmation of freedoms of speech and\npress.\nINTRODUCTION\nThis is an obscenity case, but it is not just another obscenity\ncase. This case represents one of the first, if not\n[page 3]\nthe first, applications of existing obscenity statutes to the novel\ncontext of computers. The exponential growth in computer technology, and\ninternational computer networks such as the Internet, is transforming the\nnature of communication. Computer networks have created vast new fora for\nthe exchange of ideas. They have created new communities with new\nopportunities for people with similar interests to communicate with each\nother. Until now, computer networks have been faithful to the values that\nunderlie the First Amendment. They have fostered, encouraged, and even\nnurtured the robust exchange of ideas.\nIn this case, the government seeks to use a criminal law never\nintended to apply to computer communications, to put a break on that\ndevelopment, to stifle the explosive creativity and breadth of expression\noccurring on computer networks. Where Congress has moved slowly and\ndeliberately, acting only where the implications of action, and the need\nfor action, are fully explored, the prosecutors seek to rush, stretching a\nfederal obscenity law beyond its intended purpose and imposing the \"local\ncommunity standards\" of a conservative jurisdiction to communications\noriginated elsewhere and existing within that jurisdiction only in the\nprivacy of the home. In seeking to impose censorship on computer networks\nlike the Internet through the mechanism of a single case, the government\nrisks not only the chilling of protected speech, but its direct\nsuppression. By doing so in the context of a criminal prosecution, the\ngovernment ignores the requirement that criminal statutes be clearly and\n[page 4]\n\nnarrowly defined, giving notice to those affected. In this area, where\nfundamental constitutional values are implicated, the courts must protect\nthose values by rejecting the government's clumsy attempt to censor\ncommunications in cyberspace through application of an obscenity law and\nstandards wholly inappropriate for this new medium.\nSTATEMENT OF THE CASE\nDefendants-Appellants Robert Thomas and Carleen Thomas (\"the\nThomases\") operate a computer bulletin board and related distribution\nbusiness in Milpitas, California (near San Francisco) involving sexually\nexplicit words and pictures. They were convicted of two groups of\noffenses in the United States District Court for the Western District of\nTennessee. First, they were convicted of several violations of 18 U.S.C.\nSection 1462 as a result of mailing certain videotapes to a postal\ninspector in Tennessee. (TR 905). Amici take no position on the validity\nof the convictions on those counts, and this brief does not discuss the\nfacts or law applicable to those convictions.\nSecond, they were convicted of several violations of 18 U.S.C.\nSection 1465 as a result of visual images posted onto their computer\nbulletin board in California that were obtained by a postal inspector in\nTennessee. (TR 895-96). These convictions raise important questions\nconcerning criminal statutes that were passed for one purpose and are now\nbeing stretched to achieve another purpose. They also raise important and\nlargely novel\n[page 5]\nquestions concerning the regulation of obscenity in the world of computer\nexchange of information, the so-called information superhighway or\ncyberspace. For the reasons stated below, amici respectfully urge the\nCourt to reverse the convictions pursuant to 18 U.S.C. Section 1465.\nA computer bulletin board like the Thomases' consists of\ninformation contained in one or more computers that can be accessed by\nanother computer over telephone wires by means of a modem. (James McMahon\nat TR 256-57). Although, for reasons discussed below, the example is\nimperfect, for lawyers, the most well known services analogous to that of\nthe Thomases are LEXIS or WESTLAW.\nLike LEXIS or WESTLAW, the data in the Thomases' computer were not\navailable to the general public. People who wanted access had to fill out\nan application and pay an access fee. (David Dirmeyer at TR 302). The\napplication process served several purposes. It contributed to the profit\nof the business. It ensured that those seeking access understood the\nnature of the data on the computer. It was part of an attempt to ensure\nthat minors were denied access to the computer. (Robert Thomas at TR\n\n------------------------------\n742). Only after an application was approved and the fee paid, were those\nseeking access given the codes needed to link their computers with that of\nthe Thomases.\n[page 6]\nUnlike LEXIS or WESTLAW, the data in the Thomases' computer\nconsisted of sexually explicit words and pictures.<1> In the Thomases'\ncase, the person seeking access called a phone number connected to the\nThomases' computer. The caller was then able to see written descriptions\nof the images that had been loaded into the computer (just as the initial\nimages on LEXIS and WESTLAW describe the libraries on those services).\n(David Dirmeyer at TR 303). If the caller had received the access codes\nas part of joining the bulletin board, he or she could then select the\nimage desired and press the appropriate keys on his or her connected\ncomputer. The image was then downloaded from the Thomases' computer to\nthe receiving computer.\nThat is, the image was converted into a series of digital 1's and\n0's. (James McMahon at TR 256). From the moment this stream of 1's and\n0's left the Thomases' computer and traveled along the phone lines, it was\nnot in a format that anyone could read. Someone tapping into the phone\nline along the way, without knowing the appropriate software that had been\nused to convert the image into computer data, would find the material\nincomprehensible.<2> The receiving computer received those 1's\n1 Computer technology has reached the point where it is possible to enter\npictures into a computer which, once entered, can be accessed by any\nperson with the appropriate software. (James McMahon at TR 258, 273-75).\n2 Thus, technologically, it is as though a book had been purchased in\nCalifornia and the buyer, while still in California, encoded the entire\nbook, substituting letters (i.e. all E's are replaced by F's) to make the\nbook incomprehensible. The buyer then took the encoded book to Memphis,\ndecoding it in his home there. The software used by the Thomases to\nencode the images [continued next page]\n[page 7]\nand 0's, and the appropriate software converted them back into pictures\nwhich could then be printed at the receiving end. (James McMahon at\n259-60, 291).\nAlso unlike LEXIS or WESTLAW, the computer network run by the\nThomases, like the vast majority of computer networks, allowed the members\nto communicate with each other. Thus, a member of the network could send\nmessages from his or her computer to the Thomases, to another member of\nthe board, or to all of the members of the board. (Robert Thomas at TR\n\n------------------------------\n747).\nLike LEXIS and WESTLAW, this operation was entirely automated at the\nseller's end. Neither of the Thomases had to be on their computer, or\neven in their home, for someone seeking a picture to obtain access to it.\n(James McMahon at TR 294). After the pictures had been entered into the\ncomputer in California, no person in that state had to take any further\naction for the specific images to arrive in Tennessee. Thus, it is not\ntechnologically accurate to describe the Thomases as sending pictures to\nothers. Instead, those seeking the pictures went to the computer where\nthe images were loaded and pulled them out.\nIn the summer of 1993, a U.S. postal inspector in Memphis,\nTennessee became aware of the bulletin board offered by the Thomases.\n(David Dirmeyer at TR 301). He first looked at the public portion of the\nboard which generally described the information available. (David\nDirmeyer at TR 303-312). He then\n2[continued] was GIF, a fairly common software used to translate pictures\ninto computer data. (James McMahon at TR 273-75).\n[page 8]\njoined the bulletin board by filling out an application, using a\nfictitious name, and paying a fee. (David Dirmeyer at TR 312-318). Using\nhis computer in Memphis, he then obtained the digital representations of\nseveral of the visual images in the Thomases' computer. (David Dirmeyer\nat TR 338). He used his computer software in Memphis to turn the digital\nentries into viewable images and to print them. It is those images that\nthe prosecution asserted were legally obscene in Memphis and that resulted\nin the convictions pursuant to 18 U.S.C. Section 1465.\nSUMMARY OF ARGUMENT\nThree of the elements necessary for a violation of Section 1465,\nthe statute under which the Thomases were convicted, were not present in\nthis case. First, as the Tenth Circuit held in United States v. Carlin\nCommunications, 815 F.2d 1367 (10th Cir. 1987) (\"Carlin\"), Section 1465\nprohibits transportation of tangible objects, not intangible computer\nimpulses. Second, the statute covers travel by private conveyances, not\nby phone lines. Finally, Section 1465 criminalizes the behavior of the\nperson who transports the material. In this case, it was the postal\ninspector, and not the Thomases, who transported the material. The\nprosecution is thus not only attempting to use a statute that is on its\nface inapplicable to computer exchange of information; such exchange was\nnot even contemplated when the statute was passed. It is up to Congress,\n\nnot this Court, to define the appropriate approach\n[page 9]\nto the exchange of sexually explicit material by computer network.\nEven if Section 1465 were deemed applicable to computer exchange,\nhowever, the district court erred when it instructed the jury on the\ndefinition of the \"community standards\" portion of the test created by\nMiller v. California, 413 U.S. 15 (1973), for defining obscenity. There\nwas an insufficient nexus between actions taken by the Thomases and the\ngeographic community in Memphis, Tennessee to justify Memphis or Tennessee\nas the relevant community. Computer technology has created new\n\"communities\" or groups of individuals who communicate among themselves,\nsharing thoughts, ideas, and values. These communities do not exist\ngeographically, but they exist nonetheless. The district court should\nhave instructed the jury to apply the standards of the community involved,\nthat of the members of the Thomases' bulletin board.\nIn Stanley v. Georgia, 394 U.S. 557 (1969), the Supreme Court held\nthat it was unconstitutional to punish someone for obscene material held\nin the privacy of his or her own home. Although in subsequent cases, the\nCourt limited Stanley by allowing prosecution for transport of material,\nwhether intended for the home or not, the computer technology at issue in\nthis case undercuts the rationales of those cases and provides renewed\nvitality to the values that underlie Stanley. The Thomases did not\ntransmit the material to Memphis. As the material traveled over the phone\nlines, it was an incomprehensible stream of 1's\n[page 10]\nand 0's. It utilized software, and those who did not have the appropriate\nmatching software could not read it. Except when sought by law\nenforcement, when the material arrived at its destination, it was almost\nalways arriving in a person's home and, only when the recipient's computer\nsoftware translated it back into images, could it be seen. In short,\nthere is insufficient basis, beyond the values of privacy and home\nprotected by Stanley, for finding any link between this material and\nMemphis, Tennessee. For this reason, the district court's instruction\nthat the \"community\" was Memphis was error and the convictions should be\nreversed.\nARGUMENT\nI. THE THOMASES DID NOT VIOLATE 18 U.S.C. SECTIONS 1465.\nA. Criminal Laws Should be Strictly Construed, Especially Where\nFirst Amendment Values Are at Stake.\n\n------------------------------\nThe Supreme Court has plainly stated that criminal statutes must\nnot be stretched beyond their strict meaning:\nThe rule that penal laws are to be construed strictly, is perhaps not\nmuch less old than construction itself. It is founded on the tenderness\nof the law for the rights of individuals; and on the plain principle that\nthe power of punishment is vested in the legislative, not in the judicial\ndepartment. It is the legislature, not the Court which is to define a\ncrime and ordain its punishment.\nDowling v. United States, 473 U.S. 207, 213-14 (1985)(quoting former Chief\nJustice Marshall in United States v. Wiltberger, 5 Wheat. 76, 95 (1820)).\nSee also United States v. LaMacchia, 871 F. Supp. 535 (Mass.\n1995)(rejecting an attempt to use the\n[page 11]\ncriminal wire fraud statute to punish an arguable violation of copyright\nlaws in cyberspace); Liparota v. United States, 471 U.S. 419, 427\n(1985)(noting \"our longstanding recognition of the principle that\n'ambiguity concerning the ambit of criminal statutes should be resolved in\nfavor of lenity'\" (quoting Rewis v. United States, 401 U.S. 808 (1971)).\nThese principles have particular force when the government attempts to\ncriminalize behavior that, as a result of new technology, was not even\ncontemplated when the original statute was passed.\nThese principles also have special force where First Amendment\nrights are at stake. Keyishian v. Board of Regents, 385 U.S. 589, 603\n(1967)(\"Precision of regulation must be the touchstone in an area so\nclosely touching our most precious freedoms\"). In this case, the\ngovernment's attempt to force \"new wine . . . into an old bottle\" does\ndamage to those rights and should be rejected. United States v.\nLaMacchia, 871 F. Supp. at 536.\nB. Because They Did Not Use a Private Conveyance to Transport a\nTangible Object, the Thomases Did Not Violate the Statute.\n18 U.S.C. Sections 1460 et. seq. define federal obscenity\noffenses. Sections 1461-1465 prohibit transportation of obscene material\nby mail (Sections 1461, 1463), by importation or transport via common\ncarrier (Section 1462), by broadcast (Section 1464) and by private\nconveyance (Section 1465).<3> None of these statutes, including the one\nthat the\n3 Section 1460 prohibits sale of obscene pictures on federal land.\n[page 12]\n\ngovernment chose in this case, Section 1465, deals with computer\ncommunications, such as those involving the Thomases' bulletin board.\nIn United States v. Carlin Communications, 815 F.2d 1367 (10th\nCir. 1987), the Tenth Circuit held that Section 1465 governed the physical\ntransportation of tangible objects and was inapplicable to intangible\ncommunications over telephone wires. \". . . Section 1465 . . . is\nrestricted in its terms to the transportation of tangible objects. Read\nas a whole, it is simply inapplicable to telephone messages.\" Id at 1371.\nThe Circuit upheld dismissal of indictments charging a telephone service\noffering sexually explicit messages with violation of Section 1465.\nAlthough this case involves computer communications over phone lines, not\nrecorded messages, application of the holding in Carlin to the facts of\nthis case requires reversal of the convictions based on Section 1465.\nThe Circuit in Carlin based its holding on both the language and\nlegislative history of Section 1465. Section 1465 makes it illegal to\n\"transport[] . . . an obscene, lewd, lascivious, or filthy book,\npamphlet, picture, film, paper, letter, writing, print, silhouette,\ndrawing, figure, image, cast, phonograph recording, electrical\ntranscription or other article capable of producing sound or any other\nmatter of indecent or immoral character . . .\"\nThe Tenth Circuit emphasized the list of items and the phrase \"or other\narticle\" in concluding that the list was intended to be and was a list of\n\"material\" or \"tangible\" objects. Carlin, 815 F.2d at 1371. That\nconclusion is correct.\n[page 13]\nIn this case, the material that traveled to Memphis consisted of\nthe intangible 1's and 0's that constitute computer code. More\nspecifically, the computer interprets pulses of electricity (1's) and the\nabsence of such pulses (0's). Thus the material was just as intangible as\nthe phone calls at issue in Carlin, which, depending on the phone lines\nused, consisted of either similar digital transmission or sound waves.\nThe only relevant point at which the material in this case was tangible in\nany form was after the postal inspector used his computer software in\nMemphis to translate the computer impulses and then to order the image\nprinted on the printer attached to his computer.\nThe government can be expected to argue that because the list in\nSection 1465 includes \"images,\" it covers the material in this case.\nThere is no reason to suppose that Congress used the word \"images\" to\ninclude non-tangible material. Indeed, its inclusion in a long list of\ntangible material suggests the contrary. Moreover, the matter in this\n\n------------------------------\ncase that went from California to Memphis was not an \"image.\" It was\ninstead a series of 1's and 0's that could not become an \"image\" until it\narrived at a computer in Memphis and was translated by the appropriate\nsoftware. The material did ultimately become an image, but it was the\npostal inspector who made it so, not the Thomases.\nThe legislative history of Section 1465 strongly reinforces the\nconclusion of the Tenth Circuit that the statute does not cover computer\nexchange of information. Indeed, the Circuit found that \"the legislative\nhistory ... makes clear the fact that Congress\n[page 14]\nhad no understanding or intent that these sections would reach telephone\ncalls.\" 815 F.1d at 1371. The legislative history also establishes that\nthe statute was intended to and does prohibit exchange of obscene matter\nonly by means of private conveyance and not by phone lines or, indeed,\nother common carrier lines that might carry tangible things.\nThe statute dates back to 1955, at a time when computer exchange\nwas unknown. Thus, at the time of passage, Congress could not have\nintended to cover computer exchange of data. Section 1465 was added in\n1955 to a more general set of statutes governing transmission of obscene\ninformation.<4> Section 1461 governed \"transportation of obscene matter by\nmail and section 1462 prohibit[ed] the use of common carriers for the\ntransportation of that matter\" but no statute governed \"transportation by\nprivate conveyance.\" House Report 690, 84th Congress, June 1, 1955 at 2.\nSection 1465 was added to close \"a serious loophole in the law which has\npermitted this ... to be distributed by private automobiles and by trucks.\nThis could no\n4 At the same time that Section 1465 was added, Section 1461 was amended\nin response to a different problem. There had been doubt about whether\nthe obscenity statutes covered obscene phonograph recordings as well as\nprinted matter. The Supreme Court had decided that Section 1462 did cover\nsound recordings. United States v. Alpers, 338 U.S. 680 (1950). Congress\ndetermined that there should be no ambiguity about any of the obscenity\nstatutes and therefore added additional descriptions to Section 1461 to\nmake clear that it also prohibited phonograph recordings, as well as other\nobscene \"article[s], matter[s], thing[s], device[s], or substance[s].\"\nSenate Report No. 113, 84th Congress, reprinted in 1955 U.S. Code\nCongressional and Administrative News 2210. The list still described\ntangible things, not the intangible computer exchanges in this case.\n[page 15]\nlonger be done under this legislation.\" 101 Cong. Rec. at A4051 (Remarks\n\n------------------------------\nof Representative Keating, Tuesday, April 16, 1955). See also 101 Cong.\nRec. at A4093 (Remarks of Representative Poff, June 8, 1955). The\nmaterial contained in the Thomases' computer was not tangible material\ntransported by private conveyance, and thus falls outside Section 1465.\nSection 1465 was amended in 1988. The government can be expected\nto argue that the 1988 amendments expanded it to include computer\nexchanges over phone wires. The 1988 amendments, however, suggest exactly\nthe opposite conclusion.\nEfforts to amend the federal obscenity statutes began as early as\n1985. At that time, Senator Trible introduced legislation \"to address ...\nthe use of computers ... to transmit prurient material.\" 131 Cong. Rec.\nat S8241-43 (June 17, 1985). He proposed legislation only after writing\nto the Attorney General of the United States to ask if existing law\ncovered that situation. Id. at S8242. The Attorney General first\nsuggested that it was possible that computer transmission might be illegal\nunder 47 U.S.C. Section 223 and/or 18 U.S.C. Section 1462. Id. at S8243.\nHe then suggested that Section 1465 would not prohibit the computer\ntransmissions. Quoting the remarks of Representative Keating, the\nAttorney General said that \"the legislative history suggests rather\nstrongly that this statute was enacted to cover private carriage rather\nthan use of a common carrier ... Therefore, if telephone companies are\ncommon carriers, it would appear that this section does not apply.\nMoreover, the section is limited to\n[page 16]\ntransportation for the purpose of sale or distribution.\" Id. at S8243.\nWhen the amendments were adopted as part of the Child Pornography\nand Obscenity Enforcement Act of 1988, P.L. 100-690, Section 7501 et.\nseq., Congress did address the use of computers to exchange sexual subject\nmatter, if the material involved children. Thus, Congress amended 18\nU.S.C. Section 2251 to add to its child pornography ban \"by any means\nincluding by computer.\" P.L. 100-690, Section 7511. No similar amendment\nwas made to Section 1465. P.L. 100-690, Section 7521. In other words,\nCongress knew of the problem and knew the proper language to use to\nincorporate computer exchange into existing law, but chose to prohibit\nthat exchange only for pornographic material involving children and not\nfor obscene material transported by private conveyance, as proscribed by\nSection 1465.<5>\n5 In addition, Congress amended 47 U.S.C. Section 223, governing\ntransmission of obscene material over phone lines. P.L. 100-690, Section\n7524. Whether those amendments would make the actions in this case\n\nillegal or not, and amici do not believe that they do, the Thomases were\nnot charged with violation of Section 223.\nFinally, Congress amended Section 1465 to add a prohibition\nagainst the \"use of a facility or means of interstate commerce\" to\ntransport obscenity. Debate on that addition reveals that its purpose was\nto ease the burden of proof on the government so that it no longer had to\nprove the precise means of transport used. 134 Cong. Rec. S13328-29\n(Sept. 26, 1988).\nIn the Senate, during debate, Senator Hatch quoted U.S. Attorneys\nas asserting that\n\"the present requirement of specific proof that obscene material\ntraveled in interstate commerce is a weakness in the law . . . . By using\na variety of commercial carriers, transporting material by private\nconveyance . . . distributors are able to obstruct and in some cases\nprevent investigations and prosecutions.\"\nId. The Senator then described the added language: [continued next page]\n[page 17]\nIn this case, the district court instructed the jury that a\nviolation of 18 U.S.C. Section 1465 could be found if defendants used \"any\nmethod of communication between different states.\" (TR 898). That\ninstruction was incorrect. In fact, the statute does not cover\n\"communication\" of intangible matter by computer exchange over phone\nwires. The statute only covers transportation of tangible items by\nprivate conveyance. The \"communication\" in this case was not of that kind\nand was thus not prohibited by Section 1465.\nC. Because They Did Not \"Transport\" Anything, the Thomases Did Not\nViolate the Statute.\nSection 1465 makes it illegal to \"transport\" or \"travel\" or \"use a\nfacility or means of interstate commerce for the purpose of transporting\"\nobscene material. The words used require that the seller of the material\ntake some action to transport the material physically. The Thomases did\nplace the images into their computer in California, allowed the postal\ninspector to join the bulletin board, and gave him the codes needed to\naccess the computer. However, the Thomases took no additional action that\ncould be described as \"transport\" of the images.\nAs explained above, the inspector was able to sign on to the\nbulletin board, select a photograph, pull it out of the Thomases'\n\n------------------------------\n------------------------------\n5 [continued] It would prohibit the use of a facility or means of commerce\nfor obscenity trafficking. In other words, under the language of the\nprovision, it would not be necessary for the Government to demonstrate\nthat obscene material actually traveled interstate, but only that a\nfacility or means of interstate commerce was used. Id.\n[page 18]\ncomputer and bring it to Memphis, all without the Thomases being involved\nor even present. Thus, technologically, the process is not analogous to\nmail order where a seller receives a request and then takes the steps\nneeded to transmit the order to a buyer by putting it in the mail or\ngiving it to a company like Federal Express. The process instead more\nclosely resembles a bookstore transaction, where the seller makes the\npictures available, and a buyer can come to the store, purchase a copy of\none or more of the pictures, and take them back home. In this case, the\nbuyer traveled in cyberspace, not through airports. However, the process\nis analogous. To use the language of the statute, the person who was\n\"transporting\" or \"traveling\" was the postal inspector, not the Thomases.\nThus, the Thomases did not violate the statute.<6>\nThe government may try to argue that this distinction (and the\nones in the prior section), based on the nature of the medium involved in\nthis case, are merely \"nitpicking.\" However, such distinctions are\ncrucially important in criminal law, and illustrate a more fundamental\nconcern about the applicability of\n6 See TR 861. A similar argument might be made for the protection of\npre-recorded audio messages accessible over phone lines (so-called\ndial-a-porn). A review of the briefs and opinions in the principal\nSupreme Court case involving that medium, Sable Communications v. FCC, 492\nU.S. 115 (1989), suggests that this argument was not raised or addressed.\nMoreover, 47 U.S.C. Section 223, the relevant statute, is more broadly\nwritten than Section 1465. For example, Section 223 makes the actions\nillegal \"regardless of whether the maker of such communication placed the\ncall.\" In addition, Section 223 provides a defense for those who\n\"restrict access to the prohibited communication\" to adults, as the\nThomases sought to do. 47 U.S.C. Section 223(b)(3).\n[page 19]\ncriminal laws to new contexts. Congress did not consider the problem of\ncomputer exchange of obscene photographs when it adopted Section 1465\nbecause the technology did not then exist for such exchange. The 1988\namendments did not address computer exchange except with respect to child\n\n------------------------------\npornography. See 18 U.S.C. Section 2251. Now that the technology is well\ndeveloped, the question is whether the courts will take language clearly\nintended to cover a different situation, and \"interpret\" it beyond the\nplain language in order to justify applying it to a new technology, or\nwhether the courts will wait for Congress to pass legislation that covers\nthe new situation.<7>\nThe Supreme Court has been clear. Particularly in the context of\ncriminal statutes impinging on First Amendment values, courts may not\nstretch to apply existing statutes to situations not covered by the\nlanguage or contemplated by the drafters. See section I.A above. This\ncourt should follow those principles and hold that Section 1465 does not\napply to the conduct in this case.<8>\n7 At this writing, Congress is considering legislation proposed by Senator\nJim Exon (D-Neb.), that specifically addresses sexually explicit computer\ncommunications. See \"Smut Ban Backed for Computer Net,\" New York Times,\nMarch 24, 1995, at A1.\n8 It is not clear from the record available to amici whether defense\ncounsel argued in the trial court that Section 1465 was not applicable to\nthe Thomases' conduct. Even if he did not, however, this Court must\nconsider the statute's applicability. Although certain errors can be\nwaived if not presented to the trial court, if the behavior of the\ndefendants as a matter of law was not criminal, the appellate court must\nreverse. E.g. Fed. R. Crim. Pro. 52(b); United States v. Olano, 507 U.S.\n__, 113 S. Ct. 1770, 123 L.Ed.2d 508 (1993).\n[page 20]\nII. EVEN IF SECTIONS 1465 APPLIED TO THIS CASE, THE DISTRICT COURT\nERRED\nIN DEFINING THE \"COMMUNITY\" WHOSE STANDARDS DETERMINED\nWHETHER THE\nMATERIAL WAS \"PATENTLY OFFENSIVE\" AND APPEALED TO THE\n\"PRURIENT INTEREST.\"\nThe current standards for obscenity law were established in Miller\nv. California, 413 U.S. 15 (1973). The Supreme Court created, in Miller,\na three-part test for determining if material is legally obscene. Two\nparts of that test -- patent offensiveness and appeal to the \"prurient\ninterest\" -- depend on \"applying contemporary community standards.\" 413\nU.S. at 33, quoting Mishkin v. New York, 383 U.S. 502, 508-09 (1966). In\nMiller, which involved promoting the sales of books by mailing advertising\npamphlets, the Court held that it was not error for \"community\" to be\ndefined in geographic terms to include an area less than the entire\n\ncountry. Miller, 413 U.S. at 33-34.\nIn this case, the district court instructed the jury that in\ndetermining if the pictures appealed to the prurient interest and were\npatently offensive under contemporary community standards, the jury was to\napply \"contemporary community standards from the community from which you\ncome.\" (TR 902). The district court relied on established law in the\ncontext of mail order and phone sex that permit prosecution under the\ncommunity standards of the geographic community into which the\ncommunication arrives. United States v. Orito, 413 U.S. 139 (1973); Sable\nCommunications v. FCC, 492 U.S. 115 (1989). The Thomases were convicted\nafter the jury found the images obscene according to Memphis community\nstandards.\n[page 21]\nThis case presents one of the first, if not the first,\nopportunities for an appellate court to apply existing obscenity laws to\nthe novel context of computer networks. For that reason, even if the\nCourt decides that Section 1465 applies, it should not simply apply\nexisting concepts mechanically to this novel situation. Instead, the\nCourt should examine the societal, individual, and constitutional\ninterests and determine the most appropriate method by which alleged\nobscenity should be evaluated in this new context. In doing so, the court\nshould conclude that the \"community\" in cyberspace communications is not\ngeographic at all, but instead consists of those people who have joined\ntogether on the basis of common interest, not common location, to\ncommunicate via this bulletin board. Because the district court failed to\napply this definition (and indeed explicitly rejected it, TR 726), it\nerred, and the convictions should be reversed.\nThe growth in computer technology, and computer networks, has been\nphenomenal. It has not been a local phenomenon, or even a national one,\nbut is truly global. The largest computer information exchange system,\nthe Internet, is a large network linking a number of smaller networks.\nThe Internet links at least 159 countries, and \"the majority of its users\nare not subject to United States Law.\" Lewis, Peter, \"Computer Jokes and\nThreats Ignite Debate on Anonymity,\" New York Times, Dec. 31, 1994 at 29.\nThere are now at least 20-30 million users worldwide. See \"The Global\nInformation Infrastructure: Agenda\n[page 22]\nfor Cooperation,\" (U.S. Information Infrastructure Taskforce, Feb. 15,\n1995) at 5.\nBecause of the number of people involved, the individuals who use\ncomputer networks have created a variety of electronic \"sites,\" variously\n\n------------------------------\ncalled bulletin boards (as with the Thomases) or newsgroups. These sites\nare not actual physical locations, but are places on the network where\nthose with common interests and values can \"meet\" and exchange ideas and\ninformation. Thus, if there is a community of people interested in\npre-Columbian art, or quantum mechanics, or virtually any other subject, a\nlocation will be developed for those people to share their interests. The\nrelative anonymity of the communication has fostered a willingness in some\ncontexts to share intimate confidences, confidences that many find\ndifficult if not impossible to share face-to-face. Thus, many users of\ncomputer networks report a sense of sharing, a sense of community, with\nthose they meet on the network, that is far greater than their connection\nto those who happen to live in their home town. Rheingold, Howard, The\nVirtual Community (Addison-Wesley, 1993); \"The Global Information\nInfrastructure: Agenda for Cooperation,\" supra; Alburty, Stevan, \"It's a\nBuyer's Marketplace,\" New York Times, March 20, 1995 at A17.<9>\n9 People join Internet \"to be part of a community. They're not just\nviewers, they're visitors . . . . The most basic of all human desires\nturns out . . . to be part of a community . . . . Our progeny will\nconsider it commonplace to hang out in cyberspace and meet new friends\nfrom around the globe.\"\n[page 23]\nThis community is a virtual community, not a geographic one. The\nvirtual community does not invade the interests of the geographic\ncommunities in which its members reside. When a community forms that is\ninterested in exchanging sexually explicit material on a computer network,\nnone of the complications courts have associated with distribution of\nsexual material in geographic communities exist. Thus, for example, no\ncommercial, retail outlets exist. There is no danger of having to avert\none's eyes walking down the street, and no danger that illegal activities\nwill surround the outlet. The material as it travels over phone lines is\nincomprehensible even if \"overheard.\"\nThe computer communities are also international. Material is\nposted from Finland just as easily as from next door, and one can\ncommunicate with one's neighbor in Finland at least as easily as one's\nneighbor next door. Many bulletin boards or news groups are public in the\nsense that communications are posted and may be read by anyone. Thus, not\nonly can a Memphis resident communicate privately with someone in Finland,\nhe or she can often read messages sent by someone in Finland responding to\na message sent by someone in Japan. Indeed, the technology is such that\nit is possible that a million people, in many locations, are\nsimultaneously reading that communication.\n\nThe Thomases' bulletin board, though not connected to a larger\nnetwork like Internet, was nevertheless a network, not just a system of\ntwo-way communications. Unlike mail order or dial-a-porn, the material\nwas not transmitted in a one-way\n[page 24]\nfashion from one specific person to another. Instead, a community was\ncreated consisting of a number of people, each of whom could communicate\nwith one or all of the other members of the community at once. (TR 747).\nIn this case, members of the Thomases' bulletin board could download\nphotographs or words, or they could communicate with the Thomases, or they\ncould communicate with another member of the bulletin board, or they could\nsend a message to all of the other members of the bulletin board. Id.\nThus, in contrast to mail order or dial-a-porn, the Thomases' bulletin\nboard created a genuine, non-geographic community, or group of people with\nshared interests.\nUnlike many parts of the Internet, the Thomases' board was not\npublic. Thus, the only people who could communicate on it, or read\ncommunications on it, were those who had joined the board through the\napplication process. It thus shared the qualities of community inherent\nin computer networks, without the danger that someone who did not share\nthe community's interests would wander into the wrong neighborhood.\nThis concept of computer communities is particularly important to\nthe amici in this case. Both the ACLU and the National Writers Union have\nonline services for members and others who share their interests. The\nACLU's computer \"reading room\" is designated as a \"free speech zone\"\nwithin a larger network whose corporate provider ordinarily censors\n\"offensive\" words. The Thomas Jefferson Center often communicates over\ncomputer network systems. Feminists for Free Expression also has\n[page 25]\nan online service, and is especially concerned that censorship of sexual\nideas and information in cyberspace not deprive women of the opportunity\nto form computer communities on topics including sexuality, reproduction,\nsafe sex, and sexual harassment. Especially in a climate of backlash\nagainst feminism, use of obscenity laws to punish computer communications\ncan only harm women and be used to silence controversial feminist speech.\nGiven the qualities of computer communities in general, and the\nThomases' bulletin board at issue in this case, the rationale for using\nthe geographic community of Memphis, Tennessee to decide the obscenity\nissue is weak at best. Even assuming the material involved was \"patently\noffensive\" and appealed to the \"prurient interest\" according to the\nstandards of Memphis, there was nothing obscene in Tennessee until the\npostal inspector used his private computer to translate the electric\nstream and print out the material. The material, as it was traveling to\n\n------------------------------\nTennessee consisted of electrical impulses, 1's and 0's, that were\nthemselves not obscene. There was no retail outlet or \"public depiction\"\nof sexual acts. Miller, 413 U.S. at 32. As suggested above, the Thomases\ntook no affirmative steps to get the material into Tennessee. The\nmaterial was accessible only to the community of those who joined the\nboard because they found the material of interest; thus the people of\n\"Maine or Mississippi\" (or Memphis) were not being unwillingly subjected\nto the moral standards of New York, Las Vegas, or cyberspace. Cf. Miller,\n413 U.S. at 32. If the Thomases are to be prosecuted for obscenity,\n[page 26]\nthere is simply an insufficient connection between their conduct and\nTennessee to justify use of Tennessee community standards.<10> Under these\nfacts, to judge the Thomases now by the standards of Tennessee would be\nsimply inequitable, and to permit prosecutions such as this would chill\nthe free flow of computer conversations.<11>\nIn addition, application of the local, geographic community\nstandard presents virtually insurmountable practical problems given the\ninternational nature of the more public computer networks, some of which\nalso have areas set aside for sexually explicit communications. If a\nMemphis resident obtains access to the Internet from a service such as\nProdigy or America Online, and then simply reads messages on a board sent\nby a resident of Finland to a resident of Japan and the latter's\nresponses, is American law going to attempt to make the behavior of the\nservice or of any of the three people involved illegal? To describe this\nscenario is to suggest its impossibility.<12> And beyond the\n10 The United States has relied upon the conservative standards of Memphis\nbefore to prosecute material available nationally. In 1976, the\ngovernment prosecuted a number of people in Memphis who were involved in\nthe movie Deep Throat. Quittner, Joshua, \"Computers in the 90's,\" Newsday,\nAugust 16, 1994 at B27.\n11 Whether prosecution would be permissible in California based on either\nthe images contained in the computer, which had its own software that\nwould translate the images, or based on the hard or printed copies of the\nimages, is an issue this Court need not reach.\n12 A somewhat similar argument has been made in challenging dial-a-porn\nprosecutions. In Sable, the Supreme Court rejected the argument that the\ntechnology makes it unfair to apply local standards. The Court simply\nassumed that blocking transmission [continued next page]\n[page 27]\npractical, serious questions are raised by any attempt to require people\n\n------------------------------\nthroughout the world to conform to the moral or aesthetic standards of\nconservative American localities.\nEven more fundamentally, examination of the values that underlie\nobscenity prohibitions reveals a new balance of interests, requiring the\nnew definition of community. The new technology should be measured\nagainst the interests of privacy and the home recognized by Stanley v.\nGeorgia, 394 U.S. 557 (1969).\nThe Supreme Court has repeatedly said that obscenity is not\nprotected speech. Miller v. California, 413 U.S. 15 (1973). However, in\nStanley, the Court prohibited prosecution on obscenity charges for anyone\npossessing otherwise obscene material in the privacy of his or her own\nhome. As the Court said, \"[w]hatever may be the justifications for other\nstatutes regulating obscenity, we do not think they reach into the privacy\nof one's home. If the First Amendment means anything, it means that a\nState has no business telling a man, sitting alone in his own house, what\nbooks he may read or what films he may watch. Our whole constitutional\nheritage rebels at the thought of giving government the power to control\nmen's minds.\" 394 U.S. at 565.\n12 [continued] to conservative localities was technically feasible, 492\nU.S. at 125-26, and does not appear to have considered the problems of\ninternational communication. More importantly, phone communications are\ntwo-way, with prosecutors seeking only to punish the speakers. Computer\nnetworks, by contrast, place on the same \"party line\" many speakers and\nlisteners.\n[page 28]\nThe Court has so far refused to expand Stanley beyond the\nhome.<13> However, when the rationales of Miller and Stanley (and\nsubsequent cases) are applied to computer networks, the Stanley holding,\nand the privacy interests on which it is based, are more applicable than\nin the cases involving other methods of transmission or communication.\nA vast amount of the material received via computer will be\nreceived directly into the home, in effect without having passed through\nany geographic space, at least in any tangible fashion. Thus, with the\nexception of government agents such as the postal inspector, it is likely\nthat every person receiving information from the Thomases' bulletin board\nreceived it on his or her computer in his or her home.<14> And, as\ndiscussed, until it arrived in the home, it was not discernibly obscene in\nany way. It was merely a stream of coded electrical impulses. It could\nnot be received at all until the person seeking it used a password to\npermit the initial access, and it could not be viewed\n\n------------------------------\n------------------------------\n13 Thus, it has held that someone may be prosecuted for obscenity for\nreceiving the material in the mail, United States v. Reidel, 402 U.S. 351\n(1971); by plane, United States v. Orito, 413 U.S. 139 (1973); or by\nphone, Sable Communications v. FCC, 492 U.S. 115 (1989).\n14 It is possible that someone might try to access the bulletin board from\noffice rather than home computers. Given the nature of the material\ninvolved here, that seems highly unlikely. Moreover, given the costs\nassociated with computer communication, employers can be expected to take\neffective steps to prohibit purely private communications on office\ncomputers. (For example, many employers have blocked their phone lines,\npreventing their use to access dial-a-porn numbers.)\n[page 29]\nuntil the recipient used specific software in his or her computer to\ntranslate the file into an image.<15>\nThus, returning to the rationales for severely limiting Stanley,\nnone of them supports punishment of the conduct in this case under Memphis\ncommunity standards. Use of the initial code system would prevent access\nby unwilling recipients or by children in Memphis or indeed anywhere.\nMiller, 413 U.S. at 18-19.<16> In addition, parents can program their home\ncomputers to prevent their children from accessing the network. There is\nno retail outlet, the presence of which would lower the moral tone of\nMemphis or lead to the incidental, detrimental effects caused by such\noutlets. Paris Adult Theatre I v. Slaton, 413 U.S. 49, 59 (1973). There\nis no danger of the material accidentally being seen by those other than\nits recipients because even if such a person obtained access to the\nelectrical stream, that stream, a meaningless set of 1's and 0's, would\nnot and could not be itself obscene or offensive. United States v. Orito,\n413 U.S. 139, 143-\n15 \"I [went] searching for some of the pornography for which the Internet\nis notorious. Three entries looked especially mouthwatering. . . . I\nclicked on the second of these and waited . . . before my screen was\nfilled with indecipherable symbols but no instructions for translating\nthem into the promised color photographs.\" Steingarten, Jeffrey, \"What's\nCooking in Cyberspace,\" Vogue, March, 1995, 402, 465.\n16 Cf. Rowan v. U.S. Post Office Dept., 397 U.S. 728 (1970) (emphasizing\nimportance of homeowners' autonomy, not government control, in deciding\nwhat mail to receive); Michael I. Meyerson, \"The Right to Speak, the Right\nto Hear, and the Right Not to Hear: The Technological Resolution to the\n\n------------------------------\n------------------------------\nCable/Pornography Debate,\" 21 U. Mich J.L. Ref. 137, 140, 146-47 (1988)\n(homeowners' privacy interests may outweigh interests in government\ncontrol).\n[page 30]\n44 (1973). Finally, there is no more likelihood that this material would\nescape the private home than the material in Stanley. In short, there is\nno community interest in Memphis to justify overriding the privacy\ninterests protected by Stanley and imposing Memphis community standards on\nglobal communications.\nThe Supreme Court has frequently recognized that different media\nof communication call for different First Amendment analyses that are\nsensitive to the character and technology of the medium involved. FCC v.\nPacifica Foundation, 438 U.S. 726, 748 (1978); Joseph Burstyn, Inc. v.\nWilson, 343 U.S. 495, 503 (1952); compare, e.g. Red Lion Broadcasting v.\nFCC, 395 U.S. 367 (1969) and Miami Herald v. Tornillo, 418 U.S. 241\n(1974).<17> In this case, the \"community standards\" part of the Miller\nobscenity test must be adapted not only to the technology, but to the\nunique mix of free speech and privacy interests arising from computer\ncommunications. Thus, the Court ought to hold that geographic\n\"communities\" are not appropriate or even relevant. The appropriate\n\"community\" whose standards will be applied is the community of those who\nhave access to a particular network or\n17 The idea that \"community\" need not always be defined as a local\ngeographic area is not novel. In the context of broadcast radio and\ntelevision, there is a national standard of \"indecency.\" FCC v. Pacifica,\n438 U.S. 726 (1978).\n[page 31]\nbulletin board.<18> Because the district court instructed the jury to the\ncontrary, the convictions should be overturned.\n18 This result would not eliminate the role of the jury in assessing the\n\"prurient interest\" and \"patent offensiveness\" prongs of Miller. It might\nrequire the jury, however, to review the standards set by the relevant\ncomputer community, either directly or through expert testimony.\nIf the Court were to adopt the standard that amici propose, it\ncould mean that there would be a place in cyberspace where adult material\nwould be essentially immune from prosecution. So long as the community,\nin advance, carefully defined the standards it would permit to include\nsexually explicit material, and so long as the community took effective\n\naction to assure access only by consenting adults, then at least insofar\nas communications remained within the homes of community members,\ncommunity standards could bar prosecution for obscenity. This result\nwould be consistent with many of the critiques of obscenity law,\nparticularly in terms of the vagueness and subjectivity of the \"community\nstandards\" test. See, e.g. Smith v. United States, 431 U.S. 291, 313\n(1977)(Stevens, J. dissenting)(\"The diversity within the Nation which\nmakes a single standard of offensiveness impossible to identify is also\npresent within each of the so-called local communities ... In my judgment,\nthe line between communications which 'offend' and those which do not is\ntoo blurred to identify criminal conduct.\"); Pope v. Illinois, 481 U.S.\n497, 504 (1987)(Scalia, J. concurring); Lockhart, William, \"Escape From\nThe Chill of Uncertainty; Explicit Sex and the First Amendment,\" 9 Georgia\nL.Rev. 533 (Spring 1975).\n[page 32]\nCONCLUSION\nFor all these reasons, amici respectfully ask the Court to reverse\nthe convictions that were based on 18 U.S.C. Section 1465.\nChristopher A. Hansen\nMarjorie Heins\nAmerican Civil Liberties Union\nFoundation\n132 W. 43rd St.\nNew York, New York 10036\n(212) 944-9800\nApril 12, 1995\n=============================================================\nACLU Free Reading Room | A publications and information resource of the\ngopher://aclu.org:6601 | American Civil Liberties Union National Office\nftp://ftp.pipeline.com /aclu\nmailto:infoaclu@aclu.org | \"Eternal vigilance is the price of liberty\"\n."
    },
    {
      "category": "Resource",
      "title": "aclucomplaint.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/5f6a73b37de149dc0574a7eaaf872ba2_aclucomplaint.pdf",
      "content": "COMPLAINT\nUNITED STATES DISTRICT COURT\nEASTERN DISTRICT OF PENNSYLVANIA\nCiv. No. 96-963\nAMERICAN CIVIL LIBERTIES UNION; HUMAN\nRIGHTS WATCH; ELECTRONIC PRIVACY\nINFORMATION CENTER; ELECTRONIC FRONTIER\nFOUNDATION; JOURNALISM EDUCATION ASSOCIATION;\nCOMPUTER PROFESSIONALS FOR SOCIAL\nRESPONSIBILITY; NATIONAL WRITERS UNION;\nCLARINET COMMUNICATIONS CORP.; INSTITUTE\nFOR GLOBAL COMMUNICATIONS; STOP PRISONER\nRAPE; AIDS EDUCATION GLOBAL INFORMATION\nSYSTEM; BIBLIOBYTES; QUEER RESOURCES\nDIRECTORY; CRITICAL PATH AIDS PROJECT, INC.;\nWILDCAT PRESS, INC.; DECLAN McCULLAGH dba\nJUSTICE ON CAMPUS; BROCK MEEKS dba CYBERWIRE\nDISPATCH; JOHN TROYER dba THE SAFER SEX\nPAGE; JONATHAN WALLACE dba THE\nETHICAL SPECTACLE; and PLANNED PARENTHOOD\nFEDERATION OF AMERICA, INC.,\nPlaintiffs,\nv.\nJANET RENO, in her official capacity as\nATTORNEY GENERAL OF THE UNITED STATES,\nDefendant.\nPRELIMINARY STATEMENT\n\n1. This is an action for declaratory and injunctive relief challenging provisions of the\n\"Communications Decency Act of 1996\" (the challenged provisions are referred to\nhereinafter as \"the Act\"). One provision imposes criminal penalties for \"indecent\" but\nconstitutionally protected telecommunications to individuals under the age of 18; another\ncriminalizes the use of any \"interactive computer service\" to \"send\" or \"display in a\nmanner available\" to a person under 18 any communication that \"depicts or describes, in\nterms patently offensive as measured by contemporary community standards, sexual or\nexcretory activities or organs.\" The plaintiffs, providers of and users of computer\ncommunication systems, assert that the Act is unconstitutional on its face and as applied\nbecause it criminalizes expression that is protected by the First Amendment; it is also\nimpermissibly overbroad and vague; and it is not the least restrictive means of\naccomplishing any compelling governmental purpose.\n2. In addition, plaintiffs assert that the Act violates the constitutional right to privacy\nencompassed in the First, Fourth, Fifth, and Ninth Amendments because it criminalizes\nprivate \"e-mail\" computer correspondence to or among individuals under the age of 18 if\nthe correspondence is deemed \"patently offensive\" or \"indecent.\"\n3. Plaintiffs further assert that the Act in effect prohibits the right to anonymous speech,\nguaranteed by the First Amendment, for vast portions of the computer networks.\n4. Finally, plaintiffs American Civil Liberties Union, Planned Parenthood Federation of\nAmerica, Inc., and others also assert that 18 U.S.C. Sec. 1462(c), both before and after\namendment, is unconstitutional on its face because it violates the First Amendment by\ncriminalizing the distribution or reception of any information via \"any express company\nor other common carrier, or interactive computer service\" of \"information . . . where,\nhow, or of whom, or by what means any\" \"drug, medicine, article, or thing designed,\nadapted, or intended for producing abortion . . . may be obtained or made.\"\nJURISDICTION AND VENUE\n5. This Court has jurisdiction pursuant to 28 U.S.C. Secs. 1331, 1361, and 2201. Venue is\nproper under 28 U.S.C. Sec. 1391(e).\n6. Under Sec. 561 of the Act, this action must be adjudicated by a three-judge court\nconvened pursuant to 28 U.S.C. Sec. 2284.\nPARTIES\n7. Plaintiff AMERICAN CIVIL LIBERTIES UNION (ACLU) is a nationwide,\nnonpartisan organization of nearly 300,000 members dedicated to defending the\nprinciples of liberty and equality embodied in the Bill of Rights. The ACLU is\nincorporated in the District of Columbia and has its principal place of business in New\nYork City. The ACLU sues on its own behalf, on behalf of others who use its online\ncomputer communications, and on behalf of its members who use online\ncommunications.\n\n8. Plaintiff HUMAN RIGHTS WATCH, INC. (HRW) is a leading international human\nrights organization that monitors human rights abuses in over 70 countries. It is\nincorporated in New York and has its principal place of business in New York City. It\nsues on its own behalf, on behalf of others who use its online computer communications,\nand on behalf of its members who use online communications.\n9. Plaintiff ELECTRONIC PRIVACY INFORMATION CENTER (EPIC) is a non-profit\nresearch organization that collects and distributes information concerning civil liberties\nand privacy issues arising in the new communications media. EPIC is a project of the\nFund for Constitutional Government, a tax-exempt organization incorporated in the\nDistrict of Columbia. Both EPIC and the Fund have their principal places of business in\nWashington, D.C. EPIC sues on its own behalf and on behalf of others who use its online\ncomputer communications.\n10. Plaintiff ELECTRONIC FRONTIER FOUNDATION (EFF) is a nationwide,\nnonpartisan organization of approximately 3,500 paying individual members that is\ncommitted to defending civil liberties in the world of computer communications, to\ndeveloping a sound legal framework for that world, and to educating government,\njournalists, and the general public about the legal and social issues raised by this new\nmedium. EFF is incorporated in California and has its principal place of business in San\nFrancisco. EFF sues on its own behalf, on behalf of others who use its online computer\ncommunications, and on behalf of its members.\n11. Plaintiff JOURNALISM EDUCATION ASSOCIATION (JEA) was formed in 1924.\nIt is incorporated in Minnesota and has its headquarters in Manhattan, Kansas. Its\npurpose is to serve journalism educators through opposing censorship of student\nexpression, creating aids for curriculum and instruction, facilitating the involvement of\nminority students, promoting the use of technology, and emphasizing professionalism\nthrough certification, workshops, conventions, and publications. It sues on its own behalf,\non behalf of its members who use online communications, and on behalf of the students\nwith whom the members work.\n12. Plaintiff COMPUTER PROFESSIONALS FOR SOCIAL RESPONSIBILITY\n(CPSR) is a non-profit corporation incorporated in California with national offices in\nPalo Alto. CPSR has 22 chapters in 14 states and approximately 1,550 members. As\ntechnical experts, CPSR members provide the public and policymakers with realistic\nassessments of the power, promise, and limitations of computer technology. As\nconcerned citizens, CPSR members direct public attention to critical choices concerning\nthe application of computing and how those choices affect society. CPSR sues on its own\nbehalf, on behalf of others who use its online computer communications, and on behalf of\nits members who use online communications.\n13. Plaintiff NATIONAL WRITERS UNION (NWU) is a 4,000-member labor union for\nfreelance writers founded in 1983. Its members include investigative journalists, trade\nbook authors, technical writers, political cartoonists, poets, textbook authors, and\nmultimedia contributors. NWU has its principal place of business in New York City.\n\nNWU sues on its own behalf, on behalf of others who use its online computer\ncommunications, and on behalf of its members who use online communications.\n14. Plaintiff CLARINET COMMUNICATIONS CORP. is incorporated in California and\nhas headquarters in San Jose. ClariNet publishes an electronic newspaper in Usenet\nformat with 1.2 million paying subscribers and a widely read humor newsgroup. ClariNet\nsues on its own behalf and on behalf of its subscribers and readers.\n15. Plaintiff INSTITUTE FOR GLOBAL COMMUNICATIONS (IGC) is a national\ncomputer service provider that provides inexpensive access to the international computer\nnetwork known as the Internet, as well as other online services, primarily to nonprofit\norganizations. It is a project of a California public charity; its principal place of business\nis in San Francisco, California. It sues on its own behalf and on behalf of others who use\nits online computer communications.\n16. Plaintiff STOP PRISONER RAPE, INC. (SPR) is a nonprofit organization dedicated\nto combating the problem of prisoner rape. SPR is a non-profit corporation incorporated\nin New York and has its principal place of business in New York City. It sues on its own\nbehalf and on behalf of those who use its online computer communications.\n17. Plaintiff AIDS EDUCATION GLOBAL INFORMATION SYSTEM (AEGIS) is a\nnonprofit corporation incorporated in California that operates a free computer bulletin\nboard system with one of the largest online archives of information on HIV and AIDS in\nthe world. Its home computer is located in San Juan Capistrano, California. It sues on its\nown behalf and on behalf of those who use its online computer communications.\n18. Plaintiff BIBLIOBYTES is a company that produces electronic books for sale via a\n\"World Wide Web\" site on the Internet. It is incorporated in New Jersey and its principal\nplace of business is in Hoboken, New Jersey. It sues on its own behalf and on behalf of\nthose who use its online computer communications.\n19. Plaintiff QUEER RESOURCES DIRECTORY (QRD) is one of the largest online\ndistributors of gay, lesbian, and bisexual resources on the Internet. It is an unincorporated\nassociation. Its system administrator resides in Reston, Virginia, its executive director\nresides in Los Angeles, California, and its home computer is located in Portland, Oregon.\nOther distribution point computer locations are in Maryland, California, New Zealand,\nthe United Kingdom, Michigan, and Israel. QRD sues on its own behalf and on behalf of\nthose who use its online computer communications.\n20. Plaintiff CRITICAL PATH AIDS PROJECT, INC. is an AIDS treatment and\nprevention information project that offers AIDS treatment and safer sex information via a\nfree computer bulletin board, electronic mailing lists, and a page on the World Wide\nWeb. Critical Path is also an Internet Service Provider providing free access to the\nInternet for both organizations and individuals in the Philadelphia area. It is incorporated\nin Pennsylvania and its home computer is located in Philadelphia, Pennsylvania. It sues\n\non its own behalf, on behalf of others who use its online computer communications, and\non behalf of its members who use online communications.\n21. Plaintiff WILDCAT PRESS, INC. is an independent publishing company that\npromotes its publications by providing free excerpts through a World Wide Web site on\nthe Internet. It is a limited liability partnership and has its principal place of business in\nLos Angeles, California. It sues on its own behalf and on behalf of those who use its\nonline computer communications.\n22. Plaintiff DECLAN McCULLAGH dba JUSTICE ON CAMPUS operates a nonprofit\nonline information clearinghouse on issues of student free speech. The home computer is\nlocated at the Massachusetts Institute of Technology in Cambridge, Massachusetts.\nMcCullagh also maintains a list for people interested in censorship issues called \"fight-\ncensorship.\" McCullagh resides in Pittsburgh, Pennsylvania. He sues on his own behalf\nand on behalf of those who use JUSTICE ON CAMPUS and the fight-censorship list.\n23. Plaintiff BROCK MEEKS dba CYBERWIRE DISPATCH (CWD), is the columnist\nand editor of CyberWire Dispatch, a popular and irreverent online political news column\navailable on the World Wide Web and through a computer subscription program called a\nlistserv. He also writes a column for HotWired, an online magazine. Meeks is a resident\nof Fredericksburg, Virginia. He sues on his own behalf and on behalf of those who use\nCYBERWIRE DISPATCH and read his column in HotWired.\n24. Plaintiff JOHN TROYER dba THE SAFER SEX PAGE maintains a large archive of\ninformation about safer sex on the Internet's World Wide Web. Troyer is a resident of\nSan Francisco, California. The home computer for the Safer Sex Page is located in San\nFrancisco. Troyer sues on his own behalf and on behalf of those who use THE SAFER\nSEX PAGE.\n25. Plaintiff JONATHAN WALLACE dba THE ETHICAL SPECTACLE, publishes an\nonline magazine on the Internet's World Wide Web that examines controversial issues of\nethics, law and politics in America. Wallace is a resident of New York City, and rents\ncomputer facilities in New Jersey for purposes of housing the magazine. He sues on his\nown behalf and on behalf of those who use THE ETHICAL SPECTACLE.\n26. Plaintiff PLANNED PARENTHOOD FEDERATION OF AMERICA, INC. (PPFA)\nis the leading national voluntary health organization in the field of reproductive health\ncare. PPFA and its 153 affiliates engage in public education and advocacy concerning\nsafe and legal access to all reproductive health services, including abortion, and its\naffiliates provide these services. PPFA operates a site on the Internet's World Wide Web,\nthrough plaintiff IGC. PPFA is a New York State corporation with its headquarters in\nNew York City.\n27. Defendant ATTORNEY GENERAL JANET RENO heads the United States\nDepartment of Justice, which is the agency of the United States government responsible\nfor enforcement of federal criminal laws, including the statute at issue in this case.\n\nFACTS\nEnactment of \"Indecency\" Standard for Cyberspace Communications\n28. In February, 1996, Congress adopted and the President signed the Act. In relevant\npart, the Act provides:\n\"Section 502. Obscene or Harassing Use of Telecommunications Facilities Under the\nCommunications Act of 1934.\nSection 223 (47 U.S.C. 223) is amended-\n(1) by striking subsection (a) and inserting in lieu thereof:\n(a) Whoever --\n\"(1) in interstate or foreign communications ...\n\"(B) by means of a telecommunications device knowingly --\n\"(I) makes, creates, or solicits, and\n\"(ii) initiates the transmission of,\nany comment, request, suggestion, proposal, image, or other communication which is\nobscene or indecent knowing that the recipient of the communication is under 18 years of\nage regardless of whether the maker of such communication placed the call or initiated\nthe communication; ...\n(2) knowingly permits any telecommunications facility under his control to be used for\nany activity prohibited by paragraph (1) with the intent that it be used for such activity,\nshall be fined under title 18, United States Code, or imprisoned not more than two years,\nor both.\"\n(emphasis added) This provision appears in the United States Code as 47 U.S.C. Sec.\n223(a)(1)(B) (hereinafter the \"indecency\" provision).\n29. Subsection (h)(1) of Sec. 502(2) of the Act provides that\n\"the use of the term telecommunications device' in this section\n(A) shall not impose new obligations on broadcasting station licensees and cable\noperators covered by obscenity and indecency provisions elsewhere in this Act; and\n(B) does not include the use of an interactive computer service.\"\n\nBecause \"interactive computer service\" is defined broadly in the Act (see below), the\ndefinition of \"telecommunications device\" to exclude any \"interactive computer service\"\nleaves entirely uncertain the meaning and scope of the statutory prohibitions for computer\ncommunications.\n30. Section 502(2) of the Act adds to 47 U.S.C. Sec. 223, in pertinent part:\n\"(d) Whoever --\n(1) in interstate or foreign communications knowingly\n(A) uses an interactive computer service to send to a specific person or persons under 18\nyears of age, or\n(B) uses any interactive computer service to display in a manner available to a person\nunder 18 years of age, any comment, request, suggestion, proposal, image, or other\ncommunication that, in context, depicts or describes, in terms patently offensive as\nmeasured by contemporary community standards, sexual or excretory activities or organs,\nregardless of whether the user of such service placed the call or initiated the\ncommunication; or\n(2) knowingly permits any telecommunications facility under such person's control to be\nused for an activity prohibited by paragraph (1) with the intent that it be used for such\nactivity,\nshall be fined under title 18, United States Code, or imprisoned not more than two years,\nor both.\" (emphasis added).\nThis provision appears in the United States Code as 47 U.S.C. Sec. 223(d)(1) (hereinafter\nthe \"patently offensive\" provision).\n31. Subsection (h)(2) of Sec. 502(2) of the Act provides that \"[t]he term `interactive\ncomputer service' has the meaning provided in section 230(f)(2).\" Section 230(f)(2)\ndefines \"interactive computer service\" to mean \"any information service, system, or\naccess software provider that provides or enables computer access by multiple users to a\ncomputer server, including specifically a service or system that provides access to the\nInternet and such systems operated or service offered by libraries or educational\ninstitutions.\"\n32. The provisions described in this section became effective immediately upon passage\nof the Act.\n33. No definition is given in the Act for the term \"indecent.\" The Federal\nCommunications Commission, however, has interpreted the prohibition of \"indecent\"\nradio and television broadcasts under 18 U.S.C. Sec. 1464 to cover communications that\n\"depict or describe, in terms patently offensive as measured by contemporary community\n\nstandards for the broadcast medium, sexual or excretory activities or organs.\" The\nCommission has ruled that this definition includes the use of common Anglo-Saxon street\nterms for sexual or excretory functions, as well as sexual innuendos and double\nentendres. In addition, the Commission has ruled that communications with substantial\nliterary, artistic, political, scientific, or other educational or social value, may be \"patently\noffensive\" or \"indecent.\"\n34. The Act contains two provisions that appear to establish partial defenses to criminal\nliability. Section 502 adds to 47 U.S.C. Sec. 223 a new subsection (e), which provides\nthat \"[i]n addition to any other defenses available by law: (1) No person shall be held to\nhave violated subsection (a) or (d) solely for providing access or connection to or from a\nfacility, system, or network not under that person's control, including transmission,\ndownloading, intermediate storage, access software, or other related capabilities that are\nincidental to providing such access or connection that does not include the creation of the\ncontent of the communication.\" Various exceptions to this defense are set out in\nsubsections (e)(2), (3), and (4), for conspiracies, co-ownership situations, and employer\nliability.\n35. In addition, new 223 U.S.C. Sec. 223(e)(5) provides a defense for any person who\n\"(A) has taken, in good faith, reasonable, effective, and appropriate actions under the\ncircumstances to restrict or prevent access by minors to a communication specified in\nsuch subsections, which may involve any appropriate measures to restrict minors from\nsuch communications, including any method which is feasible under available\ntechnology; or\n(B) has restricted access to such communication by requiring use of a verified credit card,\ndebit account, adult access code, or adult personal identification number.\" New Sec.\n223(e)(6) permits the Federal Communications Commission to \"describe measures which\nare reasonable, effective, and appropriate to restrict access to prohibited communications\nunder subsection (d),\" but does not authorize the Commission to enforce the Act or\napprove such measures.\n36. Section 509 of the Act may provide a different defense to liability. Section 509 adds a\nnew section, Sec. 230, to Title 47 of the United States Code. Section 230(c)(1) provides:\n\"No provider or user of an interactive computer service shall be treated as the publisher\nor speaker of any information provided by another information content provider.\" This\nsection appears to conflict with new 47 U.S.C. Sec. 223(e), which only provides a\ndefense if a \"facility, system, or network\" on which \"indecent\" or \"patently offensive\"\nmaterial appears is not under the \"control\" of the person who provides access.\n37. Before passing this Act, Congress made no findings about alternative, less restrictive\nmeans of accomplishing the goals of the Act.\nThe Nature of the Online Medium\n\n38. Online services use computers, phone lines, and modems to connect users to networks\nthat allow them to communicate with thousands of other users throughout the world, and\nto access extensive information databases from a variety of sources. Most online services\noffer a package of services that can include: electronic mail to transmit private messages\nto one or a group of users or to an established mailing list on a particular topic; chat\nrooms that allow simultaneous online discussions; discussion groups in which users post\nmessages and reply to online \"bulletin boards\"; informational databases; and access to the\nInternet.\n39. Textual, audio, and video files can all be exchanged through computer\ncommunications networks if the user has the right computer hardware and software.\n40. The Internet is the largest online network in the world. It links a large number of\nsmaller networks set up by universities, industry, nonprofit organizations, and\ngovernment. While estimates can only be approximations due to rapid growth, the\nInternet is believed to connect at least 59,000 computer networks, 2.2 million computers,\n159 countries, and 40 million users. The Internet has no centralized distribution point.\n41. Many users are connected to the Internet through an Internet Service Provider (ISP).\nISPs provide connections, software, and tools for using the Internet. Like the large\ncommercial online services, ISPs also often host online discussion groups and chat rooms\nthat are housed and maintained through the ISP's computers.\n42. Some businesses and institutions have a direct connection to the Internet, which\nmeans they are part of the vast network of computers that comprise the Internet. Many\nuniversities in the United States are directly connected to the Internet and provide\naccounts on their participating computer to students, faculty, and staff.\n43. Some online services provide content as well as access to computer networks. That is,\nin addition to providing the technical ability to subscribers to send and receive\ninformation and messages, some online services create their own information databases.\n44. Electronic mail, or e-mail, is the most basic online communication. Users are given a\npersonal e-mail address that allows them to exchange messages or files with other\npersons and organizations that have Internet e-mail addresses.\n45. \"Gopher\" is a popular way to create and access databased information on the Internet.\nGopher is a menu-driven program that allows the user to \"gopher\" through multiple\nlayers of menus to search for information on a particular topic. A \"gopher site\" is a\ndatabase that provides content associated with a particular person or organization. As a\nreference service, gopher sites often include links to related gopher sites that are\nassociated with other organizations or persons.\n46. The \"World Wide Web\" (Web) is a popular way to create and access databased\ninformation on the Internet. The World Wide Web contains sophisticated graphics and\naudio files in addition to text files. Web sites are databases that provide content\n\nassociated with a particular person or organization; they allow users to link instantly to\nother documents and Web sites by clicking on highlighted words in the text of the\ndocument being viewed.\n47. \"Online discussion groups\" are hosted by online services or by particular networks\nconnected to the Internet. The host sets up a section on the network devoted to the\ndiscussion of a particular issue and any other online user with access to the host network\ncan post messages on the topic by sending an e-mail message to the discussion group.\nUsers can also post responses to particular messages.\n48. \"Online mailing lists,\" or \"listservs\" are e-mail distribution lists. Internet users\nsubscribe to online mailing lists by sending messages from their own e-mail addresses.\nAny subscriber can then send a message that is distributed to all the other subscribers on\nthe list.\n49. \"Chat rooms\" are sections provided by online services and some computer bulletin\nboard systems in which online users can engage in simultaneous live interactive online\ndiscussion.\n50. Online discussion groups, chat rooms, and online mailing lists are sometimes\nmoderated by someone not necessarily connected with the online service provider. Many\nof these \"moderators\" are volunteers who simply are interested in a particular topic. The\nmoderators review incoming messages before they are posted to determine whether the\nmessages are related to the subject matter of the group or conform to other standards set\nup by the moderator.\n51. \"Computer bulletin board systems\" (BBSs) are online networks that are independent\nof the Internet and that usually cater to people interested in specialized subject matter or\nto people from a particular geographic region. Subscribers dial directly from their\ncomputers into the BBS host computer. BBSs often offer e-mail services among users,\nonline discussion groups, and information databases.\n52. A user with access to the Internet may use most gopher sites and Web sites without\nproviding further identification or paying an additional fee. A user with access to\nnewsgroups, online discussion groups, online mailing lists, and chat rooms may generally\nuse particular services without providing further identification or paying an additional\nfee.\n53. \"Cyberspace\" refers to the combination of all of the online communications systems\ndescribed above.\n54. Nobody owns cyberspace, and the ability of anyone to control what goes into or\nthrough online networks varies widely depending on the nature of the system. Anyone\ncan purchase the necessary equipment to get online or to create her own web page.\n\n55. Users of online systems are also content providers (that is, they are publishers),\nbecause they can transmit and distribute their own communications and can create a\npermanent archive of information accessible by other users. There is no limit to the\nnumber of people on either side of the sending or receiving end of computer\ncommunications.\n56. Online communications are interactive. This means, in part, that users of online\nsystems must seek out with specificity the information they wish to retrieve and the kinds\nof communications they wish to engage in. It also means that users can easily respond to\nthe material they receive or view online.\n57. Online systems provide users with a multitude of options for controlling and limiting,\nif desired, the kinds of information they access through online networks. Commercial\nonline services like American Online, Prodigy, and CompuServe provide features to\nprevent children from accessing chat rooms and to block access to some kinds of\nnewsgroups based on keywords, subject matter, or specific newsgroup. They also offer\nscreening software that automatically blocks messages containing certain words, and\ntracking and monitoring software to determine which resources a particular online user\n(e.g., a child) has accessed. They also offer children-only discussion groups that are\nclosely monitored by adults.\n58. Online users can also purchase special software applications to control access to\nonline resources. These applications allow users to block access to certain resources, to\nprevent children from giving personal information to strangers by e-mail or in chat\nrooms, and to keep a log of all online activity that occurs on the home computer.\n59. Once information is posted to an international online network like the Internet, it is\nnot possible to allow only residents of a particular region or country to access that\ninformation; the information becomes available to anyone in the world who has access to\nthe online network. There is currently no technological method for determining with\nspecificity the geographic location from which users access or post to online systems.\n60. Online users are given a password and user name which they must use in order to sign\nonto their online service. While some users use their full proper name as their online user\nname, many users have online names that are pseudonyms. These users therefore may\nsend, view, and receive online communications anonymously.\n61. There are forums for both \"public\" and \"private\" communications in cyberspace. E-\nmail and online mailing lists are private communications between specified persons or\ngroup of persons. Only the intended recipients of an e-mail message receive the message;\nin this sense e-mail is like regular mail. Similarly, only subscribers to an online mailing\nlist should receive the messages posted to that mailing list. Web sites, gopher sites, online\ndiscussion groups, and chat rooms, by contrast, are public because anyone with online\naccess can access them or participate in them at any time. These forums are the public\nlibraries and public squares of cyberspace.\n\nRelationship of the Plaintiffs To the Act\nAmerican Civil Liberties Union (ACLU)\n62. In addition to its legal advocacy to uphold the Bill of Rights, plaintiff ACLU has long\ndevoted considerable resources to public education about civil liberties. Since 1993, the\nACLU's public education efforts have included extensive online resources that offer\nelectronic copies of ACLU publications, reports, court briefs, news releases, and other\nmaterial related to the ACLU's legal, legislative, educational and advocacy work.\n63. The ACLU maintains its extensive online resources through America Online and the\nInternet's World Wide Web. Many of the ACLU's online databases contain material of\nsocial value that contains sexual subject matter or vulgar language. Examples include\ncopies of ACLU court briefs in cases involving obscenity, arts censorship, and\ndiscrimination against gays and lesbians. Indeed, the ACLU has posted the text of the\n\"seven dirty words\" comic monologue which the Supreme Court ruled \"indecent\" in the\n1978 Pacifica case, and which the Court itself reproduced as an appendix to its opinion.\n64. The ACLU also hosts unmoderated online discussion groups that allow citizens to\ndiscuss and debate a variety of civil liberties issues. These services allow online users to\nexpress their uncensored views on civil liberties issues and to interact with ACLU staff or\nfeatured speakers. Many of the communications in the ACLU's discussion groups have\nsexual content or vulgar language; for example, a discussion of masturbation in the\ncontext of the firing of former Surgeon General Jocelyn Elders; the content of Howard\nStern's best-selling book, Private Parts; a discussion of why the word \"fuck\" has such\nexpressive power; and a discussion of the defense of pornography and other erotic\nexpression under the First Amendment.\n65. The ACLU does not moderate its interactive services because such editing or\ncensorship would be antithetical to the ACLU's belief in freedom of speech. Furthermore,\nthe ACLU considers minors to be an important audience for its online resources. The\nability of minors to participate in chat rooms or discussion groups with other minors and\nwith adults is a vital part of their education. It is particularly important that minors be\nable to access information about their rights and to learn about and debate controversial\nissues. Thus, for the reasons discussed in this Complaint, the ACLU does not currently\nintend to self-censor any of its online communications as a result of the Act.\n66. The ACLU's web site is hosted by a private company that has expressed concern\nabout the material on the ACLU's site for fear that it would be held liable under the Act.\nThe company has not yet decided what action, if any, to take as a result of this concern.\n67. In addition to its own online resources, ACLU staff and members use other online\nservices such as e-mail, outside discussion groups, and online mailing lists as an\nimportant low-cost method of communicating and sharing documents and information\nwith each other and with those outside of the ACLU. Some of this material is also\n\nsexually explicit or contains vulgar language or descriptions of the human body or human\nreproduction.\n68. Through its online resources, the ACLU distributes information to and receives\ninformation from its affiliates, clients, members, and the public, regarding how women\ncan obtain abortions or abortifacient drugs or devices, and when doctors can perform\nabortions, including how to contact specific abortion providers, who performs specific\nabortion procedures, where to obtain specific abortifacient drugs and devices, when\nspecific abortion procedures may be used, and the legal restrictions on obtaining and\nperforming abortions in different states.\n69. The ACLU also mails out information to and receives information through the mails\nfrom its affiliates, clients, members, and the public, regarding how women can obtain\nabortions or abortifacient drugs and devices, and when doctors can perform abortions,\nincluding how to contact specific abortion providers, who performs specific abortion\nprocedures, where to obtain specific abortifacient drugs and devices, when specific\nabortion procedures may be used, and the legal restrictions on obtaining and performing\nabortions in different states.\n70. The ACLU also gives out and receives information over the telephone and via FAX\nfrom its affiliates, clients, members, and the public, regarding how women can obtain\nabortions or abortifacient drugs and devices, and when doctors can perform abortions,\nincluding how to contact specific abortion providers, who performs specific abortion\nprocedures, where to obtain specific abortifacient drugs and devices, when specific\nabortion procedures may be used, and the legal restrictions on obtaining and performing\nabortions in different states.\nHuman Rights Watch (HRW)\n71. Plaintiff HRW uses online services to communicate with human rights activists and\nothers in the field and to distribute its human rights reports worldwide through a gopher\nsite on the Internet. HRW's online resources include testimony from victims of forced\ntrafficking in prostitution in Thailand and India, reports on systematic rape in Bosnia, and\nreports of sexual abuse of female prisoners in the United States. These and other reports\ncontain graphic language and subject matter. In the view of HRW, online communication\nis a powerful new way for human rights activists, dissidents and others to communicate\nand organize away from the watchful eyes of oppressive governments.\n72. For example, a July 1995 report on slavery in Pakistan detailed tortures that are used\nto intimidate bonded laborers. That report discusses tortures that include beating of the\ngenitals and rape.\n73. HRW believes that the use of graphic language and descriptions is necessary to\nconvey the true horror of human rights abuse. Removal of material considered \"indecent\"\nor \"patently offensive\" from direct victim testimony in HRW's human rights reports\nwould greatly diminish its effectiveness in advocating for an end to human rights abuses.\n\n74. HRW believes that minors as well as adults are interested in its online information,\nand that it is important for the success of the human rights movement that minors have\naccess to this information. Thus, for the reasons discussed in this Complaint, HRW\ncurrently does not intend to self-censor any of its online communications as a result of\nthe Act.\nElectronic Privacy Information Center (EPIC)\n75. EPIC maintains its public online resources through a site on the web and through an\nonline mailing list to which any person with an Internet electronic mail address may\nsubscribe. On average, 500 people visit the Web site each day.\n76. EPIC's electronic resources include materials concerning free speech, censorship, and\nprivacy issues. Because of the nature of these issues, some of the materials necessarily\nuse sexually explicit speech or vulgar language. For example, the EPIC web site contains\nthe text of the Supreme Court's opinions in FCC v. Pacific Foundation, 438 U.S. 726\n(1978), and Cohen v. California, 403 U.S. 15 (1971), both of which contain common four\nletter words.\n77. EPIC's web site also contains the text of poems written by subscribers of America\nOnline and removed from that system by America Online management on the grounds\nthat they contain \"vulgar or sexually oriented language.\" EPIC makes such information\navailable in order to illustrate the potential effects of attempts to regulate online speech\nand expression.\n78. EPIC believes minors to be an important audience for its online resources. EPIC staff\nfrequently receive inquiries from high school students seeking information for research\nprojects. EPIC staff refer these students to EPIC's web site as a potential source of\nrelevant information.\n79. Thus, for the reasons discussed in this Complaint, EPIC does not currently intend to\nself-censor its online communications as a result of the Act.\nElectronic Frontier Foundation (EFF)\n80. Since its inception in 1990, EFF has devoted considerable resources to educating the\npublic about civil liberties and legal issues as they arise in cyberspace. Throughout EFF's\nexistence, it has initiated and/or moderated several online forums, including a forum on\nthe WELL (a California-based conferencing system and Internet Service Provider), on\nUsenet (two online discussion groups or \"newsgroups\") and on America OnLine. EFF\nalso has its own computer site on the Internet.\n81. EFF's public education efforts include the maintaining of extensive online resources\nboth on forums it runs with online service providers, and on its own Internet site. These\nresources include articles, court cases, legal papers, news releases, newsletters, and\nexcerpts from public discussions related to the EFF's legal, legislative, educational, and\n\nadvocacy work. EFF also publishes a \"home page\" on the web which is accessible to\nanyone with a user account on another site on the global Internet, as well as anyone who\nuses an online service provider that includes a \"Web browser\" among its services.\n82. EFF also maintains eight online mailing lists, both for specific civil-liberties and\nactivist activities, and for informing the public about its activities. The primary mailing\nlist has a subscriber base of approximately 7,500 individuals.\n83. EFF's web page normally receives between 70,000 to 80,000 hits per day (a hit is an\ninstance of individual access). The site normally transmits the equivalent of 120 million\nto 140 million words per day.\n84. Since virtually all interactions on the Internet or other computer networks have a\nsignificant communicative element to them, EFF's policy positions and the discussion\nforums it sponsors strongly emphasize freedom-of-speech concerns, including concerns\nabout the contours of obscenity law and liability and about the scope of the Federal\nCommunications Commission's jurisdiction to regulate so-called \"indecency.\" In\ndiscussing what the Supreme Court, in the absence of a definition of indecency, might\nconsider to be indecent, EFF must refer in detail to such texts as the George Carlin\ncomedy monologue that was the subject of the litigation in FCC v. Pacifica, to the\ntranscripts of Howard Stern broadcasts, and to literary works such as those of Allen\nGinsberg and James Joyce. EFF's web site also provides \"links\" that enable users to visit\nother sites that contain discussions and examples of \"indecent\" material.\n85. EFF believes it is important for minors to be able to educate themselves about the\nlegal and constitutional structures that frame freedom of speech online. Some EFF\nmembers are minors. This Act would radically restrict access by EFF members who are\nminors to constitutionally protected material that they could legally be given in a library\nor bookstore.\n86. Thus, for the reasons discussed in this Complaint, EFF does not currently intend to\nself-censor its online communications as a result of the Act.\n87. Nearly all of EFF's approximately 3,500 members use online communications. EFF\nmembers both receive and transmit information through a variety of online\ncommunications. EFF members do not wish to be required to self-censor \"indecent\"\nspeech in order to avoid prosecution.\nJournalism Education Association (JEA)\n88. JEA is one of the largest national organizations of high school journalism teachers\nand publication advisors. It has almost 1,600 members. JEA members increasingly use\nonline communications as part of instruction in high school journalism classes or as part\nof teaching research methods for students who write for school publications.\n\n89. JEA believes that access to online communications is essential for the education of\nhigh school students.\n90. JEA members attempt to give students the skills to enable them to engage in\nindependent online research. When students do online research directed or supervised by\nJEA members, but on computers that are not at the school or that are at the school but not\nbeing operated by a teacher, it is not possible for JEA members to ensure that students do\nnot access material that might come within the definition of the Act.\n91. Many high school students are sufficiently mature to be able to handle material that\nsome might consider \"indecent\" or \"patently offensive.\" Thus, it might not only be\nacceptable but also important for some students, under the supervision of JEA members,\nto access information about, for example, war crimes in Bosnia which might include\ngraphic descriptions of rape.\n92. If the Act goes into effect, JEA members fear they will be prosecuted if they fail to\ncensor material that some people believe should be censored under the Act.\n93. Section 223(f)(1) provides that \"[n]o cause of action may be brought in any court or\nadministrative agency against any person on account of activity that is not in violation of\nany law punishable by criminal or civil penalty, and that the person has taken in good\nfaith to implement a defense authorized under this section or otherwise to restrict or\nprevent the transmission of, or access to, a communication specified in this section.\"\n94. JEA members do not know if this section would protect them from liability for\nviolation of First Amendment rights if they unnecessarily restricted access to important\nprotected speech not covered by the Act.\n95. JEA also sues on behalf of their minor students. The students wish to retain their right\nto access constitutionally protected information and ideas.\nComputer Professionals for Social Responsibility (CPSR)\n96. CPSR, a nonprofit organization of computer professionals, maintains a site on the\nWorld Wide Web. CPSR also maintains several listservs and hosts several online\ndiscussion groups. Board of Director discussions take part online and board votes are\nsometimes taken online. CPSR also maintains two newsgroups which are not moderated.\n97. CPSR's web site is linked to a number of other Web sites, gophers and other\ncomputer networks. Many of the sites with which CPSR's site is linked appear to contain\ninformation that is of medical or health value but that might be considered indecent or\npatently offensive. Other linked sites contain other information that might also be\nconsidered indecent or patently offensive.\n98. One of the listservs, which is also a CPSR working group, is called \"Cyber Rights.\"\nPeople who participate in Cyber Rights often discuss issues of censorship and the\n\napplication of indecency rules to cyberspace. Some of this discussion is frank and uses\nstrong language and/or quotes matters that have been censored. Other listservs and\ndiscussion groups also discuss issues of censorship and contain strong language.\n99. Minors have access to the computer communications of CPSR. CPSR believes that it\nis important that social responsibility be promoted among young people who are learning\nto use online resources and that access to the CPSR resources would advance this goal.\nCPSR does not wish to restrict its online resources to adults only.\n100. Thus, for the reasons discussed in this Complaint, CPSR does not currently intend to\ncensor its online communications as a result of the Act.\n101. As computer professionals, CPSR members engage in a great deal of interaction\nthrough various computer networks. This includes e-mail, participation in listservs,\nparticipation in discussion groups, and use of various sites on computer networks. CPSR\nmembers fear prosecution as a result of their use of computer online communications.\nNational Writers Union (NWU)\n102. Plaintiff NWU maintains a site on the World Wide Web, as do several of its leaders.\nIt also maintains an online archive of NWU-related documents, and offers two online\nmailing lists to which any person, whether or not an NWU member, may subscribe. Some\nof the material on the NWU's various web sites and mailing lists contains sexually\nexplicit subject matter or vulgar words -- for example, heated debates about\nhomosexuality, and back issues of the NWU's newsletter, which include explicit articles\nabout censorship, obscenity and indecency law, and gay rights.\n103. Many NWU members use computers to communicate with each other via private e-\nmail, to exchange information, and to post literary work. Some of this material is sexually\nexplicit or contains vulgar words. Human sexuality and the human body have always\nbeen important subjects of literature and journalism and, as writers, NWU members\nnaturally address these subjects.\n104. For example, one NWU member, Robert B. Chatelle, maintains a web page that\ncontains links to erotic fiction that he has written.\n105. The NWU and its members and leaders believe that minors should continue to have\naccess to the NWU web site and other online resources. Thus, for the reasons discussed\nin this Complaint, NWU and some of its members do not currently intend to self-censor\nany of their online communications as a result of the Act. Other members would self-\ncensor in order to avoid the risk of prosecution.\nClariNet Communications Corp. (ClariNet)\n106. Plaintiff ClariNet Communications Corp. publishes an electronic newspaper known\nas the \"ClariNet e.News\" in Usenet format, which includes news articles, columns, and\n\nfinancial information. The news articles are taken from the same wire services from\nwhich print newspapers obtain their stories but, unlike some print newspapers, ClariNet\ndoes not censor the articles. ClariNet has published articles that use common Anglo-\nSaxon four letter words. It has also published articles that explicitly describe rapes and\nsexual assaults. Some of these descriptions are more explicit than the same stories in\nmost print newspapers.\n107. ClariNet also publishes a humor newsgroup in Usenet format at rec.humor.funny\nand on the Web. Some of the jokes include vulgar language or sexually explicit material.\nFor instance, some of the jokes discuss sexual acts including oral sex. Some jokes also\nuse strong and explicit language.\n108. ClariNet believes that many minors have an interest in reading the articles and jokes\nit publishes and that minors do read the material published by ClariNet.\n109. With regard to its newspaper, which is available primarily through educational\ninstitutions, corporations, and Internet service providers, ClariNet depends on the\nproviders to institute a method to obtain access. Because of the vagueness of the statutory\ndefenses, ClariNet does not know if the access systems used by the providers would\nconstitute a defense to liability.\n110. For the reasons discussed in this Complaint, ClariNet does not currently intend to\ncensor its news articles as a result of the Act. With regard to its humor newsgroup,\nClariNet is unsure what it will do to avoid liability.\nInstitute for Global Communications (IGC)\n111. Plaintiff IGC provides Internet web sites, access to the Internet, and other online\nservices primarily to nonprofit organizations. It serves approximately 400 nonprofit\ngroups, including SIECUS (the Sex Information and Education Council of the United\nStates), the Family Violence Prevention Fund, Stop Prisoner Rape, Human Rights Watch,\nPacifica Radio (disseminator of the original \"dirty words\" comic monologue), and\nnumerous women's rights groups whose online communications deal with sexual subject\nmatter, reproduction, rape, and domestic violence. It also serves approximately 15,000\nother groups, including approximately 500-600 schools, providing access to online\nservices.\n112. IGC also sponsors online discussion groups. IGC does not moderate these groups\nbut is aware that topics have included gay and lesbian sex and erotica, AIDS and HIV\ntreatment, women's health, and violence against women; many of the participants are\nminors.\n113. IGC does not have the resources to monitor the vast amount of information that is\npublished and communicated through its networks. Nor would it be consistent with IGC's\nfunction to monitor and censor the content of communications that it facilitates. IGC has\n\nno way to determine whether or not minors have gained access to specific sites on its\nnetwork, nor does it wish to restrict access to adults.\n114. IGC does not understand whether the defenses provided by the statute would protect\nit from criminal prosecution.\nStop Prisoner Rape (SPR)\n115. Plaintiff SPR maintains an extensive World Wide Web site on the Internet that\ncontains, among other things, graphic and uncensored accounts of actual rapes, written by\nthe victims themselves. The purpose of SPR is to provide education, information, and\nadvocacy regarding sexual assaults in the nation's prisons, jails, juvenile facilities, and\nother detention sites. It provides encouragement and advice to survivors, as well as\ncounseling and legal support. In 1995, \"Impact Online,\" which gives awards for\noutstanding non-profit Internet sites, named the SPR site the best on the web for prison\nissues and one of the 30 best non-profit sites.\n116. SPR believes that the graphic and uncensored nature of the information on its web\nsite is essential to its goal of educating the public and combating the persistent problem\nof prisoner rape.\n117. SPR believes that minors do access its web site, and believes it is essential to allow\nthis access to continue. Minors are among the victims of prisoner rape and are in fact\nwell-known and abundantly described in published literature on the subject to be\nparticularly singled out as targets for sexual assault precisely because of their youth.\nStatus as a minor is one of the surest demographic indicators of likely targeting for sexual\nassault of a prisoner in a facility which also includes adults. A significant portion of the\nSPR site contains recollections of individuals who were raped as minors while\nincarcerated with adults or in juvenile detention centers. The sharing of these experiences\nis invaluable to the many minors who have been imprisoned or who may be imprisoned\nand fear prison rape.\n118. Thus, for the reasons discussed in this Complaint, SPR does not currently intend to\nself-censor its online communications as a result of the Act.\nAIDS Education Global Information System (AEGIS)\n119. Plaintiff AEGIS, through its free computer bulletin board system, offers vital\ninformation about HIV and AIDS to people in many parts of the world who have no other\naccess to educational material about the disease. Much of the information in AEGIS is\nnecessarily sexually explicit because HIV/AIDS is a sexually transmitted disease.\nDocuments available from the AEGIS bulletin board include but are not limited to\nmaterials from the Center for Disease Control, Gay Men's Health Crisis, AIDS Treatment\nNews, and Body Positive Online Magazine.\n\n120. In addition to its archived material, AEGIS sponsors many online discussion groups\nfor people with AIDS or HIV. Discussion groups are offered in Dutch, French, Spanish,\nand German, in addition to English. Persons with HIV/AIDS use these online forums to\nshare experiences with other victims of the disease. Medical, social welfare, and other\npublic interest professionals also use the online forums to distribute information about the\ndisease and to answer questions posed by users. Discussions in these groups are often\nsexually explicit.\n121. AEGIS believes that it is essential to be able to use explicit language and pictures in\nits online communications and discussion groups. The information literally saves lives\nand must be communicated in terms that are not ambiguous or overly scientific and that\nall audiences can understand. Teenagers as well as adults need to have access to the\narchived information and online forums sponsored by AEGIS. Many teenagers are\nsexually active. They are entitled to information that could save their lives, presented in a\nfactual and descriptive form that is easily comprehended.\n122. Many people, including people who fear that they may be infected with HIV/AIDS,\nuse AEGIS to get information about the disease because they can do so anonymously.\nAEGIS does not want to screen to prevent minors from gaining access to its resources\nbecause such screening would infringe upon the privacy and anonymity of all users of the\nsystem. Moreover, AEGIS does not have the resources to monitor its online resources to\nscreen out content that is \"indecent\" or \"patently offensive,\" and any such screening\nprocess would undermine the educational and health goals of AEGIS's online services.\nThus, for the reasons discussed in this Complaint, AEGIS has not yet decided what\nchanges to make, if any, as a result of the Act.\nBiblioBytes\n123. Plaintiff BiblioBytes produces electronic books for sale over the World Wide Web,\nincluding romance novels, erotica, classics, adventure, and horror stories. Some of these\nelectronic publications contain language that is sexually explicit or vulgar or describes\nsexual or excretory activities or organs. One example of a current title in this category is\nHarlan Ellison's collection of short stories, Love Ain't Nothing But Sex Misspelled.\nSeveral of the stories in that collection include sexually explicit language and deal with\nevents such as abortion and prostitution. Another example of a current title that contains\nsexually explicit language is John Anderson's book, Panaflex X, which is a fictional\naccount of a woman trying to get out of the pornography industry.\n124. BiblioBytes believes that many minors have an interest in reading the books that\nBiblioBytes makes available online.\n125. BiblioBytes now requires a credit card for purchase of its electronic books.\nBiblioBytes is unsure if this process, which probably screens out most but not all minors,\nis sufficient to avoid liability under the Act. For the reasons discussed in this Complaint,\nBiblioBytes does not currently intend to take any additional steps to self-censor its online\ncommunications as a result of the Act.\n\nQueer Resources Directory\n126. Plaintiff Queer Resources Directory (QRD) is one of the largest online distributors\nof gay, lesbian, and bisexual resources on the Internet. QRD is accessed approximately\none million times a month and is distributed through several co-servers around the world.\nQRD contains links to online media; events; cultural information; business, legal,\npolitical and workplace issues; and gay, lesbian, and bisexual organizations. The topics\ncovered include parenting, families, marriage, youth organizations, religion, and\nHIV/AIDS. Some of the material is sexually explicit; for example, discussions of safer\nsex and human sexuality, and publications such as Hothead Paisan (a satiric comic book\nabout the adventures of a homicidal lesbian terrorist) and Cuir Underground (a magazine\ncovering events and people in the leather and fetish community).\n127. QRD does not wish to restrict minors from having access to its system. In fact, much\nof the material in QRD would be valuable to gay and lesbian teenagers who are\nstruggling with feelings of confusion or isolation, as well as to straight youth who want\ninformation about homosexuality. In addition, QRD believes that it is essential that\npeople be able to access its system anonymously.\n128. QRD has not made a decision on what procedures to institute, if any, should this\nstatute not be enjoined. QRD supports the use of voluntary Internet blocking software as\nan alternative to government regulation.\nCritical Path AIDS Project, Inc.\n129. Plaintiff Critical Path AIDS Project, Inc. provides free Internet access to individuals\nin the Philadelphia area and also operates a bulletin board, electronic mailing lists and a\nWeb site devoted to providing HIV/AIDS treatment information for persons with AIDS\nand safer sex information for those at risk of contracting AIDS. Critical Path's online\nresources include AIDS prevention and treatment information in eight different Asian\nlanguages, which reach youths and adults at risk for AIDS in some of the most\nunderserved communities in the nation. Critical Path also offers web subsites to such\nnonprofit groups as We the People (a large multiracial organization of HIV-positive\nindividuals), Prevention Point (a needle exchange program), Fight the Right (a political\naction network), and will soon be providing a subsite to the Youth Health Education\nProject, a safer sex outreach organization specifically targeted to teenagers. In the fall of\n1995 Critical Path was receiving about 10,000 access requests per day for information on\nits system from all over the world.\n130. The Critical Path AIDS Project web page links directly or indirectly to thousands of\ndatabases in all 50 states and many countries, thereby permitting users to access\ncommunications and retrieve documents from the far reaches of the world, without\nleaving the Critical Path web site.\n\n131. Much of the material on Critical Path's web site and bulletin board is necessarily\nsexually explicit. It is critically important as a matter of physical as well as emotional\nhealth that teenagers have access to the information that Critical Path provides.\n132. Thus, for the reasons discussed in this Complaint, Critical Path does not currently\nintend to self-censor its online communications as a result of the Act.\n133. Because of the vagueness of the defenses provided in the statute, Critical Path is\nunsure if it would be criminally liable for some of the communications posted by others\nfor which it provides access.\nWildcat Press, Inc.\n134. Plaintiff Wildcat Press, Inc. is a small independent publishing company specializing\nin classic gay and lesbian literature that promotes its publications by providing free\nexcerpts through its World Wide Web site. Wildcat Press maintains high literary\nstandards and has exhibited at the American Booksellers Association Convention.\n135. Some of the material in Wildcat Press's publications is sexually explicit or contains\nvulgar language. For example, the 1974 novel The Frontrunner tells the story of a loving\nrelationship between a young athlete and his coach during the days after the Stonewall\nRebellion and before the AIDS crisis. The sequel to that book, Harlan's Race, published\nin 1990, follows one of the characters from The Frontrunner as he reflects on the changes\nin the sexual behavior of the gay community brought on by AIDS.\n136. Wildcat Press sponsors the YouthArts Project which publishes two online youth\nmagazines, \"YouthArts East\" and \"YouthArts West,\" with support from students at the\nUniversity of Pennsylvania and University of Southern California. The online magazines\npublish poetry, fiction, essays, fine art, and photography by teenagers and are targeted to\nan audience of teenagers. Some of the material is sexually explicit. Teenagers can obtain\nthe magazine over the Web.\n137. Wildcat Press wishes to continue communicating with all interested readers,\nregardless of age. Wildcat Press believes that teenagers, especially gay and lesbian youth,\nare not harmed by but benefit from providing content to and obtaining access to the\nYouthArts Project.\n138. Thus, for the reasons discussed in this Complaint, Wildcat Press does not currently\nintend to self censor its online communications as a result of the Act.\nDeclan McCullagh dba Justice on Campus\n139. Plaintiff Declan McCullagh began Justice on Campus, a World Wide Web archive\nof information on student free speech issues, in the fall of 1995. Justice on Campus\nreceives about 150 visits to its web site daily. Although the site is housed on a private\ncomputer in Cambridge, Massachusetts attached to the Massachusetts Institute of\n\nTechnology network, McCullagh maintains editorial control over communications posted\non the site. Since many students, including college students, are under the age of 18,\nMcCullagh believes that a substantial number of minors visit the web site. Justice on\nCampus has been recognized as serving an important educational purpose, and its\nmaterials are assigned reading in one course at the Massachusetts Institute of\nTechnology.\n140. Some of the communications on the Justice on Campus site are sexually explicit or\ncontain vulgar language. For example, in the context of its free speech discussion, Justice\non Campus reproduced the texts of communications by students at Cornell University\nwhich were alleged to constitute sexual harassment. The actual language was necessary\nin order to focus on the issue of whether college administrators overreacted to the\nmaterial.\n141. McCullagh also maintains a list entitled \"fight-censorship\" to which people can\nsubscribe to receive information on censorship issues. The information includes explicit\nmaterial that has been subject to censorship by others.\n142. For the reasons discussed in this Complaint, Justice on Campus and McCullagh do\nnot currently intend to self-censor their online communications as a result of the Act.\nBrock Meeks dba CyberWire Dispatch\n143. As publisher and editor of CyberWire Dispatch (CWD), plaintiff Brock Meeks\naddresses many political and cyberspace issues, including Congressional attempts to\nregulate and to censor the Internet. CWD often employs vulgar and graphic language to\nmake a point about government censorship efforts. CWD has also published sexually\nexplicit material.\n144. Meeks also writes regularly as a columnist for the print magazine Wired and the\nonline magazine HotWired. Meeks sometimes uses vulgar and graphic speech in his\ncolumns to satirize or make political points.\n145. Meeks does not want to prevent minors, who are an important part of his audience,\nfrom reading the material in CWD and Hotwired.\n146. Thus, for the reasons discussed in this Complaint, Meeks does not currently intend\nto self-censor his online communications as a result of the Act.\nJohn Troyer, dba The Safer Sex Page\n147. Plaintiff John Troyer maintains the Safer Sex Page, a large site on the Internet's\nWorld Wide Web that offers educational information on safer sex. The Safer Sex Page is\naccessed by more than 35,000 people around the world every week.\n\n148. The Safer Sex Page includes a wide array of sex education materials from dozens of\nsources; brochures include graphics, audio, and video. The resources are both written\nspecifically for the Safer Sex Page and based on information received from other groups\nincluding the Center for Disease Control, the United States Department of Health and\nHuman Services, and the Los Angeles Gay and Lesbian Community Services Center.\n149. By their very nature, information and discussions about safer sex include explicit\nlanguage and pictures. Postings include guidelines about the risks associated with\ndifferent sexual acts. Explicitness is necessary to make safer sex materials\ncomprehensible. The public health threat of unsafe sex demands that people know with\nspecificity how to protect themselves.\n150. The Safer Sex Page includes an online discussion group called \"Safer Sex Forum\"\nthat allows participants to add their own comments to a monthly discussion topic. Users\nof the Safer Sex Forum often post comments on sexual subjects; past topics have\nincluded masturbation, condom brands, and how to talk to a partner about safer sex.\n151. Teenagers are an important audience for the resources offered through the Safer Sex\nPage and the Safer Sex Forum. Many teenagers are sexually active, or consider becoming\nsexually active before they reach adulthood. These minors are entitled to information that\ncould save their lives.\n152. Troyer is currently unsure whether he will self-censor his online communications as\na result of the Act.\nJonathan Wallace dba The Ethical Spectacle\n153. Plaintiff Jonathan Wallace publishes an online monthly newsletter entitled The\nEthical Spectacle under the pen name Jonathan Blumen. The newsletter examines the\nintersection of ethics, law and politics in society. Past issues have included articles on\nhuman experimentation by the Nazis at Auschwitz, and the morality of pornography. An\nupcoming issue will excerpt the writings of James Joyce, Henry Miller, William\nBurroughs, and other authors whose works include explicit sexual content and vulgar\nlanguage.\n154. Wallace does not wish to prevent minors from gaining access to The Ethical\nSpectacle Web page or to lose any teenage readers who may find instruction in the\nnewsletter.\n155. Thus, for the reasons discussed in this Complaint, Wallace does not currently intend\nto self-censor his online communications as a result of the Act.\nPlanned Parenthood Federation of America, Inc. (PPFA)\n156. PPFA's site on the World Wide Web provides a broad range of information relating\nto reproductive health. PPFA's site also provides educational and graphic information\n\nabout all facets of reproductive health, from contraception to prevention of sexually\ntransmitted infections, to finding an abortion provider, to information about which\nPlanned Parenthood affiliates have been providing abortions through use of the drug\nmifepristone. The educational information includes illustrations of how to place a\ncondom on a penis, and of male and female genitalia. The information PPFA presents is\nintended to be accessible to minors who seek it; and therefore frequently employs\nvernacular terminology, such as \"cum\" when referring to semen or ejaculation.\n157. PPFA's site also provides an e-mail service. Through this service, users can address\nquestions to PPFA on subjects such as abortion, contraception, prevention of sexually\ntransmitted infections, and sexuality, and PPFA responds with complete information.\nPPFA also receives information by e-mail regarding performing and obtaining abortions,\npractices necessary to reduce unintended pregnancies and sexually transmitted infections,\nand sexuality information generally.\n158. PPFA's site is accessible to any user seeking access. PPFA believes limitations on\naccess to its site would significantly diminish its effectiveness as a source of information,\nand PPFA does not currently intend to self-censor access.\n159. In addition to communicating via interactive computer services, PPFA sends and\nreceives information about performing and obtaining abortions through the mails and\ntelephone and FAX.\nAllegations Common to All Plaintiffs\n160. The effect of this statute, if implemented, would be to reduce adults to obtaining\naccess by computer to only that information that is fit for children.\n161. Given that American society is comprised of people from an endless variety of\nreligious, ethnic, cultural, political, and moral backgrounds, each with his or her own\nview of what constitutes \"indecent\" or \"patently offensive\" expression, these terms are\ncompletely vague and do not put any reasonable person on notice of what\ncommunications are prohibited.\n162. Plaintiffs and their members do not know how to define the terms \"indecent\" and\n\"patently offensive.\" All are forced as a consequence to guess at what communications\nwill be prosecuted. Because of its vagueness, the statute invites arbitrary and\ndiscriminatory enforcement, and chills constitutionally protected expression by the\nplaintiffs, their members, and other users of interactive computer services.\n163. The defenses provided under the statute are vague and contradictory. It is not clear\nwhat 47 U.S.C. Sec. 223(e)(1) means by a \"facility, system, or network\" not being \"under\n[the] control\" of a person since even online providers who do not themselves create the\ncontent of communications over their systems can technologically exercise \"control\" over\nthe communications for which they are conduits. It is also not clear whether 47 U.S.C.\nSec. 230(c)(1) provides a defense for anyone who is not a \"publisher or speaker.\" Thus,\n\nthose who act in part as access providers or hosts for interactive communications cannot\nknow to what extent they will be held liable for \"indecent\" or \"patently offensive\"\ncommunications to minors.\n164. Even if it may be technically feasible to devise a method to block access to\ncomputer communications by some or most minors, as a practical matter it is\neconomically infeasible. All of the plaintiffs would suffer serious economic hardship if\nthey were required to write separate versions of online communications: one for adults,\nand one for minors. Thus, the defense provided by section 223(e)(5) is not practically\navailable.\n165. Moreover, any blocking system would require advance identification of those\nseeking access to a web site, chat room, discussion group, or other online forum.\nInitiating age ID and blocking systems would undermine the essential purpose of the\nplaintiffs' communications -- to be disseminated as easily, widely, and quickly as\npossible, with a minimum of burden and expense.\n166. Any attempt to guarantee that minors could not access information that requires\nadvance identification of those seeking access would also make it impossible for users to\nengage in constitutionally protected anonymous speech on matters of public and private\nimportance.\n167. For those plaintiffs who have members who are minors, blocking access to online\ncommunications would deny minors access to materials that they could legally receive in\nprinted form or that they could legally given in a library or bookstore. It would deny them\naccess to materials that they have a constitutional right to receive.\n168. Section 223(e)(5) provides a defense for \"good faith, reasonable, effective, and\nappropriate actions\" to \"restrict or prevent access by minors ... including any method\nwhich is feasible.\" This defense is so vague that it is not possible for those plaintiffs who\nseek to fall within its provisions to know if they have taken the actions necessary to avoid\nliability.\n169. The plaintiffs fear prosecution or other enforcement under the statute for\ncommunicating, sending, or displaying \"indecent\" or \"patently offensive\" material in a\nmanner available to persons under age 18. They also fear liability for material posted by\nothers to their online discussion groups, chat rooms, bulletin boards, listservs, or web\nsites. Plaintiffs ACLU, PPFA, and others fear prosecution for distributing and receiving\ninformation about abortions and abortifacient drugs and devices in violation of 18 U.S.C.\nSec. 1462(c).\n170. Moreover, plaintiffs fear that if the statute goes into effect, online services and other\naccess providers such as educational institutions will ban communications that they\nconsider potentially \"indecent\" or \"patently offensive,\" thereby depriving the plaintiffs,\ntheir members, and those who use their online services of the ability to communicate\nabout important issues.\n\n171. The plaintiffs' web sites are linked to other web sites on the Internet in a virtually\nendless chain. There is no way for plaintiffs to screen the material on all of those linked\nsites or to prevent minors from accessing those sites.\nCAUSES OF ACTION\n172. Plaintiffs repeat and reallege Secs. 1-171.\n173. 47 U.S.C. Secs. 223(a)(1)(B) and (a)(2)(the \"indecency\" provision) and 223(d)(the\n\"patently offensive\" provision) violate the First Amendment to the United States\nConstitution on their face and as applied because they effect a total ban on\nconstitutionally protected communications in many parts of cyberspace. Even in those\nportions of cyberspace where it is technologically and economically feasible to deny\naccess to minors, Secs. 223(a)(1)(B) and (a)(2) and 223(d), are not the least restrictive\nmeans of accomplishing any compelling governmental purpose, and thus violate the First\nAmendment.\n174. 47 U.S.C. Secs. 223(a)(1)(B) and (a)(2) and 223(d) are vague, in violation of the\nFirst and Fifth Amendments to the United States Constitution.\n175. Even if the government could criminalize some constitutionally protected online\ncommunications to minors, 47 U.S.C. Secs. 223(a)(1)(B) and (a)(2) and 223(d) are\nunconstitutionally overbroad, in violation of the First Amendment, because they ban far\nmore constitutionally protected expression to minors than possibly could be justified by\nany governmental interest.\n176. 47 U.S.C. Secs. 223(a)(1)(B) and (a)(2) and 223(d) violate the First, Fourth, Fifth,\nand Ninth Amendment privacy rights of members and officers of the plaintiff\norganizations who use private e-mail.\n177. 47 U.S.C. Secs. 223(a)(1)(B) and (a)(2)and 223(d) violate the First Amendment\nrights of members of the plaintiff organizations and other users of computer resources to\nengage in anonymous speech.\n178. 18 U.S.C. Sec. 1462(c) on its face violates the First Amendment rights of members\nand officers of plaintiff ACLU, PPFA, and others who disseminate and receive\ninformation through express companies or other common carriers, or through interactive\ncomputer services, regarding women's access to abortions and abortifacient drugs and\ndoctors' abilities to perform abortions.\nWHEREFORE, plaintiffs respectfully request the Court to:\n(1) Declare that 47 U.S.C. Secs. 223(a)(1)(B) and (a)(2), 223(d), and 18 U.S.C. Sec.\n1462(c) violate the First, Fourth, Fifth, and Ninth Amendments to the U.S. Constitution\nand enjoin their enforcement.\n\n(2) Award plaintiffs reasonable attorneys' fees and costs.\n(3) Award such further relief as the Court deems just and appropriate.\nRespectfully submitted,\nChristopher A. Hansen\nMarjorie Heins\nAnn Beeson\nSteven R. Shapiro\nAmerican Civil Liberties Union Fdn.\n132 West 43rd St.\nNew York, NY 10036\n212-944-9800\nLaura K. Abel\nCatherine Weiss\nReproductive Freedom Project\nAmerican Civil Liberties Union Fdn.\n132 West 43 St.\nNew York, NY 10036\n212-944-9800\nStefan Presser\nAttorney ID No. 43067\nACLU of Pennsylvania\n125 South Ninth St., Suite 701\nPhiladelphia, PA 19107\n215-923-4357\nDavid L. Sobel\nMarc Rotenberg\nElectronic Privacy Information Center\n666 Pennsylvania Ave. SE, Suite 301\nWashington, D.C. 20003\n202-544-9240\n\nMichael Godwin\nElectronic Frontier Foundation\n1550 Bryant St., Suite 725\nSan Francisco, CA 941103\n415-436-9333\nAttorneys for all plaintiffs\nRoger Evans\nLegal Action for Reproductive Rights\nPlanned Parenthood Federation Of America\n810 Seventh Avenue\nNew York, New York 10019\n(212) 261-4708\nAttorney for Planned Parenthood Federation of America\nDated: February 8, 1996"
    },
    {
      "category": "Resource",
      "title": "alappat.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/fabe0363c6eacd8c27402fa967047660_alappat.pdf",
      "content": "AUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE 1\nCitation\nRank(R)\nDatabase\nMode\n33 F.3d 1526\nR 1 OF 1\nCTAF\nPage\n63 USLW 2088, 31 U.S.P.Q.2d 1545\n(CITE AS: 33 F.3D 1526)\nIn re Kuriappan P. ALAPPAT, Edward E. Averill and James G. Larsen.\nNo. 92-1381.\nUnited States Court of Appeals,\nFederal Circuit.\nJuly 29, 1994.\nApplicants appealed from reconsideration decision of Board of Patent\nAppeals and Interferences of the United States Patent and Trademark\nOffice which sustained rejection of claims of application as being\nunpatentable. After ordering matter to be heard en banc, 980 F.2d\n1439, the Court of Appeals, Rich, Circuit Judge, held that: (1)\nCommissioner of Patents and Trademarks had authority under statute\ngoverning Board of Appeals and Interferences to designate members of\npanel to consider request for reconsideration of Board's decision;\n(2) Board had sole authority to grant rehearing; and (3) computer\noperating pursuant to software may represent patentable subject\nmatter, as long as claimed subject matters meets all other statutory\npatentability claims. Reversed. Archer, Chief Judge, filed\nconcurring and dissenting opinion with which Nies, Circuit Judge,\njoined. Pauline Newman, Plager and Rader, Circuit Judges, filed\nconcurring opinions. Mayer, Circuit Judge, filed dissenting opinion\nwith which Michel, Circuit Judge, joined. Schall, Circuit Judge,\nfiled dissenting opinion, with which Clevenger, Circuit Judge,\njoined.\n*1529 Alexander C. Johnson, Jr., Marger, Johnson, McCollom &\nStolowitz, P.C., Portland, OR, argued for appellants. With him on\nthe brief was Peter J. Meza. Also on the brief was Francis I. Gray,\nTektronix, Inc., Wilsonville, OR. Allen M. Sokal, Finnegan,\nHenderson, Farabow, Garrett & Dunner, of Washington, DC, argued for\namicus curiae, Federal Circuit Bar Association. With him on the\nbrief were Gerald H. Bjorge, Herbert H. Mintz and George E.\nHutchinson. Fred E. McKelvey, Solicitor, Office of the Sol.,\nArlington, VA, argued for appellee. With him on the brief were Lee\nE. Barrett and Richard E. Schafer, Associate Sol. Of counsel were\nAlbin F. Drost and John W. Dewhirst. Herbert C. Wamsley and Richard\nC. Witte, Intellectual Property Owners, Inc., Washington, DC, were on\nthe brief for amicus curiae, Intellectual Property Owners, Inc.\nRichard H. Stern, Graham & James, Washington, DC, was on the brief\nfor amicus curiae, Seagate Technology, Inc. Also on the *1530 brief\n\nwas Edward P. Heller, III, Patent Counsel. Fred I. Koenigsberg and\nNancy J. Linck, Cushman, Darby & Cushman, Washington, DC, were on the\nbrief for amicus curiae, American Intellectual Property Law\nAssociation. Also on the brief were Harold C. Wegner and H. Ross\nWorkman, Wegner, Cantor, Mueller & Player, Washington, DC. Of\ncounsel was William S. LaFuze.\nBefore ARCHER, Chief Judge, and RICH, NIES, NEWMAN, MAYER, MICHEL,\nPLAGER, LOURIE, CLEVENGER, RADER and SCHALL, Circuit Judges.\nRICH, Circuit Judge, with whom: as to Part I (Jurisdiction): PAULINE\nNEWMAN, LOURIE and RADER, Circuit Judges, join; ARCHER, Chief Judge,\nNIES and PLAGER, Circuit Judges, concur in conclusion; and MAYER,\nMICHEL, CLEVENGER and SCHALL, Circuit Judges, dissent; and as to Part\nII (Merits): PAULINE NEWMAN, LOURIE, MICHEL, PLAGER and RADER,\nCircuit Judges, join; ARCHER, Chief Judge, and NIES, Circuit Judge,\ndissent; and MAYER, CLEVENGER and SCHALL, Circuit Judges, take no\nposition.\nKuriappan P. Alapatt, Edward E. Averill, and James G. Larsen\n(collectively Alappat) appeal the April 22, 1992, reconsideration\ndecision of the Board of Patent Appeals and Interferences (Board) of\nthe United States Patent and Trademark Office (PTO), Ex Parte\nAlappat, 23 USPQ2d 1340 (BPAI, 1992), which sustained the Examiner's\nrejection of claims 15-19 of application Serial No. 07/149,792 ('792\napplication) as being unpatentable under 35 U.S.C. s 101 (1988).\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1530)\nI. JURISDICTION\nThis court must determine whether the Board's reconsideration\ndecision constitutes a valid decision over which this court may\nexercise subject matter jurisdiction pursuant to 28 U.S.C. s\n1295(a)(4)(A) (1988) and 35 U.S.C. s 141 (1988). As discussed below,\nthe legality of the Board panel which issued the reconsideration\ndecision is in question, thus raising the issue of the validity of\nthe decision itself and consequently our authority to review that\ndecision. Therefore, before addressing the merits, it is appropriate\nthat we first determine that the decision was rendered by a legally\nconstituted panel to ensure that a jurisdictional cloud does not hang\nover our holding on the merits. See In re Bose Corp., 772 F.2d 866,\n869, 227 USPQ 1, 3-4 (Fed.Cir.1985). [FN1]\nFN1. In Bose, this court examined the composition of a panel of\n\nthe Trademark Trial and Appeal Board (TTAB), holding that this\ncourt has jurisdiction to decide whether a TTAB panel was\nproperly constituted when a decision from that panel is appealed.\nThis court stated in pertinent part: [I]t is appropriate for this\ncourt to determine whether a valid decision is before us before\naddressing the merits of that decision. The matter of the\nboard's composition is logically related to, indeed, inseparable\nfrom the merits and can be raised in the appeal from the board's\ndecision. Bose, 772 F.2d at 866, 227 USPQ at 3.\n[1] Although Alappat does not contest the validity of the Board's\nreconsideration decision, jurisdiction cannot be conferred on this\ncourt by waiver or acquiescence. Coastal Corp. v. United States, 713\nF.2d 728, 730 (Fed.Cir.1983). This court therefore has raised the\nissue of jurisdiction sua sponte, as is its duty. See Mansfield,\nColdwater & Lake Mich. Ry. Co. v. Swan, 111 U.S. 379, 382, 4 S.Ct.\n510, 511, 28 L.Ed. 462 (1884); Wyden v. Commissioner of Patents &\nTrademarks, 807 F.2d 934, 935, 231 USPQ 918, 919 (Fed.Cir.1986); see\nalso 5 WRIGHT & MILLER, FEDERAL PRACTICE AND PROCEDURE s 1393\n(1990).\nTo this end, this court, having decided to hear the case in banc,\nissued an Order on December 3, 1992, requesting briefing on the\nfollowing three questions:\n(1) When a three-member panel of the Board has rendered its\ndecision, does the Commissioner have the authority to constitute a\nnew panel for purposes of reconsideration?\n(2) If the Commissioner lacks such authority, is the decision of\nsuch a new panel a decision of the Board for purposes of 28 U.S.C. s\n1295(a)(4)(A)? If not, does this *1531 court have jurisdiction to\nreach the merits of the appealed decision?\n(3) What is the relationship, if any, between the \"reconsideration\"\naction taken in this case and \"rehearings\" by the Board provided for\nin 35 U.S.C. s 7(b)?\nConsistent with our discussion below, we hold that the answer to the\nfirst question is yes. Consequently, we need not address the second\nquestion. As to the third question, we hold, for the reasons\nexplained later, that the \"reconsideration\" by the Board was a\n\"rehearing\" as provided for in 35 U.S.C. s 7(b) (1988).\nA. Background\n\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1531)\nIn an Office Action mailed December 5, 1989, the Examiner finally\nrejected claims 15-19 under 35 U.S.C. s 101 as being directed to\nnon-statutory subject matter. Alappat appealed this rejection to the\nBoard pursuant to 35 U.S.C. s 134 (1988), and a three-member panel\nmade up of Examiners-in-Chief Lindquist, Thomas, and Krass reversed\nthe Examiner's non-statutory subject matter rejection in a decision\nmailed June 26, 1991. The Examiner then requested reconsideration of\nthis decision, pursuant to section 1214.04 of the Manual of Patent\nExamining Procedure (MPEP), stating that the panel's decision\nconflicted with PTO policy. The Examiner further requested that such\nreconsideration be carried out by an expanded panel. An expanded\neight-member panel, acting as the Board, granted both of the\nExaminer's requests. The expanded panel was made up of PTO\nCommissioner Manbeck, PTO Deputy Commissioner Comer, PTO Assistant\nCommissioner Samuels, Board Chairman Serota, Board Vice-Chairman\nCalvert, and the three members of the original panel. On April 22,\n1992, the five new members of the expanded panel issued the majority\ndecision now on appeal, authored by Chairman Serota, in which they\naffirmed the Examiner's s 101 rejection, thus ruling contrary to the\ndecision of the original three-member panel. The three members of\nthe original panel dissented on the merits for the reasons set forth\nin their original opinion, which they augmented in a dissenting\nopinion. The majority stated that its reconsideration decision was a\n\"new decision\" for purposes of requesting reconsideration or seeking\ncourt review of that decision. It did not, however, vacate the\noriginal three-member panel decision. Instead, the majority\nindicated that the original, three-member panel decision was only\n\"modified to the extent indicated.\" Alappat, 23 USPQ2d at 1347.\nThat \"modification\" was, however, a de facto reversal of the original\npanel's decision, affirming instead of reversing the examiner.\nB. Discussion\n(1) The Legality of the Board's Rehearing Panel\n[2] When statutory interpretation is at issue, the plain and\nunambiguous meaning of a statute prevails in the absence of clearly\nexpressed legislative intent to the contrary. See Mansell v.\nMansell, 490 U.S. 581, 592, 109 S.Ct. 2023, 2030, 104 L.Ed.2d 675\n(1989); Hoechst Aktiengesellschaft v. Quigg, 917 F.2d 522, 526, 16\nUSPQ2d 1549, 1552 (Fed.Cir.1990). In this case, the composition of\nthe Board and its authority to reconsider its own decisions, and the\n\nCommissioner's authority over the Board, are governed by 35 U.S.C. s\n7, which reads: (a) The examiners-in-chief shall be persons of\ncompetent legal knowledge and scientific ability, who shall be\nappointed to the competitive service. The Commissioner, the Deputy\nCommissioner, the Assistant Commissioners, and the examiners-in-chief\nshall constitute the Board of Patent Appeals and Interferences. (b)\nThe Board of Patent Appeals and Interferences shall, on written\nappeal of an applicant, review adverse decisions of examiners upon\napplications for patents and shall determine priority and\npatentability of invention in interferences declared under section\n135(a) of this title. Each appeal and interference shall be heard by\nat least three members of the Board of Appeals and Interferences, who\nshall be designated by the Commissioner. Only the Board of Patent\nAppeals and Interferences has the authority to grant rehearings. 35\nU.S.C. s 7 (1988) (emphasis added).\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1531)\n[3][4] For the reasons set forth below, we hold that s 7 grants the\nCommissioner the *1532 authority to designate the members of a panel\nto consider a request for reconsideration of a Board decision. This\nincludes, as in this case, the Commissioner designating an expanded\npanel made up of the members of an original panel, other members of\nthe Board, and himself as such, to consider a request for\nreconsideration of a decision rendered by that original panel. The\nBoard's reconsideration decision therefore constituted a valid\ndecision over which this court may exercise subject matter\njurisdiction.\n(a)\n[5][6] At the outset, we note that s 7(a) plainly and unambiguously\nprovides that the Commissioner, the Deputy Commissioner, and the\nAssistant Commissioners are members of the Board. Section 7(b)\nplainly and unambiguously requires that the Commissioner designate\n\"at least three\" Board members to hear each appeal. By use of the\nlanguage \"at least three,\" Congress expressly granted the\nCommissioner the authority to designate expanded Board panels made up\nof more than three Board members. [FN2]\nFN2. Both this court and the Court of Customs and Patent Appeals\n(CCPA), one of this court's predecessors, have reviewed Board\ndecisions rendered by panels made up of more than three Board members\n\nwithout questioning the validity of such panels. See e.g. Hahn v.\nWong, 892 F.2d 1028, 1031, 13 USPQ2d 1313, 1316 (Fed.Cir.1989)\n(seven-member panel because of significance of issues raised); In re\nLundak, 773 F.2d 1216, 1219, 227 USPQ 90, 92 (Fed.Cir.1985)\n(eighteen-member panel); In re Durden, 763 F.2d 1406, 1409 n. 3, 226\nUSPQ 359, 360 n. 3 (Fed.Cir.1985) (sixteen-member panel); In re\nHenriksen, 399 F.2d 253, 254 n. 1, 158 USPQ 224, 225 n. 1 (CCPA\n1968) (nine-member panel because of \"the nature of the legal issues\nraised\"). Other instances wherein the Commissioner has convened an\nexpanded panel include Ex parte Alpha Indus. Inc., 22 USPQ2d 1851,\n1852 (Bd.Pt.App. & Inter.1992) (five-member panel); Ex parte Fujii,\n13 USPQ2d 1073, 1074 (Bd.Pat.App. & Inter.1989) (five-member panel\nbecause of significance of issue raised); Ex parte Kristensen, 10\nUSPQ2d 1701, 1702 (Bd.Pat.App. & Inter.1989) (five-member panel); Ex\nparte Kitamura, 9 USPQ2d 1787, 1788 (Bd.Pat.App. & Inter.1988)\n(five-member panel because of possible conflict in case law); Lamont\nv. Berguer, 7 USPQ2d 1580, 1581 (Bd.Pat.App. & Inter.1988)\n(five-member panel because of novelty of issue raised); Kwon v.\nPerkins, 6 USPQ2d 1747, 1748 (Bd.Pat.App. & Inter.1988) (nine-member\npanel because of novelty of issues raised); Ex parte Horton, 226 USPQ\n697, 698 (Bd.Pat.App. & Inter.1985) (five-member panel); Ex parte\nTytgat, 225 USPQ 907, 908 (Bd.Pat.App. & Inter.1985) (five-member\npanel); and Ex parte Jackson, 217 USPQ 804, 806 (Bd.Pat.App. &\nInter.1982) (nine-member panel because legal issue was one of first\nimpression).\n[7] There is no evidence in the legislative history of s 7, or Title\n35 as a whole, clearly indicating that Congress intended to impose\nany statutory limitations regarding which Board members the\nCommissioner may appoint to an expanded panel or when the\nCommissioner may convene such a panel. [FN3] The Commissioner thus\nhas the authority to convene an expanded panel which includes, or as\nin this case is predominately made up of, senior executive\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1532)\nofficers of the PTO such as the Deputy Commissioner, the Assistant\nCommissioner, the Board's Chairman and Vice-Chairman, and himself.\n[FN4]\nFN3. The Commissioner has interpreted his authority to convene\n\nan expanded panel as granting him the authority to expand a\nthree-member panel to include additional Board members after oral\nhearing. See e.g. Ex parte Kuklo, 25 USPQ2d 1387, 1388\n(Bd.Pat.App. & Inter.1992) (five-member panel); Larson v.\nJohenning, 17 USPQ2d 1610, 1610 (Bd.Pat.App. & Inter.1991)\n(five-member panel); Ex parte Lyell, 17 USPQ2d 1548, 1549\n(Bd.Pat.App. & Inter.1990) (five-member panel); Ex parte Remark,\n15 USPQ2d 1498, 1498 (Bd.Pat.App. & Inter.1990) (five-member\npanel); Ex parte Kumagai, 9 USPQ2d 1642, 1643 (Bd.Pat.App. &\nInter.1988) (five-member panel).\nFN4. This is not to say that the Commissioner's authority to\ndesignate the members of a Board panel may or may not be\nconstrained by principles of due process or by Title 5, the\nAdministrative Procedure Act (APA). However, as noted herein,\nAlappat has not raised any such arguments in this appeal, and\ntherefore we need not address such issues.\n(b)\n[8] The focus of the jurisdictional inquiry in this case is the last\nsentence of s 7(b) which provides: \"Only the Board of Patent Appeals\nand Interferences has the authority to grant rehearings.\" The\nCommissioner contends that the reconsideration action taken in this\ncase constituted a type of \"rehearing\" as mentioned in the last\nsentence of s 7(b). For the reasons set forth below, we find the\nCommissioner's interpretation of s 7 *1533 to be a reasonable one\nentitled to deference, given that neither the statute itself nor the\nlegislative history thereof indicates Congressional intent to the\ncontrary.\n[9] We interpret the term \"rehearings\" in s 7 as encompassing any\nreconsideration by the Board of a decision rendered by one of its\npanels. The fact that s 7 refers to \"rehearings\" whereas 37 C.F.R.\n1.197 (PTO Rule 197) [FN5] refers to \"reconsideration\" is of no\nsignificance. The differing terminology appears to be nothing more\nthan the result of imprecise regulation drafting. [FN6] We have been\nunable to find any evidence suggesting that, in promulgating Rule\n197, the PTO intended to create a review process separate and\ndistinct from that provided by statute. In addition, our\ninterpretation finds support in In re Schmidt, 377 F.2d 639, 641, 153\nUSPQ 640, 642 (CCPA 1967), wherein the CCPA accepted, without\ncriticism, the PTO's treatment of a Board reconsideration pursuant to\nRule 197, on an examiner's request, as a \"rehearing\" provided for in\ns 7(b). [FN7]\n\nFN5. Rule 197(b) reads in pertinent part: A single request for\nreconsideration or modification of the decision may be made if\nfiled within one month from the date of the original\ndecision,....\nFN6. The terms \"rehearing\" and \"reconsideration\" are often used\ninterchangeably. In some contexts, a distinction is made between\nthe two. We see no basis, however, for imposing any such\ndistinctions in the context\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1533)\nof PTO Board proceedings, especially considering that the\nCommissioner argues that the PTO does not make such distinctions,\nciting McCrady, Patent Office Practice, s 235 (3d ed. 1950). We\nnote that McCrady's Patent Office Practice, 4th ed. (1959) states\nin s 235: \"These two terms 'reconsideration' and 'rehearing' seem\nto be treated by Rule 197 as interchangeable, and are so treated\nhere.\" Although not legislative history per se, we also note\nthat Karl Fenning, at the time a former Assistant Commissioner of\nPatents, stated during the 1926 House hearing on the bill to\ninclude the rehearing provision in the statute that \"It says\nrehearing, and rehearing, used in the technical or legal sense,\nis reconsideration.\" Procedure in the Patent Office, Hearing on\nH.R. 7563 and H.R. 13487 Before the Committee on Patents, United\nStates House of Representatives, 69th Cong., 2d Sess. 29 (1926)\n(1926 House Hearing ). Finally, we additionally note that\nBlack's Law Dictionary defines \"rehearing\" in part as a \"[s]econd\nconsideration of cause for purpose of calling to court's or\nadministrative board's attention any error, omission, or\noversight in first consideration.\" Black's Law Dictionary (6th\ned. 1990). Black's defines \"reconsideration\" as follows: \"[a]s\nnormally used in the context of administrative adjudication\n'reconsideration' implies reexamination, and possibly a different\ndecision by the entity which initially decided it.\"\nFN7. Apparently, the Board's reconsideration decision in the\npresent case was based on the same record that was before the\noriginal three-member panel, and Alappat was not allowed an\nopportunity to add to that record. We do not intend to suggest\nherein that \"rehearings\" under s 7(b) are limited to such\nsituations. Indeed, it would not be unreasonable to construe\n\"rehearings\" under s 7(b) broadly as also encompassing\n\nreconsideration by the Board wherein the Board allows an\napplicant to supplement the existing record or wherein the Board\nallows both the applicant and the examiner to brief the issues\nanew.\n[10] We also interpret the Commissioner's express statutory\nauthority to designate the members of a panel hearing an appeal as\nextending to designation of a panel to consider a request for a\nrehearing pursuant to s 7(b). [FN8] There is no indication to the\ncontrary in the statute, and we have found no legislative history\nindicating a clear Congressional intent that the Commissioner's\nauthority to designate the members of a Board panel be limited to the\ndesignation of an original panel or that the Board be limited to\nexercising its rehearing authority only through the panel which\nrendered an original decision. In those cases where a different\n*1534 panel of the Board is reconsidering an earlier panel decision,\nthe Board is still the entity reexamining that earlier decision; it\nis simply doing so through a different panel.\nFN8. The Commissioner has consistently interpreted his statutory\nauthority to designate the constituency of a Board panel as allowing\nhim to change or augment an originally designated panel in response\nto a request for reconsideration. See e.g. Ex parte Johnson, Appeal\nNo. 91-0143 (Bd.Pat.App. & Inter.1991) (on request for\nreconsideration, augmented panel\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1534)\nof seven examiners-in-chief granted the request and voted four to\nthree to affirm the examiner, contrary to the original\nthree-member panel); Ex parte Holt, 218 USPQ 747, 747\n(Bd.App.1982) (on request for reconsideration by Group Director,\nrehearing granted by an augmented fifteen-member panel); Ex parte\nScherer, 103 USPQ 107, 107-08 (Bd.App.1954) (rehearing by an\naugmented eleven-member panel granted because of probable\nimportance of issues); Ex parte Ball, 99 USPQ 146, 146\n(Bd.App.1953) (reconsideration granted to allow further\nconsideration by an augmented eight-member panel including the\nCommissioner); Ex parte Wiegand, 61 USPQ 97, 99 (Bd.App.1944)\n(rehearing by a different three- member panel).\n\n[11] The last sentence of s 7(b) is nothing more than an\nexclusionary statement vesting the Board with the sole authority to\ngrant a rehearing. Thus, for example, the Commissioner cannot\npersonally grant a rehearing, notwithstanding the general authority\nthat he has over the operation of the PTO. For a general history of\nthe Board and of appeals within and from the PTO, see Michael W.\nBlommer, The Board of Patent Appeals and Interferences, AIPLA\nBulletin 188 (1992), P.J. Federico, The Board of Appeals 1861-1961,\n43 JPOS 691 (1961), and Evolution of Patent Office Appeals, 22 JPOS\n838-64, 920- 49 (1940).\nThe predecessor of s 7 was section 482 of the Revised Statutes, as\namended by the Act of March 2, 1927. The 1927 Act added to the Board\nthe Commissioner, the First Assistant Commissioner, and the Assistant\nCommissioner. It also eliminated the right of an applicant to appeal\nto the Commissioner from an adverse Board decision, by adding to the\nstatute the language \"[t]he the Board of Appeals shall have sole\npower to grant rehearings,\" essentially the same provision as in\ntoday's s 7(b). Act of March 2, 1927, ch. 273, s 3, 44 Stat. 1335.\nPrior to this amendment, the Commissioner acted on petitions for\nrehearing of adverse Board decisions. Through this amendment,\nCongress effectively eliminated the onerous burden placed on the\nCommissioner regarding reviewing such appeals, instead steering\napplicants to the Board with such requests.\nThe events surrounding the enactment of the 1927 Act do not indicate\nany Congressional intent to lessen the great supervisory power that\nthe Commissioner possessed over the PTO prior to that Act. [FN9]\nIndeed, at the end of the 1926 House and Senate hearings during which\nthe last sentence of what is now s 7(b) was discussed, the Senate\nCommittee on Patents concluded:\nFN9. The Commissioner's supervisory authority under Section 482\nof the Revised Statutes prior to the 1927 Act was described aptly\nas follows: The law has provided certain official agencies to aid\nand advance the work of the Patent Office, such as the Primary\nExaminers, the Examiners of Interferences [now obsolete], and the\nExaminers-in-Chief; but they are all subordinate, and subject to\nthe official direction of the Commissioner of Patents, except in\nthe free exercise of their judgments in the matters submitted for\ntheir examination and determination. The Commissioner is the\nhead of the bureau, and he is responsible for the general issue\nof that bureau. Moore v. United States, 40 App.D.C. 591, 596\n(D.C.Cir.1913), quoting\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n\n(CITE AS: 33 F.3D 1526, *1534)\nIn re Drawbaugh, 9 App.D.C. 219, 240 (D.C.Cir.1896).\nOne lawyer [remarks of Fenning, chairman of the committee on laws\nand rules of the American Patent Law Association, Procedure in the\nPatent Office, Hearing on S. 4812 Before the Committee on Patents,\nUnited States Senate, 69th Con.2d Sess. 19, 21-22 (1926) ] has\nexpressed the fear that in providing in lines 16- 17, page 2 (sec.\n482) [the precursor to section 7(b) ], that the board of appeals\nshall have the sole power to grant \"rehearings,\" the bill may lessen\nthe present supervisory power of the commissioner, but it was agreed\nby the other lawyers at the hearing, and the Committee on Patents\nconcurs in this view, that the supervisory power of the commissioner,\nas it has existed for a number of decades, remains unchanged by the\nbill. S.Rep. No. 1313, 69th Cong., 2d Sess. 4 (1927) (emphasis\nadded). Fenning expressed the same concerns to the House Committee\non Patents. 1926 House Hearing at 22-23. The House Committee\nReport, H.R. No. 1889, 69th Cong., 2d Sess. (1927), is silent on the\nissue, thus suggesting that the House did not intend to give the last\nsentence of s 7(b) a different meaning than was ascribed to it by the\nSenate. We believe the foregoing illustrates the lack of intent on\nthe part of Congress in enacting the last sentence of s 7(b) to place\nany limitations on the Commissioner's ability to designate Board\npanels, including Board panels for \"rehearing\" purposes.\n(c)\n[12][13] Our holding is consistent with the broad supervisory\nauthority that Congress has granted the Commissioner under *1535\nTitle 35 regarding the operation of the PTO. Exemplary thereof is s\n6(a), which reads in pertinent part:\nThe Commissioner, under the direction of the Secretary of Commerce,\nshall superintend or perform all duties required by law respecting\nthe granting and issuing of patents. 35 U.S.C. s 6(a) (1988)\n(emphasis added). The Commissioner also may establish regulations\nnot inconsistent with the law, with the approval of the Secretary of\nCommerce, 35 U.S.C. s 6 (1988), cause an examination to be made of an\napplication, 35 U.S.C. s 131 (1988), declare an interference, 35\nU.S.C. s 135 (1988), and issue a patent when authorized by law, 35\nU.S.C. ss 131, 145 (1988), 151 (1988), 153 (1988).\nMoreover, the Commissioner is not bound by a Board decision that an\napplicant is entitled to a patent. Only a court can order the\nCommissioner to act, not the Board. Even though Board members serve\n\nan essential function, they are but examiner-employees of the PTO,\nand the ultimate authority regarding the granting of patents lies\nwith the Commissioner. [FN10] For example, if the Board rejects an\napplication, the Commissioner can control the PTO's position in any\nappeal through the Solicitor of the PTO; the Board cannot demand that\nthe Solicitor attempt to sustain the Board's position. Conversely,\nif the Board approves an application, the Commissioner has the option\nof refusing to sign a patent; an action which would be subject to a\nmandamus action by the applicant. The Commissioner has an obligation\nto refuse to grant a patent if he believes that doing so would be\ncontrary to law. The foregoing evidences that the Board is merely\nthe highest level of the Examining Corps, and like all other members\nof the Examining Corps, the Board operates subject to the\nCommissioner's overall ultimate authority and responsibility.\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1535)\nFN10. Examiners-in-chief are appointed by the Secretary of\nCommerce upon nomination by the Commissioner. Thus, principles\nrespecting the independence of judges or other concepts\nassociated with the judicial process are not necessarily\napplicable to Board members. The fact that we apply the clearly\nerroneous standard of review rather than the more restrictive\nsubstantial evidence standard usually applied to administrative\nboards illustrates the purely administrative nature of the Board.\nOne also should not overlook the asymmetry of s 141, which grants\napplicants, but not the Commissioner, the right to appeal a decision\nof the Board to this court. Since Congress has reenacted s 141\nseveral times since the 1927 debates about the Board's independence,\nsee 1926 House Hearing at 22-29, it is safe to infer that Congress\nbelieved the Commissioner did not need a right of appeal in view of\nhis limited control over the Board pursuant to s 7 and in view of his\nrulemaking authority pursuant to s 6(a).\n(d)\nContrary to suggestions by Amicus Curiae Federal Circuit Bar\nAssociation (FCBA), our holding does not conflict with this court's\nprevious statements in Animal Legal Defense Fund v. Quigg, 932 F.2d\n920, 928-29, 18 USPQ2d 1677, 1684 (Fed.Cir.1991), that the Board is\nnot the alter ego or agent of the Commissioner. In that case, this\n\ncourt merely pointed out that the Board derives its adjudicatory\nauthority from a statutory source independent of the Commissioner's\nrulemaking authority, and that, although the Commissioner may sit on\nthe Board, \"in that capacity he serves as any other member.\" Animal\nLegal Defense Fund, 932 F.2d at 929 n. 10, 18 USPQ2d at 1684 n. 10.\nIn other words, the Commissioner has but one vote on any panel on\nwhich he sits, and he may not control the way any individual member\nof a Board panel votes on a particular matter. However, the present\nstatutory scheme does allow the Commissioner to determine the\ncomposition of Board panels, and thus he may convene a Board panel\nwhich he knows or hopes will render the decision he desires, even\nupon rehearing, as he appears to have done in this case.\n[14] Such a result does not reduce the Board to an alter ego or\nagent of the Commissioner. To the contrary, the fact remains that\nthe Commissioner may not unilaterally overturn a decision of a Board\npanel or instruct other Board members how to vote. The\nCommissioner's limited control in this *1536 manner over the Board\nand the decisions it issues is not offensive to Title 35 as a whole,\ngiven that Congress clearly did not intend the Board to be\nindependent of any and all oversight by the Commissioner. See e.g.\nLindberg v. Brenner, 399 F.2d 990, 992-93, 158 USPQ 380, 381-82\n(D.C.1968). The plain and unambiguous wording of s 7 intertwining\nthe powers of the Board and the Commissioner clearly indicates that\nCongress did not intend the Board to have such complete independence.\n(e)\nAmicus Curiae FCBA suggests that the Commissioner's redesignation\npractices in this case violated Alappat's due process rights, citing\nUtica Packing Co. v. Block, 781 F.2d 71 (6th Cir.1986). In\naddition, an issue was raised at oral argument as to whether the\nCommissioner's designation practices are governed by any provisions\nof the Administrative Procedure Act (APA), and if so, whether the\nCommissioner's actions in this case violated any of these provisions.\nWe\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1536)\nneed not address either of these issues.\n[15] The FCBA does not have standing to make a due process argument,\nsee Broadrick v. Oklahoma, 413 U.S. 601, 610, 93 S.Ct. 2908, 2915, 37\nL.Ed.2d 830 (1973) (\"constitutional rights are personal and may not\n\nbe asserted vicariously\") and United Parcel Service, Inc. v.\nMitchell, 451 U.S. 56, 60 n. 2, 101 S.Ct. 1559, 1562 n. 2, 67 L.Ed.2d\n732 (1981) (amicus may not rely on new arguments not presented\nbelow), and Alappat has waived any due process argument by\nacquiescing to the Commissioner's actions in this case. Thus, there\nis no case or controversy before this court with respect to any\nalleged due process violation. There also is no case or controversy\nas to whether the Commissioner's actions in this case violated any\nprovision of the APA, given that Alappat does not contest these\nactions, and this is not an issue which this court may raise sua\nsponte. Moreover, neither of these issues is germane to the\njurisdictional issue this court raised sua sponte, i.e., whether the\nBoard's reconsideration decision constituted a statutorily valid\ndecision under 35 U.S.C. s 141 over which this court may exercise\nsubject matter jurisdiction pursuant to 28 U.S.C. s 1294(a)(4)(A).\n(f)\n[16] Finally, we acknowledge the considerable debate and concern\namong the patent bar and certain Board members regarding the\nCommissioner's limited ability to control Board decisions through his\nauthority to designate Board panels. [FN11] Our responsibility,\nhowever, is merely to adjudge whether the Commissioner's designation\npractices as they were applied in this particular case resulted in a\nvalid decision over which this court may exercise subject matter\njurisdiction, not to assess whether they were sound from a public\npolicy standpoint. We leave to the legislature to determine whether\nany restrictions should be placed on the Commissioner's authority in\nthis regard. Absent any congressional intent to impose such\nrestrictions, we decline to do so sua sponte.\nFN11. See e.g. En Banc Federal Circuit Will Consider Board of\nAppeals Issues in Alappat Case, 45 PTCJ 107 (1992); Changes Urged in\nStructure and Operation of PTO Appeals Board, 45 PTCJ 75 (1992);\nIndependence of the Board of Patent Appeals and Interferences,\nFederal Circuit Bar Journal, Vol. 2, No 2, pg. 215 (1992); CLE\nWeekend Highlights, 33 NYPTC Bull. 6 (1992); Patent and Trademark\nOffice Authorization Act, 138 Cong.Rec. S16, 614 (1992), reprinted in\n44 PTCJ 618-19 (1992); Review of Patent and Trademark Office Appeal\nProcedure, 57 FR 34123 (1992), reprinted in 44 PTCJ 352 (1992);\nComments Sought on Commissioner's Relationship with Appellate Boards,\n44 PTCJ 325 (1992); PTO's Automation and Board Autonomy at Issue in\nHouse Hearing on PTO Budget, 44 PTCJ 102, 103 (1992); Correspondence\nBetween Board Members and PTO Commissioner on Board Independence, 44\nPTCJ 43 (1992); Members of Board of Appeals Complain about\n\nInterference with Independence, 44 PTCJ 33 (1992); Michael W.\nBlommer, The Board of Patent Appeals and Interferences, AIPLA\nBulletin 188 (1992).\nII. THE MERITS\nOur conclusion is that the appealed decision should be reversed\nbecause the appealed claims are directed to a \"machine\" which is one\nof the categories\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1536)\nnamed in 35 U.S.C. s 101, as the first panel of the Board held.\n*1537 A. Alappat's Invention\nAlappat's invention relates generally to a means for creating a\nsmooth waveform display in a digital oscilloscope. The screen of an\noscilloscope is the front of a cathode-ray tube (CRT), which is like\na TV picture tube, whose screen, when in operation, presents an array\n(or raster) of pixels arranged at intersections of vertical columns\nand horizontal rows, a pixel being a spot on the screen which may be\nilluminated by directing an electron beam to that spot, as in TV.\nEach column in the array represents a different time period, and each\nrow represents a different magnitude. An input signal to the\noscilloscope is sampled and digitized to provide a waveform data\nsequence (vector list), wherein each successive element of the\nsequence represents the magnitude of the waveform at a successively\nlater time. The waveform data sequence is then processed to provide\na bit map, which is a stored data array indicating which pixels are\nto be illuminated. The waveform ultimately displayed is formed by a\ngroup of vectors, wherein each vector has a straight line trajectory\nbetween two points on the screen at elevations representing the\nmagnitudes of two successive input signal samples and at horizontal\npositions representing the timing of the two samples.\nBecause a CRT screen contains a finite number of pixels, rapidly\nrising and falling portions of a waveform can appear discontinuous or\njagged due to differences in the elevation of horizontally contiguous\npixels included in the waveform. In addition, the presence of\n\"noise\" in an input signal can cause portions of the waveform to\n\noscillate between contiguous pixel rows when the magnitude of the\ninput signal lies between values represented by the elevations of the\ntwo rows. Moreover, the vertical resolution of the display may be\nlimited by the number of rows of pixels on the screen. The\nnoticeability and appearance of these effects is known as aliasing.\nTo overcome these effects, Alappat's invention employs an\nanti-aliasing system wherein each vector making up the waveform is\nrepresented by modulating the illumination intensity of pixels having\ncenter points bounding the trajectory of the vector. The intensity\nat which each of the pixels is illuminated depends upon the distance\nof the center point of each pixel from the trajectory of the vector.\nPixels lying squarely on the waveform trace receive maximum\nillumination, whereas pixels lying along an edge of the trace receive\nillumination decreasing in intensity proportional to the increase in\nthe distance of the center point of the pixel from the vector\ntrajectory. Employing this anti-aliasing technique eliminates any\napparent discontinuity, jaggedness, or oscillation in the waveform,\nthus giving the visual appearance of a smooth continuous waveform.\nIn short, and in lay terms, the invention is an improvement in an\noscilloscope comparable to a TV having a clearer picture.\nReference to Fig. 5A of the '792 application, reproduced below,\nbetter illustrates the manner in which a smooth appearing waveform is\ncreated. *1538\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1538)\n<IMAGE 1 (2.75\" X 1.25\") IS AVAILABLE VIA OFFLINE PRINT TO STP AND\nNOW>\n----------\nEACH SQUARE IN THIS FIGURE REPRESENTS A PIXEL, AND THE INTENSITY\nLEVEL AT WHICH EACH PIXEL IS ILLUMINATED IS INDICATED IN\nHEXADECIMAL\nNOTATION BY THE NUMBER OR LETTER FOUND IN EACH SQUARE.\nHEXADECIMAL\nNOTATION HAS SIXTEEN CHARACTERS, THE NUMBERS 0-9 AND THE\nLETTERS A-F,\nWHEREIN A REPRESENTS 10, B REPRESENTS 11, C REPRESENTS 12, D\n\nREPRESENTS 13, E REPRESENTS 14, AND F REPRESENTS 15. THE INTENSITY\nAT WHICH EACH PIXEL IS ILLUMINATED INCREASES FROM 0 TO F.\nACCORDINGLY, A SQUARE WITH A 0 (ZERO) IN IT REPRESENTS A PIXEL\nHAVING\nNO ILLUMINATION, AND A SQUARE WITH AN F IN IT REPRESENTS A PIXEL\nHAVING MAXIMUM ILLUMINATION. ALTHOUGH HEXADECIMAL\nNOTATION IS USED\nIN THE FIGURE TO REPRESENT INTENSITY ILLUMINATION, THE INTENSITY\nLEVEL IS STORED IN THE BIT MAP OF ALAPPAT'S SYSTEM AS A 4-BIT\nBINARY\nNUMBER, WITH 0000 REPRESENTING A PIXEL HAVING NO ILLUMINATION\nAND\n1111 REPRESENTING A PIXEL HAVING MAXIMUM ILLUMINATION. POINTS\n54 AND\n52 IN FIG. 5A REPRESENT SUCCESSIVE OBSERVATION POINTS ON THE\nSCREEN\nOF AN OSCILLISCOPE. WITHOUT THE BENEFIT OF ALAPPAT'S anti-aliasing\nsystem, points 54 and 52 would appear on the screen as separate,\nunconnected spots. In Alappat's system, the different intensity\nlevel at which each of the pixels is illuminated produces the\nappearance of the line 48, a so-called vector. The intensity at\nwhich each pixel is to be illuminated is determined as follows, using\npixel 55 as an example. First, the vertical distance between the y\ncoordinates of observation points 54 and 52(<<triangle>>y subi ) is\ndetermined. In this example, this difference equals 7 units, with one\nunit representing the center-to-center distance of adjacent pixels.\nThen, the elevation of pixel 55 above pixel 54 (<<triangle>>y subi,j\n) is determined, which in this case is 2 units. The <<triangle>>y\nsubi and <<triangle>>y subi,j values are then \"normalized,\" which\nAlappat describes as converting these values to larger values which\nare easier to use in mathematical calculations. In Alappat's\nexample, a barrel shifter is used to shift the binary input to the\nleft by the number of bits required to set the most significant\n(leftmost) bit of its output signal to \"1.\" The <<triangle>>y subi\nand <<triangle>>y subi,j\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1538) values are then plugged into a\nmathematical equation for determining the intensity at which the\nparticular pixel is to be illuminated. In this particular example,\nthe equation I'(i, j) = [1 - (<<triangle>>y subi,j /<< triangle>>y\nsubi )]F, wherein F is 15 in hexadecimal notation, suffices. The\nintensity of pixel 55 in this example would thus be calculated as\n\nfollows:\n[1 - ( 2/7 ) ]15 = ( 5/7 )15 = 10.71 C 11 (or B).\nAccordingly, pixel 55 is illuminated at 11/15 of the intensity of\nthe pixels in which observation points 54 and 52 lie. Alappat\ndiscloses that the particular formula used will vary depending on the\nshape of the waveform.\nB. The Rejected Claims\nClaim 15, the only independent claim in issue, reads:\nA rasterizer for converting vector list data representing sample\nmagnitudes of an *1539 input waveform into anti-aliased pixel\nillumination intensity data to be displayed on a display means\ncomprising: (a) means for determining the vertical distance between\nthe endpoints of each of the vectors in the data list; (b) means for\ndetermining the elevation of a row of pixels that is spanned by the\nvector; (c) means for normalizing the vertical distance and\nelevation; and (d) means for outputting illumination intensity data\nas a predetermined function of the normalized vertical distance and\nelevation. Each of claims 16-19 depends directly from claim 15 and\nmore specifically defines an element of the rasterizer claimed\ntherein. Claim 16 recites that means (a) for determining the\nvertical distance between the endpoints of each of the vectors in the\ndata list, <<triangle>>y subi described above, comprises an\narithmetic logic circuit configured to perform an absolute value\nfunction. Claim 17 recites that means (b) for determining the\nelevation of a row of pixels that is spanned by the vector,\n<<triangle>>y subi,j described above, comprises an arithmetic logic\ncircuit configured to perform an absolute value function. Claim 18\nrecites that means (c) for normalizing the vertical distance and\nelevation comprises a pair of barrel shifters. Finally, claim 19\nrecites that means (d) for outputting comprises a read only memory\n(ROM) containing illumination intensity data. As the first Board\npanel found, each of (a)-(d) was a device known in the electronics\narts before Alappat made his invention. C. The Examiner's Rejection\nand Board Reviews The Examiner's final rejection of claims 15-19 was\nunder 35 U.S.C. s 101 \"because the claimed invention is non statutory\nsubject matter,\" and the original three-member Board panel reversed\nthis rejection. That Board panel held that, although claim 15\nrecites a mathematical algorithm, the claim as a whole is directed to\na machine and thus to statutory subject matter named in s 101. In\nreaching this decision, the original panel construed the means\nclauses in claim 15 pursuant to 35 U.S.C. s 112, paragraph six (s 112\n\nP 6), as corresponding to the respective structures disclosed in the\nspecification of Alappat's application, and equivalents thereof. In\nits reconsideration decision, the five-member majority of the\nexpanded, eight-member Board panel \"modified\" the decision of the\noriginal panel and affirmed the Examiner's s 101 rejection. The\nmajority held that the PTO need not apply s 112 P 6 in rendering\npatentability determinations, characterizing this court's statements\nto the contrary in In re Iwahashi, 888 F.2d 1370,\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1539) 1375, 12 USPQ2d 1908, 1912\n(Fed.Cir.1989), \"as dicta,\" and dismissing this court's discussion of\ns 112 P 6 in Arrhythmia Research Technology, Inc. v. Corazonix\nCorp., 958 F.2d 1053, 1060, 22 USPQ2d 1033, 1038 (Fed.Cir.1992) on\nthe basis that the rules of claim construction in infringement\nactions differ from the rules for claim interpretation during\nprosecution in the PTO. The majority stated that, during\nexamination, the PTO gives means-plus-function clauses in claims\ntheir broadest interpretation and does not impute limitations from\nthe specification into the claims. See Applicability of the Last\nParagraph of 35 USC s 112 to Patentability Determinations Before the\nPatent and Trademark Office, 1134 TMOG 633 (1992); Notice\nInterpreting In Re Iwahashi (Fed.Cir.1989), 1112 OG 16 (1990).\nAccordingly, the majority held that each of the means recited in\nclaim 15 reads on any and every means for performing the particular\nfunction recited.\nThe majority further held that, because claim 15 is written\ncompletely in \"means for\" language and because these means clauses\nare read broadly in the PTO to encompass each and every means for\nperforming the recited functions, claim 15 amounts to nothing more\nthan a process claim wherein each means clause represents only a step\nin that process. The majority stated that each of the steps in this\npostulated process claim recites a mathematical operation, which\nsteps combine to form a \"mathematical algorithm for computing pixel\ninformation,\" Alappat, 23 USPQ2d at 1345, and that, \"when the claim\nis viewed without the steps of this mathematical algorithm, no other\nelements or steps are *1540 found.\" Alappat, 23 USPQ2d at 1346. The\nmajority thus concluded that the claim was directed to nonstatutory\nsubject matter. [FN12]\nFN12. See also Patent and Trademark Practice is Reviewed at PTO\nDay, 45 PTCJ 245, 246 (1993); IP Laws Attempt to Adapt to Changes of\nNew Technologies, 45 PTCJ 49 (1993); Federal Circuit Will Hear In Re\n\nAlappat Case En Banc, 45 PTCJ 56 (1992); \"Means For\" Claim Recites\nNon- Statutory Algorithm When Treated as Method Claim, 44 PTCJ 69\n(1992); MPEP s 2110.\nIn its analysis, the majority further stated:\nIt is further significant that claim 15, as drafted, reads on a\ndigital computer \"means\" to perform the various steps under program\ncontrol. In such a case, it is proper to treat the claim as if drawn\nto a method. We will not presume that a stored program digital\ncomputer is not within the s 112 P 6 range of equivalents of the\nstructure disclosed in the specification. The disclosed ALU, ROM and\nshift registers are all common elements of stored program digital\ncomputers. Even if appellants were willing to admit that a stored\nprogram digital computer were not within the range of equivalents, s\n112 P 2 requires that this be clearly apparent from the claims based\nupon limitations recited in the claims.\nAlappat, 23 USPQ2d at 1345. [FN13] The Board majority also stated\nthat dependent claims 16-19 were not before them for consideration\nbecause they had not been argued by Alappat and thus not addressed by\nthe Examiner or the original three-member Board panel. Alappat, 23\nUSPQ2d at 1341 n. 1. [FN14]\nFN13. See also PTO Report on Patentable Subject Matter:\nMathematical Algorithms and Computer Programs, 1106 TMOG 5 (1989),\nreprinted in 38\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1540)\nPTCJ 551, 563 (1989).\nFN14. Nevertheless, we note that the Examiner stated during\nprosecution: \"the use of physical elements to provide the 'number\ncrunching' is not considered patentable. The mere display of\nillumination intensity data is not considered significant post\nsolution activity.\" 12/05/89 Office action, pg. 4. Thus, even\nif the specific structures recited in dependent claims 16-19 had\nbeen incorporated into claim 15, the Examiner presumably would\nhave found claim 15 to be directed to nonstatutory subject\nmatter.\nD. Analysis\n\n(1) Section 112, Paragraph Six\n[17] As recently explained in In re Donaldson, 16 F.3d 1189, 1193,\n29 USPQ2d 1845, 1050 (Fed.Cir.1994), the PTO is not exempt from\nfollowing the statutory mandate of s 112 P 6, which reads: An element\nin a claim for a combination may be expressed as a means or step for\nperforming a specified function without the recital of structure,\nmaterial, or acts in support thereof, and such claim shall be\nconstrued to cover the corresponding structure, material, or acts\ndescribed in the specification and equivalents thereof. 35 U.S.C. s\n112, paragraph 6 (1988) (emphasis added). [FN15] The Board majority\ntherefore erred as a matter of law in refusing to apply s 112 P 6 in\nrendering its s 101 patentable subject matter determination.\nFN15. Accord, In re Bond, 910 F.2d 831, 833, 15 USPQ2d 1566,\n1568 (Fed.Cir.1990); In re Iwahashi, 888 F.2d 1370, 1375, 12\nUSPQ2d 1908, 1912 (Fed.Cir.1989); In re Meyer, 688 F.2d 789, 796,\n215 USPQ 193, 199 (CCPA1982); In re Knowlton, 481 F.2d 1357,\n1366, 178 USPQ 486, 492-93 (CCPA1973); In re Foster, 438 F.2d\n1011, 1014, 169 USPQ 99, 102 (CCPA1971); In re Bernhart, 417 F.2d\n1395, 1399, 163 USPQ 611, 615 (CCPA1969); In re Prater, 415 F.2d\n1393, 1406, 162 USPQ 541, 551-52 (CCPA1969). See also generally\nR. Carl Moy, The Interpretation of Means Expressions During\nProsecution, 68 JPOS 246 (1986).\n[18] Given Alappat's disclosure, it was error for the Board majority\nto interpret each of the means clauses in claim 15 so broadly as to\n\"read on any and every means for performing the functions\" recited,\nas it said it was doing, and then to conclude that claim 15 is\nnothing more than a process claim wherein each means clause\nrepresents a step in that process. Contrary to suggestions by the\nCommissioner, this court's precedents do not support the Board's view\nthat the particular apparatus claims at issue in this case may be\nviewed as nothing more than process claims. The cases relied upon by\nthe Commissioner, namely, In re Abele, 684 F.2d 902, 214 USPQ 682\n(CCPA 1982), In re Pardo, 684 F.2d 912, 214 USPQ 673 (CCPA 1982), In\nre Meyer, 688 F.2d 789, 215 USPQ 193 (CCPA 1982), In re Walter, 618\nF.2d 758, 205 USPQ 397 (CCPA 1980), and In re Maucorps, *1541 609\nF.2d 481, 203 USPQ 812 (CCPA 1979), differ from the instant case. In\nAbele, Pardo, and Walter, given the apparent lack of any supporting\nstructure in the specification corresponding to the claimed \"means\"\nelements, the court reasonably concluded that the claims at issue\nwere in effect nothing more than process claims in the guise of\napparatus\n\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1541)\nclaims. This is clearly not the case now before us. As to Maucorps\nand Meyer, despite suggestions therein to the contrary, the claimed\nmeans-plus- function elements at issue in those cases were not\nconstrued as limited to those means disclosed in the specification\nand equivalents thereof. As reaffirmed in Donaldson, such claim\nconstruction is improper, and therefore, those cases are of limited\nvalue in dealing with the issue presently before us. We further note\nthat Maucorps dealt with a business methodology for deciding how\nsalesmen should best handle respective customers and Meyer involved a\n\"system\" for aiding a neurologist in diagnosing patients. Clearly,\nneither of the alleged \"inventions\" in those cases falls within any s\n101 category. When independent claim 15 is construed in accordance\nwith s 112 P 6, claim 15 reads as follows, the subject matter in\nbrackets representing the structure which Alappat discloses in his\nspecification as corresponding to the respective means language\nrecited in the claims: A rasterizer [a \"machine\"] for converting\nvector list data representing sample magnitudes of an input waveform\ninto anti-aliased pixel illumination intensity data to be displayed\non a display means comprising: (a) [an arithmetic logic circuit\nconfigured to perform an absolute value function, or an equivalent\nthereof] for determining the vertical distance between the endpoints\nof each of the vectors in the data list; (b) [an arithmetic logic\ncircuit configured to perform an absolute value function, or an\nequivalent thereof] for determining the elevation of a row of pixels\nthat is spanned by the vector; (c) [a pair of barrel shifters, or\nequivalents thereof] for normalizing the vertical distance and\nelevation; and (d) [a read only memory (ROM) containing illumination\nintensity data, or an equivalent thereof] for outputting illumination\nintensity data as a predetermined function of the normalized vertical\ndistance and elevation. As is evident, claim 15 unquestionably\nrecites a machine, or apparatus, made up of a combination of known\nelectronic circuitry elements. Despite suggestions by the\nCommissioner to the contrary, each of dependent claims 16-19 serves\nto further limit claim 15. Section 112 P 6 requires that each of the\nmeans recited in independent claim 15 be construed to cover at least\nthe structure disclosed in the specification corresponding to the\n\"means.\" Each of dependent claims 16-19 is in fact limited to one of\nthe structures disclosed in the specification.\n(2) Section 101\n\n[19]The reconsideration Board majority affirmed the Examiner's\nrejection of claims 15-19 on the basis that these claims are not\ndirected to statutory subject matter as defined in s 101, which\nreads: Whoever invents or discovers any new and useful process,\nmachine, manufacture, or composition of matter, or any new and useful\nimprovement thereof, may obtain a patent therefor, subject to the\nconditions and requirements of this title. [Emphasis ours.] As\ndiscussed in section II.D.(1), supra, claim 15, properly construed,\nclaims a machine, namely, a rasterizer \"for converting vector list\ndata representing sample magnitudes of an input waveform into\nanti-aliased pixel illumination intensity data to be displayed on a\ndisplay means,\" which machine is made up of, at the very least, the\nspecific structures disclosed in Alappat's\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1541)\nspecification corresponding to the means-plus-function elements\n(a)-(d) recited in the claim. According to Alappat, the claimed\nrasterizer performs the same overall function as prior art\nrasterizers, [FN16] but does so in a different way, *1542 which is\nrepresented by the combination of four elements claimed in\nmeans-plus-function terminology. [FN17] Because claim 15 is directed\nto a \"machine,\" which is one of the four categories of patentable\nsubject matter enumerated in s 101, claim 15 appears on its face to\nbe directed to s 101 subject matter.\nFN16. Representative examples of prior art rasterizers are\nillustrated in U.S. Patent No. 4,215,414, U.S. Patent No.\n4,540,938, U.S. Patent No. 4,586,037, and U.S. Patent No.\n4,672,369.\nFN17. Alappat further notes that the Examiner found the\nparticularly claimed combination to be patentably distinct from\nprior art rasterizers.\n[20] This does not quite end the analysis, however, because the\nBoard majority argues that the claimed subject matter falls within a\njudicially created exception to s 101 which the majority refers to as\nthe \"mathematical algorithm\" exception. Although the PTO has failed\nto support the premise that the \"mathematical algorithm\" exception\napplies to true apparatus claims, we recognize that our own precedent\nsuggests that this may be the case. See In re Johnson, 589 F.2d\n\n1070, 1077, 200 USPQ 199, 206 (CCPA 1978) (\"Benson [referring to\nGottschalk v. Benson, 409 U.S. 63, 93 S.Ct. 253, 34 L.Ed.2d 273\n(1972) ] applies equally whether an invention is claimed as an\napparatus or process, because the form of the claim is often an\nexercise in drafting.\"). Even if the mathematical subject matter\nexception to s 101 does apply to true apparatus claims, the claimed\nsubject matter in this case does not fall within that exception.\n(a)\n[21] The plain and unambiguous meaning of s 101 is that any new and\nuseful process, machine, manufacture, or composition of matter, or\nany new and useful improvement thereof, may be patented if it meets\nthe requirements for patentability set forth in Title 35, such as\nthose found in ss 102, 103, and 112. The use of the expansive term\n\"any\" in s 101 represents Congress's intent not to place any\nrestrictions on the subject matter for which a patent may be obtained\nbeyond those specifically recited in s 101 and the other parts of\nTitle 35. Indeed, the Supreme Court has acknowledged that Congress\nintended s 101 to extend to \"anything under the sun that is made by\nman.\" Diamond v. Chakrabarty, 447 U.S. 303, 309, 100 S.Ct. 2204,\n2208, 65 L.Ed.2d 144 (1980), quoting S.Rep. No. 1979, 82nd Cong., 2nd\nSess., 5 (1952); H.R.Rep. No. 1923, 82nd Cong., 2nd Sess., 6 (1952).\nThus, it is improper to read into s 101 limitations as to the subject\nmatter that may be patented where the legislative history does not\nindicate that Congress clearly intended such limitations. See\nChakrabarty, 447 U.S. at 308, 100 S.Ct. at 2207 (\"We have also\ncautioned that courts 'should not read into the patent laws\nlimitations and conditions which the legislature has not expressed.'\n\"), quoting United States v. Dubilier Condenser Corp., 289 U.S. 178,\n199, 53 S.Ct. 554, 561, 77 L.Ed. 1114 (1933). [22][23] Despite the\napparent sweep of s 101, the Supreme Court has held\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1542)\nthat certain categories of subject matter are not entitled to patent\nprotection. In Diamond v. Diehr, 450 U.S. 175, 101 S.Ct. 1048, 67\nL.Ed.2d 155 (1981), its most recent case addressing s 101, the\nSupreme Court explained that there are three categories of subject\nmatter for which one may not obtain patent protection, namely \"laws\nof nature, natural phenomena, and abstract ideas.\" Diehr, 450 U.S.\nat 185, 101 S.Ct. at 1056. [FN18] Of relevance *1543 to this case,\nthe Supreme Court also has held that certain mathematical subject\n\nmatter is not, standing alone, entitled to patent protection. See\nDiehr, 450 U.S. 175, 101 S.Ct. 1048; Parker v. Flook, 437 U.S. 584,\n98 S.Ct. 2522, 57 L.Ed.2d 451; Gottschalk v. Benson, 409 U.S. 63, 93\nS.Ct. 253, 34 L.Ed.2d 273. [FN19] A close analysis of Diehr, Flook,\nand Benson reveals that the Supreme Court never intended to create an\noverly broad, fourth category of subject matter excluded from s 101.\nRather, at the core of the Court's analysis in each of these cases\nlies an attempt by the Court to explain a rather straightforward\nconcept, namely, that certain types of mathematical subject matter,\nstanding alone, represent nothing more than abstract ideas until\nreduced to some type of practical application, and thus that subject\nmatter is not, in and of itself, entitled to patent protection.\n[FN20]\nFN18. Laws of nature and natural phenomena are in essence\n\"manifestations of ... nature [i.e., not \"new\"], free to all men\nand reserved exclusively to none,\" see Chakrabarty 447 U.S. at\n309, 100 S.Ct. at 2208, quoting Funk Bros. Seed Co. v. Kalo\nInoculant Co., 333 U.S. 127, 130, 68 S.Ct. 440, 441, 92 L.Ed.\n588 (1948), whereas abstract ideas constitute disembodied\nconcepts or truths which are not \"useful\" from a practical\nstandpoint standing alone, i.e., they are not \"useful\" until\nreduced to some practical application. Of course, a process,\nmachine, manufacture, or composition of matter employing a law of\nnature, natural phenomenon, or abstract idea may be patentable\neven though the law of nature, natural phenomenon, or abstract\nidea employed would not, by itself, be entitled to such\nprotection. See e.g. Parker v. Flook, 437 U.S. 584, 590, 98\nS.Ct. 2522, 2526, 57 L.Ed.2d 451 (1978) (\"a process is not\nunpatentable simply because it contains a law of nature or a\nmathematical algorithm.\"); Funk Bros. Seed, 333 U.S. at 130, 68\nS.Ct. at 441 (\"He who discovers a hitherto unknown phenomenon of\nnature has no claim to a monopoly of it which the law recognizes.\nIf there is to be invention from such a discovery, it must come\nfrom the application of the law to a new and useful end.\");\nMackay Radio & Telegraph Co. v. Radio Corp. of America, 306 U.S.\n86, 94, 59 S.Ct. 427, 431, 83 L.Ed. 506 (1939) (\"While a\nscientific truth, or the mathematical expression of it, is not a\npatentable invention, a novel and useful structure created with\nthe aid of knowledge of scientific truth may be.\").\nFN19. The Supreme Court has not been clear, however, as to\nwhether such subject matter is excluded from the scope of s 101\nbecause it represents laws of nature, natural phenomena, or\nabstract ideas. See Diehr, 450 U.S. at 186, 101 S.Ct. at 1056\n(viewed mathematical algorithm as a law of nature); Benson, 409\n\nU.S. at 71-72, 93 S.Ct. at 257 (treated mathematical algorithm as\nan \"idea\"). The Supreme Court also has not been\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1543)\nclear as to exactly what kind of mathematical subject matter may\nnot be patented. The Supreme Court has used, among others, the\nterms \"mathematical algorithm,\" \"mathematical formula,\" and\n\"mathematical equation\" to describe types of mathematical subject\nmatter not entitled to patent protection standing alone. The\nSupreme Court has not set forth, however, any consistent or clear\nexplanation of what it intended by such terms or how these terms\nare related, if at all.\nFN20. The Supreme Court's use of such varying language as\n\"algorithm,\" \"formula,\" and \"equation\" merely illustrates the\nunderstandable struggle that the Court was having in articulating\na rule for mathematical subject matter, given the esoteric nature\nof such subject matter and the various definitions that are\nattributed to such terms as \"algorithm,\" \"formula,\" and\n\"equation,\" and not an attempt to create a broad fourth category\nof excluded subject matter.\n[24] Diehr also demands that the focus in any statutory subject\nmatter analysis be on the claim as a whole. Indeed, the Supreme\nCourt stated in Diehr:\n[W]hen a claim containing a mathematical formula [, mathematical\nequation, mathematical algorithm, or the like,] implements or applies\nthat formula [, equation, algorithm, or the like,] in a structure or\nprocess which, when considered as a whole, is performing a function\nwhich the patent laws were designed to protect (e.g., transforming or\nreducing an article to a different state or thing), then the claim\nsatisfies the requirements of s 101.\nDiehr, 450 U.S. at 192, 101 S.Ct. at 1059-60 (emphasis added). In\nre Iwahashi, 888 F.2d at 1375, 12 USPQ2d at 1911; In re Taner, 681\nF.2d 787, 789, 214 USPQ 678, 680 (CCPA 1982). It is thus not\nnecessary to determine whether a claim contains, as merely a part of\nthe whole, any mathematical subject matter which standing alone would\nnot be entitled to patent protection. Indeed, because the\ndispositive inquiry is whether the claim as a whole is directed to\n\nstatutory subject matter, it is irrelevant that a claim may contain,\nas part of the whole, subject matter which would not be patentable by\nitself. [FN21] \"A claim *1544 drawn to subject matter otherwise\nstatutory does not become nonstatutory simply because it uses a\nmathematical formula, [mathematical equation, mathematical\nalgorithm,] computer program or digital computer.\" Diehr, 450 U.S.\nat 187, 101 S.Ct. at 1057.\nFN21. We note, however, that an analysis wherein one attempts to\nidentify whether any part of a claim recites mathematical subject\nmatter which would not by itself be patentable is not an improper\nanalysis. Such a dissection of a claim may be helpful under some\ncircumstances to more fully understand the claimed subject matter.\nNevertheless, even in those cases wherein courts have applied a\nvariant of the two-part analysis of In re Freeman, 573 F.2d 1237, 197\nUSPQ 464 (CCPA1978), as amended by In re Walter, 618 F.2d 758, 205\nUSPQ 397, the ultimate issue always has been whether the claim as a\nwhole is drawn to statutory subject matter. See e.g. In re Grams,\n888 F.2d at 838, 12 USPQ2d at 1827; In re Meyer, 688 F.2d at 796, 215\nUSPQ at 198; In re Pardo, 684 F.2d at 915, 214 USPQ at 676; In re\nAbele, 684 F.2d at 907, 214 USPQ at 687; In re Walter, 618\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1544)\nF.2d at 767, 205 USPQ at 407. In In re Pardo, the CCPA described\nthe Freeman-Walter two-part test as follows: \"First, the claim is\nanalyzed to determine whether a mathematical algorithm is\ndirectly or indirectly recited. Next, if a mathematical\nalgorithm is found, the claim as a whole is further analyzed to\ndetermine whether the algorithm is 'applied in any manner to\nphysical elements or process steps,' and, if it is, it 'passes\nmuster under s 101.' \" In re Pardo, 684 F.2d at 915, 214 USPQ at\n675-76 (emphasis added) (quoting In re Walter, 618 F.2d at 767,\n205 USPQ at 407.).\n(b)\n[25] Given the foregoing, the proper inquiry in dealing with the so\ncalled mathematical subject matter exception to s 101 alleged herein\nis to see whether the claimed subject matter as a whole is a\ndisembodied mathematical concept, whether categorized as a\nmathematical formula, mathematical equation, mathematical algorithm,\nor the like, which in essence represents nothing more than a \"law of\n\nnature,\" \"natural phenomenon,\" or \"abstract idea.\" If so, Diehr\nprecludes the patenting of that subject matter. That is not the case\nhere.\nAlthough many, or arguably even all, [FN22] of the means elements\nrecited in claim 15 represent circuitry elements that perform\nmathematical calculations, which is essentially true of all digital\nelectrical circuits, the claimed invention as a whole is directed to\na combination of interrelated elements which combine to form a\nmachine for converting discrete waveform data samples into\nanti-aliased pixel illumination intensity data to be displayed on a\ndisplay means. [FN23] This is not a disembodied mathematical concept\nwhich may be characterized as an \"abstract idea,\" but rather a\nspecific machine to produce a useful, concrete, and tangible result.\nFN22. The Board majority stated that each of the means of claim\n15 represents a mathematical operation. The majority failed,\nhowever, to point out any particular mathematical equations\ncorresponding to elements (c) and (d) of claim 15. In addition, we\nnote the Board majority's irreconcilable position that it is free to\nimpute mathematical equations from Alappat's specification into claim\n15, yet it refuses to impute the electrical structure designed to\ncarry out the arithmetic operations.\nFN23. Although means (a) and (b) are independent of each other\nas claimed, each utilizes the same inputs and is connected to\nelement (c), as means (c) normalizes the output of means (a) and\n(b). Means (c) is in turn connected to means element (d) which\noutputs illumination intensity data in response to an input from\nmeans (c).\n[26] The fact that the four claimed means elements function to\ntransform one set of data to another through what may be viewed as a\nseries of mathematical calculations does not alone justify a holding\nthat the claim as a whole is directed to nonstatutory subject matter.\nSee In re Iwahashi, 888 F.2d at 1375, 12 USPQ2d at 1911. [FN24]\nIndeed, claim 15 as written is not \"so abstract and sweeping\" that it\nwould \"wholly pre-empt\" the use of any apparatus employing the\ncombination of mathematical calculations recited therein. See\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1544)\n\nBenson, 409 U.S. at 68-72, 93 S.Ct. at 255-58 (1972). Rather, claim\n15 is limited to the use of a particularly claimed combination of\nelements performing the particularly claimed combination of\ncalculations to transform, i.e., rasterize, digitized waveforms\n(data) into anti-aliased, pixel illumination data to produce a smooth\nwaveform.\nFN24. The Board majority's attempts to distinguish Iwahashi on\nthe basis that the claim at issue in that case recited a ROM are\nunavailing. The Iwahashi court clearly did not find patentable\nsubject matter merely because a ROM was recited in the claim at\nissue; rather the court held that the claim as whole, directed to\nthe combination of the claimed means elements, including the\nclaimed ROM as one element, was directed to statutory subject\nmatter. It was not the ROM alone that carried the day.\n[27] Furthermore, the claim preamble's recitation that the subject\nmatter for which Alappat seeks patent protection is a rasterizer for\ncreating a smooth waveform is not a mere field-of-use label having no\nsignificance. Indeed, the preamble specifically recites that the\nclaimed rasterizer converts waveform data into output illumination\ndata for a display, and the means elements recited in the body of the\nclaim make reference not only to the inputted waveform data recited\nin the preamble but also to the output illumination data also recited\nin the preamble. Claim 15 thus defines a combination of elements\nconstituting a machine for producing an anti-aliased waveform. [28]\nThe reconsideration Board majority also erred in its reasoning that\nclaim 15 is unpatentable merely because it \"reads on a general\npurpose digital computer 'means' to perform the various steps under\nprogram *1545 control.\" [FN25] Alappat, 23 USPQ2d at 1345. The\nBoard majority stated that it would \"not presume that a stored\nprogram digital computer is not within the s 112 P 6 range of\nequivalents of the structure disclosed in the specification.\" [FN26]\nAlappat, 23 USPQ2d at 1345. Alappat admits that claim 15 would read\non a general purpose computer programmed to carry out the claimed\ninvention, but argues that this alone also does not justify holding\nclaim 15 unpatentable as directed to nonstatutory subject matter. We\nagree. We have held that such programming creates a new machine,\nbecause a general purpose computer in effect becomes a special\npurpose computer once it is programmed to perform particular\nfunctions pursuant to instructions from program software. In re\nFreeman, 573 F.2d 1237, 1247 n. 11, 197 USPQ 464, 472 n. 11 (CCPA\n1978); In re Noll, 545 F.2d 141, 148, 191 USPQ 721, 726 (CCPA 1976);\nIn re Prater, 415 F.2d at 1403 n. 29, 162 USPQ at 549-50 n. 29.\nFN25. The Board majority argued that the fact that claim 15\n\nreads on a programmed digital computer further justifies treating\nclaim 15 as a process claim. We disagree. Our discussion in\nsection II.D.(1) sufficiently sets forth why claim 15 must be\nconstrued as an apparatus claim as it is illustrated in section\nII.D.(2).\nFN26. The disclosed ALU, ROM and shift registers are all common\nelements of stored program digital computers.\n33 F.3d 1526\nAUTHORIZED FOR EDUCATIONAL USE ONLY\nPAGE\n(CITE AS: 33 F.3D 1526, *1545)\nUnder the Board majority's reasoning, a programmed general purpose\ncomputer could never be viewed as patentable subject matter under s\n101. This reasoning is without basis in the law. The Supreme Court\nhas never held that a programmed computer may never be entitled to\npatent protection. Indeed, the Benson court specifically stated that\nits decision therein did not preclude \"a patent for any program\nservicing a computer.\" Benson, 409 U.S. at 71, 93 S.Ct. at 257.\nConsequently, a computer operating pursuant to software may represent\npatentable subject matter, provided, of course, that the claimed\nsubject matter meets all of the other requirements of Title 35. In\nany case, a computer, like a rasterizer, is apparatus not\nmathematics.\nCONCLUSION\nFor the foregoing reasons, the appealed decision of the Board\naffirming the examiner's rejection is REVERSED."
    },
    {
      "category": "Resource",
      "title": "alpha_sigma.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/19a61fa75cee3053729c24a94d217644_alpha_sigma.pdf",
      "content": "Alpha Sigma\nThe Vice President's note to the Director of Academic Computing got right to the point:\nLast night I learned that Alpha Sigma is running an AppleShare server with a disk mostly\nfull of third party software. I just verified that it is available to the entire campus.\nUnless they have campus wide licenses, which I doubt, either deliberately or through not\nknowing, they represent a serious set of license violations. Several issues:\n1. Are we doing anything to tell students in the fraternities and the dormitories about\nsoftware licenses and the issue of piracy?\n2. Should someone write a note to Alpha Sigma?\n3. Does the University have any liability in the matter? Are we protected in that Alpha\nSigma has a house corporation that would be liable if vendors decided to get nasty?\nThe University had recently extended its campus network to dormitories and fraternities.\nDormitory residents each got a network drop at no cost, but had to supply their own\ncomputers and Ethernet boards. Fraternities each got a network connection from the\nhouse to the campus at not cost, but had to do their own internal wiring and supply their\nown computers, tranceivers, and Ethernet boards.\nThe University purchased site licenses for basic network software, and provided it\ndirectly to students. The University developed software for University-specific\napplications, and distributed it directly as well. Students obtained some additional\nsoftware by buying it commercially, in some cases through the campus computer store.\nStudents obtained other software by downloading freeware and shareware from network\nfiles servers at the University and elsewhere across the campus, the country, and the\nworld.\nCopyright 1994, MIT\nGreg Jackson"
    },
    {
      "category": "Resource",
      "title": "appealdecision.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/20e35c14928ee1195160f2916ed73b27_appealdecision.pdf",
      "content": "Cite as 96 C.D.O.S. 609\nUNITED STATES OF AMERICA, Plaintiff-Appellee,\nv.\nROBERT ALAN THOMAS and CARLEEN THOMAS, Defendants-Appellants.\nNos. 94-6648; 94-6649\nUnited States Court of Appeals for the Sixth Circuit\nOn Appeal from the United States District Court for the Western District of Tennessee\nBefore: MARTIN and BATCHELDER, Circuit Judges; EDMUNDS, District\nJudge.[FOOTNOTE *]\nDecided and Filed January 29, 1996\nNANCY G. EDMUNDS, District Judge.\nDefendants Robert and Carleen Thomas appeal their convictions and sentences for\nviolating 18 U.S.C. sections 1462 and 1465, federal obscenity laws, in connection with\ntheir operation of an electronic bulletin board. For the following reasons, we AFFIRM\nRobert and Carleen Thomas' convictions and sentences.\nI.\nRobert Thomas and his wife Carleen Thomas began operating the Amateur Action\nComputer Bulletin Board System (\"AABBS\") from their home in Milpitas, California in\nFebruary 1991. The AABBS was a computer bulletin board system that operated by using\ntelephones, modems, and personal computers. Its features included e-mail, chat lines,\npublic messages, and files that members could access, transfer, and download to their\nown computers and printers.\nInformation loaded onto the bulletin board was first converted into binary code, i.e., 0's\nand 1's, through the use of a scanning device. After purchasing sexually-explicit\nmagazines from public adult book stores in California, Defendant Robert Thomas used an\nelectronic device called a scanner to convert pictures from the magazines into computer\nfiles called Graphic Interchange Format files or \"GIF\" files. The AABBS contained\napproximately 14,000 GIF files. Mr. Thomas also purchased, sold, and delivered\nsexually-explicit videotapes to AABBS members. Customers ordered the tapes by\nsending Robert Thomas an e-mail message, and Thomas typically delivered them by use\nof the United Parcel Service (\"U.P.S.\").\n\nPersons calling the AABBS without a password could view the introductory screens of\nthe system which contained brief, sexually-explicit descriptions of the GIF files and adult\nvideotapes that were offered for sale. Access to the GIF files, however, was limited to\nmembers who were given a password after they paid a membership fee and submitted a\nsigned application form that Defendant Robert Thomas reviewed. The application form\nrequested the applicant's age, address, and telephone number and required a signature.\nMembers accessed the GIF files by using a telephone, modem and personal computer. A\nmodem located in the Defendants' home answered the calls. After they established\nmembership by typing in a password, members could then select, retrieve, and instantly\ntransport GIF files to their own computer. A caller could then view the GIF file on his\ncomputer screen and print the image out using his printer. The GIF files contained the\nAABBS name and access telephone number; many also had \"Distribute Freely\" printed\non the image itself.\nIn July 1993, a United States Postal Inspector, Agent David Dirmeyer (\"Dirmeyer\"),\nreceived a complaint regarding the AABBS from an individual who resided in the\nWestern District of Tennessee. Dirmeyer dialed the AABBS' telephone number. As a\nnon-member, he viewed a screen that read \"Welcome to AABBS, the Nastiest Place On\nEarth,\" and was able to select various \"menus\" and read graphic descriptions of the GIF\nfiles and videotapes that were offered for sale.\nSubsequently, Dirmeyer used an assumed name and sent in $55 along with an executed\napplication form to the AABBS. Defendant Robert Thomas called Dirmeyer at his\nundercover telephone number in Memphis, Tennessee, acknowledged receipt of his\napplication, and authorized him to log-on with his personal password. Thereafter,\nDirmeyer dialed the AABBS's telephone number, logged-on and, using his\ncomputer/modem in Memphis, downloaded the GIF files listed in counts 2-7 of the\nDefendants' indictments. These GIF files depicted images of bestiality, oral sex, incest,\nsado-masochistic abuse, and sex scenes involving urination. Dirmeyer also ordered six\nsexually-explicit videotapes from the AABBS and received them via U.P.S. at a\nMemphis, Tennessee address. Dirmeyer also had several e-mail and chat-mode\nconversations with Defendant Robert Thomas.\nOn January 10, 1994, a search warrant was issued by a U.S. Magistrate Judge for the\nNorthern District of California. The AABBS' location was subsequently searched, and the\nDefendants' computer system was seized.\nOn January 25, 1994, a federal grand jury for the Western District of Tennessee returned\na twelve-count indictment charging Defendants Robert and Carleen Thomas with the\nfollowing criminal violations: one count under 18 U.S.C. section 371 for conspiracy to\nviolate federal obscenity laws--18 U.S.C. sections 1462, 1465 (Count 1), six counts under\n18 U.S.C. section 1465 for knowingly using and causing to be used a facility and means\nof interstate commerce--a combined computer/telephone system--for the purpose of\ntransporting obscene, computer-generated materials (the GIF files) in interstate\ncommerce (Counts 2-7), three counts under 18 U.S.C. section 1462 for shipping obscene\n\nvideotapes via U.P.S. (Counts 8-10), one count of causing the transportation of materials\ndepicting minors engaged in sexually explicit conduct in violation of 18 U.S.C. section\n2252(a)(1) as to Mr. Thomas only (Count 11), and one count of forfeiture under 18\nU.S.C. section 1467 (Count 12).\nBoth Defendants were represented by the same retained counsel, Mr. Richard Williams of\nSan Jose, California. They appeared twice in federal district court for the Northern\nDistrict of California, San Jose division, before being arraigned on March 15, 1994, in\nfederal court in Memphis, Tennessee. They did not retain local counsel for the Tennessee\ncriminal prosecution. Both Defendants were tried by a jury in July, 1994. Defendant\nRobert Thomas was found guilty on all counts except count 11 (child pornography).\nDefendant Carleen Thomas was found guilty on counts 1-10. The jury also found that the\nDefendants' interest in their computer system should be forfeited to the United States.\nRobert and Carleen Thomas were sentenced on December 2, 1994 to 37 and 30 months of\nincarceration, respectively. They filed their notices of appeal on December 9, 1994.\nII.\nA.\nDefendants contend that their conduct, as charged in counts 1-7 of their indictments, does\nnot constitute a violation of 18 U.S.C. section 1465. This presents a question of statutory\ninterpretation, a matter of law, and is reviewed by this court under a de novo standard.\nUnited States v. Hans, 921 F.2d 81, 82 (6th Cir. 1990).[FOOTNOTE 1]\nDefendants' challenge to their convictions under counts 1-7, rests on two basic premises:\n1) Section 1465 does not apply to intangible objects like the computer GIF files at issue\nhere,[FOOTNOTE 2] and 2) Congress did not intend to regulate computer transmissions\nsuch as those involved here because 18 U.S.C. section 1465 does not expressly prohibit\nsuch conduct.\nIn support of their first premise, Defendants cite a Tenth Circuit dial-a-porn decision\nwhich holds that 18 U.S.C. sections 1462 and 1465 prohibit the interstate transportation\nof tangible objects; not intangible articles like pre-recorded telephone messages. See\nUnited States v. Carlin Commun., Inc., 815 F.2d 1367, 1371 (10th Cir. 1987). Defendants\nclaim Carlin is controlling because transmission of the GIF files at issue under counts 1-7\ninvolved an intangible string of 0's and 1's which became viewable images only after they\nwere decoded by an AABBS member's computer. We disagree.\nThe subject matter in Carlin--telephonic communication of pre-recorded sexually\nsuggestive comments or proposals--is inherently different from the obscene computer-\ngenerated materials that were electronically transmitted from California to Tennessee in\nthis case. Defendants erroneously conclude that the GIF files are intangible, and thus\noutside the scope of section 1465, by focusing solely on the manner and form in which\nthe computer-generated images are transmitted from one destination to another. United\n\nStates v. Gilboe, 684 F.2d 235 (2nd Cir. 1982), cert. denied, 459 U.S. 1201 (1983),\nillustrates this point.\nIn Gilboe, the Second Circuit rejected the argument that the defendant's transmission of\nelectronic impulses could not be prosecuted under a criminal statute prohibiting the\ntransportation of money obtained by fraud. The Gilboe court reasoned that:\n[e]lectronic signals in this context are the means by which funds are transported. The\nbeginning of the transaction is money in one account and the ending is money in another.\nThe manner in which the funds were moved does not affect the ability to obtain tangible\npaper dollars or a bank check from the receiving account.\nId. at 238. The same rationale applies here. Defendants focus on the means by which the\nGIF files were transferred rather than the fact that the transmissions began with\ncomputer-generated images in California and ended with the same computer-generated\nimages in Tennessee. The manner in which the images moved does not affect their ability\nto be viewed on a computer screen in Tennessee or their ability to be printed out in hard\ncopy in that distant location.\nThe record does not support Defendants' argument that they had no knowledge, intent or\nexpectation that members of their AABBS would download and print the images\ncontained in their GIF files. They ran a business that advertised and promised its\nmembers the availability and transportation of the sexually-explicit GIF files they\nselected. In light of the overwhelming evidence produced at trial, it is spurious for\nDefendants to claim now that they did not intend to sell, disseminate, or share the\nobscene GIF files they advertised on the AABBS with members outside their home and\nin other states.\nWe also disagree with Defendants' corollary position, raised at oral argument, that they\nwere prosecuted under the wrong statute and that their conduct, if criminal at all, falls\nwithin the prohibitions under 47 U.S.C. section 223(b)[FOOTNOTE 3] rather than 18\nU.S.C. section 1465. As recognized by the Supreme Court, Section 223(b) of the\nCommunications Act of 1934, was drafted and enacted by Congress in 1982 \"explicitly to\naddress 'dial-a-porn.'\" Sable Communications of Cal., Inc. v. F.C.C., 492 U.S. 115, 120-\n121 (1989). Congress amended Section 223(b) in 1988 to impose a total ban \"on dial-a-\nporn, making it illegal for adults, as well as children, to have access to sexually-explicit\nmessages\" that are indecent or obscene. Id. at 122-123.[FOOTNOTE 4] 47 U.S.C. section\n223(b) addresses commercial dial-a-porn operations that communicate sexually-explicit\ntelephone messages; not commercial computer bulletin boards that use telephone\nfacilities for the purpose of transmitting obscene, computer-generated images to approved\nmembers.\nDefendants' second premise, that Congress did not intend to regulate computer\ntransmissions because the statute does not expressly prohibit such conduct, is faulty as\nwell. We have consistently recognized that when construing federal statutes, our duty is\nto \"'construe the language so as to give effect to the intent of Congress.'\" United States v.\n\nUnderhill, 813 F.2d 105, 111 (6th Cir.), cert. denied, 482 U.S. 906 (1987) (quoting\nUnited States v. American Trucking Associations, Inc., 310 U.S. 534, 542-44 (1940)).\nThe Supreme Court observed this principle when it rejected an argument similar to one\nDefendants raise here, i.e., that Congress could not possibly have intended to include\nconduct not expressly prohibited in the statute. See United States v. Alpers, 338 U.S. 680\n(1950).\nIn United States v. Alpers, the Supreme Court considered the question whether obscene\nphonograph records--at the time, a novel means of transmitting obscenity--came within\nthe prohibition of 18 U.S.C. section 1462. Initially, the Court acknowledged that criminal\nstatutes are to be strictly construed and that \"no offense may be created except by the\nwords of Congress used in their usual and ordinary way.\" Id. at 681. The Court\nemphasized, however, that Congress' intent is the most important determination and\nstatutory language is not to be construed in a manner that would defeat that intent.\nApplying those principles, the Court held that the rule of ejusdem generis[FOOTNOTE\n5] should not be \"employed to render general words meaningless\" or \"be used to defeat\nthe obvious purpose of legislation.\" Id. at 681-83. It recognized that \"[t]he obvious\npurpose of [Section 1462] was to prevent the channels of interstate commerce from being\nused to disseminate\" any obscene matter. Id. at 683. The Court further recognized that\nSection 1462 \"is a comprehensive statute, which should not be constricted by a\nmechanical rule of construction.\" Id. at 684. Accordingly, the Court rejected the\ndefendant's argument that the general words \"other matter of indecent character\" could\nnot be interpreted to include objects comprehensible by hearing (phonographic\nrecordings) rather than sight; an argument similar to the tangible/intangible one raised\nhere, and held that obscene records fell within the scope of the criminal statute.\nIn reaching its decision, the Alpers Court found that the legislative history of Section\n1462 did not support defendant's sight/sound distinction. It was not persuaded that\nCongress' amendment of Section 1462 to add motion picture films to the list of prohibited\nmaterials \"evidenced an intent that obscene matter not specifically added was without the\nprohibition of the statute.\" Id. Rather, the Court concluded that the amendment evidenced\nCongress' preoccupation \"with making doubly sure that motion-picture film was within\nthe Act, and was concerned with nothing more or less.\" Id. We are similarly unpersuaded\nby Defendants' arguments that the absence of the words \"including by computer\" in\nSection 1465, despite Congress' addition of those words in other legislation, is evidence\nof its intent not to criminalize conduct, such as Defendants' that falls within the plain\nlanguage and intent of Section 1465.\nFurthermore, under similar facts, the U.S. Air Force Court of Criminal Appeals recently\nconsidered section 1465's plain language and its intended purpose. In United States v.\nMaxwell, 42 M.J. 568, 1995 WL 259269 (A.F. Ct. Crim. App. 1995), a defendant was\ncharged with violating Section 1465 because he had transmitted obscene visual images\nelectronically through the use of an on-line computer service. He argued that since the\nstatute is silent concerning computer transmissions, such transmissions were not to be\nincluded within the terms \"transporting obscene materials in interstate or foreign\n\ncommerce.\" The court observed that well-established principles of statutory construction\nrequire a court to look first to the statute's plain language. Maxwell, 1995 WL 259269 at\n*10 (citing Rubin v. United States, 449 U.S. 424, 430 (1981)). Applying that principle,\nthe Maxwell court concluded that the defendant's conduct fell within the plain language\nof Section 1465. Specifically, the court held:\n[t]he use of the terms \"transports,\" \"distribution,\" \"picture,\" \"image\" and \"electrical\ntranscription\" leads us to the inescapable conclusion the statute is fully applicable to the\nactivities engaged in by applicant. . . . It is clear Congress intended to stem the\ntransportation of obscene material in interstate commerce regardless of the means used to\neffect that end.\nMaxwell, 1995 WL 259269 at *10.\nLikewise, we conclude that Defendants' conduct here falls within the plain language of\nSection 1465.[FOOTNOTE 6] Moreover, our interpretation of Section 1465 is consistent\nwith Congress' intent to legislate comprehensively the interstate distribution of obscene\nmaterials. Id.\nB.\nDefendants also challenge venue in the Western District of Tennessee for counts 2-7 of\ntheir indictments. They argue that even if venue was proper under count 1 (conspiracy)\nand counts 8-10 (videotapes sent via U.P.S.), counts 2-7 (GIF files) should have been\nsevered and transferred to California because Defendants did not cause the GIF files to be\ntransmitted to the Western District of Tennessee. Rather, Defendants assert, it was\nDirmeyer, a government agent, who, without their knowledge, accessed and downloaded\nthe GIF files and caused them to enter Tennessee. We disagree. To establish a Section\n1465 violation, the Government must prove that a defendant knowingly used a facility or\nmeans of interstate commerce for the purpose of distributing obscene materials. Contrary\nto Defendants' position, Section 1465 does not require the Government to prove that\nDefendants had specific knowledge of the destination of each transmittal at the time it\noccurred.\n\"Venue lies in any district in which the offense was committed,\" and the Government is\nrequired to establish venue by a preponderance of the evidence. United States v. Beddow,\n957 F.2d 1330, 1335 (6th Cir. 1992) (quoting United States v. Williams, 788 F.2d 1213,\n1215 (6th Cir. 1986)). This court examines the propriety of venue by taking \"'into\naccount a number of factors--the site of the defendant's acts, the elements and nature of\nthe crime, the locus of the effect of the criminal conduct, and the suitability of each\ndistrict for accurate fact finding . . .'\" Id.\nSection 1465 is an obscenity statute, and federal obscenity laws, by virtue of their\ninherent nexus to interstate and foreign commerce, generally involve acts in more than\none jurisdiction or state. Furthermore, it is well-established that \"there is no constitutional\nimpediment to the government's power to prosecute pornography dealers in any district\n\ninto which the material is sent.\" United States v. Bagnell, 679 F.2d 826, 830 (11th Cir.\n1982), cert. denied, 460 U.S. 1047 (1983); United States v. Peraino, 645 F.2d 548, 551\n(6th Cir. 1981). Thus, the question of venue has become one of legislative intent.\nBagnell, 679 F.2d at 830.\nThe Bagnell court examined both sections 1462 and 1465 and found that each statute\nestablished a continuing offense within the venue provisions of 18 U.S.C. section 3237(a)\n\"that occur[s] in every judicial district which the material touches.\" Id. at 830. This court\nlikewise recognized that \"venue for federal obscenity prosecutions lies 'in any district\nfrom, through, or into which' the allegedly obscene material moves.\" Peraino, 645 F.2d at\n551 (citing 18 U.S.C. section 3237).\nSubstantial evidence introduced at trial demonstrated that the AABBS was set up so\nmembers located in other jurisdictions could access and order GIF files which would then\nbe instantaneously transmitted in interstate commerce. Moreover, AABBS materials were\ndistributed to an approved AABBS member known to reside in the Western District of\nTennessee. Specifically, Defendant Robert Thomas knew of, approved, and had\nconversed with an AABBS member in that judicial district who had his permission to\naccess and copy GIF files that ultimately ended up there. Some of these GIF files were\nclearly marked \"Distribute Freely.\" In light of the above, the effects of the Defendants'\ncriminal conduct reached the Western District of Tennessee, and that district was suitable\nfor accurate fact-finding. Accordingly, we conclude venue was proper in that judicial\ndistrict.\nC.\nDefendants further argue that their convictions under counts 1-7 of their indictments\nviolate their First Amendment rights to freedom of speech. As the Supreme Court noted\nin Bose, when constitutional facts[FOOTNOTE 7] are at issue, this court has a duty to\nconduct an independent review of the record \"both to be sure that the speech in question\nactually falls within the unprotected category and to confine the perimeters of any\nunprotected category within acceptably narrow limits in an effort to ensure that protected\nexpression will not be inhibited.\" Bose Corp. v. Consumers Union of United States, Inc.,\n466 U.S. 485, 505 (1984).\n1. Defendants' Right to Possess the GIF Files in their Home\nDefendants rely on Stanley v. Georgia, 394 U.S. 557 (1969), and argue they have a\nconstitutionally protected right to possess obscene materials in the privacy of their home.\nThey insist that the GIF files containing sexually-explicit material never left their home.\nDefendants' reliance on Stanley is misplaced.\nThe Supreme Court has clarified that Stanley \"depended not on any First Amendment\nRight to purchase or possess obscene materials, but on the right to privacy in the home.\"\nUnited States v. 12 200-Ft. Reels of Super 8mm. Film, 413 U.S. 123, 126 (1973). It has\nalso recognized that the right to possess obscene materials in the privacy of one's home\n\ndoes not create \"a correlative right to receive it, transport it, or distribute it\" in interstate\ncommerce even if it is for private use only. Nor does it create \"some zone of\nconstitutionally protected privacy [that] follows such material when it is moved outside\nthe home area.\" United States v. Orito, 413 U.S. 139, 141 (1973); see also 12 200-Ft.\nReels, 413 U.S. at 128.\nDefendants went beyond merely possessing obscene GIF files in their home. They ran a\nbusiness that advertised and promised its members the availability and transportation of\nthe sexually-explicit GIF files they selected. In light of the overwhelming evidence\nproduced at trial, it is spurious for Defendants to claim now that they did not intend to\nsell, disseminate, or share the obscene GIF files they advertised on the AABBS with\nmembers outside their home and in other states.\n2. The Community Standards to be Applied When Determining Whether the GIF Files\nAre Obscene\nIn Miller v. California, 413 U.S. 15 (1973), the Supreme Court set out a three-prong test\nfor obscenity. It inquired whether (1) \"'the average person applying contemporary\ncommunity standards' would find that the work, taken as a whole appeals to the prurient\ninterest\"; (2) it \"depicts or describes, in a patently offensive way, sexual conduct\nspecifically defined by applicable state law\"; and (3) \"the work, taken as a whole, lacks\nserious literary, artistic, political, or scientific value.\" Id. at 24.\nUnder the first prong of the Miller obscenity test, the jury is to apply \"contemporary\ncommunity standards.\" Defendants acknowledge the general principle that, in cases\ninvolving interstate transportation of obscene material, juries are properly instructed to\napply the community standards of the geographic area where the materials are sent.\nMiller, 413 U.S. at 15, 30-34. Nonetheless, Defendants assert that this principle does not\napply here for the same reasons they claim venue was improper. As demonstrated above,\nthis argument cannot withstand scrutiny. The computer-generated images described in\ncounts 2-7 were electronically transferred from Defendants' home in California to the\nWestern District of Tennessee. Accordingly, the community standards of that judicial\ndistrict were properly applied in this case.\nIssues regarding which community's standards are to be applied are tied to those\ninvolving venue. It is well-established that:\n[v]enue for federal obscenity prosecutions lies \"in any district from, through, or into\nwhich\" the allegedly obscene material moves, according to 18 U.S.C. section 3237. This\nmay result in prosecutions of persons in a community to which they have sent materials\nwhich is obscene under that community's standards though the community from which it\nis sent would tolerate the same material.\nUnited States v. Peraino, 645 F.2d 548, 551 (6th Cir. 1981). Prosecutions may be brought\neither in the district of dispatch or the district of receipt, Bagnell, 679 F.2d at 830-31, and\nobscenity is determined by the standards of the community where the trial takes place.\n\nSee Miller, 413 U.S. at 15, 30-34; Hamling v. United States, 418 U.S. 87, 105-6 (1974);\nSable, 492 U.S. at 125. Moreover, the federal courts have consistently recognized that it\nis not unconstitutional to subject interstate distributors of obscenity to varying\ncommunity standards. Hamling, 418 U.S. at 106; United States v. Sandy, 605 F.2d 210,\n217 (6th Cir.), cert. denied, 444 U.S. 984 (1979).\n3. The Implications of Computer Technology on the Definition of \"Community\"\nDefendants and Amicus Curiae appearing on their behalf[FOOTNOTE 8] argue that the\ncomputer technology used here requires a new definition of community, i.e., one that is\nbased on the broad-ranging connections among people in cyberspace rather than the\ngeographic locale of the federal judicial district of the criminal trial. Without a more\nflexible definition, they argue, there will be an impermissible chill on protected speech\nbecause BBS operators cannot select who gets the materials they make available on their\nbulletin boards. Therefore, they contend, BBS operators like Defendants will be forced to\ncensor their materials so as not to run afoul of the standards of the community with the\nmost restrictive standards.\nDefendants' First Amendment issue, however, is not implicated by the facts of this case.\nThis is not a situation where the bulletin board operator had no knowledge or control over\nthe jurisdictions where materials were distributed for downloading or printing. Access to\nthe Defendants' AABBS was limited. Membership was necessary and applications were\nsubmitted and screened before passwords were issued and materials were distributed.\nThus, Defendants had in place methods to limit user access in jurisdictions where the risk\nof a finding of obscenity was greater than that in California. They knew they had a\nmember in Memphis; the member's address and local phone number were provided on his\napplication form. If Defendants did not wish to subject themselves to liability in\njurisdictions with less tolerant standards for determining obscenity, they could have\nrefused to give passwords to members in those districts, thus precluding the risk of\nliability.\nThis result is supported by the Supreme Court's decision in Sable Communications of\nCal., Inc. v. F.C.C. where the Court rejected Sable's argument that it should not be\ncompelled to tailor its dial-a-porn messages to the standards of the least tolerant\ncommunity. 492 U.S. 115, 125-26 (1989). The Court recognized that distributors of\nallegedly obscene materials may be subjected to the standards of the varying\ncommunities where they transmit their materials, citing Hamling, and further noted that\nSable was \"free to tailor its messages, on a selective basis, if it so chooses, to the\ncommunities it chooses to serve.\" Id. at 125. The Court also found no constitutional\nimpediment to forcing Sable to incur some costs in developing and implementing a\nmethod for screening a customer's location and \"providing messages compatible with\ncommunity standards.\" Id.\nThus, under the facts of this case, there is no need for this court to adopt a new definition\nof \"community\" for use in obscenity prosecutions involving electronic bulletin boards.\nThis court's decision is guided by one of the cardinal rules governing the federal courts,\n\ni.e., never reach constitutional questions not squarely presented by the facts of a case.\nBrockett v. Spokane Arcades, Inc., 472 U.S. 491, 502 (1985).\nD.\nDefendants next raise a number of challenges to the jury instructions given at their trial.\nInitially, they claim that, as to counts 2, 3, 6 and 9, the district court should have included\nan augmented unanimity instruction because those counts involved more than one GIF\nfile or videotape. The district court instructed the jury that \"[i]f more than one article is\nalleged to be obscene in a particular count, the government is required to show only that\none of these articles was obscene.\" There was no request for an augmented unanimity\ninstruction and there was no objection at trial to the instruction given. The issue was\nraised for the first time at sentencing. Accordingly, this court reviews for plain error.\nUnited States v. Mendez-Ortiz, 810 F.2d 76 (6th Cir. 1986), cert. denied, 480 U.S. 922\n(1987).\nWe have recognized that \"[t]he plain error doctrine is to be used 'only in exceptional\ncircumstances' and only where the error is so plain that 'the trial judge and the prosecutor\nwere derelict in countenancing it.'\" Id. at 78. Moreover, \"[w]e consider whether the\ninstructions, when taken as a whole, were so clearly wrong as to produce a grave\nmiscarriage of justice.\" United States v. Sanderson, 966 F.2d 184, 187 (6th Cir. 1992).\nWhen one count of an indictment charges that a defendant committed an offense by\n\"multiple alternative 'conceptually' distinct acts,\" the defendant can request that the court\ngive the jury an augmented unanimity instruction, i.e., one that tells them that, with\nregard to this particular count, they must all agree that the defendant committed one of\nthose distinct acts. United States v. Duncan, 850 F.2d 1104, 1110 (6th Cir. 1988). With\nregard to specific, or augmented unanimity instructions, this court has recognized that the\ninstruction is not necessary \"unless 1) a count is extremely complex, 2) there is variance\nbetween the indictment and the proof at trial, or 3) there is a tangible risk of jury\nconfusion.\" Sanderson, 966 F.2d at 187. Contrary to Defendants' assertions, this court's\ndecision in Duncan does not require a court to sua sponte instruct the jury on specific\nunanimity when more than one basis for conviction is presented in a single count. Rather,\nwe have consistently recognized that the need arises when it is shown that there is a\n\"genuine risk that the jury is confused or that a conviction may occur as the result of\ndifferent jurors concluding that a defendant committed different acts.\" United States v.\nSims, 975 F.2d 1225, 1241 (6th Cir. 1992), cert. denied, ___ U.S. ___, 113 S. Ct. 1315\n(1993).\nIn Duncan, the court held that an augmented unanimity instruction should have been\ngiven because the court had been apprised of the unanimity problem in pretrial motions\nand by \"a mid-deliberation question from the jury raising the genuine possibility that\nconviction could occur as the result of different jurors using a different false statement as\nthe underlying factual predicate for guilt.\" Duncan, 850 F.2d at 1105. Defendants have\nnot demonstrated that there was a tangible risk of jury confusion here. Thus, this case is\neasily distinguished from Duncan.\n\nFurthermore, counts 2, 3, 6 and 9 were not complex, and there was no variance between\nthe indictment and the proof at trial. Accordingly, none of the circumstances existed that\nwould give rise to the need for a specific unanimity instruction. Consequently, we\nconclude that the district court did not commit error when it gave general instructions on\nunanimity. Furthermore, considering the subject matter of each GIF file and videotape\nlisted in counts 2, 3, 6 and 9, we find it unlikely that the jury would have had any trouble\nreaching unanimity on the fact that one item described in each of those counts was\nobscene.\nE.\nWe next address the Defendants' argument that the district court erred when it instructed\nthe jury that the government was not required to present expert testimony regarding the\nprurient appeal of the materials at issue here.[FOOTNOTE 9] Under the first prong of the\nMiller obscenity test, the jury must consider whether the allegedly obscene material\n\"appeals to the prurient interest.\" Miller, 413 U.S. at 24.\nThe computer-generated images and videotapes involved here portrayed bestiality, incest,\nrape, and sex scenes involving defecation, urination, and sado-masochistic abuse.\nDefendants argue that the Government is required to present expert testimony when\nsexually-explicit material is directed at a deviant group. We disagree. Neither the United\nStates Supreme Court nor this court has adopted any such per se rule.\nThe Supreme Court has consistently recognized that \"[e]xpert testimony is not necessary\nto enable the jury to judge the obscenity of material which . . . has been placed into\nevidence.\" Hamling v. United States, 418 U.S. 87, 100 (1974) (citing Paris Adult Theatre\nI v. Slaton, 413 U.S. 49, 56 (1973), Kaplan v. California, 413 U.S. 115, 120-21 (1973),\nGinzburg v. United States, 383 U.S. 463, 465 (1966)). In Paris Adult Theatre I, the Court\nobserved that the allegedly obscene materials, \"obviously, are the best evidence of what\nthey represent\" and have been consistently recognized as \"'sufficient in themselves for the\ndetermination of the question.'\" 413 U.S. at 56 (quoting Ginzburg, 383 U.S. at 465). The\nParis I Court further elaborated that:\n[t]his is not a subject that lends itself to the traditional use of expert testimony. Such\ntestimony is usually admitted for the purpose of explaining to lay jurors what they\notherwise could not understand. No such assistance is needed by jurors in obscenity\ncases; indeed the \"expert witness\" practices employed in these cases have often made a\nmockery out of the otherwise sound concept of expert testimony.\nId. at 56, n.6 (citations omitted).\nThe Court has explicitly reserved judgment on the issue whether expert testimony is\nrequired in the \"extreme case\" where \"contested materials are directed at such a bizarre\ndeviant group that the experience of the trier of fact would be plainly inadequate to judge\nwhether the material appeals to the prurient interest.\" Id. In Pinkus v. United States, 436\nU.S. 293 (1978), the Court once again reserved judgment on this question, finding that it\n\nwas not presented with the \"extreme case\" referenced in Paris I because there was expert\ntestimony in evidence which, when \"combined with the exhibits themselves, sufficiently\nguided the jury.\" Pinkus, 436 U.S. at 303.\nExpert testimony on prurient appeal to deviant groups was also presented in this case.\nDefendants' expert, Dr. Victor Pascale, a licensed clinical psychologist, testified at trial\nabout how certain groups of individuals can become sexually aroused by objects or\nconduct not normally thought of as sexual in nature, i.e., the use of whips, cross-dressing,\nurination, defecation, infliction of pain (sado-masochism), and voyeurism. Thus, as in\nPinkus, we find that the expert testimony, when combined with the allegedly obscene\nmaterials themselves, was sufficient to guide the jury with regard to prurient appeal.\nDefendants rely heavily on decisions from the Second Circuit. See United States v. Klaw,\n350 F.2d 155 (2nd Cir. 1965); United States v. Petrov, 747 F.2d 824 (2nd Cir. 1984), cert.\ndenied, 471 U.S. 1025 (1985). In Petrov, however, the court concluded that Klaw is\n\"properly understood to require expert testimony that material appeals to the prurient\ninterest of a deviant group only when the material portrays conduct not generally\nunderstood to be sexual.\" Id. at 836. Furthermore, the Petrov court concluded that expert\ntestimony is \"not required to establish the prurient appeal of photographs depicting\nbestiality.\" Id. at 837. The court further clarified that although Klaw required expert\ntestimony on depictions of sado-masochistic activity, the requirement was met where the\ndefendant's expert testified on cross-examination that such materials would appeal to the\nsexual interest of a small minority of individuals even though they would not appeal to\nthe average person. Id. at 830-31. Thus, Petrov does not compel a different result, and\nthis court concludes that the challenged jury instruction was not erroneous.\nF.\nA required element of section 1465 is that the defendant knowingly \"used a facility or\nmeans of interstate commerce\" for the purpose of transporting or transmitting obscene\nmaterial. Defendants argue that the district court's instruction, that \"facility or means of\ninterstate commerce\" includes \"any method of communication between different states,\"\nimproperly expanded the meaning of this criminal statute. Defendants failed to object to\nthe instruction, therefore, it is examined for plain error. We conclude that there is no plain\nerror here.\nContrary to Defendants' argument, the instruction finds support in 2 Devitt, Blackmar and\nO'Malley, Federal Jury Practice and Instruction, Criminal, (4th Ed. 1990), section 46.06\nat 664, which provides:\nThe term \"uses any facility in interstate . . . commerce\" means employing or utilizing any\nmethod of communication or transportation between one state and another. The term\n\"uses any facility in interstate . . . commerce\", for example, includes the use of the\ntelephone and mails.\nG.\n\nDefendants claim they were denied due process of law and a fair trial by the admission of\nuncharged GIF files and descriptions of uncharged materials at their trial. We will not\ndisturb the district court's admission of this evidence and its determinations of relevancy\nabsent a clear abuse of discretion. United States v. Seago, 930 F.2d 482, 494 (6th Cir.\n1991). We also apply an abuse of discretion standard to the district court's decision in\nbalancing the potentially unfair prejudicial impact of evidence against its probative value.\nUnited States v. Feinman, 930 F.2d 495, 499 (6th Cir. 1991). In reviewing how such a\nbalance is weighed, \"the appellate court must view the evidence in the light most\nfavorable to its proponent, giving 'the evidence its maximum reasonable probative force\nand its minimum reasonable prejudicial value.'\" United States v. Moore, 917 F.2d 215,\n233 (6th Cir. 1990), cert. denied, 499 U.S. 963 (1991).\nDefendants complain that the district court erred when it allowed the Government to\nintroduce 31 uncharged GIF files, portions of 2 uncharged videos, and the AABBS'\ndescriptions of uncharged GIF files and videotapes at trial. They assert that the material\nhad no probative value, and its introduction served only to unfairly prejudice the jury.\nBased on our review of the record, we find no abuse of discretion.\nWith regard to the videotapes, the record reveals that the district court considered\nwhether the probative value of two minutes of one of the three \"child nudist\" videotapes\nsent by Defendant Robert Thomas to Dirmeyer was substantially outweighed by the\ndanger of unfair prejudice. F.R.E. 401, 403. Despite an objection from Defendants'\ncounsel, the district court ruled that the material was probative to the issue of Mr.\nThomas' predisposition in light of his entrapment defense to count 11, charging him with\nknowing receipt of child pornography. We find no error in the admission of the\nvideotapes since they were properly introduced in response to the entrapment defense.\nDefendants' claim that the district court erred when it permitted the jury to see 31\nuncharged GIF files is likewise without merit. Each of the GIF file images was made\nfrom the charged videotapes by stopping the tapes at a certain point, making a still frame\nor photograph, and then scanning it onto the AABBS and making it available for\ndistribution as a separate item. Because the entire videotape was properly admitted and\nviewed by the jury, we reject Defendants' claim of unfair prejudice.\nDefendants also complain that the district court erred by allowing the jury to hear\nsexually-explicit descriptions of other uncharged GIF files and videotapes. Contrary to\nDefendants' contention, this material did have probative value, i.e., it was relevant to\nestablishing scienter and pandering. Defendants posted these graphic descriptions in the\npublic areas of the AABBS, and this was one way they advertised for members. See\nMishkin v. New York, 383 U.S. 502 (1966); Pinkus, 436 U.S. at 303. Accordingly, we\nreject Defendants' argument that the above evidence was clearly more prejudicial than\nprobative under F.R.E. 403, and find no abuse of discretion in its admission under F.R.E.\n401.\nH.\n\nDefendants next contend that they were denied effective assistance of counsel at their\ntrial because their retained counsel failed to: (1) move for dismissal based on Carlin; (2)\nobject to the admission of evidence at trial; (3) move for judgment of acquittal based on\nthe government's requirement to provide expert testimony regarding \"prurient appeal\" to\ndeviant groups; (4) recognize the conflict of interest inherent in his dual representation of\nboth Defendants; (5) sever the child pornography count; (6) file a suppression motion; (7)\nrequest discovery; (8) challenge the indictment as duplicative; (9) move for a mistrial;\n(10) submit a theory-of-the-case instruction; (11) introduce comparable sexually-explicit\nvideotapes available in Memphis; and (12) with regard to Carleen Thomas, failed to\nmove for a judgment of acquittal at the close of the government's case for lack of\nevidence of scienter and then called her to the stand when her testimony could only\nincriminate her.\nAs a general rule, this court \"will not review claims of ineffective counsel that are raised\nfor the first time on appeal.\" United States v. Seymour, 38 F.3d 261, 263 (6th Cir. 1994).\nThese claims are \"'best brought by a defendant in a post-conviction proceeding under 28\nU.S.C. section 2255 so that the parties can develop an adequate record on the issue.'\" Id.\n(quoting United States v. Daniel, 956 F.2d 540, 543 (6th Cir. 1992)). We consider such\nclaims on direct appeal only where the record has been sufficiently developed so as to\nallow us to evaluate counsel's performance. Seymour, 38 F.3d at 263. We find that the\nrecord here is not adequately developed for us to consider the ineffective assistance of\ncounsel claims asserted above.\nWe will, however, consider Defendant Carleen Thomas' argument that she was denied\neffective assistance of counsel because the district court refused her request for separate\ncounsel without adequate inquiry as to her reasons. Unlike the above claims, we find the\nrecord below is sufficiently developed to address this issue.\nCarleen Thomas first raised her request for separate counsel on the day of trial. The\nGovernment informed the district court that Defendants had previously been informed of\ntheir right to separate counsel but they had waived that right. While considering Carleen\nThomas' late request, the district court made additional inquiries and reviewed the record\nto determine whether she had indeed been informed of, and had waived, that right. The\ninquiry revealed both events had occurred. The district court refused to delay the trial that\nwas set to begin immediately but did offer to arrange for separate standby counsel for\nCarleen Thomas. The court also informed Carleen Thomas that, because she was not\nindigent, she would have to reimburse this counsel at the rate charged by court-appointed\nattorneys. After considering the court's offer, Carleen Thomas stated on the record that\nshe wished to continue with Mr. Williams as her retained counsel. In light of the above,\nwe reject Carleen Thomas' claim.\nI.\nDefendants' final argument challenges the district court's denial of a two-level reduction\nin their sentences for acceptance of responsibility. They claim they are entitled to the\nreduction because they fully acknowledged their conduct in running the AABBS. The\n\nsentencing court's finding regarding acceptance of responsibility is entitled to great\ndeference and is reversed only if found to be clearly erroneous. See United States v.\nIvery, 999 F.2d 1043, 1045 (6th Cir. 1993); see also U.S.S.G. section 3E1.1(a), comment,\nn.5.\nU.S.S.G. section 3E1.1(a) provides for a two-level reduction for a defendant who \"clearly\ndemonstrates acceptance of responsibility.\" To qualify for this reduction, Defendants\nwere required to show by a preponderance of the evidence that they had accepted\nresponsibility for the crime committed. United States v. Williams, 940 F.2d 176 (6th\nCir.), cert. denied, 502 U.S. 1016 (1991). U.S.S.G. 3E1.1(a), comment, n.2 clarifies that\nthe reduction is \"not intended for a defendant who puts the government to its burden of\nproof at trial by denying the essential factual elements of guilt, is convicted, and only\nthen admits guilt and expresses remorse.\" This comment further clarifies that only in\n\"rare situations\" will the adjustment apply after a trial and verdict of guilt, e.g., where the\ndefendant makes a challenge to the applicability of a statute to his conduct. Defendants\nassert that they fit the \"rare situation\" and should not have been denied the reduction.\nThe sentencing judge, however, stated more than one ground for denying the two-level\nreduction. She noted that neither Defendant acknowledged the character of the materials\nfound to be obscene. In addition, she found no indication that either of them had put aside\nmaking their living through the same means. U.S.S.G. section 3E1.1(a), comment n.1(b)\nlists voluntary termination or withdrawal from criminal conduct as a factor to be\nconsidered by the court. This court has recognized that the two-level adjustment is\nproperly denied under circumstances where the defendant continues conduct that is the\nsame type as the underlying offense. See United States v. Reed, 951 F.2d 97, 99-100 (6th\nCir. 1991), cert. denied, 503 U.S. 996 (1992); United States v. Snyder, 913 F.2d 300, 305\n(6th Cir. 1990), cert. denied, 498 U.S. 1039 (1991). Accordingly, we hold that the\nsentencing court's denial of the two-level reduction was not clearly erroneous.\nIII.\nFor the foregoing reasons, this court AFFIRMS Robert and Carleen Thomas' convictions\nand sentences.\n:::::::::::::::::::: FOOTNOTES ::::::::::::::::::::\nFN* The Honorable Nancy G. Edmunds, United States District Judge for the Eastern\nDistrict of Michigan, sitting by designation.\nFN1. Defendants assert that an appellate court is required to conduct an independent\nreview of the entire record to ensure that their First Amendment rights are protected.\nBose Corp. v. Consumers Union of United States, Inc., 466 U.S. 485, 505 (1984). It is\ntrue that in Bose, the United States Supreme Court recognized that an appellate court is to\nconduct an independent review of the record when constitutional facts are at issue, i.e.,\nactual malice in a libel case or the finding of obscenity in pornography cases. There is no\nneed to conduct an independent review when constitutional facts are not at issue.\n\nAccordingly, this first issue, which involves only statutory interpretation is reviewed\nunder a de novo standard.\nFN2. Section 1465 provides:\nWhoever knowingly transports in interstate or foreign commerce for the purpose of sale\nor distribution, or knowingly travels in interstate commerce, or uses a facility or means of\ninterstate commerce for the purpose of transporting obscene material in interstate or\nforeign commerce, any obscene, lewd, lascivious, or filthy book, pamphlet, picture, film,\npaper, letter, writing, print, silhouette, drawing, figure, image, cast, phonograph\nrecording, electrical transcription or other article capable of producing sound or any other\nmatter of indecent or immoral character, shall be fined under this title or imprisoned not\nmore than five years, or both.\nThe transportation as aforesaid of two or more copies of any publication or two or more\nof any article of the character described above, or a combined total of five such\npublications and articles, shall create a presumption that such publications or articles are\nintended for sale or distribution, but such presumption is rebuttable. 42 U.S.C.A. section\n1465 (West 1995 Supp.).\nFN3. 47 U.S.C. section 223(b) provides:\n(1) Whoever knowingly\n(A) within the United States, by means of telephone, makes (directly or by recording\ndevice) any obscene communication for commercial purposes to any person, regardless\nof whether the maker of such communication placed the call; or\n(B) permits any telephone facility under such person's control to be used for an activity\nprohibited by subparagraph (A),\nshall be fined in accordance with Title 18, or imprisoned not more than two years, or\nboth.\nFN4. In Sable, the Supreme Court affirmed the lower court's decision which upheld\nSection 223(b)'s \"prohibition against obscene interstate telephone communications for\ncommercial purposes, but enjoined the enforcement of the statute insofar as it applied to\nindecent messages.\" Id. at 117.\nFN5. This rule of statutory construction \"limits general terms which follow specific ones\nto matters similar to those specified.\" Alpers, 338 U.S. at 354.\nFN6. Our holding here renders moot Defendants' arguments that the district court's\ninstructions on conspiracy were erroneous because they allowed for a conviction based\nupon a conspiracy to commit conduct wrongfully charged in counts 2-7 of their\nindictments.\n\nFN7. Some examples of constitutional facts include those that support: the finding of\nactual malice in a defamation or libel suit; the finding that obscene materials were used\nsolely in the home and were thus protected under Stanley v. Georgia, 394 U.S. 557\n(1969), or the finding that material is obscene under the test for obscenity set forth in\nMiller v. California, 413 U.S. 15, 24 (1973).\nFN8. The following Amicus Curiae submitted briefs on behalf of Defendants in this\nmatter: the American Civil Liberties Union, the Interactive Services Association, the\nSociety for Electronic Access, and The Electronic Frontier Foundation.\nFN9. The district court instructed the jury as follows:\nYou have heard testimony from an expert witness presented on behalf of the defendants.\nAn expert is allowed to express his opinion on those matters about which he has special\nknowledge and training. Expert testimony is presented to you on the theory that someone\nthat is experienced in the field can assist you in understanding the evidence or in reaching\nan independent decision on the facts. There is no requirement, however, that expert\ntestimony be presented in an obscenity case. The government need not produce expert\nevidence that the materials are obscene, but may rely on the computer generated images\nand videotapes themselves for its argument that the materials are obscene."
    },
    {
      "category": "Resource",
      "title": "arrythmia.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/89ad8a73e09aa12ce614689465029140_arrythmia.pdf",
      "content": "958 F.2d 1053\n60 U.S.L.W. 2603, 22 U.S.P.Q.2d 1033\n(Cite as: 958 F.2d 1053)\nARRHYTHMIA RESEARCH TECHNOLOGY, INC., Plaintiff-Appellant,\nv.\nCORAZONIX CORPORATION, Defendant-Appellee.\nNo. 91-1091.\nUnited States Court of Appeals,\nFederal Circuit.\nMarch 12, 1992.\nRehearing Denied May 5, 1992.\nHolder of patent directed to analysis of electrocardiographic\nsignals in order to determine certain characteristics of heart\nfunction brought infringement suit. The United States District Court\nfor the Northern District of Texas, A. Joe Fish, and John B. Tolle,\nJJ., declared patent invalid for failure to claim statutory subject\nmatter, and plaintiff appealed. The Court of Appeals, Pauline Newman,\nCircuit Judge, held that process and apparatus claims satisfied\ncriteria for statutory subject matter.\nReversed and remanded.\nRader, Circuit Judge, filed concurring opinion.\n*1054 John F. Flannery, Fitch, Even, Tabin & Flannery, Chicago,\nIll., argued for plaintiff-appellant. With him on the brief was\nRobert J. Fox.\nRobert W. Turner, Jones, Day, Reavis & Pogue, Dallas, Tex.,\nargued for defendant-appellee. With him on the brief was John E.\nVick, Jr., Hubbard, Thurman, Tucker & Harris, Dallas, Tex.\nBefore NEWMAN, LOURIE and RADER, Circuit Judges.\nPAULINE NEWMAN, Circuit Judge.\nArrhythmia Research Technology, Inc. appeals the grant of\nsummary judgment by the United States District Court for the Northern\nDistrict of Texas [FN1] declaring United States Patent No. 4,422,459\nto Michael B. Simson (the '459 or Simson patent) invalid for failure\nto claim statutory subject matter under 35 U.S.C. s 101. The court\ndid not decide the question of infringement.\nFN1. Arrhythmia Research Technology, Inc. v. Corazonix Corp.,\nNo. CA 3-88- 1745-AJ (N.D.Tex. October 3, 1990), reconsid. denied\n(November 8, 1990) (Order); appeal authorized (November 9, 1990)\n(Order).\nWe conclude that the claimed subject matter is statutory in\n\nterms of section 101. The judgment of invalidity on this ground is\nreversed.\nThe Simson Invention\nThe invention claimed in the '459 patent is directed to the\nanalysis of electrocardiographic signals in order to determine certain\ncharacteristics of the heart function. In the hours immediately after\na heart attack (myocardial infarction) the victim is particularly\nvulnerable to an acute type of heart arrhythmia known as ventricular\ntachycardia. Ventricular tachycardia leads quickly to ventricular\nfibrillation, in which the heart ceases effectively to pump blood\nthrough the body. Arrhythmia Research states that 15-25% of heart\nattack victims are at high risk for ventricular tachycardia. It can\nbe treated or prevented with certain drugs, but these drugs have\nundesirable and sometimes dangerous side effects. Dr. Simson, a\ncardiologist, sought a solution to the problem of determining which\nheart attack victims are at high risk for ventricular tachycardia, so\nthat these persons can be carefully monitored and appropriately\ntreated.\nHeart activity is monitored by means of an electrocardiograph\ndevice, whereby electrodes attached to the patient's body detect the\nheart's electrical signals in accordance with the various phases of\nheart activity. The signals can be displayed in wave form on a\nmonitor and/or recorded on a chart. It was known that in patients\nsubject to ventricular tachycardia certain anomalous waves having very\nlow amplitude and high frequency, known as \"late potentials,\" appear\ntoward the end of the QRS [FN2] segment of the electrocardiographic\nsignal, that is, late in the ventricular contraction cycle. Dr.\nSimson's method of detecting and measuring these late potentials in\nthe QRS complex, and associated apparatus, are the subject of the '459\npatent.\nFN2. According to Arrhythmia Research, the QRS complex lasts\nabout one tenth of a second and arises from the depolarization of the\nventricles prior to contraction.\n*1055 The '459 patent specification describes these procedures.\nCertain of the heart attack patient's electrocardiographic signals,\nthose obtained from electrodes designated as X, Y, and Z leads, are\nconverted from analog to digital values, and a composite digital\nrepresentation of the QRS segment is obtained by selecting and\naveraging a large number of the patient's QRS waveforms. The anterior\nportion of the composite QRS waveform is first isolated, and then\nprocessed by a digital high pass filter in reverse time order; that\nis, backwards. This step of reverse time order filtering is described\nas the critical feature of the Simson invention, in that it enables\ndetection of the late potentials by eliminating certain perturbations\n\nthat obscure these signals. The root mean square of the reverse time\nfiltered output is then calculated, as described in the specification,\nto determine the average magnitude of the anterior portion of the QRS\ncomplex. Comparison of the output, which is measured in microvolts,\nwith a predetermined level of high frequency energy, indicates whether\nthe patient is subject to ventricular tachycardia. That is, if the\nroot mean square magnitude is less than the predetermined level, then\nlow amplitude, high frequency late potentials have been shown to be\npresent, indicating a higher risk of ventricular tachycardia. If the\nroot mean square value is greater than the predetermined level, high\nrisk for ventricular tachycardia is not indicated.\nCertain steps of the invention are described as conducted with\nthe aid of a digital computer, and the patent specification sets forth\nthe mathematical formulae that are used to configure (program) the\ncomputer. The specification states that dedicated, specific purpose\nequipment or hard wired logic circuitry can also be used.\nThe district court held that the method and apparatus claims of\nthe Simson patent are directed to a mathematical algorithm, and thus\ndo not define statutory subject matter. Claim 1 is the broadest\nmethod claim: 1. A method for analyzing electrocardiograph signals to\ndetermine the presence or absence of a predetermined level of high\nfrequency energy in the late QRS signal, comprising the steps of:\nconverting a series of QRS signals to time segments, each segment\nhaving a digital value equivalent to the analog value of said signals\nat said time; applying a portion of said time segments in reverse time\norder to high pass filter means; determining an arithmetic value of\nthe amplitude of the output of said filter; and comparing said value\nwith said predetermined level. Claim 7 is a representative apparatus\nclaim: 7. Apparatus for analyzing electrocardiograph signals to\ndetermine the level of high frequency energy in the late QRS signal\ncomprising: means for converting X, Y, and Z lead electrocardiographic\ninput signals to digital valued time segments; means for examining\nsaid X, Y, and Z digital valued time segments and selecting therefrom\nthe QRS waveform portions thereof; means for signal averaging a\nmultiplicity of said selected QRS waveforms for each of said X, Y, and\nZ inputs and providing composite, digital X, Y, and Z QRS waveforms;\nhigh pass filter means; means for applying to said filter means, in\nreverse time order, the anterior portion of each said digital X, Y,\nand Z waveform; and means for comparing the output of said filter\nmeans with a predetermined level to obtain an indication of the\npresence of a high frequency, low level, energy component in the\nfilter output of said anterior portions. The Patent and Trademark\nOffice had granted the patent without questioning that its claims were\ndirected to statutory subject matter under s 101.\n35 U.S.C. s 101\nWhether a claim is directed to statutory subject matter is a\n\nquestion of law. Although *1056 determination of this question may\nrequire findings of underlying facts specific to the particular\nsubject matter and its mode of claiming, in this case there were no\ndisputed facts material to the issue. Thus we give plenary review to\nthe question, with appropriate recognition of the burdens on the\nchallenger of a duly issued United States patent. See 35 U.S.C. s\n282 (duly issued patent is presumed valid); Interconnect Planning\nCorp. v. Feil, 774 F.2d 1132, 1139, 227 USPQ 543, 548, (Fed.Cir.1985)\n(statutory presumption of validity is based in part on recognition of\nthe expertise of patent examiners).\n[1] A new and useful process or apparatus is patentable subject\nmatter, as defined in 35 U.S.C. s 101: Whoever invents or discovers\nany new and useful process, machine, manufacture, or composition of\nmatter, or any new and useful improvement thereof, may obtain a patent\ntherefor, subject to the conditions and requirements of this title.\nThe Supreme Court has observed that Congress intended section 101 to\ninclude \"anything under the sun that is made by man.\" Diamond v.\nChakrabarty, 447 U.S. 303, 309, 100 S.Ct. 2204, 2208, 65 L.Ed.2d 144,\n206 USPQ 193, 197 (1980), quoting S.Rep. No. 1979, 82d Cong., 2d\nSess., 5 (1952); H.R.Rep. No. 1923, 82d Cong., 2d Sess., 6 (1952).\nThere are, however, qualifications to the apparent sweep of this\nstatement. Excluded from patentability is subject matter in the\ncategories of \"laws of nature, physical phenomena, and abstract\nideas\". Diamond v. Diehr, 450 U.S. 175, 185, 101 S.Ct. 1048, 1056,\n67 L.Ed.2d 155, 209 USPQ 1, 7 (1981). A mathematical formula may\ndescribe a law of nature, a scientific truth, or an abstract idea. As\ncourts have recognized, mathematics may also be used to describe steps\nof a statutory method or elements of a statutory apparatus. The\nexceptions to patentable subject matter derive from a lengthy\njurisprudence, but their meaning was probed anew with the advent of\ncomputer-related inventions.\nIn Gottschalk v. Benson, 409 U.S. 63, 72, 93 S.Ct. 253, 257, 34\nL.Ed.2d 273, 175 USPQ 673, 676 (1972) the Court held that a patent\nclaim that \"wholly pre-empts\" a mathematical formula used in a general\npurpose digital computer is directed solely to a mathematical\nalgorithm, [FN3] and therefore does not define statutory subject\nmatter under section 101. The Court described the mathematical\nprocess claimed in Benson as \"so abstract and sweeping as to cover\nboth known and unknown uses of the BCD [binary coded decimal] to pure\nbinary conversion\", 409 U.S. at 68, 93 S.Ct. at 255, 175 USPQ at 675,\nciting O'Reilly v. Morse, 56 U.S. (15 How.) 62, 113, 14 L.Ed. 601\n(1852) for its holding that the patentee may not claim more than he\nhas actually invented.\nFN3. A mathematical algorithm was defined in Benson as a\nprocedure or formula for solving a particular mathematical problem.\n\n409 U.S. at 65, 93 S.Ct. at 254, 175 USPQ at 674. As discussed in In\nre Iwahashi, 888 F.2d 1370, 1374, 12 USPQ2d 1908, 1911 (Fed.Cir.1989),\nhowever, any step-by-step process, whether mechanical, electrical,\nbiological or chemical, involves an \"algorithm\" in the broader sense\nof the term.\nIn Parker v. Flook, 437 U.S. 584, 591, 98 S.Ct. 2522, 2526, 57\nL.Ed.2d 451, 198 USPQ 193, 198 (1978) the Court explained that the\ncriterion for patentability of a claim that requires the use of\nmathematical procedures is not simply whether the claim \"wholly\npre-empts\" a mathematical algorithm, but whether the claim is directed\nto a new and useful process, independent of whether the mathematical\nalgorithm required for its performance is novel. Applying these\ncriteria the Court held nonstatutory a method claim for\ncomputer-calculating \"alarm limits\" for use in a catalytic conversion\nprocess, on the basis that \"once that algorithm is assumed to be\nwithin the prior art, the application, considered as a whole, contains\nno patentable invention.\" Flook, 437 U.S. at 594, 98 S.Ct. at 2527,\n198 USPQ at 199.\nIn accordance with Flook, the claims were analyzed to determine\nwhether the process itself was new and useful, assuming the\nmathematical algorithm was \"well known\". Id. at 592, 98 S.Ct. at\n2527, 198 USPQ at 198. As the jurisprudence developed, *1057\ninventions that were implemented by the mathematically-directed\nperformance of computers were viewed in the context of the practical\napplication to which the computer-generated data were put. The Court\nof Customs and Patent Appeals observed in In re Bradley, 600 F.2d 807,\n811-112, 202 USPQ 480, 485 (CCPA 1979), aff'd by an equally divided\ncourt, sub nom. Diamond v. Bradley, 450 U.S. 381, 101 S.Ct. 1495, 67\nL.Ed.2d 311 (1981): It is of course true that a modern digital\ncomputer manipulates data, usually in binary form, by performing\nmathematical operations, such as addition, subtraction,\nmultiplication, division, or bit shifting, on the data. But this is\nonly how the computer does what it does. Of importance is the\nsignificance of the data and their manipulation in the real world,\ni.e., what the computer is doing. [Emphases in original] Thus\ncomputers came to be generally recognized as devices capable of\nperforming or implementing process steps, or serving as components of\nan apparatus, without negating patentability of the process or the\napparatus. In Diamond v. Diehr the Court explained that non-statutory\nstatus under section 101 derives from the \"abstract\", rather than the\n\"sweeping\", nature of a claim that contains a mathematical algorithm.\nThe Court stated: \"While a scientific truth, or the mathematical\nexpression of it, is not a patentable invention, a novel and useful\nstructure created with the aid of knowledge of scientific truth may\nbe.\" Diehr, 450 U.S. at 188, 101 S.Ct. at 1057, 209 USPQ at 8-9,\n\nquoting Mackay Radio & Telegraph Co. v. Radio Corp. of America, 306\nU.S. 86, 94, 59 S.Ct. 427, 431, 83 L.Ed. 506, 40 USPQ 199, 202 (1939).\nThe mathematical algorithm in Diehr was the known Arrhenius equation,\nand the Court held that when the algorithm was incorporated in a\nuseful process, the subject matter was statutory. The Court confirmed\nthe rule that process steps or apparatus functions that entail\ncomputer-performed calculations, whether the calculations are\ndescribed in mathematical symbols or in words, do not of themselves\nrender a claim nonstatutory. Diehr, 450 U.S. at 187, 101 S.Ct. at\n1057, 209 USPQ at 8. The Court clarified its earlier holdings, [FN4]\nstating that \"[i]t is inappropriate to dissect the claims into old and\nnew elements and then to ignore the presence of the old elements in\nthe [section 101] analysis.\" Id. at 188, 101 S.Ct. at 1058, 209 USPQ\nat 9.\nFN4. Although commentators have differed in their\ninterpretations of Benson, Flook, and Diehr, it appears to be\ngenerally agreed that these decisions represent evolving views of the\nCourt, and that the reasoning in Diehr not only elaborated on, but in\npart superseded, that of Benson and Flook. See, e.g., R.L. Gable &\nJ.B. Leaheey, The Strength of Patent Protection for Computer Products,\n17 Rutgers Computer & Tech.L.J. 87 (1991); D. Chisum, The\nPatentability of Algorithms, 47 U.Pitt.L.Rev. 959 (1986).\n[2] The Court thus placed the patentability of computer-aided\ninventions in the mainstream of the law. The ensuing mode of analysis\nof such inventions was summarized in In re Meyer, 688 F.2d 789, 795,\n215 USPQ 193, 198 (CCPA 1982): In considering a claim for compliance\nwith 35 USC 101, it must be determined whether a scientific principle,\nlaw of nature, idea, or mental process, which may be represented by a\nmathematical algorithm, is included in the subject matter of the\nclaim. If it is, it must then be determined whether such principle,\nlaw, idea, or mental process is applied in an invention of a type set\nforth in 35 USC 101. The law crystallized about the principle that\nclaims directed solely to an abstract mathematical formula or\nequation, including the mathematical expression of scientific truth or\na law of nature, whether directly or indirectly stated, are\nnonstatutory under section 101; whereas claims to a specific process\nor apparatus that is implemented in accordance with a mathematical\nalgorithm will generally satisfy section 101.\nIn applying this principle to an invention whose process steps\nor apparatus elements are described at least in part in terms of\nmathematical procedures, the mathematical procedures are considered in\nthe context of the claimed invention as a whole. Diehr, *1058 450\nU.S. at 188, 101 S.Ct. at 1057, 209 USPQ at 9. Determination of\nstatutory subject matter has been conveniently conducted in two\n\nstages, following a protocol initiated by the Court of Customs and\nPatent Appeals in In re Freeman, 573 F.2d 1237, 197 USPQ 464 (CCPA\n1978); modified after the Court's Flook decision by In re Walter, 618\nF.2d 758, 205 USPQ 397 (CCPA 1980); and again after the Court's Diehr\ndecision by In re Abele, 684 F.2d 902, 214 USPQ 682 (CCPA 1982).\n[3] This analysis has been designated the Freeman-Walter-Abele\ntest for statutory subject matter. It is first determined whether a\nmathematical algorithm is recited directly or indirectly in the claim.\nIf so, it is next determined whether the claimed invention as a whole\nis no more than the algorithm itself; that is, whether the claim is\ndirected to a mathematical algorithm that is not applied to or limited\nby physical elements or process steps. Such claims are nonstatutory.\nHowever, when the mathematical algorithm is applied in one or more\nsteps of an otherwise statutory process claim, or one or more elements\nof an otherwise statutory apparatus claim, the requirements of section\n101 are met. The court explained in Abele, 684 F.2d at 907, 214 USPQ\nat 686: [P]atentable subject matter [is not limited] to claims in\nwhich structural relationships or process steps are defined, limited\nor refined by the application of the algorithm. Rather, Walter should\nbe read as requiring no more than that the algorithm be \"applied in\nany manner to physical elements or process steps,\" provided that its\napplication is circumscribed by more than a field of use limitation or\nnon- essential post-solution activity. As summarized by the PTO in Ex\nParte Logan, 20 USPQ2d 1465, 1468 (PTO Bd.Pat.App. and Interf.1991),\nthe emphasis is \"on what the claimed method steps do rather than how\nthe steps are performed\". (Emphases in original)\nAlthough the Freeman-Walter-Abele analysis is not the only test\nfor statutory subject matter, Meyer, 688 F.2d at 796, 215 USPQ at 198,\nand this court has stated that failure to meet that test may not\nalways defeat the claim, In re Grams, 888 F.2d 835, 839, 12 USPQ2d\n1824, 1827 (Fed.Cir.1989), this analytic procedure is conveniently\napplied to the Simson invention.\nAnalysis\nArrhythmia Research states that the district court erred in law,\nand that the combination of physical, mechanical, and electrical steps\nthat are described and claimed in the '459 patent constitutes\nstatutory subject matter. Arrhythmia Research stresses that the claims\nare directed to a process and apparatus for detecting and analyzing a\nspecific heart activity signal, and do not preempt the mathematical\nalgorithms used in any of the procedures. Arrhythmia Research states\nthat the patentability of such claims is now well established by law,\nprecedent, and practice.\nCorazonix states that the claims define no more than a\nmathematical algorithm that calculates a number. Corazonix states\nthat in Simson's process and apparatus claims mathematical algorithms\nare merely presented and solved, and that Simson's designation of a\n\nfield of use and post-solution activity are not essential to the\nclaims and thus do not cure this defect. Thus, Corazonix states that\nthe claims are not directed to statutory subject matter, and that the\ndistrict court's judgment was correct.\nA. The Process Claims\nAlthough mathematical calculations are involved in carrying out\nthe claimed process, Arrhythmia Research argues that the claims are\ndirected to a method of detection of a certain heart condition by a\nnovel method of analyzing a portion of the electrocardiographically\nmeasured heart cycle. This is accomplished by procedures conducted by\nmeans of electronic equipment programmed to perform mathematical\ncomputation.\nApplying the Freeman-Walter-Abele protocol, we accept for the\npurposes of this analysis the proposition that a mathematical *1059\nalgorithm is included in the subject matter of the process claims in\nthat some claimed steps are described in the specification by\nmathematical formulae. See In re Johnson, 589 F.2d 1070, 1078, 200\nUSPQ 199, 208 (CCPA 1979) (\"Reference to the specification must be\nmade to determine whether [claimed] terms indirectly recite\nmathematical calculations, formulae, or equations.\") We thus proceed\nto the second stage of the analysis, to determine whether the claimed\nprocess is otherwise statutory; that is, we determine what the claimed\nsteps do, independent of how they are implemented.\nSimson's process is claimed as a \"method for analyzing\nelectrocardiograph signals to determine the presence or absence of a\npredetermined level of high- frequency energy in the late QRS signal\".\nThis claim limitation is not ignored in determining whether the\nsubject matter as a whole is statutory, for all of the claim steps are\nin implementation of this method. The electrocardiograph signals are\nfirst transformed from analog form, in which they are obtained, to the\ncorresponding digital signal. These input signals are not\nabstractions; they are related to the patient's heart function. The\nanterior portion of the QRS signal is then processed, as the next\nstep, by the procedure known as reverse time order filtration. The\ndigital filter design selected by Dr. Simson for this purpose, known\nas the Butterworth filter, is one of several known procedures for\nfrequency filtering of digital waveforms. The filtered signal is\nfurther analyzed to determine its average magnitude, as described in\nthe specification, by the root mean square technique. Comparison of\nthe resulting output to a predetermined level determines whether late\npotentials reside in the anterior portion of the QRS segment, thus\nindicating whether the patient is at high risk for ventricular\ntachycardia. The resultant output is not an abstract number, but is a\nsignal related to the patient's heart activity.\nThese claimed steps of \"converting\", \"applying\", \"determining\",\nand \"comparing\" are physical process steps that transform one\n\nphysical, electrical signal into another. The view that \"there is\nnothing necessarily physical about 'signals' \" is incorrect. In re\nTaner, 681 F.2d 787, 790, 214 USPQ 678, 681 (CCPA 1982) (holding\nstatutory claims to a method of seismic exploration including the\nmathematically described steps of \"summing\" and \"simulating from\").\nThe Freeman-Walter-Abele standard is met, for the steps of Simson's\nclaimed method comprise an otherwise statutory process whose\nmathematical procedures are applied to physical process steps.\nIt was undisputed that the individual mathematical procedures\nthat describe these steps are all known in the abstract. The method\nclaims do not wholly preempt these procedures, but limit their\napplication to the defined process steps. In answering the question\n\"What did the applicant invent?\", Grams, 888 F.2d at 839, 12 USPQ2d at\n1827, the Simson method is properly viewed as a method of analyzing\nelectrocardiograph signals in order to determine a specified heart\nactivity. Like the court in Abele, which was \"faced simply with an\nimproved CAT-scan process\", 684 F.2d at 909, 214 USPQ at 688, the\nSimson invention is properly viewed as an electrocardiograph analysis\nprocess. The claims do not encompass subject matter transcending what\nDr. Simson invented, as in O'Reilly v. Morse, 56 U.S. (15 How.) at 113\n(claims covered any use of electric current to transmit characters at\na distance); or in Benson, 409 U.S. at 68, 93 S.Ct. at 255, 175 USPQ\nat 675 (use of claimed process could \"vary from the operation of a\ntrain to verification of driver's licenses to researching the law\nbooks for precedents\"); or in Grams, 888 F.2d at 840, 12 USPQ2d at\n1828 (invention had application to \"any complex system, whether it be\nelectrical, mechanical, chemical or biological, or combinations\nthereof.\")\nThe Simson claims are analogous to those upheld in Diehr,\nwherein the Court remarked that the applicants \"do not seek to patent\na mathematical formula.... they seek only to foreclose from others\nthe use of that equation in conjunction with all of the other steps in\ntheir claimed process\". 450 U.S. at 187, 101 S.Ct. at 1057, 209 *1060\nUSPQ at 8. Simson's claimed method is similarly limited. The process\nclaims comprise statutory subject matter.\nB. The Apparatus Claims\nThe Simson apparatus for analyzing electrocardiographic signals\nis claimed in the style of 35 U.S.C. s 112, paragraph 6, whereby\nfunctionally described claim elements are \"construed to cover the\ncorresponding structure, material, or acts described in the\nspecification and equivalents thereof\". Thus the statutory nature vel\nnon of Simson's apparatus claims is determined with reference to the\ndescription in the '459 patent specification. In re Iwahashi, 888\nF.2d 1370, 1375, 12 USPQ2d 1908, 1911-12 (Fed.Cir.1989).\nThe apparatus claims require a means for converting the\nelectrocardiograph signals from the analog form in which they are\n\ngenerated into digital form. This means is described in the\nspecification as a specific electronic device, a conventional\nanalog-to-digital converter. A minicomputer, configured as described\nin the specification, is the means of calculating composite digital\ntime segments of the QRS waveform. The product is stored, as stated\nin the specification, in the form of electrical signals. The high\npass filter means is described in the specification as the\nminicomputer configured to perform the function of reverse time order\nfiltration of the anterior portion of the QRS waveform. The\nspecification and drawings show a disc memory unit to store the\ncomposite QRS signals, and associated connecting leads to the\ncomputer's processing unit. The comparing means is the processing\nunit configured to perform the specified function of root mean square\naveraging of the anterior portion of the QRS complex, and comparison\nof the resulting output with a predetermined level to provide an\nindication of the presence of late potentials in the\nelectrocardiograph signal.\nThe Simson apparatus claims thus define \"a combination of\ninterrelated means\" for performing specified functions. Iwahashi, 888\nF.2d at 1375, 12 USPQ2d at 1911. The computer-performed operations\ntransform a particular input signal to a different output signal, in\naccordance with the internal structure of the computer as configured\nby electronic instructions. \"The claimed invention ... converts one\nphysical thing into another physical thing just as any other\nelectrical circuitry would do\". In re Sherwood, 613 F.2d 809, 819,\n204 USPQ 537, 546 (CCPA 1980), cert. denied, 450 U.S. 994, 101 S.Ct.\n1694, 68 L.Ed.2d 193 (1981) (holding statutory claims to an apparatus\nfor analyzing seismic signals including mathematically described means\nfor \"sonogramming\", \"dividing\", and \"plotting\").\n[4] The use of mathematical formulae or relationships to\ndescribe the electronic structure and operation of an apparatus does\nnot make it nonstatutory. Iwahashi, 888 F.2d at 1375, 12 USPQ2d at\n1911. When mathematical formulae are the standard way of expressing\ncertain functions or apparatus, it is appropriate that mathematical\nterms be used. See W.L. Gore & Assoc., Inc. v. Garlock, Inc., 721\nF.2d 1540, 1556, 220 USPQ 303, 315 (Fed.Cir.1983), cert. denied, 469\nU.S. 851, 105 S.Ct. 172, 83 L.Ed.2d 107 (1984) (patents are directed\nto those of skill in the art). See also In re Bernhart, 417 F.2d\n1395, 1399, 163 USPQ 611, 616 (CCPA 1969) (\"all machines function\naccording to the laws of physics which can be mathematically set forth\nif known.\") That Simson's claimed functions could not have been\nperformed effectively without the speed and capability of electronic\ndevices and components does not determine whether the claims are\nstatutory.\nCorazonix argues that the final output of the claimed apparatus\n(and process) is simply a number, and that Benson and Flook support\n\nthe position that when the end product is a number, the claim is\nnonstatutory and can not be saved by claim limitations of the use to\nwhich this number is put. However, the number obtained is not a\nmathematical abstraction; it is a measure in microvolts of a specified\nheart activity, an indicator of the risk of ventricular tachycardia.\nThat the product is numerical is not a criterion of whether the claim\nis directed to statutory subject matter. See Meyer, 688 F.2d at 796\nn. 4, 215 USPQ at *1061 198 n. 4 (explaining that so-called \"negative\nrules\" of patentability \"were not intended to be separate tests for\ndetermining whether a claim positively recites statutory subject\nmatter.\")\n[5] The Simson apparatus claims satisfy the criteria for\nstatutory subject matter. They are directed to a specific apparatus\nof practical utility and specified application, and meet the\nrequirements of 35 U.S.C. s 101.\nConclusion\nThe judgment of invalidity on the ground that the claimed method\nand apparatus do not define statutory subject matter is reversed. The\ncause is remanded for resolution of remaining issues.\nTaxable costs in favor of Arrhythmia Research.\nREVERSED AND REMANDED.\nRADER, Circuit Judge, concurring.\nNearly twenty years ago, in Gottschalk v. Benson, 409 U.S. 63,\n93 S.Ct. 253, 34 L.Ed.2d 273 (1972), the Supreme Court dealt with a\ncomputer process for conversion of binary coded decimals into pure\nbinary numbers. Benson held this mathematical algorithm ineligible\nfor patent protection. 409 U.S. at 65, 71-72, 93 S.Ct. at 254, 257.\nBecause computer programs rely heavily on mathematical algorithms,\ncommentators saw dire implications in the Supreme Court's opinion for\npatent protection of computer software. For instance, one treatise,\nciting Benson, stated: [A] recent Supreme Court decision seemingly\neliminated patent protection for computer software. Donald S. Chisum,\nPatents s 1.01 (1991); see also id. at s 1.03[6].\nThe court upholds the '459 patent by applying a permutation of\nthe Benson algorithm rule. In reaching this result, the court adds\nanother cord to the twisted knot of precedent encircling and confining\nthe Benson rule. While fully concurring in the court's result and\ncommending its ability to trace legal strands through the tangle of\npost-Benson caselaw, I read later Supreme Court opinions to have cut\nthe Gordian knot. The Supreme Court cut the knot by strictly limiting\nBenson.\nRelying on the language of the patent statute, the Supreme Court\nin Diamond v. Diehr, 450 U.S. 175, 101 S.Ct. 1048, 67 L.Ed.2d 155\n(1981), turned away from the Benson algorithm rule. Thus, I too\n\nconclude that the '459 patent claims patentable subject matter--not on\nthe basis of a two-step post-Benson test, but on the basis of the\npatentable subject matter standards in title 35. Rather than\nperpetuate a nonstatutory standard, I would find that the subject\nmatter of the '459 patent satisfies the statutory standards of the\nPatent Act.\nI.\nThe questions presented by this case are whether the '459 patent\nclaims a process and apparatus within the meaning of 35 U.S.C. s 101\n(1988). Section 101 states: Whoever invents or discovers any new and\nuseful process, machine, manufacture, or composition of matter, or any\nnew and useful improvement thereof, may obtain a patent therefor,\nsubject to the conditions and requirements of this title. According to\nthis language, \"any\" invention or discovery within the four broad\ncategories of \"process, machine, manufacture, or composition of\nmatter\" is eligible for patent protection. \"Any\" is an expansive\nmodifier which broadens the sweep of the categories. See Diamond v.\nChakrabarty, 447 U.S. 303, 308- 09, 100 S.Ct. 2204, 2207, 65 L.Ed.2d\n144 (1980). The language of section 101 conveys no implication that\nthe Act extends patent protection to some subcategories of machines or\nprocesses and not to others.\nThe limits on patentable subject matter within section 101 focus\nnot on subcategories of machines or processes, but on characteristics,\nsuch as newness and usefulness. Section 101 also specifies that, in\naddition to newness and usefulness, an invention or discovery must\nsatisfy other \"conditions and requirements.\" These other \"conditions\nand requirements\" encompass *1062 characteristics like nonobviousness\nunder 35 U.S.C. s 103 (1988), or requirements like those in 35 U.S.C.\ns 112 (1988). In other words, the language of the Patent Act does not\nsuggest that the words \"machine\" or \"process\" carry limitations\noutside their ordinary meaning. See Diehr, 450 U.S. at 182, 101 S.Ct.\nat 1054 (\"Unless otherwise defined, 'words will be interpreted as\ntaking their ordinary, contemporary, common meaning.' \"). Rather the\nAct, by its terms, extends patent protection to \"any\" machine or\nprocess which satisfies the other conditions of patentability.\nII.\nIn Benson, the Supreme Court encountered the question of whether\na method for converting binary-coded decimals, which was useful in\nprogramming digital computers, was a patentable \"process\" under\nsection 101. 409 U.S. at 64, 93 S.Ct. at 254. The Court, by reading\na limitation not found in the statute into the term \"process,\"\ndetermined the method of conversion did not satisfy section 101.\nIn Parker v. Flook, 437 U.S. 584, 98 S.Ct. 2522, 57 L.Ed.2d 451\n(1978), the Court followed Benson. Flook claimed a method for\nupdating alarm limits during catalytic conversion of hydrocarbons.\nThe Court found Flook's method involving mathematical\n\ncalculations--though applied to a post-solution use-- unpatentable.\nFlook, 437 U.S. at 590, 98 S.Ct. at 2525. Flook clearly limited the\nBenson rule to mathematical formulae and mathematical algorithms. Id.\n437 U.S. at 585, 587, 589, 590, 591, 592, 594, 595, 98 S.Ct. at 2523,\n2524, 2525, 2525, 2526, 2526, 2527, 2528. By mixing the terms\n\"formula\" and \"algorithm,\" 437 U.S. at 585-86, 98 S.Ct. at 2523,\nhowever, Flook further confused the meaning of \"mathematical\nalgorithm.\" As used by Benson, that term meant \"a procedure for\nsolving a given type of mathematical problem.\" 409 U.S. at 65, 93\nS.Ct. at 254. Thus, an \"algorithm\" required both a mathematical\nproblem and a solution procedure. A \"formula\" does not present or\nsolve a mathematical problem, but merely expresses a relationship in\nmathematical terms. A \"formula,\" even under Benson's definition, is\nnot an algorithm.\nIn the wake of Benson, the Court of Customs and Patent Appeals\nstruggled to implement the algorithm rule. [FN1] Much of the\ndifficulty sprang from the obscurity of the terms invoked to preclude\npatentability--terms like \"law of nature,\" \"natural phenomena,\"\n\"formulae,\" or \"algorithm.\" [FN2] *1063 Benson, 409 U.S. at 65, 67, 93\nS.Ct. at 254, 255; Flook, 437 U.S. at 593, 98 S.Ct. at 2527. In the\ncontext of a product's subject matter patentability, Justice\nFrankfurter discussed this analytical difficulty:\nFN1. See, e.g., In re Christensen, 478 F.2d 1392, 1396, 178 USPQ\n35 (CCPA 1973) (Rich, J., concurring) (\"The Supreme Court in Benson\nappears to have held that claims drafted in such terms are not\npatentable--for what reason remaining a mystery.\"), overruled in part\nby In re Taner, 681 F.2d 787, 214 USPQ 678 (1982); In re Johnston, 502\nF.2d 765, 773, 183 USPQ 172, 179 (CCPA 1974) (Rich, J., dissenting)\n(\"I am probably as much--if not more--confused by the wording of the\nBenson opinion as many others.\"); rev'd, Dann v. Johnston, 425 U.S.\n219, 96 S.Ct. 1393, 47 L.Ed.2d 692 (1976); In re Chatfield, 545 F.2d\n152, 157, 191 USPQ 730, 735 (CCPA 1976) (Nonstatutory claims are\n\"drawn to mathematical problem-solving algorithms or to purely mental\nsteps.\"), cert. denied, Dann v. Noll, 434 U.S. 875, 98 S.Ct. 226, 54\nL.Ed.2d 155 (1977).\nFN2. The Court in Diamond v. Diehr, 450 U.S. 175, 101 S.Ct.\n1048, 67 L.Ed.2d 155 (1981), expressly recognized that the term\nalgorithm \"is subject to a variety of definitions.\" 450 U.S. at 186\nn. 9, 101 S.Ct. at 1056 n. 9. Even Benson's definition for\n\"algorithm\" creates legal problems. For instance, the Benson-Tabbot\nalgorithm worked with numbers, but \"solved\" a \"mathematical problem\"\nonly in a very loose sense. Rather the Benson-Tabbot algorithm\ntranslated symbols from one numerical system to another. Cf. In re\nToma, 575 F.2d 872, 197 USPQ 852 (CCPA 1978) (Using a digital computer\n\nto translate technical languages was not an algorithm.); In re\nFreeman, 573 F.2d 1237, 197 USPQ 464 (CCPA 1978) (Using computer to\ntranscribe alphanumeric characters was not an algorithm.). Moreover\nsome problems, even if expressed in mathematical terms, are not\nmathematical problems. Mathematics, like a language, is a form of\nexpression. The operation of a machine, the generation of\nelectricity, the reaction of two chemicals, a baseball batter's swing,\na satellite's orbit-- all are within the descriptive power of\nmathematics. The Court of Customs and Patent Appeals recognized this\naxiomatic point: However, some mathematical algorithms ... represent\nideas or mental processes and are simply logical vehicles for\ncommunicating possible solutions to complex problems. In re Meyer, 688\nF.2d 789, 794, 215 USPQ 193, 197 (CCPA 1982). No wonder the Benson\nrule is confusing when electrical, chemical, or mechanical processes\nescape scrutiny when expressed in written language, but become suspect\nwhen expressed in the mathematical language. In In re Grams, 888 F.2d\n835, 12 USPQ2d 1824 (Fed.Cir.1989), for instance, a medical diagnostic\nprocess was considered an unpatentable \"mathematical algorithm\" even\nthough it did not present, or propose a solution to, a mathematical\nproblem at all.\nIt only confuses the issue, however, to introduce such terms as\n\"the work of nature\" and the \"laws of nature.\" For these are vague\nand malleable terms infected with too much ambiguity and equivocation.\nEverything that happens may be deemed \"the work of nature,\" and any\npatentable composite exemplifies in its properties \"the laws of\nnature.\" Arguments drawn from such terms for ascertaining\npatentability could fairly be employed to challenge almost every\npatent. Funk Bros. Seed Co. v. Kalo Inoculant Co., 333 U.S. 127,\n134-35, 68 S.Ct. 440, 443, 92 L.Ed. 588 (1948) (Frankfurter, J.,\nconcurring). When attempting to enforce a legal standard embodied in\nbroad, vague, nonstatutory terms, the courts have floundered.\nAt length, in In re Freeman, 573 F.2d 1237, 197 USPQ 464 (CCPA\n1978) as modified by In re Walter, 618 F.2d 758, 205 USPQ 397 (CCPA\n1980), the Court of Customs and Patent Appeals settled on a two-step\ntest to detect unpatentable algorithms under the Benson rule: First,\nthe claim is analyzed to determine whether a mathematical algorithm is\ndirectly or indirectly recited. Next, if a mathematical algorithm is\nfound, the claim as a whole is further analyzed to determine whether\nthe algorithm is \"applied in any manner to physical elements or\nprocess steps,\" and, if it is, it \"passes muster under s 101.\" In re\nPardo, 684 F.2d 912, 915, 214 USPQ 673, 675-76 (CCPA 1982) (citing In\nre Abele, 684 F.2d 902, 214 USPQ 682 (CCPA 1982)). Walter adopted\nFlook's implicit limitation of the Benson rule to \"mathematical\nalgorithms.\" 618 F.2d at 764-65 n. 4. Like Flook, however, Walter\nconfused \"mathematical algorithms\" with calculations, formulas, and\n\nmathematical procedures generally. Id.\nAlthough downstream from Benson, this Freeman-Walter fork hid\nsome of the same unnavigable cross-currents. In the first place, the\nterm \"mathematical algorithm\" remained vague. Without a statutory\nanchor, this term was buffeted by every judicial wind until its course\nwas indiscernible. The obscurity of the term \"mathematical algorithm\"\nis evident in two cases. In Pardo, 684 F.2d 912, the court narrowly\nlimited \"mathematical algorithm\" to the execution of formulas with\ngiven data. In the same year, the court in In re Meyer, 688 F.2d 789,\n215 USPQ 193 (CCPA 1982), sweepingly interpreted the same term to\ninclude any mental process that can be represented by a mathematical\nalgorithm.\nThe second part of the test had similar uncertainties. The test\ndid not suggest how many physical steps a claim must take to escape\nthe fatal \"mathematical algorithm\" category. In Abele, 684 F.2d 902,\nthe court upheld claims applying \"a mathematical formula within the\ncontext of a process which encompasses significantly more than the\nalgorithm alone.\" Id. at 909. Thus, the court apparently made\ncompliance with the two-part test a function of the \"significance\" of\nadditions to the algorithm--hardly a predictable standard.\nThe Court of Customs and Patent Appeals later clarified that the\ntwo-part algorithm is not the exclusive test for detecting\nunpatentable subject matter. Meyer, 688 F.2d at 796. Indeed, the\ncourt abandoned the two-step test in In re Taner, 681 F.2d 787, 214\nUSPQ 678 (CCPA 1982).\nWith the advent of the Court of Appeals for the Federal Circuit,\nthis court continued to grapple with the inherent vagueness of the\ntwo-part test for unpatentable algorithms. See In re Grams, 888 F.2d\n835, 12 USPQ2d 1824 (Fed.Cir.1989); In re Iwahashi, 888 F.2d 1370, 12\nUSPQ2d 1980 (Fed.Cir.1989). At one point, this court clarified *1064\nthat failure to satisfy the second prong of the two-part test \"does\nnot necessarily doom the claim.\" Grams, 888 F.2d at 839. Instead\nthis court recommended asking the broader question of \"What did\napplicants invent?\" in the context of the claim and its supporting\ndisclosure. Id. At another point in the same opinion, this court put\nthe central question in terms of whether \"the claim in essence covers\nonly the algorithm.\" Id. at 837.\nRecognizing the obscurity of \"algorithm,\" this court in Iwahashi\nattempted to \"take the mystery out of the term\": [W]e point out once\nagain that every step-by-step process, be it electronic or chemical or\nmechanical, involves an algorithm in the broad sense of the term.\nSince s 101 expressly includes processes as a category of inventions\nwhich may be patented and s 100(b) further defines the word \"process\"\nas meaning \"process, art or method, and includes a new use of a known\nprocess, machine, manufacture, composition of matter, or material,\" it\nfollows that it is no ground for holding a claim is directed to\n\nnonstatutory subject matter to say it includes or is directed to an\nalgorithm. This is why the proscription against patenting has been\nlimited to mathematical algorithms.... 888 F.2d at 1374 (emphasis in\noriginal). Because the Iwahashi claims as a whole described a machine\nor a manufacture (which fit within section 101 without regard to the\nmeaning of \"process\"), this court in Iwahashi did not have occasion to\nresolve conflicts over the legal bounds of \"mathematical algorithm.\"\nIn sum, the two-part test was cast in the crucible of confusion\ncreated by Benson. If the Benson algorithm rule was the last and\nbinding word on the meaning of \"process\" under section 101, this court\nwould be obligated to follow--regardless of any imprecision or\nambiguity. The Supreme Court, however, has already shown another\nreading of the Patent Act.\nIII.\nIn Diehr, the Supreme Court adopted a very useful algorithm for\ndetermining patentable subject matter, namely, following the Patent\nAct itself. Diehr upheld claims to a process for curing synthetic\nrubber which included use of a mathematical computer process. After\nsetting forth the procedural history of the case, the Supreme Court\nstated: In cases of statutory construction, we begin with the language\nof the statute. Diehr, 450 U.S. at 182, 101 S.Ct. at 1054. Perhaps\nwith an eye to the attempts to apply the Benson rule, the Court then\nnoted: [I]n dealing with the patent laws, we have more than once\ncautioned that \"courts 'should not read into the patent laws\nlimitations and conditions which the legislature has not expressed.' \"\nId. (citations omitted). Indeed Congress has never stated that\nsection 101's term \"process\" excludes certain types of algorithms.\nTherefore, as Diehr commands, this court should refrain from employing\njudicially-created tests to limit section 101.\nWith that introduction, the Court proceeded to interpret the\nword \"process\" from section 101. In doing so, the Court briefly\nexamined the history of patent laws back to 1793. See also\nChakrabarty, 447 U.S. at 308-09, 100 S.Ct. at 2207. The Court summed\nup the legislative intent of the patent laws with this broad\nadmonition: [T]he Committee Reports accompanying the 1952 Act ...\ninform us that Congress intended statutory subject matter to \"include\nanything under the sun that is made by man.\" S.Rep. No. 1979, 82d\nCong., 2d Sess., 5 (1952); H.R.Rep. No. 1923, 82d Cong., 2d Sess., 6\n(1952). Diehr, 450 U.S. at 182, 101 S.Ct. at 1054. This passage\nunderscores the fallacy of creating artificial limits for the words of\nthe 1952 Act.\nCourts should give \"process\" its literal and predictable\nmeaning, without conjecturing about the policy implications of that\nliteral reading. Cf. Chakrabarty, 447 U.S. at 316-18, 100 S.Ct. at\n2211-12. If Congress wishes to remove some processes from patent\nprotection, it can enact such an exclusion. Again, in the absence of\n\nlegislated *1065 limits on the meaning of the Act, courts should not\npresume to construct limits. The Supreme Court directed this court to\nfollow the Act.\nWith that preface, the Supreme Court in Diehr specifically\nlimited Benson. In the first place, the Court acknowledged the narrow\ndefinition of \"mathematical algorithm\" set forth by Benson. 450 U.S.\nat 186 n. 9, 101 S.Ct. at 1056 n. 9. Moreover, the Court expressly\nstated: Our previous decisions regarding the patentability of\n\"algorithms\" are necessarily limited to the more narrow definition\nemployed by the Court.... Id. Thus, after Diehr, only a mathematical\nprocedure for solution of a specified mathematical problem is suspect\nsubject matter.\nThe Supreme Court in Diehr also limited Benson to a further\nnarrow proposition. That narrow proposition supports reliance on the\nstatutory language of the 1952 Act, rather than a nonstatutory\nalgorithm rule.\nCiting Benson, the Court in Diehr stated: This Court has\nundoubtedly recognized limits to s 101 and every discovery is not\nembraced within the statutory terms. Excluded from such patent\nprotection are laws of nature, natural phenomena, and abstract ideas.\nOur recent holdings in Gottschalk v. Benson, supra, and Parker v.\nFlook, supra, both of which are computer-related, stand for no more\nthan these long-established principles. 450 U.S. at 185, 101 S.Ct. at\n1056. In Taner, 681 F.2d at 791, this court's predecessor said: [I]n\nDiehr, the Supreme Court made clear that Benson stands for no more\nthan the long-established principle that laws of nature, natural\nphenomena, and abstract ideas are excluded from patent protection and\nthat \"a claim drawn to subject matter otherwise statutory does not\nbecome nonstatutory because it uses a mathematical formula, computer\nprogram, or digital computer.\" [Citations omitted.] Thus, Diehr\nlimited Benson and its progeny to three classes of unpatentable\nsubject matter--laws of nature, natural phenomena, and abstract ideas.\nIndeed, in Chakrabarty, the Court also cited Benson for the\nproposition that these three categories are unpatentable. 447 U.S. at\n309, 100 S.Ct. at 2207; see also Flook, 437 U.S. at 593, 98 S.Ct. at\n2527.\nBecause the Supreme Court cited Benson in Diehr, 450 U.S. at\n185-86, 101 S.Ct. at 1056, this court has doubted whether Diehr\nlimited the algorithm rule. Grams, 888 F.2d at 838. However, In re\nTaner, clearly interprets Diehr as strictly limiting Benson. 681 F.2d\nat 789, 791. More importantly, the Supreme Court instructed this\ncourt to apply the language of the 1952 Act without reading\nunexpressed limitations into the statute. Diehr, 450 U.S. at 182, 101\nS.Ct. at 1054. Finally, to the extent that the Benson rule applies to\nmathematical algorithms in the wake of Diehr, the Supreme Court\ndefined \"mathematical algorithm\" very narrowly.\n\nBy strictly limiting Benson, the Supreme Court signalled a\nchange in the focus for patentability from the algorithm rule to the\nstatutory standards of the Patent Act. The Supreme Court confined\nBenson to a narrow proposition which certainly does not preclude\npatentability of the '459 patent's heart attack risk detection\nprocess.\nThe '459 Patent\nThe '459 patent discloses an apparatus and a method for\nanalyzing electrocardiograph signals to detect heart attack risks.\nThe apparatus is a machine and is covered by the Iwahashi rule. The\nmethod converts an analog signal to a digital signal which passes, in\nreverse time order, through the mathematical equivalent of a filter.\nThe filtered signal's amplitude is then measured and compared with a\npredetermined value.\nThe '459 invention manipulates electrocardiogram readings to\nrender a useful result. While many steps in the '459 process involve\nthe mathematical manipulation of data, the claims do not describe a\nlaw of nature or a natural phenomenon. Furthermore, the claims do not\ndisclose mere abstract *1066 ideas, but a practical and potentially\nlife-saving process. Regardless of whether performed by a computer,\nthese steps comprise a \"process\" within the meaning of section 101.\nThe district court granted summary judgment in favor of\nCorazonix because \"the claims of the '459 patent are drawn to a\nnonstatutory mathematical algorithm and, as such, are unpatentable\npursuant to the provisions of 35 U.S.C. s 101.\" This erroneous\nconclusion illustrates the confusion caused by Benson and its progeny.\nThis conclusion is erroneous for several reasons. First, even\nif mathematical algorithms are barred from patentability, [FN3] the\n'459 patent as a whole does not present a mathematical algorithm. The\n'459 patent is a method for detecting the risk of a heart attack, not\nthe presentation and proposed solution of a mathematical problem. In\nDiehr, the Supreme Court viewed the claims as \"an industrial process\nfor molding of rubber products,\" not a mathematical algorithm. 450\nU.S. at 192-93, 101 S.Ct. at 1060. The '459 patent's claims as a\nwhole disclose a patentable process.\nFN3. The Court in Diehr stated: \"we concluded that such an\nalgorithm, or mathematical formula, is like a law of nature, which\ncannot be the subject of a patent.\" 450 U.S. at 186, 101 S.Ct. at\n1056 (emphasis added). In fact, a mathematical algorithm does not\nappear in nature at all, but only in human numerical processes. A law\nof nature is indeed not patentable, but for reasons unrelated to the\nmeaning of \"process.\" A law of nature, even if a process, is not\n\"new\" within the meaning of s 101. Moreover, in Sarker, this court's\npredecessor gave another reason a law of nature cannot satisfy section\n101. In re Sarker, 588 F.2d 1330, 1333, 200 USPQ 132, 137 (CCPA\n\n1978). In sum, the Patent Act excludes laws of nature from patent\nprotection even without a strained explanation excluding laws of\nnature from the meaning of \"process.\" It is difficult to determine\nhow or why mathematical algorithms are \"like\" laws of nature.\nSecond, the '459 patent does not claim a natural law, abstract\nidea, or natural phenomenon. Diehr limited the Benson rule to these\nthree categories, none of which encompass the '459 patent.\nFinally, and most important, Diehr refocused the patentability\ninquiry on the terms of the Patent Act rather than on non-statutory,\nvague classifications. Under the terms of the Act, a \"process\"\ndeserves patent protection if it satisfies the Act's requirements.\nThe '459 patent claims a \"process\" within the broad meaning of section\n101. Therefore, this court must reverse and remand.\nCONCLUSION\nWhen determining whether claims disclosing computer art or any\nother art describe patentable subject matter, this court must follow\nthe terms of the statute. The Supreme Court has focused this court's\ninquiry on the statute, not on special rules for computer art or\nmathematical art or any other art.\nThe claims of the '459 patent define an apparatus and a process.\nBoth are patentable subject matter within the language of section 101.\nTo me, the Supreme Court's most recent message is clear: when all else\nfails (and the algorithm rule clearly has), consult the statute. On\nthis basis, I, too, would reverse and remand."
    },
    {
      "category": "Resource",
      "title": "borlandcertoppo.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/25af7f0066808a960aea450ee5215e28_borlandcertoppo.pdf",
      "content": "No. 94-2003\nIN THE SUPREME COURT OF THE UNITED STATES\nOctober Term, 1994\nLotus Development Corporation,\nPetitioner,\nv.\nBorland International, Inc.,\nRespondent.\nOn Petition for a Writ of Certiorari to\nthe United States Court of Appeals\nfor the First Circuit\nBRIEF IN OPPOSITION\nTO PETITION FOR CERTIORARI\nGary L. Reback\n(Counsel of Record)\nMichael Barclay\nIsabella E. Fu\nWilson, Sonsini, Goodrich & Rosati Professional Corporation\n650 Page Mill Road\nPalo Alto, California 94304\nTelephone: (415) 493-9300\nPeter E. Gelhaar\nKatherine L. Parks\nDonnelly, Conroy & Gelhaar\nOne Post Office Square\n33rd Floor\nBoston, Massachusetts 02109\n\nTelephone: (617) 542-7400\nAttorneys for Respondent\nJuly 1995\nQUESTION PRESENTED\nDid the First Circuit correctly hold that commands used to operate a computer\nspreadsheet program are uncopyrightable under 17 U.S.C. sect. 102(b)?\nRULE 29.1 STATEMENT\nRespondent Borland International, Inc. has no parent corporation or subsidiaries that are\nnot wholly owned, except for certain foreign subsidiaries in which a minimal amount of\nshares (fewer than 1%), which are not publicly traded, are held by foreign nationals in\naccordance with local law.\nTABLE OF CONTENTS\n. . . . . Page\nQUESTION PRESENTED. . . . . . . . . . . i\nRULE 29.1 STATEMENT . . . . . . . . . . ii\nTABLE OF AUTHORITIES. . . . . . . . . . v\nINTRODUCTION AND SUMMARY. . . . . . . . 1\nSTATEMENT OF THE CASE . . . . . . . . . 8\nA. Factual Background. . . . . . 9\n1. The Lotus Product. . . . 9\n2. The Borland Product. . . 11\nB. Proceedings in the District Court . . 12\nREASONS FOR DENYING THE PETITION. . . . 13\nI. THE CIRCUITS ARE IN AGREEMENT THAT WORDS USED AS\nBUTTONS TO OPERATE A PROGRAM, UNLIKE THE PROGRAM ITSELF,\nARE UNCOPYRIGHTABLE. . . . . . . . 13\nA. The District Court Erroneously Applied the \"Abstractions\" Test to\nUncopyrightable Subject Matter. . . 13\nB. The District Court's Decision to Extend Copyright to the Words That\nOperate the Program Ran Afoul of Both the Statute and the Case Law. . . .\n. . . 18\nC. There Is No Conflict Among the Circuits That Menu Commands and\nSimilar Methods of Operation Are Uncopyrightable.. . . . . . . 21\n\nII. THE FIRST CIRCUIT OPINION REMOVES THE UNCERTAINTY\nPRODUCED BY THE DISTRICT COURT AND UPHOLDS THE OVERALL\nINTELLECTUAL PROPERTY FRAMEWORK ESTABLISHED BY\nCONGRESS.. . . . . . . . . . . . . 25\nA. The First Circuit Opinion Restores Clarity and Predictability to the\nLaw. 25\nB. Both Copyright and Patent Remain Sources of Strong Protection,\nProviding Enormous Incentives for Authors and Inventors of Software\nProducts to Innovate. . . . . . . . . . . 28\nCONCLUSION. . . . . . . . . . . . . . . 29\nTABLE OF AUTHORITIES\nCASES . . . . Page(s)\nAshton-Tate Corp. v. Ross, 728 F. Supp. 597 (N.D. Cal. 1989) . . . . . 6, 21, 22, 25\nAshton-Tate Corp. v. Ross, 916 F.2d 516 (9th Cir. 1990) . . . . . 6, 21, 22\nAutoskill, Inc. v. National Educ. Support Sys., Inc., 994 F.2d 1476 (10th Cir.), cert.\ndenied, 114 U.S. 307 (1993) . . . . 22, 23\nBaker v. Selden, 101 U.S. 99 (1879) . . . . . passim\nBrown Bag Software v. Symantec Corp., 960 F.2d 1465 (9th Cir.), cert. denied sub. nom.\nBB Asset Mgmt. Inc. v. Symantec Corp., 113 S.Ct. 198 (1992) . . . . . 21\nComputer Assoc. Int'l, Inc. v. Altai, Inc., 982 F.2d 693 (2d Cir. 1992). . passim\nDigital Comm. Assoc., Inc. v. Softklone Distrib. Corp., 659 F. Supp. 449 (N.D. Ga.\n1987) . . . . . 23\nEngineering Dynamics, Inc. v. Structural Software, Inc., 26 F.3d 1335 (5th Cir. 1994) . . .\n. . 7, 24\nEngineering Dynamics, Inc. v. Structural Software, Inc., 46 F.3d 408 (5th Cir. 1995) . . . .\n. 7, 24\nGates Rubber Co. v. Bando Chem. Indus., Ltd., 9 F.3d 823 (10th Cir. 1993) . . . . . 6, 16,\nGates Rubber Co. v. Bando Chem. Indus., Ltd., No. 92-S-136 (D. Colo. filed June 12,\n1995) . . . . . 6, 23\nJohnson Controls, Inc. v. Phoenix Control Sys., Inc., 886 F.2d 1173 (9th Cir. 1989) . . . . .\n. 21\n\nLotus Dev. Corp. v. Borland Int'l, Inc., 49 F.3d 807 (1st Cir. 1995). . . . . . passim\nLotus Dev. Corp. v. Borland Int'l, Inc., 788 F. Supp. 78 (D. Mass. 1992) . . . . . passim\nLotus Dev. Corp. v. Borland Int'l, Inc., 799 F. Supp. 203 (D. Mass. 1992) . . . . . passim\nLotus Dev. Corp. v. Borland Int'l, Inc., 831 F. Supp. 202 (D. Mass. 1993) . . . . . 2, 10\nLotus Dev. Corp. v. Borland Int'l, Inc., 831 F. Supp. 223 (D. Mass. 1993) . . . . . 2, 10\nLotus Dev. Corp. v. Paperback Software Int'l, 740 F. Supp. 37 (D. Mass. 1990) . . . . .\npassim\nManufacturers Technologies, Inc. v. CAMS, Inc., 706 F. Supp. 984 (D. Conn. 1989) . . . .\n. 24\nMitek Holdings, Inc. v. Arce Eng'g Co., 864 F. Supp. 1568 (S.D. Fla. 1994) . . . . . 24\nSony Corp. v. Universal City Studios, Inc., 464 U.S. 417 (1984) . . . . . . 29\nWhelan Assoc., Inc. v. Jaslow Dental Laboratory, Inc., 797 F.2d 1222 (3d Cir. 1986),\ncert. denied, 479 U.S. 1031 (1987) . . . . . 14, 16, 25\nSTATUTES, RULES, AND REGULATIONS\n60 Fed. Reg. 28,778 (proposed June 2, 1995) . . . . . 28\nH.R. Rep. No. 1476, 94th Cong., 2d Sess. 5455 (1976), reprinted in 1976 U.S.C.C.A.N.\n5659 . . . . . 15\n17 U.S.C. sect. 101 . . . . . . . . 14\n17 U.S.C. sect. 102(b) . . . . . passim\n28 U.S.C. sect. 1292(a) . . . . . . 12\nMISCELLANEOUS\nCopyright Office Circular 61, Copyright Registration for Computer Programs . . . . . 26\nPaul Goldstein, Copyright (1989) . . . . . 15, 26\nPaul Goldstein, Infringement of Copyright in Computer Programs, 47 U. Pitt. L. Rev.\n1119 (1986) . . . . . 26\n\nKaren S. Kovach, Comment, Computer Software Design; User Interface--Idea or\nExpression? 60 U. Cin. L. Rev. 161 (1991) . . . . . . . . 3\nKenneth A. Liebman, et al., Back To Basics: A Critique Of The Emerging Judicial\nAnalysis Of The Outer Limits Of Computer Program Expression, 2 Computer Law., Dec.\n1985, at 1 . . . . . 15\nSteven W. Lundberg et al., Identifying Uncopyrightable Computer Implemented\nProcesses and Systems, 9 Computer Law., Apr. 1992, at 7 . . . . . 3\nDavid Nimmer & Melville B. Nimmer, Nimmer on Copyright (1994) . . . 14\nPamela Samuelson, Computer Programs, User Interfaces, and Section 102(b) of the\nCopyright Act of 1976: A Critique of Lotus v. Paperback, 55 Law & Contemp. Probs.,\nSpring 1992, at 311 . . . . . 3\nTimothy S. Teter, Note, Merger and the Machines: An Analysis of the Pro-Compatibility\nTrend in Computer Software Copyright Cases, 45 Stan. L. Rev. 1061 (1993) . . . . . 3\nU.S. Department of Commerce, Press Release No. 95-21, Software Patent Guidelines\nReleased Today, 6/1/95 . . . . . 28\nJulian Velasco, The Copyrightability of Nonliteral Elements of Computer Programs, 94\nColumbia L.Rev. 242 (1994) . . . . . . . 3\nTABLE OF CONVENTIONS\nBorland -- Respondent Borland International, Inc.\nLotus -- Petitioner Lotus Development Corporation\nPetition or Pet.-- Lotus' Petition for a Writ of Certiorari filed in this Court\nPet. App. -- Appendix to Lotus' Petition filed in this Court\n1st Cir. App. -- Joint Appendix of Record filed in the U.S. Court of Appeals for the First\nCircuit (the court below)\nBorland S.J. Brief--Borland's Memorandum in Support of Cross-Motion for Summary\nJudgment (Dkt. No. 141) in the district court\nEx. __ -- Exhibit __ from Exhibits in Support of Borland's Cross-Motion for Sum- mary\nJudgment (Dkt. No. 142) in the district court\nRE -- Excerpts of Record attached to Borland's opening brief in the court below (filed\nDec. 14, 1993)\n\nNo. 94-2003\nIN THE SUPREME COURT OF THE UNITED STATES\nOctober Term, 1994\nLotus Development Corporation,\nPetitioner,\nv.\nBorland International, Inc.,\nRespondent.\nOn Petition for a Writ of Certiorari to the United States Court of Appeals for the First\nCircuit\nBRIEF IN OPPOSITION\nTO PETITION FOR CERTIORARI\nINTRODUCTION AND SUMMARY\nThe Court of Appeals in this case held that the commands used to operate a computer\nspreadsheet program--common commands such as \"COPY,\" \"MOVE,\" or \"PRINT\"\ndisplayed to the user on a computer screen--are uncopyrightable under sect. 102(b) of the\nCopyright Act. The court's opinion relied on the express language of the statute that\nforbids copyright protection for \"methods of operation\" and \"systems.\" The court also\nrelied on this Court's seminal decision in the area, Baker v. Selden, 101 U.S. 99 (1879),\nwhich mandates that claims for the protection of methods of operation and systems be\ngoverned by the patent law rather than the copyright law.\nThe First Circuit's opinion carefully reviewed the leading authority from the other\ncircuits, principally the Second Circuit's decision in Computer Assoc. Int'l, Inc. v. Altai,\nInc., 982 F.2d 693 (2d Cir. 1992), that sets forth a methodology for evaluating claims of\ncopyright infringement in the text (i.e., \"code\") and \"structure\" of computer programs.\nLotus Dev. Corp. v. Borland Int'l, Inc., 49 F.3d 807, 814 (1st Cir. 1995), Pet. App. at 13a-\n15a. The First Circuit readily agreed that the methodology used in Altai and similar cases\nprovides \"a useful framework\" for evaluating infringement claims in \"code\" and \"code\nstructure\" but was simply inapposite to the issue here--the copyrightability of command\nwords, or \"menus,\" used to operate the program. 49 F.3d at 815, Pet. App. at 14a. The\nFirst Circuit viewed this issue as easily resolvable by reference to the statute and\nSupreme Court authority.\n\nJudge Boudin filed a separate opinion in which he concurred in the majority's reasoning\nas well as its conclusion. 49 F.3d at 821, Pet. App. at 27a-28a. Judge Boudin went on to\nexplain that extending copyright protection to the command words at issue by judicial\nfiat, as the district court had done, is at variance with the intent of Congress and is both\ninefficient and anticompetitive from an economic perspective. Lotus should look to the\npatent law, rather than copyright, to protect its method of operation.\nThe First Circuit decision reversed a series of opinions in this case from a single judge in\nthe District of Massachusetts.1 From the beginning, the district court eschewed a narrow\nfocus on what was actually at issue in this case--the method by which the user tells the\ncomputer program what to do. Instead, the district court viewed the case as the\nopportunity to involve itself in the developing case law regarding the protection of\ncomputer program \"code\" and \"structure.\" Although those issues are not present in this\ncase, the district court sought to inject this case into the debate about those issues, by\ncreating its own novel methodology to determine the copyrightability of all aspects of\ncomputer technology.\nThe Lotus petition describes the district court opinions variously as \"virtually canonical,\"\nas having \"a prominent role\" and as a \"touchstone\" in computer copyright law. Petition at\n2, 15, 22. Exactly the opposite is true. The district court decisions in this case and in the\npredecessor Paperback case provoked a firestorm of controversy. As the record below\nreflects, the district court opinions were widely criticized in the academic community,2\nthe legal press,3 the national financial press,4 and the computer industry press5 for\nextending copyright protection to put large sectors of the software industry off limits to\ncompetition, thereby producing a radical departure from the leading authority of other\ncircuits. Although Lotus claims that the Second Circuit's Altai decision cites the district\ncourt opinions at issue here \"with approval,\" Pet. at 16, in fact the Second Circuit\nspecifically cited and pointedly rejected the district court's \"incentive-based arguments in\nfavor of broad copyright protection\" as having a \"corrosive effect on certain fundamental\ntenets of copyright doctrine.\" 982 F.2d at 712. Astonishingly, the Lotus petition fails to\ndisclose the Second Circuit's pointed criticism of the district court's position.\nIn the proceedings below, a myriad of industry associations (representing both large and\nsmall companies), consumer groups, distinguished academics, eminent computer\nscientists, and even the Register of Copyrights of the United States all filed amicus briefs\ncriticizing the district court and urging reversal of its opinions.6 Lotus' position, by\ncontrast, has attracted little support in the software industry. Its amici have consisted of a\nfew large companies who favor the extension of copyright law to inhibit competition\nfrom the hundreds of other operating system and application software companies.\nLotus' argument that the First Circuit decision created a conflict in the circuits is pure\nfabrication. Lotus argues that there is a consensus in the circuits regarding the application\nof the \"abstractions\" test to computer programs, that the district court's opinions in this\ncase are a part of that consensus, and that the First Circuit's decision departs from that\nbody of law. But, in fact, the discussion in the circuit courts regarding the \"abstractions\"\ntest is directed to different subject matter--i.e., the program code and structure--rather\n\nthan the menus used to operate the program. That is the principal failing in Lotus'\nargument and the reason Lotus lost this case. As the First Circuit made plain, this case is\nnot about a computer program; it is about the menu words that are used as buttons and\nswitches to operate the program. The First Circuit decision does not stand for the\nproposition that it is error to apply the \"abstractions\" test to computer programs. Rather,\nthe First Circuit has held that it is error to apply the \"abstractions\" test to something (in\nthis case menus) that is not copyrightable in the first place.\nNor did the First Circuit reject the \"idea/expression\" dichotomy in applying sect. 102(b)\nas Lotus asserts. Pet. at 23. Rather, referring to the express language of the statute, the\nFirst Circuit recognized that sect. 102(b) makes \"methods of operation\" and \"systems\" as\nwell as \"ideas\" uncopyrightable. The First Circuit applied the dichotomy in the statute\nand case law, finding that the commands are on the uncopyrightable side of the line\n(which Lotus calls the \"distinction\") between \"ideas,\" \"methods of operation,\" and\n\"systems,\" on the one hand, which are uncopyrightable, and \"expression\" and\n\"description,\" on the other hand, which are copyrightable.7\nContrary to Lotus' position, no circuit has held that the menu commands that operate the\nprogram are copyrightable on any theory, \"idea/expression\" dichotomy, \"abstractions\" or\notherwise. In fact, it was the district court in this case that departed from existing\nauthority when it declined to follow the Ninth Circuit's holding that the menu command\nhierarchy of a spreadsheet is uncopyrightable under 17 U.S.C. sect. 102(b). In declining\nto follow the Ninth Circuit's decision, Ashton-Tate Corp. v. Ross, 916 F.2d 516, 521-22\n(9th Cir. 1990), the district court stated:\nIn the interest of completeness and candor, I note as well that courts in one circuit are not\nbound by the decisions of other circuits. Borland II, 799 F. Supp. at 220, Pet. App. at\n136a. Apparently lacking the \"completeness and candor\" of the district court, the Lotus\npetition does not even mention the Ashton-Tate decision.\nThe only other circuit (the Tenth Circuit) to have directly considered the copyrightability\nof menu commands vacated a district court decision holding that menu commands are\ncopyrightable and provided instructions for further consideration of the issue. Gates\nRubber Co. v. Bando Chem. Indus., Ltd., 9 F.3d 823, 843-44 (10th Cir. 1993). On\nremand, the district court held that the menu commands were uncopyrightable, citing the\nFirst Circuit's Lotus decision approvingly. Gates Rubber Co. v. Bando Chem. Indus.,\nLtd., No. 92-S-136 (D. Colo. filed June 12, 1995). Lotus' assertion that \"[i]t is now legal\nto copy menus in the First Circuit but not in the Fifth, Ninth or Tenth,\" Pet. at 28, is\nsimply preposterous.\nSimilarly, the Lotus petition claims that a particular Fifth Circuit decision \"relied\nheavily\" on the district court's analysis. Pet. at 23, citing Engineering Dynamics, Inc. v.\nStructural Software, Inc., 26 F.3d 1335, 1348-49 (5th Cir. 1994). Incredibly, the Lotus\npetition fails to point out that following publication of its initial opinion, the Fifth Circuit\nwas deluged by requests for rehearing from software and semiconductor companies,\ncomputer scientists and user groups, and subsequently issued a supplemental opinion.\nThe Fifth Circuit limited its first decision to the facts of that case and specifically\n\ndisclaimed reliance on the rationale that underlies the district court's opinions at issue\nhere. Engineering Dynamics, Inc. v. Structural Software, Inc., 46 F.3d 408, 409 (5th Cir.\n1995). It is unfathomable that Lotus could assert that neither the Second Circuit nor the\nFifth, Ninth and Tenth Circuits \"has suggested that the central tenets of [the district\ncourt's] analysis have been anything but correct.\" Pet. at 22.\nIn short, there is simply no conflict among the circuits on the protection of menu\ncommands and similar methods used to operate computer programs. Furthermore, given\nthe subject matter that is really at issue in this case and the narrow basis of the First\nCircuit's opinion, virtually any comment by this Court on the copyrightability of code or\nprogram structure in a review of this case would be dicta. There are, on the other hand, a\nvariety of cases currently proceeding through the lower courts that directly address those\nissues (discussed in Section IC below).\nSTATEMENT OF THE CASE\nThere is good reason why the district court's opinions in this case generated such\nwidespread attention and controversy. In the usual software copyright case, the defendant\nis alleged to have copied either the text (\"code\") or structure of the plaintiff's computer\nprogram, or the way the plaintiff's program looks on the computer screen when it is\nexecuting. No such copying occurred here. Lotus did not even allege any copying of its\ncode or code structure, and even the district court found that the programs looked\ndifferent on the computer screen. Borland II, 799 F. Supp. at 220, Pet. App. at 137a.\nUsers operate the program at issue here through a series of commands--common English\nwords--arranged in hierarchies called \"menus.\" 49 F.3d at 809, Pet. App. at 4a. As the\nFirst Circuit opinion explains, the precise facts of this case are critical to its disposition.\nThe menu commands of the product at issue do not function as labels or explanations for\nany buttons or switches used to operate the program. Rather, the menu commands\nthemselves are used to operate the program in much the same way that the buttons on a\nvideo cassette recorder (VCR) operate that machine. While such utilitarian methods of\noperation are perhaps patentable under the patent laws, this is not a patent case since\nLotus obtained no patent on this or any other relevant aspect of Lotus 1-2-3.\nAs the First Circuit found, \"the entire Lotus menu command hierarchy is essential to\noperating\" the program. 49 F.3d at 815-16, Pet. App. at 15a-22a. If a user types \"COPY\"\nor \"C,\" the program copies. Typing \"PRINT\" or \"P\" causes the computer to print. Typing\nmore complex sequences of commands in the hierarchy executes other operations of the\nspreadsheet. There is other text attendant to a computer program--not copied by Borland-\n-that communicates with the user or that provides information to the user. Such text\nincludes books about the program, manuals, on-screen \"help\" text, and other textual\nmaterial that does not operate the computer. In contrast, the words of the Lotus menu\ncommand hierarchy are literally the method of operating the spreadsheet program. These\nlimiting facts are crucial to the disposition of this petition.\nA. Factual Background\n\n1. The Lotus Product\nThe development of the Lotus menu command hierarchy is well chronicled in the Lotus\npetition. According to the affidavit submitted with the petition8 the commands were\norganized \"hierarchically,\" and the manner depicted in a \"menu tree,\" so that \"the\nselection of one command option from the first level menu could lead in turn to another\narray of command options on a second level menu (or `submenu') and so on.\" Kapor Aff.\nat paras. 44-45, Pet. App. at 287a. The Lotus developer drew a firm line between the\nmenu choices in the hierarchy (the \"command options\") and the explanation of those\ncommand options. According to the affidavit, for example, the \"long prompts\" (or\n\"screen help\" text) are intended to provide \"information to the user\" and \"explanations,\"\nwhile the menu commands are directed toward \"performing a particular task.\" Kapor Aff.\nat paras. 44, 101, Pet. App. at 287a, 296a.\nAs set forth in great detail in the lower court record, the Lotus spreadsheet was a great\nsuccess, but that success had little to do with the menu command hierarchy. Rather, when\nthe IBM PC was introduced in August 1981, the Lotus developers, according to the\ndistrict court, \"exploited this opportunity\" by designing the technical aspects of their\nspreadsheet product to take advantage of the technological advances of the IBM PC over\npre- existing computers. Paperback, 740 F. Supp. at 65-66, Pet. App. at 231a.\nThe menu command hierarchy was simply not a qualitatively significant part of the\nproduct at the time of its introduction, either from Lotus' viewpoint or the viewpoint of\nusers.9 The exact words and order of the Lotus menu command hierarchy were not\nimportant to the product's initial success, but they became vitally important to the success\nof later versions of Lotus' product and spreadsheets offered by Lotus' competitors for two\nreasons. First, as Judge Boudin explains (and the record below demonstrates in detail),\nusers invested their own time, money and energy in learning the Lotus commands as\nkeystroke combinations to operate the spreadsheet, just as users operate a typewriter to\nproduce readable text by touch typing on the standard QWERTY keyboard. 49 F.3d at\n819-21, Pet. App. at 24a-26a. Second, as both the majority opinion and Judge Boudin\nexplain,10 users automate those steps by creating \"macros,\" computer programs written\nby users themselves.\nLotus' own documents and the record below demonstrate that while Lotus' product\ninitially became a success because it was technologically superior to its early\ncompetition, it later maintained its share because, as Judge Boudin noted, the user's\ninvestment in learning the method of operation of the Lotus product and the creation of\nmacros \"locked in\" those users who first selected Lotus over its inferior early\ncompetition.11 Therefore, unless a new entrant with a superior product in the spreadsheet\nmarket could compete for the business of the vast majority of computer users who\ninitially chose Lotus, competition would be limited solely to new spreadsheet users, a\nminor portion of the market. In short, there would be little, if any, business for which to\ncompete.\n2. The Borland Product\n\nThe Lotus petition attempts to dismiss Borland's product as a \"clone\" or imitator, but the\nrecord below demonstrates otherwise. The Borland product was first introduced in 1989\nand won every major award for spreadsheet excellence given in the software industry.\nThe Borland product invariably ranked higher than the Lotus product in head-to-head\nreviews and user comparisons, including those conducted by Lotus.12\nNot only was the Borland product superior from technological and performance\nperspectives, but it also employed a new screen display that was different in every respect\n(save the command words) from the Lotus products at issue in this case. See Borland S.J.\nBrief (Dkt. No. 141) at 116-34. The Borland product had its own menu command\nhierarchy designed specifically to take advantage of its superior technological features\nand a different screen display. But the Borland product also provided, as an alternative,\nan enhanced version of the Lotus menu command hierarchy so that users who were\nlocked into the earlier menus could operate the new product without relearning their\nspreadsheet skill set or rewriting their macros.13\nB. Proceedings in the District Court\nThroughout the proceedings below, the district court resisted every attempt Borland made\nto secure prompt appellate review of the district court's controversial extension of\ncopyright law. The district court's earlier Paperback decision had not been appealed\nbecause Lotus settled the case following the district court's ruling and the defendant went\nout of business.\nThe district court issued its first opinion in this case on March 20, 1992, indicating that it\nintended to continue to employ its widely criticized methodology from the Paperback\ncase. Borland I, 788 F. Supp. at 89-90, Pet. App. at 163a. On July 31, 1992, the district\ncourt published its Borland II decision and an accompanying procedural order holding\nthat \"[t]he menu commands and menu hierarchy of Lotus 1-2-3 have expressive aspects\nand are copyrightable.\" Order Regulating Jury Trial, finalized Sept. 30, 1992 (Dkt. No.\n232), at 18. However, the district court said that it could not determine the \"precise scope\nof Borland's infringement\" without further trial proceedings, Borland II, 799 F. Supp. at\n221, Pet. App. at 138a, and set a trial to begin on November 2, 1992.\nImmediately following the district court's Borland II decision, Borland pulled the Lotus\nmenus from its products. On three separate occasions, Borland moved to certify for\ninterlocutory appeal the question of the menu command hierarchy's copyrightability.\nHowever, the district court denied all three of Borland's motions, greatly extending the\nproceedings.14 Ultimately, Borland argued in favor of enjoining its own product so that\nappellate review would be available pursuant to the injunction statute, 28 U.S.C. sect.\n1292(a). On August 19, 1993, the district court entered a permanent injunction against the\ncontinued sale of Borland's product and an appeal was promptly taken to the First Circuit.\nThe district court refused to stay either damages discovery or a damages trial pending the\nFirst Circuit's decision on liability. As a result, the damages phase of the case, which was\neventually terminated by the First Circuit's reversal, cost Borland millions of dollars in\n\nlegal and expert fees. Although the district court was eventually reversed, the series of\ndistrict court opinions, followed by the entry of a permanent injunction, had a devastating\neffect on Borland. For example, as the record below reflects, Borland's stock, which\ntraded at 86- in January, 1992, prior to the first of the district court's opinions in the case,\nfell to 12- in September 1993, following entry of the injunction. Borland was required of\nfinancial necessity to sell its spreadsheet products to another company and is no longer a\ncompetitor of Lotus, which is now owned by International Business Machines Corp.\n(IBM). Any further appellate proceedings, even if successful from Borland's legal\nviewpoint, can be exploited by IBM to further damage Borland competitively.\nREASONS FOR DENYING THE PETITION\nI. THE CIRCUITS ARE IN AGREEMENT THAT WORDS USED AS BUTTONS TO\nOPERATE A PROGRAM, UNLIKE THE PROGRAM ITSELF, ARE\nUNCOPYRIGHTABLE.\nA. The District Court Erroneously Applied the \"Abstractions\" Test to Uncopyrightable\nSubject Matter.\nThe Lotus petition attempts to inject this case into the ongoing debate in the case law\ninvolving the extent to which the \"structure\" of a computer program should be protected\nby copyright. But extending copyright protection to menus and similar methods of\noperation has far greater legal and economic consequences than extending copyright to\nthe structure of a computer program. The legal argument that at least some aspects of a\nprogram's structure might be copyrightable is a familiar one. A computer program, as\ndefined in 17 U.S.C. sect. 101 (a \"set of instructions\" used \"to bring about a certain\nresult\"), is a \"literary work.\" The literal elements of the program, the source code and\nobject code, are copyrightable in the same way that the literal text of a play would be.\nWithin the genre of artistic literary works like plays, courts have created the\n\"paraphrasing\" doctrine, see Pet. at 10, also known as the concept of \"comprehensive\nnon-literal similarity,\" as a basis for copyright infringement. See David Nimmer &\nMelville B. Nimmer, Nimmer on Copyright, sect. 13.03[A][1] at 13-29 (1994). If, for\nexample, someone made an unauthorized translation into French of a play originally\nwritten in English, the authors would have a claim for copyright infringement,\nnotwithstanding the fact that the original work (in English) and the unauthorized \"copy\"\n(in French) do not share any common literal expression. They are not substantially\nsimilar in terms of literal expression, but they are similar with respect to the \"structure\" of\nthe play, each of its acts, each of its scenes, and, for that matter, the breakdown of the\ndialogue into sentences.\nBecause Congress decided to apply copyright protection to the code of a computer\nprogram (the \"set of instructions\"), one might argue (as Lotus does) that copyright\ndoctrines for artistic literary works should apply to some extent to the code of a computer\nprogram, which is also a literary work. See, e.g., Whelan Assoc., Inc. v. Jaslow Dental\nLaboratory, Inc., 797 F.2d 1222, 1233-34 (3d Cir. 1986), cert. denied, 479 U.S. 1031\n\n(1987). Thus, if a programmer writes a program in \"BASIC\" and someone \"translates\"\nthat program into the programming language \"C,\" the second program is an unauthorized\ncopy notwithstanding the absence of literal similarity at the code level. The two programs\nare \"substantially similar\" with respect to their detailed \"structure.\" Hence, a few courts\ninitially applied the doctrine of \"comprehensive non-literal similarity\" to protect the\n\"structure, sequence and organization\" of a computer program, at least to some limited\nextent. See, e.g., Altai, 982 F.2d at 702-04 (citing cases).\nBut application of the concept of \"comprehensive non- literal similarity\" to computer\nprograms has been controversial because, unlike artistic works (such as plays), computer\nprograms are utilitarian objects--they perform a function.15 Copyright, unlike patent, is a\nvery broad, long-lasting, easily obtainable type of protection, and Congress has always\ntaken care to ensure that easily obtainable copyright protection would not be available for\nthe utilitarian or functional aspects of works.16 As Professor Miller, formerly a member\nof CONTU, stated:\nThe end purpose of a computer program is to achieve a utilitarian result, i.e., the\ncomputer's performance of logical operations in a way that produces the desired practical\nconsequence. One cannot compare, therefore, the underlying processes of a computer\nprogram with, say, the underlying plot structure of a novel or a screenplay of a movie.\nThis, of course, is the distinction recognized by the Supreme Court long ago in the\nseminal decision of Baker v. Selden, 101 U.S. 99 (1879).\nKenneth A. Liebman, et al., Back To Basics: A Critique Of The Emerging Judicial\nAnalysis Of The Outer Limits Of Computer Program \"Expression,\" 2 Computer Law.,\nDecember 1985 at 1, 8 (quoting Arthur Miller). Professor Miller, now Lotus' counsel,\nsummarized this concern best when he opined in a declaration in another case: \"The\ncreativity, ideas and utilitarian aspects of a copyrighted work must look elsewhere for\nlegal protection.\"17\nThe earliest attempt to apply \"non-literal similarity\" to computer programs, the Third\nCircuit's Whelan decision, resulted in protection for virtually all of the program's\nstructure. Whelan, 797 F.2d at 1238. The Second Circuit in Altai rejected the Whelan test\nbecause the Whelan test made too much copyrightable. Altai, 982 F.2d at 705-06. Under\nthe Whelan test, the \"function\" of the computer program is the work's protectable idea,\nand \"everything that is not necessary to that purpose or function would be part of the\n[protectable] expression of the idea.\" Whelan, 797 F.2d at 1236. Under the \"abstractions\"\ntest formulated by the Altai court, far fewer aspects of code structure are protected by\ncopyright. The leading post-Altai decision, the Tenth Circuit's Gates Rubber case, limited\nthe protection of code structure even further by requiring the lower courts specifically to\nconsider the proscriptions of sect. 102(b) in applying the abstractions and filtrations\nformulations. Gates Rubber, 9 F.3d at 833, 836.\nThe test formulated by the district court in this case was based on Whelan rather than\nAltai, and, for that reason, the Altai court rejected the lower court's approach as having a\n\"corrosive effect on certain fundamental tenets of copyright doctrine.\" Altai, 982 F.2d at\n712. More germane for the purposes of Lotus' petition is the fact that the district court\n\nsought to apply an abstractions-type analysis to a menu command hierarchy which,\nunlike a \"computer program,\" is not copyrightable in the first place. Borland II, 799 F.\nSupp. at 216-19, Pet. App. at 128a- 135a.\nThe \"abstractions\" test was initially applied to the text of plays--clearly copyrightable\nsubject matter. Similarly, the leading cases cited by Lotus--Whelan, Altai and Gates\nRubber--apply the abstractions test to the code of \"computer programs\" which Congress\nexpressly has said is copyrightable. By contrast, the district court here applied its own\nvariant of the abstractions test to the method of operating the program, the menu\ncommands. The Lotus petition deftly slides over this critical distinction. Compare Pet. at\n14-16 (describing the application of the test by various courts of appeals to the\n\"program\") with Pet. at 17 (discussing the district court's application of the test to so-\ncalled non-literal elements).\nAs the First Circuit opinion points out, the abstractions test assumes that the work at issue\nis copyrightable. 49 F.3d at 815, Pet. App. at 14a. Application of the \"abstractions\" test to\nthe menu command hierarchy inevitably led the district court to find something in the\nmenu command hierarchy copyrightable, id., and the district court concluded that the\nspecific commands and order chosen by Lotus were protected by copyright. Borland II,\n799 F. Supp. at 217, Pet. App. at 131a. In other words, as the First Circuit explained, the\ndistrict court's test devolved to a question of whether choices exist for the subject matter\nat issue. 49 F.3d at 811, 816, Pet. App. at 6a, 17a. Under the district court's methodology,\nif there are choices, the subject matter at issue is copyrightable. But the mere existence of\na choice does not turn uncopyrightable subject matter into copyrightable \"expression.\"\nOne might equally argue that the engines of a Ferrari and a Volkswagen embody different\n\"expressions\" of the process of internal combustion, or that the QWERTY and Dvorak\nkeyboards are different ways of \"expressing\" the means by which the user operates a\ntypewriter.\nLotus responds to this reasoning by arguing that \"computer programs,\" unlike car engines\nand keyboards, are copyrightable. Pet. at 29. Had the district court applied its abstractions\ntest to the computer program, Lotus' argument would be germane. But the district court\napplied its test to the menu command hierarchy, not to the program. Borland II, 799 F.\nSupp. at 216-19, Pet. App. at 128a-135a.\nHad the district court applied an abstractions test to the programs at issue, it would have\nquickly found no code or \"structural\" similarity on any level whatsoever--nonliteral or\notherwise. Indeed, there was no allegation in this case that Borland copied or even had\naccess to the \"structure\" of the Lotus program. Lotus did not produce its code in\ndiscovery, neither party introduced the code of its program into evidence at trial, and\nthere is every reason to believe that the Lotus program and the Borland program have\nvastly different structures to perform the same functions. In short, even after application\nof the \"abstractions\" test to the program, the district court would still be faced with the\nissue of whether the menu commands are copyrightable. That issue can only be resolved\nby reference to the statute and case law dealing with utilitarian works. In any event, the\nissues of nonliteral similarity and copyrightability of code structure could not properly be\n\nreviewed by this Court in this case, since the narrow issue present here does not raise\nthose broader issues.\nB. The District Court's Decision to Extend Copyright to the Words That Operate the\nProgram Ran Afoul of Both the Statute and the Case Law.\nThe First Circuit's reversal of the district court rests on the familiar language of sect.\n102(b):\nIn no case does copyright protection for an original work of authorship extend to any\nidea, procedure, process, system, method of operation, concept, principle, or discovery,\nregardless of the form in which it is described, explained, illustrated, or embodied in such\nwork.\nAlthough the Lotus petition at one point claims that the First Circuit's opinion rejected\nthe idea/expression dichotomy, Pet. at 23, the earlier discussion in the Lotus petition\ncorrectly points out that sect. 102(b) is, in fact, the legislative embodiment of the\nidea/expression dichotomy. Pet. at 10. In short, the First Circuit embraced the\ndemarcation in sect. 102(b) between copyrightable subject matter and uncopyrightable\n\"methods of operation,\" \"systems,\" and \"ideas\" which must look to patent law for\nprotection. It was the district court that altered that fundamental demarcation. The First\nCircuit merely followed the \"line\" between copyrightable and uncopyrightable subject\nmatter previously established by Congress and this Court in Baker v. Selden.\nConfronted with the plain language of sect. 102(b) proscribing copyright protection for\nmethods of operation, the district court limited the statute to abstractions. In the view of\nthe district court, whenever any words are attached to sect. 102(b) subject matter (such as\n\"processes\" or \"methods of operation\"), the words become copyrightable. See Borland I,\n788 F. Supp. at 91, Pet. App. at 167a; 49 F.3d at 816, Pet. App. at 17a. As the First\nCircuit pointed out, limiting uncopyrightable sect. 102(b) subject matter to abstractions\nmoves the line established long ago in Baker v. Selden between copyrightable and\nuncopyrightable subject matter. For more than 100 years, until the district court's opinion,\ncopyright law was grounded on the proposition that the barest words that state a system\nor operate a machine (e.g., \"move,\" \"copy\"), as opposed to a description of those\noperations (e.g., the long prompts) are uncopyrightable. The district court's opinions\nmoved the \"line\" between copyrightable and uncopyrightable subject matter established\nin Baker v. Selden, and that is what produced the enormous public outcry.\nIn Baker, the plaintiff, Charles Selden, obtained a copyright on a pamphlet that explained\na systematic approach to bookkeeping. The pamphlet contained a complex series of\nledgers or forms, like the various screen displays in the Lotus user interface. The Selden\nforms each contained grids, columns, and various alternative short textual descriptive\n\"headings\" or \"captions\" (such as \"Balance Forward\") like the Lotus menu commands.\nThe defendant, Baker, published forms similar in headings and arrangement to those of\nSelden. Selden sued Baker for copyright infringement because of the similarity, arguing--\nas Lotus argues here--that there was \"original expression\" in the selection, ordering and\n\narrangement of the headings and columns of the ledgers each contained in his\ncopyrighted pamphlet. See Baker v. Selden, 101 U.S. at 101.\nManifestly, since the words on Baker's forms were different from those on Selden's, this\nCourt could have found for Baker solely on the ground that the textual labels were not\nsubstantially similar. But this Court did not take that route. Stating the principal issue in\nthe case as whether Baker could use \"similar ruled lines and headings, or ruled lines and\nheadings made and arranged on substantially the same system, without violating\n[Selden's] copyright,\" id., at 101, this Court held that Selden's ledgers, including their\ncolumn arrangement and textual headings, were not copyrightable at all--and could be\ncopied verbatim. Id. at 107.\nAs the Altai court observed, 982 F.2d at 704, the holding of Baker that methods of\noperations and systems are not copyrightable is not restricted to pure abstractions:\n[T]he holding in Baker goes farther. The [Supreme] Court concluded that those aspects of\na work, which \"must necessarily be used as incident to\" the idea, system or process that\nthe work describes, are also not copyrightable. 101 U.S. at 104.\nThe First Circuit relied upon Baker in the same manner as did Altai. It relied upon\nBaker's limitations on the scope of copyright to conclude that the commands used to\noperate the Lotus program were not copyrightable. 49 F.3d at 816-17, Pet. App. at 18a.\nIndeed, the district court's limitation on sect. 102(b) not only ran afoul of Baker v. Selden\nbut was also at variance with the unique facts of this case. Here, as the First Circuit\nexplained, the words at issue are more fundamental to the operation of the program than\neven labels on buttons would be. 49 F.3d at 817, Pet. App. at 18a-19a. Here, the words of\nthe menu command hierarchy are \"essential to operating\" the program and, hence, are\npart of the method of operation. Id. at 18a. As the First Circuit explained, \"it would be\nimpossible to operate [the Lotus program] without employing its menu command\nhierarchy.\" Id. at 19a. The holding of the First Circuit, narrowly tailored to the facts\nbefore it, is wholly consistent with similar cases in other circuits.\nC. There Is No Conflict Among the Circuits That Menu Commands and Similar Methods\nof Operation Are Uncopyrightable.\nLotus argues that the First Circuit's reasoning is contrary to the law in other circuits, and\nthat review of this case is needed to resolve a conflict in the circuits. To the contrary,\nthere is no such conflict on the narrow issue actually presented here.\n1. The Ninth Circuit. Lotus cites two cases for an alleged conflict between the First and\nNinth Circuits. First, Johnson Controls, Inc. v. Phoenix Control Sys., Inc., 886 F.2d 1173,\n1175-76 (9th Cir. 1989), is a code structure case and not pertinent here at all. Second,\nLotus relies upon Brown Bag Software v. Symantec Corp., 960 F.2d 1465, 1477 (9th\nCir.), cert. denied sub. nom. BB Asset Mgmt. Inc. v. Symantec Corp., 113 S.Ct. 198\n(1992), as allegedly creating a conflict. This is misplaced. That Ninth Circuit opinion\nspecifically affirmed the lower court's holding that the menus at issue were\n\"unprotectable under copyright.\" Id. at 1472. (While there is ambiguous dicta elsewhere\n\nin Brown Bag which Lotus cites for the proposition that \"menus and keystrokes\" are\ncopyrightable, which the First Circuit also noted, see 49 F.3d at 819 n.14, Pet. App. at\n22a n.14, that dicta does not alter the Ninth Circuit's ultimate opinion.)\nIn fact, a prior Ninth Circuit decision--not cited by Lotus-- explicitly held that the menu\ncommands of a spreadsheet software product were uncopyrightable. Ashton-Tate Corp. v.\nRoss, 916 F.2d 516 (9th Cir. 1990). In Ross, the plaintiff alleged that he had designed and\ngiven Ashton-Tate a complete menu hierarchy, including numerous submenus, which\nAshton-Tate incorporated into its \"Full Impact\" spreadsheet product without\ncompensating him. Unlike this case, Ross' list was handwritten, and had been developed\nbefore any computer code was written. However, like the Lotus 1-2-3 menu tree, Ross'\ntree contained both main menus and submenus. (A copy of Ross' actual menu hierarchy\nwas included in the district court record in this case. See Borland II, 799 F. Supp. at 220,\nPet. App. at 136a.)\nThe Ashton-Tate district court ruled against Ross, finding that he was not entitled to\ncompensation because the spreadsheet menu hierarchy was not entitled to copyright\nprotection. Citing 17 U.S.C. sect. 102(b), the District Court held that Ross' \"list of labels\nfor user commands . . . is not protected under federal law.\" Ashton-Tate Corp. v. Ross,\n728 F. Supp. 597, 602 (N.D. Cal. 1989). On appeal, Ross renewed his argument, the very\nsame argument to justify copyrightability (i.e.. the presence of choices) advanced by the\ndistrict court here. Ross argued that his menu command hierarchy evidenced\nnumerous decisions by the authors about the ordering of the commands and their\narrangement in the user interface. The fact that the authors of these design documents\nchose the order and groupings displayed, out of a nearly infinite number of possibilities,\nconstitutes creative authorship. Appellants' [Ross'] Opening Brief on Appeal at 25, 1st\nCir. App. 1168. The Ninth Circuit confronted this argument directly and rejected it,\nstating that \"[t]his argument is meritless for the reasons given in the district court's order,\n728 F. Supp. at 602. The list simply does not qualify for copyright protection.\" 916 F.2d\nat 521-22.\nLotus does not mention Ashton-Tate, perhaps because the district court explicitly\ndeclined to follow it. Borland II, 799 F. Supp. at 220, Pet. App. at 136a. By reversing the\ndistrict court and agreeing with Ashton-Tate's conclusion, the First Circuit removed any\nconflict with the Ninth Circuit, rather than creating one.\n2. The Tenth Circuit. Lotus argues, and the First Circuit suggested, that the court's\nholding was in conflict with dicta in a footnote in Autoskill, Inc. v. National Educ.\nSupport Sys., Inc., 994 F.2d 1476, 1495 n.23 (10th Cir.), cert. denied, 114 U.S. 307\n(1993). A careful examination of Autoskill and subsequent Tenth Circuit authority\nreveals that there is no such conflict worthy of review at this time. Footnote 23 in\nAutoskill appears to hold that, for the purposes of a preliminary injunction, the district\ncourt did not improperly enjoin a computer program where a student/user selected\nresponses to the program's queries \"by pressing the 1, 2, or 3 keys.\" 994 F.2d at 1495\n\nn.23. The First Circuit noted this dicta and declined to \"follow\" the reasoning of this\nfootnote. 49 F.3d at 813, 818-19, Pet. App. at 12a, 21a-22a.\nTo the extent that the Autoskill footnote bears on the issues of copyrightability of menus\nand was rejected by the First Circuit, it had already been rejected by the Tenth Circuit\nitself. In Gates Rubber, 9 F.3d 823, the Tenth Circuit limited its prior holding in Autoskill\nbecause that case only involved the review of a preliminary injunction order. Id. at 841.\nThe Tenth Circuit vacated the Gates Rubber district court's finding that computer menus\nwere copyrightable, and remanded the case to that district court for further consideration\nand analysis under the appropriate legal standards. Id. at 843-44.\nThe uncopyrightability of computer menus in the Tenth Circuit was confirmed by the\nvery recent decision by the Gates Rubber district court, after the Tenth Circuit's remand.\nGates Rubber Co. v. Bando Chem. Indus., Ltd., No. 92-S-136 (D. Colo. filed June 12,\n1995). Using the analysis ordered by the Tenth Circuit, the District of Colorado found\nthat the menus of that program were uncopyrightable. Slip op. at 6-7. It saw no conflict\namong the circuits. To the contrary, the Colorado court approvingly cited the First\nCircuit's opinion in Lotus v. Borland without noting any conflict. Id. at 7. To the extent\nthat Gates Rubber still poses any issues worthy of review, this Court can ultimately grant\nreview of that case.18\n3. The Fifth Circuit. Lotus also relies upon Engineering Dynamics, 26 F.3d 1335 (5th Cir.\n1994), supplemented on pet. for reh'g, 46 F.3d 408 (5th Cir. 1995). Initially, Engineering\nDynamics was the only court of appeals case which, like the district court opinions here,\npurported to apply an \"abstractions\"-like test directly to a \"non-literal element.\" That\nparticular non-literal element was the input formats to the computer program, and not a\nmethod of operating the program. Therefore, sect. 102(b) did not play any role in the\ncourt's decision. Indeed, the court did not base its reasoning on any analysis of sect.\n102(b) or of methods of operation.\nAs discussed above, following the publication of the original opinion in Engineering\nDynamics, the Fifth Circuit was deluged with requests for rehearing. It issued a\nsupplemental opinion (not cited by Lotus) which greatly if not completely undercuts\nLotus' arguments. The Fifth Circuit's supplemental opinion rejected the assertion that it\nprotected the user formats in that case because there were \"numerous ways the input\nformats could be organized.\" It instead stated that \"[t]he panel did not say that in any case\ninvolving user interface the fact that the `author' has selected from among possible\nformats is dispositive.\" 46 F.3d at 409. This is consistent with the First Circuit's views on\none of the issues in dispute here, namely whether the availability of \"expressive choices\"\nin designing the menu command hierarchy makes the menus copyrightable. See 49 F.3d\nat 816, Pet. App. at 17a. Significantly, since the Fifth Circuit remanded that case for\nfurther proceedings, this Court can eventually review Engineering Dynamics if those\nproceedings result in any real conflict with the First Circuit.\n4. The Second and Third Circuits. Finally, Lotus argues that this case conflicts with the\nSecond and Third Circuit opinions in Altai and Whelan. As explained above, those cases\n\ninvolved the non-literal copying of code structure, rather than the \"method of operation\"\nissues involved here, and hence do not conflict with the narrow issues presented by this\ncase. Moreover, Lotus is incorrect that the First Circuit \"rejected\" Altai's abstraction-\nfiltration-comparison test. The First Circuit did not reject Altai; to the contrary, it held\nthat \"the Altai test may provide a useful framework for assessing the alleged nonliteral\ncopying of computer code.\" 49 F.3d at 815, Pet. App. at 14a. That issue is not present\nhere, and could not properly be dealt with by this Court upon review. Finally, while Altai\nand numerous other courts have harshly criticized Whelan, see 982 F.2d at 705-06, that\nhardly makes this a suitable case to review the viability of Whelan. Indeed, since Altai is\nstill pending before the Second Circuit, this Court can grant review of that case to address\nthe Altai/Whelan debate.\nII. THE FIRST CIRCUIT OPINION REMOVES THE UNCERTAINTY PRODUCED\nBY THE DISTRICT COURT AND UPHOLDS THE OVERALL INTELLECTUAL\nPROPERTY FRAMEWORK ESTABLISHED BY CONGRESS.\nA. The First Circuit Opinion Restores Clarity and Predictability to the Law.\nIn the First Circuit, many of Borland's amici urged reversal of the district court because\nof the uncertainty created by the district court's methodology and result. It is ironic in the\nextreme that Lotus would now petition this Court, claiming it is the First Circuit's\ndecision that has produced uncertainty. Software developers obviously need clear rules to\nenhance productivity. Prior to the district court's decisions, developers and their counsel,\nrelying on sect. 102(b), Baker v. Selden and Ashton- Tate v. Ross, believed that menu\ncommands and similar methods of operating a program were uncopyrightable. The First\nCircuit has now restored that clarity.\nThe alternative offered by Lotus, a case-by-case determination of whether sect. 102(b)\nmeans what it says, would have a chilling effect on software development. One need look\nno further than the facts of this case to understand the grave difficulties such a regime\nwould portend. Here, two years, two opinions, hundreds of pages, and millions of dollars\ninto this case, the district court could still not determine the \"precise scope of Borland's\ninfringement,\" Borland II, 799 F. Supp. at 221, Pet. App. at 138a, without another year\nand one-half of proceedings. Under the regime proposed by Lotus, new and better\nproducts that compete for the business of a competitor's customers can be brought to\nmarket legally only at the cost of one's company. In rejecting such a regime, the First\nCircuit has restored clarity to at least a portion of the overall intellectual property\nprotection framework established by Congress. Equally important is the fact that the First\nCircuit's opinion restores the long-standing demarcation between copyright and patent\nlaw.\nCopyright is broad, long-lasting, easily obtainable protection. Copyright protection is\nobtained for copyrightable elements of a computer program merely by making a deposit\nof any copyrightable subject matter (such as code). See Copyright Office Circular 61,\nCopyright Registration for Computer Programs, at 2, 1st Cir. App. 1170. There is no\nexamination procedure. The copyright lasts for approximately 75 years. Because\n\ncopyright protection is so easy to obtain, and lasts so long, it was neither intended for, nor\nis it suited for, the granting of government-sanctioned monopolies for methods of\noperation. See, e.g., Goldstein Treatise, sect. 2.3.1 at 78, sect. 2.15.2 at 207; Paul\nGoldstein, Infringement of Copyright in Computer Programs, 47 U. Pitt. L. Rev. 1119,\n1123-24 (1986). The monopoly on a menu command hierarchy or similar \"method of\noperation\" has far greater ramifications than even the monopoly on the \"structure\" of a\nprogram. Protecting code structure has no preclusive effect on the program's users.\nHowever, precluding a competitor's product from offering another's method of operation\nmeans that users will lose their investment in the skill set necessary to implement that\nmethod of operation if they switch to a competitor's product. 49 F.3d at 821, Pet. App. at\n26a-27a.\nSuch a broad government-sanctioned monopoly must be secured, if at all, through the\npatent system. Patents on \"methods of operation\" are difficult to obtain and last a\nrelatively short period of time (20 years or less). Patent applications must state the\ninvention, describe the prior art, and set forth the claims for protection clearly and\nspecifically. There is a complex examination process to ensure that the patentee will be\ncontributing something new to the state-of-the-art (i.e., something novel and non-\nobvious, an advancement over the prior art, etc.), as the quid pro quo for the grant of\nmonopoly. None of these safeguards are present in the copyright system established by\nCongress because it was (and is) not contemplated that the scope of copyright protection\nis tantamount to that of patent. Unless sect. 102(b) is recognized for what Congress\nintended it to be, the copyright law would afford over-extensive protection to works by\napplying only the most minimal level of scrutiny. The First Circuit's opinion is consistent\nwith the intellectual property framework established by Congress and supports its\nrationale.\nIn short, Lotus lost this case because it tried to secure patent-type protection without\nsatisfying the patent requirements of novelty, examination and contribution to the prior\nart. If, like the plaintiff in Baker v. Selden, Lotus cannot meet these requirements, or if it\nchooses not even to try, it should not be able to claim the same scope of protection\nthrough copyright law. That, as the Baker Court observed, \"would be a surprise and a\nfraud upon the public. That is the province of letters-patent not of copyright.\" 101 U.S. at\n102.\nB. Both Copyright and Patent Remain Sources of Strong Protection, Providing Enormous\nIncentives for Authors and Inventors of Software Products to Innovate.\nLotus' suggestion that the First Circuit's ruling \"could serve to roll back the scope of\nprotection for computer programs generally,\" Pet. at 29, is wholly unfounded. Copyright\nprotection remains a powerful and sufficient incentive for the development of new\nsoftware. Copyright protects against piratical copying of object code. Copyright protects\nagainst appropriation of source code, either literally or by paraphrasing. Perhaps, in\nappropriate circumstances, copyright also protects against copying the detailed\n\"structure\" of another's program.\n\nNor does the First Circuit's opinion call into question the screen display portion of a \"user\ninterface.\" Compare Pet. at 28. As the Altai court observed, copyright protection for\nscreen displays does not depend on the protection of \"non-literal elements\" of the\ncomputer program. Rather, copyright protects against the unauthorized reproduction of\n\"certain types of screen displays,\" that are \"copyrighted separately as an audiovisual\nwork.\" Altai, 982 F.2d at 703. The First Circuit did not even remotely suggest that screen\ndisplays are uncopyrightable. Rather, its holding that menu commands are\nuncopyrightable does not interfere with the protection of screen displays \"because the\nway the screens look has little bearing on how users control the program.\" 49 F.3d at 816\n& n.10, Pet. App. at 16a.\nMenu commands and similar methods of operating the program continue to be protected\nby the patent law, as they always have been. The record below contains several examples\nof menu command hierarchies, including those of IBM (Lotus' new owner) that are\nprotected by utility patents. Borland S.J. Brief, Exs. 16 & 23 (U.S. Patents Nos.\n4,989,141, 4,611,306). Indeed, the U.S. Patent and Trademark Office has recently\nannounced it is changing the rules for patentability of software, making it even easier to\nobtain software patents.19\nCONCLUSION\nThis Court has made it clear that only Congress may redraw the balance between private\nmonopoly and public access. The courts are required to defer to Congress \"when major\ntechnological innovations alter the market for copyrighted materials.\" Sony Corp. v.\nUniversal City Studios, Inc., 464 U.S. 417, 431 (1984). If Congress has not expressly\nchosen to expand the scope of copyright protection, it is not the job of the courts to do so.\nOn the contrary, \"[i]n a case like this, in which Congress has not plainly marked our\ncourse, we must be circumspect in construing the scope of rights created by a legislative\nenactment which never contemplated such a calculus of interests.\" Id. The district court\nin this case plainly thought that it was empowered to create new law in \"uncharted\"\nterritory and to \"draw the line between copyrightable and non-copyrightable elements of\ncomputer programs.\" Borland I, 788 F. Supp. at 90, Pet. App. at 165a; Paperback, 740 F.\nSupp. at 53, Pet. App. at 206a. In so doing, the district court usurped the role of Congress.\nThe First Circuit corrected this error.\nTwenty years ago, the first personal computers had no screens or keyboards; the users\noperated the machines by pressing buttons or switches on the front of the machines. No\none would ever claim that such buttons were copyrightable. Twenty years from now,\nusers will operate personal computers with spoken words, and without any physical\nbuttons or keyboards. It is inconceivable that anyone could claim that such spoken\nmethods of operation will be copyrightable. At the intermediate stage of technology\nrelevant here, Lotus used typed words as the buttons or switches to operate its\nspreadsheet program. Those words are no more copyrightable than physical buttons were\ntwenty years ago, or than spoken commands will be twenty years from now.\nFor the foregoing reasons, the petition for a writ of certiorari should be denied.\n\nRespectfully submitted,\nGary L. Reback\n(Counsel of Record)\nMichael Barclay\nIsabella E. Fu\nWilson, Sonsini, Goodrich & Rosati Professional Corporation\n650 Page Mill Road\nPalo Alto, California 94304\nTelephone: (415) 493-9300\nPeter E. Gelhaar\nKatherine L. Parks\nDonnelly, Conroy & Gelhaar\nOne Post Office Square\n33rd Floor\nBoston, Massachusetts 02109\nTelephone: (617) 542-7400\nAttorneys for Respondent\nJuly 1995\n******FOOTNOTES******\n1 See Lotus Dev. Corp. v. Borland Int'l, Inc., 788 F. Supp. 78 (D. Mass. 1992) (\"Borland\nI\"), Pet. App. at 145a; Lotus Dev. Corp. v. Borland Int'l, Inc., 799 F. Supp. 203 (D. Mass.\n1992) (\"Borland II\"), Pet. App. at 106a; Lotus Dev. Corp. v. Borland Int'l, Inc., 831 F.\nSupp. 202 (D. Mass. 1993) (\"Borland III\"), Pet. App. at 71a; Lotus Dev. Corp. v. Borland\nInt'l, Inc., 831 F. Supp. 223 (D. Mass. 1993) (\"Borland IV\"), Pet. App. at 29a. Each of\nthese opinions refers to and is based upon an earlier decision of the district court, Lotus\nDev. Corp. v. Paperback Software Int'l, 740 F. Supp. 37 (D. Mass. 1990) (\"Paperback\"),\nPet. App. at 183a, which decision was not appealed.\n2 See, e.g., Steven W. Lundberg et al., Identifying Uncopyrightable Computer\nImplemented Processes and Systems, 9 Computer Law., Apr. 1992, at 7, 9 (\"the Court in\nLotus [v. Paperback] could never have reached the correct conclusion since it never laid\nthe fundamental groundwork for it\"); Timothy S. Teter, Note, Merger and the Machines:\nAn Analysis of the Pro-Compatibility Trend in Computer Software Copyright Cases, 45\nStan. L. Rev. 1061 (1993); Pamela Samuelson, Computer Programs, User Interfaces, and\nSection 102(b) of the Copyright Act of 1976: A Critique of Lotus v. Paperback, 55 Law\n& Contemp. Probs., Spring 1992, at 311, 352-53; Karen S. Kovach, Comment, Computer\nSoftware Design; User Interface--Idea or Expression? 60 U. Cin. L. Rev. 161 (1991)\n(Paperback improperly extended copyright protection to Lotus' menu command system);\nJulian Velasco, The Copyrightability of Nonliteral Elements of Computer Programs, 94\nColumbia L.Rev. 242, 262-65 (1994). These authorities are cited in Borland's Petition for\n\nInitial In Banc Hearing, filed with the First Circuit on November 10, 1993 (\"Borland's In\nBanc Brief\"), at 2 n.9.\n3 See, e.g., Susan Kostal, Copyright Scholars Want a Fine Point Put on Spreadsheet Case,\nS.F. Daily J., Oct. 4, 1991, at 1, 8; Lotus Wins Copyright Suit, Mass. Law. Wkly., Aug.\n10, 1992, at 23. See Borland's In Banc Brief at 3 n.10.\n4 See, e.g., Borland Gains in Bid For Appeals Ruling On Lotus Copyrights, Wall. St. J.,\nAug. 20, 1993, at B3; William M. Bulkeley, Borland Case Briefs Raise Questions About\nSoftware Copyright Protection, Wall. St. J., Oct. 4, 1991, at B4; William M. Bulkeley,\nBorland Loses Infringement Claim by Lotus, Wall St. J., Aug. 13, 1993, at B5; T.R. Reid,\nConsumers Lose When Software Makers Sue Each Other, Wash. Post, Oct. 25, 1993, at\nF18; John R. Wilke, Ruling Against Borland May Intensify Copyright Debate, Wall. St.\nJ., August 3, 1992, at B1, B4. See Borland's In Banc Brief at 3 n.11.\n5 Heather Clancy, Copyright laws blurred, Computer Reseller News, Aug. 17, 1992, at\n137; Peter Coffee, Key Reader verdict shows need for open standards, PC Week, Aug.\n30, 1993, at 32; Ed Foster, That's a nice macro you wrote. Too bad Lotus now owns it,\nInfoWorld, Aug. 23, 1993, at 45; Ed Foster, Too-tight legal controls can straightjacket a\nwhole industry, InfoWorld, Sept. 6, 1993, at 49; Beth Freedman, Experts Question Ruling\nIn Lotus-Borland Case, PC Week, Aug. 10, 1992, at 6; Steve Gibson, Lotus ruling will\ndamage the industry if it protects languages, InfoWorld, Sept. 14, 1992, at 42. See\nBorland's In Banc Brief at 3 n.12.\n6 See the following: Brief Amicus Curiae of Computer Software Industry Association,\nrepresenting over 3000 companies and professional individuals; Brief of Amicus Curiae\nSoftware Entrepreneurs' Forum, representing over 1000 independent software developers,\nconsultants and software providers; Amicus Brief of 81 Distinguished Computer\nScientists; Brief of Amicus Curiae (PC User Groups), representing over 16,500\nindividual and corporate PC users, including Fortune 500 companies; Brief of Amicus\nCuriae of American Committee for Interoperable Systems (including members such as\nSun Microsystems, Tandem Computers and AT&T Global Information Solutions); Two\nBriefs Amicus Curiae on behalf of 25 Distinguished Copyright Law Professors; and Brief\nof Amicus Curiae on behalf of the Register of Copyrights.\n7 It is true, of course, that a computer program might be described as a \"method of\noperating\" the computer and, as a consequence, Congress was required to expressly\ninclude \"computer programs\" in the copyright statute to ensure that computer programs\nwould be copyrightable. But Congress did not amend the copyright statute to make menu\ncommands, buttons, switches, and similar methods of operating a program copyrightable.\nOn the contrary, sect. 102(b) of the Copyright Act plainly states that \"methods of\noperation\" are uncopyrightable. Lotus would have the courts make law that contradicts\nthe express language of the statute.\n8 It should be noted that the Kapor Affidavit was not prepared in support of Lotus'\nposition in the Borland case. Rather, the affidavit was prepared for Lotus in the earlier\n\nPaperback case in which the defendant copied Lotus' entire screen display, not merely the\ncommand words. Subsequent to the Paperback decision, as the record below indicates,\nthe author of the affidavit (who is the principal designer of the Lotus product) made it\nclear in Congressional testimony that he does not believe it is beneficial to the industry to\nextend copyright protection to individual elements of a screen display--e.g., the menus.\nThat, in his view, would constitute \"overprotection\" that is \"pernicious\" and \"stifling.\"\nSee Brief of Amicus Curiae Software Entrepreneur's Forum, filed in the First Circuit on\nDec. 23, 1993, at 6.\n9 See, e.g., Raburn Decl. at para.14, RE 3: Borland III, 831 F. Supp. at 213, Pet. App. at\n86a-87a.\n10 49 F.3d at 809-10, 819-21, Pet. App. at 4a, 24a-27a. See also Paperback, 740 F. Supp.\nat 64-65, Pet. App. at 228a; Borland II, 799 F. Supp. at 213-14, Pet. App. at 110a;\nBorland IV, 831 F. Supp. at 227, Pet. App. at 31a.\n11 Ex. 38 (Houdini Analysis of Competitive Products) at L047694, 1st Cir. App. 1196.\nAs a result of macros, 1-2-3 became, in the words of Lotus' own documents,\n\"entrenched.\" Ex. 39 (Review of Excel) at L046265, 1st Cir. App. 1198.\n12 See Ex. 1 and 2, 1st Cir. App. 1134; Borland S.J. Brief (Dkt. No. 141) at 2 n.3.\n13 P. Kahn Tr. at 65-66, RE 10-11; Bosworth Tr. at 148, 1st Cir. App. 748; Ex. 27 at\nL034481, 1st Cir. App. 1178.\n14 See Tr. of Sept. 23, 1992 Hearing at 54, 1st Cir. App. 18; Tr. of Oct. 16, 1992 Hearing\nat 15-17, 1st Cir. App. 24-25; Tr. of Aug. 19, 1993 Hearing (Dkt. No. 406) at 42-43.\n15 Altai, 982 F.2d at 704; Paul Goldstein, Copyright, sect. 2.15 at 195 (1989) (\"Goldstein\nTreatise\").\n16 See, e.g., H.R. Rep. No. 1476, 94th Cong., 2d Sess. 54-55 (1976), reprinted in 1976\nU.S.C.C.A.N. 5659, 5667-68.\n17 In declarations in an earlier case in which Professor Miller was the retained expert for\nthe party accused of infringement, Professor Miller opined on the CONTU deliberations\nand the role of copyright in protecting computer programs. Those declarations can be\nfound in the record below as exhibits to the Reply Brief of Defendant/Appellant Borland\nInternational, Inc., filed in the First Circuit on March 1, 1994. The quoted portion in the\ntext is from the second declaration at para. 29.\n18 A few district courts have protected the menu aspects of screen displays by generally\nfocusing on artistic and stylistic aspects of display, rather than the words themselves. For\nexample, in Digital Comm. Assoc., Inc. v. Softklone Distrib. Corp., 659 F. Supp. 449,\n460 (N.D. Ga. 1987), the district court protected the \"highlighting\" and \"capitalizing\" of\ncertain menus only because they \"have no relationship to the functioning . . . of the\n\ncomputer program.\" Similarly, Manufacturers Technologies, Inc. v. CAMS, Inc., 706 F.\nSupp. 984, 995-998 (D. Conn. 1989), provided protection to only the three screens that\nwere not limited by functionality and denied copyright protection to the words and format\nof most menus. Where only the methods of operation were involved, district courts have\ndeclined to protect computer menus under the copyright laws. See Mitek Holdings, Inc.\nv. Arce Eng'g Co., 864 F. Supp. 1568, 1579-80 (S.D. Fla. 1994).\n19 See U.S. Department of Commerce, Press Release No. 95-21, Software Patent\nGuidelines Released Today, 6/1/95, 60 Fed. Reg. 28,778 (proposed June 2, 1995); B.\nRosewicz, Patent Office Acts to Clarify Software Rules, Wall St. J., June 2, 1995, at A1;\nU.S. Department of Commerce, Press Release No. 95-18, USPTO to Develop Guidelines\nto Protect Software Inventions, 3/30/95; M. Betts, Feds to ease software patent\nguidelines, Computerworld, April 17, 1995, at 20.\nDocument Location: Software Industry Issues\n(http://www.http://www.aimnet.com/~software/industry\n_issues/home)\nFor sponsorship information, requests, or comments email to: Kaye Caldwell\nBack to Software Industry Issues Home Page\nPage maintained by Kaye Caldwell, Copyright(c) 1995 Kaye Caldwell. Created: 8/26/95\nUpdated: 8/26/95"
    },
    {
      "category": "Resource",
      "title": "cdafinal.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/ddff6196875b77526f70ae2ae1f54b71_cdafinal.pdf",
      "content": "Communications Decency Act\nEnacted by the U.S. Congress on February 1, 1996\nSECTION 1. SHORT TITLE; REFERENCES.\n(a) Short Title.--This Act may be cited as the\n``Telecommunications Act of 1996''.\n(b) References.--Except as otherwise expressly provided, whenever\nin this Act an\namendment or repeal is expressed in terms of an amendment to, or repeal\nof, a section or other\nprovision, the reference shall be considered to be made to a section or\nother provision of the\nCommunications Act of 1934 (47 U.S.C. 151 et seq.).\n....\nTITLE V--OBSCENITY AND VIOLENCE\nSubtitle A--Obscene, Harassing, and Wrongful Utilization of\nTelecommunications Facilities\nSEC. 501. SHORT TITLE.\nThis title may be cited as the ``Communications Decency Act of\n1996''.\nSEC. 502. OBSCENE OR HARASSING USE OF TELECOMMUNICATIONS\nFACILITIES UNDER THE COMMUNICATIONS ACT OF 1934.\nSection 223 (47 U.S.C. 223) is amended-\n(1) by striking subsection (a) and inserting in lieu thereof:\n``(a) Whoever-\n``(1) in interstate or foreign communications-\n``(A) by means of a telecommunications device knowingly-\n-\n``(i) makes, creates, or solicits, and\n``(ii) initiates the transmission of,\nany comment, request, suggestion, proposal, image, or other\ncommunication\nwhich is obscene, lewd, lascivious, filthy, or indecent, with\nintent to annoy, abuse,\nthreaten, or harass another person;\n``(B) by means of a telecommunications device knowingly-\n-\n``(i) makes, creates, or solicits, and\n``(ii) initiates the transmission of,\nany comment, request, suggestion, proposal, image, or other\ncommunication\nwhich is obscene or indecent, knowing that the recipient of\nthe communication is\nunder 18 years of age, regardless of whether the maker of\nsuch communication\nplaced the call or initiated the communication;\n``(C) makes a telephone call or utilizes a\ntelecommunications device,\n\nwhether or not conversation or communication ensues, without\ndisclosing his\nidentity and with intent to annoy, abuse, threaten, or harass\nany person at the\ncalled number or who receives the communications;\n``(D) makes or causes the telephone of another\nrepeatedly or continuously\nnumber; or\nto ring, with intent to harass any person at the called\n``(E) makes repeated telephone calls or repeatedly\ninitiates communication\nwith a telecommunications device, during which conversation\nor communication\nensues, solely to harass any person at the called number or\nwho receives the\ncommunication; or\n``(2) knowingly permits any telecommunications facility under\nhis control to be\nused for any activity prohibited by paragraph (1) with the intent\nthat it be used for such\nactivity,\nshall be fined under title 18, United States Code, or imprisoned not\nmore than two years, or\nboth.''; and\n(2) by adding at the end the following new subsections:\n``(d) Whoever-\n``(1) in interstate or foreign communications knowingly-\n``(A) uses an interactive computer service to send to a\nspecific person or\npersons under 18 years of age, or\n``(B) uses any interactive computer service to display\nin a manner\navailable to a person under 18 years of age,\nany comment, request, suggestion, proposal, image, or other\ncommunication that, in\ncontext, depicts or describes, in terms patently offensive as\nmeasured by contemporary\ncommunity standards, sexual or excretory activities or organs,\nregardless of whether the\nuser of such service placed the call or initiated the\ncommunication; or\n``(2) knowingly permits any telecommunications facility under\nsuch person's\ncontrol to be used for an activity prohibited by paragraph (1)\nwith the intent that it be\nused for such activity,\nshall be fined under title 18, United States Code, or imprisoned not\nmore than two years, or both.\n``(e) In addition to any other defenses available by law:\n``(1) No person shall be held to have violated subsection (a)\nor (d) solely for\nproviding access or connection to or from a facility, system, or\nnetwork not under that\nperson's control, including transmission, downloading,\nintermediate storage, access\nsoftware, or other related capabilities that are incidental to\nproviding such access or\n\nconnection that does not include the creation of the content of\nthe communication.\n``(2) The defenses provided by paragraph (1) of this\nsubsection shall not be\napplicable to a person who is a conspirator with an entity\nactively involved in the creation\nor knowing distribution of communications that violate this\nsection, or who knowingly\nadvertises the availability of such communications.\n``(3) The defenses provided in paragraph (1) of this\nsubsection shall not be\napplicable to a person who provides access or connection to a\nfacility, system, or network\nengaged in the violation of this section that is owned or\ncontrolled by such person.\n``(4) No employer shall be held liable under this section for\nthe actions of an\nemployee or agent unless the employee's or agent's conduct is\nwithin the scope of his or\nher employment or agency and the employer (A) having knowledge of\nsuch conduct,\nauthorizes or ratifies such conduct, or (B) recklessly disregards\nsuch conduct.\n``(5) It is a defense to a prosecution under subsection\n(a)(1)(B) or (d), or under\nsubsection (a)(2) with respect to the use of a facility for an\nactivity under subsection\n(a)(1)(B) that a person-\n``(A) has taken, in good faith, reasonable, effective,\nand appropriate\nactions under the circumstances to restrict or prevent access\nby minors to a\ncommunication specified in such subsections, which may\ninvolve any appropriate\nmeasures to restrict minors from such communications,\nincluding any method\nwhich is feasible under available technology; or\n``(B) has restricted access to such communication by\nrequiring use of a\nverified credit card, debit account, adult access code, or\nadult personal\nidentification number.\n``(6) The Commission may describe measures which are\nreasonable, effective,\nand appropriate to restrict access to prohibited communications\nunder subsection (d).\nNothing in this section authorizes the Commission to enforce, or\nis intended to provide\nthe Commission with the authority to approve, sanction, or permit,\nthe use of such\nmeasures. The Commission shall have no enforcement authority over\nthe failure to utilize\nsuch measures. The Commission shall not endorse specific products\nrelating to such\nmeasures. The use of such measures shall be admitted as evidence\nof good faith efforts\n\nfor purposes of paragraph (5) in any action arising under\nsubsection (d). Nothing in this\nsection shall be construed to treat interactive computer services\nas common carriers or\ntelecommunications carriers.\n``(f)(1) No cause of action may be brought in any court or\nadministrative agency against\nany person on account of any activity that is not in violation of any\nlaw punishable by criminal or\ncivil penalty, and that the person has taken in good faith to implement\na defense authorized under\nthis section or otherwise to restrict or prevent the transmission of,\nor access to, a communication\nspecified in this section.\n``(2) No State or local government may impose any liability for\ncommercial activities or\nactions by commercial entities, nonprofit libraries, or institutions of\nhigher education in\nconnection with an activity or action described in subsection (a)(2) or\n(d) that is inconsistent with\nthe treatment of those activities or actions under this section:\nProvided, however, That nothing\nherein shall preclude any State or local government from enacting and\nenforcing complementary\noversight, liability, and regulatory systems, procedures, and\nrequirements, so long as such\nsystems, procedures, and requirements govern only intrastate services\nand do not result in the\nimposition of inconsistent rights, duties or obligations on the\nprovision of interstate services.\nNothing in this subsection shall preclude any State or local government\nfrom governing conduct\nnot covered by this section.\n``(g) Nothing in subsection (a), (d), (e), or (f) or in the\ndefenses to prosecution under (a)\nor (d) shall be construed to affect or limit the application or\nenforcement of any other Federal\nlaw.\n``(h) For purposes of this section-\n``(1) The use of the term `telecommunications device' in this\nsection-\n``(A) shall not impose new obligations on broadcasting\nstation licensees\nand cable operators covered by obscenity and indecency\nprovisions elsewhere in\nthis Act; and\n``(B) does not include an interactive computer service.\n``(2) The term `interactive computer service' has the meaning\nprovided in section\n230(e)(2).\n``(3) The term `access software' means software (including\nclient or server\nsoftware) or enabling tools that do not create or provide the\ncontent of the communication\nbut that allow a user to do any one or more of the following:\n``(A) filter, screen, allow, or disallow content;\n``(B) pick, choose, analyze, or digest content; or\n\n``(C) transmit, receive, display, forward, cache,\nsearch, subset, organize,\nreorganize, or translate content.\n``(4) The term `institution of higher education' has the\nmeaning provided in\nsection 1201 of the Higher Education Act of 1965 (20 U.S.C. 1141).\n``(5) The term `library' means a library eligible for\nparticipation in State-based\nplans for funds under title III of the Library Services and\nConstruction Act (20 U.S.C.\n355e et seq.).''.\nSEC. 503. OBSCENE PROGRAMMING ON CABLE TELEVISION.\nSection 639 (47 U.S.C. 559) is amended by striking ``not more than\n$10,000'' and\ninserting ``under title 18, United States Code,''.\nSEC. 504. SCRAMBLING OF CABLE CHANNELS FOR NONSUBSCRIBERS.\nPart IV of title VI (47 U.S. C. 551 et seq.) is amended by adding\nat the end the following:\n``SEC. 640. SCRAMBLING OF CABLE CHANNELS FOR NONSUBSCRIBERS.\n``(a) Subscriber Request.--Upon request by a cable service\nsubscriber, a cable operator\nshall, without charge, fully scramble or otherwise fully block the\naudio and video programming\nof each channel carrying such programming so that one not a subscriber\ndoes not receive it.\n``(b) Definition.--As used in this section, the term `scramble'\nmeans to rearrange the\ncontent of the signal of the programming so that the programming cannot\nbe viewed or heard in\nan understandable manner.''.\nSEC. 505. SCRAMBLING OF SEXUALLY EXPLICIT ADULT VIDEO SERVICE\nPROGRAMMING.\n(a) Requirement.--Part IV of title VI (47 U.S.C. 551 et seq.), as\namended by this Act, is\nfurther amended by adding at the end the following:\n``SEC. 641. SCRAMBLING OF SEXUALLY EXPLICIT ADULT VIDEO SERVICE\nPROGRAMMING.\n``(a) Requirement.--In providing sexually explicit adult\nprogramming or other\nprogramming that is indecent on any channel of its service primarily\ndedicated to sexually-oriented programming, a multichannel video\nprogramming distributor s\notherwise fully block the video and audio portion of such channel so\nthat one not a subscriber to\nsuch channel or programming does not receive it.\n``(b) Implementation.--Until a multichannel video programming\ndistributor complies\nwith the requirement set forth in subsection (a), the distributor shall\nlimit the access of children\nto the programming referred to in that subsection by not providing such\nprogramming during the\n\nhours of the day (as determined by the Commission) when a significant\nnumber of children are\nlikely to view it.\n``(c) Definition.--As used in this section, the term `scramble'\nmeans to rearrange the\ncontent of the signal of the programming so that the programming cannot\nbe viewed or heard in\nan understandable manner.''.\n(b) Effective Date.--The amendment made by subsection (a) shall\ntake effect 30 days\nafter the date of enactment of this Act.\nSEC. 506. CABLE OPERATOR REFUSAL TO CARRY CERTAIN PROGRAMS.\n(a) Public, Educational, and Governmental Channels.--Section\n611(e) (47 U.S.C.\n531(e)) is amended by inserting before the period the following: ``,\nexcept a cable operator may\nrefuse to transmit any public access program or portion of a public\naccess program which\ncontains obscenity, indecency, or nudity''.\n(b) Cable Channels for Commercial Use.--Section 612(c)(2) (47\nU.S.C. 532(c)(2)) is\namended by striking ``an operator'' and inserting ``a cable operator\nmay refuse to transmit any\nleased access program or portion of a leased access program which\ncontains obscenity,\nindecency, or nudity and''.\nSEC. 507. CLARIFICATION OF CURRENT LAWS REGARDING COMMUNICATION\nOF OBSCENE MATERIALS THROUGH THE USE OF COMPUTERS.\n(a) Importation or Transportation.--Section 1462 of title 18,\nUnited States Code, is\namended-\n(1) in the first undesignated paragraph, by inserting ``or\ninteractive computer\nservice (as defined in section 230(e)(2) of the Communications Act\nof 1934)'' after\n``carrier''; and\n(2) in the second undesignated paragraph-\n(A) by inserting ``or receives,'' after ``takes'';\n(B) by inserting ``or interactive computer service (as\ndefined in section\n230(e)(2) of the Communications Act of 1934)'' after ``common\ncarrier''; and\n(C) by inserting ``or importation'' after ``carriage''.\n(b) Transportation for Purposes of Sale or Distribution.--The\nfirst undesignated\nparagraph of section 1465 of title 18, United States Code, is amended-\n(1) by striking ``transports in'' and inserting ``transports\nor travels in, or uses a\nfacility or means of,'';\n(2) by inserting ``or an interactive computer service (as\ndefined in section\n230(e)(2) of the Communications Act of 1934) in or affecting such\ncommerce'' after\n``foreign commerce'' the first place it appears;\n\n(3) by striking ``, or knowingly travels in'' and all that\nfollows through ``obscene\nmaterial in interstate or foreign commerce,'' and inserting\n``of''.\n(c) Interpretation.--The amendments made by this section are\nclarifying and shall not\nbe interpreted to limit or repeal any prohibition contained in sections\n1462 and 1465 of title 18,\nUnited States Code, before such amendment, under the rule established\nin United States v.\nAlpers, 338 U.S. 680 (1950).\nSEC. 508. COERCION AND ENTICEMENT OF MINORS.\nSection 2422 of title 18, United States Code, is amended-\n(1) by inserting ``(a)'' before ``Whoever knowingly''; and\n(2) by adding at the end the following:\n``(b) Whoever, using any facility or means of interstate or\nforeign commerce, including\nthe mail, or within the special maritime and territorial jurisdiction\nof the United States,\nknowingly persuades, induces, entices, or coerces any individual who\nhas not attained the age of\n18 years to engage in prostitution or any sexual act for which any\nperson may be criminally\nprosecuted, or attempts to do so, shall be fined under this title or\nimprisoned not more than 10\nyears, or both.''.\nSEC. 509. ONLINE FAMILY EMPOWERMENT.\nTitle II of the Communications Act of 1934 (47 U.S.C. 201 et seq.)\nis amended by adding\nat the end the following new section:\n``SEC. 230. PROTECTION FOR PRIVATE BLOCKING AND SCREENING OF\nOFFENSIVE MATERIAL.\n``(a) Findings.--The Congress finds the following:\n``(1) The rapidly developing array of Internet and other\ninteractive computer\nservices available to individual Americans represent an\nextraordinary advance in the\navailability of educational and informational resources to our\ncitizens.\n``(2) These services offer users a great degree of control\nover the information that\nthey receive, as well as the potential for even greater control in\nthe future as technology\ndevelops.\n``(3) The Internet and other interactive computer services\noffer a forum for a true\ndiversity of political discourse, unique opportunities for\ncultural development, and\nmyriad avenues for intellectual activity.\n``(4) The Internet and other interactive computer services\nhave flourished, to the\nbenefit of all Americans, with a minimum of government regulation.\n``(5) Increasingly Americans are relying on interactive media\nfor a variety of\n\npolitical, educational, cultural, and entertainment services.\n``(b) Policy.--It is the policy of the United States-\n``(1) to promote the continued development of the Internet\nand other interactive\ncomputer services and other interactive media;\n``(2) to preserve the vibrant and competitive free market\nthat presently exists for\nthe Internet and other interactive computer services, unfettered\nby Federal or State\nregulation;\n``(3) to encourage the development of technologies which\nmaximize user control\nover what information is received by individuals, families, and\nschools who use the\nInternet and other interactive computer services;\n``(4) to remove disincentives for the development and\nutilization of blocking and\nfiltering technologies that empower parents to restrict their\nchildren's access to\nobjectionable or inappropriate online material; and\n``(5) to ensure vigorous enforcement of Federal criminal laws\nto deter and punish\ntrafficking in obscenity, stalking, and harassment by means of\ncomputer.\n``(c) Protection for `Good Samaritan' Blocking and Screening of\nOffensive\nMaterial.-\n``(1) Treatment of publisher or speaker.--No provider or user\nof an\ninteractive computer service shall be treated as the publisher or\nspeaker of any\ninformation provided by another information content provider.\n``(2) Civil liability.--No provider or user of an interactive\ncomputer service\nshall be held liable on account of-\n``(A) any action voluntarily taken in good faith to\nrestrict access to or\navailability of material that the provider or user considers\nto be obscene, lewd,\nlascivious, filthy, excessively violent, harassing, or\notherwise objectionable,\nwhether or not such material is constitutionally protected;\nor\n``(B) any action taken to enable or make available to\ninformation content\nproviders or others the technical means to restrict access to\nmaterial described in\nparagraph (1).\n``(d) Effect on Other Laws.-\n``(1) No effect on criminal law.--Nothing in this section\nshall be construed to\nimpair the enforcement of section 223 of this Act, chapter 71\n(relating to obscenity) or\n110 (relating to sexual exploitation of children) of title 18,\nUnited States Code, or any\nother Federal criminal statute.\n\n``(2) No effect on intellectual property law.--Nothing in\nthis section shall\nbe construed to limit or expand any law pertaining to intellectual\nproperty.\n``(3) State law.--Nothing in this section shall be construed\nto prevent any State\nfrom enforcing any State law that is consistent with this section.\nNo cause of action may\nbe brought and no liability may be imposed under any State or\nlocal law that is\ninconsistent with this section.\n``(4) No effect on communications privacy law.--Nothing in\nthis section\nshall be construed to limit the application of the Electronic\nCommunications Privacy Act\nof 1986 or any of the amendments made by such Act, or any similar\nState law.\n``(e) Definitions.--As used in this section:\n``(1) Internet.--The term `Internet' means the international\ncomputer network of\nboth Federal and non-Federal interoperable packet switched data\nnetworks.\n``(2) Interactive computer service.--The term `interactive\ncomputer service'\nmeans any information service, system, or access software provider\nthat provides or\nenables computer access by multiple users to a computer server,\nincluding specifically a\nservice or system that provides access to the Internet and such\nsystems operated or\nservices offered by libraries or educational institutions.\n``(3) Information content provider.--The term `information\ncontent provider'\nmeans any person or entity that is responsible, in whole or in\npart, for the creation or\ndevelopment of information provided through the Internet or any\nother interactive\ncomputer service.\n``(4) Access software provider.--The term `access software\nprovider' means a\nprovider of software (including client or server software), or\nenabling tools that do any\none or more of the following:\n``(A) filter, screen, allow, or disallow content;\n``(B) pick, choose, analyze, or digest content; or\n``(C) transmit, receive, display, forward, cache,\nsearch, subset, organize,\nreorganize, or translate content.''.\nSubtitle Bviolence\nSEC. 551. PARENTAL CHOICE IN TELEVISION PROGRAMMING.\n(a) Findings.--The Congress makes the following findings:\n(1) Television influences children's perception of the values\nand behavior that are\ncommon and acceptable in society.\n\n(2) Television station operators, cable television system\noperators, and video\nprogrammers should follow practices in connection with video\nprogramming that take\ninto consideration that television broadcast and cable programming\nhas established a\nuniquely pervasive presence in the lives of American children.\n(3) The average American child is exposed to 25 hours of\ntelevision each week\nand some children are exposed to as much as 11 hours of television\na day.\n(4) Studies have shown that children exposed to violent video\nprogramming at a\nyoung age have a higher tendency for violent and aggressive\nbehavior later in life than\nchildren not so exposed, and that children exposed to violent\nvideo programming are\nprone to assume that acts of violence are acceptable behavior.\n(5) Children in the United States are, on average, exposed to\nan estimated 8,000\nmurders and 100,000 acts of violence on television by the time the\nchild completes\nelementary school.\n(6) Studies indicate that children are affected by the\npervasiveness and casual\ntreatment of sexual material on television, eroding the ability of\nparents to develop\nresponsible attitudes and behavior in their children.\n(7) Parents express grave concern over violent and sexual\nvideo programming and\nstrongly support technology that would give them greater control\nto block video\nprogramming in the home that they consider harmful to their\nchildren.\n(8) There is a compelling governmental interest in empowering\nparents to limit\nthe negative influences of video programming that is harmful to\nchildren.\n(9) Providing parents with timely information about the\nnature of upcoming video\nprogramming and with the technological tools that allow them\neasily to block violent,\nsexual, or other programming that they believe harmful to their\nchildren is a nonintrusive\nand narrowly tailored means of achieving that compelling\ngovernmental interest.\n(b) Establishment of Television Rating Code.-\n(1) Amendment.--Section 303 (47 U.S.C. 303) is amended by\nadding at the end\nthe following:\n``(w) Prescribe-\n``(1) on the basis of recommendations from an advisory\ncommittee established by\nthe Commission in accordance with section 551(b)(2) of the\nTelecommunications Act of\n1996, guidelines and recommended procedures for the identification\nand rating of video\n\nprogramming that contains sexual, violent, or other indecent\nmaterial about which parents\nshould be informed before it is displayed to children, provided\nthat nothing in this\nparagraph shall be construed to authorize any rating of video\nprogramming on the basis of\nits political or religious content; and\n``(2) with respect to any video programming that has been\nrated, and in\nconsultation with the television industry, rules requiring\ndistributors of such video\nprogramming to transmit such rating to permit parents to block the\ndisplay of video\nprogramming that they have determined is inappropriate for their\nchildren.''.\n(2) Advisory committee requirements.--In establishing an\nadvisory committee\nfor purposes of the amendment made by paragraph (1) of this\nsubsection, the\nCommission shall-\n(A) ensure that such committee is composed of parents,\ntelevision\nbroadcasters, television programming producers, cable\noperators, appropriate\npublic interest groups, and other interested individuals from\nthe private sector and\nis fairly balanced in terms of political affiliation, the\npoints of view represented,\nand the functions to be performed by the committee;\n(B) provide to the committee such staff and resources as\nmay be necessary\nto permit it to perform its functions efficiently and\npromptly; and\n(C) require the committee to submit a final report of\nits recommendations\nwithin one year after the date of the appointment of the\ninitial members.\n(c) Requirement for Manufacture of Televisions That Block\nPrograms.--Section\n303 (47 U.S.C. 303), as amended by subsection (a), is further amended\nby adding at the end the\nfollowing:\n``(x) Require, in the case of an apparatus designed to receive\ntelevision signals that are\nshipped in interstate commerce or manufactured in the United States and\nthat have a picture\nscreen 13 inches or greater in size (measured diagonally), that such\napparatus be equipped with a\nfeature designed to enable viewers to block display of all programs\nwith a common rating, except\nas otherwise permitted by regulations pursuant to section 330(c)(4).''.\n(d) Shipping of Televisions That Block Programs.-\n(1) Regulations.--Section 330 (47 U.S.C. 330) is amended-\n(A) by redesignating subsection (c) as subsection (d);\nand\n(B) by adding after subsection (b) the following new\nsubsection (c):\n\n``(c)(1) Except as provided in paragraph (2), no person shall ship\nin interstate commerce\nor manufacture in the United States any apparatus described in section\n303(x) of this Act except\nin accordance with rules prescribed by the Commission pursuant to the\nauthority granted by that\nsection.\n``(2) This subsection shall not apply to carriers transporting\napparatus referred to in\nparagraph (1) without trading in it.\n``(3) The rules prescribed by the Commission under this subsection\nshall provide for the\noversight by the Commission of the adoption of standards by industry\nfor blocking technology.\nSuch rules shall require that all such apparatus be able to receive the\nrating signals which have\nbeen transmitted by way of line 21 of the vertical blanking interval\nand which conform to the\nsignal and blocking specifications established by industry under the\nsupervision of the\nCommission.\n``(4) As new video technology is developed, the Commission shall\ntake such action as the\nCommission determines appropriate to ensure that blocking service\ncontinues to be available to\nconsumers. If the Commission determines that an alternative blocking\ntechnology exists that-\n``(A) enables parents to block programming based on\nidentifying programs\nwithout ratings,\n``(B) is available to consumers at a cost which is comparable\nto the cost of\ntechnology that allows parents to block programming based on\ncommon ratings, and\n``(C) will allow parents to block a broad range of programs\non a multichannel\nsystem as effectively and as easily as technology that allows\nparents to block\nprogramming based on common ratings,\nthe Commission shall amend the rules prescribed pursuant to section\n303(x) to require that the\napparatus described in such section be equipped with either the\nblocking technology described in\nsuch section or the alternative blocking technology described in this\nparagraph.''.\n(2) Conforming amendment.--Section 330(d), as redesignated by\nsubsection\n(d)(1)(A), is amended by striking ``section 303(s), and section\n303(u)'' and inserting in\nlieu thereof ``and sections 303(s), 303(u), and 303(x)''.\n(e) Applicability and Effective Dates.-\n(1) Applicability of rating provision.--The amendment made by\nsubsection\n(b) of this section shall take effect 1 year after the date of\nenactment of this Act, but only\n\nif the Commission determines, in consultation with appropriate\npublic interest groups and\ninterested individuals from the private sector, that distributors\nof video programming\nhave not, by such date-\n(A) established voluntary rules for rating video\nprogramming that contains\nsexual, violent, or other indecent material about which\nparents should be informed\nbefore it is displayed to children, and such rules are\nacceptable to the\nCommission; and\n(B) agreed voluntarily to broadcast signals that contain\nratings of such\nprogramming.\n(2) Effective date of manufacturing provision.--In\nprescribing regulations to\nimplement the amendment made by subsection (c), the Federal\nCommunications\nCommission shall, after consultation with the television\nmanufacturing industry, specify\nthe effective date for the applicability of the requirement to the\napparatus covered by such\namendment, which date shall not be less than two years after the\ndate of enactment of this\nAct.\nSEC. 552. TECHNOLOGY FUND.\nIt is the policy of the United States to encourage broadcast\ntelevision, cable, satellite,\nsyndication, other video programming distributors, and relevant related\nindustries (in\nconsultation with appropriate public interest groups and interested\nindividuals from the private\nsector) to-\n(1) establish a technology fund to encourage television and\nelectronics equipment\nmanufacturers to facilitate the development of technology which\nwould empower parents\nto block programming they deem inappropriate for their children\nand to encourage the\navailability thereof to low income parents;\n(2) report to the viewing public on the status of the\ndevelopment of affordable,\neasy to use blocking technology; and\n(3) establish and promote effective procedures, standards,\nsystems, advisories, or\nother mechanisms for ensuring that users have easy and complete\naccess to the\ninformation necessary to effectively utilize blocking technology\nand to encourage the\navailability thereof to low income parents.\nSubtitle C--Judicial Review\nSEC. 561. EXPEDITED REVIEW.\n\n(a) Three-Judge District Court Hearing.--Notwithstanding any other\nprovision of\nlaw, any civil action challenging the constitutionality, on its face,\nof this title or any amendment\nmade by this title, or any provision thereof, shall be heard by a\ndistrict court of 3 judges\nconvened pursuant to the provisions of section 2284 of title 28, United\nStates Code.\n(b) Appellate Review.--Notwithstanding any other provision of law,\nan interlocutory or\nfinal judgment, decree, or order of the court of 3 judges in an action\nunder subsection (a) holding\nthis title or an amendment made by this title, or any provision\nthereof, unconstitutional shall be\nreviewable as a matter of right by direct appeal to the Supreme Court.\nAny such appeal shall be\nfiled not more than 20 days after entry of such judgment, decree, or\norder."
    },
    {
      "category": "Resource",
      "title": "clipperannounce.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/d614e42b278c820ecbfbe886e1a5e62d_clipperannounce.pdf",
      "content": "White House Annoucement of the Clipper Initiative\nThis is the original public announcement by the White House of the Clipper initiative.\nTHE WHITE HOUSE\nOffice of the Press Secretary\nFor Immediate Release\nApril 16, 1993\nSTATEMENT BY THE PRESS SECRETARY\nThe President today announced a new initiative that will bring the\nFederal Government together with industry in a voluntary program to\nimprove the security and privacy of telephone communications while\nmeeting the legitimate needs of law enforcement.\nThe initiative will involve the creation of new products to accelerate\nthe development and use of advanced and secure telecommunications\nnetworks and wireless communications links.\nFor too long there has been little or no dialogue between our private\nsector and the law enforcement community to resolve the tension\nbetween economic vitality and the real challenges of protecting\nAmericans. Rather than use technology to accommodate the sometimes\ncompeting interests of economic growth, privacy and law enforcement,\nprevious policies have pitted government against industry and the\nrights of privacy against law enforcement.\nSophisticated encryption technology has been used for years to protect\nelectronic funds transfer. It is now being used to protect electronic\nmail and computer files. While encryption technology can help\nAmericans protect business secrets and the unauthorized release of\npersonal information, it also can be used by terrorists, drug dealers,\nand other criminals.\nA state-of-the-art microcircuit called the \"Clipper Chip\" has\nbeen developed by government engineers. The chip represents a new\napproach to encryption technology. It can be used in new, relatively\ninexpensive encryption devices that can be attached to an ordinary\ntelephone. It scrambles telephone communications using an encryption\nalgorithm that is more powerful than many in commercial use today.\nThis new technology will help companies protect proprietary\ninformation, protect the privacy of personal phone conversations and\nprevent unauthorized release of data transmitted electronically. At\nthe same time this technology preserves the ability of federal, state\nand local law enforcement agencies to intercept lawfully the phone\nconversations of criminals.\nA \"key-escrow\" system will be established to ensure that the \"Clipper\nChip\" is used to protect the privacy of law-abiding Americans. Each\n\ndevice containing the chip will have two unique \"keys,\" numbers that\nwill be needed by authorized government agencies to decode messages\nencoded by the device. When the device is manufactured, the two keys\nwill be deposited separately in two \"key-escrow\" data bases that will\nbe established by the Attorney General. Access to these keys will be\nlimited to government officials with legal authorization to conduct a\nwiretap.\nThe \"Clipper Chip\" technology provides law enforcement with no new\nauthorities to access the content of the private conversations of\nAmericans.\nTo demonstrate the effectiveness of this new technology, the Attorney\nGeneral will soon purchase several thousand of the new devices. In\naddition, respected experts from outside the government will be\noffered access to the confidential details of the algorithm to assess\nits capabilities and publicly report their findings. The chip is an\nimportant step in addressing the problem of encryption's dual-edge\nsword: encryption helps to protect the privacy of individuals and\nindustry, but it also can shield criminals and terrorists. We need the\n\"Clipper Chip\" and other approaches that can both provide law-abiding\ncitizens with access to the encryption they need and prevent criminals\nfrom using it to hide their illegal activities. In order to assess\ntechnology trends and explore new approaches (like the key-escrow\nsystem), the President has directed government agencies to develop a\ncomprehensive policy on encryption that accommodates:\nthe privacy of our citizens, including the need to employ voice or\ndata encryption for business purposes;\nthe ability of authorized officials to access telephone calls and\ndata, under proper court or other legal order, when necessary to\nprotect our citizens;\nthe effective and timely use of the most modern technology to build\nthe National Information Infrastructure needed to promote economic\ngrowth and the competitiveness of American industry in the global\nmarketplace; and\nthe need of U.S. companies to manufacture and export high technology\nproducts.\nThe President has directed early and frequent consultations with\naffected industries, the Congress and groups that advocate the privacy\nrights of individuals as policy options are developed.\nThe Administration is committed to working with the private sector to\nspur the development of a National Information Infrastructure which\nwill use new telecommunications and computer technologies to give\nAmericans unprecedented access to information. This infrastructure of\nhigh-speed networks (\"information superhighways\") will transmit video,\nimages, HDTV programming, and huge data files as easily as today's\ntelephone system transmits voice.\nSince encryption technology will play an increasingly important role\nin that infrastructure, the Federal Government must act quickly to\ndevelop consistent, comprehensive policies regarding its use. The\n\nAdministration is committed to policies that protect all Americans'\nright to privacy while also protecting them from those who break the\nlaw.\nFurther information is provided in an accompanying fact sheet. The\nprovisions of the President's directive to acquire the new\nencryption technology are also available. For additional details, call\nMat Heyman, National Institute of Standards and Technology, (301)\n975-2758.\nQUESTIONS AND ANSWERS ABOUT THE CLINTON\nADMINISTRATION'S TELECOMMUNICATIONS INITIATIVE\nQ: Does this approach expand the authority of government agencies to\nlisten in on phone conversations?\nA: No. \"Clipper Chip\" technology provides law enforcement with no new\nauthorities to access the content of the private conversations of\nAmericans.\nQ: Suppose a law enforcement agency is conducting a wiretap on a drug\nsmuggling ring and intercepts a conversation encrypted using the\ndevice. What would they have to do to decipher the message?\nA: They would have to obtain legal authorization, normally a court\norder, to do the wiretap in the first place. They would then present\ndocumentation of this authorization to the two entities responsible\nfor safeguarding the keys and obtain the keys for the device being\nused by the drug smugglers. The key is split into two parts, which are\nstored separately in order to ensure the security of the key escrow\nsystem.\nQ: Who will run the key-escrow data banks?\nA: The two key-escrow data banks will be run by two independent\nentities. At this point, the Department of Justice and the\nAdministration have yet to determine which agencies will oversee the\nkey-escrow data banks.\nQ: How strong is the security in the device? How can I be sure how\nstrong the security is?\nA: This system is more secure than many other voice encryption systems\nreadily available today. While the algorithm will remain classified to\nprotect the security of the key escrow system, we are willing to\ninvite an independent panel of cryptography experts to evaluate the\nalgorithm to assure all potential users that there are no unrecognized\nvulnerabilities.\nQ: Whose decision was it to propose this product?\nA: The National Security Council, the Justice Department, the Commerce\nDepartment, and other key agencies were involved in this decision This\napproach has been endorsed by the President, the Vice President, and\n\nappropriate Cabinet officials.\nQ: Who was consulted? The Congress? Industry?\nA: We have on-going discussions with Congress and industry on\nencryption issues, and expect those discussions to intensify as we\ncarry out our review of encryption policy. We have briefed members of\nCongress and industry leaders on the decisions related to this\ninitiative.\nQ: Will the government provide the hardware to manufacturers?\nA: The government designed and developed the key access encryption\nmicrocircuits, but it is not providing the microcircuits to product\nmanufacturers. Product manufacturers can acquire the microcircuits\nfrom the chip manufacturer that produces them.\nQ: Who provides the \"Clipper Chip\"?\nA: Mykotronx programs it at their facility in Torrance, California,\nand will sell the chip to encryption device manufacturers. The\nprogramming function could be licensed to other vendors in the future.\nQ: How do I buy one of these encryption devices?\nA: We expect several manufacturers to consider incorporating the\n\"Clipper Chip\" into their devices.\nQ: If the Administration were unable to find a technological solution\nlike the one proposed, would the Administration be willing to use\nlegal remedies to restrict powerful encryption devices?\nA: This is a fundamental policy question which will be considered\nduring the broad policy review. The key escrow mechanism will provide\nAmericans with an encryption product that is more secure, more\nconvenient, and less expensive than others readily available today,\nbut it is just one piece of what must be the comprehensive approach to\nencryption technology, which the Administration is developing.\nThe Administration is not saying, \"since encryption threatens the\npublic safety and effective law enforcement, we will prohibit it\noutright\" (as some countries have effectively done); nor is the\nU.S. saying that \"every Amen can, as a matter of right, is entitled to\nan unbreakable commercial encryption product.\" There is a false\n\"tension\" created in the assessment that this issue is an either-or\"\nproposition. Rather, both concerns can be, and in fact are,\nharmoniously balanced through a reasoned, balanced approach such as is\nproposed with the \"Clipper Chip\" and similar encryption techniques.\nQ: What does this decision indicate about how the Clinton\nAdministration's policy toward encryption will differ from that of the\nBush Administration?\nA: It indicates that we understand the importance of encryption\ntechnology in telecommunications and computing and are committed to\nworking with industry and public-interest groups to find innovative\nways to protect Americans' privacy, help businesses to compete, and\n\nensure that law enforcement agencies have the tools they need to fight\ncrime and terrorism.\nQ: Will the devices be exportable? Will other devices that use the\ngovernment hardware?\nA: Voice encryption devices are subject to export control\nrequirements. Case-by-case review for each export is required to\nensure appropriate use of these devices. The same is true for other\nencryption devices. One of the attractions of this technology is the\nprotection it can give to U.S. companies operating at home and\nabroad. With this in mind, we expect export licenses will be granted\non a case-by-case basis for U.S. companies seeking to use these\ndevices to secure their own communications abroad. We plan to review\nthe possibility of permitting wider exportability of these products."
    },
    {
      "category": "Resource",
      "title": "clipperdirective.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-805-ethics-and-the-law-on-the-electronic-frontier-fall-2005/f8bf4382b9e4985823c7cb3cb168c0e7_clipperdirective.pdf",
      "content": "Presidential Directive Authorizing the Clipper Initiative\nThis is the confidential Presidential directive authorizing Clipper initiative. (Declassified\ndocument obtained by the Electronic Privacy Information Center under the Freedom of\nInformation Act.)\nTHE WHITE HOUSE\nWASHINGTON\nApril 15, 1993\nSUBJECT:\nPublic Encryption Management\nAdvanced telecommunications and commercially available encryption are\npart of a wave of new computer and communications\ntechnology. Encryption products scramble information to protect the\nprivacy of communications and data by preventing unauthorized\naccess. Advanced telecommunications systems use digital technology to\nrapidly and precisely handle a high volume of communications. These\nadvanced telecommunications systems are integral to the infrastructure\nneeded to ensure economic competitiveness in the information age.\nDespite its benefits, new communications technology can also frustrate\nlawful government electronic surveillance. Sophisticated encryption\ncan have this effect in the United States. When exported abroad, it\ncan be used to thwart foreign intelligence activities critical to our\nnational interests. In the past, it has been possible to reserve a\ngovernment capability to conduct electronic surveillance in\nfurtherance of legitimate law enforcement and national security\ninterests, while at the same time protecting the privacy and civil\nliberties of all citizens. As encryption technology improves, doing so\nwill require new, innovative approaches.\nIn the area of communications encryption, the U.S. government has\ndeveloped a microcircuit that not only provides privacy through\nencryption that is substantially more robust than the current\ngovernment standard, but also permits escrowing of the keys needed to\nunlock the encryption. The system for the escrowing of keys will allow\nthe government to gain access to encrypted information only with\nappropriate legal authorization.\nTo assist law enforcement and other government agencies to.. collect\nand decrypt, under legal authority, electronically transmitted\ninformation, I hereby direct the following, action to be taken: d 10.\nINSTALLATION OF GOVERNMENT-DEVELOPED MICROCIRCUITS\nThe Attorney General of the United States.. or her representative,\nshall request manufacturers of communications hardware which\nincorporates encryption to install the U.S. government-developed\nkey-escrow microcircuits in their products. The fact of law\nenforcement access to the escrowed keys will not be concealed from the\nAmerican public. All appropriate steps shall be taken to ensure that\n\nany existing or future versions of the key-escrow microcircuit are\nmade widely available to U.S. communications hardware manufacturers,\nconsistent with the need to ensure the security of the key-escrow\nsystem. In making this decision, I do not intend to prevent the\nprivate sector from developing, or the government from approving,\nother microcircuits or algorithms that are equally effective in\nassuring both privacy and a secure key-escrow system.\nKEY-ESCROW\nThe Attorney General shall make all arrangements with appropriate\nentities to hold the keys for the key-escrow microcircuits installed\nin communications equipment. In each case, the key holder must agree\nto strict security procedures to prevent unauthorized release of the\nkeys. The keys shall be released only to government agencies that have\nestablished their authority to acquire the content of those\nCommunications that have been encrypted by devices containing the\nmicrocircuits. The Attorney General shall review for legal sufficiency\nthe procedures by which an agency establishes its authority to acquire\nthe content of such communications.\nPROCUREMENT AND USE OF ENCRYPTION DEVICES\nThe Secretary of Commerce, in consultation with other appropriate\nU.S. agencies, shall initiate a process to write standards to\nfacilitate the procurement and use of encryption devices fitted with\nkey-escrow microcircuits in federal communications systems that\nprocess sensitive but unclassified information. expect this process to\nproceed on a schedule that will permit promulgation of final standard\nwithin six months of this directive.\nThe Attorney General will procure and utilized encryption devices to\nthe extent needed to preserve the government's ability to conduct\nlawful electronic surveillance and to fulfill the need for secure\nlaw enforcement communications. Further, The Attorney General shall\nutilize funds from the Department of Justice Asset Forfeiture Super\nSurplus Fund to effect this purchase.\n/s/ William J. Clinton"
    }
  ]
}