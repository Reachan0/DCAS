{
  "course_name": "Biomedical Information Technology",
  "course_description": "This course teaches the design of contemporary information systems for biological and medical data. Examples are chosen from biology and medicine to illustrate complete life cycle information systems, beginning with data acquisition, following to data storage and finally to retrieval and analysis. Design of appropriate databases, client-server strategies, data interchange protocols, and computational modeling architectures. Students are expected to have some familiarity with scientific application software and a basic understanding of at least one contemporary programming language (e.g. C, C++, Java, Lisp, Perl, Python). A major term project is required of all students. This subject is open to motivated seniors having a strong interest in biomedical engineering and information system design with the ability to carry out a significant independent project.\nThis course was offered as part of the Singapore-MIT Alliance (SMA) program as course number SMA 5304.",
  "topics": [
    "Business",
    "Information Technology",
    "Engineering",
    "Biological Engineering",
    "Computational Biology",
    "Computer Science",
    "Data Mining",
    "Health and Medicine",
    "Biomedical Instrumentation",
    "Biomedicine",
    "Medical Imaging",
    "Business",
    "Information Technology",
    "Engineering",
    "Biological Engineering",
    "Computational Biology",
    "Computer Science",
    "Data Mining",
    "Health and Medicine",
    "Biomedical Instrumentation",
    "Biomedicine",
    "Medical Imaging"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nCourse Description\n\nBiology and medicine are moving into a new era that is characterized as being \"data-rich.\" In biological research, a single laboratory can produce terabytes of data per month that needs to be shared across the research community. Drug development involves analyzing hundreds of compounds with laboratory tests that generate huge amounts of data that must be analyzed and shared. Clinical trials assay thousands of individual data elements on hundreds of patients over many time points.\n\nThe objective of this course is to provide the students with the knowledge to address these challenges. We focus on the storage, integration, querying and management of heterogeneous, voluminous, geographically dispersed biomedical data. In addition to primary data, such as experimental data, the methods also address derived data such as those from analyzed microscope images. Examples of pathway analysis methods and the sharing and storage of the data that they generate will be presented. Querying across multiple databases is described, where the databases can be as diverse as microarray experiments, curated databases compiled by domain experts, or biomedical images. Other data sources include medical records, information on disease, references to literature, and biological pathways predicting protein expression. Several current examples from biological research will be presented.\n\nPrerequisites\n\n1.00 Introduction to Computers and Engineering Problem Solving; 6.001 Structure and Interpretation of Computer Programs; or experience with Web-based computing.\n\nReference Materials\n\nThere is no recommended text book for this course simply because to the best of our knowledge there is no single text book available that can address the breath and depth of the issues in this course. Hence the reference materials will be lecture notes, research experience of the course instructors in biomedical data management, and a set of research papers.\n\nTerm Paper\n\nA term paper is required of all students. The subject of the term paper is the choice of the student, and can as examples be a driving problem in research, a new idea for managing biomedical data, or an improvement on an existing system.\n\nCalendar\n\nInstructors Key:\n\nCFD = Prof. C. Forbes Dewey, Jr. (MIT)\n\nSSB = Prof. Sourav S. Bhowmick (NTU, Singapore)\n\nHY = Prof. Hanry Yu (NUS, Singapore)\n\nLEC #\n\nTOPICS\n\nINSTRUCTORS\n\nKEY DATES\n\nPart 1: Introduction\n\nBiomedical information technology today\n\n- Grand challenge problems in biology and medicine\n\n- The key role of information technology\n\n- Semantics, ontologies, and standards\n\n- Pathway modeling\n\n- Term paper instructions\n\nCFD\n\nPart 2: Biological and Medical Data\n\nTypes and characteristics of biological and medical data\n\n- Distributed data systems\n\n- The life cycle of scientific data\n\n- Current challenges\n\nHY\n\nAssignment 1 out\n\nExamples from liver fibrosis\n\n- Gel electrophoresis\n\n- Microarrays\n\n- FACS and other methods\n\n- Creating biological pathways\n\n- Designing new experiments\n\n- Integrating information from the literature\n\nHY\n\nPart 3: Storing, Querying, and Integrating Biomedical Data\n\nData avalanche in the biomedical world and role of databases\n\n- Relational data model\n\n- ER modeling\n\nSSB\n\nDesigning good database schema\n\n- Functional dependencies\n\n- Normalization\n\nSSB\n\nQuerying relational databases using SQL\n\nSSB\n\nQuerying relational databases using SQL (cont.)\n\n- Limitations of relational data\n\n- Introduction to semi-structured data and XML\n\nSSB\n\nIssues in querying XML data using XPath and XQuery\n\n- XML query languages\n\n- Principles of XML query processing\n\nSSB\n\nAssignment 1A due\n\nQuerying XML data (cont.)\n\n- XML and relational databases\n\nSSB\n\nQuerying graphs (molecular networks)\n\n- Querying pathways and protein sources\n\nSSB\n\nData integration without semantics\n\n- Issues related to biological data integration\n\n- Standards for publishing and sharing data\n\n- Examples and usage such as the DICOM standard\n\n- Biological databases and supporting organizations\n\nSSB\n\nAssignment 1B due\n\nPart 4: Ontology Management in Systems Biology\n\nDefinitions and importance of ontologies\n\n- Standards for publishing and sharing ontologies (OWL, RDF)\n\n- Examples and usage of ontologies in life sciences\n\n- Using unique identifiers and other semantic standards\n\nCFD\n\nDatabase approach to ontology storage and inference\n\nSSB\n\nAssignment 2 out\n\nCreating relational databases from ontologies\n\n- OWLdb\n\n- Querying databases using ontologically-based queries\n\nCFD\n\nQuerying ontologies with SPARQL\n\n- Integrating ontologies and XML query processing\n\n- Role of ontology management in system biology\n\nSSB\n\nPart 5: Biological Pathways\n\nModeling and computing pathways\n\n- Modeling and representation of pathways (SBML, CellML)\n\n- Challenges of managing disparate sources of pathways\n\n- Cell designer, cytosolve, and other computational environments\n\nCFD\n\nDiscussions with TAs related to assignments and term project\n\nMolecular network comparisons\n\n- Importance of molecular network comparison\n\n- Types of network comparison\n\n- Network comparison algorithms\n\nSSB\n\nPart 6: Biological and Medical Data Integration\n\nSWAN: An advanced architecture for sharing scientific information\n\n- The stakeholders, requirements, and functionality\n\n- The available technology\n\n- Workflow and usability\n\nGuest lecturer: Tim Clark, Harvard University\n\nAssignment 2 due 3 days later\n\nBuilding a distributed pathway-enabled information system for biological research\n\n- Scope of the data sources and the application constraints\n\n- Workflow and usability\n\n- Technical considerations\n\n- Accommodating the future\n\nCFD\n\nPart 7: Grand Challenges\n\nPredicting drug efficacy by modeling\n\n- Current limits of predictability\n\n- Living with incomplete data\n\n- Examples of success in quantitative modeling\n\nCFD\n\nRevolutionizing the drug discovery pipeline\n\n- The need for change\n\n- Key parts of the process\n\n- Quantitative modeling as a paradigm\n\nCFD\n\nPart 8: Term Paper Presentations\n\n24-26\n\nTerm paper presentations",
  "files": [
    {
      "category": "Resource",
      "title": "Constructing a Conformational Space of Pro-Ser-Thr Rich Non-Globular Domains",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/6da09141b6f68d5f68e9d4ffcac56bae_lc_project.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nSingapore-MIT Alliance\nSMA 5304 Term Project Presentation\nConstructing a Conformational\nSpace of Pro-Ser-Thr Rich Non-\nGlobular Domains\nLiu Chengcheng\nHT081976J\nCSB,SMA\n\nSingapore-MIT Alliance\nOutline\n- Rationale\nData integration\nSoftware\n- Proposed Approach\n- Proposed Architecture\nData Retrieving\nFormat Converter\nData ontology\nData Loading&wearhouse\n\nSingapore-MIT Alliance\nRationale\n- Phosphorylation on\nserine/threonine plays an\nimportant role in signaling\npathways.\n- Checkpoint proteins contain\nsequence motifs (in P-S-T-\nrich domain) bound by SH2,\nSH3 etc.\n- Data integration including\nusage of certain software to\nachieve a conformational\nspace of such domain.\nDiagram generated\nin Pathway Studio(r)\n\nSingapore-MIT Alliance\nData Integration\nLogos removed for copyright reasons.\nEBI: http://www.ebi.ac.uk/\nHSSP: http://swift.cmbi.kun.nl/swift/hssp/\nRCSB PDB: http://www.rcsb.org/pdb/\nUniProt: http://www.uniprot.org/\nPIR: http://pir.georgetown.edu/pirwww/\nRefSeq: http://www.ncbi.nlm.nih.gov/RefSeq/\n\nSingapore-MIT Alliance\nSoftware for domain/motif scanning\n-\nBlastProDom\n-\nFPrintScan\n-\nHMMPIR\n-\nHMMPfam\n-\nHMMSmart\nHMMTigr\n-\nProfileScan\n-\nScanRegExp\n-\npatternScan\n-\nSuperFamily\n-\nSignalPHMM\n-\nTMHMM\n-\nHMMPanther\n-\nGene3D\n- Families\n- Domains\n- Repeats\n- Sites\n- Motifs\n- Regions\n- Other features\nProtein's Information\nInterProScan Package\n\nSingapore-MIT Alliance\nProposed Approach:\nData Warehousing\nNATURE REVIEWS| GENETICS VOLUME 4 | MAY 2003 |337-345\nImage removed due to copyright restrictions.\nSee Fig. 5 in: Stein, L. D. \"Integrating Biological Databases.\" Nature Reviews\nGenetics 4 (May 2003): 337-345. doi:10.1038/nrg1065.\n\nSingapore-MIT Alliance\nProposed Architecture\n\nSingapore-MIT Alliance\nData Retrieving\n- Each database has a\ndata retriever\n- Parse and query the\nraw data\n(e.g. Nux Java toolkit &\nXQuery)\n- Include using software\n(e.g. patternScan)\n\nSingapore-MIT Alliance\nExample: retrieve data from UniProt\n- Start with a single modular domain e.g. SH3 (Src Homology\ndomain)\n- About 60 amino-acid residues in several cytoplasmic\nprotein tyrosine kinases (e.g. Src, Abl)\n- five or six β-strands arranged as two tightly packed anti-\nparallel β sheets\n- Binding to Pro-rich domain\n- Binding pattern X-P-P-X-P or R-X-X-K\nImage removed due to copyright restrictions.\n\"Ribbon diagram of the SH3 diagram, alpha spectrin,\nfrom chicken.\"\nhttp://en.wikipedia.org/wiki/File:1shg_SH3_domain.png\n\nSingapore-MIT Alliance\nFlowchart\nA new software to sample the conformations of\nthe pro-rich region and generate files as retrieved\ndata\n\nSingapore-MIT Alliance\nAfter searching\n\nSingapore-MIT Alliance\npatternScan identifies two\npotential SH3 binding sites\nA new software takes input file of pro-rich sequence\nto generate sample conformations\nImages removed due to copyright restrictions.\nSee http://www.blueprint.org/Home/trades.\n\nSingapore-MIT Alliance\nRetrieved data in different formats\nPROSITE\nFlat Files\nEntrez\nSwissProt\nUniProt\nXML/RDF Files\n\nSingapore-MIT Alliance\nFormat Converter\n- Specification of a DTD for the flat file\n- Mapping attributes in the flat file to elements\nand attributes in the DTD\n- Input flat filesÆ XML/RDF files by a format\nconverter\n- Example: converting PROSITE flat file to XML\nfile\n\nSingapore-MIT Alliance\n\nSingapore-MIT Alliance\n\nSingapore-MIT Alliance\n\nSingapore-MIT Alliance\nData Ontology\n\nSingapore-MIT Alliance\nData Ontology\n\nSingapore-MIT Alliance\nPart of Data Ontology\n\nSingapore-MIT Alliance\nData Loading & Warehouse\n- Loading approaches:\n- Store and query XML\nusing RDBMS?\n\nSingapore-MIT Alliance\nData Loading & Warehouse\n- Loading approaches:\n- Store and query XML\nusing RDBMS?\n- New architecture to\nstore and query\nXML/RDF?\n\nSingapore-MIT Alliance\nData Loading & Warehouse\n- Loading approaches:\n- Store and query XML\nusing RDBMS?\n- New architecture to\nstore and query\nXML/RDF?\n\nSingapore-MIT Alliance\nissues\n- Updates in source database\n- Changes in warehouse maintainance\n- Versions of software for converting and\nloading data\n\nSingapore-MIT Alliance\nReferences\nFlorescu et.al, Storing and Querying XML Data using an RDBMS, Bulletin of\nthe IEEE Computer Society Technical Committee on Data Engineering 1999\nStein, Integrating Biological Databases, Nature reviews genetics, volume 4,\n2003, 337-345\nDavidson et al, The Kleisli Approach to Data Transformation and Integration,\nBroekstra et al, Sesame: A Generic Architecture for Storing and Querying RDF\nand RDF Schema\nWilkinson et al, Efficient RDF Storage and Retrieval in Jena2\nHorridge, A Practical Guide To Building OWL Ontologies Using The Prot eg e-\nOWL Plugin and CO-ODE Tools, 2004\nXML document-to-RDBMS reference implementation setup instructions\nVersion 2.0, 2003\n\nSingapore-MIT Alliance\nTHANK YOU\n\nSingapore-MIT Alliance\nTraDES\n-\nTraDES (Trajectory Directed Ensemble\nSampling)\n-\nBeing composed to sample\nconformations of Pro-rich non-globular\ndomains\n-\nTo analyze statistically the accessibility\nof kinases or other binding proteins on\nsuch domains\n-\nTo output conformations of pro-rich\nnon-globular domains that are most\naccessible\nImages removed due to copyright restrictions.\nSee http://www.blueprint.org/Home/trades."
    },
    {
      "category": "Resource",
      "title": "Design and Implement a Biological Pathway Interaction Database (PID) System",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/61a53e17c274267fd59689ecf27aed25_assignment1.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n2.771J BEH.453J HST.958J Biomedical Information Technology\n\nDESIGN AND IMPLEMENTATION OF BIOLOGICAL PATHWAY\nINTERACTION DATABASE SYSTEM (PID)\n\n1. BACKGROUND\n\n1.1\nObjectives\n\nUpon completion of the assignment, the student should be able to:\n\n-\nConstruct an enhanced entity relationship model at a conceptual level\n-\nMap the model into a relational database system\n-\nImplement the given schema on a relational DBMS\n-\nUse a database language for manipulating and querying the data\n\n1.2\nNature of Assignment\n\nThis is an individual assignment. Discussion is allowed. However, submissions must\nbe your original work. Plagiarism will be heavily penalized.\n\n1.3\nHardware and Software Resources\n\nMachines\nDBMS\nParticipant's laptop\nPostgreSQL server\n\n1.4\nIntroduction\n\nThe assignment covers the portion of the course concerning data modelling, data-\nbase design and implementation. However, you are encouraged to include aspects\nfor improving the efficiency, presentation etc.\n\nThe overall aim of the assignment is to develop an application based on a given data\nmodel using a chosen database management system. This exercise will bring you\nthrough the crucial first part of the life cycle of a database application. The PID\ndatabase will be used as a case study. The assignment is made up of 2 components\n(Part A and Part B).\n\nPart A involves:\n-\nconstructing the Entity-Relationship (ER) model for PID\n\nPart B involves:\n-\nmapping the ER model to a relational database schema\n-\nimplementing the database using PostgreSQL. Data for populating the\ndatabase are adapted from the Syndecan-1-mediated signaling events\npathway in PID.\n-\nconstructing SQL query statements\n\n(c) H.E. Chua, 2008 Page 1/4 2.771J BEH.453J HST.958J/Fall 2008\n\n2.771J BEH.453J HST.958J Biomedical Information Technology\n\n2. DESCRIPTION OF THE ASSIGNMENT\n\nThe description of the application is given in the appendices. This includes the back-\nground and general requirements of the application, conceptual information about the\nsystem and a list of queries that must be fulfilled as a minimum.\nAll submissions must be type-written. That is, no hand written solution will be\naccepted.\n\n2.1\nPart A: Creating an ER Diagram\n\nThe appendices give conceptual information about the database requirements. Based\non the provided information, construct a suitable ER diagram.\nThe followings are required to be submitted to the stellar website by September 30th,\n2008 (12 AM Singapore Time).\n\n3⁄4 ER Diagram\n3⁄4 Semantic description of the attributes, entity-sets and relationships in your\ndiagram\n3⁄4 Any assumptions made for your design\n3⁄4 Indicate all the feature(s)/specification(s) (if any) that CANNOT be captured\nby ER-diagram.\n\nSubmission\nmust\nbe\nnamed\nin\nthe\nfollowing\nconvention:\n<FamilyName>_HW1A.<FileFormat>\n\n2.2 Part B: Mapping of the ER Diagram onto Relations and Implementation of\nthe Schema\n\nThe ER diagram (your solution) is to be mapped onto relations (tables). Follow the\ngeneral guidelines covered during the lectures to produce suitable tables. The\nsolution must clearly state the primary and foreign keys, the data type, the integrity\nconstraints, additional constraints etc. It is expected that you submit your definition in\ntextual form, e.g.\nCREATE TABLE name (\nattr1 Datatype NOT NULL,\nattr2 Datatype,\n...\nPRIMARY KEY (attr1),\nFOREIGN KEY (attr3) REFERENCES name(attr1)\nON DELETE ... ON UPDATE ...,\n\n);\nA graphical representation of your solution can be submitted in addition, however, this\ncannot substitute the textual schema definition.\nSolve the laboratory task by using the PostgreSQL Server - no other programs and\nsubmission\ntypes\nare\nallowed.\nThe\nPostgreSQL_Mini_Installation_User_Guide.doc provides you with additional\ninformation.\n\nThe schema has to be implemented in the provided relational DBMS, i.e. queries, and\nconstraint have to be created. Make full use of the DBMS's features to implement\ndata integrity requirements (such as primary, foreign keys and unique constraints).\nYour database should be populated with data (Data_Adapted_From_PID.xml)\nadapted from the Syndecan-1-mediated signalling events pathway in Pathway\nInteraction Database (PID) for the demonstration of the DBMS with respect to the\nqueries, constraints etc.\n(c) H.E. Chua, 2008 Page 2/4 2.771J / 20.453J / HST.958J/Fall 2008\n\n2.771J BEH.453J HST.958J Biomedical Information Technology\n\nCourse participants in Singapore are expected to demonstrate your project.\nInformation regarding the demonstration will be provided at a later date. During the\ndemo session, it is expected that:\n\n-\nNew queries can be written and produce satisfying results.\n-\nQuestions regarding the design and related issues can be answered\nappropriately.\n-\nThe proper working of the DBMS is demonstrated.\n\nCourse participants in MIT are expected to submit the database implementation file\n(.backup) and the query implementation file (.sql) for the following queries:\n-\nQuery 1: Count the number of interactions involved in \"Syndecan-1-mediated\nsignaling events\" pathway (Pathway ID: 200036)\n-\nQuery 2: List the molecule_ID, name, EntrezGene_ID and UniProt_ID of the\nproteins with aliase \"SYND1\"\n\n-\nQuery 3: List the names and molecule_ID of complexes having protein with\nUniProt_ID \"O14936\" as its component.\n\n-\nQuery 4: List all the references providing physical interaction inference\nsupport (Evidence: IPI) for \"Syndecan-1-mediated signaling events\" pathway\n(Pathway ID: 200036). Arrange the output in ascending order of\nreference_ID.\n\n-\nQuery 5: For pathway \"Syndecan-1-mediated signaling events\" pathway\n(Pathway ID: 200036), list the name, molecule_ID of all proteins involved in\n\"modifications\" interaction and state the interaction_ID and role of these\nproteins in these modifications interactions. Arrange the output in ascending\norder of molecule_ID followed by interaction_ID.\n\nThe followings are required to be submitted to the class website by October 9th,\n2008 (12 AM Singapore Time):\n\nAll participants (Singapore and MIT)\n3⁄4 Textual form of relational schema\n3⁄4 Semantic description of the attributes and relations\n3⁄4 Assumptions (if any)\n\nMIT participants only\n3⁄4 Database implementation in .backup file format\n3⁄4 SQL queries implementation in .sql file format\n\nSubmissions\nmust\nbe\nnamed\nin\nthe\nfollowing\nconvention:\n<FamilyName>_HW1B.<FileFormat>\n\n(c) H.E. Chua, 2008 Page 3/4 2.771J / 20.453J / HST.958J/Fall 2008\n\n2.771J BEH.453J HST.958J Biomedical Information Technology\n\nAPPENDIX A: CONCEPTUAL INFORMATION ABOUT PID\n\nThe Pathway Interaction Database (PID, http://pid.nci.nih.gov) [1, 2], created by U.S. National\nCancer Institute and Nature Publishing Group contains curated and peer-reviewed pathways\ncomposed of human molecular signaling and regulatory events and key cellular processes.\nPID seeks to address two issues affecting biological processes presentation: (1) arbitrariness\nof pathway boundaries, (2) knowledge capture at different level of details. PID has adopted a\nnetwork-level representation, similar to Reactome, HumanCyc, and KEGG. PID is focused on\nsignaling and regulatory pathways and contains only structured data which it links to. The\ndata in PID are from several sources: (1) highly curated \"NCI-Nature Curated\" collection of\npathways, (2) Reactomes, (3) BioCarta.\n\nPID: The Pathway Interaction Database.doc is a publication regarding the PID. The\npublication provides the description and requirements of the database. The provided\ninformation may be incomplete. You may wish to visit the PID website provided above for\nmore information regarding PID. You may specify additional assumptions to address\ninconsistencies or missing information. These assumptions should be clearly specified in your\nsubmission.\n\nReferences\n1.\nKrupa, S., et al., An Introduction to the NCI Pathway Interaction Database. 2006.\n2.\nSchaefer, C.F., et al., PID: The Pathway Interaction Database. 2008, Nature\nPrecedings.\n\nAPPENDIX B: QUERIES (MINIMUM REQUIREMENT)\n\n1. Count the number of interactions involved in \"Syndecan-1-mediated signaling events\"\npathway (Pathway ID: 200036)\n\n2. List the name, ID and type of all the molecules involved in \"Syndecan-1-mediated\nsignaling events\" pathway (Pathway ID: 200036).\n\n3. List the name and ID of all the interactions that \"Syntenin\" is involved in.\n\n4. List the name, ID and modification of all the components in complex \"Syndecan-\n1/HGF/MET\"\n\n5. Find the name, ID and role of all the molecules involved in modification interaction\nwith interaction_ID 201725.\n\n(c) H.E. Chua, 2008 Page 4/4 2.771J / 20.453J / HST.958J/Fall 2008"
    },
    {
      "category": "Resource",
      "title": "Instructions for the Term Paper",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/c32efc7fc0b0d2570b59f4b3cbec6cfe_termpaper_instr.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n2.771J 20.453J HST.958J SMA5304 Biomedical Information Technology\nFall, 2008\nBiomedical Information Technology\n2.771J 20. 453J HST.958J SMA 5304\nFall 2008\nInstructions for the Term Project\nEach student in the course is required to present a term project that illustrates\nthe use of the course material in a real information technology case in biology or\nmedicine. The actual content of the case can vary depending upon the student's\ninterests and existing skills. Projects can range from general studies of a class of\nproblems and the recommendation of a solution to detailed implementations in\nrunning software.\nPreliminary Project proposals should be submitted using email by Tuesday,\nOctober 18 to the respective faculty on your side of the Pacific. Microsoft Word\ndocuments are preferred because they can be easily edited electronically. If that\nis not possible, use a PDF format. These proposals will be read and approved\nduring the period October 20-30, with any required changes being negotiated\nusing email during that time. Please use email during the week of October 13 if\nyou have any questions regarding suitability of the chosen topic, etc. In the\ncover sheet of your proposal, please list:\n- Your name\n- Your email\n- The title of your proposal\n- One to three paragraphs describing the project and your\nrationale for choosing it\nYou may wish to include more than these elements to illustrate some of the\nimplementation thoughts you have. Diagrams are often useful.\nThe project should be realistically scaled to represent 36-40 hours of work, i.e.\nabout 9-10 hours of work for the four weeks between October 30 and November\n20. You will be required to turn in a report on your work and also to present a 30\nminute talk to the class on your results on December 2, 4, or 9. Those days we\nwill schedule additional hours to hold all of the presentations. Depending on\nbroadcast availability, you may not be able to present your project simultaneously\nin Cambridge and Singapore.\nHere are some examples of topics that might give you a flavor for what is\nexpected:\n1. An information object definition for biological data produced in a\nFACS experiment. (FACS = Fluorescence Activated Cell Sorting).\nProject would require going to someone doing these experiments and\n(c) 2008 C. F. Dewey, Jr., MIT\n\n2.771J 20.453J HST.958J SMA5304 Biomedical Information Technology\nFall, 2008\ncompiling a view of the information required to completely characterize the\nresults. This should be compared with the existing standards that have\nbeen proposed for FACS.\n2. A system for adding genetic data to other experimental data in a\nclinical trial. The rationale here is that the patient's test results should be\ncorrelated with individual genetic information and that information used to\nsee if genetic factors affect the test results. What data would be useful to\ncompile? What are the queries that one would like to run against the\ndata? Can you build a demonstrator?\n3. An extension to the DICOM standard to accommodate the use of\nmicrobubbles as a contrast agent in ultrasound. This will require\nsome background work to understand the DICOM standard.\n4. A general review of the National Cancer Institute program supported\nby the Center for Bioinformatics. This program supports a large\nnumber of innovative efforts in bioinformatics. See\nhttp://ncicb.nci.nih.gov/. This could involve a serious critique of what is\ndone right and what is done wrong, as you have learned it in this course.\n5. Design of a system to anticipate the physical results of breast cancer\nsurgery. It was suggested at a recent NIH meeting that a system to help\nbreast cancer patients anticipate the effects of forthcoming surgery would\nbe emotionally and psychologically helpful because it would take away\nsome of the fear of the unknown. How would such a system be designed\nand what would be its attributes?\n6. How would one make a personal human genome viewer? Suppose\nwe have the DNA profile (whatever that is) for a person. How would that\nperson use that profile intelligently to, for example, run their profile against\nthe known risk of contracting specific diseases?\n7. Work flow scenarios for accessing stored biological data. Obtain and\ndocument real work flow scenarios where biologists use experimental data\nand data queried from existing genetic and proteomic databases. How\ndoes the type of data depend on the query? Do the data drive the query?\nDo the results of the query (or subsequent manipulation of the returned\ndata) produce a subsequent query (iteration)? Something relating to web\nservices would be very attractive.\nInstructions for the Presentation and Report\nThe most important deliverable for the Term Paper is the oral presentation that\nwill occur December 2, 4, or 9 depending on when you are scheduled. This\npresentation should be scheduled for no longer than 20 minutes with 5 minutes\nof questions and 5 minutes between presentations. Class hours on those days\nmay be extended a bit to allow all of the class to present. We will issue the final\nschedule by the end of November.\nIn addition to the oral presentation, you should turn in Microsoft Word/Powerpoint\ndocuments that contain your slides and a synopsis of your presentation for each\nslide. To make this easy, you can use the \"Lecture Notes\" feature of PowerPoint\nand simply write out your presentation and then it is easy to edit the description\n(c) 2008 C. F. Dewey, Jr., MIT\n\n2.771J 20.453J HST.958J SMA5304 Biomedical Information Technology\nFall, 2008\nand the slides in a single stand-alone Powerpoint document. (This can also be\nvery helpful in practicing your presentation.) The documents are due on\nDecember 10, the last official day of classes for the Fall term at MIT.\n(c) 2008 C. F. Dewey, Jr., MIT"
    },
    {
      "category": "Resource",
      "title": "Nux Tutorial",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/c6317b4b8dbd94b579b29adc381986cd_nux_tutorial.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nNux Tutorial\nd and extract nux-1.6.zip to D:/nux.\nject properties window by selecting Properties from Project menu\nProject->Properties)\nuild Path, go to the Libraries tab1.\n\n1. Downloa\n2. Open pro\n(Menu->\n3. In Java B\n\n4. Click Add External JARs and add all jars in D:/nux/lib. Your build path should look like\nthis:\n\n1 For screenshots copyright, see statement at the end of the document.\n\nBSD license statement has added to the document, per http://acs.lbl.gov/nux/license.html\n\n5. Expand Referenced Libraries in Package Explorer panel to see the classes and packages\nin the added Nux libraries.\n\n6. Create NuxTutorial class and add the code shown below (adapted from official Nux\ntutorial). Note the errors.\nBSD license statement has added to the document, per http://acs.lbl.gov/nux/license.html\n\n7. Next, we determine which libraries to \"import\". Browse the Referenced Libraries\npackages to see where the classes are found. The class ResultSequenceSerializer, for\nexample, is found in nux.xom.xquery.\n8. After fixing all the \"import\" errors, you should get the following:\n\n9. Use a text editor to save this XQuery in D:/nux/q1.xq:\n<bib>\n{\nfor $b in doc(\"D:/nux/samples/data/books.xml\")/BOOKLIST/BOOKS/ITEM\n\nwhere $b/AUTHOR = \"Danzig\"\n\nreturn\n<book>\n{ $b/TITLE, $b/AUTHOR, $b/PRICE }\n</book>\n}\n</bib>\n\n10. Run the program and should get the following output:\n\nCopyright statement for Nux screenshots:\nNux software: Copyright (c) 2005, The Regents of the University of California, through Lawrence Berkeley National Laboratory (subject to\nreceipt of any required approvals from the U.S. Dept. of Energy). All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are\nmet:\n(1) Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n(2) Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the\ndocumentation and/or other materials provided with the distribution.\n(3) Neither the name of the University of California, Lawrence Berkeley National Laboratory, U.S. Dept. of Energy nor the names of its\ncontributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR\nIMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR\nCONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER\nIN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF\nTHE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nYou are under no obligation whatsoever to provide any bug fixes, patches, or upgrades to the features, functionality or performance of the\nsource code (\"Enhancements\") to anyone; however, if you choose to make your Enhancements available either publicly, or directly to\nLawrence Berkeley National Laboratory, without imposing a separate written license agreement for such Enhancements, then you hereby\ngrant the following license: a non-exclusive, royalty-free perpetual license to install, use, modify, prepare derivative works, incorporate into\nother computer software, distribute, and sublicense such enhancements or derivative works thereof, in binary and source code form."
    },
    {
      "category": "Resource",
      "title": "Parsing and querying XML documents",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/41be07601fb68d561c95cb73de258b08_assignment2.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n2.771J / 20.453J / HST.958J Biomedical Information Technology\n\nPARSING AND QUERYING XML DOCUMENTS\nASSIGNMENT II\n\n1. BACKGROUND\n\n1.1\nObjectives\n\nUpon completion of the assignment, the student should be able to:\n\n-\nDevelop Java programs to parse XML documents using SAX\n-\nUnderstand the schema of SBML and RDF-based markup languages\n-\nUse XQuery to query XML documents through Nux Java API\n\n1.2\nIntroduction\n\nThe aim of this assignment is to develop a program that parses XML documents and\nanswer queries on the documents using Java and XQuery. Submissions must be original\nwork.\n\n1.3\nPrerequisites\n\nBasic knowledge in Java programming is required (See Appendix A).\n\n2. DESCRIPTION OF ASSIGNMENT\n\nBioModels (http://www.ebi.ac.uk/biomodels-main/) is a repository of mathematical models\nof biological interests. Models are stored under SBML format\n(http://sbml.org/More_Detailed_Summary_of_SBML), which is encoded in XML.\n\nDownload the following models from BioModels:\n\n3⁄4 Kholodenko1999_EGFRsignaling\nhttp://www.ebi.ac.uk/biomodels/models-main/publ/BIOMD0000000048.xml\n\n3⁄4 Sasagawa2005_MAPK\nhttp://www.ebi.ac.uk/biomodels/models-main/publ/BIOMD0000000049.xml\n\n2.1\nUsing Java to parse and query XML documents\n\nWrite a Java program to parse the above documents and answer the below queries:\n\na. List all species that exists in both models\nb. List the 10th reaction in both models according to document order.\nc. In Sasagawa2005_MAPK, list all reactions that involves the species\n\"MEK\" or \"SOS\"\nPrepared by Boon-Siew Seah\n\n2.771J / 20.453J / HST.958J Biomedical Information Technology\n\nd. In Sasagawa2005_MAPK, list all reversible reactions. For each\nreaction, show the Uniprot ids of the reactants and products\ne. For both documents, list all species that are involved in more than 3 reactions\n\nYou must use the SAX API (see Appendix B) to process the XML documents. Write a\nJava method to process each query without using XPath/XQuery. You may either print\nthe answers on the screen or store them as XML documents.\n\nSubmit the following to the course website:\n\n3⁄4 Java source code\n3⁄4 A brief explanation of your algorithm\n\n2.2\nUsing XQuery\n\nNux (http://acs.lbl.gov/nux/index.html) is a Java toolkit that allows one to run XQuery\nqueries on XML documents. Write a Java program to answer queries (a) to (e) in Section\n2.1 using XQuery. Refer to http://acs.lbl.gov/nux/index.html and Nux documentation to\nlearn how XQuery can be processed using Nux Java API. You may either print the\nanswers on the screen or store them as XML documents.\n\nSubmit the following to the course website:\n\n3⁄4 Java source code\n3⁄4 XQuery file for each query\n3⁄4 A brief explanation of your algorithms\n\n3. APPENDIX A: JAVA PROGRAMMING GUIDES\n\nThe fundamentals of Java can be found at http://java.sun.com/docs/books/tutorial/java/index.html.\nSee http://java.sun.com/docs/books/tutorial/getStarted/cupojava/win32.html for a brief tutorial on how\nto install Java SE Development Kit (JDK), compile a simple Java source file, and run it.\nDownload Eclipse IDE (http://www.eclipse.org), which simplifies the coding/compiling process.\n\nJava developer checklist:\n3⁄4 Java Runtime Environment (http://java.com/en/download/manual.jsp)\n3⁄4 Java SE Development Kit 6.0 (http://java.sun.com/javase/6/download.jsp )\n3⁄4 Eclipse IDE (http://www.eclipse.org/downloads/)\n\n4. APPENDIX B: SAX PARSER GUIDES\n\nTutorials on SAX Java API can be found at http://developerlife.com/tutorials/?p=29 and\nhttp://www.ibm.com/developerworks/edu/x-dw-xusax-i.html.\n\nPrepared by Boon-Siew Seah"
    },
    {
      "category": "Resource",
      "title": "PID: The Pathway Interaction Database",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/3f4317a6e1fa9a2a91ebba8694717f5c_pid_schaefer.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nPID: The Pathway Interaction Database\nCarl F. Schaefer1, Kira Anthony2, Shiva Krupa3, Jeffrey Buchoff4, Matthew Day2, Timo Hannay2,\nKenneth H. Buetow1\n1National Cancer Institute, Center for Biomedical Informatics and Information Technology\n2Nature Publishing Group\n3Novartis Institutes for Biomedical Research, Inc., Novartis Knowledge Center\n4SRA International, Inc., Health Research and Informatics\n\nKEYWORDS: pathway, database, cell signaling, signal transduction\n\nThis document is licensed to the public under the Creative Commons Attribution 3.0 License .\n\nABSTRACT\nThe Pathway Interaction Database (PID, http://pid.nci.nih.gov) is a freely available collection of\ncurated and peer-reviewed pathways composed of human molecular signaling and regulatory\nevents and key cellular processes. Created in a collaboration between the U.S. National Cancer\nInstitute and Nature Publishing Group, the database serves as a research tool for the cancer\nresearch community and others interested in cellular pathways, such as neuroscientists,\ndevelopmental biologists, and immunologists. PID offers a range of search features to facilitate\npathway exploration. Users can browse the predefined set of pathways or create interaction\nnetwork maps centered on a single molecule or cellular process of interest. In addition, the\nbatch query tool allows users to upload long list(s) of molecules, such as those derived from\nmicroarray experiments, and either overlay these molecules onto predefined pathways or\nvisualize the complete molecular connectivity map. Users can also download molecule lists,\ncitation lists and complete database content in extensible markup language (XML) and\nBiological Pathways Exchange (BioPAX) Level 2 format. The database is updated with new\npathway content every month and supplemented by specially commissioned articles on the\npractical uses of other relevant online tools.\nINTRODUCTION\nThe Pathway Interaction Database (PID, http://pid.nci.nih.gov) is a growing collection of human\nsignaling and regulatory pathways curated from peer-reviewed literature and stored in a\ncomputable format. PID was designed to deal with two issues affecting the representation of\nbiological processes: the arbitrariness of pathway boundaries and the need to capture\nknowledge at different levels of detail. Pathway boundaries are often arbitrary and overlapping:\ndifferent biologists might include different biochemical interactions in, for example, \"the p53\nsignaling pathway\"; and it is not unusual for two pathways representing distinct processes to\nhave one or more interactions in common. This fuzziness simply reflects the fact that terms like\n\"the p53 signaling pathway\" and \"the BCR signaling pathway\" are high-level concepts of\nconvenience, designating slices through the very complex mix of concurrent processes in the\ncell. An important goal of PID is to provide an operational definition of high-level concepts like\n\"the BCR signaling pathway\" (Figure 1) in the form of predefined pathways, while at the same\ntime allowing a user to explore novel networks composed computationally from the universe of\ninteractions underlying the predefined pathways. Current knowledge of the components of any\ngiven biological process is uneven. For example, for some protein interactants the precise post-\ntranslational modifications might be known, while for other interactants perhaps the only sure\nknowledge is that the protein is \"active\". PID provides descriptive mechanisms to cover both of\nthese cases. The ability to represent information at different levels of detail is also useful in\ncommunicating generalizations. For example, it is sometimes useful to encapsulate a complex\nprocess such as cytoskeleton reorganization as a single event or to treat as a single entity a set\nof proteins such as Class 1A PI3Ks that are functionally equivalent in catalyzing a given event.\nPID has mechanisms for dealing with incomplete knowledge, for encapsulating complex events\nand for expressing generalizations.\n\nPID has adopted a network-level representation, similar to Reactome (1), HumanCyc (2), and\nKEGG (3). Like Reactome and HumanCyc, PID annotates interactions with citations to the\nliterature. PID differs from Reactome, HumanCyc, and KEGG in its focus on signaling and\nregulatory pathways; it does not attempt to cover metabolic processes or generic mechanisms\nlike transcription and translation. PID contains only structured data and it links to but does not\nreproduce molecular information readily available from other sources, such as nucleotide or\namino acid sequence, molecular weight, and chemical formula. The principal source of data in\nPID is the highly curated \"NCI-Nature Curated\" collection of pathways, but PID also includes two\nother sources of data: data imported into the PID data model from Reactome's Biological\nPathways Exchange (BioPAX) Level 2 (4) export, and an import of information from the\nBioCarta collection of pathways (Table 1). All data in PID is freely available, without restriction\non use. Bulk downloads are available in BioPAX Level 2, a standard format for exchanging\npathway information, and a PID-specific XML format at\nhttp://pid.nci.nih.gov/PID/download.shtml.\nDATA MODEL\nIn PID, an interaction is an event with its participating molecules and conditions. A PID pathway\nis a network of these events connected by the participant molecules. PID recognizes four kinds\nof molecules: small molecules (called compounds), RNA, proteins, and complexes. PID\nrecognizes five kinds of events: gene regulation (called transcription, but encompassing both\ntranscription and translation), molecule transport (called translocation), small-molecule\nconversion (called reaction), protein-protein interactions (called modification), and black-box\nprocesses whose internal composition is not provided (called macroprocesses). In addition, an\nentire pathway can be abstracted and used as a single event in another pathway. As a\nparticipant in an event, a molecule may have one of four roles: input, output, positive regulator,\nand negative regulator. These roles define simple relations: an interaction consumes its inputs\n(but not its regulators) and produces its outputs; and the inputs, positive regulators and the\nabsence of negative regulators are jointly the necessary and sufficient causes of the interaction.\nEach molecule in PID has a defining entity, called a basic molecule. Basic molecules are\ndistinguished by their nucleotide or amino acid sequence (for macromolecules) or by their\nchemical formula (for small molecules). While PID does not record the sequence of a\nmacromolecule or the chemical formula for a small molecule, each protein or RNA is associated\nwith a UniProt or Entrez Gene accession and most small molecules are associated with\nChemical Abstracts Service (CAS) registry numbers. A basic molecule has a primary name and\nmay have multiple aliases. Each molecule use, as an interactant in an interaction or as a\ncomponent of a complex, references its corresponding basic molecule. Each molecule use may\nhave additional information, including post-translational modifications (for proteins) and cellular\nlocation and activity state (for all molecule types).\nA basic protein molecule has a single identifying UniProt accession associated with a particular\namino acid sequence. If the particular isoform of a protein used in an intera\nbe associated with an Entrez Gene id\nod of identifying proteins is restricted al\nction is not known,\nthen the basic protein molecule may\nentifier instead of a\nUniProt accession; in PID, this meth\nmost entirely to the\n\nuncurated section of the database imported from BioCarta. A use of a protein as a participant in\nan interaction or component of a complex may have additional attributes: post-translational\nmodifications, an abstract activity-state attribute, and a cellular location attribute. Currently, PID\nuses 13 types of post-translational modifications, with phosphorylation being by far the most\nfrequently used modification (Table 2). The abstract activity-state attribute, with values such as\n\"active\" and \"inactive\", allows curators to distinguish functionally different forms of a protein\neven if the precise covalent modifications are not known. Values for the cellular location\nattribute are drawn from the Gene Ontology (GO) Cellular Component vocabulary (5). Cleaved\nsubunits of a precursor protein are not distinguished by the post-translational modification\nmechanism; rather they are treated as basic protein molecules separate from each other and\nfrom the precursor. However, PID explicitly relates the cleaved subunit to its precursor and\nrecords the cleavage coordinates when these are known. A PID protein corresponds roughly to\na BioPAX Level 3 proteinReference, while a BioPAX Level 3 protein corresponds to a PID\nprotein use (with post-translational modifications and cellular location).\nPID allows the definition of generic proteins, complexes, small molecules, and RNA molecules.\nA generic molecule is called a family, but is not restricted to the traditional protein families\ndefined by sequence similarity: any set of proteins (or other type of molecule) that are in some\nrespect functionally equivalent may be grouped in a family. Individual protein members of a\nprotein family may have post-translational modifications or activity-states. The family itself can\nbe used as a participant in an interaction, or as a component of a complex.\nBecause data are entered by multiple curators and because the database contains data from\nmultiple sources, PID needs rules for determining equivalence of molecules. Two basic\nmolecules that are neither families nor complexes are equivalent if they have the same external\ndatabase accession (e.g., UniProt or Entrez Gene), or if, in cases where neither has an external\ndatabase accession, they have the same name. Two molecule uses (as participant in an\ninteraction or component of a complex or member of a family) are equivalent if they refer to the\nsame basic molecule, and have the same (or no) post-translational modifications, and have the\nsame (or no) activity-state attribute, and have the same (or no) cellular location attribute. Two\nbasic families (or complexes) are equivalent if they have the same number of members (or\ncomponents) and if for each member (component) of one, there is an equivalent member\n(component) in the other. These rules are applied recursively to define, for example, equivalent\nuses of complexes with components that are families. Equivalence of molecule uses is the basis\non which novel networks are constructed: any two interactions in the database may be joined in\na network if one interaction has a participant that is equivalent to a participant in the other\ninteraction. Analogous rules of equivalence are implemented for interactions and entire\nnetworks, allowing equivalent (redundant) interactions to be pruned from the novel networks.\nAn interaction may be supported by one or more citations to the literature. Currently, 3233 of the\n4293 interactions in the NCI-Nature Curated data source are annotated with at least one of\n2957 unique PubMed references. In addition, an interaction may b\ncify the kind of evidence adduced in the cit\ne annotated with one or more\nevidence codes that spe\nations in support of the\ninteraction (Table 3).\n\nA predefined pathway is a curated pathway representing a known biological process. At\npresent, every pathway stored in the PID database is a predefined pathway and every\ninteraction in the database is a member of at least one predefined pathway. However, the\nsearch and retrieval tools allow the user to compose novel pathways from interactions defined in\nthe predefined pathways. This ability to recombine interactions and to thus create novel\npathways is a distinguishing feature of PID.\nDATA CURATION\nNature Publishing Group (NPG) editors create the NCI-Nature Curated pathways. Pathways\nselected for curation are based on potential drugs targets, suggestions made by users and\nreviewers, and other molecules known to be of interest to the cell signaling community. A list of\nNCI-Nature Curated pathways, along with a list of the pathways imported from Reactome and\nBioCarta, can be found on the Browse pathways page of the PID website:\nhttp://pid.nci.nih.gov/PID/browse_pathways.shtml\nIn curating, editors synthesize meaningful networks of events into defined pathways and adhere\nto the PID data model for consistency in data representation: molecules and biological\nprocesses are annotated with standardized names and unambiguous identifiers; and signaling\nand regulatory events are annotated with evidence codes and references. To ensure accurate\ndata representation, editors assemble pathways from data that is principally derived from\nprimary research publications. The majority of data in PID is human; however, if a finding\ndiscovered in another mammal is also deemed to occur in humans, editors may decide to\ninclude this finding, but will also record that the evidence was inferred from another species.\nPrior to publication, all pathways are reviewed by one or more experts in a field for accuracy\nand completeness.\nWEB INTERFACE AND APPLICATION\nPID provides several query options: a simple query, an advanced query, a connected molecules\nquery, and a batch query. In the simple query, the user provides the name, alias, or accession\nof a molecule or biological process; wildcarding is permitted. The query will return a list of all\nuses of the molecule, as simplex or as participant in a complex, and all uses of the biological\nprocess, in the database, with hyperlinks to visualizations of the relevant predefined pathways\ncontaining the queried entities. The user also has the option to visualize the novel network(s)\nthat include all interactions using the queried entities. The advanced query allows the user to\nconstruct the set of novel networks from interactions that (a) involve any of a set of user-\nspecified molecules, or (b) are part of any predefined pathway whose name includes a user-\nspecified key word, or (c) have a user-specified GO Biological Process term or National Cancer\nInstitute (NCI) Thesaurus (6) term as their event type or condition. An\nn for including interactions that are im\nctions retrieved by molecule, pathway\nd molecules query allows a user to fin\ns specified by name, alias, or accessi\norks satisfying the constraint, but the o\nimportant feature of the\nadvanced query is the provisio\nmediately upstream or\ndownstream of the set of intera\nname, or GO/NCI\nThesaurus term. The connecte\nd a novel network that\nconnects two or more molecule\non. The query will find only\none of the possibly many netw\nne found will have the\n\nminimum number of interactions. Finally, the batch query allows a user to upload one or two\nlists of molecule identifiers (name, alias, or accession). The user has two options: to analyze the\nnumber of molecules in the lists that \"hit\" each predefined pathway or to construct the novel\nnetwork(s) that include all interactions using any of the listed molecules. For the first option, the\nquery uses a hypergeometric distribution to compute the probability that each pathway in the\ndatabase is hit by molecules in either of the lists. The query returns a list of pathways ordered\nby P-value. In the visualization of a predefined pathway (first option) or novel pathway (second\noption), molecules from the first list are colored blue, molecules from the second list are colored\nred, and any molecules appearing in both lists are colored purple. Supplementary Figure 1\npresents an example of invoking the batch query with a single molecule list, the 120 protein\nkinases found by Greenman et al. (7) to have at least one cancer-predisposing mutation.\nSelecting the predefined pathways option, one can see that this list samples a small number of\npathways, biased toward immune cell signaling, at a P-value < 0.0001.\nWhile PID associates a single external database accession (typically a UniProt accession) with\na protein, the query interface searches PID not only by UniProt accession, but also by related\ngene identifiers (HUGO symbol, alias, Entrez Gene identifier). Any predefined pathway or novel\nnetwork can be visualized in either GIF (Graphics Interchange Format) or SVG (Scalable Vector\nGraphics) graphic mode. Network graphics are all automatically constructed from the underlying\ndata using the GraphViz package (8). Events and molecule uses in the graphics are hyperlinked\nto HTML pages of information about the interaction or molecule. In addition, any predefined\npathway or novel network can be exported in native PID XML or BioPAX Level 2 formats. Using\nthe BioPAX export, a user can also visualize PID pathways in Cytoscape (http://cytoscape.org)\na popular third-party network visualization tool (9). For any predefined pathway, the user can\nobtain (and export to tab-separated format) a list of literature citations and participating\nmolecules.\nDISCUSSION AND FUTURE DIRECTIONS\nPID is a highly structured, curated database of molecular interactions and events that compose\nhuman cell signaling and regulatory pathways. A particular strength of PID is the ability to create\nnovel networks that can reveal parallel alternative paths to events of interest, like activation of a\nprotein or disassembly of a complex in the DNA repair process. In cancer biology, such a view\ncan elucidate the variety of strategies that a given type of cancer may adopt, explain why a\nsingle-agent therapy is not effective, and suggest potential multi-agent therapies. Increasingly,\nmolecular networks are recognized as frameworks for integrating and interpreting experimental\ndata. For example, by using pathways as the integrating framework, The Cancer Genome Atlas\nproject has mapped genomic abnormalities of different types -- copy number, mutation, and\nmethylation - to a set of oncogenic processes (publication forthcoming). At present, most\nattempts to profile tumor subtypes have relied on DNA and RNA assays. However, as high-\nthroughput proteomic methods improve, the kind of detailed information on post-translational\nmodifications of proteins available in PID will be essential in m\napping more accurately the state\nof a cell.\n\nConsistent with its focus on interactions and events derived from curated signaling cascades\nand regulatory processes, PID does not at present include interaction data deriving from high-\nthroughput protein-protein interaction experiments. This reflects not a judgment on the quality of\nhigh-throughput data but a recognition that there are databases specifically designed to provide\naccess to this data (10, 11, 12). However, while it does not lead directly to the construction of\nsignaling cascades, information from high-throughput protein-protein interaction experiments\ncan be useful in interpreting the curated pathways and assessing their completeness. For\nexample, a high-throughput protein-protein interaction experiment can identify an unexpected\nbinding partner for a catalyst, suggesting the possibility that the in vivo presence of the partner\ncan sequester the catalyst and thus turn off downstream interactions. In the future PID will allow\nusers to take advantage of high-throughput protein-protein interaction data, either by allowing\nusers to upload interaction sets to be added to the novel networks created by PID queries or by\nquerying other data sources (such as Pathway Commons, http://pathwaycommons.org) as\nneeded to support a user query. The PID data model is currently being integrated with NCI's\nCancer Bioinformatics Infrastructure Objects model (caBIO) (13), thereby making PID data\naccessible on NCI's caGrid (14).\n\nACKNOWLEDGEMENTS\nFunding for this work was provided by the National Cancer Institute.\n\nREFERENCES\n1. Vastrik, I., D'Eustachio, P., Schmidt, E., Joshi-Tope, G., Gopinath, G., et al. (2007)\nReactome: a knowledge base of biologic pathways and processes. Genome Biology,\n8:R39doi:10.1186/gb-2007-8-3-r39.\n2. H1. P. Romero, J. Wagg, M.L. Green, D. Kaiser, M. Krummenacker, and P.D. Karp.\n(2004) Computational prediction of human metabolic pathways from the complete\nhuman genome. Genome Biology, 6:R2 R2.1-17.\n3. Kanehisa, M., Araki, M., Goto, S., Hattori, M., Hirakawa, M., Itoh, M., Katayama, T.,\nKawashima, S., Okuda, S., Tokimatsu, T., and Yamanishi, Y. (2008) KEGG for linking\ngenomes to life and the environment. Nucleic Acids Res., 36, D480-D484.\n4. Bader, G.D., Cary, M., Sander, C. (2006) BioPAX - Biological Pathway Data Exchange\nFormat. Encyclopedia of Genomics, Proteomics and Bioinformatics, John Wiley & Sons,\nLtd. DOI: 10.1002/047001153X.g408117.\n5. The Gene Ontology Consortium. (2000) Gene Ontology: tool for the unification of\nbiology. Nature Genet., 25:25-29.\n6. Fragoso G., de Coronado S., Haber M., Hartel F., Wright L. (2004) Overview and\nutilization of the NCI Thesaurus. Comp. Funct. Genomics, 5(8):648-54.\n7. Greenman C., et al. (2007) Patterns of somatic mutation in human cancer genomes.\nNature, 446;153-8.\n8. Gansner, E.R. and North, S.C. (1999) An open graph visualization system and its\napplications. Software - Practice and Experience, 00(S1), 1-5.\n9. Cline, M.S., Smoot, M., Cerami, E., Kuchinsky, A., et al. (2007) Integration of biological\nnetworks and gene expression data using Cytoscape. Nat Protoc., 2(10):2366-82.\n10. Chatr-aryamontri, A., Ceol, A., Montecchi-Palazzi, L., Nardelli, G., Schneider, M.V.,\nLuisa Castagnoli, L., and Cesareni, G. (2007) MINT: the Molecular INTeraction\ndatabase. Nucleic Acids Res., 35(Database issue):D572-D574; doi:10.1093/nar/gkl950.\n11. Hermjakob, H., Montecchi-Palazzi, L., Lewington, C., Mudali, S., Kerrien, S., Orchard,\nS., Vingron, M., Roechert, B., Roepstorff, P., Valencia, A., et al. (2004) IntAct: an open\nsource molecular interaction database. Nucleic Acids Res., 32:D452-455.\n12. Breitkreutz, B.J., Stark C., Reguly, T., Boucher, L., Breitkreutz, A., Livstone, M.,\nOughtred, R., Lackner, D.H., Bahler, J., Wood, V., Dolinski, K., Tyers, M. (2008) The\nBioGRID Interaction Database: 2008 update. Nucleic Acids Res, .Jan;36(Database\nissue):D637-40.\n\n13. Covitz, P.A., Hartel, F., Schaefer, C., De Coronado, S., Fragoso, G., Sahni, H.,\nGustafson, S., Buetow, K.H. (2003) caCORE: a common infrastructure for cancer\ninformatics. Bioinformatics, Dec 12;19(18):2404-12.\n14. Oster, S., Langella, S., Hastings, S., Ervin, D., Madduri, R., Phillips, J., Kurc, T.,\nSiebenlist, F., Covitz, P., Shanbhag, K., Foster, I., Saltz, J. (2008) caGrid 1.0: an\nenterprise Grid infrastructure for biomedical research. J. Am. Med. Inform. Assoc., Mar-\nApr;15(2):138-49.\n\nFIGURE\n\nFigure 1. BCR signaling pathway: The pathway header information includes the date of the\nlatest revision; the data curation or import source; the curator; the reviewers; the stable pathway\nidentifier; links to a pathway-specific molecule list and a pathway-specific references list; and\nlinks to pathway graphic and text data exchange format options.\n\nTABLES\n\nNCI-\nNature\nCurated\nReactome\nImported\nBioCarta\nImported\npathways\nsubpathways\ninteractions\nProteins\nsmall\nmolecules\ncomplexes\n\nTable 1: Summary of all data sources\n\nModification Type\nAll\nUses\nUnique\nModifications\nacetylation\nfarnesylation\ngeranylgeranylation\nglycosaminoglycan\nglycosylation\nhydroxylation\nmethylation\nmyristoylation\noxidation\npalmitoylation\nphosphorylation\nsumoylation\nubiquitination\nTable2: Post-translational modifications in NCI-Nature Curated data source\n\nCode Evidence Kind\nUses\nIAE\nInferred from Array Experiments\nIDA\nInferred from Direct Assay\nIEP\nInferred from Expression Pattern\nIFC\nInferred from Functional\nComplementation\nIGI\nInferred from Genetic Interaction\nIMP\nInferred from Mutant Phenotype\nIOS\nInferred from Other Species\nIPI\nInferred from Physical Interaction\nRGE\nInferred from Reporter Gene\nExpression\n\nTable 3: Evidence in NCI-Nature Curated data source\n\nSUPPLEMENTARY DATA\n\nSUPPLEMENTARY FIGURE LEGEND\nSupplementary Figure 1. Batch query: The Batch query allows users to upload long list(s) of\nmolecules identifiers (name, alias, or accession) and analyze the distribution of the molecules\nwithin predefined pathways (first option) or construct the complete set of network maps from\ninteractions using any of the molecules (second option). Two lists can be uploaded\nsimultaneously in order to compare data sets (e.g. genomic copy number alterations and\nsomatic mutations). For the first option, the query uses a hypergeometric distribution to compute\nthe probability that each pathway in the database is hit by molecules in either of the lists. The\nquery returns a list of pathways ordered by P-value. In the example in the figure a list of 120\nprotein kinases containing at least one cancer-predisposing mutation (Greenman C., et al.\n(2007) Patterns of somatic mutation in human cancer genomes. Nature, 446;153-8) was\noverlaid on the predefined pathways. The table below shows that this list of kinases samples 10\npredefined pathways at a probability of P < 0.0001. A number of these pathways involve\nimmune cell signaling."
    },
    {
      "category": "Resource",
      "title": "PostgreSQL Mini Installation User Guide",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/b3f88920ed478e705bc52babbefc5b5c_postgresql_user_.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 1\nDownloading and installation of PostgreSQL\n(Note: follow the PostgreSQL installation instruction from http://www.postgresql.org/download/. This\ndocument provides a summary of the installation process on the Windows XP system.)\n1) Download the installation package of PostgreSQL from http://www.postgresql.org/download/\n2) Install PostgreSQL\n\nYou will see several screens like the ones below1:\n(1) Service configuration\n\nEnter a password of your choice\nThe \"Account error\" dialog box will pop out\nthe first time the service is configured.\nClick \"Yes\" to continue the installation\n\n1 See license statement at the end of this document.\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 3\n(2) Initialize database cluster\n\n(3) Set up procedural languages\n\nEnter a password of your choice. This will be the\npassword for connecting to the local database\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 4\n(4) Set up modules\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 5\n(5) Complete the installation\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 6\nUsing PostgreSQL\nAdditional documentations can be found in http://www.postgresql.org/docs/ .\n\n1) Start pgAdmin III and double-click on PostreSQL Database Server 8.3\n\nEnter the password you set for\n\"Initialize database cluster\"\n2) Create PID database\n\nRight-click on \"Databases\" and select \"New\nDatabase...\" in the pop-up dialog\n\nBSD license statement has added to the document, per http://www.postgresql.org/about/licence\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 7\n\nEnter \"PID\" as the name of the database\n3) Create tables\n\nRight-click on \"Tables\" and select \"New Table...\"\nin the pop-up dialog\n\nBSD license statement has added to the document, per http://www.postgresql.org/about/licence\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 8\n\nEnter the table name\n\n4) Select data type\n(e.g. integer, text,\nBoolean, etc.) for this\ncolumn\n3) Enter column name\n2) Click on \"Add\" to add a new\ncolumn and edit the details for\nthe column\n1) Click on \"Columns\" tab to\nstart adding new column to the\ntable\n\nBSD license statement has added to the document, per http://www.postgresql.org/about/licence\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 9\nSetting primary key, foreign key and unique constraints\n\nPrimary key column should be\nset to non-null\n\n1) Select \"Constraints\" tab\n4) Click on \"Columns\" tab. Select the columns\nto be included in the constraint.\nMore than 1 column can be selected if required\n2) Select types of constraints\n(primary key, foreign key, or\nunique constraints)\n3) Click on \"Add\" to set the\nconstraints. \"New Primary\nKey...\" dialog will pop up\n\nBSD license statement has added to the document, per http://www.postgresql.org/about/licence\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 10\n4) Populate tables\n\n2) Click on this button to edit data in the selected table\n1) Select the table to populate\n3) Populate or edit the values in the table\n5) Save/restore the database information\ns\n1) Right-click on the database you want to save and select\n\"Backup...\" in the pop-up dialog\nFor restoring a backup file, select \"Restore...\" instead\n\nBSD license statement has added to the document, per http://www.postgresql.org/about/licence\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 11\n\n1) Click on the browse button in \"Backup Database\"\ndialog box to select where you want to backup the\nfile\n2) Save the backup file in the following format\n<FamilyName>_HW<AssignmentNumber>\nE.g. Chua_HW1B\n6) Construct SQL query\n\n1) Click on SQL button\n3) Run SQL query\n2) Enter SQL query\n\nBSD license statement has added to the document, per http://www.postgresql.org/about/licence\n\nPostgreSQL Mini Installation User Guide\n\n(c) H.E. Chua, 2008\nPage 12\n\nCopyright statement for PostgreSQL screenshots:\nPermission to use, copy, modify, and distribute this software and its documentation for any\npurpose, without fee, and without a written agreement is hereby granted, provided that the\nabove copyright notice and this paragraph and the following two paragraphs appear in all\ncopies.\n\nIN NO EVENT SHALL THE UNIVERSITY OF CALIFORNIA BE LIABLE TO ANY PARTY FOR DIRECT,\nINDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING LOST PROFITS,\nARISING OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF THE\nUNIVERSITY OF CALIFORNIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nTHE UNIVERSITY OF CALIFORNIA SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT\nNOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE. THE SOFTWARE PROVIDED HEREUNDER IS ON AN \"AS IS\" BASIS, AND\nTHE UNIVERSITY OF CALIFORNIA HAS NO OBLIGATIONS TO PROVIDE MAINTENANCE, SUPPORT,\nUPDATES, ENHANCEMENTS, OR MODIFICATIONS."
    },
    {
      "category": "Lecture Notes",
      "title": "Unifying Electronic Medical Records (EMR) Systems in Singapore",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/dc852d84a2d81aa372974c4c58cd668d_termpaper_sample.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nName: Chua Huey Eng\nTitle: Unifying Electronic Medical Records (EMR) Systems in Singapore\nRationale:\nIn Singapore, as the number of people hitting the 60s and above increase, the load on the healthcare\nsystem in Singapore will become heavier. There is a need to address this issue to ensure that the\nlevel of healthcare provided is maintained and even improved. Having a unified EMR will help to\nachieve this. The EMR also has the potential of helping the research community gather clinical data.\nIn addition, with globalization, interoperability of EMR systems in different countries can allow\npatients to seek treatment overseas with the assurance that the proper medical records and history\nare available for physicians and medical experts regardless of their geographic locations.\nA unified EMR can help improve patient's healthcare experience and provide a more consistent\nhealthcare delivery, especially for patients having chronic illnesses. With a unified EMR, in situation\nwhere a patient is delivered into the Accident & Emergency department, the doctors can get\naccurate and up-to-date medical record (including drug allergies, long-term medication etc) of the\npatient which would help to make better decision in the type of treatment to be given. The\navailability of such records would also help those who require long-term care. The care givers might\nchange in the course of the patients' life (e.g. after being treated in the hospital, the patients could\nbe discharged, but need follow up with his general practitioner). The EMR will provide subsequent\ncare givers about the type of medication and care plan given by the previous care givers.\nThe public health sector in Singapore is already quite well connected via the EMR exchange system\n(EMRX). The push now is to ensure that the rest of the private health sector is connected up with the\npublic health sector. (1-4)\nThis project will examine the current situation of EMR implementation in Singapore, identify the\npotential challenges of implementing a unified EMR system in Singapore and propose possible\napproach to tackle these challenges.\nScope:\n1. Examine the current situation of EMR implementation in Singapore.\na. The public health sector in Singapore consists of 2 clusters: Singapore Health\nServices (SingHealth) and National Health Group (NHG). The2 clusters have each\nimplemented an EMR system for their cluster and the 2 systems are currently\nconnected via an EMR exchange system (EMRX). (1,2)\nb. Find out what is the situation for private hospitals and general practitioners\n2. Examine the approach taken by other countries (e.g. Canada, New Zealand, Australia, USA)\nin implementing EMR\n3. Identify potential challenges faced in implementing a unified EMR system in Singapore.\nPossible areas are:\na. Technical challenges\ni. Standard representation of EMR\nii. Exchange format\niii. Security\n\niv. Availability\nb. Non-technical challenges\ni. Cost of implementation\nii. Resistance to change\n4. Suggest possible approach to handle challenges identified (incorporating suitable\napproaches adopted by other countries if they apply):\na. Technical challenges\ni. Identifying required contents of EMR. Leverage on ontologies based on HL-7,\nSNOMED-CT, and Continuity of Care Record (CCR) standards etc.\nii. Use a neutral exchange format e.g. XML\niii. Role-associated views for contents of EMR, password, access card, digital\nsignature, audits (6)\niv. Web-based system; back-up servers\nb. Non-technical challenges\ni. Leveraging on or extending existing infrastructure (5)\nii. Identify workflows and model approaches to minimize disruption to\nworkflows; Ease of use of EMR systems\nFocus will be placed on creating a unified EMR system nationwide (mainly focussed on standard\nrepresentation of EMR and exchange format). The approach needs to take into considerations of\nextensibility to data mining for research, change of definition of contents of EMR and\ninteroperability with other countries' systems.\nProposed Approach:\n1. Survey current EMR implementation in Singapore and other countries via Google, pubmed\netc.\n2. Approach SingHealth, NHG and NCS to find out more about the EMR and EMRX currently in\nplace.\n3. Approach private hospitals and general practitioners to find out about the type of EMR\nsystems (if any) that is in place and also the workflows.\n4. Survey literatures for approaches to handle challenges\nDifficulties may be encountered in approach 2 and 3 as there may be no responses.\n\nProposed Architecture:\nExchange Service connected to other EMR systems\nEMR Ontology\nFormat Validator\nsformer\nRetriever\nTransformer\nRecord Retriever\nTransformer\nRecord Retriever\nMedical\nRecords\nTran\nRecord\nEMR system 2\nMedical\nRecords\nEMR system 3\nMedical\nRecords\nEMR system 4\nTransformer\nQuery Constructor\nRecord Formatter\nAuthenticator\nEMR system 1\nMedical\nRecords\n\nReference:\n\n1. MOH Budget Speech (Part 2) - Transforming Healthcare. B.W. Khaw. 6 Mar 2007.\nhttp://www.moh.gov.sg/mohcorp/speeches.aspx?id=12394\n2. Healthcare IT Innovation Week Conference. Y. Yong. 2 Feb 2007.\nhttp://www.moh.gov.sg/mohcorp/speeches.aspx?id=12382\n3. Enterprise technology for government, education & healthcare. Vol 3.4. July/August 2006.\nhttp://www.pstm.net/pdf/268432PSTM%20-%20July%203.4.pdf\n4. EMR - Electronic Medical Records. Singapore Computer Systems Limited.\nhttp://www.scs.com.sg/images/EMR.pdf\n5. The Use of Existing Low-Cost Technologies to Enhance the Medical Record Documentation\nUsing a Summary Patient Record [SPR]. S. Bart, T. Hannan. Studies in Health Technologies\nand Informatics. 2007;129:350-3\n6. Confidentiality preserving audits of electronic medical record access. B. Malin, E. Airoldi.\nStudies in Health Technologies and Informatics. 2007;129:320-4\nPassword\nDB"
    },
    {
      "category": "Resource",
      "title": "Creating Databases from Ontologies",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/e318cdba2da6eed981ffde19fb3912a7_1021_db_ontology.pdf",
      "content": "MIT OpenCourseWare\ntp://ocw.mit.edu\n.453J / 2.771J / HST.958J Biomedical Information Technology\nll 2008\nr information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\nht\n\nFa\nFo\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nLecture 21 October 2008\nCreating Databases from Ontologies\nBiomedical\nInformation\nTechnology\nC. Forbes Dewey, Jr.\nMassachusetts Institute of Technology\nCambridge, MA USA\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nHere's our agenda\nReview of database technology\nHistory\nWhat is their role?\nWhat do they do well?\nWhat do they do poorly?\nOntologies\nWhy are they desirable?\nWhat are their advantages?\nWhat are their weaknesses?\nRelationship between DB and Ontologies\nExploiting the combination - OWLdb\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nReview of relational database technology\nStarted in mid-80's\n3⁄4Composed of tables with rows and columns\n3⁄4Minimal language to construct and query them:\nSQL\n3⁄4Generally fixed and unchanged relationships\nJava-based interface JDBC a real\nbreakthrough; common interface for all\nflavors. Can write programs!!!\nDatabases don't talk to each other\nStove-piping, warehousing, federation\nUpdates, security, reliability, performance\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOWL Ontologies\nDescribe meaning\n3⁄4 OWL is a language (set of relationships) that\ncan be extended with additional definitions\n3⁄4 OWL is written in RDF, is machine-readable,\nand can be parsed and combined\nRepresenting databases as ontologies\n3⁄4 Can represent a database schema by an\nontology\n3⁄4 Will discuss state-of-the art programs to do the\nconversion\n3⁄4 If we can convert, can have the best of both\nenvironments\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOWL - Web Ontology Language\n- An expressive and uniform way of defining meaning for\nterms used to transmit data and relationships\n- Can be used for many key purposes\n3⁄4Guarantee that two definitions are the same\n3⁄4Discover that two terms are synonymous\n3⁄4Encode complete object descriptions\n3⁄4Define unambiguous database schema\n- Comes in multiple flavors\n3⁄4OWL Lite - OWL DL - OWL Full\nhttp://www.w3.org/TR/2004/REC\nhttp://www.w3.org/TR/2004/REC--owl\nowl--features\nfeatures--20040210/#s2.1\n20040210/#s2.1\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOwl Structure\n- Classes\n- Properties\n- Types\n- Meta-Data\nOwl is written in RDF\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOWL - Web Ontology Language (2)\nRDF Schema Features:\nClass (Thing, Nothing)\nrdfs:subClassOf\nrdf:Property\nrdfs:subPropertyOf\nrdfs:domain\nrdfs:range\nIndividual\nhttp://www.w3.org/TR/2004/REC\nhttp://www.w3.org/TR/2004/REC--owl\nowl--features\nfeatures--20040210/#s2.1\n20040210/#s2.1\n(In)Equalitiy:\nequivalentClass\nequivalentProperty\nsameAs\ndifferentFrom\nAllDifferent\ndistinctMembers\nProperty Characteristics:\nProperty Restrictions:\nRestricted Cardinality:\nHeader Information:\nClass Axioms:\nArbitrary Cardinality\nClass Intersection:\nVersioning:\nAnnotation Properties:\nDatatypes:\nBoolean Combinations:\nFiller Information\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOWL - Web Ontology Language (3)\nRDF Schema Features:\nrdfs:subPropertyOf\nhttp://www.w3.org/TR/2004/REC\nhttp://www.w3.org/TR/2004/REC--owl\nowl--features\nfeatures--20040210/#s2.1\n20040210/#s2.1\nrdfs:subPropertyOf: Property hierarchies may be\ncreated by making one or more statements that a\nproperty is a subproperty of one or more other properties.\nFor example, hasSibling may be stated to be a\nsubproperty of hasRelative. From this a reasoner can\ndeduce that if an individual is related to another by the\nhasSibling property, then it is also related to the other by\nthe hasRelative property.\nOne of 54 base language constructs\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOWL - Web Ontology Language (2)\nRDF Schema Features:\nClass (Thing, Nothing)\nrdfs:subClassOf\nrdf:Property\nrdfs:subPropertyOf\nrdfs:domain\nrdfs:range\nIndividual\nhttp://www.w3.org/TR/2004/REC\nhttp://www.w3.org/TR/2004/REC--owl\nowl--features\nfeatures--20040210/#s2.1\n20040210/#s2.1\n(In)Equalitiy:\nequivalentClass\nequivalentProperty\nsameAs\ndifferentFrom\nAllDifferent\ndistinctMembers\nProperty Characteristics:\nProperty Restrictions:\nRestricted Cardinality:\nHeader Information:\nClass Axioms:\nArbitrary Cardinality\nClass Intersection:\nVersioning:\nAnnotation Properties:\nDatatypes:\nBoolean Combinations:\nFiller Information\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nXML Schema Datatypes used in OWL\nhttp://www.w3.org/2001/XMLSchema#name\nxsd:string, xsd:boolean, xsd:decimal, xsd:float,\nxsd:double, xsd:dateTime, xsd:time, xsd:date,\nxsd:gYearMonth, xsd:gYear, xsd:gMonthDay,\nxsd:gDay, xsd:gMonth, xsd:hexBinary,\nxsd:base64Binary, xsd:anyURI, xsd:normalizedString,\nxsd:token, xsd:language, xsd:NMTOKEN, xsd:Name,\nxsd:NCName, xsd:integer, xsd:nonPositiveInteger,\nxsd:negativeInteger, xsd:long, xsd:int, xsd:short,\nxsd:byte, xsd:nonNegativeInteger, xsd:unsignedLong,\nxsd:unsignedInt, xsd:unsignedShort, xsd:unsignedByte\nand xsd:positiveInteger\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOur approach to creating and merging databases\nCreate ontologies from database schema\nEdit and maintain the ontologies\nUtilize merged & aligned ontologies\nCreate on-the-fly databases from ontologies\nModel scientific processes - use cases\nAllow for interoperability\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nCreating ontologies from database schema\nD2RQ is a declarative language to describe\nmappings between relational database\nschemata and OWL/RDFS ontologies.\nhttp://www4.wiwiss.fu-berlin.de/bizer/D2RQ/\nCourtesy of Prof. Dr. Christian Bizer. Used with permission.\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nhttp://www4.wiwiss.fu-berlin.de/bizer/D2RQ/\nMore on D2RQ\nCourtesy of Prof. Dr. Christian Bizer. Used with permission.\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOptions for Ontology Merging & Aligning\nKim, Jaehong, Minsu Jang, Young-Guk Ha, Joo-Chan Sohn, and Sang Jo Lee. \"MoA:\nOWL Ontology Merging and Alignment Tool for the Semantic Web.\" 18th Conference on\nIAAI, Bari Italy, 2005.MoA system architecture diagram.\nAPI\nShell\nOntomo EditorMoA system architecture diagram.\nQuery Interface\nAligned\nOntology\nBossam Inference EngineMoA system architecture diagram.\nApplication\nUser\nExpert\nView\nUpdate\nMoA Engine\nSemantic\nBridge\nMerged\nS\nUser\nMerger\nh\nOntology\nell\nSB\nGeneratorMoA system architecture diagram.\nO1\nO2MoA system architecture diagram.\nSource OntologiesMoA system architecture diagram.\nArchitecture of MoA system.\nFigure by MIT OpenCourseWare, after Kim et al, 2005.\n(c) cfdewey 2008\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOptions for Ontology Merging & Aligning (2)\nLam, H.Y.K. et al. \"Using Web Ontology Language to Integrate Heterogeneous\nDatabases in the Neurosciences.\" AMIA Annual Symposium Proc. 2006, 464-468.\n[PubMed Central OpenAccess article.]\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOptions for Ontology Merging & Aligning\nProceedings of the International Workshop for Foundations of Models for Information\nIntegration (FMII-2001), Viterbo, Italy, September 2001.Block diagram of ontology merging method.\nFigure by MIT OpenCourseWare.\nBlock diag\nram of ont\nology m\nerging meth\nod.\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOptions for Ontology Merging & Aligning\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nOWLdb: A new paradigm for creating databases\n. . . . Courtesy of Kurt Stiehl\nXML\nFile\nFrom Stiehl, Kurt R. \"Development of Dynamic Database Structures Using OWL Ontologies.\" MIT BSME Thesis, June 2007.\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nIntegration - Ontology\nUniProt\nBioModels\nUniModels\nExternal Ontologies\nInternal Ontologies\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe Species Link\nUniProt\nBioModels\nProtein\nModel\nProtein\nProtein\nProtein\nProtein\nTable\nTable\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe OWLdb design\nOntology 1\nOntology 1\nMerge and align\nMerge and align\nontologies\nontologies\nOntology n\nOntology n\nOWLdb\nOWLdb\nQuery\nQuery\nontology\nontology\nJDBC\nJDBC\nSQL\nSQL\nDatabases\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nArchitecture\nBioModels.\nBioModels.\nNet\nNet\nUniProt\nUniProt\nSBO/Bio\nSBO/Bio\nPAX\nPAX\nUniProt\nUniProt\nRDF\nRDF\nUniModel\nMetaOntology\nin OWL\n(Handcrafted )\n+ inference\nrules\nOWL\ndb\nUniModel\nUniProt + BioModel\nDB\n(MySQL etc.)\nSQL\nSQL\nSPARQL\nSPARQL\nFront End\nFront End\n+\n+\nContextualization\nContextualization\n+ Use Case\n+ Use Case\nUniModel\nMetaOntology\nin OWL\n(Handcrafted )\n+ inference\nrules\nOWL\ndb\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nKey Components\nUniModels\nRegistry\nLSID\nInterface\nUniModels Ontology\nNomenclature\nUniModels / SBO / UniPROT RDF\nEditor\nProtege/SBMLEditor\nParser\nJena\nReasoner\nJena/OWLdb\nStorage\nOracle / MySQL / PostgresSQL / Sesame\nQuery\nSPARQL / SQL / D2RQ / SeRQL\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nComputational and Systems Biology"
    },
    {
      "category": "Resource",
      "title": "Gaps in Bio-Medical Data and Applications",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/0729d31db3cf98b2077e5306b33b9f82_0909_hyu.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\nFall 2008\n\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n2.771J 20.453J HST.958J SMA5304 Spring 2008\nLecture 9 September 2008, by Hanry Yu\nGaps in Bio-Medical Data and\nApplications\nBiomedical\nInformation\nTechnology\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nTypes and characteristics of biological and medical\ndata (today)\nMedial Data\nBiological Data\nCurrent challenges: fill in the gaps\nExamples from liver fibrosis Research (on Thursday)\nScope of Applications (1 week:\nHY)\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nMolecular Networks and Medical Practice\nPhotomicrograph images of\ncells removed due to\ncopyright restrictions.\nSee Nikon Small World\n(http://nikonsmallworld.com)\nDiagram of myosin molecule\nstructure removed due to\ncopyright restrictions.\nImage courtesy of Elsevier, Inc., http://www.sciencedirect.com.\nUsed with permission. Source: Apic, G., et al. FEBS Letters 579 no.\n8 (2005): 1872-1877.\nDiagrams of head / neck /\ntail structure for Myosin I,\nMyosin II, and Myosin V.\n(from Alberts et al,\nMolecular Biology of the\nCell) removed due to\ncopryight restrictions.\nFigure by MIT\nOpenCourseWare.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nWhat are Medical Data?\nDocumentation about individual patient's illness and\nmedical care\nIncludes:\n3⁄4Medical history\nAll medical events and problems experienced by patient\n3⁄4Clinical findings\nSymptoms: reported by patients (subjective)\nSigns: detected by physician during physical examination\n(objective)\nLaboratory test results\n3⁄4Diagnoses\nProcess of identifying disease by its signs, symptoms and\nlaboratory test results\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\n3⁄4Therapies\nDescription of application of treatment to effect a cure\nTreatment includes:\n- Medication, dosage and dosing schedule\n- Care regime, e.g. diet, exercise, etc.\n3⁄4Prognosis\nDuration of disease\nChances of complications\nProbable outcomes\nProspects for recovery\nRecovery period\nSurvival rates\nDeath rates\nWhat are Medical Data?\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nQuestions Medical Data Can Answer\nWhat is the patient's medical history?\nWhat are the symptoms?\nWhat are the examination findings?\nWhat are the changes in symptoms and signs over time?\n3⁄4Progression of chronic diseases\n3⁄4Provides information for prescribing treatment\nWhat are the changes in physiological function over\ntime?\nWhat were previous treatment given?\nWhat was the rationale for treatment?\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nPurposes of Medical Data\nSupports patient care\n3⁄4Basis of historical record\n3⁄4Communication among care providers\nAllergic conditions\nTreatment plan for chronic diseases (e.g. high blood pressure, diabetes)\n3⁄4Anticipate future health problems\nSupports medical/clinical research\n3⁄4Assists in screening of patient groups for clinical trials\nPatients' profile can be matched with clinical trial requirements\nElectronic health record systems can perform match and prompt doctors of\nsuitable candidates during patient's visit - improve recruitment rate\n3⁄4Electronic health record systems can systemically generate hypotheses for\nresearch based on patients' information\n3⁄4Mechanisms and causes of diseases\nFormulation of possible treatments\n3⁄4Assists in studying the efficacy of drugs and medical equipment\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nPurposes of Medical Data\nAllows surveillance of epidemic\nand bio-terrorism\n3⁄4Epidemic: SARS, avian flu etc\n3⁄4Bio-terrorism: anthrax, smallpox\netc\n3⁄4Electronic\nmedical\nrecord\nsystems\nallows\nreal-time\nnationwide surveillance.\nProvides legal record\nThe System Architecture of Nation\nThe System Architecture of Nation--Wide Hospital Emergency\nWide Hospital Emergency\nDepartment\nDepartment--based\nbased Syndromic\nSyndromic Surveillance System (ED\nSurveillance System (ED--SSS\nSSS) in\n) in\nTaiwan, established in 2003.\nTaiwan, established in 2003.\nSource: Wu,\nSource: Wu, TT--SS J., et al, 2008.\nJ., et al, 2008. \"\"Establishing a nationwide emergency department\nEstablishing a nationwide emergency department--based\nbased\nsyndromic\nsyndromic surveillance system for better public health responses in Taiwa\nsurveillance system for better public health responses in Taiwan.\nn. BMC Public Health\nBMC Public Health\n8 (2008): 18. http://\n8 (2008): 18. http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid\nwww.pubmedcentral.nih.gov/articlerender.fcgi?artid=2249581\n=2249581\nDetect outbreak\nDetect outbreak\nFormulate plan and policies\nFormulate plan and policies\nto handle outbreak\nto handle outbreak\nImage courtesy of Wu, T-S J., et al.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nTypes of Medical Data\nImages\n3⁄4Computed tomography (CT) scan\n3⁄4Magnetic resonance imaging (MRI) scan\n3⁄4Positron emission tomography (PET) scan\n3⁄4Ultrasound imaging etc\nRecorded signals\n3⁄4Blood pressure\n3⁄4Electrocardiogram (ECG) etc\nNumerical measurements\n3⁄4Temperature\n3⁄4Laboratory results etc\nTextual description\n3⁄4Medical symptoms or signs description\n3⁄4Treatment plan\n3⁄4Prognosis etc\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nImage Data - CT scan\nDiagnostic procedure that takes a detailed cross-sectional x-ray picture of a\n\"slice\" of the body\n3⁄4 X-ray machine rotates around the patient and takes pictures from many angles\n3⁄4 Computer combines the pictures into a very detailed cross-sectional image\nShow the shape, size and the exact location of organs and tissues in any\n\"slice\" of the body\nGood spatial resolution\n3⁄4 Able to distinguish 2 structures which are very near each other as separate entities\nImage size of CT scans depend on:\n3⁄4 Number of \"slices\"\n3⁄4 Resolution of scanner\n3⁄4 Area scanned\nOther important information:\n3⁄4 Device type\n3⁄4 Device settings\nCT scan of Fibrosing Mediastinitis\nCT scan of Fibrosing Mediastinitis\nSource: The FM Foundation. http://www.mrsnewengland2007.com/FM\nSource: The FM Foundation. http://www.mrsnewengland2007.com/FM--Medical\nMedical--Information.html\nInformation.htm\nCourtesy of The FM Foundation.\nUsed with permission.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nImage Data - MRI scan\nDiagnostic procedure that uses magnetic/radio waves to affect the body's atoms\n3⁄4Radio waves force nuclei (usually hydrogen - body consists mainly of water) into different\nposition\n3⁄4When they restore their position, radio waves are emitted\n3⁄4Scanner picks up signals and a computer uses the signal to compose the image\n3⁄4Image formed is based on location and strength of the signals\nUsed to visualize structure and function of the body\nProvides detailed images of body in any plane\nProvides much greater contrast between soft tissues than CT scan\n3⁄4Useful for brain, musculoskeletal, cardiovascular and cancer imaging\nContrast agents sometimes used to enhance appearance of blood vessels, tumors or inflammation.\nImage size of MRI scans depend on:\n3⁄4Number of \"slices\" (for 3D reconstruction)\n3⁄4Resolution of scanner\n3⁄4Area scanned\nOther important information:\n3⁄4Device type\n3⁄4Device settings\nAnimated MRI images of a human head\nAnimated MRI images of a human head\nSource:\nSource: Dawyne\nDawyne Reed. http://\nReed. http://en.wikipedia.org/wiki/Image:Structural.gif\nen.wikipedia.org/wiki/Image:Structural.gif\nImage Data - MRI\nImage removed due to copyright restrictions.\nSee http://en.wikipedia.org/wiki/File:Structural.gif.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nNuclear medicine imaging technique\n3⁄4 Patients given injection of very small amount of tracer (e.g. fluorine 18 - radioactive version\nof glucose. Can be used to image brain where glucose is the main source of energy)\n3⁄4 PET scanner used to detect emission from the injected tracer\n3⁄4 2D and 3D images of the scanned area is created by the computer\nCan be used for:\n3⁄4 Early detection and monitoring of cancer\nCan reveal changes in metabolism and how organs and tissues are working\nCan show if (and where) cancer is spreading to other parts of the body\n3⁄4 Neurological disease\nCan provide biochemical function information of the brain\n3⁄4 Assessment of cardiovascular disease\nCan be used to assess blood flow to the heart and how the heart is functioning\nLimitations:\n3⁄4 Can give false results if chemical balances within body are not normal.\n3⁄4 Resolution of structures of the body may not be as clear compared with CT and MRI scans\nalthough information gained from PET scan is much more.\nPET image of human brain\nPET image of human brain\nCourtesy of Jens\nCourtesy of Jens Langner\nLangner. . http://en.wikipedia.org/wiki/Image:PET\nhttp://en.wikipedia.org/wiki/Image:PET--image.jpg\nimage.jpg\nImage Data - PET\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nCombination of PET with CT and MRI\n3⁄4CT and MRI scan provides anatomic information\n3⁄4PET scan provides metabolic information\nImage size of MRI scans depend on:\n3⁄4Number of \"slices\" (for 3D reconstruction)\n3⁄4Resolution of scanner\n3⁄4Area scanned\nOther important information:\n3⁄4Device type\n3⁄4Device settings\nScans showing lung cancer (bright spot in the chest).\nScans showing lung cancer (bright spot in the chest).\nLeft: CT scan; Center: PET scan; Right: combined CT\nLeft: CT scan; Center: PET scan; Right: combined CT--PET scan\nPET scan\nSource: Mayo Clinic. http://www.mayoclinic.org/pet/\nSource: Mayo Clinic. http://www.mayoclinic.org/pet/\nLung cancer\nLung cancer\nCT scan\nCT scan\nPET scan\nPET scan\nCT\nCT--PET scan\nPET scan\nImage Data - Multi-Modal\nImaging\nImage removed due to copyright restrictions.\nSee http://www.mayoclinic.org/pet/.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nRecords the electrical activity of the heart over time\nMeasured by an array of electrodes placed on the body surface\nAmerican Heart Association requires the ECG signal to consist of 3 individual leads,\neach recording 10 bits per sample, and 500 samples per second\nSome ECG signals, may require 12 leads, 11 bits per second, 1000 samples per\nsecond, and last 24 hours\n3⁄4This ECG record requires 1.36 gigabytes of storage when converted to digital\nformat\nECG\nECG\nECG wavefor m n omen\nclature: P, Q, R,\nS, and T.\nRecorded Signals - ECG\nFigure by MIT OpenCourseWare, after Lynch, 1985.\nSource: Clifford, G. F. Azuaje, and P. McSharry. \"The Physiological Basis of\nthe Electrocardiogram.\" Advanced Methods and Tools for ECG Data Analysis.\nNorwood, MA: Artech House, 2006. Courtesy of Artech House. Used with\npermission. (c) Artech House, 2006.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nCharacteristics of Medical Data\nMedical data = single instance of observation (signs, symptoms,\nclinical findings) or description of diagnosis, therapy or prognosis\nDefined by:\n3⁄4Patient\n3⁄4Parameter being observed\n3⁄4Description of parameter\nNumerical value\nTextual description\nGraphical image\n3⁄4Device used (when applicable)\n3⁄4Device setting (when applicable)\n3⁄4Time of observation\nMedical data = collection of medical data\nExample:\nExample:\nPeter Tan has a fever of 38.1\nPeter Tan has a fever of 38.1°°C\nC on 20\non 20th\nth\nMay 2008 at\nMay 2008 at 5.30pm\n5.30pm\nPatient:\nPatient: Peter Tan\nPeter Tan\nParameter:\nParameter: Body temperature\nBody temperature\nDescription:\nDescription: 38.1\n38.1°°C\nC\nTime:\nTime: 20\n20th\nth May 2008,\nMay 2008, 5.30pm\n5.30pm\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nLifecycle of Current Clinical Research\nSource: Kahn,\nSource: Kahn, M.G\nM.G. Integrating Electronic Health Records and Clinical Trials\n. Integrating Electronic Health Records and Clinical Trials -- An Examination of Pragmatic Issues.\nAn Examination of Pragmatic Issues.\nhttp://www.esi\nhttp://www.esi--bethesda.com/ncrrworkshops/clinicalResearch/pdf/MichaelKahnPaper\nbethesda.com/ncrrworkshops/clinicalResearch/pdf/MichaelKahnPaper.pdf\n.pdf\n??\nCourtesy of Michael G. Kahn MD, PhD.\nUsed with permission.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nWhat are Biological Data?\nChemical\nMolecules\n(DNA,\nRNA,\nCarbohydrates, Proteins, Lipids): Identities &\nInteractions\nPathways and networks\n~25000 genes, 100-200 pathways and a\nfraction relevant to diseases per cell type\n(Bauch A. et al., Immune Review 2006,\n210: 187-207)\nPhenotypes (in vitro and in vivo)\nMeso-cale mechanistic studies\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nBiological Data\nImage removed due to copyright restrictions.\nSee Fig. 5 in: Bauch, A., and G. Superti-Furga. \"Charting Protein Complexes, Signaling Pathways,\nand Networks in the Immune System.\" Immunological Reviews 210, no. 1 (2006): 187-207.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nnucleic acids, proteins, carbohydrates, lipids\nChemical Molecules\n\"Anchoring of integral proteins to the plasma membrane...\"\nFigure 3-36 in Lodish, H., et al. Molecular Cell Biology. 4th edition.\nNew York, NY: W. H. Freeman, 2000.\nViewable at the NCBI Bookshelf\nhttp://www.ncbi.nlm.nih.gov/books/bv.fcgi?rid=mcb.figgrp.618\nImages removed due to copyright restrictions.\nDiagram of phospholipid bilayer,\ncontaining retinal pigment.\nMolecule structure image,\nhighlighting small domain and\nlarge domain.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nMolecular Signals and Metabolism via molecular\ninteractions (nucleic acids, proteins, carbohydrates, lipids)\nConformations and Interactions\nImage removed due to copyright restrictions.\nFigure 6-10 in Silverthorn, D. Human Physiology. 2nd ed. Prentice-Hall, 2000.\nhttp://cwx.prenhall.com/bookbind/pubbooks/silverthorn2/medialib/Image_Bank/CH06/FG06_10.jpg\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nPhosphorylation\nImage removed due to copyright restrictions.\n\"The two branches of the inositol phospholipid pathway.\"\nFigure 15-36 in Alberts, B., et al. Molecular Biology of the Cell. 4th edition.\nNew York, NY: Garland Science, 2002.\nViewable at the NCBI Bookshelf\nhttp://www.ncbi.nlm.nih.gov/books/bv.fcgi?rid=mboc4.figgrp.2812\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nPathway: e.g. Glycolysis Regulation\nImage removed due to copyright restrictions.\nSee http://www.biocarta.com/pathfiles/h_GLYCOLYSISPATHWAY.asp.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nPathway Interactions\nImage removed due to copyright restrictions.\n\"Five parallel intracellular signaling pathways...\"\nFigure 15-61 in Alberts, B., et al. Molecular Biology of the Cell. 4th edition.\nNew York, NY: Garland Science, 2002.\nViewable at the NCBI Bookshelf\nhttp://www.ncbi.nlm.nih.gov/books/bv.fcgi?rid=mboc4.figgrp.2866\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nNetwork Formation\nImage removed due to copyright restrictions.\n\"Chart of the major signaling pathways relevant to cancer in human cells...\"\nFigure 23-31 in Alberts, B., et al. Molecular Biology of the Cell. 4th edition. New York,\nNY: Garland Science, 2002.\nViewable at the NCBI Bookshelf\nhttp://www.ncbi.nlm.nih.gov/books/bv.fcgi?highlight=23-31&rid=mboc4.figgrp.4327\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nPathways and Networks\nImage removed due to copyright restrictions.\n\"Glycolysis and the citric acid cycle provide\nthe precursors needed to synthesize many\nimportant biological molecules.\"\nFigure 2-87 in Alberts, B., et al. Molecular\nBiology of the Cell. 4th edition. New York, NY:\nGarland Science, 2002.\nViewable at the NCBI Bookshelf\nhttp://www.ncbi.nlm.nih.gov/books/bv.fcgi?hi\nghlight=2-87&rid=mboc4.figgrp.318\nImage removed due to copyright restrictions.\n\"Glycolysis and the citric acid cycle are at the\ncenter of metabolism.\"\nFigure 2-88 in Alberts, B., et al. Molecular\nBiology of the Cell. 4th edition. New York, NY:\nGarland Science, 2002.\nViewable at the NCBI Bookshelf\nhttp://www.ncbi.nlm.nih.gov/books/bv.fcgi?hi\nghlight=2-88&rid=mboc4.figgrp.320\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nNetwork Dimensions\nImage removed due to copyright restrictions.\n\"A representation of all of the known metabolic reactions involving small molecules in a yeast cell.\"\nFigure 2-89 in Alberts, B., et al. Molecular Biology of the Cell. 4th edition. New York, NY: Garland\nScience, 2002. [From Jeong, H., et al. Nature 411 (2001): 41-42]\nViewable at the NCBI Bookshelf\nhttp://www.ncbi.nlm.nih.gov/books/bv.fcgi?highlight=2-89&rid=mboc4.figgrp.321\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nImportance of Biological\nPathways\nAssociation with phenotypes and diseases\nDrug discovery\nBauch, A., and G. Superti-Furga. \"Charting protein complexes, signaling pathways, and\nnetworks in the immune system.\" Immunological Reviews 210, no. 1 (2006): 187-207.\nImage removed due to copyright restrictions.\nSee Table 1 in: Bauch, A., and G. Superti-Furga. \"Charting Protein Complexes,\nSignaling Pathways, and Networks in the Immune System.\" Immunological\nReviews 210, no. 1 (2006): 187-207.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nDrug Discovery Approaches\nImage removed due to copyright restrictions.\nSee Fig. 1 in: Butcher, E. C. \"Can Cell Systems Biology Rescue Drug\nDiscovery?\" Nature Reviews Drug Discovery 4, (June 2005): 461-467.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nCell Systems Biology Approach\nCourtesy of BioSeek, Inc. Used with permission.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nHigh Content Screening (HCS)\nHigh content screening combines automated microscopy with image analysis to\ncapture multiple parameters of individual cells, to allow rapid, large scale and highly\nparallel biological research and drug discovery.\n(Neumann, Held et al. 2006)\n(Neumann, Held et al. 2006)\nLiquid handling\nLiquid handling\nsystem\nsystem\nAutomated\nAutomated\nmicroscopy\nmicroscopy\nSingle cell\nSingle cell\nanalysis\nanalysis\nAdvanced statistics\nAdvanced statistics\nfor chemical profiling\nfor chemical profiling\nCourtesy of Jan Ellenberg. Used with permission.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nQuantitative, multiple\nparameter analysis of large\nnumbers of individual cells\nCell surface markers\nIntracellular proteins\nCa++ mobilization\n12 colors and 15\nparameters\nSorting: 60,000 cell/second\nRef.: Jianmin Chen, MIT\nFluorescence Activated Cell Sorter\n(FACS) (Flow cytometry) Diagram of separation process in a flow cytometer.\nFigure by MIT OpenCourseWare\nDiagram of separat\nion proc\ness i\nn a flow cytometer\n.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nAdvantages of HCS\nCombination of modern cell biology, with all its\nmolecular tools\nHigh-throughput and high efficiency using automated\nsystem\nObtain knowledge on multiple parameters\nin an\nindividual experiment to give us rich information at\nsingle cell level\nSpatial and temporal information of the cells with their\nneighbors and environment\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nGenome wide gene functional study, e.g. genome-wide\nRNAi approach (Pelkmans et al. 2005, Sonnichsen et al. 2005);\nProteome sub-cellular localization (Huh et al. 2003);\nProtein-protein interaction, chemical profiling and drug\nscreening (Perlman et al. 2004, Mitchison 2005, Abraham et al. 2004).\nApplications of HCS\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nSystems Biology for Drug Discovery\nTarget ID and validation\nSide effects\nMolecular mechanisms for toxicity\nImages courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with\npermission. Source: Apic, G., et al. FEBS Letters 579 no. 8 (2005): 1872-1877.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nCell Systems Biology Approach\n1.\n1. Tissue Biology/\nTissue Biology/\nEngineering\nEngineering\n2. Meso\n2. Meso--scale\nscale\nUnderstanding\nUnderstanding\nCourtesy of BioSeek, Inc. Used with permission.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nMedical Data: physiologic and pathologic phenotypes\nBiological Data: molecular parts and interaction maps\nLack meso-scale functional modules or steps to\nconstruct Operations Manuals at cell/tissue/systems\nlevels; and\nRepairs Manuals\nGaps in Bio-Medical Data\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe CAR analogy\nImages removed due to copyright restrictions. Two diagrams of model car assembly,\nfrom DuraTrax \"Delphi\" Assembly and Operation Manual, http://manuals.hobbico.com/dtx/dtxc0012-manual.pdf.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe airplane analogy\nUnderstand how an airplane work:\nObserve how an airplane flying phenotype:\nTake the plane apart into individual parts\nRecord the interaction maps\nWhat is the missing information? Why it is difficult to\nconstruct an airplane operations manual from the\ndescription of the parts and their interaction maps?\nMeso-scale studies: functional modules or steps that\nare small enough to be readily described by parts; and\nyet large enough to link with other modules to\nunderstand how the whole plane works: engine,\nsteering, fuel, navigation systems etc.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nFunctional Modules vs Molecular Networks\nPhotomicrograph images of\ncells removed due to\ncopyright restrictions.\nSee Nikon Small World\n(http://nikonsmallworld.com)\nDiagram of myosin molecule\nstructure removed due to\ncopyright restrictions.\nImage courtesy of Elsevier, Inc., http://www.sciencedirect.com.\nUsed with pe rmi ssion. Sou rce: Apic, G ., et al . FEBS Lett ers 579 no.\n8 ( 2005 ): 187 2- 187 7.\nDiagrams of head / neck /\ntail structure for Myosin I,\nMyosin II, and Myosin V.\n(from Alberts et al,\nMolecular Biology of the\nCell) removed due to\ncopryight restrictions.\nFigure by MIT\nOpenCourseWare.\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nMeso-scale studies: a functional module or step of a\nlarger process is typically defined by a group of\nchemical reactions or molecular networks.\nLink Molecular Networks to Physiology/Pathology\nImprove understanding of HOW things work\nDrug development\nRegenerative medicine\nUnique opportunities for computational approach to\nhandle the complexity of constructing Operations\nManual or Repairs Manual.\nFill Gaps in Bio-Medical Data\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThings to Ponder...\nPhenotypic Processes\nPhenotypic Processes\nFunctional Modules or Steps?\nFunctional Modules or Steps?\nFunctional Modules or Steps?\nMolecular networks\nMolecular networks\nMedical Practices\nMedical Practices\n\n(c) Hanry Yu 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nNext lecture: example in liver fibrosis\nImage removed due to copyright restrictions.\nPhoto of liver with fibrosis."
    },
    {
      "category": "Resource",
      "title": "Introduction",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/ae00d661c474abbd50f4722dc2ae11a3_intro.pdf",
      "content": "MIT OpenCourseWare\ntp://ocw.mit.edu\n.453J / 2.771J / HST.958J Biomedical Information Technology\nll 2008\nr information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\nht\n\nFa\nFo\n\n2.771J 20.453J HST.958J SMA5304 Spring 2008\nLecture 4 September 2008\nIntroduction\nBiomedical\nInformation\nTechnology\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nWelcome to the class\nInformation - the class web site\nWho to contact\nThe schedule and homework issues\nObjectives and methodology\nThe information-driven scientific method\nOntologies and semantics for biomedical\ninformation\nTerm paper instructions\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nMeet the staff\nBiomedical\nInformation\nTechnology\nInstructors:\nForbes Dewey\nMIT\nSourav Bhowmick\nNTU\nHanry Yu\nNUS\nTeaching Assistants:\nHuey Eng Chua\nNTU\nBoon Soo Seah\nNTU\nBaracah Yankama\nMIT\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe Syllabus\nIntroduction (1 Week)\nThe course in outline\nTerm papers\nScope of Applications (1 Week)\nBiological and medical data\nBasic Technologies (4 Weeks)\nStoring and querying biomedical data\nRelational databases, querying methods\nXML data\nOntologies (2 Weeks)\nWhat they are and how they can be exploited\nBiological Pathways(1.5 Week)\nQuantitative descriptions of biology\nData Integration (1.5 Weeks)\nDiscussion of several large integration projects\nStudent Presentations and Summary (2 Weeks)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe Syllabus\nIntroduction (1 Week)\nThe course in outline\nTerm papers\nScope of Applications (1 Week)\nBiological and medical data\nBasic Technologies (4 Weeks)\nStoring and querying biomedical data\nRelational databases, querying methods\nXML data\nOntologies (2 Weeks)\nWhat they are and how they can be exploited\nBiological Pathways(1.5 Week)\nQuantitative descriptions of biology\nData Integration (1.5 Weeks)\nDiscussion of several large integration projects\nStudent Presentations and Summary (2 Weeks)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe Syllabus\nIntroduction (1 Week)\nThe course in outline\nTerm papers\nScope of Applications (1 Week)\nBiological and medical data\nBasic Technologies (4 Weeks)\nStoring and querying biomedical data\nRelational databases, querying methods\nXML data\nOntologies (2 Weeks)\nWhat they are and how they can be exploited\nBiological Pathways(1.5 Week)\nQuantitative descriptions of biology\nData Integration (1.5 Weeks)\nDiscussion of several large integration projects\nStudent Presentations and Summary (2 Weeks)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nReading and Homework\nRead the primary papers for each session before\nthe session.\n3⁄4 Use the secondary papers and any other material you\ncan find to expand you understanding and answer\nhomework.\nAll homework is due at the beginning of the\nassigned class. \"We take no prisoners.\" Primarily\nelectronic submission.\nTutorials can be run from your own computers.\nDownload Cell Designer:\nhttp://www.celldesigner.org/\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\n(c) cfdewey 2008\nBiomedical\nInformation\nTechnology\nOriginal work\nThere are three forms of student creativity that are\nrecorded in this class. First, each student must show\nmastery of the materials in the homework problems.\nSecond, we have tutorials in which each student should\nachieve a high level of competence. We do not test this\nformally except to observe the ability of each student to\nperform the stated exercise. Third, we have individual\nprojects. You must make sure that your original work and\ncreativity are apparent in the final presentation. Just\nreading from a review article is far short of our standard.\nIn all three cases, If a student consults with others or\nuses published materials, this must be recorded and fairly\ndescribed. Plagiarism will not be tolerated.\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\n(c) cfdewey 2008\nBiomedical\nInformation\nTechnology\nTerm paper instructions\nEach student in the course is required to\nEach student in the course is required to\npresent a term project that illustrates the use of\npresent a term project that illustrates the use of\nthe course material in a real information\nthe course material in a real information\ntechnology case in biology or medicine. The\ntechnology case in biology or medicine. The\nactual content of the case can vary depending\nactual content of the case can vary depending\nupon the student\nupon the student''s interests and existing skills.\ns interests and existing skills.\nProjects can range from general studies of a\nProjects can range from general studies of a\nclass of problems\nclass of problems and the recommendation of a\nthe recommendation of a\nsolution to a detailed implementation in running\nsolution to a detailed implementation in running\nsoftware.\nsoftware.\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nMedicine is an information science\nand a healing art\nOur objective is to create information\nsystems that serve the development of\nbiology and medicine. In the end, we\nwant to make this information available\nin human treatment of disease and the\nenhancement of life.\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\n(c) cfdewey 2008\nBiomedical\nInformation\nTechnology\nActive areas of modern biology\nBiological discovery\n3⁄4 How to knock out specific proteins\n3⁄4 How to modify the genome\n3⁄4 How to use stem cells appropriately\nMechanisms of cells, tissues and organs\n3⁄4 Predictive molecular dependencies\n3⁄4 Designable living biological constructs\n3⁄4 Direct intervention in disease states\nGenetically-aware personal healthcare\n3⁄4 \"What-if\" scenarios for medical treatment\n3⁄4 Personal genome for genetically-aware therapy\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\n(c) cfdewey 2008\nBiomedical\nInformation\nTechnology\nInformation technology in modern biology\nBiological discovery\n3⁄4 Queryable archives for high-throughput proteomics\n3⁄4 Processing algorithms to understand data\n3⁄4 Search for new relationships between known facts\nMechanisms of cells, tissues and organs\n3⁄4 Predictive models for interactions between proteins\n3⁄4 Predictive models for molecular ensembles\n3⁄4 Toxicity and dose predictions in drug development\nGenetically-aware personal healthcare\n3⁄4 Predictive response to pharmeceuticals\n3⁄4 Better control and prevention of chronic diseases\n(Alzheimer's disease, obesity, AIDS, and diabetes)\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\n(c) cfdewey 2008\nBiomedical\nInformation\nTechnology\nObjectives\n\nIntroduce the subject of bioinformatics\n\nDemonstrate the current state of the art\n\nTeach new methods to approach the field\n\nProvide design experience through a project\n\nDevelop practical applications to biological and\nmedical problems\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nMethodology\n\nSet the intellectual context\n\nDefine the scientific and engineering challenge\n\nDesign a solution\n\nImplement the solution\n\nExamine the consequences\nThe scientific method\nThe scientific method\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nKeys to biomedical computing standards\nSemantics\nInvestigators can agree on meaning\nOntologies for standardizing meaning\nCuration of ontologies - the LSID identifier\nSchema\nShare schema and concepts - Ontologies\nScaleability\nThe ability to scale to larger problems in the future\nStandard tools\nCommon ontologies and schema for sharing data\nReusable software!!!\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nSemantics and ontologies\nSemantics:\nThe science of meanings . .\nfor communication and interchange\nof scientific information\nOntology:\nA specification of a conceptualization\nTim Gruber, Stanford, circa 1993\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe big impediment . . . sematics\nWhat does the word \"sample\" mean?\n( Quiz: \"Football\" = ? )\nHow can one establish meaning with certainty?\nUse ontologies to define objects and concepts\nHow can meanings be compared and\ncombined?\nUse the Web Ontology language . . OWL\nHow can one create a \"collisionless\" schema?\nFind a good example from a related field\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe biomedical information platform\nClinical\nComplexity\nComputational\nComplexity\nBiological\nComplexity\nSystems\nComplexity\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nSystems\nKnowledge\nPathways & Models\nData\nNormalization\nExperimental\nCurated & Derived\nClinical\nApplied\nUse Cases\nDrug Trials\nStandards\nInteroperability\nData Integrity\nCuration\nPlatform\nKnowledge\nRepresentation\nInterface\nSemantic Web\nAccess & Query\nCreation & Sharing\nThe biomedical information platform\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe Syllabus\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nTypes and characteristics of biological and medical\ndata\nDistributed data systems\nThe life cycle of scientific data\nCurrent challenges\nExamples from liver fibrosis\nGel Electrophoresis\nMicroarrays\nFACS and other methods\nCreating biological pathways\nDesigning new experiments\nIntegrating information from the literature\nScope of Applications (1 week: HY)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nFluorescence Activated Cell Sorter (FACS)\n(Flow cytometry)\nQuantitative, multiple\nparameter analysis of large\nnumbers of individual cells\nCell surface markers\nIntracellular proteins\nCa++ mobilization\n12 colors and 15\nparameters\nSorting: 60,000 cell/second\nRef.: Jianmin Chen, MITDiagram of seperation process in a flow cytometer.\nFigure by MIT OpenCourseWare\nDiagram of seperat\nion pro\ncess\nin a flow cytomet\ner.\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nI\nT\nnformation\nechnology\nAll you ever wanted to know about databases\n- Relational model\n- Database schema\n- Query methods using SQL\nTrees and graphs\nXML\n- Schema for XML relations\n- Querying XML\nData integration without semantics\nIntegrating biomedical data (4 weeks: SSB)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nAn example -\nFluorescence Activated Cell Sorting (FACS)\nIllustrate the semantics issues\nGive an example of how to express semantics\nShow how XML can be used in the description\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nFACS IOD\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nFACS IOD (Expanded Portion)\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\n(c) cfdewey 2008\nBiomedical\nInformation\nTechnology\nXML schema\n<simpleType name=\"Beam_Splitter_Simple_Type\">\n<restriction base=\"dicom:Bd_64_Type\">\n<enumeration value=\"Mirror\"/>\n<enumeration value=\"Dichroic_Reflect_Low\"/>\n<enumeration value=\"Dichroic_Reflect_High\"/>\n<enumeration value=\"Block_All\"/>\n<enumeration value=\"Other\"/>\n</restriction>\n</simpleType>\n<!--xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-->\n<complexType name=\"Beam_Splitter_Type\">\n<sequence>\n<element name=\"Beam_Splitter\" type=\"filters:Beam_Splitter_Simple_Type\"/>\n<element name=\"Low_Cut_Off_1\" type=\"filters:Wavelength_Type\" minOccurs=\"0\"/>\n<element name=\"High_Cut_Off_1\" type=\"filters:Wavelength_Type\" minOccurs=\"0\"/>\n<element name=\"Low_Cut_Off_2\" type=\"filters:Wavelength_Type\" minOccurs=\"0\"/>\n<element name=\"High_Cut_Off_2\" type=\"filters:Wavelength_Type\" minOccurs=\"0\"/>\n<element name=\"Low_Cut_Off_3\" type=\"filters:Wavelength_Type\" minOccurs=\"0\"/>\n<element name=\"High_Cut_Off_3\" type=\"filters:Wavelength_Type\" minOccurs=\"0\"/>\n<element name=\"Description\" type=\"dicom:Bd_64_Type\" minOccurs=\"0\"/>\n<element name=\"Item_General_Info\" type=\"item:Item_General_Info_Type\" minOccurs=\"0\"/>\n</sequence>\n<attribute name=\"Prefix\" type=\"units:Prefixes_Type\" fixed=\"nano\"/>\n<attribute name=\"Unit\" type=\"units:Si_Unit_Name_Type\" fixed=\"meter\"/>\n</complexType>\n\n2.771J 20.453J HST.958J SMA5304 Fall 2008\n(c) cfdewey 2008\nBiomedical\nInformation\nTechnology\nDefinition and application of ontologies\n- Standards (OWL, RDF)\n- Examples and usage\n- Unique identifiers (LSID)\nDatabase approach to ontology storage\nQuerying ontologies with SPARQL\n- Integrating ontologies and XML query processing\n- Role of ontologies in systems biology\nCreating relational databases from ontologies\n- OWLdb\n- Ontology-based querying\nOntologies in Biology (2 Weeks: SSB & CFD)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nImag\nBiomedical\nInformation\nTechnology\nRDF - a step beyond XML\n- Lexical triples\n- Can be used to describe\nrelationships\n- Used to express the data in\nan OWL repository\n- XML used to transmit\ninformation stored in an OWL\nrepository\nes: W3C\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nModeling and computing biological pathways\n- SBML, CellML, MML\n- Cell Designer\n- Cytosolve\nBiological pathway databases\nMolecular network comparisons\nBiological pathways (2 weeks: CFD & SSB)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nThe CytoSolve computational network\nComposite Model\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nSWAN\n- An advanced architecture for sharing data\n- Application to Alzheimer disease\n- Generalization\n- Workflow and useability\nBuilding a distributed biological pathway system\nBiological and medical data integration\n(1 week: TC & CFD)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nPredicting drug efficacy by modeling\n- Current technology\n- Future technology\n- Ecamples\nRevolutionizing the drug discovery pipeline\n- New paradigms\n- New challenges with multiple drugs\n- Integration issues and opportunities\nGrand Challenges (1 week: CFD)\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nA new paradigm in drug toxicity and efficacy\nA new paradigm in drug toxicity and efficacy\nModeling as the preclinical accelerator\nIn Vitro\nAnimal\nHuman\nCross Prediction\nCross Prediction\nCross Prediction\nImaging Data\nIn vitro\nAnimal\nHuman\nX\n\n(c) cfdewey 2008\n2.771J 20.453J HST.958J SMA5304 Fall 2008\nBiomedical\nInformation\nTechnology\nComputational and Systems Biology"
    },
    {
      "category": "Lecture Notes",
      "title": "Molecular Network Comparisons",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/530b31c81dc670da56fbf5ff81760639_1104_molec_nw.pdf",
      "content": "MIT OpenCourseWare\ntp://ocw.mit.edu\n.453J / 2.771J / HST.958J Biomedical Information Technology\nll 2008\nr information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\nht\n\nFa\nFo\n\nImage: Dewey Lab, MIT.\n\nSMA5304: Biomedical Information Technology\n\nEvolution in Biology\nMutations and rearrangement in genomic DNA\nChanges in protein structures, abundances, and\nmodification states\nVariation at the protein level\nImpact proteins interaction with one another, with\nDNA, and with small molecules\nAffects signaling, regulatory, and metabolic networks\nChanges in network organization\nAffects cellular function, tissue-level responses,\nbehavior and morphology of whole organisms\nSMA5304: Biomedical Information Technology\n\nExample\nSMA5304: Biomedical Information Technology\nMouse\nRat\nRat_gene_1\nRat_gene_2\nMouse_gene_1\nMouse_gene_2\nA gene that diverged\nafter speciation to\nmouse and rat gene\nDuplicated to\ntwo different\ngenes\n\nMetrics for Evolutionary\nChange\nGene and protein sequences\nWhy?\nFundamental level of biological variation\nReadily available through automated sequence\ntechnology\nNetwork of protein interactions as metric?\nSMA5304: Biomedical Information Technology\n\nProtein-Protein Interaction\nOften, proteins interact with other proteins to perform\ntheir functions\nBackbone of molecular activity within the cell\nCell can be understood as a complex network of\ninteracting proteins\nSMA5304: Biomedical Information Technology\nImage removed due to copyright restrictions.\nSee: \"MAPK/ERK in Growth and Differentiation.\"\nhttp://focosi.altervista.org/mapkmap2.html.\n\nWhy?\nSMA5304: Biomedical Information Technology\nIncreased complexity (function) is not explained\nsimply by variations in gene (or protein) count\nExponential growth in data\nMass spectrometry\nGenome-wide-chromatin immunoprecipation\nYeast two-hybrid assays\nCombinatorial reverse genetic screens\nLiterature mining\n\nQuestions in evolutionary\nand comparative biology\nSMA5304: Biomedical Information Technology\nGiven that protein sequences and structures are\nconserved in and among species, are networks\nof protein interactions conserved as well?\nIs there some minimal set of interaction\npathways required for all species?\nCan we measure evolutionary distance at the\nlevel of network connectivity rather than at the\nlevel of DNA or protein sequence?\n\nMolecular Network\nComparison\nSMA5304: Biomedical Information Technology\nProcess of contrasting two or more interaction\nnetworks, representing different species,\nconditions, interaction types or time points.\n\nAnswer To\nSMA5304: Biomedical Information Technology\nWhy proteins, protein interactions and groups of\ninteractions are likely to have equivalent\nfunctions across species?\nBased on these similarities, can we predict new\nfunctional information about proteins and\ninteractions that are poorly characterized?\nWhat do these relationships tell us about the\nevolution of proteins, networks and whole\nspecies?\n\nAnswer To\nSMA5304: Biomedical Information Technology\nGiven that systematic screens for protein\ninteractions may report large numbers of false-\npositive measurements, which interactions\nrepresent true binding events?\n\nTypes of Network\nComparison\nNetwork alignment\nprocess of globally comparing two networks, identifying regions\nof similarity and dissimilarity\nNetwork integration\nprocess of combining several networks, encompassing\ninteractions of different types over the same set of elements, to\nstudy their interrelations.\nNetwork querying\na given network is searched for subnetworks that are similar to\na subnetwork query of interest\nSMA5304: Biomedical Information Technology\n\nNetwork & Sequence\nComparison\nSMA5304: Biomedical Information Technology\nCourtesy of Roded Sharan. Used with permission.\n\nNetwork & Sequence\nComparison\nSequence Comparison\nSequence alignment\nmethods were proposed\nlong before large sequence\ndatabases were widely\navailable.\nNetwork Comparison\nLarge network and\ninteraction databases have\nbeen available from the\nlate 1990s onwards, three\nto four years before the first\nnetwork comparisons were\nperformed.\nSMA5304: Biomedical Information Technology\n\nNetwork & Sequence\nComparison\nSequence Comparison\nComputational searches for\nmotifs and systematic\ncharacterization of global\nproperties arose relatively\nlate in the history of\nsequence analysis.\nLocal sequence alignment\ncan be solved efficiently\nNetwork Comparison\nOccurred early in the field\nof network comparison.\nAnalogous problem of\nidentifying conserved\nprotein modules is\ncomputationally hard\nSMA5304: Biomedical Information Technology\n\nNetwork & Sequence\nComparison\nSequence Comparison\nIntegrating biological\nsequences data types\n(nucleotides or amino\nacids) has not posed a\nmajor problem.\nNetwork Comparison\nIntegrating different data\ntypes of molecular\nnetworks is a challenging\nproblem\nSMA5304: Biomedical Information Technology\n\nProtein-Protein\nInteraction Network\n(PPI)\nSMA5304: Biomedical Information Technology\n\nNetwork Alignment\nProblem\nSMA5304: Biomedical Information Technology\n\nUsefulness\nFunctional Annotation\nAssign roles to unknown proteins\nAnnotation transfer\nAssigns to a protein of unknown function the\nannotation of a protein to which it is aligned\nLandmark extension\nIf a protein of unknown function appears as part of an\nalignment together with a \"landmark\" protein of\nknown function, we can label the protein with a\nsimilar annotation\nSMA5304: Biomedical Information Technology\n\nUsefulness\nCompute functional orthologs\nProteins which perform the same function across\nspecies\nSeparating true protein-protein interactions from\nfalse positives\nOrganizing large-scale interaction data into\nmodels of cellular signaling and regulatory\nmachinery\nIdentify novel modules by detecting unusual\nconserved subnetworks\nSMA5304: Biomedical Information Technology\n\nCore Problems\nSMA5304: Biomedical Information Technology\nA scoring framework that captures the\nknowledge about module evolution\nIdentify high scoring alignments (conserved\nfunctional modules) from among exponentially\nlarge set of possible alignments\n\nProtein Similarity\nSMA5304: Biomedical Information Technology\nMouse\nRat\nRat_gene_1\nRat_gene_2\nMouse_gene_1\nMouse_gene_2\nOrthologous proteins -\nTwo proteins from different\nspecies that diverged after a\nspeciation event\nParalogous proteins - Two\nproteins from the same\nspecies that diverged after a\nduplication event\nHomologous proteins - Two proteins that have\ncommon ancestry\n-Detected by sequence similarity\n-Proteins can be from same or different species\n\nOverview\nB. P. Kelley et al. Pathblast: a tool for alignment of protein interaction networks.\nPNAS., 2003.\nM. Chen, R. Hofestaedt. PathAligner: Metabolic Pathway Retrieval and Alignment.\nApplied Bioinformatics, 3(4), 241-252, 2004.\nR. Sharan, S. Suthram, R. M. Kelley et al. Conserved patterns of protein interaction\nin multiple species. PNAS, 102, pp. 1974-1979, 2005.\nR. Y. Pinter, O. Rokhlenko, E. Yeger-Lotem, and M. Ziv-Ukelson. Alignment of\nmetabolic pathways. Bioinformatics, 21(16):3401-8, 2005.\nM Koyuturk, Y Kim et al. Pairwise Alignment of Protein Interaction Networks.\nJournal of Comp Biology, 13(2), 2006.\nJ. Flannick, A. Novak, B.S. Srinivasan et al. Græmlin: General and robust alignment\nof multiple large interaction networks. Genome Research, 2006.\nDutkowsky, J., Tiuryn, J.: Identication of functional modules from conserved\nancestral protein-protein interactions. Bioinformatics, 2007.\nN Przulj. Biological Network Comparison with Graphlet Degree Distribution.\nBioinformatics, 23, e177-e183, 2007.\nM. Kalaev, V. Bafna, R. Sharan. Fast and Accurate Alignment of Multiple Protein\nNetworks. In Proc. of ACM RECOMB, 2008.\nSMA5304: Biomedical Information Technology\n\nPathBlast\nImplements a scoring function and search\nalgorithm to find high probability pathway\nalignments between two protein interaction\nnetworks\nSMA5304: Biomedical Information Technology\n\nPathway Alignment\nConsists of two paths one from each network (N1\nand N2)\nProteins in the first path pair with putative\nhomologs occurring in the same order in the\nsecond path\nA homologous protein pair may not occur more than\nonce per pathway alignment\nMay include nonhomologous proteins\nUsing gaps and mismatches\nSMA5304: Biomedical Information Technology\n\nGaps and Mismatches\nWhy?\nOvercome noisy PPI data as well as evolutionary variations\nGap\nOccurs when a protein interaction in one path skips over a protein in\nthe other\nMismatch\nOccurs when two proteins at the same position in the alignment do\nnot share sequence homology\nNeither gaps nor mismatches may occur consecutively\nSMA5304: Biomedical Information Technology\n\nGlobal Alignment Graph\nSMA5304: Biomedical Information Technology\nA path through this\nrepresents a conserved\npathway between the two\nnetworks\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Kelley, Brian P., et al. \"Conserved Pathways Within Bacteria and Yeast\nas Revealed by Global Protein Network Alignment.\" PNAS 100, no. 20 (September 20,\n2003): 11304-11309. Copyright (c) 2003 National Academy of Sciences, U.S.A.\n\nSimilarity Between\nProteins\nIn order to build the global alignment graph, similarity\nbetween proteins need to be measured\nUsing BLAST\nQuantifies the similarity\nAssigns it a p-value\nprobability of observing such similarity at random\nE-value or Expectation value\nnumber of different sequence pairs with score equivalent or better\nthan this hit's score that are expected to result by a random search\nUnalignable proteins are assigned max E-value of 5\nSMA5304: Biomedical Information Technology\n\nLog Probability Score\nSMA5304: Biomedical Information Technology\nProbability of true\nhomology within the protein\npair represented by v in P\nProbability that the protein-\nprotein interaction\nrepresented by e is real (not\nfalse positive error)\nExpected values of p(v)\nover all vertices and\nedges in G\nExpected values of q(e)\nover all vertices and\nedges in G\n\nAlignment Algorithm\nIdentify the highest-scoring pathway alignment\nP* of fixed length L (L vertices and L -1 edges).\nIf G is directed and acyclic,\nlinear time (in the number of edges)\nusing dynamic programming\nSMA5304: Biomedical Information Technology\n\nAlignment Algorithm\nThe highest-scoring path of length l = 2...L\nending in vertex v will have score\nSMA5304: Biomedical Information Technology\nBase Case\n\nAlignment Algorithm\nG is generally not acyclic\nFirst construct a sufficient number (5L!) of\ndirected acyclic subgraphs\nUse the dynamic programming method to\ncompute the highest-scoring paths for each.\nCan be done in linear time\nSMA5304: Biomedical Information Technology\n\nExperiments\nYeast (S. cerevisiae) vs. Bacteria (H. pylori)\nOrthologous pathways between the networks of two species.\nYeast vs. Yeast\nParalogous pathways within the network of a single species, by\naligning the yeast PPI network versus itself.\nYeast vs. Yeast\nInterrogating the protein network with pathway queries, by aligning\nthe yeast PPI network versus simple pathways.\nSMA5304: Biomedical Information Technology\n\nComparison between Yeast and\nBacteria GAGs to the\ncorresponding randomized networks\nSMA5304: Biomedical Information Technology\nGraph size and best pathway-\nalignment scores were significantly\nlarger for the real aligned networks\nBoth species indeed share\nconserved interaction pathways\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Kelley, Brian P., et al. \"Conserved Pathways Within Bacteria and Yeast\nas Revealed by Global Protein Network Alignment.\" PNAS 100, no. 20 (September 20,\n2003): 11304-11309. Copyright (c) 2003 National Academy of Sciences, U.S.A.\n\nComparison between Yeast and\nBacteria GAGs to the\ncorresponding randomized networks\nSMA5304: Biomedical Information Technology\n- Direct interaction was rare\n-Gaps and Mismatch allowed to find much\nlarger regions that were conserved\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Kelley, Brian P., et al. \"Conserved Pathways Within Bacteria and Yeast\nas Revealed by Global Protein Network Alignment.\" PNAS 100, no. 20 (September 20,\n2003): 11304-11309. Copyright (c) 2003 National Academy of Sciences, U.S.A.\n\nRelation between seemingly\nunrelated processes\nSMA5304: Biomedical I\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nonserved Pathways Within Bacteria and Yeast\nork alignment.\" PNAS 100, no. 20 (September\nSource: Kelley, Brian P., et al. \"C\n20,\nc) 2003 National Academy of Sciences, U.S.A.\nnformation Technology\nas Revealed by Global Protein Netw\n2003): 11304-11309. Copyright (\n\nYeast vs Yeast\nSearch for paralogous pathways\nConstructing a GAG merging the yeast protein\ninteraction network with an identical copy of itself\nOnly direct edge permitted\nProteins were not allowed to pair with themselves or\ntheir network neighbors\nObtain 300 highest scoring pathway alignments of\nlength 4 (level of significance p <= 0.0001)\nSMA5304: Biomedical Information Technology\n\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Kelley, Brian P., et al. \"Conserved Pathways Within Bacteria and Yeast\nas Revealed by Global Protein Network Alignment.\" PNAS 100, no. 20 (September 20,\n2003): 11304-11309. Copyright (c) 2003 National Academy of Sciences, U.S.A.\nParalogous Pathways\nSMA5304: Biomedical Information Technology\n- Both have DNA binding activity, they act in two\ndistinct processes\n- Msh2/3/6 is involved in mismatch repair during\nmeiosis and vegetative growth\n- Msh4/5 facilitates crossing over during\nhomologous recombination and is specific to\nmeiosis\n\nPathway Queries\nQuery a single protein network with specific\npathways of interest\nSimilar to using BLAST to query a sequence\ndatabase with a short nucleotide or amino acid\nsequence query\nQuery Yeast network with a MAPK pathway\nassociated with filamentation response\nSMA5304: Biomedical Information Technology\n\nQuerying Yeast\nNetwork\nSMA5304: Biomedical Information Technology\n- Two other well known pathways\n- low and high-osmolarity response\npathways\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Kelley, Brian P., et al. \"Conserved Pathways Within Bacteria and Yeast\nas Revealed by Global Protein Network Alignment.\" PNAS 100, no. 20 (September 20,\n2003): 11304-11309. Copyright (c) 2003 National Academy of Sciences, U.S.A.\n\nSMA5304: Biomedical Information Technology\nQuery: Ste20-Act1-Myo1\n\nGraphical Display\nSMA5304: Biomedical IAnformation Technology\nShort pathway queries are\ncapable of identifying both known\nand potentially novel paralogous\npathways\nImage courtesy of Brian P. Kelley. Source: Kelley, B. P., et al \"PathBLAST: A Tool for Alignment of Protein Interaction Networks.\" Nucleic\nAcids Res 32, web server issue, (July 1, 2004): W83-W88. (c) the authors, published by Oxford University Press under open access.\n\nSummary\nPathways from a well\nstudied network is used to\nshed light on their aligned\ncounterparts from a less\nwell characterized ones\nHP0609 is adjacent to\nHP0610 and HP0289,\nwhich localize to the\nbacterial outer\nmembrane, and opposite\nyeast Nup1, which\nlocalizes to the nuclear\npore.\nSMA5304: Biomedical Information Technology\nHP0609 is also\nmembrane-specific and that the\nbacterial pathway shares homology\nwith the yeast nuclear pore complex\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Kelley, Brian P., et al. \"Conserved Pathways Within Bacteria and Yeast\nas Revealed by Global Protein Network Alignment.\" PNAS 100, no. 20 (September 20,\n2003): 11304-11309. Copyright (c) 2003 National Academy of Sciences, U.S.A.\n\nSummary\nSingle pathways in\nbacteria frequently\ncorrespond to multiple\npathways in yeast\nYeast has undergone or\nmore whole-genome\nduplications relative to\nbacteria\nSMA5304: Biomedical Information Technology\nA single bacterial RNA helicase (deaD) occupies the same\npathway position, and perhaps functional role, as three different\nhelicases in yeast (Dbp2, Mak5, and Has1).\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Kelley, Brian P., et al. \"Conserved Pathways Within Bacteria and Yeast\nas Revealed by Global Protein Network Alignment.\" PNAS 100, no. 20 (September 20,\n2003): 11304-11309. Copyright (c) 2003 National Academy of Sciences, U.S.A.\n\nSummary\nProteins within high-\nscoring pathway\nalignments did not\nnecessarily pair with their\nbest sequence matches\nin other pathway\nBcp and Tsa1 are\nfunctional orthologs\ndespite weak sequence\nsimilarity\nSMA5304: Biomedical Information Technology\nBest match for bcp is Dot5 and not Tsa1\nBest match for Tsa1 is TsaA\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\ns Within Bacteria and Yeast\nPNAS 100, no. 20 (September 20,\nAcademy of Sciences, U.S.A.\nSource: Kelley, Brian P., et al. \"Conserved Pathway\nas Revealed by Global Protein Network Alignment.\"\n2003): 11304-11309. Copyright (c) 2003 National\n\nLimitations\nProteins may occur more than once in an identified\nmatched pathway\nbiologically implausible\nThe algorithm provides limited support for identifying non-\nexact pathway matches\nsupporting no more than a single consecutive deletion of proteins\nfrom the query pathway\nno more than a single consecutive insertion of proteins to the\nmatched pathway\nThe running time of the algorithm involves a factorial\nfunction of the pathway length\nSMA5304: Biomedical Information Technology\n\nMultiple Alignment\n(Sharan et al, 2005)\nThree-way alignment of the protein-protein\ninteraction networks\nCaenorhabditis elegans\nDrosophila melanogaster\nSaccharomyces cerevisiae.\nProtein interaction data were obtained from the\nDatabase of Interacting Proteins\n14,319 interactions among 4,389 proteins in yeast\n3,926 interactions among 2,718 proteins in worm\n20,720 interactions among 7,038 proteins in fly\nSMA5304: Biomedical Information Technology\n\nExperimental Results\nProtein sequences obtained from\nSaccharomyces Genome Database\nWormBase\nFlyBase\nCombined with the protein interaction data to generate a\nnetwork alignment\n9,011 protein similarity groups\n49,688 conserved interactions for the three networks\n183 protein clusters and 240 paths conserved at a\nsignificance level of P < 0.01\nSMA5304: Biomedical Information Technology\n\nConserved Network\nRegions\nSMA5304: Biomedical Information Technology\nOrange oval - Yeast\nGreen rectangle - Worm\nBlue hexagon - Fly\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Sharan, R., et al. \" Conserved Patterns of Protein Interaction in\nMultiple Species.\" PNAS 102, no. 6 (February 8, 2005): 1974-1979.\nCopyright (c) 2005 National Academy of Sciences, U.S.A.\n\nSMA5304: Biomedical Information Technology\nConserved links\nbetween different\nbiological processes\nRegions group\ntogether clusters that\nshare 15% overlap with\nat least one other\ncluster in the group\nand are all enriched for\nthe same GO cellular\nprocess\nSquare box:\nNetwork regions\nLargest number\nof conserved\nclusters\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Sharan, R., et al. \" Conserved Patterns of Protein Interaction in Multiple Species.\"\nPNAS 102, no. 6 (February 8, 2005): 1974-1979. Copyright (c) 2005 National Academy of Sciences, U.S.A.\n\nConserved Network\nRegions\nSMA5304: Biomedical Information Technology\nOrange oval - Yeast\nGreen rectangle - Worm\nBlue hexagon - Fly\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Sharan, R., et al. \" Conserved Patterns of Protein Interaction in\nMultiple Species.\" PNAS 102, no. 6 (February 8, 2005): 1974-1979.\nCopyright (c) 2005 National Academy of Sciences, U.S.A.\n\nPrediction of Protein\nFunctions\nSMA5304: Biomedical Information Technology\nBetter than sequence-\nbased methods\n(accuracy is 37-53%)\nTwo-hybrid tests of predicted interactions\nyielded a success rate in the range of 40-52%\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Sharan, R., et al. \" Conserved Patterns of Protein Interaction in Multiple Species.\"\nPNAS 102, no. 6 (February 8, 2005): 1974-1979. Copyright (c) 2005 National Academy of Sciences, U.S.A.\n\nPrediction of Proteins\nInteraction\nSMA CSB Program\nPrediction accuracy was highly significant\nCourtesy of National Academy of Sciences, U. S. A. Used with permission.\nSource: Sharan, R., et al. \" Conserved Patterns of Protein Interaction in Multiple Species.\"\nPNAS 102, no. 6 (February 8, 2005): 1974-1979. Copyright (c) 2005 National Academy of Sciences, U.S.A.\n\nOverview\nT. Shlomi, D. Segal, E. Ruppin, and R. Sharan. QPath: A\nMethod for Querying Pathways in a Protein-Protein\nInteraction Network. BMC Bioinformatics, 7(199), 2006.\nB. Dost, T. Shlomi, N. Gupta et al. QNet: A Tool for Querying\nProtein Interaction Networks. In Proc. of ACM RECOMB,\n2007.\nY. Tian, R. C. McEachin, C. Santos et al. SAGA: A subgraph\nmatching tool for biological graphs. Bioinformatics, 2006.\nSMA5304: Biomedical Information Technology\n\nQPath\nGoal\nQuerying linear pathways within a given network\nQPath\nSearches for matching pathways composed of distinct\nproteins that are similar to the query proteins in their\nsequence and interaction patterns\nSMA5304: Biomedical Information Technology\n\nPath Query Problem\nInput\na target network, represented as an undirected\nweighted graph G(V,E) with a weight function on\nthe edges w : E×E→R\na path query Q = (q1,...,qk).\nAdditionally, a scoring function H : Q×V is given.\nSMA5304: Biomedical Information Technology\n\nPath Query Problem\nOutput\nA set of best matching pathways P = (p1,...,pk) in G,\nwhere a good match is measured in two respects\nEach node in the matched pathway and its\ncorresponding node in the query are similar with\nrespect to the given scoring function H.\nThe reliability of edges in the matched pathway\nis high\nSMA5304: Biomedical Information Technology\n\nExample of Alignment\nSMA5304: Biomedical Information Technology\nImage source: Figure 1b in Shlomi, T., et al. \"QPath: A Method for Querying Pathways in a Protein-\nprotein Interaction Network.\" BMC Bioinformatics 7 (2006): 199.\n\nEvaluation of Pathway\nQueries\nQueried the yeast network with the yeast\nfilamentous growth MAPK cascade.\nSMA5304: Biomedical Information Technology\nImage source: Figure 6 (supplemental material) in Shlomi, T., et al. \"QPath: A Method for Querying\nPathways in a Protein-protein Interaction Network.\" BMC Bioinformatics 7 (2006): 199.\n\nEvaluation of QPath\nModified QPath algorithm is used to search the\nnetwork for pathways that have high interaction\nscores\nLimited to pathways consisting of 6 proteins\nAllow for (up to 3) insertions and deletions.\nIdentified a set of 271 non-redundant pathways\nwhose scores exceeded those of 99% of\nrandomly chosen pathways\nSMA5304: Biomedical Information Technology\n\nQuality Assessment of\nthe Pathways\nFunctional enrichment\nRepresenting the tendency of the pathway's\nproteins to have coherent GO functions\nExpression coherency\nmeasuring the similarity in expression profiles of\nthe pathway's coding genes across different\nexperimental conditions\nSMA5304: Biomedical Information Technology\n\nFunctional Significance\nSMA5304: Biomedical Information Technology\nSource: Table 1 in Shlomi, T., et al. \"QPath: A Method for Querying Pathways in a Protein-protein\nInteraction Network.\" BMC Bioinformatics 7 (2006): 199.\n\nBest Matching Pathways\nin Fly\nSMA5304: Biomedical Information Technology\nSource: Figure 3 in Shlomi, T., et al. \"QPath: A Method for Querying Pathways in a Protein-protein\nInteraction Network.\" BMC Bioinformatics 7 (2006): 199.\n\nIs the Insertion and Deletion\nFlexibility Really Required?\nSMA5304: Biomedical Information Technology\nMost conserved paths\nbetween the yeast and\nthe fly required more\nthan one insertion and\ndeletion\nSource: Figure 2 in Shlomi, T., et al. \"QPath: A Method for Querying Pathways\nin a Protein-protein Interaction Network.\" BMC Bioinformatics 7 (2006): 199.\n\nIs the Insertion and Deletion\nFlexibility Really Required?\nSMA5304: Biomedical Information Technology\nFunctionally enriched\npaths are strongly\ndepended on Ins/Del\nSource: Figure 2 in Shlomi, T., et al. \"QPath: A Method for Querying Pathways\nin a Protein-protein Interaction Network.\" BMC Bioinformatics 7 (2006): 199.\n\nFunctional Conservation\nFor 64% of the conserved paths, the\nmatched paths in the fly network conserved\none or more functions of the yeast query\npathways\nSMA5304: Biomedical Information Technology\n\nConclusions\nVery young field!\nAdvanced computational methodology\nScaling multiple network alignment\nAssociation of network features with diseases\nSMA5304: Biomedical Information Technology\n\nReferences Used\nT. Shlomi, D. Segal, E. Ruppin, and R. Sharan. QPath: A Method for\nQuerying Pathways in a Protein-Protein Interaction Network. BMC\nBioinformatics, 7(199), 2006.\nB. P. Kelley et al. Pathblast: a tool for alignment of protein\ninteraction networks. PNAS., 2003.\nR. Sharan, S. Suthram, R. M. Kelley et al. Conserved patterns of\nprotein interaction in multiple species. PNAS, 102, pp. 1974-1979,\n2005.\nRoded Sharan, Trey Ideker. Modeling Cellular Machinery\nThrough Biological Network Comparison. Nature\nBiotechnology, 24(4), April 2006.\nSMA5304: Biomedical Information Technology"
    },
    {
      "category": "Resource",
      "title": "A Practical Guide To Building OWL Ontologies Using The Protégé-OWL Plugin and CO-ODE Tools",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/d76d8bbee892ff47b042a0814c10e4f6_hrige_ontlgy_tut.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nA Practical Guide To Building OWL Ontologies Using The\nProt eg e-OWL Plugin and CO-ODE Tools\nEdition 1.0\nMatthew Horridge1 ,\nHolger Knublauch2, Alan Rector1, Robert Stevens1, Chris Wroe1\n1 The University Of Manchester\n2 Stanford University\nCopyright c The University Of Manchester\nAugust 27, 2004\nThis work is licensed under a Creative Commons Attribution-Noncommercial 3.0 unported license.\n\nContents\nIntroduction\n1.1\nConventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nRequirements\nWhat are OWL Ontologies?\n3.1\nThe Three Species Of OWL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.1\nOWL-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.2\nOWL-DL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.3\nOWL-Full . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.4\nChoosing The Sub-Language To Use . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2\nComponents of OWL Ontologies\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2.1\nIndividuals\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2.2\nProperties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2.3\nClasses\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nBuilding An OWL Ontology\n4.1\nNamed Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2\nDisjoint Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.3\nUsing The OWL Wizards To Create Classes . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.4\nOWL Properties\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.5\nInverse Properties\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n4.6\nOWL Property Characteristics\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.6.1\nFunctional Properties\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.6.2\nInverse Functional Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.6.3\nTransitive Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.6.4\nSymmetric Properties\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.7\nProperty Domains and Ranges\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.8\nDescribing And Defining Classes\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.8.1\nProperty Restrictions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.8.2\nExistential Restrictions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.9\nUsing A Reasoner . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.9.1\nDetermining the OWL Sub-Language\n. . . . . . . . . . . . . . . . . . . . . . . . .\n4.9.2\nUsing RACER\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.9.3\nInvoking The Reasoner . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.9.4\nInconsistent Classes\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.10 Necessary And Sufficient Conditions (Primitive and Defined Classes) . . . . . . . . . . . .\n4.10.1 Primitive And Defined Classes\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.11 Automatic Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.11.1 Classification Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.12 Universal Restrictions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.13 Automatic Classification and Open World Reasoning . . . . . . . . . . . . . . . . . . . . .\n4.13.1 Closure Axioms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.14 Value Partitions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.14.1 Covering Axioms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.15 Using the Properties Matix Wizard . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.16 Cardinality Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nMore On Open World Reasoning\n\nCreating Other OWL Constructs In Prot eg e-OWL\n6.1\nCreating Individuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.2\nhasValue Restrictions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.3\nEnumerated Classes\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.4\nAnnotation Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6.5\nMultiple Sets Of Necessary & Sufficient Conditions . . . . . . . . . . . . . . . . . . . . . .\nOther Topics\n7.1\nLanguage Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n7.2\nNamespaces And Importing Ontologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n7.2.1\nNamespaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n7.2.2\nCreating And Editing Namespaces in Prot eg e-OWL\n. . . . . . . . . . . . . . . . . 101\n7.2.3\nOntology Imports in OWL\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n7.2.4\nImporting Ontologies in Prot eg e-OWL\n. . . . . . . . . . . . . . . . . . . . . . . . 103\n7.2.5\nImporting The Dublin Core Ontology\n. . . . . . . . . . . . . . . . . . . . . . . . . 105\n7.2.6\nThe Prot eg e-OWL Meta Data Ontology . . . . . . . . . . . . . . . . . . . . . . . . 106\n7.3\nOntology Tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n7.4\nTODO List . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\nA Restriction Types\nA.1 Quantifier Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\nA.1.1\nsomeValuesFrom - Existential Restrictions\n. . . . . . . . . . . . . . . . . . . . . . 112\nA.1.2\nallValuesFrom - Universal Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . 112\nA.1.3\nCombining Existential And Universal Restrictions in Class Descriptions . . . . . . 113\nA.2 hasValue Restrictions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\nA.3 Cardinality Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\nA.3.1\nMinimum Cardinality Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\nA.3.2\nMaximum Cardinality Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n\nA.3.3\nCardinality Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\nA.3.4\nThe Unique Name Assumption And Cardinality Restrictions\n. . . . . . . . . . . . 115\nB Complex Class Descriptions\nB.1\nIntersection Classes (u)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\nB.2\nUnion Classes (⊔)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\n\nCopyright\nCopyright The University Of Manchester 2004\n\nAcknowledgements\nI would like to acknowledge and thank my colleagues at the University Of Manchester and also Stanford\nUniveristy for proof reading this tutorial/guide and making helpful comments and suggestions as to how\nit could be improved. In particular I would like to thank my immediate colleagues: Alan Rector, Nick\nDrummond, Hai Wang and Julian Seidenberg at the Univeristy Of Manchester, who suggested changes to\nearly drafts of the tutorial in order to make things clearer and also ensure the technical correctness of the\nmaterial. Alan was notably helpful in suggesting changes that made the tutorial flow more easily. I am\ngrateful to Chris Wroe and Robert Stevens who conceived the original idea of basing the tutorial on an\nontology about pizzas. I would especially like to thank Holger Knublauch from Stanford Univeristy who is\nthe developer of the Prot eg e-OWL plugin. Holger was always on hand to answer questions and provided\nfeedback and input about what the tutorial should cover. Finally, I would also like to thank Natasha\nNoy from Stanford University for using her valuable experience in teaching, creating and giving tutorials\nabout Prot eg e to provide detailed and useful comments about how initial drafts of the tutorial/guide\ncould be made better.\nThis work was supported in part by the CO-ODE project funded by the UK Joint Information Services\nCommittee and the HyOntUse Project (GR/S44686) funded by the UK Engineering and Physical Science\nResearch Council and by 21XS067A from the National Cancer Institute.\nhttp://www.co-ode.org\n\nExercise 1: Accomplish this\n1. Do this.\n2. Then do this.\n3. Then do this.\nChapter 1\nIntroduction\nThis guide introduces the Prot eg e-OWL plugin for creating OWL ontologies. Chapter 3 gives a brief\noverview of the OWL ontology language. Chapter 4 focuses on building an OWL-DL ontology and using\na Description Logic Reasoner to check the consistency of the ontology and automatically compute the\nontology class hierarchy. Chapter 6 describes some OWL constructs such as hasValue Restrictions and\nEnumerated classes, which aren't directly used in the main tutorial. Chapter 7 describes Namespaces,\nImporting ontologies and various features and utilities of the Prot eg e-OWL application.\n1.1\nConventions\nClass, property and individual names are written in a sans serif font like this.\nNames for user interface widget are presented in a style 'like this'.\nWhere exercises require information to be typed into Prot eg e-OWL a type writer font is used like this.\nExercises and required tutorial steps are presented like this:\n\nTips and suggestions related to using Prot eg e-OWL and building ontologies are\npresented like this.\nExplanation as to what things mean are presented like this.\nPotential pitfalls and warnings are presented like this.\nGeneral notes are presented like this.\nVocabulary explanations and alternative names are presented like this.\n\n1http://protege.stanford.edu\n2http://www.co-ode.org\nChapter 2\nRequirements\nIn order to follow this tutorial you must have Prot eg e 2.1 (or later)1, the Prot eg e-OWL plugin (latest beta)\nand also the OWL Wizards Plugin, which are available via the CO-ODE web site 2 . Since the release\nof Prot eg e 2.1, the Prot eg e-OWL plugin and the OWL Wizards are bundled in one single download.\nIt is also recommended (but not necessary) to use the OWLViz plugin, which allows the asserted and\ninferred classification hierarchies to be visualised, and is available from the CO-ODE web site, or can\nbe installed when Prot eg e 2.1 is installed. For installation steps, please see the documentation for each\ncomponent. Finally, it is necessary to have a DIG (Description Logic Implementers Group) compliant\nreasoner installed in order to compute subsumption relationships between classes, and detect inconsistent\nclasses. It is recommended that the latest version of the RACER reasoner be used, which can be obtained\nfrom http://www.sts.tu-harburg.de/~r.f.moeller/racer/.\n\nChapter 3\nWhat are OWL Ontologies?\nOntologies are used to capture knowledge about some domain of interest. An ontology describes the\nconcepts in the domain and also the relationships that hold between those concepts. Different ontology\nlanguages provide different facilities. The most recent development in standard ontology languages is\nOWL from the World Wide Web Consortium (W3C)1. Like Prot eg e OWL makes it possible to describe\nconcepts but it also provides new facilities. It has a richer set of operators - e.g. and, or and negation. It is\nbased on a different logical model which makes it possible for concepts to be defined as well as described.\nComplex concepts can therefore be built up in definitions out of simpler concepts. Furthermore, the\nlogical model allows the use of a reasoner which can check whether or not all of the statements and\ndefinitions in the ontology are mutually consistent and can also recognise which concepts fit under which\ndefinitions. The reasoner can therefore help to maintain the hierarchy correctly. This is particularly\nuseful when dealing with cases where classes can have more than one parent.\n3.1\nThe Three Species Of OWL\nOWL ontologies may be categorised into three species or sub-languages: OWL-Lite, OWL-DL and OWL-\nFull. A defining feature of each sub-language is its expressiveness. OWL-Lite is the least expressive\nsub-langauge.\nOWL-Full is the most expressive sub-language.\nThe expressiveness of OWL-DL falls\nbetween that of OWL-Lite and OWL-Full. OWL-DL may be considered as an extension of OWL-Lite\nand OWL-Full an extension of OWL-DL.\n3.1.1\nOWL-Lite\nOWL-Lite is the syntactically simplest sub-language. It is intended to be used in situations where only\na simple class hierarchy and simple constraints are needed. For example, it is envisaged that OWL-Lite\nwill provide a quick migration path for existing thesauri and other conceptually simple hierarchies.\n1http://www.w3.org/TR/owl-guide/\n\n3.1.2\nOWL-DL\nOWL-DL is much more expressive than OWL-Lite and is based on Description Logics (hence the suffix\nDL). Description Logics are a decidable fragment of First Order Logic2 and are therefore amenable to\nautomated reasoning. It is therefore possible to automatically compute the classification hierarchy3 and\ncheck for inconsistencies in an ontology that conforms to OWL-DL. This tutorial focuses on OWL\nDL.\n3.1.3\nOWL-Full\nOWL-Full is the most expressive OWL sub-language. It is intended to be used in situations where very\nhigh expressiveness is more important than being able to guarantee the decidability or computational\ncompleteness of the language. It is therefore not possible to perform automated reasoning on OWL-Full\nontologies.\n3.1.4\nChoosing The Sub-Language To Use\nFor a more detailed synopsis of the three OWL sub-languages see the OWL Web Ontology Language\nOverview4 . Although many factors come into deciding the appropriate sub-language to use, there are\nsome simple rules of thumb.\n- The choice between OWL-Lite and OWL-DL may be based upon whether the simple constructs of\nOWL-Lite are sufficient or not.\n- The choice between OWL-DL and OWL-Full may be based upon whether it is important to be\nable to carry out automated reasoning on the ontology or whether it is important to be able to use\nhighly expressive and powerful modelling facilities such as meta-classes (classes of classes).\nThe Prot eg e-OWL plugin does not make the distinction between editing OWL-Lite and OWL-DL on\ntologies. It does however offer the option to constrain the ontology being edited to OWL-DL, or allow\nthe expressiveness of OWL-Full -- See section 7.1 for more information on how to constrain the ontology\nto OWL-DL.\n3.2\nComponents of OWL Ontologies\nOWL ontologies have similar components to Prot eg e frame based ontologies. However, the terminology\nused to describe these components is slightly different from that used in Prot eg e . An OWL ontology\nconsists of Individuals, Properties, and Classes, which roughly correspond to Prot eg e Instances, Slots and\nClasses.\n2Logics are decidable if computations/algorithms based on the logic will terminate in a finite time.\n3Also known as subsumption reasoning.\n4http://www.w3.org/TR/owl-features\n\nMatthew\nGemma\nUSA\nFluffy\nFido\nFigure 3.1: Representation Of Individuals\n3.2.1\nIndividuals\nIndividuals, represent objects in the domain that we are interested in5 . An important difference between\nProt eg e and OWL is that OWL does not use the Unique Name Assumption (UNA). This means that\ntwo different names could actually refer to the same individual. For example, \"Queen Elizabeth\", \"The\nQueen\" and \"Elizabeth Windsor\" might all refer to the same individual. In OWL, it must be explicitly\nstated that individuals are the same as each other, or different to each other -- otherwise they might be\nthe same as each other, or they might be different to each other. Figure 3.1 shows a representation of\nsome individuals in some domain - in this tutorial we represent individuals as diamonds in diagrams.\n\nIndividuals are also known as instances. Individuals can be referred to as being\n'instances of classes'.\n3.2.2\nProperties\nProperties are binary relations6 on individuals - i.e.\nproperties link two individuals together7 .\nFor\nexample,\n\nproperty hasChild might link the individual Peter to the individual Matthew. Properties can have inverses.\nhasOwner\nisOwnedBy\nFor example, the inverse of\nis\n. Properties can be limited to having a single value -\ni.e. to being functional. They can also be either transitive or symmetric. These 'property characteristics'\nare explained in detail section 4.8. Figure 3.2 shows a representation of some properties linking some\nindividuals together.\nProperties are roughly equivalent to slots in Prot eg e . They are also known as\nroles in description logics and relations in UML and other object oriented notions.\nIn GRAIL and some other formalisms they are called attributes.\n5Also known as the domain of discourse.\n6A binary relation is a relation between two things.\n7Strictly speaking we should speak of 'instances of properties' linking individuals, but for the sake of brevity we will\nkeep it simple.\nthe property hasSibling might link the individual Matthew to the individual Gemma, or the\nEngland\nItaly\n\nMatthew\nGemma\nEngland\nli\nv\ne\ns\nI\nn\nha\nsS\nib\nli\nn\ng\nFigure 3.2: Representation Of Properties\nMatthew\nGemma\nEngland\nItaly\nUSA\nFluffy\nFido\nlives\nIn\nCo\nu\nnt\nry\nha\nsP\ne\nt\nh\na\ns\nS\ni\nb\nli\nn\ng\nPet\nCountry\nPerson\nFigure 3.3: Representation Of Classes (Containing Individuals)\n3.2.3\nClasses\nOWL classes are interpreted as sets that contain individuals. They are described using formal (math\nematical) descriptions that state precisely the requirements for membership of the class. For example,\nthe class Cat would contain all the individuals that are cats in our domain of interest.8 Classes may be\norganised into a superclass-subclass hierarchy, which is also known as a taxonomy. Subclasses specialise\n('are subsumed by') their superclasses. For example consider the classes Animal and Cat - Cat might\nbe a subclass of Animal (so Animal is the superclass of Cat). This says that, 'All cats are animals', 'All\nmembers of the class Cat are members of the class Animal', 'Being a Cat implies that you're an Animal',\nand 'Cat is subsumed by Animal'. One of the key features of OWL-DL is that these superclass-subclass\nrelationships (subsumption relationships) can be computed automatically by a reasoner - more on this\nlater. Figure 3.3 shows a representation of some classes containing individuals - classes are represented\nas circles or ovals, rather like sets in Venn diagrams.\nThe word concept is sometimes used in place of class.\nClasses are a concrete\nrepresentation of concepts.\nIn OWL classes are built up of descriptions that specify the conditions that must be satisfied by an\nindividual for it to be a member of the class. How to formulate these descriptions will be explained as\n8Individuals may belong to more than one class.\n\nthe tutorial progresses.\n\nChapter 4\nBuilding An OWL Ontology\nThis chapter describes how to create an ontology of Pizzas. We use Pizzas because we have found them\nto provide many useful examples.1\nExercise 2: Create a new OWL project\n1. Start Prot eg e\n2. When the New Project dialog box appears, select 'OWL Files' from the 'Project\nFormat' list section on the left hand side of the dialog box, and press 'New'.\nAfter a short amount of time, a new empty Prot eg e-OWL project will have been created.\n4.1\nNamed Classes\nWhen Prot eg e-OWL starts the OWLClasses tab shown in Figure 4.1 will be visible. The initial class\nhierarchy tree view should resemble the picture shown in Figure 4.2. The empty ontology contains one\nclass called owl:Thing. As mentioned previously, OWL classes are interpreted as sets of individuals (or\nsets of objects). The class owl:Thing is the class that represents the set containing all individuals. Because\nof this all classes are subclasses of owl:Thing. 2\nLet's add some classes to the ontology in order to define what we believe a pizza to be.\n1The Ontology that we will created is based upon a Pizza Ontology that has been used as the basis for a course on\nediting DAML+OIL ontologies in OilEd (http://oiled.man.ac.uk), which was taught at the University Of Manchester.\n2owl:Thing is part of the OWL Vocabulary, which is defined by the ontology located at http://www.w3.org/2002/07/\nowl/\\#\n\nFigure 4.1: The Classes Tab\nCreate subclass (of\nthe selected class)\nDelete selected class\nFigure 4.2: The Class Hierarchy Pane\n\n3. Repeat the previous steps to add the classes PizzaTopping and also PizzaBase, en\nsuring that owl:Thing is selected before the 'Create subclass' button is pressed so\nthat the classes are created as subclasses of owl:Thing.\nThe class hierarchy should now resemble the hierarchy shown in Figure 4.4.\nA class hierarchy may also be called a taxonomy.\nAlthough there are no mandatory naming conventions for OWL classes, we recom\nmend that all class names should start with a capital letter and should not contain\nspaces. (This kind of notation is known as CamelBack notation and is the nota\ntion used in this tutorial). For example Pizza, PizzaTopping, MargheritaPizza.\nAlternatively, you can use underscores to join words. For example Pizza Topping.\nWhich ever convention you use, it is important to be consistent.\nFigure 4.3: Class Name Widget\nExercise 3: Create classes Pizza, PizzaTopping and PizzaBase\n1. Press the 'Create subclass' button shown in Figure 4.2. This button creates a new\nclass as a subclass of the selected class (in this case we want to create a subclass of\nowl:Thing).\n2. Rename the class using the 'Class name widget' which is located to the right of the\nclass hierarchy (shown in Figure 4.3) to Pizza and hit return.\n4.2\nDisjoint Classes\nHaving added the classes Pizza, PizzaTopping and PizzaBase to the ontology, we now need to say these\nclasses are disjoint, so that an individual (or object) cannot be an instance of more than one of these\nthree classes. To specify classes that are disjoint from the selected class the 'Disjoints widget' which is\n\nlocated in the lower right hand corner of the 'OWLClasses' tab is used. (See Figure 4.5).\nExercise 4: Make Pizza, PizzaTopping and PizzaBase disjoint from each other\n1. Select the class Pizza in the class hierarchy.\n2. Press the 'Add siblings' button on the disjoint classes widget. This will make Pizz\naBase and PizzaTopping (the sibling classes of Pizza) disjoint from Pizza.\nNotice that the disjoint classes widget now displays PizzaTopping and PizzaBase.\nSelect the class\nPizzaBase. Notice that the disjoint classes widget displays the classes that are now disjoint to PizzaBase,\nnamely Pizza and PizzaTopping.\nFigure 4.4: The Initial Class Hierarchy\nAdd disjointclass\nCreate disjoint class from\nOWL expression\nAdd all siblings\nRemove all siblings\nRemove selected class from list\nDelete selected row\nFigure 4.5: The Disjoint Classes Widget\n\nFigure 4.6: Add Group Of Classes Wizard: Select class page\nFigure 4.7: Add Group Of Classes Wizard: Enter classes page\nOWL Classes are assumed to 'overlap'.\nWe therefore cannot assume that an\nindividual is not a member of a particular class simply because it has not been\nasserted to be a member of that class. In order to 'separate' a group of classes\nwe must make them disjoint from one another. This ensures that an individual\nwhich has been asserted to be a member of one of the classes in the group cannot\nbe a member of any other classes in that group. In our above example Pizza,\nPizzaTopping and PizzaBase have been made disjoint from one another. This\nmeans that it is not possible for an individual to be a member of a combination\nof these classes - it would not make sense for an individual to be a Pizza and a\nPizzaBase!\n\n7. Hit the 'Next' button to display the annotations page. Here we could add annotations\nif we wanted to. Most commonly annotations are used to record editorial information\nabout the ontology - who created it, when it was created, when it was revised, etc.\nThe basic OWL annotation properties are selectable by default. For now, we will not\nadd any annotations, so just hit the 'Finish' button.\n4.3\nUsing The OWL Wizards To Create Classes\nThe OWL Wizards plugin, which is available from the Prot eg e web site, is an extensible set of Wizards\nthat are designed to make carrying out common, repetitive and time consuming tasks easy. In this section\nwe will use the 'Create A Group Of Classes' wizard to add some subclasses of the class PizzaBase.\nTo use the OWL Wizards you must ensure that the OWL Wizards plugin in installed and configured in\nProt eg e .\nExercise 5: Use the 'Create Group Of Classes' Wizard to create ThinAndCrispy and DeepPan as\nsubclasses of PizzaBase\n1. Select the class PizzaBase in the class hierachy.\n2. From the Wizards menu on the Prot eg e menu bar select the item 'Create Group Of\nClasses'.\n3. The Wizard shown in Figure 4.6 will appear. Since we preselected the PizzaBase\nclass, the first radio button at the top of the Wizard should be prompting us to create\nthe classes under the class PizzaBase. If we had not preselected PizzaBase before\nstarting the Wizard, then the tree could be used to select the class.\n4. Press the 'Next' button on the Wizard--The page shown in Figure 4.7 will be dis\nplayed. We now need to tell the Wizard the subclasses of PizzaBase that we want to\ncreate. In the large text area, type in the class name ThinAndCrispyBase (for a thin\nbased pizza) and hit return. Also enter the class name DeepPanBase so that the page\nresembles that shown in Figure 4.7 .\n5. Hit the 'Next' button on the Wizard. The Wizard checks that the names entered\nadhere to the naming styles that have previously been mentioned (No spaces etc.). It\nalso checks for uniqueness - no two class names may be the same. If there are any\nerrors in the class names, they will be be presented on this page, along with suggestions\nfor corrections.\n6. Hit the 'Next' button on the Wizard. Ensure the tick box 'Make all new classes\ndisjoint' is ticked -- instead of having to use the disjoint classes widget, the Wizard\nwill automatically make the new classes disjoint for us.\n\nIf we had imported the Dublin Core ontology (see section 7.2.5) then the Dublin\nCore annotation properties would have been available to annotate our classes in\nstep 7 Exercise 5 . Dublin Core is a set of metadata elements that, in our case,\ncan be used to annotate various elements of an ontology with information such as\n'creator', 'date', 'language' etc. For more information see http://dublincore.\norg/a .\naAn ontology will be put into OWL-Full if the ontologies that are available on the Dublin Core\nwebsite are imported. We recommend that an OWL-DL version of the Dublin Core ontology\nwhich is located in the Prot eg e ontology library is imported -- details of this can be found in\nsection 7.2.5\n\nalso DeepPanBase as subclasses of PizzaBase. These new classes should also be disjoint to each other.\nHence, a pizza base cannot be both thin and crispy and deep pan. It isn't difficult to see that if we had\na lot of classes to add to the ontology, the Wizard would dramatically speed up the process of adding\nthem.\nOn page two of the 'Create group of classes wizard' the classes to be created\nare entered. If we had a lot of classes to create that had the same prefix or suffix\nwe could use the options to auto prepend and auto append text to the class names\nthat we entered.\nAfter the 'Finish' button has been pressed, the Wizard creates the classes, makes them disjoint, and\nselects them in the Prot eg e OWLClasses tab. The ontology should now have ThinAndCrispyBase and\nCreating Some Pizza Toppings\nNow that we have some basic classes, let's create some pizza toppings. In order to be useful later on the\ntoppings will be grouped into various categories -- meat toppings, vegetable toppings, cheese toppings\n\nand seafood toppings.\nExercise 6: Create some subclasses of PizzaTopping\n1. Select the class PizzaTopping in the class hierarchy.\n2. Use the OWL Wizards to add some subclasses of PizzaTopping called MeatTopping,\nUp to this point, we have created some simple named classes, some of which\nare subclasses of other classes. The construction of the class hierarchy may have\nseemed rather intuitive so far. However, what does it actually mean to be a sub\nclass of something in OWL? For example, what does it mean for VegetableTopping\nto be a subclass of PizzaTopping, or for TomatoTopping to be a subclass of Veg\netableTopping? In OWL subclass means necessary implication. In other words,\nif VegetableTopping is a subclass of PizzaTopping then ALL instances of Veg\netableTopping are instances of PizzaTopping, without exception -- if something is\na VegetableTopping then this implies that it is also a PizzaTopping as shown in\nFigure 4.9.a\naIt is for this reason that we seemingly pedantically named all of our toppings with the suffix\nof 'Topping', for example, HamTopping. Despite the fact that class names themselves carry no\nformal semantics in OWL (and in other ontology languages), if we had named HamTopping Ham,\nthen this could have implied to human eyes that anything that is a kind of ham is also a kind of\nMeatTopping and also a PizzaTopping.\n\nThe class hierarchy should now look similar to that shown in Figure 4.8 (the ordering of classes may be\nslightly different).\n\nVegetableTopping, CheeseTopping and also SeafoodTopping. Make sure that these\nclasses are disjoint to each other.\n3. Next add some different kinds of meat topping. Select the class MeatTopping, and use\nthe 'Create Group Of Classes' Wizard to add the following subclasses of Meat-\nTopping: SpicyBeefTopping, PepperoniTopping, SalamiTopping, HamTopping. Once\nagain, ensure that the classes are created as disjoint classes.\n4. Add some different kinds of vegetable toppings by creating the following disjoint sub\nclasses of VegetableTopping: TomatoTopping, OliveTopping, MushroomTopping, Pep\nperTopping, OnionTopping and CaperTopping. Add further subclasses of PepperTop\nping: RedPepperTopping, GreenPepperTopping and JalapenoPepperTopping making\nsure that the subclasses of PepperTopping are disjoint\n5. Now add some different kinds of cheese toppings. In the same manner as before, add\nthe following subclasses of CheeseTopping, ensuring that the subclasses are disjoint\nto each other: MozzarellaTopping, and ParmezanTopping\n6. Finally, add some subclasses of SeafoodTopping to represent different kinds of sea\nfood: TunaTopping, AnchovyTopping and PrawnTopping.\n\nFigure 4.8: Class Hierarchy\n\nPizzaTopping\nTomatoTopping\nVegetableTopping\nFigure 4.9: The Meaning Of Subclass -- All individuals that are members of the class TomatoTopping are\nmembers of the class VegetableTopping and members of the class PizzaTopping as we have stated\nthat TomatoTopping is a subclass of VegetableTopping which is a subclass of PizzaTopping\n4.4\nOWL Properties\nOWL Properties represent relationships between two individuals. There are two main types of properties,\nObject properties and Datatype properties. Object properties link an individual to an individual. Datatype\nproperties link an individual to an XML Schema Datatype value3 or an rdf literal4 . OWL also has a\nthird type of property - Annotation properties5 . Annotation properties can be used to add information\n(metadata -- data about data) to classes, individuals and object/datatype properties. Figure 4.10 depicts\nan example of each type of property.\nProperties may be created using the 'Properties' tab shown in Figure 4.11. It is also possible to create\nproperties using the 'Properties Widget' shown in Figure 4.12 which is located on the 'OWLClasses'\ntab. Figure 4.13 shows the buttons located in the top left hand corner of the 'Properties' tab that\nare used for creating OWL properties. As can be seen from Figure 4.13, there are buttons for creat\ning Datatype properties, Object properties and Annotation properties. Most properties created in this\ntutorial will be Object properties.\nExercise 7: Create an object property called hasIngredient\n1. Switch to the 'Propterties' tab. Use the 'Create Object Property' button (see\nFigure 4.13 - second button on the left) to create a new Object property. An Object\nproperty with a generic name will be created.\n2. Rename the property to hasIngredient as shown in Figure 4.14 (The 'Property Name\nWidget'.\n3See http://www.w3.org/TR/xmlschema-2/ for more information on XML Schema Datatypes\n4RDF = Resource Description Framework. See http://www.w3.org/TR/rdf-primer/ for an excellent introduction to\nRDF.\n5Object properties and Datatype properties may be marked as Annotation properties\n\nha\nsS\nis\nte\nr\nMatthew\nGemma\nAn object property linking the individual\nMatthew to the individual Gemma\nha\nsA\nge\nMatthew\n\"25\"^^xsd:integer\nA datatype property linking the individual\nMatthew to the data literal '25', which has a type\nof an xml:integer.\ndc\n:c\nre\nat\nor\nJetEngine\n''Matthew Horridge''\nAn annotation property, linking the class 'JetEngine'\nto the data literal (string) ''Matthew Horridge''.\nFigure 4.10: The Different types of OWL Properties\n\nFigure 4.11: The PropertiesTab\nFigure 4.12: The Properties Widget\n\nAlthough there is no strict naming convention for properties, we recommend that\nproperty names start with a lower case letter, have no spaces and have the re\nmaining words capitalised. We also recommend that properties are prefixed with\nthe word 'has', or the word 'is', for example hasPart, isPartOf, hasManufacturer,\nisProducerOf. Not only does this convention help make the intent of the property\nclearer to humans, it is also taken advantage of by the 'English Prose Tooltip\nGenerator'a, which uses this naming convention where possible to generate more\nhuman readable expressions for class descriptions.\naThe English Prose Tooltip Generator displays the description of classes etc. in a more natural\nform of English, making is easy to understand a class description. The tooltips pop up when the\nmouse pointer is made to hover over a class description in the user interface.\nHaving added the hasIngredient property, we will now add two more properties -- hasTopping, and\nhasBase. In OWL, properties may have sub properties, so that it is possible to form hierarchies of\nproperties. Sub properties specialise their super properties (in the same way that subclasses specialise\ntheir superclasses). For example, the property hasMother might specialise the more general property of\nhasParent. In the case of our pizza ontology the properties hasTopping and hasBase should be created\nas sub properties of hasIngredient. If the hasTopping property (or the hasBase property) links two\nFigure 4.13: Property Creation Buttons -- located on the Properties Tab above the property list/tree\nCreate datatype property\nCreate object property\nCreate datatype annotation property\nCreate object annotation property\nDelete selected property\nFigure 4.14: Property Name Widget\n\nindividuals this implies that the two individuals are related by the hasIngredient property.\nExercise 8: Create hasTopping and hasBase as sub-properties of hasIngredient\n1. To create the hasTopping property as a sub property of the hasIngredient property,\nright click (or ctrl click on the Mac) on the hasIngredient property in the property\nhierarchy on the 'Properties' tab. The menu shown in Figure 4.15 will pop up.\n2. Select the 'Create subproperty' item from the popup menu. A new object property\nwill be created as a sub property of the hasIngredient property.\n3. Rename the new property to hasTopping.\n4. Repeat the above steps but name the property hasBase.\nFigure 4.15: PropertyHierarchyMenu\nNote that it is also possible to create sub properties of datatype properties. However, it is not possible to\nmix and match object properties and datatype properties with regards to sub properties. For example, it\nis not possible to create an object property that is the sub property of a datatype property and vice-versa.\n4.5\nInverse Properties\nEach object property may have a corresponding inverse property. If some property links individual a to\nindividual b then its inverse property will link individual b to individual a. For example, Figure 4.16\nshows the property hasParent and its inverse property hasChild -- if Matthew hasParent Jean, then\nbecause of the inverse property we can infer that Jean hasChild Matthew.\nInverse properties can be created/specified using the inverse property widget shown in Figure 4.17. For\n\nMatthew\nJean\nha\nsC\nhil\nd\nFigure 4.16: An Example Of An Inverse Property: hasParent has an inverse property that is hasChild\ncompleteness we will specify inverse properties for our existing properties in the Pizza Ontology.\nExercise 9: Create some inverse properties\n1. Use the 'Create object property' button on the 'Properties' tab to create a new\nObject property called isIngredientOf (this will become the inverse property of hasIn\ngredient).\n2. Press the 'Assign existing property' button on the inverse property widget shown\nin Figure 4.17.\nThis will display a dialog from which properties may be selected.\nSelect the hasIngredient property and press 'OK'. The property hasIngredient should\nnow be displayed in the 'Inverse Property' widget. The properties hierarchy should\nalso now indicate that hasIngredient and isIngredientOf are inverse properties of each\nother.\n3. Select the hasBase property.\n5. Select the hasTopping property.\n6. Press the 'Create new inverse property' button on the 'Inverse Property' widget.\nUse the property dialog that pops up to rename the property isToppingOf. Close the\ndialog. Notice that isToppingOf has been created as a sub property of isIngredientOf.\nThe property hierarchy should now look like the picture shown in Figure 4.18. Notice the 'bidirectional'\narrows that indicate inverse properties.\n4.6\nOWL Property Characteristics\nha\nsP\nar\nen\nt\n4. Press the 'Create new inverse property' button on the 'Inverse Property' widget.\nThis will pop up a dialog that contains information about the newly created property.\nUse this dialog to rename the property isBaseOf and the close the dialog window\n(using the operating system close window button on the title bar). Notice that the\nisBaseOf property has been created as a sub property of the isIngredientOf property.\nThis corresponds to the fact that hasBase is a sub property of hasIngredient, and\nisIngredientOf is the inverse property of hasIngredient.\nOWL allows the meaning of properties to be enriched through the use of property characteristics. The\nfollowing sections discuss the various characteristics that properties may have:\n\nCreate new inverse property\n(Create a new property and\nassigns it to be the inverse of\nthe current property).\nUnassign current inverse\nproperty\nAssign existing property\n(Assign an existing property\nto be the inverse property of\nthe current property).\nFigure 4.17: The Inverse Property Widget\nFigure 4.18: The Property Hierarchy With Inverse Properties\n\nMargaret\nMo\nth\ner\nFigure 4.19: An Example Of A Functional Property: hasBirthMother\nFunctional properties are also known as single valued properties and also features.\n4.6.1\nFunctional Properties\nIf a property is functional, for a given individual, there can be at most one individual that is related to\nthe individual via the property. Figure 4.19 shows an example of a functional property hasBirthMother\n-- something can only have one birth mother. If we say that the individual Jean hasBirthMother Peggy\nand we also say that the individual Jean hasBirthMother Margaret6, then because hasBirthMother is a\nfunctional property, we can infer that Peggy and Margaret must be the same individual. It should be\nnoted however, that if Peggy and Margaret were explicitly stated to be two different individuals then the\nabove statements would lead to an inconsistency.\nImplies Peggy and Margaret\nare the same individual\nPeggy\nJean\nha\nsB\nirt\nhM\noth\ner\nha\nsB\nirt\nh\n4.6.2\nInverse Functional Properties\nIf a property is inverse functional then it means that the inverse property is functional. For a given\nindividual, there can be at most one individual related to that individual via the property. Figure 4.20\nshows an example of an inverse functional property isBirthMotherOf. This is the inverse property of\nhasBirthMother -- since hasBirthMother is functional, isBirthMotherOf is inverse functional. If we state\nthat Peggy is the birth mother of Jean, and we also state that Margaret is the birth mother of Jean,\nthen we can infer that Peggy and Margaret are the same individual.\nImplies same individual\nMargaret\nPeggy\nJean\nisB\nirt\nhM\noth\nerO\nf\nisB\nirt\nhM\not\nhe\nrO\nf\nFigure 4.20: An Example Of An Inverse Functional Property: isBirthMotherOf\n4.6.3\nTransitive Properties\nIf a property is transitive, and the property relates individual a to individual b, and also individual b to\nindividual c, then we can infer that individual a is related to individual c via property P. For example,\nFigure 4.21 shows an example of the transitive property hasAncestor. If the individual Matthew has an\n6The name Peggy is a diminutive form for the name Margaret\n\nExercise 10: Make the hasIngredient property transitive\n1. Select the hasIngredient property in the property hierarchy on the 'Properties' tab.\n2. Tick the 'Transitive' tick box on the 'Property Characteristics Widget'.\n3. Select the isIngredientOf property, which is the inverse of hasIngredient. Ensure that\nthe transitive tick box is ticked.\nancestor that is Peter, and Peter has an ancestor that is William, then we can infer that Matthew has an\nancestor that is William - this is indicated by the dashed line in Figure 4.21.\nMatthew\nPeter\nWilliam\nh\na\ns\nA\nn\nc\ne\ns\nt\no\nr\nh\na\ns\nA\nn\nc\ne\ns\nt\no\nr\nha\nsA\nnc\nes\nto\nr\nFigure 4.21: An Example Of A Transitive Property: hasAncestor\n4.6.4\nSymmetric Properties\nIf a property P is symmetric, and the property relates individual a to individual b then individual b is\nalso related to individual a via property P. Figure 4.22 shows an example of a symmetric property. If the\nindividual Matthew is related to the individual Gemma via the hasSibling property, then we can infer\nthat Gemma must also be related to Matthew via the hasSibling property. In other words, if Matthew\nhas a sibling that is Gemma, then Gemma must have a sibling that is Matthew. Put another way, the\nproperty is its own inverse property.\nha\nsS\nib\nli\nng\nMatthew\nGemma\nha\nsS\nib\nlin\ng\nFigure 4.22: An Example Of A Symmetric Property: hasSibling\nWe want to make the hasIngredient property transitive, so that for example if a pizza topping has an\ningredient, then the pizza itself also has that ingredient. To set the property characteristics of a property\nthe property characteristics widget shown in Figure 4.23 which is located in the lower right hand corner\nof the properties tab is used.\n\nviduals. Making a transitive property functional would therefore not make sense.\n1. Select the hasBase property.\n2. Click the 'Allows multiple values' tick box on the 'Property Charachteristics\nWidget' so that it is unticked.\nWe now want to say that out pizza can only have one base. There are numerous ways that this could be\naccomplished. However, to do this we will make the hasBase property functional, so that it may have\nonly one value for a given individual.\nExercise 11: Make the hasBase property functional\n\nIf a property is transitive then its inverse property should also be transitive.a\naAt the time of writing this must be done manually in Prot eg e-OWL . However, the reasoner\nwill assume that if a property is transitive, its inverse property is also a transitive.\nNote that if a property is transitive then it cannot be functional.a\naThe reason for this is that transitive properties, by their nature, may form 'chains' of indi\nUnticking this box makes a property functional\nTicking this box makes a property Invers Functional\nAn inverse property may be specified here. Use the 'O' button to create\na new property and simultaneously make the new property the inverse.\nUse the 'O+' button to add an existing property as the inverse.\nChecking this box makes the property symmetric\nChecking this box makes the property transitive\nFigure 4.23: Property Characteristics Widgets\n\n4.7\nProperty Domains and Ranges\nProperties may have a domain and a range specified. Properties link individuals from the domain to\nindividuals from the range. For example, in our pizza ontology, the property hasTopping would probably\nlink individuals belonging the the class Pizza to individuals belonging to the class of PizzaTopping. In\nthis case the domain of the hasTopping property is Pizza and the range is PizzaTopping -- this is\ndepicted in Figure 4.24.\nProperty Domains And Ranges In OWL -- It is important to realise that in\nOWL domains and ranges should not be viewed as constraints to be checked. They\nare used as 'axioms' in reasoning. For example if the property hasTopping has the\ndomain set as Pizza and we then applied the hasTopping property to IceCream\n(individuals that are members of the class IceCream), this would generally not\nresult in an error. It would be used to infer that the class IceCream must be a\nsubclass of Pizza! a.\naAn error will only be generated (by a reasoner) if Pizza is disjoint to IceCream\nWe now want to specify that the hasTopping property has a range of PizzaTopping. To do this the range\nwidget shown in Figure 4.25 is used. By default the drop down box displays 'Instance', meaning that the\nha\nsT\no\npi\nn\ng\np\nisTo\nppin\ngOf\nhasTopping\nisTop\npingOf\nha\nsT\no\np\npi\nn\ng\nisTop\npingO\nf\nPizza\nPizzaTopping\nFigure 4.24: The domain and range for the hasTopping property and its inverse property isToppingOf. The\ndomain of hasTopping is Pizza the range of hasTopping is PizzaTopping -- the domain and range\nfor isToppingOf are the domain and range for hasTopping swapped over\nIf a datatype property is selected, the property characteristics widget will be re\nduced so that only options for 'Allows multiple values' and 'Inverse Func\ntional' will be displayed.\nThis is because OWL-DL does not allow datatype\nproperties to be transitive, symmetric or have inverse properties.\n\nplayed in the range list.\nIt is also possible, but usually incorrect, to specify that a class rather than its\nindividuals is the range of a property. This is done by selecting 'class' in the drop\ndown box on the range widget. It is a common mistake to believe that the range\nof a property is a class when the range is really the individuals that are members\nof the class. Specifying the range of a property as a class treats the class itself as\nan individuala . This is a kind of 'meta-statement' and causes the ontology to be\nin OWL-Full.\naRemember that instances of object properties link individuals to individuals\nSelect the 'type' of range (Instance or class)\nCreate a class expression as the range\nAdd a (existing) named class as the range\nRemove the selected named class from the range\nRemove (delete) the selected class expression from the range\nFigure 4.25: Property Range Widget (For Object Properties)\nproperty links instances of classes to instances of classes.\nExercise 12: Specify the range of hasTopping\n1. Make sure that the hasTopping property is selected in the property hierarchy on the\n'Properties' tab.\n2. Press the 'Add named class' button on the 'Range Widget' (Figure 4.25).\nA\ndialog will appear that allows a class to be selected from the ontology class hierarchy.\n3. Select PizzaTopping and press the 'OK' button. PizzaTopping should now be dis\n\nIt is possible to specify multiple classes as the range for a property. If multiple\nclasses are specified in Prot eg e-OWL the range of the property is interpreted to\nbe the union of the classes. For example, if the range of a property has the classes\nMan and Woman listed in the range widget, the range of the property will be\ninterpreted as Man union Woman. a\naSee section B.2 for an explanation of what a union class is.\n\nlist.\nThis means that individuals that are used 'on the left hand side' of the hasTopping\nproperty will be inferred to be members of the class Pizza. Any individuals that\nare used 'on the right hand side' of the hasTopping property will be inferred to\nbe members of the class PizzaTopping. For example, if we have individuals a and\nb and an assertion of the form a hasTopping b then it will be inferred that a is a\nmember of the class Pizza and that b is a member of the class PizzaToppinga .\naThis will be the case even if a has not been asserted to be a member of the class Pizza and/or\nb has not been asserted to be a member of the class PizzaTopping.\nWhen multiple classes are specified as the domain for a property, Prot eg e-OWL\ninterprets the domain of the property to be the union of the classes .\nAlthough OWL allows arbitrary class expressions to be used for the domain of a\nproperty this is not allowed when editing ontologies in Prot eg e-OWL .\nExercise 13: Specify Pizza as the domain of the hasTopping property\n1. Make sure that the hasTopping property is selected in the property hierarchy on the\n'Properties' tab.\n2. Press the 'Add named class' button on the Domain Widget. A dialog will appear\nthat allows a class to be selected from the ontology class hierarchy.\n3. Select Pizza and press the OK button. Pizza should now be displayed in the domain\nTo specify the domain of a property the domain widget shown in Figure 4.26 is used.\n\nNotice that the domain of the isToppingOf property is the range of the inverse property hasTopping, and\nthat the range of the isToppingOf property is the domain of the hasTopping property. This is depicted\nin 4.24.\nExercise 15: Specify the domain and range for the hasBase property and its inverse property is-\nBaseOf\n1. Select the hasBase property.\n2. Specify the domain of the hasBase property as Pizza.\n3. Specify the range of the hasBase property as PizzaBase.\n4. Select the isBaseOf property.\n5. Make the domain of the isBaseOf property PizzaBase.\n6. Make the range of the isBaseOf property Pizza.\nAdd a (existing) named class to the domain\nRemoves the selected class from the domain\nFigure 4.26: Property Domain Widget\nWe now need to fill in the domain and range for the inverse of the hasTopping property isToppingOf:\nExercise 14: Specify the domain and range for the isToppingOf property\n1. Select the isToppingOf property.\n2. Use the same steps as above to set the domain of the isToppingOf property to Piz\nzaTopping.\n3. Set the range of the isToppingOf property to Pizza.\n\nIn the previous steps we have ensured that the domains and ranges for properties\nare also set up for inverse properties in a correct manner. In general, domain for\na property is the range for its inverse, and the range for a property is the domain\nfor its inverse -- Figure 4.24 illustrates this for the hasTopping and isToppingOf.\nIf these steps are not taken the ontology tests (see section 7.3) can be used to spot\nany discrepancies.\nAlthough we have specified the domains and ranges of various properties for the\npurposes of this tutorial, we generally advise against doing this. The fact that\ndomain and range conditions do not behave as constraints and the fact that they\ncan cause 'unexpected' classification results can lead problems and unexpected\nside effects. These problems and side effects can be particularly difficult to track\ndown in a large ontology.\n4.8\nDescribing And Defining Classes\nHaving created some properties we can now use these properties to describe and define our Pizza Ontology\nclasses.\n4.8.1\nProperty Restrictions\nIn OWL properties are used to create restrictions. As the name may suggest, restrictions are used to\nrestrict the individuals that belong to a class. Restrictions in OWL fall into three main categories:\n- Quantifier Restrictions\n- Cardinality Restrictions\n- hasValue Restrictions.\nWe will initially use quantifier restrictions. These types of restrictions are composed of a quantifier, a\nproperty, and a filler. The two quantifiers that may be used are:\n- The existential quantifier (∃), which can be read as at least one, or some7 .\n- The universal quantifier (∀), which can be read as only8 .\nFor example the restriction ∃ hasTopping MozzarellaTopping is made up of the existential quantifier\n(∃), the property hasTopping, and the filler MozzarellaTopping. This restriction describes the set, or the\n7It can also be read as 'someValuesFrom' in OWL speak.\n8It can also be read as 'allValuesFrom' in OWL speak.\n\nclass, of individuals that have at least one topping that is an individual from the class\n.\nThis restriction is depicted in Figure 4.27 -- The diamonds in the Figure represent individuals. As can\nbe seen from Figure 4.27, the restriction describes an anonymous (unnamed) class of individuals that\nsatisfy the restriction.\nA restriction actually describes an anonymous class (an unnamed class).\nThe\nanonymous class contains all of the individuals that satisfy the restriction (see\nAppendix A for further information about what a restriction actually represents\nand an explanation of existential and universal quantification). When restrictions\nare used to describe classes, they actually specify anonymous superclasses of the\nclass being described. For example, we could say that MargheritaPizza is a sub\nclass of, amongst other things, Pizza and also a subclass of the things that have\nat least one topping that is MozzarellaTopping.\nhas\nTo\npp\ning\nhasT\nop\npin\ng\nhasT\noppi\nng\nhasT\nopp\ning\nMozzarella\nThings that have at least one\nMozzarellaTopping\n(∃ hasTopping Mozzarella)\nFigure 4.27: The Restriction ∃ hasTopping Mozzarella. This restriction describes the class of individuals that\nhave at least one topping that is Mozzarella\nMozzarellaTopping\nThe restrictions for a class are displayed and edited using the 'Conditions Widget' shown in Figure\n4.28. The 'Conditions Widget' is the 'heart of' the 'OWLClasses' tab in protege, and holds virtually\nall of the information used to describe a class. At first glance, the 'Conditions Widget' may seem\ncomplicated, however, it will become apparent that it is an incredibly powerful way of describing and\ndefining classes.\nRestrictions are used in OWL class descriptions to specify anonymous superclasses of the class being\ndescribed.\n4.8.2\nExistential Restrictions\nExistential restrictions (∃) are by far the most common type of restrictions in OWL ontologies. For a set\nof individuals, an existential restriction specifies the existence of a (i.e. at least one) relationship along a\ngiven property to an individual that is a member of a specific class. For example, ∃ hasBase PizzaBase\ndescribes all of the individuals that have at least one relationship along the hasBase property to an\nindividual that is a member of the class PizzaBase -- in more natural English, all of the individuals that\nhave at least one pizza base.\n\nRemove the selected named class\nAdd a named class\nDisplay asserted\nDisplay inferred\nAdd a restriction.\nconditions\nconditions\nAdd a class expression using\nthe inline expression editor\nFigure 4.28: The Conditions Widget\nRemove (delete) the\nselected class expression\n\"NECESSARY & SUFFICIENT Header\"\nA list of necessary & sufficient\nconditions appears under this\n\"NECESSARY & SUFFICIENT\" header.\nThere may be multiple sets of\nnecessary and suficient conditions, in\nwhich case there will be multiple\n\"NECESSARY & SUFFICIENT\" headers.\n\"NECESSARY Header\"\nA list of necessary conditions\nappears under this \"NECESSARY\" header.\nThere is only one list of necessary\nconditions\n\"INHERITED Header\"\nA list of conditions that have\nbeen inherited from superclasses\nwill be displayed here. The class from\nwhich a condition is inherited is\ndisplayed next to the condition.\n\n1. Ensure that the \"NECESSARY\" header is selected\n2. Press the \"Create restriction\" button\nFigure 4.29: Creating a Necessary Restriction\nExistential restrictions are also known as Some Restrictions.\nExercise 16: Add a restriction to Pizza that specifies a Pizza must have a PizzaBase\n1. Select Pizza from the class hierarchy on the 'OWLClasses' tab.\n2. Select the \"NECESSARY\" header in the 'Conditions Widget' shown in Figure 4.29\nin order to create a necessary condition.\n3. Press the 'Create restriction' button shown in Figure 4.29. This will display the\n'Create Restriction' dialog shown in Figure 4.30, which we will use to create a\nrestriction.\nThe create restriction dialog has four main parts: The restriction type list; The property list; the filler\nedit box; and the expression builder panel. To create a restriction we have to do three things:\n- Select the type of restriction from the restriction type list - the default is an existential (∃) restric\ntion.\n- Select the property to be restricted from the property list.\n- Specify a filler for the restriction in the filler edit box (possibly using the expression builder panel).\n\nExercise 17: Add a restriction to Pizza that specifies a Pizza must have a PizzaBase (Continued...)\n1. Select '∃ someValuesFrom' from the restriction type list -- 'someValuesFrom' is\nanother name for an existential restriction.\n2. Select the property hasBase from the property list.\n3. Specify that the filler is PizzaBase -- to do this either: type PizzaBase into the filler\nedit box, or press the 'Insert class' button on the expression builder panel shown in\nFigure 4.31 to display a class hierarchy tree from which PizzaBase may be selected.\n4. Press the 'OK' button to create the restriction and close the create restriction dialog.\nIf all information was entered correctly the dialog will close and the restriction will be\ndisplayed in the 'Conditions Widget'. If there were errors the dialog will not close.\nAn error message will be displayed at the bottom of the expression builder panel -- if\nthis is the case, recheck that the type of restriction, the property and filler have been\nspecified correctly.\nProperty list\nRestriction type list\nFiller edit box\nExpression builder panel\nFigure 4.30: The Create Restriction Dialog\n\nInsert class\nFigure 4.31: Expression Builder Panel Insert Class Button\nFigure 4.32: The Expression Builder Auto-Completion Function\nA very useful feature of the expression builder is the ability to 'auto complete'\nclass names, property names and individual names. Auto completion is activated\nby pressing 'alt tab' on the keyboard. In the above example if we had typed Pi\ninto the inline expresion editor and pressed the tab key, the choices to complete\nthe word Pi would have poped up in a list as shown in Figure 4.32. The up and\ndown arrow keys could then have been used to select PizzaBase and pressing the\nEnter key would complete the word for us.\nThe conditions widget should now look similar to the picture shown in Figure 4.33.\nFigure 4.33: Conditions Widget: Description of a Pizza\n\nontology tidy, we will group our different pizzas under the class 'NamedPizza':\nExercise 18: Create a subclass of Pizza called NamedPizza, and a subclass of NamedPizza called\nMargheritaPizza\n1. Select the class Pizza from the class hierarchy on the 'OWLClasses' tab.\n2. Press the 'Create subclass' button to create a new subclass of Pizza, and name it\nNamedPizza.\n3. Create a new subclass of NamedPizza, and name it MargheritaPizza.\n4. Add a comment to the class MargheritaPizza using the comment box that is lo\ncated under the class name widget: A pizza that only has Mozarella and Tomato\ntoppings - it's always a good idea to document classes, properties etc. during ontology\nediting sessions in order to communicate intentions to other ontology builders.\nThings that have at least\none PizzaBase\nPizza\nPizzaBase\nhasBa\nse\nhasBase\nhasBase\nhasBa\nse\n(∃ hasBase PizzaBase)\nFigure 4.34: A Schematic Description of a Pizza -- In order for something to be a Pizza it is necessary for it\nto have a (at least one) PizzaBase -- A Pizza is a subclass of the things that have at least one\nPizzaBase\nWe have described the class Pizza to be a subclass of owl:Thing and a subclass of\nthe things that have a base which is some kind of PizzaBase.\nNotice that these are necessary conditions -- if something is a Pizza it is necessary\nfor it to be a member of the class owl:Thing (in OWL, everything is a member of\nthe class owl:Thing) and necessary for it to have a kind of PizzaBase.\nMore formally, for something to be a Pizza it is necessary for it to be in a relation\nship with an individual that is a member of the class PizzaBase via the property\nhasBase -- This is depicted in Figure 4.34.\nCreating Some Different Kinds Of Pizzas\nIt's now time to add some different kinds of pizzas to our ontology.\nWe will start off by adding a\n'MargheritaPizza', which is a pizza that has toppings of mozzarella and tomato. In order to keep our\n\n5. Select hasTopping as the property to be restricted.\n6. Enter the class MozzarellaTopping as the filler for the restriction -- remember that\nthis can be achieved by typing the class name MozzarellaTopping into the filler edit\nbox, or by using the 'Insert class' button (Figure 4.31) to display a dialog containing\nthe ontology class hierarchy which may be used to choose a class.\n7. Press the 'OK' button on the create restriction dialog to create the restriction -- if\nthere are any errors, the restriction will not be created, and an error message will be\ndisplayed at the bottom of the expression builder panel.\nHaving created the class MargheritaPizza we now need to specify the toppings that it has. To do this\nwe will add two restrictions to say that a MargheritaPizza has the toppings MozzarellaTopping and\nTomatoTopping.\nExercise 19: Create an existential (∃) restriction on MargheritaPizza that acts along the property\nhasTopping with a filler of MozzarellaTopping to specify that a MargheritaPizza has at\nleast one MozzarellaTopping\n1. Make sure that MargheritaPizza is selected in the class hierarchy.\n2. Select the \"NECESSARY\" header in the 'Conditions Widget', as we want to create\nand add a necessary condition.\n3. Use the 'Create restriction' button on the 'Conditions widget' (Figure 4.28) to\ndisplay the 'Create Restriction' dialog.\n4. On the 'Create restrictions' dialog make the restriction an existentially quantified\nrestriction by selecting the restriction type as '∃someValuesFrom'.\n\nNow specify that MargheritaPizzas also have TomatoTopping.\nExercise 20: Create a existential restriction (∃) on MargheritaPizza that acts along the property\nhasTopping with a filler of TomatoTopping to specify that a MargheritaPizza has at least\none TomatoTopping\n1. Ensure that MargheritaPizza is selected in the class hierarchy.\n2. Select the \"NECESSARY\" header in the 'Conditions Widget', as we want to create\nand add a necessary condition.\n3. Use the 'Create restriction' button on the 'Conditions Widget' (Figure 4.28) to\ndisplay the 'Create Restriction' dialog'.\n4. On the restrictions dialog make the restriction an existentially quantified restriction\nby selecting the restriction type as '∃ someValuesFrom'.\n5. Select hasTopping as the property to be restricted.\n6. Enter the class TomatoTopping as the filler for the restriction.\n7. Click the 'OK' button on the create restriction dialog to create the restriction.\nThe 'Conditions Widget' should now look similar to the picture shown in Figure 4.35.\nWe have added restrictions to MargeritaPizza to say that a MargheritaPizza is\na NamedPizza that has at least one kind of MozzarellaTopping and at least one\nkind of TomatoTopping.\nMore formally (reading the conditions widget line by line), if something is a mem\nber of the class MargheritaPizza it is necessary for it to be a member of the class\nNamedPizza and it is necessary for it to be a member of the anonymous class\nof things that are linked to at least one member of the class MozzarellaTopping\nvia the property hasTopping, and it is necessary for it to be a member of the\nanonymous class of things that are linked to at least one member of the class\nTomatoTopping via the property hasTopping.\nNow create the class to represent an Americana Pizza, which has toppings of pepperoni, mozzarella\nand tomato. Because the class AmericanaPizza is very similar to the class MargheritaPizza (i.e. an\nAmericana pizza is almost the same as a Margherita pizza but with an extra topping of pepperoni) we\nwill make a clone of the MargheritaPizza class and then add an extra restriction to say that it has a\n\n8. Specify the restriction filler as the class PepperoniTopping by either typing\nPepperoniTopping into the filler edit box, or by using the 'Insert class' button\nto display the class dialog, from which PepperoniTopping may be selected.\n9. Press the OK button to create the restriction.\nFigure 4.35: The Conditions Widget Showing A Description Of A MargheritaPizza\ntopping of pepperoni.\nExercise 21: Create AmericanaPizza by cloning and modifying the description of MargheritaPizza\n1. Right click (ctrl click on the Mac) on the class MargheritaPizza in the class hierarchy\non the OWLClasses tab to display the class hierarchy popup menu.\n2. From the popup menu select the menu item 'Create clone'. This will create a copy\nof the class MargheritaPizza named MargheritaPizza 2, that has exactly the same\nconditions (restrictions etc.) as MargheritaPizza.\n3. Rename the MargheritaPizza 2 to AmericanaPizza using the class name widget.\n4. Ensuring that AmericanaPizza is still selected, select the \"NECESSARY\" header in\nthe conditions widget, as we want to add a new restriction to the necessary conditions\nfor AmericanaPizza.\n5. Press the 'Create restriction' button on the conditions widget to display the 'Create\nrestriction dialog'.\n6. Select '∃ someValuesFrom' as the type of restriction to create an existentially quan\ntified restriction.\n7. Select the property hasTopping as the property to be restricted.\n\nof olives and and parmezan cheese -- create this by cloning MargheritaPizza and\nadding two existential restrictions along the property hasTopping, one with a filler of\nOliveTopping, and one with a filler of ParmezanTopping.\nFor AmericanHot pizza the conditions widget should now look like the picture shown in Figure 4.37. For\nSohoPizza the conditions widget should now look like the picture shown in 4.38.\nFigure 4.36: The Conditions Widget displaying the description for AmericanaPizza\nFigure 4.37: The Conditions Widget displaying the description for AmericanHotPizza\nThe 'Conditions Widget' should now look like the picture shown in Figure 4.36.\nExercise 22: Create an AmericanHotPizza and a SohoPizza\n1. An AmericanHotPizza is almost the same as an AmericanaPizza, but has Jalapeno\npeppers on it -- create this by cloning the class AmericanaPizza and adding an existen\ntial restriction along the hasTopping property with a filler of JalapenoPepperTopping.\n2. A SohoPizza is almost the same as a MargheritaPizza but has additional toppings\n\nHaving created these pizzas we now need to make them disjoint from one another:\nExercise 23: Make subclasses of NamedPizza disjoint from each other\n1. Select the class MargheritaPizza in the class hierarchy on the 'OWLClasses' tab.\n2. Press the 'Add all siblings' button on the 'Disjoints widget' to make the pizzas\ndisjoint from each other.\nFigure 4.38: The Conditions Widget displaying the description for SohoPizza\n4.9\nUsing A Reasoner\n4.9.1\nDetermining the OWL Sub-Language\nAs mentioned in section 3.1, OWL comes in three flavours (or sub-languages): OWL-Lite, OWL-DL (DL\nstands for Description Logics) and OWL-Full. The exact definitions of these sub-languages can be found\nin the OWL Overview, which is available on the World Wide Web Consortium website9 . Prot eg e-OWL\nfeatures a species validation facility, which is able to determine the sub-language of the ontology being\nedited. To use the species validation facility, use the 'Determine/Convert OWL Sub-language...'\noption on the 'OWL menu' shown in Figure 4.39. This will report the sub-language of the ontology.\nOne of the key features of ontologies that are described using OWL-DL is that they can be processed\nby a reasoner. One of the main services offered by a reasoner is to test whether or not one class is a\nsubclass of another class10 . By performing such tests on all of the classes in an ontology it is possible for\na reasoner to compute the inferred ontology class hierarchy. Another standard service that is offered by\nreasoners is consistency checking. Based on the description (conditions) of a class the reasoner can check\nwhether or not it is possible for the class to have any instances. A class is deemed to be inconsistent if\nit cannot possibly have any instances.\n9http://www.w3.org/TR/owl-features/\n10Known as subsumption testing -- the descriptions of the classes (conditions) are used to determine if a super\nclass/subclass relationship exists between them.\n\nReasoners are also known as classifiers.\nFigure 4.39: The OWL Menu\n4.9.2\nUsing RACER\nIn order to reason over the ontologies in Prot eg e-OWL a DIG11 compliant reasoner must be installed/configured\nand started. In this tutorial we use a reasoner called RACER, which is available for a variety of platforms\nfrom http://www.sts.tu-harburg.de/~r.f.moeller/racer/. RACER comes with a detailed manual\nthat contains installation and setup instructions. When you have installed RACER on your system, it\nshould be started with the default settings -- RACER is typically started by double clicking on the\nRACER application icon, which opens a terminal/console window and starts the reasoner running with\nHTTP communication enabled.12 -- Figure 4.40 shows a pruned version of the information that is dis\nplayed when RACER starts; The second from the bottom line indicates that HTTP communication is\nrunning, and specifies the I.P. address and port number. If for any reason RACER needs to be started on\na different port (or computer), Prot eg e-OWL can be configured via the OWL preferences dialog shown\nin Figure 4.41, which is accessible via the 'Preferences...' item on the OWL menu.\n4.9.3\nInvoking The Reasoner\nHaving started RACER, or another reasoner, the ontology can be 'sent to the reasoner' to automatically\ncompute the classification hierarchy, and also to check the logical consistency of the ontology. In Prot eg e-\nOWL the 'manually constructed' class hierarchy is called the asserted hierarchy. The class hierarchy\n11DIG = Description Logic Implementers Group -- A DIG compliant reasoner provides the means to communicate via\nthe DIG interface, which is a standard interface/protocol for talking to description logic reasoners.\n12By default racer runs with the HTTP service enabled on port 8080.\n\n;;; RACER Version 1.7.12\n;;; RACER: Reasoner for Aboxes and Concept Expressions Renamed\n;;; Supported description logic: ALCQHIr+(D)\n;;; Copyright (C) 1998-2003, Volker Haarslev and Ralf Moeller.\n;;; RACER comes with ABSOLUTELY NO WARRANTY; use at your own risk.\n;;; Commercial use is prohibited; contact the authors for licensing.\n;;; RACER is running on Mac OS Darwin computer as node Unknown\n[2004-04-16 10:22:47] HTTP service enabled for: http://130.88.195.45:8080/\n[2004-04-16 10:22:47] TCP service enabled on port 8088\nFigure 4.40: RACER Startup Screen\nFigure 4.41: The OWL Preferences Dialog\n\nwill be circled in red.\nThe task of computing the inferred class hierarchy is also know as classifying the\nontology.\nShow TODO list\nCheck consistency\nClassify taxonomy\nRun ontology tests\nView RDF/XML source\nShow Protege-OWL Syntax\nDisplay English Prose Tooltips\nFigure 4.42: The OWL Toolbar\nFigure 4.43: The Inferred Hierarchy Pane, which pops open next to the Asserted Hierarchy Pane when classifi\ncation has taken place\nthat is automatically computed by the reasoner is called the inferred hierarchy. To automatically classify\nthe ontology (and check for inconsistencies) the 'Classify Taxonomy...' action should be used. This\ncan be invoked via the OWL menu (Figure 4.39), or by using the 'Classify taxonomy' button on\nthe Prot eg e-OWL toolbar shown in Figure 4.42. To check the consistency of the ontology, the 'Check\nconsistency...' action should be used, which can be invoked from the OWL menu, or by using the 'Check\nconsistency' button on the Prot eg e-OWL toolbar. When the inferred hierarchy has been computer, an\ninferred hierarchy window will pop open next to the existing asserted hierarchy window as shown in\nFigure 4.43. If a class has been reclassified (i.e. if it's superclasses have changed) then the class name\nwill appear in a blue colour in the inferred hierarchy. If a class has been found to be inconsistent it's icon\n\nthe class\nand then press the OK button. The class\nping will be added as a necessary condition (as a superclass), so that the conditions\nwidget should look like the picture in Figure 4.44.\nFigure 4.44: The Conditions Widget Displaying ProbeInconsistentTopping\n4.9.4\nInconsistent Classes\nIn order to demonstrate the use of the reasoner in detecting inconsistencies in the ontology we will create\na class that is a subclass of both CheeseTopping and also MeatTopping. This strategy is often used as\na check so that we can see that we have built our ontology correctly. Classes that are added in order to\ntest the integrity of the ontology are sometimes known as Probe Classes.\nExercise 24: Add a Probe Class called ProbeInconsistentTopping which is a subclass of both\nCheeseTopping and Vegetable\n1. Select the class CheeseTopping from the class hierarchy on the OWLClasses tab.\n2. Create a subclass of CheeseTopping named ProbeInconsistentTopping.\n3. Add a comment to the ProbeInconsistentTopping class that is something along the\nlines of, \"This class should be inconsistent when the ontology is classified.\". This will\nenable anyone who looks at our pizza ontology to see that we deliberately meant the\nclass to be inconsistent.\n4. Ensure that the ProbeInconsistentTopping class is selected in the class hierarchy, and\nthen select the \"NECESSARY\" header in the 'Conditions widget'.\n5. Click on the 'Add named class' button on the 'Conditions Widget'. This will dis\nplay a dialog containing the class hierarchy from which a class may be selected. Select\nVegetableTopping\nVegetableTop\n\nExercise 25: Classify the ontology to make sure ProbeInconsistentTopping is inconsistent\n1. Press the 'Classify Taxonomy' button on the OWL toolbar to classify the ontology.\nAfter a few seconds the inferred hierarchy will have been computed and the inferred hierarchy window\nwill pop open (if it was previously closed). The hierarchy should resemble that shown in Figure 4.45 --\nnotice that the class ProbeInconsistentTopping is circled in red, indicating that the reasoner has found\nthis class to be inconsistent (i.e. it cannot possibly have any individuals as memebers).\nFigure 4.45: The Class ProbeInconsistentTopping found to be inconsistent by the reasoner\nIf we study the class hierarchy, ProbeInconsistentTopping should appear as a\nsubclass of CheeseTopping and as a subclass of VegetableTopping. This means\nthat ProbeInconsistentTopping is a CheeseTopping and a VegetableTopping.\nMore formally, all individuals that are members of the class ProbeInconsistentTop\nping are also (necessarily) members of the class CheeseTopping and (necessarily)\nmembers of the class VegetableTopping. Intuitively this is incorrect since some\nthing can not simultaneously be both cheese and a vegetable!\n\nTo close the inferred hierarchy use the small white cross on a red background\nbutton on the top right of the inferred hierarchy window.\nWhy did this happen? Intuitively we know something cannot at the same time\nbe both cheese and a vegetable. Something should not be both an instance of\nCheeseTopping and an instance of VegetableTopping. However, it must be re\nmembered that we have chosen the names for our classes. As far as the reasoner is\nconcerned names have no meaning. The reasoner cannot determine that something\nis inconsistent based on names. The actual reason that ProbeInconsistentTopping\nhas been detected to be inconsistent is because its superclasses VegetableTopping\nand CheeseTopping are disjoint from each other -- remember that earlier on we\nspecified that the four categories of topping were disjoint from each other using\nthe Wizard. Therefore, individuals that are members of the class CheeseTopping\ncannot be members of the class VegetableTopping and vice-versa.\nExercise 26: Remove the disjoint statement between CheeseTopping and VegetableTopping to see\nwhat happens\n1. Select the class CheeseTopping using the class hierarchy.\n2. The 'Disjoints widget' should contain CheeseTopping's sibling classes: Vegetable-\nTopping, SeafoodTopping and MeatTopping. Select VegetableTopping in the Disjoints\nwidget.\n3. Press the 'Remove selected class from list' button on the Disjoints widget (shown\nin Figure 4.5) to remove the disjoint axiom that states CheeseTopping and MeatTop\nping are disjoint.\n4. Press the 'Classify Taxonomy' button on the OWL toolbar to send the ontology to\nthe reasoner. After a few seconds the ontology should have been classified and the\nresults displayed.\n\nIt should be noticeable that ProbeInconsistentTopping is no longer inconsistent!\nThis means that individuals which are members of the class ProbeInconsistent-\nTopping are also members of the class CheeseTopping and VegetableTopping --\nsomething can be both cheese and a vegetable!\nThis clearly illustrates the importance of the careful use of disjoint axioms in\nOWL. OWL classes 'overlap' until they have been stated to be disjoint from each\nother. If certain classes are not disjoint from each other then unexpected results\ncan arise. Accordingly, if certain classes have been incorrectly made disjoint from\neach other then this can also give rise to unexpected results.\n\nshould be highlighted in red indicating that it is once again inconsistent.\n4.10\nNecessary And Sufficient Conditions (Primitive and De\nfined Classes)\nAll of the classes that we have created so far have only used necessary conditions to describe them.\nNecessary conditions can be read as, \"If something is a member of this class then it is necessary to\nfulfil these conditions\". With necessary conditions alone, we cannot say that, \"If something fulfils these\nconditions then it must be a member of this class\".\nA class that only has necessary conditions is known as a Primitive Class.\nLet's illustrate this with an example. We will create a subclass of Pizza called CheesyPizza, which will\nExercise 27: Fix the ontology by making CheeseTopping and Vegetable disjoint from each other\n1. Select the class CheeseTopping using the class hierarchy.\n2. The 'Disjoints widget' should contain MeatTopping and SeafoodTopping.\n3. Press the 'Add disjoint class' button on the disjoint classes widget to display a dialog\nwhich classes may be picked from. Select the class VegetableTopping and press the\nOK button. CheeseTopping should once again be disjoint from VegetableTopping.\n4. Test that the disjoint axiom has been added correctly -- Press the 'Classify Tax\nonomy' button on the OWL toolbar to send the ontology to the reasoner. After a\nfew seconds the ontology should have been classified, and ProbeInconsistentTopping\n\n6. Select hasTopping as the property to be restricted.\n7. In the filler edit box type CheeseTopping (or use the 'Insert class' button to display\na dialog from which CheeseTopping can be selected). Press 'OK' to close the dialog\nand create the restriction.\nThe 'Conditions Widget' should now look like the picture shown in Figure 4.46.\nOur description of CheesyPizza states that if something is a member of the class\nCheesyPizza it is necessary for it to be a member of the class Pizza and it is\nnecessary for it to have at least one topping that is a member of the class Cheese-\nTopping.\nOur current description of CheesyPizza says that if something is a CheesyPizza it is necessarily a Pizza\nand it is necessary for it to have at least one topping that is a kind of CheeseTopping. We have used\nnecessary conditions to say this. Now consider some (random) individual. Suppose that we know that\nFigure 4.46: The Description of CheesyPizza (Using Necessary Conditions)\nbe a Pizza that has at least one kind of CheeseTopping.\nExercise 28: Create a subclass of Pizza called CheesyPizza and specify that it has at least one\ntopping that is a kind of CheeseTopping\n1. Select Pizza in the class hierarchy on the 'OWLClasses' tab.\n2. Press the 'Create subclass' button to create a subclass of Pizza.\nRename it to\nCheesyPizza.\n3. Make sure that CheesyPizza is selected in the class hierarchy. Select the \"NECES\nSARY\" header in the conditions widget. (You may have to select the 'Asserted' tab\non the 'Conditions Widget' -- the automatically shows the 'Inferred' tab after\nclassification).\n4. Press the 'Create restriction' button on the conditions widget to display the 'Create\nrestriction dialog'.\n5. Select '∃someValuesFrom' as the type of restriction to be created.\n\nthis individual is a member of the class Pizza. We also know that this individual has at least one kind of\nCheeseTopping. However, given our current description of CheesyPizza this knowledge is not sufficient\nto determine that the individual is a member of the class CheesyPizza. To make this possible we need to\nchange the conditions for CheesyPizza from necessary conditions to necessary AND sufficient conditions.\nThis means that not only are the conditions necessary for membership of the class CheesyPizza, they\nare also sufficient to determine that any (random) individual that satisfies them must be a member of\nthe class CheesyPizza.\nA class that has at least one set of necessary and sufficient conditions is known as\na Defined Class.\nClasses that only have necessary conditions are also known as 'partial' classes.\nClasses that have at least one set of necessary and sufficient conditions are also\nknown as 'complete' classes.\nmoved from under the\"NECESSARY\" header in the conditions widget to be under the\"NECESSARY\nAND SUFFICIENT\" header. This can be accomplished by dragging and dropping the conditions one-\nby-one.\nExercise 29: Convert the necessary conditions for CheesyPizza into necessary & sufficient condi\ntions\n1. Ensure that CheesyPizza is selected in the class hierarchy.\n2. On the 'Conditions Widget' select the ∃ hasTopping CheeseTopping restriction.\n3. Drag the ∃ hasTopping CheeseTopping restriction from under the \"NECESSARY\"\nheader to on top of the \"NECESSARY & SUFFICIENT\" header.\n4. Select the class Pizza.\n5. Drag the class Pizza from under the \"NECESSARY\" header to on top of the ∃hasTop\nping CheeseTopping restriction (note not on top of the \"NECESSARY & SUFFI\nCIENT\" header this time).\nThe 'Conditions Widget' should now look like the picture shown in Figure 4.47.\nIn order to convert necessary conditions to necessary and sufficient conditions, the conditions must be\n\nWe have converted our description of CheesyPizza into a definition. If something\nis a CheesyPizza then it is necessary that it is a Pizza and it is also necessary\nthat at least one topping that is a member of the class CheeseTopping. Moreover,\nif an individual is a member of the class Pizza and it has at least one topping that\nis a member of the class CheeseTopping then these conditions are sufficient to\ndetermine that the individual must be a member of the class CheesyPizza. The\nnotion of necessary and sufficient conditions is illustrated in Figure 4.48.\nIf you accidentally dropped Pizza onto the \"NECESSARY & SUFFICIENT\"\nheader (rather that onto the ∃ hasTopping CheeseTopping) in Exercise 29 the\nconditions widget will look like the picture shown in Figure 4.49. In this case, a new\nnecessary and sufficient condition has been created, which is not what we want.\nTo correct this mistake, drag Pizza on top of the ∃ hasTopping CheeseTopping\nrestriction.\nFigure 4.47: The Description of CheesyPizza (Using Necessary AND Sufficient Conditions)\nNECESSARY CONDITIONS\nNamedClass\nCondition\nCondition\nCondition\nCondition\nimplies\nIf an individual is a member of 'NamedClass' then it must satisfy the conditions.\nHowever if some individual satisfies these necessary conditions, we cannot say\nthat it is a member of 'Named Class' (the conditions are not 'sufficient' to be able\nto say this) - this is indicated by the direction of the arrow.\nNECESSARY & SUFFICIENT CONDITIONS\nNamedClass\nCondition\nCondition\nCondition\nCondition\nimplies\nIf an individual is a memeber of 'NamedClass' then it must satisfy the conditions.\nIf some individual satisfies the condtions then the individual must be a member\nof 'NamedClass' - this is indicated by the double arrow.\nFigure 4.48: Necessary And Sufficient Conditions\n\nSUFFICIENT\" and vice versa using Cut and Paste. Right click (ctrl click on a\nMac) on a condition and select Cut or Paste from the popup menu.\no summarise: If class A is described using necessary conditions, then we can say that if an individual\ns a member of class A it must satisfy the conditions. We cannot say that any (random) individual that\natisfies these conditions must be a member of class A. However, if class A is now defined using necessary\nnd sufficient conditions, we can say that if an individual is a member of the class A it must satisfy the\nonditions and we can now say that if any (random) individual satisfies these conditions then it must be\nmember of class A. The conditions are not only necessary for membership of A but also sufficient to\netermine that something satisfying these conditions is a member of A.\now is this useful in practice? Suppose we have another class B, and we know that any individuals that\nre members of class B also satisfy the conditions that define class A. We can determine that class B is\nubsumed by class A -- in other words, B is a subclass of A. Checking for class subsumption is a key\nask of a description logic reasoner and we will use the reasoner to automatically compute a classification\nierarchy in this way.\nIn OWL it is possible to have multiple sets of necessary & sufficient conditions.\nThis is discussed later in section 6.5\nFigure 4.49: An INCORRECT description of CheesyPizza\nConditions may also be transferred from \"NECESSARY\" to \"NECESSARY &\nT\ni\ns\na\nc\na\nd\nH\na\ns\nt\nh\n4.10.1\nPrimitive And Defined Classes\nClasses that have at least one set of necessary and sufficient conditions are known as defined classes --\nthey have a definition, and any individual that satisfies the definition will belong to the class. Classes\nthat do not have any sets of necessary and sufficient conditions (only have necessary conditions) are\nknow as primitive classes. In Prot eg e-OWL defined classes have a class icon with an orange background.\nPrimitive classes have a class icon that has a yellow background. It is also important to understand that\nthe reasoner can only automatically classify classes under defined classes - i.e. classes with at least one\nset of necessary and sufficient conditions.\n\nHaving created a definition of a CheesyPizza we can use the reasoner to automatically compute the\nsubclasses of CheesyPizza.\nExercise 30: Use the reasoner to automatically compute the subclasses of CheesyPizza\n1. Ensure that a reasoner (RACER) is running.\n2. Press the 'Classify Taxonomy...' button on the toolbar (See Figure 4.42).\nAfter a few seconds the inferred hierarchy should have been computed and the inferred hierarchy window\nwill pop open (if it was previously closed). The inferred hierarchy should appear similar to the picture\nshown in Figure 4.50.\nFigures 4.51 and 4.52 show the OWLViz display of the asserted and inferred\nhierarchies respectively. Notice that classes which have had their superclasses changed by the reasoner\nare shown in blue.\n13Sometimes know as ontology normalisation.\nFigure 4.50: The Asserted and Inferred Hierarchies Displaying The Classification Results For CheesyPizza\n4.11\nAutomatic Classification\nBeing able to use a reasoner to automatically compute the class hierarchy is one of the major benefits of\nbuilding an ontology using the OWL-DL sub-language. Indeed, when constructing very large ontologies\n(with upwards of several thousand classes in them) the use of a reasoner to compute subclass-superclass\nrelationships between classes becomes almost vital. Without a reasoner it is very difficult to keep large\nontologies in a maintainable and logically correct state. In cases where ontologies can have classes that\nhave many superclasses (multiple inheritance) it is nearly always a good idea to construct the class\nhierarchy as a simple tree. Classes in the asserted hierarchy (manually constructed hierarchy) therefore\nhave no more than one superclass. Computing and maintaining multiple inheritance is the job of the\nreasoner. This technique13 helps to keep the ontology in a maintainable and modular state. Not only\ndoes this promote the reuse of the ontology by other ontologies and applications, it also minimises human\nerrors that are inherent in maintaining a multiple inheritance hierarchy.\n\nNamePizza\nPizza\nCheesyPizza\nMargheritaPizza\nAmericanHotPizza\nAmericanaPizza\nSohoPizza\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nFigure 4.51: OWLViz Displaying the Asserted Hierarchy for CheesyPizza\nCheesyPizza\nMargheritaPizza\nSohoPizza\nNamePizza\nPizza\nAmericanHotPizza\nAmericanaPizza\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nFigure 4.52: OWLViz Displaying the Inferred Hierarchy for CheesyPizza\n\nThe reasoner has determined that MargheritaPizza, AmericanaPizza, American-\nHotPizza and SohoPizza are subclasses of CheesyPizza.\nThis is because we\ndefined CheesyPizza using necessary and sufficient conditions. Any individual\nthat is a Pizza and has at least one topping that is a CheeseTopping is a member\nof the class CheesyPizza. Due to the fact that all of the individuals that are\n\nCheeseTopping.\naOr toppings that belong to the subclasses of CheeseTopping\n\nIt is important to realise that, in general, classes will never be placed as sub\nclasses of primitive classes (i.e. classes that only have necessary conditions) by the\nreasonera .\naThe exception to this is when a property has a domain that is a primitive class. This can\ncoerce classes to be reclassified under the primitive class that is the domain of the property --\nthe use of property domains to cause such effects is strongly discouraged.\n\ntakes the superclass-subclass relationships that have been found by the reasoner and puts them into\nthe asserted (manually constructed) hierarchy. For example, if the 'Assert Selected Changes' button\nwas pressed with the selection shown in Figure 4.53, CheesyPizza would be added as a superclass of\nAmericanaPizza.\n\nDespite that fact that this facility exists, it is generally considered a bad idea to\nput computed/inferred relationships into the 'manually constructed' or asserted\nmodel whilst an ontology is being developed -- we therefore advise against using\nthis button during the development of an ontology.\ndescribed by the classes MargheritaPizza, AmericanaPizza, AmericanHotPizza\nand SohoPizza are Pizzas and they have at least one topping that is a Cheese-\nToppinga the reasoner has determined that these classes must be subclasses of\n4.11.1\nClassification Results\nAfter the reasoner has been invoked, computed superclass-subclass relationships and inconsistent classes\nare displayed in the 'Classification Results' pane shown in Figure 4.53. The 'Classification Results'\npane pops open after classification at the bottom of the Prot eg e-OWL application window. The 'spanner\nicon' on the left hand side of the pane is the 'Assert Selected Change(s)' button. Pressing this button\n4.12\nUniversal Restrictions\nAll of the restrictions we have created so far have been existential restrictions (∃). Existential restrictions\nspecify the existence of at least one relationship along a given property to an individual that is a member\nof a specific class (specified by the filler).\nHowever, existential restrictions do not mandate that the\nonly relationships for the given property that can exist must be to individuals that are members of the\nspecified filler class.\n\naren't members of the class MozzarellaTopping.\nUniversal restrictions are also know as All Restrictions.\nThe above universal restriction ∀ hasTopping MozzarellaTopping also describes\nthe individuals that do not participate in any hasTopping relationships. An indi\nvidual that does not participate in any hasTopping relationships what so ever, by\ndefinition does not have any hasTopping relationships to individuals that aren't\nmembers of the class MozzarellaTopping and the restriction is therefore satisfied.\nFor a given property, universal restrictions do not specify the existence of a rela\ntionship. They merely state that if a relationship exists for the property then it\nmust be to individuals that are members of a specific class.\nppose we want to create a class called VegetarianPizza. Individuals that are members of this class\nn only have toppings that are CheeseTopping or VegetableTopping. To do this we can use a universal\nAssert selected change(s)\nFigure 4.53: The Classification Results Pane\nFor example, we could use an existential restriction ∃ hasTopping MozzarellaTopping to describe the\nindividuals that have at least one relationship along the property hasTopping to an individual that is\na member of the class MozzarellaTopping. This restriction does not imply that all of the hasTopping\nrelationships must be to a member of the class MozzarellaTopping. To restrict the relationships for a\ngiven property to individuals that are members of a specific class we must use a universal restriction.\nUniversal restrictions are given the symbol ∀. They constrain the relationships along a given property\nto individuals that are members of a specific class. For example the universal restriction ∀ hasTopping\nMozzarellaTopping describes the individuals all of whose hasTopping relationships are to members of the\nclass MozzarellaTopping -- the individuals do not have a hasTopping relationships to individuals that\nSu\nca\n\n7. Press the 'OK' button on the dialog to close the dialog and create the restriction --\nif there are any errors (due to typing errors etc.) the dialog will not close and an error\nmessage will be displayed at the bottom of the expression builder panel.\naSee section B.2 for more information about union classes.\nAt this point the conditions widget should look like the picture shown in Figure 4.55.\nrestriction.\nExercise 31: Create a class to describe a VegetarianPizza\n1. Create a subclass of Pizza, and name it VegetarianPizza.\n2. Making sure that VegetarianPizza is selected, click on the \"NECESSRY\" header in\nthe 'Conditions Widget'.\n3. Press the 'Create restriction' button on the 'Conditions Widget' to display the\n'Create restriction dialog'.\n4. Select the type of restriction as '∀ allValuesFrom' in order to create a universally\nquantified restriction.\n5. Select hasTopping as the property to be restricted.\n6. For the filler we want to say CheeseTopping or VegetableTopping. First insert the\nclass CheeseTopping either by typing CheeseTopping into the filler box, or by using\nthe 'Insert class' button. We now need to use the unionOf operator between the\nclass names. The unionOf operator may be inserted using the button shown in Figure\n4.54a . Insert the unionOf symbol by pressing the 'Insert unionOf' button on the\nexpression builder panel.\nNext insert the class VegetableTopping either by typing\nit or by using the 'Insert class button'. You should now have CheeseTopping ⊔\nVegetableTopping in the filler edit box.\n\nThis means that if something is a member of the class VegetarianPizza it is nec\nessary for it to be a kind of Pizza and it is necessary for it to only (∀ universal\nquantifier) have toppings that are kinds of CheeseTopping or kinds of Vegetable-\nTopping.\nIn other words, all hasTopping relationships that individuals which are members\nof the class VegetarianPizza participate in must be to individuals that are either\nmembers of the class CheeseTopping or VegetableTopping.\nThe class VegetarianPizza also contains individuals that are Pizzas and do not\nparticipate in any hasTopping relationships.\nInstead of using the 'Insert unionOf' button in\nExercise 31 , we could have\nsimply typed or into the filler edit box and it would have automatically been\nconverted to the union of symbol (⊔).\nInsert union of\nInsert class\nFigure 4.54: Using the Expression Builder Panel to insert Union Of\nFigure 4.55: The Description of VegetarianPizza (Using Necessary Conditions)\n\nIn situations like the above example, a common mistake is to use an intersec\ntion instead of a union. For example, CheeseTopping u VegetableTopping. This\nreads, CheeseTopping and VegetableTopping.\nAlthough \"CheeseTopping and\nVegetable\" might be a natural thing to say in English, this logically means some\nthing that is simultaneously a kind of CheeseTopping and VegetableTopping. This\nis obviously incorrect as demonstrated in section 4.9.4. If the classes CheeseTop\nping and VegetableTopping were not disjoint, this would have been a logically\nlegitimate thing to say - it would not be inconsistent and therefore would not be\n'spotted' by the reasoner.\n\nIn the above example it might have been tempting to create two universal re\nstrictions -- one for CheeseTopping (∀ hasTopping CheeseTopping) and one for\nVegetableTopping (∀ hasTopping VegetableTopping).\nHowever, when multiple\nrestrictions are used (for any type of restriction) the total description is taken\n\nbeen equivalent to one restriction with a filler that is the intersection of Moz\nzarellaTopping and TomatoTopping -- as explained above this would have been\nlogically incorrect.\nCurrently VegetarianPizza is described using necessary conditions. However, our description of a Veg\netarianPizza could be considered to be complete.\nWe know that any individual that satisfies these\nconditions must be a VegetarianPizza. We can therefore convert the necessary conditions for Vegetari\nanPizza into necessary and sufficient conditions. This will also enable us to use the reasoner to determine\nthe subclasses of VegetarianPizza.\nExercise 32: Convert the necessary conditions for VegetarianPizza into necessary & sufficient\nconditions\n1. Ensure that VegetarianPizza is selected in the class hierarchy.\n2. On the 'Conditions Widget' select the (∀ universal) restriction on the hasTopping\nproperty.\n3. Drag the hasTopping restriction from under the \"NECESSARY\" header to on top of\nthe \"NECESSARY & SUFFICIENT\" header.\n5. Drag the class Pizza from under the \"NECESSARY\" header to on top of the hasTop\nping restriction (note not on top of the \"NECESSARY & SUFFICIENT\" header this\ntime).\nThe 'Conditions Widget' should now look like the picture shown in Figure 4.56.\nto be the intersection of the individual restrictions. This would have therefore\n4. Select the class Pizza.\n\nWe have converted our description of VegetarianPizza into a definition. If some\nthing is a VegetarianPizza, then it is necessary that it is a Pizza and it is also\nnecessary that all toppings belong to the class CheeseTopping or VegetableTop\nping. Moreover, if something is a member of the class Pizza and all of it's toppings\nare members of the class CheeseTopping or the class VegetableTopping then these\nconditions are sufficient to recognise that it must be a member of the class Veg\netarianPizza. The notion of necessary and sufficient conditions is illustrated in\nFigure 4.48.\n\na set of necessary and sufficient conditions) we can use the reasoner to perform automatic classification\nand determine the vegetarian pizzas in our ontology.\nExercise 33: Use the reasoner to classify the ontology\n1. Ensure that a resoner (RACER) is running. Press the 'Classify taxonomy' button.\nYou will notice that MargheritaPizza and also SohoPizza have not been classified as subclasses of Veg\netarianPizza. This may seem a little strange, as it appears that both MargheritaPizza and SohoPizza\nhave ingredients that are vegetarian ingredients, i.e. ingredients that are kinds of CheeseTopping or\nkinds of VegetableTopping. However, as we will see, MargheritaPizza and SohoPizza have something\nmissing from their definition that means they cannot be classified as subclasses of VegetarianPizza.\nReasoning in OWL (Description Logics) is based on what is known as the open world assumption (OWA).\nIt is frequently referred to as open world reasoning (OWR). The open world assumption means that we\nFigure 4.56: The Conditions Widget Displaying the Definition of VegetarianPizza (Using Necessary and Suffi\ncient Conditions)\n4.13\nAutomatic Classification and Open World Reasoning\nWe want to use the reasoner to automatically compute the superclass-subclass relationship (subsumption\nrelationship) between MargheritaPizza and VegetarianPizza and also, SohoPizza and VegetarianPizza.\nRecall that we believe that MargheritaPizza and SohoPizza should be vegetarian pizzas (they should\nbe subclasses of VegetarianPizza). This is because they have toppings that are essentially vegetarian\ntoppings -- by our definition, vegetarian toppings are members of the classes CheeseTopping or Veg\netableTopping and their subclasses. Having previously created a definition for VegetarianPizza (using\n\ncannot assume something doesn't exist until it is explicitly stated that it does not exist. In other words,\nbecause something hasn't been stated to be true, it cannot be assumed to be false -- it is assumed that\n'the knowledge just hasn't been added to the knowledge base'. In the case of our pizza ontology, we\nhave stated that MargheritaPizza has toppings that are kinds of MozzarellaTopping and also kinds of\nTomatoTopping. Because of the open world assumption, until we explicitly say that a MargheritaPizza\nonly has these kinds of toppings, it is assumed (by the reasoner) that a MargheritaPizza could have other\ntoppings. To specify explicitly that a MargheritaPizza has toppings that are kinds of MozzarellaTopping\nor kinds of MargheritaTopping and only kinds of MozzarellaTopping or MargheritaTopping, we must add\nwhat is known as a closure axiom14 on the hasTopping property.\n4.13.1\nClosure Axioms\nA closure axiom on a property consists of a universal restriction that acts along the property to say that\nit can only be filled by the specified fillers. The restriction has a filler that is the union of the fillers that\noccur in the existential restrictions for the property15 . For example, the closure axiom on the hasTopping\nproperty for MargheritaPizza is a universal restriction that acts along the hasTopping property, with a\nfiller that is the union of MozzarellaTopping and also TomatoTopping. i.e. ∀ hasTopping (Mozzarel\nlaTopping ⊔ TomatoTopping).\nExercise 34: Add a closure axiom on the hasTopping property for MargheritaPizza\n1. Make\nsure\nthat\nMargheritaPizza is\nselected\nin\nthe\nclass\nhierarchy\non\nthe\n'OWLClasses' tab.\n2. Select the\"NECESSARY\" header in the 'Conditions Widget'.\n3. Press the 'Create restriction' button on the conditions widget to display the 'Create\nRestriction dialog'.\n4. Select the restriction type as '∀ allValuesFrom' (universal restriction).\n5. Select hasTopping as the property to be restricted.\n6. In the filler edit box enter MozzarellaTopping ⊔ TomatoTopping. This can be done\nby typing MozzarellaTopping or TomatoTopping into the filler edit box (\"or\" will\nbe automatically converted to ⊔ as the filler is typed). This can also be accomplished\nby using the 'Insert class' button and the 'Insert unionOf' button to insert the\nclass MozzarellaTopping, then insert the unionOf symbol and then insert the class\nTomatoTopping.\n7. Press the OK button to create the restriction and add it to the class MargheritaPizza.\nThe conditions widget should now appear as shown in Figure 4.57.\n14Also referred to as a closure restriction.\n15And technically speaking the classes for the values used in any hasValue restrictions (see later).\n\nFigure 4.57: Conditions Widget: Margherita Pizza With a Closure Axiom for the hasTopping property\nThis now says that if an individual is a member of the class MargeritaPizza then\nit must be a member of the class Pizza, and it must have at least one topping\nthat is a kind of MozzarellaTopping and it must have at least one topping that\nis a member of the class TomatoTopping and the toppings must only be kinds of\nMozzarellaTopping or TomatoTopping.\nA common error in situations such as above is to only use universal restrictions in\ndescriptions. For example, describing a MargheritaPizza by making it a subclass of\nPizza and then only using ∀ hasTopping (MozzarellaTopping ⊔ TomatoTopping)\nwithout any existential restrictions.\nHowever, because of the semantics of the\nuniversal restriction, this actually means either: things that are Pizzas and only\nhave toppings that are MozzarellaTopping or TomatoTopping, OR, things that are\nPizzas and do not have any toppings at all.\nExercise 35: Add a closure axiom on the hasTopping property for SohoPizza\n1. Select SohoPizza in the class hierarchy on the 'OWLClasses' tab.\n2. Select the \"NECESSARY\" header in the 'Conditions Widget'.\n3. Press the 'Create restriction' button to display the 'Create Restriction dialog'.\n4. Select the restriction type as, '∀ allValuesFrom', as we want to create a universally\nquantified restriction.\n5. Select hasTopping as the property to be restricted.\n6. In the filler edit box enter the union of the toppings for SohoPizza by typing\nParmezanTopping or MozzarellaTopping or TomatoTopping or OliveTopping.\nNote that the \"or\" keywords will automatically be converted to the unionOf symbol\n(⊔) as you type to give \"ParmezanTopping ⊔ MozzarellaTopping ⊔ TomatoTopping\n⊔ OliveTopping\".\n7. Press the OK button to create the restriction and close the dialog. If the dialog will\nnot close due to errors, check that the class names have been spelt correctly.\n\nExercise 36: Automatically create a closure axiom on the hasTopping property for AmericanaPizza\n1. Select AmericanaPizza in the class hierarchy on the OWLClasses tab.\n2. In the 'Conditions Widget' right click (Ctrl click on the Mac) on one of the exis\ntential hasTopping restrictions. Select 'Add closure axiom' from the pop up menu\nthat appears. A closure restriction (universal restriction) will be created along the\nhasTopping property, which contains the union of the existential hasTopping fillers.\nExercise 37: Automatically create a closure axiom on the hasTopping property for AmericanHot-\nPizza\n1. Select AmericanHotPizza in the class hierarchy on the OWLClasses tab.\n2. In the 'Conditions Widget' right click (Ctrl click on the Mac) on one of the exis\ntential hasTopping restrictions. Select 'Add closure axiom' from the pop up menu\nthat appears.\nHaving added closure axioms on the hasTopping property for our pizzas, we can now used the reasoner\nto automatically compute classifications for them.\nExercise 38: Use the reasoner to classify the ontology\n1. Press the 'Classify taxonomy' button on the OWL toolbar to invoke the reasoner.\nFor completeness, we will add closure axioms for the hasTopping property to AmericanaPizza and also\nAmericanHotPizza. At this point it may seem like tedious work to enter these closure axioms by hand.\nFortunately Prot eg e-OWL has the capability of creating closure axioms for us.\nAfter a short amount of time the ontology will have been classified and the 'Inferred Hierarchy' pane\nwill pop open (if it is not already open). This time, MargheritaPizza and also SohoPizza will have\nbeen classified as subclasses of VegetarianPizza. This has happened because we specifically 'closed' the\nhasTopping property on our pizzas to say exactly what toppings they have and VegetarianPizza was\ndefined to be a Pizza with only kinds of CheeseTopping and only kinds of VegetableTopping. Figure\n4.58 shows the current asserted and inferred hierarchies. It is clear to see that the asserted hierarchy is\nsimpler and 'cleaner' than the 'tangled' inferred hierarchy. Although the ontology is only very simple at\nthis stage, it should be becoming clear that the use of a reasoner can help (especially in the case of large\nontologies) to maintain a multiple inheritance hierarchy for us.\n\nAsserted Hierarchy\nPizza\nMargheritaPizza\nVegetarianPizza\nCheesyPizza\nSohoPizza\nAmericanaPizza\nNamedPizza\nAmericanHotPizza\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nInferred Hierarchy\nCheesyPizza\nVegetarianPizza\nSohoPizza\nMargheritaPizza\nNamedPizza\nAmericanaPizza\nAmericanHotPizza\nPizza\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nis-a\nFigure 4.58: The asserted and inferred hierarchies showing the \"before and after\" classification of Pizzas into\nCheesyPizzas and VegetarianPizzas.\n4.14\nValue Partitions\nIn this section we create some Value Partitions, which we will use to refine our descriptions of various\nclasses. Value Partitions are not part of OWL, or any other ontology language, they are a 'design pattern'.\nDesign patterns in ontology design are analogous to design patterns in object oriented programming --\nthey are solutions to modelling problems that have occurred over and over again. These design patterns\nhave been developed by experts and are now recognised as proven solutions for solving common modelling\nproblems. As mentioned previously, Value Partitions can be created to refine our class descriptions, for\nexample, we will create a Value Partition called 'SpicinessValuePartition' to describe the 'spiciness' of\nPizzaToppings. Value Partitions restrict the range of possible values to an exhaustive list, for example, our\n'SpicinessValuePartition' will restrict the range to 'Mild', 'Medium', and 'Hot'. Creating a ValuePartition\nin OWL consists of several steps:\n1. Create a class to represent the ValuePartition. For example to represent a 'spiciness' ValuePartition\nwe might create the class SpicinessValuePartition.\n2. Create subclasses of the ValuePartition to represent the possible options for the ValuePartition.\nFor example we might create the classes Mild, Medium and Hot as subclasses of the SpicynessVal\nuePartition class.\n3. Make the subclasses of the ValuePartition class disjoint.\n4. Provide a covering axiom to make the list of value types exhaustive (see below).\n5. Create an object property for the ValuePartition. For example, for our spiciness ValuePartition,\nwe might create the property hasSpiciness.\n\nExercise 39: Create a ValuePartition to represent the spiciness of pizza toppings\n1. Select 'Create Value Partition' from the Wizards menu on the Prot eg e menu bar\nto invoke the ValuePartition wizard.\n2. On the first page of the wizard type SpicinessValuePartition as the name of the\nValuePartition class and press the Next button.\n3. Now enter hasSpiciness for the ValuePartition property name, and press the 'Next'\nbutton.\n4. We now need to specify the values for the value type. In the text area type Mild and\npress return, type Medium and press return, and type Hot and press return. This will\ncreate Mild, Medium and Hot as subclasses of the SpicinessValuePartition class. Press\nthe 'Next' button to continue.\n5. The ValuePartition names will be verified. Press the 'Next' button.\n6. The annotations page will be visible. At this point we could add annotations to the\nValuePartition if we wanted. However, at the moment we won't, so press the 'Next'\nbutton to continue.\n7. The final page of the wizard prompts us to specify a class that will act as a 'root'\nunder which all ValuePartitions will be created. We recommend that ValuePartitions\nare created under a class named ValuePartition, which is the default option. Press the\nFinish button to create the ValuePartition.\n6. Make the property functional.\n7. Set the range of the property as the ValuePartition class. For example for the hasSpiciness property\nthe range would be set to SpicinessValuePartition.\nIt should be relatively clear that due to the number of steps and the complexity of some of the steps,\nit would be quite easy to make a mistake. It could also take a significant amount of time to create\nmore than a few ValuePartitions. Fortunately, the OWL Wizards package contains a wizard for creating\nValuePartitions - appropriately named the 'Create ValuePartition' wizard.\nLet's create a ValuePartition that can be used to describe the spiciness of our pizza toppings. We will\nthen be able to classify our pizzas into spicy pizzas and non-spicy pizzas. We want to be able to say\nthat our pizza toppings have a spiciness of either 'mild', 'medium' or 'hot'. Note that these choices are\nmutually exclusive - something cannot be both 'mild' and 'hot', or a combination of the choices.\nLet's look at what the wizard has done for us (refer to Figure 4.59 and Figure 4.60):\n1. A ValuePartition class has been created as a subclass of owl:Thing.\n2. A SpicinessValuePartition class has been created as a subclass of ValuePartition.\n3. The classes Mild, Medium, Hot have been created as subclasses of SpicinessValuePartition.\n4. The classes Mild, Medium and Hot have been made disjoint from each other.\n\nFigure 4.59: Classes Added by the 'Create ValuePartition' Wizard\nFigure 4.60: The Conditions Widget Displaying the Description of the SpicinessValuePartition Class\n5. A class that is the union of Mild, Medium and Hot has been created as the subclass of Spiciness-\nValuePartition (see Figure 4.60).\n6. A hasSpiciness object property has been created.\n7. The hasSpiciness property has been made functional\n8. SpicinessValuePartition has been set as the range of the hasSpiciness property.\n4.14.1\nCovering Axioms\nAs part of the ValuePartition pattern we use a covering axiom. A covering axiom consists of two parts:\nThe class that is being 'covered', and the classes that form the covering. For example, suppose we have\nthree classes A, B and C. Classes B and C are subclasses of class A. Now suppose that we have a covering\naxiom that specifies class A is covered by class B and also class C. This means that a member of class A\nmust be a member of B and/or C. If classes B and C are disjoint then a member of class A must be a\nmember of either class B or class C. Remember that ordinarily, although B and C are subclasses if A an\nindividual may be a member of A without being a member of either B or C.\n\nIn Prot eg e-OWL a covering axiom manifests itself as a class that is the union of the classes being covered,\nwhich forms a superclass of the class that is being covered. In the case of classes A, B and C, class A\nwould have a superclass of B ⊔ C. The effect of a covering axiom is depicted in Figure 4.61.\nA\nB\nC\nA\nB\nC\nWithout a covering axiom\nWith a covering axiom\n(B and C are subclasses of A)\n(B and C are subclasses of A\nand A is a subclass of B union C)\nFigure 4.61: A schematic diagram that shows the effect of using a Covering Axiom to cover class A with classes\nB and C\nOur SpicinessValuePartition has a covering axiom to state that SpicinessValuePartition is covered by the\nclasses Mild, Medium and Hot -- Mild, Medium and Hot are disjoint from each other so that an individual\ncannot be a member of more than one of them. The class SpicinessValuePartition has a superclass that\nis Mild ⊔ Medium ⊔ Hot. This covering axiom means that a member of SpicinessValuePartition must be\na member of either Mild or Medium or Hot.\nThe difference between not using a covering axiom, and using a covering axiom is depicted in Figure 4.62.\nIn both cases the classes Mild, Medium and Hot are disjoint -- they do not overlap. It can be seen that in\nthe case without a covering axiom an individual may be a member of the class SpicinessValuePartition\nand still not be a member of Mild, Medium or Hot -- SpicynessValuePartition is not covered by Mild,\nMedium and Hot. Contrast this with the case when a covering axiom is used. It can be seen that if an\nindividual is a member of the class SpicinessValuePartition, it must be a member of one of the three\nsubclasses Mild, Medium or Hot -- SpicinessValuePartition is covered by Mild, Medium and Hot.\nSpicinessValuePartition\nMild\nMedium\nHot\nSpicinessValuePartition\nMild\nMedium\nHot\nWithout a covering axiom\nWith a covering axiom\n(SpicinessValuePartition is covered by\nMild, Medium, Hot)\nFigure 4.62: The effect of using a covering axiom on the SpicinessValuePartition\n\nthey have restrictions on the along the hasSpiciness property, with fillers of subclasses\nof the SpicinessValuePartition.\nTo complete this section, we will create a new class SpicyPizza, which should have pizzas that have spicy\ntoppings as its subclasses. In order to do this we want to define the class SpicyPizza to be a Pizza\nthat has at least one topping (hasTopping) that has a spiciness (hasSpiciness) that is Hot. This can be\naccomplished in more than one way, but we will create a restriction on the hasTopping property, that\n4.15\nUsing the Properties Matix Wizard\nWe can now use the SpicinessValuePartition to describe the spiciness of our pizza toppings. To do this\nwe will add an existential restriction to each kind of PizzaTopping to state it's spiciness. Restrictions\nwill take the form, ∃ hasSpiciness SpicynessValuePartition, where SpicinessValuePartition will be one\nof Mild, Medium or Hot. As we have over twenty toppings in our pizza ontology this could take rather\na long time. Fortunately, the Properties Matrix Wizard can help to speed things up. The properties\nmatrix wizard can be used to add existential restrictions along specified properties to many classes in a\nquick and efficient manner.\nExercise 40: Use the properties matrix wizard to specify the spiciness of pizza toppings\n1. Invoke the property matrix wizard by selecting the 'Properties Matrix' item from\nthe 'Wizards' menu on the Prot eg e menu bar.\n2. The first page to be displayed in the property matrix wizard is the classes selection\npage shown in Figure 4.63. By selecting toppings in the class hierarchy, and using the\nbuttons in the middle of the page ('>>' and '<<') classes may be transferred to the\nright hand side list. Select all of the pizza topping classes and transfer them to the\nright hand side list as shown in Figure 4.63. You should only select the classes that\nare 'actual' toppings, so classes such as CheeseTopping should not be selected. After\nselecting the toppings press the 'Next' button on the wizard.\n3. The wizard should now be displaying the page shown in Figure 4.64. Select the has-\nSpiciness property and use the (>>) button to move the property to the right hand\ncolumn (as shown in Figure 4.64). Press the 'Next' button on the wizard.\n4. In the final page on the wizard, the property fillers should be specified. This is done\nby double clicking on each class that is listed and selecting a filler of either Mild,\nMedium or Hot. Select fillers of Mild for everything except PepperoniTopping and\nSalamiTopping, which should have fillers of Medium, and JalapenoPepperTopping\nand SpicyBeef, which should have fillers of Hot. After selecting fillers, the wizard\npage should resemble Figure 4.65.\n5. Press the 'Finish' button to create the restrictions on the toppings and close the\nwizard. After the wizard has closed, select some different toppings and notice that\n\nFigure 4.63: Property Matrix Wizard: Class Selection Page\nFigure 4.64: Property Matrix Wizard: Property Selection Page\nFigure 4.65: Property Matrix Wizard: Restriction Fillers Page\n\nhas a restriction on the hasSpiciness property as its filler.\nExercise 41: Create a SpicyPizza as a subclass of Pizza\n1. Create a subclass of Pizza called SpicyPizza.\n2. With SpicyPizza selected in the class hierarchy, select the \"NECESSARY & SUFFI\nCIENT\" header in the conditions widget.\n3. Press the 'Create restriction' button on the conditions widget to show the 'Create\nRestriction Dialog'.\n4. Select '∃ someValuesFrom' as the type of restriction.\n5. Select hasTopping as the property to be restricted.\n6. The filler should be: PizzaTopping u ∃ hasSpiciness Hot. This filler describes an\nanonymous class, which contains the individuals that are members of the class Piz\nzaTopping and also members of the class of individuals that are related to the members\nof class Hot via the hasSpiciness property. In other words, the things that are Piz\nzaToppings and have a spiciness that is Hot. To enter this restriction as a filler type,\nPizzaTopping and some hasSpiciness Hot. The \"and\" keyword will be converted\nto the intersection symbol u, the \"some\" keyword will be converted to the existential\nquantifier symbol ∃.\n7. The 'Create Restriction Dialog' should now appear similar to the picture shown\nin Figure 4.67. Press the OK button to close the dialog and create the restriction.\n8. Finally, drag Pizza from under the \"NECESSARY\" header to on top of the newly\ncreated restriction (∃ hasTopping (PizzaTopping u ∃ hasSpiciness Hot)).\nFigure 4.66: The definition of SpicyPizza\nThe conditions widget should now look like the picture shown in Figure 4.66\n\nWe should now be able to invoke the reasoner and determine the spicy pizzas in our ontology.\nExercise 42: Use the reasoner to classify the ontology\n1. Press the 'Classifiy Taxonomy' button on the OWL toolbar to invoke the reasoner\nand classify the ontology.\nOur description of a SpicyPizza above says that all members of SpicyPizza are\nPizzas and have at least one topping that has a Spiciness of Hot. It also says that\nanything that is a Pizza and has at least one topping that has a spiciness of Hot\nis a SpicyPizza.\nIn the final step of Exercise 41 we created a restriction that had the class expres\nsion (PizzaTopping u ∃ hasSpiciness Hot) rather than a named class as its filler.\nThis filler was made up of an intersection between the named class PizzaTopping\nand the restriction ∃ hasSpiciness Hot. Another way to do this would have been\nto create a subclass of PizzaTopping called HotPizzaTopping and define it to be\na hot topping by having a necessary condition of ∃ hasSpiciness Hot. We could\nhave then used ∃ hasTopping HotPizzaTopping in our definition of SpicyPizza.\nAlthough this alternative way is simpler, it is more verbose. OWL allows us to\nessentially shorten class descriptions and definitions by using class expressions in\nplace of named classes as in the above example.\nFigure 4.67: Create Restriction Dialog: A Restriction Describing a Spicy Topping\n\nw\nor\nks\nWi\nth\nMatthew\nNick\nw\no\nr\nk\ns\nW\ni\nt\nh\nHai\nFigure 4.68: Cardinality Restrictions: Counting Relationships\nAfter the reasoner has finished, the 'Inferred Hierarchy' class pane will pop open, and you should find\nthat AmericanHotPizza has been classified as a subclass of SpicyPizza -- the reasoner has automatically\ncomputed that any individual that is a member of AmericanHotPizza is also a member of SpicyPizza.\n4.16\nCardinality Restrictions\nIn OWL we can describe the class of individuals that have at least, at most or exactly a specified number\nof relationships with other individuals or datatype values. The restrictions that describe these classes are\nknown as Cardinality Restrictions. For a givien property P, a Minimum Cardinality Restriction specifies\nthe minimum number of P relationships that an individual must participate in. A Maximum Cardinality\nRestriction specifies the maximum number of P relationships that an individual can participate in. A\nCardinality Restriction specifies the exact number of P relationships that an individual must participate\nin.\nRelationships (for example between two individuals) are only counted as separate relationships if it can\nbe determined that the individuals that are the fillers for the relationships are different to each other. For\nexample, Figure 4.68 depicts the individual Matthew related to the individuals Nick and the individual\nHai via the worksWith property. The individual Matthew satisfies a minimum cardianlity restriction of\n2 along the worksWith property if the individuals Nick and Hai are distinct individuals i.e. they are\ndifferent individuals.\nLet's add a cardinality restriction to our Pizza Ontology. We will create a new subclass of Pizza called\n\nInterestingPizza, which will be defined to have three or more toppings.\nExercise 43: Create an InterestingPizza that has at least three toppings\n1. Switch to the OWLClasses tab and make sure that the Pizza class is selected.\n2. Create a subclass of Pizza called InterestingPizza.\n3. Select the \"NECESSARY & SUFFICIENT\" header in the conditions widget.\n4. Press the 'Create restriction' button to bring up the 'Create restriction dialog'.\n5. Select '≥ minCardinality' as the type of restriction to be created.\n6. Select hasTopping as property to be restricted.\n7. Specify a minimum cardinality of three by typing 3 into the restriction filler edit box.\n8. Press the 'OK' button to close the dialog and create the restriction.\n9. The conditions widget should now have a \"NECESSARY\" condition of Pizza, and a\n\"NECESSARY & SUFFICIENT\" condition of hasTopping ≥ 3. We need to make\nPizza part of the necessary and sufficient conditions. Drag Pizza and drop it on top\nof the hasTopping ≥ 3 condition.\nThe conditions widget should now appear like the picture shown in Figure 4.69.\nFigure 4.69: The Conditions Widget Displaying the Description of an InterestingPizza\n\nWhat does this mean?\nOur definition of an InterestingPizza describes the set\nof individuals that are members of the class Pizza and that have at least three\nhasTopping relationships with other (distinct) individuals.\nExercise 44: Use the reasoner to classify the ontology\n1. Press the 'Classify Taxonomy' button on the OWL toolbar.\nAfter the reasoner has classified the ontology, the 'Inferred Hierarchy' window will pop open. Expand\nthe hierarchy so that InterestingPizza is visible. Notice that InterestingPizza now has subclasses Ameri\ncanaPizza, AmericanHotPizza and SohoPizza -- notice MargheritaPizza has not been classified under\nInterestingPizza because it only has two distinct kinds of topping.\n\nExercise 45: Create NonVegetarianPizza as a subclass of Pizza and make it disjoint to Vegetarian-\nPizza\n1. Select Pizza in the class hierarchy on the 'OWLClasses' tab. Press the 'Create\nsubclass' button to create a new class as the subclass of Pizza.\n2. Rename the new class to NonVegetarianPizza.\n3. Make NonVegetarianPizza disjoint with VegetarianPizza -- while NonVegetarian-\nPizza is selected, press the 'Add named class' button on the disjoint classes widget\n(Figure 4.5).\nChapter 5\nMore On Open World Reasoning\nThis examples in this chapter demonstrate the nuances of Open World Reasoning.\nWe will create a NonVegetarianPizza to complement our categorisation of pizzas into VegetarianPizzas.\nThe NonVegetarianPizza should contain all of the Pizzas that are not VegetarianPizzas. To do this\nwe will create a class that is the complement of VegetarianPizza. A complement class contains all of\nthe individuals that are not contained in the class that it is the complement to. Therefore, if we create\nNonVegetarianPizza as a subclass of Pizza and make it the complement of VegetarianPizza it should\ncontain all of the Pizzas that are not members of VegetarianPizza.\n\nExercise 46: Make VegetarianPizza the complement of VegetarianPizza\n1. Make sure that NonVegetarianPizza is selected in the class hierarchy on the\n'OWLClasses tab'.\n2. Select the \"NECESSARY & SUFFICIENT\" header in the 'Conditions Widget'.\n3. Press the 'Create new expression' button, which will 'pop' open an 'inline expres\nsion editor' in the 'Conditions Widget' as shown in Figure 5.1. The inline expression\neditor contains an edit box for typing expressions into, and the expression builder panel\n(the same one that is found in the 'Create restriction dialog'), which can be used\nto insert class names and logical symbols into the edit box.\n4. Type not VegetarianPizza into the edit box. The \"not\" keyword will be converted\ninto the 'complement of ' symbol (¬). Alternatively, to enter the expression using the\nexpression builder panel, use the 'Insert complementOf' button shown in Figure\n5.3 to insert the complementOf symbol, and the use the 'Insert class' button (Figure\n5.3) to display a dialog from which VegetarianPizza can be selected.\n5. Press the return key to create and assign the expression. If everything was entered\ncorrectly then the inline expression editor will close and the the expression will have\nbeen created. (If there are errors, check the spelling of \"VegetarianPizza\").\nA very useful feature of the expression editor is the ability to 'auto complete' class\nnames, property names and individual names. The auto completion for the inline\nexpression editor is activated using the tab key. In the above example if we had\ntyped Vege into the inline expresion editor and pressed the tab key, the choices\nto complete the word Vege would have poped up in a list as shown in Figure 5.2.\nThe up and down arrow keys could then have been used to select VegetarianPizza\nand pressing the Enter key would complete the word for us.\nThe conditions widget should now resemble to picture shown in 5.4. However, we need to add Pizza to the\nnecessary and sufficient conditions as at the moment our definition of NonVegetarianPizza says that an\nindividual that is not a member of the class VegetarianPizza (everything else!) is a NonVegetarianPizza.\nWe now want to define a NonVegetarianPizza to be a Pizza that is not a VegetarianPizza.\n\nFigure 5.1: Conditions Widget: Inline Expression Editor\nFigure 5.2: Conditions Widget: Inline Expression Editor Auto Completion\nInsert complement of\nInsert class\nFigure 5.3: Using the Expression Builder Panel to insert Complement Of\nFigure 5.4: The\nConditions\nWidget\nDisplaying\nthe\nIntermediate\nStep\nof\nCreating\na\nDefinition\nforNonVegetarianPizza\n\nThe 'Conditions Widget' should now look like the picture shown in Figure 5.5.\nThe complement of a class includes all of the individuals that are not members of\nthe class. By making NonVegetarianPizza a subclass of Pizza and the comple\nment of VegetarianPizza we have stated that individuals that are Pizzas and are\nnot members of VegetarianPizza must be members of NonVegetarianPizza. Note\nthat we also made VegetarianPizza and NonVegetarianPizza disjoint so that if an\nindividual is a member of VegetarianPizza it cannot be a member of NonVege\ntarianPizza.\n\nExercise 48: Use the reasoner to classify the ontology\n1. Press the 'Classify taxonomy' button on the OWL toolbar.\nAfter a short time\nthe reasoner will have computed the inferred class hierarchy, and the inferred class\nhierarchy pane will pop open.\nThe inferred class hierarchy should resemble the picture shown in Figure 5.6. As can be seen, Margher\nFigure 5.5: The Conditions Widget Displaying the Definition forNonVegetarianPizza\nExercise 47: Add Pizza to the necessary and sufficient conditions for NonVegetarianPizza\n1. Make sure NonVegetarianPizza is selected in the class hierarchy on the 'OWLClases'\ntab.\n2. Select Pizza in the 'Conditions Widget'.\n3. Drag Pizza from under the \"NECESSARY\" header, and drop it onto the '¬ Vegetar\nianPizza' condition to add it to the same set of necessary and sufficient conditions as\n¬ VegetarianPizza.\n\nExercise 50: Use the reasoner to classify the ontology\n1. Press the 'Classify taxonomy' button on the OWL toolbar.\nExamine the class hierarchy. Notice that UnclosedPizza is neither a VegetarianPizza or NonVegetari\nanPizza.\nExercise 49: Create a subclass of NamedPizza with a topping of Mozzarella\n1. Create a subclass of NamedPizza called UnclosedPizza.\n2. Making sure that UnclosedPizza is selected in the 'Conditions Widget' select the\n\"NECESSARY\" header.\n3. Press the 'Create restriction' button to display the 'Create restriction dialog'.\n4. Select '∃ someValuesFrom' in order to create an existential restriction.\n5. Select hasTopping as the property to be restricted.\n6. Type MozzarellaTopping into the filler edit box to specify that the toppings must be\nindividuals that are members of the class MozzarellaTopping.\n7. Press the 'OK' button to close the dialog and create the restriction.\nIf an individual is a member of UnclosedPizza it is necessary for it to be a Named-\nPizza and have at least one hasTopping relationship to an individual that is a\nmember of the class MozzarellaTopping.\nRemember that because of the Open\nWorld Assumption and the fact that we have not added a closure axiom on the\nhasTopping property, an UnclosedPizza might have additional toppings that are\nnot kinds of MozzarellaTopping.\nitaPizza and SohoPizza have been classified as subclasses of VegetarianPizza.\nAmericanaPizza and\nAmericanHotPizza have been classified as NonVegetarianPizza. Things seemed to have worked. How\never, let's add a pizza that does not have a closure axiom on the hasTopping property.\n\nFigure 5.6: The Inferred Class Hierarchy Showing Inferred Subclasses of VegetarianPizza and NonVegetarian-\nPizza\n\nAs expected (because of Open World Reasoning) UnclosedPizza has not been\nclassified as a VegetarianPizza. The reasoner cannot determine UnclosedPizza is\na VegetarianPizza because there is no closure axiom on the hasTopping and the\npizza might have other toppings. We therefore might have expected Unclosed-\nPizza to be classified as a NonVegetarianPizza since it has not been classified\nas a VegetarianPizza.\nHowever, Open World Reasoning does not dictate that\nbecause UnclosedPizza cannot be determined to be a VegetarianPizza it is not\na VegetarianPizza -- it might be a VegetarianPizza and also it might not be a\nVegetarianPizza! Hence, UnclosePizza cannot be classified as a NonVegetarian-\nPizza.\n\nChapter 6\nCreating Other OWL Constructs In\nProt eg e-OWL\nThis chapter discusses how to create some other owl constructs using Prot eg e-OWL . These constructs\nare not part of the main tutorial and may be created in a new Prot eg e-OWL project if desired.\n6.1\nCreating Individuals\nOWL allows us to define individuals and to assert properties about them. Individuals can also be used\nin class descriptions, namely in hasValue restrictions and enumerated classes which will be explained in\nsection 6.2 and section 6.3 respectively. To create individuals in Prot eg e-OWL the 'Individuals Tab' is\nused.\nSuppose we wanted to describe the country of origin of various pizza toppings. We would first need to\nadd various 'countries' to our ontology. Countries, for example, 'England', 'Italy', 'America', are typically\nthought of as being individuals (it would be incorrect to have a class England for example, as it's members\nwould be deemed to be, 'things that are instances of England'). To create this in our Pizza Ontology we\n\nExercise 51: Create a class called Country and populate it with some individuals\n1. Create Country as a subclass of owl:Thing.\n2. Switch to the 'Individuals Tab' shown in Figure 6.1 and select the class Country in\nthe 'Classes' tree.\n3. Press the 'Create Instance' button shown in Figure 6.2. (Remember that 'Instance'\nis another name for 'Individual' in ontology terminology).\n4. An individual that is a member of Country will be created with a auto-generated name.\nRename the individual using the 'Name' widget (located on the individuals tab to\nthe right of the class view and instances list) to Italy.\n5. Use the above steps to create some more individuals that are members of the class\nCountry called America, England, France, and Germany.\nFigure 6.1: The Individuals Tab\nwill create a class Country and then 'populate' it with individuals:\n\nCreate instance\n(of selected class)\nDelete selected instance\nDuplicate selected instance\nFigure 6.2: Instances Manipulation Buttons\nFigure 6.3: The SameAs Widget\nRecall from section 3.2.1 that OWL does not use the Unique Name Assumption (UNA). Individuals can\ntherefore be asserted to be the 'Same As' or 'Different From' other individuals. In Prot eg e-OWL these\nassertions can be made using the 'SameAs' and 'DifferentFrom' tabs shown in Figure 6.3, which are\nlocated with the 'Name' widget on the 'Individuals' tab.\nHaving created some individuals we can now use these individuals in class descriptions as described in\nsection 6.2 and section 6.3.\n6.2\nhasValue Restrictions\nA hasValue restriction, denoted by the symbol 3, describes the set of individuals that have at least one\nrelationship along a specified property to a specific individual. For example, the hasValue restriction\nhasCountryOfOrigin 3 Italy (where Italy is an individual) describes the set of individuals (the anonymous\nclass of individuals) that have at least one relationship along the hasCountryOfOrigin property to the\nspecific individual Italy. For more information about hasValue restrictions please see Appendix A.2.\nSuppose that we wanted to specify the origin of ingredients in our pizza ontology. For example, we might\nwant to say that mozzarella cheese (MozzarellaTopping) is from Italy. We already have some countries\nin our pizza ontology (including Italy), which are represented as individuals. We can use a hasValue\n\nbe selected.\n8. Press 'OK' to close the dialog and create the restriction.\nThe 'Conditions Widget' should now look similar to the picture shown in Figure 6.4.\nThe conditions that we have specified for MozzarellaTopping now say that: in\ndividuals that are members of the class MozzarellaTopping are also members of\nthe class CheeseTopping and are related to the individual Italy via the hasCoun\ntryOfOrigin property and are related to at least one member of the class Mild\nvia the hasSpiciness property. In more natural English, things that are kinds of\nmozzarella topping are also kinds of cheese topping and come from Italy and are\nmildly spicy.\nFigure 6.4: The Conditions Widget Displaying The hasValue Restriction for MozzarellaTopping\nrestriction along with these individuals to specify the county of origin of MozzarellaTopping as Italy.\nExercise 52: Create a hasValue restriction to specify that MozzarellaTopping has Italy as its country\nof origin.\n1. Switch to the 'Properties' tab. Create a new object property and name it hasCoun\ntryOfOrigin.\n2. Switch to the 'OWLClasses' tab and select the class MozzarellaTopping.\n3. Select the \"NECESSARY\" header in the 'Conditions Widget'.\n4. Press the 'Create restriction' button on the 'Conditions Widget' to bring up the\n'Create restriction dialog'.\n5. Select 3 hasValue as the type of restriction to be created.\n6. Select hasCountryOfOrigin as the property to be restricted.\n7. In the restriction filler box enter the individual Italy as a filler -- either type Italy\ninto the filler edit box, or, press the 'Insert individual' button on the expression\nbuilder panel, which will pop open a dialog box from which the individual Italy may\n\nWith current reasoners the classification is not complete for individuals. Use in\ndividuals in class descriptions with care -- unexpected results may be caused by\nthe reasoner.\nExercise 53: Convert the class Country into an enumerated class\n1. Switch the the 'OWLClasses' tab and select the class Country.\n2. Select the \"NECESSARY & SUFFICIENT\" header in the 'Conditions Widget'.\n3. Press the 'Create new expression' button. The inline expression editor will pop\nopen.\n4. Type {America England France Germany Italy} into the expression edit box. (Re\nmember to surround the items with curly brackets). Remember that the auto complete\nfunction is available -- to use it type the first few letters of an individual and press\nthe tab key to get a list of possible choices.\n5. Press the enter key to accept the enumeration and close the expression editor.\nThe 'Conditions Widget' should now look similar to the picture shown in Figure 6.5.\n6.3\nEnumerated Classes\nAs well as describing classes through named superclasses and anonymous superclasses such as restrictions,\nOWL allows classes to be defined by precisely listing the individuals that are the members of the class. For\nexample, we might define a class DaysOfTheWeek to contain the individuals (and only the individuals)\nSunday, Monday, Tuesday, Wednesday, Thursday, Friday and Saturday. Classes such as this are known\nas enumerated classes.\nIn Prot eg e-OWL enumerated classes are defined using the 'Conditions Widget' expression editor - the\nindividuals that make up the enumerated class are listed (separated by spaces) inside curly brackets. For\nexample {Sunday Monday Tuesday Wednesday Thursday Friday Saturday}. The individuals must first\nhave been created in the ontology. Enumerated classes described in this way are anonymous classes -\nthey are the class of the individuals (and only the individuals) listed in the enumeration. We can attach\nthese individuals to a named class in Prot eg e-OWL by creating the enumeration as a \"NECESSARY &\nSUFFICIENT\" condition.\n\nThis means that an individual that is a member of the Country class must be one\nof the listed individuals (i.e one of America England France Germany Italy. a More\nformally, the class country is equivalent to (contains the same individuals as) the\nanonymous class that is defined by the enumeration -- this is depicted in Figure\n6.6.\naThis is obviously not a complete list of countries, but for the purposes of this ontology (and\nthis example!) it meets our needs.\n\nThe enumerated classes wizard is available for creating enumerated classes in the\nabove fashion.\n6.4\nAnnotation Properties\nOWL allows classes, properties, individuals and the ontology itself (technically speaking the ontology\nFigure 6.5: The Conditions Widget Displaying An Enumeration Class\nEngland\nItaly\nAmerica\nFrance\nGermany\nEnumerated Class\n(dashed line)\nCountry (solid line)\nFigure 6.6: A Schematic Diagram Of The Country Class Being Equivalent to an Enumerated Class\nheader) to be annotated with various pieces of information/meta-data. These pieces of information may\ntake the form of auditing or editorial information. For example, comments, creation date, author, or,\nreferences to resources such as web pages etc. OWL-Full does not put any constraints on the usage\nof annotation properties. However, OWL-DL does put several constraints on the usage of annotation\nproperties -- two of the most important constaints are:\n\n- The filler for annotation properties must either be a data literal1, a URI reference or an individual.\n- Annotation properties cannot be used in property axioms -- for example they may not be used\nin the property hierarchy, so they cannot have sub properties, or be the sub property of another\nproperty. The also must not have a domain and a range set for them.\nOWL has five pre-defined annotation properties that can be used to annotate classes (including anony\nmous classes such as restrictions), properties and individuals:\n1. owl:versionInfo -- in general the range of this property is a string.\n2. rdfs:label -- has a range of a string. This property may be used to add meaningful, human readable\nnames to ontology elements such as classes, properties and individuals. rdfs:label can also be used\nto provide multi-lingual names for ontology elements.\n3. rdfs:comment -- has a range of a string.\n4. rdfs:seeAlso -- has a range of a URI which can be used to identify related resources.\n5. rdfs:isDefinedBy -- has a range of a URI reference which can be used to reference an ontology that\ndefines ontology elements such as classes, properties and individuals.\nFor example the annotation property rdfs:comment is used to store the comment for classes in the Prot eg e-\nOWL plugin. The annotation property rdfs:label could be used to provide alternative names for classes,\nproperties etc.\nThere are also several annotation properties which can be used to annotate an ontology. The ontology\nannotation properties (listed below) have a range of a URI reference which is used to refer to another\nontology. It is also possible to the use the owl:VersionInfo annotation property to annotate an ontology.\n- owl:priorVersion -- identifies prior versions of the ontology.\n- owl:backwardsCompatibleWith -- identifies a prior version of an ontology that the current ontology\nis compatible with. This means that all of the identifiers from the prior version have the same\nintended meaning in the current version. Hence, any ontologies or applications that reference the\nprior version can safely switch to referencing the new version.\n- owl:incompatibleWith -- identifies a prior version of an ontology that the current ontology is not\ncompatible with.\nTo create annotation properties the 'Create annotation datatype property' and 'Create annota\ntion object property' buttons on the 'Properties' tab should be used. To use annotation properties\nthe annotations widgets shown in Figure 6.7 is used. An annotations widget is located on the OWL-\nClasses, Properties, Individuals and Metadata tab for annotation classes, properties, individuals and the\nontology respectively. Annotations can also be added to restrictions and other anonymous classes by right\nclicking (ctrl click on a Mac) in the conditions widget and selecting 'Edit annotation properties...'.\n1A data literal is the character representation of a datatype value, for example,\"Matthew\", 25, 3.11.\n\nCreate a new\nannotation value\nAdd a TODO list\nannotation item\nAdd an existing individual\nas an annotation\nDelete the selected\nannotation\nFigure 6.7: An annotations widget\n6.5\nMultiple Sets Of Necessary & Sufficient Conditions\nIn OWL it is possible to have multiple sets of necessary and sufficient conditions as depicted in Figure\n6.8. In the 'Conditions Widget', multiple sets of necessary and sufficient conditions are represented\nusing multiple \"NECESSARY & SUFFICIENT\" headers with necessary and sufficient conditions listed\nunder each header as shown in Figure 6.8. To create a new set of necessary and sufficient conditions, any\n\"NECESSARY & SUFFICIENT\" header (any that is visible) should be selected and then the condition\ncreated (for example using the 'Create Restriction dialog').\nAlternatively, a condition should be\ndragged and dropped onto a \"NECESSARY & SUFFICIENT\" header to create a new set of necessary\nand sufficient conditions and move the condition to that new set. To add to an existing set of necessary\nand sufficient conditions, one of the conditions in the set should be selected and then the condition\ncreated (for example using 'Create Restrictions dialog'), or an existing condition may be dragged and\ndropped onto the existing set (below the \"NECESSARY & SUFFICIENT\" header) to add the condition\nto the existing set.\nNECESSARY CONDITIONS\nCondition\nCondition\nNamedClass\nNECESSARY & SUFFICIENT CONDITIONS\nCondition\nCondition\nimplies\nNECESSARY & SUFFICIENT CONDITIONS\nCondition\nCondition\nImplies\nImplies\nFigure 6.8: Necessary Conditions, and Multiple Sets of Necessary And Sufficient Conditions\n\nFigure 6.9: The Definition of a Triangle Using Multiple Necessary & Sufficient Conditions\nExercise 54: Create a class to define a Triangle using multiple sets of Necessary & Sufficient con\nditions\n1. Create a subclass of owl:Thing named Polygon.\n2. Create a subclass of Polygon named Triangle.\n3. Create an object property named hasSide.\n4. Create an object property named hasAngle.\n5. On the 'OWLClasses' tab select the Triangle class.\nSelect the \"NECESSARY &\nSUFFICIENT\" header in the 'Conditions Widget'. Press the 'Create restriction\nbutton' on the 'Conditions Widget' to display the 'Create restriction dialog'.\n6. Select = cardinality as the type of restriction to be created. Select hasSide as the\nproperty to be restricted. In the filler edit box type 3. Press 'OK' to close the dialog\nand create the restriction\n7. Select the \"NECESSARY & SUFFICIENT\" header in the 'Conditions Widget'\nagain. Press the 'Create restriction' button to display the 'Create restriction'\ndialog.\n8. Select = cardinality as the type of restriction to be created. Select hasAngle as the\nproperty to be restricted. In the filler edit box type 3. Press 'OK' to close the dialog\nand create the restriction.\n9. Drag Polygon from under the \"NECESSARY\" header and drop it onto the hasSide\n= 3 restriction.\n10. Select the hasAngle = 3 restriction.\nClick the 'Add named class...'\nbutton to\ndisplay a dialog containing the class hierarchy. Select the Polygon class and click the\n'OK' button to close the dialog.\nThe 'Conditions Widget' should now look like the picture shown in Figure 6.9.\n\nChapter 7\nOther Topics\n7.1\nLanguage Profile\nAs explained in section 3.1 on page 11, there are three sub-languages of OWL: OWL-Lite, OWL-DL and\nOWL-Full. When editing an ontology Prot eg e-OWL offers the ability to constrain the constructs used\nin class expressions etc. so that the ontology being edited falls into either the OWL-DL or OWL-Full\nsub-langauges. The desired sub-language, or 'language profile' to be used can be set via the Prot eg e-\nOWL preferences dialog shown in Figure 4.41 on page 52. To choose between OWL-DL and OWL-Full,\nthe 'OWL (supports one of the following OWL species)' should be ticked, and then either the\n'OWL DL (optimized for reasoning)' or the 'OWL Full (supports the complete range of OWL\nelements)' should be selected.\n7.2\nNamespaces And Importing Ontologies\nOWL ontologies are able to import other OWL ontologies rather like importing packages in java, or\nincluding files in C/C++. This section describes namespaces, which are a general naming mechanism\nand are usually used to facilitate ontology importing. It then describes how to import ontologies in\ngeneral.\n7.2.1\nNamespaces\nEvery ontology has its own namespace -- this is known as the default namespace. An ontology may\nalso use other namespaces. A namespace is a string of characters that prefixes the class, property and\nindividual identifiers in an ontology.\nBy maintaining different namespaces for different ontologies it\nis possible for one ontology to reference classes, properties and individuals in another ontology in an\nunambiguous manner and without causing name clashes. For example, all OWL ontologies (including the\nPizza ontology developed in this tutorial) reference the class owl:Thing. This class resides in the OWL\nvocabulary ontology that has the namespace http://www.w3.org/2002/07/owl#.\nIn order to ensure that namespaces are unique they manifest themselves as Unique Resource Identifiers\n\n(URIs)1 ending in either '/' or '#'. For example, the default namespace in Prot eg e-OWL (the names\npace that is assigned to newly created ontologies in Prot eg e-OWL ) is http://a.com/ontology#.\nThis\nmeans that all identifiers for classes, properties and individuals that are created in Prot eg e-OWL (by de\nfault) are prefixed with http://a.com/ontology#. For example, the full name for the class PizzaTopping is\nhttp://a.com/ontology#PizzaTopping. The full name for the class MargheritaPizza is http://a.com/ontology#MargheritaPizz\nFortunately, Prot eg e-OWL hides these namespace prefixes which means that we don't have to type in\nthese long winded names every time we want to use a class, property or individual identifier.\nNamespaces help to avoid name clashes when one ontology references classes, properties and individu\nals in another ontology. For example, suppose an ontology about aircraft, AircraftOntology has a class\nnamed Wing, which describes the wing of an aeroplane. An ontology about birds, BirdOntology also\nhas a class named Wing, which describes the wing of a bird. The namespace for the AircraftOntology is\nhttp://www.ontologies.com/aircraft#. The namespace for the BirdOntology is http://www.birds.com/ontologies/BirdOntology\nEvidently, the Wing class in the AircraftOntology is not the same as the Wing class in the BirdOntology.\nNow suppose that the AircraftOntology imports the BirdOntology. Because of the namespace mechanism,\nthe full name for the Wing class in the AircraftOntology is http://www.ontologies.com/aircraft#Wing. The\nfull name for the Wing class in the BirdOntology is http://www.birds.com/ontologies/BirdOntology#Wing.\nHence, when the AircraftOntology refers to classes in the BirdOntology no name clash will occur. Note\nthat neither of the above namespace URIs necessarily have to be URLs i.e. they don't necessarily have\nto have a physical location (on the web) -- URIs are used because they ensure Uniqueness.\nIn order to make referencing classes, properties and individuals more manageable when using multiple\nnamespaces, namespace prefixes are used.\nA namespace prefix is a short string, usually a sequence\nof around two or three characters that represents a full namespace. For example, we could use \"ac\"\nto represent the above 'aircraft ontology' namespace http://www.ontologies.com/aircraft# and the prefix\n\"bird\" to represent the 'bird ontology' namespace http://www.birds.com/ontologies/BirdOntology#. When\nwe now use identifiers such as class names, we prefix the identifier with the namespace prefix and a colon.\nFor example ac:Wing or bird:Wing.\nFor a given ontology, the default namespace is the namespace for that ontology -- in Prot eg e-OWL\nthe default namespace corresponds to the namespace of the ontology that is being edited. When using\nidentifiers that belong to the default namespace (the ontology being edited) a namespace prefix is not\nused -- classes, properties and individuals are simply referenced using their 'local' name. However, for\nimported ontologies we must use a namespace prefix to refer to classes, properties and individuals in the\nimported ontology. For example, suppose we were editing the 'aircraft ontology', which has a namespace\nof http://www.ontologies.com/aircraft# and we wanted to refer to classes in the 'bird ontology' with the\nnamespace of http://www.birds.com/ontologies/BirdOntology# and the namespace prefix of \"bird\". When\nwe refer to classes without a namespace prefix, for example Wing, we are talking about classes in the\naircraft ontology. When we refer to classes with a namespace prefix 'bird', for example bird:Wing, we are\ntalking about classes in the bird ontology.\n7.2.2\nCreating And Editing Namespaces in Prot eg e-OWL\nEditing The Default Namespace\nThe default namespace can be set using the 'Default Namespace' widget, which is located in the top\nleft corner of the 'Metadata' tab and is shown in Figure 7.1. To change the default namespace simply\ntype a new namespace into the edit box. The namespace must be a valid URI and must end in either '/'\nor '#'. Some examples of valid namespaces are listed below:\n1Note that Unique Resource Locators (URLs), which identify physical locations of documents (e.g. web pages) are a\nspecial form of URI.\n\nMake default namespace\nAdd to ont-policy file\nDefault Namespace\nAdd prefix\nRemove prefix\nFigure 7.1: The Default Namespace and Namespaces Widget\n- myNameSpace#\n- universityOfManchester:ontologies:pizzas#\n- http://www.cs.man.ac.uk/ontologies/pizzas/\nCreating Other Namespaces\nAs well as specifying a default namespace for the ontology it is possible to setup other namespace prefix\n- namespace mappings. This makes it possible to refer to classes, properties and individuals in other\nontologies.\nTo create/setup namespaces and their associated prefixes in Prot eg e-OWL the 'Namespace Prefixes'\nwidget shown in Figure 7.1 is used. This widget contains three columns: 'Prefix', 'Namespace' and\n'Imported' -- we will deal with the 'Imported' column later. When Prot eg e-OWL creates a new OWL\nproject it automatically creates/sets up three namespaces:\n- rdf -- http://www.w3.org/1999/02/22-rdf-syntax-ns# (The Resource Description Framework names\npace)\n- rdfs -- http://www.w3.org/2000/01/rdf-schema# (The RDF-Schema namespace)\n- owl -- http://www.w3.org/2002/07/owl# (The OWL vocabulary namespace)\nLet's add a new namespace and prefix, which we can use in our ontology. For the purposes of this example\nwe will add a prefix and namespace for the wine ontology2, which has the namespace http://www.w3.org/TR/2004/REC\n2The wine ontology is discussed and used as an example in the W3C OWL Guide. It contains information about various\ntypes of wine and wineries.\n\nowl-guide-20040210/wine#.\nExercise 55: Create a namespace and prefix to refer to classes, properties and individuals in the\nWine ontology\n1. Press the 'Add prefix' button on the 'Namespace prefix' widget shown in Figure\n7.1 to create a new namespace. A new namespace http://www.domain2.com# will be\ncreated with a prefix of p1.\n2. Double click on the prefix p1 to edit it. Change it to vin, which is the namespace\nprefix used in the wine ontology.\n3. Double click on the namespace http://www.domain2.com# to edit it.\nChange it to\nhttp://www.w3.org/TR/2004/REC-owl-guide-20040210/wine#. If the namespace is en\ntered incorrectly i.e. if the namespace is not a valid URI and it does not end in '/'\nor '#' Prot eg e-OWL will reject the entry and revert to the previous value for the\nnamespace.\n4. We can now reference concepts in the wine ontology, and create classes and properties\nin the wine ontology namespace. For example create a new object property and name\nit vin:myWineProperty.\nThe property myWineProperty resides in the vin namespace http://www.w3.org/TR/2004/REC-owl-guide\n20040210/wine# (hence the prefixed name vin:myWineProperty).\nThe full name of the property is\ntherefore http://www.w3.org/TR/2004/REC-owl-guide-20040210/wine#myWineProperty.\n7.2.3\nOntology Imports in OWL\nOWL ontologies may import one or more other OWL ontologies. For example, suppose that the Air\ncraftOntology imports the BirdOntology which contains descriptions of various birds (perhaps we want\nto simulate bird strikes on aircraft) -- all of the classes, properties, individuals and axioms that are con\ntained in the BirdOntology will be available to be used in the AircraftOntology. This makes it possible to\nuse classes, properties and individuals from the BirdOntology in class descriptions in the AircraftOntology.\nIt also makes it possible to extend the descriptions of classes, properties and individuals in the BirdOn\ntology by creating the extention descriptions in the AircraftOntology. Notice the distinction between\nreferring to classes, properties and individuals in an other ontology using namespaces, and completely\nimporting an ontology. When an ontology imports another ontology, not only can classes, properties\nand individuals be referenced by the importing ontology, the axioms and facts that are contained in the\nontology being imported are actually included in the importing ontology. It should be noted that OWL\nallows ontology imports to be cyclic so for example OntologyA may import OntologyB and OntologyB\nmay import OntologyA.\n7.2.4\nImporting Ontologies in Prot eg e-OWL\nOntology imports are usually co-ordinated using namespaces.\nThe ontology being imported has its\nnamespace and also namespace prefix set up and is then imported. To import an ontology in Prot eg e-\nOWL we must first locate the ontology that we want to import and determine its URL. For the purposes\n\nof this example we will import the koala ontology, which is a simple ontology created by Holger Knublauch\n(author of the Prot eg e-OWL plugin) that demonstrates the constructs of OWL. The koala ontology is\nlocated on the web at http://protege.stanford.edu/plugins/owl/owl-library/koala.owl.\nLet's import the koala ontology -- for the purposes of this tutorial the koala ontology may be imported\ninto a new, empty OWL ontology.\nExercise 56: Import the koala ontology into an ontology\n1. Switch to the 'Metadata' tab.\n2. Press the 'Add prefix' button located on the 'Namespace prefix' widget. A new\nnamespace and namespace prefix will be created.\n3. Edit the namespace prefix, changing it to koala.\n4. We\nnow\nneed\nto\nspecify\nthe\nnamespace.\nWhen\nimporting\nontologies\nthe\nnamespace should be the actual URL that the ontology is located at,\nfol\nlowed by '/' or '#'.\nEdit the namespace for the koala prefix, changing it to\nhttp://protege.stanford.edu/plugins/owl/owl-library/koala.owl#.\n5. Now tick the 'Import tick box' that lies on the same line as the koala prefix and\nnamespace. You will be presented with a dialog stating that the changes will not take\nplace until the file is saved and reloaded. Click the 'Yes' button on the dialog. If you\nhaven't already saved the project you will be presented with the save dialog box --\ngive the project a name and save it.\nAfter these steps have been performed Prot eg e-OWL will import the koala ontology and then save and\nreload the project.\nWhen the project is reloaded the 'OWLClasses' tab will be displayed and will\ncontain classes from the koala ontology - likewise, the properties tab will also display properties from the\nkoala ontology. It should be noted that imported classes cannot be edited (they cannot have information\nretracted) or deleted - class descriptions can only have information added to them.\nAlternative Locations\nWhen it is intended that an ontology should be imported, it is usual for the namespace URI to actually\nbe a URL (i.e. a pointer to a physical location) that points to the location where the ontology may be\nfound. In most situations this is usually a web address. By ticking the 'Imported' tickbox Prot eg e-OWL\nwill attempt to find the ontology at the location that is specified by the namespace URI (URL). This\nsounds great, but what if there is no internet connection available, or the ontology doesn't actually exist\nat the namespace URI? Fortunately, it is possible to specify an alternative URI (URL), which can point\nto a 'local' copy of the ontology -- for example a URL that points to a location on the hard disk, or\nserver on the local area network. Alternative locations are specified in the ontology policy file, which is\nlocated in the Prot eg e-OWL plugin folder. This file does not need to be edited by hand - it can be edited\nusing the ontology policy dialog.\n\nExercise 57: Specifing an alternative location for an imported ontology\n1. Select the ontology concerned in the 'Namespaces Prefixes' widget.\n2. Press the 'Add to ont-policy file' button that is located on the 'Namespaces\nPrefixes' widget shown in Figure 7.1. This will open the ontology policy file dialog\nshown in Figure 7.2.\n3. As can be seen from 7.2 the koala ontology will have been added to the import policy\n(last line). To specify an alternative URI double click on the Alternative URI box\non the koala ontology row - any valid URI may be entered. Press 'OK' to close the\ndialog.\nThe alternative URIs\nThe (namespace) URIs of\nThese URIs could point to\nontologies that are in the\nfiles on the local hard disk etc.\nontology policy file.\nFigure 7.2: The Ontology Policy File Dialog\nfor an imported ontology follow these steps:\nTo specify an alternative location\n7.2.5\nImporting The Dublin Core Ontology\nThe Dublin Core ontology is based on the Dublin Core Meta Data Terms.\nThe Dublin Core Meta\nData Terms were standardised/developed by The Dublin Core Meta Data Initiative3 . They are a set of\n3http://www.dublincore.org/\n\nelements/terms that can be used to describe resources -- in our case, we can use these terms to describe\nthe 'resources' such as classes, properties and individuals in an ontology. The full set of Dublin Core\nMeta Data Terms is described at http://www.dublincore.org/documents/dcmi-terms/, the following\nlist contains a few examples:\n- title -- Typically, a Title will be a name by which the resource is formally known.\n- creator -- Examples of a Creator include a person, an organisation, or a service. Typically, the\nname of a Creator should be used to indicate the entity.\n- subject -- Typically, a Subject will be expressed as keywords, key phrases or classification codes\nthat describe a topic of the resource.\nRecommended best practice is to select a value from a\ncontrolled vocabulary or formal classification scheme.\n- description -- Description may include but is not limited to: an abstract, table of contents,\nreference to a graphical representation of content or a free-text account of the content.\n- contributor -- Examples of a Contributor include a person, an organisation, or a service. Typi\ncally, the name of a Contributor should be used to indicate the entity.\nIn order to annotate classes and other ontology entities with the above information and other Dublin\nCore Meta Data Terms the Dublin Core Meta Data ontology (DC Ontology) must be imported. Because\nDublin Core Meta Data is so frequently used Prot eg e-OWL has an automated mechanism for importing\nthe Dublin Core Meta Data ontology. The ontology can be imported in following manner:\nExercise 58: Import the Dublin Core Meta Data Elements Ontology\n1. From the 'OWL Menu' select 'Dublin Core metadata...'.\n2. A dialog box will appear. Tick the tickbox on the dialog to import the ontology.\n3. A message will be displayed saying that Prot eg e-OWL needs to reload the ontology.\nPress the 'Yes' button.\n4. After a few seconds the Dublin Core Meta Data ontology will have been imported.\nClose the 'Dublin Core metadata' dialog with the 'Close' button.\n5. Switch to the 'Properties' tab. As shown in Figure 7.3, a number of annotation\nproperties (representing the Dublin Core Meta Data Terms) will have been imported.\nThese annotation properties may be used in the standard way (described in section\n6.4).\n7.2.6\nThe Prot eg e-OWL Meta Data Ontology\nSeveral features used by the Prot eg e-OWL plugin (such as marking classes so that any primitive subclasses\nare automatically made disjoint) rely on the use of various Prot eg e-OWL annotation properties. These\nannotation properties are contained in the Prot eg e-OWL Meta Data Ontology, which is located in the\n\nFigure 7.3: Imported Dublin Core Elements Available As Annotation Properties\n\nProt eg e-OWL plugin folder. In order for these annotation properties to be used, the Prot eg e-OWL Meta\nData Ontology must be imported in the following manner:\nExercise 59: Import the Prot e-OWL Meta Data Ontology\neg\n1. Select the 'Preferences...' item from the 'OWL Menu' to display the preferences\ndialog shown in Figure 4.41 on page 52.\n2. Tick the 'Import protege metadata ontology' tickbox. You will be presented with\na 'Confirm Reload' dialog box asking you to reload the ontology for the changes to\ntake effect. Press the 'Yes' button.\n7.3\nOntology Tests\nProt eg e-OWL provides a test framework, which contains various tests that may be run on the ontology\nbeing edited.\nThese tests range from sanity tests such as checking that a property's characteristics\ncorrespond correctly with its inverse property's characteristics, to OWL-DL tests, which are designed to\nfind constructs such as metaclasses that put an ontology into OWL-Full. The test framework is based\nupon a plugin architecture that enables new tests to be added by third party programmers - check the\nProt eg e-OWL website for the availability of addon tests.\nThe various tests may be configured via the 'Test Settings' dialog shown in Figure 7.4, which is accessible\nvia the 'Test Settings...' item on the 'OWL Menu'. To run the tests the 'Run Ontology Tests...'\nitem should be selected from the 'OWL Menu', or the 'Run Ontology Tests...' button should be\npressed on the OWL Toolbar.\nAfter the ontology test have been run the results are displayed in a popup pane at the bottom of the\nscreen as shown in Figure 7.5. The test results pane has the following columns:\n- Type -- The type of test result (a warning, and error etc.).\n- Source -- The source of the test result (e.g. a class or property). Double clicking on the source\nwill automatically navigate to the source, by automatically selecting a class on the 'OWLClasses'\ntab, or a property on the 'Properties' tab for example.\n- Test Result -- A message that describes the result obtained.\nIn some cases Prot eg e-OWL is able to modify/correct aspects of the ontology that the tests have found\nto be at fault. In these cases, when the test is selected the small 'spanner' button on the left hand side\nof the test results pane will be enabled. Clicking this button will repair the ontology fault that gave rise\nto the test result.\n7.4\nTODO List\nProt eg e-OWL features a simple but useful TODO List mechanism. Classes, properties and the ontology\nitself can be annotated with TODO items. These can be attached to classes, properties and the ontology\n\nFigure 7.4: The Ontology Test Settings Dialog\nFigure 7.5: Ontology TestResults\n\nby using the 'Add TODO List Item' button that is located on the 'Annotation Widgets'. Pressing\nthe 'Add TODO List Item' creates a new annotation property that may be filled in with a textual\ndescription of the TODO task. To locate TODO items the 'Show TODO List...' item should be\nselected from the 'OWL Menu' or the 'Show TODO List...' button pressed on the OWL Toolbar.\nThis will display a list of TODO items in a popup pane at the bottom of the screen. Double clicking on\neach TODO item in this list will cause Prot eg e-OWL to automatically navigate to the TODO item in\nthe ontology.\n\nAppendix A\nRestriction Types\nThis appendix contains further information about the types of property restrictions in OWL. It is intended\nfor readers who aren't too familiar with the notions of logic that OWL is based upon.\nAll types of restrictions describe an unnamed set that could contain some individuals. This set can be\nthought of as an anonymous class. Any individuals that are members of this anonymous class satisfy the\nrestriction that describes the class (Figure A.1). Restrictions describe the constraints on relationships\nthat the individuals participate in for a given property.\nWhen we describe a named class using restrictions, what we are effectively doing is describing anonymous\nsuperclasses of the named class.\nA.1\nQuantifier Restrictions\nQuantifier restrictions consist of three parts:\n1. A quantifier, which is either the existential quantifier (∃), or the universal quantifier (∀).\n2. A property, along which the restriction acts.\n3. A filler that is a class description.\nFor a given individual, the quantifier effectively puts constraints on the relationships that the individual\nparticipates in. It does this by either specifying that at least one kind of relationship must exist, or by\nspecifying the only kinds of relationships that can exist (if they exist).\nA set of individuals that satisfy\na restriction - the restriction essentially\ndescribes an anonymous (unnamed) class\nthat contains these individuals.\nFigure A.1: Restrictions Describe Anonymous Classes Of Individuals\n\npr\nop\npro\np\npro\np\npro\np\nClass A\nAnonymous class\nprop\npro\np\np\nr\no\np\np\nro\np\nFigure A.2: A Schematic Of An Existential Restriction (∃ prop ClassA)\nA.1.1\nsomeValuesFrom - Existential Restrictions\nExistential restrictions, also known as 'someValuesFrom' restrictions, or 'some' restrictions are denoted\nusing ∃ - a backwards facing E. Existential restrictions describe the set of individuals that have at\nleast one specific kind of relationship to individuals that are members of a specific class. Figure A.2\nshows an abstracted schematic view of an existential restriction, ∃ prop ClassA - i.e. a restriction along\nthe property prop with a filler of ClassA. Notice that all the individuals in the anonymous class that\nthe restriction defines have at least one relationship along the property prop to an individual that is\na member of the class ClassA. The dashed lines in Figure A.2 represent the fact that the individuals\nmay have other prop relationships with other individuals that are not members of the class ClassA even\nthough this has not been explicitly stated -- The existential restriction does not constrain the prop\nrelationship to members of the class ClassA, it just states that every individual must have at least one\nprop relationship with a member of ClassA -- this is the open world assumption (OWA).\nFor a more concrete example, the existential restriction, ∃ hasTopping MozzarellaTopping, describes the\nset of individuals that take place in at least one hasTopping relationship with an other individual that\nis a member of the class MozzarellaTopping -- in more natural English this restriction could be viewed\nas describing the things that 'have a Mozzarella topping'. The fact that we are using an existential\nrestriction to describe the group of individuals that have at least one relationship along the hasTopping\nproperty with an individual that is a member of the class MozzarellaTopping does not mean that these\nindividuals only have a relationship along the hasTopping property with an individual that is a member\nof the class MozzarellaTopping (there could be other hasTopping relationships that just haven't been\nexplicity specified).\nA.1.2\nallValuesFrom - Universal Restrictions\nUniversal restrictions are also known as 'allValuesFrom' restrictions, or 'All' restrictions since they con\nstrain the filler for a given property to a specific class. Universal restrictions are given the symbol ∀ -\ni.e. an upside down A. Universal restrictions describe the set of individuals that, for a given property,\nonly have relationships to other individuals that are members of a specific class. A feature of universal\nrestrictions, is that for the given property, the set of individuals that the restriction describes will also\ncontain the individuals that do not have any relationship along this property to any other individuals. A\nuniversal restriction along the property prop with a filler of ClassA is depicted in Figure A.3. Once again,\nan important point to note is that universal restrictions do not 'guarentee' the existence of a relationship\nfor a given property. They merely state that if such a relationship for the given property exists, then it\nmust be with an individual that is a member of a specified class.\n\npr\nop\npro\np\npro\np\nClass A\nprop\nAnonymous class\nFigure A.3: A Schematic View Of The Universal Restriction, ∀ prop ClassA\nLet's take a look at an example of a universal restriction. The restriction, ∀ hasTopping TomatoTopping\ndescribes the anonymous class of individuals that only have hasTopping relationships to individuals\nthat are members of the class TomatoTopping, OR, individuals that definitely do not participate in any\nhasTopping relationships at all.\nA.1.3\nCombining Existential And Universal Restrictions in Class Descrip\ntions\nA common 'pattern' is to combine existential and universal restrictions in class definitions for a given\nproperty. For example the following two restrictions might be used together, ∃ hasTopping Mozzarel\nlaTopping, and also, ∀ hasTopping MozzarellaTopping. This describes the set of individuals that have at\nleast one hasTopping relationship to an individual from the class MozzarellaTopping, and only hasTop\nping relationships to individuals from the class MozzarellaTopping.\nIt is worth noting that is particularly unusual (and probably an error), if when describing a class, a\nuniversal restriction along a given property is used without using a 'corresponding' existential restriction\nalong the same property. In the above example, if we had only used the universal restriction ∀hasTopping\nMozzarella, then we would have described the set of individuals that only participate in the hasTopping\nrelationship with members of the class Mozzarella, and also those individuals that do not participate in\nany hasTopping relationships - probably a mistake.\nA.2\nhasValue Restrictions\nA hasValue restriction, denoted by the symbol 3, describes an anonymous class of individuals that are\nrelated to another specific individual along a specified property. Contrast this with a quantifier restric\ntion where the individuals that are described by the quantifier restriction are related to any indvidual\nfrom a specified class along a specified property. Figure A.4 shows a schematic view of the hasValue\nrestriction prop 3 abc. This restriction describes the anonymous class of individuals that have at least\none relationship along the prop property to the specific individual abc. The dashed lines in Figure A.4\nrepresent the fact that for a given individual the hasValue restriction does not constrain the property\nused in the restriction to a relationship with the individual used in the restriction i.e. there could be\nother relationships along the prop property. It should be noted that hasValue restrictions are semanti\ncally equivalent to an existential restriction along the same property as the hasValue restriction, which\nhas a filler that is an enumerated class that contains the individual (and only the individual) used in the\nhasValue restriction.\n\nAnonymous class\npro\np\np\nr\no\np\np\nro\np\npr\nop\npro\np\nprop\nprop\np\nr\no\np\nabc\nFigure A.4: A Schematic View Of The hasValue Restriction, prop 3 abc -- dashed lines indicate that this\ntype of restriction does not constrain the property used in the hasValue restriction solely to the\nindividual used in the hasValue restriction\nA.3\nCardinality Restrictions\nCardinality restrictions are used to talk about the number of relationships that an individual may partici\npate in for a given property. Cardinality restrictions are conceptually easier to understand than quantifier\nrestrictions, and come in three flavours: Minumum cardinality restrictions, Maximum cardinality restric\ntions, and Cardinality restrictions.\nA.3.1\nMinimum Cardinality Restrictions\nMinimum cardinality restrictions specify the minimum number of relationships that an individual must\nparticipate in for a given property. The symbol for a minimum cardinality restriction is the 'greater than\nor equal to' symbol (≥). For example the minimum cardinality restriction, ≥ hasTopping 3, describes the\nindividuals (an anonymous class containing the individuals) that participate in at least three hasTopping\nrelationships. Minimum cardinality restrictions place no maximum limit on the number of relationships\nthat an individual can participate in for a given property.\nA.3.2\nMaximum Cardinality Restrictions\nMaximum cardinality restrictions specify the maximum number of relationships that an individual can\nparticipate in for a given property. The symbol for maximum cardinality restrictions is the 'less than\nor equal to' symbol (≤). For example the maximum cardinality restriction, ≤ hasTopping 2, describes\nthe class of individuals that participate in at most two hasTopping relationships. Note that maximum\ncardinality restrictions place no minimum limit on the number of relationships that an individual must\nparticipate in for a specific property.\n\nA.3.3\nCardinality Restrictions\nCardinality restrictions specify the exact number of relationships that an individual must participate in\nfor a given property. The symbol for a cardinality restrictions is the 'equals' symbol (=). For example,\nthe cardinality restriction, = hasTopping 5, describes the set of individuals (the anonymous class of\nindividuals) that participate in exactly five hasTopping relationships. Note that a cardinality restriction\nis really a syntactic short hand for using a combination of a minimum cardinality restriction and a\nmaximum cardinality restriction. For example the above cardinality restriction could be represented by\nusing the intersection of the two restrictions: ≤ hasTopping 5, and, ≥ hasTopping 5.\nA.3.4\nThe Unique Name Assumption And Cardinality Restrictions\nOWL does not use the Unique Name Assumption (UNA)1. This means that different names may refer to\nthe same individual, for example, the names \"Matt\" and \"Matthew\" may refer to the same individual (or\nthey may not). Cardinality restrictions rely on 'counting' distinct individuals, therefore it is important\nto specify that either \"Matt\" and \"Matthew\" are the same individual, or that they are different individ\nuals. Suppose that an individual \"Nick\" is related to the individuals \"Matt\", \"Matthew\" and \"Matthew\nHorridge\", via the worksWith property. Imagine that it has also been stated that the individual \"Nick\" is\na member of the class of individuals that work with at the most two other individuals (people). Because\nOWL does not use the Unique Name Assumption, rather than being viewed as an error, it will be inferred\nthat two of the names refer to the same individual2 .\n1Confusingly, some reasoners (such as RACER) do use the Unique Name Assumstion!\n2If \"Matt\", \"Matthew\" and \"Matthew Horridge\" have been asserted to be different individuals, then this will make the\nknowledge base inconsistent.\n\nAppendix B\nComplex Class Descriptions\nAn OWL class is specified in terms of its superclasses. These superclasses are typically named classes\nand restrictions that are in fact anonymous classes. Superclasses may also take the form of 'complex\ndescriptions'.\nThese complex descriptions can be built up using simpler class descriptions that are\ncemented together using logical operators. In particular:\n- AND (u) -- a class formed by using the AND operator is known as an intersection class. The class\nis the intersection of the individual classes.\n- OR (⊔) -- A class formed by using the OR operator is known as a union class. The class formed\nis the union of the individual classes.\nB.1\nIntersection Classes (u)\nAn intersection class is described by combining two or more classes using the AND operator (u). For\nexample, consider the intersection of Human and Male -- depicted in Figure B.1. This describes an\nanonymous class that contains the individuals that are members of the class Human and the class Male.\nThe semantics of an intersection class mean that the anonymous class that is described is a subclass of\nHuman and a subclass of Male.\nThe anonymous intersection class above can be used in another class description. For example, suppose\nwe wanted to build a description of the class Man. We might specify that Man is a subclass of the\nanonymous class described by the intersection of Human and Male. In other words, Man is a subclass of\nHuman and Male.\nB.2\nUnion Classes (⊔)\nA union class is created by combining two or more classes using the OR operator (⊔). For example,\nconsider the union of Man and 'Woman' -- depicted in Figure B.2. This describes an anonymous class\nthat contains the individuals that belong to either the class Man or the class Woman (or both).\n\nMale\nHuman\nIntersection of Human and Male\nFigure B.1: The intersection of Human and Male (Human u Male) -- The shaded area represents the intersection\nMan\nWoman\nFigure B.2: The union of Man and Woman (Man ⊔ Woman) -- The shaded area represents the union\nThe anonymous class that is described can be used in another class description. For example, the class\nPerson might be equivalent of the union of Man and Woman."
    },
    {
      "category": "Resource",
      "title": "AlzPharm: Integration of Neurodegeneration Data using RDF",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/cf29d1944802c2f95a66ee61e8b582b4_lam_bmc.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n<supplement> <title> <p>Semantic E-Science in Biomedicine</p> </title> <editor>Yimin Wang, Zhaohui Wu, Huajun Chen</editor> <note>Research</note> </supplement>\nBioMed Central\nBMC Bioinformatics\nResearch\nOpen Access\nAlzPharm: integration of neurodegeneration data using RDF\nHugo YK Lam1, Luis Marenco2,3, Tim Clark8,9, Yong Gao9, June Kinoshita10,\nGordon Shepherd4, Perry Miller2,3,5, Elizabeth Wu10, Gwendolyn T Wong10,\nNian Liu2,3, Chiquito Crasto2,4, Thomas Morse4, Susie Stephens11 and Kei-\nHoi Cheung*2,3,6,7\nAddress: 1Interdepartmental Program in Computational Biology and Bioinformatics, Yale University, New Haven, CT, USA, 2Center for Medical\nInformatics, Yale University, New Haven, CT, USA, 3Department of Anesthesiology, Yale University, New Haven, CT, USA, 4Department of\nNeurobiology, Yale University, New Haven, CT, USA, 5Department of Molecular, Cellular and Developmental Biology, Yale University, New\nHaven, CT, USA, 6Department of Genetics, Yale University, New Haven, CT, USA, 7Department of Computer Science, Yale University, New Haven,\nCT, USA, 8Initiative in Innovative Computing, Harvard University, Cambridge, MA, USA, 9Massachusetts General Hospital, Boston, MA, USA,\n10Alzheimer Research Forum and 11Oracle, Burlington, MA, USA\nEmail: Hugo YK Lam - Hugo.YK.Lam@yale.edu; Luis Marenco - Luis.Marenco@yale.edu; Tim Clark - Tim_Clark@harvard.edu;\nYong Gao - YGao@partners.org; June Kinoshita - JuneKino@alzforum.org; Gordon Shepherd - Gordon.Shepherd@yale.edu;\nPerry Miller - Perry.Miller@yale.edu; Elizabeth Wu - Ewu@alzforum.org; Gwendolyn T Wong - Wonglabow@verizon.net;\nNian Liu - Nian.Liu@yale.edu; Chiquito Crasto - Chiquito.Crasto@yale.edu; Thomas Morse - Tom.Morse@yale.edu;\nSusie Stephens - Susie.Stephens@gmail.com; Kei-Hoi Cheung* - Kei.Cheung@yale.edu\n* Corresponding author\nPublished: 9 May 2007\nBMC Bioinformatics 2007, 8(Suppl 3):S4\ndoi:10.1186/1471-2105-8-S3-S4\nThis article is available from: http://www.biomedcentral.com/1471-2105/8/S3/S4\n(c) 2007 Lam et al; licensee BioMed Central Ltd.\nThis is an open access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0),\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nAbstract\nBackground: Neuroscientists often need to access a wide range of data sets distributed over the Internet. These data\nsets, however, are typically neither integrated nor interoperable, resulting in a barrier to answering complex\nneuroscience research questions. Domain ontologies can enable the querying heterogeneous data sets, but they are not\nsufficient for neuroscience since the data of interest commonly span multiple research domains. To this end, e-\nNeuroscience seeks to provide an integrated platform for neuroscientists to discover new knowledge through seamless\nintegration of the very diverse types of neuroscience data. Here we present a Semantic Web approach to building this\ne-Neuroscience framework by using the Resource Description Framework (RDF) and its vocabulary description\nlanguage, RDF Schema (RDFS), as a standard data model to facilitate both representation and integration of the data.\nResults: We have constructed a pilot ontology for BrainPharm (a subset of SenseLab) using RDFS and then converted\na subset of the BrainPharm data into RDF according to the ontological structure. We have also integrated the converted\nBrainPharm data with existing RDF hypothesis and publication data from a pilot version of SWAN (Semantic Web\nApplications in Neuromedicine). Our implementation uses the RDF Data Model in Oracle Database 10g release 2 for\ndata integration, query, and inference, while our Web interface allows users to query the data and retrieve the results\nin a convenient fashion.\nConclusion: Accessing and integrating biomedical data which cuts across multiple disciplines will be increasingly\nindispensable and beneficial to neuroscience researchers. The Semantic Web approach we undertook has demonstrated\na promising way to semantically integrate data sets created independently. It also shows how advanced queries and\ninferences can be performed over the integrated data, which are hard to achieve using traditional data integration\napproaches. Our pilot results suggest that our Semantic Web approach is suitable for realizing e-Neuroscience and\ngeneric enough to be applied in other biomedical fields.\nPage 1 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nBackground\ne-Science involves developing tools, technologies, and\ninfrastructure to support multidisciplinary and collabora\ntive science enabled by the Internet [1]. One of the chal\nlenges that e-Science aims to address is data integration. e-\nNeuroscience [2], otherwise known as neuroinformatics,\nshares the same vision as e-Science but focuses on the neu\nrosciences. It is also encompassed by the informatics-ori\nented goal of the Human Brain Project, which emphasizes\nthe importance of integrating heterogeneous neuro\nscience-related information from the molecular level to\nthe behavioral level [3]. Integrating neuroscience data,\nincluding sequence data, molecular data, disease data and\nbehavioral data, will be a significant step towards better\nunderstanding brain function [4].\nBy combining the experimental results produced by\nmulti-disciplinary groups, one can allow a more thorough\ninvestigation and understanding of complex neuroscience\nresearch problems, including the study of neurodegenera\ntive diseases such as Alzheimer's Disease (AD) and Parkin\nson's Disease (PD) [2]. Below, we discuss some of the\nchallenges involved in integrating rapidly growing hetero\ngeneous and distributed neuroscience data.\n1. Registry. A large number of neuroscience resources\nhave been developed independently to address various\nresearch needs. While search engines (e.g., Google) can\nhelp users locate neuroscience resources of interest, such\nkeyword based search approaches suffers from the prob\nlem of specificity and sensitivity. For example, if a search\nis performed using the keyword \"neuron\", a large number\nof hits will be returned. To address this problem, central\nregistries of neuroscience resources have been created to\ncategorize and keep track of existing neuroscience data\nsets. These registries provide search interfaces for users to\nfind data of potential interest. The Neuroscience Database\nGateway (NDG) [5] is one such example. NDG was\nlaunched in 2004 as a pilot project sponsored by the Soci\nety for Neuroscience, with an exclusive focus on categoriz\ning neuroscience resources. It employs a set of standard\nterms (e.g., name, description, URL, and species) for\ndescribing each resource (e.g., a database or a software\ntool). As the number of neuroscience resources continues\nto grow, such a centralized approach to registering\nresources may not be easily maintainable (it is difficult for\na single person or a single group to keep track of such a\nrapidly growing collection of resources). A better and\nmore efficient framework that allows registration and dis\ncovery of this kind of distributed resource will be neces\nsary.\n2. Interface. Within NDG each of the different data\nsources has its own data format and interface. For exam\nple, Cell-Centered Database (CCDB) [6] (cellular imaging\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\ndata) provides a free text search interface; SenseLab [7]\n(integration of multidisciplinary sensory data) has a struc\ntured form search interface; and CoCoDat [5] (cortical cell\nand micro-circuitry data) is available for download as a\nMicrosoft Access database. Examples of the differing Web\ninterfaces are shown in Figure 1. Although each of these\ndata sources contains different types of data, they refer to\ncommon bio-entities. Such heterogeneity in data format\nand user interface makes data interoperability and data\nanalysis difficult, yet currently the only way to integrate\nthe data is to do it manually. A standardized and machine-\nunderstandable data format with an open and unified\ndata access model is crucial to building a data integration\nframework for e-Neuroscience.\n3. Nomenclature. One of the difficulties in enabling neu\nroscience data sources to be broadly sharable is a lack of\nstandard nomenclature. For example, different terms (e.g.,\nNeural Arch and Vertebral Arch) may be used to describe\nthe same neuro-anatomical region (e.g., part of the spinal\ncord). Ambiguity also arises when the same term is asso\nciated with multiple meanings (e.g., spine could mean\nvertebral spine or dendritic spine). It would be highly\nadvantageous if there were an e-Neuroscience framework\nthat could better reconcile the ambiguities.\n4. Granularity. Different neuroscience data sources may\nmodel the same type of data at different levels of granular\nity. For example, CCDB uses a single \"dendrite\" compart\nment for all data associated with dendrites, whereas\nNeuronDB (a subdatabase of SenseLab) subdivides den\ndrites into types (e.g., apical and basal) and compart\nments (e.g., proximal, medial, and distal). As a result, data\nwithin NeuronDB can be associated with specific den\ndritic compartments, which is not possible in CCDB. An\nideal data framework would be able to model data at dif\nfering levels of granularity.\nSemantic Web approach to representing and integrating\ndata\nThe primary goal of the Semantic Web is to expose the\nsemantics of Web-accessible data using a machine-reada\nble knowledge representation format so that data can be\nmore easily interpreted and integrated by computer pro\ngrams (or Web agents). As a result, the Semantic Web con\nsists of components that aim to fulfill the requirements in\nthis realm. The fundamental components of the Semantic\nWeb include the following: knowledge representation,\nontological languages, and Semantic-Web-aware tools.\nKnowledge representation\nKnowledge representation comes in different forms that\nexhibit different levels of complexity. A controlled vocab\nulary is a knowledge base that holds definitions of terms.\nA thesaurus is a more expressive knowledge base that, in\nPage 2 of 12\n(page number not for citation purposes)\n\nExamples of three neuroscience database Web interfaces\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nFigure 1\nExamples of three neuroscience database Web interfaces. The Web interfaces of CocoDat, NeuronDB, and the Cell\nCentered Database.\naddition, holds assertions regarding the semantic rela\ntionships between the terms. An ontology is a specifica\ntion of a representational vocabulary for a shared domain\nof discourse [8]. It captures domain concepts and their\nrelations and properties. Ontologies can be categorized\ninto upper level ontology (contains common and generic\nknowledge that can be shared across different domains),\nmiddle level ontology (contains focused domain span\nning knowledge), and domain level ontology (contains\ndomain-specific knowledge) [9]. With the application of\nthe Semantic Web, controlled vocabularies, thesauri, and\nontologies are exposed to processing by Web-aware\nagents, as well as to human access and interpretation. This\nfacilitates extensible knowledge representation and\nsemantic interoperability, and critically deepens our abil\nity to treat the Web as a true knowledge base.\nRecognizing the increasing need for using expressive bio\nontologies to facilitate machine-based data integration\nand inference, community efforts have begun to build\nontologies for use by computer applications deployed in\ndifferent domains of biosciences. Examples include the\nGene Ontology [10] (a controlled vocabulary describing\ngene and gene product attributes), Plant Ontology [11] (a\ncontrolled vocabulary describing plant structures, growth,\nand developmental stages), and Unified Medical Lan\nguage System [12] (a vocabulary database about biomed\nical and health related concepts). In response to the\ngrowing number of bio-ontologies, the National Center\nfor Biomedical Ontologies (NCBO) [13] was established\nto enable researchers to find, create, disseminate, and\nmanage biomedical information and knowledge in a\nmachine-processable form. The Center's resources include\nthe Open Biomedical Ontologies library [14], the Open\nBiomedical Data (OBD) repositories, and tools for access\ning and using these biomedical ontologies and their asso\nciated data in research. Many of the ontologies hosted by\nthe NCBO can be cross-referenced or inter-linked to facil-\nPage 3 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nitate\nmore\ncomprehensive\nknowledge\nacquisition,\nalthough much research is still in progress to help deter\nmine equivalence across ontologies, and to further\nexplore automating the labor intensive mapping process.\nThere are also ongoing efforts to create upper level ontol\nogies for disparate domains. This kind of ontology focuses\non providing a set of general concepts upon which\ndomain-specific ontologies (e.g., microarrays, proteom\nics, and pathways) could be constructed. Examples in the\nbiological domain include the Functional Genomics\nInvestigation Ontology (FuGO) [15], and Ontology of\nEXPeriment (EXPO) [16].\nIn research investigations that commonly span domains,\nsuch as neuroscience, providing the ability to construct\nupper ontologies and bridge ontologies is critical to inter-\noperability.\nSemantic Web languages\nTo enable computers to process, understand, and infer\nence over an ontology, it is necessary to have a computer\nlanguage, or what we call an ontological language, to for\nmalize an ontology in a way that it can be reasoned over\nby software automatically. It is also essential to have a\ncommon format that can facilitate the interchange of data.\nTo this end, the W3C has recommended two standards for\nbuilding an ontology in the Semantic Web - Resource\nDescription Framework (RDF) [17] and Web Ontology\nLanguage (OWL) [18].\nRDF models concepts and their instances in a format\ncalled a triple. A triple is an RDF statement which contains\na subject, a predicate and an object about a resource where\nthe subject is the resource itself, the predicate is the rela\ntionship between the resource and the object, and the\nobject can be another resource or a data value. RDF in fact\ncan be specified in different syntax formats, although the\nmost commonly used format is the RDF/XML, which\nemploys the eXtensible Markup Language (XML) to struc\nture its representation of resources. Descriptions of the\nconcepts and their relations (e.g., subclass/superclass) are\nspecified separately in a specialized RDF format called\nRDF Schema (RDFS) [19]. The following example illus\ntrates an RDF statement:\n<http://en.wikipedia.org/wiki/Dopamine#,\nhttp://en.wikipedia.org/wiki/Function#,\nhttp://en.wikipedia.org/wiki/Neurotransmitter#>\nexpressing that Dopamine has the Function of being a Neu\nrotransmitter. Each component of the triple is identified\nusing a Uniform Resource Identifier (URI) [20]. When\nresources have the same URI they are assumed to be the\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nsame entity, and any data about the entity can be merged.\nAs triple statements become connected together, they\nform a directed labeled graph.\nOWL extends RDF by adding more vocabulary to describe\nthe relations such as cardinality and equality among\nclasses and properties. Advanced knowledge representa\ntion includes making assertions or claims about explicit\nobjects (e.g., \"acetylcholinesterase is an enzyme\"). Repre\nsenting knowledge in such an explicit form in OWL is\nbased on Description Logics, which enables computers to\ndraw new conclusions from existing knowledge. Insights\nfrom the Description Logics research community have\nhad a strong influence on the design of OWL, particularly\non the formalization of the semantics, the choice of lan\nguage constructors, and the integration of data types and\ndata values [21].\nWe have chosen to use RDFS for knowledge representa\ntion in the initial stages of this project, as it is well devel\noped, widely used, and expressive enough for our case.\nSemantic Web-aware tools\nOntologies (written in RDFS or OWL) are the key compo\nnents of the Semantic Web. Without suitable tools for\ndeveloping, processing, storeing, and inferencing over the\ndata, it would not be possible to infer new knowledge\ncould hardly be inferred. Consequently, a large number of\nopen source and commercial Semantic Web tools have\nbeen developed. They are:\n1. Ontology editors and visualization tools. These tools\nallow users to develop, edit, and visualize ontologies and\ntheir associated data. Examples include Protege [22],\nWebOnto [23], and GrOWL [24]. There are also advanced\nontology editors that allow alignment and integration of\nmultiple ontologies (e.g., COBrA [25]).\n2. Parsers. To enable the development of computer appli\ncations that utilize and process ontologies, RDF and OWL\nparsers have been made available for most popular pro\ngramming languages. For example, PerlRDF is one of the\nRDF parsers written in Perl [26]. Jena is a framework for\nbuilding Semantic Web applications and for parsing RDF,\nRDFS and OWL in the Java programming environment\n[27].\n3. Database and querying tools. To provide persistence,\nmanagement and querying capabilities for RDF/OWL,\nseveral RDF database systems have been implemented.\nAmong them, Sesame (a.k.a OpenRDF) [28] and Kowari\n[29] are open-source RDF database systems while the Ora\ncle RDF Data Model [30] is a feature of the Oracle Data\nbase and therefore a commercial offering. Some of these\ndatabase systems (e.g., Sesame) implement their RDF\nPage 4 of 12\n(page number not for citation purposes)\n\nPartial BrainPharm data\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nquery languages in compliance with the SPARQL standard\nspecifications [31]. Besides, tools such as D2RQ [32] are\nalso available for mapping relational schema to OWL/\nRDFS ontologies.\n4. Reasoners. To support reasoning based on Description\nLogics specified in OWL, a number of reasoners have been\ndeveloped including Racer [33], FaCT [34], and Pellet\n[35].\nResults\nAs described in the Methods section, we hand-crafted an\nontology for BrainPharm using RDFS. We then instanti\nated the ontology with some pilot data, which our neuro\nscientists extracted from a subset of the BrainPharm data.\nFigure 2 shows a portion of the pilot data set (pathological\nmechanisms) in tabular format. The first four columns\ncontain information about different types of neurons\nincluding their neuronal properties, such as receptors and\nchannels localized to different neuronal compartments.\nThe remaining columns capture information about (i) the\npathological changes caused by certain pathological\nagents (e.g., beta Amyloid) to the neuronal properties\n(e.g., beta Amyloid inhibits the I Calcium channel of CA1\npyramidal neuron), (ii) the drugs and their actions on the\npathological changes (e.g., Nifedipine reduces the patho\nlogical effect of beta Amlyloid on the molecular properties\nof CA1 pyramidal neuron), (iii) stages of the disease (e.g.,\nearly, middle, and late stages), and (iv) literature sources\n(e.g., PubMed sources).\nWe loaded a subset of BrainPharm in RDF, and a subset of\nSWAN in RDF, into the ORACLE RDF Data Model. We\nthen created inference rules based upon the RDFs. In our\npilot use case, we loaded: (i) the BrainPharm drug-related\ndata including the drug property and drug action informa\ntion related to the pathological mechanisms underlying\nAD, and (ii) the SWAN data including publication,\nhypothesis, and annotation information [36]. This\napproach is potentially easier to manage and adapt than\nintegrating many data sets using a relational model, as no\nschema has to be pre-defined for our RDF models.\nAs a demonstration, we developed a Web-based applica\ntion called \"AlzPharm\" [37] which allows users to relate\nthe drug information from BrainPharm to the publication\ninformation stored in SWAN. Our Web interface uses Java\nserver faces to render different information into different\nUser Interface (UI) components, and the connection to\nthe Oracle database is made available by Java Database\nConnectivity (JDBC).\nFigure 3 shows some of the UI components of our demo\nand depicts a schematic data flow of the information\ntransferring from their original data sources to the Oracle\nRDF Data Models. Figure 3A shows that the data originat\ning from BrainPharm are loaded into our database\nFigure 2\nPartial BrainPharm data. A portion of the pilot data set retrieved from the BrainPharm database.\nPage 5 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S4\ndirectly after RDF conversion, and that the data originat\ning from AlzForum [38] are converted into RDF, made\navailable by SWAN at their website, and then loaded into\nour database. Figure 3B shows the original Web interface\nto the AlzForum data repository, which is not in RDF for\nmat. Figure 3C shows part of the Web query interface that\nwe developed to allow users to query data across both the\nBrainPharm and SWAN datasets.\nAn integrated query\nOur Web interface provides not only information about\nthe individual datasets in our database, but also a simple\ntext field for scientists to enter a drug name for finding the\npublications in SWAN that mention the molecular targets\nof interest. The drug being searched has to exist in the\nBrainPharm dataset, otherwise there will be no result. For\nthis reason, we also provide drug name suggestions, ena\nbled by the Asynchronous JavaScript and XML (AJAX)\ntechnology, to the users based the data in real time. After\nour system receives the search request from the user, it\nexecutes the following SQL query statement and queries\nthe underlying RDF models with the specified drug name:\nSELECT distinct drugname DRUG_NAME, target TARGET,\njournal JOURNAL, title TITLE, pmid PMID\nFROM TABLE(\nSDO_RDF_MATCH(\n'(?drug b:name ?drugname)\n(?drug b:hasMolecularTarget ?target)\n(?mech b:hasPharmacologicalAgent ?drug)\n(?mech b:hasPharmacologicalTarget ?path)\n(?path b:hasPathology ?disease)\n(?disease b:name ?disname)'\n,\nSDO_RDF_Models('brainpharm'),\nSDO_RDF_Rulebases('RDFS'),\nSDO_RDF_Aliases(SDO_RDF_Alias('b','http://\nycmi.med.yale.edu/brainpharm#')),\n'lower(disname) = \"alzheimer\"\"s disease\"'\n)\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\n) bpharm,\nTABLE(\nSDO_RDF_MATCH(\n'(?pub s:title ?title)\n(?pub s:journal ?journal)\n(?pub s:abstract ?abs)\n(?pub s:pmid ?pmid)\n(?pub rdf:type s:Publication)'\n,\nSDO_RDF_Models('swan'),\nSDO_RDF_Rulebases('RDFS'),\nSDO_RDF_Aliases(SDO_RDF_Alias('s','http://purl.org/\nswan/)),\nnull\n)\n) swan\nwhere regexp_like(swan.abs, bpharm.target, 'i') and\nlower(drugname) = lower(?)\nThe query results shown in Figure 3C list the SWAN pub\nlications related to the drug Donepezil (with acetylcho\nlinesterase being the molecular target of the drug), which\nis indication by \"?\" at the end of the query. The user can\nclick on the drug name to get more detailed information\ndirectly from BrainPharm about the effect of the drug on\nsome known pathological mechanism(s) related to AD. In\naddition, users can also click on the AlzForum link under\nthe PMID (PubMed ID) column to go to AlzForum for\nadditional comments that have been given by AD\nresearchers for that publication, as shown in Figure 3B.\nThe results demonstrated how a complex query can be for\nmulated to integrate BrainPharm's drug data and SWAN's\npublication data. In addition, it also demonstrated the use\nof RDF inferencing based on the parent-child (is-a) rela\ntionship between the Publication class (e.g., original arti\ncles retrieved from PubMed) and ARFPublication class\n(e.g., PubMed articles that have been commented by\nresearchers/curators associated with AlzForum) as defined\nin the SWAN RDF Schema and shown below.\nPage 6 of 12\n(page number not for citation purposes)\n\nThe AlzPharm Web application\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nFigure 3\nThe AlzPharm Web application. (A) The data sources of the application. (B) The AlzForum website. (C) The interface of\nthe application.\nPage 7 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S4\n<rdf:Description rdf:about=\"ARFPublication\">\n<rdfs:label>ARFPublication</rdfs:label>\n<rdf:type rdf:resource=\"Class\"/>\n<rdfs:subClassOf rdf:resource=\"Publication\"/>\n</rdf:Description>\nSince our query has specified retrieval of all the related\nPublications (?pub rdf:type s:Publication) from the data-\nset, the Oracle RDF Data Model will identify all the publi\ncations - including the ARF publications, which are\nrelated to AD drugs (e.g., Donepezil) based on the RDFS\nrules that contain their relationship we defined. Although\nthe hierarchical relation here only has two levels, the is-a\ninference could be applied to any number of levels.\nSemantic inferencing is not directly supported by the rela\ntional approach.\nA \"group-by\" query\nAs shown in Figure 3C (bottom), we queried BrainPharm\nto group and count AD drugs based on their molecular\ntargets and clinical usage. The SQL query statement is as\nfollows:\nSELECT\ncount(distinct\nbpharm.drugname)\nNO_OF_DRUGS,\nbpharm.target\nMOLECULAR_TARGET,\nbpharm.disname CLINICAL_USAGE\nFROM TABLE(\nSDO_RDF_MATCH(\n'(?drug b:hasMolecularTarget ?target)\n(?mech b:hasPharmacologicalAgent ?drug)\n(?mech b:hasPharmacologicalTarget ?path)\n(?path b:hasPathology ?disease)\n(?drug b:name ?drugname)\n(?disease b:name ?disname)'\n,\nSDO_RDF_Models('brainpharm'),\nSDO_RDF_Rulebases('RDFS'),\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nSDO_RDF_Aliases(SDO_RDF_Alias('b','http:ontowed.y\nale.edu/AlzPharm/download/brainp harm.rdfs')),\n'lower(disname) = \"alzheimer\"\"s disease\"'\n)\n) bpharm\ngroup by bpharm.target, bpharm.disname\nThe output of this query indicates that there are two\ngroups of drugs available for AD. The first one contains\none drug, which molecular target is acetylcholinesterase.\nThe second group also contains one drug but its molecular\ntarget is calcium ion channel. The query demonstrated\nhow to make use of the \"GROUP BY\" feature (which is\nsupported by standard SQL) to perform aggregation on\nRDF data. Implementations of other RDF query languages\nby other RDF databases do not support aggregate func\ntions such as \"COUNT\", \"SUM\" and \"AVERAGE\" with\n\"GROUP BY\". The Oracle Database has the advantage of\nthe RDF query being embedded within a SQL statement.\nConclusions and future directions\nAs Sir Tim Berners-Lee has reinforced, today most of the\nworld's data are still locked in large data stores and are not\npublished as an open Web of inter-referring resources\n[39]. Areas such as neuroscience, which rely heavily on\nanalyzing a tremendous amount of data of disparate and\ndiverse types, cannot fully leverage the potential of the\navailable knowledge that is captured in this way. There is\nan emerging need for an infrastructure that can facilitate\nthe interchange of such data. In this paper, we have shown\nthe benefits of exposing data in RDF format, which can be\nshared, integrated, and reasoned about. We have also\nshown how to use the Oracle RDF Data Model to create a\nSemantic Web repository for integrating data relating to\nAD from BrainPharm and SWAN. We further demon\nstrated the RDF querying and RDFS inferencing features,\nincluding the support of data aggregation functions\n(based on traditional SQL) and semantic inference rules\n(based on RDFS) provided by the Oracle RDF Data Model,\nwhich can hardly be achieved by traditional data integra\ntion. The Oracle Database's extensions to SQL for query\ning RDF data are particularly powerful - allowing\nrelational data to be queried alongside RDF data. For\nexample, one can formulate a complex nested query that\nretrieves data from both an RDF graph and a relational\ntable and join the query results using a relational join.\nTechnically, our approach can also be adapted to other\nintegration solutions such as data warehousing and query\nmediation.\nPage 8 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nWhile neuroscientists always need to access and integrate\nbiomedical data that span multiple disciplines, integrat\ning neuroscience data using our proposed Semantic Web\napproach appears to be effective, based on our results. We\nbelieve that our approach is the robust candidate for e-\nNeuroscience and could be generalizable to be applied in\nother biomedical fields.\nTo increase the use of Semantic Web in e-Neuroscience,\nwe suggest the following future work:\n1. User-friendly query interface. We will extend the Web-\nbased application to allow users to perform more kinds of\nqueries (e.g., queries that are based on drug properties and\nneuronal properties).\n2. Enhanced integration. To support better integrative\nneuroscience research, we will strengthen the linkage\nbetween BrainPharm and SWAN. While we are in the\nprocess of enhancing the ontological representation of\nBrainPharm and SWAN, more AD-related data are being\nadded to the two databases.\n3. OWL support. Oracle Database 10g release 2 provides\nsupport for storing, querying, and inferencing over RDF\nand RDFS. Currently, it is also possible to store OWL in\nthe Oracle RDF Data Model, but OWL inferencing can\nonly be performed indirectly through application layer\nfunctionality. The next release of the Oracle Database will\nprovide native support for OWL and we plan to take\nadvantage of this capability to better integrating disparate\ndata sources and ensure more advanced inferencing.\n4. Query mediation. The data integration system we dem\nonstrated focuses on building a central repository of data.\nWe are interested in exploring a federated data approach,\nwhere the query is mediated across distributed data\nsources. Efforts in this area are ongoing within the compu\nter science research community (e.g., [40]). Initial work\nhas started within the life science domain, e.g., Stephens\net al. have described a federated database approach for\nquerying drug safety data [41].\n5. Use case. To make Semantic Web technologies useful to\nneuroscience researchers, it is important to drive our\nSemantic Web development by real use cases. While\nSenseLab focuses on data at the molecular and basic\nresearch level, AlzForum focuses on cataloging and docu\nmenting research hypotheses (including clinical trial stud\nies) relating to AD. The potential benefit of integrating\nSenseLab and AlzForum is to support translational\nresearch in AD. We will develop use cases in this transla\ntional research context. For this, we will need to interact\nclosely with domain experts.\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nMethods\nWe used the Oracle RDF Data Model provided by Oracle\nDatabase10 g release 2 to store and semantically integrate\ndata from two independently created neuroscience data\nsources, namely, BrainPharm (a subset of SenseLab [7])\nand SWAN [36]:\nData sources\nBrainPharm\nBrainPharm includes data for support of research on\ndrugs for the treatment of neurological disorders [42]. It\ncontains information about the effect of drugs on patho\nlogical (or molecular) mechanisms (which involve neuro\nnal\nproperties\nsuch\nas\nreceptors,\ncurrents,\nand\nneurotransmitters) mediating the pathological changes in\nvarious neurological disorders such as AD. Figure 4 shows\nthe ontology diagram of BrainPharm, which was created\nmanually using Protege. As shown in the diagram, the\nmain classes include: disease (e.g., AD), drug (subclass of\nagent), pathological mechanism (which contains related\npharmacological and pathological information), patholog\nical change (which has a pathological agent and its effect and\ntargets), neuron (e.g., CA1 pyramidal neuron), and neuron\nproperty (which has the following subclasses: transmitter,\ncurrent, and receptor). There are also non-hierarchical rela\ntionships among these classes. For example, pathological\nmechanism relates to drug through the hasPharmacologica\nlAgent property. The BrainPharm ontology was designed\nand populated based on the input from our neuroscien\ntists.\nSWAN/AlzForum\nSWAN is a project to develop knowledge management\ntools and resources for AD researchers, based on an eco\nsystem model of scientific discourse [43]. The SWAN\nproject is currently developing an OWL ontology for rep\nresenting information about scientists, experiments, pub\nlications, scientific data, bibliographic data, scientific\nontologies, biomedical research collaborations, and sci\nentific Web communities. A beta release of SWAN is now\nunder development, with planned deployment on the\nAlzheimer Research Forum Web site [44] in early to mid\n2007. AlzForum [38] is a widely used scientific Web com\nmunity, which reports on the latest Alzheimer's scientific\nresearch, and develops data sources of genes, scientific\narticles, animal models, antibodies, medications, grants,\nresearch jobs, and more. Prior to employing OWL to\nimplement the Semantic Web, a SWAN pilot version was\nimplemented in 2005-2006 using RDF/S to represent the\ndata (we acquired in this project). Figure 5 shows the\nontology diagram of a portion of the SWAN pilot knowl\nedgebase.\nPage 9 of 12\n(page number not for citation purposes)\n\nThe BrainPharm ontology\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nFigure 4\nThe BrainPharm ontology. A simplified schematic representation of the ontology for the BrainPharm data.\nData conversion and storing\nAs a pilot demonstration, we have integrated the drug-\nrelated information extracted from BrainPharm that is\nrelated to AD with the SWAN hypothesis and publication\ninformation extracted from SWAN/AlzForum. We have\nmanually created the RDFS for BrainPharm as described\nbefore and converted the extracted data into RDF. Since\nthe SWAN data are already available in RDF format, we\nthen loaded both the BrainPharm and SWAN data,\nincluding their corresponding RDFS, into the Oracle RDF\nData Model using its data loader tool, which supports\nloading RDF in N-triple format. As a result, we used Jena\nto simply convert the RDF/XML into N-triple before we\nloaded the data. While SWAN already has its own name-\nspace for URIs, we defined our BrainPharm namespace for\nURIs so that data values referenced by different URI's\ncould be differentiated and joined correctly.\nRDF queries\nWe used the SPARQL-like RDF query syntax required by\nthe Oracle RDF Data Model to query our data in RDF.\nExamples of such kind of queries are illustrated in the\nresults section.\nWeb application\nOur Web application has been implemented using the\nJava Web technology. We have also used AJAX on the Web\npage to perform asynchronous query to the server so as to\nprovide some non-critical information, such as drug name\nsuggestion in the search, in a timely and non-interruptive\nmanner. Moreover, we have used Java Server Faces to\nrender different information, such as drug count and\nsearch result, into different UI components on the inter\nface. Our application has been deployed to a Tomcat Web\nApplication Server 5.5 running on a SUSE Linux machine\nwith four Intel Xeon CPUs at 2.80 GHz and 4 GB memory,\nwhich is where the Oracle Database is also running.\nCompeting interests\nThe authors declare that they have no competing interests.\nPage 10 of 12\n(page number not for citation purposes)\n\nThe SWAN ontology\nBMC Bioinformatics 2007, 8(Suppl 3):S4\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\nFigure 5\nThe SWAN ontology. A simplified schematic representation of the ontology for the SWAN data.\nAuthors' contributions\nHL implemented AlzPharm using the Oracle RDF Data\nModel and built the Web user interface. KC is responsible\nfor the Semantic Web development of SenseLab. GS, PM,\nCC, NL, TM, and KC are members of the SenseLab/Brain-\nPharm team. TC, YG, EW, JK, and GW are members of the\nAlzForum/SWAN team. SS provided technical help on the\nOracle RDF Data Model. All authors have contributed to\nthe final version of the manuscript.\nAcknowledgements\nThis work was supported in part by NIH grants K25 HG02378, P01\nDC04732, T15 LM 07056, P20 LM07253, NSF grant DBI-0135442, and a\ngrant from the Ellison Medical Foundation.\nThis article has been published as part of BMC Bioinformatics Volume 8 Sup\nplement 3, 2007: Semantic e-Science in Biomedicine. The full contents of\nthe supplement are available online at http://www.biomedcentral.com/\n1471-2105/8?issue=S3.\nReferences\n1.\nHey T, Trefethen AE: Cyberinfrastructure for e-Science. Science\n2005, 308(5723):817-21.\nPage 11 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S4\n2.\nMartone ME, Gupta A, Ellisman MH: E-neuroscience: challenges\nand triumphs in integrating distributed data from molecules\nto brains. Nat Neurosci 2004, 7(5):467-472.\n3.\nHuerta MF, Koslow SH, Leshner AI: The Human Brain Project:\nan international resource. Trends Neurosci 1993, 16(11):436-8.\n4.\nKoslow SH: Discovery and integrative neuroscience. Clin EEG\nNeurosci 2005, 36(2):55-63.\n5.\nNeuroscience Database Gateway [http://big.sfn.org/NDG/site/]\n6.\nMartone ME, Zhang S, Gupta A, Qian X, He H, Price DL, Wong M,\nSantini S, Ellisman MH: The cell-centered database: a database\nfor multiscale structural and protein localization data from\nlight and electron microscopy.\nNeuroinformatics 2003,\n1(4):379-96.\n7.\nMarenco L, Tosches N, Crasto C, Shepherd G, Miller PL, Nadkarni\nPM: Achieving Evolvable Web-Database Bioscience Applica\ntions Using the EAV/CR Framework: Recent Advances. J Am\nMed Inform Assoc 2003, 10(5):444-453.\n8.\nGruber T: Ontolingua: a translation approach to providing\nportable ontology specifications. Knowledge Acquisition 1993,\n5(2):199-200.\n9.\nSemy SK, Pulvermacher MK, Obrst LJ: Toward the Use of an\nUpper Ontology for U.S. Government and U.S. Military\nDomains. Mitre technical report: MTR-04B0000063 2004.\n10. Ashburner M, Ball C, Blake J, Botstein D, Butler H, Cherry M, Davis\nA, Dolinski K, Dwight S, Eppig J, et al.: Gene ontology: tool for the\nunification of biology. Nature Genetics 2000, 25:25-29.\n11. Jaiswal P, Avraham S, Ilic K, Kellogg EA, McCouch S, Pujar A, Reiser\nL, Rhee SY, Sachs MM, Schaeffer M, et al.: Plant Ontology (PO): a\ncontrolled vocabulary of plant structures and growth stages.\nComparative and Functional Genomics 2005, 6:388-97.\n12. Cimino J, Sideli R: Using the UMLS to bring the library to the\nbedside. Med Decis Making 1991, 11(4 Suppl):S116-20.\n13. National Center for Biomedical Ontologies [http://www.bio\nontology.org]\n14. Burek P, Hoehndorf R, Loebe F, Visagie J, Herre H, Kelso J: A top-\nlevel ontology of functions and its application in the Open\nBiomedical Ontologies. Bioinformatics 2006, 22(14):e66-e73.\n15. Functional Geneomics Investigation Ontology\n[http://\nfugo.sourceforge.net/]\n16. Ontology of Experiment [http://expo.sourceforge.net/]\n17. Resource Description Framework [http://www.w3.org/RDF/]\n18. Web Ontology Language (OWL) [http://www.w3.org/TR/owl\nfeatures/]\n19. RDF Schema [http://www.w3.org/TR/rdf-schema/]\n20. Uniform Resource Identifier [http://www.w3.org/Addressing/]\n21. Baader F, Calvanese D, McGuinness D, Nardi D, Patel-Schneider P:\nThe Description Logic Handbook Cambridge University Press; 2002.\n22. Protege [http://protege.stanford.edu/]\n23. WebOnto [http://kmi.open.ac.uk/projects/webonto/]\n24. GrOWL\n\n[http://ecoinformatics.uvm.edu/technologies/growl\nknowledge-modeler.html]\n25. Aitken S, Korf R, Webber B, Bard J: COBrA: a bio-ontology edi\ntor. Bioinformatics 2005, 21(6):825-6.\n26. PerlRDF [http://www.gingerall.org/perlrdf.html]\n27. Jena [http://jena.sourceforge.net/]\n28. Sesame [http://www.openrdf.org/]\n29. Kowari [http://kowari.sourceforge.net/]\n30. Oracle RDF Data Model\n[http://www.oracle.com/technology/\ntech/semantic_technologies]\n31. SPARQL [http://www.w3.org/TR/rdf-sparql-query]\n32. D2RQ [http://sites.wiwiss.fu-berlin.de/suhl/bizer/D2RQ/]\n33. Haarslev V, Moeller R, Wessel M: Querying the Semantic Web\nwith Racer + nRQL. In Proceedings of the KI-04 Workshop on Appli\ncations of Description Logics Ulm, Germany: Deutsche Bibliothek; 2004.\n34. FaCT [http://www.ontoknowledge.org/tools/fact.shtml]\n35. Pellet [http://www.mindswap.org/2003/pellet/]\n36. Gao Y, Kinoshita J, Wu E, Miller E, Lee R, Seaborne A, Cayzer S, Clark\nT: SWAN: A Distributed Knowledge Infrastructure for\nAlzheimer Disease Research. Journal of Web Semantics 2006,\n4(3):.\n37. AlzPharm [http://ontoweb.med.yale.edu/AlzPharm]\n38. Kinoshita J, Fagan A, Ewbank D, Marlatt M, Heyn P, Monte Sdl, Lom\nbardo NE: Alzheimer Research Forum live discussion: insulin\nresistance: a common axis linking Alzheimer's, depression,\nand metabolism? Journal of Alzheimer's Disease 2006, 9(1):89-93.\nhttp://www.biomedcentral.com/1471-2105/8/S3/S4\n39. Berners-Lee T, Hall W, Hendler J, Shadbolt N, Weitzner DJ: Creat\ning a Science of the Web. Science 2006, 313:769-771.\n40. Chen H, Wu Z, Wang H, Mao Y: RDF/RDFS-based Relational\nDatabase Integration. ICDE. Atlanta, Georgia 2006:94.\n41. Stephens S, Morales A, Quinian M: Applying semantic web tech\nnologies to drug safety determination. IEEE Intelligent Systems\n2006, 21(1):82-6.\n42. BrainPharm [http://senselab.med.yale.edu/BrainPharm]\n43. Semantic Web Applications in Neuromedicine\n[http://\nswan.mindinformatics.org]\n44. Alzheimer Research Forum [http://www.alzforum.org]\nPublish with BioMed Central and every\nscientist can read your work free of charge\n\"BioMed Central will be the most significant development for\ndisseminating the results of biomedical research in our lifetime.\"\nSir Paul Nurse, Cancer Research UK\nYour research papers will be:\navailable free of charge to the entire biomedical community\npeer reviewed and published immediately upon acceptance\ncited in PubMed and archived on PubMed Central\nyours -- you keep the copyright\nBioMedcentral\nSubmit your manuscript here:\nhttp://www.biomedcentral.com/info/publishing_adv.asp\nPage 12 of 12\n(page number not for citation purposes)"
    },
    {
      "category": "Lecture Notes",
      "title": "cPath: Open Source Software for Collecting, Storing, and Querying Biological Pathways",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/117e668873c92dd20adca84c8e437e70_cerami_bmc.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nBioMed Central\nBMC Bioinformatics\nSoftware\nOpen Access\ncPath: open source software for collecting, storing, and querying\nbiological pathways\nEthan G Cerami*1, Gary D Bader*2, Benjamin E Gross*1 and Chris Sander*1\nAddress: 1Computational Biology Center, Memorial Sloan-Kettering Cancer Center 1275 York Avenue, Box 460, New York, NY 10021, USA and\n2Banting and Best Department of Medical Research, Terrence Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, 160\nCollege St, Toronto, Ontario M5S 3E1, Canada\nEmail: Ethan G Cerami* - cpath-bmc@cbio.mskcc.org; Gary D Bader* - cpath-bmc@cbio.mskcc.org; Benjamin E Gross* - cpath\nbmc@cbio.mskcc.org; Chris Sander* - cpath-bmc@cbio.mskcc.org\n* Corresponding authors\nPublished: 13 November 2006\nReceived: 16 June 2006\nBMC Bioinformatics 2006, 7:497\ndoi:10.1186/1471-2105-7-497\nAccepted: 13 November 2006\nThis article is available from: http://www.biomedcentral.com/1471-2105/7/497\n(c) 2006 Cerami et al; licensee BioMed Central Ltd.\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0),\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nAbstract\nBackground: Biological pathways, including metabolic pathways, protein interaction networks,\nsignal transduction pathways, and gene regulatory networks, are currently represented in over 220\ndiverse databases. These data are crucial for the study of specific biological processes, including\nhuman diseases. Standard exchange formats for pathway information, such as BioPAX, CellML,\nSBML and PSI-MI, enable convenient collection of this data for biological research, but mechanisms\nfor common storage and communication are required.\nResults: We have developed cPath, an open source database and web application for collecting,\nstoring, and querying biological pathway data. cPath makes it easy to aggregate custom pathway\ndata sets available in standard exchange formats from multiple databases, present pathway data to\nbiologists via a customizable web interface, and export pathway data via a web service to third-\nparty software, such as Cytoscape, for visualization and analysis. cPath is software only, and does\nnot include new pathway information. Key features include: a built-in identifier mapping service for\nlinking identical interactors and linking to external resources; built-in support for PSI-MI and\nBioPAX standard pathway exchange formats; a web service interface for searching and retrieving\npathway data sets; and thorough documentation. The cPath software is freely available under the\nLGPL open source license for academic and commercial use.\nConclusion: cPath is a robust, scalable, modular, professional-grade software platform for\ncollecting, storing, and querying biological pathways. It can serve as the core data handling\ncomponent in information systems for pathway visualization, analysis and modeling.\nBackground\nPathway Data Collection for Biology\nThe complete sequencing of the genomes of numerous\norganisms provides a genetic \"parts list\" for human and\nmany model organisms [1,2]. However, a blueprint for\nhow these parts are assembled is required to explain how\nthe system works [3]. This wiring diagram for a cell con\nsists of multiple biological data types, including meta\nbolic pathways, signal transduction pathways, protein-\nprotein interaction networks, gene regulatory networks\nand genetic interactions. For example, the galactose utili\nzation pathway which allows yeast to harvest energy from\nPage 1 of 9\n(page number not for citation purposes)\n\nBMC Bioinformatics 2006, 7:497\ngalactose sugar consists of a well-studied series of bio\nchemical reactions responsible for converting galactose\ninto glucose-6-phosphate, and a gene regulatory mecha\nnism for switching the pathway on or off [4]. Aberrations\nwithin specific pathways have been implicated in many\nhuman diseases [5]. For example, the p53 tumor-suppres\nsor pathway has important functions in regulating cell\nproliferation, and is disrupted in many human cancers\n[6].\nHaving interaction and pathway data available in com\nputable form enables the construction of in silico models\nof complex biological processes according to specific\nhypotheses about how the process works. Such hypothe\nses can then be verified or falsified by experiment and the\nmodels further refined [4]. In the longer term, it may be\npossible to study the complete \"integrated circuit\" of a\ncell, and create mathematical models for understanding\nwhich perturbations within the circuit give rise to cancer\n[5]. Computational modeling of pathways may enable the\nidentification and classification of common logic mod\nules within the cell [7], better enable mechanistic based\ndrug development [3], facilitate the rational design of\ncombination therapies [6], and accelerate the speed of\nclinical trials [8].\nCentral to any of these endeavors is the creation and\nmaintenance of interaction and pathway databases.\nBecause of the need to store and organize growing\namounts of pathway information and the lack of a com\nmon point of organization, the number of interaction\ndatabases is growing rapidly, and over 220 exist in the\nyear 2006 [2,9]. Unfortunately, as is the case with many\nbiological data resources [10], interaction and pathway\ndatabases have unique data models, distinct access meth\nods, different file formats, and subtle semantic differences\n[9]. This diversity of implementation makes it extremely\ndifficult to collect data from multiple sources, and there\nfore slows down scientific research involving pathways\n[11,12].\nTo make heterogeneous data sources easier to use, several\nstandard XML exchange formats for sharing interaction\nand pathway data have been developed. The Systems Biol\nogy Markup Language (SBML) [13] and CellML [14] rep\nresent mathematical models of pathways designed for\nquantitative simulation of concentration profiles of com\nponents over time. The Proteomics Standards Initiative's\nMolecular Interaction (PSI-MI) format enables exchange\nof molecular interaction data sets [11]. Finally, the Biolog\nical Pathway Exchange (BioPAX) format enables exchange\nof biological pathways in general [15].\nAs more pathway databases make their data available in\nstandard formats, it is easier to aggregate pathway infor\nhttp://www.biomedcentral.com/1471-2105/7/497\nmation from multiple sources. A convenient single point\nof access for pathway information would provide\nresearchers with a more complete and powerful view of\nbiological networks and cellular machinery. Database and\nsoftware systems that work towards this goal include path\nway databases with original content, such as those listed\nin Table 2 and in Pathguide [16]; network analysis soft\nware applications that support multiple import formats\nand local interaction data stores, like PIANA [17], Ondex\n[18] and Cytoscape [19] and biological network data inte\ngration systems, similar in scope to sequence integration\nsystems like SRS [20], like Biozon [21], SigPath [22], Bio\nmodels [23], Atlas [24] and PKB [25]. cPath is part of the\nlatter class, but is the only system that is jointly open\nsource, easy to locally install, contains identifier resolu\ntion services, provides web based front end and web serv\nice API and includes support for pathway and molecular\ninteraction information available in both the PSI-MI and\nBioPAX standard database file formats.\nImplementation\nTechnical Architecture\ncPath is built using a traditional three-tier web architec\nture. The first tier consists of the open source MySQL data\nbase [26], and full-text index files generated by the open\nsource Lucene index engine, which also handles most\nquery tasks for the web service [27]. The second tier con\nsists of a Java servlet application, which uses the Jakarta\nStruts Library [28] for cleanly separating application logic\nfrom HTML/XML presentation. The second tier also uses\nthe Xerces Java XML parser [29], the open source JDOM\nlibrary [30], and ARP: Another RDF Parser [31]. In-mem\nory caching is provided via the open source Ehcache tool\nkit [32], and database pooling is provided by the Apache\nDatabase Connection Pool (DBCP) [33]. Real-time log\nging is provided by Apache Log4J [34], unit tests are writ\nten in JUnit [35], functional tests are written in Anteater\n[36], and the entire build process is fully automated via\nAnt [37] and Cruise Control [38]. Detailed information\nabout the cPath architecture, including graphical dia\ngrams and definitions of the table structure, can be found\nin the Architecture Guide PDF on the cPath developer web\nsite [39].\nData Model\nThe core cPath data model consists of just three elements:\nbiological entities, links between biological entities, and\nlinks to external databases. For example, when storing a\nPSI-MI interaction, such as \"p53 binds to TP73\", cPath\nsplits the PSI-MI record into three biological entity\nrecords: one for the interaction, one for p53 and one for\nTP73. For each record, cPath stores the complete PSI-MI\nd with that entity. cPath then stores\nfrom the interaction record to p53,\ninteraction record to TP73. Finally,\nPage 2 of 9\n(page number not for citation purposes)\nXML content associate\ntwo internal links, one\nand a second from the\n\nBMC Bioinformatics 2006, 7:497\ncPath stores external link records defined in the PSI-MI\nrecord for each of the biological entities; for example,\ncPath will store a link from p53 to its UniProt identifier,\nas well as links from p53 to any matching Gene Ontology\n(GO) terms if those references are present in the PSI-MI\nfile. External links are supplemented by any unification\nlinks available in the identifier mapping system.\nBy maintaining a simple data model, and storing XML\nwithin a relational database structure, cPath is able to\nstore data in multiple XML formats, including PSI-MI and\nBioPAX and the cPath table structure need not be updated\nwhen these formats change. cPath does not define any\nnew XML formats, but rather adopts the data models of\nPSI-MI and BioPAX. Thus cPath can store any biological\ninformation represented by these standard exchange for\nmats, from protein sequence, to experimental description,\nto thermodynamics information for biochemical reac\ntions. Not all information will be displayed via the web\ninterface, but all will be available in the XML returned by\nthe web service API. Additional tables within cPath are\nused to support the three core entity tables. For example,\ncPath maintains an identity and reference table for map\nping between identifiers, an external database table for\ncreating hyperlinks to other biological databases, an\norganism table for storing basic organism data, an XML\ncache table for storing pre-computed XML assembly doc\numents to speed loading of commonly accessed pages,\nand a log table for storing fatal errors in production mode.\nResults\nOverview\nUsing cPath, researchers can import interaction and path\nway data from multiple sources, access such data via a\nstandard web interface, and export data to third-party\napplications via a standards-based web service (Figure 1).\nBiologists, computational biologists, and software devel\nopers can utilize cPath for content aggregation, query and\nanalysis (see Table 1 for a list of target audiences). cPath\ncan serve as a modular, core software layer in larger path\nway information systems that are capable of visualizing,\nanalyzing, and modeling biological pathways. All cPath\nsoftware is freely available under an open source license\nfor local installation and modification. The key features\nprovided by cPath are detailed below.\nKey Feature: Identifier Mapping System\nA recurring problem in bioinformatics is linking related or\nidentical data described by different databases when mul\ntiple database identifiers (primary keys) are used to refer\nto the same biological entity [40,41]. Interaction data\nbases may use different identifiers for their proteins, RNA,\nDNA or small molecules (for example, a protein may be\nidentified with a UniProt accession number, RefSeq acces\nsion number or an NCBI GI number). This use of multiple\nhttp://www.biomedcentral.com/1471-2105/7/497\nidentifiers can significantly hinder the ability to seam\nlessly use data from diverse sources, such as to retrieve all\ninteractions involving a protein from numerous data\nsources. Recognizing when protein records that use differ\nent database identifiers actually represent the same pro\ntein allows a query for the protein to correctly retrieve\nboth original records [41]. To address this specific issue,\ncPath provides an identifier mapping system capable of\nstoring equivalence between two or more identifiers. The\nsystem is pre-populated with identifier mappings loaded\nfrom external files. For example, a single protein unifica\ntion mapping may map UniProt accession numbers to\nequivalent RefSeq accession numbers. Identifier mapping\nfiles are simple tab-delimited text files that must be loaded\ninto cPath prior to import of any interaction or pathway\ndata sets. With some scripting ability, cPath identifier\nmapping files can be created from external database\nresources, such as Alias Server [42], the EBI International\nProtein Index (IPI) [43], or Ensembl BioMart [44]. Sample\nprotein unification files, derived from the IPI Protein\nCross-References dataset, are available for download from\nthe cPath web site. cPath also uses identifier equivalences\navailable in imported pathway datasets that contain mul\ntiple database references for the same interactors.\nImportantly, cPath also provides a similar service for stor\ning relationships between non-equivalent, but related\nbiological entities. For example, a researcher can import a\nUniProt to Affymetrix mapping file, then when a new pro\ntein with a matching UniProt identifier is subsequently\nimported into cPath, it is annotated with all known\nAffymetrix probe set identifiers. This is useful for tools\nthat link gene expression data to pathways.\nKey Feature: Scalable Pathway Data Aggregation\nTo support data aggregation from multiple databases,\nsuch as to create custom integrated sets of pathways for\nlocal use, cPath supports the PSI-MI [11] and BioPAX [15]\nexchange formats. As more databases make their data\navailable in either of these two standard formats, cPath\nbecomes increasingly useful. As some popular pathway\ndatabases do not permit public redistribution of their\ndata, it is difficult for central websites to collect a complete\nset of pathways for research use. A local installation of\ncPath is one way to effectively collect and access all of this\ndata. For example, we have successfully aggregated data\nfrom MINT [45] and IntAct [46], resulting in a final data\nset of over 20,000 proteins, and more than 84,000 inter\nactions. cPath has also been successfully used to store all\nhuman pathways from Reactome [47], and one of our\nactive users has used cPath to successfully store over 1 mil\nlion interaction records. A complete list of external data\nbases, which have been successfully imported and stored\nusing cPath is provided in Table 2.\nPage 3 of 9\n(page number not for citation purposes)\n\ncPath Open Source Pathway Database Software Overview\nBMC Bioinformatics 2006, 7:497\nhttp://www.biomedcentral.com/1471-2105/7/497\nFigure 1\ncPath Open Source Pathway Database Software Overview. cPath is open source software for collecting, storing, and\nquerying biological pathways. At left, multiple databases can be imported into cPath via standard exchange formats. At right,\ncPath data can be viewed via a standard web browser or exported via an XML-based web service API, making cPath data avail\nable to third-party applications for pathway visualization and analysis.\ncPath supports PSI-MI format Level 1 and BioPAX format\nLevels 1 and 2. Level 1 of PSI-MI represents protein-pro\ntein interactions. Level 1 of BioPAX represents metabolic\npathways, Level 2 adds support for molecular interactions\nand post-translational protein modifications, such as\nthose supported by PSI-MI, and future levels will add sup\nport for signaling pathways, gene regulatory networks and\ngenetic interactions by the end of 2006.\nKey Feature: Standardized Web Interface for Browsing and\nQuerying Pathways\nOnce pathway data is stored in cPath, it is available for\nbrowsing via a standard web browser. For example, the\nCancer Cell Map [48] currently uses cPath software as the\nunderlying database, and makes available a set of cancer-\nspecific pathways curated by the Institute of Bioinformat\nics in collaboration with Memorial Sloan-Kettering Can\ncer Center. Users of cancer.cellmap.org or any other cPath\npowered site, have multiple options for querying. A user\ncan begin with a list of pathways, or search for a specific\npathway of interest, and drill down to view embedded\ncomponents, such as biochemical reactions, complexes\nand proteins (Figure 2). Alternatively, a user can enter a\nsearch string, such as a protein name or identifier, in the\nquery box, and link from the resulting query results page\nto interactors, interactions or pathways. cPath includes a\nfull-text search engine that automatically ranks records\nbased on relevance of search results and supports a simple\nlanguage to define more complex queries, such as\nBoolean combinations of words.\nKey Feature: Standardized Web Service Interface for\nApplication Communication\nData stored in cPath can be made available for query and\nexport via a standards-based web service interface. For\nexample, a third-party application can retrieve a list of all\npathways stored in cPath, and then retrieve the full details\nof each pathway in subsequent calls back to cPath. The\nresult of each query is a BioPAX or PSI-MI formatted XML\ndata file that can be parsed and used by the application.\nBy exposing all data via a standards-based web service\ninterface, cPath enables interoperable communication\nPage 4 of 9\n(page number not for citation purposes)\n\nBMC Bioinformatics 2006, 7:497\nhttp://www.biomedcentral.com/1471-2105/7/497\nTable 1: cPath is useful for biologists, computational biologists and software developers.\nTarget Audience\ncPath Usage\nBiologists\nBrowse and search for pathways of interest. Drill down from a pathway to member interactions and\nmolecules. Search for a specific protein of interest, and look up its role in specific pathways. Use third-\nparty tools to visualize and analyze pathways. For example, overlay expression data onto pathways of\ninterest, and algorithmically identify regions of correlated activity.\nComputational Biologists\nDownload all pathways in BioPAX format for global analysis using your own software. Install cPath\nlocally to aggregate external and/or private data sets. Use cPath to distribute, annotate and share\ncomputationally predicted interaction data sets or pathway models.\nSoftware Developers/Tool Builders Build third-party software tools on top of the open cPath web service API, in order to programmatically\naccess pathway data. For example, build software for visualizing pathways and organizing member\nmolecules based on cellular location.\nwith other software modules, and enables third-party\napplications to more easily build and expand tools for vis\nualization, analysis and model simulation. For example,\nthe cPath plugin for Cytoscape [19] enables researchers to\ndownload and visualize protein-protein interaction net\nworks. A second Cytoscape plugin enables researchers to\nview gene expression data along a color gradient and in\nthe context of known biological pathways retrieved from\ncPath (Figure 3). The cPath web service is not tied to a spe\ncific operating system or programming language, and uses\na REST-based (Representational State Transfer) architec\nture [49], which has only two requirements: queries must\nbe specified as Internet URLs, and response documents\nmust be specified as XML documents. This REST-based\napproach is considerably simpler than other web service\noptions, such as SOAP [50], and enables developers to\ninteractively experiment with the cPath web service with\njust a standard web browser. This helps lower the develop\nment effort required to interface with cPath, while simul\ntaneously maintaining platform and language independence.\nKey Feature: caBIGTM Interoperability\nIn addition to our own software engineering require\nments, cPath meets specific interoperability and testing\nrequirements of the National Cancer Institute (NCI) Can\ncer Biomedical Informatics Grid, or caBIGTM. The goal of\ncaBIGTM is to create a common infrastructure of interoper\nable tools and data specifically focused on cancer research\n[12,51], and software funded via caBIG is required to meet\nspecific interoperability requirements. For example, sil\nver-level compliance requires that the software use stand\nard exchange formats, make all data available via well\ndescribed APIs, and use standard messaging systems\nwhere appropriate [52]. Through caBIGTM, cPath has been\nformally tested by a third-party partner institution, Ore\ngon Health & Science University (OHSU). cPath was\ntested on multiple operating systems, and with multiple\nversions of the required software providing quality assur\nance (QA) of the entire software system. Since early 2004,\nthe cPath web service has handled more than 537,000\nqueries from over 5,800 distinct hosts (IP addresses),\nmostly from Cytoscape users using the cPath query\nplugin.\nKey Feature: Open Source License, Local Installation and\nCustomization\ncPath is freely available under the GNU Lesser General\nPublic License (LGPL) for academic and commercial use.\ncPath can be used to distribute pathway data on the Inter\nnet, or can be used to share private data locally within an\nindividual lab, department or company. Stable releases of\nthe cPath software are available for download, as are\nnightly snapshots of the latest code, which is not guaran\nteed to be stable, but may have new features compared to\nthe last stable release. A complete administrator guide\n(available in PDF format) describes the step-by-step proc\ness for installing a new instance of cPath. Installation\nrequires some computer system administration skill and\nability to work with the command line, thus is geared\ntowards computational biologists and software develop\ners. Once installed, cPath can be administered via the\ncommand line using a Perl script wrapper around a Java\nadministration program or via a web-based administra\ntion interface. After installation, typical set-up includes\nloading selecting identifier mapping and PSI-MI or Bio-\nPAX files and running the text indexer via the command\nline administration script or the web-based interface.\nOnce these are done, cPath is fully functional and is ready\nfor use. Any problems with import, such as errors in the\ninput files, are detected by a validator and reported. The\nweb-based administration provides several options for\ncustomizing the look and feel of cPath, including the abil\nity to set global headers, footers, and home page content.\nAdditionally, we maintain a public mailing list where new\nusers can post questions related to the administration and\nuse of cPath (cpath@googlegroups.com).\nConclusion\ncPath is a robust, scalable, modular, professional-grade\nsoftware platform for collecting, storing, and querying\nbiological pathways. It can serve as the core data handling\ncomponent in information systems for pathway visualiza\ntion, analysis and modeling. As cPath evolves, we hope to\nPage 5 of 9\n(page number not for citation purposes)\n\nBrowsing Pathways using cPath\nBMC Bioinformatics 2006, 7:497\nhttp://www.biomedcentral.com/1471-2105/7/497\nIncludes pathway name,\norganism, source of data,\navailability restrictions,\nand comments.\nBasic Pathway Data\nLists all molecules that\nparticipate In the pathway.\nMolecule List\nLists all interactions that\nparticipate In the pathway.\nInteraction List\nEnables users to search for pathways\nor proteins of interest.\nSearch Box\nRolling over members of an\ninteraction opens a pop-up\nbox with cellular location a\nand synonyms.\nSample Pop-Up Box\nCustomizable headers, footers, and\nhome page content.\nCustomizable Content\nFigure 2\nBrowsing Pathways using cPath. cPath provides a web interface for querying biological pathways. This screenshot is of the\nhuman Androgen receptor pathway from the Cancer Cell Map [48].\nattract new collaborators and developers to contribute to\nits open source development. We also envision that cPath\nwill provide the software infrastructure for a large-scale,\ninternational effort to pool pathways from multiple\nsources into common repositories that provide conven\nient integrated points of access for the scientific commu\nnity.\nFuture cPath software development will focus on increas\ning levels of data aggregation and linking. Currently,\ncPath is capable of integrating data at the interactor (e.g.\nprotein) level by simply recognizing identifiers referenc\ning the same protein, but it is incapable of detecting dupli\ncate interaction or pathway records, resolving conflicting\ninformation and detecting semantic inconsistencies\nbetween different sources, all of which are required for\ntrue integration. Furthermore, while cPath is capable of\nimporting both PSI-MI and BioPAX data, the web inter\nface and web service must be set to support one of these\nexchange formats at a time. To support both exchange for\nmats simultaneously, we will focus on creating translators\nbetween PSI-MI and BioPAX, and expand the roster of\navailable web services queries to support both formats.\ncPath will also support PSI-MI Level 2.5, which expands\nthe format scope to include other interactors, such as\nsmall molecules, DNA, and RNA and will support BioPAX\nLevel 3.0 and future levels as they become available. We\nalso plan to integrate BioPAX and PSI-MI validators, cur\nrently under development by others, into the cPath\nimport pipeline to verify that all incoming BioPAX and\nPSI-MI records conform to their respective format defini\ntions and to community best practices.\nPage 6 of 9\n(page number not for citation purposes)\n\nSample Cytoscape Plugin for Interfacing with cPath\nBMC Bioinformatics 2006, 7:497\nhttp://www.biomedcentral.com/1471-2105/7/497\nGraphical rendering of the\nKit Receptor pathway.\nNetwork Visualization\nWindow for viewing\ninteractor or interaction\ndetails.\nNode / Edge Details\nNode color indicates\nexpression level. Red\nindicates high expression\nlevel. Blue indicates\nlow expression level.\nOverlay Expression Data\nSlider for selecting current\nexperimental condition.\nCondition Selector\nVisual legend for viewing\nand configuring the color gradient.\nVisual Legend\nFigure 3\nSample Cytoscape Plugin for Interfacing with cPath. The Cytoscape Expression Viewer plugin enables researchers to\nvisualize expression data on biological pathways. The plugin utilizes the cPath web service API to retrieve pathway data, such as\nthe Kit receptor pathway from the Cancer Cell Map [48].\nWith the availability of tools for converting SBML and\nCellML to BioPAX developed by BioModels.net [23], we\nwill be able to import SBML and CellML data sets present\nin BioModels.net directly into cPath. We will also support\npathway export in SBML and CellML. Furthermore, in\norder to expand the number of other resources cPath is\ncapable of linking to, we plan to integrate the MIRIAM\n(Minimal Information Requested In the Annotation of\nBiochemical Models) URI set. This community-derived\ndata set provides a list of stable URIs and URL patterns for\ncross-linking bioinformatics resources and is currently\nused in SBML and BioModels.net [53].\nPage 7 of 9\n(page number not for citation purposes)\n\nBMC Bioinformatics 2006, 7:497\nhttp://www.biomedcentral.com/1471-2105/7/497\nTable 2: External databases successfully imported into cPath.\nDatabase Name\nDatabase Type\nURL\nRelease Date Tested\nData Format used f\ncPath Import\nor\nDatabase Stats\nCancer Cell Map\nSignaling Pathways\nhttp://cancer.cellmap.org\nApril, 2006\nBioPAX, Level 2\nPathways: 10\nInteractions: 2,104\nPhysical Entities: 899\nDatabase of\nInteracting Proteins\n(DIP) [54, 55]\nProtein-Protein\nInteractions\nhttp://dip.doe\nmbi.ucla.edu/\nApril, 2006\nPSI-MI, Level 1\nInteractions: 54,511\nPhysical Entities: 19,003\nEcocyc [56]\nMetabolic and Signaling\nPathways\nhttp://ecocyc.org/\nRegistration required to\ndownload data\nMarch, 2006\nBioPAX, Level 1\nPathways: 224\nInteractions: 4,644\nPhysical Entities: 3,511\nHuman Protein\nReference Database\n(HPRD) [57]\nProtein-Protein\nInteractions\nhttp://hprd.org/\nRegistration required to\ndownload data\nSept, 2005\nPSI-MI, Level 1\nInteractions: 4,450\nPhysical Entities: 12,226\nIntAct [46]\nProtein-Protein\nInteractions\nhttp://www.ebi.ac.uk/\nintact\nMay, 2006\nPSI-MI, Level 1\nInteractions: 67,816\nPhysical Entities: 28,006\nKEGG [58, 59]\nMetabolic Pathways\nftp://ftp.genome.jp/pub/db/\ncommunity/biopax/\nJuly, 2006\nBioPAX, Level 2\nHuman Data Only Pathways:\nInteractions: 3,285\nPhysical Entities: 2,018\nMolecular Interaction\nDatabase (MINT) [45]\nProtein-Protein\nInteractions\nhttp://\nmint.bio.uniroma2.it/mint/\nMay, 2005\nPSI-MI, Level 1\nInteractions: 44,904\nPhysical Entities: 16,325\nReactome [47]\nMetabolic and Signaling\nPathways\nhttp://reactome.org/\nMay, 2006\nBioPAX, Level 2\nHuman Data Only Pathways:\nInteractions: 2,962\nPhysical Entities: 3,197\nAvailability and Requirements\n- Project Name: cPath\n- Project Home Page: http://cbio.mskcc.org/dev_site/\ncpath/\n- Operating System(s): Platform independent; tested on\nWindows, Linux and Mac OS X\n- Programming Languages: Java\n- Other Requirements: MySQL 4.0 or higher; Apache\nTomcat Server 4.1 or higher; Apache Ant 1.6 or higher,\nPerl 5.0 or higher. All required software is ope\nand freely available.\n- License: Free for academic and commercial use\nthe GNU Lesser General Public License (LGPL).\n- Example site running cPath software: Memori\nKettering Cancer Cell Map, http://cancer.cellmap\nAuthors' contributions\nEC managed the overall software development pr\ncPath, wrote most of the code for cPath, and wrot\ndraft of this manuscript. GB conceived of th\nproject, managed the scientific and technical g\nhelped draft the manuscript. BG contributed to\ninterface for displaying BioPAX records, built th\nistrative interface for customizing cPath web pa\nbuilt the cPath plugin for overlaying expression d\nbiological pathways. CS conceived of the cPath\nand provided overall scientific and technical guid\nauthors read and approved the final manuscript.\nAcknowledgements\nPartial funding for cPath was provided by the National Cancer Institute\n(NCI) caBIG initiative and the Alfred W. Bressler Scholars Endowment\nFund. We thank Shannon McWeeney, Vincent Yau, and Ranjani Ram\nakrishnan, of the Center for Biostatistics, Computing & Informatics in Biol\nogy and Medicine, at Oregon Health & Science University (OHSU) for\ntesting cPath on multiple platforms, and performing overall quality assur\nance (QA) of the entire software system and providing a useful BioPAX val\nidation tool. We also thank Iain Keddie of GlaxoSmithKline for code\ncontributions, including performance optimizations of the cPath import and\nfull-text indexing pipeline.\nReferences\n1.\nIdeker T, Galitski T, Hood L: A new approach to decoding life:\nsystems biology. Annu Rev Genomics Hum Genet 2001, 2:343-372.\nn source\n2.\nSchaefer CF: Pathway databases.\nAnn N Y Acad Sci 2004,\n1020:77-91.\n3.\nKitano H: Systems biology: a brief overview. Science 2002,\n295(5560):1662-1664.\nrs under\n4.\nIdeker T, Thorsson V, Ranish JA, Christmas R, Buhler J, Eng JK, Bum-\ngarner R, Goodlett DR, Aebersold R, Hood L: Integrated genomic\nand proteomic analyses of a systematically perturbed meta\nbolic network. Science 2001, 292(5518):929-934.\nal Sloan-\n5.\nHanahan D, Weinberg RA: The hallmarks of cancer. Cell 2000,\n100(1):\n.org/.\n57-70.\n6.\nHahn WC, Weinberg RA: Modelling the molecular circuitry of\ncancer. Nat Rev Cancer 2002, 2(5):331-341.\n7.\nNurse P: Systems biology: understanding cells. Nature 2003,\n424(6951):883.\nocess for\n8.\nSander C: Genomic medicine and the future of health care.\ne the first\nScience 2000, 287(5460):1977-1978.\ne cPath\n9.\nCary MP, Bader GD, Sander C: Pathway information for systems\nbiology. FEBS Lett 2005, 579(8):1815-1820.\noals, and\n10. Stein L: Creating a bioinformatics nation.\nNature 2002,\nthe web\n417(6885):119-120.\n11. Hermjakob H, Montecchi-Palazzi L, Bader G, Wojcik J, Salwinski L,\ne admin\nCeol A, Moore S, Orchard S, Sarkans U, von Mering C, Roechert B,\nges, and\nPoux S, Jung E, Mersch H, Kersey P, Lappe M, Li Y, Zeng R, Rana D,\nata onto\nNikolski M, Husi H, Brun C, Shanker K, Grant SG, Sander C, Bork P,\nZhu W, Pandey A, Brazma A, Jacq B, Vidal M, Sherman D, Legrain P,\nproject,\nCesareni G, Xenarios I, Eisenberg D, Steipe B, Hogue C, Apweiler R:\nance. All\nThe HUPO PSI's molecular interaction format--a commu\n\nnity standard for the representation of protein interaction\ndata. Nat Biotechnol 2004, 22(2):177-183.\nPage 8 of 9\n(page number not for citation purposes)\n\nBMC Bioinformatics 2006, 7:497\nhttp://www.biomedcentral.com/1471-2105/7/497\n12. Buetow KH: Cyberinfrastructure: empowering a \"third way\"\nin biomedical research. Science 2005, 308(5723):821-824.\n13. Hucka M, Finney A, Sauro HM, Bolouri H, Doyle JC, Kitano H, Arkin\nAP, Bornstein BJ, Bray D, Cornish-Bowden A, Cuellar AA, Dronov S,\nGilles ED, Ginkel M, Gor V, Goryanin, Hedley WJ, Hodgman TC,\nHofmeyr JH, Hunter PJ, Juty NS, Kasberger JL, Kremling A, Kummer\nU, Le Novere N, Loew LM, Lucio D, Mendes P, Minch E, Mjolsness\nED, Nakayama Y, Nelson MR, Nielsen PF, Sakurada T, Schaff JC, Sha\npiro BE, Shimizu TS, Spence HD, Stelling J, Takahashi K, Tomita M,\nWagner J, Wang J: The systems biology markup language\n(SBML): a medium for representation and exchange of bio\nchemical network models. Bioinformatics 2003, 19(4):524-531.\n14. Lloyd CM, Halstead MD, Nielsen PF: CellML: its future, present\nand past. Prog Biophys Mol Biol 2004, 85(2-3):433-450.\n15. BioPAX : Biological Pathways Exchange\n[http://www.bio\npax.org/]\n16. Bader GD, Cary MP, Sander C: Pathguide: a pathway resource\nlist. Nucleic Acids Res 2006, 34(Database issue):D504-6.\n17. Aragues R, Jaeggi D, Oliva B: PIANA: protein interactions and\nnetwork analysis. Bioinformatics 2006, 22(8):1015-1017.\n18. Kohler J, Baumbach J, Taubert J, Specht M, Skusa A, Ruegg A, Rawlings\nC, Verrier P, Philippi S: Graph-based analysis and visualization\nof experimental results with ONDEX.\nBioinformatics 2006,\n22(11):1383-1390.\n19. Shannon P, Markiel A, Ozier O, Baliga NS, Wang JT, Ramage D, Amin\nN, Schwikowski B, Ideker T: Cytoscape: a software environment\nfor integrated models of biomolecular interaction networks.\nGenome Res 2003, 13(11):2498-2504.\n20. Zdobnov EM, Lopez R, Apweiler R, Etzold T: The EBI SRS server\n-recent developments. Bioinformatics 2002, 18(2):368-373.\n21. Birkland A, Yona G: BIOZON: a system for unification, man\nagement and analysis of heterogeneous biological data. BMC\nBioinformatics 2006, 7:70.\n22. Campagne F, Neves S, Chang CW, Skrabanek L, Ram PT, Iyengar R,\nWeinstein H: Quantitative information management for the\nbiochemical computation of cellular networks. Sci STKE 2004,\n2004(248):pl11.\n23. Le Novere N, Bornstein B, Broicher A, Courtot M, Donizelli M,\nDharuri H, Li L, Sauro H, Schilstra M, Shapiro B, Snoep JL, Hucka M:\nBioModels Database: a free, centralized database of curated,\npublished, quantitative kinetic models of biochemical and\ncellular systems.\nNucleic Acids Res 2006, 34(Database\nissue):D689-91.\n24. Shah SP, Huang Y, Xu T, Yuen MM, Ling J, Ouellette BF: Atlas - a\ndata warehouse for integrative bioinformatics. BMC Bioinfor\nmatics 2005, 6:34.\n25. The Pathway Knowledge Base [http://pkb.stanford.edu]\n26. MySQL [http://www.mysql.com]\n27. Apache Lucene [http://lucene.apache.org/java/docs/]\n28. Apache Struts [http://struts.apache.org/]\n29. Apache Xerces Java Parser. .\n30. JDOM [http://jdom.org/]\n31. ARP: Another RDF Parser [http://www.hpl.hp.com/personal/jjc/\narp/]\n32. Ehcache [http://ehcache.sourceforge.net/]\n33. Apache Commons DBCP [http://jakarta.apache.org/commons/\ndbcp/]\n34. Apache Log4j [http://logging.apache.org/log4j/docs/]\n35. JUnit [http://junit.org/]\n36. Anteater [http://aft.sourceforge.net/]\n37. Apache Ant [http://ant.apache.org/]\n38. Cruise Control [http://cruisecontrol.sourceforge.net/]\n39. cPath Developer Site [http://cbio.mskcc.org/dev_site/cpath/]\n40. Stein LD: Integrating biological databases. Nat Rev Genet 2003,\n4(5):337-345.\n41. Karp PD: Database links are a foundation for interoperability.\nTrends Biotechnol 1996, 14(8):273-279.\n42. Iragne F, Barre A, Goffard N, De Daruvar A: AliasServer: a web\nserver to handle multiple aliases used to refer to proteins.\nBioinformatics 2004, 20(14):2331-2332.\n43. Kersey PJ, Duarte J, Williams A, Karavidopoulou Y, Birney E,\nApweiler R: The International Protein Index: an integrated\ndatabase for proteomics experiments.\nProteomics 2004,\n4(7):1985-1988.\n44. Ensembl BioMart [http://www.ensembl.org/Multi/martview]\n45. Zanzoni A, Montecchi-Palazzi L, Quondam M, Ausiello G, Helmer-\nCitterich M, Cesareni G: MINT: a Molecular INTeraction data\nbase. FEBS Lett 2002, 513(1):135-140.\n46. Hermjakob H, Montecchi-Palazzi L, Lewington C, Mudali S, Kerrien S,\nOrchard S, Vingron M, Roechert B, Roepstorff P, Valencia A, Margalit\nH, Armstrong J, Bairoch A, Cesareni G, Sherman D, Apweiler R:\nIntAct: an open source molecular interaction database.\nNucleic Acids Res 2004, 32(Database issue):D452-5.\n47. Joshi-Tope G, Gillespie M, Vastrik I, D'Eustachio P, Schmidt E, de\nBono B, Jassal B, Gopinath GR, Wu GR, Matthews L, Lewis S, Birney\nE, Stein L: Reactome: a knowledgebase of biological pathways.\nNucleic Acids Res 2005, 33(Database issue):D428-32.\n48. The Cancer Cell Map [http://cancer.cellmap.org]\n49. Fielding RT: Architectural Styles and the Design of Network-\nbased Software Architectures. In Information and Computer Sci\nence University of California, Irvine; 2000.\n50. Gudgin M, Hadley M, Mendelsohn N, Moreau JJ, Nielsen HF: SOAP\nVersion 1.2 Part 1: Messaging Framework, W3C Recom\nmendation 24 June 2003.\n[http://www.w3.org/TR/2003/REC\nsoap12-part1-20030624/].\n51. Bouchie A: Coming soon: a global grid for cancer research.\nNat Biotechnol 2004, 22(9):1071-1073.\n52. caBIG Compatibility Guidelines, National Cancer Institute\nCenter for Bioinformatics, NCICB\n[https://cabig.nci.nih.gov/\nguidelines_documentation/caBIG_Compatibility_Document]\n53. Le Novere N, Finney A, Hucka M, Bhalla US, Campagne F, Collado-\nVides J, Crampin EJ, Halstead M, Klipp E, Mendes P, Nielsen P, Sauro\nH, Shapiro B, Snoep JL, Spence HD, Wanner BL: Minimum infor\nmation requested in the annotation of biochemical models\n(MIRIAM). Nat Biotechnol 2005, 23(12):1509-1515.\n54. Salwinski L, Miller CS, Smith AJ, Pettit FK, Bowie JU, Eisenberg D:\nThe Database of Interacting Proteins: 2004 update. Nucleic\nAcids Res 2004, 32(Database issue):D449-51.\n55. Xenarios I, Rice DW, Salwinski L, Baron MK, Marcotte EM, Eisenberg\nD: DIP: the database of interacting proteins. Nucleic Acids Res\n2000, 28(1):289-291.\n56. Karp PD, Riley M, Paley SM, Pelligrini-Toole A: EcoCyc: an encyclo\npedia of Escherichia coli genes and metabolism. Nucleic Acids\nRes 1996, 24(1):32-39.\n57. Peri S, Navarro JD, Amanchy R, Kristiansen TZ, Jonnalagadda CK,\nSurendranath V, Niranjan V, Muthusamy B, Gandhi TK, Gronborg M,\nIbarrola N, Deshpande N, Shanker K, Shivashankar HN, Rashmi BP,\nRamya MA, Zhao Z, Chandrika KN, Padma N, Harsha HC, Yatish AJ,\nKavitha MP, Menezes M, Choudhury DR, Suresh S, Ghosh N, Saravana\nR, Chandran S, Krishna S, Joy M, Anand SK, Madavan V, Joseph A,\nWong GW, Schiemann WP, Constantinescu SN, Huang L, Khosravi-\nFar R, Steen H, Tewari M, Ghaffari S, Blobe GC, Dang CV, Garcia JG,\nPevsner J, Jensen ON, Roepstorff P, Deshpande KS, Chinnaiyan AM,\nHamosh A, Chakravarti A, Pandey A: Development of human\nprotein reference database as an initial platform for\napproaching systems biology in humans. Genome Res 2003,\n13(10):2363-2371.\n58. Kanehisa M, Goto S, Hattori M, Aoki-Kinoshita KF, Itoh M,\nKawashima S, Katayama T, Araki M, Hirakawa M: From genomics\nto chemical genomics: new developments in KEGG. Nucleic\nAcids Res 2006, 34(Database issue):D354-7.\n59. Ogata H, Goto S, Sato K, Fujibuchi W, Bono H, Kanehisa M: KEGG:\nKyoto Encyclopedia of Genes and Genomes. Nucleic Acids Res\n1999, 27(1):29-34.\nPage 9 of 9\n(page number not for citation purposes)"
    },
    {
      "category": "Resource",
      "title": "LinkHub: a Semantic Web system that facilitates cross-database queries and information retrieval in proteomics",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/8b05d0c4db91ef1f0c5e123bbcf701ea_smith_bmc.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n<supplement> <title> <p>Semantic E-Science in Biomedicine</p> </title> <editor>Yimin Wang, Zhaohui Wu, Huajun Chen</editor> <note>Research</note> </supplement>\nBioMed Central\nBMC Bioinformatics\nResearch\nOpen Access\nLinkHub: a Semantic Web system that facilitates cross-database\nqueries and information retrieval in proteomics\nAndrew K Smith2, Kei-Hoi Cheung2,3,4,6, Kevin Y Yip2, Martin Schultz2 and\nMark B Gerstein*1,2,5\nAddress: 1Department of Molecular Biophysics and Biochemistry, Yale University, New Haven, Connecticut, 06520, USA, 2Department of\nComputer Science, Yale University, New Haven, Connecticut, 06520, USA, 3Center for Medical Informatics, Yale University, New Haven,\nConnecticut, 06520, USA, 4Department of Genetics, Yale University, New Haven, Connecticut, 06520, USA, 5Program in Computational Biology\nand Bioinformatics, Yale University, New Haven, Connecticut, 06511, USA and 6Department of Anesthesiology, Yale University, New Haven,\nConnecticut, 06520, USA\nEmail: Andrew K Smith - andrew.smith@yale.edu; Kei-Hoi Cheung - kei.cheung@yale.edu; Kevin Y Yip - yuklap.yip@yale.edu;\nMartin Schultz - martin.schultz@yale.edu; Mark B Gerstein* - mark.gerstein@yale.edu\n* Corresponding author\nPublished: 9 May 2007\nBMC Bioinformatics 2007, 8(Suppl 3):S5\ndoi:10.1186/1471-2105-8-S3-S5\nThis article is available from: http://www.biomedcentral.com/1471-2105/8/S3/S5\n(c) 2007 Smith et al; licensee BioMed Central Ltd.\nThis is an open access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0),\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nAbstract\nBackground: A key abstraction in representing proteomics knowledge is the notion of unique\nidentifiers for individual entities (e.g. proteins) and the massive graph of relationships among them.\nThese relationships are sometimes simple (e.g. synonyms) but are often more complex (e.g. one-\nto-many relationships in protein family membership).\nResults: We have built a software system called LinkHub using Semantic Web RDF that manages\nthe graph of identifier relationships and allows exploration with a variety of interfaces. For\nefficiency, we also provide relational-database access and translation between the relational and\nRDF versions. LinkHub is practically useful in creating small, local hubs on common topics and then\nconnecting these to major portals in a federated architecture; we have used LinkHub to establish\nsuch a relationship between UniProt and the North East Structural Genomics Consortium.\nLinkHub also facilitates queries and access to information and documents related to identifiers\nspread across multiple databases, acting as \"connecting glue\" between different identifier spaces.\nWe demonstrate this with example queries discovering \"interologs\" of yeast protein interactions\nin the worm and exploring the relationship between gene essentiality and pseudogene content. We\nalso show how \"protein family based\" retrieval of documents can be achieved. LinkHub is available\nat hub.gersteinlab.org and hub.nesg.org with supplement, database models and full-source code.\nConclusion: LinkHub leverages Semantic Web standards-based integrated data to provide novel\ninformation retrieval to identifier-related documents through relational graph queries, simplifies\nand manages connections to major hubs such as UniProt, and provides useful interactive and query\ninterfaces for exploring the integrated data.\nPage 1 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nBackground\nBiological research is producing vast amounts of data (e.g.\nfrom high throughput experiments such as sequencing\nprojects, and microarray experiments) at a prodigious\nrate. Most of this data is made freely available to the pub\nlic, and this has created a large and growing number of\ninternet and world wide web-accessible biological data\nresources which are characterized by being distributed,\nheterogeneous, and having a large size variance, i.e. huge,\nmega-databases such as UniProt [1] down to medium,\nsmall or \"boutique\" databases (e.g., TRIPLES [2]) gener\nated for medium or small scale experiments or particular\npurposes. Most computational analyses of biological data\nwill require using multiple integrated datasets, and inte\ngrated data along with rich, flexible and efficient inter\nfaces to it encourages exploratory data analysis which can\nlead to serendipitous new discoveries: the sum is greater\nthan its parts. Currently, integration often must be done\nmanually in a labor and time intensive way by finding rel\nevant datasets, understanding them, writing code to com\nbine them, and finally doing the desired analysis. The\nbasic requirements for better, more seamless integrated\nanalysis are uniformity and accessibility; data are ineffec\ntual if scattered among incompatible resources.\nWeb search engines and hyperlinks are the basic and com\nmonly used ways to find things on the web and navigate\nweb content but they do not enable fine-grained cross-site\nanalysis of data. To improve upon this, one key issue is the\nneed for standardization and its widespread use, and tools\nsupporting and enabling it. Biological data is too vast for\nbrute-force centralization to be the complete solution to\ndata interoperability. We must have standards and sys\ntems for people and groups to work independently creat\ning and making data available (although ultimately\ncooperatively and collaboratively) but still in the end all\nor most of the pieces of biological knowledge and data are\nconnected together in semantically rich ways. The W3C's\n[3]Semantic Web [4-6] is a promising candidate: it allows\nweb information to be expressed in fine-grained struc\ntured ways so applications can more readily and precisely\nextract and cross-reference key facts and information from\nit without having to worry about disambiguating meaning\nfrom natural language texts. Standard and machine-read\nable ontologies such as the Gene Ontology [7] are also\ncreated and their common use encouraged to further\nreduce semantic ambiguity, although there is a need to\nmake these ontologies more machine-friendly [8].\nA key abstraction or \"scaffold\" for representing biological\ndata is the notion of unique identifiers for biological enti\nties and relationships among them. For example, each\nprotein sequence in the UniProt database is given a\nunique accession, e.g. Q60996, which can be used as a key\nto access its UniProt sequence record. UniProt sequence\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nrecords also contain cross-references to related informa\ntion in other databases, e.g. related Gene Ontology and\nPFAM identifiers (although the relationship types, e.g.\n\"functional annotation\" and \"family membership\"\nrespectively, are not specified). Two identifiers such as\nQ60996 and GO:0005634 and the cross-reference\nbetween them can be viewed as a single edge between two\nnodes in a graph, and conceptually then a large, impor\ntant part of biological knowledge can be viewed as a mas\nsive graph whose nodes are biological entities such as\nproteins, genes, etc. represented by identifiers and the\nlinks in the graph are typed and are the specific relation\nships among the biological entities. Figure 1a is a concep\ntual illustration of the graph of biological identifier\nrelationships; the problem is that this graph only con\ncretely exists piecemeal or not at all.\nA basic problem preventing this graph of relationships\nfrom being more fully realized is the problem of nomen\nclature. Often, there are many synonyms for the same\nunderlying entity caused by independent naming, e.g.\nstructural genomics centers assigning their own protein\nidentifiers in addition to UniProt's. There can also be lex\nical variants of the same underlying identifier (e.g.\nGO:0008150 vs. GO0008150 vs. GO-8150). Synonyms\nare a small part of the overall problem, however, and\nmore generally there are many kinds of relationships\nincluding one-to-one and one-to-many relationships. For\nexample, a single Gene Ontology or PFAM identifier can\nbe related with many UniProt identifiers (i.e. they all\nshare the same functional annotation or family member\nship). PFAM represents an important structuring principle\nfor proteins and the genes they come from, the notion of\nfamilies (or domains) based on evolution; proteins shar\ning common PFAM domains are evolutionarily related\n(called homologs) and likely have the same or similar func\ntions. Gene Ontology consists of three widely used struc\ntured, controlled vocabularies (ontologies) that describe\ngene products such as proteins in terms of their associated\nbiological processes, cellular components and molecular\nfunctions in a species-independent manner. The concep\ntual graph of identifier relationships is richly connected,\nand a transitive closure even a few levels deep can lead to\nindirect relationships with a great number of other enti\nties. Being able to store, manage, and work with this graph\nof entities and relationships can lead to many opportuni\nties for interesting exploratory analysis and LinkHub is\nsuch a system for doing this.\nLinkHub: a system for loosely coupled, collaborative\nintegration of biological identifier relationships\nThe Semantic Web is increasingly gaining traction as the\nkey standards-based platform for biological data integra\ntion [9,10], and since LinkHub is a natural fit to Semantic\nWeb technologies we use them as the basis of LinkHub.\nPage 2 of 12\n(page number not for citation purposes)\n\nGraph of relationships and hub of hubs organization\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nA)\nB)\nFigure 1\nGraph of relationships and hub of hubs organization. (a) A conceptualization of the semantic graph of interrelationships\namong biological identifiers, with boxes representing instances of biological identifiers (originating database names given inside)\nand different edge types representing different kinds of relationships (b) LinkHub as an enabler of an efficient \"hub of hubs\"\norganization of biological data. The different colors represent different labs, organizations, or logical groupings of data\nresources.\nPage 3 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nLinkHub is designed based on a semantic graph model,\nwhich captures the graph of relationships among biologi\ncal entities discussed above. To provide a scalable imple\nmentation while also exploring Semantic Web database\ntechnologies, we implemented LinkHub in both MySQL\n[11] and Resource Description Framework or RDF [12]\ndatabases. LinkHub provides various interfaces to interact\nwith this graph, such as a web frontend for viewing and\ntraversing the graph as a dynamic expandable/collapsible\nHTML list (see figure 2) and a mechanism for viewing par\nticular path types in the graph, as well as with RDF query\nlanguages.\nCentralized data integration to an extent does make sense,\ne.g. a lab or organization might want to create a local data\nwarehouse of interconnections among its individual data\nresources; but it does not want to have to explicitly con\nnect its data resources up to everything in existence, which\nis impossible. The key idea is that if groups independently\nmaintaining data resources each connect their resources\nup to some other resource X, then any of them can reach\nany other through these connections to X, and we can col\nlectively achieve incremental global data integration in\nthis way. LinkHub is a software architecture and system\nwhich aims to help realize this goal by enabling one to\ncreate such local minor hubs of data interconnections and\nconnect them to major hubs such as UniProt in a feder\nated \"hub of hubs\" framework and this is illustrated in fig\nure 1b.\nPaper organization\nIn the results section next, we will demonstrate how\nLinkHub enables novel information retrieval to docu\nments attached to LinkHub graph nodes based on the\nrelational structure of the LinkHub graph; a particular\npractical use case of this, providing \"family views\" to data,\nwill be given. We will then give concrete examples of the\nkinds of integrated, cross-database queries that can be\ndone with LinkHub, in combination with a previous sys\ntem of ours called YeastHub, in support of scientific\nexploratory analysis; example queries discovering \"inter\nologs\" of yeast protein interactions in the worm and\nexploring the relationship between gene essentiality and\npseudogene content will be given. We will then discuss\nrelated work to LinkHub and future directions before con\ncluding. In the methods section we describe implementa\ntion details of LinkHub, including its data models and\nhow they are populated with data and LinkHub's web\ninteractive and query interfaces.\nResults\nNovel information retrieval based on LinkHub relational\ngraph structure\nThe \"path type\" interface to LinkHub allows one to flexi\nbly retrieve useful subsets of the web documents attached\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nto identifier nodes in the graph based on the graph's rela\ntional structure. Normal search engines relying on key\nword searches could not provide such access, and\nLinkHub thus enables novel information retrieval to its\nknown web documents. An important practical use of this\n\"path type\" interface is as a secondary, orthogonal inter\nface to other biological databases in order to provide dif\nferent views of their underlying data. For example,\nMolMovDB [13] provides movie clips of likely 3D\nmotions of proteins, and one can access it by PDB [14]\nidentifiers. However, an alternative useful interface (actu\nally provided by LinkHub) is a \"family view\" where one\nqueries with a PDB identifier and can view all available\nmotion pages for proteins in the same family as the query\nPDB identifier. LinkHub also provides a similar \"family\nview\" interface to structural genomics data in the SPINE\nsystem [15]. The system is flexible and one can easily\nimagine other similar applications, e.g. a \"functional\nview\" where all pages for proteins that have the same\nGene Ontology function as a given protein are shown or a\n\"pseudogene family view\" where all pages for pseudo-\ngenes of proteins in the same family are shown. While the\n\"path type\" interface is a simple way of providing novel,\nrelational access to LinkHub identifier node-linked docu\nments, RDF query language access to the LinkHub rela\ntional graph would allow the most flexible novel\ninformation retrieval.\nCross-database RDF queries\nTo demonstrate the data interaction and exploration capa\nbilities engendered by the RDF version of LinkHub, the\nRDF-formatted LinkHub dataset is loaded into our Yeast-\nHub [16] system which uses Sesame [17] as its native RDF\nrepository. Two demonstration queries below written in\nSeRQL (Sesame implementation of RQL) [18] demon\nstrate one can efficiently do the kinds of interesting pre\nliminary scientific investigation and exploratory analysis\ncommonly done at the beginning of research initiatives\n(e.g. to see whether they are worth pursuing further).\nThese queries make use of information present in both\nYeastHub and LinkHub (and thus could not be done\nwithout joining the two systems), and LinkHub is used as\n'glue' to provide connections (both direct and indirect)\nbetween different identifiers. It is noteworthy that these\nqueries can be formulated and run in relatively little time\n(a few hours at most) and they roughly duplicate some\nresults from published papers. In effect, LinkHub does the\nup-front time-consuming manual work of integrating\nmultiple datasets, and this integrated data is generally use\nful for efficient formulation and execution of queries,\nwhich is in contrast to the papers which likely required\nextensive \"one-off\" effort to combine the necessary data to\nachieve their results.\nPage 4 of 12\n(page number not for citation purposes)\n\nThe basic DHTML list interface to LinkHub\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nFigure 2\nThe basic DHTML list interface to LinkHub. Here, the data and relationships for UniProt identifier P26364 are pre\nsented. P26364 is presented at the root of the list, and lower levels contain information on additional related identifiers. Each\nidentifier has two subsections: Links which gives a list of hyperlinks to web documents directly relevant to the identifier; and\nEquivalent or Related Ids which contains a list of additional identifiers related to the first identifier (the relationship type if it\nexists is given in parentheses; a synonym relationship is assumed if no relationship is given). The identifiers in the Equivalent and\nRelated Ids section may themselves be further related to other identifiers which will have their own Links and Equivalent or\nRelated Ids sections, ad nauseum. The initial display shows the transitive closure of the root identifier one level deep, and\ndynamic callbacks to the server retrieve additional data when the user clicks on identifiers whose subsections have not yet\nbeen loaded; in this way, the user can explore the relationship paths he desires without performance penalties (of loading the\nwhole graph) or 'information overload'. The interface is dynamic, and a '+' list icon can be expanded to view the hidden under\nlying content, and a '-' list icon can be clicked to hide the content.\nPage 5 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nQuery 1: finding worm 'interologs' of yeast protein\ninteractions\nProteins rarely act in isolation and often interact with one\nanother and other molecules to perform necessary cellular\nactions. Experimental determinations of protein interac\ntions are expensive and computational methods can lev\nerage them for further interaction predictions. With this\nquery we want to consider all the protein interactions in\nyeast (S. cervisiae) and see how many and which of them\nare present as evolutionarily related homologs in worm\n(C. elegans), also known as interologs [19], i.e. protein\npairs in worm corresponding to evolutionarily related\nknown interacting pairs in yeast. We thus start with a data-\nset containing known and predicted yeast protein interac\ntions which is already loaded into YeastHub; here the\ninteractions are expressed between yeast gene names. Part\nof the SeRQL statement for this query together with a por\ntion of its corresponding output can be seen in figure 3.\nHowever, abstractly, the query is doing the following. For\neach yeast gene name in the interaction set we can use\nLinkHub's data as 'glue' to determine its homologs (via\nPfam) in worm by traversing identifier type paths in the\nLinkHub relationship graph like the following:\nyeast gene name → UniProt Accession → Pfam accession\n→ UniProt Accession → WormBase ID.\nThen, for each pair in the yeast protein interaction dataset,\nwe determine if both of its yeast gene names lead to\nWormBase IDs [20] in this way and print those WormBase\nIDs as possible protein interactions if so.\nQuery 2: exploring pseudogene content versus gene\nessentiality in yeast and humans\nPseudogenes are genomic DNA sequences similar to nor\nmal genes (and usually derived from them) but are not\nexpressed into functional proteins; they are regarded as\ndefunct relatives of functional genes [21,22]. In the que\nries here we explore the relationship between gene essen\ntiality (a measure of how important a gene is to survival of\nan organism) and the number of pseudogenes in an\norganism. We might hypothesize that more essential\ngenes might have larger numbers of pseudogenes, and we\nexplore this idea with queries of the joined YeastHub and\nLinkHub data. First, YeastHub has the MIPS [23] Essential\nGenes dataset, and we use this as our data on gene essen\ntiality; LinkHub contains a small dataset of yeast pseudo-\ngenes [24].\nAbstractly, for each yeast gene name in the list of essential\ngenes, we determine its pseudogenes by traversing identi\nfier type paths in the LinkHub graph like the following:\nyeast gene name → UniProt Accession → yeast pseudog\nene\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nFor each essential yeast gene we then determine how\nmany pseudogenes it has. We can then inspect the list of\nessential genes to see if there is a relationship between\nessentiality and number of pseudogenes. Humans have a\nlarge number of known pseudogenes [25] but gene essen\ntiality is difficult to characterize in humans (with many\ntissue types and developmental states complicating the\nissue). Since essentiality is well studied in yeast, one thing\nwe can do is determine the human homologs of yeast\nessential genes, which would perhaps likely be \"more\nimportant\" in a survival sense, and examine them for pat\nterns associated with essentiality. For each yeast gene\nname in the list of essential genes, we can find the homol\nogous pseudogenes in human by traversing identifier type\npaths in the LinkHub graph like the following:\nyeast gene name → UniProt Accession → Pfam accession\n→ human UniProt Id → UniProt Accession → Pseudog\nene LSID\nPart of the SeRQL for the first query (for yeast pseudo-\ngenes) and results from both can be seen in figure 3, and\nthey show that few yeast essential genes are associated\nwith pseudogenes whereas this is not the case with\nhuman. This may reflect the difference in processes of cre\nation of the predominate numbers of yeast and human\npseudogenes (duplication vs retrotransposition, see\n[21,22]).\nDiscussion\nRelated work\nThe basic conceptual underpinnings of LinkHub, i.e., the\nimportance of biological identifiers and linking them, was\ngiven by Karp [26]. LinkHub uses a Semantic Web\napproach to build a practical system based on and extend\ning Karp's ideas on database links. The Semantic Web\napproach can also be used to implement database integra\ntion solutions based on the general approaches of data\nwarehousing [27,28] and federation [29-31]. Essentially,\ndata warehousing focuses on data translation, i.e. translat\ning and combining multiple datasets into a single data\nbase, whereas federation focuses on query translation, i.e.\ntranslating and distributing the parts of a query across\nmultiple distinct databases and collating their results into\none. A methodological overview and comparison of these\ndatabase integration approaches was discussed in the bio\nmedical context [32]. LinkHub's architecture is a hybrid of\nthese two approaches: individual LinkHub instantiations\nare a kind of mini, local data warehouse of commonly\ngrouped data and these are connected to large major hubs\nsuch as UniProt in a federated fashion; efficiency is gained\nby obviating the need for all source datasets to be individ\nually connected to the major hubs.\nPage 6 of 12\n(page number not for citation purposes)\n\nExample RDF queries\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nFigure 3\nExample RDF queries. (a) shows a part of the SeRQL query that finds pairs of worm (C. elegans) proteins homologous to\npairs of interacting proteins in yeast (C. cervisiae), i.e. \"interologs\". b) shows part of the corresponding query results. (c) shows\nthe SeRQL query that explores the relationship between gene essentiality and the level of pseudogene content in yeast, which\nis one feature that might be hypothesized to be associated with essentiality, with queries of the joined YeastHub and LinkHub\ndata. (d) shows the yeast pseudogenes found, interestingly only one. (e) shows part of the list of pseudogenes found in human\nhomologs for a similar query; the full list is long, around 20000, consistent with there being many known pseudogenes in\nhumans.\nPage 7 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nLinkHub differentiates itself by not integrating all aspects\nof biological data but rather focusing on an important and\nmore manageable high-level structuring principal, namely\nbiological identifiers and the relationships (and relation\nship types) among them; hyperlinks to identifier-specific\npages present in the \"Links\" section of the LinkHub web\ninterface give access to additional attributes and data. In\nfact, our YeastHub system addressed integration more\ngenerally by transforming many datasets to common RDF\nformat and storing and giving RDF query access to them\nin an RDF database. The problem with YeastHub was that\nthe integration was thin, with rich connections among the\nintegrated datasets being limited. LinkHub is thus useful\nand complementary to YeastHub in this respect as a \"con\nnecting glue\" among the datasets in that it makes and\nstores these cross-references and enables better integrated\naccess to the YeastHub data; the example queries above\ndemonstrated this.\nLinkHub's primary web interface can be viewed as a kind\nof \"Semantic Web browser\". Other work has also\nattempted to build browsers for Semantic Web data,\nincluding HayStack [33], Sealife [34], and BioGuide [35].\nLinkHub is a more lightweight browser than HayStack\n(with a focus on biological relationship browsing) and\ndiffers from Sealife by being data-centric (establishing\nsemantic links between data identifiers while treating web\ndocuments as metadata associated with the identifiers) as\nopposed to document-centric (establishing semantic links\nbetween terms/phrases appeared in different web docu\nments). BioGuide uses RDF similar to LinkHub, but it is\nlimited in that it focuses on abstract conceptual modelling\nof resources and their interconnections rather than on\ninstance data as LinkHub; also its interface presents the\ndata using graph drawing software with Java, whereas\nLinkHub is more lightweight and relies only on the web\nbrowser with JavaScript. Finally, there have been a\nnumber of graph database systems and query languages\ndeveloped through the years but they suffer from being\nproprietary; none have developed into widely used stand\nard systems. However, it should be pointed out that some\nof these systems support advanced graph data mining and\nanalysis operations not supported by RDF query lan\nguages and these features might be necessary for effective\nanalysis of biological data represented in RDF [36].\nFuture directions\nCurrently, LinkHub has limited web document hyperlinks\nattached to its nodes, and if this could be increased the\nutility of the novel information retrieval based on query\ning the LinkHub relational graph, e.g. \"path type\" inter\nface, would be enhanced. We are working to leverage the\nrich information in the LinkHub relational graph for\nenhanced automated information retrieval to web or sci\nentific literature (MedLine) documents relevant to identi\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nfier nodes, e.g. proteomics identifiers, in the graph. A\nsimple search for the identifier itself would likely not give\noptimal results due to conflated senses of the identifier\ntext and identifier synonyms. In general, we need to con\nsider and query for the key related concepts of an identi\nfier, and these are present in the LinkHub subgraph\nsurrounding the identifier. We consider the web pages\nattached to the identifiers in the subgraph as a \"gold\nstandard\" for what additional relevant documents should\nbe like, and we plan to use them as training sets to con\nstruct classifiers used to score and rank additional docu\nments for relevance. We feel that this idea could be\ngeneralized and that the Semantic Web, which provides\ndetailed information about terms and their relationships,\ncould be leveraged to provide enhanced automated infor\nmation retrieval or web search for Semantic Web terms.\nWe also hope to explore how other relevant Semantic\nWeb-related technologies could be effectively used in\nLinkHub, in particular named graphs [37] and Life Sci\nence IDentifiers or LSIDs [38]. Named graphs allow RDF\ngraphs to be named by URI, allowing them to be\ndescribed by RDF statements; named graphs could be\nused to provide additional information (metadata) about\nidentifier mappings, such as source, version, and quality\ninformation. LSID is a standard object naming and dis\ntributed lookup mechanism being promoted for use on\nthe Semantic Web, with emphasis on life sciences applica\ntions. An LSID names and refers to one unchanging data\nobject, and allows versioning to handle updates. The LSID\nlookup system is in essence like what Domain Name Serv\nice (DNS) does for converting named internet locations to\nIP numbers. We could possibly use LSID for naming\nobjects in LinkHub and incorporate LSID lookup func\ntionality. Finally, like software such as Napster and\nGnutella did for online file sharing, we plan to explore\nenhancing LinkHub to enable multiple distributed\nLinkHub instantiations to interact in peer-to-peer net\nworks for dynamic biological data sharing, possibly using\nweb services technologies such as Web Services Descrip\ntion Language (or WSDL) [39] and Universal Description,\nDiscovery and Integration (or UDDI) [40] for dynamic\nservice discovery, and available peer-to-peer toolkits.\nConclusion\nOur paper demonstrates the natural use of Semantic Web\nRDF to inter-connect identifiers of data entries residing in\nseparate web-accessible biological databases. Based on\nsuch a semantic RDF graph of biological identifiers and\ntheir relationships, useful, non-trivial cross-database que\nries, inferences, and semantic data navigation can be per\nformed through web interactive and query access. In\naddition, these semantic relationships enable flexible and\nnovel information retrieval access based on queries of the\nLinkHub graph's relational structure to web documents\nPage 8 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nattached to identifier nodes. LinkHub also can simplify\nand manage connections to major hubs such as UniProt\nfor a lab or organization. LinkHub can be evaluated by\nconsidering its current active and practical use in a\nnumber of settings. We have already established the \"hub\nof hubs\" relationship between UniProt and LinkHub (i.e.\nUniProt cross-references to our LinkHub). In addition,\nLinkHub cross-references the targets of the structural\ngenomics initiative to UniProt and serves as a \"related\nlinks\" and \"family viewer\" gateway for the Northeast\nStructural Genomics Consortium with which we are affil\niated; LinkHub also serves as the \"family viewer\" for Mol-\nMovDB. LinkHub is a step towards answering the\nquestion \"a life science Semantic Web: are we there yet?\"\n[41].\nMethods\nObtaining LinkHub data\nA key problem in populating the LinkHub database\n(described below) is how to determine the relationships\namong biological identifiers, a specific case of the so-\ncalled ontology alignment problem [42,43]. Biology is\nblessed with a fundamental, commonly accepted princi\nple around which data can be organized, namely biologi\ncal sequences such as DNA, RNA, and protein, and various\nstring matching techniques (such as dynamic program\nming [44] and BLAST [45]) for biological sequences can\nsolve a large part of the ontology alignment problem in\nbiology. LinkHub thus takes advantage of biological\nsequence matching, in particular conservative, exact\nsequence matching, to cross-reference or align biological\nidentifiers. LinkHub also takes advantage of available\nsources of pre-computed identifier mappings, with the\nmost important one being UniProt which is arguably the\nmost important major proteomics resource and serves as\nLinkHub's backbone content (i.e. most relationships\nbetween identifiers in LinkHub are indirect through Uni-\nProt). The general strategy for mapping identifiers in\nLinkHub is to first take advantage of known and trusted\npre-computed identifier mappings; if such pre-computed\nmappings are unavailable, an attempt is made to map\nidentifiers based on exact sequence matches of their\nunderlying sequences to UniProt and other sources of\nsequence data whose identifiers are stored in LinkHub.\nEfficient, exact sequence matching programs were devel\noped and used to do quick inter-database cross-referenc\ning or alignment based on exact sequence matches (e.g. to\ncross-reference TargetDB to UniProt, see below). A custom\nPerl module was developed and used to index UniProt\n(and in general sequence databases in FASTA format [46])\nto support this fast exact sequence matching. Specialized\nPerl web crawlers and other scripts were written to fetch\nand extract data from different sources in different for\nmats; identifiers, identifier relationships, and other\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nrelated information were extracted from the sources and\ninserted into the LinkHub MySQL database (which is also\nconverted to RDF and inserted into the RDF version of\nLinkHub; see below). A running instantiation of the\nLinkHub system is at http://hub.gersteinlab.org and http:/\n/hub.nesg.org, and it is actively used and populated with\ndata from the Gerstein Lab [47] and related to the lab's\nresearch interests. Thus while the ideas of LinkHub can be\napplicable more generally to biological data, the concrete\ninstantiation of LinkHub focuses heavily on proteomics\ndata, as that is a key research initiative of the Gerstein Lab.\nThe \"hub of hubs\" relationship described above has\nalready been established between UniProt and LinkHub\n(i.e. UniProt hyperlinks to the LinkHub instantiation and\ncross-references to it in its DR lines). In addition, LinkHub\ncross-references the proteins which are targets of the struc\ntural genomics initiative (obtained from the TargetDB\nresource [48]) to UniProt and the LinkHub instantiation\nserves as a \"related links\" and \"family viewer\" (more\nbelow) gateway for the Northeast Structural Genomics\nConsortium (NESG) [49] with which the Gerstein Lab is\naffiliated. Additional focuses of the LinkHub instantiation\nare yeast resources, macromolecular motions [13], and\npseudogenes [50].\nLinkHub database models\nLinkHub is conceptually based on the Semantic Web\n(graph) model and we thus represent it and store it in\nRDF. RDF is a popular data model (or ontological lan\nguage) for the Semantic Web that represents data as a\ndirected labelled graph. Essentially, in RDF URIs [51] are\nused for globally unique naming of the nodes (which rep\nresent objects) and the edges (which represent relation\nships between nodes) of the graph, and literal values may\nalso be used in place of pointed to nodes. In addition,\nRDF comes with query languages (e.g., RDQL [52]) to\nallow the user to pose semantic queries against graph\ndata. While there are more advanced ontological lan\nguages such as the Web Ontology Language or OWL [53]\nthat support data reasoning based on Description Logics\nor DL [54], RDF is easy to learn and use and much can be\neffectively modelled with it. For example, the benefits of\nrepresenting proteomics data in RDF were discussed [9]\nand UniProt data has also recently been made available in\nRDF format [55]. However, there could be a potential\nproblem in performance and scalability when using the\nnew RDF database technology, which can be an important\nimpediment to more active and widespread use of the\nSemantic Web. In this regard, the creation of high-per\nformance RDF databases should be a research priority of\nthe Semantic Web community. Thus, while we would ide\nally use only RDF, to support LinkHub's practical daily use\nfor its web interactive interfaces we also model and store\nits data using relational database technology (MySQL) for\nefficiency and robustness. A drawback is that relational\nPage 9 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S5\ndatabases do not naturally model graph structures or pro\nvide efficient graph operations for which special proce\ndural codes are necessary (e.g. for the \"path type\" view\ndescribed below). It is straightforward mapping between\nthe relational and RDF versions of LinkHub and we have\nwritten Java code to do this.\nThe relational structure of LinkHub, shown in figure 4a,\nreflects how the graph of biological identifier relation\nships and associated data, such as URLs of identifier-spe\ncific web pages, are managed and stored. Biological\nidentifiers are stored in the identifier table and are typed,\nwhere the identifier_types table gives the type. Thus, for\nexample, two different identifiers in separate databases\nwhich happen to have the same identifier text can never\ntheless be distinguished by differing identifier types\n(based on the databases they come from). The mappings\ntable is used to store the relationships between identifiers,\nwith the \"type\" attribute giving the description or mean\ning of the relationship. The identifier table thus gives the\nnodes and the mappings table the edges of the graph of\nbiological\nidentifier\nrelationships.\nThe\nresource,\nresource_accepts, and link_exceptions tables together\nmanage and store URLs for identifier-specific web pages\n(e.g. the web page at UniProt giving specific information\nparticular to some UniProt identifier). The basic idea is\nthat web resources such as UniProt have template URLs\nwhich can be interpolated with particular identifiers to\ngenerate identifier-specific URLs. The resource table con\ntains a short name, longer description, and the template\nURL\nof\nweb\nresources\nsuch\nas\nUniProt.\nThe\nresource_accepts table lists the particular types of identifi\ners that can be interpolated into a resource's template\nURL, as well as an exception type except_type. The excep\ntion type is to handle cases where not all identifiers of an\naccepted type are legal, i.e. some of the identifiers cannot\nbe interpolated into the template URL to generate a valid\nURL. If except_type is NONE then there are no exceptions\nand all identifiers of the type are accepted. Otherwise\nexcept_type has value NACC or ACC. If except_type is\nNACC, then the exceptions are explicitly given in the\nlink_exceptions table (i.e. the identifiers in the\nlink_exceptions table of the given type for the resource are\nthe ones that cannot be interpolated into the template\nURL, and all other identifiers of the type CAN be interpo\nlated). If except_type is ACC then the behaviour is the\nopposite: the identifiers NOT listed in the link_exceptions\ntable are the exceptions and the ones explicitly listed are\nthe only ones that can be interpolated into the resource's\ntemplate URL. NACC and ACC exception types are both\nsupported to allow the most efficient handling of excep\ntions, i.e. whichever is smaller between the set of accepted\nidentifiers and the set of exception identifiers can be listed\nin link_exceptions thus minimizing the amount of space\nnecessary for storing exceptions. The resource_group table\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nsupports grouping of web resources, e.g. all web resources\nmaintained by the Gerstein Lab or relating to protein\nstructure. Finally, the resource_attribute table allows free\ntext attributes to be associated with web resource, however\nit is not currently used. Figure 4 also provides details of\nthe LinkHub RDF model and how it is related to the rela\ntional model; a simple example RDF graph is also given.\nLinkHub web interfaces\nThe primary interactive interface to the LinkHub database\nis a web-based interface (implemented using the so-called\nAJAX technologies [56], i.e. DHTML, JavaScript, DOM,\nCSS, etc.) which presents subsets of the graph of relation\nships in a dynamic expandable/collapsible list view. This\ninterface allows viewing and exploring of the transitive\nclosure of the relationships stemming from a given iden\ntifier interactively one layer at a time: direct edges from the\ngiven identifier are initially shown and the user may then\nselectively expand fringe nodes an additional layer at a\ntime to explore further relationships (computing the full\ntransitive closure is prohibitive, and could also cause the\nuser to \"drown\" in the data, and we thus limit it initially,\nand in each subsequent expansion, to anything one edge\naway, with the user then guiding further extensions based\non which relationships he would like to explore). Figure 2\nis a screenshot of the interface and gives more details of it.\nThe second, \"path type\" interface presents results the same\nas the first interface (i.e. dynamic expandable/collapsible\nlist view) but allows users to query and view particular\nidentifier type paths in the LinkHub graph. For example,\none might want to view all proteins in some database in\nthe same Pfam family as a given protein; in LinkHub Pfam\nrelationships are stored for UniProt proteins, so one could\nview the fellow family members of the given protein by\nspecifying to view all relational paths in the LinkHub\ngraph whose identifier types match:\nGiven protein in database → equivalent UniProt protein\n→ Pfam family → UniProt proteins → other equivalent\nproteins in database.\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthors' contributions\nAKS is the primary (first) author and is responsible for the\nmajority of the work, implementation, and writing. KYY\ndid the conversion of the relational (MySQL) version of\nLinkHub to RDF, integrated it into YeastHub, and wrote\nand executed the demo RDF queries over the joined Yeast-\nHub/LinkHub. KHC, MS, and MBG are faculty advisors\nand provided high-level direction and guidance to the\nwork.\nPage 10 of 12\n(page number not for citation purposes)\n\nLinkHub relational and RDF data models\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\nFigure 4\nLinkHub relational and RDF data models. (a) LinkHub relational model (b) An example RDF graph of two statements or\ntriplets: (Q60996, gene_annotation, GO:0005634) and (Q60996, protein family, PF01603), which describe that there is a pro\ntein (Q60996) whose gene annotation is identified by GO: 0005634 and protein_family by PF01603. This also exemplifies using\nan RDF graph to connect multiple resources. Here, it connects UniProt, Gene Ontology, and Pfam. The detailed description\nassociated with each identifier can be provided by the corresponding resource (the URL or URI can provide access to such\ndetailed descriptions). (c) Illustrates how the key LinkHub relational tables identifier_types, identifiers, and mappings (repro\nduced above the RDF structure) are mapped to the corresponding RDF structure. The resulting RDF graph captures different\ntypes of object identifiers stored in different databases and the relations (or mappings) between these object identifiers. The\nmapping types are explicitly represented as RDF properties. (d) Shows how the rest of the LinkHub relational tables (repro\nduced above the RDF structure) map to the RDF structure. The resulting RDF graph captures the different web resources\n(which can be grouped) accessible by LinkHub. In addition, the graph captures information about which web resources accept\nwhich types of object identifiers, as well as exceptions.\nAcknowledgements\nAS and MG's funding for this work is from NIH/NIGMS grant P50\nGM62413-01. KC's funding for this work is from NIH grant K25 HG02378\nand NSF grant DBI-0135442.\nThis article has been published as part of BMC Bioinformatics Volume 8 Sup\nplement 3, 2007: Semantic e-Science in Biomedicine. The full contents of\nthe supplement are available online at http://www.biomedcentral.com/\n1471-2105/8?issue=S3.\nReferences\n1.\nBairoch A, Apweiler R, Wu CH, Barker WC, Boeckmann B, Ferro S,\nGasteiger E, Huang H, Lopez R, Magrane M, Martin MJ, Natale DA,\nPage 11 of 12\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8(Suppl 3):S5\nO'Donovan C, Redaschi N, Yeh LS: The Universal Protein\nResource (UniProt). Nucleic Acids Res 2005, 33:D154-D159.\n2.\nKumar A, Cheung KH, Tosches N, Masiar P, Liu Y, Miller P, Snyder\nM: The TRIPLES database: a community resource for yeast\nmolecular biology. Nucleic Acids Res 2002, 30(1):73-75.\n3.\nWorld Wide Web Consortium (W3C) [http://www.w3.org]\n4.\nAntoniou G, Van Harmelen F: A semantic Web primer Cambridge,\nMass.: MIT Press; 2004.\n5.\nBerners-Lee T, Hendler J, Lassila O: The semantic web. Scientific\nAmerican 2001:35-43.\n6.\nShadbolt N, Hall W, Berners-Lee T: The Semantic Web Revis\nited. IEEE Intelligent Systems 2006, 21(3):96-101.\n7.\nAshburner M, Ball C, Blake J, Botstein D, Butler H, Cherry J, Davis A,\nDolinski K, Dwight S, Eppig J: Gene Ontology: tool for the unifi\ncation of biology. Nature Genetics 2000, 25:25-29.\n8.\nSoldatova LN, King RD: Are the current ontologies in biology\ngood ontologies? Nat Biotechnol 2005, 23(9):1095-1098.\n9.\nWang X, Gorlitsky R, Almeida JS: From XML to RDF: how\nsemantic web technologies will change the design of 'omic'\nstandards. Nat Biotechnol 2005, 23(9):1099-1103.\n10. W3C Semantic Web Health Care and Life Sciences Interest\nGroup [http://www.w3.org/2001/sw/hcls/]\n11. MySQL Database [http://www.mysql.com]\n12. Resource Description Framework (RDF) [http://www.w3.org/\nRDF/]\n13. MolmovDB Database of Macromolecular Movements [http:/\n/www.molmovdb.org]\n14. Berman H, Westbrook J, Feng Z, Gilliland G, Bhat T, Weissig H,\nShindyalov I, Bourne P: The Protein Data Bank. Nucleic Acids\nResearch 2000, 28(1):235-242.\n15. Goh CS, Lan N, Echols N, Douglas SM, Milburn D, Bertone P, Xiao R,\nMa LC, Zheng D, Wunderlich Z, et al.: SPINE 2: a system for col\nlaborative structural proteomics within a federated data\nbase framework. Nucleic Acids Res 2003, 31(11):2833-2838.\n16. Cheung KH, Yip KY, Smith A, Deknikker R, Masiar A, Gerstein M:\nYeastHub: a semantic web use case for integrating data in\nthe life sciences domain. Bioinformatics 2005, 21(Suppl 1):i85-96.\n17. Sesame RDF Database [http://www.openrdf.org]\n18. Broekstra J, Kampman A: SeRQL: A Second Generation RDF\nQuery Language. Proc SWAD-Europe Workshop on Semantic Web\nStorage and Retrieval 2003.\n19. Yu H, Luscombe NM, Lu HX, Zhu X, Xia Y, Han JD, Bertin N, Chung\nS, Vidal M, Gerstein M: Annotation transfer between genomes:\nprotein-protein interologs and protein-DNA regulogs.\nGenome Res 2004, 14(6):1107-1118.\n20. Chen N, Harris TW, Antoshechkin I, Bastiani C, Bieri T, Blasiar D,\nBradnam K, Canaran P, Chan J, Chen CK, et al.: WormBase: a com\nprehensive data resource for Caenorhabditis biology and\ngenomics. Nucleic Acids Res 2005:D383-389.\n21. Zhang Z, Gerstein M: Large-scale analysis of pseudogenes in\nthe human genome. Curr Opin Genet Dev 2004, 14(4):328-335.\n22. Harrison PM, Gerstein M: Studying genomes through the aeons:\nprotein families, pseudogenes and proteome evolution. J Mol\nBiol 2002, 318(5):1155-1174.\n23. MIPS [http://mips.gsf.de/genre/proj/yeast/]\n24. Harrison P, Kumar A, Lan N, Echols N, Snyder M, Gerstein M: A\nsmall reservoir of disabled ORFs in the yeast genome and its\nimplications for the dynamics of proteome evolution. J Mol\nBiol 2002, 316(3):409-419.\n25. Zhang Z, Harrison PM, Liu Y, Gerstein M: Millions of years of evo\nlution preserved: a comprehensive catalog of the processed\npseudogenes in the human genome.\nGenome Res 2003,\n13(12):2541-2558.\n26. Karp PD: Database links are a foundation for interoperability.\nTrends Biotechnol 1996, 14(8):273-279.\n27. Agrawal D, El Abbadi A, Singh A, Yurek T: Efficient view mainte\nnance at data warehouses. Proceedings of the 1997 ACM SIGMOD\ninternational conference on Management of data 1997:417-427.\n28. Zdobnov EM, Lopez R, Apweiler R, Etzold T: The EBI SRS server\n- recent developments. Bioinformatics 2002, 18(2):368-373.\n29. Sheth A, Larson J: Federated Database Systems for Managing\nDistributed, Heterogeneous, and Autonomous Databases'.\nACM Computing Surveys 1990, 22(3):.\n30. Haas L, Schwarz P, Kodali P, Kotlar E, Rice J, Swope W: Discover\nyLink: A system for integrated access to life sciences data\nsources. IBM Systems Journal 2001, 40(2):489-511.\nhttp://www.biomedcentral.com/1471-2105/8/S3/S5\n31. Kolatkar PR, Sakharkar MK, Tse CR, Kiong BK, Wong L, Tan TW,\nSubbiah S: Development of software tools at BioInformatics\nCentre (BIC) at the National University of Singapore (NUS).\nPac Symp Biocomput 1998:735-746.\n32. Sujansky W: Heterogeneous database integration in biomedi\ncine. J Biomed Inform 2001, 34(4):285-298.\n33. Quan D, Huynh D, Karger D: Haystack: A Platform for Author\ning End User Semantic Web Applications. International Seman\ntic Web Conference 2003:738-753.\n34. Schroeder M, Burger A, Kostkova P, Stevens R, Habermann B, Dieng-\nKuntz R: Sealife: a semantic grid browser for the life sciences\napplied to the study of infectious diseases. Stud Health Technol\nInform 2006, 120:167-178.\n35. Cohen-Boulakia S, Froidevaux C, Pietriga E: Selecting Biological\nData Sources and Tools with XPR, a Path Language for RDF.\nPacific Symposium on Biocomputing (PSB), Maui, Hawaii 2006.\n36. Angles R, Gutierrez C: Querying RDF Data from a Graph Data\nbase Perspective.\n2nd European Semantic Web Conference\n(ESWC2005) .\n37. Carroll J, Bizer C, Hayes P, Stickler P: Named Graphs. Journal of\nWeb Semantics 2005, 3(4):.\n38. Clark T, Martin S, Liefeld T: Globally distributed object identifi\ncation for biological knowledgebases. Briefings in Bioinformatics\n2004, 5(1):59-70.\n39. WSDL - Web Service Description Language\n[http://\nwww.w3.org/TR/wsdl]\n40. UDDI.org [http://www.uddi.org/]\n41. Neumann E: A life science Semantic Web: are we there yet?\nSci STKE 2005, 2005(283):e22.\n42. Kalfoglou Y, Schorlemmer M: Ontology mapping: the state of\nthe art. The Knowledge Engineering Review 2003, 18(01):1-31.\n43. Dou D, McDermott D, Qi P: Ontology Translation on the\nSemantic Web. International Conference on Ontologies, Databases\nand Applications of Semantics 2003:952-969.\n44. Smith TF, Waterman MS: Identification of common molecular\nsubsequences. J Mol Biol 1981, 147(1):195-197.\n45. Altschul SF, Gish W, Miller W, Myers EW, Lipman DJ: Basic local\nalignment search tool. J Mol Biol 1990, 215(3):403-410.\n46. NCBI FASTA format description [http://www.ncbi.nlm.nih.gov/\nblast/fasta.shtml]\n47. Gerstein Group - Yale Bioinformatics\n[http://www.gerstein\nlab.org]\n48. TargetDB [http://targetdb.pdb.org/]\n49. Northeast Structural Genomics Consortium (NESG) [http:/\n/www.nesg.org]\n50. Pseudogene.org [http://www.pseudogene.org]\n51. Naming and Addressing: URIs, URLs, ... [http://www.w3.org/\nAddressing/]\n52. RDQL - A Query Language for RDF [http://www.w3.org/Sub\nmission/RDQL/]\n53. OWL Web Ontology Language Reference\n[http://\nwww.w3.org/TR/owl-ref/]\n54. The description logic handbook theory, implementation,\nand applications\n[http://www.cambridge.org/uk/catalogue/cata\nlogue.asp?isbn=0521781760]\n55. UniProt RDF download site\n[http://www.isb-sib.ch/~ejain/rdf/\ndata/]\n56. AJAX entry at Wikipedia [http://en.wikipedia.org/wiki/AJAX]\nPublish with BioMed Central and every\nscientist can read your work free of charge\n\"BioMed Central will be the most significant development for\ndisseminating the results of biomedical research in our lifetime.\"\nSir Paul Nurse, Cancer Research UK\nYour research papers will be:\navailable free of charge to the entire biomedical community\npeer reviewed and published immediately upon acceptance\ncited in PubMed and archived on PubMed Central\nyours -- you keep the copyright\nBioMedcentral\nSubmit your manuscript here:\nhttp://www.biomedcentral.com/info/publishing_adv.asp\nPage 12 of 12\n(page number not for citation purposes)"
    },
    {
      "category": "Resource",
      "title": "OWL Web Ontology Language Overview",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/4731eea5727fb8198b1aca08ee24acdf_owl_w3c.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nOWL Web Ontology Language\nOverview\nW3C Recommendation 10 February 2004\nThis version:\nhttp://www.w3.org/TR/2004/REC-owl-features-20040210/\nLatest version:\nhttp://www.w3.org/TR/owl-features/\nPrevious version:\nhttp://www.w3.org/TR/2003/PR-owl-features-20031215/\nEditors:\nFrank van Harmelen (Vrije Universiteit, Amsterdam) Frank.van.Harmelen@cs.vu.nl\nPlease refer to the errata for this document, which may include some normative corrections.\nSee also translations.\nCopyright (c) 2004 W3C(r) (MIT, ERCIM, Keio), All Rights Reserved. W3C liability, trademark, document use and software\nlicensing rules apply.\nDeborah L. McGuinness (Knowledge Systems Laboratory, Stanford University)\nAbstract\nThe OWL Web Ontology Language is designed for use by applications that need to process the\ncontent of information instead of just presenting information to humans. OWL facilitates greater\nmachine interpretability of Web content than that supported by XML, RDF, and RDF Schema\n(RDF-S) by providing additional vocabulary along with a formal semantics. OWL has three\nincreasingly-expressive sublanguages: OWL Lite, OWL DL, and OWL Full.\nThis document is written for readers who want a first impression of the capabilities of OWL. It\nprovides an introduction to OWL by informally describing the features of each of the sublanguages\nof OWL. Some knowledge of RDF Schema is useful for understanding this document, but not\nessential. After this document, interested readers may turn to the OWL Guide for more detailed\ndescriptions and extensive examples on the features of OWL. The normative formal definition of OWL\ncan be found in the OWL Semantics and Abstract Syntax.\nStatus of this document\nThis document has been reviewed by W3C Members and other interested parties, and it has been\nendorsed by the Director as a W3C Recommendation. W3C's role in making the Recommendation is\nto draw attention to the specification and to promote its widespread deployment. This enhances the\nfunctionality and interoperability of the Web.\nThis is one of six parts of the W3C Recommendation for OWL, the Web Ontology Language. It has\nbeen developed by the Web Ontology Working Group as part of the W3C Semantic Web Activity\n1 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\n(Activity Statement, Group Charter) for publication on 10 February 2004.\nThe design of OWL expressed in earlier versions of these documents has been widely reviewed and\nsatisfies the Working Group's technical requirements. The Working Group has addressed all\ncomments received, making changes as necessary. Changes to this document since the Proposed\nRecommendation version are detailed in the change log.\nComments are welcome at public-webont-comments@w3.org (archive) and general discussion of\nrelated technology is welcome at www-rdf-logic@w3.org (archive).\nA list of implementations is available.\nThe W3C maintains a list of any patent disclosures related to this work.\nThis section describes the status of this document at the time of its publication. Other documents may\nsupersede this document. A list of current W3C publications and the latest revision of this technical\nreport can be found in the W3C technical reports index at http://www.w3.org/TR/.\nTable of contents\n1. Introduction\n1. Document Roadmap\n2. Why OWL?\n3. The three sublanguages of OWL\n4. The structure of this document\n2. Language Synopsis\n1. OWL Lite Synopsis\n2. OWL DL and OWL Full Synopsis\n3. Language Description of OWL Lite\n1. OWL Lite RDF Schema Features\n2. OWL Lite Equality and Inequality\n3. OWL Lite Property Characteristics\n4. OWL Lite Property Restrictions\n5. OWL Lite Restricted Cardinality\n6. OWL Lite Class Intersection\n7. OWL Datatypes\n8. OWL Lite Header Information\n9. OWL Lite Annotation Properties\n10. OWL Lite Versioning\n4. Incremental Language Description of OWL DL and OWL Full\n5. Summary\nReferences\nAcknowledgements\nChange Log\n1. Introduction\nThis document describes the OWL Web Ontology Language. OWL is intended to be used when the\ninformation contained in documents needs to be processed by applications, as opposed to situations\nwhere the content only needs to be presented to humans. OWL can be used to explicitly represent\nthe meaning of terms in vocabularies and the relationships between those terms. This representation\nof terms and their interrelationships is called an ontology. OWL has more facilities for expressing\nmeaning and semantics than XML, RDF, and RDF-S, and thus OWL goes beyond these languages\nin its ability to represent machine interpretable content on the Web. OWL is a revision of the\n2 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nDAML+OIL web ontology language incorporating lessons learned from the design and application of\nDAML+OIL.\n1.1 Document Roadmap\nThe OWL Language is described by a set of documents, each fulfilling a different purpose, and\ncatering to a different audience. The following provides a brief roadmap for navigating through this\nset of documents:\nThis OWL Overview gives a simple introduction to OWL by providing a language feature listing\nwith very brief feature descriptions;\nThe OWL Guide demonstrates the use of the OWL language by providing an extended\nexample. It also provides a glossary of the terminology used in these documents;\nThe OWL Reference gives a systematic and compact (but still informally stated) description of\nall the modelling primitives of OWL;\nThe OWL Semantics and Abstract Syntax document is the final and formally stated normative\ndefinition of the language;\nThe OWL Web Ontology Language Test Cases document contains a large set of test cases for\nthe language;\nThe OWL Use Cases and Requirements document contains a set of use cases for a web\nontology language and compiles a set of requirements for OWL.\nThe suggested reading order of the first four documents is as given since they have been listed in\nincreasing degree of technical content. The last two documents complete the documentation set.\n1.2 Why OWL?\nThe Semantic Web is a vision for the future of the Web in which information is given explicit meaning,\nmaking it easier for machines to automatically process and integrate information available on the\nWeb. The Semantic Web will build on XML's ability to define customized tagging schemes and\nRDF's flexible approach to representing data. The first level above RDF required for the Semantic\nWeb is an ontology language what can formally describe the meaning of terminology used in Web\ndocuments. If machines are expected to perform useful reasoning tasks on these documents, the\nlanguage must go beyond the basic semantics of RDF Schema. The OWL Use Cases and\nRequirements Document provides more details on ontologies, motivates the need for a Web\nOntology Language in terms of six use cases, and formulates design goals, requirements and\nobjectives for OWL.\nOWL has been designed to meet this need for a Web Ontology Language. OWL is part of the\ngrowing stack of W3C recommendations related to the Semantic Web.\nXML provides a surface syntax for structured documents, but imposes no semantic constraints\non the meaning of these documents.\nXML Schema is a language for restricting the structure of XML documents and also extends\nXML with datatypes.\nRDF is a datamodel for objects (\"resources\") and relations between them, provides a simple\nsemantics for this datamodel, and these datamodels can be represented in an XML syntax.\nRDF Schema is a vocabulary for describing properties and classes of RDF resources, with a\nsemantics for generalization-hierarchies of such properties and classes.\nOWL adds more vocabulary for describing properties and classes: among others, relations\nbetween classes (e.g. disjointness), cardinality (e.g. \"exactly one\"), equality, richer typing of\nproperties, characteristics of properties (e.g. symmetry), and enumerated classes.\n1.3 The three sublanguages of OWL\n3 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nOWL provides three increasingly expressive sublanguages designed for use by specific communities\nof implementers and users.\nOWL Lite supports those users primarily needing a classification hierarchy and simple\nconstraints. For example, while it supports cardinality constraints, it only permits cardinality\nvalues of 0 or 1. It should be simpler to provide tool support for OWL Lite than its more\nexpressive relatives, and OWL Lite provides a quick migration path for thesauri and other\ntaxonomies. Owl Lite also has a lower formal complexity than OWL DL, see the section on OWL\nLite in the OWL Reference for further details.\nOWL DL supports those users who want the maximum expressiveness while retaining\ncomputational completeness (all conclusions are guaranteed to be computable) and\ndecidability (all computations will finish in finite time). OWL DL includes all OWL language\nconstructs, but they can be used only under certain restrictions (for example, while a class may\nbe a subclass of many classes, a class cannot be an instance of another class). OWL DL is so\nnamed due to its correspondence with description logics, a field of research that has studied\nthe logics that form the formal foundation of OWL.\nOWL Full is meant for users who want maximum expressiveness and the syntactic freedom of\nRDF with no computational guarantees. For example, in OWL Full a class can be treated\nsimultaneously as a collection of individuals and as an individual in its own right. OWL Full\nallows an ontology to augment the meaning of the pre-defined (RDF or OWL) vocabulary. It is\nunlikely that any reasoning software will be able to support complete reasoning for every\nfeature of OWL Full.\nEach of these sublanguages is an extension of its simpler predecessor, both in what can be legally\nexpressed and in what can be validly concluded. The following set of relations hold. Their inverses\ndo not.\nEvery legal OWL Lite ontology is a legal OWL DL ontology.\nEvery legal OWL DL ontology is a legal OWL Full ontology.\nEvery valid OWL Lite conclusion is a valid OWL DL conclusion.\nEvery valid OWL DL conclusion is a valid OWL Full conclusion.\nOntology developers adopting OWL should consider which sublanguage best suits their needs. The\nchoice between OWL Lite and OWL DL depends on the extent to which users require the\nmore-expressive constructs provided by OWL DL. The choice between OWL DL and OWL Full\nmainly depends on the extent to which users require the meta-modeling facilities of RDF Schema\n(e.g. defining classes of classes, or attaching properties to classes). When using OWL Full as\ncompared to OWL DL, reasoning support is less predictable since complete OWL Full\nimplementations do not currently exist.\nOWL Full can be viewed as an extension of RDF, while OWL Lite and OWL DL can be viewed as\nextensions of a restricted view of RDF. Every OWL (Lite, DL, Full) document is an RDF document,\nand every RDF document is an OWL Full document, but only some RDF documents will be a legal\nOWL Lite or OWL DL document. Because of this, some care has to be taken when a user wants to\nmigrate an RDF document to OWL. When the expressiveness of OWL DL or OWL Lite is deemed\nappropriate, some precautions have to be taken to ensure that the original RDF document complies\nwith the additional constraints imposed by OWL DL and OWL Lite. Among others, every URI that is\nused as a class name must be explicitly asserted to be of type owl:Class (and similarly for\nproperties), every individual must be asserted to belong to at least one class (even if only owl:Thing),\nthe URI's used for classes, properties and individuals must be mutually disjoint. The details of these\nand other constraints on OWL DL and OWL Lite are explained in appendix E of the OWL Reference.\n1.4 The structure of this document\nThis document first describes the features in OWL Lite, followed by a description of the features that\n4 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nare added in OWL DL and OWL Full (OWL DL and OWL Full contain the same features, but OWL\nFull is more liberal about how these features can be combined).\n2. Language Synopsis\nThis section provides a quick index to all the language features for OWL Lite, OWL DL, and OWL\nFull.\nIn this document, italicized terms are terms in OWL. Prefixes of rdf: or rdfs: are used when terms are\nalready present in RDF or RDF Schema. Otherwise terms are introduced by OWL. Thus, the term\nrdfs:subPropertyOf indicates that subPropertyOf is already in the rdfs vocabulary (technically : the\nrdfs namespace). Also, the term Class is more precisely stated as owl:Class and is a term introduced\nby OWL.\n2.1 OWL Lite Synopsis\nThe list of OWL Lite language constructs is given below.\nRDF Schema Features:\n(In)Equality:\nProperty Characteristics:\nClass (Thing,\nNothing)\nrdfs:subClassOf\nrdf:Property\nrdfs:subPropertyOf\nrdfs:domain\nrdfs:range\nIndividual\nequivalentClass\nequivalentProperty\nsameAs\ndifferentFrom\nAllDifferent\ndistinctMembers\nObjectProperty\nDatatypeProperty\ninverseOf\nTransitiveProperty\nSymmetricProperty\nFunctionalProperty\nInverseFunctionalProperty\nProperty Restrictions:\nRestricted Cardinality:\nHeader Information:\nRestriction\nonProperty\nallValuesFrom\nsomeValuesFrom\nminCardinality (only 0 or\n1)\nmaxCardinality (only 0 or\n1)\ncardinality (only 0 or 1)\nOntology\nimports\nClass Intersection:\nVersioning:\nAnnotation Properties:\nintersectionOf\nDatatypes\nxsd datatypes\nversionInfo\npriorVersion\nbackwardCompatibleWith\nincompatibleWith\nDeprecatedClass\nDeprecatedProperty\nrdfs:label\nrdfs:comment\nrdfs:seeAlso\nrdfs:isDefinedBy\nAnnotationProperty\nOntologyProperty\n2.2 OWL DL and Full Synopsis\nThe list of OWL DL and OWL Full language constructs that are in addition to or expand those of\n5 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nOWL Lite is given below.\nClass Axioms:\nBoolean Combinations of Class\nExpressions:\noneOf, dataRange\ndisjointWith\nunionOf\nequivalentClass\ncomplementOf\n(applied to class expressions)\nintersectionOf\nrdfs:subClassOf\n(applied to class expressions)\nArbitrary Cardinality:\nFiller Information:\nminCardinality\nhasValue\nmaxCardinality\ncardinality\n3. Language Description of OWL Lite\nThis section provides an informal description of the OWL Lite language features. We do not discuss\nthe specific syntax of these features (see the OWL Reference for definitions). Each language feature\nis hyperlinked to the appropriate place in the OWL Guide for more examples and guidance on\nusage.\nOWL Lite uses only some of the OWL language features and has more limitations on the use of the\nfeatures than OWL DL or OWL Full. For example, in OWL Lite classes can only be defined in terms\nof named superclasses (superclasses cannot be arbitrary expressions), and only certain kinds of\nclass restrictions can be used. Equivalence between classes and subclass relationships between\nclasses are also only allowed between named classes, and not between arbitrary class expressions.\nSimilarly, restrictions in OWL Lite use only named classes. OWL Lite also has a limited notion of\ncardinality - the only cardinalities allowed to be explicitly stated are 0 or 1.\n3.1 OWL Lite RDF Schema Features\nThe following OWL Lite features related to RDF Schema are included.\nClass: A class defines a group of individuals that belong together because they share some\nproperties. For example, Deborah and Frank are both members of the class Person. Classes\ncan be organized in a specialization hierarchy using subClassOf. There is a built-in most\ngeneral class named Thing that is the class of all individuals and is a superclass of all OWL\nclasses. There is also a built-in most specific class named Nothing that is the class that has no\ninstances and a subclass of all OWL classes.\nrdfs:subClassOf: Class hierarchies may be created by making one or more statements that a\nclass is a subclass of another class. For example, the class Person could be stated to be a\nsubclass of the class Mammal. From this a reasoner can deduce that if an individual is a\nPerson, then it is also a Mammal.\nrdf:Property: Properties can be used to state relationships between individuals or from\nindividuals to data values. Examples of properties include hasChild, hasRelative, hasSibling,\nand hasAge. The first three can be used to relate an instance of a class Person to another\ninstance of the class Person (and are thus occurences of ObjectProperty), and the last\n(hasAge) can be used to relate an instance of the class Person to an instance of the datatype\n6 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nInteger (and is thus an occurence of DatatypeProperty). Both owl:ObjectProperty and\nowl:DatatypeProperty are subclasses of the RDF class rdf:Property.\nrdfs:subPropertyOf: Property hierarchies may be created by making one or more statements\nthat a property is a subproperty of one or more other properties. For example, hasSibling may\nbe stated to be a subproperty of hasRelative. From this a reasoner can deduce that if an\nindividual is related to another by the hasSibling property, then it is also related to the other by\nthe hasRelative property.\nrdfs:domain: A domain of a property limits the individuals to which the property can be\napplied. If a property relates an individual to another individual, and the property has a class as\none of its domains, then the individual must belong to the class. For example, the property\nhasChild may be stated to have the domain of Mammal. From this a reasoner can deduce that\nif Frank hasChild Anna, then Frank must be a Mammal. Note that rdfs:domain is called a global\nrestriction since the restriction is stated on the property and not just on the property when it is\nassociated with a particular class. See the discussion below on property restrictions for more\ninformation.\nrdfs:range: The range of a property limits the individuals that the property may have as its\nvalue. If a property relates an individual to another individual, and the property has a class as\nits range, then the other individual must belong to the range class. For example, the property\nhasChild may be stated to have the range of Mammal. From this a reasoner can deduce that if\nLouise is related to Deborah by the hasChild property, (i.e., Deborah is the child of Louise),\nthen Deborah is a Mammal. Range is also a global restriction as is domain above. Again, see\nthe discussion below on local restrictions (e.g. AllValuesFrom) for more information.\nIndividual : Individuals are instances of classes, and properties may be used to relate one\nindividual to another. For example, an individual named Deborah may be described as an\ninstance of the class Person and the property hasEmployer may be used to relate the\nindividual Deborah to the individual StanfordUniversity.\n3.2 OWL Lite Equality and Inequality\nThe following OWL Lite features are related to equality or inequality.\nequivalentClass : Two classes may be stated to be equivalent. Equivalent classes have the\nsame instances. Equality can be used to create synonymous classes. For example, Car can be\nstated to be equivalentClass to Automobile. From this a reasoner can deduce that any\nindividual that is an instance of Car is also an instance of Automobile and vice versa.\nequivalentProperty: Two properties may be stated to be equivalent. Equivalent properties\nrelate one individual to the same set of other individuals. Equality may be used to create\nsynonymous properties. For example, hasLeader may be stated to be the equivalentProperty to\nhasHead. From this a reasoner can deduce that if X is related to Y by the property hasLeader,\nX is also related to Y by the property hasHead and vice versa. A reasoner can also deduce that\nhasLeader is a subproperty of hasHead and hasHead is a subProperty of hasLeader.\nsameAs: Two individuals may be stated to be the same. These constructs may be used to\ncreate a number of different names that refer to the same individual. For example, the\nindividual Deborah may be stated to be the same individual as DeborahMcGuinness.\ndifferentFrom: An individual may be stated to be different from other individuals. For example,\nthe individual Frank may be stated to be different from the individuals Deborah and Jim. Thus,\nif the individuals Frank and Deborah are both values for a property that is stated to be\nfunctional (thus the property has at most one value), then there is a contradiction. Explicitly\nstating that individuals are different can be important in when using languages such as OWL\n(and RDF) that do not assume that individuals have one and only one name. For example, with\nno additional information, a reasoner will not deduce that Frank and Deborah refer to distinct\nindividuals.\nAllDifferent: A number of individuals may be stated to be mutually distinct in one AllDifferent\nstatement. For example, Frank, Deborah, and Jim could be stated to be mutually distinct using\nthe AllDifferent construct. Unlike the differentFrom statement above, this would also enforce\nthat Jim and Deborah are distinct (not just that Frank is distinct from Deborah and Frank is\ndistinct from Jim). The AllDifferent construct is particularly useful when there are sets of distinct\n7 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nobjects and when modelers are interested in enforcing the unique names assumption within\nthose sets of objects. It is used in conjunction with distinctMembers to state that all members of\na list are distinct and pairwise disjoint.\n3.3 OWL Lite Property Characteristics\nThere are special identifiers in OWL Lite that are used to provide information concerning properties\nand their values. The distinction between ObjectProperty and DatatypeProperty is mentioned above\nin the property description.\ninverseOf: One property may be stated to be the inverse of another property. If the property P1\nis stated to be the inverse of the property P2, then if X is related to Y by the P2 property, then\nY is related to X by the P1 property. For example, if hasChild is the inverse of hasParent and\nDeborah hasParent Louise, then a reasoner can deduce that Louise hasChild Deborah.\nTransitiveProperty: Properties may be stated to be transitive. If a property is transitive, then if\nthe pair (x,y) is an instance of the transitive property P, and the pair (y,z) is an instance of P,\nthen the pair (x,z) is also an instance of P. For example, if ancestor is stated to be transitive,\nand if Sara is an ancestor of Louise (i.e., (Sara,Louise) is an instance of the property ancestor)\nand Louise is an ancestor of Deborah (i.e., (Louise,Deborah) is an instance of the property\nancestor), then a reasoner can deduce that Sara is an ancestor of Deborah (i.e.,\n(Sara,Deborah) is an instance of the property ancestor).\nOWL Lite (and OWL DL) impose the side condition that transitive properties (and their\nsuperproperties) cannot have a maxCardinality 1 restriction. Without this side-condition, OWL\nLite and OWL DL would become undecidable languages. See the property axiom section of the\nOWL Semantics and Abstract Syntax document for more information.\nSymmetricProperty: Properties may be stated to be symmetric. If a property is symmetric, then\nif the pair (x,y) is an instance of the symmetric property P, then the pair (y,x) is also an instance\nof P. For example, friend may be stated to be a symmetric property. Then a reasoner that is\ngiven that Frank is a friend of Deborah can deduce that Deborah is a friend of Frank.\nFunctionalProperty : Properties may be stated to have a unique value. If a property is a\nFunctionalProperty, then it has no more than one value for each individual (it may have no\nvalues for an individual). This characteristic has been referred to as having a unique property.\nFunctionalProperty is shorthand for stating that the property's minimum cardinality is zero and\nits maximum cardinality is 1. For example, hasPrimaryEmployer may be stated to be a\nFunctionalProperty. From this a reasoner may deduce that no individual may have more than\none primary employer. This does not imply that every Person must have at least one primary\nemployer however.\nInverseFunctionalProperty: Properties may be stated to be inverse functional. If a property is\ninverse functional then the inverse of the property is functional. Thus the inverse of the property\nhas at most one value for each individual. This characteristic has also been referred to as an\nunambiguous property. For example, hasUSSocialSecurityNumber (a unique identifier for\nUnited States residents) may be stated to be inverse functional (or unambiguous). The inverse\nof this property (which may be referred to as isTheSocialSecurityNumberFor) has at most one\nvalue for any individual in the class of social security numbers. Thus any one person's social\nsecurity number is the only value for their isTheSocialSecurityNumberFor property. From this a\nreasoner can deduce that no two different individual instances of Person have the identical US\nSocial Security Number. Also, a reasoner can deduce that if two instances of Person have the\nsame social security number, then those two instances refer to the same individual.\n3.4 OWL Lite Property Restrictions\nOWL Lite allows restrictions to be placed on how properties can be used by instances of a class.\nThese type (and the cardinality restrictions in the next subsection) are used within the context of an\nowl:Restriction. The owl:onProperty element indicates the restricted property. The following two\nrestrictions limit which values can be used while the next section's restrictions limit how many values\n8 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\ncan be used.\nallValuesFrom: The restriction allValuesFrom is stated on a property with respect to a class. It\nmeans that this property on this particular class has a local range restriction associated with it.\nThus if an instance of the class is related by the property to a second individual, then the\nsecond individual can be inferred to be an instance of the local range restriction class. For\nexample, the class Person may have a property called hasDaughter restricted to have\nallValuesFrom the class Woman. This means that if an individual person Louise is related by\nthe property hasDaughter to the individual Deborah, then from this a reasoner can deduce that\nDeborah is an instance of the class Woman. This restriction allows the property hasDaughter to\nbe used with other classes, such as the class Cat, and have an appropriate value restriction\nassociated with the use of the property on that class. In this case, hasDaughter would have the\nlocal range restriction of Cat when associated with the class Cat and would have the local\nrange restriction Person when associated with the class Person. Note that a reasoner can not\ndeduce from an allValuesFrom restriction alone that there actually is at least one value for the\nproperty.\nsomeValuesFrom: The restriction someValuesFrom is stated on a property with respect to a\nclass. A particular class may have a restriction on a property that at least one value for that\nproperty is of a certain type. For example, the class SemanticWebPaper may have a\nsomeValuesFrom restriction on the hasKeyword property that states that some value for the\nhasKeyword property should be an instance of the class SemanticWebTopic. This allows for\nthe option of having multiple keywords and as long as one or more is an instance of the class\nSemanticWebTopic, then the paper would be consistent with the someValuesFrom restriction.\nUnlike allValuesFrom, someValuesFrom does not restrict all the values of the property to be\ninstances of the same class. If myPaper is an instance of the SemanticWebPaper class, then\nmyPaper is related by the hasKeyword property to at least one instance of the\nSemanticWebTopic class. Note that a reasoner can not deduce (as it could with allValuesFrom\nrestrictions) that all values of hasKeyword are instances of the SemanticWebTopic class\n3.5 OWL Lite Restricted Cardinality\nOWL Lite includes a limited form of cardinality restrictions. OWL (and OWL Lite) cardinality\nrestrictions are referred to as local restrictions, since they are stated on properties with respect to a\nparticular class. That is, the restrictions constrain the cardinality of that property on instances of that\nclass. OWL Lite cardinality restrictions are limited because they only allow statements concerning\ncardinalities of value 0 or 1 (they do not allow arbitrary values for cardinality, as is the case in OWL\nDL and OWL Full).\nminCardinality: Cardinality is stated on a property with respect to a particular class. If a\nminCardinality of 1 is stated on a property with respect to a class, then any instance of that\nclass will be related to at least one individual by that property. This restriction is another way of\nsaying that the property is required to have a value for all instances of the class. For example,\nthe class Person would not have any minimum cardinality restrictions stated on a hasOffspring\nproperty since not all persons have offspring. The class Parent, however would have a\nminimum cardinality of 1 on the hasOffspring property. If a reasoner knows that Louise is a\nPerson, then nothing can be deduced about a minimum cardinality for her hasOffspring\nproperty. Once it is discovered that Louise is an instance of Parent, then a reasoner can\ndeduce that Louise is related to at least one individual by the hasOffspring property. From this\ninformation alone, a reasoner can not deduce any maximum number of offspring for individual\ninstances of the class parent. In OWL Lite the only minimum cardinalities allowed are 0 or 1. A\nminimum cardinality of zero on a property just states (in the absence of any more specific\ninformation) that the property is optional with respect to a class. For example, the property\nhasOffspring may have a minimum cardinality of zero on the class Person (while it is stated to\nhave the more specific information of minimum cardinality of one on the class Parent).\nmaxCardinality: Cardinality is stated on a property with respect to a particular class. If a\nmaxCardinality of 1 is stated on a property with respect to a class, then any instance of that\nclass will be related to at most one individual by that property. A maxCardinality 1 restriction is\n9 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nsometimes called a functional or unique property. For example, the property\nhasRegisteredVotingState on the class UnitedStatesCitizens may have a maximum cardinality\nof one (because people are only allowed to vote in only one state). From this a reasoner can\ndeduce that individual instances of the class USCitizens may not be related to two or more\ndistinct individuals through the hasRegisteredVotingState property. From a maximum\ncardinality one restriction alone, a reasoner can not deduce a minimum cardinality of 1. It may\nbe useful to state that certain classes have no values for a particular property. For example,\ninstances of the class UnmarriedPerson should not be related to any individuals by the\nproperty hasSpouse. This situation is represented by a maximum cardinality of zero on the\nhasSpouse property on the class UnmarriedPerson.\ncardinality: Cardinality is provided as a convenience when it is useful to state that a property\non a class has both minCardinality 0 and maxCardinality 0 or both minCardinality 1 and\nmaxCardinality 1. For example, the class Person has exactly one value for the property\nhasBirthMother. From this a reasoner can deduce that no two distinct individual instances of\nthe class Mother may be values for the hasBirthMother property of the same person.\nAlternate namings for these restricted forms of cardinality were discussed. Current recommendations\nare to include any such names in a front end system. More on this topic is available on the publicly\navailable webont mail archives with the most relevant message at http://lists.w3.org/Archives/Public\n/www-webont-wg/2002Oct/0063.html.\n3.6 OWL Lite Class Intersection\nOWL Lite contains an intersection constructor but limits its usage.\nintersectionOf: OWL Lite allows intersections of named classes and restrictions. For example,\nthe class EmployedPerson can be described as the intersectionOf Person and\nEmployedThings (which could be defined as things that have a minimum cardinality of 1 on the\nhasEmployer property). From this a reasoner may deduce that any particular EmployedPerson\nhas at least one employer.\n3.7 OWL Datatypes\nOWL uses the RDF mechanisms for data values. See the OWL Guide section on datatypes for a\nmore detailed description of the built-in OWL datatypes taken largely from the XML Schema\ndatatypes.\n3.8 OWL Lite Header Information\nOWL Lite supports notions of ontology inclusion and relationships and attaching information to\nontologies. See the OWL Reference for details and the OWL Guide for examples.\n3.9 OWL Lite Annotation Properties\nOWL Lite allows annotations on classes, properties, individuals and ontology headers. The use of\nthese annotations is subject to certain restrictions. See the section on Annotations in the OWL\nReference for details.\n3.10 OWL Lite Versioning\nRDF already has a small vocabulary for describing versioning information. OWL significantly extends\nthis vocabulary. See the OWL Reference for further details.\n4. Incremental Language Description of OWL DL and OWL Full\n10 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nBoth OWL DL and OWL Full use the same vocabulary although OWL DL is subject to some\nrestrictions. Roughly, OWL DL requires type separation (a class can not also be an individual or\nproperty, a property can not also be an individual or class). This implies that restrictions cannot be\napplied to the language elements of OWL itself (something that is allowed in OWL Full).\nFurthermore, OWL DL requires that properties are either ObjectProperties or DatatypeProperties:\nDatatypeProperties are relations between instances of classes and RDF literals and XML Schema\ndatatypes, while ObjectProperties are relations between instances of two classes. The OWL\nSemantics and Abstract Syntax document explains the distinctions and limitations. We describe the\nOWL DL and OWL Full vocabulary that extends the constructions of OWL Lite below.\noneOf: (enumerated classes): Classes can be described by enumeration of the individuals that\nmake up the class. The members of the class are exactly the set of enumerated individuals; no\nmore, no less. For example, the class of daysOfTheWeek can be described by simply\nenumerating the individuals Sunday, Monday, Tuesday, Wednesday, Thursday, Friday,\nSaturday. From this a reasoner can deduce the maximum cardinality (7) of any property that\nhas daysOfTheWeek as its allValuesFrom restriction.\nhasValue: (property values): A property can be required to have a certain individual as a value\n(also sometimes referred to as property values). For example, instances of the class of\ndutchCitizens can be characterized as those people that have theNetherlands as a value of\ntheir nationality. (The nationality value, theNetherlands, is an instance of the class of\nNationalities).\ndisjointWith: Classes may be stated to be disjoint from each other. For example, Man and\nWoman can be stated to be disjoint classes. From this disjointWith statement, a reasoner can\ndeduce an inconsistency when an individual is stated to be an instance of both and similarly a\nreasoner can deduce that if A is an instance of Man, then A is not an instance of Woman.\nunionOf, complementOf, intersectionOf (Boolean combinations): OWL DL and OWL Full\nallow arbitrary Boolean combinations of classes and restrictions: unionOf, complementOf, and\nintersectionOf. For example, using unionOf, we can state that a class contains things that are\neither USCitizens or DutchCitizens. Using complementOf, we could state that children are not\nSeniorCitizens. (i.e. the class Children is a subclass of the complement of SeniorCitizens).\nCitizenship of the European Union could be described as the union of the citizenship of all\nmember states.\nminCardinality, maxCardinality, cardinality (full cardinality): While in OWL Lite, cardinalities\nare restricted to at least, at most or exactly 1 or 0, full OWL allows cardinality statements for\narbitrary non-negative integers. For example the class of DINKs (\"Dual Income, No Kids\")\nwould restrict the cardinality of the property hasIncome to a minimum cardinality of two (while\nthe property hasChild would have to be restricted to cardinality 0).\ncomplex classes : In many constructs, OWL Lite restricts the syntax to single class names\n(e.g. in subClassOf or equivalentClass statements). OWL Full extends this restriction to allow\narbitrarily complex class descriptions, consisting of enumerated classes, property restrictions,\nand Boolean combinations. Also, OWL Full allows classes to be used as instances (and OWL\nDL and OWL Lite do not). For more on this topic, see the \"Design for Use\" section of the Guide\ndocument.\n5. Summary\nThis document provides an overview of the Web Ontology Language by providing a brief introduction\nto why one might need a Web ontology language and how OWL fits in with related W3C languages.\nIt also provides a brief description of the three OWL sublanguages: OWL Lite, OWL DL, and OWL\nFull along with a feature synopsis for each of the languages. This document is an update to the\nFeature Synopsis Document. It provides simple descriptions of the constructs along with simple\nexamples. It references the OWL reference document, the OWL Guide, and the OWL Semantics and\nAbstract Syntax document for more details. Previous versions ( December 15, 2003, September 5,\n2003, August 18, 2003, July 30, 2003, May 1, 2003, March 20, 2003, January 2, 2003, July 29, 2002,\nJuly 8, 2002, June 23, 2002, May 26, 2002, and May 15, 2002) of this document provide the historical\n11 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nview of the evolution of OWL Lite and the issues discussed in its evolution.\nReferences\n[OWL Guide]\nOWL Web Ontology Language Guide, Michael K. Smith, Chris Welty, and Deborah L.\nMcGuinness, Editors, W3C Recommendation, 10 February 2004, http://www.w3.org/TR/2004\n/REC-owl-guide-20040210/ . Latest version available at http://www.w3.org/TR/owl-guide/ .\n[OWL Reference]\nOWL Web Ontology Language Reference, Mike Dean and Guus Schreiber, Editors, W3C\nRecommendation, 10 February 2004, http://www.w3.org/TR/2004/REC-owl-ref-20040210/ .\nLatest version available at http://www.w3.org/TR/owl-ref/ .\n[OWL Abstract Syntax and Semantics]\nOWL Web Ontology Language Semantics and Abstract Syntax, Peter F. Patel-Schneider, Pat\nHayes, and Ian Horrocks, Editors, W3C Recommendation, 10 February 2004,\nhttp://www.w3.org/TR/2004/REC-owl-semantics-20040210/ . Latest version available at\nhttp://www.w3.org/TR/owl-semantics/ .\n[OWL Test]\nOWL Web Ontology Language Test Cases, Jeremy J. Carroll and Jos De Roo, Editors, W3C\nRecommendation, 10 February 2004, http://www.w3.org/TR/2004/REC-owl-test-20040210/ .\nLatest version available at http://www.w3.org/TR/owl-test/ .\n[OWL Requirements]\nOWL Web Ontology Language Use Cases and Requirements, Jeff Heflin, Editor, W3C\nRecommendation, 10 February 2004, http://www.w3.org/TR/2004/REC-webont-req-20040210/ .\nLatest version available at http://www.w3.org/TR/webont-req/ .\n[OWL Issues]\nWeb Ontology Issue Status. Michael K. Smith, ed. 1 November 2003.\n[DAML+OIL Reference]\nDAML+OIL Reference Description . Dan Connolly, Frank van Harmelen, Ian Horrocks, Deborah\nL. McGuinness, Peter F. Patel-Schneider, and Lynn Andrea Stein. W3C Note 18 December\n2001.\n[XML]\nExtensible Markup Language (XML).\n[XML Schema]\nXML Schema .\n[XML-SCHEMA2]\nXML Schema Part 2: Datatypes - W3C Recommendation, World Wide Web Consortium, 2 May\n2001.\n[RDF/XML Syntax]\nRDF/XML Syntax Specification (Revised), Dave Beckett, Editor, W3C Recommendation, 10\nFebruary 2004, http://www.w3.org/TR/2004/REC-rdf-syntax-grammar-20040210/ . Latest version\navailable at http://www.w3.org/TR/rdf-syntax-grammar/ .\n[RDF Concepts]\nResource Description Framework (RDF): Concepts and Abstract Syntax, Graham Klyne and\nJeremy J. Carroll, Editors, W3C Recommendation, 10 February 2004, http://www.w3.org\n/TR/2004/REC-rdf-concepts-20040210/ . Latest version available at http://www.w3.org/TR/rdf\nconcepts/ .\n[RDF Schema]\nRDF Vocabulary Description Language 1.0: RDF Schema, Dan Brickley and R. V. Guha,\nEditors, W3C Recommendation, 10 February 2004, http://www.w3.org/TR/2004/REC-rdf\nschema-20040210/ . Latest version available at http://www.w3.org/TR/rdf-schema/ .\n[RDF Semantics]\nRDF Semantics, Patrick Hayes, Editor, W3C Recommendation, 10 February 2004,\nhttp://www.w3.org/TR/2004/REC-rdf-mt-20040210/ . Latest version available at\nhttp://www.w3.org/TR/rdf-mt/ .\n12 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\n[Description Logics]\nThe Description Logic Handbook. Franz Baader, Diego Calvanese, Deborah McGuinness,\nDaniele Nardi, Peter Patel-Schneider, editors. Cambridge University Press, 2003; and\nDescription Logics Home Page.\nAcknowledgements\nThis document is the result of extensive discussions within the Web Ontology Working Group as a\nwhole. The participants in this Working Group included: Yasser alSafadi, Jean-Francois Baget,\nJames Barnette, Sean Bechhofer, Jonathan Borden, Frederik Brysse, Stephen Buswell, Jeremy\nCarroll, Dan Connolly, Peter Crowther, Jonathan Dale, Jos De Roo, David De Roure, Mike Dean,\nLarry Eshelman, Jerome Euzenat, Tim Finin, Nicholas Gibbins, Sandro Hawke, Patrick Hayes, Jeff\nHeflin, Ziv Hellman, James Hendler, Bernard Horan, Masahiro Hori, Ian Horrocks, Jane Hunter,\nFrancesco Iannuzzelli, Rudiger Klein, Natasha Kravtsova, Ora Lassila, Massimo Marchiori, Deborah\nMcGuinness, Enrico Motta, Leo Obrst, Mehrdad Omidvari, Martin Pike, Marwan Sabbouh, Guus\nSchreiber, Noboru Shimizu, Michael Sintek, Michael K. Smith, John Stanton, Lynn Andrea Stein,\nHerman ter Horst, David Trastour, Frank van Harmelen, Bernard Vatant, Raphael Volz, Evan\nWallace, Christopher Welty, Charles White, and John Yanosy.\nChange Log Since Last Call Release\nAdded owl:Nothing to OWL Lite.\nAdded pointer to last call document under title\nChanged all links to owl-absyn to owl-semantics\nIncorporated Lee Lacy's grammatical comments from public-webont-comments dated April 21,\n2003.\nIncorporated Lee Lacy's other comments: annotation properties, version properties, and other\nmissing tags in 2.2 (which got reorganised as a result)\nchanged hasOffSpring example to hasDaughter (request of Morten Frederiksen)\nincorporated all Lasilla's comment, including replacing \"machine readability\" by \"machine\ninterpretability\" and various typo's.\nAdded sentence on lower complexity class of OWL Lite, as proposed by Jim Hendler\nAdded first sentence to section 1, after Sandro Hawke's comment\nRestored link to style file\nAdded link to test document and May 1 version\nAdded references section\nChanged back to relative references to sections\nChanged links to http://www.w3.org/TR/xx from previous versions with updates later to\n...TR/2003/CR-xx-20030818/\nChange Log Since Candidate Recommendation\nAdded Change Log since candidate recommendation.\nDeleted Control Ms at the end of all lines.\nIncorporated Jeff Rafter's public webont comments.\nUpdated Status, Document links, date of publication, etc. according to PR email from chair.\nChange Log Since Proposed Recommendation\nTwo broken links fixed - W3C icon was referenced by referring to local W3c expansion\nsrc=\"OWL Web Ontology Language Overview_files/ as was gif for author. Added full expansion\nto W3C icon (http://www.w3.org/Icons/w3c_home) and email gif (http://www.w3.org/2001/sw\n/WebOnt/guide-src/Email.Deborah.McGuinness.gif).\nRemoved control Ms at the end of every line introduced with new version transfer.\nAdded links to previous version in December 2003.\n13 of 14\n10/21/2008 12:10 AM\n\nOWL Web Ontology Language Overview\nhttp://www.w3.org/TR/owl-features/\nUpdated document taking Lee Lacy's comments dated January 12, 2004. (Comments mostly\nsmall editorial changes, cell spacing change of 30 to 27 in table, ...)\nIncluded Benjamin Nowack's editorial comments.\nUpdated Reference format.\n14 of 14\n10/21/2008 12:10 AM"
    },
    {
      "category": "Resource",
      "title": "QPath: A Method for Querying Pathways in a Protein-protein Interaction Network",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/ac5d464ff020978fb70026cb8290ee18_shlomi_bmc.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nBioMed Central\nBMC Bioinformatics\nResearch article\nOpen Access\nQPath: a method for querying pathways in a protein-protein\ninteraction network\nTomer Shlomi1, Daniel Segal2, Eytan Ruppin1,3 and Roded Sharan*1\nAddress: 1School of Computer Science, Tel-Aviv University, Tel-Aviv 69978, Israel, 2Dept. of Molecular Microbiology and Biotechnology, Tel-Aviv\nUniversity, Tel-Aviv 69978, Israel and 3School of Medicine, Tel-Aviv University, Tel-Aviv, Tel-Aviv 69978, Israel\nEmail: Tomer Shlomi - shlomito@post.tau.ac.il; Daniel Segal - dsegal@post.tau.ac.il; Eytan Ruppin - ruppin@post.tau.ac.il;\nRoded Sharan* - roded@post.tau.ac.il\n* Corresponding author\nPublished: 10 April 2006\nReceived: 11 November 2005\nBMC Bioinformatics2006, 7:199\ndoi:10.1186/1471-2105-7-199\nAccepted: 10 April 2006\nThis article is available from: http://www.biomedcentral.com/1471-2105/7/199\n(c) 2006Shlomi et al; licensee BioMed Central Ltd.\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0),\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nAbstract\nBackground: Sequence comparison is one of the most prominent tools in biological research, and\nis instrumental in studying gene function and evolution. The rapid development of high-throughput\ntechnologies for measuring protein interactions calls for extending this fundamental operation to\nthe level of pathways in protein networks.\nResults: We present a comprehensive framework for protein network searches using pathway\nqueries. Given a linear query pathway and a network of interest, our algorithm, QPath, efficiently\nsearches the network for homologous pathways, allowing both insertions and deletions of proteins\nin the identified pathways. Matched pathways are automatically scored according to their variation\nfrom the query pathway in terms of the protein insertions and deletions they employ, the sequence\nsimilarity of their constituent proteins to the query proteins, and the reliability of their constituent\ninteractions. We applied QPath to systematically infer protein pathways in fly using an extensive\ncollection of 271 putative pathways from yeast. QPath identified 69 conserved pathways whose\nmembers were both functionally enriched and coherently expressed. The resulting pathways\ntended to preserve the function of the original query pathways, allowing us to derive a first\nannotated map of conserved protein pathways in fly.\nConclusion: Pathway homology searches using QPath provide a powerful approach for identifying\nbiologically significant pathways and inferring their function. The growing amounts of protein\ninteractions in public databases underscore the importance of our network querying framework\nfor mining protein network data.\nBackground\nSequence homology searches have been the workhorse of\nbioinformatics for the past 30 years, providing the means\nto study the function and evolution of genes and proteins.\nRecent technological advances in large-scale measure\nments of protein-protein interactions (PPIs) such as yeast\ntwo-hybrid screens [1,2] and protein co-immunoprecipi\ntation assays [3-5] have allowed us to shift our perspective\nfrom single genes and proteins to more complex func\ntional units, such as protein pathways and complexes.\nStudying the function and evolution of protein modules\nunderscores the importance of extending homology\nsearch tools from the single gene level to the network\nlevel.\nPage 1 of 9\n(page number not for citation purposes)\n\nThe QPath algorithmic flow\nBMC Bioinformatics 2006, 7:199\nFigure 1\nThe QPath algorithmic flow. (a) Given a query pathway,\na weighted PPI network, and sequence similarity scores\nbetween the query proteins and the network proteins, the\nQPath algorithm identifies a set of matching pathways. These\nare scored to capture the tendency of their constituent pro\nteins to have a coherent function. (b) An example of an align\nment that induces protein insertions (F') and deletions (C).\nIn contrast to the vast research on gene and protein\nhomology detection, there are only a few studies on\nhomology detection at the network level, including stud\nies on PPI networks [6-8], metabolic networks [9-12], and\ngene expression networks [13-16]. Most of these studies\nhave focused on the identification of network regions that\nare conserved across several species. Initial attempts at the\nproblem of query searches, i.e. searching for instances of a\nquery subnetwork within a given network, have been\nmade by Kelley et al. [6] and Pinter et al. [12] but both\nmethods were limited in their applicability. The Path-\nBLAST algorithm of Kelley et al. was designed to compare\ntwo protein networks and identify conserved pathways\n(linear, non-branching paths of interacting proteins). By\nconstraining one of the networks to be a single pathway,\nPathBLAST was also applied for query searches. The use of\nthe PathBLAST algorithm in this context has several draw\nbacks: (a) proteins may occur more than once in an iden\ntified\nmatched\npathway,\nwhich\nis\nbiologically\nimplausible; (b) the algorithm provides limited support\nfor identifying non-exact pathway matches, supporting no\nmore than a single consecutive deletion of proteins from\nthe query pathway and no more than a single consecutive\ninsertion of proteins to the matched pathway; and (c) the\nrunning time of the algorithm involves a factorial func\ntion of the pathway length, limiting its applicability to\nshort pathways (in practice, it was applied to paths of up\nto 5 proteins). Pinter et al. have recently developed a path\nway alignment tool called MetaPathwayHunter and\napplied it to mine metabolic networks. The algorithm\nenables fast queries of more general pathways that take\nthe form of a tree (a subnetwork with no cycles). How\never, it is limited to searching within a collection of trees\nhttp://www.biomedcentral.com/1471-2105/7/199\nrather than within a general network. Finally, Leser has\ndeveloped a query language for mining biological net\nworks [17].\nHere we give a novel comprehensive framework for que\nrying linear pathways within a given network. Our algo\nrithm, QPath, searches for matching pathways composed\nof distinct proteins that are similar to the query proteins\nin their sequence and interaction patterns. The matched\npathways are scored according to their level of variation\nfrom the query pathway in terms of protein insertions and\ndeletions, the sequence similarity of their constituent pro\nteins to the query proteins, and the reliability of their con\nstituent interactions. We provide a computational\nmethod for estimating the weight of each of these terms in\nthe overall score, so as to maximize the fraction of the\nfunctionally significant matching pathways identified.\nWe applied QPath to analyze the PPI networks of the yeast\nS. cerevisiae, the fly D. melanogaster, and human, aiming to\naddress two coupled, fundamental questions motivated\nfrom sequence analysis: (i) Can pathway homology be\nused to identify functionally significant pathways? (ii)\nCan one infer the function of a pathway based on path\nway homology information? We provide positive answers\nto both questions. Notably, our finding that matched\npathways in fly tend to preserve the function of their cor\nresponding query pathways in yeast, has enabled us to\nderive a first annotated map of protein pathways in fly\nthat are conserved from yeast.\nResults\nThe QPath algorithm\nWe developed a novel algorithm for querying a given pro\ntein network with a linear pathway of interest. The algo\nrithm searches for matching pathways that are similar to\nthe query in their sequence and interaction patterns. It\nrelies on efficient graph-theoretic techniques, allowing it\nto process long pathways (up to 10 proteins) in minutes\n(see Methods and Supp.1 Table 3). While the algorithm\ncan be applied to query any gene or protein network, we\nfocus the discussion on its applications to mining PPI net\nworks. QPath receives as input a query pathway consisting\nof a linear chain of interacting proteins; a PPI network\nwith reliability scores for its interactions; and sequence\nsimilarity scores between the query proteins and the net\nwork proteins (Figure 1a). Similar to sequence alignment,\nthe algorithm aligns the query pathway to putative path\nways in the target network, so that proteins in analogous\npositions are sequence similar. Each matched pathway\nmay contain a (bounded) number of protein insertions,\nrepresenting proteins not aligned to the query proteins,\nand protein deletions, representing omission of matches\nto some query proteins (Figure 1b). The pathways are\nscored based on a sequence score, which measures their\nPage 2 of 9\n(page number not for citation purposes)\n\nBMC Bioinformatics 2006, 7:199\nhttp://www.biomedcentral.com/1471-2105/7/199\nTable 1: Functional significance of yeast and fly pathways. Functional enrichment and expression coherency of high interaction score\npathways and random pathways in the PPI networks of yeast and fly.\nHigh interaction score pathways\nRandom pathways\nNumber of pathways\nFunctional enrichment Expression coherency (p-value) Functional enrichment\nExpression coherency (p-value)\nYeast 271\n80%\n< 1e-300\n17%\n4.0e-4\nFly\n20%\n0.024\n0%\n> 0.05\nsequence similarity to the query pathway; an interaction\nscore, which measures the reliability of their constituent\ninteractions; and the number of protein insertions and\ndeletions they employ. The top-scoring pathways are\nidentified using a dynamic programming based algorithm\nthat guarantees that matched pathways will be comprised\nof distinct proteins. The output of the algorithm is a set of\nnon-redundant, significant matching pathways. The\nQPath program is available upon request.\nPathway queries in the yeast and fly networks\nTo evaluate the utility of our algorithm in analyzing PPI\nnetworks, we applied it to the yeast and fly protein inter\naction networks, which are the largest and most well\ninvestigated networks in public databases [18]. As a first\ntest of the algorithm, similarly to [6] , we queried the yeast\nnetwork with the yeast filamentous growth MAPK cas\ncade. The algorithm correctly recovered two known\nhomologous MAPK pathways as the top matches (Supp.\nFigure 6). Next, we wished to perform a systematic evalu\nation of the algorithm's performance on the yeast and fly\nnetworks. Since the yeast network is supported by many\nmore large-scale experiments [18] and, hence, expected to\nbe more complete and accurate, we reasoned that by que\nrying putative yeast pathways within the fly network we\ncould reveal novel functional pathways therein, capitaliz\ning on the more complete information in yeast.\nTo obtain a comprehensive set of putative pathways in the\nPPI network of yeast, we applied a modified version of the\nQPath algorithm to search the network for pathways that\nhave high interaction scores (not based on specific query\npathways, see Methods). The search was limited to path\nways consisting of 6 proteins to achieve reasonable run\nning times when applying QPath to query those pathways\nwhile allowing for (up to 3) insertions and deletions. We\nidentified a set of 271 non-redundant pathways whose\nscores exceeded those of 99% of randomly chosen path\nways (see Methods). The full list of identified pathways\nappears on the supplemental website [19].\nWe used two standard methods to assess the quality of\nthese pathways (see Methods and Table 1): (i) Functional\nenrichment - representing the tendency of the pathway's\nproteins to have coherent Gene Ontology (GO) functions;\nand (ii) Expression coherency - measuring the similarity\nin expression profiles of the pathway's coding genes across\ndifferent experimental conditions. In total, 80% of the\nyeast pathways were functionally enriched. In addition,\nthe resulting pathways were significantly coherently\nexpressed (Wilcoxon rank p < 1e-300). The significant\nfunctional enrichment and expression coherency of the\nidentified pathways suggest that these pathways are bio\nlogically significant. In agreement with the expected lower\nquality of the fly network, we observed lower rates of func\ntional enrichment and expression coherency when ana\nlyzing analogously-computed high-scoring pathways in\nfly (Table 1).\nFor each significant pathway in yeast we executed the\nQPath algorithm to search for matching pathways in fly.\nIn total, 63% of the yeast queries had matches in fly with\nup to three insertions and deletions. Given a yeast query,\nthe probability of finding matching pathways in fly was\nhighly correlated with the interaction score of the query\n(Spearman p = 2.1e-04). Only few of the queries had\nmatching pathways with no insertions or deletions,\nimplying that the algorithm's support for insertions and\ndeletions was essential for identifying matching pathways\n(Figure 2a and Supp.1 Table 2a).\nA query pathway potentially gives rise to multiple match\ning pathways, each with a different sequence score, inter\naction score and indel category, defined by the number of\ninsertions and deletions employed by the pathway. In\norder to compare sequence and interaction scores for\npathways from different indel categories, we normalized\ntheir scores by the number of proteins and interactions\nthey contain, respectively. We found a statistically signifi\ncant correlation between the functional enrichment of the\nmatched pathways and their normalized interaction and\nsequence scores (Spearman p = 4e-15 and p = 0.003 for\ninteraction and sequence scores, respectively). Further\nmore, the indel category of a pathway was also found to\nbe correlated with its functional enrichment: as expected,\nfly pathways exhibiting fewer protein insertions and dele\ntions (hence, better conserving the query proteins) tended\nto be more functionally enriched than more distant path\nway matches (Figure 2b and Supp.1 Table 2b).\nMotivated by these observations, we devised a scoring\nscheme that assigns each pathway a score reflecting its\nPage 3 of 9\n(page number not for citation purposes)\n\nProperties of matched pathways in different indel categories\nBMC Bioinformatics 2006, 7:199\nFigure 2\nProperties of matched pathways in different indel\ncategories. (a) The fraction of yeast queries with identifia\nble matching fly pathway out of all yeast queries within differ\nent indel categories. (b) The fraction of matched fly pathways\nthat are functionally enriched out of all matched fly pathways\nin each indel category. Indel categories not covered by any\nmatched pathway were marked as having 0% functionally\nenriched pathways.\nestimated probability to be functionally enriched given its\ninherent characteristics, i.e., the number of insertions and\ndeletions it employs and its normalized interaction and\nsequence scores (Methods). For each yeast query we refer\nto the matched pathway with the highest obtained score\nand, hence, most likely to be functionally enriched, as the\nbest-match pathway.\nTo assess the biological significance of the best-match\npathways in fly, we compared their functional enrichment\nand expression coherency to that of fly pathways that are\nnot the results of a query. In total, 51% of the best-match\npathways were functionally enriched. Within the set of\n20% of the best-match pathways which were predicted to\nhave the highest probability to be functionally enriched,\n91% were indeed functionally enriched (Figure 3a). In\ncomparison, the percentage of functionally enriched path\nways in a set of fly pathways with the same length and dis\ntribution of interaction scores was 5%, which is\nsignificantly lower (p < 1e-4). The expression coherency of\nthe best-match pathways was also significantly higher\nthan that of randomly chosen pathways (p < 1e-4, Figure\n3b). These results suggest that best-match pathways are\nbiologically significant.\nFunction conservation in yeast to fly pathways\nNext, we investigated whether pathway similarity may be\nused to infer the function of a matched pathway based on\nthe known function of the corresponding query pathway.\nOverall, out of the 171 yeast query pathways with an iden\ntified fly best-match pathway, 69 were functionally\nenriched and had a functionally enriched fly best-match\npathway. Moreover, for 64% of these queries, the fly best-\nmatch pathways preserved one or more functions of the\ncorresponding yeast query pathways. In contrast, when\nhttp://www.biomedcentral.com/1471-2105/7/199\nrandomly shuffling the matches between fly pathways\nand yeast queries, only 31% of the fly pathways exhibited\nconservation of function (p < 1e-04). Interestingly, the\npathway-based conservation of function was also much\nhigher than the function conservation level among yeast-\nfly best sequence match proteins, which is estimated at\n40% [6].\nWe used the observed function conservation to derive a\nfunctional annotation of all fly best-match pathways,\nbased on the enriched functions of their corresponding\nqueries in yeast. Figure 4 summarizes these results in an\nannotated map of conserved fly (best-match) pathways.\nThe map exhibits a modular structure, where groups of\npathways overlap to define distinct network regions with\ncommon functions (the clustering coefficient is 0.26, sig\nnificantly higher than in random networks that preserve\nvertex degrees (p < 0.05)). To evaluate the statistical signif\nicance of these predicted annotations, we computed for\neach best-match pathway the prevalence of the predicted\nannotation among its proteins (using a hypergeometric\nscore), and compared these statistics with results obtained\nafter randomizing the matches between yeast and fly\npathways. The predicted annotations were found to be\nsignificantly more prevalent (p < 1e-04).\nQuerying known signaling pathways from yeast and\nhuman\nTo demonstrate the use of our algorithm in a BLAST-like\nmanner to query known protein pathways, we applied it\nto search the fly network for matches to queries consisting\nof known signaling pathways from yeast and human. As a\nfirst example, we used a ubiquitin-ligation pathway in\nyeast to query the fly network (Figure 5a). We identified a\nputatively homologous pathway in fly that is likely to be\ninvolved in protein degradation as well. Three out of its\nfive proteins were annotated as being involved in ubiqui\ntin-dependent protein degradation: Ubp64E is a putative\nubiquitin-specific protease; morgue is annotated as a\nubiquitin conjugating enzyme involved in apoptosis; and\nago is a bona fide component of the SCF ubiquitin ligase\ncomplex [20,21]. Eye growth defects common to Ubp64E\nand ago mutants, may suggest that this pathway functions\nin the regulation of growth and apopotosis.\nAs a second example, we used two signaling pathways in\nhuman as queries to the fly network: a MAPK cascade and\na Hedgehog signaling pathway. The top-scoring pathway\nin each case agreed well with the known functional anno\ntations in fly. The MAPK query and its best-match are\nshown in Figure 5b. As expected for a MAPK-based signal\ning cascade, Nek2 is a putative receptor signaling protein\nserine/threonine kinase. Tsp is likely a growth factor,\nbased on its EGF-like domain, which could serve as a lig\nand for Nek2. Dap160 and Fur2 are experimentally\nPage 4 of 9\n(page number not for citation purposes)\n\nFunctional significance of best-match pathways in fly\nBMC Bioinformatics 2006, 7:199\nFigure 3\nFunctional significance of best-match pathways infly\nFunctional enrichment (a) and expression coherency (b) of\nfly best-match pathways obtained by QPath compared to fly\npathways that are not the result of a query. x-axis: Fraction\nof best-match pathways in fly. y-axis in (a): Fraction of func\ntionally enriched pathways out of the set of pathways deter\nmined by x. y-axis in (b): Mean expression coherency of the\npathways determined by x. The random pathway curves\nshow the mean and standard deviation of the functional\nenrichment and expression coherency computed for random\nchoices of pathway sets in fly.\nproven to be involved in receptor processing and internal\nization, respectively [22]. Although no experimental\ninformation is available for Rgl, Rap21, Epac and pkc98E,\nall available annotations fit into a G-protein coupled\nreceptor protein signaling pathway: Rgl is a putative RAL\nGDP-dissociation stimulator, Rap21 has putative GTPase\nactivity, Epac has putative cyclic nucleotide-dependent\nguanyl-nucleotide exchange factor activity, and both\npkc98E and cdc2c are annotated as protein serine/threo\nnine kinases. Interestingly, RNAi against cdc2c causes\nabnormal growth of cells in culture [23] , and the pheno\ntype of mutant Nek2 implicates it in the regulation of\nmitosis [24]. Taken together, these evidences suggest that\nthe inferred pathway could be involved in a cell-cell com\nmunication signaling cascade that regulates cell prolifera\ntion.\nFigure 5c shows the fly pathway that best matches the\nhuman hedgehog signaling query. The known annotation\nof the pathway's proteins agrees well with its putative role\nin hedgehog signaling: ptc is a bona-fide receptor of\nhedgehog located at the plasma membrane [25]. Csk,\nannotated as a protein-tyrosine kinase, could well serve to\nfurther transmit the signal from ptc downstream. The cyc\nlin-dependent protein kinase Cdk5, in association with\nthe cyclin CycE, are well poised to further transmit the sig\nnal to the ultimate transcription factor ci. Ample experi\nmental data show that ci, like ptc participates in the\nhedgehog signaling pathway, which in flies regulates cell\ngrowth in many tissues [25].\nhttp://www.biomedcentral.com/1471-2105/7/199\nDiscussion and conclusion\nWe have presented a novel framework for querying linear\npathways in PPI networks, allowing both deletions of pro\nteins from the query pathway and insertions of proteins to\nthe matched pathway. Matched pathways are assigned\nwith scores reflecting their tendency to be functionally\nenriched, based on their variation from the query path\nway, the sequence similarity of their proteins to the query\nproteins, and the reliability of their constituent interac\ntions.\nThe effectiveness of the algorithm was demonstrated in\nquerying the fly PPI network using protein pathways from\nyeast and human. When applying the algorithm to search\nfor yeast pathway queries in fly, the matching pathways\nwere significantly more functionally enriched compared\nto arbitrary pathways in the fly network. The resulting\npathways tended to preserve the function of the original\nquery pathways, demonstrating the applicability of our\ntool for predicting pathway function much in the same\nway as gene and protein functions are predicted using\nBLAST.\nAs with any PPI network study, it is important to deal with\nthe vast amounts of noise present in the protein interac\ntion data [26-28]. To handle false positive interactions we\nhave assigned confidence scores to the interactions. To\nexamine the contribution of the confidence scores for\nfinding biologically-meaningful pathways, we repeated\nthe functional enrichment and expression coherency anal\nyses for sets of randomly chosen pathways from the yeast\nand fly networks obtained by discarding the interaction\nconfidence scores. The percent of functionally enriched\npathways and expression coherency rates found in these\nrandom sets were significantly lower than those found for\nhigh-scoring pathways (Table 1, Supp. Figure 7). Moreo\nver, for both yeast and fly we found a statistically signifi\ncant correlation between interaction scores and functional\nenrichment (Spearman correlation of 0.47 and 0.29,\nrespectively, with p < 1e-300).\nAccommodating for false negatives is a difficult challenge,\nbut QPath handles those to some extent by allowing the\nintroduction of protein indels to the matching pathway.\nIncorporating genetic interactions in the network may\nalso help to tackle the problem of false negatives, as\ngenetic interactions may indicate physical interactions\nbetween proteins [29]. In particular, for fly, the set of\ngenetic interactions reported in FlyGRID [30] has signifi\ncant overlap with the physical network, with a hyper-geo\nmetric p-value of 3.9e-7. To test whether merging genetic\nand physical interactions contributes to the identification\nof functionally significant pathways, we applied QPath to\nre-query the human MAPK pathway in the merged net\nwork of fly (Figure 5b). The pathway identified is a variant\nPage 5 of 9\n(page number not for citation purposes)\n\nFly best-match pathway map\nBMC Bioinformatics 2006, 7:199\nFigure 4\nFly best-match pathway map. A map of yeast best-match\npathways in fly. Nodes represent best-match pathways and\nedges connect pathways that share at least two proteins.\nEach node is colored according to the enriched function of\nthe corresponding query pathway in yeast. Pathways whose\npredicted annotation is also enriched among their constitu\nent proteins appear as boxes; all other pathways appear as\nellipses. Specific pathways can be looked up according to\ntheir number in the supplemental website [19].\nof the EGFR receptor-kinase-signaling cascade, and five\nout of its seven proteins appear in the curated homolo\ngous fly pathway in KEGG [31]. The hypothetical signal is\ntransmitted to the EGF receptor, and further relayed\nthrough ksr and C3G, a proven kinase and an annotated\nRas guanyl-nucleotide exchange factor, respectively, to\nRas85D. The latter has been shown experimentally to acti\nvate phl [32]. The putative signal is further transmitted to\nthe MAP kinase kinase Dsor1, and downstream to rl, an\nannotated nuclear MAP kinase which likely activates spe\ncific transcription factors. Furthermore, ksr, phl, Dsor1\nand rl are all required for modulation of the EGFR-medi\nated Ras85D mitogenic response [33]. Using genetic inter\nactions is crucial for identifying this pathway as 5 out of\nits 7 interactions are genetic. This result suggests that\nmerging both genetic and physical interactions may help\ncoping with undetected protein-protein interactions.\nWe have only just begun to explore the world of protein\nnetworks, with the first drafts of the human PPI network\njust coming out [34,35]. With an ever increasing amount\nof genomes sequenced and protein interaction networks\nrecovered, it is becoming increasingly important to\ndevelop tools for interpreting these data to provide\ndetailed models of cellular machinery across organisms.\nWe expect QPath to take a growing role in this explora\nhttp://www.biomedcentral.com/1471-2105/7/199\ntion, giving essential means to use existing knowledge for\ninferring novel pathways and their function.\nMethods\nData acquisition and processing\nProtein-protein interaction data for yeast and fly were\ndownloaded from DIP ([18] ; April 2005 download) and\ncontained 15,166 interactions among 4,726 proteins in\nyeast, and 22,837 interactions among 7,028 proteins in\nfly (for fly, we complemented the DIP data by interactions\nfrom [36] ). Additional 2378 genetic interactions in fly\nwere downloaded from FlyGRID [30]. To assign confi\ndence scores to these interactions we used the logistic-\nregression-based scheme employed in [8]. Briefly, true\npositive and true negative interactions were used to train\na logistic regression model, which assigns each interaction\na reliability score based on the experimental evidence for\nthis interaction, which includes the type of experiments in\nwhich the interaction was observed, and the number of\nobservations in each experimental type. For yeast, we par\ntitioned the experiments into four categories: co-immu\nnoprecipitation screens [3,4] , yeast two-hybrid assays\n[2,37,38] , large scale experiments (other studies denoted\nas exp:g class in DIP) and small scale experiments\n(denoted as exp:s class in DIP). For fly, due to the smaller\nnumber of interaction screens available, we used each of\nthree available large-scale screens [36,39,40] as a separate\ncategory. In addition, we used small scale fly experiments\nas a fourth category.\nPathway alignment\nWe represent a PPI network using an undirected weighted\ngraph G with a set V of n vertices, representing proteins, a\nset E of m edges, representing interactions, and an edge\nweight function w(·,·) representing interaction reliabili\nties. Given a pathway query Q = (q1,...,qk), let h(qi, j)\ndenote a sequence similarity score between query node qi\nand vertex j ∈ V. An alignment of Q in G is defined as a\npair (P, M), where P = (p1,...,pk) is a matched path in G,\nand M is a mapping of query nodes onto P ∪ {0}. The\nalignment allows up to Nins insertions and up to Ndel dele\ntions, where deleted query nodes are mapped to 0 by M.\nThe weight of an alignment is a summation of the interac\nl-1\ntion score,\nw p ,p\nand the sequence score,\n∑( i\ni+1 )\ni=1\nk\n∑\nh qi ,M pi ) . Edge weights were set to logarithm\n(\n(\n)\n\ni=1,pi ′=0\nof the reliability estimation of the corresponding interac\ntions. The sequence similarity score, h(qi, j), between\nquery node qiand vertex j∈ V was set to logarithm of the\nPage 6 of 9\n(page number not for citation purposes)\n\nYeast and human queries and their best-matches in fly\nBMC Bioinformatics 2006, 7:199\nFigure 5\nYeast and human queries and their best-matches in\nfly. Yeast and human pathway queries and their best-matches\nin fly. (a) Yeast ubiquitin ligation pathway query in fly. (b)\nHuman MAPK pathway query in fly. The pathway denoted by\nan asterisk is the result of querying a combined network of\nPPIs and genetic interactions (appearing in red). (c) Human\nHedgehog pathway query in fly.\nBLAST E-value between the corresponding proteins, nor\nmalized by the maximum score over all pairs.\nPathway search module\nThe goal of the algorithm is to identify a matched pathway\nwith distinct vertices yielding an optimal alignment to the\nquery. To this end, we adapt the color coding technique of\nAlon et al. [41] , which serves to find simple paths (i.e.,\npaths with distinct vertices) of a fixed length k in a graph.\nIn color coding, one assigns a randomly chosen color\nfrom {1,...,k} to every vertex in the graph, transforming\nthe problem of finding a simple length-k path to that of\nfinding a path of length k that spans distinct colors. Since\nany particular path may be assigned non-distinct colors\nand, hence, fail to be discovered, many random coloring\ntrials are executed. Below, we describe one iteration of\ncolor coding tailored to the query case.\nOur algorithm starts by assigning every vertex v ∈ V a color\nc(v) drawn uniformly at random from the set C ={1,...,k +\nNins}. For a given coloring, we use dynamic programming\nto find an optimal matching pathway. We let W(i, j, S,\nθdel) denote the maximum weight of an alignment for the\nfirst i nodes in the query that ends at vertex j∈ V, induces\nθdel deletions, and visits a vertex of each color in S. W(i, j,\nS, θdel) is computed recursively as follows:\n\n,\n,\n-( ) del\n,\n+ h q\n(\n(\n, )\nE\nW i( -1 m S c j ,θ\n) + w( m j )\ni , j )\nm j ∈\n\nW i j S\n, , ,θ\n) = max\nW i m S -c( ),θ\n)\nw m j )\nm j )\n(\ndel\nm V\n\n( ,\n,\n\nj\ndel +\n( ,\n( ,\n∈E\n∈\n\nW i -1 j S,θ\n-1)\nθdel ≤\n(\n, ,\ndel\nNdel\n\nhttp://www.biomedcentral.com/1471-2105/7/199\nThe maximum weight of an alignment is\nmax\n,\n∈, ⊆C,θ≤Ndel\nj V S\nW (k, j, S, θ), and the corresponding alignment is\nobtained through standard dynamic programming back\ntracking. In fact, the algorithm outputs not only the opti\nmal match but a set of high scoring matches for each\ncombination of number of insertions and deletions\nemployed. The running time of each trial depends on the\nlength of the query, the size of the network and the\nnumber of insertions and deletions allowed, and is\n2O(k+Nins)mNdel. The probability that any given path is\nassigned k distinct colors is at least e -k-Nins. Thus, for any ε\n∈ (0,1), the running time of the algorithm for obtaining\nthe optimal match with probability at least 1-ε is ln(n/\nε)2O(k+Nins)mNdel. We used ε = 0.01 for all runs of the algo\nrithm, yielding a practical time of a few minutes per query\n(Supp.1 Table 3). The resulting pathways were filtered to\nremove pathways that overlap by at least 20% of their pro\nteins.\nTo search a network for pathways with high interaction\nscores, regardless of a specific query, we ran the algorithm\nwith a dummy path query, consisting of dummy proteins\nthat were defined to have the same sequence similarity\nscore with respect to all network vertices. To search a net\nwork for random pathways, regardless of their interaction\nscore, we assigned an equal interaction score for all inter\nactions.\nPathway scoring module\nWe assigned protein pathways a functional significance\nscore that represent their tendency to be functionally\nenriched given four parameters characterizing each path\nway: a normalized sequence score, a normalized interac\ntion score, number of insertions, and number of\ndeletions. Given a set of matched pathways, logistic\nregression [42] was used to predict their functional enrich\nment based on these parameters alone. To avoid over-fit\nting, the set of pathways was partitioned into five equal\nparts. For each part, we trained the logistic regression on\nthe remaining four parts, and used the inferred parameters\nto derive the scores of the pathways in the left-out part.\nFunctional enrichment\nFunctional enrichments of protein pathways were com\nputed based on GO process annotations [43] for their pro\nteins. Yeast GO annotations were obtained from SGD [44]\n, and fly GO annotations were obtained from FlyBase\n[45]. For a given pathway P and a given term t, the func\ntional enrichment score was computed as follows: sup\npose P has let n(t) proteins that are annotated with term t\n(or with a more specific term). Let p(t) be the hypergeo-\nPage 7 of 9\n(page number not for citation purposes)\n\nBMC Bioinformatics 2006, 7:199\nmetric probability for observing n(t) or more proteins\nannotated with term t in a protein subset of size |P|. Hav\ning found a term t0 with minimal probability p(t0), the\nscore was set to the p-value of the enrichment under term\nt0, computed by comparing p(t0) with the analogous\nprobabilities for 10,000 random sets of proteins of size\n|P|.\nExpression coherency\nExpression coherency of a pathway was measured as the\nmean absolute value of the pairwise Pearson correlations\nbetween the expression patterns of the genes that code for\nthe pathway's proteins. To assess the significance of the\nexpression coherency of a set of pathways, we compared it\nto the expression coherency distribution of a random set\nof pathways with the same size distribution. Gene expres\nsion measurements were obtained from Stanford microar\nray database [46] and included 973 and 170 conditions\nfor yeast and fly, respectively.\nAuthors' contributions\nTS performed the computational analysis. DS performed\nthe biological analysis. All authors participated in design\ning the study and preparing the manuscript.\nAdditional material\nAdditional File 1\nsupplementary figures and tables. The file contains supplementary figures\n6 and 7, and tables 2 and 3.\nClick here for file\n[http://www.biomedcentral.com/content/supplementary/1471\n2105-7-199-S1.doc]\nAcknowledgements\nWe thank Trey Ideker and Vineet Bafna for helpful discussions. T.S. is grate\nful for the generous support of the Tauber Fund. E.R is supported by the\nCenter for Complexity Science. R.S. is supported by an Alon fellowship.\nThis research was supported in part by a research grant from the Ministry\nof Science and Technology, Israel.\nReferences\n1.\nFields S, Song O: A novel genetic system to detect protein-pro\ntein interactions. Nature 1989, 340(6230):245-246.\n2.\nUetz P, Giot L, Cagney G, Mansfield TA, Judson RS, Knight JR, Lock\nshon D, Narayan V, Srinivasan M, Pochart P, Qureshi-Emili A, Li Y,\nGodwin B, Conover D, Kalbfleisch T, Vijayadamodar G, Yang M, John\nston M, Fields S, Rothberg JM: A comprehensive analysis of pro\ntein-protein interactions in Saccharomyces cerevisiae.\nNature 2000, 403(6770):623-627.\n3.\nGavin AC, Bosche M, Krause R, Grandi P, Marzioch M, Bauer A,\nSchultz J, Rick JM, Michon AM, Cruciat CM, Remor M, Hofert C,\nSchelder M, Brajenovic M, Ruffner H, Merino A, Klein K, Hudak M,\nDickson D, Rudi T, Gnau V, Bauch A, Bastuck S, Huhse B, Leutwein\nC, Heurtier MA, Copley RR, Edelmann A, Querfurth E, Rybin V,\nDrewes G, Raida M, Bouwmeester T, Bork P, Seraphin B, Kuster B,\nNeubauer G, Superti-Furga G: Functional organization of the\nyeast proteome by systematic analysis of protein complexes.\nNature 2002, 415(6868):141-147.\nhttp://www.biomedcentral.com/1471-2105/7/199\n4.\nHo Y, Gruhler A, Heilbut A, Bader GD, Moore L, Adams SL, Millar A,\nTaylor P, Bennett K, Boutilier K, Yang L, Wolting C, Donaldson I,\nSchandorff S, Shewnarane J, Vo M, Taggart J, Goudreault M, Muskat B,\nAlfarano C, Dewar D, Lin Z, Michalickova K, Willems AR, Sassi H,\nNielsen PA, Rasmussen KJ, Andersen JR, Johansen LE, Hansen LH, Jes\npersen H, Podtelejnikov A, Nielsen E, Crawford J, Poulsen V,\nSorensen BD, Matthiesen J, Hendrickson RC, Gleeson F, Pawson T,\nMoran MF, Durocher D, Mann M, Hogue CW, Figeys D, Tyers M:\nSystematic identification of protein complexes in Saccharo\nmyces cerevisiae by mass spectrometry.\nNature 2002,\n415(6868):180-183.\n5.\nAebersold R, Mann M: Mass spectrometry-based proteomics.\nNature 2003, 422(6928):198-207.\n6.\nKelley BP, Sharan R, Karp RM, Sittler T, Root DE, Stockwell BR,\nIdeker T: Conserved pathways within bacteria and yeast as\nrevealed by global protein network alignment. Proc Natl Acad\nSci U S A 2003, 100(20):11394-11399.\n7.\nMatthews LR, Vaglio P, Reboul J, Ge H, Davis BP, Garrels J, Vincent S,\nVidal M: Identification of potential interaction networks using\nsequence-based searches for conserved protein-protein\ninteractions\nor\n\"interologs\".\nGenome\nRes\n2001,\n11(12):2120-2126.\n8.\nSharan R, Suthram S, Kelley RM, Kuhn T, McCuine S, Uetz P, Sittler\nT, Karp RM, Ideker T: Conserved patterns of protein interac\ntion in multiple species.\nProc Natl Acad Sci U S A 2005,\n102(6):1974-1979.\n9.\nDandekar T, Schuster S, Snel B, Huynen M, Bork P: Pathway align\nment: application to the comparative analysis of glycolytic\nenzymes. Biochem J 1999, 343 Pt 1:115-124.\n10. Ogata H, Fujibuchi W, Goto S, Kanehisa M: A heuristic graph com\nparison algorithm and its application to detect functionally\nrelated\nenzyme\nclusters.\nNucleic\nAcids\nRes\n2000,\n28(20):4021-4028.\n11. Forst CV, Schulten K: Phylogenetic analysis of metabolic path\nways. J Mol Evol 2001, 52(6):471-489.\n12. Pinter RY, Rokhlenko O, Yeger-Lotem E, Ziv-Ukelson M: Align\nment\nof\nmetabolic\npathways.\nBioinformatics\n2005,\n21(16):3401-3408.\n13. Enard W, Khaitovich P, Klose J, Zollner S, Heissig F, Giavalisco P,\nNieselt-Struwe K, Muchmore E, Varki A, Ravid R, Doxiadis GM, Bon\ntrop RE, Paabo S: Intra- and interspecific variation in primate\ngene expression patterns. Science 2002, 296(5566):340-343.\n14. Stuart JM, Segal E, Koller D, Kim SK: A gene-coexpression net\nwork for global discovery of conserved genetic modules. Sci\nence 2003, 302(5643):249-255.\n15. Bergmann S, Ihmels J, Barkai N: Similarities and differences in\ngenome-wide expression data of six organisms. PLoS Biol 2004,\n2(1):E9.\n16. Sohler F, Zimmer R: Identifying active transcription factors and\nkinases from expression data using pathway queries. Bioinfor\nmatics 2005, 21(suppl_2):ii115-ii122.\n17. Leser U: A query language for biological networks. Bioinformat\nics 2005, 21 Suppl 2:ii33-ii39.\n18. Salwinski L, Miller CS, Smith AJ, Pettit FK, Bowie JU, Eisenberg D:\nThe Database of Interacting Proteins: 2004 update. Nucleic\nAcids Res 2004, 32(Database issue):D449-51.\n19. website: QPath supplemental website. [http://www.cs.tau.ac.il/\n~shlomito/QPath/].\n20. Moberg KH, Mukherjee A, Veraksa A, Artavanis-Tsakonas S, Hariha\nran IK: The Drosophila F box protein archipelago regulates\ndMyc protein levels in vivo. Curr Biol 2004, 14(11):965-974.\n21. Moberg KH, Bell DW, Wahrer DC, Haber DA, Hariharan IK: Archi\npelago regulates Cyclin E levels in Drosophila and is mutated\nin human cancer cell lines. Nature 2001, 413(6853):311-316.\n22. Roebroek AJ, Ayoubi TA, Creemers JW, Pauli IG, Van de Ven WJ:\nThe Dfur2 gene of Drosophila melanogaster: genetic organ\nization, expression during embryogenesis, and pro-protein\nprocessing activity of its translational product Dfurin2. DNA\nCell Biol 1995, 14(3):223-234.\n23. Boutros M, Kiger AA, Armknecht S, Kerr K, Hild M, Koch B, Haas SA,\nConsortium HF, Paro R, Perrimon N: Genome-wide RNAi analy\nsis of growth and viability in Drosophila cells. Science 2004,\n303(5659):832-835.\n24. Prigent C, Glover DM, Giet R: Drosophila Nek2 protein kinase\nknockdown leads to centrosome maturation defects while\nPage 8 of 9\n(page number not for citation purposes)\n\nBMC Bioinformatics 2006, 7:199\nhttp://www.biomedcentral.com/1471-2105/7/199\noverexpression causes centrosome fragmentation and cyto\nkinesis failure. Exp Cell Res 2005, 303(1):1-13.\n25. Lum L, Beachy PA: The Hedgehog response network: sensors,\nswitches, and routers. Science 2004, 304(5678):1755-1759.\n26. Deng M, Sun F, Chen T: Assessment of the reliability of protein-\nprotein interactions and protein function prediction. Pac\nSymp Biocomput 2003:140-151.\n27. Sprinzak E, Sattath S, Margalit H: How reliable are experimental\nprotein-protein\ninteraction\ndata?\nMol\nBiol\n2003,\n5(327):919-923.\n28. von Mering C, Krause R, Snel B, Cornell M, Oliver SG, Fields S, Bork\nP: Comparative assessment of large-scale data sets of pro\ntein-protein interactions. Nature 2002, 417(6887):399-403.\n29. Wong SL, Zhang LV, Tong AH, Li Z, Goldberg DS, King OD, Lesage\nG, Vidal M, Andrews B, Bussey H, Boone C, Roth FP: Combining\nbiological networks to predict genetic interactions. Proc Natl\nAcad Sci U S A 2004, 101(44):15682-15687.\n30. Breitkreutz BJ, Stark C, Tyers M: The GRID: the General Repos\nitory for Interaction Datasets. Genome Biol 2003, 4(3):R23.\n31. Kanehisa M, Goto S: KEGG: kyoto encyclopedia of genes and\ngenomes. Nucleic Acids Res 2000, 28(1):27-30.\n32. Li W, Melnick M, Perrimon N: Dual function of Ras in Raf activa\ntion. Development 1998, 125(24):4999-5008.\n33. Karim FD, Rubin GM: Ectopic expression of activated Ras1\ninduces hyperplastic growth and increased cell death in Dro\nsophila imaginal tissues. Development 1998, 125(1):1-9.\n34. Rual JF, Venkatesan K, Hao T, Hirozane-Kishikawa T, Dricot A, Li N,\nBerriz GF, Gibbons FD, Dreze M, Ayivi-Guedehoussou N, Klitgord N,\nSimon C, Boxem M, Milstein S, Rosenberg J, Goldberg DS, Zhang LV,\nWong SL, Franklin G, Li S, Albala JS, Lim J, Fraughton C, Llamosas E,\nCevik S, Bex C, Lamesch P, Sikorski RS, Vandenhaute J, Zoghbi HY,\nSmolyar A, Bosak S, Sequerra R, Doucette-Stamm L, Cusick ME, Hill\nDE, Roth FP, Vidal M: Towards a proteome-scale map of the\nhuman protein-protein interaction network. Nature 2005.\n35. Stelzl U, Worm U, Lalowski M, Haenig C, Brembeck FH, Goehler H,\nStroedicke M, Zenkner M, Schoenherr A, Koeppen S, Timm J, Mint\nzlaff S, Abraham C, Bock N, Kietzmann S, Goedde A, Toksoz E,\nDroege A, Krobitsch S, Korn B, Birchmeier W, Lehrach H, Wanker\nEE: A human protein-protein interaction network: a resource\nfor annotating the proteome. Cell 2005, 122(6):957-968.\n36. Stanyon CA, Liu G, Mangiola BA, Patel N, Giot L, Kuang B, Zhang H,\nZhong J, Finley RLJ: A Drosophila protein-interaction map cen\ntered on cell-cycle regulators. Genome Biol 2004, 5(12):R96.\n37. Ito T, Chiba T, Ozawa R, Yoshida M, Hattori M, Sakaki Y: A compre\nhensive two-hybrid analysis to explore the yeast protein\ninteractome. Proc Natl Acad Sci U S A 2001, 98(8):4569-4574.\n38. Ito T, Tashiro K, Muta S, Ozawa R, Chiba T, Nishizawa M, Yamamoto\nK, Kuhara S, Sakaki Y: Toward a protein-protein interaction\nmap of the budding yeast: A comprehensive system to\nexamine two-hybrid interactions in all possible combinations\nbetween the yeast proteins. Proc Natl Acad Sci U S A 2000,\n97(3):1143-1147.\n39. Formstecher E, Aresta S, Collura V, Hamburger A, Meil A, Trehin A,\nReverdy C, Betin V, Maire S, Brun C, Jacq B, Arpin M, Bellaiche Y, Bel\nlusci S, Benaroch P, Bornens M, Chanet R, Chavrier P, Delattre O,\nDoye V, Fehon R, Faye G, Galli T, Girault JA, Goud B, de Gunzburg J,\nJohannes L, Junier MP, Mirouse V, Mukherjee A, Papadopoulo D,\nPerez F, Plessis A, Rosse C, Saule S, Stoppa-Lyonnet D, Vincent A,\nWhite M, Legrain P, Wojcik J, Camonis J, Daviet L: Protein interac\ntion mapping: a Drosophila case study. Genome Res 2005,\n15(3):376-384.\n40. Giot L, Bader JS, Brouwer C, Chaudhuri A, Kuang B, Li Y, Hao YL,\nOoi CE, Godwin B, Vitols E, Vijayadamodar G, Pochart P, Machineni\nH, Welsh M, Kong Y, Zerhusen B, Malcolm R, Varrone Z, Collis A,\nMinto M, Burgess S, McDaniel L, Stimpson E, Spriggs F, Williams J,\nNeurath K, Ioime N, Agee M, Voss E, Furtak K, Renzulli R, Aanensen\nN, Carrolla S, Bickelhaupt E, Lazovatsky Y, DaSilva A, Zhong J, Stan-\nyon CA, Finley RLJ, White KP, Braverman M, Jarvie T, Gold S, Leach\nM, Knight J, Shimkets RA, McKenna MP, Chant J, Rothberg JM: A pro\ntein interaction map of Drosophila melanogaster. Science\n2003, 302(5651):1727-1736.\n41. Alon N, Yuster R, Zwick U: Color-Coding. Journal of the ACM 1995,\n42(4):844-856.\n42. Hastie T, Tibshirani R, Friedman JH: The Elements of Statistical\nLearning. Springer Verlag ; 2001.\n43. Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM,\nDavis AP, Dolinski K, Dwight SS, Eppig JT, Harris MA, Hill DP, Issel-\nTarver L, Kasarskis A, Lewis S, Matese JC, Richardson JE, Ringwald M,\nRubin GM, Sherlock G: Gene ontology: tool for the unification\nof biology. The Gene Ontology Consortium. Nat Genet 2000,\n25(1):25-29.\n44. Issel-Tarver L, Christie KR, Dolinski K, Andrada R, Balakrishnan R,\nBall CA, Binkley G, Dong S, Dwight SS, Fisk DG, Harris M, Schroeder\nM, Sethuraman A, Tse K, Weng S, Botstein D, Cherry JM: Saccharo\nmyces Genome Database. Methods Enzymol 2002, 350:329-346.\n45. Drysdale RA, Crosby MA: FlyBase: genes and gene models.\nNucleic Acids Res 2005, 33(Database issue):D390-5.\n46. Ball CA, Awad IA, Demeter J, Gollub J, Hebert JM, Hernandez-Bous\nsard T, Jin H, Matese JC, Nitzberg M, Wymore F, Zachariah ZK,\nBrown PO, Sherlock G: The Stanford Microarray Database\naccommodates additional microarray platforms and data\nformats. Nucleic Acids Res 2005, 33(Database issue):D580-2.\nPublish with BioMed Central and every\nscientist can read your work free of charge\n\"BioMed Central will be the most significant development for\ndisseminating the results of biomedical research in our lifetime.\"\nSir Paul Nurse, Cancer Research UK\nYour research papers will be:\navailable free of charge to the entire biomedical community\npeer reviewed and published immediately upon acceptance\ncited in PubMed and archived on PubMed Central\nyours -- you keep the copyright\nBioMedcentral\nSubmit your manuscript here:\nhttp://www.biomedcentral.com/info/publishing_adv.asp\nPage 9 of 9\n(page number not for citation purposes)"
    },
    {
      "category": "Resource",
      "title": "Relational Databases for Querying XML Documents: Limitations and Opportunities",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/5105858b042f14c2fe1384dfab9d3fcc_inlining_vldb.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nRelational Databases for Querying XML Documents:\nLimitations and Opportunities\nJayavel Shanmugasundaram\nKristin Tufte\nGang He\nChun Zhang\nDavid DeWitt\nJeffrey Naughton\nDepartment of Computer Sciences\nUniversity of Wisconsin-Madison\n{jai, tufte, czhang, dewitt, naughton}@cs.wisc.edu, ganghe@microsoft.com\nAbstract\nXML is fast emerging as the dominant standard\nfor representing data in the World Wide Web.\nSophisticated query engines that allow users to\neffectively tap the data stored in XML\ndocuments will be crucial to exploiting the full\npower of XML. While there has been a great deal\nof activity recently proposing new semi-\nstructured data models and query languages for\nthis purpose, this paper explores the more\nconservative approach of using traditional\nrelational database engines for processing XML\ndocuments conforming to Document Type\nDescriptors (DTDs). To this end, we have\ndeveloped\nalgorithms\nand\nimplemented\na\nprototype system that converts XML documents\nto relational tuples, translates semi-structured\nqueries over XML documents to SQL queries\nover tables, and converts the results to XML. We\nhave qualitatively evaluated this approach using\nseveral real DTDs drawn from diverse domains.\nIt turns out that the relational approach can\nhandle most (but not all) of the semantics of\nsemi-structured queries over XML data, but is\nlikely to be effective only in some cases. We\nidentify the causes for these limitations and\npropose certain extensions to the relational\nPermission to copy without fee all or part of this material\nis granted provided that the copies are not made or\ndistributed for direct commercial advantage, the VLDB\ncopyright notice and the title of the publication and its\ndate appear, and notice is given that copying is by\npermission of the Very Large Data Base Endowment. To\ncopy otherwise, or to republish, requires a fee and/or\nspecial permission from the Endowment\nProceedings\nof\nthe\n25th\nVLDB\nConference,\nEdinburgh, Scotland, 1999.\nmodel that would make it more appropriate for\nprocessing queries over XML documents.\n1. Introduction\nExtensible Markup Language (XML) is fast emerging as\nthe dominant standard for representing data on the\nInternet. Like HTML, XML is a subset of SGML.\nHowever, whereas HTML tags serve the primary purpose\nof describing how to display a data item, XML tags\ndescribe the data itself. The importance of this simple\ndistinction cannot be underestimated - because XML data\nis self-describing, it is possible for programs to interpret\nthe data. This means that a program receiving an XML\ndocument can interpret it in multiple ways, can filter the\ndocument based upon its content, can restructure it to suit\nthe application's needs, and so forth.\nThe initial impetus for XML may have been primarily\nto enhance this ability of remote applications to interpret\nand operate on documents fetched over the Internet.\nHowever, from a database point of view, XML raises a\ndifferent exciting possibility: with data stored in XML\ndocuments, it should be possible to query the contents of\nthese documents. One should be able to issue queries over\nsets of XML documents to extract, synthesize, and\nanalyze their contents. But what is the best way to provide\nthis query capability over XML documents?\nAt first glance the answer is obvious. Since an XML\ndocument is an example of a semi-structured data set (it is\ntree-structured, with each node in the tree described by a\nlabel), why not use semi-structured query languages and\nquery evaluation techniques? This is indeed a viable\napproach, and there is considerable activity in the semi-\nstructured data community focussed upon exploiting this\napproach [5,14]. While semi-structured techniques will\nclearly work, in this paper we ask the question of whether\nthis is the only or the best approach to take. The downside\nof using semi-structured techniques is that this approach\nturns its back on 20 years of work invested in relational\n\ndatabase technology. Is it really the case that we cannot\nuse relational technology, and must start afresh with new\ntechniques? Or can we leverage relational technology to\nprovide query capability over XML documents?\nIn this paper we demonstrate that it is indeed possible\nto use standard commercial relational database systems to\nevaluate powerful queries over XML documents. The key\nthat makes this possible is the existence of Document\nType Descriptors (DTDs) [2] (or an equivalent, such as\nDCDs [4] or XML Schemas [16]). A DTD is in effect a\nschema for a set of XML documents. Without DTDs or\ntheir equivalent, XML will never reach its full potential,\nbecause a tagged document is not very useful without\nsome agreement among inter-operating applications as to\nwhat the tags mean. Put another way, the reason the\nInternet community is so excited about XML is that there\nis the vision of a future in which the vast majority of files\non the web are XML files conforming to DTDs. An\napplication encountering such a file can interpret the file\nby consulting the DTDs to which the document conforms.\nOur approach to querying XML documents is the\nfollowing. First, we process a DTD to generate a\nrelational schema. Second, we parse XML documents\nconforming to DTDs and load them into tuples of\nrelational tables in a standard commercial DBMS (in our\ncase, IBM DB2). Third, we translate semi-structured\nqueries (specified in a language similar to XML-QL [9] or\nLorel [1]) over XML documents into SQL queries over\nthe corresponding relational data. Finally, we convert the\nresults back to XML.\nThe good news is that this works. A main contribution\nof this paper is the description of an approach that enables\none to take the XML queries, data sets, and schemas so\nforeign to the relational world and process them in\nrelational systems without any manual intervention. This\nmeans that we are presented with a large opportunity: all\nof the power of relational database systems can be\nbrought to bear upon the XML query problem.\nHowever, the fact that something is possible does not\nnecessarily imply that it is a good idea. Our experience\nwith implementing this system and using it with over 30\ndifferent XML DTDs has revealed that there are a number\nof limitations in current relational database systems that in\nsome instances make using relational technology for\nXML queries either awkward or inefficient. Relational\ntechnology proves awkward for queries that require\ncomplex XML constructs in their results, and may be\ninefficient when fragmentation due to the handling of set-\nvalued attributes and sharing causes too many joins in the\nevaluation of simple queries. Another contribution of this\npaper is the identification of those limitations, and a\ndiscussion of how they might be removed. It is an open\nquestion at this point whether the best approach is to start\nwith relational technology and try to remove those\nlimitations, or to start with a semi-structured system and\ntry to add the power and sophistication currently found in\nrelational query processing systems.\n1.1 Related Work\nThere has been a lot of work developing special purpose\nquery engines for semi-structured data [5,14]. Many of\nthe abstracts submitted to the XML query languages\nworkshop use this approach [18]. Our goal in this paper,\nhowever, is to investigate the use of relational database\nsystems to process queries on semi-structured documents.\nIn this sense, our work is similar to the work on STORED\n[10]. However, our approach differs in important ways.\nThe STORED approach uses a combination of relational\nand semi-structured techniques to process any semi-\nstructured documents. We begin with the assumption that\nthe document conforms to a schema and store the\ndocument entirely within the relational system. Further,\nwe handle recursive queries, address the issue of\nconstructing the result in XML and evaluate the relational\napproach using real DTDs.\nOracle 8i provides some basic support for querying\nXML documents using a relational engine [17]. However,\nthe translation from document schemas to relational\nschemas is manual and not automatic as in our approach.\nIn addition, Oracle 8i does not provide support for semi-\nstructured queries over XML documents and provides\nonly primitive support for converting results to XML.\nThere has also been work on processing SGML data\nusing an OODBMS [6]. The conclusion was that this is\nfeasible with some extensions to OO query languages.\nOur work considers a more restricted set of documents\n(XML, rather than SGML) and considers mapping to the\nrelational model, rather than a general OO model.\nOur method of eliminating wild cards and alternations\nin path expression queries to enable processing by a\nrelational engine bears some similarities to the work on\ncompile time optimization of path expressions in semi-\nstructured query engines [12,15]. Our different focus,\nhowever, results in modified techniques.\n1.2 Roadmap\nThe rest of the paper is organized as follows. Section 2\ngives an overview of XML documents, schemas and\nquery languages. The algorithms for translating DTDs and\nXML documents to a relational format and an evaluation\nof the algorithms using real DTDs are given in Section 3.\nSection 4 describes the translation of queries over XML\ndocuments to SQL queries. Section 5 deals with the\nconversion of the results to XML. Section 6 concludes by\nproposing extensions to the relational model that will\nmake it more suitable for processing XML documents.\n2. Overview of XML, XML Schemas and\nXML Query Languages\nIn this section, we give a very brief overview of XML,\nXML schemas and XML query languages. Further details\ncan be obtained from the references.\n\n2.1 Extensible Markup Language\nExtensible Markup Language (XML) is a hierarchical\ndata format for information exchange in the World Wide\nWeb. An XML document consists of nested element\nstructures, starting with a root element. Element data can\nbe in the form of attributes or sub-elements. Figure 1\nshows an XML document that contains information about\na book. In this example, there is a book element that has\ntwo sub-elements, booktitle and author. The author\nelement has an id attribute with value \"dawkins\" and is\nfurther nested to provide name and address information.\nFurther information on XML can be found in [3,8].\n<book>\n<booktitle> The Selfish Gene </booktitle>\n<author id = \"dawkins\">\n<name>\n<firstname> Richard </firstname>\n<lastname> Dawkins </lastname>\n</name>\n<address>\n<city> Timbuktu </city>\n<zip> 99999 </zip>\n</address>\n</author>\n</book>\nFigure 1\n<!ELEMENT book (booktitle, author)\n<!ELEMENT article (title, author*, contactauthor)>\n<!ELEMENT contactauthor EMPTY>\n<!ATTLIST contactauthor authorID IDREF IMPLIED>\n<!ELEMENT monograph (title, author, editor)>\n<!ELEMENT editor (monograph*)>\n<!ATTLIST editor name CDATA #REQUIRED>\n<!ELEMENT author (name, address)>\n<!ATTLIST author id ID #REQUIRED>\n<!ELEMENT name (firstname?, lastname)>\n<!ELEMENT firstname (#PCDATA)>\n<!ELEMENT lastname (#PCDATA)>\n<!ELEMENT address ANY>\nFigure 2\n2.2 DTDs and other XML Sche mas\nDocument Type Descriptors (DTDs) [2] describe the\nstructure of XML documents and are like a schema for\nXML documents. A DTD specifies the structure of an\nXML element by specifying the names of its sub-elements\nand attributes. Sub-element structure is specified using the\noperators * (set with zero or more elements), + (set with\none or more elements), ? (optional), and | (or). All values\nare assumed to be string values, unless the type is ANY in\nwhich case the value can be an arbitrary XML fragment.\nThere is a special attribute, id, which can occur once for\neach element. The id attribute uniquely identifies an\nelement within a document and can be referenced through\nan IDREF field in another element. IDREFs are untyped.\nFinally, there is no concept of a root of a DTD - an XML\ndocument conforming to a DTD can be rooted at any\nelement specified in the DTD. Figure 2 shows a DTD\nspecification, while Figure 1 gives an XML document that\nconforms to this DTD.\nDocument Content Descriptors (DCDs) [4] and XML\nSchemas [16] are extensions to DTDs. For our purposes,\nthe main difference between these and DTDs is that they\nallow typing of values and set size specification. If DCDs\nand XML Schemas become standard, the additional\ninformation would aid in our translation process; for\nexample, we could create tables with integer attributes\nwhere appropriate instead of using just strings. The types\nin the current DCD proposal are compatible with types\nsupported by current relational systems. More complex\ntypes will require object-relational extensions.\n2.3\nXML Query Languages\nSELECT X.author.lastname\nFROM book X\nWHERE X.booktitle = \"The Selfish Gene\"\nFigure 3\nWHERE <book>\n<booktitle> The Selfish Gene </booktitle>\n<author>\n<lastname> $l </lastname>\n</>\n</> IN a.xml, b.xml\nCONSTRUCT <lastname> $l </lastname>\nFigure 4\nThere are many semi-structured query languages that can\nbe used to query XML documents, including XML-QL\n[9], Lorel [1], UnQL [5] and XQL (from Microsoft). All\nthese query languages have a notion of path expressions\nfor navigating the nested structure of XML. XML-QL\nuses a nested XML-like structure to specify the part of a\ndocument to be selected and the structure of the result\nXML document.\nFigure 4 shows an XML-QL query to determine the\nlast name of an author of a book having title \"The Selfish\nGene\", specified over a set of XML documents\nconforming to the DTD in Figure 2. The last names thus\nselected will be nested within a lastname tag, as specified\nin the construct clause of the query. Lorel is more like\nSQL and its representation of the same query is shown in\nFigure 3. In this paper, we use a combination of XML-QL\nand Lorel (modified appropriately for our purposes).\n\n3. Storing XML Documents in a Relational\nDatabase System\nIn this section, we describe how to generate relational\nschemas from XML DTDs. The main issues that must be\naddressed include (a) dealing with the complexity of DTD\nelement specifications (b) resolving the conflict between\nthe two-level nature of relational schemas (table and\nattribute) vs. the arbitrary nesting of XML DTD schemas\nand (c) dealing with set-valued attributes and recursion.\n3.1 Simplifying DTDs\nIn general, DTDs can be complex and generating\nrelational schemas that capture this complexity would be\nunwieldy at best. Fortunately, one can simplify the details\nof a DTD and still generate a relational schema that can\nstore and query documents conforming to that DTD.\nNote that it is not necessary to be able to regenerate a\nDTD from the generated relational schema. Rather, what\nis required is that (a) any document conforming to the\nDTD can be stored in the relational schema, and (b) any\nXML semi-structured query over a document conforming\nto the DTD can be evaluated over the relational database\ninstance.\nMost of the complexity of DTDs stems from the\ncomplex specification of the type of an element. For\ninstance, we could specify an element a as <!ELEMENT\na ((b|c|e)?,(e?|(f?,(b,b)*))*)>, where b, c, e and f are other\nelements. However, at the query language level, all that\nmatters is the position of an element in the XML\ndocument, relative to its siblings and the parent-child\nrelationship between elements in the XML document. We\nnow propose a set of transformations that can be used to\n\"simplify\" any arbitrary DTD without undermining the\neffectiveness of queries over documents conforming to\nthat DTD. These transformations are a superset of similar\ntransformations presented in [10].\ne1** A e1*\n(e1, e2)* A e1*, e2*\ne1*? A e1*\n(e1, e2)? A e1?, e2?\ne1?* A e1*\n(e1|e2) A e1?, e2?\ne1?? A e1?\nFigure 5\nFigure 6\n..., a*, ..., a*, ... A a*, ...\n..., a*, ..., a?, ... A a*, ...\n..., a?, ..., a*, ... A a*, ...\n..., a?, ..., a?, ... A a*, ...\n..., a, ..., a, ... A a*, ...\nFigure 7\nThe transformations are of three types: (a) flattening\ntransformations which convert a nested definition into a\nflat representation (i.e., one in which the binary operators\n\",\" and \"|\" do not appear inside any operator - see Figure\n5) (b) simplification transformations, which reduce many\nunary operators to a single unary operator (Figure 6) and\n(c) grouping transformations that group sub-elements\nhaving the same name (for example, two a* sub-elements\nare grouped into one a* sub-element - see Figure 7). In\naddition, all \"+\" operators are transformed to \"*\"\noperators.\nOur\nexample\nspecification\nwould\nbe\ntransformed to: <!ELEMENT a (b*, c?, e*, f*)>.\nThe transformations preserve the semantics of (a) one\nor many and (b) null or not null. The astute reader may\nnotice that we have lost some information about relative\norders of the elements. This is true; fortunately, this\ninformation can be captured when a specific XML\ndocument is loaded into this relational schema (e.g., by\nposition fields in the tuples representing some of the\nelements.) We now explore techniques for converting a\nsimplified DTD to a relational schema.\n3.2 Motivation for Special Sche ma Conversion\nTechniques\nTraditionally, relational schemas have been derived from\na data model such as the Entity-Relationship model. This\ntranslation is straightforward because there is a clear\nseparation between entities and their attributes. Each\nentity and its attributes are mapped to a relation.\nWhen converting an XML DTD to relations, it is\ntempting to map each element in the DTD to a relation\nand map the attributes of the element to attributes of the\nrelation. However, there is no correspondence between\nelements and attributes of DTDs and entities and\nattributes of the ER-Model. What would be considered\n\"attributes\" in an ER-Model are often most naturally\nrepresented as elements in a DTD.\nFigure 2 shows a\nDTD that illustrates this point. In an ER-Model, author\nwould be an \"entity\" and firstname, lastname and address\nwould be attributes of that entity. In designing a DTD,\nthere is no incentive to make author an element and\nfirstname, lastname and address attributes. In fact, in\nXML, if firstname and lastname were attributes, they\ncould not be nested under name because XML attributes\ncannot have a nested structure. Directly mapping elements\nto relations is thus likely to lead to excessive\nfragmentation of the document.\n3.3 The Basic Inlining Techniq ue\nThe Basic Inlining Technique, hereafter referred to as\nBasic, solves the fragmentation problem by inlining as\nmany descendants of an element as possible into a single\nrelation. However, Basic creates relations for every\nelement because an XML document can be rooted at any\nelement in a DTD. For example, the author element in\nFigure 2 would be mapped to a relation with attributes\nfirstname, lastname and address. In addition, relations\nwould be created for firstname, lastname and address.\nWe must address two complications: set-valued\nattributes and recursion. In the example DTD in Figure 2,\nwhen creating a relation for article, we cannot inline the\nset of authors because the traditional relational model\n\ndoes not support set-valued attributes. Rather, we follow\nthe standard technique for storing sets in an RDBMS and\ncreate a relation for author and link authors to articles\nusing a foreign key. Just using inlining (if we want the\nprocess to terminate) necessarily limits the level of\nnesting in the recursion.\nTherefore, we express the\nrecursive relationship using the notion of relational keys\nand use relational recursive processing to retrieve the\nrelationship. In order to do this in a general fashion, we\nintroduce the notion of a DTD graph.\nbook\nauthor\ntitle\ncontactauthor\nauthorID\neditor\n*\n?\n*\nname\narticle\nmonograph\nbooktitle\nname\naddress\nauthorid\n?\nfirstname\nlastname\nFigure 8\neditor\n*\nname\nmonograph\ntitle\nauthor\nname\naddress\nauthorid\n?\nfirstname\nlastname\nFigure 9\nA DTD graph represents the structure of a DTD. Its\nnodes are elements, attributes and operators in the DTD.\nEach element appears exactly once in the graph, while\nattributes and operators appear as many times as they\nappear in the DTD. The DTD graph corresponding to the\nDTD in Figure 2 is given in Figure 8. Cycles in the DTD\ngraph indicate the presence of recursion.\nThe schema created for a DTD is the union of the sets\nof relations created for each element. In order to\ndetermine the set of relations to be created for a particular\nelement, we create a graph structure called the element\ngraph. The element graph is constructed as follows.\nDo a depth first traversal of the DTD graph, starting at\nthe element node for which we are constructing relations.\nEach node is marked as \"visited\" the first time it is\nreached and is unmarked it once all its children have been\ntraversed.\nIf an unmarked node in the DTD graph is reached\nduring depth first traversal, a new node bearing the same\nname is created in the element graph. In addition, a\nregular edge is created from the most recently created\nnode in the element graph with the same name as the DFS\nparent of the current DTD node to the newly created node.\nIf an attempt is made to traverse an already marked\nDTD node, then a backpointer edge is added from the\nmost recently created node in the element graph to the\nmost recently created node in the element graph with the\nsame name as the marked DTD node.\nThe element graph for the editor element in the DTD\ngraph in Figure 8 is shown in Figure 9. Intuitively, the\nelement graph expands the relevant part of the DTD graph\ninto a tree structure.\nGiven an element graph, relations are created as\nfollows. A relation is created for the root element of the\ngraph. All the element's descendents are inlined into that\nrelation with the following two exceptions: (a) children\ndirectly below a \"*\" node are made into separate relations\n- this corresponds to creating a new relation for a set-\nvalued child; and (b) each node having a backpointer edge\npointing to it is made into a separate relation - this\ncorresponds to creating a new relation to handle recursion.\nFigure 10 shows the relational schema that would be\ngenerated for the DTD in Figure 2. There are several\nfeatures to note in the schema. Attributes in the relations\nare named by the path from the root element of the\nrelation. Each relation has an ID field that serves as the\nkey of that relation. All relations corresponding to\nelement nodes having a parent also have a parentID field\nthat serves as a foreign key. For instance, the\narticle.author\nrelation\nhas\na\nforeign\nkey\narticle.author.parentID that joins authors with articles.\nThe XML document in Figure 1 would be converted to\nthe following tuple in the book relation:\n(1, The Selfish Gene, Richard, Dawkins,\n<city>Timbuktu</city><zip>99999</zip>, dawkins)\nThe ANY field, address, is stored as an uninterpreted\nstring; thus the nested structure is not visible to the\ndatabase system without further support for XML (see\nSection 6). Note that if the author Richard Dawkins has\nauthored many books, then the author information will be\nreplicated for each book because it is replicated in the\ncorresponding XML documents.\nWhile Basic is good for certain types of queries, such\nas \"list all authors of books\", it is likely to be grossly\ninefficient for other queries. For example, queries such as\n\"list all authors having first name Jack\" will have to be\nexecuted as the union of 5 separate queries. Another\ndisadvantage of Basic is the large number of relations it\ncreates. Our next technique attempts to resolve these\nproblems.\n\nbook (bookID: integer, book.booktitle : string, book.author.name.firstname: string, book.author.name.lastname: string,\nbook.author.address: string, author.authorid: string)\nbooktitle (booktitleID: integer, booktitle: string)\narticle (articleID: integer, article.contactauthor.authorid: string, article.title: string)\narticle.author (article.authorID: integer, article.author.parentID: integer, article.author.name.firstname: string,\narticle.author.name.lastname: string, article.author.address: string, article.author.authorid: string)\ncontactauthor (contactauthorID: integer, contactauthor.authorid: string)\ntitle (titleID: integer, title: string)\nmonograph (monographID: integer, monograph.parentID: integer, monograph.title: string, monograph.editor.name: string,\nmonograph.author.name.firstname: string, monograph.author.name.lastname: string,\nmonograph.author.address: string, monograph.author.authorid: string)\neditor (editorID: integer, editor.parentID: integer, editor.name: string)\neditor.monograph (editor.monographID: integer, editor.monograph.parentID: integer, editor.monograph.title: string,\neditor.monograph.author.name.firstname: string, editor.monograph.author.name.lastname: string,\neditor.monograph.author.address: string, editor.monograph.author.authorid: string)\nauthor (authorID: integer, author.name.firstname: string, author.name.lastname: string, author.address: string,\nauthor.authorid: string)\nname (nameID: integer, name.firstname: string, name.lastname: string)\nfirstname (firstnameID: integer, firstname: string)\nlastname (lastnameID: integer, lastname: string)\naddress (addressID: integer, address: string)\nFigure 10\nbook (bookID: integer, book.booktitle.isroot: boolean, book.booktitle : string)\narticle (articleID: integer, article.contactauthor.isroot: boolean, article.contactauthor.authorid: string)\nmonograph (monographID: integer,monograph.parentID: integer, monograph.parentCODE: integer,\nmonograph.editor.isroot: boolean, monograph.editor.name: string)\ntitle (titleID: integer, title.parentID: integer, title.parentCODE: integer, title: string)\nauthor (authorID: integer, author.parentID: integer, author.parentCODE: integer, author.name.isroot: boolean,\nauthor.name.firstname.isroot: :boolean, author.name.firstname: string, author.name.lastname.isroot: boolean,\nauthor.name.lastname: string, author.address.isroot: boolean, author.address: string, author.authorid: string)\nFigure 11\n3.4 The Shared Inlining Technique\nThe Shared Inlining Technique, hereafter referred to as\nShared, attempts to avoid the drawbacks of Basic by\nensuring that an element node is represented in exactly\none relation. The principal idea behind Shared is to\nidentify the element nodes that are represented in multiple\nrelations in Basic (such as the firstname, lastname and\naddress elements in the example) and to share them by\ncreating separate relations for these elements.\nWe must first decide what relations to create. In\nShared, relations are created for all elements in the DTD\ngraph whose nodes have an in-degree greater than one.\nThese are precisely the nodes that are represented as\nmultiple relations in Basic. Nodes with an in-degree of\none are inlined. Element nodes having an in-degree of\nzero are also made separate relations, because they are not\nreachable from any other node. As in Basic, elements\nbelow a \"*\" node are made into separate relations.\nFinally, of the mutually recursive elements all having in-\ndegree one (such as monograph and editor in Figure 8),\none of them is made a separate relation. We can find such\nmutually recursive elements by looking for strongly\nconnected components in the DTD graph.\nOnce we decide which element nodes are to be made\ninto separate relations, it is relatively easy to construct the\nrelational schema. Each element node X that is a separate\nrelation inlines all the nodes Y that are reachable from it\nsuch that the path from X to Y does not contain a node\n(other than X) that is to be made a separate relation.\nFigure 11 shows the schema derived from the DTD graph\nof Figure 8. One striking feature is the small number of\nrelations compared to the Basic schema (Figure 10).\nInlining an element X into a relation corresponding to\nanother element Y creates problems when an XML\ndocument is rooted at the element X. To facilitate queries\non such elements we make use of isRoot fields.\nThe element sharing in Shared has query processing\nimplications. For example, a selection query over all\nauthors accesses only one relation in Shared compared to\nfive relations in Basic. Despite the fact that Shared\naddresses some of the shortcomings and shares some of\n\nbook (bookID: integer, book.booktitle.isroot: boolean, book.booktitle : string, author.name.firstname: string,\nauthor.name.lastname: string, author.address: string, author.authorid: string)\narticle (articleID: integer, article.contactauthor.isroot: boolean, article.contactauthor.authorid: string,\narticle.title.isroot: boolean, article.title: string)\nmonograph (monographID: integer, monograph.parentID: integer, monograph.parentCODE: integer,\nmonograph.title: string, monograph.editor.isroot: boolean, monograph.editor.name: string,\nauthor.name.firstname: string, author.name.lastname: string, author.address: string, author.authorid: string)\nauthor (authorID: integer, author.parentID: integer, author.parentCODE: integer, author.name.isroot: boolean,\nauthor.name.firstname.isroot: boolean, author.name.firstname: string, author.name.lastname.isroot: boolean,\nauthor.name.lastname: string, author.address.isroot: boolean, author.address: string, author.authorid: string)\nFigure 12\nthe strengths of Basic, Basic performs better in one\nimportant respect - reducing the number of joins starting\nat a particular element node. Thus we explore a hybrid\napproach that combines the join reduction properties of\nBasic with the sharing features of Shared\n3.5 The Hybrid Inlining Technique\nThe Hybrid Inlining Technique, or Hybrid, is the same as\nShared except that it inlines some elements that are not\ninlined in Shared. In particular, Hybrid additionally\ninlines elements with in-degree greater than one that are\nnot recursive or reached through a \"*\" node. Set sub-\nelements and recursive elements are treated as in Shared.\nFigure 12 shows the relational schema generated using\nthis hybrid approach. Note how this schema combines\nfeatures of both Basic and Shared - author is inlined with\nbook and monograph even though it is shared, while\nmonograph and editor are represented exactly once.\nSo far, we have implicitly assumed that the data model\nis unordered, i.e., the position of an element does not\nmatter. Order could, however, be easily incorporated into\nour framework by storing a position field for each\nelement.\n3.6 A Qualitative Evaluation of the Basic, Shared\nand Hybrid Techniques\nIn this section we qualitatively evaluate our relation-\nconversion algorithms using 37 DTDs available from\nRobin Cover's SGML/XML Web page [8]. We did not\npose any criterion for selecting DTDs except for\navailability for easy download and validity. Some DTDs\nwere excluded because they did not pass our XML parser,\nthe IBM alphaWorks xml4j.\n3.6.1 Evaluation Metric\nOur major concern in evaluating the algorithms is the\nefficiency of query processing. Our metric is the average\nnumber of SQL joins required to process path expressions\nof a certain length N. We use this metric because path\nexpressions are at the heart of query languages proposed\nfor semi-structured data. We are particularly concerned\nabout path expressions because we use a relational\ndatabase which uses joins to process path expressions.\nThis\nsubsection\nlogically\ncontains\n\"forward\nreferences\" to Section 4, in which we describe how SQL\nqueries are generated from semi-structured XML queries.\nHowever, the only point from Section 4 that is necessary\nto understand the results here is that a single semi-\nstructured query could give rise to a union of several SQL\nqueries, and that each of these queries may contain some\nnumber of joins. The use of Basic vs. Shared vs. Hybrid\ndetermines how many queries are generated, and how\nmany joins are found in each query. Although Basic and\nHybrid reduce the number of joins per SQL query, their\nhigher degree of inlining could cause more SQL queries\nto be generated. For each algorithm, each DTD, and a\nvariable number of path lengths, we make the following\nmeasurements:\n-\nThe average number of SQL queries generated for\npath expressions of length N.\n-\nThe average number of joins in each SQL query\nfor path expressions of length N.\n-\nThe total average number of joins in order to\nprocess path expressions of length N (the product\nof the two previous measurements.)\nIn Sections 3.6.2 and 3.6.3, we assume that path\nexpressions start from an arbitrary element in the DTD.\nWe relax this assumption in Section 3.6.4.\n3.6.2 Evaluation Results for Expression Paths of\nLength 3\nIn this section we show the results for path expressions of\nlength 3, which is the longest path length applicable to all\n37 DTDs. We shall examine the results for other path\nlengths in the next section. In the interest of space, we\nshow the results only for a subset of the DTDs and\nsummarize the others.\nFirst we consider whether the Basic approach is\npractical. For 11 of our 37 DTDs, Basic did not run to\ncompletion because it ran out of virtual memory. The\nreason for this is that Basic generates huge numbers of\nrelations if DTDs have large strongly connected\ncomponents.\nWe can see this effect clearly on some of\nthe DTDs that Basic did run to completion. One 19 node\n\naml\nbips14\nmath\nnitf-x\nofx1516\npif\nresidential\nsaej\nsmil\nvrml\naml\nbips14\nmath\nnitf-x\nofx1516\npif\nresidential\nsaej\nsmil\nvrml\nDTD has a SCC size of 4, and the number of relations\ncreated is 204 times as many as created by Hybrid,\ntotalling 3462 relations. Due to this severe limitation of\nBasic, we concentrate on the comparisons between\nShared and Hybrid.\nproduces at least the number of SQL queries as Shared.\nFigure 15 shows the total number of joins.\nUsing the average total number of joins required to\nprocess path expressions of length 3, we can roughly\ncategorize the 37 DTDs into four groups:\nGroup 1. DTDs for which Hybrid reduces a large\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\naml\nbips14\nmath\nnitf-x\nofx1516\npif\nresidential\nsaej\nsmil\nvrml\nJoins/Query\nShared\nHybrid\npercentage of joins per SQL query but incurs a smaller\nincrease in the number of SQL queries. The net result is\nHybrid requires fewer joins than Shared. Example: DTD\n\"ofx1516\".\nGroup 2. DTDs for which Hybrid reduces a large\npercentage of joins per SQL query and incurs a\ncomparable increase in the number of SQL queries. The\ntotal number of joins is about the same. Example: DTD\n\"vrml\".\nGroup 3. DTDs for which Hybrid reduces some joins\nper SQL query, but not enough to offset the increase in\nthe number of SQL queries; therefore Hybrid generates\nFigure 13\nmore joins for a path expression than Shared. Example:\nDTD \"saej\".\nGroup 4. DTDs for which both Shared and Hybrid\nproduce about the same number of joins per SQL query,\nand about the same number of SQL queries, resulting in\napproximately the same total number of joins. Example:\nDTD \"math\".\nHybrid inlines more than Shared in Groups 1, 2 and 3.\nThis reduces the number of joins per SQL query but\nincreases the number of SQL queries. The net increase or\ndecrease in the total number of joins depends on the\nstructure of the DTD. In Group 4, most of the shared\nnodes are either set nodes or involved in recursion. Since\nShared and Hybrid treat set nodes and recursive nodes\n1.8\n1.6\n1.4\n1.2\n0.8\n0.6\n0.4\n0.2\nShared\nHybrid\nTotal Joins\nQueries\nFigure 14\nidentically, there is no significant difference in their\nperformance in Group 4.\nShared\nHybrid\nGroup 1\nGroup 2\nGroup 3\nGroup 4\nNum\nDTDs\n2.5\n1.5\n0.5\nThe number of DTDs in each group from all 37 DTDs\nis summarized in the table above. We can infer that in a\nlarge number of DTDs (Group 4), most of the shared\nnodes are either set nodes or recursive nodes.\n3.6.3 Results for Path Expressions of Other Lengths\nFigure 15\nFigures 13, 14 and 15 show results for 10 of the\nDTDs. As shown in Figure 13, Hybrid eliminates a large\nnumber of joins for some DTDs, whereas for others,\nHybrid and Shared produce about the same number of\njoins. Figure 14 shows that for some DTDs, querying over\n3-length path expressions using Hybrid requires more\nSQL queries than using Shared, while for other DTDs, the\nnumber of SQL queries is the same. Note that for any path\nexpression, Shared always produces at least the number of\njoins per SQL query as Hybrid, and Hybrid always\nIn the previous section, we showed the results for path\nexpressions of length 3. In order to see how the results\ncarry over to other path lengths, let us examine how the\nnumber of joins scales with the path length. We found\nthat for almost all the DTDs, the number of joins scales\nlinearly with the path length, the only difference is the\nscaling factor, which is determined by the structure of the\nDTD. Furthermore, the gap between the performance of\nShared and Hybrid typically widens when the path\nlengthens. Figure 16 and Figure 17 show the scaling for\ntwo DTDs in group 1 and group 3 respectively.\n\nPath Length\nTotal Joins\nShared\nHybrid\nFigure 16\n10 11\nPath Length\nTotal Joins\nShared\nHybrid\nFigure 17\n3.6.4 Evaluation Using Path Expressions Starting\nFrom the Document Root\nSo far, we have examined the performance of our\nalgorithms assuming path expressions start from an\narbitrary node in the DTD graph. What is different if the\npath expressions start from the root of a document? The\nreal difference is in the total number of joins. A path\nexpression starting from the root of a document is always\nconverted to one SQL query - therefore the total number\nof joins is equivalent to the number of joins per SQL\nquery. Since the Hybrid algorithm always produces fewer\njoins per SQL query, it is always better than Shared for\npath expressions that start from the document root.\nFor DTDs in groups 3 and 4 (the majority of DTDs),\nboth Shared and Hybrid are practically the same. The\nmain issue is the excessive fragmentation of the DTDs\nthat leads to the number of joins being almost equal to the\nlength of the path expression (Figure 17). This is likely to\nbe very inefficient in the relational model, especially for\nlong path lengths. The main cause of this fragmentation is\nthe presence of set sub-elements. Section 6 includes a\nproposed extension to alleviate this problem.\n4. Converting Semi-Structured Queries to\nSQL\nSemi-structured query languages have a lot more\nflexibility than SQL. In particular, they allow path\nexpressions with various operators and wild cards. The\nchallenge is to rewrite these queries in SQL exploiting\nDTD information. In this section, we consider only\nqueries with string values as results. Queries with more\ncomplex result formats are dealt with in Section 5. For\nease of exposition, we present the translation algorithm\nonly in the context of the Shared approach. The\ngeneralization to the other approaches is straightforward.\n4.1 Converting Queries with Si mple Path\nExpressions to SQL\nConsider the following XML-QL query, and an\nequivalent Lorel-like query, over the DTD in Figure 2 that\nasks for the first and last name of the author of a book\nwith title \"The Selfish Gene\". Note that we have slightly\nextended the XML-QL syntax to query over all\ndocuments conforming to a DTD.\nSelect Y.name.firstname,\nY.name.lastname\nFrom book X, X.author Y\nWhere X.booktitle = \"Databases\"\nWHERE <book>\n<booktitle> The Selfish Gene </booktitle>\n<author>\n<name>\n<firstname> $f </firstname>\n<lastname> $l </lastname>\n</name>\n</author>\n</book> IN * CONFORMING TO pubs.dtd\nCONSTRUCT <result> $f $l </result>\nAs can be seen from the Lorel-like representation, this\nquery essentially consists of five path expressions,\nnamely,\nbook,\nX.author,\nY.name.firstname,\nY.name.lastname\nand\nX.booktitle.\nOf\nthese\npath\nexpressions, book is the root path expression and the\nothers are dependent path expressions. This query is\ntranslated into SQL as follows: (a) first, the relation(s)\ncorresponding to start of the root path expression(s) are\nidentified and added to the from clause of the SQL query,\nthen (b) if necessary, the path expressions are translated to\njoins among relations (when elements are inlined, joins\nare not necessary). The SQL query generated in this\nfashion for the example query above is shown in Figure\n18. Note that a join condition has been added to the where\nclause to link the book and author and a selection\n(A.parentCODE = 0, where 0 indicates that the parent of\nthe author is a book) is performed on author to make sure\nthat only authors reached through book are considered.\n\nSelect A.\"author.name.firstname\",\nA.\"author.name.lastname\"\nFrom author A, book B\nWhere B.bookID = A.parentID\nAND A.parentCODE = 0\nAND B.\"book.booktitle\" = \"The Selfish Gene\"\nFigure 18\n4.2 Converting Simple Recursive Path Expressions\nto SQL\nConsider the following XML-QL query that requires the\nnames of all editors reachable directly or indirectly from\nthe monograph with title \"Subclass Cirripedia\". The\ncorresponding XML-QL query (and an equivalent Lorel\nlike query) is shown below:\nWHERE <*.monograph>\n<editor.(monograph.editor)*>\n<name> $n </name>\n</>\n<title> Subclass Cirripedia </title>\n</> IN * CONFORMING TO pubs.dtd\nCONSTRUCT <result> $n </result>\nSelect Y.name\nFrom *.monograph X, X.editor.(monograph.editor)* Y\nWhere X.title = \"Subclass Cirripedia\"\nThere are two interesting features about this query.\nThe first is the tag \"*.monograph\" which states that we\nare interested in monographs reachable from any path.\nThe second is the tag \"editor.(monograph.editor)*\" that\nspecifies all editors reachable directly or indirectly from a\nmonograph. The trick in converting this to a least fix-\npoint query such as that supported by IBM DB2 is to\ndetermine (a) the initialization of the recursion and (b) the\nactual recursive path expression. In the example above,\nthe initialization of the recursion is the path expression\n*.monograph.editor\nwith\nthe\nselection\ncondition\nmonograph.title = \"Subclass Cirripedia\" and the recursive\npath expression is monograph.editor. Each can be\nconverted to a SQL fragment just like a simple path\nexpression. The final query is the union of the two SQL\nfragments within a least fix-point operator. The query\ngenerated in this fashion is shown in Figure 19, in IBM\nDB2 syntax. Note that the \"with clause\" is the equivalent\nof the least fix-point operator in DB2.\nWith Q1 (monographID, name) AS\n(Select X.monographID, X.\"editor.name\"\nFrom monograph X\nWhere X.title = \"Subclass Cirripedia\"\nUNION ALL\nSelect Z.monographID, Z.\"editor.name\"\nFrom Q1 Y, monograph Z\nWhere Y.monographID = Z.parentID AND\nZ.parentCODE = 0\n)\nSelect A.name\nFrom Q1 A\nFigure 19\n4.3 Converting Arbitrary Path Expressions to\nSimple Recursive Path Expressions\nIn general, path expressions can be of arbitrary\ncomplexity. For example, we could have a query that asks\nfor all the name elements reachable directly or indirectly\nthrough monograph. This would be represented in a\nLorel-like language as (an equivalent query can be\nexpressed in XML-QL):\nSelect X\nFrom monograph.(#)*.name X\nWe have a general technique that takes path\nexpressions appearing in such queries (in this example\n\"monograph.(#)*.name\")\nand\ntranslates\nthem\ninto\npossibly many simple (recursive) path expressions. SQL\nqueries are then generated for each simple recursive path\nexpression. This notion of splitting a path expression to\nmany simple path expressions is crucial to processing\nqueries having arbitrary path expressions in SQL. The\ndetails of the technique are tedious and we omit them here\nin the interest of space.\nOur technique is general enough to handle path\nexpressions with nested recursion (e.g., \"(a.(b)*.c)*\").\nHowever, relational database systems such as IBM DB2\ncannot currently handle these queries because they do not\nhave support for nested recursive queries.\n5. Converting Relational Results to XML\nIn the previous section, we assumed that the results of a\nquery were string values. We relax this assumption in this\nsection and explore how the tabular results returned by\nSQL queries can be converted to complex structured\nXML documents. This is perhaps the main drawback in\nusing current relational technology to provide XML\nquerying - constructing arbitrary XML result sets is\ndifficult. In this section we give some examples, using\nXML-QL as the illustrative query languages because it\nprovides XML structuring constructs.\n5.1 Simple Structuring\nConsider the query in Figure 20 that asks for the first\nname and last name of all the authors of books, nested\nappropriately. Constructing such results from a relational\nsystem is natural and efficient, since it only requires\nattaching the appropriate tags for each tuple (Figure 21).\n5.2 Tag Variables\nA tag variable is one that ranges over the value of an\nXML tag. Some queries requiring tag variables in their\nresults are naturally translated to the relational model.\nConsider the query in Figure 22 that ask for names of\nauthors of all publications, nested under a tag specifying\nthe type of publication.\nThis can be handled by\ngenerating a relational query that contains the tag value as\nan element of the result tuple. Then at result generation\n\nWHERE <book>\n<author>\n<firstname> $f </firstname>\n<lastname> $l </lastname>\n</>\n</> IN * CONFORMS TO pubs.dtd\nCONSTRUCT <author>\n<firstname> $f </firstname>\n<lastname> $l </lastname>\n</author>\nFigure 20\nWHERE <$p>\n<author>\n<firstname> $f </firstname>\n<lastname> $l </lastname>\n</>\n</> IN * CONFORMS TO pubs.dtd\nCONSTRUCT <$p>\n<author>\n<firstname> $f </firstname>\n<lastname> $l </lastname>\n</author>\n</>\n(book, Richard, Dawkins)\n(book, NULL, Darwin)\n(monograph, NULL, Darwin)\nFigure 22\ntime, the tag attribute in the result tuple can be converted\nto the appropriate XML tag (Figure 23).\n5.3 Grouping\nConsider the query in Figure 24 that requires all the\npublications of an author (assuming an author is uniquely\nidentified by his/her last name) to be grouped together,\nand within this structure, requires the titles of publications\nto be grouped by the type of the publication. The\nrelational result from the translation of this query will be a\nset of tuples having fields corresponding to last name of\nauthor, title of publication and type of publication.\nHowever, we cannot use the relational group-by operator\nto group by last name and type of publication because the\nSQL group-by semantics implies that we should apply an\naggregate function to title, which does not make sense.\nThus, the options are either (a) have the relational engine\norder the result tuples first by last name and then by type\nand scan the result in order to construct the XML\ndocument or (b) get an unordered set of tuples and do a\ngrouping operation, by last name and then by type,\noutside the relational engine. The first approach is\nillustrated in Figure 25.\nFigure 25 illustrates several points. The first is that\ntreating tag variables as attributes in the result relation\nprovides a way of uniformly treating the contents of the\nresult XML document. In this case, we are able to group\nby the tag variable just like any other attribute. The\nsecond observation is that some relational database\nfunctionality (hash-based group-by) is either not fully\nexploited or is duplicated outside.\n<author>\n<firstname> Richard </firstname>\n(Richard, Dawkins)\n(NULL, Darwin)\n<lastname> Dawkins </lastname>\n</author>\n<author>\n<lastname> Darwin </lastname>\n</author>\nFigure 21\nFigure 23\n<book>\n<author>\n<firstname> Richard </firstname>\n<lastname> Dawkins </lastname>\n</author>\n</book>\n<book>\n<author>\n<lastname> Darwin </lastname>\n</author>\n</book>\n<monograph>\n<author>\n<lastname> Darwin </lastname>\n</author>\n</monograph>\n5.4 Complex Element Construction\nUnfortunately, returning tag values as tuple attributes\ncannot handle all result construction problems. In\nparticular, queries that are required to return complex\nXML elements are problematic. Consider a query that\nasks for all article elements in the XML data set, and\nfurthermore assume that an article may have multiple\nauthors\nand\nmultiple\ntitles.\nIn\nobject-relational\nterminology, article has two set-valued attributes, authors\nand titles, corresponding to two set sub-elements in XML\nterminology.\nWHERE <book>\n<article> $a </article>\n</> IN * CONFORMS TO pubs.dtd\nCONSTRUCT <article> $a </>\nTo create the appropriate result, we must retrieve all\nauthors and all titles for each article. This is difficult to do\nin the relational model because flattening multiple set-\nvalued attributes into tuple format gives rise to a multi-\nvalued dependency [11] and is likely to be very inefficient\nwhen the sets are large, for example, if papers have many\nauthors and many titles. There appears to be no efficient\nway to tackle this problem in the traditional relational\nmodel. One solution would be to return separate relations,\neach flattening one set-valued attribute and \"join\" these\nrelations outside the database while constructing the XML\ndocument. However, this requires duplication of database\nfunctionality both in terms of execution and optimization.\nThis solution would be particularly bad for an element\nwith many set-valued attributes. A related problem occurs\nwhen reconstructing recursive elements. We return to\nthese issues in Section 6.\n\nWHERE <$p>\n<author>\n<(title|booktitle)> $t </>\n<name> Darwin </name>\n<author>\n<book>\n<lastname> $l </lastname>\n<title> Origin of Species </title>\n</>\n<title> The Descent of Man </title>\n</> IN * CONFORMS TO pubs.dtd\n</book>\nCONSTRUCT <author ID=authorID($l)>\n<name> $l </name>\n<$p ID=pID($p)>\n<title> $t </>\n(Darwin, book, Origin of Species)\n(Darwin, book, Descent of Man)\n(Darwin, monograph, Subclass\n<monograph>\n<title> Subclass Cirripedia </title>\n</monograph>\n</author>\n</>\nCirripedia)\n<author>\n</>\n(Dawkins, book, The Selfish Gene)\n<name> Dawkins </name>\n<book>\n<title> The Selfish Gene </title>\n</book>\n</author>\nFigure 24\n5.5 Heterogeneous Results\nConsider the following XML-QL query that creates a\nresult document having both titles and authors as elements\n(this is the heterogeneous result). This is easily handled in\nour approach for translating queries because this query\nwould be split into two queries, one for selecting titles and\nanother for selecting authors. The results of the two\nqueries can be handled in different ways, one constructing\ntitle elements and another constructing author elements.\nThe results can then be merged together.\nWHERE <article>\n<$p> $y </>\n</article> IN * CONFORMING TO pubs.dtd\nCONSTRUCT <$p> $y </>\n5.6 Nested Queries\nXML-QL is structured in terms of query blocks and one\nquery block can be nested under another. These nested\nqueries can be rewritten in terms of SQL queries, using\nouter joins (and possibly skolem function ids) to construct\nthe association between a query and a sub-query. The\ndetails are complex and we omit it in the interest of space.\n6. Conclusions\nWith the growing importance of XML documents as a\nmeans to represent data in the World Wide Web, there has\nbeen a lot of effort on devising new technologies to\nprocess queries over XML documents. Our focus in this\npaper, however, has been to study the virtues and\nlimitations of the traditional relational model for\nprocessing queries over XML documents conforming to a\nschema. The potential advantages of this approach are\nmany - reusing a mature technology, using an existing\nhigh performance system, and seamlessly querying over\ndata represented as XML documents or relations. We\nhave shown that it is possible to handle most queries on\nXML documents using a relational database, barring\ncertain types of complex recursion.\nFigure 25\nOur qualitative evaluation based on real DTDs from\ndiverse domains raises some performance concerns -\nspecifically, in many cases relatively simple XML queries\nrequire either many SQL queries, or require a few SQL\nqueries with many joins in them. It is an open question\nwhether semi-structured query processing techniques can\ndo this kind of work more efficiently. The fact that semi-\nstructured models represent a sequence of joins as a path\nexpression, or handle what is logically a union of queries\nby using wildcards and \"or\" operators, does not\nautomatically imply more efficient evaluation strategies.\nOur experience has shown that relational systems\ncould more effectively handle XML query workloads with\nthe following extensions:\nSupport for Sets: Set-valued attributes would be useful\nin two important ways. First, storing set sub-elements as\nset-valued attributes [19,21] would reduce fragmentation.\nThis is likely to be a big win because most of the\nfragmentation we observed in real DTDs was due to sets.\nSecond, set-valued attributes, along with support for\nnesting [13], would allow a relational system to perform\nmore of the processing required for generating complex\nXML results.\nUntyped/Variable-Typed References: IDREFs are not\ntyped in XML. Therefore, queries that navigate through\nIDREFs cannot be handled in current relational systems\nwithout a proliferation of joins - one for each possible\nreference type.\nInformation Retrieval Style Indices: More powerful\nindices, such as Oracle8i's ConText search engine for\nXML [17], that can index over the structure of string\nattributes would be useful in querying over ANY fields in\na DTD. Further, under restricted query requirements,\nwhole fragments of a document can be stored as an\nindexed text field, thus reducing fragmentation.\nFlexible Comparisons Operators: A DTD schema\ntreats every value as a string. This often creates the need\nto compare a string attribute with, say, an integer value,\nafter typecasting the string to an integer. The traditional\nrelational model cannot support such comparisons. The\nproblem persists even in the presence of DCDs or XML\n\nSchemas\nbecause\ndifferent\nDTDs\nmay\nrepresent\n\"comparable\" values as different types. A related issue is\nthat of flexible indices. Techniques for building such\nindices have been proposed in the context of semi-\nstructured databases [14].\nMultiple-Query Optimization/Execution: As outlined\nin Section 4, complex path expressions are handled in a\nrelational database by converting them into many simple\npath expressions, each corresponding to a separate SQL\nquery. Since these SQL queries are derived from a single\nregular path expression, they are likely to share many\nrelational scans, selections and joins. Rather than treating\nthem all as separate queries, it may be more efficient to\noptimize and execute them as a group [20].\nMore Powerful Recursion: As mentioned in Section 4,\nin order to fully support all recursive path expressions,\nsupport for fixed point expressions defined in terms of\nother fixed point expressions (i.e., nested fixed point\nexpressions) is required.\nThese extensions are not by themselves new and have\nbeen proposed in other contexts. However, they gain new\nimportance in light of our evaluation of the requirements\nfor processing XML documents. Another important issue\nto be considered in the context of the World Wide Web is\ndistributed query processing - taking advantage of\nqueryable XML sources. Further research on these\ntechniques in the context of processing XML documents\nwill, we believe, facilitate the use of sophisticated\nrelational data management techniques in handling the\nnovel requirements of emerging XML-based applications.\n7. Acknowledgements\nFunding for this work was provided by DARPA through\nRome Research Laboratory Contract No. F30602-97-2\n0247 and NSF through NSF Award CDA-9623632.\n8. References\n1.\nS. Abiteboul, D. Quass, J. McHugh, J. Widom, J.\nWiener, \"The Lorel Query Language for\nSemistructured Data\", International Journal on\nDigital Libraries, 1(1), pp. 68-88, April 1997.\n2. J. Bosak, T. Bray, D. Connolly, E. Maler, G. Nicol,\nC. M. Sperberg-McQueen, L. Wood, J. Clark, \"W3C\nXML Specification DTD\",\nhttp://www.w3.org/XML/1998/06/xmlspec-report\n19980910.htm.\n3.\nT. Bray, J. Paoli, C. M. Sperberg-McQueen,\n\"Extensible Markup Language (XML) 1.0\",\nhttp://www.w3.org/TR/REC-xml.\n4.\nT. Bray, C. Frankston, A. Malhotra, \"Document\nContent Description for XML\",\nhttp://www.w3.org/TR/NOTE-dcd.\n5.\nP. Buneman, S. Davidson, G. Hillebrand, D. Suciu,\n\"A Query Language and Optimization Techniques for\nUnstructured Data\", Proceedings of the ACM\nSIGMOD Conference, Montreal, Canada, June 1996.\n6.\nV. Christophides, S. Abiteboul, S. Cluet, M. Scholl,\n\"From Structured Documents to Novel Query\nFacilities\", Proceedings of the ACM SIGMOD\nConference, Minneapolis, Minnesota, May 1994.\n7.\nG. Copeland, S. Khoshafian, \"A Decomposition\nStorage Model\", Proceedings of the ACM SIGMOD\nConference, Austin, Texas, May 1985.\n8.\nR. Cover, \"The SGML/XML Web Page\",\nhttp://www.oasis-open.org/cover/xml.html.\n9.\nDeutsch, M. Fernandez, D. Florescu, A. Levy, D.\nSuciu, \"XML-QL: A Query Language for XML\",\nhttp://www.w3.org/TR/NOTE-xml-ql.\n10. Deutsch, M. Fernandez, D. Suciu, \"Storing Semi-\nstructured Data with STORED\", Proceedings of the\nACM SIGMOD Conference, Philadelphia,\nPennslyvania, May 1999.\n11. R. Fagin, \"Multi-valued Dependencies and a New\nNormal Form for Relational Databases\", ACM\nTransactions on Database Systems, 2(3), pp. 262-278,\n1977.\n12. M. Fernandez, D. Suciu, \"Optimizing Regular Path\nExpressions Using Graph Schemas\", Proceedings of\nthe Fourteenth ICDE Conference, Orlando, Florida,\nFebruary 1998.\n13. Jaeschke, H. J. Schek, \"Remarks on the Algebra of\nNon First Normal Form Relations\", Proceedings of\nthe ACM Symposium on Principles of Database\nSystems, Los Angeles, California, March 1982.\n14. J. McHugh, S. Abiteboul, R. Goldman, D. Quass, J.\nWidom, \"Lore: A Database Management System for\nSemistructured Data\", SIGMOD Record, 26(3), pp.\n54-66, September 1997.\n15. J. McHugh, J. Widom, \"Compile-Time Path\nExpansion in Lore\", Workshop on Query Processing\nfor Semistructured Data and Non-Standard Data\nFormats, Jerusalem, Israel, January 1999.\n16. Microsoft Corporation, XML Schema,\nhttp://www.microsoft.com/xml/schema/reference/star\n.asp.\n17. Oracle Corporation, \"XML Support in Oracle 8 and\nbeyond\", Technical white paper,\nhttp://www.oracle.com/xml/documents.\n18. The Query Languages Workshop (QL'98),\nhttp://www.w3.org/TandS/QL/QL98/, December\n1998.\n19. K. Ramasamy, J. F. Naughton, D. Maier, \"Storage\nRepresentations for Set-Valued Attributes\", Working\nPaper, Department of Computer Sciences, University\nof Wisconsin-Madison.\n20. T. Sellis, \"Multiple-Query Optimization\", ACM\nTransactions on Database Systems, 12(1), pp. 23-52,\nJune 1990.\n21. Zaniolo, \"The Database Language GEM\",\nProceedings of the ACM SIGMOD Conference, San\nJose, California, May 1983."
    },
    {
      "category": "Resource",
      "title": "Understanding and Using the Meaning of Statements in a Bio-ontology: Recasting the Gene Ontology in OWL",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/d53673ffd07213792965b541368d7201_aranguren_bmc.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nBioMed Central\nBMC Bioinformatics\nCommentary\nOpen Access\nUnderstanding and using the meaning of statements in a\nbio-ontology: recasting the Gene Ontology in OWL\nMikel Egana Aranguren1, Sean Bechhofer1, Phillip Lord2, Ulrike Sattler1 and\nRobert Stevens*1\nAddress: 1School of Computer Science, University of Manchester, Manchester, UK and 2School of Computing Science, University of Newcastle,\nNewcastle, UK\nEmail: Mikel Egana Aranguren - mikel.eganaaranguren@cs.man.ac.uk; Sean Bechhofer - sean.bechhofer@manchester.ac.uk;\nPhillip Lord - phillip.lord@newcastle.ac.uk; Ulrike Sattler - sattler@cs.man.ac.uk; Robert Stevens* - robert.stevens@manchester.ac.uk\n* Corresponding author\nPublished: 20 February 2007\nReceived: 17 October 2006\nBMC Bioinformatics 2007, 8:57\ndoi:10.1186/1471-2105-8-57\nAccepted: 20 February 2007\nThis article is available from: http://www.biomedcentral.com/1471-2105/8/57\n(c) 2007 Aranguren et al; licensee BioMed Central Ltd.\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0),\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nAbstract\nThe bio-ontology community falls into two camps: first we have biology domain experts, who\nactually hold the knowledge we wish to capture in ontologies; second, we have ontology specialists,\nwho hold knowledge about techniques and best practice on ontology development. In the bio\nontology domain, these two camps have often come into conflict, especially where pragmatism\ncomes into conflict with perceived best practice. One of these areas is the insistence of computer\nscientists on a well-defined semantic basis for the Knowledge Representation language being used.\nIn this article, we will first describe why this community is so insistent. Second, we will illustrate\nthis by examining the semantics of the Web Ontology Language and the semantics placed on the\nDirected Acyclic Graph as used by the Gene Ontology. Finally we will reconcile the two\nrepresentations, including the broader Open Biomedical Ontologies format. The ability to\nexchange between the two representations means that we can capitalise on the features of both\nlanguages. Such utility can only arise by the understanding of the semantics of the languages being\nused. By this illustration of the usefulness of a clear, well-defined language semantics, we wish to\npromote a wider understanding of the computer science perspective amongst potential users\nwithin the biological community.\n1 Background\nIn this paper, we explain the role of a Knowledge Repre\nsentation (KR) language's semantics. To illustrate the util\nity of language semantics we will use it to explore the\nreconciliation of the representations used for the Gene\nOntology (GO) [1] and that used for the ontologies repre\nsented in the W3C recommendation Web Ontology Lan\nguage (OWL [2]). A language's semantics is often a great\nconcern to computer scientists, a concern that is some\ntimes lost on biologists. The goal of this paper is, there\nfore, to explain the role of language semantics to a\ncommunity outside computer science (this albeit anecdo\ntal evidence is built up over many years of teaching and\ntutorials in this domain between the two disciplines). In\nthe text of this document Boldface font is used to refer to\nobjects and logical keywords within an ontology and Ital\nics Boldface font for terms that have a definition available\nin the glossary (see Additional file 1).\nPage 1 of 13\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8:57\nDifferent knowledge representation languages provide dif\nferent means to make statements about the knowledge to\nbe captured in different ways. The semantics of these lan\nguages tell both humans and computers how to interpret\nstatements made in those languages. Different languages\nhave varying expressivity and computational properties,\nhence the corresponding tools can offer different querying\nand reasoning mechanisms; consequently there is often a\nneed to exchange between languages to take advantage of\ntheir characteristics. For example, the Web Ontology Lan\nguage OWL-DL [3] comes with rather high expressivity\nand some powerful reasoning services. As a consequence,\nwe can annotate data using terms (and expressions built\nfrom these terms) whose meaning is defined in some\nOWL-DL knowledge base, usually called an \"ontology\",\nand then use a software application called a reasoner to\nquery that data. The reasoner will take into account the\ndefinitions of the terms when answering queries, thereby\nproviding flexible access to that data. When translating a\nknowledge base from one language to another, we have to\nmake sure that the knowledge captured in statements in\none language is changed as little as possible when trans\nforming them into statements in another language.\nHence, the semantics of one language needs to be recon\nciled with the semantics of the other.\nThe GO has become the de facto standard for describing\nthe principal attributes (the molecular function, biologi\ncal process, and cellular component) of knowledge about\ngene products across many databases [1,4]. It succeeds in\nthe major aim of an ontology in providing a common,\nshared understanding of the concepts used to describe\nthose attributes-for humans. It does this by providing\nterms used to label those concepts as well as natural lan\nguage definitions of those terms.\nGO is part of an umbrella project that encompasses many\nother bio-ontologies called Open Biomedical Ontologies\n(OBO [5]). GO uses a knowledge representation language\ndeveloped in-house-based on the Directed Acyclic Graph\n(DAG) [4]. The DAG is a common-place representation\nacross computer science and other disciplines. What the\nedges and nodes in the DAG mean, their semantics, is\ndetermined by the specific user community. In some\ngraphs, for example, a node represents a railway station,\nan atom, etc. As we will see in Section 4 there is a particular\nmeaning to the edges and nodes used in representing GO,\nwhich have been determined by the GO Consortium. The\nGO's DAG is encoded using a syntax also developed by\nthis group. The DAG has the tremendous advantage of\nsimplicity and this has been a factor in enabling the Gene\nOntology to develop to its current pre-dominant status\n[6].\nhttp://www.biomedcentral.com/1471-2105/8/57\nGO's DAG is available in different formats, including\nMySQL tables, XML and OWL [7]. The most commonly\nused format is, however, the OBO file format, which is\nshared by most of the other OBO bio-ontologies [8].\nThe OBO file format not only enforces the syntax the OBO\nfiles should have, it also provides a set of elements that\ncan be used to define semantics such as domain, range,\nis_symmetric, is_cyclic, is_transitive, etc. GO's DAG can\nbe represented in the OBO file format, making use of a\nsubset from all the possible elements available. Other bio\nontologies make use of other elements, and all those bio\nontologies (GO and other OBO bio-ontologies) are com\npliant with the OBO file format.\nThe OBO site states that submitted ontologies can be pre\nsented in the OBO file format (including GO's DAG) or in\nOWL. Being a collection of bio-ontologies, it would be\nuseful to be able to translate ontologies between the two\nformats. Indeed, this has already been attempted in both\nthe current version of DAG-Edit [9] and its successor,\nOBO-Edit [10], the COBrA ontology editor [11] and as an\ninitial step in the Gene Ontology Next Generation\n(GONG) project [12,13].\nThe primary purpose in this paper is not to present a trans\nlation of the DAG and OBO formats into OWL, but to\nshow how such a translation is achieved. Such translation\nhas already been done by the Gene Ontology consortium\nthemselves [14]. We use the case study here as an illustra\ntion of the use of a language's semantics to achieve the\ntranslation and in doing so show how a strict semantics is\nvery important. In doing this, in Section 2 we explain why\ncomputer scientists, in particular, like to have a well-\ndefined semantics in their knowledge representation lan\nguages. In Sections 3 and 4 we outline the semantics of\nGO's DAG representation and that of OWL. In Section 5,\nwe attempt to reconcile the two representations. Section 7\ndescribes the implementation of this translation.\n2 Why do computer scientists care so much\nabout semantics?\nge representation community within compu\nas the aim of representing knowledge in a\nunderstandable by humans and one that is\nally amenable. Computers, of course, do not\nme facility to \"understand\" knowledge cap\nntology as do the human users of that ontol\nmputer, the term labeling a concept is not\nible. For illustration (see Figure 1) we will use\ny simplistic ontology that is by no means bio\nhis article a toy example is able to convey the\nantics more easily than a \"true\" biological\nat would obscure the message. Taking the\nigure 1, a human might read the information\nPage 2 of 13\n(page number not for citation purposes)\nThe knowled\nter science h\nform both\ncomputation\nhave the sa\ntured in an o\nogy. To a co\ncomprehens\na deliberatel\nlogical. For t\npoint of sem\nexample th\nexample in F\n\nAn example toy ontology of Person\nBMC Bioinformatics 2007, 8:57\nin this representation as saying that\nson is either a Man or a Woman, but\ntime\"(at least not in this view of the\n\"an instance of Per\nnot both at the same\nworld!). In contrast,\na computer might not have such an understanding. A\nhuman brings their world experience and their under\nstanding of terms such as \"man\" and \"woman\" to under\nstanding the representation-something a computer does\nnot do.\nThe need to capture knowledge with high-fidelity and\ninterpret it unambiguously is enabled by having a repre\nsentation language with well-defined semantics. In the\nsame way that a C programming language compiler must\nunambiguously \"understand\" what each of the language\ncomponents means in terms of constructing a programme\nthat runs on a particular machine, so must a computer\nunderstand what each of the statements in the description\nof some knowledge represents. This is not the deeper mean\ning of the software (such as typesetting this document\naccording to standard publishing principles) or what, for\ninstance, an ontology is stating about biology. What is\nunambiguously interpreted is the relationship between\nthe symbols being used. The (computer's) \"understand\ning\" is determined by the semantics of the language-be it\na programming language or a knowledge representation\nlanguage. As we will see below, just as a compiler needs to\nknow exactly what a particular programming construct\nmeans, though not the intention of the programmer, a\ncomputer needs to be able to interpret what the \"circles\nand arrows\" mean in Figure 1.\nFigure 1 shows, on its right hand side, a simple ontology\nof Person, with two child classes of Man and Woman. As\nhuman users we understand, or believe we understand,\nwhat is being represented in such an ontology; \"there are\ntwo kinds of Person, namely Man and Woman\". We can,\nhowever, ask several supplementary questions about this\nontology:\nFigure 1\nAn example toy ontology of Person. The ontology takes a\nvery simplified view of biological reproduction, for the sake\nof clarity.\nhttp://www.biomedcentral.com/1471-2105/8/57\n- Are all instances of Man also instances of Person?\n- Are Man and Woman the only kinds of Person that\nexist?\n- Is it possible for an instance of Person to be both a Man\nand a Woman?\nNow consider the left part of Figure 1 where we say that a\nPerson has Gonads and that a Man has Testis. Again, we\nmight ask ourselves several additional questions:\n- How many Testis does a Man have?\n- Can a Man only have Testis or may he have other parts?\n- Does having a Testis make an instance of Person a Man?\n- Are Testis the only gonads a Man can have?\n- Do all Man have Testis?\n- Are all Testis parts of Man?\n- May I say anything more about the parts that a Man has?\nAgain, as human users of the ontology shown in Figure 1,\nwe may understand, deduce, guess, or know the answers\nto these questions, or we may not; it is certain, however,\nthat the computer will not do so. It is in the semantics of\nthe knowledge representation language that the answers\nto such questions can be couched. It is part of the seman\ntics of a language that says whether two children of a con\ncept are overlapping, that is, is it possible for an instance\nof Person to be both a Man and a Woman. For a computer\nto know both the answer to this and that the only possible\nkinds of Person are Man and Woman, this has to either\nfollow from the semantics of \"is-a arrows\" of our formal\nism, or it would have to be explicitly stated. Remember\nthat the labels are just symbols; the computer does not\nunderstand those symbols, but the semantics of the lan\nguage specifies, for instance, that we have symbols for\nclass names (such as Man and Testis), that we have sym\nbols for property names (such as has-part), and that the\nhas-part-labelled arrow from Man to Testis means that\neach instance of the class called Man is has-part-related to\nat least one instance of the class called Testis.\nReturning to human users, the semantics of a program\nming language tells us how a computer will interpret our\nnables us to write software that does\no. Similarly, the semantics of a knowl\nlanguage tells us how a computer, a\nr human should understand the state-\nPage 3 of 13\n(page number not for citation purposes)\nsoftware, and thus e\nwhat we want it to d\nedge representation\nreasoner, or anothe\n\nBMC Bioinformatics 2007, 8:57\nments in our knowledge base-and a precise semantics\ntells us this in an unambiguous way.\nThe semantics might enable a human to interpret a state\nment as \"each and every Man has at least one Testis\", as\nthere is no other interpretation possible; he or she can also\nbring their world knowledge to decide whether this is\ntrue. A user might believe they understand what is repre\nsented in the ontology shown in Figure 1, but dangerous\nassumptions might be made when doing so and this is\nwhere ambiguity can occur. If the knowledge representa\ntion language has a precise semantics, then the knowledge\ncaptured in the ontology expressed in that language can\nbe decoded with precision; that is, we can interpret exactly\nwhat each statement in a language means. Precision is\nvital for humans since it enables them to agree on the\nmeaning of a statement, and for the design of software to\ntake into account a knowledge base since it enables the\ncomparison of what the software actually does with what\nit is supposed to do according to the semantics of the under\nlying knowledge representation language. For example, a\nprecise semantics allows us to make statements about the\nsoundness and completeness of a query answering tool:\ndoes it retrieve all and only those answers that should be\nretrieved according to the semantics? This can mean, how\never, that we need to make an effort to understand the\nsemantics [15].\n3 OWL\nOWL-DL [3] is an ontology language based on description\nlogics (DLs), which are a family of logic-based knowledge\nrepresentation formalisms describing \"objects\", \"classes\"\nand the \"relationships\" between them [16]. Most DLs are\nfragments of standard first order logic. Originally, they\nwere designed to give a unified logical basis to various\nwell-known traditions of knowledge representation like\nframe-based systems and semantic networks [17]; they\nhave found various applications in conceptual modelling\nand as a logical underpinning of ontology languages [16].\nOWL-DL is based on an expressive DL, i. e., it provides a\nwealth of constructors to describe complex class expres\nsions from atomic classes and relationships. In this sec\ntion, we will only use a small portion of OWL-DL's\nexpressiveness to highlight its core features.\nThe semantics of OWL-DL is best understood when talk\ning about \"objects\" that are \"instances\" of \"classes\", and\nthat are related to other objects via \"relations\".\nAn object can be an instance of a class, and a class can be\na sub-class of another class. For example, the object Rob\nert is an instance of the class Man which, in turn, is a sub\nclass of Person. The meaning of the sub-class relationship\nis that all instances of the sub-class, Man, are also\ninstances of its super class(es), Person. In OWL-DL, to\nhttp://www.biomedcentral.com/1471-2105/8/57\ndescribe a class, we can describe it in terms of other classes\n(e.g., saying that Man are \"Person and not Woman\") and\nof properties of its instances.\nIn Section 2, we have informally described an ontology\nwith classes Man, Woman, Person, and others. In this sec\ntion, we will formalize some of these classes in OWL-DL.\nWe start by fixing the relationship between these three\nclasses. First, we declare that Man and Woman are \"dis\njoint\"; that is, it is not possible for an object to be an\ninstance of both classes; this is expressed in the first state\nment of Figure 2. Similarly, we have to decide whether it\nis possible for an instance of Person to be neither an\ninstance of Woman nor of Man. Assuming that this is not\nthe case, we add the second statement of Figure 2.\nTogether, these four statements imply that every person is\neither a man or a woman, but not both.\nNext, we make use of OWL-DL's ability to describe a class\nby describing its superclasses and how its instances are\nrelated to other objects. For example, the definition of the\nclass Man in Figure 2 states that an instance of Man is a\n(instance of) Person which has an instance of Testis\nrelated to it via the has-part property. As this statement\nonly says something about the existence of a relationship\nto another object, it is called an \"existential\" restriction-\nwhich is expressed in OWL-DL using the someValues-\nFrom keyword. This asserts only that an instance of Man\nmight have several parts that are testis, and other parts, as\nwell-which is why we use the \"amongst other things\" in the\nparaphrase. For example, we have left it open in our\ndescription of Man whether a Man has ovaries, and so,\nwith respect to the above definition of Man, a Man may or\nmay not have ovaries. Additionally, to make this more\nprecise, OWL-DL also allows \"universal\" restrictions to be\nmade: e.g., in the definition of Woman, we say that an\ninstance of Woman is related via the relation has-part only\nto instances of the complement of Testis, i.e., no part of a\nwoman can be an instance of Testis. This is expressed\nusing the allValuesFrom keyword and complementOf,\nanother expressive means which corresponds to logical\nnegation.\nIn the definitions of the classes Man and Woman, we have\nused the keyword complete to indicate that the following\nexpressions provide necessary and sufficient conditions\nfor an object to be an instance of this class. That is, if we\nknow that Robert is a Man, we also know that he has a\npart that is a testis and, if we find a person that has a part\nwhich is a testis, then this person is an instance of Man.\nThis gives rise to the use of the \"any\" in the paraphrasing\nused in Figure 2. Replacing complete with partial means\nthat only the first conclusion can be drawn. For example,\nFigure 3 contains a partial definition of Eunuch as those\nPersons that do not have Testis; so every Eunuch has no\nPage 4 of 13\n(page number not for citation purposes)\n\nMan and Woman in OWL\nBMC Bioinformatics 2007, 8:57\nhttp://www.biomedcentral.com/1471-2105/8/57\nFigure 2\nMan and Woman in OWL. Description and paraphrase provided.\nparts which are Testis, but not everyone with no Testis is\na Eunuch.\nIn all of these examples, we have only stated restrictions\nconcerning Man and Woman and the objects to which\nthey are related by the has-part relation. We have not\nrestricted any other relationships we might choose to\ndescribe, such as has-mother, nor have we said anything\nabout instances of Testis apart from the fact that they can\nbe parts of a Man. After all, other species' male instances\nalso have Testis, i.e., according to our ontology so far, an\ninstance of Testis can be part of other objects or of noth\ning at all.\nIn order to avoid such \"homeless\" testis, we can add a\nrestriction which states that an instance of Testis is a part\nof a male animal. For this to have the desired effect, we\nalso need to state that has-part is indeed the inverse of the\nrelation part-of. Both statements are found in Figure 4.\nDue to its description logic underpinning, OWL-DL\nontologies can be submitted to a DL reasoner which pro\nvides reasoning services. Most importantly, a reasoner can\ndecide the consistency of each class defined in the ontol\nogy and it can compute the implicit class hierarchy. For\nexample, given the statements made so far, the reasoner\ninfers that a Eunuch is, in fact, a subclass of Woman. This\nseems a little counter-intuitive, so we might also assert\nthat a Eunuch is a subclass of Man. The reasoner will then\ntell us that Eunuch is inconsistent: there can be no\ninstances of it. In this case, it is probably our definition of\nMan that is a poor model of reality. The inconsistency of\nthe Eunuch forces us to re-examine this model. The pre\ncise and explicit nature of models in OWL-DL allows us to\ncheck the knowledge we have captured as OWL-DL state\nments and have them to be interpreted correctly.\nFor a complete description of OWL-DL, we refer the reader\nelsewhere [3]. Here, we have only used a small part of\nOWL-DL's expressiveness. In addition to using a relation\nin both directions (e.g., we have used the inverse direction\nof has-part via part-of), OWL-DL also enables us to state\nthat a relation such as part-of is transitive (e.g., making a\nSemiNiferousTubule part of a Testis also makes it part of\na Man) and to restrict the number of objects to which an\ninstance of a class is related by a specific relationship (e.g.,\nrestricting the number of gonads a Person has to 2). It\nshould be enough, however, to indicate that the well-\ndefined semantics of OWL-DL enables both the author\nand a computer to \"understand\" precisely what has been\nstated, and enable software such as a reasoner to deduce\nimplicit knowledge from such representations [18,19].\n4 GO and DAG\nThe aim of this section is to elucidate the semantics of\nGO's encoding and not to examine the correctness of the\nbiology captured in that encoding, which has been done\nelsewhere [20]. There is need, however, to sometimes look\nat the biology in order to understand the encoding. In\ncontrast to OWL, the semantics of the representation used\nby the GO is not based on a logical formalism. Our under\nstanding of the GO DAG's semantics comes from its\ndescription in English [21], from consultation with mem\nbers of the Gene Ontology Consortium, and from infer\nences made from the ontology itself.\nThe GO is formalised as a Directed Acyclic Graph (DAG);\nsee Figure 5 for an example of a DAG. More precisely, a\n\"directed graph\" is a structure with \"nodes\" and \"edges\",\nthe latter being ordered pairs of nodes. In our case, both\nnodes and edges are \"labelled\": nodes with the term\ndenoting the class they stand for, and edges with the kind\nof relationship that relates the corresponding classes. In\nGO's DAG, edge labels are restricted to is-a and part-of.\nSuch a graph is acyclic, i.e., a DAG, if there is no path via\nedges that relates a node with itself-regardless of the\nedge's label, but using them only in a \"forward\" way. The\ngraph in Figure 5 is a DAG, for example. In GO, the term\nlabelling a node refers to this node and all of its children\nPage 5 of 13\n(page number not for citation purposes)\n[21].\n\nEunuch in OWL\nTestis in OWL\nBMC Bioinformatics 2007, 8:57\nhttp://www.biomedcentral.com/1471-2105/8/57\nFigure 3\nEunuch in OWL. Description and paraphrase provided.\nIn addition to this structured knowledge, the GO DAG\ncontains additional information within nodes: a specific\nGO identifier for each node, as well as \"exact\", \"broad\",\n\"narrow\" and \"related\" synonyms for the term labelling a\nnode, and possibly a definition of the meaning of the\nterm. The latter are given in natural language, i.e., they are\nfree text descriptions that \"define\" what a term means. As\na consequence, they may come with all the ambiguities of\nnatural language, and we can sometimes not distinguish,\nfor example, between a necessary condition and one that\nis necessary and sufficient. GO definitions are used by\nannotators and GO curators alike when using GO, and are\nnot intended to be used by an automated reasoning tool\nto draw new inferences. The format for the GO DAG also\nallows for some provenance information, such as author,\nsource, etc. but this detail is beyond the scope of this arti\ncle, where the emphasis is on the main ontological com\nponents of the representation.\nNext, we discuss what kind of statements can be made in\nGO's DAG representation. Firstly, GO uses two relation\nships, is-a and part-of. Figure 5 shows an example of a GO\nDAG with both kinds of relationships. The is-a relation\nship points from a child (more specialised) to a parent\n(more generalised) term [21]. We note that, if a parent has\nmore than one child, there is no way to distinguish\nbetween possibly overlapping (e.g., Carnivores and Mam\nmal) and disjoint (e.g., Man and Woman) classes [21].\nWhen interpreting the GO documentation, care should be\ntaken because the part-of relationship, in GO's usage,\ntalks about parts and parents, not parts and wholes, as is\nontologically conventional [22]. In Figure 5, we can see\nwhat some [13,23] have called \"orphan\" nodes, i.e., a\nnode that is part-of another node, but is not a kind of any\nnode. Conventionally, this would be a child with no par\nent, i.e., an orphan, and the GO curators are undertaking\nan effort to remove such orphans since they indicate an\nimprecise modeling (personal communication with Ame\nlia Ireland from the Gene Ontology Consortium).\nThere are (at least) four readings of a part-of relationship\nin GO's DAG [21]. Considering the part-of edge from a\nnode labelled P to a node labelled W, we have the follow\ning possibilities:\n1. The part-of relationship makes no assumption of the\nexistence of the relationship between the nodes in either\ndirection. Any P may or may not be part of a W and any\nW may or may not have a part that is a P. An example is\nPerson and Testis. Note that this need not contradict the\ndirected nature of the arcs. The part-of is directed, but\nthese semantics tell us how it is to be interpreted, particu\nlarly with respect to whether such a relationship exists or\nnot.\n2. Wherever a P exists, it is as part of a W, e.g., Nucleus and\nCell.\n3. Wherever a W exists, it has a part that is a P, e.g., Avian-\nRedBloodCell and Nucleus.\n4. Wherever a P exists, it is a part of a W and wherever a W\nexists, it has a part that is a P. This reading is simply the\nconjunction of readings 2 and 3. An example of this is\nNuclearMembrane and Nucleus.\nIn the GO documentation [21] the \"true path rule\" states\nthat \"the pathway from a child term all the way up to its\ntop-level parent(s) must always be true\". This should be\ntrue for both kinds of relationship in GO. For the is-a rela\ntionship, this means that an individual labelled as Man\ncould also legitimately be labelled as Person or Animal.\nSo, a gene product labelled as a photoreceptor activity is\nalso a kind of signal transducer activity and finally, a\nFigure 4\nTestis in OWL. Description and paraphrase provided.\nPage 6 of 13\n(page number not for citation purposes)\n\nA Gene Ontology Directed Acyclic Graph (DAG)\nBMC Bioinformatics 2007, 8:57\nhttp://www.biomedcentral.com/1471-2105/8/57\nFigure 5\nA Gene Ontology Directed Acyclic Graph (DAG). The DAG has both is-a and part-of relationships.\nmolecular function. Thus, the \"true path rule\", when\nworking along is-a relationships implies that we read\nthese relationships in a monotonic way, i.e., every instance\nof a class is also an instance of its superclasses, without\nexceptions.\nFor the part-of relationship, this has several implications.\nFirstly, it means that this relation is assumed to be transi\ntive, e.g., if a gene is part of a nucleus which, in turn, is part\nof a cell, then this gene is part of this cell. This assumption\nis widely accepted [24]. Secondly, this means that we have\nto choose one of the readings 2 or 4 mentioned above.\nThe GO editing style guide mentions that the majority of\npart-of links in GO conform to reading 2; readings 1 and\n3 are not used as they would violate the true path rule in\nGO [21].\nIf we restrict our attention to reading 2, then it is not dif\nficult to verify that the true path rule is even correct when\nwe combine both kinds of relationship in one path: a path\nusing both is-a and part-of becomes indeed part-of. The\nGO DAG editing style guide warns explicitly against\nemploying a reading different from the second one since\nsuch an \"abuse\" might yield unwanted consequences via\nthe true path rule, and suggests that the best strategy is to\nre-structure GO with new nodes and relationships so that\nonly reading 2 is employed and the true path rule can be\nemployed correctly. As a consequence, while we might\nhave stated that a Testis is part of Man, we cannot say any\nthing about a Man having part Testis since this would\ninvolve reading 3.\n5 Reconciling the two representations\nIn this section we reconcile the semantics of OWL-DL and\nGO's DAG: we analyse how one can be translated to the\nother and where, in that process, there could be problems.\nTo perform such a translation it is necessary to understand\nthe semantics of source and target languages and the aim\nis, of course, to say the same in each representation.\nPage 7 of 13\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8:57\nWe start by assessing a technical issue that does not affect\nthe semantics, but is important: naming conventions.\nOWL-DL has got its own naming conventions: non alpha\nnumeric characters or white spaces are not allowed in the\nnames of the classes, only underscores and alpha-numeric\ncharacters. This presents a problem since many GO term\nnames include non-alphanumeric characters. A solution\nto this problem is to translate any non-alphanumeric\ncharacter into a string that spells out the disallowed: for\nexample (-)-borneol dehydrogenase activity in GO\nwould\nbecome\nPAR_MINUS_PAR_MINUS_borneol_dehydrogenase_ac\ntivity in OWL. There is a choice to be made as to whether\nthe term or GO identifier become the class label. The id is\nthe primary identifier (GO:0047503), but the term is the\nmore readable. Whatever the decision, one can be repre\nsented using the class label and one using an assertion on\nan \"annotation property\": in OWL-DL, we can declare a\nproperty to be an annotation property, and then use such\na property to attach information to classes-without them\nbeing taken into account by an OWL-DL reasoner. That is,\nassertions on annotation properties act as comments from\na DL point of view, yet they can be displayed to the biolo\ngist as a piece of information on this class-just as in GO.\nThe most suitable annotation property for labelling a term\nwith its id is rdfs:label, which is already included in OWL.\nWe cannot translate the natural language definitions asso\nciated with a term into OWL-DL axioms. These definitions\nmight be expressible in OWL, yet we cannot automatically\ngenerate the correct OWL-DL expressions from a piece of\nEnglish text. We can, however, capture them using\nanother assertion on an annotation property.\nWe can capture the synonyms and other alternative labels\ngiven for a term in a variety of ways:\n1. As assertions on an annotation property;\n2. Using equivalence, subclass and superclass axioms;\n3. A mixture of approaches one and two.\nIn the first approach, we can use a series of annotation\nproperties such as exact synonym, broad synonym, nar\nrow synonym and related synonym.\nIn the second approach, if S1,...,Sn are the exact synonyms\ngiven for a term T, then we translate this into an equiva\nlence axiom EquivalentClasses(T S1...Sn). Thus, each\ninstance of Si is also an instance of T and each Sj and, vice\nversa, each instance of T is also an instance of each Si.\nIn OWL-DL, an equivalence axiom Equivalent\nClasses(T S) means that the classes T, S involved have\nhttp://www.biomedcentral.com/1471-2105/8/57\nthe same extent of instances. It can further be argued that\nthey are therefore the same class. If the synonyms are\nexact, this is logically correct, though the ontologist might\nbe presented with a plethora of classes in the user inter\nface. It can be argued, however, that for the user this is\nsimply a presentational issue, and that the user interface\nshould collapse equivalent classes. Some methodologies,\nsuch as [25], suggest that a minimal number of classes\nshould be used in an ontology. Use of equivalent classes\ndoes not break such an edict if we interpret classes with\nthe same extent of objects as the same class (which is, after\nall, what is being said). It should be remembered, as is the\nmessage all through this article, that the reader should be\nwary of conflating presentation and the real semantics of\na statement. Just as assumptions can be made about the\npresentation in Figure 1, so can assumptions be made\nabout syntax showing \"multiple\" classes in an OWL-DL\nfile.\nA more significant argument is that this solution conflates\na class level argument with a lexical argument. It should\nbe remembered that labels on classes can change, while\nthe class itself is unaltered. One only has to think, for\ninstance, of the different French, German and English\nwords for Leg that all refer to the same class of instances.\nAlso, the equivalence axiom approach breaks when the\nsynonyms are not exact synonyms. It could then be argued\nthat the synonym labels should not be used, but one of\nnarrow, broad or related. Hence the equivalence axiom\nsolution is slightly sub-optimal since we would have pre\nferred to have only a single class and more than one name\nfor it, yet this would have required some expressiveness\nnot (yet) available in OWL-DL, and the second approach\nhas largely the same effect. In a similar manner to the\nequivalence axiom, if we have an alternative name S that\nis \"broader than\" a term T, then we add a statement Sub\nclassOf(T S), and if we have an alternative name S that\nis \"narrower than\" a term T, then we add a statement\nSubclassOf(S T).\nPlease note that the second approach does not take into\naccount related class labels which are not either exact, nar\nrow nor broad, like virulence and pathogenesis. In this\ncase, we can only suggest to use the first approach. In\napproach two, we cannot completely translate all class\nlabels in an OWL-DL form, because the related-to tag has\nno reasonable representation as either subclass axiom or\nrestriction upon a class, so we would have to use approach\nthree, with a mixture of logical axioms and one assertion\non an annotation property.\nThe use of the extra equivalence and subclass axioms has\na logical argument and can be useful. When a reasoner is\napplied to such a translation, inconsistencies can be\nfound. If the translator, however, feels that this approach\nPage 8 of 13\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8:57\nmixes lexical and logical issues then only approach 1,\nusing only assertions on annotation properties is the most\nvalid approach.\nNext, the DAG is-a relationship translates directly into\nOWL's sub-class relationship since they have the same\nsemantics, i.e., every instance of a class is also an instance\nof each of its superclasses.\nWe can assume that subclasses in the DAG representation,\nlike OWL subclasses, overlap by default, i.e., if C1 and C2\nare subclasses of the same superclass, then we cannot\nexclude that there exists an object that is an instance of\nboth C1 and C2. This will capture most of the biology in\nGO correctly. However, we might want to examine the GO\nand check, for each pair of subclasses, whether we cannot\nprovide more information. For example, we should ask\nourselves whether it is possible for an individual molecu\nlar function to be both function-x and function-y at the\nsame time. If this is not the case, then we should make this\nknowledge explicit in the OWL ontology through the\naxiom DisjointClasses(function-x function-y).\nIn a similar manual step, we should add covering con\nstraints where appropriate. A covering axiom means that,\nif an object is a member of a class, then it must be a mem\nber of one of the classes that it is asserted to \"cover\". That\nis, if Person covers Man and Woman, then any object that\nis a Person must be either a member of Man or a member\nof Woman, but it is possible not to have enough informa\ntion to know to which of these classes that object belongs.\nFor a biological example, if Enzyme activity covers all the\nenzyme functions, then an enzyme activity must be one of\nthose activities; a new enzyme activity would be inconsist\nent with the ontology. The GO DAG representation does\nnot allow such axioms and we believe that biologists\nwould not use them widely even if it were possible\nbecause such axioms would require more knowledge than\nis usually available. An assumption of no covering is,\ntherefore, not unreasonable.\nSince the GO DAG does not capture disjointness or cover\ning constraints, its inclusion is a matter of capturing bio\nlogical knowledge, and there is no way of simply\nautomating knowledge of disjointness. An automatic\ntranslation is possible if it is assumed that there is no \"cov\nering\" and all sibling classes can possibly overlap.\n5.1 Capturing the GO DAG part-of in OWL\nOWL-DL provides a language that allows us to use as\nmany properties as we want, and we can constrain their\ninterpretation in a number of ways using existential, uni\nversal, or cardinality restrictions, and we can make state\nments about them such as one property being implied by\nanother one or that a property is transitive. In Section 4,\nhttp://www.biomedcentral.com/1471-2105/8/57\nwe have discussed four possible readings of the GO DAG's\npart-of links, and we show here how these different inter\npretations can be captured via translations to OWL-DL\naxioms. The advantage here is that, rather than using a sin\ngle construct which may be read in a number of different\nways, OWL-DL allows us to distinguish between these dif\nferent readings. We can then use different readings of the\npart-of relationship (e.g., those discussed in Section 4),\nwithout any danger of confusion. In the following exam\nples, we consider how we capture the particular semantics\nof the assertion P part-of W.\nReading 1 does not impose any restrictions on an\ninstance of P or W as they only deal with the potential for\nthe relationship. If one insists, one can translate this read\ning into an OWL-DL axiom\nSubClassOf (P UnionOf ((restriction(part-of\nsomeValuesFrom W))\nComplementOf\n(restriction(part-of\nsomeVal\nuesFrom W))),\nyet this statement does not impose any constraints:\nindeed, it is equivalent to saying that P is a subclass of\nOWL:thing or saying nothing. In contrast, impossibili\nties do impose constraints, and we can express them in\nOWL-DL: to express that a P can never be part of a W, we\ncan add the OWL-DL axiom\nSubClassOf (P ComplementOf (restriction(part\nofallValuesFromW)))\nReading 2 Whenever a P exists, it is part of a W. This can\nbe represented through the following axiom:\nSubClassOf(P restriction(part-of someValues\nFrom W)),\nstating that, for each and every instance of P, there must be\nan instance of W of which it is a part. For example, every\ninstance of SemiNiferousTubule is a part of an instance of\nTestis.\nReading 3 Whenever a W exists, it has some P as a part.\nThis can be represented through the following axiom:\nSubClassOf (W restriction(has-part someVal\nuesFrom P)),\nprovided that we have declared that the property has-part\nis the inverse of part-of, as in Figure 4 (many description\nlogics allow the definition and use of inverse relation\nships; in OWL there is no inverse property operator for use\nin expressions, but we can introduce and define properties\nPage 9 of 13\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8:57\nas inverses). Inverse properties are interpreted as one\nwould expect: two individuals a and b are related via a\nproperty P if and only if b and a are related via the inverse\nof P. For example, we can use such an axiom to state that\nevery instance of Testis has a part that is an instance of\nSemiNiferousTubule. Please note that this statement and\nthe one given as an example for the third reading are inde\npendent in the sense that they do not imply each other.\nReading 4 This is simply a conjunction of 2 and 3, and we\ncan thus encode it by including both axioms introduced\nabove.\nAs mentioned before, GO employs reading 2 for part-of\nlinks. Hence we translate each such link into the corre\nsponding OWL statement. Additionally, we can then\nmanually add more statements, e.g., in cases where our\nbiology tells us that reading 4 would be more precise.\nThese various semantics for the part-of relationship used\nin the GO DAG pre-date the OBO relationships described\nbelow in Section 6. In the OBO relationships, as we shall\nsee, the semantics are more strictly defined and the trans\nlation to an existential property on a class, as in interpre\ntation above, is clear.\nRecall that, in GO, orphan nodes are those that do not\nhave any outgoing is-a link. In OWL-DL, the correspond\ning classes do not cause any problems since they will be\nautomatically placed in the class hierarchy under the most\ngeneral class called OWL:thing. There are, therefore, no\norphan nodes in an OWL-DL ontology and any modelling\nthat makes any biological assertions to overcome placing\nsubclass axioms to OWL:thing must be part of a process\nindependent of the translation of representation.\nThat completes our discussion of the translation of GO's\nDAG into OWL-DL. We can see, therefore, that it is possi\nble to represent what is captured in the GO in OWL-DL\nwith making only two assumptions, both of which are rea\nsonable. The OWL-DL representation will capture the\nsame knowledge as the GO DAG. In addition, we can even\ndistinguish between the uses of readings two and four in\nthe part-of relationship in GO.\n5.2 Translating OWL-DL back into DAG\nAs we have observed above, the DAG's is-a relationship\nand the subclass relationship in an OWL-DL ontology\nhave the same reading. Hence we can take an OWL-DL\nrepresentation of a DAG ontology, ask a reasoner such as\nFaCT++, Pellet or Racer [26-28] to infer all subclass rela\ntionships, and then translate the resulting class hierarchy\nback into DAG format. To be more precise, for each class\nname A, we first ask the reasoner to return all classes that\nare equivalent (if we have used the translation of syno\nnyms using equivalence axioms described above) with A.\nhttp://www.biomedcentral.com/1471-2105/8/57\nThen we choose a \"main\" node label A' from A and the\nreasoner's answer, and create a node labelled A' whose\nexact synonyms are set to A (in case that A' is different\nfrom A) and the reasoner's answer (possibly minus A'). As\na result of this step, we obtain a set of nodes labelled with\nterms and exact synonyms. Next, for each pair of node\nlabels A, B, we ask the reasoner whether A is a subclass of\nB. If this is the case, we add an is-a link from A to B, oth\nerwise we do not do anything. Similarly, for each pair of\nnode labels A, B, we ask the reasoner whether A is a sub\nclass of restriction(part-of someValuesFrom B). If\nthis is the case, we add a part-of link from A to B, other\nwise we do not do anything. Narrow and broad synonyms\ncan be obtained by looking for subclasses and super\nclasses, respectively, yet this would be exactly the same\ninformation as represented in the is-a structure and thus\nredundant. Finally, those features of the GO DAG that we\nhave translated to assertions on annotation properties can\nbe retrieved and back-translated appropriately.\nAs a result, we obtain a graph whose nodes are labelled\nwith names and sets of synonyms, and whose edges are\nlabelled with is-a and part-of. If any axioms have been\nadded to the GO in OWL, such as disjointness or covering\naxioms, these are retrieved through calls to the reasoner.\nDisjointness can be represented in the OBO format (see\nSection 6 below), but covering cannot. So, the back-trans\nlation of an augmented GO in OWL might well be lossy;\ni.e., they are lost in translation. This would also be true of\nall those features of OWL-DL that cannot be expressed in\nthe OBO format. In general, this graph might not neces\nsarily be acyclic, i.e., it may contain cycles. Since the GO\nDAG only allows part-of and not has-part relationships,\nhowever, common sense tells us that we should obtain an\nacyclic graph: a cycle would need to involve a part-of link\nsince pure is-a cycles have been collapsed into a single\nnode by construction. Now a cycle involving a part-of\nlink, say from a node labelled A, would mean that, in\nevery world conforming to our ontology, we have an infi\nnite chain of instances ai of A with a1 part-of a2 part-of a3\npart-of..., which clearly clashes with our intuition. How\never, if other relationships are used in the DAG, such as\nhas-location or interacts-with, a cycle could easily arise\n(e.g. a protein that interacts with itself). As we will see\nbelow (Section 6) the wider OBO language allows cycles.\n6 Representing other OBO relationships in\nOWL\nOpen biomedical Ontologies (OBO [5]) is a collection of\nbio-ontologies, and they come with a core set of biologi\ncal properties for use within OBO ontologies [29,30]. The\naim is to have consistent interpretation and use of proper\nties representing biological relationships. Here we\ndescribe what aspects of the OBO relationships can be\nrepresented in OWL. The OBO relationships talk about\nPage 10 of 13\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8:57\nproperties at three levels, and we can easily distinguish\nthese relationships in OWL:\n1. Stating that an individual a is an instance of a class C:\nthis is expressed by\nIndividual(a type C)\n2. Stating that an individual a is related via a certain prop\nerty P with an individual b: this is expressed by\nIndividual(a P b)\n3. Stating that each instance of a class C is related via a\nproperty P to some instance of a class D.\nSubClassOf(C restriction(P someValuesFrom\nD))\nIn our experience, the third of the above relationships is\nthe most commonly used in building ontologies based on\nclasses, where the (all - some) form of definition used in\nthe OBO relationships fits perfectly with the DL style of\nrelationships [31]. The OBO relationships, so far at least,\nare therefore readily mapped to a restriction with existen\ntial quantification. The OBO relationships are of the third\nkind, but built upon a series of primitive relationships\nbetween instances such as part-of holding between two\ncontinuants; located-in holding between a continuant\nand a region; derives-from holding between two continu\nants; etc.\nAs mentioned, these basic OBO relationships can be\nexpressed in OWL. In OBO, they are extended, however,\nto take into account both temporal and spatial aspects,\nnone of which can be expressed in OWL: for example,\nOWL allows us to state that every instance of C must be\nlocated-in an instance of D, yet we can not express that an\ninstance of C' must eventually be located-in an instance of\nD or that an instance of E will eventually be an instance of\na class F. For example, we might want to express that Adult\nis -a-cont child because an instance of the class Adult\nhas at some previous time point been a Child. Since OWL-DL\ntakes an entirely static view of the world, such a statement\ncannot be made in OWL. There are extensions of (the DL\nunderlying) OWL-DL that can deal with these temporal\naspects [32], but the reasoners used for OWL-DL do not\nhandle these logics nor does the OWL-DL syntax or\nsemantics accommodate these temporal aspects.\nThe OBO file format includes several aspects that should\nbe translated into OWL; some of them are required\naspects, others are optional, see Table 1. Some of these\naspects have already been analysed in this paper for the\nGO's\nDAG:\nthe\nsynonyms\n(related_synonym,\nhttp://www.biomedcentral.com/1471-2105/8/57\nexact_synonym,\nbroad_synonym\nand\nnarrow_synonym), is_a (sub-class relationship in OWL),\nrelationship (existential restrictions in OWL, as already\ndescribed in the case of part-of) and is_transitive (transi\ntive properties in OWL). For the rest, the translation is\nprovided in Table 1. It is intended that the OBO language\nhas the same semantics as OWL (personal communica\ntion with Chris Mungall from the Gene Ontology Consor\ntium) and this is the approach we have adopted, though\nthe documentation was at times unclear.\nIn Table 1, many of the OBO entries are described as being\n\"extra-logical\" in OWL-DL. This means that they are not\npart of the descriptions of the objects in a class. For\ninstance, a GO id is a description of the class, not a\ndescription of the instances or objects of that class. OWL\nDL can currently only represent these extra-logical aspects\nwith the annotation properties mentioned earlier in Sec\ntion 5.\nThe OBO optional tag is_cyclic is intended to convey that\na relationship can be used to form cycles (such as, inter\nacts-with forming cycles of interacting proteins). Proper\nties in OWL-DL are inherently free to do this and so\nis_cyclic could only be preserved as another annotation\nproperty.\nThe OBO file format allows for property hierarchies (for\nexample in the Sequence Ontology [33]), but the DAG\ndoes not use them. For the wider OBO representation, it\nis perfectly possible to translate property hierarchies.\n7 Implementation\nThis translation has been implemented as a Java (1.5) pro\ngramme [34]. It takes a GO ontology expressed in the\nOBO 1.0 format [8] and produces the same ontology\nexpressed in OWL DL in the RDF/XML syntax [35].\nThe OBO flat file is read and the WonderWeb OWL API\n[36] is used to create the OWL-DL ontology. The OBO flat\nfile is parsed and loaded into memory as an intermediate\nrepresentation that is later explored by the programme\nand each OBO element is used, as appropriate, to supply\nparameters to operations on the WonderWeb API. For\nexample, two class identifiers are supplied to the subclass\noperation to create an OWL subclass axiom; the id of the\nOBO term is supplied as a value for rdfs:label property;\nthe second half of the OBO part-of relationship is sup\nplied as a filler for an existential restriction on the part-of\nobject property; and so forth. Finally a new OWL file in\nRDF/XML syntax is created on the hard disk.\nThe translation uses the approach 2 to deal with syno\nnyms: exact synonyms, narrow synonyms and broad syn-\nPage 11 of 13\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8:57\nhttp://www.biomedcentral.com/1471-2105/8/57\nTable 1: Translation of OBO aspects into OWL.\nOBO stanza\nOWL\nRequired/Optional\nname\nOWL-DL class name\nrequired\nid\nExtra-logical\nrequired\nalt_id\nExtra-logical\noptional\nnamespace\nOWL namespace\noptional\ndefinition\nExtra-logical\noptional\ncomment\nExtra-logical\noptional\nsubset\nExtra-logical\noptional\nrelated_synonym\n\"Some values from\" restriction on\noptional\nrelated_synonym\nexact_synonym\nEquivalent class\noptional\nbroad_synonym\nSuperclass\noptional\nnarrow_synonym\nSubclass\noptional\nxref_analog\nExtra-logical\noptional\nxref_unknown\nExtra-logical\noptional\nis_a\nSubclass\noptional\nrelationship\n\"Some values from\" restriction on object\noptional\nproperty\nis_obsolete\nExtra-logical\noptional\nuse_term\nObject property\noptional\ndomain\ndomain\noptional\nrange\nrange\noptional\n\nis_cyclic\n(see Section 6)\noptional\nis_transitive\ntransitive\noptional\nis_symmetric\nsymmetric\noptional\nonyms are translated as new equivalent classes, subclasses\nand superclasses, respectively.\n8 Discussion\nIn this paper we have attempted to convey why computer\nscientists seem to care so much about a representation\nlanguage's semantics. In essence, it is in order to prevent\nambiguity of interpretation (at a far simpler level than\nintention) of statements in the language. We only have to\nthink back to our toy informal ontology for Man and\nWoman to see the trouble that imprecision can give. One\nonly has to substitute genes, proteins, processes, etc. into\nthese types of informal statement to realise the wide vari\nety of interpretations that can be placed on ill-defined\nstatements. \"P53 activates transcription\"-is all transcrip\ntion activated by P53? do all P53 activate transcription? In\nthis sense formality is very useful. OWL is, of course, not\nthe only formal language. Our point here is, however, to\nexemplify the benefits of such formality in communicat\ning to humans and computers.\nBy examining the semantics of OWL-DL and GO's DAG,\nwe have seen that converting from GO DAG to OWL-DL\npresents no real problem, as long as we are willing to\nmake assumptions on disjointness and covering. We can\neven translate our OWL-DL ontology back into DAG.\nThere are various benefits of having an OWL-DL version\nof a DAG ontology. Firstly, we can say things in OWL-DL\nthat we cannot say in DAG, and we can thus make prop\nerties and relations explicit. For example, we can express\ncovering between classes, we can use properties in both\ndirections, and we can formulate necessary and sufficient\ndefinitions of classes. Secondly, these statements are ame\nnable to machine interpretation: that is, we can have an\nOWL-DL reasoner classify our ontology and detect incon\nsistent classes. This can help us find modeling errors in\nour ontology, e.g., when the reasoner comes back with un\nintended inferred is-a links or inconsistent classes, and\nthus supports the design of a good ontology. Thirdly, we\ncan annotate documents with complex OWL-DL class\ndescriptions and have the reasoner take these into account\nwhen answering queries. That is, we are no longer\nrestricted to the classes present in the ontology, but we can\nmake them up on-the-fly and have these descriptions\ntaken into account for query answering. In DL style ontol\nogies, it is common for classes defined in an ontology to\nbe the building blocks of other classes, rather than enu\nmerating all the possible classes. Obviously, converting an\nontology that comes with such expressiveness and infer\nence services to one that lacks them might lead to an\nimpoverished ontology. Fourthly, we can extend our\ntranslations in a straightforward way to other OBO rela\ntions.\nIn summary, we have described the role of a language's\nsemantics. We have also described the role and benefits of\na representation language with well-defined semantics\nand reasoning support. The core of the argument is that, if\nPage 12 of 13\n(page number not for citation purposes)\n\nBMC Bioinformatics 2007, 8:57\nontologies are to fulfill their role of providing a common,\nshared understanding of a knowledge domain, then the\nstatements within that ontology have to be able to be\ninterpreted unambiguously. We then examined the\nsemantics of GO's DAG and compared it with OWL-DL.\nOur results of examining the expressive means provided\nby both formalisms and their semantics is that conver\nsions between the OBO representation and the GO DAG\nsubset is possible (within some constraints) and leads to\ninteresting new possibilities.\n9 Authors' contributions\nAll authors contributed both writing and thought to this\npaper. MEA led this effort. RS, SB, PL and US produced an\nearly draft and MEA brought it to conclusion, including\nthe implementation. US and SB provided expertise on\nOWL and description logics. All authors read and\napproved the final manuscript.\nAdditional material\nAdditional File 1\n\"Glossary\". list of computer science terms used in this article, with their\ndefinitions.\nClick here for file\n[http://www.biomedcentral.com/content/supplementary/1471\n2105-8-57-S1.pdf]\n10 Acknowledgements\nMEA is funded by Manchester University and EPSRC. The authors would\nlike to thank Chris Mungall and Amelia Ireland for their help with GO, the\nGO DAG and the OBO file format.\nReferences\n1.\nGene Ontology Consortium: Gene Ontology: Tool for the Uni\nfication of Biology. Nature Genetics 2000, 25:25-29.\n2.\nOWL Web Ontology Language Guide [http://www.w3.org/TR/\nowl-guide]\n3.\nHorrocks I, Patel-Schneider PF, van Harmelen F: From SHIQ and\nRDF to OWL: The Making of a Web Ontology Language.\nJournal of Web Semantics 2003, 1:7-26.\n4.\nGene Ontology Consortium: Creating the Gene Ontology\nresource: Design and Implementation. Genome Research 2001,\n11:1425-1433.\n5.\nOpen Biomedical Ontology [http://obo.sourceforge.net]\n6.\nBada M, Stevens R, Goble C, Gil Y, Ashburner M, Blake JA, Cherry JM,\nHarris M, Lewis S: A Short Study on the Success of the Gene\nOntology. Journal of Web Semantics 2004, 1:.\n7.\nGO downloads [http://geneontology.org/GO.downloads.shtml]\n8.\nFile format guide\n[http://www.geneontology.org/GO.for\nmat.shtml]\n9.\nDAG-Edit user guide [http://www.godatabase.org/dev/java/dage\ndit/docs/index.html]\n10. OBO-Edit user's guide\n[http://www.godatabase.org/dev/java/\noboedit/docs/index.html]\n11. Aitken S, Korf R, Webber B, Bard J: COBrA: a bio-ontology edi\ntor. Bioinformatics 2005, 21(6):825-826.\n12. Gene Ontology Next Generation\n[http://www.gong.manches\nter.ac.uk/]\n13. Wroe C, Stevens R, Goble C, Ashburner M: A Methodology to\nMigrate the Gene Ontology to a Description Logic Environ\nhttp://www.biomedcentral.com/1471-2105/8/57\nment Using DAML+OIL. 8th Pacific Symposium on biocomputing\n(PSB) 2003:624-636.\n14. MAPPING OBO TO OWL\n[http://www.godatabase.org/dev/\ndoc/mapping-obo-to-owl.html]\n15. Goodwin J: Experiences of using OWL at the Ordenance Sur\nvey. Proc of OWL Experiences and Directions 2005.\n16. Baader F, Calvanese D, McGuinness D, Nardi D, Patel-Schneider P,\n(Eds): The Description Logic Handbook Theory, Implementation and Appli\ncations Cambridge University Press; 2003.\n17. Duce D, Ringland G: Background and Introduction. In\nApproaches to Knowledge Representation: An Introduction Edited by: Rin\ngland GA, Duce DA. New York: Wiley; 1988:1-12.\n18. Stevens R, Goble C, Horrocks I, Bechhofer S: Building a Bioinfor\nmatics Ontology Using OIL. IEEE Transactions on Information Tech\nnology and Biomedicine 2002, 6(2):135-41.\n19. Stevens R, Goble C, Horrocks I, Bechhofer S: OILing the Way to\nMachine Understandable Bioinformatics Resources.\nIEEE\nTransactions on Information Technology and Biomedicine 2002, 6:129-34.\n20. Smith B, Williams J, Schulze-Kremer S: The Ontology of the Gene\nOntology. Annual symposium of American Medical Informatics Associa\ntion (AMIA) 2003.\n21. The GO Editorial Style Guide\n[http://www.geneontology.org/\nGO.usage.shtml]\n22. Winston M, Chaffin R, Herrmann D: A Taxonomy of Part-Whole\nRelations. Cognitive Science 1987, 11:417-444.\n23. Yeh I, Karp PD, Fridman Noy N, Altman RB: Knowledge acquisi\ntion, consistency checking and concurrency control for Gene\nOntology (GO). Bioinformatics 2003, 19(2):241-248.\n24. Simons PM: Parts. A study in Ontology Oxford: Clarendon; 1987.\n25. Gomez-Perez A, Juristo N: METHONTOLOGY: From Ontolog\nical Art Towards Ontological Engineering. Engineering Work\nshop on Ontological Engineering (AAAI97) 1997.\n26. Tsarkov D, Horrocks I: Optimised Classification for Taxonomic\nKnowledge Bases. Proc of the 2005 Description Logic Workshop (DL\n2005) 2005.\n27. Sirin E, Parsia B, Cuenca Grau B, Kalyanpur A, Katz Y: Pellet: A\nPractical OWL-DL Reasoner.\n[http://www.mindswap.org/\npapers/PelletJWS.pdf]. [Submitted for publication to the Journal of\nWeb Semantics].\n28. Haarslev V, Moller R: RACER System Description. IJCAR-01, Vol\nume 2083 of LNAI, SV 2001.\n29. Smith B, Ceusters W, Klagges B, Kohler J, Kumar A, Lomax J, Mungall\nC, Neuhaus F, Rector A, Rosse C: Relations in biomedical ontol\nogies. Genome Biology 2005, 6(5):R46.\n30. OBO relation ontology [http://obofoundry.org/ro/]\n31. Levesque H, Brachman R: A fundamental tradeoff in knowledge represen\ntation and reasoning Morgan Kaufman. Readings in Knowledge Repre\nsentation; 1985:41-70.\n32. Wolter F, Zakharyaschev M: Temporalising Description Logics.\nIn Frontiers of Combining Systems Volume 2. Edited by: Gabbay D, de\nRijke M. Studis Press/Wiley; 2000.\n33. Eilbeck K, Lewis S, Mungall C, Yandell M, Stein L, Durbin R, Ashburner\nM: The Sequence Ontology: a tool for the unification of\ngenome annotations. Genome Biology 2005, 6(5):R44.\n34. GO to OWL converter\n[http://www.gong.manchester.ac.uk/\ndownloads/]\n35. OWL Web Ontology Language Reference\n[http://\nwww.w3.org/TR/owl-ref/]\n36. OWL API [http://sourceforge.net/projects/owlapi]\nPage 13 of 13\n(page number not for citation purposes)"
    },
    {
      "category": "Lecture Notes",
      "title": "An XML Standard for the Dissemination of Annotated 2D Gel Electrophoresis Data Complemented with Mass Spectrometry Results",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/20-453j-biomedical-information-technology-fall-2008/7faff9d713e516e5c69403701d2c93a3_stanislaus_bmc.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n20.453J / 2.771J / HST.958J Biomedical Information Technology\n\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nBioMed Central\nBMC Bioinformatics\nResearch article\nOpen Access\nAn XML standard for the dissemination of annotated 2D gel\nelectrophoresis data complemented with mass spectrometry\nresults\nRomesh Stanislaus*1, Liu Hong Jiang1, Martha Swartz2, John Arthur2 and\nJonas S Almeida1\nAddress: 1Department of Biostatistics, Bioinformatics and Epidemiology, Medical University of South Carolina, Charleston, South Carolina, USA\nand 2Department of Medicine, Medical University of South Carolina, Charleston, South Carolina, USA\nEmail: Romesh Stanislaus* - stanisrc@musc.edu; Liu Hong Jiang - jiangliu@musc.edu; Martha Swartz - swartzm@musc.edu;\nJohn Arthur - arthurj@musc.edu; Jonas S Almeida - almeidaj@musc.edu\n* Corresponding author\nPublished: 29 January 2004\nReceived: 03 September 2003\nBMC Bioinformatics 2004, 5:9\nAccepted: 29 January 2004\nThis article is available from: http://www.biomedcentral.com/1471-2105/5/9\n(c) 2004 Stanislaus et al; licensee BioMed Central Ltd. This is an Open Access article: verbatim copying and redistribution of this article are permitted in all\nmedia for any purpose, provided this notice is preserved along with the article's original URL.\nAbstract\nBackground: Many proteomics initiatives require a seamless bioinformatics integration of a range\nof analytical steps between sample collection and systems modeling immediately assessable to the\nparticipants involved in the process. Proteomics profiling by 2D gel electrophoresis to the putative\nidentification of differentially expressed proteins by comparison of mass spectrometry results with\nreference databases, includes many components of sample processing, not just analysis and\ninterpretation, are regularly revisited and updated. In order for such updates and dissemination of\ndata, a suitable data structure is needed. However, there are no such data structures currently\navailable for the storing of data for multiple gels generated through a single proteomic experiments\nin a single XML file. This paper proposes a data structure based on XML standards to fill the void\nthat exists between data generated by proteomics experiments and storing of data.\nResults: In order to address the resulting procedural fluidity we have adopted and implemented a\ndata model centered on the concept of annotated gel (AG) as the format for delivery and\nmanagement of 2D Gel electrophoresis results. An eXtensible Markup Language (XML) schema is\nproposed to manage, analyze and disseminate annotated 2D Gel electrophoresis results. The\nstructure of AG objects is formally represented using XML, resulting in the definition of the AGML\nsyntax presented here.\nConclusion: The proposed schema accommodates data on the electrophoresis results as well as\nthe mass-spectrometry analysis of selected gel spots. A web-based software library is being\ndeveloped to handle data storage, analysis and graphic representation. Computational tools\ndescribed will be made available at http://bioinformatics.musc.edu/agml. Our development of\nAGML provides a simple data structure for storing 2D gel electrophoresis data.\nBackground\npost-genomic era due to the sheer volume and diversity of\nThe dissemination of information gathered by high\nexperimental data. The challenge is compounded by the\nthroughput methods is particularly challenging in the\nlack of widely accepted standards for all but the most well\nPage 1 of 7\n(page number not for citation purposes)\n\nBMC Bioinformatics 2004, 5\nestablished methods. This is especially true in the field of\nproteomics [1] due to competing methodologies and the\nneed for some measure of user intervention in data\nannotation.\nProteomics for a major part relies on experimental analy\nsis to identify and elucidate proteins in the cell. One of the\nmajor experimental methods used in the identification of\nproteins is 2D gel electrophoresis (2DE) coupled with\nmass spectrometry (MS). 2DE/MS systems have the ability\nto identify a large number of proteins in a single sample.\nStudies have shown that 2DE/MS systems could identify\nsomewhere in the region of thousands of proteins per\nsample [2-4]. Thus, the amount of information obtained\nby 2DE/MS is enormous in terms of data. In addition, the\nchoice of 2DE \"spots\" to analyze through MS is often the\nobject of human intervention. Finally, the 2DE gel matrix\nis characterized by heterogeneity that results in distortion\nin the electrophoretic migration pattern. These properties\nplace a high demand on pre-processing, thus requiring to\nmanually curate the gels. The experimental procedures\nadopted may vary depending on the researcher, but typi\ncally results in the creation of a composite representation\nof repeat analysis often designated as an annotated \"vir\ntual gel\". The protein isolates (spots) are subsequently\nanalyzed by mass spectrometry and referenced to the nor\nmalized position in the composite representation (i.e. the\nvirtual gel). The procedure described outlines not only the\nneed of a standard notation to represent the diverse data\ngenerated in the process but also the need for support-\nintensive manipulation by both users and computational\ntools specific to the analytical equipment used. Finally,\nthe stored common representation will also need to be\nregularly updated by bioinformatic tools that automati\ncally query ever-enlarging public repositories.\nThe eXtensible Markup Language (XML) is particularly\nwell suited to represent biological data and methods and\nis presently the consensus choice in most areas [5-11].\nAccordingly, XML syntax notation was used in this report\nto identify a suitable syntax for data collected by 2DE/MS\nsystems, which was designated as Annotated Gel Markup\nLanguage (AGML). XML notation provides a structured\ndocument representation of 2DE/MS experimental data\nthat can be transmitted over the Web as universally under\nstandable, self-describing documents. The main advan\ntage in XML is that data could be integrated in context\nwithin a single document, thereby making the data imme\ndiately meaningful to a reader, human or machine.\nThe recent proposals for a formal model to represent a\nproteomics workflow such as PEDRo (Proteomics Experi\nment Data Repository) [12] and HUPO ML http://\npsidev.sourceforge.net/proteomics, provides a structure\nfor proteomics experiments. The model covers many\nhttp://www.biomedcentral.com/1471-2105/5/9\naspects of a proteomics experiment including sample ori\ngin, separation techniques and mass spectrometry data\nanalysis. However, it does not provide a structure for stor\ning and dissemination of 2DE/MS data for multiple gel\nruns generated from a single experiment in the same XML\nfile. PEDRo puts a much stronger emphasis on MS Analy\nsis, while AGML is clearly 2DE centric. PEDRo and HUPO\nML framework consist of many distributed entities that\nneed software from the authors to see it. AGML however,\nconsist of one XML file with all the relevant information\non that experiment. Also, AGML is always stored as a XML\nfile. Additionally, there are similar projects, such as SASH\nIMI http://sashimi.sourceforge.net/, that have been devel\noped to provide XML markup to mass spectrometry data\nand GAML http://www.gaml.org that have been devel\noped to store and archive analytical instrument data.\nAGML and GAML (Generalized analytical markup lan\nguage) bear a structural similarity to each other, however\nits functions and reasons it was developed for are quite\ndifferent. For example, GAML stores and archives data\nfrom analytical instruments, on the other hand AGML\nstores and archives data from 2DE/MS experiments.\nThus considering the diversity of the data generated\nthrough 2DE/MS experiments and a lack of a universal\nstructure for storing and dissemination of 2DE/MS data,\nwe propose AGML as a common representative language\nfor storing and disseminating 2DE/MS experimental data.\nResults\nAGML version 1.0 was created and implemented as\ndescribed in Figure 1 using Unified Modeling Language\n(UML). Many AGML elements are optional, although\nsome are required to identify the data. This allows the user\nto use the markup even when not all the necessary infor\nmation is available. The user can then enter the informa\ntion as it becomes available. An AGML document\ndescribes one 2DE/MS experiment that may include one\nor many gels and, the conditions under which the gels\nwere run. In addition, it also includes a virtual image,\noften designated as the virtual gel, generated as a compos\nite of real gels as described under materials and methods.\nIt should be noted that many commercial gel analysis soft\nware packages accommodate the composition of virtual\ngel documents. Accordingly, the virtual gel information\nwould have to be parsed from the results file generated by\nthe package. The following is a description of the imple\nmentation of AGML schema.\nGel information Section\nThis\nsection\nconsists\nof\ntwo\nsub-sections:\n<sample_type>describing the sample information and the\ntion describing the running conditions.\normation includes the tissue type and the\nfrom where the sample was collected.\nPage 2 of 7\n(page number not for citation purposes)\n<conditions>sec\nThe sample inf\nstrain/species\n\nUnified Modeling Language (UML) representation of AGML data model\nBMC Bioinformatics 2004, 5\nhttp://www.biomedcentral.com/1471-2105/5/9\nFigure 1\nUnified Modeling Language (UML) representation of AGML data model. The dashed line separates the spot-specific from the\ngel-specific data described in the text as distinct AGML sections. The separation reflects an analytical distinction between the\nelectrophoretic component from the image analysis and mass spectrometry. However, the integration in the common AGML\ndocument is seamless. It is represented here for explanatory purposes only. The UML diagram represented was generated\nusing FUJABA http://www.fujaba.de/.\nUnder the sample information the user could include as\nmuch information as deemed useful.\nThe next section gives a description of the running condi\ntions under which the gels were run. It includes tags for\nthe description of the apparatus and chemicals used in the\nexperiment. Additionally, under <sample_prep>element\nthe details of the sample preparation protocol or other rel\nevant material could be included.\nUnder the element tag <first_dimension>, many tags are\navailable to include different variables used during the iso\nelectric focusing period in a 2DE experiment. For exam\nple, tags are provided to markup the gel type, gradient\ntype, carrier ampholytes used, and the pH range\nemployed in the iso-electric focusing. In addition, tags are\nalso provided to markup the length of rehydration of the\ngel and the running conditions for the isoelectric focusing.\nUnder the element tag <second_dimension>, information\nregarding the second dimension in 2DE experiment could\nbe recorded. Tags provided in this section include the\n<apparatus>to identify the type of the apparatus used,\n<gel_composition>to describe the composition of the gel.\nAdditional description of the tagging system is detailed for\nintegrated documentation of individual spots and the var\nious gels that include them. The self-descriptive nature of\nthe XML notation greatly simplifies this task, particularly\nwhen accompanied by a UML diagram as represented in\nFigure 1.\nPage 3 of 7\n(page number not for citation purposes)\n\nBMC Bioinformatics 2004, 5\nSpot Information Section\nThe spot information section consist of two sections\nnamely\n<virtual>describing\nthe\nvirtual\ngel\nand\n<reals>describing the real gel characteristics. The <vir\ntual>is a composite representation of all the annotated\nspots found in the distinct real gels. The main advantage\nin having a virtual gel is the comprehensive consensus\nrepresentation of all the annotated spots, i.e. identified or\ncharacterized spots, in the entire 2DE/MS experiment.\nThe <reals>tag consists of the markup to identify spot\ninformation relating to a gel run in a 2DE/MS experiment.\nWithin the <reals>, tags are provided to identify each spot\nwithin a given real gel (<real>). Since a gel has many pro\ntein spots, under the <spots>tag many <spot>elements\ncould exist. Each <spot>tag, however, has other element\nthat uniquely identifies that spot within the gel. These\ninclude a unique id (<ssp_num>), pH (<spot_pi>), molecu\nlar weight (spot_mw>) and additional parameters. Addi\ntionally, if this spot was subjected to MS and identified,\ntags are provided to include the data generated through\nthis process. These include among other tags <database>,\n<search_engine>and, <species_limitations>(see Fig. 1 and\nweb link).\nWhen all the data specific to real gels are completed, the\nvirtual gel can be automatically composed within the\nAGML document. The virtual gel consists of all the spot\ninformation as <reals>, but with an additional tag,\n<real_gel_id>, to indicate from which real gel the spot\ninformation comes from. The software to generate a vir\ntual gel and real gels was written in PHP and Java(r) (see\navailability). The tag specifications are constantly being\nupdated; as such please see the AGML 1.0 web site for the\nlatest tag descriptions (see availability).\nData Input and Data Display\nThe method employed was generated for processing and\ndisplay of data generated by PDQUEST(r) software (Bio-\nRAD, Hercules, CA, USA). However, the proposed XML\nschema can be used to annotate any type of 2DE gel data.\nThe AGML data is displayed by way of a Java applet\nthrough a web interface (Fig. 2). The current implementa\ntion displays a web page that includes the virtual gel and\nsample information. Links are provided to access the real\ngels and spot information. Text file generated from\nPDQUEST can easily be uploaded, XML generated and\nviewed. The spots that are in the virtual gel are highlighted\nin the real gels with a different color to indicate where\neach spot came from.\nDiscussion\nThe aim of this paper is to propose standard XML syntax\nfor data exchange and visualization of 2DE/MS experi\nmental data that is designated as the annotated gel\nhttp://www.biomedcentral.com/1471-2105/5/9\nmarkup language (AGML). However, this does not limit\nadapting AGML, a XML application, for data storage [13].\nThe proposed AGML syntax captures the essence of a 2D\ngel experiment and its pertinent MS data, and conveys\nenough information to analyze and replicate the results.\nThe need to go beyond a format for data storage in the\ndevelopment of the AGML syntax is justified by the\ndiverse set of methods involved and, the enduring obsta\ncles to full automation. The need for a common format to\nmanipulate as well as to store the data is captured by the\nconcept of annotated \"virtual gel\". This practical solution\nwas reflected in the identification of the data model and\nultimately mimicked by the AGML schema.\nAGML syntax could easily be adapted by other applica\ntions to present the data in XML format. In this specific\napplication the 2DE experimental data was generated\nusing PDQUEST coupled with a MicroMass MALDI-TOF\ninstrument using MassLynx and Micromass global server\nsoftware for protein identification (MicroMass, Manches\nter, U.K.). The data generated from a 2DE/MS experiment\nusing the above instrumentation is stored using the man\nufacturer specific formatting as tab-delimited files. This\ntext file is then converted to AGML syntax through a web\ninterface using software written in PHP (see availability).\nThe conversion of the tab-delimited file to AGML syntax\nand, if requested, web-based graphical representation, is\nfully automated. The latter application illustrates the\nadvantage of using AGML as a common format as the\ngraphical displaying is in effect a web-based service avail\nable for any dataset represented in our proposed AGML\nsyntax notation. Registered users can then decide whether\nto deposit the AGML to the database. Since AGML con\nforms to the XML rules, it's highly flexible and simple to\nmodify [5]. This adaptability of the syntax, also known as\ncontent scalability, helps in defining new elements when\nnew information is acquired through 2DE/MS experi\nments. This is a great asset in an emerging field like pro\nteomics where new information is discovered at a rapid\npace, which requires a constant adaptation of the prevail\ning data model.\nIn the field of bioinformatics experimental data needs to\nbe analyzed, stored, updated and exchanged often by\nresearchers [5]. To this effect, a bioinformatics infrastruc\nture built around AGML will fulfill all these aspects for\n2DE/MS experimental data. The ultimate goal of develop\ning the AGML syntax, is to enable proteomics research to\nmove into the 'browsing mode' of searching through exist\ning information databases along similar lines as proposed\nby Aebersold [14,15].\nThe proposed AGML document contains the experimental\nprocedure, the experimental results and the composite vir\ntual gel. It is useful to compare the proposed standards\nPage 4 of 7\n(page number not for citation purposes)\n\nA Sample screenshot of the AGML Visualizer in action\nBMC Bioinformatics 2004, 5\nhttp://www.biomedcentral.com/1471-2105/5/9\nFigure 2\nA Sample screenshot of the AGML Visualizer in action. AGML Visualizer software is capable of reading AGML documents and\ndisplay a visual representation of virtual and real gels described in the AGML document instance. In this representative figure,\nthe real gel is shown as the small figure atop the virtual gel. Left side of the gel depicts all the pertinent information regarding\nthe gel (gel information as described in methods). The right side of the gel displays the information on a particular spot (spot\ninformation as described in methods). The AGML Visualizer is based on the AGML schema proposed in this paper.\nwith related work in transcriptomics. For example, MAGE\nML [16] has the representation of DNA array data in XML\nformat as the sole purpose. A similar focus on representa\ntion of data is found in ProML [17], which only includes\nthe protein sequence information while not making\nallowances for the description of the methodological pro\ncedure followed. The advantage in incorporating both the\nexperimental procedure and the results, as we have pro\nposed in AGML, is that the data could be understood in\nthe context of the experiment. The methodological detail\nfacilitates repeating the experiment documented in AGML\nby another researcher. Arguably, the need to include\nmethodological detail in AGML reflects unresolved meth\nodological challenges in proteomic profiling based on 2D\ngel electrophoresis, a lesser problem in sequencing or\ntranscriptomics projects.\nAGML can be incorporated to be used with large descrip\ntors of proteomics information. Using XML namespace\nrules, AGML markup can easily be incorporated into any\nother schema. Specifically, the PEDRo model proposed by\nTaylor et al. explicitly accommodates the representation\nof 2DE/MS data [12] where AGML could be particularly\nuseful. AGML by no way replaces the structure envisioned\nby PEDRo; instead proposes an XML format for handling\n2DE/MS data that can be incorporated into the existing\nlarge schemas such as PEDRo. In order to transmit subsets\nof information from this repository, the PEDRo model\nhas to employ other methods [12]. Accordingly, the\nPEDRo model could use AGML syntax to transmit the\ndescription of individual 2DE/MS experiments. For that\npurpose, the AGML could greatly benefit from general-\npurpose XML translation languages (e.g. XSLT). Addition\nally, with the wide use of resource description framework\n(RDF, http://www.w3.org/RDF), AGML can easily be\nPage 5 of 7\n(page number not for citation purposes)\n\nBMC Bioinformatics 2004, 5\nincorporated into other proposed model frameworks that\nhave been written in XML. Thus incorporating the\nstrengths of AGML, such as storing multiple gel runs per\nexperiment in the same file, with the strengths of other\nproposed models such as PEDRo and HUPO ML.\nConclusions\nAGML notation provides users with a compact representa\ntion scheme for 2DE/MS experimental data that can be\ndelivered over the World Wide Web as universally under\nstandable self-defining documents. In addition to the\nadvantages inherent to representing information as alpha\nnumeric strings that can be easily stored, transmitted\nbetween machines and between applications using\nemerging XML technologies such as SOAP, AGML is par\nticular suitable for usage in the development of proteom\nics web-services. The emphasis of AGML to accommodate\nnot only the data but also methodological detail reflects\nunresolved methodological challenges in proteomics pro\nfiling based on 2D Gel Electrophoresis. The proposed\nAGML syntax was developed for an integrative bioinfor\nmatics infrastructure encompassing a facility for high\nthroughput 2DE/MS, a computational biology group ana\nlyzing the data and, finally, researchers and clinicians col\nlecting the samples in a concerted effort to identify\nproteomic profile patterns indicative of various degrees of\nactive disease or predisposition thereof. As such AGML\nsyntax is ideal for incorporation into complex proteomics\nschemas such as PEDRo, as well as storing information as\na standalone applications, due to XML's self-describing\nnature, for future reference.\nMethods\nDesign principles\nFor the purpose of AGML, we attempted to include all\nessential information that is required to identify a spot\ngenerated in a 2D-gel electrophoresis experiment. In order\nto accomplish this we used meaningful syntax familiar to\ninvestigators in the field to markup the data and kept the\nmarkup to the sufficient minimum. The latter is impor\ntant to reduce the size of the document, which is impor\ntant in storage and transmission. Also, the syntax used\ndoes not constrain the meaning of the data it holds. The\nsyntax was designed merely to provide a placeholder in\ncontext for the data. An AGML document can represent\none 2DE/MS experiment consisting of the sample infor\nmation, running conditions and spot data of several gels\n(known as real gels) that were run per experiment (Fig. 1).\nIn addition, the AGML document should also contain a\ncomposite representation of the set of real gels, known as\nthe virtual gel, that represents the annotated spots of the\nreal gels. The virtual gel concept developed in AGML pro\nvides a representation of all the gels per experiment that\nhave their spots identified and annotated represented in\none virtual gel. This is somewhat different from other uses\nhttp://www.biomedcentral.com/1471-2105/5/9\nof the virtual gel concept in proteomics where it is meant\nto represent a reconstructed gel, whose molecular weight\ninformation is acquired by mass spectrometry rather than\nby gel electrophoresis [18]. In keeping to these guidelines\nwe propose the following structure for the XML applica\ntion AGML. An implementation decision was taken to fol\nlow a recommendation that all tags be elements with no\nattributes [19]. This is because the elements in AGML\nschema represent the logical units of information and fur\nther clarification, in our view, was not required.\nStructure of AGML documents\nThe AGML documents consist of two main sections: the\ngel information section, and the spot information section\n(Fig. 1). The gel information section describes the infor\nmation about the sample and the conditions under which\nthe sample was run. The spot information section consists\nof the spot information in each gel. Two subsections make\nup the spot information section, one that holds informa\ntion about the 2DE gels (known as real gels) and the other\nthe reconstructed virtual gel. The virtual gel represents the\nannotated spots in the real gels. In addition, under the\nroot element, elements are included to identify a specific\nAGML document. Thus, the main features of the structure\nof an AGML document are as follows:\nGel information section\n1) Sample section\nDescribes the pertinent information about the sample.\n2) Conditions sections\nDescribes 2DE-running conditions. In addition, it also\ncontains the instruments used, protocols and reagents.\nSpot information section\n3) Virtual gel section\nDescribes the virtual representation of all the annotated\nspots of real gel data.\n4) Real gel section\nStores the data from the 2DE experiment that were run per\nexperiment. It can contain any number of 2DE gels that\ndescribes the specific experiment. It can also include addi\ntional information from the mass spectrum of the protein\nspot that was used for the protein identification.\nXML schema for the proposed AGML structure and the\nelements defined in the schema are available on the\nAGML web site http://bioinformatics.musc.edu/agml.\nPage 6 of 7\n(page number not for citation purposes)\n\nBMC Bioinformatics 2004, 5\nAuthors' contributions\nRS and JSA devised the schema and wrote the manuscript.\nRS wrote the PHP scripts to handle data and to generate\nthe AGML documents. LHJ made the web interface and\nmaintains the AGML Visualizer. JA and MS provided\nexperimental expertise. JA contributed in writing the man\nuscript. All authors read and approved the final\nmanuscript.\nAcknowledgements\nWe would like to thank Shuyuan Wu for the critical reading of the manu\nscript and Jennifer Franklin for initial writing of the software for AGML Vis\nualizer. This work was supported by the NHLBI Proteomics Initiative\nthrough contract N01-HV-28181.\nReferences\n1.\nTyers M, Mann M: From genomics to proteomics. Nature 2003,\n422(6928):193-197.\n2.\nGorg A, Obermaier C, Boguth G, Harder A, Scheibe B, Wildgruber\nR, Weiss W: The current state of two-dimensional electro\nphoresis with immobilized pH gradients. Electrophoresis 2000,\n21(6):1037-1053.\n3.\nFey SJ, Larsen PM: 2D or not 2D. Two-dimensional gel\nelectrophoresis. Curr Opin Chem Biol 2001, 5(1):26-33.\n4.\nHarry JL, Wilkins MR, Herbert BR, Packer NH, Gooley AA, Williams\nKL: Proteomics: capacity versus utility. Electrophoresis 2000,\n21(6):1071-1081.\n5.\nAchard F, Vaysseix G, Barillot E: XML, bioinformatics and data\nintegration. Bioinformatics 2001, 17(2):115-125.\n6.\nFreier A, Hofestadt R, Lange M, Scholz U, Stephanik A: BioDa\ntaServer: a SQL-based service for the online integration of\nlife science data. In Silico Biol 2002, 2(2):37-57.\n7.\nKitano H: Standards for modeling. Nat Biotechnol 2002, 20(4):337.\n8.\nLacroix Z: Biological data integration: wrapping data and\ntools. IEEE Trans Inf Technol Biomed 2002, 6(2):123-128.\n9.\nMartin AC: Can we integrate bioinformatics data on the\nInternet? Trends Biotechnol 2001, 19(9):327-328.\n10. Matsuno H, Doi A, Hirata Y, Miyano S: XML documentation of\nbiopathways and their simulations in Genomic Object Net.\nGenome Inform Ser Workshop Genome Inform 2001, 12:54-62.\n11. Juty NS, Spence HD, Hotz HR, Tang H, Goryanin I, Hodgman TC:\nSimultaneous modelling of metabolic, genetic and product-\ninteraction networks. Brief Bioinform 2001, 2(3):223-232.\n12. Taylor CF, Paton NW, Garwood KL, Kirby PD, Stead DA, Yin Z,\nDeutsch EW, Selway L, Walker J, Riba-Garcia I et al.: A systematic\napproach to modeling, capturing, and disseminating pro\nteomics experimental data. Nat Biotechnol 2003, 21(3):247-254.\n13. Bos B: XML representation of relational database. 1997 [http:/\n/www.w3.org/XML/RDB.html].\n14. Aebersold R: Constellations in a cellular universe. Nature 2003,\n422(6928):115-116.\n15. Marte B: proteomics. Nature 2003, 422(6928):191.\n16. Spellman PT, Miller M, Stewart J, Troup C, Sarkans U, Chervitz S,\nBernhart D, Sherlock G, Ball C, Lepage M et al.: Design and imple\nmentation of microarray gene expression markup language\n(MAGE-ML). Genome Biol 2002, 3(9):RESEARCH0046.\n17. Hanisch D, Zimmer R, Lengauer T: ProML - the protein markup\nlanguage for specification of protein sequences, structures\nand families. In Silico Biol 2002, 2(3):313-324.\n18. Walker AK, Rymar G, Andrews PC: Mass spectrometric imaging\nof immobilized pH gradient gels and creation of \"virtual\"\ntwo-dimensional gels. Electrophoresis 2001, 22(5):933-945.\n19. Cover R: SGML/XML Elements versus Attributes: When\nshould I use Elements, and when should I use Attributes?\n2000 [http://www.oasis-open.org/cover/elementsAndAttrs.html].\nhttp://www.biomedcentral.com/1471-2105/5/9\nPublish with BioMed Central and every\nscientist can read your work free of charge\n\"BioMed Central will be the most significant development for\ndisseminating the results of biomedical research in our lifetime.\"\nSir Paul Nurse, Cancer Research UK\nYour research papers will be:\navailable free of charge to the entire biomedical community\npeer reviewed and published immediately upon acceptance\ncited in PubMed and archived on PubMed Central\nyours -- you keep the copyright\nBioMedcentral\nSubmit your manuscript here:\nhttp://www.biomedcentral.com/info/publishing_adv.asp\nPage 7 of 7\n(page number not for citation purposes)"
    }
  ]
}