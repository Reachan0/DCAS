{
  "course_name": "The History of Computing",
  "course_description": "This course focuses on one particular aspect of the history of computing: the use of the computer as a scientific instrument. The electronic digital computer was invented to do science, and its applications range from physics to mathematics to biology to the humanities. What has been the impact of computing on the practice of science? Is the computer different from other scientific instruments? Is computer simulation a valid form of scientific experiment? Can computer models be viewed as surrogate theories? How does the computer change the way scientists approach the notions of proof, expertise, and discovery? No comprehensive history of scientific computing has yet been written. This seminar examines scientific articles, participantsâ€™ memoirs, and works by historians, sociologists, and anthropologists of science to provide multiple perspectives on the use of computers in diverse fields of physical, biological, and social sciences and the humanities. We explore how the computer transformed scientific practice, and how the culture of computing was influenced, in turn, by scientific applications.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Humanities",
    "History",
    "History of Science and Technology",
    "Modern History",
    "Engineering",
    "Computer Science",
    "Humanities",
    "History",
    "History of Science and Technology",
    "Modern History"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 1 session / week, 3 hours / session\n\nDescription\n\nThis course will focus on one particular aspect of the history of computing: the use of the computer as a scientific instrument. The electronic digital computer was invented to do science, and its applications range from physics to mathematics to biology to the humanities. What has been the impact of computing on the practice of science? Is the computer different from other scientific instruments? Is computer simulation a valid form of scientific experiment? Can computer models be viewed as surrogate theories? How does the computer change the way scientists approach the notions of proof, expertise, and discovery? No comprehensive history of scientific computing has yet been written. This seminar will examine scientific articles, participants' memoirs, and works by historians, sociologists, and anthropologists of science to provide multiple perspectives on the use of computers in diverse fields of physical, biological, and social sciences and the humanities. We will explore how the computer transformed scientific practice, and how the culture of computing was influenced, in turn, by scientific applications.\n\nRequirements\n\nStudents are expected to participate in class discussions by reading the assigned materials before class, thinking about the issues and historical patterns suggested in the readings, and relating these issues to their own personal experience. Students will submit a short (one page) reading response paper in the morning before each class. The papers are intended to provoke discussion, rather than give definitive answers. The instructor will provide tentative questions for response papers, but students are encouraged to raise their own questions. The response papers will serve as a basis for subsequent discussion in class.\n\nAssignments for this course also include a final paper (10-15 pages; typed, double-spaced, with 1.25\" margins). The final paper is due in class on Session 14. On that day, students will give brief presentations (5-10 min.) of their final papers. A proposal for the final paper (1-2 pages) is due in class on Session 9. It will receive the instructor's feedback the following week. The proposal should include:\n\nthe central question the final paper will address;\n\nthe historical significance of this question and how it relates to discussions in class;\n\na brief outline; and\n\na tentative bibliography, including both primary and secondary sources.\n\nGrading\n\nThe seminar meets only once a week. This means that attendance is particularly important. If you do need to miss class, you must obtain permission from the instructor in advance.\n\nFinal grades will be determined as follows:\n\nACTIVITIES\n\nPERCENTAGES\n\nClass Participation\n\nReading Response Papers\n\nFinal Paper",
  "files": [
    {
      "category": "Resource",
      "title": "anthony_final.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/e7be11fdfff1e2b3287276d748a34bef_anthony_final.pdf",
      "content": "Facial Recognition: Limited Application in Safety and Security\nAnthony Ronald Grue\nSTS.035\nIntroduction:\nThe field of biometrics is concerned with the statistical study of biological\nproperties. Computers ever since their conception are used as a tool for the statistical\nanalysis due to their processing speed and storage capacity. In addition through the field\nof artificial intelligence computers made a name for themselves as symbolic processors.\nBiometrics is concerned with large quantities of data which need to be handled and\nanalyzed statistically but have symbolic and not numeric representations making it a\nprime candidate for computer application.\nFacial recognition with its first research in computing occurring in the mid\nseventies belongs to the field of biometrics. The human face also presents an interesting\nproblem for a computer in its vagueness and complexity. There is the general structure,\nthe uniqueness of the details of the features, the shading of the skin, facial hair, and then\nadded accessories such as sunglasses which propose widely varying situations which are\nnot typically seen in other image processing and recognition applications.\nFacial recognition has been around for a considerable amount of time in the form\nof a photo id which is fairly trusted in our society. Until now the processor deciding\nwhether a person is the same as one in a photo has always been a human brain and never\na computer. Computers introduced into this type of identification however will not\nsimply server to replace humans but have broadened the impact of the field. No longer is\nit only feasible to compare a person to the card they are holding in front of them but with\nfacial recognition on a computer you can compare a person to a database of images which\n\nyou store, enabling you to identify a person you have never meet before or for you to\nlook for 1000 people at once and find at least some of them.\nThis however has sparked an enormous controversy with discussions pertaining to\nthe reliability of facial recognition systems and whether or not they constrict freedom\nsince facial recognition, unlike many other biometric identification techniques, can be\nentirely passive. Despite promises of stronger security and a safer country in the age of\nterrorism the recent lab to real world transition of facial recognition has meet its critics.\nI argue that facial recognition technology has matured allowing accurate\nidentification of individuals wishing to be identified but that facial recognition is\nprimarily being used in an attempt to solve safety and security problems which it can not\nhope to tackle and thus is bound to be ostracized by society for its great potential to\ninvade an individual's privacy.\nBackground:\nSince the early 1950's when digital computers were born and the world gained\nsignificant processing power, computer scientists have endeavored in bringing thought\nand the senses to the computer. Vision is a core element in the human experience and if\ncomputers gained the gift of sight they would be one large step closer to fully integrating\ninto human society and could be capable of providing a vast majority of useful functions\nsuch as recognizing and classifying environments the computer interacts with or\nidentifying people by their pictures in a large database.\nThe very first step towards machine vision was at the National Bureau of\nStandards on their SEAC computer. With recent developments in AI and the importance\nof symbolic processing coming to light Russell Kirsch made the move as the first to do\n\nimage processing by designing a drum scanner which read in a small picture of his baby\nson and the executed algorithms to process the image cleaning it up for the computer and\nthus starting the field of image processing (pg. 9, Kirsch).\nThe next logical step towards making computers user friendly, intelligent, and\nhumanlike would be their ability to recognize humans to eventually enable interaction.\nFacial recognition was picked up in the early seventies by M.D. Kelley and then Takeo\nKanade as an interesting problem in machine vision. At first the focus in identifying faces\nwas on patterns and particular facial features (pg. 470, Zhao). Over time emphasis has\ngrown to building a set of faces which can be combined together to form any face, thus\npaying attention to the mathematical variations in peoples faces instead of their features.\nWith humans an inherent problem exists in that we can only know so many\npeople because we can only sustain a social network of limited depth. Computers\nhowever are capped only in their storage space. This gives computers the potential to\nknow everyone and interact with them or identify them. The technical challenge for\ncomputers is not remembering many faces but trying to differentiate people in a large\ndatabase because the more individuals you have the less differentiated they will be.\nWhile the technical challenge is slowly being overcome the even more difficult\nproblem of social acceptance is being encountered. Plagued with the fears expressed in\nGeorge Orwell's 1984 most members of society are very concerns about the use of a\ncomputer system which is capable of recognizing them wherever they go. If the system\nsucceeds in its task it could then inform the government of anyone's whereabouts at any\ntime and inventing big brother quite successfully. September 11th and the rise of terrorism\nawareness has given the government an window of opportunity in which Americans are\n\nwilling to give up some privacy, freedom, and convenience in order to be better protected\nand some have used this window to try facial recognition in public places.\nTechnical Material Overview:\nTakeo Kanade in his 1977 thesis Computer recognition of human faces presents\nthe first work in facial recognition. Facial recognition like many other fields, such as\nspeech recognition, was a process that was not understood when it was first attempted on\na computer. Thus Kanade spent effort postulating how a human looks at another\nindividuals face and is immediately able to recognize that it is indeed a human face and\nidentify all the features and where they are located on the face. Most importantly if they\nhave seen the person before they recognize the face and can correctly associate it with\nthat person's identity. Due to interest from the image recognition community and\ninterests in application by the government and commercial communities' facial\nrecognition provided itself as a reasonable problem to tackle on a computer so he made\nthe first attempt (pg. 1, Kanade).\nThe image recognition and artificial intelligence community saw facial\nrecognition as a problem of symbolic recognition paralleling problems of text recognition\nwhich at the time was a recent success in the community. Two glaring differences\nhowever, stood out. The first was the range of quality that different pictures can have.\nThe differences in two pictures of the same person due to poor camera, improper lighting,\nand other photographic aspects must first be eliminated in order to further analyze the\nimage. The second difference from standard symbolic recognition is that unlike text there\nis no predefined pattern of exclusive objects at fairly fixed distances. To cope with these\n\nissues any system that was to be designed had to be extremely flexible and determine on\nthe fly which parts of a picture are relevant to facial recognition and then further analyze\nthose parts.\nWhile Kanade's system was surprisingly successful at classifying pictures it still\nhad a fair share of problems which included failing even classifying of all faces which\nhad a beard and 63 of 79 test cases where the face had any turn or tilt. Out of these 800\nfaces used however, 40 where chosen for recognition tests and where correctly identified\n45-75% correct identification. One interesting point Kanade made was by having a\nhuman perform the algorithm by hand which provided a 75% success rate. While it took\nlonger the human actually turned out more accurate at the algorithm. This demonstrated\nthat computers could still make significant increases in reliability as the field matured.\nSince Kanade's work much progress has been made the biggest technically is in\nthe shift to the eigenfaces method What started as a interesting way to model surfaces\nwhich fluids would flow over this DARPA funded research evolved into a way to store\nfacial images using a small set of core data (pg. 3, Wisniewski). This method creates a\nlibrary of eigenfaces, a set of images ranging in quantities of 8 to 100 in which all stored\nfaces are a linear combination of. This method heavily relies on preprocessing making the\nface the right angle with the right lighting before encoding as a linear combination of the\neigenfaces in the system. The primary advantage to this system is it allows very rapid\nsearching for a match because once you have encoded a face in eigenface you can look to\nsee if there is another one in your database that is very similar.\nIntroduction to Society:\n\nResearch having begun 25 years ago facial recognition products are starting to\nemerge into real life application and have brought the US population to their attention\nparticularly since the rising threat of terrorism. In 2001 the city of Tampa, Florida\nmonitored every attendant of the Super Bowl using FaceIt the most prominent facial\nrecognition application on the market, created by Visionics Corporation. No suspects\nwere identified however despite the attendance of 71,000 people (Woodward). In\naddition Tampa, a few other cities, and some airports including Boston's Logan have\ninstalled face recognition software which to date has been ineffective at identifying any\ncriminal suspects (Bray).\nSome police agencies however, have been using more benevolent forms of facial\nrecognition. When presented with an image of a suspect they can enter the image into a\ncomputer that then presents them with a list of possible matches of people who already\nhave a criminal record. None of which are guaranteed to be the suspect but it gives law\nenforcement a starting point and allows them to take more information into consideration\nthough further investigation than just the persons facial identity as determined by the\ncomputer.\nAnalysis of the Success and Need of Facial Recognition:\nFirst I believe computers are capable of facial recognition and in a way that\nparallels the way humans perform the task. Kanade's technique takes localized features\non the face and deeply analyzes them for shapes, designs and certain measurement values\nand then compares those against others in a database. The eigenface technique using\ndifferent maps which contain all the features of human faces a key is build containing the\nlinear combination of the maps needed to reproduce the face using this key for easy\n\ncomparison and look up. These strategies are each a piece of how a human being\nrecognizes a face. We use a \"holistic\" approach in which we consider both the general\nstructure and differences but also record in our mind precise information about the other\npersons features (pg. 411, Zhao). To demonstrate the capabilities of facial recognition\nsystems a standard database and method for testing these systems, FERET was developed\nto ensure levels of reliability. FERET is a database and testing standard that includes a\nlibrary of images and procedures for the tests (pg. 61, Phillips). The conception of\nFERET demonstrates that people expect accountability from facial recognition software.\nThe most important issue in facial recognition which the engineers have some\ncontrol over is whether or not computers can be trusted to the task. The first issue to be\nconsidered for any system when considering trustworthiness is what the system is going\nto be used for and whether or not it satisfies the requirements of the situation. As in any\nsystem the more accurate facial recognition is the more trusted it will be but the way it is\nused is even more important. Facial recognition can be used in two manners one is to\nidentify a person by using a database of previously acquired pictures the other is to verify\na person is who they claim they are (pg. 56, Phillips). Facial recognition allows for\nthresholds of detection which adjust how close a face must be to one in the database to\nmake a positive match. For identification purposes the system should have a very low\ntolerance thus preventing the likelihood of false identifications of the wrong individual.\nHowever in cases where facial recognition is used to confirm you are who you claim you\nare tolerance can vary more greatly. If you wish not to present an inconvenience you\nwould set a fairly loose threshold but if you didn't want any false verification you would\nset it high in realization that some legitimate matches would be lost (pg. 57, Phillips). As\n\na result of the flexibility of the sensitivity you can build a fairly trustworthy system if the\napplication is considered.\nHumans however, tend to set their standards for computer reliability far greater\nthan standards for themselves or other human beings. When a human makes a mistake we\nare sympathetic and understanding because we have shared the experience When a\ncomputer makes a mistake though we tend to believe that the fault is inherit in the system\nand will repeat itself, thus believing any fault no matter the size indicates a fundamental\nflaw in the system. Statistically though facial recognition technology does a surprising\njob at accurately identifying individuals and not making very many false positives. In\nface recognition tests for verification on FERET between 1994 and 1996 the false\nverification rates over different days was two percent and over 1.5 years was still 2\npercent(pg. 61, Phillips). A false negative was 11 percent on different days and 43\npercent over 1.5 years. Legally one of the most accepted forms of evidence in a police\nstation or a court is an eyewitness. People trust that they are capable of recognizing others\nhowever in a study of lineup procedures it was recorded that in lineups of six to eight\npeople that are absent of the perpetrator a witness will misidentify an individual 43% of\nthe time due to the biases they have and the belief that one of the six or eight must be the\none they are looking for. In addition humans judge the members of a line up against each\nother and build up evidence in their mind that one of the line members must be the\nperpetrator because they look the same in comparison to the rest of the line (pg. 2,\nSteblay). Computers do not have the human biases built in to them and thus turn out to be\nmore effective at protecting the innocent by not falsely identifying an individual as a\nsuspect. Despite this incredible demonstration computers remain with a lack of human\n\ntrust. To gain the trust of the population system designers will have to further invest in\ntests like FERET that convinces people of the technologies power.\nIf we don't trust computers why spend time, money, and effort in the\ndevelopment and deployment of facial recognition technology. The reason is a desire by\nthe general population for more regulated and secure environments. The government is\ninterested in the technology to fight general crime and in the post September 11th world\nbecause the public is asking the government why they failed in preventing the attack. The\ngovernment as a result is turning to look for a technological fix for a serious problem one\nthat can not be fully rectified through monitoring the entire American population with\nfacial recognition systems. DARPA none-the-less started its Human ID at a Distance\nprogram funding which provided a grant to Visionics among other companies to continue\ntheir research (Woodward). DARPA is looking for technology that can identify people in\ncrowds and at long ranges which they believe would permit them to better identify\nsuspects in the field off United States soil and in the US. The essence of a need to better\ntrack people from an intelligence point of view is revealed. If it was possible to know\nwhere everyone was at anytime then if ever an individual was a danger to society they\nwould be able to be stopped. In this seemingly perfect world however there would be no\nfreedom and thus the idea of safety becomes a far less valuable goal.\nFacial recognition allows us to evaluate its success in two lights due to its having\nexisted in the lab and it having been introduced into people's lives. The first is from a\ntechnical standpoint which as demonstrated by the FERET tests it is becoming\nincreasingly successful in. The second however is whether or not it achieves the goal of\nproviding better security and saftey in environments where it is deployed. Boston's\n\nLogan Airport has adopted the technology in light of the September 11th attacks and is\nspending a considerable amount of time testing the system and trying employs in its use\n(Bray). However at the time of the September 11th attacks, only 2 of the 19 terrorists were\neven know to United States and for only one did a picture exist (ACLU). The facial\nrecognition system would not have come through had it been implemented then, not\nbecause the technology was lacking, but because the human factor of identifying which\npeople in the population are terrorists and not ordinary residents.\nAdditionally, the facial recognition software is easily fooled by those looking into\nthe camera at different angles and those with sunglass or a beard. As a result facial\nrecognition is only reliable when the subject is wishing to be identified. If they are trying\nto hide on the other hand there are fairly cheap solutions to an expensive to implement\nsolution just grow facial hair or wear sunglasses and you have rendered all current\ntechniques of facial recognition useless. Returning to understanding the purpose of your\nsystem, for Logan to achieve its goal of eliminating terrorists on planes with facial\nrecognition technology they would have to have a list of all approved passengers and a\nlow tolerance in their system. This would create such a large inconvenience to the flying\npublic however that it is a useless solution.\nConclusion:\nFacial recognition has meet considerable success in achieving the ability to verify\nidentities in certain environments using both facial features and eigenfaces but that is not\nenough to make the technology a success. Unfortunately it attempts to solve the problems\nof crime and poor security by using a identification system that everyone is already\ninducted into. Unfortunately this system does not bring about an increase in security since\n\nit is so easily stepped around. Facial recognition technology has its uses but can only\nexpand so much. Used by police departments facial recognition can provide investigators\na way to make a hunt for perpetrators more efficient, but not entirely replace the hunt.\nLike machine translation for the government, facial recognition too is best used when it\nassists people by narrowing down the field of data which they are exposed to instead of\ntrying to evaluate it all my itself. In addition it leaves human beings in the loop and is\nonly used when necessary.\nCapturing images of everyone in their day to day tasks merely strips them of all\nprivacy they have and indeed realizes the big brother society that the public is rightly\nafraid of. Safety and national security are important goals but not at the cost of our\nfreedoms and using facial recognition this will do little but scar it. It is clear that facial\nrecognition technology has great potential in the verification of identities. It's use\nhowever must be closely monitored and can not be applied to fix problems when external\nfactors prevent it from any possible success.\n\nWorks Citied:\nPrimary Sources:\nKirsch, Russell. SEAC and the Start of Image Processing at the National Bureau of\nStandards. IEEE Annals of the History of Computing, Vol. 20, No. 2, 1998\nKanade, Takeo. Computer recognition of human faces. 1977.\nWisniewski, Helena. Face Recognition and Intelligent Software Agents - An Integrated\nSsytem. Prepared for the U.S. Senate Committee on Commerce, Science, and\nTransportation.\nSecondary Sources:\nPhillips, P. Jonathon. Martin, Alvin. Wilson, C.l. Przybocki, Mark. An Introduction\nto Evaluating Biometric Systems. National Institute of Standards and Technology.\nComputer. IEEE. Vol. 33, No. 2, February 2000\nW. Zhao, R. Chellappa, P. J. Phillips, and A. Rosenfeld. 2003. \"Face recognition: A\nliterature survey.\" ACM Computing Surveys (CSUR). ACM Press New York, NY.\n\"Q&A On Face-Recognition.\" ACLU Privacy & Technology: Surveillance &\nWiretapping. September 2, 2003.\nBray, Hiawatha. Reliability of face scan technology in dispute. Boston Globe, August 5,\n2002.\nWoodward, John D. Super Bowl Surveillance: Facing Up to Biometrics. RAND\nDocuments. 2001.\nSources for External Information:\nNancy Steblay, Jennifer Dysart, Solomon Fulero, and R. C. L. Lindsay. Eyewitness\nAccuracy Rates in Sequential and Simultaneous Lineup Presentations: A Meta-Analytic\nComparison. Law and Human Behavior, Vol. 25, No. 5, October 2001."
    },
    {
      "category": "Resource",
      "title": "2dan.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/eac0013fb3c959593e7c48f6000fae57_2dan.pdf",
      "content": "Week 2 Reading Response\nDaniel Roy\nFebruary 11, 2004\nAccording to a study by the US Department of Commerce study, 1 in the year 2000, fifty\none percent of US homes owned a computer and fortyone percent of homes had Internet\naccess. These numbers leave no doubt that the personal computer is a recognizable feature\nof American society; it is also well accepted that computers are largely a tool for word\nprocessing, email, Internet access and similar tasks.\nTo what extent has the computer\nreached a state of \"closure\" as defined by Pinch and Bijker?2\nI believe that the computer has reached a state of 'temporary' closure; A majority of\nUS families agree on the \"purpose, meaning and physical form\" of the 'computer' (which\nhas come to mean the personal computer in American society).3\nThis consensus on the\ncomputer's physical form is remarkable given the dramatic transformations computers have\nundergone in their short history. Computers have reached closure despite these dramatic\ntransformations because of the short time frame during which computers have become pop\nular. This closure will be short lived, however, as computers shrink in size, grow in number,\n1http://www.ntia.doc.gov/ntiahome/fttn00/contests00.html\n2Edwards, 7\n3Edwards, 7\n\nand eventually disappear from sight. How does one define 'computer' when one's refrigerator,\ncar, jacket and cell phone are all computers? A single, coherent definition of a \"computer\"\nwill soon become impossible. While the idea of closure may be an interesting theme to apply\nto the development of new technologies, the nearly limitless applications of computers makes\nit difficult to gain anything from understanding the development of computers via the idea\nof reaching a \"closure.\"\nIn Mahoney's article, he relates the historical analogy that compares the development\nof the computer with that of the automobile. 4 That the computer will eventually leave its\ncurrent temporary state of \"closure\" points to a flaw in a comparison of the automobile to\nthe computer. While the physical realization and purpose of the automobile has remained\nvirtually unaltered in its entire history, the computer has already dispersed itself into every\naspect of modern life.\nThe effect of the computer may be more comparable to the effect of the printing press.\nBoth opened up a new level of access to \"knowledge.\" While the printing press democratized\naccess to information, the computer has performed a similar role with censorship: today\nit is the people not the State that decides what is and is not acceptable and accessible.\nAnother analogy preferable to the automobile is the train, which was the first great revolution\nin transportation. Trains immediately shrunk the physical space separating distant cities.\nLikewise, the Internet has shrunk the \"cultural space\" separating the four corners of the\nworld.\n4Mahoney, 14\n\nWired\nFor many years I have read Wired, a magazine devoted to the technical. However, I have\nnever approached Wired from the perspective of genres as discussed by Kling. What genre\nbest matches Wired and how has its genre and tone changed through the dotcom bust?\nLaunched in 1993, Wired prophesied an eminent technological utopia. However, Wired\nwas transformed by the dotcom bust; A magazine previously several hundred pages thick is\nnow usually half that (with twice the amount of advertising). Has the bust's effect reached\nbeyond simple page counts?\nI am convinced that I have witnessed a significant change of tone since the dotcom\nera. While it is clear that both the pre and postbust eras of Wired journalism employed\nutopian/futurist views of computing, Wired's unbridled enthusiasm has been attenuated by\na modicum of reality.\nAs a classic example of the utopian genre, a January 1994 article, entitled \"The Other\nRevolution in Health Care,\" describes a future world (2004) improved by technology: in one\nscene, a man collapses due to a heart attack, immediately triggering an automatic emergency\ncall and the forwarding of his medical records to the EMT unit enroute; Upon arriving they\nalready know his full name, wife's phone number, and his allergy to penicillin. In another\nfuture scenario, a young girl has a conversation about puberty and sex with her computer,\nhelping her get through troubled times.\nAccording to Kling, the utopian genre is incapable of addressing the reaction to new\n\ntechnology in a social context. 5 The existence of a technology is insufficient to guarantee its\nsuccessful integration into and improvement of a situation or society in general. In the first\ncase of a utopian idea of medical network, the fact that the such a scene would require a\nmassive collaboration between relatively stubborn and stagnant corporate and governmental\nentities is totally ignored. In the second example, the author completely ignores any issues\nthat parents may have letting a child be educated on issues of sex by a computer.\nThe Wired of 2004 still subscribes to a utopian view of technology. The best example of\nthis is the \"Found\" section which occupies the final page of the magazine with an \"image\nfrom the future:\" this month, valentine candies that also cure common psychological prob\nlems. However, Wired's enthusiasm and futurist leanings are on the tamer side: a recent\nWired (December 2003) insert titled \"Unwired\" expounded the future of wireless technology.\nHowever, the most exciting utopia they could muster was one in which all of one's wireless\ncharges would appear on a single bill.6 Of course, an extensive study is necessary to show\nany real trend in the genre of Wired's journalism.\n5Kling, 8\n6Wired December 2003, \"Unwired\""
    },
    {
      "category": "Resource",
      "title": "week2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/5c658d72e5812ac1ea75fb97091ea34f_week2.pdf",
      "content": "WEEK 2 ASSIGNMENT\nWrite a 1-2 page response to your readings. You may choose some questions from the list\nbelow, but you are encouraged to raise your own questions. Your paper must touch upon\nall the readings assigned for the upcoming session.\n1. Which factors shaped the origins of the first digital computers? Would it be fair to say\nthat computers were superior to the contemporary analog computing devices?\n2. Discuss the notion of \"closure\" as defined by Pinch and Bijker. Has the development\nof the computer reached \"closure\"?\n3. Discuss the relationship between (de)centralized technological and organizational\nstructures using the SAGE case or your own example. Can the same technological\nstructure be used in different organizational modes? Can the same organization combine\ndifferent technological structures?\n4. Discuss the validity of the \"impact\" model of the relations between computers and\nsociety using the Global Bank Brazil case or your own example.\n5. Do you agree with Edwards's argument that computers are not gender-neutral?\n6. Which fields of science and technology contributed to the development of the\ncomputer? How can we incorporate the individual histories of these fields into the history\nof computing? Can the computer be seen as the pinnacle of these individual histories?\n7. What are the strengths and the weaknesses of the historical analogy between the\ndevelopment of the computer and the automobile? Can you suggest another analogy for\nthe computer?\n8. What is your answer to Mahoney's question, \"Where is the Middletown of today, ...\ntransformed by the presence of the microcomputer?\"\n9. Do you agree that Vannevar Bush's account of the Memex was utopian?\n10. Discuss the difference between \"reality transcending\" and \"situation transcending,\"\nand the notion of \"web model\" according to Kling.\n11. Classify the books or articles that you have read about computing according to the\nfive genres of literature discussed by Kling. Which genre appeals to you most? Why?\n12. What questions pertinent to the history of computing have not been raised in the\nreadings?"
    },
    {
      "category": "Resource",
      "title": "3anthony.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/d68753dbd9ad4d470affc33751fcd8e4_3anthony.pdf",
      "content": "Anthony Grue\nSTS.035\nWeek 3 response\nWhen I looked up \"random\" in the American Heritage Dictionary it gave me two separate\ndefinitions(1). In general it means lacking pattern, however for mathematics or statistics, it is\ndefined as statistically evenly distributed. The debate between these two definitions is what lies\nat the core of the argument on whether or not through a software based function can be random\nand if not then is anything in the world random or are we deceiving ourselves. Even the human\nmind can be predictable, once given a few sentences to read I was asked afterward for a single\ndigit and a double digit number. Both we're predicted correctly because the wording had given\nme a patter of thought. Natural events may be random, however they often are hard to monitor.\nSo one random number based on time or voltage fluctuations used as a seed should be sufficient\nbecause it is not the pure randomness that simulations desire but more so test cases and inputs\nthat don't conform to a pattern relevant to the experiment, a pattern that would make the results\nunreasonable in nature and thus the \"pseudorandom\" numbers seem to satisfy our requirements\nto test a variety of conditions including those at the edges of the domain with an equal\nprobability and as S.K. Zaremba of the US Army realized, the goal in designing generating\nfunctions should be in reducing error and not ensuring randomness if we'd like to make the most\npossible progress.\nComputer simulations I feel are a bridge between the worlds of theory and experimenting.\nProgramming itself is closer to theory in that a theorist tries to develop a pattern in mathematical\nterms which he believe natural phenomenon adhere to. Programming is creating and writing a\npattern is machine languages which the programmer believes will model the natural\nphenomenon. More often than not though programmers are little more than translators,\ntranscribing mathematical and physical theory in a way that computers can understand and\ncompute quickly. Thus I agree with Galisons belief that programs are marginal in the role of\nphysics because the programmer is generally not making discoveries or the only individual who\ncan program this particular theory, instead the achievement and the uniqueness is usually and\nrightfully attributed to the physicist. The program is necessary because as as Kowarski argues,\ncomputers have permeated into every practice that analyzes data due to their unbarred speed and\ncapacity, and they will never be able to be done away with and in our specialized world it is\nunlikely that every physicist or experimenter will learn how to translate his theories and models\ninto a computer.\nWhile what programming is has influence over the lives of a select group of people, the question\nthat affects a wider audience is whether or not running a simulation programmed into a computer\nis equivalent to running a set of experiments. I will discuss the some primary differences\nbetween lab and field experimenting and computer simulations, then why I believe they are\nfundamentally different in nature, and finally why lab experiments must continue to live on. First\ncomputers take a model into them that has been created by humans and then encoded for\nmachines by humans, while field and lab work which is the behavior that our model is trying to\nmimic. Thus the first two disadvantages in computer simulations arise. First our model may be\nflawed and the flaw may be lack of account for special cases or edges of our domain, a failure to\nrecognize the true domain of all the inputs and conditions, or in the fundamental elements which\n\nmake up the model. Experimentation doesn't have any of these flaws in that you test in the\nnatural environment which your product is to be run. The second difference between computers\nsimulations and experiments, is that computer simulations allow you to test an enormous amount\nof conditions, many times at relatively low cost. In addition you can model conditions which you\nwould be unable to physically reproduce without extreme cost or danger such as low gravity or\nincredible heat. Third computers allow you to measure any property of any modeled object or\ngroup of objects. In experiments you can note see what a single atom is doing when surrounded\nby billions of other atoms. Experiments require instrumentation that can consume space and\nbecome cumbersome to being placed in a non-obstructive manner. As Heisenberg's Uncertainty\nprinciple states, if you measure something you always change it to some extent in observing it,\ncomputers avoid this because you are not actually observing an object but instead recording it's\npredicted state. The Monte Carlo project proved particularly incredible in the measurement and\nsafety aspects, each neutron that was being simulated could be fully observed and one didn't\nhave to be in the middle of a nuclear explosion to make these observations, a physical\nimpossibility. The advantage to traditional experimenting here however is if you know your\nequipment is working and to what degree it is accurate, the confidence of your results being\nrealistic are higher, because you are measuring actual physical effects as opposed to simply\npredicting them, and these results are more valuable in seeing how your object truly behaves.\nThe conclusion is that the theory, simulation, and experimentation complement each other and\nnot replace each other. Computers let you sample a far greater variety of conditions, thus\nallowing you to understand trends and possibly even improve your models based on their output.\nThese simulations though are founded on the theory and if that theory is faulty only lab and field\nexperimentation can guide you the right way. As a result I fell computers are indeed a step away\nfrom reality but give us a more complete picture of what may be happening. PhDs should very\nrarely awarded on computer simulations alone because if it can't be reproduced in strict theory or\nthe field then any work is of little use. If however the computer simulations can come up with\ninformation of how to proceed in the field, or accurately estimate something that is not\nunderstood they may be of merit. The most honorable use for computers should be in producing\na great multitude of test and predictions cheaply and quickly, that can be verified in the lab, and\nthen continuously refined.\n1. The American Heritage(r) Dictionary of the English Language, Fourth Edition\nCopyright (c) 2000 by Houghton Mifflin Company.\nGalison, Peter. \"Monte Carlo Simulations: Artificial Reality.\" In Image and Logic: A Material\nCulture of Microphysics (Chicago and London: University of Chicago Press, 1997), pp. 689-780.\nKowarski, L. \"The Impact of Computers on Nuclear Science.\" In Computing As a Language of\nPhysics, edited by International Center for Theoretical Physics (Vienna: International Atomic\nEnergy Agency, 1972), pp. 27-37."
    },
    {
      "category": "Resource",
      "title": "3steve.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/32c1105d33f13edf13beda0231855e19_3steve.pdf",
      "content": "Steven Stern\nSTS.035\nReading Response, Week 3\nIn the early days of computing, the definition of \"random\" became\ninterchangeable with the definition of \"pseudo-random\". Computer scientists of the time\nagreed that their functions were not random, since they knew an upper bound on when\nthe random numbers generated would begin repeating. In fact, this upper bound was\nrather small. If a pseudo-random function, which repeated every 1010 digits, were to be\nused in a cryptographic scheme today, the scheme could be easily broken on a personal\ncomputer. Perhaps a comparison to today's computers isn't reasonable, since it is\npossible that in the year 2050, today's cryptographic schemes will seem trivial.\nHowever, despite the fact that it served their purposes then, I think their definition of\nrandomness was very weak.\nI would accept a computer-generated sequence as random. Computers use many\nphysical events to generate random numbers. For example, some computers use the time\nbetween keystrokes, variations in white-noise detected by the computer's microphone, or\nthe speed that the hard drive spins. This can, of course, be improved. If the actual\nrandomness of the computer's randomly generated numbers is of extreme importance,\nsuch as when generating the private key for the VeriSign root certificate, more extreme\ninputs can be used. Pure randomness, from a physics point of view, can be achieved by\nsimply attaching a Geiger counter to a computer.\nWhile reading about the uncertainties people had in the Monte Carlo method, one\nparticular event came to mind. If you ask a person to determine whether a coin is fair, it\nseems very intuitive to flip the coin a thousand times and record the results. Nobody\nwould object to that method of calculating this result, despite the fact that it is possible\n(though terribly unlikely) that an unfair coin would appear fair in this test. However, if\nthe computer wishes to perform the equivalent of this test, people object. Instead, people\nbelieve the computer should study the density and exact shape of the coin to determine\nwhether it will flip fairly or not. I can't see any difference between this example, and the\nmodeling the computers were doing with nuclear reactions.\nThe main advantage of a computer simulation, as compared to a laboratory\nexperiment, is that a computer simulation is a controlled environment. A computer can\nmodel a nuclear chain reaction that, if it were to happen in reality, would level an entire\nPacific island, without causing any real damage at all. I do believe that a simulation is a\nstep away from reality, but by studying reality well enough, it is possible to make this\nstep extremely small. Perhaps this argument is getting a bit too metaphysical, but when a\nperson throws a ball, he can't tell if the motion of the ball is \"reality\" or an extremely\ngood simulation. Perhaps we are all in a simulation, and when we throw a ball, an\nextremely fast computer calculates the trajectory of the ball, taking into account the force\nof the throw, the spin on the ball, and the air resistance around the ball.\n\nI do believe that computer simulation should count as a science. In fact, there are\n2 distinct fields of computer simulation that should count as a science: using the\nsimulation, and developing better simulations. So long as the simulation is close enough\nto reality, I do not see any difference between work done in a simulation and work done\nin reality. I also believe that work done to make better simulations should be worthy of a\nPhD. If a mechanical engineer develops a fundamentally superior method for building\nskyscrapers, that significantly reduce the cost of building one, it is considered very\nsignificant. However, that engineer only developed a better way to do what can already\nbe done. Developing a near-perfect computer simulation."
    },
    {
      "category": "Resource",
      "title": "week3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/935d6e28b9ef2bbd037ba4f3da3d4f8b_week3.pdf",
      "content": "WEEK 3 ASSIGNMENT\nWrite a 1-2 page response to your readings. You may choose some questions from the list\nbelow, but you are encouraged to raise your own questions. Your paper must touch upon\nall the readings assigned for the upcoming session. Some sections in the readings are\nhighly technical; you can skip the technical details and focus on a larger argument. Please\nspell-check and proof-read your paper before submission.\n1. How was the notion of randomness redefined in the context of digital computing?\nWould you accept computer-generated sequences as random? Can you give other\nexamples of our intuitive notions being revised when faced with possibilities and\nrestrictions of computer implementation?\n2. Is programming closer to theorizing or experimenting?\n3. Do you agree with Galison that computer programmers in physics have a \"dual role as\nmarginal and necessary\" (p. 732)? Would this apply to other fields as well?\n4. What are the advantages and the disadvantages of computer simulation as compared to\nlaboratory experiment? Is computer simulation a step toward reality or a step away from\nit? Should computer simulation count as science? Should PhDs in science be awarded for\nwork based exclusively on computer simulation?\n5. Can computer models serve as a common language for specialists from different\nfields? Do you agree with the parallels Galison draws between the evolution of function\nof computer simulation and the three types of trading languages: foreigner talk, pidgin,\nand creole (p. 770)?\n6. What role did the reality/simulation distinction play in the ways computer simulation\nspecialists dealt with moral issues associated with working on nuclear weapons? Can we\nalways draw a sharp line between simulation and reality?"
    },
    {
      "category": "Resource",
      "title": "4jason.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/a4e8ef60117a73eca9a97b405399a4ea_4jason.pdf",
      "content": "Jason Ruchelsman\n\nSTS.0035\nFebruary 25, 2004\n\nWeek 4 Response Paper\n\nFrom Atmosphere to Computer Screen - Before any type of weather\nforecasting can be performed, models must be built on computers to analyze data. For\nthis to happen, raw data, or actual weather observations from weather stations around the\nworld and onboard satellites, must be gathered. This raw data includes temperatures,\natmospheric pressures, cloud gatherings, etc. All this \"raw\" data is collected at stations\nand transferred to computers. Once in a computer, this raw data must be transformed into\ncomputer data - information that computers can act on and utilize. Coded computer\nmodels have been created that reviewed previous raw data and act on (\"massage\") the\ncurrent raw data to remove abnormalities from the raw data. These models compare the\ncurrent raw data versus data from years and seasons passed to ensure fairly similar\nobservations have been taken by the weather stations and satellites. Once the data is\nfiltered through computer models and considered usable according to international\nstandards, the data is considered \"computer data\" (\"model-filtered data\") and can then be\npassed through a number of different computer models that use this \"clean\" data to either\npredict weather in specific areas or display the current climate in those areas.\nI think this model/data relationship is a very useful symbiotic one. In many places\nthroughout history, observations and collected raw data have been used to build models\nand theories. Examples include raw data being used to come up with the V=IR rule used\nin circuits in physics and even Newton's Third Law. These models come from observing\nraw data instead of originating in mathematical equations. However, with time, we gain\nmore and more raw data, analyze it, and can incorporate this new knowledge to improve\nour previous models. In weather forecasting and climate science, specifically, our earth\nand its atmosphere change with time (for instance global warming), and hence our current\nmodels cannot be used forever. However, as we update our models every so often with\nnewly observed raw data, we can improve our models and get \"cleaner\" data to use for\npredicting weather. So while we use computer models to clean up data for efficient use\nby separate prediction models, that raw data is also used to clean up and improve our\ndata-processing models. This symbiosis creates ever-improving computer models that\nmeteorologists can use far into the future.\nLack of Data, Lack of Problem - Forrester argued that even with a \"lack\" of\ndata, exceptional models could still be built and used. Forrester believed that we have so\nmuch data collected, but we do not know what to do with it. He maintained we should\nfigure out how to use the data, i.e. create a working model, instead of worrying about\ncollecting gratuitous data. Forrester also argued that these models could be used as policy\ntools even without data because they would be so comprehensive. If all possible\nrelationships and interactions were included in the model, then it could be used to make\naccurate predictions and simulations. I agree with Forrester. Though scientists are\ncontinually focused on collecting and ever-growing pile of data, if they do not have\ncorrect models that contain the correct relationships and dynamics between variables,\nthen they will not be able to utilize that data. Rather than wasting collecting enormous\n\namounts of data and using guess-and-check methods to create a model out of thin air,\nmuch time would be saved by coming up with a model first and then using it on smaller\namounts of collected data. Even if the model was not perfect, as long as it was the focus\nof concentration instead of the data, it could help, as Forrester held, \"reveal which data\nmight be most important\". This would save much time and effort. As an aerospace\nengineer trained to integrate systems and examine the dynamics of massive systems, I\nmust agree with Forrester. Understanding the relationships and dynamics in a system is of\nutmost importance when trying to design, build, and evaluate (collect data and analyze it)\naerospace systems tat function to the best of their ability."
    },
    {
      "category": "Resource",
      "title": "4kathy.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/a064678b611fac691c525b8711a8c988_4kathy.pdf",
      "content": "Katherine A Franco\nSTS.035\nProfessor Gerovitch\nFebruary 25, 2004\nWeek 4 Reading Response\nComputer models are designed by taking into consideration observed data and\ncomputer data. Then the computer is able to extrapolate from missing data points what\nthe temperature most likely is. This is essential because much of the earth's surface is\njust not populated enough to have exact observations about temperatures and most of the\nearth's surface is water. By evaluating new data and previous data, the computer is able\nto find a closer approximation for the temperature. This is a form of data massaging.\nThis is similar in the same way that polls are taken. By taking data from a few random\npoints, you are assuming you have enough knowledge to make a statement about the rest.\nForrester argues that computer models could replace good data for policies\nbecause they would be able to model \"the complex interactions among all the different\nelements in a system\" (Edwards, 17). I feel that it is a dangerous idea to let a computer\nmodel complex interaction. In doing so, you are ignoring the chaos factor, as well as a\nmajor portion of the human factor. For example, if computer modeling were used for the\nway different entities interact with each other, say in planning a city, you can make sure\nthat neighborhoods are grouped well enough, but you cannot very well tell if two\nneighbors just do not get along because of deep emotional issues, possibly causing an\nemotional rift to move throughout the neighborhood and eventually lead to its downfall.\nAs radical as this may sound, I feel taking the emotional human part, or the chaotic\nnatural part out of the problem, you are assuming the world can work in the same way as\na machine, when there are some parts that just cannot be modeled.\nOn the issues of the validity of \"validation\" and \"verification\" of climate models,\nI agree with Edwards that you cannot speak properly of validating a computer model.\nThere is no way to pinpoint the truth in each intricate detail of a model. If \"validation\" is\nas Edwards writes, \"definitive proof of truth\" (\"Global Climate Change,\" 11), there is no\nway to check every point especially at one moment in time and now that all points are\ntruthful. In the case of forecasting climates, this is especially true. There is no way to\nprove which model will be the correct one if there is no true climate to compare it to.\nEdwards definition of \"verification\" as a \"demonstration of internal consistency and an\nabsence of detectable flaws\" (\"Global Climate Change,\" 11), is a much better way to go\nabout checking a model. It is much more plausible to check that a computer model\nmakes sense from a human standpoint than to verify the truth of the model."
    },
    {
      "category": "Resource",
      "title": "week4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/169eebdd54d2063320de67d14d954aa9_week4.pdf",
      "content": "WEEK 4 ASSIGNMENT\nWrite a 1-2 page response to your readings. You may choose some questions from the list\nbelow, but you are encouraged to raise your own questions. Your paper must touch upon\nall the readings assigned for the upcoming session. Please spell-check and proof-read\nyour paper before submission.\n1. What is the relationship between raw observations, computer data, and computer\nmodels in weather forecasting and climate science? Can you give examples of \"data\nmassage,\" \"data-laden models,\" or \"model-filtered data\" from other fields?\n2. What reasons did Forrester have to argue that \"computer models could serve important\npolicy purposes even in the absence of good data\"? Do you agree with him? Give\nexamples.\n3. In what sense did computer models of weather, climate, and world dynamics shape our\nnotion of \"the world\"? What is \"global\" about global models? What are the benefits and\nthe risks of global models?\n4. Discuss various techniques for dealing with the \"computational bottleneck\" in general\ncirculation models (GCMs). How are similar problems resolved in other fields?\n5. Can we properly speak of \"validation\" or \"verification\" of computer models? Give\nexamples.\n6. Is the model/data relationship in computational sciences a vicious circle or a\nsymbiosis?\n7. Discuss the role of the model/data relationship in political debates over climate change.\nWould you side with the \"frontier\" or the \"high-proof\" scientists?"
    },
    {
      "category": "Resource",
      "title": "5josh1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/sts-035-the-history-of-computing-spring-2004/736daa9e6cf2b9a0970d357f863abb9e_5josh1.pdf",
      "content": "Joshua Tauber\n\nWeek 5 response\n\nMy area of research is in formal methods for verification of distributed\ncomputation. One of the chief goals of our research group (and my research\nprogram, in particular) is to increase the automation of reasoning about the\ncorrectness of distributed system designs and their implementations.\n\nOne of the chief tools we use is the Larch Prover (LP). LP is an automated\nproving assistant. In the Donald MacKenzie's taxonomy, LP is an interactive\nprover that produces non-human-like proofs. Producing a \"proof\" with LP\ngenerally consists of an iterative process very much like the one described\nBoyer. The human enters a conjecture which LP then attempts to prove. LP will\napply one or more of its available rules to generate (hopefully simpler)\nsubgoals to prove. Most likely LP will get stuck somewhere in the process and\nneed guidance to continue. For example, the user might have to suggest a value\nto instantiate into an existential quantifier in order to discharge a branch of\na case analysis. The result at the end of a successful interaction is a claim\nby LP that the desired conjecture has been proved.\n\nThe interesting point is to examine what remains from this process. The LP\nuser now has a \"script\" for proving the theorem. The script is the series of\ncommands that the user enters to get LP to agree that the conjecture is true.\nEntries in the script may include some obvious steps that any mathematician\nwill recognize (at least once they are decoded) like \"use induction on A\" or\n\"instantiate B as D+E\". On the other hand, the script may include commands\nasking LP to perform larger operations like \"use critical pairs\" (an operation\nrelated to the resolution). Most interesting however, is what is _not_ there.\nWhat is not there is the actual text of what would recognized as a formal\nproof. That is, the proof script consist _only_ of the hints (commands) to\ngive LP when it gets stuck.\n\nTo be fair, one could ask LP to print out most of the intermediate steps in\nexcruciating detail. In practice, however, no one ever does. Why? For three\nreasons.\n\nFirst, the details of the formal proofs are not actually very\ninteresting. The exact steps do not serve an explanatory function. This is\nexactly the same reason almost no full text formal proofs have been published.\nMathematicians care that the formal steps _can_ be done, but they do not care\nwhat they actually are.\n\nSecond, partly by design, LP tends not to jump over the \"big steps\" on its own.\nSo the interesting bits of the proof (e.g. its structure) do tend to end up in\nthe proof script. If you are lucky, the interesting bits are not swamped by\n\nextraneous minutia.\n\nThird, we trust LP to do the brute force plodding flawlessly. LP may not be\nvery \"smart\". It probably won't get to the end of a proof on its own.\nHowever, the steps it does take we trust to be sound.\n\nIn many ways, this third point distinguishes the whole research area of theorem\nprovers and automated theorem proving assistants from the sort of computer\nassisted proof done by Appel and Haken. In the proof of the four color\ntheorem, Appel and Haken used a specialized (and if my old adviser, David\nGries, is to be believed, poorly structured) computer program to verify certain\ncases of the proof. The very fact that this program was written as part of the\nproof makes verifying the program part of verifying the proof.\n\nIn contrast, theorem provers are used, examined, extended, and debugged\nrepeatedly over a period of years. The very fact that a community of users\nexists for a particular tool lends assurance that the tool performs its\nassigned tasks as requested. In some sense, the correctness of the theorem\nprover itself is a conjecture that is separable from the theorems it is used to\ncheck. Does this body of evidence for the correctness of a theorem prover\nactually constitute a proof, in the mathematical sense? Perhaps not. But by\nthe same token, neither does peer review and publication of a purported \"proof\"\nconstitute definitive proof that the publication is, in fact, correct.\n\nIn some ways LP proof scripts are easier to check than large mathematical\ntreatise. I suspect, for example, that it would be easier me to write my\nown theorem proving assistant to recheck an LP script than for me to verify\nthe steps in Andrew Wiles proof of the Taniyama-Shimura conjecture.\n\nDo LP proofs scripts serve explanatory functions? They may. Over time our\nresearch group has developed a body of proof technology in a mathematical\nsense. As a result, the proofs about distributed system that our group\nproduces follows a very stylized form. (This stylized form is what has led to\nthe push for automation of the proof techniques.) As a result, the part of the\nproof then ends up in the LP proof script tends to be the part that makes this\nparticular proof different from previous ones. Thus, to the educated eye, the\nproof script actually highlights the interesting parts of the proof.\n\nI would argue, however, that not all proofs need be explanatory. Some are in\nfact, practical ends in themselves. That is, proving a system correct may only\nbe as interesting in so far as one cares that the system is correct and it may\nhave no further implications for building further mathematical structures.\nIn these cases, proof scripts become very useful. In particular, when a system\ndesign changes it is often very easy to reverify the system using LP when\nreworking even an informal proof by hand may be extremely cumbersome."
    }
  ]
}