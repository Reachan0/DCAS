{
  "course_name": "Modeling Environmental Complexity",
  "course_description": "This course provides an introduction to the study of environmental phenomena that exhibit both organized structure and wide variability—i.e., complexity. Through focused study of a variety of physical, biological, and chemical problems in conjunction with theoretical models, we learn a series of lessons with wide applicability to understanding the structure and organization of the natural world. Students also learn how to construct minimal mathematical, physical, and computational models that provide informative answers to precise questions.\nThis course is appropriate for advanced undergraduates. Beginning graduate students are encouraged to register for 12.586 (graduate version of 12.086). Students taking the graduate version complete different assignments.",
  "topics": [
    "Engineering",
    "Systems Engineering",
    "Computational Modeling and Simulation",
    "Science",
    "Earth Science",
    "Environmental Science",
    "Engineering",
    "Systems Engineering",
    "Computational Modeling and Simulation",
    "Science",
    "Earth Science",
    "Environmental Science"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nPrerequisites\n\nStudents should have completed\n18.03SC Differential Equations\nor its equivalent and have some familiarity with partial differential equations.\n\nDescription\n\nThis course provides an introduction to the study of environmental phenomena that exhibit both organized structure and wide variability--i.e., complexity. Emphasis is on the development of quantitative theoretical models, with special attention given to macroscopic continuum or statistical descriptions of microscopic dynamics. Concepts and problems include the microdynamics and macrodynamics of random walks and fluid flow; extreme deviations and anomalous diffusion; geological and ecological networks; percolation theory; dynamical origin of fractals and scale invariance; the origin and complex kinetics of biogeochemical cycles.\n\nObjectives\n\nThrough focused study of a variety of physical, biological, and chemical problems in conjunction with theoretical models, students learn a series of lessons with wide applicability to understanding the structure and organization of the natural world. Such lessons include: How complexity can derive from simple dynamics; why fractals are ubiquitous in the natural world; and generic consequences of complex biogeochemical kinetics. Students will also acquire specific skills, including: The statistical analysis of data with wide variability; how to use computer simulations to reveal fundamental phenomena; and how to construct a minimal model of a complex system that provides informative answers to precise questions. A unifying theme is the relation of macroscopic complexity to microscopic dynamics.\n\nTopics\n\nIntroduction.\n\nWhat is environmental complexity?\n\nWhy study it?\n\nComplexity can emerge from simple interactions.\n\nObjectives; course overview.\n\nFrom microdynamics to macrodynamics I: Random walks.\n\nFrom random walks to diffusion.\n\nThe central limit theorem, Gaussian fluctuations, and the concept of universality.\n\nLesson: Temporal and spatial averaging of random movements yields diffusion; Gaussian fluctuations are ubiquitous.\n\nFrom microdynamics to macrodynamics II: The lattice gas.\n\nThe microdynamical square dance: Cellular automata.\n\nThe macrodynamical fluid: Navier-stokes equations.\n\nConservation laws, symmetry, and the separation of scales.\n\nLesson: Complex macrodynamics--e.g., turbulence--can arise from simple microdynamics; identification of appropriate symmetries and conservation laws can suffice for correctness.\n\nThe geometry of aggregating networks, especially rivers.\n\nThe laws of Horton and Hack: Scale invariance, fractals, and allometric scaling.\n\nScheidegger's model of river networks.\n\nUniversality classes.\n\nLesson: The aggregation of random walks yields network geometries quantitatively consistent with real river networks.\n\nSelf-organized criticality.\n\nPhysical cartoons: Sandpiles, avalanches, and earthquakes.\n\nRelation to Scheidegger's rivers.\n\nEquilibrium critical phenomena and non-equilibrium steady states.\n\nLesson: Scale-invariant fluctuations can arise generically, without \"tuning\" to a critical point.\n\nLarge deviations and anomalous diffusion.\n\nBeyond the central limit theorem: Long-tailed distributions and scale invariance.\n\nLevy flights; continuous time random walk.\n\nDiffusion in disordered media; first passage times.\n\nPossible relations to the movement of animals, people, and groundwater.\n\nLesson: Long tails beget long tails, but transport through disordered media provides them for free.\n\nPercolation theory.\n\nExamples: Transport in porous media, forest fires, and epidemics.\n\nOne-dimensional representation.\n\nPercolation on the Bethe lattice.\n\nScaling laws in d-dimensions.\n\nFractals, scaling, and universality at the percolation threshold.\n\nFinite-size scaling and renormalization.\n\nLesson: Critical points generate scale-invariant phenomena.\n\nThe geometry of random networks, including food webs.\n\nConnectivity, clusters, and the Erdos-renyi random network.\n\nPreferential attachment and the Barabasi-albert scale-free network.\n\nFood webs.\n\nLesson: Mechanisms of connectivity can strongly influence network geometry.\n\nGlobal metabolism: The origin and structure of biogeochemical cycles.\n\nThe biological and geological carbon cycles.\n\nEnergy sources and sinks.\n\nCycles and irreversible thermodynamics.\n\nLesson: Cycles are expected in open systems held out of equilibrium.\n\nDisordered kinetics.\n1. Averaging over first-order kinetics.\n2. Aging and the 1 / t decay of apparent rate constants.\n3. Random rate and random channel models.\n4. The lognormal distribution and its ubiquity in natural systems.\n5. Lesson: Complex kinetics can derive from aggregated first-order kinetics.\n\nRequirements\n\nThere are 3 project-oriented problem sets. A final, independent project on a topic of the student's choice is due at the end of the term, including a written report and an oral presentation. There is no exam.\n\nGrading\n\nACTIVITIES\n\nPERCENTAGES\n\nAssignments\n\n40%\n\nFinal Project\n\n40%\n\nClass Participation\n\n20%",
  "files": [
    {
      "category": "Assignment",
      "title": "Modeling Environmental Complexity, assignment 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/91b5a61399da7ef0d0767599484d427c_MIT12_086F14_PS1.pdf",
      "content": "(b) Many random walks in nature are biased. One of the famous examples is a bacterium\nmoving up a chemical gradient. A bacterium measures the local concentration of the\nchemical, takes a step in a random direction, and measures the change in the chemical\nconcentration. Depending on the change in concentration, the bacterium adjusts the\nstep size.\nThus, the bacterium moves up (or down if it is toxic) the gradient with\nprobability q = 1 + ε. Since this is a random process there is some probability that the\nbacterium will move up the gradient, and then back down to where it started. If we trap\nFigure 1: Two lorises\n12.086/12.586 Problem Set 1\nDue: October 2\nIn this first problem set, we introduce a couple of neat ideas about random walks that might come\nup in models (e.g. your final projects). It's possible to do almost everything here with paper,\npencil, and a couple cups of coffee. In fact, a couple of these only require you to give a reasonable,\nintuitive argument. So feel free to use any method you like. Problem 4 will require you to run a\n(r)\nscript I've written for you in MATLAB.\n-Robert\n1. Return Probability\nLoris are small primates which live in South East Asia, Sri Lanka, and India (Figure 1). One\nparticular group of them feed on nectar from certain flowers that grow in the canopy. The\nproblem is that these flowers are distributed far apart and once a loris feeds on a flower it\ntakes a while for the flower to produce more nectar. Thus an individual often wastes a lot of\nenergy to visit an empty flower.\n(a) We are interested in the amount of stress an individual Loris puts on the total number of\nflowers. One could conceive of similar problems facing organisms that live in a number of\ndifferent dimensions (e.g. a nematode grazing on a flat surface), so generalize the problem\nto d dimensions.\nMake the simplifying assumption grazers scour the area randomly\n(unbiased random walk).\ni. How does the volume V of likely positions visited by the grazer scale in time?\nii. How does the density ρ of grazed sites scale in time? Discuss the result in d =1,2,\nand 3 in the limit that time goes to infinity. (Hint: How does the mean-square\ndistance vary as a function of time?)\nCourtesy of PDClipart.org.\n\na bacterium in a gradient, what is the probability that it will never return to where it\nstarted? Assume that the gradient can be modeled as a one-dimensional lattice (Hint:\nLet p be the probability that the bacterium does return. Suppose that the bacterium\ntakes a step up the gradient to x = 1. It will then either return to x = 0 or go a random\nwalk which might eventually take it back to 1. The probability that it returns to x = 1\nis the same as returning to x = 0. Use this to write p in terms of ε.)\n(c) Optional: Can you think of an example like the first which takes place on a fractal?\nHow could the Loris interact as to avoid visiting empty flowers? (Hint: in real life they\ndo)\n2. First Passage in One Dimension\nIn the last problem we focused on \"will a random walk ever hit the same place twice?\" This\ntime, the question is \"how long until a random walker returns to a point?\" In the lectures we\nsaw that this question is related to the distribution of river basin sizes; however the problem\nhas many other applications. In one-dimension, the size of a population can be thought to\ntake a random walk (do births outnumber deaths at a given point). The first passage to zero\ncorresponds to the time when the population goes extinct. Brain cells behave similarly. A\nneuron is constantly being bombarded with chemicals that make it either easier or harder\nfor it to carry a charge.\nWhen the charge reaches a certain threshold, the neuron fires.\nThis problem has been considered by Gerstein and Mandelbrot (Random walk models for\nthe spike activity of a single neuron Biophysical Society 1964) among others. There are also\nanalogues in higher dimensions (e.g. when will a Loris return to a flower). To make things\nmathematically simpler we will only consider one-dimensional systems on a lattice. We will\nfind the probability a random walker will return after a time T.\n(a) Will constraining ourselves to one-dimension influence the final result?\n(b) Will constraining ourselves to a lattice influence the final result?\n(c)\nUse this code (or write your own or do the analysis) to generate an ensemble of first return\ntimes (about 10000 test cases works well). Use this data to estimate the probability of a\nrandom walk having a particular return time F(T). In general, F ∼T -ν/2. Estimate ν\nfor the one dimensional case. Where do you suppose the 2 in the exponent come from?\n(d) What is the expected time ⟨T⟩until the walker returns to zero? What does this mean?\n3. Sediment Accumulation\nThis problem is concerned with sediment accumulation over geological time scales, i.e., the\nchange in the thickness of a sediment layer as a function of time. Two of the main processes\nthat affect the sediment thickness are deposition and erosion, both of which are complex\ngeomorphic processes whose rates fluctuate in time. Figure 2 illustrates the sediment thickness\nas a function of time. It has been widely noted that the thickness of a sediment section does\nnot scale linearly with the time interval it represents (Figure 3). These data suggest that the\nthickness δ(t) scales like tα, with α ≃0.5. Equivalently, the sedimentation rate R(t) = δ(t)/t\nscales like tβ, with β = α -1 ≃-0.5. That is, the sedimentation rate appear to be slowing\nThe code, first_return.m, simulates a random walk and finds the time of first return.\n1If you are using MATLAB once you have an ensemble of times and you want a histogram, use [freq,x]=hist(X), and\nget ν by fitting log(freq) ∝-ν/2 log(T). (Hint: bin the first return time logarithmically, and remember to multiply\nby the Jacobian to get the original PDF if you do)\n\ndown with the length of the time interval. In this problem, we will try to construct a simple\nmodel that captures this apparent slowdown.\n(a) Let h(n) be the height of the sediment after time n. It is important to realize that the\nordinate of Figure 3 does not correspond to height h(n), but rather to height difference\nδ(t) after time t:\nδ(t) = h(n + t) -h(n).\nWe model the sedimentation process as a discrete, 1-D random-walk. At each step, the\nheight of the sediment changes by a random amount δ(1) = h(n + 1) -h(n), with δ > 0\ncorresponding to net deposition, and δ < 0 to net erosion. Assume that all steps are\nindependent and are drawn from a common probability density function p(s) that has\nmean μ and variance σ2.\ni. What is the probability density function p[δ(t)] for large t?\nii. What is the average rate of sediment accumulation at time t, for large t?\niii. Are these results in agreement with the data shown in Figure 3?\n(b) The key point is that only preserved thickness is observed. That is, when δ(t) < 0 all\nthe material from the corresponding time period has been removed and no stratigraphic\nˆ\nrecord remains. Thus, we need to calculate the apparent thickness changes\n\nδ(t) (the\nˆ\nobservable thickness changes of preserved sediments). Express the pdf p δ(t) in terms\nof the pdf of the height difference, p(δ).\n(c) Show that, for large t, the apparent rate of sediment accumulation θ(t) is\n\nσ\nθ(t) = μ + √\n2πt\nh\ne-μ2t/2σ2/Φ(μ\n√\nt/σ)\ni\n,\nwhere Φ is the cumulative distribution function (cdf) of the standard normal distribution,\ni.e.\nΦ(x) = √\nd\nZ x\ne-y2/2 y.\nπ\n-inf\n(d) Under what condition is the rate given above consistent with the data shown in Figure\n3?\n4. Diffusion-limited Aggregations\nSo far in this problem set, we've considered a few interesting one-dimensional random walk\nproblems, but these systems tend to rely heavily on a lack of particle interaction. While\nthis can often be fruitful in modeling the chemotaxis pathways of 1-dimensional bacteria, or\nin determining the effect of primates on local fauna development, more complicated systems\nthrive on interaction. One such theory of interaction is known as diffusion-limited aggregation\n(DLA) - in this process, an initial \"sticky\" particle is placed in a system. Other particles are\nallowed to randomly walk until they hit this first particle, after which they stick to it and begin\nto form an aggregate. As you may have guessed this phenomenon is widely seen in nature.\nExamples of this include aggregates of dust in the atmosphere and organic aggregates in the\nocean (or 'marine snow').\nThe code, DLA.m, on the STUDY MATERIALS page\n(a)\nusesMATLAB to simulate diffusion-limited\nThe simulation places a sticky spot in the center of a 101 by 101 two-dimensional\nlattice, and lets random walkers in from the outside until they encounter this sticky\nboundary. Upon 'sticking' to this boundary, they become part of it, and the next walker\nis released. Run this script, and plot the aggregate.\naggregation.\n\n(b) Write a short code that makes a plot of the mass of the aggregate contained in a circle\nof radius r as a function of r. How does the mass scale with the radius?\n(c) Find the partial differential equation and boundary conditions that correspond to DLA\nin the continuum limit.\nFigure 2: Illustration of the sedimentation pro-\ncess. (a) sediment thickness as a function of time.\n(b) preserved sediment, observable at the last\ntime point of the process. Bottom bars indicate\nwhether a time interval left a sedimentary record\n(dotted), or all deposited material from time in-\nterval was eroded away (open). From P.M. Sadler,\nD.J. Strauss, J Geol Soc London 147, 471 (1990).\n(c) American Geophysical Union. All rights reserved. This content is\nexcluded from our Creative Commons license. For more information,\n(c) Geological Society of London. All rights reserved. This content is\nsee http://ocw.mit.edu/help/faq-fair-use/.\nexcluded from our Creative Commons license. For more information,\n.\nsee http://ocw.mit.edu/help/faq-fair-use/.\nFigure 3: Sedimentation accumulation data. Pre-\n.\nserved thickness of section as a function of time\nspan represented by section.\nFrom D.J. Jerol-\nmack, P.M. Sadler, J Geophys Res-Earth 112:F3,\nF03S13 (2007), doi:10.1029/2006JF000555.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Modeling Environmental Complexity, assignment 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/8f9af71d8fa8b337b1367601147a4b0c_MIT12_086F14_PS2.pdf",
      "content": "12.086/12.586 Problem Set 2\nScale-free phenomena\nDue: October 21\nOctober 7, 2014\n1. White Collar Crime One fantastically complex system is the accounting records of\na large company. In addition to the multitude of mechanisms that influence accounts,\npeople also lie. Is there any way one can identify \"normal\" accounts just by looking\nat them? One tool that is used to find evidence of \"certain irregularities in accounting\npractices\" is the probability distribution for the first digit of randomly chosen number.\nOne may guess that the first digit of a randomly chosen stock price would be as likely to\nbe 3 as to be 9; however empirically 1 occurs about 30% of the time while 9 occures only\nabout 5% of the time. There is an empirical p.d.f that describes this. To find cooked\nbooks, auditors compare the observed frequency of first digits from accounting records\nto the empirical p.d.f.. In fact, the first digit of numbers that describe many natural\nsystems (e.g. river drainage areas, city populations, addresses, physical constants) all\nhave what appears to be the same probability distribution. If one posits the existence\nof some universal probability distribution for the first digits of naturally occurring\nnumbers, it is possible to calculate the observed probability distribution. The essential\nobservation is that if there is a universal probability distribution function P(x) for the\nfirst digit, then the shape of the function cannot change by rescaling the data (i.e.\nassume the probability that Microsoft's stock is selling for something that starts with\na 1 does not depend on whether we are trading in dollars or yen). Thus, P(λx) =\nf(λ)P(x).\n(a) Use this constraint along with the requirement that P always be normalized to\nshow that f = λ-1 and P ∝x-1.\n(b) What is the probability that the first digit is a d? (Hint: find the probability that\na number picked between 1 and 10 will be between d and d + 1.)\n(c) Benford (1938) collected data from a variety of different collections of numbers\n(e.g. addresses, physical constants, death rates). Here is the observed pdf for\nthe first digit of data points from 741 various measures of the cost of things.\nP(d = 1) = 32.4, P(d = 2) = 18.8, P(d = 3) = 10.1, P(d = 4) = 10.1,\nP(d = 5) = 9.8, P(d = 6) = 5.5, P(d = 7) = 4.7, P(d = 8) = 5.5, P(d = 9) = 3.1.\nCompare this result to theory.\n(d) (Optional) Generalize this result to first digits in base b.\n\n2. Diffusion on an ice cube tray In class we considered the case of diffusion on a comb.\nWe found that an unbiased random walker could get stuck as it wandered back and\nforth on a tooth of the comb. We again consider a random walker that gets stuck in a\ntrap. The idea is that we place a marble into an ice cube tray and shake it randomly.\nIf we shake it gently the marble spends a very long time in each hole in the tray. The\nharder we shake the tray, the more frequent the marble gets kicked into a new hole.\nIf we shake the tray very hard the marble jumps on every shake. In this final case,\nthe marble does not even \"see\" the holes and simply jumps randomly across the tray,\nresulting in an unbiased random walk.\n(a) The example of a marble in an infinite ice cube tray is clearly contrived. Give\nan example of a real system you suspect might be similar. (Example: Thermal\nagitation effectively shakes a system. The free-energy of a system can often be\nvisualized with many local minima, in which a system can get stuck.)\n(b) Exponential distributions are common in nature (e.g. the time between the decay\nof radioactive atoms).\nThey also describe the probability that particle taken\nfrom a system will have some specific energy. For example, the average nitrogen\nmolecule on Earth is moving at about 500 m sec-1, however there are some moving\nat 50000 m sec-1. The probability that we can find such a molecule is proportional\nto e-E/kBT, where E is the kinetic energy of an N2 molecule moving at 50000 m\nsec-1, T is temperature and Kb is the Boltzmann constant. This observation gives\nrise to Arrhenius' Law which predicts the time τ a particle spends in a well of\ndepth V is proportional to eV/kBT. How does the diffusion constant depend on\nthe temperature of the particle (i.e. how hard we are shaking the tray)? How\ndoes the mean-square distance of the marble scale with time? Give a plot of the\nscaling exponent as a function of the temperature of the particle.\n(c) To make the system sub-diffusive we need to add randomness to topography as\nwell. Suppose that the probability of landing in a well of depth V is e-V/V0, where\nV0 is the average depth of a well. (If you like, you can interpret V0 as the thermal\nenergy of the topography just like kBT is the thermal energy of the particle).\nGiven that τ is a function of V , use this probability distribution to show that the\nprobability the marble is stuck in a well for a time τ is proportional to τ -(1+μ).\nWhat is μ?\n(d) How does the mean-square distance of the marble scale with time? Give a plot of\nthe scaling exponent as a function of the temperature of the particle (Hint: For\nwhat values of μ is ⟨τ⟩finite?).\n(e) (Optional) Can you think of a physical system in which the step sizes have a\npower law distribution as would be the case for a L evy walk?\n(f) Recall that ⟨X2⟩= ⟨l2⟩N. Combine the prediction of ⟨l2⟩from L evy walks with\nthis result to find the scaling of a ⟨X2⟩in time for a continious time random walk\nwith power law step sizes.\n3. Particle aggregation In this problem we study randomly aggregating particles.\nSpecifically, we are concerned with the particle mass distribution. Consider a sim-\n\nple model where particles occupy a finite 1-D lattice. At each time step, each particle\ncan randomly jump to the next lattice site with probability p > 0, or remain in its\ncurrent position. After all the particles have had a chance to jump, if two particles oc-\ncupy the same site, they are merged into one particle whose mass is the sum of masses\nof the combined particles. We say the system is in steady-state when the particle mass\ndistribution does not change with time.\n(a) What is the steady-state particle mass distribution if the system has:\ni. Absorbing boundaries (particles that jump from the last lattice site are re-\nmoved from the system)?\nii. Periodic boundaries? (particles can jump from the last lattice site to the first\nlattice position)?\nTo make the problem more interesting, we inject new particles into the system. At each\ntime step, after particles have jumped and merged, empty lattice sites are populated\nwith particles of unit mass. The addition of particles to the system changes the steady-\nstate particle mass distribution, such that it follows the power-law\np(m) ∝m-α,\n(1)\nwhere m is a mass.\n(b) Simulate such a system of aggregating particles with injection and periodic bound-\naries until it reaches steady-state (10,000 time steps and a lattice of size 1000\nshould work). Start your simulation from a lattice that is uniformly occupied\nwith particles of mass 1, and set the jump probability p = 0.5. Use your simula-\ntion to estimate the exponent of particle mass distribution α.\n(c) Provide a theoretical explanation for the scaling law (1) and your estimate of α.\n(Hint: consider any similarities with the Scheidegger model discussed in class.)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Modeling Environmental Complexity, assignment 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/f99a481cb7c6a97db32c36c97953c656_MIT12_086F14_PS3.pdf",
      "content": "12.086/12.586 Problem Set 3\nPercolation\nDue: November 13\nOctober 28, 2014\n1. Flood Plains In central Africa there are large, flat plains which are home to elephants,\nbaboons, wild dogs, and lions. In the dry season, the landscape has many small water\nholes. However, during the rainy season, the ponds flood and the landscape has a\nlarge interconnected water way (watch Planet Earth for footage of this). Thus, aquatic\nanimals are isolated from each other during the dry season, but can mix in the wet\nseason. A similar example has been found in the fossil record where a population of\nmollusks was seen to have periodic episodes of intense speciation when the climate\nwas dry (leading to many isolated communities living in disconnected ponds), while\nbeing more homogeneous during wet climates. An interesting question is: how much\nrain does it take to transform a landscape of many small, disconnected ponds into one\nwith at least one giant lake? We will answer this question using percolation theory.\nThe initial ponds form in minima of the topography. In order for two ponds to be\nconnected, water levels need to rise enough to swamp the land between them. If the\nwater levels rise, a certain proportion p of the ridges will flood. In this case, how large\nFigure 1: Bond Percolation for various values of p. The baboon is sitting at a site (red circle)\nbetween 4 ponds (blue circles). It could potentially move to any of the neighboring plots of\ndry ground (red 'X'), however the ridges that connect the red circle to the land to the North\nand West are flooded out (blue lines).\n\nmust p be for there is an infinitely large lake? This process is called bond percolation.\nBut rather than placing sites at random, we will place bonds between neighboring sites\nwith probability p (Figure 1).\n(a) To gain some intuition, begin by placing local minima of the topography (i.e.\nponds) on a square lattice. Think about a baboon that is sitting on the ground\nbetween 4 ponds. What is the probability pˆ that the baboon can walk to the dry\nland to the East without getting wet? In the lingo, the baboon walks on the dual\nof the square lattice.\n(b) Let pˆc be the critical value of pˆ such that there is an infinite tract of land where\nthe baboons can walk without getting wet. What is pˆc in terms of pc? (Hint:\nDraw a picture)\n(c) Given the last two results what is the value of pc?\n(d) Return to a more realistic case. Assume now that the topography is a a surface\nwhose height fluctuations from its mean have a Gaussian distribution with mean\nelevation 0 (Figure 2). If the water level rises to h, everything with elevation\nless than h will flood. How high must h be to ensure that there is an infinite\nlake? (Hint: A similar trick as before works since the topography is symmetric\nabove and below the mean. How would the picture change if the topography were\nturned upside down and everything higher than h flooded?)\nFigure 2: A surface whose height fluctuations from its mean have a Gaussian distribution.\n\n2. Chemical Avalanches It has been observed that when a liquid dissolves a solid at low\ntemperature, the reaction does not happen at a constant rate. Rather, the dissolution\nfront eats into the solid in fits and jumps called chemical avalanches. Here we will\nexplore a model of dissolution based on two assumptions.\n- Any small volume of the material on the surface of the solid will react at a rate\nRi ∝e-Ei/kBT. Here Ei is an activation energy and kBT is the thermal energy of\nthe material.\n- The activation energy is a random variable Ei = E0+pi∆E, where pi is uniformly\ndistributed between zero and one. For ease of notation, define Θ to be kBT/∆E.\nThus, Ri = τ -1\n0 e-pi/Θ. Here τ0 is a constant with units of time.\nThis phenomenon has been observed in the lab. For example, when CuCl2 is dissolved\nin water and placed on a strip of magnesium, the magnesium replaces the copper, ac-\ncording to the reaction Mg(s)+CuCl2(aq) →MgCl2(aq)+Cu(s). Furthermore, during\neach reaction a small, magnetic pulse is produced. By measuring the magnitude of\nthe magnetic field, it is possible to track how quickly the magnesium bar is dissolving.\nInterestingly, at low temperatures the bar does not dissolve at a constant rate. Figure\n3 shows the magnetic field as a function of time and a histogram of the size of magnetic\npulses (these figures are from Claycomb et al. Phys. Rev. Lett. 87 (2001) 178303).\nWe observe a power law distribution of event size (i.e. the probability that N many\nreactions occur together scales like N -μ). These avalanches are phenomenologically\nsimilar to the avalanches we studied in Per Bak's sand pile. In fact, Claycomb et al.\ndevelop a sand pile model to describe this experiment.\n(c) American Physical Society. All rights reserved. This content is\n(c) American Physical Society. All rights reserved. This content is\nexcluded from our Creative Commons license. For more information,\nexcluded from our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\nsee http://ocw.mit.edu/help/faq-fair-use/.\nFigure 3: Left: Strength of the magnetic field (proportional to the number of reactions) as\na function of time. Right: Histogram of the size of peak values.\n(a) First, find the probability that a particular site on the surface will be the next\nto dissolve.\nThe probability that any particular site will dissolve in the next\nshort amount of time ∆t is Ri∆t. How long should ∆t be to predict that one\n\nsite somewhere on the surface dissolves in this period of time? Given that the\nprobability Pi of a particular surface site dissolving is proportional to it reaction\nrate, what must the proportionality constant be?\n(b) Given the result from the last part, we can simulate the reaction. At each time\nstep we first look at the reaction rates on the surface to find how long we need\nto wait before a reaction will occur. We then select which site will dissolve using\nthe probability distribution. We remove the selected site and write down that an\namount of time ∆t elapsed during that time step. The simulation finishes when\nhalf of the availible points have been removed. Write code that will simulate this\nprocess in two dimensions (or use the code on the website). Run the simulation\nat high temperature and low temperature. Describe qualitatively the difference\nbetween the two.\n(c) For a given temperature Θ, what proportion π of sites will take longer than τ to\ndissolve? (Hint: what is the probability that a randomly selected point will?).\nTo gain some intuition for the system, we can paint all of the points that decay\nfaster than τ red (hot) and those that decay more slowly blue (cool). Blue points\nare placed with probability π and red points are placed with probability 1 -π.\nThere is code online to let you see the hot and cold points for a given choice of τ\nand Θ. Take a look.\n(d) For a given Θ and τ we can understand the dynamics of the front in terms of two\nphenomena walls and holes. A wall is a connected set of points that decays slowly\nand spans the system. A hole is a connected set of points that decay quickly.\nWhat happens when the front encounters a wall? What is the largest value of τ\nfor which there still exists a wall somewhere in the system?\n(e) We may suspect that the reaction is always limited by that amount of time it\ntakes to \"break on through to the other side\" of the slowest reacting wall. If\nthis is the case how does the total time it takes to run the reaction depend on\ntemperature? Confirm this suspicion numerically.\n(f) What happens when a front encounters a hole? Describe the relation of holes to\navalanches. How do the existence of large avalanches effect the claim that there\nis some characteristic time for the reaction to finish. Does the small possibility\nof large avalanches effect the average time it takes for the reaction to run or our\nconfidence that a specific experiment will take that long to finish (i.e. the variance\nin the run time)?\n(g) The code online outputs the p.d.f. of avalanche size as a function of the number\nof elements in it. What shape is the distribution for large Θ (e.g. Θ = 1)? What\nshape is the distribution for small Θ (try Θ = 500-1). Plot the mean and variance\nof this distribution as a function of temperature to show that there is a critical\ntemperature below which avalanches destroy any confidence in our guess for the\nmean run time.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/f1c6007935b3d1ce61985b72369e6463_MIT12_086F14_intro.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nAugust 29, 2014\nContents\nIntroduction\n1.1\nWhat is environmental complexity? . . . . . . . . . . . . . . .\n1.2\nWhy study complexity?\n. . . . . . . . . . . . . . . . . . . . .\n1.3\nComplexity can emerge from simple interactions . . . . . . . .\n1.4\nObjectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5\nRequirements . . . . . . . . . . . . . . . . . . . . . . . . . . .\nIntroduction\nReferences: [1-3]\n1.1\nWhat is environmental complexity?\nThe basic laws of physics are simple.\n- Newton's second law, F = ma, tells us how apples fall, tennis balls\nbounce, and molecules collide.\n- Maxwell's equations describe interactions between electric currents and\nmagnetic fields.\n- There are modifications at high velocities (relativity) and small sizes\n(quantum mechanics).\nThese laws are simply described by differential equations and have tremen-\ndous predictive power.\n\nNow look out the window. You see\n- People, grass, trees.\n- Rocks, birds, squirrels, clouds, the river.\n- Further out: oceans and fish; mountains and glaciers.\n- Further in: vast microbial communities (up to a billion/cc)\nWhy are they there? How did they get there? Why do they look like they\ndo?\nThese things are all obvious to the eye, and such a familiar part of our\neveryday experience that they are virtually unnoticed. Yet answering these\nquestions using the laws of physics can appear impossible. Why?\nThese phenomena all exhibit structure with variability.\nIf the structure were perfectly ordered, like a crystal, we could understand it.\nConversely, if the structure were perfectly disordered, like an ideal gas, we\ncould also understand it.\nThe structure of the natural world, on the other hand, usually lies somewhere\nin between.\nWe refer to this type of intermediate variability as complexity.\n1.2\nWhy study complexity?\nComplex systems often exhibit variability over a wide range of scales. Con-\nsider again the Earth, from large to small scales:\n- Continents and oceans.\n- Mountains, rivers.\n\n- Lakes, glaciers.\n- Rocks and soils.\nStudies of complexity seek the origin of such variability.\nIn some cases, we are able to specify a set of qualitative criteria--universality\nclasses--that allow for quantitative predictions of \"emergent behavior\" in a\nwide variety of systems.\nThis general goal has however been achieved only in relatively narrow cases\n(e.g., the transition to chaos) or with respect to well-defined models (e.g.,\nself-organized criticality).\nRather than seeking general laws applicable all complex systems, we instead\nacknowledge their differences. Earthquakes are neither avalanches nor stock\nmarket crashes; river networks are neither evolutionary trees nor leaf venation\npatterns.\nWe nevertheless suggest that studies of individual, exemplary, complex sys-\ntems, can offer insight applicable to other complex systems.\nWe refer to these insights as lessons [1]. Some of these lessons are noted in\nsyllabus.\n1.3\nComplexity can emerge from simple interactions\nHere's one such insight:\nNature can produce complex structures from simple interactions.\nWe illustrate this idea with a model of a fluid. We like fluids because much\nof the complexity of our natural environment derives from fluid motions:\nthe weather, the climate, rivers, oceans. At some scales the flow can ap-\npear chaotic (e.g., turbulent bursts of wind), while at others it can appear\norganized (e.g., the jet stream, hurricanes, tornadoes).\n\nTo model a fluid, we must describe how the flow at a particular point in space\naffects the flow at other points. We build a model from three ideas:\n- Locality. Fluid particles influence only their immediate neighbors.\n- Conservation. Particles, and their momentum, are conserved.\n- Symmetry. There is no preferred direction for flow (isotropy).\nRather than assuming a continuum and deriving partial differential equations,\nwe instead seek the simplest possible model from which fluid motions emerge.\nWe include only the following ingredients:\n- Identical particles hop at unit speed from site to site on a regular lattice.\n- Collisions conserve particle number and momentum.\nHere's one time step in the model's evolution.\n(a) initial condition; (b) hop; (c) collide.\n(c)\n(a)\n(b)\nNow increase the size of the system, letting many particles evolve over many\ntime steps. Then average the particle motions in space and time, to obtain\na \"smooth\" picture of the flow.\nRemarkably, these coarse-grained flows are virtually identical to the motion\nof real fluids, including all the beautiful structure of turbulent motions.\nWhat have we learned?\n\nSimple caricatures of the real world can produce beautifully complex behav-\nior.\nWhy does it work?\n- Formally: because our three requirements of fluid motion are fulfilled.\n- Informally: because many particles interact over long times. (Thus one\ncould say we obtain \"quality from quantity\" [2].)\n- More subtly: because there is a separation of length and time scales\nbetween the microscopic motion of particles and the macroscopic motion\nof fluids.\n1.4\nObjectives\nThe objective of this course is to teach lessons such as those which we just\nlearned with our discrete fluid.\nTo do so, we will consider a mix of fundamental models (like the discrete fluid)\nalong with studies of specific systems that occur in our natural environment.\nThe natural systems are chosen because a) they provide a context in which\nto learn interesting lessons; and b) they are interesting in their own right.\nSuch problems include\n- Networks (rivers, food webs).\n- Transport through disordered (porous) media.\n- Extreme events, like earthquakes and avalanches.\n- Global metabolism (aka biogeochemical cycles): origin, structure, and\nrates.\n\nIn other words, we emphasize what you see out the window: why the natural\n(physical and biological) environment looks like it does, how it is maintained,\nand (to a lesser extent) how it got there.\nIn these studies we will encounter several fundamental models and concepts.\nThese include\n- Random walks.\n- Gaussian and non-Gaussian fluctuations.\n- Structure of random networks.\n- Percolation theory: critical phenomena, scaling, universality, fractals,\nrenormalization.\n- Self-organized criticality.\n- Disordered kinetics.\nLessons to be learned include\n- How complexity can derive from simplicty.\n- How to derive (macroscopic) statistical descriptions of systems from their\n(microscopic) dynamics.\n- Why fractals and scale-invariance are ubiquitous.\n- Why non-Gaussian fluctuations occur so often in natural systems.\n- How to understand the complex kinetics of \"global metabolism.\"\n- How to use computer simulations to reveal fundamental phenomena.\n- How to construct a \"minimal\" model of a complex system that\n- matches the right level of description to the phenomena of interest;\nand\n- answers a question worth asking.\n\n1.5\nRequirements\n- Class participation.\n- Project-oriented problem sets.\n- Final project.\n- Students choose a subject of interest related to complexity in the\nenvironment.\n- Students prepare a brief project proposal to be given orally, in class,\nshortly before mid-semester.\n- Results are presented orally in class at the end of the term; a written\nreport is due the date of the last class.\n- Compared to undergraduates, a deeper level of originality, breadth,\nand substance is expected from graduate students.\n- Grades: approximately 40% problem sets, 40% final project, and 20%\nclass participation.\n- No exams.\nReferences\n[1] Goldenfeld, N. & Kadanoff, L. P. Simple lessons from complexity. Science\n284, 87-89 (1999).\n[2] Bak, P.\nHow Nature Works: the Science of Self-Organized Criticality\n(Springer-Verlag, New York, 1997).\n[3] Rothman, D. H. & Zaleski, S. Lattice-gas Cellular Automata: Simple Mod-\nels of Complex Hydrodynamics (Cambridge University Press, Cambridge,\n1997).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 2-5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/32303be6bc9b21df2280be1f41eb5c24_MIT12_086F14_twolevels.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nSeptember 10, 2014\nContents\nFrom microdynamics to macrodynamics\n1.1\nRandom walks . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.1\nOne-dimension, discrete time and space . . . . . . . . .\n1.1.2\nHigher dimensions\n. . . . . . . . . . . . . . . . . . . .\n1.1.3\nThe binomial distribution and the Gaussian limit . . .\n1.1.4\nCentral-limit theorem . . . . . . . . . . . . . . . . . . .\n1.1.5\nMacrodynamics: the diffusion equation . . . . . . . . .\n1.2\nThe lattice gas\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.1\nMicrodynamical equations . . . . . . . . . . . . . . . .\n1.2.2\nMacrodynamical equations of the lattice gas . . . . . .\n1.2.3\nSymmetry . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.4\nSeparation of scales . . . . . . . . . . . . . . . . . . . .\nFrom microdynamics to macrodynamics\nThroughout the course we will suggest that simple idealized microdynamics,\nsuitably averaged in space and/or time, suffices as a representation of complex\nmacroscopic continuum behavior.\nWe now provide two examples in which such a connection can be shown\nexplicity:\n- Random walks →diffusion.\n- Lattice gas →fluid flow (as in the previous lecture).\nThe interest in these models derives in part from their statistical dynamics.\n\n1.1\nRandom walks\nReferences: [1-3]\n1.1.1\nOne-dimension, discrete time and space\nConsider a (drunkard's) random walk along a line:\n- Start at time t = 0 and position x = 0.\n- Every τ seconds, take a random step s to the left or right.\n- Assume equiprobable steps of equal size δ:\nP(s = δ) = P(s = -δ) = 1/2.\n- No memory (statistically independent jumps).\nWe think of this as a caricature of real diffusion (e.g., Brownian motion).\nNow consider an ensemble of N independent random walks (i.e., many such\ndrunkards, each acting with no awareness of the others).\nLet xi(n) be the position of the ith walker after n steps. Then\nxi(n) = xi(n -1) + s.\nThe mean position of a large ensemble of walkers after n steps is\n⟨x(n)⟩=\nlim\nN→inf\nN\nxi(n\nN i=1\n-1) + s\n= ⟨x(n\nX\n-1)⟩+ ⟨s⟩\n= ⟨x(n -1)⟩.\n\nHere we have used the angle brackets ⟨·⟩to denote the ensemble average.\nThe result shows that the mean position is independent of n, thus retaining\npermanent memory of the initial condition:\n⟨x(n)⟩= 0.\nIntuitively we understand that there should nevertheless be a wide spread in\nthe probability P(x) that increases with time:\n-10\n-5\n0.1\n0.2\n0.3\n0.4\nprobability density\nx\n1/2\nWe characterize this spread by the root-mean-square displacement\n\nx2(n)\n\n.\nTo calculate it, first write\nx2\ni(n) =\n\nxi(n -\n1) + s\n\n= x2\ni(n -1) + 2sxi(n -1) + s2.\nBecause the mean of a sum of random variables is the sum of the means, the\nmean-square displacement in the ensemble is\n\nx2(n)\n\n=\n\nx2(n\n1)\n\n+ 2 s x(n\n1) +\n\ns2\n=\n\nx2\n-\n⟨\n-\n⟩\n(n -1)\n\n+ 2 s\nx(n\n1) +\n\ns2\n=\n\nx2(n -1)\n\n+ δ2\n⟨⟩⟨\n-\n⟩\n.\nIn the second relation, we have replaced the average of a product with the\nproduct of averages because s is uncorrelated to x. (This also may be deduced\nfrom the observation that the walk contains no memory of past steps.)\nNote that our result is in the form of a recursion, which is readily put in the\nsimpler form\n\nx2(n)\n\n= nδ2\n\nSince t = nτ, we have\n\nx2\n= δ2t/τ = 2Dt,\nwhere we have defined the diffusion coefficient\nδ2\nD =\n.\n2τ\nThus the mean-squared displacement increases linearly with time, like 2Dt.\nConsequently the root-mean-square displacement increases like the square-\nroot of time:\n\n1/2\nx2\nIn\n\n= (2Dt)1/2.\ntuitively we√understand that the width of a bell-shaped distribution P(x, t)\nincreases like\n2Dt.\nIndeed, in the plot above,\n\n1/2\nx2\n= 1, 2, and 4\ncorresponding to times t such that\n2Dt = 1, 4, and 16.\nFor a small molecule in water, D ≃10-5 cm2/s. So imagine you're a bac-\nterium (size ∼10-4 cm), and you want to know how how long some molecular\nn\nutrien\n\nt will take to diffuse a distance laway from you. Identifying lwith\n1/2\nx2\n, the diffusion time τd is\nτd ∼l2/2D.\nConsider two particular cases:\nl(cm)\nτd (s)\n10-4\n5 × 10-4\n5 × 104\nIn other words, the molecule would stay within a length commensurate with\na bug's size for only about a millisecond. But it would stay within 1 cm for\nabout 14 hours!\n\nThis huge change is a consequence of the quadratic scaling τd ∝l2, a hallmark\nof diffusive processes.\nIn contrast, for a simple advective flow times scale linearly with distance.\n1.1.2\nHigher dimensions\nBefore moving on, we first argue that our little toy problem is equally valid\nin higher dimensions.\nIn, say, two dimensions, the random walker is on a plane. In our discrete\napproximation, this corresponds to a lattice with a \"Manhattan metric,\" with\nthe drunkard originating at his corner bar and moving ±δ in each dimension\nat each time step.\nBecause the drunk's motion in x is independent of his motion in y,\n\nx2\nSince\n\n=\n\ny2 = 2Dt\nthe mean-square distance from the\n\norigin is\nr2 = x2 + y2,\nwe have\n\nr2\n= 4Dt.\nThe generalization to higher dimensions is obvious. The point is that we\nretain the diffusive scaling l2 ∝t.\n1.1.3\nThe binomial distribution and the Gaussian limit\nWe return now to one dimension, and seek the probability P(x, n) that a\nrandom walker is at position x after n steps.\nIn doing so, we generalize the toy problem so that\nP(s = δ) = p\nP(s = -δ) = q = 1 -p,\n\ni.e., the random walk takes positive steps of size δ with probability p and\nnegative steps with probability q = 1 -p.\nThe displacement after k positive steps is\nx(n) = [k -(n -k)]δ\n= (2k -n)δ\nThe probability of arriving at this point by a specific sequence of k positive\nsteps and n -k negative steps is\npkqn-k.\nSince there are two choices per step, there are 2n possible sequences of steps.\nThe number of possible sequences\n\nin which k of the n steps are positive is\nn\nn!\nk\n≡\n.\nk!(n -k)!\nThe probability of having exactly k positive steps in n attempts is the bino-\nmial distribution\nn!\nP(k, n) =\npkqn-k.\nk!(n -k)!\nFor large n (long times) the binomial distribution approaches the Gaussian\ndistribution\nP(k, n)dk =\ne-(k-μ)2/2σ2dk\n(2πσ2)1/2\nwhere P(k)dk is the probability that k is between k and k + dk, and\nμ = ⟨k⟩= np,\nσ2 =\n\nk2\nW\n\n-⟨k⟩2 = npq.\ne can write this in a simpler form by substituting x = (2k -n)δ. The\nresulting distribution then corresponds to an unbiased random walk about\nx = 0 with p = q = 1/2.\nNote that in the symmetric case we can also substitute\ndx = 2δdk,\nt = nτ,\nD = δ2/2τ\nto obtain\nP(x, t)dx =\ne-x /4Dtdx,\n(4πDt)1/2\ni.e., a Gaussian with mean ⟨x⟩= 0 and variance ⟨x2⟩= 2Dt.\n\n1.1.4\nCentral-limit theorem\nThe previous result is in fact more general. No matter what distribution P(s)\nthe step size is drawn from, the long-time limit of P(x) is still Gaussian.\nTo show this, we shall use the Fourier-transform pair\ninf\nφ(k) =\nZ\neikxP(x)dx\n-inf\nP(x) = 2\nZ inf\ne-ikxφ(k)dk.\nπ\n-inf\nThe first relation also defines the average (or characteristic function)\nφ(k) =\n\neikx\n.\nNote that the jth derivative evaluated at zero has the simple form\ndjφ(k)\n= ij\nZ inf\nxjP(x)dx\ndkj\nk=0\n-inf\n= ij\nxj\nwhere xj\nis the jth moment of P(x).\n\nW\n\n,\ne express φ(k) as a Taylor series of the moments:\ndφ\nφ(k) = φ(0) + k\nk\n+\ndk\n\nk=0\nd2φ\ndk2\n\nk=0\n+ O(k3)\n= 1 + ik⟨x⟩-k2\nx2 + O(k3).\nNow return to our random walk. The distribution\n\nP(x) derives from the sum\nof random steps si, i = 1, . . . , n.\nWe allow si to derive from any probability distribution with finite mean and\nfinite variance. For convenience we assume that all si are drawn from the\nsame distribution with zero mean (but it doesn't matter).\nAssuming the walk starts at the origin, the location of the walk after n steps\nis given by the sum\nn\nx(n) =\nX\nsi.\ni=1\n\nThe mean-square distance is\n\nx2\nn\n=\ni,j\nX\n=1\n⟨sisj⟩= n\n\ns2\n\n= nσ2,\nwhere σ ≡\n\ns\n\nis the variance of s.\nSince\n\nx2\ngrows with n, we consider the reduced sum\nw(n) = x(n)/n1/2,\nwhose variance\n\nw2\nis constant.\nWe seek the probability density P(w). To do so, we write its characteristic\nfunction\nφw(k) =\nD\neikw(n)E\n=\n*\nexp\n\nik\nj\nn\nX\nn\ns\n1/2\nj=1\n!+\nwhere we have merely used the definitions of φ, w, and x. Since the expo-\nnential of a sum is a product of exp\n*\nonentials,\nY\nn\nφw(k) =\neiksj/n /2\nj=1\n+\nn\n=\nY\nj=1\nD\neiksj/n /2E\nwhere in the latter relation we have used the independence of each random\nstep sj. Since each term in the product above is equal,\nφw(k) =\n≡\nD\nn\neiks/n1/2E\n\nφs\nk/√n\nn .\nwhere we have implicitly defined the characteristic function φs.\nExpanding φs(k/√n) in powers of the moments, we have\nφs\nk/√n\n\n= 1 -k2σ2\n2n + O\nk3\n,\nn3/2\n\nwhere the first-order term vanished from the assumption that ⟨s⟩= 0.\nFor large n, the third-order term can be neglected. Substitution of the re-\nmaining expansion into the expression for φw(k) then yields, for large n,\n\nk2σ2\nlim φw(k) =\nlim\nn→inf\nn→inf\n-\nn\n2n\n\n=\nlim exp\nn→inf\n\nn log\n\nk2σ2\n1 -\n\"\n2n\n\n=\nlim exp n\nn→inf\n\n-k2σ2\n2n\n+ 1\nk2σ2\n.\n+ . .\nn\n!#\n= e-k2σ2/2.\nThe final step is the inverse Fourier transform to obtain P(w):\nP(w) =\ninf\n2π\nZ\ne-ikwφw(k)dk.\n-inf\n= √\ne-w /2σ2,\n2πσ2\ni.e., a Gaussian distribution with zero mean and variance σ2.\nThis is the central limit theorem: for large n, the sum of random numbers\ndrawn from any distribution with finite variance asymptotically approaches\nthe Gaussian distribution.\nOur rescaling by 1/√n hides the growing variance but does not change the\nresult: the distribution P(x) of the random walk is Gaussian, no matter how\nthe steps are made.\nThis is an elementary statement of universality: in the long-time limit, the\ndetails of the \"microdynamics\"--i.e., the step-size distribution--do not mat-\nter. The long-time limit of the Gaussian requires only that the probability\nof extremely large events be extremely small.\nThis result underlies the ubiquity of the Gaussian distribution: any process\nthat results from \"sums\" of random variables is likely to yield Gaussian fluc-\ntuations.\n\n1.1.5\nMacrodynamics: the diffusion equation\nWe now proceed to derive the diffusion equation from our random walk.\nSuppose we have a long tube of cross-section A in which particles undergo\nrandom walks. We are interested in N(x), the number of particles at x (i.e.,\nbetween x -δ/2 and x + δ/2), along with the particle flux Jx.\nHow many particles pass through a unit area in unit time, from x to x + δ?\nAnd in the other direction?\nIn other words, what is the net flux Jx?\nWe imagine a boundary between x and x + δ. During one time step τ, half\nthe particles at x cross over to the right, and half the particles at x + δ cross\nover to left.\nThe net flux (number particles per unit area per unit time) is\nJx =\nN(x)\n-N(x + δ)\nAτ\nwhere the factor of 1/2 comes from the fact that half the particles at each\nlocation move away from the boundary rather than towards it.\nRearranging and multiplying by δ2/δ2,\nδ2\nJx = -2τ\nδ\nN(x + δ)\nAδ\n-N(x)\nAδ\n\nDefining the number density or concentration C = N/Aδ and recalling D =\nδ2/2τ, we have\nC(x + δ)\n)\nJx =\nD\n-C(x\n-\n.\nδ\n\nLetting δ →0, we obtain\n∂C\nJx = -D\n.\n∂x\nThis is Fick's (first) law: the concentration flux goes down the concentration\ngradient, at a rate given by the diffusivity D.\nFick's law is an example of a \"linear-response relation.\" Others include Ohm's\nlaw and Hooke's law. The linearity is essentially an assumption, which follows\nin our case from assuming that the two sides of the boundary through which\nparticles flow act independently of one another.\nNow consider particles flowing into and out of a box with cross-sectional area\nA perpendicular to and width δ parallel to the x-axis.\nThe concentration C(t) inside the box changes with the net flux into it.\nIn τ units of time the concentration changes as\nC(t + τ) -C(t) =\nAτ\nJx(x) -Jx(x + δ)\n\nAδ\nThe factor of Aτ converts the concentration flux to the number of particles\nflowing through the face, and the factor of 1/Aδ converts that number to a\nconcentration. Simplifying, we obtain\nC\nτ\n(t + τ) -C(t)\n\n= -\nJ\nδ\nx(x + δ) -Jx(x)\n\n.\nLetting τ →0 and δ →0, we obtain\n∂C\n∂t = -∂Jx\n∂x\n\nSubstituting Fick's first law for Jx then yields the diffusion equation:\n∂C\n∂2C\n= D\n∂t\n.\n∂2x\nThese developments can be derived succinctly by an alternative approach.\nLet\nPn(i) = probability that a random walker is at site i after n steps.\nSince steps to the left and right occur with equal probability, we have\nPn(i) = 2Pn-1(i + 1) + 1Pn\n-1(i -1)\nNow set\nt = nτ\nand\nx = iδ\nand consider the probability to be spread over an interval of size δ so that\nPn(i) = δ · p(x, t).\nThen\np(x, t) = 2p(x + δ, t -τ) + 1p(x\n-δ, t -τ).\nMultiplying both sides by 1/τ and rearranging, we have\nτ [p(x, t) -p(x, t -τ)] = δ2\n2τ · 1 [p(x + δ, t\nt\n-τ) -2p(x,\nδ\n-τ) + p(x -δ, t -τ)]\nWe recognize the LHS as a finite difference in time and the RHS as a finite\ndifference of finite differences in space.\nThus in the limit as τ →0 and δ →0, we have\n∂p\n∂2p\n= D\n∂t\n∂x2,\nD = δ2\n2τ\nexpressing the diffusion of probability.\nReverting back to the concentration C, note that in higher dimensions, Fick's\nfirst law is\nJ = -D∇C\n\nand mass conservation yields\n∂C\n\n=\n∂t\n-∇· J.\nCombining the two, we have the diffusion equation\n∂C = D\n,\nt\n∇2C\n∂\nwhich may be straightforwardly obtained by generalization of our random\nwalk to higher dimensions.\nBy deriving the diffusion equation via a random walk, we have exposed the\nconnection of diffusion to random motion.\nThe universality of the Gaussian distribution tells us that only the diffusivity\nD changes as the distribution of step sizes (or waiting times) changes, not\nthe diffusion equation itself, provided that the step size and waiting time\ndistributions are not too wide.\nConclusion: The simplest possible random walks are solutions to the diffusion\nequation. Consequently:\n- We can think about diffusive processes as random walks.\n- We can equally think about random walks as diffusive.\n- Should we wish to numerically solve the diffusion equation, we can sim-\nulate random walks instead.\n1.2\nThe lattice gas\nReferences: [4,5]\nWe now return to the lattice gas of Lecture 1 and sketch its relation to the\nequations of fluid dynamics.\nIn some sense, the continuum limit of the lattice gas follows similar arguments\nto that for the diffusion equation.\n\nHowever there are two additional issues: symmetry and scale separation. We\ncomment briefly on the first and in some detail on the second.\n1.2.1\nMicrodynamical equations\nRecall the model's evolution:\n(c)\n(a)\n(b)\nA\nS\nA\nS\nA\nS\nBefore\nAfter\nThe particle dynamics evolve as\nni(x + ci, t + 1) = ni(x, t) + Δi[n(x, t)].\nThe quantities n = (n1, n2, . . . , n6) are Boolean variables that indicate the\npresence (ni = 1) or absence (ni = 0) of particles.\nParticles move from sites x to neighboring sites at x + ci.\nParticles move with unit speed in the directions given by\nci = (cos πi/3, sin πi/3),\ni = 1, 2, . . . , 6.\nΔi ∈{-1, 0, 1} is the collision operator. Example: the three-body collision:\n(3)\nΔi = ni+1ni+3ni+5n in i+2n i+4 -nini+2ni+4n i+1n i+3n i+5,\nwhere n i = 1 -ni and a subscript x is taken to imply \"x mod 6\".\n\n(2)\nThere is a also a two-body collision ∆i . Then\n(2)\n(3)\n∆i = ∆i\n+ ∆i .\nThis is the entire dynamics, due to Frisch, Hasslacher, and Pomeau [4].\nNote that ∆i conserves mass,\nX\n∆i(n) = 0,\ni\nand momentum,\nX\nci∆i(n) = 0.\ni\nUsing mass conservation, we sum the microdynamical equation over each\ndirection i to obtain\nX\nni(x + ci, t + 1) =\nX\nni(x, t).\ni\ni\nSimilarly\nX\ncini(x + ci, t + 1) =\nX\ncini(x, t).\ni\ni\nThese are the microscopic mass-balance and momentum-balance equations\nof the lattice gas.\n1.2.2\nMacrodynamical equations of the lattice gas\nConsider an area A of lattice sites enclosed by a perimeter S.\nMass conservation requires that\nX X\n[ni(x, t + 1) -ni(x, t)] = -(net mass flux out of\n)\nx∈A\ni\nS .\nNow define the average particle occupancy ⟨ni⟩. The averages ⟨·⟩are con-\nstructed so that they vary slowly in space and time--more on this later, when\nwe will refer to the macroscopic length scale as Lhydro.\nIn terms of the averaged quantities, we have\n\n- P\ni⟨ni⟩: slowly varying mass.\n- P\ni⟨ni⟩ci: slowly varying mass flux.\nWe identify the left-hand side above as the time derivative of the mass and\nthe right-hand side as the divergence of the mass flux. Then\n∂t\nX\n⟨ni⟩= -∂α\nX\n⟨ni⟩ciα,\ni\ni\nwhere the α-component of the ith velocity vector ci is given by ciα, and\nd\nrepeated Greek indices are summed (i.e., XαYα =\nWe describe the momentum flux similarly, i.e.,\nP\nα=1 XαYα.)\nX X\n[ni(x, t + 1) -ni(x, t)]ciα =\nα\n∈A\ni\n-(net flux of\n-momentum out of\nx\nS).\nAveraging allows identification of\n- P\ni⟨ni⟩ciα: slowly varying α-component of momentum.\n- P\ni⟨ni⟩ciαciβ: slowly varying α-momentum carried by ⟨ni⟩in the β-\ndirection.\nThus the LHS averages to the time derivative of α-momentum and the RHS\nis the divergence of the flux of α-momentum:\n∂t\nX\n⟨ni⟩ciα = -∂β\nX\n⟨ni\niβ\ni\n⟩ciαc .\ni\nNow define the mass density\nρ =\nX\n⟨ni ,\ni\n⟩\nand the momentum density\nρuα =\nX\ni\n⟨ni⟩ciα.\n\nSubstitution above then yields the continuity equation,\n∂tρ = -∂α(ρuα),\nand the macroscopic momentum-balance equation,\n(0)\n∂t(ρuα) = -∂βΠαβ,\nwhere\n(0)\nΠαβ =\nX\ni\n⟨ni⟩ciαciβ\nis the inviscid momentum flux density tensor.\n1.2.3\nSymmetry\nThe arguments above provide the basic foundation of the continuum limit\nand its correspondence to real fluid dynamics.\nHowever one should ask whether the appearance of terms like ciαciβ in the\nmomentum flux cause the fluid motion to be hexagonally symmetric (rather\nthan isotropic).\nIn the real world, the inviscid momentum flux density tensor takes the form\n(0)⋆\nΠαβ = pδαβ + ρuαuβ\nwhere p is the pressure and\n1 α = β\nδαβ =\n\n.\nelse\nThrough symmetry arguments one may obtain the general form of the lattice\nanalog when the average velocity u is small. Expanding to second order, one\nobtains\n(0)\nΠαβ = p0(ρ)δαβ + λ\nαβγδ(ρ)uαuβ + O(u ).\nIn real fluids, λαβγδ is isotropic, meaning that it is invariant under rotation.\nThe isotropy of the lattice gas turns out to depend on the symmetry proper-\nties of fourth-order tensors made\nX\nfrom\nciαciβciγciδ.\ni\n\nSurprisingly, it turns out that six velocities suffice for isotropy! (This result\nis indeed familiar in elasticity theory, where it is often shown that the stress-\nstrain relation in a hexagonally symmetric system is isotropic.)\nNote that a similar question could be asked for our random walk: Is a random\nwalk on a lattice isotropic?\nIn this case, in the continuum limit we no longer relate second-rank tensors\n(e.g., stress and strain) via a fourth-rank tensor, but instead we relate vec\ntorial quantities (mass flux and concentration gradient) via a second-rank\ntensor.\nOne may then show that symmetry rests only on the isotropy of second-rank\ntensors formed from\nciαciβ,\ni\nfor which 4-fold symmetry (i.e., a square lattice) suffices for isotropy.\nFurther information can be found in Ref. [5].\n1.2.4\nSeparation of scales\nA related question of more general importance concerns the separation of\nlength scales between that of the lattice unit and that of the fluid continuum.\nBecause real fluids are made of atoms or molecules, our remarks below are in\nthat context, but they easily translate to our lattice model.\nConsider the following macroscopic length scales in a flow:\nU\nl 3\nl\nl\n\nOf the length scales li we define\nLhydro : the smallest characteristic length scale of macroscopic motions.\nWe are also interested in the mean free path\nRmfp : the characteristic length scale between molecular collisions.\nFluids may be regarded as continuous fields if\nLhydro » Rmfp.\nWhen this condition holds, the evolution of the macroscopic field may be\ndescribed by continuum mechanics, i.e., partial differential equations.\nTo make this idea clearer, consider a thought experiment in which we measure\nthe density of a fluid over a length scale R using some particularly sensitive\ndevice. We then move the device in the x-direction over a distance of roughly\n10R.\nSuppose R ∼ L1 ∼ Rmfp. Then we expect the density to vary greatly in space\nas in Figure (a) below:\ndensity\nx/L\nx/L\nx/L\nhydro\n(a)\n(b)\n(c)\nWe expect that the fluctuations in (a) should decrease as R increases. (Statistics\ntells us that these fluctuations should decrease like 1/N 1/2, where N ∝ .3 is the average number of\nmolecules in a box of size .. )\nOn the other hand, if R ∼ Lhydro (see (c)), variations in density should reflect\ndensity changes due to macroscopic motions (e.g., a rising hot plume), not\nmerely statistical fluctuations.\n\nOur assumption of a continuum implies that there is an intermediate scale,\nl∼L2, over which fluctuations are small. Thus the continuum hypothesis\nimplies a separation of scales between the molecular scale, L1 ∼lmfp, and the\nhydrodynamic scale, Lhydro.\nBoth the lattice gas and real fluids provide the happy situation in which there\nis a genuine \"scale-gap\" between phenomena like (a) and (c). Such situations\ngive confidence to the notion of a continuum and the partial differential equa-\ntion that models it.\nHowever in many \"complex\" problems, especially non-physical (i.e., biologi-\ncal) problems, the existence of such a separation is not obvious. For example:\n- Physical: flow through (fractal) fractures.\n- Biological: ecological interactions between organisms.\nIn such cases it may be better to concentrate directly on connectivity and\nthe way it varies with scale.\nWe next address an elementary physical example of connectivity: river net-\nworks.\nReferences\n[1] Berg, H. C.\nRandom Walks in Biology (Princeton University Press,\nPrinceton, 1993).\n[2] Tennekes, H. & Lumley, J. L. A First Course in Turbulence (MIT Press,\nCambridge, MA, 1972).\n[3] Ma, S.-K. Statistical Mechanics (World Scientific, Singapore, 1985).\n[4] Frisch, U., Hasslacher, B. & Pomeau, Y. Lattice-gas automata for the\nNavier-Stokes equations. Phys. Rev. Lett. 56, 1505-1508 (1986).\n\n[5] Rothman, D. H. & Zaleski, S. Lattice-gas Cellular Automata: Simple Mod-\nels of Complex Hydrodynamics (Cambridge University Press, Cambridge,\n1997).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 6-7",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/20c4922eb09cc07841b8386d576d213c_MIT12_086F14_rivers.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nSeptember 16, 2014\nContents\nRiver networks\n1.1\nScale invariance of random walks\n. . . . . . . . . . . . . . . .\n1.2\nAllometric scaling . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nSize distribution of river basins\n. . . . . . . . . . . . . . . . .\n1.4\nScaling relation . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5\nUniversality classes . . . . . . . . . . . . . . . . . . . . . . . .\nRiver networks\nRiver networks are among the most beautiful of Nature's large-scale scale-\ninvariant phenomena.\nTo see what we mean by scale-invariant, we briefly return to random walks.\nImage courtesy of NASA.\n\n1.1\nScale invariance of random walks\nDefine the rms excursion r = ⟨x2(t)⟩1/2. We have previously shown that\nr ∝t1/2.\nNow rescale time t →bt and note that\nr(t) = b-1/2r(bt).\nThis simple manipulation yields a remarkable observation: the statistics of\nthe random walk are unchanged by the simultaneous rescaling\nx →b1/2x,\nt →bt.\nThis means that the random walk is statistically equivalent at all scales, e.g.\nHere b = 1/5 and the inset is \"blown up\"\nby a factor of 5 and the vertical axis by\n√by stretching the horizontal axis\n5.\n[Another example: go to any financial website that provides graphs of market\nfluctuations at a time scale of your choosing (days, weeks, months, years).\nNote that aside from long-term trends, all graphs look alike!]\nAlthough we present the random walk as an example of scale-invariance, note\nthat space and time do not scale in the same way.\nSuch scaling is called self-affine, but for now it suffices to simply note the\nstatistical equivalence at different scales.\n1.2\nAllometric scaling\nRiver basins exhibit a similar phenomenon: they too have statistically similar\nshapes at all scales, but their dimensions scale differently.\n\nWe refer to the two lengths as L and L :\n∥\n⊥\nThe area a is\na ∝L L .\n∥\n⊥\nMeasurements made from maps typically show\nL\n∝LH,\n1/2 ≲H\n⊥\n≲\n∥\nand therefore\na ∝L1+H\n∥\nThe case H = 1 in (a) yields geometric similarity or self-similarity: no matter\nwhat the size of a, all basins \"look alike.\"\nThe case H = 1 in (b) is called allometric scaling (as opposed to \"isometric\"):\ndimensions grow at different rates.\nSpecifically,\nL⊥\nL∥\n∝LH-1\n∥\n∝\n\na\n1+H\nH-1\n= a-1-H\n1+H .\nSince observed values of H fall within 0 < H < 1,\n1 -H > 0.\n1 + H\nTherefore\n- large river basins tend to be long and thin; and\n- small river basins tend to be short and fat.\nUpon appropriate rescaling, however, they all look the same.\n\n1.3\nSize distribution of river basins\nSuppose we stand at a point x0 chosen at random on a landscape. What is\nthe size of the area a that drains into it?\nWe could estimate a by walking uphill from x0, always following the steepest\npath. That brings us to a drainage divide, providing an estimate of L .\n∥\nObtaining the full area a, however, requires more work. A particularly labor\nintensive method would be to create a grid of, say, 1 m, and to place a person\nat each grid site above x0. We then ask each person to follow his/her path of\nsteepest descent from one grid site to the next. Then if N people eventually\narrive at x0, the drainage basin has size N m2.\nBut what would a be a step to the right or left?\nMore generally, what is the probability distribution Pa(a) of drainage areas?\nTo answer this question we create a model of a landscape made of random\nbumps. The bumps are smooth on a small scale but otherwise independently\nchosen from some well-behaved distribution like a Gaussian.\nWe then tilt the landscape so that all paths of steepest descent are always\ndirected in the direction of the tilt.\nWe then populate the landscape as before, and follow each path of steepest\ndescent. Supposing that the square grid is oriented 45*to the tilt direction,\neach step down will also be a step to the left or right, and the coalescence of\nthe various paths will look like this:\n\nIf we then trace out any basin, we find that its left and right boundaries are\nparticular realizations of a random walk.\nThis is Scheidegger's 1967 model of river networks [1].\nSince for a random walk we have ⟨x2⟩1/2 ∝t1/2, we substitute\nt →L ,\nx\n∥\n→L⊥\nand conclude\nL⊥∝\n1/2\nL∥\n⇒\na ∝\n3/2\nL\n.\n∥\nSince our random walks are always directed toward the bottom boundary, the\nlength l of the longest stream in each basin scales like l ∝L , and therefore\n∥\nl ∝a2/3\nReal rivers exhibit a similar scaling law, called Hack's Law [2]:\nl ∝ah,\n0.57 ≲h ≲0.60.\nThe correspondence between the two suggests that our model is reasonable.\nTo find Pa(a), we write\nφl(y) = left basin boundary\nφr(y) = right basin boundary\nand assume that they both start at y = 0. Note that the difference\nφ(y) = φl(y) -φr(y)\nis itself a random walk that not only begins at y = 0 but also ends at y = 0.\n\nWe ask a precise question: What is the probability that φ(y) returns to its\ninitial position for the first time after n steps?\nThis is the classic first-return or first-passage time of a random walk. The\nanswer, for large n, is [3,4]\nP(n) = 2√n-3/2.\nπ\nSince our random walks are directed, the main stream length l ∝n. Therefore\nPl(l) ∝l-3/2.\nTo obtain the area distribution, we recall l ∝a2/3 and write\nl\nl\nPa(a) = P l(a)\nd\nda\n∝(a2/3)-3/2a-1/3\n= a-4/3.\nReal rivers exhibit\nP\nτ\na(a) ∝a-,\nτ = 1.43 ± 0.02,\nsuggesting once again that our model is reasonable.\n1.4\nScaling relation\nGathering our results, we have\nl ∝ah\nPa(a) ∝a-τ\nPl(l) ∝l-γ\nwhere, comparing Scheidegger's random-walk model to real observations, we\nhave\nExponent\nScheidegger\nReal world\n8 ± 0.02\n3 ± 0.02\n± 0.1\nh\n2/3\n0.5\nτ\n4/3\n1.4\nγ\n3/2\n1.8\n\nSince we are looking at areas and lengths, we expect that, whatever their real\nvalues, the exponents h, τ, and γ should be related to each other. We find\nthis relation by writing\nl\nPa(a) = P\nl(a)\nd\nl\nda\n∝(ah)-γah-1\n= a-[1-h(1-γ)],\nwhich yields\nτ = 1 -h(1 -γ).\nThis is an example of a scaling relation: an algebraic relationship that gives\nthe explicit dependence between exponents. In this case, it says that we need\nonly know two exponents to obtain the third. (Further work [5,6] shows that\nthere is only one independent exponent.)\nOur scaling relation is readily verified by substituting the value for Scheideg-\nger's model:\n= 1\n-3\n\n1 -3\nAs for the real world, we have\n\n1.43 ≃1 -0.58(1 -1.8) = 1.46.\nOverall we see that the statistical geometry of river networks--the power-\nlaw scaling, and the relations between the exponents--is well described by\nScheidegger's random walks.\nNote that we have said nothing about how real rivers form.\nInstead we note that their tendency to aggregate (i.e., connect) as they flow\ndownhill is the main ingredient necessary to account for their principal geo-\nmetric features after they form.\nWe suspect that this reflects the universal properties of random walks: i.e.,\nthat the mean square fluctuation in one dimension scales roughly like the\nmean fluctuation in the other.\n\nIf this is true, it means that natural landscapes contain no particularly special\nfeatures that suggest that the typical paths of steepest descent are unlike\nrandom walks.\nThat the Scheidegger model does not capture the correct values of the expo-\nnents τ, h, and γ suggests nevertheless that something important is missing.\nWe proceed to consider what that might be.\n1.5\nUniversality classes\nLet us consider our random-walk model as a member of a wider class of\nmodels based on the kind of path taken by flowing water:\n- (a) Non-convergent.\n- (b) Directed random walks (Scheidegger).\n- (c) Undirected random walks.\nNow consider Hack's law l ∝ah.\nThe trivial non-convergent case (a) yields h = 1.\nDirected random walks (b) yield h = 2/3.\nUndirected random walks (c) yield h = 5/8 [7].\nRemaining exponents are obtained from our previous scaling relation, aug-\nmented by the additional relation τ = 2 -h [5,6].\n\nEach of these cases may be considered universality classes. These classes are\ndelineated by qualitative conditions: here, the way in which flowing water\ncan aggregate. These qualitative conditions then lead to specific quantitative\npredictions of exponents.\nWhich universality class is \"correct\"? One could argue that undirected ran-\ndom walks are the most realistic class, and that it is no surprise that their\nHack exponent, h = 5/8, is the closest to the observed h ≃0.58.\nAlthough such reasoning may possibly be valid, it misses the main lesson:\nAggregating random walks capture the main features of river network geome-\ntry.\nAll the rest comes down to getting the exponents \"right.\" But because it is\nnot precisely clear what it would mean to be correct, it is both more inter-\nesting and safer to simply learn our lesson and ask if it has any applicability\nelsewhere.\nReferences\n[1] Scheidegger, A. E. A stochastic model for drainage patterns into an in-\ntramontane trench. Bull. Int. Assoc. Sci. Hydrol. 12, 15-20 (1967).\n[2] Hack, J. T. Studies of longitudinal stream profiles in Virginia and Mary-\nland. U.S. Geological Survey Professional Papers 294-B, 45-97 (1957).\n[3] Feller, W.\nAn Introduction to Probability Theory and Its Applications\n(John Wiley & Sons, New York, 1968).\n[4] Redner, S. A Guide to First-Passage Processes (Cambridge University\nPress, Cambridge, UK, 2001).\n[5] Dodds, P. S. & Rothman, D. H. A unified view of scaling laws for river\nnetworks. Phys. Rev. E. 59, 4865-4877 (1999).\n[6] Dodds, P. S. & Rothman, D. H. Scaling, universality, and geomorphology.\nAnnu. Rev. Earth Planet. Sci. 28, 571-610 (2000).\n\n[7] Manna, S. S., Dhar, D. & Majumdar, S. N. Spanning trees in two dimen-\nsions. Phys. Rev. A 46, 4471-4474 (1992).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 8-9",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/1f7ba6eee7a17e8240228818b1a9919a_MIT12_086F14_soc.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nSeptember 22, 2014\nContents\nSelf-organized criticality\n1.1\nAvalanches . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nEarthquakes . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nCritical phenomena . . . . . . . . . . . . . . . . . . . . . . . .\n1.4\nDirected sandpiles . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5\nThe lessons learned . . . . . . . . . . . . . . . . . . . . . . . .\nSelf-organized criticality\nScheidegger's model of rivers has been rediscovered in many different con-\ntexts.\nA particularly interesting example is the directed sandpile model.\nBut we first discuss the \"classical\" undirected sandpile model of Bak, Tang,\nand Wiesenfeld [1].\nOn a grid of size L × L, assign a number\nZ(x, y) = number of sand grains at location x, y\nAt each time step, choose a site randomly and add one grain of sand:\nZ(x, y) →Z(x, y) + 1.\nContinue to repeat these random additions until a site is \"unstable\" and\ntopples.\nThe toppling rule: when Z(x, y) ≥Zc,\nZ(x, y) →Z(x, y) -4\n\nand a grain of sand is added to each of the nearest neighboring sites:\nZ(x ± 1, y) →Z(x ± 1, y) + 1\nZ(x, y ± 1) →Z(x, y ± 1) + 1.\nWhen sand is transferred to neighboring sites, the neighboring sites them-\nselves can also topple. As can their neighbors, etc. The toppling continues\nuntil no more sites are unstable. If a boundary of the system is reached,\nparticles fall offthe edge.\nClick here to see a simulation of the sandpile model.\n(An alternative formulation, due to Grassberger [1], considers a room full of\nbureaucrats. When their paper work piles up beyond a critical level, they\npass offone unit of work to each of their neighboring bureaucrats. . .)\n1.1\nAvalanches\nThe interest in such a model is in the avalanches. Define the avalanche size\ns = number of sites that topple in a single event.\nSimulations show a power-law distribution of s:\nP(s) ∼s-τ,\nτ ≃1.1\nThe importance of such a relation is that there is no characteristic avalanche\nsize (i.e., the distribution's mean and variance exist only if one assumes a\nfinite system size L).\nOne can find data for real avalanches, or perform experiments with laboratory\nsandpiles, that, at least in some cases, confirm this picture.\nHowever its importance derives not from its detailed correspondence to real\nsandpiles but instead the apparent ubiquity of such power-law phenomena in\nnatural systems.\n\n1.2\nEarthquakes\nConsider, for example, an earthquake fault. Model it on a grid, so that Z(x, y)\nrepresents stress supported by a local asperity (i.e., friction due to surface\nroughness).\nRegional stress can be modeled by successively adding one unit of stress at\nrandom sites. When stress exceeds a critical threshold, the asperity breaks\nsuch that 4 units of stress are removed and one unit is distributed to each of\nthe nearest neighbors.\nThis model is of course merely a reinterpretation of the sandpile model. But\nthe distribution of avalanches, reinterpreted as earthquakes, has a remark-\nable correspondence to the Gutenberg-Richter scaling law: the number N of\nearthquakes of magnitude m (amount of energy released) scales like\nN(m) ∼m-b,\nb ≃1\n1.3\nCritical phenomena\nWhen the temperature of a magnet is raised to a critical temperature Tc, the\nmagnetization M decreases sharply, with infinite slope, to zero. If held at\nthe critical point, one finds zones of magnetization of all sizes.\nAnalogous phenomena occur at the critical point of fluids, where vapor and\nliquid phases become indistinguishable, and density fluctuations occur at all\nscales.\nThis scale-free behavior is characteristic of all equilibrium critical phenomena,\nand is independent of the material properties of the system.\nTo be more precise about scale invariance, suppose that the fluctuation size\nx scales like\np(x) ∝x-α.\nNote that this distribution is invariant, except for a prefactor, under the\n\nchange of scale x →bx:\np(bx) = (bx)-α = b-αp(x).\nThe power law is the only distribution of this type [2].\nThe lack of a characteristic fluctuation size is a general property of equilib-\nrium critical phenomena, wherein long-range correlations exist at the critical\ntemperature Tc.\nBak's sandpile model is interesting because it exhibits such critical behav-\nior without any \"tuning\" of the temperature.\nThe system instead \"self-\norganizes\" to the critical state.\nConsequently the phenomenon is known\nas self-organized criticality.\n1.4\nDirected sandpiles\nWe proceed to show how Scheidegger's rivers relate to Bak's avalanches.\nWe make one key change to Bak's sandpile: we assume that the \"tilt\" of the\npile requires that sand flow only downhill [3,4].\nWe tilt a square lattice diagonally, and add particles at random sites on the\ntop row. We take Zc = 2, so that when Z(x, y) ≥Zc,\nZ(x, y) →Z(x, y) -2\nand we add \"sand\" to the neighboring sites in the nearest lower row:\nZ(x ± 1, y -1) →Z(x ± 1, y -1) + 1\nIf those sites are now unstable, the sand is transferred to the nearest neighbors\nbelow once again, and so on.\nThe avalanching continues until all sites are once again stable such that Z ≤\nZc = 2 everywhere.\nThe correspondence with the Scheidegger model follows from identifying the\npaths taken by unstable particles of sand with those of Scheidegger's rain-\ndrops or random walkers.\n\nSpecifically, we once again see that the avalanche \"basin\" is bounded by di-\nrected random walks, and we inherit not only the same first-passage problem\nof Scheidegger but also the same exponents.\nIn particular, we have the avalanche size distribution\nP(s) ∼s-τ,\nτ = 4/3.\nFinally, we note that Takayasu's model of random aggregation [5] is also\nequivalent to Scheidegger's model. In this case particles move about ran-\ndomly on a 1D lattice, with constant reinjection of mass. In steady state, the\ndistribution of mass is the same as the basin distribution or the avalanche\ndistribution.\n1.5\nThe lessons learned\nThere are two principle lessons:\n- The allometry imposed by random walks can account for a wide variety\nof apparently unrelated phenomena in which size distributions decay as\npower laws.\n- The lack of a characteristic fluctuation size--i.e., scale invariance--can\noccur without the need to \"tune\" a control parameter to a critical value,\nas in equilibrium critical phenomena.\nThe first lesson does does not in itself mean that rivers, sandpiles, etc. are\ntruly the result of some mechanism that generates random walks. Instead it\nmerely establishes consistency with the geometry of random walks.\nThe second lesson is deeper, in that it suggests that the critical state is not\nso special. Indeed we shall see an example later, when we discuss percolation\ntheory, where this issue displays itself in a surprising and powerful way in a\ndynamical context.\n\nReferences\n[1] Bak, P.\nHow Nature Works: the Science of Self-Organized Criticality\n(Springer-Verlag, New York, 1997).\n[2] Newman, M. E. J.\nPower laws, Pareto distributions, and Zipf's law.\nContemporary Physics 46, 323-351 (2005).\n[3] Dhar, D. & Ramaswamy, R. Exactly solved model of self-organized critical\nphenomena. Phys. Rev. Lett. 63, 1659-1662 (1989).\n[4] Dhar, D. The Abelian sandpile and related models. Physica A 263, 4-25\n(1999).\n[5] Takayasu, H., Nishikawa, I. & Tasaki, H. Power-law mass distribution\nof aggregation systems with injection. Physical Review A 37, 3110-3117\n(1988).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 10-11",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/07e6d13519c6a1847639ad91820b7865_MIT12_086F14_anomalous.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nSeptember 24, 2014\nContents\nAnomalous diffusion\n1.1\nBeyond the central limit theorem . . . . . . . . . . . . . . . .\n1.2\nLarge fluctuations and scale invariance . . . . . . . . . . . . .\n1.3\nL evy flights . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4\nContinuous time random walk . . . . . . . . . . . . . . . . . .\n1.5\nDiffusion on a comb . . . . . . . . . . . . . . . . . . . . . . . .\n1.5.1\nInfinite L\n. . . . . . . . . . . . . . . . . . . . . . . . .\n1.5.2\nFinite L . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6\nL evy walks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.7\nThe lessons learned . . . . . . . . . . . . . . . . . . . . . . . .\nAnomalous diffusion\nIn our studies of river network geometry, we have seen how simple random\nwalks create a hierarchy of shapes.\nHowever the random walks need not be so simple, and generalizations of the\ndiffusive scaling ⟨x2⟩∼t are possible.\nSuch behavior occurs when there is no characteristic jump size or when there\nis no characteristic waiting time between jumps.\nThe problem has lately attracted much controversy and attention in ecology\n(animal movement [1-3]) and sociology (human movement [4]).\nIt also occurs widely in physical problems of transport, such as in diffusion\nwith traps, and has been applied with much success to problems of dispersion\nin groundwater flow [5].\nAnother example is diffusion in the presence of\n\nconvection rolls [6].\nIn this lecture, our principal goal is to illustrate how anomalous diffusion\nmay arise, thereby suggesting one way in which deviations from the scaling\npredictions of simple random walks may arise in particular problems.\n1.1\nBeyond the central limit theorem\nOur discussion of the random walk centered on analysis of the sum XN of N\nrandom variables li:\nN\nXN =\nli\nThere we found that the distribution of\nX\nXN is Gaussian. Our sketch of the\ncentral limit theorem required that the second-moment ⟨l2⟩be finite.\nThis condition is not met when the distribution p(l) is \"long-tailed\" or\n\"broad.\" Consider\np(l) ∼l-(1+μ),\nμ > 0,\nl →inf.\nAssuming a lower limit l0,\n⟨l⟩=\nZ inf\ninf\nlp(l)dl =\nl0\nZ\nl-μdl\nl0\nand\n⟨l2⟩=\nWhether the mean or variance exists\nZ inf\nl1-μdl\nl0\ndepends on the value of μ:\n0 < μ ≤1 :\n⟨l⟩, ⟨l2⟩infinite\n1 < μ ≤2 :\n⟨l⟩finite, ⟨l2⟩infinite\nμ > 2 :\n⟨l⟩, ⟨l2⟩finite\nThe latter case (μ > 2) falls within the conditions of our derivation of the\ncentral limit theorem.\n\nThe others do not. A different limit theorem nevertheless exists [7,8] to show\nthat the sum XN converges to a \"stable\" distribution.\nThe resulting random walks are qualitatively different from those we've con-\nsidered previously, and require a generalization of the diffusive law ⟨x2⟩∝t.\nThis is called anomalous diffusion. It appears, at least phenomenologically,\nin varied settings: diffusion of passive scalars in turbulence, dispersion of\ncontaminants in groundwater, animal foraging, human travel. The various\nempirical reports are however controversial.\nHere we consider two related types:\n- L evy flights. Random walks with power-law step sizes at equal incre-\nments of time.\n- Continuous time random walk. Random walks of equal step sizes but\nwith power-law waiting times.\nWe proceed by examining the sum XN.\n1.2\nLarge fluctuations and scale invariance\nFirst, we seek some statistical intuition and ask [8]: What is the largest value\nlc(N) encountered among the N terms of the sum XN?\nThe probability that l > lc is chosen in a particular trial is\nP(l > lc) =\nZ inf\np(l)dl\nlc\nIf l > lc occurs at most once in N trials, we have, for large N,\nP(l ≤lc) ≃1,\nN →inf\nThe probability that lc occurs only once in N trials is maximized when\nN P(l > lc) [P(l ≤lc)]N-1 ≃N P(l > lc) = 1\n\nSubstituting p(l) = l-(1+μ), we have\nN l-μinf\nlc(N) ∼\nand therefore\nlc(N) ∼N 1/μ,\nN →inf.\nFor large but finite N, the region l > lc(N) is effectively unsampled.\nFor 0 < μ ≤1, we can therefore ignore the long tail of p(l) and estimate the\nsum XN by multiplying the \"truncated\" mean N times:\nZ lc(N)\nXN ∼N\nlp(l)dl\nWe obtain\nZ N 1/μ\nμ\nN(N 1/μ)(1-μ) = N 1/μ (μ < 1)\nXN ∼N\nl-dl ∼\nN ln N\n(μ = 1)\nor, equivalently,\nXN ∼\nlc\n(μ < 1)\nlc ln lc (μ = 1)\nThus the typical value of the sum XN is dominated by the largest term within\nit, lc(N).\nNote that we have obtained this result even though ⟨l⟩and therefore ⟨XN⟩\ndo not exist.\nWe can obtain the variance by a similar agument. We have, for μ < 1,\nVarXN\n= N Var\n= N\nN\n\nl2\nN\nl\n-⟨l⟩2\n∼\n\n1/μ(2-μ)\n-\n(XN/N)\n\n∼N 2/μ -N 2/μ-1\n∼N 2/μ\n(μ < 1, N →inf)\nHere the limitation to μ < 1 applies to the term ⟨l⟩2. But when μ = 1 its log\ndivergence scales away nevertheless and we obtain the same result.\n\nFor μ > 1 the mean\n⟨l⟩∼O\n\n1 μ\nl\n\n-\n= const.\nBut l2\nstill diverges for μ ≤2 so that\nVarXN\n= N\n\nl2 -⟨l⟩\n/μ\n\n∼N 2\n-\n\nconst · N\n∼N 2/μ\n(μ < 2, N →inf)\nwhere we obtain the same asymptotic scaling since 2/μ > 1.\nFinally, note that the variance diverges logarithmically for μ = 2. When\nμ > 2, the variance grows linearly with N, as for a typical random walk, and\nthe central-limit theorem applies.\nRecalling that l\nc ∼N /μ, we thus have that the variance of the sum\nVarXN ∼l2\nc,\nμ < 2.\nConclusion: When μ < 2, the sum XN is dominated by the largest fluctuation\nlc(N). This holds true even for 1 < μ < 2 because the typical deviation of\nXN from its mean scales like lc.\n1.3\nL evy flights\nA picture of a L evy flight looks like this: many small steps are occasionally\nfollowed by a much larger step, which are, collectively, followed by a much\nmuch larger step.\nIn this way there is no intrinsic scale to the process, and no length scale ever\ndominates.\nIn our present formulation, rms displacements r grow like\nr ∼t1/μ.\nThis super-diffusive behavior for small μ < 2 is a consequence of the instan-\ntaneous jump, i.e., assuming t ∝N.\n\nThus practical applications tend to include a modification for jump times, as\nwe next consider.\n1.4\nContinuous time random walk\nThe CTRW is a random walk on a regular lattice with random waiting times\nτ between each step:\nψ(τ) = probability of waiting time τ.\nIt is essentially diffusion with \"traps,\" in which the trap waiting time differs\nin both space and time.\nAs before, we take the jump size distribution to be p(l), but with finite mean\nand variance.\nAfter N steps, we have, as usual, the mean-square distance growing linearly\nwith N:\n⟨X2\nN⟩= ⟨l2⟩N,\nN →inf\nwhere\n⟨l2⟩=\nl2p(l)dl.\nNearest-neighbor hops\nZ\n⇒⟨l2⟩= the squared lattice spacing.\nThe total time t taken by the N hops is\nN\nt =\nX\nτn.\nn=1\nThe problem thus concerns the sum of random waiting times τ rather than\nrandom steps l.\nIf ψ(τ) is well behaved such that ⟨τ⟩is finite,\nt ∼N⟨τ⟩\nand\n⟨X2⟩= 2Dt,\nD = ⟨l2⟩\n2⟨τ⟩,\n\ni.e., typical diffusion.\nThe interesting case corresponds to a long-tailed ψ(τ) such that\nψ(τ) ∼τ -(1+μ),\n0 < μ < 1,\nτ →inf\nWhen μ < 1, ⟨τ⟩= inf. Applying the results of our earlier analysis, the total\ntime t can be estimated from the largest expected waiting time τc in N steps:\n/μ\n∼N\nZ τc\nN 1\nt\nτψ(τ)dτ ∼N\nZ\nτ -μdτ ∼N 1/μ,\n0 < μ < 1\nAfter N steps of the random w\n\nalk,\n\nwe h\n\nave, as usual\nX2 = l2 N.\nBut now N ∼tμ and therefore\n\nX2 ∼l2 tμ,\n0 < μ < 1.\nThis behavior is called\n\nsub-diffusive\n\n, because\n\nX2\ngrows slower than time\n(0 < μ < 1).\n1.5\nDiffusion on a comb\nThe most interesting cases of anomalous diffusion occur when the power-law\ndistributions of step size or waiting times arise intrinsically, rather than by\nimposition.\nProbably the simplest such case is a random walk on a comb.\nWe take the x-axis along the backbone of the comb and L as the length of\neach of the comb's equally spaced \"teeth.\"\nIn considering diffusion along x, we must take account of the time spent\n\"trapped\" in the teeth.\n1.5.1\nInfinite L\nFor infinitely long teeth, L →inf, and the waiting time in a tooth is given\nby the distribution of first-passage times (already used in our study of river\n\nbasins):\nψ(τ) ∼τ -3/2,\nτ →inf\nApplying the results of the previous section, we recognize μ = 1/2 and con-\nclude that\n⟨x2⟩∼t1/2\n⇒\n⟨x2⟩1/2 ∼t1/4\nThus the rms displacement grows subdiffusively, like t1/4, rather than t1/2.\n1.5.2\nFinite L\nIf the \"trap\" size L is finite, the time required to explore a given trap is\nτc ∼L2/D0,\nwhere D0 is the bare diffusion coefficient inside the trap.\nFor times t ≪τc, the subdiffusive scaling of the previous section applies.\nFor t ≫τc, however, we must consider that the average residence time in a\ntrap is no longer infinite.\nThe distribution ψ(τ) instead has an effective cutoffsuch that\nτc\nτc\n⟨τ⟩∼\nZ\nτ ψ(τ) dτ =\nZ\nτ -1/2dτ = τ 1/2\nc\n∼L.\nThus for times t ≫τc, the effect of the traps is merely one of increasing the\ntime interval between hops along the backbone x. That is, we have as usual\n⟨x2\nl\n⟩= 2Dt,\nD =\n,\nt\nτ\n2⟨τ\n≫\n⟩\nc\nwhere l = the tooth spacing. Substituting for ⟨τ⟩, however, we find\nD ∼1/L.\nThus the effect of finite L is to scale the effective diffusion coefficent by 1/L.\n\n1.6\nL evy walks\nThe CTRW can be combined with L evy flights to render the latter more\nphysically appealing.\nOne idea is to combine the jump-size and waiting-time distributions into a\njoint probability density [9,10]\nl\nΨ(l, t) = p(l) δ\n\nt -v(l)\n\nwhere p(l) has the usual power law tail and v(l) is a (possibly) length-\ndependent velocity.\nThe resulting random walk is called a L evy walk [9,10]. It visits exactly the\nsame sites as a L evy flight, but waiting times scale with distance hopped.\nAnother idea is for the waiting times and step sizes to be independent [4],\ni.e.\nψ(τ) = τ -(1+α),\n0 < α < 1\nand\np(l) ∼l-(1+β),\n0 < β < 2\nwhere the restriction on α is such that the waiting times promote sub-diffusion\nwhereas the jump sizes tend towards super-diffusion.\nApplying our earlier results,\nX ∼⟨l⟩∼N 1/β\nand\nt ∼⟨τ⟩∼N 1/α\nand therefore\nX ∼tα/β.\n1.7\nThe lessons learned\n- Long-tailed distributions break the central-limit theorem and produce\nlarge fluctuations, intermittency, and scale invariance; i.e., variability.\n\n- These distributions need not be introduced ad hoc.\nSome problems,\nparticularly transport in disordered media, generate them \"for free.\"\n- Resulting rms fluctuations\n\nx2( )\n1/\nt\n∼tα scale anomalously, with α =\n1/2.\nReferences\n[1] A. M. Edwards et al. Revisiting L evy flight search patterns of wandering\nalbatrosses, bumblebees and deer. Nature 449, 1044-1049 (2007).\n[2] Sims, D. W. et al. Scaling laws of marine predator search behaviour.\nNature 451, 1098-1102 (2008).\n[3] Humphries, N. et al. Environmental context explains L evy and Brownian\nmovement patterns of marine predators. Nature 465, 1066-1069 (2010).\n[4] Brockmann, D., Hufnage, L. & Geisel, T. The scaling laws of human\ntravel. Nature 439, 462-465 (2006).\n[5] Berkowitz, B. & Scher, H. Theory of anomalous chemical transport in\nrandom fracture networks. Physical Review E 57, 5858 (1998).\n[6] Young, W., Pumir, A. & Pomeau, Y. Anomalous diffusion of tracer in\nconvection rolls. Physics of Fluids A: Fluid Dynamics 1, 462 (1989).\n[7] Gnedenko, B. V. & Kolmogorov, A. N. Limit Distributions for Sums\nof Independent Random Variables (Addison-Wesley, Reading, Mas-\nsachusetts, 1968).\n[8] Bouchaud, J.-P. & Georges, A. Anomalous diffusion in disordered media:\nstatisical mechanisms, models, and physical applications.\nPhys. Rep.\n195, 127-293 (1990).\n[9] Shlesinger, M. F., Zaslavsky, G. M. & Klafter, J. Strange kinetics. Nature\n363, 31-37 (1993).\n[10] Shlesinger, M. F., Klafter, J. & Zumofen, G. Above, below and beyond\nBrownian motion. American Journal of Physics 67, 1253-1259 (1999).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 12-18",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/a8b26843ad438d5f648b3b0330193d02_MIT12_086F14_percolation.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nSeptember 29, 2014\nContents\nPercolation theory\n1.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.1\nWhat's percolation?\n. . . . . . . . . . . . . . . . . . .\n1.1.2\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nPercolation in one dimension . . . . . . . . . . . . . . . . . . .\n1.3\nClusters in two dimensions . . . . . . . . . . . . . . . . . . . .\n1.4\nPercolation on the Bethe lattice . . . . . . . . . . . . . . . . .\n1.4.1\nInfinite dimensionality . . . . . . . . . . . . . . . . . .\n1.4.2\nPercolation threshold . . . . . . . . . . . . . . . . . . .\n1.4.3\nThe strength P . . . . . . . . . . . . . . . . . . . . . .\n1.4.4\nMean cluster size S . . . . . . . . . . . . . . . . . . . .\n1.4.5\nCluster numbers ns(p)\n. . . . . . . . . . . . . . . . . .\n1.5\nScaling laws in d-dimensions . . . . . . . . . . . . . . . . . . .\n1.5.1\nThe strength P . . . . . . . . . . . . . . . . . . . . . .\n1.5.2\nThe mean cluster size S\n. . . . . . . . . . . . . . . . .\n1.6\nFractals\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6.1\nCluster radius . . . . . . . . . . . . . . . . . . . . . . .\n1.6.2\nCorrelation length\n. . . . . . . . . . . . . . . . . . . .\n1.6.3\nThe fractal dimension D . . . . . . . . . . . . . . . . .\n1.6.4\nScaling of the infinite cluster at p = pc\n. . . . . . . . .\n1.6.5\nRelating D to d via the correlation length ξ\n. . . . . .\n1.7\nFinite-size scaling . . . . . . . . . . . . . . . . . . . . . . . . .\n1.8\nRenormalization . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.8.1\nSelf-similarity . . . . . . . . . . . . . . . . . . . . . . .\n1.8.2\nReal-space renormalization . . . . . . . . . . . . . . . .\n1.8.3\nCalculation of the correlation-length exponent ν . . . .\n1.8.4\nOne dimension\n. . . . . . . . . . . . . . . . . . . . . .\n1.8.5\nTriangular lattice . . . . . . . . . . . . . . . . . . . . .\n\nPercolation theory\nReference: Stauffer and Aharony [1].\n1.1\nIntroduction\nWe have previously defined complex systems as exhibiting both structure and\nvariability.\nTo this mix, we now add \"connectivity.\" That is, the structure amidst vari-\nability is often a consequence of the way \"microscopic\" components of a\nsystem \"connect.\"\n1.1.1\nWhat's percolation?\nPercolation theory provides a systematic way of studying connectivity in\nwhich \"connection\" is defined geographically: two locations in space are said\nto be connected if they are near each other, and unconnected if they are not.\nThe simplest such systems are defined on a regular lattice. Consider, for\nexample, a square lattice\nfigure\nOccupy a fraction p of the lattice squares by, say, coloring them with a black\ndot.\nNow define\nCluster: a group of occupied (nearest) neighboring sites.\nPercolation theory describes how the number and properties of clusters changes\nwith the occupation probability p.\nWe assume that the occupancy of any particular site is independent of the\nothers.\n\nThen if we have N squares and N is large,\n- pN are occupied, and\n- (1 -p)N are empty.\nThe richness of the problem is seen by viewing typical clusters on square\nlattices of varying p.\nSee, for example, this website.\nAt p ≃0.6, one cluster extends from one end of the lattice to the other.\nWe call this the critical probability pc, and we shall show that clusters formed\nat pc exhibit many of the features of \"structured variability.\"\nIn particular, the study of such structures will bring us in contact with the\nfollowing subjects:\n- Scale invariance. The critical clusters are fractals.\n- Universality. Scaling properties do not depend on details like lattice\ngeometry.\n- Finite-size scaling. We show how scale-invariant systems behave in sys-\ntems of different size, and how that relates to non-scale invariant systems.\n- Renormalization. We introduce a technique for determining properties\nof scale-invariant systems.\nMore generally, the goal is to show how \"incipient connectedness\" leads to\ninteresting non-trivial properties.\nWe shall also highlight the ways such incipient connectedness occurs generi-\ncally, without the need to set a parameter like p to pc.\n\n1.1.2\nExamples\nWe illustrate some of the pertinent phenomena with two introductory exam\nples on square lattices.\nForest fires Suppose occupied sites represent trees in a forest, and unoccu\npied sites empty space.\nLight a fire at the top row, and sweep through the lattice row-by-row. Entire\nsweeps alternate as follows:\n- Recently ignited trees ignite neighbors to the bottom and right.\n- In the next sweep, recently ignited trees ignite neighbors to the top and\nleft.\n- Trees burn out after one complete sweep.\nThe simulation continues until all trees are burnt, or all remaining trees\ncannot be burned.\nWhat is the duration (number of lattice sweeps) of the forest fire as a function\nof p?\n- Small p: short, because only a few trees can burn.\n- Large p: short, because in the limit of a fully occupied forest, each tree\nimmediately burns its neighbor.\n- p r pc: very long.\n\nIndeed, there is a (theoretical) singularity at pc.\nWhy? Because at p = pc the largest cluster of neighbors spans the system,\nbut it contains many contorted \"dead ends,\" requiring the fire to wind its\nway backwards and forwards.\nRelated examples can be found via Wikipedia.\nFluid invasion We now literally think of a true \"percolation\" process: the\ninfiltration of a water-filled rock with oil.\nGenerally water spreads preferentially on solid surfaces, so that it is called\nthe wetting fluid.\nAs a consequence, the penetration of a small pore by the non-wetting fluid\n(oil) is impeded by surface tension. Modeling the pore as a simple capillary\ntube of radius R, the situation looks like\nσ1s\nσ2s\nσ\nθ\nnonwetting\nwetting\nThe pressure difference between the non-wetting fluid and the wetting fluid\nis\n2σ cos θ\nΔp =\nR\n.\nwhere σ is the surface tension.\nNow imagine a large network of capillary tubes of different radii R. If the\ninvading non-wetting fluid is pushed sufficiently slowly, the nonwetting fluid\nadvances along a front of least resistance, i.e., the next tube it invades is\nalways the one for which the accessible radius is largest, requiring the smallest\nΔp.\n\nWe can model this on a square lattice by assigning a random number to each\nsite, which we take to be representative of the pressure ∆p required to invade\nthat site.\nThe invader then merely advances at each time step by filling the neighboring\nsite with the smallest ∆p.\nThis model is called invasion percolation [2].\nAs the invading cluster grows to a size L, it is always representative of an\nincipient spanning cluster in a system of size L. Thus this critical cluster is\nobtained dynamically, rather than by choosing p = pc.\nWe shall show that this incipient cluster is fractal. What that means is that,\nif we assigned unit mass to each occupied site, then the total mass M scales\nnot like Ld, where d is the number of dimensions, but rather like\nM ∝LD,\nD < d.\nIndeed, when d = 3 we have\nD = 2.5\n(d = 3).\nAn important characteristic of such critical phenomena is that they display\nuniversality. Here this means that the dimension D = 2.5 does not depend\non the particular type of lattice.\nConsequently we expect it to be valid in truly disordered systems such as\nporous rock.\nIndeed, one can conduct the following experiment. Fill a rock with water,\nand push the water out slowly with oil. As soon as the water reaches the\nother end, stop the experiment and measure the fraction φ of the pore space\nfilled by the invading fluid, oil.\nSince M ∝LD, we expect.\nLD\nφ ∝Ld = L-1/2.\n\nRemarkably, this is precisely\nwhat is found [3]:\nThe process just described is similar to the upward secondary migration of\noil from its source to its subsurface reservoir.\nWe find, therefore, that although a cm-scale laboratory simulation of sec-\nondary migration predicts an oil saturation of about 30%, at the 100-m\nreservoir scale we would expect only 0.3%!.\n1.2\nPercolation in one dimension\nConsider a long chain of lattice sites. Sites are occupied (black) with proba-\nbility p, and unoccupied with probability 1 -p.\n-- -*-- -- -- -- -- -*\nSince the occupation of each site is independent of the others,\nP(n arbitrary sites are occupied) = pn\nThe probability that a fixed site is to the left end of an s-cluster is therefore\n(1 -p)2ps\nEach site has an equal probability of being the left end of an s-cluster. Thus\nin a system of size L, the total number of s-clusters is, ignoring end effects,\nL(1 -p)2ps\nDefine\nns = number of s-clusters per site.\nThen, obviously,\nns = ps(1 -p)2.\nA\n\npl\not\no\nf\nfi\nrs\nt\npa\nth\ns\nat\nur\na\nt\ni\non v\ns sample diameter.\nFigure by MIT OpenCourseWare.\n\nWe also have\nP(arbitrary site is part of s-cluster) = nss,\nlarger than ns by a factor of s, since there are s ways an arbitrary site can\nbe situated within an s-cluster.\nWhat is the percolation threshold?\n- At p = 1, all sites are occupied.\n- For p < 1, there are necessarily holes as L →inf.\nThus\npc = 1.\nSumming over all possible cluster sizes, we obtain the probability that an\narbitrary site is a member of any cluster:\nX\ninf\nnss = p\n(p < pc)\ns=1\nwhere we write p < pc to eliminate the possibility of an infinite cluster at pc.\nIt is instructive to obtain the previous result from the definition of ns:\nX\nd\nn\ns\nss =\nX\np (1\ns\n-p)2s = (1 -p)2 X\np\ns\ns\nps\ndp\n= (1 -p)2\nd\np\np\ndp\nX\ns\ns\n= (1 -p)2\nd\npdp\n\np\n1 -p\n= p.\n\nAnother quantity of interest is\nws = P(arbitrary occupied site belongs to an s-cluster)\nP(site belongs to s-cluster)\n= P(site belongs to any cluster)\nnss\n= P\n.\ns nss\n\nThen, defining\nS = average cluster size,\nwe have\nS =\nX\nwss =\ns\nX\ns\nnss2\nP\n.\ns nss\nWe can calculate S explicitly, following the same scheme as above:\nX\nnss2 = (1\np\ns\n-)2 X\ns2ps\ns\nd\n= (1 -p)2\n\np\ndp\nX\nps.\ns\nNoting that\n\np d\ndp\n= p d\ndp + p2 d2 and\ndp2\nusing the previous trick to calculate\nthe sums, we obtain\n1 + p\nS =\n.\n1 -p\nand note that S diverges at p = pc = 1.\nNext, we define the correlation function\ng(r) = P(site a distance r from occupied site is in same cluster)\nObviously,\ng(0) = 1\nand\ng(1) = p.\nThus\ng(r) = pr.\nConsequently g(r) decays exponentially, like\ng(r) = e-r/ξ,\nwhere we have defined\nξ = correlation length\n=\n-1 .\nln p\nTo determine how ξ behaves near p = pc = 1, write\np = 1 -(pc -p).\n\nThen for p close to pc = 1,\nln[1 -(pc -p)] ≃-(pc -p)\nyielding\nξ =\n,\np\npc -p\n→pc.\nThus ξ also diverges as p →pc.\nHow does ξ vary with S? Comparing both results, we have\nS ∝ξ,\np →pc\nsince as p →pc both quantities represent complete occupancy of the lattice.\nSummary: In one dimension, the mean cluster size S and the correlation\nlength ξ diverge like\n(pc -p)-1,\na simple power law.\nSimilar power-law behavior will be evident in higher dimensions.\n1.3\nClusters in two dimensions\nA two dimensional square lattice serves to illustrate the main difficulties of\nhigher dimensions.\nConsider a cluster of size s = 1:\n*\n*× *\nP(s = 1) = p(1 -p)4\n*\nSize s = 2\n*\n*× *\n(2 orientations)\nP(s = 2) = 2p2(1 -p)6\n*× *\n*\n\nSize s = 3:\n*\n*\n*\n*× *\n× × *\n*× *\n(×2)\n*\n(×4)\n*×\n*\n*× *\n*\n*\nP(s = 3) = 2p3(1 -p)8 + 4p3(1 -p)7\nSize s = 4:\n×\n×\n×\n×\n× (2)\n× (8)\n× × (4)\n× × (4)\n× × (1)\n×\n× ×\n× ×\n×\n×\n×\ntotal: 19\nSize s = 5: 63.\nSize s = 24 : 1013!\nThese objects, called lattice animals, can be very complex.\nYet the general form of the probability P(s = s0) is clear: we need to know\nthe multiplicity of various forms, and the perimeter t.\nThus we define\ngst = number of lattice animals of size s and perimeter t.\nThen the average number of s-clusters per lattice site in d dimensions is\nns =\nX\ngstps(1\nt\n-p)t.\nIn general, there is no exact solution for gst, only special cases on special\nlattices.\n1.4\nPercolation on the Bethe lattice\nThe Bethe lattice--also known as a Cayley tree--is one such special lattice.\n\nEach site on the Bethe lattice has z > 2 neighbors. The simplest case is z = 3:\nThe center is the origin, and the exterior sites are said to be on the surface.\n1.4.1\nInfinite dimensionality\nThe Bethe lattice apparently does not reside in any particular number of\ndimensions d.\nHowever there is a sense in which the Bethe lattice corresponds to d = inf.\nTo see this, take the radius of the Bethe lattice to be r. If the Bethe lattice\nlived in d-dimensions, we'd have\nd\nvolume (# sites) ∝ r\nd-1\nsurface (# exterior sites) ∝ r\nwhich implies\nsurface ∝ (volume)(d-1)/d = (volume)1-1/d.\nOn the Bethe lattice,\n- The origin is surrounded by z = 3 sites.\n- The 2nd shell has z(z - 1) = 6 sites.\n- The 3rd has z(z - 1)2 = 12 sites, etc\n\nThus within a distance r from the origin, there are, including the origin, and\nsetting z1 = z -1,\n\nr\nz(zr\n1 + z 1 + z1 + z1 + . . . z1\n-\n= 1 +\n1 -1) volume sites.\nz1 -1\nBut at a distance r there are\nzzr-1\nsurface sites.\nThen, taking r large,\nsurface\nlim\nr→infvolume = lim\nr→inf\nzzr-1\n1 + z(zr\n1-1)\nz1-1\n= z1 -1\nz1\n= z -2 = const.,\nz -1\nwhere the second equality follows from dividing the numerator and denomi-\nnator by zzr-1\nand taking the limit. Thus as r →inf,\nsurface ∝volume\n⇒\nd = inf.\nThis observation does not diminish the interest of the Bethe lattice for per-\ncolation, but it does point out its inapplicability to modeling branched d = 2\nstructures such as river networks.\n1.4.2\nPercolation threshold\nFor what values of p is the origin connected to infinity? Note that\n- z -1 \"new\" bonds emanate from each site.\n- These bonds connect to an occupied site with probability p.\nThus\n⟨# occupied new neighbors⟩= (z -1)p.\nNote that\n(z -1)p < 1\n⇒\nP(connected path) →0 exponentially.\nThus we expect a connected path when\np > pc = z -1 = 1\nfor\nz = 3.\nDoes p > pc guarantee a connection of the origin to inf?\n\n1.4.3\nThe strength P\nDefine\nP = P(arbitrary site--e.g., origin--belongs to infinite cluster).\nNote that the arbitrary site may be either occupied or unoccupied.\nWe\ndistinguish between\np =\n\"concentration\"\nP =\n\"strength\"\nwhere the sense of \"strength,\" corresponds, e.g., to a kind of rigidity of the\npercolation cluster (were it, say, connected by springs).\nTo calculate P, we define\nQ = P(arbitary occupied site x is not connected to inf\nthrough one fixed branch).\nTake z = 3 for simplicity. Then the local geometry looks like\nWe have\nP(2 sub-branches do not connect x′ to inf) = Q2,\nimplying that\nP(x′ occupied but not connected to inf) = pQ2.\nTherefore\nQ = P(connection broken at x′) + P(connection broken elsewhere)\n= (1 -p) + pQ2,\nwhich has the solutions\nQ = 1\nand\nQ =\n-p.\np\nWe identify the first solution with p < pc and the second with p > pc.\n\nNow note that\nP(origin is occupied but not connected to inf) = p -P\n= pQ .\nThe first equality follows from the observation that only occupied sites can\nbe connected to infinity. The second relation arises from the definition of Q\nwith z = 3. Equating the two, we have\np -P = pQ\n⇒\nP = p(1 -Q3).\nThen our two solutions for Q correspond to\np < pc,\nQ = 1\n⇒\nP = 0\nand\n1 -p\nP\n1 -p 3\np > pc,\nQ =\n⇒\n= 1 -\n.\np\np\np\nThus the strength P--the probability that the origin belongs to the infinite\ncluster--rises abruptly at pc = 1/2.\nUsing our previous analogy between P and rigidity, one may think of this as\na transition from no rigidity, to a kind of floppiness, to strong rigidity.\nQualitatively, the behavior of P(p) is similar to what one finds in classical\nphase transitions, such as the spontaneous magnetization that occurs in the\ntransition from paramagnetism to ferromagnetism as the temperature T is\nlowered through the Curie temperature Tc.\nTo zoom in on the behavior of P as p → pc from above, we substitute x =\np -pc and expand in powers of x. We obtain, to leading order,\nP ∝(p -pc) ,\np →pc ↓\n\n1.4.4\nMean cluster size S\nAssume again that z = 3. Define\nT = mean cluster size for 1 branch.\ni.e., the average number of sites connected to the origin and belonging to 1\nbranch.\nNote that sub-branches have the same mean cluster size (because all sites in\nthe interior are essentially equivalent).\nTherefore each occupied neighbor contributes, on average, T sites to the\ncluster, so that\nT\n= P(neighbor empty) × 0\n+ P(neighbor occupied) × (1 + 2T)\nwhere the factor of 2T comes from the two sub-branches. We obtain\np\nT = p(1 + 2T)\n⇒\nT =\n,\np < p\n-\nc = 1/2.\n2p\nThe mean cluster size S is then the sum of all z = 3 branches plus the origin:\nS = p(1 + 3T).\nSubstituting our solution above for T, we obtain\np(1 + p)\nS =\n,\np < p =\n-\nc\n1/2.\n2p\nWe have therefore obtained exact results for S(p < pc) and P(p > pc).\nHow does the mean cluster size S behave as p →pc from below? Near pc the\nnumerator of S ∼const., so\nconst.\nS ∝\np\n2 -\nand therefore\nS ∝(pc -p)-1 ,\np →pc ↑\nThus S diverges, with exponent -1, near the critical point pc.\n\nIn contrast, we found above that P vanishes at pc like P ∝(p -pc)1.\nAnalogous exponents on d-dimensional lattices are more complicated. The\npower-law approach to criticality, however, is general, and is a defining char-\nacteristic of thermal phase transitions.\n1.4.5\nCluster numbers ns(p)\nRecall the number of s-clusters per site:\nns(p) =\nX\ngstps(1 -p)t,\nt\nwhere gst is the number of s clusters with perimeter t.\nThe perimeter is straightforwardly computed on the Bethe lattice:\n- a 1-cluster has z neighbors.\n- a 2-cluster has z + (z -2) neighbors (it removes one neighbor and adds\nz -1).\n- each additional site adds z -2 neighbors.\nThus an s-cluster has\nt = z + (s -1)(z -2)\n= s(z -2) + 2\nSince each s-cluster has the same perimeter, gst →gs, and the expression for\nns(p) becomes\nns = g\ns\n2+s(z\n2)\nsp (1 -p)\n-.\nWe set z = 3, and normalize by ns(pc) to avoid the prefactor gs:\nns(p)\nns(pc) =\n1 -p\n1 -pc\np\npc\n1 -p\n1 -pc\ns\n\nSince pc = 1/2 we replace the product of denominators in the brackets with\na factor a = 4 and write\nns(p)\nns(pc) =\n1 -p\n1 -pc\n\n1 -a(p -pc)2\nWe obtain a further simplification by writing\ns ,\na = 4.\nc = -ln 1 -a(p -pc)2\n∝(p -\n\npc)2,\np →p\n\nc\nso that\nns(p)\ncs\nn\n∝e-,\np\ns(pc)\n→pc\nwhere we have taken the prefactor constant as p →pc.\nThus the ratio of cluster numbers decays exponentially with cluster size. In\ntwo and three dimensions such an exponential decay turns out to be valid\nonly for large clusters for p < pc.\nWe next seek the asymptotic behavior of the cluster number ns(p) near pc,\nrather than the ratio.\nRecall the expression for the mean cluster size that we derived earlier in\nSection 1.2:\nS =\nP\ns nss2\nwhere\nP\ns nss ∝\nX\nnss2,\np\ns\n→pc\nwe obtain the proportionality since the denominator is finite at pc. [It\ngives the probability (p) that an arbitrary site belongs to any cluster.]\nBut we already found in Section 1.4.4 that\nS ∝(p -pc)-1,\np →pc ↑\nTherefore\nX\ns2n\ns(pc) = inf\nand\nX\ns ns(p = pc) is finite.\ns\ns\n\nWhat more can we say about ns(pc)?\n\nClearly it must decay with increasing s. But how?\nIf it were to decay exponentially, we would necessarily have\nS(pc) ∝\nX\ns2n\nαs\ns(pc)\ns\n∝\nX\ns e-\n,\nα > 0.\ns\nBut then S(pc) would be finite, contradicting the above.\nThus we assume a power-law decay with exponent τ for large s:\nns(pc) ∝s-τ\n(In studies of phase transitions τ is known as the Fisher exponent.)\nThe assumption of this power-law relation allows us to evaluate S and specify\nτ. Assuming p is just below pc,\nS ∝\nX\ns2\nns(p)\nns(pc)\ns\nX\nns(pc)\n=\ns2-τe-cs\ns\n=\nZ\ns2-τe-csds\nTo evaluate the integral, substitute z = cs so that\nS =\nZ z\nc\n2-τ\ne-z dz\nc\n= cτ-3\nZ\nz2-τe-zdz\nThe exponential decay of the integrand for large z guarantees its convergence,\nso that\nS ∝cτ-3 = (p -pc)2τ-6\nsince, by definition, c = (p -pc)2.\nBut we previously found S ∝(p -pc)-1. Therefore\n2τ -6 = -1\n⇒\nτ = 5/2.\n\nFinally, using our result ns(p) ∝ns(pc)e-cs, we obtain\nns(p) ∝s-5/2e-cs ,\nc = (p -pc)2.\nThe boxed relation holds for all p and large s; the second relation is for p\nnear pc.\nThis completes our study of the Bethe lattice. The main results are the power\nlaws for\n- mean cluster size S ∝(pc -p)-1\n- strength P ∝(p -p\nc)\nand the above result for the cluster numbers ns(p).\n1.5\nScaling laws in d-dimensions\nWe now seek an understanding of percolation that includes the Bethe-lattice\nsolution as a special case.\nTo do so, we postulate the following scaling laws:\nCluster numbers:\nns(p) ∝s-τe-cs,\ns →inf\nwhere\nc ∝|p -pc|1/σ,\np →pc\nHere τ and σ are constants that depend only on d.\nWe also have the ratio\nns(p)\ne\nns(pc) ∝\n-cs\naccompanied, as before, by the critical cluster number\nns(pc) ∝s-τ\n\n1.5.1\nThe strength P\nWe seek\nP = fraction of sites belonging to infinite cluster\n= (fraction of occupied sites) -(fraction belonging to finite clusters)\n= p -\nnss.\ns finite\nAt p = p ,\nX\nc P = 0 and therefore\nX\nns(pc)s =\nX\nns(pc)s = pc\ns finite\ns\nFor the infinite sum to converge, we require τ > 2.\nNow approximate P near pc by\nP = pc -\nX\nns(p)s +\ns\nO(p -pc),\np →pc\nThen\nP ≃\nX\n[ns(pc)\ns\n-ns(p)]s\n=\nX\ns1-τ(1 -e-cs)\ns\n≃\nZ\ns1-τ(1 -e-cs)ds\nThe passage from the summation to the integral is made possible by noting\nthat the main contribution to the sum comes for large s ∼1/c as c →0.\nWe integrate by parts, using\nR\nf ′gds = -\nfg′ds + (fg) where\nf(s) = s2-τ\nand\ng(\nR\ns) = 1 -e-cs.\nThe term fg yields\ns2-\nτ(1 -e-cs)\ninf= 0 -s2-τ[cs -(cs)2/2 + . . .]\n= 0\nby requiring (as one finds) τ < 3. The remaining integral,\n\nafter substituting\nz = cs as in Section 1.4.5, yields cτ-2 × const. Consequently\nP ∝cτ-2 = (p -pc)(τ-2)/σ\n\nand therefore\nP = (p -pc)β\nwhere we have obtained the scaling relation\nτ\nβ =\n-2\nσ\n.\nNote that the Bethe lattice solution β = 1, τ = 5/2, and σ = 1/2 is obtained\nas a special case.\n1.5.2\nThe mean cluster size S\nNear pc, we have\nS\nP\ns nss\n≃\n,\np\npc\n→pc\nConverting to an integral,\nS ∝\nZ\ns2nsds\n∝\nZ\ns2-τe-csds\n= cτ-3\nZ\nz2-τe-zdz\nThen\nS ∝cτ-3 = |p -pc|(τ-3)/σ\nand therefore\nS ∝|p -pc|-γ ,\nwhere we have obtained the critical exponent for cluster sizes,\nγ =\n-τ\nσ\n.\nWe proceed to generalize these results for the kth moment of n\nX\ns, defined by\nMk =\nskns.\ns\n\nAs above,\nMk ∝\nX\nsk-τe-cs\ns\n∝\nZ\nsk-τe-csds\n∝cτ-1-k\nZ\nzk-τe-zdz\nyielding,\nMk ∝cτ-1-k ∝|p -pc|(τ-1-k)/σ.\nThis is simply a generalization of our previous results for β (k = 1) and -γ\n(k = 2).\nThus we see that \"everything\" depends on two exponents, σ and τ (or β and\nγ).\nThese relationships, known as scaling laws, originated in the study of thermal\nphase transitions.\nThe exponents depend on the dimension d, but the relations between them\ndo not.\nImportantly, the exponents do not depend on the type of lattice (square,\ntriangular, etc.) This is known as universality.\n1.6\nFractals\nNear pc, the geometry of clusters turns out to be fractal. In this section we\ndefine fractals, and show why this special geometry emerges near the critical\npoint.\n1.6.1\nCluster radius\nClusters can have complex shapes.\nFIGURE\n\nOne way of expressing this complexity is to determine\nRs = radius of gyration of an s-cluster,\nwhich we express as\nR2\ns =\nwhere\nX\ns\ns i=1\n|ri -r0|2,\nri = position of ith site in cluster\nand\nr0 = center of mass of an s-cluster\n=\nThe\nX\ns\nri.\ns i=1\nmean-square distance between every pair of sites on the cluster is also\nrelated to Rs:\nr\ns\nX\ns\ns\n\ns\ni=1\nX\nj=1\n| i -rj|2 = 2R2\ns,\nwhere the factor of 2 comes from counting each pair twice.\n1.6.2\nCorrelation length\nDefine the correlation length\nξ = an average distance between two cluster sites.\nWhereas 2R2\ns is the mean-square distance between two sites on an s-cluster,\nξ2 is this same distance averaged over all finite sizes s.\nWe obtain that average by noting that, as already discussed,\nP(site belongs to s-cluster) = sns.\nThere are (obviously) s sites in each s-cluster. We thus weight the average\nof R2\ns by s · sns, to obtain the squared correlation length\nξ2\n2 P\ns Rss2ns\n=\nP\n.\ns s2ns\n\nIn Section 1.2 we saw how ξ diverges as p →pc when d = 1. We expect\nsimilar behavior for d > 1 and therefore write\nξ ∝|p -pc|-ν\nwhere ν is another exponent.\nGiven these definitions, we seek how Rs varies with s at p = pc. But we must\nfirst take a detour and finally define what we mean by \"fractal.\"\n1.6.3\nThe fractal dimension D\nSuppose each occupied site is assigned a unit of mass, while unoccupied sites\nhave no mass.\nIn a \"Euclidean\" or \"space-filling\" geometry, we expect that\nmass(s) ∝Rd\ns in d dimensions.\nSuppose instead that we observe\nmass ∝lengthD.\nObjects are called fractals if\nD < d and D = integer.\nNow assume\nRs ∝s1/D,\n(p = pc,\ns →inf)\nThe fractal dimension D is known exactly in d = 2 and approximately in\nd = 3:\nd = 2 :\nD = 91/48 ≃1.9\nd = 3 :\nD ≃2.5\nSince D and ν both describe the geometry of critical clusters, we expect\nthat they are related. To see how, we recall from Section 1.5.2 that the kth\nmoment of ns,\nMk =\nX\nskn\n(\ns\ns\n∝|p -pc| τ-1-k)/σ.\n\nSince Rs ∝s1/D, our expression for ξ2 above is simplified to\nM\nξ2\n2+2/D\n=\np\nM2\n∝| -pc|-2/(Dσ).\nComparing to our definition of the correlation-length exponent ν just above\nin Section 1.6.2, we immediately find\n2ν = Dσ\nor\n1 = σν.\nD\nWe have thus related the fractal dimension D to the correlation exponent ν.\n1.6.4\nScaling of the infinite cluster at p = pc\nAway from pc, we know the following about the largest cluster:\n- For p < pc, the largest cluster is finite.\n- For p > pc, the largest cluster is infinite.\nWhat happens at p = pc?\nTo answer this question, we pose the following question:\nHow does the size smax of the largest cluster vary in a finite system of size L?\n- For p < pc, we have, from Section 1.5,\nns ∝s-τe-cs,\ns →inf,\nBut the number of clusters of size smax in a system of size L is just\nnsmax ∼\ns\nLd ∝\n-τ\nmaxe-csmax.\nTaking logarithms on both sides of the proportionality and noting\nlog smax ≪smax, we have\nsmax ∝log L,\np < pc .\n\n- For p > pc, we have the obvious relation\nsmax ∝Ld,\np > pc .\n- For p = pc, we expect that the radius of gyration Rsmax scales with the\nsystem size:\nRsmax ∝L,\np = pc.\nBy the results of the previous section,\nRs ∝s1/D,\np = pc,\ns →inf.\nCombining these relations, we obtain\nsmax ∝LD,\np = pc ,\nThus the largest cluster at p = pc has fractal dimension D < d, which results\nfrom the transition from smax ∝log L just below pc to smax ∝Ld just above.\nThis result, which follows here from the scaling assumption R\ns ∝s /D of the\nprevious section, has been confirmed by extensive numerical simulation.\n1.6.5\nRelating D to d via the correlation length ξ\nThe above results correspond to p well below pc, at pc, and well above it.\nNow suppose p is near pc, with p > pc, and consider the correlation length ξ.\nWe consider two samples of different size L of a larger system.\n- If L ≪ξ, we inherit the above results for p = pc:\nsmax ∝LD.\n- If L ≫ξ, the probability P that a site belongs to the infinite (spanning)\ncluster provides\nsmax ∝PLd ∝(p -pc)βLd,\np →pc.\n\nThese two expressions should be equal when\n-ν\nL ∼ξ ∝|p -pc|\n.\nwhere the latter expression derives from our definition of the correlation ex\nponent ν (Section 1.6.2).\nSubstituting L ∼|p-pc|-ν into each equation for smax and equating the two,\nwe obtain\nβ -dν = -Dν\n⇒\nD = d -β/ν ,\nwhich relates the difference between the fractal and Euclidean dimensions to\nthe correlation exponent ν. (The various scaling relations in Section 1.5.2\ncan now be used to obtain further relations that include the dimensionality\nd.)\n1.7\nFinite-size scaling\nThe dependence of smax on the system size L and the correlation length ξ\nsuggests that there is a general way in which behavior in finite systems reflects\nthe \"true\" asymptotic scaling one finds in infinite systems.\nConsider, for example, the strength P--the probability that a site belongs\nto the spanning cluster. As we have already seen, in an infinite system P\nsharply rises from zero at p = pc:\nWhat happens, however, when L is finite?\n- When L is small, clusters formed at p < pc can span the finite system\nprovided that the correlation length ξ 2 L.\n- Larger L, however, requires larger p associated with larger ξ.\nConsequently P must depend on both p and L.\n\nWe expect that, for large systems near pc,\nP = P[(p -pc), L],\np →pc,\nL →inf\nWe seek a functional dependence on (p -pc) and L for which the tradeoff\nbetween the correlation length ξ and the system size L is evident.\nSince (p -pc) controls the correlation length, we propose the form\nP = L-AF\n\n(p -pc)LB\n,\np →pc,\nL →inf\nWe proceed to infer the form of F.\nFirst, note that as L →inffor p > pc, we obtain, for p near pc,\nP ∝(p -pc)β independent of L.\nIn other words, as L becomes large, the dependence of P on L must vanish.\nMore generally, for large z = (p -pc)LB,\nF(z) ∝zA/B,\nz →inf\nso that the dependence of P on L vanishes, yielding\nP ∝(p -pc)A/B\n⇒\nβ = A/B.\nwhere the relation to β derives from its definition in Section 1.5.1.\nAt p = pc, we have seen that\nsmax ∝LD,\np = pc.\nTherefore the probability P that a site belongs to smax scales like\ns\nP\nmax\n= L\n∝LD-d,\np = pc.\nd\nSince this result is obtained at p = pc, it must be equivalent to\nP(0) = L-AF(0)\nTherefore\nA = d -D = β/ν\n\nwhere the second equality was derived just above in Section 1.6.5.\nUsing β = A/B, we find\nB = A/β = 1/ν.\nSubstituting into our general form for finite-size scaling, we obtain\nP = L-β/νF (p -pc)L1/ν ,\nwhich expresses\nh\ni\nP as a function of L and p -pc in terms of the correlation\nlength exponent ν and the scaling relation P ∝(p -pc)β.\nTo understand this result, imagine that we measure P as a function of p -pc\nand L. Finite-size scaling says that plots of\nP/L-β/ν vs. (p -pc)L1/ν\nwill all fall on the same curve. It is thus a way of estimating β and ν.\nAs another type of practical application, consider again the problem of inva-\nsion percolation described in Section 1.1.2.\nThe mass M of the invading cluster at \"breakthrough\" in a system of size L\nscales like\nM ∝LD\nThe fraction of sites belonging to this cluster is P.\nSince the invading cluster at breakthrough corresponds to the largest cluster\nat p = pc, we have\nP = P(0) ∝L-β/ν = LD-d = L-1/2 for d = 3.\nFinally, we expose the crucial role played by the correlation length in the\nabove arguments.\nWe express finite-size scaling in terms of the correlation length ξ ∝|p -pc|-ν\nso that\nP = L-β/νF1(L/ξ).\n\nMore generally, if a quantity Q scales for large L ≫ξ like\nQ ∝|p -p\nχ\nc| ∝ξ-χ/ν,\nL ≫ξ,\nwe merely replace β with χ above so that\nQ(L, ξ) = L-χ/νq1(L/ξ)\nξ-χ/ν\nL\nχ/ν\n≫ξ\n∝\n,\nL-\nL ≪ξ\nwhere the scaling for small L ≪ξ corresponds also to scaling with respect to\nany L and p = pc, as in the example of invasion percolation.\n1.8\nRenormalization\nRenormalization is a powerful method for understanding systems that exhibit\nself-similarity.\n1.8.1\nSelf-similarity\nLet us clarify the meaning of self-similar. As we have seen above (Section\n1.7) in our discussion of finite-size scaling, the behavior of any quantity, say\nP, with respect to L depends on the size of L compared to the correlation\nlength ξ, i.e.,\nξD-d\nL ≫ξ\nP(L, ξ) ∝\nLD-d\nL ≪ξ\nThus all systems smaller than the correlation length ξ are similar to each\nother (in an average sense), in that they \"see\" only the system size L rather\nthan any intrinsic limitation ξ.\nMore compelling proof of this statement comes from numerical simulations\nof percolation at p = pc, where one finds outstanding adherence to the power\nlaw s\nD\nmax ∝L .\nAt some point, of course, small clusters become sensitive to the lattice con-\nstant or pixel size, and large clusters know that they are pushing up against\nthe correlation length ξ. So we expect that self-similarity holds for\nlattice constant ≪cluster size ≪ξ\n\n1.8.2\nReal-space renormalization\nWe discuss a particular form of renormalization, called real-space renormal-\nization.\nConsider, for example, an L × L square lattice. Replace each site on this\nlattice with a \"super-site\" of linear dimension b ≪ξ.\nSupersites contain some sort of average of the original sites. Consequently\ninformation is lost.\nFrom self-similarity, however, we expect that each supersite of bd micro-sites\nrelates to the others in a way that is similar to the statistical relations between\nthe micro-sites.\nTo implement such a procedure, we need an averaging rule to determine when\na supersite is \"occupied.\"\nOnce the averaging rule is determined, we then calculate\np′(p) = P(supersite is occupied given microsites\noccupied with probability p).\nClusters of supersites are then statistically similar to clusters of microsites\nwhen p is a fixed point of p′(p), i.e., when p = p∗such that\np′(p∗) = p∗.\nWe then identify pc = p∗as the occupancy fraction of microsites that yields\nself-similar behavior.\n1.8.3\nCalculation of the correlation-length exponent ν\nAll of this depends crucially on the correlation length ξ, which must be the\nsame in both the micro-lattice and averaged lattice, i.e.\nξ(micro-sites) = ξ′(super-sites, in micro-units)\n\nIn the original lattice, we have, near pc,\nξ = const · |p -pc|-ν.\nIn the renormalized (averaged) lattice, we must have\nξ′ = const · b · |p′ -pc|-ν.\nwhere the constants are the same and b is the averaging length.\nSince ξ = ξ′, we have\nb|p′ -pc|-ν = |p -p\nν\nc|-\nThis is the basic statement of renormalization. Taking logarithms on both\nsides, we solve for the correlation exponent ν:\nν = log\n|p′ -pc|\nlog\nlog\n|p -pc|\n\nλ\nb =\n.\nlog b\nTo understand λ, we expand p′(p) around its fixed point p∗:\np′(p) = p′[p∗+ (p -p∗)]\ndp′\n= p′(p∗) + (p -p∗)\n+\n(p\np∗)2.\ndp\n\np=p∗\nO\n-\nSince p′(p∗) = p∗= pc, we have, after dropping\n\nhigher-order terms,\ndp′\ndp\n\np=p∗≃p′ -pc = λ.\np -pc\nConsequently we see that λ gives the rate at which p′ changes with respect\nto p near pc, thus determining the stability of the fixed point p∗of the renor-\nmalization group transformation.\n1.8.4\nOne dimension\nAs a first example, consider one-dimensional percolation (Section 1.2).\nWe group the sites into cells of b sites.\n\nThese cells are \"connected\" only if each site among the b sites is occupied.\nThus\np′ = pb.\nThe fixed point p∗= 1, which we identify with the percolation threshold\npc = 1 deduced earlier.\nWe also calculate the correlation length ξ. In units of the distance between\nsupersites, we have\nξ′ = ξ/b.\nAt p = p′, ξ′ = ξ only if ξ = 0 or inf. We identify the latter with the fixed\npoint p∗= pc = 1.\nWe calculate the correlation-length exponent ν by first computing\ndp′\nλ =\n=\ndp\n\nbpb-1\np=p∗\n|p=1 = b\nwhich yields\nν = log λ = 1,\nlog b\nprecisely as we obtained earlier in Section 1.2.\n1.8.5\nTriangular lattice\nIn higher dimensions we must identify transformations p′ that provide con-\nnections. These connections connect lines in d = 2, planes in d = 3, etc.\nThere is no single way to do this, and no way yields an exact result.\nAs a rule, we say that a supersite is occupied if contains a cluster that spans\nbd sites.\nWe consider site percolation on a triangular lattice.\n\nSupersites--the big circles--are located at centers of triangles such that no\noriginal sites are shared among supersites.\nA supersite is considered occupied if occupied microsites span any of the three\nlattice directions. Thus\n'p = P (all 3 sites occupied) + P (2 neighboring sites occupied).\nNeighbors turn out to be any pair, and there are three ways of choosing pairs.\nThus\n'\np = p 3 + 3p 2(1 - p).\nGraphically, p'(p) looks like\n∗\n∗\nThe fixed points p that solve p'(p ∗) = p are\n∗\np = 0, 1/2, and 1.\n'\nThese points occur wherever p'(p) intersects the diagonal line p = p.\n∗\nIf we interpret the mapping p'(p) as a dynamical system, we find that p = 0\n∗\n∗\nand p = 1 are stable fixed points, and p = 1/2 is unstable. (Recall that\n|dp'/dp|p ∗ < 1 ⇒ stability.)\n\nIn other words, successive mappings initiated above p∗= 1/2 lead to a fully\noccupied superlattice, whereas successive mappings below p∗= 1/2 lead to a\nfully empty superlattice.\nWe thus identify pc = 1/2, in exact agreement with the known value for the\ntriangular lattice.\nThe rate at which at which perturbations from pc are unstable under the\nmapping p′(p) is given by\ndp′\nλ = dp\n\np∗= 6p -6p2|1/2 = 3\nAs in Section 1.8.4, we obtain the correlation-length exponent ν from λ:\nlog b\nν = log λ = log(31/2) = 1.355.\nlog(3/2)\nHere we have used b2 = 3 since 3 microsites contribute to 1 supersite. The\nresult ν = 1.355 compares very well to conjectures that the exact result is\nν = 4/3.\nReferences\n[1] Stauffer, D. & Aharony, A. Introduction to Percolation Theory, 2nd edi-\ntion (Taylor and Francis, London, 1992).\n[2] Feder, J. Fractals (Plenum Press, New York, 1988).\n[3] Hirsch, L. M. & Thompson, A. H. Minimum saturations and buoyancy in\nsecondary migration. AAPG Bulletin 79, 696-710 (1995).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 19",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/f6da02f74cb40f089e00d3f08d7fef50_MIT12_086F14_networks.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nOctober 20, 2014\nContents\nRandom and scale-free networks\n1.1\nFood webs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nRandom networks . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nScale-free networks . . . . . . . . . . . . . . . . . . . . . . . .\nRandom and scale-free networks\nOur study of percolation examines connectivity on a lattice.\nWe now proceed to an examination of aspects of connectivity without regard\nto a fixed underlying geometry.\nWe begin with an example from the natural world: food webs.\n1.1\nFood webs\nFood webs describe which kind of organisms eat which other kinds.\nThe simplest food web is a food chain.\nAt the base of the food chain are producers, or autotrophs.\nAt the next trophic level one finds consumers, or heterotrophs, which live off\nof primary producers.\nAt the next higher trophic level are the consumers of consumers, etc.\nWe can group organisms into trophic species, i.e. functional groups that con-\n\ntain organisms that appear to eat and be eaten by the exact same species\nwithin a food web.\nConnections between trophic species then provide a simple representation of\na food web.\nHere's an example, from the East River Valley, 120 miles southwest of Denver:\nwww.foodwebs.org∗\nThe web structure in the image is organized vertically, with node color rep-\nresenting trophic level. Red nodes represent basal species, such as plants\nand detritus, orange nodes represent intermediate species, and yellow nodes\nrepresent top species or primary predators.\nNote that this image has 4 trophic levels, with some species well connected\nand others not so much.\nIn what follows, we focus on models that predict distributions of connectivity\nto see if we can learn more.\n∗Image produced with FoodWeb3D, written by R.J. Williams and provided by the Pacific Ecoinformatics\nand Computational Ecology Lab [1].\nImage courtesy of Pacific Ecoinformatics and Computational Ecology Lab. Used with permission.\n\n1.2\nRandom networks\nReference: Newman [2].\nA perfectly plausible null hypothesis is to imagine that species represent\nnodes and predator-prey relationships represent links (edges) that are chosen\nrandomly.\nFor simplicity, we ignore the directed nature of the predator-prey link, and\nseek information only about the existence of the link.\nWe then define a random network as follows:\n- We specify n nodes (i.e., species).\n- We specify the probability p that any two nodes are connected.\nNote that for any given node, there are\nn -1 possible connections.\nSince there are n possible starting points for those n -1 connections, there\nare\nn(n -1) possible links,\nwhere the factor of 1/2 arises because we care only about the existence of the\nlink, not its direction (i.e, we don't count links twice).\nThe expected number of links l(n) in the random graph is\nl(n) = p · (number of possible links)\nn(n\n= p\n-1).\nDefine\nki = number of links to node i.\nki is called the degree of node i.\n\nThe mean number of links attached to a node is\nl(n)\n⟨k⟩= 2 n\nThe factor of 2 arises because each link is attached to 2 nodes. We thus have\n2pn(n\n⟨k⟩=\n-1) = p(n\n1)\n2n\n-\n≃pn.\n⟨k⟩is called the mean degree of the random network.\nWe seek the degree probability distribution: the probability of observing a\nnode with degree k.\nTo obtain a node with degree k, we must have k \"successful\" connections,\neach with probability p, and (n -1 -k) unsuccessful connections.\nThe number of possible combinations of such connections is given by the\nbinomial coefficient\nn -1\nk\n\n(n\n=\n-1)!\n.\n(n -1 -k)! k!\nThe probability Pk of observing k connections at a given node is then given\nby the binomial distribution\nPk =\nn -1\npk(1 -p)n-1-k.\nk\nThe binomial distribution is a bell-shaped curve. If n →infand p →0 while\n⟨k⟩= np remains constant, then the binomial distribution converges to the\nPoisson distribution\nPk = ⟨k⟩k e-⟨k⟩\n,\nk!\nthe mean and variance of which are both ⟨k⟩.\nThe random-network null-hypothesis thus makes a specific prediction: degree\ndistributions are bell-shaped, with a mean and variance of ⟨k⟩.\nReal food web data is, however, inconsistent with this prediction [3].\n\n1.3\nScale-free networks\nReference: Albert and Barab asi [4]\nWe now consider a model of a growing network. It too should be considered\na null hypothesis rather than a mechanistic model of food webs.\nThere are two ingredients:\n- Growth. We start with m0 nodes with pre-existing connections. At each\ntime step we add a new node with m ≤m0 links to pre-existing nodes.\n- Preferential attachment.\nNew links tend to attach to already well-\nattached nodes.\nSpecifically: the probability Π that a new node is\nconnected to node i is proportional to ki, the degree of the ith node:\nki\nΠ(ki) =\nsee\nP\n.\nj kj\nWe can easily\nthat after t time steps, there are\nt + m0 nodes and mt links.\nTo derive the degree distribution, we assume that ki and t are continuous.\nThen the rate at which ki changes is proportional to Π(ki):\ndki = mΠ(ki).\ndt\nThe factor of m arises by identifying the units of time with the interval\nbetween time steps and recalling that m links are added at each time step.\nWe next substitute for Π(ki):\ndki\ndt = m\nki\nSince\nP\n.\nj kj\nthere are mt links after t\nX\nunits of time, the sum\nkj(t) = 2mt,\nj\n\nwhere the factor of 2 comes from counting each link twice (both \"incoming\"\nand \"outgoing\"), and we have ignored the small correction (for large t) that\nwould arise from not counting the initial links.\nSubstituting the sum into the growth equation above, we obtain\ndki\nki\n=\ndt\n.\n2t\nSeparating variables, we have\ndki\nki\n= dt.\n2t\nIntegrating both sides, we have\nln ki(t) =\nln t + const.\n⇒\nki = Ct1/2.\nNow define\nti = time of inception of the ith node.\nThe initial condition is then ki(ti) = m, and therefore\nt\nki(t) = m\n\nti\n/2\n.\n(1)\nThe number of links attached to the ith node therefore grows like t1/2, but\nthe prefactor m/√ti depends on its time of inception.\nWe seek the continuous probability density function p(k) that a node has\ndegree k.\nTo do so, we first define the cumulative probability distribution function\nP[ki(t) < k] = probability that the ith node has fewer than k links.\nWe rewrite this expression using (1):\nt\nP[ki(t) < k] = P\n\"\nm\n\nti\n/2\n< k\n#\n(2)\n= P\n\nm2t\nti >\n.\nk2\n\n(3)\n\nNow recall that there are m0 + t nodes, and one node is added at each time\nstep.\nThus the time ti at which the ith node is added is uniformly distributed\nbetween 0 and m0 + t (assuming the same rate for the first m0 nodes).\nThe probability density function p(ti) is therefore constant over that interval.\nSince it must integrate to unity, we have\np(ti) =\n.\nm0 + t\nConsequently the RHS of (3) is\nP\n\nm2t\nti >\nm\n=\nk2\n\nZ\n0+t\np(ti)dti\nm2t/k2\n= 1 -\nZ m2t/k2\ndti\nm0 + t\nm2t\n= 1 -\n.\nk2(m0 + t)\nInserting this into (3), we obtain\nm2t\nP[ki(t) < k] = 1 -\n.\nk2(m0 + t)\nWe can now obtain p(k) by noting that\nd\np(k) =\nP[ki(t) < k]\ndk\nd\n= -dk\n\nm2t\nk2(m0 + t)\n2m2t\n\n=\nk-3,\nm0 + t\nwhich in the limit of large t becomes\np(k) ∼2m2k-3.\nThis degree distribution is distinctive for two reasons:\n\n- Unlike the bell-curve of random networks centered at ⟨k⟩, here the degree\ndistribution is one-sided, with its maximum at 0.\n- The power-law form of the distribution means that it is scale-free.\nWe say that the distribution is scale-free because its form is independent of\nscale (and therefore time).\nTo be precise, note that if we have a power-law distribution\np(x) = x-α,\nthen it is invariant, except for a prefactor, under the change of scale x →bx:\np(bx) = (bx)-α = b-αp(x).\nThe power law is the only distribution of this type [5].\nAre real food webs scale-free? The answer, it seems, is sometimes:\nDunne et al. [3]\nIn this figure, power-law degree distributions are concave upward, exponen-\ntial distributions are straight lines, and uniform distributions are concave\ndownward.\nThough hardly the rule in ecology, a great deal of other networks are appar-\nently scale free. Some examples [4]:\nCopyright (2002, 2006) National Academy of Sciences, U.S.A. Used with permission.\n\n- The World Wide Web and the internet.\n- Scientific citations and co-authorship networks.\n- Metabolic networks. (One considers the nodes to be substrates (e.g.,\nATP, H2O) and the links to represent chemical reactions.)\nThe ubiquity of such networks leads one to ask if the power-law behavior is\ntruly signficant. For an interesting perspective on this question, see Ref. [6].\nFinally, if indeed metabolism is in some way scale-invariant, might that prop-\nerty carry over to the scale of entire ecosystems and therefore biogeochemical\ncycles?\nWe don't know, but we now turn to discuss some interesting ways in which\nmetabolism expresses itself at the scale of ecosystems.\nReferences\n[1] Yoon, I. et al. Webs on the Web (WoW): 3D visualization of ecologi-\ncal networks on the WWW for collaborative research and education. In\nProceedings of the IS&T/SPIE Symposium on Electronic Imaging, Visu-\nalization and Data Analysis 5295, 124-132 (2004).\n[2] Newman, M. E. J. Neworks: An Introduction (Oxford University Press,\nOxford, U.K., 2010).\n[3] Dunne, J. A., Williams, R. J. & Martinez, N. D. Food-web structure\nand network theory: The role of connectance and size. Proceedings of the\nNational Academy of Sciences USA 99, 12917-12922 (2002).\n[4] Albert, R. & Barab asi, A.-L. Statistical mechanics of complex networks.\nReviews of Modern Physics 74, 47-97 (2002).\n[5] Newman, M. E. J.\nPower laws, Pareto distributions, and Zipf's law.\nContemporary Physics 46, 323-351 (2005).\n[6] Fox Keller, E. Revisiting \"scale-free\" networks. BioEssays 27, 1060-1068\n(2005).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 20-21",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/e713a344f2556825a778cacd95c2c732_MIT12_086F14_biocycle.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nOctober 22, 2014\nContents\nOrigin of biogeochemical cycles\n1.1\nThe carbon cycle . . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.1\nThe biological cycle . . . . . . . . . . . . . . . . . . . .\n1.1.2\nThe rock cycle . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nEnergy flow . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nTwo-reservoir model\n. . . . . . . . . . . . . . . . . . . . . . .\n1.4\nReactive species . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.1\nNo equilibrium solution . . . . . . . . . . . . . . . . . .\n1.4.2\nCycles . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5\nCycles and the breaking of detailed balance\n. . . . . . . . . .\n1.6\nSummary\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nOrigin of biogeochemical cycles\nReference: Morowitz [1]\n1.1\nThe carbon cycle\n1.1.1\nThe biological cycle\nThe carbon cycle may be viewed in various ways. In its most familiar mani-\nfestation, one has the reaction\nCO2 + H2O ⇌CH2O + O2\nPhotosynthesis goes to the right, respiration to the left. CH2O is shorthand\nfor organic carbon, i.e., a carbohydrate \"fixed\" by photosynthesis from CO2.\n\nRoughly half this reaction takes place on land, the other half at sea. But\nnearly all of the CO2 in the atmosphere and oceans is in the oceans.\nThis is the essence of the biological carbon cycle, which is nearly a closed\nsystem: about 99.9% of the carbon fixed by photosynthesis returns back to\nthe oceans and atmosphere via respiration.\n1.1.2\nThe rock cycle\nThe other 0.1% of the organic carbon which is fixed is eventually buried.\nSome (inorganic) CO2 is also buried, as carbonate. A rough picture looks\nlike this:\nphotosynthesis\nrespiration\nCO2+H2O\nCH2O+O2\natmospheric CO2\noceanic C\norganic carbon\nburial\nvolcanos\nweathering\ninorganic carbon\nburial (carbonate)\nIf CO2 in the atmosphere and oceans is not to be depleted, there must be\na source to counter the sink of burial. The source is volcanism (and related\nmetamorphic and hydrothermal processes).\nWeathering processes (i.e., erosion) provide a means, via the so-called \"Urey\nreactions,\" of extracting CO2 from the atmosphere and transporting some of\nit to the oceans. Then, assuming no other changes, it is eventually buried\nagain. This is the geochemical, or \"rock\" cycle.\nSchematically, CO2 concentrations evolve as\nd[CO2] r volcanism - (weathering + burial)\ndt\n\nIf there were no volcanic source, weathering and burial would deplete the\nCO2 in the oceans and atmosphere in about 105-106 years. So it turns out\nthat we owe our existence to mantle convection and plate tectonics!\nThe field of (bio)geochemical cycles is devoted to the study of all elemental\ncycles, not just that of carbon.\nProminent among them are the oxygen,\nnitrogen, sulfur, and phosphorous cycles. In detail they differ from the carbon\ncycle but the basic theme--cycling through organisms at fast time scales and\nrocks at slow time scales--remains the same.\nThe various cycles are not independent: they are instead coupled into a kind\nof \"supercycle,\" with prominent subcycles, like that of carbon, oxygen, and\nsulfur, identifiable within the supercycle.\n1.2\nEnergy flow\nThe existence of biogeochemical cycles such as the carbon cycle raises a nat-\nural question: Why do cycles exist?\nMorowitz proposes an answer: the flow of energy through a chemically react-\ning system requires the existence of chemical cycles, i.e.,\ncycles\nenergy sink\nenergy source\nThe cycles occur in any intermediate system. The Earth is one such exam-\nple: the energy source is (dominantly) solar radiation; the energy sink is outer\nspace.\nThe \"energy flow\" may be generalized to any flow from a higher to lower\npotential (e.g., rock movement, or chemical diffusion).\nMorowitz's theory is essentially an application of fundamental principles\nin irreversible thermodynamics as they apply to non-equilibrium stationary\nstates.\n\n1.3\nTwo-reservoir model\nWe start with a very simple model and proceed to somewhat less simple (but\nstill highly idealized) systems. Consider a gas placed in a box between two\nreservoirs, one side of which is held at temperature T1 and the other at T2:\nT1\nn1\nn2\nT2\nX\nThe gas has average number density Ψ.\nThe barrier is at the midpoint and contains pores that are small compared\nto the mean-free-path of the particles so that the residence times within the\nreservoirs are much longer than the time it takes to traverse the barrier.\nIn steady state, there is a flow of heat from the hotter to the colder side. We\nassume each side is perfectly mixed and in equilibrium with their respective\nreservoirs. Then the steady state is characterized by\nn1, n2 = number density of atoms on sides 1 and 2\nT1, T2 = temperature on sides 1 and 2\nIn steady state the mass fluxes in each direction must be equal. These fluxes\nare proportional to\n√\n(mv 2/2) 1/2 ∝\nT,\nleading to Prigogine's solution\nn1\nT1 = n2\nT2.\nAs expected, the density is inversely related to temperature. The sum of the\ndensities is constrained by mass conservation:\nn1 + n2 = 2Ψ\nWe thus have the (obvious) result that the flow of heat through the system\nresults in a concentration difference.\n\nNow imagine that the system were entirely isolated by adiabatic (insulating)\nwalls. Then the system would come to an equilibrium state characterized by\nn1 = n2.\nConsequently the non-equilibrium state is more ordered (i.e., it has lower\nentropy). The order is maintained by the flow of energy through the system.\n1.4\nReactive species\nWe now replace the perfect gas by two chemical species A and B which react\nas:\nk1(T)\nA GGGGGGGGGB\nFGGGGGGGGG B\nk2(T)\nThe system is therefore characterized by concentrations\n[A1], [B1], [A2], [B2]\nThe evolution of the system follows the kinetic equations of the form\nd[A1] = reactions B1AA1\ndt\n-reactions A1AB1\n+ flow of A2 to box 1\n-flow of A1 from box 1.\nThe flow rate through the barrier is proportional to the thermal velocity of\nthe molecules. Take the transfer rates to be\nν12 ∝\np\nT1\nflow 1 →2\nν21 ∝\np\nT2\nflow 2 →1\nThe explicit equations for [A1] and [B1] are then\nd[A1] = k2(T1)[B1]\nk1(T1)[A1] + ν21[A2]\nν12[A1]\n(1)\ndt\n-\n-\nd[B1] = -k2(T1)[B1] + k1(T1)[A1] -ν12[B1] + ν21[B2]\n(2)\ndt\nalong with similar equations for [A2] and [B2].\nWe proceed to the following points:\n\n1.4.1\nNo equilibrium solution\nIn the absence of flow, thermal equilibrium would predict\nk1(T1)[A1] = k2(T1)[B1]\nor\n[B1]\nk1(T1)\n=\n[A1]\nK\nk2(T1) ≡\n(T1)\nwhere K(T1) is the equilibrium constant of the reaction.\nA similar result must hold for box 2:\n[B2]\n[A2] = k1(T2)\nk\n) ≡K(T2)\n2(T2\nBut\n- A1 and B1 each flow from side 1 to 2 at rate ν12.\n- A2 and B2 each flow from side 2 to 1 at rate ν21.\nIf there were no thermal gradient (i.e., if T1 = T2), the steady-state ratios\n[B]/[A] would be equal on each side:\n[B1]\n[B2]\n=\n[A1]\n.\n[A2]\nBut these ratios cannot be equal in general, because T1 = T2 and, in general,\nK(T1) = K(T2).\nThus there is no thermal equilbrium, and non-equilibrium concentrations are\nexpected.\n1.4.2\nCycles\nWe now show the existence of cycles. Adding (1) and (2) in steady state, we\nobtain\nν21\n\n[A2] + [B2]\n\n= ν12\n\n[A1] + [B1]\n\nAs expected, there is\nno net flow of\n\n[A] + [B]\n\nacross the boundary.\nConsequently any flow of A must be balanced by an equal and opposite flow\nof B.\nBecause there is no thermal equilibrium, we have\nk1(T1)[A1] -k2(T1)[B1] = 0\nFrom equation (1), we have that in steady state, the quantity above must\nbalance the flow of A:\nk1(T1)[A1] -k2(T1)[B1] = ν21[A2] -ν12[A1]\nBut the RHS above must also be non-zero, requiring\nν21[A2] = ν12[A1]\nConsequently\n- There must be a finite net flow of A in one direction.\n- This flow must be balanced by an equal and opposite flow of B.\nWe therefore find a cycle. We conclude that\n- The steady state is out of equilibrium.\n- Energy flow leads to internal organization.\n- The organization includes a cyclic flow of material.\n1.5\nCycles and the breaking of detailed balance\nConsider a vat in contact with a isothermal reservoir, with the chemical\nreactions\nk1\nk3\nk5\nA GGGGGB B GGGGGB\nGG\nFGGGGG\nFGGGGG C\nGGGB\nFGGGGG A\nk2\nk4\nk6\n\nThe equilibrium concentrations satisfy\nk1[A] = k2[B]\nk3[B] = k4[C]\nk5[C] = k6[A]\nThe specific equilibrium concentrations [A], [B], [C] follow from the condition\nthat mass is conserved:\n[A] + [B] + [C] = const.\nEquilibrium follows from microscopic reversibility: each process must have\nthe same probability as the reverse process.\nThus there must be no flow (or cycle) around the system in equilibrium.\nNote, however, that we could maintain a steady state but still have a net flow\nF around the system, such that\nk1[A] -k2[B] = k3[B] -k4[C] = k5[C] -k6[A] = F.\nThis is one example of a cycle. We proceed to provide a general condition\nfor such a cycle to exist.\nConsider a (canonical ensemble of) system(s) at equilibrium. Define\nfi = Prob(system is in state i )\ntij = Prob(system in state i will change to state j in unit time)\nIn equilibrium we have detailed balance:\nfitij = fjtji\nAssume that the system is in contact with an isothermal reservoir, and irra-\ndiate the system with a constant flux of electromagnetic radiation, such that\nthere is net absorption of radiation.\nThe steady state will be characterized by a flow of heat to the reservoir:\nradiation →system →heat to reservoir.\n\nThe steady state will be characterized by new occupation numbers and tran-\nsition probabilities\nfi\n′\nand\nt′\nij.\nIf detailed balance were to hold, for every transition involving absorption of\nradiation, a reverse transition would exist in which the system would radiate\na photon.\nBut there would then be no net absorption of energy and flow of heat. Con-\nsequently detailed balance does not hold in general for the steady state:\nfi\n′t′\nij = fj\n′t′\nji\n(3)\nIn the steady state the occupation numbers are time independent. Therefore\n\"incoming\" transitions balance \"outgoing\" transitions:\ndfi\n′\n= 0 =\n)\ndt\nX\nProb(j →i\nj\n-Prob(i →j)\n!\n(4)\n=\nX\nfj\n′t′\nji\nj\n-fi\n′t′\nij\n\n(5)\nFor at least for one fi\n′, fj\n′ pair, the term above in parentheses must be non-\nzero due to the relation (3). On the other hand, the requirement that the\nsum vanish means that other terms in the sum must also be non-zero.\nWe therefore identify cycles: For at least some states i, j, the paths from i to\nj and from j to i are not equal; i.e., states leave by one path and return by\nanother.\nWe thus obtain Morowitz's cycling theorem:\nIn steady state systems, the flow of energy through the system from\na source to a sink will lead to at least one cycle in the system.\n1.6\nSummary\nThese general considerations refer to molecular organization, but we expect\nthat they should apply to ecosystems at all scales, and perhaps even the\n\nevolution of life. In summary:\n- The Earth's surface receives energy from a source (the Sun) and gives it\nup to a sink (outer space).\n- Energy flow causes a cyclic flow of matter; and a cyclic flow of matter\nrequires an energy flow.\n- Energy flow led to life and biogeochemical cycles. \"Thus the problem\nof the origin of life and the development of the global ecosystem merge\ninto one and the same problem\" (Morowitz, p. 120).\nReferences\n[1] Morowitz, H. J. Energy Flow in Biology (Ox Bow Press, Woodbridge,\nCT, 1979).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Modeling Environmental Complexity, Lecture 22-25",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-086-modeling-environmental-complexity-fall-2014/c880e0cfdce96923ff4f446796c593dd_MIT12_086F14_kinetics.pdf",
      "content": "Lecture notes for 12.086/12.586, Modeling Environmental Complexity\nD. H. Rothman, MIT\nOctober 31, 2014\nContents\nDisordered Kinetics\n1.1\nRelaxation in the carbon cycle . . . . . . . . . . . . . . . . . .\n1.2\nRelaxation rate constants\n. . . . . . . . . . . . . . . . . . . .\n1.2.1\nArrhenius kinetics . . . . . . . . . . . . . . . . . . . . .\n1.2.2\nFirst order decay . . . . . . . . . . . . . . . . . . . . .\n1.2.3\nAging\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.4\nRationalizing the aging effect\n. . . . . . . . . . . . . .\n1.3\nDisordered kinetics . . . . . . . . . . . . . . . . . . . . . . . .\n1.4\nRandom rate models . . . . . . . . . . . . . . . . . . . . . . .\n1.4.1\nPreservation of static disorder . . . . . . . . . . . . . .\n1.4.2\nContinuous superposition . . . . . . . . . . . . . . . . .\n1.5\nRandom channel model . . . . . . . . . . . . . . . . . . . . . .\n1.5.1\nFixed rates\n. . . . . . . . . . . . . . . . . . . . . . . .\n1.5.2\nFluctuating rates . . . . . . . . . . . . . . . . . . . . .\n1.5.3\nDecay function\n. . . . . . . . . . . . . . . . . . . . . .\n1.6\nRelation between random rates and random channels . . . . .\n1.7\nUniversal random rate distribution\n. . . . . . . . . . . . . . .\n1.7.1\nInverse Laplace transform\n. . . . . . . . . . . . . . . .\n1.7.2\nLognormal distribution . . . . . . . . . . . . . . . . . .\n1.7.3\nRelation to keff(t) . . . . . . . . . . . . . . . . . . . . .\n1.8\nThe elementary cycle A ⇌B\n. . . . . . . . . . . . . . . . . .\n1.8.1\nEquilibrium ratio . . . . . . . . . . . . . . . . . . . . .\n1.8.2\nTurnover time and age . . . . . . . . . . . . . . . . . .\n\nDisordered Kinetics\n1.1\nRelaxation in the carbon cycle\nRecall again the carbon cycle:\nCO2 + H2O ⇌CH2O + O2\nThe back reaction--respiration--is a process of degradation or decay.\nThat is, microbes feed on organic detritus, slowly returning it to the atmo-\nsphere as CO2.\nA good example is the fate of leaves after they fall offtrees. Another is the\ndecay of marine detritus as it falls to the bottom of the sea, and degrades in\nsediments.\nAn example of another kind of decay is the weathering or dissolution of silicate\nminerals, here represented schematically as CaSiO3:\nCaSiO3 + CO2 ⇌CaCO3 + SiO2.\nLeft-to-right, such reactions schematically represent the uptake of CO2 from\nthe atmosphere and its transformation to dissolved HCO-\n3 during weathering\nof silicate rocks, and its eventual precipitation and burial in the oceans as\ncarbonate minerals.\nWe say that processes of decay and weathering represent relaxation, in that\nsome quantity slowly diminishes, either until it vanishes or until some irre-\nducible fraction is obtained.\n1.2\nRelaxation rate constants\nWhat sets the rates of relaxation?\n\n1.2.1\nArrhenius kinetics\nClassical equilibrium chemical kinetics predicts reaction rate constants k in\nterms of activation energies Ea.\nThe activation energy is a potential barrier that is surmounted by a sufficient\nthermal fluctuation.\nDefine\nβ = kBT\nwhere T is temperature and kB is Boltzmann's constant.\nArrhenius kinetics predicts the rate constant\nk = ωe-βEa,\nwhere ω is called is the \"attempt frequency\" or \"frequency factor.\"\nIn the classical interpretation of Arrhenius kinetics, the fraction of reactant\nmolecules with a kinetic energy greater than Ea is given by the Boltzmann\nfactor exp(-βEa).\nIn this essentially phenomenological characterization, the temperature defines\nthe characteristic size of a thermal fluctuation, Ea is the energy barrier that\nmust be overcome by the fluctuation, and ω is the frequency at which the\nfluctuations lead to reaction.\n1.2.2\nFirst order decay\nConsider the reaction\nk\nAGGGGGAProducts,\nsignifying the disappearance or extinction of A with rate constant k.\nThe meaning of the rate constant k is that, in a small interval of time ∆t ≪\nk-1,\nP(an arbitrary molecule reacts) ' k∆t.\n≪\n≃\n\nThis probability applies to each molecule independently.\nThus if we have N molecules of A at time t, after a small time Δt, we have\nN(t + Δt) = N(t) - kNΔt\nand therefore\nN(t + Δt) - N(t) = -kN.\nΔt\nLetting Δt → dt, we have the first-order decay\ndN = -kN\ndt\nwith solution\nN(t) = N(0)e -kt .\n1.2.3\nAging\nIn investigations of naturally occuring chemical decays within the carbon\ncycle, it is often difficult to measure k directly. Instead one measures, say, a\nconcentration c per unit volume V such as\nc = N/V,\nor equivalently, a weight fraction, and then infers k from\nd log c\n1 dc\nk = -\n= -\n,\ndt\nc dt\nwhich is easily obtained from the slope of log c(t) on a semilog plot.\nSuch data may be obtained, e.g., from the decay of leaves, the degradation\nof organic matter in mud or sediment, or the dissolution of minerals.\nWe then meet a very interesting problem: plots of log c(t) vs t are often\nsublinear, like\n\n-\nSuch a relation is broadly consistent with the sublinear decay of log c(t).\nHowever it leaves open the interpretation of n.\nIf instead we restrict ourselves to first-order kinetics, we note that the concave\nupward appearance of log c(t) suggests a kind of effective rate constant keff\nthat decreases with time like\nd log c\nkeff(t) = -\n.\n(1)\ndt\nSuch a relation implies that the effective first-order rate constant depends on\nthe age of the material that is decaying.\nMuch data has been obtained for keff(t) [1,2]:\nCourtesy Elsevier, Inc., http://www.sciencedirect.com.\nUsed with permission.\nCourtesy Elsevier, Inc., http://www.sciencedirect.com.\nUsed with permission.\nOne way of interpreting such a plot is to suggest that the reaction kinetics\nare not first order, but instead of order n such that\ndc =\nn\nt\n-kncn,\nd\n≥1\nwhere kn is a different rate constant and the power n suggests something like\nthe need for an n-body collision for the extinction of a particular molecule.\nSeparating variables above, we obtain\nc-ndc = -kndt\n⇒\nc ∝\nt 1-n,\nn > 1,\n\nThese data are for the decay of organic matter (left) and mineral dissolution.\nBoth are roughly consistent with the power law\nk\n= 0.2 × t-1\neff\nat time scales that span orders of magnitude, from days to millions of years.\nAt least at first glance, it seems entirely remarkable that both problems\nquantitatively yield the same aging effect.\nIf we were to again assume nth-order kinetics, we would find\n1 dc\nkeff(t) =\n=\nt-1\nn\n6.\nc dt\nn\n×\n⇒\n≃\n-1\nWe know of no way to justify the ubiquity of 6th-order kinetics.\nThus we must turn to other interpretations of the aging effect.\n1.2.4\nRationalizing the aging effect\nBroadly speaking, the causes are thought to be either intrinsic or extrinsic.\nIntrinsic causes\n- Microbial degradation of organic matter. It is commonly assumed that\nsome organic compounds are metabolized slowly while others are me-\ntabolized quickly.\nIn the jargon, the fast compounds are called labile, while the others are\ncalled refractory or recalcitrant.\nIn this view, the slow decay of keff(t) is interpreted as a labile-to-refractory\ncascade.\n- Mineral dissolution. A similar rationale is invoked: due to local impu-\nrities or defects, some bits of mineral surface area dissolve faster than\nothers.\n\nExtrinsic causes\nExtrinsic causes are environmental.\nThe relevant environment is microsopic: at the scale of the typical bug's\nuniverse (which has a radius of about 10 μm), or a pore in a sedimentary\nrock (a few μm's again).\nThat is, the material undergoing decay can be somehow inaccessible:\n- Microbial degradation. Association of organic matter with high-surface\narea clay-sized minerals may afford some protection from enzymatic hy-\ndrolysis, such that the least protected organic matter degrades first.\n- Mineral dissolution. Tight pores or other effects of geometric confine-\nment may make some minerals harder to access by sufficiently unsatu-\nrated fluids, providing a mechanism for a fast-to-slow cascade.\nIt seems obvious that all these factors--intrinic and extrinsic--play some role\nin the aging effect.\nHowever it is hardly obvious why two entirely different systems--organic\nmatter decay and mineral dissolution--should behave the same way, quanti-\ntatively.\nThus we seek a more fundamental perspective.\n1.3\nDisordered kinetics\nAnother perspective views the aging process as a consequence of disordered\nkinetics [3,4].\nIn disordered kinetics, rate constants are not constant. They are instead rate\ncoefficients that may vary.\nThere are two kinds of variation: static and dynamic.\n- Static disorder. Fluctuations are \"frozen\" and last forever. The fluctu-\nations typically manifest themselves as random initial conditions. An\n-\n\nexample would be the distribution of \"lability\" discussed above.\n- Dynamic disorder. The environment changes as the reaction progresses,\nso that rate coefficients are random in time, due, e.g., to a changing\nclimate.\nOf course, any chemical system exhibits fluctuations at some microscopic\nscale due to thermal noise.\nBut in the usual thermodynamic or continuum limit, the relative mean-square\nfluctuation of, say, the numDber\nN 2\nV\nNV\nENV of molecules in a volume V scales like\n→0 as V\n⟨\n⟩2\n→inf.\n\nwhere NV = NV -⟨NV ⟩. Thus we can ignore such thermal fluctuations in\nmacroscopic systems.\nWe instead consider the qualitatively different case of relative fluctuations\nthat do not vanish with increasing system size. These are called intermittent.\nConsider again our first-order decay.\nIn the absence of any intermittent\nfluctuations, we have\nc(t)\nc = -kc\n⇒\n= e-kt.\nc(0)\nIf instead we have fluctuations, c must be integrated over all possible random\ntrajectories of k = k(t), which yields\n⟨c(t)⟩=\n\nexp\n\n-\nZ t\nk(t′)dt′\nc(0)\n\n.\nNote that\n⟨c(t)⟩= e-⟨k⟩t\nc(0)\nThis situation applies equally to dynamical disorder, where k = k(t) is some\nrandom function of time, and static disorder, where k is just a single random\nrate coeffient.\nWe conclude that ⟨c(t)⟩potentially includes rich behavior that goes well\nbeyond naive averaging of rate coefficients.\n\n1.4\nRandom rate models\nWe now specialize to the case of static disorder, but first consider the condi-\ntions under which it may be assumed.\n1.4.1\nPreservation of static disorder\nThe simplest case of static disorder is a system with two components A1 and\nA2, such that\nk1\nk2\nA1GGGGGGAP\nand\nA2GGGGGGAP\nSetting\nA1 = [A1],\nA2 = [A2],\nand\nc = A1 + A2\nwe have\nc(t) = A1(0)e-k1t + A (0)e-k2t\nIn geochemistry, such models of superposed exponential decays are called\n\"multi-G\" models [5].\nIn some situations it is more realistic to imagine that A1 and A2 interact. For\nexample,\nν\nk1\nk2\nA1 GGGGB\nFGGGG A2,\nA1GGGGGGAP,\nA2GGGGGGAP\nν\nIn terms of differential equations, we have\nA1 = -(k1 + ν)A1 + νA2\nA2 = -(k2 + ν)A2 + νA1\nAs ν →0, we recover the \"biexponential\" model above.\nWhen mixing is fast relative to the decay reactions, i.e., when ν ≫k1 and\nν ≫k2, A1 ≃A2 at long times t ≫ν-1 and the aggregate system A1 + A2\nbehaves as if there were just a single (average) rate coefficient (k1 + k2)/2:\nc(t) = c(0) exp\n\n-2(k1 + k2)t\n\n.\n\nWe conclude that non-exponential decays occur for static disorder only when\ninteractions among the decaying species are slow compared to the \"intrinsic\"\ndecay rates.\n1.4.2\nContinuous superposition\nA more general approach to static disorder without mixing follows from the\nassumption of a continuous distribution of rates.\nDefine\nck(k, t)dk = concentration of reactants with rate coefficient\nbetween k and k + dk at time t.\nAssuming first-order kinetics,\nd ck(k)dk =\nk\nt\n-kc (k)dk,\nd\nand therefore\nck(k, t)dk = ck(k, 0)e-ktdk.\nThe total concentration evolves as\ninf\nc(t) =\nZ\nck(k, t)dk\n=\nZ inf\nck(k, 0)e-ktdk.\nForming the probability density\nck(k, 0)\np(k) =\nw\nR infck(k, 0)dk\ne obtain the normalized decay\nc(t)\ninf\n=\nZ\np(k)e-ktdk.\n(2)\nc(0)\nWe call this the random rate model [6]. In geochemistry, it is called the reac-\ntive continuum model [7]. Mathematically, it represents the Laplace transform\nof p(k).\n\nNote that the probability\np(k)dk = initial fraction of material decaying at rates between k and k + dk.\nAs an example, suppose [7]\np(k) =\nkα-1e-ak,\nα > 0\nΓ(α)\nwhere Γ(·) is the gamma function and a is a parameter. Insertion into the\nrandom rate model then yields\nc(t) = (a + t)-α.\nc(0)\nThus we see, for k ≪a-1, another way of interpreting a power law decay of\nc(t): instead of inferring the order n of the kinetics from α, as in Section 1.2.3,\nwe may merely view it as deriving from a power-law decay of the random rate\ndistribution p(k).\nIt is also of interest to consider the time dependent effective relaxation rate (1):\nd log c\nkeff(t) = -\ndt\n=\nα\na + t\nComparing with the data shown in Section 1.2.3, we see good agreement at\nlong times if α ' 0.2.\n1.5\nRandom channel model\nWe now consider the problem of parallel relaxation from an entirely different\npoint of view [8].\nAssume that relaxation takes place locally, on a microscopic scale.\nRelaxation results from passage through a \"channel.\" We conceive of a chan-\nnel as a sequence of events necessary for the decay of a microscopic unit of\nmaterial.\nChannels are labeled by the index j = 1, 2, . . ., and are characterized by\nλj = relaxation rate in jth channel.\n\n1.5.1\nFixed rates\nWe divide a macroscopic body into M weakly interacting, similarly prepared,\nsubsystems labeled by the index s.\nThe subsystems differ from each other only in that they have different sets\nof open and closed channels.\nWe define the Boolean variable\n1 if the jth channel is open in subsystem s\nIjs =\n0 else.\nThe jth channel is\n- open with probability Pj; and\n- closed with probability 1 -Pj.\nDefine\nQs = set of open channels in subsystem s.\nWhen a channel is closed, it does not contribute to the relaxation. Then the\ntotal rate Ws at which a subsystem s relaxes is\nWs =\nj\nX\nλj.\n∈Qs\nRelaxation of the concentration cs(t) in subsystem s then follows\ncs(t) = exp\ncs(0)\n\nThe normalized concentration c(t) in\n-\nj\nX\nλjt\n∈Qs\n.\nthe entire macroscopic body is the av-\nerage over the M subsystems:\nc(t) =\nc\nM\nX\ns(t)\ns\n.\ncs(0)\n\nThen the relaxation c(t) of the entire macroscopic body--i.e., relaxation av-\neraged over the ensemble of subsystems--is a a sum over the subsystems:\nc(t) =\nexp\nM\nX\ns\n\n-\nj\nX\nλjt\n∈Qs\n\n.\nThe entire system therefore relaxes at a distribution of rates given by Ws.\nWe rewrite the sums in terms of the Boolean variable Ijs:\nc(t) =\nexp\nM\nX\ns\n\n-\nX\nλjIjst\nj\n!\nFor large M, the sum over s is equivalent to an ensemble average over the\nsubsystems s:\nc(t) =\n*\nexp\n\n-\nλjt\nj\n!+\ns\nSince the rates implied by the sum over j\nX\nvary from subsystem to subsystem,\nwe see that we have a discrete representation of the random rate model.\nHowever we now have access to an alternative representation.\nFirst, we convert the sum to a product:\nc(t) =\n*Y\ne-λjt\nj\n+\ns\nAssuming each channel is independent of the others, the average of the prod-\nuct is equal to a product of averages:\nc(t) =\nY\ne-λjt\nj\n\n(3)\ns\nWe next address the average over s, bringing back the index variable Ijs for\nclarity:\n\ne-λjt\n= Prob(channel j closed)\ns\n· e0 + Prob(channel j open) · e-λjt\n=\nM\nM\n\"\n-\nX\nIjs\ns\n!\n+\nX\nIjse-λjt\ns\n#\n\nUsing the definition of Pj we thus have, for large M,\n\ne-λjt\n= (1 -P\nλjt\nj) + Pje-\ns\nSubstituting this expression into equation (3), we find that the system relaxes\naccording to\nc(t) =\nY\n(1 -P ) + P\nλjt\nj\nje-\nj\n\n.\n(4)\n1.5.2\nFluctuating rates\nThe preceding interpretation assumes channels remain open or closed forever.\nWe may instead allow the channels to open and close randomly, in response\nto, say, environmental fluctuations.\nWe can then define the fluctuating variable\n0,\nchannel j closed at time t\nλj(t) =\nλj, channel j open.\nThen\nt\n\nc(t) =\n*\nexp\n\"\n-\nX Z\nλj(t′)dt′\n.\nj\n#+\nIf the probabilities per unit time of opening and closing are constant, we have\na random telegraph process [9].\nThe probability Pj then represents the fraction of time the jth channel is\nopen.\nWhen the correlation time of opening and closing of the jth channel is long\ncompared to λ-1\nj , open channels are genuinely \"active\" and we recover equa-\ntion (4) assuming independence and the new interpretation of Pj.\n\n1.5.3\nDecay function\nWe rewrite the product (4) as:\nY\n(1 -P\nλ\nj) + Pje-\njt\n= exp\n\"X\nlog\n1 -P +\nt\nj\nPje-λj\nj\nj\n#\nWe assume that Pj ≪1, corresponding in the fluctuating case\n\nto channels\nbeing almost always closed. Then\nlog\n1 -P\nλjt\nλjt\nj + Pje-\n≃-Pj(1 -e-\n).\nThe decay function (4) then becomes\n\nc(t) = exp\n\"\n-\nX\nPj(1\nj\n-e-λjt)\n#\n.\nTo simplify further, define the density of rates\nρ(λ) =\nX\nPjδ(λ -λj).\nj\nThen\nc(t) = exp\n\n-\nZ inf\nρ(λ)(1 -e-λt)dλ\n\n,\n(5)\ncalled the random channel model [6,8].\n1.6\nRelation between random rates and random channels\nAt first glance, the random rate model (2) looks entirely different from the\nrandom channel model (5).\nMoreover, p(k) and ρ(λ) differ:\n- ρ(λ)dλ is the average number of (open) channels with an individual rate\nbetween λ and λ + dλ.\n- p(k)dk is the overall probability that the total rate of relaxation is be-\ntween k and k + dk.\n\nNote also that p(k) is a normalized probability density, while ρ(λ) is an\nunnormalized number density.\nTo appreciate the difference between the two, recall from Section 1.4.2 that,\nin the context of the random rate model,\np(k) =\nkα-1e-ak\n⇒\nc(t) = (a + t)-α.\nΓ(α)\nwhere in the second relation we have suppressed the normalizing factor c(0).\nWhat ρ(λ) is associated with c(t)?\nTaking the logarithm and differentiating both sides of the random channel\nmodel, we obtain\nd log c\n-\ninf\n=\nλρ\nt\nZ\n(λ)e-λtdλ.\nd\nThe LHS is identical to our previous expression (1) for keff(t). The RHS is\nthe Laplace transform of λρ(λ). Therefore\nρ(λ) =\n(\nλL-1[kefft)].\n(6)\nFor the above example of p(k), we found keff= α/(a + t) in Section 1.4.2. In\nthat case,\nρ(λ) =\nα\n-\nλL 1\n\na + t\n\n= αe-aλ.\nλ\nWe find that p(k) and ρ(λ) are equal only if α = 1.\nWe can obtain a general relation between p(k) and ρ(λ) by noting that\nkeff(t) = -\nc\ndc\ndt =\nR inf\n0 kp(k)e-ktdk\nwhere\nR infp(k)e\n-ktdk\nwe have merely substituted the random rate model (2) for c. Substi-\ntution into (6) then yields\nρ(λ) = λ L-1\n\"R inf\n0 kp(k)e-ktdk\n#\nwhere we have taken λ conjugate to t\nR\n,\ninfp(k)e ktdk\n-\nin the inverse Laplace transform.\n\nFrom these observations we see that each model is essentially a reinterpreta-\ntion of the other.\nTo better understand the connection, we require the probability distribution\nP(N1, N2, . . .) = P(N1 channels of type 1, N2 channels of type 2, . . .),\nwhich in an appropriate limit is Poissonian [6], expressed in terms of the\naverages ⟨N1⟩, ⟨N2⟩, etc.\nIn this interpretation, each channel has a very small probability of being\nopen. By defining the total rate of relaxation\nk =\nX\nNjλj,\nj\nwe find the probability p(k)dk according to\np(k)dk =\nX X\n. . . P(N1, N2, . . .) δ\nN\nN\n-\n\nk\nX\nNjλj\nj\n!\ndk,\n(7)\nshowing that the total \"macroscopic\" rate k is a weighted average of the\n\"microscopic\" rates λj.\nNow recall that our overall goal is to evaluate the average decay function\n⟨c⟩= e-kt .\nWe now see two interpretations of the\n\naverage\n\n⟨·⟩:\n- ⟨·⟩is an average over all possible rates k randomly drawn from p(k).\n- ⟨·⟩is an average over all possible rates k randomly drawn from p(k) as\ncomputed by (7).\nThe two models are thus physically equivalent.\nThe differences are a matter of formal expression and interpretation:\n- Random channels:\nscopic contributions\n\ne-kt\nderives from fluctuations of individual micro-\nto the decay process.\n\n- Random rates:\n\ne-kt\nderives from fluctuations of the total macroscopic\ndecay rate.\nIn the context of the present discussion, the utility of each model will be\ndetermined by the extent to which it provides an understanding of the mech-\nanisms that produce the observed aging effects discussed in Section 1.2.3.\n1.7\nUniversal random rate distribution\n1.7.1\nInverse Laplace transform\nTo gain an understanding of how a particular decay process works, one would\nlike to know either the rate distribution p(k) or ρ(λ).\nFor practical purposes, p(k) is often a more sensible quantity to work with. In\nprincipal, we may obtain an estimate of it from the inverse Laplace transform\nof c:\np(k) = L-1 [c(t)] .\nThe inverse is exact, but the problem is unfortunately ill posed, meaning that\nsmall amounts of noise in c(t) can lead to large differences in p(k). Conversely,\nsignficantly different rate distributions p(k) can produce effectively the same\nc(t).\nSuch inverse problems may be solved, however, by the method of regulariza-\ntion. The idea is to narrow the space of possible solutions to those for which\np(k) is \"smooth,\" i.e., those for which\n\ndp\n\ndk\n\nis small, while simultaneously minimizing\n\nthe squared error\n||cˆ-c||2\nwhere cˆ is the decay function predicted by the smooth estimate of p(k).\nOne also wants to constrain the inverse problem so that\np(k)dk = 1.\nR\n\nThere are a variety of ways to perform such a constrained regularized inver-\nsion, but we do not discuss them here.\nInstead we note that, in a surprisingly wide range of circumstances, p(k)\nturns out to be the lognormal distribution [10]\np(k) =\nk\np\n2πσ2 exp\n-(ln k -μ)2\n,\n2σ2\n\nwhich has parameters μ and σ.\nResults for plant-matter decay throughout North America are shown here [10]:\n1.7.2\nLognormal distribution\nTo see why p(k) is often lognormal, we examine some of its properties.\nFirst, consider the new random variable\nx = ln k.\nF\no\nur p\nlots\nof\nplan\nt-ma\ntter\n\nd\ne\nc\nay v\ns ti\nme a\nnd k\ni\nn\ne\nt\nic\ns.\nFigure by MIT OpenCourseWare.\n\nThe pdf ρ(x) is given by\ndk\nρ(x) = p[k(x)]dx\n=\nex√\n(\nexp\n2πσ2\n-x -μ)2\n2σ2\n\nex\n=\n√\n2πσ2 exp\n-(x -μ)2\n2σ2\n\nWe therefore see that the random variable x = ln k has a Gaussian distribu-\ntion with mean\nμ = ⟨ln k⟩\nand variance\nσ2 = Var(ln k)\nTo see why the lognormal is ubiquitous, we consider the following model of\ndecay [11].\nSuppose that degradation of a particular organic compound (i.e., a \"micro-\nscopic\" unit) occurs only after N distinct local conditions have been satisfied.\nFor the problem of decaying organic matter, examples of such conditions\ninclude the\n- water content\n- pH\n- nutrient concentration\n- microbial community\n- oxidizing agent\n- concentration and type of organic matter, etc.\nIf any condition is not satisfied, then degradation of the compound fails to\noccur.\n\nLet pi be the probability that the ith condition in such a list is satisfied.\nAssuming that the pi's are independent, the probability P that a degradation\n\"event\" occurs in a given time is\nP = p1p2 . . . pN.\nP is the probability per unit time that an individual micro-unit vanishes,\ngiven a particular set of probabilities pi.\nAnother micro-unit may, however, be associated with a different set of pi's,\nleading, then, to a different P. Thus the distribution of P would seem to\ndepend on the particular distribution of each pi.\nHowever it does not. To see why, write\nln P = ln p1 + ln p2 + . . . + ln pN.\nSo long as the random variables ln pi are well behaved (i.e., their first and\nsecond moments exist), the central limit theorem tells us that, for N large,\nln P is Gaussian, with variance σ2 =\nX\nvar(ln pi).\ni\nIdentifying the rate constant k with the probability P per unit time of degra-\ndation, we thus find that k is lognormal.\nConsequently the universality of the lognormal rate distribution derives from\nthe central limit theorem.\nSpecifically, while additive processes produce Gaussian distributions, multi-\nplicative processes produce lognormals.\nMontroll and Shlesinger [11] distinguish the two cases with popular sayings.\nFor the additive Gaussian case:\nfoot bone 'tached to the leg bone, leg bone 'tached to the knee bone,\nknee bone 'tached to the thigh bone, thigh bone 'tached to the hip\nbone. . ...\n\nThen with some variation in the length of each type of bone in a large pop-\nulation, heights of individuals are Gaussian. An entertaining version of this\nconcept can be found by viewing this video.\nOn the other hand, lognormal distributions characterize processes whose suc-\ncessful execution follows Franklin's proverb:\nfor the want of a nail the shoe was lost, for the want of a shoe the\nhorse was lost, for the want of a horse the rider was lost. . ..\nA musical version is here.\n1.7.3\nRelation to keff(t)\nRecall that the observational data suggest an aging of the effective rate con-\nstant such that\nkeff(t) ≃0.2 × t-1.\nIn principle, we should expect that this result would follow from\nkeff(t) = -\nc\ndc\ndt =\nR inf\n0 kΛ(k; μ, σ)e-ktdk\nwhere Λ(k; μ, σ) is the lognormal pdf\nR infΛ(k; μ, σ)e ktdk\n-\nΛ(k; μ, σ) =\nk\n√\n(ln\nexp\n2πσ2\n-\nk -μ)2\n2σ2\n\nWe can estimate the required integrals when the variance σ2 is large. First,\nchange the variable of the lognormal to κ = k/eμ (i.e., express k in units of\nits median eμ):\nΛκ(κ) =\nκ\n√\n(ln\nexp\n2πσ2\n-\nκ)2\n.\n2σ2\nTaking logs on both sides,\n\n(ln κ)2\nln Λκ(κ) = -ln κ -\n2σ2\n-ln(2πσ2).\n\nWhen the second term is much smaller than the first, i.e., when\n| ln κ| ≪2σ2\nwe have\nΛκ(κ) ∝κ\n⇒\nΛ(k) ∝1\nk\nshowing that a lognormal distribution is remarkably similar to a simple power\nlaw.\nFor practical purposes we suppose that the power law holds between values\nkmin and kmax and vanishes elsewhere.\nThen our expression for keffbecomes\nkeff(t) =\nR kmax e\nkmin\n-ktdk\nNoting\nR\n.\nkmax k\nkmin\n-1e-ktdk\nthat the exponential integral\ninf\nE1(kmint) =\nZ\nk-1e-ktdk\nkmin\nwe have\nkeff(t) = t\n\ne-kmaxt -e-kmint\nE1(kmaxt) -E1(kmint)\nAt long times t\n\n≫kmax\n-1 we can neglect the terms involving kmax so that\nkeff(t) = t\ne-kmint\nE1(kmint)\n\nIf times are not so long so that t ≪k-1\nmin, the numerator is effectively unity\nand we can employ the asymptotic expansion [12]\nE1(kmint) = -γ -ln kmint\nwhere γ = 0.5772 . . . is Euler's constant. Then\nkeff(t) ∼t\n\n,\n-γ -ln kmint\n\nk-1\nmax ≪t ≪k-1\nmin.\nWe see that keff(t) is not a pure power law but instead contains a logarithmic\ncorrection.\n\nEmpirical studies [13] suggest that -7 ≲ln kmint ≲-3. Supposing an average\nvalue of -5 we then find\nkeff(t) ≃0.2 × t-1\nas found in the experimental data.\n1.8\nThe elementary cycle A ⇌B\nConsider again the carbon cycle:\nphotosynthesis\nCO2 + H2O GGGGGGGGGGGGGGGGGGGB\nFGGGGGGGGGGGGGGGGGGG CH2O + O2\nrespiration\nSimplify it by writing\nphotosynthesis\nA GGGGGGGGGGGGGGGGGGGB\nFGGGGGGGGGGGGGGGGGGG B\nrespiration\nand now take the rates as\nkA\nA GGGGGGB\nFGGGGGG B\nk\nwhere\n- A →B at a constant rate kA.\n- B →A at a random rate k.\n1.8.1\nEquilibrium ratio\nThe simplest case: B →A at a deterministic rate k = kB:\nkA\nA GGGGGGB\nFGGGGGG B\nkB\nIn terms of differential equations, we have\nA = -kAA + kBB\nB = kAA -kBB\n\nWe find the equilibrium ratio\nA\nB = kB .\nkA\nReturning to the random rate k, we set\nb(k)dk = fraction of B that reacts at a rate k between k and k + dk.\nB is the sum of its parts:\ninf\nb(k)dk = B.\nA is converted to a continuum\nZ\nof k-types of B:\nA →b(k)dk,\n0 ≤k ≤inf,\nwith specified probability\np(k)dk,\n0 ≤k ≤inf.\nA and b(k) change as\ninf\nA = -kAA +\nb(k) = k p(k)A\nZ\nkb(k)dk.\nA\n-kb(k).\nIn steady state,\nkA\nb(k) =\np(k)A.\nk\nThe equilibrium ratio\nA\nB =\nA\nInserting\nR\n.\ninfb(k)dk\nthe steady solution for b(k),\nA\nB =\n=\nkA\nR infk\n-1p(k)dk\nkA\n⟨k-1⟩\nThus A/B is determined by the first negative moment k-1\nof the pdf p(k).\nThe first negative moment of the lognormal is\n\nk-1\n=\nZ inf\nk-1Λ(k)dk = e-μ+σ /2.\n\nTherefore\nA\neμ-σ2/2\n=\nB\n.\nkA\nNote that when\nσ = 0\nand\nμ = log kB\nwe recover the case of the single deterministic rate,\nA\nB = kB .\nkA\nInteresting phenomena result from the disordered case σ > 0. To see why,\nsuppose that we had wrongly assumed that B →A at the mean rate\n⟨k⟩=\nZ inf\nkΛ(k)dk = eμ+σ /2.\nWe would then make the relative error\n(A/B)wrong\n(A/B)true\n=\n⟨k⟩\n1/ ⟨k-1⟩\n= ⟨k⟩k-1 .\nInserting the expressions for the first positiv\n\ne and\n\nnegative moments of the\nlognormal, we have\n(A/B)wrong\n=\n(A/B)true\n\neσ ,\nlognormal\nshowing that the error in the equilibrium\n\nconcentration ratio increases expo-\nnentially with σ when rates are lognormal.\n\n1.8.2\nTurnover time and age\nReference: [14]\nDefine\n- turnover time: the mean time taken by the reaction B →A.\n\n- the mean age of B: the mean time each bit of a population of B has\nspent being B.\nWe imagine that we can probe the reservoir of B and determine the time that\neach molecule has spent being B since it was \"born\" by the reaction A →B.\nAge distribution\nThe age distribution is\npa(τ)dτ = fraction of B with age between τ and τ + dτ,\nwhere\nZ inf\npa(τ)dτ = 1.\nThe mean age a is\na =\nZ inf\nτpa(τ)dτ.\nExit-time distribution\nThe exit time is the age of a bit of B when it is\ntransformed to A.\nThe exit time distribution pε(τ) is the age distribution of B when B →A:\npε(τ)dτ = P(B →A after waiting a time between τ and τ + dτ).\npε(τ) is also called the transit time, residence time, and first-passage time\ndistribution. It too integrates to unity:\nZ inf\npε(τ)dτ = 1.\nThe turnover time is the mean exit time ε, where\nZ inf\nε =\nτpε(τ)dτ.\nIn general, pε(τ) = pa(τ) and a = ε.\nConsider, e.g., human populations:\n\n- The mean exit time ε ≃70 yr.\n- The mean age a ≃30 yr.\nBiogeochemical cycles typically exhibit the opposite behavior, with differ-\nences measured in orders of magnitude.\nConsider, e.g, marine organic carbon:\n- The turnover time ε ≃14 yr.\n- The mean age a ≃5000 yr.\nSurvival function and its relation to age and exit time\nDefine the flux\nJ(τ) = mass with age ≤τ that reacts from B →A per unit time.\nAssume a steady input and output flux J0 to and from the B-state. Then\nJ0 -J(τ) = the total reactive flux with age > τ.\nDivide by J0 to obtain the dimensionless survival function\nJ(τ)\nS(τ) = 1 -\n.\nJ0\nS(τ) is an impulse response: it gives the fraction of B that survives a time\n> τ as species B.\nWe can also write it in terms of the exit time distribution:\nS(τ) =\nZ inf\npε(τ ′)dτ ′\nτ\nTake derivatives on both sides, we find the exit time distribution\ndS\npε(τ) = -\n.\ndτ\n(8)\n\nConsequently the turnover (mean exit) time is\nε = -\nZ 1\ndS\nτ\ndτ\ndτ\n= -τS(τ)j1\n0 +\nZ 1\nS(τ)dτ\nwhere we have integrated by parts. We find\nε =\nZ\nS(τ)dτ\n.\nThe mass B at any particular moment in time contains contributions that\nwere \"born\" at all past times, weighted by the fraction that remains.\nFor a steady state in which J0 is the steady \"input\" flux to B and B0 is the\nsteady mass of B, the contributions to B0 are integrated over the survival\nfunction, scaled by J0:\nB0 = J0\nZ 1\nS(τ)dτ.\nThus the turnover time is simply\nε = B0/J0 ,\nwhich could have been inferred immediately from dimensional analysis.\nIn steady state, the dimensional survival flux J0 -J(τ) must be balanced by\nB0pa(τ), the mass per unit time that passes the \"age barrier\" at t to become\njust older than t:\nJ0 -J(τ) = B0pa(τ).\nIn the analogy with human populations, this statement is akin to observing\nthat the death rate of people older than, say, 65, must be balanced in steady\nstate by the rate at which the younger population crosses the 65-year age\nbarrier.\nDividing the expression above by J0, we obtain\nS(τ) = εpa(τ).\nTherefore the age distribution\npa(τ) =\nS(τ)\nε\n.\n\nExample: single decay rate k0\nIn this case the survival function is\nS(τ) = e-k0τ.\nThe exit time distribution is\ndS\npε(τ) = -\n= k0e-k0τ\ndτ\nand the turnover time is\nε = k0\n-1.\nThe age distribution is\nS(τ)\npa(τ) =\n= k0e-k0τ.\nε\nThus a(τ) = ε(τ) ∝e-τ/ε, a very special case!\nDisordered rates\nThe mean age is\na = ε\nZ inf\nτS(τ)dτ\n= 1\ninf\nε\nZ\nτdτ\nZ inf\np(k)e-kτdk\n= ε\nZ inf\ndk p(k)\nZ inf\ndτ τe-kτ\n= 1\ninf\nε\nZ\ndk k-2p(k)\nand therefore\na = 1\nε\n\nk-2\n.\nSimilar calculations yield the turnover time:\nε = -\nZ inf\ndS\nτ\ndτ\ndτ\n=\nZ inf\nτdτ\nZ inf\nkp(k)e-kτdk\nZ0\ninf\nZ inf\n=\ndk kp(k)\ndτ τe-kτ\n=\nZ inf\ndk k-1p(k).\n\nConsequently\nε =\n\nk-1\n.\nThe lognormal case\nWhen p(k) is lognormal, computation of the first and\nsecond negative moments readily yield the turnover time\nε = e-μ+σ2/2\nand the mean age\na = e-2μ+2σ /ε = e-μ+3σ /2.\nConsequently\na = εeσ ,\nshowing that the ratio of the mean age to the turnover time grows exponen-\ntially with σ2.\nMarine organic carbon\nConsider again marine organic carbon:\n- Primary productivity is about J0 = 50 Gt/yr.\n- The oceans contains about B0 = 700 Gt organic C.\n- Thus the turnover time ε = B0/J0 ≃14 yr.\n- The mean age a ≃5000 yr.\nIf we may assume that marine respiration rates are lognormally distributed,\nthen\nσ =\np\nln(a/ε) ≃2.4.\nReferences\n[1] Middelburg, J. J. A simple rate model for organic matter decomposition\nin marine sediments. Geochimica et Cosmochimica Acta 53, 1577-1581\n(1989).\n\n[2] Fantle, M. S. & DePaolo, D. J. Ca isotopes in carbonate sediment and\npore fluid from ODP Site 807A: The Ca2+(aq)-calcite equilibrium frac-\ntionation factor and calcite recrystallization rates in Pleistocene sedi-\nments. Geochimica et Cosmochimica Acta 71, 2524-2546 (2007).\n[3] Plonka, A. Dispersive Kinetics (Kluwer, Boston, 2001).\n[4] Ross, J.\nThermodynamics and Fluctuations Far from Equilibrium\n(Springer, New York, 2008).\n[5] Berner, R. A.\nEarly Diagenesis: A Theoretical Approach (Princeton\nUniversity Press, Princeton, N. J., 1980).\n[6] Vlad, M. O., Huber, D. L. & Ross, J. Rate statistics and thermody-\nnamic analogies for relaxation processes in systems with static disorder:\nApplication to stretched exponential. J. Chem. Phys. 106, 4157-4167\n(1997).\n[7] Boudreau, B. P. & Ruddick, B. R. On a reactive continuum represen-\ntation of organic matter diagenesis. American Journal of Science 291,\n507-538 (1991).\n[8] Huber, D. L. Statistical model for stretched exponential relaxation in\nmacroscopic systems. Phys. Rev. B 31, 6070-6071 (1985).\n[9] Gardiner, C. W. Handbook of Stochastic Methods (Springer, New York,\n1985).\n[10] Forney, D. C. & Rothman, D. H. Common structure in the heterogeneity\nof plant-matter decay. Journal of The Royal Society Interface 9, 2255-\n2267 (2012).\n[11] Montroll, E. W. & Shlesinger, M. F. On 1/f noise and other distributions\nwith long tails. Proc. Natl. Acad. Sci. USA 79, 3380-3383 (1982).\n[12] Bender, C. M. & Orszag, S. A. Advanced Mathematical Methods for Sci-\nentists and Engineers (McGraw Hill Book Company, New York, 1978).\n[13] Rothman, D. H. & Forney, D. C.\nPhysical model for the decay and\npreservation of marine organic carbon. Science 316, 1325-1328 (2007).\n\n[14] Bolin, B. & Rodhe, H. A note on the concepts of age distribution and\ntransit time in natural reservoirs. Tellus 25, 58-62 (1973).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n12.086 / 12.586 Modeling Environmental Complexity\nFall 2014\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}