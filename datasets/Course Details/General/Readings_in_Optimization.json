{
  "course_name": "Readings in Optimization",
  "course_description": "In keeping with the tradition of the last twenty-some years, the Readings in Optimization seminar will focus on an advanced topic of interest to a portion of the MIT optimization community: randomized methods for deterministic optimization. In contrast to conventional optimization algorithms whose iterates are computed and analyzed deterministically, randomized methods rely on stochastic processes and random number/vector generation as part of the algorithm and/or its analysis. In the seminar, we will study some very recent papers on this topic, many by MIT faculty, as well as some older papers from the existing literature that are only now receiving attention.",
  "topics": [
    "Engineering",
    "Systems Engineering",
    "Systems Optimization",
    "Mathematics",
    "Applied Mathematics",
    "Engineering",
    "Systems Engineering",
    "Systems Optimization",
    "Mathematics",
    "Applied Mathematics"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 1 session / week, 2 hours / session\n\nCourse Overview\n\n15.099 Topic for Fall 2003: Randomized Methods for (Continuous) Deterministic Optimization\n\nIn keeping with the tradition of the last twenty-some years, the Readings in Optimization seminar will focus on an advanced topic of interest to a portion of the MIT optimization community. As has been the case for many previous versions of this seminar, we often choose a topic that is of current interest (perhaps even \"hot\") in the optimization community, or that is topical in practice. Randomized methods for deterministic optimization certainly meets the first criterion (if not the second as well).\n\nIn contrast to conventional optimization algorithms whose iterates are computed and analyzed deterministically, randomized methods rely on stochastic processes and random number/vector generation as part of the algorithm and/or its analysis. Consider the simplex method, for example. One can develop a randomized version of the simplex method by choosing incoming columns or entire bases according to some stochastic process. For more general nonlinear optimization problems, a simple randomized algorithm would be to base the search direction on a randomly chosen vector; the distribution of the vector might be iteration-dependent, of course. There are very sophisticated randomized algorithms for convex and non-convex optimization that rely on recently-developed methods for approximately generating uniformly distributed random variables on convex sets. In terms of complexity analysis, many randomized algorithms have excellent properties: they solve problems to a high accuracy in polynomial time with high probability or their expected running time is polynomial. Of course, these sorts of statements are vague until we define \"high probability\", etc. In the seminar, we will study some very recent papers on this topic, many by MIT faculty, as well as some older papers from the existing literature that are only now receiving attention.\n\nSeminar Format\n\nThe seminar will meet once a week for two hours. In each session, one or more students or a faculty member will have the responsibility to lead the discussion. Typically, each session will cover one or two papers from the literature (published or working papers). Student discussion leaders have responsibility for preparing a conference quality presentation (with overheads) and for preparing a handout of transparencies for the class. Therefore, the seminar also provides a friendly setting for developing presentation skills and practicing teaching. The seminar is intended to be an informal forum for discussion and for interaction among the student and faculty participants, and works best when everyone contributes. (Indeed, in the past the seminar has been most successful when it is \"alive\" and several individuals are adding to the discussion leader's presentation by suggesting material on the board.) Since we are collectively exploring an advanced topic, the discussion leader need not feel that he or she must have a complete grasp of everything being presented -- often coming to class with questions about a technical point leads to the most lively discussion and the greatest learning.\n\nGrades\n\nSince this is an advanced seminar, grading and distinguishing between student performance is not very important (at least to me). Students who make an honest effort to make good presentations and to contribute to the best of their ability will receive a good grade (an A).\n\nSession Coverage\n\nSince this is an informal seminar, we do not typically keep to any fixed schedule. If we find that we need more time for a paper once we are discussing it, then we will typically extend the discussion to the next session and delay subsequent sessions. Or, if someone discovers some new material that we might like to discuss, then we might add that to the agenda. The\ncalendar\nprovides an outline of the coverage for the course sessions.",
  "files": [
    {
      "category": "Resource",
      "title": "A Randomized Algorithm For LP Feasibility",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/3e9ff3c64a892f177385bb9fd1244786_ses2_dunagan.pdf",
      "content": "A\nRandomized\nAlgorithm\nF\nor\nLP\nF\neasibilit\ny\nfrom\nA\nSimple\nP\nolynomialtime\nRescaling\nAlgorithm\nfor\nSolving\nLinear\nPrograms\nb\ny\nJohn\nDunagan\nand\nSan\ntosh\nV\nempala\nPresen\nted\nb\ny\nAndrew\nMenard\nSeptem\nb\ne r\n\nThis presentation is based on: Dunagan, John, and Santosh Vempala. \"A Simple Polynomial-Time Rescaling\nAlgorithm for Solving Linear Programs.\" MIT Mathematics Department, 2003.\n\nOutline\n\nThe\nP\nerceptron\nAlgorithm\n\nCondition\nNum\nb\ne r\n\nRandomized\nRescaling\n\nThe\nRandomized\nRescaling\nAlgorithm\n\nLinear\nF\neasibilit\ny\n\nAx\n\nx\n\nCan\nb\ne\nused\nto\nsolv\ne\nLP\n\nalso\nindep\nenden\ntly\nuseful\n\nW\ne\nw\nan\nt\nsomething\nstrictly\nfeasible\nso\nw\ne\nwill\nb\ne\nlo\noking\nfor\nAx\n\nClassic\nP\nerceptron\nAlgorithm\n\nLet\nx\n\nIf\nx\ni\nsatises\nAx\n\nx\n\nquit\n\nOtherwise\nnd\nan\nunsatised\nconstrain\nt\na\nj\nx\n\nSet\nx\ni+1\n\nx\ni\n\na\nj\n\nRun\ntime\nof\nClassic\nP\nerceptron\n\nIf\nthere\nexists\na\nsolution\nthere\nm\nust\nb\ne\na\nsolution\nz\nsuc\nh\nthat\nthere\nis\na\nball\nof\nradius\n\naround\nz\n\nand\nz\nis\nthe\nclosest\np\no i n\nt\nto\nthe\norigin\nwith\nthat\nprop\nert\ny\n\nTh\nus\na\n\nj\nz\n\nConsider\nthe\ndistance\nfrom\nx\ni+1\nto\nz\na\n\njjz\n\nx\ni+1\njj\n\njjz\njj\n\nz\nx\ni\n\na\nj\njj\nj\n\njjx\ni\n\na\n\nz\n\nx\ni\n\nz\na\n\nj\n\nxa\n\nj\n\nj\n\nBut\nw\ne\nkno\nw\nxa\n\nj\n\nb\ny\nconstruction\nand\nz\na\n\nj\n\nb\ny\nconstruction\nso\n\njjz\n\nx\ni\njj\n\nTh\nus\nthe\nalgorithm\nterminates\nin\nno\nmore\nthan\nz\nsteps\nsince\nthe\nnorm\nis\nalw\na\nys\np\nositiv\ne\n\nCondition\nNum\nb\ne r s\n\nTh\nus\nwhen\nusing\nthis\nalgorithm\nthe\ndicult\ny\nis\nrelated\nto\nthe\ndistance\nfrom\nthe\norigin\nto\nthe\np\noin\nt\nz\n\nW\ne\ndene\nthe\ncondition\nn\num\nb\ne r\n\nof\nthe\nproblem\nas\n\njjz\njj\n\nTh\nus\nthe\np\nerceptron\nalgorithm\nterminates\nin\niterations\n\nWhat\nif\nw\ne\nhad\na\nw\na\ny\nof\nmo\ndifying\na\nproblem\nto\nincrease\n\nth\nus\ndecreasing\nthe\nrun\ntime\n\nIdea\n\nnd\na\np\noin\nt\nnear\nthe\nfeasible\nregion\nrescale\nso\narea\nnear\nthe\np\no i n\nt\nwhic\nh\nshould\ninclude\nfeasible\nregion\nexpands\nwhile\narea\nfar\nfrom\nthe\np\no i n\nt\ncon\ntracts\n\nRescaling\nalgorithm\n\nIdea\n\nstart\nwith\na\nrandom\nunit\nv\nector\nand\nmo\nv\ne\nit\nin\nthe\ndirection\nof\nro\nws\nof\nA\nif\nit\nstarts\nclose\nto\nfeasible\nregion\nit\nshould\nsta\ny\nclose\nto\nfeasible\nregion\n\nLet\nx\nb\ne\na\nrandom\nunit\nv\nector\n\nRep\neat\nat\nmost\nn\nlog\nn\ntimes\n\n{\nIf\nthere\nexists\na\nro\nw\n\na\nsuc\nh\nthat\n\na\n\nset\nx\ni+1\n\nx\ni\n\na\nx\ni\na\nx\ni\n\n32n\n{\nIf\nx\n\nrestart\n\nIf\nthere\nstill\nexists\na\nro\nw\na\nwith\n\na\nx\n\nrestart\n32n\n\nWhat\nthe\nhec\nk\nis\nthis\ndoing\n\nSupp\nose\nw\ne\nha\nv\ne\nthe\ncen\nter\np\no i n\nt\nz\n\nat\na\ndistance\n\nwith\na\nball\nof\nradius\n\nab\nout\nit\nin\nthe\nfeasible\ncone\n\nW\ne\nstart\nwith\na\nrandom\nv\nector\nwhic\nh\nhas\nz\nx\n\np\nn\nwith\nprobabilit\ny\n\nAs\nw\ne\nup\ndate\nx\nz\nx\ndo\nes\nnot\ndecrease\n\nx\n\nx\n\na\n\na\na\nz\n\nxz\n\nx\n\na\nz\n\nxz\n\nTherefore\nif\nw\ne\nstarted\nclose\nto\nz\n\nw\ne\nsta\ny\nclose\n\nF\nurther\nb\necause\nthis\npro\nduct\ncannot\ndecrease\nx\ncannot\nb\necome\nzero\nin\nthis\ncase\n\nBut\nthe\nmagnitude\nof\nx\nwill\ndecrease\nat\neac\nh\nstep\nso\nw\ne\nm\nust\nterminate\n\na\n\nx\n\nx\n\na\n\nx\n\na\nx\n\nx\n\n1024n\n\nSo\nafter\nthe\nsp\necied\nn\num\nb\ne r\nof\niterations\nw\ne\nha\nv\ne\na\ncon\ntradiction\nb\ne t\nw\neen\nthe\nsizes\nof\nx\nand\nxz\n\nso\nw\ne\nm\nust\nha\nv\ne\nterminated\n\nOK\nwhat\nno\nw\n\nSo\nwith\nprobabilit\ny\nat\nleast\n\nw\ne\npic\nk\ned\na\nstarting\nx\nthat\nterminates\nwith\na\ng o\no\nd\nresult\nit\nis\nno\nmore\nthan\nin\nviolation\nof\nan\ny\nconstrain\nt\nand\nit\nis\nclose\n32n\nto\nz\n\nAnd\nwith\nprobabilit\ny\nno\nmore\nthan\n\nw\ne\nha\nv\ne\na\np\no i n\nt\nthat\nterminates\nwith\nx\n\nor\ntak\nes\nto\no\nman\ny\niterations\nin\nwhic\nh\ncase\nw\ne\ntry\nagain\nor\nit\nends\nwith\na\np\no in\nt\nthat\nis\nno\nmore\nthan\nin\nviolation\nof\nan\ny\nconstrain\nt\nbut\nmigh\nt\nb\ne\nfar\nfrom\n32n\nz\n\nNo\nw\nw\ne\nrescale\nA\nour\nnew\nproblem\nis\nA\n\nAI\n\nx\nT\n\nx\n\nIn\nthe\ng o\no\nd\ncase\n\nincreases\na\nlot\n\nIn\nthe\nbad\ncase\n\ndecreases\na\nlittle\n\nResults\nof\nrescaling\n\nPrior\nto\nthe\nrescaling\nstep\nA\nhas\ncondition\nn\num\nb\ne r\n\nand\ncen\nter\nz\n\nAfter\nit\nwill\nha\nv\ne\na\nnew\ncondition\nn\num\nb\ne r\nof\nat\nleast\n\nConsider\nthe\np\noin\nt\nz\n\nz\n\nz\n\nx\nx\n\na\ni\nz\n\nThe\nradius\nof\na\nball\naround\nthis\np\no i n\nt\nin\nthe\ncone\nis\n\nmin\ni\n\njz\n\nj\n\nExpand\nthis\nand\ndo\nsome\nalgebra\n\nW\ne\nnd\nthat\nin\nthe\ng o\no\nd\ncase\n\n4n\n\nAnd\nin\nthe\nbad\ncase\n\n16n\n\nObserv\nation\n\nIf\nw\ne\ndo\nthis\nrescaling\nrep\neatedly\n\nw\ne\nexp\nect\nto\nsee\nthe\ngo\no\nd\ncase\nwith\nprobabilit\ny\nat\nleast\n\nso\nw\ne\nexp\nect\nto\nsee\n\ngro\nwing\nif\nw\ne\ndo\nthis\nrep\neatedly\n\nDetailed\nprobabilitites\n\nLet\nX\ni\n\nif\nw\ne\nha\nv\ne\nthe\ng o\no\nd\ncase\nin\niteration\ni\nand\n\notherwise\nP\ni\n\nLet\nY\ni\n\nThen\nclearly\nE\n\nY\ni\n\ni\nE\n[Y\ni\n]2\n\nAnd\nfurther\nb\ny\nthe\nCherno\nb\nound\nP\nr\nY\ni\n\nE\n\nY\ni\n\ne\n\nE\n[Y\ni\n] 2\n\ne\nn\n\nConsider\ni\n\nn\nlog\n\nand\n\nThen\ne\n\nTh\nus\nwith\nprobabilit\ny\n\ne\nn\n\nY\ni\nis\nwithin\n\nof\nits\nexp\nectation\nso\n\ni\n\niY\ni\n\nY\ni\n\n4n\n16n\n\nExpanding\nall\nof\nthis\nmess\nout\nw\ne\nget\nthat\nwith\nprobabilit\ny\n\ne\nn\n\ni\n\n4n\n\nAnd\nonce\nit\nhas\ngro\nwn\nthis\nlarge\nsolving\nthe\noriginal\nproblem\nis\neasy\n\nBringing\nit\nall\ntogether\n\nSet\nB\n\nI\n\n32n\n\nP\nerceptron\nphase\n{\nLet\nx\nb\ne\nthe\norigin\n{\nRep\neat\nat\nmost\nn\ntimes\n\nif\nthere\nexists\na\nro\nw\na\nwith\nax\n\nx\n\nx\n\na\n\nIf\nAx\n\noutput\nsolution\nB\nx\n\nImpro\nv\nemen\nt\nphase\n{\nLet\nx\nb\ne\na\nrandom\nunit\nv\nector\n{\nRep\neat\nat\nmost\nl\nn\n\nn\n\ntimes\n\nIf\nthere\nexists\na\nro\nw\na\nwith\n\nx\n\nx\n\nx\n\na\nx a\na\n\nIf\nx\n\nrestart\nimpro\nv\nemen\nt\nphase\n{\nIf\nthere\nstill\nexists\na\nro\nw\na\nwith\n\nx\n\nx\n\nx\n\na\nx a\n\nrestart\nimpro\nv\nemen\nt\na\n\nphase\n\nIf\nAx\n\noutput\nsolution\nB\nx\n\nSet\nA\n\nAI\n\nx\nT\n\nand\nB\n\nB\nI\n\nx\n\ngo\nbac\nk\nto\np\nerceptron\nphase\nx\n\nx\n\nT\n\nAnalysis\n\nW\ne\nkno\nw\nfrom\nthe\np\nerceptron\nanalysis\nthat\nif\n\nis\nsucien\ntly\nlarge\nthe\np\nerceptron\nphase\nnishes\nwith\na\nfeasible\nsolution\n\nW\ne\nkno\nw\nfrom\nthe\nprobabilit\ny\nargumen\nt\nthat\nafter\nO\nn\nlog\n\ntimes\nthrough\nthe\nimpro\nv\nemen\nt\nphase\n\nwill\nb\ne\nsucien\ntly\nlarge\nwith\nhigh\nprobabilit\ny\nprobabilit\ny\nat\nleast\n\ne\nn\n\nEac\nh\npass\nthrough\nthe\np\nerceptron\nphase\ntak\nes\nO\nn\n\niterations\neac\nh\nc\nhec\nking\nm\nconstrain\nts\neac\nh\nof\nwhic\nh\ntak\nes\nO\nn\ntime\nfor\na\ntotal\nof\nO\nn\nm\np\ne r\npass\n\nEac\nh\npass\nthrough\nthe\nimpro\nv\nemen\nt\nphase\nhas\nO\nn\nlog\nn\niterations\nagain\neac\nh\none\nc\nhec\nks\nm\nconstrain\nts\nat\nO\nn\ntime\neac\nh\nfor\na\ntotal\nof\nO\nn\nm\nlog\nn\n\nTh\nus\nthe\no\nv\nerall\nrun\ntime\nis\nO\nn\nm\nlog\nn\nlog\n\nwith\nhigh\nprobabilit\ny\nprobabilit\ny\nat\nleast\n\ne\nn\n\nThere\nis\na\npro\nof\nthat\nlog\n\nis\np\nolynomial\nin\nthe\ninputsso\nthis\nis\na\np\nolynomial\ntime\nalgorithm\nwith\nhigh\nprobabilit\ny\nprobabilit\ny\nat\nleast\n\ne\nn"
    },
    {
      "category": "Resource",
      "title": "Las Vegas Algorithms for Linear (and Integer) Programming when the Dimension is Small",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/ab28b6ba26b99307ccbf58366a61769d_ses3_clarkson.pdf",
      "content": "Las Vegas Algorithms for Linear (and Integer) Programming\nwhen the Dimension is Small\nKenneth L. Clarkson\npresented by Susan Martonosi\nSeptember 29, 2003\nThis presentation is based on: Clarkson, Kenneth L. Las Vegas Algorithms for Linear and Integer Programming When the Dimension\nis Small. Journal of the ACM 42(2), March 1995, pp. 488-499. Preliminary version in Proceedings of the 29th Annual IEEE\nSymposium on Foundations of Computer Science, 1988.\n\nOutline\n- Applications of the algorithm\n- Previous work\n- Assumptions and notation\n- Algorithm 1: \"Recurrent Algorithm\"\n- Algorithm 2: \"Iterative Algorithm\"\n- Algorithm 3: \"Mixed Algorithm\"\n- Contribution of this paper to the field\n\nApplications of the Algorithms\nAlgorithms give a bound that is \"good\" in n (number of constraints), but \"bad\" in d\n(dimension). So we require the problem to have a small dimension.\n- Chebyshev approximation: fitting a function by a rational function where both\nthe numerator and denominator have relatively small degree. The dimension is the\nsum of the degrees of the numerator and denominator.\n- Linear separability: separating two sets of points in d-dimensional space by a\nhyperplane\n- Smallest enclosing circle problem: find a circle of smallest radius that encloses\npoints in d dimensional space\n\nPrevious work\n- Megiddo: Deterministic algorithm for LP in O(22dn)\n- Clarkson; Dyer: O(3d2 n)\n- Dyer and Frieze: Randomized algo. with expected time no better than O(d3dn)\n- This paper's \"mixed\" algo.: Expected time\n√\nO(d2 n) + (log n)O(d)d/2+O(1) + O(d4\nn log n) as n →inf\n\nAssumptions\n- Minimize x1 subject to Ax ≤b\n- The polyhedron F(A, b) is non-empty and bounded and 0 ∈F(A, b)\n- The minimum we seek occurs at a unique point, which is a vertex of F(A, b)\n- If a problem is bounded and has multiple optimal solutions with optimal value\n∗\nx1, choose the one with the minimum Euclidean norm\n∗\nmin{∥x∥2|x ∈F(A, b), x1 = x1}\n- Each vertex of F(A, b) is defined by d or fewer constraints\n\nNotation\nLet:\n- H denote the set of constraints defined by A and b\n- O(S) be the optimal value of the objective function for the LP defined on S ⊆ H\n- \"Each vertex of F (A, b) is defined by d or fewer constraints\" implies that\n∃B(H) ⊂ H of size d or less such that O(B(H)) = O(H). We call this subset\nB(H) the basis of H. All other constraints in H\\B(H) are redundant.\n- a constraint h ∈ H be called extreme if O(H\\h) < O(H) (these are the\nconstraints in B(H)).\n\nAlgorithm 1: Recursive\n- Try to eliminate redundant constraints\n- Once our problem has a small number of constraints (n ≤9d2), then use Simplex\nto solve it.\n- Build up a smaller set of constraints that eventually include all of the extreme\nconstraints and a small number of redundant constraints\n√\n- Choose r = d\nn unchosen constraints of H\\S at random\n- Recursively solve the problem on the subset of constraints, R ∪S\n- Determine which remaining constraints (V ) are violated by this optimal solution\n√\n- Add V to S if it's not too big (|V | ≤2 n).\n- Otherwise, if V is too big, then pick r new constraints\nWe stop once V is empty: we've found a set S ∪R such that no other constraints\nin H are violated by its optimal solution. This optimal solution x is thus optimal\nfor the original problem.\n\nRecursive Algorithm\nInput: A set of constraints H. Output: The optimum B(H)\n1. S ←∅; Cd ←9d2\n2. If n ≤Cd return Simplex(H)\n2.1 else repeat:\n√\nchoose R ⊂H\\S at random, with |R| = r = d\nn\nx ←Recursive(R ∪S)\nV ←{h ∈H| vertex defined by x violates h}\n√\nif |V | ≤2 n then S ←S ∪V\nuntil V = ∅\n2.2 return x\n\nRecursive Algorithm: Proof Roadmap\nQuestions:\n- How do we know that S doesn't get too large before it has all extreme constraints?\n- How do we know we will find a set of violated constraints V that's not too big (i.e.\nthe loop terminates quickly)?\nRoadmap:\nLemma 1. If the set V is nonempty, then it contains a constraint of B(H).\nLemma 2. Let S ⊆ H and let R ⊆ H\\S be a random subset of size r, with |H\\S| =\nm. Let V ⊂ H be the set of constraints violated by O(R ∪ S). Then the expected size\nof V is no more than d(m-r+1) .\nr-d\nAnd we'll use this to show the following Lemma:\n\nLemma 3. The probability that any given execution of the loop body is \"successful\"\n√\n(|V | ≤2 n for this recursive version of the algorithm) is at least 1/2, and so on\naverage, two executions or less are required to obtain a successful one\nThis will leave us with a running time\n√\nT (n, d) ≤2dT (3d n, d) + O(d2 n) for n > 9d2 .\n\nRecursive Algorithm: Proof of Lemma 1\nProof. Lemma 1: When V is nonempty, it contains a constraint of B(H).\nSuppose on the contrary that V = ∅ contains no constraints of B(H).\nL\nLet a point x ⪯ y if (x1, ∥x∥2) ≤ (y1, ∥y∥2) (x is better than y).\n∗\nLet x ∗ (T ) be the optimal solution over a set of constraints T . Then x (R ∪S) satisfies\n∗\nall the constraints of B(H) (it is feasible), and thus x ∗ (R ∪ S) ⪰ x (B(H)).\n∗\n∗\nHowever, since R ∪ S ⊂ H, we know that x ∗ (R ∪ S) ⪯ x (H) = x (B(H)). Thus,\n∗\nx (R ∪ S) has the same obj. fcn value and norm as x ∗ (B(H)). By the uniqueness of\n∗\n∗\nthis point, x ∗ (R ∪ S) = x (B(H)) = x (H), and V = ∅. Contradiction!\nSo, every time V is added to S, at least one extreme constraint of H is added (so we'll\ndo this at most d times).\n\nRecursive Algorithm: Proof of Lemma 2\nProof. Lemma 2: The expected size of V is no more than d(m-r+1) .\nr-d\nFirst assume problem nondegenerate.\nLet CH = {x ∗ (T ∪ S)|T ⊆ H\\S}, subset of optima.\nLet CR = {x ∗ (T ∪ S)|T ⊆ R}\nThe call Recursive(R ∪ S) returns an element x ∗ (R ∪ S):\n- an element of CH\n- unique element of CR satisfying every constraint in R.\n\nRecursive Algorithm: Proof of Lemma 2\nChoose x ∈CH and let vx = number of constraints in H violated by x.\n\n∗\n\nE[|V |] = E[\nx∈CH vxI(x = x (R ∪ S))] =\nvxPx\nx∈CH\nwhere\n∗\n1 if x = x ∗ (R ∪ S)\nI(x = x (R ∪ S))\n=\n0 otherwise\nand Px = P (x = x ∗ (R ∪ S))\nHow to find Px?\n\nRecursive Algorithm: Proof of Lemma 2\n∗\nLet N = number of subsets of H\\S of size r s.t. x ∗ (subset) = x (R ∪S).\nm\nN\nThen N =\nPx and Px =\nm .\nr\n( r )\n∗\nTo find N , note that x ∗ (subset) ∈CH and x (subset) = x ∗ (R ∪S) only if\n∗\n- x (subset) ∈CR as well\n∗\n- x (subset) satisfies all constraints of R\n∗\nTherefore, N = No. of subsets of H\\S of size r s.t. x ∗ (subset) ∈CR and x (subset)\nsatisfies all constraints of R.\n\nRecursive Algorithm: Proof of Lemma 2\n∗\nFor some such subset of H\\S of size r and such that x ∗ (subset) = x (R ∪S), let T\n∗\nbe the minimal set of constraints such that x ∗ (subset) = x (T ∪S).\n∗\n- x (subset) ∈CR implies T ⊆R\n- nondegeneracy implies T is unique and |T | ≤d\nLet ix = |T |.\n∗\n∗\nIn order to have x ∗ (T ∪S) = x (R ∪S) (and thus x ∗ (subset) = x (R ∪S)), when\nconstructing our subset we must choose:\n- the ix constraints of T ⊆R\n- r -ix constraints from H\\S\\T \\V\n\nr-ix )\nm-r+1(m-vx-ix\n(m-vx-ix\nTherefore, N =\nm-vx-ix and Px =\n(m\n≤\nr-d\nr-ix-1 )\n(m\nr-ix\nr )\nr )\n(m-vx-ix\n\nr-ix-1 ) ≤ dm-r+1\nE[|V |] ≤ m-r+1\nx∈CH vx\n(m\nr-d\nr )\nr-d\n(where the summand is E[No. of x ∈CR violating exactly one constraint in R] ≤ d)\nFor the degenerate case, we can perturb the vector b by adding (ε, ε2, ..., εn) and\nshow that the bound on |V | holds for this perturbed problem, and that the perturbed\nproblem has at least as many violated constraints as the original degenerate problem.\n\nRecursive Algorithm: Proof of Lemma 3\nProof. Lemma 3: P(successful execution) ≥ 1/2; E[Executions til 1st success] ≤ 2.\n√\nHere, P(unsuccessful execution) = P (|V | > 2 n)\n√\n√\n2E[|V |] ≤ 2dm-r+1 = 2n-d\nn+1 (since r = d √ n) ≤ 2 n\n√\nr-d\nn-1\n√\nSo, P(unsuccessful execution)= P (|V | > 2 n) ≤ P (|V | > 2E[|V |]) ≤ 1/2, by\nthe Markov Inequality.\nP(successful execution) ≥ 1/2, and the expected number of loops until our first\nsuccessful execution is less than 2.\n\nRecursive Algorithm: Running Time\nAs long as n > 9d2 ,\n- Have at most d + 1 augmentations to S (succesful iterations), with expected 2 tries\nuntil success\n√\n√\n- With each success, S grows by at most 2 n, since |V | ≤2 n\n- After each success, we run the Recursive algorithm on a problem of size |S ∪R| ≤\n√\n√\n√\n2d\nn + d\nn = 3d\nn\n- After each recursive call, we check for violated constraints, which takes O(nd) each\nof at most d + 1 times\n√\nT (n, d) ≤2(d + 1)T (3d n, d) + O(d2 n), for n > 9d2\n\nAlgorithm 2: Iterative\n- Doesn't call itself, calls Simplex directly each time\n- Associates weight wh to each constraint which determines the probability with\nwhich it is selected\n- Each time a constraint is violated, its weight is doubled\n- Don't add V to a set S; rather reselect R (of size 9d2) over and over until it includes\nthe set B(H)\n\nAlgorithm 2: Iterative\nInput: A set of constraints H. Output: The optimum B(H)\n1. ∀h ∈H, wh ←1; Cd = 9d2\n2. If n ≤Cd, return Simplex(H)\n2.1 else repeat:\nchoose R ⊂H at random, with |R| = r = Cd\nx ←Simplex(R)\nV ←{h ∈H| vertex defined by x violates h}\nw(H)\nif w(V ) ≤2 9d-1 then for h ∈V , wh ←2wh\nuntil V = ∅\n2.2 return x\n\nIterative Algorithm: Analysis\n- Lemma 1: \"If the set V is nonempty, then it contains a constraint of B(H)\" still\nholds (proof as above with S = ∅).\n- Lemma 2: \"Let S ⊆ H and let R ⊆ H\\S be a random subset of size r, with\n|H\\S| = m. Let V ⊂ H be the set of constraints violated by O(R ∪ S). Then\nthe expected size of V is no more than d(m-r+1) \" still holds with the following\nr-d\nchanges. Consider each weight-doubling as the creation of multinodes. So \"size\" of\na set is actually its weight. So we have S = ∅, and thus |H\\S| = m = w(H).\n+1 ≤ w(H)\nThis gives us E[w(V )] ≤ d(w(H)-9d2\n9d-1\n9d2-d\n- Lemma 3: If we define a \"successful iteration\" to be w(V ) ≤ 2w(H) , then Lemma 3\n9d-1\nholds, and the probability that any given execution of the loop body is \"successful\"\nis at least 1/2, and so on average, two executions or less are required to obtain a\nsuccessful one.\n\n′\nIterative Algorithm: Running Time\nThe Iterative Algorithm runs in O(d2 n log n)+(d log n)O(d)d/2+O(1) expected time,\nas n →inf, where the constant factors do not depend on d.\nFirst start by showing expected number of loop iterations = O(d log n)\n- By Lemma 3.1, at least one extreme constraint h ∈B(H) is doubled during a\nsuccessful iteration\n- Let d′ = |B(H)|. After kd′ successful executions w(B(H)) =\n2nh ,\nh∈B(H)\nwhere nh is the number of times h entered V and thus\nh∈B(H) nh ≥ kd′\n-\nh∈B(H) wh ≥\nh∈B(H) 2k = d′2k\n- When members of V are doubled, increase in w(H) = w(V ) ≤ 9d-1 , so after kd′\nsuccessful iterations, we have\n′\n2kd\n9d\n-1)kd\n9d-1\nw(H) ≤ n(1 +\n≤ ne\n\n- V sure to be empty when w(B(H)) > w(H) (i.e. P (Choose B(H)) > 1). This\ngives us:\nk > ln(n/d′) , or kd′ = O(d log n) successful iterations = O(d log n) iterations.\nln 2- 2d\n9d-1\nWithin a loop:\n- Can select a sample R in O(n) time [Vitter '84]\n- Determining violated constraints, V , is O(dn)\n2Cd\n- Simplex algorithm takes dO(1) time per vertex, times\n⌊d/2⌋\nvertices [?]. Using\nStirling's approximation, this gives us O(d)d/2+O(1) for Simplex\nTotal running time:\nO(d log n) ∗ [O(dn) + O(d)d/2+O(1)] = O(d2 n log n) + (d log n)O(d)d/2+O(1)\n\nAlgorithm 3: Mixed\n- Follow the Recursive Algorithm, but rather than calling itself, call the Iterative\nAlgorithm instead\n√\n- Runtime of Recursive: T (n, d) ≤ 2(d + 1)T (3d n, d) + O(d2 n), for n > 9d2\n\n√\n- In place of T (3d\n(n), substitute in runtime of Iterative algorithm on 3d\nn\nconstraints\n√\n- Runtime of Mixed Algorithm: O(d2 n)+(d2 log n)O(d)d/2+O(1)+O(d4\nn log n)\n\nContributions of this paper to the field\n- Leading term in dependence on n is O(d2 n), an improvement over O(d3dn)\n- Algorithm can also be applied to integer programming (Jan's talk)\n- Algorithm was later applied as overlying algorithm to \"incremental\" algorithms\n(Jan's talk) to give a sub-exponential bound for linear programming (rather than\nusing Simplex once n ≤ 9d2, use an incremental algorithm)"
    },
    {
      "category": "Resource",
      "title": "Polytopes, their diameter, and randomized simplex",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/085bdedf922416c74a2b31a620457eb9_ses4_kalai.pdf",
      "content": "Polytopes, their diameter, and randomized simplex\nPresentation by: Dan Stratila\nOperations Research Center\nSession 4: October 6, 2003\nBased primarily on:\nGil Kalai. A subexponential randomized simplex algorithm (extended abstract).\nIn STOC. 1992. [Kal92a].\nand on:\nGil Kalai. Linear programming, the simplex algorithm and simple polytopes.\nMath. Programming (Ser. B), 1997. [Kal97].\n\nStructure of the talk\n1. Introduction to polytopes, linear programming, and the simplex method.\n2. A few facts about polytopes.\n3. Choosing the next pivot. Main result in this talk.\n4. Subexponential randomized simplex algorithms.\n5. Duality between two subexponential simplex algorithms.\n6. The Hirsch conjecture, and applying randomized simplex to it.\n7. Improving diameter results using an oracle for choosing pivots.\n\nPolytopes and polyhedra\nA polyhedron P ⊆ Rd is the intersection of finitely many halfspaces, or in matrix\nnotation P := {x ∈ Rd : Ax ≤ b}, where A ∈ Rn×d and b ∈ Rn . A polytope is a\nbounded polyhedron.\nDimension of polyhedron P is dim(P ) := dim(aff(P )), where aff(P ) is the affine\nhull of all points in P .\nA polyhedron P ∈ Rd with dim(P ) = k is often called a k-polyhedron. If\nd = k, P called full-dimensional. (Most of the time we assume full-dimensional\nd-polyhedra, not concerned much about the surrounding space.)\nAn inequality ax ≤ β, where a ∈ Rd and β ∈ R, is called valid if ax ≤ β for all\nx ∈ P .\n\nVertices, edges, ..., facets\nA face F of P is the intersection of P with a valid inequality ax ≤ β, i.e.\nF := {x ∈ P : ax = β}.\nFaces of dimension d - 1 are called facets, 1 ... edges, and 0 ... vertices. Vertices\nare points, ⇔ basic feasible solutions (algebraic), or extreme points (linear cost).\nSince 0x ≤ 0 is valid, P is a d-dimensional face of P . 0x ≤ 1 is valid too, so ∅ is\na face of P , and we define its dimension to be -1.\nSome vertices are connected by edges, so we can define a graph G =\n(V (G), E(G)), where V (G) = {v : v ∈ vert(P )} and E(G) = {(v, w) ∈\nV (G)2 : ∃ edge E of P s.t. v ∈ E, w ∈ E}.\nFor unbounded polyhedra often a inf node is introduced in V (G), and we add\ngraph arcs (v, inf) whenever v ∈ E where E is an unbounded edge of P .\n\nExample of a 3-polytope\nF\nF\nFigure 1: A 3-polytope (left) and its graph (right). Four vertices, three edges,\nand facet F are shown in corresponding colors.\n\nLinear programming and the simplex method\nA linear programming problem max{cx : Ax ≤ b} is the problem of maximizing\na linear function over a polyhedron.\n- If problem bounded (cost of feas. sol. finite), optimum can be achieved at\nsome vertex v.\nIf problem unbounded, can find edge E of P = {x ∈ Rd : Ax ≤ b} s.t. cx is\n-\nunbounded on the edge.\n- If problem bounded, vertex v is optimal ⇔ cv ≥ cw for all w adjacent to v\n(for all (v, w) ∈ E(G)).\nGeometrically, the simplex method starts at a vertex (b.f.s.) and moves from one\nvertex to another along a cost-increasing edge (pivots) until it reaches an optimal\nvertex (optimal b.f.s).\n\nVertices as intersections of facets\nAny polytope can be represented by its facets P = {x ∈ Rd : Ax ≤ b}, or by its\nvertices P = conv({v : v ∈ vert(P)}).\nIf vertices are given, then LP is trivial--just select the best one. Most of the\ntime, facets are given. Number of vert. exponential in number of facets makes\ngenerating all vertices from the facets impractical.\nRepresent a vertex v as intersection of d facets. Any vertex is situated at the\nintersection of at least d facets; any non-empty intersection of d facets yields a\nvertex.\nd\nWhen situated at a vertex v given by ∩i=1Fi, easy to find all adjacent vertices.\nRemove each facet Fi, and intersect with all other facets not in {F1, . . . , Fd}.\nExcept when...\n\nDegeneracy and simple polytopes\nWhen a vertex is at the intersection of > d facets, procedure above may leave us\nat the same vertex. Worse, sometimes need such changes before can move away\nfrom a vertex in cost-increasing direction.\nThis is (geometric) degeneracy.\nIn standard form degenerate vertices yield\ndegenerate b.f. solutions. Other \"degenerate\" b.f. solutions may appear because\nof redundant constraints.\nIf all vertices of P belong to at most d facets (⇒ exactly d), P is called simple.\nSimple polytopes correspond to non-degenerate LPs, and have many properties\n[Zie95, Kal97].\nWe restrict ourselves to simple polytopes. Ok for two reasons: 1) any LP can\nbe suitably perturbed to become non-degenerate; 2) perturbation can be made\nimplicit in the algorithms.\n\nA few facts about polytopes\nDisclaimer: results not used or related to subexponential simplex pivot rules (main\nresult in this talk).\nThe f -vector: fk(P ) :=# of k-faces of P .\nDegrees: let degc(v) w.r.t. to some objective function c be the # of neighboring\nvertices w with cw < cv.\nThe h-vector: hk,c(P ) :=# of vertices of degree k w.r.t. objective c in P .\nNote: there is always one vertex of degree d, and one of degree 0.\nProperty: hk,c(P ) = hk(P ), independent of c.\n\nhk,c(P ) = hk(P ), proof (1/2)\nProof. Count p := |{(F, v) : F is a k-face of P , v is max. on F }, in two ways.\nPick facets.\nBecause c in general position ⇒ v unique for each F , hence\np = fk(P ).\nOn the other hand, pick a vertex v, and assume degc(v) = r. Let T = {(v, w) :\ncv > cw}, by definition T = r.\n| |\nFor simple polytopes, each vertex v has d adjacent edges, and any k of them\ndefine a k-face F that includes v.\nμ\nT\n¶\nSo, # of k-facets that contain v as local maximum is\n|\nk\n| =\nμ\nr\n¶\n.\nk\n\nhk,c(P ) = hk(P ), proof (2/2)\nSumming over all v ∈ vert(P ), we obtain fk(P ) = Pd\nμ\nr\n¶\n.\nr=k hr,c(P ) k\nEquations linearly independent in hr,c. This completely determines hr,c(P ) in\nterms of fk(P ). But fk(P ) independent of c, so same true for hr(P ).\n\nThe Euler Formula and Dehn-Sommerville Relations\nr=k(-1)r-kfr(P )\n.\nWe can expess hk(P ) = Pd\nμ\nr\n¶\nk\nWe know that h0(P ) = hd(P ) = 1, hence f0(P )-f1(P )+· · ·+(-1)dfd(P ) = 1,\nd\n+ (-1)d-1fd-1(P ) = 1 -(-1) .\nor f0(P ) -f1(P ) + · · ·\nIn 3 dimensions, V -E + F = 2.\nBack to hk,c(P ), note that if degc(v) = k then deg-c(v) = d -k.\nBecause of independence of c, we obtain the Dehn-Sommerville Relations:\nhk(P ) = hd-k(P ).\n\nCyclic polytopes and the upper bound theorem\nA cyclic d-polytope with n vertices is defined by n scalars t1, . . . , tn as\nconv({(ti, t2\ni , . . . , ti\nd) : i = 1, d}). Can use other curves too.\nAll cyclic d-polytopes with n vertices have same structure, denote by C(d, n).\nThe polar C∗(d, n) := {x ∈ (Rd)∗ : xv ≤ 1, ∀v ∈ C(d, n)} is a simple polytope.\nProperty: C(d, n) has the maximum number of k-facets for any polytope with\nn vertices.\nThe polar C∗(d, n) has the maximum number of k-facets for any polytope with\nn facets (the face lattice).\nExact expression for fk-1\nelaborate,\nbut a simple one is fk-1 =\nPmin{d,k}\nμd - i¶\nhi(P). For more interesting details, see [Zie95].\ni=0\nk - i\n\nAbstract objective functions and the combinatorial structure\nAn abstract objective function assigns a value to every vertex of a simple polytope\nP, s.t. every non-empty face F of P has a unique local maximum vertex.\nAOFs are gen. of linear objective functions. Most results here apply.\nThe combinatorial structure of a polytope is all the information on facet inclusion,\ne.g. all vertices, all edges and the vertices they are composed of, all 3-facets and\ntheir composition, etc.\nLemma: Given graph G(P) of simple polytope P, connected subgraph H =\n(V (H), E(H)) with k vertices defines a k-face if and only if ∃ AOF s.t. all\nvertices in V (H) come before all vertices in V (G(P)) \\ V (H).\nProperty: The combinatorial structure of any simple polytope is determined by\nits graph.\n\nMain result in this talk--context\nIn the simplex algorithm we often make choices on which vertex to move to next.\nCriteria for choosing the next vertex are called pivot rules.\nIn the early days, \"believed\" simple rules guarantee a polynomial number of\nvertices in path. Klee and Minty [KM72] have shown exponential behaviour.\nAfter that, not known even if LP can be solved in polynomial time at all, until\n[Kha79]. But still,\n- Finding a pivot rule (deterministic or randomized) that would yield a polynomial\nnumber of vertex changes--open since simplex introduced.\nFor some f(n), exponential: f(n) ∈ Ω(kn), k > 1. Polynomial: f(n) ∈ O(nk)\nfor some fixed k ≥ 1. Subexponential f(n\nk) for any fixed k ≥ 1 and\nf(n) 6∈ Ω(kn) for any fixed k > 1.\n) 6∈ O(n\n\nMain result in this talk\nShortly before a different technique in [SW92], shorty aftewards a subexponential\nanalysis for it in [MSW96].\n- The first randomized pivot rule that yields subexponential expected path length\n(presented from [Kal92a, Kal97]).\nExpectation over internal random choices of algorithm; applicable to all LP\ninstances.\nImmediate application to diameter of polytopes and the Hirsch conjecture (more\nabout diameters and the Hirsch conjecture later).\n\nAlgorithm 1\nSimplest randomization (Dantzig, others): next vertex random with equal prob.\namong neighboring cost-increasing vertices. Hard to analyize in general; G artner,\nHenk and Ziegler show quadratic lower bounds on Klee-Minty cubes.\nReminder: P Given P = {x ∈ Rd : Ax ≤ b}, so in LP terms: d = # of variables,\nn = # of constraints. Also given c ∈ Rd .\nA1-1 (parameter r, start vertex v):\n1. Find vertices on r facets F1, F2, . . . , Fr s.t. ∀Fi, cv < max{cx : x ∈ Fi}.\n2. Choose a facet Fk at random from F1, F2, . . . , Fr with equal probability.\n3. Solve max{cx : x ∈ Fk} recursively. Let the optimum vertex be w.\n4. Finish solving the problem from w recursively.\nHow is this a simplex algorithm?\n\nA1-1: Implementation of step 1\nFor step 1, easy to find the first d facets.\nFor the rest r - d facets, let\nk := d, z := v and proceed as follows:\n1. Solve an LP from z with only the k facets recursively. Let result be z.\n2. If z feasible for original problem, optimum found, A1-1 terminates.\n3. Otherwise, first edge E on path that leaves P gives new facet F . Let z be the\npoint in E ∩ F . If r facets, stop; otherwise go to step 1.\nUp to now we are tracing a path along the vertices of the original problem.\n\nA1-1: Implementation of steps 2 and 3\nFirst, note that when solving max{cx : x ∈ Fk}, tracing a path along vertices of\nFk. This is also a path along vertices of P, since we are working with Fk in its\ndimension.\nIf k = r or k = r - 1, then last vertex ∈ Fk, can continue our path in step 3.\nBut if k < r - 1, then backtracking from the last vertex found when discovered.\nNot \"honest\" simplex.\nEasy to fix. Since facet Fk is chosen uniformly among facets F1, . . . , Fr, this\ncan be done by choosing uniformly among Fi1, . . . , Fir , where i1, . . . , ir order in\nwhich facets encountered by step 1.\nSo, generate random k before step 1, and stop once reached k-th facet (Kalai\nalso offers another workaround).\n\nA1-1: Implementation of step 4\nA facet F is active w.r.t. a vertex v if ∃w ∈ vert(F) s.t. cw > cv.\nApply algorithm recursively from w using only those facets which are active. At\nmost n - 1 such facets (Fk from step 3 cannot be active).\nComplexity analysis\nLet f1(P, c) := E[# of pivots when solving max{cx : x ∈ P} by A1]. Let\nf1(d, n) := max\n(c)\nf1({x ∈ Rd : Ax ≤ b}, c) : A ∈ Rn×d, c ∈ Rd, b ∈ Rna\n.\nFirst part of analysis: probabilistic reasoning to obtain a recurrence relation on\nf1(d, n).\nSecond part: solving the recurrence (using generating functions).\n\nA1-1: Analysis of step 1\nIt takes f1(d, i) to solve an LP in d variables with i facets using A1-1. So step 1\ntakes at most Pr\ni=1 f1(d, i).\nIn step 2, note that there is at least one vertex in the path for each random\nnumber generated.\nIn step 3, the expected complexity is f1(d - 1, n - 1).\nAfter step 3, we only need to consider the active facets w.r.t. w. How many?\nAssume facets F1, . . . , Fr are ordered according to their top vertex. Then selecting\nfacet i ⇒ at most n - i - 1 active facets w.r.t. w.\nSo with probability 1 we will have n - i - 1 active facets, for i = 1, 2, . . . , r.\nr\nRec.: f1(d, n) = 2 Pr\nf1(d, i)+f1(d- 1, n- 1)+ 1 Pn-1\nPl\nf1(d, n- i).\ni=d\nr\nn-r-1\ni=d\n\n(The real) Algorithm 1\nBefore analyzing the recurrence, we improve A1-1.\nA1 (parameter c > 2, start vertex v):\n1. Starting from v, find vertices on r active facets F1, F2, . . . , Fr.\n2. Choose a facet Fk at random from F1, F2, . . . , Fr with equal probability.\n3. Solve max{cx : x ∈ Fk} recursively. Let the optimum vertex be w.\n4. Let l := |{F : F active w.r.t.\nIf l > (1 - c)n then let v := w and go to\nw}|.\nstep 1; otherwise, finish solving recursively from w.\nLet r := max\n(c)n\n2 , d\na\n. What is probability of not returning to step 1? If r = n\neasily geometric with ratio = P( no return) = P(l < (1 - c)n) = 1 - c.\nIn general, analysis more complicated.\n\n¶\nA1: the recurrence\nr\nX\nr\nX\nf1(d, n) ≤\nf1(d, i) +\nf (d - 1, n - 1) +\nf1(d, n - i)i.\n1 - c\n1 - c\n(1 - c)n\ni=d\ni=bcnc\n(1)\nμ\nd + logb n\nTaking b = 1-c, we get a bound of f1(d, n) ≤ bd(6n)logb n\nlogb n\n.\nTaking c = 1 -\n, we obtain\n√\nd\nf1(d, n) ≤ n 16\n√\nd .\n(2)\n\nAlgorithm 2\nDelete step 4, repeat steps 1-3 until step 1 detects an optimal vertex. Equivalent\nto setting c := 1 in 1.\nA2 (start vertex v):\n1. Starting from v, find vertices on r active facets F1, F2, . . . , Fr. If unable to\nfind r distinct active facets ⇒ opt. vertex found.\n2. Choose a facet Fk at random from F1, F2, . . . , Fr with equal probability.\n3. Solve max{cx : x ∈ Fk} recursively. Let the optimum vertex be w.\n4. Delete inactive facets, set v := w, and go to step 1.\nRecurrence is:\nf2(d, n) ≤ f2(d - 1, n - 1) +\nn/2\nX\ng(d, i) + 2\nn/2\nX\nn\ni=d\ni=1\ng(d, n - i).\n(3)\n\nA2: the bounds\nd\nlog d\nBy solving the recurrences, we get f2(d, Kd) ≤ 2C\n√\nKd , and f2(d, n) ≤ n\nC\nq\n.\nWhen co-dimension (m := n - d) is small the following bound is very useful:\n2C√m log d .\nNext: the interesting A3.\n\nAlgorithm 3\nA3 (start vertex v):\n1. From d facets containing v, select a facet F0 at random, with equal probability.\n2. Apply A3 to F0 recursively, and let w be the optimum.\n3. Set v := w and go to step 1.\nSimple! This algorithm is the dual of the algorithm discovered by Sharir and\nWelzl [SW92] (more about this later).\nFor now, note that in a simple polytope, there can be at most 1 non-active facet\nadjacent to any vertex v, unless v is optimal.\n\nA3: the recursion\nFirst, if all facets active, with probability d the chosen facet yields n - i active\nfacets at step 3, for i = 1, . . . , d.\nSecond, if one facet inactive, with probability d-1 the chosen facet yields n - i\nfacets at step 3, for i = 1, . . . , d - 1.\nSecond alternative is worse, so we factor it in and obtain recursion f3(d, n) ≤\nf(d - 1, n - 1) + 1 Pd-1 f(d, n - i).\ni=1\nd-1\nThis yields bound f3(d, n) ≤ eC√n log d . A4, which we do not present now, gives\neC√d log n, better, like A2.\n\nSubexponential behaviour\n5·108\n1·109\n1.5·109\n2·109\nFigure 2: Asymptotic behaviour of the exponential 2d , the polynomial d3 and the\nsubexponential 2\n√\nd .\n\nThe duality of A4 and the Sharir-Welzl algorithm\nFollowing [Gol95], we show what the Sharir-Welzl algorithm (Algorithm B)\n[MSW96] does to the polytope of the dual LP. Reminder: algorithm B was called\nBasisLP in the second part of Session 3.\nUnlike before, we'll use lots of traditional LP terminology. Let H be a set of\nconstraints, and B a set of constraints that define a basis.\nB (set of constraints H, basis C with C ⊆H):\n1. Begin at C.\n2. Choose random constraint h ∈H \\ C\n3. Solve LP recursively with constraints H \\ {h}, from C. Let result be B.\n4. If B violates h, then form new basis C0 := basis(B, h); otherwise optimum\nfound.\n5. Let C := C0 and go to step 1.\n\nThe dual problems\nPrimal (we run B on this problem):\nmax{cx : Ax ≤ b}.\n(4)\nDual (we see what B does to this problem):\nmin{yb : y ≥ 0, yA = c}.\n(5)\nWe will imagine the dual problem in the yA = c space, so only the inequality\nconstraints y ≥ 0 define facets; yA = c is simply an affine transformation of the\nspace.\n\nThe correspondence, up to step 3\nC := initial feasible basis ! C := initial feasible vertex. (Not true.)\nChoosing random h ∈ H \\ C ! choosing random facet yh ≥ 0 that contains C:\n- We know, by complementary slackness, that un-tight constraints in the primal\ncorrespond to 0-level variable components in the dual.\nOnly the yi ≥ 0 constraints define facets in the dual polytope.\n-\nActive constraint at a vertex C defines a facet that constains C.\n-\nSolve recursively the LP with constrains H \\h starting from C ! solve recursively\nLP on facet yh = 0 starting from C.\nIf we remove a constraint in the primal, this is the same as requiring yh = 0\n-\nin the dual.\n\nThe correspondence, step 4\nIn both cases we obtain a new basis (! vertex) B.\nIf B violates h ! B not optimal: infeasible primal solutions correspond to\nsuboptimal dual solutions.\nC0 := basis(B, h) is a pivot operation ! C0 := move away along an unique edge\nfrom yh = 0. But, there is no \"move along an edge\" in A3!\nSlight adjustment to A3, in order to achieve perfect duality: in step 1, pick a\nrandom facet among d active facets.\nAfter we found optimum w on facet F0, this facet is not active (since w optimum\non it). Moreover, this facet is defined by d - 1 of the edges at w (in a simple\npolytope, every d - 1 edges at a vertex define a facet, and conversely).\n\nThe correspondence, steps 4 and 5\nHence only one remaining edge can be cost-improving ⇒ any simplex algorithm\nwill take it. So, our algorithm takes it when it tries to find the d-th facet.\nBut this implies that the choice of d facets available to A3 is exactly the same as\nthe choice of d facets available after moving along the unique edge.\nIn steps 5 and 1 this yields the same choice of un-tight constraints in the primal!\nSo, a variant of the Sharir-Welzl algorithm B when followed on the dual polytope\nis exactly the same as the (slightly modified) Kalai algorithm A3.\n\nThe Hirsch conjecture\nThe diameter δ(G(P )) of a polytope is the diameter of its graph, i.e. the longest\nshortest path between any pair (v, w) of vertices. Denote by δ( ~G(P )) the longest\nshortest path in the cost-function directed graph of P .\nLet Δ(d, n) := max{δ(G(P )) : P is a d-polytope with n facets }. Let H(d, n) :=\nmax{δ(G(P )) : P is a d-polytope with n facets, c is any cost function }.\nClearly, the simplex algorithm cannot guarantee a better performance on P than\nδ(G(P )). Moreover, Δ(d, n) ≤ H(d, n).\nConjecture (Hirsch, [Dan63]): Δ(P ) ≤ n - d.\nFalse for unbounded polyhedra [KW67]. Lower bound of Δ(d, n) ≥ n- d+ bd/5c.\nStill best lower bound!\n\nStatus of Hirsch conjecture for polytopes\nStill open!\nExponential bound Δ(d, n) ≤ n2d-3 [Larman, 1970].\nUntil recently (w.r.t. 1992) no sub-exponential bound known.\nBounds of n2 log d+3 and nlog d+1 in [Kal92b, KK92] respectively.\nHow randomized pivot rules affect the Hirsch conjecture? A randomized simplex\nalgorithm gives only hope that a deterministic algorithm with the same complexity\nmay be devised.\nBut, because E[...] is over choices, at least one of these choices (even if we don't\nknow it), yields a path of length less that E[...].\n\nA friendly oracle\nSo all our bounds on the number of simplex pivots, immediately apply to H(d, n)\n(since simplex takes only monotone paths) and hence to Δ(d, n).\nIn algorithms A1-A4 we spend at most O(d2n) for each pivot, and generate at\nmost 1 random number per pivot.\nWhat if we allow much more time per pivot? Result will still apply to the Hirsch\nconjecture. Do not want algorithms such as \"construct the graph, find the\nshortest path, then parse it\", since analysis is equivalent to Hirsch conjecture.\nBut, can still make use of a more powerful oracle that makes choices at each\npivot step. Works from within Algorithm 4.\n\nAlgorithm 4\nA4 (start vertex v):\n1. From the active facets w.r.t v, select a facet F0 at random, with equal\nprobability.\n2. Find vertices recursively until reached F0, or until optimum found.\n3. Solve recursively on F0. Let result be v.\n4. Go to step 1.\nAs mentioned, bound of eC√d log n .\nNow instead of selecting F0 at random, order all facets in increasing order\nF1, . . . , Fn of max{cx : x ∈ Fi}. Select F0 s.t. max{x : x ∈ F0} above the\nmedian (i > bn/2c in the ordering).\nLet f4(d, n) be the number of steps using the oracle.\n\nA4: the recursion\nAt most f4(d, n/2) pivots for step 2. Pivots from step 4 (counting everything\nthat happens) is again f4(d, n/2). Clearly, step 3 takes f4(d - 1, n - 1). Hence:\nf4(d, n) ≤ 2f4(d, bn/2c) + f4(d - 1, n - 1) + 1.\n(6)\nTo solve this, let φ(d, t) := 2tf4(d, 2t). Then, from (6), we obtain φ(d, t) ≤\nφ(d - 1, t) + φ(d, t - 1).\nBy simple combinatorial reasoning (counting all paths to the bottom), this yields\nμ\nd + t\n¶\nμ\nlog n + d\n¶\nφ(d, t) ≤\n. So f4(d, n) ≤ n\nd\nlog n\n.\nμa + b¶\nFinally, by combinatorics\na\n≤ ab (or ba), we obtain f4(d, n) ≤ nlog d+1 .\n\nHow smart the oracle?\nNot too smart:\n1. Solve max{cx : x ∈ Fi} for each facet Fi using some polynomial LP algorithm.\n2. Rank all values.\nOnly needs to be done once per instance. Hence bound nlog d+1 can be achieved\nby a polynomial-pivot-time deterministic simplex algorithm!\nNot combinatorial; overkill.\n\nReferences\n[Dan63]\nGeorge B. Dantzig. Linear programming and extensions. Princeton University Press, Princeton, N.J.,\n1963.\n[Gol95]\nMichael Goldwasser. A survey of linear programming in randomized subexponential time. ACM SIGACT\nNews, 26(2):96-104, 1995.\n[Kal92a]\nGil Kalai. A subexponential randomized simplex algorithm (extended abstract). In Proceedings of the\ntwenty-fourth annual ACM symposium on Theory of computing, pages 475-482. ACM Press, 1992.\n[Kal92b]\nGil Kalai. Upper bounds for the diameter and height of graphs of convex polyhedra. Discrete Comput.\nGeom., 8(4):363-372, 1992.\n[Kal97]\nGil Kalai. Linear programming, the simplex algorithm and simple polytopes. Math. Programming, 79(1-3,\nSer. B):217-233, 1997.\n[Kha79]\nL. G. Khachiyan. A polynomial algorithm in linear programming. Dokl. Akad. Nauk SSSR, 244(5):1093-\n1096, 1979.\n[KK92]\nGil Kalai and Daniel J. Kleitman. A quasi-polynomial bound for the diameter of graphs of polyhedra.\nBull. Amer. Math. Soc. (N.S.), 26(2):315-316, 1992.\n[KM72]\nVictor Klee and George J. Minty. How good is the simplex algorithm? In Inequalities, III (Proc. Third\nSympos., Univ. California, Los Angeles, Calif., 1969; dedicated to the memory of Theodore S. Motzkin),\npages 159-175. Academic Press, New York, 1972.\n[KW67]\nVictor Klee and David W. Walkup. The d-step conjecture for polyhedra of dimension d < 6. Acta Math.,\n117:53-78, 1967.\n\n[MSW96] J. Matouˇsek, M. Sharir, and E. Welzl. A subexponential bound for linear programming. Algorithmica,\n16(4-5):498-516, 1996.\n[SW92]\nMicha Sharir and Emo Welzl. A combinatorial bound for linear programming and related problems. In\nSTACS 92 (Cachan, 1992), volume 577 of Lecture Notes in Comput. Sci., pages 569-579. Springer, Berlin,\n1992.\n[Zie95]\nG unter M. Ziegler. Lectures on polytopes, volume 152 of Graduate Texts in Mathematics. Springer-Verlag,\nNew York, 1995."
    },
    {
      "category": "Resource",
      "title": "Pure Adaptive Search in Global Optimization",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/0292134a68638bc07fcf576635255ae7_ses6_zabinsky1.pdf",
      "content": "Pure Adaptive Search in Global Optimization\nby\nZ. B. Zabinsky and R. L. Smith\nPresented by Michael Yee\nNovember 3, 2003\nOutline\n- Pure Random Search versus Pure Adaptive Search\n- Relationship to Solis and Wetz (1981)\n- Distribution of improvement in objective function value\n- Performance bounds\nPure Adaptive Search\n[1]\nGlobal Optimization Problem\n- Problem (P):\nmin\nx∈S f(x)\nwhere x ∈Rn, S is convex, compact subset of Rn, and f continuous over S\n- f satisfies Lipschitz condition, i.e., |f(x) -f(y)| ≤kf∥x -y∥, ∀x, y ∈S\n- x∗= arg minx∈S f(x)\n- y∗= f(x∗) = minx∈S f(x)\n- y∗= maxx∈S f(x)\nPure Adaptive Search\n[2]\nPure Random Search (PRS)\n- Generate sequence of independent, uniformly distributed points\nX1, X2, . . . ,\nin the feasible region S. Denote their associated objective function values by\nY1 = f(X1), Y2 = f(X2), . . .\n- When stopping criterion met, best point generated so far is taken as\napproximation to true optimal solution\nPure Adaptive Search\n[3]\nThis presentation is based on: Zabinsky, Zelda B., and Robert L. Smith. Pure Adaptive Search\nin Global Optimization. Mathematical Programming 55, 1992, pp. 323-338.\n\nPure Adaptive Search (PAS)\nStep 0. Set k = 0, and S0 = S\nStep 1. Generate Xk+1 uniformly distributed in Sk, and set Wk+1 = f(Xk+1)\nStep 2. If stopping criterion met, STOP. Otherwise, set\nSk+1 = {x : x ∈S and f(x) < Wk+1},\nIncrement k, Goto Step 1.\nPure Adaptive Search\n[4]\nSolis and Wetz\n- Give sufficient conditions for convergence of random global search methods\n- Experimental support for linear relation between function evaluations and\ndimension\n- PAS satisfies H1 since objective function values are increasing\n- PAS satisfies H2 since the optimal solution is always in the restricted feasible\nregion\nPure Adaptive Search\n[5]\nImportance of Strict Improvement\n- What if consecutive points were allowed to have equal objective function\nvalues?\n- Let S be a unit hypersphere, with f(x) = 1 on S except for a depression on a\nhypersphere of radius ε, Sε, where f(x) drops to value 0 at the center of the\nε-ball Sε\n- Then, P(random point is in Sε) = volume(Sε)/volume(S) = εn\n- Thus, PAS could have expected number of iterations that is exponential in\ndimension (if strict improvement were not enforced)\nPure Adaptive Search\n[6]\nSome Notation\n- Let p(y) = P(Yk ≤y), for k = 1, 2, . . . and y∗≤y ≤y∗\n- For PRS,\np(y) = v(S(y))/v(S),\nwhere S(y) = {x : x ∈S and f(x) ≤y} and v(·) is Lebesgue measure\n- Note that for PAS,\nP(Wk+1 ≤y|Wk = z) = v(S(y))/v(S(z)) = p(y)/p(z),\nfor k = 1, 2, . . . and y∗≤y ≤z ≤y∗\nPure Adaptive Search\n[7]\n\nConnection Between PAS and PRS\nDefinition. Epoch i is said to be a record of the sequence {Yk, k = 0, 1, 2, . . .} if\nYi < min(Y0, Y1, . . . , Yi-1). The corresponding value Yi is called a record value.\nLemma 1.\nFor the global optimization problem (P), the stochastic process\n{Wk, k = 0, 1, 2, . . .} ∼{YR(k), k = 0, 1, 2, . . .}, where R(k) is the kth record of\nthe sequence {Yk, k = 0, 1, 2, . . .}. In particular,\nP(Wk ≤y) = P(YR(k) ≤y), for k = 0, 1, 2, . . . , and y∗≤y ≤y∗\nPure Adaptive Search\n[8]\nProof of Lemma 1\nProof. First, we show that the conditional distributions are equal.\nP(YR(k+1) ≤y|YR(k) = x) = P(YR(k)+1 ≤y|YR(k) = x)\n+P(YR(k)+2 ≤y, YR(k)+1 ≥x|YR(k) = x) + · · ·\n= P(YR(k)+1 ≤y)\n+P(YR(k)+2 ≤y)P(YR(k)+1 ≥x) + · · ·\n= P(Y1 ≤y) Pinf\ni=0 P(Y1 ≥x)i\n=\nP (Y1≤y)\n1-P (Y1≥x)\n= v(S(y))/v(S(x))\n= P(Wk+1 ≤y|Wk = x).\nPure Adaptive Search\n[9]\nNext, we use induction to show that the unconditional distributions are equal.\nBy definition, R(0) = 0 and Y0 = W0 = y∗, thus YR(0) = W0.\nFor the base case k = 1,\nP(YR(1) ≤y) = P(YR(1) ≤y|Y0 = y∗)\n= P(W1 ≤y|W0 = y∗)\n= P(W1 ≤y),\nfor all y∗≤y ≤y∗\nThus, YR(1) ∼W1.\nPure Adaptive Search\n[10]\nFor k > 1, suppose that YR(i) ∼Wi for i = 1, 2, . . . , k. Then,\nP(YR(k+1) ≤y) = E[P(YR(k+1) ≤y|YR(k))]\n=\nR x\n0 P(YR(k+1) ≤y|YR(k) = x) dFYR(k)(x)\n=\nR x\n0 P(Wk+1 ≤y|Wk = x) dFWk(x)\n= E[P(Wk+1 ≤y|Wk)]\n= P(Wk ≤y),\nfor all y∗≤y ≤y∗\nThus, YR(k+1) ∼Wk+1.\nFinally, since the two sequences are equal in conditional and marginal\ndistribution, they are equal in joint distribution. 2\nPure Adaptive Search\n[11]\n\nLinear versus Exponential\nTheorem 1.\nLet k and R(k) be respectively the number of PAS and PRS\niterations needed to attain an objective function value of y or better, for\ny∗≤y ≤y∗. Then\nR(k) = ek+o(k), with probability 1,\nwhere limk→info(k)/k = 0, with probability 1.\nProof. Use general fact about records that limk→inf\nln R(k)\nk\n= 1, with probability\n1... 2\nPure Adaptive Search\n[12]\nRelative Improvement\nDefinition. Let Zk = (y∗-Yk)/(Yk -y∗) be the relative improvement obtained\nby the kth iteration of PRS.\nThen, the cumulative distribution function F of Zk is given by\nF(z) = P(Zk ≤z)\n= P(Yk ≥(y∗+ zy∗)/(1 + z))\n=\n\nif z < 0,\n1 -p((y∗+ zy∗)/(1 + z))\nif 0 ≤z < inf.\nNote also that the random variables Zk are iid and nonnegative.\nPure Adaptive Search\n[13]\nRelative Improvement Process\nLemma 2.\nLet Z1, Z2, . . . denote a sequence of iid nonnegative continuous\nrandom variables with density f and cdf F. Let M(z) denote the number of\nrecord values (in the max sense) of {Zi, i = 1, 2, . . .} less than or equal to z.\nThen {M(z), z ≥0} is a nonhomogeneous Poisson process with intensity\nfunction λ(z) = f(z)/(1 -F(z)) and mean value function m(z) =\nR z\n0 λ(z) ds.\nTheorem 2.\nLet N(z) be the number of PAS iterations achieving a relative\nimprovement at most z for z ≥0. Then {N(z), z ≥0} is a nonhomogeneous\nPoisson process with mean value function\nm(z) = ln(1/p((y∗+ zy∗)/(1 + z))), for 0 ≤z < inf.\nPure Adaptive Search\n[14]\nDistribution of Objective Function Values\nTheorem 3.\nP(Wk ≤y) = Pk-1\ni=0\np(y)(ln(1/p(y)))i\ni!\nProof. The events {Wk < y} and {N((y∗-y)/(y -y∗)) < k} are equivalent, so\nP(Wk ≤y) = P(Wk < y) = P(N((y∗-y)/(y -y∗)) < k),\nand by previous theorem N(z) is a Poisson random variable with mean\nm(z) = ln(1/p((y∗+ zy∗)/(1 + z))),\netc. 2\nPure Adaptive Search\n[15]\n\nPerformance Bounds\nLet N ∗(y) be the number of iterations require by PAS to achieve a value of y or\nbetter. Then\nN ∗(y) = N((y∗-y)/(y -y∗)) + 1\nCorollary 1.\nThe cumulative distribution of N ∗(y) is given by\nP(N ∗(y) ≤k) =\nk-1\nX\ni=0\np(y)(ln(1/p(y)))i\ni!\n,\nwith\nE[N ∗(y)] = 1 + ln(1/p(y)),\nV ar(N ∗(y)) = ln(1/p(y))\nPure Adaptive Search\n[16]\nBounds for Lipschitz Functions\nLemma 3.\nFor global optimization problem (P) over a convex feasible region S\nin n dimensions with diameter dS = max{∥w -v∥, w, v ∈S} and Lipschitz\nconstant kf,\np(y) ≥((y -y∗)/kfdS)n, for y∗≤y ≤y∗.\nTheorem 4.\nFor any global optimization problem (P) over a convex feasible\nregion in n dimensions with diameter at most d and Lipschitz constant at most\nk,\nE[N ∗(y)] ≤1 + [ln(kd/(y -y∗))]n\nand\nV ar(N ∗(y)) ≤[ln(kd/(y -y∗))]n\nfor y∗≤y ≤y∗.\nPure Adaptive Search\n[17]\nConclusions\n- Complexity of PRS is exponentially worse than that of PAS\n- General performance bounds using theory from stochastic processes\n- Specific performance bounds for Lipschitz functions : linear in dimension!\n- But is this too good to be true?!\nPure Adaptive Search\n[18]"
    },
    {
      "category": "Resource",
      "title": "Pure Adaptive Search in Global Optimization",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/1d77114d9a5461654a87fdb4b9ec45f5_ses6_zabinsky2.pdf",
      "content": "This presentation is based on: Zabinsky, Zelda B., and Robert L. Smith. Pure Adaptive Search in Global\nOptimization. Mathematical Programming 55, 1992, pp. 323-338."
    },
    {
      "category": "Resource",
      "title": "Semidefinite Programming (SDP) and the Goemans-Williamson MAXCUT Paper",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/a837b244b710301b020bab0dd9a92a71_ses1_goemans1.pdf",
      "content": "Semidefinite Programming (SDP)\nand the Goemans-Williamson\nMAXCUT Paper\nRobert M. Freund\nSeptember 8, 2003\nThis presentation is based on: Goemans, Michel X., and David P. Williamson. Improved Approximation Algorithms for Maximum Cut and\nSatisfiability Problems Using Semidefinite Programming. Journal of the ACM 42(6), November 1995, pp. 1115-1145.\n\nOutline\n- Alternate View of Linear Programming\n- Facts about Symmetric and Semidefinite Matrices\n- SDP\n- SDP Duality\n- Approximately Solving MAXCUT using SDP and Random\nVectors\n- Interior-Point Methods for SDP\n2003 Massachusetts Institute of Technology\n\nLinear\nAlternative Perspective\nProgramming\nLP : minimize c · x\ns.t.\nai · x = bi, i = 1, . . . , m\nn\nx ∈R+.\nn\n\"c · x\" means the linear function \"\nj=1 cjxj \"\nn\nn\nR+ := {x ∈R| x ≥0} is the nonnegative orthant.\nn is a convex cone.\nR+\nK is convex cone if x, w ∈K and α, β ≥0\n⇒ αx + βw ∈K.\n2003 Massachusetts Institute of Technology\n\nLinear\nAlternative Perspective\nProgramming\nLP : minimize c · x\ns.t.\nai · x = bi, i = 1, . . . , m\nn\nx ∈R+.\n\"Minimize the linear function c · x, subject to the condition that x\nmust solve m given equations ai · x = bi, i = 1, . . . , m, and that\nn\nx must lie in the convex cone K = R+.\"\n2003 Massachusetts Institute of Technology\n\nLinear\nAlternative Perspective\nProgramming\nLP Dual Problem...\nm\nLD : maximize\nyibi\ni=1\nm\ns.t.\nyiai + s = c\ni=1\nn\ns ∈R+.\nFor feasible solutions x of LP and (y, s) of LD, the duality gap\nis simply\nm\nm\nc · x -\nyibi =\nc -\nyiai\n· x = s · x ≥0\ni=1\ni=1\n2003 Massachusetts Institute of Technology\n\nLinear\nAlternative Perspective\nProgramming\n...LP Dual Problem\n∗\n∗\nIf LP and LD are feasible, then there exists x ∗ and (y , s )\nfeasible for the primal and dual, respectively, for which\nm\n∗\n∗\n∗\n∗\nc · x -\nyibi = s · x = 0\ni=1\n2003 Massachusetts Institute of Technology\n\nSemidefinite\nCone\nFacts about the\nIf X is an n × n matrix, then X is a symmetric positive\nsemidefinite (SPSD) matrix if X = XT and\nvTXv ≥0 for any v ∈Rn\nIf X is an n × n matrix, then X is a symmetric positive definite\n(SPD) matrix if X = XT and\nvTXv > 0 for any v ∈Rn, v = 0\n2003 Massachusetts Institute of Technology\n\nSemidefinite\nCone\nFacts about the\nSn denotes the set of symmetric n × n matrices\nSn\n+ denotes the set of (SPSD) n × n matrices.\nSn\n++ denotes the set of (SPD) n × n matrices.\n2003 Massachusetts Institute of Technology\n\nFacts about the\nSemidefinite\nCone\nLet X, Y ∈ Sn .\n\"X ⪰ 0\" denotes that X is SPSD\n\"X ⪰ Y \" denotes that X - Y ⪰ 0\n\"X ≻ 0\" to denote that X is SPD, etc.\nRemark: Sn = {X ∈ Sn | X ⪰ 0} is a convex cone.\n+\n2003 Massachusetts Institute of Technology\n\nFacts about\nEigenvalues and\nEigenvectors\nIf M is a square n × n matrix, then λ is an eigenvalue of M with\ncorresponding eigenvector q if\nMq = λq and q = 0 .\nLet λ1, λ2, . . . , λn enumerate the eigenvalues of M.\n2003 Massachusetts Institute of Technology\n\nFacts about\nEigenvalues and\nEigenvectors\nThe corresponding eigenvectors q1, q2, . . . , qn of M can be\nchosen so that they are orthonormal, namely\niT\nqj\nq\n= 0 for i\niT i\n= j, and\nq\nq\n= 1\nDefine:\nn\nQ := q 1 q · · · q\nThen Q is an orthonormal matrix:\nQTQ = I, equivalently QT = Q-1\n2003 Massachusetts Institute of Technology\n\nFacts about\nEigenvalues and\nEigenvectors\nλ1, λ2, . . . , λn are the eigenvalues of M\nq , q2, . . . , qn are the corresponding orthonormal eigenvectors of\nM\nn\nQ := q 1 q · · · q\nQ-1\nQTQ = I, equivalently QT =\nDefine D:\n\nλ1\n\nλ2\n\nD :=\n...\n.\nλn\nProperty: M = QDQT .\n2003 Massachusetts Institute of Technology\n\nFacts about\nEigenvalues and\nEigenvectors\nThe decomposition of M into M = QDQT is called its\neigendecomposition.\n2003 Massachusetts Institute of Technology\n\nFacts about\nSymmetric\nMatrices\n- If X ∈ Sn, then X = QDQT for some orthonormal matrix Q\nand some diagonal matrix D. The columns of Q form a set of n\northogonal eigenvectors of X, whose eigenvalues are the\ncorresponding entries of the diagonal matrix D.\n- X ⪰ 0 if and only if X = QDQT where the eigenvalues (i.e.,\nthe diagonal entries of D) are all nonnegative.\n- X ≻ 0 if and only if X = QDQT where the eigenvalues (i.e.,\nthe diagonal entries of D) are all positive.\n2003 Massachusetts Institute of Technology\n\nFacts about\nSymmetric\nMatrices\n- If M is symmetric, then\nn\ndet(M ) =\nλj\nj=1\n2003 Massachusetts Institute of Technology\n\nFacts about\nSymmetric\nMatrices\n- Consider the matrix M defined as follows:\nP\nv\nM =\nT\n,\nv\nd\nwhere P ≻ 0, v is a vector, and d is a scalar. Then M ⪰ 0 if\nTP -1\nand only if d - v\nv ≥ 0.\n- For a given column vector a, the matrix X := aaT is SPSD,\ni.e., X = aaT ⪰ 0.\n- If M ⪰ 0, then there is a matrix N for which M = N TN . To\nsee this, simply take N = D2QT .\n2003 Massachusetts Institute of Technology\n\nSDP\nX\nSemidefinite Programming\nThink about\nLet X ∈ Sn. Think of X as:\n- a matrix\n- an array of n2 components of the form (x11, . . . , xnn)\n- an object (a vector) in the space Sn .\nAll three different equivalent ways of looking at X will be useful.\n2003 Massachusetts Institute of Technology\n\nSemidefinite Programming\nSDP\nLinear Function of X\nLet X ∈ Sn. What will a linear function of X look like?\nIf C(X) is a linear function of X, then C(X) can be written as\nC - X, where\nn\nn\nC - X :=\nCijXij.\ni=1 j=1\nThere is no loss of generality in assuming that the matrix C is\nalso symmetric.\n2003 Massachusetts Institute of Technology\n\nSDP\nSemidefinite Programming\nDefinition of SDP\nSDP : minimize C - X\ns.t.\nAi - X = bi , i = 1, . . . , m,\nX ⪰ 0,\n\"X ⪰ 0\" is the same as \"X ∈ Sn\"\n+\nThe data for SDP consists of the symmetric matrix C (which is\nthe data for the objective function) and the m symmetric matrices\nA1, . . . , Am, and the m-vector b, which form the m linear\nequations.\n2003 Massachusetts Institute of Technology\n\nSemidefinite Programming\nSDP\nExample...\n\nA1 = 0\n,\nA2 = 2\n0 , b =\n, and C = 2\n,\n\nThe variable X will be the 3 × 3 symmetric matrix:\n\nx11\nx12\nx13\n\nX = x21\nx22\nx23\n,\nx31\nx32\nx33\nSDP : minimize\nx11 + 4x12 + 6x13 + 9x22 + 0x23 + 7x33\ns.t.\nx11 + 0x12 + 2x13 + 3x22 + 14x23 + 5x33 = 11\n0x11 + 4x12 + 16x13 + 6x22 + 0x23 + 4x33 = 19\n\nx11\nx12\nx13\nX = x21\nx22\nx23 ⪰ 0.\nx31\nx32\nx33\n2003 Massachusetts Institute of Technology\n\nSemidefinite Programming\nSDP\n...Example\nSDP : minimize\nx11 + 4x12 + 6x13 + 9x22 + 0x23 + 7x33\ns.t.\nx11 + 0x12 + 2x13 + 3x22 + 14x23 + 5x33 = 11\n0x11 + 4x12 + 16x13 + 6x22 + 0x23 + 4x33 = 19\n\nx11\nx12\nx13\nX = x21\nx22\nx23 ⪰ 0.\nx31\nx32\nx33\nIt may be helpful to think of \"X ⪰ 0\" as stating that each of the n eigenvalues\nof X must be nonnegative.\n2003 Massachusetts Institute of Technology\n\nSemidefinite Programming\nSDP\nLP ⊂SDP\nLP : minimize c · x\ns.t.\nai · x = bi, i = 1, . . . , m\nn\nx ∈R+.\nDefine:\n\nai1\n. . .\nc1\n. . .\n\n. . .\n\na\n.\ni2\n. . .\n. , i = 1, . . . , m, and C = ..\nc\n..\n...\n.. .\nAi = ..\n.\n...\n.\n.\n.\n.\n.\n.\n.\n. . . ain\n. . . cn\nSDP : minimize C - X\ns.t.\nAi - X = bi , i = 1, . . . , m,\nXij = 0, i = 1, . . . , n, j = i + 1, . . . , n,\n\nx1\n. . .\n\nx2\n. . .\n\n. ⪰0,\nX = ..\n..\n...\n.\n.\n.\n.\n. . . xn\n2003 Massachusetts Institute of Technology\n\nSDP Duality\nm\nSDD : maximize\nyibi\ni=1\nm\ns.t.\nyiAi + S = C\ni=1\nS ⪰ 0.\nNotice\nm\nS = C -\nyiAi ⪰ 0\ni=1\n2003 Massachusetts Institute of Technology\n\nSDP Duality\nand so equivalently:\nm\nSDD : maximize\nyibi\ni=1\nm\ns.t.\nC -\nyiAi ⪰ 0\ni=1\n2003 Massachusetts Institute of Technology\n\nExample\nSDP Duality\n\nA1 = 0\n,\nA2 = 2\n0 , b =\n, and C = 2\n\nSDD : maximize 11y1 + 19y2\n\ns.t.\ny1 0\n7 + y2 2\n0 + S = 2\n\nS ⪰ 0\n2003 Massachusetts Institute of Technology\n\nExample\nSDP Duality\nSDD : maximize 11y1 + 19y2\n\ns.t.\ny1 0\n7 + y2 2\n0 + S = 2\n\nS ⪰ 0\nis the same as:\nSDD : maximize\n11y1 + 19y2\ns.t.\n\n1 - 1y1 - 0y2 2 - 0y1 - 2y2 3 - 1y1 - 8y2\n2 - 0y1 - 2y2 9 - 3y1 - 6y2 0 - 7y1 - 0y2 ⪰ 0.\n3 - 1y1 - 8y2 0 - 7y1 - 0y2 7 - 5y1 - 4y2\n2003 Massachusetts Institute of Technology\n\nWeak Duality\nSDP Duality\nWeak Duality Theorem: Given a feasible solution X of SDP\nand a feasible solution (y, S) of SDD, the duality gap is\nm\nC - X -\nyibi = S - X ≥ 0 .\ni=1\nIf\nm\nC - X -\nyibi = 0 ,\ni=1\nthen X and (y, S) are each optimal solutions to SDP and\nSDD, respectively, and furthermore, SX = 0.\n2003 Massachusetts Institute of Technology\n\nSDP Duality\nStrong Duality\n∗\n∗\nStrong Duality Theorem: Let z and zD denote the optimal\nP\nobjective function values of SDP and SDD, respectively.\nSuppose that there exists a feasible solution ˆ\nX of SDP such that\nX ≻ 0, and that there exists a feasible solution (ˆ ˆ\nˆ\ny, S) of SDD\nsuch that ˆS ≻ 0. Then both SDP and SDD attain their optimal\nvalues, and\n∗\n∗\nzP = zD .\n2003 Massachusetts Institute of Technology\n\nSDP\nSome Important\nWeaknesses of\n- There may be a finite or infinite duality gap.\n- The primal and/or dual may or may not attain their optima.\n- Both programs will attain their common optimal value if both\nprograms have feasible solutions that are SPD.\n- There is no finite algorithm for solving SDP .\n- There is a simplex algorithm, but it is not a finite algorithm.\nThere is no direct analog of a \"basic feasible solution\" for SDP .\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nProblem\nM. Goemans and D. Williamson, Improved\nApproximation Algorithms for Maximum Cut and\nSatisf iability Problems using Semidef inite\nProgramming, J. ACM 42 1115-1145, 1995.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nProblem\nG is an undirected graph with nodes N = {1, . . . , n} and edge\nset E.\nLet wij = wji be the weight on edge (i, j), for (i, j) ∈ E.\nWe assume that wij ≥ 0 for all (i, j) ∈ E.\nThe MAX CUT problem is to determine a subset S of the nodes\nN for which the sum of the weights of the edges that cross from\nS to its complement\nS := N \\ S).\nS is maximized (\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nFormulations\nProblem\nThe MAX CUT problem is to determine a subset S of the nodes\nN for which the sum of the weights wij of the edges that cross\nfrom S to its complement\nS := N \\ S).\nS is maximized (\n\nLet xj = 1 for j ∈ S and xj = -1 for j ∈ S.\nn\nn\nMAXCUT : maximizex 4\nwij(1 - xixj )\ni=1 j=1\ns.t.\nxj ∈{-1, 1}, j = 1, . . . , n.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nFormulations\nProblem\nn\nn\nMAXCUT : maximizex 4\nwij(1 - xixj)\ni=1 j=1\ns.t.\nxj ∈{-1, 1}, j = 1, . . . , n.\nLet\nY = xxT .\nThen\nYij = xixj\ni = 1, . . . , n, j = 1, . . . , n.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nFormulations\nProblem\nAlso let W be the matrix whose (i, j)th element is wij for\ni = 1, . . . , n and j = 1, . . . , n. Then\nn\nn\nMAXCUT : maximizeY,x 1\nwij (1 - Yij)\ni=1 j=1\ns.t.\nxj ∈{-1, 1}, j = 1, . . . , n\nY = xxT.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nFormulations\nProblem\nn\nn\nMAXCUT : maximizeY,x 1\nwij (1 - Yij)\n4 i=1 j=1\ns.t.\nxj ∈{-1, 1}, j = 1, . . . , n\nY = xxT.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nFormulations\nProblem\nThe first set of constraints are equivalent to\nYjj = 1, j = 1, . . . , n.\nn\nn\nMAXCUT : maximizeY,x 1\nwij (1 - Yij)\n4 i=1 j=1\ns.t.\nYjj = 1, j = 1, . . . , n\nY = xxT.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nFormulations\nProblem\nn\nn\nMAXCUT : maximizeY,x 1\nwij (1 - Yij)\n4 i=1 j=1\ns.t.\nYjj = 1, j = 1, . . . , n\nY = xxT.\nNotice that the matrix Y = xxT is a rank-1 SPSD matrix.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nFormulations\nProblem\nWe relax this condition by removing the rank-1 restriction:\nn\nn\nRELAX : maximizeY\nwij (1 - Yij )\ni=1 j=1\ns.t.\nYjj = 1, j = 1, . . . , n\nY ⪰ 0.\nIt is therefore easy to see that RELAX provides an upper bound\non MAXCUT, i.e.,\nMAXCUT ≤ RELAX.\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nComputing a Good Solution\nProblem\nn\nn\nRELAX : maximizeY 4\nwij (1 -Yij )\ni=1 j=1\ns.t.\nYjj = 1, j = 1, . . . , n\nY ⪰ 0.\nLet ˆY solve RELAX\nFactorize ˆ = V T ˆ\nY\nˆ V\nvT ˆ\nˆ\nv1 ˆ\nˆ\nYij =\nV T ˆ\n= ˆi vj\nV = [ˆ v2 · · · vn] and ˆ\nˆ V\nij\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nComputing a Good Solution\nProblem\nLet ˆ\nY solve RELAX\nFactorize ˆ = V T ˆ\nY\nˆ V\nvT ˆ\nˆ\nv1 ˆ\nˆ\nYij =\nV T ˆ\n= ˆi vj\nV = [ˆ v2 · · · vn] and ˆ\nˆ V\nij\nLet r be a random uniform vector on the unit n-sphere Sn\nS := {i | rT ˆvi ≥ 0}\nS := {i | rT ˆvi < 0}\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nComputing a Good Solution\nProblem\nProposition:\nvT ˆ\n\nvi)\nvj)\n\n= arccos(ˆ vj )\ni\nP sign(rT ˆ\n= sign(rT ˆ\n.\nπ\n2003 Massachusetts Institute of Technology\n\n^Vi\nVj\n^\nThe MAX CUT\nProblem\nComputing a Good Solution\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nProblem\nComputing a Good Solution\nLet r be a random uniform vector on the unit n-sphere Sn\nS := {i | rT ˆvi ≥ 0}\nS := {i | rT ˆvi < 0}\nLet E[Cut] denote the expected value of this cut.\nTheorem: E[Cut] ≥ 0.87856 × MAXCUT\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nComputing a Good Solution\nProblem\nvi)\nvj )\nE[Cut] = 1\nwij × P sign(rT ˆ\n= sign(rT ˆ\n2 i,j\nT\narccos(ˆi ˆ\nv vj )\n= 2\nwij\nπ\ni,j\narccos( ˆYij )\n= 2\nwij\nπ\ni,j\n=\nwij arccos( ˆYij )\n2π i,j\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nComputing a Good Solution\nProblem\nE[Cut] = 1\nwij arccos( ˆYij )\n2π i,j\n=\nwij 1 - ˆ\n2 arccos( ˆ\nYij )\nYij\nYij\nπ\n1- ˆ\ni,j\n\n2 arccos(t)\nwij 1 - ˆ\n≥ 1\nYij min-1≤t≤1 π\n1-t\ni,j\nθ\n= RELAX × min0≤θ≤π π 1-cos θ\n≥ RELAX × 0.87856\n2003 Massachusetts Institute of Technology\n\nThe MAX CUT\nProblem\nComputing a Good Solution\nSo we have\nMAXCUT ≥ E[Cut] ≥ RELAX × 0.87856 ≥ MAXCUT × 0.87856\nThis is an impressive result, in that it states that the value of the\nsemidefinite relaxation is guaranteed to be no more than 12.2%\nhigher than the value of NP -hard problem MAXCUT.\n2003 Massachusetts Institute of Technology\n\nThe Logarithmic Barrier Function for SPD Matrices\nLet X ⪰ 0, equivalently X ∈ Sn .\n+\nX will have n nonnegative eigenvalues, say\nλ1(X), . . . , λn(X) ≥ 0 (possibly counting multiplicities).\n∂Sn = {X ∈ Sn | λj(X) ≥ 0, j = 1, . . . , n,\n+\nand λj(X) = 0 for some j ∈{1, . . . , n}}.\n2003 Massachusetts Institute of Technology\n\nThe Logarithmic Barrier Function for SPD Matrices\n∂Sn = {X ∈ Sn | λj(X) ≥ 0, j = 1, . . . , n,\n+\nand λj(X) = 0 for some j ∈{1, . . . , n}}.\nA natural barrier function is:\n\nn\nn\nB(X) := -\nln(λi(X)) = - ln\nλi(X) = - ln(det(X)).\nj=1\nj=1\nThis function is called the log-determinant function or the\nlogarithmic barrier function for the semidefinite cone.\n2003 Massachusetts Institute of Technology\n\nThe Logarithmic Barrier Function for SPD Matrices\n\nn\nn\nB(X) := -\nln(λi(X)) = - ln\nλi(X) = - ln(det(X)).\nj=1\nj=1\n\nQuadratic Taylor expansion at X = X:\n\nX-1\n\n2DX-1\n\n2DX-1\nB(X + αD) ≈ B(X) + α\n- D + 1 α2 X-1\n\n- X-1\n\n.\nB(X) has the same remarkable properties in the context of\ninterior-point methods for SDP as the barrier function\nn\n-\nj=1 ln(xj ) does in the context of linear optimization.\n2003 Massachusetts Institute of Technology\n\nInterior-point\nPrimal and Dual SDP\nMethods for SDP\nSDP : minimize C - X\ns.t.\nAi - X = bi , i = 1, . . . , m,\nX ⪰ 0\nand\nm\nSDD : maximize\nyibi\ni=1\nm\ns.t.\nyiAi + S = C\ni=1\nS ⪰ 0 .\nIf X and (y, S) are feasible for the primal and the dual, the duality gap is:\nm\nC - X -\nyibi = S - X ≥ 0 .\ni=1\nAlso,\nS - X = 0 ⇐⇒ SX = 0 .\n2003 Massachusetts Institute of Technology\n\nInterior-point\nPrimal and Dual SDP\nMethods for SDP\n\nn\nn\nB(X) = -\nln(λi(X)) = - ln\nλi(X) = - ln(det(X)) .\nj=1\nj=1\nConsider:\nBSDP (μ) : minimize C - X - μ ln(det(X))\ns.t.\nAi - X = bi , i = 1, . . . , m,\nX ≻ 0.\nLet fμ(X) denote the objective function of BSDP (μ). Then:\n-∇fμ(X) = C - μX-1\n2003 Massachusetts Institute of Technology\n\nInterior-point\nPrimal and Dual SDP\nMethods for SDP\nBSDP (μ) : minimize C - X - μ ln(det(X))\ns.t.\nAi - X = bi , i = 1, . . . , m,\nX ≻ 0.\n∇fμ(X) = C - μX-1\nKarush-Kuhn-Tucker conditions for BSDP (μ) are:\n\nAi - X = bi , i = 1, . . . , m,\n\nX ≻ 0,\n\nm\n\nC - μX-1 =\nyiAi.\ni=1\n2003 Massachusetts Institute of Technology\n\nInterior-point\nPrimal and Dual SDP\nMethods for SDP\n\nAi - X = bi , i = 1, . . . , m,\n\nX ≻ 0,\nm\n\nC - μX-1 =\nyiAi.\ni=1\nDefine\nS = μX-1 ,\nwhich implies\nXS = μI ,\n2003 Massachusetts Institute of Technology\n\nInterior-point\nPrimal and Dual SDP\nMethods for SDP\nand rewrite KKT conditions as:\n\nAi - X = bi , i = 1, . . . , m, X ≻ 0\n\nm\nyiAi + S = C\n\ni=1\nXS = μI.\n2003 Massachusetts Institute of Technology\n\nInterior-point\nPrimal and Dual SDP\nMethods for SDP\n\nAi - X = bi , i = 1, . . . , m, X ≻ 0\n\nm\nyiAi + S = C\n\ni=1\nXS = μI.\nIf (X, y, S) is a solution of this system, then X is feasible for\nSDP , (y, S) is feasible for SDD, and the resulting duality gap is\nn\nn\nn\nn\nS - X =\nSijXij =\n(SX)jj =\n(μI)jj = nμ.\ni=1 j=1\nj=1\nj=1\n2003 Massachusetts Institute of Technology\n\nInterior-point\nPrimal and Dual SDP\nMethods for SDP\n\nAi - X = bi , i = 1, . . . , m, X ≻ 0\n\nm\nyiAi + S = C\n\ni=1\nXS = μI.\nIf (X, y, S) is a solution of this system, then X is feasible for\nSDP , (y, S) is feasible for SDD, the duality gap is\nS - X = nμ.\n2003 Massachusetts Institute of Technology\n\nInterior-point\nMethods for SDP\nPrimal and Dual SDP\nThis suggests that we try solving BSDP (μ) for a variety of\nvalues of μ as μ → 0.\nInterior-point methods for SDP are very similar to those for linear\noptimization, in that they use Newton's method to solve the KKT\nsystem as μ → 0.\n2003 Massachusetts Institute of Technology\n\nWebsite for SDP\nA good website for semidefinite programming is:\nhttp://www-user.tu-chemnitz.de/ helmberg/semidef.html.\n2003 Massachusetts Institute of Technology"
    },
    {
      "category": "Resource",
      "title": "ses5_solis_wets.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/11c27c87ad84545ea4858c87a60c6e19_ses5_solis_wets.pdf",
      "content": "Minimization by Random Search Techniques\nby Solis and Wets\nand\nan Intro to Sampling Methods\nPresenter: Michele Aghassi\nOctober 27, 2003\nThis presentation is based on: Solis, F. J., and R. J-B. Wets. Minimization by Random Search Techniques. Mathematical\nOperations Research 6, 1981, pp. 19-30.\n\nRecap of Past Sessions\n- LP\n- Kalai (1992, 1997)\n∗ use randomized pivot rules\n- Motwani and Raghavan (1995), Clarkson (1998, 1995)\n∗ solve on a random subset of constraints, recursively\n- Dunagan and Vempala (2003): LP Feasibility (Ax ≥ 0, 0 = 0)\n∗ Generate random vectors and test for feasibility\n∗ If not, try moving in deterministic (w.r.t. random vector already selected)\ndirection to achieve feasibility\n- NLP\n- Storn and Price (1997): Unconstrained NLP\n∗ Heuristic\n∗ Select random subsets of solution population vectors\n∗ Perform addition, subtraction, component swapping and test for obj func\nimprovement\n\nMotivation\nWhat about provably convergent algorithms for constrained NLPs?\n- Random search techniques first proposed in the 1950s\n- pre-1981 proofs of convergence were highly specific and involved\n- Solis and Wets, 1981: Can we give more general sufficient conditions for convergence,\nunifying the past results in the literature?\n- Solis and Wets paper interesting more from a unifying theoretical standpoint\n- Computational results of the paper relatively unimpressive\n\nOutline\n- Part I: Solis and Wets paper\n- Motivation for using random search\n- Appropriate goals of random search algorithms\n- Conceptual Algorithm encompassing several concrete examples\n- Sufficient conditions for global search convergence, and theorem\n- Local search methods and sufficient conditions for convergence, and theorem\n- Defining stopping criteria\n- Some computational results\n- Part II: Intro to Sampling Methods\n- Traditional Methods\n- Hit-and-run algorithm\n\nWhy Use Random Search Techniques?\nLet f : Rn → R, S ⊆ Rn .\n(P)\nmin\nf (x)\ns.t.\nx ∈ S\n- Function characteristics difficult to compute (e.g. gradients, etc.)\n- Function is \"bumpy\"\n- Need global minimum, but there are lots of local minima\n- Limited computer memory\n\nWhat is an Appropriate Goal?\n- Problems\n- Global min may not exist\n- Finding min may require exhaustive examination (e.g. min occurs at point at\nwhich f singularly discontinuous)\n- Response\nDefinition 1. α is the Essential Infimum of f on S iff\nα\n=\ninf\n\n{t | v(x ∈ S | f(x) < t) > 0} ,\nwhere v denotes n-dimensional volume or Lebesgue measure. Optimality region\nfor P is given by\n(\n{x ∈ S | f(x) < α + ε} ,\nα finite\n=\nRε,M\n{x ∈ S | f(x) < -M} ,\nα = -inf,\nfor a given \"big\" M > 0\n\nWhat is Random Search?\nConceptual Algorithm:\n1. Initialize: Find x0 ∈ S. Set k := 0\n2. Generate ξk ∈ Rn (random) from distribution μk\nk+1\n3. Set x\n= D(xk, ξk). Choose μk+1. Set k := k + 1. Go to step 1.\n\"\n\n\"\nk\n\nk-1\nμk(A)\n=\nP x ∈ A x , x , . . . , x\nThis captures both\n- Local search =⇒ supp(μk) is bounded and v(S ∩ supp(μk)) < v(S)\n- Global search =⇒ supp(μk) is such that v(S ∩ supp(μk)) = v(S)\n\nSufficient Conditions for Convergence\n\n(H1) D s.t.\nf(xk)\ninf\nnonincreasing\nk=0\nf(D(x, ξ)) ≤ f(x)\nξ ∈ S\n=⇒\nf(D(x, ξ)) ≤ min {f(x), f(ξ)}\n(H2) Zero probability of repeatedly missing any positive-volume subset of S.\ninf\nY\n∀A ⊆ S s.t. v(A) > 0,\n(1 - μk(A))\n=\nk=0\ni.e. sampling strategy given by μk cannot consistently ignore a part of S with\npositive volume (Global search methods satisfy (H2))\n\nExample Satisfying (H1) and (H2), I\nDue to Gaviano [2].\nk\nk\nk\nD(x , ξ )\n=\n(1\n\n- λk)x + λkξk where\nh\ni\nk\nk\nk\nk\nλk\n=\narg\nmin\nf ((1 - λ)x + λξ ) | (1 - λ)x + λξ\n∈ S\nλ∈[0,1]\nk\nμk unif on n-dim sphere with center x\nand r ≥ 2diam(S).\nWhy?\n\n- (H1) satisfied since f (xk)\ninf\nnonincreasing by construction\nk=0\n- (H2) satisfied because sphere contains S\n\nExample Satisfying (H1) and (H2), II\nDue to Baba et al. [1].\n(\nk\nξk,\nξk ∈ S and f(ξk) < f(x )\nk\nk\nD(x , ξ )\n=\nk\nx , o.w.\nk\nμk\n∼\nN (x , I)\nWhy?\n\n- (H1) satisfied since f(xk)\ninf\nnonincreasing by construction\nk=0\nk\n- (H2) satisfied because S contained in support of N (x , I)\n\nGlobal Search Convergence Theorem\n\nk inf\nTheorem 1. Suppose f measurable, S ⊆ Rn measurable, (H1), (H2), and\nx\nk=0\ngenerated by the algorithm. Then\n\"\n\"\nk\nlim P x ∈ Rε,M\n=\nk→inf\nk ∈ Rε,M =⇒ xl\nProof. By (H1), x\n∈ Rε,M , ∀l< k\n\"\n\"\nk-1\nY `\n\nk\nP x ∈ S\\Rε,M\n≤\n1 - μl(Rε,M )\nl=0\n\"\n\"\n\"\n\"\nk-1\nY `\n\nk\nk\nP x ∈ Rε,M\n= 1 - P x ∈ S\\Rε,M\n≥\n1 -\n1 - μl(Rε,M )\nl=0\n\"\n\"\nk-1\nY `\n\nk\n1 ≥ lim P x ∈ Rε,M\n≥\n1 - lim\n1 - μl(Rε,M )\n= 1,\nk→inf\nk→inf l=0\nwhere last equality follows from (H2).\n\nLocal Search Methods\n- Easy to find examples for which the algorithm will get trapped at local minimum\n- Drastic sufficient conditions ensure convergence to optimality region, but are very\ndifficult to verify\nFor instance\n(H3) ∀x0 ∈ S\n\nL0 =\nx ∈ S | f (x) ≤ f (x0)\n\nis compact and\n∃γ > 0 and η ∈ (0, 1] (possibly depending on x0) s.t., ∀k and ∀x ∈ L0,\n`ˆ\n\nˆ\n\nμk\nD(x, ξ) ∈ Rε,M\n∪\ndist(D(x, ξ), Rε,M ) < dist(x, Rε,M ) - γ\n≥\nη.\nIf f and S are \"nice,\" local search methods demonstrate better convergence behavior.\n\nExample Satisfying (H3), I\n- int(S) = ∅\n- ∀α ∈R, S ∩{x | f(x) ≤α} convex and compact\nHappens whenever f quasi-convex and either S compact or f has bounded level\nsets\n- ξk chosen via uniform distribution on hypersphere with center xk and radius ρk\n- ρk is a function of x , x , . . . , xk-1 and ξ1, . . . , ξk-1 such that ρ = infk ρk > 0\n-\n(\nξk,\nξk ∈S\nk\nk\nD(x , ξ )\n=\nk\nx , o.w.\nProof. L0 compact convex since level sets are.\nRε,M has nonempty interior since S does.\n∴ can draw ball contained in interior of Rε,M .\nv(region I)\nNow take γ = ρ and η =\n> 0\nv(hypersphere with radius ρ)\n\nExample Satisfying (H3)\nρ/2\nx\ny\nL\nR\nρ\nM\nε,\nk\nk\nρ\nz\nI\nII\nv(region II)\n>\nv(region I)\n= η.\nv(hypersphere with radius ρk)\nv(hypersphere with radius ρ)\n\nl\nl\nl\nl\nLocal Search Convergence Theorem, I\nTheorem 2. Suppose f is a measurable function, S ⊆ Rn is a measurable, and (H1)\n\nk inf\nand (H3) are satisfied. Let x\nbe a sequence generated by the algorithm. Then,\nk=0\n\"\n\"\nk\nlim P x ∈ Rε,M\n=\n1.\nk→inf\nProof. Let x0 be the initial iterate used by the algorithm. By (H1), all future iterates\nin L0 ⊇ Rε,M . L0 is compact. Therefore ∃p ∈ Z s.t. γp > diam(L0).\n\"\n\"\n\"\n\"\nP xl+p ∈ Rε,M, x ∈ Rε,M\nP x l+p ∈ Rε,M | x\n=\n`\n\n∈ Rε,M\nP xl ∈ Rε,M\n\"\n\"\n≥\nP x l+p ∈ Rε,M, x ∈ Rε,M\n\"\n≥\nP x ∈ Rε,M, dist(x k, Rε,M ) ≤ γ(p - (k - l)),\nk = l, . . . , l + p)\n≥\nηp\nby repeated Bayes rule and (H3)\n\nLocal Search Convergence Theorem, II\n`\nxkp\n\nClaim: P\n∈Rε,M ≤(1 -ηp)k , ∀k ∈{1, 2, . . . }\nBy induction\n\"\n\"\n`\n(k = 1) P xp ∈Rε,M\n\n≥\nP xp ∈Rε,M, x 0 ∈Rε,M\n≥ ηp\n\"\n\"\n\"\n\"\n\"\n\"\n∈Rε,M | x(k-1)p ∈Rε,M\nP x(k-1)p\nxkp ∈Rε,M\n=\nP xkp\n\n(Genl k) P\n\n∈Rε,M\nh\n\"\n\"i `\nx(k-1)p ∈Rε,M\n1 -ηp k-1\n≤\n1 -P xkp ∈Rε,M |\n\n≤\n`\n1 -ηp `\n1 -ηp k-1\n\"\n\"\n\"\n\"\n∴ P xkp+l ∈Rε,M\n≥ P xkp ∈Rε,M\n≥\n1 -\n`\n1 -ηp k ,\nl = 0, 1, . . . , p -1\n\nStopping Criteria\n\nk inf\nk\n- So far, we gave a conceptual method for generating\nx\nsuch that f (x ) →\nk=0\nessential inf plus buffer\n- In practice, need stopping criterion\n- Easy to give stopping criterion if have LB on μk(Rε,M ) (unrealistic)\n- How to do this without knowing a priori essential inf or Rε,M ?\n- Has been shown that even if S compact and convex and f ∈ C2, each step of alg\nleaves unsampled square region of nonzero measure, over which f can be redefined\nso that global min is in unsampled region\n- \"search for a good stopping criterion seems doomed to fail\"\n\n′\nRates of Convergence\n- Measured by distributional characteristics of number of iters or function evals\nrequired to reach essential inf (e.g. mean)\n- Solis and Wets tested 3 versions of the conceptual alg (1 local search, 2 global\nsearch) on various problems (constrained and unconstrained)\n- They report results only for\nmin x x\nx∈Rn\nwith stopping criterion ∥xk∥≤10-\n- Found that mean number of function evals required ∝n.\n\nConclusion and Summary of Part I\n- Why use random search techniques?\n- How to handle pathological cases? (essential infimum, optimality region)\n- Conceptual Algorithm unifies past examples in the literature\n- Global and local search methods\n- Sufficient conditions for convergence and theorems\n- Issue of stopping criteria\n- Computational results\n\nPart II: Traditional Sampling Methods\n- Transformation method\n- easier to generate Y than X, but well-behaved transformation between the two\n- Acceptance-rejection method\n- Generate a RV and subject it to a test (based on a second RV) in order to\ndetermine acceptance\n- Markov-regression\n- Generate random vector component-wise, using marginal distributions w.r.t.\ncomponents generated already\nImpractical because complexity increases rapidly with dimension.\n\nPart II: Approximate Sampling Methods\n- Perform better computationally (efficient)\n- generates a sequence of points, whose limiting distribution is equal to target\ndistribution\nHit-and-Run: Generate random point in S, a bounded open subset of Rd, according to\nsome target distribution π.\n1. Initialize: select starting point x0 ∈S. n := 0.\n2. Randomly generate direction θn in Rd, according to distribution ν\n(corresponds to randomly generating a point on a unit sphere).\nn\n3. Randomly select step size from λn ∈{λ | x + λθn ∈S} according to distribution\nL(xn, θn)\nn+1\nn\n4. Set x\n:= x + λnθn . n := n + 1. Repeat.\ne.g. generate point according to uniform distribution on S: use all uniform distributions\n\nFurther Reading\nReferences\n[1] Baba, N., T. Shoman, and Y. Sawaragi. \"A Modified Convergence Theorem for a\nRandom Optimization Algorithm,\" Information Science, 13 (1977).\n[2] Gaviano, M. \"Some General Results on the Convergence of Random Search\nAlgorithms in Minimization Problems.\" In Towards Global Optimization, eds. L.\nDixon and G. Szeg o. Amsterdam.\n[3] Solis, Francisco J. and Roger J.B. Wets. \"Minimization by Random Search\nTechniques,\" Mathematics of Operations Research, 6: 19 - 30 (1981).\n[4] H.E. Romeijn, Global Optimization by Random Walk Sampling Methods, Thesis\nPublishers, Amsterdam, 1992."
    },
    {
      "category": "Resource",
      "title": "I. Integer programming part of Clarkson-paper; II. Incremental Linear Programming, Section 9.10.1 in Randomized Algorithms-book",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/447811ef5d267f866da5abf01d028742_ses3_book.pdf",
      "content": "I. Integer programming part of Clarkson-paper\nII. Incremental Linear Programming, Section 9.10.1 in\nRandomized Algorithms-book\npresented by Jan De Mot\nSeptember 29, 2003\n1/23\nThis presentation is based on: Clarkson, Kenneth L. Las Vegas Algorithms for Linear and Integer Programming When the Dimension\nis Small. Journal of the ACM 42(2), March 1995, pp. 488-499. Preliminary version in Proceedings of the 29th Annual IEEE\nSymposium on Foundations of Computer Science, 1988.\nand Chapter 9 of: Motwani, Rajeev, and Prabhakar Raghavan. Randomized Algorithms. Cambridge, UK: Cambridge University\nPress, 1995.\n\nOutline\nPart I: Integer Linear Programming (ILP)\n-\nPrevious work\n-\nAlgorithm for solving Integer Linear Programs [Clarkson 1995]\nbased on the mixed algorithm for LP (Susan)\n- Concept\n- Running Time Analysis\nPart II: Incremental Linear Programming\n-\nConcept\n-\nSeideLP [Seidel 1991]\n-\nBasisLP [Sharir and Welzl 1992]\n2/23\n\nPart I: Integer Linear Programming\n3/23\n\nPrevious Work\n-\n[Lenstra 1983] showed how to solve an ILP in polynomial time\nwhen the numbers of variables is fixed.\n-\nSubsequent improvements (e.g. by [Frank and Tardos 1987])\nshow that the fasted deterministic algorithm requires\noperations on -bit numbers.\n-\nRunning time of new ILP algorithm:\nThis is substantially faster than Lenstra's for\n4/23\n\nILP Problem\n-\nFind the optimum of:\nwhere and\n5/23\n\nNotation and Preliminaries\n-\nLet:\n-\ndenote the set of constraints defined by and\n-\ndenote the optimal solution of the ILP defined on\n(not the corresponding LP relaxation).\n-\nAssume:\n- Bounded solution by adding to a new set of constraints :\nwhere and where we use a result by\n[Schrijver 1986]: if an ILP has finite solution, then every coordinate\nof that optimum has size no more than where is the facet\ncomplexity of\n- Unique solution by choosing the lexicographically largest point\nachieving the optimum value.\n6/23\n\nILP Algorithm: Concept\n-\nFirst it is established that an optimum is determined by a small\nset ([Bell 1977] and [Scarf 1977]):\nLemma: There is a set with and with\n-\nILP algorithms are variations on the LP algorithms, with sample\nsizes using rather than and using Lenstra's algorithm in\nthe base case.\n-\nHere, we convert the mixed algorithm for LPs to a mixed\nalgorithm for ILPs, establishing the right sample sizes and\ncriteria for successful iterations in both the recursive and\niterative part of the mixed algorithm.\n7/23\n\nILP Algorithm: Details\n-\nLemma 2, related to the LP recursive algorithm, needs to be\nredone due to the fact that is not unique.\n-\nReminder: why do we need lemma 2?\nWe want to make sure the set of violated constraints does not\nbecome too big.\n-\nLemma 2 (ILP version): Let and let be a\nrandom subset of size with\nLet\nbe the set of constraints violated by Then with\nprobability\n-\nOther necessary lemma's remain valid or can be adapted easily,\nyielding the following essential parameters for the ILP mixed\nalgorithm:\n- Recursive part: use Lenstra's algorithm for\nand require for a successful iteration.\n- Iterative part: with a corresponding bound\nof\n8/23\n\nILP Algorithm: Proof of Lemma 2 (ILP version)\n-\nProof. Lemma 2 (ILP version): With probability\n-\nAssume is empty. For not empty: similar proof.\nLet and let denote the\nnumber of constraints in violated by\nWe know that for some\nwith\nWe want to find such that the probability that\nis\nless then This probability is bounded above by:\nwhich is no more than:\n9/23\n\nILP Algorithm: Proof of Lemma 2 (cont'd)\nwhich is again no more than:\nand using elementary bounds, this quantity is less than\nfor\n10/23\n\nILP Algorithm: Running Time\n-\nWe have the following theorem:\nThe ILP algorithm requires expected\nrow operations on -bit vectors, and\nexpected operations on -bit numbers, as where\nthe constant factors do not depend on or\n11/23\n\nPart II: Incremental Linear Programming\n12/23\n\nIncremental LP\n-\nRandomized incremental algorithms for LP\n-\nConcept:\n- add constraints in random order,\n- after adding each constraint, determine the optimum of the\nconstraints added so far.\n-\nTwo algorithms will be discussed:\n- SeideLP\n- BasisLP\n13/23\n\nAlgorithm SeideLP\nInput: A set of constraints\nOutput: The optimum of the LP defined by\n0. if\noutput\n1. Pick a random constraint\nRecursively find\n2.1. if\ndoes not violate output\nto be\nthe optimum\n2.2. else project all the constraints of onto and\nrecursively solve this new linear programming problem;\n14/23\n\nSeideLP: Running Time\n-\nLet denote an upper bound on the expected running\ntime for a problem with constraints in dimensions.\n-\nThen:\n- First term: cost of recursively solving the LP defined by the\nconstraints\n- Second term: checking whether violates\n- Third term (with probability ): cost of projecting + recursively\nsolving smaller LP.\n-\nTheorem: There is a constant such that the recurrence\nsatisfies the solution\n15/23\n\nSeideLP: Further Discussion\n-\nIn Step 2.2. we completely\ndiscard any information obtained\nfrom the solution of the LP\n-\nFrom the above figure, it follows we must consider all\nconstraints in\n-\nBut: Can we use to \"jump-start\" the recursive call in\nstep 2.2.?\n-\nRESULT: Algorithm BasisLP\n16/23\n\nAlgorithm BasisLP\nInput:\nOutput: A basis for\n0. If output\n1. Pick a random constraint\nBasisLP( );\n2.1. if\ndoes not violate output\n2.2. else output BasisLP( Basis( ));\nBasis returns a basis for a set of or fewer constraints.\n17/23\n\nBasisLP: Why does it work?\n-\nEach invocation of Basis occurs when the violation test in 2.1.\nfails (i.e. does violate ).\n-\nWhat is the probability that we fail a violation test?\n- Let\n- Remember:\n- Pr(\nviolates the optimum of )\n- This probability decreases further if contains some of the\nconstraints of\n- This was indeed the motivation for modifying SeideLP to BasisLP.\n18/23\n\nBasisLP: Running Time\n-\nNotation:\n- Given , we call\nenforcing in if\n- Let denote minus the number of constraints that are\nenforcing in is called the hidden dimension of\n-\nLemma 1: If is enforcing in then (i) and (ii)\nis extreme in all such that\n-\nSo, the probability that a violation occurs\ncan be bounded by\n-\nWe establish that the decreases by at least 1 at each\nrecursive call in step 2.2. It turns out is likely to decrease\nmuch faster.\n-\nTheorem: The expected running time of BasisLP is\n19/23\n\nBasisLP: Analysis Details\n-\nProof of Lemma 1. If\nis enforcing in then\n- (i)\nWe have which can not be true if were a\nsubset of\n- (ii) is extreme in all such that\nAssume the contrary:\na\ncontradiction.\n20/23\n\nBasisLP: Analysis Details (Cont'd)\n-\nLemma 2: Let and let be an\nextreme constraint in Let be a basis of\nThen:\n(i) Any constraint that is enforcing in is also enforcing in\n(ii) is enforcing in\n(iii)\nProof:\n- (i)\nthen:\n- (ii) Since is extreme in\n- (iii) Follows readily.\n-\nSo, the numerator of decreases by at least 1 at\neach execution.\n21/23\n\nBasisLP: Analysis Details (Cont'd)\n-\nShow that this decrease is likely to be faster.\n-\nGiven and a random we bound the\nprobability that violates If it does, check the\nprobability distribution of the resulting hidden dimension.\n-\nLemma 3: Let be the extreme constraints of\nthat are not in numbered so that\nThen, for all and for is enforcing in\nBasis (proof: immediate from lemma 2.)\n-\nIn other words: when then all of\nwill be\nenforcing and the arguments of the recursive call will have\nhidden dimension\n-\nObservation: since any is equally likely to be is uniformly\ndistributed on the integers in and the resulting hidden\ndimension is uniformly distributed on the integers in\n22/23\n\nBasisLP: Analysis Details (Cont'd)\n-\nLet denote the maximum expected number of violation\ntests for a call to BasisLP with arguments where\nand\n-\nWe get:\n-\nThis yields:\nand consequently the expected running time of BasisLP is\nAugmenting the analysis with Clarkson's sampling technique\nimproves the running time of the mixed algorithm to\n23/23"
    },
    {
      "category": "Resource",
      "title": "Differential Evolution: a stochastic nonlinear optimization algorithm by Storn and Price, 1996",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/15-099-readings-in-optimization-fall-2003/c5b8927f32a15cab2545d57397d3cabb_ses2_storn_price.pdf",
      "content": "Differential Evolution:\na stochastic nonlinear optimization\nalgorithm by Storn and Price, 1996\nPresented by David Craft\nSeptember 15, 2003\nThis presentation is based on: Storn, Rainer, and Kenneth Price. Differential Evolution - A Simple and\nEfficient Heuristic for Global Optimization over Continuous Spaces. Journal of Global Optimization 11,\n1997, pp. 341-359.\n\nThe highlights of\nDifferential Evolution (DE)\nA population of solution vectors are successively updated by\naddition, subtraction, and component swapping, until the\npopulation converges, hopefully to the optimum.\nNo derivatives are used.\nVery few parameters to set.\nA simple and apparently very reliable method.\n\nDE: the algorithm\nStart with NP randomly chosen solution vectors.\nFor each i in (1, ...NP), form a 'mutant vector'\nvi = xr1+F.(xr2-xr3)\nWhere r1, r2, and r3 are three mutually distinct\nrandomly drawn indices from (1, ...NP), and\nalso distinct from i, and 0<F<=2.\n\nDE: forming the mutant vector\nvi = xr1+F.(xr2-xr3)\n. xr1\n. xr3\n. xr2\n.\n.\n.\n.\nSolution space\n. vi\n.\nxi\n\nDE: From old points to mutants\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\nDE: Crossover xi and vi to form\nthe trial vector\n.\n.\nPossible trial vectors\noriginal x\nmutant v\n\nDE: Crossover xi and vi to form\nthe trial vector ui\nxi = (xi1, xi2, xi3, xi4, xi5)\nvi = (vi1, vi2, vi3, vi4, vi5)\nui = (__, __, __, __, __)\nFor each component of vector, draw a random number\nin U[0,1]. Call this randj. Let 0<=CR<1 be a cutoff. If\nrandj<=CR, uij= vij, else uij= xij.\nTo ensure at least some crossover, one component of ui\nis selected at random to be from vi .\n\nDE: Crossover xi and vi to form\nthe trial vector ui\nxi = (xi1, xi2, xi3, xi4, xi5)\nvi = (vi1, vi2, vi3, vi4, vi5)\nSo, for example, maybe we have\nui = (vi1, xi2, xi3, xi4, vi5)\nIndex 1 randomly\nselected as definite\ncrossover\nrand5<=CR, so it\ncrossed over too\n\nDE: Selection\nIf the objective value COST(ui) is lower than COST(xi), then\nui replaces xi in the next generation. Otherwise, we keep xi.\n\nNumerical verification\nMuch of the paper is devoted to trying the algorithm on many\nfunctions, and comparing the algorithm to representative\nalgorithms of other classes. These classes are:\n-Annealing algorithms\n-Evolutionary algorithms\n-The method of stochastic differential equations\nSummary of tests: DE is the only algorithm which consistently\nfound the optimal solution, and often with fewer function\nevaluations than the other methods.\n\nNumerical verification: example\nThe fifth De Jong function, or \"Shekel's Foxholes\"\n(See equation 10 on page 348 of the Differential Evolution\npaper.)\n\nThe rest of the talk...\n-\nWhy is DE good?\n-\nVariations of DE.\n-\nHow do we deal with constraints?\n-\nAn example from electricity load management.\n\nWhy is DE good?\n-Simple vector subtraction to generate 'random' direction.\n-More variation in population (because solution has not\nconverged yet) leads to more varied search over solution\nspace.\n-∆= (xr2-xr3)\n[discuss: size and direction]\n-Annealing versus \"self-annealing\".\n\nVariations of DE\nxr1 : instead of random, could use best\n(xr2-xr3) : instead of single difference, could\nuse more vectors, for more variation.\nfor example (xr2-xr3+xr4-xr5)\nCrossover: something besides bernoulli\ntrials...\n\nDealing with constraints\n- Penalty methods for 'difficult' constraints.\n- Simple projection back to feasible set for\nl<=x<=u type constraints.\n- Or, random value U[l,u] (when, why?)\n\nExample: Appliance Job Scheduling\nHourly electricity prices\n(cents/kWh):\nPower requirements for\n3 different jobs (kW):\nStart time constraints.\n\nExample: Appliance Job Scheduling\nObjective: find start times for each job which minimize cost.\nCost includes a charge on the maximum power used throughout\nthe day. This couples the problems!\nmin\n( )\n( )\n. .\n1,...,\nJ\ni\ni\ni\ni\ni\ni\nt x\nD x\ns t a\nx\nu\ni\nJ\n=\n+\n≤\n≤\n=\n∑\nwhere\n( )\n( ) ( ,\n)\ni\ni\ni\nx\nl\ni\ni\ni\ni\nx\nt x\np t e t x dt\n+\n= ∫\nCost of job i\nstarted at time xi\n[0, ]\n( )\nmax\n( ,\n)\nt\nT\ni\ni\nD x\nr\ne t x\n∈\n= ⋅\n∑\nDemand charge\n\nConvergence for different F\nOther settings:CR=0.3, NP=6\n\nAppliance Job Scheduling: Solution\nSolution\nTotal energy profile\nElectricity price over time\n\nWrap-up\n-DE is widely used, easy to implement, extensions and variations\navailable, but no convergence proofs.\n-More information:\nDE homepage: practical advice (e.g. start with NP=10*D and\nCR=0.9, F=0.8), source codes, etc.\nhttp://www.icsi.berkeley.edu/~storn/code.html\nDE bibliography, 1995-2002. Almost entirely DE applications.\nhttp://www.lut.fi/~jlampine/debiblio.htm"
    }
  ]
}