{
  "course_name": "Data Storytelling Studio: Climate Change",
  "course_description": "This course explores visualization methodologies to conceive and represent systems and data, e.g., financial, media, economic, political, etc., with a particular focus on climate change data in this version of the course. Topics include basic methods for research, cleaning, and analysis of datasets, and creative methods of data presentation and storytelling. The course considers the emotional, aesthetic, ethical, and practical effects of different presentation methods as well as how to develop metrics for assessing impact. Coursework includes readings, visualization exercises, and a final project.",
  "topics": [
    "Fine Arts",
    "Game Design",
    "Media Studies",
    "Visual Arts",
    "Graphic Design",
    "Social Science",
    "Anthropology",
    "Ethnography",
    "Communication",
    "Fine Arts",
    "Game Design",
    "Media Studies",
    "Visual Arts",
    "Graphic Design",
    "Social Science",
    "Anthropology",
    "Ethnography",
    "Communication"
  ],
  "syllabus_content": "Course Meeting Times\n\nLecture / Activity: 2 sessions / week, 1.5 hours / session\n\nPrerequisites\n\nNone.\n\nThe course is open to all technical levels and backgrounds. We will prioritize students with a strong background in one or more of the following areas: journalism, software development, data analysis, documentary, visual and performing arts.\n\nCourse Description\n\nWe are swimming in data -- \"Big\" and small, global and personal. And we are also facing complicated problems like climate change and inequality whose stories can only be told with data. The need for public understanding of data-driven issues is higher than ever before. But raw data doesn't make a good story... and that's where you come in.\n\nThis class is focused on how to tell stories with data to create social change. We will learn through case studies, examples and hands-on work with tools and technologies. We will introduce basic methods for research, cleaning and analyzing datasets, but the focus is on\ncreative methods and media for data presentation and storytelling.\nWe will consider the emotional, aesthetic and practical effects of different presentation methods as well as how to develop metrics for assessing impact.\n\nOver the course of the semester, students will work in small groups to create 5 sketches, each using a different technique for telling a data-driven story. Think about a \"sketch\" as a half-realized project; where you have implemented just enough of the most important details of the idea in order for us to understand your vision. A sketch is NOT a fully realized presentation of a data story. For the final project, students will have the chance to expand upon one of these sketches to create a fully realized presentation of a data-driven story.\n\nThis semester, Spring 2017, will have a special focus on climate change data\n. Most examples will use data related to this topic, homeworks will be related to it, and sketches and final projects must be connected to it as well. We will take a broad view of that topic, including everything from traditional datasets about the warming oceans, to data on migration caused by the effects of climate change.\n\nLearning Objectives\n\nStudents will learn techniques for finding a story in data, building a basic set of tool-assisted data analysis skills.\n\nStudents will build things that tell data-driven stories with a rich set of digital and non-digital tools, online and offline.\n\nStudents will practice arts- and rhetoric-based approaches to telling data-driven stories.\n\nStudents will learn to connect data stories to meaningful, situated social action.\n\nStudents will learn basic techniques for measuring the impact of data-driven storytelling.\n\nStudents will learn basic ethnographic and anthropological approaches to identifying and researching audiences.\n\nCourse Requirements\n\nThis is a hands-on studio course and we will do a lot of peer production of knowledge, so your participation and presence is essential to making it a success. Each of the main technique-focused sketches will include an introduction to approaches and tools, but then focus on a small group project that you will present for discussion and criticism to the class. The course culminates in a final project that will be a presentation of a data-driven story in some media, for a particular audience with a set of goals. Each project must be done in a group of two or more. I encourage you to work with different people for each project.\n\nHere's a description of these modules and the associated required coursework.\n\nMODULES\n\nREQUIRED COURSEWORK AND GRADING CRITERIA\n\nFinding and Telling Stories with Data\n\nIn this initial set of classes, we get acquainted with an arc of inquiry that leads from questions and data to visual arguments using data.\n\nHands-on activities, readings, and discussion of case studies\n\nCharts and Creative Charts\n\nThis includes traditional charts (bar chart, line chart, etc), novel charting (sankey diagram, tree diagram, etc), and explanatory graphics and infographics.\n\nSmall group project sketch, graded on:\n\nHow centrally the data is featured\n\nThe appropriateness and effectiveness of your use of the charting technique for the story you are trying to tell\n\nData Sculptures\n\nThese are physical objects that represent the data in some way that tells a story. These could be made with cardboard and scissors, or digital design tools and a 3D printer.\n\nSmall group project sketch, graded on:\n\nHow centrally the data is featured\n\nThe appropriateness and effectiveness of your use of the charting technique for the story you are trying to tell\n\nThe cohesiveness of your story\n\nThe appropriateness of the implementation for your audiences\n\nPersonal Stories\n\nThese are evocative images, quotes, and stories that connect your audience to the reality of some dataset.\n\nSmall group project sketch, graded on:\n\nHow centrally the data is featured\n\nThe appropriateness and effectiveness of your use of the medium for the story you are trying to tell\n\nThe cohesiveness of your story\n\nThe appropriateness of the implementation for your audiences\n\nParticipatory Data Games\n\nThese could be anything from online quizzes, to activities where participants represent the data with their bodies.\n\nSmall group project sketch, graded on:\n\nHow centrally the data is featured\n\nThe appropriateness and effectiveness of your use of the mapping technique\n\nThe cohesiveness of your story\n\nThe appropriateness of the implementation for your goals\n\nThe appropriateness of the implementation for your audience\n\nMaps and Creative Maps\n\nThis includes traditional map-making, paper-based map creation, and unmapping techniques that break some of the classic rules of mapping (but still use their visual language).\n\nSmall group project sketch, graded on:\n\nHow centrally the data is featured\n\nThe appropriateness and effectiveness of your use of the mapping technique\n\nThe appropriateness of the implementation for your goals\n\nThe appropriateness of the implementation for your audiences\n\nFinal Project Studio\n\nThe final group of classes is set up as a studio, focused on finding and telling your data story in order to create your final group project.\n\nThe final project will integrate many of the skills and approaches we cover throughout the semester. I anticipate that one of the small projects you do in the technique modules will grow into your final project, but that doesn't have to be the case. The final project is NOT a sketch; you should be creating a real, functioning version of the idea you have in mind. The final module will consist mostly of in-class studio time to work and get feedback on your progress. This final project must gather, analyze, and synthesize various civic datasets into a data-driven presentation.\n\nSee the\nFinal Project Requirements\npage for more details.\n\nSmall group project, which may iterate on one of your earlier project sketches. It will be graded on:\n\nHow centrally the data is featured\n\nThe appropriateness and effectiveness of your use of the mapping technique\n\nThe appropriateness of the implementation for your goals\n\nThe appropriateness of the implementation for your audiences\n\nThe appropriateness of your impact assessment techniques (ie. NOT the outcomes of your impact assessment)\n\nAssessments of your contributions by your team members\n\nGraduate Student Paper Reviews\n\nThis class is offered to undergraduates and graduate students, meeting together. Graduate students will be expected to offer more substantial work for all assignments. In addition to this, most classes will include extra readings for graduate students. For each class with such a reading, one graduate student will be picked to present a short review and any meaningful takeaways from that paper. This short presentation can be informal, and should include:\n\nA review of the main argument of the reading\n\nYour thoughts on any applications or \"good to know\" takeaways from the reading\n\nAt least one question to spark discussion about the reading's topic\n\nFor graduate students, this presentation will count towards your participation grade.\n\nGrading\n\nGrading is broken down as described in the table below. Evaluation criteria for each assignment is detailed within the\nCourse Requirements section\nabove.\n\nGroup\n\nWeight\n\nIn-class participation, attendance, peer-assistance, and graduate student paper reviews\n\n20%\n\nInitial Assignments\n\nHomework 1: Data Visualization blog post\n\nHomework 2: Data log blog post\n\n15%\n\nTechnique Sketches with Writeups\n\nCharts and creative chart project\n\nData sculpture project\n\nPersonal story project\n\nMaps and creative maps project\n\nParticipatory game project\n\n45%\n\nFinal Project\n\nData blog posts\n\nSketch presentation\n\nFinal presentation\n\nMethodology and impact narratives\n\nTeammate review\n\n20%\n\nCourse Policies\n\nYou are expected to produce your own original work for each assignment. For group projects you are expected to contribute to the team's effort in valuable ways. Raise any concerns about team members on group projects to me privately as soon as possible. All students will be held to the standards of\nMIT's Academic Integrity Handbook (PDF)\n.\n\nPlagiarism\n\nPlagiarism -- use of another's intellectual work without acknowledgement -- is a serious offense. It is the policy of the CMS/W Faculty that students who plagiarize will receive an F in the subject, and that the instructor will forward the case to the Committee on Discipline. Full acknowledgement for all information obtained from sources outside the classroom must be clearly stated in all written work submitted. All ideas, arguments, and direct phrasings taken from someone else's work must be identified and properly footnoted. Quotations from other sources must be clearly marked as distinct from the student's own work. For further guidance on the proper forms of attribution, consult the style guides available in the MIT Writing and Communication Center and the\nMIT Website on Plagiarism\n.\n\nTechnology Policy\n\nLaptops, tablet, or cell-phones may be used for note-taking during discussions. That said, there will be \"zero-tech\" times during classes when you are required to put away / shut-off all technology in order to engage in discussion, criticism, etc.\n\nAttendance Policy\n\nEmail the instructor as soon as you know that you will be absent for any reason. Your participation grade will go down by 15 points with each unexcused absence (out of a total of 50) but there are opportunities to make up some lost points by doing extra credit assignments. If you miss an in-class assignment such as a presentation or group exercise you should be prepared to take a 0 for it.\n\nGetting Help\n\nI will be available for help over email; no office hours are scheduled. For writing assistance please use the MIT Writing and Communication Center.",
  "files": [
    {
      "category": "Resource",
      "title": "Data Science for Good: What Problems Fit?",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/cms-631-data-storytelling-studio-climate-change-spring-2017/45bf2a265814787684eb9b7e0ec9f44b_MITCMS_631s17_koschinsky_2015.pdf",
      "content": "Data Science for Good:\nWhat Problems Fit? \nJulia Koschinsky, Ph.D.\nGeoDa Center for Geospatial Analysis and Computation \nArizona State University\n \nP.O. Box 875302, Tempe, AZ 85287\n(480) 965-7533 \njulia.koschinsky@asu.edu\n1. ABSTRACT\nMaking sense of emerging sources of big, open, and\nadministrative data has become paramount. This analysis assesses\nkey characteristics of projects that are widely assumed to generate\nnew and actionable insights and have social impacts. I review 72\nuse cases by prominent organizations in the \"data science for\ngood\" community to determine the types of problems where data\nscience techniques add value. The four main categories I identify\nare 1) improving data infrastructure by combining data with\nhigher temporal and spatial resolution and automating data\nanalysis to enable more rapid and locally specific responses, 2)\npredicting risk to help target prevention services, 3) matching\nsupply and demand more efficiently through near-real time\npredictions for optimized resource allocation, and 4) using\nadministrative data to assess causes, effectiveness and impact. In\nalmost all cases, the insights that are generated are based on an\nautomated process, are localized, in near real-time and\ndisaggregated.\nKeywords\nData science, problem, actionable insight, impact\n2. THE CHALLENGE\nMaking sense of big data, open data, administrative data, social\nmedia data and combinations of these data has become paramount\n[1]. We are not only looking for insights but for actionable\ninsights that can augment existing government and nonprofit\npractices. Government and nonprofits are not alone in figuring out\nthis puzzle: According to a 2011 survey of 3,000 companies in 30\nindustries and 100 countries, for almost four of 10 respondents,\n\"the leading obstacle to widespread analytics adoption is lack of\nunderstanding of how to use analytics to improve the\nbusiness\" [2]. Even if one can figure out how to gain not only new\nbut actionable insights from data, another challenge is the\ntranslation of these insights into impacts. Insights need to be\n\"closely linked to business strategy, easy for end-users to\nunderstand and embedded into organizational processes so that\naction can be taken at the right time.\" [2].\nA key reason why it is non-trivial to translate data analytics results\ninto insights and impacts for social good is that this effort requires\ncollaboration across traditionally siloed disciplines, skillsets and\ndepartments with their own jargons, cultures and ways of\nthinking. In order to inform a social or public problem with data\nanalytics, this problem needs to be defined from the perspective of\nthe people making decisions that influence the problem resolution,\nso that technological and statistical solutions can ultimately be\nembedded within these decision workflows. Not all techniques in\nthe toolboxes of computer and data scientists meaningfully inform\nBloomberg Data for Good Exchange Conference.\n28-Sep-2015, New York City, NY, USA.\npublic and nonprofit problems. Therefore the question arises\nwhich types of public and nonprofit questions and problems can\nbe informed by data science.\nLike technology, data science does not improve social outcomes\nby itself. At its best, it augments existing implementation\nprocesses [3]. Figuring out which organizational processes are\nparticularly prone to such an augmentation and which agencies\nare ready to adopt or expand data-driven cultures is important to\ntranslating insights into impacts. And even when data analytics\nproves to make existing operational processes more efficient, the\nquestion still remains whether the outcomes are socially and\npolitically desirable or not [4]. This skepticism is reflected in the\ngrowing criticism of Minority Report-style surveillance (informed\nby predictive modeling of crime such as in Chicago) and of the\n\"governance of algorithms,\" which are often black-boxed and\noutside of the realm of accountability to residents [5, 6].\nAnother prominent critique of technological and data-driven data-\nfor-good projects is that they promote a perspective that assumes\nthat \"there's an app\" for every problem [7]. There is a tendency to\noffer band-aid solutions that, for instance, might help manage the\nprocess of serving a few homeless persons a little better but ignore\nlong-term structural problems such as inequality, racial\ndiscrimination or shifts to lower paying service sector jobs that\ncannot be easily fixed with a civic tech tool or predictive model\ndeveloped during a hackathon weekend.\nAs more cities are displaying the results of quantitative indicators\non dashboards, critics point out that the choices about what data\nare collected, how indicators are measured, what goals they\nrepresent, and how they are displayed are innately political rather\nthan merely technical [8, 9]. Arguments to \"just let the data speak\"\nas if they were objectively representing an independent truth are\nmisleading.\n3. QUESTION AND METHODOLOGY\nThis analysis assesses key characteristics of projects that are\nwidely assumed to generate new and actionable insights and have\nsocial impacts. To do so, I conduct a preliminary review of 72 use\ncases by prominent organizations in the \"data science for good\"\ncommunity to determine the types of problems where data science\ntechniques add different kinds of value. I chose organizations that\nfocus on data science methods such as machine learning or\npredictive modeling and impact measurement. Efforts that\nprimarily specialize in the visualization of raw data or basic\nstatistical analysis are not included. Related projects in civic tech\n(such as Code for America's) are also excluded since most of\nthese projects focus more on technological advances to\ngovernment problems than on data analytics.\nFour organizations were chosen that represent well-known efforts\nin the data-for-good community: DataKind, Bayes Impact, the\nData Science for Social Good (DSSG) Fellowship (University of\nChicago), and New York's Mayor's Office of Data Analytics\n\n(MODA). This is a convenience sample that is not designed to be\nrepresentative. It will be extended over time as more projects are\ndocumented online. However, it is noteworthy that there is already\nsubstantial overlap in the questions and problems addressed by the\nfour organizations, suggesting that the sample does effectively\ncapture some common trends.\nTo identify the universe of use cases for this paper, I chose the\nprojects listed on the organization's websites in mid-July 2015\n(specifically the seven winning projects of the 2014 Bayes Impact\n24-hour Hackathon , 23 projects on DataKind's project page , 38\nfellowship projects of DSSG , and four projects from MODA's\n2013 Annual Report ). Table 1 contains the categorization, name,\nagency, sponsor, problem, short description, data, and method\nused in each of these projects.\n4. FINDINGS\n4.1 Types of Problems\nThe four main categories that I identify to classify the 72 use\ncases in terms of the problems that data science helps to address\nare 1) improving data infrastructure by combining data with\nhigher temporal and spatial resolution and automating data\nanalysis to enable more rapid responses, 2) targeting limited\nresources to highest risks for prevention efforts, 3) matching\nsupply and demand more efficiently through near-real time\npredictions for optimized resource allocation, and 4) using\nexisting data to assess performance and impact. In almost all of\nthe cases, the insights that are generated are based on an\nautomated process, are localized, in near real-time and\ndisaggregated. This section discusses these findings in more\ndetail.\nThe range of problem areas of the use cases is so broad that the\nchoice of problem area does not seem to be a constraining factor.\nHow the problem is defined and what data are available within a\ngiven problem area seems to be more relevant. Common problem\nareas in the sample include health problems, non-completion of\nschool or service programs, government corruption, human rights\nviolations, neighborhood blight (abandoned properties), access to\nfunding for nonprofits, poverty and homelessness, as well as\ngovernment operations (such as fire, building codes, and\npolicing).\nOne of the key differences between traditional quantitative\nanalysis in the social sciences (e.g. using multivariate regression\nmodels) and the use cases analyzed here is that their reliance on\nmachine learning methods comes with a shift in focus from\ndescriptive to predictive and prescriptive insights [10].\nDescriptive insights address the question what has happened and\nwhy; predictive insights focus on what could happen while\nprescriptive insights inform choices about how to respond to what\nhas happened or could happen. The vast majority of use cases in\nthis sample produce prescriptive or predictive insights, i.e.\ninsights that are (or at least appear to be) actionable without\nrequiring additional analysis. Projects often include the full\npathway from identifying patterns in past and current data (e.g.\nwhy students dropped out of school in the past) to predicting\n1 http://bayeshack.devpost.com/submissions\n2 http://www.datakind.org/projects/\n3 http://dssg.io/projects/\nfuture behavior (e.g. risk scores of who might soon drop out) to\ninforming intervention strategies (e.g. to help prevent drop-outs).\nThe use cases general fit Santos' [3] criteria for actionable results:\nThey a) inform a better-than-usual selection of response that b)\ncan be implemented in a feasible and efficient way and that c) are\nrelated to an improved outcome. One of the reasons why the\nresults are actionable is the reliance on disaggregated units of\nanalysis rather than aggregates, which is driven by the increasing\navailability of electronically generated data at this scale. This\ndisaggregation makes insights actionable at the individual level\nsince it focuses the analysis on a unit that matches that of\ndecisionmakers. An example is the disaggregation of smart meter\nreadings for the total household to estimate the energy that could\npotentially be saved by individual appliances.\nThese are the four categories I identify to characterize the types of\nproblems and value added by data science in the sample (letters\nalso used in Table 1):\nA. Improving data infrastructure to enable faster and\nlocal responses\nby combining data with higher temporal and spatial\nresolution and automating data analysis to enable more\nrapid and locally specific responses\nB.\nPredicting risk to help target prevention services\nassisting a service provider with targeting of limited\nprevention resources based on prediction of elevated risk\nC.\nDetecting space-time clusters to help match supply\nand demand\npredicting optimized allocation of resources to better\nmatch supply and demand across a complex system\nD. Using administrative data to assess causes,\neffectiveness and impact\nimproving services or systems through an assessment of\neffectiveness based on analysis of existing administrative\ndata or combining past data on process and outcome\nThese categories are not mutually exclusive: The same use case\ncan be part of multiple categories at different stages. For instance,\na case could start with building a data infrastructure, then proceed\nwith estimating elevated risks in sub-samples and conclude with\nassessing the effectiveness of service delivery. To reflect this,\nsome use cases in Table 1 are classified in more than one category.\nThis following sections illustrate each of these categories with\nexamples (see Table 1 for more details).\nImproving Data Infrastructure to Enable Faster and Local\nResponses\nSeveral use cases pertain to automating and centralizing data\naccess, usually for data that are more location-specific and timely\nthan traditional censuses (although often not as complete).\nExamples include the creation of a central atlas of businesses in\nNew York after Hurricane Sandy as part of post-disaster aid and\nthe merging of data for different medications to identify negative\nside effects of interactions between them. There are also examples\nof improving automated measurement, e.g. testing the\nmeasurement of poverty with proxies from satellite images such\n4http://www.nyc.gov/html/analytics/downloads/pdf/ annual_report_2013.pdf\n\nas roof type or light patterns; or generating inflation estimates in\nnear-real time with greater local accuracy through web scraping.\nThis data infrastructure and analysis serves as the foundation for\nwork in other categories, such as targeting resources or assessing\nprogram effectiveness. For instance, the automated process of\nidentifying roof types was used to help a nonprofit allocate\nresources to households with less wealth (measured by living in\nhomes with thatched as opposed to metal roofs).\nPredicting Risk to Help Target Prevention Services\nA very common use case that all four organizations worked on is\nrelated to assisting stakeholders with prioritizing where limited\nprevention resources should be targeted based on predicted\nelevated risk of an undesirable outcome. The typical scenario here\nis that a nonprofit or government intervenes to address a problem\nsuch as a fire, structurally unsafe home, school non-completion, or\nhuman rights violation. Interventions involved sending fire and\nhousing inspectors to homes to detect unsafe conditions in\nadvance, having school counselors help at-risk students stay on\ntrack for graduation, or using publicity campaigns to put public\npressure on representatives to stop human rights violations as they\nwere automatically tracked in near-real time. The problem in these\ncases is that the intervention is limited to a sample of the total\npopulation due to resource constraints. Data science is used to\nfirst model the determinants of elevated risk based on past\nincidents and then use the results from these models to predict\nrisks for new cases. As part of an early warning system, an\nestimated prediction of highest risk helps identify which sub\ngroups to prioritize.\nUse case examples include the estimation of risk scores for\nindividual students (for dropping out of school or college\nundermatching), patients (for adverse health outcomes such as\nobesity or maternal mortality), offenders (for re-committing\ndomestic violence) or officers (for police brutality). Other\nexamples quantify the risk that a particular home will be\nabandoned, catches fire, violates housing codes, or contains lead;\nthat an accident occurs in a mine; that a company fails to report\nhazardous waste; or that an area is subject to concentrations of\n311 complaints or disaster impacts. A good example of an early\nwarning system is a use case where phone-based sensors to track\nthe temperature of vaccine coolers in Africa are used to predict\npower outages (DataKind, NexLeaf and MedicMobile). This\ninformation allows stakeholders to intervene in advance and\nprevent vaccine spoilage. A related group of use cases is the\nsearch for targets with elevated risk of engaging in illegal\nactivities, providing enough information to identify existing or\nemerging targets. In this case data patterns are used to identify\npotential child prostitution rings by location and phone number,\nprobable fraud in contract bidding by contractor, or likely money\nlaundering by particular businesses.\nDetecting Space-Time Clusters to Help Match Supply and\nDemand\nIn a set of related use cases data analytics helps to match supply\nand demand more efficiently by optimizing the allocation of\nresources across an entire complex system in near-real time. In\nthese cases there is typically a supplier of a good or service and a\npopulation of people or entities using this service. In contrast to\nthe previous example, the goal here is not to identify an at-risk\nsample within this population but to more optimally distribute\ngoods or services across the entire population. The problem here\nis that the use of services varies across space and time, leading to\nmismatches between supplied services and demand for them. Data\nanalytics identifies when these concentrations in demand are\nlikely to occur to help optimize the matching supply of services.\nFor instance, such matching can occur between buses and riders to\navoid overcrowding; between shared bikes and stations to aid\nrebalancing; between employers and job seekers aided by training\nprograms; between surplus food and nearby food banks; or\nbetween hospices and terminally ill children. In one example,\ntraditional federal labor census data were supplemented with\nonline data streams from employment sites to provide workforce\nagencies with more localized and timely information on how to\nbetter target their services (DSSG, Department of Labor,\nCareerBuilder and Skills for Chicagoland's Future).\nUsing Administrative Data to Assess Causes, Effectiveness and\nImpact\nAnother common use case pertains to program or systems\nevaluation and impact measurement using existing data collected\nfor other purposes. The goal here is to improve a sponsor's service\ndelivery through an assessment of the effectiveness of its services\nbased on administrative data they or others have been collecting\nas part of service delivery. This is more affordable than to collect\nnew data solely for evaluation purposes, as is often the case. In\nmany of these examples services were delivered with the help of\ntechnology (through phone message texting, mobile apps, or\nwebsites). As a result, databases of users and a log of the service\ndelivery itself were collected automatically. The question to be\naddressed through data science is how services can be delivered\nmore effectively, e.g. to prevent dropping out of services, avoid\ndisconnects between mentors and students, or improve a\nprovider's chance of obtaining crowd-sourced funds online.\nExamples include the mining of text messages or other electronic\nadministrative data to identify successful practices (e.g. nonprofit\nfundraising) or interactions (e.g. between tutors and students,\ncrisis mentors and teens) among some stakeholders that can be\nused to improve sub-optimal practices or relations among others.\nIn related examples of impact measurement, DataKind helped the\nhealth nonprofit Nurse-Family Partnership determine that its\nprograms increased children's vaccine rates. It also assisted the\nNew York City Parks Department in an evaluation of the impact\nof tree pruning, which turns out to reduce the risk of hazardous\ntree conditions during storms in New York City. Furthermore, new\nsmall businesses that utilized the New York City Business Atlas\nwere able to open two and a half months earlier than those not\nutilizing the atlas (MODA).\nParticularly interesting examples of program or systems\nevaluation combined data sources in a way that connected an\noutcome with data on the process that helped generate this\noutcome. This connection provides insights into the full life cycle\nof a problem to aid program or system reform: For instance, one\nuse case designed more effective homeless prevention services by\nlinking data from two service providers that were assisting people\nbefore and after they became homeless. Another case merged data\non financial contributions with that on voting behavior to\ndocument the influence of contributions on voting decisions and\ntrack this relationship for each political representative. When\ninfluence on voting is purchased, this documents a conflict with\nhow the political process is supposed to function, warranting\nreform. A third example combined judgments on human rights\nviolations by the European Court of Human Rights with data on\nwhether the judgment was enforced. Again, here the effectiveness\nof judgments is assessed in terms of their implementation. One of\nthe reasons why these connections had not been made before is\nbecause of the technical challenge of combining datasets without\ncommon IDs, data structures and formats.\n4.2 Sponsors and Data\nAll but three projects had a sponsoring agency, which typically\ndefines the problem or question, often shares internal data, and\n\nuses the results. Some projects are designed to automate the\nprocess of generating analytic results, so the process can be\nintegrated with day-to-day operations (e.g. DataKind's project\nwith Benetech or MODA's project with New York's fire\ndepartment).\nAlmost all projects are based on individual-level units of analysis\nthat can be identified by their characteristics and/or location (such\nas persons, businesses, parcels, bikes, contracts, or organizations).\nA few projects analyze aggregated data to identify overall trends\nin a country or region, e.g. in risk factors of maternal mortality\n(sponsored by Mexico's Office of the President and implemented\nby DSSG), mismatches between terminally ill children and\nhospice services in the U.K. (DataKind), or child poverty across a\ncity or country (DataKind's work for DC Action for Children and\nNorth East Child Poverty Commission). Some combine\naggregated with disaggregated data to first target a geographic\narea and then identify particular individuals at risk within these\nareas (e.g., DSSG's analysis to help the Illinois Department of\nHuman Services target its services for improved birth outcomes).\nSince DSSG is located in Chicago, many of DSSG's projects are\nconducted in collaboration with sponsors in Chicago. Similarly,\nall of MODA's projects are in New York City although other cities\nhave started to adopt some of their best practices (e.g. the City of\nNew Orleans improved its distribution of smoke detectors through\nestimates of fire risk that were informed by MODA's efforts and\naided by Enigma.io). DataKind has the largest share of\ninternational projects, including several projects in Africa,\nSoutheast Asia, and the UK (reflecting the work of its\ninternational chapters in the UK, Bangalore, Singapore, and\nDublin). DSSG worked with international sponsors from Mexico,\nQatar, Australia, and Costa Rica. Especially the projects\nsponsored by human rights nonprofits had a global focus (e.g. by\nAmnesty International, Ushaidi, or Benetech).\nHalf of the sponsors were nonprofits. Many of these nonprofits\nshared administrative data that they had collected for operational\npurposes and were now looking to re-analyze to answer other\nquestions. For instance, Bayes Impact used logs from\nDonorsChoose, a crowdfunding platform for teachers, to predict\nthe funding success of proposed projects as they are being\nproposed to allow teachers to adjust their project descriptions in\nreal time (DataKind also worked with this sponsor but not as part\nof their listed projects). Another example mentioned before is\nNexLeaf, a nonprofit that uses cell phones to monitor\ntemperatures in order to prevent vaccine spoilage due to power\noutages in Africa. DataKind helped develop an early warning\nsystem using NexLeaf's text message data.\nOf the other half of sponsors, 36% were government agencies.\nThe majority were local governments, including many police\ndepartments and school districts that shared internal data for re\nanalysis. Health departments, transit agencies, and planning\ndepartments (concerned with addressing housing abandonment)\nwere also frequently represented, often using a combination of\ninternal and open city data (such as 311 or parcel data). New\nYork's Mayor's Office of Data Analytics specialized in helping\ncity agencies improve operations through analytics with internal\nand open data from the fire department, buildings, and emergency\nmanagement. One of the challenges for managing an open data\ninfrastructure like New York's is related to data quality and\ndecentralized cleaning of data. Data-for-good projects are one of\nmany efforts involved in cleaning open data but there is often no\ncentralized way to access cleaned data, annotated metadata or\ncode/workflows to clean updated versions of the same data. As a\nresult, there is a lot of duplication of efforts that could be\nstreamlined more.\nThe federal Department of Labor also sponsored a project to\nestimate risks of mining accidents to prioritize targeting of\ninspector visits (Bayes Impact). In another project they sponsored\nDSSG started developing an open source real-time labor market\ninformation system to help match local labor demand and\neducation/job training more efficiently. The only private agency in\nthe sample was the World Bank (4 projects), with two projects on\ndetecting fraud in contract bidding (DSSG), one on automating\nthe measurement of poverty through detection of light patterns\nand one on measuring inflation faster and more locally through\nscraped web data (both DataKind). Three projects were sponsored\nby public-private/nonprofit partnerships, for instance involving\ncollaborations between the City of Memphis and community-\nbased organizations to address blight and housing abandonment\n(DSSG). In Chicago, Skills for Chicagoland's Future received data\nfrom the online employment site CareerBuilder to assess which\nadditional skills job seekers need to secure a job (DSSG).\nThe three projects without a sponsor were general public interest\nprojects. In two cases they were based on open data, to predict\nside effects of drug interactions and identify potential money\nlaundering (both Bayes Impact). In one case users had to submit\ntheir own building energy use data to obtain recommendations for\nwhere energy could be saved (DSSG).\n4.3 Methods and Tools\nMachine learning or predictive modeling was the most frequently\nused method in the sample, especially for predicting/preventing\nrisk and for better matching supply and demand (categories B and\nC). Common examples of specific methods include decision tree\nlearning, optimization and cluster algorithms, natural language\nprocessing, and neural networks. One of the most common use\ncase was the generation of scores to estimate risks. Exploratory\ndata analysis and data or map visualizations were also used often,\nsometimes in preliminary analyses or to present and communicate\nthe results. Several projects conducted remote sensing analysis to\nclassify images for improving the measurement of poverty.\nPropensity score matching was most often used for those projects\nseeking to measure impacts.\nMany project descriptions (e.g. DataKind's) do not contain details\nabout the tools that were used for the analysis. Hence the\ninformation summarized here is based on the small subset of\nprojects that does mention what tools were applied. One of the\nnoteworthy trends that emerged from the assessment of this subset\nis the common use of open-source tools and open-source code,\nwhich enables the sharing of code and replication of the analysis\nin other places and contexts. Many projects make their code\navailable on GitHub. Since all groups (except for Bayes Impact's\nhackathon) are engaged in ongoing data science projects, there are\nmultiple efforts to scale existing projects and replicate them in\nother domains, coding events, or cities. These efforts are aided by\nplatforms to help organizations replicate data-for-good projects\n(such as the datalook.io website).\nProjects relied on 1) Python tools (e.g. pandas for data processing\nand analysis, scikit-learn for machine learning, NLTK for natural\nlanguage processing, scraperwiki for scraping web pages,\nmatplotlib for statistical graphics, and the flask web framework);\n2) Data-Driven Documents (d3.js javascript library) for web-\nbased data visualization; 3) R packages for statistical analysis\n(e.g. gbm (Generalized Boosted Models), ggmaps for statistical\nplots, and Matching for propensity score matching); and 4) cloud\nmapping solutions such as Mapbox and OpenStreet Map for web\nmapping, Foursquare's Quattroshapes for geocoding, and\nElasticsearch gazetteer for geographic indexing.\n\n4.4 Limitations\nThis analysis was designed as a preliminary overview of some\nimportant state-of-the-art projects in the data science for good\ncommunity in the U.S. and some of its international partners. It is\ncharacterized by several limitations: In many cases, the project\ndescriptions were very short (e.g. less than a page), which could\nresult in misclassifications (e.g. regarding project scope or\norganizations involved in the project) and has led to missing data\n(e.g. on methods and tools that were applied). Since some of the\n2015 DSSG projects are still ongoing, a more detailed project\ndescription will only become available later in 2015. Further,\nsince the categorization of projects is part of a first preliminary\nreview it is somewhat ad hoc and subjective. It will be tested and\nadjusted with additional use cases in the near future.\n5. CONCLUSION\nOf all of the use cases in the sample, the ones that are most\ncontroversial are those closest to surveillance and most at risk of\nviolating privacy rights. Many of the crime-related examples fall\ninto this category. For instance, Chicago's police department has\nbeen criticized for sending officers to the homes of potential\noffenders based on modeling results, which suggested that these\nresidents could be likely to commit an offense. The possibility that\nthe intervention itself might further facilitate the undesired\noutcome is often ignored here. But even the estimation of which\nstudents are at risk of dropping out of school or services could be\ncontroversial depending on how the intervention in response to\nthe risk estimation is structured (e.g. whether students are\ninformed about the availability of services with or without letting\nthem know that they are estimated to be at risk of dropping out).\nThe extent to which data-science-for-good insights are translated\nto actual impacts is related to how much a project's solution is\nembedded within the decision processes of institutions that have\nimpacts. Ironically, this integration and related project scoping\nand networking tends to take much more time than the technical\nimplementation of a data-driven solution. The four agencies that\nimplemented the 72 projects differ in their approach: On the one\nhand, Bayes Impact conducted a 24-hour hackathon. Within this\nframework, there is no time for an in-depth understanding of the\nagency processes that a data-driven solution could augment.\nOn the other hand, Mike Flowers who directed MODA under the\nBloomberg administration spent a significant amount of time\nunderstanding workflows, networking with stakeholders and\nbuilding trust to prepare for a meaningful integration of data-\ndriven strategies and outcomes within agencies. As expected, the\nhackathon results run the risk of having a short-lived impact\nunless someone continues the development in another forum (e.g.\nmany of the Bayes Impact project links are already broken). On\nthe other hand, MODA's impact, for instance, on the New York\nfire department and New York's open data infrastructure\n(DataBridge) have been sustained because they were\ninstitutionalized.\nDataKind and the Data Science for Social Good fellowship fall in-\nbetween these two examples. While DataKind also conducts\nhackathons, they employ full-time staff to spend several months\nscoping projects with a focus on sustained impacts after the\nvolunteer contributions. In addition, the organization has been\nmoving towards longer-term engagements with their own data\nscientist staff (Data Corps). The DSSG fellowship engages data\nscientists for three months. It also provides staff support for\nproject scoping and management to ensure that project results are\nrelevant to sponsoring agencies and that they are integrated within\na sponsor's decision processes. Several projects are extended over\nmultiple summers.\nThe \"killer app\" critique [6] is related to the extent of this\nintegration effort: Arguably, the more non-technical work is\ninvested in the integration of the sponsor's decision processes\n(understanding the process, networking, trust building, etc.), the\nmore data-driven solutions have a chance of improving the\ndelivery of infrastructure services (like 911 response times,\nfighting fires or issuing licenses to new businesses more\nefficiently) or nonprofit services (like preventing vaccine spoilage\nor disseminating micro grants).\nThe political dimensions of the choices embedded in data-driven\nsolutions deserve more room in public discussions. For instance,\nwhen we rely on social media to aid disaster response, do we\ninadvertently end up prioritizing areas where people tweet more,\npotentially shortchanging areas on the wrong side of the digital\ndivide like those with more seniors or low-income residents? This\nwas one of the lessons from civic tech where apps to report pot\nholes to the city resulted in lots of reports from whiter wealthier\nareas, which actually had fewer potholes than other areas but a\nhigher propensity to report them. At the same time, new civic tech\nefforts to improve large-scale sensor data collection related to\ninfrastructure promise to not only advance the efficiency but also\nthe equitable distribution of infrastructure improvements [11].\nOne of the goals of this preliminary meta-level analysis of data-\nscience-for-good projects is to aid the discussion of how our\ntechnical and statistical solutions are related to these larger\nquestions in order to ensure that the impacts remain sustainable,\nequitable and address privacy concerns.\n6. REFERENCES\n1.\nChen, H., Chiang, R. H. L., Storey, V. 2012. Business\nIntelligence and Analytics: From Big Data to Big Impact.\nMIS Quarterly 36, 4 (December), 1165-1188.\n2.\nLaValle, S., Lesser, E. Shockley, R., Hopkins, M.S., and\nKruschwitz, N. 2011. Big Data, Analytics and the Path From\nInsights to Value. MIT Sloan Management Review 52, 2\n(Winter), 21-31.\n3.\nBoba Santos, R. 2014. The Effectiveness of Crime Analysis\nfor Crime Reduction: Cure or Diagnosis? Journal of\nContemporary Criminal Justice 30, 147-168.\n4.\nToyama, K. 2015. Geek Heresy: Rescuing Social Change\nfrom the Cult of Technology. PublicAffairs, New York, NY.\n5.\nTownsend, A. 2013. Smart Cities: Big Data, Civic Hackers,\nand the Quest for a New Utopia. W. W. Norton & Company,\nNew York, NY.\n6.\nBoyd, D., Levy, K. and Marwick, A. 2014. The Networked\nNature of Algorithmic Discrimination. Data &\nDiscrimination: Collected Essays (Eds. Seeta Pena\nGangadharan and Virginia Eubanks), 43-57.\n7.\nMorozov, E. 2014. To Save Everything, Click Here. The Folly\nof Technological Solutionism. PublicAffairs.\n8.\nMattern, S. 2015. Mission Control: A History of the Urban\nDashboard. Places Journal, March.\n9.\nKitchin, R., Lauriaulta, T. P., McArdle, G. 2015. Knowing\nand governing cities through urban indicators, city\nbenchmarking and real-time dashboards. Regional Studies,\nRegional Science 2, 1, 6-28.\n10. IBM Corporation. 2013. Descriptive, predictive, prescriptive:\nTransforming asset and facilities management with analytics.\nIBM Software Thought Leadership White Paper (October).\n11. Adibhatla, V., Henke, G. and Atwater, P. 2015. Street Quality\nIdentification Device. ARGO Labs Working Paper.\n\n!\nTable 1. Summary of 72 Data-Science-for-Good Projects that were Reviewed\nCat\nProject Name\nAgency\nSponsor\nProblem\nShort Description\nData\nMethods\nA\nScraping Websites to Collect Consumption and\nPrice Data\nDataKind\nWorld Bank\nMeasuring inflation\nlocally + timely\nAutomate access to online data about inflation in Africa.\nData scraped from web\ndata visualization\nA\nWant to Save 268 Days of Data Acquisition?\nDataKind\nMicrofinance Information\nExchange\nAccess to info for micro\nloans\nAutomate access to online data relevant for microfinancing.\nopen online microfinance data\nscraping data from web\nAD\nDriving Small Business Growth with Analytics\nMODA\nNew Business Acceleration\nTeam (NBAT)\nFragmented data\nsources\nCentralize data without common ID to create a census of\nbusinesse in New York. Measure impact of time saved by\nsystem.\nDept. of Consumer Affairs, Dept of Health +\nMental Hygiene, Dept of Environmental\nProtection, tax parcels\ndata and map visualization, impact measurement\nAB\nUsing the Simple to Be Radical\nDataKind\nGiveDirectly\nMeasuring poverty\nAutomate the identification of poor villages who are eligible for\nmobile phone-based cash transfers.\nsatellite images\nsatellite image processing and machine learning to\ndifferentiate roof types\nA\nShining a Light on Poverty\nDataKind\nWorld Bank\nMeasuring poverty\nAutomate the measurement of poverty with light data.\nsatellite images\nsatellite image analysis, correlations\nA\nMapping Poverty to Beat It\nDataKind\nDC Action for Children\nMeasuring poverty\nConvert PDF documents of child well-being indicators to\ninteractive online maps.\nKIDS COUNT\ndata and map visualization\nA\nDelving into Child Poverty Data\nDataKind\nNorth East Child Poverty\nCommission\nMeasuring poverty\nGive NECPC a more real time understanding of child poverty and\ncommunicate the data in a more actionable way to encourage\nimmediate responses.\nCitizens Advice Bureau\ndata and map visualization\nA\nDrug Safety in Your Pocket\nBayes Impact\nNo Sponsor\nUnknown drug\ninteractions\nPredict novel interactions for pairs of drugs that do not have a\nhistorical interaction record.\nAERS (Federal Drug Adverse Event Reporting\nSystem) dataset\ndata classified by the RxNorm hierarchy; neural\nnetworks\nA\nCase Foundation: A Hairball to Help Non-Profits\nUntangle Strategy\nDSSG\nCase Foundation\nNonprofit funding\nIdentify networks of similar nonprofits and funders that support\nthem.\nData scraped from web (tweets, news)\nnatural language processing (TF-IDF) and social\nnetwork analysis\nB\nPredicting College Persistence among High\nSchool Students\nDSSG\nKIPP Chicago - Public Schools Edu: College non-\ncompletion\nPredict a student's risk of struggling in college.\nData from KIPP Chicago - College Prep Public\nSchools\npredictive modelling\nB\nMesa Public Schools: Undermining\nUndermatching\nDSSG\nMesa public schools\nEdu: College\nundermatching\nPredict gifted students likely to undermatch in college enrollment. Data from Mesa public schools and college test\nscores\npredictive modelling\nB\nEarly Warning Systems for Struggling Students\nDSSG\nMontgomery County Public\nSchools\nEdu: High school non-\ncompletion\nImprove existing early warning system to identify high school\nstudents at risk of not graduating.\nData from Montgomery County Public Schools\nrisk scores based on predictive modelling (Poisson\nregression, random forest, ordinal regression trees,\nCox regression)\nB\nIdentifying High School Students Who May Not\nGraduate on Time\nDSSG\nWake County and Arlington\nPublic School Districts\nEdu: High school non-\ncompletion\nScale existing early warning system to identify high school\nstudents at risk of not graduating.\nschool district data\nrisk scores based on predictive modelling\nB\nKeep In Touch: Robust Retention Strategies for\nHealth Leads\nDSSG\nHealth Leads\nHealth: Disconnect\nfrom services\nIdentify patients' risk of dropping out of health-related service\nprovision.\nData from Health Leads\npredictive modelling\nB\nIDHS Project: Better Birth Outcomes\nDSSG\nIllinois Department of Human\nServices\nHealth: Adverse births\nIdentify women at greatest risk of adverse birth for targeting\nsupport services.\nData from Illinois Department of Human\nServices\nmachine learning, predictive modeling, mapping\nvisualization\nBD\nDefining the Undefinable, Measuring the\nUnmeasurable\nDSSG\nNurse-Family Partnership\nHealth: Adverse births\nDetermine risk factors associated with dropping out early or not\nachieving program goals.\nData from Nurse-Family Partnership\nimpact evaluation\nB\nNorthShore: mining medical data to tackle the\nobesity crisis\nDSSG\nNorthShore University Health\nSystem\nHealth: Child obesity\nPredict obesity risk for a child based on hospital's medical\nrecords to guide health interventions.\nNorthShore University Health System's\nElectronic Medical Records\nlinear regression\nB\nPredictive Modeling for Public Health:\nPreventing Childhood Lead Poisoning\nDSSG\nChicago Department of Public\nHealth\nHealth: Lead\ncontamination\nIdentify homes at high risk of lead contamination.\nblood test results, building and inspection\nrecords, census data\nmachine learning; claddification algorithms (logistic\nregression, support vector machines, random forests)\nB\nMaternal Mortality in Mexico: Distilling Data into\nPolicy Strategies\nDSSG\nMexico's Office of the President Health: Maternal\nmortality\nDetermine the risk factors associated with maternal mortality.\nbirth and death, patient discharge records,\nhospital data, Census data - back to 1990\nexploratory analysis and predictive modeling (logistic\nregression, decision tree, random forest)\nB\nWarm Calls and Persuadability: Enroll America\nDSSG\nEnroll America\nHealth: Uninsured\nPredicting an individual's probability of enrolling in subsidized\nhealth insurance.\nData from Enroll's GetCoveredAmerica\ncampaign\ncorrelation matrix, Lasso regression\nB\nKeeping it Cool: Using Mobile Technology to\nPreserve Vaccines\nDataKind\nNexLeaf\nHealth: Spoiled\nvaccines\nDecrease spoiled vaccines due to power outages through phone-\nbased temperature monitoring.\nInternal data from NexLeaf\ndata visualization, correlation analysis\n\n!\nB\nImproving Long-Term Financial Soundness by\nIdentifying Causes of Home Abandonment in\nMexico\nDSSG\nInfonavit\nHsg: Abandoned\nproperties\nDetermine the risk factors associated with housing abandonment. Data from Infonavit, census and home surveys,\nloans\nexploratory data analysis\nBD\nEasing the Distress of Neighborhoods with\nData\nDSSG\nCity of Memphis and CDCs\nHsg: Abandoned\nproperties\nDetermine risk that a home becomes abandoned.\nunemployment, poverty, income; and real estate\ndata\nclustering algorithm, random forest classifier, hedonic\nregression, propensity score matching\nBD\nProactive Blight Reduction and Neighborhood\nRevitalization\nDSSG\nCity of Cincinnati\nHsg: Abandoned\nproperties\nEarly warning system for when and where properties are likely to\nbecome blighted.\nCity of Cincinnati data\npredictive modelling and impact analysis\nBA\nCook County Land Bank Part 2: A Real Estate\nFinder for Vacant Properties\nDSSG\nCook County Land Bank\nAuthority\nHsg: Abandoned\nproperties\nSuggest which abandoned properties should be prioritized for\npurchase to avoid further neighborhood decline.\nparcel and neighborhood data (crime,\ndemographics and socio-economics)\npredictive modelling\nB\nAn automated filter for the Department of\nBuildings (DOB) B+ program\nMODA\nDepartment of Buildings\nBuilding code\nviolations\nEstimate risk of building violations to prioritize building\ninspections.\nDepartment of Building and 311 data\npredictive modelling\nB\nPredictive Analytics for Smarter City Services\nDSSG\nCity of Chicago\nCity complaints\nIdentify areas and times with higher risk of complaints about\ngraffiti, potholes, etc.\nCity of Chicago 311 data (open)\npredictive modelling\nB\nPredictive analytics of crime\nDSSG\nChicago Police Department\nCrime\nDetect emerging crime problems at daily level to allocate officers\nmore effectively.\nData from Chicago Police Department and\nUniversity of Chicago's Crime Lab\npredictive modelling\nB\nOut for Justice: A decision support system for\npolice departments\nBayes Impact\nSan Francisco Police\nDepartment\nCrime\nHelp San Francisco police department (SFPD) optimize patrol\ncar placement.\nSFPD 911 data and OSM street data\nmachine learning (boosted Poisson regression trees);\noptimization algorithms; predictive model\nB\nPreventing Domestic Violence with Data-driven\nAction\nBayes Impact\nHigh Point, NC Police Dept.\nCrime: Domestic\nviolence\nPrevent recidivism among domestic violence offenders.\nHigh Point Police Department's data\npredictive modelling\nB\nDetecting and Visualizing Prostitution Rings\nBayes Impact\nThorn\nCrime: Child\nprostitution\nHelp discover and geolocate previously unnoticed prostitution\nrings in U.S.\nData scraped from web (adult posts)\nsoft text matching\nB\nHow Network Analysis Can Help Identify Money\nLaundering Schemes\nBayes Impact\nNo Sponsor\nCrime: Money\nlaundering\nIdentify individuals and businesses that could be laundering their\nmoney.\nopen data (UK business registries, incl. offshore\ncompanies)\nnetwork analysis\nB\nIdentifying Fraud & Collusion in International\nDevelopment Projects\nDSSG\nWorld Bank Group\nCrime: Fraud in\ncontract bidding\nIdentify likely fraud in contract bidding.\nInternational contract bidding data from World\nBank Group\npredictive modelling\nB\nClean Development: Data Mining for Corruption\nRisks\nDSSG\nWorld Bank Group\nCrime: Fraud in\ncontract bidding\nIdentify likely fraud in contract bidding.\nInternational contract bidding data from World\nBank Group\npredictive modelling\nB\nEarly Warning Indicators for Adverse Police\nInteractions\nDSSG\nCharlotte-Mecklenburg PD\nCrime: Police brutality\nDevelop early warning system to flag officers at risk of engaging\nin adverse interactions.\nCharlotte-Mecklenburg Police Department data predictive modelling + early warning systems\nB\nUsing Data for a More Transparent Government\nDSSG\nHarris School of Public Policy\nGovernment corruption Automatically detect which congressional allocations were\nearmarked.\nCongressional documents\nmachine learning (Support Vector Machine, Name\nIdentity Recognizer)\nB\nPredictive Enforcement of Pollution and\nHazardous Waste Violations\nDSSG\nEnergy Policy Inst., University\nof Chicago\nHazardous waste\nviolations\nPredict a company's risk of severe environmental violations.\nEPA data: reporting, monitoring, inspection,\nenforcement (RMP + RCRA)\npredictive modelling\nB\nQCRI: Tapping Twitter for Faster Disaster Relief\nDSSG\nQatar Computation Research\nInstitute\nDisaster response\nUse tweets to aid disaster response in near-real time.\nTweets\nmapping, classification, extraction (CRF), clustering/\nmerging (SDLA algorithm)\nBA\nDisaster Response and Recovery\nMODA\nOffice of Emergency\nManagement\nDisaster response\nAnalyze 911 and 311 data in near-real time to aid faster disaster\nresponse.\nVarious city data sources, city's 311 and 911\ndata.\ngeocoding, pattern analysis, data integration\nBA\nFDNY's Risk Based Inspection System (RBIS)\nMODA\nFDNY\nFire\nForecast risk of fire to prioritize fire inspections.\nData from FDNY and DataBridge (housing)\npredictive modelling\nBD\nOut On a Limb - For Data\nDataKind\nNYC Parks Department\nHazardous tree\nconditions\nDetermine if tree pruning reduces risk of hazardous tree\nconditions during storm.\nInternal data from NYC Parks Department\ndata visualization, impact analysis and predictive\nmodeling\nB\nMine Risk Evaluator\nBayes Impact\nDepartment of Labor\nMine accidents\nHelp mine inspection managers to prioritize their next inspection. Department of Labor data\npredictive modelling\nB\nEnergywise\nDSSG\nNo Sponsor\nEnergy conservation\nAssess which actions result in high energy use that could be\nreduced.\nUser submits building energy data\npredictive modelling\nB\nMaking Smart Meters Smarter\nDSSG\nPecan St., Elevate Energy, Oak\nPark\nEnergy conservation\nAddress challenge of load disaggregation to estimate energy use\nof individual appliances.\nPecan Street and Oak Park (ComEd, Smart\nCities, Green Button, Direct, ISEIF) data\nneural networks, hidden Markov models, sparse\ncoding\nB\nUshahidi: Machine Learning for Human Rights\nDSSG\nUshaidi\nHuman rights violations Automatically identify high-risk situations in real-time.\nText message data from Ushaidi\nmachine learning and natural language processing\n\n!\nB\nPredicting and preventing human rights abuses\nDataKind\nAmnesty International\nHuman rights violations Automatically identify high-risk situations in future based on\npatterns of past urgent messages.\nAmnesty International internal data\ntext analysis and predictive modelling\nBA\nStrengthening Global Human Rights Through\nMapping\nDataKind\nBenetech\nHuman rights violations Automatically flag and map concentrations in human rights\nviolations in near-real time.\nBenetech data (collected through Martus)\ntext analysis and automated reports/maps\nBA\nPredicting and Preventing Nonprofit Financial\nDefault\nDataKind\nGuideStar\nNonprofit default\nPredict risk of nonprofit financial default.\nSupplemented GuideStar data (operations) with\nGreatNonprofits (nonprofit reviews)\npredictive modelling\nC\nDivvy Part 2: A Crystal Ball for Rebalancing\nDSSG\nDivvy\nUnbalanced shared\nbikes\nRebalancing bike-share bikes to avoid supply-demand\nmismatches at a station.\nInternal data from Divvy\npredictive modelling (Poisson regression)\nC\nCTA: Why Bus Crowding Happens and How\nData Can Help\nDSSG\nChicago Transit Authority\nUnbalanced bus loads\nOptimize allocation of buses to avoid overcrowding.\nData from Chicago Transit Authority\nbus service simulations to forecast impact of adding\nor removing service\nC\nIdentifying New Opportunities for Food Bank\nDonation from Food Service Retail\nDSSG\nFeeding America\nFood waste vs. hunger Identify total pounds of surplus food within a service area of a\nfood bank.\nData about local foodservice channels from\nFeeding America\nestimation of total amount of food available from\ndifferent sources\nCA\nImproving Local Labor Market Matching with\nHigh Frequency Resume and Jobs Data\nDSSG\nDepartment of Labor\nSkills gap\nDevelop real-time labor market information system to close skills\ngap.\nfederal, local, private, and public business and\nlabor market datasets\nlabor demand models and skills gap analysis\nC\nIdentifying Skills Gaps to Reduce\nUnemployment\nDSSG\nSkills for Chicagol.'s Future;\nCareerbuilder\nSkills gap\nIdentify which additional skills job seekers need to find a job.\nData from CareerBuilder\ntext analysis\nCA\nFinding 30,000 Missing Children\nDataKind\nShooting Star Chase\nUnbalanced match\nterminally ill children-\nhospices\nMatch terminally ill children with nearby hospices with extra\ncapacity.\nIntegrated data from Shooting Star Chase with\npublic data on hospice and healthcare sector\nand demographic data\nmulti-layer map visualization\nC\nAnticipating Back to School Numbers, Before\nSummer Vacation\nDSSG\nChicago Public Schools\nUnknown student-\nschool match\nEstimate in spring how many students will enroll in a school in fall\nto save costs.\nCity of Chicago and Chicago Public Schools\ndata and map visualization, machine learning\nDC\nInsight for DonorsChoose\nBayes Impact\nDonorsChoose\nFunding: Nonprofits\nHelp teachers understand the best way to get their projects\nfunded on DonorsChoose.\nData from DonorsChoose\npredictive modelling\nDC\nHelping Great Causes Get Funded\nDataKind\nGlobal Giving\nFunding: Nonprofits\nImprove online crowd-funding for nonprofits through analysis of\nsuccessful organizations.\nInternal data from Global Giving\ndecision trees and regression analysis\nD\nClustering Arts Organizations to Help Them\nThrive\nDataKind\nCultural Data Project\nFunding: Nonprofits\nImprove training based on better understanding what helps arts\norganizations succeed.\nFinancial and programmatic data from 11,000+\narts and cultural institutions\ncluster analysis to identify peer communities\nDC\nAustralian Conservation Foundation Project:\nEngage and Protect\nDSSG\nAustralian Conservation\nFoundation\nFunding: Nonprofits\nImprove effectiveness of fundraising through data analysis and\nexperiments.\nInternal data from Australian Conservation\nFoundation\ndata exploration, clustering techniques, predictive\nmodeling, experiments\nD\nGoing Mobile\nDataKind\nGrameen Foundation\nFunding: Access to\nmicro loans\nImprove effectiveness of text message help for subsistence\nfarmers.\ntext message data from Grameen Foundation\ntext analysis\nD\nUnderstanding Text data to Help Disadvantaged\nFamilies\nDataKind\nButtle UK\nFunding: Access to\nmicro loans\nImprove provision of micro grants based on analysis of past\npatterns.\nButtle UK reports\nnatural language processing\nD\nLearning from Text Messages to Help Teens in\nCrisis\nDataKind\nCrisis Text Line\nTeen crises\nImprove text-based teen crisis intervention through analysis of\nexisting patterns.\nCrisis Text Line internal data\ntext analysis\nD\nA Different Kind of House Call\nDataKind\nMobilizing Health\nHealth: Access in poor\nrural areas\nImprove doctor-patient e-relationship through analysis of existing\npatterns.\nMobilizing Health internal data\ntext analysis\nD\nThe Match Game: Measuring the National\nImpact of Nurse-Family Partnership\nDSSG\nNurse-Family Partnership\nHealth: Adverse births\nDetermine if program is effective at improving health outcomes\nfor mothers and babies.\nData from Nurse-Family Partnership, National\nImmunization Survey\npropensity score matching\nD\nImproving Access to Education by Supporting\nTutors\nDataKind\nThe Access Project\nEdu: Low-income\nstudent access: best\nuniv.s\nImprove tutor-student relationship through analysis of existing\npatterns.\nThe Access Project internal data\ntext analysis and data visualization\nD\nUncovering the ABCs of Successful Online\nMentoring\nDataKind\niCouldBe\nEdu: High school non-\ncompletion\nImprove e-mentoring drop-out prevention program based on\nanalysis of past patterns.\nInternal data from iCouldBe\npredictive modelling\nD\nTracking the Paths of Homelessness\nDSSG\nChicago Alliance to End\nHomelessness\nHomelessness\nIdentify which housing types are most effective at providing\nhousing stability.\nAnonymized data from Chicago Alliance to End\nHomelessness (HMIS)\ndata visualization (Sankey diagram)\nDA\nSharing data to learn about homelessness\nDataKind\nSt Mungo's Broadway\nHomelessness\nImprove provision of services to homeless residents by\nunderstanding what services they need before they become\nhomeless.\nLinked data from St Mungo's Broadway and\nCitizens Advice\ndata and map visualization, network analysis\nDA\nTracing Policy Ideas From Lobbyists Through\nState Legislatures\nDSSG\nSunlight Foundation\nGovernment corruption Determine to what extent lobbyists are writing legislative bills that\nare considered for adoption.\nData scraped from web and Sunglight\nFoundation data\ntext analysis and impact analysis\n\n!\nDA\nLet the Sun Shine on Politics\nDataKind\nSunlight Foundation\nGovernment corruption Determine if financial contributions influence political\nrepresentatives' votes.\nOpenSecrets lobbying database + Sunlight\nFoundation data on fundraising activities of\npoliticians\naffinity score metric to track relation between\ndonations and voting over time\nDA\nShining Light on International Human Rights\nCase Law\nDataKind\nHURIDOCS\nHuman rights violations Allow HURIDOCS to track whether human rights case judgments\nwere enforced.\nIntegrate ECHR HUDOC database (Caselaw\nAnalyzer) with Council of Ministers data on case\nexecution.\nscraping data from web and integrating it\nD\nHeatmaps for Habitats: Enriching Conservation\nSensor Data\nDSSG\nTEAM Network\nSpecies conservation\nDetermine how temperature changes affect species movement.\nTEAM data\nradial basis interpolation, heatmaps\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nCMS.631 Data Storytelling Studio: Climate Change\nSpring 2017\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    }
  ]
}