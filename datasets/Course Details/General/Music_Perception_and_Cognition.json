{
  "course_name": "Music Perception and Cognition",
  "course_description": "This course is a survey of perceptual and cognitive aspects of the psychology of music, with special emphasis on underlying neuronal and neurocomputational representations and mechanisms. Basic perceptual dimensions of hearing (pitch, timbre, consonance/roughness, loudness, auditory grouping) form salient qualities, contrasts, patterns and streams that are used in music to convey melody, harmony, rhythm and separate voices. Perceptual, cognitive, and neurophysiological aspects of the temporal dimension of music (rhythm, timing, duration, temporal expectation) are explored. Special topics include comparative, evolutionary, and developmental psychology of music perception, biological vs. cultural influences, Gestaltist vs. associationist vs. schema-based theories, comparison of music and speech perception, parallels between music cognition and language, music and cortical action, and the neural basis of music performance.",
  "topics": [
    "Health and Medicine",
    "Sensory-Neural Systems",
    "Science",
    "Biology",
    "Neurobiology",
    "Neuroscience",
    "Cognitive Science",
    "Health and Medicine",
    "Sensory-Neural Systems",
    "Science",
    "Biology",
    "Neurobiology",
    "Neuroscience",
    "Cognitive Science"
  ],
  "syllabus_content": "This page includes a\ncalendar\nof lecture topics.\n\nCourse Meeting Times\n\nLectures: 2 sessions / week, 2 hours / session\n\nPrerequisites\n\nNeural Coding and Perception of Sound (\nHST.723J\n) or permission of instructor. The course will be as self-contained as possible. We will introduce the musical, physical, mathematical, psychological, and neuroscience concepts we need as we go along. Coverage of topics will begin with concrete musical listening examples, discuss the results of systematic psychological studies, and then delve into possible neural representations and mechanisms.\n\nFormat\n\nLecture plus demonstrations and discussions.\n\nTexts\n\nRequired\n\nDeutsch, D., ed.\nThe Psychology of Music\n. 2nd ed. San Diego, CA: Academic Press, 1998. ISBN: 9780122135651.\n\nHandel, S.\nListening: An Introduction to the Perception of Auditory Events\n. Cambridge, MA: MIT Press, 1989. ISBN: 9780262081795.\n\nLevitin, D.\nThis Is Your Brain On Music\n. New York, NY: Dutton Adult/Penguin, 2006. ISBN: 9780525949695.\n\nSnyder, B.\nMusic and Memory\n. Cambridge, MA: MIT Press, 2001. ISBN: 9780262194419.\n\nRecommended\n\nAello, R., ed.\nMusical Perceptions\n. New York, NY: Oxford University Press, 1994. ISBN: 9780195064759.\n\nMcAdams, S., and E. Bigand.\nThinking in Sound: The Cognitive Psychology of Human Audition\n. New York, NY: Oxford University Press, 1993. ISBN: 9780198522584.\n\nMoore, B. C. J.\nAn Introduction to the Psychology of Hearing\n. 5th ed. San Diego, CA: Academic Press, 2003. ISBN: 9780125056281.\n\nCoursework and Grading\n\nCOURSEWORK\n\nGRADING\n\nDESCRIPTIONS\n\nProblem sets\n\n10%\n\nOne problem set will be on harmonic structure and tuning systems. The other will cover topics in music perception and cognition.\n\nMusical examples\n\n10%\n\nFind 5 musical examples from any genre that illustrate or illuminate different aspects of music perception and cognition related to melody, harmony, rhythm, your own musical preference, and some aspect of your choosing. We will listen to them as a class and discuss them.\n\nReading assignment and presentation\n\n10%\n\nA relevant paper will be chosen, presented (10-15'), and discussed by the class. This can be one of the papers on the reading list or any paper that you feel is important or insightful.\n\nFundamental unsolved questions in music psychology - 3-4 page outline/discussion\n\n20%\n\nI have compiled a list of unsolved questions in music psychology. Please choose from the list or suggest your own problem. Write up an account of the nature of the problem (1-2 paragraphs), its theoretical significance (1 paragraph), current theories (if any, 1-3 paragraphs), two plausible hypothetical explanations (2-4 paragraphs), ideas concerning how the question might be solved or hypotheses tested (1 paragraph), and some assessment of how soon the problem will likely be solved (1 paragraph). Each student will present a problem and outline their thinking about it, which will form the basis for a class discussion.\n\nTerm project\n\n50% of final grade\n\nA research paper, review paper, or research project (e.g. psychological or physiological experiment, computer model/simulation) related to the psychology of music. Topics will be presented orally and discussed in class in mid-March. Project results will be presented and discussed in class in the last two weeks of class. Target length of paper will depend on nature of project. Final papers will be due on the last day of class. I will be happy to read and give comment on outlines and drafts at any stage of preparation.\n\nGeneral Themes\n\nI group the themes we will cover in terms of Quality and Form, Memory and Anticipation, Codes and Computations, Parallels with Speech and Language, Emotion and Meaning, Psychological Functions, and Origins. We will look at each of these themes in terms of several perspectives: the structure of sound, the perceptual psychology of hearing, our own internal experiences of sound and music, music theory and practice, the neuroscience of the auditory system and the brain at large, computational neuroscience and neural networks, and the psychology of perception, cognition, memory, and emotion.\n\nQuality and Form\ninvolves how we distinguish different musical sounds: pitches, timbres, consonances, musical intervals, chords, melody, and rhythmic patterns. Some of the questions we will address involve how we perceive the basic elements and patterns of music: How do we distinguish pitches? When do sound-objects stand apart or fuse together? What pitches do we hear when a chord is sounded? Why do octaves sound similar? What are the acoustic and perceptual dimensions of timbre? How do we recognize melodies? Why do we perceive transposed melodies as being similar, essentially identical? How are individual events and their rhythmic organization perceived?\n\nMemory and anticipation\ninvolves how we experience sounds in the context of others that came before. Music unfolds over time on several timescales, from subtle differences in expressive timing to note-transitions to melodies and tonal centers to larger, longer structures of repetition and change. This involves memory and anticipation on many levels - echoic memory, working memory, and long term memory. How do tonal and rhythmic expectations arise? What is their neural basis? How are temporal expectations created and violated? How does music exploit them? To what degree are these expectations universal and to what degree are they the result of cultural conditioning?\n\nCodes and computations\nconcerns the neural processes that subserve our experience of music. How does the auditory system represent sounds? How (and why) are pitches at the fundamentals of harmonic complexes heard? What kinds of neural representations and information processing operations are involved? We will examine different neural codes and computations that are based on activation of specific subsets of neurons (channel codes and connectionist networks) and on patterns of spikes (temporal codes and neural time delay/timing networks). How does the nervous system carry out these operations? How much of the structure of music arises directly from the neural codes in the auditory system? How much arises through learned associations and modification of synaptic connections? What kinds of neural net models have been proposed to explain various aspects of musical experience? What kinds are possible? What assumptions underlie high-level, neurological models of music's various psychological functions?\n\nParallels and differences between music, speech, and language\nexplores similarities and differences between music and speech sounds on one hand, and music and language structure on the other. Although the same auditory system subserves both music and speech perception, music and speech typically utilize different sets of acoustic contrasts as primitive features (e.g. tonal music depends on pitch relations, while (nontonal) languages use phonetic elements based on timbral distinctions such as vowel spectra, attack, spectral flux). Can a comprehensive model of auditory tonal quality (timbre) account for the salient distinctions that phonetic systems utilize?\n\nEmotion and pleasure\nare essential parts of musical experience. We create and listen to music for our own pleasure. Why is music pleasurable in the first place? How is tension created and relieved? Why (how) is \"expressive timing\" expressive? Why does music (sometimes) have profound effects on our emotions? What is the neural basis of these effects? What areas of the brain are involved in emotion and meaning in music? How can highly artificial, highly unnatural structurings of sound have meaning for us? Are they tied to mechanisms/habits related to speech perception? Is musical meaning dependent on previous experience and cultural associations, or does it (also) emulate internal body-rhythms associated with our emotions?\n\nPsychological functions\nof music involve the way that music is used by individuals and groups to achieve different ends. Music can be used for mood control, auditory-cognitive interest, meditation and stress reduction, dance, distraction, symbolic ritual, expression of self- and collective identity, evocation of feelings of nostalgia, religious awe, patriotism, anger, hate, joy, love, and sorrow. Different types of music lend themselves to particular psychological functions, and different psychological functions presumably engage different neuronal circuits and processes in the brain. To which uses one puts music may be a function of one's personality and culture. What would a full-blown neurologically-grounded theory of personality and music preference look like?\n\nOrigins\nconcerns how we as a species and as individuals come to be able to deal with the highly complex structure of music. This can arise from evolutionarily-primitive general-purpose mechanisms, recent evolutionary adaptations, and/or associations/connections acquired in development. Is music perception and cognition parasitical on speech reception and language comprehension mechanisms or are there more general faculties for handling temporal patterns, sequences, and associations that support both music and language cognition? What are the similarities and differences between music and language? Is the perception of music a recently evolved capability (and if so, why), or is it based on basic perceptual and cognitive mechanisms that are much more ancient? Do animals apprehend musical structure in some meaningful sense? Do they derive pleasure from it? What dimensions of music perception and cognition would we predict are likely to be shared by other species? How do infants perceive music, how does this change over time?\n\nSince this course is focused on perception and cognition, there are many aspects of the psychology of music that we will deal with only tangentially: e.g. music and personality, music and cultural identity, musical talent and creative genius. If there is sufficient interest in these areas (as well as others), we will organize space to address them.\n\nCalendar\n\nLEC #\n\nTOPICS\n\nKEY DATES\n\nCourse introduction\n\nOverviews: structure of music, music's psychological and social functions\n\nOverview: auditory perception and the time sense\n\nOverview of the auditory system\n\nPitch\n\nPitch mechanisms and neurocomputational models\n\nCentral representation of pitch - problems and prospects\n\nTimbre\n\nConsonance, dissonance, and roughness\n\nScales, tuning and harmony\n\nMelody\n\nHarmony\n\nTonal expectation (guest lecture/demonstration by Elizabeth Chew, MIT)\n\nMusic therapy: clinical applications of the neuropsychology of music (guest lecture by Dr. Kathleen Howland, Boston Conservatory and Wellesley MA Public Schools)\n\nMusic and the cerebral cortex (guest lecture by Dr. Daniel Bendor, MIT)\n\nAbsolute pitch, tone deafness, and cortical representation of music (guest lecture by Psyche Louie, Harvard Medical School)\n\nProblem set due\n\nNeurology of music and music-based therapies (guest lecture by Dr. Gottfried Schlaug, director of Music and Neuroimaging Laborabory at Harvard Medical School)\n\nRhythm, timing, and expectation\n\nEmotion, meaning, expectation and reward\n\nImaging studies of creativity and musical performance (guest lecture by Aaron Berkowitz, Harvard University)\n\nFormal theories of music cognition and language\n\nFundamental problems paper due\n\nDevelopmental psychology of music\n\nGuest lecture by Adena Schachner on beat synchronization in animals\n\nListening assignments writeups due\n\nStudent paper presentations: Janata (2003); Chen and Zatorre (2006)\n\nMusic perception by cochlear implant users (Guest lecture by Ray Goldsworthy, Sensimetrics)\n\nEvolutionary origins\n\nStudent paper presentations: Bhatara on autism, 3 Emotions paper\n\nMusic and speech\n\nStudent final project presentations\n\nMusic and personality, music and multimodal interactions\n\nAudio-visual interactions\n\nWrap up and recapitulation\n\nFinal projects due",
  "files": [
    {
      "category": "Resource",
      "title": "Some fundamental problems in the psychology of music",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/cf84f15b1df8014e7f7067c0f5f26624_MITHST_725S09_assn01_fdqst.pdf",
      "content": "HST.725 Spring 2009\nSome fundamental problems in the psychology of music\n\nHere are some suggested topics, but you are not limited to these. Please choose from the list or\nsuggest your own problem. Write up an account of the nature of the problem (1-2 paragraphs), its\ntheoretical significance (1 paragraph), current theories (if any, 1-3 paragraphs), two plausible\nhypothetical explanations (2-4 paragraphs), ideas concerning how the question might be solved\nor hypotheses tested (1 paragraph), and some assessment of how soon the problem will likely be\nsolved (1 paragraph). Each student will present a problem and outline their thinking about it,\nwhich will form the basis for a class discussion.\n\n1. How is fine timing information that is available in early stages of auditory processing\nutilized by the central neuronal processors?\n\n2. How do we account for the perceptual invariance of pitch and timbre over large dynamic\nranges? What are the central representations/mechanisms?\n\n3. What is the nature of the cortical representation of auditory objects such that two\ninstruments with different pitches can be heard simultaneously?\n\n4. Transposition: What is the neuronal basis for the ability to recognize transposed\nmelodies?\n\n5. Time-stretching: What is the neuronal basis for the ability to recognize rhythmic\npatterns with different tempos?\n\n6. What are the roles of descending pathways and recurrent connections in the auditory\npathway, cerebral cortex, and limbic system vis-a-vis music?\n\n7. Is there a coherent mapping between timbral space as studied by music perception\nresearchers and phonetic space as studied by speech psychoacousticians?\n\n8. Are there basic operations and neuronal mechanisms that can realize analysis of both\nmusical and linguistic structure (syntactics)? Are there music-specific faculties?\n\n9. Long term memory and music: how are melodies retained over long periods of time\n(years, decades). What is the nature of the engram for music?\n\n10. What would it take to design cochlear implants that permit their users to get melody,\nharmony, and timbre?\n\n11. What is the present state of automatic music recognition? What are the current\nbarriers? How does this compare with automatic speech recognition?\n\n12. Is music perception/cognition well described in terms of Bayesian inference?\n\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nHST.725 Spring 2009\n13. What is the role of the cerebellum in music perception?\n\n14. Where in the brain are tonal and rhythmic expectancies generated? What is the nature\nof the representation of pitch and rhythm in these areas?\n\n15. What does auditory-visual synesthesia have to say about neural coding? Are the\nassociations arbitary or do similar ones recur?\n\n16. What are the parallels and differences between auditory and visual perception and\ncognition (e.g. transpositional invariance and magnification and/or translation\ninvariance)? Are auditory and visual grouping mechanisms subserved by similar (or\nanalogous) operations/neurocomputations?\n\n17. What would a full-blown neurocomputational and neurological theory of musical\npreference and personality look like?\n\n18. What music therapies are possible?\n\n19. Why does music (and/or rhythmic induction) help (some) patients with movement\ninitiation disorders? What does this say about the relation between music and motor\ncontrol?\n\n20. What is the nature of auditory-motor linkages for finger tapping, musical performance,\nand dance? Does rhythm perception activate motor centers, and does rhythmic activity\nfacilitate rhythm perception?\n\n21. Comparative psychology of music: To what extent do animals generate rhythmic\nexpectancies? tonal expectancies? musical preferences?\n\n22. What is the nature of neuronal processes responsible for music that one cannot get out\nof one's head (auditory imagery)? Is there a tie-in with some types of central tinnitus?\n\n23. What are the similarities and differences between musical and spoken humor?\n\n24. Are there critical periods and/or stages of development of music cognition?\n\n25. Add your own fundamental questions.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Assignment #1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/3ce9284fd09810ff2b52722c5a50bd1e_MITHST_725S09_pset_01.pdf",
      "content": "HST 725 Music Perception & Cognition\nAssignment #1\n=================================================================\n\n1. Harmonic series.\n\nA. What are the first 10 harmonics of a 200 Hz fundamental (F0)?\n\nB. Which partials can be \"heard out\" or \"resolved\" as individual pitches?\n\nC. What would be the first 10 subharmonics of 200 Hz?\n\nD. What would be the fundamental of 400, 500, 600 and 700 Hz?\n\nE. What are subharmonics 1-10 of 400, 500, 600, and 700 Hz.\n\nF. Which subharmonic(s) do the partials have in common?\n\nG. How is this related to the fundamental frequency?\n\n2. Common harmonics\n\nWe will assume that each note consists of a harmonic complex of harmonics 1-12.\n\nLet the lower note F0 = 200 Hz.\n\nA musical interval of an octave in just tuning is a frequency ratio of 2/1.\n\nA musical interval of a fifth in just tuning is a frequency ratio of 3/2.\n\nA musical interval of a fourth in just tuning is a frequency ratio of 4/3.\n\nA musical interval of a major third in just tuning is a frequency ratio of 5/4.\n\nA. What is the fundamental frequency of a note an octave above 200 Hz?\n\nHow many harmonics do the two notes share?\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\nB. What is the fundamental frequency of a note a fifth above 200 Hz?\n\nHow many harmonics do the two notes share?\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\nC. What is the fundamental frequency of a note a fourth above 200 Hz?\n\nHow many harmonics do the two notes share?\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\nD. What is the fundamental frequency of a note a major third above 200 Hz?\n\nHow many harmonics do the two notes share?\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\nE. Do you see any patterns emerging here?\n\n3. Tuning systems\n\nWe have decided to devise a tuning system in which we divide the octave into 12 logarithmically spaced semitones\n(equally temperament tuning, chromatic scale). There are several ways of doing this. One is to take the twelfth root\nof 2. The first note in the scale is 1, the second note is 21/12 the third 22/12, the fourth 23/12 and so on up to the octave\n212/12= 2. These frequency ratios are multiplied by the frequency of the first note in the scale (the tonic). Frequency\nratios can be expressed in cents. There are 1200 cents to the octave. A semitone is 100 cents, a perfect fifth is 800\ncents, a tritone is 600 cents.\n\nA. If (F0) note A = 440 Hz, what are the frequencies of the other notes in the octave that\nspans 440 to 880 Hz? What are the frequencies in the octave below it?\n\nB. How big is a semitone (one step in the scale) in terms of percent change in frequency?\nWhat percent change in frequency is 50 cents? 25 cents?\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nC. In percentage terms, how much does the equally tempered scale differ from just\nintonation for the fifth (3/2), fourth (4/3)? You can calculate this out or consult the table in\nHandel, p. 331. If the jnd for fundamental frequency is in the neighborhood of 0.2% under the\nbest of conditions, do you expect this difference to be audible? Where is the greatest discrepancy\nbetween intervals based on just intonation and those based on equal temperament?\n\nD. If one were to devise a tuning system that divided the octave into 10 logarithmically\nequal steps, what would the frequencies be for the octave that spans 440-880 Hz? How far would\nthese notes diverge from those of just-intonation? William Sethares in his book Tuning, Timbre,\nand Spectrum discusses such a scale and has written musical compositions based on it.\n\n4. Major aspects of music\nA. Which aspects of music depend (most directly) on perception of pitch? (Two or more\nexamples)\nB. Which aspects of music depend on perception of distinct events?\nC. Which aspects of music depend on memory processes (musical contexts, kinds of\nexpectations)?\n\n5. Pitch and the limits of musical tonality\nA. Roughly, what is the range of pure tone frequencies that we can hear?\nB. What is the range of pitch (f, F0) frequencies for musical tonality (i.e. over which octaves,\nmusical intervals, and melodies can be readily recognized).\nC. What would constitute an explanation (neural or psychological) for why these ranges are\ndifferent?\nD. Provide a possible (neural or psychological) explanation for why we hear the missing\nfundamental. (Paragraph)\nE. What does it mean to say that musical pitch is highly invariant with respect to tone intensity,\nlocation, and duration? What is metamery? What would be an example of pitch metamery?\n\n6. Timbres of musical instruments\nA. What is the main functional role that timbre plays in most western tonal music?\nB. What is the acoustic dimension that distinguishes timbres of stationary sounds?\nC. What are two factors that distinguish timbres of non-stationary (time-varying) sounds?\n\nClasses of instruments: 1. pipe organ (vibrating air column), 2. violin (bowed string), 3. piano\n(struck string), 4. bells (struck, metal), 5. snare drum (struck, membrane)\nD. Which classes produce harmonic tones? inharmonic tones?\nE. Which classes can produce a melody? rhythm?\n\n7. Scales and musical intervals\nA. What is a scale?\nB. What role do scales play in music perception?\nC. What is the tonic? What functional role does the tonic play in perception of melody and\nharmony?\nD. Why do melodies played in different modes have distinctive qualities, despite their use of the\nsame set of notes?\n\n8. Consonance\nA. What defines a musical interval? Does an interval depend on the absolute (F0) frequency of\nits root?\nB. \"Consonance\" is associated with 1) euphony and tonal preference on one hand and 2)\nstability/instability and tension/resolution on the other. Dependence of consonance on musical\ncontext notwithstanding, which isolated intervals (octaves, seconds, fourths, fifths, sevenths) are\nperceived as more consonant? Octaves, fourths, fifths. more dissonant? Seconds, sevenths.\nC. Two rival theories of consonance were proposed by Helmholtz and Stumpf in the 19th\ncentury. What perceptual aspect of tone combinations does each rely on?\nD. Which aspect is thought to be the result of the beating of nearby harmonics? of waveform\nregularity and its consequences for pitch?\n\n9. Harmony and harmonics\nA. What notes and musical intervals constitute a major triad chord (I) in the key of C (major)?\nWhat notes and musical intervals constitute a minor triad chord (I) in the key of C (minor)?\nB. Tonal hierarchy of notes. In the context of Krumhansl's probe-tone studies, we discussed tonal\nhierarchies based on 1) the tonic, 2) notes in I - triad, 3) other notes in the diatonic scale, and 4)\nother notes in the chromatic scale. Which notes would fall into these respective classes for the\nkey of C major?\n\nFor simplicity assume that the tonic (F0) of a just-tuned diatonic scale is 200 Hz and the notes of\nthe scale consist of harmonics 1-6 (consult Handel, p. 331 for just temperament F0 ratios, p. 364\nfor chord notes).\nC. What would be the fundamental frequencies (F0s) of the notes in the major triad (I) if the root\nis 200 Hz?\nD. What harmonics would be present? How many pairs of common harmonics (overlaps) are\nthere?\nE. What would be the fundamentals of the notes in the minor triad (I)? How many harmonic\noverlaps would there be?\n\nIn major keys, chords of scale degrees I, IV, and V have major interval patterns (Major 3rd +\nMinor 3rd), while other scale degrees II, III, VI, VII have minor interval patterns (Minor 3rd +\nMajor 3rd). If chord stability, consonance, and pitch unity were determined solely by the\nproportion of coincident harmonics, would you expect the major or minor triad pattern to be\nmore stable? Why?\nIf chord stability were determined by the strength of the fundamental bass, which in turn were\ndetermined by the number of coincident subharmonics, which pattern would be more stable?\n\n10. Chord progressions\nA. What is a chord progression?\nB. In musical contexts, chord stability is also influenced by its relation to the tonic. If degree of\nrelatedness between a chord (II-VII) and the tonic chord (I) of the key (Krumhansl et al, 1982, Handel,\np. 365) determines the perceptual \"stability\" of that chord, then what pattern of movement would\nbe expected for a I-IV-VII-I progression? Assume that movement from a less stable chord to a\nmore stable one is \"resolution\" (R), while the opposite movement builds \"tension\" (T), e.g., a I-IV-\nII-V-I produces a pattern of movement of T-T-R-R, see Handel, p. 341).\nC. What is key modulation?\nD. Why might perceived relatedness of chords depend on key context? (Handel, p. 373)\n\n11. Melody\nA. What is a melody?\nB. What does it mean to say that melody is invariant under transposition?\nC. What distinguishes a tonal from an atonal melody (see Handel, pp. 355-361)?\nD. Which is more important for melody recognition in tonal contexts: absolute pitch, pitch\ncontour sequences of musical intervals, relations of notes to the tonic?\nE. What are the shortest notes that can support a good melody (ballpark)? the longest notes?\n\n12. Rhythm\nA. Define tempo, accent, beat, meter, and rhythm.\nB. How does rhythm differ from melody? How are these two aspects of music similar? How are\nthey different?\nC. Why is accent important for perception of rhythmic pattern?\nD. If tempo is set at 1 quarter note = 1 beat at 120 bpm, how long in absolute terms is a quarter\nnote? a 16th note?\nE. How do the note durations needed to support a good melody relate to those needed for a good\nrhythm?\n\n13. Organization of voices (auditory scene analysis)\nA. What acoustical factors influence whether two instruments will be perceptually fused (heard\nas one voice)?\nB. What distinguishes a homophonic from a polyphonic piece of music? What musical factors\n(melody, harmony, rhythm) influence whether a musical piece is (perceived as) one or the other?\n\n14. Innate vs. learned mechanisms. In your opinion, which aspects of music perception and\ncognition are likely to depend on bottom-up mechanisms of auditory perception? Which aspects\nare likely to depend on prior auditory experience that is not culture specific? Which are likely to\ndepend on culture-specific auditory experiences, i.e. cultural conditioning? (Short paragraph,\nbriefly give reasoning.)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Assignment #1 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/9c9273972bcdce8f743fe085bef4bf7d_MITHST_725S09_sol_pset_01.pdf",
      "content": "HST 725 Music Perception & Cognition (Spring, 2007)\nAssignment #1\nhttp://www2.siba.fi/akustiikka/?id=39&la=en\n=================================================================\n\n1. Harmonic series.\n\nA. What are the first 10 harmonics of a 200 Hz fundamental (F0)?\n1st harmonic (fundamental):200 Hz, 2nd: 400 Hz, 3:600 Hz, 4:800 Hz, 5:1000 Hz, 6:1200 Hz, 7:\n1400 Hz, 8:1600 Hz, 9:1800 Hz, 10:2000 Hz.\n\nB. Which partials can be \"heard out\" or \"resolved\" as individual pitches?\n(Partials are not divisible by whole numbers, usually interpreted by auditory system as noise).\nThe partials that are harmonics of lower frequencies can be \"resolved\" as individual pitches. For\nexample, the 1.5 partial of 200 Hz is the same as 3rd harmonic of 100 Hz (300 Hz in both cases),\nso it can be resolved.\n\nC. What would be the first 10 subharmonics of 200 Hz?\nSubharmonic-frequencies below the fundamental, 1/(harmonic #).\n1: 200 Hz, 2:100 Hz, 3: 66.7 Hz, 4: 50 Hz, 5: 40 Hz, 6: 33.3 Hz, 7: 28.6 Hz, 8: 25 Hz, 9: 22.2 Hz,\n10: 20 Hz\n\nD. What would be the fundamental of 400, 500, 600 and 700 Hz?\n100 Hz. They are the 4th, 5th, 6th, and 7th harmonics of the fundamental.\n\nE. What are subharmonics 1-10 of 400, 500, 600, and 700 Hz.\n*400 Hz- 1: 400 Hz, 2: 200 Hz, 3: 133.3 Hz, 4: 100 Hz, 5: 80 Hz, 6: 66.7 Hz, 7: 57.1 Hz, 8: 50\nHz, 9: 44.4 Hz, 10: 40 Hz\n*500 Hz- 1: 500 Hz, 2: 250 Hz, 3: 166.7 Hz, 4: 125 Hz, 5: 100 Hz, 6: 83.3 Hz, 7: 71.4 Hz, 8:\n62.5 Hz, 9: 55.6 Hz, 10: 50 Hz\n*600 Hz- 1: 600 Hz, 2: 300 Hz, 3: 200 Hz, 4: 150 Hz, 5: 120 Hz, 6:100 Hz, 7: 85.7 Hz, 8: 75 Hz,\n9: 66.7 Hz, 10: 60 Hz\n*700 Hz- 1: 700 Hz, 2: 350 Hz, 3: 233.3 Hz, 4: 175 Hz, 5: 140 Hz, 6: 116.7 Hz, 7:100 Hz, 8:87.5\nHz, 9: 77.8 Hz, 10: 70 Hz\n\nF. Which subharmonic(s) do the partials have in common?\n\nG. How is this related to the fundamental frequency?\n\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\n2. Common harmonics\n\nWe will assume that each note consists of a harmonic complex of harmonics 1-12.\n\nLet the lower note F0 = 200 Hz.\n\nA musical interval of an octave in just tuning is a frequency ratio of 2/1.\n\nA musical interval of a fifth in just tuning is a frequency ratio of 3/2.\n\nA musical interval of a fourth in just tuning is a frequency ratio of 4/3.\n\nA musical interval of a major third in just tuning is a frequency ratio of 5/4.\n\nFor 200 Hz:\nHarmonics-1: 200 Hz, 2nd: 400 Hz, 3:600 Hz, 4:800 Hz, 5:1000 Hz, 6:1200 Hz, 7: 1400 Hz,\n8:1600 Hz, 9:1800 Hz, 10:2000 Hz, 11: 2200, 12:2400\nSubharmonics-1: 200 Hz, 2:100 Hz, 3: 66.7 Hz, 4: 50 Hz, 5: 40 Hz, 6: 33.3 Hz, 7: 28.6 Hz, 8: 25\nHz, 9: 22.2 Hz, 10: 20 Hz, 11: 18.2 Hz, 12: 16.7 Hz\n\nA. What is the fundamental frequency of a note an octave above 200 Hz?\n2/1*200 Hz=400 Hz (2nd ) harmonic\n\nHow many harmonics do the two notes share? (harmonics 1-12)\n6 (400 Hz, 800 Hz, 1200 Hz, 1600 Hz, 2000 Hz, 2400 Hz)\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\n4 (200 Hz, 100 Hz, 66.7 Hz, 33.3 Hz)\n\nB. What is the fundamental frequency of a note a fifth above 200 Hz?\n3/2*200 Hz=300 Hz (3rd harmonic)\n\nHow many harmonics do the two notes share?\n\nFor 300 Hz-1: 300 Hz, 2: 600 Hz, 3: 900 Hz, 4:1200 Hz, 5:1500 Hz, 6:1800 Hz,\n7:2100 Hz, 8: 2400 Hz, 9: 2700 Hz, 10: 3000 Hz, 11: 3300 Hz, 12: 3600 Hz\n\n4 (600 Hz, 1200 Hz, 1800 Hz, 2400 Hz)\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\n3 (100 Hz, 50 Hz, 33.3 Hz)\n\nC. What is the fundamental frequency of a note a fourth above 200 Hz?\n4/3*200 Hz= 266.7 Hz\n\nHow many harmonics do the two notes share?\n\n3 (800 Hz, 1600 Hz, 2400 Hz)\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\n2 (66.7 Hz, 33.3 Hz)\n\nD. What is the fundamental frequency of a note a major third above 200 Hz?\n5/4*200 Hz=250 Hz\n\nHow many harmonics do the two notes share?\n\n2 (1000 Hz, 2000 Hz)\n\nHow many subharmonics do the two notes share above 30 Hz? What are they?\n\n1 (50 Hz)\n\nE. Do you see any patterns emerging here?\nYes, the number of shared harmonics is the total number of harmonics in a note (12) divided by\nthe number in the numerator of the frequency ratio. For example, the shared harmonics for a note\n\na fifth above is 12/(numerator in frequency ratio)=12/3=4. Likewise, the number of\nsubharmonics shared is 5-(number in the denominator of the frequency ratio) as 5 may symbolize\nhalfway point of the octave. total number thirds (the major unit, as it is the smallest harmonic in\nthis example and the harmonic with the lowest number that is consonant, unlike the 2nd)?\n\n3. Tuning systems\n\nWe have decided to devise a tuning system in which we divide the octave into 12 logarithmically spaced semitones\n(equally temperament tuning, chromatic scale). There are several ways of doing this. One is to take the twelfth root\nof 2. The first note in the scale is 1, the second note is 21/12 the third 22/12, the fourth 23/12 and so on up to the octave\n212/12= 2. These frequency ratios are multiplied by the frequency of the first note in the scale (the tonic). Frequency\nratios can be expressed in cents. There are 1200 cents to the octave. A semitone is 100 cents, a perfect fifth is 800\ncents, a tritone is 600 cents.\n\nA. If (F0) note A = 440 Hz, what are the frequencies of the other notes in the octave that\nspans 440 to 880 Hz? What are the frequencies in the octave below it?\n\nB. How big is a semitone (one step in the scale) in terms of percent change in frequency?\nWhat percent change in frequency is 50 cents? 25 cents?\nEquations:\nA=B*2(n/1200 for finer calculations) where A and B are frequencies of two different notes.\nN=log2 (A/B) approximately equal to N=log10(A/B) where N is the number of cents\n\nA semitone is a half step on the scale (100 cents), so the percent change in frequency is . A/B=\n21/12= 1.047. 1.047-1=.047 or 4.7%.\n\nAlternatively, 100/1200=1/12=.083 or 8.3%.\n\nC. In percentage terms, how much does the equally tempered scale differ from just\nintonation for the fifth (3/2), fourth (4/3)? You can calculate this out or consult the table in\nHandel, p. 331. If the jnd for fundamental frequency is in the neighborhood of 0.2% under the\nbest of conditions, do you expect this difference to be audible? Where is the greatest discrepancy\nbetween intervals based on just intonation and those based on equal temperament?\nFor the fifth, the equally tempered scale has a frequency ratio of 1.498 and corresponds to 700\ncents, versus 1.500 and 702 for the just intonation scale. The equally tempered scale has a lower\nfrequency ratio by .002 and is 2 cents less. No, it is not likely audible as the difference is less\nthan a tenth of the just noticeable difference under the best of conditions. The greatest\ndiscrepancy between the two scales occur at the dissonant intervals: major second D and minor\nseventh A for around 20 cents difference or tritone F# and minor seventh A# with a frequency\nratio difference of 0.018 each.\n\nD. If one were to devise a tuning system that divided the octave into 10 logarithmically\nequal steps, what would the frequencies be for the octave that spans 440-880 Hz? How far would\nthese notes diverge from those of just-intonation? William Sethares in his book Tuning, Timbre,\nand Spectrum discusses such a scale and has written musical compositions based on it.\nThe frequencies would be 44 Hz apart so 484, 528...\n\n4. Major aspects of music\n\nA. Which aspects of music depend (most directly) on perception of pitch? (Two or more\nexamples)\nFrequency and period is dependent on the perception of pitch and are hard to measure otherwise.\nSound pressure of the tone and spectrum or harmonic spacing are other aspects. Rate and place\nof stimulation is affected by pitch, as seen in some cochlear implant studies.\n\nB. Which aspects of music depend on perception of distinct events?\nEchoes serve as an aspect that depends on perception of distinct events. Music depends on\nperception of distinct events when there are dissonant occurrences, like two sources that produce\ndifferent sounds (vocals and bells) or a violinist who does not sync up to the rest of the orchestra.\n\nC. Which aspects of music depend on memory processes (musical contexts, kinds of\nexpectations)?\nExpectations of timing and rhythm may depend on memory processes. Music associated with\ntraditions (such as the wedding march or military fanfares) or widely used musical pieces (like\nthe religious \"Amazing Grace\") can depend on context. For example, the wedding song and\n\"Amazing Grace\" are thought to be slower and more calming than the more bright brass notes of\nthe military wake-up trumpet call).\n\n5. Pitch and the limits of musical tonality\nA. Roughly, what is the range of pure tone frequencies that we can hear?\nWe can hear the frequencies from about 20 to 20,000 Hz.\n\nB. What is the range of pitch (f, F0) frequencies for musical tonality (i.e. over which octaves,\nmusical intervals, and melodies can be readily recognized).\nMost of music occurs within two octaves in the frequency range of 220 to 880 Hz. Components\nof an orchestra (brass, winds, and strings) produce sounds within this range. The range of vocal\nperception a bit larger in the 30 to 5000 Hz.\n\nC. What would constitute an explanation (neural or psychological) for why these ranges are\ndifferent?\nThe range of frequencies we can hear and those that are observed in easily recognized melodies\nare different because we are only able to make meaning of certain patterned sounds, such as\nthose that contain uniform waveforms and expected, 'musically pleasing' note and rhythm\ncombinations. We may hear static or alarm noises at lower or higher frequencies but cannot\nconstruct a meaningful interpretation.\n\nD. Provide a possible (neural or psychological) explanation for why we hear the missing\nfundamental.\nThe phenomenon that Licklider described for hearing the missing fundamental may be the ability\nof the higher cognitive functions to perceive pitch by subtracting frequencies of the harmonic\n(instead of hearing each harmonic separately), resulting in filling in of the missing fundamental\n(a part of the expected harmonic pattern). Neurologically, some theories point to the ability to\ninfer activity from the patterns of the basilar membrane.\n\nE. What does it mean to say that musical pitch is highly invariant with respect to tone intensity,\nlocation, and duration? What is metamery? What would be an example of pitch metamery?\nMusical pitch is not dependent to tone intensity, location, or duration as it is dependent on\nfrequency; a C sharp sounds like a C sharp no matter how intensely it is played on the piano, if it\nis played an octave higher, or if it is held onto longer. An equation confirms this: I=P/A\n(amplitude does not affect frequency, only wavelength and speed of sound).\n\n6. Timbres of musical instruments\nA. What is the main functional role that timbre plays in most western tonal music?\nTimbre gives music texture in tonal music. It is similar to the onset of homophony and\npolyphony after the monophony of chants in Western music, which gave more rich texture with\nmore vocal or instrumental parts.\n\nB. What is the acoustic dimension that distinguishes timbres of stationary sounds?\nStationary sounds do not refer to temporal qualities (timing, such as the envelope qualities of\nattack time and decay) that distinguish between the different sound textures made by instruments\n\nC. What are two factors that distinguish timbres of non-stationary (time-varying) sounds?\nSpectrum and envelope (coloration, tonal character, vibratos, tremolos, etc) are used to perceive\ntimbre\n\nClasses of instruments: 1. pipe organ (vibrating air column), 2. violin (bowed string), 3. piano\n(struck string), 4. bells (struck, metal), 5. snare drum (struck, membrane)\nD. Which classes produce harmonic tones? inharmonic tones?\nHarmonic tones are produced by violins, pianos, and pipe organs. Inharmonic tones can be\ncreated by bells and snare drums.\n\nE. Which classes can produce a melody? rhythm?\nPipe organs, violins and pianos can produce a melody. Bells and snare drums can produce\nrhythms. Bells may also be able to produce rhythm if there is a series of bells with different\npitches (similar to a xylophone).\n\n7. Scales and musical intervals\nA. What is a scale?\nA scale is a series of musical notes in ascending or descending order, usually with the same step\nsize between each note.\n\nB. What role do scales play in music perception?\nScales give a dimension of order in music perception and serve as the basis for how we perceive\npitch. For example intervals and perception in differences between harmonics can be better\nunderstood if one has heard scales played, especially on a piano.\n\nC. What is the tonic? What functional role does the tonic play in perception of melody and\nharmony?\nA tonic is the first note in a musical scale. The musical piece is based on the tonic, and the chord\nincluding the tonic is also usually prevalent; it can be thought of as the 'home key.' Melody and\n\nharmony of the piece may change to different keys and produce different moods, and the tonic\nserves a benchmark for comparison. For example, a symphony may start in C minor and switch\nto E flat major during the exposition or development and conclude in the tonic key of C minor.\n\nD. Why do melodies played in different modes have distinctive qualities, despite their use of the\nsame set of notes?\nMelodies in different modes have distinctive qualities because the pitch relationships between\nthe notes may be somewhat different. Comparing major and minor modes, F in the major mode\nincludes an F# while that of F minor includes the white key. The medieval modes also exemplify\nthis; the fourth interval is augmented in Lydian mode while it is perfect in the other modes, the\nLocrian fifth is diminished while the others are perfect, and there is a mix of major and minor\nintervals (except for the prime and octave) in the different modes.\n\n8. Consonance\nA. What defines a musical interval? Does an interval depend on the absolute (F0) frequency of\nits root?\nA musical interval is defined by the space (number of half steps) between one note and the other\nnote or notes. An interval does not depend on the absolute frequency of the root.\n\nB. \"Consonance\" is associated with 1) euphony and tonal preference on one hand and 2)\nstability/instability and tension/resolution on the other. Dependence of consonance on musical\ncontext notwithstanding, which isolated intervals (octaves, seconds, fourths, fifths, sevenths) are\nperceived as more consonant or dissident?\nOctaves, thirds, fourths, and fifths are interpreted as more consonant, while seconds and sevents\nare interpreted as more dissonant.\n\nC. Two rival theories of consonance were proposed by Helmholtz and Stumpf in the 19th\ncentury. What perceptual aspect of tone combinations does each rely on?\nHelmholtz proposed that the more mismatched the harmonic (the more beats between the notes),\nthe more dissonant the sound, which explains why whole whole tones<perfect fifths<octaves in\nconsonance. On the other hand, Stumpf based his theory of consonance and dissonance on the\nfusion and nonfusion, respectively, of tonal combinations. Helmholtz's theory depends on beats\nwhile Stumpf's relies on fusion.\n\nD. Which aspect is thought to be the result of the beating of nearby harmonics? of waveform\nregularity and its consequences for pitch?\nDissonance is thought to be the result of beating of harmonics nearby. Waveform regularity and\nmore uniform distribution of pitch contribute to consonance.\n\n9. Harmony and harmonics\nA. What notes and musical intervals constitute a major triad chord (I) in the key of C (major)?\nWhat notes and musical intervals constitute a minor triad chord (I) in the key of C (minor)?\nFor a major chord in C major: C, E, and G. C and E, as well as E and G, correspond to a third. C\nand G correspond with the interval of a fifth.\nFor C minor: C, E flat, and G. The intervals are the same as those for C major.\n\nB. Tonal hierarchy of notes. In the context of Krumhansl's probe-tone studies, we discussed tonal\nhierarchies based on 1) the tonic, 2) notes in I - triad, 3) other notes in the diatonic scale, and 4)\nother notes in the chromatic scale. Which notes would fall into these respective classes for the\nkey of C major?\n1) C serves as the tonic note. 2) C,E, and G are in triad I. 3) C D E F G A B are in the diatonic\nscale and 4) C C# D D# E F F# G G# A B flat B.\n\nFor simplicity assume that the tonic (F0) of a just-tuned diatonic scale is 200 Hz and the notes of\nthe scale consist of harmonics 1-6 (consult Handel, p. 331 for just temperament F0 ratios, p. 364\nfor chord notes).\nC. What would be the fundamental frequencies (F0s) of the notes in the major triad (I) if the root\nis 200 Hz?\nIf 200 Hz is the frequency of note C, E is 5/4*200=250 Hz and G is 3/2*200=300 Hz.\n\nD. What harmonics would be present? How many pairs of common harmonics (overlaps) are\nthere?\nThe third and the fifth harmonics would be present. There is a pair of third harmonics (the C to E\nand E to G).\nIf question is asking about the scale, all 6 harmonics would be present and there are 5 2nd\nharmonics, 4 3rds, 3 4ths, 2 5ths and 1 6th.\n\nE. What would be the fundamentals of the notes in the minor triad (I)? How many harmonic\noverlaps would there be?\nThe fundamentals of the notes and the harmonic overlaps would be approximately the same, but\nhaving the E flat instead of the E corresponding to a white key would alter the calculations by a\nhalf step more for the C to E flat 3rd harmonic and half a step less for the E flat to G third.\n\nIn major keys, chords of scale degrees I, IV, and V have major interval patterns (Major 3rd +\nMinor 3rd), while other scale degrees II, III, VI, VII have minor interval patterns (Minor 3rd +\nMajor 3rd). If chord stability, consonance, and pitch unity were determined solely by the\nproportion of coincident harmonics, would you expect the major or minor triad pattern to be\nmore stable? Why?\nI would expect the major triad to be more stable because there is more symmetry in the chord\npatterns (no half step differences between the third harmonics). Also, I, IV, and V have more\nconsonance than the minor scale dcgrees (especially the II and VII).\n\nIf chord stability were determined by the strength of the fundamental bass, which in turn were\ndetermined by the number of coincident subharmonics, which pattern would be more stable?\nIn this case, perhaps the minor triad pattern would be more stable because it may have more\ncoincident subharmonics and therefore a stronger fundamental base and greater stability (unless\nthe shared subharmonics for I and V are greater than those shared between II, III, and VII).\n\n10. Chord progressions\nA. What is a chord progression?\n\nChord progression is a series of chords played according to the order of a scale.\n\nB. In musical contexts, chord stability is also influenced by its relation to the tonic. If degree of\nrelatedness between a chord (II-VII) and the tonic chord (I) of the key (Krumhansl et al, 1982, Handel,\np. 365) determines the perceptual \"stability\" of that chord, then what pattern of movement would\nbe expected for a I-IV-VII-I progression? Assume that movement from a less stable chord to a\nmore stable one is \"resolution\" (R), while the opposite movement builds \"tension\" (T), e.g., a I-IV-\nII-V-I produces a pattern of movement of T-T-R-R, see Handel, p. 341).\nT-T-T-R\n\nC. What is key modulation?\nModulation is the process of changing from one key to another, sometimes the same key an\noctave higher or lower (so key signature does not change though it can in modulation in general).\n\nD. Why might perceived relatedness of chords depend on key context? (Handel, p. 373)\nThere is an element of expectation that the context key engenders; relevant notes and triads to the\nkey context sound consonant while others sound \"jarring\". Spatial differences of chords within\nthe contexts (versus no context) are also important.\n\n11. Melody\nA. What is a melody?\nA melody is a linear combination of musical tones that is thought of as a unified entity.\n\nB. What does it mean to say that melody is invariant under transposition?\nThe melody stays the same no matter what key it is played in.\n\nC. What distinguishes a tonal from an atonal melody (see Handel, pp. 355-361)?\nTonal melodies are perceived to have a single theme because of sequential contours of a melody\n(the amplitude up and down or +/- patterns), size and direction of semitone intervals between\nsuccessive notes, the pattern of scale steps in a tonal framework, and the actual notes played in\nthe melody.\n\nD. Which is more important for melody recognition in tonal contexts: absolute pitch, pitch\ncontour sequences of musical intervals, relations of notes to the tonic?\nRelation of the notes to the tonic is more important for melody recognition in tonal contexts.\n\nE. What are the shortest notes that can support a good melody (ballpark)? the longest notes?\nThe shortest notes are 900 Hz and the longest 200 Hz.\n\n12. Rhythm\nA. Define tempo, accent, beat, meter, and rhythm.\nTempo-speed or pace of a composition\nAccent-an emphasis placed on a certain musical note, played louder and with faster onset\nBeat-a basic time unit used in music\nMeter- a length measurement of stressed and unstressed beats\nRhythm-timing of a series of notes\n\nB. How does rhythm differ from melody? How are these two aspects of music similar? How are\nthey different?\nRhythm focuses on temporal components while melody focuses on pitch relations, though there\nis still an element of rhythm in melody.\n\nC. Why is accent important for perception of rhythmic pattern?\nAccents call attention to certain beats and sometimes changes in rhythm, which may help guide a\nlistener rhythmically. For example, in the beginning of Stravinsky's \"Rite of Spring\" gives an\naccent every six beats to give a sense of progression of tenseness and conflict.\n\nD. If tempo is set at 1 quarter note = 1 beat at 120 bpm, how long in absolute terms is a quarter\nnote? a 16th note?\nA half note (?) would be 120*2=240 bmp and a 16th note is 120*2*2 (quartereighth\nsixteenth)=480 Hz.\n\nE. How do the note durations needed to support a good melody relate to those needed for a good\nrhythm?\nNote durations can add to the sentiments or mood of a piece. For example, a fermata may give a\nsense of closure to a piece or movement of a piece.\n\n13. Organization of voices (auditory scene analysis)\nA. What acoustical factors influence whether two instruments will be perceptually fused (heard\nas one voice)?\nThe pitch or frequency range and timbre, as well as rhythmic synchronicity and beat patterns,\ninfluence whether instruments are thought of as fused.\n\nB. What distinguishes a homophonic from a polyphonic piece of music? What musical factors\n(melody, harmony, rhythm) influence whether a musical piece is (perceived as) one or the other?\n\nA homophonic voice is centered on one melody and rhythm, even if there are several voices\ncontributing to the harmony (ie an acapella group). A polyphonic piece has greater texture\nbecause the different parts or voices may enter at different times with varying rhythms and\nharmonies.\n\n14. Innate vs. learned mechanisms. In your opinion, which aspects of music perception and\ncognition are likely to depend on bottom-up mechanisms of auditory perception? Which aspects\nare likely to depend on prior auditory experience that is not culture specific? Which are likely to\ndepend on culture-specific auditory experiences, i.e. cultural conditioning? (Short paragraph,\nbriefly give reasoning.)\nBottom-up mechanisms that just rely on sensory inputs may include timbre, as it seems to be\nrecognized very easily and there are no circumstances I know of that can impair somebody's\nability to tell apart the sounds of a waterfall or drum. Rhythm may also be in this category but\nthere are instances where rhythm may appeal to a higher process of expectation. For example,\nParkinson's disease or stroke patients can improve their gait or be roused from their catatonia, in\nthe case of PD. Autistic individuals often respond to the rhythmic components in music therapy.\nThose that are deaf (and thus without the bottom up processes involved in hearing) are likely to\n\nrecognize patterns in metronome ticking or ebbing and flowing of the tide. I believe having\nrelative 'perfect' pitch can be conditioned. The notion of consonance is likely inherent as it is\nimmediately and universally recognized. Some cultures may have more dissonant sounding\nelements, most basic chants still have musicality.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Course Introduction",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/ef79c16ae27c2f1ef58c8c0e27bb98f4_MITHST_725S09_lec01_intro.pdf",
      "content": "Music Perception & Cognition\nHST 725\nPeter Cariani\nDepartment of Otology and Laryngology\nHarvard Medical School\nSpeech, Hearing and Biotechnology Program\nHarvard-MIT Division of Health Sciences & Technology\nwww.cariani.com\nWednesday, February 4, 2009\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nOutline\n- Course mechanics\n- Class survey\n- Music, mind, and brain\n- FORM & QUALITY\n- PATTERNS OF EVENTS IN TIME\n- NEURAL MECHANISMS\n- MEMORY/GROUPING\n- EMOTION/MEANING\n- ORIGINS\n- Overview of topics\n- Music introduction\nWednesday, February 4, 2009\n\nWednesday, February 4, 2009\n\nTexts\nTexts: (Available at the MIT Coop and/or MIT Press Bookstore)\n-Deutsch, D. ed. 1999. The Psychology of Music. San Diego: Academic Press.\n\nRequired. (MIT Coop)\n-Snyder, Bob. 2000. Music and Memory. MIT Press. (Currently required, may be\n\noptional, MIT Coop & MIT Press Bookstore)\n-Handel, S. 1989. Listening: an Introduction to the perception of Auditory Events.\n\nMIT Press. Recommended. (MIT Press Bookstore)\n-Levitin, D. 2006. This is Your Brain on Music. Required. (MIT Coop, optional)\n-McAdams & Bigand. 1993. Thinking in Sound: The Cognitive Psychology of Human\nAudition. Oxford. Recommended. Not at the Coop.\n-Aello, R. ed. 1994. Musical Perceptions. OUP. Recommended, not at the Coop.\n-Moore BCJ. 2003. An Introduction to the Psychology of Hearing, Fifth Ed.. San\nDiego: Academic Press. Recommended. At the Coop.\nWednesday, February 4, 2009\n\nFormat\nFormat:\nLecture format + demonstrations, discussions & presentations.\nBegin promptly at 7 PM.\n\nWe will always have a 5-10' break at 8 PM.\nLecture\nMusic presentations, of one sort or another\nStudent presentation followed by discussion (when we do this)\nFor each aspect of music, we'll try to cover topics in this order:\nMusic & sound (stimuli)\nPsychoacoustics, psychology\n(listener's response, incl. our own)\nNeurocomputational models (information processing theories)\nPossible neurobiological substrates (neurophysiology)\nWe will also go back and forth between bottom-up approaches to\n\nparticular aspects and their relevance to music as a whole.\nWednesday, February 4, 2009\n\nClass meeting timeline\n50'\n50'\n5-10' Break\nStretch\nMusic\nWednesday, February 4, 2009\n\nOrganismic biology (undergrad @ MIT mid 1970s)\nBiological cybernetics & epistemology (1980s)\n\nBiological alternatives to symbolic AI\n\nHoward Pattee, Systems Science, SUNY-Binghamton\nTemporal coding of pitch & timbre (1990s-present)\n\nAuditory neurophysiology, neurocomputation\nHow is information represented in brains?\nCommonalities of coding\nacross modality & phyla\nNeural timing nets for temporal processing\n\nAuditory scene analysis\nPossibilities inherent in time codes\n\nTemporal alternatives to connectionism\n\nsignal multiplexing; adaptive signal creation broadcast\nMy trajectory\nWednesday, February 4, 2009\n\nAvid listener, but a mediocre musician\nV. interested in music growing up , played violin (badly)\nAttempted to teach myself music theory in HS\nHeavily into baroque music & progressive rock\nElectronic & dissonant \"experimental\" music\nTook \"sound sculpting\" as an MIT undergrad\nWorked w. Bertrand Delgutte on neural coding of pitch\n\n& Mark Tramo on consonance (1990's)\nDeveloped timing nets for music (2000's)\nProposed course in music perception for Harvard-MIT\nHST graduate speech & hearing program (2003)\nTaught this course at Tufts in fall 2003\nTaught graduate course @ MIT in 2004 & 2007\nTeaching @ Tufts & MIT this term\nMy trajectory vis-a-vis music\nWednesday, February 4, 2009\n\nBig questions (Whys and Hows)\n- To be explained: the \"unreasonable\neffectiveness\" of music\"\n(to paraphrase Wigner on the unreasonable effectiveness of mathematics in explaining the physical world)\n- Why does music have its profound effects on\nus?\n- How does the auditory system and the brain\nwork such that music can have the effects that\nit does?\n-\n(to paraphrase Warren McCulloch, \"What is a number that a man may know it, and a man that he may\nknow a number?\")\nWednesday, February 4, 2009\n\nOrganizing themes: Music, mind, and brain\n- FORM & QUALITY OF SOUNDS (tones)\n- PATTERNS OF EVENTS IN TIME (events)\n- NEURAL MECHANISMS\n- MEMORY & ORGANIZATION (grouping)\n- EMOTION & MEANING, tension & relaxation\n- ORIGINS: Why music?\nWednesday, February 4, 2009\n\nCourse rationale(s)\n- Music is an important aspect of the auditory sense that rivals\nspeech and language in complexity\n- Many of us come to auditory research through a native\ninterest in music\n- Music affords an alternative perspective on hearing and\nneuroscience, spanning acoustics, sensory physiology,\nauditory perception & auditory cognition\n- We strive to be systematic and integrative in our treatment\n(lecture format, common grounding)\n- A primary goal is to facilitate intellectual synthesis; to organize\ndisparate facts into coherent wholes\n- We want students to choose & formulate their own problems,\narticulate their own perspectives, and delve deeply into an\narea of personal interest (fundamental problems, term projects)\nWednesday, February 4, 2009\n\nGeneral Plan\n- Initial overview\n- Music, What we hear, How we hear\n- Elements of music\n- Pitch, timbre, consonance, chords; neural representations\n- Organizations of tone and event patterns\n- Melodies, Rhythmic patterns, expectancies; neuro-computations\n- Effects --\n- anticipations and emotional-cognitive effects;\n- towards a functional neurology of music\n- Origins & special topics (why music)\nWednesday, February 4, 2009\n\nTuesday Feb. 3\nCourse mechanics, introductions, and course design\nSurvey of topics to be covered\nOverview of the structure of music\nHorizontal and vertical dimensions. Pitch, tone quality/color, consonance, melody,\nharmony, tonality, organization of voices, rhythm, dynamics, expressive timing,\ntonal and rhythmic hierarchies\nOverview of music's psychological and social functions\nEmotion & meaning, psychological and social functions of music.\nThursday, Feb. 5\nOverview of auditory perception and the time sense\nPitch, timbre, consonance/roughness, loudness, rhythm, auditory grouping, event\nstructure\nWednesday, February 4, 2009\n\nThursday, Feb 12 Pitch\nMusical acoustics I - periodic sounds\nSound & vibration, production of sounds, representations of sound, waveforms & power\nspectra,\nPsychophysics of pitch\nNeurocomputational models for pitch - spectral pattern and temporal models\nLicklider, Terhardt, Grossberg & Cohen, Bharucha\nRepresentation of pitch in the auditory system, time & place\nNeural evidence pros & cons\nPitch in object formation and separation\nTuesday, Feb. 17 NO CLASS -- PRESIDENTS' DAY (Monday class schedule)\nThursday, Feb. 19 Timbre\nMusical acoustics II - complex tones and time-varying sounds\nSound & vibration, production of sounds, representations of sound, waveforms & power\nspectra, characteristics of musical instruments and human voices, similarities and differences\nbetween speech and musical sounds (\"lexical music\")\nTimbre - Acoustic correlates - spectrum, time-frequency trajectory, amplitude dynamics\nDimensional analysis of timbre perceptual spaces (multidimensional scaling)\nRole of timbre in defining & distinguishing separate voices, musical coloration\n\nNeural correlates, coding of spectrum, attack, decay, modulation\nTimbral space and phonetic contrasts; Tonal languages and music\nWednesday, February 4, 2009\n\nTuesday, Feb. 24 Consonance\nHarmony I: Consonance, dissonance, and roughness\n\nTheories: Helmholtz, Stumpf, Plomp, Terhardt\nSensory and hedonic aspects\nNeural correlates (auditory nerve, midbrain, cortex)\nScales and tuning systems\n\nHistory, basic psychophysics, scales and tuning systems, role in music theory\nRelations between auditory and cultural factors\nThursday, Feb. 26\nHarmony II: chords and keys\n\nPerception of chords, pitch multiplicity (Parncutt, Terhardt), higher order structure\nof pitch space\n(Shepard, Krumhansl), fundamental bass, keys, major-minor and\nresolved/unresolved chords, tonality induction, tonal schemas/key relations,\ncomputational models (Leman), neural correlates of tonal relations and expectations\n(fMRI, ERP)\n\nTuesday, March 3\nMelody\nPerception of note sequences, existence region, melodic expectation, melodic\nrecognition, melodic memory, melodic grouping processes (phrases), neural representation\nof melody, problem of melodic invariance under transposition\nWednesday, February 4, 2009\n\nThursday, March 5\nRhythm I: Rhythm perception and production\nBasic psychophysics of rhythm perception and production\nRole of rhythm in melodic recognition & recall\nRhythm II: Computational models\nOscillator models, clock models, rhythmic hierarchies, timing nets\nTime perception, event structure, and temporal expectations\nAuditory spectral and temporal integration; chunking of segments\n\nTime perception (Fraisse, Jones)\nTuesday, March 10\nGestalts: Auditory scene analysis: grouping/chunking/\n\nGrouping of sounds - onset, harmonicity, rhythm\n\nSound streams (Bregman, Deutsch), polyphony, polyrhythms\nGrouping of tones and events\nGrouping processes and musical structure\nCommon mechanisms; analogies in vision\nState of automatic music recognition systems\nWednesday, February 4, 2009\n\nThursday, March 12 Music of the Hemispheres\nMusic and the cerebral cortex. Overview of functional role of cortex in music\nperception & cognition. Results of imaging and lesion studies. Hemispheric\nasymmetries. Neurological theory of psychological functions.\nTuesday, March 17\nAnticipation and expectancy\nThursday, March 19\nEmotion and meaning in music: what it means to us (internal semantics, memory,\nfashion/identity, pleasure)\nMusic and psychological functions - activation of different circuits related to\ndifferent uses/effects of music\nMusic and long-term memory: how can we remember melodies years later?\nInnate vs. cultural determinants of musical expectation and preference\nWeek of March 23\nNo class - MIT Spring Break\nWednesday, February 4, 2009\n\nThursday, April 2 Music therapy (K. Howland, music therapist)\n- \"Clinical applications of the neuropsychology of music.\" Guest speaker Kathleen M.\nHowland Ph.D., MT-BC, CCC-SLP. Clinical problems, current therapies, and prospects for\nnew therapies.\nTuesday, April 7 Music and Cortical Function\nNeurology of music, Effects of cortical lesions on music perception and cognition\nActivation of circuits responsible for different musical functionalities\nThursday, April 9 Music, Speech & Language\n- Music cognition and psycholinguistics, speech and language:\nParallels and contrasts between music, speech, and language (Bernstein, Jackendoff, Lerdahl)\nIs there a grammar of music? Rule-following vs. rule-obeying systems. Symbols and\ncategorical perception. What are the neurocomputational substrates for recognition of musical\nstructure?\nTuesday, April 14 Developmental psychology of music\nDevelopmental psychology of music - perception & cognition\nRhythmic expectation, melody perception, early preferences\nInnate faculties vs. associative learning\nThursday, April 16 Evolutionary origins\nThe debate about the evolutionary psychology of music.\nWednesday, February 4, 2009\n\nTuesday, April 21 NO CLASS Patriot's Day Holiday\nThursday, April 23 Clinical issues\n- Clinical issues. Music exposure and hearing loss. Music perception and hearing impairment. Music\nand hearing aids. Music perception by cochlear implant users. Possible technological remedies.\nTuesday, April 28 Creativity & performance\n- Music performance & creativity. fMRI studies. Organization and timing of movement.\nThursday, April 30 Student Final Project Presentations\nTuesday, May 5\nStudent Final Project Presentations\nThursday, May 7 Special topics\n- Special topics: absolute pitch & pitch memory, synesthesia, audio-visual parallels, etc.\nTuesday, May 12 Special topics\n- Some possible topics: music performance (motor timing & sequencing), music & dance, spatia\nhearing, architectural acoustics\nThursday, May 14 Wrap-up and Recapitulation\n- Overview and recap of major themes; other special topics\nWednesday, February 4, 2009\n\nCoursework\nCoursework:\n- Problem sets (20%)\nOne problem set will be on harmonic structure and tuning systems. The other will cover topics in music\nperception and cognition.\n- Musical examples (10%)\nFind 5 musical examples from any genre that illustrate or illuminate different aspects of music perception &\ncognition related to melody, harmony, rhythm, your own musical preference, and some aspect of your\nchoosing. We will listen to them as a class and discuss them.\n- Reading assignment & presentation (10%)\nA relevant paper will be chosen, presented (10-15'), and discussed by the class. This can be one of the papers\non the reading list or any paper that you feel is important or insightful.\n- Fundamental unsolved questions in music psychology - 3-4 page outline/discussion (20%)\nI have compiled a list of unsolved questions in music psychology. Please choose from the list or suggest your\nown problem. Write up an account of the nature of the problem (1-2 paragraphs), its theoretical\nsignificance (1 paragraph), current theories (if any, 1-3 paragraphs), two plausible hypothetical\nexplanations (2-4 paragraphs), ideas concerning how the question might be solved or hypotheses tested\n(1 paragraph), and some assessment of how soon the problem will likely be solved (1 paragraph). Each\nstudent will present a problem and outline their thinking about it, which will form the basis for a class\ndiscussion.\n- Term project (50% of final grade)\nA research paper, review paper, or research pro ject (e.g. psychological or physiological experiment,\ncomputer model/simulation) related to the psyc hology of music. Topics will be presented orally and\ndiscussed in class in mid-March. Project results will be presented and discussed in class in the last two\nweeks of class. Target length of paper will depend on nature of project. Final papers will be due on the\nlast day of c lass. I will be happy to read an d give comment on outlines and drafts at any stage of\npreparation.\nWednesday, February 4, 2009\n\nSource: IMSLP.org\nAn Introduction to Music:\nSound unfolding in time\nwww.cariani.com\nWednesday, February 4, 2009\n\nSound unfolding in time: an introduction to music\n- Music: a bird's eye view; provisional definition\n- Ubiquity of music: Nature and nurture\n- Sound unfolding in time\n- Horizontal dimension (time, sequential sounds)\n- Melody (Temporal patterns/sequences of pitches)\n- Chord progressions, key modulations (Temporal patterns/\nsequences of pitch relations)\n- Rhythm (Temporal patterns/sequences of events)\n- Vertical dimension (sound quality, concurrent sounds)\n- Pitch (Dominant periodicities) & Timbre (spectrum, frequency microdynamics)\n- Harmony (Constellations of concurrent pitches)\n- Number of independent trajectories: voices, streams\n- Relations to perceptual dimensions\n- Psychological questions\nWednesday, February 4, 2009\n\nMusic as stimulus, idea, action, and private experience\nPsychology of music examines relations\nbetween music and mind.\nrelation\nMusic is half of this relation.\nMind has different facets:\n1st person experience\n3rd person overt behavior\nUnderlying neural activity\nFunctional organization of\ninformational processes\nWednesday, February 4, 2009\n\nMusic: a provisional definition\nDeliberate organization of patterns of sound for interest or pleasure.\nDeliberate organization of auditory experience for interest or pleasure.\n\n\"Organization\" can involve composition or\n\nperformance or selection of sounds\n\nor even selective attention to sounds (Cage)\n\"Interest\" and \"pleasure\" are similarly very broadly construed.\nWednesday, February 4, 2009\n\nUbiquity of music: Nature and nurture\n- Music has been part of human culture for > 40,000 years\n- Every known extant culture has some form of music\n- Many cultures equate musical with social harmony (Greeks)\n- Relative contributions of nature (biology) & nurture (culture)\nto the experience of music.\n- A great deal of diversity exists across cultures in the forms\nmusic takes (ethnomusicology)\n- There are universals related to how we hear that are given by\nbiology (auditory science).\n- But there are also the effects of culture-based training of how\nwe hear (what aspects we attend to).\n- There are also culturally-specific interpretations and\nmeanings associated with what is heard.\n- In these lectures we will focus mainly on the universals --\nbasic aspects of music that are shared across cultures.\n- We want a general framework for talking about music that can\nencompass both the Western tonal music (classical, jazz, popular) as well\nWednesday, February 4, 2009\n\nHorizontal and vertical dimensions\nTonal quality\n(pitch, spectrum)\nTime (beats, seconds)\nsuccessions of events, changes\nWednesday, February 4, 2009\n\nHorizontal and vertical dimensions\nTonal quality\n(pitch, spectrum)\nTime (beats, seconds)\nsuccessions of events, changes\nWednesday, February 4, 2009\n\nHorizontal and vertical dimensions\nTonal quality\n(pitch, spectrum)\nhttp://www.well.com/user/smalin/compare.htm\nTime (beats, seconds)\nsuccessions of events, changes\nWednesday, February 4, 2009\nCourtesy of Stephen Malinowski. Used with permission.\n\nHorizontal and vertical dimensions\nTonal quality\n(pitch, spectrum)\nDensity\nComplexity\n# independent trajectories\nhttp://www.well.com/user/smalin/compare.htm\nTime (beats, seconds)\nWednesday, February 4, 2009\nCourtesy of Stephen Malinowski. Used with permission.\n\nHorizontal dimension (time)\nTemporal patterns and sequences of sound-changes\nMelody: temporal patterns of pitches\nCadences, key modulations:\ntemporal patterns of pitch constellations\nRhythm: temporal patterns of events\nBernstein on musical intervals and dimensions\nSource: IMSLP.org\nTime\nWednesday, February 4, 2009\n\nHorizontal dimension (time)\nDifferent musical cultures utilize different aspects of musical\n\npossibility. Ethnomusicologists, anthropologists, and\nhistorians have theories as to why cultures adopt\n\nparticular musical styles.\nExamples of music that are focused on melody.\n\n(Traditional fiddle-playing in France -- video)\n\n(Gasparyan, Armenian flute music)\nIndian ragas\nExamples of musics focused on chord progressions\n\nWestern symphonic \"classical\" music, Rock\nExamples of music focused on rhythm\nAfrican drumming (many examples)\nMbira music, Senegal -- video\nWednesday, February 4, 2009\n\n------------------------\nVertical dimension (Harmony)\nPatterns of concurrent sounds\nConstellations of pitches (intervals, chords)\nSound texture (timbre)\nNumber of independent voices\nExample of horizontal and vertical organization:\n\nSatie Music Animation Machine\nHorizontal dimension involves temporal context & memory\nBuild-up of representations and expenctancies\nVertical dimension involves tonal interactions\nMasking, fusions of sounds\nWednesday, February 4, 2009\n\nRethinking the role of time\n- Time as coding auditory quality (pitch, timbre, rhythm)\n- Time as metrical structure of events\nRepetition and change in music\nBuildup of temporal pattern expectations\n- Time as ordinal sequence of events\nPerception\ncognition\n&\nmotor\ndomains\nWednesday, February 4, 2009\n\nAuditory qualities in music perception & cognition\n- Pitch\n\nMelody, harmony, consonance\n- Timbre\nInstrument voices\n- Loudness Dynamics\n- Organization Fusions, objects. How many voices?\n\n- Rhythm\nTemporal organization of events\n- Longer pattern Repetition, sequence\n- Mnemonics Familiarity\n- Hedonics\nPleasant/unpleasant\n\n- Semantics Cognitive & emotional associations\nWednesday, February 4, 2009\n\n8k\nFrequency ranges of (tonal) musical instruments\n> 6 kHz\n2.5-4 kHz\n27 Hz\n4 kHz\nHz\nHz\nHz\nHz\nWednesday, February 4, 2009\n\nDimensions of auditory objects\nDimensions of event perception\nAuditory qualities and their organization\nUnitary events & their organization\nObjects: Quasi-stationary\nEvents: abrupt perceptual\nassemblages of qualities\ndiscontinuities\nTimbre\nLoudness\nLocation\nSpatial Dimensions\nPitch\nTEMPORAL\nEVENT\nSTRUCTURE\nTiming & order\n(metric, sequence)\nDuration\nFUSION/SEPARATION\nFUSION/SEPARATION\nCommon onset & harmonic structure => fusion\nCommon onset, offset => fusion\nDifferent F0s, locations, onset => separation\nDiff. meters, pitch, timbre => separation\nPOLYPHONY\nSTREAMS, POLYRHYTHMS\nWednesday, February 4, 2009\n\nMusic: patterns of events in time\norganized relations between events\nWednesday, February 4, 2009\n\nMusic: patterns of events in time\norganized relations between events\nWednesday, February 4, 2009\n\nFrom cochlea to cortex\n10,000k\nPrimary\nauditory cortex\n(Auditory forebrain)S\nc\nh\nematic of afferent auditory pathways, from the cochlea to the auditory cortex.\nAuditory thalamus\n500k\nInferior colliculus\n(Auditory midbrain)\nLateral lemniscus\nAuditory brainstem\n30k\nAuditory nerve (VIII\n3k\nCochlea\nWednesday, February 4, 2009\nFigure by MIT OpenCourseWare.\n\nMECHANISM\nNeural codes\nNeural\narchitectures\nFunctions\nInformation-processing\noperations\nSensory\nencodings\nMotor\ncommands\nExternal\nworld\nReceptors\nEffectors\nWednesday, February 4, 2009\n\nMECHANISM\nNeurophysiology\nMusic cognition\nNeurocomputation\nMusic theory\nWednesday, February 4, 2009\n\nNeurophysiology\nNeurocomputation\nMusic cognition\nMusic theory\nNeural responses\nSchemas, grammars\nNeural codes\nEvent structures\nNeuroanatomy\nTonal hierarchies\nPsychoacoustics\nMemory\nReverse-engineering\nAesthetics, hedonics\nExplaining pitch\nPitch as a primitive\nWednesday, February 4, 2009\n\nVisual grouping\nDember & Bagwell, 1985, A history of perception, Topics in the History of Psychology, Kimble & Schlesinger, eds. Three arranged groups of 16 squares: rectangular, square, and trapezoidal.\nFigure by MIT OpenCourseWare.\nWednesday, February 4, 2009\n\nAcoustical grouping\n\n(Snyder, Music & Memory)\nWednesday, February 4, 2009\nSource: Snyder, Bob. Music and Memory. Cambridge, MA: MIT Press, 2000. Courtesy of MIT Press. Used with permission.\n\nMelodic grouping & rhythmic grouping\nWednesday, February 4, 2009\nSource: Snyder, Bob. Music and Memory. Cambridge, MA: MIT Press, 2000. Courtesy of MIT Press. Used with permission.\n\nRhythmic\nHierarchy\nHandel\nWednesday, February 4, 2009\nSource: Handel, S. Listening: an Introduction to the\nPerception of Auditory Events. Cambridge, MA: MIT Press,\n1989. Courtesy of MIT Press. Used with permission.\n\nRepeated patterns, groupings,\nexpectancies, and their violations\nWednesday, February 4, 2009\n\nGlobal temporal pitch representation (Cariani and Delgutte, 1996)\nPitch (frequency) =\nthe predominant interval\nor interval pattern\nPitch strength (salience) =\nthe relative fraction of\npitch-related intervals in\nthe whole distribution\nDetectability: A pitch can be\nheard iff its salience\n-All-order interspike intervals\n-Population-wide distribution:\n-All auditory nerve fibers\n-(all CFs, all SRs)\nPredictions\nWednesday, February 4, 2009\n\nNeural timing nets\nFEED-FORWARD TIMING NETS\nRECURRENT TIMING NETS\n- Temporal sieves\n- Build up pattern invariances\n- Extract (embedded) similarities\n- Detect periodic patterns\n- Multiply autocorrelations\n- Separate auditory objects by F0\n- Pitch & timbre matching\n- Metric induction\n- Time domain comb filters\nRelative delay \nTime\nt\nSj(t)\nSi(t)\nSi(t) Sj(t - )\nindividual\nmultiplicative\nterm\nSi(tm) Sj(tm - t)\n\n\nconvolution\ntime-series\nterm m\ntwo sets\nof input\nspike trains\nInput time sequence\nAll time delays present\n0\n1\n2\n3\nCoincidence\nunits\nDirect inputs\nRecurrent,\nindirect inputs\nTime patterns reverberate\nthrough delay loops\nWednesday, February 4, 2009\n\nEmotion & meaning in music\nPsychological functions of music: why we do it\n- Perceptual-cognitive interest (formalism, surprise)\n- Mood control & emotional expression (expressionism, nostalgia)\n- Social functions (religious, athletic, & civic ritual; courtship; dance;\ngroup cohesion; shared symbols; group identity)\nSources of meaning: reference and/or construction\nThe meaning of meaning: semiotics\n- External env. associations: linkages w. memories\n- Lyrics and their semantics\n- Internal associations: body rhythms, patterns\n- External musical associations, expectations (e.g. dirge)\n- Intrinsic music expectations (harmonic & rhythmic org.)\nWhat cues convey emotional meaning in music?\nWednesday, February 4, 2009\n\nWednesday, February 4, 2009 Figure illustrating regions of the brain that may be involved in music perception and performance.\nFigure by MIT OpenCourseWare. After Tramo, M. Science 291, no. 5501 (2001): 54-56.\n\nReading for Thursday, Feb. 8\nWhat we hear:\nDeutsch Chapter 4\n(Rasch & Plomp)\nWednesday, February 4, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Interactions between tones: Consonance & dissonance",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/51819fb4c1cc2e167f42605791472dc3_MITHST_725S09_lec08_conson.pdf",
      "content": "HST.725: Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\nInteractions between tones:\nConsonance & dissonance:\nFriday, March 13, 2009\n\nConsonance and dissonance: relevance\n- Pitch interactions between notes\n- Musical intervals\n- Euphoniousness, smoothness, clarity\n- Determine choice of musical intervals (scales)\n- Vertical Harmonies - concurrent notes, chords\n- Horizontal Harmonies - melodies\n- May provide a foundation for tonal structure\n- Tonal tension-relaxation, pitch stability\n- Bernstein on intervals (movie, see Blackboard)\nFriday, March 13, 2009\n\nTonal consonance: interactions of tones\n- Pythagorean experiments\n- Beating, roughness, fusion\n- Psychophysics of consonance\n- Meanings of \"consonance\" and \"dissonance\"\n- Euphonious, \"pleasant\" vs. jarring, unpleasant\n- Smooth, well-defined, unified vs. rough, buzzy, unsettled\n- Neural correlates of roughness (cochlear filtering)\n- Periodicities below the range of the pitch mechanism\n- Population-wide fluctuations in discharge rates\n- Neural correlates of tonal fusion (pitch)\n- Consonance in music\n- Tuning systems and scales\n- Instability-Stability (tension-resolution)\nFriday, March 13, 2009\n\nPredicted consonance of harmonic complexes (n=1-6)\nGra\nph\no\nf predicte\nd\nco\nns\nonan\nces of\nharm\nonic\ncom\nplex\nes\n.\nFigure by MIT OpenCourseWare.\nFriday, March 13, 2009\n\nConsonant intervals\nIn most tonal contexts, these intervals are perceived as more consonant.\nHowever there can be contexts where some of these intervals can be dissonant.\nCONSONANT INTERVALS\nTable of consonant inte\nrvals.\nFigure by MIT OpenCourseWare.\n\nC-Major diatonic scale (white keys CDEFGABC)\nC-Minor diatonic scale (CD\nDi\nag\nra\nm\nof\no\nne\noctave, C-C, of a piano keyboard.\nFigure by MIT OpenCourseWare.\nFriday, March 13, 2009\n\nPythagoreans (6th c. BCE)\ninterplay of music,\nscience, & mysticism\nquaternery (1+2+3+4)\ncontains consonances\nmusic of the spheres\nuniversal harmonies\nnumerologies\nphysics, acoustics\nGalileo (father & son)\nDescartes\nMersenne, Saveur\nRameau\nFourier, Ohm, Helmholtz\nSeebeck\nFriday, March 13, 2009\n\nmusic of the\nspheres\nuniversal\nharmonies\nnumerologies\nphysics, acoustics\nWikipedia: Musica universalis:\nThe three branches of the Medieval\nconcept of musica were presented by\nBoethius in his book De Musica:\n\nmusica universalis (sometimes\nreferred to as musica mundana)\n\nmusica humana (the internal\nmusic of the human body)\n\nmusica instrumentalis (sounds\nmade by singers and\ninstrumentalists)\nFriday, March 13, 2009\n\nPythagorean ratios\nImages removed due to copyright restrictions.\nFigure 2-5 and 2-6 in Pierce, John R. The Science of Musical Sound.\nRevised ed. New York, NY: W. H. Freeman, 1992.\nFigure 2-5. Greek citharis. The cithara\nwas sacred to Apollo.\nPierce, The Science of Musical Sound\nFriday, March 13, 2009\n\nSpectrum of a string\nImage removed due to copyright restrictions. See Fig. 2.6 in Sethares, W. A. Tuning, Tibre, Spectrum,\nScale. 2nd ed. New York, NY: Springer, 2005. ISBN: 9781852337971. [Preview in Google Books]\nFriday, March 13, 2009\n\nSpectrum\nof plucked\nstrings\nImage removed due to copyright restrictions. See Fig. 2.5 in Sethares, W. A. Tuning, Tibre, Spectrum,\nScale. 2nd ed. New York, NY: Springer, 2005. ISBN: 9781852337971. [Preview in Google Books]\nFriday, March 13, 2009\n\nFrom beating to roughness to tonal separation\nFriday, March 13, 2009\nImage removed due to copyright restrictions. See Fig. 2.17 in Sethares, W. A. Tuning, Tibre,\n\nSpectrum, Scale. 1st ed. New York, NY: Springer, 1998. ISBN: 9783540761730.\n\nance\nensory Disson\nSensory dissonance (roughness)\nGraph of sen\nsory dis\nsonance vs.\nfr\nequenc\ny interval, showing\nstrong peak around\nfirst\nsemitone interval.\nFigure by MIT OpenCourseWare.\nFriday, March 13, 2009\n\nTonal\ninteractions\n(tone generator demo)\nDi\nag\nram representing pe\nrceptual p\nhenome\nna resulting from\ntwo t\nones w\nith a small\nfrequency di\nfferen\nce -- graphed as pitch vs. frequency.\nFigure by MIT OpenCourseWare.\nFriday, March 13, 2009\n\nBeating of harmonics\nFriday, March 13, 2009\n\nImage removed due to copyright restrictions. See Fig. 2.15 in Sethares, W. A. Tuning, Tibre,\n\nSpectrum, Scale. 1st ed. New York, NY: Springer, 1998. ISBN: 9783540761730.\nFriday, March 13, 2009\nSpectral fusion\n\nf\ns\nnding\nons\n\ne\nCourtesy of Prof. Mark J. Tramo, M.D., Ph.D. Used with permission.\nBeating o\nharmonic\nand\ncorrespo\nfluctutati\nin neural\ndischarg\nrates\nFriday, March 13, 2009\n\nNeural coding of roughness\nDischarge rate fluctuations in neuronal ensembles in the 20-120\nHz range encode beatings of nearby harmonics\nThese fluctuations exist in ensembles of auditory nerve fibers\n(CF band) and across the whole AN population (population\nPST)\nThey are seen at the level of the midbrain (IC) -- work by\nMcKinney, Delgutte, & Tramo\nRoughness as infra-pitch -- too slow for pitch mechanisms, too\nfast for resolving individual events (rhythm)\nNot clear to me whether it is the rate fluctutations per se or\nexistence of low periodicities below the pitch range (longer than\nthe duration of the interval analysis window) that cause the\nroughness quality per se\nFriday, March 13, 2009\n\nKameoka & Kuragawa, 1969a, Pure tone ratings\nJapanese audio engineers, \"sunda/nigotta\" (clearness/turbidity)\nImage removed due to copyright restrictions. Kameoka, A., and M. Kuriyagawa. \"Consonance\nTheory Consonance of Dyads.\" J Acoust Soc Am 45 (1969): 1451-1459.\nFriday, March 13, 2009\n\nPlomp & Levelt (1965) Dissonance of pure tone dyads\n0.6 Graph of interval consonance as function of frequency separation relative to critical bandwidth, showing maximum dissonance at frequency separation around 0.2 to 0.3.\n0.4\n0.4\n0.6\n0.2\n0.8\n1.0\n0.2\n0.4\n0.6\n0.8\n1.0\nConsonance\n1.0\n0.8\n0.2\nConsonance\nDissonance\nFrequency Separation\nFigure by MIT OpenCourseWare.\nFriday, March 13, 2009\n1 crit. band = 20%\nfrequency separation\n\n1.0 Graph of interval consonance as function of frequency separation relative to critical bandwidth, showing maximum dissonance at frequency separation around 0.2 to 0.3.\n0.8\n0.2\nConsonance\n0.6\n0.4\n0.4\n0.6\n0.2\n0.8\n1.0\n0.2\n0.4\n0.6\n0.8\n1.0\nConsonance\nDissonance\nFrequency Separation\nFigure by MIT OpenCourseWare.\nFriday, March 13, 2009\nHarmonics completely fuse if f < 2%\nHarmonics beat and cause roughness if 2% < f < 20%\n1 crit. band = 20%\nfrequency separation\n\nGrap\nh of critical bandw\nidth\nas a function of its\ncenter\nfrequency.\nFrequency discrimination is much finer than tonal fusion\nFigure by MIT OpenCourseWare.\nFriday, March 13, 2009\n\nPlomp & Levelt (1965) Dissonance of pure tone dyads\nFriday, March 13, 2009\n\nVan de Geer et al (1962) Consonance of pure tone dyads\nFriday, March 13, 2009\n\nBeating of harmonics\n500 1000 1500\nFourth\n500 1000 1500\nMajor Third\n500 1000 1500\nMinor Second\n!\nFriday, March 13, 2009\n500 1000 1500\nOctave\n500 1000 1500\nFifth\n500 1000 1500\nTritone\n\nPredicted consonance of harmonic complexes (n=1-6)\nFriday, March 13, 2009\nGra\nph\no\nf predicte\nd\nco\nns\nonan\nces of\nharm\nonic\ncom\nplex\nes\n.\nFigure by MIT OpenCourseWare.\n\nConsonance perception: different conceptions\n-Psychophysics of consonance\n-Meanings of \"consonance\" and \"dissonance\"\n-Euphonious, \"pleasant\" vs. jarring, unpleasant\n-Smooth, well-defined, unified vs. rough, buzzy,\n\nunsettled\n-see Sethares (1999), Ch. 4 for more depth\n-Tenney (1988) book, History of 'Consonance' and 'Dissonance'\n-melodic: relatedness of pitches sounded successively\n-polyphonic: interval between two simultaneous tones\n-pleasant vs unpleasant combinations; fusion of tones\n-contrapuntal: from music theory voice leading techniques(4th diss)\n-functional: relationship of individual tones to root or tonic\n-sensory: roughness and presence of beats\nFriday, March 13, 2009\n\nRoughness isnt all there is to consonance.....\nPart of the difficulty of obtaining consonance judgements is the meaning\nof consonance for listeners.\nVan de Geer, Levelt & Plomp (1962) used the same stimulus set of pure\ntone dyads but asked subjects to rate the stimuli according to 10 criteria.\nVan de Geer, Levelt & Plomp (1962) carried out an important study where they\nasked Dutch listeners to judge tone pairs according to ten different scales:\nEnglish Dutch\nfrom David Huron's website\nhigh-low\n(hoog-laag)\nsharp-round\n(scherp-rond)\nbeautiful-ugly\n(mooi-lelijk)\nactive-passive\n(actief-passief)\nconsonance-dissonant\n(consonant-dissonant)\neuphonious-diseuphonious(welluidend-onweeluidend)\nwide-narrow\n(wijd-nauw)\nsounds like one tone-sounds like more tones(klinkt als een toon-klinkt als meer tonen)\ntense-quiet\n(gespanen-rustig)\nrough-smooth\n(ruw-glad)\nFriday, March 13, 2009\n\nRoughness isnt all there is to consonance.....\nNon-musician listeners judged each harmonic interval\nusing a 7-point scale for each semantic term. Using\nfactor analysis, van de Geer, Levelt and Plomp found\nthat the responses grouped into three independent\nfactors. The analysis produced three statistically\nsignificant factors. One factor (dubbed pitch)\nincluded the scales high, sharp, tense, narrow, and\nactive. A second factor (dubbed pleasantness)\nincluded the scales euphonious, consonant, and\nbeautiful. A third factor (dubbed fusion) included the\nscales rough, more tones and fusion.\nThe first factor (pitch) was found to correlate\ndirectly with the mean frequency of the pitches used\nin the interval.\nFriday, March 13, 2009\n\nVand de Geer et al (1962) conclusions (D. Huron)\nVan de Geer et al made the following 3 conclusions:\n1. Musical intervals are judged using three basic dimensions: pitch\nheight, pleasantness, and fusion.\n2. Musicians and non-musicians use the term \"consonant\"\ndifferently. Musicians typically consider unisons, octaves, fifths\nand fourths as the most consonant, whereas non-musicians\ntypically experience thirds and sixths as being more consonant.\n3. Non-musicians conceive of \"consonance\" primarily in terms of\npleasantness.\nNo straightforward relationship between consonance & fusion. [for\nPure tone stimuli! -- pac]\nThe main lesson is that care must be taken when instructing\nlisteners to judge intervals. Some terms are largely synonymous\n(such as euphonious and pleasant), whereas other terms are not\ninterchangeable (such as pleasant and fused).\nFriday, March 13, 2009\n\nvan de Geer et al\nFriday, March 13, 2009\n\nVan de Geer et al 1962\ndata replotted pac 2007\nFriday, March 13, 2009\n\nConsonance perception: theories\nCultural conditioning\nSmall Is beautiful, simple\n-\nsmall integer ratios (1:1, 2:1, 3:2, 4:3, 5:4)\n- simpler, smoother waveforms\n-\nless complex interspike interval patterns\nRoughness: interactions of nearby tones in filters\n(Helmholtz, cochlear & neural filtering)\nFusion of tones\n- consonance related to number of competing\npitches, unity of perception (Stumpf)\nDual theories: Terhardt, Helmholtz: sensory\n(peripheral beating) & cognitive (expectations,\ncontext); sensory vs. musical consonance\nFriday, March 13, 2009\n\nRoughness isnt all there is to consonance.....\nRoughness (Helmholtz)\nPitch fusion/tonal fusion (Stumpf)\nNumber of voices (\"chorus effect\", Huron)*\nShrillness (high frequency partials, Huron)\nPresence of noise (conjecture)\nhttp://www.harmony-central.com/Effects/Articles/Chorus/\nFriday, March 13, 2009\n\nHarmonic complex w. upper harmonics\nRoughness isnt all there is to consonance.....\nFriday, March 13, 2009\n\nNeural basis of consonance\nIn the 1990s we (Mark Tramo, Peter Cariani,\nand Bertrand Delgutte did an extensive neuro\nphysiological study of the neural basis of\nconsonance in the cat auditory nerve.\nWe found neural correlates both\nfor roughness and pitch fusion.\nThese neural correlates both match up with\nhuman listener judgments quite well.\nFriday, March 13, 2009\n\nMark Tramos stimulus set\nFriday, March 13, 2009\nCourtesy of Prof. Mark J. Tramo, M.D., Ph.D. Used with permission.\n\nFriday, March 13, 2009\n\nFriday, March 13, 2009\n\nStep 3!\n!\"#$%&'(\n\"%)*'+,'\"(-.(\n%))(%)&'/+%#0'(\n1*&,2'\"(3\"*+4(\n\"352%/$-+*,(\n*+&'/0%)(\"*'0'\"!\nD'$1-/%)($-=')(\n6&'1(7(\n89(:11);(&%1'/*+4(*+&'/0%)(\n<*+=-<(-.(>?@($\"(&-(&2'(\nA-1B*+&'/0%)(=*\"&/*53#-+(\n%,,-3+&(.-/()*$*&'=(\n./'C3'+,;(/'\"-)3#-+(%+=(\n)-<'/()*$*&(-.($3\"*,%)(1*&,2(!\n6&'1(?(\nE9(!\"#$%&'(&2'(/')%#0'(\n+3$5'/\"(-.(*+&'/0%)\"(\n%\"\"-,*%&'=(<*&2('%,2(1*&,2(\n1'/*-=*,*&;(F?@BG@@(HIJ(\n3\"*+4(%(='+\"'(%//%;(-.(\n*+&'/0%)(1%K'/+(\"*'0'\"9!\n6&'1(L(\nM9(E-$13&'(N1%K'/+(\n\"%)*'+,'O(P(&2'(/%#-(-.(\n1*&,2B/')%&'=(*+&'/0%)\"Q5*+(\n&-($'%+(R(*+&'/0%)\"Q5*+9(\nA*&,2'\"(<*&2(\"%)*'+,'\"(S(T9\n\"2-3)=(5'(%3=*5)'9(U%V(\n\"%)*'+,'(*\"(&%W'+(%\"(&2'(\n*+='V(-.(1*&,2(\"&%5*)*&;X(\n,-+\"-+%+,'9!\nFriday, March 13, 2009\n?(\n\nPitch salience maps - pure tone dyads 440 Hz root (16/15, 4/3, 45/32, 3/2)\nFriday, March 13, 2009\n\nFriday, March 13, 2009\nPitch salience maps - complex tone dyads 440 Hz root n=1-6, (16/15, 4/3, 45/32, 3/2)\nPitch estimate\nInterspike interval (ms)\n\nFriday, March 13, 2009\n\nPITCH FUSION\nCONSONANCE\nFriday, March 13, 2009\nEstimated from interspike\nMeasured via\ninterval patterns\npsychophysical tests\nin the auditory nerve\n\nPresent results\nAuditory nerve simulations enable putative\nneural representations and information-\nprocessing operations to be explored in more\nsystematic fashion and compared with\npsychophysical data\nI recently simulated the pure and complex\ntone consonance experiments of Kameoka &\nKuragawa (1969) in order to test the\nrobustness of consonance models based on\npopulation-interval representations and\npitch salience estimates.\nFriday, March 13, 2009\n\nCenter frequency (Hz)\n# intervals/mean\nAuditory nerve model\nHuman middle ear\n48 Gammatone filters\nParameters fit to\nreplicate cat ANF\nresponses (broader than\n\"auditory filters\")\n3 classes of fibers/CF\n144 Simulated ANFs\nAdaptive gain control\nGeisler & Greenberg, 1986\nSpontaneous activity\n(Poisson)\nFILTER BANK\nINPUT SIGNAL\nRECTIFICATION\n0.1\nFrequency (kHz)\nLOW PASS FILTER\nCOMPRESSION\nMag\nAvg.\nrate 50\n(s/s)\n1k\n10k\nFrequency (Hz)\nLevel (dB SPL)\nPST NEUROGRAM\nPOPULATION\nINTERVAL\nDiSTRIBUTION\n100 0\nPeristimulus time (ms)\nAll-order interspike interval (ms)\nFriday, March 13, 2009\n\nImage removed due to copyright restrictions.\nFig. 2 in Rose, J. E., et al. J Neurophysiol\n30, no. 4 (1967): 769.\nImage removed due to copyright restrictions.\nFig. 10 in in Rose, J. E., et al. J Neurophysiol\n34, no. 4 (1971): 685-699.\nFriday, March 13, 2009\n\nNEUROGRAM\nDischarge rate (s/s)\nCharacteristic frequency (Hz)\nRATE-PLACE PROFILE\nPOPULATION-INTERVAL DISTRIBUTION\nPeristimulus time (ms)\npeak/mean\n0.005\n0.01\nCharacteristic frequency (Hz)\nInterval (ms)\nFriday, March 13, 2009\n\nMODEL\nNEUROGRAM\nDischarge rate (s/s)\nCharacteristic frequency (Hz)\nRATE-PLACE PROFILE\nPOPULATION-INTERVAL DISTRIBUTION\nPeristimulus time (ms)\npeak/mean\n0.005\n0.01\nCharacteristic frequency (Hz)\nInterval (ms)\nFriday, March 13, 2009\n\nHow does a\ntemporal\nmodel\npredict\nwhether a\npitch should\nbe audible?\nStep 1\nSimulate\nauditory\nnerve\nresponse\nto stimulus\nFriday, March 13, 2009\n\nStep 2\nApply\nexponential\ninterval\nweighting\ntau = 10 ms\nStep 3\nEstimate\nsaliences of\nall alternative\npitches using\nsubharmonic\ninterval sieves\nFriday, March 13, 2009\n\nNonexclusive\nallocation of\nintervals:\nHarmonically\nrelated pitches\nshare intervals\nand interfere\nminimally.\nNon-\nharmonically\nrelated pitches\ninterfere\nmaximally.\nFriday, March 13, 2009\n\nSome observations\n1. The all-order interspike interval distribution at the\nlevel of the auditory nerve constitutes an\nautocorrelation-like representation of the stimulus.\n2. Since each low harmonic generates intervals at its\nown period and its multiples, the representation\nincludes all subharmonics of the partials.\n3. The interval patterns are formed from the summation\nof subharmonics (cf. Terhardt's virtual pitch)\n4. The sieve computes the pattern-strength of these\nsubharmonics of the partials.\n5. This representation contains both overtone &\nundertone series (i.e. more than pure spectral overlap).\nFriday, March 13, 2009\n\nHarmonic\nresolution\nResolvability of partials (Plomp, 1976)\nFriday, March 13, 2009\n\n(Harmonics 1-4)\nStep 4: Those pitches with saliences > 1.3\nshould be audible.\nPitch salience map\nHarmonics 1-12 of 200 Hz\nFriday, March 13, 2009\n\nPlomp & Levelt (1965) Dissonance of pure tone dyads\nFriday, March 13, 2009\nGrap\nh of\nint\nerva\nl co\nnson\nan\nce\nas\nfun\nctio\nn of\nfre\nquen\ncy separati\non r\nel\nativ\ne to\ncritical\nbandwidth,\nshowing maximum dissonance at frequency separation around 0.2 to 0.3.\nFigure by MIT OpenCourseWare.\n\nKameoka & Kuragawa, 1969a, Pure tone ratings\nJapanese audio engineers, \"sunda/nigotta\" (clearness/turbidity)\nFriday, March 13, 2009\nImage removed due to copyright restrictions. Kameoka, A., and M. Kuriyagawa. \"Consonance\nTheory Consonance of Dyads.\" J Acoust Soc Am 45 (1969): 1451-1459.\n\nModel predictions, est. pitch fusion = maximum salience\n3:2\n2:1\n3:1\n4:1\nFriday, March 13, 2009\n\nKameoka & Kuragawa, 1969a, Complex tone ratings (diff. scale)\nFriday, March 13, 2009\nImage removed due to copyright restrictions. Kameoka, A., and M. Kuriyagawa. \"Consonance\nTheory Consonance of Dyads.\" J Acoust Soc Am 45 (1969): 1451-1459.\n\nKK datapoints\nsemitones\nModel predictions, est. pitch fusion = maximum salience\nFriday, March 13, 2009\n\nEstimated consonance of pure & complex tone dyads!\nKameoka & Kureagawa psychophysical data!\nTemporal pitch multiplicity model!\nFriday, March 13, 2009\nImage removed due to copyright restrictions. Kameoka, A., and M. Kuriyagawa. \"Consonance\nTheory Consonance of Dyads.\" J Acoust Soc Am 45 (1969): 1451-1459.\n\nDesigning a scale system - 12 equally tempered notes/oct.\nFriday, March 13, 2009\n\ndiatonic\nscale\nFriday, March 13, 2009\nD\ni\na\ng\nr\na\nm\nof one octave, C-C, of a piano keyboard.\nFigure by MIT OpenCourseWare.\n\nDesigning a scale system - 10 equally tempered notes/oct.\nFriday, March 13, 2009\n\nDesigning a scale system - 9 equally tempered notes/oct.\nFriday, March 13, 2009\n\nDesigning a scale system - 8 equally tempered notes/oct.\nFriday, March 13, 2009\n\nDesigning a scale system - 7 equally tempered notes/oct.\nFriday, March 13, 2009\n\nDesigning a scale system - 6 equally tempered notes/oct.\nFriday, March 13, 2009\n\nDesigning a scale system - 5 equally tempered notes/oct.\nFriday, March 13, 2009\n\nNeural coding of pitch fusion\nCovaries with roughness models; many parallels. Both\nexplain basic consonance of complex harmonic tones quite\nwell\nResponsible interval information probably exists at least up\nto the level of the midbrain (IC) -- work by Greenberg (FFR)\nInterval models parallel spectral pattern approaches\n- (e.g. Terhardts subharmonics, Parncutt)\nPitch competition and stability leads to a theory of tonal\nstability and higher levels of tension-relaxation.\nFusion is similar to Stumpfs theory\nBased in part on undertone series; may be related to\nRiemanns theory of harmonic dualism\nFriday, March 13, 2009\n\nEstimated pitch-stability of major and minor triads!\n1.34!\n1.43!\n4%+*'$)+('&!/'..D!@E!\n@!\n2!\nF!\n2.0$'()*!.'&#)+3).!14!5#(36).!\n\"#$%&'()*!#+(),-'&!*#.(,#/%01+.!\n75#(36!.('/#&#(89!%+#(89!4%.#1+:!\n;#(36!7<=:!\n@!\nGH!\nF!\n>+(),.5#?)!#+(),-'&!7$.:!\nI!\nI!\nI!\nI!\n@AB'C1,!(,#'*!\n@AB#+1,!(,#'*!\n4%+*'$)+('&!/'..D!@E!\nI!\nI!\nI!\nI!\n#+(),.5#?)!#+(),-'&.!\n'..13#'()*!JK!\n4%+*'$)+('&!!\n/'..!@E!\nFriday, March 13, 2009\n\nEstimated pitch-stability of triads of all scale degrees!\n!\"#$%&'()*+,-+./012+3,+456712++\n89)+:&7#()\";+&#<%\"=$>61+\n3,+>?+!@A++\n@76%\"#\")&7B+761$%=1*+C&D+E+!$1-+E+C\")+E+!$1,+EE+F$G+E+H\"#+\n>\"#+\n&$G+\n>\"#+\n&$G+\n1$1,+\n1$1-+\n#&D+\n#&D+\n#&D+\n#&D+\n#&D+ #&D+\n#\")+\n#\")+\n#\")+\n#\")+\n#\")+\n#\")+\n\n-+\n,+\nPitch\nstability\n\nPitch\ninstability\nC&I\"#$#+1&%\"6);6+\nJ\n8J\n!\"#$%&\nFriday, March 13, 2009\n\nhttp://www.musictheory.net/load.php?id=55\nChord progressions, \"cadences\"\n\nsequences of chords\ntension & relaxation\ninstability-stability\nOne of the self-conscious\naims of 20th c. \"atonal\" music\n(e.g. Schoenberg) is the\navoidance of tonal centers and\nexpectations\nCourtesy of MIT Press. Used with permission. Source: Handel, S. Listening: An Introduction\nto the Perception of Auditory Events. MIT Press, 1989.\nFriday, March 13, 2009\n\nTonal hierarchies\nCourtesy of MIT Press.\nUsed with permission. Source:\nHandel, S. Listening: An Introduction\n\nto the Perception of Auditory Events.\nMIT Press, 1989.\nFriday, March 13, 2009\nS\nch\ne\nma\nti\nc\no\nf\n\nh\na\nr\nm\no\nn\ni\nc\n\nmotion indicating conventional interpretations of tension and release.\nFigure by MIT OpenCourseWare.\n\nMain Points re: consonance\n- Early experiments with strings (Greeks)\n- Psychophysics of consonance\n- Meanings of \"consonance\" and \"dissonance\"\n- Euphonious, \"pleasant\" vs. jarring, unpleasant\n- Smooth, well-defined, unified vs. rough, buzzy, unsettled\n- Beating & roughness (Helmholtz), fusion (Stumpf)\n- Neural correlates of roughness (cochlear filtering)\n- Periodicities below the range of the pitch mechanism\n- Population-wide fluctuations in discharge rates\n- Neural correlates of tonal fusion (pitch)\n- Consonance in music - where does it lead?\n- Tuning systems and scales\n- Instability-Stability (tension-resolution)\nFriday, March 13, 2009\n\nReading/assignment for next meetings\n-\nScales and tuning systems\nHistory, basic psychophysics, scales and tuning systems, role in\nmusic theory. Relations between auditory and cultural factors\nHandel chapter on musical grammars -- deals with melody &\nharmony\nReading: Deutsch, Burns chapter on intervals & scales\nFriday, March 13, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Melody & Harmony: combinations and sequences of pitches unfolding in time",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/f1c2d19f6a77a03be3e430356745d4bc_MITHST_725S09_lec10_mel.pdf",
      "content": "Melody & Harmony:\ncombinations and sequences of\npitches unfolding in time\nThursday, May 14, 2009\nSchemat\nic model of the cochlea.\nHST.725: Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\nImage by MIT OpenCourseWare.\n\nMelody (Wikipedia)\nIn music, a melody (from Greek  - meloidia,\n\"singing, chanting\"[1]), also tune, voice, or line, is a\nlinear succession of musical tones which is perceived as\na single entity. In its most literal sense a melody is a\nsequence of pitches and durations, while more\nfiguratively the term has occasionally been extended to\ninclude successions of other musical elements such as\ntone color.\nThursday, May 14, 2009\n\nMelody: note sequences unfolding over time\n- Melody: sequences of sounds, vertical dim.\n- Tonality: relating to a tonic (pitch)\nIvor Cutler \"Go and sit upon the grass\"\n- Existence region: tone durations\n- Intervals vs. contour vs. absolute pitch vs. scale\n- Tonal vs. atonal sequences\n- Invariance over key transpositions\n- Multiple melodic lines: polyphony\n- Hierarchical structure: phrases\n- Repetition & change\n- Formation of expectation & its violation\n- Melodic memory\n- Musical preferences: personality, style\nThursday, May 14, 2009\n\nStyle analysis (La Rue, Guidelines for Style Analysis)\n- Sound (texture)\n- timbre, combination, contrast\n- range, gaps, special effects, idiom\n- Harmony (functions: color & tension)\n- tonal structure: linear & modal, unifieed, polycentric, atonal,\nserial, etc\n- Movement relationships: progressions, modulations\n- Part exchange, counterpoint, imitation\n- Melody\nRange, mode, vocal/instrumental\nMotion: stepwise, skipping, leaping, chromatic, active/stable,\narticulated/continuous\nPatterns: rising, falling, sawtooth, undulating, etc.\nPeaks and lows\nThursday, May 14, 2009\n\nStyle analysis, cont. (La Rue)\n- Rhythm\n- Surface rhythm, vocabulary & frequency of patterns\n- Meter, tempo, module (fraction, pulse, motive, phrase,\nsentence, larger groupings)\n- Patterns of change: stress, lull, transition\n- Fabrics: homorhythmic, polyrhythmic, variant rhythmic\ndensity\n- Growth\n- systematic movements in musical dimensions, tempos,\ndynamics, meters, etc\n- Movement: structural/ornamental\n- Text influence (lyrics, lyric functions)\nThursday, May 14, 2009\n\nStyle analysis, cont. (La Rue)\n- Dont Fence Me In (Cole Porter)\nFred Hersch\nWilly Nelson/Leon Russell\nGreatest Cowboy Songs\nLouie Armstrong\nDavid Byrne\nThursday, May 14, 2009\n\nComposing melodies\nMelody first: Note trajectories\nKey: From a set of notes in a scale\nPhrases & phrase structure\n(pattern, similarity/proximity, timing)\nChords first: From chord progressions\nThursday, May 14, 2009\n\n- Melody is said to result where there are interacting\npatterns of changing events occurring in\ntime.\"[1]Change is necessary for events \"to be\nunderstood as related or unrelated.\" Melodies often\nconsist of one or more musical phrases, motifs, and\nare usually repeated throughout a song or piece in\nvarious forms.\n- Melodies may also be described by their melodic\nmotion or the pitches or the intervals between\npitches..., pitch range, tension and release, continuity\nand coherence, cadence, and shape. \"Many extant\nexplanations [of melody] confine us [sic] to specific\nstylistic models, and they are too exclusive.\"[1]\nMelody (Wikipedia)\nThursday, May 14, 2009\n\nEstablishment of the tonic (tonal system, tonality induction)\n- First note (most salient)\n- Last note (most salient in memory)\n- Most frequent or longest duration note\n- Note pattern may imply a tonic\n- Perception of tonic may be influenced by\nmelodic and harmonic context\n- Key-finding algorithms have been developed,\nbut these can make errors (i.e. no strict rules apply)\n- What does the existence of the tonic imply\nabout pitch memory? about melodic order?\nThursday, May 14, 2009\n\nTonal hierarchy of notes\nwithin the key of C\nRanking:\nsimilarity to the tonic\nNotion of distance\nfrom tonic in\npitch-similarity space\nMelody as trajectory\naway from and toward\nthe tonic and/or other\npoints in space\nButler\nThursday, May 14, 2009\nC\no\nn\nic\nal\nr\nep\nre\ns\ne\nn\nt\na\nt\ni\no\nn\n\no\nf\n\ntonal hierarchy of the 12-tone set for the key of C (after Krumhansl, 1979).\nFigure by MIT OpenCourseWare.\n\nCourtesy of Stephen Malinowski. Used with permission.\nMusic Animation Machine\nHARMONIC COMPASS\nThursday, May 14, 2009\nC\no\nn\nic\nal\nr\nep\nre\ns\ne\nn\nt\na\nt\ni\no\nn\n\no\nf\n\ntonal hierarchy of the 12-tone set for the key of C (after Krumhansl, 1979).\nFigure by MIT OpenCourseWare.\n\nTonal system\nsee also\nhttp://www.musictheory.net\nfor introduction to keys\nfrom Bigand chapter\nThursday, May 14, 2009\nDiagram showing how scale establishes pa\nr\nti c\nul a\nr\ni\nn\ntr\na\n- a\nnd inter-key relationships, inc\nluding tonic/dominant and circ\nle of fifths.\nFigure by MIT OpenCourseWare.\n\nHome\nNear\nFar away\nPitch distances\nThursday, May 14, 2009\nDiagr\nam showi\nng ho\nw scale estab\nl\ni\ns\nh\ne\ns\n\np\narticular\nintr\na- and inter-key relationships, including tonic/dominant and circle of fifths.\nFigure by MIT OpenCourseWare.\n\nMelodic groupings, pitch hierarchies, and musical tension\nThursday, May 14, 2009\nImage removed due to copyright restrictions. See Fig. 8.2 in Bigand, E., and S. McAdams.\nThinking in Sound. New York, NY: Oxford University Press, 1993. ISBN: 9780198522577.\n\nWhat makes a melody a recognizable pattern?\nWhat is the representational essence of melody such that it\ncan be recognized\n1) if notes are transposed (all shifted by the same frequency\nratio)?\n2) if notes are played faster or slower (tempo invariant)\nis it contour? : up/down changes in pitch\ndoes it depend on musical intervals?:\nas relative distances in pitch space\nabsolute pitches?: note\nscale position?: re tonic\nThursday, May 14, 2009\n\nMelody\nWhat is the\nrepresentational\nessence\nof melody such that\nit can be recognized\nunder note deletions\nand transformation?\ntempo invariant\ncontour : up/down\ninterval: rel. pitch dist.\nabsolute pitch: note\nscale position: re tonic\nThursday, May 14, 2009\nCourtesy of MIT Press. Used with permission. Source: Handel, S.\nListening: An Introduction to the Perception of Auditory Events MIT Press, 1989.\n\nThursday, May 14, 2009\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction to the Perception of Auditory Events.\nMIT Press, 1989.\n\nMelody:\ncontour\ninterval\nnote\nscale position\nThursday, May 14, 2009\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction\nto the Perception of Auditory Events. MIT Press, 1989.\n\nMelody\nand\nNote\nDurations\nToo short:\nWeak\nPitches\nToo long:\nLack of\ninteraction\nbetween\npitches\nFrom Thinking in Sound\nMcAdams, Bigand eds.\nThursday, May 14, 2009\nFo\nr famil\niar songs like \"Twinkle twinkle\" and \"Happy Birthday\", note durations rang\ne from less than 200 msec to about 2 seconds.\nFigure by MIT OpenCourseWare.\n\nMusic & memory\nCourtesy of MIT Press. Used with permission.\nSource: Synder, B. Music and Memory.\nCambridge, MA: MIT Press, 2000.\nThursday, May 14, 2009\n\nWhat makes a \"good\"or memorable melody?\nCoherence of pattern\nBalance between order & chaos (surprise)\nU-shaped preference curve\nRelated physiological assumptions:\nRelations (Gestaltists) ~ correlation-based\nrepresentations\nvs.\nlocal features (associationists)\n\natomistic feature detectors, machine vision\nThursday, May 14, 2009\n\nFigures from A Primer of Visual Literacy by Donis A. Dondis.\nCambridge, Mass., MIT Press [1973]. Used with permission.\nTension-relaxation\nImplication-realization (implication-expectation)\n\n(from Meyer, 1956, Emotion & Meaning in music)\ncf. Namour's application to melody\nDistance from tonic, patterns of stress and relaxation\nA Primer of Visual Literacy\nDonis Dondis, MIT Press, 1973\nThursday, May 14, 2009\n\nGestaltist principles\nRelations rather than perceptual atoms\nIntervals (relations between notes, re: tonic) as relations\nNotion of strong vs. weak organization\nPrinciples of simplicity, similarity, proximity, inclusiveness,\ncommon fate, closure\nThursday, May 14, 2009\nPatterns illustrating Gestalt organization.\nFigure by MIT OpenCourseWare.\n\nGestalt principles (Jay Dowling, in Aiello)\nThursday, May 14, 2009\nD\ni\na\ngram illustrating Gestalt principles: proximity, good continuation, similarity.\nFigure by MIT OpenCourseWare.\n\nMelody\nProbe-\nmelody\nstudies\nThursday, May 14, 2009\nCourtesy of MIT Press. Used with permission. Source: Handel, S.\nListening: An Introduction to the Perception of Auditory Events MIT Press, 1989.\n\nStrong vs. weak organization\nThursday, May 14, 2009\nPatterns illustrating Gestalt organization.\nCourtesy of MIT Press. Used with permission.\nSource: Synder, B. Music and Memory.\nCambridge, MA: MIT Press, 2000.\nFigure by MIT OpenCourseWare.\n\nPhrase structure from groupings\nThursday, May 14, 2009\nCourtesy of MIT Press. Used with permission.\nSource: Synder, B. Music and Memory.\nCambridge, MA: MIT Press, 2000.\n\nMusic & memory\nThursday, May 14, 2009\nSource: Synder, B. Music and Memory.\nCambridge, MA: MIT Press, 2000.\nCourtesy of MIT Press. Used with permission.\n\nDeep structure of melodies\nEven if the surface structure is\naltered quite a bit (as is common\nin jazz or any variations on a\ntheme), the melody is\nrecognizable. Part of this may be\nthe result of chord progressions,\nand aspect of the deep intervallic\nharmonic and melodic structure.\nSchenker pioneered a method of\nreducing a melody to its\nessentials, stripping off\nsuccessive layers of ornament.\nThursday, May 14, 2009\n\nSchenkarian time-span\nreduction of melody\n(Lerdahl)\nImages removed due to copyright restrictions.\nFig. 1.6 and 1.7 in Lerdahl, F. Tonal Pitch Space.\nNew York, NY: Oxford University Press, 2001.\nPreview in Google Books.\nThursday, May 14, 2009\n\nSchenkarian time-span\nreduction of melody\n(Lerdahl)\nImages removed due to copyright restrictions.\nFig. 1.3 in Lerdahl, F. Tonal Pitch Space.\nNew York, NY: Oxford University Press, 2001.\nPreview in Google Books.\nThursday, May 14, 2009\n\nChord progression &\nharmonic groupings\nImage removed due to copyright restrictions.\nSee Fig. 8.2 in Bigand, E., and S. McAdams.\nThinking in Sound. New York, NY: Oxford University Press,\n1993. ISBN: 9780198522577.\nThursday, May 14, 2009\n\nTonality and harmony\n- Harmony: concurrent sounds, vertical dim.\n- Tonality: relating to a tonic (pitch center, \"home\")\n- Keys formed by different tonics & scales\n- Piston: tonality: note; modality: scale\n- Triads, inversions, and degrees\n- Krumhansl's probe-tone studies\n- Structure of note-note & note-key similarities\n- Is it just note frequency? Common harmonics?\n- Pitch memory & establishment of tonal centers\n- Chord progressions, harmonic distances\n- Key modulations, harmonic movements\n- Harmonic tension-relaxation dynamics:\n- pitch stability (multiplicity of alt. organizations)\n- movement to & away from tonic (confirmation of 1 pitch framework)\nThursday, May 14, 2009\n\nTriads: 3-note chords made up of thirds\nMajor: root + major third + fifth\nMinor: root + minor third + fifth\nImage removed due to copyright restrictions.\nSee Ex. 15, 16 in Piston, Walter. Harmony.\nThursday, May 14, 2009\n\nChord notation: scale degrees\nChords are also distinguished and notated by the scale degree of their root note or bass note.\nFor example, since the first scale degree of the C major scale is the note C, a triad built on\ntop of the note C would be called the one chord, which might be notated 1, I, or even C, in\nwhich case the assumption would be made that the key signature of the particular piece of\nmusic in question would indicate to the musician what function a C major triad was fulfilling,\nand that any special role of the chord outside of its normal diatonic function would be inferred\nfrom the context.\nRoman numerals indicate the root of the chord as a scale degree within a particular key as\nfollows:\nI tonic\nii supertonic\niii mediant\nIV sudominant\nV dominant\nvi submediant\nvii subtonic/leading tone\nMany analysts use lower-case Roman numerals to indicate minor triads and upper-case for\nmajor ones, with degree and plus signs (o and +) to indicate diminished and augmented\ntriads, respectively.\nThursday, May 14, 2009\n\nProbe-melody studies\nListeners can use both contour\n(pitch height, pitch direction\nchanges) and the interval/scale\ndegree structure for melodic\nrecognition.\nFor well-formed coherent easily\nremembered melodic patterns,\n(STRONG PATTERNS)\ninterval alterations are highly\nnoticable.\nFor ill-formed, hard-to-remember\nmelodies (WEAK PATTERNS),\ncontour is used more for\nFigures from A Primer of Visual Literacy by Donis\nA. Dondis. Cambridge, Mass., MIT Press [1973].\nUsed with permission.\nThursday, May 14, 2009\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction\nto the Perception of Auditory Events. MIT Press, 1989.\n\nNote-key relations\nProbe tone studies:\nhow well does a given\npitch \"fit in\" with a\npreviously played\nchord or scale?\nMeasure of similarity\nor compatibility\nThursday, May 14, 2009\nSource: Krumhansl, C. L., and E. J. Kessler.\n\"Tracing the Dynamic Changes in Perceived Tonal Organization\n\nin a Spatial Representation of Musical Keys.\"\nPsychological Review 89, no. 4 (July 1982): 334-368.\nCourtesy of the American Psychological Association.\n\nHow much of the\nstructure of tonal pitch\nspace - perceptual\nHow much of it is\ndistances between\nacquired through\nnotes and keys and\nassociative learning\nbetween keys and\n(culture) of pitch\nother keys - falls out\ncombinations?\nof the structure of\nbasic auditory\nrepresentations?\nThursday, May 14, 2009\n\nNote-chord\nKrumhansl\nprobe tone\nstudy\nCorrelations of\nsimulated PIDs\nThursday, May 14, 2009\n\nThursday, May 14, 2009\n\nProbe tone profiles\nfor related keys\nThursday, May 14, 2009\nSource: Krumhansl, C. L., and E. J. Kessler.\n\"Tracing the Dynamic Changes in Perceived Tonal Organization\nin a Spatial Representation of Musical Keys.\"\nPsychological Review 89, no. 4 (July 1982): 334-368.\nCourtesy of the American Psychological Association.\n\nContext effects: relatedness of chords within & across keys\nSource: Fig. 1 in Bharucha, J. and C. L. Krumhansl.\n\"The representation of harmonic structure in music:\nHierarchies of stability as a function of context.\" Cognition 13, no.\n1 (January 1983): 63-102. Courtesy Elsevier, Inc.,\nhttp://www.sciencedirect.com. Used with permission.\nThursday, May 14, 2009\n\nSimilarity relations\nbetween chords in\nthe key of C\nSource: Fig. 1 in Bharucha, J. and C. L.\nKrumhansl. \"The representation of harmonic\nstructure in music: Hierarchies of stability\nas a function of context.\" Cognition 13, no.\n1 (January 1983): 63-102. Courtesy Elsevier, Inc.,\nhttp://www.sciencedirect.com.\nUsed with permission.\nThursday, May 14, 2009\n\nLeman & Carreras (1997):\nImages removed due to copyright restrictions.\nSee Figs. 1 and 4 in Leman, M. and F. Carreras.\n\"Schema and Gestalt: Testing the Hypothesis of Psychoneural Isomorphism by Computer Simulation.\"\nIn Music, Gestalt, and Computing: Studies in Cognitive and Systematic Musicology. Heidelberg,\nGermany: Springer, 1997. DOI: 10.1007/BFb0034112\nThursday, May 14, 2009\n\nMelodic groupings, pitch hierarchies, and musical tension\nThursday, May 14, 2009\nImage removed due to copyright restrictions. See Fig. 8.2 in Bigand, E., and S. McAdams.\nThinking in Sound. New York, NY: Oxford University Press, 1993. ISBN: 9780198522577.\n\nChord progressions, \"cadences\"\n\nsequences of chords\ntension & relaxation\ninstability-stability\nOne of the self-conscious\naims of 20th c. \"atonal\" music\n(e.g. Schoenberg) is the\navoidance of tonal centers and\nexpectations\nhttp://www.musictheory.net/load.php?id=55\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction\nto the Perception of Auditory Events. MIT Press, 1989.\nThursday, May 14, 2009\n\nCommon progressions\n\"The most common chord progressions, in the common practice\nperiod and in popular music, are based on the first, fourth, and\nfifth scale degrees (tonic, subdominant and dominant); see three\nchord song, eight bar blues, and twelve bar blues.\nThe chord based on the second scale degree is used in the\nmost common chord progression in Jazz, II-V-I.\nThe circle of fifths progression is generally regarded as the most\ncommon progression of the common practice period\n(1600-1900), involving a series of descending perfect fifths that\noften occur as ascending perfect fourths. The circle of fifths\nmakes up many of the most commonly used progressions, such\nas II6, V, I in major.\"\n-- Wikipedia\nThursday, May 14, 2009\n\nCommon progressions used in\ncontemporary popular music\nwelve-bar bluesI - vi - IV - V:\ne 50s progressionI - V - vi - IV:\nr example 'Dammit' (Blink-182), 'With or\nithout You' (U2), 'Let It Be' (The Beatles).\nhis progression uses the same chords as the\nT\nth\nfo\nW\nT\n\n50s progression, in a different order.\nI - I - IV - V: for example the verse of 'Good\nRiddance (Time of Your Life' by Green Day.\nThursday, May 14, 2009\n\nThree chord song\n\"A three-chord song is a song whose music is built around three chords that are\nplayed in a certain sequence. Perhaps the most prevalent type of three-chord\nsong is the simple twelve bar blues used in blues and rock and roll.\nTypically, the three chords used are the chords on the tonic, subdominant, and\ndominant (scale degrees I, IV and V): in the key of C, these would be the C, F\nand G chords. Sometimes the V7 chord is used instead of V, for greater tension.\nThree-chord songs are easy for the listener to remember, which can make them\neffective in pop music. Some of the most famous songs to use three-chord\npatterns are \"Louie Louie\" by The Kingsmen and \"Wild Thing\" by The Troggs.\nThree-chord songs like these are also easier to learn than other, more\ncomplicated songs. Among others, country singer Hank Williams and folk singer\nBob Dylan have written large numbers of such songs. Denis Leary's song\n\"Asshole\" uses a three chord progression. Punk music very often features three-\nchord songs - sometimes called a 'three chord trash' (cf. The Ramones).\"\n-- Wikipedia.\nThursday, May 14, 2009\n\nCommon progressions used\nin the common practice period (roughly 1600-1900)\nI, i May progress to any other triad. May interrupt any progression.\n\nMajor keys\n\nMinor keys\nii\nii-V, ii-vii6\n\nii6\n ii6\n-V\n\nii*\nii-V, ii-vii6\niii iii-ii6\n, iii-IV, iii-V, iii-vi\n\nIII III-ii6\n, III-iv, III-VI\nIV\nIV-I, IV-ii, IV-V, IV-vii6 iv iv-i, iv-ii6\n, iv-V, iv-VII\n\nIV*\nIV-V, IV-vii6\nV\nV-I, V-vi\n\nV\n\nV-i, V-VI\n\nv* v-VI\nvi\nvi-ii, vi-IV, vi-V, vi-iii-IV VI VI-ii6\n, VI-iv, VI-V, VI-III-iv\nvii6 vii6\n-I, vii6-V\nvii6\n/VII vii6-i/VII-III\n* ii and IV in minor used with an ascending #6; v in minor used with a descending 7.\nSee Chord (music)#Quality and Triads for a brief explanation of the notation used in this\ntable.d\nThursday, May 14, 2009\n\n\"In music, modulation is most commonly the act or process of\nchanging from one key (tonic, or tonal center) to another. This\nmay or may not be accompanied by a change in key signature.\nModulations articulate or create the structure or form of many\npieces, as well as add interest.\nThere are several different types of modulation -- (these) modulations may be\nprepared or unprepared, smooth or abrupt. It is smoother to modulate to more\nclosely related keys than to keys further away. Closeness is determined by the\nnumber of notes in common between keys, which provides more possible pivot\nchords, and their closeness on the circle of fifths. A modulation is often\ncompleted by a cadence in the new key, which helps to establish it. Brief\nmodulations are often considered tonicizations.\"\n-- Wikipedia, music modulation.\nTypes of modulation (different ways of bridging the transition): common chord,\ncommon tone, chromatic, enharmonic, phrase (direct, abrupt, \"truck drivers\ngear change\", sequential.\nModulation (Changes in tonic, key)\nThursday, May 14, 2009\n\nMusic Animation Machine (Triads, LATTICE)\nCourtesy of Stephen Malinowski. Used with permission.\nThursday, May 14, 2009\n\nChord groupings and musical tension\nThursday, May 14, 2009\nS\nch\ne\nma\nti\nc\no\nf\n\nh\na\nr\nm\no\nn\ni\nc\n\nmotion indicating conventional interpretations of tension and release.\nFigure by MIT OpenCourseWare.\n\nHierarchies of organization\nQualities - similarity relations\n- Tonal hierarchies\n- Proximity to tonic (key, scale-relations)\n- Chord hierarchies\n- Proximity to major or minor triad\nEvents grouped in time\n- Melodic hierarchies (time)\n- Phrases, themes\n- Rhythmic hierarchies\n- Harmonic movements -\nThursday, May 14, 2009\n\nTonal system\nsee also\nhttp://www.musictheory.net\nfor introduction to keys\nThursday, May 14, 2009\nDiagram showing how scale establishes pa\nr\nti c\nul a\nr\ni\nn\ntr\na\n- a\nnd inter-key relationships, inc\nluding tonic/dominant and circ\nle of fifths.\nFigure by MIT OpenCourseWare.\n\nChord Hierarchies\nDistance relations\nGreater distance from tonic\ncreates greater tension\nSmaller distance resolves\ntension\nSource: Fig. 1 in Bharucha,\nSource: Krumhansl, C., J. J. Bharucha, and E. J. Kessler.\nJ. and C. L. Krumhansl.\n\"Perceived Harmonic Structure of Chords in Three Related Musical\n\"The representation of\nKeys.\" J Exp Psychol Hum Percept Perform 8, no. 1 (Feb 1982):\nharmonic structure in music: pp. 24-36. Courtesy of American Psychological Association.\nHierarchies of stability as a function of context .\nCognition 13, no. 1 (January 1983): pp. 63-102.\nCourtesy Elsevier, Inc., http://www.sciencedirect.com.\nUsed with permission.\nThursday, May 14, 2009\n\nTonal hierarchies:\ntrees, nestings,\nand neighborhoods\nThursday, May 14, 2009\nS\nch\ne\nma\nti\nc\no\nf\n\nh\na\nr\nm\no\nn\ni\nc\n\nmotion indicating conventional interpretations of tension and release.\nFigure by MIT OpenCourseWare.\nSource: Krumhansl, C., J. J. Bharucha, and E. J. Kessler.\n\"Perceived Harmonic Structure of Chords in Three Related Musical\nKeys.\" J Exp Psychol Hum Percept Perform 8, no. 1 (Feb 1982):\npp. 24-36. Courtesy of American Psychological Association.\n\nTonal hierarchies\nThursday, May 14, 2009\nS\nch\ne\nma\nti\nc\no\nf\n\nh\na\nr\nm\no\nn\ni\nc\n\nmotion indicating conventional interpretations of tension and release.\nFigure by MIT OpenCourseWare.\n\nKatz (in Musical Networks)\nAttempt to develop\ncomputer models\nthat behave in a manner\nlike human listeners in\ntheir evaluation of\nmelodies\nThursday, May 14, 2009\nTwo graphs removed due to copyright restrictions.\nSee Fig. 15 in Katz, Bruce F. \"An Ear for Melody.\"\nIn Musical Networks. Edited by N. Griffith and P. M. Todd.\nMIT Press, 1999. (Reprinted from Connection Science 6:299\n(1994).)\n\nTillman, Bharucha & Bigand\nKey relations through\nbottom-up and top-down\nassociations\nConnectionist nets\nCourtesy of the Cognitive Science Society.\nUsed with permission.Source: Bharucha, J. J. \"MUSACT:\nA Connectionist Model of Musical Harmony.\"\nIn Program of the Ninth Annual Conference of the Cognitive\nScience Society, pp. 508-517.\nThursday, May 14, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Neural mechanisms of musical pitch",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/113fd4591251002969c621ff301915d2_MITHST_725S09_lec05_pitchmech.pdf",
      "content": "Neural mechanisms\nof musical pitch The letters PITCH are drawn in a block shadow style where upper and left edges of the characters are not shown, but implied by the shadows.\nwww.cariani.com\nFriday, March 13, 2009\nSchemat\nic model of the cochlea.\nFigure by MIT OpenCourseWare.\nFigure by MIT OpenCourseWare.\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nBig questions - why music?\n- What does music do for us?\n- Why is music effective at this?\n- How is music structured to make it effective?\n- What are the neural codes & computations?\n- Why is music the way it is? (e.g. why scales?)\n- How/why did music arise?\nevolutionary adaptation?\nhijack internal rewards?\n- How can I become a rock star?\nself-control of states?\nFriday, March 13, 2009\n\noverview\nRoadmap\nfunctions of music\nsound, ear\nloudness & pitch\nbasic qualities of notes\ntimbre\nconsonance, scales & tuning\ninteractions between notes\nmelody & harmony\npatterns of pitches\ntime, rhythm, and motion\npatterns of events\ngrouping, expectation, meaning interpretations\nmusic & language\nFriday, March 13, 2009\n\nRoadmap\nmusic therapy\nneurology of music\ndevelopmental & comparative psychology\norigins: evolutionary psychology\nhow/why music fulfils its diverse functions\nmy own belief is that music\nspeaks the language of the brain,\na temporal pattern code\nand that this is why music can affect us\nin so many different ways\nFriday, March 13, 2009\n\nHardware\nComputations\nDecisions\nNeural\narchitectures\nNeural codes\nFunctions\nInformation-processing\noperations\nSensory\nencodings\nMotor\ncommands\nExternal\nworld\nReceptors\nEffectors\nReverse-\nengineering\nthe brain\nSignals\nPitch mechanisms\nin the auditory CNS\nFriday, March 13, 2009\n\nBasic analysis strategies\n- Frequency-domain\n- Place-codes form central spectra\n- In some models, interspike intervals form central spectra (Goldstein)\n- Patterns of partials are analyzed to infer F0\n- Architectures: feature-detectors and connectionist networks\n- Output: pitch detectors\n- Time-domain theories\n- Temporal patterns of spikes form autocorrelation-like representations\n- Dominant interval patterns correspond to F0-pitch\n- Architectures1:\n- Time-to-place conversion (Jeffress, Licklider. time-delay neural networks)\n- Output: Pitch detectors\n- Architectures2:\n- Time-to-time conversion (neural timing nets)\n- Output: Temporal patterns of spikes; pattern similarity detection\n- Evidence in the auditory pathway\n- Neural timing models\n- Pitch matching, similarity, and F0-based separation\nFriday, March 13, 2009\n\nSearch for the missing fundamental: theories & models of musical pitch\n- Distortion theories (nonlinear processes produce F0 in the cochlea)\n- Spectral pattern theories\n- Pattern-recognition/pattern-completion\n- Fletcher: frequency separation\n- The need for harmonic templates (Goldstein)\nTerhardt's Virtual pitch: adding up the subharmonics\n- Musical pitch equivalence classes\n- Pitch classes and neural nets: Cohen & Grossberg\n- Learning pitch classes with connectionist nets: Bharucha\n- Temporal theories\n- Residues: Beatings of unresolved harmonics (Schouten, 1940's)\n- Problems with residues and envelopes\n- Temporal autocorrelation models (Licklider, 1951)\n- Interspike interval models (Moore, 1980)\n- Correlogram demonstration (Slaney & Lyon, Apple demo video)\nFriday, March 13, 2009\n\nBasic aspects of pitch to be explained\n- Pure tone pitches (50-20,000 Hz)\n- Complex tone pitches (periodic sounds F0s 30-1000 Hz)\n- Pitch equivalence classes (pure & complex tones w. diff spectra)\n- Precision and robustness of pitch discrimination\n- Pitch salience (why some pitches are strong or weak)\n- Pitch similarities (octave relations)\n- Musical interval recognition/transposition/pitch relativity\n- Role of common periodicity in auditory grouping\n- How multiple notes are simultaneously represented.\n- Pitch memory (for relative & absolute pitch)\nFriday, March 13, 2009\n\nHarmonic series\nA harmonic series conists of integer multiples of a fundamental frequency,\ne.g. if the fundamental is 100 Hz, then the harmonic series is: 100, 200,\n300, 400, 500, 600 Hz, .... etc.\nThe 100 Hz fundamental is the first harmonic, 200 Hz is the second\nharmonic. The fundamental is often denoted by F0.\nThe fundamental frequency is therefore the greatest common divisor of all\nthe frequencies of the partials.\nHarmonics above the fundamental constitute the overtone series.\nSubharmonics are integer divisions of the fundamental:\ne.g. for F0= 100 Hz, subharmonics are at 50, 33, 25, 20, 16.6 Hz etc.\nSubharmonics are also called\nundertones.\nThe fundamental period is 1/F0, e.g. for F0=100 Hz, it is 1/100 sec or 10\nFriday, March 13, 2009\n\nPeriodic sounds: time and frequency domains\nWaveforms\nPower Spectra\nAutocorrelations\nFormant-related\nPitch periods, 1/F0\nVowel quality\n125 Hz\n100 Hz\nTimbre\n[ae]\nF0 = 100 Hz\n[ae]\nF0 = 125 Hz\n[er]\nF0 = 100 Hz\n[er]\nF0 = 125 Hz\n0 1\nTime (ms)\nFrequency (kHz)\nInterval (ms)\nFriday, March 13, 2009\n\nPitch : basic properties to be explained\n- Highly precise percepts\n- Musical half step: 6% change F0\n- Minimum JND's: 0.2% at 1 kHz (20 usec time difference, comparable to ITD jnd)\n- Highly robust percepts\n- Robust quality Salience is maintained at high stimulus intensities\n- Level invariant (pitch shifts < few % over 40 dB range)\n- Phase invariant (largely independent of phase spectrum, f < 2 kHz)\n- Strong perceptual equivalence classes\n- Octave similarities are universally shared\n- Musical tonality (octaves, intervals, melodies) 30 Hz - 4 kHz\n- Perceptual organization (\"scene analysis\")\n- Fusion: Common F0 is a powerful factor for grouping of frequency components\n- Two mechanisms? Temporal (interval-based) & place (rate-based)\n- Temporal: predominates for periodicities < 4 kH (level-independent, tonal)\n- Place: predominates for frequencies > 4 kHz(level-dependent, atonal)\nFriday, March 13, 2009\n\nPeriodic sounds\nproduce distinct\npitches\nMany different\nsounds produce\nthe same pitches\nStrong\n- Pure tones\n- Harmonic complexes\n- Iterated noise\nWeaker\n- High harmonics\n- Narrowband noise\nVery weak\n- AM noise\n- Repeated noise\nStrong\npitches\nWeaker\nlow\npitches\nFriday, March 13, 2009 Schematic representation of eight signals with the same low fundamental pitch but different sets of harmonics.\nFigure by MIT OpenCourseWare.\n\nDuplex time-place representations\n\"Pitch is not simply frequency\"\nMusical tonality: octaves, intervals, melodies\nStrong phase-locking (temporal information)\ntemporal representation\nlevel-invariant, precise\nplace representation\nlevel-dependent, coarse\n1k\n10k\nFrequency (kHz)\nFriday, March 13, 2009\n\nDuplex time-place representations\ntemporal representation\nlevel-invariant\n- strong (low fc, low n, \"resolved\")\n- weak (high fc, high n; \"unresolved\"\nF0 < 100 Hz)\nplace-based\nrepresentation\nlevel-dependent\ncoarse\n1k\n10k\nSimilarity\ncf. Terhardt's\nto\nspectral and virtual pitch\ninterval\npattern\nSimilarity to place pattern\nFriday, March 13, 2009\n\nA \"two-mechanism\" perspective\n(popular with some psychophysicists, compatible with spectral pattern models of F0 pitch)\nharmonic number\nn= 5-10\nplace-based\nrepresentations\nlevel-dependent\ncoarse\n1k\n10k\nf, F0\nDominance region\nunresolved harmonics\nweak temporal mechanism\nphase-dependent; first-order intervals\nplace-based\nrepresentation\nlevel-independent\nfine\nresolved harmonics\nstrong spectral pattern mechanism\nphase-independent\nrate-place? interval-place?\nFriday, March 13, 2009\n\nFriday, March 13, 2009 Schematic of afferent auditory pathways, from the cochlea to the auditory cortex.\nFigure by MIT OpenCourseWare.Schematic of afferent auditory pathways, from the cochlea to the auditory cortex.\n\nCharacteristic freq. (kHz)\nSome\nLocal\nCentral spectrum\npossible\nauditory\nrepresentations\nMasking phenomena\nLoudness\nCF\nSynchrony-place\nPhase-place\nInterval-place\nPure tone pitch JNDs: Goldstein\nPopulation interval\nStages of\n1/F0\nintegration\nPopulation-interval\nAll-at-once\nComplex tone pitch\nGlobal\nFriday, March 13, 2009\n\nANFs\nFriday, March 13, 2009\n\nGeneral theories of pitch\n1. Distortion theories\n- reintroduce F0 as a cochlear\ndistortion component (Helmholtz)\n-sound delivery equipment can\nreintroduce F0 through distortion\n-however, masking F0 region does not\nmask the low pitch (Licklider)\n-low pitch thresholds and growth of\nsalience with level not consistent with\ndistortion processes (Plomp, Small)\n-binaurally-created pitches exist\n2. Spectral pattern theories\n-Operate in frequency domain\n-Recognize harmonic relations\non resolved components\n3. Temporal pattern theories\n-Operate in time domain\n-Analyze interspike interval dists.\nFriday, March 13, 2009\nStimulus\nF0= 80 Hz\ndB\n0 Frequency (kHz)3\narray of cochlear band-pass filters\nauditory\nnerve fiber\ntuning curves\ninterspike intervals\ndischarge rates\nPower spectrum\nAutocorrelation\nrepresentation\nrepresentation\nFrequency domain\nTime domain\nPopulation rate-\nplace profile\nPopulation\ninterspike interval\ndistribution\nfrequency\noptimal\n(linear scale)\nmatch\nF0 = 200 Hz\nF0 = 160 Hz\n1/F0\n1/F1\nF0 = 100 Hz\nInterval (ms)\nharmonic templates\nPitch  best fitting template\n# intervals\n\n\"Virtual\" pitch: F0-pitch as pattern completion\n\"Missing fundamental\" analogy to illusory contour\nFriday, March 13, 2009 The letters PITCH are drawn in a block shadow style where upper and left edges of the characters are not shown, but implied by the shadows.\nFigure by MIT OpenCourseWare.\n\nPsychological perspectives on pitch\nAnalytical: break sounds into frequencies (perceptual atoms, features),\n\nthen analyze patterns (templates, combinations)\n(British empiricism; machine perception)\nRelational: extract invariant relations from patterns\n(Gestaltists, Gibsonians, temporal models)\nNativist/rationalist: mechanisms for pitch are given by innate\nknowledge and/or computational mechanisms\n\ndifferences re: how recently evolved these are\nAssociationist: mechanisms for pitch (e.g. templates) must be\n\nacquired through experience (ontogeny, culture)\nInteractionist: (Piaget) interaction between native faculties and\nFriday, March 13, 2009\n\nSpectral pattern theories\nCentral spectrum\n- Not the lowest harmonic\n- Not simple harmonic spacings\n- Not waveform envelope or peak-picking\n(pitch shift exps by Schouten & de Boer)\n- Must do a real harmonic analysis of\nspectral fine structure to find common\nF0 = 200 Hz\ndenominator, which is the fundamental\nF0 = 160 Hz\nfrequency (comb filtering works)\nF0 = 100 Hz\n- Terhardt: find common subharmonics\n- Wightman: autocorrelation of spectra\nharmonic templates\n- Goldstein, Houtsma: match spectral\nexcitation pattern to harmonic templates Pitch  best fitting template\n- SPINET: Use lateral inhibition/center\nsurround then fixed neural net to\nOutput of comb filters\ngenerate equivalence classes\n- Barucha: adaptive connectionist\nnetworks for forming harmonic\nassociations (hear many harmonic\nexemplars; problems with F0 range --\nfrequency\n(linear scale)\noptimal\nmatch\nFriday, March 13, 2009\n\nSpectral pattern\nanalysis\nvs.\ntemporal pattern\nanalysis\nNote: Some models,\nsuch as Goldstein's\nuse interspike interval\ninformation to first form\na Central Spectrum\nwhich is then analyzed using\nharmonic spectral templates.\nThere are thus dichotomies\n1) between use of\ntime and place information\nas the basis of the central\nrepresentation, and\n2) use of spectral vs.\nautocorrelation-like central\nrepresentations\nStimulus\nF0= 80 Hz\ndB\narray of cochlear band-pass filters\nauditory\nnerve fiber\nFrequency (kHz)\ntuning curves\ndischarge rates\ninterspike intervals\n# intervals\nPower spectrum\nrepresentation\nFrequency domain\nPopulation rate-\nplace profile\nfrequency\noptimal\n(linear scale)\nmatch\nF0 = 200 Hz\nF0 = 160 Hz\nF0 = 100 Hz\nharmonic templates\nPitch  best fitting template\nAutocorrelation\nrepresentation\nTime domain\nPopulation\ninterspike interval\ndistribution\n1/F0\n1/F1\nInterval (ms)\nFriday, March 13, 2009\n\nResolution of harmonics\nFriday, March 13, 2009 Graph of threshold shift (dB) vs. frequency (0 to 4kHz).\nFigure by MIT OpenCourseWare.\n\nPeriodic sounds\nproduce distinct\npitches\nMany different\nsounds produce\nthe same pitches\nStrong\n- Pure tones\n- Harmonic complexes\n- Iterated noise\nWeaker\n- High harmonics\n- Narrowband noise\nVery weak\n- AM noise\n- Repeated noise\nStrong\npitches\nWeaker\nlow\npitches\nFriday, March 13, 2009 Schematic representation of eight signals with the same low fundamental pitch but different sets of harmonics.\nFigure by MIT OpenCourseWare.\n\nGoldsteins\nFriday, March 13, 2009\nFigure removed due to copyright restrictions.\nDiagram of periodicity pitch as harmonic frequency pattern recognition.\nfigure 3 in Goldstein, J. L., et al. \"Verification of the Optimal Probabilistic Basis of\nAural Processing in Pitch of Complex Tones.\" J Acoust Soc Am 63 (1978): 486-510.\nhttp://dx.doi.org/10.1121/1.381749\n\nGoldstein JL (1970) Aural combination tones. In: Frequency Analysis and Periodicity\nDetection in Hearing (Plomp R, Smoorenburg GF, eds), pp 230-247. Leiden: A.\nW. Sijthoff.\nGoldstein JL (1973) An optimum processor theory for the central formation of the pitch\nof complex tones. J Acoust Soc Am 54:1496-1516.\nJulius Goldstein\nGoldstein JL, Kiang NYS (1968) Neural correlates of the aural combination tone 2f1-f2.\nIEEE Proc 56:981-992.\nreferences\nGoldstein JL, Srulovicz P (1977) Auditory-nerve spike intervals as an adequate basis for\naural frequency measurement. In: Psychophysics and Physiology of Hearing\n(Evans EF, Wilson JP, eds). London: Academic Press.\nGoldstein JL, Buchsbaum G, First M (1978a) Compatibility between psychophysical and\nphysiological measurements of aural combination tones. J Acoust Soc Am\nModels for\n63:474-485.\nGoldstein JL, Buchsbaum G, Furst M (1978b) Compatibility between psychophysical and\npure tone\nphysiological measurements of aural combination tones... Journal of the\nAcoustical Society of America 63:474-485.\npitch\nGoldstein JL, Gerson A, Srulovicz P, Furst M (1978c) Verification of the optimal\ndiscrimination,\nprobabilistic basis of aural processing in pitch of complex tones. J Acoust Soc Am\n63:486-510.\nlow pitches of\nH. L. Duifhuis and L. F. Willems and R. J. Sluyter ( 1982,) Measurement of pitch in\nspeech: An implementation of Goldstein's theory of pitch perception,. jasa, 71,:\n1568--1580.\ncomplex tones,\nHoutsma AJM, Goldstein JL (1971) Perception of musical intervals: Evidence for the\ncentral origin of the pitch of complex tones. In: M.I.T./R.L.E.\nbinaural pitches,\nHoutsma AJM, Goldstein JL (1972) The central origin of the pitch of complex tones:\nEvidence from musical interval recognition. J Acoust Soc Am 51:520-529.\nand\nP. Srulovicz and J. Goldstein ( 1983) A central spectrum model: A\nsynthesis of\nauditory nerve timing and place cues in monoaural communication offrequency\naural distortion\nspectrum,. jasa, 73,: 1266--1276,.\nproducts\nSrulovicz P, Goldstein JL (1977) Central spectral patterns in aural signal analysis based\non cochlear neural timing and frequency filtering. In: IEEE, p 4 pages. Tel Aviv,\nIsrael.\nSrulovicz P, Goldstein JL (1983) A central spectrum model: a synthesis of auditory-nerve\ntiming and place cues in monaural communication of frequency spectrum. J\nAcoust Soc Am 73:1266-1276.\nFriday, March 13, 2009\n\nTerhard's method of common subharmonics\nSpectral vs. virtual pitch: duplex model\nVirtual pitch computation:\n1. Identify frequency components, e.g. 1000, 1200, 140\n2. Find common subharmonics\n\n3. Strongest common subharmonic after\nF0 weighting is the virtual pitch\nTerhardt's model has been extended by\nParncutt to cover pitch multiplicity\nand fundamental bass of chords\nFriday, March 13, 2009\n\nTerhard's method\n1. Identify frequency components, e.g. 1000, 1200, 1400\n2. Find common subharmonics, f/n for n = 1, 2, 3, ...\nf=1000: 500, 333, 250,\n200, 166, 143, 125, 111, 100, ...\nf=1200: 600, 400, 300, 240,\n200, 171, 150, 133, 109,\n100, f=1400: 700, 466, 350, 280, 233, 200, 175, 155,\n140, ...100, ...\n3. Strongest common subharmonic after F0 weighting, which\nbiases against low F0s, is the virtual pitch\nParallels with all-order interspike interval models\nEach harmonic generates intervals at its subharmonics\nAdding together all the intervals and finding the most\ncommon intervals therefore finds the common\nsubharmonics (F0/n)\nF0-weighting is achieved by limiting interval length\nFriday, March 13, 2009\n\nTerhardt references\nTerhardt E (1970) Frequency analysis and periodicity detection in the sensations of\nroughness and periodicity pitch. In: Frequency Analysis and Periodicity Detection\nin Hearing (Plomp R, Smoorenburg GF, eds). Leiden: A. W. Sijthoff.\nTerhardt E (1974a) On the perception of periodic sound fluctuations (roughness).\nAcustica 30:201-213.\nTerhardt E (1974b) Pitch, consonance, and harmony. J Acoust Soc Am 55:1061-1069.\nTerhardt E (1977) The two-component theory of musical consonance. In: Psychophysics\nand Physiology of Hearing (Evans EF, Wilson JP, eds), pp 381-390. London:\nAcademic Press.\nTerhardt E (1979) Calculating virtual pitch. Hearing Research 1:155-182.\nTerhardt E (1984) The concept of musical consonance: a link between music and\npsychoacoustics. Music Perception 1:276-295.\nTerhardt E, Stoll G, Seewann M (1982a) Pitch of complex signals according to virtual-\npitch theory: test, examples, and predictions. J Acoust Soc Am 71:671-678.\nTerhardt E, Stoll G, Seewann M (1982b) Algorithm for extraction of pitch and pitch\nsalience from complex tonal signals. J Acoust Soc Am 71:679-688.\nParncutt R (1989) Harmony: A Psychoacoustical Approach. Berlin: Springer-Verlag\nFriday, March 13, 2009\n\nSPINET:\nCohen Grossberg, Wyse JASA\nFixed\nneural\nnetwork:\nconnection\nweights\narranged\nso as to form\npitch-equivalence\nclasses\nFriday, March 13, 2009\nCourtesy of Prof. Stephen Grossberg. Used with permission.\nSource: Cohen, M. A., S. Grossberg, and L. L. Wyse. \"A Spectral Network Model of Pitch Perception.\" Technical Report\nCAS/CNS TR-92-024, Boston University. Also published in J Acoust Soc Am 98, no. 2 part 1 (1995): 862-79.\n\nNeural networks\nwij\nwij\nPurpose: group combinations of\nRate\nvariable\nintegrators\ni\nfeatures into equivalence classes\nwij\nj\nfeature\nA\nAAAA\nA\nB B\nAdaptive adjustment of synaptic\nB\nweights so as to properly classify\nB\nB\nB\nB\nB\no b j e c t s b y t h e i r f e a t u r e\ncombinations\nfeature 1\nFriday, March 13, 2009\nCourtesy of MIT Press. Used with permission.\nSource: Arbib, M. A., ed. The Handbook of Brain Theory and Neural Networks.\n2nd ed. Cambridge MA: MIT Press, 2003. ISBN: 9780262011976.\n\nNeural networks\nRate\nvariable\nConnectionist networks\ni\nintegrators\nwij\nPurely spatial correlators\nPlace-Place mappings\nj\nvariable\nwij, ij\nCoincidence i\ndetectors\nij\nTime-delay networks\nij\nj\nSpatio-temporal correlators\nTime-Place mappings\nRate\nvariable\nintegrators\ni\nwij\nij\nwij, ij\nj\nvariable\nTiming nets\nij\nCoincidence i\ndetectors\nij\nTemporal correlators\nwij\nwij\nij\nij\nij\nTime-Time mappings\nj\nFriday, March 13, 2009\n\nHippocampus as a connectionist architecture\nLorente de No\nAuto-associative network\n(rate-channel code)\nFriday, March 13, 2009\nCourtesy of the MIT Press. Used with permission.\nSource: Fig 3.14 in Churchland, P. and T. Sejnowski. The Computational Brain.\nCambridge, MA: MIT Press, 1992. ISBN: 9780262531207.\n\nCerebral cortex\nHippocampus\nCerebellar cortex\nCORTICAL\nSTRUCTURES\nFox\nCajal\nRATE\nCODES\nTIME\nCODES\nPURELY SPATIAL\nSPATIO-TEMPORAL\nCORRELATORS\nCORRELATORS\neffective connectivity\neffective connectivity\n&\ntiming relations\nFriday, March 13, 2009\n\nSpectral pattern theories - pros & cons\nDo make use of frequency tuning properties of auditory elements\nNo clear neural evidence of narrow (< 1/3 octave) frequency\n\nchannels in low-BF regions (< 2 kHz)\n(re: mistuning\ndetection)\nOperate on perceptually-resolved harmonics\nDo not explain low pitches of unresolved harmonics\nRequire templates or harmonic pattern analyzers\nLittle neural evidence for resolved low harmonics or req. analyzers\nPossible evidence for F0-detectors (Bendor & Wang(2005)\nProblems w. templates: relative nature of pitch\nDo not explain well existence region for F0\nFriday, March 13, 2009\n\nTime domain analysis of auditory-nerve fiber firing rates.\nVowel Formant Regions\nHugh Secker-Walker & Campbell Searle, J. Acoust. Soc. 88(3), 1990\nNeural responses to /da/ @ 69 dB SPL from Miller and Sachs (1983)\nLow\nCF\nHigh\nCF\nF0\nF1\nF2\nF3\nPeristimulus time (ms)\nFriday, March 13, 2009\nReprinted with permission, from Secker-Walker HE, Searle CL. 1990. \"Time-domain Analysis of Auditory-Nerve-Fiber Firing Rates.\"\nJ Acoust Soc Am 88 (3): 1427-36. Copyright 1990, Acoustical Society of America.\n\nFriday, March 13, 2009\nSource: Cariani, P. A., and B. Delgutte.\n\"Neural Correlates of the Pitch of Complex Tones.\nI. Pitch and Pitch Salience.\" J Neurophysiol 76\n(1996): 1698-1716. [0022-3077/96].\nCourtesy of the American Physiological\nAssociation. Used with permission.\n\nTemporal pattern theories\nSch\nImage removed due to copyright restrictions.\nSee Fig. 2, \"Schematic representation of the origination of low pitch.\"\nIn van Noorden, L. \"Two Channel Pitch Perception.\" Clynes, M., ed.\n\noutens temporal theory (1940s)\ndepended on\ninteractions between\nunresolved (high) harmonics. It was\n. displaced by discovery of dominance\nregion and binaural combination\npitches in the 1960s. The idea\npersists, however in the form of\nspectral mechanisms for resolved\nharmonics and temporal ones for\nunresolved harmonics.\nporal autocorrelation)\nMusic, Mind and Brain. New York, NY: Plenum, 1982.\n.\n\nvan Noorden (1982)\n First-order intervals\n(renewal density)\n All-order intervals (tem\nLicklider (1951)\nMeddis & Hewitt (1991)\nlease see Figure 1 in Meddis, R., and M. J. Hewitt.\nirtual Pitch and Phase Sensitivity of a Computer\nModel of the Auditory Periphery. I. Pitch identification.\nJ Acoust Soc Am 89, no. 6 (1991): 2866-2882.\nDiagram of a neuronal autocorrelator.\nV\nImages by MIT OpenCourseWare.\nImage removed due to copyright restrictions.\nSee Moore, B. C. J.\n\nAn Introduction to the\nPsychology of Hearing. 5th ed.\nSan Diego, CA: Academic Press, 2003.\n\nMoore (1982)\n\n First-order\n\nintervals\nFriday, March 13, 2009\nSchemat\nic model of the cochlea.\n\nSchematic model o\nf the cochlea.\nInterval-based\ntheories of pitch\nMoore\nFirst-order intervals\n(1982)\n(renewal density)\nvan Noorden (1982) Diagram of a neuronal autocorrelator.\nAll-order intervals\n(temporal autocorrelation) Schematic model of the cochlea.\nFriday, March 13, 2009 Schematic model of the cochlea.\nImage removed due to copyright restrictions.\nSee Fig. 2, \"Schematic representation of the origination of low pitch.\" In van Noorden, L.\n\"Two channel pitch perception.\" In Clynes, M. ed. Music, Mind and Brain\n.\nNew York, NY: Plenum Press, 1982.\nImage removed due to copyright restrictions.\nMoore, B. C. J. An Introduction to the Psychology of Hearing. 5th ed.\nSan Diego, CA: Academic Press, 2003.\n\nLickliders (1951) duplex model of pitch perception\nLickliders binaural triplex model\nImage removed due to copyright restrictions.\nFigure 5, \"Schematic illustration of hypothetical auditory system.\"\nJ.C.R. Licklider (1959) \"Three\nAuditory Theories\" in Psychology: A Study\nof a Science, Vol. 1, S. Koch, ed., McGraw-\nHill, pp. 41-144.\nFriday, March 13, 2009\nSchemat\ni\nc model of the cochlea.Diagram of a neuronal autocorrelator.\nFigure by MIT OpenCourseWare.\nFrequency\n\nBasic plan of the Jeffress binaural crosscorrelator\nFriday, March 13, 2009\n\nJeffress temporal correlation model for sound localization (1948)\nFriday, March 13, 2009\n\nTapped delay lines: synaptic and transmission delays\nFriday, March 13, 2009\nDiagram of a neuronal autocorrelator.\nFigure by MIT OpenCourseWare.\n\nFriday, March 13, 2009\nFigure by MIT OpenCourseWare.\nS\nchemati\nc model of\nthe cochl\nea.\n\nAutocorrelation and interspike intervals\nAutocorrelation functions\nFundamental\nCorr() = S(t) S(t- )\nperiod\nt\n1/F0\nShift\nMultiply\nSum the products\nfor each delay \nto compute\nautocorrelation\nfunction\ntime lag\n\nAutocorrelations =\nHistograms of\nof spike trains\nall-order intervals\nFriday, March 13, 2009\n\nAutocorrelations =\nHistograms of\nDelay lines,\nof spike trains\nall-order intervals\ncoincidence\ndetectors, and\nautocorrelation\nFriday, March 13, 2009 Diagram of a neuronal autocorrelator.\nFigure by MIT OpenCourseWare.\n\nFriday, March 13, 2009\nImages removed due to copyright restrictions.\nSee Figure 6.16A-D in Lyon, R., and S. Shamma. \"Auditory Representations of Timbre\nand Pitch.\" In Auditory Computation. Edited by R. R. Fay. New York, NY: Springer, 1996.\n\n1950s Tape autocorrelator\nFriday, March 13, 2009\nImages removed due to copyright restrictions.\nTwo photos of a tape autocorrelator machine (magnetic correlatograph).\nSee Plates 3.1 and 3.2 in Lange, F. H. Correlation Techniques: Foundations\nand Applications of Correlation Analysis. Iliffe, 1967.\n\nBiddulphs speech autocorrelograms (from Lange, Correlation Techniques)\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\n\"Biddulph's Correlatogram 29\" showing various sounds.See Plate 3.4 in Lange, F. H.\nCorrelation Techniques:Foundations and Applications of Correlation Analysis. Iliffe, 1967.\n\nSee Cariani, P. \"Recurrent Timing Nets for F0-based Speaker Separation.\" Paper for Proceedings of Perspectives on Speech\nSeparation, Montreal, October 30-November 2, 2003.\nBig dogs can be dangerous.\nFriday, March 13, 2009\n\nCorrelograms: interval-place displays (Slaney & Lyon)\nFrequency (CF)\nAutocorrelation lag\nFriday, March 13, 2009\n\nCorrelograms\nFriday, March 13, 2009\nImages removed due to copyright restrictions.\nSee Figure 6.17 in Lyon, R. and S. Shamma. \"Auditory Representations of Timbre and Pitch.\"\nIn Auditory Computation. Edited by R. R. Fay. New York, NY: Springer, 1996.\n\nINTERVAL\nDISTRIBUTIONS\nAND\nOCTAVE\nSIMILARITY\nFriday, March 13, 2009\nThis image is from the article Cariani, P.\n\"Temporal Codes, Timing Nets, and Music\nPerception.\" Journal of New Music Research\n30, no. 2 (2001): 107-135. DOI:\n10.1076/jnmr.30.2.107.7115.\nThis journal is available online at\nhttp://www.ingentaconnect.com/content\n/routledg/jnmr/\n\nOctave\nsimilarity\nFriday, March 13, 2009\nThis image is from the article Cariani, P. \"Temporal Codes,\nTiming Nets, and Music Perception.\" Journal of New Music\nResearch 30, no. 2 (2001): 107-135.\nDOI: 10.1076/jnmr.30.2.107.7115. This journal is available online at:\nhttp://www.ingentaconnect.com/content/routledg/jnmr/\n\nPhysiological and functional representations\nInterval-place\nRate-place\nSpatiotemporal pattern\nGlobal interval\nprofiles\n(Place & time)\nCentral autocorrelation\nCentral spectrum\nTime-domain\nFrequency-domain\nrepresentation\nrepresentation\nFriday, March 13, 2009\n\nDifferent representations can support analogous strategies for\npitch extraction, recognition, and comparison\nCentral autocorrelation\nCentral spectrum\nTime-domain\nFrequency-domain\nrepresentation\nrepresentation\nExplicit\nidentification\nof individual\nharmonics &\ndeduction of F0\nvia common\nsubharmonics\nor pattern\nrecognition\nTemplate-based\nglobal recognition of\npitch-related patterns\n(neural networks,\nharmonic templates,\ninterval sieves)\nRelative pitch\ncomparison\nmechanisms\n(matching,\noctaves,\nmusical intervals)\nSpectral patterns\nTemporal patterns\nFriday, March 13, 2009\n\nCochlear nucleus I\nUnipolar click trains\nUnipolar click train\nVariable F0\nFixed F0 (160 Hz)\nPitch period ~1/F0\nPitch ~160 Hz\nF0 = 80-160 Hz\nF0 = 160-320 Hz\nPitch period\n1 = mean\n1/F0\n# intervals/bin\nPooled\nANF's\n1/F0\n2/F0\nPitch period\n1/F0\nNormalized # intervals\nInterval (ms)\n35-40-23, Chop-S, CF: 2065, Thr: 5.3, SR: 18, CM, 80 dB SPL\nChop\nS\n35-40-23, Chop-S, CF: 2065, Thr: 5.3, SR: 18 s/s, 80 dB SPL\n35-40-22, Chop-S, CF: 2065, Thr: 5.3, SR: 18 s/s, 80 dB SPL\n1/F0\n# intervals\n2/F0\nPitch period\n1/F0\nInterval (ms)\nInterval (ms)\nPitch period\n1/F0\n33-9-23, Chop-S, CF: 11750, Thr: 14.1, SR: 119, CM, ~80 dB SPL\n35-5-19, Chop-S, CF: 5888, Thr: 23.2, SR: 0.6 s/s, 80 dB SPL\n35-5-18, Chop-S, CF: 5888, Thr:23.2 SR:0.6, 80 dB SPL\n1/F0\n# intervals\n2/F0\nPitch period\n1/F0\nPitch period\n1/F0\nPeristimulus time (ms)\nPeristimulus time (ms)\nFriday, March 13, 2009\n\nPitch height and pitch chroma\nImages removed due to copyright restrictions. Figures 1, 2 and 7 in this paper.\nRoger N. Shepard\nGeometrical approximations to the\nstructure of musical pitch.\nPsychological Review\n89(4):305-322, 1982\nFriday, March 13, 2009\n\nInharmonic complex tones (inharmonic AM tones)\nWere used to falsify spectral models based on simple f-\nspacings and simple temporal models based on\nwaveform envelopes.\nRules of thumb:\nLow harmonics (perceptually resolved):\npitch is phase-insensitive\n\npitch follows fine structure of waveform, not\n\nenvelope (pitch shifts, de Boers rule)\nHigh harmonics (unresolved)\npitch can be phase-sensitive (octave shifts)\nFriday, March 13, 2009\n\nTemporal theories - pros & cons\nMake use of spike-timing properties of\nelements in early processing (to midbrain at least)\nInterval-information is precise & robust & level\ninsensitive\nNo strong neurally-grounded theory of how this\ninformation is used\nUnified model: account for pitches of perceptually\n\nresolved & unresolved harmonics in an elegant\nway (dominant periodicity)\nExplain well existence region for F0 (albeit with\nlimits on max interval durations)\nDo explain low pitches of unresolved harmonics\nInterval analyzers require precise delays & short\ncoincidence windows\nFriday, March 13, 2009\n\nThree networks\nRate\nvariable\nConnectionist networks\ni\nintegrators\nwij\nPurely spatial correlators\nPlace-Place mappings\nj\nvariable\nwij, ij\nCoincidence i\ndetectors\nij\nTime-delay networks\nij\nj\nSpatio-temporal correlators\nTime-Place mappings\nRate\nvariable\nintegrators\ni\nwij\nij\nwij, ij\nj\nvariable\nTiming nets\nij\nCoincidence i\ndetectors\nij\nTemporal correlators\nwij\nwij\nij\nij\nij\nTime-Time mappings\nj\nFriday, March 13, 2009\n\nNeural timing nets\nFEED-FORWARD TIMING NETS\nRECURRENT TIMING NETS\n- Temporal sieves\n- Build up pattern invariances\n- Extract (embedded) similarities\n- Detect periodic patterns\n- Multiply autocorrelations\n- Separate auditory objects by F0\n- Pitch & timbre matching\n- Metric induction\n- Time domain comb filters\nRelative delay \nTime\nt\nSj(t)\nSi(t)\nSi(t) Sj(t - )\nindividual\nmultiplicative\nterm\nSi(tm) Sj(tm - t)\n\n\nconvolution\ntime-series\nterm m\ntwo sets\nof input\nspike trains\nFriday, March 13, 2009 Schematic representation of a delay loop matched filter.\nFigure by MIT OpenCourseWare.\n\nFeedforward coincidence net\ncoincidences\nof two nearly\nsimultaneous\npulses required\nto produce\noutput spike\nin coincidence\ndetectors\nSi(t) Sj(t - )\nindividual\nmultiplicative\nterm\nconvolution\ntime-series\nterm m\nSi(tm) Sj(tm - )\n\nTime\nt\nlag\ni leads j\nj leads i\nDelay \nRelative delay between inputs i, j\nSj(t)\nSi(t)\ncross-correlation\nlag term n\npopulation autocorrelation\n Si(t) Sj(t - n)\n \nt\n[Si(t) Sj(t - ) Si(t-) Sj(t -  - )]\nt\nFriday, March 13, 2009\n\nCommon timbre\n[ae] - 100\nPopulation autocorrelations of the output\nof a coincidence array for all vowel combinations\n[ae] - 100\nSame vowel (same F0s & formants)\n[ae] - 125\nSame F0s, different formants\nSame formants, different F0s\nDifferent F0s and formants\n[ae] - 125\n[er] - 100\n[er] - 100\n[er] - 125\n[er] - 125\n10 15 0\n10 15 0\n10 15 0\n10 15\nInterval (ms)\nFriday, March 13, 2009\n\nDetection of arbitrary periodic patterns\nPeriodic patterns invariably build up in\ndelay loops whose recurrence times equals\nthe period of the pattern and its multiples.\n0\n2\n3\nInput pattern\n1010110010110101100101101011001011010...\n1 = 11 ms = recurrence time\nof input pattern10101100101\n1\n\"cyclochronism\" (Popov)\nFriday, March 13, 2009\n\n3\n1 = 11 timesteps = recurrence time\nof repeating 10101100101 pattern\nBuildup\nof activation\nin loop with\nrecurrence time\nof 11 timesteps\n1010110010110101100101101011001011010...\nChannel\nrecurrence time\n0\n1\nPeriodic\npattern builds up\nTimesteps\nLa Marseillaise rhythm\n1100110001000100010001000000110011001100010000000100110000000000...\nDelay loop\n(recurrence time,\nin samples)\nRhythmic\nsubpatterns\nTimesteps (samples)\nFriday, March 13, 2009\n\nTraditional approach (Frequency domain)\nSegregate\nAE-ER\nfrequency\nchannels\n\nAssign\nchannels\nto objects\nER\nAE\nFriday, March 13, 2009\n\nIs a time-domain strategy possible?\nEffect of different F0s in the time domain\nVowel [ae]\nF0 = 100 Hz\nVowel [er]\nF0 = 125 Hz\nDouble vowel\n[ae]+[er]\nTime (msec)\nFriday, March 13, 2009\n\nA general hypothesis re\nphase relations & grouping\n1. Constant temporal relations fuse\n2. Changing temporalrelations separate\n3. The build-up mechanism is indifferent to\nparticular stationary phase relations, but\nsensitive to changes in phase.\n4. After stable objects are formed, they are\nanalyzed via representations & mechanisms\nthat are phase-insensitive (pitch, timbre, loudness)\nFriday, March 13, 2009\n\nReading/assignment for next meeting\n- Pitch models & mechanisms\nFriday, March 13, 2009\n\nPitch classes\nand\nperceptual similarity\nBuild up harmonic\nHarmonic similarity relations\nassociations\nare direct consequences\nfrom repeated\nof the inherent structure\nexposure to harmonic\nof interval codes\ncomplex tones\nFriday, March 13, 2009\n\nFrom cochlea to cortex\n10,000k\nPrimary\nauditory cortex\n(Auditory forebrainSc\nh\nem\na\nt\nic of afferent auditory pathways, from the cochlea to the auditory cortex.\nAuditory thalamus\n500k\nInferior colliculus\n(Auditory midbrain\nLateral lemniscus\nAuditory brainstem\n30k\nAuditory nerve (VIII\n3k\nCochlea\nFriday, March 13, 2009\nFigure by MIT OpenCourseWare.\n\nBasic problems to be solved\n- \"Hyperacuity problem\"\n- Account for the precision of pitch discriminations given the relatively coarse tunings of\nauditory neurons (at all levels), especially lower-frequency ones (BFs < 2 kHz)\n- \"Dynamic range problem\"\n- Account for the ability of listeners to discriminate small fractional changes (I/I) in intensity\nover a large dynamic range, and especially at high SPLs, where the vast majority of firing\nrates are saturated.\n- \"Level-invariance problem\"\n- Account for the invariance (and precision) of auditory percepts over large dynamic ranges\ngiven the profound changes in neural response patterns that occur over those ranges (rate\nsaturation, rate non-montonicities).\n-Pitch equivalence\n-Account for the ability to precisely match pitches of pure and complex tones (pitch\nequivalence, metamery) given differences in spectra and under conditions where stimulus\nintensities are roved 20 dB or more\n-Relative nature of pitch & transpositional invariance\n-Account for the ability to precisely match pitches an octave apart (and/or to recognize\npatterns of pitch sequences) in the absence of an ability to identify absolute frequencies/\nperiodicities. Account for ability to recognize transposed melodies as similar.\nFriday, March 13, 2009\n\nSome generalities about the auditory system\n- Rough cochleotopy is found at all levels, but not necessarily in all pops\n- Orderly tonotopic spatial maps exist only at low tone levels, near neural thresholds\nAs one ascends the afferent pathway:\n- Numbers of neurons at each level increases (usually 2x or more)\n- Fine timing information exists in great superabundance in\nlower\nstations, but becomes successively sparser\n- Firing rates (spontaneous & driven) decline (usually 2x or more)\n- Inhibition increases; % nonmontonic rate-level functions increase\n- Greater proportion of phasic responders, onset & offset responses\n- Diversity and complexity of response increases\n- History-dependence and contextual effects increase\n- Some modulation tuning that suc. declines in periodicity\nTypical BMFs: AN: 200-300 Hz; IC: 50-100 Hz; Ctx (< 16 Hz)\n- No clear \"pitch detectors\" (Schwarz & Tomlinson, 1991);\n-until, perhaps, recently (Bendor & Wang, 2005)\n- No narrow (BW < 0.3 octaves) \"frequency channels\" for BFs < 2 kHz (thus far)\nFriday, March 13, 2009\n\nBrainstem stations involved in localization of sounds\nFriday, March 13, 2009 Diagram of main structures in the ascending chain from cochlea to cortex.\nFigure by MIT OpenCourseWare. Diagram of main structures in the ascending chain from cochlea to cortex.\n\nThree cochlear nuclei :\nAVCN\nPVCN\nDCN\nBifurcation of auditory nerve\nInnervation of 3 major\ncochleotopically-organized\nFriday, March 13, 2009\nSource: public domain\n\nCochlear nuclei : first station in the auditory CNS\nFriday, March 13, 2009\nImages removed due to copyright restrictions.\nFigures 1, 3 and 13 in Irvine, D. R. F. The Auditory Brainstem. New York, NY: Springer, 1986. ISBN: 9783540162995.\n\nSource: public domain\nCochlear nuclei : 3 major divisions (AVCN, PVCN, DCN)\nFriday, March 13, 2009\n\nCochlear nuclei :\n3 major divisions\n(AVCN, PVCN, DCN)\nFriday, March 13, 2009\n\nCochlear nuclei :\nTypes of responses seen\n(to tone bursts at CF):\nrimary-like (AVCN)\nrimary-like w. notch (AVCN)\nhase-locked (PVCN)\nhopper (PVCN)\nImage removed due to copyright restrictions.\n\nSee Fig. 2.18 in Romand, R., and P. Avan.\nauser (DCN)\n\"Anatomical and Functional Aspects of the Cochlear Nucleus.\"\n\nThe Central Auditory System. Edited by G. Ehret and R. Romand.\nuild-up (DCN)\nNew York, NY: Oxford University Press, 1997.\n[Preview this image in Google Books.]\nnset (PVCN)\nost are linked to a particular\neuronal morphological type\n-) indicate main regions\nP\nP\nP\nC\nP\nB\nO\nM\nn\n(\nFriday, March 13, 2009\n\nCochlear\nnucleus units:\nresponses to\ntone bursts\nNote: (C) & (H)\n\"chopping\" occurs\nfor f > 1.5 kHz;\nphase-locking to\nfine structure\nfor f < 1.5 kHz\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nSee Fig. 2.18 in Romand, R., and P. Avan.\n\"Anatomical and Functional Aspects of the Cochlear Nucleus.\"\nThe Central Auditory System. Edited by G. Ehret and R. Romand.\nNew York, NY: Oxford University Press, 1997.\n[Preview this image in Google Books.]\n\nCariani (1999)\nNeural Plasticity\nFriday, March 13, 2009\n\nFriday, March 13, 2009\n\nFriday, March 13, 2009\n\nAuditory central pathways: road map\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nFigure 1 in Irvine, D. R. F. The Auditory Brainstem. New York, NY: Springer, 1986. ISBN: 9783540162995.\n\nBrainstem stations involved in localization of sounds\nFriday, March 13, 2009 Pair of diagrams depicting brainstem stations involved in localizing sounds, with callout detailing the lateral superior olive neurons.\nFigure by MIT OpenCourseWare.Pair of diagrams depicting brainstem stations involved in localizing sounds, with callout detailing the lateral superior olive neurons.\n\nAuditory midbrain: inferior colliculus\nFriday, March 13, 2009\nCopyright (c) 1984, Wiley-Liss, Inc., a subsidiary of John Wiley & Sons, Inc. Reprinted with permission of John Wiley & Sons., Inc.\nSources: Fig. 3 in Morest, D. K., and D. L. Oliver. \"The Neuronal Architecture of the Inferior Colliculus in the Cat: Defining the Functional\nAnatomy of the Auditory Midbrain.\" J Comp Neurol 222, no. 2 (1984): 209-236.\nFig 23 in Oliver, D. L., and D. K. Morest. \"The Central Nucleus of the Inferior Colliculus in the Cat.\" J Comp Neurol 222, no. 2 (1984): 237-264.\n\nNarrowly-tuned\nunits in ICC (high BF)\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nSee Fig. 4.8 in Ehret, G. \"The Auditory Midbrain...\" in\nThe Central Auditory System. Edited by G. Ehret and R. Romand.\nNew York, NY: Oxford University Press, 1997.\n[Preview this image in Google Books.]\n\nAuditory midbrain: periodotopy?\nFriday, March 13, 2009 Two graphs - 3C and 2D - of isofrequency planes of the inferior colliulus of a cat.\nFigure by MIT OpenCourseWare.\n\nModulation detectors in the midbrain\nProblems:\n1) MTF tuning degrades\nat high SPLs & in noise\n2) Wrong operation.\nModulation tuning\ndoes not account for\npitches of resolved\nharmonics of\ninharmonic tones\n(pitch-shift exps)\n3) Representation will\ndegrade when multiple\nF0s are present (doesn't\nsupport scene analysis)\n4) Does not explain pitch\nequivalence of pure &\ncomplex tones\n5) Structural. Could be\nSources for auditory CNS figures: Gunter Ehret (1997) The auditory midbrain, a\n\"shunting yard\" of acoustical information processing. In: The Central Auditory\nSystem, Ehret, G. & Romand, R., eds. Oxford University Pres. Langner, G. and\nSchreiner, C.E. Periodicity coding in the inferior colliculus of the cat. I. Neuronal\nmechanisms. J. Neurophysiol. 60:1799-1822. See also Langner (1992) review,\nPeriodicity coding in the auditory system. Hearing Research, 60:115-142.\ndue to ratio of excitation-\ninhibition rather than for\nspecific function\nFriday, March 13, 2009\nImages removed due to copyright restrictions.\nSee Fig. 3 in Langner, G. and Schreiner, C.E.\n\"Periodicity coding in the inferior colliculus of the cat. I. Neuronal mechanisms.\"\nJ. Neurophysiol. 60 (1988): 1799-1822.\n\nStimulus-related temporal discharge patterns in IC (PTs to ~4 kHz, F0s to 1200 Hz)\nFriday, March 13, 2009\nImages removed due to copyright restrictions.\nSee Fig. 2 in Langner, G. and Schreiner, C.E.\n\"Periodicity coding in the inferior colliculus of the cat. I. Neuronal mechanisms.\"\nJ. Neurophysiol. 60 (1988): 1799-1822.\n\nCoding of pitch in the inferior colliculus\nAM broadband noise, Fm = 160 Hz, 1000 contralateral monotic presentations @ 80 dB SPL\nPeristimulus time (ms)\nInterval (ms)\nPeriod time (ms)\nPST histogram, all-order interval histogram, and period histogram (6.25 ms analysis\nperiod). Total number of spikes: 4421. Note the longer (~40 ms) preferred intervals for this\nunit and the pitch-related spacings (6.25 ms) between the individual interval peaks.\nClick train, F0 = 160 Hz, 500 contralateral monotic presentations @ 80 dB SPL\nPeristimulus time (ms)\nPeristimulus time (ms)\nInterval (ms)\nPeriod time (ms)\nTotal number of spikes: 418. Patterns of longer intervals are pitch-related.\nFriday, March 13, 2009\n\nUpper limits of temporal pattern information (rough estimate)\nCochlear hair cells: no limit, but weakening AC component\nAuditory nerve: < 4-5 kHz abundant & highly significant;\nstatistical significance depends on #spikes ( > 5 kHz)\nCochlear nucleus: depending\nMidbrain: 4-5 kHz in inputs (frequency-following response)\nInterval information: 1/F0 up to ~1200 Hz\nThalamus: 10% of units lock to 2-3 kHz with SI > 0.3\n\n(deRibaupierre, lightly anesthetized preps)\nPrimary cortex: 200 Hz averaged gross surface potentials\n\n(unanesthetized, 100 Hz anesthetized; Goldstein\n&\nKiang, 1959);\n300 Hz averaged gross potentials (CSD, input layers,\nSteinschneider et al); anecdotal reports of locking\nto 1 kHz in single units, but these are very rare\nRule-of-thumb: anesthesia decreases fmax by factor of 2\nFriday, March 13, 2009\n\nAuditory thalamus: medial geniculate body\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nSee Figure 1 in Morest, D. K. \"The Neuronal Architecture of the Medial Geniculate Body of the Cat.\"\nJ Anat 98 (October 1964): 611-30. Available online at http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1261345/.\n\nGyri: hills\nSulci: valleys\nAuditory cortex is\nlocated in the\nSuperior\nTemporal\nFriday, March 13, 2009 Cross section of human brain, showing locations of various gyri.\nFigure by MIT OpenCourseWare.Cross section of human brain, showing locations of various gyri.\n\nLaminated \"cortical\" structures Diagram of laminated structures of sensory, association and motor cortex.\nRamon y Cajal\nFriday, March 13, 2009\nFigure by MIT OpenCourseWare, after Sutherland / Woodburne (1967).Diagram of laminated structures of sensory, association and motor cortex.\n\nPrimary and secondary auditory cortex regions\nFriday, March 13, 2009 Diagram showing two views of the location of primary and secondary auditory cortex.\nFigure by MIT OpenCourseWare.Diagram of laminated structures of sensory, association and motor cortex.\n\nCochleotopic organization of auditory cortex (cartoon)\nTwo concepts best kept separate in one's mind:\n[Purves et al])\nFriday, March 13, 2009 Diagram showing cochleotopic organization of auditory cortex, with different regions corresponding to different auditory frequencies.\nFigure by MIT OpenCourseWare.Diagram showing cochleotopic organization of auditory cortex, with different regions corresponding to different auditory frequencies.\n\nImages: Publ\nAuditory cortex: cat\nic domain\nFriday, March 13, 2009\n\nAuditory central pathways:\nFriday, March 13, 2009\nFig. 1.11 (p. 38) in De Ribaupierre, F. \"Acoustical Information Processing in the Auditory Thalamus and Cerebral Cortex.\"\nIn The Central Auditory System. Edited by G. Ehret and R. Romand. New York, NY: Oxford University Press, 1997.\n[Preview this image in Google Books]\n\nAuditory central pathways: cortico-thalamic connections\nFriday, March 13, 2009\nFig. 1.12 (p. 39) in De Ribaupierre, F. \"Acoustical Information Processing in the Auditory Thalamus and Cerebral Cortex.\"\nIn The Central Auditory System. Edited by G. Ehret and R. Romand. New York, NY: Oxford University Press, 1997.\n[Preview this image in Google Books]\n\nAuditory cortex: responses to high frequency pure tones\nFriday, March 13, 2009\nFigures removed due to copyright restrictions.\nFig. 2, 3, 4 and 9 in Phillips, D. P., et al. \"Level-dependent Representation of Stimulus Frequency in Cat\nPrimary Auditory Cortex.\" Exp Brain Res 102 (1994): 210-226. DOI: 10.1007/BF00227510.\n\nPitch-related temporal\npatterns in field potentials\nin awake monkey cortex\nFigure. Averaged cor\ntical field potentials\n(current source densi\nty analysis, lower lami\nna 3, site BF=5 kHz)\nin response to 50\nms\nclick trains\nF0=100\n500 Hz. Ripples up to\n300-400 Hz show syn\nchronized component\nof the ensemble-\nresponse, From\nSteinschneider (1999).\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nSee Fig. 9 right, in Steinschneider, M., et al. \"Click Train Encoding\nin Primary Auditory Cortex of the Awake Monkey: Evidence for Two\nMechanisms Subserving Pitch Perception.\" J Acoust Soc Am 104,\nno. 5 (1998): 2935-2955. DOI: 10.1121/1.423877.\n\nPure tone temporal response profiles in auditory cortex (A1)\nFriday, March 13, 2009\nCourtesy of Prof. Mark J. Tramo, M.D., Ph.D. Used with permission.\nSource: Tramo, Mark J. \"Neural Representations of Acoustic Information in Relation to Voice Perception.\" Havard University PhD Thesis, 1999.\n\nWhere everything takes place:\nfrom cochlea to cortex, and beyond Schematic of afferent auditory pathways, from the cochlea to the auditory cortex.\n10,000k\n500k\n30k\n3k\nPrimary\nauditory cortex\n(Auditory forebrain)\nAuditory thalamus\nInferior colliculus\n(Auditory midbrain)\nLateral lemniscus\nAuditory brainstem\nAuditory nerve (VIII)\nCochlea\nFriday, March 13, 2009\nFigure by MIT OpenCourseWare.\n\nTonotopy, cochleotopy & frequency maps: Common pitfalls\nOrderly spatial arrangements of frequency-tuned neurons\n(\"auditory frequency maps\") exist at every auditory station.\nHowever, these maps are coarse relative to perceptual\ndiscriminations, especially for low frequencies (< 2 kHz) and for\nmoderate to high sound levels (> 60 dB SPL).\nI have yet to see evidence in the literature for neuronal tuning\nfiner than about 1/2 octave for low frequency tones at high\nlevels (barely good enough to resolve the 2nd harmonic).\nIn auditory cortex the ordering of frequency tunings is only seen\nat very low sound levels -- tonotopy breaks down at moderate\nto high levels (> 60 dB SPL).\nFriday, March 13, 2009\n\nTonotopy: seen at all auditory stations\n- Simple tonotopic order only seen at levels near neural thresholds;\nthis order breaks down at mod-high levels\n- At every auditory station, tuning of most units broadens at higher\nintensities (especially for tones < 1 KHz; exceptions to this rule usually\ninvolve high-BF units)\n- Q values (BW/BF) increase with BF; however frequency\ndiscrimination declines with BF\n- Does not solve the problem of pitch of complex tones\n- Additional mechanisms are needed\n- Tonotopy likely reflects mappings of most direct connections to\nsensory surfaces rather than carrying the information for\nfrequency coding per se\nFriday, March 13, 2009\n\nPhillips et al 1994\nFriday, March 13, 2009\nFigure removed due to copyright restrictions.\nFig. 9 in Phillips, D. P., et al. \"Level-dependent Representation of Stimulus Frequency in Cat Primary Auditory Cortex.\"\nExp Brain Res 102 (1994): 210-226. DOI: 10.1007/BF00227510.\n\nNarrowly-tuned\nunits in auditory\ncortex (high BF)\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nSet of six graphs (latency, intensity and spike count vs. tone frequency) from Phillips, 1989.\n\nFriday, March 13, 2009\n\nFriday, March 13, 2009\nCourtesy of Prof. Mark J. Tramo, M.D., Ph.D. Used with permission.\nSource: Tramo, Mark J. \"Neural Representations of Acoustic Information in Relation to Voice Perception.\" Havard University PhD Thesis, 1999.\n\nRATE MAPS\n971211.4S\n960405.2M\n70 dB\n960807.9M\n90 dB\n960405.3M\n960621.4S\nTemporal response profiles\nA\n80 dB\n70 dB\nC\n70 dB\n960621.3S\n971202.6M\n70 dB\n980218.1M\n980218.5M\n971124.7M\n971203.2S\n80 dB\n100 dB\n80 dB\n80 dB\nB\n960402.4S\n960411.2S\n80 dB\n90 dB\n70 dB\n971124.1M\n90 dB\n70 dB\n960328.4S\n960405.6S\n80 dB\n50 dB\n971203.3S\n80 dB\n960405.7M\n960411.1M\n70 dB\n980216.4M\n971211.1S\n90 dB\n80 dB\nFriday, March 13, 2009\nPost-Stimulus Time (ms)\nCourtesy of Prof. Mark J. Tramo, M.D., Ph.D. Used with permission.\nSource: Tramo, Mark J. \"Neural Representations of Acoustic\nInformation in Relation to Voice Perception.\" Havard University\nPhD Thesis, 1999.\n\nRate-frequency\nprofiles for\n15 cortical ON units\ntest\nprofile\nF2\nF1\nprofile\nprofile\nDecision analysis\nFriday, March 13, 2009\n\nSchwarz & Tomlinson 1990\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nSee Fig. 7 in Schwarz, D. W., and R. W. Tomlinson.\n\"Spectral response patterns of auditory cortex neurons to harmonic complex tones\nin alert monkey (Macaca mulatta).\" J Neurophysiol 64, no. 1 (1990): 282-298.\n\n- The results of lesion studies motivated by interest in\nmusic and the brain have led to major revisions in\nfundamental hypotheses about the functional role of\nprimary auditory cortex (A1) in frequency processing\nand pure-tone pitch perception\n- The results of single- and multi-unit neuron recordings\nin A1 raise questions about the functional relevance of\ntonotopy and \"sharp-tuning\" to pitch perception\nFriday, March 13, 2009\n\nBendor & Wang(2005) F0-tuned units in auditory cortex\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nSee Fig. 1 in Bendor and Wang, \"The neuronal representation of pitch in primate auditory cortex.\"\nNature 436 (2005): 1161-1165.\n\nBendor & Wang (2005)\nF0-tuned neurons:\nfirst evidence of \"true\" F0\n\nsensitive neurons\ncoarsely tuned (1 octave)\nnot clear what the SPLs are\nnonmonotonic responders\nHigh degree of level dependence\nbegs the question of how\na rate-based representation\nusing these units can account\nfor level-invariance of the\npitch percept (same problem\nas Phillips et al, 1994)\nFriday, March 13, 2009\nCourtesy of Daniel Bendor. Used with permission.\nSource: Bendor, D. and X. Wang, \"The Neuronal Representation of Pitch in Primate Auditory Cortex.\"\nNature 436 (2005): 1161-1165.\nImage removed due to copyright restrictions. See Fig. 3 in Bendor, D. and\nX. Wang, \"The neuronal representation of pitch in primate auditory cortex.\"\nNature 436 (2005): 1161-1165.\n\nSome of the difficulties: rate-place profiles\n- Saturation of firing rates at higher levels ( > 80 dB SPL)\n- Units are generally coarsely tuned (ctx neural bandwidths 0.5-2 oct)\n- Disconnect between freq. discrim. and neural Q values\n- (Reccanzone, however correlation with cortical territory/# neurons)\n- High response variability; low firing rates\n- May be difficult to account for jnd's < 1%, esp. at higher levels (Siebert's\nclassical analysis was carried at lower SPLs)\n- No mechanisms for complex tones are evident\n- Components spaced < 300 Hz apart not resolved in either cat auditory\nnerve or macaque auditory ctx (Steinschneider)\n- No low-BF harmonic combination units seen\nFriday, March 13, 2009\n\nHow do higher auditory stations\nrepresent and process sounds?\n- What is the fate of neural timing information?\n- How does the auditory CNS make use of it?\n- Where do representations responsible for fine\npitch distinctions reside?\nWhat are the central neural codes & computations?\nFriday, March 13, 2009\n\nTramo, Mark Jude BIOLOGY AND\nMUSIC:\nEnhanced: Music of the Hemispheres\nScience 2001 291: 54-56\nMusic & Cortex\nFriday, March 13, 2009 Figure illustrating regions of the brain that may be involved in music perception and performance.\nFigure by MIT OpenCourseWare. After Tramo, M. Science 291, no. 5501 (2001): 54-56.\n\nFunctional organization of the perceptual side\nEvaluation in terms\nof manifold implications\nEvaluation in terms\n(associations, plans\nself-\nof basic system-goals\nsustaining\n(limbic system)\ncognitive schemas)\npatterns\nreceptor surfaces\nBuildup of\nsensory\nimages\nSensory\ntransduction\nStructure of\nenvironmental\nevents\nAttentional\nfacilitation\nof image\nformation\nAttentional\nfacilitation\nof image\nformation\nEarly\nsensory\ncodng\nFriday, March 13, 2009\n\nFriday, March 13, 2009\nTwo figures removed due to copyright restrictions.\nFig 2.8, input projections to the cochlear nucleus; and Fig 7.8, pathways from auditory cortex to cochlea.\nIn The Central Auditory System. Edited by G. Ehret and R. Romand. New York, NY: Oxford University Press, 1997.\n\nSome generalities about the auditory system\n- Rough cochleotopy is found at all levels, but not\n\nnecessarily in all neural populations\n- Highly ordered tonotopic maps exist only at low tone levels, near\nneural thresholds\n- As one ascends the afferent pathway:\n- Numbers of neurons at each level increases\n- Fine timing information exists in great superabundance in lower\nstations, but becomes successively sparser\n- Firing rates (spontaneous & driven) decline\n- Inhibition increases; % nonmontonic rate-level fns incr.\n- Diversity and complexity of response increases\n- History-dependence and contextual effects increase\n- Some modulation tuning that suc. declines in periodicity\nTypical BMFs: AN: 200-300 Hz; IC: 50-100 Hz; Ctx (< 16 Hz)\n- No clear \"pitch detectors\" (Schwarz & Tomlinson, 1991)\n- No narrow (BW < 0.3 octaves) \"frequency channels\" for BFs < 2 kHz\nFriday, March 13, 2009\n\nBasic problems to be solved\n- \"Hyperacuity problem\"\n- Account for the precision of pitch discriminations given the relatively coarse tunings of\nauditory neurons (at all levels), especially lower-frequency ones (BFs < 2 kHz)\n- \"Dynamic range problem\"\n- Account for the ability of listeners to discriminate small fractional changes (I/I) in intensity\nover a large dynamic range, and especially at high SPLs, where the vast majority of firing\nrates are saturated.\n- \"Level-invariance problem\"\n- Account for the invariance (and precision) of auditory percepts over large dynamic ranges\ngiven the profound changes in neural response patterns that occur over those ranges (rate\nsaturation, rate non-montonicities).\n-Pitch equivalence\n-Account for the ability to precisely match pitches of pure and complex tones (pitch\nequivalence, metamery) given differences in spectra and under conditions where stimulus\nintensities are roved 20 dB or more\n-Relative nature of pitch & transpositional invariance\n-Account for the ability to precisely match pitches an octave apart (and/or to recognize\npatterns of pitch sequences) in the absence of an ability to identify absolute frequencies/\nperiodicities. Account for ability to recognize transposed melodies as similar.\nFriday, March 13, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Neural representation of musical pitch",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/39eec90527b485a5ca3f83803bc0ba4d_MITHST_725S09_lec04_pitch.pdf",
      "content": "Neural representation\nof musical pitch The letters PITCH are drawn in a block shadow style where upper and left edges of the characters are not shown, but implied by the shadows.\nwww.cariani.com\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nPitch: the basis of musical tonality\n- Operational definition of pitch\n- Pitch of pure tones\n- Pitch of harmonic complexes at the fundamental\n- Pitch of the missing fundamental\n- Pitch of unresolved harmonics\n- Repetition pitch\n- Pitch salience\n- Relative vs. absolute pitch\n- Pitch circularity\n- Pitch: how many dimensions do we need?\n- Models of pitch: Place vs. temporal theories\n- Envelope vs. fine structure (Schouten & de Boer)\n- Residue theories (incomplete filtering of unresolved harmonics)\n- Temporal autocorrelation theories (Licklider)\n- Analytical (Helmholtz) vs. Gestalt (Stumpf) perspectives\n- Spectral pattern analysis/completion vs. dominant periodicity\nWednesday, February 11, 2009\n\nDimensions of auditory objects\nDimensions of event perception\nAuditory qualities and their organization\nUnitary events & their organization\nObjects: Quasi-stationary\nEvents: abrupt perceptual\nassemblages of qualities\ndiscontinuities\nTimbre\nLoudness\nLocation\nSpatial Dimensions\nPitch\nTEMPORAL\nEVENT\nSTRUCTURE\nTiming & order\n(metric, sequence)\nDuration\nFUSION/SEPARATION\nFUSION/SEPARATION\nCommon onset & harmonic structure => fusion\nCommon onset, offset => fusion\nDifferent F0s, locations, onset => separation\nDiff. meters, pitch, timbre => separation\nPOLYPHONY\nSTREAMS, POLYRHYTHMS\nWednesday, February 11, 2009\n\nA few words about Loudness\n- Loudness is the perceptual attribute that covaries with the intensity\nof sounds (loudness is the subjective attribute, intensity is the\nphysical, acoustical property)\n- We mentioned that the auditory system has a huge dynamic range,\nover a factor of 100,000 between the sound pressure level of the\nsoftest and the loudest sounds.\n- Loudness is important in music for several reasons\n- Listening level (louder music is more salient, captures attention)\n- Onsets and accents (loudness contrast accents notes)\n- Dynamics (changes in loudness communicate tension, relaxation)\n- Safety issues (listening to music at high levels (>100 dB SPL) for\nprolonged periods of time will damage your ears and impair your\nability to hear music\nWednesday, February 11, 2009\n\nTypical sound levels in music\nOn origins of music dynamics notation\nhttp://www.wikipedia.org/wiki/Pianissimo\nText removed due to copyright\nrestrictions. See the Wikipedia\narticle.\n-\nPain\n\n> 130 dB SPL\n-\nLoud rock concert 120 dB SPL\n-\nLoud disco\n\n110 dB SPL\n-\nfff\n\n100 dB\nSPL\n-\nf\n(forte, strong)\n80 dB\nSPL\n-\np\n(piano, soft)\n60 dB\nSPL\n-\nppp\n\n40 dB SPL\n-\nLower limit\n-\nTheshold of hearing 0 dB SPL\nTuesday, February 10, 2009\n\nTypical sound pressure levels in everyday life\nDisco\nCourtsey of WorkSafe, Department of Consumer and Employment Protection, Western Australia (http://www.safetyline.wa.gov.au).\nhttp://www.safetyline.wa.gov.au/institute/level2/course18/lecture54/l54_03.asp\nWednesday, February 11, 2009\n\nD\nia\ngr ams\no\nf\nt he a\ndd\nit\ni ve r\nesul\nt of\n(si\nne w\nave)\nfun\ndame\nntal\npl\nus\ns\necond thorugh fifth ha\nrm\non\nics.\nSound level meters and frequency weightings\nA: based on human equal loudness contours @ ~40 dB SL\nFletcher-Munson curves (recently revised)\nC: flat-weighting\nGraph by MIT OpenCourseWare. SPL meter photo courtesy of EpicFireworks on Flickr.\nWednesday, February 11, 2009\n\nDynamic range of some musical instruments\nImages removed due to copyright restrictions.\nGraphs of relative intensity vs. pitch for different instruments: violin,\ndouble bass, flute, B-flat clarinet, trumpet, french horn.\nFigure 8.5 in Pierce, J. R. The Science of Musical Sound. Revised ed. New York,\nNY: W.H. Freeman & Co., 1992. ISBN: 9780716760054.\nNoise floor: ~ 45 dB SPL\nConversation: 60 dB SPL\nSymphony: 80-90 dB SPL\nDisco: 100 dB SPL\nWednesday, February 11, 2009\n\nHearing loss with age (overexposure to loud sounds\n\naccelerates this process) Graph of progressive loss of high frequency sensistivity with increasing age, normalized to a 20 year old.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nSteps to prevent hearing damage\nUse earplugs (reduce levels by 20-30 dB)\nPhoto courtesy of KarenD on Flickr.\nTake measures in recurring situations where you experience\nringing in your ears (concerts, discos)\nImpulsive loud sounds are worst (gunshots, hammering)\nBe wary of cranking up the level in cars, especially when the\nwindows are down (if it sounds terribly loud when youre\nstopped at a light, this should tell you something)\nWith personal sound players (MP3s, iPods, walkman),\nalways set the listening level in quiet\ndont crank up the level in noisy situations\nuse the volume limiter feature (set this in quiet)\nif you listen in noisy situations (mowing the lawn), then by all\nmeans use noise-cancellation headphones\nWednesday, February 11, 2009\n\nPitch in music\n- Tonal music is based in large part on pitch\nrelations\n- Sequences of pitches constitute melodies\n- Relations between combinations of pitches\nconstitute harmonies\n- Sets of pitches make up musical scales, which\nare the perceptual atoms of musical tonality\n- Musical pitch is relative pitch (transpositional\ninvariance)\n- We will discuss absolute pitch later in the course\nWednesday, February 11, 2009\n\nOperational definition of \"pitch\"\n- Pitch is that auditory quality that varies with the periodicity and/or\nfrequency of sounds.\n- (i.e. not loudness, duration, location, or timbre)\n- Operationally, pitch is defined as the frequency of a pure tone to\nwhich a sound is matched.\n- Since pure tone pitch changes very slightly (0-4%) with large changes\nin sound pressure level (40 dB), the level of the reference tone also\nhas to be specified.\n- For musical sounds (complex tones), this much celebrated\ndependence of pitch on level is quite minimal (< 1% over 40 dB). The\nmore harmonics, the smaller the effect.\nWednesday, February 11, 2009\n\nPitch metamery\n(perceptual\nequivalence)\nSounds with different\nfrequency spectra can\nproduce the same pitch Schematic representation of eight signals with the same low fundamental pitch but different sets of harmonics.\nFigure by MIT OpenCourseWare.\nWednesday, February 11, 2009\n\nRange of pitches of pure & complex tones\n- Pure tone pitches\n- Range of hearing (30-20,000 Hz)\n- Range in tonal music (100-4000 Hz)\n- Pitches of individual partials in a complex, \"analytical\" pitch\n- Most (tonal) musical instruments produce harmonic\ncomplexes that evoke pitches at their fundamentals\n(F0s)\n- Called virtual pitch, periodicity pitch, low pitch\n- Range of F0s in tonal music (30-4000 Hz)\n- Range of missing fundamental (30-1200 Hz)\nWednesday, February 11, 2009\n\nMusic spectrograms\nPitch is not simply frequency\nMusic pitches are not pure tones -\nThey are mostly harmonic complex tones\nThe pitch that is heard for a harmonic complex tone\ncorresponds to the fundamental frequency of\nthe tone (with very few exceptions)\nWednesday, February 11, 2009\n\n\"Virtual\" pitch: F0-pitch as pattern completion The letters PITCH are drawn in a block shadow style where upper and left edges of the characters are not shown, but implied by the shadows.\nFigure by MIT OpenCourseWare.\n\"Missing fundamental\" analogy to illusory contour\nWednesday, February 11, 2009\n\nFundamentals and harmonics\n-\nPeriodic sounds (30-20kHz)\nproduce pitch sensations.\n-\nPeriodic sounds consist of\nrepeating time patterns.\n-\nThe fundamental period (F0) is the\nduration of the repeated pattern.\n-\nThe fundamental frequency is the\nrepetition frequency of the pattern.\n-\nIn the Fourier domain, the\nfrequency components of a\nperiodic sound are all members of\na harmonic series (n = 1*F0, 2*F0,\n3*F0...).\n-\nThe fundamental frequency is\ntherefore the greatest common\ndivisor of all of the component\nfrequencies.\n-\nThe fundamental is also therefore\na subharmonic of all component\nfrequencies. Diagrams of the additive result of (sine wave) fundamental plus second thorugh fifth harmonics.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nEmergent pitch\nMissing\nLine spectra\nAutocorrelation (positive part)\nF0\nPure tone\n200 Hz\nWednesday, February 11, 2009\n\nHarmonic series\nA harmonic series conists of integer multiples of a fundamental frequency,\ne.g. if the fundamental is 100 Hz, then the harmonic series is: 100, 200,\n300, 400, 500, 600 Hz, .... etc.\nThe 100 Hz fundamental is the first harmonic, 200 Hz is the second\nharmonic. The fundamental is often denoted by F0.\nThe fundamental frequency is therefore the greatest common divisor of all\nthe frequencies of the partials.\nHarmonics above the fundamental constitute the overtone series.\nSubharmonics are integer divisions of the fundamental:\ne.g. for F0= 100 Hz, subharmonics are at 50, 33, 25, 20, 16.6 Hz etc.\nSubharmonics are also called\nundertones.\nThe fundamental period is 1/F0, e.g. for F0=100 Hz, it is 1/100 sec or 10\nWednesday, February 11, 2009\n\nAuditory system:\nFrequency analyzer vs. Periodicity analyzer\nConceptual models of resonance:\nHelmholz resonator\nband-pass filter -- one frequency\nfrequency decomposition\nsimple oscillator models Four diagrams of a vibrating stretched string at the first four complete harmonic frequencies f, 2f, 3f and 4f.\nString\nmany harmonics\ncomb filter\nFigure by MIT OpenCourseWare.\nComplex oscillator - delay loop\nmatched filter, complex pattern generator Schematic representation of a delay loop matched filter.\nFigure by MIT OpenCourseWare.\nWednesday, February 11, 2009\n\nHelmholtz resonator\nhttp://www.phys.unsw.edu.au/jw/Helmholtz.html\nCourtesy of Joe Wolfe. Used with permission.\nhttp://www.phys.unsw.edu.au/music\n\nCourtesy of Joe Wolfe. Used with permissions.\nhttp://www.phys.unsw.edu.au/music\nWednesday, February 11, 2009\n\nSirens\nA simple siren is produced by forcing compressed air\nthrough equally spaced holes on a rotating disk. This\nproduces a periodic vibration whose frequency equals\nDe la Tour's siren\nthe rate of holes passing by the air nozzle.\nWednesday, February 11, 2009\n\nEarly sound analysis of vowels\nIn this 19th century apparatus developed by Koenig, waveforms were visualized by viewing a flame reflected on a rotating\nmirrored drum. Vowel sounds resulted in the same flame pattern regardless of their pitch level.\nWednesday, February 11, 2009\n\nStimulus\narray of cochlear band-pass filters\nauditory\nnerve fiber\ndB\nFrequency (kHz)\nF0= 80 Hz\ntuning curves\ndischarge rates\ninterspike intervals\nPower spectrum\nrepresentation\nFrequency domain\nPopulation rate-\nplace profile\nfrequency\noptimal\n(linear scale)\nmatch\nF0 = 200 Hz\nF0 = 160 Hz\nF0 = 100 Hz\nharmonic templates\nAutocorrelation\nrepresentation\nTime domain\nPopulation\ninterspike interval\ndistribution\n1/F0\n1/F1\nInterval (ms)\n# intervals\nPitch  best fitting template\nWednesday, February 11, 2009\n\nCorrelograms\nWednesday, February 11, 2009\nImages removed due to copyright restrictions.\nSee Figures 6.16A-D and 6.17 in Lyon, R. and S. Shamma. \"Auditory Representations of Timbre and Pitch.\"\nIn Auditory Computation. Edited by R. R. Fay. New York, NY: Springer, 1996.\n\nLicklider virtual pitch masking demonstration (iTunes/Spectrograph)\nWednesday, February 11, 2009\n\nPeriodic sounds\nproduce distinct\npitches\nStrong\npitches\nMany different\nsounds produce\nthe same pitches\nStrong\n- Pure tones\n- Harmonic complexes\n- Iterated noise\nWeaker\n- High harmonics\n- Narrowband noise\nWeaker\nlow\nVery weak\npitches\n- AM noise\n- Repeated noise Schematic representation of eight signals with the same low fundamental pitch but different sets of harmonics.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nAs harmonic numbers increase, the missing\nfundamental gets weaker.\nWednesday, February 11, 2009\n\n- Highly precise percepts\nPitch basics\n- Musical half step: 6% change F0\n- Minimum JND's: 0.2% at 1 kHz (20 usec time difference, comparable to ITD jnd)\n- Highly robust percepts\n- Robust quality Salience is maintained at high stimulus intensities\n- Level invariant (pitch shifts < few % over 40 dB range)\n- Phase invariant (largely independent of phase spectrum, f < 2 kHz)\n- Strong perceptual equivalence classes\n- Octave similarities are universally shared\n- Musical tonality (octaves, intervals, melodies) 30 Hz - 4 kHz\n- Perceptual organization (\"scene analysis\")\n- Fusion: Common F0 is a powerful factor for grouping of frequency components\n- Two mechanisms? Temporal (interval-based) & place (rate-based)\n- Temporal: predominates for periodicities < 4 kH (level-independent, tonal)\n- Place: predominates for frequencies > 4 kHz(level-dependent, atonal)\nWednesday, February 11, 2009\n\nPure tone pitch discrimination\nbecomes markedly worse\nabove 2 kHz\nWeber fractions for\nfrequency (f/f) increase\n1-2 orders of magnitude\nbetween 2 kHz and 10 kHz Graph of Weber fraction vs. freqency for human data.\nFigure by MIT OpenCourseWare.\n\nWednesday, February 11, 2009\nJND's\nFigure by MIT OpenCourseWare.Three graphs describing optimal performance for pure-tone frequency discrimination.\n\nPure tone\npitch\ndiscrimination\nimproves\nat longer\ntone\ndurations\nand\nat\nhigher\nsound\npressure\nlevels\nWednesday, February 11, 2009 Graphs of delta-f vs. duration (ms) and level (dB SPL) for human data.Graphs of delta-f vs. duration (ms) and level (dB SPL) for human data.\nFigure by MIT OpenCourseWare.\n\n\"Pitchedness\" as a function of sound duration\nWednesday, February 11, 2009\nGraph removed due to copyright restrictions.\nFigure 36, comparing \"Tone pitch\" and \"click pitch\" response. In Licklider, J. C. R. \"Basic Correlates of the\nAuditory Stimulus.\" Handbook of experimental psychology. Edited by S. S. Stevens. Oxford, UK: Wiley,\n1951. pp. 985-1039.\n\n8k\nFrequency ranges of (tonal) musical instruments\n> 6 kHz\n2.5-4 kHz\n27 Hz\n4 kHz\nHz\nHz\nHz\nHz\nWednesday, February 11, 2009\n\nThe neural coding problem in audition:\nHow does the brain represent and\nprocess acoustic patterns, such that we\nhear what we hear?\nIn particular, how does it represent\nperiodic sounds, such that we hear\npitches at the fundamentals of musical\nsounds?\nWednesday, February 11, 2009\n\nWhere everything takes place:\nfrom cochlea to cortex, and beyond\n10,000k\n500k\n30k\n3k\nPrimary\nauditory cortex\n(Auditory forebrain)\nAuditory thalamus\nInferior colliculus\n(Auditory midbrain)\nLateral lemniscus\nAuditory brainstem\nAuditory nerve (VIII)\nCochlea\nWednesday, February 11, 2009 Schematic of afferent auditory pathways, from the cochlea to the auditory cortex.\nFigure by MIT OpenCourseWare.\n\nHardware\nComputations\nDecisions\nNeural\narchitectures\nNeural codes\nFunctions\nInformation-processing\noperations\nSensory\nencodings\nMotor\ncommands\nExternal\nworld\nReceptors\nEffectors\nReverse-\nengineering\nthe brain\nSignals\nWednesday, February 11, 2009\n\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.Schematic of afferent auditory pathways, from the cochlea to the auditory cortex.\n\nEar and cochlea Schematic of how traveling waves move through the cochlea, with the frequency of peak amplitude (\"tuning\") decreasing the further the wave moves through the cochlea.\nFigure by MIT OpenCourseWare.\nWednesday, February 11, 2009\nSchematic of how\ntraveling waves move\nthrough the c\nochlea, with th\ne frequency of p\neak amplitude (\"tu\nning\") decrea\nsing the further t\nhe wave moves\nthrough th\ne cochlea.\n\n~30,000 fibers (humans)\nWednesday, February 11, 2009\n\nNeural frequency tuning\nPLACE PRINCIPLE\nDisconnect between cochlear tuning\n& pitch discrimination for freqs < 4 khz\nCF = characteristic frequency Graph for nerve responses for various frequencies.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nTemporal coding in the auditory nerve\nCat, 100x @ 60 dB SPL\nCharacteristic freq. (kHz)\nPeristimulus time (ms)\nWednesday, February 11, 2009\n\nPeristimulus time (m\nTime domain analysis of auditory-nerve fiber firing rates.\nHugh Secker-Walker & Campbell Searle, J. Acoust. Soc. 88(3), 1990\nNeural responses to /da/ @ 69 dB SPL from Miller and Sachs (1983)\nHigh CFs\nLow CFs\nF1\nF2\nF3\nPeristimulus time (ms)\nWednesday, February 11, 2009\nReprinted with permission, from Secker-Walker HE, Searle CL. 1990. \"Time-domain Analysis of Auditory-nerve-fiber Firing Rates.\" J Acoust Soc Am 88 (3):\n1427-36. Copyright 1990, Acoustical Society of America.\n\nPhase-locking in auditory nerve fibers\n250 Hz tone Plot of nerve fiber signals, showing triggering at the same frequency as the sine wave stimulus.\nSee Javel E, McGee JA, Horst W, Farley GR, \"Temporal mechanisms in auditory stimulus coding.\"\nIn: G. M. Edelman, W. E. Gall and W. M. Cowan, ed, Auditory Function: Neurobiological\nBases of Hearing, Wiley: New York 1988; p. 518.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nA\nD\nAuditory\nFirst order\nnerve fiber\nB 100\nE 25\nintervals\nresponses\nto a periodic\nsound\nC\nF 30\nAll order\nH 100\nJ 14\nFirst order\nintervals\nI\nK 20\nAll order\nintervals\nPeristimulus time (ms)\nInterspike interval (ms)\nWednesday, February 11, 2009\n\nGraphics describing how interspike intervals in the auditory nerve encode stimulus periodicities.\n!\"#$%&'()$*(\"#$%+,-&*(\"*#.$*,/0(#1%2*\"$%+$*$\"310$*&45/-/&*'$%(10(3(4$&*\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nGlobal temporal pitch representation (Collaborator B. Delgutte)\nPitch (frequency) =\nthe predominant interval\nor interval pattern\nPitch strength (salience) =\nthe relative fraction of\npitch-related intervals in\nthe whole distribution\nDetectability: A pitch can be\nheard iff its salience\n-All-order interspike intervals\n-Population-wide distribution:\n-All auditory nerve fibers\n-(all CFs, all SRs)\nPredictions\nWednesday, February 11, 2009\n\nStimulus waveform\n1/F0\nStimulus Autocorrelation\nPitch =1/F0\nConstruction of the\npopulation-interval\ndistribution\nPost-stimulus time histograms\nAll-order interval histograms\nof the auditory nerve\n(Cariani & Delgutte,\nJ. Neurophysiol.\n1996)\nCharacteristic frequency (kHz)\n.5\n.2\nPopulation-PST histogram\nPopulation-interval histogram\n1/F0\n# spikes\n# intervals\nPeristimulus time (ms)\nInterval (ms)\nWednesday, February 11, 2009\n\nSource: Cariani, P. A., and B. Delgutte.\n\"Neural Correlates of the Pitch of Complex\nTones. I. Pitch and Pitch Salience.\"\nJ Neurophysiol 76 (1996): 1698-1716.\n[0022-3077/96].\nCourtesy of the American Physiological\nAssociation. Used with permission.\n\nStimulus Autocorrelation\nPitch =1/F0\nCharacteristic frequency (kHz)\nAll-order interval histograms\n.5\n.2\nPopulation-interval histogram\nAutocorrelation functions\nFundamental\nCorr() = S(t) S(t- )\nperiod\nt\n1/F0\nShift\nMultiply\nSum the products\nfor each delay \nto compute\nautocorrelation\nfunction\ntime lag\n\nAutocorrelations\nHistograms of\n=\nof spike trains\nall-order intervals\n# intervals\nInterval (ms)\nSource: Cariani, P. A., and B. Delgutte. \"Neural Correlates of the Pitch of Complex Tones. I. Pitch and Pitch Salience.\" J Neurophysiol 76 (1996):\n1698-1716. [0022-3077/96]. Courtesy of the American Physiological Association. Used with permission.\nWednesday, February 11, 2009\n\nMany different\nsounds produce\nStrong\nthe same pitches\npitches\nStrong\n- Pure tones\n- Harmonic complexes\n- Iterated noise\nWeaker\n- High harmonics\n- Narrowband noise\nVery weak\n- AM noise\n- Repeated noise\nWeaker\nlow\npitches Schematic representation of eight signals with the same low fundamental pitch but different sets of harmonics.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\n125 Hz\n250 Hz\n500 Hz\nMany\ndifferent\nsounds\nproduce\nthe\nsame\npitch\npitch\nmetamery\nFastl, H. & Stoll, G.\nScaling of pitch strength,\nHearing Research\n1(1979): 293-301\nWednesday, February 11, 2009\nCourtesy Elsevier, Inc., http://www.sciencedirect.com. Used with permission.\n\nUse the structure of perception to find neural codes:\n1. Use stimuli that produce equivalent percepts\n2. Look for commonalities in neural response\n3. Eliminate those aspects that are not invariant\nMetameric\nNeural\nNeural codes, representations:\nstimuli\nresponse\nthose aspects of the\n(same percept,\npattern\nneural response\nthat play a functional role\ndifferent power spectra)\nin subserving\nthe perceptual distinction\nStimulus A\n(AM tone, fm = 200 Hz)\nCandidate\nStimulus B\n\"neural codes\"\n(Click train, F0 = 200 Hz)\nor representations\nCommon aspects\nIntensity\nof neural response\nthat covary\nwith the percept\nof interest\nOther parameters\nfor which percept is\ninvariant\nLocation\nDuration\nWednesday, February 11, 2009\n\nPitch equivalence classes\n(keep the percept constant, identify neural response invariances)\nSix stimuli that produce a low pitch at 160 Hz\nPopulation\ninterval\nWaveform\nPower spectrum\nAutocorrelation distribution\nInterspike\ninterval (ms)\nPure tone\n160 Hz\nAM tone\nFm:160 Hz\nFc:640 Hz\nHarms 6-12\nAM tone\nClick train\nAM noise\nF0 :160 Hz\nFm :160 Hz\nFc:6400 Hz\nFm :160 Hz\nPitch frequency\nPitch period\nF0 : 160 Hz\nLag (ms)\nFrequency (Hz)\nTIme (ms)\nWEAK\nPITCHES\nSTRONG\nPITCHES\nWednesday, February 11, 2009\n\nvan Norden, 1981; after Ritsma (1962) Graph comparing three gradients (F0-dependent, n-dependent, and Fc-dependent).\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nLevel-invariance\nPitch equivalence Graphs of level-invariance and pitch equivalence.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.Graphs of level-invariance and pitch equivalence.\n\nA correlational representation for loudness?\nCorrelation between\nStimulus autocorrelation\npopulation-interval\ndistributions and stimulus\nautocorrelation serves as\nan index of the amount of\ncommon, stimulus-driven\ntime structure in the auditory\nnerve array.\nPopulation-interval distributions\nAs the sound pressure\nlevel increases, a\n40 dB SPL\nprogressively greater\nr = 0.62\nfraction of the activity\n31 fibers\nin the array is stimulus\nlocked and mutually\ncorrelated.\n60 dB SPL\nThis representation\nr = 0.70\nmakes use of the\n61 fibers\ndynamic range of the\nentire auditory nerve\n80 dB SPL\narray, and leads to a\ntheory of partial\nloudnesses of multiple\nr = 0.77\nauditory objects in a\n17 fibers\nvery straightforward\nway.\n# intervals\nAll-order interval (msec)\nWednesday, February 11, 2009\n\nWednesday, February 11, 2009\nSource: Cariani, P. A., and B. Delgutte.\n\"Neural Correlates of the Pitch of Complex Tones.\nI. Pitch and Pitch Salience.\" J Neurophysiol 76\n(1996): 1698-1716. [0022-3077/96].\nCourtesy of the American Physiological\nAssociation. Used with permission.\n\nANF\nANF\nAUTO\nPopulation-interval\nDATA\nSIMULATION\nCORRELATION\ndistributions and\nautocorrelation functions\nA\nPure Tone\nF=160 Hz\nPure Tone\n160 Hz\nB\nAM Tone\nFc=640 Hz, Fm=160 Hz\n3.5\nAM Tone\n2.5\n1.5\nFm =160 Hz\n0.005\n0.01\nFc = 640 Hz\n0.5\nC\nClick train\nF0= 160 Hz\n4.5\nClick Train\n3.5\n2.5\n1.5\nF0 = 160 Hz\n0.5\n0.005\n0.01\n0.015\nD\nAM noise\nFm= 160 Hz\nAM Broadband Noise\nFm = 160 Hz\nInterval (ms)\nInterval (ms)\nInterval (ms)\nWednesday, February 11, 2009\n\nInterval (ms)\nThe running population-interval distribution\nPopulation autocorrelogram\n79 AN fibers,\n~100,000 spikes\nA\nB\n1/F0\nPeristimulus time (ms)\nPopulation interval\nhistograms\n(cross sections)\n1000 A\n# intervals\nInterval (ms)\n# intervals\nB\nInterval (ms)\nWednesday, February 11, 2009\n\nPitch shift of inharmonic complex tones\nFm = 125 Hz\nStimulus waveform\nStimulus autocorrelation\nPopulation interval\nFc = 750 Hz\n1/Fm\n1/Fm\ndistributions\n1/Fm\nn=6\n# intervals\nn = 5.86\n* *\n# intervals\nn = 5.5\n# intervals\n* *\nn = 5\n# intervals\nFreq (kHz)\nPeristimulus time (ms)\nLag (ms)\nInterval (ms)\nWednesday, February 11, 2009\n\nC\nFc=640 Hz, Fm=160-320 Hz\nPitch and\nInterval (ms)\nE\nG\n1/Fm\nde Boer's\nrule\nPeristimulus time (ms)\nWednesday, February 11, 2009\n\nPitch shift of inharmonic complex tones\nPhase-invariant nature of all-order interval code\nWednesday, February 11, 2009\n\nWednesday, February 11, 2009\n\nInterval (ms)\nCochlear nucleus IV: Pitch shift\nVariable-Fc\nAM\ntone\nFm = 125 Hz Fc = 500-750 Hz Pitch ~ de Boer's rule\nPooled ANF (n=47)\nFc\nChop-S (PVCN) Unit 35-40 CF: 2.1 kHz\nde Boer's\nrule\n(pitches)\n500 (Hz)\nThr: 5.3 SR: 17.7\n45-17-4 CF: 408 Hz\n45-15-8 CF:4417\n1/Fm\nThr: -18, SR: 39 s/s\nPeristimulus time (ms)\nInterval (ms)\n(AVCN)\nPeristimulus time (ms)\nde Boer's\n(pitches)\nsub-\nharmonics\nof Fc\n1/Fc\nPrimarylike\nThr: 21.3 SR: 159\nPauser (DCN)\nrule\nWednesday, February 11, 2009\n\nDominance region for pitch (harmonics 3-5 or partials 500-1500 Hz)\nWednesday, February 11, 2009\n\nWednesday, February 11, 2009\n\nCoding of vowel quality (timbre)\nWednesday, February 11, 2009\n\nIntervals (ms)\nIntervals (ms)\nPitch masking\nVariable-F0 click train in broad-band noise\nClick train: F0= 160-320 Hz, positive polarity, 80 dB SPL\nPeak/background ratio: intervals @ 1/F0  150 usec/mean over all intervals\nWhat degree of temporal\nInformal pitch thresholds, s/n dB: 12 (MT), 13 (PC), 16 (BD)\ncorrelation is necessary for\npitch to become audible?\ns/n: 8 dB\np/b = 1.11\ns/n: 32 dB\np/b = 2.38\ns/n: 20 dB\np/b = 1.57\ns/n: no noise\np/b =3.26\nPeristimulus time (ms)\nWednesday, February 11, 2009\n\nVowels\nPopulation-interval coding of timbre (vowel formant structure)\nSignal autocorrelation [ae]\nVoice pitch\nPopulation-wide distributions of\nshort intervals for 4 vowels\nFormant-\nstructure\nmagnitude\nPopulation interval histogram\n[]\n[]\n# intervals\n[u]\nVoice pitch\n[]\nFormant\n1/F1\nstructure\n# intervals\nInterval (ms)\nInterval (ms)\nWednesday, February 11, 2009\n\nTime domain analysis of auditory-nerve fiber firing rates.\nHugh Secker-Walker & Campbell Searle, J. Acoust. Soc. 88(3), 1990\nNeural responses to /da/ @ 69 dB SPL from Miller and Sachs (1983)\nHigh CFs\nLow CFs\nF1\nF2\nF3\nPeristimulus time (ms)\nW\nReprinted with permission, from Secker-Walker HE, Searle CL. 1990. \"Time-domain Analysis of Auditory-nerve-fiber Firing Rates.\" J Acoust Soc Am 88 (3):\n1427-36. Copyright 1990, Acoustical Society of America.\nednesday, February 11, 2009\n\nSummary\nPopulation-interval representation of pitch\nat the level of the auditory nerve\nPitch of the\nAM tone\nPower spectrum Autocorrelation\n\"missing\nfundamental\"\nPure tone\nAM tone\nClick train\nAM noise\nPitch\nEquivalence\n40 dB SPL\nLevel invariance\nn = 6\n5.86\n5.5\nPitch shift of\ninharmonic\nAM tones\nPhase invariance\nAM tone\nQFM tone\n1/F06-12 1/F03-5\nDominance region\nF03-5=160 Hz\n240 Hz\n320 Hz\n480 Hz\nStrong pitch\nWeak pitch\nV. weak pitch\nPitch salience\nWednesday, February 11, 2009\n\nTemporal coding of pitch in the auditory nerve\nPitch = predominant all-order interspike interval\nPitch strength = relative proportion of pitch-related intervals\nTimbre (tone quality) = pattern of other intervals\nStimulus autocorrelation ~ population-interval distribution\nReadily explains:\n- Pitch equivalence classes\n- Invariance w.  sound pressure level\n- Invariance w.  waveform envelope, phase spectrum\n- Existence region of musical tonality (octaves, melody)\n- Pitches of resolved & unresolved harmonics\n- Pitches of harmonic & inharmonic tone complexes\nWednesday, February 11, 2009\n\ne ~ 30 ms\nOCTAVE\nSIMILARITY\nFROM\nSIMILARITY\nOF\nINTERSPIKE\nINTERVAL\nREPRESENTATIONS\nWednesday, February 11, 2009\nThis image is from the article Cariani, P. \"Temporal Codes, Timing Nets, and Music Perception.\" Journal of New Music Research 30, no. 2\n(2001): 107-135. DOI: 10.1076/jnmr.30.2.107.7115. This journal is available online at http://www.ingentaconnect.com/content/routledg/jnmr/\n\nCorrelations between population-interval patterns\nPure tones\nHarmonics 1-6\nR-values (0-1)\nWednesday, February 11, 2009\nThis image is from the article Cariani, P. \"Temporal Codes, Timing Nets, and Music Perception.\" Journal of New Music Research 30, no. 2 (2001): 107-135.\nDOI: 10.1076/jnmr.30.2.107.7115. This journal is available online at http://www.ingentaconnect.com/content/routledg/jnmr/\n\nExistence region of musical tonality\nis coextensive with spike timing information\nStrong phase-locking (temporal information)\nPhase-locking as measured by\nsynchronization index\ndeclines dramatically\nabove ~4 kHz\nMusical tonality: octaves, intervals, melodies\ntemporal representation\nlevel-invariant, precise\nplace representation\nlevel-dependent, coarse\n1k\n10k\nFrequency (kHz)\nWednesday, February 11, 2009\n\nDuplex time-place representations\ntemporal representation\nlevel-invariant\n- strong (low fc, low n)\n- weak (high fc, high n; F0 < 100 Hz)\nplace-based\nrepresentation\nlevel-dependent\ncoarse\n1k\n10k\nSimilarity\ncf. Terhardt's\nto\nspectral and virtual pitch\ninterval\npattern\nSimilarity to place pattern\nWednesday, February 11, 2009\n\nTwo codes for \"pitch\nPlace code\nPitch = place of excitation\nPitch height\nAbsolute\nLow vs. high\nExistence region\nf: .100-20,000 Hz\nFrequency analysis\nFourier spectrum\nTime code\nPitch = dominant periodicity\nMusical pitch\n\"Chroma\", Tonality\nRelational\nMusical intervals, tonality\nMelodic recognition\n& transposition\nExistence region\nF0: 30-4000 Hz\nPeriodicity analysis\nAutocorrelation\nWednesday, February 11, 2009\n\nPitch dimensions: height & chroma\nWednesday, February 11, 2009 Two drawings representing rising pitch: one a straight vertical arrow, and the other a rising spiral that puts any given note in the scale at the same point in each rotation.\nFigure by MIT OpenCourseWare.\n\nPitch height and pitch chroma\nWednesday, February 11, 2009\nImages removed due to copyright restrictions.\nFigures 1, 2, and 7 in Shepard, R. N. \"Geometrical Approximations to the Structure of Musical Pitch.\"\nPsychological Review 89, no. 4 (1982): 305-322.\n\nTemporal theories - pros & cons\nMake use of spike-timing properties of\nelements in early processing (to midbrain at least)\nInterval-information is precise & robust & level\ninsensitive\nNo strong neurally-grounded theory of how this\ninformation is used\nUnified model: account for pitches of perceptually\n\nresolved & unresolved harmonics in an elegant\nway (dominant periodicity)\nExplain well existence region for F0 (albeit with\nlimits on max interval durations)\nDo explain low pitches of unresolved harmonics\nInterval analyzers require precise delays & short\ncoincidence windows\nWednesday, February 11, 2009\n\nSpectral pattern models\nMostly conceived within a frequency analysis framework\n\"Auditory filters\" derived from psychophysics, not\nphysiology\nWednesday, February 11, 2009\n\nShapes of perceptually-derived \"auditory filters\" (Moore)\nDont conflate these with cochlear filters or auditory\nnerve excitation patterns! Auditory filters are derived\nfrom psychophysical data & reflect the response of the\nwhole auditory system. For lower frequencies and higher\nlevels AFs have much narrower bandwidths than\ncochlear resonances or auditory nerve fiber responses.\nWednesday, February 11, 2009 Three graphs showing perceptually derived auditory filters. Three graphs showing perceptually derived auditory filters.\nFigures by MIT OpenCourseWare.\n\nFrom masking patterns\nto \"auditory filters\" as a\nmodel of hearing\nPower spectrum\nFilter metaphor\nNotion of one central\nspectrum that subserves\n2.2. Excitation pattern Using the filter shapes and bandwidths derived from masking experiments we can\nproduce the excitation pattern produced by a sound. The excitation pattern shows how much energy comes\nthrough each filter in a bank of auditory filters. It is analogous to the pattern of vibration on the basilar\nmembrane. For a 1000 Hz pure tone the excitation pattern for a normal and for a SNHL (sensori-neural\nhearing loss) listener look like this: The excitation pattern to a complex tone is simply the sum of the\npatterns to the sine waves that make up the complex tone (since the model is a linear one). We can hear out\na tone at a particular frequency in a mixture if there is a clear peak in the excitation pattern at that\nfrequency. Since people suffering from SNHL have broader auditory filters their excitation patterns do not\nhave such clear peaks. Sounds mask each other more, and so they have difficulty hearing sounds (such as\nspeech) in noise. --Chris Darwin, U. Sussex, http://www.biols.susx.ac.uk/home/Chris_Darwin/Perception/Lecture_Notes/Hearing3/\nhearing3.html\nWednesday, February 11, 2009\nCourtesy of Prof. Chris Darwin (Dept. of Psychology at the University of Sussex). Used with permission.\n\nResolvability of harmonics (Plomp, 1976)\nFundamental\nfrequency\n(F0)\nWednesday, February 11, 2009\nImage removed due to copyright restrictions.\nGraph of frequency separation between partials vs. frequency of the partial.\nFrom Plomp, R. Aspects of Tone Sensation. New York, NY: Academic Press, 1976.\n\nResolution of harmonics (based on psychophysics)\nWednesday, February 11, 2009 Graph of threshold shift (dB) vs. frequency (0 to 4kHz).\nFigure by MIT OpenCourseWare.\n\nGoldsteins\nharmonic\ntemplates\nFigure removed due to copyright restrictions.\nDiagram of periodicity pitch as harmonic frequency pattern recognition. Figure 3 in Goldstein, J. L., et al.\n\"Verification of the Optimal Probabilistic Basis of Aural Processing in Pitch of Complex Tones.\"\nJ Acoust Soc Am 63 (1978): 486-510. http://dx.doi.org/10.1121/1.381749\nWednesday, February 11, 2009\n\nA \"two-mechanism\" perspective (popular with some psychophysicists)\nn= 5-10\nunresolved harmonics\nweak temporal mechanism\nphase-dependent; first-order intervals\nharmonic number\nplace-based\nrepresentation\nlevel-independent\nfine\nresolved harmonics\nstrong spectral pattern mechanism\nphase-independent\nrate-place? interval-place?\nDominance region\nf, F0\nplace-based\nrepresentations\nlevel-dependent\ncoarse\n1k\n10k\nWednesday, February 11, 2009\n\nGoldstein JL (1970) Aural combination tones. In: Frequency Analysis and Periodicity\nDetection in Hearing (Plomp R, Smoorenburg GF, eds), pp 230-247. Leiden: A.\nW. Sijthoff.\nGoldstein JL (1973) An optimum processor theory for the central formation of the pitch\nof complex tones. J Acoust Soc Am 54:1496-1516.\nJulius Goldstein\nGoldstein JL, Kiang NYS (1968) Neural correlates of the aural combination tone 2f1-f2.\nIEEE Proc 56:981-992.\nreferences\nGoldstein JL, Srulovicz P (1977) Auditory-nerve spike intervals as an adequate basis for\naural frequency measurement. In: Psychophysics and Physiology of Hearing\n(Evans EF, Wilson JP, eds). London: Academic Press.\nGoldstein JL, Buchsbaum G, First M (1978a) Compatibility between psychophysical and\nphysiological measurements of aural combination tones. J Acoust Soc Am\nModels for\n63:474-485.\nGoldstein JL, Buchsbaum G, Furst M (1978b) Compatibility between psychophysical and\npure tone\nphysiological measurements of aural combination tones... Journal of the\nAcoustical Society of America 63:474-485.\npitch\nGoldstein JL, Gerson A, Srulovicz P, Furst M (1978c) Verification of the optimal\ndiscrimination,\nprobabilistic basis of aural processing in pitch of complex tones. J Acoust Soc Am\n63:486-510.\nlow pitches of\nH. L. Duifhuis and L. F. Willems and R. J. Sluyter ( 1982,) Measurement of pitch in\nspeech: An implementation of Goldstein's theory of pitch perception,. jasa, 71,:\n1568--1580.\ncomplex tones,\nHoutsma AJM, Goldstein JL (1971) Perception of musical intervals: Evidence for the\ncentral origin of the pitch of complex tones. In: M.I.T./R.L.E.\nbinaural pitches,\nHoutsma AJM, Goldstein JL (1972) The central origin of the pitch of complex tones:\nEvidence from musical interval recognition. J Acoust Soc Am 51:520-529.\nand\nP. Srulovicz and J. Goldstein ( 1983) A central spectrum model: A\nsynthesis of\nauditory nerve timing and place cues in monoaural communication offrequency\naural distortion\nspectrum,. jasa, 73,: 1266--1276,.\nproducts\nSrulovicz P, Goldstein JL (1977) Central spectral patterns in aural signal analysis based\non cochlear neural timing and frequency filtering. In: IEEE, p 4 pages. Tel Aviv,\nIsrael.\nSrulovicz P, Goldstein JL (1983) A central spectrum model: a synthesis of auditory-nerve\ntiming and place cues in monaural communication of frequency spectrum. J\nAcoust Soc Am 73:1266-1276.\nWednesday, February 11, 2009\n\nTerhard's method of common subharmonics\nSpectral vs. virtual pitch: duplex model\nVirtual pitch computation:\n1. Identify frequency component\n2. Find common subharmonics\n3. Strongest common subharmonic after\nF0 weighting is the virtual pitch\nTerhardt's model has been extended by\nParncutt to cover pitch multiplicity\nand fundamental bass of chords\nWednesday, February 11, 2009\n\nTerhardt references\nTerhardt E (1970) Frequency analysis and periodicity detection in the sensations of\nroughness and periodicity pitch. In: Frequency Analysis and Periodicity Detection\nin Hearing (Plomp R, Smoorenburg GF, eds). Leiden: A. W. Sijthoff.\nTerhardt E (1974a) On the perception of periodic sound fluctuations (roughness).\nAcustica 30:201-213.\nTerhardt E (1974b) Pitch, consonance, and harmony. J Acoust Soc Am 55:1061-1069.\nTerhardt E (1977) The two-component theory of musical consonance. In: Psychophysics\nand Physiology of Hearing (Evans EF, Wilson JP, eds), pp 381-390. London:\nAcademic Press.\nTerhardt E (1979) Calculating virtual pitch. Hearing Research 1:155-182.\nTerhardt E (1984) The concept of musical consonance: a link between music and\npsychoacoustics. Music Perception 1:276-295.\nTerhardt E, Stoll G, Seewann M (1982a) Pitch of complex signals according to virtual-\npitch theory: test, examples, and predictions. J Acoust Soc Am 71:671-678.\nTerhardt E, Stoll G, Seewann M (1982b) Algorithm for extraction of pitch and pitch\nsalience from complex tonal signals. J Acoust Soc Am 71:679-688.\nWednesday, February 11, 2009\n\nSPINET:\nCohen Grossberg, Wyse JASA\nFixed\nneural\nnetwork:\nconnection\nweights\narranged\nso as to form\npitch-equivalence\nclasses\nWednesday, February 11, 2009\nCourtesy of Prof. Stephen Grossberg. Used with permission.\nSource: Cohen, M. A., S. Grossberg, and L. L. Wyse.\n\"A Spectral Network Model of Pitch Perception.\"\nTechnical Report CAS/CNS TR-92-024, Boston\nUniversity. Also published in J Acoust Soc Am\n98, no. 2 part 1 (1995): 862-79.\n\nBroad tuning and rate saturation\nat moderate levels in low-CF\nauditory nerve fibers confounds\nrate-based resolution of\nharmonics.\nLow SR auditory nerve fiber Graph of spikes/sec versus fequency for a low SR auditory nerve fiber, at sound levels from 25 to 95 dB.\nRose, 1971\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nSpectral pattern theories - pros & cons\nDo make use of frequency tuning properties of\nelements in the auditory system\nNo clear neural evidence of narrow (< 1/3 octave)\nfrequency channels in low-BF regions (< 2 kHz)\nOperate on perceptually-resolved harmonics\nDo not explain low pitches of unresolved harmonics\nRequire templates or harmonic pattern analyzers\nLittle or no neural evidence for required analyzers\nProblems w. templates: relative nature of pitch\nDo not explain well existence region for F0\nLearning theories don't account for F0 ranges\nor for phylogenetic ubiquity of periodicity pitch\nWednesday, February 11, 2009\n\nProblems with rate-place models\nIn contrast to musical (F0) pitch percepts....\nRate-place spectral profiles\n- have coarse resolution ( 1 octave)\n- change with sound level\n- worsen dramatically at higher sound levels\n- should work better for high frequencies\n- cannot account for F0 pitches of unresolved\n\nharmonics\nWednesday, February 11, 2009\n\nCharacteristic freq. (kHz)\nSome\nLocal\nCentral spectrum\npossible\nRate-place\nauditory\nMasking phenomena\nrepresentations\nLoudness\nCF\nSynchrony-place\nCentral spectrum\nInterval-place\nCF\nPeristimulus time (ms)\nPure tone pitch JNDs\nPopulation interval\nStages of\n1/F0\nintegration\nPopulation-interval\nAll-at-once\nComplex tone pitch\nGlobal\nInterval\nWednesday, February 11, 2009\n\nSingle-formant vowel\nSingle-formant vowel\nCochlear nucleus II\nVariable F0\nVariable F0\nSpectra and waveform for F0=80\nSpectra and waveform for F0=160\ndB\ndB\n0 Frequency (kHz) 3 0\nTime(ms)\n0 Frequency (kHz) 3 255\nTime(ms)\nF1 = 640 Hz\nF1 = 640 Hz\nPitch ~ 1/F0\nF0 = 80-160 Hz\nF0 = 160-320 Hz\nPooled\nANF's\n1/F0\n1/F0\npitch\npitch 10\nInterval (ms)\nUnit 45-18-9\nCF: 400 Hz\nUnit 45-13-6\nCF: 750 Hz\nAVCN Pri\nThr: 21.4 dB SPL\nAVCN Pri\nThr: 23.6 dB SPL\nPri\nInterval (ms)\nUnit 16-5-56\nChop-S\nF1 = 600 Hz\nF0 = 100-125 Hz\n1/F0\npitch\n1/F0\npitch\nChop\nS\nPause\nCF: 4418 Hz\nThr: -17.6 dB SPL\nUnit 45-15-15\nCF: 4418 Hz\nUnit 45-15-16\nCF: 1514 Hz\nThr: 10.6 dB SPL\nUnit 45-12-6\nChop-S\n80 dB SPL\nCF: 3510 Hz\nThr: 6.9 dB\nSR: 26 s/s\nInterval (ms)\n1/F0\npitch\n1/F0\npitch\nThr: -17.6 dB SPL\nPause\nPause\nSR: 39 s/s\nSR: 39 s/s\n1/F0\npitch\n2/F0\nPeristimulus time (ms)\nPeristimulus time (ms)\nInterval (ms)\n1/F0\npitch\nWednesday, February 11, 2009\n\nModulation detectors in the midbrain\nStimulus-related temporal discharge patterns\nModulation-tuning\nof discharge rate\nSee: Gunter Ehret (1997) The auditory midbrain, a \"shunting yard\" of acoustical information processing.\nIn The Central Auditory System, Ehret, G. & Romand, R., eds. Oxford University Press.\nLangner, G. and Schreiner, C.E. Periodicity coding in the inferior colliculus of the cat. I. Neuronal mechanisms.\nJ. Neurophysiol. 60:1799-1822.\nLangner (1992) review, Periodicity coding in the auditory system. Hearing Research, 60:115-142.\nWednesday, February 11, 2009\nImages removed due to copyright restrictions.\nSee Fig. 2 and 3 in Langner, G. and C. E. Schreiner.\n\"Periodicity Coding in the Inferior Colliculus of the Cat. I. Neuronal Mechanisms.\"\nJ Neurophysiol 60 (1988): 1799-1822.\n\nPitch-related temporal\npatterns in field potentials\nin awake monkey cortex\nFigure. Averaged cor\ntical field potentials\n(current source densi -\nty analysis, lower lami-\nna 3, site BF=5 kHz)\nin response to 50\nms\nclick trains\nF0=100\n500 Hz. Ripples up to\n300-400 Hz show syn\nchronized component\nof the ensemble-\nresponse, From\nSteinschneider (1999).\nWednesday, February 11, 2009\nImage removed due to copyright restrictions.\nSee Fig. 9 right, in Steinschneider, M., et al.\n\"Click Train Encoding in Primary Auditory\nCortex of the Awake Monkey: Evidence for Two\nMechanisms Subserving Pitch Perception.\"\nJ Acoust Soc Am 104, no. 5 (1998): 2935-2955.\nDOI: 10.1121/1.423877.\n\nWednesday, February 11, 2009\nCourtesy of Prof. Mark J. Tramo, M.D., Ph.D. Used with permission.\nSource: Tramo, Mark J. \"Neural Representations of Acoustic Information in Relation to Voice Perception.\"\nHavard University PhD Thesis, 1999.\n\nPure tone temporal response profiles in auditory cortex (A1)\nWednesday, February 11, 2009\nCourtesy of Prof. Mark J. Tramo, M.D., Ph.D. Used with permission.\n\nSource: Tramo, Mark J. \"Neural Representations of Acoustic Information in Relation to Voice Perception.\" Havard University PhD Thesis, 1999.\n\nPhase-locking in thalamus and cortex\nDe Ribaupierre: 10% of thalamic units in awake cats with\nsynchronization indices of 0.3 or better to 1-2 kHz tones\nReports of isolated cortical units with phase-locking\nto Fm of AM tones up to 1 kHz (Semple)\nPitch detectors in thalamus and cortex\nSchwarz & Tomlinson failed to find true F0 detectors in\ntheir study of > 200 cortical units in awake macaque\nRiquimaroux found 16 units that responded both to pure tones\nand harmonic complexes that would evoke the same pitch\nWednesday, February 11, 2009\n\nBendor & Wang(2005) F0-tuned units in auditory cortex\nWednesday, February 11, 2009\nImage removed due to copyright restrictions.\nSee Fig. 1 in Bendor and Wang. \"The Neuronal Representation of Pitch in\nPrimate Auditory Cortex.\" Nature 436 (2005): 1161-1165.\n\nThe enigma of the central representation of pitch\nThe tight correspondences between psychophysics and the\npopulation interspike interval code strongly suggest that our\nperception of pitch depends on this information.\nYet, despite some recent advances, we still do not understand\nhow the central auditory system uses this information.\nWhat happens to neural timing information as one ascends the\nauditory pathway from auditory nerve to cortex?\nIs time converted to some sort of place code (e.g. pitch\ndetectors) or is some other kind of code involved?\nWednesday, February 11, 2009\n\nDischarge rate as a function of frequency and intensity\nAuditory nerve fiber\nRose (1971) Graph of spikes/sec versus fequency for a low SR auditory nerve fiber, at sound levels from 25 to 95 dB.\nWednesday, February 11, 2009\nFigure by MIT OpenCourseWare.\n\nFrequency response curves for fibers in the cochlear nerve of the squirrel monkey.\nLeft: low spontenous activity; right: high spontaneous activity.\nFrom Rose, J. E., et al. \"Some Effects of Stimulus Intensity on Response of Auditory Nerve Fibers in the Squirrel Monkey.\" J Neurophysiol 34 (1971): 685-699.\nFour graphs removed due to copyright restrictions.\nSee Fig. 2 and Fig. 4 in Rose, J. E., et al. \"Some Effects of Stimulus\nIntensity on Response of Auditory Nerve Fibers in the Squirrel Monkey.\"\nJ Neurophysiol 34 (1971): 685-699.\n\nAlan Palmer\nIn Hearing, Moore ed.\nFigure 4 in Palmer, Alan. \"Neural Signal Processing.\" Chapter 3 in Hearing. 2nd ed. Edited by B. C. J. Moore. Academic Press, 1995.\n[Preview this image in Google Books]\nWednesday, February 11, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Rhythm: patterns of events in time",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/b4b6bc19e131fc7f6b365d0fef32845d_MITHST_725S09_lec16_rhy.pdf",
      "content": "Rhythm: patterns\nof events in time\nHST.725: Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\nThursday, May 14, 2009\nCourtesy of John Hart (http://nanobliss.com). Used with permission.\n\n1. Rhythmic pattern induction & expectation\n2. Meter -\nthe inferred metrical grid\n3. The Time Sense\nchunking of repeating patterns\nSource: Snyder, J. S., and E. W. Large. \"Gamma-band Activity Reflects\nthe Metric Structure of Rhythmic Tone Sequences.\" Cog Brain Res 24 (2005):\n117-126. Courtesy Elsevier, Inc., http://www.sciencedirect.com.\nUsed with permission.\nImage of Salvador Dali's painting \"The Persistence of Memory\"\nremoved due to copyright restrictions.\nSee http://en.wikipedia.org/wiki/File:The_Persistence_of_Memory.jpg\nThursday, May 14, 2009\n\nRhythm: patterns of events in time\nWhat is rhythm? Perceived patterns of events in time\nWhat constitutes an event? What makes events salient\n(accented)?\nHow many individual events can we distinguish (< 12/sec)?\nAuditory sense and the time sense (supramodal)\n- Perception of duration, weber fractions for time\nRhythmic pattern induction & expectation\n- Rhythmic pattern invariance w. respect to tempo\nMeter (regular underlying grid of accented/nonaccented\nevents)\nRhythmic hierarchies, rhythmic complexity\nSmall integer-ratios again: models (clock, oscillator, timing net)\nPolyrhythms; analogy to polyphony\nInteractions between melody & rhythm: accents\nRhythms: musical, body, and brain; kinesis\nThursday, May 14, 2009\n\nMusic notation: time durations\nFig. 2.2 in Sethares, W. A. Rhythm and Transforms.\nSpringer, 2007. ISBN: 9781846286391. Preview in Google Books.\nThursday, May 14, 2009\n\nTempo (absolute timescale, in beats/minute)\nDiagram of musica\nl tempos,\nin b\neats per\nminut\ne.\nFigure by MIT OpenCourseWare.\nThursday, May 14, 2009\n\nTempo\nRanges of events; intervals from 50 ms to 2 sec\nToo short: events fuse\nToo long: successive events don't cohere, interact\nPitch (> 30 Hz); infra-pitch (10-30 Hz); rhythm (<\n10 Hz)\nFor a brisk tempo of 120 bpm, 2 Hz,\na quarter note is 500 msec (2 Hz)\nan eighth note is 250 msec (4 Hz)\na sixteenth note is 125 ms (8 Hz)\na 32nd note is 62 ms (16 Hz)\nThursday, May 14, 2009\n\nRhythm: general observations I\n- Different levels of temporal organization\n- Handel's basketball game analogy:\n- Patterning\n- Rhythm: perception of grouping & ordering of events\n- Perceptual groupings of events in time create perceived\nrhythmic patterns\n- Temporal pattern expectancies create groupings\n- pattern repetition and\n- similar patterns of salient auditory contrasts (accents)\n- Underlying temporal framework\n- (metrical grid, meter, tempo)\nThursday, May 14, 2009\n\nExamples of repeating patterns - rows of shapes.\nRhythm: recurring patterns of events in time\nEvery repeating pattern creates an\nexpectancy of its continuation\nFigure by MIT OpenCourseWare.\nThursday, May 14, 2009\n\nExamples of repeating patterns - rows of shapes.\nEvery repeating pattern creates an\nexpectancy of its continuation\nFurther, there is a \"chunking\" of the repeating\npattern (the invariant pattern becomes an\nobject)\nFigure by MIT OpenCourseWare.\nThursday, May 14, 2009\n\nRhythm generation demonstration\n- Repeating patterns of events\n- Drum score representation\n- Synthesizer\nThursday, May 14, 2009\n\nAcoustical grouping\n\n(Snyder, Music & Memory)\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000. Courtesy of MIT Press.\nUsed with permission.\nThursday, May 14, 2009\n\nMelodic & rhythmic grouping\n(Snyder, Music & Memory)\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000. Courtesy of MIT Press.\nUsed with permission.\nThursday, May 14, 2009\n\nTemporal grouping\n\n(Snyder, Music & Memory)\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000.\nCourtesy of MIT Press. Used with permission.\nThursday, May 14, 2009\n\nRepetition\nof a\nrhythmic\npattern\nestablishes\nthe pattern\nImage removed due to copyright restrictions.\na) Two measure rhythmic pattern.\nb) Complete 2-bar pattern, followed by a repetition of the complete pattern.\nc) Complete 2-bar pattern, followed by two repetitions of the 2nd measure.\nd) Complete 2-bar pattern, followed by two repetitions of the 2nd measure in reverse.\ne) Complete 2-bar pattern; unique 3rd measure, and then a repetition of the 2nd measure.\nMusic Theory,\nThursday, May 14, 2009\n\nNecklace notation: cyclical repeating patterns\nFig. 2.6 in Sethares, W. A. Rhythm and Transforms.\nSpringer, 2007. ISBN: 9781846286391.\nPreview in Google Books.\nThursday, May 14, 2009\n\nNecklace notation: cyclical repeating patterns\nsee Sethares, 2007. Necklace notation: Safi al-Din al-Urmawi 13th c. Bagdad Book of Cycles\nFig. 2.4 in Sethares, W. A. Rhythm and Transforms. Springer, 2007. ISBN: 9781846286391. Preview in Google Books.\nThursday, May 14, 2009\n\nNecklace notation: cyclical repeating patterns\nFig. 2.5 in Sethares, W. A. Rhythm and Transforms. Springer, 2007. ISBN: 9781846286391.\nPreview in Google Books .\nSethares, 2007\nThursday, May 14, 2009\n\nMemory processes generate musical context\nTonality induction -- repetition of particular notes & sets of harmonics that\nestablishes a tonal expectation through which all subsequent\nincoming tonal patterns are processed -- establishment of the tonic\nRhythmic induction -- repetition of patterns of accented and unaccented\nevents that establishes a temporal pattern of expectation for\nsubsequent events\nBoth kinds of induction operate on similarities and contrasts between\nprevious and subsequent sounds & events\nOLD + NEW heuristic:\n1) OLD incoming patterns similar to previous ones build up\nthe images of previous ones, confirm +\nstrengthen expectations, create relaxation\n2) NEW different patterns create contrasts that violate\nexpectations established from previous inputs,\ncreate tension\n3) degree of contrast (distance in perceptual space) determines\nthe degree of tension created/resolved\nThursday, May 14, 2009\n\nHierarchy & time order (Snyder, Music & Memory, MIT Press, 2000)\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000.\nCourtesy of MIT Press. Used with permission.\nThursday, May 14, 2009\n\nDetection of arbitrary periodic patterns\nPeriodic patterns invariably build up in\ndelay loops whose recurrence times equals\nthe period of the pattern and its multiples.\nInput pattern\n1010110010110101100101101011001011010...\n1 = 11 ms = recurrence time\nof input pattern10101100101\nThursday, May 14, 2009\n\nTemporal coding of rhythm\nS\"mulusdriven temporal pa3erns of spikes encode event structures\n- Exist at the cor-cal level for periodici-es < 15 Hz\n- Can directly encode rhythmic pa<erns\n- Amenable to processing via recurrent -ming nets (RTNs)\n- Chunk recurrent pa<erns of events to create rhythmic expectancies\nno \n pitch\n -mbre\n dura-on\nAll time delays present\n0\nTime patterns reverberate\nthrough delay loops\n1\nRecurrent,\nindirect inputs\n2\n3\nCoincidence\nunits\nDirect inputs\nInput time sequence\n quality Examples of repeating patterns - rows of shapes.\nFigure by MIT OpenCourseWare.\nThursday, May 14, 2009\n\nIn addition to rhythmic patterning,\nwe seem to infer an underlying metrical\ngrid to the stream of events\n(e.g. inferences that allow us to tap our\nfingers or toes to a beat or to keep time\nwith the music)\nThis perception of an underlying metrical\norder is important for coordination of\nmusicians playing in groups.\nMeter serves as a temporal context that is\nsomewhat independent of individual events\n(somewhat like the tonic vis-a-vis melody)\nThursday, May 14, 2009\n\nSev\nera\nl n\nota\nted examples of meter and accent patterns.\nThursday, May 14, 2009\n\nMeter (e.g. 4 pulses per measure, accent)\nDefinition: The number of pulses between the more or\nless regularly recurring accents\n(Cooper and Meyer , 1960).\nMost authors define meter similarly, as somehow\ndependent upon (and perhaps contributing to)\npatterns of accent.\nZuckerkandl (1956), however, views meter as a series\nof \"waves\" that carry the listener continuously from\none beat to the next. For him, they result not from\naccentual patterns but simply and naturally from the\nconstant demarcation of equal time intervals.\nhttp://www.music.indiana.edu/som/courses/rhythm/illustrations\nThursday, May 14, 2009\n\nPulse & the metrical grid (meter)\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000. Courtesy of MIT Press.\nUsed with permission.\nThursday, May 14, 2009\n\nPulse\n- Definition: A series of regularly recurring, precisely\nequivalent stimuli ( Cooper and Meyer , 1960).\n- According to Parncutt (1987), a chain of events,\nroughly equally spaced in time.\nhttp://www.music.indiana.edu/som/courses/rhythm/illustrations\nThursday, May 14, 2009\n\nThree arranged g\nroups of 16 squares: rectangular, square, and trapezoidal.\nThursday, May 14, 2009\n\nAccent causes\ngrouping which\ndetermines\nperceived rhythmic\npattern\nRhythm is a\nperceptual\nattribute\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nCourtesy of MIT Press. Used with permission.\nThursday, May 14, 2009\n\nFactors that cause events to be accented:\nauditory contrast, salience\n- note duration\n- note intensity\n- sharpness of attack\n- duration of silence preceding it\n- contrast: melodic contour/ pitch change\n-\n(accented beats are \"on time\")\n- position within a metrical organization\n- According to Cooper & Meyer (1960), an accented tone\nmust be set off from the rest of the series in some way (i.e.\na salient contrast)\nregularity of timing\nThursday, May 14, 2009\n\nExpressive timing & expectation\nexpressive timing Definition:\nMusic psychologists' term for the\ndeviations from a strictly\nuniform\npulse that occur in live performance.\nThese\ndeviations most commonly\noccur near the ends of phrases and\nother grouping units. See Todd\n(1985).\nhttp://www.music.indiana.edu/som/courses/rhythm/illustrations\nThursday, May 14, 2009\n\nMeter and beat induction\nSource: Palmer, C., and C. L. Krumhansl.\n\"Mental representations for musical meter.\"\nJ Exp Psychol Hum Percept Perform 16, no. 4 (Nov 1990): 728-741.\n- From Thinking in Sound\nCourtesy of the American Psychological Association.\nThursday, May 14, 2009\n\nrhythmic, metrical dissonance\n- metrical dissonance Definition: According to\nKrebs (1987), a situation in which the pulses in two\nmetrical levels are not well aligned, either because\nthe duration of the pulses in one level is not an\nintegral multiple or division of the duration of the\npulses in the other level, or because the pulses in\none level are displaced by some constant interval\nfrom those in the other level. See also Yeston's\nrhythmic dissonance .\nhttp://www.music.indiana.edu/som/courses/rhythm/illustrations\nThursday, May 14, 2009\n\nEvent-related potentials & violations of temporal expectation\n(notes, chords, beats, words (phonetic, semantic), many other levels of expectation)\nPhoto and graph of EEG/ERP removed due to copyright restrictions.\nSee: http://www.musicianbrain.com/methods.php#methods\nThursday, May 14, 2009\n\nThursday, May 14, 2009\n\nSnyder & Large experiments on beat induction\nJ.S. Snyder, E.W. Large / Cognitive Brain Research 24 (2005) 117-126\nFig. 1. Pure-tone (262 Hz, 50 ms duration) stimulus patterns are shown with inter-onset intervals of 390 ms (above) and schematized metrical accent\nrepresentations (below). The periodic control condition consisted of isochronous tones designed to elicit a simple pulse perception (A). The binary control\ncondition consisted of alternating loud and soft tones, designed to elicit a duple meter perception (B). The omit-loud condition consisted of the binary control\npattern with missing loud tones on 30% of two-tone cycles (C). The omit-soft condition consisted of the binary control pattern with missing soft tones on 30%\nof two-tone cycles (D).\nSource: Snyder, J. S., and E. W. Large. \"Gamma-band Activity Reflects the Metric\nStructure of Rhythmic Tone Sequences.\" Cog Brain Res 24 (2005): 117-126.\nThursday, May 14, 2009\nCourtesy Elsevier, Inc., http://www.sciencedirect.com. Used with permission.\n\nJ.S. Snyder, E.W. Large / Cognitive Brain Research 24 (2005) 117-126\nSource: Snyder, J. S., and E. W. Large.\n\"Gamma-band Activity Reflects the Metric\nStructure of Rhythmic Tone Sequences.\"\nCog Brain Res 24 (2005): 117-126.\nCourtesy Elsevier, Inc., http://www.sciencedirect.com.\nUsed with permission.\nFigure 2. Process to calculate evoked and gamma-band activity (GBA).\nThursday, May 14, 2009\n\nFigure 4.\n(a) Time-frequency representation of the evoked and induced GBA results, averaged over all subjects. Tone onset occurs at\nzero and 390 ms. (b) Comparison of induced/evoked peak activity in the presence and absence of loud and soft tones.\nCourtesy of University of Finance and Management, Warsaw. Used with permission.\nThursday, May 14, 2009\n\nJ.S. Snyder, E.W. Large / Cognitive Brain Research 24 (2005) 117-126\nSource: Snyder, J. S., and E. W. Large. \"Gamma-band Activity Reflects the Metric Structure of\nRhythmic Tone Sequences.\" Cog Brain Res 24 (2005): 117-126.\nCourtesy Elsevier, Inc., http://www.sciencedirect.com. Used with permission.\nFigure 7. Tone omissions: induced and evoked GBA.\nThursday, May 14, 2009\n\nFigure 5.\nPerturbed stimuli; 'x' represents tone onset.\nCourtesy of University of Finance and Management,\nWarsaw. Used with permission.\nThursday, May 14, 2009\n\nEvoked GBA\nCourtesy of University of Finance and Management, Warsaw. Used with permission.\nFigure 6.\nTime-frequency representation of the evoked and induced GBA in response to early, late, or on-time tones averaged over all\nsubjects. The white dashed line represents where a tone was expected. (a) Evoked activity is predicted by the presence of\ntones. The white box highlights an exception, activity where the tone was expected in the case of an early tone. (b) The white\nbox indicates a peak in the induced activity where the tone was expected for the case of late tones.\nThursday, May 14, 2009\n\nInduced GBA\nFigure 6.\nCourtesy of University of Finance and Management, Warsaw. Used with permission.\nTime-frequency representation of the evoked and induced GBA in response to early, late, or on-time tones averaged over all\nsubjects. The white dashed line represents where a tone was expected. (a) Evoked activity is predicted by the presence of\ntones. The white box highlights an exception, activity where the tone was expected in the case of an early tone. (b) The white\nbox indicates a peak in the induced activity where the tone was expected for the case of late tones.\nThursday, May 14, 2009\n\nSUMMARY\nEvoked GBA appears to represent sensory processing\nas predicted by the presence of tones, much like the\nMLR. Induced GBA may reflect temporally precise ex\npectancies for strongly and weakly accented events in\nsound patterns. Moreover, induced GBA behaves in a\nmanner consistent with perception-action coordination\nstudies using perturbed temporal sequences. Taken\ntogether, the characteristics of induced GBA provide\nevidence for an active, dynamic system capable of\nmaking predictions (i.e., anticipation), encoding metri\ncal patterns and recovering from unexpected stimuli.\nGBA appears to be a useful neuroelectric correlate\nof rhythmic expectation and may therefore reflect pulse\nperception. Due to the anticipatory nature of GBA, it\nmay be supposed there is an attentional dependence.\nFuture research should aim to manipulate attentional\nstate, localize neural sources and further probe the\nrole of induced GBA in meter perception.\nThursday, May 14, 2009\nCourtesy of University of Finance and Management, Warsaw. Used with permission.\n\nSyncopation - violation of metrical expectations\nImage removed due to copyright restrictions.\nDefinition of syncopation with some musical examples.\nFrom Jones, G. T. Music Theory. New York, NY: Barnes and Noble Books, 1974.\nMusic Theory, Thad. Jones\nThursday, May 14, 2009\n\nRhythmic streaming (segregation/fusion of rhythmic\n- African xylophone music\n- Timbre effects\n- Pitch difference\n- Competition of frequency separations\nThursday, May 14, 2009\n\nRhythmic elaboration -subdividing time intervals\nSmulevitch & Povel (2000) in Rhythm: Perception & Production, Desain & Windsor eds Diagram using a cube to illustrate the elaboration of a quarter note in terms of eight and sixteenth notes.\nFigure by MIT OpenCourseWare.\nThursday, May 14, 2009\n\nRhythmic\no\nHierarchy\nHandel\nSource: Handel, S. Listening: An Introduction t\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nCourtesy of MIT Press. Used with permission.\nThursday, May 14, 2009\n\nRhythmic Hierarchy\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nHandel\nCourtesy of MIT Press. Used with permission.\nThursday, May 14, 2009\n\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nCourtesy of MIT Press. Used with permission.\nHandel\nThursday, May 14, 2009\n\nPolyrhythms\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nHandel\nCourtesy of MIT Press. Used with permission.\nThursday, May 14, 2009\n\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nCourtesy of MIT Press. Used with permission.\nThursday, May 14, 2009\n\nPolyrhythms (polyrhythms:rhythm::polyphony:melody)\nSource: Handel, S. Listening: An Introduction to\nHandel\nThursday, May 14, 2009\nthe Perception of Auditory Events. Cambridge,\nMA: MIT Press, 1989.\nCourtesy of MIT Press. Used with permission.\nConlon Nancarrow\n\nRhythm & Grouping\n- Three examples from\n- Bregman & Ahad\n- Auditory Scene Analysis CD\n- African xylophone music\ninterference between rhythmic patterns\nseparation of patterns via pitch differences\nseparation of patterns via timbral diffs\n\nConflicting rhythms interfere unless the events\ncan be separated out in separate streams\nThursday, May 14, 2009\n\nMetrical vs. rhythmic phrases (rel. independence)\n(Snyder, Music & Memory)\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000. Courtesy of MIT Press.\nUsed with permission.\nThursday, May 14, 2009\n\nMajor points -- rhythm\nRhythm involves perception of temporal patterns of events\nRecurring patterns group into chunks that create expectations of\nfuture temporal occurences of events (rhythmic pattern\ninduction)\nRhythmic grouping occurs on the same timescale as\nmelodic grouping.\nWe also infer a metrical grid that involves a regular set of\ntimepoints (pulse, tatum) and a regular pattern of accented/\nunaccented events (meter). (Metrical induction)\nExpectations generated from rhythmic grouping and metrical\ninduction processes can be manipulated for tension-relaxation\neffect.\nThursday, May 14, 2009\n\nTime, memory, and anticipation\nImage of Salvador Dali's painting \"The Persistence of Memory\"\nremoved due to copyright restrictions.\nSee http://en.wikipedia.org/wiki/File:The_Persistence_of_Memory.jpg\nThursday, May 14, 2009\n\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000.\nCourtesy of MIT Press. Used with permission.\nTemporal integration windows\n(Snyder, Music & Memory)\nThursday, May 14, 2009\n\nn.\nTimescales\n& memory\n(Snyder, Music & Memory)\nSource: Snyder, Bob. Music and Memory.\nCambridge, MA: MIT Press, 2000.\nCourtesy of MIT Press. Used with permissio\nThursday, May 14, 2009\n\n)\nry.\nMemory\n& grouping\n(Snyder, Music & Memory\nSource: Synder, B. Music and Memo\nCambridge, MA: MIT Press,\n2000.Courtesy of MIT Press.\nUsed with permission.\nThursday, May 14, 2009\n\nMemory processes generate musical context\nTonality induction -- repetition of particular notes & sets of harmonics that\nestablishes a tonal expectation through which all subsequent\nincoming tonal patterns are processed -- establishment of the tonic\nRhythmic induction -- repetition of patterns of accented and unaccented\nevents that establishes a temporal pattern of expectation for\nsubsequent events\nBoth kinds of induction operate on similarities and contrasts between\nprevious and subsequent sounds & events\nOLD + NEW heuristic:\n1) OLD incoming patterns similar to previous ones build up\nthe images of previous ones, confirm +\nstrengthen expectations, create relaxation\n2) NEW different patterns create contrasts that violate\nexpectations established from previous inputs,\ncreate tension\n3) degree of contrast (distance in perceptual space) determines\nThursday, May 14, 2009\n\nTime, memory, and anticipation\nThursday, May 14, 2009\n\nTime\nWhat is time? Newtonian & Bergsonian time\nThe perception of time\nDuration, succession, and perspective\nRelativity of time\nConstant Weber fraction for time estimation\nAging & time perception (internal clocks slow down)\nDuration and event-density\nLearning & temporal prediction (anticipation)\nBrains as temporal prediction machines\nModels of time (interval) perception & production\nClock models -- accumulators (hourglass)\nOscillator models (pendulum)\nDelay-detectors and static representations of time\nRhythmic hierarchies, simple ratios, and groupings\nTemporal memory traces (delay loops, cyclochronism)\nThursday, May 14, 2009\n\nTime\n\"time...does not exist without changes.\" Aristotle, Physics, IV\nTime as an absolute world-coordinate (Newtonian time) vs. time as epistemic\nchange (psychological, Bergsonian time)\n\"A man in sound sleep, or strongly occupy'd with one thought, is insensible of time... Whenever we\nhave no successive peceptions, we have no notion of time, even tho' there be a real succession\nin the objects...time cannot make its appearance to the mind, either alone, or attended with a\nsteady unchangeable object, but is always discovered by some perceivable succession of\nchangeable objects.\" Hume as quoted in Fraisse, pp. 3-4\nMeasurement of time\nHow is time measured, psychologically, by the neural mechanisms and informational\norganizations that constitute our minds?\nThursday, May 14, 2009\n\nDuration\n60 BPM\nOur sense of the length of time (Fraisse, 1962, The Psychology of Time)\n152 BPM\nConstant Weber fractions for interval estimation\nErrors are proportional to the interval estimated\nWeber's law for timing; jnd's on the order of 8-12%\ndepending on modality (hearing, touch, vision)\nTemporal prediction of reward in conditioning\n(Scalar timing intimately related to the response latency in conditioning when interval\nbetween stimulus and reward are varied, see R. Church, A Concise Introduction to Scalar\nTiming Theory, 2003. See also Fraisse's (1963) discussion of Pavlov and Popov\ncyclochronism model)\nSome general observations (Fraisse via Snyder, Music & Memory):\nFilled time durations appear shorter than empty ones\nRate of novel events makes durations appear shorter\n(monotonous durations are experienced as longer, but remembered as shorter)\nAging: young children overestimate durations; older adults underestimate durations\n(A systematic change in internal timing mechanisms with age? cf absolute pitch)\nImplications for music: pieces with high event densities go faster; those\nwith low ones seem to take forever; duration is in the mind of the\nbeholder and his/her expectations\nThursday, May 14, 2009\n\nBeat\ninduction\nand\nduration\ndiscrimination\nWeber's\nLaw\nImage removed due to copyright restrictions.\nGraph illustrating Weber's Law. See Fig. 4.13 in Jones and Yee,\n\"Attending to auditory events: the role of temporal organization.\"\nIn Thinking in Sound. Edited by E. Bigand and S. McAdams.\nNew York, NY: Oxford University Press, 1993. ISBN: 9780198522577.\nThursday, May 14, 2009\n\nSuccession\nTime order:\nbefore and after (Fraisse, Snyder)\nOur recollection of time order\ndepends on memory mechanisms,\nhow distant in the past were the\nevents\nRepresentation of order in long-term\nmemory is poor\nLTM is massively parallel, not serial\nTime order within chunks is better\npreserved than between them\nPrimacy and recency: first and last\nelements in a chunk best\nremembered, most salient\nThursday, May 14, 2009\n\nPerspective: Past, present, future\nMediated by different psych/brain mechanisms\nPast: long term memory\nPresent: working memory\nFuture: anticipation, planning\nMusic (like sports) focuses our minds on the\npresent, on events that have occurred in the last\nfew seconds to minutes.\nThursday, May 14, 2009\n\nMechanisms of timing and temporal processing\n- Temporal contiguity models of learning\n- Clock models\n- Switched accumulator, e.g. hourglass\n- Explicit measurement of time durations\n- Ordering of durations by magnitude\n- Time delay detectors/generators\n- Array of tuned delay elements, detectors, oscillators\n- Explicit measurement of time durations; storage of patterns\n- Generators of time delays (timers)\n- Rhythmic hierarchies (Jones)\n- well-formed patterns create strong expectations\n- Temporal memory trace\n- Timeline of events stored in reverberating memory\n- Readout of events & (timing of) their consequences\nThursday, May 14, 2009\n\nTemporal expectations on different timescales\n- Pitch: repetitions on microtemporal\n\ntimescales (200 usec to 30 ms)\n- Infra-pitch: not well defined, repetitions\n\nwith periods 30-100 ms\n- Rhythms: patterns of individuated events\nwith periods 100 ms to several secs\n- Longer temporal expectations (> few secs)\nThursday, May 14, 2009\n\nMetrical and nonmetrical patterns (cf. tonal & atonal melodies)\nImage removed due to copyright restrictions.\nSee Fig. 4.8 in Jones and Yee, \"Attending to auditory events:\nthe role of temporal organization.\" In Thinking in Sound.\nEdited by E. Bigand and S. McAdams. New York, NY:\nOxford University Press, 1993. ISBN: 9780198522577.\nJones & Yee,\nAttending to auditory events:\nthe role of temporal organization\nin Thinking in Sound\nThursday, May 14, 2009\n\nTemporal reproductions are better for well-formed temporal patterns\nImage removed due to copyright restrictions.\nSee Fig. 4.9 in Jones and Yee, \"Attending to auditory events:\nthe role of temporal organization.\" In Thinking in Sound.\nEdited by E. Bigand and S. McAdams. New York, NY:\nOxford University Press, 1993. ISBN: 9780198522577.\nThursday, May 14, 2009\n\nHigher-order (longer-range) metrical patterns\nImage removed due to copyright restrictions.\nSee Fig. 4.7 in Jones and Yee, \"Attending to auditory events:\nthe role of temporal organization.\" In Thinking in Sound.\nEdited by E. Bigand and S. McAdams. New York, NY:\nOxford University Press, 1993. ISBN: 9780198522577.\nThursday, May 14, 2009\n\nHierarchical & nonhierarchical ratios of event timings\nImage removed due to copyright restrictions.\nSee Fig. 4.10 in Jones and Yee, \"Attending to auditory events:\nthe role of temporal organization.\" In Thinking in Sound.\nEdited by E. Bigand and S. McAdams. New York, NY:\nOxford University Press, 1993. ISBN: 9780198522577.\nThursday, May 14, 2009\n\nClock & hierarchical models of beat perception\nImage removed due to copyright restrictions.\nSee Fig. 4.11 in Jones and Yee, \"Attending to auditory events:\nthe role of temporal organization.\" In Thinking in Sound.\nEdited by E. Bigand and S. McAdams. New York, NY:\nOxford University Press, 1993. ISBN: 9780198522577.\nThursday, May 14, 2009\n\nMechanisms of timing and temporal processing\n- Temporal contiguity models of learning\n- Clock models\n- Switched accumulator, e.g. hourglass\n- Explicit measurement of time durations\n- Ordering of durations by magnitude\n- Time delay detectors/generators\n- Array of tuned delay elements, detectors, oscillators\n- Explicit measurement of time durations; storage of patterns\n- Generators of time delays (timers)\n- Rhythmic hierarchies (Jones)\n- well-formed patterns create strong expectations\n- Temporal memory trace\n- Timeline of events stored in reverberating memory\n- Cylcochronism (Popov, see Fraisse, memory store is itself temporal)\n- Readout of events & (timing of) their consequences\nThursday, May 14, 2009\n\nWarren:\nHolistic &\nanalytic\nsequence\nrecognition\nholistic:\ntemporal\ncompounds\n(cohere into\nunified\npatterns)\nanalytic:\nexplicit ID\nof elements\nand orders\nImage removed due to copyright restrictions.\nSee Fig. 3.2 in Warren, \"Perception of acoustic sequences:\nglobal integration vs. temporal resolution.\" In Thinking in Sound.\nEdited by E. Bigand and S. McAdams. New York, NY: Oxford University\nPress, 1993. ISBN: 9780198522577.\nThursday, May 14, 2009\n\nTimescale similarities & differences of temporal processing\n- On all timescales:\n- mechanisms for internalizing timecourses of\nevents, for building up temporal patterns\n- Differences between timescales\n- Pitch: support of multiple patterns (pitch\nmechanism low harmonics) => temporal\n\"transparency\", non-interference\n- Rhythm: interference between patterns unless\nseparated into different streams\n- another way of thinking about this is that for\nrhythm stream formation mechanism is not based\non periodicity alone\nThursday, May 14, 2009\n\nLickliders (1951) duplex model of pitch perception\nTime-delay nets\nLickliders binaural triplex model\nImage removed due to copyright restrictions.\nSchematic\nmodel of the\nc\nochlea.\nJ.C.R. Licklider (1959) \"Three\nAuditoryTheories\" in Psychology: A Study\nof a Science, Vol. 1, S. Koch, ed., McGraw-\nHill, pp. 41-144.\nFigure by MIT OpenCourseWare. Diagram of a neuronal autocorrelator.\nFigure by MIT OpenCourseWare.\nThursday, May 14, 2009\n\nS (t)\ntwo sets\nFEED-FORWARD TIMING NETS\nRECURRENT TIMING NETS\n- Temporal sieves\n- Build up pattern invariances\n- Extract (embedded) similarities\n- Detect periodic patterns\n- Multiply autocorrelations\n- Separate auditory objects\nNeural timing nets\nRelative delay\nTime\nt\nSj(t)\ni\nSi(t) Sj(t - )\nindividual\nmultiplicative\nterm\nSi(tm) Sj(tm - t)\n\nconvolution\ntime-series\nterm m\nof input\nspike trains\nInput time sequence\nAll time delays present\nCoincidence\nunits\nDirect inputs\nRecurrent,\nindirect inputs\nTime patterns reverberate\nt\nhrough delay loops\nThursday, May 14, 2009\n\nIs a time-domain strategy possible?\nEffect of different F0s in the time domain\nVowel [ae]\nF0 = 100 Hz\nVowel [er]\nF0 = 125 Hz\nDouble vowel\n[ae]+[er]\nTime (msec)\nThursday, May 14, 2009\n\nAuditory \"pop-out\"\nphenomena suggest\na period-by-period\ntransient\ndisparity\nLast 2 periods - first 2\nongoing\ndisparity\nThursday, May 14, 2009\n\nFigure by MIT OpenCourseWare. Schematic representation of a delay loop matched filter.\nThursday, May 14, 2009\n\nDetection of arbitrary periodic patterns\nPeriodic patterns invariably build up in\ndelay loops whose recurrence times equals\nthe period of the pattern and its multiples.\nInput pattern\n1010110010110101100101101011001011010...\n1 = 11 ms = recurrence time\nof input pattern10101100101\nThursday, May 14, 2009\n\nSchematic representation of a dela\ny loop matche\nd filter.\nFigure by MIT OpenCourseWare.\nThursday, May 14, 2009\n\nRecurrent\ntiming net\nwith single\nRevised buildup rule:\nMin(direct, circulating)\nplus a fraction of their\nabsolute difference\nSource: Cariani, P. \"Neural Timing Nets.\"\nNeural Networks 14 (2001): 737-753.\nCourtesy Elsevier, Inc.,\nhttp://www.sciencedirect.com.\nUsed with permission.\nThursday, May 14, 2009\n\nError-adjustment rule:\nH(t) = H(t-tau) + Btau[X(t)-H(t-tau)]\nLoop-dependent scaling of adj rate:\nBtau = tau/33 ms\nThursday, May 14, 2009\n\nThursday, May 14, 2009\n\nThursday, May 14, 2009\n\nThursday, May 14, 2009\n\nThursday, May 14, 2009\n\nTonal & rhythmic contexts\nTonality induction:\nestablishment of a tonic\nestablishment of tonal system: key, mode, set of pitches\nestablishment of harmonic relations\nWestern tonal music:\nRelations of notes to the tonic\nRelations of notes to the triad that defines the key (I)\nharmonic center\nRelations of chords to I triad & tonic -- chord progressions\nDistance in perceptual similarity\nTension-resolution + movement between the two\nRelations of different keys and key modulations\nMovements between keys, tension-resolution, larger\nstructures & rhythms of harmonic movement\nThursday, May 14, 2009\n\nBuild-up and separation of two auditory objects\nTwo vowels with different fundamental frequencies (F0s) are added together\nand passed through the simple recurrent timing net. The two patterns build up\nIn the delay loops that have recurrence times that correspond to their periods.\nTime (msec)\nVowel [ae]\nF0 = 100 Hz\nPeriod = 10 ms\nVowel [er]\nF0 = 125 Hz\nPeriod = 8 ms\nCharacteristic delay channel (ms)\nTime (ms)\nThursday, May 14, 2009\n\nFragment from G. Ligeti's Musica Ricercata\n-1\n1 Signal rms envelope\n0.5\n9 sec\nThis image is from the article Cariani, P. \"Temporal Codes, Timing Nets, and Music Perception.\"\nJournal of New Music Research 30, no. 2 (2001): 107-135. DOI: 10.1076/jnmr.30.2.107.7115.\nThis journal is available online at http://www.ingentaconnect.com/content/routledg/jnmr/\nThursday, May 14, 2009\n\nFragment from G. Ligeti's Musica Ricercata\n-1\nSignal rms envelope\n9 sec\n0.5\nAutocorrelogram\nTIme re: signal onset (samples)\nRecurrent timing net\nTIme re: signal onset (samples)\nThis image is from the article Cariani, P. \"Temporal Codes, Timing Nets, and Music Perception.\"\nJournal of New Music Research 30, no. 2 (2001): 107-135. DOI: 10.1076/jnmr.30.2.107.7115.\nThis journal is available online at http://www.ingentaconnect.com/content/routledg/jnmr/\nThursday, May 14, 2009\n\nTIme re: signal onset (samples)\nProfile of mean signal values in delay channels\nProfile of std. deviations in delay channels\nAutocorrelogram\nDelay (samples)\nDelay (samples)\nDelay (samples)\nThis image is from the article Cariani, P. \"Temporal Codes, Timing Nets, and Music Perception.\"\nJournal of New Music Research 30, no. 2 (2001): 107-135. DOI: 10.1076/jnmr.30.2.107.7115.\nThis journal is available online at http://www.ingentaconnect.com/content/routledg/jnmr/\nThursday, May 14, 2009\n\nAutocorrelogram\nLigeti envelope (fragment end)\nProfile of mean signal values in delay channels\nLoop delay = 88\n32 0\nDelay (samples)\nRecurrent timing net\nLoop delay = 134\n1.5\nLoop delay = 178\nTime (samples)\n0.5\nDelay channel (samples)\nTime (samples)\nResponse of a recurrent timing network to the\nLigeti\nfragment.\nH( j,i +j) =\nmax (X( 1,i ), X(\n1,i )*H(\nj,i )*(1+j/100)) where X is the in\nenvelope of the Ligeti fragment, and H is the value of the signal in delay loop j (firs\nindex) at time t (second index). The buildup factor (1+j/100) depends on the duration\nof the delay loop (i.e. equal to j samples). The mean signal value H in the delay\nchannels over the last 200 samples (thicker line) and over the whole fragment (thin\nline) are shown in the top right line plot. The waveforms that are built up in the three\nmost activated delay loops are shown above. The results, not surprisingly resemble\nthose obtained with the running\nautocorrelation.\nThe sampling rate of the\nsignal was approximately 10 Hz.\nThis image is from the article Cariani, P. \"Temporal Codes, Timing Nets, and Music Perception.\"\nJournal of New Music Research 30, no. 2 (2001): 107-135. DOI: 10.1076/jnmr.30.2.107.7115.\nThis journal is available online at http://www.ingentaconnect.com/content/routledg/jnmr/\nThursday, May 14, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Systems of pitch relations: Scales, tunings and notations",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/3045ff24f18fb715e2f65f4fe7a3fe56_MITHST_725S09_lec09_scales.pdf",
      "content": "Systems of pitch relations:\nScales, tunings and notations\nThursday, May 14, 2009\nHST.725: Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nWhat are scales, and why do we have them?\n- Systems of discrete pitches & intervals between them\n- Determine tonal systems\n- Wide variety of scales in the world\n- Octaves, fifths, & fourths very common\n- Numbers of notes:\n- pentatonic (5 notes/octave)\n- diatonic (7 notes/octave)\n- chromatic (12 notes/octave)\n- \"microtonal\" (from Western perspective, > 12 notes/octave)\n- Arab music (24-TET), 31-TET\n- Possible reasons for numbers of notes (72)\n- although musicians & listeners easily keep track of more\nThursday, May 14, 2009\n\nScales: which intervals are included, sequence of intervals\n- Scales have reference points (first note in a scale)\n\ntonic, key, frame of reference, often first note played\n\naction of auditory short-term memory & relative pitch\n- Ordering of musical intervals within the scale\n- Modes (Greek or ecclesiastical modes)\n- Major scale pattern T-T-S-T-T-T-S (T whole tone, 12%, S semitone 6%)\n- Minor scale pattern: T-S-T-T-S-T-T\n- Note same sets of intervals in related major & minor scales that use\nsame notes (C major, A minor), and interval sets but w. different interval\nrelationships to the tonic\n- Circle of fifths: which scales share the same notes,\n- therefore have many common harmonics & subharmonics\n- and are therefore related in pitch space; distance reflects difference\n- Ascending vs. descending intervals\n- Scale notes vs. expressive deviations from them (\"ornaments\")\nThursday, May 14, 2009\n\nNote similarity/compatibility and contrast as a basis for scale\nTonal hierarchy\nof similarity relations\nThursday, May 14, 2009\nC\no\nn\nic\nal\nr\nep\nre\ns\ne\nn\nt\na\nt\ni\no\nn\n\no\nf\n\ntonal hierarchy of the 12-tone set for the key of C (after Krumhansl, 1979).\nFigure by MIT OpenCourseWare.\nDiagram showing how scale establishes pa\nr\nti c\nul a\nr\ni\nn\ntr\na\n- a\nnd inter-key relationships, inc\nluding tonic/dominant and circ\nle of fifths.\nFigure by MIT OpenCourseWare.\n\nTuning systems and scales\nWe will discuss tuning systems first, then scales,\nbut the two are interrelated and affect each other.\nThursday, May 14, 2009\n\nDesign constraints: What intervals to include?\n\nHow many notes in the scale?\nPresence of human voices (tendency for just intervals)\nContrast: similar and dissimilar notes (re: tonic)\nSmall numbers of notes (recognizability)\nChoice of note combinations: consonance, roughness\nMusical instruments available\n\nThursday, May 14, 2009\n\nDesign constraints: What intervals to include?\n\nHow many notes in the scale?\nMusical instruments and scale systems\nMake specialized tunings possible\n\nTechnology to implement tunings (logarithms)\nVersatility, compatibility w. other instruments\nAbility to sound reasonably good in all keys\nEqual temperament (log ratios)\n(beginning late 16th with Vincenzo. Galileo, Zhu Zaiyu, China)\nNon-equal temperament produces \"colors\" or \"moods\"\nfor different keys (for better or worse)\nThursday, May 14, 2009\n\nPythagorean ratios\nImages removed due to copyright restrictions.\nFigure 2-5 and 2-6 in Pierce, John R. The Science of Musical Sound.\nRevised ed. New York, NY: W. H. Freeman, 1992.\nFigure 2-5. Greek citharis. The cithara\nwas sacred to Apollo.\nPierce, The Science of Musical Sound\nFriday, March 13, 2009\n\nMathematics, numerology\nmusic, and mysticism\nDrawn by Robert Fludd, the Monochord\ninvented\nby\nPythagoras,\nshowing\ncorrespondences between pitch, proportion\nand\nastral\nbodies.\nhttp://\nwww.elodielauten.net/concept.html\nThursday, May 14, 2009\n\ngle\nox,\nor\na\nch,\nter\nas\nthe\new\nent\nin,\ntific\nas\nws\nins\n\nMonochords & tuning\nThe monochord consisted of a sin\nstring stretched over a sound b\nwith the strings held taut by pegs\nweights on either end. It used\nmoveable bridge to change pit\nand was usually plucked. A la\ninstrument of the same principle w\nplayed with a bow, called\n\"trumpet marine\" (Adkins, N\nGrove). It was used as an instrum\nas early 300 BC by Euclid (Rip\nNew Grove), and as a scien\ninstrument by Pythagoras as early\nthe 6th century BC No one kno\nwhen it first appeared, as its orig\nextend into prehistory.\nCourtesy of Jeff Cottrell. Used with permission.\nThursday, May 14, 2009\n\nScales begin with musical practice --\nwhat sounds best is the criterion for a good scale\ndoes it give the composer a beautiful palette of notes?\n11th century: Guido of Arezzo (fl.\n~991/2-1033). \"By laying out the\nnotes of a scale on a monochord,\nhe was able to teach choir boys\nhow to sing chant and also to\nImages removed due to copyright restrictions.\ndetect incorrect chanting. The\nFigure 2-6 in Pierce, John R. The Science of Musical Sound.\ntones intervals used in chants\nRevised ed. New York, NY: W. H. Freeman, 1992.\nwere M2, m2, m3, P4, and P5.\nThese six intervals were the\n\"consonantiae\", and (according to\nGuido) no chant uses any other\nintervals. Guido admits one could\nfind more on the monochord if\n\"art (did not) restrain us by its\nauthority\" (Palisca).\" Cottrell,\nHistory of the Monochord\nCourtesy of Jeff Cottrell. Used with permission.\nThursday, May 14, 2009\n\nNote similarity/compatibility as a basis for scale\nInclude just ratios (voices)\nK & K psychophysical data (circles)\nMinimize clashing of\ntones, i.e. roughness\nImage removed due to copyright restrictions.\nMax fusion\nKameoka, A., and M. Kuriyagawa. \"Consonance Theory I.\n(Sethares: optimize spectrum\nConsonance of Dyads.\" J Acoust Soc Am 45 (1969): 1451-1459.\n\nfor tunings to min beating e.g.\n10-TET)\nProvide contrast\nbetween consonant &\ndissonant relations\nSystematicity: allow for\nchord/key modulations\nThursday, May 14, 2009\n\nSome history of tuning systems (consult Wikipedia, many books for more)\nJust tuning -- ancient & folk traditions, integer ratios\nPythagorean tuning -- pre-Renaissance, fifths & octaves\nMeantone temperament -- Renaissance, tempered fifths\nWell-temperament - Baroque, \"moods & colors\" of keys\nSome keys more out of tune, Bach, Tartini advocates\nEqual-temperament (12-TET)\nCommon Practice Period of Western music (~1600-1900)\nVincenzo Galileo (1581)\nAncient China (7-TET), and Zhu, Zaiyu (12-TET,1584)\nThursday, May 14, 2009\n\nEarly tuning systems\nPythagorean &\nJust tuning systems\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. MIT Press, 1989.\nThursday, May 14, 2009\n\nSome history of tuning systems (consult Wikipedia, many books for more)\nTwelve tone equal temperament took hold for a variety of\nreasons.\nIt conveniently fit the existing keyboard design, and was a\nbetter approximation to just intonation than the nearby\nalternative equal temperaments.\nIt permitted total harmonic freedom at the expense of just a\nlittle purity in every interval.\nThis allowed greater expression through enharmonic\nmodulation, [a means of shifting between keys using chords\nthat are shared by two keys].... Equal temperament became\nthe standard gradually during the Romantic era.\nThursday, May 14, 2009\n\nDesigning a scale system - 12 equally tempered notes/oct.\nThursday, May 14, 2009\n\nProblems that tuning creates and solves.... (Wikipedia, Musical temperament)\n\"Just intonation has the problem that it cannot modulate to a different key (a very\ncommon means of expression throughout the Common practice period of music)\nwithout discarding many of the tones used in the previous key, thus for every key\nthe musician wishes to modulate to, the instrument must provide a few more\nstrings, frets, or holes for him or her to use. When building an instrument, this can\nbe very impractical.\nWell temperament is the name given to a variety of different systems of\ntemperament that were employed to solve this problem, in which some keys are\nmore in tune than others, but all can be used. This phenomenon gives rise to\ninfinite shades of key-colors, which are lost in the modern standard version: 12\ntone equal temperament (12-TET). Unlike Meantone temperament, which alters\nthe fifth to temper out the Syntonic comma, 12-TET tempers out the Pythagorean\ncomma, thus creating a cycle of fifths that repeats itself exactly after 12 steps.\nThis allowed the intervals of Tertian harmony, thirds and fifths, to be fairly close to\ntheir just counterparts (the fifths almost imperceptibly beating, the thirds a little\nmilder than the Syntonic beating of Pythagorean tuning), while permitting the\nfreedom to modulate to any key and by various means (e.g. common-tone and\nenharmonic modulation, see modulation). This freedom of modulation also\nallowed substantial use of more distant harmonic relationships, such as the\nNeapolitan chord, which became very important to Romantic composers in the\n19th century.\"\nThursday, May 14, 2009\n\nC-Major diatonic scale\nThursday, May 14, 2009\nD\ni\na\ng\nr\na\nm\nof one octave, C-C, of a piano keyboard.\nFigure by MIT OpenCourseWare.\n\ndiatonic\nscale\nThursday, May 14, 2009\nD\ni\na\ng\nr\na\nm\nof one octave, C-C, of a piano keyboard.\nFigure by MIT OpenCourseWare.\n\nDiatonic scale\n\"In Music theory, the diatonic major scale is a fundamental building block of the\nWestern musical tradition. The diatonic scale is composed of two tetrachords\nseparated by intervals of a whole tone. The pattern of intervals in semitones is as\nfollows 2-2-1-2-2-2-1. The major scale begins on the first note and proceeds by\nsteps to the first octave. In solfege, the syllables for each scale degree are \"Do-Re-\nMi-Fa-Sol-La-Ti-Do\". The natural minor scale can be thought of in two ways, the first\nis as the relative minor of the major scale, beginning on the sixth degree of the scale\nand proceeding step by step through the same tetrachords to the first octave of the\nsixth degree. In solfege \"La-Ti-Do-Re-Mi-Fa-Sol.\" Alternately, the natural minor can\nbe seen as a composite of two different tetrachords of the pattern 2-1-2-2-1-2-2. In\nsolfege \"Do-Re-Mi-Fa-Sol-La-Ti-Do.\" All of non-folk Western harmony from the some\npoint in the late Renaissance up to the late nineteenth century is based upon these\ntwo objects and the unique relationships created by this system of organizing 7\nnotes. It should be kept in mind that most pieces of music change key, and thus\nscale, but are still related to the beginning diatonic scale. The white keys on a piano\ncorrespond to the diatonic scale of C major (C-D-E-F-G-A-B-C), with the notes a\nwhole tone apart, except for E-F and B-C, which is an interval of a semitone (half a\ntone). Diatonic comes from the greek \"diatonikos\" or \"to stretch out\". It is\nsometimes used to refer to all the modes, but is generally used only in reference to\nthe major and minor scales.\"\n-- Wikipedia\nThursday, May 14, 2009\n\nThree tuning systems\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction to the\nPerception of Auditory Events. MIT Press, 1989.\nThursday, May 14, 2009\n\nNote F0 frequencies\nEqually-tempered scale\nTable removed due to copyright restrictions.\nFrequencies of notes in tempered scale.\nThe subscripts indicate octave\n(register). Note that the octave\nboundaries are at C, not A\nThursday, May 14, 2009\n\nJust Intonation Network\nhttp://www.justintonation.net/\nThursday, May 14, 2009\nText description of just intonation and musical examples removed due to copyright restrictions.\n\nJust intonation -- conclusions\n- Although differences between just and\nequally-tempered tunings might not be\ndiscriminable when notes are presented\nsequentially (as for measuring JNDs),\n- these differences can become apparent\nwhen notes are sounded together.\n- The differences are somewhat subtle,\nbut are most obvious when the notes\nare sustained harmonic complexes, e.g.\norgan-like.\nThursday, May 14, 2009\n\nMicrotonal music\n- http://infohost.nmt.edu/~jstarret/microtone.html\n- \"Most of the music we hear in based on a system\ncalled 12 tone equal temperament (or 12TET\nfor short), where the octave is divided into 12\nequal parts. Microtonal music is generally\ndefined as any music that is not 12TET. Some\nfolk musics are based on the harmonic series,\nsome divide the octave into 19 or 31 equal\nparts, some divide the octave into 43 unequal\nparts, some don't divide the octave at all....\nThere are an infinite number of ways to choose\nyour tonal resources.\"\nsee also http://www.corporeal.com/cm_main.html\nThursday, May 14, 2009\n\nBill Sethares:\n1. Relations between\ntuning systems & dissonance:\nFor inharmonic\ninstruments, there are situations\nwhere just tunings sound more\ndissonant. (His explanation for\nGamelan tunings)\nBook cover image removed due to copyright\nrestrictions.\nSethares, W. A. Tuning, Tibre, Spectrum, Scale.\n2. Experiments with\nalternate scales and\ntunings -- 10 TET music.\n\"Ten Fingers: If God had intended us to play\nin ten tones per octave, he would have given\nus ten fingers.\"\nThursday, May 14, 2009\n\nHarry Partch\n-\nHarmonic Canons: there are two types. The simpler\ntype is Harmonic Canon II; these box-like instruments\nhave 44 strings and adjustable bridges which are\nuniquely configured for each piece. Harmonic Canon I\nhas two planes of 44 strings each. The planes intersect\nnear the middle of each string and thus the player may\nplay on either plane or both at once. Also a moveable\npyrex rod controls the pitch on some strings in one\nplane. The harmonic canons are both melody\ninstruments and as providers of the harmonic\nunderpinning, hence its name, canon, used in the sense\nof \"law\". It is played with picks or fingers and is strikingly\nused in cascades of pitches. Partch built his first canon\nin 1945, and continued to refine the instrument into the\nhttp://www.newband.org/instruments.htm#partch%20instruments\nThursday, May 14, 2009\nPhotos by Bob Vergara, A.P.S. Used with permission.\n\nHistory of scales\nPentatonic (5-note), heptatonic scales\nDiatonic scales (Western tradition, 7 notes, \"heptatonic\")\nEcclesiastical modes (traditional & medieval church music)\nCommon practice period (1600-1900) streamlined scale\nsystems to two modes, Ionian (major scale) and Aeolian\n(minor scale), for reasons that may have to do with the\ndifficulties of harmonic construction (e.g. in modulating\nbetween keys).\nWe will discuss major and minor scales first, then modal\nscales.\nThursday, May 14, 2009\n\nMajor and minor scales\n-Major scale pattern:\n-T-T-S-T-T-T-S\n-Minor scale pattern:\n-T-S-T-T-S-T-T\nCourtesy of MIT Press. Used with permission.\nSource: Handel, S. Listening: An Introduction to\nthe Perception of Auditory Events. MIT Press, 1989.\nThursday, May 14, 2009\n\nKey relations\nof diatonic scales\nin terms of\nshared notes\nMajor scales\n& minor scales\nsharing same notes\nEach step around the\ncircle is a change of 1\nnote in common.\nDistance around the\ncircle is a measure of\nkey distance\nCircle\nof\nFifths\nSource: Wikipedia.\nThursday, May 14, 2009\n\nNote relatedness, distance\nfrom each other\nfrom the tonic\nThursday, May 14, 2009\nC\no\nn\nic\nal\nr\nep\nre\ns\ne\nn\nt\na\nt\ni\no\nn\n\no\nf\n\ntonal hierarchy of the 12-tone set for the key of C (after Krumhansl, 1979).\nFigure by MIT OpenCourseWare.\n\nModes show the effects of different scale types\nScarborough Fair/Canticle\nSimon&Garfunkel\nhttp://www.8notes.com/articles/modes/\nMusical example removed due to copyright restrictions.\nGaillarde I-II-II\nConvivum Musicum Gothenburg\nThursday, May 14, 2009\n\nModes\nMajor scale\nMinor scale\nThursday, May 14, 2009\n\nnt modes\nC Major scale\ninor scale\nWhy do they sound different, despite the same note set?\nBecause the notes have different patterns of relations to\nthe tonic, and particular musical intervals may be present\nor absent from a given modal scale.\n\"Happy Birthday\" in differe\nThursday, May 14, 2009\nA M\nSource: Wikipedia.\n\nHow would we distinguish C-major from A-minor key\n(or any of the other modes below, for that matter)\nif they have the same note set?\nEstablishment of the tonic, and its consonant intervals.\nC Major scale\nA Minor scale\n-Minor scale pattern:\n-T-S-T-T-S-T-T\n-Major scale pattern:\n-T-T-S-T-T-T-S\n-T-S-T-T-T-S-T\nS-T-T-T-S-T- T-\nT-T-T-S-T- T-S\nT-T-S-T-T-S-T\nNo 4th\nTritone\n4th & 5th\nNo tritone\nThursday, May 14, 2009\n\nCourtesy of Ed Friedlander.\nhttp://www.pathguy.com/modes.htm#phrypara\nLydian mode\nexample\nThursday, May 14, 2009\n\nCourtesy of Ed Friedla\nhttp://www.pathguy.com/modes.ht\nnder.\nm#phrypara\nPhrygian\nmode\nThursday, May 14, 200\n\nAn \"exotic\" mode\n\"The Answer is Dark\" is an example of one of those\nmore exotic modes. It's in a mode of a scale that uses\n3 half-step intervals, causing one interval to be an\naugmented second. In the chart below, the bottom line\ndesignates the type of interval between each member\nof the scale where: h = half step a = augmented whole\nstep w = whole step\nG# A B# C# D# E# F# G#\nh a\nh\nw\nw h\nw\ni.e. S,T+,S,T,T,S,T\nListen to a MIDI file of the scale mode:\nIt would be in G# Mixolydian except that the A# has been lowered\nto A.\nThis is sometimes called a \"mixed mode\" because it has\ncharacteristics of two diatonic modes.\nhttp://www.elvenminstrel.com/tolkien/modes.htm\nThursday, May 14, 2009\n\nModes (Reference slide)\nAccording to the nomenclature of medieval music theorists, who were dealing largely with unchorded plainsong, our natural major is\nthe church \"Ionian Mode\" (C-D-E-F-G-A-B-C), and our natural minor is the church \"Aeolian mode\" (C-D-D#-F-G-G#-A#-C). I became\ncurious about modes when I learned that \"Wreck of the Edmund Fitzgerald\" and \"Scarborough Fair\" use the old balladic scale\nwhich matches the church \"Dorian Mode\" (C-D-D#-F-G-A-A#-C). I used the eerie church \"Mixolydian mode\" (C-D-E-F-G-A-A#-C) for\nmy intranet version of \"The Pathology Blues\", on our quizbank. You can also hear the church \"Mixolydian mode\" in \"The Beat Goes\nOn\", \"Luck Be a Lady Tonight\", \"Norwegian Wood\", \"Day Tripper\", \"Sundown\" (Gordon Lightfoot), \"Cats in the Cradle\", \"City of New\nOrleans\" (verse but not chorus), and the theme to \"Star Wars\".\nCaedmon recordings used it for the tune for the mystical first song\nin Yeats's play \"The Only Jealousy of Emer\". The other church modes are novelties at best. Some of the old Gregorian chant \"Sing\nmy tongue...\" seems to be Phrygian mode. There is some of the church \"Phrygian mode\" in \"Fiddler on the Roof\", and if the song is\nfully transposed into the church Phygian mode, it still sounds okay. My own attempt to write a song using the church Phrygian mode\nwas dismal. I wrote a little song in an unabashed church \"Lydian mode\". The mode itself suggested the subject. Unless you only use\nthe subdominant as a leading tone for the dominant, any melody you write in this \"mode\" will be unnerving -- the subdominant is\nequidistant from the lower and upper tonics. A correspondent pointed out that the \"Lydian\" mode makes up some of the \"Jetsons\"\nand \"Simpsons\" theme. Bartok wrote a short piece in the Lydian mode .In the Locrian mode, the dead-center position of the dominant\nmakes this even more unmusical. A music professional told me once that no ethnomusicologist has ever documented a folk tune in\nwhat medieval theorists called the \"Locrian mode\". I browsed a little in Plato, Aristotle, pseudo-Plutarch's \"De Musica\", and of course\nthe Oxford History of Music,\nand came away wondering if the medieval music theorists (Boethius, Gregory the Great, their\nsuccessors) really meant the same thing as did the Greeks who named the modes. Today most people (following a scholar named\nWestphal)\ntell us that the Greek modes were indeed used as \"scales\" with the tonic notes being the low-pitched one, just as the\nchurch mode theorists say. This seems to be based on statements in Plato and Aristotle that the modes had distinct emotive\nqualities, as our major and minor scales do. Another school of thought (that of Munro) claims that for the ancients, the modes were\nactually keys, i.e., you could play any melody in any mode. If this is true, then the ancient Greeks had either perfect pitch or a\nstandard pitchpipe. I think people have probably liked similar tunes in different eras. I tried to figure out how the ancient Greeks\nwould have played some of our favorites. Ancient Greek lyres typically had seven strings. (Some Hebrew lyres must have had ten\nstrings -- see Psalm 33.) The system of modes is also called \"harmoniae\", which meant \"fitting\" or \"tuning\". Greek writers on music\ntalk about the normal tuning comprising two tetrachords, i.e., a series of four notes with the lowest and highest separated by a major\nfourth and sharing the center string. Pythagoras and Terpander are both credited with the idea of having the highest string be an\noctave of the lowest string.\nhttp://www.pathguy.com/modes.htm\nCourtesy of Ed Friedlander.\nThursday, May 14, 2009\n\nScala (Program for calculating scales)\nScala is a freeware software application for experimenting with musical tunings.\nSee http://www.huygens-fokker.org/scala/\nThursday, May 14, 2009\n\nModes\nWhat are Modes of a Scale?\n\"A modal melody is one that is not in a \"key\" of the major or mi\nsort common in music of the Western world in the past 300 to 4\nyears.\nInstead, its scale may be comprised of almost any set\ntones, not only those that imply 3-part harmony. In fact, generall\nshould not imply 3-part harmony and a bass line. Many of the mo\nmelodies I like best are virtually impervious to triadic harmonizati\nThere are two common types of modal scales: pentatonic a\nheptatonic, meaning 5-tone and 7-tone, respectively.\nFolk mu\nfrom many parts of the world, including Celtic, American, African, a\nChinese, often use modes of pentatonic scales.\"\nListen to a MIDI file of two pentatonic modes:\nnor\nof\ny it\ndal\non.\nnd\nsic\nnd\nhttp://www.elvenminstrel.com/tolkien/modes.htm\nThursday, May 14, 2009\n\nImportant points\n- Scales are anchored pitch systems\n- The anchor is the tonic, first note in the scale\n- The pitch intervals of the notes re: the tonic\ngive the scale its characteristic tonality\n- Scales include both consonant and dissonant\nintervals that provide tonal contrast.\n- Equal temperament tuning systems use logarithmic\nfrequency spacings to achieve systematicity\n(equality of keys good for key modulations).\n- The 12-TET system represents just frequency ratios\n(2:1, 3:2, 4:3, 5:4, 5:3) fairly well -- important\nbecause of consonance, fusion, pitch stability.\nThursday, May 14, 2009\n\nBalance between consonance and dissonance\n\nstability and uncertainty\ntension and relaxation\n\"As Frank Zappa explained it, \"The creation and\ndestruction of harmonic and 'statistical' tensions is\nessential to the maintenance of compositional drama. Any\ncomposition (or improvisation) which remains consistent\nand 'regular' throughout is, for me, equivalent to watching\na movie with only 'good guys' in it, or eating cottage\ncheese.\"[2] In other words, a composer cannot ensure a\nlistener's liking by using exclusively consonant sounds.\nHowever, an excess of tension may disturb the listener.\nThe balance between the two is essential.\" (Wikipedia)\nThursday, May 14, 2009\n\nReading/assignment for next meeting\nBook reviews due TODAY\nHarmonics & Scales Problem set due next MONDAY.\n- We will do Harmony & Melody next time.\n- Reading:\n- You may find Wikipedia entries on consonance and\ndissonance, melody and harmony useful.\n- Do read Chapters 8 & 9 in Aiello on melody (Butler\n& Brown) and tonal expectancies (Bharucha).\n- Handel, Chapter 10, \"Grammars of music and\nlanguage\" on Blackboard also covers similar\nterritory.\nThursday, May 14, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Timbre perception",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/2635f0c55b5361b9c3d9f333436f1d75_MITHST_725S09_lec07_timbre.pdf",
      "content": "Timbre perception\nwww.cariani.com\nFriday, March 13, 2009\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\noverview\nRoadmap\nfunctions of music\nsound, ear\nloudness & pitch\nbasic qualities of notes\ntimbre\nconsonance, scales & tuning\ninteractions between notes\nmelody & harmony\npatterns of pitches\ntime, rhythm, and motion\npatterns of events\ngrouping, expectation, meaning interpretations\nmusic & language\nFriday, March 13, 2009\n\nWikipedia on timbre\nIn music, timbre (pronounced /tm-br'/, /tm.br/ like tamber, or /\ntm(br)/,[1] from Fr. timbre tb) is the quality of a musical note or\nsound or tone that distinguishes different types of sound production,\nsuch as voices or musical instruments. The physical characteristics of\nsound that mediate the perception of timbre include spectrum and\nenvelope. Timbre is also known in psychoacoustics as tone quality or\ntone color.\nFor example, timbre is what, with a little practice, people use to\ndistinguish the saxophone from the trumpet in a jazz group, even if both\ninstruments are playing notes at the same pitch and loudness. Timbre\nhas been called a \"wastebasket\" attribute[2] or category,[3] or \"the\npsychoacoustician's multidimensional wastebasket category for\neverything that cannot be qualified as pitch or loudness.\"[4]\nFriday, March 13, 2009\n\nTimbre ~ sonic texture, tone color\nPaul Cezanne, Apples, Peaches, Pears, and Grapes c. 1879-80); Oil on canvas, 38.5 x 46.5 cm; The Hermitage, St. Petersburg\nFriday, March 13, 2009\nPaul Cezanne. \"Apples, Peaches, Pears and Grapes.\" Courtesy of the iBilio.org WebMuseum.\n\nTimbre ~ sonic texture, tone color\nFriday, March 13, 2009\n\"Stilleben\" (\"Still Life\"), by Floris van Dyck, 1613. (Public domain image, from Wikipedia.)\n\nAnalogy to\nvisual texture\nRoughness\nSmoothness\nFriday, March 13, 2009\nPhoto courtesy of hoveringdog on Flickr.\n\nTimbre: a multidimensional tonal quality\nuses in tonal music:\ntone \"color\", \"texture\"\ndistinguishes instruments\nimportant for\ninstrument\ndesign\nsound mass\n\"timbral music\":\nambient music\nprimary dimension of\nelectronic music\nsonic change\nlexical music\nFriday, March 13, 2009\nPhoto courtesy of Pam Roth.\nUsed with permission.\nPhoto courtesy of Miriam Lewis. Used with permission.\nPhoto courtesy of Per-Ake Bystrom.\nUsed with permission.\n\nWhat makes different timbres distinctive?\nTimbre: a multidimensional tonal quality\nComplicated.....but there are two basic aspects\nStationary\nAspects\n(spectrum)\nDynamic\nAspects\n spectrum\n intensity\n pitch\nattack\ndecay\nVowels\nConsonants\nhttp://www.wikipedia.org/\nFriday, March 13, 2009\nPhoto courtesy of Per-Ake Bystrom.\nUsed with permission.\n\n\"The elusive attributes of timbre\"\nJ.F. Schouten (1968, p.42) describes the \"elusive attributes of\ntimbre\" as \"determined by at least five major acoustic\nparameters\" which Robert Erickson (1975) finds \"scaled to\nthe concerns of much contemporary music\":\n1. The range between tonal and noiselike character.\n2. The spectral envelope\n3. The time envelope in terms of rise, duration, and decay.\n4. The changes both of spectral envelope (formant-glide) and\nfundamental frequency (micro-intonation).\n5. The prefix, an onset of a sound quite dissimilar to the\nensuing lasting vibration.\nFriday, March 13, 2009\n\nTimbre perception: summary of factors\n- Timbre: tonal quality (= pitch, loudness, duration or location)\n- Defines separate voices, musical coloration\n- Multidimensional space: not completely well understood\n- Two general aspects: spectrum & dynamics\n- Stationary spectrum\n- Spectral center of gravity - low or high, \"brightness\"\n- Formant structure (spectral peaks)\n- Harmonicity\n- Amplitude-frequency-phase dynamics\n- Amplitude dynamics (attack, decay)\n- amplitude modulation (roughness)\n- Frequency dynamics\n- relative timings of onsetsand offsets of partials\n- frequency modulation (vibrato)\n- Phase dynamics (noisiness, phase coherence, chorus effect)\n- Analogy with phonetic distinctions in speech\n- Vowels (stationary spectra; formant structure)\n- Consonants (dynamic contrasts: amplitude, frequency & noise)\n- Temporal integration windows and timbral fusion\nFriday, March 13, 2009\n\nStationary and dynamic factors in timbre perception\n- Periodicity (noise-like or tone-like)\n- Harmonicity (is this properly an aspect of timbre?)\n- Phase coherence (noise-incoherent; tones-coherent)\n- Smoothness or roughness\n- Stationary spectrum\n- Spectral peaks (formants), spectral tilt (brightness)\n- Amplitude-frequency-phase dynamics\n- Amplitude dynamics (attack, sustain, decay)\n- amplitude modulation (roughness, tremolo)\n- Frequency dynamics\n- relative timings of onsets & offsets of partials\n- frequency modulation (vibrato)\n- Phase dynamics (phase shifts, chorus effect)\n- Analogy with phonetic distinctions in speech\n- Vowels (stationary spectra; formant structure)\n- Consonants (dynamic contrasts: amplitude, frequency & noise)\nFriday, March 13, 2009\n\nHarmonicity\nRafael A. Irizarry's Music and Statistics Demo\nSpectrograms of Harmonic Instruments\nFrequency dynamics\nviolin, trumpet, guitar\n(more harmonic,\nstationary spectra)\nNon-Harmonic Instruments\nmarimba, timpani, gong\n(more inharmonic,\ntime-varying spectra)\nhttp://www.biostat.jhsph.edu/~ririzarr/Demo/demo.html\nFriday, March 13, 2009\nCourtesy of Rafael A. Irizarry. Used with permission.\n\nTimbre: a multidimensional tonal quality\ntone texture, tone color\ndistinguishes voices,\ninstruments\nStationary\nAspects\n(spectrum)\nDynamic\nAspects\n spectrum\n intensity\n pitch\nattack\ndecay\nVowels\nConsonants\nhttp://www.wikipedia.org/\nFriday, March 13, 2009\nPhoto courtesy of Pam Roth.\nUsed with permission.\nPhoto courtesy of Miriam Lewis.\nUsed with permission.\nPhoto courtesy of Per-Ake Bystrom.\nUsed with permission.\n\nSome methods for studying the perceptual space\nof timbre\n1. Try to derive the structure of the space from the\ndimensionality of listener judgments\n\n- Similarity magnitude estimations\n- Similarity rankings\n- Multidimensional scaling\n\n2. \"Analysis by synthesis\"\nSystematically vary acoustic parameters known\nto influence timbre to find acoustic correlates of\nperceptual dimensions, e.g.\n- Formant structure\n\n- Attack and decay parameters\nFriday, March 13, 2009\n\nGrey (1975)\nTimbre:\nPerceptual\ndimensions\nstudied using\na \"confusion\nmatrix\"\nFriday, March 13, 2009\nFigure removed due to copyright restrictions.\nFigure from Butler, David\nThe Musician's Guide\nto Perception and\nCognition, 1992. Schirmer.\nAlso see:\nGrey, J. & Moorer, J.\n1977.\nPerceptual evaluations\nof synthesized musical\ninstrument tones.\nJ. Acoustical Society of America\n63:1493-1500\n\nTimbre dimensions: spectrum, attack, decay\nCourtesy of Hans-Christoph Steiner. Used with permission.\nAfter J. M. Grey, Stanford PhD Thesis (1975) and Grey and Grey & Gordon, 1978, JASA\nGordon, JASA (1978)\nFriday, March 13, 2009\n\nAmplitude dynamics (envelope, intensity contour)\n(Garageband demonstration)\nFriday, March 13, 2009 Graph of ADSR waveform, amplitude versus time, with segments labelled attack, decay, sustain and release.\nFigure by MIT OpenCourseWare.\n\nSpectrum as a function of intensity (trumpet)\nTimbre can change with intensity\nFriday, March 13, 2009\nGr\nap\nh\nof loud\nness spectra of a trumpet p\nl\na\ny\ni\nn\ng\nth\ne\nsa\nme\np\nit\nc\nh\n\na\nt\n\nt\nh\nr\nee\ndynamic levels. At pp, only partials 1 and 2 register; at mf, partials 1-4 are roughly eq\nual and diminish above the 5th, whereas at ff the subjective loudness of partials increases steadily through the 9th before diminishing.\nFigure by MIT OpenCourseWare. After Hanson (1988).\n\nVocal Ring, or The Singer's Formant\nOne seemingly mysterious property of the singing voice is its\nability to be heard even over a very loud orchestra. At first\nglance, this is counter-intuitive, since the orchestra is\nperceived by us to be so much louder than a single singer.\nThe answer to this mystery lies in the way the sound energy\nof the operatic voice is distributed across various frequencies.\nhttp://www.ncvs.org/ncvs/tutorials/voiceprod/tutorial/singer.html\nFriday, March 13, 2009\nText and images removed due to copyright restrictions.\nSee http://www.ncvs.org/ncvs/tutorials/voiceprod/tutorial/singer.html.\n\nVocal Ring, or The Singer's Formant\nFriday, March 13, 2009\nText and images removed due to copyright restrictions.\nSee http://www.ncvs.org/ncvs/tutorials/voiceprod/tutorial/singer.html.\n\nSinger's\nformant\nCook, Perry, ed.\nMusic, Cognition &\nComputerized Sound\nMIT Press 2001\nFriday, March 13, 2009\nCourtesy of MIT Press. Used with permission. Source: Cook, P., editor. Music, Cognition & Computerized Sound.\nCambridge, MA: MIT Press, 2001.\n\nFrequency\ndynamics\nof note\nonsets\n(clarinet)\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nFigure 4-4 in Butler, David. The Musician's Guide to Perception and Cognition.\nNew York, NY: Schirmer/Macmillan, 1992. ISBN: 9780028703411.\n\nTime-course of harmonics\nFriday, March 13, 2009\nFigure 3 (p. 119) in Risset, J-C., and Wessel, D. L. \"Exploration of Timbre by Analysis and Synthesis.\"\nChapter 5 in Deutsch, D., ed. The Psychology of Music. 2nd ed. San Diego, CA: Academic Press,\n1998. ISBN: 9780122135651. [View this image in Google Books]\n\nTime-window for timbral integration\nAppears to be similar to that for pitch (~30 ms)\nEvidence:\nIndistinguishability of ramps vs. damps < 30 ms (Patterson)\nReversal of 30 ms speech segments - no effect\nTimbral fusion of 2 single-formant vowels\n(L.A. Chistovich, 1985)\n50 Hz alternating double vowels did not fuse (20 ms\noffset)\nCommon onset grouping windows (~25-30 ms)\nFriday, March 13, 2009\n\nVoice qualities\n\nanother description of aspects of timbral space outside phonetic distinctions\nFriday, March 13, 2009\nCourtesy of The National Center for Voice and Speech. Used with permission.\nTable removed due to copyright restrictions.\nSee http://www.ncvs.org/ncvs/tutorials/voiceprod/tutorial/quality.html\n\nMusic timbre space and phonetic space\nHuman speech communications systems are mostly built on timbral\ndistinctions, although there are tonal languages in which pitch contour\nconveys distinctions.......\nThis could be because of the different voice pitches of human\nspeakers, or it could be due to the relative ease of rapidly changing\nvocal resonances rather than changing voice pitch (harder to sing than\nto talk)\nVowels = sustained notes = spectral differences (formants)\nConsonants = onset patterns = amplitude & frequency fluxes\nI believe that we will eventually come to a unified theory of both\nmusical timbral distinctions and phonetic distinctions that is grounded\nin how the auditory system encodes spectrum and rapid changes.......\nFriday, March 13, 2009\n\nSpeech\nNeurogram\n(cat auditory nerve,\nDelguttte, 1996)\nFriday, March 13, 2009\nFigure 16.1 (p. 511) in Delgutte, B. \"Auditory Neural Processing of Speech.\"\nChapter 16 in The Handbook of Phonetic Sciences. Edited by W. Hardcastle and J. Laver.\nMalden, MA: Wiley-Blackwell, 1999. ISBN: 9780631214786.\n[View this image in Google Books]\n\nPossible interval-based neural correlates for basic phonetic distinctions\nCHARACTERISTIC\nACOUSTIC\nDISTINCTION\nPHONETIC CLASS\nEXAMPLES\nINTERVAL CORRELATES\nVoice Pitch (80-400 Hz)\npitch contours,  over time\nvoice pitch, F0\nprosody\nmost common interval\nrunning interval \nVoice onset time\nVOT\nprominent interval between\nonset/offset responses\nSpectral Pattern\nstationary\nlow frequency\nformant pattern\nnasal resonances\nvowels\nnasals\n[u], [ae], [i]\n[m], [n]\nintervals for periodicities\n50-5000 Hz\nSpectro-temporal pattern\nfast transition\nslow transition\nformant transitions\nconsonants\nsemivowels\ndipthongs\n[b], [d], [g]\n[w], [r], [y]\n[ay], [aw],[ey]\ncross-BF intervals (?)\ntiming of FM responses (?)\nslow  in interval distr.\nlow freq modulations\ninteractions\nSpectral Dispersion\nnoise-excitation\n(frication)\nfricative consonants\n/f/, /s/,//,/v/,// semi periodic temporal\nstruct. ;phase incoherence\nVoiced-unvoiced\nvoiced/unvoiced\nstop consonants\nfricatives\nwhispered/voiced\n[b]/[p]\n[v]/[f]\npresence of harmonic\nstructure in intervals\ndegree interval dispersion\nDynamic Amplitude Patterns\namplitude time profiles\nabrupt/gradual \n(buildup / decay)\naffricative/fricative\n/t/ vs //\nchip vs ship\nadaptation + running\ninterval buildup patterns\n(Autocorrelations  shape)\nRhythm\nmetrical aspects\nword rhythm\nspeaking rate\nLonger interval patterns\n(50-500 msec)\nDuration\nduration\nprominent interval between\nonset & offset responders\nSuprasegmental structure\nword time pattern\nwhole word patterns\nlonger time structures\nFriday, March 13, 2009\n\nMusic based on\ntimbral contrasts\nKurt Schwitters,\nUr Sonata (1932)\nperf. George Melly, Miniatures\nFriday, March 13, 2009\n\nMusic based on\ntimbral contrasts\nKurt Schwitters,\nUr Sonata (aka \"Ursonate\") (1932)\nperf. George Melly, Miniatures\nImages of score and photos of Schwitters performing Ur Sonata\nremoved due to copyright restrictions.\nSee http://writing.upenn.edu/pennsound/x/Schwitters.html.\nFriday, March 13, 2009\n\nStationary spectral aspects of timbre\n[ae]\nF0 = 100 Hz\n[ae]\nF0 = 125 Hz\n[er]\nF0 = 100 Hz\n[er]\nF0 = 125 Hz\nWaveforms\nPower Spectra\nFormant-related\nVowel quality\nTimbre\n0 1\nTime (ms)\nFrequency (kHz)\nAutocorrelations\nPitch periods, 1/F0\n125 Hz\n100 Hz\nInterval (ms)\nFriday, March 13, 2009\n\nFormants and the vocal tract\nFriday, March 13, 2009\nImage removed due to copyright restrictions.\nDiagram of eight vocal tract positions for some english vowels:\nheed, hid, head, had, hod, hawed, hood, who'd. (Source unknown.)\n\nTimbre and spectrum\nVowel space\nF1\nFrequency (kHz)\nF2 F3 F4\nF1 F2\n[ae]\n[], \"er\"\n[], \"er\"\nFriday, March 13, 2009\nPlot of vowel space (first vs. second formant frequencies) removed due to\ncopyright restrictions. See http://www.ncvs.org/ncvs/tutorials/voiceprod/tutorial/filter.html.\nAdapted from Peterson, G.E., and H.L. Barney.\n\"Control Methods Used in a Study of the Vowels.\" J Acoust Soc Am 24, no. 2 (1952): 175-184.\n\nHigh F2 Formant Sweep\nLow F2 Formant Sweep\n[i]\n[]\n[i]\n[u]\n[a]\n[u]\nAuditory nerve fiber\nAuditory nerve fiber\nCF: 1.4 kHz Thr: 2.0 SR: 90.7\n35-60\nCF: 1.4 kHz Thr: 2.0 SR: 90.7\n35-60\nInterspike interval (ms)\nInterspike interval (ms)\n1/F0\nn/F1\n1/F1\n1/F0\nn/F1\n1/F1\nTwo-formant vowel sweeps\nPVCN Chop-S\ni\nCF: 2.1 kHz Thr: 5.3 SR: 17.7\nSecond formant (Hz)\nInterspike interval (ms)\nDCN Pauser\nCF: 1.3 kHz Thr: 24.8 SR:0.0\n1/F0\nn/F1\nHigh F2\nI\n\n\nLow F2\n\nu\nFirst formant (Hz)\nAVCN Pri-N\nCF: 1.5 kHz Thr: 8.8 SR: 247.1\nInterspike interval (ms)\n1/F0\n1/F0\nInterspike interval (ms)\n1/F1\nn/F1\nPeristimulus time (ms)\n\nPeristimulus time (ms)\nFriday, March 13, 2009\n\nSecond formant (Hz)\ni\nu\n\n\n\nI\nHigh F2\nLow F2\nTwo-formant vowel sweeps\nFirst formant (Hz)\nFriday, March 13, 2009\n\nLow F2 Formant Sweep\n[u]\n[a]\n[u]\nAuditory nerve fiber\nCF: 1.4 kHz Thr: 2.0 SR: 90.7\n35-60\nInterspike interval (ms)\nn/F1\n1/F0\nFriday, March 13, 2009\n\nSecond formant (Hz)\ni\nu\n\n\n\nI\nHigh F2\nLow F2\nTwo-formant vowel sweeps\nFirst formant (Hz)\nFriday, March 13, 2009\n\nHigh F2 Formant Sweep\n[i]\n[]\n[i]\nAuditory nerve fiber\nCF: 1.4 kHz Thr: 2.0 SR: 90.7\n35-60\nInterspike interval (ms)\nn/F1\n1/F1\n1/F0\nFriday, March 13, 2009\n\nGUY-BUY-DIE\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\nTime\nFrequency\nFriday, March 13, 2009\n\nSummary I: Uses of timbre in music\n- Distinguishes musical instruments\n- Tone coloration (Western tonal music)\n- Primary dimension of auditory contrast in some\nmusic (electronic, ambient)\nFriday, March 13, 2009\n\nSummary II: Acoustical correlates of timbre\n- Time-invariant properties (static sounds)\n- Stationary spectrum (sustained notes)\n- Speech: vowels\n- Relatively well-understood & characterized\n- Time-varying properties (rapidly changing sounds)\n- Onsets & offsets of notes\n- Amplitude dynamics (envelope, attack, decay)\n- Frequency dynamics (spectral changes, vibrato)\n- Speech: consonants\n- Phase shifts (chorus effect & electronic contexts)\n- Relatively poorly understood & characterized\nFriday, March 13, 2009\n\nTimbre: a multidimensional tonal quality\nuses in tonal music:\ntone \"color\", \"texture\"\nimportant for\ninstrument\ndistinguishes instruments\ndesign\n\"timbral music\": primary\ndimension of change\nStationary\nAspects\n(spectrum)\nDynamic\nAspects\n spectrum\n intensity\n pitch\nattack\ndecay\nVowels\nConsonants\nhttp://www.wikipedia.org/\nFriday, March 13, 2009\nPhoto courtesy of Pam Roth.\nUsed with permission.\nPhoto courtesy of Miriam Lewis.\nUsed with permission.\nPhoto courtesy of Per-Ake Bystrom.\nUsed with permission.\n\nhttp://en.wikipedia.org/wiki/Timbre\nNext up: consonance and scales\nAny questions?\nFriday, March 13, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "What we hear: Basic dimensions of auditory experience",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/52563e93de4c8813e614115d8e3500d9_MITHST_725S09_lec03_what.pdf",
      "content": "HST 725\nMusic Perception & Cognition\nLecture 3\nWhat we hear:\nBasic dimensions of auditory experience\nwww.cariani.com\nTuesday, February 10, 2009\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nWhat we hear: dimensions of auditory experience\n- Hearing: ecological functions (distant warning,\ncommunication, prey detection; works in\nthe dark)\n- Detection, discrimination, recognition, reliability, scene analysis\n- Operating range: thresholds, ceilings, & frequency limits\n- Independent dimensions of hearing & general properties\n- Pitch\n- Timbre (sound quality)\n- Loudness\n- Duration\n- Location\n- Distance and Size\n- Perception of isolated pure tones\n- Interactions of sounds: beatings, maskings, fusions\n- Masking (tones vs. tones, tones in noise)\n- Fusion of sounds & the auditory \"scene\":\n- how many objects/sources/voices/streams?\n- Representation of periodicity and spectrum\nTuesday, February 10, 2009\n\nMECHANISM\nNeural codes\nNeural\narchitectures\nFunctions\nInformation-processing\noperations\nSensory\nencodings\nMotor\ncommands\nExternal\nworld\nReceptors\nEffectors\nTuesday, February 10, 2009\n\nhttp://www.batsnorthwest.org/\n(c) Scott Pederson.\nCorynorhinus townsendii -\nTownsend's Big-eared Bat\nHearing: ecological functions\n- Distant warning of predators\napproaching\n- Identification of predators\n- Localization/tracking of prey\n- Con-specific communication\nMating/competition\nCooperation (info. sharing)\n\nTerritory\n- Navigation in the dark\n- General recognition of sounds\nhttp://www.pbs.org/wgbh/nova/wolves/\nhttp://www.pbs.org/lifeofbirds/songs/index.html\n\nPhoto: US Fish and Wildlife Service.\nTuesday, February 10, 2009\n\nThe Effect of Context on Information Processing\nin the Auditory System\nEll\nEllen Covey\nUniversity of Washington\nCourtesy of Ellen Covey. Used with permission.\nSeattle, WA\nTuesday, February 10, 2009\n\nJim Simmons, Brown\nTuesday, February 10, 2009\nCourtesy of James Simmons. Used with permission.\n\nTemporal organization\n-\nEvents\n-\nNotes\n-\nTemporal patterns of events\nOrganization of sounds\n-\nVoices, instruments\n-\nStreams\n-\nObjects\nPaul Cezanne. \"Apples, Peaches, Pears and Grapes.\"\nThe auditory scene:\nbasic dimensions\n-\nSources\nCourtesy of the iBilio.org WebMuseum.\n\nAttributes of sounds\n-\nLoudness (intensity)\n-\nPitch\n(dominant periodicity)\n-\nTimbre\n(spectrum)\n-\nDuration\n-\nLocation (bearing, range)\nTuesday, February 10, 2009\n\nAuditory qualities in music perception & cognition\n- Pitch\n\nMelody, harmony, consonance\n- Timbre\nInstrument voices\n- Loudness Dynamics\n- Organization Fusions, objects. How many voices?\n\n- Rhythm\n\nTemporal organization of events\n- Longer pattern Repetition, sequence\n- Mnemonics\nFamiliarity, novelty\n- Hedonics\nPleasant/unpleasant\n- Affect\nEmotional associations, meanings\n- Semantics Cognitive associations/expectations\nTuesday, February 10, 2009\n\nDimensions of auditory objects\nDimensions of event perception\nAuditory qualities and their organization\nUnitary events & their organization\nObjects: Quasi-stationary\nEvents: abrupt perceptual\nassemblages of qualities\ndiscontinuities\nTimbre\nLoudness\nLocation\nSpatial Dimensions\nPitch\nTEMPORAL\nEVENT\nSTRUCTURE\nTiming & order\n(metric, sequence)\nDuration\nFUSION/SEPARATION\nFUSION/SEPARATION\nCommon onset & harmonic structure => fusion\nCommon onset, offset => fusion\nDifferent F0s, locations, onset => separation\nDiff. meters, pitch, timbre => separation\nPOLYPHONY\nSTREAMS, POLYRHYTHMS\nTuesday, February 10, 2009\n\nVisual scene\nLine\nShape\nTexture\nLightness\nColor\nTransparency\nObjects\nApparent distance\nApparent size\netc.\nMargaret Bourke-White\nFort Peck Dam 1936\nPhoto removed due to copryight restrictions. Cover of LIFE Magazine, Nov. 23, 1936.\nView in Google Books.\nTuesday, February 10, 2009\n\nPsychophysics\nPerceptual\nStimulus\nCharacterizing\n& predicting\nneural responses\nWhy does the system\nrespond as it does?\nStimulus\nRetrodiction\nTransmission\nfidelity\nEstimates of\nchannel capacity\nperformance\nReverse\nengineering\nHow does it work?\nWhat aspects of\nneural response\nare critical for perceptual\nfunction?\nRetrodiction of percepts\nCorrespondence\nBetween putative\nneural representation\n& perceptual performance\nNeural\nresponses\nBiophysical\nPsychoneural\nmodels\nneurocomputational models\nTuesday, February 10, 2009\n\nPerceptual functions\nSubjective vs. objective measures\nSubjective measures\nMagnitude estimation\nObjective measures\nDetection: capability of distinguishing the presence or absence of a stimulus\n\n(or some aspect of a stimulus, e.g. AM detection)\nThreshold: the value of a stimulus parameter at which a stimulus can be reliably\ndetected\nSensation level (SL): sound level re: threshold\nDiscrimination: capability of distinguishing between two stimuli\nDifference limen: the change in a stimulus parameter required for reliable\n\ndiscrimination, just-noticeable-difference (jnd)\nWeber fraction: Difference limen expressed as proportional change (e.g. f/f)\nMatching task: subject changes parameter that matches two stimuli\nTwo-alternative forced choice (2AFC)\nRanking tasks\nRecognition: correct identification of a particular stimulus\nMasking: impairment of ability to detect a signal in the presence of other signals\nTuesday, February 10, 2009\n\nVibrations create compressions and expansions of air\nSound waves are alternating local\nchanges in pressure\nThese changes propagate through\nspace as \"longitudinal\" waves\nCondensation phase (compression):\npressure increases\nRarefaction (expansion) phase:\npressure decreases\nHandel\nTuesday, February 10, 2009\nSource: Handel, S. Listening: an Introduction to the Perception of Auditory Events.\nCambridge, MA: MIT Press, 1989. Courtesy of MIT Press. Used with permission.\n\nWaveforms\nMicrophones convert sound pressures to electrical voltages.\nWaveforms plot pressure as a function of time, i.e. a \"time-series\" of amplitudes.\nWaveforms are complete descriptions of sounds.\nAudio CDs sample sounds at 44,100 samples/sec.\nOscilloscope demonstration.\nWaveform of transient \"clack\" sound, metal rod striking wooden stick.\nFigure by MIT OpenCourseWare.\nTuesday, February 10, 2009\n\nOscilloscope demonstration\nWaveforms plot pressure as a function of time, i.e. a \"time-series\" of amplitudes.\nWaveforms are complete descriptions of sounds.\n\nTuesday, February 10, 2009\n\nSampling rate (samples/second)\nNowadays sounds are usually converted to strings of numbers that indicate\nsound pressure or voltage at each of many equally spaced points in time. THe\nnumber of samples collected per sec is the sampling rate.\n\nTuesday, February 10, 2009\n\nFrom sound to numbers\nCD quality sound\nsound pressure changes\n16 bits = 216 = 64k\nvoltage levels,\nmicrophone\nsampling rate @\n44,100 samples/sec\nelectrical voltage changes\ndigitizer\n(analog to digital converter)\nnumerical values, time-series\nThe upper limit of human hearing is ~ 20,000 cycles/sec (Hertz, Hz).\nThere is a theorem in signal processing mathematics that the highest frequency that can\nbe represented is 1/2 the sampling rate (called the Nyquist frequency).\nThis is why sound for CDs is sampled at 44.1 kHz.\nIn theory, this is the point where all sound distinctiona we can hear is captured.\nMP3s compress the description by about 10-fold (we will discuss later).\nTuesday, February 10, 2009\n\nSound level basics\n- Sound pressure levels are measured relative to an absolute\nreference\n- (re: 20 micro-Pascals, denoted Sound Pressure Level or SPL).\n- Since the instantaneous sound pressure fluctuates, the\naverage amplitude of the pressure waveform is measured\nusing root-mean-square RMS. (Moore, pp. 9-12)\n- Rms(x) = sqrt(mean(sum(xt2)))\n- Where xt is the amplitude of the waveform at each instant t in the\nsample\n- Because the dynamic range of audible sound is so great, magnitudes\nare expressed in a logarithmic scale, decibels (dB).\n- A decibel of amplitude expresses the ratio of two amplitudes\n(rms pressures, P1 and P_reference) and is given by the\nequation:\n\ndB = 20 * log10(P1/P_reference)\n\n20 dB = 10 fold change in rms level\nTuesday, February 10, 2009\n\nDecibel scale for relative amplitudes (levels)\n(rules of thumb)\n20 dB = fold change amplitude\n10 dB = 3+ fold change\n6 dB = 2 fold change amplitude\n3 dB = 1.4 fold change\n2 dB = 1.26 fold change (26 %)\n1 dB = 1.12 fold change (12%)\n0 dB = 1 fold change (no change)\n-6 dB = 1/2\n-20 dB = 1/10 fold change\nTuesday, February 10, 2009\n\nDynamic range\n0 dB SPL is set at 20 microPascals\n60 dB SPL is therefore a 1000 fold change in RMS over 0 dB\nA typical background sound level is 50-60 dB SPL.\nDynamic range describes the range of sound pressure levels.\nThe auditory system registers sounds from 20 dB to >> 120 dB SPL\nThe auditory system has a dynamic range in excess of 100 dB (!) or a\nfactor of 105 = 100,000 in amplitude.\nIt is quite remarkable that musical sounds remain recognizable over\nmost of this range. This a fundamental aspect of hearing that all\nauditory theories must address -- how auditory percepts remain\nlargely invariant over this huge range (perceptual constancy).\nTuesday, February 10, 2009\n\nHearing has a huge dynamic range!\nHearing has a huge dynamic range!\nThe dynamic range of human\nhearing is the ratio of the sound\npressure level of the softest sound that\ncan be heard to the loudest one that\ncan be tolerated without pain.\nThis dynamic range is > 100,000 (>\n100 dB or 105 fold), and is roughly\ncomparable to the 65,536 amplitude\nsteps that are afforded by 16-bit\ndigitization.\nCD quality sound\n16 bits = 216 = 64k\nvoltage levels,\nsampling rate @\n44,100 samples/sec\nTuesday, February 10, 2009\n\nTypical sound levels in music\nOn origins of music dynamics notation\nhttp://www.wikipedia.org/wiki/Pianissimo\nText removed due to copyright\nrestrictions. See the Wikipedia\narticle.\n-\nPain\n\n> 130 dB SPL\n-\nLoud rock concert 120 dB SPL\n-\nLoud disco\n\n110 dB SPL\n-\nfff\n\n100 dB\nSPL\n-\nf\n(forte, strong)\n80 dB\nSPL\n-\np\n(piano, soft)\n60 dB\nSPL\n-\nppp\n\n40 dB SPL\n-\nLower limit\n-\nTheshold of hearing 0 dB SPL\nTuesday, February 10, 2009\n\nTypical sound pressure levels in everyday life\nDisco\n\nTuesday, February 10, 2009\nCourtesy of WorkSafe, Department of Consumer and Employment Protection, Western Australia (http://www.safetyline.wa.gov.au).\n\nDemonstrations\n- Demonstrations using waveform generator\n- Relative invariance of pitch & timbre with level\n- Loudness matching\n- Pure tone frequency limits\n- Localization\nTuesday, February 10, 2009\n\nLoudness\nDimension of perception that changes with\nsound intensity (level)\nIntensity ~ power;\nLevel~amplitude\nDemonstration using waveform generator\nMasking demonstrations\nMagnitude estimation\nLoudness matching\nTuesday, February 10, 2009\n\nSound level meters and frequency weightings\nA-weighting: perceived loudness\nC-weighting: flat\n\nC-weighting is closest to flat response, with B-weighting rolling off more low frequencies and A-weighting having a more pronounced low frequency rolloff and curve thoughout.\nGraph by MIT OpenCourseWare. SPL meter photo courtesy of EpicFireworks on Flickr.\n\nTuesday, February 10, 2009\nC\n-we\nigh\ntin\ng i\ns c\nlos\nest\nto\nf\nl\na\nt\n\nr\ne\ns\npo\nn\ns\ne,\nwit\nh B\n-weighting rol\nling off more low freq\nu\ne\nncie\ns\nand A-weighting having a more pronounced low frequency rolloff and curve thoughout.\n\nLoudness as a function of pure tone level & frequency\nAbsolute detection thresholds\non the order of\n1 part in a million,\n pressure ~1/1,000,000 atm\n(Troland, 1929) Constant loudness curves for people with acute hearing, sound pressure (dB) vs. frequency. 70 dB equates to musical f, while 50 db equates to p.\nFigure by MIT OpenCourseWare.\nTuesday, February 10, 2009\n\nLoudness perception: Three graphs at 100 Hz, 1kHz, and 10kHz; shows that loudness perception at 100Hz drops of below about 50 sones.\nTuesday, February 10, 2009\nFigure by MIT OpenCourseWare.\n\nLoudness perception: population percentiles Graphs of threshold of hearing at various frequencies for a group of Americans, showing about 30dB diffference between the most sensitive 1% and the 90% curve.\nFigure by MIT OpenCourseWare.\nTuesday, February 10, 2009\n\nIntensity discrimination improves at higher sound levels\nBest Weber fraction\nFigure by MIT OpenCourseWare. Graph comparing noticeable intensity differences for different species - human, cat, rat, mouse and parakeet.\nTuesday, February 10, 2009\n\nHearing loss with age Graph of progressive loss of high frequency sensistivity with increasing age, normalized to a 20 year old.\nTuesday, February 10, 2009\nFigure by MIT OpenCourseWare.\n\nDynamic range of some\nmusical instruments\nImages removed due to copyright restrictions.\nGraphs of relative intensity vs. pitch for different instruments: violin, double bass, flute, B-flat clarinet, trumpet, french horn.\nFigure 8.5 in Pierce, J. R. The Science of Musical Sound. Revised ed. New York, NY: W.H. Freeman & Co., 1992. ISBN: 9780716760054.\nTuesday, February 10, 2009\n\nPeriodicity and spectrum\nPeriodicity vs. frequency\nLongstanding and ongoing dichotomy between\nformally-equivalent, yet complementary\nperspectives (de Cheveigne chapter on\npitch)\nVibrating strings vs. Helmholtz resonators\nComb filters vs. band-limited filters\nAutocorrelation vs. Fourier analysis\nand yet another paradigm\nComplex oscillator (delay loop)\nTuesday, February 10, 2009\n\nComplex modes of vibration\nMost physical systems have multiple\nmodes of vibrations that create\nresonances that favor particular\nsets of frequencies.\nVibrating strings or vibrating columns\nof air in enclosures exhibit\nharmonic resonance patterns.\nMaterial structures that are struck\n(bells, xylophones, percussive\ninstruments) have resonances\nthat depend partly on their\nshape and therefore\ncanproduce frequencies that\nare not harmonically related.\nMore later on what this means for\npitch and sound quality.\nFour diagrams of a vibrating stretched string at the first four complete harmonic frequencies f, 2f, 3f and 4f.\nTuesday, February 10, 2009\n\nFrequency spectra\nThe Greeks understood simple relationships between vibration rate & pitch.\nExperiments with musical instruments and tuning systems were carried out by\nmany people (Galileo\ns father, Galileo, Saveur, Mersenne, others).\nJoseph Fourier (1768-1830) showed that any waveform can be\nrepresented as the sum of many sinusoids (\nFourier spectrum).\nGeorge Ohm (1789-1854) postulated that sounds can be decomposed into component sinusoids\nHermann von Helmholtz (1821-1894) postulated that the ear analyzes sound\nby first breaking sounds into their partials and then doing associative pattern-recognition\nDebate between Seebeck, Ohm, & Helmholtz (1844) over periodicity vs. spectral pattern\nForeshadows temporal vs. place codes, autocorrelation vs. Fourier spectrum\nEach sinusoid of a particular frequency (frequency component, partial) has 2 parameters:\n- 1) its magnitude (amplitude of the sinusoid)\n- 2) its phase (relative starting time)\nA sound with 1 frequency component is called a pure tone.\nA sound with more than one is called a complex tone.\nTuesday, February 10, 2009\n\nFundamentals and harmonicsDiagrams of the additive result of (sine wave) fundamental plus second thorugh fifth harmonics.\n- Periodic sounds (30-20kHz)\nproduce pitch sensations.\n- Periodic sounds consist of\nrepeating time patterns.\n- The fundamental period (F0) is the\nduration of the repeated pattern.\n- The fundamental frequency is the\nrepetition frequency of the pattern.\n- In the Fourier domain, the\nfrequency components of a\nperiodic sound are all members of\na harmonic series (n = 1*F0, 2*F0,\n3*F0...).\n-\nThe fundamental frequency is\ntherefore the greatest common\ndivisor of all of the component\nfrequencies.\n- The fundamental is also therefore\na subharmonic of all component\nfrequencies.\nTuesday, February 10, 2009\nFigure by MIT OpenCourseWare.\n\nHarmonic series\nA harmonic series consists of integer multiples of a fundamental frequency,\ne.g. if the fundamental is 100 Hz, then the harmonic series is: 100, 200,\n300, 400, 500, 600 Hz, .... etc.\nThe 100 Hz fundamental is the first harmonic, 200 Hz is the second\nharmonic. The fundamental is often denoted by F0.\nThe fundamental frequency is therefore the greatest common divisor of all\nthe frequencies of the partials.\nHarmonics above the fundamental constitute the overtone series.\nSubharmonics are integer divisions of the fundamental:\ne.g. for F0= 100 Hz, subharmonics are at 50, 33, 25, 20, 16.6 Hz etc.\nSubharmonics are also called\nundertones.\nThe fundamental period is 1/F0, e.g. for F0=100 Hz, it is 1/100 sec or 10\nTuesday, February 10, 2009\n\nSound quality contrasts\n- Impulsive sounds\nDuration\n- Sustained sounds\n- Stationary vs. nonstationary\n- Pitched sounds\n- Time domain: Periodic sound patterns\nPattern\n- Frequency domain: harmonics\ncomplexity, - Inharmonic sounds\ncoherence\n- Combinations of unrelated periodic patterns\n- Complexity: Number of independent patterns\n- Noises\n- Aperiodic sound patterns, high complexity\nTuesday, February 10, 2009\n\nMinimal\ndurations\nGraph removed due to copyright restrictions.\nFigure 36, comparing \"Tone pitch\" and \"click pitch\" responses.\nIn Licklider, J. C. R. \"Basic Correlates of the Auditory Stimulus.\"\nHandbook of Experimental Psychology. Edited by S. S. Stevens.\nOxford, UK: Wiley, 1951. pp. 985-1039.\nLicklider (1951)\n\"Basic correlates\nof the auditory stimulus\"\nTuesday, February 10, 2009\n\nPeriodic vs. aperiodic sounds\n- Periodic sound patterns -- \"tones\"\n- Aperiodic sound patterns -- \"noise\"\nTuesday, February 10, 2009\n\nRange of pitches of pure & complex tones\n- Pure tone pitches\n- Range of hearing (~20-20,000 Hz)\n- Range in tonal music (100-4000 Hz)\n- Most (tonal) musical instruments\nproduce harmonic complexes that\nevoke pitches at their fundamental\nfrequencies (F0s)\n- Range of F0s in tonal music (30-4000 Hz)\n- Range of missing fundamental (30-1200 Hz)\nTuesday, February 10, 2009\n\nJND's\nTuesday, February 10, 2009 Three graphs describing optimal performance for pure-tone frequency discrimination.\nFigure by MIT OpenCourseWare.\n\nPure tone pitch discrimination\nbecomes markedly worse\nabove 2 kHz\nWeber fractions for\nfrequency (f/f) increase\n1-2 orders of magnitude\nbetween 2 kHz and 10 kHz\nTuesday, February 10, 2009 Graph of Weber fraction vs. freqency for human data.\nFigure by MIT OpenCourseWare.\n\nPure tone\npitch\ndiscrimination\nimproves\nat longer\ntone\ndurations\nand\nat\nhigher\nsound\npressure\nlevels\nTuesday, February 10, 2009 Graphs of delta-f vs. duration (ms) and level (dB SPL) for human data.\nFigure by MIT OpenCourseWare.\n\nEmergent pitch\nMissing\nLine spectra\nAutocorrelation (positive part)\nF0\nPure tone\n200 Hz\nTuesday, February 10, 2009\n\nCorrelograms: interval-place displays (Slaney & Lyon)\nFrequency (CF)\nFrequency (CF)\nAutocorrelation lag (time delay)\nTuesday, February 10, 2009\nCourtesy of Malcolm Slaney (Research Staff Member of IBM Corporation). Used with permission.\n\n8k\nFrequency ranges of (tonal) musical instruments\n> 6 kHz\n2.5-4 kHz\n27 Hz\n4 kHz\nHz\nHz\nHz\nHz\nTuesday, February 10, 2009\n\nFrequency ranges: hearing vs. musical tonality\n100 Hz\n2 kHz\nRange of hearing\nAbility to detect sounds: ~ 20-20,000 Hz\nMusical tonality\nOctaves, intervals, melody: 30-4000 Hz\nTemporal\nneural\nmechanism\nPlace\nmechanism\nTuesday, February 10, 2009\n\nDuplex time-place representations\ntemporal representation\nlevel-invariant\n- strong (low fc, low n)\n- weak (high fc, high n; F0 < 100 Hz)\nplace-based\nrepresentation\nlevel-dependent\ncoarse\n1k\n10k\nSimilarity\ncf. Terhardt's\nto\nspectral and virtual pitch\ninterval\npattern\nSimilarity to place pattern\nTuesday, February 10, 2009\n\nA \"two-mechanism\" perspective (popular with some psychophysicists)\nn= 5-10\nunresolved harmonics\nweak temporal mechanism\nphase-dependent; first-order intervals\nharmonic number\nplace-based\nrepresentation\nlevel-independent\nfine\nresolved harmonics\nstrong spectral pattern mechanism\nphase-independent\nrate-place? interval-place?\nDominance region\nf, F0\nplace-based\nrepresentations\nlevel-dependent\ncoarse\n1k\n10k\nTuesday, February 10, 2009\n\nPitch dimensions: height & chroma\nTuesday, February 10, 2009 Two drawings representing rising pitch: one a straight vertical arrow, and the other a rising spiral that puts any given note in the scale at the same point in each rotation.\nFigure by MIT OpenCourseWare.\n\nPitch height and pitch chroma\nTuesday, February 10, 2009\nImages removed due to copyright restrictions.\nFigures 1, 2, and 7 in Shepard, R. N. \"Geometrical approximations to the structure of musical pitch.\"\nPsychological Review 89, no. 4 (1982): 305-322.\n\nTwo codes for \"pitch\nPlace code\nPitch = place of excitation\nPitch height\nAbsolute\nLow vs. high\nExistence region\nf: .100-20,000 Hz\nTime code\nPitch = dominant periodicity\nMusical pitch\n\"Chroma\", Tonality\nRelational\nMusical intervals, tonality\nMelodic recognition\n& transposition\nExistence region\nF0: 30-4000 Hz\nTuesday, February 10, 2009\n\nNote durations in music\nTuesday, February 10, 2009 For familiar songs like \"Twinkle twinkle\" and \"Happy Birthday\", note durations range from less than 200 msec to about 2 seconds.\nFigure by MIT OpenCourseWare.\n\nTimbre: a multidimensional tonal quality\nStationary\nDynamic\nAspects\nAspects\nPhoto Courtesy of Per-Ake\nBystrom.Used with permission.)\n(spectrum)\nspectrum\nintensity\npitch\nVowels\nattack\ndecay\nPhoto Courtesy of Miriam\nLewis. Used with permission.)\nConsonants\n(Photo Courtesy of Pam Roth.\ntone texture, tone color\nUsed with permission.)\ndistinguishes voices,\ninstruments\n\nStationary spectral aspects of timbre\n[ae]\nF0 = 100 Hz\n[ae]\nF0 = 125 Hz\n[er]\nF0 = 100 Hz\n[er]\nF0 = 125 Hz\nWaveforms\nPower Spectra\nFormant-related\nVowel quality\nTimbre\n0 1\nTime (ms)\nFrequency (kHz)\nAutocorrelations\nPitch periods, 1/F0\n125 Hz\n100 Hz\nInterval (ms)\nTuesday, February 10, 2009\n\nRafael A. Irizarry's Music and Statistics Demo\nSpectrograms\nof Harmonic Instruments\nviolin, trumpet, guitar\nNon-Harmonic Instruments\nmarimba, timpani, gong\nAudio samples at this page:\nhttp://www.biostat.jhsph.edu/~ririzarr/Demo/demo.html\nTuesday, February 10, 2009\nCourtesy of Rafael A. Irizarry. Used with permission.\n\nTimbre dimensions: spectrum, attack, decay\nTuesday, February 10, 2009\nCourtesy of Hans-Christoph Steiner.\nUsed with permission. After J. M. Grey,\nStanford PhD Thesis (1975) and Grey and\nGordon, JASA (1978).\n\nInterference interactions between tones\n[Public domain image]\nTuesday, February 10, 2009\n\nMasking audiograms\n[Public domain image]\nTuesday, February 10, 2009\nWegel & Lane, 1924\n\n1000 Hz pure tone masker\nTuesday, February 10, 2009\nGraph removed due to copyright restrictions.\nSee Fig. 3, \"Average masking patterns for 1000 cps based upon three listeners\" in Ehmer,\nRichard H. \"Masking Patterns of Tones.\" The Journal of the Acoustical Society of America,\nvol. 31, no. 8 (1959): 1115. http://www.zainea.com/masking2.htm\n\nTone on tone masking curves (Wegel & Lane, 1924)\n[Public domain images]\nTuesday, February 10, 2009\n\nResolvability of harmonics (Plomp, 1976)\nTuesday, February 10, 2009\nImage removed due to copyright restrictions.\nGraph of frequency separation between partials vs. frequency of the partial. From Plomp, R. Aspects of Tone Sensation.\nNew York, NY: Academic Press, 1976.\n\nFrom masking patterns\nto \"auditory filters\" as a\nmodel of hearing\nPower spectrum\nFilter metaphor\nNotion of one central\nspectrum that subserves\n2.2. Excitation pattern. Using the filter shapes and bandwidths derived from masking experiments we can\nproduce the excitation pattern produced by a sound. The excitation pattern shows how much energy comes\nthrough each filter in a bank of auditory filters. It is analogous to the pattern of vibration on the basilar\nmembrane. For a 1000 Hz pure tone the excitation pattern for a normal and for a SNHL (sensori-neural\nhearing loss) listener look like this: The excitation pattern to a complex tone is simply the sum of the\npatterns to the sine waves that make up the complex tone (since the model is a linear one). We can hear out\na tone at a particular frequency in a mixture if there is a clear peak in the excitation pattern at that\nfrequency. Since people suffering from SNHL have broader auditory filters their excitation patterns do not\nhave such clear peaks. Sounds mask each other more, and so they have difficulty hearing sounds (such as\nspeech) in noise. --Chris Darwin, U. Sussex\nTuesday, February 10, 2009\nCourtesy of Prof. Chris Darwin (Dept. of Psychology at the University of Sussex).\n\nShapes of perceptually-derived \"auditory filters\" (Moore)\nDont conflate these with cochlear filters or auditory\nnerve excitation patterns! Auditory filters are derived\nfrom psychophysical data & reflect the response of the\nwhole auditory system. For lower frequencies and higher\nlevels AFs have much narrower bandwidths than\ncochlear resonances or auditory nerve fiber responses.\nTuesday, February 10, 2009 Three graphs showing perceptually derived auditory filters. Three graphs showing perceptually derived auditory filters.\nFigures by MIT OpenCourseWare.\n\nResolution of harmonics\nTuesday, February 10, 2009 Graph of threshold shift (dB) vs. frequency (0 to 4kHz).\nFigure by MIT OpenCourseWare.\n\nA \"two-mechanism\" perspective (popular with some psychophysicists)\nn= 5-10\nunresolved harmonics\nweak temporal mechanism\nphase-dependent; first-order intervals\nharmonic number\nplace-based\nrepresentation\nlevel-independent\nfine\nresolved harmonics\nstrong spectral pattern mechanism\nphase-independent\nrate-place? interval-place?\nDominance region\nf, F0\nplace-based\nrepresentations\nlevel-dependent\ncoarse\n1k\n10k\nTuesday, February 10, 2009\n\nSpectral pattern\nanalysis\nvs.\ntemporal pattern\nanalysis\nNote: Some models,\nsuch as Goldstein's\nuse interspike interval\ninformation to first form\na Central Spectrum\nwhich is then analyzed using\nharmonic spectral templates.\nThere are thus dichotomies\n1) between use of\ntime and placeinformation\nas the basis of the central\nrepresentation, and\n2) use of spectral vs.\nautocorrelation-like central\nrepresentations\nStimulus\nF0= 80 Hz\ndB\n0 Frequency (kHz)3\narray of cochlear band-pass filters\ndischarge rates\nPower spectrum\nrepresentation\nFrequency domain\nPopulation rate-\nplace profile\nfrequency\noptimal\n(linear scale)\nmatch\nF0 = 200 Hz\nF0 = 160 Hz\nF0 = 100 Hz\nharmonic templates\nPitch  best fitting template\nauditory\nnerve fiber\ntuning curves\ninterspike intervals\nAutocorrelation\nrepresentation\nTime domain\nPopulation\ninterspike interval\ndistribution\n1/F0\n1/F1\nInterval (ms)\n# intervals\nTuesday, February 10, 2009\n\nJNDs for pure tone frequency\n(Roederer, 1995)\nTuesday, February 10, 2009\nGraph removed due to copyright restrictions.\nFig. 2.9 in Roederer, J. G. The Physics and Psychophysics of Music: An Introduction.\nNew York, NY: Springer, 1995.\n\nCritical bands\nPartial fusion,\nas tonal fusion\npartial loudness summation\n(Roederer, 1995)\nTwo sine waves,\none fixed at 400 Hz,\nthe other ascending\nfrom 400 Hz to 510 Hz\nat which point it is\nseparated from the\nfirst by a\ncritical bandwidth.\nTuesday, February 10, 2009\nGraph removed due to copyright restrictions.\nFig. 2.12 in Roederer, J. G. The Physics and Psychophysics of Music: An Introduction.\nNew York, NY: Springer, 1995.\nSee 2nd graph on this page:\n\nhttp://www.sfu.ca/sonic-studio/handbook/Critical_Band.html\n\nCritical\nbandwidths\n(Roederer, 1995)\n\nTuesday, February 10, 2009\nGraph removed due to copyright restrictions.\nFig. 2.13 in Roederer, J. G. The Physics and Psychophysics of Music: An Introduction.\nNew York, NY: Springer, 1995.\nSee 1st graph on this page: http://www.sfu.ca/sonic-studio/handbook/Critical_Band.html\n\nCritical bands (conventional, place-based interpretation)\nCRITICAL BAND and CRITICAL BANDWIDTH\nFor a given FREQUENCY, the critical band is the smallest BAND of frequencies around it\nwhich activate the same part of the BASILAR MEMBRANE. Whereas the DIFFERENTIAL\nTHRESHOLD is the just noticeable difference (jnd) of a single frequency, the critical\nbandwidth represents the ear's resolving power for simultaneous tones or partials.\nIn a COMPLEX TONE, the critical bandwidth corresponds to the smallest frequency\ndifference between two PARTIALs such that each can still be heard separately\n. It may\nalso be measured by taking a SINE TONE barely MASKed by a band of WHITE NOISE\naround it; when the noise band is narrowed until the point where the sine tone\nbecomes audible, its width at that point is the critical bandwidth. See: RESIDUE\n.\nIn terms of length (see diagram under BASILAR MEMBRANE) the critical bandwidth is nearly\nconstant at 1.2 mm, within which are located about 1300 receptor cells, and is\ngenerally independent of intensity (unlike COMBINATION TONES). Twenty-four critical\nbands of about one-third octave each comprise the audible spectrum.\nTuesday, February 10, 2009\nTruax, B., ed. From \"CRITICAL BAND and CRITICAL BANDWIDTH.\" http://www.sfu.ca/sonic-studio/handbook/Critical_Band.html\nHandbook for Acoustic Ecology. 2nd edition, 1999. Courtesy of Barry Truax. Used with permission.\n\nCritical bands (usually interpreted in terms of frequency analysis)\nSimultaneous tones lying within a critical bandwidth do not give any increase in\nperceived loudness over that of the single tone, provided the sound pressure level\nremains constant. For tones lying more than a critical bandwidth apart, their\ncombination results in increased loudness.\nWhen two tones are close together in frequency, BEATS occur, and the resulting\ntone is a fusion of the two frequencies. As the frequency difference increases,\nroughness in the tones appears, indicating that both frequencies are activating the\nsame part of the basilar membrane. Further apart, the two frequencies can be\ndiscriminated separately, as shown below by DfD, whereas roughness only\ndisappears at a frequency separation equal to the critical bandwidth DfCB. At this\npoint, the two frequencies activate different sections of the basilar membrane. This\nphenomenon only applies to monaural listening with pure tones. With DICHOTIC\nlistening, the basilar membrane of each ear is activated separately, and therefore no\nroughness results. With complex tones, frequency discrimination is improved but the\ncritical bandwidth remains the same for each of the component partials.\nAlternative interpretation is that critical bandwidths are the result of fusion of\n(e.g. interspike interval) representations rather than cochlear proximity per se.\nTuesday, February 10, 2009\nTruax, B., ed. From \"CRITICAL BAND and CRITICAL BANDWIDTH.\" http://www.sfu.ca/sonic-studio/handbook/Critical_Band.html\nHandbook for Acoustic Ecology. 2nd edition, 1999. Courtesy of Barry Truax. Used with permission.\n\nMasking by signal swamping\nReduce signal/noise to disrupt\nsignal detection\nCamouflage: pattern fusion\nDisruption of pattern detection\nRe: varieties of masking in the auditory\ns y s t e m , s e e D e l g u t t e ( 1 9 8 8 )\nPhysiological mechanisms of masking.\nIn. Duifhuis, Horst & Wit, eds. Basic\nIssues in Hearing. London. Academic\nPress, 204-14.\nTuesday, February 10, 2009\nPhoto courtesy of kirklandj on Flickr.\n\nSpatial hearing\nAzimuth:\ninteraural time differences (20-600 usec)\ninteraural level differences\nElevation:\nreceived spectrum of broadband sounds (pinna effects)\nDistance\nSpatial form (size, shape)\nEnclosure size, shape\nImage removed due to copyright restrictions.\nDiagram showing effect of interaural path-length differences.\nReverberation pattern\nFigure 2.1 in Warren, R. M. Auditory Perception: A New Synthesis.\nNew York, NY: Pergamon Press, 1982. ISBN: 9780080259574.\nPatterns of long delays\nAssignment of spatial attributes\nto auditory objects\nTuesday, February 10, 2009\n\nInteraural time difference and localization of sounds\nTuesday, February 10, 2009 Interaural time difference grows approximately linearly from 0 msec at 0 degrees to 0.6 msec at 90 degrees and then falling back to 0 msec at 180 degrees.\nFigure by MIT OpenCourseWare.\n\nBinaural cross-correlation and cancellation\nBinaurally-created pitches\n\nTones (F0 from one harmonic in each ear)\nPhase-disparity pitches (auditory analog\n\nof Julez random-dot stereodiagrams)\nRepetition pitches (weak)\nBinaural masking release (BMLD)\n\nA tone in noise that is just masked is\n\npresented to one ear. The tone cannot be heard initially.\nNow also present the identical noise alone in the other ear\n\nand the tone pops out. The noise appears to be cancelled\nout, providing up to 15 dB of unmasking.\nTuesday, February 10, 2009\n\nGeneralist vs. specialist sensory systems (conjectures)\n- General-purpose vs. special-purpose systems\n- Adaptability vs. adaptedness\n\nAdaptable: optimized for many different envs\nAdaptedness: high degree of optimization\n\nTradeoff between the two\nPanda gut (highly adapted) vs. human gut (omnivore, high adaptability)\nIn sensory systems, high adaptability is favored when appearances are\nhighly variable; adaptedness when appearances are highly constrained\nIntra-species communications: adaptedness is favored\nSignal production and reception under same genetic coordination\ne.g. pheromone systems\nInter-species interactions (predator or prey): adaptability is favored under\nvarying relations, adaptedness under stable relations\n(e.g. navigation systems, early warning systems, predator or prey\nrecognition)\nTuesday, February 10, 2009\n\nReading for Tuesday, Feb 13\nNext meeting we will introduce neural coding and\ngive an overview of the auditory system.\nWeinberger chapter in Deutsch (3)\nLook over auditory physiology chapter in Handel (12)\nTuesday, February 10, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Why we listen: The psychological functions of music",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/hst-725-music-perception-and-cognition-spring-2009/0b97823cebd3d10cf5d01ec5c701109b_MITHST_725S09_lec02_why.pdf",
      "content": "Why we listen:\nThe psychological functions\nof music\nWednesday, February 4, 2009\nHST.725 Music Perception and Cognition, Spring 2009\nHarvard-MIT Division of Health Sciences and Technology\nCourse Director: Dr. Peter Cariani\n\nAgenda\n- Definition of music\n- What is a psychological function? Brains as goal-seeking systems\n- Why we listen: how individuals use music for their own purposes\n- Social psychology of music: its social functions\n- Mass psychology of music\nWednesday, February 4, 2009\n\nContext\n- Contextualists vs. details people (two kinds of people in this world)\n- We are setting the context for our investigation of musical structure\n- What is a psychological function? Brains as goal-seeking systems\n- Why we listen: how we use music in our lives, why do we find it useful?\n- The question to be answered (to paraphrase Warren McCulloch):\nWhat is music such that it has its manifold effects on the human mind, and\nhow does the human mind function, such that music has its manifold effects?\nWednesday, February 4, 2009\n\nMusic: a provisional definition\nRandy Newman\nRagtime\nWhat makes sound musical? Its how we use it. (functional definition)\nA functional relation between sound and listener, not simply the sound itself\nDeliberate organization of sound for pleasure.\nDeliberate organization of sound sequences for pleasure.\nDeliberate organization of extended auditory experiences for pleasure.\n\n\"Organization\" can involve composition or\n\nperformance or selection of sounds\n\nor even selective attention to sounds (Cage's silences)\n\"Pleasure\" is similarly very broadly construed, and can mean\nSource: IMSLP.org\n\npsychological reward or interest of any sort.\n\nWednesday, February 4, 2009\n\nMy provisional definition:\nSequences of sonic events designed or selected to produce desired\npsychological effects not related to explicit communication\nMusic consists of sequences of sonic events that produce perceptual contrasts.\nPrimarily, these contrasts involve\ntonality (pitch: melody & harmony)\nrhythm (relative timings of events (rhythm)\ntimbre (especially in electronic music).\nGasparyan\nA cool wind is blowing\nStockhausen\nKontakte\nBrian Eno\nOn Land\nMickey Hart\nUdu Chant\nWednesday, February 4, 2009\nImage removed due to copyright restrictions.\nStill image from \"Mbire, Otabuna mukaire - olumbe wamanyi, Balikowa Centurio,\nPeter Kabodha and David Kasata.\" JVC / Smithsonian Folkways Video Anthology\nof Music and Dance of Africa, Vol. 1 (Egypt, Uganda and Senegal).\n\nMusic vs. speech\nMusic is somewhat distinct from acoustic communication in which component sounds\nare symbolic vehicles through which encoded messages are conveyed\n(e.g. speech, Morse code), because their functions are different\nSpeech sounds not part of a coded message system can be musical\nMusical sequences can also be used as symbols in communication (bugle calls)\nSpeech also has rhythmic aspects that are musical (lexical music, poetry)\nOf course, music and speech do come together in vocal music, where speech is made\nmusical without destroying its communicative aspects.\nKurt Schwitters\nUr sonata (excerpt)\nCharles Amirkanian\nDutiful Ducks\nWednesday, February 4, 2009\n\nBorderline cases:\nSound selection: Naturally occuring sounds regarded aesthetically, as in \"found art\",\nAmbient music: sounds that might not be readily recognized as music\nExtremely minimalist music (Tibetan singing bowl)\nJohn Cage's silences (4' 33\")\nWednesday, February 4, 2009\nMarcel Duchamp. \"Fountain\" , 1917. Photo by Alfred Steiglitz.\n\nMusic as stimulus, idea, action, and private experience\nrelation\nPsychology of music examines relations between music and mind.\nMusic is half of this relation.\nMind has different aspects:\n1st person experience (introspection)\n3rd person overt behavior (behavior)\nUnderlying neural physical activity\nMy definition of \"mind\" is the\nfunctional organization of informational processes in the brain (a.k.a. mental processes)\n\nWednesday, February 4, 2009\n\nPsychological functions\nOrganisms are goal-seeking systems (homeostasis, survival, reproduction)\nNervous systems evolved to coordinate behavior of motile animals\nFunctionalities of nervous systems\nSense the internal state of the organism and the state of the world\nChoose behaviors appropriate to sensed conditions\nImplement actions through effectors\nEmbedded goal-states that steer behavior\nSets of drives and motivations (sometimes mutually competing)\nMaslow's hierarchy of needs\nWe will assume for the moment that a psychological function is fulfilled\nwhen a goal state is achieved and the corresponding drive is reduced.\nWednesday, February 4, 2009\n\nsteering: percept-action coordinations!\naction!\nperception!\ninteraction w.!\nenvironment!\ninternal goals\nWednesday, February 4, 2009\n\n!\n\"\n#\n$\nhomeostat\nelement\n(pivoting\nmagnet)\nuniselector\ncapacitance\nresistance\nposition\nof the plate\ndetermines\nvoltage to\nuniselector\nand to\nA-coils\nof other\nmodules\nbattery\nA\nB\nC\nD\ncoils\nwires from other modules (inputs)\noutput\nto\nother\nmodules\nSummed\neffect\nof coil\nmagnetic\nfields on\npivoting magnet\nif V deviates from\nits null value > !\nuniselector\nadvances\nHOMEOSTAT MODULE A\nCybernetics, c. 1950-1960:\nadaptive. goal-seeking devices\nAshby's homeostat \"maintain homeostasis\"\nWednesday, February 4, 2009\nPhoto removed due to copyright restrictions.\nW.Ross Ashby, Warren McCulloch, Grey Walter, and Norbert\nWiener at a meeting in Paris. See http://www.rutherfordjournal.org/article020101.html\nPhoto of the homeostat removed due to copyright restrictions.\nSee http://www.vintagecomputer.net/electronic_brain/homeostat.jpg.\n\nWednesday, February 4, 2009\n\nLimbic & other reward systems: evaluation, emotion & motivation\nSome basic system goals:\nImage of limbic system removed due to copyright restrictions.\nMaintain homeostasis\nReproduce\nSeek pleasure\nAvoid pain\nReduce stress\nSelf-regulate, self-determine\nRelieve boredom\nSelf-affirm\nExplore\nPlay\nSource: US NIH\nWednesday, February 4, 2009\n\nMaslows Hierarchy of needs\n- WhPyramid shaped diagram\nwith most funda\nmental needs liste\nd at t\nhe bottom.\n-\n(Diagram\nWednesday, February 4, 2009\nMaslows Hierarchy of needs\n- Where might music fit in?\n-\n(Diagram from Wikipedia)\nFigure by MIT OpenCourseWare.\n\nPsychological functions of music\n- Perceptual & cognitive (engaging, interesting, entertaining)\n- Psychodynamic (e.g. Self-expression/actualization, identity)\n- Emotional (e.g. mood control, emotional contrast, arousal)\n- Social (e.g. membership,conformity/individuation/rebellion, ceremony, warfare, mating,\nsocial status, atmosphere of public spaces)\nWednesday, February 4, 2009\nImage removed due to copyright restrictions.\nCover of book \"Musical Identities\" with a photo of Johnny Rotten.\n\nWednesday, February 4, 2009 Figure illustrating regions of the brain that may be involved in music perception and performance.\nFigure by MIT OpenCourseWare. After Tramo, M. Science 291, no. 5501 (2001): 54-56.\n\nAs individuals we use music to control our own mental states\nfunctions of music for individual listeners\nSocial psychology of music: small groups, large groups, societies\nfunctions of music for voluntary groups (e.g. bonding, coordination)\nsocial functions of music (e.g. rituals, national identity, class,\neconomics of music production & consumption, politics)\nMass psychology of music: cultural dynamics\nwhy do particular kinds of music become popular @ different times?\nPsychohistory of music: are there larger patterns in history?\nWhy we listen:\nsome psychological functions of music in everyday life\nWednesday, February 4, 2009\n\nAs individuals we use music to control our mental state\nfor pleasure or beauty\nfor mood control (happy, sad)\nfor relaxation, stress reduction, pain masking, meditation\nfor distraction, arousal, to make the time go by\nfor amusement, cognitive interest, \"auditory cheesecake\"\nfor self-affirmation, motivation, identity-assertion\nfor enhancement of spirituality, religious feeling, serene or ecstatic\nand for many other reasons and activities.....\nWhy we listen:\nsome psychological functions of music in everyday life\nRed Hot Chili Peppers\nSnow (Hey Oh)\nLive your life\nT.I.\nClocks\nColdplay\nArterial\nRachel's\nI can't make you love me\nBonnie Rait\nSpirits Drifting\nBrian Eno\nPiano Space\nTakahashi\nEl Rey de Francia\nFlorata\nAnnua gaudia Calixtinus\nFlorata\nMonkey chant\nWhirling dervishes\nTibetan singing bowl\nTibetan Chakra Meditations\nAutobahn\nKraftwerk\nSunrise, sunset\nBright Eyes\nHerbie Hancock\nMaiden Voyage\nWednesday, February 4, 2009\n\nMovement: dance, exercise, repetitive work\nMemory: music for nostalgia, music for mnemonics\nArousal: music to stay alert (driving music)\nPlaying music and playing music games (guitar hero)\nImmersion: computer game music\nControl of sleep: waking or falling asleep\nMood setting: romantic activities\nDistraction during daily routines (bathing)\nSinging along (show tunes)\nFear, fright, suspense\nCatharsis, alienation, channeling anger\nEnhancement of activities in everyday life\nGet low\nBright Eyes\nRise of Nations\nBlue Monday\nNew Order\nAvenue Q\nSsltarello\nDead Can Dance\nPostizo\nMarc Ribot\nFly me to the moon\nBobby Darin\nLet's stay together\nAl Green\nSoul Man\nSam & Dave\nPsycho\nWednesday, February 4, 2009\n\nRage/Anger/Alienation\nSlipknot\nBefore I forget\nSlipknot\nPsychosocial\nWednesday, February 4, 2009\nPhoto of American heavy metal band Slipknot removed due to copyright restrictions.\n\nPolitical message/identity\nDown & out\nUnion solidarity (folk song)\nUS Civil rights movement (gospel)\nSongs of protest (folk, nuclear war)\nPoverty & despair (jazz)\nAnti-apartheid\nBrother, Can you spare a dime?\nBing Crosby\nFree Nelson Mandela\nThe Specials\nEve of Destruction\nBarry McGuire\nWinter in America\nGil Scott-Heron\nWe shall Overcome\nThe Specials\nWhich side are you on?\nFlorence Reese\nEyes on the Prize\nWednesday, February 4, 2009\n\nSocial-psychological functions: what does music do for social relations?\nGroup bonding, identity formation, camaraderie, musical subcultures\nGroup coordination (work songs)\nNonverbal communication\nIdentity formation & loyalty (nationalism, tribalism, anthems)\nSignification in rituals (weddings, funerals, public office)\nShared culture & aesthetic frames of reference\nPair-bonding rituals (dances, social events)\nPolitical movements\nVehicle for cultural/political dissent (beats, punk, skinheads, E. Europe in the Cold War, Iran)\nStatus differentiation (high vs. lowbrow, music & class)\nEconomic uses (Muzak, sets tone for public spaces, music industry)\nWe will rock you\nQueen\nWednesday, February 4, 2009\n\nAs individuals we use music to control our own mental states\nfunctions of music for individual listeners\nSocial psychology of music: small groups, large groups, societies\nfunctions of music for voluntary groups (e.g. bonding, coordination)\nsocial functions of music (e.g. rituals, national identity, class,\neconomics of music production & consumption, politics)\nMass psychology of music: cultural dynamics\nwhy do particular kinds of music become popular @ different times?\nPsychohistory of music: are there larger patterns in history?\nWhy we listen:\nsome psychological functions of music in everyday life\nMaymin\nNPR\nWednesday, February 4, 2009\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nHST.725 Music Perception and Cognition\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}