{
  "course_name": "Spatial Database Management and Advanced Geographic Information Systems",
  "course_description": "This semester long subject (11.521) is divided into two halves. The first half focuses on learning spatial database management techniques and methods and the second half focuses on using these skills to address a ‘real world,’ client-oriented planning problem. The first half of the semester may be taken separately using the class number 11.523 and the second half may be taken separately as 11.524.\nIn order to help shape and utilize the information infrastructure that will support the management and development of our metropolitan areas, planners need a basic understanding of the tools and technology for querying, analyzing, and sharing complex databases and maps. Managing online access to large and constantly-changing spatial datasets can be a powerful aid to planning and can facilitate inter-agency cooperation and collaboration in an increasingly decentralized world. But it requires the use of knowledge representation methods, client-server technologies and access control issues that are quite different from what are needed to model and visualize standalone datasets on a personal computer. Hence, planners should acquire basic skills in database management, digital spatial data analysis, and networking.\nThe 11.523 portion of the semester addresses these issues while retaining a focus on planning (rather than on computer science). This is an intensive, hands-on class that stresses learning by doing. Exercises and examples involving real-world data, maps, and images are used to develop skills with database query languages and the design development and use of structured databases. Class work utilizes web tools, GIS, and database software with lab exercises primarily on the new high-performance PC computing cluster. Specifically, we will access an Oracle 8i database using SQL (structured query language) and use ArcView for GIS. Each week there are two sixty to ninety-minute classes plus another 90+ minute hands-on lab in electronic classrooms. Class lectures will focus on concepts and case discussion, the scheduled lab time focuses on computer mechanics and skill building. Specific topics during 11.523 include:\n\nfinding, understanding and structuring digital spatial data that are available on the Internet using various browsing, visualization, and data management tools;\nconsiderable work with relational database technologies and the Structured Query Language (SQL) to design, construct, query, and update urban planning databases;\nsome experience with so-called ‘client/server’ and ’enterprise GIS’ technologies for facilitating distributed access to complex spatial data and urban planning applications;\nadvanced GIS topics such as 3D visualizations and geospatial web services.\n\nThe 11.524 portion of the semester will treat the classroom like a professional planning office, working as a team to produce a two deliverables for their client, Lawrence Community Works, Inc. (LCW), a community development corporation located in the City of Lawrence, Massachusetts. LCW and DUSP recently agreed to work together for the next five years to design and implement a multi-tier web-based planning system that promotes democratic involvement and informs community development projects. Your involvement this semester is critical, because the implementation plan that you craft this semester will serve as the road map for both organizations for years to come and the simple web-based planning tool that you design will engage stakeholders by giving them a better sense of how technologies can aid decision-making processes. To assist you with the more technical aspects of the project, we hired Robert Cheetham, President of Azavea, Inc. (http://www.azavea.com/ ), to provide exactly 100 hours of consultancy services. Through their project work, students will enhance important professional skills by:\n\nformulating an implementation plan for a real client;\ndesigning a simple web-based tool for understanding problems;\nengaging constituents and stakeholders in a real setting;\nintegrating theory and practice by evaluating the role of technology in community development;\nlearning to communicate effectively within a group and with a professional consultant;\nworking with such tools as the WWW, Access, ArcView, ArcIMS, SDE, etc.",
  "topics": [
    "Business",
    "Information Technology",
    "Engineering",
    "Civil Engineering",
    "Surveying",
    "Computer Science",
    "Data Mining",
    "Graphics and Visualization",
    "Social Science",
    "Sociology",
    "Community Development",
    "Urban Studies",
    "Urban Planning",
    "Business",
    "Information Technology",
    "Engineering",
    "Civil Engineering",
    "Surveying",
    "Computer Science",
    "Data Mining",
    "Graphics and Visualization",
    "Social Science",
    "Sociology",
    "Community Development",
    "Urban Studies",
    "Urban Planning"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nDescription\n\nThis semester long subject (11.521) is divided into two halves. The first half focuses on learning spatial database management techniques and methods and the second half focuses on using these skills to address a 'real world,' client-oriented planning problem. The first half of the semester may be taken separately using the class number 11.523 and the second half may be taken separately as 11.524.\n\nIn order to help shape and utilize the information infrastructure that will support the management and development of our metropolitan areas, planners need a basic understanding of the tools and technology for querying, analyzing, and sharing complex databases and maps. Managing online access to large and constantly-changing spatial datasets can be a powerful aid to planning and can facilitate inter-agency cooperation and collaboration in an increasingly decentralized world. But it requires the use of knowledge representation methods, client-server technologies and access control issues that are quite different from what are needed to model and visualize standalone datasets on a personal computer. Hence, planners should acquire basic skills in database management, digital spatial data analysis, and networking.\n\nThe\n11.523 portion of the semester\naddresses these issues while retaining a focus on planning (rather than on computer science). This is an intensive, hands-on class that stresses learning by doing. Exercises and examples involving real-world data, maps, and images are used to develop skills with database query languages and the design development and use of structured databases. Class work utilizes web tools, GIS, and database software with lab exercises. Specifically, we will access an Oracle 8i database using SQL (structured query language) and use ArcView for GIS. Each week there are two sixty to ninety-minute classes plus another 90+ minute hands-on lab in an electronic classroom. Class lectures will focus on concepts and case discussion, the scheduled lab time focuses on computer mechanics and skill building. Specific topics during 11.523 include:\n\nfinding, understanding and structuring digital spatial data that are available on the Internet using various browsing, visualization, and data management tools;\n\nconsiderable work with relational database technologies and the Structured Query Language (SQL) to design, construct, query, and update urban planning databases;\n\nsome experience with so-called 'client/server' and 'enterprise GIS' technologies for facilitating distributed access to complex spatial data and urban planning applications;\n\nadvanced GIS topics such as 3D visualizations and geospatial web services.\n\nThe\n11.524 portion of the semester\nwill treat the classroom like a professional planning office, working as a team to produce a two deliverables for their client, Lawrence Community Works, Inc. (LCW), a community development corporation located in the City of Lawrence, Massachusetts. LCW and DUSP recently agreed to work together for the next five years to design and implement a multi-tier web-based planning system that promotes democratic involvement and informs community development projects. Your involvement this semester is critical, because the implementation plan that you craft this semester will serve as the road map for both organizations for years to come and the simple web-based planning tool that you design will engage stakeholders by giving them a better sense of how technologies can aid decision-making processes. Through their project work, students will enhance important professional skills by:\n\nformulating an implementation plan for a real client;\n\ndesigning a simple web-based tool for understanding problems;\n\nengaging constituents and stakeholders in a real setting;\n\nintegrating theory and practice by evaluating the role of technology in community development;\n\nlearning to communicate effectively within a group and with a professional consultant;\n\nworking with such tools as the WWW, Access, ArcView, ArcIMS, SDE, etc.\n\n11.521 versus 11.523 or 11.524\n\nThe subject 11.521 = 11.523 + 11.524 and you can register for 11.521 or (11.523 plus 11.524) or either one of the half semester modules.\n\nThe subject 11.521 is a full-semester class that earns 12 units ( 3-3-6) of H-level graduate credit\n\nThe subject 11.523 includes classes 1-13 of 11.521 (plus labs) and earns 6 units (2-2-2) of H-level graduate credit. This subject covers the spatial database portion of 11.521\n\nThe subject 11.524 includes classes 14-26 of 11.521 (plus labs) and earns units to be arranged (generally 1-1-4 unless you are taking 11.524 a second time). This subject covers the advanced GIS project portion of 11.521\n\nThe subject 11.521 cannot be taken for credit with 11.523 or 11.524 in the same semester; the subject 11.524 can be taken again in another term. Students who have not decided in which class to enroll should sign up for both 11.521 and 11.523, then drop one of the subjects by the drop date.\n\nPrerequisites\n\nThe prerequisite for this class is\n\n(a) either\n\n11.204\n: Planning, Communications and Digital Media,\n\n11.208\n: Introduction to Computers in Public Management II or\n\n11.520\n: A Workshop on Geographic Information Systems, and\n\n(b) an understanding of analytic methods that most undergraduates acquire via general Institute requirements and MCP students obtain from course from\n\n11.220\n: Quantitative Reasoning and Statistical Analysis I (which may be taken concurrently).\n\nRequirements\n\nExercises, class discussions, and projects use real databases and problems taken from current Planning Support Systems (PSS), involving local and regional planning agencies. These data include parcel-level maps, tabular data, and digital orthophotos for all of Boston; land use, wetland, and other environmental planning datasets for the state; and detailed information about the neighborhoods being studied for the project.\n\nThe full course includes nine lab exercises; 11.523 students complete the first six labs, and 11.524 students do the last three. Each lab includes an assignment to be turned in. To facilitate a quick turnaround on grading, these assignments will be evaluated on a three-point scale: check-minus, check, check-plus. Students in 11.521 and 11.523 will complete three homework sets and have an examination before Spring Break. Students in 11.521 and 11.524 will complete a half-semester group project during the second half of the term that provides an opportunity to apply GIS and database concepts in a more realistic context. The project concludes with an oral presentation to the client and a written report. In addition to preparing paper maps of various sizes, each team will build a web site to showcase its work.\n\nGrading\n\n**11.521:\n\n**Grade is average of 11.523 and 11.524 grades\n\n11.523:\n\n6 Lab Exercises (collectively).............15%\n\n3 Problem Sets (collectively)..............45%\n\nExamination.......................................35%\n\nClass Participation...............................5%\n\n11.524:\n\nLab 7.....................................................................................10%\n\nLab 8.....................................................................................15%\n\nLab 9.....................................................................................15%\n\nInternal and On-Site Project Presentations...........................10%\n\nFinal Project Part one: Implementation..................................25%\n\nFinal Project Part Two: Web-based Planning Application.......25%\n\nLateness Policy\n\nTurning in assignments promptly is important both for keeping current with the subject matter, which is cumulative, and to keep all students on a level playing field. Hence, we have adopted a strict policy towards credit for assignment that is turned in late.\n\nLab exercises are typically due one week after the lab is run. A late lab exercise will be accepted up until one week after the original due date for a loss of one grade (e.g., a \"check\" becomes a \"check-minus\"). After that, late assignments will receive no credit and will not be accepted.\n\nLate problem sets will have two points deducted for each day (including weekends and holidays) after the due date. Hence, a problem set turned in three days late would lose 6 points. If it would have earned 90 points if turned in on time, it would receive only 84 points under these conditions. Regardless, no problem sets will be accepted after the answers have been posted, typically two weeks after the initial due date.",
  "files": [
    {
      "category": "Resource",
      "title": "ps3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/7d9041d81ba4d52ad7375165cc7e34cc_ps3.pdf",
      "content": "Problem Set 3: Relational Database\nDesign\nOverview\nIn this problem set you will:\n-\nCreate an entity-relationship diagram for the 'urisa' database\n-\nConstruct a simple database design\n1. Entity-Relationship Diagram for the 'urisa' Database\n*\nLook over the schema for the 'urisa' database , and then draw an entity-relationship\ndiagram for it. Your diagram should include the authors, titles, keywords, and match\ntables. Make sure to clearly indicate the primary and foreign keys and the cardinality\nrelationships. You can draw your E-R diagram on paper or use a software package to\nassist you. If you choose to create your diagram electronically, make sure to save the\noutput in a format that can be read easily without the software that created the diagram.\nAn ideal choice is PDF, but image formats such as GIF, JPEG, and PNG are also\nacceptable provided the diagram is readable.\n2. A Simple Database Design\nImagine you work for the public housing agency of a city, and you have been charged\nwith keeping track of who is living in the agency's developments over time. To help you\nin this task, you have decided to use a relational database for your record keeping. Your\ntask is to design a database that allows you to capture the facts described below:\n-\nThe city has three public housing developments. You want to record their names,\nlocations, the year they opened, and their height in stories.\n-\nFor each unit in the development, you want to keep track of the number of\nbedrooms, the number of bathrooms, whether the unit has a kitchen or living\nroom, and the square footage.\n-\nThe database should keep track of the households living in the units. For each\nmember of a household, you want to record their name, date of birth, sex, and\nindicate whether or not they are they are the head of the household (more than one\nperson can share that distinction).\n* Kindly refer to the Assignment Section\n\n-\nYou also want to keep track of when a household moved into and out of a\nparticular unit. You want to be able to follow households as they move from one\nunit to another or from one development to another. Think about how you will\nfind the unit that the household is currently occupying (i.e., what query would\nyou write to find the current unit of each household).\nYou will invent data for the three developments; two units in each development; and\nthree families, one with 2 members, one with 3 members, and one with 4 members.\nInclude records for each household making one move to another unit. You will insert\nthese data in your database using INSERT statements.\nYou may be interested to know that this assignment was inspired by records kept by the\nBoston Housing Authority about their developments. Hence, this type of problem has\ndefinite real-world importance.\nThe Process\nFollow the following process while designing your database:\n-\nConsider the problem, identifying the entities involved, their attributes, and\nrelationships among them.\n-\nDraw an entity-relationship diagram that captures your thinking. Turn in your E-R\ndiagram with your problem set. As in part 1, you may either create your diagram\non paper or use software. The same caveats for electronic diagrams in part 1 apply\nhere.\n-\nMake sure that your schema adheres to third normal form.\n-\nIn a text editor, construct a script that implements a schema that represents your\nentities and relationships. Name this file username_dbschema.sql, where\nusername is your Athena username. Record the output from running your SQL\nscript in the file username_dbschema_log.txt. Follow these guidelines as you\nwrite your script:\no Include the \"SET ECHO ON\" command at the start of the file. This will\nallow you to see your commands as they execute.\no Use the SQL*Plus SPOOL command to create your log file automatically.\nDon't forget to use the 'SPOOL OFF' command at the end of the script.\no Include DROP TABLE statements for all your tables. This will help if you\nhave to run your script more than once, which will almost certainly be\nnecessary. Include the clause \"CASCADE CONSTRAINTS\" at the end of\nyour statement. This makes sure any foreign key constraints that refer to\nthis table are dropped too. If these constraints are not dropped, Oracle will\nreport an error when you try to drop the table. For example:\n\nDROP TABLE parcels CASCADE CONSTRAINTS;\no Include CREATE TABLE statements for all your tables.\no Review the notes entitled \"Enforcing Referential Integrity in Oracle.\"\nThen, write:\n\nALTER TABLE ADD CONSTRAINT statements to define the\ntables' primary keys.\n\nALTER TABLE ADD CONSTRAINT statements to define the\ntables' foreign keys.\no Include comments that indicate the meaning of your statements. SQL\ncomments begin with two dashes together (--). Everything after the dashes\nis ignored on that line only. For example:\n-- This text is a comment.\nSELECT * FROM cat; -- The text after the dashes is\nalso a comment.\n-- However, the SELECT statement above is not part\n-- of the comment.\n-\nReview your database design using the database design lecture notes*. Pay\nparticular attention the database design rules of thumb. Are you breaking any of\nthese rules? If so, why? Remember, breaking the rules is often OK, provided you\nhave a good reason. If you make some choices you think that might raise some\nquestions, make sure to address them in your comments.\n-\nRun your script in SQL*Plus using the command '@dbschema.sql'. Correct any\nerrors in your script and run it again. Keep trying until it works. Errors generated\nby attempts to drop tables that you haven't created yet are normal and can be\nignored. Note that you can use the '@file.sql' syntax to run any SQL script. The\n.sql extension is assumed if you leave it out.\n-\nAdd some sample data to your tables. Create another script called\nusername_dbinsert.sql. Record the output from running your SQL script in the\nfile username_dbinsert_log.txt. Insert about five rows in each table using\n'INSERT INTO table VALUES (...)' statements. For example, consider the table\nmytable created by this CREATE TABLE statement:\nCREATE TABLE mytable (\nmycomment\nVARCHAR2(10),\nmylowvalue NUMBER,\nmyhighvalue NUMBER,\nmydate\nDATE);\nYou could insert two rows into mytable this way:\n* Kindly refer to the Assignment Section\n\nINSERT INTO mytable\nVALUES ('Hi Mom', 1, 5, '30-OCT-98');\nINSERT INTO mytable (mycomment, mydate)\nVALUES ('Hi Dad', '1-NOV-98');\nNote that Oracle is fussy about date values and will, by default, accept dates only\nin the format 'DD-MON-YY' within single quotes as shown above. You may use\nthe TO_DATE function to use a different format in a particular instance, for\nexample:\nINSERT INTO mytable (mycomment, mydate)\nVALUES ('Bye Mom', TO_DATE('11/10/1998',\n'MM/DD/YYYY'));\nAlternatively, you can use the 'ALTER SESSION SET NLS_DATE_FORMAT'\ncommand to change the format for a particular session, as shown below:\nALTER SESSION SET NLS_DATE_FORMAT = 'MM/DD/YYYY';\nAfter executing the statement above, the following statement should work:\nINSERT INTO mytable (mycomment, mydate)\nVALUES ('Bye Dad', '2/15/2002');\nRefer to the Oracle8i SQL Reference for the details of TO_DATE, ALTER\nSESSION SET NLS_DATE_FORMAT, and date format models. Be forewarned:\ndabbling in date format models has many potential gotchas (most notably\nconfusing MM (months) with MI (minutes)). Read carefully!\n-\nRemember to use a COMMIT statement after inserting rows to make sure the data\nis saved permanently. A SQL error may cause an automatic ROLLBACK of your\nchanges. (You can use the ROLLBACK statement on purpose if you want to undo\nchanges since the last COMMIT.) Many statements include implied COMMITs,\nand not all errors cause a ROLLBACK. Query your tables often to make sure that\nyour SQL statements are having the desired effect!\n-\nTest all your primary and foreign key constraints with some INSERT statements\nthat are intended to fail. Try to insert a duplicate primary key. Also try to insert a\nforeign key that does not exist as a primary key in the referenced table. For every\nconstraint you create, you should have an INSERT statement that tests the\nconstraint. Record these statements in the text file username_dbtest.sql. Record\nthe output from running your SQL script in the file username_dbtest_log.txt.\n-\nExtra credit: Write a series of statements that records two households moving\nfrom one unit to another, with one taking over the unit once held by the other. At\nleast transaction control statement such as COMMIT or ROLLBACK is\nrequired.\n\n3. What to Turn In\nThe breakdown of point values for this assignment is as follows:\n-\nEntity relationship diagram for the 'urisa' database: 15 points\n-\nEntity relationship diagram for the housing database: 25 points\n-\nSchema definition file and log file: 30 points\n-\nData insert file and log file: 10 points\n-\nConstraint test file and log file: 20 points\n-\nExtra credit: 5 extra credit points\nTurn in your username_dbschema.sql, username_dbschema_log.txt,\nusername_dbinsert.sql, username_dbinsert_log.txt, username_dbtest.sql,\nusername_dbtest_log.txt and two entity relationship diagrams files."
    },
    {
      "category": "Exam",
      "title": "exam.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/3b7ddc1259da185c91102055789607d2_exam.pdf",
      "content": "Examination\nInstructions\nThis is an open-book, open-note examination. You are free to use the web (especially the\nclass web pages and Oracle documentation) to help you. Like any examination, however,\nwe expect your submission to reflect your work exclusively. Hence any communication\nvia any means (e.g., voice, paper, e-mail, zephyr) with anyone other than the class\ninstructors is prohibited.\nThe exam duration is 90 minutes but you can take 2 hours so that there is less time\npressure. All the tables needed for the exam questions are accessible in Oracle via\nSQL*Plus using your personal Oracle account that we have been using for lab exercises\nand homework.\nThe exam is worth a total of 100 points.\nAn effective way for you to prepare your exam answers is to use the same familiar\nmethods you have used for the lab assignments and homework. Create an ASCII text or\nHTML file in your CRL or Athena locker to contain your answers. Name your exam\nusername_exam.txt if you use text format or username_exam.html if you use HTML\nformat. For your own security, we suggest that you save it in the \"Private\" subdirectory\nof your locker (i.e., the user smith might create the text file on her H:\\ drive from a PC\nand name it H:\\Private\\smith_exam.txt. If she stored the file in her CRL locker, it\nwould be S:\\smith\\private\\smith_exam.txt). We strongly recommend that you retain the\nfile containing your answers until we return the graded exams to you.\n-\nRemember to turn in your exam (in plain ASCII text or HTML format) before\nleaving the room.\n-\nMake sure to include your name and Athena user ID near the beginning of your\nfile (failure to include this will cost you 5 points; you lose 2 points if you supply\nonly one piece of information)!\n-\nPlease confirm with an instructor that your exam has been received.\nFinally, don't spend all your time on one or two questions. Start by looking over all the\nquestions to get a general sense of what, and how much, is being asked, and the grade\npoints associated with each question. Then start work on your answers but move on to the\nnext question if you've spent more than 10 minutes on any one of them.\nGood luck!\n\nPart I: Conceptual and 'Fix SQL' Questions (40 points)\nQuestion I-1.\nThe query below is intended to find the average price per square foot of each parcel that\nwas sold. For any parcel that was sold more than once, we would like to compute the\naverage price per square foot. However, the query generates an error message.\nSELECT p.parcelid, count(*), s.sprice/sum(p.sqft)\nFROM parcels p, sales s\nWHERE p.parcelid = s.parcelid\nGROUP BY p.parcelid\nORDER BY count(*) DESC;\nQuestion I-1a (4 points): Why does the query generate an error message?\nQuestion I-1b (8 points): Rewrite this query to produce the correct result. Show your\nSQL and its output.\nQuestion I-2 (10 points)\nDescribe in a few sentences (using illustrative examples from class data tables) the main\ndifferences among one-to-one, one-to-many, and many-to-many relationships. How are\nmany-to-many relationships typically handled when designing relational databases?\nQuestion I-3\n*\nBased on the parcels database described in the parcels database , answer the following\nquestions:\nQuestion I-3a ( 10 points): Draw an E-R diagram for the parcels, owners, and sales\ntables.\nQuestion I-3b ( 8 points): Suggest a query involving both a 'group by' and a three-way-\njoin of these three tables. Show your SQL query and the table that it returns.\n* Kindly refer to the Exams Section\n\nPart II: Writing SQL Statements (60 points)\nFor all the questions in this part, show us the SQL and SQL*Plus statement(s) you used\nand their results. We cannot give you partial credit if we are unable to follow your work.\n(Note, there is no requirement to answer all questions with a single SQL statement. If you\nfind it convenient to break up a complex query into more than one SQL statement, that is\nokay. Just be clear about what you did.)\nQuestion II-1\nQuestion II-1a (5 points): Based on the parcels database, which parcel has the highest\nper sqft property value (land value + building value)?\nQuestion II-1b (4 points): Who owns this parcel?\nQuestion II-1c (4 points): Has there been a fire on this parcel?\nQuestion II-2\nQuestion II-2a (6 points): How many URISA papers use keywords that have \"DATA\"\nas part of the keywords? For each of the keywords, count the paper numbers and sort it\nby the counts.\nQuestion II-2b (10 points): Using the URISA database, develop a SQL query that lists\nall the keyword codes along with the number of times they were used for all the papers\nauthored by NICHOLAS R. CHRISMAN.\nQuestion II-3: This query identifies all the zoning variances that involved a board\ndecision that agreed with the BRA recommendation:\nselect CASENUMBER, brarecom, boarddecis\nfrom zoning\nwhere brarecom > 0 and boarddecis > 0\nand brarecom = boarddecis\norder by brarecom;\nQuestion II-3 (6 points): Rewrite the query to count how many of these cases had each\npossible result for the brarecom (and boarddecis) variables.\nQuestion II-3b (10 points): For each brarecom value, determine the number of these\ncases that requested requested converting vacant land into housing?\n\nQuestion II-4: Consider the SALES table in the parcels database.\nQuestion II-4(a) (5 points): Write a query that lists all parcels in the SALES table that\nsold more than once.\nQuestion II-4(b) (10 points): Write a query to determine the time (in days) between the\nearliest and latest sale date for all parcels that sold more than once. [Note that you can\nsubtract two dates in order to get the number of intervening days.]\nExam Turnin Checklist\n-\nIs your name and Athena ID at the top of your exam? If not, you'll lose 5 points\n(2 points if you include one but not the other)!\n-\nIs your completed test saved in a plain text (ASCII) file named\nusername_exam.txt or HTML (web page) file named username_exam.html?\n-\nDid you confirm with an instructor that your exam was received?"
    },
    {
      "category": "Exam",
      "title": "practiceexam.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/0f10b84ea53073de177f24dd5e15db48_practiceexam.pdf",
      "content": "PRACTICE Examination\nThis is last year's exam. Note that it was considered a bit\ntoo long and too hard. This year's will be shorter and will\ninclude a bit more on database design and less of the most\ntechnical stuff. Otherwise, it will have a similar format.\nInstructions\nThis is an open-book, open-note examination. You are free to use the web (especially the\nclass web pages and Oracle documentation) to help you. Like any examination, however,\nwe expect your submission to reflect your work exclusively. Hence any communication\nvia any means (e.g., voice, paper, e-mail, zephyr) with anyone other than the class\ninstructors is prohibited.\nThe exam duration is 90 minutes. All the tables needed for the exam questions are\naccessible in Oracle via SQL*Plus using your personal Oracle account that we have been\nusing for lab exercises and homework.\nThe exam is worth a total of 100 points.\nAn effective way for you to prepare your exam answers is to use the same familiar\nmethods you have used for the lab assignments and homework. Create an ASCII text or\nHTML file in your Athena account to contain your answers. Name your exam\nusername_exam.txt if you use text format or username_exam.html if you use HTML\nformat. For your own security, we suggest that you save it in the \"Private\" subdirectory\nof your Athena account (i.e., the user smith might create the text file\n/mit/smith/Private/smith_exam.txt). Note that you need the capital \"P\"! We strongly\nrecommend that you retain the file containing your answers until we return the graded\nexams to you.\n-\nRemember to turn in your exam (in plain ASCII text or HTML format) before\nleaving the room.\n-\nMake sure to include your name and Athena user ID near the beginning of your\nfile (failure to include this will cost you 5 points; you lose 2 points if you supply\nonly one piece of information).\n-\nPlease confirm with an instructor that your exam has been received.\n\nTo turn in your exam, use the turnin command with assignment 100. If your exam were\nnamed username_exam.txt, you would use this command to turn it in from the 11.521\nwindow:\nturnin -c 11.521 100 username_exam.txt\nFinally, don't spend all your time on one or two questions. Start by looking over all the\nquestions to get a general sense of what, and how much, is being asked, and the grade\npoints associated with each question. Then start work on your answers but move on to the\nnext question if you've spent more than 10 minutes on any one of them.\nGood luck!\nPart I: Short Answer and 'Fix SQL' Questions (45\npoints)\nQuestion I-1.\nThe query below is intended to find all the parcels owned by Gerald Rappaport, but it\nfails with the error 'ORA-00904: invalid column name':\nSELECT p.parcelid, p.add1, p.add2, p.zip\nFROM parcels p, owners o\nWHERE p.onum = o.ownernum\nAND o.oname = \"GERALD RAPPAPORT\";\nQuestion I-1a (3 points).\nWhy doesn't the query do what is intended?\nQuestion I-1b (7 points).\nRewrite this query to produce the correct result. Show your SQL and its output.\nQuestion I-2.\nTake a look at the query and its output below, which is intended to list information about\nthe parcels that:\n-\nare greater than 20,000 square feet or are in ward-precinct-block (wpb) 112\n-\nhad at least one fire\nSELECT p.parcelid, p.wpb, p.sqft, f.fdate\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid\nAND p.sqft > 20000\nOR p.wpb = 112\n\n---------- ---------- ---------- ---------\nORDER BY p.parcelid, p.sqft, f.fdate;\nPARCELID\nWPB\nSQFT FDATE\n100000 02-AUG-88\n100000 02-APR-89\n5500 01-AUG-87\n5500 02-AUG-88\n5500 02-APR-89\n5500 02-JUL-89\n5500 26-JUL-89\n5500 26-JUL-90\n50000 02-JUL-89\n9 rows selected.\nNotice that the parcel with parcelid = 3 is listed six times. However, this parcel had only\ntwo fires.\nQuestion I-2a (3 points).\nWhy doesn't the query do what is intended? (Note: You should mention a specific term\nthat applies to an aspect of this problem.)\nQuestion I-2b (7 points).\nRewrite the query to obtain the right result. Show your SQL and its output.\nQuestion I-3(a) (5 points).\nConsider the structure of the keywords table in the URISA database. Which of the\nnormal forms that we have discussed in detail in class does this table violate? Why?\nQuestion I-3(b) (5 points).\nHow would you redesign this database with respect to the keywords table only to correct\nthis problem? (The other URISA tables, authors, titles, and match, should remain\nunchanged.) Make sure to describe the resulting keys and their relationships. You do not\nneed to write SQL statements that implement your result, although you are welcome to\ndo so to augment your discussion. A verbal description of the changes you would make is\nsufficient.\n\n---------- ---------- ---------- ----------\nQuestion I-4.\nSuppose the city is considering reducing the building values (stored in the tax table) of\nparcels that experienced fires by the amount of the total estimated losses from all the\nfires. First, we can make a copy of the tax table called mytax that will hold the new\nvalues:\nCREATE TABLE mytax AS\nSELECT *\nFROM tax;\nTable created.\nWe can test the impact of this change running this query:\nSELECT t.parcelid, t.bldval, SUM(f.estloss) losses,\nt.bldval - SUM(f.estloss) new_bldval\nFROM mytax t, fires f\nWHERE t.parcelid = f.parcelid (+)\nGROUP BY t.parcelid, t.bldval\nORDER BY t.parcelid;\nPARCELID\nBLDVAL\nLOSSES NEW_BLDVAL\n9 rows selected.\nFrom this query, we can see that three parcels (2, 3, and 20) in the mytax table have\nqualifying losses from fires. However, since parcel 20 has a NULL value for bldval, its\nbuilding value will remain NULL.\nNow, we can attempt to update the mytax table:\nUPDATE mytax t\nSET t.bldval = t.bldval -\n( SELECT SUM(f.estloss)\nFROM fires f\nWHERE f.parcelid = t.parcelid)\nWHERE EXISTS\n( SELECT NULL\nFROM fires f, mytax t\nWHERE f.parcelid = t.parcelid);\n9 rows updated.\n\n---------- ---------- ----------\nNotice that all nine rows in mytax were updated, not just the three with qualifying fires.\nIf we look at the tax table now, we'll see that many of the building values have been\nwiped out and set to NULL:\nSELECT t.parcelid, t.bldval, SUM(f.estloss) losses\nFROM mytax t, fires f\nWHERE t.parcelid = f.parcelid (+)\nGROUP BY t.parcelid, t.bldval\nORDER BY t.parcelid;\nPARCELID\nBLDVAL\nLOSSES\n9 rows selected.\nQuestion I-4(a) (7 points). Why were all nine rows in the table updated instead of only\nthe three we wanted (parcels 2, 3, and 20, that had fires)?\nQuestion I-4(b) (8 points). Rewrite the UPDATE statement above so that it updates only\nthe three parcels in the mytax table that had fires. Run your UPDATE statement, then\nrerun the last SELECT statement above to show the results from the update. Remember\nto ROLLBACK any updates that don't work correctly before running the next update. (If\nyou run into too many problems, remember that you can DROP the mytax table and\nCREATE it again.) Show your SQL UPDATE statement and the results from the last\nquery above after the update.\nPart II: Writing SQL Statements (55 points)\nFor all the questions in this part, show us the SQL and SQL*Plus statement(s) you used\nand their results. We cannot give you partial credit if we are unable to follow your work.\nQuestion II-1(a) (10 points).\nUsing the ZONING database, write a query that finds:\n-\nby neighborhood name\n-\nthe count of cases\n-\nwith a known board decision\n\n-\nthat propose to change the land use from 'VACANT LAND' to 'OFFICE'\n-\nfor those neighborhoods that have more than one such case.\nUse the text descriptions of the land uses, not numeric codes. Sort by the counts in\ndescending order.\nQuestion II-1(b) (15 points).\nNow, find the names of all the neighborhoods that have no cases with a known board\ndecision that propose to change the land use from 'VACANT LAND' to 'OFFICE', i.e.,\nthe neighborhoods not returned by the query in Question II-1(a). List the neighborhood\nnames in ascending order.\nQuestion II-2 (15 points).\nUsing the ZONING database, list the count of cases by neighborhood name where the\nstreet name is 'CENTRE'. Include all the neighborhoods, whether they have a case or not.\nList the neighborhood name and the count of cases sorted by the neighborhood name in\nascending order.\nQuestion II-3 (15 points).\nConsider the SALES table in the 'toy' PARCELS database. Which GRANTORs were also\nGRANTEEs? Show only their names, in alphabetical order and without duplicates.\nExam Turnin Checklist\n-\nIs your name and Athena ID at the top of your exam? If not, you'll lose 5 points\n(2 points if you include one but not the other)!\n-\nIs your completed test saved in a plain text (ASCII) file named\nusername_exam.txt or HTML (web page) file named username_exam.html?\n-\nDid you turn in your test with the turnin command? You should use a command\nlike this:\nturnin -c 11.521 100 username_exam.txt\n-\nDid you confirm with an instructor that your exam was received?"
    },
    {
      "category": "Resource",
      "title": "lab1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/9d15807415d25c692ec612a61562cbe2_lab1.pdf",
      "content": "Lab 1:\nIntroduction to Oracle and SQL\nThis lab exercise has two primary purposes: (1) to acquaint you with the computing\nenvironment and basic tools that we will be using this semester, and (2) to introduce you\nto simple relational joins and database queries using the structured query language\n(SQL). For the SQL queries, we will use a set of seven, small tables that are similar in\nstructure and content to the types of information about property ownership and landuse\nthat are maintained by most local assessing and planning offices. For ArcView, we will\nuse the lab exercises from 11.204 (one of the prerequisites for this course).\nPart I: Attach CRL Lockers to your computer\nIn order to access the files in the CRL space, you need to attach several CRL lockers to\nyour computer. These network storage lockers will already be attached if you are doing\nthese exercises from CRL PCs. If you are an MIT student and wish to do the exercises\non your own laptop while connected to the internet, talk to the staff. (You'll need the\nSQL*Plus application software or an ODBC driver for Oracle).\nOpen \"my computer\", in the menu Tools, choose \"Map Network Drive...\". Map\n\"\\\\grotto\\crlclass\" as the Drive K:.\n\nClick on \"different user name\", in the new windows type in your CRL user account and\npassword (make sure put \"crl\\\" before your username.) Then click OK.\nClick Finish. Wait for a minute for the locker being attached. In the same way, add in the\nfollowing lockers. You don't need to specify the username and password again after you\nmap the first one since Windows remember the username and password during the\nsession.\nDrive M: \\\\crypt\\massgis\n\nDrive S: \\\\grotto\\crlspace1\nDrive X:\\\\agora\\crlbucket\nThe naming system of the lockers is slightly different from the one in CRL. H: drive is\nused here as the Athena locker rather than the CRL locker. You can access your CRL\nspace through drive S--open Drive S and go one level down to find your folder.\nPART II: ORACLE SQLPlus9i SETUP\nFor our SQL exercises we will use databases stored in an Oracle database engine running\non a CRL server, named bulfinch.mit.edu. We will use so-called 'client/server' technology\nto query these databases via MITnet using SQL*Plus-- an Oracle client that connects to\nthe 'backend' database engine using Oracle's Net9 with standard TCP/IP protocols. Most\nof this is transparent to the user. Here are the steps needed to connect to the database\nengine from any windows XP computers.\nSteps\nA. Login to the windows XP using your Athena account. Make sure the domain is set to\n\"ATHENA.MIT.EDU (Kerberos Realm)\".\nB. Start/Programs/Oracle/SQL Plus\nC. Fill in the user name and password of your CRL Oracle account. Use CRL as the Host\nString. Then press OK. On the first class, you are going to use the public account--user\nname \"parcels\", and the password will be given by the instructor in class. Then we will\ncollect your information and create a CRL Oracle account for you. In the following labs\nyou are going to use your own CRL Oracle account.\nD. The interface of Oracle SQL Plus looks like the following. \"SQL>\" is the prompt in\nOracle SQL Plus which indicates that it is ready for Oracle SQL Plus to accept your\ncommands.\n\nPART III: Running Basic SQL Select Statement Queries\nAt this point, you have all the connections and windows in place and you are ready to\nbegin doing SQL queries. Now let's use our small, hypothetical parcel and property tax\ndatabase to get a feel for how we can use SQL*Plus to run simple queries. Elsewhere on\nthe class help pages, we describe this sample parcel database* and the basic structure of\nthe SELECT command*. Type in some simple queries or you can use cut-and-paste to\ngrab pieces of queries from any text editors. You will probably find it helpful to edit the\nqueries in a separate window with text editors such as 'Notepad'. When you are finished\nediting a query, you can cut and paste it into the SQL window.\n.\nTry out each of the following SQL examples of SELECT statements.\nQuery Tasks\nThe simplest query\nSQL Statements\nSELECT * FROM tax;\n* Kindly refer to the Labs section\n\nlisting the TAX table\nA query with an\nSELECT parcelid, (landval + bldval)\nexpression and a column\nalias\nA simple query that\ntot_val, tax\nFROM tax;\nSELECT COUNT(*), MIN(tax), MAX(tax),\naggregates (groups) over\na whole table\nThis example uses a\nAVG(tax)\nFROM tax;\nSELECT parcelid, 'Total prop value\nliteral string in the\nSELECT list\nA simple query using the\nis', (landval + bldval), tax\nFROM tax;\nSELECT *\n\"IS NULL\" syntax to list\nonly those parcels with\nat least 20,000 sq. ft.\nand no missing value\nCompare the results of\nFROM parcels\nWHERE sqft >= 20000 OR sqft IS NULL;\nSELECT *\nthe query 5 with query 6.\nWhy are they different?\nA query to find values\nFROM parcels\nWHERE sqft >= 20000 OR sqft = NULL;\nSELECT *\nwithin a certain range\nAnother way of writing\nFROM parcels\nWHERE sqft >= 10000 AND sqft <=\n100000;\nSELECT *\nthe query above using the\n-- \"BETWEEN\" keyword\nA simple join between\nFROM parcels\nWHERE sqft BETWEEN 10000 AND 100000;\nSELECT p.*, f.estloss\nPARCELS and FIRES. Note\nthat only those parcels\nwhich had fires are\nlisted.\nA slight variation of\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid;\nSELECT p.parcelid, p.sqft,\nquery 9.\np.landuse, f.estloss\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid\nORDER BY f.estloss;\nPART IV: TUNING SQL*PLUS AND SPOOLING OUTPUT TO A FILE\nThe end of the 'SQL Help'* web page contains some useful tips and tricks to customize\nyour SQL*Plus environment, to save and retrieve SQL queries, and to spool SQL output\ntables into text files. Review these tips and tricks paying particular attention to\n1.\nthe use of set linesize nnn to set the line width to nnn characters\n2.\nthe use of COLUMN sss FORMAT A5 and the like to control formatting of\ncolumn output, and\n* Kindly refer to the Labs section\n\n3.\nthe use of the spool file command to start and stop the spooling of SQL*Plus\noutput to a Unix file.\nRegarding the spool command, if you do not specify a full path name for the file, it will\nbe written in the default directory -- that is, your H drive. Try out the spool command by\nspooling to a file, running one or two SQL queries, turning off the spooling, and then\nopening up the spooled file in your text editor window.\nPART V: PRINTOUT\nWe cannot print the SQL statement and the query result directly from Oracle SQL Plus.\nThere are two alternative ways to print them out.\n1)\nSpool the SQL statements to a \".LST\" file, open it in a text editor such as Notepad,\nthen print it there.\n2)\nCopy the SQL statements and paste them in a text editor then print there.\nPrint out in either way the SQL statements and the query results for Query 3, 7 and 10 in\nPART III.\nPART VI: ARCVIEW REVIEW\nIn order to refresh yourself of ArcView, you could take a look at the lab5 in 11.204 as a\nreview. But for those who haven't taken 11.204, 11.208 or 11.520, we require that you\ncomplete the lab5 of 11.204 and hand in the final layout you create.\nPART VII: WHAT TO TURN IN\nPlease note that the in-lab exercises for 11.521 are aimed at making sure that you\nunderstand the computing setup and the basic mechanics of the various mapping and\ndbms packages and query languages. In terms of grading, all the lab exercises add up to\nthe equivalent of one homework set and each exercise is recorded only as a 'check-plus',\n'check', and 'check-minus' so that they are primarily an indication of whether you did\nthem.\nYou should turn in the printout described in Part V above and (the map you created in\nPart VI if you'd haven't taken 11.204, 11.208 or 11.520). Make sure that your name, MIT\nemail address and the date are on the printout.\nNotes:\n1. For information about the usage of the cluster, pleaser reference the following\nlink\nhttp://web.mit.edu/windows/cluster/\n\n2. A short-cut of mapping the drives.\nIn order to simply the drive mapping process, we create a batch file which can\nautomatically map all the drives required in this class. When next time you log in\nwindows, simply double click on the file to get the lockers mapped instead of going\nthrough steps described in Part I. You will be asked for the password for four times."
    },
    {
      "category": "Resource",
      "title": "lab2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/f33900a3cd0962e55ba04cc751d60e3d_lab2.pdf",
      "content": "Lab 2: Intermediate Oracle and SQL\n(Same as Problem Set 1)\nDue: A day before lecture #6\nPURPOSE\nThis lab uses the 'parcels'* and 'urisa'* database tables stored in Oracle to help you think\nrelationally about data and improve your understanding of how SQL 'select' statements\nhandle 'group by', joins, self-joins, and missing values. You will also begin to create\nsome temporary tables.\nPART 1: SQL Plus Logon and Setup\nIn order to access the \"parcels\" and \"urisa\" database, you need to log on using one\nof two different Oracle accounts--the user names are 'parcels' and 'urisa'; and the\npasswords are the same - the one we gave you in the first lab. We use separate\naccounts for security reasons. Each account can access only a few small tables -\nthose needed for these exercises.\nFor your information, the SQL 'create' statements used to create the 'parcels'\ntables are shown in the 'PARCELS Database Schema'* link from the 'SQL Notes'*\nsection of the class Web pages. The SQL 'create' statements used for the 'urisa'\ntables are shown in the 'URISA Database Notes'* link.\nThis lab will require you to create temporary tables. Since all of you are using the\nsame userid, there's a chance that more than one of you tries to create tables with\nthe same name. To avoid such problems, we emailed a unique tablename prefix in\nthe form 'Tnn' to each of you. For more information, please consult the section\nentitled 'Creating unique temporary tables'* in the SQL help* notes.\nBeginning next week, you will connect to Oracle using your own individual\naccount with the same userid as your Athena-id. We'll give you an initial\ntemporary password. Your instructor will tell you your temporary password.\nPlease change this password when you first login using your Athena ID using the\nSQL command: 'password'. You will be prompted for your old password and then\nthe new password twice. We recommend that you use a different password from\nyour Athena or CRL passwords.\n* Kindly refer to the Labs section\n\nPART 2: Querying the 'Toy' Parcel Database (30 points)\nConstruct SQL statements for the following queries:\na. (2 points) Which parcels had square footage greater than 10,000 square\nfeet? List the PARCELID, PID, WPB, ZIP, LANDUSE, and SQFT\ncolumns, and sort by PARCELID in ascending order.\nb.\n(2 points) Which of these parcels in part a had land use code 'C'?\nc.\n(3 points) Which of these parcels in part a had land use code 'C' or\n'E'?\nd.\n(3 points) Repeat the answer from part c, but this time list the name of\nthe owner in the first column.\ne.\n(3 points) What is the total loss for each owner whose parcel(s)\nburned? List the owner and the total loss. Sort by the owner's names in\nascending order.\nf.\n(3 points) How many parcels do each owner own and what total\nsquare footage of land do they own? Include the owner name, the owner\nID number, the parcel count, and total square footage in your listing. Sort\nby the owner's names.\ng.\n(3 points) Modify your answer to part f above to exclude any parcels\nwith square footage less than 30,000 square feet.\nh.\n(3 points) Modify your answer to part g above to exclude any owners\nthat only own one qualifying parcel.\ni.\n(4 points) The following queries produce slightly different results.\nBriefly explain why the results make sense for each case. Explain the\ndifference or similarity between COUNT(*) and COUNT(tax).\n1.SELECT COUNT(*), COUNT(tax), MIN(tax), MAX(tax),\nAVG(landval)\nFROM tax;\n2.SELECT COUNT(*), COUNT(tax), MIN(tax), MAX(tax),\nAVG(landval)\nFROM tax\nWHERE tax IS NOT NULL;\nj.\n(4 points) What is the total value (land value plus building value) per\nsquare foot of each parcel? Sort by this statistic in descending order.\nInclude the parcel id, building value, land value, and the square footage in\nyour query. Make sure that you avoid potential \"divide by zero\" errors and\n\nthat you include only rows with valid values for the square footage,\nbuilding value, and land value. Your query should return 8 rows.\nHowever, the TAX table has 9 rows and the PARCELS table has 20 rows.\nHow do you account for having only 8 rows in the result?\nPART 3: Querying the URISA Proceedings Database (30 points)\na.\n(9 points) Which keywords were used at least 30times? Sort by the\ncount of appearances in descending order.\nb.\n(9 points) List the authors who wrote at least 4 papers. Sort by the\npaper count in descending order.\nc.\n(12 points) Find the paper number and title (first 40 characters) of all\npapers using both keyword 305 (LOCATIONAL/SPATIAL ANALYSIS)\nand 218 (LAND USE PLANNING). Sort by the titles. Be aware that you\nneed a self-join to avoid getting no rows in your result!\nPART 4: Additional Questions (40 points)\na.\n(12 points) We want to write a query that computes the total loss from\nfires for each owner (who had at least one parcel that was in a fire) where\nthat owner's total loss is greater than $100,000. As a first attempt, we\ncome up with this query:\nSELECT P.PARCELID, O.ONAME, SUM(F.ESTLOSS) TOTAL_LOSS\nFROM PARCELS P, OWNERS O, FIRES F\nWHERE P.ONUM = O.OWNERNUM\nGROUP BY O.ONAME\nHAVING SUM(F.ESTLOSS) > 1000000\nORDER BY O.ONAME;\nHowever, this query does not run. Write a corrected version of this query\nthat works and show its output. Explain what was broken and how you\nfixed it. Hint: More than one thing is wrong.\nb.\n(14 points) Which of the papers written in 1988 had three or more\nauthors? Show the paper number and author count, and sort by the author\ncount in descending order, then the paper number in descending order.\nc.\n(14 points) Among all these 1988 papers written by multiple authors,\nwhich ones use keywords containing the word 'GEOGRAPHIC' or\n'LAND' (but not 'NEW ENGLAND'). Do not use keyword numbers when\nwriting your query or queries. List the paper ID and author names for each\nsuch paper. Sort them by the paper ID, the author's last name, and the\nauthor's first name.\n\nPART 5: WHAT TO TURN IN\nInstead of a lab assignment, the answers to this lab constitute Problem Set 1. Turn\nin your answers (both the SQL statements and the result of the queries) to the Part\n2 (parcels), and Part 3 (URISA), and Part 4 (additional) queries. Save your\nanswers as a plain text file. You can use any text editors to cut and paste the\nrelevant questions and your answers from the lab exercise page and your Oracle\nwindow into your lab assignment output.\nTo make it easier for us to rerun your queries, please do not include line numbers\nin your SQL statements (SQL*Plus will print these by default). To avoid this,\nwrite your query in an editor first, then copy-and-paste the SQL statement into\nSQL*Plus. Then, copy-and-paste the answer in SQL*Plus into your editor buffer.\nAny answer that includes line numbers in the SQL statement will lose a point for\nthat question.\nWhile not required, we encourage you to format your SQL statements on multiple\nlines to improve their readability. Use the examples we provide as a guide.\nBe careful to sort your results as stated in the questions. You will lose some credit\nif the results are not sorted correctly.\nWe only need your answer in digital format. The problem set is due a day before\nlecture #6."
    },
    {
      "category": "Resource",
      "title": "lab3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/83e5f886fd7052e9014eea7cc976c364_lab3.pdf",
      "content": "Lab 3: More SQL --\nThe Zoning Variance Database & Categorization via\nLookup Tables\n(Same as Problem Set 2)\nThis Lab exercise #3 begins in lab with lecture #6 and due back before lecture\n#9.\nIntroduction\nThis lab has two main purposes: (1) to acquaint you with a Zoning Variance\nDatabase*recording the characteristics of some 1800 zoning variances filed during the\nmid 1980s building boom in Boston, and (2) to learn how SQL's 'group by' capabilities\ncan help you interpret and analyze large, shared 'read-only' datasets by creating local\nlookup tables in which you can accumulate local knowledge.\nThe zoning variance database* contains information collected by Clark Broida (MCP '87)\nabout all Boston zoning variance applications from early 1984 through mid 1987. Zoning\nvariances request permission for landuses that deviate from the established zoning and\nlanduse regulations. Much of the development and rehabilitation that occurred in Boston\nduring the 1980s required a zoning variance. Clark encoded these data while working as\nan MCP intern with the Boston Redevelopment Authority (BRA) in order to help\nunderstand typical zoning variance request patterns and to inform zoning changes. His\nMCP thesis (C. Broida, June, 1987) analyzed these data and the zoning review process. In\na few weeks, when we start linking GIS software to relational databases we will analyze\nand map these zoning variance data.\nWe will also use the zoning variance database to study a more sophisticated use of SQL's\n'group by' capabilities. By creating local 'lookup' tables, we can categorize and\nreinterpret large, shared, 'read-only' datasets without needing 'write' access to the detailed,\n'official' datasets.\nA set of class notes relevant to this exercise and related lectures and homework questions\nare available online. They are grouped under a 'ZONING Database' section of the SQL\nNotes* and include:\nZoning Variances*\nSchema of ZONING table (and listing of\nrelated lookup tables)\n* Kindly refer to the Labs section\n\n1980 Census data (by\nBoston NSA)*\nSchema of 1980 Boston Census data (and\nrelated lookup tables)\nSchema of Decision, Use,\nNSA, Neighbrhd Lookup\nTables*\nSchema of Lookup tables (second half of\nCensus data web page)\nSub-Neighborhood lookup\ntable*\nThe NSA and NEIGHBRHD tables\n(bottom of Zoning Variance web page)\nSQL examples using\nzoning variances*\nAnnotated SQL queries of ZONING table\nGrouping zoning\napplicants via 'lookup'\ntables*\nAnnotated SQL queries illustrating use of\nlookup tables to categorize ownership of\nproperties seeking zoning variances\nZoning Variance Database\nEvolution Chart*\nStages of evolution of the ZONING\nvariance database\nPART 1: SQL Queries Exploring the Zoning Variance database\nLogon to SQL Plus with your own account.\nReview the sample SQL zoning queries* in the class notes. Be sure that you understand\nthe encoding of zoning variance information -- especially existing and proposed landuse,\nthe handling of missing values, how particular code violations are encoded, and how the\nBoard recommendations and decisions are encoded. Review -- and rerun -- the sample\nqueries to get a feel for the data -- which types of code violations were typical, which\nones were approved, how did they spread across neighborhoods, etc.\nIn constructing your queries, pay attention to how you handle 'missing values'. When\ncomputing the fraction of variances approved, for example, be careful not to count\nvariances for which the outcome is not known. For all questions, show your SQL\nstatements and their resulting output.\nQuestion I-1 (10 points). A few of the sample queries use the AVG functions (and a\nlittle arithmetic) to compute the percentage of variances that met various conditions.\nWhich are the most common yard violations: front, side, rear yard or setback violations?\nWhat fraction of all zoning variances (with known sideyard conditions) involved sideyard\nviolations?\nQuestion I-2 (10 points): List the case number, sub-neighborhood, existzonin, estimated\ncost, board recommendation (brarecom), board decision, offstreet parking indicator\n(#101), floor-area-ratio indicator (far151), and sideyard indicator (syard191) for all\nvariances proposing to convert vacant land to housing in CHARLESTOWN (this is a\nneighborhood, not a sub-neighborhood). Use the column formatting commands to adjust\n* Kindly refer to the Labs section\n\ncolumn widths so the queries print on an 80-column page. Use the name\n'CHARLESTOWN' in your query, not the numeric code that corresponds to this\nneighborhood. Sort by the case numbers in ascending order.\nQuestion I-3 (10 points): Fix the following SQL query so that it counts the proposed\nuses of zoning variances where the existing use is vacant land (code 10).\nSELECT PRPSEDUSE, LANDUSE, COUNT(*)\nFROM ZONING Z, USE U\nWHERE Z.PRPSEDUSE = U.USE_CODE\nGROUP BY PRPSEDUSE, LANDUSE\nHAVING EXISTUSE = 10;\nQuestion I-4 (10 points): Write a query that returns the name of the neighborhood\n(neighbrhd) along with the count of cases that propose to change the land use from\nvacant land to commercial. Sort by the count of cases in descending order, then the\nneighborhood names in ascending order. Use the names of the land uses\n('COMMERCIAL', 'VACANT LAND') rather than numeric codes in your query.\nQuestion I-4extra: Optional (just for fun) (3 extra credit points): Repeat the query\nabove, only show all the neighborhoods, regardless of whether they had a qualifying case\nor not (i.e., the count should be zero for any neighborhoods that did not show up in the\nlast query). Note: This query involves multiple SQL queries or a complex SQL query\nusing techniques beyond what we have demonstrated in class; that's why it's an extra\ncredit question. Don't spend a lot of time on it -- just understand why it isn't so easy to get\nthe zero-case rows added to the table in one easy step.\nQuestion I-5 (15 points): Next, we want to compute the percentage of variances, by\nneighborhood, that proposed to convert vacant lantdto housing. This sounds easy, but\nisn't because it's hard to compute the numerator and denominator of this fraction in the\nsame query. It is less elegant but more easily understood to do this in three steps. First,\ngenerate a view for the denominator -- i.e., a table that counts (by zoning.neighbrhd) all\nzoning variances (with known existing/proposed use).\nNext, compute the numerator -- i.e., a table showing the counts (by neighborhood) of\nthose vacant-to-housing variances.\nNow combine these two temporary tables into a third table showing the total and filtered\ncounts (for each neighborhood) in side-by-side columns, along with their ratio (the\ndesired fraction, expressed as a percent).\nInclude in your lab assignment all three SQL statements and the final result showing the\ntotal and filtered counts (and percents). Sort your results by the neighborhoods by name.\nInclude both the name and number of the neighborhood in your results. (It is possible but\nhard to use SQL to generate such a table all in one step. We'll show you a way later on.\nThink about why this is the case.)\n\nQuestion I-5extra: Optional (just for fun) (2 extra credit points): Here's another\nquestion involving percentages. Compute by neighborhood (neighbrhd), the percent of\nvariances for which the existing land use is 'housing' and the proposed use is 'housing'.\nInclude the neighborhood name (via the lookup table) in your results, and sort them by\nthe neighborhood name.\nQuestion I-6 (15 points): Now let's look at the percentage of variances (with a known\noutcome) that were approved. For all variances with a known BRARECOM and known\nBOARDDECIS, determine the number of variances and the percentage approved for each\nneighborhood (neighbrhd). Consider 'approved' to mean codes 1 and 2 (i.e., approved as\nsubmitted or approved with provisions).\nQuestion I-6extra: Optional (just for fun) (2 extra credit points): Use the 1980\ncensus table (aggregated by neighborhood statistical area, nsa) to determine which of the\nNSAs are above average in income. Which sub-neighborhoods (the 64 NSAa) had above\naverage incomes? (Think about and explain how you developed the estimate of the\n'average' income that you choose to use here. This is not a trick question with a precise\nanswer. There are several plausible answers and you should think about which one you\nchoose.) Now determine the fraction of housing-to-housing variances (with a known\ndecision) that were approved for these two groups of sub-neighborhoods: (a) those with\nabove average income, and (b) those with below average income.\nPART 2: Using Lookup Tables to Update and Categorize Read-Only\nDatabases\nIn this part, you will be categorizing the zoning variances based on the type of land\nownership of the parcels. We began discussing good and bad ways of doing this in class,\nand we have extensive online notes about the concepts and queries needed for the\nsuggested strategy: \"Grouping Zoning Applicants via Lookup Tables\"*. Be sure you\nunderstand the concept behind using lookup tables and 'group by' queries to create and\nuse your customized categorizations of variance without ever needing to change anything\nin the 'official' zoning table. Please also note that the class reading that develops these\nideas further using, as a context, the problem of correcting 'spelling errors' in owner\nnames recorded in the official Boston parcel database: Ferreira, Joseph Jr., \"Information\nTechnologies that Change Relationships between Low-Income Communities and the\nPublic and Non-profit Agencies that Serve Them,\" Chapter 7 in MIT Press Book from\nSpring 1996 DUSP colloquium on High Technology and Low-Income Communities. In\naddition, the PowerPoint slides that were used to discuss this paper* are also available\nonline.\nQuestion II-1 (15 points): Using the lookup table technique, develop a new table that\ncategorizes property owners in the zoning database into groups called 'individual',\n'public', 'corporate', 'other', or 'unknown'. Provide an annotated list of all the SQL\n* Kindly refer to the Labs section\n\nstatements (including 'update' commands) that you use to generate this table. For\nexample, one such 'update' command from the notes is:\nUPDATE apptype\nSET newapp = 'BOSTON, PFD'\nWHERE applicant LIKE '%FACILIT%';\nDon't spend a lot of time building 'updates' to catch every last corporation or trust. Once\nyou've developed half a dozen update 'rules' (in addition to those in the notes), you should\nstop and focus your time on the rest of the questions below that use these results.\nQuestion II-2 (15 points): For each of your 5 ownership categories in III-5 above,\nprepare a summary table showing: the total number of variances with a known proposed\nuse, the total number of variances with 'housing' as the proposed use, and the percentage\nof variances that involved a proposed use of housing. Sort by the name of your\ncategories. Briefly indicate whether the results suggest a pattern that might be worth\nlooking into.\nQuestion II-2extra (2 extra credit points): If you have extra time, try using 'group by'\ncommands as illustrated in latter sections of the \"Grouping Zoning Applicants via\nLookup Tables\"* notes to produce frequency distributions of a few other zoning violations\n-- broken down by the ownership categories you create in above. See if you can find\ncategories of land ownership for which the rate of zoning variance approval is\nsignificantly different.\nWhat to Turnin\nWe only need your answers (including SQL statements) in digital format. The problem\nset is due before the start of lecture #9.\n* Kindly refer back to the Labs section"
    },
    {
      "category": "Resource",
      "title": "lab4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/0a06361b08c77bfc02412624435b5f77_lab4.pdf",
      "content": "Lab 4: Querying Oracle from a Client\nApplication\nObjectives\nSQL*Plus is not the only interface to Oracle. You can use widely available desktop office\nproductivity software (specifically, Microsoft Access and Microsoft Excel) to connect to\nthe Oracle database and run queries. These packages offer a graphical user interface for\ndatabase queries, which contrasts starkly with the text-based SQL*Plus interface we have\nused up to now. This lab will help familiarize you with using Access to query Oracle.\nAgenda\nYou will use Microsoft Access to:\n-\nConnect to the Oracle database\n-\nRun some familiar queries\n-\nSave query output as a dBase DBF file\n-\nSave query output to a delimited text file\n-\nUse the SQL view to alter a SQL statement directly.\nQuerying Oracle Using Microsoft Access\nBefore You Start: Oracle and ODBC Checkout\nUsing Microsoft Access\nLaunch Microsoft Access using the Start > Programs > Microsoft > Access menu item.\nIn the right-hand pane \"New\", choose to New Blank Database.\n\nIn the file dialog that follows, name your new database as \"username_lab4.mdb.\"\n\nYou should now see a database window like the one below:\nClick on the \"New\" button, then select \"Link Table\" as shown in the window below.\n\nIn the file dialog that appears next, in the \"Files of Type\" area, select \"ODBC\nDatabases()\".\n\nIn the \"Select Data Source\" window, click on the \"Machine Data Source\" tab, then pick\n\"CRL Oracle\" as the data source.\n\nWhen you click OK, you'll have to log on. Log onto your Oracle account (the username\nis not case sensitive).\nAfter a pause, you'll see a \"Link Tables\" window like the one below.\n\nThe list of tables here looks different from the output of \"SELECT * FROM CAT;\" in\nSQL*Plus. Notice that many tables owned by users are visible here. Here, all the non-\nsystem objects that are visible to your account are shown in \"fully qualified\" form,\nmeaning that tables are shown in the USER.TABLE format. Hence, an object such as the\nFIRES table in the parcels database shows up as PARCELS_DATA.FIRES. Scroll down\nthe list, then select the tables PARCELS_DATA.FIRES, PARCELS_DATA.OWNERS,\nand PARCELS_DATA.PARCELS. You can select more than one table by clicking on\neach one. Your window, with tables selected, should look like this:\n(Note: Sometimes when you link a table, you will be asked to select the \"Unique Record\nIdentifier\" (a.k.a. the primary key) for each table. You can select multiple fields (up to\n10) for the primary key. That does not happen with these tables because the primary keys\nwere defined in Oracle, and Access recognizes that.)\nNow your database window will look like this, showing your linked tables.\n\nNotice that Access prepended the name of the user who owned the table to its name. This\nis inconvenient for us, so let's rename the tables back to FIRES, OWNERS, and\nPARCELS. RIGHT-click on the table's name, select \"Rename\" from the context menu,\nand rename the tables. After you're done, your window should look like this:\nNow, let's build and run a query in Access:\n\nClick on the \"Queries\" tab, and then click on the \"New\" button to create a new query.\nChoose \"Design View\", and then click \"OK\".\n-\nThe \"Show Table\" dialog box lets you add one or more tables to a query by\nselecting the table and clicking the \"Add\" button. The window will stay open to\nlet you add more tables. Close the window with the \"Close\" button. Add the tables\nto the query in this order:\no FIRES\no PARCELS\no OWNERS\n\nAfter you close the \"Show Table\" dialog box, you will see the query window. It\nshould resemble the image below.\nNotice that the unique identifier columns you specified earlier are shown in bold.\nAlso notice the line connecting the PARCELID column in the FIRES and\nOWNERS tables. This line represents a join between these two tables, and Access\ndraws it automatically because it recognizes that the columns are both keys (or\npart of a key) and have the same name. However, since the relationship between\nPARCELS and OWNERS is not drawn, because the columns do not have the\nsame name.\n-\nLet's join PARCELS and OWNERS together. You will probably find it easier to\ndo this if you:\no Maximize the query window\no Move the PARCELS table in between OWNERS and FIRES (if it isn't\nalready)\no Resize the top pane of the window to provide more room for the table\ndescriptions\no Lengthen the size of the PARCELS table so you can see all its columns.\n\nNow, click and hold on a column name (e.g., OWNERNUM in OWNERS), then\ndrag until you are over the corresponding name in another table (e.g., ONUM in\nPARCELS) to describe a join between the columns. When you are done, your\nquery window should look like this:\n-\nNow we need to indicate which columns we want to show in the results. Double\nclick on the following columns to make them appear in the output:\no PARCELS.PARCELID\no PARCELS.SQFT\no OWNERS.ONAME\no FIRES.FDATE\n\no FIRES.ESTLOSS\n-\nin the toolbar. Your results should look like this:\nRun the query now by choosing Query > Run or clicking on the \"Run\" button\n\n-\nUse the View > SQL View menu item to see the SQL text of your query.\nHere is the query again, reformatted for readability:\nSELECT PARCELS.PARCELID, PARCELS.SQFT, OWNERS.ONAME,\nFIRES.FDATE, FIRES.ESTLOSS\nFROM (FIRES INNER JOIN PARCELS ON FIRES.PARCELID =\nPARCELS.PARCELID)\nINNER JOIN OWNERS ON PARCELS.ONUM =\nOWNERS.OWNERNUM;\nNotice that Access uses a different syntax than we have seen to specify joins.\nInstead of using the WHERE clause, it uses an \"INNER JOIN\" syntax in the\nFROM clause that explicitly names the columns being joined. Although this is\nunfamiliar (and incompatible with Oracle when using the SQL*Plus interface), in\nsome ways this method is better than Oracle's, since it makes it very clear what\ntable is joined to what, whether the join is an inner (i.e., \"normal\") or outer join,\nand what columns are needed to perform the join. Oracle's syntax buries this\ninformation in the WHERE clause where it can become obscured.\n\n-\nYou can edit the query in the SQL View window. Add the condition \"WHERE\nESTLOSS >= 40000\" to the SQL statement (remember to place this clause before\nthe semicolon). Now switch back to design view with View > Design View.\nNotice that your new condition has been added to the criteria in the graphical\ninterface (look under ESTLOSS in the lower pane of the window).\n-\nNow, let's see the results. Click on the \"Run\" button\nto run your query. After\nresizing the ONAME column and the window, the results should look like the\nimage below.\n\n-\nNow, let's change the query to eliminate Gerald Rappaport from the results. Use\nView > Design View to return to the query designer. Beneath the ONAME field\nin the lower pane of the window, add the following criterion:\n<>'GERALD RAPPAPORT'\nYou may want to make the ONAME column wider so you can see all the text.\n\n-\nRun your query again. See how the results changed? Also use the View > SQL\nView menu item to see how the underlying SQL statement changed.\n-\nOften, it is convenient to be able to save the results of a query to an external file.\nFirst, save your query by closing it. When Access prompts you to save changes,\naccept, and keep the default name \"Query1\". You'll return to the Database\nwindow with the \"Queries\" tab selected. Make sure \"Query1\" is highlighted.\nNow, use the File > Save As/Export menu item to open the save dialog box.\nChoose the option \"To an External File or Database\", then use the \"dBase IV\n(*.dbf)\" file type, and save your output to the file lab4.dbf.\n-\nNow, save the output again, this time as a text file. Follow the instructions for\nsaving as a DBF file above, except this time, choose the file type \"Text Files\n(*.txt; *.csv; *.tab; *.asc)\". This time, the Export Text Wizard will appear. In the\nsuccessive screens, make the following choices:\no Delimited format\no Comma delimiter\n\no Include field names on first row\no Text qualifier \" (a double quotation mark, the default)\no Filename \"query1.txt\".\nOpen this file in a text editor such as Windows Notepad or the Programmer's File\nEditor and see if it contains what you expected.\n-\nNow, have a look at the DBF table you just saved. Click on the \"Tables\" tab, and\nthen click on the \"New\" button. In the \"New Table\" dialog box, choose the \"Link\nTable\" option. In the \"Link\" dialog box, choose Files of Type \"dBASE IV\n(*.dbf)\", and then pick the LAB4.DBF file you just created. When the \"Select\nIndex Files\" dialog box appears, click the \"Cancel\" button. You should now have\na table in your window named \"LAB4.\" Double-click on its entry to view its\ncontents. Saving files in dBase format is often useful since so many programs can\nread this format. Notably, ArcView understands the dBase format, so this is a\nuseful way to move data into ArcView.\n-\nNow, try your hand at another query. Modify the query you have prepared so far\nso that it shows the fires:\no Only for properties owned by \"MGH, INC.\" or \"GERALD RAPPAPORT\"\no and the square footage is greater than 20000.\nNotes:\no To specify equality, just place the value in the criteria box (e.g., for\n\"SQFT = 30000\", just enter \"30000\" in the criteria box under SQFT).\no To specify an \"OR\" condition, you need to put the criteria below each\nother in the \"or\" rows below the first criteria rows.\no To specify an \"AND\" condition for a single column, place both criteria in\nthe same box separated by the keyword \"AND\" (e.g., \"> 60000 AND <\n200000\").\nWhat to Turn In\nTurn in the SQL statement and the output from the final query you performed above in a\ntext file. The query output should be saved in a file called yourusername_lab4.txt using\nthe same delimited format you used above. You need to copy-and-paste the SQL into a\ntext editor such as Windows Notepad or Programmer's File Editor (a.k.a. PFE) before\nyou can save it to a text file; call this file yourusername_lab4.sql.\nWe only need your answers (including SQL statements) in digital format. The assignment\nis due a day before lecture #9."
    },
    {
      "category": "Resource",
      "title": "lab5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/2c388abd837029637e4d36b860a1bf7d_lab5.pdf",
      "content": "Lab 5: Mapping Boston Zoning Variances\nPurpose:\nArcView allows access to Oracle tables on our database server. In this exercise, we'll\nlearn how to access Oracle tables from ArcView and use this capability to create a 'pin-\nmap' showing the location of zoning variances on the Boston maps that we used earlier in\nthe semester.\nNeeded Info:\n-\nClark Broida's database of Boston Zoning variances (stored in the ZONING* table\non the Oracle server)\n-\nAssorted Boston maps described in the web page of CRL-supported datasets.\n(1) Preparing the ZONING data\nIn class, we explained how the table lonlat4 contained 'geocoding' information about the\nlocation of each zoning variance --namely, the longitude and latitude of the\ncorresponding parcel. However, the longitude values needed to be multiplied by -1 to\nrepresent values in the Western Hemisphere. We used the following Oracle query to\ncreate a 'view' that made this change:\nCREATE VIEW lonlat5 AS\nSELECT casenumber, -1 * longitude longitude, latitude,\nstreetname, quality\nFROM lonlat4;\nUse SQL*Plus to connect to Oracle and create your own view, lonlat5, to convert the\nlongitudes.\n(2) Connecting ArcView to Oracle\nThe SQL connection from ArcView to Oracle can be made from the SQL Connect\noption of the Project menu. The SQL dialogue window that pops up allows you to run a\nsingle SQL command that extracts a table from Oracle and makes it available as an\nordinary ArcView table (that can be linked or joined with other ArcView tables). (Note\nthat, however small or large the resulting SQL table, ArcView will bring over the entire\ntable right away. Don't use this method to access directly the entire parcel database for\nBoston!)\nOpen ArcView and use this method to grab a copy of the lonlat5view that you just\ncreated. Name the table 'lonlat5' in the SQL dialogue window so that you remember from\nwhence it came.\n* Kindly refer to the Labs section\n\n(3) Mapping the Zoning Variances\nTo map the zoning variances, you'll need to convert the latitude/longitude values in the\nlonlat5 table into 'points' on your map. Since all the Boston area maps we've been using\nare in Massachusetts State Plane coordinates (not latitude/longitude), we'll have to worry\nabout map projections.\n(a) Open a View window and use the View > Add Event Theme menu item to convert\nthe latitude/longitude values in your lonlat5 table into 'pin-map' points on your ArcView\nmap. Enough zoning variances have been georeferenced for the general envelope of\nBoston to be visible around all the dots. HOWEVER, the coordinates are expressed in\nlat/lon -- not the state plane coordinates we have used when drawing maps of Boston and\nvicinity last month. If you were to add, say, the Massachusetts town boundary map in\n/mit/massgis/2000/state/towns (polygon) to your view, the lonlat locations of the zoning\nvariances won't line up with the town boundaries (which are in Massachusetts State Plane\nCoordinates, Mainland Zone, NAD83, meters). On PCs this locker is available as\n\\\\crypt\\massgis\\2000\\state\\towns. On CRL machines, this locker is mapped as drive M:.\n(b) Open a second View window and add the Massachusetts town boundaries as a theme\nin this view. Once we've projected the latitude/longitude of the zoning variances, we will\nbe able to add them to this view.\n(c) Now, let's project the variances from latitude/longitude to state plane coordinates.\nHighlight the first View window (showing only the zoning variances from lonlat5\nmapped in latitude/longitude 'geographic' coordinates). Choose View > Properties from\nthe menus and set the Map Units to 'decimal degrees' (to indicate that the coordinates\nread in from disk are geographic coordinates expressing latitude/longitude location in\ndecimal degrees). Next, click the 'Projection...' button and set the coordinate system to be\nused by this View window to be 'State Plane - 1983' with type set to 'Massachusetts,\nMainland'. Note that, when you click OK and return to the View Properties dialogue box,\nthe map units have been reset to meters (in accordance with the projected state plane\nparameters for the projected view you are about to see). You may set the distance units to\nthe units of your choice. When you click 'OK' the zoning variances will now be displayed\nin Massachusetts state plane coordinates -- but they still are saved on disk in\nlatitude/longitude. Highlight the projected zoning variance theme in your View window\nand choose Theme > Convert to Shapefile from the menus to save the projected zoning\nvariances in the projected units -- i.e., Massachusetts state plane coordinates. As usual, be\ncareful to select (and remember) an appropriate directory in which to store the projected\nshapefile. Once you've save the projected zoning variances to disk, you can add them to\nthe other View (with the Massachusetts town boundaries).\nAlternate strategy for projecting zoning variances\nTo project the zoning variance latitude/longitude values to Massachusetts State Plane,\nyou can follow a slightly different procedure from the one we used in class. This method\nuses the Projector! extension. This procedure, when it works, is a bit more streamlined\n\nthan that outlined above. However, in some cases, obscure permission problems have\nprevented students from using the Projector! button to do the coordinate transformation.\nDepending on what ArcView operations you have done, ArcView may refuse to save the\nprojected coverage because it does not have write permission for the MassGIS towns\nshapefile. In such cases you can use the original method demonstrated in class instead of\nthe Projector! extension.\nHighlight the first View window (with the mapped zoning variances from lonlat5).\nChoose the File > Extensions menu option and load the 'Projector!' option. Notice the\nnew 'projection' button at the far right of the toolbar. Click it to see if we can figure out\nhow to convert the zoning variances. When you do this ArcView will complain if you\nhaven't set any map units yet -- we need to tell ArcView that the coordinates of our\nmapped zoning variances are expressed in decimal degrees. Use the View > Properties\ndialogue box to set the map units to decimal degrees. Now click the projection button\nonce again, accept the default choice of 'meters' for displaying the projected results, and\nthen (in the next popup window) set the projection to be 'State Plane - 1983' so that it\nuses the 1983 North American Datum. The 'type' will reset automatically to\nMassachusetts Mainland (a fine choice...). Click 'OK' to accept the projection and then\n'Yes' again when asked whether to recompute lengths/areas in meters. Now, click 'Yes'\nand 'OK' when asked whether to add the resulting shapefile as a theme in one of your\nView windows. Add the projected zoning variances to your second View (with the\nMassachusetts town boundaries) and, when prompted, specify a path and filename in\nwhich to save the projected theme as a shapefile (and then load it into your View\nwindow).\nNow you have 'pin map' of the projected zoning variances showing up within the town\nboundaries of Boston where they belong. (Compared with the projection method used in\nclass, this way is a little more direct in projecting, saving, and adding the zoning\nvariances to the Massachusetts Town view.)\n(4) Analyzing Spatial Patterns of the Zoning Variances\nLet's examine and map various subsets of the zoning variance cases -- for example, all\napproved variances. We're not quite ready to do this since the lonlat5 table has none of\nthe zoning variance characteristics -- we'll have to join it to the ZONING table* using\n'casenumber'. We can do this in Oracle or we can move the entire zoning table into\nArcView and do all the queries (and joins) there. Since the ZONING table isn't that big,\nbringing the whole table into ArcView is manageable. However, for other situations --\nsuch as the landuse owner categorization exercise that we did earlier, we might want to\nrun the queries in Oracle, store the results in a SQL 'view' and pull the view over to\nArcView.\n(d) Now let's add a few other coverages to give more meaning to the zoning variance\nmap. Add the msa5_tr90 and bostnbrd coverages (showing Eastern Mass 1990 census\n* Kindly refer to the Labs section\n\ntracts and Boston neighborhood boundaries). The data are located in a CRL locker,\ncrlmaps. On CRL machines, this locker is normally attached as drive N: using the name\n\\\\crypt\\crlmaps and the data are in N:\\meters83\\massmaps\\boston. On CRL machines\nyou can also enter the environment variable $BOSTON_METRO into the 'add theme'\ndialogue box. These environment variables are described on the CRL metadata help page\nhttp://gis.mit.edu/metadata and retain the same names even if the data are moved to\nanother CRL locker.) Finally, if you want to get more exotic, add the MIT OrthoServer\nextension so that you can slip orthophoto imagery under your maps as demonstrated in\nclass.\n(e) After joining the zoning data to your projected-and-mapped lonlat5 data, generate a\npin-map showing the location of all variances (that were geo-referenced) which proposed\nto convert vacant land to housing. Your map should be zoomed in to just fit Boston\nonscreen and should show city boundaries and census tracts as well as the zoning\nvariance locations.\n(f) Now change the symbols used to draw the Part (e) variances (involving vacant land\nconverted to housing) so that a different symbol is used for those which were\nAPPROVED (code 1 or 2). You will also want to exclude the missing value cases so the\nthan one way to do this. For exam\ntwo symbols apply only to approved/not-approved variances. Once again, there is more\nple, you can use the 'hammer' query tool\nassociated\nwith the theme properties of your zoning variance theme. Select only those variances that\nare vacant-to-housing and have a known Board decision. Then set the symbols to be\ndisplayed based on the Board decision. Alternatively, you could write an Oracle query\nthat creates a view with a WHERE clause limiting the variances -- and then pull the\nresulting table over to ArcView. The former option is easier here. But, if you wanted to,\nsay, tag the zoning variances with some of their 1980 census characteristics* (which are\nstored, by sub-neighborhood, in the Oracle table called CENSUS), then it would be easier\nto generate the desired table in Oracle before pulling it across.\n(g) Next let's examine whether the approval rate of vacant-land-to-housing variances\nappears to be different across parts of Boston that have high/medium/low housing value -\n- as measured by the 1990 census data. Selected 1990 Census tract data are stored in an\nINFO table called msa5_tr90.dat stored together with the msa5_tr90 census tract\ncoverage mentioned earlier. The data table is stored in an INFO database (this is the 'info'\npart of the software called ArcInfo.) Add this table to your ArcView project -- just\nremember to set the table type to 'INFO' and to look in the sub-directory called 'info' in\nthe $BOSTON_METRO directory (N:\\meters83\\massmaps\\boston). You will have to\njoin (or link) this data table to the msa5_tr90 theme in order to map the census data. The\ncolumn names in the msa5_tr90.dat table are the official Census Bureau names. As\nexplained in Tom Grayson's Census notes in lecture 3 of course 11.208, the technical\ndocumentation for STF3 census data contains the data dictionary for these variables. But\nwe'll save you some time: the H061A001 variable contains the median value of owner-\noccupied housing units. Use this variable to generate a thematic map of the housing\n* Kindly refer to the Labs section\n\nvalues across the Boston census tracts. Now zoom in a bit on a part of town of particular\ninterest to you and fiddle with the map so that the Part (f) variances (with approved/not-\napproved symbols) are readable on top of your thematic map.\n(h) Finally, let's ask some questions about the zoning variances that fall within\nhigh/medium/low value tracts. How many vacant-to-housing variances are in above-\naverage value tracts (1990)? What fractions are approved? From the map, we can see\nwhich variances fall within the high/medium/low value tracts. But we can't easily\ncompute the counts and fraction-approved because the zoning variances aren't 'tagged'\nwith the number of the census tract that contains them. Here's an opportunity to use some\nof the spatial data processing capabilities of our GIS. We can do a spatial join -- in this\ncase a so-called 'point-in-polygon' operation -- to find out which zoning variances\n(points) are contained within which census tracts (polygons). There are several ways to\ndo this. (You may also want to refer to one of last Fall's 11.520 lab exercises for more\ninformation). We'll use the method that involves a 'spatial' join of the lonlat5 attribute\ntable to the msa5_tr90 attribute table.\nOpen up the attribute table for msa5_tr90 shapefile and click on the column heading\nmarked 'Shape'. Next, open the attribute table for your lonlat5 theme and click on its\n'Shape' column. Now select the menu item Table > Join. The attributes for msa5_tr90\nwill disappear. If you examine the attribute table for lonlat5, however, you should now\nsee all the census tract columns appended to the lonlat5 table. You've done an (outer)\njoin of the census tract table to the lonlat5 table using the spatial location of the zoning\nvariances to relate each variance to the census tract that contains it. All the zoning\nvariances within a census tract have the same (duplicated) census data brought over from\nmsa5_tr90. The 'Shape' columns aren't true attributes; they serve as placeholders that\nremind us that each row of the attribute table is tagged with a hidden spatial object ID\nthat associates it with the vector geometry of that object's boundary. That geometry is\nused to carry out the 'spatial join'.\nWe still have a ways to go to answer the part (h) questions because the original\nmsa5_tr90 attribute table had only the census tract identifiers -- and not the census\nvariable that are in the msa5_tr90.dattable and have to be joined in. Once you have\njoined in the data table, use ArcView's query tools (and Field > Statistics options) to\ncompute the desired numbers: the number of vacant-to-housing variances in above-\naverage income (1990) tracts and the fraction of them that were approved. In addition to\ncomputing these two numbers, turn in a printout of a table showing the casenumber,\nboard decision, 1980 nsa number, and 1990 census tract number for all vacant-to-housing\nvariances that are within ROSLINDALE (i.e., NSA subnghbrd 49, 50 and 51).\nIf we could easily put ArcView tables back into Oracle, it might be easier to do these last\nfew steps in Oracle. But ArcView can't easily update Oracle tables. Hence, we are stuck\nwith the one-way path for moving portions of Oracle tables into ArcView before we do\nany spatial processing. There are tools around that facilitate moving tables from ArcView\ninto Oracle, but we won't use them until the project portion of the course.\n\nLab Assignment\nThe only parts of this exercise that you need turn in are:\n(a) The two numbers (variance count and fraction approved) and the Roslindale table\nfrom Part (h), and\n(b) A printed layout showing your two maps of Boston from Parts (f) and (g) with the\nlocation of the vacant-to-housing variances highlighted in various ways.\nTurn in the printout in before lecture #12.\nOPTIONAL Question 1 (just for fun...)\nFor simple queries, it's easier to use ArcView's SQL tools to run the queries using the\nSQL connection -- or even to query *.dbf versions of the ZONING database* and lookup\ntables (rather than do the queries in Oracle and bring them over with the browser and\naddins). But, suppose you wanted to use the institutional categories of ownership that you\ndeveloped in the last homework set. It took a while to develop these as you accumulated\nthe SELECT and UPDATE SQL statements that built the cross-reference table. Hence,\nyou'd like to leave all this on a network database server that could protect private data\nwhile letting you reach it quickly from any Athena or PC 'client' when you had a chance\nto work on it and map the results.\nFor all those variances whose board decision is known, what is the approval rate (code 1\nor 2) broken down by your institutional categories? What fractions are in high income\nneighborhoods and tracts (as defined earlier) by each institutional category? What about\nfor the vacant-to-housing subset? Map the locations of the variances in the various\ninstitutional categories. Do you see any patterns worth pursuing? Are they closer to major\nroads, downtown, more/less dense residential neighborhoods,...? Perhaps you are\ncomparing apples and oranges -- the institutionally owned property might not be\ncomparable to the one-, two-, and triple-deckers owned by individuals. Use the\n'existzonin' variable to zero in on those variances on property that is zoned for single\nthrough 3-family structures and then redo some of these comparisons.\nOPTIONAL Question 2 (just for more fun...)\nNow let's do an exercise similar to Part (f) above that uses additional 1990 census data--\nviz. census data that aren't already included in the data tables for the ArcInfo census tract\nlayer. We'll mount Massachusetts STF3A data online at CRL and pull off the needed\nSTF3A data. In this case, let's find census data indicating the extent of auto ownership in\n* Kindly refer to the Labs section\n\neach Boston census tract and compare the incidence and approval rates of vacant-to-\nhousing zoning variances within 1990 census tracts that are above/below average in your\nmeasure of auto ownership. As explained in the 11.208 Census notes, the technical\ndocumentation for STF3 census data has several variables related to vehicle usage. For\nexample:\nH38. AGGREGATE VEHICLES AVAILABLE(1) BY TENURE(2)\nUniverse: Occupied housing units\nTotal:\nOwner occupied\nRenter occupied\nUse these variables (with appropriate normalization) to construct some measure of auto\nownership that allows you to group Boston census tracts into above/below 'average'\ncategories. Think about your reasoning and the specific census variables and formulae\nthat you used to compute your measure. Generate a map (just as you did earlier) showing\nthe location of all variances (that were geo-referenced) which proposed to convert vacant\nland to housing. Use color (or grayscale) again to distinguish approved/dis-approved\nvariances but this time use thematic shading of the census tract map to indicate parts of\ntown where auto ownership is high/medium/low."
    },
    {
      "category": "Resource",
      "title": "lab6.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/dc20424c16528d8bc481906730c2bbf3_lab6.pdf",
      "content": "Lab 6: Raster Modeling with ArcView's\nSpatial Analyst\nOverview\nThe purpose of this lab exercise is to introduce spatial analysis methods using raster\nmodels of geospatial phenomena. Thus far this semester we have represented spatial\nphenomena as discrete features modeled in the GIS as points, lines, or polygons--i.e., so-\ncalled 'vector' models of geospatial features. Sometimes it is useful to think of spatial\nphenomena as 'fields' such as temperature, wind velocity, or elevation. The spatial\nvariation of these 'fields' can be modeled in various varous ways including contour lines\nand raster grid cells. In this lab exercise, we shall focus on raster models and examine\nArcView's 'Spatial Analyst' extension. We shall use raster models to create a housing\nvalue 'surface' for a portion of Boston. To create the 'surface' we will explore ArcView's\ntools for converting vector data sets into raster data sets--in particular, we will 'rasterize'\nthe 1986-1995 housing sales data for Boston and the 1990 Census data for Boston\nblock groups. (For those of you who took 11.520 in the Fall, this lab is very similar to\nwhat we did to interpolate housing values for Cambridge. The main difference is that, this\ntime, the sales data are in Oracle and they involve multiple-sale and other complications\nthat require data manipulation before being pulled into ArcView.)\nA housing value 'surface' for Boston would show the high and low value neighborhoods\nmuch like an elevation map shows height. The computation needed to do such\ninterpolations involve lots of proximity-dependent calculations that are much easier using\na so-called 'raster' data model instead of the vector model that we have been using. Thus\nfar, we have represented spatial features--such as Boston block group polygons--by the\nsequence of boundary points that need to be connected to enclose the border of each\nspatial object--for example, the contiguous collection of city blocks that make up each\nCensus block group. A raster model would overlay a grid (of fixed cell size) over all of\nBoston and then assign a numeric value (such as the block group median housing value\nor the block group ID) to each grid cell depending upon, say, which block group\ncontained the center of the grid cell. Depending upon the grid cell size that is chosen,\nsuch a raster model can be convenient but coarse-grained with jagged boundaries, or fine-\ngrained but overwhelming in the number of cells that must be encoded.\nIn this exercise, we only have time for a few of the many types of spatial analyses that are\npossible using rasterized datasets. Remember that our immediate goal is to use the Boston\nsales data to generate a housing-value 'surface' for Boston. We'll do this by\n'rasterizing' the sales data and then taking advantage of the regular grid structure in the\nraster model so that we can easily do the computations that let us smooth out and\ninterpolate the housing values reported in the housing sales datasets.\n\n(1) Spatial Analyst Setup\nStart with a brand new ArcView project, create a new view, and add several Boston\nthemes (stored in the /mit/crlmaps/meters83/massmaps/boston directory) as indicated\nbelow. If you have a CRLspace directory, you should also set your working directory to\nbe a subdirectory of your CRL space. Hence, you should:\n-\nActivate the Project window\n-\nSelect 'Properties' from the Project menu\n-\nSet the working directory to /mit/crlspace1/YourAthenaID/lab6\n(Note: you may need to 'attach' the locker and/or create the sub-directory first.)\n-\nActivate a View window or open a new one\n-\nAdd the following themes to the view (all from the\n/mit/crlmaps/meters83/massmaps/boston directory which, on the PC is also\nknow as: \\\\crypt\\crlmaps\\meters83\\massmaps\\boston). Note that some of these\nare shapefiles and some are ArcInfo 'coverages' where you can click the coverage\nicon in the dialogue box to get the expanded list of coverage types to be sure that\nyou load the 'polygon' layer.\no bostnbrd (polygon)\no msa_town (polygon)\no msa_water.shp\no wardbound (polygon)\n-\nAlso add a polygon and a point theme for Boston's Ward 12 parcels and Boston's\n1990 Census block-groups:\no /mit/crlclass/11.521/data/boston_bg (polygon)\no /mit/crlclass/11.521/data/ward12bnd.shp\n-\nOrder the themes, top to bottom, as follows:\no Ward12bnd.shp\no Msa_water.shp\no Wardbound\no Bostnbrd\no Boston_bg\no Msa_town\nHighlight the Wardbound theme and press the 'Zoom to Active Theme(s)' button\nso\nthat the map shows all of Boston. Adjust the colors and transparency of their symbols so\nthat the ocean is blue with no border, the town boundaries around Boston are visible and\nyou can see Boston's Ward 12 as the area from Franklin part up through Lower Roxbury\nto Dudley Square. Create a thematic map of median housing value by shading the\nBoston_bg theme based on the 1990 medhhval values. (See the data dictionary for this\n\nlayer on the MassGIS site for the meaning of all the variables in the Boston_bg attribute\ntable--but you will only need medhhval). Be sure to exclude block groups with\nmedhhval = 0 by setting '0' to be the null value. At this point, your ArcView window\nshould look something like this:\nSetting 'Spatial Analyst' Properties\nArcView's raster manipulation tools are bundled with its Spatial Analyst extension. It's a\nbig bundle so lets open Arcview's help system first to find out more about the tools.\nFollow this sequence of clicks to find the relevant spatial analyst topics: Help Topics >\nContents > Extensions > Spatial Analyst. During the exercise, you'll find these online\nhelp pages helpful in clarifying the choices and reasoning behind a number of the steps\nthat we will explore. Be sure, at some point, to take a look at the overview and\nperforming analysis sections.\nThe Spatial Analyst module is an extension, so it must be loaded into ArcView\nseparately. (Note: this is because raster modeling capabilities do not come standard with\nArcView. The Spatial Analyst extension must be purchased separately, and actually costs\nmore than ArcView alone.)\n-\nSelect 'Extensions' from the 'File' menu\n-\nCheckmark 'Spatial Analyst' and OK the selection (Note: if you only highlight\n'Spatial Analyst' without checking the box, then clicking 'OK' will not load the\nextension.)\n\nOnce the Spatial Analyst extension is loaded, a new main-menu heading called Analysis\nwill be available whenever a View window is active. Make sure that you go to View >\nProperties and set the map units to meters and the distance units to miles. If the map\nunits are not set, Spatial Analyst will not know what units to use when performing an\nanalysis.\nBefore building and using raster datasets, we should set the grid cell sizes and the spatial\nextent of our grid, and we need to identify the 'no data' regions outside of Ward 12 that\nwe wish to 'mask' off. Let's begin by specifying a grid cell size of 100 meters and an\nanalysis extent covering all of Boston's Ward 12. To do this, select 'Properties' from the\n'Analysis' menu and specify:\nItem\nAnalysis Extent\nSame As Ward12bnd.shp\nAnalysis Cell Size\nAs Specified Below\nAnalysis Cell Size\nNumber of Rows\nNumber of Columns 25\nAnalysis Mask\nNo Mask Set\nValue\nNote: Hitting 'Enter' (or 'Return') after typing 100 for the cell size will cause the\nrow/column numbers to be recomputed. When all the values are properly set, click 'OK'.\nNow we are ready to build a 100 meter raster grid model for Ward 12. With your View\nwindow open, convert the Ward12bnd.shp to a grid theme using these steps and\nparameter settings:\n-\nHighlight the Ward12bnd.shp theme and select 'Convert to Grid' from the\nTheme menu\n-\nSpecify the subdirectory and grid file name. Use the name: boswd12gd (this is the\nname for the saved grid files and you should put them in your working directory\nthat you setup earlier.)\n-\nIf you had not already set the Analysis Properties, you would have been prompted\nat this point to set them (as we did above) to:\nItem\nValue\nOutput Grid Extent\nSame As Ward12bnd.shp\nOutput Grid Cell Size 100\n\nNumber of Rows\nNumber of Columns\n-\nA series of dialog boxes will now come up. Respond as follows:\no Pick 'conversion field' to set the cell values\nUse Wd12bnd_id (we want a single value for the entire ward at this point\nsince we want to tag all the cells in Ward 12 for inclusion in the study)\no Join feature attributes to grid?\nNo (we don't want to pull over any more data at this point)\no Add grid as theme to the View?\nYes, do add Boswd12gd to the view\nIf successful, the Boswd12gd theme will be added to the View legend. Turn it on and\nnotice that the shading covers all the grid cells whose center point falls inside of the\nspatial extent of the Ward12bnd theme. The cell value associated with the grid cells is\n12 (if you picked wd12bnd_id for the cell values).\nAt this point we don't need the old Ward12bnd.shp theme coverage any longer. We used\nit to set the spatial extent for our grid work, but that setting is now retained. To reduce\nclutter in your View window, you can delete the Ward12bnd.shp theme from the View\nlegend. (Later, you can also use File > Manage Data Sources to permanently erase some\nof the temporary shapefiles and grid themes that you create during this exercise.)\n(2) Interpolating Housing Values Using SALES Data\nThis part of the lab will demonstrate some techniques for filling in missing values in your\ndata using interpolation methods. In this case, we will explore different ways to estimate\nhousing values for Boston's Ward 12. Keep in mind that there is no perfect way to\ndetermine the value of a property.\nA city assessor's database of all properties in the city would generally be considered a\ngood estimate of housing values because the data set is complete and maintained by an\nagency which has strong motivation to keep it accurate. This database does have\ndrawbacks, though. It is updated sporadically, people lobby for the lowest assessment\npossible for their property, and it's values often lag behind market values by many years.\nRecent sales are another way to get at the question. On the one hand, their numbers are\nbelievable because the price results out of an informed negotiation between a buyer and a\nseller that results in the true of the property being revealed (if you are a believer in the\neconomic market-clearing model). However, the accuracy of such data sets are\nsusceptible to short-lived boom or bust trends and, since individual houses (and lots)\nmight be bigger or smaller than those typical of their neighborhood, individual sale prices\nmay or may not be representative of housing prices in their neighborhood.\n\n---------- ---------- --------- ---------- ---------- -------------------- --------------------\n-- ------- -\nAlternatively, the census presents us with yet another estimate of housing value--the\nmedian housing values aggregated to the block group level. However, this data set is also\nvulnerable to criticism from many angles. The numbers are self-reported, only a sample\nof the population is asked to report, and the data are aggregated up to the block group\nlevel. The benefit of census data is that they are cheaply available and they cover the\nentire country.\n(2.1) Pulling Ward 12 Data from the ASSESS_DATA.SALES Table\nTo begin exploring some of these ideas, we will use an Oracle table called SALES\ncontaining information about the sale price of residential Boston parcels that sold\nbetween 1986 and 1995. This table is owned by the user ASSESS_DATA. You need to\nspecify the fully-qualified table name, ASSESS_DATA.SALES, when querying from this\ntable, because you do not own this table and you already have a synonym called SALES\nthat refers to the table PARCELS_DATA.SALES. From your Oracle window, take a look\nat the ASSESS_DATA.SALES table:\nset pause '-- Press [Return] to continue--'\nset pause on\nset pagesize 24\nset linesize 120\nselect * from assess_data.sales;\nSALE_ID PARCEL_ID SALEDATE STATECLASS\nPRICE SELLER\nBUYER\nSA BASE_ID C\n1 0100003000 01-JUL-87\nW1 0100003 N\n2 0100003000 17-FEB-89\nD3 0100003 N\n3 0100004000 09-JUN-86\nW1 0100004 N\n4 0100004000 25-OCT-90\nD3 0100004 N\n5 0100005000 01-MAR-90\nA1 0100005 N\n6 0100012000 03-OCT-90\nD3 0100012 N\n7 0100013000 28-MAR-88\nW1 0100013 N\n8 0100014000 15-JUL-94\nW1 0100014 N\n9 0100019000 01-NOV-89\nD3 0100019 N\n10 0100022000 30-AUG-91\nW2 0100022 N\n11 0100024000 20-NOV-87\nA1 0100024 N\n12 0100028000 12-DEC-88\nD2 0100028 N\n13 0100029000 01-OCT-91\nD3 0100029 N\n14 0100039000 13-APR-94\nA1 0100039 N\n15 0100043000 09-APR-90\nX1 0100043 N\n16 0100043000 14-FEB-94\nE1 0100043 N4\n17 0100043000 23-NOV-94\nL1 0100043 N\n135000 DALY PAUL ET AL\n85000 PIAZZA DAVID M\n125000 CAPONE ROBERT ET AL\n115000 EMERSON JEFFREY F\n90000 DIGIROLAMO JOSPH G\n115000 STRAW BRUCE E JR ET\n150000 CARCO MARIE\n114000 TRIPI GIACOMO\n125500 TRICOMI JOSEPHINE\nPIAZZA DAVID\nONE HUNDRED REALTY T\nEMERSON JEFFREY\nDILLON KELLEY A\nDIGIROLAMO JOHN F ET\nSCIACCA ANTONIO ET A\nMELIA GERARD ET AL\nTRIPPE VIRGINIA\nBROWN STEPHEN P\n117000 NIGRO ANTONIO J ET A CAHILL STEPHEN F ET\n60000 IANNACCONE MARY\nSHEA RAFFAELA\n95000 FRANCIS MARK S ET AL MELE ANTHONY\n80000 BONO ANTHONY ET AL\nSTEWART ROBERT ET AL\n47800 DAPOLITO ANTHONY M E DAMATO FILIPPO\n165000 DAVOLIO MICHAEL ET A SCIORTINO SALVATORE\n85000 SCIORTINO SALVATORE MASSACHUSETTS HOUSIN\n49500 MASSACHUSETTS HOUSIN MORAN DESERRAE J\n\n---------- ------------------------ ----------------------\n18 0100046000 28-FEB-90\n47500 MATTHEWS ALICE\nBICKFORD WILLIAM J E\nD3 0100046 N\n19 0100048000 30-OCT-86\n159000 CARBONE CHRIS ET AL ROGERS ROBERT ET AL\nW1 0100048 N\n20 0100048000 22-APR-91\n35000 GARDEN MANAGEMENT CO TWO 06 PRINCETON RLT\nL1 0100048 N\n21 0100048000 27-FEB-95\n40000 TWO 06 PRINCETON RLT WARSHAW GEORGE\n0100048 N\n-- Press [Return] to continue --\n...\n...\n...\n[ 68134 rows total ]\nThe first two characters of the parcel_id (and the base_id) are the Ward. Let's see how\nmany Ward 12 sales are included in the ASSESS_DATA.SALES table:\nselect count(*), count(distinct parcel_id), count(distinct base_id)\nfrom assess_data.sales\nwhere substr(parcel_id, 1, 2) = '12';\nCOUNT(*) COUNT(DISTINCTPARCEL_ID) COUNT(DISTINCTBASE_ID)\nHmm, there are 853 sales involving 557 distinct parcel numbers and 433 unique base_id\nvalues. Condos within the same building/development share the same base_id (and\nparcel footprint) but have different parcel numbers (the last 3 digits differ).\nUnfortunately, split parcels can also retain the same base_id--but they have different\nfootprints as well as differing last three digits. For the purposes of this exercise, we will\nignore complications involving split parcels but will address complications associated\nwith condo sales and multiple sales of individual parcels.\nTo begin, let's construct a SQL query that pulls into ArcView the IDs and (average) sale\nprice of all Ward 12 parcels:\ncreate view holdsales1 as\nselect base_id, avg(price) saleprice, count(*) sales\nfrom assess_data.sales\nwhere substr(base_id,1,2) = '12'\ngroup by base_id;\nThere are 433 rows in this table--including one base_id that showed up 72 times in the\nSALES table! From ArcView, we can connect to Oracle using the Properties/SQL-\nConnect menu option. (Remember to 'connect' to Oracle by making the project window\nactive and then selecting Project > SQL Connect. The project window is the one labeled\nUntitled until you save your project, then yourprojectfilename.apr after you do save it.)\nIn the SQL Connect dialog box, you will need to press the 'Connect' button, then enter\nyour Oracle username and password in the format YourAthenaID/password, where\npassword is your Oracle password). Make the connection and pull this holdsales1 table\ninto ArcView.\n(2.2) Mapping Ward 12 Parcels\n\nThere are 135000+ parcels in Boston but we've saved a smaller shapefile for just the\n2,592 in Ward 12. Add these Ward 12 parcels as a theme in your ArcView window:\n/mit/crlclass/11.521/data/bospar96wd12.shp\nYou'll see that the attribute table contains both a parcel_id and a base_id column. We\ncould use base_id to join the holdsales1 table to 'Attributes of Bospar96wd12.shp' and\nthen do a thematic map based on sales price. (Try it later if you have time.) But many of\nthe parcels are so small and the number of sales so many that the resulting thematic map\nof housing prices won't be too readable. In addition, the unsold parcels won't be shaded at\nall.\nWe'd like to use the SALES data as an indication of housing value in the area\nsurrounding the sale. One way to do such an interpolation is to compute a housing value\nfor any particular location that is some type of average of nearby sales prices. By\nrasterizing the space within Ward 12, we can identify a finite and manageable number of\nplaces to consider (each grid cell) and then we can use the capacity of the GIS to know\nwhich sales are 'nearby' to help us compute a useful average. (We don't have to rasterize\nthe Ward. We could consider every parcel and set it's value to be a weighted average of\nits sales--if any--and its neighbors. But that requires a lot more geometry calculations so\nanalysts often settle for a quicker raster analysis as illustrated next.)\nBefore doing this interpolation, we must join the sales data in holdsales1 to the mappable\nparcel data. We could use bospar96wd12.shp for this purpose but it will be easier to do\nthe analysis if we join the sales data to a 'point' coverage rather than to a polygon\ncoverage. Since we'll only have time today to show one of the simpler interpolation\nmethods, we'll do that. The staff has already created a 'point' coverage for Ward 12\nparcels whereby each parcel_id (and base_id) is associated with a 'point' lying (more or\nless) in the middle of each parcel. Add this coverage to your ArcView window:\n/mit/crlclass/11.521/data/bospar96wd12pt.shp\nNow, join the holdsales1 to the 'Attributes of Bospar96wd12pt.shp' table using the\nbase_id field. You should find 468 matches--a few dozen more than the 433 rows in\nholdsales1 because of some split-parcels in Ward 12 (a problem that we will ignore for\nthis exercise).\n(2.3) Interpolating Housing Values from Sales Price Data\nWe are now ready to do the interpolation via the averaging approach that we discussed\nabove.\n-\nso Ward 12 fills your view window.\nHighlight Bospar96wd12pt.shp and press the 'Zoom to Active Theme(s)' button\n-\nUse the 'hammer' Query tool\nto select all parcels that sold--that is, had a\nsaleprice > 0. (If you don't, the interpolation will try to include all the parcels\nwith null saleprices and probably produce errors as well as meaningless results.)\n\n-\nNow, select 'Interpolate Grid' from the 'Surface' menu. Use the default 'Method'\n(which is a weighted inverse distance method, IDW).\n-\nUse Saleprice as your Z Value Field, and the defaults for 'Number of Neighbors'\n(12), 'Power' (2), and 'No barriers'\n-\nClick OK\n-\nThe grid theme that is created is quite strange--it fills the entire rectangle\ncontaining Ward 12 and looks something like this:\nThe interpolated surface is shown thematically by shading each cell dark or light\ndepending upon whether that cell is estimated to have a lower housing value (darker\nshades) or higher housing value (lighter shades). Based on the parameters we set, the cell\nvalue is an inverse-distance weighted average of the 12 closest sales. Since the power\nfactor was set to the default (2), the weights are proportional to the square of the distance.\nThis interpolation heuristic seems reasonable, but the surface extends far beyond the\nWard 12 borders (all the way to the rectangular bounding box that covers Ward 12). This\nproblem is easily fixed by setting the 'mask' to be used when interpolating. We can\nprevent the interpolation from computing values outside of the Ward 12 boundary by\n'masking' off those cells that fall outside. Do this by adding a mask to the Analysis\nProperties:\n-\nReopen the Analysis > Properties dialog box and set the Analysis Mask to be\nSoswd12gd--the grid that we computed earlier from the Ward12bnd.shp\nshapefile.\n\nWith this analysis mask set, interpolate the Saleprice values in Bospar96wd12pt.shp\nonce again and you'll get a surface that looks like this (after making the 'no data' case\ntransparent):\nAll the values inside Ward 12 are the same as before, but the cells outside Ward 12 are\n'masked off' and set to be transparent. Delete the unmasked surface, and use Theme >\nProperties to rename the masked surface to be 'Surface-ward12-sales2'.\nClose inspection indicates that the surface is severely distorted with almost all the cells in\nthe lowest-priced shading category--which goes up to $600,000! The one white cell\ncontains the one parcel in Ward 12 that sold for more than $675,000 and that parcel sold\n(once) for $6,592,010. If we exclude just that one parcel before interpolating the value\nsurface, the result looks like this:\n\nThis interpolated surface begins to look more reasonable, although it is still likely to be\nquite sensitive to outliers--especially since we have done nothing to control for the size\nof the housing units that are sold. Closer inspection of the Oracle data dictionaries\nassociated with the Boston assessing data (see the bottom of the CRL metadata page)\nindicates that the SALES table contains a stateclass field that indicates the parcel's land\nuse type as a three-digit code. A few lookup tables are also of interest. The USECAT\ntable breaks the detailed stateclass code into 'categoryid' ranges such as RP = 'residential\nproperty' and RA = 'apartment property', and the STCLASS table relates each stateclass\ncode to this two-character categoryid and to another abbreviated 'landuse' code. Also, a\nSALECODE table explains the codes that indicate which sales were 'arms length' and\nwhich were not a good indication of market value. (The tables USECAT, STCLASS, and\nSALECODE are also owned by the user ASSESS_DATA. As such, it is a good idea to\nfully qualify the table name with the owner name (e.g., ASSESS_DATA.SALECODE) as\nshown below. These tables have public synonyms defined for them, meaning that any\nuser can query from them without qualifying the table name provided the user does not\nhave a private object that conflicts. Actually, ASSESS_DATA.SALES has a public\nsynonym defined for it too, but it conflicts with the private synonym already defined in\nyour schema, so the private synonym takes precedence. You can write queries on the data\ndictionary 'view' that is called ALL_SYNONYMS in order to see what's going on.)\nA quick look at the breakdown of sales codes indicates that about half of the Ward 12\nsales were non-market value sales to/from a financial institution--probably due to\nforeclosure and only the SX, W1, W2, and X1 sales are likely to be representative of fair\nmarket value.\n\n-- ------------------------------------------------------- ----------\nselect s.salecode, substr(descript,1,55) description, count(*)\nfrom assess_data.sales s, assess_data.salecode c\nwhere substr(base_id, 1, 2) = '12'\nand s.salecode = c.salecode\ngroup by s.salecode, substr(descript, 1, 55)\nhaving count(*) > 10\norder by salecode, substr(descript, 1, 55);\nSA DESCRIPTION\nCOUNT(*)\nA1 Sale among members of the same family or relatives\nD2 Property significantly improved after assessment but be\nD3 Sale of improved property at an atypical price; \"specul\nE1 Sale to or from federal, state, or local government\nK1 Sale to or from a charity, educational, or religious or\nL1 Sale to or from a financial institution not reflecting\nMW Multi-parcel sale, not personally verified\nN3 Multi-parcel sale conveyed in one deed, not fair market\nN9 Sale price of unit reflects a tenant cash discount\nSX Auction sale; verified as arm's length\nW1 Price within 10% of most current assessment\nW2 Consistent with inspection and market, sale not verifie\nX1 Field inspected by staff, sale personally verified by s\n13 rows selected.\nWith this in mind, let's create a new view that restricts the selection to fair-market sales\nof condos and 1-4 family units:\ncreate view holdsales2 as\nselect base_id, landuse, avg(price) saleprice, count(*) sales\nfrom assess_data.sales s, assess_data.stclass c\nwhere substr(base_id,1,2) = '12'\nand s.stateclass = c.stateclass\nand (landuse in ('R1', 'R2', 'R3', 'R4') or\ns.stateclass = 102)\nand (salecode in ('SX', 'W1', 'W2', 'X1'))\ngroup by base_id, landuse;\nLet's bring this view, with 210 rows, over to ArcView as holdsales2 and do another\ninterpolation. This time, the interpolated surface looks like this:\n\nThis time, the interpolated values are much less skewed with the grid cells ranging from\n31K--about 200K. The 'low' and 'high' value parts of Ward 12 are quite different than\nbefore. Do you have faith in these results? Remember the block_id that appeared 72\ntimes in the SALES table. Our analysis counted it as one sale. Is it a split-parcel (with\nmany units built on a sub-division) or does it represent multiple sales of condos in the\nsame complex?\nIf you were doing this analysis for real, you would want to iron out your methodology on\na small part of the City (such as Ward 12) before applying the analysis to the entire city.\nIn such a case, you might want to adjust the grid cell size and, perhaps, adjust the mask\nso that it excluded parts of the city that weren't really residential neighborhoods. Picking\nappropriate cell sizes and masks can be time consuming and is as much an art as a\nscience. There are also many more sophisticated statistic methods for interpolating and\nestimating value surfaces. (S*Plus is one package that runs on Athena machines and\nsupports spatial regression, kriging and other techniques that explicitly account for spatial\ninteractions).\nWe don't have time to refine the analysis further (for example to examine multiple sale\nissues, split parcels, and price inflation during the 1986-1995 period), or to compare\nalternative interpolation models. But this exercise should be enough to give you a sense\nof when and why it is often important to have more data manipulation capabilities than\nArcView provides, and how the ArcView/Oracle link matters as you begin to work with\nlarger datasets. You may also wish to review last Fall's raster modeling exercise, lab7 of\n11.520 to see more examples and discussion of interpolation and 'map algebra' modeling.\n\nAlso, think about this interpolation approach versus using a thematic map of block group\ndata or a nearest-neighbor smoothed grid cell map of either block group data or\nindividual parcel assessments.\nAnalyzing 'real world' datasets--especially disaggregated administrative datasets such as\nassessment and sales data--often requires the complexities and subtleties involved in this\nexercise. What should a planner know in order to get past the simple (and wrong) first or\nsecond round of interpolation? How can you tell if someone you hire knows how to do\ndisaggregated spatial analyses that are meaningful? How can you institutionalize the data\nprocessing and modeling so that planners can routinely tap these administrative datasets\nfor planning purposes with confidence and reliability? (Development of the 'salecodes'\nused to tag market-value and non-market-value sales is one example of how data quality\ncan be distinguished. However, given Boston's parcel numbering schemes and limited\ncross-reference tables, the handling of condo sales and parcel subdivisions remains\ncomplex and prone to analysis errors.)\n(3) Lab Assignment\nMost of the questions suggested above are simply to stimulate your thinking. Only a few\nitems need to be turned in for this lab assignment. Create another view holdsales3 for the\nsame landuse categories but for the 'L1' salecodes that reflect foreclosures. This view\nshould have 125 rows. Redo the interpolated housing value surface using these 125 rows.\nTurn in the following:\nA. Your SQL query to create the view.\nB. A printout of the interpolated surface (equivalent to the interpolated\nimages shown above--a screen dump is okay, but make sure it is readable,\nespecially if you use grayscale output).\nC. A brief few sentences commenting on changed housing value patterns that\nyou see in this final map, and one or two other analysis strategies that you\nmight take to account for one or another of the complications that we\nhaven't yet addressed.\nYou may turn in this assignment on paper or electronically. This lab assignment is\nintended to be done during today's lab but it is okay if you want to finish it later as long\nas it is turned in a day before lecture #14."
    },
    {
      "category": "Lecture Notes",
      "title": "lect1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/7089d34864ecca25644819adfa3b6659_lect1.pdf",
      "content": "Course Introduction and the Marriage:\nPlanners and Data\nPart A: Course Intro\n-\nGeneral motivation: Spatial analysis, distributed/shared data,\nPlanning project involving GIS (more motivation later)\n-\nDescription, Syllabus, logistics\n-\nSoftware (Oracle, ArcView, MS-Access),\nPart B: The Marriage: Planners & Data*\nPart C: Introduction to Lab Exercise #1\n-\nGIS - ArcView map of Mass Towns\n-\nDatabase Management - MS-Access to query simple parcel and\ntax tables\n-\nComplexities when you 'roll your own' and/or share data online\no Computing population density for Massachusetts towns\no Using someone else's administrative data\no Handling complex queries: which properties flipped\nquickly within a year of foreclosure\no Accumulating reusable knowledge\n-\nWhere we're headed: Geospatial web services and distributed\naccess to shared databases\n-\nLab #1: Intro to Computing Environment, SQL, and ArcView\no Accessing Oracle database engine using SQL*Plus\no Review of ArcView\n* Kindly refer to Lecture Notes section"
    },
    {
      "category": "Lecture Notes",
      "title": "lect1LH.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/5da6dc25a59b985bce321c7d21b94817_lect1LH.pdf",
      "content": "The Marriage: Planners and Data\nPart I: What do planners do?\nPlanning is a systematic and creative way to influence the future of a neighborhood, city,\nregion, etc.\nPlanners respond to social, economic, and cultural challenges by...\n-\nenhancing the quality of life\n-\nprotecting the environment\n-\npromoting equity and equality\n-\nguiding growth and development\nTo achieve these objectives, planners involve stakeholders in decision-making processes,\nassist communities in creating a vision for the future, analyze information to generate\nsolutions to problems, and present recommendations to public officials and citizen\ngroups.\nPlanners Are Information Stewards\n-\nPractical guide for advancement of the city planning movement\n-\nGeneral understanding of city planning\n-\nGeneral acceptance of the desirability of having a city plan\n-\nCornell University, International Anthology of Conference Papers on Urban\nPlanning 1794 - 1918\nFrederick Law Olmsted, 1913 (Proceedings of the Fifth National Conference on City\nPlanning, Boston)\nThe Evolving Definition of Planning\n\"...the working out in broad outline the things that need to be done and the methods for\ndoing them to accomplish the purpose set for the enterprise.\"\n(Gulick, 1937).\n\"...deciding in advance what is to be done; that is, a plan is a projected course of action.\"\n(William, 1958).\n\n\"...a process; that is, a continuous activity taking place within a unit and requiring some\ninput of resources and energy in order to be sustained.\"\n(Yehezkel, 1963).\n\"...any activity centrally concerned with the linkage between knowledge and organized\naction.\" (Wright, 1980).\n\"...the art of organizing space, science integrating research and knowledge of various\ndisciplines, and politics using available means to achieve specific aims.\" (Kozlowski,\n1988).\nPlanners Collect and Organize Data, then Communicate Information\nCollect --- Reality --- Data\n-\nPrimary data sources (Field surveys, interviews, and questionnaires)\n-\nSecondary data sources (US Census Bureau, Bureau of Labor Statistics, etc.)\nOrganize --- Information\n-\nStore and manipulate data (SQL and Oracle)\n-\nAnalyze data (ArcView, ArcGIS, Spatial Analyst, SPSS, etc.)\nCommunicate --- Knowledge --- Action --- New Reality\n-\nTo experts, publics, and clients (Final critique)\n-\nVerbal, written, and graphic (Project deliverables)\nPart II: The Evolving Relationship\n-\nThe Planner has changed (from physical planning to organizing constituents and\ncoordinating programs)\n-\nThe Data have changed (availability, format, content)\nFocus on Democratic Involvement and Transparency\n-\nBottom-up versus top-down approach to public participation (involvement of\nCBOs and emphasis on local knowledge)\n-\nTechnological advancements have had an impact on planning-related tools (E-\nmail, GIS, and the WWW)\n\n-\nEfforts to integrate, represent and transmit local knowledge (neighborhood\ninformation systems)\nProcess persists...Reality --- Data --- Information --- Knowledge --- Action --- New\nReality"
    },
    {
      "category": "Lecture Notes",
      "title": "lect2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/99fe780b6b6efb0d08088a88b99be558_lect2.pdf",
      "content": "Relational Database Management &\nGeospatial Data\n-\nSQL and the Sample Parcel Database\no Examining the schema: table structure and data types\no Reviewing software setup and using SQL*Plus\no The basic SELECT statement\no Sample SQL Queries using ArcView and the Cambridge\nSALES89 table\no Qualities of a Good Database Design\no Why use a more elaborate database management system\n(DBMS)?\n-\nDatabase Management: Motivation and Fundamentals (from 11.520\nlecture notes)\no The Web as an information repository\no Often need more highly structured data repositories (and query\ntools)\no Planner's perspective and GIS implications\no Data types, parsing, & mix-n-match issues\n-\nThe Relational Model\no All data are represented as tables\no Querying one or more tables via the basic SELECT statement\no Gets interesting when \"rows\" in each table have different meaning\no One-to-Many Complications (same-house sales; multi-polygon\ntowns;...)\n-\nSQL and the Sample Parcel Database*\no Examining the schema: table structure and data types\n\nWhy spin off an owner's table\n\nWhy have an owner number\n\nEntity-relationship diagrams and normalization\n\nDatabase design issues and tradeoffs\no Reviewing software setup and using SQL*Plus\n\ndiscussion of lab questions\n* Kindly refer to the Lecture Notes section\n\nUse of NULL: difference between IS NULL and =\nNULL\n\nSpooling files, fixed width fonts, use of COLUMN...\n\nTable prefixes - why use table alias, distinguishing\ntable owner\n\ndistributed access to table column\n\nUse of SQL Notes* and Oracle help\no The basic SELECT statement to query one or more tables:\nSELECT [DISTINCT] column_name1[,\ncolumn_name2, ...]\nFROM table_name1[, table_name2, ...]\nWHERE search_condition1\n[AND search_condition2 ...]\n[OR search_condition3...]\n[GROUP BY column_names]\n[ORDER BY column_names];\no Note that the order of the clauses matters! The clauses, if included, must\nappear in the order shown! Oracle will report an error if you make a\nmistake, but the error message (e.g., \"ORA-00933: SQL command not\nproperly ended\") may not be very informative.\no Sample SQL Queries using the Parcel Database*\n\nSee Lab 1* examples\n\nSee examples and other help in SQL Notes*\no Sample SQL Queries using ArcView and the Cambridge\nSALES89 table\n\nExample A: Select address, date, realprice columns from\nsales89 table for houses that sold after July 1, 1989 for\nmore than $250,00\nSELECT address, date, realprice\nFROM sales89\nWHERE realprice > 250000 and date > \"07/01/1989\"\n* Kindly refer to Lecture Notes Section\n\nExample B: Count the number of 1989 sales associated\nwith each address that is listed in the sales89 table and\norder the results by sale_count, then, address, and date:\nSELECT address, count(distinct date) sale_count\nFROM sales89\nWHERE realprice > 250000 and date > \"07/01/1989\"\nGROUP BY address, date\nORDER BY count(distinct date), address, date\n\nExample C: For every sales89 sale in Cambridge, list\nthe address, saledate, and sales price along with the percent\nof adults in the surrounding census block group who had\nless than a high school education. The sales89 and\ncambbgrp tables could be joined by a common column (if\nthe sales89 table had a column listing the census block\ngroup) or by a spatial join (that used the geographic data to\ncompute which block group contained each sale):\nSELECT s.address, s.date, s.realprice,\n100*(c.EDU1 + c.EDU2 / c.EDUTOTAL) low_ed_percent\nFROM cambbgrp c, sales89 s\nWHERE c.stcntrbg = s.stcntrbg\nif the sales89 table included as a 'foreign key' the stcntrbg\n'primary key' from the cambbgrp table, or:\nSELECT s.address, s.date, s.realprice,\n100*(c.EDU1 + c.EDU2 / c.EDUTOTAL)\nlow_ed_percent\nFROM cambbgrp c, sales89 s\nWHERE s.SpatialObject IS CONTAINED WITHIN\nc.SpatialObject\no Qualities of a Good Database Design\n\nTables reflect real-world structure of the problem\n\nCan represent all expected data over time\n\nAvoids redundant storage of data items\n\nProvides efficient access to data\n\nSupports the maintenance and integrity of data over time\n\nClean, consistent, and easy to understand\n\nNote: These objectives are sometimes contradictory!\no Why use a more elaborate database management system\n(DBMS)?\n\nHandling multi-table complexity (one-to-many, ...)\n\nEase of documenting/replicating queries/results\n\nPerformance\n\nSecurity\n\nSafe for multiple users\n\nSharing data among applications\n\nBuilt-in data dictionary\n-\nDatabase Management: Motivation and Fundamentals (Repeat of\noutline from end of previous lecture)\no The Web as an information repository\n\nA rich information source but a loosely structured\ncollection of relatively unstructured data\n\nHard to find what you want without search engines and\nportals to index and structure the information and\nstandardize the query process\n\nHard to utilize and extend knowledge on the Web without\ncontrolling/copying it (broken links, complex\nparsing/extraction, limited quality control, etc.)\no Often need more highly structured data repositories (and query\ntools)\n\nDesktop tools such as Excel, MS-Access, Filemaker, etc.\nhandle personal database management needs (mailing lists,\nsurvey results, etc.)\n\nComplex software often needed to manage multi-user\naccess to 'persistent data'\n\nTypes of databases: single-user, corporate, engineering,\nscience, image/video, geographic, ...\n\nIssues: performance, metadata, user interface, data\nstructure, concurrency, distributed, ...\n\nOther 'big-system' issues: Security/reliability/integrity\nrequirements (parcel ownership records, census data, major\nroads)\n\nOther complications: transaction processing, data\nwarehousing, online analytic processing, data mining, ...\n\nOur focus: data structure issues and query capabilities\n\n--\no Planner's perspective and GIS implications\n\nComplex, semi-structured questions that involve one-of-a-\nkind analyses:\n\nWhich buildings in Boston have more than 1000\nsquare feet of retail space and are located in\nneighborhoods with above-average incomes?\n\nWhat level of trace gas exposures can be anticipated\nfrom EPA's Toxic Release Inventory sites?\n\nHave 'move-to-opportunity' families had better job-\nretention experience than inner city residents who\nreceive job training and housing assistance?\n\nRecognize that planner needs are different from those of\nCity Hall\n\n(corporate) vs. Professional (end-user) needs/goals\n\ncity hall (enterprise) issues -- efficient data\nentry/retrieval/accuracy/security using tools that\nfacilitate automation, maintenance, access control,\nand simple interfaces for edits, reports, common\nqueries\n\nplanning professional issues\nstartup/flexibility/modeling/integration/power using\ntools that can extract, merge, transform data; handle\ntime series; and support complex queries\n\nStructured vs. unstructured databases\n\nHighly structured data - Census data parcel records,\netc. with SQL query tools\n\nUnstructured data - Web pages with search engines\nand 'free-format text retrieval' tools\n\nGIS 'demos' are easy but spatial analysis is hard\n\nNo sweat if the data you want are already cleaned,\nparsed, and precisely suited to your question\n\nUseful spatial analyses involves judicious mixing\nand matching data from official and local sources\n\nTapping into distributed, non-static databases can get\ncomplex for non automatable tasks\no Data types, parsing, & mix-n-match issues\n\nAlphanumeric: Character strings; integers, floating point\nnumbers, dates, binary codes, ...\n\nMulti-dimensional: Images, maps, spatial objects, 3D\nmodels, video, math models, ...\n\nEncoding/parsing addresses, zips, census tracts (77 Mass\nAve, Cambridge, MA 02139)\n\nStorage space, column headers (metadata), null/missing\nvalues\n- The Relational Model\no All data are represented as tables\n\nEach table can be stored or viewed as one 'flat file'\n\nTables are comprised of rows and columns\n\nSimple queries select particular rows and columns from a\ntable\n\nEach table has a primary key, a unique identifier\nconstructed from one or more columns\n\nA table is linked (joined) to another by including the other\ntable's primary key. Such an included column is called a\nforeign key\n\nMore complex queries relate (join) multiple tables using\nprimary/foreign keys\n\nThe results of any given query are just another table! (so\ncomplex queries can involve sub-queries)\n\nOne-to-many (and many-to-many) relations can be handled\nthrough the use of aggregation functions (sum, count,\naverage, minimum, etc.)\no Gets interesting when \"rows\" in each table have different meaning\nand joining tables involves one-to-many or many-to-many\nmatches. Consider:\n\nhouse sales in a 'sales' table\n\npersons in the owner table\n\ntax payments in a 'tax' table\n\ncounts and other statistics in a census tract table\no Handling one-to-many and many-to-many relations can be useful\nbut tricky:\n\nOwners may have multiple properties; properties may sell\nmore than once; etc.\n\nHow can you join the tables in order to determine all\nowners that have been in arrears on their taxes within two\nyears of buying a property\n\nAre new owners more likely to be in arrears on their taxes\nif the property is in a low (high) income census tract?\n\nOther SQL Commands and Notes (Mostly for later\nlectures & labs)\n- Review: SELECT Statement Syntax\n- SQL Miscellany\n- Creating a table: CREATE TABLE\n- Dropping a table: DROP TABLE\n- Storing a Query: CREATE VIEW\n- Joins: Multiple Table Queries\n- Aggregration: GROUP BY, Group Functions\nSQL Miscellany\no DESCRIBE\no Numbers and strings\no AND and OR\no LIKE\no SUBSTR\no Expressions\nCreating a Table\no CREATE TABLE table_name ...\no CREATE TABLE table_name AS SELECT ...\nDropping a Table\no DROP TABLE table_name;\nStoring a Query: CREATE VIEW\no CREATE VIEW view_name AS SELECT ...\nJoins: Multiple Table Queries\no See: SQL Help Notes*\n* Kindly refer to Lecture Notes Section\n\nAggregration: GROUP BY, Group Functions\nSimple GROUP BY Example From the Parcels\nDatabase\nWhen a SQL statement contains a GROUP BY clause, the rows are selected using the\ncriteria in the WHERE clause and are then aggregated into groups that share common\nvalues for the GROUP BY expressions. The HAVING clause may be used to eliminate\ngroups after the aggregation has occurred.\nThese examples draw on the PARCELS sample database* that we have used previously.\n1. List all the fires, including the\ndate of the fire:\n2. List the count of fires by parcel:\nSELECT PARCELID, FDATE\nFROM FIRES\nORDER BY PARCELID, FDATE;\nSELECT PARCELID, COUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nORDER BY PARCELID;\nGroups are shown in color, but this\nquery does not actually perform\ngrouping.\nGroups and summary functions have been\ncalculated; notice that no FDATE values are\nshown.\nPARCELID\nFDATE\n2 02-AUG-88\n2 02-APR-89\n3 26-JUL-89\n3 26-JUL-90\n7 01-AUG-87\n20 02-JUL-89\nPARCELID FIRE_COUNT\nThe Different Roles of the WHERE Clause and the\nHAVING Clause\nThe WHERE clause restricts the rows that are processed before any grouping occurs.\nThe HAVING clause is used with GROUP BY to limit the groups returned after\ngrouping has occurred.\n* Kindly refer to Lecture Notes Section\n\n3. List all the fires that\noccurred on or after 1\nAugust 1988:\n4. List the count of fires that\noccurred on or after 1 August\n1988 by parcel:\n5. List the count of fires that\noccurred on or after 1 August\n1988 by parcel for parcels that\nhad more than one fire:\nSELECT PARCELID,\nFDATE\nFROM FIRES\nWHERE FDATE >=\nTO_DATE('01-AUG-\n1988',\n'DD-MON-YYYY')\nORDER BY PARCELID,\nFDATE;\nSELECT PARCELID,\nCOUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nWHERE FDATE >=\nTO_DATE('01-\nAUG-1988',\n'DD-\nMON-YYYY')\nGROUP BY PARCELID\nORDER BY PARCELID;\nSELECT PARCELID,\nCOUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nWHERE FDATE >=\nTO_DATE('01-\nAUG-1988',\n'DD-\nMON-YYYY')\nGROUP BY PARCELID\nHAVING COUNT(FDATE) > 1\nORDER BY PARCELID;\nGroups are shown in\ncolor, but this query\ndoes not actually\nperform grouping. Note\nthat the fire at parcel 7\non 1 August 1987 has\nbeen excluded by the\nWHERE clause.\nThis query shows the result of\ngrouping, but no HAVING\nclause is applied. Groups that\nsatisfy the HAVING clause of\nQuery 5 are shown in bold.\nFinal result, after groups that\nfail the HAVING clause have\nbeen eliminated.\nPARCELI\nD\nFDAT\nE\n2 02-\nAUG-\n2 02-\nAPR-\n3 26-\nJUL-\n3 26-\nJUL-\n20 02-\nJUL-\nPARCELI\nD\nFIRE_COU\nNT\nPARCELI\nD\nFIRE_COU\nNT\n\nRules for GROUP BY Queries\n-\nIn a GROUP BY query, all expressions in the SELECT list not containing\ngroup functions (SUM, AVG, COUNT, etc.) must appear in the GROUP BY\nclause.\nThe following query is invalid because it includes a column (FDATE) that is not\nin the GROUP BY clause. This query will fail with the Oracle error \"ORA-00979:\nnot a GROUP BY expression\":\nSELECT PARCELID, FDATE, COUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nORDER BY PARCELID, FDATE;\nThink for a minute why this query does not make sense. For each distinct value of\nPARCELID, there may be multiple values of FDATE. For example, the parcel with\nPARCELID = 2 had fires on both 2 Aug. 1988 and 2 Apr. 1989. When we group by\nPARCELID alone, the results of the query will have at most one row for each value of\nPARCELID. If we include FDATE in the SELECT list, which FDATE should Oracle\npick for PARCELID = 2? The answer is undefined, and that is why the query is invalid.\nOracle is unable to pick a single value of an unaggregated item to represent a group.\nTo fix this query, we must ensure that the SELECT list and the GROUP BY clause\ncontain the same expressions (excluding expressions that use group functions such as\nCOUNT(FDATE)).We have two choices. First, we can remove FDATE from the\nSELECT list (and the ORDER BY clause):\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nORDER BY PARCELID;\nSecond, we can add FDATE to the GROUP BY clause:\n\nSELECT PARCELID, FDATE, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID, FDATE\nORDER BY PARCELID, FDATE;\nBe careful when picking this second option! Adding a column to the GROUP BY clause\nmay change the meaning of your groups, as in this example. Notice that all the\nFIRE_COUNT values for this last query are 1. That's because by adding FDATE to the\nGROUP BY clause we have effectively made each group a single row from the FIRES\ntable--not very interesting!\n-\nAll GROUP BY expressions should appear in the SELECT list.\n(How else will you know what group is being shown?)\nTo find the names of the owners of exactly one parcel, we can use this query:\nSELECT OWNERS.ONAME, COUNT(*) PARCEL_COUNT\nFROM PARCELS, OWNERS\nWHERE PARCELS.ONUM = OWNERS.OWNERNUM\nGROUP BY OWNERS.ONAME\nHAVING COUNT(*) = 1;\nThe query below is valid, but uninformative. Who are the single-parcel owners?\nSELECT COUNT(*) PARCEL_COUNT\nFROM PARCELS, OWNERS\nWHERE PARCELS.ONUM = OWNERS.OWNERNUM\nGROUP BY OWNERS.ONAME\nHAVING COUNT(*) = 1;\nShowing the count of parcels when we've restricted the parcel count to 1 is not\nvery interesting. We can simply leave the count out of the SELECT list. Note that\nyou can use a HAVING condition without including the group function in the\nSELECT list:\nSELECT OWNERS.ONAME\nFROM PARCELS, OWNERS\nWHERE PARCELS.ONUM = OWNERS.OWNERNUM\nGROUP BY OWNERS.ONAME\nHAVING COUNT(*) = 1;\n\n------------------------ ----------\n-\nGROUP BY expressions can be more elaborate than simple column\nreferences.\nExpressions such as\nCOL1 + COL2\n(the sum of two columns)\nCOL1 || COL2 || COL3 (three columns concatenated together)\nare also valid in the GROUP BY clause. As noted above, the expression should\nappear both in the GROUP BY clause and in the SELECT list. A column alias,\nwhile valid in the SELECT list, may not be used in the GROUP BY clause. You\nmust repeat the entire expression from the SELECT list in the GROUP BY clause.\nNote, however, that a column alias is valid in the ORDER BY clause.\nSuppose we want to count the parcel owners based on the city and state they live\nin, formatting the city and state as \"City, State\" (e.g., \"BOSTON, MA\"). The\nquery below is valid:\nSELECT CITY || ', ' || STATE CITY_STATE,\nCOUNT(*) OWNERS\nFROM OWNERS\nGROUP BY CITY || ', ' || STATE\nORDER BY CITY_STATE;\nCITY_STATE\nOWNERS\nBOSTON, MA\nBROOKLYN, NY\nBURLINGTON, VT\nNEW YORK, NY\nThe query below will fail with the Oracle error \"ORA-00904: invalid column\nname\" because \"TOTAL_VAL\" is merely a column alias, not a real column.\n(Curiously, column aliases are valid in the ORDER BY clause, as shown above.)\nHence the actual expression must be included in the GROUP BY clause as above:\nSELECT CITY || ', ' || STATE CITY_STATE,\nCOUNT(*) OWNERS\nFROM OWNERS\n\nGROUP BY CITY_STATE\nORDER BY CITY_STATE;\n-\nThe HAVING clause restricts the groups that are returned.\nDo not confuse it with the WHERE clause, which refers to the original rows\nbefore they are aggregated. While you can use the HAVING clause to screen out\ngroups that the WHERE clause would have excluded, the WHERE is more\nefficient than the GROUP BY clause, because it operates while the rows are being\nretrieved and before they are aggregated, while the HAVING clause operates only\nafter the rows have been retrieved and aggregated into groups.\nThe query below lists the count of fires by parcel, counting only fires with a loss\nof at least $40,000:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nWHERE ESTLOSS >= 40000\nGROUP BY PARCELID\nORDER BY PARCELID;\nAn incorrect way to attempt this query is to place the \"ESTLOSS >= 40000\"\ncondition in the HAVING clause rather than the WHERE clause. The following\nquery will fail with the Oracle error \"ORA-00979: not a GROUP BY expression\"\nbecause we are attempting to exclude a group using a column that is not part of\nthe GROUP BY clause and hence out of context:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nHAVING ESTLOSS >= 40000\nORDER BY PARCELID;\nSuppose we want to look at losses for fires by ignition factor (IGNFACTOR), but want to\nignore the case where IGNFACTOR is 2. We can write this query two ways.\nFirst, we can use a WHERE clause:\nSELECT IGNFACTOR, COUNT(FDATE) FIRE_COUNT,\nSUM(ESTLOSS) LOSSES\n\n---------- ---------- ---------- ---------\n- ----------\nFROM FIRES\nWHERE IGNFACTOR <> 2\nGROUP BY IGNFACTOR\nORDER BY IGNFACTOR;\nSecond, we can use a HAVING clause:\nSELECT IGNFACTOR, COUNT(FDATE) FIRE_COUNT,\nSUM(ESTLOSS) LOSSES\nFROM FIRES\nGROUP BY IGNFACTOR\nHAVING IGNFACTOR <> 2\nORDER BY IGNFACTOR;\nBoth of these queries return the same correct result, but the first version using\nWHERE is more efficient because it screens out rows when they are initially\nretrieved by the database engine, while the second version using HAVING takes\neffect only after all the rows have been retrieved and aggregated. This can make a\nbig difference in performance in a large database.\n-\nGroup functions ignore NULL values.\nRemember, however, that COUNT(*) counts rows, not any particular column.\nHence COUNT(*) is sometimes helpful when a particular column of interest\ncontains NULLs. This can lead to different results if you are not careful. For\nexample, the TAX table includes one row with no BLDVAL:\n-\n-\nSELECT *\n-\nFROM TAX\n-\nWHERE BLDVAL IS NULL;\n-\n-\nPARCELID\nPRPTYPE\nLANDVAL\nBLDVAL\nTAX\n-\n-\nN.B.: To find rows with NULLs in them, you must use the syntax \"expr IS NULL\", as\nabove. If you use \"expr = NULL\", the query will run\nbut not return any rows. The other comparison operators (e.g., =, <>, !=, >, <, >=, <=,\nLIKE) will never match NULL. For example, the\nquery below executes but returns no rows:\n\n----------\n-------------\n---------- ---------------\nSELECT *\nFROM TAX\nWHERE BLDVAL = NULL;\nno rows selected\nIf we count records in the TAX table by row using COUNT(*), we get one result:\nSELECT COUNT(*)\nFROM TAX;\nCOUNT(*)\nbut if we count the building values we get a different one:\nSELECT COUNT(BLDVAL)\nFROM TAX;\nCOUNT(BLDVAL)\nValues of ONUM in the PARCELS table are not unique. That explains why\nCOUNT(ONUM) and COUNT(DISTINCT ONUM) return different results in the\nquery below:\nSELECT COUNT(ONUM) OWNERS,\nCOUNT(DISTINCT ONUM) DISTINCT_OWNERS\nFROM PARCELS;\nOWNERS DISTINCT_OWNERS\nIn the last three queries, we were treating the entire set of rows as a single group\n(i.e., we used a group function such as COUNT without a GROUP BY clause).\nNow let's use a GROUP BY to see if ownership of properties in various land use\ncategories is concentrated among a few owners:\nSELECT LANDUSE,\nCOUNT(*) PARCELS,\nCOUNT(ONUM) OWNERS,\nCOUNT(DISTINCT ONUM) DISTINCT_OWNERS\nFROM PARCELS\nGROUP BY LANDUSE;\n\n--- ---------- ---------- ---------------\nLAN\nPARCELS\nOWNERS DISTINCT_OWNERS\nA\nC\nCL\nCM\nE\nR1\nR2\nR3\n9 rows selected.\nWhich value do we want to use for the count of owners, OWNERS or\nDISTINCT_OWNERS? Why?\nGROUP BY Examples\nFind the parcels that experienced more than one fire:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nHAVING COUNT(FDATE) > 1\nORDER BY PARCELID;\nList the fires with a loss of at least $40,000:\nSELECT PARCELID, FDATE, ESTLOSS\nFROM FIRES\nWHERE ESTLOSS >= 40000\nORDER BY PARCELID, FDATE, ESTLOSS;\nList the count of fires by parcel, counting only fires with a loss of at least $40,000:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nWHERE ESTLOSS >= 40000\nGROUP BY PARCELID\nORDER BY PARCELID;\nFind the parcels that experienced more than one fire with a loss of at least $40,000:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nWHERE ESTLOSS >= 40000\nGROUP BY PARCELID\nHAVING COUNT(FDATE) > 1\nORDER BY PARCELID;"
    },
    {
      "category": "Lecture Notes",
      "title": "lect3.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/3bc0329426d015192f34de12308fe651_lect3.pdf",
      "content": "Handling One-to-Many Relations - Grouping and\nAggregation\n-\nNo class/lab next Tuesday\no Today's lab is also Problem Set #1 - due two weeks from today\no We won't cover all of today's lab exercises in this lab preparation\ntalk - the rest will be covered this Thursday\n-\nHandling One-to-Many Relations\no Today's lab prep will review SQL queries from last Thursday's\nlecture notes\no Key concept is use of GROUP BY statements to handle one-to-\nmany relations\no We also introduce another database (of URISA proceedings) to\nlearn more about SQL queries and relational database design\n-\nSQL queries and GROUP BY expressions\no See the Sample Parcel Database*\no See SQL Notes* and Oracle help\no See Lab 1* examples\no The basic SELECT statement to query one or more tables:\nSELECT [DISTINCT] column_name1[, column_name2,\n...]\nFROM table_name1[, table_name2, ...]\nWHERE search_condition1\n[AND search_condition2 ...]\n[OR search_condition3...]\n[GROUP BY column_names]\n[ORDER BY column_names];\no Note that the order of the clauses matters! The clauses, if included, must\nappear in the order shown! Oracle will report an error if you make a\nmistake, but the error message (e.g., \"ORA-00933: SQL command not\nproperly ended\") may not be very informative.\n* Kindly refer to Lecture Notes Section\n\nAggregration: GROUP BY, Group Functions\nSimple GROUP BY Example From the Parcels\nDatabase\nWhen a SQL statement contains a GROUP BY clause, the rows are selected using the\ncriteria in the WHERE clause and are then aggregated into groups that share common\nvalues for the GROUP BY expressions. The HAVING clause may be used to eliminate\ngroups after the aggregation has occurred.\nThese examples draw on the PARCELS sample database* that we have used previously.\n1. List all the fires, including the date\nof the fire:\n2. List the count of fires by parcel:\nSELECT PARCELID, FDATE\nFROM FIRES\nORDER BY PARCELID, FDATE;\nSELECT PARCELID, COUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nORDER BY PARCELID;\nGroups are shown in color, but this\nquery does not collapse groups into a\nsingle row.\nGroups and summary functions have been\ncalculated; notice that no FDATE values are\nshown.\nPARCELID\nFDATE\n2 02-AUG-88\n2 02-APR-89\n3 26-JUL-89\n3 26-JUL-90\n7 01-AUG-87\n20 02-JUL-89\nPARCELID FIRE_COUNT\nThe Different Roles of the WHERE Clause and the\nHAVING Clause\nThe WHERE clause restricts the rows that are processed before any grouping occurs.\nThe HAVING clause is used with GROUP BY to limit the groups returned after\ngrouping has occurred.\n* Kindly refer to Lecture Notes Section\n\n3. List all the fires that\noccurred on or after 1\nAugust 1988:\n4. List the count of fires that\noccurred on or after 1 August\n1988 by parcel:\n5. List the count of fires that\noccurred on or after 1 August\n1988 by parcel for parcels that\nhad more than one fire:\nSELECT PARCELID,\nFDATE\nFROM FIRES\nWHERE FDATE >=\nTO_DATE('01-AUG-\n1988',\n'DD-MON-YYYY')\nORDER BY PARCELID,\nFDATE;\nSELECT PARCELID,\nCOUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nWHERE FDATE >=\nTO_DATE('01-\nAUG-1988',\n'DD-\nMON-YYYY')\nGROUP BY PARCELID\nORDER BY PARCELID;\nSELECT PARCELID,\nCOUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nWHERE FDATE >=\nTO_DATE('01-\nAUG-1988',\n'DD-\nMON-YYYY')\nGROUP BY PARCELID\nHAVING COUNT(FDATE) > 1\nORDER BY PARCELID;\nGroups are shown in\ncolor, but this query\ndoes not actually\nperform grouping. Note\nthat the fire at parcel 7\non 1 August 1987 has\nbeen excluded by the\nWHERE clause.\nThis query shows the result of\ngrouping, but no HAVING\nclause is applied. Groups that\nsatisfy the HAVING clause of\nQuery 5 are shown in bold.\nFinal result, after groups that\nfail the HAVING clause have\nbeen eliminated.\nPARCELI\nD\nFDAT\nE\n2 02-\nAUG-\n2 02-\nAPR-\n3 26-\nJUL-\n3 26-\nJUL-\n20 02-\nJUL-\nPARCELI\nD\nFIRE_COU\nNT\nPARCELI\nD\nFIRE_COU\nNT\n\nRules for GROUP BY Queries\n-\nIn a GROUP BY query, all expressions in the SELECT list not containing\ngroup functions (SUM, AVG, COUNT, etc.) must appear in the GROUP BY\nclause.\nThe following query is invalid because it includes a column (FDATE) that is not\nin the GROUP BY clause. This query will fail with the Oracle error \"ORA-00979:\nnot a GROUP BY expression\":\nSELECT PARCELID, FDATE, COUNT(FDATE)\nFIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nORDER BY PARCELID, FDATE;\nThink for a minute why this query does not make sense. For each distinct value of\nPARCELID, there may be multiple values of FDATE. For example, the parcel with\nPARCELID = 2 had fires on both 2 Aug. 1988 and 2 Apr. 1989. When we group by\nPARCELID alone, the results of the query will have at most one row for each value of\nPARCELID. If we include FDATE in the SELECT list, which FDATE should Oracle\npick for PARCELID = 2? The answer is undefined, and that is why the query is invalid.\nOracle is unable to pick a single value of an unaggregated item to represent a group.\nTo fix this query, we must ensure that the SELECT list and the GROUP BY clause\ncontain the same expressions (excluding expressions that use group functions such as\nCOUNT(FDATE)).We have two choices. First, we can remove FDATE from the\nSELECT list (and the ORDER BY clause):\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nORDER BY PARCELID;\nSecond, we can add FDATE to the GROUP BY clause:\n\nSELECT PARCELID, FDATE, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID, FDATE\nORDER BY PARCELID, FDATE;\nBe careful when picking this second option! Adding a column to the GROUP BY clause\nmay change the meaning of your groups, as in this example. Notice that all the\nFIRE_COUNT values for this last query are 1.That's because by adding FDATE to the\nGROUP BY clause we have effectively made each group a single row from the FIRES\ntable--not very interesting!\n-\nAll GROUP BY expressions should appear in the SELECT list.\n(How else will you know what group is being shown?)\nTo find the names of the owners of exactly one parcel, we can use this query:\nSELECT OWNERS.ONAME, COUNT(*) PARCEL_COUNT\nFROM PARCELS, OWNERS\nWHERE PARCELS.ONUM = OWNERS.OWNERNUM\nGROUP BY OWNERS.ONAME\nHAVING COUNT(*) = 1;\nThe query below is valid, but uninformative. Who are the single-parcel owners?\nSELECT COUNT(*) PARCEL_COUNT\nFROM PARCELS, OWNERS\nWHERE PARCELS.ONUM = OWNERS.OWNERNUM\nGROUP BY OWNERS.ONAME\nHAVING COUNT(*) = 1;\nShowing the count of parcels when we've restricted the parcel count to 1 is not\nvery interesting. We can simply leave the count out of the SELECT list. Note that\nyou can use a HAVING condition without including the group function in the\nSELECT list:\nSELECT OWNERS.ONAME\nFROM PARCELS, OWNERS\nWHERE PARCELS.ONUM = OWNERS.OWNERNUM\nGROUP BY OWNERS.ONAME\nHAVING COUNT(*) = 1;\n\n------------------------ ----------\n-\nGROUP BY expressions can be more elaborate than simple column\nreferences.\nExpressions such as\nCOL1 + COL2\n(the sum of two columns)\nCOL1 || COL2 || COL3 (three columns concatenated together)\nare also valid in the GROUP BY clause. As noted above, the expression should\nappear both in the GROUP BY clause and in the SELECT list. A column alias,\nwhile valid in the SELECT list, may not be used in the GROUP BY clause. You\nmust repeat the entire expression from the SELECT list in the GROUP BY clause.\nNote, however, that a column alias is valid in the ORDER BY clause.\nSuppose we want to count the parcel owners based on the city and state they live\nin, formatting the city and state as \"City, State\" (e.g., \"BOSTON, MA\"). The\nquery below is valid:\nSELECT CITY || ', ' || STATE CITY_STATE,\nCOUNT(*) OWNERS\nFROM OWNERS\nGROUP BY CITY || ', ' || STATE\nORDER BY CITY_STATE;\nCITY_STATE\nOWNERS\nBOSTON, MA\nBROOKLYN, NY\nBURLINGTON, VT\nNEW YORK, NY\nThe query below will fail with the Oracle error \"ORA-00904: invalid column\nname\" because \"TOTAL_VAL\" is merely a column alias, not a real column.\n(Curiously, column aliases are valid in the ORDER BY clause, as shown above.)\nHence the actual expression must be included in the GROUP BY clause as above:\nSELECT CITY || ', ' || STATE CITY_STATE,\nCOUNT(*) OWNERS\nFROM OWNERS\n\nGROUP BY CITY_STATE\nORDER BY CITY_STATE;\n-\nThe HAVING clause restricts the groups that are returned.\nDo not confuse it with the WHERE clause, which refers to the original rows\nbefore they are aggregated. While you can use the HAVING clause to screen out\ngroups that the WHERE clause would have excluded, the WHERE is more\nefficient than the GROUP BY clause, because it operates while the rows are being\nretrieved and before they are aggregated, while the HAVING clause operates only\nafter the rows have been retrieved and aggregated into groups.\nThe query below lists the count of fires by parcel, counting only fires with a loss\nof at least $40,000:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nWHERE ESTLOSS >= 40000\nGROUP BY PARCELID\nORDER BY PARCELID;\nAn incorrect way to attempt this query is to place the \"ESTLOSS >= 40000\"\ncondition in the HAVING clause rather than the WHERE clause. The following\nquery will fail with the Oracle error \"ORA-00979: not a GROUP BY expression\"\nbecause we are attempting to exclude a group using a column that is not part of\nthe GROUP BY clause and hence out of context:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nHAVING ESTLOSS >= 40000\nORDER BY PARCELID;\nSuppose we want to look at losses for fires by ignition factor (IGNFACTOR), but want to\nignore the case where IGNFACTOR is 2. We can write this query two ways.\nFirst, we can use a WHERE clause:\nSELECT IGNFACTOR, COUNT(FDATE) FIRE_COUNT,\nSUM(ESTLOSS) LOSSES\n\n---------- ---------- ---------- ---------\n- ----------\nFROM FIRES\nWHERE IGNFACTOR <> 2\nGROUP BY IGNFACTOR\nORDER BY IGNFACTOR;\nSecond, we can use a HAVING clause:\nSELECT IGNFACTOR, COUNT(FDATE) FIRE_COUNT,\nSUM(ESTLOSS) LOSSES\nFROM FIRES\nGROUP BY IGNFACTOR\nHAVING IGNFACTOR <> 2\nORDER BY IGNFACTOR;\nBoth of these queries return the same correct result, but the first version using\nWHERE is more efficient because it screens out rows when they are initially\nretrieved by the database engine, while the second version using HAVING takes\neffect only after all the rows have been retrieved and aggregated. This can make a\nbig difference in performance in a large database.\n-\nGroup functions ignore NULL values.\nRemember, however, that COUNT(*) counts rows, not any particular column.\nHence COUNT(*) is sometimes helpful when a particular column of interest\ncontains NULLs. This can lead to different results if you are not careful. For\nexample, the TAX table includes one row with no BLDVAL:\n-\n-\nSELECT *\n-\nFROM TAX\n-\nWHERE BLDVAL IS NULL;\n-\n-\nPARCELID\nPRPTYPE\nLANDVAL\nBLDVAL\nTAX\n-\n-\nN.B.: To find rows with NULLs in them, you must use the syntax \"expr IS NULL\", as\nabove. If you use \"expr = NULL\", the query will run but not return any rows. The other\ncomparison operators (e.g., =, <>, !=, >, <, >=, <=, LIKE) will never match NULL. For\nexample, the query below executes but returns no rows:\n\n----------\n-------------\n---------- ---------------\nSELECT *\nFROM TAX\nWHERE BLDVAL = NULL;\nno rows selected\nIf we count records in the TAX table by row using COUNT(*), we get one result:\nSELECT COUNT(*)\nFROM TAX;\nCOUNT(*)\nbut if we count the building values we get a different one:\nSELECT COUNT(BLDVAL)\nFROM TAX;\nCOUNT(BLDVAL)\nValues of ONUM in the PARCELS table are not unique. That explains why\nCOUNT(ONUM) and COUNT(DISTINCT ONUM) return different results in the\nquery below:\nSELECT COUNT(ONUM) OWNERS,\nCOUNT(DISTINCT ONUM) DISTINCT_OWNERS\nFROM PARCELS;\nOWNERS DISTINCT_OWNERS\nIn the last three queries, we were treating the entire set of rows as a single group\n(i.e., we used a group function such as COUNT without a GROUP BY clause).\nNow let's use a GROUP BY to see if ownership of properties in various land use\ncategories is concentrated among a few owners:\nSELECT LANDUSE,\nCOUNT(*) PARCELS,\nCOUNT(ONUM) OWNERS,\nCOUNT(DISTINCT ONUM) DISTINCT_OWNERS\nFROM PARCELS\nGROUP BY LANDUSE;\n\n--- ---------- ---------- ---------------\nLAN\nPARCELS\nOWNERS DISTINCT_OWNERS\nA\nC\nCL\nCM\nE\nR1\nR2\nR3\n9 rows selected.\nWhich value do we want to use for the count of owners, OWNERS or\nDISTINCT_OWNERS? Why?\nGROUP BY Examples\nFind the parcels that experienced more than one fire:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nGROUP BY PARCELID\nHAVING COUNT(FDATE) > 1\nORDER BY PARCELID;\nList the fires with a loss of at least $40,000:\nSELECT PARCELID, FDATE, ESTLOSS\nFROM FIRES\nWHERE ESTLOSS >= 40000\nORDER BY PARCELID, FDATE, ESTLOSS;\nList the count of fires by parcel, counting only fires with a loss of at least $40,000:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nWHERE ESTLOSS >= 40000\nGROUP BY PARCELID\nORDER BY PARCELID;\nFind the parcels that experienced more than one fire with a loss of at least $40,000:\nSELECT PARCELID, COUNT(FDATE) FIRE_COUNT\nFROM FIRES\nWHERE ESTLOSS >= 40000\nGROUP BY PARCELID\nHAVING COUNT(FDATE) > 1\nORDER BY PARCELID;\n\nIntroducing the URISA PROCEEDINGS database:\n-\nDatabase for URISA Proceedings papers\n-\nRelational tables for Author, Title, Paper, Keyword relationships\n-\nHandling multiple authors and multiple keywords\n-\nHelp pages and sample queries for the URISA database*\nSample SQL Queries using ArcView and the Cambridge SALES89 table\n-\nExample A: Select address, date, realprice columns from sales89\ntable for houses that sold after July 1, 1989 for more than $250,00\nSELECT address, date, realprice\nFROM sales89\nWHERE realprice > 250000 and date > \"07/01/1989\"\n-\nExample B: Count the number of 1989 sales associated with each\naddress that is listed in the sales89 table and order the results by\nsale_count, then, address, and date:\nSELECT address, count(distinct date) sale_count\nFROM sales89\nWHERE realprice > 250000 and date > \"07/01/1989\"\nGROUP BY address, date\nORDER BY count(distinct date), address, date\n-\nExample C: For every sales89 sale in Cambridge, list the address,\nsaledate, and sales price along with the percent of adults in the\nsurrounding census block group who had less than a high school\neducation. The sales89 and cambbgrp tables could be joined by a\ncommon column (if the sales89 table had a column listing the census\nblock group) or by a spatial join (that used the geographic data to\ncompute which block group contained each sale):\nSELECT s.address, s.date, s.realprice,\n100*(c.EDU1 + c.EDU2 / c.EDUTOTAL) low_ed_percent\nFROM cambbgrp c, sales89 s\nWHERE c.stcntrbg = s.stcntrbg\n* Kindly refer to Lecture Notes Section\n\nif the sales89 table included as a 'foreign key' the stcntrbg 'primary key'\nfrom the cambbgrp table, or:\nSELECT s.address, s.date, s.realprice,\n100*(c.EDU1 + c.EDU2 / c.EDUTOTAL) low_ed_percent\nFROM cambbgrp c, sales89 s\nWHERE s.SpatialObject IS CONTAINED WITHIN\nc.SpatialObject"
    },
    {
      "category": "Lecture Notes",
      "title": "lect4.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/dde1442583c4746d07ca7a12bc0f6988_lect4.pdf",
      "content": "Advanced SQL - Subqueries and\nComplex Joins\nOutline for Today:\n-\nThe URISA Proceedings database - more practice with increasingly\ncomplicated SQL queries\n-\nAdvanced Queries:\no Sub-queries: one way to nest or a cascade query is to stick a\nquery in the 'where' clause: e.g., find parcels owned by XXX\nfrom that set of parcels that had a fire. This is a powerful way to\ntake advantage of the fact that any SQL query returns a table -\nwhich can they be the starting point of another SQL query.\no Self-joins: the 'where' clause can become quite complex with\nmany joins and related 'and' and 'or' conditions. But handling 'and'\nconditions is a little tricky. How can you find papers the use both\nkeyword Y and keyword Z if the table relating papers and\nkeywords only shows one pair at a time?\n-\nThe zoning variance database\no Understanding the schema and rationale for the Boston zoning\nvariance database (which we use later to map them as study\nspatial patterns as well as to illustrate concepts about distributed\ndatabases and community empowerment.\no Using the history of zoning database to understand how real\ndatabases evolve over time\nMore URISA database Queries\n-\n...from the URISA database* page\n-\nAdditional notes on SQL*Plus formatting* added to SQL Notes*\nAdvanced Queries: Subqueries\nA subquery can be nested within a query\n* Kindly refer to Lecture Notes section\n\nExample: Find the parcel with the highest estimated loss from a fire\nSELECT *\nFROM FIRES\nWHERE ESTLOSS =\n(SELECT MAX(ESTLOSS)\nFROM FIRES);\nAlternatively, include the subquery as an inline \"table\" in the FROM clause:\nSELECT F.*\nFROM FIRES F,\n(SELECT MAX(ESTLOSS) MAXLOSS\nFROM FIRES) M\nWHERE F.ESTLOSS = M.MAXLOSS;\nExample: Find the parcels that have not had a fire\nSELECT *\nFROM PARCELS\nWHERE PARCELID NOT IN\n(SELECT PARCELID\nFROM FIRES);\nor, more efficiently,\nSELECT *\nFROM PARCELS P\nWHERE NOT EXISTS\n(SELECT NULL\nFROM FIRES F\nWHERE P.PARCELID = F.PARCELID);\nExample: Find the parcels that have not obtained a permit:\nSELECT *\nFROM PARCELS\nWHERE (PID, WPB) NOT IN\n(SELECT PID, WPB\nFROM PERMITS);\nor, more efficiently,\nSELECT *\nFROM PARCELS P\n\nWHERE NOT EXISTS\n(SELECT NULL\nFROM FIRES F\nWHERE P.PARCELID = F.PARCELID);\nAdvanced Queries: Self-Join\nA table can be joined to itself\nExample: Find the paper numbers in the URISA database for papers that use both\nkeyword code 601 AND 602.\nThe following query does not work, because it is not possible for value for a single\ncolumn in a single row to contain two values at the same time:\nSELECT PAPER\nFROM MATCH\nWHERE CODE = 601\nAND CODE = 602;\nThis type of query requires a self-join, which acts as if we had two copies of the MATCH\ntable and are joining them to each other.\nSELECT M1.PAPER\nFROM MATCH M1, MATCH M2\nWHERE M1.PAPER = M2.PAPER\nAND M1.CODE = 601\nAND M2.CODE = 602;\nIf you have trouble imagining the self-join, pretend that we actually created two copies of\nMATCH, M1 and M2:\nCREATE TABLE M1 AS\nSELECT * FROM MATCH;\nCREATE TABLE M2 AS\nSELECT * FROM MATCH;\nThen, we could join M1 and M2:\nSELECT M1.PAPER\nFROM M1, M2\nWHERE M1.PAPER = M2.PAPER\nAND M1.CODE = 601\nAND M2.CODE = 602;\nThe self-join allows us to perform this sort of operation without actually having to copy\nthe table. We can just act as if we had two copies.\n\nNow, let's add the titles to the paper numbers:\nSELECT M1.PAPER, T.TITLE\nFROM MATCH M1, MATCH M2, TITLES T\nWHERE M1.PAPER = M2.PAPER\nAND M1.PAPER = T.PAPER\nAND M1.CODE = 601\nAND M2.CODE = 602;\nExample: Find the time that passed between a fire on a parcel and all fires\noccurring within 300 days later on the same parcel\nSELECT F1.PARCELID, F1.FDATE FIRE1, F2.FDATE\nFIRE2,\nF2.FDATE - F1.FDATE INTERVAL\nFROM FIRES F1, FIRES F2\nWHERE F1.PARCELID = F2.PARCELID\nAND F2.FDATE > F1.FDATE\nAND F2.FDATE <= F1.FDATE + 300;\nNote that a number of days can be added to a date.\nThe Zoning Variance Database\nZoning Variances*\nSchema of ZONING table (and\nlisting of related lookup tables)\nSQL examples using zoning\nvariances *\nAnnotated SQL queries of ZONING\ntable\n1980 Census data (by Boston\nNSA)*\nSchema of 1980 Boston Census data\n(and related lookup tables)\nSchema of Decision, Use, NSA,\nNeighbrhd Lookup Tables*\nSchema of Lookup tables (second\nhalf of Census data web page)\nSub-Neighborhood lookup table* The NSA and NEIGHBRHD tables\n(bottom of Zoning Variance web\npage)\nGrouping zoning applicants via\n'lookup' tables*\nAnnotated SQL queries illustrating\n* Kindly refer to Lecture Notes section\n\nuse of lookup tables to categorize\nownership of properties seeking\nzoning variances. (These topics are\nthe focus of next week's lecture and\nlab #3.)\nZoning Variance Database\nEvolution Chart *\nStages of evolution of the ZONING\nvariance database\n* Kindly refer to Lecture Notes section"
    },
    {
      "category": "Lecture Notes",
      "title": "lect5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/93577f87a3199e27f54e21adf095c70c_lect5.pdf",
      "content": "Distributed Access to Parcel-Level City\nDatabases\nPart A: Introduction to 'Zoning Variance' data base\nDuring the next month, you'll be analyzing, cross-referencing, and mapping a\ndataset created by Clark Broida (MCP, 1987) of some 1800 zoning variances that\nwere requested for Boston properties during a two-year boom-period in the mid\n1980s. The SQL Notes* section of the class web page contains more information\nabout all the databases used in the class. Thus far, we have only referenced one of\nthe zoning variance links - the Zoning Variance data dictionary*. Shortly, we will\nuse another: SQL examples using zoning variances*. Often, the data that we wish\nto study cannot be linked to mappable objects in a straightforward (one-to-one)\nmanner. For example, we may wish to study those zoning variances involving\nvacant land under city control that are proposed for use as housing. Figuring out\nwhich variances are controlled by the city is a database manipulation task in and\nof itself and understanding the neighborhoods proximate to the proposed site\nmight require a side effort - using GIS - to tag each zoning variance with, say, the\ncensus tract that surrounds its location. We want to help you understand - and\ngain some hands-on experience - with relational and spatial database management\ntechniques that can facilitate such multi-stage analyses. Moreover, we want to\nhelp you understand how the architecture of the city's information infrastructure\ncan affect the types of analyses that are possible and the extent to which\ndecentralized access to city data can be an effective empowerment tool.\nPart B: Using lookup tables to merge local data with large, 'read-only' official\ndatabases.\nThe rest of today's lecture focuses on the use of locally-owned 'lookup' tables that can be\nused to interpret and cross-reference large, city-owned datasets that are shared as read-\nonly databases with city agencies and NGOs. Our example uses parcel-level databases of\nland use and ownership - a very detailed data layer that has recently become much more\nstandardized and accessible. To emphasize how often it is necessary to do extensive data\nprocessing before such data can be utilized effectively, we consider the problem of\naddressing the 'spelling errors' in owner names that complicate efforts to determine\nownership patterns from typical parcel databases. For example, there are at least 17\ndifferent spellings of the Boston Redevelopment Authority in the 'owner' field of the\nofficial parcel database for Boston. As the class syllabus indicates, this lecture draws\nheavily on my paper: Ferreira, Joseph Jr., Information Technologies that Change\nRelationships between Low-Income Communities and the Public and Non-profit Agencies\nthat Serve Them. This paper is Chapter 7 of High Technology and Low-Income\n* Kindly refer to Lecture Notes section\n\nCommunities: Prospects for the Positive Use of Advanced Information Technology,\nEdited by Donald A. Schon, Bish Sanyal, and William J. Mitchell, MIT Press, 1997.\nMuch of the lecture explains how one can use local 'lookup' tables and SQL 'update'\nqueries to correct the spelling errors (and construct other ownership groupings). After\nillustrating the techniques, we discus how these methods can provide a useful alternative\nto 'top-down' and 'bottom up' strategies for fixing the spelling errors. In particular, they\nprovide a 'middle-out' alternative that allows decentralized accumulation of useful\nknowledge that can be readily linked to official datasets outside the user's control. Here\nare the queries that we will run* in class and the PowerPoint slides* that outline the\nmethods and ideas in the book chapter.\nDuring next week's lab and homework set #2, you'll use similar methods to categorize the\nowners of the properties in the zoning variance database. A set of notes about these\nqueries is available in the SQL Notes* section of the class web page as this link:\nGrouping zoning applicants via 'lookup' tables*.\n* Kindly refer to Lecture Notes section"
    },
    {
      "category": "Lecture Notes",
      "title": "lect5ppt.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/882d8e7a20b414155a223340365a6140_lect5ppt.pdf",
      "content": ""
    },
    {
      "category": "Lecture Notes",
      "title": "lect5queries.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/6c709491c64ef7c11050fc265d19f2d0_lect5queries.pdf",
      "content": "------------------------------ ----------\n------------------------------ -------- ---------- ---------\nSQL Queries\nUsing lookup tables to merge local data with large,\n'read-only' official databases.\nHere are the queries that we ran in class two days after lecture #5 to study land use and\nownership patterns in the parcel database for Boston. The queries track those in this\npaper: Ferreira, Joseph Jr., \"Information Technologies that Change Relationships\nbetween Low-Income Communities and the Public and Non-profit Agencies that Serve\nThem.\" This paper is Chapter 7 of \"High Technology and Low-Income Communities:\nProspects for the Positive Use of Advanced Information Technology,\" Edited by Donald\nA. Schon, Bish Sanyal, and William J. Mitchell, MIT Press, 1997.\nSELECT owner, count(*) parcels FROM parcel96\nWHERE owner LIKE '%BOSTON%'\nGROUP BY owner HAVING count(*) > 1\nORDER BY count(*) desc;\nOWNER\nPARCELS\nCITY OF BOSTON\nCITY OF BOSTON BY FCL\nBOSTON REDEVELOPMENT AUTH\nBOSTON HOUSING AUTHORITY\nBOSTON KENMORE REALTY CORP\nBOSTON UNIVERSITY TRSTS OF\nCITY OF BOSTON FCL\nBOSTON WHARF CO GPS\nBOSTON REDEVELOPMENTAUTH\nBOSTON REDEVELOPMNT AUTH\nROMAN CATH ARCH BOSTON\nBOSTON REDVLPMNT AUTH\nBOSTON UNIVERSITY TRSTS\nBOSTON HOUSING AUTH\nBOSTON UNIVERSITY TRS OF\nselect owner, count(*) parcels, sum(totalval)/1000 totval_k,\nsum(lotsize)/43560 acres\nfrom parcel96\nwhere owner like '%BOSTON%' and owner like '%UNIV%'\ngroup by owner order by count(*) desc;\nOWNER\nPARCELS\nTOTVAL_K\nACRES\nBOSTON UNIVERSITY TRSTS OF\n85,824\n14.5\n89,008\n32.8\nBOSTON UNIVERSITY TRSTS\nBOSTON UNIVERSITY TRS OF\nBOSTON UNIVERSITY TRST OF\nBOSTON UNIVERSITY\nBOSTON UNIVRSTY TRSTS OF\n29,654\n6.2\n6,847\n2.1\n38,978\n25.6\n18,186\n2.0\n\n------------------------------ ------- ---------- ---------\n------------------------------ ------- ---------- ---------\nBOSTON UNIVERSITY TRST\n3,180\n0.6\nBOSTON UNIV TRUSTEESOF\n1,192\n0.0\nBOSTON UNIVERSITY TRS\n8,547\n2.9\nBOSTON UNIV TRSTS MTGEE\n0.2\nBOSTON UNIVERSITY TS OF\n1,276\n0.2\nBOSTON UNIVERSITY TRUSTEE OF\n4,090\n0.6\nBOSTON UNIV TRST OF MASS\n0.2\nTRUSTEES OF BOSTON UNIV\n0.2\nTRSTS OF BOSTON UNIVERSITY\n2,791\n2.1\nBOSTON UNIVERSKTY TRSTS OF\n0.1\nBOSTON UNIV TRSTS OF\n1,337\n0.2\nTRUSTEES OF BOSTON UNIVERITY\n0.2\nBOSTON UNIVSTY TRST OF\n1,544\n0.1\nBOSTON UNIV TRSTS OF MTGEE\n0.1\nBOSTON UNIVERSITY TRSTS THE\n0.1\nBOSTON UNIVERSITY TRSTS OF.\n0.1\nBOSTON UNIVERSITY TR OF\n1,774\n0.6\nBOSTON UNIV TRUSTEES\n1,800\n0.2\nSELECT owner, count(*) parcels, sum(totalval)/1000 totval_k,\nsum(lotsize)/43560 acres\nFROM parcel96\nWHERE owner LIKE '%BOSTON%' AND\n(owner LIKE '%REDEV%' or owner LIKE '%REDV%')\nGROUP BY OWNER;\nOWNER\nPARCELS\nTOTVAL_K\nACRES\nBOSTON REDEVELOMENT AUTH\n0.2\nBOSTON REDEVELOPMENT\n0.5\nBOSTON REDEVELOPMENT AUTH\n106,863\n123.9\n1BOSTON REDEVELOPMENT AUTHRTY\n0.1\nBOSTON REDEVELOPMENTAUTH\n11.9\nBOSTON REDEVELOPMENTAUTHRTY\n0.1\nBOSTON REDEVELOPMNT AUTH\n32,975\n23.3\nBOSTON REDEVELPMENT AUTH\n1,418\n3.0\nBOSTON REDEVELPMNT AUTH\n5,073\n2.4\nBOSTON REDEVELPOMENT AUTH\n0.2\nBOSTON REDEVLPMNT AUTH\n7,488\n3.2\nBOSTON REDEVLPMNT AUTHOR\n2,955\n3.3\nBOSTON REDEVLPMNT AV\n0.0\nBOSTON REDVLPMNT AUTH\n2,472\n7.8\nBOSTON REDVLPMNT AUTHOR\n3,416\n1.8\nBOSTON REDVLPMNT AUTHORITY\n1,095\n0.5\nBOSTON REDVLPMNT CORP\n0.1\nPARCELS\nTOTVAL_K\nACRES\nBOSTON REDEVELOPMENT AUTH\n164,991\n182.3\nCREATE TABLE blookup\nSTORAGE (initial 1M NEXT 250K PCTincrease 50 MAXEXTENTS 500)\nAS\nSELECT DISTINCT owner, owner fix_owner\nFROM parcel96;\n\n----------\n----------\n------------------------------ ------------------------------\nSELECT count(*) FROM blookup;\nCOUNT(*)\nSELECT count(*) from parcel96;\nCOUNT(*)\nSELECT * FROM BLOOKUP\nWHERE owner LIKE '%BOSTON%' AND\n(owner LIKE '%REDEV%' or owner LIKE '%REDV%');\nOWNER\nFIX_OWNER\nBOSTON REDEVELOMENT AUTH\nBOSTON REDEVELOPMENT\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTHRTY\nBOSTON REDEVELOPMENTAUTH\nBOSTON REDEVELOPMENTAUTHRTY\nBOSTON REDEVELOPMNT AUTH\nBOSTON REDEVELPMENT AUTH\nBOSTON REDEVELPMNT AUTH\nBOSTON REDEVELPOMENT AUTH\nBOSTON REDEVLPMNT AUTH\nBOSTON REDEVLPMNT AUTHOR\nBOSTON REDEVLPMNT AV\nBOSTON REDVLPMNT AUTH\nBOSTON REDVLPMNT AUTHOR\nBOSTON REDVLPMNT AUTHORITY\nBOSTON REDVLPMNT CORP\n17 rows selected.\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nBOSTON REDEVELOPMENT AUTH\nSELECT owner, count(*) parcels FROM parcel96\nWHERE owner LIKE '%BOSTON%'\nGROUP BY owner HAVING count(*) > 1\nORDER BY count(*) desc;\n/* Here's the one example that we used in class to illustrate\nthe use of a UPDATE statement to enforce a 'rule' that\nwe construct to make some spelling corrections. By\nsaving these update statements, we can accumulate useful\nand re-usable 'knowledge' about how to categorize the\nparcel owners.\n*/\nupdate blookup set fix_owner = 'BOSTON REDEVELOPMENT AUTH'\nWHERE owner LIKE '%BOSTON%' AND\n(owner LIKE '%REDEV%' or owner LIKE '%REDV%');\n17 rows updated.\ncreate index p96owner on blookup(owner);\nOnce we have created an index (to speed the table join),\n\n------------------------------ ----------\nwe can use this query to re-group the parcels owned by\nthe various BRA spellings so the earlier list of multi-parcel\nowners reflects the change categorization:\nSELECT fix_owner, count(*) parcels\nFROM parcel96 p, blookup b\nWHERE p.owner = b.owner\nand p.owner LIKE '%BOSTON%'\nGROUP BY fix_owner HAVING count(*) > 1\nORDER BY count(*) desc;\nFIX_OWNER\nPARCELS\nCITY OF BOSTON\nCITY OF BOSTON BY FCL\nBOSTON REDEVELOPMENT AUTH\nBOSTON HOUSING AUTHORITY\nBOSTON KENMORE REALTY CORP\nBOSTON UNIVERSITY TRSTS OF\nCITY OF BOSTON FCL\nBOSTON WHARF CO GPS\nROMAN CATH ARCH BOSTON\nBOSTON UNIVERSITY TRSTS\nBOSTON HOUSING AUTH\n...\n133 rows selected."
    },
    {
      "category": "Lecture Notes",
      "title": "lect6.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/e1a561117cae28678fdd9ba027b481f2_lect6.pdf",
      "content": "The Zoning Variance Database & More\nAdvanced\nSQL Query Construction Techniques\nOutline\n-\nThe Zoning Variance Database\n-\nMore About Queries (SELECT Statements)\no Review: SELECT Statement Syntax\no Ordering Rows Returned by a Query\no Order of Operations with 'AND' and 'OR'\no SELECT DISTINCT\no Cartesian Products\no Null Values\no Outer Joins\no Inner vs. Outer Joins with GROUP BY\n-\nViews and Other Table-Like Database Objects\n-\nThe Data Dictionary\n-\nData Manipulation Language\no INSERT: Add Rows to a Table\no DELETE: Delete Rows from a Table\no UPDATE: Modify Data in a Table\n-\nTransaction Control\n-\nData Definition Language\no Create and Drop Objects\no Access Privileges for Objects\n-\nSQL Query Construction Techniques\no Method 1: Creating Intermediate Tables\no Method 2: Use a View Instead of a Table\no Method 3: Use a Subquery\no Method 4: Use a More Efficient Subquery\n\nThe Zoning Variance Database\nZoning Variances*\nSchema of ZONING table (and listing of\nrelated lookup tables)\n1980 Census data (by\nBoston NSA)*\nSchema of 1980 Boston Census data (and\nrelated lookup tables)\nSchema of Decision, Use,\nNSA, Neighbrhd Lookup\nTables*\nSchema of Lookup tables (second half of\nCensus data web page)\nSub-Neighborhood lookup\ntable*\nThe NSA and NEIGHBRHD tables\n(bottom of Zoning Variance web page)\nSQL examples using\nzoning variances*\nAnnotated SQL queries of ZONING table\nGrouping zoning\napplicants via 'lookup'\ntables*\nAnnotated SQL queries illustrating use of\nlookup tables to categorize ownership of\nproperties seeking zoning variances\nZoning Variance Database\nEvolution Chart*\nStages of evolution of the ZONING\nvariance database\nMore About Queries (SELECT\nStatements)\nReview: SELECT Statement Syntax\nBasic Syntax :\nSELECT expr1, expr2, expr3, ...\nFROM object1, object2, ...\nWHERE conditions\nGROUP BY expr4, expr5, expr6, ...\nHAVING conditions\nORDER BY expr7, expr8, expr9, ...\nNote that the order of the clauses matters! The clauses, if included, must appear in the\norder shown! Oracle will report an error if you make a mistake, but the error message\n(e.g., \"ORA-00933: SQL command not properly ended\") may not be very informative.\n* Kindly refer to Lecture Notes section\n\n---------- --- ----------\nOrdering Rows Returned by a Query\nFirst of all, almost every SQL statement you write should specify the way the rows will\nbe sorted. That means you should include an ORDER BY clause in nearly every SQL\nSELECT statement. While examples are in the notes, we haven't emphasized how to sort\nin descending order. For this you can use the 'DESC' keyword after the expression you\nwant to sort that way. (SQL also has an 'ASC' keyword for ascending order. Since it is the\ndefault, it can be omitted.)\nThe syntax looks like this:\nSELECT ...\nORDER BY expr1 [ [ ASC | DESC ] , expr2 [ ASC |\nDESC ] ... ]\nFor example, let's sort the parcels by land use in ascending order and the square footage\nin descending order:\nSELECT parcelid, landuse, sqft\nFROM parcels\nORDER BY landuse ASC, sqft DESC;\nPARCELID LAN\nSQFT\n7 A\n14 A\n16 A\n18 A\n11 C\n2 C\n19 C\n8 C\n1 C\n4 CL\n6 CM\n20 E\n5 E\n9 R1\n17 R1\n13 R2\n3 R3\n12 R3\n\n---------- --- ----------\n---------- --- ----------\n20 rows selected.\nNotice that the query can mix the ASC and DESC keywords in a single ORDER BY\nclause.\nOrder of Operations with 'AND' and 'OR'\nThe Boolean operators 'AND' and 'OR' can do unexpected things when you combine\nthem in a query and you're not careful. Suppose we want to find parcels that have a\nsquare footage of 5300 or 10000, and, of those, find the ones with land use code 'A'.\nWe might (incorrectly) write a query like this:\nSELECT parcelid, landuse, sqft\nFROM parcels\nWHERE sqft = 5300\nOR sqft = 10000\nAND landuse = 'A'\nORDER BY landuse ASC, sqft DESC;\nPARCELID LAN\nSQFT\n14 A\n12 R3\nNotice that it returned a row with LANDUSE = 'R3'. That's not what we wanted! The\nproblem is that the 'AND' and 'OR' operators, when mixed, are not processed in the\nsequence written, but rather follow an order of operations much as in algebra\n(exponentation before everything, then multiplication and division before addition and\nsubtraction). In Boolean logic, 'AND' is like multiplication and 'OR' is like addition, and\nOracle orders their processing accordingly. Hence, the query above is actually equivalent\nto this one:\nSELECT parcelid, landuse, sqft\nFROM parcels\nWHERE sqft = 5300\nOR (\nsqft = 10000\nAND landuse = 'A')\nORDER BY landuse ASC, sqft DESC;\nPARCELID LAN\nSQFT\n14 A\n12 R3\n\n---------- --- ----------\n----------\n----------\nSince the order of operations can surprise you at inconvenient times, you should always\nuse parentheses to force the correct order whenever you mix 'AND' and 'OR' in a\nWHERE clause. Here is the correct way to write the query:\nSELECT parcelid, landuse, sqft\nFROM parcels\nWHERE (\nSQFT = 10000\nOR SQFT = 5300)\nAND LANDUSE = 'A'\nORDER BY landuse ASC, sqft DESC;\nPARCELID LAN\nSQFT\n14 A\nSELECT DISTINCT\nNormally, a query may return duplicate rows. For example, if we query the FIRES table\nto list the parcels that had fires, we'll find that the parcels that had more than one fire\n(parcels 2 and 3) show up multiple times:\nSELECT parcelid\nFROM fires\nORDER BY parcelid;\nPARCELID\n6 rows selected.\nIf we don't want to see the duplicates, we can add the keyword DISTINCT right after\nSELECT:\nSELECT DISTINCT parcelid\nFROM fires\nORDER BY parcelid;\nPARCELID\n4 rows selected.\n\n---------- -----------------------\n---------- --------------- ----------\nNow parcels 2 and 3 show up only once. You only use the DISTINCT once, right after\nSELECT, to apply to the entire row. You do not apply it to each column. Hence, this\nquery is valid:\nSELECT DISTINCT p.onum, o.oname\nFROM parcels p, owners o\nWHERE p.onum = o.ownernum\nORDER BY p.onum;\nONUM ONAME\n9 PATRICK KING\n10 METHUINON TRUST\n11 FERNANDO MARTINEZ\n18 JOHN MCCORMACK\n29 FRANK O'BRIEN\n32 GERALD RAPPAPORT\n38 BAY STATE, INC.\n55 THOMAS KELLIHER\n89 JOSEPH NOONAN\n100 MGH, INC.\n200 VANDELAY INDUSTRIES\n11 rows selected.\nHowever, the following incorrect query, with two DISTINCT keywords, generates the\ncryptic error message \"ORA-00936: missing expression\":\nSELECT DISTINCT p.onum, DISTINCT o.oname\nFROM parcels p, owners o\nWHERE p.onum = o.ownernum\nORDER BY p.onum;\nNote also that you can use DISTINCT with the group functions (e.g., COUNT, AVG,\nSTDDEV) to get these functions to consider only distinct values within a group:\nSELECT COUNT(wpb) wpb_ct,\nCOUNT(DISTINCT wpb) wpb_ct_distinct,\nCOUNT(*) row_ct\nFROM parcels;\nWPB_CT WPB_CT_DISTINCT\nROW_CT\n1 row selected.\nFinally, note that COUNT(DISTINCT *) does not work. This makes sense if you think\nabout it. Why do you think this is the case?\nCartesian Products\nWhat's wrong with this query?\nSELECT p.parcelid, p.onum, o.ownernum, o.oname\nFROM parcels p, owners o;\nThis query returns 200 rows!\n\nThere are only 20 rows in PARCEL and 10 rows in OWNERS, so what's going on? The\nproblem here is that this query has no WHERE clause that specifies how the PARCEL\ntable relates to the OWNERS table. Without this information, Oracle does not know how\nto match a row in PARCEL to a corresponding row in OWNERS. What does it do\ninstead? It matches every row in PARCEL to every row in OWNERS. Hence, we end up\nwith:\n(20 rows in PARCEL) matched to (10 rows in OWNERS) = 20 x 10 = 200 rows\nreturned\nThis kind of unconstrained join is called a Cartesian product. This result is desirable only\nunder rare circumstances. If you have queries that are returning a suspiciously large\nnumber of rows, you have probably unwittingly requested a Cartesian product. Note that\nfor tables of even modest size, the number of rows returned by a Cartesian product can be\nexplosive. If you generate a Cartesian product of one table with 1,000 rows with another\ntable with 2,000 rows, your query will return 1,000 x 2,000 = 2,000,000 rows! That's\nright--two million rows! Hence, you should very careful to avoid unintentional Cartesian\nproducts.\nTo fix this query, we need to specify how the owner numbers stored in the PARCEL\ntable should be matched to owner numbers in the OWNERS table. In PARCEL, the\nowner numbers are stored in ONUM, while in OWNERS they are stored in\nOWNERNUM. Here is the repaired query with the appropriate join condition in the\nWHERE clause:\nSELECT p.parcelid, p.onum, o.ownernum, o.oname\nFROM parcels p, owners o\nWHERE p.onum = o.ownernum;\nThis query returns 20 rows, which is definitely an improvement.\nNote that a Cartesian product can easily be hidden in a query that requires multiple joins.\nSuppose we want to find all the papers, with associated keywords, written by authors\nwith the last name WALKER. We could try this query:\nCOLUMN keyword FORMAT A20 TRUNC\nCOLUMN title\nFORMAT A25 TRUNC\nSELECT a.lastname, a.fnamemi, k.keyword, t.title\nFROM keywords k, match m, titles t, authors a\nWHERE m.code = k.code\nAND t.paper = a.paper\nAND a.lastname = 'WALKER'\nORDER BY a.lastname, a.fnamemi, k.keyword, t.title;\n\nThis query returns a whopping 6174 rows! What's wrong? All of the tables appear to be\ninvolved in a join condition. The problem is that while the MATCH and KEYWORDS\ntables are tied together, and the TITLES and AUTHORS tables are linked to each other,\nnothing links these two sets of tables together. Adding another join condition fixes it:\nSELECT a.lastname, a.fnamemi, k.keyword, t.title\nFROM keywords k, match m, titles t, authors a\nWHERE m.code = k.code\nAND t.paper = a.paper\nAND m.paper = t.paper\nAND a.lastname = 'WALKER'\nORDER BY a.lastname, a.fnamemi, k.keyword, t.title;\nThis query returns a much more reasonable 14 rows. Note that we could have also\nspecified \"m.paper = a.paper\" and it would have worked too. Why?\nA Cartesian product can easily be hidden by a GROUP BY, since it will aggregate all the\nspurious rows, and you will not see the rows that made up the groups. Here's a variation\non the earlier, broken example, now with a GROUP BY:\nSELECT a.lastname, a.fnamemi, count(k.keyword)\nkeywords, count(t.title) titles\nFROM keywords k, match m, titles t, authors a\nWHERE m.code = k.code\nAND t.paper = a.paper\nAND a.lastname = 'WALKER'\nGROUP BY a.lastname, a.fnamemi\nORDER BY a.lastname, a.fnamemi;\nBecause this query returns only counts, it's not obvious that the query is defective--unless\nyou have an idea about what results are reasonable! Always scrutinize your results!\nNULL Values\nNULL is a special value that means \"missing\" or \"unknown.\" It can be placed in a\ncolumn of any type, unless the column has been declared NOT NULL, in which case\nNULL values are forbidden. A NULL is not the same as zero or any other value.\nSpecial rules apply when NULL values are involved:\n-\nA row containing NULL value in a column will never match another row in a\njoin, not even another one containing NULL.\n\n-\nRemember that in logical conditions (e.g., col1 = col2, col3 > col4, col5 < 0),\nNULL does not equal NULL; logical expressions containing NULL will always\nevaluate to UNKNOWN, which is similar (but not identical) to FALSE.\n-\nNever use NULL with one of the Boolean operators (col1 = NULL, col2 <>\nNULL, col3 < NULL, col4 <= NULL, col5 > NULL, col6 >= NULL). All of\nthese will probably not perform as intended. Always use the IS operator when\ntesting for NULL (col7 IS NULL, col8 IS NOT NULL).\n-\nGroup functions on a column ignore NULL values.\nFor more information on NULL values and how Oracle treats them, consult the Oracle\ndocumentation on NULL.\nOuter Joins\nTake a look at this query:\nSELECT p.parcelid, f.fdate\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid\nORDER BY p.parcelid, f.fdate;\nThe query above returned 6 rows, but there are 20 parcels. Fourteen parcels seem to be\nmissing. Where did they go? The answer is that Oracle will only list the parcels that\noccur in both tables, PARCELS and FIRES.\nHow do we get around this problem if we want to see all 20 rows in the parcel table,\nwhether they match a record in FIRES or not? The answer is an outer join. The standard\njoin is also known as an \"inner join,\" meaning that the default behavior of not matching\nNULL values occurs. In an outer join, we explicitly tell Oracle that we want it to display\nNULL values that would otherwise be excluded by adding the (+) outer join operator to\neach column in the WHERE clause where the additional NULLs should appear.\nSELECT p.parcelid, f.fdate\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid (+)\nORDER BY p.parcelid, f.fdate;\nNote that the position of the outer join operator (+) is significant! This query will run but\nreturn a different result:\nSELECT p.parcelid, f.fdate\nFROM parcels p, fires f\nWHERE p.parcelid (+) = f.parcelid\nORDER BY p.parcelid, f.fdate;\n\nSome additional class notes on outer joins* are available. If you wish, you can peruse the\nOracle 8i documentation on outer joins.\nInner vs. Outer Joins with GROUP BY\nList all the parcels that had a fire, including the address and date of the fire (this\nrequires an inner join):\nSELECT p.parcelid, p.add1, p.add2, f.fdate\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid\nORDER BY p.parcelid, f.fdate;\nRepeat the same query, except list all the parcels, whether they had a fire or not\n(this requires an outer join):\nSELECT p.parcelid, p.add1, p.add2, f.fdate\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid (+)\nORDER BY p.parcelid, f.fdate;\nList the count of fires for the parcels that had a fire (this requires an inner join with\ngrouping):\nSELECT p.parcelid, COUNT(fdate) fire_count\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid\nGROUP BY P.PARCELID\nORDER BY COUNT(fdate) DESC, p.parcelid;\nNote that the query above lists the parcels in descending order of the count of fires. When\nspecifying a group function or other expression in the ORDER BY clause, you must use\nthe full expression, even if you defined a column alias for it in the SELECT list. In this\ncase, we must use COUNT(FDATE) rather than FIRE_COUNT in the ORDER BY\nclause. The DESC keyword after COUNT(FDATE) indicates that we want the fire counts\nshown in descending order, rather than the default ascending order. You need to apply the\nDESC keyword to every expression in the ORDER BY clause that you want in\ndescending order.\nList the count of fires for all parcels, whether it experienced a fire or not (this\nrequires an outer join with grouping):\nSELECT p.parcelid, COUNT(fdate) fire_count\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid (+)\nGROUP BY p.parcelid\nORDER BY COUNT(fdate) DESC, p.parcelid;\n* Kindly refer to Lecture Notes section\n\nNote that the query above uses an outer join on the FIRES table -- indicated by the outer\njoin symbol (+) -- to include the parcels that are not listed in the FIRES table in the count.\nThe outer join symbol indicates where a NULL should replace a real value if none is\navailable in the table. Note that we need to use the outer join symbol with both columns\nin FIRES that we are joining with PARCEL.\nThe query below runs but returns the wrong result--some parcels that had no fires show\nup with one fire in the count. Why?\nSELECT p.parcelid, COUNT(*) bogus_fire_count\nFROM parcels p, fires f\nWHERE p.parcelid = f.parcelid (+)\nGROUP BY p.parcelid\nORDER BY COUNT(*) DESC, p.parcelid;\nViews and Other Table-Like Database\nObjects\n-\nViews\n-\nSynonyms\nA synonym is simply a second name for an existing object. These are particular\nconvenient when a table is owned by another user (or, stated differently, stored in\na different schema). You have been using synonyms all along for the objects in\nthe PARCELS, URISA, and ZONING databases. To see the synonyms, use this\nquery:\nSELECT synonym_name, table_owner, table_name\nFROM user_synonyms\nORDER BY synonym_name;\n-\nOthers (use this link to find a discussion of most of the Oracle 8i schema objects)\nViews are the most useful of these alternate object types for our purposes. A view is a\nquery that is stored in the database, then treated like a table. Unlike a table you create\nusing CREATE TABLE ... AS SELECT, which creates a one-time snapshot of the data\nreturned by the query, a view will reflect the current state of the tables in the underlying\nquery. Hence, if the tables in the database are changing over time, the same query on a\nview may return different results at different times. Creating a view is similar to the\nCREATE TABLE ... AS SELECT statement; instead, use CREATE VIEW ... AS\nSELECT. For example:\nCREATE VIEW parcel_owners\n\n---------------------------\nAS SELECT p.parcelid, o.oname, P.ADD1, P.ADD2,\nP.ZIP\nFROM parcels p, owners o\nWHERE p.onum = o.ownernum(+);\nCREATE VIEW owner_sqft\nAS SELECT o.oname, SUM(SQFT) TOTAL_SQFT\nFROM parcels p, owners o\nWHERE p.onum = o.ownernum\nGROUP BY o.oname;\nNote that the column alias TOTAL_SQFT in the example above is required because\nOracle needs to know what to name the column in the view. Do not include an ORDER\nBY clause in the SELECT statement that you use to create the view.\nOnce the view is created, it can be treated for (almost) all intents and purposes as a true\ntable. You can describe them to see their structure:\nDESCRIBE parcel_owners\nDESCRIBE owner_sqft\nThe Data Dictionary\nInformation describing all the Oracle objects in the database is stored in the Oracle data\ndictionary, which you can access through a large number of data dictionary views. We\ncan query data dictionary views just like any view or table. You're already familiar with\nthe view CAT which provides you with a catalog of objects that you own:\nSELECT * FROM cat;\nMany other such views are available. The USER_SYNONYMS view mentioned above is\none of them. The data dictionary view USER_VIEWS includes information about the\nviews we just created. To see its structure, we can use the DESCRIBE statement in\nSQL*Plus:\nSQL> DESCRIBE user_views\nName\nNull?\nType\n----------------------------------------- -------- -\nVIEW_NAME\nNOT NULL\nVARCHAR2(30)\nTEXT_LENGTH\nNUMBER\nTEXT\nLONG\n\nTYPE_TEXT_LENGTH\nNUMBER\nTYPE_TEXT\nVARCHAR2(4000)\nOID_TEXT_LENGTH\nNUMBER\nOID_TEXT\nVARCHAR2(4000)\nVIEW_TYPE_OWNER\nVARCHAR2(30)\nVIEW_TYPE\nVARCHAR2(30)\nTo see the definition of the views we just created, we can use the following statements:\nSET LONG 5000\nSELECT view_name, text\nFROM user_views\nWHERE view_name IN ('PARCEL_OWNERS', 'OWNER_SQFT');\nNote that the column TEXT has type \"LONG\". In order to ensure that SQL*Plus displays\nthis LONG column properly, we used the \"SET LONG 5000\" statement before running\nthe query on USER_VIEWS.\nData Manipulation Language\nSELECT statements view or query the contents of tables. With Data Manipulation\nLanguage (DML) statements, we can alter the contents of the tables. DML statements\ninclude:\n-\nINSERT\n-\nDELETE\n-\nUPDATE\nINSERT: Add Rows to a Table\nGeneral syntax:\nINSERT INTO table1 (col1, col2, ...)\nVALUES (value1, value2, ...)\nor\nINSERT INTO table1 (col1, col2, ...)\n\nSELECT ...\nExample: Add a row to the FIRES table\nINSERT\nINTO fires (parcelid, fdate, ignfactor,\nestloss)\nVALUES (12, '17-JAN-96', 2, 35000)\nDELETE: Delete Rows from a Table\nGeneral syntax:\nDELETE\nFROM table1\nWHERE conditions;\nExample: Delete fires with losses less than $50000 from the database\nDELETE\nFROM fires\nWHERE estloss < 50000;\nUPDATE: Modify Data in a Table\nGeneral syntax:\nUPDATE table1\nSET col1 = value1, col2 = value2, ...\nWHERE conditions;\nor\nUPDATE table1\nSET col1 =\n(SELECT ...)\nWHERE conditions;\nExample: Change the building value of a particular parcel\nUPDATE tax\nSET bldval = 200000\nWHERE parcelid = 11;\nNote: You can also update a table using a subquery. This typically involves one or more\ncorrelated subqueries (see these examples). Correlated subqueries are beyond this\noverview.\n\nTransaction Control\nTransaction control statements allow several SQL statements to be grouped together into\na unit (a transaction) that are either processed or rejected as a whole. These statements\ninclude:\n-\nCOMMIT: makes permanent all changes since the start of the session or the\nprevious COMMIT\n-\nROLLBACK: reverses pending changes to the database\n-\nSAVEPOINT: allows more refined control over COMMITs and ROLLBACKs\n-\nSET TRANSACTION: allows more refined control over transaction progress\nData Definition Language\nData Definition Language (DDL) statements affect the structure and security provisions\nof the database, among other things.\nCreate and Drop Objects\nCreate new objects\nCREATE TABLE table1 ... ;\nCREATE VIEW view1 ... ;\nCREATE INDEX index1 ON table1 (col1, ... );\nDrop objects permanently\nDROP TABLE table1;\nDROP VIEW view1;\nDROP INDEX index1;\nModify existing objects\nALTER TABLE table1;\nALTER VIEW view1;\nALTER INDEX index1;\n\nAccess Privileges for Objects\nSpecific privileges on tables can be given to individual users\nGRANT SELECT\nON table1\nTO user1;\nGRANT SELECT, INSERT, UPDATE (col1)\nON table1\nTO user1\nWITH GRANT OPTION;\nPrivileges can be revoked\nREVOKE ALL\nON table1\nFROM user1;\nSQL Query Construction Techniques:\nBuilding the Answer to a Complex Question\nMethod 1: Creating Intermediate Tables\nIn previous years, the introductory exercises encouraged creating temporary tables as\nshown here. We now deprecate that practice in favor of creating views, especially when\ntrying to build a simple query into a more complex one. In some cases, however, creating\nyour own tables makes sense. One example is the solution to the problems with the\nproperty owners' names in the real-world parcel database.\nAdapted from Joe's URISA database examples*:\n/* Find papers using keywords related to GIS and\nmapping: */\nDROP TABLE gispapers;\nDROP VIEW gispapers;\nCREATE TABLE gispapers AS\nSELECT m.code, keyword, m.paper\n* Kindly refer to Lecture Notes section\n\nFROM keywords k, match m\nWHERE m.code = k.code\nAND(\nkeyword LIKE '%GIS%'\nOR keyword LIKE '%GEOGRAPHIC\nINFORMATION%'\nOR keyword LIKE '%MAPPING%');\n/* Counts of papers using these keywords */\nSELECT m.code, k.keyword, count(distinct\nt.paper) papers\nFROM match m, titles t, keywords k\nWHERE m.paper = t.paper AND k.code = m.code\nAND m.code IN\n(SELECT code\nFROM gispapers)\nGROUP BY m.code, k.keyword\nORDER BY m.code;\nMethod 2: Use a View Instead of a Table\nWe can create a view instead of a table using the identical SELECT statement, but\nsubstituting 'CREATE VIEW' for 'CREATE TABLE' in the example above. We have to\ndrop the table first because a table and a view may not have the same name.\n/* Find papers using keywords related to GIS and\nmapping: */\nDROP TABLE gispapers;\nCREATE VIEW gispapers\nAS SELECT m.code, keyword, m.paper\nFROM keywords k, match m\nWHERE m.code = k.code\nAND (\nkeyword LIKE '%GIS%'\nOR keyword LIKE '%GEOGRAPHIC\nINFORMATION%'\nOR keyword LIKE '%MAPPING%');\n/* Counts of papers using these keywords */\nSELECT m.code, k.keyword, count(distinct\nt.paper) papers\nFROM match m, titles t, keywords\n\nWHERE m.paper = t.paper AND k.code = m.code\nAND m.code IN\n(\nSELECT code\nFROM gispapers)\nGROUP BY m.code, k.keyword\nORDER BY m.code;\nNote that we can query from the view implementation of GISPAPERS the same as from\nthe table implementation. A view, however, is simply a stored query (which retains its\nties to the original table), while the table copies the data (and possibly wastes a lot of\nspace in the database). We can look at the text of the view with the following query\nagainst the Oracle data dictionary:\n-- Use SET LONG 5000 so that SQL*Plus will\ndisplay enough characters\n-- from the view definition column for us to see\nthe entire query.\nSET LONG 5000\nSELECT text\nFROM user_views\nWHERE view_name = 'GISPAPERS';\nNote that the name of the view must be in UPPERCASE letters and surrounded by 'single\nquotation marks'.\nMethod 3: Use a Subquery\nA view is just a stored query. We can embed this query in our original SQL statement so\nthat we can accomplish the entire task with one statement. The subquery below is the\nsame as the query in the CREATE TABLE and CREATE VIEW statements, except that\nthe columns keyword and m.paper have been removed because they are not needed in the\nsubquery. (If you included them, you would see the Oracle error \"ORA-00913: too many\nvalues\".)\nSELECT m.code, k.keyword, count(distinct\nt.paper) papers\nFROM match m, titles t, keywords k\nWHERE m.paper = t.paper AND k.code = m.code\nAND m.code IN\n(SELECT m.code\nFROM keywords k, match m\nWHERE m.code = k.code\nkeyword LIKE '%GIS%'\nAND (\nOR keyword LIKE\n'%GEOGRAPHIC INFORMATION%'\nOR keyword LIKE '%MAPPING%'\n\n)\n)\nGROUP BY m.code, k.keyword\nORDER BY m.code;\nMethod 4: Use a More Efficient Subquery\nThe query above works, but is not as fast as it could be because Oracle may be returning\nmany more rows in the subquery than needed. We can rewrite this query using the more\nefficient but less obvious EXISTS syntax.\nSELECT m.code, k1.keyword, count(distinct\nt.paper) papers\nFROM match m, titles t, keywords k1\nWHERE m.paper = t.paper\nAND k1.code = m.code\nAND EXISTS\n(SELECT NULL\nFROM keywords k2\nWHERE m.code = k2.code\nkeyword LIKE '%GIS%'\nAND (\nOR keyword LIKE '%GEOGRAPHIC\nINFORMATION%'\nOR keyword LIKE '%MAPPING%'))\nGROUP BY m.code, k1.keyword\nORDER BY m.code;\nNote that we use NULL in the subquery's SELECT list to indicate that we do not care\nabout the contents returned by the subquery, but only if the subquery returns a row or not\neach time it is executed (once for each candidate row in the outer query)."
    },
    {
      "category": "Lecture Notes",
      "title": "lect7.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/a69668cb3f76aeb74b005dbbaa446d09_lect7.pdf",
      "content": "Referential Integrity and Relational\nDatabase Design\nOutline\nCorrelated Updates - examples of UPDATEs only for SELECTed rows\nReview: The Relational Model\nReview: Qualities of a Good Database Design\nReview: Introduction to Entity-Relationship Modeling\nReview: E-R Modeling Process\nReview: From E-R Model to Database Design\nDatabase Design Example\nDatabase Normalization\nReview: Database Design Rules of Thumb\nEnforcing Referential Integrity in Oracle\nExample: The Parcels Database\nParcels Database Enhancements\nReview: The Relational Model\n-\nAll data are represented as tables (relations)\n-\nTables are comprised of rows and columns (tuples)\n-\nRows are (officially) unordered (i.e., the order in which rows are referenced does\nnot matter)\n-\nA proper relational table contains no duplicate rows.\n-\nEach table has a primary key, a unique identifier constructed from one or more\ncolumns\n-\nMost primary keys are a single column (e.g., OWNERNUM for OWNERS)\n-\nA table is linked to another by including the other table's primary key. Such an\nincluded column is called a foreign key\nReview: Qualities of a Good Database Design\n-\nReflects real-world structure of the problem\n-\nCan represent all expected data over time\n-\nAvoids redundant storage of data items\n-\nProvides efficient access to data\n-\nSupports the maintenance of data integrity over time\n\n-\nClean, consistent, and easy to understand\n-\nNote: These objectives are sometimes contradictory!\nReview: Introduction to Entity-Relationship Modeling\n-\nEntity-Relationship (E-R) Modeling: A method for designing databases\n-\nA simplified version is presented here\n-\nRepresents the data by entities that have attributes.\n-\nAn entity is a class of distinct identifiable objects or concepts\n-\nEntities have relationships with one another\n-\nResult of the process is a normalized database that facilitates access and avoids\nduplicate data\nReview: E-R Modeling Process\n-\nIdentify the entities that your database must represent\n-\nDetermine the cardinality relationships among the entities and classify them as\none of\no One-to-one (e.g., a parcel has one address)\no One-to-many (e.g., a parcel may be involved in many fires)\no Many-to-many (e.g., parcel sales: a parcel may be sold by many owners,\nand an individual owner may sell many parcels)\n-\nDraw the entity-relationship diagram\n-\nDetermine the attributes of each entity\n-\nDefine the (unique) primary key of each entity\nReview: From E-R Model to Database Design\n-\nEntities with one-to-one relationships should be merged into a single entity\n-\nEach remaining entity is modeled by a table with a primary key and attributes,\nsome of which may be foreign keys\n-\nOne-to-many relationships are modeled by a foreign key attribute in the table\nrepresenting entity on the \"many\" side of the relationship (e.g., the FIRES table\nhas a foreign key that refers to the PARCELS table)\n-\nMany-to-many relationships among two entities are modeled by a third table that\nhas foreign keys that refer to the entities. These foreign keys should be included\nin the relationship table's primary key, if appropriate\n-\nCommercially available tools can automate the process of converting a E-R model\nto a database schema\nDatabase Design Example (from old exercise in 11.208)\nCambridge Fire Department Database\n\n*\n-\nProblem Statement\n-\nProposed Solution*\nDatabase Normalization\nMuch of formal database design is focused on normalizing the database and ensuring\nthat design conforms to a level of normalization (e.g., first normal form, second normal\nform, etc.). Although there are higher normal forms, Third Normal Form is generally\nconsidered good enough for typical applications. Normalization generally involves taking\na design with fewer tables and fewer columns and transforming it into a design with more\ntables with more columns -- after conducting some tests and applying some rules. A good\nreference on first through third normal forms, with nice examples, can be found here:\n-\nDavid Faour's \"Database Normalization\" at swynk.com\nOther Database Normalization References:\n-\nWeb Developer's Virtual Library\n-\nStuart Graduate School of Business\n-\nMicrosoft Product Support Services\n-\nPHPBuilder.com\n-\nAbout.com\n-\nSQL Server Magazine\n-\nDatabasics at geekgirls.com\nReview: Database Design Rules of Thumb\n-\nKeep data items atomic (e.g., first and last names are separate). Concatenating\ncolumns together later on-the-fly is generally easy, but separating them is not.\n(First Normal Form)\no What is an example of where parsing subfields from a column may go\nawry?\no When might you want to include the combined fields in a column anyway?\n-\nDefine the primary key first. Use a descriptive name (PARCELID, not ID)\n-\nIn fact, use descriptive names that give a new user a decent chance of guessing\nwhat they mean for all your columns! (E.g., use PARCEL_COUNT rather than\nPACT)\n-\nUse a single column for the primary key whenever possible; multi-column\nprimary keys are appropriate for many-to-many relationships\n-\nUse lookup tables rather than storing long values\n-\nUse numeric keys whenever possible (What about ZIP codes?)\n-\nAvoid intelligent keys (exception: lookup tables)\n* Kindly refer to the Lecture Notes section\n\n-\nAvoid using multiple columns to represent a one-to-many relationship (e.g.,\ncolumns such as CHILD1, CHILD2 in a table called PARENT rather than putting\nthe children in a separate table. (First Normal Form)\n-\nFor readability, use the primary key name for foreign keys unless the same\nforeign key is used multiple times in the same table (e.g., state of work and state\nof residence for a person might both be foreign keys that reference a table of\nstates)\n-\nDo not include two columns whose values are linked together (e.g., county name\nand county ID) unless one of the columns is the primary key of the table (Third\nNormal Form)\n-\nAvoid allowing NULL values in columns that have a discrete range of possible\nvalues (e.g., integers between 1 and 10, inclusive)\no Not applicable to DBF files, which do not support NULLs\n-\nAvoid using multiple tables with similar structures that represent minor variants\non the same entity (e.g., putting Boston parcels and Cambridge parcels in separate\ntables).\no Why is this rule often hard to practice with GIS?\n-\nPlan ahead for transferring data to a different database. For example, you may\nwant to move data from Oracle to DBF, or Microsoft Access to Oracle.\no Avoid column names with characters with other than UPPER CASE\nletters (A-Z), digits (0-9), and the underscore (_). Other characters may\nnot be accepted by a database. Some database systems may be case\nsensitive with regard to column names, while others are not.\no Keep your column names relatively short. Different databases support\ndifferent numbers of characters in column names (e.g., 30 for Oracle, 64\nfor Microsoft Access, 10 for DBF). Try to make column names differ in\nthe first few characters rather than at the end to avoid column name\nduplication if the names are truncated during the conversion process (e.g.,\nuse COL1 and COL2, not LONG_COLUMN_NAME_1 and\nLONG_COLUMN_NAME_2).\no Note that keeping column names short may be at odds with keeping your\ncolumn names meaningful for neophytes. Be aware that you are making a\ntradeoff!\n-\nRemember that these are rules of thumb, not absolute laws! Bend the rules if you\nmust but have a justification for your decision. The limitations of a GIS software\npackage often provide a good reason.\nEnforcing Referential Integrity in Oracle\nExample: The Parcels Database*\n-\nTables and Primary Keys\n* Kindly refer to the Lecture Notes section\n\nTable\nPrimary Key\nPARCELS PARCELID\nOWNERS OWNERNUM\nFIRES\nPARCELID, FDATE\nTAX\nPARCELID\n-\nCardinality Relationships\nPrimary Table Columns Foreign Table Columns Cardinality\nOWNERS.OWNERNUM PARCELS.ONUM\nOne-to-many\nPARCELS.PARCELID\nFIRES.PID, FIRES.WPB One-to-many\nPARCELS.PARCELID\nTAX.PARCELID\nOne-to-one\nParcels Database Enhancements\n-\nDefine a single-column primary key for the FIRES table (FIRES.FIREID)\n-\nMerge the TAX and PARCEL tables or add the year to the tax table to keep track\nof taxes over time (changes the relationship to one-to-many)\n-\nRename PARCELS foreign key ONUM to be consistent with the OWNERS table\n-\nImprove column names"
    },
    {
      "category": "Resource",
      "title": "Webtest_Baltimore.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/7aa7d4842bf60a45161c1b146ca94381_Webtest_Baltimore.pdf",
      "content": "NAME:\nINSTRUCTIONS\nThe goal of this lab is to familiarize you with different types of Neighborhood Information\nSystems currently in use and to help you assess aspects of these sites which may\nprove useful for the Lawrence project. Before filling out this survey, please explore\nevery feature of the website listed below in order to gain a general understanding\nof the project history and goals, as well as the data capabilities of the site. Once\nyou feel comfortable with the site's overall organization and content, please evaluate the\nsite according to the following:\nBaltimore Neighborhood Indicators Alliance\nhttp://www.bnia.org/index.html\nExample address: 100 E. 23rd Street\nUse/Quality of data dictionary or glossary?\n(data definitions and origins, potential data issues)\npoor\n\nok\n\nexcellent\nAbility to retrieve parcel-level data?\n(data or statistics in table or chart format)\npoor\nAbility to map parcel-level data?\n(e.g. housing or land-use information)\npoor\nAbility to retrieve census data?\n(data or statistics in table or chart format)\npoor\nAbility to map census data?\n(e.g. income, education, race, ethnicity)\npoor\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nUse/Quality of legends and data labels?\npoor\n\nok\n\nexcellent\n\nDescribe your ability to control how data are queried?\n(e.g. population density v. raw population numbers; percentage of vacant lots v. number of vacant lots)\npoor\n\nok\n\nexcellent\nDescribe your ability to control how data are presented?\n(e.g multiple layers of data on a map; zoom, colors or symbols, classification)\npoor\n\nok\n\nexcellent\nDescribe the site's use of local knowledge or non-traditional data?\n(people's stories, thoughts, ideas, opinions)\npoor\n\nok\n\nexcellent\nDescribe the site's overall aesthetics - the look and feel of the site?\npoor\n\nok\n\nexcellent\nDescribe the site's organization - how straightforward is the basic layout?\npoor\n\nok\n\nexcellent\nDescribe the site's ability to communicate project history, mission, and goals?\npoor\n\nok\n\nexcellent\nWhat is most useful about this site?\nWhat is least useful about this site?\nRank the following:\nOn a scale of 1 to 4, how well do you think the site serves the following users?\n1 meaning \"best served\" and 4 meaning \"least served\"\n____ Researcher/Professional\n____ Nonprofit/Community\nDevelopment Organization\n____ Government Employee\n____ Community Resident"
    },
    {
      "category": "Resource",
      "title": "Webtest_Los_Angeles.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/75f01d382ecbb0f47ae948811d3066b9_Webtest_Los_Angeles.pdf",
      "content": "NAME:\nINSTRUCTIONS\nThe goal of this lab is to familiarize you with different types of Neighborhood Information\nSystems currently in use and to help you assess aspects of these sites which may\nprove useful for the Lawrence project. Before filling out this survey, please explore\nevery feature of the website listed below in order to gain a general understanding\nof the project history and goals, as well as the data capabilities of the site. Once\nyou feel comfortable with the site's overall organization and content, please evaluate the\nsite according to the following:\nNeighborhood Knowledge Los Angeles\nhttp://nkla.sppsr.ucla.edu/index.cfm\nExample address: 15801 SAN FERNANDO MISSION BLVD\nUse/Quality of data dictionary or glossary?\n(data definitions and origins, potential data issues)\npoor\n\nok\n\nexcellent\nAbility to retrieve parcel-level data?\n(data or statistics in table or chart format)\npoor\nAbility to map parcel-level data?\n(e.g. housing or land-use information)\npoor\nAbility to retrieve census data?\n(data or statistics in table or chart format)\npoor\nAbility to map census data?\n(e.g. income, education, race, ethnicity)\npoor\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nUse/Quality of legends and data labels?\npoor\n\nok\n\nexcellent\n\nDescribe your ability to control how data are queried?\n(e.g. population density v. raw population numbers; percentage of vacant lots v. number of vacant lots)\npoor\n\nok\n\nexcellent\nDescribe your ability to control how data are presented?\n(e.g multiple layers of data on a map; zoom, colors or symbols, classification)\npoor\n\nok\n\nexcellent\nDescribe the site's use of local knowledge or non-traditional data?\n(people's stories, thoughts, ideas, opinions)\npoor\n\nok\n\nexcellent\nDescribe the site's overall aesthetics - the look and feel of the site?\npoor\n\nok\n\nexcellent\nDescribe the site's organization - how straightforward is the basic layout?\npoor\n\nok\n\nexcellent\nDescribe the site's ability to communicate project history, mission, and goals?\npoor\n\nok\n\nexcellent\nWhat is most useful about this site?\nWhat is least useful about this site?\nRank the following:\nOn a scale of 1 to 4, how well do you think the site serves the following users?\n1 meaning \"best served\" and 4 meaning \"least served\"\n____ Researcher/Professional\n____ Nonprofit/Community\nDevelopment Organization\n____ Government Employee\n____ Community Resident"
    },
    {
      "category": "Resource",
      "title": "Webtest_Oakland.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/8900fdceba8d9596a1d88e80a704601e_Webtest_Oakland.pdf",
      "content": "NAME:\nINSTRUCTIONS\nThe goal of this lab is to familiarize you with different types of Neighborhood Information\nSystems currently in use and to help you assess aspects of these sites which may\nprove useful for the Lawrence project. Before filling out this survey, please explore\nevery feature of the website listed below in order to gain a general understanding\nof the project history and goals, as well as the data capabilities of the site. Once\nyou feel comfortable with the site's overall organization and content, please evaluate the\nsite according to the following:\nUrban Strategies Council's Oaktown Datahouse\nhttp://www.urbanstrategies.org/\nExample address: 2043 E 21st St\nUse/Quality of data dictionary or glossary?\n(data definitions and origins, potential data issues)\npoor\n\nok\n\nexcellent\nAbility to retrieve parcel-level data?\n(data or statistics in table or chart format)\npoor\nAbility to map parcel-level data?\n(e.g. housing or land-use information)\npoor\nAbility to retrieve census data?\n(data or statistics in table or chart format)\npoor\nAbility to map census data?\n(e.g. income, education, race, ethnicity)\npoor\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nUse/Quality of legends and data labels?\npoor\n\nok\n\nexcellent\n\nDescribe your ability to control how data are queried?\n(e.g. population density v. raw population numbers; percentage of vacant lots v. number of vacant lots)\npoor\n\nok\n\nexcellent\nDescribe your ability to control how data are presented?\n(e.g multiple layers of data on a map; zoom, colors or symbols, classification)\npoor\n\nok\n\nexcellent\nDescribe the site's use of local knowledge or non-traditional data?\n(people's stories, thoughts, ideas, opinions)\npoor\n\nok\n\nexcellent\nDescribe the site's overall aesthetics - the look and feel of the site?\npoor\n\nok\n\nexcellent\nDescribe the site's organization - how straightforward is the basic layout?\npoor\n\nok\n\nexcellent\nDescribe the site's ability to communicate project history, mission, and goals?\npoor\n\nok\n\nexcellent\nWhat is most useful about this site?\nWhat is least useful about this site?\nRank the following:\nOn a scale of 1 to 4, how well do you think the site serves the following users?\n1 meaning \"best served\" and 4 meaning \"least served\"\n____ Researcher/Professional\n____ Nonprofit/Community\nDevelopment Organization\n____ Government Employee\n____ Community Resident"
    },
    {
      "category": "Resource",
      "title": "Webtest_Providence.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/da0d5de58f539e7e377aaf3c873d2365_Webtest_Providence.pdf",
      "content": "NAME:\nINSTRUCTIONS\nThe goal of this lab is to familiarize you with different types of Neighborhood Information\nSystems currently in use and to help you assess aspects of these sites which may\nprove useful for the Lawrence project. Before filling out this survey, please explore\nevery feature of the website listed below in order to gain a general understanding\nof the project history and goals, as well as the data capabilities of the site. Once\nyou feel comfortable with the site's overall organization and content, please evaluate the\nsite according to the following:\nThe Providence Plan\nhttp://www.providenceplan.org/\nExample address: 193 Dean St\nUse/Quality of data dictionary or glossary?\n(data definitions and origins, potential data issues)\npoor\n\nok\n\nexcellent\nAbility to retrieve parcel-level data?\n(data or statistics in table or chart format)\npoor\nAbility to map parcel-level data?\n(e.g. housing or land-use information)\npoor\nAbility to retrieve census data?\n(data or statistics in table or chart format)\npoor\nAbility to map census data?\n(e.g. income, education, race, ethnicity)\npoor\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nok\n\nexcellent\nUse/Quality of legends and data labels?\npoor\n\nok\n\nexcellent\n\nDescribe your ability to control how data are queried?\n(e.g. population density v. raw population numbers; percentage of vacant lots v. number of vacant lots)\npoor\n\nok\n\nexcellent\nDescribe your ability to control how data are presented?\n(e.g multiple layers of data on a map; zoom, colors or symbols, classification)\npoor\n\nok\n\nexcellent\nDescribe the site's use of local knowledge or non-traditional data?\n(people's stories, thoughts, ideas, opinions)\npoor\n\nok\n\nexcellent\nDescribe the site's overall aesthetics - the look and feel of the site?\npoor\n\nok\n\nexcellent\nDescribe the site's organization - how straightforward is the basic layout?\npoor\n\nok\n\nexcellent\nDescribe the site's ability to communicate project history, mission, and goals?\npoor\n\nok\n\nexcellent\nWhat is most useful about this site?\nWhat is least useful about this site?\nRank the following:\nOn a scale of 1 to 4, how well do you think the site serves the following users?\n1 meaning \"best served\" and 4 meaning \"least served\"\n____ Researcher/Professional\n____ Nonprofit/Community\nDevelopment Organization\n____ Government Employee\n____ Community Resident"
    },
    {
      "category": "Resource",
      "title": "zonin_overl_dis_over.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/d5d86ca3cf330eb7def5f7df88e3500d_zonin_overl_dis_over.pdf",
      "content": "Connery Associates\nJuly 22, 2002\nMemorandum\nAttached please find copies of a proposed zoning amendment. The language and format\nnecessarily conforms to the protocols of the current City Zoning Ordinance. However,\nto assist in our discussion I have prepared the following summary.\n1.0 Overview\n- The amendment establishes a Reviviendo Gateway Overlay District that permits\ndevelopment flexibility in order to unlock the value of existing buildings and\ninfrastructure, while also addressing issues such as housing diversity, affordable\nhousing, parking, and regulatory clarity.\n- The underlying or current zoning is not changed. The new regulations are\napplicable only if the property owner chooses to use the RGO regulations.\nHowever, once the RGO is chosen, all RGO regulations will apply to the\nproperty.\n- Adoption will require a two-thirds vote of the City Council.\n2.0 Key Terms\n- As of Right, a zoning term indicating that the owner has a right to use property for\na particular use, without further public hearings or a vote from a public body.\nThe owner, however, remains subject to all environmental, health, public safety\nand building regulations.\n- Special Permit, a zoning term indicating the owner has a right to develop only at\nthe discretion of the Lawrence City Council or other appropriate public body. To\nsecure the right to build, a two-thirds vote is required and additional conditions\nmay be added to the special permit. Both the owner and the parties of interest\nhave a right to seek redress in the court system if they are not in agreement with\nthe special permit decision\n\n2.0 Summary of Key Changes\nFor property zoned Residential-3\n- Permits rehabilitation of multi-family by right, currently special permit.\n- Permits new multi-family development by right, currently by special permit.\n- Permits town houses as a form of single-family development, currently not\npermitted.\n- Reinstates 5,000 square feet as the minimum residential lot size.\n- Reinstates the traditional density of 1 dwelling unit per 2,500 square feet of lot\narea.\n- Makes changes to lot coverage requirements that permit logical and normal\nresidential development options.\n- Maintains building height for new development at 3 stories and 45 feet.\n- Requires a 10% affordable housing requirement for residential developments over\n20 units.\nFor property zoned Business 2 and 3\n- Permits rehabilitation of multi-family by right.\n- Allows rehabilitation of commercial and mixed-use development by right.\n- Allow for new mixed-use development (including residential) by right.\n- Requires a 10% affordable housing requirement for residential developments over\n20 units.\nFor property zoned Industrial-2\n- Permits research, laboratory, and biotech uses by right, and without restrictive\nfloor space requirements.\n- Permits publishing, printing, and sign making by right.\n- Permits restaurants by right in existing buildings but prohibits stand-alone fast\nfood restaurants and drive through facilities.\n- Permits a bar or lounge as part of a restaurants by right.\n- Permits outdoor cafes by right.\n- Permits rehabilitation of commercial and mixed-use buildings by right.\n- Permits mixed-use with residential uses by right.\n- Permits Artist live / work space by right.\n- Requires a 10% affordable housing requirement for residential developments over\n20 units.\n\nFor all residential development\n- The RGO generally reflects current parking regulations but amends parking\nregulations to encourage adaptive reuse of buildings and reinvestment into\nexisting residential properties.\nFinal Comment\n- The zoning proposal is designed to address the specific land use and development\nissues germane to the Gateway Area, it does not effect the current zoning\nregulations for the remainder of the community."
    },
    {
      "category": "Resource",
      "title": "zoning_extract.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/2ce8e6ce1e8207b8bb5063531c02afc5_zoning_extract.pdf",
      "content": "Zoning Analysis\n1.0 Introduction\nFor zoning to be an effective community development tool, it must recognize the unique land use\ncharacteristics of the various portions of the community. The Lawrence Zoning Ordinance has\nnumerous features that are appropriate to the development pattern of the community. However,\nin some cases, there is a tendency to employ a \"one size fits all\" approach.\nThe Reviviendo Gateway District (Gateway) is characterized by access to the regional highway\nnetwork and the historic land use patterns of the North Common neighborhood, downtown\nLawrence, and the Mill District. In this area, the current zoning ordinance creates unnecessary\nobstacles to reinvestment. The redevelopment potential, as outlined in the vision statement,\ncannot be achieved given current zoning regulations. These regulations minimize reinvestment\nopportunities for both residential and commercial development by creating use, rehabilitation,\nand procedural barriers that effectively minimize property values, regardless of the regional\naccess and historic attributes of the area.\nThe following report illustrates specific zoning issues that, taken individually and together, need\nto be addressed if long-term and sustainable reinvestment is to occur consistent with the goals of\nthe Reviviendo Gateway Initiative.\n2.0 Residential Use\nThe role of housing is an often overlooked but key element in any long-term economic\ndevelopment effort. In many instances housing is the important initial step necessary to attract\nnew commercial activity, since it creates a market for local business activity. Specifically, new\nhousing provides additional disposable income and is the major factor in creating a viable\nprimary market area. For any area to become a functioning regional commercial center it needs\nfirst to become a successful local commercial center. It is highly unlikely that a failed or\nunderachieving commercial area will attract regional attention. Future regional economic success\ndepends on the short-term reconstruction of the primary market area, and additional housing is\nthe key to a successful primary market area.\nUnfortunately, our review indicates that current zoning policies discourage residential re-\ninvestment. Essentially, the normal residential rehabilitation process has been short-circuited by\na number of dimensional, use, and procedural requirements. We find that the following issues\nneed to be addressed if long-term and sustainable redevelopment of any significant volume is to\noccur.\na) Minimum Lot Sizes\nThe current lot minimum of 10,000 square feet in the Residence 3 (R3) District, a zoning district\nthat comprises almost half of the Reviviendo Gateway District, has no relationship to the historic\nor existing lot sizes in the area. The current regulations essentially create a large number of non-\nconforming lots. The overall effect is to discourage residential investment by making reuse of\nexisting residential lots contingent on difficult lot consolidation efforts or by Board of Appeal\ndecisions that can be easily appealed. Requiring a suburban residential density at the urban core\nof the community increases the cost of housing both in terms of land assembly and procedural\n\ncomplications. The net effect is to reduce the property value of existing residential lots in an area\nthat already exhibits some the lowest residential property values in the Commonwealth.\nb) Dwelling Unit Density\nThe requirement of one dwelling per 5,000 square feet essentially prevents two-family\ndevelopments on lots less than 10,000 square feet. Ironically, many quality two-family\nneighborhoods in Lawrence are comprised of lots with less than 10,000 square feet and with a\ndevelopment density less than one dwelling unit per 5,000 square feet.\nThe one unit per 5,000 square feet of lot area requirement simply compounds the negative impact\nof the current minimum lot requirements. It seriously retards the development of a new two-\nfamily house on lots less than 10,000 square feet. Section 29-13e permits rehabilitation and\nalteration of existing one- and two-family houses on \"undersized\" lots, but it does not allow for\nnew construction on \"undersized\" lots nor does it protect the many three- and four-family\ndwellings in the Reviviendo Gateway District. While the requirements of 29-13e are logical for\nmany portions of Lawrence, they are very problematic in the urban core. By establishing\nresidential density standards that diminish rehabilitation options for 3- and 4-family homes, the\ncurrent zoning undermines property value and the long-term economic viability of the Gateway.\nc) Yard Setback Requirements\nSimilar to the existing lot size and density requirements, the side yard setback requirement creates\nan obstacle to logical residential development. As required, the 12-foot side yard produces a 26-\nfoot building zone (or less) for the vast majority of lots in the R3 District. Twenty-six feet or less\nis not impossible building width for new construction, but it is not a typical new house width. In\nthis instance the side yard requirements can make the difference between seeking a dubious\nvariance, or assuming the added costs and risks of building an atypical layout; or it can result in\nno investment.\nIn some portions of the community the current side yard standard may be appropriate but at the\nhistoric core, the side yard requirements in conjunction with lot size and unit density restrictions\ncombine to create another economic hurdle hindering residential reuse and investment.\nd) Lot Coverage\nThe current lot coverage requirement is the clearest example of a dimensional regulation\nundermining residential use and investment in the Gateway. In the R3 district, all the other\nresidential disincentives notwithstanding, if you can assemble a 10,000 square foot lot your house\ncan cover only 15% of the lot. The resulting building footprint is very small; i.e. 750 square feet.\nWhile it is possible to build a house at this scale it is not cost effective, and it certainly restricts\nthe development of two-family houses. Thus, the current zoning provides yet another obstacle to\nresidential use in an area least able to absorb extra development costs. However, the lot coverage\nobstacle is not a community wide phenomenon. For example, the R1 residential district also\nrequires a 10,000 square foot lot, but here the owner is allowed a 30% building coverage, so he or\nshe can build a cost efficient house footprint of 1,500 square feet. Yet in the historic urban\ncenter, there is a clear zoning policy to make houses smaller. This policy adds another layer of\neconomic inefficiency into an area that clearly requires economic incentives.\n\ne) Row or Town House\nThe current zoning has no line item clearly permitting the development of town or row houses, a\nhighly efficient and effective form of single family housing in urban centers throughout the\nnation. Further, even if permitted the current density requirements would prevent logical and\neconomic development of this form of single-family development.\nf) Restrictions on Multi-family Dwellings\nIn the R3 district rehabilitation of multi-family buildings requires a special permit. Essentially,\nthe current policy discourages investment into existing multi-family buildings by forcing a time\nconsuming, expensive, and discretionary procedure as a requirement for residential rehabilitation.\nThe normal reinvestment process, encouraged almost everywhere in the nation, is subject to a\ndiscretionary review by the Board of Appeals in the Reviviendo Gateway District.\nFurther, it should be noted that R3 and R4 are classified as multi-family districts in the Lawrence\nZoning Ordinance. However, not only can an owner not rehabilitate a multi-family building\nwithout entering into a discretionary process, an owner in these multi-family districts is not\npermitted to build multi-family housing by right. The R3 and R4 Districts are the only two\nzoning districts in Lawrence where the primary use of the district is not allowed by right.\nGiven current regulations, even if a special permit is granted, using section 29-23i, the density\nlimitations noted above will permit only 8 units per acre, thus effectively making the exercise\nmoot. A density of 8 units per acre is less than the multi-family density allowed in most suburban\ntowns; indeed it is a lower density than many of the more stable and viable neighborhoods of\nLawrence. For all practical purposes privately financed multi-family development at any\nmeaningful scale is not allowed in the Reviviendo Gateway District.\ng) Parking Requirements\nParking is often an economic restriction on residential development due to the high cost of\nproviding adequate on-site spaces. While parking is a necessary expense, in urban environments\nparking regulations are particularly onerous for residential rehabilitation projects. In Lawrence\ntwo off-street parking spaces are required for a two-bedroom unit. Thus current zoning equates a\ntwo-bedroom apartment to a four-bedroom single family home in terms of parking demand. The\nunduly high parking requirement not only ignores the possibility and potential of other off street\nparking arrangements in the urban center, it adds considerable cost to housing development that\ncannot be readily absorbed given the residential property values in the Reviviendo Gateway\nDistrict.\nSummary\nTaken as individual or collective restrictions, it is clear that residential development in the\nGateway faces severe regulatory and economic obstacles. Surely, any residential project can be\napproved as a variance request as long as one is willing to risk an unfavorable decision by the\nZBA or a judicial appeal\npursuant to Chapter 40A. However, this practice cannot be considered a logical community\ndevelopment standard or an indication of appropriate zoning policies.\nTaken as a whole, current zoning clearly discourages residential development, particularly multi-\nfamily rehabilitation. While current zoning may be appropriate for other areas of the community,\n\nfor the Reviviendo Gateway District it depresses residential land values and prevents residential\nreinvestment from serving as the basis of a long-term economic revival.\n3.0 Commercial Uses, Business 2 and 3 Districts\nSimilar to the impact on residential uses, the current zoning regulations in the Business-3 (B3)\nDistrict creates unnecessary difficulties for traditional reinvestment and rehabilitation activities.\na) Rehabilitation of Commercial and Mixed Use\nConsistent with a zoning approach that limits direct investment into existing structures, the B2\nand B3 districts require that any rehabilitation of mixed-use or commercial property receive a\nspecial permit. While this process has allowed some development to occur, on a competitive\nlevel it places downtown Lawrence and adjacent commercial areas in a disadvantageous position.\nEssentially, an uncertain discretionary process (Section 29-23hh) becomes the basis of\nredevelopment, not a community plan or consistency with a historic and traditional land use\npattern. The above restrictions seem more incongruous since new commercial / residential\nmixed-use are allowed by right. Thus, to invest in the historic architectural image of the\ndowntown (B2 and B3 Districts) requires a special permit, however, developing a vacant lot or a\nlot created by removing a building is allowed by right.\nRequiring that all rehabilitation be subject to a special permit creates an imbalanced approach to\ncommercial investment in the B2 and B3 portions of the Gateway. The current policy makes\nmeaningful long-term planning difficult, and creates yet another economic hurdle to investing in\nexisting buildings and the architectural heritage of the area.\nFinally, there is a use anomaly relative to liquor stores. Liquor sales require a special permit in\nthe B3 District, which encompasses downtown Lawrence, while they are allowed by right in\nNeighborhood and Local Business Districts (B1 and B2).\nSummary\nThe Business 3 District does allow for significant uses. However, the ordinance-wide bias\nagainst rehabilitation by right creates a significant economic disadvantage that minimizes\nrevitalization options and may inadvertently lead to the loss of important architectural quality.\n4.0 Industrial Use\nLawrence has the infrastructure for a regional industrial / commercial center, but it cannot unlock\nthat potential under current zoning policies. The nineteenth century textile mills that characterize\nthe Industrial 2 (I2) District are a wonderful symbol of Lawrence. The mills have a number of\nadaptive reuse possibilities, some of which have been realized. However, the zoning ordinance\nhas a number of economically significant restrictions based on obsolete perceptions of modern\nindustrial activity. These restrictions are hindering the true potential of the Mill District. In many\ninstances the Table of Uses permits low value uses by right and hinders high end uses by\nrequiring special permits or not allowing a particular use.\n\na) Printing, Publishing and Sign Making\nWhile trucking is permitted by right, the ordinance has failed to recognize that the printing and\npublishing industry is no longer ink-based and continues to prohibit such high-tech computer\ngenerated activities. Further, some of the reasons for a special permit seem dubious or no longer\ngermane. For example, the primary reason to require a special permit for a printing establishment\nis to require a fence around the property and to require a loading dock. Similarly, sign making\nrequires a special permit in the Industrial 2 District, and the only special permit criterion is a\nbuffer or fence requirement. To move major uses into a discretionary use category for seemingly\nminor requirements that can be handled elsewhere in the ordinance minimizes the economic value\nof the entire I2 district.\nb) Biotech\nBiotech is allowed only by special permit and then only with the stipulation that biotech-\nmanufacturing activity not exceed 50% of the floor area. Since I2 is an Industrial District it is\nunclear why a modern industrial use would be prohibited from more than 50% of the floor area,\nand why the industrial use in general could not simply be allowed as of right. One of the most\nvaluable industrial uses in the modern economy is subject to a special permit to ensure that it does\nnot become a manufacturing facility in a manufacturing district. Clearly, given modern realities\nthe current zoning restrictions need to be reconsidered.\nc) Residential Use\nNationwide, textile mills have proven to be spectacular residential venues either as stand alone or\nas mixed-use buildings. However, the current zoning specifically excludes residential and\ncommercial mixed use in the I2 District. Thus the ability to create a lively ground floor\nenvironment with residences above is noticeably lacking in the current zoning. Residential use is\nallowed as a stand-alone use by special permit. However, this requires the ground floors to be\nused for residential purposes, a function not always practical in older buildings. Further, while\npermitted by special permit, the parking requirement of two spaces per two-bedroom unit remains\na considerable economic obstacle for viable residential reuse.\n5.0 Arts and Culture\nThe ordinance is silent on artist live / work space, a use type that has a proven track record as a\ncatalyst for revitalization. While said use does exist in the area, the potential is minimized\nwithout clear development guidelines. The ordinance needs to provide clear guidelines and\nincentive in the I2 District for artist live / work space.\nFurther, the ability to build a theatre or a performing arts center in either the downtown or Mill\nDistrict is not clear. The ordinance allows a theatre by special permit but the special permit\nrequirements state that use must \"abut\" a \"major thoroughfare\". Centers for performance, large or\nsmall, can be critical elements for community development and identity and should be\nencouraged as part of the overall redevelopment strategy."
    },
    {
      "category": "Resource",
      "title": "zoning_process_timel.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/fa1564fc2d2b72af321c80ce5a6c4567_zoning_process_timel.pdf",
      "content": "REVIVIENDO GATEWAY INITIATIVE\nRGI OVERLAY ZONING DISTRICT\nAPPROVAL PROCESS & TIMELINE\nMARCH - JULY, 2003\nKEY DATES:\nKEY ACTION STEPS\nMarch 18th\nSubmission of zoning change proposal to the Lawrence City\nCouncil\n(Vote by Council to consider the submitted zoning change with a\nrecommendation to send it immediately to the Planning Board)\nApril 9th\nPlanning Board Public Hearing\nThe Planning Board has 65 days from receipt of zoning proposal\nfrom council to hold public hearing.\nThe goal is a meeting and a vote to approve or approve with\namendments on the same night. They could hold additional\nsessions until early May. If they do not take action by that time it\nreverts to the Council without their input.\nA City Council vote on March 18th would allow the Planning\nBoard time to advertise the public hearing and hold a public\nhearing on April 9th.\nEarly-Mid May\nCity Council Public Hearing\nCity Council required to hold public hearing within 21 days of the\nPlanning Board's public hearing.\nAfter City Council public hearing, the zoning proposal will be\nreferred to Ordinance Committee for review and comment.\nLate May to\nOrdinance Committee public hearing, late May to early June\nEarly June\n(Committee approves, defeats, or approves with amendments, and\nreports back to full Council)\nJune to\nDeciding City Council Vote\nEarly July\n(Need 6 of 9 votes, the vote could occur on one night or in up to\nthree successive City Council meetings)\nLate July -\nConclusion of Appeal Period\nNote:\nIf the April 5th Planning Board meeting is missed, the entire\nprocess will slip into August."
    },
    {
      "category": "Resource",
      "title": "zoning_QA.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/b1f35bce34d841209474e862d3103e57_zoning_QA.pdf",
      "content": "Frequently Asked Questions:\nReviviendo Gateway Overlay District\nZoning Proposal\nFebruary 2003\nQ. Why is a zoning change necessary?\nA. The vision of redevelopment and reinvestment that has emerged from a two-year\ncommunity-led planning process for the mill district, North Common neighborhood and\ndowntown Lawrence cannot be achieved under current zoning. Reinvestment in new\nhousing and small business opportunities are inadvertently restricted by the current\nzoning regulations.\nQ What is the Reviviendo Gateway Overlay District Zoning Proposal (RGO)?\nA. The RGO is technically an overlay district that does not affect current development\nregulations or affect any other area in Lawrence. What it provides is an incentive to\nchoose a development option that reflects the vision and hopes of the local community.\nQ. What must a property owner give back in order to use the RGO?\nA. All projects using the RGO will be subject to Site Plan Review, a process that\nprovides assurances that what is proposed is actually built and that features like lighting\nand points of access of are taken into consideration for the benefit of the community and\nabutters. Also, for all residential projects over 20 units the RGO requires that 10% of the\nunits be designated for affordable housing, in this way protecting existing residents as\nreinvestment proceeds.\nQ. What does the RGO mean to Lawrence?\nA. It does not change existing regulations in the city, but it may provide an example of\nhow to unlock reinvestment potential in other areas. It also illustrates how Lawrence can\nbest serve its own community development interests in the future by working to develop\na clear vision and goals that help to shape the zoning for a particular area.\nQ. Is zoning the only change needed for revitalization?\nA. No. Zoning is one of many efforts that must be in place to create a revitalized\nLawrence, but appropriate zoning is the critical first step, the foundation upon which all\nreinvestment depends. Without proper zoning all planning and improvement hopes are\nessentially limited if not crippled. The RGO is the key to unlock the potential of the\nGateway district.\nQ. What are some of the RGO particulars?\nA. Essentially, the RGO would allow traditional and common uses to occur. For\nexample, it would permit mixed use (residential use over a commercial first floor) in the\n\nmill district by right. It removes inadvertent barriers for reinvestment into multi-family\nbuildings; it creates standard regulations for uses such as biotech, printing and publishing.\nHowever, most importantly it removes inadvertently restrictive regulations for small-\nscale residential use and small family businesses.\nQ. How does a zoning amendment happen?\nA. The process of public meetings has been established by the State for all communities.\nEssentially, the City Council starts the process by accepting a zoning proposal for debate.\nThe Planning Board acts as an advisor and holds a public meeting, and they send their\nwritten comments back to the City Council. The City Council then holds another public\nmeeting and may seek the advice of its ordinance committee. It is a long process, usually\n4 to 5 months but at each step of the way the public has the opportunity to participate in\nthe debate. Once voted by the City Council, the amendment becomes law after 20 days.\nQ. What can we as citizens and business people do to help?\nA. The most important thing is to stay informed, and we will be pleased to provide you\nwith information and answer your questions. Also, it is important that, if time permits,\nyou attend the public meetings and let your voice be heard.\nSummary Statement.\nThe Reviviendo Gateway Overlay proposal reflects the neighborhood renewal vision of\nliterally hundreds of people who participated in the RGI planning process over the past\ntwo years. It is the crucial first step in the renewal process. Without more logical and\nmodern development regulations, the City will not be able to unlock the potential of the\nneighborhood for the benefit of the people who live there.\nThe proposal is respectful of all other parts of the community. The technique chosen, an\noverlay district, has no impact on any other area in the community. The RGO is a\nframework for future reinvestment that establishes traditional opportunities for existing\nhomeowners, small businesses, and property owners. In many cases it simply removes\ninadvertent barriers to traditional development. The RGO is the foundation for all future\ncommunity development in the neighborhood, and by creating a zoning district that\nreflects the vision of the people it affirms the best in Lawrence and provides the greatest\nopportunity for success.\nIf you would like more information about the RGO zoning proposal, please contact:\nTom Galligani, Director of Planning and Development, City of Lawrence"
    },
    {
      "category": "Resource",
      "title": "zoningmap.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/2e09cdb7ed12ee1ca4d274d4e661714d_zoningmap.pdf",
      "content": "MISSERVILLE\nPARK\nREVIVIENDO\nPLAYGROUND\nHERITAGE\nSTATE PARK\nC A M P A G N O N E C O M M O N\nS\np\ni\nc k e\nt\nR\ni v\ne r\nN e w b u r y\nU n i o n\nJ a c k s o n\nA p p l e t o n\nL a w r e n c e\nM i l l\nE a s t\nB r o o k\nP r o s p e c t\nA l l e n\nE s s e x\nS u m m e r\nA v o n\nE r v i n g\nJ a c k s o n\nG a r d e n\nC o m m o n\nC a n a l\nM e t h u e n\nH a v e r h i l l\nE l m\nO a k\nM a p l e\nO r c h a r d\nM e c h a n i c\nA l b i o n\nW i l m o t\nJ a c k s o n\nT r i n i t y\nS h o r t\nI s l a n d\nM\nD u c k\nB r i d g e\nH i g h\nH o w a r d\nS a r g e n t\nG r o v e\nP l a t t\nB e l m o n t\nG e n e r a l\nF u l t\no n\nS t .\nM a r s t o n\nS t .\nN\nPROPOSED RGO DISTRICT\nN\nThis is the boundary of the\nReviviendo Gateway Overlay\n(RGO) District\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nH a v e r h i l l\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nA v e .\nC t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nr\ne\nv\ni\nR\nk\nc\na\nm\ni\nr\nr\ne\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nS t .\nl\na\nn\na\nC\nh\nt\nr\no\n300 feet\nCity of Lawrence, Massachusetts\nMarch 2003"
    },
    {
      "category": "Resource",
      "title": "correlated_updates.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/6869d346c142144a8f55ec67b131a57d_correlated_updates.pdf",
      "content": "Correlated Update Statements\nFirst, let's create private copies of the PARCELS, OWNERS, and FIRES tables:\nDROP TABLE myparcels;\nCREATE TABLE myparcels\nAS SELECT * FROM parcels;\nDROP TABLE myowners;\nCREATE TABLE myowners\nAS SELECT * FROM owners;\nDROP TABLE myfires;\nCREATE TABLE myfires\nAS SELECT * FROM fires;\nA simple update: Change the address of \"VANDELAY INDUSTRIES\" to \"300\nATLANTIC\":\n-- See the old value\nSELECT *\nFROM myowners\nWHERE oname = 'VANDELAY INDUSTRIES';\n-- Perform the update\nUPDATE myowners\nSET address = '300 ATLANTIC'\nWHERE ONAME = 'VANDELAY INDUSTRIES';\n-- Check our work\nSELECT *\nFROM myowners\nWHERE oname = 'VANDELAY INDUSTRIES';\n-- Commit the change permanently\nCOMMIT;\nA more complicated update:\n-- Look at estimated losses by ZIP code\nSELECT f.parcelid, f.fdate, p.zip, f.estloss\nFROM myfires f, myparcels p\nWHERE f.parcelid = p.parcelid\nORDER BY p.zip, f.parcelid;\n-- Increase the losses for parcels in ZIP 02130 by 50%\nUPDATE myfires f\nSET estloss = estloss * 1.50\nWHERE EXISTS\n(SELECT NULL\nFROM myparcels p\n\nWHERE p.parcelid = f.parcelid\nAND p.zip = '02130');\n-- Check the result\nSELECT f.parcelid, f.fdate, p.zip, f.estloss\nFROM myfires f, myparcels p\nWHERE f.parcelid = p.parcelid\nORDER BY p.zip, f.parcelid;\n-- Rollback\nROLLBACK;\n-- Check again\nSELECT f.parcelid, f.fdate, p.zip, f.estloss\nFROM myfires f, myparcels p\nWHERE f.parcelid = p.parcelid\nORDER BY p.zip, f.parcelid;\nThe most advanced form uses a subquery in the SET clause too.\n-- Set the losses for parcels in ZIP 02130 to the ZIP code\nUPDATE myfires f\nSET estloss =\n(SELECT TO_NUMBER(p.zip)\nFROM myparcels p\nWHERE p.parcelid = f.parcelid)\nWHERE EXISTS\n(SELECT NULL\nFROM myparcels p\nWHERE p.parcelid = f.parcelid\nAND p.zip = '02130');\n-- Check the result\nSELECT f.parcelid, f.fdate, p.zip, f.estloss\nFROM myfires f, myparcels p\nWHERE f.parcelid = p.parcelid\nORDER BY p.zip, f.parcelid;\n-- Commit the change\nCOMMIT;\nNote that it is important to have a WHERE clause in correlated updates to avoid Oracle\nerrors."
    },
    {
      "category": "Resource",
      "title": "index.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/ccbfc3437752b7f97e4b86c62ad2ab26_index.pdf",
      "content": "SQL Notes\nPlease refer to the pages linked below for help with the SQL labs and assignments:\n-\nSQL setup (Lab 1 exercise for running SQL*Plus from CRL and WinAthena\nPCs)*\n-\nSQL help*\n-\nPARCELS database*\n-\nURISA database*\n-\nOuter Join help*\n-\nZONING database\no Zoning Variances*\no 1980 Census data (by Boston NSA)*\no Schema of Decision, Use, NSA, Neighbrhd Lookup Tables*\no Sub-Neighborhood lookup table*\no SQL examples using zoning variances*\no Grouping zoning applicants via 'lookup' tables*\no Zoning Variance Database Evolution Chart*\n-\nSQL*Plus Formatting and Documentation Notes*\n-\nOracle 8i Documentation\nAvailable online at\nhttp://technet.oracle.com/docs/products/oracle8i/doc_index.htm.\nThe documentation is generally available both in HTML format (good for\nviewing online in a browser) and PDF format (better for printing).\nParticularly useful references:\no Oracle 8i SQL Reference. This is the authoritative reference for Oracle's\nflavor of SQL.\no SQL*Plus Quick Reference. A concise guide to SQL*Plus commands.\no SQL*Plus Reference. The full SQL*Plus manual.\no Oracle 8i Designing and Tuning for Performance. Suggests ways to tune\nqueries and database designs to improve performance. Offers insights into\nhow Oracle operates.\no Oracle 8i Error Messages. Provides extra information about Oracle's\nsometimes cryptic error messages.\nNote: To access this documentation you will need to register for a free\nmembership to the Oracle Technology Network. To register, click the 'My\nProfile' button in the upper right portion of the page and then complete\nand submit the registration form.\n* Kindly refer back to the Tools section"
    },
    {
      "category": "Resource",
      "title": "lookup.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/2fc0f978715038615a9fd6ca4da22ef8_lookup.pdf",
      "content": "------------------------------ --------------- ----------\n------------------------------ --------------- ----------\nGrouping Zoning Applicants via Lookup\nTables\nThis sequence of SQL queries uses Clark Broida's Zoning database* to illustrate\nstrategies for combining local information with other people's data.\nThe 'ZONING' database contains information about all zoning variances formally\nrequested in Boston during two+ years in the mid-1980s -- the heyday of the Boston's 80s\nboom. Suppose we wish to compare the types of zoning variances filed by public and\nprivate institutions and by individuals during that time. The 'applicant' field stores the\nname of zoning variance applicants and is often enough to tell us whether it was a\ncompany, the city, a non-profit organization, or an individual. For example, here's\neveryone with 'Boston' in their name:\nCOLUMN fname FORMAT A15\nselect applicant, fname, count(*) variances\nfrom zoning\nwhere applicant like '%BOSTON%'\ngroup by applicant, fname\norder by applicant, fname;\nAPPLICANT\nFNAME\nVARIANCES\nBANK OF BOSTON\nBOSTON CENTER FOR THE ARTS\nBOSTON CHATAQUA PROPERTIES,INC\nBOSTON COLLEGE HIGH SCHOOL\nBOSTON COLLEGE, TRUSTEES OF\nBOSTON DESIGN CENTER\nBOSTON FOOD COOPERATIVE INC.\nBOSTON HOUSING AUTHORITY\nBOSTON LOCK & SAFE COMPANY\nBOSTON PRESERVATION ALLIANCE\nBOSTON SCHOOL HOUSE ASSOCIATES\n...\nHere's everyone with 'university' in their name:\nSELECT applicant, fname, count(*) variances\nFROM zoning\nWHERE applicant LIKE '%UNIVERSITY%'\nGROUP BY applicant, fname;\nAPPLICANT\nFNAME\nVARIANCES\nBOSTON UNIVERSITY\nBOSTON UNIVERSITY, TRUSTEES\nBOSTON UNIVERSITY, TRUSTEES OF\n* Kindly refer to the Tools section\n\nHARVARD UNIVERSITY\nNORTHEASTERN UNIVERSITY\nSHOWA WOMEN'S UNIVERSITY OF JA\nSUFFOLF UNIVERSITY\nNote that Boston University submitted 3 variances and their 'name' is spelled differently\neach time. We could standardize the spelling of Boston University in the zoning table.\nBut, if the zoning table was maintained by another agency and updated periodically (to\nreport hearing results, subsequent design review outcomes, etc.) we do not want to make\nany changes to our copy of the 'master' zoning table. Even if we are fixing spelling errors,\nwe would have to make the corrections all over again each time a new 'official' version of\nthe zoning table arrived.\nLet's take a look at some of the data and try to use our understanding of relational\ndatabase management to find a way in which we can handle data errors and re-groupings.\nselect applicant, count(*) variances\nfrom zoning\ngroup by applicant\nhaving count(*) > 3\norder by count(*) DESC;\napplicant\nSMITH\nBRA\nSULLIVAN\nKELLY\nDOHERTY\nDUMBAUGH\nLEE\nMCCARTHY\nWONG\nO'CONNELL\nCLIFFORD\nBARRY\nDRISCOLL\nCARROLL\nWILLIAMS\nvariances\nOut of the 1801 zoning variances reported in the table, only 192 applicant names are\nrepeated! And, the top-15 applicant list is dominated by individual names. Only the\n'BRA', the Boston Redevelopment Authority, looks like it isn't the name of an individual.\nBut, the earlier queries already showed us that Boston University had filed 3 variances\nwith a different spelling of their name each time. In fact, a little digging shows us that the\n'City of Boston' is listed only once, but the Public Facilities Department (of the City) filed\n5 or 6 variances under 3 or 4 different spellings, depending upon whether the Public\nFacilities Commission is something different from PFD! Shortly, we'll assume that it is\nnot.\nselect applicant, count(*) variances\nfrom zoning\n\nwhere applicant like '%FACILIT%'\ngroup by applicant;\napplicant\n(count(*))\nPUBLIC FACILITIES DEPT\nPUBLIC FACILITIES DEPARTMENT\nPUBLIC FACILITES COMMISSION\nPUBLIC FACILITIES CITY OF BOST\nWith a more little time and effort, we could do more such queries and gradually develop\na much sharper sense of which applicants are institutions and who are the big players. BY\nUSING SOME OF WHAT WE HAVE LEARNED ABOUT RELATIONAL DATA\nMODELS, WE CAN KEEP THESE CHANGES IN A SEPARATE TABLE AND\nACCUMULATE THE RESULTS OF OUR EFFORT OVER TIME WITHOUT\nDISTURBING THE 'OFFICIAL' TABLE.\nLet's start by creating a lookup table to store the (first and last) name of applicants, the\ncorrected applicant name and a yet-to-be-determined grouping where we will store\n'public', 'private', 'individual', etc.. We could create the table explicitly and then 'insert'\nrows, or create the table as the 'select' statement. We show both ways below. When\ncreating the table explicitly, be sure that the datatypes are an exact match or you may\nhave trouble joining the tables later. When creating as a 'select', you must rename the\nduplicate copy of 'applicant' and set the new field to a long string of the desired width.\nCREATE TABLE apptype\n( fname varchar(20),\napplicant varchar(30),\nnewapp varchar(30),\nagroup varchar(12));\nINSERT INTO apptype\nSELECT DISTINCT fname, applicant, applicant, 'UNKNOWN'\nFROM zoning;\nCREATE TABLE apptype AS\nSELECT DISTINCT fname, applicant, applicant newapp,\n'xxxxxxxxxxxx' agroup\nFROM zoning;\nUPDATE apptype SET agroup = 'UNKNOWN';\ncreate index app on apptype(applicant);\n1702 rows are inserted/indexed.\nIn class and lab, we developed several SQL queries using the zoning table and the new\napptype table to determine the number of variances and total existing square footage for\nproperty owners that are the city, local universities, Trusts, etc. Note that the zoning table\ncontains a field, 'fname' (for first name), that is blank if the applicant is not an individual.\nNow, let's build some 'rules' that will store the knowledge we wish to accumulate about\nspelling corrections in applicant names and group membership.\n\n------------------------------ ----------\n------------------------------ ----------\n-------------------- ------------------------------ ---------- --------\n--\nupdate apptype\nset newapp = 'BOSTON, PFD' where applicant like '%FACILIT%';\nupdate apptype\nset newapp = 'BOSTON UNIVERSITY'\nwhere applicant like '%BOSTON UNIVERSITY%';\nThese two 'updates' standardize the name used to represent PFD and Boston University\nby replacing what is stored in the 'newapp' field. Let's run some queries to see the results\n'before' and 'after' regrouping via 'newapp':\nBEFORE:\nselect z.applicant, count(*) variances\nfrom zoning z\nwhere z.applicant like '%UNIVERSITY%'\nGROUP BY z.applicant;\nAPPLICANT\nVARIANCES\nBOSTON UNIVERSITY\nBOSTON UNIVERSITY, TRUSTEES\nBOSTON UNIVERSITY, TRUSTEES OF\nHARVARD UNIVERSITY\nNORTHEASTERN UNIVERSITY\nSHOWA WOMEN'S UNIVERSITY OF JA\nSUFFOLF UNIVERSITY\nAFTER regrouping:\nselect a.newapp, count(*) variances\nfrom zoning z, apptype a\nwhere z.applicant = a.applicant and\nz.fname = a.fname and\na.applicant like '%UNIVERSITY%'\nGROUP BY a.newapp;\nNEWAPP\nVARIANCES\nBOSTON UNIVERSITY\nHARVARD UNIVERSITY\nNORTHEASTERN UNIVERSITY\nSHOWA WOMEN'S UNIVERSITY OF JA\nSUFFOLF UNIVERSITY\nNow, let's run some queries that use the apptype table to check which\napplicants have the most square footage under zoning review.\nselect fname, applicant, sum(existsqft) sqft, count(*) variances\nfrom zoning\ngroup by fname, applicant\nhaving count(*) >= 3\norder by 4 desc;\nFNAME\nAPPLICANT\nSQFT\nVARIANCES\nBRA\n\n-------------------- ------------------------------ ---------- --------\n--\nCHARLES C.\nDUMBAUGH\nBOSTON HOUSING AUTHORITY\nKEVIN\nCARROLL\nGOLD ASSOCIATES\nNORTHEASTERN UNIVERSITY\n-2\nThis list uses none of our re-grouped data and shows few owners of multiple variance\nrequests. (We'll ignore the problems with negative (unknown) square footages for now.)\nNext, we'll join to the 'apptype' and run the same query but group by the 'newapp' field.\nselect a.fname, a.newapp, sum(existsqft) sqft, count(*) variances\nfrom zoning z, apptype a\nwhere z.applicant = a.applicant and\nz.fname = a.fname\ngroup by a.fname, a.newapp\nhaving count(*) >= 3\norder by 4 desc;\nFNAME\nNEWAPP\nSQFT\nVARIANCES\nBRA\nBOSTON, PFD\nCHARLES C.\nDUMBAUGH\nBOSTON HOUSING AUTHORITY\nKEVIN\nCARROLL\nNORTHEASTERN UNIVERSITY\nGOLD ASSOCIATES\nBOSTON UNIVERSITY\n-2\nThe standardization of PFD and Boston University names moves them onto our multiple-\nvariance list. But the 'sqft' column reminds us that square footage is not always known --\nremember that a code of '-1' is used for 'missing'. With modern RDBMS packages, such\ncases would be encoded as NULL. We could rerun the query excluding those zoning\nvariance cases where square footage is not known.\nselect a.fname, a.newapp, sum(existsqft) sqft, count(*) variances\nfrom zoning z, apptype a\nwhere z.applicant = a.applicant and\nz.fname = a.fname and\nexistsqft > 0\ngroup by a.fname, a.newapp\nhaving count(*) >= 3\norder by 4 desc;\n\n---------- ------------------------------ ---------- ----------\nFNAME\nNEWAPP\nSQFT VARIANCES\nBOSTON, PFD\nBRA\nCHARLES C. DUMBAUGH\nWow! Most of the multi-variance owners drop out when we consider only the cases\nwhere square footage is reported. That probably makes sense since it's know for most\nresidential property with a small lot and single individual owner. But who knows the size\nof a public housing development when they fill out a zoning variance application for the\nBHA.\nInstead of pursuing this line of reasoning further where we are only correcting the\nmisspelling of owner names, let's use the same idea to CATEGORIZE TYPE OF\nOWNERSHIP by updating the values stored in the 'agroup' field of our 'apptype' lookup\ntable.\nupdate apptype\nset agroup = 'INSTITUTION' where fname = ' ';\nupdate apptype\nset agroup = 'TRUST'\nwhere applicant like '%TRUST%';\nupdate apptype\nset agroup = 'UNIVERSITY'\nwhere applicant like '%UNIVERSITY%';\nupdate apptype\nset agroup = 'CITY'\nwhere (applicant like '%CITY%' and applicant like '%BOSTON%')\nor applicant like '%FACILIT%';\ncommit;\n/* commit these changes so they won't be rolled back\nif you run an SQL with a syntax error */\nThe first of these four 'updates' sets the 'agroup' to 'INSTITUTION' wherever the\nfirstname was blank in the original data. The next three 'updates' reset 'agroup' for records\nthat appear to be universities, trusts, or the city of Boston.\nselect agroup, sum(existsqft) sqft, count(*) variances\nfrom zoning z, apptype a\nwhere z.applicant = a.applicant and\nz.fname = a.fname\ngroup by agroup\nhaving count(*) >= 3\norder by 3 desc;\nAGROUP\nSQFT VARIANCES\n\n------------ ---------- ----------\n------------ ----------- ---------- ----------\nUNKNOWN\nINSTITUTION\nTRUST\nUNIVERSITY\nCITY\nThe square footage associated with the 'institutional' owned parcels requesting variances\nis larger than that of the 'unknown' group that comprises mainly individually owned\nparcels. In fact, the 'trust' and 'university' cases that were separated from the other\ninstitutional cases amount to more than half the square footage of the individually owned\ncases.\nNow, let's add conditions and qualifiers to the same basic SQL to examine further some\nof the differences that might exist in zoning variance characteristics across the five broad\ncategories of ownership that we have identified. E.G., here's a table that looks only at\nresidentially zoned property and computes the fraction of cases that involved floor area\nratio violations (among all cases where FAR151 was not missing).\nCOLUMN far_percent FORMAT 999.99\nselect a.agroup, 100*avg(far151-1) FAR_percent,\nsum(existsqft) sqft, count(*) variances\nfrom zoning z, apptype a\nwhere z.applicant = a.applicant and\nz.fname = a.fname and\nsubstr(EXISTZONIN,1,1) in ('R', 'S', 'H') and\nfar151 > 0\ngroup by a.agroup\norder by 4 desc;\nAGROUP\nFAR_PERCENT\nSQFT VARIANCES\nUNKNOWN\n34.36\nINSTITUTION\n33.33\nTRUST\n45.00\nCITY\n.00\nUNIVERSITY\n.00\nHmm, a high percentage of residential variances requested floor area ratio violations and\nthe 'trust' properties were more likely than average to want this.\nNow let's redo this query but instead of looking at floor area ratios violations, let's look at\nfront/side/rear yard restrictions. (See the appendix below for various descriptive statistics\nregarding these codes.)\ncreate table t1yard as\nselect distinct casenumber, RYARD201, FYARD181, SYARD191,\n0 combo\nfrom zoning;\nupdate t1yard\nset combo = 1\nwhere (RYARD201 = 2 or FYARD181 = 2 or SYARD191 = 2);\n\n---------- ----------\n------------ ------------ ---------- ----------\nselect combo, count(*) variances\nfrom t1yard\ngroup by combo\norder by combo;\nCOMBO VARIANCES\n<== 40% involve yard violations\nCOLUMN yard_percent FORMAT 999.99\nselect a.agroup, 100*avg(combo) yard_percent,\nsum(existsqft) sqft, count(*) variances\nfrom zoning z, apptype a, t1yard t\nwhere z.applicant = a.applicant and\nz.fname = a.fname and z.casenumber = t.casenumber and\nsubstr(EXISTZONIN,1,1) in ('R', 'S', 'H')\ngroup by a.agroup\norder by 4 desc;\nAGROUP\nYARD_PERCENT\nSQFT VARIANCES\nUNKNOWN\n43.92\nINSTITUTION\n33.90\nTRUST\n32.35\nCITY\n60.00\nUNIVERSITY\n.00\nHmm, institutionally owned (and trusts) are less likely to have front/side/rear yard\nrestrictions! Given the number of cases, that difference is significant.\nAt this point, we might remember from class that there are several duplicate casenumber\nin the zoning table and we may want to exclude those cases (since they involve some\nform of mistakes) to avoid biasing our results. To do this, we illustrate the use of side\ntables to handle outliers and special cases by creating a table with the casenumbers for all\ncases that have duplicate rows in the zoning table. Since the characteristics differ and we\ndon't know which set is 'correct', we'll probably want to exclude these case numbers from\nmany of our SQL queries.\ncreate table t1double as\nselect casenumber, count(*) cases\nfrom zoning\ngroup by casenumber\nhaving count(*) > 1;\nNow, redo the previous breakdown of variances by ownership category, excluding the 8\nduplicated cases:\nselect a.agroup, 100*avg(combo) yard_percent,\nsum(existsqft) sqft, count(*) variances\nfrom zoning z, apptype a, t1yard t\nwhere z.applicant = a.applicant and\nz.fname = a.fname and z.casenumber = t.casenumber and\nsubstr(EXISTZONIN,1,1) in ('R', 'S', 'H') and\nz.casenumber NOT IN (select casenumber from t1double)\n\n------------ ------------ ---------- ----------\n---------- ----------\n------------ ----------- ---------- ----------\ngroup by a.agroup\norder by 4 desc;\nAGROUP\nYARD_PERCENT\nSQFT VARIANCES\nUNKNOWN\n43.92\nINSTITUTION\n33.53\nTRUST\n31.63\nCITY\n60.00\nUNIVERSITY\n.00\nNot too much change in the results, but it does become a useful technique to exclude\ncases that you've identified as outliers.\nFinally, let's try to find another condition that varies between 'trust', 'institution' and\n'unknown' (mostly individuals). What about lotsize restrictions? We can group the four\nrelevant variables in the same fashion that we just did for front/side/rear yard violations.\ncreate table t1lot as\nselect distinct casenumber,\nLOTSZE141, LOTSZE142, LOTSZE143, LOTSZE144, 0 combo\nfrom zoning;\nupdate t1lot\nset combo = 1\nwhere ( LOTSZE141 = 2 or LOTSZE142 = 2 or LOTSZE143 = 2\nor LOTSZE144 = 2);\nselect combo, count(*) variances\nfrom t1lot\ngroup by combo\norder by combo;\nCOMBO VARIANCES\n<== 39% of variances involved lotsize\nCOLUMN lot_percent FORMAT 999.99\nselect a.agroup, 100*avg(combo) lot_percent,\nsum(existsqft) sqft, count(*) variances\nfrom zoning z, apptype a, t1lot t\nwhere z.applicant = a.applicant and\nz.fname = a.fname and z.casenumber = t.casenumber and\nsubstr(EXISTZONIN,1,1) in ('R', 'S', 'H') and\nz.casenumber NOT IN (select casenumber from t1double)\ngroup by a.agroup\norder by 4 desc;\nAGROUP\nLOT_PERCENT\nSQFT VARIANCES\nUNKNOWN\n49.79\nINSTITUTION\n33.53\nTRUST\n41.84\nCITY\n40.00\n\n---------- ----------\n---------- ----------\nUNIVERSITY\n.00\nHmm, this time the difference between unknown (i.e., individually owned properties) and\ninstitutionally owned properties is even larger. Institutionally owned residential\nproperties are much less likely to seek variances for lotsize violations.\nOf course, this breakdown of ownership categories is only a beginning since many other\n'rules' could be constructed to sort out and better categorize the class of ownership. As we\nlearn more and more about the applicants, we can add more 'update' rules.\nIn this way, we can accumulate our knowledge gradually without disturbing the 'official'\nfiles and without altering the basic queries. As we add more 'knowledge' to our lookup\ntable, the same query will produce different (better and better) results. We never have to\nmake any changes to the original zoning table. When an updated version of the zoning\ntable becomes available, we can replace our old one with the new table, and still use the\nsame old queries and all our knowledge in the lookup table. We'll do a bit of this in the\nhomework.\nFOOTNOTE: More complications can arise if the original zoning table undergoes major\nchanges in its structure or content from one version to the next. But, we can address many\nof these complications with other slightly more complex strategies. For example, when a\nnew, updated zoning table arrives, we can run queries to identify all the names in the new\nzoning table that don't show up in our old 'apptype' table (and vice versa).\nAPPENDIX: Examining Front/Side/Rear Yard\nViolations\nOFFPKG231\nselect SYARD191, count(*) variances\nfrom zoning\ngroup by SYARD191\norder by SYARD191;\nSYARD191 VARIANCES\n-1\nselect FYARD181, count(*) variances\nfrom zoning\ngroup by FYARD181\norder by FYARD181;\nFYARD181 VARIANCES\n\n---------- ----------\n----------\n----------\n----------\n---------- ----------\n-1\nselect RYARD201, count(*) variances\nfrom zoning\ngroup by RYARD201\norder by RYARD201;\nRYARD201 VARIANCES\n-1\nOnly 8 cases had missing values for each of these front/side/rear variance requests, and\nthe following query shows they were the same 8 cases:\nselect count(*) from zoning\nwhere RYARD201 <=0 or FYARD181 <=0 or SYARD191 <=0;\nCOUNT(*)\nOf the cases where the front/side/rear variance requests were recorded, here's the\nbreakdown by various combinations:\nselect count(*) from zoning\nwhere RYARD201 = 2 or FYARD181 = 2 or SYARD191 = 2;\nCOUNT(*)\nselect count(*) from zoning\nwhere RYARD201 >0 and FYARD181 >0 and SYARD191 >0;\nCOUNT(*)\nselect (RYARD201-1 + FYARD181-1 + SYARD191-1) total,\ncount(*) variances\nfrom zoning\nwhere RYARD201 >0 and FYARD181 >0 and SYARD191 >0\ngroup by (RYARD201-1 + FYARD181-1 + SYARD191-1);\nTOTAL VARIANCES"
    },
    {
      "category": "Resource",
      "title": "outerjoin.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/e3d1ec4afa5569b40125a843e833b89e_outerjoin.pdf",
      "content": "'OUTER JOIN' Class Notes\nThis join of parcels and fires drops out any parcel that didn't have a fire:\nselect p.parcelid, add1, add2, count(fdate) fires\nfrom parcels p, fires f\nwhere p.parcelid = f.parcelid\ngroup by p.parcelid, add1, add2;\nThis set of queries will save the results of the previous join in a table and then add in one\nrow for every parcel in the parcel table that didn't have a fire:\ncreate table t1holdf as\nselect p.parcelid, add1, add2, count(fdate) fires\nfrom parcels p, fires f\nwhere p.parcelid = f.parcelid\ngroup by p.parcelid, add1, add2;\ninsert into t1holdf\nselect parcelid, add1, add2, 0\nfrom parcels\nwhere parcelid NOT IN (select parcelid from fires);\nNow, here's an 'outer join' SQL statement that redoes the original query in a way that\nadds\nin the rows for parcels without fires (just like the two-step create/insert statements\nabove). (We've added an additional column--the sum of the estimated fire losses--so you\nsee how NULLs are handled).\nselect p.parcelid, add1, add2, count(fdate) fires, sum(estloss)\nfrom parcels p, fires f\nwhere p.parcelid = f.parcelid (+)\ngroup by p.parcelid, add1, add2;"
    },
    {
      "category": "Resource",
      "title": "parcels.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/c5296bde71ab2efab698a875d79cdbe7_parcels.pdf",
      "content": "The \"Parcels\" Database\nSwitchboard\nObject\nObjectType\nLastModified\nDescription\nFIRES*\nTable\n2/6/2001 1:16:09 PM\nOWNERS* Table\n2/6/2001 1:16:16 PM\nPARCELS* Table\n2/6/2001 1:16:20 PM\nPERMITS* Table\n2/6/2001 1:16:25 PM\nSALES*\nTable\n2/6/2001 1:16:29 PM\nTAX*\nTable\n2/6/2001 1:16:34 PM\nZONING*\nTable\n2/6/2001 1:16:39 PM\n* Kindly refer to the Tools section"
    },
    {
      "category": "Resource",
      "title": "parcelsfires.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/401812887b2125f673799c7212942d5e_parcelsfires.pdf",
      "content": "The \"Parcels\" Database\nFIRES\nPARCELID FDATE IGNFACTOR ESTLOSS\n7 01-Aug-87\n3 26-Jul-89\n3 26-Jul-90\n2 02-Aug-88\n2 02-Apr-89\n20 02-Jul-89\n4 1000000"
    },
    {
      "category": "Resource",
      "title": "parcelsowners.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/6d6561c3d0a87836feb012913d108f6d_parcelsowners.pdf",
      "content": "The \"Parcels\" Database\n\nOWNERS\nOWNERNUM\nONAME\nADDRESS\nCITY\nSTATE ZIP\n10 METHUINON TRUST\n400 COLUMBUS BOSTON\nMA\n29 FRANK O'BRIEN\n660 TREMONT\nBOSTON\nMA\n55 THOMAS KELLIHER\n221 BROADWAY NEW YORK\nNY\n9 PATRICK KING\n201 BLUE HILL\nBOSTON\nMA\n89 JOSEPH NOONAN\n200 MORRISEY BOSTON\nMA\n38 BAY STATE, INC.\n200 CONGRESS BOSTON\nMA\n100 MGH, INC.\n220 CAMBRIDGE BOSTON\nMA\n32 GERALD RAPPAPORT\n55 PRIEST\nBURLINGTON VT\n11 FERNANDO MARTINEZ 196 GREEN\nBOSTON\nMA\n18 JOHN MCCORMACK\n21 STATE ST\nBOSTON\nMA\n200 VANDELAY INDUSTRIES 500 FLATBUSH BROOKLYN\nNY"
    },
    {
      "category": "Resource",
      "title": "parcelsparcels.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/be470b0eed9324a73782e82083c39b90_parcelsparcels.pdf",
      "content": "The \"Parcels\" Database\n\nPARCELS\nPARCELID PID WPB ADD1\nADD2\nZIP\nSQFT ONUM LANDUSE\n1 101 224\n550 BOYLSTON\n18 C\n2 109 292\n220 BERKELEY\n02116 100000\n32 C\n3 103 112\n196 GREEN\n11 R3\n4 104 267\n290 MELNIA CASS\n18 CL\n5 191 209\n400 COLUMBUS\n10 E\n6 324 342\n221 FENWAY\n55 CM\n7 101 265\n580 NO. BEACON\n32 A\n8 106 234\n550 BEACON\n200 C\n9 108 453\n201 BLUE HILL\n9 R1\n10 123 287\n100 COLUMBIA\n11 109 381\n100 BOYLSTON\n02199 210000\n18 C\n12 110 250\n200 MORRISSEY\n89 R3\n13 183 236\n55 HARRISON\n38 R2\n14 121 550\n120 MARLBOROUGH\n18 A\n15 142 231\n34 MASSACHUSETTS 02114\n16 103 276\n930 COMMONWEALTH 02116\n200 A\n17 131 283\n660 TREMONT\n29 R1\n18 145 229\n45 HUNTINGTON\n18 A\n19 127 653\n300 BEACON\n32 C\n20 129 543\n220 CAMBRIDGE\n100 E"
    },
    {
      "category": "Resource",
      "title": "parcelspermits.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/b47a7dee72802a08a3234d7631a8df45_parcelspermits.pdf",
      "content": "The \"Parcels\" Database\nPERMITS\nPID WPB PTYPE APPDATE ISSUDATE ESTCOST FEE\n110 250\n2 02-Jun-88 02-Sep-88\n103 112\n3 09-Aug-89 03-Dec-89\n101 265\n7 02-Sep-87 02-Nov-87\n100000 2100\n109 292\n3 03-Sep-88 10-Dec-88\n300000 7000\n101 265\n7 19-Jul-88 17-Oct-88\n21200 800"
    },
    {
      "category": "Resource",
      "title": "parcelssales.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/11-521-spatial-database-management-and-advanced-geographic-information-systems-spring-2003/73f6770b177fdffd9ad59ad2ba6a02dc_parcelssales.pdf",
      "content": "The \"Parcels\" Database\nSALES\nPARCELID SDATE\nGRANTOR\nGRANTEE\nSPRICE BKNUM PGNUM\n10-Feb-\nB.U. TRUST CORP. GERALD\nRAPPAPORT\n3 07-Jul-89 THOMAS FOLEY\nFERNANDO\nMARTINEZ\n01-Feb-\nFERNANDO\nMARTINEZ\nDAVID NOBLE\n02-Apr-\nMICHAEL\nFLAHERTY\nJOSEPH NOONAN\n03-Mar-\nBOSTON PROP. CO. THOMAS\nMCCORMACK\n10-Mar-\nN.E. TREST CORP.\nGERLAD\nRAPPAPORT"
    }
  ]
}