{
  "course_name": "Introduction to Algorithms (SMA 5503)",
  "course_description": "This course teaches techniques for the design and analysis of efficient algorithms, emphasizing methods useful in practice. Topics covered include: sorting; search trees, heaps, and hashing; divide-and-conquer; dynamic programming; amortized analysis; graph algorithms; shortest paths; network flow; computational geometry; number-theoretic algorithms; polynomial and matrix calculations; caching; and parallel computing.\nThis course was also taught as part of the Singapore-MIT Alliance (SMA) programme as course number SMA 5503 (Analysis and Design of Algorithms).",
  "topics": [
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures",
    "Engineering",
    "Computer Science",
    "Algorithms and Data Structures"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hour / session\n\nCourse Objectives and Outcomes\n\nCourse Objectives\n\nThis course introduces students to the analysis and design of computer algorithms. Upon completion of this course, students will be able to do the following:\n\nAnalyze the asymptotic performance of algorithms.\n\nDemonstrate a familiarity with major algorithms and data structures.\n\nApply important algorithmic design paradigms and methods of analysis.\n\nSynthesize efficient algorithms in common engineering design situations.\n\nCourse Outcomes\n\nStudents who complete the course will have demonstrated the ability to do the following:\n\nArgue the correctness of algorithms using inductive proofs and loop invariants.\n\nAnalyze worst-case running times of algorithms using asymptotic analysis. Compare the asymptotic behaviors of functions obtained by elementary composition of polynomials, exponentials, and logarithmic functions. Describe the relative merits of worst-, average-, and best-case analysis.\n\nAnalyze average-case running times of algorithms whose running time is probabilistic. Employ indicator random variables and linearity of expectation to perform the analyses. Recite analyses of algorithms that employ this method of analysis.\n\nExplain the basic properties of randomized algorithms and methods for analyzing them. Recite algorithms that employ randomization. Explain the difference between a randomized algorithm and an algorithm with probabilistic inputs.\n\nAnalyze algorithms using amortized analysis, when appropriate. Recite analyses of simple algorithms that employ this method of analysis. Describe different strategies for amortized analysis, including the accounting method and the potential method.\n\nDescribe the divide-and-conquer paradigm and explain when an algorithmic design situation calls for it. Recite algorithms that employ this paradigm. Synthesize divide-and-conquer algorithms. Derive and solve recurrences describing the performance of divide-and-conquer algorithms.\n\nDescribe the dynamic-programming paradigm and explain when an algorithmic design situation calls for it. Recite algorithms that employ this paradigm. Synthesize dynamic-programming algorithms, and analyze them.\n\nDescribe the greedy paradigm and explain when an algorithmic design situation calls for it. Recite algorithms that employ this paradigm. Synthesize greedy algorithms, and analyze them.\n\nExplain the major algorithms for sorting. Recite the analyses of these algorithms and the design strategies that the algorithms embody. Synthesize algorithms that employ sorting as a subprocedure. Derive lower bounds on the running time of comparison-sorting algorithms, and explain how these bounds can be overcome.\n\nExplain the major elementary data structures for implementing dynamic sets and the analyses of operations performed on them. Recite algorithms that employ data structures and how their performance depends on the choice of data structure. Synthesize new data structures by augmenting existing data structures. Synthesize algorithms that employ data structures as key components.\n\nExplain the major graph algorithms and their analyses. Employ graphs to model engineering problems, when appropriate. Synthesize new graph algorithms and algorithms that employ graph computations as key components, and analyze them.\n\nDemonstrate a familiarity with applied algorithmic settings - such as computational geometry, operations research, security and cryptography, parallel and distributed computing, operating systems, and computer architecture - by reciting several algorithms of importance to different fields.\n\nPrerequisites\n\nA strong understanding of programming and a solid background in discrete mathematics, including probability, are necessary prerequisites to this course.\n\nFor MIT Students, this course is the header course for the MIT/EECS Engineering Concentration of Theory of Computation. You are expected to have taken\n6.001\nStructure and Interpretation of Computer Programs and\n6.042J / 18.062J\nMathematics for Computer Science, and received a grade of C or higher in both classes. If you do not meet these requirements, you must talk to a TA before registering for the course.\n\nLectures\n\nLectures will be held twice a week on Mondays and Wednesdays for 1.5 hours. You are responsible for material presented in lectures, including oral comments made by the lecturer.\n\nRecitations\n\nStudents must attend a one-hour recitation session each week. The course staff will schedule recitations. You are responsible for material presented in recitation. Attendance in recitation has been well correlated in the past with exam performance. Recitations also give you a more intimate opportunity to ask questions and interact with the course staff. Your recitation instructor will assign your final grade. Recitations will be taught by the teaching assistants on Fridays.\n\nHandouts\n\nMost handouts will be made available on the server in formats suitable for printing. Students should download and print out the handouts from the server. You will be informed via the server and/or email where and when the few handouts that are not available from the server can be obtained.\n\nText\n\nCormen, Thomas, Charles Leiserson, Ronald Rivest, and Clifford Stein.\nIntroduction to Algorithms\n. 3rd ed. MIT Press, 2009. ISBN: 9780262033848.\n\nExtra Help\n\nEach Teaching Assistant will post his or her weekly office hours on the server. As an experiment, we will offer homework labs during the term. The time and location will be on the specific problem set. A homework lab is a place where you can go to do your homework with others in the class. Teaching Assistants will be available at the homework lab to help if you have questions about the problem set.\n\nIn addition, as a free service to its students, the MIT Department of Electrical Engineering and Computer Science provides one-on-one peer assistance in many basic undergraduate Course VI classes. During the first nine weeks of the term, you may request a tutor who will meet with you for a few hours a week to aid in your understanding of course material. You and your tutor arrange the hours that you meet, for your mutual convenience. More information is available on the HKN Web page.\n\nTutoring is also available from the Tutorial Services Room (TSR) sponsored by the Office of Minority Education. The tutors are undergraduate and graduate students, and all tutoring sessions take place in the TSR or the nearby classrooms.\n\nRegistration\n\nPlease fill out a sign-up sheet on the course server. The information you provide will help the course staff to get to know you better and create a mailing list and a course directory. Signing up is a requirement of the course. You will find it difficult to pass the course if you aren't in the class! You should notify your TA immediately if you drop the course after having registered. Listeners should also register for the course in order to be on the mailing list.\n\nYou must register before Ses #1. We will email your recitation assignment to you one day after Ses #1.\n\nProblem Sets\n\nNine problem sets will be assigned during the semester. The course\ncalendar\nshows the tentative schedule of assignments and due dates, but the actual due date will always be on the problem set itself.\n\nLate homework will generally not be accepted. If there are extenuating circumstances, you should make\nprior\narrangements with your recitation instructor.\nAn excuse from the Dean's Office will be required if prior arrangements have not been made\n.\n\nEach problem should be written up on a separate sheet (or sheets) of paper, since problems may be graded by separate graders. Mark the top of each sheet with the following:\n\nyour name,\n\nthe name of your recitation instructor,\n\nthe problem number,\n\nthe people you worked with on the problem (see Collaboration Policy), or \"Collaborators: none\" if you solved the problem completely alone.\n\nYou may handwrite or type your answers.\nYou must submit your answers on three-hole punch paper\nand hand in a physical copy. The course staff puts rings through the holes to avoid losing homework. In addition, your graded homework can easily be included in your loose-leaf course notebook.\n\nYou should be as clear and precise as possible in your write-up of solutions. Understandability of your answer is as desirable as correctness, because communication of technical material is an important skill.\n\nA simple, direct analysis is worth more points than a convoluted one, both because it is simpler and less prone to error and because it is easier to read and understand. Sloppy answers will receive fewer points, even if they are correct, so make sure that your handwriting is legible. It is a good idea to copy over your solutions to hand in, which will make your work neater and give you a chance to do sanity checks and correct bugs.\n\nThe problem sets include exercises that should be solved but not handed in. These questions are intended to help you master the course material and will be useful in solving the assigned problems. Material covered in exercises will be tested on exams.\n\nDescribing Algorithms\n\nYou will often be called upon to \"give an algorithm\" to solve a certain problem. Your write-up should take the form of a short essay. A topic paragraph should summarize the problem you are solving and what your results are. The body of your essay should provide the following:\n\nA description of the algorithm in English and, if helpful, pseudocode.\n\nAt least one worked example or diagram to show more precisely how your algorithm works.\n\nA proof (or indication) of the correctness of the algorithm.\n\nAn analysis of the running time of the algorithm.\n\nRemember, your goal is to communicate. Graders will be instructed to take off points for convoluted and obtuse descriptions.\n\nGrading Policy\n\nThe final grade will be primarily based on problem sets, one in-class quiz (\nQ1\n), one take-home quiz (\nQ2\n), and a final. The problem sets will together be worth about 80 points, the in-class quiz about 80 points, the take-home quiz about 150 points, and the final exam about 180 points.\n\nAlthough the problem sets account for only 80 points in your final grade, you must do them. The following table shows the impact of failing to do problems:\n\nPROBLEMS SKIPPED\n\nIMPACT\n\nNone\n\nOne-hundredth of a Letter Grade\n\nOne-tenth of a Letter Grade\n\nOne-fifth of a Letter Grade\n\nOne-fourth of a Letter Grade\n\nOne-third of a Letter Grade\n\nOne-half of a Letter Grade\n\nOne Letter Grade\n\nTwo Letter Grades\n\n9 or more\n\nFail\n\nPlease observe that this table is for\nproblems\nskipped, not\nproblem sets\n. The specifics of this grading policy are subject to change if the need arises.\n\nCollaboration Policy\n\nThe goal of homework is to give you practice in mastering the course material. Consequently, you are encouraged to collaborate on problem sets. In fact, students who form study groups generally do better on exams than do students who work alone. If you do work in a study group, however, you owe it to yourself and your group to be prepared for your study group meeting. Specifically, you should spend at least 30-45 minutes trying to solve each problem beforehand. If your group is unable to solve a problem, talk to other groups or ask your recitation instructor.\n\nYou must write up each problem solution by yourself without assistance\n, however, even if you collaborate with others to solve the problem. You are asked on problem sets to identify your collaborators. If you did not work with anyone, you should write \"Collaborators: none.\" If you obtain a solution through research (e.g., on the Web), acknowledge your source, but write up the solution in your own words.\nIt is a violation of this policy to submit a problem solution that you cannot orally explain to a member of the course staff\n.\n\nNo collaboration whatsoever is permitted on exams\n. The course has a take-home exam for the second quiz which you must do entirely on your own, even though you will be permitted several days in which to do the exam. More details about the collaboration policy for the take-home exam will be forthcoming in lecture 20. Please note that this lecture constitutes part of the exam, and attendance is mandatory.\n\nPlagiarism and other anti-intellectual behavior cannot be tolerated in any academic environment that prides itself on individual accomplishment. If you have any questions about the collaboration policy, or if you feel that you may have violated the policy, please talk to one of the course staff. Although the course staff is obligated to deal with cheating appropriately, we are more understanding and lenient if we find out from the transgressor himself or herself rather than from a third party.\n\nThis course has great material, so have fun!",
  "files": [
    {
      "category": "Resource",
      "title": "ps1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/21bf373b58dcd53a7650a8072a76a448_ps1.pdf",
      "content": "Introduction to Algorithms\nSeptember 7, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 5\nProblem Set 1\nMIT students: This problem set is due in lecture on Wednesday, September 21, 2005. The\nhomework lab for this problem set will be held 2-4 P.M. on Sunday, September 18, 2005.\nReading: Chapters 1-4 excluding Section 4.4.\nBoth exercises and problems should be solved, but only the problems should be turned in.\nExercises are intended to help you master the course material. Even though you should not turn in\nthe exercise solutions, you are responsible for material covered in the exercises.\nMark the top of each sheet with your name, the course number, the problem number, your\nrecitation section, the date and the names of any students with whom you collaborated.\nYou will often be called upon to \"give an algorithm\" to solve a certain problem. Your write-up\nshould take the form of a short essay. A topic paragraph should summarize the problem you are\nsolving and what your results are. The body of the essay should provide the following:\n1. A description of the algorithm in English and, if helpful, pseudo-code.\n2. At least one worked example or diagram to show more precisely how your algorithm works.\n3. A proof (or indication) of the correctness of the algorithm.\n4. An analysis of the running time of the algorithm.\nRemember, your goal is to communicate. Full credit will be given only to correct solutions\nwhich are described clearly. Convoluted and obtuse descriptions will receive low marks.\nExercise 1-1.\nDo Exercise 2.3-6 on page 37 in CLRS.\nExercise 1-2.\nDo Exercise 3.1-6 on page 50 in CLRS.\nExercise 1-3.\nDo Exercise 3.2-4 on page 57 in CLRS.\nExercise 1-4.\nDo Problem 4.3-4 on page 75 of CLRS.\nProblem 1-1.\nAsymptotic Notation\nFor each of the following statements, decide whether it is always true, never true, or sometimes\ntrue for asymptotically nonnegative functions\nand\n. If it is always true or never true, explain\nwhy. If it is sometimes true, give one example for which it is true, and one for which it is false.\n\nHandout 5: Problem Set 1\n(a)\n\n(b)\n\n(c)\n\n!\"#$%!\"#\n(d)\n'&(\n\nand\n$)*\n\n\"#\n(note the little-\n) )\n(e)\n+\n\n# and\n\n,+\n$\n-\nProblem 1-2.\nRecurrences\nGive asymptotic upper and lower bounds for\n.\n\" in each of the following recurrences. Assume\nthat\n.\nis constant for\n0/2143 . Make your bounds as tight as possible, and justify your answers.\n(a)\n.\n$5\n.\n6879: ;=<\n(b)\n.\n\" '7\n.\n\"6?>?\"@;=<\n\n(c)\n.\n\n.\n\"6?5?5A\n(d)\n.\n\"\n.\nCB\nD%;=< ;=<\n(e)\n.\nE143\n.\n687?\"1GFIHCJ\n\n(f)\n.\n\" $F\n.\n\"6?5?\"@:K\n(g)\n.\n\n.\n\"6?5L\nB\n\"\nB\nM\n38N\nM\n(h)\n.\n\"\n.\nPO 5?@;=<\n(i)\n.\n\"\n.\n\"6?>?\n.\nN?6?>8\"D%\"\n(j)\n.\n\"\nB\n\n.\n\nB\n\"143838\nProblem 1-3.\nUnimodal Search\nAn array\nQSR\n1 TUT#WV is unimodal if it consists of an increasing sequence followed by a decreasing\nsequence, or more precisely, if there is an index\nXZY\\[\n185*UTUT]T^_I` such that\na\nQSRcb\nVed\nQSRcb\n1]V for all\n1f/\nb\nd\nX\n, and\na\nQSRcb\nVeg\nQSRcb\n1]V for all\nX\n/\nb\ndD .\nIn particular,\nQSRcX\nV is the maximum element, and it is the unique \"locally maximum\" element\nsurrounded by smaller elements (\nQhRiX\nOj1]V and\nQhRiX\n1]V ).\n(a) Give an algorithm to compute the maximum element of a unimodal input array\nQhR\n1 TUTkV\nin\n\n-;=<\" time. Prove the correctness of your algorithm, and prove the bound on its\nrunning time.\nA polygon is convex if all of its internal angles are less than\n14l?3nm (and none of the edges cross each\nother). Figure 1 shows an example. We represent a convex polygon as an array\noR\n1 TUTkV where\neach element of the array represents a vertex of the polygon in the form of a coordinate pair\nqpe_rs .\nWe are told that\no-R\n1]V is the vertex with the minimum\np\ncoordinate and that the vertices\noR\n1 TUT#WV\nare ordered counterclockwise, as in the figure. You may also assume that the\np\ncoordinates of the\nvertices are all distinct, as are the\nr coordinates of the vertices.\n\nHandout 5: Problem Set 1\ntfucv^w\ntfucx^w\ntfucy^w\ntfu{z#w\nt|uc}^w\ntfuc~^w\ntfu\nUw\ntfuc^w\ntfuiw\nFigure 1: An example of a convex polygon represented by the array\noR\n1 TUT_V .\noR\n1]V is the vertex\nwith the minimum\np -coordinate, and\noR\n1 TUT#V are ordered counterclockwise.\n(b) Give an algorithm to find the vertex with the maximum\np coordinate in\n\n;< time.\n(c) Give an algorithm to find the vertex with the maximum\nr coordinate in\n\n;< time."
    },
    {
      "category": "Resource",
      "title": "ps1sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/1fa860afa3b3889551cecd686afdf8de_ps1sol.pdf",
      "content": "Introduction to Algorithms\nSeptember 30, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 8\nProblem Set 1 Solutions\nProblem 1-1.\nAsymptotic Notation\nFor each of the following statements, decide whether it is always true, never true, or sometimes\ntrue for asymptotically nonnegative functions f and g. If it is always true or never true, explain\nwhy. If it is sometimes true, give one example for which it is true, and one for which it is false.\n(a) f(n) = O(f(n)2)\nSolution: Sometimes true: For f(n) = n it is true, while for f(n) = 1/n it is not\ntrue. (The statement is always true for f(n) = Ω(1), and hence for most functions\nwith which we will be working in this course, and in particular all time and space\ncomplexity functions).\n(b) f(n) + g(n) = Θ (max (f(n), g(n)))\nSolution: Always true: max(f(n), g(n)) ≤f(n) + g(n) ≤2 max(f(n), g(n)).\n(c) f(n) + O(f(n)) = Θ(f(n))\nSolution: Always true: Consider f(n) + g(n) where g(n) = O(f(n)) and let c be a\nconstant such that 0 ≤g(n) < cf(n) for large enough n. Then f(n) ≤f(n)+g(n) ≤\n(1 + c)f(n) for large enough n.\n(d) f(n) = Ω(g(n)) and f(n) = o(g(n))\n(note the little-o)\nSolution: Never true: If f(n) = Ω(g(n)) then there exists positive constant cΩand\nnΩsuch that for all n > nΩ, cg(n) ≤f(n). But if f(n) = o(g(n)), then for any\npositive constant c, there exists no(c) such that for all n > no(c), f(n) < cg(n). If\nf(n) = Ω(g(n)) and f(n) = o(g(n)), we would have that for n > max(nΩ, no(cΩ))\nit should be that f(n) < cΩg(n) ≤f(n) which cannot be.\n(e) f(n) = O(g(n)) and g(n) = O(f(n))\nSolution: Sometimes true: For f(n) = 1 and g(n) = ∥n ∗sin(n)∥it is true, while\nfor any f(n) = O(g(n)), e.g. f(n) = g(n) = 1, it is not true.\n\nHandout 8: Problem Set 1 Solutions\nProblem 1-2.\nRecurrences\nGive asymptotic upper and lower bounds for T(n) in each of the following recurrences. Assume\nthat T(n) is constant for n ≤3. Make your bounds as tight as possible, and justify your answers.\n(a) T(n) = 2T(n/3) + n lg n\nSolution: By Case 3 of the Master Method, we have T(n) = Θ(n lg n).\n(b) T(n) = 3T(n/5) + lg2 n\nSolution: By Case 1 of the Master Method, we have T(n) = Θ(nlog5(3)).\n(c) T(n) = T(n/2) + 2n\nSolution:\nCase 3 of master's theorem, (check that the regularity condition holds),\nΘ(2n).\n(d) T(n) = T(√n) + Θ(lg lg n)\nSolution:\nChange of variables: let m = lg n.\nRecurrence becomes S(m) =\nS(m/2) + Θ(lg m). Case 2 of master's theorem applies, so T(n) = Θ((lg lg n)2).\n(e) T(n) = 10T(n/3) + 17n1.2\nSolution:\nSince log3 9 = 2, so log3 10 > 2 > 1.2. Case 1 of master's theorem\napplies, Θ(nlog3 10).\n(f) T(n) = 7T(n/2) + n3\nSolution: By Case 3 of the Master Method, we have T(n) = Θ(n3).\n(g) T(n) = T(n/2 + √n) +\n√\nSolution: By induction, T(n) is a monotonically increasing function. Thus, for large\nenough n, T(n/2) ≤T(n/2+√n) ≤T(3n/4). At each stage, we incur constant cost\n√\n6046, but we decrease the problem size to atleast one half and at most three-quarters.\nTherefore T(n) = Θ(lg n).\n\nHandout 8: Problem Set 1 Solutions\n(h) T(n) = T(n -2) + lg n\nSolution: T(n) = Θ(n log n). This is T(n) = Pn/2\ni=1 lg 2i ≥Pn/2\ni=1 lg i ≥(n/4)(lg n/4) =\nΩ(n lg n). For the upper bound, note that T(n) ≤S(n), where S(n) = S(n-1)+lg n,\nwhich is clearly O(n lg n).\n(i) T(n) = T(n/5) + T(4n/5) + Θ(n)\nSolution: Master's theorem doesn't apply here. Draw recursion tree. At each level,\ndo Θ(n) work. Number of levels is log5/4 n = Θ(lg n), so guess T(n) = Θ(n lg n) and\nuse the substitution method to verify guess.\nIn the f(n) = Θ(n) term, let the constants for Ω(n) and O(n) be n0, c0 and c1, respec-\ntively. In other words, let for all n ≥n0, we have c0n ≤f(n) ≤c1n.\n- First, we show T(n) = O(n).\nFor the base case, we can choose a sufficiently large constant d1 such that T(n) <\nd1n lg n.\nFor the inductive step, assume for all k < n, that T(k) < d1n lg n. Then for\nk = n, we have\nT(n)\n≤\nT\nn\n\n+ T\n4n\n\n+ c1n\n≤\nd1\nn\n5 lg\nn\n\n+ d1\n4n\n5 lg\n4n\n\n+ c1n\n=\nd1n lg n -d1n\n5 lg 5 -4d1n\nlg\n\n+ c1n\n=\nd1n lg n -n\nlg 5 + 4 lg(5/4)\n!\nd1 -c1\n!\n.\nThe residual is negative as long as we pick d1 > 5c1/(lg 5+4 lg(5/4)). Therefore,\nby induction, T(n) = O(n lg n).\n- To show that T(n) = Ω(n), we can use almost the exact same math.\nFor the base case, we choose a sufficiently small constant d0 such that T(n) >\nd0n lg n.\nFor the inductive step, assume for all k < n, that T(k) > d0n lg n. Then, for\nk = n, we have\nT(n)\n≥\nT\nn\n\n+ T\n4n\n\n+ c0n\n≥\nd0\nn\n5 lg\nn\n\n+ d0\n4n\n5 lg\n4n\n\n+ c0n\n=\nd0n lg n + n\n\nc0 -\nlg 5 + 4 lg(5/4)\n!\nd0\n!\n.\n\nHandout 8: Problem Set 1 Solutions\nThe residual is positive as long as d0 < 5c0/(lg 5 + 4 lg(5/4)). Thus, T(n) =\nΩ(n lg n).\n(j) T(n) = √n T(√n) + 100n\nSolution: Master's theorem doesn't apply here directly. Pick S(n) = T(n)/n. The\nrecurrence becomes S(n) = S(√n) + 100. The solution of this recurrece is S(n) =\nΘ(lg lg n). (You can do this by a recursion tree, or by substituting m = lg n again.)\nTherefore, T(n) = Θ(n lg lg n).\nProblem 1-3.\nUnimodal Search\nAn array A[1 . . n] is unimodal if it consists of an increasing sequence followed by a decreasing\nsequence, or more precisely, if there is an index m ∈{1, 2, . . ., n} such that\n- A[i] < A[i + 1] for all 1 ≤i < m, and\n- A[i] > A[i + 1] for all m ≤i < n.\nIn particular, A[m] is the maximum element, and it is the unique \"locally maximum\" element\nsurrounded by smaller elements (A[m -1] and A[m + 1]).\n(a) Give an algorithm to compute the maximum element of a unimodal input array A[1 . . n]\nin O(lg n) time. Prove the correctness of your algorithm, and prove the bound on its\nrunning time.\nSolution: Notice that by the definition of unimodal arrays, for each 1 ≤i < n either\nA[i] < A[i + 1] or A[i] > A[i + 1]. The main idea is to distinguish these two cases:\n1. By the definition of unimodal arrays, if A[i] < A[i + 1], then the maximum\nelement of A[1..n] occurs in A[i + 1..n].\n2. In a similar way, if A[i] > A[i + 1], then the maximum element of A[1..n] occurs\nin A[1..i].\nThis leads to the following divide and conquer solution (note its resemblance to binary\nsearch):\n1 a, b ←1, n\n2 while a < b\ndo mid ←⌊(a + b)/2⌋\nif A[mid] < A[mid + 1]\nthen a ←mid + 1\nif A[mid] > A[mid + 1]\nthen b ←mid\n8 return A[a]\n\nHandout 8: Problem Set 1 Solutions\nThe precondition is that we are given a unimodal array A[1..n]. The postcondition is\nthat A[a] is the maximum element of A[1..n]. For the loop we propose the invariant\n\"The maximum element of A[1..n] is in A[a..b] and a ≤b\".\nWhen the loop completes, a ≥b (since the loop condition failed) and a ≤b (by\nthe loop invariant). Therefore a = b, and by the first part of the loop invariant the\nmaximum element of A[1..n] is equal to A[a].\nWe use induction to prove the correctness of the invariant. Initially, a = 1 and b = n,\nso, the invariant trivially holds. Suppose that the invariant holds at the start of the loop.\nThen, we know that the maximum element of A[1..n] is in A[a..b]. Notice that A[a..b]\nis unimodal as well. If A[mid] < A[mid + 1], then the maximum element of A[a..b]\noccurs in A[mid+1..b] by case 1. Hence, after a ←mid+1 and b remains unchanged\nin line 4, the maximum element is again in A[a..b]. The other case is symmetric.\nTo complete the proof, we need to show that the second part of the invariant a ≤b is\nalso true. At the start of the loop a < b. Therefore, a ≤⌊(a + b)/2⌋< b. This means\nthat a ≤mid < b such that after line 4 or line 5 in which a and b get updated a ≤b\nholds once more.\nThe divide and conquer approach leads to a running time of T(n) = T(n/2)+Θ(1) =\nΘ(lg n).\nA polygon is convex if all of its internal angles are less than 180*(and none of the edges cross each\nother). Figure 1 shows an example. We represent a convex polygon as an array V [1 . . n] where\neach element of the array represents a vertex of the polygon in the form of a coordinate pair (x, y).\nWe are told that V [1] is the vertex with the minimum x coordinate and that the vertices V [1 . . n]\nare ordered counterclockwise, as in the figure. You may also assume that the x coordinates of the\nvertices are all distinct, as are the y coordinates of the vertices.\n(b) Give an algorithm to find the vertex with the maximum x coordinate in O(lg n) time.\nSolution: Notice that the x-coordinates of the vertices form a unimodal array and we\ncan use part (a) to find the vertex with the maximum x-coordinate in Θ(lg n) time.\n(c) Give an algorithm to find the vertex with the maximum y coordinate in O(lg n) time.\nSolution: After finding the vertex V [max] with the maximum x-coordinate, notice\nthat the y-coordinates in V [max], V [max + 1], . . . , V [n -1], V [n], V [1] form a uni-\nmodal array and the maximum y-coordinate of V [1..n] lies in this array. Again part\n(a) can be used to find the vertex with the maximum y-coordinate. The total running\ntime is Θ(lg n).\n\nHandout 8: Problem Set 1 Solutions\nV [5]\nV [8]\nV [9]\nV [1]\nV [2]\nV [3]\nV [4]\nV [6]\nV [7]\nFigure 1: An example of a convex polygon represented by the array V [1 . . 9]. V [1] is the vertex\nwith the minimum x-coordinate, and V [1 . . 9] are ordered counterclockwise."
    },
    {
      "category": "Resource",
      "title": "ps2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/50cf7a38931c43f09bd71e7256cb2789_ps2.pdf",
      "content": "Introduction to Algorithms\nSeptember 21, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 6\nProblem Set 2\nMIT students: This problem set is due in lecture on Monday, October 3, 2005. The homework\nlab for this problem set will be held 2-4 P.M. on Sunday, October 2, 2005.\nSMA students:\nReading: Sections 5.1-5.3 and Chapters 6, 7, and 9.\nBoth exercises and problems should be solved, but only the problems should be turned in.\nExercises are intended to help you master the course material. Even though you should not turn in\nthe exercise solutions, you are responsible for material covered in the exercises.\nMark the top of each sheet with your name, the course number, the problem number, your\nrecitation section, the date and the names of any students with whom you collaborated.\nYou will often be called upon to \"give an algorithm\" to solve a certain problem. Your write-up\nshould take the form of a short essay. A topic paragraph should summarize the problem you are\nsolving and what your results are. The body of the essay should provide the following:\n1. A description of the algorithm in English and, if helpful, pseudo-code.\n2. At least one worked example or diagram to show more precisely how your algorithm works.\n3. A proof (or indication) of the correctness of the algorithm.\n4. An analysis of the running time of the algorithm.\nRemember, your goal is to communicate. Full credit will be given only to correct solutions\nwhich are described clearly. Convoluted and obtuse descriptions will receive low marks.\nExercise 2-1. Do Exercise 5.2-4 on page 98 in CLRS.\nExercise 2-2. Do Exercise 6.5-7 on page 142 in CLRS.\nExercise 2-3. Do Exercise 7.2-1 on page 153 in CLRS.\nExercise 2-4. Do Exercise 9.3-8 on page 193 of CLRS.\nExercise 2-5. Do Problem 9-1 on page 194 of CLRS.\n\nHandout 6: Problem Set 2\nProblem 2-1. Is this (almost) sorted?\nHarry Potter, the child wizard of Hogwarts fame, has once again run into trouble. Professor Snape\nhas sent Harry to detention and assigned him the task of sorting all the old homework assignments\nfrom the last 200 years. Being a wizard, Harry waves his wand and says, ordinatus sortitus, and\nthe papers rapidly pile themselves in order.\nProfessor Snape, however, wants to determine whether Harry's spell correctly sorted the papers.\nUnfortunately, there are a large number n of papers and determining whether they are in perfect\norder takes\n(n) time.\nProfessor Snape instead decides to check whether the papers are almost sorted. He wants to know\nwhether 90% of the papers are sorted: is it possible to remove 10% of the papers and have the\nresulting list be sorted?\nIn this problem, we will help Professor Snape to find an algorithm that takes as input a list A\ncontaining n distinct elements, and acts as follows:\n- If the list A is sorted, the algorithm always returns true.\n- If the list A is not 90% sorted, the algorithm returns false with probability at least 2/3.\n(a) Professor Snape first considers the following algorithm:\nRepeat k times:\n1. Choose a paper i independently and uniformly at random from the open in\nterval (1, n). (That is, 1 < i < n.)\n2. Compare paper A[i - 1] and A[i]. Output false and halt if they are not sorted\ncorrectly.\n3. Compare paper A[i] and A[i + 1]. Output false and halt if they are not sorted\ncorrectly.\nOutput true.\nShow that for this algorithm to correctly discover whether the list is almost sorted\nwith probability at least 2/3 requires k =\n(n). Hint: Find a sequence that is not\nalmost sorted, but with only a small number of elements that will cause the algorithm\nto return false.\n(b) Imagine you are given a bag of n balls. You are told that at least 10% of the balls are\nblue, and no more than 90% of the balls are red. Asymptotically (for large n) how\nmany balls do you have to draw from the bag to see a blue ball with probability at\nleast 2/3? (You can assume that the balls are drawn with replacement.)\n\nHandout 6: Problem Set 2\n(c) Consider performing a \"binary search\" on an unsorted list:\nBINARY-SEARCH(A, key, left, right)\nSearch for key in A[left . . right].\n1 if left = right\nthen return left\nelse mid ←(left + right)/2≤\nif key < A[mid]\nthen return BINARY-SEARCH(A, key, left, mid -1)\nelse return BINARY-SEARCH(A, key, mid, right)\nAssume that a binary search for key1 in A (even though A is not sorted) returns slot i.\nSimilarly, a binary search for key2 in A returns slot j. Explain why the following fact\nis true: if i < j, then key1 key2. Draw a picture. Hint: First think about why this is\nobviously true if list A is sorted.\n(d) Professor Snape proposes a randomized algorithm to determine whether a list is 90%\nsorted. The algorithm uses the function RANDOM(1, n) to choose an integer inde\npendently and uniformly at random in the closed interval [1, n]. The algorithm is\npresented below.\nIS-ALMOST-SORTED(A, n, k)\nDetermine if A[1 . . n] is almost sorted.\n1 for r 1 to k\ndo i RANDOM(1, n)\nPick i uniformly and independently.\nj BINARY-SEARCH(A, A[i], 1, n)\nif i 6 = j\nthen return false\n6 return true\nShow that the algorithm is correct if k is a sufficiently large constant. That is, with k\nchosen appropriately, the algorithm always outputs true if a list is correctly sorted and\noutputs false with probability at least 2/3 if the list is not 90% sorted.\n(e) Imagine instead that Professor Snape would like to determine whether a list is 1 -\nsorted for some 0 < < 1. (In the previous parts = 0.10.) For large n, determine the\nappropriate value of k, asymptotically, and show that the algorithm is correct. What is\nthe overall running time?\nProblem 2-2. Sorting an almost sorted list.\nOn his way back from detention, Harry runs into his friend Hermione. He is upset because Pro\nfessor Snape discovered that his sorting spell failed. Instead of sorting the papers correctly, each\npaper was within k slots of the proper position. Hermione immediately suggests that insertion sort\nwould have easily fixed the problem. In this problem, we show that Hermione is correct (as usual).\nAs before, A[1 . . n] in an array of n distinct elements.\n(a) First, we define an \"inversion.\" If i < j and A[i] > A[j], then the pair (i, j) is called an\n\nHandout 6: Problem Set 2\ninversion of A. What permutation of the array {1, 2, . . . , n} has the most inversions?\nHow many does it have?\n(b) Show that, if every paper is initially within k slots of its proper position, insertion\nsort runs in time O(nk). Hint: First, show that INSERTION-SORT(A) runs in time\nO(n + I), where I is the number of inversions in A.\n(c) Show that sorting a list in which each paper is within k slots of its proper position\ntakes\n(n lg k) comparisons. Hint: Use the decision-tree technique.\n(d) Devise an algorithm that matches the lower bound, i.e., sorts a list in which each paper\nis within k slots of its proper position in (n lg k) time. Hint: See Exercise 6.5-8 on\npage 142 of CLRS.\nProblem 2-3. Weighted Median.\nFor n distinct elements x1, x2, . . . , xn with positive weights w1, w2, . . . , wn such that Pn wi = 1,\ni=1\nthe weighted (lower) median is the element xk satisfying\n\nwi < 2\nxi<xk\nand\n\n1 .\nwi 2\nxi>xk\n(a) Argue that the median of x1, x2, . . . , xn is the weighted median of x1, x2, . . . , xn with\nweights wi = 1/n for i = 1, 2, . . . , n.\n(b) Show how to compute the weighted median of n elements in O(n lg n) worst-case\ntime using sorting.\n(c) Show how to compute the weighted median in (n) worst-case time using a linear-\ntime median algorithm such as SELECT from Section 9.3 of CLRS.\n(d) The post-office location problem is defined as follows. We are given n points p1, p2, . . . , pn\nwith associated weights w1, w2, . . . , wn. We wish to find a point p (not necessarily one\nof the input points) that minimizes the sum Pn wi d(p, pi), where d(a, b) is the dis-\ni=1\ntance between points a and b.\nArgue that the weighted median is a best solution for the one-dimensional post-office\nlocation problem, in which points are simply real numbers and the distance between\npoints a and b is d(a, b) = |a - b|.\n(e) Find the best solution for the two-dimensional post-office location problem, in which\nthe points are (x, y) coordinate pairs and the distance between points a = (x1, y1) and\nb = (x2, y2) is the Manhattan distance given by d(a, b) = |x1 - x2| + |y1 - y2|."
    },
    {
      "category": "Resource",
      "title": "ps2sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/918110223b953b1865bd166dac2ddf77_ps2sol.pdf",
      "content": "Introduction to Algorithms\nOctober 7, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 12\nProblem Set 2 Solutions\nProblem 2-1. Is this (almost) sorted?\nHarry Potter, the child wizard of Hogwarts fame, has once again run into trouble. Professor Snape\nhas sent Harry to detention and assigned him the task of sorting all the old homework assignments\nfrom the last 200 years. Being a wizard, Harry waves his wand and says, ordinatus sortitus, and\nthe papers rapidly pile themselves in order.\nProfessor Snape, however, wants to determine whether Harry's spell correctly sorted the papers.\nUnfortunately, there are a large number n of papers and determining whether they are in perfect\norder takes\n(n) time.\nProfessor Snape instead decides to check whether the papers are almost sorted. He wants to know\nwhether 90% of the papers are sorted: is it possible to remove 10% of the papers and have the\nresulting list be sorted?\nIn this problem, we will help Professor Snape to find an algorithm that takes as input a list A\ncontaining n distinct elements, and acts as follows:\n- If the list A is sorted, the algorithm always returns true.\n- If the list A is not 90% sorted, the algorithm returns false with probability at least 2/3.\n(a) Professor Snape first considers the following algorithm:\nRepeat k times:\n1. Choose a paper i independently and uniformly at random from the open in\nterval (1, n). (That is, 1 < i < n.)\n2. Compare paper A[i - 1] and A[i]. Output false and halt if they are not sorted\ncorrectly.\n3. Compare paper A[i] and A[i + 1]. Output false and halt if they are not sorted\ncorrectly.\nOutput true.\nShow that for this algorithm to correctly discover whether the list is almost sorted\nwith probability at least 2/3 requires k =\n(n). Hint: Find a sequence that is not\nalmost sorted, but with only a small number of elements that will cause the algorithm\nto return false.\nSolution: We show that Snape's algorithm does not work by constructing a counter\nexample that has the following two properties:\n- A is not 90% sorted.\n\n` =\n(\nY\n\nHandout 12: Problem Set 2 Solutions\n- Snape's algorithm outputs false with probability 2/3 only if k =\n(n).\nIn particular, we consider the following counter-example:\nA = [≥n/2∅+ 1, . . . , n, 1, 2, 3, . . . , ≥n/2∅] .\nLemma 1 A is not 90% sorted.\nProof.\nAssume, by contradiction, that the list is 90% sorted. Then, there must be\nsome 90% of the elements that are correctly ordered with respect to each other. There\nmust be one of these correctly ordered elements in the first half of the list, i.e., with\nindex i ≥n/2∅. Also, there must be one of these correctly ordered elements in\nthe second half of the list, i.e. with index j > ≥n/2∅. However, A[i] > A[j], by\nconstruction, which is a contradiction. Therefore A is not 90% sorted.\nLemma 2 Snape's algorithm outputs false with probability 2/3 only if k =\n(n).\nProof.\nNotice that on each iteration of the algorithm, there are only two choices that\nallow the algorithm to detect that the list is not sorted: i = ≥n/2∅or i = ≥n/2∅+ 1.\nDefine indicator random variables as follows:\n1 if i = ≥n/2∅or i = ≥n/2∅+ 1 on iteration `,\nX\n0 otherwise.\nNotice, then, that Pr{X` = 1} = 2/n and Pr{X` = 0} = (1 -2/n). Therefore, the\nprobability that Snape's algorithm does not output false for all k iterations (i.e., that\nSnape's algorithm does not work) is:\nk\n=\nPr (X` = 0)\n`=1\n2 ⎛k\n=\n1 - n\nWe want to determine the minimum value of k for which Snape's algorithm works,\nthat is, the minimum value of k such that the probability of failure is no more than 1/3:\n2 ⎛k\n1 -\n\n.\nn\nSolving for k, we determine that:\nln (1/3)\nk\n\n.\nln 1 -2\nn\nWe now recall the following math fact (see CLRS 3.11):\n\n⎛x\n1 -\n\n.\nx\ne\n\n.\n(\nY\n\n.\nHandout 12: Problem Set 2 Solutions\nFrom this, we calculate that:\n\n⎛\nln 1 -\n- .\nx\nx\nWe then conclude the following:\nln (1/3)\nk\n\nln 1 - 2\nn\nln (1/3)\n-2/n\nn ln 3\nWe conclude that Snape's algorithm is correct only if k =\n(n).\n(b) Imagine you are given a bag of n balls. You are told that at least 10% of the balls are\nblue, and no more than 90% of the balls are red. Asymptotically (for large n) how\nmany balls do you have to draw from the bag to see a blue ball with probability at\nleast 2/3? (You can assume that the balls are drawn with replacement.)\nSolution: Since the question only asked the asymptotic number of balls drawn, (1)\n(plus some justification) is a sufficient answer. Below we present a more complete\nanswer.\nAssume you draw k balls from the bag (replacing each ball after examining it).\nLemma 3 For some constant k sufficiently large, at least one ball is blue with proba\nbility 2/3.\nProof.\nDefine indicator random variables as follows:\n1 if ball i is blue\nXi =\n0 if ball i is red\nNotice, then, that Pr Xi = 1 = 1/10 and Pr Xi = 0 = 9/10. We then calculate the\nprobability that at least one ball is blue:\nk\n=\n1 -\nPr (Xi = 0)\ni=1\n9 ⎛k\n= 1 - 10\nTherefore, if k = lg(1/3)/ lg 0.9, the probability of drawing at least one blue ball is at\nleast 2/3.\n\nHandout 12: Problem Set 2 Solutions\n(c) Consider performing a \"binary search\" on an unsorted list:\nBINARY-SEARCH(A, key, left, right)\nSearch for key in A[left . . right].\n1 if left = right\nthen return left\nelse mid d(left + right)/2e\nif key < A[mid]\nthen return BINARY-SEARCH(A, key, left, mid -1)\nelse return BINARY-SEARCH(A, key, mid, right)\nAssume that a binary search for key1 in A (even though A is not sorted) returns slot i.\nSimilarly, a binary search for key2 in A returns slot j. Explain why the following fact\nis true: if i < j, then key1 key2. Draw a picture. Hint: First think about why this is\nobviously true if list A is sorted.\nSolution:\nFigure 1: An example of a binary-search decision tree of an unordered array.\nFor the purpose of understanding this problem, think of the decision-tree version of\nthe binary search algorithm. (Notice that unlike sorting algorithms, the decision tree\nfor binary search is relatively small, i.e., O(n) nodes.)\nConsider the example in Figure 1, in which a binary search is performed on the un\nsorted array [9 7 10 15 16 20 25 22]. Assume key1 = 20 and key2 = 25. Both 20\nand 25 are 25, and choose the right branch from the root. At this point, the two\nbinary searches diverge: 20 < 25 and 25 25. Therefore key1 takes the left branch\nand key2 takes the right branch. This ensures that eventually key1 and key2 are ordered\ncorrectly.\nx\nWe now generalize this argument. For key1, let x1, x2, . . . , xk be the k elements that\nare compared against key1 in line 4 of the binary search (where k = O(lg n)). (In\nthe example, x1 = 15, x2 = 25, and x3 = 20.) Let y1, y2, . . . , yt be the t elements\ncompared against key2. We know that x1 = y1. Let ` be the smallest number such that\n` ∈= y`. (In particular, ` > 1.) Since i < j, by assumption, we know that key1 cannot\n\n(\nHandout 12: Problem Set 2 Solutions\nbranch right while key2 simultaneously branches left. Hence we conclude that\nkey1 < x`-1 = y`-1 key2 .\n(Note that a relatively informal solution was acceptable for the problem, as we simply\nasked that you \"explain why\" this is true. The above argument can be more carefully\nformalized.)\n(d) Professor Snape proposes a randomized algorithm to determine whether a list is 90%\nsorted. The algorithm uses the function RANDOM(1, n) to choose an integer inde\npendently and uniformly at random in the closed interval [1, n]. The algorithm is\npresented below.\nIS-ALMOST-SORTED(A, n, k)\nDetermine if A[1 . . n] is almost sorted.\n1 for r 1 to k\ndo i RANDOM(1, n)\nPick i uniformly and independently.\nj BINARY-SEARCH(A, A[i], 1, n)\nif i ∈ = j\nthen return false\n6 return true\nShow that the algorithm is correct if k is a sufficiently large constant. That is, with k\nchosen appropriately, the algorithm always outputs true if a list is correctly sorted and\noutputs false with probability at least 2/3 if the list is not 90% sorted.\nSolution:\nOverview: In order to show the algorithm correct, there are two main\nlemmas that have to be proved: (1) If the list A is sorted, the algorithm always returns\ntrue; (2) If the list A is not 90% sorted, the algorithm returns false with probability\nat least 2/3. We begin with the more straightforward lemma, which essentially argues\nthat binary search is correct. We then show that if the list is not 90% sorted, then at\nleast 10% of the elements fail the \"binary search test.\" Finally, we conclude that for\na sufficiently large constant k, if the list is not 90% sorted, then the algorithm will\noutput false with probability at least 2/3.\nLemma 4 If the list A is sorted, the algorithm always returns true.\nProof.\nThis lemma follows from the correctness of binary search on a sorted list,\nwhich was shown in recitation one. The invariant is that key is in array A between left\nand right.\nFor the rest of this problem, we label the elements as \"good\" and \"bad\" based on\nwhether they pass the binary sort test.\ngood if i = BINARY-SEARCH(A, A[i], 1, n)\nlabel(i) =\nbad\nif i ∈= BINARY-SEARCH(A, A[i], 1, n)\n\nHandout 12: Problem Set 2 Solutions\nNotice that it is not immediately obvious which elements are good and which elements\nare bad. In particular, some elements may appear to be sorted correctly, but be bad\nbecause of other elements being missorted. Similarly, some elements may appear\nentirely out of place, but be good because of other misplaced elements. A key element\nof the proof is showing that a badly sorted list has a lot of bad elements.\nLemma 5 If the list A is not 90% sorted, then at least 10% of the elements are bad.\nProof.\nAssume, by contradiction, that fewer than 10% of the elements are bad.\nThen, at least 90% of the elements are good. Recall the definition of a 90% sorted\nlist: if 10% of the elements are removed, then the remaining elements are in sorted\norder. Therefore, remove all the bad elements from the array. We now argue that\nthe remaining elements are in sorted order. Consider any two of the remaining good\nelements, key1 and key2, where key1 is at index i and key2 is at index j. If i < j,\nthen Part(c) shows that key1 key2. Similarly, if j < i, then Part(c) shows that\nkey2 key1. That is, the two elements are in correctly sorted order. Since all pairs of\nelements are in sorted order, the array of good elements is in sorted order.\nOnce we have shown that there are a lot of bad elements, it remains to show that we\nfind a bad element through random sampling.\nLemma 6 If the list A is not 90% sorted, the algorithm returns false with probability\nat least 2/3.\nProof.\nFrom Lemma 5, we know that at least 10% of the elements are bad. From\nPart(b), we know that if we choose k > lg(1/3)/ lg 0.9, then with probability 2/3\nwe find a bad element. Therefore, we conclude that the algorithm returns false with\nprobability at least 2/3.\n(e) Imagine instead that Professor Snape would like to determine whether a list is 1 -\nsorted for some 0 < < 1. (In the previous parts = 0.10.) For large n, determine the\nappropriate value of k, asymptotically, and show that the algorithm is correct. What is\nthe overall running time?\nSolution: Lemma 4 is the same as in Part(d). A simple modification of Lemma 5\nshows that if the array is not (1-)-sorted, then there must be at least n bad elements;\notherwise, the remaining (1 - )n elements would form a (1 - )-sorted list. Finally,\nit remains to determine the appropriate value of k\nIn this case, we want to choose k such that\n(1 - )k 3\nWe choose k = c/, then we can conclude (using CLRS 3.11) that:\n(1 - )1/ c\n(1 - )k\n\n⎛c\ne\n\nHandout 12: Problem Set 2 Solutions\nWe therefore conclude that if k = (1/), the algorithm will find a bad element with\nprobability at least 2/3. The running time of the algorithm is O(lg n/).\nProblem 2-2. Sorting an almost sorted list.\nOn his way back from detention, Harry runs into his friend Hermione. He is upset because Pro\nfessor Snape discovered that his sorting spell failed. Instead of sorting the papers correctly, each\npaper was within k slots of the proper position. Hermione immediately suggests that insertion sort\nwould have easily fixed the problem. In this problem, we show that Hermione is correct (as usual).\nAs before, A[1 . . n] in an array of n distinct elements.\n(a) First, we define an \"inversion.\" If i < j and A[i] > A[j], then the pair (i, j) is called an\ninversion of A. What permutation of the array {1, 2, . . . , n} has the most inversions?\nHow many does it have?\nSolution: The permuation {n, n - 1, . . . , 2, 1} has the largest number of inversions.\nn\nIt has\n= n(n - 1)/2 inversions.\n(b) Show that, if every paper is initially within k slots of its proper position, insertion\nsort runs in time O(nk). Hint: First, show that INSERTION-SORT(A) runs in time\nO(n + I), where I is the number of inversions in A.\nSolution: Overview: First we show that INSERTION-SORT(A) runs in time O(n+ I),\nwhere I is the number of inversions, by examining the insertion sort algorithm. Then\nwe count the number of possible inversions in an array in which every element is\nwithin k slots of its proper position. We show that there are at most O(nk) inversions.\nLemma 7 INSERTION-SORT(A) runs in time O(n + I), where I is the number of\ninversions in A.\nProof.\nConsider an execution of INSERTION-SORT on an array A. In the outer loop,\nthere is O(n) work. Each iteration of the inner loop fixes exactly one inversion. When\nthe algorithm terminates, there are no inversions left. Hence, there must be I iterations\nof the inner loop, resulting in O(I) work. Therefore the running time of the algorithm\nis O(n + I).\nWe next count the number of inversions in an array in which every element is within\nk slots of its proper position.\nLemma 8 If every element is within k slots of its proper position, then there are at\nmost O(nk) inversions.\nProof.\nWe provide an upper bound on the number of inversions. Consider some\nparticular element, A[i]. There are at most 4k elements that can be inverted with A[i],\n\nHandout 12: Problem Set 2 Solutions\nin particular those elements in the range A[i - 2k . . i + 2k]. Therefore, i is a part of at\nmost 4k inversions, and hence there are at most 4nk inversions.\nFrom this we conclude that the running time of insertion sort on an array in which\nevery element is within k slots of its proper position is O(nk).\nAs a side note, it seems possible to prove this directly, without using inversions, by\nshowing that the inner loop of insertion sort never moves an element more than k\nslots. However, this is not as easy as it seems: even though an element is always\nbegins within k slots of its final position, it is necessary to show that it never moves\nfarther away. For example, what if it moves k + 2 slots backwards, and then is later\nmoved 3 slots forward? However, perhaps one can show that an element never moves\nmore than 4k slots.\n(c) Show that sorting a list in which each paper is within k slots of its proper position\ntakes\n(n lg k) comparisons. Hint: Use the decision-tree technique.\nSolution: We already know that sorting the array requires\n(n lg n) comparisons. If\nk > n/2, then n lg n =\n(n lg k), and the proof is complete. For the remainder of this\nproof, assume that k n/2.\nOur goal is to provide a lower-bound on the number of leaves in a decision tree for\nan algorithm that sorts an array in which every element is within k slots of its proper\nposition. We therefore provide a lower bound on the number of possible permutations\nthat satisfy this condition.\n(k!)\nFirst, break the array of size n into ≥n/k∅ blocks, each of size k, and the remainder\nof size n (mod k). For each block, there exist k! permutations, resulting in at least\n→n/k∗ total permutations of the entire array. None of these permutations move an\nelement more than k slots.\nNotice that this undercounts the total number of permutations, since no element moves\nfrom one k-element block to another, and we ignore permutations of elements in the\nremainder block.\nWe therefore conclude that the decision tree has at least (k!)→n/k∗ leaves. Since the\ndecision tree is a binary tree, we can then conclude that the height of the decision tree\nis\n(k!)→n/k∗\nlg\nn\n\nlg (k!)\nk\nn\n\n(c1k lg k)\nk\nc1(n - k) lg k\nc1n lg k\n=\n(n lg k)\n\nh\ni\nh\ni\nh\ni\nHandout 12: Problem Set 2 Solutions\n(The last step follows because of our assumption that k n/2.)\n(d) Devise an algorithm that matches the lower bound, i.e., sorts a list in which each paper\nis within k slots of its proper position in (n lg k) time. Hint: See Exercise 6.5-8 on\npage 142 of CLRS.\nSolution: For the solution to this problem, we are going to use a heap. We assume\nthat we have a heap with the following subroutines:\n- MAKE-HEAP() returns a new empty heap.\n- INSERT(H, key, value) inserts the key/value pair into the heap.\n- EXTRACT-MIN(H) removes the key/value pair with the smallest key from the\nheap, returning the value.\nFirst, consider the problem of merging t sorted lists. Assume we have lists A1, . . . , At,\neach of which is sorted. We use the following strategy (pseudocode below):\n1. Make a new heap, H.\n2. For each of the t lists, insert the first element into the list. For list i, perform\nINSERT(H, At[1], i).\n3. Repeat n times:\n(a) Remove the smallest element from the heap using EXTRACT-MIN(H). Let v\nbe the value returned, which is the identity of the list.\n(b) Put the extracted element from list v in order in a new array.\n(c) Insert the next element from the list v.\nThe key invariant is to show that after every iteration of the loop, the heap contains\nthe smallest element in every list. (We omit a formal induction proof, as the question\nonly asked you to devise an algorithm.) Notice that each EXTRACT-MIN and INSERT\noperation requires O(lg k) time, since there are never more than 2k elements in the\nheap. The loop requires only a constant amount of other work, and is repeated n\ntimes, resulting in O(n lg k) running time.\nIn order to apply this to our problem, we consider A as a set of sorted lists. In partic\nular, notice that A[i] < A[i + 2k + 1], for all i n - 2k - 1: the element at slot i can\nat most move forwards during sorting to slot i + k and the element at slot i + 2k + 1\ncan at most move backwards during sorting to slot i + k + 1.\nFor the moment, assume that n is divisble by 2k. We consider the the t = 2k lists\ndefined as follows:\nA1 =\nA[1], A[2k + 1], A[4k + 1], . . . A[n - (2k - 1)]\nA2 =\nA[2], A[2k + 2], A[4k + 2], . . . A[n - (2k - 2)]\n. . . At =\nA[2k], A[4k], A[6k], . . . , A[n]\n\nHandout 12: Problem Set 2 Solutions\nEach of these lists is sorted, and each is of size n. Therefore, we can sort these lists\nin O(n lg k) time using the procedure above.\nWe now present the more precise pseudocode:\nSORT-ALMOST-SORTED(A, n, k) Sort A if every element is within k slots of its proper position.\n1 H MAKE-HEAP()\n2 for i 1 to 2k\ndo INSERT(H, A[i], i)\n4 for i 1 to n\ndo j EXTRACT-MIN(H)\nB[i] A[j]\nif j + 2k n\nthen INSERT(H, A[j + 2k], j)\n9 return B\nRecall that a heap is generally used to store a key and its associated value, even though\nwe often ignore the value when describing the heap operations. In this case, the value\nis an index j, while the key is the element A[j]. As a result, the heap returns the index\nof the next smallest element in the array.\nCorrectness and performance follow from the argument above.\nNotice that there is a second way of solving this problem. Recall that we already\nknow how to merge two sorted lists that (jointly) contain n elements in O(n) time. It\nis possible, then to merge the lists in a tournament. We give an example for k = 8,\nwhere A + B means to merge lists A and B:\nRound 1: (A1 + A2), (A3 + A4), (A5 + A6), (A7 + A8)\nRound 2:\n(A1 + A2 + A3 + A4), (A5 + A6 + A7 + A8)\nRound 3:\n(A1 + A2 + A3 + A4 + A5 + A6 + A7 + A8)\nNotice that there are lg k merge steps, each of which merges n elements (dispersed\nthrough up to k lists) and hence has a cost of O(n). This leads to the desired running\ntime of O(n lg k).\nProblem 2-3. Weighted Median.\nn\nFor n distinct elements x1, x2, . . . , xn with positive weights w1, w2, . . . , wn such that\nP\ni=1 wi = 1,\nthe weighted (lower) median is the element xk satisfying\nX\nwi < 2\nxi<xk\nand\nX\nwi\n.\nxi>xk\n\nHandout 12: Problem Set 2 Solutions\n(a) Argue that the median of x1, x2, . . . , xn is the weighted median of x1, x2, . . . , xn with\nweights wi = 1/n for i = 1, 2, . . . , n.\nSolution: Let xk be the median of x1, x2, . . . , xn. By the definition of median, xk\n⎠\n⎝\nis larger than exactly\nn+1 - 1 other elements xi. Then the sum of the weights of\nelements less than xk is\n\n⎛\nX\nn + 1\nwi =\n·\n- 1\nn\nxi<xk\nn - 1\n=\n·\nn\nn - 1\n2n\nn\n< 2n\n< 2\n⎠\n⎝\nSince all the elements are distinct, xk is also smaller than exactly n -\nn+1 other\nelements. Therefore\n\n⎛\nX\nn + 1\nwi =\n· n -\nn\nxi>xk\nn + 1\n=\n1 -\n·\nn\n⎛ ⎛\nn\n1 - n\nTherefore by the definition of weighted median, xk is also the weighted median.\n(b) Show how to compute the weighted median of n elements in O(n lg n) worst-case\ntime using sorting.\nSolution: To compute the weighted median of n elements, we sort the elements and\nthen sum up the weights of the elements until we have found the median.\n\nX\nX\nX\n\n!\nHandout 12: Problem Set 2 Solutions\n1 WEIGHTED-MEDIAN(A)\n2 k 1\n3 s 0\ns = Total weight of all xi < xk\n4 while s + wk < 1/2\ndo s s + wk\nk k + 1\n7 return xk\nThe loop invariant of this algorithm is that s is the sum of the weights of all elements\nless than xk :\ns =\nwi\nxi<xk\nWe prove this is true by induction. The base case is true because in the first iteration\ns = 0. Since the list is sorted, for all i < k, xi < xk . By induction, s is correct because\nin every iteration through the loop s increases by the weight of the next element.\nThe loop is guaranteed to terminate because the sum of the weights of all elements\nis 1. We prove that when the loop terminates xk is the weighted median using the\ndefinition of weighted median.\nLet s0 be the value of s at the start of the next to last iteration of the loop: s = s0 +wk-1.\nSince the next to last iteration did not meet the termination condition, we know\ns + wk-1 < 2\nX\n= s\n<\nwi\nxi <xk\nNote that if the loop has zero iterations this is still true since s = 0 < 1 . This proves\nthe first condition for being a weighted median. Next we prove the second condition.\nThe sum of the weights of elements greater than xk is\nwi = 1 -\nwi - wk = 1 - s - wk\nxi>xk\nxi<xk\nBy the loop termination condition,\nX\nwi = s\n- wk\nxi<xk\n-s\n- + wk\n\nHandout 12: Problem Set 2 Solutions\n1 -s -wi 2\nX\nwi 2\nxi>xk\nThus xk also satisfies the second condition for being the weighted median. Therefore\nxk is the median and the algorithm is correct.\nThe running time of the algorithm is the time required to sort the array plus the time\nrequired to find the median. We can sort the array in O(n lg n) time. The loop in\nWEIGHTED-MEDIAN has O(n) iterations requiring O(1) time per iteration, so the\noverall running time is O(n lg n).\n(c) Show how to compute the weighted median in (n) worst-case time using a linear-\ntime median algorithm such as SELECT from Section 9.3 of CLRS.\nSolution: The weighted median can be computed in (n) worst case time given a\n(n) time median algorithm. The basic strategy is similar to a binary search: the\nalgorithm computes the median and recurses on the half of the input that contains the\nweighted median.\nLINEAR-TIME-WEIGHTED-MEDIAN(A, l)\n2 n length[A]\n3 m MEDIAN(A)\n4 B ←\nB = {A[i] < m}\n5 C ←\nC = {A[i] m}\n6 wB 0\nwB = total weight of B\n7 if length[A] = 1\nthen return A[1]\n9 for i 1 to n\ndo if A[i] < m\nthen wB wB + wi\nAppend A[i] to array B\nelse Append A[i] to array C\n14 if l + wB > 1\nWeighted median ≤B\nthen LINEAR-TIME-WEIGHTED-MEDIAN(B, l)\nelse LINEAR-TIME-WEIGHTED-MEDIAN(C, wB )\nThe initial call to this algorithm is LINEAR-TIME-WEIGHTED-MEDIAN(A, 0). In\nthis algorithm, A is an array that contains the median of the initial input and l is the\ntotal weight of the elements of the initial input that are less than all the elements of A.\nB contains all elements less than the median, C contains all elements greater or equal\nto the median, and wB is the total weight of the elements in B.\n\nX\nX\nX\nHandout 12: Problem Set 2 Solutions\nTo prove this algorithm is correct, we show that the following precondition holds for\nevery recursive call: the weighted median y of the initial A is always present in the\nrecursive calls of A, and l is the total weight of all elements xi less than all the the\nelements of A. This precondition is trivially true for the initial call. We prove that the\nprecondition is also true in every recursive call by induction. Assume for induction\nthat the precondition is true. First let us consider the case in which l + wB > . Since\ny must be in A, at line 14 y must be either in B or C. Since the total weight of all\nelements less than any element in C is greater than 1/2, then by definition the weighted\nmedian cannot be in C, so it must be in B. Furthermore, we have not discarded any\nelements less than any element in B, so l is correct and the precondition is satisfied.\nIf l + wB 1 on line 14, then y must be in C. All elements of C are greater than all\nelements of B, so the total weight of the elements less than the elements of C is l+wB\nand the precondition of the recursive call is also satisfied. Therefore by induction the\nprecondition is always true.\nThis algorithm always terminates because the size of A decreases for every recursive\ncall. When the algorithm terminates, the result is correct. Since the weighted median\nis always in A, then when only one element remains it must be the weighted median.\nThe algorithm runs in (n) time. Computing the median and splitting A into B and\nC takes (n) time. Each recursive call reduces the size of the array from n to dn/2e.\nTherefore the recurrence is T(n) = T(n/2) + (n) = (n).\n(d) The post-office location problem is defined as follows. We are given n points p1, p2, . . . , pn\nwith associated weights w1, w2, . . . , wn. We wish to find a point p (not necessarily one\nn\nof the input points) that minimizes the sum P\nwi d(p, pi), where d(a, b) is the dis-\ni=1\ntance between points a and b.\nArgue that the weighted median is a best solution for the one-dimensional post-office\nlocation problem, in which points are simply real numbers and the distance between\npoints a and b is d(a, b) = |a - b|.\nSolution:\nWe argue that the solution to the one-dimensional post-office location problem is the\nweighted median of the points. The objective of the post-office location problem is to\nchoose p to minimize the cost\nn\nc(p) =\nwid(p, pi)\ni=1\nWe can rewrite c(p) as the sum of the cost contributed by points less than p and points\ngreater than p:\nc(p) = ⎞\nwi(p - pi)A + ⎞\nwi(pi - p)A\npi<p\npi>p\n\nX\nX\nX\nX\nX\nX\n\n!\n\n!\nHandout 12: Problem Set 2 Solutions\nNote that if p = pk for some k, then that point does not contribute to the cost. This\ncost function is continuous because limp!x c(p) = c(x) for all x. To find the minima\nof this function, we take the derivative with respect to p:\ndc\nX\nX\n= ⎞\nwiA - ⎞\nA\nwi\ndp\npi<p\npi>p\nNote that this derivative is undefined where p = pi for some i because the left- and\nright-hand limits of c(p) differ. Note also that dc\ndp is a non-decreasing function because\ndc\nas p increases, the number of points pi < p cannot decrease. Note that dp < 0 for\np < min(p1, p2, . . . , pn) and dc > 0 for p > max(p1, p2, . . . , pn). Therefore there is\ndp\nsome point p such that dc 0 for points p < p and dc 0 for points p > p, and\ndp\ndp\nthis point is a global minimum. We show that the weighted median y is such a point.\nFor all points p < y where p is not the weighted median and p ∈= pi for some i,\nwi <\nwi\npi<p\npi>p\ndc\nThis implies that dp < 0. Similarly, for points p > y where p is not the weighted\nmedian and p ∈= pi for some i,\nwi >\nwi\npi<p\npi>p\nThis implies that dp > 0. For the cases where p = pi for some i and p ∈\ndc\n= y, both\nthe left- and right-hand limits of dc\ndp always have the same sign so the same argument\napplies. Therefore c(p) > c(y) for all p that are not the weighted median, so the\nweighted median y is a global minimum.\n(e) Find the best solution for the two-dimensional post-office location problem, in which\nthe points are (x, y) coordinate pairs and the distance between points a = (x1, y1) and\nb = (x2, y2) is the Manhattan distance given by d(a, b) = |x1 - x2| + |y1 - y2|.\nSolution:\nSolving the 2-dimensional post-office location problem using Manhattan distance is\nequivalent to solving the one-dimensional post-office location problem separately for\neach dimension. Let the solution be p = (px, py ). Notice that using Manhattan dis\ntance we can write the cost function as the sum of two one-dimensional post-office\nlocation cost functions as follows:\nn\nn\ng(p) =\nwi|xi - px| +\nwi|yi - py |\ni=1\ni=1\n\nHandout 12: Problem Set 2 Solutions\ng\nNotice also that\ndoes not depend on the y coordinates of the input points and has\npx\ndc\nexactly the same form as dp from the previous part using only the x coordinates as\ng\ninput. Similarly, px depends only on the y coordinate. Therefore to minimize g(p),\nwe can minimize the cost for the two dimensions independently. The optimal solution\nto the two dimensional problem is to let px be the solution to the one-dimensional\npost-office location problem for inputs x1, x2, . . . , xn, and py be the solution to the\none-dimensional post-office location problem for inputs y1, y2, . . . , yn."
    },
    {
      "category": "Resource",
      "title": "final_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/d9a4dadcde8f58811056d4bf5bc403df_final_sol.pdf",
      "content": "Introduction to Algorithms\nDecember 23, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 36\nFinal Exam Solutions\nFinal Exam Score Distribution\n# of students\n\nHandout 36: Final Exam Solutions\nProblem 1. Recurrences [15 points] (3 parts)\nGive a tight asymptotic upper bound (O notation) on the solution to each of the following recur\nrences. You need not justify your answers.\n(a) T (n) = 2T (n/8) + ∈n.\nSolution: (n1/3 lg n) by Case 2 of the Master Method.\n(b) T (n) = T (n/3) + T (n/4) + 5n\nSolution: (n).\n⎤\n8T (n/2) + (1) if n2 > M ,\n(c) T (n) =\nM\nif n\nM ;\n2 ←\nwhere M is a variable independent from n.\nSolution: n3/\n∈\nM . The recursion tree has approximately lg n - lg\n∈\nM =\nlg n/\n∈\nM levels. In the tree, every internal node has 8 children, each with cost\n\nO(1). At the bottom of the tree, there are approximately 8lg(n/\np\nM ) = n/\n∈\nM\nleaves. Since each leaf costs M , and the total cost is dominated by the leaves, the\n\nsolution is M n/\n∈\nM\n= n3/\n∈\nM .\n\nHandout 36: Final Exam Solutions\nProblem 2. Algorithms and running times [9 points]\nMatch each algorithm below with the tightest asymptotic upper bound for its worst-case running\ntime by inserting one of the letters A, B, . . ., I into the corresponding box. For sorting algorithms,\nn is the number of input elements. For matrix algorithms, the input matrix has size n × n. For\ngraph algorithms, the number of vertices is n, and the number of edges is (n).\nYou need not justify your answers. Some running times may be used multiple times or not at all.\nBecause points will be deducted for wrong answers, do not guess unless you are reasonably sure.\nInsertion sort\nA: O(lg n)\nHeapsort\nB: O(n)\nBUILD-HEAP\nC: O(n lg n)\nStrassen's\nD: O(n )\nBellman-Ford\nE: O(n lg n)\n2.5)\nDepth-first search\nF: O(n\nG: O(nlg 7)\nFloyd-Warshall\nJohnson's\nH: O(n3)\nPrim's\nI: O(n3 lg n)\nSolution: From top to bottom: D, C, B, G, D, B, H, E, C.\n\nHandout 36: Final Exam Solutions\nProblem 3. Substitution method [10 points]\nUse the substitution method to prove a tight asymptotic lower bound (Δ-notation) on the solution\nto the recurrence\nT (n) = 4T (n/2) + n 2 .\nSolution: By the master method, we know T (n) = (n2 lg n). Therefore, our induction hypoth\nesis is T (m) √ cm2 lg m for all m < n.\nFor m = 1, we have the base case that T (1) = 1 > c12 lg 1 for all c > 0.\nFor the inductive step, assume for all m < n, T (m) √ cm2 lg m. The induction hypothesis yields\nT (n)\n=\n4T (n/2) + n 2\n\nn\nn\n√ 4c\nlg\n+ n 2\n= cn lg n - cn 2 lg 2 + n\n= cn lg n + (1 - c)n 2 .\nFor c < 1, this quantity is always greater than cn2 lg n. Therefore, T (n) = Δ(cn2 lg n).\n\nHandout 36: Final Exam Solutions\nProblem 4. True or False, and Justify [35 points] (7 parts)\nCircle T or F for each of the following statements to indicate whether the statement is true or\nfalse, respectively. If the statement is correct, briefly state why. If the statement is wrong, explain\nwhy. The more content you provide in your justification, the higher your grade, but be brief. Your\njustification is worth more points than your true-or-false designation.\nT F Let A1, A2, and A3 be three sorted arrays of n real numbers (all distinct). In the comparison\nmodel, constructing a balanced binary search tree of the set A1 [A2 [A3 requires Δ(n lg n)\ntime.\nSolution: False. First, merge the three arrays, A1, A2, and A3 in O(n) time. Second,\nconstruct a balanced binary search tree from the merged array: the median of the array\nis the root; recursively build the left subtree from the first half of the array and the right\nsubtree from the second half of the array. The resulting running time is T (n) = 2T (n/2)+\nO(1) = O(n).\nT F Let T be a complete binary tree with n nodes. Finding a path from the root of T to a given\nvertex v 2 T using breadth-first search takes O(lg n) time.\nSolution: False. Breadth-first search requires Δ(n) time. Breadth-first search examines\neach node in the tree in breadth-first order. The vertex v could well be the last vertex\nexplored. (Also, notice that T is not necessarily sorted.)\n\nHandout 36: Final Exam Solutions\nT F Given an unsorted array A[1 . . n] of n integers, building a max-heap out of the elements of\nA can be performed asymptotically faster than building a red-black tree out of the elements\nof A.\nSolution: True. Building a heap takes O(n) time, as described in CLRS. On the other\nhand, building a red-black tree takes Δ(n lg n) time, since it is possible to produce a sorted\nlist of elements from a red-black tree in O(n) time by doing an in-order tree walk (and\nsorting requires Δ(n lg n) time in a comparison model).\nT F Suppose we use a hash function h to hash n distinct keys into an array T of length m.\nAssuming simple uniform hashing, the expected number of colliding pairs of elements is\n(n2/m).\nSolution: True. Let Xi,j be an indicator random variable equal to 1 if elements i and j\ncollide, and equal to 0 otherwise. Simple uniform hashing means that the probability of\nelement i hashing to slot k is 1/m. Therefore, the probability that i and j both hash to the\nsame slot Pr(Xi,j ) = 1/m. Hence, E [Xi,j ] = 1/m. We now use linearity of expectation\nto sum over all possible pairs i and j:\nn\nn\nE [number of colliding pairs] = E 4 ⎦ ⎦\nXi,j ⎡\ni=1 j=i+1\nn\nn\n⎦ ⎦\n=\nE [Xi,j ]\ni=1 j=i+1\nn\nn\n⎦ ⎦\n=\n1/m\ni=1 j=i+1\nn(n + 1)\n=\n2m\n= (n 2/m)\n\nHandout 36: Final Exam Solutions\nT F Every sorting network with n inputs has depth Δ(lg n).\nSolution: True. Let d be the depth of the network. Since there are n inputs to the\nnetwork, there can be at most nd comparators. (One way of seeing this is by the pigeon\nhole principle: if there are n wires and more than nd comparators, then some wire must\ntraverse more than d comparators, resulting in a depth > d.)\nIn the comparison-based model, it is possible to simulate the sorting network one compara\ntor at a time. The running time is equal to the number of comparators (times a constant\nfactor overhead). Therefore, every sorting network must have at least Δ(n lg n) compara\ntors, by the lower-bound for sorting in the comparison-based model.\nTherefore, nd > Δ(n lg n), implying that the depth d is Δ(lg n).\nT F If a dynamic-programming problem satisfies the optimal-substructure property, then a lo\ncally optimal solution is globally optimal.\nSolution: False. The property which implies that locally optimal solutions are globally\noptimal is the greedy-choice property. Consider as a counterexample the edit distance\nproblem. This problem has optimal substructure, as was shown on the problem set, how\never a locally optimal solution--making the best edit next--does not result in a globally\noptimal solution.\n\nHandout 36: Final Exam Solutions\nT F Let G = (V, E) be a directed graph with negative-weight edges, but no negative-weight\ncycles. Then, one can compute all shortest paths from a source s 2 V to all v 2 V faster\nthan Bellman-Ford using the technique of reweighting.\nSolution: False. The technique of reweighting preserves the shortest path by assigning\na value h(v) to each vertex v 2 V , and using this to calculate new weights for the edges:\nw(u, v) = w(u, v) + h(u) - h(v). However, to determine values for h(v) such that the\nedge weights are all non-negative, we use Bellman-Ford to solve the resulting system\nof difference constraints. Since the technique of reweighting relies on Bellman-Ford, it\ncannot run faster than Bellman-Ford.\n\nHandout 36: Final Exam Solutions\nProblem 5. Red-black trees [15 points] (3 parts)\n(a) Assign the keys 2, 3, 5, 7, 11, 13, 17, 19 to the nodes of the binary search tree below so\nthat they satisfy the binary-search-tree property.\nnil\nnil\nnil\nnil\nnil\nnil\nnil\nnil\nnil\nSolution: 5 points for the correct answer:\n\nHandout 36: Final Exam Solutions\n(b) Explain why this binary search tree cannot be colored to form a legal red-black tree.\nSolution: We prove this by contradiction. Suppose that a valid coloring exists. In a\nred-black tree, all paths from a node to descendant leaves contain the same number of\nblack nodes. The path (17, 19, NIL) can contain at most three black nodes. Therefore\nthe path (17, 11, 3, 5, 7, NIL) must also contain at most three black nodes and at least\nthree red nodes. By the red-black tree properties, the root 17 must be black and the\nNIL node must also be black. This means that there must be three red nodes in the\npath (11, 3, 5, 7), but this would mean there are two consecutive red nodes, which\nviolates the red-black tree properties. This is a contradiction, therefore the tree cannot\nbe colored to form a legal red-black tree.\n5 points for correct answer. 2-4 points for stating the red-black tree rules, but not\nproving why the tree does not satisfy the rules. 1 point for stating that the tree is\nunbalanced.\n\nHandout 36: Final Exam Solutions\n(c) The binary search tree can be transformed into a red-black tree by performing a single\nrotation. Draw the red-black tree that results, labeling each node with \"red\" or \"black.\"\nInclude the keys from part (a).\nSolution: Rotate right around the root. There are several valid ways to color the\nresulting tree. Here is one possible answer (all nodes are colored black except for 7).\n5 points for the correct answer. 2 points for the correct rotation but incorrect coloring.\n\nHandout 36: Final Exam Solutions\nProblem 6. Wiggly arrays [10 points]\nAn array A[1 . . 2n + 1] is wiggly if A[1] ← A[2] √ A[3] ← A[4] √ . . . ← A[2n] √ A[2n + 1].\nGiven an unsorted array B[1 . . 2n+ 1] of real numbers, describe an efficient algorithm that outputs\na permutation A[1 . . 2n + 1] of B such that A is a wiggly array.\nSolution: There are several ways to solve this problem in (n) time. You can find the median k\nof B using the deterministic (n) select algorithm and partition B around the median k into two\nequal sized sets Blow and Bhigh. Assign A[1] k. Then for each i > 1, if i is even, assign an\nelement from Bhigh to A[i], otherwise assign an element from Blow to A[i]. Since all elements in\nBhigh are greater than or equal to all elements in Blow and the median is less than or equal to all\nelements in Bhigh, the array is wiggly. The overall running time is (n).\n10 points for correct (n) solution and correct analysis. 8-9 points for correct solution but missing\na minor step in the analysis.\n5 points for correct (n lg n) solution and correct analysis. 2-4 points for correct solution but\nincomplete analysis.\n\nHandout 36: Final Exam Solutions\nProblem 7. Difference constraints [12 points] (2 parts)\nConsider the following linear-programming system of difference constraints (note that one con\nstraint is an equality):\nx1 -x4 ← -1\nx1 -x5 ← -4\nx2 -x1 ← -4\nx\nx2 -x3 = -9\n3 -x1\n←\nx3 -x5\n←\nx4 -x3 ← -3\nx5 -x1\n←\nx5 -x4\n←\n(a) Draw the constraint graph for these constraints.\nx\nSolution: The equality constraint can be written as two inequality constraints, x2 -\n3 ←-9, and x3 -x2\n9. A completely correct constraint graph received 6 points.\n←\nSolutions that had edges in the wrong direction received only 4 points, and solutions\nthat did not handle the equality constraint received 3 points.\n(b) Solve for the unknowns x1, x2, x3, x4, and x5, or explain why no solution exists.\nSolution: No solution to this system exists because the constraint graph has a negative-\nweight cycle. For example, x1 ; x3 ; x4 ; x5 ; x1 has weight 5-3+1-4 = -1.\nA full-credit solution (6 points) must exhibit the negative weight cycle.\n\nHandout 36: Final Exam Solutions\nProblem 8. Amortized increment [12 points]\nk-1\n⎦\nAn array A[0 . . k - 1] of bits (each array element is 0 or 1) stores a binary number x =\nA[i] 2i .\n·\ni=0\nTo add 1 (modulo 2k) to x, we use the following procedure:\nINCREMENT(A, k)\n1 i 0\n2 while i < k and A[i] = 1\ndo A[i] 0\ni i + 1\n5 if i < k\nthen A[i] 1\nGiven a number x, define the potential (x) of x to be the number of 1's in the binary representation\nof x. For example, (19) = 3, because 19 = 100112. Use a potential-function argument to prove\nthat the amortized cost of an increment is O(1), where the initial value in the counter is x = 0.\nSolution: (x) is a valid potential function the number of 1's in the binary representation of x is\nalways nonnegative, i.e., (x) √ 0 for all x. Since the initial value of the counter is 0, 0 = 0.\nLet ck be the real cost of the operation INCREMENT(A, k), and let dk be the number of times the\nwhile loop body in Lines 3 and 4 execute (i.e., dk is the number of consecutive 1's counting from\nthe least-significant bit of the binary representation of x). If we assume that executing all of Lines\n1, 2, 5, and 6 require unit cost, and executing the body of the while loop requires unit cost, then\nthe real cost is ck = 1 + dk ,\nThe potential decreases by one every time the while loop is executed. Therefore, the change in\npotential, = k - k-1 is at most 1 - dk . More specifically, = 1 - dk if we execute Line\n6 , and = -dk if we do not.\nThus, using the formula for amortized cost, we get\ncˆk = ck +\n= 1 + dk +\n← 1 + dk + 1 - dk\n=\n2.\nTherefore, the amortized cost of an increment is O(1).\nOnly solutions that explicitly calculate/explain the real cost ck of a single increment received full\ncredit. Solutions that give an aggregate analysis or any other method that did not use the potential\nfunction received at most 6 points. One or two points were deducted from correct solutions that\ndid not explain why the potential function is valid or calculate 0.\n\nHandout 36: Final Exam Solutions\nProblem 9. Minimum spanning trees [12 points]\nLet G = (V, E) be a connected, undirected graph with edge-weight function w : E ∪\n, and\nassume all edge weights are distinct. Consider a cycle ≤v1, v2, . . . , vk , vk+1≥ in G, where vk+1 = v1,\nand let (vi, vi+1) be the edge in the cycle with the largest edge weight. Prove that (vi, vi+1) does\nnot belong to the minimum spanning tree T of G.\nSolution: Proof by contradiction. Assume for the sake of contradiction that (vi, vi+1) does be\nlong to the minimum spanning tree T. Removing (vi, vi+1) from T divides T into two connected\ncomponents P and Q, where some nodes of the given cycle are in P and some are in Q. For any\ncycle, at least two edges must cross this cut, and therefore there is some other edge (vj , vj+1) on\nthe cycle, such that adding this edge connects P and Q again and creates another spanning tree T 0.\nSince the weight of (vj , vj+1) is less than (vi, vi+1), the weight of T 0 is less than T and T cannot\nbe a minimum spanning tree. Contradiction.\n\nHandout 36: Final Exam Solutions\nProblem 10. Multithreaded scheduling [10 points]\nA greedy scheduler runs a multithreaded computation in 260 seconds on 4 processors and in 90\nseconds on 32 processors. Is it possible that the computation has work T1 = 1024 and critical-path\nlength T1 = 64? Justify your answer.\nSolution: For greedy schedulers, we know that min{T1/P, T1} ←TP\nT1/P + T . The\n←\nnumbers given above satisfy all of the above inequalities for both values of P . Therefore, it is\npossible that the work and critical path are correct.\n\nHandout 36: Final Exam Solutions\nProblem 11. Transposing a matrix [40 points] (4 parts)\nLet X be an N × N matrix, where N is an exact power of 2. The following code computes\nY = XT:\nTRANS(X, Y, N)\n1 for i 1 to N\ndo for j 1 to N\ndo Y [j, i] X[i, j]\nConsider the cache-oblivious two-level memory model with a cache of M elements and blocks of\nB elements. Assume that both matrices X and Y are stored in row-major order, that is, the linear\norder of X in memory is X[1, 1], X[1, 2], . . ., X[1, N], X[2, 1], X[2, 2], . . ., X[2, N], . . . , X[N, 1],\nX[N, 2], . . . , X[N, N], and similarly for Y .\n(a) Analyze the number MT(N) of memory transfers incurred by TRANS when N\nM.\n→\nSolution: Since the loop scans through matrix X one row at a time, the number of\nmemory transfers required for accessing X is O(N 2/B). We incur O(N 2) memory\ntransfers to access Y , however, because Y is accessed one column at a time. When we\naccess the block containing Y [j, i], since N\nM and we scan through all of column\n→\ni before accessing Y [j + 1, i], each access to Y may incur a memory transfer.\nTherefore, MT(N) = O(N 2).\n\nq\nHandout 36: Final Exam Solutions\nNow, consider the following divide-and-conquer algorithm for computing the transpose:\nR-TRANS(X, Y, N)\n1 if N = 1\nthen Y [1, 1] X[1, 1]\nelse Partition X into four (N/2) × (N/2) submatrices X11, X12, X21, and X22.\nPartition Y into four (N/2) × (N/2) submatrices Y11, Y12, Y21, and Y22.\nR-TRANS(X11, Y11, N/2)\nR-TRANS(X12, Y21, N/2)\nR-TRANS(X21, Y12, N/2)\nR-TRANS(X22, Y22, N/2)\nAssume that the cost of partitioning is O(1).\n(b) Give and solve a recurrence for the number MT(N) of memory transfers incurred by\nR-TRANS when N\nM.\n→\nSolution: If we make either the tall-cache assumption (i.e., M = Δ(B2)), or we\nassume that the matrix is stored in the recursive block layout, then\n⎤\n4T (n/2) + (1) if cn2 > M,\nMT (n) =\n.\nM/B\nif cn\nM\n←\nThe recursion tree has approximately lg N - lg( M/c) levels. Since every level\nhas 4 times as many nodes as the previous level, the solution to the recurrence is\ndominated by the cost of the leaves. The tree has 4lg(N pc/\np\nM ) leaves, each of cost\nM/B. Therefore, MT (N) is\n\n⎣2\nM\nN∈c\nMT (N)\n=\nB\n∈\nM\ncN 2\n=\nB\n⎣\nN 2\n= O\n.\nB\n\nHandout 36: Final Exam Solutions\nThe following multithreaded algorithm computes the transpose in parallel:\nP-TRANS(X, Y, N)\n1 if N = 1\nthen Y [1, 1] X[1, 1]\nelse Partition X into four (N/2) × (N/2) submatrices X11, X12, X21, and X22.\nPartition Y into four (N/2) × (N/2) submatrices Y11, Y12, Y21, and Y22.\nspawn P-TRANS(X11, Y11, N/2)\nspawn P-TRANS(X12, Y21, N/2)\nspawn P-TRANS(X21, Y12, N/2)\nspawn P-TRANS(X22, Y22, N/2)\nsync\n(c) Give and solve recurrences describing the work T1(N) and critical-path length T1(N)\nof P-TRANS. What is the asymptotic parallelism of the algorithm?\nSolution:\nN\nT1(N)\n=\n4T1\n+ O(1)\n= (N 2).\nN\nT1(N)\n= T\n+ O(1)\n= (lg N).\nThe parallelism of the algoritm is T1/T1, or (N 2/ lg N).\n\nHandout 36: Final Exam Solutions\nProfessor Kellogg inadvertantly places two additional sync statements into his code as follows:\nK-TRANS(X, Y, N)\n1 if N = 1\nthen Y [1, 1] X[1, 1]\nelse Partition X into four (N/2) × (N/2) submatrices X11, X12, X21, and X22.\nPartition Y into four (N/2) × (N/2) submatrices Y11, Y12, Y21, and Y22.\nspawn K-TRANS(X11, Y11, N/2)\nsync\nspawn K-TRANS(X12, Y21, N/2)\nsync\nspawn K-TRANS(X21, Y12, N/2)\nspawn K-TRANS(X22, Y22, N/2)\nsync\n(d) Give and solve recurrences describing the work T1(N) and critical-path length T1(N)\nof K-TRANS. What is the asymptotic parallelism of this algorithm?\nSolution: The work for the algorithm remains the same.\nN\nT1(N)\n=\n4T1\n+ O(1)\n= (N 2).\nThe critical path increases, however, because we only solve one of the subproblems in\nparallel.\nN\nT1(N)\n=\n3T\n+ O(1)\n= (N lg 3).\nThe parallelism of the algorithm is T1/T1, or (N 2-lg 3).\n\nSCRATCH PAPER -- Please detach this page before handing in your exam.\n\nSCRATCH PAPER -- Please detach this page before handing in your exam."
    },
    {
      "category": "Resource",
      "title": "final.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/dbda8457c7e07e59da73b24b9d372d34_final.pdf",
      "content": "Introduction to Algorithms\nDecember 20, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nFinal Exam\nFinal Exam\n\nDo not open this exam booklet until you are directed to do so. Read all the instructions on\nthis page.\n\nWhen the exam begins, write your name on every page of this exam booklet.\n\nThis exam contains 11 problems, some with multiple parts. You have 180 minutes to earn\n180 points.\n\nThis exam booklet contains 20 pages, including this one. Two extra sheets of scratch paper\nare attached. Please detach them before turning in your exam at the end of the examination\nperiod.\n\nThis exam is closed book. You may use two handwritten A4 or\n\ncrib sheets. No\ncalculators or programmable devices are permitted.\n\nWrite your solutions in the space provided. If you need more space, write on the back of the\nsheet containing the problem. Do not put part of the answer to one problem on the back of\nthe sheet for another problem, since the pages may be separated for grading.\n\nDo not waste time and paper rederiving facts that we have studied. It is sufficient to cite\nknown results.\n\nDo not spend too much time on any one problem. Read them all through first, and attack\nthem in the order that allows you to make the most progress.\n\nShow your work, as partial credit will be given. You will be graded not only on the correct\nness of your answer, but also on the clarity with which you express it. Be neat.\n\nGood luck!\nName:\n\n6.046J/18.410J Final Exam\nName\nGrade sheet: Do not write in the spaces below.\n1 Recurrences\nProblem Title\nParts Points Grade Grader\nAlgorithms and running times\nSubstitution method\nTrue or False, and Justify\nRed-black trees\nWiggly arrays\nDifference constraints\nAmortized increment\nMinimum spanning trees\nMultithreaded scheduling\nTransposing a matrix\nTotal\n\n6.046J/18.410J Final Exam\nName\nProblem 1. Recurrences [15 points] (3 parts)\nGive a tight asymptotic upper bound (\nnotation) on the solution to each of the following recur\nrences. You need not justify your answers.\n\n(a)\n\n.\n(b)\n\n$#%'&\n\n(c)\n\n%\n!\"\n\nif\n\n$()%+*\n\nif\n\n%\nwhere\nis a variable independent from\n.\n\n6.046J/18.410J Final Exam\nName\nProblem 2. Algorithms and running times [9 points]\nMatch each algorithm below with the tightest asymptotic upper bound for its worst-case running\ntime by inserting one of the letters A, B,\n, I into the corresponding box. For sorting algorithms,\n\nis the number of input elements. For matrix algorithms, the input matrix has size\n\n. For\ngraph algorithms, the number of vertices is\n, and the number of edges is\n!\" .\nYou need not justify your answers. Some running times may be used multiple times or not at all.\nBecause points will be deducted for wrong answers, do not guess unless you are reasonably sure.\n\nInsertion sort\nA:\n\nHeapsort\nB:\n\nBUILD-HEAP\nC:\n\nStrassen's\nD:\n\nBellman-Ford\nE:\n\nDepth-first search\nF:\n\nFloyd-Warshall\nG:\n\nJohnson's\nH:\n\nPrim's\nI:\n\n6.046J/18.410J Final Exam\nName\nProblem 3. Substitution method [10 points]\nUse the substitution method to prove a tight asymptotic lower bound (\n-notation) on the solution\nto the recurrence\n)\n\n6.046J/18.410J Final Exam\nName\nProblem 4. True or False, and Justify [35 points] (7 parts)\nCircle T or F for each of the following statements to indicate whether the statement is true or\nfalse, respectively. If the statement is correct, briefly state why. If the statement is wrong, explain\nwhy. The more content you provide in your justification, the higher your grade, but be brief. Your\njustification is worth more points than your true-or-false designation.\nT F Let\n\n,\n\n, and\n\nbe three sorted arrays of\nreal numbers (all distinct). In the comparison\n\nmodel, constructing a balanced binary search tree of the set\n\nrequires\n\ntime.\nT F Let be a complete binary tree with nodes. Finding a path from the root of to a given\n\nvertex\n\nusing breadth-first search takes\n\ntime.\n\n6.046J/18.410J Final Exam\nName\n\nT F Given an unsorted array of integers, building a max-heap out of the elements of\n\ncan be performed asymptotically faster than building a red-black tree out of the elements\nof\n.\nT F Suppose we use a hash function\n\nto hash\ndistinct keys into an array\nof length\n\n.\nAssuming simple uniform hashing, the expected number of colliding pairs of elements is\n\n!\n\n.\n\n6.046J/18.410J Final Exam\nName\n\nT F Every sorting network with\ninputs has depth\n\n.\nT F If a dynamic-programming problem satisfies the optimal-substructure property, then a lo\ncally optimal solution is globally optimal.\n\n6.046J/18.410J Final Exam\nName\nT F Let\n\n&\nbe a directed graph with negative-weight edges, but no negative-weight\n\nto all\n\ncycles. Then, one can compute all shortest paths from a source\n\nfaster\nthan Bellman-Ford using the technique of reweighting.\n\n6.046J/18.410J Final Exam\nName\nProblem 5. Red-black trees [15 points] (3 parts)\n&\n&\n&\n&\n&\n\n&\n\n&\n\n(a) Assign the keys\n\nto the nodes of the binary search tree below so\nthat they satisfy the binary-search-tree property.\nnil\nnil\nnil\nnil\nnil\nnil\nnil\nnil\nnil\n(b) Explain why this binary search tree cannot be colored to form a legal red-black tree.\n\n6.046J/18.410J Final Exam\nName\n(c) The binary search tree can be transformed into a red-black tree by performing a single\nrotation. Draw the red-black tree that results, labeling each node with \"red\" or \"black.\"\nInclude the keys from part (a).\n\n6.046J/18.410J Final Exam\nName\nProblem 6. Wiggly arrays [10 points]\n(\n(\nAn array\n\nis wiggly if\n\n(\n\n.\nGiven an unsorted array\n\nof real numbers, describe an efficient algorithm that outputs\na permutation\n\nof\n\nsuch that\n\nis a wiggly array.\n\n6.046J/18.410J Final Exam\nName\nProblem 7. Difference constraints [12 points] (2 parts)\nConsider the following linear-programming system of difference constraints (note that one con\nstraint is an equality):\n(\n\n(\n\n(\n\n(\n\n(\n\n(\n\n(\n\n(\n\n(a) Draw the constraint graph for these constraints.\n\n(b) Solve for the unknowns\n,\n\n,\n,\n, and\n\n, or explain why no solution exists.\n\n6.046J/18.410J Final Exam\nName\nProblem 8.\nAmortized increment [12 points]\nAn array\n\nof bits (each array element is\nor\n) stores a binary number\n\n.\nTo add\n(modulo\n\n) to\n, we use the following procedure:\nINCREMENT\n\n&\n\n2 while\nand\n\ndo\n\n5 if\n\nthen\n\nGiven a number\n, define the potential\n\nof\nto be the number of\n's in the binary representation\nof\n. For example,\n\n, because\n\n. Use a potential-function argument to prove\nthat the amortized cost of an increment is\n\n, where the initial value in the counter is\n\n.\n\n6.046J/18.410J Final Exam\nName\nProblem 9. Minimum spanning trees [12 points]\n\nLet\n\n&\n\n&\n\nbe a connected, undirected graph with edge-weight function\n\n, and\n&\n&\n\nassume all edge weights are distinct. Consider a cycle\n\n&\n\n&\n\nin , where\n&\n\n,\n\nand let\n\nbe the edge in the cycle with the largest edge weight. Prove that\n\ndoes\nnot belong to the minimum spanning tree\nof\n.\n\n6.046J/18.410J Final Exam\nName\nProblem 10. Multithreaded scheduling [10 points]\nA greedy scheduler runs a multithreaded computation in\n\nseconds on\nprocessors and in\n\nseconds on\nprocessors. Is it possible that the computation has work\n\nand critical-path\nlength\n? Justify your answer.\n\n6.046J/18.410J Final Exam\nName\nProblem 11. Transposing a matrix [40 points] (4 parts)\nLet\n\nbe an\n\nmatrix, where\n\nis an exact power of\n. The following code computes\n\nT:\n&\n\n&\n\nTRANS\n\n1 for\n\nto\n\ndo for\n\nto\n\n&\ndo\n\n&\n\n%\nConsider the cache-oblivious two-level memory model with a cache of\nelements and blocks of\n\nelements. Assume that both matrices\n&\n\nand\n& are stored in row-major order, that is, the linear\n&\norder of\n&\n\nin memory is\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n\n&\n&\n\n&\n\n, and similarly for .\n%\n(a) Analyze the number MT\n\nof memory transfers incurred by TRANS when\n\n.\n\n6.046J/18.410J Final Exam\nName\nNow, consider the following divide-and-conquer algorithm for computing the transpose:\n&\n\n&\n\nR-TRANS\n\n1 if\n\n&\n&\nthen\n\nPartition\ninto four\n&\n\"\n\n\" submatrices\n\n,\n\n,\n\n, and\n\n.\nelse Partition\ninto four\n\"\n\" submatrices\n\n,\n\n,\n\n, and\n.\n\n\"\n\nR-TRANS\n\n\"\nR-TRANS\n\n&\n&\n&\n\n&\n&\n\nR-TRANS\n\n&\n\"\n\nR-TRANS\n\n&\n\n\"\n\nAssume that the cost of partitioning is\n\n.\n(b) Give and solve a recurrence for the number MT\n\nof memory transfers incurred by\n%\nR-TRANS when\n\n.\n\n6.046J/18.410J Final Exam\nName\nThe following multithreaded algorithm computes the transpose in parallel:\n&\n\n&\n\nP-TRANS\n\n1 if\n\n&\n&\nthen\n\n&\n\nPartition\ninto four\n\"\n&\n\n\" submatrices\n\n,\n\n,\n\n, and\n\n.\nelse Partition\ninto four\n\"\n\"\n\" submatrices\n\n,\n\n,\n\n, and\n.\nspawn P-TRANS\n\n&\n&\n\n&\n&\n&\n\nspawn P-TRANS\n\n\"\nspawn P-TRANS\n\n\"\n\nspawn P-TRANS\n\n&\n\n\"\n\nsync\n\n\"\n\n(c) Give and solve recurrences describing the work\n\nand critical-path length\n\nof P-TRANS. What is the asymptotic parallelism of the algorithm?\n\n6.046J/18.410J Final Exam\nName\nProfessor Kellogg inadvertantly places two additional sync statements into his code as follows:\nK-TRANS\n\n&\n\n&\n\nif\n\nthen\n\n&\n\n&\n\nelse Partition\ninto four\n\"\n\n\"\nsubmatrices\n\n,\n\n,\n\n, and\n\n.\nPartition\n\ninto four\n\"\n\n\"\nsubmatrices\n\n,\n\n,\n\n, and\n\n.\nspawn K-TRANS\n\n&\n\n&\n\"\n\nsync\nspawn K-TRANS\n\n&\n\n&\n\"\n\nsync\nspawn K-TRANS\n\n&\n\n&\n\"\n\nspawn K-TRANS\n\n&\n\n&\n\"\n\nsync\n(d) Give and solve recurrences describing the work\n\nand critical-path length\n\"\n\nof K-TRANS. What is the asymptotic parallelism of this algorithm?\n\nSCRATCH PAPER -- Please detach this page before handing in your exam.\n\nSCRATCH PAPER -- Please detach this page before handing in your exam."
    },
    {
      "category": "Resource",
      "title": "prac_final_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/63b00c36e38227e05c8f5f9c8206aad7_prac_final_sol.pdf",
      "content": "!\"#%$\n&(') * +,'-.* ,!0/2134657 ,!* *, 98\n:;\"<=,:>@?BADC,;*=BAD<,>FE\n'FG \"H JIK!\"#,' 4L\nM9$\nA%CN2O<,<P\n&(')Q 9,'&(\"D ' G$3RS, GUTV' W*G ,'\nXZY\\[^]`_Wa]`b\ncDdeY6fgahM[^ikjmln[^o\nprqsdeitu_VadehMv.w\nxky\nL % z,{| H *} \"~|FR !\" z *!$r, U') G *') GH JG L\n;\nx\nW * !2 G D\nADO,E*<,<HJ\nx\nW *L 13,4*L!*,9 G ,R\n;\n, 4L9$g J ' U*G LK , Gz') )\nC0\n\n`\nA,A\n\n')*\n\n;\nxn\nU u} \"~u| #,*\nN\n' $r, 'z 4J uU {KKnM{ #, s\"U \"^} \"~\n,R !*\nN\nV { #, `*!\"!0 { '% GUQ'#,',G * #\n;\nxn\n' V$B ',!* *, \"H { { ') |*G G\n;\nr$B U GU4L,' {\nN\nz') ,H u @ )¡\n,¢ K £ \" * #¤ { ') !\" 4\n;\ny\n¥ % £{ £{ '¦ £, K £ '§ ¥, { ') !\" 4\nRsr 9 +,',B% 'W{ ', !* 4\n;\nx\n&\\!*,¤$r 'r \"4L * !$\n;\ny\nK D W{ G¤ F4^ ¤ \"4L (c),¥$s, (c){ ', !* 4\n;«a\nG¤ ' #,\n,!*!@¬ 4 ') (c), GzD ) , R(c) 4(r)* (')G 'B D «!\"!*9zB$B 4L,R 0 (4L, «{ ',#')\n;\nx\n7 9°$B 'V')R\nN\n{ '¦ \"!`') G *!\"!` L#,B\n;H\n, ±*!\"!` L#,',G Gn D u, !$2\n,'') V¢$r, 'V, '\nN\n,!*¥^ !*,' $uz ^ * ^$r, 13{ ' V\n;\nTV %\n;\nxn\nG '\" * #3,!*#,' 4\nN\nG '\" ¥ ±4J\"\"G n\"/( #,!*\"9\n;m\n±{ G G\n, !$S £ 1 D z !\"{ !*,'\"μ$S 4J\"U*G ,\n;\nxk¶\nF GU!* R ·\nK,4L\nE\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\nO\ne¿Aree¦i E\nÆi\n7 '¦ z}F B *,\n^ +,!*!\"9z\" #H}F *,\nN\n!\"!| (c) B K !*, RL|913\n;\nS 4J') « S K '(c)*V,'')\nN\n$r, i !*Gi{ ') |*G L Ue`i i1⁄4nð21⁄2AoJ1⁄2o'') M, '\n;\n/\n;\n#\n;*N\n+,'so} *,oo7 '¦ \" #o,W÷\n!* 4J ¤\"J ,4L{ ,'\"9,ø9 Ge4LFG !§e G , *\n\"4L u\nN\n^,'')\n'H*Luu5u÷J!\"#§÷u8\n;\nK3{ '¦ \"!V' G J*!\"!V| #B +,'J,'') U e { *4J!V '\n;\nyK9 r '\nN\n$r, þA1⁄2Ar1⁄4z B V J{B')93*G ,$Sy * % \"\n;\nAW *G '£±4L G \" D *,\nN\nD L \"4L m*!\"!* G\nN\n4J GB\"LF { ,' *, Gu')'9$U\"(+, G5 \" # ! \"! ,!*#,') 4L8\\ Gu G\n,L{ rD\n;\nW V£,' )ø9 ' \" #£ *4J r *!\"#,' 4o*\nE\n#\n1⁄2iozi ¿%$'&u5÷J!\"#§÷u8(\n)*\"+-,\".0/21\n3-4*657*0879-+:/<;\"+0/>=7*6?.:@-/\"8<90/Auu5u÷u8A379057*B6,\".\nC\n*64+:D*63\"4*FE-@-/\"/9:/-GH39:5*6E7*-;:@-E\"E*:/;\"*JIs5u÷.8LK\nO\nIs5÷M\nO\n8ONius5÷u8(\nePoJG D L ' ' £9 { {,' W±{ '% \"Q?.\".H9 H D J } ,÷R?.\".,1\"u R,\n&u5÷J!*,#§÷u8z \"4L u n{ '+,'4\n\"o s') 3\nN\no M,4L,' *~ G \"4L M,R?7.-.\n,{ ')D *,U*2&\nN\n*!\" W B,!¢ *4J ,L* #,!* S?.\".J{ ')D \"U, !*G\n, \"#U,T&\n;\n#\n1⁄2iozi ¿%$VU\"5.:E-3790W7*08>379057*X&u5!\"#§÷u8YB\nC\n.:E,:3Z\";-+\",-*6379057*X&u5u÷H!*,#÷.8(\n\\[\n\ny\nB ') ( 13* (c){|,!$| 4J*! \"4L (!\"#,' 4 % (c) G B 0!\" «,¢ ^]`_ba`4J* \"4¥ 4\n*UJG *') GU#'){ dc\n\n,' ¤8\n#\n1⁄2iozi ¿%$\ne*\",(\n)*\"+-,\".0/21\nf\"4*6D7+-g:@*H.0?<+0/h]i_jak59:/9:5-@\"5<;0@\"3<9\",>*0l-@7+-gF3.\n3\"4*6D7+-g:@*>.:?>3-47*m]n_jak5+:o9:5-@\"5>?7g-.\nC\nB6+:/-8>3\"4*:E*>+:E*657+0/\"p<+-g:G.:E9:3-4\"5,F?.:E\n;\".05\"q-@\"39:/-Gh]r_2a'5+:o9:5-@\"5>?g\".\nC\n,>90/>q7.-g:p-/7.0579-+\"g637905*ts0*u(vG2(\n3\"4*6w\"8-57.0/\"8,\"Z0x7+0E\"q\n+\"g0G7.0E7903\"4-57y(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\nP\ne¿Aree¦i E\nE.i\n' ,'-B!\" zc\n-r,' ¥, «} \" !*9\nN\n\"'!\" (c) 'O{\n5+,'') 8'O|\n5+,'-r,!* 8\n;\noeASi\"}\nE\ne¦AB1⁄2AB1⁄4»¦A1⁄2i\nA ¿i1⁄2i iFþiFþ\ni\n,'') z, £ ')' , £ ') GU} \" ') V'¦ U~ 'J{*\n;\n{\n|\nT$\nS4J ' ') 4\nN\ns!\" \"e u S') '') Is5÷u8K\nP\nIs5÷M\nP\n8LN\n!\"#§÷(r)*\nIu5u÷u8LK~&u5÷J!*,#§÷u8\n;\n#\n1⁄2iozi ¿%$V7+-g\",-*\n{\n|\nW4J{ \" #« (c)4L G \"¥,÷\n!* 4L R, u5u÷H!*,#÷u8r \"4L «+'$s!\"#,' 4i£,'RF* #\n\"H ,4L{ ,'\"ø9 GU4J G !\n;\n#\n1⁄2iozi ¿%$V7+-g\",-*\n{\n|\n/2r '¦$3 * ,'$3 ,' H ' ,J÷ G *#, zus5!\"#§÷u8\n;\n#\n1⁄2iozi ¿%$V7+-g\",-*\n{\n|\n¶\nB ±J#,',{ ~KZ5Pzz8. ± ± G #, W,BG±J J\nN\n!* s5P\\8W ,± G #\nu % e5P\\8K*« ^4L\" *4^ 4\n, J G #, ¥\nM,$eB ' 1o*\nGM,$Ur '¦ 1\n\"R_\n;\nW\nN\n4J* \"4¥ 4o9{ , * #W ' ,4^ K\" !\" G ` G # ^5P\\8\n;\n\n4J9$3 4L V ,U!\"!0 G # ,' G \" *\nN\n\" G G\n;\n#\n1⁄2iozi ¿%$Vf\"E-@7*\n{\n|\n§ 2Io £L4J* \"4¥ 4o{ \" # ' £P\n;\n\nN\n+,',$M{ \"',rB ' * T]z, Gia\nN\n\n,' z{ D U+')4] aK\"o\"` { D U+',4] aK*iI\n;\n#\n1⁄2iozi ¿%$V7+-g\",-*\n{\n|\n¢¤{ ') !\" 4h\n\n*{|,!$|B,4L\"! *4J (' G * !\" 0 ¤¤{ ') !\" 4h\n\nG^\n\n¤{!$| 4J*,!\n*4J !\"#,' 4\nN\n\n,L{!$3 4J*,!¢ *4J !\"#') 4\n;\n#\n1⁄2iozi ¿%$Vf\"E-@7*\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\n=\ne¿Aree¦i E\n\ni\n' ,'-B!\" , G\n>\n\"μ$\n;\n-r,'« , s, ¤} \" « !*9\nN\n\"'!\" ¤ 'L{\n5Q'(' 8('|\n5+,'«-B!\" 8\n;\ns#,B ¤^ ')*\n\ni1⁄4»v\n[\nA 1⁄4»¦Ar1⁄2(r)+,'$B 'z '\n;±\n'z, ')¤*!\"!« s !\" D Go Go,e y\n* % \"\nN\nG1⁄2A1⁄4 b{\n?\n|(r)4L,'R \" #L,!*,\n;\n{\n|\nW ' ¤ 13\" «^G % ^ ' ' \\ ^4L,* ,*s^G$3 ,4L\"¤9 (z s,{| ')D *, (c) ' F51\nN\n7 8\nN\ny\n!\" @51\nN\n7 8\nN\n,BGM 4^ 'c51\nN\n7 8( % J ,£,M 13{ GM') * #z \"4L ¥,(us5\nA\n8{ 'K{ø\n')D *,\n;\n#\n1⁄2iozi ¿%$Vf\"E-@7*(\n,\"*>+64+\",04>37+0=7g-*u(\n{\n|\nW V D !24J'¦ \"~ GU J9 }F r÷,{| ')D *, z5\n;\n\n;\"N\n4o9r 'W!\"!0,{ '%ø\n*,\nN\n3 ¥4J'¦ \"~ G3, J{ '{ ')D *,B8K#r !\" ' GM,s ¤ % ,!. !\n, z,r }\n;\n#\n1⁄2iozi ¿%$V7+-g\",-*u(\nf\"49\",>.0/7g0pHG90D7*-,H+0/>@\"q-q7*0E>=7.0@\"/-8<.:/>3-47*>+-;:3-@7+-gH;-.-,:3T(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\n\n{\n|\n§ itK\n5vPzz8K ¥z£ \"# GM#,',{ M, GM!\"\n¥S4L\" *4^ 4\n{ \" #z ') ¥L\n;\nW { % S*A\n\n,$\n{B,*'(c), B ' *\n\nG\n\n4^ B £ ¥ '¦ £{ D \"A\n;\n#\n1⁄2iozi ¿%$\n7+-g\",-*u(\n7.0/7,-9:8*:E>3-47*6G-E7+0q\"4<9:/\nC\n49\";04hhKj¡ \":¢:£¥¤j+:/-8>3\"4*>*:8-G7*-,\n+:E*5 \":¢ 8@5v¢¥z£%8@5v£¥: @8(\nf-47*\nC\n*\"90G\"4-3<.:?>3-47*>*08\"G*\",>+0E7*6¦B§¦<+0/\"8> >E*\",0q7*-;:39:D*\"g0p2(\nf\"4*F(c)-a\"f<9-,>;\"g-*\"+0E7g0p\n5v -z¢ 8@5v¢¥:£ 8d(\n«.\nC\n*:D*:E>3\"4*>,:4.:E-37*-,:3>q+:3-4>=7*03\nC\n*\"*0/h +0/-8\n£F9-,>.:?<;-.\",03> >/7.03>¬<+\",>,-*\"*0/>?\"E.:5>3-47*6(c)-a\"fT(\n{\n|\nW J # ' J !*9\nG ')* A\n,*#,B4J u\"n(r)\n\n')R\n;\nJ D D *,R -M ¢\nG ')* T s ,P o*U,U G # { , $¢\n;\n' ,'-r,!*\nE\n+,!*!\" * # 9o*L4JD13\"4L,!O 9\n;\n°\n°\n°\n°\n°\n°\n°\n°\n°\n°\n°±\n3μ\n¶\n·\n·\n·\n·\n·\n·\n·\n·\n·μ\n·\n·\n·\n·\n·\n·\n·\n·\n·μ\n3μ\na\n¢\n\nP\nM\nP\n:\nM\n:\nP\nMYo\n<\nM\nO\nA\nM\n=\n=\nM\n=\n=\nM\n:\n\nM\n\nO\nM\n=\n»\n]\n£\n#\n1⁄2iozi ¿%$Sf\"E-@7*(\nf-47*6?g\".\nC\nq\"@,:4*\",61⁄4>@-/79037,>+:/-8>3\"4*>;:@-31⁄2¡]z -z£¥¤VD7,(\n¡¢¥\n»\n\\a3⁄4¤\n47+-,H;-+:q+-;\"903\"p>1⁄42(\nf\"4*>;:@-3>5\"@,:3>=*657+0o7905\"@-5H=-p>3\"4*6(c)7+0o7Z07g-.\nC\n(c)9:/Z\";0@\"3>3-47*-.:E*:5T(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\n:\ne¿Aree¦i E\n¿\ni\n§$3{| ) \" #\n7 { { . ., !*GJ!\"*R, . £ % !$^ $3{ V 1\n;\nW W\" { *`£ } W,F÷s£,'G ur!* #D\nA\n\nA\n\nzA:A:A0\nAAA\n54J ' G±\"¥ £ 4^ 'W,13 Gø9*~ £ ') '). $s R, 8\n;\n/(, ±!\"* £± ,!*G\nD z4L, Ao ,', ')\nN\nW 1 ^\"!* μ )ø9!\"*#, G\nN\nGJ')G ¤, D z| { !\" ^\n!\"*\n;\n\n.\n!*\" z \" \\£,'G ¤+')4<A( CÆ\n5\" !\" B 8\\ L z 4^ '¤,u{ ¤D z G\n,| z!\"*\n*]iKEAH_\nEE:E`I\nA\nE\n_o5Æ^_6A98\n;\n\n, !*Gn!\"*R, ¥ $3{ ) £ 1 L9±,V ±9r,*Gn!\"')#\n{ ¤D z G\nu!\"* IQ'4J!\"!$\nN\n, !*G\n!*\"R u4L\" *4J*~ z 4\n9B '¤!\"!!*\" ¤|\n} ') z,| z 4^ 'z z{ , ¤D z G\n,| z!\"*\n;\n¶\nB ze zIL\" ^!\"#,' 4\n+,'\n\"{ ', !* 4\n;\n\nD * ' \" #£ *4L zc\n#\n1⁄2io^iF¿%$\nI\n*>,\".-g:D*F3-47*6q-E7.0=7g-*:5\nC\n9:3-4>8\"p-/7+0579-;6q\"E.:G-E7+05\"59:/-G2(\nÐ*:31⁄2NO\nÆ-OO87*0/7.037*63-47*>.0q\"39:5+\"g<O-O:;-.\",03uO-O\ns3\"4+:3<9\",Bk3\"4*>,:@-5<.:?>3-47*>,0l\"@+:E*>.:?>/-@\"5-=7*0Et.0?>3\"E+-9\"g-9:/-G\nC\n479037*>,0q7+-;\"*>;047+0E7+-;:3*:E,H.0D7*0E\n+-g\"g>g\"90/7*-,-yH.0/7*65+:p<+-;:49\"*0D7*6=-p>3\"p-q7*-,\"*03\"39:/-Gt.0/7g0p>3\"4*\nC\n.0E\"8,\nA×z×:×\nÆEs09:G-/7.0E790/\"G>3-47*6E*:5+\"90/790/\"G\nC\n.:E-87,-yu(\nI\n*>;\"+0/<*:o-q\"E*\",-,mN^O\nÆ-OOE*\";0@\"E,\"90D7*-g:p<+-,F?.\"g-g-.\nC\n,u1\nNO\nÆ-OK\n4L\"\nIUØ\nEU\nUYU\nEvÞaß`UYU\nI\nÞaa`a\nNO\nAaO`N5vAX_5aIO\nÆ-O¡_JIO\nAaO*8)8\n\nC\n47*0E7*JIO\nÆ-OK\nE\nI E\n\nA\nI\n(\nU>3+0=7g-*H.0?>3\"4*6D7+-g:@*\",JIO\nA×z×:×\n÷O;-+0/H=*>9:/9:39-+\"g-g:p<;\".05\"q-@\"3*:8\n90/Auu5u÷u8A379057*(\nf-47*>*0l\"@+:39\".0/t+0=7.0D7*>,-+:p,63\"4*6?7.-g\"g-.\nC\n9:/-G21\n90/<.:E-8*:E>37.>.0q\"39:5+\"g-g0p\n3-p\"q*\",-*:3\nC\n.0E\"8,\nA×:×z×\nÆ B\nC\n*65-@7,03>?790E7,03<.:q-379057+-g\"g0p>3\"p-q7*-,\"*03\nC\n.:E-87,\nAO×z×z×\nA?7.0Et,-.057*JA a\nÆ B6+0/\"8>3-47*0/>q7g-+\";-*F3-47*6E*:5+\"90/790/-G\nC\n.:E-87,JA N\nAO×z×z×\nÆ1⁄2.:/>3-47*6?9:/+\"g>g-9:/*u(\n,\"90/\"G>8\"p-/7+0579-;6q\"E.:G-E7+05\"59:/-GB\nC\n*H;-.05\"q-@\"3*H*-+\";04>D7+-g:@*mN^O\nÆ-O90/<,\"*0l\"@*:/;\"*6?.:E<+-g\"gJÆK\nA×:×z×\n÷i(\nw+\";04>D7+-g:@*>9\",6E*:l-@790E7*-,ius5u÷u8A379057*63.>;\".05\"q-@\"3*7Bk?7.0E<+637.037+-g6E\"@-/\"/9:/-G>379057*\n.0?Auu5u÷\n\n8(\nU-?\"3*:E>37*0E-5790/7+0379-.:/BRNO\n÷uO\nC\n9\"g-g>;\".0/\"3+\"90/>3\"4*6D7+-g:@*>.:?>3-47*>.0q\"39:5+\"g>,\".-g:@-39\".0/uæ\nC\n*>;\"+0/HE*\";-.0/7,03\"E-@7;03H3-47*>,-.\"g0@\"39\".0/<9:3,\"*-g:?cs§3-47+03<9\",Bk3\"4*>g\".-;\"+0379-.:/,\nC\n4*:E*\nC\n*>,:4.:@g:8\n90/7,-*:E-3tg-9:/*6=\"E*\"+0e7,-y6=\"p>5+\"90/\"3+\"90/790/\"GcO\"O=7+-;0e\"q.\"90/\"3*:E,7O-OF+-,>9\",6@,:@+\"g-g:p>87.0/7*\nC\n9:3-4>8\"p-/7+0579-;\nq-E7.0G\"E+:5-5790/\"GT(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\no\ne¿Aree¦i E\ne\ni\n&(')* I¤!*#,') 4J*e5\nO\n{ '¦ 8\n&.!\" *!3 { ,!2\"UI¤!*#,') 4L\"J W+,' G±&(')* W* !\"!* Oe\n;\n¶\n,4L . % £ '\n'9$B!`{ ,!*, :I« J{ !*, W U' !\" D £ UU+,'4\n\"\n¤ B')R\n;\nJ{ '\" W W U4L9B L,!*!\n. '{ 9\" ¤Q'4° z{ ,!* *eIK!*#,') 4L\" z ¤ ',9R,\n+,'4\n* #u+ (r) '\"{\n£{,9\" !* H\"3 '-r '')')\n;\n-r'*4J{ !*\" $\nN\n!\" L £,9 4J K D H{ ')* 1*£-B '')')u ,£*~\nADN\nG± % S '÷\n{ 9\" Te\n\n\\e\n\n×:×z×\n\\e\nA\n9r u') !\\ 4^| '*~ z £\n<\nG\nA%;\n\n{ ', !* 4\n\"W UG |*G £ L{ ')* 1*{,9 *, * UQ\n,'!\",GB{\"B!\"\nN\nH D u,!*!\n'z{,9 *, z*!\"!( ') {'¦ G+')46IK!*#,') 4L\"L e K ')R\nGJ D s 'z-B '')'\nz\"!*!2 r 'W| 9r '){ R G\n;\n\nW ')B, *{ ') !* 4o* K&2ø9 ')G\n;\n, *G '« ¥+!\"!*9z\" #¿i1⁄4zi§1⁄4J{ { '913\"4L% \"M!\"#,' 4\n;\n&\\ J 4ie\n\n\"s ¥ ' J,'!\",G\n;\n\nN\n+'iAK\nO\n\nP\n\n×z×:×\n÷\nN\n{ ne\nI\n* ') ±'!\",G D ± ,H' ,4\n+,'H\n5,'¥ '¦ ±M\n')!*,G±* 9,'$|8\n;\n-r'W 1|4J{B!\"\nN\n*!e\n\nK\n<¡×uON\ne\n\nK\n<¡×u=N\ne!iSK\n<¡×u:N\nGneYðTK\n<¡×uPN\n£ ' )ø9,\n!\"#,' 4\n, !*G2{ !*, ne\n\n, Ge\n\n* ') ±')!*,G\nN\ne!iU\" , G2')!*,G\nN\n, G\neYð¥\"s ^ ' H,'!\",G5\nz ') ') ¥\"K *!\"! , #'F4J8\n;\nK% B% H,!*!G \"*, ,' ^4JG\n`nJ* zI` SG 3\"G z s{ '\" 91\"K÷{,9 *, ¥\" ,'!*,G ^| Q' s$n '\"{B^ B S, ,!*!$\nU4L,G\n;\nAoW H{ '\" 91\"£ ,'4J* # G\nN\n')\"#\nN\n£,9 '¦ G\nN\no\nW H ' ø9 J,!*#,') 4 *!\"!\n,!9$34J* *4J*~ K K % ,!u 4¥ '£,«,'(c) ')*{ £ G G\n;\nu\n¶\nr J±, ') 13,4L{ !* K\nW',*#,1*!*,*4\n;\n#\n1⁄2iozi ¿%$\nÐ7*03m÷JK\n=\n+0/\"8<g\"*03me\n\nK\n<¡×uP\nB(r)e\n\nK\n<¡×uC\nB(r)e!ibK\n<¡×uO\nB6+:/-8me!ðbK\n<¡×\noL(\nf-47*>.0q\"39:5+\"g\n/\"@-5\"=*:E<.0?<;\"+0EH3-E790q,F/*\"*087*08<9\",\nO\nB\nC\n49\"g-*63\"4*6?790E7,037Z0?7903t+-g:G.0E7903\"4-5Hq-E7.08\"@;\"*-,\nP\n;\"+0E>3\"E9:q,u(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\nC\nePo&\\'9r « D (c) ' )ø9 ,!*#,') 4\nV¥'D *¥ G\nO;\n5UoSo o oo`yK\n4L,$')!*,G\n,U| !\" ` U ,!*Q !*!ac¬8\n#\n1⁄2iozi ¿%$\n7.0/7,-9:8*:E<+>;-+:Eg\".-+:8mc.0?<,\"90W7*J÷\nC\n479-;:4<9-,>g\"*-,\",63-47+0/H4+\"g0?>?\"@g\"gB69u(*u(0B(r)÷a\n<`×a\n(\nÐ7*03me\nI\n=7*63-47*6?9:E,:3<9037*05>37.6G7.>90/\"3.63\"4*6/7*0o\"3<;-+:Eg\".-+:8mi(\nf-4*:/B'8-@7*\n37.63-47*6/+:3-@\"E*H.0?>3\"4*6?790E7,037Z0?9:3<+\"g0G7.0E7903\"4-5uB6903H?.-g\"g-.\nC\n,F3-47+03m÷Ne\nIø\nA\n+0/\"8\ne\nI\nø\n<¡×a\n(\n«7*0/7;-*7B6;-+:Eg\".-+:8mu9-,657.0E7*63-47+0/>47+-g:?>?-@7g-gu(\n.0Et;-+\"g-;:@g-+:39\".0/Hq-@\"E-q7.-,\"*-,7B\nC\n*>;-+:/>3-E7+0/7,0?7*0Et+6q.0E\"39\".0/t.0?>3\"4*>g\".-+:8<.0?<9:3*:5me\nI\n?-E7.05<;\"+0E7g-.\"+08mj3.>;\"+0E7g-.\"+08\n<37.65+:e*>;\"+0E7g-.\"+08mc*:o+\";037g0p>47+-g:?>?-@7g-g\nC\n49\"g-*Fe*\"*0q790/\"G<;-+:Eg\".-+:8mi+:3<g-*\"+-,:3\n47+-g:?>?-@7g-gu(\nf-49\",>9\",6=*\";-+0@7,-*\n<¡×a\n_2÷aue\nI\n_\n<¡×a\n(\nU-?-37*0E\nC\n*6q7*0E\"?.:E-5>3\"49\",>.0q7*0E7+0379-.:/B\n*:D*:E-p<;\"+0E7g-.\"+08t9-,>+:3<g-*\"+-,:3>4+\"g0?>?\"@g\"g(\nf-4\"@,7B690?1⁄2u<9-,63\"4*6/\"@-5\"=*:E<.0?<;\"+0E7g-.\"+087,\nq\"E.:8-@7;-*:8>=-pH3-47*6?9:E,:3Z0?7903t+-g:G.:E9:3-4\"5Bk3\"4*:/\nA\nIuE\n\ne\nIy\n<¡×a\nuT(\nþ7.037*63-47+03>3\"4*\n.:q-379057+-g6/\"@-5\"=*:E<.:?<;-+:Eg-.\"+087,muCAI\n9\",>+03<g\"*-+\",03\nA\nI E\n\ne\nI\n(\n«7*0/7;-*7BJu!Mu AyI\nO\nB\nC\n479-;:4>q-E7.0D7*-,F3-4+:3>3\"4*6?790E7,037Z0?9:3<+\"g0G7.0E7903\"4-5>47+-,H+6E+:39-.F=.:@-/-8t.0?\nO\n(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\n\ne¿Aree¦i E\n\ni\n\n»A2»¦i»¦A1⁄2iAeAozi ¿s»¦1⁄2e»¦1⁄2\n#\n¿1⁄4A\n\n¿ i JA\n\n¿1⁄4S5\nO\n{ ,' 8\nI !\"')# J 4¥ '«{ ', !* 4JW D L 9\n') + 'V U,{ \"4L\"~D *,\n{ ',B!\" 4L\nN\n, ,!*!$G D\nR¥ \" #sIK'¦ ')1*\\ \"4L\n;\n* #sI¤' '1\"K, ' ^ G\n4L,$\nR *#,\n;\nWB $± ') ^, '\n4J$m \"J{ ') !\" 4L\nN\n,4L 4J{ % \" ,!V G2% 'H %\n;\n\" #3IK' '¥μ 29, #\nG|* *{|9 '+ !¢*~,'G\n'!\"*\nL!r V ,4L{ D *,B,!0{ ', !* 4J\n;\n\n^\"\n' 4J') GS % £ H4L\"# $n ')!*\"n G '¦ L^r9$r,# H\"3¥ *4J H4L, *\nN\n,R\n:;\"<=,:\n*S\n-r,!*!2\nO,<<,<\n, GU B GH 9RF*!\"!*u J9,!B 4L,$3,r ,!*!\" # { GH J *4\n;\nH V L{ '¦ ,r \"} \"\nN\n1\"!*!0 4J r { ', !* 4J{|, GH L \"4\n;\nA\n\ne¦»1⁄2 1⁄4Aie¦A 1⁄2þy$\n\" #uIK' ')1*¤, ' ^ ,Gu÷R *#,\n;\nyK ' !\" G\n9r ', \"\n;\n/(\nR \"# SA¤ Ge\n}F D\nI\n¬ «F B4^ '¢ * «, !*Gz B '\n;\n/(, ^\n$Æ\nN\n\" ')\nN\n{ ' G G\n\nE\n, uR *#, % S z£, !*G *!\"!*\" #L\nu B ' $\n;\nW \" #\n\n{SM ')!*\"^ « Ru,§4J{ \" #H,*#, 4L £,§ * K R *#, W¤ %\n^R \"# « !\"GS 13 Gs *(c)} %\nN\nz \"!* ¤ r '$e\n$ÆL\"(c) B ' S$\n^R \"# +')4\n^\nE\n;\n5*8U7 9o o '!\"*M,3 4J{ !*9$\nHD1 ø9-.!*9o!\"#,' 4\n4J{ K H\"#ø\n4J\n;\ny\n')* s') * #L *4J s$r, 'z!\"#,' 4\n;\n\n, o4J $ 13{ ') 9$r, '\n') * #£ \"4L * #L+ \"u5aY8\nN\n' u578G % ` ') * #£ *4J\nD1 ø9-.!*9Z,!*#,') 4\n,UL £,'Rz iur '¦ \" G G #\n;\n#\n1⁄2iozi ¿%$\nI\n*65+:e*>+6G\"E+:q-4\nC\n903\"4m÷uNN\nO\nD7*0E\"39\";-*\",B±÷ED7*0E\"39\";-*\",\n\n×z×:×\n\nA\n;\".0E\"E*\",0q7.0/\"89:/-GH3.63\"4*6e\"/9:G-4\"3,7B\nD*:E-379-;\"*-,X£\n\n×z×:×\n:£!\n;-.:E-E7*-,:q.0/\"89:/-GH3.\n3\"4*H;-.0@\"/-379-*\",BF+0/\"8>3\nC\n.>,0q7*-;\"9-+\"g6D*:E-379-;\"*-,X]m+0/\"8ma7(\nI\n*6q-@\"3<+0/t*08\"G*6?\"E.:51⁄2]J37.\nI\nC\n9:3-4<;\"+0q7+-;\"903\"p\"\nI\n(\nI\n*6q-@\"3<+0/<*:8-G7*6?-E7.\nI\n37.m£\nE\nC\n903\"4<;-+:q+\";-9:3-p\nA\n9:?<;-.:@-/\"3-pmÆh9-,\nC\n9-g\"g-9:/-G>37.6=*6E\"@g\"*08H=-p>e\"/9:G-4\"3mA!(\nI\n*6q-@\"3<+0/t*08\"G*>.:?<;-+:q+\";-903\"p\nA\n?\"E.:51⁄2£\nE\n37.Ja(\nI\n*6/.\nC\n?9:/-8t+65+:o905\"@-5H?g\".\nC\n9:/>3-479-,6G\"E+:q-42(\n#0?>3-47*6?7g-.\nC\n4+\",6D+\"g0@7*$HB\n3\"4*:/>3-47*0E7*>9\",>+\nC\n+:p>3.>+\",-,\"90G\"/>e-/790G\"4-37,63.H+-g-g>;\".0@\"/-379-*\",BF+-,>+:E-G\"@*:8>/*:o-32(\na790/7;-*F3-479-,6?7g-.\nC\n9-,>9:/-37*0G\"E+\"gB69:3\nC\n9\"g-g6q79-;:e<.:/*>9:/;\".059:/-Gt*08\"G*6?7.0E<*\"+-;:4\n;\".0@\"/-3\"p1⁄2£\nE\n37.64+:D*6?7g-.\nC\n.0?\nA\n(\n#:?>3-479-,>*:8-G7*>;-.:5*\",6?-E7.05He-/9:G-4\"3\"\nI\nBk3-47*0/\n;\".0@\"/-3\"pmÆ1⁄29\",6E-@7g-*:8>=-p>e\"/9:G-4\"3mA!(\nf\"4*FE-@-/\"/9:/-GH39:5*>.:?>3-479-,>+\"g0G7.0E7903\"4-5<9\",u5u÷AN%\nN\nO\n\nE'&\n\nE\n&\n8d(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\nAD<\n5¦*\"8e ')!*\"L') B` *`!\"#,' 4\n5Q',4°&u,' ^5¦*8)8`B u W!\"#') 4°G \\ % { ' G W\n,*#,B4J ^ D S s') } *') 4L\n;\n* #I¤' '^G 4J G ^o 13{ !\" % \"\n;\n')!*\" 13{ !*,* J *J,!*#,') 4\n(* #3IK' '\nN\n, G)* #3IK' 'H*J3* G\nD W !\"#') 4\n*')'\n;\nTV z G % z !*\" r M ')!*\"e , 13 GJ *\n,!*#,') 4\n,'') !$2 J#r n\"B J,§ J{ ') !\" 4\n;\nyK '!*\"\n,3\" L *4o D s U*#, 4L u*{* !\" u\"± \"z{ ,' * !\"',\n;\nT(c) G\n\n$B ' G ' G * #U,\nM%1 ø9-.!*9\nN\nD u{ ' , !\"G±$r,\n##, :co5 ¤D D\n$B '{ 'F( '% #%$n !\"GS£,'Re+' r '¦$n\" H,0 H{ ', !* 4\n+,'(c)B\" 3\n% \"+ '¦$3*#, 4L G D 13*\n;\n#\n1⁄2iozi ¿%$*#:?>3-47*0E7*>9-,6/7.6?g\".\nC\n.:?<,-9:W*$\nBk3\"4*:/>3-47*0E7*65-@7,03<+>;:@-3<9:/>3-479-,\nG\"E+:q-4t.0?<;\"+0q+\";-9:3-ptg-*\",-,63\"4+:/t(\nÐ.\".0e790/\"G<+:3>3-47*>,03\"E-@7;03\"@-E7*>.0?>3\"4*>;:@-3uB\nC\n*6/.:3*F3-47+03>3\"49\",6G9:D*\",>+>,-*:3mI\n.:?<;-.:@-/\"39\"*-,H,0@7;04>3\"4+:3<90?>3\"4*+\n9-,\n3\"4*F@-/9\".0/t.0?>3\"4*>,\"*037,m\nE\n?.:EmÆ-,IABk3-47*0/>3\"4*>,:@-5\nI/.10\n\nI\n9\",>g-*\",-,63\"4+:/\n&\nI\n&\n(\ns2#u(*u(0Bk3\"4*:E*>9\",>+>,0@\"=,\"*03<.:?<;-.:@-/\"39\"*-,H,0@7;04>3\"4+:3>3-47*6l-@7.037+-,>.:?>3-47*\ne\"/9:G-4\"3,F3-47+03>3\"4*:p<+0E7*\nC\n9\"g-g\"90/\"G>3.6=7*6E-@7g-*:8>=\"p<9-,>,:5+\"g-g\"*0E>3\"4+:/>3-47*6/-@\"5-=7*0E\n.:?<;-.:@-/\"39\"*-,H90/>3\"4*>,:@-=7,-*:3T(§y\n(c)7*0E7g-9:/<;-+:/>q-E7*-,\"*0/\"3>3\"4*>,\"*037,JI\n+:/-8\"+\n3.\nU\"E-3\"4-@\"E<*:o-qg\"+-9:/9:/-G\nC\n4\"pmI\n;\"+0/>/7.03>=7*>+-,\",-9:G-/7*08He-/790G\"4-37,(\n\nEI\"IDIBEDI@ÐBNDOBIIBNI%IsO(O)OO@×¦Ø*OUU+U,OU.Ø*Y O,Þ0ß\\a Oa6aa U,Þaa ×Ø\"UY æc\neKOaJU\nAA\neP% JAr1⁄2 3»\n[\n1⁄4z¿i iAre\n\n1⁄4»Ar1⁄2y$«Iu S, !4J \"B#^,¢ ¤R *#,\nN\n\" #¥I¤' '«B% D\nB ',!,uR *#, ¤ B ^ ,' Gu sG r !\"{,d *\n;\n7B G \" #s *¤ G '9r '¤,#\nN\nL ,z4J ,# G± e G\n, se!\"* s,(c)!*!`{|,9\" !* LG !\"!*\" #e{ \"'\n;\nyK L °z\"9 W\n1|*!* e4J!\"! ,R *#, u9£9$\nU D\nG !*!\"* #{ ,*'L' 4L,* u% u e, !\n4J \" #\n;\nM ')!*\"S*(c) 9A9 «z * RJ0 G \" #¥, (c) * SR *#, ¥ GS99$\n;\nTV \" #^^{| ')+ \" \"\nN\n'!\"*z\" ^ G K4J!\"!* B ¤ !\"GS GS\" ^ )1|*!\"\n;\ny¤ r '\nN\n,μ 'z4¥ U , #\nN\ns*z !\"\nGU u{ \"4L,!(9,!* *,o * #\n,$\nzIJ* !\"#,' 4\n;\n5*8U/213{ !*,*£$co5\n;\n\n;*N\nD ¤{ ') !\" 4o\"\\M ')!*\"£ '¦$3* #V 9,!B G£z$±*\\ !\"\nLG J\n;\n#\n1⁄2iozi ¿%$Sf\"4*>,\"*03<.:?>e-/790G\"4-37,63.6=7*>*0o79-g\"*08H?.0E\"5<+6D7*0E\"3*0ot;-.:D*:E<90/>3\"4*\n9:/;\".05\"q+:39:=9\"g-9:3-pHG-E7+0q\"4T(\n9:/-8790/\"G>3-47*>,057+-g\"g-*\",03t,0@7;04<;\".0D7*0E<9\",6þ 47Z-;\".05\"qg\"*037*\n+:/-8H3-49\",>9\",\nC\n4\"p>(c)*:Eg\"90/<9\",6@-/7+0=7g-*637.>,-.\"g0D7*63-47*6q\"E.0=7g-*:5<*:?-?79-;\"9-*:/-37g0p2(\n5¦*\"8ey¤ o !\"GUM ')!*\"H£ ,R U \"#,,!*u J GUL') , !\" ,!* *, dc\n#\n1⁄2iozi ¿%$S«7*>;-+:/>@,\"*>+65Z\"+0q\"q-E7.0o79057+0379-.:/<+\"g0G7.0E9:3-4\"5>?7.0E877*0E\"3*:o>.:D*:E<+0/\"8\n3\"4-@7,>*0o79-g\"*>+>,:@-=7,-*:3<.0?>e\"/9:G-4\"3,>.:?<,-9:W*>+:3>5.\",03H3\nC\n9\";-*F3-47*>.0q\"39:5-@\"5>/-@\"5-=7*0E2("
    },
    {
      "category": "Resource",
      "title": "practicefinal.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/581317b8494540c79fc2930cff1d8de0_practicefinal.pdf",
      "content": "!\"#%$\n&(' ) *'+,) -!/.1023\n45\"67-48:9<;>=-5)7<;>6-8@?\n'@A \"B DCE!\"#-' 3F\nGH$\n;%=I1J6-6K\n&L'M* H-'&L\"> ' A$2NO- AQPR' S)A -'\nTVU(WYX[ZR\\X[]\n^>_`Ubac\\dGWfehgjikWfl\nmhn\nF % o-pq B )r \"stq@N !\" o )!u$v- Q'M A )'M AB DA F\nm\nS )w !1 A >\n;>J-?)6-6Bxy{zDy\nm\nS )F 02-3|)F!)-H A}t~ -N\n- }3FH$c D ' Q)A FE - Ao'M M\n=/\n\n[\n;-;\n\n'M)t\n\nmk\nQ r \"stq #-)\nI\n' $v- 'o 3D Q pEEkGp #- \"Q \"fr \"s\nt~ -N !)\nI\nt~ R p #- [)!\"!/t~ p '% AQ*'#-'-A ) #\nmk\n' R$< '-!) )- \"B p p 'M q)A A\nv$< Q AQ3F-' p\nI\no'M -B :M\n- E \" ) # p 'Mt !\" 3\nn\nY % p p ' - E ' Y- p 'Mt !\" 3\nt Nv H -'-<% 'Sp '-t !) 3\nm\n&(!)-$v 'v \"3F ) !$\nn\nE > Sp~ A @3f \"3F ¡-Y$- ¡p '-t !) 3\n5£¢\nA ' #-\n-!)!:¤ 3¥w 'M ¡- Ao> M - N¡ 3¦) L'MA '< > £!\"!)Ho<$< 3F-N / L3F-§ £p '-#'M\nmh\nH(c)$< 'R'MN\nI\np ' \"!['M A )!\"![t~ F#-<\n5B\n- a)!\"![t~ F#-'-A Ak > - !$«\n-''M R$v- 'R- § '\nI\nt -!)Yf !)-' $o f ) f$v- 02p ' R\nPR %\nmk\nA '\"t ) #¬-!)#-' 3\nI\nA '\"t~ Y a3D\"}\"A k\".L #-!)\"H\n5(r)\nap A A\n- !$O 0 > o !\"p !)-'\" $O 3D\"Q)A -\nmh°\n@ AQ!) N ±\n2E-3F\n?\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\nJ\nY13⁄4vÞßa A\nA~a\n\n' or@ < )-\nf -!)!\"Ho\" #Br@ § )-\nI\nw !\"!q ¡ < Et !)- NFtqH02\nO 3D'M £ O E '¡)R-''M\nI\n$v- j !)Ajp 'M q)A F QÞ[a a¶aa1·3⁄4uaD·æ''M G- § '\n.\n#\n5)I\n-'cr )-ee\n\n' \" #c-Se\n!) 3D \"D -3Fp -'\"H-eHt A`3F@A !`t~ A - )\n\"3F i\nI\nt~ f-''M\n'B)FiiieD!\"#enð\n2E¬p ' \"!R' A D)!\"!Rtq #< -'D-''M Qt ` t~p )3D!R '\noEH v '\nI\n$v- o3⁄4·3⁄4v¶o < R Dp<'MH2)A -$Oo )w % \"\no\no<oc÷S )A 'a3F A \"w > )- ¬øouu u2u,yþ,yI\n> F \"3F y1u1u þ (r))!\"!) A\nI\n3D A<\"F@ p -' )- A'M'H$Q\"L - Ai \" # vu-!)#-'M 3Fð( A A\n-Fp v>\nS R-' MeH ' \" # )3D v )!\"#-' 3e)\n?\no\nÞocDA > F ' ' H p p~-' Sap~ '% \"BH B > D r -~e-3\"n N-\n\ni{eD!)-#enðo \"3F ap~ ' -'3\n\"c 'M ¬\nI\nc G-3F-' )s A \"3F G-\n-p~ 'M> )-Q)\n\nI\n)!\" S <-! )3D -F) #-!) Dp~ 'M> \"Q- !)A\nt~ - \"#Q-\n\no\no\nn\n< 'M L 02) ¡pq-!$q 3D)! \"3F L!\"#-' 3} % ¡w A < /u!\" £- [3D) \"3Y 3\n)QDA )'M AQ#'Mp \"!\ni\n\n-'2ð\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\nK\nY13⁄4vÞßa A\nA,a\n' -'+<!\" #!\n+v-' Y- £r \" t~ !)H\nI\n\"'!\" ¡ '%$\ni -''M ð'%&\ni -'+v-!) ð\n`3⁄4Oa'\nA\nßo<·o<¶μ3⁄4~·a\no 1a·a a@oa@o\na\n-''M o- 'M' - 'M AQr \" 'M R' Qs 'Dp~)\n$\n&\nP$\nO3D ' 'M 3\nI\n!\" \"` O'M ''M )(i{enð*\nK\n(i{e+\nK\nð-,\n!\"#e¦)\n(iienð-*\n\ni{eD!)-#enð\n$\n&\n÷S3Dp \" #£ ¡3F A \"Y-e\n!) 3F ~ N- /.iieB!)-#enðv \"3F £ '$!\"#-' 3j-'N@) #\n\"B -3Fp -'\"eHt AQ3D A !\n$\n&\n.1v '$¬t ) -'$¬ -' B ' -De A )#- oii!\"#enð\n$\n&\n°\n< aD#-'-p 102*Vi4365#7oð, a a A #- S-<AaD )8:9;3\nI\n!) i=<65>~ðSt~ -a A #\n% `i=<65>~ðE)£ f3F\" )3f 3\n- D A #- Yt~\nG-$`< ' 0c)?8\nAG-$Qv ' 0\n\"@3A8\nS\nI\n3D) \"3Y 3æHp - ) #S ' -B0¥3f E\" !\" A [ A # fi=<65>~ð\ni\n\n3DH$¬ 3F R -Q!\"!/ A # -' A \"§ )\nI\n\" A A\nð\n$\n&\nC D(æt~ F3D) \"3Y 3ep \" # ' 60\n\nI\n-'-$Gp \"'-v< ' ) Eo- AF\nI\n\n-' op > Q 'M3G HE\"10æ\"[ p > Q '-3G HE)F(\n$\n&\np 'Mt !\" 3JI\n\n)pq-!$q<-3F\"! )3D L' A )t !\" / p 'Mt !\" 3JI\n\nAI\n\np~!$q 3D)-!\n)3D !\"#-' 3\nI\n1I\n\n-Fp~!$2 3D)-! )3D !\"#'M 3\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\nY13⁄4vÞßa A\nK\na\n' -'+<!\" - A\n\" $\n+v-'£ - -u r \" £t~ !)H\nI\n\"'!\" '-$\ni*'L' ðL'&\ni -'£+<!\" ð\n#-< ft 'M)\nLNM\na¶μPO\n\no ¶μ3⁄4v·¦ -'$< 'o '\n5a\n'o- § 'M)!\"!£t~ u!\" > Act Ac-` o\n§ )w % \"\nI\nA·3⁄4~¶ $\n&¦3F-'N \" #F-!)-\n$\n&\nS ' 02\" £fA % f ' ' ( f3F-) -)fA$2 -3F\"H Lo -pq 'M> )- ¡ ' @i{0\nI\n\nð\nI\nn\n!\" :i{0\nI\n\nð\nI\n-<AG 3ft~ 'Q!ui{0\nI\n\nðL % D --G 02p~ AG'M ) #o \"3F Y-Lii\n;\nðp~ 'Epe\n'M> )-\n$\n&\nS R > !13D' \"s AQ DH r@ ve-pq 'M> )- oi\n\n5\"I\n3eHv 'S!\"!/-p~ '%e\n)-\nI\n2 Y3D' \"s A¬- Dp~ 'p~ 'M> )-<ðE#v !\" 't~ AG- % -!, !\n- o-v r\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\nR\n$\n&\nC F0S*\niP365#7oðEt~ Yo \"# AG#-'-p G- AG!\" UT\nt~ YO3F\" )3f 3\np \" #o 'M Y-0\nS p % O)VT\nt~\n-$\np<-)'¡- < ' ) >\n\nA>\n\n3f < t~ Y ' p > \"V0\n$\n&\nS Dw # ' Dt~ !)H\nA 'M)t~ VW\n-)#-<3D \"kXW\n\n'MN\nD > > )-Y+[Z\nA 'M)t~ EY -6W æ)Q-Q A # p - $AZ\n' -'+v-!)\n?\n-!)!\" ) #UW Hæ)F3D>02\"3F-!%W H\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\]\n^\n_\n_\n_\n_\n_\n_\n_\n_\n_a`\nb\n^\nc\nc\nc\nc\nc\nc\nc\nc\ncad\ne\nc\nc\nc\nc\nc\nc\nc\nc\ncad\n_\n_\n_\n_\n_\n_\n_\n_\n_a`\n\nZ\nY\nK\n+\nK\n+\nK\n+gf\n+\nJ\n;\n+\n+\n+\nR\n+\nR\nJ\n+\nh\n\ni\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\nY13⁄4vÞßa A\nj\na\n$2pq M \" #\n\np p~ , ,- !)AD!\")N- , % !$f $2p~ R 0\nS S\" p )[ r S-@e-'A nv!) #>\nk\n\nk\n\n5#lmlmln5\nkpo\ni3D ' Aa\"Y 3ft~ 'S-w02 AeH)s 'M 'M, $ N- ð\n.L- a!\") a -!)A\n> o3F- qæ -'- 'M\nI\nS 0 f\"!) MeH!\")#- A\nI\nAD'MA - > otq p !\" ft~\n!\")\n\n,\n!)\" o \" (-'A 'M3srL ut\ni\" !\" < ð( F o 3ft~ '-np > o A\n-q o!\")\n)HF*vqw\nxymz{\nk\ny\næi=t|rHð\n\n- !)Ak!\")N- Y $2p~ M 0 FHa-R aHv-)Ak!\"'M#\np > o A\nn!\") Q}*'3D!\"!$\nI\n- !)A\n!)\"N 3F\" )3D)s o 3\nH< '!\"!!)\" q\nr 'M o-q o 3ft~ '~o op - > o A\n-q o!\")\n°\n< o` #~F\" f!\"#-' 3\n-'\n\"p '-t !) 3\n\n> ) ' \" # )3F #!\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\nf\nY13⁄4vÞßa A\n\na\n&L'M) C!)#-'M 3D)`i\nJ\np ' ð\n&,!\" )!2 p u-!1\"QC!)#-'M 3F\"D S -' Aa&L'M) S) !\"!)\n°\n-3F , u% '\n'H$<![p -!)- m}£ Dp !)- S Q' !\" > QQ -'3b\"\n2 t<'MN\nDp '\" S S Q3FH< F-!)!\n, 'p~ H\" *'3(c) op -!) )`CE!)#-'M 3F\" o2 t '-HN-\n-'3\n) # ¦ '\"p\np~-H\"t !) B\"¬ '+v ''M'M\n+v')3Dp !)\" $\nI\n!\" F -H 3D E > Bp 'M) 3)+< ''M'Mn -)s\n;>I\nAa % O 'e\np~ H\" E\n\n5#m#m5\no\nHv 'M !( 3ftq ')s ot~\nA\n;%5\n\np '-t !) 3b\"S QA q)A Fp 'M) 3)p~-H )- ) Q*\n-'!\"-A<p~\"t<!\"\nI\nB > -!)!\n'op~-H )- o)!\"!Lt~ 'M p~' A 'M3\nCE!)#-'M 3F\"F `2E t 'MN\nAD > 'o+< ''M'\no\"!)!1 v 'Stq Hv 'Mp N A\n\nS 'M<- )p 'Mt !) 3e)2E&1eH 'MA\n÷- )A '£ Y !\"!)Ho\" #@O1a¶#O¶Dp p 'H02\"3F% \"G!\"#-' 3\n&( D 3\n\n\" Yw ' D-'!\"-A\n\nI\n'rU*\nJ\nK\n5##mm5e\nI\np\n{\n) w 'M a'!\"-A > a -B' -3\n-'B\ni-'Y§ ' aG\n'M!)-Aa) H-'$qð\n+v'S 0q3Dp<!\"\nI\n)\n\n*\n\nJI\n\n*\n\n7I\n*\n\n4I\nAE*\n\nKI\nw ' MeHw-\n!\"#-' 3\n- !)A«p !)-\n\n- A?\n\n) w 'M§ a'M!)-A\nI\nQ\" - A«'M!)-A\nI\n- A\nY\" fw ' B-'!\"-Ai\no 'M 'M Y\"E§ )!\"! - #'@3Dð\n2E% <% B-!)!A \")- -' f3DA\nD) #}[ OA 2\"A o p '\" H3\"Ee¥p~-H )- Y\" -'!)-A ftq *' $k '\"p<f < O- -!)!$\nt~ Q3F-A\no\no<ocS Bp '\" H3\" -'3D) # t A\nI\n÷'M\"#\nI\n-H ' A\nI\ne\nS Bw ' eHw D-!)#-'M 3)!\"!\n-!H$23D) )3D)s E E % -!n 3Yt~ '-£-'¡ 'M)p A A\ni\n°\nv Da- 'M 02-3Fp !) E\n÷S'-)#-3)!)-)3\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\n=\no\nÞoc&('Hv £ > ¡ w ' MeHw -!)#-'M 3\nRY'> )Yt~ A\nJ5\ni4[oE\n3F-$'M!)-A\n-Qtq !\" [ Q -!)* !)!!¤ð\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\n\nY13⁄4vÞßa A\n\na\n\nμ¿1μaμ3⁄4~·j3⁄4Y3⁄4uaoa 1μ·`μ·6:1¶1⁄2\nM\n1{aUD3⁄4\nM\n1¶Oi\nJ\np -' ð\nC!\"'M# D 3Yt~ '£p '-t !) 3DS > F H\n'M 'R Q-p \"3F\"s> )-\np '-t<!\" 3F\nI\n- -!)!$A >\nt NY @\" #CE' 'M3)( \"3F\n) #C' '3\"E- ' f A\n3F-$\nN )#-\nS< $a 'M f- '\n3D$(r) \"Dp 'Mt !\" 3F\nI\n-3F 3Dp % \" -!R A«% 'B %\n\" #¬CE' 'Y «H- #\nAq) )pqH ' !)s-'A\n'!\")\nF!v R -3Fp > )-<-!/p '-t !) 3D\n\nf\"\n' 3D'M AO % B3F\"# $a 'M!)\"k A ' FfvH$v-# B\"¬Y )3D B3F- )\nI\n-N\n45\"67-4\n)O\n+v-!)!1\nJ-66-6\n- AQ < AB HN@)!\"!)n DH-!< 3F-$¬-v -!)!\" # p~ AB D )3\nB R Fp ' -v \"r \"\nI\n3\"!)!/ 3D v p '-t !) 3Dpq- AB F \"3\no\no<o\n\nM\nßμ·¶1⁄2aßo ·o¢¡\n\" #CE' 'M3)- ' f -Ae}N )#-\noE ' !\" A\nHv '-£|- \"\n.L\nN \"# r A`\nr@ > ¤\n{\n¤ £@ <3ft~ ' ) £- !)Ao < '\n.L- f\n$Ht\nI\n\" 'M\nI\np ' A A\n\n¥8\nx\n- N )#- % O o- !)At~ )!\"!)\" #F\nt~ < ' t$\nS @\" #\n\np~OG 'M!)\"f £ N-3Dp \" #B-)#- 3F - ) E N )#- S %\nfN \"# £ !\"AO 02 A )¡r %\nI\no \"!) v '$`\n$UtF\"¡ < ' Ot$\nfN \"# 'M3\nx\ni)ð\n\nHe e '!\")G-¬ 3Dp !)H$\nB>0 eH+,!)He!\"#-' 3\n3Dp E B\"#e\n3D\nn\n'M)t~ 'M ) #F )3D $v- 'o!\"#-' 3\ni\n\n- c3D $} 02p 'M H$v- '\n'M ) # \"3F ) #F \"§¦i >5m(c)ð\nI\n' )¦i=>5m(c)ðA % [ 'M ) # )3D\n>0 eH+,!)HV-!)#-'M 3\n-QF -'No F>v ' \" A1(c) A #\nð\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\n;>6\ni)\"ð` 'M!)\"F'M <[ )[!\"#-' 3\ni*'-3(c)&n-' fi)ðMð[t< n S!\"#'M 3(c)A ( % p ' A S\n-)#-<3D f > Ow 'M r )'M 3F\n) #C' 'fA 3D A fc 02p !\" % \"\n'M!)\" 02p !)-) D )D-!)#-'M 3\na) #¬CE' '\nI\n- A«) #¬CE' 'B)D2) A\n> S !\"#'M 3\n)'M'\nPR o A % ot~ !)\" v G 'M!)\"` - 02 AD )\n-!)#-'M 3b-''M !$« D#v k\"< D- Dp 'Mt !\" 3\noE '!)\"\n-2\" F )3e > Q)#- 3F )p~)t !\" \"a \"op -' ) !\"'-\nP¡ A\n\n$< ' A ' A ) #Q-\nG%0 eH+,!)H\nI\n> p ' - !\"Aa$v-\n##- § m!ei2> >\n$< 'p '@L '% #%$a !\"AO-'N` ' v '$a\" § B-/ Bp '-t !) 3\n-'¡<\" ¬\n% \" '$¬)#- 3F A > 02)\nð\n\nAÆ\"C>E<A>E:E<E>I<ÆE<EC%EILIMIÐ:NO)ÐOO O-IO,O)× I-Ø/U(U IU\nUEIUDO\n;;\no\nÞoD3⁄4v·6¬μ\n\n¶o1a a3⁄4vß\nM\n¶μ3⁄4v·¢¡£Cn O- !~3D \"<#f- N )#-\nI\n\" #YC' '£<% >\n< '-!-nN )#- < f -' A A v !\"p-\"W )\n\nA \" # ) A 'Hv '-#\nI\nF -o3D -# Aa `w A\n- `!\") -¡!)![pq-H\"t !) FA !\"!)\" #`p \"'\noE F (c)o\"H S\n0q)!) `3D!\"! -N )#- HH$\nQ >\nA !)!\") #p -)'F' 3F-) % `- !\n3D \" #\nG 'M!)\"O)¡ H1⁄4H £o ) ND/w A \" #Y- ¡ ) ON )#- Y AOHH$\nPR \" #ffpq 'M \" \"\nI\n'!\")o\" fw A E3D!\"!) < !\"AO AO\" f M0q)!\"\no v '\nI\n- 'o3Y Q - #\nI\n)o t !\"\nw AQ p \"3F-!LH-!) )-c ) #\n-$\n#~D) !\"#-' 3\ni)ðQ.102p !)-)$!ci\n\n5)I\n> p 'Mt !\" 3æ\"(G 'M!)\" '$2) #R H-!< Ao$a)( t !\"\nFA D\nð\ni)\"ð`o æ !\"AQG 'M!)\"B -N Q \"#--!)n Dw AQF'M - t !\" -!) )- \"!"
    },
    {
      "category": "Exam",
      "title": "prac_quiz1sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/f36fc83aa1a04bcefd37b939f9d7776f_prac_quiz1sol.pdf",
      "content": "Introduction to Algorithms\nOctober 6,2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 11\nPractice Quiz 1 Solutions\nProblem -1.\nRecurrences\nSolve the following recurrences by giving tight\n-notation bounds. You do not need to justify your\nanswers, but any justification that you provide will help when assigning partial credit.\n(a)\n\nSolution: Master method does not apply directly, but we have\n\n!\n\n. Now apply case 3 of master method to get\n\n. Therefore, we have\n\n)\n\n. Lower bound is obvious.\n(b)\n\n!\n\nSolution: Master method does not apply directly. But\n\nis much smaller than\n\n! ,\ntherefore ignore the lower order term and guess that the answer is\n\n.\nCheck by substitution.\n(c)\n\n/\n\nSolution: By Case 1 of the Master Method, we have\n\n;\n=\n?\n.\n(d)\n\n!\n\nSolution: By Case 3 of the Master Method, we have\n\n.\n(e)\n\n/\n\nSolution: By Case 2 of the Master Method, we have\n\n=\n\n.\n(f)\n\nA\n\n!\n\n=\nSolution: By Case 2 of the Master Method, we have\n\n=\nB\n\n.\n\nHandout 11: Practice Quiz 1 Solutions\n(g)\n\n!\n\n=\nSolution: By Case 3 of the Master Method, we have\n\n=\n.\n(h)\n\n!\n\nSolution:\n\nB\n\n. This is\n\n!\n\n. For the upper bound, note that\n\n, where\n\n,\nwhich is clearly\n)\n\n.\nProblem -2.\nTrue or False\nCircle T or F for each of the following statements, and briefly explain why. The better your\nargument, the higher your grade, but be brief. No points will be given even for a correct solution\nif no justification is presented.\n(a) T F\nFor all asymptotically positive\n\n,\n\n.\nSolution: True. Clearly,\n\nis\n\n. Let\n\n. For\nany\n!\n\"\n$ ,\n\n!\n\nfor all\n\n( for some\n\n( . Hence,\n\n)\n\n,\nwhence\n\n)\n\n. Thus,\n\n.\n(b) T F\nThe worst-case running time and expected running time are equal to within con-\nstant factors for any randomized algorithm.\nSolution: False. Randomized quicksort has worst-case running time of\n\nand expected running time of\n\n.\n(b) T F\nThe collection\n+\n\n,\n.\n\n/\n.\n/\n.\n=\n1 of hash functions is universal, where the three\nhash functions map the universe\n,\n/\n/\n/\n1 of keys into the range\n,\n$\n/\n\n/\n!\naccording to the following table:\n;\n.\n\n;\n\n.\n\n;\n\n.\n=\n\n;\n\n$\n!\n$\n\n!\n$\n$\n$\n\n$\n\nHandout 11: Practice Quiz 1 Solutions\nSolution: True. A hash family\n+\nthat maps a universe of keys\ninto\n\nslots is\nuniversal if for each pair of distinct keys\n;\n/\n\n, the number of hash functions\n.\n\n+\nfor which\n.\n\n;\n\n.\n\nis exactly\n\n+\n\n. In this problem,\n\n+\n\nand\n\n. Therefore, for any pair of the four distinct keys, exactly\nhash function\nshould make them collide. By consulting the table above, we have:\n.\n\n.\n\nonly for\n.\n=\nmapping into slot\n!\n.\n\n.\n\nonly for\n.\nmapping into slot\n$\n.\n\n.\n\nonly for\n.\n\nmapping into slot\n\n.\n\n.\n\nonly for\n.\n\nmapping into slot\n$\n.\n\n.\n\nonly for\n.\nmapping into slot\n\n.\n\n.\n\nonly for\n.\n=\nmapping into slot\n$\nProblem -3.\nShort Answers\nGive brief, but complete, answers to the following questions.\n(a) Argue that any comparison based sorting algorithm can be made to be stable, without\naffecting the running time by more than a constant factor.\nSolution:\nTo make a comparison based sorting algorithm stable, we just tag all\nelements with their original positions in the array. Now, if\n\n, then we\ncompare\nand\n, to decide the position of the elements. This increases the running\ntime at a factor of 2 (at most).\n(b) Argue that you cannot have a Priority Queue in the comparison model with both the\nfollowing properties.\n\nEXTRACT-MIN runs in\n\ntime.\n\nBUILD-HEAP runs in\n\ntime.\nSolution:\nIf such priority queues existed, then we could sort by running BUILD-HEAP (\n\n)\nand then extracting the minimum\n\ntimes (\n\n). This algorithm would\nsort\n\ntime in the comparison model, which violates the\n\nB\n\nlower bound\nfor comparison based sorting.\n\nHandout 11: Practice Quiz 1 Solutions\n(c) Given a heap in an array\n\nwith\n\nas the maximum key (the heap is a max\nheap), give pseudo-code to implement the following routine, while maintaining the\nmax heap property.\nDECREASE-KEY\n\n/\n- Decrease the value of the key currently at\n\nby\n. Assume\n\n$ .\nSolution:\nDECREASE-KEY\n\n/\n\nMAX-HEAPIFY\n\n/\n\n(d) Given a sorted array\nof\ndistinct integers, some of which may be negative, give an\nalgorithm to find an index\nsuch that\n\nand\n\nprovided such an index\nexists. If there are many such indices, the algorithm can return any one of them.\nSolution:\nThe key observation is that if\n\n\"\nand\n\n, then\n\n. Similarly if\n\nand\n\n, then\n\n\"\n. So if we look at the middle element of the array, then half\nof the array can be eliminated. The algorithm below (INDEX-SEARCH) is similar to\nbinary search and runs in\n\nB\ntime. It returns -1 if there is no answer.\nINDEX-SEARCH\n\n/\n\n/\n\nif\n\n\"\n\nreturn -1\n\nif\n\nthen return\n\nif\n\n\"\n\nthen return INDEX-SEARCH\n\n/\n\n/\n\nelse return INDEX-SEARCH\n\n/\n\n/\n\nProblem -4.\nSuppose you are given a complete binary tree of height\n. with\n\n!\nleaves, where\neach node and each leaf of this tree has an associated \"value\"\n(an arbitrary real number).\nIf\n; is a leaf, we denote by\n\n;\nthe set of ancestors of\n; (including\n; as one of its own ancestors).\nThat is,\n\n;\nconsists of\n; ,\n; 's parent, grandparent, etc. up to the root of the tree.\nSimilarly, if\n;\nand\nare distinct leaves we denote by\n\n;\n/\n\nthe ancestors of either\n;\nor\n. That\nis,\n\n;\n/\n\n;\n\nHandout 11: Practice Quiz 1 Solutions\ny\nx\nA(x,y) shown in bold\nf(x,y) = 19+15+21+36+20+30 = 141\nDefine the function\n\n;\n/\nto be the sum of the values of the nodes in\n;\n/\n.\nGive an algorithm (pseudo-code not necessary) that efficiently finds two leaves\n;\n( and\n( such that\n\n;\n(\n/\n(\nis as large as possible. What is the running time of your algorithm?\nSolution:\nThere are several different styles of solution to this problem. Since we studied divide-and-conquer\nalgorithms in class, we just give a divide-and-conquer solution here. There were also several\ndifferent quality algorithms, running in\n)\n\n,\n)\n\n, and\n)\n\n. These were worth up to\n\n,\n, and\npoints, respectively. A correct analysis is worth up to\npoints.\nFirst, let us look at an\n)\n\nsolution then show how to make it\n)\n\n. For simplicity, the\nsolution given here just finds the maximum value, but it is not any harder to return the leaves\ngiving this value as well.\nWe define a recursive function MAX1\n\nto return the maximum value of\n\n;\n--the sum of the\nancestors of a single node--over all leaves\n; in\n's subtree. Similarly, we define MAX2\n\nto be a\n\nHandout 11: Practice Quiz 1 Solutions\nfunction returning the maximum value of\n\n;\n/\nover all pairs of leaves\n;\n/\nin\n's subtree. Calling\nMAX2 on the root will return the answer to the problem.\nFirst, let us implement MAX1\n. The maximum path can either be in\n's left subtree or\n's right\nsubtree, so we end up with a straightforward divide and conquer algorithm given as:\nMAX1\n\n1 return\nvalue\n\n, MAX1\nleft\n\n/ MAX1\nright\n\nFor MAX2\n, we note that there are three possible types of solutions: the two leaves are in\n's left\nsubtree, the two leaves are in\n's right subtree, or one leaf is in each subtree. We have the following\npseudocode:\nMAX2\n\n1 return\nvalue\n\n, MAX2\nleft\n\n/ MAX2\nright\n\n/ MAX1\nleft\n\nMAX1\nright\n\nAnalysis:\nFor MAX1, we have the following recurrence\n\n!\n\n!\n\n(1)\nby applying the Master Method.\nFor MAX2, we have\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n(2)\nby case 2 of the Master Method.\nTo get an\n)\n\nsolution, we just define a single function, MAXBOTH, that returns a pair--the\nanswer to MAX1 and the answer to MAX2. With this simple change, the recurrence is the same as\nMAX1\nProblem -5.\nSorting small multisets\nFor this problem\nis an array of length\n\nobjects that has at most\n\ndistinct keys in it, where\n\n. Our goal is to sort this array in time faster than\n\nB\n\n. We will do so in two phases.\nIn the first phase, we will compute a sorted array\nthat contains the\ndistinct keys occuring in\n2 .\nIn the second phase we will sort the array\nusing the array\nto help us.\n\nHandout 11: Practice Quiz 1 Solutions\nNote that\nmight be very small, like a constant, and your running time should depend on\nas well\nas\n. The\nobjects have satellite data in addition to the keys.\nExample: Let\n\n/\n/\n\n$\n\n(\n/\n\n/\n\n/\n\n$\n\n(\n/\n\n/\n/\n/\n\n$\n\n(\n/\n\n/\n\n. Then\n\n$ and\n\n.\nIn the first phase we compute\n\n/\n\n/\n/\n/\n\n$\n\n(\n\n.\nThe output after the second phase should be\n\n/\n\n/\n\n/\n\n/\n\n/\n/\n/\n/\n/\n\n$\n\n(\n/\n\n$\n\n(\n/\n\n$\n\n(\n\n.\nYour goal is to design and analyse efficient algorithms and analyses for the two phases. Remember,\nthe more efficient your solutions, the better your grade!\n(a) Design an algorithm for the first phase, that is computing the sorted array\nof length\ncontaining the\ndistinct keys. The value of\nis not provided as input to the algorithm.\nSolution:\nThe algorithm adds (non-duplicate) elements to array\nwhile maintaining\nsorted\nat every intermediate stage. For\n\n/\n!\n/\n\n/\n, element\n\nis binary searched in\narray\n4 . If\n\noccurs in\n4 , then it need not be inserted. Otherwise, binary search\nalso provides the location where\n\nshould be inserted into array\nto maintain\nin\nsorted order. All elements in\nto the right of this position are shifted by one place to\nmake place for\n\n.\n(b) Analyse your algorithm for part (a).\nSolution:\nBinary search in array\nfor each element of array\ntakes\n)\n\ntime since size of\nis at most\n. This takes a total of\n)\n\ntime. Also, a new element is inserted\ninto array\nexactly\ntimes, and the total time over all such insertions is\n)\n\n!\n\n)\n\n. Thus, the total time for the algorithm is\n)\n\n)\n\nsince\n\n.\n(c) Design an algorithm for the second phase, that is, sorting the given array\n2 , using the\narray\nthat you created in part (a). Note that since the objects have satellite data, it\nis not sufficient to count the number of elements with a given key and duplicate them.\nHint: Adapt Counting Sort.\nSolution:\nBuild the array\nas in counting sort, with\n\ncontaining the number of elements in\nthat have values less than or equal to\n\n. Counting sort will not work as is since\n\nHandout 11: Practice Quiz 1 Solutions\n\nis necessarily an integer. Or, it may be some integer of very large value (there is\nno restriction on our input range). Therefore\n\nis an invalid index into our array\n7 .\nWhat we would like to do is assign an integral \"label\" for the value\n\n. The label we\nchoose is the index of the value\n\nin the array\ncalculated in the last part of the\nproblem.\nHow do we find this index? We could search through\nfrom beginning to end, looking\nfor the value\n\n, then returning the index of\nthat contains\n\n. This would take\n)\n\ntime. But, since\nis already sorted, we can use BINARY-SEARCH to speed this\nup to\n)\n\nB\n. Let BINARY-SEARCH\n\n/\n;\nbe a procedure that takes a sorted array\n\nand an item\n; within the array, and returns\nsuch that\n\n; . The modified version\nof COUNTING SORT is included below, with modified lines in bold:\nCOUNTING-SORT\n\n/* Uses Arrays\n\n,\n\n, and\n2 -out\n\n*/\nFor\n\nto\ndo\n\n$ ;\n/* Initialize */\nFor\n\nto\n\ndo\n/* Count number of elements */\nLocation\n\nBINARY-SEARCH\n\n/\n\n;\nC[Location]\n\nC[Location]\n\n;\n\n;\nFor\n\n! to\ndo\n/* Build cumulative counts */\n\n;\nFor\n\ndownto\ndo\n/* Construct Sorted List A-Out */\nLocation\n\nBINARY-SEARCH\n\n/\n\n;\nOut-Location\n\nD[Location];\nD[Location]\n\nD[Location]\n\n;\n2 -out[Out-Location]\n\n;\nOutput(\n2 -out);\n(d) Analyse your algorithm for part (c).\nSolution:\nThe running time of the modification to COUNTING-SORT we described can be bro-\nken down as follows:\n\nFirst Loop:\n)\n\n.\n\nSecond Loop:\n)\n\niterations, each iteration performing a BINARY-SEARCH on\nan array of size\n. Total Work:\n)\n\nB\n.\n\nThird Loop:\n)\n\n.\n\nFourth Loop:\n)\n\niterations, each iteration performing a BINARY-SEARCH on\nan array of size\n. Total Work:\n)\n\nB\n.\n\nHandout 11: Practice Quiz 1 Solutions\nThe running time is dominated by the second and fourth loops, so the total running\ntime is\n)\n\nB\n."
    },
    {
      "category": "Exam",
      "title": "practice_quiz1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/b6584cd7e7b738d85519048d75ca49e2_practice_quiz1.pdf",
      "content": "Introduction to Algorithms\nOctober 4, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 10\n6.046 fall 2005 Quiz Review--modified from 6.046 Spring 2005\n1. Recurrences\nSolve the following recurrences by giving tight Θ-notation bounds. You do not need to\njustify your answers, but any justification that you provide will help when assigning partial\ncredit.\n(a) T(n) = T(n/3) + T(n/6) + Θ(n\n√\nlog n)\n(b) T(n) = T(n/2) + T(√n) + n\n(c) T(n) = 3T(n/5) + lg 2 n\n(d) T(n) = 2T(n/3) + n lg n\n(e) T(n) = T(n/5) + lg 2 n\n(f) T(n) = 8T(n/2) + n\n(g) T(n) = 7T(n/2) + n\n(h) T(n) = T(n -2) + lg n\n2. True or False\nCircle T or F for each of the following statements, and briefly explain why. The better your\nargument, the higher your grade, but be brief. No points will be given even for a correct\nsolution if no justification is presented.\nT F For all asymptotically positive f(n), f(n) + o(f(n)) = Θ(f(n)).\nT F The worst-case running time and expected running time are equal to within constant\nfactors for any randomized algorithm.\nT F The collection H = {h1, h2, h3} of hash functions is universal, where the three hash\nfunctions map the universe {A, B, C, D} of keys into the range {0, 1, 2} according\nto the following table:\nx\nh1(x)\nA\nB\nC\nD\nh2(x)\nh3(x)\n3. Short Answers\nGive brief, but complete, answers to the following questions.\n(a) Argue that any comparison based sorting algorithm can be made to be stable, without\naffecting the running time by more than a constant factor.\n(b) Argue that you cannot have a Priority Queue in the comparison model with both the\nfollowing properties.\n\nHandout 10: 6.046 fall 2005 Quiz Review--modified from 6.046 Spring 2005\n- EXTRACT-MIN runs in Θ(1) time.\n- BUILD-HEAP runs in Θ(n) time.\n(c) Given a max-heap in an array A[1 . . .n] with A[1] as the maximum key (the heap is\na max heap), give pseudo-code to implement the following routine, while maintaining\nthe max heap property.\nDECREASE-KEY (i, δ) - Decrease the value of the key currently at A[i] by δ. Assume\nδ ≥0.\n(d) Given a sorted array A of n distinct integers, some of which may be negative, give an\nalgorithm to find an index i such that 1 ≤\nn and A[i] = i provided such an index\ni ≤\nexists. If there are many such indices, the algorithm can return any one of them.\n\nHandout 10: 6.046 fall 2005 Quiz Review--modified from 6.046 Spring 2005\n4. Suppose you are given a complete binary tree of height h with n = 2h leaves, where each\nnode and each leaf of this tree has an associated \"value\" v (an arbitrary real number).\nIf x is a leaf, we denote by A(x) the set of ancestors of x (including x as one of its own\nancestors). That is, A(x) consists of x, x's parent, grandparent, etc. up to the root of the tree.\nSimilarly, if x and y are distinct leaves we denote by A(x, y) the ancestors of either x or y.\nThat is,\nA(x, y) = A(x) ∪A(y) .\nDefine the function f(x, y) to be the sum of the values of the nodes in A(x, y).\ny\nx\nA(x,y) shown in bold\nf(x,y) = 19+15+21+36+20+30 = 141\nGive an algorithm (pseudo-code not necessary) that efficiently finds two leaves x0 and y0\nsuch that f(x0, y0) is as large as possible. What is the running time of your algorithm?\n\nh\ni\nh\ni\nh\ni\nHandout 10: 6.046 fall 2005 Quiz Review--modified from 6.046 Spring 2005\n5. Sorting small multisets\nFor this problem A is an array of length n objects that has at most k distinct keys in it, where\nk < √n. Our goal is to sort this array in time faster than Ω(n log n). We will do so in two\nphases. In the first phase, we will compute a sorted array B that contains the k distinct keys\noccuring in A. In the second phase we will sort the array A using the array B to help us.\nNote that k might be very small, like a constant, and your running time should depend on k\nas well as n. The n objects have satellite data in addition to the keys.\n279 , 1010 , π, 5, 1010 , π, 128\nExample: Let A = 5, 1010 , π, 128\n279 . Then n = 10 and k = 4.\nIn the first phase we compute B =\n279 , π, 5, 1010 .\nThe output after the second phase should be 279 , 279 , π, π, π, 5, 5, 1010 , 1010 , 1010 .\nYour goal is to design and analyse efficient algorithms and analyses for the two phases.\nRemember, the more efficient your solutions, the better your grade!\n(a) Design an algorithm for the first phase, that is computing the sorted array B of length k\ncontaining the k distinct keys. The value of k is not provided as input to the algorithm.\n(b) Analyse your algorithm for part (a).\n(c) Design an algorithm for the second phase, that is, sorting the given array A, using the\narray B that you created in part (a). Note that since the objects have satellite data, it is\nnot sufficient to count the number of elements with a given key and duplicate them.\nHint: Adapt Counting Sort.\n(d) Analyse your algorithm for part (c)."
    },
    {
      "category": "Exam",
      "title": "quiz1_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/f0cdfd373e9f8b7c839e7ed13bbfe748_quiz1_sol.pdf",
      "content": "Introduction to Algorithms\nOctober 14, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 14\nQuiz 1 Solutions\nDo not open this quiz booklet until you are directed to do so. Read all the instructions on\n-\nthis page.\nWhen the quiz begins, write your name on every page of this quiz booklet.\n-\nThis quiz contains 4 problems, some with multiple parts. You have 80 minutes to earn 80\n-\npoints.\nThis quiz booklet contains 13 pages, including this one. Two extra sheets of scratch paper\n-\nare attached. Please detach them before turning in your quiz at the end of the examination\nperiod.\nThis quiz is closed book. You may use one handwritten A4 or 8 1 × 1100 crib sheet. No\n-\ncalculators or programmable devices are permitted.\nWrite your solutions in the space provided. If you need more space, write on the back of the\n-\nsheet containing the problem. Do not put part of the answer to one problem on the back of\nthe sheet for another problem, since the pages may be separated for grading.\nDo not waste time and paper rederiving facts that we have studied. It is sufficient to cite\n-\nknown results.\nDo not spend too much time on any one problem. Read them all through first, and attack\n-\nthem in the order that allows you to make the most progress.\nShow your work, as partial credit will be given. You will be graded not only on the correct\n-\nness of your answer, but also on the clarity with which you express it. Be neat.\nGood luck!\n-\nProblem Parts Points Grade Grader\nTotal\nName:\n\nHandout 14: Quiz 1 Solutions\nProblem 1. Asymptotic Running Times [12 points] (4 parts)\nFor each algorithm listed below,\ngive a recurrence that describes its worst-case running time, and\n-\ngive its worst-case running time using -notation.\n-\nYou need not justify your answers.\n(a) Binary search\nSolution: T (n) = T (n/2) + (1) = (lg n)\n(b) Insertion sort\nSolution: T (n) = T (n - 1) + (n) = (n2)\n\nHandout 14: Quiz 1 Solutions\n(c) Strassen's algorithm\nnlg 7)\nSolution: T (n) = 7T (n/2) + (n2) = (\n(d) Merge sort\nSolution: T (n) = 2T (n/2) + (n) = (n lg n)\n\nHandout 14: Quiz 1 Solutions\nProblem 2. Substitution Method [7 points]\nConsider the recurrence\nT (n)\n= T (n/2) + T (n/4) + n ,\nT (m)\n=\n1 for m 5.\nUse the substitution method to give a tight upper bound on the solution to the recurrence using\nO-notation.\nSolution: We guess T (n) = O(n), which leads to the induction hypothesis T (m) cm for all\nm < n. For c 1, we have the base cases T (n) = 1 cn for n 5. The induction hypothesis\nyields\nT (n) = T (n/2) + T (n/4) + n cn/2 + cn/4 + n = (3c/4 + 1)n.\nIf we choose c = 4, then T (n) (3 + 1)n = 4n = cn. By induction on n, T (n) cn for c 4\nand all n 1.\n\n!\nHandout 14: Quiz 1 Solutions\nProblem 3. True or False, and Justify [44 points] (11 parts)\nCircle T or F for each of the following statements to indicate whether the statement is true or\nfalse, respectively. If the statement is correct, briefly state why. If the statement is wrong, explain\nwhy. The more content you provide in your justification, the higher your grade, but be brief. Your\njustification is worth more points than your true-or-false designation.\nT F The solution to the recurrence T (n) = 3T (n/3) + O(lg n) is T (n) = (n lg n).\nO(nlog3 3)\nSolution: False. Case 3 of the master theorem applies: f (n) =\n= O(n) for\nf (n) = O(lg n), hence, T (n) = O(n).\nT F Let Fk denote the kth Fibonacci number. Then, the n2th Fibonacci number Fn can be\ncomputed in O(lg n) time.\nSolution: True. The n2th Fibonacci number can be computed in O(lg n2) = O(lg n)\ntime by using square and multiply method with matrix\n.\n\nHandout 14: Quiz 1 Solutions\nT F Suppose that an array contains n numbers, each of which is -1, 0, or 1. Then, the array\ncan be sorted in O(n) time in the worst case.\nSolution: True. We may use counting sort. We first add 1 to each of the elements in the\ninput array such that the precondition of counting sort is satisfied. After running counting\nsort, we subtract 1 from each of the elements in the sorted output array.\nA solution based on partitioning is as follows. Let A[1 . . n] be the input array. We define\nthe invariant\nA[1 . . i] contains only -1,\n-\nA[i + 1 . . j] contains only 0, and\n-\nA[h . . n] contains only +1.\n-\nInitially, i = 0, j = 0, and h = n + 1. If h = j + 1, then we are done; the array is sorted.\nIn the loop we examine A[j +1]. If A[j +1] = -1, then we exchange A[j +1] and A[i+1]\nand we increase both i and j with 1 (as in partition in quicksort). If A[j + 1] = 0, then we\nincrease j with 1. Finally, if A[j + 1] = +1, then we exchange A[j + 1] and A[h - 1] and\nwe decrease h by 1.\nT F An adversary can provide randomized quicksort with an input array of length n that forces\nthe algorithm to run in !(n lg n) time on that input.\nSolution: False. As we saw in lecture, for any input, the expected running time of\nquicksort is O(n lg n), where the expectation is taken over the random choices made by\nquicksort, independent of the choice of the input.\n\nHandout 14: Quiz 1 Solutions\nT F The array\n20 15 18 7 9 5 12 3 6 2\nforms a max-heap.\nSolution: True.\nA[1] = 20 has children A[2] = 15 20 and A[3] = 18 20.\n-\nA[2] = 15 has children A[4] = 7 15 and A[5] = 9 15.\n-\nA[3] = 18 has children A[6] = 5 18 and A[7] = 12 18.\n-\nA[4] = 7 has children A[8] = 3 7 and A[9] = 6 7.\n-\nA[5] = 9 has child A[10] = 2.\n-\nA[6], . . . , A[10] have no children.\n-\nT F Heapsort can be used as the auxiliary sorting routine in radix sort, because it operates in\nplace.\nSolution: False. The auxiliary sorting routine in radix sort needs to be stable, meaining\nthat numbers with the same value appear in the output array in the same order as they do\nappear in the input array. Heapsort is not stable. It does operate in place, meaning that\nonly a constant number of elements of the input array are ever stored outside the array.\n\nHandout 14: Quiz 1 Solutions\nT F There exists a comparison sort of 5 numbers that uses at most 6 comparisons in the worst\ncase.\nSolution: False. The number of leaves of a decision tree which sorts 5 numbers is 5!\nand the height of the tree is at least lg(5!). Since 5! = 120, 26 = 64, and 27 = 128, we\nhave 6 < lg(5!) < 7. Thus at least 7 comparisons are required.\nT F Suppose that a hash table with collisions resolved by chaining contains n items and has a\nload factor of = 1/ lg n. Assuming simple uniform hashing, the expected time to search\nfor an item in the table is O(1/ lg n).\nSolution: False. The expected time to search for an item in the table is O(1 + ) =\nO(1 + 1/ lg n) = O(1). At least a constant running time O(1) is needed to search for an\nitem; subconstant running time O(1/ lg n) is not possible.\n\ni\ni\nHandout 14: Quiz 1 Solutions\nT F Let X be an indicator random variable such that E [X] = 1/2. Then, we have E\nhp\nX =\n1/\np\n2.\nSolution: False. Since X is an indicator random variable, X = 0 or X = 1. For both\npossible values\np\nX = X, which implies that E\nhp\nX = E [X] = 1/2.\nT F Suppose that a hash table of m slots contains a single element with key k and the rest of\nthe slots are empty. Suppose further that we search r times in the table for various other\nkeys not equal to k. Assuming simple uniform hashing, the probability is r/m that one of\nthe r searches probes the slot containing the single element stored in the table.\nSolution: False. The probability p that one of the r searches collides with the single\nelement stored in the table is equal to 1 minus the probability that none of the r searches\nr\ncollides with the single element stored in the table. That is, p = 1 - (1 - 1/m) .\n\nHandout 14: Quiz 1 Solutions\nT F Let S be a set of n integers. One can create a data structure for S so that determining\nwhether an integer x belongs to S can be performed in O(1) time in the worst case.\nSolution: True. Perfect hashing.\n\nHandout 14: Quiz 1 Solutions\nProblem 4. Close Numbers [17 points] (3 parts)\nConsider a set S of n 2 distinct numbers. For simplicity, assume that n = 2k + 1 for some\nk 0. Call a pair of distinct numbers x, y ≤ S close in S if\nmax z - min z\n,\n|x - y| n - 1\nz2S\nz2S\nthat is, if the distance between x and y is at most the average distance between consecutive numbers\nin the sorted order.\n(a) Explain briefly why every set S of n 2 distinct numbers contains a close pair of\nnumbers.\nSolution: Without loss of generality, assume S = {z1, z2, . . . , zn}, with zi zi+1.\nThe average distance between two consecutive numbers zi and zi+1 is\nn-1\nX\nn - 1 i=1\n(zi+1 - zi) = n - 1(zn - z1).\nThere exists at least one pair of consecutive numbers x and y whose distance between\nthem is less than or equal to the avearge. The result then follows from the definition\nof the close pair.\n\nHandout 14: Quiz 1 Solutions\n(b) Suppose that we partition S around a pivot element p ≤S, organizing the result into\ntwo subsets of S: S1 = {x ≤S\nx p} and S2 = x ≤S\nx p}. Prove that either\n|\n{\n|\n1. every pair x, y ≤S1 of numbers that is close in S1 is also close in S, or\n2. every pair x, y ≤S2 of numbers that is close in S2 is also close in S.\nS\nShow how to determine, in O(n) time, a value k ≤{1, 2} such that every pair x, y ≤\nk of numbers that is close in Sk is also close in S.\nSolution: Without loss of generality, assume that the elements in Si are in sorted\norder. For k = 1, 2, let ak be the average distance between two consecutive numbers\nin Sk , and let nk the number of elements in Sk . Using the result from Part (a), we have\na1 = n1 -1 max z -min z = n1 -1 p -min z\n,\nz2S1\nz2S1\nz2S\nand\na2 = n2 -1 max z -min z = n2 -1 max z -p .\nz2S2\nz2S2\nz2S\nThe average distance a between two consecutive numbers in S in sorted order is then\ngiven by\na = n -1 max z -min z\nz2S\nz2S\n= n -1 p -min z + n -1 max z -p\nz2S\nz2S\nn1 -1\nn2 -1\n=\na1 +\na2.\nn -1\nn -1\nNote that n1 + n2 = n + 1, because p is included in both S1 and S2. So, a is a weighted\naverage of a1 and a2:\na = (1 -)a1 + a2,\nwhere = (n2 -1)/(n -1).\nSuppose that a1 a2. If x and y are a close pair in S1, then\nx -y a1 = (1 -)a1 + a1 (1 -)a1 + a2 = a.\n|\n|\nThis implies that every close pair in S1 is also a close pair in S. Similarly, if a2 a1,\nthen every close pair in S2 is a close pair in S.\nThe average distance ak can be computed in O(n) time, by searching for the minimum\nor the maximum number in Sk . Therefore, the subset Sk with the specified property\ncan be computed in O(n) time.\n\nHandout 14: Quiz 1 Solutions\n(c) Describe an O(n)-time algorithm to find a close pair of numbers in S. Explain briefly\nwhy your algorithm is correct, and analyze its running time. (Hint: Use divide and\nconquer.)\nSolution: The idea is to partition S recursively until we find a close pair.\n1. Determine the median of S and use it to partion S into S1 and S2.\n2. Use the result from Part (b) to determine the set Sk that contains a close pair of S.\n3. Recurse on Sk until Sk contains 2 elements.\nSince each recursive step reduces the cardinality of the set by roughly a half, the\nrecursion is guaranteed to terminate. After each recursive step, the remaining set\ncontains a close pair of S.\nStep 1 takes O(n) time in the worst case, if we use the deterministic median-finding\nalgorithm. Step 2 takes O(n) time based on the result from Part (b). Therefore, the\nrunning time of the algorithm is given by the following recurrence:\nT (n) = T (n/2) + O(n),\nwith the solution T (n) = O(n) according to the master theorem.\n\nSCRATCH PAPER -- Please detach this page before handing in your exam.\n\nSCRATCH PAPER -- Please detach this page before handing in your exam."
    },
    {
      "category": "Exam",
      "title": "quiz1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/e0b2d539356892002422e63268e16f88_quiz1.pdf",
      "content": "Introduction to Algorithms\nOctober 12, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nQuiz 1\nQuiz 1\n\nDo not open this quiz booklet until you are directed to do so. Read all the instructions on\nthis page.\n\nWhen the quiz begins, write your name on every page of this quiz booklet.\n\nThis quiz contains 4 problems, some with multiple parts. You have 80 minutes to earn 80\npoints.\n\nThis quiz booklet contains 13 pages, including this one. Two extra sheets of scratch paper\nare attached. Please detach them before turning in your quiz at the end of the examination\nperiod.\n\nThis quiz is closed book. You may use one handwritten A4 or\n\ncrib sheet. No\ncalculators or programmable devices are permitted.\n\nWrite your solutions in the space provided. If you need more space, write on the back of the\nsheet containing the problem. Do not put part of the answer to one problem on the back of\nthe sheet for another problem, since the pages may be separated for grading.\n\nDo not waste time and paper rederiving facts that we have studied. It is sufficient to cite\nknown results.\n\nDo not spend too much time on any one problem. Read them all through first, and attack\nthem in the order that allows you to make the most progress.\n\nShow your work, as partial credit will be given. You will be graded not only on the correct\nness of your answer, but also on the clarity with which you express it. Be neat.\n\nGood luck!\nProblem\nPoints Grade Grader\nParts\nTotal\nName:\n\n6.046J/18.410J Quiz 1\nName\nProblem 1. Asymptotic Running Times [10 points] (5 parts)\nFor each algorithm listed below,\n\ngive a recurrence that describes its worst-case running time, and\n\ngive its worst-case running time using\n-notation.\nYou need not justify your answers.\n(a) Binary search\n(b) Insertion sort\n\n6.046J/18.410J Quiz 1\nName\n(c) Randomized quicksort\n(d) Strassen's algorithm\n(e) Merge sort\n\n6.046J/18.410J Quiz 1\nName\nProblem 2.\nSubstitution Method [7 points]\nConsider the recurrence\n\nUse the substitution method to give a tight upper bound on the solution to the recurrence using\n-notation.\n\n6.046J/18.410J Quiz 1\nName\nProblem 3.\nTrue or False, and Justify [48 points] (12 parts)\nCircle T or F for each of the following statements to indicate whether the statement is true or\nfalse, respectively. If the statement is correct, briefly state why. If the statement is wrong, explain\nwhy. The more content you provide in your justification, the higher your grade, but be brief. Your\njustification is worth more points than your true-or-false designation.\nT F Let\nand\n\nbe asymptotically nonnegative functions. Then, at least one relationship of\n\nand\n\nmust always hold.\nT F The solution to the recurrence\n\nis\n\n.\n\n6.046J/18.410J Quiz 1\nName\n\nT F Let\ndenote the\n\nth Fibonacci number. Then, the\n\nth Fibonacci number\ncan be\n\ncomputed in\ntime.\n\nT F Suppose that an array contains\nnumbers, each of which is\n\n,\n, or\n. Then, the array\n\ncan be sorted in\ntime in the worst case.\n\n6.046J/18.410J Quiz 1\nName\n\nT F An adversary can provide randomized quicksort with an input array of length that forces\nthe algorithm to run in\n\ntime on that input.\nT F The array\n\nforms a max-heap.\n\n6.046J/18.410J Quiz 1\nName\nT F Heapsort can be used as the auxiliary sorting routine in radix sort, because it operates in\nplace.\n\nT F There exists a comparison sort of\nnumbers that uses at most comparisons in the worst\ncase.\n\n6.046J/18.410J Quiz 1\nName\n\nT F Suppose that a hash table with collisions resolved by chaining contains\nitems and has a\nload factor of\n\n. Assuming simple uniform hashing, the expected time to search\n\nfor an item in the table is\n\n.\n\nT F Let\n\nbe an indicator random variable such that\n\n. Then, we have\n\n.\n\n6.046J/18.410J Quiz 1\nName\nT F Suppose that a hash table of\n\nslots contains a single element with key\nand the rest of\nthe slots are empty. Suppose further that we search\ntimes in the table for various other\n\nkeys not equal to\n. Assuming simple uniform hashing, the probability is\n\nthat one of\nthe\nsearches probes the slot containing the single element stored in the table.\n\nT F Let\nbe a set of\nintegers. One can create a data structure for\nso that determining\n\nwhether an integer belongs to\ncan be performed in\n\ntime in the worst case.\n\n6.046J/18.410J Quiz 1\nName\nProblem 4. Close Numbers [15 points] (2 parts)\n\nclose in\nif\nConsider a set\nof\ndistinct numbers. Call a pair of distinct numbers\n\nthat is, if the distance between\nand\nis at most the average distance between consecutive numbers\nin the sorted order.\n\n(a) Explain briefly why every set\nof\ndistinct numbers contains a pair of close\nelements.\n\n6.046J/18.410J Quiz 1\nName\n\naround a pivot element\n(b) Suppose that we partition\n\n, organizing the result into\n\ntwo subsets of\n\n:\n\n. Prove that, for\n\nand\nof numbers that are close in\n(not just\nsome\n\n, there exists a pair\n\nin\n).\n\n6.046J/18.410J Quiz 1\nName\n\n(c) Describe an\n-time algorithm to find a close pair of numbers in . Analyze your\nalgorithm. (Hint: Use divide and conquer.)\n\nSCRATCH PAPER -- Please detach this page before handing in your exam.\n\nSCRATCH PAPER -- Please detach this page before handing in your exam."
    },
    {
      "category": "Exam",
      "title": "quiz2_practice.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/87e3ae92a585f8383a70452da325e233_quiz2_practice.pdf",
      "content": "Introduction to Algorithms\nApril 25-April 29, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Charles E. Leiserson and Ronald L. Rivest\nQuiz 2\nPractice Quiz 2\nThis take-home quiz contains 5 problems worth 25 points each, for a total of 125 points. Each\nproblem should be answered on a separate sheet (or sheets) of 3-hole punched paper.\nMark the top of each problem with your name, 6.046J/18.410J, the problem number, your\nrecitation time, and your TA. Your exam is due between 9:00 and 11:00 A.M. on Friday, April\n29, 2005. Late exams will not be accepted unless you obtain a Dean's Excuse or make prior\narrangements with your recitation instructor. You must hand in your own exam in person.\nThe quiz should take you about 10 hours to do, but you have four days in which to do it. Plan\nyour time wisely. Do not overwork, and get enough sleep. Ample partial credit will be given for\ngood solutions, especially if they are well written. Of course, the better your asymptotic bounds,\nthe higher your score. Bonus points will be given for exceptionally efficient or elegant solutions.\nWrite-ups: Each problem should be answered on a separate sheet (or sheets, stapled separately\nfor each problem) of 3-hole punched paper. Mark the top of each problem with your name,\n6.046J/18.410J, the problem number, your recitation time, and your TA. Your solution to a prob\nlem should start with a topic paragraph that provides an executive summary of your solution. This\nexecutive summary should describe the problem you are solving, the techniques you use to solve\nit, any important assumptions you make, and the running time your algorithm achieves.\nWrite up your solutions cleanly and concisely to maximize the chance that we understand\nthem. Be explicit about running time and algorithms. For example, don't just say you sort n\nnumbers, state that you are using heapsort, which sorts the n numbers in O(n lg n) time in the\nworst case. When describing an algorithm, give an English description of the main idea of the\nalgorithm. Use pseudocode only if necessary to clarify your solution. Give examples, and draw\nfigures. Provide succinct and convincing arguments for the correctness of your solutions. Do not\nregurgitate material presented in class. Cite algorithms and theorems from CLRS, lecture, and\nrecitation to simplify your solutions.\nPart of the goal of this exam is to test engineering common sense. If you find that a question\nis unclear or ambiguous, make reasonable assumptions in order to solve the problem, and state\nclearly in your write-up what assumptions you have made. Be careful what you assume, however,\nbecause you will receive little credit if you make a strong assumption that renders a problem trivial.\nBugs, etc.: If you think that you've found a bug, send email to 6.046 course staff.\nCorrections and clarifications will be sent to the class via email and posted on the class website.\nCheck your email and the class website daily to avoid missing potentially important announcements.\nIf you did not receive an email last Friday reminding you about Quiz 2, then you are not on the\nclass email list and you should let your recitation instructor know immediately.\n\n6.046J/18.410J Quiz 2\nPolicy on academic honesty: This quiz is \"limited open book.\" You may use your course notes,\nthe CLRS textbook, basic reference materials such as dictionaries, and any of the handouts posted\non the course web page, but no other sources whatsoever may be consulted. For example, you\nmay not use notes or solutions from other times that this course or other related courses have been\ntaught, or materials on the World-Wide Web. (These materials will not help you, but you may\nnot use them anyhow.) Of prime importance, you may not communicate with any person except\nmembers of the 6.046 staff about any aspect of the exam until after noon on Friday, April 29, even\nif you have already handed in your exam.\nIf at any time you feel that you may have violated this policy, it is imperative that you contact\nthe course staff immediately. If you have any questions about what resources may or may not be\nused during the quiz, send email to 6.046 course staff.\nSurvey: Attached to this exam is a survey on your experiences with the exam, especially as they\nrelate to academic honesty. Please detach the survey, fill it out, and hand it in when you hand in\nyour exam. Responses to the survey will be anonymous. No attempt will be made to associate a\nresponse with a person. This information will be used to gauge the usefulness of the exam, and\nsummary statistics will be provided to the class.\nPLEASE REREAD THESE INSTRUCTIONS ONCE A DAY DURING THE EXAM.\nGOOD LUCK, AND HAVE FUN!\n\n6.046J/18.410J Quiz 2\nProblem 1. Static Graph Representation\nLet G = (V, E) be a sparse undirected graph, where V = {1, 2, . . . , n}. For a vertex v ⊗ V and\nfor i = 1, 2, . . . , out-degree(v), define v's ith neighbor to be the ith smallest vertex u such that\n(v, u) ⊗ E, that is, if you sort the vertices adjacent to v, then u is the ith smallest.\nConstruct a representation of the graph G to support the following queries:\n-DEGREE(v): returns the degree of vertex v.\n-LINKED(u, v): output TRUE if an edge connects vertices u and v, and FALSE otherwise.\n-NEIGHBOR(v, i): returns v's ith neighbor.\nYour data structure should use asymptotically as little space as possible, and the operations should\nrun asymptotically as fast as possible, but space is more important than time. Analyze your data\nstructure in terms of both space and time.\nProblem 2. Video Game Design\nProfessor Cloud has been consulting in the design of the most anticipated game of the year: Take-\nhome Fantasy. One of the levels in the game is a maze that players must navigate through multiple\nrooms from an entrance to an exit. Each room can be empty, contain a monster, or contain a life\npotion. As the player wanders through the maze, points are added or subtracted from her life\npoints L. Drinking a life potion increases L, but battling a monster decreases L. If L drops to 0 or\nbelow, the player dies.\nAs shown in Figure 1, the maze can be represented as a digraph G = (V, E), where vertices\ncorrespond to rooms and edges correspond to (one-way) corridors running from room to room. A\nvertex-weight function f : V !\nrepresents the room contents:\n-If f(v) = 0, the room is empty.\n-If f(v) > 0, the room contains a life potion. Every time the player enters the room, her life\npoints L increase by f(v).\n-If f(v) < 0, the room contains a monster. Every time the player enters the room, her life\npoints L drop by |f(v)|, killing her if L becomes nonpositive.\nThe entrance to the maze is a designated room s ⊗ V , and the exit is another room t ⊗ V . Assume\nthat a path exists from s to every vertex v ⊗ V , and that a path exists from every vertex v ⊗ V to t.\nThe player starts at the entrance with L = L0 life points, i.e. L0 is the value of f for the entrance.\nThe figure shows L0 = 1.\nProfessor Cloud has designed a program to put monsters and life potions randomly into the maze,\nbut some mazes may be impossible to safely navigate from entrance to exit unless the player enters\nwith a sufficient number L0 > 0 of life points. A path from s to t is \"safe\" if the player stays alive\nalong the way, i.e., her life-points never become non-positive. Define a maze to be r-admissible if\na safe path through the maze exists when the player begins with L0 = r.\n\n6.046J/18.410J Quiz 2\n+1\n+4\n-3\n-10\nExit\nEntrance\nFigure 1: An example of a 1-admissible maze.\nHelp the professor by designing an efficient algorithm to determine the minimum value r so that\na given maze is r-admissible, or determine that no such r exists. (For partial credit, solve the\nproblem determining whether a maze is r-admissible for a given r.)\nProblem 3. Image Filtering\nTwo-dimensional filtering is a common operation in vision and image processing. An image\nis represented as an n × n matrix of real values. As shown in Figure 2, the idea is to pass a\nk × k window across the matrix, and for each of the possible placements of the window, the filter\ncomputes the \"product\" of all the values in the window. The \"product\" is not typically ordinary\nmultiplication, however. For this problem, we shall assume it is an associative and commutative\nbinary operation → with identity element e, that is, x → e = e → x = x. For example, the product\ncould be + with identity element 0, × with 1, min with ←, etc. Importantly, you may not assume\nthat → has an inverse operation, such as - for +.\nTo be precise, given an n × n image\n⎞\na00\na01\n. . .\na0(n-1)\nA =\n⎟\n⎟\n⎟\n⎟\n⎠\na10\n. . .\na11\n. . .\n. . .\n. . .\na1(n-1)\n. . .\nC\nC\nC\nC\nA ,\na(n-1)0 a(n-1)1 . . . a(n-1)(n-1)\n\nreplacements\n6.046J/18.410J Quiz 2\nn\nn\nk\nk\n(\n)\ni, j\nFigure 2: The output element bij is the \"product\" of all the a's in the shaded square.\nthe (k × k)-filtered image is the n × n matrix\n⎞\nb00\nb01\n. . .\nb0(n-1)\n⎟\nC\n⎟\nb10\nb11\n. . .\nb1(n-1)\nC\n⎟\nC\nB = ⎟\n..\n,\n. .\n..\n..\nC\n⎠\n.\n.\n.\n.\nA\nb(n-1)0 b(n-1)1 . . . b(n-1)(n-1)\nwhere for i, j = 0, 1, . . . , n - 1,\ni+k-1 j+k-1\n⎛\n⎛\nbij =\naxy .\nx=i\nj=y\n(For convenience, if x n or y n, we assume that axy = e.)\nGive an efficient algorithm to compute the (k × k)-filter of an input matrix A. While analyzing\nyour algorithm, do not treat k as a constant. That is, express your running time in terms of n and k.\n(For partial credit, solve the problem in one dimension.)\nProblem 4. ViTo Design\nYou are designing a new-and-improved digital video recorder, called ViTo. In the ViTo software,\na television show i is represented as a triple: a channel number ci, a start time si , and an end\ntime ei. The ViTo owner inputs a list of n shows to watch and for each show i = 1, 2, . . . , n,\nassigns it a pleasure rating ri. Since shows may overlap, and the ViTo can record only one show\nat a time, the ViTo should record the subset of the shows that maximize the aggregate \"pleasure.\"\nSince the owner receives no pleasure from watching only part of a show, the ViTo never records\npartial shows. Design an efficient algorithm for the ViTo to select the best subset of shows to\nrecord.\n\n6.046J/18.410J Quiz 2\nProblem 5. Growing a Graph\nWe wish to build a data structure that supports a dynamically growing directed graph G = (V, E).\nInitially, we have V = {1, 2, . . . , n} and E = ≥. The user grows the graph with the following\noperation:\n-INSERT-EDGE(u, v): Insert a directed edge from vertex u to vertex v, that is, E E inf\n{(u, v)}.\nIn addition, at any time the user can query the graph for whether two vertices are connected:\n-CHECK-PATH(u, v): Return TRUE if a directed path from vertex u to vertex v exists; other\nwise, return FALSE.\nThe user grows the graph until it is fully connected. Since the number of edges increases monoton\nically and the user never inserts the same edge twice, the total number of INSERT-EDGE operations\nis exactly n(n - 1). During the time that the graph is growing, the user performs m CHECK-PATH\noperations which are intermixed with the n(n - 1) INSERT-EDGE's. Design a data structure that\ncan efficiently support any such sequence of operations.\n\nIntroduction to Algorithms\nMay 6, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Charles E. Leiserson and Ronald L. Rivest\nQuiz 2 Solutions\nQuiz 2 Solutions\nProblem 1. Static Graph Representation\nLet G = (V, E) be a sparse undirected graph, where V = {1, 2, . . . , n}. For a vertex v ⊗ V and\nfor i = 1, 2, . . . , out-degree(v), define v's ith neighbor to be the ith smallest vertex u such that\n(v, u) ⊗ E, that is, if you sort the vertices adjacent to v, then u is the ith smallest.\nConstruct a representation of the graph G to support the following queries:\n-DEGREE(v): returns the degree of vertex v.\n-LINKED(u, v): output TRUE if an edge connects vertices u and v, and FALSE otherwise.\n-NEIGHBOR(v, i): returns v's ith neighbor.\nYour data structure should use asymptotically as little space as possible, and the operations should\nrun asymptotically as fast as possible, but space is more important than time. Analyze your data\nstructure in terms of both space and time.\nSolution: We give a solution that uses (E) space for the data structure and takes (1) time for\neach of the three operations. Create a hash table that contains key (u, v) if (u, v) ⊗ E or key (u, i)\nif vertex u has an i-th neighbor. It is possible that for some u and v = i, vertex u has both an\nadjacent vertex v and an i-th neighbor. This is handled by storing satellite data with each record\nof the hash table. For the record with key (u, i) in the hash table, if u has a neighbor v = i, then\nindicate so using a bit in the record; if u has an i-th neighbor, then store the corresponding neighbor\nvertex index in the record. Also, for every vertex u that is connected to some other vertex, store its\ndegree in the record for key (u, 1).\nThus, for each vertex u in the first coordinate of the key, the hash table has at most degree(u) +\n⎝n\ndegree(u) = 2 degree(u) entries. The total number of entries is thus at most\nu=1 2 degree(u) =\n4|E|. By using perfect hashing, and choosing a suitable hash function through a small number\nof random samplings (during data structure construction), we can make the lookup time (1) and\nspace requirement linear in the number of entries stored, i.e., (E) (see CLRS, page 249, Corollary\n11.12). We can use the same family of hash functions as in CLRS by converting each 2-tuple (u, v)\ninto a distinct number (u - 1)n + v in the range of [1 . . . n2]. The total space requirement of the\ndegree array and hash table is thus (V + E).\nThen, DEGREE(v) looks up the key(v, 1) in the hash table. If found, it returns the degree value\nstored in the record. Otherwise, it returns 0, since v is not adjacent to any vertex. This takes (1)\ntime. LINKED(u, v) looks up the key (u, v) in the hash table and returns TRUE if it exists and the\nassociated bit in the record is set. This is (1) time. NEIGHBOR(v, i) looks up the key (v, i) in\nthe hash table - if it exists and a neighbor vertex is stored in the record, it returns its index. This is\nalso (1) time.\n\n6.046J/18.410J Quiz 2 Solutions\n+1\n+4\n-3\n-10\nEntrance\nExit\nFigure 1: An example of a 1-admissible maze.\nProblem 2. Video Game Design\nProfessor Cloud has been consulting in the design of the most anticipated game of the year: Take-\nhome Fantasy. One of the levels in the game is a maze that players must navigate through multiple\nrooms from an entrance to an exit. Each room can be empty, contain a monster, or contain a life\npotion. As the player wanders through the maze, points are added or subtracted from her life\npoints L. Drinking a life potion increases L, but battling a monster decreases L. If L drops to 0 or\nbelow, the player dies.\nAs shown in Figure 1, the maze can be represented as a digraph G = (V, E), where vertices\ncorrespond to rooms and edges correspond to (one-way) corridors running from room to room. A\nvertex-weight function f : V !\n\nrepresents the room contents:\n-If f(v) = 0, the room is empty.\n-If f(v) > 0, the room contains a life potion. Every time the player enters the room, her life\npoints L increase by f(v).\n-If f(v) < 0, the room contains a monster. Every time the player enters the room, her life\npoints L drop by |f(v)|, killing her if L becomes nonpositive.\nThe entrance to the maze is a designated room s ⊗ V , and the exit is another room t ⊗ V . Assume\nthat a path exists from s to every vertex v ⊗ V , and that a path exists from every vertex v ⊗ V to t.\n\n6.046J/18.410J Quiz 2 Solutions\nThe player starts at the entrance with L = L0 life points, i.e. L0 is the value of f for the entrance.\nThe figure shows L0 = 1.\nProfessor Cloud has designed a program to put monsters and life potions randomly into the maze,\nbut some mazes may be impossible to safely navigate from entrance to exit unless the player enters\nwith a sufficient number L0 > 0 of life points. A path from s to t is \"safe\" if the player stays alive\nalong the way, i.e., her life-points never become non-positive. Define a maze to be r-admissible if\na safe path through the maze exists when the player begins with L0 = r.\nHelp the professor by designing an efficient algorithm to determine the minimum value r so that\na given maze is r-admissible, or determine that no such r exists. (For partial credit, solve the\nproblem determining whether a maze is r-admissible for a given r.)\nSolution:\nWe give an algorithm with running time O(V E lg r), where r is the minimum life needed at entry\nfor the maze to be admissible. The problem is solved in two parts.\n-An algorithm to determine if a given maze is admissible for a given r: This is done by using a\nmodified version of Bellman-Ford. For every node u, this algorithm computes the maximum\nnumber of points q[u] that the player can have on reaching u. Since the player will die if she\nreaches u with negative points, the value of q[u] is either -→ (denoting that the player cannot\nreach u) or positive. Thus if q[t] is positive (t is the exit node), then the graph is r-admissible.\n-We know that the minimum r cannot be less than 1. Thus we use a combination of exponential\nand binary search to find the minimum value of r. We use the modified Bellman-Ford log r\ntimes to find the minimum r.\nThe running time of the algorithm is O(V E log r), where r is the minimum r, where the maze is\nr-admissible.\nDetermining Admissibility for a given r We use a modified version of Bellman-Ford algorithm.\nGiven an r, for every node u we find the maximum (positive) number of points q[u] the player can\nhave when she reaches u. If q[t] is positive, then the graph is r-admissible.\nFor each vertex u ⊗ V , we maintain p[u] which is a lower bound on q[u]. We initialize all the p[u]'s\nto -→, except the entrance, which is initialized to r. As we run the Bellman-Ford Algorithm and\nrelax edges, the value of p[u] increases until it converges to q[u] (if there are no positive weight\ncycles). The important point to note is that reaching a node with negative points is as good as not\nreaching it at all. Thus, we modify p[u] only it becomes positive, otherwise p[u] remains -→. We\nchange the relaxation routine to incorporate this as follows.\n\n6.046J/18.410J Quiz 2 Solutions\nV-RELAX(u, v)\n1 if (u, v) ⊗ E\nthen if ((p[v] < p[u] + f[v]) and (p[u] + f[v] > 0))\nthen p[v] p[u] + f[v]\n4 [v] u\nAfter all the edges have been relaxed V times, if there are no negative weight cycles, all p[u]'s will\nhave converged to the corresponding q[u]'s (the maximmum number of points you can have on\nreaching vertex u). If q[t] is positive at this point, then the player can reach there with positive life\npoints and thus the graph is r-admissible. If p[t] is not positive, however, we relax all the edges one\nmore time (just like Bellman-Ford). If p[u] of any node changes, we have found a positive weight\ncycle which is reachable from s starting with r points. Thus the player can go around the cycle\nenough times to collect all the necessary points to reach t and thus the graph is r-admissible. If we\ndont find a reachable positive weight cycle and p[t] is -→, then the graph is not r admissible. The\ncorrectness of the algorithm follows from the correctness of Bellman-Ford, and the running time\nis O(V E).\nFinding the minimum r for which the graph is r-admissible Given the above sub-routine, we\nnow find the minimum r. We first check if the graph is 1-admissible. If it is, we return 1 as the\nanswer. If it is not, then we check if it is 2-admissible and then 4-admissible and so on. Thus on\nthe ith step we check if the graph is 2i-1-admissible. Eventually, we find k such that the graph is\nnot 2k-1-admissible, but it is 2k-admissible. Thus the minimum value of r lies between these two\nvalues. Then we binary search between r = 2k-1 and r = 2k to find the right value of r.\nAnalysis: The number of iterations is k + O(lg r) = O(lg r), since k = ∅lg r∪. Thus you have to\nrun Bellman-Ford O(lg r) times, and the total running time is O(V E lg r).\nAlternate Solutions Some people visited nodes in DFS or BFS order starting from the exit,\nrelaxing edges to find the minimum number of points needed to get from any node u to the exit.\nThe problem with this approach is that in the presence of positive weight cycles, the algorithm runs\nfor O(M(V + E)) time, where M is the total sum of all monster points. This number can be big\neven if the real r is small. Some people did the same thing, except with Bellman-Ford instead of\nsearch, which gives a running time of O(MV E). There were a couple of other clever solutions\nwhich ran in O(V 2E time.\nProblem 3. Image Filtering\nTwo-dimensional filtering is a common operation in vision and image processing. An image\nis represented as an n × n matrix of real values. As shown in Figure 2, the idea is to pass a\nk × k window across the matrix, and for each of the possible placements of the window, the filter\ncomputes the \"product\" of all the values in the window. The \"product\" is not typically ordinary\n\nreplacements\n6.046J/18.410J Quiz 2 Solutions\nn\nn\nk\nk\n(\n)\ni, j\nFigure 2: The output element bij is the \"product\" of all the a's in the shaded square.\nmultiplication, however. For this problem, we shall assume it is an associative and commutative\nbinary operation ≤ with identity element e, that is, x ≤ e = e ≤ x = x. For example, the product\ncould be + with identity element 0, × with 1, min with →, etc. Importantly, you may not assume\nthat ≤ has an inverse operation, such as - for +.\nTo be precise, given an n × n image\n⎨\na00\na01\n. . .\na0(n-1)\n⎩\nC\n⎩\na10\na11\n. . .\na1(n-1)\nC\n⎩\nC\nA = ⎩\n..\n,\n. .\n..\n..\nC\n.\n.\n⎪\n.\n.\nA\na(n-1)0 a(n-1)1 . . . a(n-1)(n-1)\nthe (k × k)-filtered image is the n × n matrix\n⎨\nb00\nb01\n. . .\nb0(n-1)\n⎩\nC\n⎩\nb10\nb11\n. . .\nb1(n-1)\nC\n⎩\nC\nB = ⎩\n..\n,\n. .\n..\n..\nC\n.\n.\n⎪\n.\n.\nA\nb(n-1)0 b(n-1)1 . . . b(n-1)(n-1)\nwhere for i, j = 0, 1, . . . , n - 1,\ni+k-1 j+k-1\n⎛\n⎛\nbij =\naxy .\nx=i\nj=y\n(For convenience, if x ← n or y ← n, we assume that axy = e.)\nGive an efficient algorithm to compute the (k × k)-filter of an input matrix A. While analyzing\nyour algorithm, do not treat k as a constant. That is, express your running time in terms of n and k.\n(For partial credit, solve the problem in one dimension.)\n\n6.046J/18.410J Quiz 2 Solutions\nSolution:\nWe can solve the two-dimensional filtering problem in (n2) time by first reducing the problem\nto two one-dimensional filtering problems and then showing how a one-dimensional filter on n\nelements can be solved in (n) time. We assume that k n, since filtered values for k > n are\nthe same as for k = n. The (n2)-time algorithm is optimal, since there are n2 values to compute.\nDefine the intermediate matrix C by\n⎨\nc00\nc01\n. . .\nc0(n-1)\nC =\n⎩\n⎩\n⎩\n⎩\n⎪\nc10\n. . .\nc11\n. . .\n. . .\n. . .\nc1(n-1)\n. . .\nC\nC\nC\nC\nA ,\nc(n-1)0 c(n-1)1 . . . c(n-1)(n-1)\nwhere for i, j = 0, 1, . . . , n - 1,\nj+k-1\n⎛\ncij =\naiy ,\ny=j\nthat is, C is the one-dimensional k-filter on each row of A. We have\ni+k-1 j+k-1\n⎛\n⎛\nbij =\naxy\nx=i\ny=j\ni+k-1\n⎛\n=\ncxj ,\nx=i\nand thus B is just the one-dimensional k-filter on each column of C.\nIt remains to devise an efficient method to compute one-dimensional k-filters. The naive algorithm\ntakes (kn) time to solve the one-dimensional problem for an array of length n. Using this one-\ndimensional algorithm to solve the two-dimensional problem costs (kn2) to compute C from A\nand another (kn2) to compute B from C, resulting in (kn2) overall. Many students found a\nway to compute the one-dimensional problem in (n lg k), resulting in a two-dimensional solution\nof (n2 lg k). In fact, as some students discovered, the one-dimensional problem can be solved in\n(n) time, leading to a two-dimensional solution of (n ).\nThe (n)-time solution for the one-dimensional problem works as follows. Let the input array be\nA = ∈a0, a1, . . . , an-1i and the k-filtered output array be B = ∈b0, b1, . . . , bn-1i, where\ni+k-1\n⎛\nbi =\nax .\nx=i\nAssume without loss of generality that n is evenly divisible by k, since otherwise, we can pad the\nend of a with identity elements e to make n a multiple of k without more than doubling n.\nThe idea is to divide the arrays into blocks of k elements. Observe that any window of k elements\nstarting at a given location i consists of the product of a suffix of one block and a prefix of the next\n\n6.046J/18.410J Quiz 2 Solutions\nblock. Thus, we compute prefixes and suffixes of each block as follows. For i = 0, 1, . . . , n - 1,\ndefine\n⎜\ne\nif i mod k = 0,\nfi =\nfi-1 ≤ ai-1 otherwise;\nand for i = n - 1, n - 2, . . . , 0, define\n⎜\nai\nif (i + 1) mod k = 0,\ngi =\nai ≤ fi+1 otherwise.\nb\nThese two arrays can be computed in (n) time, and then we obtain the output array by computing,\nfor i = 0, 1, . . . , n - 1,\ni = gi ≤ fi+k ,\nwhich also takes (n) time.\nAs an example, consider a one-dimensional 4-filter:\nb0 = (a0 ≤ a1 ≤ a2 ≤ a3)\n= g0 ≤ f4\nb1 = (a1 ≤ a2 ≤ a3) ≤ (a4) = g1 ≤ f5\nb2 = (a2 ≤ a3) ≤ (a4 ≤ a5) = g2 ≤ f6\nb3 = (a3) ≤ (a4 ≤ a5 ≤ a6) = g3 ≤ f7\nb4 = (a4 ≤ a5 ≤ a6 ≤ a7)\n= g4 ≤ f8\nb5 = (a5 ≤ a6 ≤ a7) ≤ (a8) = g5 ≤ f9\nb6 = (a6 ≤ a7) ≤ (a8 ≤ a9) = g6 ≤ f10\n. . .\nProblem 4. ViTo Design\nYou are designing a new-and-improved digital video recorder, called ViTo. In the ViTo software,\na television show i is represented as a triple: a channel number ci, a start time si , and an end\ntime ei. The ViTo owner inputs a list of n shows to watch and for each show i = 1, 2, . . . , n,\nassigns it a pleasure rating ri. Since shows may overlap, and the ViTo can record only one show\nat a time, the ViTo should record the subset of the shows that maximize the aggregate \"pleasure.\"\nSince the owner receives no pleasure from watching only part of a show, the ViTo never records\npartial shows. Design an efficient algorithm for the ViTo to select the best subset of shows to\nrecord.\nSolution: Assume ViTo has enough harddisk space to record any subset of the programs. We use\na dynamic programming approach to the problem.\nFirst let's show the optimal substructure. Let showi denote the triple (ci, si, ei), shows denote\nthe whole list of shows show1, ..., shown, and shows(t) denote the subset of shows showj such\nthat ej < t, i.e. all the shows with ending times before time t. Consider an optimal solution\n\n6.046J/18.410J Quiz 2 Solutions\nshowi1 , showi2 , ..., showik . Then showi1 , showi2 , ..., showik-1 must be an optimal solution to the\nsubproblem shows(sik ) since if not, we could cut and paste a better solution to this subproblem,\nappend showik to it, and get a better solution than the optimal one.\nSort the shows by ending time, so ei ej for i < j and if ei = ej then si < sj . (if two or more\nshows start and end at the same time, then we can just keep the one with the maximum pleasure ri,\nbreaking ties arbitrarily). This can be done with counting sort in linear time: with n shows, there\nare only a maximum of 2n possible starting/ending times, and there are only 24 hours in a day,\ni.e. a limited (constant) amount of time, therefore the range of possible times is O(n). Relabel\nthe shows so that show1, ..., shown are in sorted order. Let showsi be the list of shows up to and\nincluding the i-th show, i.e. showsi = show1, show2, ..., showi.\nNote that shows(t), the subset of shows showj such that ej < t, is equal to showk(t) for some k(t).\nThe aggregate pleasure p(i) of an optimal solution for shows in showi is:\n⎜\nif i < 1;\np(i) =\nmax{p(k(si)) + ri, p(i - 1)} otherwise.\nThe optimal solution is:\n⎞\n⎧ {}\nif i < 1;\n⎟\nrecord(i) =\nrecord(k(si)) inf {showi} if p(k(si)) + ri > p(i - 1);\n⎧\n⎠ record(i - 1)\notherwise.\nRunning Time = time to sort the shows + time to find p(n) = O(n).\nProblem 5. Growing a Graph\nWe wish to build a data structure that supports a dynamically growing directed graph G = (V, E).\nInitially, we have V = {1, 2, . . . , n} and E = ≥. The user grows the graph with the following\noperation:\n-INSERT-EDGE(u, v): Insert a directed edge from vertex u to vertex v, that is, E E inf\n{(u, v)}.\nIn addition, at any time the user can query the graph for whether two vertices are connected:\n-CHECK-PATH(u, v): Return TRUE if a directed path from vertex u to vertex v exists; other\nwise, return FALSE.\nThe user grows the graph until it is fully connected. Since the number of edges increases monoton\nically and the user never inserts the same edge twice, the total number of INSERT-EDGE operations\nis exactly n(n - 1). During the time that the graph is growing, the user performs m CHECK-PATH\noperations which are intermixed with the n(n - 1) INSERT-EDGE's. Design a data structure that\ncan efficiently support any such sequence of operations.\n\n6.046J/18.410J Quiz 2 Solutions\nSolution: To solve this problem, we keep an n × n transitive-closure matrix T that keeps track\nof whether there exists a directed path between each pair of vertices. We give an algorithm such\nthat each CHECK-PATH operation takes O(1) time, and a sequence of n(n - 1) INSERT-EDGE\noperations take a total of O(n3) time in the worst case. Combining these bounds, any sequence\nof m CHECK-PATH and n(n - 1) INSERT-EDGE operations takes a total of O(n3 + m) time. We\nlater improve the data structure to deal with the case in which m is small, to get a total time of\nO(min {n3 + m, n m}).\nOur data structure maintains a transitive-closure matrix T = (tuv ) such that\n⎜\n: if there exists a directed path from u to v in G ,\ntuv =\n: otherwise .\nThe matrix T is similarly to an adjacency matrix, except that instead of keeping track of the exis\ntence of edges u ! v, it keeps track of paths u v. Note that the 1's in the u-th row correspond\nto all the vertices that u can reach, and the 1's in the u-th column correspond to all the vertices that\ncan reach u. We initialize tuu = 1 because there is a directed path (of no edges) from a vertex to\nitself.\nGiven T, the implementation of CHECK-PATH(u, v) is straightforward: just query the value of tuv .\nThis query can be performed in constant time, so CHECK-PATH runs in constant time. Pseudocode\nfor CHECK-PATH is given below:\nCHECK-PATH(u, v)\n1 if tuv = 1\nthen return TRUE\nelse return FALSE\nThe tricky part of the data structure is maintaining the matrix T on an INSERT-EDGE(u, v). When\nthe edge (u, v) is added, we check each vertex x. If x can reach u, and x cannot already reach v,\nthen we update the matrix to indicate that u can reach all the vertices that v can reach (in addition\nto the vertices that it could reach before). In other words, let Rw be the set of vertices that the\nvertex w can reach (i.e., the set of indices of 1's in the w-th row in T). Then when adding (u, v),\nwe iterate over all x ⊗ V . For each x such that u ⊗ Rx and v 6⊗ Rx, we set Rx Rx inf Rv .\nPseudocode for INSERT-EDGE is given below:\nINSERT-EDGE(u, v)\n1 for x 1 to n\ndo if txu = 1 and txv = 0\nx can reach u but not v\nthen for y 1 to n\ndo txy max {txy , tvy }\nIf v y, add x y to T\nCorrectness. The following theorem proves that our algorithm is correct.\n\n6.046J/18.410J Quiz 2 Solutions\nTheorem 1The INSERT-EDGE operation maintains the invariant that txy = 1 iff there exists a\ndirected path from x to y in G.\nProof.\nWe prove by induction on INSERT-EDGE operations. That is, we assume that the\ntransitive-closure matrix is correct up to (before) a particular INSERT-EDGE(u, v) operation, and\nthen we show that it is correct after that operation. We do not have to prove anything for CHECK-PATH\nas that operation does not modify the matrix.\nFirst, suppose that x y before the edge (u, v) is added. Then txy = 1 before the INSERT-EDGE\noperation. The only place txy can be updated is in line 4, and if so, it keeps its value of 1. This\nbehavior is correct because adding edges cannot destroy a path.\nSuppose that x 6 y before the edge (u, v) is added, but x y after the edge is added. Therefore,\nit must be the case the path from x to y uses the edge (u, v). Therefore, we have x u and v y\nbefore the INSERT-EDGE(u, v), so by assumption txu = 1 and tvy = 1. Furthermore, it must also\nv before the addition of (u, v), or we would violate the assumption that x 6\nbe true that x 6\ny.\nThus, we reach line 4, and txy tvy = 1.\nThe last case to consider is the one in which x 6 y after the operation. We need to make sure\nthat we have txy = 0 in this case. If there is no path, then txy = 0 before the addition of (u, v).\nMoreover, there is no path that uses (u, v), so either txu = 0 or tvy = 0. If txu = 0, we don't enter\nthe loop in line 2, so the update in line 4 is not performed. If txu = 1, then tvy = 0, and line 4 sets\nthe value of txy 0.\nAnalysis. Now let us examine the runtime of our algorithm. Each CHECK-PATH operation is just\na table lookup, which takes O(1) time. The analysis of INSERT-EDGE is slightly more complicated.\nWe can trivially bound the worst-case cost of INSERT-EDGE to O(n2) because we have nested for\nloops, each iterating over n items and doing constant work in line 4. We can show a tighter\nbound on a sequence of n(n - 1) INSERT-EDGE operations using aggregate analysis. Each time\nINSERT-EDGE runs, the outer loop (line 1) executes, performing the constant work from line 2 on\nn items. Thus, the contribution of the outer loop totals to O(n 3). The inner loop (line 3) executes\nonly when txv = 0, and when it finishes, txv = 1. Thus, for a particular vertex x, the inner loop can\nbe executed at most n times (actually, n - 1, as we begin with txx = 1). Since there are n vertices,\nthe inner loop can run at most n2 times in total for a total O(n3) work in the worst case. Thus, the\ntotal runtime for n(n - 1) INSERT-EDGEs and m CHECK-PATHs is O(n3 + m).\nSlight improvements. There is another data structure with O(1) cost for each INSERT-EDGE but\nO(n2) for each CHECK-PATH. To implement this data structure, we can use an adjacency list: we\nkeep an array A[1..n] of size n indexed by vertex and keep a (linked) list of all the outgoing edges\nfrom the corresponding vertex. To perform an INSERT-EDGE(u, v), simply insert v at the front\nof A[u] in O(1) time. (Note that edges are inserted only once, so we do not have to worry about\nv being present in the list already.) To perform CHECK-PATH(u, v), we run some sort of search,\nlet's say breadth-first search, starting at vertex u. If v is encountered at any point along the search,\n\n6.046J/18.410J Quiz 2 Solutions\nreturn TRUE. If not, return FALSE. Correctness of this algorithm should be somewhat obvious.\nBFS takes O(V + E) = O(n2) time. Thus, the total runtime of the sequence of operations is\nO(n 2 + n m).\nThis data structure is probably worse than the one given above. It seems safe to assume that m n\nas you probably query each vertex at least once. Assuming that m n is also reasonable. If\nyou do not want make these assumptions, and you know m ahead of time, you can choose the\nappropriate data structure.\nIt turns out that we can also combine both data structures to achieve the better of the two bounds\neven if m is not known ahead of time. To do this, we use the adjacency-list data structure until there\nhave been n queries. Once we reach the n-th query (CHECK-PATH), we construct the transitive-\nclosure matrix and then use the matrix for all subsequent operations. Construction of the matrix\ntakes O(n3) time by simply running BFS from each vertex u and marking each reachable vertex v\nby tuv 1. Thus, if m n, we use only the adjacently list, to get a total runtime of O(n2m). If\nm ← n, we first use the adjacency list for a total of O(n3) work, then we transform to the transitive-\nclosure matrix in O(n3) time, then we use the matrix for all subsequent operations, which comes\nto a total of O(n + m). Thus, this data structure achieves a runtime of O(min {n + m, n 2 m}) in\nthe worst case."
    },
    {
      "category": "Exam",
      "title": "quiz2_sol.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/96f941f98dfe207c30eabfb34bee5e2d_quiz2_sol.pdf",
      "content": "Introduction to Algorithms\nDecember 9, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 33\nQuiz 2 Solutions\n# of students\nQuiz 2 Score\nProblem 1. Ups and downs\nMoonlighting from his normal job at the National University of Technology, Professor Silver-\nmeadow performs magic in nightclubs. The professor is developing the following card trick. A\ndeck of n cards, labeled 1, 2, . . . , n, is arranged face up on a table. An audience member calls out\na range [i, j], and the professor flips over every card k such that i ← k ← j. This action is repeated\nmany times, and during the sequence of actions, audience members also query the professor about\nwhether particular cards are face up or face down. The trick is that there are no actual cards: the\nprofessor performs these manipulations in his head, and n is huge.\nUnbeknownst to the audience, the professor uses a computational device to perform the manip\nulations, but the current implementation is too slow to work in real time. Help the professor by\ndesigning an efficient data structure that supports the following operations on n cards:\n- FLIP(i, j): Flip over every card in the interval [i, j].\n- IS-FACE-UP (i): Return TRUE if card i is face up and FALSE if card i is face down.\n\nHandout 33: Quiz 2 Solutions\nSolution: Let F be the number of FLIP operations requested by the audience. Notice that perform\ning a single flip FLIP(i, j) is equivalent to performing two flips, FLIP(i, ∗) and FLIP(j + 1, ∗).\nOne fast solution is to use a dynamic order-statistic tree, where an element with key i represents a\nflip of the interval [i, ∗). For both x = i and x = j + 1, FLIP inserts x into the tree T if x ∪≡ T ,\nand deletes x from T if x ≡ T . IS-FACE-UP is implemented by returning true if the number of\nelements in the tree less than i (call it z) is even, and false if z is odd. One way to compute z\nis to insert i into T , set z to be one less than the rank of i, and then delete i from T . This data\nstructure requires O(min {F, n}) space and supports FLIP and IS-FACE-UP operations each in\nO(lg(min {F, n})) time. A completely correct solution of this type received full credit.\nThe following list describes other types of solutions that students submitted and the approximate\nnumber of points awarded to each.\n1. Another solution is to create a static 1-d range tree T containing the elements from 1 to n as\nits keys. Each node x in the tree stores a bit that corresponds to a flip of the interval of all\nelements in the subtree rooted at x. FLIP(i, j) performs a range query on [i, j], and flips the\nstored bit for the O(lg n) disjoint subtrees that are found by the query. IS-FACE-UP(i) walks\ndown the range tree to the node for i and returns true if the sum of the bits of nodes along\nthe path from the root to i is even. This data structure uses O(n) space and supports both\noperations in O(lg n) time. This type of solution received about 20 points.\n2. Other students assumed that F ∩ n, and stored each of the flip intervals [i, j] in an interval\ntree. The IS-FACE-UP(i) procedure simply queries the interval tree and returns true if the\nnumber of intervals that overlap i is even. If the tree stores overlapping flip intervals, then\nFLIP and IS-FACE-UP run in O(lg F ) time and O(F lg F ) time, respectively. If we do not\nallow overlapping intervals in the tree, then FLIP runs in O(F lg F ) time but IS-FACE-UP\nruns in O(lg F ) time. This type of solution received about 13 points.\n3. A simple slow solution is to use a bit-vector of length n to record which bits are flipped.\nThis solution supports FLIP and IS-FACE-UP in O(j - i) and O(1) time, respectively. Simi\nlarly, another simple solution that stores all F flip-intervals in a linked list supports FLIP and\nIS-FACE-UP in O(1) and O(F ) time, respectively. Either of these solutions received about 8\npoints.\n4. Any solution that ran slower than the simple slow solution (for example, O(lg n + j - i) for\nFLIP) received about 5 points.\n\nHandout 33: Quiz 2 Solutions\nProblem 2. The Data Center\nThe world-famous architect Gary O'Frank has been commissioned to design a new building, called\nthe Data Center. Gary wants his top architectural prot eg e to design a scale model of the Data Center\nusing precision-cut sticks, but he wants to preclude the model from inadvertently containing any\nright angles. Gary fabricates a set of n sticks, labeled 1, 2, . . . , n, where stick i has length xi.\nBefore giving the sticks to the prot eg e, he shows them to you and asks you whether it is possible\nto create a right triangle using any three of the sticks. Give an efficient algorithm for determining\nwhether there exist three sticks a, b, and c such that the triangle formed from them -- having sides\nof lengths xa, xb, and xc -- is a right triangle (that is, x + xb = x 2).\na\nc\nSolution: Let X[1..n] be the array with stick sizes. We are asked to determine whether there exist\ndistinct indices i, j, and k such that X[i]2 + X[j] = X[k]2 .\nAs an initial step we sort X[1..n] in ascending order. This can be done in worst-case O(n lg n)\ntime by for example heapsort. As soon as the array is sorted we first observe that it is sufficient to\ncheck X[i]2 + X[j] = X[k]2 for indices i, j, and k with i < j < k.\nIn order to obtain a worst-case O(n2) algorithm, we increase k from 1 to n in an outerloop and we\nsearch in linear time in an innerloop for indices i and j, i < j < k, with X[i]2 + X[j]2 = X[k] .\n1 Sort X[1..n] in ascending order\n2 k 1\n3 while k ← n\ndo i, j 1, k - 1\nwhile i < j\nif X[i]2 + X[j] = X[k]2 then return true\nif X[i]2 + X[j]2 < X[k]2\nthen i i + 1\nelse j j - 1\n10 return false\nWe will prove the invariant:\n0 2\n0 < j0\n[1 ← i0 < j ← k - 1 and X[i ] + X[j0]2 = X[k] ] implies [i ← i\n← j].\nInitially, i = 1 and j = k - 1 and the invariant holds. For the inductive step, assume that the\ninvariant holds when we enter the innerloop. Notice that X[1..n] is sorted in increasing order. If\nX[i]2 + X[j]2 < X[k]2, then, for i < j ← j,\n0 2\nX[i]2 + X[j ] ← X[i]2 + X[j] < X[k]2\nand the invariant holds for i i + 1. If X[i]2 + X[j]2 > X[k]2, then, for i ← i < j,\nX[i0]2 + X[j] → X[i]2 + X[j] > X[k]2\n\nHandout 33: Quiz 2 Solutions\nand the invariant holds for j j - 1.\nIf the innerloop finishes, then i = j and the invariant shows that there are no indices i and j ,\ni0 < j0\n0 2\n1 ←\n← k - 1, such that X[i ] + X[j0]2 = X[k]2 . This proves the correctness of the\nalgorithm. The innerloop has worst-case O(n) running time, hence, together with the outerloop\nthe algorithm runs in worst-case O(n2) time.\n\nHandout 33: Quiz 2 Solutions\nProblem 3. Nonnegativizing a matrix by pivoting\n\nA matrix M [1 . . n, 1 . . n] contains entries drawn from\n∅ {∗}. Each row contains at most 10\nfinite values, some of which may be negative. The goal of the problem is to transform M so that\nevery entry is nonnegative by using only pivot operations:\nPIVOT(M, i, x)\n1 for j 1 to n\ndo M [i, j] M [i, j] + x\nM [j, i] M [j, i] - x\nGive an efficient algorithm to determine whether there exists a sequence of pivot operations with\nvarious values for i and x such that, at the end of the sequence, M [i, j] → 0 for all i, j = 1, 2, . . . , n.\nSolution:\nSuppose that we have a sequence ∈PIVOT(M, i1, x1), PIVOT(M, i2, x2), . . . , PIVOT(M, ik , xk )i of\npivots. Since each pivot operation simply adds to columns and subtracts from rows, by the asso\nciativity and commutativity of addition, the order of the pivot operations is irrelevant. Moreover,\nsince PIVOT(M, i1, x1) followed by PIVOT(M, i2, x2) is equivalent to PIVOT(M, i1, x1 + x2), there\nis no need to pivot more than once on any index. Thus, any sequence of pivots is equivalent to a\nsequence of exactly n pivots ∈PIVOT(M, 1, x1), PIVOT(M, 2, x2), . . . , PIVOT(M, n, xn)i, where\nsome of the xi may be 0.\nx\nThe only pivots that affect a matrix entry M [i, j] are PIVOT(M, i, xi) and PIVOT(M, j, xj ). Thus,\nafter the entire sequence of pivots has been performed, the resulting matrix M 0 has entries M 0[i, j] =\nM [i, j] + xi - xj . We want every entry M 0[i, j] to be nonnegative, which is to say that M [i, j] +\ni - xj → 0, or xj - xi ← M [i, j]. Thus, we only need to solve a set of difference constraints.\nWe can ignore the difference constraints where M [i, j] = ∗, which leaves at most 10n difference\ncontraints in n variables. It takes us O(n ) time to find the at-most 10n finite entries, and we can\nuse the Bellman-Ford algorithm [CLRS, Section 24.4] to solve them in O(n · (10n)) = O(n2)\ntime, for a total of O(n2) time.\n\nHandout 33: Quiz 2 Solutions\nProblem 4. Augmenting the QueueinatorTM\nBy applying his research in warm fission, Professor Uriah's company is now manufacturing and\nselling the QueueinatorTM, a priority-queue hardware device which can be connected to an ordinary\ncomputer and which effectively supports the priority-queue operations INSERT and EXTRACT-MIN\nin O(1) time per operation. The professor's company has a customer, however, who actually needs\na \"double-ended\" priority queue that supports not only the operations INSERT and EXTRACT-MIN,\nbut also EXTRACT-MAX. Redesigning the QueueinatorTM hardware to support the extra operation\nwill take the professor's company a year of development. Help the professor by designing an\nefficient double-ended priority queue using software and one or more QueueinatorTM devices.\nSolution:\nKeep two Queueinators, MIN and MAX, where MAX has the keys negated, of roughly equal\nsize and keep an element mid which is the smallest element in MAX. While inserting an element\nwith key k, compare it to mid and insert it in MIN if k < mid and into MAX otherwise. For\nEXTRACT-MIN, extract from MIN and for EXTRACT-MAX, extract from MAX. If one empties,\nextract all the elements from the other into a sorted array. Split the array into half and insert the\nsmaller half into MIN and the larger half into MAX. This solution provides O(1) amortized cost\nfor all operations.\nProof of Correctness: The invariant is that all the elements in MIN are smaller than mid and all\nthe elements in MAX are larger than or equal to mid. The other invariant is that MIN and MAX\ntogether contain all the elements that have been inserted and not yet been extracted. The invariants\nare maintained during all operations. Therefore, extractions return the correct results.\nRunning time analysis: The potential function is (i) = 2 ||MIN| - |MAX||, where |MIN|\nand |MAX| are the number of elements in the MIN and MAX queueinators respectively. Both\nMIN and MAX are empty initially, and the potential is 0. The potential obviously never becomes\nnegative. Let us look at the amortized costs.\n1.INSERT Inserts into MIN or MAX. The real cost is 1 and the potential either increases by 2\n(if you inserted into the bigger queue) or decreases by 1 (if you insert into the smaller queue).\nThus the cost is always O(1).\n2.EXTRACT-MIN If the MIN is non-empty, then the real cost is 1 and the potential either\nincreases or decreases by 2. If MIN is empty, then you have to rebalance the queues. The\npotential before the rebalance is equal to 2 the number of elements in MAX, and the po\ntential after the rebalance is either 0 (or 2 if the number of elements is odd, but that doesn't\nchange much). The real cost of rebalancing is 2 the number of elements in MAX, since all\nthe elements are extracted and then inserted again. Thus the change in potential pays for the\nrebalancing, and the amortized cost is O(1).\n3.EXTRACT-MAX It is analogous to EXTRACT-MIN.\nTherefore the amortized cost of the operations is 0(1).\nThere were other good solutions, some of them are given below\n\nHandout 33: Quiz 2 Solutions\n1.Use 4 queueinators where 2 of them to keep track of the deleted elements. Those solutions\nlost a couple of points due to the use of the extra hardware.\n2.Use extra fields in the items to keep track of deletions. These also lost a couple of points due\nto extra assumptions that you can change the elements.\n3.Use hash tables to keep track of deleted elements. This only provides expected O(1) amor\ntized time, and assumes that the keys are integers in a range. Therefore, they lost about 5\npoints.\n4.Use direct access tables to keep track of deleted elements, lost about 6-7 points due to the\nextra space.\nThe analysis was very important for the solutions and the solutions that had incomplete or incorrect\nrunning time analysis lost points for that. In addition, a convincing correctness argument was\nrequired for full credit. People who gave the correct algorithm but did not claim or prove amortized\nbounds lost many points.\n\nHandout 33: Quiz 2 Solutions\nProblem 5. Spam distribution\nProfessor Hormel is designing a spam distribution network. The network is represented by a rooted\n\ntree T = (V, E) with root r ≡V and nonnegative edge-weight function w : E !\n. Each vertex\nv ≡V represents a server with one million email addresses, and each edge e ≡E represents\na communication channel that costs w(e) dollars to purchase. A server v ≡V receives spam\nprecisely if the entire path from the root r to v is purchased. The professor wants to send spam\nfrom the root r to k ←|V | servers (including the root) by spending as little money as possible.\nHelp the professor by designing an algorithm that finds a minimum-weight connected subtree of T\nwith k vertices including the root. (For partial credit, solve the problem when each vertex v ≡V\nhas at most 2 children in T .)\nSolution:\nExecutive Overview. The solution to this problem is based on dynamic programming. We define\nk|V | subproblems, one for each combination of a vertex v ≡V and a number k0 ←k. Each\nsubproblem is of the form \"Find the minimum-weight connected subtree of rooted at v with k0\nvertices.\" Each subproblem can be solved in O(k) time, resulting in a running time of O(k2|V |).\nNotation. Throughout this solution, we use the following notation:\n- MWCT(v,i): a minimum-weight connected subtree of i nodes rooted at v\n- child(v,i): child i of node v\n- w(v, i): the weight of the edge from v to child i\n- W (S): the sum of the weights of all the edges in tree S\n- deg(v): the number of children of node v\nOptimal Substructure. This problem exhibits both optimal substructure and overlapping sub\nproblems. For intuition, consider a binary tree T . Let v be a node in the tree, and consider a\nMWCT of T rooted at v with ` nodes. If T1 is the left subtree of v and has `1 nodes, then T1\nis a MWCT rooted at v's left child with `1 nodes. Similarly, if T2 is the right subtree of v and\nhas `2 nodes, then T2 is a MWCT rooted at v's right child with `2 nodes. The proof follows by\na cut-and-paste argument. Assume that T1 is not a MWCT rooted at v's left child. Then there is\nanother tree, S, rooted at v's left child with `1 nodes and with less weight than T1. We can then\nreduce the weight of the tree rooted at v by substituting S for tree T1, contradicting our assumption\nthat the tree rooted at v is a minimum-weight connected subtree with k nodes.\nWe can now observe how to use the overlapping subproblems. Once we have calculated the\nMWCT(v, `) for all v ≡V and all ` ←k0, we can determine the MWCT(v, k0 + 1). In par\nticular, we choose subtrees rooted at v's children that contain k0 nodes in total. That is, if there are\n` nodes in the left subtree of v, then there must be k0 -` nodes in the right subtree. We choose ` to\n\nHandout 33: Quiz 2 Solutions\nsplit the tree between v's left and right children to minimize the total weight. We now proceed to\ngeneralize this to arbitrary degree trees, and explain the algorithm in more detail.\nAlgorithm Description. Let T[v] be the subtree of T rooted at v. Let T[v, c] be the subtree\nof T rooted at v consisting of v and the trees rooted at children 1 . . c. More formally, T[v, c] =\nv ∅{T[w] : w = childv, i, 1 ←i ←c}.\nWe create two |V | × k × |V | arrays: C[1 . . |V |, 1 . . k, 1 . . |V |] and B[1 . . |V |, 1 . . k], 1 . . |V |.\nC[v, k0, c] holds the cost of the minimum-weight connected subtree of T[v, c] with k0 nodes. The\narray B is used to reconstruct the tree after the dynamic program has terminated. B[v, k0, c] holds\nthe number of children in the subtree of the MWCT of T[v, c] with k0 nodes rooted at child c.\nNotice that the resulting arrays are three-dimensional tables of size k|V | . Fortunately, we will\nonly have to fill in k|V | of the entries, leaving the rest empty/uninitialized, as we will see when\nthe algorithm is analyzed. (For simplicity, we assume that arbitrary-sized memory blocks can be\nallocated in O(1) time. If memory allocation is more costly, we can reduce the memory usage to\nO(k|V |).)\nThe main procedure to calculate the MWCT of V with k nodes is as follows:\nMWCT(V, k)\n1 for all v ≡V\ndo for c = 1 to deg(v)\ndo C[v, 1, c] 0\nB[v, 1, c] 0\n5 for ` = 2 to k\ndo for all v ≡V\ndo w child(v, 1)\nC[v, `, 1] w(v, w) + C[w, ` -1, deg(w)]\nB[v, `, 1] ` -1\nfor c = 2 to deg(v)\ndo i FIND-NUM-CHILDREN(v, `, c)\nB[v, `, c] i\nif i = 0 then C[v, `, c] C[v, `, c -1]\nif i = ` then C[v, `, c] w(v, w) + C[w, ` -1, deg(w)]\nif 0 < i < ` then C[v, `, c] C[v, ` -i] + w(v, w) + C[w, i, deg(w)]\nWe begin in lines 1-4 by initializing C[v, 1, c] = 0 for all v ≡V and all c ←|V |. These are the\nsmallest subproblems considered: the one node minimum-weight connected subtree rooted at v\nconsists simply of v itself, and hence has cost zero.\nWe proceed with three nested loops to fill in the arrays. In the outer loop (line 5) , we iterate ` from\n2 to k. In the second loop (line 6), we iterate v over all nodes in V . In the inner loop (line 10), we\niterate c from 2 to deg(v).\n\nHandout 33: Quiz 2 Solutions\nWithin the loop, we are examining the subtree T [v, c] and the node w = child(v, c). Let S be the\nMWCT of T [v, c] containing ` nodes. We want to calculate C[v, `, c], the cost of S.\nFirst consider the case where c = 1. In this case, all the nodes in S are in the subtree rooted at w.\nTherefore, S consists of node v and the MWCT of w with ` - 1 nodes.\nNow consider the case where c → 2. Notice that some of the nodes in S may be in subtrees\nrooted at the first c - 1 children of v, and some may be in the subtree rooted at w. The function\nFIND-NUM-CHILDREN(v, `, c) calculates the number of nodes in S that are in the subtree rooted\nat w; the remaining ` - i - 1 are in the subtrees rooted at the first c - 1 children of v.\nIt is then easy to determine the cost of S. If no nodes in S are in the subtree rooted at w, then S is\njust the MWCT of T [v, c - 1] with ` nodes (line 11). If all the nodes in S are in the subtree rooted\nat w, then S consists of node v along with the MWCT of w with ` - 1 nodes (line 12). Finally, if i\nis between 0 and `, then S consists of the MWCT of T [v, c - 1] with ` - i nodes, plus the MWCT\nof w with i nodes (line 13).\nIt remains to discuss the FIND-NUM-CHILDREN procedure:\nFIND-NUM-CHILDREN(v, `, c)\n1 w child(v, c)\n2 min-weight C[v, `, c - 1]\n3 num 0\n4 for i = 1 to ` - 2\ndo wt C[v, ` - i, c - 1] + w(v, c) + C[w, i, deg(w)]\nif wt < min-weight\nthen min-weight wt\nnum i\n9 if min-weight > w(v, w) + C[w, ` - 1, deg(w)]\nthen num `\n11 return num\nThe FIND-NUM-CHILDREN procedure compares all possible ways of dividing ` nodes between\nT [v, c- 1] and the subtree rooted at w = child(v, c). First, it considers the case where all ` children\nare in T [v, c - 1] and zero children are in the tree rooted at w (line 2-3). Next, it iterates through\nthe loop ` - 2 times, placing ` - i nodes in T [v, c - 1] and i nodes in the subtree rooted at w (lines\n4-8). Finally, it considers the case where ` - 1 children are in the subtree rooted at w (lines 9-10).\nIt then returns the choice which minimizes the weight.\nThe final procedure in the algorithms prints out the tree, performing a depth-first traversal of the\nresulting tree:\n\nHandout 33: Quiz 2 Solutions\nPRINT-TREE(v, k)\n1 PRINT(v)\n2 ` k\n3 for c = deg(v) downto 1\ndo if ` > 0 and B[v, `, c] ∪= 0\nthen w child(v, c)\nPRINT-TREE(v, B[v, `, c])\n` ` - B[v, `, c]\nThe PRINT-TREE procedure starts with the last child of v, and examines B[v, `, c] to determine the\nnumber of nodes in the subtree root at child c. It then recurses into that subtree, and updates the\nnumber of nodes remaining in the MWCT.\nRunning Time. First, examine lines 1-4 of MWCT: the two loops iterate over every edge of\nevery node, resulting on O(|E|) = O(|V |) operations. Next, the for-loop on line 5 repeats O(k)\ntime. Now we examine lines 6-15. The innermost loop executes once for every edge of every\nnode, i.e., O(|E|) = O(|V |) times. Each iteration of the loop calls FIND-NUM-CHILDREN(v, `, c)\nwhich takes O(`) = O(k) time. Therefore each iteration of lines 6-15 costs O(k|V |). Therefore\nthe entire cost of MWCT is O(k2|V |). Finally, printing the output costs O(|V |).\nCorrectness. The correctness follows by induction on k using a cut-and-paste argument. The\nloop invariant maintained by the innermost loop is that for all c ← c, C[v, `, c ] is equal to the cost\nof the MWCT of T[v, c ]. The loop invariant of the outer loop is that for all v0, for all ` ← `, for\nall c ← deg(v), C[v, ` , c ] is equal to the cost of the MWCT of T[v , c ] with `0 nodes. These two\ninvariants need to be proved together by induction. (We omit mention of the B array here, though\nits correctness follows by the same argument as follows.)\nConsider immediately after the innermost loop has terminated for some v, `, and c. We argue\nthat C[v, `, c] is the cost of the MWCT of T[v, c]. Assume not. Then there is some other subtree\nS of T[v, c] with ` nodes and cost < C[v, `, c]. Consider the subtree of S rooted at child c of v\nwith i nodes. (S may be the empty tree.) We know that the cost of this subtree must be at least\nx = C[child(v, c), i, deg(child(v, c))], since by induction x is the MWCT of child c of v with i\nnodes. Similarly, consider the subtree of S consisting of all the nodes in T[v, c - 1]. Again, the\ncost of this subtree must be at least y = C[v, ` - i, c - 1], since by induction y is the MWCT of\nT[v, c - 1] with ` - i nodes. But FIND-MIN-CHILDREN ensures that the C[v, `, c] is no more than\nx+ y+ w(v, c), contradicting our assumption. Finally, the inductive step of the outer loop invariant\nfollows from the inner loop invariant, concluding the proof.\n\nHandout 33: Quiz 2 Solutions\nProblem 6. A tomato a day\nProfessor Kerry loves tomatoes! The professor eats one tomato every day, because she is obsessed\nwith the health benefits of the potent antioxidant lycopene and because she just happens to like\nthem very much, thank you. The price of tomatoes rises and falls during the year, and when the\nprice of tomatoes is low, the professor would naturally like to buy as many tomatoes as she can.\nBecause tomatoes have a shelf-life of only d days, however, she must eat a tomato bought on day\ni on some day j in the range i ← j < i + d, or else the tomato will spoil and be wasted. Thus,\nalthough the professor can buy as many tomatoes as she wants on any given day, because she\nconsumes only one tomato per day, she must be circumspect about purchasing too many, even if\nthe price is low.\nThe professor's obsession has led her to worry about whether she is spending too much money\non tomatoes. She has obtained historical pricing data for n days, and she knows how much she\nactually spent on those days. The historical data consists of an array C[1 . . n], where C[i] is the\nprice of a tomato on day i. She would like to analyze the historical data to determine what is the\nminimum amount she could possibly have spent in order to satisfy her tomato-a-day habit, and\nthen she will compare that value to what she actually spent.\nGive an efficient algorithm to determine the optimal offline (20/20 hindsight) purchasing strategy\non the historical data. Given d, n, and C[1 . . n], your algorithm should output B[1 . . n], where B[i]\nis the number of tomatoes to buy on day i.\nSolution:\nYou can solve this problem in (n) time, which is the fastest possible asymptotic solution because\nit requires\n(n) time to scan the cost array. For every day i, you must buy the tomato for that day\nin the window W(i) ≥ [i - d + 1, i] inf [1, n]. Note that the greedy choice works: in the optimal\nsolution, you should buy the tomato for day i on the minimum cost day Ti in W(i). Once you\ncalculate Ti for all i, you can easily compute B in (n) time.\nYou can compute all Ti in O(n) time by computing the sliding window minimum Ti for each i in\namortized O(1) time. Use a double-ended queue (deque) of days Q = ∈q1, q2, . . . , qmi such that\nday q1 is the minimum cost day in W(i) and each entry qk>1 is the minimum cost day of the days\nin W(i) following qk-1. Then q1 = Ti and this invariant can be maintained in amortized O(1) time\nusing the following algorithm:\n\nHandout 33: Quiz 2 Solutions\nBUYTOMATOES(d, C[1 . . n])\n1 Q ≤\n2 B[1 . . n] 0\n3 for i 1 to n\ndo if not EMPTY(Q) and HEAD(Q) ←i -d\nthen POP-FRONT(Q)\nRemove old day\nwhile not EMPTY and C[i] ←C[TAIL(Q)]\ndo POP-BACK(Q)\nRemove non-minimum-cost days\nPUSH-BACK(Q, i)\nAdd current day\nB[HEAD(Q)] B[HEAD(Q)] + 1\n10 return B\nEach day i is added once to Q and removed at most once from Q, so the total number of deque\noperations is O(n). Each deque operation can be done in O(1) time. The loop in the algorithm\nexecutes for n iterations, so the overall running time is (n). The deque requires O(min(n, d))\nspace since there can be at most one element for each of the past d days. The return array B\nrequires (n) space, so the overall space used is (n).\nThere are other ways to compute Ti in amortized O(1) time that also received full credit. Slower\nsolutions that received partial credit include solutions that compute Ti in O(log d) or O(d) time,\nsolutions that compute B directly by looking ahead up to d days at each step, dynamic program\nming solutions, and solutions that sort the tomato prices and maximize the number of tomatoes\npurchased at lower prices."
    },
    {
      "category": "Resource",
      "title": "dyn_multi_alg.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/41ba2bd0da08d73b8b211daa43a75be6_dyn_multi_alg.pdf",
      "content": "Introduction to Algorithms\nDecember 5, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 29\nA Minicourse on Dynamic Multithreaded Algorithms\nCharles E. Leiserson ∗\nMIT Computer Science and Artificial Intelligence Laboratory\nCambridge, Massachusetts 02139, USA\nDecember 5, 2005\nAbstract\nThis tutorial teaches dynamic multithreaded algorithms using a Cilk-like [11, 8, 10] model.\nThe material was taught in the MIT undergraduate class 6.046 Introduction to Algorithms as\ntwo 80-minute lectures. The style of the lecture notes follows that of the textbook by Cormen,\nLeiserson, Rivest, and Stein [7], but the pseudocode from that textbook has been \"Cilkified\"\nto allow it to describe multithreaded algorithms. The first lecture teaches the basics behind\nmultithreading, including defining the measures of work and critical-path length. It culminates\nin the greedy scheduling theorem due to Graham and Brent [9, 6]. The second lecture shows\nhow parallel applications, including matrix multiplication and sorting, can be analyzed using\ndivide-and-conquer recurrences.\n1 Dynamic multithreaded programming\nAs multiprocessor systems have become increasingly available, interest has grown in parallel pro\ngramming. Multithreaded programming is a programming paradigm in which a single program\nis broken into multiple threads of control which interact to solve a single problem. These notes\nprovide an introduction to the analysis of \"dynamic\" multithreaded algorithms, where threads can\nbe created and destroyed as easily as an ordinary subroutine can be called and return.\n1.1 Model\nOur model of dynamic multithreaded computation is based on the procedure abstraction found in\nvirtually any programming language. As an example, the procedure FIB gives a multithreaded\nalgorithm for computing the Fibonacci numbers:1\n∗Support was provided in part by the Defense Advanced Research Projects Agency (DARPA) under Grant F30602-\n97-1-0270, by the National Science Foundation under Grants EIA-9975036 and ACI-0324974, and by the Singapore-\nMIT Alliance.\n1This algorithm is a terrible way to compute Fibonacci numbers, since it runs in exponential time when logarithmic\nmethods are known [7, pp. 902-903], but it serves as a good didactic example.\n\nHandout 29: Dynamic Multithreaded Algorithms\nFIB(n)\n1 if n < 2\nthen return n\n3 x ← spawn FIB(n - 1)\n4 y ← spawn FIB(n - 2)\n5 sync\n6 return (x + y)\nA spawn is the parallel analog of an ordinary subroutine call. The keyword spawn before the\nsubroutine call in line 3 indicates that the subprocedure FIB(n - 1) can execute in parallel with\nthe procedure FIB(n) itself. Unlike an ordinary function call, however, where the parent is not\nresumed until after its child returns, in the case of a spawn, the parent can continue to execute in\nparallel with the child. In this case, the parent goes on to spawn FIB(n - 2). In general, the parent\ncan continue to spawn off children, producing a high degree of parallelism.\nA procedure cannot safely use the return values of the children it has spawned until it executes\na sync statement. If any of its children have not completed when it executes a sync, the procedure\nsuspends and does not resume until all of its children have completed. When all of its children\nreturn, execution of the procedure resumes at the point immediately following the sync statement.\nIn the Fibonacci example, the sync statement in line 5 is required before the return statement\nin line 6 to avoid the anomaly that would occur if x and y were summed before each had been\ncomputed.\nThe spawn and sync keywords specify logical parallelism, not \"actual\" parallelism. That is,\nthese keywords indicate which code may possibly execute in parallel, but what actually runs in\nparallel is determined by a scheduler, which maps the dynamically unfolding computation onto\nthe available processors.\nWe can view a multithreaded computation in graph-theoretic terms as a dynamically unfolding\ndag G = (V, E), as is shown in Figure 1 for FIB. We define a thread to be a maximal sequence\nof instructions not containing the parallel control statements spawn , sync, and return . Threads\nmake up the set V of vertices of the multithreaded computation dag G. Each procedure execution is\na linear chain of threads, each of which is connected to its successor in the chain by a continuation\nedge. When a thread u spawns a thread v, the dag contains a spawn edge (u, v) ∈ E, as well\nas a continuation edge from u to u's successor in the procedure. When a thread u returns, the\ndag contains an edge (u, v), where v is the thread that immediately follows the next sync in the\nparent procedure. Every computation starts with a single initial thread and (assuming that the\ncomputation terminates), ends with a single final thread. Since the procedures are organized in a\ntree hierarchy, we can view the computation as a dag of threads embedded in the tree of procedures.\n1.2 Performance Measures\nTwo performance measures suffice to gauge the theoretical efficiency of multithreaded algorithms.\nWe define the work of a multithreaded computation to be the total time to execute all the operations\nin the computation on one processor. We define the critical-path length of a computation to be\nthe longest time to execute the threads along any path of dependencies in the dag. Consider, for\n\nHandout 29: Dynamic Multithreaded Algorithms\n\nfib(3)\nfib(2)\nfib(1)\nfib(1)\nfib(2)\nfib(1)\nfib(0)\nfib(0)\nfib(4)\nFigure 1: A dag representing the multithreaded computation of FIB(4). Threads are shown as circles, and\neach group of threads belonging to the same procedure are surrounded by a rounded rectangle. Downward\nedges are spawns dependencies, horizontal edges represent continuation dependencies within a procedure,\nand upward edges are return dependencies.\nexample, the computation in Figure 1. Suppose that every thread can be executed in unit time.\nThen, the work of the computation is 17, and the critical-path length is 8.\nWhen a multithreaded computation is executed on a given number P of processors, its running\ntime depends on how efficiently the underlying scheduler can execute it. Denote by TP the running\ntime of a given computation on P processors. Then, the work of the computation can be viewed\nas T1, and the critical-path length can be viewed as Tinf.\nThe work and critical-path length can be used to provide lower bounds on the running time on\nP processors. We have\nTP ≥T1/P ,\n(1)\nsince in one step, a P-processor computer can do at most P work. We also have\nTP ≥Tinf,\n(2)\nsince a P-processor computer can do no more work in one step than an infinite-processor computer.\nThe speedup of a computation on P processors is the ratio T1/TP, which indicates how many\ntimes faster the P-processor execution is than a one-processor execution. If T1/TP = Θ(P), then\nwe say that the P-processor execution exhibits linear speedup. The maximum possible speedup is\nT1/Tinf, which is also called the parallelism of the computation, because it represents the average\namount of work that can be done in parallel for each step along the critical path. We denote the\nparallelism of a computation by P.\n1.3\nGreedy Scheduling\nThe programmer of a multithreaded application has the ability to control the work and critical-path\nlength of his application, but he has no direct control over the scheduling of his application on a\n\nHandout 29: Dynamic Multithreaded Algorithms\ngiven number of processors. It is up to the runtime scheduler to map the dynamically unfolding\ncomputation onto the available processors so that the computation executes efficiently. Good on\nline schedulers are known [3, 4, 5] but their analysis is complicated. For simplicity, we'll illustrate\nthe principles behind these schedulers using an off-line \"greedy\" scheduler.\nA greedy scheduler schedules as much as it can at every time step. On a P-processor computer,\ntime steps can be classified into two types. If there are P or more threads ready to execute, the step\nis a complete step, and the scheduler executes any P threads of those ready to execute. If there are\nfewer than P threads ready to execute, the step is an incomplete step, and the scheduler executes\nall of them. This greedy strategy is provably good.\nTheorem 1 (Graham [9], Brent [6]) A greedy scheduler executes any multithreaded computation\nG with work T1 and critical-path length Tinf in time\nTP ≤ T1/P + Tinf\n(3)\non a computer with P processors.\nProof. For each complete step, P work is done by the P processors. Thus, the number of com\nplete steps is at most T1/P, because after T1/P such steps, all the work in the computation has been\nperformed. Now, consider an incomplete step, and consider the subdag G′ of G that remains to be\nexecuted. Without loss of generality, we can view each of the threads executing in unit time, since\nwe can replace a longer thread with a chain of unit-time threads. Every thread with in-degree 0 is\nready to be executed, since all of its predecessors have already executed. By the greedy scheduling\npolicy, all such threads are executed, since there are strictly fewer than P such threads. Thus, the\ncritical-path length of G′ is reduced by 1. Since the critical-path length of the subdag remaining\nto be executed decreases by 1 each for each incomplete step, the number of incomplete steps is at\nmost Tinf. Each step is either complete or incomplete, and hence Inequality (3) follows.\nCorollary 2 A greedy scheduler achieves linear speedup when P = O(P).\nProof. Since P = T1/Tinf, we have P = O(T1/Tinf), or equivalently, that Tinf = O(T1/P). Thus,\nwe have TP ≤ T1/P + Tinf = O(T1/P).\n1.4 Cilk and ⋆Socrates\nCilk [4, 11, 10] is a parallel, multithreaded language based on the serial programming language C.\nInstrumentation in the Cilk scheduler provides an accurate measure of work and critical path. Cilk's\nrandomized scheduler provably executes a multithreaded computation on a P-processor computer\nin TP = T1/P + O(Tinf) expected time. Empirically, the scheduler achieves TP ≈ T1/P + Tinf\ntime, yielding near-perfect linear speedup if P ≪ P.\nAmong the applications that have been programmed in Cilk are the ⋆Socrates and Cilkchess\nchess-playing programs. These programs have won numerous prizes in international competition\nand are considered to be among the strongest in the world. An interesting anomaly occurred\n\nHandout 29: Dynamic Multithreaded Algorithms\nduring the development of ⋆Socrates which was resolved by understanding the measures of work\nand critical-path length.\nThe ⋆Socrates program was initially developed on a 32-processor computer at MIT, but it was\nintended to run on a 512-processor computer at the National Center for Supercomputing Appli\ncations (NCSA) at the University of Illinois. A clever optimization was proposed which, during\ntesting at MIT, caused the program to run much faster than the original program. Nevertheless, the\noptimization was abandoned, because an analysis of work and critical-path length indicated that\nthe program would actually be slower on the NCSA machine.\nLet us examine this anomaly in more detail. For simplicity, the actual timing numbers have\nbeen simplified. The original program ran in T32 = 65 seconds at MIT on 32 processors. The\n′\n\"optimized\" program ran in T\n= 40 seconds also on 32 processors. The original program had\nwork T1 = 2048 seconds and critical-path length Tinf = 1 second. Using the formula TP =\nT1/P +Tinf as a good approximation of runtime, we discover that indeed T32 = 65 = 2048/32+1.\nThe \"optimized\" program had work T1 = 1024 seconds and critical-path length Tinf = 8 seconds,\nyielding T ′\n= 40 = 1024/32 + 8. But, now let us determine the runtimes on 512 processors.\n′\nWe have T512 = 2048/512 + 1 = 5 and T512 = 1024/512 + 8 = 10, which is twice as slow!\nThus, by using work and critical-path length, we can predict the performance of a multithreaded\ncomputation.\nExercise 1-1. Sketch the multithreaded computation that results from executing FIB(5). Assume\nthat all threads in the computation execute in unit time. What is the work of the computation?\nWhat is the critical-path length? Show how to schedule the dag on 2 processors in a greedy fashion\nby labeling each thread with the time step on which it executes.\nExercise 1-2. Consider the following multithreaded procedure SUM for pairwise adding the ele\nments of arrays A[1 . . n] and B[1 . . n] and storing the sums in C[1 . . n]:\nSUM(A, B, C)\n1 for i ← 1 to length[A]\ndo C[i] ← spawn ADD(A[i], B[i])\n3 sync\nADD(x, y)\n1 return (x + y)\nDetermine an asymptotic bound on the work, the critical-path length, and the parallelism of the\ncomputation in terms of n. Give a divide-and-conquer algorithm for the problem that is as parallel\nas possible. Analyze your algorithm.\nExercise 1-3. Prove that a greedy scheduler achieves the stronger bound\nTP ≤ (T1 - Tinf)/P + Tinf .\n(4)\nExercise 1-4. Prove that the time for a greedy scheduler to execute any multithreaded computa\ntion is within a factor of 2 of the time required by an optimal scheduler.\n\nHandout 29: Dynamic Multithreaded Algorithms\nExercise 1-5. For what number P of processors do the two chess programs described in this\nsection run equally fast?\nT\nExercise 1-6. Professor Tweed takes some measurements of his (deterministic) multithreaded\nprogram, which is scheduled using a greedy scheduler, and finds that T4 = 80 seconds and\n64 = 10 seconds. What is the fastest that the professor's computation could possibly run on\n10 processors? Use Inequality (4) and the two lower bounds from Inequalities (1) and (2) to derive\nyour answer.\n2 Analysis of multithreaded algorithms\nWe now turn to the design and analysis of multithreaded algorithms. Because of the divide-and-\nconquer nature of the multithreaded model, recurrences are a natural way to express the work\nand critical-path length of a multithreaded algorithm. We shall investigate algorithms for matrix\nmultiplication and sorting and analyze their performance.\n2.1 Parallel Matrix Multiplication\nTo multiply two n × n matrices A and B in parallel to produce a matrix C, we can recursively\nformulate the problem as follows:\n\nC11 C12\nC21 C22\n!\n=\n=\n\nA11 A12\nA21 A22\n!\n·\n\nB11 B12\nB21 B22\n!\nA11B11 + A12B21 A11B12 + A12B22\n!\n.\nA21B11 + A22B21 A21B12 + A22B22\nThus, each n × n matrix multiplication can be expressed as 8 multiplications and 4 additions of\n(n/2) × (n/2) submatrices. The multithreaded procedure MULT multiplies two n × n matrices,\nwhere n is a power of 2, using an auxiliary procedure ADD to add n × n matrices. This algorithm\nis not in-place.\nADD(C, T, n)\n1 if n = 1\nthen C[1, 1] ← C[1, 1] + T[1, 1]\n3 return\n4 partition C and T into (n/2) × (n/2) submatrices\n5 spawn ADD(C11, T11, n/2)\n6 spawn ADD(C12, T12, n/2)\n7 spawn ADD(C21, T21, n/2)\n8 spawn ADD(C22, T22, n/2)\n9 sync\n10 return\n\nHandout 29: Dynamic Multithreaded Algorithms\nMULT(C, A, B, n)\n1 if n = 1\nthen C[1, 1] ← A[1, 1] · B[1, 1]\n3 return\n4 allocate a temporary matrix T[1 . . n, 1 . . n]\n5 partition A, B, C, and T into (n/2) × (n/2) submatrices\n6 spawn MULT(C11, A11, B11, n/2)\n7 spawn MULT(C12, A11, B12, n/2)\n8 spawn MULT(C21, A21, B11, n/2)\n9 spawn MULT(C22, A21, B12, n/2)\n10 spawn MULT(T11, A12, B21, n/2)\n11 spawn MULT(T12, A12, B22, n/2)\n12 spawn MULT(T21, A22, B21, n/2)\n13 spawn MULT(T22, A22, B22, n/2)\n14 sync\n15 ADD(C, T, n)\nThe matrix partitionings in line 5 of MULT and line 4 of ADD take O(1) time, since only a constant\nnumber of indexing operations are required.\nTo analyze this algorithm, let AP (n) be the P-processor running time of ADD on n×n matrices,\nand let MP (n) be the P-processor running time of MULT on n × n matrices. The work (running\ntime on one processor) for ADD can be expressed by the recurrence\nA1(n)\n=\n4A1(n/2) + Θ(1)\n=\nΘ(n 2) ,\nwhich is the same as for the ordinary double-nested-loop serial algorithm. Since the spawned\nprocedures can be executed in parallel, the critical-path length for ADD is\nAinf(n)\n=\nAinf(n/2) + Θ(1)\n=\nΘ(lg n) .\nThe work for MULT can be expressed by the recurrence\nM1(n)\n=\n8M1(n/2) + A1(n)\n=\n8M1(n/2) + Θ(n 2)\n=\nΘ(n 3) ,\nwhich is the same as for the ordinary triple-nested-loop serial algorithm. The critical-path length\nfor MULT is\nMinf(n)\n=\nMinf(n/2) + Θ(lg n)\n=\nΘ(lg 2 n) .\n\nHandout 29: Dynamic Multithreaded Algorithms\nThus, the parallelism for MULT is M1(n)/Minf(n) = Θ(n3/ lg 2 n), which is quite high. To multiply\n1000× 1000 matrices, for example, the parallelism is (ignoring constants) about 10003/102 = 107 .\nMost parallel computers have far fewer processors.\nTo achieve high performance, it is often advantageous for an algorithm to use less space,\nbecause more space usually means more time. For the matrix-multiplication problem, we can\neliminate the temporary matrix T in exchange for reducing the parallelism. Our new algorithm\nMULT-ADD performs C ← C + A · B using a similar divide-and-conquer strategy to MULT.\nMULT-ADD (C, A, B, n)\n1 if n = 1\nthen C[1, 1] ← C[1, 1] + A[1, 1] · B[1, 1]\n3 return\n4 partition A, B, and C into (n/2) × (n/2) submatrices\n5 spawn MULT-ADD(C11, A11, B11, n/2)\n6 spawn MULT-ADD(C12, A11, B12, n/2)\n7 spawn MULT-ADD(C21, A21, B11, n/2)\n8 spawn MULT-ADD(C22, A21, B12, n/2)\n9 sync\n10 spawn MULT-ADD(C11, A12, B21, n/2)\n11 spawn MULT-ADD(C12, A12, B22, n/2)\n12 spawn MULT-ADD(C21, A22, B21, n/2)\n13 spawn MULT-ADD(C22, A22, B22, n/2)\n14 sync\n15 return\nLet MAP (n) be the P-processor running time of MULT-ADD on n × n matrices. The work for\nMULT-ADD is MA1(n) = Θ(n3), following the same analysis as for MULT, but the critical-path\nlength is now\nMAinf(n)\n=\n2MAinf(n/2) + Θ(1)\n=\nΘ(n) ,\nsince only 4 recursive calls can be executed in parallel.\nThus, the parallelism is MA1(n)/MAinf(n) = Θ(n ). On 1000×1000 matrices, for example, the\nparallelism is (ignoring constants) still quite high: about 10002 = 106. In practice, this algorithm\noften runs somewhat faster than the first, since saving space often saves time due to hierarchical\nmemory.\n\n?\nHandout 29: Dynamic Multithreaded Algorithms\nl/2\nl\nA\n≤A[\n2]\n≥A[\n2]\nm\nj\nj\nl/\nl/\n+ 1\n≤A[l/2]\n≥A[l/2]\nB\nFigure 2: Illustration of P-MERGE. The median of array A is used to partition array B, and then the lower\nportions of the two arrays are recursively merged, as, in parallel, are the upper portions.\n2.2 Parallel Merge Sort\nThis section shows how to parallelize merge sort. We shall see the parallelism of the algorithm\ndepends on how well the merge subroutine can be parallelized.\nThe most straightforward way to parallelize merge sort is to run the recursion in parallel, as is\ndone in the following pseudocode:\nMERGE-SORT (A, p, r)\n1 if p < r\nthen q ←⌊(p + r)/2⌋\nspawn MERGE-SORT (A, p, q)\nspawn MERGE-SORT (A, q + 1, r)\nsync\nMERGE(A, p, q, r)\n7 return\nThe work of MERGE-SORT on an array of n elements is\nT1(n)\n=\n2T1(n/2) + Θ(n)\n=\nΘ(n lg n) ,\nsince the running time of MERGE is Θ(n). Since the two recursive spawns operate in parallel, the\ncritical-path length of MERGE-SORT is\nTinf(n)\n=\nTinf(n/2) + Θ(n)\n=\nΘ(n) .\nConsequently, the parallelism of the algorithm is T1(n)/Tinf(n) = Θ(lg n), which is puny. The\nobvious bottleneck is MERGE.\nThe following pseudocode, which is illustrated in Figure 2, performs the merge in parallel.\n\nHandout 29: Dynamic Multithreaded Algorithms\nP-MERGE (A[1 . . l], B[1 . . m], C[1 . . n])\n1 if m > l\nwithout loss of generality, larger array should be first\nthen P-MERGE (B[1 . . m], A[1 . . l], C[1 . . n])\nreturn\n4 if n = 1\nthen C[1] ← A[1]\nreturn\n7 if l = 1\nand m = 1\nthen if A[1] ≤ B[1]\nthen C[1] ← A[1]; C[2] ← B[1]\nelse C[1] ← B[1]; C[2] ← A[1]\nreturn\n12 find j such that B[j] ≤ A[l/2] ≤ B[j + 1] using binary search\n13 spawn P-MERGE (A[1 . . (l/2)], B[1 . . j], C[1 . .(l/2 + j)])\n14 spawn P-MERGE (A[(l/2 + 1) . . l], B[(j + 1) . . m], C[(l/2 + j + 1) . . n])\n15 sync\n16 return\nThis merging algorithm finds the median of the larger array and uses it to partition the smaller\narray. Then, the lower portions of the two arrays are recursively merged, and in parallel, so are the\nupper portions.\nTo analyze P-MERGE, let PMP (n) be the P-processor time to merge two arrays A and B\nhaving n = m + l elements in total. Without loss of generality, let A be the larger of the two\narrays, that is, assume l ≥ m.\nWe'll analyze the critical-path length first. The binary search of B takes Θ(lg m) time, which\nin the worst case is Θ(lg n). Since the two recursive spawns in lines 13 and 14 operate in parallel,\nthe worst-case critical-path length is Θ(lg n) plus the worst-case critical path-length of the spawn\noperating on the larger subarrays. In the worst case, we must merge half of A with all of B, in\nwhich case the recursive spawn operates on at most 3n/4 elements. Thus, we have\nPMinf(n)\n≤ PMinf(3n/4) + Θ(lg n)\n=\nΘ(lg 2 n) .\nTo analyze the work of MERGE, observe that although the two recursive spawns may operate\non different numbers of elements, they always operate on n elements between them. Let αn\nbe the number of elements operated on by the first spawn, where α is a constant in the range\n1/4 ≤ α ≤ 3/4. Thus, the second spawn operates on (1 - α)n elements, and the worst-case work\nsatisfies the recurrence\nPM1(n) = PM1(αn) + PM1((1 - α)n) + Θ(lg n) .\n(5)\nWe shall show that PM1(n) = Θ(n) using the substitution method. (Actually, the Akra-Bazzi\nmethod [2], if you know it, is simpler.) We assume inductively that PM1(n) ≤ an- b lg n for some\n\nHandout 29: Dynamic Multithreaded Algorithms\nconstants a, b > 0. We have\nPM1(n)\n≤ aαn - b lg(αn) + a(1 - α)n - b lg((1 - α)n) + Θ(lg n)\n=\nan - b(lg(αn) + lg((1 - α)n)) + Θ(lg n)\n=\nan - b(lg α + lg n + lg(1 - α) + lg n) + Θ(lg n)\n=\nan - b lg n - (b(lg n + lg(α(1 - α))) - Θ(lg n))\n≤ an - b lg n ,\nsince we can choose b large enough so that b(lg n + lg(α(1 - α))) dominates Θ(lg n). Moreover,\nwe can pick a large enough to satisfy the base conditions. Thus, PM1(n) = Θ(n), which is the\nsame work asymptotically as the ordinary, serial merging algorithm.\nWe can now reanalyze the MERGE-SORT using the P-MERGE subroutine. The work T1(n)\nremains the same, but the worst-case critical-path length now satisfies\nTinf(n)\n=\nTinf(n/2) + Θ(lg 2 n)\n=\nΘ(lg 3 n) .\nThe parallelism is now Θ(n lg n)/Θ(lg 3 n) = Θ(n/ lg 2 n).\nExercise 2-1. Give an efficient and highly parallel multithreaded algorithm for multiplying an\nn× n matrix A by a length-n vector x that achieves work Θ(n2) and critical path Θ(lg n). Analyze\nthe work and critical-path length of your implementation, and give the parallelism.\nExercise 2-2. Describe a multithreaded algorithm for matrix multiplication that achieves work\nΘ(n3) and critical path Θ(lg n). Comment informally on the locality displayed by your algorithm\nin the ideal cache model as compared with the two algorithms from this section.\nExercise 2-3. Write a Cilk program to multiply an n1 ×n2 matrix by an n2 ×n3 matrix in parallel.\nAnalyze the work, critical-path length, and parallelism of your implementation. Your algorithm\nshould be efficient even if any of n1, n2, and n3 are 1.\nExercise 2-4. Write a Cilk program to implement Strassen's matrix multiplication algorithm in\nparallel as efficiently as you can. Analyze the work, critical-path length, and parallelism of your\nimplementation.\nExercise 2-5. Write a Cilk program to invert a symmetric and positive-definite matrix in parallel.\n(Hint: Use a divide-and-conquer approach based on the ideas of Theorem 31.12 from [7].)\nExercise 2-6. Akl and Santoro [1] have proposed a merging algorithm in which the first step is to\nfind the median of all the elements in the two sorted input arrays (as opposed to the median of the\nelements in the larger subarray, as is done in P-MERGE). Show that if the total number of elements\nin the two arrays is n, this median can be found using Θ(lg n) time on one processor in the worst\ncase. Describe a linear-work multithreaded merging algorithm based on this subroutine that has a\nparallelism of Θ(n/ lg 2 n). Give and solve the recurrences for work and critical-path length, and\ndetermine the parallelism. Implement your algorithm as a Cilk program.\n\n!\nHandout 29: Dynamic Multithreaded Algorithms\nExercise 2-7. Generalize the algorithm from Exercise 2-6 to find arbitrary order statistics. De\nscribe a merge-sorting algorithm with Θ(n lg n) work that achieves a parallelism of Θ(n/ lg n).\n(Hint: Merge many subarrays in parallel.)\nExercise 2-8. The length of a longest-common subsequence of two length-n sequences x and y\ncan be computed in parallel using a divide-and-conquer multithreaded algorithm. Denote by c[i, j]\nthe length of a longest common subsequence of x[1 . . i] and y[1 . . j]. First, the multithreaded\nalgorithm recursively computes c[i, j] for all i in the range 1 ≤ i ≤ n/2 and all j in the range\n1 ≤ j ≤ n/2. Then, it recursively computes c[i, j] for 1 ≤ i ≤ n/2 and n/2 < j ≤ n, while in\nparallel recursively computing c[i, j] for n/2 < i ≤ n and 1 ≤ j ≤ n/2. Finally, it recursively\ncomputes c[i, j] for n/2 < i ≤ n and n/2 < j ≤ n. For the base case, the algorithm computes\nc[i, j] in terms of c[i - 1, j - 1], c[i - 1, j], and c[i, j - 1] in the ordinary way, since the logic of\nthe algorithm guarantees that these three values have already been computed.\nThat is, if the dynamic programming tableau is broken into four pieces\nI\nII\nIII\nIV\n,\nthen the recursive multithreaded code would look something like this:\nI\nspawn II\nspawn III\nsync\nIV\nreturn\nAnalyze the work, critical-path length, and parallelism of this algorithm. Describe and analyze\nan algorithm that is asymptotically as efficient (same work) but more parallel. Make whatever\ninteresting observations you can. Write an efficient Cilk program for the problem.\nReferences\n[1] Selim G. Akl and Nicola Santoro. Optimal parallel merging and sorting without memory\nconflicts. IEEE Transactions on Computers, C-36(11), November 1987.\n[2] M. Akra and L. Bazzi. On the solution of linear recurrence equations. Computational Opti\nmization and Application, 10:195-210, 1998.\n[3] Robert D. Blumofe. Executing Multithreaded Programs Efficiently. PhD thesis, Depart\nment of Electrical Engineering and Computer Science, Massachusetts Institute of Techno\nlogy, September 1995.\n\nHandout 29: Dynamic Multithreaded Algorithms\n[4] Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson,\nKeith H. Randall, and Yuli Zhou. Cilk: An efficient multithreaded runtime system. In\nProceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Paral\nlel Programming (PPoPP), pages 207-216, Santa Barbara, California, July 1995.\n[5] Robert D. Blumofe and Charles E. Leiserson. Scheduling multithreaded computations by\nwork stealing. In Proceedings of the 35th Annual Symposium on Foundations of Computer\nScience (FOCS), pages 356-368, Santa Fe, New Mexico, November 1994.\n[6] Richard P. Brent. The parallel evaluation of general arithmetic expressions. Journal of the\nACM, 21(2):201-206, April 1974.\n[7] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction\nto Algorithms. The MIT Press and McGraw-Hill, second edition, 2001.\n[8] Matteo Frigo, Charles E. Leiserson, and Keith H. Randall. The implementation of the Cilk\n5 multithreaded language. In ACM SIGPLAN '98 Conference on Programming Language\nDesign and Implementation (PLDI), pages 212-223, Montreal, Canada, June 1998.\n[9] R. L. Graham. Bounds on multiprocessing timing anomalies. SIAM Journal on Applied\nMathematics, 17(2):416-429, March 1969.\n[10] Keith H. Randall. Cilk: Efficient Multithreaded Computing. PhD thesis, Department of\nElectrical Engineering and Computer Science, Massachusetts Institute of Technology, May\n1998.\n[11] Supercomputing Technologies Group, MIT Computer Science and Artificial Intelligence\nLaboratory. Cilk 5.3.2 Reference Manual, November 2001."
    },
    {
      "category": "Resource",
      "title": "l12_skiplists.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/c69eacf7b8344572d9ced8efff02f2b3_l12_skiplists.pdf",
      "content": "Introduction to Algorithms\nOctober 25, 2005\nMassachusetts Institute of Technology\n6.046J/18.410J\nProfessors Erik D. Demaine and Charles E. Leiserson\nHandout 17\nLecture Notes on Skip Lists\nLecture 12 -- October 26, 2005\nErik Demaine\nBalanced tree structures we know at this point: red-black trees, B-trees, treaps.\n-\nCould you implement them right now? Probably, with time. . . but without looking up any\n-\ndetails?\nSkip lists are a simple randomized structure you'll never forget.\n-\nStarting from scratch\nInitial goal: just searches -- ignore updates (Insert/Delete) for now\n-\nSimplest data structure: linked list\n-\nSorted linked list: (n) time\n-\n2 sorted linked lists:\n-\n- Each element can appear in 1 or both lists\n- How to speed up search?\n- Idea: Express and local subway lines\n- Example: 14 , 23, 34 , 42 , 50, 59, 66, 72 , 79, 86, 96 , 103, 110, 116, 125\n(What is this sequence?)\n- Boxed values are \"express\" stops; others are normal stops\n- Can quickly jump from express stop to next express stop, or from any stop to next\nnormal stop\n- Represented as two linked lists, one for express stops and one for all stops:\n- Every element is in bottom linked list (L2); some elements also in top linked list (L1)\n- Link equal elements between the two levels\n- To search, first search in L1 until about to go too far, then go down and search in L2\n\n| {z }\nHandout 17: Lecture Notes on Skip Lists\n- Cost:\n- Minimized when\n|L1| + |L2|\n|L1| = |L1| + n\n|L1|\nn\n|L1| = |L1|\n≤ |L1| 2 = n\n≤ |L1| = infn\n≤ search cost = 2infn\n- Resulting 2-level structure:\nsqrt n\nsqrt n\nsqrt n\nsqrt n\nsqrt n\n3 linked lists: 3 infn\n-\n·\nk\nk linked lists: k infn\n-\n·\nlg n\nlg n linked lists: lg n\ninfn = lg n n 1/ lg n = (lg n)\n-\n·\n·\n=2\n- Becomes like a binary tree:\n- (In fact, a level-linked B+-tree; see Problem Set 5.)\n- Example: Search for 72\nLevel 1: 14 too small, 79 too big; go down 14\nLevel 2: 14 too small, 50 too small, 79 too big; go down 50\nLevel 3: 50 too small, 66 too small, 79 too big; go down 66\nLevel 4: 66 too small, 72 spot on\n\nHandout 17: Lecture Notes on Skip Lists\nInsert\nNew element should certainly be added to bottommost level\n-\n(Invariant: Bottommost list contains all elements)\nWhich other lists should it be added to?\n-\n(Is this the entire balance issue all over again?)\nIdea: Flip a coin\n-\n- With what probability should it go to the next level?\n- To mimic a balanced binary tree, we'd like half of the elements to advance to the next-\nto-bottommost level\n- So, when you insert an element, flip a fair coin\n- If heads: add element to next level up, and flip another coin (repeat)\nThus, on average:\n-\n- 1/2 the elements go up 1 level\n- 1/4 the elements go up 2 levels\n- 1/8 the elements go up 3 levels\n- Etc.\nThus, \"approximately even\"\n-\nExample\nGet out a real coin and try an example\n-\nYou should put a special value -∗ at the beginning of each list, and always promote this\n-\nspecial value to the highest level of promotion\nThis forces the leftmost element to be present in every list, which is necessary for searching\n-\n. . . many coins are flipped . . .\n(Isn't this easy?)\nThe result is a skip list.\n-\nIt probably isn't as balanced as the ideal configurations drawn above.\n-\nIt's clearly good on average.\n-\nClaim it's really really good, almost always.\n-\n\nHandout 17: Lecture Notes on Skip Lists\nAnalysis: Claim of With High Probability\nTheorem: With high probability, every search costs O(lg n) in a skip list with n elements\n-\n- What do we need to do to prove this? [Calculate the probability, and show that it's high!]\n- We need to define the notion of \"with high probability\"; this is a powerful technical notion,\nused throughout randomized algorithms\nInformal definition: An event occurs with high probability if, for any\n1, there is an\n-\n→\nappropriate choice of constants for which E occurs with probability at least 1 -O(1/n)\n- In reality, the constant hidden within O(lg n) in the theorem statement actually depends on c.\nPrecise definition: A (parameterized) event E occurs with high probability if, for any\n-\n\n1, E occurs with probability at least 1 - c/n, where c is a \"constant\" depending\n→\nonly on .\nThe term O(1/n) or more precisely c/n is called the error probability\n-\n- The idea is that the error probability can be made very very very small by setting to\nsomething big, e.g., 100\nAnalysis: Warmup\nLemma: With high probability, skip list with n elements has O(lg n) levels\n-\n- (In fact, the number of levels is (log n), but we only need an upper bound.)\nProof:\n-\n- Pr{element x is in more than c lg n levels} = 1/2c lg n = 1/nc\n- Recall Boole's inequality / union bound:\n+ Pr{Ek}\nPr{E1 ≥E2 ≥· · · ≥Ek } Pr{E1} + Pr{E2} + · · ·\n- Applying this inequality:\nPr{any element is in more than c lg n levels} n 1/nc = 1/nc-1\n·\n- Thus, error probability is polynomially small and exponent ( = c -1) can be made\narbitrarily large by appropriate choice of constant in level bound of O(lg n)\n\nHandout 17: Lecture Notes on Skip Lists\nAnalysis: Proof of Theorem\nCool idea: Analyze search backwards--from leaf to root\n-\n- Search starts at leaf (element in bottommost level)\n- At each node visited:\nIf node wasn't promoted higher (got TAILS here), then we go [came from] left\nIf node was promoted higher (got HEADS here), then we go [came from] up\n- Search stops at root of tree\n- Know height is O(lg n) with high probability; say it's c lg n\n- Thus, the number of \"up\" moves is at most c lg n with high probability\n- Thus, search cost is at most the following quantity:\nHow many times do we need to flip a coin to get c lg n heads?\n- Intuitively, (lg n)\nAnalysis: Coin Flipping\nClaim: Number of flips till c lg n heads is (lg n) with high probability\n-\n- Again, constant in (lg n) bound will depend on\nProof of claim:\n-\n- Say we make 10c lg n flips\n- When are there at least c lg n heads?\nc lg n 1 9c lg n\n- Pr{exactly c lg n heads} =\n10c lg n\n!\nc lg n\n· 2\n· 2\n|\n{z\n}\n|\n{z\n} |\n{z\n}\nheads\ntails\norders\nHHHTTT vs. HTHTHT\n9c lg n\n- Pr{at most c lg n heads}\n10c lg n\n! 1\nc lg n\n· 2\n|\n{z\n} |\n{z\n}\ntails\noverestimate\non orders\ny\n- Recall bounds on\n\n:\nx\ny x\n!\ny\ny x\ne\nx\nx\nx\n\nHandout 17: Lecture Notes on Skip Lists\n- Applying this formula to the previous equation:\n\nPr{at most c lg n heads}\n10c lg n\n! 1 9c lg n\nc lg n\ne 10c lg n\n!c lg n 1 9c lg n\n·\n\nc lg n\n· 2\n9c lg n\n= (10e)c lg n\n· 2\n9c lg n\n= 2lg(10e)·c lg n · 2\n= 2\n= 2(lg(10e)-9)c lg n\n- lg n\n=\n1/n\n- The point here is that, as 10 ! ∗, = 9 -lg(10e) ! ∗, independent of (for all) c\n- End of proof of claim and theorem\nAcknowledgments\nThis lecture is based on discussions with Michael Bender at SUNY Stony Brook."
    }
  ]
}