{
  "course_name": "Infinite Random Matrix Theory",
  "course_description": "No description found.",
  "topics": [
    "Mathematics",
    "Algebra and Number Theory",
    "Differential Equations",
    "Linear Algebra",
    "Probability and Statistics",
    "Science",
    "Physics",
    "Theoretical Physics",
    "Mathematics",
    "Algebra and Number Theory",
    "Differential Equations",
    "Linear Algebra",
    "Probability and Statistics",
    "Science",
    "Physics",
    "Theoretical Physics"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nDescription\n\nThis is a course on the mathematics and applications of infinite random matrices. We will learn about the tools such as the Stieltjes transform, and Free Probability used to characterize infinite random matrices. Our emphasis will be on exploring known connections between these tools (such as the combinatorial aspects of free probability) and discovering new connections (such as between multivariate orthogonal polynomials and free cumulants of free probability).\n\nOur aim is to touch upon various branches of the study of infinite random matrices-a consequence is that we will end up lingering on some areas longer than others. Our hope is that this course will confer:\n\nSome familiarity with several of the main thrusts of work in infinite random matrices-sufficient to give you some context for formulating and seeking known solutions to applications in engineering and physics;\n\nSufficient background and facility to let you read current research publications in the area of infinite random matrix theory;\n\nA set of tools, both analytical and computational, for the analysis of new random matrices that arise in new problems you may encounter.\n\nPrerequisites\n\nNo particular prerequisites are needed. We assume that students have had an undergraduate course in Linear Algebra (\n18.06\n) or its equivalent and some exposure to probability (\n6.041\nor\n6.042J\nare more than sufficient). Knowledge of combinatorial theory is a bonus. A familiarity with MATLAB(r) will also be useful.\n\nContent\n\nThe goal for the course is, paradoxically, to be broad as well as deep. Our plan is to touch upon the following broad areas while attempting to uncover deep insights into the underlying mechanisms that unify these areas.\n\nBelow is a tentative list of topics that might be covered in the course; We will select material adaptively based on student background, interests, and rate of progress. If you are interested in some other topics, please let us know and we'd be happy to accommodate your interests.\n\nCombinatorial Aspects:\nUsing combinatorial techniques to derive the limiting distribution of the three classical random matrix ensembles. Path counting and random matrix theory. Generalizations to counting paths on torii.\n\nStieljtes Transform Based Methods:\nThe MarÂ¡cenko-Pastur theorem. Other generalizations. Silverstein's sample covariance matrix. Convergence issues.\n\nFree Probability:\nThe concept of freeness. Free cumulants and non-crossing partitions. The R and S transform. Fluctuations and Second Order Freeness. Combinatorial interpretations.\n\nEquilibrium Measure:\nThe Hermite, Laguerre and Jacobi orthogonal polynomials. Interpretation of the limiting distribution as the equilibrium measure of (univariate) orthogonal polynomials. Applications to physics.\n\nFredholm Determinants:\nTracy-Widom Distribution. Eigenvalue spacings and the Riemann Hypothesis.\n\nJack Polynomials:\nMultivariate orthogonal polynomials. Combinatorial aspects. Connections to random matrices.\n\nApplications:\nWireless Communications, Statistical Physics.\n\nHomework\n\nHomework assignments will be handed out bi-weekly. They will mainly consist of MATLAB(r) based explorations of the material covered in class. You will not need to turn them in, although being able to do them will greatly help your understanding of the material.\n\nMid-Term Project\n\nYou will be asked to read a paper on a topic of interest to you that involves random matrix theory. See the\nproject\nsection for more information.\n\nSemester Project\n\nThe semester project can be an extension of the mid-term project if it sustains your interest. Otherwise, you will be asked to come up with some insights into a random matrix problem that is of interest to you.\n\nSee the\nproject\nsection for more information.\n\nGrading\n\nSince this is an advanced graduate class on a very active research area, the grading will be based on your participation in the class.\n\nTextbooks\n\nThere are no textbooks covering a majority portion of the material we will be studying in this course. Please see the\nreadings\nsection for more information.",
  "files": [
    {
      "category": "Resource",
      "title": "biane_ess.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/e182e2b0d26e4359155f3d51a2f7127f_biane_ess.pdf",
      "content": "Characters\nof\nsymmetric\ngroups\nand\nfree\ncum\nulan\nts\nPhilipp\ne\nBiane\nAbstra\nct\nW\ne\nin\nv\nestigate\nKero\nvs\nform\nula\nexpressing\nthe\nnormalized\nirre\nducible\nc\nharacters\nof\nsymmetric\ngroups\nev\naluated\non\na\ncycle\nin\nterms\nof\nthe\nfree\ncum\nulan\nts\nof\nthe\nasso\nciated\nY\noung\ndiagrams\n\nIn\ntro\nduction\nLet\n\nb\ne\na\nprobabilit\ny\nmeasure\non\nR\nwith\ncompact\nsupp\nort\nIts\nCauc\nh\ny\ntrans\nform\nhas\nthe\nexpansion\nZ\n\nX\n\nM\nk\nz\nk\n\nG\n\nz\n\ndx\n\nz\n\nz\n\nx\nR\nk\n\nwhere\nthe\nM\nk\nare\nthe\nmomen\nts\nof\nthe\nmeasure\n\nThis\nLauren\nt\nseries\nhas\nan\nin\nv\nerse\nfor\ncomp\nosition\nK\nz\n\nwith\nan\nexpansion\n\nX\nR\nk\nz\nk\n\nK\n\nz\n\nz\n\nk\n\nThe\nR\nk\nare\ncalled\nthe\nfree\ncum\nulan\nts\nof\n\nand\ncan\nb\ne\nexpressed\nas\np\nolynomials\nin\nterms\nof\nthe\nmomen\nts\nF\nree\ncum\nulan\nts\nsho\nw\nup\nin\nthe\nasymptotic\nb\neha\nviour\nof\nc\nharacters\nof\nlarge\nsymmetric\ngroups\nMore\nprecisely\n\nl e t\n\nb\ne\na\nY\noung\ndiagram\nto\nwhic\nh\nw\ne\nasso\nciate\na\npiecewise\na ne\nfunction\n\nR\n\nR\nwith\nslop\nes\n\nsuc\nh\nthat\n\nx\n\njxj\nfor\njxj\nlarge\nenough\nas\nin\nFig\n\nb\nelo\nw\nwhic\nh\ncorresp\nonds\nto\nthe\npartition\n\nAlternativ\nely\nw\ne\ncan\nenco\nde\nthe\nY\noung\ndiagram\nusing\nthe\nlo\ncal\nminima\nand\nlo\ncal\nmaxima\nof\nthe\nfunction\n\ndenoted\nb\ny\nx\n\nx\nm\nand\ny\n\ny\nm\nresp\nectiv\nely\n\nwhic\nh\nf o r m\nt\nw\no\ni n\nterlacing\nsequences\nof\nin\ntegers\nThese\n\nMathematics\nSubje\nct\nClassic\nation\nPrimary\n\nSecondary\n\nPHILIPPE\nBIANE\nare\n\nand\n\nresp\nectiv\nely\nin\nthe\npicture\nx\n\ny\n\nx\n\ny\n\nx\n\ny\n\nx\n\nF\nig\n\nAsso\nciated\nwith\nthe\nY\noung\ndiagram\nthere\nis\na\nunique\nprobabilit\ny\nmeasure\n\non\nthe\nreal\nline\nsuc\nh\nt h a t\nZ\nQ\nm\n\ni\nz\n\ny\ni\n\ndx\n\nQ\nm\nfor\nall\nz\n\nC\nn\nR\nz\n\nx\nR\ni\nz\n\nx\ni\n\nThis\nprobabilit\ny\nmeasure\nis\nsupp\norted\nb\ny\nthe\nset\nfx\n\nx\nk\ng\nand\nis\ncalled\nthe\ntransition\nmeasure\nof\nthe\ndiagram\nsee\nK\nW\ne\nshall\ndenote\nb\ny\nR\nj\n\nits\nfree\ncum\nulan\nts\nLet\n\nS\nn\nb\ne\na\np\nerm\nutation\nwith\nk\n\ncycles\nof\nlength\n\nk\n\nof\nlength\n\nP\n\netc\nW\ne\nshall\nk\neep\nk\n\nk\n\nxed\nand\ndenote\nr\n\nj\n\nj\nk\nj\n\nwhile\nw\ne\nlet\nn\n\nThe\nnormalized\nc\nharacter\n\nasso\nciated\nto\na\nY\noung\ndiagram\nwith\nn\ncells\nhas\nthe\nfollo\nwing\nasymptotic\nev\naluation\nfrom\nB\n\nY\nr\n+1\nk\nj\n\nR\nj\n\nn\nr\n\nO\nn\n\nj\n\nHere\nthe\nO\nterm\nis\nuniform\no\nv\ner\nall\nY\noung\ndiagrams\nwhose\nn\num\nb\ners\nof\nro\nws\nand\ncolumns\nare\n\nA\np\nn\nfor\nsome\nconstan\nt\nA\nand\nall\np\nerm\nutations\nwith\nr\n\nr\n\nfor\nsome\nr\n\nAs\nremark\ned\nb\ny\nS\nKero\nv\nK\n\nfree\ncum\nulan\nts\ncan\nb\ne\nused\nto\nget\nuniv\nersal\nexact\nform\nulas\nfor\nc\nharacter\nv\nalues\nMore\nprecisely\nconsider\nthe\nfollo\nwing\nquan\ntities\n\nk\n\nnn\n\nn\n\nk\n\nc\nk\n\nfor\nk\n\nwhere\nc\nk\nis\na\ncycle\nof\norder\nk\nwith\nc\n\ne\nTheorem\n\nKero\nvs\nform\nula\nfor\nc\nharacters\nTher\ne\nexist\nuniversal\np\nolyno\nmials\nK\n\nK\n\nK\nm\n\nwith\ninte\nger\nc\no\necients\nsuch\nthat\nthe\nfol\nlowing\nidenti\nties\nhold\nfor\nany\nn\nand\nany\nY\noung\ndiagr\nam\n\nwith\nn\nc\nel\nls\n\nk\n\nK\nk\nR\n\nR\n\nR\nk\n\nW\ne\nlist\nthe\nfew\nrst\nsuc\nh\np\nolynomials\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\n\nThe\nco\ne cien\nts\nof\nKero\nvs\np\nolynomials\nseem\nto\nha\nv\ne\nsome\nin\nteresting\ncom\nbinatorial\nsignicance\nalthough\nthe\nsituation\nis\nfar\nfrom\nb\neing\nundersto\no\nd\nIn\nthis\npap\ner\nw\ne\nshall\ngiv\ne\na\npro\nof\nof\nthe\nab\no\nv\ne\ntheorem\ncompute\nsome\nof\nthe\nco\ne cien\nts\nin\nthe\nform\nula\nas\nw\nell\nas\ngiv\ne\nsome\ninsigh\nt\ni n\nto\nthis\nproblem\nThis\npap\ner\nis\norganized\nas\nfollo\nws\nIn\nSection\n\nw\ne\ngather\nsome\ninformation\non\nfree\ncum\nulan\nts\nBo\nolean\ncum\nulan\nts\nand\ntheir\ncom\nbinatorial\nsignicance\nIn\nSection\n\nw\ne\ni n\ntro\nduce\nsome\nelemen\nts\nin\nthe\ncen\nter\nof\nthe\nsymmetric\ngroup\nalgebra\nThese\nare\nused\nin\nSection\n\nto\ngiv\ne\na\ncom\nbinatorial\npro\nof\nof\nTheorem\n\nIn\nSection\n\nw\ne\ngiv\ne\nanother\npro\nof\nbased\non\na\nform\nula\nof\nF\nrob\nenius\nwhic\nh\nyields\na\ncomputationally\ne cien\nt\nform\nula\nfor\ncomputing\nKero\nvs\np\nolynomials\nIn\nSection\n\nw\ne\ncompute\nthe\nco\ne cien\nts\nof\nthe\nlinear\nterms\nof\nKero\nvs\np\nolynomials\nas\nw\nell\nas\nsome\nco\ne cien\nts\nof\ndegree\n\nW\ne\nmak\ne\nsome\nremarks\nin\nSection\n\non\nthe\np\nossible\ncom\nbinatorial\nsignicance\nof\nthe\nco\ne cien\nts\nof\nKero\nvs\np\nolynomials\nThis\nin\nv\nolv\nes\nin\na\nnatural\nw\na\ny\nthe\nCa\nyley\ngraph\nof\nthe\nsymmetric\ngroup\nFinally\nin\nSection\n\nw\ne\nlist\nthe\nv\nalues\nof\nKero\nv\np\nolynomials\nup\nto\n\nI\nw\nould\nlik\ne\nto\nthank\nA\nOk\nounk\no\nv\nand\nR\nStanley\nfor\nuseful\ncomm\nunication\nas\nw\nell\nas\nG\nOlshanski\nfor\npro\nviding\nme\na\ncop\ny\no f\nIO\n\nNoncrossing\npartitions\nmomen\nts\nand\nfree\ncum\nulan\nts\nF\nrom\nthe\nrelation\nb\net\nw\neen\nmomen\nts\nand\ncum\nulan\nts\ngiv\nen\nb\ny\n\nG\n\nK\nhi\n\nw\ne\nobtain\nb\ny\nLagrange\nin\nv\nersion\nform\nula\nthat\n\nG\n\nz\n\nk\n\nz\nR\nk\n\nk\n\nwhere\nz\n\nLz\n\ndenotes\nthe\nco\ne cien\nt\no f\nz\n\nin\nthe\nexpansion\nof\na\nLauren\nt\nseries\nLz\n\nF\nrom\nthis\nw\ne\nget\nthat\nthe\nco\ne cien\nt\no f\nM\nl\n\nM\nl\nr\nin\nR\nk\nis\nequal\nto\n\nr\nP\n\nl\ni\n\nl\nl\nr\nk\n\ni\n\nl\n\nl\nr\nk\n\nP\nif\nk\n\nj\nl\nj\n\nand\nto\n\nif\nnot\nj\nCon\nv\nersely\none\nhas\n\nK\nz\n\nk\n\nM\nk\n\nz\nk\n\nP\nand\nthe\nco\ne cien\nt\no f\nR\nl\n\nR\nl\nr\nin\nM\nk\n\nwith\nk\n\ni\nil\ni\nis\nequal\nto\n\nr\nk\n\nP\nl\n\nl\nr\nk\n\nl\ni\n\ni\nIt\nwill\nb\ne\nalso\nin\nteresting\nto\nin\ntro\nduce\nthe\nseries\n\nX\nH\n\nz\n\nG\n\nz\n\nz\n\nB\nk\nz\nk\nk\n\nThe\nco\ne cien\nts\nB\nk\nin\nthis\nform\nula\nare\ncalled\nBo\nolean\ncum\nulan\nts\nSW\nand\nthe\nP\nco\ne cien\nt\nfor\nB\nl\n\nB\nl\nr\nin\nM\nk\n\nw ith\nj\nj\nl\nj\n\nk\nis\nthe\nm\nultinomial\nco\ne cien\nt\n\nr\nl\n\nl\n\nl\nr\n\nl\n\nl\n\nl\nr\n\nA\nc o m\nbinatorial\nin\nterpretation\nof\nthese\nform\nulas\nis\naorded\nb\ny\nR\nS p\ne i c\nhers\nw\nork\nSp\nwhic\nh\nw\ne\nr e c a l l\nn o\nw\nA\nnoncrossing\npartition\nof\nf\n\nk\ng\nis\na\npartition\nsuc\nh\n\nPHILIPPE\nBIANE\nthat\nthere\nare\nno\na\nb\nc\nd\nwith\na\n\nb\n\nc\n\nd\na\nand\nc\nb\nelong\nto\nsome\nblo\nc\nk\no f\nt h e\npartition\nand\nc\nd\nb\nelong\nto\nsome\nother\nblo\nc\nk\nThe\nnoncrossing\npartitions\nform\na\nrank\ned\nlattice\nwhic\nh\nwill\nb\ne\ndenoted\nb\ny\nN\nC\nk\n\nW\ne\nshall\nuse\nthe\norder\nopp\nosite\nto\nthe\nrenemen\nt\norder\nso\nthat\nthe\nrank\nof\na\nnoncrossing\npartition\nis\nk\n\nn\num\nb\ne r\nof\nparts\nThe\nrelation\nb\net\nw\neen\nmomen\nts\nand\nfree\ncum\nulan\nts\nno\nw\nr e a d s\nX\n\nM\nk\n\nR\n\nN\nC\n\nk\n\nwhere\nfor\na\nnoncrossing\npartition\n\nr\n\none\nhas\nR\n\nQ\ni\nR\nj\ni\nj\n\nwhere\nj\ni\nj\nis\nthe\nn\num\nb\ner\nof\nelemen\nts\nof\nthe\npart\n\ni\n\nIt\nfollo\nws\nfrom\n\nthat\nthe\nP\nco\ne cien\nt\no f\nR\nl\n\nR\nl\nr\nin\nthe\nexpression\nof\nM\nk\nwith\nk\n\nil\ni\n\nis\nequal\nto\nthe\n\nr\nn\num\nb\ner\nof\nnoncrossing\npartitions\nin\nN\nC\nk\n\nw ith\nl\ni\nparts\nof\ni\nelemen\nts\nand\nis\ngiv\nen\nb\ny\n\nA\nparallel\ndev\nelopmen\nt\nc a n\nb\ne\nmade\nfor\nthe\nconnection\nb\ne t\nw\neen\nBo\nolean\ncu\nm\nulan\nts\nand\nmomen\nts\nA\npartition\nof\nf\n\nk\ng\nis\ncalled\nan\nin\nterv\nal\npartition\nif\nits\nparts\nare\nin\nterv\nals\nThe\nin\nterv\nal\npartitions\nform\na\nlattice\nB\nk\n\nwhic\nh\nis\nisomorphic\nto\nthe\nlattice\nof\nall\nsubsets\nof\nf\n\nk\ng\nassign\nto\nan\nin\nterv\nal\npartition\nthe\ncom\nplemen\nt\ni n\nf\n\nk\ng\nof\nthe\nset\nof\nlargest\nelemen\nts\nin\nthe\nparts\nof\nthe\npartition\nThe\nform\nula\nfor\nexpressing\nthe\nM\nk\nin\nterms\nof\nthe\nB\nk\nis\nX\n\nM\nk\n\nB\n\nB\n\nk\n\nOn\ncen\ntral\nelemen\nts\nin\nthe\ngroup\nalgebra\nof\nthe\nsymmetric\ngroup\nLet\n\nb\ne\na\nY\noung\ndiagram\nand\nfor\nn\n\nj j\nlet\n\nb\ne\na\none\nto\none\nmap\nfrom\nthe\ncells\nof\n\nto\nthe\nset\nf\n\nn g\nConsider\nthe\nasso\nciated\np\nerm\nutation\n\nwhose\ncycles\nare\ngiv\nen\nb\ny\nthe\nro\nws\nof\nthe\nmap\n\nF\nor\nexample\nthe\nfollo\nwing\nmap\nwith\nn\n\ngiv\nes\nthe\np\nerm\nutation\nwith\ncycle\ndecomp\nosition\n\n14 24 1\n\n22 13\n\nF\nig\n\nIf\n\nis\nthe\nset\nof\nsuc\nh\nmaps\ndened\non\n\nw\ne\nshall\ncall\na\nn\nthe\nelemen\nt\nin\nthe\ngroup\nalgebra\nof\nS\nn\ngiv\nen\nb\ny\nX\na\nn\n\nsee\nK\nO\nIf\n\nhas\none\nro\nw\nof\nlength\nl\n\nw\ne\ncall\na\nln\nthe\ncorresp\nonding\nelemen\nt\nNote\nthat\na\nn\n\nne\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\n\nLemma\n\nTher\ne\nexists\nuniversal\np\nolynomials\nP\n\nwith\ninte\nger\nc\no\necients\nsuch\nthat\nfor\nal\nl\nn\none\nhas\na\nn\n\nP\n\na\nn\n\na\njjn\n\nP\nand\nj\nj\ndeg\nP\n\na\nj\nn\n\nj j\nThe\npro\nof\nis\nb\ny\ninduction\non\nthe\nn\num\nb\ner\nof\ncells\nof\n\nThis\nis\nclear\nb\ny\ndenition\nif\n\nhas\none\nro\nw\nIf\n\nhas\nmore\nthan\none\nro\nw\nth en\nlet\n\nb\ne\n\nwith\nthe\nlast\nro\nw\ndeleted\nand\nlet\nk\nb\ne\nthe\nlength\nof\nthis\nro\nw\nOne\nhas\nX\na\n\nn\na\nk\nn\n\nwhere\n\nis\na\nmap\non\nthe\ndiagram\n\nand\n\na\nmap\non\nthe\ndiagram\nk\n\nwith\none\nro\nw\nof\nlength\nk\n\nF\nor\nan\ny\npair\n\nthere\nis\na\nunique\npair\nA\nB\nwhere\nA\nis\na\nsubset\nof\ncells\nof\n\nB\nis\na\nsubset\nof\ncells\nof\nk\n\nand\na\nbijection\n\nfrom\nA\nto\nB\nwhic\nh\ntells\non\nwhic\nh\ncells\nthe\nt\nw\no\nm a p s\n\nand\n\ncoincide\nThe\ncycle\nstructure\nof\n\ndep\nends\nonly\non\n\nk\n\nA\nB\n\nand\nnot\non\nthe\nv\nalues\ntak\nen\nb\ny\nthe\nmaps\n\nLet\n\nk\nAB\n\nb\ne\nthe\ndiagram\nwith\njj\n\nj Aj\nb\no\nxes\nputting\nsome\noneb\no\nx\nro\nws\nif\nnecessary\nof\nthis\nconjugacy\nclass\nF\nor\neac\nh\nA\nB\n\ntak\ne\nsome\ncorresp\nonding\n\nand\ntak\ne\na\nmap\non\nthe\ndiagram\n\nk\nAB\n\nw h i c\nh\nrealizes\nthe\np\nerm\nutation\n\nIf\nnecessary\nput\nthe\nxed\np\noin\nts\nin\nthe\noneb\no\nx\nr o\nws\nNo\nw\nextend\nthis\nto\nall\npairs\nof\nmaps\n\nc o\nv\narian\ntly\nwith\nresp\nect\nto\nthe\naction\nof\nS\nn\n\nEac\nh\nmap\non\n\nk\nAB\n\nis\nobtained\nexactly\nonce\nand\nif\nA\n\nB\n\nthen\nclearly\n\nk\nAB\n\nIt\nfollo\nws\nthat\nX\n\nn\na\n\nn\na\nk\nn\n\na\nn\n\na\n\nAB\n\nAB\n\njAj\nF\nor\nall\nterms\nin\nthe\nsum\none\nhas\nj\n\nAB\n\nj\n\njj\nThe\npro\nof\nfollo\nws\nb\ny\ninduction\nThe\ncondition\non\ndegrees\nis\nc\nhec\nk\ned\nalso\nb\ny\ninduction\n\nJucysMurph\ny\nelemen\nts\nand\nKero\nvs\nform\nula\nConsider\nthe\nsymmetric\ngroup\nS\nn\nacting\non\nf\n\nn g\nand\nlet\n\nb\ne\na\nnew\nsym\nb\nol\nW\ne\nim\nb\ned\nS\nn\nin\nto\nS\nn\nacting\non\nf\n\nn g\n\nfg\nIn\nthe\ngroup\nalgebra\nC\nS\nn\n\nconsider\nthe\nJucysMurph\ny\nelemen\nt\nJ\nn\n\nn\n\nwhere\ni\nj\n\ndenotes\nthe\ntransp\nosition\nexc\nhanging\ni\nand\nj\n\nLet\nE\nn\ndenote\nthe\northog\nonal\npro\njection\nfrom\nC\nS\nn\n\non\nto\nC\nS\nn\n\nie\nE\nn\n\nif\n\nS\nn\nand\nE\nn\n\nif\nnot\nIf\nw\ne\nendo\nw\nC\nS\nn\n\nwith\nits\ncanonical\ntrace\n\ne\nie\n\nis\nthe\nlinear\nextension\nof\nthe\nnormalized\nc\nharacter\nof\nthe\nregular\nrepresen\ntation\nthen\nE\nn\nis\nthe\nconditional\nexp\nectation\non\nto\nC\nS\nn\n\nwith\nresp\nect\nto\n\nW\ne\ndene\nthe\nmomen\nts\nof\nthe\nJucysMurp\ny\nelemen\nts\nb\ny\n\nM\nk\n\nE\nn\nJ\nk\nn\n\nT\no\nthis\nsequence\nof\nmomen\nts\nw\ne\ncan\nasso\nciate\na\nsequence\nof\nfree\ncum\nulan\nts\nthrough\nthe\nconstruction\nof\nsection\n\nW\ne\nc a l l\nR\nk\nthese\nfree\ncum\nulan\nts\nBy\nconstruction\nthe\nM\nk\nand\nR\nk\nb\nelong\nto\nthe\ncen\nter\nof\nthe\ngroup\nalgebra\nC\nS\nn\n\nev\nen\nto\nZ\nS\nn\n\nThe\nrelev\nance\nof\nthese\nmomen\nts\nand\ncum\nulan\nts\nis\nthe\nfollo\nwing\nLemma\n\nF\nor\nany\nn\nand\nany\nY\noung\ndiagr\nam\n\nwith\nn\nb\noxes\none\nhas\n\nR\nk\n\nR\nk\n\nPHILIPPE\nBIANE\nSince\n\nis\nan\nirreducible\nc\nharacter\nit\nis\nm\nultiplicativ\ne\non\nthe\ncen\nter\nof\nthe\nsymmetric\ngroup\nalgebra\nand\ntherefore\nit\nis\nenough\nto\nc\nhec\nk\nt h a t\n\nM\nk\n\nM\nk\n\nLet\n\nb\ne\nthe\ninduced\nc\nharacter\non\nS\nn\n\nthen\n\nM\nk\n\nn\n\nand\nthe\nresult\n\nJ\nk\n\nfollo\nws\nfrom\nthe\ncomputation\nof\neigen\nv\nalues\nof\nJucysMurph\ny\nelemen\nts\nSee\neg\nB\nSection\n\nOne\nhas\nX\n\nJ\nk\n\ni\n\ni\nk\n\nn\ni\n\ni\nk\nf\nng\nA\nterm\nin\nthis\nsum\ngiv\nes\na\nnon\ntrivial\ncon\ntribution\nto\nM\nk\nif\nand\nonly\nif\nthe\np\ner\nm\nutation\n\ni\n\ni\nk\n\nxes\n\nIn\norder\nto\nsee\nwhen\nthis\nhapp\nens\nw\ne\nha\nv\ne\nto\nfollo\nw\nthe\nimages\nof\n\nb\ny\nthe\nsuccessiv\ne\npartial\npro\nducts\nof\ntransp\nositions\nLet\nj\n\nsup fl\n\nk\nj\ni\nl\n\ni\nk\ng\nIf\nthis\nset\nis\nempt\ny\nthen\n\ni\nk\n\nIf\nnot\nthen\none\nhas\n\ni\n\ni\nj\n\nwhere\n\nhence\nw\ne\ncan\ncon\ntin\nue\nand\nlo\nok\nfor\nj\n\nsupfl\n\nj\n\nj\ni\nl\n\ni\nj\n\ng\nIn\nthis\nw\na\ny\nw\ne\nconstruct\na\nsequence\nj\n\nj\n\nIf\nand\nonly\nif\nthe\nlast\nterm\nof\nthis\nsequence\nis\n\nthen\nw\ne\nget\na\nnon\ntrivial\ncon\ntribu\ntion\nLet\n\nb\ne\nthe\npartition\nof\n\nk\nsuc\nh\nthat\nl\nand\nm\nb\nelong\nto\nthe\nsame\npart\nif\nand\nonly\nif\ni\nl\n\ni\nm\n\nThe\nfact\nthat\n\ni\n\ni\nk\n\nxes\n\ndep\nends\nonly\non\nthis\npartition\nand\nw\ne\ncall\nadmissible\npartitions\nthe\nones\nfor\nwhic\nh\n\ni\n\ni\nk\n\nxes\n\nF\nurthermore\nthe\nconjugacy\nclass\nin\nS\nn\n\nof\n\ni\n\ni\nk\n\ndep\nends\nonly\non\nthe\npartition\nLet\n\nb\ne\nt h e\nY\noung\ndiagram\nformed\nwith\nthe\nnon\ntrivial\ncycles\nof\nthis\nconjugacy\nclass\nLet\nX\nZ\n\ni\n\ni\nk\n\ni\n\ni\nk\n\nwhere\ni\n\ni\nk\n\nmeans\nthat\nthe\npartition\nasso\nciated\nto\nthe\nsequence\ni\n\ni\nk\nis\n\nthen\nw\ne\nha\nv\ne\nX\nM\nk\n\nZ\n\nadmissible\nLet\nc\n\nb\ne\nthe\nn\num\nb\ner\nof\nparts\nof\n\nthen\nthe\nn\num\nb\ner\nof\nk\ntuples\ni\n\ni\nk\n\nis\nequal\nto\nn\nc\n\nwhere\nas\nusual\nn\nk\n\nnn\n\nn\n\nk\n\nand\none\nhas\nj\nj\n\nc\n\ntherefore\none\nhas\nn\nc\n\nZ\n\nn\njj\na\n\nn\n\nn\nj j\n\nn\n\nc\n\na\n\nn\nIn\norder\nthat\n\nb\ne\na\ncycle\nof\nlength\nk\n\nit\nis\nnecessary\nan\nsu cien\nt\nthat\n\nb\ne\nthe\npartition\nf\nk\ng\nfg\nfg\n\nfk\n\ng\nAll\nother\nadmissible\npartitions\nha\nv\ne\nc\n\nk\n\nW\ne\ndeduce\nthat\nX\nM\nk\n\na\nk\nn\n\nZ\n\nadmissible\n\nc\n\nk\n\nIt\nfollo\nws\nfrom\nSection\n\nthat\nM\nk\nis\na\np\nolynomial\nwith\nin\nteger\nco\ne cien\nts\ninde\np\nenden\nt\no f\nn\nin\nthe\na\nj\nn\n\nof\nthe\nform\na\nk\nn\n\np\nolynomial\nin\na\nj\nn\n\nj\n\nk\n\nW\ne\nc a n\nt h\nus\nin\nv\nert\nthis\np\nolynomial\nrelation\nand\nget\na\nk\nn\n\nM\nk\n\np\nolynomial\nin\nM\nj\n\nj\n\nk\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\nwith\np\nolynomial\nwith\nin\nteger\nco\ne cien\nts\nSince\nM\nk\ncan\nb\ne\nexpanded\nas\np\nolyno\nmials\nwith\nin\nteger\nco\ne cien\nts\nin\nthe\nR\nj\nw\ne\nth\nus\nha\nv\ne\na\nk\nn\n\nR\nk\n\np\nolynomial\nin\nR\nj\n\nj\n\nk\n\nApplying\n\nto\nb\noth\nsides\nof\nthis\nequation\nand\nusing\nLemma\n\nw\ne\nobtain\nTheorem\n\nF\nrob\nenius\nform\nula\nand\nfree\ncum\nulan\nts\nLet\n\nb\ne\na\npartition\nof\nn\nwith\n\nand\ni\n\ni\n\nn\ni\nLet\nY\nz\n\nz\n\ni\n\nthen\nthe\nv\nalue\nof\nthe\nnormalized\nc\nharacter\n\non\na\ncycle\nof\nlength\nk\nis\ngiv\nen\nb\ny\nF\nrob\nenius\nform\nula\n\nn\nk\n\nc\nk\n\nz\n\nz\nz\n\nz\n\nk\n\nz\n\nk\nz\n\nk\nSee\nM\nI\nExample\n\npages\n\nb\new\nare\nthat\nc\nharacters\nare\nnot\nnormalized\nin\nMacdonalds\nb\no\nok\nNo\nw\nw\ne\nremark\nthat\nz\nz\n\nz\n\nG\n\nz\n\nn\n\nH\n\nz\n\nn\n\ntherefore\n\nn\nk\n\nc\nk\n\nz\n\nH\n\nz\n\nn\n\nH\n\nz\n\nn\n\nk\n\nk\nUsing\nthe\nin\nv\nariance\nof\nthe\nresidue\nunder\ntranslation\nof\nthe\nv\nariable\none\ngets\n\nn\nk\n\nc\nk\n\nz\n\nH\n\nz\n\nH\n\nz\n\nk\n\nk\nComparing\nwith\n\nw\ne\ndeduce\nthe\nfollo\nwing\nform\nula\nfor\nKero\nvs\np\nolynomials\nTheorem\n\nConsider\nthe\nformal\np\nower\nseries\n\nX\nB\nj\nz\nj\n\nH\nz\n\nz\n\nj\n\nDene\n\nk\n\nz\n\nH\n\nz\n\nH\n\nz\n\nk\n\nk\nand\n\nH\n\nz\n\nk\nR\nk\n\nz\nk\nthen\nthe\nexpr\nession\nof\n\nk\nin\nterms\nof\nthe\nR\nk\n\ns\nis\ngiven\nby\nKer\novs\np\nolynomials\nThis\nform\nula\nfor\ncomputing\nKero\nvs\np\nolynomials\nw\nas\nsho\nwn\nto\nme\nb\ny\nA\nOk\nounk\no\nv\nO\nIt\nseems\nplausible\nthat\nS\nKero\nv\nw\nas\na\nw\nare\nof\nthis\nsee\nesp\necially\nthe\naccoun\nt\no f\nK e r o\nvs\ncen\ntral\nlimit\ntheorem\nin\nIO\nIt\nis\nm\nuc\nh\neasier\nto\nimplemen\nt\nthan\nthe\nalgorithm\ngiv\nen\nb\ny\nthe\npro\nof\nin\nSection\n\nW\ne\ngiv\ne\nthe\nresult\nof\nsome\nMaple\ncomputations\nin\nSection\n\nPHILIPPE\nBIANE\n\nComputation\nof\nsome\nco\ne\ncien\nts\nof\nKero\nvs\np\nolynomials\nP\nP\nF\nor\na\nterm\nR\nk\n\nR\nk\nr\ndene\nits\nde\ngr\ne\ne\nb\ny\nj\nk\nj\nand\nits\nweight\nis\nj\nk\nj\n\nIt\n\nr\nj\nis\nclear\nfrom\nsign\nconsiderations\nthat\nin\nthe\nexpansion\nof\n\nk\nonly\nterms\nof\nw\neigh\nt\nha\nving\nthe\nopp\nosite\nparit\ny\no f\nk\no\nccur\nThe\nterm\nof\nhighest\nw\neigh\nt\ni s\nR\nk\n\nand\nit\nis\nthe\nonly\nterm\nwith\nthis\nw\neigh\nt\nas\nfollo\nws\nfrom\nTheorem\n\nW\ne\nshall\nrst\nb\ne\nin\nterested\nin\nthe\nterms\nof\ndegree\none\nTheorem\n\nThe\nc\no\necient\nof\nR\nk\nl\nin\n\nk\nis\ne\nqual\nto\nthe\nnumb\ner\nof\ncycles\nc\n\nS\nk\n\nof\nlength\nk\n\nsuch\nthat\n\nk\n\nc\nhas\nk\n\nl\ncycles\nIn\norder\nto\npro\nv\ne\nthe\ntheorem\nw\ne\nshall\ncompute\nthe\ngenerating\nfunction\nfor\nthe\nlinear\nco\ne cien\nts\nusing\nTheorem\n\nform\nula\nSince\nw\ne\nare\nin\nterested\nonly\nin\nlinear\nterms\nw\ne\nsee\nthat\nthe\nform\nula\nexpressing\n\nk\nin\nterms\nof\nR\nj\nis\nthe\nsame\nas\nthe\none\nin\nterms\nof\nB\nj\n\nPut\nB\ni\n\ntx\ni\n\nW\ne\nshall\nnd\nthe\nco\ne cien\nt\nof\nz\n\nin\nH\nz\nH\nz\n\nH\nz\n\nk\n\nk\neeping\nonly\nthe\nterms\nwith\ndegree\none\nin\nt\nOne\nhas\nH\nz\n\nz\n\ntxz\n\nx\ntherefore\nk\n\nt\nH\nz\nH\nz\n\nH\nz\n\nk\n\nx\nX\nz\nz\n\nz\n\nk\n\nz\n\nk\nz\n\nx\n\nj\n\nj\n\nUsing\nagain\nin\nv\nariance\nof\nresidue\nb\ny\ntranslation\none\nobtains\nk\n\nk\n\nk\n\nX\n\nX\nY\n\nX\n\nx\nl\nR\nk\nl\n\nk\n\nx\n\nj\n\nl\n\nQ\nk\nx\n\nl\n\nk\nk\nl\nj\n\nl\nl\nwhere\nQ\nk\nx\n\nxx\n\nx\n\nk\n\nDenote\nb\ny\nd\n\nthe\ndimension\nof\nthe\nirreducible\nrepresen\ntation\nwith\nY\noung\ndia\ngram\n\nLemma\n\nL\net\n\nb\ne\na\nY\noung\ndiagr\nam\nwith\nk\nc\nel\nls\nlet\nX\nP\n\nx\n\nx\n\nc\n\nb\ne\nits\nc\nontent\np\nolynomial\nand\nc\n\nnumb\ner\nof\ncycles\nof\n\nthen\nX\nd\n\nx\nl\n\nP\n\nx\n\nS\nk\nSee\nM\n\nI\nExample\n\nI\nExample\n\nand\n\nLet\nc\nk\nb\ne\nthe\ncycle\n\nk\n\nb\ny\nthe\northogonalit\ny\nrelations\nfor\nc\nharacters\nand\nLemma\n\none\nhas\nX\nX\n\nd\n\nc\nk\nP\n\nxP\n\ny\n\nx\nl\n\n;1\nc\nk\n\ny\nl\n\nk\n\nS\nk\nLet\nus\ncompute\nthe\nco\ne cien\nt\nof\ny\nin\nthe\nleft\nhand\nside\nof\n\nOnly\nho\nok\ndiagrams\n\nk\n\nl\n\nl\n\nfor\nl\n\nk\n\ncon\ntribute\nand\nfor\nsuc\nh\na\ndiagram\n\nd\n\nc\nk\n\nk\n\nl\n\nOne\nhas\nP\n\nx\n\nQx\n\nl\n\nthe\nco\ne cien\nt\no f\ny\nin\n\nP\n\ny\n\nl\nk\n\nis\n\nk\n\nand\nP\n\nx\n\nQx\n\nl\n\ntherefore\nw\ne\nn d\nf o r m\nula\n\nfor\nthe\nleft\nhand\nk\nl\nside\nComparing\nwith\nthe\nrigh\nt\nhand\nside\nw\ne\nget\nTheorem\n\nTheorem\n\nhas\nalso\nb\ne e n\npro\nv\ned\nb\ny\nR\nStanley\nSt\nb\ny\na\nclosely\nrelated\nmetho\nd\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\n\nTheorem\n\nThe\nc\no\necient\nof\nR\nk\n\nR\n\nin\n\nk\nfor\nk\n\nis\nk\n\nk\nk\n\nk\n\nAgain\nthis\nfollo\nws\nfrom\nTheorem\n\nthrough\nsome\nlength\ny\n\nbut\nstraigh\ntforw\nard\ncomputations\nwhic\nh\nare\nomitted\nMore\ngenerally\n\nbased\non\nn\numerical\nin\nv\nestigations\nw\ne\nconjecture\nthe\nfollo\nwing\nform\nula\nfor\nterms\nof\nw\neigh\nt\nk\n\nConjecture\n\nThe\nc\no\necient\nof\nR\nl\n\nR\nl\ns\nin\n\nk\n\nwith\nk\n\nl\n\nl\n\ns\n\nsl\ns\n\nis\ne\nqual\nto\ns\nY\nk\n\nk\nk\n\nl\n\nl\ns\n\nj\n\nl\nj\n\nl\n\nl\ns\n\nj\n\nThe\nv\nalidit\ny\nof\nthis\nconjecture\nhas\nb\neen\nc\nhec\nk\ned\nup\nto\nk\n\nA\npro\nof\nfor\nthe\nother\ncases\nat\nleast\nfor\ndegree\nt\nw\no\nterms\ncan\npresumably\nb\ne\ngiv\nen\nusing\nTheorem\n\nbut\nthe\ncomputations\nb\necome\nquic\nkly\nv\nery\nin\nv\nolv\ned\nNo\nsuc\nh\nsimple\npro\nduct\nform\nula\nseems\nto\nb\ne\na\nv\nailable\nfor\nthe\ngeneral\nterm\nAnother\nnatural\nconjecture\nis\nthat\nall\nco\ne cien\nts\nin\nKero\nvs\nform\nula\nare\nnon\nnegativ\ne\ni n\ntegers\nwhic\nh\nalso\nhas\nb\neen\nc\nhec\nk\ned\nup\nto\nk\n\nSee\nthe\nnext\nSection\nfor\nmore\non\nthis\n\nConnection\nwith\nthe\nCa\nyley\ngraph\nof\nsymmetric\ngroup\n\nLet\nus\nexplore\nmore\nthoroughly\nthe\nconnections\nb\net\nw\neen\nthe\nM\nk\n\nB\nk\n\nR\nk\nand\nk\n\nF\norm\nulas\n\nand\n\npro\nvide\na\nnatural\ncom\nbinatorial\nmo\ndel\nfor\nexpressing\nmomen\nts\nin\nterms\nof\nfree\nor\nBo\nolean\ncum\nulan\nts\nW\ne\nwill\nb\ne\nlo\noking\nfor\nsimilar\nmo\ndels\nfor\nexpressing\nthe\nother\nconnections\nObserv\ne\nrst\nthat\nfor\nall\nmeasures\nasso\nciated\nwith\nY\noung\ndiagrams\none\nhas\nM\n\nB\n\nR\n\nW\ne\nwill\nrestrict\nourselv\nes\nto\nthis\ncase\nin\nthe\nfollo\nwing\nLet\nus\napply\nKero\nvs\nform\nula\nto\nthe\ntrivial\nc\nharacter\nAs\nw\ne\nshall\nsee\nthis\nwill\ngiv\ne\na\nlot\nof\ninformation\nThe\nprobabilit\ny\nmeasure\nasso\nciated\nwith\nthe\ntrivial\nc\nharacter\nis\nn\n\nn\nwith\nCauc\nh\ny\ntransform\nn\nn\nz\n\nn\n\nGz\n\nz\n\nz\n\nn\nThe\ncorresp\nonding\nmomen\nts\nare\nX\nn\n\nM\nk\n\nk\n\nn\nk\n\nn\nn\nk\n\nk\n\nk\n\nk\n\nn\nj\nn\n\nn\n\nn\n\nj\n\nW\ne\nwill\nnd\nit\nuseful\nto\nin\nterpret\nthis\nas\nthe\ngenerating\nfunction\nfor\nthe\nrank\nin\na\ntotally\nordered\nset\nwith\nk\n\nelemen\nts\nW\ne\nt a k\ne\nthis\ntotally\nordered\nset\nas\nthe\nset\nI\nk\n\nof\npartitions\nof\nf\n\nk\n\ng\ngiv\nen\nb\ny\nf\n\nj\ng\nfj\n\ng\nfj\n\ng\n\nfk\n\ng\nand\nthe\nrank\nis\nthe\nn\num\nb\ner\nof\nparts\nX\n\nM\nk\n\nk\n\nn\nj\nj\n\nI\nk\n;1\n\nPHILIPPE\nBIANE\nThe\nk\nth\nfree\ncum\nulan\nt\nof\nthis\nmeasure\nis\nthe\ngenerating\nfunction\n\nk\n\nX\nX\n\nk\n\nk\n\nn\nl\n\nk\n\nR\nk\n\nk\n\nk\n\nl\n\nl\nn\nj\nj\n\nl\n\nN\nC\n\nk\n\nF\nor\nthe\nBo\nolean\ncum\nulan\nts\none\nnds\n\nk\n\nX\nB\nk\n\nnn\n\nk\n\nk\n\nX\nk\n\nn\nj\n\nk\n\nn\nj\nj\n\nj\n\nj\n\nB\n\nk\n\nThe\nev\naluation\nof\nthe\ntrivial\nc\nharacter\non\n\nk\ngiv\nes\nnn\n\nn\n\nk\n\nThis\nis\nthe\ngenerating\nfunction\nrecall\nthat\nl\n\nis\nthe\nn\num\nb\ner\nof\ncyles\nof\n\nX\n\nk\n\nk\n\nn\nl\n\nS\nk\nL e t\nu s\nn o\nw\nconcen\ntrate\non\nthe\nform\nula\nexpressing\nthe\nfree\ncum\nulan\nts\nin\nterms\nof\nBo\nolean\ncum\nulan\nts\nand\nthe\nBo\nolean\ncum\nulan\nts\nin\nterms\nof\nmomen\nts\nThe\nrst\nsuc\nh\nexpressions\nare\nR\nR\nR\n\nB\n\nB\n\nB\n\nB\n\nR\nR\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nR\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\nB\nB\n\nM\n\nM\n\nM\n\nM\n\nB\nB\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nB\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nThese\nform\nulas\ncon\ntain\nsigns\nbut\nw\ne\ncan\nmak\ne\nall\nco\ne cien\nts\np\nositiv\ne\nb\ny\na n\no\nv\nerall\nsign\nc\nhange\nof\nall\nv\nariables\nW\ne\nare\ngoing\nto\ngiv\ne\na\nc o m\nbinatorial\nin\nterpretation\nof\nthese\nco\ne cien\nts\nLet\nus\nreplace\nmomen\nts\nfree\ncum\nulan\nts\nand\nBo\nolean\ncum\nulan\nts\nb\ny\nt h e\nv\nalues\n\nand\n\nIt\nseems\nnatural\nto\ntry\nto\nin\nterpret\nthe\nform\nulas\nexpressing\nfree\ncum\nulan\nts\nas\npro\nviding\na\ndecomp\nosition\nof\nthe\nlattice\nof\nnoncrossing\npartitions\nN\nC\nk\n\nB\n\nin\nto\na\ndisjoin\nt\nunion\nof\nsubsets\nwhic\nh\nare\npro\nducts\nof\nBo\nolean\nlattices\nwhereas\nthe\nform\nula\nexpressing\nBo\nolean\ncum\nulan\nts\nshould\ncome\nfrom\na\ndecomp\nosition\nof\nthe\nBo\nolean\nlattice\nB\nk\n\nI\n\nin\nto\na\nunion\nof\npro\nducts\nof\ntotally\nordered\nsets\nIt\nturns\nout\nthat\nsuc\nh\ndecomp\nositions\nexist\nand\nw\ne\nshall\nno\nw\ndescrib\ne\nthem\nFirst\nw\ne\nl o\no k\na t\nt h e\nf o r m\nula\nfor\nexpressing\nBo\nolean\ncum\nulan\nts\nin\nterms\nof\nmomen\nts\nOn\nthe\nBo\nolean\nlattice\nof\nin\nterv\nal\npartitions\nlet\nus\nput\na\nnew\nstronger\norder\nrelation\nF\nor\nthis\nnew\norder\na\nco\nv\ners\nb\nif\nand\nonly\nif\nb\ncan\nb\ne\nobtained\nfrom\na\nb\ny\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\nM\ndeleting\nthe\nlast\nelemen\nt\nof\nsome\nin\nterv\nal\nif\nthis\nin\nterv\nal\nhad\nat\nleast\nthree\nelemen\nts\nor\nif\nit\nis\nthe\nin\nterv\nal\n\nThe\nresulting\ndecomp\nosition\nof\nthe\nBo\nolean\nlattice\nof\nin\nterv\nal\npartitions\nof\nf\n\ng\nis\nsho\nwn\nin\nthe\nfollo\nwing\npicture\nIt\ncorresp\nonds\nto\nthe\nform\nula\nfor\nB\n\nab\no\nv\ne\nThe\nrst\nline\nin\nthe\npicture\ncorresp\nonds\nto\nthe\nin\nterv\nal\nM\n\nthe\nsecond\nand\nthird\nline\naccoun\nt\nfor\nthe\nt\nw\no\nin\nterv\nals\nM\n\nM\n\nthe\nfourth\nline\nfor\nthe\npro\nduct\nin\nterv\nal\nM\n\nand\nthe\nlast\nline\nfor\nthe\np\noin\nt\ncorresp\nonding\nto\n\nThe\nranking\nis\nhorizon\ntal\nThe\npro\nof\nthat\nthis\ndecomp\nostion\nyields\nthe\nrigh\nt\nin\nterpretation\nof\nthe\nBo\nolean\ncum\nulan\ntmomen\nt\nform\nula\nis\neasy\nand\nleft\nto\nthe\nreader\nF\nig\n\nNo\nw\nlet\nus\ndecomp\nose\nthe\nlattice\nof\nnoncrossing\npartitions\nin\nto\na\nunion\nof\nBo\nolean\nlattices\nF\nor\nthis\nw\ne\nput\nthe\nfollo\nwing\nnew\norder\non\nnoncrossing\npartitions\nA\nnoncrossing\npartition\na\nco\nv\ners\na\nnoncrossing\npartition\nb\nif\nand\nonly\nif\nb\ncan\nb\ne\nobtained\nfrom\na\nb\ny\ncutting\na\npart\nof\nb\nb\ne t\nw\neen\nt\nw\no\nsuccessiv\ne\nelemen\nts\ni\ni\n\nF\nor\nexample\nw\ne\ng i v\ne\nhere\nthe\nlist\nof\nthe\nBo\nolean\nin\nterv\nals\nobtained\nin\nthis\nw\na\ny\ni n\nN\nC\n\ncorresp\nonding\nto\nthe\nform\nula\nfor\nR\n\nNext\nto\neac\nh\ni n\nterv\nal\nw\ne\ngiv\ne\nthe\nterm\nto\nwhic\nh\nit\ncorresp\nonds\nin\nthe\nform\nula\nConsider\nthe\nCa\nyley\ngraph\nof\nS\nk\nwith\nresp\nect\nto\nthe\ngenerating\nset\nof\nall\ntransp\nositions\nThe\nlattice\nN\nC\nk\n\ncan\nb\ne\nem\nb\nedded\nin\nto\nS\nk\n\nas\nthe\nsubset\nof\nelemen\nts\nlying\non\na\ngeo\ndesic\nfrom\ne\nto\nthe\nfull\ncycle\nk\n\nIn\nthis\nem\nb\nedding\nthe\ncycles\nof\na\np\nerm\nutation\ncorresp\nond\nto\nthe\nparts\nof\na\npartition\nhence\nthe\nfunctions\nj\nj\nand\nl\n\nW\ne\ng i v\ne\nin\nthe\nnotation\nthe\ncycle\nstructure\nof\na\n\nnoncrossing\npartition\nas\nan\nelemen\nt\no f\nS\nk\n\nAn\nin\nterv\nal\n\nin\nw hic\nh\n\nhas\na\nl\nk\ncycle\nstructure\n\nl\n\nk\nl\nk\ncorresp\nonds\nto\na\nterm\nB\ns\n\nB\nl\nB\nl\n\nB\nk\n\nw here\ns\nis\nsuc\nh\n\nthat\nthe\nrank\nof\n\nis\ns\n\nl\n\nl\nk\n\ne\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nObserv\ne\nthat\neac\nh\ni n\nterv\nal\nab\no\nv\ne\nis\nin\nfact\nan\nin\nterv\nal\nfor\nthe\nBruhat\norder\n\nPHILIPPE\nBIANE\nLo\noking\nat\nthe\nab\no\nv\ne\nresults\nand\nat\nTheorem\n\nit\nis\ntempting\nto\ntry\nin\nterpreting\nKero\nv\np\nolynomials\nas\ncoming\nfrom\na\ndecomp\nosition\nof\nthe\nsymmetric\ngroup\nin\nto\nin\nterv\nals\nfor\nsome\nsuitable\norder\nrelation\nin\nwhic\nh\nthe\nadjacency\nrelation\nshould\nb\ne\ninduced\nb\ny\nthe\none\nof\nthe\nCa\nyley\ngraph\nThe\nco\ne cien\nt\nof\nR\nl\n\nR\nl\ns\nw\nould\ncoun\nt\nthe\nn\num\nb\ne r\nof\nin\nterv\nals\nisomorphic\nto\nthe\nordered\nset\n\ns\nN\nC\n\nl\nN\nC\n\nl\n\nN\nC\ns\n\nl\ns\n\nSuc\nh\nin\nterv\nal\nw\nould\nb\ne\nof\nthe\nform\n\nwith\nP\nP\nj\nj\n\nk\n\nl\nj\n\nand\nj\n\nj\n\nk\n\nl\nj\n\nThe\nob\nvious\nc\nhoice\nfor\nS\nj\nj\nthe\nrst\nterm\nR\nk\n\nin\n\nk\nw\nould\nb\ne\nto\ntak\ne\nthe\nset\nof\ngeo\ndesics\nfrom\ne\nto\n\nk\n\nObserv\ne\nh o\nw\nev\ner\nthat\nb\necause\nof\nsign\nproblems\nw\ne\nshould\nget\na\nsigned\nco\nv\nering\nof\nk\n\nnamely\neac\nh\nelemen\nt\no f\nS\nk\nw\nould\nb\ne\ncon\ntained\nin\na\ncertain\nn\num\nb\ne r\no f\ni n\nterv\nals\nand\nin\nterv\nals\ncorresp\nonding\nto\nterms\nof\nev\nen\ndegree\nw\nould\ngiv\ne\na\nm\nultiplicit\ny\no n e\nwhile\nterms\nof\no\nd d\ndegree\nw\nould\ngiv\ne\na\nm\nultiplicit\ny\n\nthe\nsum\nof\nm\nultiplicities\nw\nould\nthen\nb\ne\n\nfor\nan\ny\n\nS\nk\n\nOne\nw\na\ny\nto\nget\naround\nthis\nproblem\nof\nsigned\nco\nv\nering\nw\nould\nb\ne\nto\nlo\nok\nat\nthe\nexpression\nof\nc\nharacters\nin\nterms\nof\nBo\nolean\ncum\nulan\nts\nwhere\nthis\nproblem\ndisapp\nears\nOne\nw\nould\nthen\nb\ne\nlead\nto\nlo\nok\nfor\na\ndecomp\nosition\nof\nthe\nCa\nyley\ngraph\nin\nto\na\nunion\nof\npro\nducts\nof\nBo\nolean\nlattices\nIt\nis\nhere\nnatural\nto\ntry\ndoing\nso\nb\ny\nusing\nthe\nBruhat\norder\nIndeed\nsome\ndecomp\nositions\nof\nthe\nsymmetric\ngroup\nin\nto\nBo\nolean\nlattices\nha\nv\ne\napp\neared\nin\nthe\nlitterature\nLS\n\nM\nbut\nthey\nare\nnot\nthe\nones\nw\ne\nare\nlo\noking\nfor\nindeed\nb\ny\nTheorem\n\none\ncan\ncompute\nthe\ntotal\nn\num\nb\ne r\no f\ni n\nterv\nals\nwhic\nh\nshould\no\nccur\nin\nthe\ndecomp\nosition\nof\nS\nk\n\nand\nev\nen\nthe\ngenerating\nfunction\nof\nthe\nn\num\nb\ner\nof\nterms\naccording\nto\ntheir\ndegrees\nit\nis\ngiv\nen\nb\ny\n\nY\nS\np\nx\n\np\n\nx\np\nx\n\nii\n\nS\np\nx\n\np\n\nS\np\nx\np\np\n\nj\n\nwhereas\nthe\nab\no\nv\ne\ndecomp\nositions\nha\nv\ne\nk\n\nin\nterv\nals\nIt\nhas\nb\neen\nobserv\ned\nb\ny\nR\nStanley\nSt\nthat\nif\none\nev\naluates\nthe\nc\nharacter\nof\na\ncycle\nfor\na\nrectangular\np\n\nq\nY\noung\ndiagram\nthen\none\ncan\nimpro\nv\ne\nthe\nform\nulas\n\nto\n\nb\ny\nreplacing\nthem\nb\ny\ntheir\nhomogeneous\nt\nw\nov\nariable\ncorresp\nondan\nts\nwhile\nthe\nc\nharacter\nis\nno\nw\ngiv\nen\nb\ny\nthe\nrhs\nof\n\nwith\nx\n\np\ny\n\nq\n\nThis\ngiv\nes\nmore\nevidence\nfor\nthe\nconnection\nwith\nthe\nCa\nyley\ngraph\nof\nsymmetric\ngroup\nLet\nus\nno\nw\nlo\nok\nat\nthe\nrst\nv\nalues\nof\nk\n\nThe\ncases\nof\n\nk\nfor\nk\n\ndo\nnot\npresen\nt\ndi cult\ny\nso\nlet\nus\nconcen\ntrate\non\n\nR\n\nR\n\nR\n\nR\n\nW\ne\nalready\n\nha\nv\ne\nthe\nin\nterpretation\nof\nthe\nterms\nR\n\nand\nR\n\nthey\nshould\ncorresp\nond\nrep\nectiv\nely\nto\nthe\nin\nterv\nal\ne\n\nof\nelemen\nts\nsuc\nh\nthat\nde\n\nd\n\nd\nis\nthe\ndistance\nin\nthe\nCa\nyley\ngraph\nand\nthe\neigh\nt\none\np\noin\nt\ni n\nterv\nals\nc\nwhere\nc\nis\na\ncycle\nwhose\npro\nduct\nwith\n\nis\na\ncycle\nIt\nremains\nto\nco\nv\ner\nthe\nelemen\nts\nof\nS\n\nsatisfying\nde\n\nd\n\nb\ny\n\nin\nterv\nals\nisomorphic\nto\na\ncycle\nThis\nshould\nyield\n\nelemen\nts\nwith\nde\n\nd\n\nwhic\nh\nare\ncoun\nted\nt\nwice\nAfter\nsome\nguessw\nork\nthe\nfollo\nwing\nnon\nunique\ndecomp\nosition\ncan\nb\ne\nfound\nThe\n\nin\nterv\nals\nare\n\nand\ntheir\nconjugates\nb\ny\n\nThe\n\nelemen\nts\ncoun\nted\nt\nwice\nare\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\nwhic\nh\napp\nears\nin\nthe\nin\nterv\nals\n\nand\n\nand\nall\nits\nconjugates\nb\ny\n\nV\nalues\nof\n\nk\nfor\nk\n\nto\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nReferences\nB\nP\n\nBiane\nR\nepr\nesentations\nof\nsymmetric\ngr\noups\nand\nfr\ne\ne\np r\nob\nability\nAdv\nMath\n\nIO\nV\nIv\nano\nv\nG\nOlshanski\nKer\novs\nc\nentr\nal\nlimit\nthe\nor\nem\nfor\nthe\nPlancher\nel\nme\nasur\ne\no n\nY\noung\ndiagr\nams\nPreprin\nt\nJune\n\nK\nS\nV\nKero\nv\nT\nr\nansition\npr\nob\nabilities\nof\nc\nontinual\nY\noung\ndiagr\nams\nand\nthe\nMarkov\nmoment\npr\noblem\nF\nunct\nAnal\nAppl\n\nK\nS\nV\nKero\nv\nT\nalk\nat\nIHP\nc\nonfer\nenc\ne\nJan\n\nK\nO\nS\nV\nKero\nv\nG\nOlshanski\nPolynomial\nfunctions\non\nthe\nset\nof\nY\noung\ndiagr\nams\nC\nR\nAcad\nSci\nP\naris\nS\n\ner\nI\nMath\n\nno\n\nLS\nA\nLascoux\nMP\n\nS c\nh utzen\nb\nerger\nT\nr\neil\nlis\net\nb\nases\ndes\ngr\noup\nes\nde\nCoxeter\nElectron\nJ\n\nCom\nbin\n\nNo\n\nResearc\nh\npap\ner\n\npp\nM\nI\nG\nMacdonald\nSymmetric\nfunctions\nand\nHal\nl\np\nolynomials\nSecond\nEdition\nOxford\nUniv\nPress\nOxford\n\nMo\nA\nI\nMolev\nStirling\np\nartitions\nof\nthe\nsymmetric\ngr\noup\nand\nL\naplac\ne\no p\ner\nators\nfor\nthe\northo\ng\nonal\nLie\nalgebr\na\nPro\nceedings\nof\nthe\nth\nConference\non\nF\normal\nP\no\nw\ner\nSeries\nand\nAlgebraic\nCom\nbinatorics\nNoisyleGrand\n\nDiscrete\nMath\n\nno\n\nO\nA\nOk\nounk\no\nv\nPriv\nate\ncomm\nunication\nJan\nuary\n\nSp\nR\nSp\neic\nher\nCombinatorial\nThe\nory\nof\nthe\nF\nr\ne\ne\nP r\no\nduct\nwith\nA\nmalgamation\nand\nOp\ner\nator\nV\nalue\nd\nF\nr\ne\ne\nP r\nob\nability\nThe\nory\nMemoirs\nof\nthe\nAMS\n\nSt\nR\nStanley\n\nPriv\nate\ncomm\nunication\nMa\ny\n\nSt\nR\nStanley\n\nIrr\ne\nducible\nsymmetric\ngr\noup\nchar\nacters\nof\nr\ne\nctangular\nshap\ne\nPreprin\nt\nSeptem\nb\ner\n\nPHILIPPE\nBIANE\nSW\nR\nSp\neic\nher\nR\nW\noroudi\nBo\nole\nan\nindep\nendenc\ne\nF\nree\nprobabilit\ny\n\nFields\nInstitue\nComm\nu\nnications\nD\nV\noiculescu\nEd\n\nep\nar\ntement\nde\nMa\nth\n\nEcole\nNormale\nSup\n\nCNRS\nD\n\nema\ntiques\net\nApplica\ntions\n\nerieure\n\nr\nue\ndUlm\n\np\naris\nFRANCE\nEmail\naddr\ness\n\nPhilippeBianeensfr"
    },
    {
      "category": "Resource",
      "title": "courseinfo.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/90c6a4b0fe370d1ed14908876d49f757_courseinfo.pdf",
      "content": "18.338J/16.394J: The Mathematics of Infinite Random Matrices\nProfessor Alan Edelman\nHandout #1, Thursday, September 9, 2004 -- Course Outline\nSummary. This is a course on the mathematics and applications of infinite random matrices. Our aim is\nto touch upon various branches of the study of infinite random matrices--a consequence is that we will\nend up lingering on some areas longer than others. Our hope is that this course will confer:\n- some familiarity with several of the main thrusts of work in infinite random matrices--sufficient to\ngive you some context for formulating and seeking known solutions to applications in engineering\nand physics;\n- sufficient background and facility to let you read current research publications in the area of\ninfinite random matrix theory;\n- a set of tools, both analytical and computational, for the analysis of new random matrices that\narise in new problems you may encounter.\nLecturer. Alan Edelma\nContent. The goal is for the course is, paradoxically, to be broad as well as deep. Our plan (unlikely to\nsurvive contact with the reality of an actual semester) is to touch upon the following broad areas while\nattempting to uncover deep insights into the underlying mechanisms that unify these areas. This is a\ntentative list of topics that might be covered in the course; We will select material adaptively based on\nour background, interests, and rate of progress. If you are interested in some other topics, please let\nus know and we'd be happy to accommodate your interests.\nCombinatorial aspects. Using combinatorial techniques to derive the limiting distribution of the\nthree classical random matrix ensembles. Path counting and random matrix theory. Generaliza-\ntions to counting paths on torii.\nStieljtes transform based methods. The MarËcenko-Pastur theorem. Other generalizations. Sil-\nverstein's sample covariance matrix. Convergence issues.\nFree probability. The concept of freeness. Free cumulants and non-crossing partitions. The R and\nS transform. Fluctuations and Second Order Freeness. Combinatorial interpretations.\nn\n\nEquilibrium Measure. The Hermite, Laguerre and Jacobi orthogonal polynomials. Interpretation\nof the limiting distribution as the equilibrium measure of (univariate) orthogonal polynomials.\nApplications to physics.\nFredholm Determinants. Tracy-Widom Distribution. Eigenvalue spacings and the Riemann Hy-\npothesis.\nJack Polynomials. Multivariate orthogonal polynomials.\nCombinatorial aspects.\nConnections to\nrandom matrices.\nApplications. Wireless Communications, Statistical Physics.\nPrerequisites. We assume that the reader has had an undergraduate course in Linear Algebra (18.06) or\nits equivalent and some exposure to probability (6.041 or 6.042 are more than sufficient). Knowledge\nof combinatorial theory is a bonus.\nRequirements. Problem sets, mid-term project and final project.\nHomework. Homework assignments will be handed out bi-weekly. They will mainly consist of MATLAB\nbased explorations of the material covered in class.\nYou will not be needed to turn them in\nalthough being able to do them will greatly help your understanding of the material.\nMid-Term Project. You will be asked to read a paper on a topic of interest to you that involves\nrandom matrix theory and present it via some mixture of the following perspectives:\n- Write a description of greater clarity than the original publication, or\n- Devise an improved solution to the problem under consideration, and write up your improve-\nment (with appropriate discussion of the original solution).\n- Implement the result in MATLAB in order to study its performance in practice when the random\nmatrices are finite. Considerations include choice of random matrix result, design of good\ntests, interpretation of results, and design and analysis of heuristics for improving performance\nin practice.\nSemester project. The semester project can be an extension of the mid-term project if it sustains\nyour interest. Otherwise, you will be asked to come up with some insights into a random matrix\nproblem that is of interest to you.\nIdeally, the topic you choose will be motivated by a computational problem you need to solve in\nyour research. If the project is large, it may be tackled by a group.\nOtherwise, feel free to ask us for suggestions and ideas. Our goal is that you are able to get your\nhands wet trying to solve a problem while using computational and analytical tools that you've\nlearned about.\nIn the past, a student's whole PhD thesis came out of such an exploration. While that might\nbe the exception and rather than the norm we hope we can instil a sense of adventure in you to\ntackle an interesting random matrix problem and to, hopefully, help you get some useful results\nout of it.\nGrading. In this spirit, and since this is an advanced graduate class on a very active research area, the\ngrading will be based on your participation in the class.\nTextbooks. There are no textbooks covering a majority portion of the material we will be studying in\nthis course. We will be giving out course readers during the semester to help you study the material\nbefore the lectures. There will be research papers handed out in class and posted on the\nGuest Speakers. We will have guest speakers that will help give us their own perspective on their research\ninvolving random matrices. While these speakers will appear as part of the Applied Math Colloquium\nseries, attendance is strongly encouraged. The confirmed dates for two of the speakers are:\n- Dr. Anna Scaglione. Monday, October 25, 2004, 4:15 pm\n- Dr. Roland Speicher. Monday, November 18, 2004, 4:15 pm\nserver."
    },
    {
      "category": "Resource",
      "title": "mandp.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/4aaadd9c5350b0b0293fe9af97504a0e_mandp.pdf",
      "content": "On the Empirical Distribution of\nEigenvalues of a Class of Large\nDimensional Random Matrices\nby\nJack W. Silverstein*\nDepartment of Mathematics\nBox 8205\nNorth Carolina State University\nRaleigh, North Carolina 27695-8205\nand\nZ.D. Bai\nDepartment of Applied Mathematics\nNational Sun Yat-Sen University\nKaohsiung, Taiwan\nSummary\nA stronger result on the limiting distribution of the eigenvalues of random Hermitian\nâ\nmatrices of the form A+XTX , originally studied in MarËcenko and Pastur [4], is presented.\nHere, X (N Ãn), T (nÃn), and A (N ÃN) are independent, with X containing i.i.d. entries\nhaving finite second moments, T is diagonal with real (diagonal) entries, A is Hermitian,\nand n/N â c > 0 as N âinf. Under addtional assumptions on the eigenvalues of A\nand T, almost sure convergence of the empirical distribution function of the eigenvalues of\nA + XTXâ is proven with the aid of Stieltjes transforms, taking a more direct approach\nthan previous methods.\n* Supported by the National Science Foundation under grant DMS-8903072\nAMS 1991 subject classifications. Primary 60F15; Secondary 62H99.\nKey Words and Phrases. Random matrix, empirical distribution function of eigenval\nues, Stieltjes transform.\n\nZ\nâ\n1. Introduction. Consider the random matrix XTX , where X is N Ã n containing\nindependent columns, and T is n Ã n Hermitian, independent of X. Several papers have\ndealt with the behavior of the eigenvalues of this matrix when N and n are both large but\nhaving the same order of magnitude (MarËcenko and Pastur [4], Grenander and Silverstein\n[2], Wachter [6], Jonsson [3], Yin and Krishnaiah [8], Yin [7]). The behavior is expressed\nin terms of limit theorems, as N âinf, while n = n(N) with n/N âc > 0, on the\nâ\nâ\nempirical distribution function (e.d.f.) F XT X of the eigenvalues , (that is, F XT X (x) is\nâ\nthe proportion of eigenvalues of XTX\nâ¤x), the conclusion being the convergence, in\nâ\nâ\nsome sense, of F XT X to a nonrandom F. The spectral behavior of XTX\nis of significant\nimportance to multivariate statistics. An example of the use of the limiting result can be\nfound in Silverstein and Combettes [5], where it is shown to be effective in solving the\ndetection problem in array signal processing when the (unknown) number of sources is\nsizable.\nThe papers vary in the assumptions on T, X, and the type of convergence (almost\nsure, or in probability), maintaining only one basic condition: F T converges in distribution\n(weakly or strongly) to a nonrandom probability distribution function, denoted in this\npaper by H. However, the assumptions on X share a common intersection: the entries of\nâ\nNX being i.i.d. for fixed N, same distribution for all N, with unit variance (sum of the\nvariances of real and imaginary parts in the complex case).\nIn MarËcenko and Pastur [4] and Grenander and Silverstein [2], only convergence in\nprobability (at continuity points of F) is established. The others prove strong convergence.\nIt is only in Yin and Krishnaiah [8] and Yin [7] where T is considered to be something\nother than diagonal, although it is restricted to being nonnegative definite. The weakest\nassumptions on the entries of X are covered in Yin [7]. All others assume at the least a\nmoment higher than two. A minor difference is the fact that only MarËcenko and Pastur [4]\nand Wachter [6] allow for complex X; the proofs in the other papers can easily be extended\nto the complex case.\nOnly MarËcenko and Pastur [4] considers arbitrary H. The others assume H to have\nall moments, relying on the method of moments to prove the limit theorem. These proofs\ninvolve intricate combinatorial arguments, some involving graph theory. On the other\nhand, the proof in MarËcenko and Pastur [4] requires no combinatorics. It studies the\nlimiting behavior of the Stieltjes transform\nâ\ndF XT X\nmXT Xâ (z) =\n(Î»)\nÎ» -z\nâ\nof F XT X , where z âC+ â¡{z âC : Im z > 0}. A function in z and t â[0, 1] is\nconstructed which is shown to converge (in probability) to a solution of a nonrandom first\norder partial differential equation (p.d.e.), the solution at t = 1 being the limiting Stieltjes\n\nÎ¼\nZ\nÂ¶\ntransform. Using the method of characteristics, this function is seen to be the solution to a\ncertain algebraic equation. Before presenting this equation, it is appropriate to mention at\nthis point that MarËcenko and Pastur [4] considered a more general form of matrix, namely\nA + XTXâ, where A is N Ã N Hermitian, nonrandom, for which F A converges vaguely,\nas N âinf, to a (possibly defective) distribution function A. Letting m(z) denote the\nStieltjes transform of F, and mA(z) the Stieltjes transform of A, the equation is given by\n(1.1)\nm(z) = mA z -c\nÏdH(Ï)\n.\n1 + Ïm(z)\nIt is proven in MarËcenko and Pastur [4] that there is at most one solution to the p.d.e.,\nimplying (1.1) uniquely determines the limiting distribution function via a well-known\ninversion formula for Stieltjes transforms.\nThe main purpose of the present paper is to extend the result in MarËcenko and Pastur\n[4], again with the aid of Stieltjes transforms, to almost sure convergence under the mild\nconditions on X assumed in Yin [7], at the same time weakening the assumptions on T\n(assumed in MarËcenko and Pastur [4] to be formed from i.i.d. random variables with d.f.\nH) and A. Although some aspects require arguments of a more technical nature, the\nproof is more direct than those mentioned above, avoiding both extensive combinatorial\narguments and the need to involve a p.d.e. By delineating the roles played by basic matrix\nproperties and random behavior, it provides for the most part a clear understanding as to\nwhy the e.d.f. converges to a nonrandom limit satisfying (1.1).\nIt is remarked here that the approach taken in this paper is currently being used\nas a means to extend the result to arbitrary T, and to investigate the convergence of\nindividual eigenvalues associated with boundary points in the support of F (see Silverstein\nand Combettes [5]).\nThe remainder of the paper is devoted to proving the following.\nTheorem 1.1. Assume\na) For N = 1, 2, . . . XN = ( â1\nN XN\nij â C, i.d. for all N, i, j, independent\nij ), N Ã n, XN\nacross i, j for each N, E|X1\n1 1 -EX1 |2 = 1.\n1 1\nb) n = n(N) with n/N âc > 0 as N âinf.\nc) TN = diag(Ï1\nN , . . . , Ï N ), Ï N â R, and the e.d.f. of {Ï1\nN , . . . , Ï N } converges almost\nn\ni\nn\nsurely in distribution to a probability distribution function H as N âinf.\nâ\nd) BN = AN + XN TN XN , where AN is Hermitian N Ã N for which F AN converges\nvaguely to A almost surely, A being a (possibly defective) nonrandom d.f.\ne) XN , TN , and AN are independent.\nThen, almost surely, F BN , the e.d.f. of the eigenvalues of BN , converges vaguely, as\nN âinf, to a (nonrandom) d.f. F, whose Stieltjes transform m(z) (z âC+) satisfies (1.1).\n\nThe proof is broken up into several parts. Section 2 presents matrix results, along\nwith results on distribution functions. The main probabilitistic arguments of the proof\nare contained in section 3. The proof is completed in section 4, while section 5 provides a\nsimple proof of at most one solution m(z) â C+ to (1.1) for z â C+ .\n\np\nX\n2. Preliminary Results. For rectangular matrix A let rank(A) denote the rank of A,\nand for positive integers i â¤rank(A), let sA be the ith largest singular value of A. Define\ni\nsA to be zero for all i > rank(A). When A is square having real eigenvalues, Î»A will denote\ni\ni\nthe ith largest eigenvalue of A. For q âCN , kqk will denote the Euclidean norm, and kAk\nA\nÎ»AAâ\nthe induced spectral norm on matrices (that is, kAk = s\n=\n).\nFor square C with real eigenvalues, let F C denote the e.d.f. of the eigenvalues of C.\nThe measure induced by a d.f. G on an interval J will be denoted by G{J }.\nThe first three results in the following lemma are well-known. The fourth follows\ntrivially from the fact that the rank of any matrix is the dimension of its row space.\nLemma 2.1.\na) For rectangular matrices A, B of the same size,\nrank(A + B) â¤rank(A) + rank(B).\nb) For rectangular matrices A, B in which AB is defined,\nrank(AB) â¤min(rank(A), rank(B)).\nc) For Hermitian N Ã N matrices A, B,\nN\n(Î»A -Î»B )2 â¤tr (A -B)2 .\ni\ni\ni=1\nd) For rectangular A, rank(A) â¤the number of non-zero entries of A.\nThe following result can be found in Fan [1].\nLemma 2.2. Let m, n be arbitrary non-negative integers. For A, B rectangular matrices\nof the same size,\nA+B\nA\n+ sn+1.\ns m+n+1 â¤sm+1\nB\nFor A, B rectangular for which AB is defined\nAB\nA\nB\nsm+n+1 â¤sm+1sn+1.\nThese inequalities can be expressed in terms of empirical distribution functions. For\nâ\nâ\nrectangular A let\nAAâ denote the matrix derived from AA\nby replacing in its spectral\nâ\nA\ndecomposition the eigenvalues with their square roots. Thus, Î» AAâ = si .\ni\nLemma 2.3. Let x, y be arbitrary non-negative numbers. For A, B rectangular matrices\nof the same size,\nâ\nâ\nâ\nAAâ\nF\n(A+B)(A+B)â {(x + y, inf)} â¤F\n{(x, inf)} + F BBâ {(y, inf)}.\n\nIf, additionally, A, B are square, then\nâ\nâ\nâ\nAAâ\nF\n(AB)(AB)â {(xy, inf)} â¤F\n{(x, inf)} + F BBâ {(y, inf)}.\nProof. Let N denote the number of rows of Aâ, B. Let m â¥0, n â¥0 be the smallest integers\nâ\nA\nB\nAAâ\nBBâ\nfor which sm+1 â¤x and sn+1 â¤y. Then F\n{(x, inf)} = m/N and F\n{(y, inf)} =\nâ\nâ\nâ\nA+B\nAAâ\nBBâ\nn/N, so that F â\n(A+B)(A+B)â {(sm+n+1, inf)} â¤F\n{(x, inf)} + F\n{(y, inf)} in the\nâ\nâ\nAB\nAAâ\nBBâ\nfirst case, and F\n(AB)(AB)â {(sm+n+1, inf)} â¤ F\n{(x, inf)} + F\n{(y, inf)} in the\nsecond case. Applying Lemma 2.2 we get our result.\nFor any bounded f : R âR, let kfk = supx |f(x)|. Using Lemma 2.2 it is straight\nforward to verify Lemma 3.5 of Yin [7] which states: For N Ã n matrices A, B\nâ\nâ\nkF AA -F BB\n(2.1)\nk â¤\nrank(A -B).\nN\nThis result needs to be extended.\nLemma 2.4. For N Ã N Hermitian matrices A, B\nkF A -F B k â¤\nrank(A -B).\nN\nProof. Let I denote the N Ã N identity matrix and c be any real number for which\nboth A + cI and B + cI are non-negative definite. For any x â R, F A (x) -F B (x) =\nF (A+cI)2 ((x + c)2) -F (B+cI )2\n-F (B+cI )2\n((x + c)2). thus, kF A -F B k = kF (A+cI)2\nk, and\nwe get our result from (2.1).\nThe next result follows directly from Lemma 2.1 a), b) and Lemma 2.4.\nLemma 2.5 Let A be N ÃN Hermitian, Q, Q both N Ãn, and T , T both n Ãn Hermitian.\nThen\na)\nkF A+QT Q â -F A+QT Q\nâ\nk â¤ 2\nN rank(Q -Q)\nand\nb)\nkF A+QT Q â -F A+QT Q â k â¤ 1 rank(T -T ).\nN\nThe next lemma relies on the fact that for N Ã N B, Ï âC, and q âCN for which B\nâ\nand B + Ïqq are invertible,\n(2.2)\nq â(B + Ïqq â)-1 = 1 + ÏqâB-1q q â B-1 ,\nâ\nâ\nâB-1\nâ\nwhich follows from q B-1(B + Ïqq ) = (1 + Ïq\nq)q .\n\nÂ¡\nÂ¢\n\nÂ¡\nÂ¢\n\nP\nX\nX\nLemma 2.6. Let z âC+ with v = Im z, A and B N Ã N with B Hermitian, Ï âR, and\nq âCN . Then\nkAk\nâ¤\ntr\nâ\n(B -zI)-1 -(B + Ïqq -zI)-1 A\n.\nv\nâ\nâ\nâ\nProof. Since (B -zI)-1 -(B + Ïqq -zI)-1 = Ï(B -zI)-1qq (B + Ïqq -zI)-1, we have\nby (2.2)\n=\nâ\nÏtr (B -zI)-1qq (B -zI)-1A\n1 + Ïqâ(B -zI)-1q\nâ\n(B -zI)-1 -(B + Ïqq -zI)-1 A\ntr\n=\nâ(B -zI)-1A(B -zI)-1\nâ¤kAk |Ï|\nk(B -zI)-1qk\n|1 + Ïqâ(B -zI)-1q| .\nq\nq\nÏ\n1 + Ïqâ(B -zI)-1q\nâ\nÎ»B eie\ni\nWrite B =\nwhere the ei's are the orthonormal eigenvectors of B. Then\ni\nâ\n|ei q|2\nÎ»B -z\nk(B -zI)-1 qk =\n|2 ,\n|\ni\nand\nâ\n|ei q|2\nÎ»B -z\nâ\n|1 + Ïq â(B -zI)-1 q| â¥|Ï| Im q (B -zI)-1 q = |Ï|v\n.\n|\n|\ni\nThe result follows.\nLemma 2.7. Let z1, z2 â C+ with max(Im z1, Im z2) â¥ v > 0, A and B N Ã N with A\nHermitian, and q âCN . Then\n|tr B((A -z1I)-1 -(A -z2I)-1)| â¤|z2 -z1|NkBk 2 , and\nv\nâ\nâ\n|q B(A -z1I)-1 q -q B(A -z2I)-1 q| â¤|z2 -z1| kqk2kBk\n.\nv\nProof. The first inequality follows easily from the fact that for N Ã N matrices C, D,\nâ\n|tr CD| â¤(tr CC â tr DD )1/2 â¤NkCk kDk,\nand the fact that k(A -ziI)-1k â¤1/v, i = 1, 2. The second inequality follows from the\nlatter observation.\nLet M(R) denote the collection of all sub-probability distribution functions on R.\nv\nv\nVague convergence in M(R) will be denoted by -â(that is, FN -âG as N âinfmeans\nD\nlim FN {[a, b]} = G{[a, b]} for all a, b continuity points of G). We write FN -âG if FN\nN âinf\nand G are probability d.f.'s. We denote the d.f. corresponding to the zero measure simply\nby 0.\n\nX\nZ\nZ\n\nX\nX\nR\nLemma 2.8. For {FN }inf\nâM(R), FN 6= 0, such that no subsequence converges vaguely\nN =1\nto 0, there exists a positive m such that\ninf FN {[-m, m]} > 0.\nN\nProof. Suppose not. Then a sequence mi âinfand a subsequence {FNi }inf can be found\ni=1\nv\nsatisfying FNi {[-mi, mi]} â0, which implies FNi -â0, a contradiction.\nLet {fi} be an enumeration of all continuous functions that take a constant\nvalue\nm\n(m a positive integer) on [a, b], where a, b are rational, 0 on (-inf, a - 1 ] âª[b + m , inf),\nm\nand linear on each of [a - 1 , a], [b, b + 1 ]. Standard arguments will yield the fact that for\nm\nm\nF1, F2 âM(R)\nD(F1, F2) â¡\ninf\nfi dF1 -\nfidF2 2-i\ni=1\nis a metric on M(R) inducing the topology of vague convergence (a variation of this metric\nhas been used in Wachter [6] and Yin [7] on the space of probability d.f.'s). Using the Helly\nselection theorem, it follows that for FN , GN âM(R)\n(2.3)\nlim kFN -GN k = 0 =â\nlim D(FN , GN ) = 0.\nN âinf\nN âinf\nSince for all i and x, y âR, |fi(x) -fi(y)| â¤|x -y| it follows that for e.d.f.'s F, G on\nthe (respective) sets {x1, . . . , xN }, {y1, . . . , yN }\nâ\nâ\nN\nN\nD2(F, G) â¤\n(xj -yj )2\n(2.4)\nâ\nâ \n|xj -yj |\nâ¤\n.\nN\nN\nj=1\nj=1\nFinally, since for G âM(R) the Stieltjes transform mG(z) =\ndG(Î») (z âC+)\nÎ» -z\npossesses the well-known inversion formula\nZ b\nG{[a, b]} =\nlim\nIm mG(Î¾ + iÎ·)dÎ¾\nÏ Î·â0+\na\n(a, b continuity points of G), it follows that for any countable set S âC+ for which R âS\n(the closure of S), and FN , G âM(R)\nv\n(2.5)\nlim mFN (z) = mG(z) âz âS =â FN -âG as N âinf.\nN âinf\n\nb\nb\ne\nX\ne\nÂ·\n\n3. Truncation, Centralization, and an Important Lemma. Following along similar\nlines as Yin [7], we proceed to replace XN and TN by matrices suitable for further analysis.\nTo avoid confusion, the dependency of most of the variables on N will occasionally be\ndropped from the notation. All convergence statements will be as N âinf.\nLet b\nand b\nXT b\nX = ( â1 Xij ). Using Lemmas\nXij = Xij I(|Xij |<\nâ\nN )\nBN = A+ b\nXâ, where b\nN\n2.5a and 2.1d, it follows as in Yin [7] pp. 58-59 that\nb\na.s.\n(3.1)\nkF BN -F BN k -â0.\ne\nXT e\ne\nb\nX ( e\nb\nXij ). Since rank(E b\nLet BN = A + e\nXâ where X = X -E b\nXij = Xij -E b\nX) â¤1,\nwe have from Lemma 2.5a\n(3.2)\nkF BN -F BN k -â0.\nFor Î± > 0 define TÎ± = diag(Ï1I(|Ï1 |â¤Î±), . . . , ÏnI(|Ïn |â¤Î±)), and let Q be any N Ã n\nmatrix. If Î± and -Î± are continuity points of H, we have by Lemma 2.5b and assumptions\nb) and c)\nkF A+QT Q â -F A+QTÎ± Q â\nn\na.s.\nc\nk â¤\nrank(T -TÎ±) =\nI(|Ïn |>Î±) -âcH{[-Î±, Î±] }.\nN\nN i=1\nIt follows that if Î± = Î±N âinfthen\nâ\nâ\na.s.\nkF A+QT Q -F A+QTÎ± Q\n(3.3)\nk -â0\nChoose Î± = Î±N âinfso that\nX Î±8\ninf\n(3.4)\nÎ±4(E|X1 1|2I(|X1 1 |â¥ln N ) +\n) â0 and\nN 2 (E|X1 1 |4I(|X1 1|<\nâ\nN ) + 1) < inf.\nN\nN =1\n(Note: It is easy to verify N 2 E|X1 1|4I(|X1 1 |<\nâ\nN ) is summable.)\ne\nXij I(|Xij |<ln N ), X = ( â1 Xij ), Xij = Xij -Xij , and\nLet Xij = Xij I(|Xij |<ln N ) -E e\nN\nX = ( â1 Xij ). Then, from (2.4), Lemma 2.1c, and simple applications of the Cauchy-\nN\nSchwarz inequality we have\nâ\nâ\nXTÎ± X\ne â\nâ\nD2(F A+ e\ne , F A+XTÎ± X ) â¤ 1 tr ( e\nXTÎ±X -XTÎ±X )2\nN\n= 1 tr (XTÎ±X â)2 + tr (XTÎ±X â + XTÎ±X â)2 + 2tr (XTÎ±X â + XTÎ±X â)XTÎ±X â\nN\n\nX\ne\n1 Â·\nÎ¼\nÂ¶1/2\nâ\nâ\nâ\nâ¤\ntr (XTÎ±X â)2 + 4tr (XTÎ±X XTÎ±X ) + 4 tr (XTÎ±X â XTÎ±X )tr (XTÎ±X â)2\n.\nN\nIt is straightforward to show\nâ\nâ\nâ\nâ\nâ)2)1/2\ntr (XTÎ±X â)2 â¤ Î±2tr (X X )2 and tr (XTÎ±X XTÎ±X ) â¤ (Î±4tr (X X )2tr (X X\n.\nTherefore, in order to show\nâ\nâ\na.s.\nXTÎ± X\n(3.5)\nD(F A+e\ne , F A+XTÎ± X ) -â 0\nit is sufficient to verify\na.s.\n(3.6)\nÎ±4\ntr (X X â)2 -â 0 and\ntr (X X â)2 = O(1) a.s.\nN\nN\nFor any N Ã n matrix Y = (Yij) with Yij â C i.i.d., mean zero, and finite eighth\nmoment, it is straightforward to show for all N\n(3.7)\nE(tr (Y Y â)2) = NnE| Y1 1| 4 + Nn(N + n - 2)E2| Y1 1|\nand\n(3.8) Var(tr (Y Y â)2)\nâ¤ K(N 2E| Y1 1| 8 + N 3(E| Y1 1| 6E| Y1 1| 2 + E2| Y1 1| 4) + N 4(E| Y1 1| 4E2| Y1 1| 2 + E4| Y1 1| 2)),\nn\nwhere K depends only on the maximum of N . The verification of (3.8) can be facilitated\nby writing the variance as\n\n(3.9)\nE(Yi jYk jYk lY i lYi jYk jYk lYi l) - E(Yi jYk jYk lYi l)E(Yi jYk jYk lYi l)\ni j k l\ni j k l\n(where Y a b is the complex conjugate of Ya b) and using the following facts:\n1) For any non-zero term in (3.9), at least one of the ordered pairs of indices\n(i, j), (k, j), (k, l), (i, l) must match up with one of (i, j), (k, j), (k, l), (i, l), and none\nof the eight random variables appear alone.\n2) EZa EZb â¤ EZa+b for nonnegative random variable Z and nonnegative a, b.\nSince EX1 1 = 0 and X1 1 = X1 1I(|X1 1|â¥ln N) + E( e\ne\nX1 1I(|X1 1 |<ln N)), we have\n(3.10)\nE| X1 1| 2 = Var(Re X1 1) + Var(Im X1 1)\nX1 1I(|X1 1 |â¥ln N)) + Var(Im e\n= Var(Re e\nX1 1I(|X1 1 |â¥ln N)) â¤ E| X1 1| 2I(|X1 1 |â¥ln N)\n\ne\n2I\nâ\nâ¤ 2(E| X1 1|\n(ln N â¤|X1 1 |<\nN ) + | EX1 1I(|X1 1|<\nâ\n| 2P(| X1 1| â¥ ln N))\nN )\nâ¤ KE| X1 1| 2I(|X1 1|â¥ln N ) â 0.\nFor m â¥ 4\nE| X1 1| m â¤ 2m-1(E| X1 1| mI(|X1 1 |â¥ln N ) + | E e\nX1 1I(|X1 1|<ln N )| m)\nmI\nâ¤ 22(m-1)E| X1 1|\n(ln N â¤|X1 1 |<\nâ\nN ) + (22(m-1) + 22m-1)(E| X1 1| )m\nm-4\nâ¤ Km(N\nE| X1 1| 4I(ln N â¤|X1 1|<\nâ\nN ) + 1).\nTherefore, using (3.7), (3.10), and (3.4) we find\nâ\nâ\nE\nÎ±4tr (X X )2 â¤ Î±4K(\nE| X1 1| 4I(ln N â¤|X1 1|<\nN ) +\n+ E2| X1 1| 2)\nN\nN\nN\nâ¤ Î±4K0(E| X1 1| 2I(|X1 1|â¥ln N ) +\n) â 0,\nN\nand from (3.8) (using again E| X1 1| 4I(|X1 1|<\nâ\nâ¤ NE| X1 1| 2)\nN )\nÎ±8\n4I\nVar(Î±\ntr (X X â)2) â¤ K N 2 (E| X1 1|\n(|X1 1 |<\nâ\nN ) + 1)\nN\na.s.\n4 1\nâ\nwhich, from (3.4), is summable. Therefore, Î±\nN tr (X X )2 -â 0.\nSimple applications of the dominated convergence theorem will yield E| X1 1|\nâ\nE| X1 1 - EX1 1| 2 = 1. Moreover, it is straightforward to verify for m â¥ 4\nE| X1 1| m â¤ Km(ln N)m-2 .\nThus, from (3.7) we find\nE\ntr (X X â)2 â c(1 + c),\nN\nand from (3.8)\nVar(\ntr (X X â)2) â¤ K (ln N)2\nN\nn2\nâ\na.s.\nwhich is summable. Therefore, N tr (X X )2 -â c(1 + c), so that (3.6) holds, which\nimplies (3.5). This, together with (2.3), (2.5), and (3.1-3.3), shows that, in order to prove\nv\nF BN -â Fc,H , it is sufficient to verify for any z â C+\na.s.\nm\nâ (z) -â mFc,H (z).\nF A+XT X\nNotice the matrix diag(E| X1 1| 2Ï1\nN , . . . , E| X1 1| 2Ï N ) also satisfies assumption c) of\nn\nTheorem 1.1. We will substitute this matrix for T, and replace X by â\nX (at least\nE|X 1 1 |\n\ne\nÎ¼\nÂ¶\nÎ¼X\nX\nX\nÂ¶\nX\nfor N sufficiently large so that E|X1 1|2 > 0). Since |Xij I(|Xij |<ln N )| â¤ln N + E|X1 1| we\nhave (for N sufficiently large) â E|X1 1 | |Xij | â¤a ln N for some a > 2. Let log N denote\nthe logarithm of N with base e1/a (so that a ln N = log N). Simplifying notation, we write\nBN = A + XTXâ with X = ( â1 Xij ) where,\nN\n1) Xij are i.i.d. for fixed N,\n2) |X1 1| â¤log N,\n3) EXij = 0, E|X1 1 |2 = 1,\nand, along with assumptions b), c), d) of Theorem 1.1, proceed to show for any z âC+\na.s.\nmF BN (z) -âmFc,H (z).\nAs will be seen in the next section, the following lemma and (2.2) contribute the most\nto the truth of Theorem 1.1.\nLemma 3.1. Let C = (cij ), cij â C, be an N Ã N matrix with kCk â¤ 1, and\nY = (X1, . . . , XN )T , Xi âC, where the Xi's are i.i.d. satisfying conditions 2) and 3).\nThen\nâ\n(3.11)\nE|Y CY -tr C|6 â¤KN 3 log12 N\nwhere the constant K does not depend on N, C, nor on the distribution of X1.\nProof: We first consider C real. Since 1 â¥kCk = (Î»CCT )1/2, it follows that |cii| â¤1 for\neach i. We have\nÂ¡X\nX\n\nâ\n\nE|Y CY -tr C|6 â¤32 E\ncii(|Xi|2 -1)\nÂ¢6 + E\ncij XiXj 6 .\ni\ni6=j\nFor the first sum the expansion is straightforward:\nE\nÂ¡X\ncii(|Xi|2 -1)\nÂ¢6 â¤K log12 N\n|cii|6 +\n(c\n+ |ciicjj |3)\niicjj\ni\ni\ni6=j\n+\n(ciicjj ckk )2\nâ¤KN 3 log12 N\ni j k\ndistinct\nFor the second sum we have the expression\n\nci1 j1 ci2 j2 ci3 j3 cj4 i4 cj5 i5 cj6 i6 EXi1 Xj1 Xi2 Xj2 Xi3 Xj3 Xi4 Xj4 Xi5 Xj5 Xi6 Xj6 .\ni1 =\nj1\n. . .\ni6 =\nj6\n\nP\nNotice a term will be zero if any Xk appears alone. The sum can be further decom\nposed into sums where each one corresponds to a partitioning of the 12 indices, with each\nset in the partition containing at least 2 indices, none containing any pair il, jl. Consider\none such sum. The summation is performed by 1) restricting the indices in the same parti\ntion set to take on the same value, and 2) not allowing indices from different partition sets\nto take on the same value. The expected value part will be the same for each term and\ncan be factored out. It is bounded in absolute value by log12 N. The sum can be further\ndecomposed, using an inclusion-exclusion scheme, where each resulting sum only satisfies\n1). By Lemma 3.4 of [Yin], each of these sums is bounded in absolute value by\nÂ¡ X\nX\nÂ¢1/2\nci1 j1 Â· Â· Â·\nci6 j6\nâ¤N 3\ni1 =\nj1\ni6 =\nj6\nsince\nci1 j1 = tr CCT â¤N. Thus we get (3.11).\nFor arbitrary C we write C = C1 + iC2 with C1 and C2 real. It is a simple matter to\nverify max(kC1k, kC2k) â¤kCk. Using this, the inequality\nâ\nâ\nâ\n|Y CY -tr C| â¤|Y C1Y -tr C1| + |Y C2Y -tr C2|\nand the truth of (3.11) for real matrices, we get our result.\n\nZ\nA\n!\nX\n4. Completing the Proof of Theorem 1.1. Fix z = u + iv â C+. We begin by\nâ\nseparating the convergence of F AN into two cases. Consider first the behavior of F XN TN XN .\na.s.\nâ\nIt is straightforward to verify n tr X XN -â 1, either by using Lemma 3.1 (with C = I),\nN\nâ\nor by just taking the fourth moment of n tr X XN - 1. This implies that, almost surely,\nN\nâ\nany vaguely convergent subsequence of F X X must be proper, or, in other words, the\nâ\nD\nsequence { F XN XN } is almost surely tight. Since F TN -â H a.s., it follows from the\nâ\nsecond inequality in Lemma 2.3 that, almost surely, { F XN TN XN } is tight.\nNow suppose A = 0, that is, almost surely, only o(N) eigenvalues of AN remain\nbounded. Let, for Hermitian C, | C| denote the matrix derived from C by replacing in its\nspectral decomposition the eigenvalues with their absolute values (the singular values of\nâ\nC). Writing AN = BN - XN TN XN , we have from the first inequality in Lemma 2.2\nâ\nF |AN |{ (x + y, inf )} â¤ F |BN |{ (x, inf )} + F |XN TN XN |{ (y, inf )}\na.s.\nfor non-negative x, y. It follows that for every x â¥ 0, F |BN |{ (x, inf )} -â 1, that is,\nv\nF BN -â 0 almost surely. Thus, the Stieltjes transforms of F AN and F BN converge almost\nsurely to zero, the limits obviously satisfying (1.1).\nWe assume for the remainder of the proof A 6 = 0. Using again the first inequality in\nâ\nv\nLemma 2.2 it follows that, whenever { F XN TN XN } is tight, and F BNi -â 0 on a subse\nv\nquence { Ni} , we have F ANi -â 0. Thus, { F BN } almost surely satisfies the conditions of\nLemma 2.8. Therefore, the quantity\nv dF BN (x)\nÎ´ = inf Im(mF BN ) â¥ inf\nN\n2(x2 + u2 ) + v2\nis positive almost surely.\nFor i = 1, 2, . . . , n, let qi (= qN ) denote the ith column of XN , B(i) = BN =\ni\n(i)\nâ\nBN - Ïiqiqi ,\nX\nÏi\nn\nN\nn\nx = xN =\n1 + ÏimF BN (z) and x(i) = x(i) =\nX\nÏj\nN\nN\n1 + Ïj m\nB(i) (z) .\ni=1\nj=1\nF\nNotice both Im x and Im x(i) are non-positive. Write BN - zI = AN - (z - x)I +\nâ - xI. Then\nXN TN XN\nâ\n(AN - (z - x)I)-1 = (BN - zI)-1 + (AN - (z - x)I)-1(XN TN XN - xI)(BN - zI)-1 ,\nand, using (2.2)\nn\nâ\n(4.1) mAN (z - x) - mBN (z) =\ntr (AN - (z - x)I)-1\nÏiqiq - xI (BN - zI)-1\nN\ni\ni=1\n\nA X\n!\nX\nÂ£\nÂ¤\nÂ£\nÂ¤\nÂ£\nÂ¤\n\nn\n= N tr (AN -(z-x)I)-1\nÏi\nâ\ni (B(i) -zI)-1 -x(BN -zI)-1\nâ\n1 + Ïiqi (B(i) -zI)-1qi\nqiq\ni=1\nn\n= N\n1 + ÏimF BN (z)\ni=1\nwhere di = dN\ni =\nÏi\ndi,\nâ\n1 + ÏimF BN (z)\nqi (B(i)-zI)-1(AN -(z-x)I)-1 qi-\ntr (BN -zI)-1(AN -(z-x)I)-1 .\nâ\n1 + Ïiqi (B(i) -zI)-1qi\nN\nNotice the norms of (BN - zI)-1,\n(B(i) - zI)-1,\n(AN - (z - x)I)-1,\nand\n\n(AN -(z -x(i))I)-1 are all bounded by 1/v. Using the fact that qi is independent of\nboth B(i) and x(i), we have by Lemma 3.1\nlog12 N\nâ\nK log12 N\nE| kqik2 -1|6 â¤ K\nE| i (B(i) -zI)-1 qi -\ntr (B(i) -zI)-1|6 â¤\n, and\nN 3\n,\nq\nv6\nN 3\nN\nâ\n6 â¤\nE|qi (B(i)-zI)-1(AN -(z-x(i))I)-1 qi-\ntr (B(i)-zI)-1(AN -(z-x(i))I)-1|\nK log12 N .\nv12\nN 3\nN\nThis is enough to ensure that, almost surely,\nâ\n| kqik2 -1|, |qi (B(i) -zI)-1 qi -m\n(4.2)\nF\nB(i) (z)|\nmax max\n,\niâ¤n\nâ\ni (B(i) -zI)-1(AN -(z -x(i))I)-1 qi -\ntr (B(i) -zI)-1(AN -(z -x(i))I)-1\nN\n| â 0.\n|q\nD\nWe concentrate now on a realization for which (4.2) holds, Î´ > 0, F TN -â H, and\nv\nF AN -â A. Lemma 2.6 gives us\nâ\ni (B(i) -zI)-1 qi|\n(4.3)\nmax max |mF BN (z) -m\nB(i) (z)|, |mF BN (z) -q\nF\nâ 0.\niâ¤n\nFor N large enough so that\nÎ´\nâ\n|Im mF BN (z) -Im m\nB(i) (z)|, |Im mF BN (z) -Im q i (B(i) -zI)-1 qi|\nF\nmax max\niâ¤n\n< 2 ,\nwe have for i, j â¤ n\n<\n1 + ÏimF BN (z)\nâ\n|mF BN (z) -qi (B(i) -zI)-1\n-1\nqi|,\nâ\n1 + Ïiqi (B(i) -zI)-1\nÎ´\nqi\nand\nÏj\nÏj\nB(i) (z)\nmF BN (z) -mF\n-\nâ¤ Î´2 |\n|.\n1 + Ïj mF BN (z)\n1 + Ïj m\nB(i) (z)\nF\n\nÂ·\n\nZ\nZ\nÂ¡\nÂ¢\nTherefore,\n1 + ÏimF BN (z)\n, |x - x(i)|\nâ 0.\n(4.4)\n- 1\nmax max\nâ\n1 + Ïiqi (B(i) - zI)-1qi\niâ¤n\nUsing Lemmas 2.6, 2.7, (4.2)-(4.4), we have maxiâ¤n di â 0, and since\nÏi\n1 + ÏimF BN (z)\nâ¤ ,\nÎ´\nwe conclude from (4.1) that\nmAN (z - x) - mBN (z) â 0\nConsider a subsequence {Ni} on which mF\nBNi (z) converges to a number m. Since\nÏ\nf(Ï) = 1 + Ïm\nis bounded, and\nÏ\n- f(Ï)\n(z) - m\nâ¤ Î´2 |\n|\nmF\nBNi\n,\n1 + ÏmF\nBNi (z)\nit follows that, along {Ni},\nso that\nÏdH(Ï)\n1 + Ïm ,\nx (= xNi ) â c\nÏdH(Ï)\n1 + Ïm .\nm = mA z - c\nTherefore, m is unique (MarËcenko and Pastur [4] or Section 5 below), and we must have\nmF BN (z) â m, an event which occurs with probability 1. Therefore, using (2.5), the proof\nis complete.\n\nZ\nR\n.\nZ\nR\nR\n.\nÎ¼\nZ\nÂ¶ Z\n\nR\n\nZ\n3R\nR\n\nR\nR\n=\nZ\nZ\nR\nR\n.\n\nZ\nZ\nR\nR\n\nZ\nZ\n\nR\n\nZ\nZ\n\nR\n\nZ\nR\n\nZ\n\n5. A Proof of Uniqueness. The following lemma renders the proof of Theorem 1.1\nto be free of any dependence on arguments involving p.d.e.'s.\nLemma 5.1. For z = z1 + iz2 â C+, there exists at most one m â C+ s.t.\ndA(Ï )\n(5.1)\nm =\nÎ»dH(Î»)\nÏ - z - c\n1+Î»m\nProof. For m = m1 + im2 â C+ satisfying (5.1) we have\ndA(Ï )\nÎ»(1+Î»m1 )dH (Î»)\nm =\nÎ»2 m2 dH(Î»)\nÏ - z1 + c\n- i z2 + c\n(1+Î»m1 )2 +Î»2 m\n(1+Î»m1 )2 +Î»2 m\nTherefore\n(5.2)\nm2 = z2 + c\nÎ»2m2dH (Î»)\ndA(Ï )\n.\n1 + Î»m\n|\n|\nÎ»dH (Î»)\nÏ - z + c\n1+Î»m\nSuppose m = m1 + im2 â C+ also satisfies (5.1). Then\n(5.3)\nm - m =\nÎ»dH(Î»)\nÎ»dH(Î») dA(Ï )\n1+Î»m\n-\n1+Î»m\nc\nÎ»dH(Î»)\nÎ»dH(Î»)\nÏ - z + c\nÏ - z + c\n1+Î»m\n1+Î»m\nÏ - z + c\nÎ»2dH (Î»)\ndA(Ï )\n(m - m)c\n(1 + Î»m)(1 + Î»m)\nÎ»dH (Î»)\nÎ»dH(Î»)\nÏ - z + c\n1+Î»m\n1+Î»m\nUsing H older's inequality and (5.2) we have\nÎ»2dH(Î»)\ndA(Ï )\nc\n(1 + Î»m)(1 + Î»m)\nÎ»dH (Î»)\nÎ»dH(Î»)\nÏ - z + c\nÏ - z + c\n1+Î»m\n1+Î»m\nâ\nâ\nâ\nâ\nâ\nâ\nâ \n1/2\nâ\nâ\nâ \nÎ»2dH (Î»)\nÎ»2dH(Î»)\ndA(Ï )\ndA(Ï )\nâ\nâ\nâ¤\nc\n1 + Î»m\n1 + Î»m|\n|\n|\n|\nÎ»dH(Î»)\nÎ»dH(Î»)\nÏ - z + c\nÏ - z + c\n1+Î»m\n1+Î»m\nâ\nâ\nâ\nâ \n1/2\nâ\nâ \n1/2\nÎ»2dH(Î»)\nÎ»2dH(Î»)\nm2\nm2\nâc\nâc\n< 1 .\n=\nR Î»2\n1 + Î»m\n1 + Î»m|\nÎ»2\nm2 dH(Î»)\n|\n|\n|\nm2 dH(Î»)\nz2 + c\nz2 + c\n|1+Î»m|\n|1+Î»m|\nTherefore, from (5.3) we must have m = m.\nc\n1/2\n\nREFERENCES\n[1] Fan, K. (1951). Maximum properties and inequalities for the eigenvalues of completely\ncontinuous operators. Proc. Nat. Acad. Sci. U.S.A. 37 760-766.\n[2] Grenander, U., and Silverstein, J.W. (1977). Spectral analysis of networks with random\ntopologies. SIAM J. Appl. Math. 32 499-519.\n[3] Jonsson, D. (1982). Some limit theorems for the eigenvalues of a sample covariance matrix.\nJ. Multivariate Anal. 12 1-38.\n[4] MarËcenko, V.A. and Pastur, L.A. (1967). Distribution of eigenvalues for some sets of ran\ndom matrices. Math. USSR-Sb. 1 457-483.\n[5] Silverstein, J.W. and Combettes, P.L. (1992). Signal detection via spectral theory of large\ndimensional random matrices. IEEE Trans. Signal Processing 40 2100-2105.\n[6] Wachter, K.W. (1978). The strong limits of random matrix spectra for sample matrices of\nindependent elements. Ann. Probab. 6 1-18.\n[7] Yin, Y.Q. (1986). Limiting spectral distribution for a class of random matrices. J. Multi\nvariate Anal. 20 50-68.\n[8] Yin, Y.Q., and Krishnaiah, P.K. (1984). A limit theorem for the eigenvalues of product of\ntwo random matrices. J. Multivariate Anal. 13 489-507."
    },
    {
      "category": "Resource",
      "title": "numrand_report.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/c6e176e20183778bacd89da6794237bf_numrand_report.pdf",
      "content": "18.325 - Random Matrices\nNumerical Methods for Random Matrices\nPerOlof Persson (persson@mit.edu)\nDecember 19, 2002\n\n(\n\nLargest Eigenvalue Distributions\nIn this section, the distributions of the largest eigenvalue of matrices in the\nÎ²ensembles are studied. Histograms are created first by simulation, then\nby solving the Painlev e II nonlinear differential equation.\n1.1\nSimulation\nThe Gaussian Unitary Ensemble (GUE) is defined as the Hermitian n Ã\nn matrices A, where the diagonal elements xjj and the upper triangular\nelements xjk = ujk + ivjk are independent Gaussians with zeromean, and\nVar(xjj) = 1,\n1 â¤j â¤n,\n(1)\nVar(ujk) = Var(vjk) = 2,\n1 â¤j < k â¤n.\nSince a sum of Gaussians is a new Gaussian, an instance of these matrices\ncan be created conveniently in MATLAB:\nA=randn(n)+i*randn(n);\nA=(A+A')/2;\nThe largest eigenvalue of this matrix is about 2ân. To get a distribution\nthat converges as n âinf, the shifted and scaled largest eigenvalue Î»0\nis\nmax\ncalculated as\nÎ»0\n= n\nmax\n6 Î»max -2ân\n\n.\n(2)\nIt is now straightforward to compute the distribution for Î»0\nby simula\nmax\ntion:\nfor ii=1:trials\nA=randn(n)+i*randn(n);\nA=(A+A')/2;\nlmax=max(eig(A));\nlmaxscaled=n^(1/6)*(lmax2*sqrt(n));\n% Store lmax\nend\n% Create and plot histogram\nThe problem with this technique is that the computational requirements\nand the memory requirements grow fast with n, which should be as large\nas possible in order to be a good approximation of infinity. Just storing\nthe matrix A requires n2 doubleprecision numbers, so on most computers\n\ntoday n has to be less than 104. Furthermore, computing all the eigenvalues\nof a full Hermitian matrix requires a computing time proportional to n .\nThis means that it will take many days to create a smooth histogram by\nsimulation, even for relatively small values of n.\nTo improve upon this situation, another matrix can be studied that has\nthe same eigenvalue distribution as A above. In [2], it was shown that this\nis true for the following symmetric matrix when Î² = 2:\nâ\nâ N(0, 2)\nÏ(n-1)Î²\nÏ(n-1)Î²\nN(0, 2)\nÏ(n-2)Î²\nHÎ² â¼ â\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ \n.\n(3)\n.\n.\n.\n.\n.\n.\n.\n.\n.\nÏ2Î²\nN(0, 2)\nÏÎ²\nÏÎ²\nN(0, 2)\nHere, N(0, 2) is a zeromean Gaussian with variance 2, and Ïd is the square\nroot of a Ï2 distributed number with d degrees of freedom. Note that the\nmatrix is symmetric, so the subdiagonal and the superdiagonal are always\nequal.\nThis matrix has a tridiagonal sparsity structure, and only 2n double\nprecision numbers are required to store an instance of it.\nThe time for\ncomputing the largest eigenvalue is proportional to n, either using Krylov\nsubspace based methods or the method of bisection [7].\nIn MATLAB, the builtin function eigs can be used, although that re\nquires dealing with the sparse matrix structure. There is also a large amount\nof overhead in this function, which results in a relatively poor performance.\nInstead, the function maxeig is used below to compute the eigenvalues.\nThis is not a builtin function in MATLAB, but it can be downloaded from\nhttp://www.mit.edu/~persson/mltrid. It is based on the method of bi\nsection, and requires just two ordinary MATLAB vectors as input, corre\nsponding to the diagonal and the subdiagonal.\nIt also turns out that only the first 10n\ncomponents of the eigenvector\ncorresponding to the largest eigenvalue are significantly greater than zero.\nTherefore, the upperleft ncutoff by ncutoff submatrix has the same largest\neigenvalue (or at least very close), where\nncutoff â 10n\n3 .\n(4)\nMatrices of size n =\n1012 can then easily be used since the computations can\n105. Also, for these large values of\nbe done on a matrix of size only 10n 3 =\nn the approximation Ï2\nn â n is accurate.\n\nA histogram of the distribution for n = 109 can now be created using\nthe code below.\nn=1e9;\nnrep=1e4;\nbeta=2;\ncutoff=round(10*n^(1/3));\nd1=sqrt(n1:1:n+1cutoff)'/2/sqrt(n);\nls=zeros(1,nrep);\nfor ii=1:nrep\nd0=randn(cutoff,1)/sqrt(n*beta);\nls(ii)=maxeig(d0,d1);\nend\nls=(ls1)*n^(2/3)*2;\nhistdistr(ls,7:0.2:3)\nwhere the function histdistr below is used to histogram the data.\nIt\nassumes that the histogram boxes are equidistant.\nfunction [xmid,H]=histdistr(ls,x)\ndx=x(2)x(1);\nH=histc(ls,x);\nH=H(1:end1);\nH=H/sum(H)/dx;\nxmid=(x(1:end1)+x(2:end))/2;\nbar(xmid,H)\ngrid on\nThe resulting distribution is shown in Figure 1, together with distribu\ntions for Î² = 1 and Î² = 4. The plots also contain solid curves representing\nthe \"true solutions\" (see next section).\n1.2\nPainlev e II\nInstead of using simulation to plot the distributions of the largest eigen\nvalues, it can be computed from the solution of the Painlev e II nonlinear\ndifferential equation [6]:\nq00 = sq + 2q\n(5)\n\n-6\n-4\n-2\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nNormalized and Scaled Largest Eigenvalue\nProbability\nÎ²=1\n-6\n-4\n-2\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nNormalized and Scaled Largest Eigenvalue\nProbability\nÎ²=2\n-6\n-4\n-2\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nNormalized and Scaled Largest Eigenvalue\nProbability\nÎ²=4\nFigure 1: Probability distribution of scaled largest eigenvalue (105 repeti\ntions, n = 109)\nwith the boundary condition\nq(s) â¼Ai(s),\nas s âinf.\n(6)\nThe probability distribution f2(s), corresponding to Î² = 2, is then given by\nd\nf2(s) = ds F2(s),\n(7)\nwhere\nF2(s) = exp\n\n-\nZ inf\n(x -s)q(x)2 dx\n\n.\n(8)\ns\nThe distributions for Î² = 1 and Î² = 4 are the derivatives of\nR inf\ns\nF1(s)2 = F2(s)e-\nq(x) dx\n(9)\nand\n!2\nR\nR\n\ninf\ns\ne-1\ninf\ns\nq(x) dx\nq(x) dx +\ns\ne\nF2(s)\n(10)\nF4\n=\n.\nTo solve this numerically using MATLAB, first rewrite (5) as a firstorder\nsystem:\nd\nq\nq0\n=\nds\nq0\nsq + 2q3\n.\n(11)\n\nR\nZ\nR\nR\nR\nThis can be solved as an initialvalue problem starting at s = s0 = suf\nficiently large positive number, and integrating along the negative saxis.\nThe boundary condition (6) then becomes the initial values\nq(s0)\n=\nAi(s0)\nq0(s0)\n=\nAi0(s0).\n(12)\nAlthough the distributions can be computed from q(s) as a postprocessing\nstep, it is most convenient to add a few variables and equations to the ODE\n(x - s)q(x)2 dx is\ninf\ns\nsystem. When computing F2(s), the quantity I(s) =\nrequired. Differentiate this twice to get\nI 0(s) = -\ns\ninf\nq(x)2 dx\n(13)\nand\nI00(s) = q(s)2 .\n(14)\nAdd these equations and the variables I(s), I0(s) to the ODE system, and\nthe solver will do the integration. This is not only easier and gives less code,\nit will also give a much more accurate solution since the same tolerance\nrequirements are imposed on I(s) as on the solution q(s).\nIn a similar way, the quantity J(s)\ninf\ns\nq(x) dx is needed when com\n=\nputing F1(s) and F4(s). This is handled by adding the variable J(s) and\nthe equation J0(s) = -q(s).\nThe final system now has the form\nâ\nâ\nâ\nâ q\nq0\nd\nds\nâ\nâ\nâ\nâ\nâ\nq0\nI\nI0\nâ\nâ\nâ\nâ\nâ \n=\nâ\nâ\nâ\nâ\nâ\nsq + 2q â\nâ\nâ\nâ\nâ \n(15)\nI\nq\nJ\n-q\nwith the initial condition\nâ\nâ\nâ\nâ\nAi(s0)\nq(s0)\nAi0(s0)\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ \n=\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ \nq0(s0)\nI(s0)\nI0(s0)\ninf\ns0 (x - s0)Ai(x)2 dx\nAi(s0)2\n(16)\n.\ninf\ns0\nJ(s0)\nAi(x) dx\nThis problem can be solved in just a few lines of MATLAB code using the\nbuiltin RungeKutta based ODE solver ode45. First define the system of\nequations as an inline function\n\ndeq=inline('[y(2); s*y(1)+2*y(1)^3; y(4); y(1)^2; y(1)]','s','y');\nNext specify the integration interval and the desired output times.\ns0=5;\nsn=8;\nsspan=linspace(s0,sn,1000);\nThe initial values can be computed as\ny0=[airy(s0); airy(1,s0); ...\nquadl(inline('(xs0).*airy(x).^2','x','s0'),s0,20,1e25,0,s0); ...\nairy(s0)^2; quadl(inline('airy(x)'),s0,20,1e18)];\nwhere the quadl function is used to numerically approximate the integrals\nin (16). Now, the integration tolerances can be set and the system inte\ngrated:\nopts=odeset('reltol',1e13,'abstol',1e15);\n[s,y]=ode45(deq,sspan,y0,opts);\nThe five dependent variables are now in the columns of the MATLAB vari\nable y. Using these, F2(s), F1(s), and F4(s) become\nF2=exp(y(:,3));\nF1=sqrt(F2.*exp(y(:,5)));\nF4=sqrt(F2).*(exp(y(:,5)/2)+exp(y(:,5)/2))/2;\ns4=s/2^(2/3);\nThe probability distributions f2(s), f1(s), and f4(s) could be computed by\nnumerical differentiation:\nf2=gradient(F2,s);\nf1=gradient(F1,s);\nf4=gradient(F4,s4);\nbut it is more accurate to first do the differentiation symbolically:\nf2(s) = -I0(s)F2(s)\nf1(s) =\n2F1(s) (f2(s) + q(s)F2(s)) e-J(s)\n\n(17)\n(18)\n\nf4(s)\nf2(s) 2 +\nJ(s) + e-J(s)\ne-J(s)\nJ(s)\n+ F2(s)q(s)\n=\ne\n- e\n3 4F4(s)\n(19)\nand evaluate these expressions:\n\n-8\n-6\n-4\n-2\n-0.1\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\ns\nfÎ²(s)\nÎ²=1\nÎ²=2\nÎ²=4\nFigure 2: The probability distributions f1(s), f2(s), and f4(s), computed\nusing the Painlev e II solution.\nf2=y(:,4).*F2;\nf1=1/2./F1.*(f2+y(:,1).*F2).*exp(y(:,5));\nf4=1/2^(1/3)/4./F4.*(f2.*(2+exp(y(:,5))+exp(y(:,5)))+ ...\nF2.*y(:,1).*(exp(y(:,5))exp(y(:,5))));\nFinally, plot the curves:\nplot(s,f1,s,f2,s4,f4)\nlegend('\\beta=1','\\beta=2','\\beta=4')\nxlabel('s')\nylabel('f_\\beta(s)','rotation',0)\ngrid on\nThe result can be seen in Figure 2.\n\nq\nEigenvalue Spacings Distributions\nAnother quantity with an interesting probability distribution is the spacings\nof the eigenvalues of random matrices. It turns out that the eigenvalues are\nalmost uniformly distributed, which means that every random matrix gives a\nlarge number of spacings. The distributions can then be efficiently computed\nby simulation.\nTwo other methods are used to compute the spacings distribution - the\nsolution of the Painlev e V nonlinear differential equation and the eigenvalues\nof the Prolate matrix. Finally, the results are compared with the spacings\nof the zeros along the critical line of the Riemann zeta function.\n2.1\nSimulation\nAs before, the simulations are made with matrices from the Gaussian Uni\ntary Ensemble. The normalized spacings of the eigenvalues Î»1 â¤ Î»2 â¤ . . . â¤\nÎ»N are computed according to\nÎ´0 = Î»k+1 - Î»k\n2Î²n - Î»2\nk,\nk â n/2,\n(20)\nk\nÏÎ²\nwhere Î² = 2 for the GUE. The distribution of the eigenvalues is almost\nuniform, with a slight deviation at the two ends of the spectrum. Therefore,\nonly half of the eigenvalues are used, and one quarter of the eigenvalues at\neach end is discarded.\nAgain, to allow for a more efficient simulation, the tridiagonal matrix (3)\nis used instead of the full Hermitian matrix. In this case, all the eigenvalues\nare computed, which can be done in a time proportional to n2. While this\ncould in principle be done using the MATLAB sparse matrix structure and\nthe eigs function, the more efficient trideig function is used below to\ncompute all the eigenvalues of a symmetric tridiagonal matrix. It can be\ndownloaded from http://www.mit.edu/~persson/mltrid.\nThe histogram can now be computed by simulation with the following\nlines of code. Note that the function chi2rnd from the Statistics Toolbox\nis required.\nn=1000;\nnrep=1000;\nbeta=2;\nds=zeros(1,nrep*n/2);\nfor ii=1:nrep\nl=trideig(randn(n,1),sqrt(chi2rnd((n1:1:1)'*beta)/2));\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nNormalized Consecutive spacings\nProbability\nRandom Matrix Eigenvalue Distribution\nFigure 3: Probability distribution of consecutive spacings of random matrix\neigenvalues (1000 repetitions, n = 1000)\nd=diff(l(n/4:3*n/4))/beta/pi.*sqrt(2*beta*nl(n/4:3*n/41).^2);\nds((ii1)*n/2+1:ii*n/2)=d;\nend\nhistdistr(ds,0:0.05:5);\nThe resulting histogram can be found in Figure 3. The figure also shows the\nexpected curve as a solid line.\n2.2\nPainlev e V\nThe probability distribution p(s) for the eigenvalue spacings when Î² = 2\ncan be computed with the solution to the Painlev e V nonlinear differential\nequation (see [5] for details):\n(tÏ00)2 + 4(tÏ0 - Ï) tÏ0 - Ï + (Ï0)2 = 0\n(21)\n\n=\np\nZ\nZ\n\nwith the boundary condition\n\nt\nt\n,\nas t â0+ .\n(22)\nÏ(t) â- Ï -\nÏ\nThen p(s) is given by\nd2\np(s) =\nE(s)\n(23)\nds2\nwhere\nZ Ïs Ï(t)\nE(s) = exp\ndt\n.\n(24)\nt\nExplicit differentiation gives\np(s) =\n2 ÏsÏ0(Ïs) -Ï(Ïs) + Ï(Ïs)2 E(s).\n(25)\ns\nThe secondorder differential equation (21) can be written as a firstorder\nsystem of differential equations:\nd\nÏ\nÏ0\ndt\nÏ0\n-t\n(Ï -tÏ0) (tÏ0 -Ï + (Ï0)2)\n.\n(26)\nThis is solved as an initialvalue problem starting at t = t0 = very small\npositive number. The value t = 0 has to be avoided because of the division\nby t in the system of equations. This is not a problem, since the boundary\ncondition (22) provides an accurate value for Ï(t0) (as well as E(t0/Ï)). The\nboundary conditions for the system (26) then become\n(\nt0\nt0\nÏ(t0)\n= -Ï -\nÏ\n(27)\nÏ0(t0)\n= -\nÏ .\nÏ -2t0\nTo be able to compute E(s) using (24), the variable\nt Ï(t0)\nI(t) =\ndt0\n(28)\nt0\nÏ\nis added to the system, as well as the equation d I = t . The corresponding\ndt\ninitial value is\nt0\nt\nt0\nt2\nI(t0) â\n(29)\n-Ï -Ï2\ndt = -Ï -2Ï\n2 .\n\nPutting it all together, the final system is\nâ\nâ\nâ\nâ\nÏ\nÏ0\nd\np\nâ\nâÏ0â  =\n-\n(Ï - tÏ0) (tÏ0 - Ï + (Ï0)2)â \n(30)\nt\ndt\nI\nÏ\nt\nwith boundary condition\nâ\nâ\nâ\n2 â\nt0\nÏ\nÏ(t0)\nâ- t\nÏ\n-\n2t0 â\nâÏ0(t0)â  = â - Ï -\nt2\nâ  .\n(31)\nÏ\nI(t0)\n2Ï2\n- t\nÏ\n0 -\nThis system is defined as an inline function in MATLAB:\ndesig=inline(['[y(2); 2/t*sqrt((y(1)t*y(2))*' ...\n'(t*y(2)y(1)+y(2)^2)); y(1)/t]'],'t','y');\nSpecify the integration interval and the desired output times:\nt0=1e12;\ntn=16;\ntspan=linspace(t0,tn,1000);\nSet the initial condition:\ny0=[t0/pi(t0/pi)^2; 1/pi2*t0/pi; t0/pit0^2/2/pi^2];\nFinally, set the integration tolerances and call the solver:\nopts=odeset('reltol',1e13,'abstol',1e14);\n[t,y]=ode45(desig,tspan,y0,opts);\nThe solution components are now in the columns of y. Use these to evaluate\nE(s) and p(s):\ns=t/pi;\nE=exp(y(:,3));\np=1./s.^2.*E.*(t.*y(:,2)y(:,1)+y(:,1).^2);\np(1)=2*s(1); % Fix due to cancellation\nA plot of p(s) can be made with the command\nplot(s,p)\ngrid on\nand it can be seen in Figure 4. Plots are also shown of E(s) and Ï(t).\n\nQ\n-70\n-60\n-50\n-40\n-30\n-20\n-10\nt\nÏ(t)\n0.2\n0.4\n0.6\n0.8\ns\nE(s), p(s)\nFigure 4: Painlev e V (left), E(s) and p(s) (right).\n2.3\nThe Prolate Matrix\nAnother method to calculate the distribution of the eigenvalue spacings is\nto compute the eigenvalues Î»i of the operator\nZ 1\nf(y) â\nQ(x, y)f(y) dy,\nQ(x, y) = sin ((x - y)Ït) .\n(32)\n(x - y)Ï\n-1\nThen E(2t) =\ni(1 - Î»i), and p(s) can be computed as before. To do this,\nfirst define the infinite symmetric Prolate matrix:\nâ\nâ\na0\na1\n. . .\n=\ninf\nâ\nâ\nâ\nâ \n(33)\na1\na0\n. . .\nA\n.\n.\n.\n.\n.\n.\n.\n.\n.\n=\nwith a0 = 2w, ak = (sin 2Ïwk)/Ïk for k\n1, 2, . . ., and 0 < w < . A\ndiscretization of Q(x, y) is achieved by setting w = t/n and extracting the\nupperleft n Ã n submatrix An of Ainf.\nBelow, the full matrix An is used, and all the eigenvalues are computed\nin n3 time using the eig function. However, An commutes with the following\nsymmetric tridiagonal matrix [4], and therefore has the same eigenvectors:\nâ\nâ Î±1\nÎ²1\nÎ²1\nÎ±2\nÎ²2\nTn =\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ \n(34)\n.\n.\n.\n.\n.\n.\n.\n.\n.\nÎ²n-2 Î±n-1\nÎ²n-1\nÎ²n-1\nÎ±n\n\nwhere\n\nÎ±k\n=\nn+1\ncos 2Ïw\n- k\nÎ²k\n=\n2k(n - k).\n(35)\nIt is then in principle possible to use the new techniques described in [1] to\ncompute all the eigenvalues and eigenvectors of Tn in n2 time, and then get\nthe eigenvalues of An by dot products. This is not done in this example.\nThe code for computing E(s) is shown below. This time, p(s) is evaluated\nby numerical differentiation since no information about the derivative of\nE(s) is available.\ns=0:0.01:5;\nn=100;\nE0=zeros(size(s));\nfor ii=1:length(s)\nQ=gallery('prolate',n,s(ii)/2/n);\nE0(ii)=prod(1eig(Q));\nend\np0=gradient(gradient(E0,s),s);\nTo improve the accuracy in E(s), Richardson extrapolation can be used.\nThis is done as follows, where the values are assumed to converge as 1/n2:\n% ... Compute s and E using Painleve V in previous section\nEs=zeros(length(t),0);\nE1=zeros(size(s));\nfor n=20*2.^(0:3)\nfor ii=1:length(s)\nQ=gallery('prolate',n,s(ii)/2/n);\nE1(ii)=prod(1eig(Q));\nend\nEs=[Es,E1];\nend\nfor ii=1:3\nmax(abs(EsE(:,ones(1,size(Es,2)))))\nEs=Es(:,2:end)+diff(Es,1,2)/(2^(ii+1)1);\nend\nmax(abs(EsE))\nThe errors max0â¤sâ¤5 E1(s) - E(s) are shown in Table 1, for n = 20, 40, 80,\n|\n|\nand 160. The error after all extrapolations is of the same order as the \"exact\nsolution\" using Painlev e V.\n\nN\nError 0\nError 1\nError 2\nError 3\n0.2244\n0.0561\n0.7701\n0.0140\n0.0483\n0.5486\n0.0035\n0.0032\n0.0323\n2.2673\nÂ·10-3\nÂ·10-7\nÂ·10-8\nÂ·10-11\nTable 1: Difference between Prolate solution E1(s) and Painlev e V solution\nE(s) after 0, 1, 2, and 3 Richardson extrapolations.\n2.4\nRiemann Zeta Zeros\nIt has been observed that the zeros of the Riemann zeta function along the\ncritical line Re(z) = 2 behave similar to the eigenvalues of random matrices\nin the GUE. Here, the distribution of the scaled spacings of the zeros is\ncompared to the corresponding distribution for eigenvalues computed using\nthe Painlev e V equation from the previous chapters.\nDefine the nth zero Î³n = nth as\nÎ¶\n+ iÎ³n\n= 0,\n0 < Î³1 < Î³2 < . . .\n(36)\nCompute a normalized spacing:\nÎ³n\nlog Î³n/2Ï\nÎ³n = av spacing near Î³n\n= Î³n Â·\n2Ï\n.\n(37)\nZeros of the Riemann zeta function can be downloaded from [3]. Assum\ning that the MATLAB variable gamma contains the zeros, and the variable\noffset the offset, these two lines compute the consecutive spacings\nÎ³\nÎ³n+1 - n\nand plot the histogram:\ndelta=diff(gamma)/2/pi.*log((gamma(1:end1)+offset)/2/pi);\nhistdistr(delta,0:0.05:5.0);\nThe result can be found in Figure 5, along with the Painlev e V distribution.\nThe curves are indeed in good agreement, although the number of samples\nhere is a little to low to get a perfect match.\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nNormalized Consecutive spacings\nProbability\nRiemann Zeta Zero Distribution\nFigure 5: Probability distribution of consecutive spacings of Riemann zeta\nzeros (30, 000 zeros, n â 1012 , 1021 , 1022)\n\nReferences\n[1] I. Dhillon. A new algorithm for the symmetric tridiagonal eigenvalue/\neigenvector problem, 1997. PhD. thesis, University of California, Berke\nley.\n[2] Ioana Dumitriu and Alan Edelman. Matrix models for beta ensembles.\nJournal of Mathematical Physics, 2002.\n[3] Andrew Odlyzko.\nTables of zeros of the riemann zeta function.\nhttp://www.dtc.umn.edu/~odlyzko/zeta tables/index.html.\n[4] D. Slepian. Prolate spheroidal wave functions, Fourier analysis, and\nuncertainty V: The discrete case.\nTechnical Report 57, Bell System\nTech. J., 1978.\n[5] Craig A. Tracy and Harold Widom. Introduction to random matrices.\nIn \"Geometric and Quantum Aspects of Integrable Systems\" (Ed. G.\nF. Helminck), Lecture Notes in Physics 424 (1993) 103130, Springer\nVerlag.\n[6] Craig A. Tracy and Harold Widom. The distribution of the largest\neigenvalue in the Gaussian ensembles. In \"CalogeroMoserSutherland\nModels\" (Ed. J.F. van Diejen, L. Vinet), CRM Ser. in Math. Phys. (4),\nSpringerVerlag, New York, 2000, 461-472.\n[7] Lloyd N. Trefethen and David Bau. Numerical Linear Algebra. SIAM,\n1997."
    },
    {
      "category": "Resource",
      "title": "peters.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/d56121d44665a6d7c32ad9c30369b4a6_peters.pdf",
      "content": "!\n\n\"\n#\n\n\"\n\"$\n\n!\n\n#\n\n\"\n\"\n\n\"\n\n%\"\n\"$\n\n#\n\n\"\n\n#\n\n#\n%\n\n#\"\n#\n$\n\n!\n\n\"\n\n&\n\n'\n\n%\"\n\"\n\n\"\n\n(\n$\n)\n\n#\"\n#\n\n\"\n#%\n\n#\n\n*\n\n\"\n\n\"\n\n\"\n#\n\n!\n!\n%\n$\n\n*\n\n%\n\n#\"\n#\n\n#\n\n\"\n\"$\n\n\"\n\n\"\n\n#\n\n!\n#\n#\n\n#\"\n\n\"\n\n\"\n\n\"\n&#\n\n'\n\n\"\n\n\"$\n\n!\n\n\"\n\n#\n$\n\n#\n\n$\n#\n\n#\n\n#\"\"\n\n+\"\n\n\"\n\n%\n\n,\"\n\n-\n$\n\n#\n&#'\n.#\n/001$\n\n%\n\n&\n\n\"\n\n&\n\n'\n\n(\n\n)\n\n')\n\n)\n\n*\n\n')\n\n+\n\n\"\n\n\"\n\n,\n\n)'\n\n&\n\n)\n\n-\n\n\"\n\n.\n\n/\n\n!\n\"\n\n/\n\n')\n\n$\n\n!\n\n\"\n\n!\n\n%\n\n)\n\n/\n\n)\n\n!\n\n$\n\n!\n\n)\n\n)\n\n%\n\n!\n\n)\n\n'\n\n)\nÃ\n\n&\n\n!\n\n!\n\n+\n\n&\n\n%\n\n!\n\n!\n\n\"\n\n.\n\n$\n\n!\n\n\"\n\n\"\n\n/\n\n\"\n\n%\n\n)\n\n:\n\n&\n\n\"\n\n(\n\n\"\n\n\"\n\n;\n!\n\n+\n\n!\n\n+\n\n&\n\n\"\n\n!\n\n%\n\n&\n\n'\n%\n\n#\n<\n\n#\n&\n\n=\n\"\n\n'\n\n)\n\n&\n\n)\n>\n\n)\n\n)\n\n)\n\n)\n\n)\n>\n\n)\n\n?\n\n/\n\n(\n\n!\n\n/\n\n/\n\n)\n>\n\n)\n\n)\n>\n\n/\n\n)\n\n@\n\n.\n\n/\n\n&\n\n!\n\n\"\n\n!\n\n\"\n\n/\n\n(\n\n(\n\n!\n\n$\n\n$\n\n$\n\n&\n\n/\n\n#!\n\n$\n\n##!\n%&\n'(\n\n)\n)!\n\n/\n\nA\n\n/\n\n&\n\n&\n\n&\n\n&\n\n!\n\n\"\n\n&\n\n&\n\n8B\nC\n\n879 A\n\n!\n\n.\n8:\n;\n=9\n\n8>\n\n8:\n\"\n.\n\n')\n\n)\n\n!\n\n)\n\n)\n\nA\n\n)\n\n)\n\n%\n\n\"\n\n.\n\n'\n&\n\n&\n\nD\n\n!\n%\n\nA\n\n2 3\n\n)\n\n:\n;\n&\n\n:\n;\n\n)\n\n;\n:\nï¿½\n\n:\n;\n\n)\n\n;\n:\nï¿½\n\n/\n\nA\n\n)\n\nF\n\n)\nF\n\n'\n\n\"\n\nA\n\n)\n\n@\n\n@\n\n>\n\n@\n\n@\n\n@\n\n)\n\n@\n\nG\n'\n&\n\n:\n;\n=\n?\nB\nC\n>\n\n>\n;\nC\n:\n=\n?\nB\nï¿½\n\n>\n;\nC\nï¿½\n\n;\n:\n\n/\n\n;\nï¿½\n\n-\n\n)\n\n\"\n\n4:\n\"\n\n'\n\n%\n\n/\n\n'\n\n'\n\n)\n\n\"\n\n'\n\n')\n\n)\n\n')\n\n)\n\n4;\n\n!\n\n0'\n\n)\n\n@\n\nG\n'\n\n)\n\n)\n\n)\n\n)\n\n)\n\n)\n\n@\n\n)\n\n@\n\n)\n\n)\n\n)\n\n@\n\n@\n\n@\n\n@\n\n)\n\n@\n\n@\n\n@\n\n@\n\n)\n\n@\n\n)\n:\n\n)\n>\n&\n\n)\n\n:\n&\n\n&\n\n4=\n$\n\n&\n\n'\n\n'\n%\n\n'\n\n)\n>\n\n)\n\n4?\n\n.\n\n)\n>\n\n/\n\n!\n\n@\n\n)\n>\n&\n\n!\n\n(\n\n!\n\nH\n\n&\n\n(\n\n/\n\nH\n\n</\n4:\n$\n\n(\n\n)\n\n)\n\n)\n\n)\n>\n&3\n\n'\n\n\"\n\n2 3\nI\n\n(\n\n*\n#!\n\n')\n\n$\n\n&\n\n)\n\n@\n\n%\n\n)\n\n@\n\n@\n\n)\n\n@\n\n)\n\n@\n\n&\n4=\n&\n\nA\n\n\"\n\n$\n\n/\n\n(\n\n&\n\n)\n\n')\n\n)\n\nG\n'\n\n)\n\n)\n\n@\n\n@\n\n@\n\n@\n\n)\n\n@\n\n@\n\n&\n\n7:\n$\n\n!\n\n')\n\n@\n\n!\n\n!\n\n')\n\n@\n\n!\n\n&\n\n'\n\n%\n\n)\n\n)\n\n%\n\n')\n\n)\n\n%\n\n8!\n\n!\n)\n\n!\n\n%\n\n)\n\n/\n\n/\n\n\"\n\n\"\n\n\"A\n\n'\n\n)\n\nJ\n\n)\n\n)\n\n)\n\n)\n\n)\n\n'\n\n&\n\n')\n\n@\n\nI\n\n)\n\nï¿½\n\nï¿½\n\n@\n\n@\n\n)\n\nï¿½\n\nï¿½\n\n)\n\nï¿½\n\nï¿½\n\n)\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\n)\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\n)\n\n)\n\n')\n\n&\n\n)\n\n%\n\n')\n\n')\n'\n\n!\n\n)\n@\n!\n\n)\n@\n\n!\n\n!\n\n!\n\n)\n@\n\n!\n\n!\n\n)\n\n8!\n\n!\n&\n\n,\n\n/\n\n!\n\n')\n!\n\n\"\n\n\"\n!\n\n')\n\n!\n\n7;\n!!%\n&\n\n!\n\n\"\n\n\"\n!\n\n8\"\n!\n\n@\n)\n!\n\n!\n\n%\n\n!\n\n!\n\n!\n\n&\n7:\n\n!\n\n\"\n!\n\n#\n!\n\n)\n\"\n!\n\n@\n\n'\n\n!\n\n)\n\n!\n!\n\n!\n\n!\n\n)\n@\n!\n\" !\n\n)\n!\n#\n!\n\n#\n!\n\n)\n\n!\n&\n\n#\n8!\n)\n\n8!\n)\n\n)\n\n)\n!\n\n!\n\n!\n\n!\n!\n!\n\n!\n\n#\n8!\n\n)\n!\n\n8\"\n!\n\n@\n)\n8#\n!\n\n)\n!\n\n!\n7=\n\n*\n!)\n&\n\n@\n\n)\n\n&\n\n\"\n\n\"\n\n(\n\n')\n\n(\n\n)\n\n@\n\n\"\n\n\"\n\n\"\n\n(\n\n\"\n\n@\n\n\"\n\n)\n\"\n\n@\n\"\n\n\"\n\n7;\n\n,\n!\n\n\"\n\n)\n\nÃ\n\n@\nÃ\n\n7?\n!&\n\n)\n\n8?9\n\n$\n\n&\n\n,\n\n)\n\n%\n\n)\n$\n\n&\n\n')\n'\n\n'\n\n'\n\nI\n\nI\n\n$\n\n&\n\n/\n\n&\n\n(\n\n$\n\n&\n\n'\n%\n\n@\n&\n\n@\n&\n\n#\n.\n\n&\n\n&\n\n)\n\n)\n$\n\n&\n\n\"\n\n@\n&\n\n@\n\n-\n\n@\n\n\"\n\n\"\n\n!\n\n)\n$\n)\n\nÃ\n\n@\nÃ\n\n>\n\n>\n\n>\n\n'\n@\n'\n\n>\n\n:\n)! !\n\n*\n#!\n\n/\n\n'\n\n%\n\n:\n\n.\n\n/\n\n)\n\n')\n\n')\n\n)\n\nG\n'\n\n)\n\n)\n\n)\n\n)\n\n)\n\n(\n\n&\n\n(\n\n\"\n\n(\n\n\"\n\n(\n\n/\n\n\"\n\nG\n'\n\n:\n;\n=\n\n;\n=\n:\n%\n\n(\n\n)\n\n)\n\n%\n\n%\n\n)\n\n,\n\n&\n4=\n\n\"\n\n-\n\n)\n\n;\n\n:\n=\n\n&\n\n)\n\n)\n\n/\n\n(\n\n(\n\n(\n\n:4\n\"\n\nï¿½\n\nï¿½\n\nï¿½\nï¿½\n\nï¿½\n\n%\n\n/\n\n#\n\n(\n\nï¿½\n\nï¿½\n\n(\n\nï¿½\n\nï¿½\n\n\"\n\n(\n\nï¿½\n\nï¿½\n\n&\n\nD\n\n%\n\n/\n\n'\n\n)\n\n)\n\n&\n\n:7\n$\n\n&\n\n)\n\n,\n\nI\n\n\"\n\n,\n\n/\n\n::\n!&\n\n,\n7?\n\n')\n'\n\n'\n\n&\n\n'\n\n!\n\n')\n\n>\n\n>\n\n/\n\n>\n\n&\n\n\"\n\nI\n\n(\n\n\"\n\n!\n\n&\n\n(\n\n!\n\n)\n\n&\n/\n\n!\n\n)\n\n)\n\n)\n\n)\n\n#\n\n\"\n\n#\n\n%\n\n\"\n\n@\n#\n\n)\n\n@\n\n&\n\n&\n:7\n\n)\n\n)\n\n)\n\n-\n\n\"\n\n(\n\n)\n\n)\n\n)\n\n)\n\n&\n\n(\n\nG\n\n\"\n\n)\n\nÃ\n\n@\nÃ\n\n(\n\n!\n\n1$\n$\n\n$\n\n&,\"\n#!\n\n,\n$\n44'\n,\n/000$\n/$\n5$\n\n,$\n\n&174/'\n88898:0$\n8$\n$\n\n.$\n\n#$\n$\n\n&177;'\n/419/7;$\n<$\n$\n\n$\n\n&\n\n$\n##'\n\"$\n.$\n,$\n\n&177;'\n4779=84$\n:$\n$\n\n$\n\n)\n&$%3$\n##\n$'\n,\n$\n1<791==$\n;$\n$\n\n$\n\n#>\n\n,$\n.$\n\n&177='\n::89:7/$\n4$\n$\n\n,\n\n&1778'\n48194<<$\n=$\n$\n\n,$\n$\n\n&177<'\n;119;/=$\n7$\n$\n\n,\"\n\n,\n\n&177='$\n10$\n$\n##\n!\n\n.$\n\n#$\n$\n\n&17=;'\n8/898<;$\n11$\n$\n##\n\"\n\n!\n\n$\n\"$\n\n&1771'\n/019//0$\n1/$\n$\n##\n\n#\n\n$\n\n,\n177<\n?>@\n#\n177:\n$\n//49/<1$\n18$\n$\n##\n&$'\n\n%\n\n&\n#\n\n\"\"\n#\n!\n$\n1/'\n,\n1774$\n1<$\n$3$\n##\n6$.$\n>\n\"\n\n$\n\n&\n\n'\n\n&\n,\n,\n\n!\n$\n1'\n,\n1778$\n\n!\"\n#\n\n(\n\nA"
    },
    {
      "category": "Resource",
      "title": "tools.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/de114a16f14f07511027bd02fc2a003a_tools.pdf",
      "content": "Advances in Random Matrix Theory:\nLet there be tools\nAlan Edelman\nMIT: Dept of Mathematics,\nComputer Science AI Laboratories\nWorld Congress, Bernoulli Society\nBarcelona, Spain\nWednesday July 28, 2004\n2/1/2005\nBrian Sutton, Plamen Koev,\nIoana Dumitriu,\nRaj Rao and others\n\nMessage\nIngredient: Take Any important mathematics\nThen Randomize!\nThis will have many applications!\nWe can't keep this in the hands of specialists\nanymore: Need tools!\n2/1/2005\n\nTools\nSo many applications ...\nRandom matrix theory: catalyst for 21st century\nspecial functions, analytical techniques, statistical\ntechniques\nIn addition to mathematics and papers\nNeed tools for the novice!\nNeed tools for the engineers!\nNeed tools for the specialists!\n2/1/2005\n\nThemes of this talk\nTools for general beta\nWhat is beta? Think of it as a measure of (inverse)\nvolatility in \"classical\" random matrices.\nTools for complicated derived random matrices\nTools for numerical computation and simulation\n2/1/2005\n\nPrecise statements require nâinfetc.\n\nLet S = random symmetric Gaussian\nMATLAB: A=randn(n); S=(A+A')/2;\nS known as the Gaussian Orthogonal Ensemble\n\nn=20; s=30000; d=.05;\ne=[];\n%gather up eigenvalues\nim=1;\n%imaginary(1) or real(0)\nfor i=1:s,\nv=eig(a)'; e=[e v];\nend\naxis('square'); axis([-1.5 1.5 -1 2]); hold on;\nt=-1:.01:1; plot(t,sqrt(1-t.^2),'r');\nWigner's Semi-Circle\nThe classical & most famous rand eig theorem\nNormalized eigenvalue histogram is a semi-circle\n%matrix size, samples, sample dist\na=randn(n)+im*sqrt(-1)*randn(n);a=(a+a')/(2*sqrt(2*n*(im+1)));\nhold off; [m x]=hist(e,-1.5:d:1.5); bar(x,m*pi/(2*d*n*s));\n\nÏ3\nÏ\nG\nG\nÏ2\nÏ\n2/1/2005\nÏ6\nG\nÏ5\nG\nÏ6\nÏ4\nG\nÏ5\nG\nÏ4\nÏ3\nÏ1 G\nSame eigenvalue distribution as GOE:\nO(n) storage !! O(n2) compute\nsym matrix to tridiagonal form\n\nG\n4Î²\nÏ\nÏ6Î²\nG\nÏ5Î²\nG\nÏ6Î²\nÏ4Î²\nG\nÏ5Î²\nÏ3Î²\nÏ\nÏ2Î²\nG\n3Î²\nÏÎ²\nG\nÏ2Î²\nG\nÏÎ²\nGeneral beta\nbeta:\n2/1/2005\n1: reals 2: complexes 4: quaternions\nBidiagonal Version corresponds\nTo Wishart matrices of Statistics\n\nTools\nMotivation: A condition number problem\n\nThe Polynomial Method\n\n9 trick\n2/1/2005\nJack & Hypergeometric of Matrix Argument\nMOPS: Ioana Dumitriu's talk\nThe tridiagonal numerical 10\n\nTools\nMotivation: A condition number problem\n\nThe Polynomial Method\n\n9 trick\n2/1/2005\nJack & Hypergeometric of Matrix Argument\nMOPS: Ioana Dumitriu's talk\nThe tridiagonal numerical 10\n\nNumerical Analysis:\nCondition Numbers\nÎº(A) = \"condition number of A\"\nIf A=UÎ£\nÎº(A) = Ïmax/Ïmin .\nAlternatively, Îº(A) = âÎ» max (A'A)/âÎ» min (A'A)\nOne number that measures digits lost in finite\nprecision and general matrix \"badness\"\nSmall=good\nLarge=bad\nThe condition of a random matrix???\n2/1/2005\nV' is the svd, then\n\nVon Neumann & co.\nSolve Ax=b via x= (A'A) -1A' b\nM âA-1\nMatrix Residual: ||AM-I||2\n||AM-I||2< 200Îº2 n Îµ\nHow should we estimate Îº?\nAssume, as a model, that the elements of A are\nindependent standard normals!\nâ\n2/1/2005\n\nVon Neumann & co. estimates\n(1947-1951)\n\"For a 'random matrix' of order n the expectation value\nhas been shown to be about n\"\nGoldstine, von Neumann\nâ10n\"\nBargmann, Montgomery, vN\nGoldstine, von Neumann\nX inf\nP(Îº<n)\nâ0.02\nP(Îº< â10n)â0.44\nP(Îº<10n) â0.80\n2/1/2005\n\"... we choose two different values of Îº, namely n and\n\"With a probability ~1 ... Îº < 10n\"\n\n/\n/\nx\nx\ne\nx\nx\ny\n-\n-\n+\n=\nDistribution of Îº/n\nâinf\nExperiment with n=200\n2/1/2005\nRandom cond numbers, n\n\nFinite n\nn=10\nn=25\nn=50\nn=100\n2/1/2005\n\nCondition Number Distributions\nP(Îº/n > x) â 2/x\nP(Îº/n2 > x) â 4/x2\nReal n x n, nÃinf\nComplex n x n, nÃinf\nGeneralizations:\n-Î²: 1=real, 2=complex\n-finite matrices\n-rectangular: m x n\n2/1/2005\n\n2/1/2005\nReal n x n, nÃinf\nComplex n x n, nÃinf\nCondition Number Distributions\nP(Îº/n > x) â 2/x\nP(Îº/n2 > x) â 4/x2\nSquare, nÃinf: P(Îº/nÎ² > x) â (2Î²Î²-1/Î(Î²))/xÎ² (All Betas!!)\nGeneral Formula: P(Îº>x) ~CÎ¼/x Î²(n-m+1),\nwhere Î¼= Î²\nWm-1,n+1 (Î²)\nand C is a known geometrical constant.\n1F1((Î²/2)(n+1), ((Î²/2)(n+m-1); -(x/2)Im-1)\n(n-m+1)/2th moment of the largest eigenvalue of\nDensity for the largest eig of W is known in terms of\nfrom which Î¼ is available\nTracy-Widom law applies probably all beta for large m,n.\nJohnstone shows at least beta=1,2.\n\nTools\nMotivation: A condition number problem\n\nThe Polynomial Method\n\n9 trick\n2/1/2005\nJack & Hypergeometric of Matrix Argument\nMOPS: Ioana Dumitriu's talk\nThe tridiagonal numerical 10\n\nMultivariate Orthogonal Polynomials\n&\n\nThe important special functions of the 21st century\nBegin with w(x) on I\nâ« pÎº(x)pÎ»(x) â(x)Î² âi w(xi)dxi = Î´ÎºÎ»\nJack Polynomials orthogonal for w=1\non the unit circle. Analogs of xm\n2/1/2005\nHypergeometrics of Matrix Argument\nIoana Dumitriu's talk\n\n2/1/2005\nMultivariate Hypergeometric Functions\n\n2/1/2005\nMultivariate Hypergeometric Functions\n\nWishart (Laguerre) Matrices!\n2/1/2005\n\n2/1/2005\nPlamen's clever idea\n\nTools\nMotivation: A condition number problem\n\nThe Polynomial Method\n\n9 trick\n2/1/2005\nJack & Hypergeometric of Matrix Argument\nMOPS: Ioana Dumitriu's talk\nThe tridiagonal numerical 10\n\n2/1/2005\nMops (Dumitriu etc.) Symbolic\n\nA=randn(n); S=(A+A')/2; trace(S^4)\ndet(S^3)\nSymbolic MOPS applications\n2/1/2005\n\nÎ²=3; hist(eig(S))\nSymbolic MOPS applications\n2/1/2005\n\nA=randn(m,n); hist(min(svd(A).^2))\n2/1/2005\nSmallest eigenvalue statistics\n\nTools\nMotivation: A condition number problem\n\n9 trick\n2/1/2005\nJack & Hypergeometric of Matrix Argument\nMOPS: Ioana Dumitriu's talk\nThe Polynomial Method -- Raj!\nThe tridiagonal numerical 10\n\nCourtesy of the Polynomial Method\n2/1/2005\nRM Tool - Raj!\n\n2/1/2005\n\nâ\nâ«\ninf\n=\ninf\n-\n=\n-\nÎ\n=\n)\n(\n)\nÎ¶(\nk\ns\nu\ns\nk\ndu\ne\nu\ns\ns\nÏ\n)\nÎ¶ 2\n(\n=\n+\n+\n+\n+\n=\n...\nThe Riemann Zeta Function\nOn the real line with x>1, for example\nMay be analytically extended to the complex plane,\nwith singularity only at x=1.\n2/1/2005\n\n2/1/2005\n-3\n-2\n-1\n0 1â2 1\nâ\nâ«\ninf\n=\ninf\n-\n=\n-\nÎ\n=\n)\n(\n)\nÎ¶(\nk\nx\nu\nx\nk\ndu\ne\nu\nx\nx\nAll nontrivial roots of Î¶(x) satisfy Re(x)=1/2.\n(Trivial roots at negative even integers.)\nThe Riemann Hypothesis\n\n2/1/2005\n-3\n-2\n-1\n0 1â2 1\nThe Riemann Hypothesis\nâ\nâ«\ninf\n=\ninf\n-\n=\n-\nÎ\n=\n)\n(\n)\nÎ¶(\nk\nx\nu\nx\nk\ndu\ne\nu\nx\nx\nAll nontrivial roots of Î¶(x) satisfy Re(x)=1/2.\n(Trivial roots at negative even integers.)\nÎ¶(x)| along Re(x)=1/2 Zeros =.5+i*\n14.134725142\n21.022039639\n25.010857580\n30.424876126\n32.935061588\n37.586178159\n40.918719012\n43.327073281\n48.005150881\n49.773832478\n52.970321478\n56.446247697\n59.347044003\n|\n\nComputation of Zeros\n\n10^k+1\nthrough 10^k+10,000 for k=12,21,22.\nSee http://www.research.att.com/~amo/zeta_tables/\nA=randn(n)+i*randn(n); S=(A+A')/2;\n2/1/2005\nOdlyzko's fantastic computation of\nSpacings behave like the eigenvalues of\n\n2/1/2005\nNearest Neighbor Spacings &\nPairwise Correlation Functions\n\n2/1/2005\nPainleve Equations\n\nSpacings\n\nNormalize so that average spacing = 1.\n\njth)\nConjecture: These functions are the same for random\nmatrices and Riemann zeta\n2/1/2005\nTake a large collection of consecutive zeros/eigenvalues.\nSpacing Function = Histogram of consecutive differences\n(the (k+1)st - the kth)\nPairwise Correlation Function = Histogram of all possible\ndifferences (the kth - the\n\nTools\nMotivation: A condition number problem\n\nThe Polynomial Method\n\n9 trick\n2/1/2005\nJack & Hypergeometric of Matrix Argument\nMOPS: Ioana Dumitriu's talk\nThe tridiagonal numerical 10\n\nEveryone's Favorite Tridiagonal\n-2\n-2\n-2\n...\n...\n...\n...\n...\nn2\nd2\ndx2\n2/1/2005\n\nEveryone's Favorite Tridiagonal\n-2\n-2\n-2\n...\n...\n...\n...\n...\nn2\nd2\ndx2\n(Î²n)1/2\n+\nG\nG\nG\ndW\nÎ²1/2\n+\n2/1/2005\n\nStochastic Operator Limit\n,\nN(0,2)\nÏ\nÏ\nN(0,2)\nÏ\nÏ\nN(0,2)\nÏ\nÏ\nN(0,2)\nnÎ²\n~\nH\nÎ²\nÎ²\n2Î²\n2)Î²\n(n\n1)Î²\n(n\n1)Î²\n(n\nÎ²\nn\nâ\nâ\nâ\nâ\nâ\nâ\nâ \nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\n-\n-\n-\nÎ²\nx\ndx\nd\n+\n-\n,\nG\nÎ²\nH\nH\nn\nn\nÎ²\nn\n+\nâ\ninf\n...\n...\n...\n2/1/2005\n,\ndW\n\n2/1/2005\nLargest Eigenvalue Plots\n\nMATLAB\nbeta=1; n=1e9; opts.disp=0;opts.issym=1;\nalpha=10; k=round(alpha*n^(1/3)); % cutoff parameters\nd=sqrt(chi2rnd( beta*(n:-1:(n-k-1))))';\nH=spdiags( d,1,k,k)+spdiags(randn(k,1),0,k,k);\nH=(H+H')/sqrt(4*n*beta);\neigs(H,1,1,opts)\n2/1/2005\n\nTricks to get O(n9) speedup\n-\n-\n-\ngeneral purpose eigensolvers.)\n-\nconvergence of the largest eigenvalue)\n-\nstructures and numerical choices.)\n-\n1/3\ndetermined numerically by the top k Ã k segment of n. (This is an\ninteresting mathematical statement related to the decay of the Airy\nfunction.)\n2/1/2005\nSparse matrix storage (Only O(n) storage is used)\nTridiagonal Ensemble Formulas (Any beta is available due to the\ntridiagonal ensemble)\nThe Lanczos Algorithm for Eigenvalue Computation ( This allows\nthe computation of the extreme eigenvalue faster than typical\nThe shift-and-invert accelerator to Lanczos and Arnoldi (Since we\nknow the eigenvalues are near 1, we can accelerate the\nThe ARPACK software package as made available seamlessly in\nMATLAB (The Arnoldi package contains state of the art data\nThe observation that if k = 10n\n, then the largest eigenvalue is\n\nLevel Densities\n2/1/2005\n\nOpen Problems\nThe distribution for general beta\nSeems to be governed by a convection-diffusion equation\n2/1/2005\n\nRandom matrix tools!\n2/1/2005"
    },
    {
      "category": "Resource",
      "title": "b1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/d648ab1fac93a4617d3cf255d07ff7a6_b1.pdf",
      "content": "!\n\n\"\n\n#$\n\n%\n\n&\n\n'\n\n#$\n\n(\n\n#$\n\n)\n\n*\n\n!\n\nï¿½\n\n+\n\nï¿½\n\nï¿½\n\n,\n\nï¿½\n\n-.\n+\n\n#$\n\"\n\n$\n\n,\n\nï¿½\n\nï¿½\n\n,\n\n.\n\nï¿½\n\nï¿½\n\n++\n\nï¿½\n\nï¿½\n\n,\n\n/\n. -\n\n+\n\n)\n\n*\n\n%\n\nï¿½\n\n.\n\nï¿½\n\n.\n\nï¿½\n\n.\nÃ\n\nï¿½\n\nï¿½\n\n+0\n\nï¿½\n\n-.\n\n%\n\n++\n+\n\n.\n\nï¿½\n\nï¿½\n\n+6\n\n!\n\n'\n\n$\n\n'\n\nï¿½\n\nï¿½\n\nï¿½\n\n.\n\n-.\n\nï¿½\n\nï¿½\n\n'\n\n-.\n\nï¿½\n\nï¿½\n\n-.\n\nï¿½\n\nï¿½\n\nï¿½\n\n+7\n\n'\n'\n\n-.\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\n.\n\nï¿½\n\nï¿½\n\nï¿½\n\n+8\n\n+90\n\n)\n\n#$\n\nï¿½\n\nï¿½\n\nï¿½\n\n+:\n\n;\n-.\n\n)\n\n'\n\nï¿½\n\n!\n\n.\n+\n\n!\n\n!\n\n!\n\n!\n\n\"\n\n#\n\n\"\n\n$\n\n%\n\n\"!\n\n!\n\n&\n\n!\n\n'\n\n$ (\n\n#$\n\n%\n\n-.\n+\n,\n\n+<\n\n%\n\n.\n\n+\n/\n,\n\n+=\n\n.\n\n+\n\n+>\n\n*\n\n*\n.\n\n)\n\n?\n\n%\n\n.\n\n+\n\n.-\n\n++@\n\n!\n\n?\n\n.\n\n+\n\n+++\nA\n\n+<\n\n++@\n\n.\n+\n\n+\n\n++0\n\n!\n\n.\n\n*\n\n.\n\n++6\n\n*\n\nA\n\n.\n\nÃ\n\nï¿½\n\nï¿½\n\nÃ\n\nï¿½\n\nï¿½\n\n+<\n\n-.\n+\n\nÃ\n\nï¿½\n\nï¿½\n\nÃ\n\nï¿½\n\nï¿½\n\n,\n\n.\n\n+\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\n++7\n\n,\n\nA\n\n+\n\n+\n\nï¿½\n\nï¿½\n\nï¿½\n\n.\n\nï¿½\n\nï¿½\n\n++8\n\n,\n\nA\n\n'\n\nï¿½\n\nï¿½\n\nï¿½\n\n%\n\nï¿½\n\nB\n\n.\n\nï¿½\n\nï¿½\n\n@\n.-\n\nï¿½\n\nï¿½\n\n*\n\n*\n\nï¿½\n\nï¿½\n\n++:\n\n#\n\n'\n\n'\n\n'\n\n-\n\n-.\n\nï¿½\n\nï¿½\n\n++<\n\n++\n\n++<\n\nï¿½\n\n-.\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\n++=\n\nï¿½\n\nï¿½\n\nï¿½\n\n-.\n+\n\n+ /\n\nï¿½\n\n++>\n\n+\n\n.\n\n+\n\n)\n\n.\n\n.\n+\n\n.\n+\n\n.\n\n.\n+\n\n.\n\n.\n\n.\n+\n\n.\n\n+\n\n.\n\n.\n+\n\n.\n\n.\n\n++\n:\n\n)\n\n!\n\nï¿½\n\nï¿½\n\nï¿½\n\n)\n\n!\n\n*\n\nï¿½\n\nï¿½\n\nï¿½\n\n!\n\nï¿½\n\nï¿½\n\nï¿½\n\n!\n\nï¿½\n\nï¿½\n!\n\n)\n\n!\n\nï¿½\n\nï¿½\n\n)\n\n!\n\nï¿½\n\n\"\n\n!\"#\n\n!\n\n*\n\n$\n\n\"\n\n%\n\n&\n&\n\n$\n\n'\n\n(\n\n\"\n\n!\n!)#\n\n!\n\n\"\n#\n\n\"!\n(\n\n!\n\n!\n\n'\n\nï¿½\n\nï¿½\n\nï¿½\n\n\"*!\n\n:\n\n$\n\n#\n\n#\n\n&\n\n)\n\n!\n\nï¿½\n\nï¿½\n\n!\n#\n\n!\n#\n\n!\n\n&\n\n)\n\n!\n\nï¿½\n\nï¿½\n\n!\n#\n\n!\n#\n\n!\n\n#\n\n#\n\n\"\n\n*\n\n&\n\n+\n\nï¿½\n!\n\nï¿½\n\n+\n\nï¿½\n!\n\n!\n\n#\n\n+\n&\n\n&\n\n#\n\n+\n\nï¿½\n!\n\n\"\n\n&\n\nï¿½\n!\n\nï¿½\n!\n\n!!+#\n\n,\n\n,-\n\nï¿½\n\nï¿½\n\nï¿½\n\n!\n\nï¿½\n\n!\n\n,-\n\nï¿½\n\nï¿½\n\nï¿½\n\n!\n\nï¿½\n\n!\n\n,-\n\n,\n.\n-\n\n#\n\n,\n.\n-\n\n,-\n\n/\n/\n\n$\n\nï¿½\n\nï¿½\n\n,\n.\n-\n\nï¿½\n\nï¿½\n\n#\n\nï¿½\n\n!!\n\n-\n\n!!.#\n\n,-\n\n!\n\n,-\n\n/\n\n/\n\n#\n\n,\n.\n-\n\n,\n.\n-\n\n,-\n\n,-\n\n,-\n\n/\n\n/\n\n/\n\n/\n\n!\n\n!\n\n<\n\n!\n\n%\n\n\"\n\n#$\n\n&\n+8\n\n\"\n\n#\n\n$\n\n$%&\n\n!!!'\n+\n\n+\n\n!\n\n\"\n\nC\n++\n\n+\n\n!\n\nDE\"\n!\nF\n\nG\n\n+\n\n+\n\n.\n#\n\n-.\n\n.\n#\n\n.\n#\n\n+0+\n\n#\n\n$\n\nH5\n\nE+<8\nF\n\n(\n\n#!\n\n.\n\n)\n\n!!!\n\n.\n\n*\n\n.\n#\n\n.\n#\n\n&\n%\n\"\n\n+\n\n,\n!!!\n\nE\nF\n-.\n\n\"\n.-\n\n\"\n-.\n\n-!.-\n#\n\n,\n\n.\n\n=\n\n$\n\n(\n\n,\n-\n\n#\n\n!\n#\n!\n\n!\n#\n!\n\nÃ\n\n*\n\n#\n\n!\n\n*\n\n!\n\n\"\n\n)\n\nH5\n\n)\n\n!\n\n$\n\nD\n\n$\n\nD\n\n%\n\n$\n\n$\n\n\"\n\n/\n$\n\n#\n\nE$\n\n# F\n.\n@\n\nE\nF\n\n!\nH\n\n\"\n\n!!\n\nI\n\n%&\n\n'&\n\n.\n%\n&\n\nI\n'\n&\n\n%\n\n'\n\nï¿½\n\n#\n,\n\n(!\n\n&\n\nJ\nE+87\n\n:<+F\n\n'\n\nE+@6\n\n0F\n\n)\n\n+90\n\n.\n+\n\n>\n\n+\n\n.\n+\n\n.\n\n)\n\n'\n\n'\n\n@\n+\n+00\n+\n@\n\n+0\n\n)\n\nG\n\nK\n\n(\n$\n\n/\n\n.\n+\n\n$\n\n#\n\n$\n\n!\n\n&\n%\n\"\n\n.\n+\n\n!\n\n!\n\n+0+\n\nD\n\n*\n\n+0\n\n+0\nA\n\n+6\n\n+0+\n\nG\n\n$\n\nH5\n\n$\n\n.\n+\n\n'\n\nH5\n\nA\n\n+>8@\"\n%\n+>=7\n#\n\n&\n\n%\n\nH5\n\n$\n\n&\nL\n\nM\n\n$\n\n'\n\n)\n\nH5\n\nE+@@\nF\n\n+@\n\n/\n\n!\"\n\n-\n\n!\n\n!\n\n/\n\n!\n\n\"\n\n\"\n\n\"\n\n\"\n\n#\n$\n\n!\n\n\"\n\n#\n\n%\n\n%\n*\n\n*\n\n%\n\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n*\n*\n\n%\n\n&\n%\n\n!\n\n\"%\n\n#\n%\n\n!\n\n%\n\n%\n\n#\n\" %\n\n#\n%\n\n#\n%\n\n#\n\n%\n\n\"\n\n!\n#\n\n!\n\n\"\n\n!\n\n!\n#\n\nï¿½\n\n,\n\n-\n\n#\n\n!\n\n!#\n\n!\n\n\"\n\n!\n\n\"\n\n!\n\n#\n\n!\n\n\"\n#\n\"\n\n*\n#\n\n!\n\"\n\n!\n\"\n\n!\n#\n\n!\n#\n\n!\n\n#\n\n!\n\n#\n\n!\n\n'\n$\n\n#\n\n!\n#\n\n!\n\n'\n\n'\n\n#\n\n!\n\n(\n#\n\n!\n\n(\n\n$\n\n#\n\n,\n\n-\n\n)\n\n,(\n\n-\n\n*\n\n/\n\n)\n\n*\n\n!\n\n(\n\n++\n\n(\n\n!\"\"#\n\n*\n\n\"3!\n\n*\n\n+\n\n'\n\n#\n,\n'\n\n!\n\n'\n\n+\n\n,\n\n,\n\n-\n\n,\n+\n\n+\n\n!)\n\n*\n\n,\n\n,\n\n,\n,\n\n$\n\n+\n\n#\n\n+\n\n'\n\n#\n,\n'\n\n!\n\n+\n\n,\n&\n\n,\n+\n\n+\n\n%\n\n-\n\n,\n\n,\n\n+\n\n+\n\n-\n+\n\n#\n\n,\n\n,\n\n,\n\n,\n\n,\n\n#\n\n,\n\n.\n,\n\n.\n\n#\n\n5 #\n\n,\n\n+\n\n+\n\n+\n\n.+\n\n+\n\n.\n\n!\n\n.\n\n!\n\n/\n\nH5\n\n+0+\nA\n\n+>6>\nE+@>\nF\nA\n\nJ\nE+8<\nF\n\n+\n\n+0+\n\n+\n\n+\n\n+0\n\n,\n\n,\n\nH\n'\n\n+\n\n.\n\n+\n\n+\n\n-\n\n+\n\n,\n\nN\n\n-\n-.\n\nN\n\n,\n\n,\n\n#\n\n-\n$\n-\n.\n\n+\n\n+\n\n,\n\n,\n\n,\n\n,\n\n$\n\nH5\n\n+\n\n+\n\n+\n\n+07\n\n$\n\n)\n\n?\n\nN\n%\n\n?\n\n'\n\n?\n\nE07\nF\n\nN\n\n%\n\n(\n,\n\n!\n\n.-\n\n-.\n\nE\n\nF\n\n+08\n\n,\n\n!\n\n+6\nD\n\n+08\n\n.\n\nA\n\n.\n\n.\n\n.\n\n.\n\n.\n\n&\n\n+08\n\n$\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n+0:\n\n+0:\n\nN\n\nN\n\n+0:\n\n.\n\n)\n\n)\n\n#\n.\nE\n\nF\n\n#\n\n*\n\n.\n\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n\nA\n\n?\n\n.\n\n!\n\n#\n\n.\n\n.\nE\n\n*\n\nF\n\n/\n\n.\n\n.\n\n.\n\n+7\n\n%\n\nN\n\n+0:\n\nC\n+:\n\n?\n\n#\n\n+\n\nA\n\n%\n\n-\n\n/\n\nE+8<\nF\n\n(\n\n/\n\n!\n\n.\n\n!\n\n)!\n!\n\"8!\n\n)\n\n!\n\n)\n!\n\n!\n\n)\n!)!\n!\n\n)\n!\n\n)!)\n!\n\n$\n\n:\n\n,;\n-\n\n(\n\n)\n!\n\n!\n\nï¿½\n\n:\n\n!\n\n\"8!\n\n%\n;\n\"\n\n!\n\n\"\n\n)\n\nC\n+:\n\n+0:\n\n-\n+\n\n,\n\n.\n\n$\n\n.\n\n+0=\n\n$\n\nO\n\nC\n+8\n\n?\n\n.\n\n+8\nK\n\n'\n\n.\n\n.\n\n+0>\n\n.\n\n.\n\n!\n\n+8\n\n.\n\n+6@\n#\n\n.\n+\n!\n\n-\n\n+0>\n\n'\n\nï¿½\n\n.\n\n+\n\n+\n\n+\n\nï¿½\n\n+\n\n+\n\nï¿½\n\n+\n\n+\n\nï¿½\n\n+\n\n+\n\n+\n\nï¿½\n\n.\n\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\n\n+\n\n+\n\nï¿½\n\n+\n\n+\n\nï¿½\n\n+\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\n)\n\n+:\n\nC\n+:\n\n+0>\n\n+:\n\n+6@\n\n+0>\n\n.\n+\n\n+\n\n+\n\n+6+\n\n$\n\nN\n\n+07\n\nH5\n\n+6\n\n#\n\n\"\n\nN\n\n&\n\n+\n\n+\n\n?\n\n%\n\n%\n.\n%\n\nH\n\n.\n\n'\n\n+\n\n+\n\n&\n%\n.\n\n%\n\n+:\n\n%\n\n+\n\n+\n\n+\n\n+\n\n&\n\nN\n\n+\n\n.\n+\n\n$\n\n+\n\n+\n\n$\n%\n\n!\n\n+6+\n\nE++@\nF\n)\n\n.\n\n.\n\n+60\n\n.\n\n.\n\n%\n\n'\n\n.\n\n+66\n\n\"\n\n.\n\n+67\n\nJ\n\n.\n\n.\n\n+68\n\nE\n\nF\n\n+6:\n\n+68\n\n+66\n\n+67\nA\n\n+0>\n\n+:\n\n.\n+\n\n+\n\nï¿½\n\nï¿½\n\n+\n\n!\n\n+67\n\n+6+\n\n+<\n\n$\n\n!\"\n\n#\n\n6!75\n\n9:;\n\n-\n\n9:;\n\n9:;\n%\n\n!\n\nÃ\n\n\"\n\n'\n\"!\n\n&\n\n$\n\n)\n\n!\n\n)\n\n!\n\n'\n\"!\n'\n\n!\"!\n\n*\n\n#\n\n*\n\n*\n\n#\n\n)\n\n\"\n\n38!\n\n$\n\n!\n\n#\n\n#\n\n!\n\n<\n\n&\n\n#\n\n!5=#\n\n*\n\n\"\n\n\"\n\n(\n(\n.\n\n#\n\n\"\n\n#\n.!\n\n\"\n\n.!\n#\n;(\n\n*\n\n#\n'\n\n'\n\n,\n\n-\n\n#\n\n(\n\n!\n\n.\n\n#\n\n,\n\n#\n\n(\n\n.\n\n(\n\n.\n\n(\n\n.\n\n!\n\n+=\n\n!5!#\n\n&\n\nH5\n\nP\n\nQ\n\n'\n\nE+@6\nF\nD\n\n&\n+0+\n\n$\n\n&\n\n)\n\nG\n\n\"\n\n/\n\n#\n\n$\n\n$2&\n\n.\n\n*.\n\n!!!\n+\n\n.\n\n!\n&\n\nDE@\n+\n\n0F\n\nDE@\n+\n0F\n*DE@\n+\n0F!\n)\n\nG\n\n+\n\n.\n#\n\n.\n#\n\n-.\n\n#\n\n$\n\n.\n\n$\n\n&\n\n%\n\n+0+\n\n'\n\n.\n+\n\n.\n+\n\n.\n\n)\n\nD\n\nI\n\n.\n\n.\n\n)\n)\n\n.\n\n)\n)\n\n.\n\n+6=\n\n+>\n&\n\n'\n\n'\n+00\n\n'\n\n+6>\n\nï¿½\nï¿½\n\n!\n\n)\n\n%\n\n%\n\n*\n%\n\n%\n\n*\n\n.\n\n.\n\n.\n+\n*4\n\n.\n+\n+7@\n\n%\n\n%\n\n+\n*\n\n$\n\n+\n@\n*\n@\n@\n+\n@\n*\n\n-.\n\n-.\n*\n!\n.\n\n-.\n*\n\"\n.\n\n-.\n*\n\n.\n@\n+\n@\n*\n+\n@\n*\n@\n+7+\n\n)\n\n+6>\n)\n\n.\n\nï¿½\n\n#\n\nï¿½\n.\n\n#\n.\n\n+70\nA\n\n+6>\n\nï¿½\n\n+76\nï¿½\n\n)\n\n-.\n\nI\n\n.\n\nï¿½\n\n.\n\n.\n\n$\n\n.\nï¿½\n\n!\n\n\"\n\n/\n\n#\n\n$\n\n$3&\n\n!!!\n\n!\n\nDE@\n+\n0F\n\n*\n\n.\n\n*.\n\n.\n\n*.\n\n!!!\n\n!\n\n$\n\nDE@\n+\n0F\n*DE@\n+\nF\n\n!\n\n0@\n\n!\n\n+6=\n\n+7\n+\n%\n\nC\n+=\n\nG\n\n&5\n\n.\n#\n\n#\n\n$\n\n%\n\n(\n\n/\n\n#\n\n.\n\n)\n!\n\n#\n\n/\n\n#\n\n!\n\n\"\n\n#\n\n.\n\n)\n\n.\n\n+77\n\n#\n\n#\n\n.\n\n!\n\n&\n\n,\n\n,\n\n,\n\n,\n\n,\n\n<\n\n,\n\n,\n\n$\n\n,\n\n,\n\n,\n\n,\n\n%\n\"\n;!!\n\n!\n=\n\n>\n\n,\n\n>\n\n;;!\n\n!\n\n?\n\n;@!\n\n:\n\n>\n\n3A!!\n?\n\nB(\n\nC !\n\n;;!\n\nD\n\n$\n\n'\n\n\"\n\nG\n\n\"\n\nO5\n\n&5\n\n&\n+6\n\nH5\n\n0+\n\n'\n\n'\n\n+7\n\n$\n\nH5\n\n(\n\n/\n\n#\n\n.\n+\n#\n\n.\n\n.\n\n.\n\n#\n\n#\n\n.\n+\n#\n\n.\n\n.\n\n!\n\n.\n+\n\n+\n\n+\n\n+7:\n\n#\n\n-!45\n+\n\n+\n\n+\n\n+\n\n+7<\n\n.\n-.\n\n!!!\n\n$%&\n$2&\n\n$3&\n\n!\n$$\n(\n\n)\n\n-.\n\n-.\n\n-.\n\n(\n\nD\n\nA\n\n(\n\nH\n\n%\n\n(\n\nA\n\n)\n\n(\n\n(\n\n(\n\n&\n\n&\n0++\n\nN\n\nï¿½\n\n+\n\nï¿½\n&\n\nï¿½\n\n%\n\nï¿½\n\nE0+@\nF\n)\n\nï¿½\n\nï¿½\n\n#\nM\n\n&\n68+\n\n%\n.\n\n+7:\n\nE+@<\nF\n$*\n+\n\n,\n\n&\n\n+7<\n\n.\n\n.\n=\n\n$\n\nE+>6\nF\n\n(\n,\n\n,\n\nÃ\n\n+\n*\n\n+7@\n(\nï¿½\n\n+70\n\n%\n.\n,\n\n,\n\n'\n.\n\n%\n'\n.\n,\n\n,\n\n%'\n.\n,\n\nï¿½\n\n,\n\n,\n\n,\n\nï¿½\n\n+7=\n\n%\n\n+\n\n-.\n*\n\n-.\n\n-.\n\n-.\n\n-.\n*\n\n-.\n\n-.\n\n%\n\n%'5\n.\n%' 5\n\n%\n.\n\n'\n.\n\n.\n\n%'5\n.\n\n%' 5\n.\n\n'\n\nH\n\nï¿½\n\n-.\nï¿½\n\n,\n\nI\n,\n\n+70\n\n%'\n.\nI\n'\nï¿½\n\n%\n-.\n%\nï¿½\n\n.\n%%\nI\n%'\n.\n%'\n+7>\n)\n\n%\n.\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n.\n%\n\n%\n\n%\n\n+8@\n\n%\n.\n@\n\n%\n\n.\nI\n%\n\nI\n%\n%\n\n+8+\n\n+7> R+8+\n\n%\n\n$\nE+++\nF\n\n#\n\nD\n\n%\n\n(\n\n.\n\n*\n\nï¿½\n\n.\n\nÃ !\n\n%\n.\n%\nï¿½\n\n%\n.\n\n%\nï¿½\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n.\n\n%\n\n%\n\n%\n\n%\n\n%\n.\n\n%\n.\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n.\n\nE+\n+\n+\n+F!\nO\n\n+>\n\n+7=\n\n(\n\n.\n\nï¿½\n\n.\n\nÃ !\n\n%\n.\n%\n\n%\n\nS\n\n%\n\n%\n\n.\n\nE\n\nF\n\n%\n.\n\n%\nï¿½\n\n%\n.\n\n%\nï¿½\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n.\n.\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n.\n\n%\nS\nS\n\n%\n'\n\n.\nI\n'\n\n)\n\n%\n\n%\n\n'\n\n.\n\n'\n\n+80\n!\n\n'\n@\n\n%\n\n@\nI\n'\n\nI\n'\n@\n\n@\n'\n\n+\n\n.\n%\n\n+ 5\n\n+\n\n'\nI\n'\n\nK\n\n+80\n\n+:\n\n.\n+\n\n+\n\n+\n\n+\n\n+86\n)\n\n%\n\n'\n\n'\n\n+80\n\n'\n\n=\n\nG\n\n+86\n\n+7<\n\n.\n\n.\n=\n\n$\n\n/\n\n\"\n\n\"\n\n,\n\n><\n#\n\n$\n\n$\n\n,\n\n,\n\n;\n!\"\n5 #\n\n,\n\n,\n\n*\n\n&\n\n6!)?\n\n5\"8\n\n!\n\n\"!\n\n;!\n\n!\n\n\"!\n\n;!\n\n!\n\n!\n\n!\n@;!\n\n!?\n/\n\n;\n\n$\n\n#\n\n$\n\n'\n\n'\n\n#\n\n\" #\n\n; #\n\n$\n\n'#\n\n$\n#\n\n$\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n'\n\n!\n\n#\n\n*\n\n'\n\nï¿½\n\n/\n\n*\n\n'\n\n,\n\n-\n\n!\n\n#\n!\n\n@\n\n!\n\n\"\n\n!\n\n$\n\n#\n\nï¿½\n\n!\nï¿½\n\nï¿½\n\n!\nï¿½\n\n!\nï¿½\n\nï¿½\n\n!\n\n!\nï¿½\n\nï¿½\n\n!\nï¿½\n\nï¿½\n\n!\n\n!\nï¿½\n\nï¿½\n\n!\n\nï¿½\n\nï¿½\n\n#\n\n!\n\n!\n\n$\n\n<\n\n$\n!55#\n\n\"\n\n*\n\n'\n\n,\n\n-\n\n5 #\n\n5 #\n\n/\n\n#\n\nï¿½\n\nï¿½\n\n!\n\nï¿½\n\nï¿½\n\nï¿½\n\n5 #\n\n5 #\n\n'\n\n$\n\n&'\n\n*\n\n#\n\n5 #\n\nï¿½\n\nï¿½\n\nï¿½\n\n$\n\n\"!\n\nï¿½\n\nï¿½\n\n*\nï¿½\n\n$\n\n!\"!\n\n*\n$\n\n*!\n\n0:\n\n#\n\n'\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n%\n\n#\n\n/\n\n!\n\n!\n\n! 5 . #\n\n#\n/4\n\n$\n\n+\n\n,\n\n#\n/\n\n-\n\n#\n\n;\n\n;\n\n$\n\n#\n/5\n\n\"\n\n\"\n\n@@!\n\n\"\n\n\"\n\n%\n\n(\n\nï¿½\n\n)\n\n? #\n\nï¿½\n\nï¿½\n\nï¿½\n\n*\n\"\n\n!\n\n\"\n\n!\n*\n\nï¿½\n\nï¿½\n\n-\n\nï¿½\n\nï¿½\n\nï¿½\n\nï¿½\n\n(\n\n5 #\n\n? #\n\n#\n\n#\n\n0<\n\n'\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n6?!\n\n/\n\n-\n\n,\n\n,\n\n)\n\n/\n\n'\n\n/\n\n/\n\n!\n\n!\n\n\"\n\n!\n\n!\n\n!\n@ !\n\n!\n\n\"\n#\n!\n\nB\n\nE%\n\nF\n\n.\n\n+8<\n\n.\n\nï¿½\n\nï¿½\n\n.\n\n+8=\n\nï¿½\n\nï¿½\n\n.\n+\n\nB\n\nï¿½\n\nï¿½\n\n+\n%\n\n%\n\n.\n@\n\n.\n+\n\n.\n\n+8>\n\n(\n0(\n\n(\n.\n%\n\n%\n\n'\n\n-.\n\n+:@\n'\n\n.\n%\n\n'\n\n.\n'\n\n.\n(\n'\n\n.\n'\n\n.\n@\n\n0=\n\n.\n\n+8>\n\n.\n\n.\n\n.\n\n.\n@\n\n%\n\nE0@+\nF\n\nC\n\nE8@\nF\n\nH5\n%\n\n'\n\nE0@+\nF\n\n(\nDE@\n+F\n\n+\n-!-\n\nï¿½\n\n;E\n\n+F\n\n+\n;\n\n@\n\n$\n\nDE@\n+\n\n0F!\n\nï¿½\n\n;\n\n@!\n\n$%&\n\n#\n\n/\n\nDE@\n+F\nï¿½\n\nDE@\n+F\nï¿½\n\nï¿½\n\nï¿½\n\nDE@\n+F\nï¿½\n\n!\n!\n!\n!\n!\n!\n!\n!\n!\n\nS\n\nï¿½\n\nDE@\n+F\nï¿½\n\nDE@\n+F\n\n*!\n\n@A!\n\n?,*\n-\n(\n\n(\n\nEF%\n\n:\n\n:\n\n@G!\n\n&\n\nEF%\n\nEF%\n\nEF%\n\n=\n\n,*\n-\n(\n\n(\n\n<\n\n+++\n\nN\n\n%\n\n'\n\n'\n\n%\n\n'\n\n'\n\n%\n\n'\n\n+:+\n\n.\n\n'\n\n%\n\n'\n\n'\n\n%\n\n0>\n\n)\n\n+\n\nï¿½\n\n+\n\n.-\n\nï¿½\n\n+\n\n.\n\n'\n\n@\n\n$\n\n.\n+\n\nN\n\nï¿½\n\n-.\n%\n\n%\n\n%\n\n'\n-.\n'\n\n'\n\n+:0\n\n+\n-.\n+\n\n+\n\nï¿½\n\n-.\n\n+:6\n\n(\n\n#\n!\n\n+\n\n.\n\n+:7\n+\n\n+\n\n\"\n\n'\n\n+\n\n+\n\n.\n\n+:8\n\n?\n\n!\n\n!\n\nï¿½\n\n!\n\nï¿½\n\nï¿½\n\n*\n\n*!\n\n?\n\nï¿½\n\nï¿½\n\n!\nï¿½\n\nï¿½\n\n;!\n\n@!\n\n!\n\n!\n\n;!\n\n!\n\n8!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n6@\n\n!\n\n!\n\nG!\n\n!\n\n?\n\n!\nA!\n\n!\n\n!\n\n!\n\n(\n\n(\n\n&\n\n!\n\n!\n8*!\n\n!\n\n(\n\n!\n\n!\n\n(\n\n8*!\n\nG!\n\n@!\n\n-!5.\n\n-!58\n\n+\n\n'\n\n+<+\n\nH\n;!\n\n!\n\n!\n\n#\n(\n\n#\n\n(\n\n(\n\n#\n(\n\n(\n\n#\n\n(\n\n(\n\n#\n\n(\n\n(\n\n(\n\n(\n\n!\n\n6+\n:\nD\n\n:\n\n:\n\n!\n\n(\n\n(\n\n,\n\n-\n\n,$\n\n-\n\n(\n(\n\n%\n@\n\"!\n\nI\n\n(\n\n!\n\n(\n\nH\n@!\n\n8!\nO\n\n++6\n\n+++\n\nH5\n\nJ\n\n+7<\n\n@\nE8@\nF\n\n-!--\n\n#\n\nDE@\n+F\nï¿½\n\nï¿½\n\nDE@\n+F\nï¿½\n\nDE@\n+F\nï¿½\n\n+<0\n\nï¿½\n\n-.\n\n!\n!\n!\n!\n!\n!\n!\n!\n!\n\nS\n\nï¿½\n\nDE@\n+F\nï¿½\n\nDE@\n+F\n\nï¿½\n\n+\n\n+\n\n+\n\n+\n\n.\n\n;+\n+\n\nS\n\n+<6\nS\n;+\n\n+\n\n@\n\n.\n+\n\n.\n;\n\n+<7\n\n;\n\nJ\n\n!\n\n\"\n\n(\n\n!\n\n!\n\n(\n\"\n!\n\n'\n\n\"!\n\n\"\n\n(\n\n\"\n!\n\n'\n\n\"!\n\n$\n\n(\n\n@!\n\n(\n\n83!\n\n8;!\n(\n\n8;!\n\n,\"\n-\n\n&\n3@\n3!\n\n!\n\n'*\n\n!\n\n'*\n\n!\n\n8@!\n\n'*\n\n#\n\n#\n*\n\n!\n\n*\n\n(\n\nS\nA\n\n'\n\n+<6\n\n$\n\n+7<\n\n+\n\n.\n\n;+\n\n+<:\n;+\n\n!\n\n+:>\n\n%\n\nDE@\n+F\n'\n\n;E\n\n+F\n+<<\n\n+<6\n\n$\n\n*\n\n/\n\nA\n\n,\n\n-\n\n!\n8G!\n\nA\n\n!\n\n$\n\nÃ\n\n-\n\n,$\n\n-\n\n!\n\n,\n\n$\n\n\"\n\n!\n\n%\n\n!\n\n$\n\nÃ\n\n$\n%\n#\n\n+<6\n\n+7<\n\n.\n+\n\n$\n\nH5\n\nO5\n\n&5\n\n+7<\n\n+:\n\n#$\n\n)\n\n'\n\n.\n\n+<>\n\nD\n\n+<>\n\n?\n\n%\n\n'\n\n%\n%\n\n+<>\n\n.\n\n%\n%\n+=@\n\n&\nE+<:\nF\n\n+\n\n#\n\n!\n\n.\n#\n\n.\n\n+\n\n!\n\n&\n\n#\n\n#\n\n=\n\"\n\n\"\n\n!\"\n\n\"\n\nÃ\n\n'\n\n'\n\n.\n%\n\n:\n\n.\n%\n\n!\n\n:\n\n%\n\n:\n\n.-\n%\n:\n\n+=@\n\n+\n+\n\n(\n\n0!\n\n%\n.\n\n:\n\n!\n\n:\n\n:\n\n+=+\n%\n\n%\n\nD\n\n:\n\n!\n.\n!\n\n:\n\n!\n:\n\n&\n\n!\n\n:\n\n!\n\n:\n\n+=+\n\n!\n\n:\n\n:\n\n@\n\n(\n#EF!\n\n-.\n\n:\n\n!\n:\n\n:\n+=0\n\n'\n\n+:\n+\n\n+\n\n+\n\n.\n\n:\n\n.\n\n+\n\n.\n\n:\n\n.\n\n:\n\n.\n+\n\n%\n\n+\n+\n\n+\n\n+\n\n!\n\n0!\n\n%\n.\n\n!\n\n%\n\n%\n\n%\n\n%\n\n%\n\n+>\n\n+\n+\n+\n\n+\n:\n\n.\n\n0:\n\n+\n\n%\n\n%\n\n%\n\n+\n\nK\n\n'\n\n.\n\n%\n\n%\n\n%\n\n+\n+\n\n+\n%\n\n.\n+\n\n%\n\n%\n\n%\n\n%\n\n+\n\n%\n\nA\n\n?\n\nO\n\n%\n\n%\n\n.\n\n%\n\n+=6\n\n.\n%\n\n+=6\n\n+\n\n%\n\nJ'\n\n%\n\n.\n\n#$\n\n\"\n\n+=\n\n.\n+\n\nE\nF\n\n.\n\n+\n\n#\n\n!\n\n#\n.\n\n\"\n\n=\n\n#\n\ndensity\nY\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n-1\n-0.5\n0.5\n)\n++-\n\nA\n\n+ @\n\n+@\n\nO5\n\n!\n\n$ (\n\nB\n\nB\n\n<\n\nï¿½\n\nK\n\nG3!\n\n\"\n\n!\n\n#\n;\n\n\"\n\n\"\n;\nG\n\n#\n\"\n\n\"\n\n;\nG\n=\n\nG\n\n$ (\n\n++<\n\n'\n\n)\n\n++<\n\n.\n+\n\n+=7\n\n#\n\n++<\n\n'\n\n!\n\n+<\n+\n%\n)\n++\n\n+@@@\n+@\n\n+@\n\nO5\n\n;\n.\n\nA\n\n6:\n\n-\n\n+=@\n\n.\n\n.\n\n%\n%\n+=8\n\nA\n\n'\n\n.\n%\n\n$\n\n.\n\n+=:\n\n%\n\n<\n\n-.\n\n+=<\n\nD\n\nï¿½\n\nE%\n%F\n\n<\n\n<\n\n+==\n!\n\n%\n\n<\n\nH\n\n%\n+=>\n!\n\n)\n\n\"\n\n<\n\n<\n\n.\n*\n\n%\n%\n+>@\n\n<\n\n.\n\n<\n\n*=\n)\n\n+=8\n\n+\nK\n<\n\n.\n<\n\n<\n\n.\n\n%\n%\n+>+\n\n+==\n\n+>+\n\n$\n<\n\n)\n\n>\n\n-.\n\n*\n!\n\n9/\n\nK\n\n'\n\n+\n\n?\n<\n\n.\n\n%\n\n?\n+>0\n\n?\n%\n\n?\n\n%\n\n+\n\n?\n\n?\n\n?\n.\n\n+>6\n\n%\n\n?\n\n+==\n\n+>+\n\n%\n\n+>+\n\n+>0\n\n*\n\n?\n<\n\n.\n\n%\n\n?\n+>7\n\n)\n\n*=\n\n?\n%\n\n?\n\n'\n\n\"\n\nO\n\n+>@\n\nE+8>\nF\n\n6<\n\n-!:;\n\n.\n%\n\n-!:5\n\n+\n\n?\n+\n\n.\n%\n\n?\n+>8\n\n?\n%\n\n?\n\n%\n\n-!<8!\n\n=\n\nA\"!\n\nA*!\n\n*\n\"\n\n#\n/%\n\n8!\n\n/%\n\n8!\n\n/\n\n8!\n\n!\n\"\n/\n\n!\n\nH\n\n\"\n\n#\n/%\n\n8!\n\n:\n\nA@!\n%\n\n.\n\n+>8\n\n%\n\n.\n+\n\n%\n\n+>6\n\n%\n.\n\n+=7\n\n$\n\n+>8\n\n+\n\n?\n+\n\n.\n\n% '\n\n?\n+>:\n\n?\n?\n\n% '\n\n?\n\n%\n\n'\n\n+\n\n?\n\n?\n\n?\n.\n@\n\n?\n.\n\n+><\n\n?\n\n% '\n\n?\n\n?\n\n% '\n\n?\n\n'\n\n%\n\n+>8\n\n+>:\n\n+=8\n\n'\n\n%\n%\n!\n\n.\n\n+>8\n\n.\n+\n%\n\n%\n\n+>=\n\n+>8\n\n%\n\n5%\n\n.\n\n+>>\n\n+>=\n\n'\n\n%\n\n!\n\n+>>\n\nÃ\n\n%\n\n'\n\n'\n\n%\n\n%\n\n%\n\n%\n\n6=\n\n-\n\n*\n\n*\n\n\"\n!\n\n8!\n\n\"\n\n8!\"\n\n*\n\n\"\n!\n\n\"\n\n#\n8!\"\n\n\"\n\n\"\n\n8!\n\n**!\n\n'\n\n!,\n-9\n!\n\n!\n\n!B\"#\n\n/\n\n'\n\n&\n\n&\n\n!\n\n&\n\n!\n\n#\n#\n#\n\n*!\n\"\n\n/\n\n65!\n\n\" ! .\n\n(\n:\n\n;\n\nG:\n\n:\n\n!\n\n#\n\n!!+\n\n!\n\n!\n\n\"#\n\n;#\n\n!\n\n#\n#\n\n!\n\n3#\n\n3#\n\n#\n\n\"\n#\n#\n\n\"\n\n;\n\n\"\nG\n\"\n\n3#\n\n#\n\n*\"!\n\"\n\"\n\n#\n\nG\n\"\n;\n\n6>\n\n;\n\n;\n5!\n! #\n\n\"\n#\n\nA\"\n\n\";\n\n#\n\n!\n\n#\n\n!\n\n#\n\n\"\n\n\";\n$\n\n\"\n!\n\n%$\nA\n\n\"\n!\n%\n\n\"\n!\n\n*3!\n\n#\n\n!\n\n!!=\n\n*\n\n!\n\n!\n\n!\n#\n\n!\n\n,\n-\n*;!\n\n!\n\n\"\n\n)\n\n!\n\n)9\n\n)\n\n*\n\n!\n\n\")9\n\n\"\n\n\"\n\n#\n)\n\n\"\n\n)\n\n\"\n\n#\n)\n\n\")\n\n\"\n\n!\n\n\"\n\n!\n\n65\"\n\n!\n\n;\n\n\"\n\n\"\n\n!\n\n\"\n\n%\n\n!\n\n\" #\n\n-\n\n!\n\n\"\n\n$0\n6!.!\n/\n\n!!=\n\n$\n\n-\n\n*\n$\n\n!\n\n#\n$\n#\n\n*\n\n-\n\n#\n!\n\n!\n$\n\n-\n\n*\n$\n\n!\n\n#\n\n!\n\n\"\n\n#\n\n!\n\n*\n$\n\n!\n\n:\n\n'\n\n#\n!\n\n#\n!\n\n#\n!\n\n\"#\n!\n#\n\"\n#\n!\n\n*\n\n-\n\n!\n\n'\n\n-\n\n!\n\n7@\n\n&\n'(\n\n#\n.\n!\n\n%\n\n'\n\nO5\n\n%\n\n'\n\nE6+\nF\n\nE00+\n\n=7\nF\n\n.-\n\n++@8\n\n$\n\nO5\n\nO5\n\n#\n\n.\n\n+7\n\n.\n+\n\n+\n\n+\n\n+\n\n+\n\n+\n\n++@:\n\n+\n\n0+\n\n++8\n\n+\n\nO5\n\n.\n+\n\n+\n+\n++@<\n\n++@:\n\n++@8\n\n'\n\n1 '\n\n(\n\n.\nE 2\n\nF\n\n.\n\n*\n\n/\n\n+\n\n.\n\n(\n@\n\n+\n\n@\n\n!\n\n.\n\n++@=\n\n+\n\n, 4\n\n-\n\n*A!\n\n%\n\n%\n\n7+\n$\n\n\"1\n\n!\n\n!\n\n!\n\n#\n\n&\n\n&\n\n&\n\n*A!\n\nÃ\n\nÃ\n\n%\n\n*G!\n\nÃ\n\nÃ\n\n*!\nH\n'\n\n-.\n\n++++\n\n!\n\n++@=\n\n.\n\n+++0\n\n+++@\n\n$\n)\n\n.\n\n+++0\n\n.\nÃ\n\nÃ\n\nÃ\n\nÃ\n\nÃ\n\nÃ\n\nÃ\n\nÃ\n\n+++6\n)\n\n$\n\n*\n\n.\n*\n\n.\n\n.\n*\n\n!\n\n.\nÃ\n\nÃ\n\nÃ\n\nÃ\n\nÃ\n\nÃ\n\n+++7\n\n$\n\n*\n\n.\n*\n\n*\n\n.\n*\n\n*\n\n.\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n%\n\n$\n\n+++0\n\n*\n\n*\n\n'\nH\n\n*\n\n*\n\n*\n\n*\n\nG\n\nG\n\n)\n+0\n\n+++6\n\n+++7\n!\n\n$\n\n+++0\n\nG\n?\n\n*\n\n*\n\n*\n\n*\n\n)\n+0-\n\n+++6\n\n+++7\n\n'\n\n*\n\n'\n\n)\n+6-\n\n)\n+0\n\n+++6\n\n+++7\n\n'\n\n*\n\n'\n\n)\n+6\n\n+++6\n\n+++7\nD\n\nG\n\n)\n+0\n\nA\n\nG\n\n+++0\n\n.\n%\n\n+++8\n\n%\n\n?\n\nA\n\nH\n\n)\n+6\n\n)\n+0\n\nA\n\nA\n\n'\n\n'\n\n)\n+6\n\n'\n\n\"\n\n!!\n\n,\n\n!\n\n!\n%\n\n)\n+0\n\n)\n+7-\n\n)\n+6\n\n'\n\nA\n\n+++8\n\n&\n'\n\n.\n\n<\n\n+++:\n\n<\n\n%\n\n)\n+0\n\n.\nA\n\n.\n+\n\n<\n.\n\n)\n+6\n\n.\n+\n\n.\nA\n\n<\n.\n\n+++:\n\nA\n.\n\n+\n\n+++<\n!\n\n)\n+7\n\n)\n+6\n\n+++<\n\n.\n\nA\n.\n+\n\n.\n\n.\n\nA\n.\n\n.\n@\nO\n+++<\n\n+++8\n\n.\n\n%\n\n+++=\n\n%\n\n.\n%\n\n+++>\n\n%\n\n.\n@\n\n&\n\n++@:\n\n+=7\n\n!\n\n;2\n;2\n+\n.\n\n;02\n\n++0@\n\n+\n\n%\n\n.\n\n++0+\n\n+\n\n%\n\n++0+\n\n++@<\n\nA\n\n+=7\n\n+<\n+\n\nÃ\n\n%\n\n%\n\n++@<\n\nÃ\n\nA\n\n+\n\nA\n\n'\n\nE+67\nF\n\n.\n!\n\n++@8\n\n-.\n\n++00\n\n)\n\n.\n\n/\n\n++06\n\n.\n\n++07\n\n)\n\n'\n\n++07\n\n.\n+\n\n.\n@\n.\n\n!\n\n$\n\nE00+\n\n=7\nF\n\n*\n\n*\n\n*\n\n'\n\n'\n\nA\n\n++07\n\nA\n'\"\n\n++07\n\n.\n+\n\nA\n\nM\n\nM\n\nK\n5\"\n\n+++:\n\n++07\n\n.\n%\n\n/\n\n%\n\n.\n+\n\n'\n\n'\n\n++\n:\n\n'\n\n.\n\n%\n\n++08\n\n/\n\n)\n\n;\n)\n\n%\n\n/\n\n/\n%\n\n)\n+8-\n\n!\n\n)\n\n!\n;\n.\n=\n\n!\n;\n.\n\n!\n;\n!\n\n!\n;\n\n;\n\n;\n\n?\n\n%\n\n!\n;\n++08\n\n+\n\n.\n\n++0:\n\n!\n;\n\n++08\n\n;\n\n++0:\n\n$\n\n%\n\n+\n\n+\n\n.\n\n++0<\n\n!\n;\n\n++0<\n\n)\n+8\n\nÃ\n\n&\n\n.\n@\n\n.\n)\n\n++00\n\n+\n\n.\n\n+\n\n7:\n\n.\n\n+\n\n++0=\n\n'\n\n$\n\n'\n\n#$\n\n++0=\n%\n\n#\n\n+=\n\n?\n\n+\n\n+\n+\n\n.\n\n#\n\n+\n#\n\n+:\n%\n\n++@6\n\n++@0\n\n+\n\n+\n\n+\n\n.\n\n+ >\n\n++0>\n\n.\n+\n\n+\n\n@\n++6@\n!\n\n+<\n+\n\n+\n\n.\n\n++6+\n\n+\n\n!\n\n++0>\n\n++0<\n\nE6+\nF\n\n+\n\n+ /\n\n.\n\n++60\n!\n;\n\n/\n0 /\n\n:\n\n\"A!\n\n#\n\n3!\n\n3*!\n\n%\n(\n\nÃ\n\n++60\n\n%\n\nJ'\n\n&\"\n\n;\n+\n\nK\n@\n++66\n\n+0\n\n%\n\n7<\n\nE=7\nF\n%\n\n++60\n\n?\n\n'\n\n;\n\n;\n\n.\n+\n#\n\nE=:\nF\nS\n\n.\n+\n\nS\n\n++60\n&\n\n++60\n\nS\n\nÃ\n\n%\n\nÃ\n\n>\nH\n\n)\n+8\n\n.\n\n.\n\n!\n\n\"\n&\n\n*\n!\"\n\n$\n\n!\n\n\"$\n$\n\n#\n\n.\n\n.\n\n\"$\n#\n\n\"\n\n.\n\n.\n\n.\n\n.\n\n3;!\n\nA\n\n%\n\n8!\n\n.\n\n!!5)#\n\n8!\n\n8!\n\n#\n8!!\n\n3@!\n\n8!\n\n;8!\n\n!\n3 !\n\"\n\n(\n\n!\n\n!!!.#\n\n#\n\n!!7=#\n\n!\n\n\"\n\n\"\n!\n38!\n\n\"\n\nï¿½\n\n!\n\n\"\n\n#\n\nÃ\n\n.\n\n.\n\n.\n\n.\n\n3G!\n\n/\n\n7=\n\n)\n+:-\n\n)\n+7\n\n*\n\n*\n\n#\nA\n\n#\n-\n\n&\n\n!\n\n!\n\n3A!\n*\n\n#\n\nï¿½\n\n!\n\n$\n\n\"\n&\n\n*\n!5\n\n&\n\n\"\n\n*\n!+\n\n#\n\n6\"!!\n\"\n\n!\n\n!\n\n+\n\n!\n\n+\n\n;\n\n#\n8;\n!\n\n+\n\n\"\n;\n!\n\n\"\n!\n#\n\"\n!!!\n\n/\n\n#\n\n*\n\n)\n\n!/\n\n/\n)\n\n!/\n\n)\n%\n\nO5\n\n!\n\nA\n\nÃ\n\n+\n\n!\n\n$\n\nE%\n'F\n\nTE%\n'F\n\nA\n\nO5\n\n%\n\n)\n++\n\nA\n\nTE%\n'F\n\n.\n+\n\nO5\nC\n\nTE%\n'F\n\nA\n\nU\n!\n\nU\nK\n\n=\n@\n\nO5\n\n.\n+\n\n4 \"\n\n\"\n=\n\n@\n\n\"\n\nTE%\n'F\n\n\"\n\nA\n\n!\n\n7>\n\"\n\n\"\n\n+\n!\n\n'\n\n#1\n\nE0:\nF\n\n=\n@\n\n4\"\n\n\"\n=\n\nD\n\n\"\n\n\"\n=\n\n@\n\n\"\n\n\"\n=\n\nE0:\nF\n\"\n\n\"\n\n4\"\n\n\"\n=\n\n=\n\nÃ\n\n\"\n\n\"\n\n@\n\nÃ\n\n\"\n\n\"\n\n%\n&\n+<+\n\n+<\n+\n\nA\n\nA\n\nB\n\nA\n\nV\n\nB\n\n-.\n\nB\n\nB\n\nD\n\n++++\n\nB\n\n.\n\nK\n*\n\n*\n\n'\n\n+++0\n\nE>>\nF\n\nB\n\n.\n\n+\nH\n\n+\n\n.\n\nB\n\n+\nH\n\n+\n\n%\n\nV\n\nB\n\nA\n\nO5\n\n$\nA\n\n'\n\nA\n\n@\nE7>\nF\n\n8@"
    },
    {
      "category": "Resource",
      "title": "biane_ess2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/d709bd7785bc30c3535139c76f77e3f4_biane_ess2.pdf",
      "content": "Characters\nof\nsymmetric\ngroups\nand\nfree\ncum\nulan\nts\nPhilipp\ne\nBiane\nAbstra\nct\nW\ne\nin\nv\nestigate\nKero\nvs\nform\nula\nexpressing\nthe\nnormalized\nirre\nducible\nc\nharacters\nof\nsymmetric\ngroups\nev\naluated\non\na\ncycle\nin\nterms\nof\nthe\nfree\ncum\nulan\nts\nof\nthe\nasso\nciated\nY\noung\ndiagrams\n\nIn\ntro\nduction\nLet\n\nb\ne\na\nprobabilit\ny\nmeasure\non\nR\nwith\ncompact\nsupp\nort\nIts\nCauc\nh\ny\ntrans\nform\nhas\nthe\nexpansion\nZ\n\nX\n\nM\nk\nz\nk\n\nG\n\nz\n\ndx\n\nz\n\nz\n\nx\nR\nk\n\nwhere\nthe\nM\nk\nare\nthe\nmomen\nts\nof\nthe\nmeasure\n\nThis\nLauren\nt\nseries\nhas\nan\nin\nv\nerse\nfor\ncomp\nosition\nK\nz\n\nwith\nan\nexpansion\n\nX\nR\nk\nz\nk\n\nK\n\nz\n\nz\n\nk\n\nThe\nR\nk\nare\ncalled\nthe\nfree\ncum\nulan\nts\nof\n\nand\ncan\nb\ne\nexpressed\nas\np\nolynomials\nin\nterms\nof\nthe\nmomen\nts\nF\nree\ncum\nulan\nts\nsho\nw\nup\nin\nthe\nasymptotic\nb\neha\nviour\nof\nc\nharacters\nof\nlarge\nsymmetric\ngroups\nMore\nprecisely\n\nl e t\n\nb\ne\na\nY\noung\ndiagram\nto\nwhic\nh\nw\ne\nasso\nciate\na\npiecewise\na ne\nfunction\n\nR\n\nR\nwith\nslop\nes\n\nsuc\nh\nthat\n\nx\n\njxj\nfor\njxj\nlarge\nenough\nas\nin\nFig\n\nb\nelo\nw\nwhic\nh\ncorresp\nonds\nto\nthe\npartition\n\nAlternativ\nely\nw\ne\ncan\nenco\nde\nthe\nY\noung\ndiagram\nusing\nthe\nlo\ncal\nminima\nand\nlo\ncal\nmaxima\nof\nthe\nfunction\n\ndenoted\nb\ny\nx\n\nx\nm\nand\ny\n\ny\nm\nresp\nectiv\nely\n\nwhic\nh\nf o r m\nt\nw\no\ni n\nterlacing\nsequences\nof\nin\ntegers\nThese\n\nMathematics\nSubje\nct\nClassic\nation\nPrimary\n\nSecondary\n\nPHILIPPE\nBIANE\nare\n\nand\n\nresp\nectiv\nely\nin\nthe\npicture\nx\n\ny\n\nx\n\ny\n\nx\n\ny\n\nx\n\nF\nig\n\nAsso\nciated\nwith\nthe\nY\noung\ndiagram\nthere\nis\na\nunique\nprobabilit\ny\nmeasure\n\non\nthe\nreal\nline\nsuc\nh\nt h a t\nZ\nQ\nm\n\ni\nz\n\ny\ni\n\ndx\n\nQ\nm\nfor\nall\nz\n\nC\nn\nR\nz\n\nx\nR\ni\nz\n\nx\ni\n\nThis\nprobabilit\ny\nmeasure\nis\nsupp\norted\nb\ny\nthe\nset\nfx\n\nx\nk\ng\nand\nis\ncalled\nthe\ntransition\nmeasure\nof\nthe\ndiagram\nsee\nK\nW\ne\nshall\ndenote\nb\ny\nR\nj\n\nits\nfree\ncum\nulan\nts\nLet\n\nS\nn\nb\ne\na\np\nerm\nutation\nwith\nk\n\ncycles\nof\nlength\n\nk\n\nof\nlength\n\nP\n\netc\nW\ne\nshall\nk\neep\nk\n\nk\n\nxed\nand\ndenote\nr\n\nj\n\nj\nk\nj\n\nwhile\nw\ne\nlet\nn\n\nThe\nnormalized\nc\nharacter\n\nasso\nciated\nto\na\nY\noung\ndiagram\nwith\nn\ncells\nhas\nthe\nfollo\nwing\nasymptotic\nev\naluation\nfrom\nB\n\nY\nr\n+1\nk\nj\n\nR\nj\n\nn\nr\n\nO\nn\n\nj\n\nHere\nthe\nO\nterm\nis\nuniform\no\nv\ner\nall\nY\noung\ndiagrams\nwhose\nn\num\nb\ners\nof\nro\nws\nand\ncolumns\nare\n\nA\np\nn\nfor\nsome\nconstan\nt\nA\nand\nall\np\nerm\nutations\nwith\nr\n\nr\n\nfor\nsome\nr\n\nAs\nremark\ned\nb\ny\nS\nKero\nv\nK\n\nfree\ncum\nulan\nts\ncan\nb\ne\nused\nto\nget\nuniv\nersal\nexact\nform\nulas\nfor\nc\nharacter\nv\nalues\nMore\nprecisely\nconsider\nthe\nfollo\nwing\nquan\ntities\n\nk\n\nnn\n\nn\n\nk\n\nc\nk\n\nfor\nk\n\nwhere\nc\nk\nis\na\ncycle\nof\norder\nk\nwith\nc\n\ne\nTheorem\n\nKero\nvs\nform\nula\nfor\nc\nharacters\nTher\ne\nexist\nuniversal\np\nolyno\nmials\nK\n\nK\n\nK\nm\n\nwith\ninte\nger\nc\no\necients\nsuch\nthat\nthe\nfol\nlowing\nidenti\nties\nhold\nfor\nany\nn\nand\nany\nY\noung\ndiagr\nam\n\nwith\nn\nc\nel\nls\n\nk\n\nK\nk\nR\n\nR\n\nR\nk\n\nW\ne\nlist\nthe\nfew\nrst\nsuc\nh\np\nolynomials\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\n\nThe\nco\ne cien\nts\nof\nKero\nvs\np\nolynomials\nseem\nto\nha\nv\ne\nsome\nin\nteresting\ncom\nbinatorial\nsignicance\nalthough\nthe\nsituation\nis\nfar\nfrom\nb\neing\nundersto\no\nd\nIn\nthis\npap\ner\nw\ne\nshall\ngiv\ne\na\npro\nof\nof\nthe\nab\no\nv\ne\ntheorem\ncompute\nsome\nof\nthe\nco\ne cien\nts\nin\nthe\nform\nula\nas\nw\nell\nas\ngiv\ne\nsome\ninsigh\nt\ni n\nto\nthis\nproblem\nThis\npap\ner\nis\norganized\nas\nfollo\nws\nIn\nSection\n\nw\ne\ngather\nsome\ninformation\non\nfree\ncum\nulan\nts\nBo\nolean\ncum\nulan\nts\nand\ntheir\ncom\nbinatorial\nsignicance\nIn\nSection\n\nw\ne\ni n\ntro\nduce\nsome\nelemen\nts\nin\nthe\ncen\nter\nof\nthe\nsymmetric\ngroup\nalgebra\nThese\nare\nused\nin\nSection\n\nto\ngiv\ne\na\ncom\nbinatorial\npro\nof\nof\nTheorem\n\nIn\nSection\n\nw\ne\ngiv\ne\nanother\npro\nof\nbased\non\na\nform\nula\nof\nF\nrob\nenius\nwhic\nh\nyields\na\ncomputationally\ne cien\nt\nform\nula\nfor\ncomputing\nKero\nvs\np\nolynomials\nIn\nSection\n\nw\ne\ncompute\nthe\nco\ne cien\nts\nof\nthe\nlinear\nterms\nof\nKero\nvs\np\nolynomials\nas\nw\nell\nas\nsome\nco\ne cien\nts\nof\ndegree\n\nW\ne\nmak\ne\nsome\nremarks\nin\nSection\n\non\nthe\np\nossible\ncom\nbinatorial\nsignicance\nof\nthe\nco\ne cien\nts\nof\nKero\nvs\np\nolynomials\nThis\nin\nv\nolv\nes\nin\na\nnatural\nw\na\ny\nthe\nCa\nyley\ngraph\nof\nthe\nsymmetric\ngroup\nFinally\nin\nSection\n\nw\ne\nlist\nthe\nv\nalues\nof\nKero\nv\np\nolynomials\nup\nto\n\nI\nw\nould\nlik\ne\nto\nthank\nA\nOk\nounk\no\nv\nand\nR\nStanley\nfor\nuseful\ncomm\nunication\nas\nw\nell\nas\nG\nOlshanski\nfor\npro\nviding\nme\na\ncop\ny\no f\nIO\n\nNoncrossing\npartitions\nmomen\nts\nand\nfree\ncum\nulan\nts\nF\nrom\nthe\nrelation\nb\net\nw\neen\nmomen\nts\nand\ncum\nulan\nts\ngiv\nen\nb\ny\n\nG\n\nK\nhi\n\nw\ne\nobtain\nb\ny\nLagrange\nin\nv\nersion\nform\nula\nthat\n\nG\n\nz\n\nk\n\nz\nR\nk\n\nk\n\nwhere\nz\n\nLz\n\ndenotes\nthe\nco\ne cien\nt\no f\nz\n\nin\nthe\nexpansion\nof\na\nLauren\nt\nseries\nLz\n\nF\nrom\nthis\nw\ne\nget\nthat\nthe\nco\ne cien\nt\no f\nM\nl\n\nM\nl\nr\nin\nR\nk\nis\nequal\nto\n\nr\nP\n\nl\ni\n\nl\nl\nr\nk\n\ni\n\nl\n\nl\nr\nk\n\nP\nif\nk\n\nj\nl\nj\n\nand\nto\n\nif\nnot\nj\nCon\nv\nersely\none\nhas\n\nK\nz\n\nk\n\nM\nk\n\nz\nk\n\nP\nand\nthe\nco\ne cien\nt\no f\nR\nl\n\nR\nl\nr\nin\nM\nk\n\nwith\nk\n\ni\nil\ni\nis\nequal\nto\n\nr\nk\n\nP\nl\n\nl\nr\nk\n\nl\ni\n\ni\nIt\nwill\nb\ne\nalso\nin\nteresting\nto\nin\ntro\nduce\nthe\nseries\n\nX\nH\n\nz\n\nG\n\nz\n\nz\n\nB\nk\nz\nk\nk\n\nThe\nco\ne cien\nts\nB\nk\nin\nthis\nform\nula\nare\ncalled\nBo\nolean\ncum\nulan\nts\nSW\nand\nthe\nP\nco\ne cien\nt\nfor\nB\nl\n\nB\nl\nr\nin\nM\nk\n\nw ith\nj\nj\nl\nj\n\nk\nis\nthe\nm\nultinomial\nco\ne cien\nt\n\nr\nl\n\nl\n\nl\nr\n\nl\n\nl\n\nl\nr\n\nA\nc o m\nbinatorial\nin\nterpretation\nof\nthese\nform\nulas\nis\naorded\nb\ny\nR\nS p\ne i c\nhers\nw\nork\nSp\nwhic\nh\nw\ne\nr e c a l l\nn o\nw\nA\nnoncrossing\npartition\nof\nf\n\nk\ng\nis\na\npartition\nsuc\nh\n\nPHILIPPE\nBIANE\nthat\nthere\nare\nno\na\nb\nc\nd\nwith\na\n\nb\n\nc\n\nd\na\nand\nc\nb\nelong\nto\nsome\nblo\nc\nk\no f\nt h e\npartition\nand\nc\nd\nb\nelong\nto\nsome\nother\nblo\nc\nk\nThe\nnoncrossing\npartitions\nform\na\nrank\ned\nlattice\nwhic\nh\nwill\nb\ne\ndenoted\nb\ny\nN\nC\nk\n\nW\ne\nshall\nuse\nthe\norder\nopp\nosite\nto\nthe\nrenemen\nt\norder\nso\nthat\nthe\nrank\nof\na\nnoncrossing\npartition\nis\nk\n\nn\num\nb\ne r\nof\nparts\nThe\nrelation\nb\net\nw\neen\nmomen\nts\nand\nfree\ncum\nulan\nts\nno\nw\nr e a d s\nX\n\nM\nk\n\nR\n\nN\nC\n\nk\n\nwhere\nfor\na\nnoncrossing\npartition\n\nr\n\none\nhas\nR\n\nQ\ni\nR\nj\ni\nj\n\nwhere\nj\ni\nj\nis\nthe\nn\num\nb\ner\nof\nelemen\nts\nof\nthe\npart\n\ni\n\nIt\nfollo\nws\nfrom\n\nthat\nthe\nP\nco\ne cien\nt\no f\nR\nl\n\nR\nl\nr\nin\nthe\nexpression\nof\nM\nk\nwith\nk\n\nil\ni\n\nis\nequal\nto\nthe\n\nr\nn\num\nb\ner\nof\nnoncrossing\npartitions\nin\nN\nC\nk\n\nw ith\nl\ni\nparts\nof\ni\nelemen\nts\nand\nis\ngiv\nen\nb\ny\n\nA\nparallel\ndev\nelopmen\nt\nc a n\nb\ne\nmade\nfor\nthe\nconnection\nb\ne t\nw\neen\nBo\nolean\ncu\nm\nulan\nts\nand\nmomen\nts\nA\npartition\nof\nf\n\nk\ng\nis\ncalled\nan\nin\nterv\nal\npartition\nif\nits\nparts\nare\nin\nterv\nals\nThe\nin\nterv\nal\npartitions\nform\na\nlattice\nB\nk\n\nwhic\nh\nis\nisomorphic\nto\nthe\nlattice\nof\nall\nsubsets\nof\nf\n\nk\ng\nassign\nto\nan\nin\nterv\nal\npartition\nthe\ncom\nplemen\nt\ni n\nf\n\nk\ng\nof\nthe\nset\nof\nlargest\nelemen\nts\nin\nthe\nparts\nof\nthe\npartition\nThe\nform\nula\nfor\nexpressing\nthe\nM\nk\nin\nterms\nof\nthe\nB\nk\nis\nX\n\nM\nk\n\nB\n\nB\n\nk\n\nOn\ncen\ntral\nelemen\nts\nin\nthe\ngroup\nalgebra\nof\nthe\nsymmetric\ngroup\nLet\n\nb\ne\na\nY\noung\ndiagram\nand\nfor\nn\n\nj j\nlet\n\nb\ne\na\none\nto\none\nmap\nfrom\nthe\ncells\nof\n\nto\nthe\nset\nf\n\nn g\nConsider\nthe\nasso\nciated\np\nerm\nutation\n\nwhose\ncycles\nare\ngiv\nen\nb\ny\nthe\nro\nws\nof\nthe\nmap\n\nF\nor\nexample\nthe\nfollo\nwing\nmap\nwith\nn\n\ngiv\nes\nthe\np\nerm\nutation\nwith\ncycle\ndecomp\nosition\n\n14 24 1\n\n22 13\n\nF\nig\n\nIf\n\nis\nthe\nset\nof\nsuc\nh\nmaps\ndened\non\n\nw\ne\nshall\ncall\na\nn\nthe\nelemen\nt\nin\nthe\ngroup\nalgebra\nof\nS\nn\ngiv\nen\nb\ny\nX\na\nn\n\nsee\nK\nO\nIf\n\nhas\none\nro\nw\nof\nlength\nl\n\nw\ne\ncall\na\nln\nthe\ncorresp\nonding\nelemen\nt\nNote\nthat\na\nn\n\nne\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\n\nLemma\n\nTher\ne\nexists\nuniversal\np\nolynomials\nP\n\nwith\ninte\nger\nc\no\necients\nsuch\nthat\nfor\nal\nl\nn\none\nhas\na\nn\n\nP\n\na\nn\n\na\njjn\n\nP\nand\nj\nj\ndeg\nP\n\na\nj\nn\n\nj j\nThe\npro\nof\nis\nb\ny\ninduction\non\nthe\nn\num\nb\ner\nof\ncells\nof\n\nThis\nis\nclear\nb\ny\ndenition\nif\n\nhas\none\nro\nw\nIf\n\nhas\nmore\nthan\none\nro\nw\nth en\nlet\n\nb\ne\n\nwith\nthe\nlast\nro\nw\ndeleted\nand\nlet\nk\nb\ne\nthe\nlength\nof\nthis\nro\nw\nOne\nhas\nX\na\n\nn\na\nk\nn\n\nwhere\n\nis\na\nmap\non\nthe\ndiagram\n\nand\n\na\nmap\non\nthe\ndiagram\nk\n\nwith\none\nro\nw\nof\nlength\nk\n\nF\nor\nan\ny\npair\n\nthere\nis\na\nunique\npair\nA\nB\nwhere\nA\nis\na\nsubset\nof\ncells\nof\n\nB\nis\na\nsubset\nof\ncells\nof\nk\n\nand\na\nbijection\n\nfrom\nA\nto\nB\nwhic\nh\ntells\non\nwhic\nh\ncells\nthe\nt\nw\no\nm a p s\n\nand\n\ncoincide\nThe\ncycle\nstructure\nof\n\ndep\nends\nonly\non\n\nk\n\nA\nB\n\nand\nnot\non\nthe\nv\nalues\ntak\nen\nb\ny\nthe\nmaps\n\nLet\n\nk\nAB\n\nb\ne\nthe\ndiagram\nwith\njj\n\nj Aj\nb\no\nxes\nputting\nsome\noneb\no\nx\nro\nws\nif\nnecessary\nof\nthis\nconjugacy\nclass\nF\nor\neac\nh\nA\nB\n\ntak\ne\nsome\ncorresp\nonding\n\nand\ntak\ne\na\nmap\non\nthe\ndiagram\n\nk\nAB\n\nw h i c\nh\nrealizes\nthe\np\nerm\nutation\n\nIf\nnecessary\nput\nthe\nxed\np\noin\nts\nin\nthe\noneb\no\nx\nr o\nws\nNo\nw\nextend\nthis\nto\nall\npairs\nof\nmaps\n\nc o\nv\narian\ntly\nwith\nresp\nect\nto\nthe\naction\nof\nS\nn\n\nEac\nh\nmap\non\n\nk\nAB\n\nis\nobtained\nexactly\nonce\nand\nif\nA\n\nB\n\nthen\nclearly\n\nk\nAB\n\nIt\nfollo\nws\nthat\nX\n\nn\na\n\nn\na\nk\nn\n\na\nn\n\na\n\nAB\n\nAB\n\njAj\nF\nor\nall\nterms\nin\nthe\nsum\none\nhas\nj\n\nAB\n\nj\n\njj\nThe\npro\nof\nfollo\nws\nb\ny\ninduction\nThe\ncondition\non\ndegrees\nis\nc\nhec\nk\ned\nalso\nb\ny\ninduction\n\nJucysMurph\ny\nelemen\nts\nand\nKero\nvs\nform\nula\nConsider\nthe\nsymmetric\ngroup\nS\nn\nacting\non\nf\n\nn g\nand\nlet\n\nb\ne\na\nnew\nsym\nb\nol\nW\ne\nim\nb\ned\nS\nn\nin\nto\nS\nn\nacting\non\nf\n\nn g\n\nfg\nIn\nthe\ngroup\nalgebra\nC\nS\nn\n\nconsider\nthe\nJucysMurph\ny\nelemen\nt\nJ\nn\n\nn\n\nwhere\ni\nj\n\ndenotes\nthe\ntransp\nosition\nexc\nhanging\ni\nand\nj\n\nLet\nE\nn\ndenote\nthe\northog\nonal\npro\njection\nfrom\nC\nS\nn\n\non\nto\nC\nS\nn\n\nie\nE\nn\n\nif\n\nS\nn\nand\nE\nn\n\nif\nnot\nIf\nw\ne\nendo\nw\nC\nS\nn\n\nwith\nits\ncanonical\ntrace\n\ne\nie\n\nis\nthe\nlinear\nextension\nof\nthe\nnormalized\nc\nharacter\nof\nthe\nregular\nrepresen\ntation\nthen\nE\nn\nis\nthe\nconditional\nexp\nectation\non\nto\nC\nS\nn\n\nwith\nresp\nect\nto\n\nW\ne\ndene\nthe\nmomen\nts\nof\nthe\nJucysMurp\ny\nelemen\nts\nb\ny\n\nM\nk\n\nE\nn\nJ\nk\nn\n\nT\no\nthis\nsequence\nof\nmomen\nts\nw\ne\ncan\nasso\nciate\na\nsequence\nof\nfree\ncum\nulan\nts\nthrough\nthe\nconstruction\nof\nsection\n\nW\ne\nc a l l\nR\nk\nthese\nfree\ncum\nulan\nts\nBy\nconstruction\nthe\nM\nk\nand\nR\nk\nb\nelong\nto\nthe\ncen\nter\nof\nthe\ngroup\nalgebra\nC\nS\nn\n\nev\nen\nto\nZ\nS\nn\n\nThe\nrelev\nance\nof\nthese\nmomen\nts\nand\ncum\nulan\nts\nis\nthe\nfollo\nwing\nLemma\n\nF\nor\nany\nn\nand\nany\nY\noung\ndiagr\nam\n\nwith\nn\nb\noxes\none\nhas\n\nR\nk\n\nR\nk\n\nPHILIPPE\nBIANE\nSince\n\nis\nan\nirreducible\nc\nharacter\nit\nis\nm\nultiplicativ\ne\non\nthe\ncen\nter\nof\nthe\nsymmetric\ngroup\nalgebra\nand\ntherefore\nit\nis\nenough\nto\nc\nhec\nk\nt h a t\n\nM\nk\n\nM\nk\n\nLet\n\nb\ne\nthe\ninduced\nc\nharacter\non\nS\nn\n\nthen\n\nM\nk\n\nn\n\nand\nthe\nresult\n\nJ\nk\n\nfollo\nws\nfrom\nthe\ncomputation\nof\neigen\nv\nalues\nof\nJucysMurph\ny\nelemen\nts\nSee\neg\nB\nSection\n\nOne\nhas\nX\n\nJ\nk\n\ni\n\ni\nk\n\nn\ni\n\ni\nk\nf\nng\nA\nterm\nin\nthis\nsum\ngiv\nes\na\nnon\ntrivial\ncon\ntribution\nto\nM\nk\nif\nand\nonly\nif\nthe\np\ner\nm\nutation\n\ni\n\ni\nk\n\nxes\n\nIn\norder\nto\nsee\nwhen\nthis\nhapp\nens\nw\ne\nha\nv\ne\nto\nfollo\nw\nthe\nimages\nof\n\nb\ny\nthe\nsuccessiv\ne\npartial\npro\nducts\nof\ntransp\nositions\nLet\nj\n\nsup fl\n\nk\nj\ni\nl\n\ni\nk\ng\nIf\nthis\nset\nis\nempt\ny\nthen\n\ni\nk\n\nIf\nnot\nthen\none\nhas\n\ni\n\ni\nj\n\nwhere\n\nhence\nw\ne\ncan\ncon\ntin\nue\nand\nlo\nok\nfor\nj\n\nsupfl\n\nj\n\nj\ni\nl\n\ni\nj\n\ng\nIn\nthis\nw\na\ny\nw\ne\nconstruct\na\nsequence\nj\n\nj\n\nIf\nand\nonly\nif\nthe\nlast\nterm\nof\nthis\nsequence\nis\n\nthen\nw\ne\nget\na\nnon\ntrivial\ncon\ntribu\ntion\nLet\n\nb\ne\nthe\npartition\nof\n\nk\nsuc\nh\nthat\nl\nand\nm\nb\nelong\nto\nthe\nsame\npart\nif\nand\nonly\nif\ni\nl\n\ni\nm\n\nThe\nfact\nthat\n\ni\n\ni\nk\n\nxes\n\ndep\nends\nonly\non\nthis\npartition\nand\nw\ne\ncall\nadmissible\npartitions\nthe\nones\nfor\nwhic\nh\n\ni\n\ni\nk\n\nxes\n\nF\nurthermore\nthe\nconjugacy\nclass\nin\nS\nn\n\nof\n\ni\n\ni\nk\n\ndep\nends\nonly\non\nthe\npartition\nLet\n\nb\ne\nt h e\nY\noung\ndiagram\nformed\nwith\nthe\nnon\ntrivial\ncycles\nof\nthis\nconjugacy\nclass\nLet\nX\nZ\n\ni\n\ni\nk\n\ni\n\ni\nk\n\nwhere\ni\n\ni\nk\n\nmeans\nthat\nthe\npartition\nasso\nciated\nto\nthe\nsequence\ni\n\ni\nk\nis\n\nthen\nw\ne\nha\nv\ne\nX\nM\nk\n\nZ\n\nadmissible\nLet\nc\n\nb\ne\nthe\nn\num\nb\ner\nof\nparts\nof\n\nthen\nthe\nn\num\nb\ner\nof\nk\ntuples\ni\n\ni\nk\n\nis\nequal\nto\nn\nc\n\nwhere\nas\nusual\nn\nk\n\nnn\n\nn\n\nk\n\nand\none\nhas\nj\nj\n\nc\n\ntherefore\none\nhas\nn\nc\n\nZ\n\nn\njj\na\n\nn\n\nn\nj j\n\nn\n\nc\n\na\n\nn\nIn\norder\nthat\n\nb\ne\na\ncycle\nof\nlength\nk\n\nit\nis\nnecessary\nan\nsu cien\nt\nthat\n\nb\ne\nthe\npartition\nf\nk\ng\nfg\nfg\n\nfk\n\ng\nAll\nother\nadmissible\npartitions\nha\nv\ne\nc\n\nk\n\nW\ne\ndeduce\nthat\nX\nM\nk\n\na\nk\nn\n\nZ\n\nadmissible\n\nc\n\nk\n\nIt\nfollo\nws\nfrom\nSection\n\nthat\nM\nk\nis\na\np\nolynomial\nwith\nin\nteger\nco\ne cien\nts\ninde\np\nenden\nt\no f\nn\nin\nthe\na\nj\nn\n\nof\nthe\nform\na\nk\nn\n\np\nolynomial\nin\na\nj\nn\n\nj\n\nk\n\nW\ne\nc a n\nt h\nus\nin\nv\nert\nthis\np\nolynomial\nrelation\nand\nget\na\nk\nn\n\nM\nk\n\np\nolynomial\nin\nM\nj\n\nj\n\nk\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\nwith\np\nolynomial\nwith\nin\nteger\nco\ne cien\nts\nSince\nM\nk\ncan\nb\ne\nexpanded\nas\np\nolyno\nmials\nwith\nin\nteger\nco\ne cien\nts\nin\nthe\nR\nj\nw\ne\nth\nus\nha\nv\ne\na\nk\nn\n\nR\nk\n\np\nolynomial\nin\nR\nj\n\nj\n\nk\n\nApplying\n\nto\nb\noth\nsides\nof\nthis\nequation\nand\nusing\nLemma\n\nw\ne\nobtain\nTheorem\n\nF\nrob\nenius\nform\nula\nand\nfree\ncum\nulan\nts\nLet\n\nb\ne\na\npartition\nof\nn\nwith\n\nand\ni\n\ni\n\nn\ni\nLet\nY\nz\n\nz\n\ni\n\nthen\nthe\nv\nalue\nof\nthe\nnormalized\nc\nharacter\n\non\na\ncycle\nof\nlength\nk\nis\ngiv\nen\nb\ny\nF\nrob\nenius\nform\nula\n\nn\nk\n\nc\nk\n\nz\n\nz\nz\n\nz\n\nk\n\nz\n\nk\nz\n\nk\nSee\nM\nI\nExample\n\npages\n\nb\new\nare\nthat\nc\nharacters\nare\nnot\nnormalized\nin\nMacdonalds\nb\no\nok\nNo\nw\nw\ne\nremark\nthat\nz\nz\n\nz\n\nG\n\nz\n\nn\n\nH\n\nz\n\nn\n\ntherefore\n\nn\nk\n\nc\nk\n\nz\n\nH\n\nz\n\nn\n\nH\n\nz\n\nn\n\nk\n\nk\nUsing\nthe\nin\nv\nariance\nof\nthe\nresidue\nunder\ntranslation\nof\nthe\nv\nariable\none\ngets\n\nn\nk\n\nc\nk\n\nz\n\nH\n\nz\n\nH\n\nz\n\nk\n\nk\nComparing\nwith\n\nw\ne\ndeduce\nthe\nfollo\nwing\nform\nula\nfor\nKero\nvs\np\nolynomials\nTheorem\n\nConsider\nthe\nformal\np\nower\nseries\n\nX\nB\nj\nz\nj\n\nH\nz\n\nz\n\nj\n\nDene\n\nk\n\nz\n\nH\n\nz\n\nH\n\nz\n\nk\n\nk\nand\n\nH\n\nz\n\nk\nR\nk\n\nz\nk\nthen\nthe\nexpr\nession\nof\n\nk\nin\nterms\nof\nthe\nR\nk\n\ns\nis\ngiven\nby\nKer\novs\np\nolynomials\nThis\nform\nula\nfor\ncomputing\nKero\nvs\np\nolynomials\nw\nas\nsho\nwn\nto\nme\nb\ny\nA\nOk\nounk\no\nv\nO\nIt\nseems\nplausible\nthat\nS\nKero\nv\nw\nas\na\nw\nare\nof\nthis\nsee\nesp\necially\nthe\naccoun\nt\no f\nK e r o\nvs\ncen\ntral\nlimit\ntheorem\nin\nIO\nIt\nis\nm\nuc\nh\neasier\nto\nimplemen\nt\nthan\nthe\nalgorithm\ngiv\nen\nb\ny\nthe\npro\nof\nin\nSection\n\nW\ne\ngiv\ne\nthe\nresult\nof\nsome\nMaple\ncomputations\nin\nSection\n\nPHILIPPE\nBIANE\n\nComputation\nof\nsome\nco\ne\ncien\nts\nof\nKero\nvs\np\nolynomials\nP\nP\nF\nor\na\nterm\nR\nk\n\nR\nk\nr\ndene\nits\nde\ngr\ne\ne\nb\ny\nj\nk\nj\nand\nits\nweight\nis\nj\nk\nj\n\nIt\n\nr\nj\nis\nclear\nfrom\nsign\nconsiderations\nthat\nin\nthe\nexpansion\nof\n\nk\nonly\nterms\nof\nw\neigh\nt\nha\nving\nthe\nopp\nosite\nparit\ny\no f\nk\no\nccur\nThe\nterm\nof\nhighest\nw\neigh\nt\ni s\nR\nk\n\nand\nit\nis\nthe\nonly\nterm\nwith\nthis\nw\neigh\nt\nas\nfollo\nws\nfrom\nTheorem\n\nW\ne\nshall\nrst\nb\ne\nin\nterested\nin\nthe\nterms\nof\ndegree\none\nTheorem\n\nThe\nc\no\necient\nof\nR\nk\nl\nin\n\nk\nis\ne\nqual\nto\nthe\nnumb\ner\nof\ncycles\nc\n\nS\nk\n\nof\nlength\nk\n\nsuch\nthat\n\nk\n\nc\nhas\nk\n\nl\ncycles\nIn\norder\nto\npro\nv\ne\nthe\ntheorem\nw\ne\nshall\ncompute\nthe\ngenerating\nfunction\nfor\nthe\nlinear\nco\ne cien\nts\nusing\nTheorem\n\nform\nula\nSince\nw\ne\nare\nin\nterested\nonly\nin\nlinear\nterms\nw\ne\nsee\nthat\nthe\nform\nula\nexpressing\n\nk\nin\nterms\nof\nR\nj\nis\nthe\nsame\nas\nthe\none\nin\nterms\nof\nB\nj\n\nPut\nB\ni\n\ntx\ni\n\nW\ne\nshall\nnd\nthe\nco\ne cien\nt\nof\nz\n\nin\nH\nz\nH\nz\n\nH\nz\n\nk\n\nk\neeping\nonly\nthe\nterms\nwith\ndegree\none\nin\nt\nOne\nhas\nH\nz\n\nz\n\ntxz\n\nx\ntherefore\nk\n\nt\nH\nz\nH\nz\n\nH\nz\n\nk\n\nx\nX\nz\nz\n\nz\n\nk\n\nz\n\nk\nz\n\nx\n\nj\n\nj\n\nUsing\nagain\nin\nv\nariance\nof\nresidue\nb\ny\ntranslation\none\nobtains\nk\n\nk\n\nk\n\nX\n\nX\nY\n\nX\n\nx\nl\nR\nk\nl\n\nk\n\nx\n\nj\n\nl\n\nQ\nk\nx\n\nl\n\nk\nk\nl\nj\n\nl\nl\nwhere\nQ\nk\nx\n\nxx\n\nx\n\nk\n\nDenote\nb\ny\nd\n\nthe\ndimension\nof\nthe\nirreducible\nrepresen\ntation\nwith\nY\noung\ndia\ngram\n\nLemma\n\nL\net\n\nb\ne\na\nY\noung\ndiagr\nam\nwith\nk\nc\nel\nls\nlet\nX\nP\n\nx\n\nx\n\nc\n\nb\ne\nits\nc\nontent\np\nolynomial\nand\nc\n\nnumb\ner\nof\ncycles\nof\n\nthen\nX\nd\n\nx\nl\n\nP\n\nx\n\nS\nk\nSee\nM\n\nI\nExample\n\nI\nExample\n\nand\n\nLet\nc\nk\nb\ne\nthe\ncycle\n\nk\n\nb\ny\nthe\northogonalit\ny\nrelations\nfor\nc\nharacters\nand\nLemma\n\none\nhas\nX\nX\n\nd\n\nc\nk\nP\n\nxP\n\ny\n\nx\nl\n\n;1\nc\nk\n\ny\nl\n\nk\n\nS\nk\nLet\nus\ncompute\nthe\nco\ne cien\nt\nof\ny\nin\nthe\nleft\nhand\nside\nof\n\nOnly\nho\nok\ndiagrams\n\nk\n\nl\n\nl\n\nfor\nl\n\nk\n\ncon\ntribute\nand\nfor\nsuc\nh\na\ndiagram\n\nd\n\nc\nk\n\nk\n\nl\n\nOne\nhas\nP\n\nx\n\nQx\n\nl\n\nthe\nco\ne cien\nt\no f\ny\nin\n\nP\n\ny\n\nl\nk\n\nis\n\nk\n\nand\nP\n\nx\n\nQx\n\nl\n\ntherefore\nw\ne\nn d\nf o r m\nula\n\nfor\nthe\nleft\nhand\nk\nl\nside\nComparing\nwith\nthe\nrigh\nt\nhand\nside\nw\ne\nget\nTheorem\n\nTheorem\n\nhas\nalso\nb\ne e n\npro\nv\ned\nb\ny\nR\nStanley\nSt\nb\ny\na\nclosely\nrelated\nmetho\nd\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\n\nTheorem\n\nThe\nc\no\necient\nof\nR\nk\n\nR\n\nin\n\nk\nfor\nk\n\nis\nk\n\nk\nk\n\nk\n\nAgain\nthis\nfollo\nws\nfrom\nTheorem\n\nthrough\nsome\nlength\ny\n\nbut\nstraigh\ntforw\nard\ncomputations\nwhic\nh\nare\nomitted\nMore\ngenerally\n\nbased\non\nn\numerical\nin\nv\nestigations\nw\ne\nconjecture\nthe\nfollo\nwing\nform\nula\nfor\nterms\nof\nw\neigh\nt\nk\n\nConjecture\n\nThe\nc\no\necient\nof\nR\nl\n\nR\nl\ns\nin\n\nk\n\nwith\nk\n\nl\n\nl\n\ns\n\nsl\ns\n\nis\ne\nqual\nto\ns\nY\nk\n\nk\nk\n\nl\n\nl\ns\n\nj\n\nl\nj\n\nl\n\nl\ns\n\nj\n\nThe\nv\nalidit\ny\nof\nthis\nconjecture\nhas\nb\neen\nc\nhec\nk\ned\nup\nto\nk\n\nA\npro\nof\nfor\nthe\nother\ncases\nat\nleast\nfor\ndegree\nt\nw\no\nterms\ncan\npresumably\nb\ne\ngiv\nen\nusing\nTheorem\n\nbut\nthe\ncomputations\nb\necome\nquic\nkly\nv\nery\nin\nv\nolv\ned\nNo\nsuc\nh\nsimple\npro\nduct\nform\nula\nseems\nto\nb\ne\na\nv\nailable\nfor\nthe\ngeneral\nterm\nAnother\nnatural\nconjecture\nis\nthat\nall\nco\ne cien\nts\nin\nKero\nvs\nform\nula\nare\nnon\nnegativ\ne\ni n\ntegers\nwhic\nh\nalso\nhas\nb\neen\nc\nhec\nk\ned\nup\nto\nk\n\nSee\nthe\nnext\nSection\nfor\nmore\non\nthis\n\nConnection\nwith\nthe\nCa\nyley\ngraph\nof\nsymmetric\ngroup\n\nLet\nus\nexplore\nmore\nthoroughly\nthe\nconnections\nb\net\nw\neen\nthe\nM\nk\n\nB\nk\n\nR\nk\nand\nk\n\nF\norm\nulas\n\nand\n\npro\nvide\na\nnatural\ncom\nbinatorial\nmo\ndel\nfor\nexpressing\nmomen\nts\nin\nterms\nof\nfree\nor\nBo\nolean\ncum\nulan\nts\nW\ne\nwill\nb\ne\nlo\noking\nfor\nsimilar\nmo\ndels\nfor\nexpressing\nthe\nother\nconnections\nObserv\ne\nrst\nthat\nfor\nall\nmeasures\nasso\nciated\nwith\nY\noung\ndiagrams\none\nhas\nM\n\nB\n\nR\n\nW\ne\nwill\nrestrict\nourselv\nes\nto\nthis\ncase\nin\nthe\nfollo\nwing\nLet\nus\napply\nKero\nvs\nform\nula\nto\nthe\ntrivial\nc\nharacter\nAs\nw\ne\nshall\nsee\nthis\nwill\ngiv\ne\na\nlot\nof\ninformation\nThe\nprobabilit\ny\nmeasure\nasso\nciated\nwith\nthe\ntrivial\nc\nharacter\nis\nn\n\nn\nwith\nCauc\nh\ny\ntransform\nn\nn\nz\n\nn\n\nGz\n\nz\n\nz\n\nn\nThe\ncorresp\nonding\nmomen\nts\nare\nX\nn\n\nM\nk\n\nk\n\nn\nk\n\nn\nn\nk\n\nk\n\nk\n\nk\n\nn\nj\nn\n\nn\n\nn\n\nj\n\nW\ne\nwill\nnd\nit\nuseful\nto\nin\nterpret\nthis\nas\nthe\ngenerating\nfunction\nfor\nthe\nrank\nin\na\ntotally\nordered\nset\nwith\nk\n\nelemen\nts\nW\ne\nt a k\ne\nthis\ntotally\nordered\nset\nas\nthe\nset\nI\nk\n\nof\npartitions\nof\nf\n\nk\n\ng\ngiv\nen\nb\ny\nf\n\nj\ng\nfj\n\ng\nfj\n\ng\n\nfk\n\ng\nand\nthe\nrank\nis\nthe\nn\num\nb\ner\nof\nparts\nX\n\nM\nk\n\nk\n\nn\nj\nj\n\nI\nk\n;1\n\nPHILIPPE\nBIANE\nThe\nk\nth\nfree\ncum\nulan\nt\nof\nthis\nmeasure\nis\nthe\ngenerating\nfunction\n\nk\n\nX\nX\n\nk\n\nk\n\nn\nl\n\nk\n\nR\nk\n\nk\n\nk\n\nl\n\nl\nn\nj\nj\n\nl\n\nN\nC\n\nk\n\nF\nor\nthe\nBo\nolean\ncum\nulan\nts\none\nnds\n\nk\n\nX\nB\nk\n\nnn\n\nk\n\nk\n\nX\nk\n\nn\nj\n\nk\n\nn\nj\nj\n\nj\n\nj\n\nB\n\nk\n\nThe\nev\naluation\nof\nthe\ntrivial\nc\nharacter\non\n\nk\ngiv\nes\nnn\n\nn\n\nk\n\nThis\nis\nthe\ngenerating\nfunction\nrecall\nthat\nl\n\nis\nthe\nn\num\nb\ner\nof\ncyles\nof\n\nX\n\nk\n\nk\n\nn\nl\n\nS\nk\nL e t\nu s\nn o\nw\nconcen\ntrate\non\nthe\nform\nula\nexpressing\nthe\nfree\ncum\nulan\nts\nin\nterms\nof\nBo\nolean\ncum\nulan\nts\nand\nthe\nBo\nolean\ncum\nulan\nts\nin\nterms\nof\nmomen\nts\nThe\nrst\nsuc\nh\nexpressions\nare\nR\nR\nR\n\nB\n\nB\n\nB\n\nB\n\nR\nR\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nR\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\nB\nB\n\nM\n\nM\n\nM\n\nM\n\nB\nB\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nB\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nM\n\nThese\nform\nulas\ncon\ntain\nsigns\nbut\nw\ne\ncan\nmak\ne\nall\nco\ne cien\nts\np\nositiv\ne\nb\ny\na n\no\nv\nerall\nsign\nc\nhange\nof\nall\nv\nariables\nW\ne\nare\ngoing\nto\ngiv\ne\na\nc o m\nbinatorial\nin\nterpretation\nof\nthese\nco\ne cien\nts\nLet\nus\nreplace\nmomen\nts\nfree\ncum\nulan\nts\nand\nBo\nolean\ncum\nulan\nts\nb\ny\nt h e\nv\nalues\n\nand\n\nIt\nseems\nnatural\nto\ntry\nto\nin\nterpret\nthe\nform\nulas\nexpressing\nfree\ncum\nulan\nts\nas\npro\nviding\na\ndecomp\nosition\nof\nthe\nlattice\nof\nnoncrossing\npartitions\nN\nC\nk\n\nB\n\nin\nto\na\ndisjoin\nt\nunion\nof\nsubsets\nwhic\nh\nare\npro\nducts\nof\nBo\nolean\nlattices\nwhereas\nthe\nform\nula\nexpressing\nBo\nolean\ncum\nulan\nts\nshould\ncome\nfrom\na\ndecomp\nosition\nof\nthe\nBo\nolean\nlattice\nB\nk\n\nI\n\nin\nto\na\nunion\nof\npro\nducts\nof\ntotally\nordered\nsets\nIt\nturns\nout\nthat\nsuc\nh\ndecomp\nositions\nexist\nand\nw\ne\nshall\nno\nw\ndescrib\ne\nthem\nFirst\nw\ne\nl o\no k\na t\nt h e\nf o r m\nula\nfor\nexpressing\nBo\nolean\ncum\nulan\nts\nin\nterms\nof\nmomen\nts\nOn\nthe\nBo\nolean\nlattice\nof\nin\nterv\nal\npartitions\nlet\nus\nput\na\nnew\nstronger\norder\nrelation\nF\nor\nthis\nnew\norder\na\nco\nv\ners\nb\nif\nand\nonly\nif\nb\ncan\nb\ne\nobtained\nfrom\na\nb\ny\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\nM\ndeleting\nthe\nlast\nelemen\nt\nof\nsome\nin\nterv\nal\nif\nthis\nin\nterv\nal\nhad\nat\nleast\nthree\nelemen\nts\nor\nif\nit\nis\nthe\nin\nterv\nal\n\nThe\nresulting\ndecomp\nosition\nof\nthe\nBo\nolean\nlattice\nof\nin\nterv\nal\npartitions\nof\nf\n\ng\nis\nsho\nwn\nin\nthe\nfollo\nwing\npicture\nIt\ncorresp\nonds\nto\nthe\nform\nula\nfor\nB\n\nab\no\nv\ne\nThe\nrst\nline\nin\nthe\npicture\ncorresp\nonds\nto\nthe\nin\nterv\nal\nM\n\nthe\nsecond\nand\nthird\nline\naccoun\nt\nfor\nthe\nt\nw\no\nin\nterv\nals\nM\n\nM\n\nthe\nfourth\nline\nfor\nthe\npro\nduct\nin\nterv\nal\nM\n\nand\nthe\nlast\nline\nfor\nthe\np\noin\nt\ncorresp\nonding\nto\n\nThe\nranking\nis\nhorizon\ntal\nThe\npro\nof\nthat\nthis\ndecomp\nostion\nyields\nthe\nrigh\nt\nin\nterpretation\nof\nthe\nBo\nolean\ncum\nulan\ntmomen\nt\nform\nula\nis\neasy\nand\nleft\nto\nthe\nreader\nF\nig\n\nNo\nw\nlet\nus\ndecomp\nose\nthe\nlattice\nof\nnoncrossing\npartitions\nin\nto\na\nunion\nof\nBo\nolean\nlattices\nF\nor\nthis\nw\ne\nput\nthe\nfollo\nwing\nnew\norder\non\nnoncrossing\npartitions\nA\nnoncrossing\npartition\na\nco\nv\ners\na\nnoncrossing\npartition\nb\nif\nand\nonly\nif\nb\ncan\nb\ne\nobtained\nfrom\na\nb\ny\ncutting\na\npart\nof\nb\nb\ne t\nw\neen\nt\nw\no\nsuccessiv\ne\nelemen\nts\ni\ni\n\nF\nor\nexample\nw\ne\ng i v\ne\nhere\nthe\nlist\nof\nthe\nBo\nolean\nin\nterv\nals\nobtained\nin\nthis\nw\na\ny\ni n\nN\nC\n\ncorresp\nonding\nto\nthe\nform\nula\nfor\nR\n\nNext\nto\neac\nh\ni n\nterv\nal\nw\ne\ngiv\ne\nthe\nterm\nto\nwhic\nh\nit\ncorresp\nonds\nin\nthe\nform\nula\nConsider\nthe\nCa\nyley\ngraph\nof\nS\nk\nwith\nresp\nect\nto\nthe\ngenerating\nset\nof\nall\ntransp\nositions\nThe\nlattice\nN\nC\nk\n\ncan\nb\ne\nem\nb\nedded\nin\nto\nS\nk\n\nas\nthe\nsubset\nof\nelemen\nts\nlying\non\na\ngeo\ndesic\nfrom\ne\nto\nthe\nfull\ncycle\nk\n\nIn\nthis\nem\nb\nedding\nthe\ncycles\nof\na\np\nerm\nutation\ncorresp\nond\nto\nthe\nparts\nof\na\npartition\nhence\nthe\nfunctions\nj\nj\nand\nl\n\nW\ne\ng i v\ne\nin\nthe\nnotation\nthe\ncycle\nstructure\nof\na\n\nnoncrossing\npartition\nas\nan\nelemen\nt\no f\nS\nk\n\nAn\nin\nterv\nal\n\nin\nw hic\nh\n\nhas\na\nl\nk\ncycle\nstructure\n\nl\n\nk\nl\nk\ncorresp\nonds\nto\na\nterm\nB\ns\n\nB\nl\nB\nl\n\nB\nk\n\nw here\ns\nis\nsuc\nh\n\nthat\nthe\nrank\nof\n\nis\ns\n\nl\n\nl\nk\n\ne\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nB\n\nObserv\ne\nthat\neac\nh\ni n\nterv\nal\nab\no\nv\ne\nis\nin\nfact\nan\nin\nterv\nal\nfor\nthe\nBruhat\norder\n\nPHILIPPE\nBIANE\nLo\noking\nat\nthe\nab\no\nv\ne\nresults\nand\nat\nTheorem\n\nit\nis\ntempting\nto\ntry\nin\nterpreting\nKero\nv\np\nolynomials\nas\ncoming\nfrom\na\ndecomp\nosition\nof\nthe\nsymmetric\ngroup\nin\nto\nin\nterv\nals\nfor\nsome\nsuitable\norder\nrelation\nin\nwhic\nh\nthe\nadjacency\nrelation\nshould\nb\ne\ninduced\nb\ny\nthe\none\nof\nthe\nCa\nyley\ngraph\nThe\nco\ne cien\nt\nof\nR\nl\n\nR\nl\ns\nw\nould\ncoun\nt\nthe\nn\num\nb\ne r\nof\nin\nterv\nals\nisomorphic\nto\nthe\nordered\nset\n\ns\nN\nC\n\nl\nN\nC\n\nl\n\nN\nC\ns\n\nl\ns\n\nSuc\nh\nin\nterv\nal\nw\nould\nb\ne\nof\nthe\nform\n\nwith\nP\nP\nj\nj\n\nk\n\nl\nj\n\nand\nj\n\nj\n\nk\n\nl\nj\n\nThe\nob\nvious\nc\nhoice\nfor\nS\nj\nj\nthe\nrst\nterm\nR\nk\n\nin\n\nk\nw\nould\nb\ne\nto\ntak\ne\nthe\nset\nof\ngeo\ndesics\nfrom\ne\nto\n\nk\n\nObserv\ne\nh o\nw\nev\ner\nthat\nb\necause\nof\nsign\nproblems\nw\ne\nshould\nget\na\nsigned\nco\nv\nering\nof\nk\n\nnamely\neac\nh\nelemen\nt\no f\nS\nk\nw\nould\nb\ne\ncon\ntained\nin\na\ncertain\nn\num\nb\ne r\no f\ni n\nterv\nals\nand\nin\nterv\nals\ncorresp\nonding\nto\nterms\nof\nev\nen\ndegree\nw\nould\ngiv\ne\na\nm\nultiplicit\ny\no n e\nwhile\nterms\nof\no\nd d\ndegree\nw\nould\ngiv\ne\na\nm\nultiplicit\ny\n\nthe\nsum\nof\nm\nultiplicities\nw\nould\nthen\nb\ne\n\nfor\nan\ny\n\nS\nk\n\nOne\nw\na\ny\nto\nget\naround\nthis\nproblem\nof\nsigned\nco\nv\nering\nw\nould\nb\ne\nto\nlo\nok\nat\nthe\nexpression\nof\nc\nharacters\nin\nterms\nof\nBo\nolean\ncum\nulan\nts\nwhere\nthis\nproblem\ndisapp\nears\nOne\nw\nould\nthen\nb\ne\nlead\nto\nlo\nok\nfor\na\ndecomp\nosition\nof\nthe\nCa\nyley\ngraph\nin\nto\na\nunion\nof\npro\nducts\nof\nBo\nolean\nlattices\nIt\nis\nhere\nnatural\nto\ntry\ndoing\nso\nb\ny\nusing\nthe\nBruhat\norder\nIndeed\nsome\ndecomp\nositions\nof\nthe\nsymmetric\ngroup\nin\nto\nBo\nolean\nlattices\nha\nv\ne\napp\neared\nin\nthe\nlitterature\nLS\n\nM\nbut\nthey\nare\nnot\nthe\nones\nw\ne\nare\nlo\noking\nfor\nindeed\nb\ny\nTheorem\n\none\ncan\ncompute\nthe\ntotal\nn\num\nb\ne r\no f\ni n\nterv\nals\nwhic\nh\nshould\no\nccur\nin\nthe\ndecomp\nosition\nof\nS\nk\n\nand\nev\nen\nthe\ngenerating\nfunction\nof\nthe\nn\num\nb\ner\nof\nterms\naccording\nto\ntheir\ndegrees\nit\nis\ngiv\nen\nb\ny\n\nY\nS\np\nx\n\np\n\nx\np\nx\n\nii\n\nS\np\nx\n\np\n\nS\np\nx\np\np\n\nj\n\nwhereas\nthe\nab\no\nv\ne\ndecomp\nositions\nha\nv\ne\nk\n\nin\nterv\nals\nIt\nhas\nb\neen\nobserv\ned\nb\ny\nR\nStanley\nSt\nthat\nif\none\nev\naluates\nthe\nc\nharacter\nof\na\ncycle\nfor\na\nrectangular\np\n\nq\nY\noung\ndiagram\nthen\none\ncan\nimpro\nv\ne\nthe\nform\nulas\n\nto\n\nb\ny\nreplacing\nthem\nb\ny\ntheir\nhomogeneous\nt\nw\nov\nariable\ncorresp\nondan\nts\nwhile\nthe\nc\nharacter\nis\nno\nw\ngiv\nen\nb\ny\nthe\nrhs\nof\n\nwith\nx\n\np\ny\n\nq\n\nThis\ngiv\nes\nmore\nevidence\nfor\nthe\nconnection\nwith\nthe\nCa\nyley\ngraph\nof\nsymmetric\ngroup\nLet\nus\nno\nw\nlo\nok\nat\nthe\nrst\nv\nalues\nof\nk\n\nThe\ncases\nof\n\nk\nfor\nk\n\ndo\nnot\npresen\nt\ndi cult\ny\nso\nlet\nus\nconcen\ntrate\non\n\nR\n\nR\n\nR\n\nR\n\nW\ne\nalready\n\nha\nv\ne\nthe\nin\nterpretation\nof\nthe\nterms\nR\n\nand\nR\n\nthey\nshould\ncorresp\nond\nrep\nectiv\nely\nto\nthe\nin\nterv\nal\ne\n\nof\nelemen\nts\nsuc\nh\nthat\nde\n\nd\n\nd\nis\nthe\ndistance\nin\nthe\nCa\nyley\ngraph\nand\nthe\neigh\nt\none\np\noin\nt\ni n\nterv\nals\nc\nwhere\nc\nis\na\ncycle\nwhose\npro\nduct\nwith\n\nis\na\ncycle\nIt\nremains\nto\nco\nv\ner\nthe\nelemen\nts\nof\nS\n\nsatisfying\nde\n\nd\n\nb\ny\n\nin\nterv\nals\nisomorphic\nto\na\ncycle\nThis\nshould\nyield\n\nelemen\nts\nwith\nde\n\nd\n\nwhic\nh\nare\ncoun\nted\nt\nwice\nAfter\nsome\nguessw\nork\nthe\nfollo\nwing\nnon\nunique\ndecomp\nosition\ncan\nb\ne\nfound\nThe\n\nin\nterv\nals\nare\n\nand\ntheir\nconjugates\nb\ny\n\nThe\n\nelemen\nts\ncoun\nted\nt\nwice\nare\n\nCHARA\nCTERS\nOF\nSYMMETRIC\nGR\nOUPS\nAND\nFREE\nCUMULANTS\nwhic\nh\napp\nears\nin\nthe\nin\nterv\nals\n\nand\n\nand\nall\nits\nconjugates\nb\ny\n\nV\nalues\nof\n\nk\nfor\nk\n\nto\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nR\n\nReferences\nB\nP\n\nBiane\nR\nepr\nesentations\nof\nsymmetric\ngr\noups\nand\nfr\ne\ne\np r\nob\nability\nAdv\nMath\n\nIO\nV\nIv\nano\nv\nG\nOlshanski\nKer\novs\nc\nentr\nal\nlimit\nthe\nor\nem\nfor\nthe\nPlancher\nel\nme\nasur\ne\no n\nY\noung\ndiagr\nams\nPreprin\nt\nJune\n\nK\nS\nV\nKero\nv\nT\nr\nansition\npr\nob\nabilities\nof\nc\nontinual\nY\noung\ndiagr\nams\nand\nthe\nMarkov\nmoment\npr\noblem\nF\nunct\nAnal\nAppl\n\nK\nS\nV\nKero\nv\nT\nalk\nat\nIHP\nc\nonfer\nenc\ne\nJan\n\nK\nO\nS\nV\nKero\nv\nG\nOlshanski\nPolynomial\nfunctions\non\nthe\nset\nof\nY\noung\ndiagr\nams\nC\nR\nAcad\nSci\nP\naris\nS\n\ner\nI\nMath\n\nno\n\nLS\nA\nLascoux\nMP\n\nS c\nh utzen\nb\nerger\nT\nr\neil\nlis\net\nb\nases\ndes\ngr\noup\nes\nde\nCoxeter\nElectron\nJ\n\nCom\nbin\n\nNo\n\nResearc\nh\npap\ner\n\npp\nM\nI\nG\nMacdonald\nSymmetric\nfunctions\nand\nHal\nl\np\nolynomials\nSecond\nEdition\nOxford\nUniv\nPress\nOxford\n\nMo\nA\nI\nMolev\nStirling\np\nartitions\nof\nthe\nsymmetric\ngr\noup\nand\nL\naplac\ne\no p\ner\nators\nfor\nthe\northo\ng\nonal\nLie\nalgebr\na\nPro\nceedings\nof\nthe\nth\nConference\non\nF\normal\nP\no\nw\ner\nSeries\nand\nAlgebraic\nCom\nbinatorics\nNoisyleGrand\n\nDiscrete\nMath\n\nno\n\nO\nA\nOk\nounk\no\nv\nPriv\nate\ncomm\nunication\nJan\nuary\n\nSp\nR\nSp\neic\nher\nCombinatorial\nThe\nory\nof\nthe\nF\nr\ne\ne\nP r\no\nduct\nwith\nA\nmalgamation\nand\nOp\ner\nator\nV\nalue\nd\nF\nr\ne\ne\nP r\nob\nability\nThe\nory\nMemoirs\nof\nthe\nAMS\n\nSt\nR\nStanley\n\nPriv\nate\ncomm\nunication\nMa\ny\n\nSt\nR\nStanley\n\nIrr\ne\nducible\nsymmetric\ngr\noup\nchar\nacters\nof\nr\ne\nctangular\nshap\ne\nPreprin\nt\nSeptem\nb\ner\n\nPHILIPPE\nBIANE\nSW\nR\nSp\neic\nher\nR\nW\noroudi\nBo\nole\nan\nindep\nendenc\ne\nF\nree\nprobabilit\ny\n\nFields\nInstitue\nComm\nu\nnications\nD\nV\noiculescu\nEd\n\nep\nar\ntement\nde\nMa\nth\n\nEcole\nNormale\nSup\n\nCNRS\nD\n\nema\ntiques\net\nApplica\ntions\n\nerieure\n\nr\nue\ndUlm\n\np\naris\nFRANCE\nEmail\naddr\ness\n\nPhilippeBianeensfr"
    },
    {
      "category": "Resource",
      "title": "other_der_035.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/b54b3e95aac73884b294f78f41b790de_other_der_035.pdf",
      "content": "Some Elementary Results around the\nWigner Semicircle Law\nAnne Boutet de Monvel and Alexei Khorunzhy\n\nContents\nLecture 0. Introduction. Motivations and Generalities\nLecture 1. GOE and the Semicircle Law\nLecture 2. Proof of the Semicircle Law\nLecture 3. Smoothed Eigenvalue Density\nGeneralizations of Theorems 3.1-3.3 and universality conjecture\nLecture 4. Eigenvalues outside of the limiting spectrum\nBibliography\ni\n\nContents\nIn these lecture notes we give an accessible introduction to the spectral\ntheory of random matrices. We consider Gaussian Orthogonal Ensemble\nas the main subject to present and prove the semicircle (or Wigner) law.\nThis is the fundamental statement in the spectral theory of large random\nmatrices.\nWe deal in frameworks of the resolvent and moments approaches and\ngive two proofs of the semicircle law. Then we formulate the theorems that\ncan be regarded as generalizations and improvements of this statement. In\nparticular, we show the relevance of these two techniques in the studies\nof local properties of the eigenvalue distribution inside and outside of the\nlimiting spectra.\nWe try not to overload these notes with technical details; our main task\nis to make the reader familiar with key points of the reasonings. Therefore\nwe do not present the complete proofs of the improvements of the Wigner\nsemicircle law.\n\nLecture 0\nIntroduction.\nMotivations and\nGeneralities\nRandom Matrices and their Use. Random matrices are in extensive use\nin various fields of theoretical physics (in particular, in models of disordered\nsolid state and chaotic systems, statistical mechanics, quantum field theory).\nThe mathematical contents of random matrices is rich and provides struc\ntures of fairly general type (for example, see the book-length review [22]).\nGraph theory, classical compact groups, orthogonal polynomials, integral\nequations, non-commutative probability theory, combinatorics are enriched\ndue to the studies of random matrix properties. We refer the reader to re\ncent papers and reviews, for example [9, 20, 24, 29], to get acquainted with\nreferences to recent results and various applications of random matrices.\nWhat is important that under \"random matrices\" we mean here matrices\nwhose entries are of the same order of magnitude. One of the examples is\ngiven by random matrices\n(0.1)\nAN (x, y) = a(x, y),\nx, y\n\n= 1, . . . , N\nwith independent identically distributed random variables a(x, y).\nThe family of random matrices is vast and incorporates different ensem\nbles whose probability distribution is chosen according to the model to be\ndescribed.\n\n0. Introduction. Motivations and Generalities\nTo get some examples, one can can consider such representatives of (0.1)\nas the set UN of all unitary matrices UN . The compact group UN supplied\nwith the Haar measure becomes the probability space.\nAnother example of extensively studied family of ensembles is given by\nrandom Hermitian N Ã N matrices MN whose probability distribution PN\nis invariant under unitary transformations of CN . In particular, one can\nconsider PN with the density\n(0.2)\np(MN ) = Z-1 exp{-N Tr V (MN )},\nN\nwhere ZN is the normalization constant and V (t) is a function from a suitable\nclass.\nIn the last two examples the matrices UN and MN have entries that\nare strongly correlated between themselves. Nevertheless, for these classes\nthere exist explicit form of the joint probability distribution of eigenvalues\nof these matrices (see, e.g., [22]). This allows one to get into deep details in\ntheir study.\nOur goals. In present lectures we would like to present the tools that can be\nused when the explicit form of the eigenvalue distribution of matrices (0.1)\nis unknown. For example, this takes place when {a(x, y)} are independent\narbitrarily distributed random variables. This family of random matrices\nwas the first under consideration (see [30]) and the semicircle law was first\nestablished for it in the limit N âinf. It concerns the limiting distribution of\neigenvalues that is given, broadly speaking, by a rather massive (comparing\nwith N ) part of the whole collection of eigenvalues. This asymptotic regime\nis known as the global one.\nMore detailed properties of the spectrum (in other words, those that are\ndetermined by more local regimes than that given by the semicircle law)\nhave not been studied in this case of arbitrarily distributed {a(x, y)}.\nOur aim is to present here several results on the distribution of eigen\nvalues of AN in the limit N âinf. We describe two main techniques to\nprove the semicircle law. They are based on the classical resolvent and\nthe moment approaches of the spectral theory of operators. In the global\nasymptotic regime these two approaches are equivalent.\nHowever, their use in local regimes is no more classical and require es\nsential modifications. We develop necessary modifications and show that\nthese two approach are complementary in the studies of the inner and outer\nparts of the limiting spectra (i.e., the support of the semicircle distribution),\nrespectively.\nOrganization of these Lecture Notes. To give more clear account on\nour ideas, we consider the ensemble of gaussian random matrices as our main\n\n0. Introduction. Motivations and Generalities\nsubject. Namely, we consider the case of real symmetric random matrices\nwith independent entries that have joint Gaussian distribution; the ensemble\nwe are based on is known as the Gaussian Orthogonal Ensemble of random\nmatrices (GOE). Together with its Hermitian analogue abbreviated by GUE,\nthese two ensembles represent the principal subject of random matrix theory.\nThey are the most deeply studied and they are the easiest to verify one or\nanother conjecture about the random matrix properties.\nWe prove the semicircle law by using the moment and the resolvent ap\nproaches in lectures 1 and 2, respectively. Then we turn to improvements of\nthe semicircle law inside of the limiting spectrum and outside of it. Lectures\n3 and 4 are devoted to these considerations.\nWe give a brief account on results that are similar to the semicircle law\nbut are derived for other ensembles of random matrices.\nAlthough our main attention in this addition is devoted to random ma\ntrices with independent entries, we formulate analogues of several statements\nvalid also in the case of Gaussian correlated random variables.\nAcknowledgements. These lecture notes represent amended and enlarged\nversion of the notes prepared for the MSRI Program \"Random Matrix Mod\nels and Their Applications\" (Spring-Summer 1999). The authors are grate\nful to A. Its, P. Bleher, and H. Widom and other organizers for their kind\ninvitation to participate the workshops and for financial support.\n\nLecture 1\nGOE and the\nSemicircle Law\nIn this lecture we prove the semicircle law for random symmetric matrices\nAN whose entries are jointly independent (excepting the symmetry) real\nrandom variables. This statement concerns the eigenvalue distribution of\nthe ensemble {AN } in the limit N âinf.\nWe consider real symmetric matrices in order to simplify computations.\nThe same result is valid for Hermitian random matrices. Also for simplicity,\nwe start with the case when the entries of AN have joint Gaussian distribu\ntion.\nOur aim is to describe two general approaches of the proof in the shortest\nand simplest way that makes the ideas clear. That is why we are related\nin this lecture only with the Gaussian ensemble {AN }. Generalizations of\n{AN } and their properties will be considered further on.\nDefinition of GOE. Thus, we consider an N Ã N matrix with entries\nAN (x, y) = a(x, y),\n1 â¤x â¤y â¤N\nthat is real and symmetric\nAN (x, y) = AN (y, x).\nWe assume that any collection {a(x, y)}1â¤xâ¤yâ¤N is a family of random vari\nables whose joint distribution is the one of Gaussian independent random\nvariables.\n\n1. GOE and the Semicircle Law\nWe also assume a(x, y), x < y to be identically distributed. The same\nconcerns random variables a(x, x). More precisely, we write that\n= y;\n(1.1)\nE a(x, y) = 0,\nE a(x, y)2 =\nv ,\nif x\n2v , if x = y,\nwhere E denotes the mathematical expectation with respect to the measure\ngenerated by the family {a(x, y), x â¤ y}N\nx,y=1. In fact, one can determine\nall random variables a(x, y), x, y â N on the same probability space. In this\ncase E also denotes corresponding mathematical expectation.\nOne can rewrite the last condition of (1.1) in the form\n(1.2)\nE a(x, y)a(s, t) = v 2(Î´xsÎ´yt + Î´xtÎ´ys),\nwhere Î´ is the Kronecker Î´-symbol:\n1, if x = y,\nÎ´xy =\n0, if x = y.\nGiven (1.2), it is convenient to write the distribution of {AN } in a compact\nform:\n\n(1.3)\nP (AN ) =\nexp -\n2 Tr A2\n,\nZN\n4v\nN\nwhere ZN is the normalization constant:\n\nZN =\nexp -\n2 Tr A2\nd a(x, y).\n4v\nN\n1â¤xâ¤yâ¤N\nIndeed, one can easily observe that\n\nP (AN ) = ZN\nexp - 2v a(x, y)2\nexp -\n2 a(x, x)2\n4v\n1â¤x<yâ¤N\n1â¤xâ¤N\n\n=\nexp -\na(x, y)2 +\na(x, y)2\nZN\n4v\n1â¤x<yâ¤N\n1â¤x=yâ¤N\n(a(x, y) = a(y, x))\n\nN\n=\nexp -\na(x, y)2\nZN\n4v2\nx,y=1\n\n=\nexp -\nTr A2\nN\nZN\n4v\nwhich is (1.3).\nDefinition (1.3) shows that the distribution P (AN ) is invariant under\nthe orthogonal transformations of RN . Therefore the ensemble described is\nknown as the Gaussian Orthogonal Ensemble (GOE) of random matrices.\n\n1. GOE and the Semicircle Law\nSee the book [22] for the history and basic results on eigenvalue distribution\nof this and other ensembles of random matrices. The introductory article\n[31] is recommended for those who are interested in combinatorics of matrix\nintegrals.\nEigenvalue distribution function. The eigenvalue distribution of real\nsymmetric (or complex hermitian) N Ã N matrix HN is described by the\nfunction\n(1.4)\nÏ(Î»; HN ) = 1 #\n\nÎ»(\nj\nN ) â¤Î» ,\nN\nwhere\nÎ»(N ) â¤Â· Â· Â· â¤Î»(N )\nN\nare the eigenvalues of HN . This function is called the normalized eigenvalue\ncounting function (NCF) of the matrix HN . It is clearly a step-like function\nincreasing from 0 to 1.\nIn mathematical literature, one can meet also the term empirical eigen\nvalue distribution function. This term seems somewhat misleading (because\nwe consider Ï determined for a matrix AN but not for the sum over N\nsamples). In our notes we keep the term NCF common for the spectral\ntheory.\nGiven a random matrix AN , the corresponding function Ï(Î»; AN ) is\nrandom. The semicircle law first proved by Wigner [30] states that the\nNCF of the matrix\nAN (x, y) = â AN (x, y)\nN\nweakly converges in average as N âinfto a nonrandom distribution:\n(1.5a)\nlim Ï(Î»; AN ) = ÏW(Î»),\nN âinf\nwhose density is given by\nâ\nW(Î») â¡ÏW(Î») =\n4v2 -Î»2 , if |Î»| â¤2v,\n(1.5b)\nÏâ²\n0,\nif |Î»| > 2v.\nWeak convergence in average means here that for any non-random function\nÏ(Î») âCinf(R),\nE lim\nÏ(Î») d Ï(Î»; AN ) =\nÏ(Î») d ÏW(Î»).\nN âinf R\nR\nAs it was mentioned above, we will prove this statement twice by two\ndifferent approaches.\n\n1. GOE and the Semicircle Law\n' Moment relations approach. We describe first the method used by\nWigner in the proof of the semicircle law (see [30] and [7, 26] for the source\nand for improvements of the method, respectively). Here one is interested\nin the asymptotic behavior of the moments\nM(N ) = E\nÎ»j d ÏN (Î»)\nj\nR\nof the measure\nd ÏN (Î») â¡ d Ï(Î»; AN ).\nLet us note that due to the definition (1.4) of the NCF, we simply have that\nMj\n(N ) = E 1 Tr Aj â¡E AN\nj\n,\nN\nN\nwhere we denote the normalized trace of a matrix AN by angle brackets:\nâ¨AN â©â¡\nTr AN .\nN\nBasing on computations that are somewhat different from the original\ntechnique by Wigner, we will derive the relations\n, if j = 2k,\n(1.6a)\nlim Mj\n(N ) = mj =\ntk v2k\nN âinf\n0,\nif j = 2k + 1,\nwhere tk , k âN are given by the recurrence relations\nt0 = 1\n(1.6b)\nk-1\ntk =\ntk-1-j tj .\nj=0\nThen we will show that (1.6) is equivalent to (1.5).\n( Resolvent approach. Another method to study the limiting NCF is\nrelated to the resolvent GN (z) = (AN -z)-1 . It is not hard to see that its\nnormalized trace is simply the Stieltjes transform of ÏN (Î»):\nd ÏN (Î»)\ngN (z) â¡\nTr GN (z) =\n.\nN\nR Î» -z\nIn these terms, convergence (1.5) means that for all z âCÂ± = C \\ R,\n(1.7a)\nlim E gN (z) = fW(z),\nN âinf\nwhere fW(z) is the Stieltjes transform of ÏW(Î»);\nd ÏW(Î»)\n(1.7b)\nfW(z) =\n.\nÎ» -z\nR\n\n1. GOE and the Semicircle Law\nWe will derive shortly that fW(z) satisfies the equation\n(1.8)\nfW(z) = -z - v2fW(z) .\n(1.8) is equivalent to (1.6b). This can be easily derived from the definition\n(1.7b) of fW(z) as Stieltjes transform that implies the relation\ntk v2k\ninf\nfW(z) =\n.\n-z\nzk\nk=0\nThe proposition to consider gN (z), that is the generating function of the mo\nments M(N ), instead of the moments by themselves is due to V.Marchenko\nj\nand L.Pastur who derived (1.8) as a by-product of their more general re\nsults [21]. The resolvent approach in random matrix theory was further\ndeveloped by A.Khorunzhy and L.Pastur (see for example [17] and [18]).\nThe crucial step here is to consider the moments\nP (N ) = E[gN (z)]l,\nl\n\nâ¥ 1\nl\nthat are shown to satisfy an infinite system of relations resembling the system\nof equations for correlation functions of statistical mechanics. The idea\nto write such equations for random matrices dates back to F.Berezin [1].\nBroadly speaking, Berezin showed that the moments P (N ) factorize to the\nl\npowers of fW(z). This fact leads to statements like (1.7).\nRecently it was shown that for convergence (1.7) it is sufficient to con\nsider the two first relations from this infinite hierarchy. This leads to a\nrather short proof of the semicircle law.\nDerivation of the moment relations. We start with the moment ap\nproach to derive relations (1.6b). Gaussian random variables are rather\nconvenient to deal with. One of the reasons is that if one has a centered\nGaussian random variable Î³, then\n(1.9)\nE Î³Ï(Î³) = E Î³2 E Ïâ²(Î³)\nfor all non-random functions Ï such that the integrals in (1.9) exist. In the\nmore general case of a vector Î³ = (Î³1, . . . , Î³m) of Gaussian random variables\nwith zero average one has\nm\n\nâÏ(Î³)\n(1.10)\nE Î³j Ï(Î³) =\nE Î³j Î³l E\n.\nâÎ³l\nl=1\nAs the simplest application, one can easily derive from (1.9) that\nk\nE Î³2k = E Î³ Ã Î³2k-1 = v2 (2k - 1)!!,\nwhere v2 = E Î³2 .\n\n1. GOE and the Semicircle Law\nLet us now consider the moments\nN\nM(N ) = N-1\nE A2k-1\n(1.11)\n(x, y)AN (y, x).\n2k\nN\nx,y=1\nUsing (1.10), we can write that\nEA2k-1(x, y)AN (y, x)\nN\nN\n\nâA2k-1(x, y)\nN\n(1.12)\n=\nE AN (y, x)AN (s, t) E âAN (s, t)\n.\ns,t=1\nIt is obvious that\nN\nâA2k-1(x, y) =\n2k-2\nA2k-2-l(x, s)AN\nl (t, y).\nN\nâAN (s, t)\nl=0\nUsing (1.2) and substituting these relations into the right-hand side of (1.12),\nwe obtain that\nE A2k-1(x, y)AN (y, x)\nN\n2 2k-2\n\nv\nN (y, y) + A2k-2-l(x, y)Al\n=\nE A2k-2-l(x, x)Al\nN (x, y) .\nN\nN\nN\nl=0\nRegarding the sum over y in (1.11) and taking into account the symmetry\ncondition AN (x, y) = AN (y, x), we can write that\nN 2k-2\nA2k-2-l(x, y)Al\nN (x, y) = (2k -1)A2k-2(x, x).\nN\nN\ny=1 l=0\nThus, we derive relation\n2k-2\nM(N )\nEâ¨A2k-2-l\nN â©+ v 2 2k -1 M(N )\n2k = v\nN\nâ©â¨Al\nN\n2k-2.\nl=0\nOne can rewrite this equality in the form\n2k-2\nM(N )\nM(N )\nM(N ) + v 2B(N ) + v 2 2k -1 M(N )\n(1.13)\n2k = v\n2k-2-l\nl\n2k-2\nN\n2k-2,\nl=0\nwhere\n2k-2\n\n(1.14)\nB(N ) =\nEâ¨A2k-2-lâ©â¨Al\nN\nN â© .\nN â©-Eâ¨A2k-2-lâ©Eâ¨Al\n2k-2\nN\nl=0\nNow, if one assumes that\nB(N ) = o(M(N )\n(1.15)\n2k-2) as N âinf,\n2k-2\n\n1. GOE and the Semicircle Law\nand accept that\nM(N )\n(1.16)\n= 0,\n2k+1\nthen one can easily derive (1.6) from (1.13).\n(1.16) follows immediately from the observation that for any particular\nvalues of the variables {yi}\nE a(x, y1) Â· Â· Â· a(y2k , x) = 0\nas the average of the product of an odd number of gaussian random variables.\nRelation (1.15) reflects the property of selfaverageness of the moments\nM(N ) . In Lecture 4 we will show that the much more powerful estimate\nj\nB(N )\n(2k + 2)2Î±\nM(N )\n(1.17)\n2k-2 â¤\nN2\n2k-2,\nÎ±\n\n>\n\nholds for all k âª N2/3 as N âinf. This will lead to estimates of the norm\nof AN and other important consequences.\n\nLecture 2\nProof of the Semicircle\nLaw\nNow let us turn to the proof of (1.7) for GOE. We follow the scheme devel\noped in [17, 18] and modified in [11].\nWe will use twice the resolvent identity\n(2.1)\nG - Gâ² = -G(H - Hâ²)Gâ² ,\nG = (H - z)-1,\nGâ² = (Hâ² - z)-1 ,\nthat is true for hermitian matrices H and Hâ² of the same dimension and\nz â CÂ±.\nRegarding (2.1) with H = AN and Hâ² = 0, we obtain the relation\nN\nGN (x, x â²) = Î¶Î´x,xâ² - Î¶\nGN (x, y)AN (y, x â²),\ny=1\nwhere GN = (AN - z)-1 , Î¶ â¡ (-z)-1 and Î´x,y is the Kronecker Î´-symbol.\nWe are interested in the average value of the normalized trace gN (z) =\nN-1 Tr GN . It is clear that\n(2.2)\nE gN (z) = Î¶ - Î¶\nE GN (x, y)AN (y, x).\nN x,y\nNow we can apply (1.10) to the last average from (2.2) and obtain the\nrelation\nN\n\nâGN (x, y)\nE GN (x, y)AN (y, x) =\nE AN (y, x)AN (s, t) E âAN (s, t) .\ns,t=1\n\nâ²\nâ²\n\n2. Proof of the Semicircle Law\nOne can easily deduce from (2.1) that\nâGN (x, y)\n(2.3)\n= -GN (x, s)GN (t, y).\nâAN (s, t)\nIndeed, it is sufficient to consider (2.1) with Hâ² = AN and\nH(x , y â²) = AN (x , y â²) + âÎ´xâ²,sÎ´yâ²,t\nand to find the ratio (G -Gâ²)/â in the limit â â0.\nRemembering definition (1.2) and using (2.3), we obtain that\nv\n\n(2.4)\nE gN (z) = Î¶ + Î¶ N2\nE GN (x, x)GN (y, y) + GN (x, y)GN (x, y) .\nx,y\nOne can rewrite this relation in the form\nv E Î¦(1)\n(2.5)\nE gN (z) = Î¶ + Î¶v2 E[gN (z)]2 +\n(z),\nN\nN\nN (z)â©â¡ N-1 Tr G2\nwhere Î¦(1)(z) = â¨G2\nN (z). We see that the first moment\nN\nof gN (z) is expressed via the second moment of this variable added by the\nterms vanishing in the limit N âinf.\nIndeed, elementary estimates\n\n(2.6)\nâ¨G2\nN (z) â¤â¥GN (z)â¥2 â¤\nN (z)â©â¤G2\n|Im z|2\nÎ¦(1)\n\nshow that N (z) = O(1) as N âinf.\nHaving (2.5), we can proceed by two ways.\nThe first approach inspired by the work of Berezin [1] is to derive an\ninfinite system of recurrence relations for the moments L(N ) = E[gN (z)]k ,\nk\nk â¥ 2. This method has been developed in [17, 18] and extensively used\nfor various ensembles of random matrices and random operators (see, for\nexample [14, 15]).\nThe second approach proposed in [11] represents a shortened version of\nthe method of infinite system of relations. Loosely speaking, it uses only\nthe two first relations and lead to a fairly short proof of the semicircle law.\nThis shortened version has been widely applied in the studies of random\nmatrix eigenvalue distribution [5, 16, 19, 25]. This approach seems to be\nunavoidable in the studies of smoothed eigenvalue density and its fluctua\ntions [2]. However, certain passages can appear as somewhat tricky things\nin this shortened version. Thus, we start with the discussion of the infinite\nsystem method.\n\n2. Proof of the Semicircle Law\nInfinite System Approach [17, 18]. One can derive a system of relations\nfor the moments L(N) = E[gN (z)]k subsequently applying to the last factor\nk\nin Lk relations (2.2), (1.10), and (2.3). Then one obtains for k â¥2\nv\nÎ¦(k)\nE[gN (z)]k = Î¶ E[gN (z)]k-1 + Î¶v2 E[gN (z)]k+1 + v E Î¦(k)(z) + N E N (z),\nN\nN\nwhere\n(z) = [gN (z)]k-1â¨G2\nÎ¦(k)\nN (z)â©,\nN\n\n(z) = k [gN (z)]k-2â¨G3\nÎ¦(k)\nN (z)â©.\nN\nN\nThus for the moments Lk we have the relations\nL(N)\n(2.7)\n= Î¶Î´k,1 + (1 -Î´k,1)Î¶L(N) + Î¶v2L(N) + Î¨(k)(z),\nk\nk-1\nk+1\nN\nwhere, according to estimates (2.6),\n\nÎ¨(k)\n\nv\nk\n(2.8)\n(z) â¤\n1 +\n.\nN\nÎ·kN\nN\nIt is not hard to see that (2.7) can be rewritten in a vector form\nL(N) = l + TzL(N) +\n(2.9)\n\nÎ¨(N),\nwhere lk = Î´k,1Î¶ and\n[Tze]k = (1 -Î´k,1)Î¶ek-1 + v 2Î¶ek+1.\nNow it is not hard to show that\nv\nâ¥Tzâ¥â¤Î· +\n.\nÎ·\nTherefore for Î· > 2v one has â¥TZ â¥< 1. Introducing the equation\n(2.10)\nLâ² = l + TzLâ²\nthat obviously has one solution, one can easily deduce from (2.9) and (2.10)\nthat\n\nL(N) -\n\nLâ² = O(N-1).\nThis proves convergence (1.7).\nShort Proof of the Semicircle Law [10].\nProof. Denoting E gN (z) â¡fN (z) and regarding that\ny GN (x, y)GN (x, y) =\nG2\nN (x, y), we derive our first main relation\n(2.11)\nfN (z) = Î¶ + Î¶v2f2\nN (z) + Î¦N (z) + Î¨N (z),\nwhere\nv\nÎ¦N (z) =\nEâ¨G2\nN (z)â©\nN\n\n2. Proof of the Semicircle Law\nand\nÎ¨N (z) = E gN (z)gN (z) -E gN (z) E gN (z).\nWe see that (2.11) has a form close to (1.8) and all that we need is to show\nthat Î¦N (z) and Î¨N (z) vanish as N âinf.\nThe first condition is fulfilled for z âCÂ± because\n\n(2.12)\nâ¨G2\nN (z) â¤â¥GN (z)â¥2 â¤\n|Im z|2 .\nN (z)â©â¤G2\nThus,\nv\n(2.13)\n|Î¦N (z)| â¤ NÎ·2 ,\nwhere we have denoted Î· := |Im z|.\nThe second condition reflects the selfaveraging property of gN (z). We\nare going to prove below that\n4v\n(2.14)\nE |gN -E gN (z)|2 â¤ Î·4N2\nprovided Î· â¥4v2 . Then (1.7) will be proved.\nLet us introduce the centered random variable\ng *(z) = g(z) -E g(z)\n(we omit subscript N when no confusion can arise). It is easy to see that\nE g *(z1)g *(z2) = E g *(z1)g(z2).\nSlight modification of (2.2) reads as\nz) g(z) = -Î¶\nE g *(Ë\nE g *(Ë\nz) G(x, y)AN (x, y).\nN x,y\nThe first term of the right-hand side vanishes because E g* = 0.\nUsing once more (1.10), one can write that\nN\nE g *(Ëz) G(x, y)AN (x, y) =\nE AN (y, x)AN (s, t)\ns,t=1\nâGN (x, y)\nâg*(Ëz)\n\nÃ E g *(Ëz)\n+ E GN (x, y) âAN (s, t) .\nâAN (s, t)\nThe first derivative in the curly brackets is already computed. The second\ngives\nz)\n=\nâg(Ë\nG2(t, s),\nâg*(Ë\nz)\n= - 1\nN\nG(u, s)G(t, u) = - 1 Ë\nâAN (s, t)\nâAN (s, t)\nN\nN\nu=1\nwhere Ë\nz).\nG â¡GN (Ë\n\n2. Proof of the Semicircle Law\nAfter some simple manipulations, we derive our second main relation\nz)g(z) = Î¶v2 E g *(Ë\n(2.15)\nE g *(Ë\nz)g(z)g(z)\n\nv\nz)\n\nG2\n2v\nË\n+ Î¶\nE g *(Ë\n+ Î¶ N2 E G2G .\nN\nAll that we need now is the identity\nE g *(Ë\nz)g(z) E g(z) + E g *(Ë\nz)g(z)g(z) = E g *(Ë\nz)g *(z)g(z)\nand the fact that g( z) = g(z).\nRegarding (2.15) with Ë\nz, we derive that\nz =\nE |g *(z)|2 â¡E g *(Ë\nz)g(z)\nz)g(z) |E g(z)| + |Î¶| v 2 E g *(Ë\nâ¤|Î¶| v 2 E g *(Ë\nz)g *(z) |g(z)|\n\nz)|\n\n2 |Î¶| v E G2G\nG2\nË\n(2.16)\n+ |Î¶| v2\nE |g *(Ë\n+\n.\nN\nN2\nUsing estimates similar to (2.12), we obtain that\n2v\n(2.17)\nE |g *(z)|2 â¤2v 2Î·-1 E |g *(z)|2 + v2\nE |g *(z)|2 1/2\n+\n.\nNÎ·3\nN2Î·4\nThis implies (2.14). The semicircle law (1.7) is proved for GOE.\n\nLet us make several important remarks here.\nRemark. The first observation is that the estimate (2.6) indicates fairly\nfast decreasing of the variance of the random variable\nN\n(2.9)\ngN (z) =\nGN (x, x; z)\nN x=1\nas N âinf. It follows from (2.6) and the Borel-Cantelli lemma that gN (z)\nconverges to a non-random limit (actually, fW(z)) with probability 1. Let\nus stress that in the classical probability theory the variance of the sum of\nindependent random variables SN = (Î¾1 + Â· Â· Â· + Î¾N )N-1 that is analogous\nto (2.17) is of the order N-1 . The difference is that in (2.17) we have a\nsum of dependent random variables GN (x, x; z). Let us note that (2.13) is\na consequence of the more powerful statement that the centered random\nvariable\nÎ³N (z) = Tr GN (z) -E Tr GN (z)\nconverges in distribution to a gaussian random variable as N âinf. We\ndiscuss this property in more details in Lecture 4.\nRemark. The next remark is related to the observation that estimates\n(2.13) and (2.14) show that in (2.11) terms Î¦N (z) and Î¨N (z) vanish not\nonly for Î· > Î·0 but also for z with imaginary part vanishing at the same time\n\n2. Proof of the Semicircle Law\nas N increases. This implies serious consequences concerning the smoothed\neigenvalue density of large random matrices. In particular, one can trace out\nthe proof of a version of the famous universality conjecture for local prop\nerties of random matrix spectra. We address this topics also in Lecture 4.\nNow let us discuss generalization of the semicircle law to the case of\nrandom matrices with arbitrary distributed random entries a(x, y).\nThe first ensemble generalizing GOE is the Wigner ensemble of random\nreal symmetric matrices\nWN (x, y) = â w(x, y),\nx, y\n\n= 1, . . . , N\nN\nwhose entries are jointly independent random variables satisfying conditions\n(1.1). We do not assume the probability distribution functions\nP(x,y)(Î¾) = Prob{w(x, y) â¤Î¾}\nare the same and have a special form. In fact, one can consider here\nthe more general case when the distributions P (N ) can be dependent on\n(x,y)\nN. In this case it should be pointed out that the set of random variables\n{wN (x, y)}1â¤xâ¤yâ¤N is determined on the same probability space.\nTo complete preparations, let us introduce notations for the moments of\nwN (x, y)\ninf\nV (N )(x, y) =\nÎ¾j d PN (x, y).\nj\n-inf\nTheorem 2.1. Let us consider the ensemble\n(2.18)\nHN = hN + WN ,\nwhere hN is a sequence of non-random matrices such that there exists the\nlimit\nÎ¼(Î») = lim Ï(Î»; hN ).\nN âinf\nLet P (N )\n(x,y) satisfy the Lindeberg condition\nN\nÎ¾2 d P (N )\n(2.19)\nlim\nâ\n(x,y)(Î¾) = 0 âÏ > 0.\nN âinf N2\nx,y=1 Ï\nN\nThen the Stieltjes transform\ninf\n(1)\nd Ï(Î»; HN )\ng\n(z) =\nN\nÎ» -z\n-inf\nconverges in probability as N âinfto a nonrandom function fh(z) that\nsatisfies the equation\ninf\nd Î¼(Î»)\n(2.20)\nfh(z) =\nÎ» -z -v2fh(z) .\n-inf\n\n2. Proof of the Semicircle Law\nThis statement is somewhat more general than the theorem proved by\nPastur [23]. He considered HN with a diagonal non-random part hN and\nthe conditions imposed on PN were a bit restrictive than (2.18) but also\nclose to the Lindeberg conditions.\nAnother generalization of GOE is given by the real symmetric matrices\nÎN\n(2.21)\nÎN (x, y) = â Î³(x, y),\nN\nwhere random variables Î³(x, y), x â¤y have joint Gaussian distribution with\nzero average and covariance\nE Î³(x, y)Î³(s, t) = V (x, s)V (y, t) + V (x, t)V (y, s),\nwhere V is a symmetric and non-negatively defined matrix.\nTheorem 2.2. [3] Let the matrices\nV (x, y), if x â¤N and y â¤N,\nVN (x, y) = 0,\notherwise\nbe bounded\n(2.22)\nâ¥VN â¥â¤v\nand satisfy condition\nlim Ï(Î»; VN ) = Î½(Î»).\nN âinf\nThen the Stieltjes transform inf\n(2)\ng\n=\nd Ï(Î»; ÎN )Î» -z\nN\n-inf\nconverges with probability 1 to a nonrandom function f2(z) given by\nv\nd Î½(Î»)\nf2(z) =\n-z -Î»Ï(z)\nand Ï(z) satisfies the equation\nv\nÎ» d Î½(Î»)\n(2.23)\nÏ(z) =\n-z -Î»Ï(z) .\n\nLecture 3\nSmoothed Eigenvalue\nDensity\nIn the spectral theory of random matrices, the universality conjecture can\nbe regarded as the most challenging problem. It concerns the local spectral\ncharacteristics of large random matrices.\nIn paper [11] we developed an approach to study the asymptotic regime\nthat can be called semi-local, or mesoscopic. The subject under considera\ntion is the eigenvalue distribution function smoothed over the intervals âN\nof the length 1 âª|âN | âªN, N âinf. In papers [2, 4] we proved limiting\ntheorems that reflect the universality property of the smoothed eigenvalue\ndensity of large random matrices.\nIn this lecture we present theorems of papers [11] and [2] and describe\nbriefly the scheme of their proofs.\nIt is not hard to see that the Stieltjes transform fN (z) with Im z = Îµ > 0\neffects the control of the eigenvalues that are situated in the vicinity of the\ninterval (Î» -Îµ, Î» + Îµ). It becomes clear if one consider Im fN (Î» + i Îµ) as a\nsmoothing of the measure d ÏN (Î»):\nÎµ\nIm fN (Î» + i Îµ) =\n(Î» -Î¼)2 + Îµ2 d ÏN (Î¼) â¡\nÏÎµ,Î»(Î¼) d ÏN (Î¼).\nIn these terms, the limiting transition N âinf for random variable\nfN (Î» + i Îµ) with given positive Îµ can be regarded as the global spectral\ncharacteristics, i.e. as the variable related with O(N) eigenvalues of AN .\n\n3. Smoothed Eigenvalue Density\nIndeed, the variable\nÏ(Î» + Îµ; AN ) - Ï(Î» - Îµ; AN ),\n|Î»| < 2v\nis also global because it involves O(N) eigenvalues of AN .\nIf one is interested in more detailed description of the limiting eigenvalue\ndistribution of AN , it is natural to study the limit of fN (Î» + i ÎµN ), where\nÎµN â 0 at the same time as N infinitely increases. We call the variable\nÎ¾N (Î») := Im fN (Î» + i ÎµN )\nthe smoothed or regularized eigenvalue density.\nIn these studies, one can separate two regimes that are fairly different.\nThe asymptotic regime that correspond to the case of ÎµN = O(N-1) is\nknown as the local one. The regime intermediate between the global and\nlocal ones can be described as ÎµN = N-Î± with 0 < Î± < 1. According to the\ntheoretical physics terminology, it can be called the mesoscopic regime.\nIn this lecture we are going to discuss the proof and several consequences\nof the following statements.\nTheorem 3.1 ([11]). Consider the GOE AN and the resolvent GN (z) =\n(AN - z)-1 . Then convergence in average\nâ\n4v2 - Î»\n(3.1)\nlim E\nTr GN (Î» + i N-Î±) = - Î»\n2 + i\nN âinf\nN\n2v\n2v\nholds provided 0 < Î± < 1 and |Î»| < 2v.\nLet us look once more at the scheme presented in Lecture 2. It is clear\nthat it does not work directly because one does not have any more estimates\nof the type (2.5). Then the relation (2.8) cannot be reduced to inequality\n(2.9) that gives the estimate of the variance E |g*|2 by itself multiplied by\nE |g| is out of use. As a consequence, one cannot derive (2.7) from (2.9).\nTherefore the proof of Theorem 3.1 requires essential modifications of the\napproach.\nTo do this, we have to pass back from the short scheme described in\nLecture 2 to the infinite system of relations inspired by the idea of Berezin.\nLet us explain now how it has to be modified.\nThe estimate (2.6) and its consequence (2.8) allows one to consider only\nfirst k â¤ k0 relations from the infinite system (2.7). The matter is that the\ninfinite system of relations (2.7) and its finite counterpart are related via the\nterm Lk0 . If one consider a new system of k0 relations of the form (2.7) but\nwith the term Lk0+1 removed in the relation number k0, this will change a\nlittle the first components of the solution of this equation with respect to\n\n3. Smoothed Eigenvalue Density\n-k\nthe first several moments L(N) . This is due to a priori estimate |Lk| â¤Î·\n.\nk\nThe truncated system of k0 relations is closed and can be solved uniquely.\nThis procedure is in fact equivalent to that one described in Lecture 2 in\nthe long scheme.\nScheme of the proof of Theorem 3.1. The first principal modification\nof the scheme of Lecture 2 is that we consider the part of (2.7) with k â¥\nk0 > 1 and rewrite it in the form\n(3.2)\nv 2L(N) = Lk-1 -zLk -Î¨(k) .\nk+1\nN\nTo simplify the description of the proof, let us assume that Re z = 0. Then\nunder conditions of Theorem 3.1 relation (3.2) will have the form\n(3.3)\nL(N) = 1 Lk-1 -\ni\nLk -Î¨(k) .\nk+1\nv2NÎ±\nN\nv\nSince Im z = N-Î±, we cannot use the absolute estimates as it is done in\nLecture 2 (see estimate (2.8)). One should use the estimates with respect\nto Lk.\n(N)\nLoosely speaking, the term Î¨(k) can be estimated by N-Î³L\nwith some\nN\nk\nÎ³ > 0 (to make possible this estimate, we will need our second principal\nmodification).\n-Î³\nUsing the fact that Lk enters into relation (3.3) with factor N\n, one\ncan reduce it by subsequent substitutions to the form\n\ni\nl\nÎ¨(k)\n(3.4)\nL(N) = 1\n2 Lk-1 +\nk\nLk-l+1 + Ë N (z).\nk+1\nv\nv2NÎ³\nl=1\nInequality (2.6) shows that L1 â¤ NÎ±, but it enters (3.4) with the factor\nN-kÎ³ . This allows us to neglect the terms that increase provided k > k0,\nwhere k0 is sufficiently large.\nk\nThe term Î¨(k) involves the factors E gN (N) and cannot be directly esti-\nN\nmated in terms of L(N) . To do this, we pass from complex variables gN (z) to\nk\nthe real variables Î¾ = Î»gN (Î» + i N-Î±) â¥0 and Î¼ = Re gN (Î» + i N-Î±). This\nis the second modification of the general scheme. It seems to be a trivial\none, but this is not completely right.\nThe matter is that consideration of the moments E gk leads to the ne-\nN\ncessity of consideration of the family of moments E Î¾pÎ¼q. Those with large\nnumber of q are difficult to estimate. Fortunately, we will need the family\n\n3. Smoothed Eigenvalue Density\nof three types of moments\nW (N ) = E Î¾k\nk\nN ,\nV (N ) = E Î¼N Î¾k\nk\nN ,\nU(N )\n= E Î¼N Î¾k\nk\nN .\nThis family is closed and satisfies our conditions.\nProof of Theorem 3.1. Let us introduce the matrices\nBÎ» = NÎ±(AN - Î»I),\nB\n\n= NÎ±AN ,\nand\nBÎ»\nP = 1 + B2 ,\nQÎ» = 1 + B2 .\nÎ»\nÎ»\nThen\nÎ±\nÎ¾N (Î») = PÎ»\nÎ± ,\nÎ¼\n\n= QÎ» ,\nwhere for we denoted for N-dimensional matrix HN\nÎ±\nHN = NÎ±-1 Tr HN .\nIt is not hard to derive that\nâP(x, y) = -P(x, s)Q(t, y) - P(x, t)Q(s, y) - Q(x, s)P(t, y) - Q(x, t)P(s, y)\nâB(s, t)\nand\nâQ(x, y) = P(x, s)P(t, y) + P(x, t)P(s, y) - Q(x, s)Q(t, y) - Q(x, t)Q(s, y)\nâB(s, t)\nThese relations represent (2.3) rewritten for real and imaginary parts sepa\nrately.\nUsing these relations and the formula (1.10) and regarding the identity\nPÎ» = I - PÎ»B2\nÎ»\n= I + Î»N Î±QÎ» - QÎ»B,\none can derive the system of relations\n(3.5a)\nWk+1 = 1\nv2 Wk-1 + 1\nv2 Vk-1 + Uk-1 + Î(N )\n1 (k),\n(3.5b)\nVk+1 = - Î»\n2v2 Wk+1 +\n2v2NÎ± Vk + Î(N )\n2 (k),\nand\n(3.5c)\nUk+1 = - Î»\n2v2 Vk+1 +\n2v2NÎ± Uk + Î(N )\n3 (k),\n\n3. Smoothed Eigenvalue Density\nwhere\n(3.5)\nÎ(N )(k) = N\nv\n1-Î± E Î¾k-1(P 2Î± + Q2 Î±)4v2(k -1) E Î¾k-2PÎ»Q2 Î± ,\nÎ»\nÎ»\nN2-2Î±\nÎ»\n(3.6)\nÎ(N )(k) = - N\nv\n-Î± E Î¾k PÎ»QÎ»\nÎ± - 4v2k\nN2-2Î± E Î¾k-1PÎ»\n2QÎ»\nÎ± ,\nÎ±\n(3.7)\nÎ(N )(k) = - 2v\nE Î¼Î¾kPÎ»QÎ»\nÎ± - N\nv\n-Î± E Î¾k (P 3Î± -PÎ»\n2QÎ» ).\nN1-Î±\nÎ»\nIt is easy to see that\nÎ(N )\n\n8(k -1)\n1 (k) â¤ N2-2Î± Wk-1 +\nWk ,\nN1-Î± Wk + NÎ±\nand Î(N )(k) and Î(N )(k) can be estimated similarly. This estimate looks\nappropriate excepting the fact that we have in the right-hand side the term\nWk-1. To ensure that Wk-1 can be estimated via Wk , we prove the following\nsimple statement.\nLemma 3.2. Under conditions of Theorem 3.1\n1 4v2 -Î»2\nE Î¾2 â¥\nâ¡ ÏÏ(Î»)\n4v4\nfor large enough N.\nProof. Let consider (3.5a) with k = 1;\nE Î¾2 = v -2 + Î»v-2 E Î¼ + E Î¼ 2 + Î(N )(1),\nwhere\nÎ(N )(1) â¤3N-Ï E Î¾ with Ï = min{Î±; 1 -Î±}\n\n.\n\nSince |E Î¼| â¤ E Î¼2, then we can write that\nE Î¾2 â¥\n\nE Î¼2 - Î»\n2v2\n+ 4v2 -Î»2\n4v4\n-\nÎ(N )\n1 (1)\n\nâ¥(ÏÏ)2 -3N-Ï\nE Î¾2 .\n\nAn important consequence of Lemma 3.1 is that\nwk := (Wk)1/k â¥ ÏÏ and Wk â¤Wk+m\nm\n.\nÏÏ\nNow we can derive from (3.5b) the relation\nÎ»\nÎ(N )\nVk = -\n2 Wk-1 + 2 (k),\n2v\n\n3. Smoothed Eigenvalue Density\nwhere\nÎ(N )\n2 (k)\nâ¤\n\n1 + Î» k-1\n\np\nWk-1-p +\nU0\n2v2\n2v2NÎ±\n(2v2NÎ±)k-1\np=1\nNÎ±\n.\nâ¤ ÏÏv2NÎ±(1 -[ÏÏv2NÎ±]-1) Wk-1 + (2v2NÎ±)k-1\nThus,\nÎ»\nVk = -\nWk-1(1 + o(1)).\n2v2\nSimilar computations lead to the relation\nÎ»\nUk = -\n2 Vk-1(1 + o(1)).\n2v\nSubstituting these two last equalities into (3.5a) and treating it in the same\nway, one can obtain easily that\nÎ(N )\nWk+1 = (ÏÏ)2Wk-1 + 4N-ÏWk +\n(k).\nThen, an elementary procedure leads to the proof of convergences\nE Î¾ âÏÏ,\nÎ»\nE Î¼ â-2v2 ,\nÎ»2\nE Î¼ 2 â 4v4 .\nTheorem 3.1 is proved.\n\nIn this statement, the most important is the convergence of the smoothed\ndensity of eigenvalues\n(3.6)\nE Î¾N (Î») â¡E Im gN (Î» + i N-Î±) âÏÏ(Î»),\nN âinf.\nThis relation plays a crucial role in the proof of the selfaveraging (or strong\nselfaveraging) property of the random variable Î¾N (Î») and in the proof of the\nuniversal behaviour of the correlation function E Î¾N (Î»1)Î¾N (Î»2) as well. Let\nus formulate the corresponding results.\nTheorem 3.3. Under hypotheses of Theorem 3.1,\n(3.7)\nE g *(Î» + i N-Î±)\n2 = O(N2-2Î±).\nProof. To explain the proof of this statement, let us consider relation (2.15)\nand assume once more that Î» = 0. Using identity\n**\nE g * gg = 2 E g * g E g + E g * g g ,\n\nGeneralizations of Theorems 3.1-3.3 and universality conjecture\nwe can rewrite (2.15) in the form\n\n*\n*\n2v 2 E g g E g â¤\nE g * g + N1-Î± E |g | + O\n.\nNÎ±\nN2-2Î±\nIf we have (3.6), it is not hard to derive from this inequality the estimate\n(3.7).\n\nFinally, let us formulate the theorem about the fluctuations of the smoo\nthed eigenvalue density of GOE. This is an analog of the central limit theo\nrem.\nTheorem 3.4. [2] Under hypotheses of Theorem 3.1, the random variable\nÎ³N (Î») = N1-Î±[Î¾N (Î») -E Î¾N (Î»)]\nconverges in distribution as N âinfto a centered Gaussian random variable\nwith variance 1/4. If one consider two points Î»1 = Î»2 such that Î»1, Î»2 â\nÎ» â(-2v, 2v), then\nN (Î»1)Î¾o\n(3.8)\nE Î¾o\nN (Î»2) = - N2(Î»1 -Î»2)2 (1 + o(1))\nin the limit N âinfprovided\n(3.9)\nNÎ± âª|Î»1 -Î»2| âª1.\nGeneralizations of Theorems 3.1-3.3 and\nuniversality conjecture\nWigner random matrices. It should be noted that Theorems 3.1-3.3 con\nsidered for 0 < Î± < Î±0 are valid for the Wigner ensemble of random matrices\n(2.8) with jointly independent arbitrary distributed random variables w(x, y)\nhaving several first moments finite\nE[wN (x, y)]2k = Vk < inf.\nIn particular, Theorem 3.3 holds for k = 4 and Î±0 = 1/8 (see [2]-II). These\nresults show that the universality conjecture holds for large random matri\nces with independent entries. They are far from being optimal, and it is\ninteresting to check out the optimal bound for Î±0 and its dependence on Vk .\nWishart-type random matrices. Let us consider the ensemble of random\nmatrices\nm\n(3.10)\nHm,N (x, y) =\nÎ¸Î¼(x)Î¸Î¼(y),\nx, y\n\n= 1, . . . , N,\nN Î¼=1\n\n3. Smoothed Eigenvalue Density\nwhere the random variables {Î¸Î¼(x)}, x, Î¼ âN have joint Gaussian distribu\ntion with zero mathematical expectation and covariance\nE{Î¸Î¼(x)Î¸Î½ (y)} = u 2Î´xy Î´Î¼Î½ .\nHere Î´xy denotes the Kronecker delta-symbol.\nThis ensemble introduced in mathematical statistics is known for m = N\nas the Wishart ensemble.\nThe eigenvalue distribution of (3.10) in the limit N, m âinf was con\nsidered first [21], where more general random matrix ensembles were also\nconsidered.\nRandom matrices of the form (3.10) are at present of extensive use in the\nstatistical mechanics of disordered spin systems and in the models of memory\nin the theory of neural networks. The difference between the Wigner random\nmatrices (2.8) and (3.10) is that in the second case the entries Hm,N (x, y)\nare statistically dependent random variables.\nTheorem 3.5. Let Gm,N (z) = (Hm,N -z)-1 . Then, for N, m âinf,\nm/N âc > 0, the random variable\nR(Î±)\nm,N (Î») := Im Tr Gm,N (Î» + i N-Î±)N-1\nconverges with probability 1 as N âinfto the nonrandom limit\n(3.11)\nÏÏc(Î») =\n4cu4 -[Î» -(1 + cu2)]2\n2Î»u2\n\nâ\nâ\n\nprovided 0 < Î± < 1 and Î» âÎc,u = u2(1 -\nc)2, u2(1 +\nc)2 .\nRemark. The limiting expression (3.11) for the eigenvalue distribution was\nderived in the global regime in [21].\nTheorem 3.6. Consider k random variables, i = 1, . . . , k,\n,\nÎ³(Î±)\nm,N (Î»i) -E R(Î±)\nm,N (i) â¡N1-Î± R(Î±)\nm,N (Î»i)\nwhere Î»i = Î» + ÏiN-Î± with given Ïi. Then under hypotheses of Theorem\n3.5 the joint distribution of the vector (Î³N (1), . . . , Î³N (k)) converges to the\ncentered Gaussian k-dimensional distribution with covariance\n4 -(Ïi -Ïj )2\n(3.12)\nC(Ïi, Ïj ) = [4 + (Ïi -Ïj )2] .\nRemark. It is easy to see that if |Ï1 -Ï2| âinf, then\n(3.13)\nC(Ï1, Ï2) = -(Ï1 -Ï2)-2(1 + o(1)).\nThis coincides with the average value of the Dyson's 2-point correlation\nfunction for real symmetric matrices considered at large distances |t1 -t2| â«\n1.\n\nGeneralizations of Theorems 3.1-3.3 and universality conjecture\nLet us note that the limiting distribution of the random variables Î³N and\nÎ³m,N coincide and do not depend on particular values of Î» and Î±. This shows\nthat the fluctuations of the smoothed eigenvalue density Î¾ are universal in\nthe mesoscopic regime. Thus, our results can be regarded as a support of the\nuniversality conjecture for local spectral statistics of large random matrices.\n\nLecture 4\nEigenvalues outside of\nthe limiting spectrum\nOur main goal in this section is to describe the proof of estimate (1.17) and\ndiscuss its consequence with respect to the norm of random matrices.\nMoments and extreme eigenvalues. First of all, let us note that having\nproved (1.17) for all k â¤ NÎ² with Î² > 0, we easily derive from (1.13) that\ninequality\nk-1\nM(N )\nM(N )\nM(N ) â¤ (1 + Îµ)2 v\n2k-2-2j\n2j\n2k\nj=0\nwith positive Îµ also holds for all k â¤ NÎ² and N > N0(Îµ).\nâ\nRegarding the numbers m â â¡ m2k(Îµ) determined by the following re\n2k\ncurrence relations\nk-1\nâ\nâ\nâ\nâ\nm2k = (1 + Îµ)2 v\nm2k-2-2j m2j ,\nm\n= 1,\nj=0\nwe then derive that inequality\nM(N )\nâ\nâ¤ m2k\n2k\nÎ²\nholds for k â¤ N .\nNow let us follow the reasoning that is usual in the norm estimates for\nrandom matrices (see, for example [7, 8]). Taking into account that the\nâ\nfamily m2k (Îµ), k â N represents the moments of the semicircle distribution\n(1.5) with v2 replaced by [(1 + Îµ)v]2, we obtain the estimate\nâ\n2k\nm2k (Îµ) â¤ [(1 + Îµ)v]\n.\n\n4. Eigenvalues outside of the limiting spectrum\nThus, we have that\nM(N )\n2k\n(4.1)\nâ¤[(1 + Îµ)v]\nâk â¤NÎ² .\n2k\nThis implies the estimate with probability 1\n(4.2)\nlim sup â¥AN â¥â¤2v(1 + 2Îµ),\nN âinf\nwhere the spectral norm â¥AN â¥is defined as the largest absolute value of an\neigenvalue of AN .\nInequality (4.2) can be derived from (4.1) using elementary computa\ntions. Indeed, if one denotes by nN (s) the number of eigenvalues lying\noutside of the interval (-s, s)\nnN (s) â¡#{j | Î»(N ) â¥s},\nj\nthen one can write the sequence of inequalities\n2k\nM(N ) â¥E\nâ¥s 2k E nN (s) â¥ s\nProb{â¥AN â¥â¥s}.\n2k\nR\\(-s,s)\nN\nThen for PN (Îµ) â¡Prob{â¥AN â¥â¥2v(1 + 2Îµ)} we have the estimate\nM(N )\n2k\nPN (Îµ) â¤N inf\nk [2v(1 + Îµ)]2k = N exp{-NÎ² log(1 + Îµ/2)}\nthat implies (4.2).\nLet us discuss two aspects of the results presented. Inequality (4.2) is\nvalid for all positive Îµ. This means that (4.2) holds for Îµ = 0 and this implies\nthat the maximal eigenvalue of AN is bounded by 2v in the limit N âinf.\nÂ¿From the other hand, the semicircle law states that with probability 1\nthere exist eigenvalues of AN falling into vicinity of 2v in this limit. Thus,\nthe maximal eigenvalue (and also the minimal one, due to symmetry of the\nprobability distribution of AN (1.3)) converges to 2v (-2v).\nThis fact is also valid for the Wigner ensemble of random matrices WN\n(2.17) with arbitrary distributed entries w(x, y)N-1/2 provided that several\nfirst moments E w(x, y)2p are finite (see for example [7, 13] and [26]).\nThe second remark concerns the maximal power Î²0 in (4.1). This (criti\ncal) exponent reflects the behaviour of the differences âl between the eigen\nvalues from the vicinity of the extremal eigenvalue Î»(N )\nmax. Indeed, one can\nwrite that\nM(N )\nÎ»(N )\nÎ»(N ) 2k\n2k = N [ 1 ]2k + [Î»2\n(N )]2k + . . . [ N ]\n2k\n= [Î»(N ) ]\n1 + [1 + â(N )]2k + . . . N-1 .\nmax\n\n4. Eigenvalues outside of the limiting spectrum\nIf 2k grows faster with N than the difference â(N ) vanishes, then one gets\nan asymptotic behaviour of M(N ) different from (4.1).\n2k\nOur scheme shows that (4.1) is valid for k âª N2/3 when the GOE is\nconsidered. Therefore one can conclude that Î²0 â¥ 2/3. The early studies of\nGOE with the help of the orthogonal polynomials approach [6] show that\nÎ²0 = 2/3. This conclusion is confirmed and improved by Tracy and Widom\nin a series of papers (see for example [28]). The same conclusion follows\nfrom the works by Sinai and Soshnikov [26] and by Soshnikov [27], where\nthe Wigner ensemble is considered (see also [13] for certain generalizations\nof [27]). Equality Î²0 = 2/3 means that the average distance between eigen\nvalues at the border of the is of the order N-2/3 .\nScheme of the proof of (1.17). We follow the technique developed in [3]\nfor random matrices with Gaussian correlated entries. For simplicity, we\nconsider in details only the case of independent random variables.\nWe rewrite definition (1.14) for B2k in the form\nB(2)\n2k (N) =\nEâ¨Ap1 â©*â¨Ap2 â©* ,\nN\nN\np1,p2â¥1\np1+p2=2k\nwhere Î¾* = Î¾ - E Î¾. The general idea is to use recurrent relations for B(2)\n2k\nthat can be derived again with the help of (1.9). These relations are similar\nthose we have got for M(N ) (1.13) and therefore one can expect to obtain\n2k\nestimates of B2k in terms of M2k.\nLet us apply identity\nE Î¾1\n*Î¾* = E Î¾1\n*Î¾2,\nto B(2) and rewrite it in the following form\n2k\nN\nB(2)\nEâ¨Ap1 â©*Ap2-1\n2k (N) =\n(x, y)AN (y, x).\nN\nN\nN\np1,p2â¥1\nx,y=1\np1+p2=2k\nNow we can apply to the last average (1.9) with Î³ = AN (y, x). After simple\ncomputations similar to the formula (1.12), we obtain equality\nk-1\nB(2)\nB(2)\n2B(3)\n2k (N) = 2v\n2k-2-2j (N)M(N ) + v\n2k-2(N)\n2j\nj=0\n(4.3)\n+ v 2\np2 Eâ¨Ap1 â©* â¨Ap2 â© + v2(2k - 2)2\nM(N )\nN\nN\nN\n2N2\n2k-2.\np1,p2â¥1\np1+p2=2k-2\n\n4. Eigenvalues outside of the limiting spectrum\nHere and below we assume that\nB(m)\np1\np2\npm ,\n(4.4)\n(N) =\nE L* L* Â· Â· Â· L*\n2k\np1,...,pmâ¥1\np1+Â·Â·Â·+pm=2k\nwhere we denote Lp = â¨Ap â©.\nN\nNow let us remark that if regarding (4.3), we could forget about the term\nB(3)\n2k-2, then (1.17) would follow as a simple consequence of the ordinary\nprinciple of mathematical induction. Namely, assuming that the estimate\nB(m)\n\n(2j)mÏ\nM(N )\n(4.5)\n2j (N) â¤ Nm\n2j\ntaken with m = 2 holds for all j â¤ k - 1 and substituting these inequal\nities into (4.3) with B(3) ejected, one can derive after certain amount of\n2k\ncomputations that (4.5) holds also for j = k.\nPresence of the term B(3)\n2k-2 makes the scheme of the proof more compli\ncated, but not too much. The observation is that B(2) is depends on B(3)\n2k\n2k-2,\nwhere variable m has increased from 2 to 3, but 2k has decreased to 2k -2.\nThus, one has just to modify the reasoning based on the mathematical in\nduction principle.\nThus, our aim is to prove (4.5). We proceed from (4.3) by deriving a\nrecurrent relation for B(m)(N). It has a similar form, where B(m)(N) is\n2k\n2k\n(N), B(m+1)\nexpressed in terms of B(m)(N), B(m-1)\n2j\n(N) with j â¤ k -1.\n2j\n2j\nLet us note that due to definition of B(m), one has always m â¤ 2k.\n2k\nThe case of equality m = 2k corresponds to one term in (4.4) where p1 =\np2 = Â· Â· Â· = pm = 1. In this case estimate (4.5) can be verified by direct\ncomputations, as well as in the case of m = 2k -1.\nNow, the scheme of the ordinary mathematical induction (the \"linear\"\none) of the proof of (4.5) can be replaced by a two-dimensional scheme,\nwhere one moves along the points (k, m) such that m + 2k = L. On the\nlines m = 2k and m = 2k - 1 relation (4.5) is easy to be verified. Next,\nassuming that (4.5) holds for all (k, m) such that m + 2k â¤ L, one moves\nalong the line m + 2k = L + 1 from the point closest to m = 2k to the point\nwith m = 2. The structure of relations (4.3) is such that this procedure\nleads to the estimate (4.5) for B(m)(N) on the line m + 2k = L + 1.\n\n2k\nNow let us carry out several key-point computations of this proof. Re\ngarding\nB(m) =\nE[L* L* Â· Â· Â· L*\n]*Lpm\n2k\np1\np2\npm-1\npi\n\n4. Eigenvalues outside of the limiting spectrum\nand applying to the last factor our usual scheme, we derive relation\n*\nB(m) = v 2\nE[L* L* Â· Â· Â· L*\n]\n\nLqm Lqm+1 + pm -1 Lpm-2\n\n2k\np1\np2\npm-1\nN\npi\nq1+q2=pm-2\nv\n2pj\n\nL*\n+\nE L* Â· Â· Â· L*\np1\npj-1\nN Lpm+pj -2\nÂ· Â· Â· L*\n.\nN\npj+1\npm-1\npi\nUsing identity\nE X*Y Z = E XY *Z + E XY Z* + E XY *Z* -E X E Y *Z* ,\nand denoting\nD(m) =\nE|L* L*\npm |,\nÂ· Â· Â· L*\n2k\np1\np2\np1,...,pmâ¥1\np1+Â·Â·Â·+pm=2k\nwe derive inequality\nk-1\nD(m)\nD(m) â¤ 2v\n2k-2-2j M2j + v 2D(m+1)\n2k\n2k-2\nj=0\nk-1\n+ v 2\nD(m-1) D(2)\nv2(2k -1) D(m)\n+\n2k-2-j\nj\nN\n2k-2\nj=0\nv2(2k -1)2 k-1\nD(m-2)\n2v2(2k -1) D(m)\n+\nN2\n2k-2-2j M2j +\nN2\n2k-2.\nj=0\nThis implies the following inequality\n\nk-1\n\nD(m)\nD(m)\n\n2k â¤ 2v\n2k-2-2j M2j\nj=0\nk-1\n\n(4.6)\n+ v 2 2j\nN\n-\n1 D(m-2) M2j + Î¨k(N),\n2k-2-2j\nj=0\nwhere Î¨k(N) contains unimportant terms. Among these terms there is the\nterm D(m+1)\nD(m)\nthat is also of order smaller than 2k . This means that\n2k-2\nwe can actually return back to the ordinary mathematical induction of the\nproof of (4.5).\nAssuming that (4.5) holds, we derive from (4.6) inequality\n\nk-1\nD(m)\n2 (2k -2 -2j)mÏ\nM2k-2-2j M2j\nâ¤ 2v\n2k\nNm\nj=0\nk-1\n(2k -2 -2j)(m-2)Ï\n(4.7)\n+ v 2\n(2j -1)M2k-2-2j M2j + |Î¨k (N)| .\nNm\nj=0\n\n4. Eigenvalues outside of the limiting spectrum\nThe first problem is related with number 2 in front of the first terms in the\nright-hand side of (4.7). However, one can easily avoid it assuming that\n)mÏ\nÏ > 1/2. Then for all m â¥2 the function (2k -2t\nis convex and we\ndeduce that\nD(m)\n1)(m-2)Ï +1\nâ¤ (2k -2)mÏ + (2k -\nX2k-2(N),\n2k\nwhere\nk-1\nX2k-2(N) â¡v\n(2j -1)M2k-2-2j M2j .\nj=0\nIt follows from (1.13) that\n|X2k-2(N)| = M2k -v 2 2k -1 M2k-2 -v 2D(2)\nN\n2k-2\n2k -1\n2k-2(N) + (2k -2)2Ï\nâ¤M2k +\nX\nN2\nX2k-2(N).\nN\nCombining these estimates, we see that to prove (4.5), one has to determine\nparameter Ï and the relation between k and N in such a way that\n(4.8)\n(2k -2)mÏ + (2k -1)(m-2)Ï +1\n1 - 2k -1 -(2k -2)2Ï\nâ¤(2k)mÏ\nN\nN2\nfor all m â¥2 and all possible k.\nWe divide both sides by (2k)mÏ , take m = 2 and observe that the in\nequality\n\n1 2Ï\n4k -2\n1 -\n+\n< 1\nk\n(2k)2Ï\nis valid for large enough values of k only when Ï is greater than 1.\nIn fact, taking m = 2, we provide the maximal value for the first factor\nfrom (4.8). Regarding its product with the second factor, we obtain that\ninequality (4.8) holds only when\n2k\n(2k -2)2Ï\n+\nN\nN2\n< 2k .\nThis inequality is true under condition that\nk2Ï +1 < N2 .\nThis means that (4.5) holds in the limit N âinfunder condition that\nk âªN2/3 .\n\nâ²\nâ²\n4. Eigenvalues outside of the limiting spectrum\nNorm estimates. Let us complete this lecture with estimates for the norm\nof random matrices ÎN (2.21) with correlated entries.\nTheorem 4.1 ([3]). Under hypotheses of Theorem 2.2,\nâ\nlim sup â¥ÎN â¥â¤2\nvÎ½1.\nIf the matrix V is such that\ninf\n(4.9)\nTr V r\nN â¤\nÎ»r d Î½(Î»),\nr\n\nâN,\nN\nthen the upper bound of the support Î of the distribution\nÏV (Î») = lim Ï(Î»; ÎN )\nN âinf\ncoincides with the estimate from above for the norm. This means that there\nare no eigenvalues of ÎN in the limit N âinfoutside of Î.\nCondition (4.9) holds for V (x, y) = u(x -y) with u(x) â¥0. However, in\ngeneral one cannot guarantee that all eigenvalues of ÎN are inside of Î for\nN = inf.\nTo show this, it is sufficient to consider V (x, y) = w(x) with\nv , if x = 1,\nw(x) = v,\nif x = 1\nwith v > 4v. Then\nÎ = (-2v, 2v)\nbut\nâ\nâ¥ÎN e1â¥â vvâ² > 2v.\nTheorem 4.2 gives sufficient conditions to avoid the situation when there\ncould be eigenvalues outside of the support of the limiting eigenvalue distri\nbution. This is important in a series of applications of random matrices, in\nparticular in the statistical mechanics of disordered spin systems.\n\nBibliography\n[1] F.A. Berezin, Some remarks on the Wigner distribution, Teoret. Mat. Fiz., 17 (1973)\n305-318.\n[2] A. Boutet de Monvel and A. Khorunzhy, Asymptotic distribution of smoothed eigen\nvalue density. I. Gaussian Random Matrices & II. Wigner Random Matrices, Random\nOper. Stochastic Equations, 7 (1999) 1-22 & 149-168.\n[3] A. Boutet de Monvel and A. Khorunzhy, On the Norm and Eigenvalue Distribution\nof Large Random Matrices, Ann. Probability, 27 (1999) 913-944.\n[4] A. Boutet de Monvel and A. Khorunzhy, On universality of smoothed eigenvalue\ndensity of large random matrices, J. Phys. A: Math. Gen., 32 (1999) L413-L417.\n[5] A. Boutet de Monvel, A. Khorunzhy and V. Vasilchuk, Limiting eigenvalue distribu\ntion of random matrices with correlated entries, Markov Process. Related Fields, 2, 4\n(1996), 607-636.\n[6] B.V. Bronk, Accuracy of the semicircle approximation for the density of eigenvalues\nof random matrices, J. Mathematical Phys., 5 (1964) 215-220.\n[7] Z. F\nos, The eigenvalues of random symmetric matrices, Combina\nuredi and J. Koml\ntorica, 1 (1981) 233-241.\n[8] S. Geman, A limit theorem for the norm of random matrices, Ann. Probab., 8 (1980)\n252-261.\n[9] T. Guhr, A. M\nuller, Random matrix theories in quan-\nuller-Groeling and H. Weidenm\ntum physics: common concepts, Physics Reports, 299 (1998) 189-425.\n[10] A. Khorunzhy, Eigenvalue distribution of large random matrices with correlated en\ntries, Mat. Fiz. Anal. Geom., 3 (1996) 80-101.\n[11] A. Khorunzhy, On smoothed density of states for Wigner random matrices, Random\nOper. Stochastic Equations, 5, 2 (1997) 147-162.\n[12] A. Khorunzhy, On dilute unitary random matrices, J. Phys. A: Math. Gen., 31 (1998)\n4773-4784.\n[13] A. Khorunzhy, Sparse random matrices: spectral edge and statistics of rooted trees,\nAdv. in Appl. Probab., 33 (2001) 1-18.\n[14] A. Khorunzhy, B. Khoruzhenko and L. Pastur, Asymptotic properties of large random\nmatrices with independent entries, J. Math. Phys., 37 (1996) 5033-5060.\n\nBibliography\n[15] A. Khorunzhy, B. Khoruzhenko, L. Pastur and M. Shcherbina, The large-n limit\nin statistical mechanics and the spectral theory of disordered systems, In: Phase\nTransitions and Critical Phenomena, Vol. 15, Eds.: C. Domb and J.L. Lebowitz\n(1992) 73-239.\n[16] A. Khorunzhy and W. Kirsch, Limit of infinite band width for product of two random\nmatrices, Random Oper. Stochastic Equations, 5 (1997) 325-336.\n[17] A. Khorunzhy and L. Pastur, Limits of infinite interaction radius, dimensionality and\nnumber of components for random operators with off-diagonal randomness, Comm.\nMath. Phys., 153 (1993) 605-646.\n[18] A. Khorunzhy and L. Pastur, On the eigenvalue distribution of the deformed Wigner\nensemble of random matrices, In: \"Spectral operator theory and related topics\", 97-\n127, Adv. Soviet Math., 19, Ed. V.A. Marchenko, Amer. Math. Soc., Providence, RI,\n1994.\n[19] A. Khorunzhy and G.J. Rodgers, On the Wigner law in dilute random matrices, Rep.\nMath. Phys., 43 (1998) 297-319.\n[20] H. Kunz, Matrices al eatoires en physique, Presses Polytechniques et Universitaires\nRomandes, Lausanne, 1998.\n[21] V. Marchenko and L. Pastur, Eigenvalue distribution of certain ensembles of random\nmatrices. Mat. Sbornik 72 507-536 (1967) (English translation: Math. USSR Sb., 1\n(1967) 457-483).\n[22] M.L. Mehta, Random Matrices, Academic Press, New York, 1991.\n[23] L. Pastur, On the spectrum of random matrices, Teor. Mat. Fiz., 10 (1973) 102-111\n(in russian).\n[24] L. Pastur, Random Matrices as Paradigm, Mathematical Physics 2000, Eds. A. Fokas,\nA. Grigoryan, T. Kibble and B. Zegarlinski, Imp. Coll. Press, London, 2000, 216-265.\n[25] L. Pastur, A. Khorunzhy and V. Vasilchuk, On asymptotic property of spectra of sum\nof random independent one-dimensional operators, Reports of Acad. Sci. Ukraine, N2\n(1994) 25-27 (in russian).\n[26] Ya.G. Sina Ä± and A.B. Soshnikov, A refinement of Wigner's semicircle law in a neigh\nborhood of the spectrum edge for random symmetric matrices, Funktsional. Anal. i\nPrilozhen., 32, no. 2 (1998) 56-79 (English translation: Func. Anal. Appl., 32, no. 2\n(1988) 114-131).\n[27] A. Soshnikov, Universality at the edge of the spectrum in Wigner random matrices,\nComm. Math. Phys., 207 (1999) 697-733.\n[28] C.A. Tracy and H. Widom, Introduction to random matrices, in \"Geometric and\nquantum aspects of integrable systems\", Lecture Notes in Physics, 424, Springer,\nBerlin, 1993, 103-130.\n[29] P. van Moerbeke, Integrable Lattices: Random Matrices and Random Permutations,\n\"Random matrices and their applications\", Eds. P. Bleher and A. Its, MSRI Publi\ncations 40, Cambridge, 2000, 1-98.\n[30] E. Wigner, Characteristic vectors of bordered matrices with infinite dimensions, Ann.\nof Math., 62 (1955) 548-564.\n[31] A. Zvonkin, Matrix integrals and map enumeration: an accessible introduction,\nMath. Comput. Modelling, 26 (1997) 281-304."
    },
    {
      "category": "Resource",
      "title": "diacon_pap_S0273.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-338j-infinite-random-matrix-theory-fall-2004/3100804bbd5d43e7c54ddb8135df6c8e_diacon_pap_S0273.pdf",
      "content": "BULLETIN (New Series) OF THE\nAMERICAN MATHEMATICAL SOCIETY\nVolume 40, Number 2, Pages 155-178\nS 0273-0979(03)00975-3\nArticle electronically published on February 12, 2003\nPATTERNS IN EIGENVALUES:\nTHE 70TH JOSIAH WILLARD GIBBS LECTURE\nPERSI DIACONIS\nAbstract. Typical large unitary matrices show remarkable patterns in their\neigenvalue distribution. These same patterns appear in telephone encryption,\nthe zeros of Riemann's zeta function, a variety of physics problems, and in the\nstudy of Toeplitz operators. This paper surveys these applications and what\nis currently known about the patterns.\nIntroduction\nThis paper surveys what we know about the distribution of the eigenvalues of\ntypical large unitary matrices. The topic occurs naturally in problems of statistics,\nphysics and number theory. The mathematical interconnections are also fascinating,\nand it is hard to escape the feeling that there is something unseen to be discovered.\nTo keep the paper within bounds, the following classical compact groups will be\nfeatured:\nOn the n Ã n real matrices M such that MM T = id.\nUn the n Ã n complex matrices M such that MM â = id.\nSn the n Ã n permutation matrices.\n\"Typical elements\" are studied by using Haar measure. This is a probability\nmeasure P on a group G which is translation invariant: for any measurable set A\nin G and any element M in G\nP(A) = P(MA).\nFor the symmetric group, we all have an intuitive feel for what it means to pick\na permutation at random, at least via shuffling cards. For the other groups this\nis less familiar. The following method for picking a group element at random may\nhelp.\nConsider the orthogonal group On. Here is a simple algorithm: fill out an empty\nn Ã n array with independent picks from the standard Gaussian bell-shaped curve.\nThen perform the Gram-Schmidt algorithm on this array: normalize the first row to\nhave norm one, take the first row out of the second row and normalize to have norm\none, and so on. This constructs an orthogonal matrix which is Haar distributed.\nPut more formally, put product measure on Rn with each factor having density\ne-x /2/\nâ\n2Ï. The Gram-Schmidt algorithm gives a map T from almost all of Rn\nonto On. The image of the product measure is Haar measure.\nReceived by the editors October 10, 2002.\n2000 Mathematics Subject Classification. Primary 00-02, 60B15.\nc\n2003 American Mathematical Society\n\nP\nPERSI DIACONIS\n.\nFigures 1-4: Five realizations for n = 100 from Haar measure on On, Un, Sn, and\nindependent uniform points.\n2 dx . . . dx\ni\nThis is easy to prove and understand. Each row of the original array has density\nproportional to e-\nx\n. This measure on Rn is invariant under orthog\nn\nonal transformations. By inspection, T (MX) = MT (X) where X is the original\narray. Hence, P(MT (X) â A) = P(T (MX) â A) = P(T (X) â A). A more an\nalytical proof can be found in Eaton [40]. Perhaps more convenient: if an n Ã n\nmatrix of independent Gaussian entries is input to the QR algorithm, the resulting\northogonal piece is Haar distributed. See [32] for a survey of constructions of Haar\nmeasure.\nThe same construction works for the unitary group Un using the usual complex\ninner product. Here the original entries of the array are chosen as independent,\nstandard, complex Gaussian variables with density e-|z| /Ï on C.\nFor any of the groups On, Un, Sn in its standard matrix representation, any ele-\niÎ¸1\nment is diagonalizable with all eigenvalues on the unit circle. Call these {e\n, . . . ,\neiÎ¸n }. The main question to be studied is: pick MÎµG from Haar measure; how are\n{eiÎ¸1 , . . . , eiÎ¸n } distributed? To begin our study, Figures 1 through 3 show eigenval\nues for five independent realizations from On, Un, Sn when n = 100. Also shown for\ncomparison are five realizations of 100 points chosen uniformly and independently\non the unit circle.\nFigures 1 and 2 are similar. Each shows sets of 100 points neatly arranged\naround the unit circle. There are slight variations, but the points are close to 1/100\napart. A careful look shows the eigenvalues for On come in complex conjugate\npairs. In contrast, Figure 4 shows that completely random points have much greater\nvariability than the eigenvalues of random matrices. Figure 3 corresponds to the\nsymmetric group. It shows neatly arranged points with varying densities. The rest\nof this paper presents a fairly detailed theoretical understanding of these and more\nsubtle patterns. Before this, let us pose a basic question.\nWHO CARES?\n\nX\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\nThere are many questions; why study these? The next four sections of the\npaper offer motivation; the eigenvalues appear in applied problems of telephone\nencryption (Section One) and in routine statistical work (Section Two). They\nappear in the mathematical understanding of the zeros of Riemann's zeta function\n(Section Three). They also have remarkable internal properties suggesting study\nfor their own sake (Section Four).\nSection Five gives a general picture for understanding and proving things about\nunitary eigenvalues. This uses tools of representation theory. Section Six gives\npointers to the literature on topics not covered: other ensembles, free probability,\nde Finetti-type theorems, largest eigenvalues and much else.\nAs an applied mathematician who is not a physicist, connecting my interests to\nGibbs' legacy seemed like an impossible task. Despite my limitations, mathemat\nical physics runs throughout random matrix theory. The physics of the telephone\ndrives the analysis of Section One. Particle scattering directly connects physics and\nrandom matrices. Szeg o's strong limit theorem was proved in answer to a question\nof Onsager on Ising phase transitions. The first rigorous proof of the equivalence of\nensembles for Gibbs' measures can also be understood as a part of random matrix\ntheory. Physics illuminates much of mathematics. We hope for the converse.\nI thank my coauthors--Dan Bump, Steve Evans and Mehrdad Shahshahani--\nalong with my students--Joe Blitzstein, Marc Coram, Jason Fulman, Eric Rains\nand Kelly Wieand--for their contributions to this work. Thanks, too, to my ran\ndom matrix friends--Percy Deift, Kurt Johansson, Alexei Borodin, Neil O'Connell,\nAndre Okunkov, Craig Tracy and Harold Widom.\n1. Telephone encryption\nMy interest in random orthogonal matrices began with an applied problem in\ntelephone encryption. While it is well understood how to cryptographically scram\nble up bits, telephone encryption must make the scrambling commensurate with\nthe physics of the telephone and be done rapidly enough to permit normal con\nversation. One scheme due to Aaron Wyner [85] digitized speech into 8-bit blocks\nand treated these as real numbers. Vectors of 256 such blocks can be encrypted\nby rotating with a 256 Ã 256 random orthogonal matrix. This scrambled vector is\ntransmitted, and the receiver decrypts the message by multiplying by the inverse\nmatrix. Keeping the length of the signal constant is crucial to practical encryption\nof speech.\nAll of this requires a stream of random orthogonal matrices. The Gram-Schmidt\nprocedure previously described takes order n3 steps to generate an n Ã n matrix.\nAfter all, the rows above the ith have to be removed by an inner product of length\nn. The number of operations is thus of order\nn\nin = 0(n 3).\ni=1\nWhen n = 256, putting in the constants, this algorithm takes approximately 16Ã106\noperations and is simply too slow to allow natural speech on the telephone.\nNeil Sloane suggested that perhaps approximately random orthogonal matrices\nwould be practically as good. He suggested forming an approximately random\nelement of On by multiplying a few random reflections: matrices of the form I -\n2uuT with u chosen uniformly on the unit sphere. One can multiply a matrix by\n\nZ\n\nPERSI DIACONIS\na reflection in order n2 operations. This raised the following problem: how many\nreflections are required to have an approximately uniform product? Preliminary\nwork with Shahshahani [30], brilliantly completed by Rosenthal [83] and Porod\n[79]\n, shows that 2 n log n products are necessary and suffice to achieve approximate\nuniformity. The lower bound of this theorem proceeds as follows: consider a single\nproduct I -2uuT . Why isn't this random on its own? For one thing, it fixes an\nn -1 dimensional subspace. Similarly, the product of k reflections fixes an n -k\ndimensional subspace. Thus if k is not large enough, the trace of the product will\nbe large. This raises the question, how large will the trace of a uniformly chosen\nelement of On typically be? We have finally arrived at an eigenvalue question.\nConsider a uniformly chosen matrix MÎµOn. Its diagonal entries are small num\nbers (about size ân\n1 ), and different rows should not be too dependent. The basic\ncentral limit theorem of probability says that if you add up a large number of\napproximately independent random numbers, the sum should be approximately\ndistributed like the bell-shaped curve e-x /2/\nâ\n2Ï. Mallows and I were able to\nprove this:\nTheorem. Let M be chosen uniformly in On. Then, as n tends to inf,\n(1.1)\nx\n/2\ne-t\n0,\nP{tr M â¤x} -\ndt\nâ\n2Ï\nâ\n-inf\nuniformly in x.\nThis result will be extended and refined in later sections. It implies that no\nmatter how large n is, the trace of a random orthogonal matrix is less than three\nn log n+cn random reflections are required to make the trace this small\nReturning to the original telephone encryption problem, the bounds show that\nin absolute value with high probability. Using character theory, it is not hard to\nshow that\nunder the convolution measure.\n1 n log n + cn reflections suffice to be close to random. If all that is wanted is the\nimage of a vector following a product of reflections, this is available at cost of order\nn2 log n (it takes order n steps to multiply a vector by a reflection). This gives\na substantial speedup. In summary, for this example, the eigenvalues of random\northogonal matrices came in the back door as a tool for proving lower bounds on\nrunning times in an applied problem.\n2. Statistics and eigenvalues\nThe earliest manifestations of random matrix theory may be the fluctuation\ntheory of correlations. Statisticians frequently analyze high dimensional data by\nlooking at covariance matrices and their eigen-decompositions into principal com\nponents. To explain by example [67], consider the scores of 100 pupils on 5 math\nexams through the term. If the ith students' scores are Xi = (Xi1, . . . , Xi5), then\n5P\nthe data matrix X is the 100 Ã 5 matrix with the Xi as rows. It is natural to look\nat linear functions of the scores, say, Î³\nXi =\nÎ³j Xij . The norm one vector Î³â\nÂ·\nj=1\nwhich maximizes the variance of the hundred numbers Î³ X1, . . . , Î³ Â· X100 is called\nÂ·\nthe first principal component of X. The vector Î³ââ maximizing variance subject to\northogonality to Î³â is the second principal component, and so on. In the example,\nthe first principal component is approximately the average of the five scores, while\n\nR\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\nthe second principal component is approximately the difference between the aver\nage of the first two tests and the last three tests. Histograms of the data on these\nfirst two principal component directions might well be used to assign final grades\nand assess the progress of the class. If we are to look at the patterns in Î³â and Î³ââ,\nit is natural to ask about their stability. If the data had come out slightly different,\nwould the inferences change much?\nIt is not hard to see that the principal components are the eigenvectors of a\nsuitably scaled version of the 5 Ã 5 covariance matrix XT X. The variance of the\ndata projected onto the maximizing eigendirections are the eigenvalues. If the\ndata is a sample from a larger population or modelled as stochastic in other ways,\nunderstanding fluctuations of the eigenanalysis is random matrix theory.\nIn general, n Ã p data matrices are considered with rows which are indepen\ndent samples from some fixed population. R. A. Fisher and J. Wishart found the\nsampling distribution of XT X when the population is Gaussian. In the 1930's,\nWilks, Hsu, Girshick and others derived the joint distribution of the eigenvalues\nand eigenvectors for the Gaussian case. Anderson [5] and Muirhead [70] give a\nnormal approximation for the eigenvalues when n is large and p is fixed for general\ndistributions for X. The mathematical development, largely due to Alan James,\nis intimately linked to zonal polynomials, the spherical functions associated to the\naction of the orthogonal group O(p) on the positive definite matrices. See [65] for\ndetails and references.\nModern statistical work, as applied in areas such as data mining or search en\ngines, deals also with cases with p large. The empirical distribution of the bulk\nof eigenvalues of covariance matrices was studied by Marcenko-Pastur [66]. They\nshowed that if n, p âinfwith n/p âÎ³, then\n(2.1)\np {#e.v. â¤nt} âG(t)\nwith G a distribution function having density\nÎ³ p\n(b -t)(t -a), a â¤t â¤b, a = (1 -Î³\n2 )2, b = (1 + Î³\n2 )2 .\n(2.2)\ng(t) = 2Ït\nThese distributions vary considerably in shape with Î³.\nFollowing work of Johansson, Johnstone [58] derived the fluctuation theory of the\nextreme eigenvalues for the Gaussian case. He showed that the largest eigenvalue\n`1 satisfies\n(2.3)\n`1 -Î¼np\nF1\nÏnp\nâ\nwhere\ndenotes weak âconvergence,\nâ\nÎ¼np = (\nâ\nn -1 + âp)2, Ïnp = (\nâ\nn -1 + âp) â\n+ âp\n(2.4)\nn -1\nand F1 is the Tracy-Widom distribution\n(2.5)\nF1(s) = e-1\ninf q(x)+(x-s)q\ns\n(x)dx ,\nwhere q solves the Painlev e Î  equation\n(2.6)\nq00 = xq(x) + 2q 3(x),\nq(x) â¼Ai(x) as\n.\nx âinf\nHere the scaling is non-classical - the standard deviation grows with sample size as\nn . Johnstone has shown that this approximation is useful for n as small as ten.\n\nPERSI DIACONIS\nMuch of the mathematical work on eigenvalues in statistics was done for Gauss\nian random variables. Because of the orthogonal invariance of Gaussian vectors,\nthe mathematical development is closely related to the orthogonal group. Useful\nsurveys of available results for Gaussian and more general populations appear in\nBai [8] and Muirhead [70].\n3. Connections with the Riemann zeta function\nThere is a surprising, unexplained connection between the eigenvalues of random\nmatrices and the zeros of Riemann's zeta function. We give a brief fresh look at\nthis from a statistical point of view, following joint work with Marc Coram [24].\nPointers to the large literature are given at the end of the section.\nFor complex s with re(s) > 1 the Riemann zeta function is defined by\ninf\n\nX 1\n-1\n(3.1)\nÎ¶(s) =\nns = Î p 1 -ps\nn=1\nwhere the product is over all primes. The zeta function can be continued to the\nwhole complex plane with a simple pole at s = 1. Riemann showed that knowledge\nof the zeros of Î¶(s) would give information about the distribution of primes. It is\nknown that, except for \"trivial zeros\" at -2, -4, -6, . . ., all the zeros are in the\ncritical strip 0 < re(s) â¤1. Riemann showed that the number of zeros in the strip\nwith imaginary parts between zero and T is\nT\nT\n(3.2)\nN(T ) =\nlog 2Ïe + 0(log T ) as T âinf.\n2Ï\nThis means that the zeros get denser higher up with local density log 2\nT\nÏ\n.\nT\nre(s) = 1\nat height\n. The Riemann hypothesis says that all the zeros are on the critical line\nWe next connect the zeros in a neighborhood of the strip at height T to the eigen\nvalues of typical unitary matrices in Un. To have the same density of eigenvalues as\nzeros, following an idea of Keating and Snaith [60], [61], choose n = log 2\nT\nÏ . In the\ndata to be described below, 50, 000 zeros starting at the 1020 zero are considered.\n=.15 Ã 1020 and n\n\nHere T\n= log 2\nT\nÏ =42. To compare the zeros with eigenvalues,\nwe wrap blocks of 42 zeros around the unit circle. More precisely, given zeros\nZ1, Z2, . . . , ZN of the form Zj = 1 + iÏj with Ï1 . . . < Ïj . . . < ÏN , form spacing Ïj =\nÏj+1 -Ïj . Split the spacings into disjoint groups of size n + 1. Each group of\nspacings Ï1, . . . , Ïn is mapped onto the unit circle by taking xj = exp(2Ïi( Îj )) for\nÎn\n1 â¤ j â¤ n, where Îj = Pj\nÏn and U is a uniform random variable on [0, 2Ï]\nn=1\nchosen independently for each group.\nWhen N = 50, 000 and n = 42 this gives about 50, 000/43 =1190 different\nwrapped data sets. The claim is that these data sets are distributed like the eigen\nvalues of matrices chosen from Haar measure on the unitary group U42.\nThis\n\nwell-posed hypothesis was exhaustively tested in [24]. We present a few of the re\nsults here, but the bottom line is that the wrapped zeta data passes virtually all\nthe tests thrown at it.\nOne approach to testing goodness of fit of the wrapped zeta data to unitary\neigenvalues is to look at the trace. As explained in the section above\n(3.3)\nPn |TrM\nâ¥t âe-t uniformly in t as n âinf.\n|\n\np\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\nObserved Value\nCount\nObserved Value\nCount\nFigure 5. Zeta data\nFigure 6. Null data\nFigures 5-6: On the left, a histogram of 1190 zeta-function-based\nnorm-squared \"traces\" with the standard exponential density func\ntion superimposed. On the right, a histogram of 1190 independent\nstandard exponential random variables.\nFor application to the zeta data, n = 42. Work of Johansson, described in fact\ntwo of Section Four below, shows that the exponential approximation in (3.3) is\nremarkably good.\nFigure 5 shows a histogram of the 1190 \"traces\" based on the wrapped zeta data\nwith the exponential density imposed. To help the reader calibrate, Figure 6 shows\na sample from a true exponential distribution. The two pictures seem interchange\nable. More formal tests also show the traces match the exponential distribution\nremarkably closely.\nA second test may be based on strange correlations found by Kelly Wieand [96],\n[97]. For 0 < a < b â¤ 2Ï let Xab(M) be the number of eigenvalues of M satisfying\na < Î¸j < b. Because of the neat distribution of eigenvalues, this random quantity\nhas expected value n(b - a)/2Ï. Wieand shows that\n(3.4)\nYab = Xab -n(b-a)/2Ï\nlog n/Ï2\nâ N(0, 1).\nThus the fluctuations are at a logarithmic level, and the normalized error follows\nthe bell-shaped normal distribution. To understand the limiting process, Wieand\ncalculated the correlation between Yab, Ycd. She found that in the large n limit\nCorr(Yab , Ycd) â\nâ§\nâª\nâ¨\nâª\nâ©\nif\nâ(a, b) â© â(c, d) = 0\nif b = c\n-\n+ 1\nif a = c\nThese are strange correlations. They say that if [a, b] contains [c, d] properly,\nthen Yab, Ycd are approximately independent, while if the two intervals share a sin\ngle endpoint, the limiting variables have correlation Â±\nfound this surprising. (At first I did not think these correlations were positive def\ninite!) In retrospect, the limiting variables make perfect sense. Suppose each point\nÎ¸ on the circle is assigned an independent Gaussian variable ZÎ¸ with mean zero and\n2 . Experienced probabilists\n\np\nPERSI DIACONIS\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0.2\n0.4\n0.6\n0.8\n1.2\nZeta Function\nUnitary (theoretical)\n0. 8\n0. 6\n0. 4\n0. 2\nFigure 7. Correlations for 0, Ï\nand\n+ Ï\nÎ¸, Î¸\n. Solid line is the\ntheoretical curve for Haar measure on Un. The circles depict the\nempirical correlations calculated from wrapped zeta data.\nvariance . Assign the interval [a, b] to Zb - Za. These variables have the correla\ntions reported above. Clearly, if the intervals have distinct endpoints, the variables\nZb -Za and Zd -Zc are independent, while for example: E(Zb -Za)(Zd -Zb) = -\nThis being observed, the obvious question is, where is the \"white noise\" ZÎ¸\n2.\nhidden in random matrices? A lovely, simple answer was given by Hughes et al.\n[53]. They showed that for each Î¸, with M chosen uniformly in Un,\niÎ¸\n(3.5)\nZn = im log DET (e - M)/ log n/Ï2\nÎ¸\nhas a limiting normal distribution with the limits being independent for different Î¸.\nThus the log characteristic polynomial is approximately normal. Using the principle\nof the argument, they showed that Wieand's results follow.\nWith all of this background, let us ask if we can find these strange correlations\nhidden in the zeros of the zeta function. To begin with, Wieand's results are large\nn limits and here n = 42. A finite sample correlation was calculated by Bump-\nDiaconis [20], with uniform approximation available through Bump-Diaconis-Keller\n[21]. The correlations for intervals (0, Ï\nÎ¸, Ï\n), (\n+Î¸) are shown in Figure 7. Of course,\nwhen Î¸ = 0, the correlation is one. As Î¸ varies, the correlation drops, and when\n(so the intervals share an endpoint) it is -\nAlso shown are the empirical correlations based on the wrapped zeta data. We\nÏ\nÎ¸ =\n.\nagain see a striking match. The work with Coram reports extensive further testing\nof both specific features and an omnibus test. The upshot is a remarkable fit be\ntween the zeta data and the unitary eigenvalues. The only question to be answered\nnow is, where is the operator?\nThe first connections between zeta zeros and random matrix theory were drawn\nby Hugh Montgomery following a conversation with Freeman Dyson. Montgomery\nsuggested (and roughly proved) that the pair correlations - chance of finding a zero\n\nQ\nY\nX\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\nat distance x from a first zero - should match up with the pair correlations of the\neigenvalues of stochastic Hermitian matrices (GUE) after suitable density adjust\nment to make the mean spacing one in both cases. Odlyzko [71], [72] carried out a\nremarkable study of data from consecutive zeros and eigenvalues. Marvelous new\nmethods were invented for accurate computation of zeros far up. Michael Berry\nposited remarkable correction terms to the Dyson-Montgomery 2-point correla\ntions, and Odlyzko was able to show an amazing match to zeta data. Much of this\nwork is carefully reviewed in Conrey [22], Berry and Keating [12] and Katz-Sarnak\n[59]. In particular, the last authors suggest that random matrix theory works for\ngeneral families of L-functions. Keating and Snaith [60], [61] opened a new chap\nter by suggesting unambiguously that the characteristic polynomial Z(M, Î¸) =\nn\n(1 - eiÎ¸j -Î¸) was a useful surrogate for the zeta function. They showed that mo-\nj=1\nments of the zeta function along the critical line matched moments of Z(M, Î¸) over\nUn and, in joint work with several sets of coauthors (see e.g. [23]), make remark\nable predictions about zeta behavior which matches data and number theoretic\nheuristics. This has led number theorists to ask even more detailed questions of\nprobabilists. For example, to understand the biggest gap between zeros, one would\nlike to understand the biggest gap between unitary eigenvalues. This is open at\nthis writing.\n4. Five surprising facts\nAnother reason for studying the eigenvalues is that the mathematics is surpris\ning and beautiful. The joint probability density for the eigenvalues of a Haar-\ndistributed random matrix in Un is well known as the Weyl denominator formula,\n(4.1)\nf2(Î¸1, . . . , Î¸n) = (2Ï)nn!\n|e iÎ¸j - e iÎ¸k |2 .\nj<k\nThis is a probability density on (0, 2Ï)n with respect to product Lebesgue mea\nsure. See [47] for the classical derivation. Alas, this elegant, explicit formula is not\nof much use in understanding the distribution of eigenvalues. All one can see is\nthat f2 tends to zero as Î¸j and Î¸k approach each other, so the eigenvalues tend to\nrepel. Physicists write the product as\n(4.2)\ne-Î²H(Î¸1...Î¸n) with Î² = 2, H = -\nlog |e iÎ¸j - e iÎ¸k |\nj<k\nand invoke statistical physics intuition for a \"Coulomb Gas\" of n repelling electrical\nparticles around a circle.\nThe following theorems make some of this intuition precise, but show there are\nmany surprises hidden in the simple formula (4.1).\nFact One: The eigenvalues are very neatly spaced (but slightly random). This can be\nseen visually in Figure 2. To interpret the mathematical statement below, note two\nthings: First, the sum of n complex numbers equally spaced around the unit circle\nis zero. Second, the sum of n complex numbers put on the unit circle at random\n(independently and uniformly) is of order ân. This follows from the classical central\nlimit theorem of probability theory. In joint work with Mallows [29] we proved:\n\nZ\n\nZ\n\nZ\nZ\nX\np\nPERSI DIACONIS\nTheorem. For M chosen from Haar measure, n large and any ball B âC,\ne -|z|\n(4.3)\nP{Tr(M) âB} â¼\ndz.\nÏ\nB\nHere the trace is not divided by ân, so the eigenvalues practically cancel out.\nIf Br is the ball in C centered at zero with radius r, the right side of (4.3) equals\n1 -e-r .\nI still find it mysterious, looking at (4.1) and asking how the cancellation occurs.\nOf course, things do not cancel perfectly. Wieand's theorem described in Section\nThree above shows that the number of eigenvalues in a fixed interval of the unit\ncircle is n times the interval's length, plus fluctuations of order âlog n.\nFact Two: The traces are amazingly close to Gaussian. Consider the error term in\nthe Gaussian approximation to the trace at (4.3). Johansson [56] proved:\nTheorem. There are universal constants c, Ï > 0 such that\ndz\nc\nnÏn\nâ¤\ne -|z|\nP{Tr M â B} -\nÏ\nB\nuniformly in Borel sets B.\nPeople used to the usual error terms in probability find this result fantastic; for\nthe classical central limit theorem for the sum of n points randomly put on the unit\ncircle, the error is of order n. Here, the error is super-exponential.\nTwo closely related findings:\n(a) The moments of the trace equal the normal moments\ne -|z|\na\nb\nM)b dM =\nz\nz |\n(4.4)\n(Tr M)a Tr (\ndz.\n| | |\nÏ\nThe equality (4.4) for all integers a, b smaller than n is joint work with Colin\nMallows, which is discussed at length in Section Five below.\n(b) An analogous result is proved for the trace of a random permutation matrix.\nTheorem. For Î , a uniformly chosen permutation matrix\n2n\nP {Tr Î  Îµ B} -P (B)| â¼\n|\n(n + 1)!\n(4.5)\nwith P(B) =\n1/i! for B â{1, 2, 3, . . .}.\ne iâB\nIn summary, the first thoughts suggesting a Gaussian limit for the trace were\nthat the trace is the sum of a lot of small, approximately uncorrelated random\nterms. While this is true, there is some mysterious global constraint that forces the\nhigh order contact with the Gaussian law.\nFact Three: Higher order traces go from order to chaos. In investigating the fine\nstructure of the eigenvalues, traces of higher powers are studied. In joint work with\nShahshahani [32] discussed in Section Five below, we proved:\nTheorem. For M chosen from Haar measure on Un, for j fixed and n âinf,\nP{Tr(M j) â B} âP{ j Z â B}\nwith Z a standard complex Gaussian variable.\n\nY\n\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\nAs j increases, âjZ becomes more spread out. Eric Rains [80] proved that a\nkind of phase transition occurs for j â¥ n.\nTheorem. Let M be chosen from Haar measure on Un. For any n, and any j â¥ n,\nthe eigenvalues of M j are exactly distributed as n points chosen independently and\nuniformly on the unit circle.\n. I find the contrast between facts one,\ntwo and three unsettling. I still have no mental picture that explains how these\ncan all hold. I have tried to think about generating Haar-distributed eigenvalues\nby putting down n uniform points independently and taking appropriate nth roots.\nRains' result can be demystified slightly by computation:\nM\nno\nM n\nn\nThus high powers of\nhave\nstructure in their eigenvalues. The trace of\nis approximately Gaussian, but with error\nThe joint mixed moments of the eigenvalues of M j are\nZ\nn\neijÎ¸k (bk -ak ) f2(Î¸1, . . . , Î¸k) dÎ¸1, . . . , dÎ¸n.\nk=1\nExpanding f2 from (4.1) as a polynomial, we see that for j â¥ n we get zero unless\nbk = ak for 1 â¤ k â¤ n. These are just the joint mixed moments for independent\nuniform points.\nRains [80] proved similar results for all the classical compact Lie groups. There is\na subtlety here. Take the orthogonal group O2n. The eigenvalues come in conjugate\npairs, and this is preserved for powers. Rains shows that for suitably large j the\neigenvalues of M j are exactly distributed as n random points and their conjugates.\nSome light on these strange doings follows from work of Forrester-Rains [42],\nHaake [49] and Rains [81]. For simplicity, consider M chosen from Haar measure\non U2n. They prove that for all n, the eigenvalues of M 2 are exactly distributed\nas the union of two independent sets of eigenvalues from M1, M2 chosen from Haar\nmeasure on Un. Similarly, the eigenvalues of M 3 â U3n are exactly distributed as\nthe union of eigenvalues of M1, M2, M3 independently chosen in Un. Their final\nresult has no divisibility requirements and applies for all powers j. It shows that\nthe eigenvalues of M n â Un are exactly distributed as independent points from U1.\nThese extra facts compound the mystery.\nFact Four: Neat marginals.\nThe foundations of random matrix theory were laid out in a great series of papers\nby Dyson [38], [39], who labeled the unitary ensemble CUE (Compact Unitary\nEnsemble). Dyson showed that the marginal distribution of n eigenvalues has a\nneat form. Physicists call these \"n-point correlations\" for mysterious historical\nreasons (they are not correlations!). Thus f2 from (4.1), which could be written\nf2\nn, is the n-point distribution. Informally, f2\nk(Î¸1, . . . , Î¸k) is the probability density\nfor an eigenvalue in dÎ¸1, dÎ¸2, . . . , dÎ¸k from a Haar-distributed matrix in Un. The\nelegant fact (due to Dyson) is a simple, closed-form formula:\nf2\nk(Î¸1 . . . Î¸k) = DET sin(n(Î¸a - Î¸b)) 1 â¤ a, b â¤ k.\nsin(Î¸a - Î¸b)\n\nsin n(Î¸1-Î¸2)\nFor example, f 1 = Constant, f 2 = 1 -\nsin(Î¸1-Î¸2)\n.\nMaachi [63], [64] created a general theory for point processes with k-point dis\ntributions having determinental form. See Daley-Verre-Jones [25] for a concise and\n\np\nX\nP\nY\nY\nPERSI DIACONIS\nvery readable treatment of point processes and Macchi's work. Soshnikov [88] gives\na marvelous survey showing how surprisingly many ensembles admit neat determi\nnental forms, and how a wide variety of limit theorems can be proved from these\nforms. Following work of Macchi, Diaconis-Evans [34] survey developments where\ndeterminants are replaced by permanents or immanents.\nFact Five: The Toeplitz connection.\nI find the following connection surprising. Shahshahani and I proved that if M\nis chosen from Haar measure on Un, the trace of successive powers has limiting\nGaussian distributions. As n âinf, for any fixed k and Borel sets B1, . . . , Bk\nk\n(4.6)\nP(TrM âB1, . . . , TrM k\nP( j Z âBj )\nY\n)\nB\nâ\nk â\nj=1\nwith Z a standard complex Gaussian variable.\nIn a seemingly very different sphere, G. Szeg o derived the limiting asymptotics\nfor the eigenvalues of Toeplitz matrices. This is a rich subject, and I will not\ntry to develop it in detail. B ottcher and Silbermann [17] is a remarkably good\nintroduction. Briefly, a Toeplitz matrix is an n Ã n matrix with complex entries\nwhich are constant down the main diagonals, such as\nâ¤\nâ¡\nâ¢â¢â£\na\nb\nc\nd\n\ne\na\nb\nc\n\nf\ne\na\nb\n\ng\nf\ne\na\n\nâ¥â¥â¦\nSzeg o determined the asymptotics of the determinants of a sequence of Toeplitz\nR 2Ï\ng(j-k) where Ë\nimÎ¸) dÎ¸\nmatrices Tn(g) constructed with (j, k) entry Ë\ng(m) = 2Ï\ng(e\nis the Fourier transform of a function on the unit circle.\nTheorem (Strong-Szeg o).\ninf\n-inf\nThen\nfË (k)\niÎ¸ ) = e f (e iÎ¸ )\nwith\n(4.7)\nLet g(e\nk < inf\n|\n|\n| |\n.\nfË(0)+\nk=1 f (k)f (-k)k+o(1)\ninf\nn\nDET Tn(g) = e\n.\nSzeg o's theorem has dozens of variations and applications from time series and\nelectrical engineering to the first proof of phase transitions in the Ising model.\no\nGrenander-Szeg [48] is a classical, readable overview of this material, as is Chap\nter Five in B ottcher-Silbermann [17].\nThe point of the present presentation is that (4.6) and (4.7) seem completely\nunconnected, and yet they are easily equivalent. The key connection is a classical\ndeterminant identity of Heine and Szeg o.\nf (e iÎ¸ ),\nProposition. For f as above and g = e\nZ 2Ï\nZ 2Ï\nn\nf (e iÎ¸j )\niÎ¸a\niÎ¸b\n-e\n2 dÎ¸1 . . . dÎ¸n = Tn(g).\n(4.8)\n|\n|\ne\ne\n. . .\n(2Ï)n\nj=1\n1â¤ aâ¤ bâ¤ n\n\nX\nX\nZ\nX\nY\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\nIt is not hard to see this directly; expand the determinant on the right side as a\nsum of products of n terms. Each term is a Fourier transform, and so the product\nis an n-fold integral of the same form as the left side. Recognizing a Vandermonde\nand elementary manipulations complete the proof. Alternatively, in joint work with\nBump [20], we have shown that (4.8) follows from the classical Jacobi-Trudi identity\nof symmetric function theory.\nWith (4.8) established we can now see the equivalence of (4.6) and (4.7). Begin\nwith (4.6). This is a limit theorem for the traces. Passing to Fourier transforms,\nlet\nk\nf(e iÎ¸) =\naj cos(jÎ¸) + bj sin(jÎ¸).\nj=1\niÎ¸1\niÎ¸n\nThen, for M âUn with eigenvalues e\n, . . . , e\nn\niÎ¸j ).\na1re Tr(M) + b1im Tr(M) + . . . + ak re Tr(M k) + bkim Tr(M k) =\nf(e\nj=1\nWe will use aj , bj as transform variables. Noting next that the transform of a\nGaussian variable âjZ = âj(X + iY ) is\nj\nâj(ax+by)-x -y 2 dxdy\n4 (a 2+b2)\ne\n= e\n,\nÏ\nwe see that the limiting normality of (4.6) is equivalent to convergence of the trans\nforms\nâ\nâ\nY f (e iÎ¸1 )\nY\nk\n2 + b2\nj )â \n(2Ï)n\nZ\n. . .\nZ\nn\ne\n|e iÎ¸j -e iÎ¸k |2 dÎ¸1 . . . dÎ¸n âexp\nX j\n.\nâ\n4(aj\nj=1\n1â¤j<kâ¤n\nj=1\no's theorem for the trigonometric polynomial f. Thus Szeg\nThis is just Szeg\no's\ntheorem implies (4.6). Conversely, (4.6) shows the Fourier transforms converge,\nand so Szeg o's theorem holds for trigonometric polynomials. It is not hard to pass\nto the limit and derive the result for general f.\nThere are many proofs of Szeg o's theorem in the references above. Johansson\n[55] gives a careful development of the asymptotic analysis required to go from\npolynomials to more general functions.\nThe present approach leads to straightforward generalizations in two directions.\nFirst, the limiting normality of traces of powers for other groups such as On or\nSP2n gives Szeg o-type theorems for determinants with entries the coefficients of\nexpansions in Jacobi polynomials. To be fair, these are classically known [52]. A\nsecond generalization was determined in joint work with Bump [20]. This gives\nasymptotics for the determinants of Toeplitz minors. These seem new, but closely\nrelated work has been done by Tracy-Widom [94].\nHere is a simple example. Let Î» be a partition of m. Define the Toeplitz minor\nn (g) = det (Ë\nT Î»\ng(Î»i -i + j)1â¤i, jâ¤n.\nThen, for Î» fixed and n âinf, and g = ef as in (4.7)\ninf\nT Î»\nn (g)/Tn(g) â¼ 1\nx Î»(Ï)\n(kfË(k))Î³n (Ï).\nm!\nk=1\nÏâSm\n\nP\nP\nX\nX\nX\nP\nP\n\n!\nY p\np\nR\nPERSI DIACONIS\nHere the sum is over the symmetric group Sm, xÎ»(Ï) is the irreducible character\nassociated to Î», and Î³n(Ï) is the number of cycles of length k in Ï. The minor\nT Î»\nn (g) is obtained from the original Toeplitz matrix by striking the first Î»1 columns,\nkeeping the first row but striking the next Î»1 - Î»2 rows, keeping the next row and\nso on. For example, when Î» = (1) the minor is obtained by striking the first column\nand the second row, and the right side is fË(1). It seems strange that characters\nappear. See [20] for extensions.\nA third benefit of the present approach: it offers some explanation for the form\ninf\nkfË(k)fË(-k) in the Szeg o corrections. The k appears because var (M k) = k.\nk=1\nI do not want to leave this area without pointing to a beautiful related devel\nopment due to Estelle Basor. She has derived the limit theory for the spectrum of\na variety of operators of Hankel, Toeplitz and mixed-type in sweeping generality.\nHer results are paired with Gaussian limit theorems of the same flavor as those of\nthis section. A readable survey with extensive references is in [10], [11].\nI do not feel we understand the parallel between (4.6) and (4.7). The determinant\nidentity seems like a magic trick!\n5. A general approach\nA general approach to studying unitary eigenvalues has gradually been devel\noped. This begins in joint work with Mallows [29] and Shahshahani [32]. The\npresent refined account was developed with Steve Evans [33].\nFor Mn â Un with eigenvalues {eiÎ¸j }, let În be the measure on the unit circle\nT which puts mass one at each eigenvalue. We may study În via linear, quadratic,\nfËj eijÎ¸\n. . . , functionals. Thus if f : T\nC has Fourier expansion f(eiÎ¸ ) =\nâ\njâZ\nn\n(5.1)\nÎn(f) =\nf(e iÎ¸j ) = nfË0 +\ninf\nfËj Tr(M j\nn).\nn) +\ninf\nfË-j Tr(M j\nj=1\nj=1\nj=1\nThe key to studying such functionals is an explicit formula for the joint mixed\nmoments of the traces. It was proved in joint work with Evans and Shahshahani.\nProposition. (a) Consider a = (a1, . . . , ak) and b = (b1, . . . , bk) with aj , bj â\n{0, 1, 2, . . .}. Let Z1, Z2, . . . , Zn be independent standard complex normal random\nvariables.\nk\nk\nThen, for n â¥ max (\njaj ,\njbj )\nZ\nk\nY\nk\nn)aj (TrM j bj\nY\n(trM j\nn) dMn = Î´ab\njaj aj !\nUn j=1\nj=1\nk\n= E\n( jZj )aj ( jZ j )bj .\nj=1\nn) Tr(M k\n(b) For any j, k,\nTr(M j\nn )dMn = Î´jk min (j, k).\nThe proof of this proposition is basic Schur-Weyl duality. First, introduce\nthe power sum symmetric functions Pj (x1, . . . , xn) = xj + . . . + xj and for Î¼ a\nn\nQ\naj\npartition of some integer K with ai parts equal to i, let PÎ¼ =\nj Pj .\nSince\n\nTrM j = Pj (eiÎ¸1 , . . . , eiÎ¸n ), the left side in (a) is < PÎ¼, PÎ½ > for the inner product\nn\n\nX\n*\n+\nX\nX\nY\nY\nZ\nX\nP\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\ngiven by integration over Un. The power sums form a basis for the homogeneous\nsymmetric polynomials of degree K in x1, . . . , xn. A second basis is given by the\nSchur functions sÎ». All needed properties are in MacDonald [65] or Stanley [89].\nThe two key properties for present purposes are:\n(5.2) Orthogonality: hsÎ», sÏ i = Î´Î»Ï Î´`(Î»)â¤n for any partitions Î», Ï with `(Î») the\nnumber of parts in Î».\n(5.3) Schur-Weyl Duality: For any partition Î¼ of K,\nPÎ¼ =\nÏÎ» sÎ»\nÎ¼\nÎ»`K\nwhere the sum is over partitions of K, and ÏÎ» is the irreducible character of the\nÎ¼\nsymmetric group SK associated with Î» on the Î¼th conjugacy class.\nUsing these formulae we simply compute: If Î¼ is a partition of K and Î½ is a\npartition of L,\nÏÏ\nhPÎ¼, PÎ½ i =\nÏÎ» sÎ»,\nr sÏ\nÎ¼\nÏ `L\nX\nÎ»`K\nÎ¼\nÏ Î´(`(Î») â¤ n).\n= Î´KL\nÏÎ»ÏÎ»\nÎ»`K\nWhen K â¤ n, all partitions of K appear and the second orthogonality relation\nfor characters shows our expression equals\nK\nÎ´KLÎ´Î¼Î½\njaj aj ! = Î´ab\njaj aj !\nj=1\nThis last equals the joint mixed moments of âjZj by an easy calculation. This\nproves (a). To prove (b), observe that the calculation above gives, for any j, k,\nn)Tr(M k\nTr(M j\nn )dMn = Î´jn\n|ÏÎ»\n(j)|2Î´(`(Î») â¤ n).\nÎ»`j\nHere ÏÎ» is the character of a j-cycle. These are explicitly known. They are zero\n(j)\nunless Î» is a hook shape and (-1)`(Î»)-1 if Î» is a hook shape. Now (b) follows.\nThe proposition shows that Tr(M j\nn) behaves asymptotically like âjZj , and one\ncan then plug into Fourier series expansions. My work with Evans exploits this\ncarefully for a variety of functionals. Of course, care is needed in bounding the tail\nof these sums and that is where (b) comes in.\nHere is one carefully stated example:\nfËj\ndenote the space of functions f in L2(T ) such that k f k2\n2 =\nLet H\nj| <\n| | |\njâZ\n2 ; H\nzj\nFor example, f(z) =\nis precisely the functions such that\nâ H\ninf.\nP Ëf(n)ânZn converges almost surely, where Zn\nplex Gaussian variables.\nare independent, standard, com\n2 with fËi(0) = 0, 1 â¤ i â¤ k, then the random\njointly normal, centered\nProposition. If f1, f2, . . . , fk â H\nvector (În(f1), . . . , În(fk)) converges in distribution to a\nrandom vector (V1, V2, . . . , Vk) with E(VaVb) =< fa, fb > 1\n2 .\n\nP\nP\nX p\nPERSI DIACONIS\nThis proposition shows there is a limiting Gaussian field indexed by H\n2 naturally\nassociated with unitary eigenvalues. As discussed in Diaconis-Evans [33], [35], the\nHilbert space H\n2 of \" 1 differentiable functions\" or functions of \"finite energy\"\nappears in many contexts, and it is natural to seek an explanation for its appearance\nhere. This is lacking at present.\nLet PMn (Z) = det(Mn - Iz) be the characteristic polynomial of Mn â Un. Then\nn\nP 0\n/PMn =\n(z - eiÎ¸j )-1 =\ninf\nTr(M j\nn)zj . From the proposition, this random\nMn\nj=1\nj=1\npower series converges in distribution to the random analytic function\ninf\nG(z) =\njZj zj\n|z| < 1\nj=1\nwhere the Zj are independent, standard Gaussian random variables. With a bit\nmore work, one can check that this convergence occurs in the space of continuous\nC-valued functions on {z â C : z < 1} in the topology of uniform convergence on\n| |\ncompacts.\nRandom analytic functions like G have been intensely studied, and one can show\nthat G takes all values in C infinitely, often with probability one. More precise\nstatements are in [33]. Figure 8 shows a plot of the size of P 0\n/PMn for a single\nMn\nrandom choice of Mn when n = 100. The zeros show up as the tree-like shape, and\nthe original eigenvalues show up as the crosses on the unit circle. Figure 9 shows\na similar plot of G(z). Similar tree-like shapes appear when the plots are based on\nthe zeta zeros as explained in Section Three.\nThis section shows how functions of the eigenvalues can be studied using traces.\nThe method works for non-smooth functions such as the number of eigenvalues in\nan interval and for functions of several eigenvalues.\nThere are other approaches available as well. Soshnikov [86] gives a determinen\ntal expression for the Laplace transform of a linear statistic and uses it to derive\nGaussian limits such as the proposition above. Hughes and Rudnick [54] use Sosh-\nnikov's method to derive non-Gaussian limit theorems for the number of eigenvalues\nin intervals of length 1/n.\nAdler and Van Moerbeke [1], [2], [3] have studied the eigenvalues by studying the\njoint Laplace transform of the traces of all powers. They show the transform satisfies\na hierarchy of non-linear equations with Virasoro constraints, similar to the well-\nstudied Toda lattice. This puts them into the well-studied territory of integrable\nsystems, and some of the remarkable tools developed there can be used to get novel\nasymptotics and even simple recursions for quantities, like the distribution of the\nlength of the longest increasing sequence in a random permutation.\nThe eigenvalues can also be studied by looking at the joint distribution of the\ncoefficients of the characteristic polynomial. This is instituted in Haake [49]. Of\ncourse, the coefficients are just the elementary symmetric functions in the eigen\nvalues, and the traces are the power sum symmetric functions. Change of basis\nformulae between these two sets of symmetric functions give some information. For\nexample, Alex Gamburd and I have shown that the kth moment of the jth coeffi\ncient equals the number of k Ã k \"magic squares\" with all row and column sums\nequal to j. Nonetheless, the coefficients of the characteristic polynomial are less\ntractable than the traces - the limiting distribution of e.g., the middle coefficient,\nis not known at this writing.\n\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nFigure 8. A realization of P 0\n/PMn for Mn drawn from Haar on\nMn\nUn and n = 100 is depicted here. The grayscale indicates the tanh\nof the absolute value of real part of this function.\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nFigure 9. A realization of the random analytic function G(z)\n(truncated to 1000 terms) is depicted here. The grayscale indicates\nthe tanh of the absolute value of real part of this function.\n\n-\n\nPERSI DIACONIS\n6. Some topics not covered\nI want to point readers to three rich, related areas. The first \"enumeration\" sets\nthe present topic in a much broader context: study a group through understanding\nwhat \"typical elements\" look like. The second \"free probability\" is a growing set of\ntools to answer questions like: \"Suppose you know the eigenvalues of each of two\nsymmetric matrices. For typical matrices, what can you say about the eigenvalues\nof their sum?\" The third topic describes a different application of random matrix\ntheory to de Finetti's theorem in statistics and the equivalence of ensembles. To\nkeep with the title of this section, the treatment is brief.\n6.1. Enumeration. One way of understanding a group is to ask about the prop\nerties of typical elements. For the symmetric group Sn this is actively developed\nas the subject of permutation enumeration. Thus consider the following questions:\nPick w â Sn at random:\n- How many fixed points does w have?\n- How many cycles?\n- What is the length of the longest cycle?\nWhat is the order of w (smallest k so wk = 1)?\n-\nAll of these questions only depend on w through its conjugacy class - they\nare invariant under irrelevant relabeling. The results are given in terms of the\nproportions of permutations:\n- P {FP (w) = j} = 1 1 + O 2n\nMonmort (1708)\n\ne j!\nn!\nP\n# cycles-(log n) â¤ x\nR x e-t2/2\ndt\n-\nâlog n\nâ -inf\nâ\n2Ï\nGoncharov (1942)\n.\nAV length of longest cycle is cn with c = .624...\nShepp-Lloyd (1966)\nlog order(w)-(log n)2/2\nP\nâ¤ x\nR x\n2/2 dt\nErd os-Turan (1965)\n-\n((log n)/3) 2\nâ -inf e-t\nâ\n2Ï\nThese theorems give a good feel for the behavior of typical permutations. Related\nquestions also arise in practical statistical problems [28] and in the analysis of the\nrunning time of computer algorithms. The results on the length of the longest cycle\nexplain the fluctuations in the density of Figure 3 above.\nAs an abstraction, let G be a finite or compact group. Pick g â G from the\nuniform distribution. One may ask for the limiting distribution of the conjugacy\nclass containing g. All of the problems discussed in the bulk of this paper are of\nthis type. Indeed, two unitary matrices are conjugate if and only if they have the\nsame eigenvalues. Of course, put this bald way, the question seems strange. It is\nan empirical fact that the general question seems to lead to elegant mathematics\nwhich has surprisingly useful consequences. A marvelous survey, making just these\npoints and verifying them on finite groups of Lie type, is given in Fulman [43].\nWith all this evidence, what are you waiting for? Go get a group you'd like to\nlearn about and try a simple case.\n6.2. Eigenvalues of typical conjugates. How are the eigenvalues of a sum of\nsymmetric matrices related to the eigenvalues of the summands? Of course, the\ntraces add up, and an amazing host of further inequalities are satisfied. The exact\ndetermination of these inequalities is a great achievement of modern mathematics.\nFulton [44] gives an inspiring account. These theorems give extreme or worst case\nbounds.\n\nZ\nZ\nR\nR\nZ\nZ\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\nThe calculus of free probability may be presented as the typical case answer.\nThus let Î£1, Î£2 be real symmetric matrices with eigenvalues {Î»1\n0 , . . . , Î»0\nn},\n1 , . . . , Î»00\n{Î»00\nn}. Conjugate Î£1 and Î£2 by randomly chosen orthogonal matrices. The\neigenvalues of the sum will now be random, and their distribution can be described\nvia the free convolution of Î»0 and Î»00. Here is a specific example drawn from the\nsplendid introduction of Biane [13]. Let n = 2m be even. Choose an m-dimensional\nsubspace at random (uniformly) and let Î£1 be the matrix for projection onto this\nsubspace. Thus, Î£1 has m zero eigenvalues and m eigenvalues equal to one. Let\nÎ£2 be independently formed in a similar way. How are the eigenvalues of Î£1 + Î£2\ndistributed? Free probability shows that for large n,\nx\n# e.v.(Î£1 + Î£2)\nP\nn\nâ¤ x â\n0 Ï\np\nt(1 -t)\ndt.\nThis striking result is the tip of a remarkable set of results and tools which are\nrapidly becoming a major area of probability and functional analysis.\nFree probability was created by Dan Voiculescu to answer questions in Von Neu\nmann algebras. It is not known if the Von Neumann algebras associated to the free\ngroups on 2-generators and on 3-generators are isomorphic. Voiculescu hoped to in\ntroduce an entropy-like invariant to distinguish these cases. Voiculescu's summary\n[95] is replete with many pointers to the huge emerging literature.\n6.3. Beyond eigenvalues. The eigenvalues capture the coordinate-free aspects of\na matrix. A different set of properties is captured by the actual matrix entries.\nConsider the following result:\nTheorem (E. Borel). Pick Î from the uniform distribution on the orthogonal group\nOn. Then\nP {ân Î11 â¤ x} â\nx\ne-t /2dt.\n-inf\nBorel [15] proved the result in studying \"Equivalence of Ensembles\" in statistical\nmechanics. There, the \"microcanonical distribution\" is a suitable uniform distri\nbution U(dx) on the constant energy surface {x â RN : H(x) = hâ}. One can\npredict properties by calculating averages as\nf(x)U(dx). Maxwell, Boltzmann\nand Gibbs also considered a canonical measure UÎ²(dx) = Z-1e-Î²H(x)dx on RN\nwith Î² chosen so\nH(x)UÎ²(dx) = hâ. The equivalence of ensembles asserts that\n(under conditions)\nf(x) U(dx) '\nf(x) UÎ²(dx),\nwhen N is large. Borel took the simplest case: H(x) = x +\n+ xN . Then the\nÂ· Â· Â·\nmicrocanonical measure becomes uniform on the sphere, and the canonical measure\nbecomes product Gauss measure. Taking f to be a continuous function depending\nonly on x1 and using the fact that the first row of a random orthogonal matrix\nis Haar-distributed show that the stated theorem on matrices gives a version of\nequivalence of ensembles.\nBorel himself, followed by Paul Levy and others, extended the result to functions\ndepending on many coordinates. In joint work with D'Aristotle, Eaton, Freedman,\nLauritzan and Newman, this result has been extended and applied to give a va\nriety of results in mathematical statistics [7], [36], [37]. The results show that in\n\nPERSI DIACONIS\na suitable sense, the entries {ân Îi,j } are jointly distributed as independent stan\ndard Gaussian variables. While this is true in a suitable sense (arbitrary linear\ncombinations), it is not true for the eigenvalues. The eigenvalues of Î â On lie\non the unit circle. The eigenvalues of a matrix of independent Gaussian variables\nfill out the disc with radius ân uniformly, with order ân on the real axis [8], [41].\nDetermining the right class of functions for equivalence of ensembles is still an open\nproblem.\nThe behavior of the matrix entries under conjugation by a random unitary matrix\nhas been studied by Pickrell [78], Olshansky-Vershik [77], and Borodin-Olshansky\n[16]. Their interest is in the representation theory of the injective limit U(inf).\nResults are often proved by passage to the limit from U(n). Their elegant results\nare too rich to state completely, but for a broad class of examples, the resulting\nconjugation is approximately a constant times the identity when the dimension is\nlarge.\n6.4. Topics really not covered. The present paper is based on my Gibbs Lecture\nbut incorporates a few recent developments. The field of random matrix theory has\nhad an explosive growth. Much of this has been on the distribution of the largest\neigenvalue of random symmetric or Hermitian matrices. There have been many\nfine surveys. The work of Baik-Deift-Johansson on an integrable systems approach\nto largest eigenvalues and the longest increasing subsequence of a random permu\ntation is surveyed in [27]. The work of Tracy-Widom on a wide variety of random\nmatrix results and applications using Painlev e transcendents is surveyed in [90],\n[91] and [92], [93]. The work of Adler-Van Moerbeke linking random matrices to\nVirasoro algebras and much else is surveyed in [3]. For work of Okounkov, con\nnecting random matrices and random permutations through Riemann surfaces, see\n[75]. A wonderful connection between classical queuing theory, tableaux combina\ntorics and random matrix theory has been developed by Bougerol-Jeulin [18] and\nby O'Connell-Yor [74]. I have not really touched on the physical applications of\nrandom matrix theory, though Mehta [68] and Bohigas et al. [14] give extensive\npointers. Similarly, I lament not describing the many interactions with algebraic\ncombinatorics. See [4], [43], [51]. Many of the results stated here for unitary matri\nces are \"universal\", applying to many other matrix ensembles (just as the central\nlimit theorem): see Tracy-Widom [93] for an overview of the many great results. I\nhave focused on eigenvalues of unitary or Hermitian matrices. There are remark\nable probabilistic theorems for non-Hermitian matrices. See [8] and [45], [46] for\npointers.\nI hope I have given a picture of a thriving zoo with a wealth of novel findings\nthat touch many areas of pure and applied mathematics.\nReferences\n[1] Adler, M.; Van Moerbeke, P., Integrals over Classical Groups, Random Permutations, Toda\nand Toeplitz Lattices. Comm. Pure Appl. Math. 2001, 54, 153-205.\n[2] Adler, M.; Van Moerbeke, P., Recursion Relations for Unitary Integrals, Combinatorics and\nthe Toeplitz Lattice. Technical Report, Dept. of Mathematics, Brandeis, 2002.\n[3] Adler, M.; Shiota, T.; Van Moerbeke, P., Random Matrices, Virasoro Algebras, and Non-\nCommutative KP. Duke Math. J. 1998, 94, 379-431. MR 99e:58088\n[4] Aldous, D.; Diaconis, P., Longest Increasing Subsequences: From Patience Sorting to the\nBaik-Deift-Johansson Theorem. Bull. Amer. Math. Soc. 1999, 36, 413-432. MR 2000g:60013\n\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\n[5] Anderson, T., Asymptotic Theory for Principal Component Analysis. Ann. Math. Statist.\n1963, 34, 122-148. MR 26:3149\n[6] d'Aristotle, A., An Invariance Principle for Triangular Arrays. Jour. Theoret. Probab. 2000,\n13, 327-342.\n[7] d'Aristotle, A.; Diaconis, P; Newman, C., Brownian Motion and the Classical Groups. Tech\nnical Report, Stanford University, 2002.\n[8] Bai, Z., Methodologies in Spectral Analysis of Large Dimensional Random Matrices: A Re\nview. Statistica Sinica 1999, 9, 611-677. MR 2000e:60044\n[9] Baik, J.; Deift, P.; Johansson, K., On the Distribution of the Length of the Longest Increasing\nSubsequence of Random Permutations. Jour. Amer. Math. Soc. 1999, 12, 1119-1178. MR\n2000e:05006\n[10] Basor, E., Distribution Functions for Random Variables for Ensembles of Positive Hermitian\nMatrices. Comm. Math. Phys. 1997, 188, 327-350. MR 99b:82046\n[11] Basor, E., Connections Between Random Matrices and Szeg o Limit Theorem. In Spectral\nProblems in Geometry and Arithmetic; Branson, T., Ed.; Amer. Math. Soc.: Providence, RI,\n1999; 1-7. MR 2000e:47049\n[12] Berry, M.; Keating, J., The Riemann Zeros and Eigenvalue Asymptotics. Siam Review 1999,\n41, 236-266. MR 2000f:11107\n[13] Biane, P., Free Probability for Probabilists, 2000, preprint.\n[14] Bohigas, O.; Giannoni, M., Chaotic Motion and Random Matrix Theories. In Mathematical\nand Computational Methods in Nuclear Physics; Dehesa, J.L., Ed.; Springer Lecture Notes\nin Physics, 1984, 209, 1-99. MR 86c:58129\n[15] Borel, E., Sur les Principes de la Theorie Cinetique des Gaz. Annales, L'Ecole Normal Sup.\n1906, 23, 9-32.\n[16] Borodin, A.; Olshansky, G., Correlation Kernels Arising from the Infinite-Dimensional Uni\ntary Group and Its Representations. University of Pennsylvania, Department of Mathematics,\n2001, preprint.\n[17] B ottcher, A. and Silbermann, B., Introduction to Large Truncated Toeplitz Matrices.\nSpringer-Verlag: New York, 1999. MR 2001b:47043\n[18] Bougerol, Ph. and Jeulin, Th., Paths in Weyl Chambers and Random Matrices. Laboratoire\nde Probabilities: Paris 2001, preprint.\n[19] Boutet de Monvel, A.; Pastur, L.; Shcherbina, M., On the Statistical Mechanics Approach\nin the Random Matrix Theory: Integrated Density of States. Jour. Statist. Phys. 1995, 79,\n585-611. MR 96d:82033\n[20] Bump, D. and Diaconis, P., Toeplitz Minors. Jour. Combin. Th. A. 2002, 97, 252-271. MR\n2002j:47052\n[21] Bump, D.; Diaconis, P.; Keller, J., Unitary Correlations and the Fejer Kernel. Mathematical\nPhys., Analysis, Geometry 2002, 5, 101-123.\n[22] Conrey, B., L-Functions and Random Matrices. In Mathematics Unlimited 2001 and Beyond;\nEnquist, B., Schmid, W. Eds.; Springer-Verlag: Berlin, 2001; 331-352.\n[23] Conrey, B.; Farmer, D.; Keating, J.; Rubinstein, M.; Snaith, W., Correlation of Random\nMatrix Polynomials. Technical Report, American Institute of Mathematics, 2002.\n[24] Coram, M.; Diaconis, P., New Tests of the Correspondence Between Unitary Eigenvalues and\nthe Zeros of Riemann's Zeta Function. Jour. Phys. A. 2002, to appear.\n[25] Daley, D.; Verre-Jones, D., An Introduction to the Theory of Point Processes. Springer-Verlag:\nNew York, 1988. MR 90e:60060\n[26] Deift, P., Orthogonal Polynomials and Random Matrices: A Riemann-Hilbert Approach.\nCourant Lecture Notes #3, NYU/Courant Institute: New York, and Amer. Math. Soc.:\nProvidence, RI, 1999. MR 2000g:47048\n[27] Deift, P., Integrable Systems and Combinatorial Theory. Notices, Amer. Math. Soc. 2000,\n47, 631-640. MR 2001g:05012\n[28] Diaconis, P., Group Representations in Probability and Statistics. Ins. Math. Statist., Hay\nward, CA, 1986. MR 90a:60001\n[29] Diaconis, P., Applications of the Method of Moments in Probability and Statistics. In Mo\nments in Mathematics; Landau, H., Ed.; Amer. Math. Soc.: Providence, RI, 1987; 125-142.\nMR 89m:60006\n[30] Diaconis, P.; Shahshahani, M., Products of Random Matrices as They Arise in the Study of\nRandom Walks on Groups. Contemp. Math. 1986, 50, 183-195. MR 87k:60025\n\nPERSI DIACONIS\n[31] Diaconis, P.; Shahshahani, M., The Subgroup Algorithm for Generating Uniform Random\nVariables. Prob. Eng. and Info. Sci. 1987, 1, 15-32.\n[32] Diaconis, P.; Shahshahani, M., On the Eigenvalues of Random Matrices. In Studies in Ap\nplied Probablility; Gani, J., Ed.; Jour. Appl. Probab.: Special Vol. 31A, 1994; 49-62. MR\n95m:60011\n[33] Diaconis, P.; Evans, S., Linear Functionals of Eigenvalues of Random Matrices. Transactions\nAmer. Math. Soc. 2001, 353, 2615-2633. MR 2002d:60003\n[34] Diaconis, P.; Evans, S., Immanants and Finite Point Processes. Jour. Combin. Th. A. 2000,\n91, 305-321. MR 2001m:15018\n[35] Diaconis, P.; Evans, S., A Different Construction of Gaussian Fields from Markov Chains:\nDirichlet Covariances. Ann. Inst. Henri Poincar e, 2002, to appear.\n[36] Diaconis, P.; Freedman, D., A Dozen deFinetti-Style Results in Search of a Theory. Ann.\nInst. Henri Poincar e, 1987, 23, 397-423. MR 88f:60072\n[37] Diaconis, P.; Eaton, M.; Lauritzan, S., Finite deFinetti Theorems in Linear Models and\nMultivariate Analysis. Scand. Jour. Statist. 1992, 19, 289-315. MR 94g:60065\n[38] Dyson, F., Statistical Theory of the Energy Levels of Complex Systems, I, II, III. J. Math.\nPhys. 1962, 3, 140-156, 157-165, 166-175. MR 26:1111, MR 26:1112, MR 26:1113\n[39] Dyson, F., Correlations Between Eigenvalues of a Random Matrix. Comm. Math. Phys. 1970,\n19, 235-250. MR 43:4398\n[40] Eaton, M., Multivariate Statistics; Wiley: New York, 1983. MR 86i:62086\n[41] Edelman, A.; Kostlan, E.; Shub, M., How Many Eigenvalues of a Random Matrix Are Real?\nJour. Amer. Math. Soc. 1994, 7, 297-267. MR 94f:60053\n[42] Forrester, P.; Rains, E., Inter-Relationships Between Orthogonal, Unitary and Symplectic\nMatrix Ensembles. MSRI Publications 2001, 40, 171-207. MR 2002h:82008\n[43] Fulman, J., Random Matrix Theory Over Finite Fields. Bull. Amer. Math. Soc. 2002, 39,\n51-86. MR 2002i:60012\n[44] Fulton, W., Eigenvalues, Invariant Factors, Highest Weights and Schubert Calculus. Bull.\nAmer. Math. Soc. 2000, 37, 209-249. MR 2001g:15023\n[45] Fyodorov, Y.; Khoruzhenko, B.; Sommers, H., Universality in the Random Matrix Spectra in\nthe Regime of Weak Non-Hermiticity. Ann. Inst. Henri Poincar\neorique 1998,\ne: Physique Th\n68, 440-489. MR 99i:60080\n[46] Goldsheid, I.; Khoruzhenko, B., Eigenvalue Curves of Asymmetric Tri-Diagonal Random\nMatrices. Electronic Jour. Probab. 2000, 5, Paper 16. MR 2002j:82061\n[47] Goodman, R.; Wallach, W., Representations and Invariants of the Classical Groups. Cam-\nbridge Press: Cambridge, 1998. MR 99b:20073\n[48] Grenander, U.; Szeg o, G., Toeplitz Forms and Their Applications. University of California\nPress: Berkeley, 1958. MR 20:1349\n[49] Haake, F., Secular Determinants of Random Unitary Matrices. Jour. Pys. A. 1996, 29, 3641-\n3658. MR 97g:82002\n[50] Haake, F., Quantum Signatures of Chaos, 2nd Ed.; Springer-Verlag: Berlin, 2001.\n[51] Hanlon, P.; Stanley, R.; Stembridge, J., Some Combinatorial Aspects of the Spectra of Nor\nmally Distributed Random Matrices. Contemp. Math. 1992, 138, 151-174. MR 93j:05164\n[52] Hirschman, I., The Strong Szeg o Limit Theorem for Toeplitz Determinants. Amer. Jour.\nMath. 1966, 88, 577-614. MR 35:2064\n[53] Hughes, C.; Keating, J.; O'Connell, W., On the Characteristic Polynomial of a Random\nUnitary Matrix. Comm. Math. Phys. 2001, 220, 429-451. MR 2002m:82028\n[54] Hughes, C.; Rudnick, Z., Mock-Gaussian Behavior for Linear Statistics of Classical Compact\nGroups. Department of Mathematics, Tel Aviv University, 2002, preprint.\n[55] Johansson, K., On Szeg o's Asymptotic Formula for Toeplitz Determinants and Generaliza\ntions. Bull. Sc. Math. 1988, 112, 257-304. MR 89m:47021\n[56] Johansson, K., On Random Matrices from the Compact Classical Groups. Ann. Math. 1997,\n145, 519-545. MR 98e:60016\n[57] Johansson, K., The Longest Increasing Subsequence in a Random Permutation and a Unitary\nRandom Matrix Model. Math. Res. Lett. 1998, 5, 63-82. MR 99e:60033\n[58] Johnstone, I., On the Distribution of the Largest Eigenvalue in Principal Component Analysis.\nAnn. Statist. 2001, 29, 295-327. MR 2002i:62115\n[59] Katz, N.; Sarnak, P., Random Matrices, Frobenius Eigenvalues, and Monodromy. Amer.\nMath. Soc.: Providence, RI, 1999. MR 2000b:11070\n\nPATTERNS IN EIGENVALUES: THE 70TH JOSIAH WILLARD GIBBS LECTURE\n[60] Keating, J.; Snaith, N., Random Matrix Theory and Î¾( 1 + it). Commun. Math. Phys. 2000,\n214, 57-89. MR 2002c:11107\n. Commun. Math.\nPhys. 2000, 214, 91-110. MR 2002c:11108\n[61] Keating, J.; Snaith, N., Random Matrix Theory and L-Functions at s = 2\n[62] Kiessling, M.; Spohn, H., A Note on the Eigenvalue Density of Random Matrices. Comm.\nMath. Phys. 1999, 199, 638-695. MR 2000a:82031\n[63] Macchi, O., Stochastic Processes and Multicoincidences. IEEE Transactions 1971, 17, 1-7.\n[64] Macchi, O., The Coincidence Approach to Stochastic Point Processes. Adv. Appl. Probab.\n1975, 7, 83-122. MR 52:1876\n[65] MacDonald, I., Symmetric Functions and Hall Polynomials, 2nd Ed.; Clarendon Press: Ox\nford, 1995. MR 96h:05207\n[66] Marchenko, V.; Pastur, L., Distribution of Some Sets of Random Matrices. Mat. Sb. 1967,\n1, 507-536.\n[67] Mardia, K.; Kent, J.; Bibby, J., Multivariate Analysis. Academic Press: New York, 1979.\nMR 81h:62003\n[68] Mehta, M., Random Matrices, 2nd Ed.; Acad. Press: New York, 1991. MR 92f:82002\n[69] Mezzadri, F., Random Matrix Theory and the Zeros of Î¾0(s). Dept. of Mathematics, Univer\nsity of Bristol, 2002, preprint.\n[70] Muirhead, R., Latent Roots and Matrix Variates: A Review of Some Aymptotic Results.\nAnn. Statist. 1978, 6, 5-33. MR 56:16919\n[71] Odlyzko, A., On the Distribution of Spacings Between Zeros of the Zeta Function. Math.\nComp. 1987, 48, 273-308. MR 88d:11082\n[72] Odlyzko, A., The 1020-th Zero of the Riemann Zeta Function and 175 Million of Its Neighbors.\nATT Laboratories, 1992, preprint.\n[73] O'Connell, N., Random Matrices, Non-Colliding Processes and Queues. Laboratoire de Prob\nabilites, Paris 6, 2002, preprint.\n[74] O'Connell, N.; Yor, M., Brownian Analogues of Burke's Theorem. Stoch. Proc. Appl. 2001,\n96, 285-304. MR 2002h:60175\n[75] Okounkov, A., Random Matrices and Random Permutations. Math. Res. Notices 2000, 20,\n1043-1095. MR 2002c:15045\n[76] Olshansky, G., An Introduction to Harmonic Analysis on the Infinite-Dimensional Unitary\nGroup. University of Pennsylvania, Dept. of Mathematics, 2001, preprint.\n[77] Olshanski, G.; Vershik, A., Ergodic Unitarily Invariant Measures on the Space of Infinite\nHermitian Matrices. In Contemporary Mathematical Physics; Amer. Soc. Transl. Ser. 2, 1996,\n175, 137-175. MR 98e:28015\n[78] Pickrell, D., Mackey Analysis of Infinite Classical Motion Groups. Pacific Jour. 1991, 150,\n139-166. MR 92g:22041\n[79] Porod, U., The Cut-Off Phenomenon for Random Reflections. Ann. Probab. 1996, 24, 74-96.\nMR 97e:60012\n[80] Rains, E., High Powers of Random Elements of Compact Lie Groups. Probab. Th. Related\nFields 107, 219-241. MR 98b:15026\n[81] Rains, E., Images of Eigenvalue Distributions Under Power Maps. ATT Laboratories, 1999,\npreprint.\n[82] Rains, E., Probability Theory on Compact Classical Groups., Harvard University: Depart\nment of Mathematics, 1991, Ph.D. thesis.\n[83] Rosenthal, J., Random Rotations, Characters and Random Walks on SO(N). Ann Probab.\n1994, 22, 398-423. MR 95c:60008\n[84] Sinai, Y.; Soshnikov, A., Central Limit Theorem for Traces of Large Random Symmetric\nMatrices with Independent Matrix Elements. Bol. Soc. Brasil. Mat. (N.S.) 1998, 29, 1-24.\nMR 99f:60053\n[85] Sloane, N., Encrypting by Random Rotations. Technical Memorandum, Bell Laboratories,\n1983.\n[86] Soshnikov, A., The Central Limit Theorem for Local Linear Statistics in Classical Com\npact Groups and Related Combinatorial Identities. Ann. Probab. 2000, 28, 1353-1370. MR\n2002f:15035\n[87] Soshnikov, A., Level Spacings Distribution for Large Random Matrices: Gaussian Fluctua\ntions. Ann. Math. 1998, 148, 573-617. MR 2000f:15014\n\nPERSI DIACONIS\n[88] Soshnikov, A., Determinantal Random Point Fields. Russian Math. Surveys 2000, 55, 923-\n975. MR 2002f:60097\n[89] Stanley, R., Enumerative Combinatorics. Vol. 2 ; Cambridge University Press: Cambridge,\n1999. MR 2000k:05026\n[90] Tracy, C.; Widom, H., Introduction to Random Matrices. In Geometric and Quantum Aspects\nof Integrable Systems; Springer-Verlag: Berlin, 1993, 103-130. MR 95a:82050\n[91] Tracy, C.; Widom, H., Random Unitary Matrices, Permutations and Painlev e. Comm. Math.\nPhysics 1999, 207, 665-685. MR 2001h:15019\n[92] Tracy, C.; Widom, H., On the Relations Between Orthogonal, Symplectic and Unitary En\nsembles. Jour. Statist. Phys. 1999, 94, 347-363.\n[93] Tracy, C.; Widom, H., Universality of the Distribution Functions of Random Matrix Theory.\nCRM Proceedings 2000, 26, 251-264. MR 2002f:15036\n[94] Tracy, C.; Widom, H., On the Limit of Some Toeplitz-Like Determinants. SIAM J. Matrix\nAnal. Appl. 2002, 23, 1194-1196.\n[95] Voiculescu, D., Lectures on Free Probability Theory. Springer Lecture Notes in Mathematics\n2000, 1738, 279-349. MR 2001g:46121\n[96] Wieand, K., Eigenvalue Distributions of Random Matrices in the Permutation Group and\nCompact Lie Groups, Harvard University: Department of Mathematics, 1998, Ph.D. thesis.\n[97] Wieand, K., Eigenvalue Distributions of Random Permutation Matrices. Ann. Probab. 2000,\n28, 1563-1587. MR 2002d:15027\nDepartment of Mathematics and Statistics, Stanford University, Stanford, CA 94305\nE-mail address: diaconis@math.stanford.edu"
    }
  ]
}