{
  "course_name": "Introduction to Statistical Methods in Economics",
  "course_description": "This course will provide a solid foundation in probability and statistics for economists and other social scientists. We will emphasize topics needed for further study of econometrics and provide basic preparation for 14.32 Econometrics. Topics include elements of probability theory, sampling theory, statistical estimation, and hypothesis testing.",
  "topics": [
    "Mathematics",
    "Probability and Statistics",
    "Social Science",
    "Economics",
    "Econometrics",
    "Mathematics",
    "Probability and Statistics",
    "Social Science",
    "Economics",
    "Econometrics"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hour / session\n\nDescription\n\nThis course will provide a solid foundation in probability and statistics for economists and other social scientists. We will emphasize topics needed for further study of econometrics and provide basic preparation for\n14.32 Econometrics\n. Topics include elements of probability theory, sampling theory, statistical estimation, and hypothesis testing.\n\nPrerequisites\n\nNo prior preparation in probability in statistics is required, but familiarity with basic algebra and calculus (single and multi-variable) is assumed. Calculus at the level of\n18.01 Single Variable Calculus\nand\n18.02 Multivariable Calculus\nis sufficient.\n\nTextbooks\n\nRequired\n\nLarsen, R., and M. Marx.\nIntroduction to Mathematical Statistics and Its Applications\n. 4th ed. Upper Saddle River, NJ: Pearson Prentice Hall, 2005. ISBN: 9780131867932.\n\nRecommended\n\nAlternatively, you may consider one of the following textbooks which are good, but somewhat more difficult:\n\nDeGroot, M., and M. Schervish.\nProbability and Statistics\n. 3rd ed. Reading, MA: Addison-Wesley, 2001. ISBN: 9780201524888.\n\nLindgren, B.\nStatistical Theory\n. 4th ed. New York, NY: Chapman and Hall, 1993. ISBN: 9780412041815.\n\nLindgren doesn't offer much intuition, but it's a nice reference.\n\nAdditional for Background\n\nIn addition, I'll now list a few well-written popular science books on probability and statistical topics - reading any of those is of course optional and won't help you much in terms of doing well on problem sets or exams, but it's always a good habit to get a wider perspective and develop less formal intuitions on any subject you are studying.\n\nEkeland, I.\nThe Broken Dice and Other Mathematical Tales of Chance\n. Chicago, IL: University of Chicago Press, 1996. ISBN: 9780226199924.\n\nHuff, D., and I. Geis.\nHow to Lie With Statistics\n. New York, NY: W.W. Norton, 1993. ISBN: 9780393310726.\n\nStigler, S.\nThe History of Statistics: The Measurement of Uncertainty before 1900\n. Cambridge, MA: Belknap Press of Harvard University Press, 1990. ISBN: 9780674403413.\n\n------.\nStatistics on the Table: The History of Statistical Concepts and Methods\n. Cambridge, MA: Harvard University Press, 2002. ISBN: 9780674009790.\n\nTaleb, N.\nFooled by Randomness: The Hidden Role of Chance in Life and in the Markets\n. 2nd ed. New York, NY: Random House, 2008. ISBN: 9781400067930.\n\nRequirements\n\nThe problem sets will typically be handed out on Tuesday and due the following Tuesday. You are expected to complete the problem sets on your own and without consulting old problem set solutions - it will clearly be in your interest to understand all of the material on them. If you fail to turn in more than two problem sets, you can't get a course grade better than D. The overall problem set score for the class will be calculated based on your seven best problem set grades, so you can miss out on one problem set without affecting your grade.\n\nThe exams are non-cumulative, with the first two offered in-class and the third offered during final exam week. The exams will be closed book unless otherwise indicated.\n\nRegular attendance at the recitation is strongly recommended, as the TA will discuss problem sets, clarify lecture material, and provide other useful guidance.\n\nCourse Policies\n\nProblem Sets\n\nProblem sets are designed to help you learn how to apply the material presented in lectures and recitations. You are permitted to discuss course material, including homework, with other students in the class. However, you must turn in your own individual solutions to each set of homework problems. Discussion with others is intended to clarify ideas, concepts, and technical questions, not to derive group homework set solutions. Identical homework set answers (especially when the steps used to derive answers are not shown or when questions of interpretation are involved) violate this policy and may receive no credit. Also, you are expected to complete the problem sets without consulting old problem set solutions.\n\nProblem Set Solutions\n\nHandwritten solutions are fine, as long as they are legible and neat. Please remember: if we can't read it, we can't grade it.\n\nLateness\n\nIn fairness to students who complete assignments on time, late homework sets will not be accepted. You may turn in assignments during the lecture on the day they are due. After the lecture, assignments may be placed in a designated box. Do not leave assignments in the instructors' offices or mailboxes. Because late homework will not be accepted you will be allowed to drop your lowest homework score. You can also e-mail your answers before the deadline, for alternative submissions you should ask the instructors for permission beforehand.\n\nExams\n\nTaking all three exams is a requirement of the course. Missing an exam without a valid excuse will result in a failing grade for the entire course.\n\nAbsences\n\nTo be considered valid, an excuse must be proffered prior to the exam that is to be missed, if at all possible, the excuse must be in writing, and it must be verifiable. These criteria are necessary but not sufficient, however. We reserve the right to deem an excuse meeting the above criteria invalid. Any medical excuse must be accompanied by a dated note from the MIT Medical Center. Regardless of the reason for missing the exam, you must get advanced clearance from the Dean of Student Support Services.\n\nMake-up Exams\n\nAn oral make-up exam will be given in the event of a valid excuse.\n\nRegrades\n\nAll requests for regrades must be submitted in writing within one week of the exam being handed back. The entire exam will be regraded; it is therefore possible that a regrade could result in a lower score.\n\nAcademic Integrity\n\nCheating or academic dishonesty in any form will not be tolerated and will result in swift punitive action. This includes but is not restricted to copying information from other students' exams, communicating with other students during exams, failing to follow the rules of the exams regarding notes, calculators, etc., altering an exam for the purpose of a regrade, and producing fraudulent written excuses. Any student found to have cheated or behaved unethically or dishonestly will be given a grade of F on the exam involved and referred to the appropriate disciplinary committees within MIT for further action.\n\nGrading\n\nACTIVITIES\n\nPERCENTAGES\n\nProblem sets\n\n25%\n\nExam 1\n\n25%\n\nExam 2\n\n25%\n\nExam 3\n\n25%",
  "files": [
    {
      "category": "Assignment",
      "title": "Problem Set #1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/456138af4f3daa310d641ccf82123714_MIT14_30s09_pset01.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n& '( )' *( +,\n\n- ' %.\n!\n\n/\n\n'\n%\n\n( .\n% 1 ' %. 0\n%\n(\n! 0\n\n' % 1\n\n%\n\n\" !\n\n' 1\n\n&0\n\n3!\n\n%\n\n% ' %'\n!\n( 1\n% 00 1\n!\n!\n( 1\n% 0\n\n!!\n\n!!5\n( 1\n% 00\n\n'\n36 014 0\n1 /\n!\n\n'\n3 0145\n\n/\n\n'(\n!\n\n%\n\n' /\n\n1 !\n\n, !\n\n1 !\n\n1 '\n\n!\n\n. , 3(+(64( 3((84( 3((4( 3+((4( 3+(+(84(\n3((4 '(\n1 3((84( 3((64( 3+(+(64(\n3+((84( 3+((4( 3((4 ( !\n!( , /\n\n0'(\n' 1\n\n( %/ 9\n/\n!: 0 ;%5\n4 ;% ' 0\n\n,5\n4 ;% ' 0\n\n4 ;% '\n\n5 <\n% 9:\n\n5 70\n\n+\n\n= !\n! !\n\n% '0\n\n' 0\n!\n\n% >\n\n3!0 1\n!4 =\n! % /\n?? ' @ = ' '\n>( !\n\n'( 0\n'( !(\n\n( 0\n\n3<.0\n\n0AA%.0!A%.A=B&!4\n4 &% = ! 1\n\n/\n\"( C( D\n\n0 0 00' 0\n\n/\n\n4 &% = ! 1\n\n/\n\"( C( D\n\n0 0 00' 0\n1 /\n%\n\n4 ' 3\n:\n\nE\n: F\n1 14\n% 0\n\n= ! 1\n1 /\n\"( C( D( &\n\n0 % ' 0\n\n1 /\n\n;% '\n' 7/ ! ! 5\n4 ;% '\n' 7/ ! ! %\n\n/\n\n& .' /\n\n1 !! G\"DD$$HH I\nGD\"$DH$H (I\n1 !! G\"\"C9$#I\n0 G\"$9C#\"5I 3+ 0\n\n$\n( '\n/\n\n9/\nJ\n1 0\n\n1 ! % 1 . 1 0'!\n\n0' + ! !\n' /\n' 1 %!(\n' 1 !(\n' 1\n'! 9\n<\n\n'\n\n? 5 36\n%( ( +\n\n- ' 1 F\n\n0 1 ?(\n\n'\n!\n1 1 C\n;\n\nC! -\n' 1\nJ\n\n'0 % 3\n\n4( ' ' ( 3\n. %4\n'\n!\n' / %\n\n3K%4(\n% . % %\n' 8 1\n' 3L4(\n\n% . % %\n' 1\nF\n3$4(\n% .\n% %\n' , 0\n'\n\n0 !/ '\n\nK%( L( $ ?( ( ( 0\n/' D0\n\n'\n\n' !!\n. % '\n\n4 C': 1 ' 0\n\n<\n% C': 1\n\n%\n)\n( 0 1 00\n\n4 00\n\n>/ 0\n1 +8 0\n1 %\n\" 0\n<\n\n'\n0 ! 5 \"\n\n2 1\n1 <\n%\n% ' 15\n4 00\n\n1 3 C4 1\nC(\n\n'>/ 0\n\n%\n0 GI 1\n/ C(\n'\n% 0\n\n% 0 )'(\n\n' C (\n'( >/ 0\nH\n\nM\n\n4 L\n.\n\n0 ( %\n\n'\n\n' / C5"
    },
    {
      "category": "Assignment",
      "title": "Problem Set #1 — Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/e3917773bf1588c4771c9411f7ba18c4_MIT14_30s09_sol_pset01.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #l - Solutions\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, February 17, 2009\nInstructions\nYou may work together to solve the problems but must each hand in independently-written solutions,\nso make sure to show all of your work. Each part of each question is worth 1point, although partial\ncredit may be rewarded for incorrect answers.\nQuestion 1\nA delegation of three is to be chosen from the untenured faculty of the MIT Economics Department\n(numbering ten) to represent the department in an Institute-wide committee. In how many ways\na) can the delegation be chosen?\nSolution to (a): Since there are 10 untenured faculty members, there are \"10 choose 3\"\n(y)=\n=\n= 120 different ways to choose the three faculty members. Further,\nif the three faculty members are selected to unique positions such as the President, Vice-\nPresident, and Secretary of the delegation, then there would be % = 10.9.8 = 720 total\nways since each of the 120 different combinations of faculty members can be mixed into\nthe 3 positions in 6 different ways.\nb) can it be chosen, if two people refuse to go together?\nSolution to (b): Since from part (a) we know that there are 120 different ways to selcted\namong the 10 untenured faculty members, we can approach this problem from at least\ntwo directions. We can either subtract out the combinations where the two odious faculty\nmembers have been included, or we can directly count the number of ways that we can\nhave at most one of the two who refuse.\nThe first way is simple. We compute 120 - #(Both are chosen to go together). In\norder to get them both, we first choose the two of them (this is a constraint on the\nproblem-we should try to satisfy these either first or last to avoid more complex counting\nissues). There is only one way to choose both of them in a combination sense (although\nwith permutations there are definitely 2 ways to pick them: you can pick one or the other\nfirst); this leaves us with 8 different ways to pick the remainder member of the committee.\nThus, we arrive at our answer of 120 - 8 = 112.\nIn order to demonstrate that the other method would give the same answer, let's first\ncount the number of ways to pick a group without having to deal with the two odious\nindividuals: (:)\n= $& =\n= 56. Now, recalling that there are two ways to pick\nan odious member, let's count the number of ways we can pick two additional faculty\nmembers: (i)= & =\n= 28. So, we arrive at our final count:\n#(at most 1odious member) = #(0 odious members) + 2 .#(1 odious member)\n= 56 +2.28 = 112.\nAs we hoped, both approaches gave the same answer.\n\nc) can it be chosen, if two particular members insist on either both going or neither going?\nSolution to (c): If two members insist on either both going or neither going, we have a\nsimilar problem as before, but we can compute it very simply from the numbers from\npart (b). The event A that we're interested in is A = {Bothgo U Neither go). In part\n(b) we discovered the following:\n# (3 Person Committees) = 120\n# {Bothgo) = 8\n# {Only 1goes) = 28 x 2 = 56\n# {Neithergoes) = 56\nSo, in order to use the addition counting rule, we need to have mutually exclusive events.\nBut, obviously {Bothgo)rl{Neithergoes) = 0 so we simply add the two counts together:\n8 + 56 = 64.\nd) can it be chosen, if two people must be chosen from MIT assistant faculty (6 professors) and\none person must be chosen from visiting assistant faculty (4 professors)?\nSolution to (d): This should be easy if you've already figured out parts (a)-(c), not because\nyou've computed the answer yet, but because the methods are similar. We just break the\nproblem into its two parts: choosing MIT assistant faculty and choosing visiting assistant\n6 . 5\nfaculty. This give us -.\n= 60. Does this answer make sense? It is less than\n2 -\nVisiting\nM I T\nif there were just two people who hated each other, as this is equivalent to the problem\nwhere four people refuse to go together, but we have to have one of them. So, we would\nexpect the count to be less than what we found in (b).\nQuestion 2\nIn the seventeenth century, Italian gamblers used to bet on the total number of spots rolled with\nthree dice. They believed that the chance of rolling a total of 9 ought to equal the chance of rolling\na total of 10. They noted that altogether there are six combinations to make 9: (1,2,6), (1,3,5),\n(1,4,4), (2,3,4), (2,2,5), and (3,3,3). Similarly, there are six combinations for 10: (1,4,5), (1,3,6),\n(2,2,6), (2,3,5), (2,4,4), (3,3,4). Thus, argued the gamblers, 9 and 10 should have the same chance.\nEmpirically, they found this not to be true, however. Galileo solved the gambers' problem. How?\na) How many permutations of three dice are there that sum to 9?\nSolution to (a): Here is the list of how many permutations for each 3-tuple that sum to\n9:\nSo, we find that there are a total of 6 + 6 + 3 +6 + 3 + 1= 25 possible ways to obtain 9\nas the sum of the three dice.\n\nb) How many permutations of three dice are there that sum to lo?\nSolution to (b): Here is the list of how many permutations for each 3-tuple that sum to\n10:(1,4,5), (1,3,6), (2,2,6), (2,3,5), (2,4,4), (3,3,4)\nSo, we find that there are a total of 6 + 6 + 3 +6 + 3 + 3 = 27 possible ways to obtain 9\nas the sum of the three dice.\nc) How many total permutations of three dice are there? What was Galileo's solution? Explain.\nSolution to (c): Since there are a total of Z3 = 216 possible permutations of the three dice,\nGalileo's solution must have been the application of the multiplication rule. Since each\ndie gives us an independent outcome, we know that each permutation of the 3-tuples is\nequally likely. So, what that means is that rather than thinking about the combinations\nof the 3 dice, we must consider the permutations which are uniformly or evenly likely.\nThe Italian gamblers then would have adjusted their bets to account for the fact that 10's\nare more likely than 9's:\n5 &.\nNote: a quick (albeit incomplete) answer to the problem would have observed that since\nwe expect each dice to have an average contribution of 3.5 = (1+2 +3+4+ 5+6)/6 = F,\nwe will expect 10 and 11to have the same probabilities due to symmetry and a Central\nLimit Theorem will tell us that the probability of getting events away from the center of\nthe possible outcomes (when summing random variables) are less probable. So, since 9\nis away from the average outcome of 10.5, we know that the probabilities should decline\nmonotonically. You'll learn more about this later in the course.\nQuestion 3\nVenn diagrams or set diagrams are diagrams that show all hypothetically possible logical relations\nbetween a finite collection of sets (groups of things). Venn diagrams were invented around 1880 by\nJohn Venn. They are used in many fields, including set theory, probability, logic, statistics, and\ncomputer science (Wikipedia: http://en.wikipedia.org/wiki/Venn_Diagram).\na) Draw a Venn diagram for the three events A, B, and C contained in the sample space S and\nproperly label all possible union and intersections of events.\nSolution to (a): Here is an example:\n\nb) Draw a Venn diagram for the three events A, B, and C contained in the sample space S and\nproperly label all possible combination of events where A nB nC = 0.\nc) Try (but don't spend too much time-it's just for fun) to draw a complete Venn diagram for\nthe four events A, B, C, and D contained in the sample space S where you include all possible\nSolution to (b): Here is an adapted example from the following website:\nhttp://www.cs.kent.ac.uk/events/conf/2004/euler/eulerdiagrams.html.\nC\nS\n\nunions and intersections of events. How many mutually exclusive regions should such a diagram\ninclude?\nSolution to (c): Here is an example from the website cited in part (b).\nd) How many mutually exclusive regions should such a diagram with k E N events include?\nSolution to (d): We will try this problem two different ways. A proof by induction (show\ntrue for 1and then true for k and k + 1) would be preferred as it provides the logical\njustifications, but we'll start by looking at small examples.\nWe first note that if you have just one event, there are two possible regions: A and A\".\nWith two events, we know that there are A nB, A\" n B, A nBe,and A\" n Bc. That's\nfour. Perhaps we're seeing a pattern. If you look at your picture for part (a) and count\nall of the separate regions, you'll find that there are eight for 3 events. We hypothesize\nthat the formula for the number of is 2'.\nA proof by induction would go like this: With one event, you're either in or out, which\ngives us 2. Assume the formula holds for k:2' is the number of mutually exclusive events\nin such a diagram. For k+ 1,we recognize, by the same logic that for the k+ 1event, both\nit and its complement will intersect the 2' events, generating 2\"'\nmututally exclusive\nevents.\nNote: I suspect that some of you may have interpreted this question differently. I will try\nto take into account any confusion for which I am responsible in the grading process.\nQuestion 4\nDoes a monkey have a better chance of rearranging \"ACCLLUUS\" to spell \"CALCULUS,\"\n\nor of rearranging \"AABEGLR\" to spell \"ALGEBRA?\" (2 points.)\nSolution: How many letters is \"CALCULUS\"? Eight. How many letters is \"ALGEBRA\"? Seven.\nHow many unique permutations of the letters \"ACCLLUUS\" are there? We have & = 7!\ndifferent permutations since there are two C's, L's, and U's. How many unique permutations\nof the letters \"AABEGLR\" are there? We start out with at most 7!, but we have duplicate A's,\nso we know that there must be 7!/2! different permutations, which is less than 7!. Thus, we\nknow that \"ALGEBRA\" is twice as likely to come up randomly on a monkey's Shakespearean\ntypewriter.\nQuestion 5\nIn Lecture 1, you learned about event partitions. Give three different examples of partitions of a\nsingle draw from a deck of playing cards.\nSolution: There are many different partitions that could be made. I will provide just three\nexamples here.\n- Example 1: {{All Hearts), {All Clubs), {All Spades), {All Diamonds))\n- Example 2: {{All Red Cards) , {All Black Cards))\n- Example 3: {{All Even Numbers) , {All Odd Numbers) , {All Aces) , {All Royalty))\nQuestion 6\nThe MIT football team plays 12 games in a season. In each game they have\nprobability of winning,\nprobability of losing, and\nprobability of tying. Games are independent. What is the probability\nthat the team has 8-3-1 record? (8 wins, 3 losses, and 1ties)\nSolution: Sorry, there was a typo on the problem set. If you solved it correctly for either an\n8-3-1 or 6-4-2 record, you'll receive full credit.\nYou should have received the following solution for the 8-3-1 record. Since each game is\nan independent event, we can compute the probability of getting that particular record in a\nparticular order: (i) (i) (i) = 3.175e - 06. Now, that's pretty small! However, we still\nneed to compute the number of ways that we could obtain that record. If there are twelve\ngames and we have 8 wins, 3 losses, and 1tie, we can order those in & = 1980 ways. That's\na lot of ways, though! This means that the total probability of the Beavers getting a decent\nrecord like that is \"\n8!3!1! (A)\n3 7;)(()>' = .00628715\nwhich is still pretty small, but we have to remember that this is just the probability of getting\nexactly this record. If we want at least that good of a record, we have to add in all better\npossible seasons as well.\nNote: These probabilities and records weren't actually taken from the Beaver's true perfor-\nmance. ;)\nQuestion 7\nYou and your friends just rented a car from Enterprise for an 8,000 mile cross-country road trip\nto see all of the sights from from Boston Harbor to the Golden Gate Bridge. Your rental car may\nbe of three different types: brand new (and not a lemon), nearly 1year old, or a lemon (bound to\nbreak down). That many miles can be demanding on a rental car. If the car you receive is brand\nnew (New), it will break down with probability 0.05. If it is one year old (One), it will break down\nwith probability 0.1. If it is just a lemon (Lemon), it will break down with probability 0.9. The\nprobability that the car Enterprise gives you a car that is New, One, or Lemon is 0.8, 0.1, and 0.1,\nrespectively. Compute the probability that your car is going to break down on your road trip.\n\nSolution: Since getting each car is a mutually exclusive event, we can simply add up the\nprobabilities of getting each car after multiplying by the probabilities of break down for each\ncar. In particular, we get that the probability of getting a new car and it breaking down\nis jointly 0.8 x 0.05 = 0.04. Similarly, we find for one year old cars and lemons the joint\nprobability to be 0.1 x 0.1 = 0.01 and 0.1 x 0.9 = 0.09. Thus, we obtain the total probability\nof the car breaking down is simply\n0.04 +0.01 + 0.09 = 0.13\nv v v\nNew\nOne\nLemon\nMake sure to take your cell phones with you so you can call for help!\nQuestion 8\na) Bayes' formula is really important. Write down Bayes' formula and describe it in words.\nSolution to (a): Bayes' formula is easily derived from the conditional expectation formula:\nwhich by symmetry gives us Bayes' formula: P (AB) = P(B$Ay(A). A more general version\nmakes use of the Law of Total Probability:\nWhat Bayes' formula tells us is that if we know the marginals of two events and we know even\none of the conditionals, we can back out what the other conditional distribution is. This is\nreally helpful, as illustrated by your work on the problems below.\nFurther, here are a couple of common applications.\nb) Suppose that five percent of men and 0.25 percent of women are color blind. A colorblind\nperson is chosen at random. What is the probability of this person being male? Assume that\nthere are an equal number of males and females. What if there were twice as many males as\nfemales?\nSolution to (b): The events A and B are being male and colorblind. We write the formula:\nP (ColorblindlMale) P (Male)\nP(MalelColorb1ind) =\nP (Colorblind)\nwhich we arrive at by making the assumption that 50% of the population is male and 50%\nis female and have computed the marginal probability of being colorblind by multiplying\nthe probability (independent draws) of being male and colorblind and adding that to the\nprobability of female and colorblind (two mututally exclusive events): 0.5 x 0.05+0.5 x 0.0025.\nIf there are twice as many males as females we just have to change the formula slightly to\naccount for the different marginal of A. After doing this we obtain:\nP (Colorblind1Male) P (Male)\nP (MalelColorblind) =\nP (Colorblind)\n\nc) Suppose that there exists an imperfect test for Tuberculosis (TB). If someone has TB, there\nis a ninety-five percent chance that the test will come up \"red.\" If someone does not have TB,\nthere is only a two percent chance that the test will come up red. Finally, the chance that\nanyone has TB is, say, five percent (in the United States; in other countries Tuberculosis is\nendemic). Once someone takes the test and it comes up red, what is the probability that they\nhave TB?\nSolution to (c): We do the same thing as in part (b), just with different marginal and con-\nditional probabilities and some algebra. In particular, we have P (PositivelTB) = 0.95,\nP (Positive1\nT B ) = 0.02, and P ( T B ) = 0.05. What we want to know is P (TBIPositive).\nWe can compute the marginal P (Positive) by using the information that we know from the\nmarginal and conditional distributions:\nP (Positive) = P ( T B )P (PositivelTB)+P ( N T B )P (Positive1\nT B )\n= (0.05) x (0.95)+ (1 - 0.05) x (0.02)\nNow that we know that marginal, we can use Bayes7formula:\nP (PositivelTB)P ( T B )\nP (TBIPositive) =\nP (Positive)\nThis is why rare diseases can be so hard to accurately diagnose, because even small false\npositive rates get amplified by the large population that is going to test positive that does not\nhave the disease."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/4e71faba6ddac1151d53135fe77c59b1_MIT14_30s09_pset02.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #2\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, February 24, 2009\nQuestion 1\nRecall that a random variable X has the binomial distribution if\nwhere n is the number of trials and p is the chance of success. For the following\ncrudely-disguised questions about the binomial distribution, do the following: Define\np, n, what the specific \"trials\" are, what \"success\" is. Then write down the relevant\ndistribution and answer the specific question.\n1. If 25 percent of the balls in a certain box are red, and if 15 balls are selected\nfrom the box at random, with replacement, what is the probability that more\nthan four red balls will be obtained?\n2. (3 pts.) Suppose an economist is organizing a survey of American minimum\nwage workers, and is interested in understanding how many workers that earn\nthe minimum wage are teenagers.' Suppose further that one out of every four\nminimum wage workers is a teenager. If the economist finds 80 minimum\nwage workers for his survey, what's the probability that he interviews exactly\n14 teenagers? 35 teenagers? What's the probability that he gets at least 5\nteenagers in his survey?\n3. (Bonus Question) A city has 5000 children, including 800 who have not been\nvaccinated for measles. Sixty-five of the city's children are enrolled in a day care\ncenter. Suppose the municipal health department sends a doctor and nurse to\nthe day care center to immunize any child who has not already been vaccinated.\nFind a formula for the probability that exactly k of the children at the day\ncare center have not been vaccinated. (Hint: This is not exactly a binomial\ndistribution problem.)\n'In the debate over the minimum wage, one point that is always made is that a lot of workers\non the minimum wage are middle-class teenagers. Since most of them are not supporting a family,\nthe harms of an increase in the minimum wage outweigh the benefits. This point never convinces\nanyone.\n\nQuestion Two\nSuppose you flip a weighted coin (probability of heads is p and probability of tails is\nq = 1- p) n times.\n1. What is the probability that you get a particular ordering of k heads and n -k\ntails?\n2. What is the probability that you get k heads and n - k tails?\n3. Let X =the number of heads in n flips. What is the probability density function\nof X?\n4. What does this question have to do with the MIT Beaver's football team ques-\ntion from Problem Set #I? Explain.\nSuppose now that you have a hat with two coins, one weighted as above and one fair.\nYou choose one at random and flip that one n times.\nI. Let Y =the number of heads in n flips. What is the PDF of Y?\n2. What is the probability that you chose the fair coin given that Y = k?\nQuestion Three\nSuppose that two balanced dice are rolled. Determine and sketch the probability\ndistribution of each of the following random variables.\n1. Let X denote the absolute value of the difference between the two numbers that\nappear.\n2. Let Y denote the product of the two numbers that appear.\n3. Let Z denote the number of even numbers that appear.\nQuestion Four\nSuppose that you have just purchased a new battery for your smoke detector, and\nthe life of the battery is a random variable X, with pdf\nwhere x E (0,oo).Assume that t and s are real non-negative numbers.\n1. Use the properties of a pdf to find the value of k.\n2. Find an expression for P(X 2 t).\n\n3. Find an expression for P(X 2 t + sI X\n2 s).\n4. Suppose that your batteries have lasted s weeks without dying. Based on your\nabove answers, are you more concerned that the battery is about to die that\nyou were when you first put it in?\nQuestion Five\nSuppose we investigate the pattern of genetic inheritance for the color of an exotic\nflower which has either blue or red blossoms. Since the flower lives in a close symbiotic\nrelationship with the very shy squirrel monkey which can't be held in captivity, there\nis no way of doing a controlled laboratory experiment to answer the research questions.\nEach flower carries the color genes of both its \"father\" and its \"mother,\" so its\ngenetic information can be described as a pair of genes (GM, GF) as given by the\nfollowing table:\n\"Fat her1'\nB\nR\n\"Mother\" B\nThe phenotype corresponding to red blossoms, R,is said to be dominant if any\nflower which contains at least one gene of the R type (e.g. the combination (R,B)) has\nred blossoms. Either the blue or the red phenotype is dominant, but before having\nseen a single specimen of the flower, we think that each possibility is equally likely.\n1. Suppose we know beforehand that the R and the B alleles are equally frequent,\ni.e. Pi(B) = Pi(R) =\nfor i = F,M, and independent across the \"parents,\"\ni.e. PFM(GF, GM) = PF(GF) PM(GM). If the blue phenotype B is dominant,\nwhat is the probability that a given specimen of the flower has red blossoms?\nWhat is the probability of red blossoms if the R is dominant?\n2. It takes a lot of effort to find a single specimen of the plant, so all a well-funded\ntwo-month expedition by a team of MIT botanists to the Amazon could gather\nwas a sample of 15 flowers. If R is dominant, what is the probability of 9 out\nof the 15 flowers having red blossoms?\n3. Our expedition did in fact return with a sample of 9 red and 6 blue blossoms.\nGiven that, what is the likelihood that the red phenotype is dominant?\n4. At the same time, there is a lonely graduate student working in the same area for\ntwo entire years on the same research question. The graduate student is totally\ncut off from the outside world and doesn't know about the other expedition's\nfindings yet, but bases his inference solely on his own sample. What is his\nposterior probability of R being dominant given that he found N flowers, out of\nwhich x have red blossoms? Show that this probability does not depend directly\non N, but only the difference between the number x of red blossoms, and the\nnumber N - x of blue blossoms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #2 — Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/7b821e6a50dd84251533a02fe3898f3d_MIT14_30s09_sol_pset02.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #2 - Solutions\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, February 24, 2009\nQuestion 1\nRecall that a random variable X has the binomial distribution if\nwhere n is the number of trials and p is the chance of success. For the following crudely-\ndisguised questions about the binomial distribution, do the following: Define p, n, what the\nspecific \"trials\" are, what \"success\" is. Then write down the relevant distribution and answer\nthe specific question.\n1. If 25 percent of the balls in a certain box are red, and if 15 balls are selected from\nthe box at random, with replacement, what is the probability that more than four red\nballs will be obtained?\na Solution to 1: For this problem, we have that p = .25, n = 15. Each \"trial\" is the\nselection of a ball from the box, and each \"success\" is drawing a red ball.\nThe probability that more than four red balls will be obtained can be computed\ntwo ways. One way would be to compute the direct probability by summing up\nthe probabilities of getting 5, 6, ..., or 15 balls. That's the long way. I instead\nwill compute it using the complementary event {k > 4)\" = { k < 4 ) where k is\nthe number of red balls drawn. So, this makes the problem a little simpler as I\nonly have to compute 5 probabilities and then sum over them using the binomial\nformula:\n\nSo, when we sum over the probability of getting P ({k < 4)) = .68648594. Thus,\nthe complementary event's (the complementary event to the complementary event\nis what we're looking for) probability will be P ({k > 4)) = 1- P ({k < 4)) =\n1-.68648594 = .31351406. So, instead of counting 11cases, we only had to count\n5.\n2. (3 pts.) Suppose an economist is organizing a survey of American minimum wage\nworkers, and is interested in understanding how many workers that earn the minimum\nwage are teenagers.' Suppose further that one out of every four minimum wage workers\nis a teenager. If the economist finds 80 minimum wage workers for his survey, what's\nthe probability that he interviews exactly 14 teenagers? 35 teenagers? What's the\nprobability that he gets at least 5 teenagers in his survey?\nSolution to 2: In this case, we have p = 0.25 again and n = 80. We again use the\nbinomial formula to obtain the solution to the first question:\nThe second uses the same formula:\n3. (Bonus Question) A city has 5000 children, including 800 who have not been vaccinated\nfor measles. Sixty-five of the city's children are enrolled in a day care center. Suppose\nthe municipal health department sends a doctor and nurse to the day care center\nto immunize any child who has not already been vaccinated. Find a formula for\nthe probability that exactly k of the children at the day care center have not been\nvaccinated. (Hint: This is not exactly a binomial distribution problem.)\nSolution to 3: In previous years, a similar problem was just approximated by\nthe binomial distribution. It turns out that for large n, the binomial distribution\ngives a good approximation to problems like this one. Further, for large n and\nlarge k, the Normal (also known as the Gaussian) distribution also gives a very\ngood approximation. I am going to solve this questions all three ways to give you\na sense as to the exact answer.\nSince the problem is actually a discrete problem with sampling without replace-\nment, the binomial distribution is not exactly correct. If we had sample with\nreplacement, then it would work just fine. This problem is an example of the\nhypergeometric distribution (Wikipedia: Hypergeometric Distribution). The hy-\npergeometric distribution is typically couched in a \"defective parts\" problem where\nyou have a batch of N parts, m of which are defective. You then sample n dif-\nferent parts without replacement and wish to know the probability of getting\n'In the debate over the minimum wage, one point that is always made is that a lot of workers on the\nminimum wage are middle-class teenagers. Since most of them are not supporting a family, the harms of an\nincrease in the minimum wage outweigh the benefits. This point never convinces anyone.\n\nexactly k defective units. In our case, N = 5000 children, m = 800 unvaccinated\nchildren, n = 65 children at the day care center, and k represents the number of\nunvaccinated children at the day care center. Without going into the details of its\nderivation, the hypergeometric distribution takes into account the change in con-\nditional probabilities when you sample without replacement. Intuitively, though,\nyou're trying to figure out how to split the 5000 children into two groups-the\nsampled and unsampled groups. Then, you're trying to figure out the probabil-\nity that you have a particular k number of unvaccinated children in the sampled\npart. From Wikipedia, \"The formula can be understood as follows: There are\n(f) possible samples (without replacement). There are (T) ways to obtain k de-\nfective objects and there are (:I;\")\nways to fill out the rest of the sample with\nnon-defective objects.\" The formula follows:\nwhich would be, in our case:\n5000-800\nf (k; 5000, 800, 65) = ( k ) ( 65-k )\nIt is extremely interesting to compare how the different approximations perform.\nHere are two charts that show how well the approximations do for large N ( N =\n5000) and small N ( N = 125):\nN=5000, m=800, n=65\nN=125, m=20, n=65\nk\nHypergeometric Binomial\nNormal\nk\nHypergeometric Binomial\nNormal\n0.0003\n0.0003\n0.0001\n0.0001\n0.0009\n0.0001\n0.0009\n0.0009\n0.0009\n0.0025\n0.0009\n0.0025\n0.0036\n0.0035\n0.006\n0.0002\n0.0036\n0.006\n0.0107\n0.0104\n0.0132\n0.0014\n0.0107\n0.0132\n0.0248\n0.0243\n0.0257\n0.0061\n0.0248\n0.0257\n0.0472\n0.0467\n0.0448\n0.02\n0.0472\n0.0448\n0.0758\n0.0755\n0.0698\n0.0503\n0.0758\n0.0698\n0.1047\n0.1048\n0.0969\n0.0987\n0.1047\n0.0969\n0.1263\n0.1269\n0.1202\n0.1531\n0.1263\n0.1202\n0.1347\n0.1356\n0.1331\n0.1886\n0.1347\n0.1331\n0.1283\n0.1292\n0.1316\n0.1849\n0.1283\n0.1316\n0.1 1\n0.1 106\n0.1162\n0.144\n0.1 1\n0.1162\n0.0854\n0.0856\n0.0916\n0.0886\n0.0854\n0.0916\n0.0604\n0.0603\n0.0644\n0.0427\n0.0604\n0.0644\n0.0391\n0.0389\n0.0405\n0.0158\n0.0391\n0.0405\n0.0233\n0.023\n0.0227\n0.0044\n0.0233\n0.0227\n0.0128\n0.0125\n0.0114\n0.0009\n0.0128\n0.01 14\n0.0065\n0.0063\n0.0051\n0.0001\n0.0065\n0.0051\n0.0031\n0.0029\n0.002 19\n0.0031\n0.002\n0.0013\n0.0013\n0.0007\n0.0013\n0.0007\n0.0005\n0.0005\n0.0002\n0.0005\n0.0002\n0.0002\n0.0002\n0.0001\n0.0002\n0.0001\n0.0001\n0.0001\n0 23\n0.0001\n0 24\n0 25\nSo, the real question is, if I didn't care if you had shown your work, could you\nhave just taken the easy route on this problem and used the binomial formula? I\nguess the answer depends on how many decimals you show! ;)\n\nQuestion Two\nSuppose you flip a weighted coin (probability of heads is p and probability of tails is q = 1-p)\nn times.\n1. What is the probability that you get a particular ordering of k heads and n - k tails?\nSolution to 1: The probability of getting a particular ordering of k heads and\nn - k tails would be pkqnpk.\n2. What is the probability that you get k heads and n - k tails?\nSolution to 2: From part 1, the probability of getting any particular ordering\nof k heads and n - k tails would be pkqn-k,\nbut we have to take into account\nthe number of permutations that exist for getting k heads and n - k tails. We\ncan think about this as the \"ALGEBRA\" and \"CALCULUS\" problem, by simply\nlabeling the heads as \"H\" and tails as \"T\" and then figure out how many different\nwords we can write. This is pretty simple: 6which just so happens to be\nthe same as the binomial coefficient, ( ) So, it turns out that we just have the\nbinomial formula for this problem:\n3. Let X =the number of heads in n flips. What is the probability density function of\nX ?\nSolution to 3: Well, I just have to rewrite the answer to 2 slightly differently to\nchange the notation to refer to the random variable, X and its PDF, f (x;n):\nP(X = x) = f (x;n) = ( :)pX(l-PY-%-\n4. What does this question have to do with the MIT Beaver's football team question from\nProblem Set #1? Explain.\nSolution to 4: The MIT Beaver's football team question was virtually the same\nproblem, with a slight additional generalization, because we had three differ-\nent outcomes. We could write this as two binomial trials (number of ties, then\nnumber of wins in remaining games) or we could write it using a slightly more\ngeneral version of the binomial theorem which known as the multinomial the-\norem (Wikipedia: Multinomial Theorem). We can write these coefficients as:\nand the distribution that we would use would be the\nmultinomial distribution (Wikipedia: Multinomial Distribution):\n\nTaking a closer look at the solution for the MIT Beavers question from Problem\nSet #I, it quickly becomes apparent that there are 3 possibilities with varying\nprobabilities: Wins (pw), Losses (pL),and Ties (pT),each with a specific k. Thus,\nthe MIT Beavers question maps into the composition of two binomials, which is\njust the multinomial theorem.\nI must highlight, however, that even if you knew nothing about the binomial\ntheorem, the techniques of the multiplication rule and permutation counting rules\nwas sufficient to answer that question. This is merely to help you learn about more\ngeneral methods of dealing with these types of questions.\nSuppose now that you have a hat with two coins, one weighted as above and one fair. You\nchoose one at random and flip that one n times.\n1. Let Y =the number of heads in n flips. What is the PDF of Y?\nSolution to 1: This question is about a mixture distribution. We have two coins,\neach of which we use with probability p = 1. So, the PDF will be that we use the\nfair coin's PDF half of the time and the unfair coin the other half of the time:\nweightedCoin\n2. What is the probability that you chose the fair coin given that Y = k?\nSolution to 2: In order to deduce the answer to this question, we apply Bayes'\nrule again, but with PDFs. We would like to know P(Fair1Y = k). We know\nwhat the denominator is in Bayes' rule from part 1 (just above):\nWe now just need to get the other parts explicitly: P(Fair) =\nand P ( Y =\n-\nkIFair) = ( ) 0.5Y(l - 0.5).'Y,\nthe fair coin's PDF. So, we now use Bayes'\nRule:\n4( i ) 0.5*(1 - 0 . 5 ) \" ~ ~\nP(Fair1Y = k) = ( ) 0 5 ( 1 - 0.5)~-. + ( )pk(l -P)~-*\n\\\n/ \\\n/\nV\nY\nFair Coin\nWeighted Coin\n\nQuestion Three\nSuppose that two balanced dice are rolled. Determine and sketch the probability distribution\nof each of the following random variables.\n1. Let X denote the absolute value of the difference between the two numbers that appear.\nThe PDF for the absolute difference between two dice can take on 11 different\nvalues ranging from -5 to +5. We could count all of the possibilities, or we could\njust recognize that due to the symmetry of the dice we can just treat this like\nthe regular two dice problem where the same outcomes are just relabeled. So, it\nturns out that we can use the same distribution with a shifted support:\nOutcome, x\n-5\n-4\n-3\n-2\n-1\n0 +l +2 +3 $4\n$5\nNurnberofWaystoObtain\nwhich, since there are 36 outcomes for the two dice, we have:\nThe sketch of f (x) will be done on the board.\n2. Let Y denote the product of the two numbers that appear.\nSolution to 2: The product of two numbers on a dice can take on the following\noutcomes:\nOutcome, y\n\nNumber of Waystoobtain 1 2\nf (Y)\n1 2 2 3 2 4 2 1 2 4\nOutcome, y\n15 16 18 20 24 25 30 36\nNumber of Ways toobtain 2\nf (y)\n2 1 2 2 2 1 2 1\nThe sketch of f (y) will be done on the board.\n3. Let Z denote the number of even numbers that appear.\nSolution to 3: There are three possible outcomes: 0, 1, or 2. The outcome of 1\neven number has twice the probability of 0 or 2. Thus, we have that the PDF has\nf (0) = 0.25, f (1)= 0.5, and f (2) = 0.25. The sketch of f (x) is straightforward\nfrom this information and will be done on the board.\n\nQuestion Four\nSuppose that you have just purchased a new battery for your smoke detector, and the life of\nthe battery is a random variable X, with pdf\nwhere x E (0,oo). Assume that t and s are real non-negative numbers.\n1. Use the properties af a pdf to find the value of k.\nSolution to 1: We know that the PDF must integrate to 1:\n2. Find an expression for P(X > t).\nSolution to 2: This expression is straightforward now that we have the integration\nconstant, k:\nwhich can be simplified to\n3. Find an expression for P(X 2 t + slX 2 s).\nSolution to 3: We can just use the formula for conditional probabilities:\n4. Suppose that your batteries have lasted s weeks without dying. Based on your above\nanswers, are you more concerned that the battery is about to die that you were when\nyou first put it in?\nSolution to 4: If my batteries have lasted s weeks without dying, based on my\nanswer to part 3, I should be just as worried as I was before, since survival of\nthe battery tells me nothing new about its likelihood of dying. The exponential\ndistribution (which this is) has this very special property, that no matter how\nlong something has lasted, its rate/probability of failure is constant at any given\ntime.\n\nQuestion Five\nSuppose we investigate the pattern of genetic inheritance for the color of an exotic flower\nwhich has either blue or red blossoms. Since the flower lives in a close symbiotic relationship\nwith the very shy squirrel monkey which can't be held in captivity, there is no way of doing\na controlled laboratory experiment to answer the research questions.\nEach flower carries the color genes of both its \"father\" and its \"mother,\" so its genetic\ninformation can be described as a pair of genes (GM, GF) as given by the following table:\n\"Fat her1'\nB\nR\n\"Mother\" B\nThe phenotype corresponding to red blossoms, R, is said to be dominant if any flower\nwhich contains at least one gene of the R type (e.g. the combination (R,B)) has red blossoms.\nEither the blue or the red phenotype is dominant, but before having seen a single specimen\nof the flower, we think that each possibility is equally likely.\n1. Suppose we know beforehand that the R and the B alleles are equally frequent,\ni.e. Pi(B) = Pi(R) = i!j for i = F,M, and independent across the \"parents,\" i.e.\nPFM(GF, GM) = PF(GF)PM(GM). If the blue phenotype B is dominant, what is the\nprobability that a given specimen of the flower has red blossoms? What is the proba-\nbility of red blossoms if the R is dominant?\na Solution to 1: The probability of a flower having red blossoms is the probability\nof only getting the recessive genotype on both alleles. Thus, we can compute\nPFM(RF,RM) = PF(RF)PM(RM)= i!j - i!j = i.\nIf the R is dominant, then we can solve this by relabeling blue as red and taking\nthe complementary event and probabilities which yields q.\n2. It takes a lot of effort to find a single specimen of the plant, so all a well-funded\ntwo-month expedition by a team of MIT botanists to the Amazon could gather was\na sample of 15 flowers. If R is dominant, what is the probability of 9 out of the 15\nflowers having red blossoms?\na Solution to 2: This is another basic binomial question. We have a sample of size\n15 with P(Red Blossom) = a which yields the following formula:\nP(9 Red Blossom; 15 Flowers) = ( )P ) (i)9\n($)15-9\n3. Our expedition did in fact return with a sample of 9 red and 6 blue blossoms. Given\nthat, what is the likelihood that the red phenotype is dominant?\na Solution to 3: Bayes' rule is our friend here, again. We just need to pull together\nthe pieces. We know that the alleles are equally frequent, which means that the\ndistribution of alleles should not influence our sampling. We should just consider\n\n15-6\nwhat we suspect, beforehand the chance of the red versus the blue allele being\ndominant as equal. Thus, we have P(RedDominant) = f. Then, we have the\nbinomial distribution for the red and blue phenotypes:\nP(9 Red Blossomsl Red is Dominant; 15Flowers) = ( '9' ) (a) (O)\"'\nP(6 Blue BlossomsI Blue is Dominant; 15Flowers) = ( f ) (:) (i)\nwhich gives us the denominator for Bayes' rule and all of the pieces to compute\nwhat we are seeking:\nP(9 Red Blossoms) Red Dominant)P(Red Dominant)\nP(Red Domi9 Red) = P(9RlR Dom)P(R Dom) + P(6 BIB Dom)P(B Dom)\n+(;) (i) (3\n-- f(Y) (i) (f) 15-9 + f (7)(2) (f)\nThis is really interesting, as a difference of only three blossoms is enough to tell\nyou something with 95% significance. However, it should be noted that this is\nactually a difference of 6 blossoms, since 9 - 6 = 3 versus 6 - 9 = -3.\n4. At the same time, there is a lonely graduate student working in the same area for two\nentire years on the same research question. The graduate student is totally cut off from\nthe outside world and doesn't know about the other expedition's findings yet, but bases\nhis inference solely on his own sample. What is his posterior probability of R being\ndominant given that he found N flowers, out of which x have red blossoms? Show that\nthis probability does not depend directly on N , but only the difference between the\nnumber x of red blossoms, and the number N - x of blue blossoms.\n\nSolution to 4: We just use the answer from part 3 to solve this:\nP ( x Red BlossomsI Red Dominant)P(Red Dominant)\nP(Red Domlx Red) = P ( x RIR Dom)P(RDom) + P ( N - x BIB Dom)P(BDom)\nwhich is just a function of the difference between x and N - x, or the difference\nbetween red and blue blossoms discovered."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/9197cb740caca50a7fc405b8229cf4be_MIT14_30s09_pset03.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #3\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, March 3, 2009\nQuestion One\n1. Write down the definition of a cumulative distribution function (CDF). Explain\nwhat it means in words, perhaps using an example.\n2. Verify whether the following function is a valid CDF. If yes, draw a graph of\nthe corresponding PDF.\nCu\nmu\nl\native\n\nd\ni\ns\nt\nr\ni\nb\nu\nt\ni\non function for problem 1, part 2.\n3. Verify that the following function is a valid PDF and draw the corresponding\nCDF.\nProba\nb\ni\nl\ni\nt\ny\n\nd\nistribution function for problem 1, part 3.\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\n\nQuestion Two\n1. Give a p.d.f, whose c.cLf, is not wntinuous but is right-continuous.\n%e/f~/uncertaix AIways give a bfief explanation if the statement is tme, or\ncounter-examples and a short ~ I a n a t i o n\nof the wunter-wmpleer if the statement\nis Ealse or mrt;ain,\n1. If P(Al B> > P(A) and P(AIC) > P(A), then P(AIB,C) P(A).\n2. A continuous p.d.f. can never take s d u e greater than 1.\n3. P(A) = P(AI B)P(B) m e a ~\nthat A anld B are independent.\nQuestion Three\n(Source: B&n/Engelhardt, Ch. 2, ex. 8)\nA nonnegative integer-valued random variable X hw a CDF of the form PIX) =\n1-(1/2)~+~\nforx=O, 1,2 ,.,. aadzeroifx<O.\n1. Find the pdf of X.\n2, Find P 110 < X 5 201.\n3. Find PIX b evert] .\nQuestion Four\n1. Suppose that n randam variable has a PDF that is proportional ko s on the\ninterval [O, I]. Write down a formula for this PDF. What is the corwpanding\nGbF?\n2. Now suppose that the random &able has a CDF that is parportional to s on\nthe interval [a, 11. Write down a formula for thh CDF. What is the correspond-\ning PDF?\nQuestion Five\nSuppose that the joint PDF of X and Y is given by\nkzSy f o r O < x < y < l\nfx,. = { 11\nelsewhere\n1. What is the value of k?\n\n2. What is the marginal PDF, fi ($1, of &?\n3. What is the value of the marginal cdfof x, Fx(x), d x = i?\n4 What is the conditiod PBF of y (conditional on x, i.6 f (ylx]}? Are X wd\nY ixkdependent? Explain.\n5. Wt is the probability that X +V < l?\nQuestion Six\n(Bh/EngeIhardt, Ch. 2, ex. ID)\nLet X be ~a W e t e random variable such that P[X = x] = U othade. Snppcse\nthe CDF is P(s) = .05x(X + x] ah the values z = 1, 2,3, or 4.\nI. Sketch the graph af the CDF.\n2; Sketch th6 graph of th& &mete pdf, f(x),\n3. Write down the debition of E[X]\na d\nfind E[A."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #3 — Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/7b7388dfecf65bb2c5efd41bcf9a60b6_MIT14_30s09_sol_pset03.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #3\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, March 3, 2009\nQuestion One\n1. Write down the definition of a cumulative distribution function (CDF). Explain what\nit means in words, perhaps using an example.\nSolution to (1): One definition of the CDF is f (.) : R H [0,1] where f (x) -\nPT(X5 x). The CDF tells us the cumulative probability up to particular point\nof the ordered support of the random variable, X. What this means is that we\ncan know what the chances are that something less than or equal to (or to the\nleft, depending on how you wish to interpret the ordering) an outcome, x, occurs.\n2. Verify whether the following function is a valid CDF. If yes, draw a graph of the\ncorresponding PCumu\nla\nti\nve\n\ndistr\ni\nb\nu\nt\ni\no\nn\n\nf\nu\nn\nction for problem 1, part 2.\n- -\nSolution to (2): The function is in fact a valid CDF. It is bounded below by\nzero and above by one. It also satisfies the left and right limit conditions as\nlim,,-,\nFx(x) = 0 and lim,,,\nFx(x) = 1. However, it is a mixture random\nvariable where it has a continuous distribution and a mass point at 2. The PDF\nby MIT OpenCourseWare.\nImage\n\nis the following equation:\n3. Verify that the following function is a valid PDF and draw the corresponding CDF\na SolutioProba bility distribution function for problem 1, part 3.\nsitive everywhere\nand integrates to 1 (the triangle Image by MIT OpenCourseWare.\nhas area of\nand the interv\n$\nal from 5 to 6 has\narea of\nwhich together sum to 1).The CDF is straightforward. I will write the\nPDF and then CDF down analytically first, to make for easier integration:\nDrawing this curve is relatively straightforward, at least if you pay little attention\nto detail as I am not a graphic designer:\n\nQuestion Two\n1. Give a p.d.f. whose c.d.f. is not continuous but is right-continuous.\nSolution to (1): This will have to come from a distribution with at least one mass\npoint (or it could be a completely discrete distribution). Konrad's lecture notes\nhave an example of the CDF:\nD\ne\nr\ni\nv\ned cumulative distribution function for problem 1, part 3.\nE\nx\na\nm\np\nl\ne\nof\na pr\no\nb\na\nb\ni\nlity distribution function whose cumulative distribution function is not continuous but right-continuous. Function is a step function.\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare.\n\nTrue/false/uncertain: Always give a brief explanation if the statement is true, or counter-\nexamples and a short explanation of the counter-examples if the statement is false or uncer-\ntain.\n1. If P(A1B) > P(A) and P(A1C) > P(A), then P(AIB,C) > P(A).\nSolution to (1): False. Just because two conditional probabilities are large, does\nnot mean that their joint probability will not be large. One example is the prob-\nability of getting sick (event A), given it is winter time (event B). You are more\nlikely to get sick during winter than the average during the year. You are also\nmore likely to get sick, conditional on taking medication that you don't need\n(randomly-event C). However, the probability of getting sick is likely lower if\nyou take preventive medications only during the peak times of the winter when\neveryone else is getting sick. The same thing applies to flu vaccines (high proba-\nbility of getting sick if you get a shot, high probability of getting sick during the\nwinter, potentially lower interaction probability).\n2. A continuous p.d.f. can never take a value greater than 1.\nSolution to (2): False. An example of a continuous PDF would be the uniform\nPDF defined as f (x) = 6 if 0 5 x < i and zero elsewhere. This PDF clearly\nis properly defined and has a value greater than one over an uncountable set of\noutcomes. Further, this statement would be more properly applied to CDFs.\n3. P(A) = P(AIB)P(B) means that A and B are independent.\nSolution to (3): False. This means that A and B are actually correlated as the\nlaw of total probability gives us that\nSo, what this means is that either P(AIBe)= 0 (which means that A only occurs if\nB does which would imply that they cannot be independent) or P(Bc)= 0 (which\nmeans that B = S,the sample space and then A and B would be independent).\nA simple example of A and B would be, in the space of a single roll of a die,\nA = {Rolla 4 ) and B = {Rollan evennumber). In this example, P(A) = i,\nP(B) = 5 , and P(A1B) = i. However, P ( A n B ) = i # P(A)P(B) = i.;.\nHowever, if B = S, then, it turns out that since P(S) = 1, we actually do\nhave that P(AIS)P(S) = P(A)P(S) = P(A) . 1 = P(A) which means both\nindependence and the condition in the question both hold simultaneously. Still,\nthis is not that interesting of a result. :)\nQuestion Three\n(Source: BainlEngelhardt, Ch. 2, ex. 8)\nA nonnegative integer-valued random variable X has a CDF of the form F(x) = 1-\n(1/2)\"+' for x = 0, 1, 2, . . . and zero if x < 0.\n\n1. Find the pdf of X .\nSolution to (1): The PDF is the difference in CDF at each point. Since this is an\ninteger random variable, we need to compute the difference in probabilities of the\nadjacent discrete outcomes:\nAlso, the PDF is such that f (x) = 0 for anything that is not a nonnegative integer.\n2. Find P [lo < X 5 201\nSolution to (2): For those of you who have seen the geometric series before, you\nquickly recognized that this is the just a finite difference in sums:\nOr, since we already have the CDF, you can just use that:\n3. Find P[Xis even].\nSolution to (3): Since we just want even numbers, we just need to compute it for\never other number. We can do this easily by just multiplying each x by 2 which\nwill allow us to skip all of the even numbers in the PDF. We then just need to\ncompute the infinite sum:\n\nQuestion Four\n1. Suppose that a random variable has a PDF that is proportional to x on the interval\n[O, 11. Write down a formula for this PDF. What is the corresponding CDF?\nSolution to (1):The PDF is proportional to x:\nf (x) = kx ifx E [O,1]\nand zero otherwise. By the integration property of PDFs, we know that k = 2.\nThe CDF is just the integral of the PDF:\nFor completeness we define the CDF as F(x) = 1if x > 1and F(x) = 0 if x < 0.\n2. Now suppose that the random variable has a CDF that is porportional to x on the\ninterval [0,11. Write down a formula for this CDF. What is the corresponding PDF?\nSolution to (2): The CDF is proportional to x:\nF(x) = kxifx E [O,1]\nwhich, by the properties of CDFs means that k = 1 to ensure that the CDF\nis bounded by zero and one. We also define the CDF as F(x) = 1 if x > 1\nand F(x) = 0 if x < 0 for completeness (don't forget to do this on exams and\nproblem sets-you need to define PDFs and CDFs on the whole support of the real\nnumbers). The corresponding PDF would be the derivative:\nf(x) = l i f x E [ O , l ]\nand zero elsewhere. This is the uniform PDF.\nQuestion Five\nSuppose that the joint PDF of X and Y is given by\n{ x 3 for0 < x < y < I\n~ X , Y=\nelsewhere\n1. What is the value of k?\n\nSolution to (1): For fX,yto be a PDF, the value of k must ensure that the density\nintegrates to 1:\nSo, k must be equal to 24 for the density to integrate to 1and, thus, be a proper\nprobably density function.\n2. What is the marginal PDF, fx(x), of x?\nSolution to (2): The definition of the marginal PDF is\nIn words, to obtain the marginal of x, all we have to do is integrate out the other\nrandom variables in the joint density, which means we integrate out y in this case.\nWe already performed this integral in the previous problem, so I will simply write\ndown the solution from the work above:\nWe could also solve for the marginal PDF of y, which would force us to do a\ndifferent integral, but I leave that exercise undone here.\n3. What is the value of the marginal cdf of x, Fx(x), at x = f ?\nSolution to (3): The marginal CDF of x is defined as the CDF of the marginal\nPDF or\n\nSo, by integrating this PDF, which we already did in part (I) of this question, we\nget:\nWhich, when we evaluate this at 4, we obtain F' (4) = 6 (4)4 (4 - f ( f ) 2 ) =\n5 - 5\n-\n16 ' 6 - 32'\n4. What is the conditional PDF of y (conditional on x, i.e. f (ylx))? Are X and Y\nindependent? Explain.\nSolution to (4): We again write down the definition of the conditional distribution\n(which is just a simple extension of the definition of conditional probability:\nWe clearly have all parts of this equation. Interestingly enough, though, we didn't\nneed the integration constant, k, to obtain the conditional distribution. This is\nrelevant for many Bayesian applications and advanced statistical methods such\nas Metropolis-Hastings Markov Chain Monte Carlo. You'll learn more about its\nrelevancy later, but here we will use the densities with k just to illustrate:\nAgain, for the interested reader, computing f (xly) is also possible upon obtain-\ning the marginal of y, fY(y). Then, we could either compute the conditional\ndistribution directly or use Bayes Rule:\nWe also must remember to answer the second part of the question: Are X and\nY independent? It turns out that they are not independent since the conditional\ndistribution of y is still a function of x. While at first glance it appears that we\nshould be able to factor out the marginals from the joint density via the \"factoring\n\nrule,\" we must remember that it only applies when the support of our joint distri-\nbution is rectangular. But, computing the marginals is the easiest way to see that\nit does, in fact, matter. While it is possible to have a carfully constructed non-\nrectangular support and still have two independent random variables composing\nthe joint density, in our case it doesn't work out that way.\n5. What is the probability that X +Y < l ?\nSolution to (5): We would like to integrate over the region where X +Y < 1. We\ncan perform this many ways, but I'm going to just compute it directly. One think\nto remember is that we need to be careful with our integration bounds. When\nintegrating y out, we must remember that x < y < 1-x where the first inequality\nis from the definition of the PDF and the second inequality is from the condition\nthat X +Y < 1+Y < 1- X. The combination of the two inequalities reminds\nus that x < 1 is also a condition we must put on x when integrating. We now\nperform the integration:\nwhich is fortunately less than 1. :) Also, an additional check would be to notice\nthat the form of the density would put a lot more mass close to (1,I),and we only\nintegrated out the smaller half of the triangular region bounded by 0 < x < y < 1.\nQuestion Six\n(BainIEngelhardt, Ch. 2, ex. 10)\nLet X be a discrete random variable such that P[X = x] = 0 otherwise. Suppose the\nCDF is F(x) = .05x(1+ x) at the values x = 1, 2, 3, or 4.\n1. Sketch the graph of the CDF.\n\nSolution to (1):We can plot this discrete CDF in a program like Matlab by using\nthe floor 1x1 operator: F(x) = .05 1x1 (1+ 1x1). Here is the plot of the CDF on\nthe interval [O, 51:\n2. Sketch the graph of the discrete pdf, f (x).\nSolution to (2): The PDF is simple to plot as well. We just want to use the\ndifference where we put mass points at 1, 2, 3, and 4, and recognize that it is a\ndiscrete PDF:\n\nC Discrete PDF\n3. Write down the definition of E[X]and find E[X].\nSolution to (3): The definition of E[X]is different for discrete and continuous\nrandom variables, although they are related via a limiting argument. I write\nthem both down for completeness, even though for this problem we will only be\nusing the discrete one:\nContinuous : E[XI\n= .I:\",\nx f (x)dx\nDiscrete : E [XI = xxf (x)\nwhere f (x) is the PDF of the random variable X. In this problem, we have a\nsimple sum:"
    },
    {
      "category": "Assignment",
      "title": "Problem Set #4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/b1c8e1965950d6efe3e3cfbf345f8319_MIT14_30s09_pset04.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #4\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, March 17, 2009\nQuestion One\nSuppose that the PDF of X is as follows:\ne-\"\nforx > 0\nf (4= 0\nf o r x 5 O\n1. Determine the PDF for Y = Xi.\n2. Determine the PDF for W = X : for k E N.\nQuestion Two\nSuppose that the PDF of a random variable X is as follows:\nL x f o r O < x < 5\nf (4= 0\notherwise\nAlso, suppose that Y = X(5-X). Determine the PDF and CDF of Y. You can solve\nthis in two ways. First, you can compute fy(y) using the formula given in class:\ntaking care that g(x) is piece-wise monotonic. Second, you can solve this by finding\nFy(y) = P[Y 5 y] directly, as we did in recitation. You will receive extra-credit if\nyou can do it both ways.\n\nQuestion Three\n(BainIEngelhardt, p. 226)\n(6 points) Let X be a random variable that is uniformly distributed on [O,1] (i.e.\nf(x) = 1 on that interval and zero elsewhere). Use two techniques from class (\"2-\nstepn/CDF technique and the transformation method) to determine the PDF of each\nof the following:\nQuestion Four\n(BainIEngelhardt p. 227)\nIf X N Binomial(n,p), then find the pdf of Y = n - X.\nQuestion Five\n(BainIEngelhardt p. 227)\nLet X and Y have joint PDF f (x,Y) = 4e- 2(x+y) for 0 < x < 00 and 0 < y < co,\nand zero otherwise.\n1. Find the CDF of W = X +Y .\n2. Find the joint pdf of U = $ and V = X.\n3. Find the marginal pdf of U."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #4 — Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/464704cd0b2a7fcf8aa98a3318f6b853_MIT14_30s09_sol_pset04.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #4 - Solutions\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, March 17, 2009\nQuestion One\nSuppose that the PDF of X is as follows:\ne-\"\nforx > 0\nf (4= 0\nf o r x 5 0\n1. Determine the PDF for Y = X i .\nSolution to 1: In order to find the PDF, we can use the CDF or \"2-Step\"\nmethod. We write:\nfor y > 0 and zero for y 5 0.\n2. Determine the PDF for W = X i for k E N.\nSolution to (2): This is just a straightforward generalization of part 1. We\n\ncan write:\nfor w > 0 and zero for w 5 0.\nQuestion Two\nSuppose that the PDF of a random variable X is as follows:\n$x\nf o r O < x < 5\nf (4= 0\notherwise\nAlso, suppose that Y = X(5-X). Determine the PDF and CDF of Y. You can solve\nthis in two ways. First, you can compute fy(y) using the formula given in class:\ntaking care that g(x) is piece-wise monotonic. Second, you can solve this by finding\nFy(y) = P [ Y 5 y] directly, as we did in recitation. You will receive extra-credit if\nyou can do it both ways.\nSolution: We first need to find the inverse function, g-l(y) = x. By solving we\nobtain:\nNow, we can apply the transformation result above since we do have a piecewise\nmonotonic function, g(x), with two roots over the interval. Since we know it is\na parabola, we solve for where the derivative is zero in order to obtain the two\n\nmonotonic pieces (one will be monotonically increasing, the other decreasing).\nSo, we find\ngf(x)= 5 -22 = 0 * x = -.\nSo, it turns out that at the midpoint, we have a maximum (since the second\nderivative is negative).\nWe now simply apply the formula to the two halves of the function and add\nthem together:\n'ro get the CDF, we just integrate:\nBoth the PDF and CDF are defined on the interval 0 < y < ? and the PDF is\nzero otherwise and the CDF is zero for y 5 0 and one for\n< y. Now, just to\ncheck our answer (and for extra credit), we will also use the CDF or \"2-Step\"\n\nmethod:\non the interval 0 < y 5 T. We got the same answer! Great!\nQuestion Three\n(BainIEngelhardt , p. 226)\n(6 points) Let X be a random variable that is uniformly distributed on [0,1](i.e.\nf (x) = 1 on that interval and zero elsewhere). Use two techniques from class (\"2-\nstepV/CDFtechnique and the transformation method) to determine the PDF of each\nof the following:\n1. Y =xi.\nSolution to (1): First, g(x) = x i + gp'(y) = y4. Using the \"2-step\"\ntechnique, we get\n\nUsing the transformation technique (after checking that g(x) is monotonic\non the nonzero support of f (x)), we get\nwhere fY(y) is defined above on [O,1] and zero otherwise.\nSolution to (1): First, g(x) = e-x + gP1(w) = -log w (note: \"log\" typ-\nically denotes \"ln\" or the natural log, log base e in economics and many\nother sciences). Using the \"2-step\" technique while paying close attention\nto the inequalities, we get\n=./\nd x =\nx:x& log w\n=./\nd x =\nx:xilog w\n= (x)b\"w\nFw(w) = logw\nUsing the transformation technique (after checking that g(x) is monotonic\non the nonzero support of f (x)), we get\nwhere fW(w) is defined above on [!, 11 and zero otherwise.\n\nSolution to (1): First, g(x) = 1- e-x + g-'(2) = -log (1- x) (note:\n\"log\" typically denotes \"ln\" or the natural log, log base e in economics and\nmany other sciences). Using the \"2-step\" technique, we get\nUsing the transformation technique (after checking that g(x) is monotonic\non the nonzero support of f (x)),we get\nwhere fz(z) is defined above on [ O , 1 - :]\nand zero otherwise.\nQuestion Four\n(BainIEngelhardt p. 227)\nIf X\nBinomial(n,p), then find the pdf of Y = n - X.\nSolution: The random variable Y = n - X is a straightforward discrete trans-\nformation. We right the inverse function, g-l(y) = n - Y. We now write the\nbinomial pdf:\nBy inspection, we see that we can simply substitute in the linear transformation\n(which is monontonic with Jacobian is -1,i.e. absolute value of 1for all possible\n\noutcomes):\n= Binomial(n, 1-p)\nSo, we see that this simple transformation simply relabeled a success as a failure\nand vice versa in our n Bernoulli trials. This is what we would have expected.\nQuestion Five\n(BainIEngelhardt p. 227)\nLet X and Y have joint PDF f (x,y) = 4e-2(x+~)for 0 < x < oo and 0 < y < oo,\nand zero otherwise.\n1. Find the CDF of W = X +Y.\nSolution to (I): The CDF of W = X + Y can be obtained by defining\nZ = X and finding the joint distribution of W and Z, and then integrating\nout Z to obtain the marginal of W. We first define the transformation of\nx and y to obtain w and x and find its inverse:\nThe Jacobian is really easy to get once we've written g(x,y) as a linear\ntransformation in matrix notation:\nSo, since g(x,y) is linear (and, hence, monotonic), we can just use the\ntransformation technique:\n\nwhere 1.1 denotes the absolute value of the determinant operator. Now,\nto get the CDF we need to get the marginal of W and then integrate,\ntaking into account the bounds on X and Y inducing bounds on W of\nZ < W < m :\nNow that we have the marginal, we use integration by parts to obtain the\nCDF:\nFw (w) = 1- (2w + l)e-2W\nAlternatively, we could have just used the convolution formula adapted to\nthis problem:\nf m\nwhich would have yielded the same solution:\nwhich is the same integral we performed above.\n2. Find the joint pdf of U = $ and V = X.\nSolution to (2): We use similar methods to those in part (1). Define g(x,y)\nand g-l(u, v):\n\nwith its corresponding Jacobian:\nwhich has a determinant of I JI = 3. Since x > 0 and y > 0, we can use\nthe transformation methods without worrying about multiple roots:\nSo, we have obtained the joint pdf.\n3. Find the marginal pdf of U .\nSolution to (3): The marginal pdf of U can be obtained by integrating out\nv:\nFinally, just to check to make sure that we have a valid PDF, we can\nintegrate to verify that it does, in fact, integrate to one:"
    },
    {
      "category": "Assignment",
      "title": "Problem Set #5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/1e1b29763c6edb4c01c695e0e376c5e4_MIT14_30s09_pset05.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #5\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, March 31, 2009\nQuestion One\nThe convolution formula is a useful trick when we are interested in the sum or average\nof independent random variables. In the last problem set, we dealt with the random\nvariable X, below.\ne-\"\nforx > 0\nf (4= 0\nforx<O\nNow, suppose that X = XI = X2= . . . = Xkare independent, identically distributed\nrandom variables.\n1. Using the convolution formula, determine the PDF of fi = ;(x1+ X 2 ) Hint:\nDefine Zl = X1 and Z2= XI +X2 and then use the transformation method to\nget back to Y2from 2 2 .\n2. Compute its expectation: E[Y2].\n3. Using the convolution formula, determine the PDF for & = ;(XI +X2 +X3).\nHint: Use the hint from part 1 to define Z3 = X1 + X2+ X3 and perform a\nconvolution with X3 and Z2 to transform the problem into Z2 and Z3.\n4. Compute its expectation: IE[Y3].\n5. Using the convolution formula, determine the PDF for Yk= :(x1+X2+. - +\nXk) = :ck\nTry to determine a pattern from part 1 and part 3\nZ=IXk. Hint:\nusing the methods from their hints.\n6. Compute its expectation: E[Yk].\n7. What does this tell us about the mean of a sample of size Ic? Is this property\nspecific to the exponential distribution? Explain.\n\nQuestion Two\n(BainIEngelhardt, p. 228)\nSuppose that XI, X2, . . . ,Xkare independent random variables and let Y, = ui(Xi)\nfor i = 1,2,.. . ,k. Show that Yl, Y2, . .. ,Yk are independent. Consider only the case\nwhere Xi is continuous and yi = ui(xi) is one-to-one. Hint: If xi = wi(yi) is the\ninverse transformation, then the Jacobian has the form\nFor extra credit, prove the Hint about the Jacobian.\nQuestion Three\nMoved to a later problem set.\nQuestion Four\nOrder statistics are very useful tools for analyzing the properties of samples.\n1. Write down the general formula of the pdf and cdf for the kth order statistic of\na sample of size n of a random variable X with CDF F'(x).\nQuestion Five\n(BainIEngelhardt p. 229)\nLet X1 and X2be a random sample of size n = 2 from a continuous distribution\nwith pdf of the form f (x) = 2x if 0 < x < 1and zero otherwise.\n1. Find the marginal pdfs of the smallest and largest order statistics, Yl and Y2.\n2. Compute their expectations, IEIYl] and IE[&].\n3. Find the joint pdf of Yl and Y2.\n4. Find the pdf of the sample range R = Y2 - Yl.\n5. Compute the expectation of the sample range, IE[R].\n\nQuestion Six\n(BainIEngelhardt p. 229)\nConsider a random sample of size n from a distribution with pdf f(x) = x 1\n-if\n15 x < 00; zero otherwise.\n1. Give the joint pdf of the order statistics.\n2. Give the pdf of the smallest order statistic, Yl.\n3. Compute its expectation, EIYl], or explain why it does not exist.\n4. Give the pdf of the largest order statistic, Y,.\n5. Compute the expectation, IE[X],of a single draw X from f (x). Does the integral\ndiverge? What does that say about the existence of E[Y,]? Explain.\n6. Derive the pdf of the sample range, R = Y, - Yl, for n = 2. Hint: Use par-\ntial fractions, searching on Yahoo for \"QuickMathn will help you get the partial\nfractions via computer:\nhttp://72.3.253.76:8080/webMathematica5'/quickmath/page.jsp ?sl=algebra&s2=partialfractions&s3= basic\n7. Compute its expectation, E[R], or explain why it does not exist.\n8. Give the pdf of the sample median, Y,, assuming that n is odd so that r =\n(n+ 1)/2 E N.Express the pdf as a function of just r and y, (eliminate all n's\nand k7s).\n9. Compute its expectation, E[Y,], or explain why it does not exist."
    },
    {
      "category": "Assignment",
      "title": "Problem Set #5 — Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/03ef5da497d3f4d85c8ca073cbb4eec3_MIT14_30s09_sol_pset05.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nProblem Set #5 - Solutions\n14.30 - Intro. to Statistical Methods in Economics\nInstructor: Konrad Menzel\nDue: Tuesday, March 31, 2009\nQuestion One\nThe convolution formula is a useful trick when we are interested in the sum or average of\nindependent random variables. In the last problem set, we dealt with the random variable\nX, below.\ne-\"\nforx > 0\nf (4= 0\nforx<O\nNow, suppose that X = X1 = X2 = - .- = XI, are independent, identically distributed\nrandom variables.\n1. Using the convolution formula, determine the PDF of & = (xl+X2). Hint: Defilze\nZl = X1 and Z2 = X1+X2 and then use the transformation method to get back to Y2\nfrom Z2.\nSolution to 1: To use the convolution formula, we need the joint PDF of X1 and\nX2 and x2 as a function of y2 and xl. The function is x2 = 2y2 - xl. Also, since\nthey are independent, we can just construct the joint PDF by multiplying the two\nmarginals, fxl(xl) and fx2(x2). This gives a joint PDF of f (xl, x2) = e-(x1+x2)\nfor xl > 0 and x2 > 0 and zero otherwise. The convolution formula adapted to\nthis problem (taking into account the limits) is (where we take into account the\nchange in variables formula for x2 as a function of xl and y2 using the Jacobian)\n2. Compute its expectation: IE[Y2].\n\nSolution to 2: To compute the expectation, we use the standard formula for\ncontinuous random variables:\nThis integral must be computed using two iterations of integration by parts.\nAlternatively, we could have used the properties of expectations (no convolution\nnecessary) to obtain\n3. Using the convolution formula, determine the PDF for & = ;(XI +X2+ X3). Hint:\nUse the hint from part 1 to define Z3 = XI +X2+X3 and perform a convolution with\nX3 and Z2 to transform the problem into Z2 and Z3.\n\nSolution to 3: Apply the same method to the results from part I, where we\nobtained fY2(y2).We write the joint PDF of XI, X2,and X3 as\nWe'll take a slightly different approach for this problem, in order to help us solve\npart 5 later. Define Z2 = XI +X2 and Z3 = Xl +X2 +X3. Now, we can ignore any\nJacobian transformation and directly apply the convolution formula. We can first\nsolve for 22's distribution by only using the convolution on the joint distribution\nof XI and X2.\nNow, we use the convolution on the joint distribution of Z2 and X3 to obtain the\ndistribution of Z3:\nBut, we were interested in Y3, not Z3. SO,we perform a simple continuous inverse\ntransformation of random variables using Z3 = 3Y3:\n4. Compute its expectation: IE[Y3].\n\nSolution to 4: Very easily we can apply the properties of expectations to determine\nagain that IE[Y3]= 1. However, we can also determine this using the convolution\nformula. What we should have learned from part 2 was that all of the leading\nintegration by parts terms will not matter as yGey = 0 for y = oo and for y = 0\nfor any k E N.So, we only need to worry about the last term in the integration\nby parts sequence, which ends up being eP3y3 (verify it if you like).\n5. Using the convolution formula, determine the PDF for Yk = i(xl+X2+ ..+Xk) =\nX k . Hint: Trg to determine a pattern from part 1 and part 3 using the methods\nfrom their hints.\nSolution to 5: We use the convolution formula using the sequence determined from\npart 3. We define more partial sums Z1 = XI, Z2 = X1+X2, Z3 = X1 +X2+X3,\n... , Zk = c:=,\nXi. This allows us to easily construct the inverse functions for\nX's as function of 2 ' s as they are just the difference between adjacent 2's. This\ngives the following Jacobian:\nwhich, conveniently has a determinant of 1. So, we can just ignore the Jacobian\ncomponent. We now write the joint distribution:\nSince the joint distribution of all x's is just a function of zk, we would say that\nxk is a sufficient statistic for the distribution of the sum of k independent x's.\nNow, all we need to do is integrate out each of xl through xk-1 in order to get the\nmarginal of zk. F'rom part 3, we learned that the convolution will yield:\nand\n\nwhich, if repeated, will yield the general formula for Zk:\nwhich, upon applying the inverse transform method for Zk = kYk:\nwhich is what we were looking for. Interestingly enough, this converges to a\nNormal or Gaussian distribution as we send k to infinity. This is just a special\ncase of a more general theorem: the Central Limit Theorem. Below we see a\nplot of the convergence of the mean of k random draws from the exponential\ndistribution to the Normal distribution:\nConwrgence of Sample Mean of i.i.d. Exponential RVs to Normal\n-Normal approx. k=10\n2.5\n-Normal approx. k=50\nhY\n1.5\n0.5\n-\nI\nI\nI \\ \\?%F\n---\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\n6. Compute its expectation: IEIYk]\nSolution to 1: See part 4. The expectation is 1. :)\n7. What does this tell us about the mean of a sample of size k? Is this property specific\nto the exponential distribution? Explain.\nSolution to 7: The mean of an i.i.d. (independent and identically distributed)\nsample of size k is the same as the expectation of a single draw. What this means\n\nis that the average of a sample of size k is an unbiased estimate of the average or\nmean of a distribution.\nThis property is not specific to the exponential distribution. You may have not\nnoticed this through all of the integration, but if you computed the expectation\nusing the properties of the expecation operator, you would have recognized that\nyou didn't use any properties of the exponential distribution to discover this.\nQuestion Two\n(BainIEngelhardt , p. 228)\nSuppose that XI, X2,. . . ,Xk are independent random variables and let Y, = ui(Xi) for\ni = 1,2,.. . ,k. Show that Yl, Y2,.. . ,Yk are independent. Consider only the case where Xi is\ncontinuous and yi = ui(xi) is one-to-one. Hint: If xi = wi(yi) is the inverse transformation,\nthen the Jacobian has the form\nk\n.\nFor extra credit, prove the Hint about the Jacobian.\nSolution: We can write Xi = wi(Yl,Y2,...,Yk) where wi ( 9 ) is the inverse function of\nui(.), i.e. wi(.) = uil(-). Since ui is only a function of Xi, the inverse transform\nwill only be a function of Y,, or Xi = wi(Y,). With this intuition, we can show the\nindependence by showing that pdfs can be factored:\nWe now apply the transformation method:\nwhere\nsince each wi is only a function of yi and not y-i. So, all of the off diagonal derivatives\nare zero. Thus, the Jacobian can be easily computed since we have a diagonal matrix:\nk\nd\nJ = ni=l &wi (yi)-\n\nWith this fact, we can now substitute in all of the pieces:\nwhere we use the independence of the X's and the Hint about the Jacobian in the first\nline, the absolute value of a product is equal to the product of the absolute values in\nthe second line, commutative and associative properties of multiplication in the third\nline, and the definition of the transformation of a single random variable in the last\nline. So, Yl, ...,Ykare independent and we are done.\nQuestion Three\nMoved to a later problem set.\nQuestion Four\nOrder statistics are very useful tools for analyzing the properties of samples.\n1. Write down the general formula of the pdf and cdf for the kth order statistic of a sample\nof size n of a random variable X with CDF Fx(x).\nSolution to 1: The general formula for the kth order statistic, Yk,with pdf f ( x )\n( f ( x ) > 0 on a < x < b and zero otherwise) and cdf F ( x ) is:\nn!\ng k ( Y k ) = (k - I)!(n- k)! [F(Y~)]\"'[I - ~ ( y k ) ] ~ - '\nf (yn)\nif a < yk < b and zero otherwise. The marginal cdf can be written as\nQuestion Five\n(BainIEngelhardt p. 229)\nLet X1 and X2 be a random sample of size n = 2 from a continuous distribution with\npdf of the form f ( x )= 2x if 0 < x < 1 and zero otherwise.\n\n1. Find the marginal pdfs of the smallest and largest order statistics, Yl and Y2.\nSolution to 1: The marginal pdfs of the smallest and largest order statistics from\na sample of size n = 2 can be derived by using the marginal pdf formula, but we\nfirst need the CDF of X:\nNow, we use the marginal pdf formula:\nand\n2. Compute their expectations, EIYl] and E[&].\nSolution to 2: We apply the formula for the expectation of a random variable:\nSo, the expectation of the first order statistic is .\nFor the second (maximal)\n\norder statistic, we get\nFortunately, we find the expectation of the maximal order statistic to be larger\nthan the minimal (or first) order statistic.\n3. Find the joint pdf of Yl and Y2.\nSolution to 3: The joint pdf of Yl and Y2 can be obtained from the pdf f (x) (the\njoint pdf can be written as g(yl, ...,y,) = n!f (yl). ..f (9,) for n independently\nsampled observations from the distribution defined by f (x)) taking into account\nthe permutations of yl and y2:\n4. Find the pdf of the sample range R = Y2 - Yl.\nSolution to 4: The pdf of the sample range is just a transformation of the joint\nPDF, similar to all of the convolutions that we've been doing. Consider the inverse\ntransforms: Yl = Yl and Y2 = R + Yl. Then we can use the transform methods:\nwhere J = 1\n1 = 1 So, applying the formula for the joint pdf from part 3;\nwe get:\n~ Y I , R ( Y ~ , = 8 ~ 1 ( ~\n+ ~ 1 )\nwhich we now use to integrate out yl to get the marginal of R. We proceed,\npaying careful attention to the change in bounds (draw a picture to convince\n\nyourself-first with Yl and fi and then with R and Yl)\n5. Compute the expectation of the sample range, E[R].\nSolution to 5: Compute it:\nIt is worth noting that the expectation for the sample range is equal to the differ-\nence between the expected first and last order statistics (minimal and maximal\norder statistics).\nQuestion Six\n(BainIEngelhardt p. 229)\nConsider a random sample of size n from a distribution with pdf f (x) = -$if 1 5 x < m;\nzero otherwise.\n1. Give the joint pdf of the order statistics.\nSolution to 1: The joint pdf can be represented as a relabeling of the original\njoint pdf of XI through X,, the random variables representing the sample.\n\nIn particular, we can write:\n2. Give the pdf of the smallest order statistic, Yl.\na Solution to 2: The pdf of the smallest order statistic is the PDF when we integrate\nout all of the other order statistics. We already have a formula for this, so we'll\nuse it, rather than deriving it all over again. We use k = 1 and n:\nn!\ngk (yk) = (k - I ) ! ( n- k ) ! [F(Y~)I\"'\n[l- F ( Y ~ ) ] \" - ~\nf (yx)\n3. Compute its expectation, IEIY1], or explain why it does not exist.\nSolution to 3: Again, we have another integration to practice the formula for the\nexpectation of a random variable using our answer from part 2:\n4. Give the pdf of the largest order statistic, Yn.\n\nSolution for 4: The pdf for the largest order statistic is computed from the same\nformula as for the smallest order statistic:\nn!\ngk(Yk) = (k - l)!(n - k ) ! ['(yk)lk-'\n[l- ~ ( y k ) ] ~ - ~\nf (yk)\n5 . Compute the expectation, IE[X],of a single draw X from f (x). Does the integral\ndiverge? What does that say about the existence of E[Yn]? Explain.\nSolution to 5:\n= [logXIS\"\n= 00-0\nE[X] = co,\nor, in other words, the integral diverges. This suggests that at least one order\nstatistic cannot have an expectation, even though the smallest order statistic did\nsince the expectation of X could be constructed from the order statistics as well\nby computing the expectation of each and then average over all n order statistics.\nBy a bounding argument, we can say that since the smallest order statistic has\nan expectation, and the total expectation does not exist for X, then the largest\norder statistic must not have a finite expectation. While it would be possible\nfor multiple order statistics to have nonexistent expectation, I do not determine\nwhich order statistic is the dealbreaker. Feel free to tinker with the formulas to\nfigure it out for yourself.\n6. Derive the pdf of the sample range, R = Yn -Y', for n = 2. Hint: Use partial fractions,\nsearching on Yahoofor \"QuickMath\" will help you get the partial fractions via computer:\nhttp://72.3.253.76:8080/webMathematica3/quickmath/page. jsp ?s1=algebra&s2=partialfractions&s3=\nSolution to 6: We again define two random variables. Call them S = Yl and\nR = Yn -Yl and the inverse transforms of S = Yl and Y2 = R +S. The joint pdf\nhttp://www.quickmath.com/webMathematica3/quickmath/page.jsp?s1=algebra&s2=partialfractions&s3=basic\n\nfrom part 1can now be used:\nWe use the transformation formula, noting that the Jacobian has a determinant\nwhich we can solve very painfully via partial fractions, unless you use a computer\nlike this great online service I found: http: //72.3.253.76:8080/webMathematica3/quickmath/pa\nThis is the partial fraction decomposition:\nwhich we can now integrate. The solution we obtain for the pdf is\nwhere r > 0. The PDF of the sample range and the first and second order\nstatistics in a sample of size n = 2 are plotted below, and compared to the kernel\nestimates from 1million samples of size n = 2 to benchmark the theory.\n.*\n*A web site I found to do this is: http://www.quickmath.com/webMathematica3/\nquickmath/page.jsp?s1=algebra&s2=partialfractions&s3=basic\n\nKernel and Analytic PDFs\n-fx(x)= l/x2 sampling distribution (kernel)\n-gl(yl) first order statistic (kernel)\n-g2(y2)second order statistic (kernel)\n-fR(r) sample range (kernel)\n-fx(x)= l/x2 sampling distribution (analytic)\n-gl(yl) first order statistic (analytic)\n1 -g2(y2)second order statistic (analytic)\n~\n~\n-fR(r) sample range (analytic)\n7. Compute its expectation, IE[R],or explain why it does not exist.\nSolution to 7: The expectation of the range cannot exist as the expectation of the\nmaximal order statistic does not exist, and E[R] = E[&] - EIYl]. Even though\nIE[K]exists, we need both to exist to compute it.\n8. Give the pdf of the sample median, Y,,assuming that n is odd so that r = (n+1)/2 E N.\nExpress the pdf as a function of just r and y, (eliminate all n's and k's).\nSolution to 8: The sample median is the order statistic with r = k = (n+ 1)/2.\nWe can compute this in the same way as before, using the formula:\nn!\ng'(yr)\n= (r -\n- r)!IF(y,)Ir-l [ I - ~ ( y , ) l ~ - ~\nf(y,)\n(27-- I ) ! (yr - I)'-'\nST ( Y T )\n= [(r- 1)!12\n9:\n9. Compute its expectation, E[Y,], or explain why it does not exist.\n\nSolution to 9: We will attempt to compute the expectation:\n-\n\" (y. - l).-l\n-\n(2r - 1 ypl dyr\n[(r- I ) ! ]\n--\n( 2 - 1 ) [(--;(Yir-\n1Y)\" -\n[(r- I ) ! ]\n2 ~ - 1\n(27-- I ) !\n1 (y. -\n= [[,\n- l)!I2(-G\n:\n.\n\n+\n2r - 1 (yr -\nL a - 7 Yr2'\ndY.1\n1\"Y - 1) (\n(27-- 1\n( y - 1)-l\nr\n[(r- 1)!12\n3:.\n)\nwhich we now solve for E[Y,]:\nA few numerical checks will yield that this is, in fact, the correct formula: for\nr = 2, we get a median of 3 and for r = 3, we get a median of 2.5. For r = 5, the\nmedian is 2.25."
    },
    {
      "category": "Exam",
      "title": "Exam I",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/487dd6ce78798890c420fa1c2dcb1a43_MIT14_30s09_exam01_09.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Exam I\nSpring 2009\nInstructions: This exam is closed-book and closed-notes. You may use a calculator. Please read\nthrough the exam first in order to ask clarifying questions and to allocate your time appropriately. In\norder to receive partial credit in the case of computational errors, please show all work. You have\napproximately 85 minutes to complete the exam. Good luck!\n1.(20 points) Short Questions True, false, or uncertain? Always give a brief explanation or a simple\ncounter-example.\n(a) If X and Y are independent, then the support of the joint distribution fXY (x, y) of the random\nvariables X and Y is rectangular.\n(b) A continuous p.d.f. can never take a value greater than 1.\n(c) The following function is a c.d.f. of a random variable:\n\nif x < 1\n\n0.2\nif 1 ≤ x < 2\nG(x) = 0.2x\nif 2 ≤ x < 4\n\nif x ≥ 4\n(d) The function in part (c) is a c.d.f. of a discrete random variable.\n2. (15 points) Two airlines, Sun Express, and Commuter Jet, are serving four major US airports. We\nare interested in the reliability of each of these airlines, and we have the following data on the\nprobability of a significant delay (20 minutes or more) for departing flights from each of these cities.\nAtlanta\nChicago\nPhoenix\nSeattle\nSun Express\nCommuter Jet\n% delayed\n# flights/day\n% delayed\n# flights/day\n12%\n11%\n30%\n25%\n5%\n5%\n25%\n20%\n(a) Given these numbers, and all else equal, which of the two airlines appears to have a better\nrecord?\nA website reports the overall on-time rate for each airline which is defined as one minus the probability\nof a significant delay for a randomly chosen flight by that airline, where each flight departing from any\nof these four cities may be chosen with equal probability.\n(b) Use the law of total probability to calculate the on-time rate for each of the two airlines. Based\non your result, which airline would you prefer if you made your choice based only on the\ninformation from the website?\n(c) How do you reconcile your result from (b) with your answer in (a)? Discuss the relationship in\nterms of conditional and unconditional probabilities, and feel free to draw parallels with\nexamples discussed in class.\n\n3. (15 points)\n(a) Suppose\nfXY (x, y) =\ncx2y2\nif 0 ≤ x ≤ 3 and 0 ≤ y ≤ 3\notherwise\nWhat does c have to be so that fXY (x, y) is a proper joint p.d.f. of two random variables X\nand Y ? Given the correct value of c, are X and Y independent?\n(b) Now let's modify the problem a little bit: suppose\nbx2y2\nif 0 ≤ x ≤ y ≤ 3\ngXY (x, y) =\notherwise\nDraw the support of gXY (x, y) in the (x, y) plane (i.e. the area in which the function is strictly\npositive). What does b now have to be for gXY (x, y) to be a p.d.f.? Are X and Y still\nindependent? Why or why not?\n4. (30 points)\nYou are a miner during the Alaska Gold Rush of the 1890s, and you are prospecting a tract of land\nalong a small creek in the forests and want to determine whether you are likely to find gold there. It is\ncostly to rush back to town to register a formal claim on the lot which would allow you to exploit it, so\nyou want to be at least 60% certain that there is gold in the ground. Let G be the event that there is\ngold on the specific tract you are surveying, and suppose that without additional information, the\nprobability of finding gold is P (G) = 0.1.\nAfter years out in the wild, you have learned that there are are some important signs to look for: if there\nis gold, the rocks below the ground are darker than usual, the bushes have shorter roots, the cranberries\nyou find in the place have a sweeter taste, and the first moose you'll see will wag its tail to the right. If\nthere is no gold, you may still observe any of these indicators with some probability, to be specific:\nB\nP (B|G)\nP (B|GC )\nMoose wags tail to the right\n1.0\n0.7\nDark rocks\n1.0\n0.4\nShort roots\n1.0\n0.5\nSweet cranberries\n1.0\n0.3\nRegardless of whether there is gold or not, the pieces of evidence are independent of each other. Clearly,\nif you observe that either of the above is not true, the tract contains no gold for sure, and you should\nmove on.\nHowever, there is fierce competition: other diggers are also surveying the same area, and the tract will\nbe awarded to the first person to show up at the land registry and pay the official fee. Therefore, you\nwant to base your conclusions on as few pieces of evidence as possible and rush to town as soon as you\nare certain enough that there is gold, i.e. as soon as P (G|B) ≥ 0.6.\n(a) State Bayes' Law. Derive a formula for the posterior P (G|B) that depends only on P (G) and\nP (B|G)\nthe ratio L = P (B|GC ) . Does P (G|B) increase or decrease in L?\n(b) Compute L for each of the different pieces of evidence listed in the table. Given independence,\nhow do you calculate the ratio L for combinations of pieces of evidence, e.g. B=\"dark rocks and\nshort roots\"?\n(c) Given the values of L, in which order should you check for the different indicators? If there is\ngold in the ground, what is the minimum number of pieces of evidence that you have to check\nbefore P (G|B) ≥ 0.6?\nNow fast forward to the year 2009, and suppose that you are the chief prospector of a multinational\nmining company looking for gold in northern Canada. You can drill the ground at N different spots and\nhave the samples analyzed in a lab. For a given sample, a chemical test gives a positive result with\n\nprobability p if there is gold, and if there is no gold, the probability of a positive result is 1 -p. The\ntest is independent across the N samples. Define the event B=\"x out of N samples produced a positive\nresult.\"\nP (B|G)\n(d) Depending on N and x, what is the probability P (B|G)? What is the ratio L(N, x) := P (B|GC ) ?\n(e) Suppose p = 0.8, and we obtained a positive test result for 4 out of 12 samples. What is\nL(12, 4)? Given your result from (a), what is the posterior probability P (G|B)?\n(f) Suppose instead that we obtained a positive test result for x samples, and a negative result for\nx + 4 samples (so the total number of samples is 2x + 4). How does your answer differ from (e)?\n5. (10 points) Is the following statement true, false, or uncertain: \"If P (A|B) > P (A) and\nP (A|C) > P (A), then P (A|BC) > P (A)?\" Construct a simple numerical counterexample with a state\nspace S = {s1, s2, s3, s4}, specifying the probability for each of the 4 outcomes, and defining events A,\nB, and C."
    },
    {
      "category": "Exam",
      "title": "Exam II",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/437ceb34efa23a56f7fb7b47b837574d_MIT14_30s09_exam02_09.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Exam II\nSpring 2009\nInstructions: This exam is closed-book and closed-notes. You may use a calculator. Please read\nthrough the exam first in order to ask clarifying questions and to allocate your time appropriately. In\norder to receive partial credit in the case of computational errors, please show all work. You have\napproximately 85 minutes to complete the exam. Good luck!\n1.(15 points) Short Questions Answers should be brief, but complete.\n(a) Confirm or correct the following statement: for any random variables X1 and X2,\nE[X1 + X2] = E[X1] + E[X2] and Var(X1 + X2) = Var(X1) + Var(X2).\n(b) Suppose X ∼ U[0, 1], and Y = -λ\n1 log(1 -X). Find the c.d.f. of Y .\n(c) Briefly explain the relationship (1) between the binomial distribution and the standard normal\ndistribution, and (2) between the binomial distribution and the Poisson distribution for a large\nnumber n of trials in the binomial experiment.\n2. (20 points) We are investigating the duration of unemployment for workers who just lost their jobs,\nand unemployment durations T are distributed according to the p.d.f.\nfT (t; λ) =\nλe-λt\nif t ≥ 0\notherwise\nfor some λ > 0.\n(a) Calculate E[T ] and E[T 2] for a fixed value for λ.\n(b) Calculate Var(T ) for a given λ.\nSuppose now that there are two different types of workers losing their jobs: there is a proportion\npS = 0.2 of skilled workers which are in high demand and tend to find a new job easily, and a share\n(1 -pS) of unskilled workers U that tend to be unemployed for a longer period. For skilled workers, the\ndistribution of unemployment durations measured in weeks is given by the p.d.f. stated above with\nλS = 0.32, and for unskilled workers, we have λ = λU = 0.08. In other words, we can treat λ as a\nrandom variable which takes the values λS and λU with probabilities pS and 1 -pS, respectively, and\nthe p.d.f. fT (t; λ) corresponds to the conditional p.d.f. of T given λ.\n(c) Calculate the unconditional expectation E[T ] of length of an unemployment spell.\n(d) Calculate the (unconditional) variance Var(T ) of unemployment duration.\n(e) State the joint p.d.f. fλ,T of (λ, T ), and calculate the conditional probability P(λ = λS|T = 10).\nHow does this compare to the unconditional probability P(λ = λS) = pS? Intuitively, how do you\nexplain this difference?\n3. (10 points) Suppose you have the following information about the joint distribution of two random\nvariables X and Y : Their expectations are E[X] = 2 and E[Y ] = 1.5, and the variances are Var(X) = 4\nand Var(Y ) = 9, respectively. Also, it is known that the correlation coefficient is (X, Y ) = 1\n3 .\nCalculate the expectation of the product E[XY ].\n4. (30 points) Suppose X ∼ N(0, σ2), and we define\n\n-1\nif X < -1\nY = g(X) :=\nif |X| ≤1\n\nif X > 1\n\n(a) Given σ2, what is the p.d.f. of Y ?\n(b) Calculate the expectation E[Y ] and the variance Var(Y ) as a function of σ2 .\n(c) What would σ2 have to be in order for the variance to be Var(Y ) = 0.05?\nNow, suppose instead that X is from some unknown symmetric distribution, i.e. with a c.d.f. satisfying\nFX(x) = 1 -FX(x), and suppose that E[X] = 0 and Var(X) = σ2 . Also given this new random\nvariable, Y = g(X) is defined as above.\n(d) Find the expectation E[Y ] and the variance Var(Y ) in terms of values of the c.d.f. FX(x).\n(e) Use Chebyshev's Inequality\nVar(X)\nP(|X -E[X]| > ε) ≤\nε2\nto give the largest value of σ2 which ensures Var(Y ) ≤ 0.05 without any further knowledge on the\ndistribution of X. How does this compare to your answer in (c)? Hint: Start by rewriting the\nleft-hand side Chebyshev's Inequality in terms of the c.d.f. of X.\n5. (15 points) Suppose you observe a sample X1, . . . , Xn of i.i.d. random variables, where the Xis are\nexponentially distributed with failure rate λ for each i, i.e. Xi has marginal p.d.f.\nλe-λx\nif x ≥ 0\nfX(x) =\notherwise\nWe are interested in the maximum of the sample, Yn := max{X1, . . . , Xn}.\n(a) Give the cumulative distribution function (c.d.f) FYn (y) of Yn.\n(b) Now suppose λ = 1. Derive the c.d.f. FY n (y) of Y n := max{X1, . . . , Xn} -log n, and show that for\nn →inf,\nlim F (y) = e -e -y\nn→inf\nYn\n\nTa\nble\nof c\numul\nativ\ne ar\neas\nunde\nr th\ne st\nanda\nrd n\norma\nl di\nstri\nbuti\non.\nImage by MIT OpenCourseWare.\n\nTab\nle\nof\ncum\nula\ntiv\ne a\nrea\ns u\nnde\nr t\nhe\nsta\nnda\nrd\nnor\nmal\ndi\nstr\nibu\ntio\nn.\nImage by MIT OpenCourseWare."
    },
    {
      "category": "Exam",
      "title": "Exam III",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/275c335ed43005ad0fea614233c0a676_MIT14_30s09_exam03_09.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Exam III\nSpring 2009\nInstructions: This exam is closed-book and closed-notes. You may use a calculator and a cheat sheet\nconsisting of 1 page of notes or formulae. Please read through the exam first in order to ask clarifying\nquestions and to allocate your time appropriately. In order to receive partial credit in the case of\ncomputational errors, please show all work. You have approximately 85 minutes to complete the exam.\nGood luck!\n1.(15 points) Short Questions True/false? Explain, and if false, give a correct version of the\nstatement.\n(a) Given a single observation X, the most powerful test of the simple hypotheses H0 : θ = θ0 against\nHA : θ = θA for fixed values θ0 and θA rejects for small values of the likelihood ratio f0 (X) if\nfA(X)\nθA < θ0, and for large values of the likelihood ratio if θA > θ0.\n(b) In order to construct a hypothesis test of H0 : θ = θ0 versus HA : θ = θA based on a statistic\nT (X1, . . . , Xn), and with size α = 0.1, we only have to know the distribution of T (X1, . . . , Xn)\nunder the null hypothesis.\n(c) An estimator θˆn is always consistent if Var(θˆn)\n0 as the sample size n →inf.\n→\n2. (25 points) Suppose you observe a random variable X ∼U[-θ, θ]. You have only this one single\nobservation.\n(a) Find a method of moments estimator for θ. Is this estimator unbiased?\n(b) Derive FY (y), the c.d.f. of Y := X2 .\n(c) Use your result from part (b) to construct a 1 -α = 0.9 confidence interval for θ based on Y .\nDoes it matter whether you had an unbiased estimator for θ?\n3. (35 points) You have an i.i.d. sample X1, . . . , Xn, where Xi is exponentially distributed with\nfailure rate λ, so that the p.d.f. of Xi is given by\n|\nλe-λx\nif x ≥0\nfX(x λ) =\notherwise\nSuppose we observe the sample {0.37, 2.58, 2.04, 2.32, 2.88, 0.29, 2.41, 0.16} of 8 observations, which has\nmean X n = 1.63 and sample variance S2 := 1 P8\n(Xi -1.63)2 = 1.325. Recall that for an exponential\nn\ni=1\ndistribution with failure rate λ, Eλ[X] = λ\n1 , and Varλ(X) = λ\n2 .\n(a) Write down the likelihood function for λ and a sample X1, . . . , Xn.\n(b) Derive the maximum likelihood estimator and compute the estimate for the given sample.\n(c) Is the maximum likelihood estimator for λ unbiased? If not, can you sign its bias? Hint: use\nJensen's Inequality.\nNow, suppose we are interested in testing the hypothesis H0 : λ = 0.4 against HA : λ = 0.2. Otherwise\nthe setup is the same as before. Hint: You don't have to solve parts (a)-(c) before doing the remaining\nquestions.\n\n(d) Derive a most powerful test of the hypothesis H0 : λ = 0.4 against HA : λ = 0.2 for a given\nsignificance level α. Describe the critical region in terms of the sample mean, X n. Hint: for this\npart of the problem you don't have to derive the critical level explicitly.\n(e) It can be shown that for n i.i.d. draws X1, . . . , Xn from an exponential distribution with failure\nrate λ, Yn := 2λ(X1 + X2 + . . . + Xn) follows a χ2 distribution with 2n degrees of freedom (this\nresult is far from obvious and the math needed to derive this is beyond the scope of this class). In\norder to achieve a probability of a type-I error α = 0.1, how do you choose the critical value on\nthe sample mean in the test from part (d)? Do you reject the null hypothesis for the sample of\nsize 8 given above?\n4. (15 points) You are conducting a randomized trial which is supposed to determine whether a new\ndrug lowers blood pressure. Suppose, you observe an i.i.d. sample of n1 outcomes for the treatment\ngroup which gets the active ingredient, X1, . . . , Xn1, and an i.i.d. sample of n2 observations Z1, . . . , Zn2\nfor the control group which is administered a placebo. The two samples are mutually independent and\nXi ∼N(μX, σ2 ) and Zi ∼N(μZ, σ2 ), where σ2 and σ2 are known.\nX\nZ\nX\nZ\n(a) Suppose you want to test H0 : μX = μZ against HA : μZ > μX. Give the variance of the difference\nin sample means X n1 -Z n2, and construct a test based on X n1 -Z n2 at a significance level\nα = 0.05.\n(b) Derive the power of this test as a function of μX -μZ. How does the power depend on the\n\nvariance of Xn1 -Zn2?\n(c) Suppose you can allocate a total of n subjects to a treatment group of size n1 = γn and a control\ngroup of size n2 = (1 -γ)n. Depending on the ratio c := σX , what is the optimal fraction γ of\nσZ\nsubjects you should allocate to treatment? If σ2 > σ2 , should you allocate more or less than half\nX\nZ\nof the n subjects to the treatment group?"
    },
    {
      "category": "Resource",
      "title": "Statistical Tables",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/1f87c9b9d001cc4eefd483f98e9cf2c2_MIT14_30s09_tool01.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nTa\nble\nof c\numul\nativ\ne ar\neas\nunde\nr th\ne st\nanda\nrd n\norma\nl di\nstri\nbuti\non.\nImage by MIT OpenCourseWare.\n\nTab\nle\nof\ncum\nula\ntiv\ne a\nrea\ns u\nnde\nr t\nhe\nsta\nnda\nrd\nnor\nmal\ndi\nstr\nibu\ntio\nn.\nImage by MIT OpenCourseWare.\n\nTable of upper percentiles of Student t dist\nributions - degrees of\nfreedom 1-34.\nImage by MIT OpenCourseWare.\n\nT\nab\nle\no\nf\nup\npe\nr\npe\nrc\nen\nti\nle\ns\nof\nS\ntu\nde\nnt\nt\nd\nis\ntr\nib\nut\nio\nns\n-\nd\neg\nre\nes\no\nf\nfr\nee\ndo\nm\n-7\n9.\nImage by MIT OpenCourseWare.\n\nT\nab\nle\no\nf\nup\npe\nr\npe\nrc\nen\nti\nle\ns\nof\nS\ntu\nde\nnt\nt\nd\nis\ntribut\nions -\ndegre\nes of\nfreedo\nm 80-1\n00, an\nd infi\nnity.\nImage by MIT OpenCourseWare.\n\nT\nab\nl\ne\n\no\nf\n\nu\np\np\ner\na\nnd\nl\now\ner\np\ner\nce\nnt\nil\nes\no\nf\nth\ne\nch\ni-\nsq\nua\nre\nd\ndi\nst\nri\nbution\n- deg\nrees o\nf free\ndom 1-\n34.\nImage by MIT OpenCourseWare.\n\nTable of upper and lower percentiles of the chi-squared\nd\nis\ntr\nib\nut\nio\nn\n-\nde\ngr\nee\ns\nof\nf\nre\ned\nom\n35-50\n.\nImage by MIT OpenCourseWare."
    },
    {
      "category": "Exam",
      "title": "Exam I, Spring 2008",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/ba0d6e92b940a082ceeae76382224e70_MIT14_30s09_exam01_08.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Exam I\nSpring 2008\nInstructions: This exam is closed-book and closed-notes. You may use a calculator. Please read\nthrough the exam first in order to ask clarifying questions and to allocate your time appropriately. In\norder to receive partial credit in the case of computational errors, please show all work. You have\napproximately 85 minutes to complete the exam. Good luck!\n1.(30 points) Short Questions\nDon't spend much time on these questions, a short answer to each suffices.\n(a) For a sequence of n independent trials, each of which can result in a \"success\" (with probability p)\nor a \"failure\" (probability 1 -p), what is the p.d.f. fX(x) of the total number x of successes? Be\ncareful about specifying the p.d.f. for all real numbers.\n(b) You are given the joint p.d.f.\nc exp\n(x + y)(x\ny)\nx\n[ 2, 2], y\n[ 2, 2]\nfXY (x, y) =\n\n{-\n-\n}\n∈-\n∈-\notherwise\nwhere c is a positive constant such that the density integrates to 1. Are X and Y independent?\n(c) A pregnant woman goes to her obstetrician complaining of visual disturbances. \"Don't worry\",\nher OB tells her, \"only a small fraction of miscarriages or other adverse events are preceded by\nvisual disturbances.\" Explain briefly, preferably using a formula, why the patient should be\nannoyed, not reassured.\nTrue/false/uncertain: Always give a brief explanation if the statement is true, or examples if the\nstatement is false or uncertain.\n(d) Two events based on the same realization of a physical randomization device (e.g. a single card\ndrawn from a deck of cards) can't be independent.\n(e) In principle, one can always recover the joint distribution of random variables given their marginal\ndistributions, although calculations can at times be difficult.\n\n2. (20 points)\n(a) Verify whether the the following function a valid CDF. If yes, draw a graph of the corresponding\nPDF.\n(b) Verify that the following function is a valid PDF and draw the corresponding CDF.\n3. (30 points) Lucy is a chimp living in a cognitive scientist's laboratory. She spends her days playing\ngames with letters, but doesn't attach any specific meaning to, nor does she have any preference for any\ngiven letter.\n(a) The scientist gives Lucy a box with 16 cubes, each of which has a letter printed on it. Some of the\nletters appear multiple times - more specifically, the letters are\nC IIII M NN O PP SSSS W\nLucy is then asked to arrange the cubes in a row. Reading the letters of the cubes, is the row\nmore likely to start with \"MISSISSIPPI\" or \"WISCONSIN\"? Hint: it may be more practical to\ncheck whether the ratio of the probabilities is greater than 1 instead of calculating both\nprobabilities, so you may be able to cancel many terms.\nC\numula\nt\ni\nv\ne\n\nd\ni\ns\nt\nr\ni\nb\nution function for problem 2a. by MIT OpenCourseWare.\nProba\nb\ni\nl\ni\nt\ny\n\nd\ni\nstribution function for problem 2b. by MIT OpenCourseWare.\n\n(b) It turned out that Lucy preferred to juggle around with the cubes or throw them at the\nexperimenter, so the scientist decides to replace them with a keyboard with 16 keys with the\nfollowing letters: C (1 key), I (4 keys), M (1 key), N (2 keys), O (1 key), P (2 keys), S (4 keys),\nand W (1 key) - just to be clear, the number of keys for each letter is the same as the number of\ncubes in the previous part. Lucy hits each key with equal probability. If she types a chain of 16\ncharacters, is it more likely to start with \"MISSISSIPPI\" or \"WISCONSIN\"?\n(c) In the experiment in (b), is the chain of 16 characters more likely to contain \"MISSISSIPPI\" or\n\"WISCONSIN\", starting at an arbitrary position of the sequence?\n4. (20 points) In many dry regions, crops are irrigated with circle irrigation: the water for irrigation\nis pumped up from a well at the center of the field and spread over the field. This is done by sprinklers\nwhich are mounted on a long straight pipe which moves like the arm of a clock over a circular area\naround the center. This means in particular that crops are planted only on a circle of a given radius R\n(the standard length for these systems is about 1\n4 mile) around the well. The total quantity of water\nused for irrigation is normalized to 1.\n(a) Suppose, there is a continuum of sprinklers along the pipe which dispense the same amount of\nwater at any given point in time, and the arm moves around the circle at a constant speed.\nPutting a system of straight coordinates (x, y) with the origin at the center of the circle (so that\nthe circle is given by the coordinates (x, y) such that x2 + y2 ≤R2), what is, up to a\nproportionality factor (i.e. no need to calculate complicated integrals), the joint p.d.f. of the\ncoordinate at which a random drop of water falls? Intuitively, what does this mean in terms of\nhow much water a given area of the field receives? Do any parts of the field receive more water\nthan others?\n(b) If you want to plant the same crop across the entire circle, you would want all plants to receive\nabout the same amount of water. You can control the distribution of water over the area through\nthe amount q of water discharged by the sprinkler at a distance r from the center given the\nposition of the pipe, as given by the angle ω formed between the pipe and a line from the center\nto a given point on the edge of the circle. How would you have to choose q(r, ω) if the system\nrotates at a constant speed?"
    },
    {
      "category": "Exam",
      "title": "Exam II, Spring 2008",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/bd7c63e68c81e810e5bb2ea177135bde_MIT14_30s09_exam02_08.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Exam 2\nSpring 2008\nInstructions: This exam is closed-book and closed-notes. You may use a calculator. Please read\nthrough the exam first in order to ask clarifying questions and to allocate your time appropriately. In\norder to receive partial credit in the case of computational errors, please show all work. You have\napproximately 85 minutes to complete the exam. Good luck!\n1. (24 points) Short Questions\nDon't spend much time on these questions, a short answer to each suffices.\n(a) Given a random variable X, define the standardization Z of X and derive its variance.\n(b) Suppose X 25 is the mean of a sample of n = 25 i.i.d. observations with Xi ∼ N(1, 4). What is the\nprobability that the sample mean X 25 is between 0.5 and 1.5?\nTrue/false/uncertain: Give a brief explanation (preferably using some algebra) if true, or try to correct\nthe statement if false.\n(c) Flights operated by Phoenix-based Sunshine Airlines have longer average delays at every major\nairport in the US than Seattle-based Air Grey Skies. Therefore, the expected delay of a randomly\nchosen flight by Sunshine Airlines is longer than that of a randomly chosen Air Grey Skies flight.\n(d) The Central Limit Theorem says that in a large sample of i.i.d. observations X1, . . . , Xn, the Xi's\napproximately follow a normal distribution.\n2. (20 points)\nSuppose X and Y are random variables which are not necessarily independent, and 0 ≤ p ≤ 1\n(a) Using only the definitions of variances and covariances, show that\nVar(pX + (1 - p)Y ) = p 2Var(X) + 2p(1 - p)Cov(X, Y ) + (1 - p)2Var(Y )\n(for this problem, you are not supposed to use properties of variances derived in class).\n(b) What is the variance of pX + (1 - p)Y in terms of the variances of X and Y and the correlation\ncoefficient %(X, Y )?\n(c) Suppose Var(X) = Var(Y ). Is the variance of pX + (1 - p)Y greater or less than that of X?\n(d) Now suppose that X and Y are scores from two different Math tests. You are interested in some\nunderlying \"math ability\", and the two scores are noisy (and possibly correlated) measurements\nwith E[X] = E[Y ] = μ, Var(X) = σ2 , Var(Y ) = σ2 , and Cov(X, Y ) = σXY . Instead of using only\nX\nY\none of the measurements, you decide to combine them into a weighted average pX + (1 - p)Y\ninstead. What is the expectation of this weighted average? Which value of p minimizes the\nvariance of the weighted average?\n\n3. (10 points)\n(a) According to Chebyshev's Inequality, how does the probability of the event (\n> ε)\nrelate to the variance Var(X) of the random variable X?\n|X - E[X]|\n(b) You and your friend are planning to meet on Inman Square at 7:30pm. Both of you try to be on\ntime, and the times at which each of you arrives are independent of another. Also assume that the\nstandard deviation σ of the arrival time (measured in minutes) is the same for both of you. What\ncan σ at most be so that with probability of at least 92 percent, none of you has to wait for the\nother for more than 10 minutes?\n4. (21 points)\nYou are working with a supercomputer back in the 1960s which operates using punch cards. For this\ntype of machines, a piece of code is punched into the cards, where a bit is read as \"1\" if a hole is\nstamped out in the corresponding position on the card, and otherwise it's read as \"0\".\nBefore you feed the code into the computer, another machine has to copy it on a different format of\npunch cards. This process does not work entirely error-free, and for a code of length n bits, the number\nX of copying errors is distributed as a Poisson random variable with arrival rate λ =\nn , i.e.\nX ∼ P\n¡\n¢\n.\nn\n(a) One way of thinking about the problem is as follows: when copying a code of n bits, for every bit,\nthere is a constant, but small, probability p that the copying machine flips a zero for a one and\nvice versa. If the copying errors are independent across different bits, what is the distribution of\nthe number of errors? If n is very large, what justifies the use of the Poisson distribution\nsuggested above instead? - please be as precise as you can.\nNow suppose the only copying error the machine can make is not to punch out the positions\ncorresponding to \"1\"s properly, e.g. because a piece of cardboard remains stuck in the hole, so that the\ncomputer will read it as a \"0\" instead of a \"1\". On the other hand all \"0\"s will be copied correctly.\nWe'll assume that in a code of length n, the number of \"1\"s Y follows a binomial distribution with the\nprobability of a \"1\" being p = 2\n1 .\n(b) Derive the expectation and the variance of the number X of copying errors for a code of length n.\nShow your work. Hint: Remember that for a Poisson random variable X with arrival rate λ, the\np.d.f. is given by\nλx e-λ\n1⁄2\nx!\nfor x = 0, 1, 2, . . .\nfX (x) =\notherwise\nand E[X] = Var(X) = λ.\n\n5. (15 points)\nSuppose, X ∼ U[0, 1] is uniformly distributed on the interval [0, 1], and Y has p.d.f.\n1⁄2\nλeλy\nif y ≤ 0\nfY (y) =\notherwise\nGive a function u( ) such that Y = u(X) (hint: what is the c.d.f. of Y ?).\n·\n6. (10 points)\nSuppose Var(X) = Var(Y ) = 1 and E[X] = 2 and E[Y ] = 1, and the correlation coefficient is\n%(X, Y ) = 1\n3 . What is the expectation of the squared difference between the two random variables,\nE[(X - Y )2]?\n\nTa\nble\nof c\numul\nativ\ne ar\neas\nunde\nr th\ne st\nanda\nrd n\norma\nl di\nstri\nbuti\non.\nImage by MIT OpenCourseWare.\n\nTab\nle\nof\ncum\nula\ntiv\ne a\nrea\ns u\nnde\nr t\nhe\nsta\nnda\nrd\nnor\nmal\ndi\nstr\nibu\ntio\nn.\nImage by MIT OpenCourseWare."
    },
    {
      "category": "Exam",
      "title": "Exam III, Spring 2008",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/422abaf276484ce893c2733dbcb6401b_MIT14_30s09_exam03_08.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Exam 3\nSpring 2008\nInstructions: This exam is closed-book and closed-notes. You may use a calculator and a cheat sheet.\nPlease read through the exam first in order to ask clarifying questions and to allocate your time\nappropriately. In order to receive partial credit in the case of computational errors, please show all\nwork. You have 90 minutes to complete the exam. Good luck!\n1. (25 points) Expectations and Variances\nLet\nX ∼ N(μX , σ2 ), and Y ∼ N(μY , σ2 )\nX\nY\nbe normally distributed random variables with Cov(X, Y ) = σXY . We look at a weighted sum of the\ntwo random variables, Z = wX + (1 - w)Y for some constant w.\n(a) As a function of w, what is the expectation of Z?\n(b) As a function of w, what is the variance of Z?\n(c) Calculate E[Z2].\n(d) Suppose you want to invest your savings, and X and Y are the returns to stock 1 and 2\nrespectively. If the fraction of your savings invested in stock 1 is w, your total return will be\nZ = wX + (1 - w)Y . Suppose both assets have the same expected return μX = μY , and you'd like\nto chose w to keep the variation of your return as small as possible. Given your answer to (b),\nwhich value of w minimizes the variance of Z? Suppose X and Y are independent. When is the\noptimal w not between zero and one? Why shouldn't you just invest everything in the stock with\nthe lower variance?\n(e) (optional, extra credit): Suppose that X = -inf with probability pX , and X ∼ N(μX , σ2 ) with\nX\nprobability 1 - pX . Similarly, Y = -inf with probability pY , and Y ∼ N(μY , σ2 ) with probability\nY\n1 - pY . Also, X and Y are independent as before. Again, you have a combination of assets\nwX + (1 - w)Y , and it seems reasonable that you'd want to keep the probability\nP (wX + (1 - w)Y = -inf) as small as possible. What is the probability of such a shock given w?\nWould you still want to diversify? Does this contradict what you found in part (d)? A short\nanswer suffices, no algebra needed.\n2. (25 points) Estimation\nYou and your friend are waiting for your printing jobs in the Athena cluster. There are many other\nstudents in the lab, and the number of printing jobs in a 10-minute interval follows a Poisson\ndistribution with (yet unknown) arrival rate λ.\nSuppose that each time you run into your friend, you have already picked up your print-outs and are\njust having a 10 minute long chat with your friend. You keep track of the number Xi of printouts\ncoming out of the printer during each of those 10-minute time intervals. For a sample X1, . . . , X12, you\nfind that the mean is X 12 = 5.17, and the mean of squares is n\n1 P\ni\nn\n=1 Xi\n2 = 31.43.\n(a) Calculate the method of moments estimator for the Poisson rate λ using the sample mean.\n(b) Recall that for a Poisson random variable X, Var(X) = λ. Can you construct an alternative\nmethod of moments estimator based on the information given above? Is that estimator different\nfrom that in (a)? If yes, do you think that this is a problem?\nAthena is MIT's UNIX-based computing environment. OCW does not provide access to it.\n\nNow, instead of counting the number of printing jobs, you only keep track of the time spent waiting\nuntil your friend's printing job came out. Your statistic textbook tells you that the waiting time Ti for\nthe rth occurrence of a Poisson event has the p.d.f.\ntr-1\nif t > 0\n1⁄2\n(r\nλ\n-\nr\n1)!\ne-λt\nfT (t) =\notherwise\nYou know that your friend's printing job is always 5 positions behind your own in the queue (i.e. r = 5)\nand you only keep track of the time Ti you are waiting together.\n(c) What is the likelihood and the log-likelihood function for the i.i.d. sample T1, . . . , Tn?\n(d) Find the maximum likelihood estimator for λ.\n(e) You lost your detailed notes on the sample T1, . . . , Tn, but you still remember that the average\nobserved waiting time was T n = 3.84, and the sample variance of waiting times, Sˆn = 4.12. Will\nyou still be able to compute a consistent estimator for λ?\n3. (15 points) Confidence Intervals\nSuppose you have an i.i.d. sample X1, . . . , X25 of 25 observations, where Xi ∼ N(μ, σ2). The mean of\nthe sample is X 25 = 1.2.\n(a) Construct a 95% confidence interval for μ, assuming that σ2 = 4.\nX 2\n1 P25 X2\n(b) Now suppose we didn't know σ2, but I told you that\n25 = 25\ni=1\ni = 6.38. Construct a 95%\nconfidence interval for μ.\n(c) Suppose you want to test the null hypothesis H0 : μ = 0 against HA : μ > 0 at the 5% significance\nlevel. Given X 25 and X2 as before (and assuming that you don't know the true variance σ2), do\nyou reject the null hypothesis?\n4. (20 points) Hypothesis Tests\nSuppose X ∼ U[-θ, θ]. You have only one single observation from that distribution, and you want to\ntest\nH0 : θ = 1 against HA : θ = 0.1\n(a) State the p.d.f. of X (hint: be careful about where the p.d.f. is zero and where it's not).\n(b) Derive the most powerful test - which result from the class are you using to show that the test is\nindeed most powerful?\n(c) Consider the test \"reject H0 if X < 0.1\". What is the size α of this test? What is its power\n|\n|\n1 - β? Be sure to give the definition of size and power when you do the calculation.\n(d) Can you construct a most powerful test of size 5%?\n\n5. (15 points) Hypothesis Tests\nYou are conducting a randomized experiment on telepathy in which your experimental subjects have to\ntake a test. A medium, i.e. a person with supernatural abilities, claims that she is able to influence\nother peoples' thoughts and feelings only through extra-sensory perception.\nYou split your N experimental subjects into two groups of m and n individuals, respectively. For the\nfirst m individuals (\"treatment group\"), the medium is sitting in a room next door with the solutions\nmanual to the test, thinking about the test-taker in order to help him/her on the test. The second\ngroup of n individuals (\"controls\") takes the test under normal conditions. In order not to boost the\nconfidence of either group, participants in neither group are told whether they are helped by the\nmedium.\nYou observe the samples X1, . . . , Xm of scores for the group which received help from the medium, and\nY1, . . . , Yn are the scores of the control group. You know beforehand that\nXi ∼ N(μX , σ2), and Yi ∼ N(μY , σ2)\nEach individual is tested separately and under identical conditions, so we assume that all observations\nare independent.\n(a) Give the variances of X m and Y n. What is the variance of X m - Y n?\n(b) For a given total number of experimental subjects N = m + n, which value of m minimizes the\nvariance of the difference X m - Y n?\n(c) You want to conduct a test of H0 : μX = μY against HA : μX = μY with size α = 5%. Suppose\nσ2 = 4, m = 20 and n = 8, and you find that Xm - Yn = 1.74. Do you reject the null hypothesis?\n(d) Using your results from above, how many additional participants would you have to add at least\nin order to distinguish an effect of μX - μY = 1 points from μX - μY = 0 points with probability\n95%? Hint: you can add subjects to the treatment group, the control group, or both (whichever\nrequires the smallest number of additional participants).\nHave a great Summer!\n\nTa\nble\nof c\numul\nativ\ne ar\neas\nunde\nr th\ne st\nanda\nrd n\norma\nl di\nstri\nbuti\non.\nImage by MIT OpenCourseWare.\n\nTab\nle\nof\ncum\nula\ntiv\ne a\nrea\ns u\nnde\nr t\nhe\nsta\nnda\nrd\nnor\nmal\ndi\nstr\nibu\ntio\nn.\nImage by MIT OpenCourseWare.\n\nTable of upper percentiles of Student t dist\nributions - degrees of\nfreedom 1-34.\nImage by MIT OpenCourseWare."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/b7e094cbc0fd2de22977a35a0f957786_MIT14_30s09_lec01.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 1\nKonrad Menzel\nFebruary 3, 2009\nIntroduction and Overview\nThis class will give you an introduction to Probability Theory and the main tools of Statistics. Probability\nis a mathematical formalism to describe and analyze situations in which we do not have perfect knowledge\nof all relevant factors. In modern life, we are all routine consumers of statistical studies in fields ranging\nfrom medicine to sociology, and probabilistic reasoning is crucial to follow most of the recent debates in\neconomics and finance.\nIn the first half of this class, we'll talk about probabilities as a way of describing genuine risk - or our\nsubjective lack of information - over events.\nExample 1 In subprime lending, banks offered mortgages to borrowers who were much less likely to repay\nthan their usual clientele. In order to manage the risks involved in lending to prospective home-owners\nwho do not own much that could serve as collateral, thousands of these loans were bundled and resold as\n\"mortgage backed securities,\" i.e. the bank which made the original loans promised to pay the holder of\nthat paper whatever repayment it received on the loans. Eventually, there were more complicated financing\nschemes under which the pool was divided into several \"tranches\", where a first tranche was served first,\ni.e. if the tranche had a nominal value of, say, 10 million dollars, anyone holding a corresponding claim\ngot repaid whenever the total of repayments in the pool surpassed 10 million dollars. The lower tranches\nwere paid out according to whatever money was left after serving the high-priority claims.\nHow could it be that the first \"tranche\" from a pool with many very risky loans was considered to be \"safe\"\nwhen each of the underlying mortgages was not? The low-priority tranches were considered riskier - why?\nAnd why did in the end even the \"safe\" securities turn out to be much riskier in retrospect than what\neveryone in the market anticipated? We'll get back to this when we talk about the Law of Large Numbers,\nand under which conditions it works, and when it doesn't.\nUsually in order to answer this type of question, you'll have to know a lot about the distribution (i.e.\nthe relative likelihood) of outcomes, but in some cases you'll actually get by with much less: in some\ncases you are only concerned with \"typical\" values of the outcome, like expectations or other moments\nof a distribution. In other cases you may only be interested in an average over many repetitions of a\nrandom experiment, and in this situation the law of large numbers and the central limit theorem can\nsometimes give you good approximations without having to know much about the likelihood of different\noutcomes in each individual experiment.\nThe second half of the class deals with the question how we can learn about populations and probability\ndistributions from data. In any empirical science you'll come across the problem of inductive reasoning,\nwhich means drawing general conclusions from a few (or even very many) observed special cases. In\npolitical polls (\"who would you vote for in the next presidential election?\"), a survey institute typically\n\npolls at most a few thousand out of over a hundred potential voters. In medical trials, we try to draw\nconclusions about the effectiveness of a drug for an entire population from only a few dozen study\nparticipants.\nIf we only observe a subset of individuals (e.g. a random sample of voters in an exit poll) from a population\nof interest (e.g. all voters who turned out for a primary election), there will be some uncertainty over\nwhether this sample was actually representative for the whole population with respect to the question\nwe're after (e.g. the vote share for a particular candidate). Formalizing this for practical use makes heavy\nuse of probability theory.\nExample 2 The controversial first Lancet study on civilian casualties in the Iraq war surveyed a random\nsample of 1849 households (which had in total 12,801 members) across the country three and a half years\nafter the invasion in March 2003, and extrapolated the number of deaths reported by the surveyed household\nto the total population of the whole country, which is about 29 million. The authors of the study arrived\nat an estimate of about 112,000 \"excess\" deaths for the first 18 months after the invasion and stated\nthat \"with 95% confidence\", the actual number was between 69,000 and 155,000. We will see later on in\nthe course what exactly this statement means. The width of the confidence interval around the estimate\ngives a measure of the uncertainty inherent in extrapolating from a small sub-population to the entire\ncountry. Since this is a politically and emotionally charged subject, the study triggered an intense debate\nin scientific publications and the blogosphere - reading up on the debate will teach you a lot about how\nstatistics is actually \"done\" in practice.\nSet Theory and Events\n2.1\nRandom Experiments\nDefinition 1 A random experiment is any procedure which can - at least theoretically - (a) be repeated\narbitrarily often and under identical conditions, and (b) has a well-defined set of possible outcomes.\nA standard example for this would be a coin flip which can produce two different outcomes, heads H\nor tails T (we'll neglect the possibility that the coin ends up standing upright on its edge). Another\nimportant type of experiments in the realm of statistics would be an exit poll after an election: say we\nask 2,000 randomly selected voters as they exit the poll stations to report which candidate they voted\nfor. We could in principle redraw arbitrarily many further samples of 2,000 individuals from the total\npopulation that turned out to vote on election day, so condition (a) is satisfied. The set of outcomes\nfor this experiment is the respective number of interviewed persons which reports to have voted for each\ncandidate on the ballot.\nDefinition 2 The sample space S is the collection of all possible outcomes of an experiment.\nFor many purposes, we are not primarily interested in single outcomes, but instead group collections\nof outcomes together into events. Therefore we will in the following describe the experiment in terms of\nsets.\nDefinition 3 An event A can be any collection of outcomes (this includes individual outcomes, the empty\nset, or the entire sample space).\nIf the realized outcome is a member of the event A , then A is said to occur.\nLet's look at last year's presidential race as an example. At the most elementary level, we could\ndescribe the sample space S as the collection of individuals who may - as a logical possibility - be elected\n\nas president in November, i.e. as a first try we could look at the main candidates at the early stages of\nthe primaries:\nS = {Clinton, Huckabee, McCain, Obama, Paul, Romney, Schwarzenegger}\nIs this a good description? - probably not: even though these are the most likely outcomes, we can't\nlogically rule out that some other candidate (from either party or independent) enters the race later on,\nso a more fool-proof definition of the random experiment would augment the sample space\nS\n=\n{Clinton, Huckabee, McCain, Obama, Paul, Romney, Schwarzenegger,\nother Democrat, other Republican, other Independent}\nbut to keep things simple, let's just ignore this possibility for now.\nSome events of interest could be e.g.\n\"The 44th president of the US will be Republican\"\n=\n{Huckabee, McCain, Paul, Romney, Schwarzenegger,\nother Republican}\n\"The 44th president is married to the 42nd president\n=\n{Clinton}\n2.2\nMore about Sets and Events\n2.2.1\nSet Inclusion \"⊂\"\nThe event B is contained in A if every outcome in B also belongs to A, or in symbols\nB ⊂A if (s ∈B =⇒s ∈A)\nClearly, any event C is contained in the sample space S, i.e.\nC ⊂S for any event C\nand every event includes the impossible event\n∅⊂C for any event C\nA\n\nVenn diagram of B implies A.\nFigure 1: B ⊂A - \"B implies A\"\nIf A and B contain each other, they are equal,\nA ⊂B and B ⊂A =⇒A = B\nImage by MIT OpenCourseWare.\n\nand set inclusion is transitive, i.e.\nA ⊂B and B ⊂C =⇒A ⊂C\nIn our presidential elections example, since (if we can trust Wikipedia, McCain was born on an American\nair base in the Panama Canal zone)\n\"The 44th President was born in Panama\"\n=\n{McCain}\n⊂\n\"The 44th President was born abroad\" = {McCain, Schwarzenegger}\nand\n{McCain,Schwarzenegger} ⊂\"The 44th President is a Republican\"\nwe can conclude that\n\"The 44th President was born in Panama\" ⊂\"The 44th President is a Republican\"\n2.2.2\nUnions of Sets, \"∪\"\nThe union of A and B is the collection of all outcomes that are members of A or B (or both, this is the\nlogical, inclusive \"or\" corresponding to the symbol ∨). In symbols\nA ∪B = {s ∈S|s ∈A ∨s ∈B}\nThe set union is symmetric:\nA\n\nV\nenn diagram of union of A and B.\nFigure 2: Union of A and B - \"A or B\"\nA ∪B = B ∪A\nFurthermore,\nB ⊂A =⇒A ∪B = A for any events A, B ⊂S\nIn particular,\nA ∪∅\n=\nA\nA ∪A\n=\nA\nA ∪S\n=\nS\nIt also doesn't matter in which order we take union of sets/events (associative property):\nA ∪B ∪C = (A ∪B) ∪C = A ∪(B ∪C)\nImage by MIT OpenCourseWare.\n\n2.2.3\nIntersections of Sets, \"∩\"\nThe intersection of A and B is the (possibly empty) collection of outcomes that are members of both A\nand B, written as\nA ∩B = {s ∈S|s ∈A ∧s ∈B}\nwhere \"∧\" denotes the logical \"and\". Some texts use the alternative notation A ∩B = AB. As the set\nA Ven\nn\n\ndiagram of intersection of A and B.\nFigure 3: Intersection of A and B - \"A and B\"\nunion, the intersection is symmetric,\nA ∩B = B ∩A\nAlso\nB ⊂A =⇒A ∩B = B for any events A, B ⊂S\nFrom this it follows that\nA ∩∅\n=\n∅\nA ∩A\n=\nA\nA ∩S\n=\nA\nAgain, like the set union, the intersection of sets has the associative property\nA ∩B ∩C = A ∩(B ∩C) = (A ∩B) ∩C\nIn addition, set intersection and union have the distributive properties\nA ∩(B ∪C) = (A ∩B) ∪(A ∩C)\nand\nA ∪(B ∩C) = (A ∪B) ∩(A ∪C)\nAs an example, for the events\nA\n=\n\"President 44 is a Woman\" = {Clinton}\nB\n=\n\"President 44 was born in Midwest\" = {Clinton,Romney}\nC\n=\n\"President 44 is a Republican\" = {Huckabee,McCain,Paul,Romney,Schwarzenegger}\nImage by MIT OpenCourseWare.\n\nwe can see that\nA ∩(B ∪C)\n=\n{Clinton} ∩{Clinton,Huckabee,McCain,Paul,Romney,Schwarzenegger}\n=\n{Clinton}\n(A ∩B) ∪(A ∩C)\n=\n{Clinton} ∪∅= {Clinton}\nas it should be according to the first distributive property.\n2.2.4\nSet Complement, Ac\nThe complement AC of A is the set of outcomes in S which do not belong to A, i.e.\nAC = {s ∈S|s ∈/ A} = S\\A\nA\n\nVenn diagram of the complement of A.\nFigure 4: Complement to A - \"not A\"\nFrom the definition, you can easily check that complements have the following properties\n(AC)C\n=\nA\nA ∪AC\n=\nS\nA ∩AC\n=\n∅\nFrom the last statement, it follows that\nSC = ∅\nand together with the first property, this implies\n∅C = S\nOne useful set of relationships between intersections and unions is the following\n(A ∪B)C\n=\nAC ∩BC\n(A ∩B)C\n=\nAC ∪BC\nImage by MIT OpenCourseWare.\n\nA\n\nVenn\ndi\nag\nram of a complementation rule.\nFigure 5: Illustration of (A ∩B)C = AC ∪BC - you can see the rule (A ∪B)C = AC ∩BC from the same\ngraph.\n2.2.5\nPartitions of Events\nA and B are disjoint (or mutually exclusive) if they have no outcomes in common, i.e.\nA ∩B = ∅\nA collection of events A1, A2, . . . is said to be exhaustive if their union equals S, i.e.\n[\nAi = A1 ∪A2 ∪. . . = S\ni≥1\nA collection of events A1, A2, . . . is called a partition of the sample space if (1) any two distinct events\nAi, Aj (with i = j), Ai and Aj are disjoint Ai ∩Aj = ∅, and (2) the collection A1, A2, . . . is exhaustive.\nIn a similar fashion we can define partitions of an event B as collections of mutually exclusive subevents\nwhose union equals B.\n\nA\ndi\nag\nra\nm\nof\na\ns\net partitioned into different regions.\nFigure 6: Partition of S into A1, A2, . . . , A8\nImage by MIT OpenCourseWare.\nImage by MIT OpenCourseWare."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/0ae3bdadf74a48e05aed6f639c1b23d2_MIT14_30s09_lec02.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nX\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 2\nKonrad Menzel\nFebruary 5, 2009\nProbability of Events\nSo far, we have only looked at definitions and properties of events - some of them very unlikely to\nhappen (e.g. Schwarzenegger being elected 44th president), others relatively certain - but we haven't said\nanything about the probability of events, i.e. how likely an event is to occur relative to the rest of the\nsample space.\nFormally, a probability P is defined as a function from a collection of events A = {A1, A2, . . .} in S1 to\nthe real numbers, i.e.\nA\n-→\nR\nP :\nA\n7→\nP (A)\nIn order to get a useful definition of a probability, we require any probability function P to satisfy the\nfollowing axioms:\n(P1) P (A) ≥ 0 for any event A ∈A.\n(P2) P (S) = 1 - i.e. \"for sure, something is going to happen\"\n(P3) For any sequence of disjoint sets A1, A2, . . .,\n⎛\n⎞\nP ⎝\nAi⎠ =\nP (Ai)\ni≥1\ni≥1\nAs a mathematical aside, in order for these axioms (and our derivations of properties of P (A) next\nlecture) to make sense, it must in fact be true that the collection A in fact contains the event S, and\nthe complements and unions of its members, and this is what constitutes a sigma-algebra as defined in\nthe footnote on the previous page. But again, for this class, we'll take this as given without any further\ndiscussion, so you can ignore this fine print for now.\n1For a consistent definition of a probability, this collection of events must satisfy the following properties\n(S1) S ∈A\n(S2) If A ∈A, then its complement AC ∈A\n(S3) Any countable union of events A1, A2, . . . is in A, i.e. A1 ∪A2 ∪. . . ∈A\nSuch a collection of events is called a sigma-algebra on S. For the purposes of this class, this is not important, and we'll\ntake it as given that the problem at hand satisfies these axioms.\n\nDefinition 1 A probability distribution on a sample space S is a collection of numbers P (A) which\nsatisfies the axioms (P1)-(P3).\nNote that the axioms (P1)-(P3) do not pin down a unique assignment of probabilities to events. Instead,\nthese axioms only give minimal requirements which any probability distribution should satisfy in order\nto be consistent with our basic intuitions of what constitutes a probability (we'll actually check that\nbelow). In principle any function P (·) satisfying these properties constitutes a valid probability, but we'd\nhave to see separately whether it's actually a good description of the random experiment at hand, which\nis always a hard question. In part 5 of this class (\"Special Distributions\"), we'll discuss a number of\npopular choices of P (·) for certain standard situations.\nSome Properties of Probabilities\nNow we still have to convince ourselves that the axioms (P1)-(P3) actually are sufficient to ensure that\nour probability function has the properties we would intuitively expect it to have, i.e. (1) the probability\nthat an event happens plus the probability that it doesn't happen should sum to one, (2) the probability\nthat the impossible event, ∅, happens should equal zero, (3) if an event B is contained in an event A, its\nprobability can't be greater than P (A), and (4) the probability for any event should be in the interval\n[0, 1]. We'll now prove these properties from the basic axioms.\nProposition 1\nP (AC ) = 1 -P (A)\nProof: By the definition of the complement AC ,\n(P 2)\nDefn.\"AC \"\n(P 3)\n1 = P (S)\n=\nP (A ∪AC ) = P (A) + P (AC )\nwhere the last step uses that A ∩AC = ∅, i.e. that A and its complement are disjoint. Rearranging this,\nwe get\nP (AC ) = 1 -P (A)\nwhich is what we wanted to show\nProposition 2\nP (∅) = 0\nProof: Since ∅C = S, we can use the previous proposition to show that\nProp.1\n(P 2)\nP (∅) = P (SC )\n=\n1 -P (S) = 1 -1 = 0\nProposition 3 If B ⊂ A, then P (B) ≤P (A).\nAs an aside, cognitive psychologists found out that even though this rule seems very intuitive, people\noften violate it in everyday probabilistic reasoning.2 Proof: In order to be able to use the probability\n2E.g. in a study by the psychologists Daniel Kahneman and Amos Tversky, several people were given the following\ndescription of Linda:\nLinda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply\nconcerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations.\nIndividuals who were asked to give the probability that Linda was a bank teller tended to state a lower figure than those\nasked about the probability that she was a feminist bank teller.\n\naxioms, it is useful to partition the event A using properties of unions and intersections\nA = A ∩S = A ∩(B ∪BC ) = (A ∩B) ∪(A ∩BC ) = B ∪(A ∩BC )\nwhere the last step uses that B ⊂ A implies that A ∩B = B. Now in order to be able to use axiom (P3),\nnote that B and A ∩BC are disjoint:\nB ∩(A ∩BC ) = B ∩(BC ∩A) = (B ∩BC ) ∩A = ∅∩A = ∅\nTherefore, we can conclude\nP (A) = P (B) + P (A ∩BC ) ≥ P (B)\nby axiom (P1)\nProposition 4 For any event A, 0 ≤P (A) ≤ 1.\nProof: 0 ≤ P (A) is axiom (P1). For the second inequality, note (P1) also implies that P (AC ) ≥ 0.\nTherefore by proposition 1\nP (A) = 1 -P (AC ) ≤1\nProposition 5\nP (A ∪B) = P (A) + P (B) -P (A ∩B)\nProof: Note that, as in the proof of proposition 3, we can partition the events A and B into\nA = A ∩S = A ∩(B ∪BC ) = (A ∩B) ∪(A ∩BC )\nand in the same fashion\nB = (B ∩A) ∪(B ∩AC )\nYou can easily check that these are in fact partitions, i.e.\neach of the two pairs of sets is disjoint.\nTherefore, we can see from axiom (P3) that\nP (A) = P ((A ∩B) ∪(A ∩BC )) = P (A ∩B) + P (A ∩BC )\nand\nP (B) = P (B ∩A) + P (B ∩AC )\nTherefore\nP (A) + P (B) = P (A ∩B) +\n\nP (A ∩BC ) + P (B ∩A) + P (B ∩AC )\n\n= P (A ∩B) + P (A ∪B)\nby (P3) since (A ∩B), (A ∩BC ), (B ∩AC ) is a partition of A ∪B (figure 6 gives a graphical illustration\nof the idea). Rearranging the last equation gives the desired result\n\nA\nVe nn\ndi ag\nra m o\nf\ndisjoint events.\nFigure 1: Partition of A ∪B into disjoint events\nExample: \"Simple\" Probabilities\nSuppose we have a finite sample space with outcomes which are ex ante symmetric in the sense that we\nhave no reason to believe that either outcome is more likely to occur than another. If we let n(C) denote\nthe number of outcomes in an event C, we can define a probability\nn(A)\nP (A) := n(S)\ni.e.\nthe probability equals the fraction of all possible outcomes in S that are included in the event\nA. This distribution is called the \"simple\" probability distribution or also the \"logical\" probability. A\nrandomization device (e.g. a coin or a die) for which each outcome is equally likely is said to be fair.\nNow let's check whether the three axioms are in fact satisfied:\n(P1): P (A) ≥ 0 follows directly from the fact that n(·) only takes (weakly) positive values.\n(P2): P (S) = n\nn\n(\n(\nS\nS\n)\n) = 1.\n(P3): For two disjoint events A and B,\nn(A ∪B)\nn(A) + n(B) + n(A ∩B)\nn(A)\nn(B)\nP (A ∪B) =\n=\n=\n+\n= P (A) + P (B)\nn(S)\nn(S)\nn(S)\nn(S)\nFor more than two sets, the argument is essentially identical.\nExample 1 Suppose a fair die is rolled once. Then the sample space equals S = {1, 2, . . . , 6}, so n(S) =\n6. What is the probability of rolling a number strictly greater than 4? - since the event is A = {5, 6},\nn(A) = 2 = 1\nn(A) = n({5, 6}) = 2. Hence P (A) = n(S)\n3 .\nIf a die is rolled twice, what is the probability that the sum of the numbers is less than or equal to 4?\nLet's check: S = {(1, 1), (1, 2), . . ., (2, 1), (2, 2), . . . , (6, 6)}, so that n(S) = 62 = 36. The event\nB = \"Sum of Dice ≤ 4\" = {(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (3, 1)}\nso that P (B) = n(B) =\n6 = 1\nn(S)\n6 .\nIn a minute, we'll look at more sophisticated techniques for enumerating outcomes corresponding to\ncertain events.\nImage by MIT OpenCourseWare.\n\nCounting Rules\nThe examples we looked at so far were relatively simple in that it was easy to enumerate the outcomes\nin A and S, respectively. If S has many elements, and an event A is sufficiently complex, it may be\nvery tedious and impractical to obtain n(A) and n(S) by going down the full list of outcomes. Today,\nwe'll look at combinatorics part of which gives simple rules for counting the number of combinations or\npermutations of discrete objects (outcomes) corresponding to a different pattern (event).\nExample 2 The famous chess player Bobby Fischer (who died 3 weeks ago) eventually got bored of\nplaying \"classic\" chess and proposed a variant in which only the 8+8 pawns are set up as usual, but the\nother pieces (1 king, 1 queen, 2 bishops, 2 knights, 2 rooks) are put in random positions on the first rank,\nwhere each white piece faces the corresponding black piece on the other side. As further restrictions, (1)\none bishop must be on a black, the other on a white square, and (2) the king must start out between the\ntwo rooks (in order to allow for castling).\nThe idea behind this is that since chess players tend to use standard game openings which work well\nonly for the standard starting positions, the new variant forces them to play more creatively if there are\nenough possible ways of setting up a game to make it impossible for players to memorize openings for any\nconstellation. But how many possible starting positions are there?\nWe'll actually do the calculation later on in the lecture today using some of the counting techniques\nintroduced in this class. If you get bored, you can already start figuring out a (preferably elegant) way\nof attacking the problem.\nFor now, we will not explicitly talk about random experiments or probabilities, but digress on methods\nto enumerate and count outcomes which we will put to use later on in the lecture.\n4.1\nComposed Experiments\nRule 1 (Multiplication Rule): If an experiment has 2 parts, where the first part has m possible\noutcomes, and the second part has n possible outcomes regardless of the outcome in the first part, then\nthe experiment has m · n outcomes.\nExample 3 If a password is required to have 8 characters (letters or numbers), then the corresponding\nexperiment has 8 parts, each of which has 2 · 26 + 10 = 62 outcomes (assuming that the password is case-\nsensitive). Therefore, we get a total of 628 (roughly 218 trillion) distinct passwords. Clearly, counting\nthose up by hand would not be a good idea.\nExample 4 The standard ASCII character set used on most computer systems has 127 characters (ex\ncluding the space): each character is attributed 1 byte = 8 bit of memory. For historical reasons, the 8th\nbit was used as a \"parity\" bit for consistency checks to detect transmission or copying errors in the code.\nTherefore, we have an experiment of 7 parts, each of which has outcomes from {0, 1}, so we have a total\nnumber of 27 = 128 distinct characters.\nExample 5 A card deck has 52 cards, so if we draw one card each from a blue and a red deck, we get\n52 · 52 = 2704 possible combinations of cards (if we can't tell ex post which deck each card came from,\nwe get a smaller number of distinguishable outcomes). If, on the other hand, we draw two cards from the\nsame deck without putting the first card back on the stash, regardless of which card we drew first, only 51\ncards will remain for the second draw. Of course which 51 cards are left is going to depend on which card\nwas drawn at first, but notice that this doesn't matter for the multiplication rule. Therefore, if we draw\ntwo cards from the same deck, we'll have 52 ∗ 51 = 2652 possible combinations.\n\n|\n{z\n}\n|\n{z\n}\nThe last example illustrates two types of experiments that we want to describe more generally: sampling\nwith replacement versus sampling without replacement, each of which has a different counting rule.\n- n draws from a group of size N with replacement:\nN · N · . . . · N\n=\nN n\nn times\npossible outcomes.\n- n draws from a group of size N without replacement (where N ≥ n):\nN(N -1)(N -2) . . . 3 · 2 · 1\nN!\nPN,n := N(N -1)(N -2) . . . (N -(n -1)) =\n=\n(N -n)(N -(n + 1)) . . . 3 · 2 · 1\n(N -n)!\npossible outcomes, where k! := 1 · 2 · . . . (k -1)k (read as \"k-factorial\"), and we define 0! = 1.\nIn fact, both of these enumeration rules derive from the multiplication rules, but since they are very\nprominent in statistics, we treat them separately.\n4.2\nPermutations\nExample 6 A shuffled deck of cards is a permutation of an ordered deck of cards: it contains each card\nexactly once, though the order will in most cases be different.\nDefinition 2 Any ordered rearrangement of objects is called a permutation.\nNote that generating permutations corresponds to drawing N out of a group of N without replacement.\nExample 7 Dodecaphony is a composition scheme in modern classical music in which each piece is based\non a tone row in which each of the twelve notes of the chromatic scale (C, C sharp, D, D sharp, etc. up\nto B) appears exactly once. Therefore, each tone row is a permutation of the chromatic scale, and we\ncould in principle count the number of all possible distinct \"melodies\" (about 479 million).\nExample 8 The famous traveling salesman problem looks at a salesman who has to visit, say, 15 towns\nin an arbitrary order, and given distances between towns, we are supposed to find the shortest route which\npasses through each town on the list (at least) once. Using our formula for drawing 15 out of a group of\n15, we can calculate that there are 15!, which is about 1.3 trillion, different paths, so this is a complicated\nproblem, and we won't solve it.\nWe could imagine that in each town, the salesman has to visit 5 customers. If we consider all possible\npaths from customers to customers, we get (15 · 5)! permutations (that's a lot!). However, it may seem\nsensible to restrict our search to travel plans according to which the salesman meets with all 5 customers\nonce he is in town (in an order to be determined). There are 5! possible orders in which the salesman\ncan see customers in each town, and 15! possible orders in which he can visit towns, so we can use the\nmultiplication rule to calculate the number of permutations satisfying this additional restriction as\n(5!5! . . . 5!)\n15!\n= (5!)1515!\n15 times\nwhich is still an insanely high number, but certainly much less than the (15·5)! unrestricted permutations.3\n3Few people, if any, have a good intuition for the scale of factorials since k! grows extremely fast in k.\nStirling's\n\n4.3\nCombinations\nExample 9 If we want to count how many different poker hands we can draw from a single deck of cards,\ni.e. 5 cards drawn from a single deck without replacements, we don't care about the order in which cards\nwere drawn, but rather whether each of the card was drawn at all.\nDefinition 3 Any unordered collection of elements is called a combination.\nA combination constitutes a draw without replacement from a group, but since we now do not care about\nthe order of elements, we don't want to double-count series of draws which consist of the same elements,\nonly in different orders. For a collection of n elements, there are n! different orders in which we could\nhave drawn them (i.e. the number of permutations of the n elements). Therefore the number of different\ncombinations of n objects from N objects is\n] outcomes from drawing n out of N without replacement\nN!\nCN,n =\n=\n] orders in which can draw n elements\n(N -n)!n!\nThis number is also known as the binomial coefficient, and often denoted as\nN\nN!\n:=\nn\n(N -n)!n!\nNote that, even though we look at a ratio of factorials, the binomial coefficient always takes integer values\n(as it should in order for the number of combinations to make sense).\nExample 10 For poker, we can use this formula to calculate that there are\n= 2598960 possible\nhands.\nExample 11 A functional study group should not have more than, say, 5 members (there is no peda\ngogical justification for this number, but I just want to keep the math from becoming too complicated).\nThere are currently 28 students registered for this class. How many possibilities for viable study groups\n(including students working on their own) would be possible? We'll have to calculate the number of study\ngroups for each group size 1, 2, 3, 4, 5 and add them up, so that (if I didn't make any mistakes) there are\nS =\n+\n+\n+\n+\n= 28 + 378 + 3, 276 + 20, 475 + 98, 280 = 122, 437\npossible study groups.\nNow back to our \"challenge problem\" from the beginning of the class:\napproximation, which works quite well for \"high\" values of k is\nk! ≈\n√\n2kπ\n„ k «k\ne\nIn the pop-sci literature a common comparison to illustrate extremely large numbers involves the estimated total number of\natoms in the observable universe, which is about 1080 (well, I don't have an intuition for that either!). In terms of factorials,\n1080 ≈59!. The number 75! can be expressed as roughly 2.5 1030 (two and a half million trillion trillion) times the number\n·\nof atoms in the universe.\nSince you'd want to avoid calculations involving such high numbers, note that for most purposes, we only have to deal with\nratios of factorials, so we should first see which terms cancel, e.g.\n98!\n98·97·96·95·94!\n=\n.\n94!\n94!\n\nExample 12 Back to Fischer Random Chess: Let's first ignore the restrictions (1) and (2) about the\nrooks and bishops, i.e. allow for any allocations of the pieces on the bottom rank of the board. We have\nto allocate the 8 white (or black, this doesn't matter) pieces onto the 8 squares in the first rank of the\nchessboard. Notice that this is a permutation, so that we have 8! possible orderings. However, rooks,\nknights and bishops come in pairs and for the rules of the game the \"left\" and the \"right\" piece are\nequivalent. Therefore, there are 2 · 2 · 2 possible ways of generating each starting position by exchanging\nthe two rooks/knights/bishops with each other, respectively. Hence, the number of distinct games is\n8!\n]Games =\n= 7! = 5040\nAs we said earlier, the actual rules for Fischer Random Chess impose furthermore that (1) one bishop is\nplaced on a black, and the other on a white square, and (2) that the king has to start out between the two\nrooks. For this variant, we can use the multiplication rule if we are a little clever about the order in which\nwe fill up the row: I propose that we first allocate the two bishops, one on a random white, the other on\na random black square, so there are 4 · 4 possibilities. Next, the queen takes one out of the remaining 6\nsquares (6 possibilities, obviously). Now we put the two knights on any of the five squares that are left.\nThis is a combination, so there are\n=\n6·2 = 10 ways of allocating the knights. Because of the\nrestriction on the king and the rooks, there is always exactly one way of setting up the three pieces onto\nthe three remaining free fields. In sum, we have\n]Games = 4 · 4 · 6 · 10 · 1 = 960\npotential \"games\" to be played.\nThe crucial point about the order in which we place the pieces is to make sure that we can apply the\nmultiplication rule, i.e. that the way we place the first pieces does not affect the number of possibilities\nwe have left for the remaining pieces. As far as I can see, this only matters for the bishops: Say, we\nplaced the rooks and the king first and then put up the bishops. Then we'd have to distinguish whether (a)\nall three pieces are on fields of the same color (so we'd have 1 · 4 = 4 possibilities of placing the bishops\non fields of different colors), or (b) one of the three pieces stands on a field of a different color than the\nother two (leaving us with 2 · 3 = 6 possibilities for the bishops). As long as we place the bishops first and\nthe king before the two rooks, it seems to be irrelevant in which order we proceed thereafter.\nThe Presidential Death Date Paradox (Recitation)\nConspiracy theories about living and dead presidents are typically built around \"weird\" coincidences.\nFor example, for the two American presidents who were assassinated, i.e. Lincoln and Kennedy, one\ncan find long lists of more or less remarkable commonalities between the two - e.g. Lincoln purportedly\nhad a secretary named Kennedy who had warned him not to go the theater where he was shot, whereas\nKennedy had a secretary named Evelyn Lincoln who had warned him not to go to Dallas before his\nassassination (well, that's at least what Wikipedia says...).\nOne particular coincidence is the fact that several of the 39 presidents who already died share the same\ndeath dates: Filmore and Taft both died on March 8. John Adams and Thomas Jefferson both died on\nJuly 4th in 1826, exactly 50 years after the signing of the declaration of independence, and James Monroe\ndied exactly five years later, on July 4, 1831. Is this something to be surprised about?\nLet's first look at the simple probability that two given presidents died on a fixed day, say February 6,\nassuming that probabilities equal the proportion of outcomes belonging to that event: we get that there\nis only one combination of the two presidents' death dates falls on February 6th, but by the multiplication\n\nrule for enumerations, there are a total of 3652 possible combinations of death dates. Hence the probability\nfor this event is 1/3652 which is an extremely small number.\nHowever, there is also a large number of pairs of presidents and days in the year which could be potential\ncandidates for a double death date. Now, the probability of the event A that at least two out of the 39\npresidents died on the same day can in principle be calculated as the ratio of the number of all possible\ncombinations that have one pair of presidents with the same death date, two pairs, three presidents\non one death date, and so forth. A more elegant way to attack this problem is by noting that, since\nA ∪AC = S and A ∩AC = ∅, from the axioms P3 and P2 we have P (A) = P (S) -P (AC ) = 1 -P (AC ).\nThe event AC can be formulated as \"all 39 dead presidents have different birthdays.\" If there were only\ntwo dead presidents, there are 364 ways in which, given the death date of the first, the death date of\nthe second could fall on a different date. You should now note that counting the number of possibilities\nof assigning different death dates to each of the n presidents corresponds to the experiment of drawing\nn out of 365 days without replacement, so the number of possibilities is\n365!\nThe total number of\n(365-n)! .\npossible assignments of death dates to presidents corresponds to drawing dates without replacement, so\nthe number is 365n .\nHence the probability of having at least one pair of presidents with the same death date is\n365!\nP (A) = 1 -P (AC ) = 1 - 365n(365 -n)!\nwhich, for n = 39 is equal to about 87.82%. Using the formula, we can also calculate this probability for\ndifferent numbers of presidents:\nn\nP(A)\n0.27%\n2.71%\n11.69%\n41.14%\n70.63%\n99.41%\n100.00%\nAs we can see from the last line, one intuition for the probability increasing to one is that we eventually\n\"exhaust\" the number of potential separate death dates until eventually we have more dead presidents\nthan death dates.\nSo, to resolve the paradox, while the event that two given presidents died on a fixed date would indeed\nbe a great coincidence (i.e. has a very low probability), with an increasing number of presidents, there\nis a combinatorial explosion in the number of different constellations for such an event. In other words,\nwhile each individual outcome remains very unlikely, the \"number of potential coincidences\" increases\nvery steeply, so that with a high probability at least some coincidences must happen.\nThe story behind the other conspiracy theories is presumably the same: people have been combing through\nzillions of details trying to find only a relatively tiny number of stunning parallels between Lincoln and\nKennedy. In statistics, this search strategy is commonly called \"data mining,\" and in this context we\nspeak of those rare coincidences which actually occur as \"false discoveries,\" which are typically not due\nto any systematic relationships, but simply result from the sheer numbers of potential relationships that\nwe might investigate or test simultaneously."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/9c89201451ee315f78f75d1dcdfef47e_MIT14_30s09_lec03.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 3\nKonrad Menzel\nFebruary 10, 2009\nCounting Rules and Probabilities\nRecall that with simple probabilities, each outcome is equally likely, and for a finite sample space, we can\ngive the probability of an event A as\nn(A)\nP (A) = n(S)\nWe'll now see how to make good use of counting rules to calculate these probabilities.\nExample 1 Draw two cards from a deck of 52 cards with replacement, assuming that each card is picked\nwith equal probability. What is the possibility of drawing two different cards?\nS = {(A♣, A♣), (A♣, A♠), . . .} =⇒ n(S) = 522\nThe event \"two different cards\" consists of\n52!\nA = {(A♣, A♠), (A♣, A♥), . . .} =⇒ n(A) =\n= 52 · 51\n(52 -2)!\nso that\nn(A)\n52!\nP (A) =\n=\n=\n≈ 0.98\nn(S)\n(52 -2)!(52)2\nAlternatively, we could have used proposition 1 on probabilities:\nP (A) = 1 -P (AC ) = 1 -P (\"two cards are same\") = 1 -P (\"2nd card same as 1st\") = 1 -\n=\nIn some other examples, computing the probability of an event through its complement may simplify the\ncalculation a lot.\nExample 2 Suppose Oceania attacks the capital of Eurasia1 with 16 missiles, 8 of which carry a nuclear\nwarhead.\nSuppose the Eurasian army can track all 16 projectiles and has 12 missiles each of which\ncan intercept one incoming missile with absolute certainty, but can't tell which of the missiles carry a\nconventional load. What is the combinatorial probability that Eurasia cannot avert disaster and at least\none of the nuclear warheads reaches its target? What would be your intuitive guess?\n1The names are taken from Orwell's novel \"1984\", so this is not supposed to be a real-world example.\n\nSince in any event, exactly 4 projectiles reach their target, the sample space S consists of all combinations\nof 4 missiles out of 16. Therefore the number of elements of S is given by the binomial coefficient\n\n16!\nn(S) =\n=\n12!4!\nIn order to evaluate the probability, one approach is to use the complement rule. The event complementary\nto A =\"At least one nuclear warhead hits target\" is AC =\"All missiles hitting the target are conventional\",\nand the outcomes in AC are given by all combinations of 4 missiles out of 8 (the conventional ones), so\nthat\n\nn(AC )\n8!\n=\n=\n4!4!\nTherefore,\n12!4!8!\n12! 8!\n8 · 7 · 6 · 5\nP (A) = 1 -P (AC ) = 1 -\n= 1 -\n= 1 -\n=\n16!4!4!\n16! 4!\n16 · 15 · 14 · 13\nSo it turns out that this probability is extremely close to one - I'm not sure whether you would have\nexpected this, but despite being politically incorrect, this example shows that our intuitions may fail easily\nin combinatoric problems, last but not least because of the high numbers of possibilities.\nExample 3 The famous birthday \"paradox\" is about a (once) popular party game: given you have a\ngroup of n friends, what is the probability that at least a pair of them has the same birthday (assuming\nthat all birthdays are equally likely, which is actually only approximately true empirically)? Again, let's\nlook at the complementary event AC that each of your n friends has a different birthday: since this\ncorresponds to drawing n out of 365 without replacement, we can use the corresponding formula\n365!\nn(AC ) = (365 -n)!\nso that we can calculate the probability P (A) of at least two of your friends having the same birthday:\nP (A) = 1 -P (AC ) = 1 - n(AC ) = 1 -\n365!\nn(S)\n(365 -n)!365n\nThis formula is not yet particularly easy to read, so let's just write down the probabilities in decimals for\na few values of n:\nn\nP (A)\n0.027\n0.117\n0.253\n0.411\n0.569\n0.706\n0.97\n\nMany people find these probabilities very high, but it's usually because one is tempted to start thinking\nabout the problem by calculating the probability that any of your n friends has the same birthday as you.\nYou can convince yourself that this probability is\n\nn\n\nn\nP (A ) = 1 -\n1 -\n= 1 -\nfor which our list looks different: The reason for this discrepancy is that in the previous situation, A also\nn\nP (A)\n0.014\n0.027\n0.040\n0.053\n0.066\n0.079\n0.128\n0.634\ncontained all pairs among your n friends, and that number went up very quickly.\nIndependent Events\nIntuitively, we want to define a notion that for two different events A and B the occurrence of A does\nnot \"affect\" the likelihood of the occurrence of B, e.g. if we toss a coin two times, the outcome of the\nsecond toss should not be influenced in any way by the outcome of the first. In order to keep notation\nsimple, we will from now on denote\nP (A ∩B) = P (AB)\nDefinition 1 The events A and B are said to be independent if\nP (A ∩B) = P (A)P (B)\nFrom this you can see that independence is merely a property of the probability distribution, not neces\nsarily of the physical nature of the events. So while in some examples (e.g. the series of coin tosses) we\nhave a good intuition for independence, in most cases we'll have no choice but need to check the formal\ncondition.\nExample 4 Say we roll a fair die once, what are the probabilities for the events\nA =\n{2, 4, 6}\nB =\n{1, 2, 3, 4}\nn(A)\nand their intersection? Counting outcomes, P (A) = n(S) = 3\n6 = 1\n2, and similarly, P (B) = 4\n6 = 2\n3. The\nprobability of the intersection of events is\nP (AB) = P ({2, 4}) =\n=\n= P (A)P (B)\nso the events are independent even though they resulted from the same roll.\nIn order to see how independence depends crucially on the underlying probability distribution, now suppose\n\nthat the die had been manipulated so that P (6) = 3\n8 .\n, whereas for all other numbers n = 1, . . . , 5, P (n) =\nThen, by axiom (P3) on adding probabilities of disjoint events,\nP (A) =\n+\n+\n=\n,\nP (B) =\n=\nand\nP (AB) =\n=\n< P (A)P (B) =\nOne interpretation of independence is the following: suppose we know that B has occurred, does that\nknowledge change our beliefs about the likelihood of A (and vice versa)? We'll formalize this in the next\nsection, and it will turn out that if A and B are independent, there is nothing about event A to be learnt\nfrom the knowledge that B occurred.\nProposition 1 If A and B are independent, then A and BC are also independent.\nProof: Since we can partition A into the disjoint events AB and ABC , we can write\n(P 3)\nIndep.\nP (ABC ) = P (A) -P (AB)\n=\nP (A) -P (A)P (B) = P (A)(1 -P (B)) = P (A)P (BC )\nproving independence\nWe can now extend the definition of independence to more than two events:\nDefinition 2 A collection of events A1, A2, . . . are independent if for any subset Ai1 , Ai2 , . . . of these\nevents (all indices being different)\nP (Ai1 ∩Ai2 ∩. . .) = P (Ai1 ) · P (Ai2 ) · . . .\nE.g. for three events A, B, C,\nP (AB) = P (A)P (B),\nP (AC) = P (A)P (C),\nP (BC) = P (B)P (C)\nand\nP (ABC) = P (A)P (B)P (C)\nExample 5 Let the sample space be S = {s1, s2, s3, s4}, and P (si) = 1\n4 for all outcomes. Then each of\nthe events\nA = {s1, s2},\nB = {s1, s3},\nC = {s1, s4}\noccurs with probability 1\n2 . The probability for the event A ∩B is\nP (AB) = P ({s1}) =\n= P (A)P (B)\nand likewise for any other pair of events, so the events are pairwise independent. However, taken together,\nthe full collection is not independent since\nP (ABC) = P ({s1}) =\n=\n= P (A)P (B)P (C)\nIntuitively, once we know that both A and B occurred, we know for sure that C occurred.\n\nA\nV enn dia\ngr\nam of c\nonditional probability.\nConditional Probability\nSuppose the occurrence of A affects the occurrence (or non-occurrence) of B and vice versa. How do we\ndescribe the probability of B given knowledge about A? - We already argued heuristically that if the\nevents are independent, then A does not reveal any information about B. But what if it does? How do\nwe change probabilities as a result?\nExample 6 If we throw a fair die, and I tell you that in fact the outcome was an even number, i.e that\nthe event B = {2, 4, 6} occurred. What's the probability of having rolled a 6? Since there are only three\nequally likely possibilities in B, 6 being one of them, we'd intuitively expect the answer to be 1\n3 . Here we\nbasically simplified the sample space, to S = B = {2, 4, 6}, and calculated the simple probability for the\nredefined problem.\nDefinition 3 Suppose A and B are events defined on S such that P (B) > 0. The conditional probability\nof A given that B occurred is given by\nP (A ∩B)\nP (A|B) =\nP (B)\nIntuitively, the numerator redefines which outcomes in A are possible once B is known to have occurred,\nthe denominator does the same thing for the whole sample space.\nFigure 1: The Event A Conditional on B\nRemark 1 Conditional probability and independence: if A and B are independent,\nP (AB)\nP (A)P (B)\nP (A|B) =\n=\n= P (A)\nP (B)\nP (B)\nso B occurring tells us nothing about A, so the conditional probability is the same as the unconditional\nprobability.\nExample 7 This example is adapted from Greg Mankiw's blog:2 On platforms like Intrade, you can trade\nassets which pay 1$ if a given event (e.g. Yankees win the World Series) occurs. If the market works as\nit should, the prices of this type of assets at a given time t can be interpreted as probabilities given the\ninformation traders have at that point in time. On the political market on Intrade, you can trade assets\nfor the events\n2http://gregmankiw.blogspot.com/2006/11/bayes-likes-obama\nImage by MIT OpenCourseWare.\n\nX\nP\n- Ai that candidate i wins the presidential elections (without conditioning on nomination)\n- Bi that candidate i wins the nomination of her/his party\n- Ck that the nominee of party k wins the election\nWe can now use the probabilities which are implied by the asset for the corresponding event to answer the\nquestion what the market \"thinks\" which candidate of either party has the highest probability of winning\nthe presidential elections if nominated P (Ai|Bi) - i.e. nominating which candidate would give each party\nthe highest chances of winning the presidency.\nWe can (relatively) safely assume that a candidate who is not nominated by the party has no chances of\nwinning the presidency, so that\nAi ⊂ Bi =⇒ Ai ∩Bi = Ai\nso that\nP (Ai ∩Bi)\nP (Ai)\nP (Ai|Bi) =\n=\nP (Bi)\nP (Bi)\nso that we only have to plug in the prices for the corresponding assets. Based on asset prices on February\n6 on the Intrade political markets, we get the following numbers (in the last column I report the values\nfrom Mankiw's original blog entry, as of November 2006).\ncandidate\nP (Ai)\nP (Bi)\nP (Ai|Bi)\nP Nov006(Ai|Bi)\nClinton\n28.7%\n45.2%\n63.5%\n51%\nHuckabee\n0.5%\n2.0%\n25.0%\nNA\nMcCain\n34.4%\n93.0%\n37.0%\n63%\nObama\n35.0%\n53.0%\n66.0%\n88%\nPaul\n0.4%\n1.2%\n33%\nNA\nRomney\n1.2%\n2.6%\n46.2%\n50%\nIn order to distinguish it from the conditional probabilities P (A|Bi), P (A) is also called the marginal\nprobability of A. The relationship between marginal and conditional probabilities is given by the Law of\nTotal Probability:\nTheorem 1 (Law of Total Probability) Suppose that B1, . . . , Bn is a partition of the sample space S\nsuch that P (Bi) > 0 for every i = 1, . . . , n. Then\nn\nP (A) =\nP (A|Bi)P (Bi)\ni=1\nfor any event B.\nProof: From the definition of a conditional probability, P (A|Bi)P (Bi) = P (A ∩Bi) for any event Bi.\nSince B1, . . . , Bn is a partition of the sample space, (A ∩B1), . . . , (A ∩Bn) are disjoint and exhaustive for\nA - i.e. constitute a partition for A. Therefore, by the axiom (P3) on probabilities of unions of disjoint\nsets,\nn\ni=1 P (A ∩Bi) = P (A)\nExample 8 In medical data we can often find that patients treated by older, and more experienced, heart\nsurgeons have in fact higher post-operative death rates than those operated by younger surgeons - say\nwe observe a death rate of 6.0% for experienced surgeons, and onlyl 5.5% for unexperienced surgeons.\n\nDoes this mean that the surgeons' skill decreases with age? Probably not - let's suppose there are four\ndifferent types of procedures a surgeon may have to perform - single, double, triple, and quadruple bypass\n(the terminology refers to the number of coronary arteries that have to be bypassed artificially). The\ncomplexity of the procedure and the risk to the patient increase in the number of bypasses, and it might\nalso be that the patients who are generally \"sicker\" may tend to require a more complicated procedure.\nSuppose we are told that for each procedure, patients of the experienced surgeon face significantly lower\ndeath rates, but that the overall patient mortality is lower for unexperienced surgeons. In light of the law\nof total probability, how does that fit together? Let's look at an example (these numbers are of course\nmade up):\nUnexperienced\nExperienced\nProcedure\nDeath Rate\nPercentage of Cases\nDeath Rate\nPercentage of Cases\nSingle Bypass\n4.0%\n50.0%\n2.0%\n25.0%\nDouble Bypass\n6.0%\n40.0%\n4.0%\n25.0%\nTriple Bypass\n10.0%\n9.0%\n6.0%\n25.0%\nQuadruple Bypass\n20.0%\n1.0%\n12.0%\n25.0%\nTotal\n5.5%\n100.0%\n6%\n100.0%\nIn the notation of the Law of Total Probability, the overall death rate P (A) for, say, experienced\nsurgeons can be computed from the death rate conditional on procedure Bi, P (A|Bi), and the base\nrates/proportions P (Bi) of cases corresponding to each procedure.\nWe can see that since experienced surgeons are assigned a disproportionately large share of risky cases\n(presumably because you need more experience for these), their average (better: marginal) death rate is\nhigher than that of unexperienced surgeons, even though they perform better conditional on each treatment\ncategory. This phenomenon is often referred to as a composition effect.\nSo what is the practical importance of each type of probabilities? If you were to choose among surgeons\nfor a bypass operation, the type of procedure should only depend on your health status, not whether the\nsurgeon is experienced or not, so in that situation you should only care about the conditional probabilities.\nIt's harder to come up with a good use for the marginal death rates.\nIn most statistical analysis, you'd in fact be interested in conditional death rates (e.g. if you are interested\nin the effect of experience on mortality), and the variable \"type of procedure\" would be treated as what\nstatisticians call a confounding factor. A classical problem in statistics and econometrics is that often\nmany of the relevant confounding factors are not observed, and you'll learn about \"tricks\" of dealing with\nthat problem.\nRemark 2 Another closely related concept is that of conditional independence, which is going to be very\nimportant in Econometrics. Two events A and B are said to be independent conditional on event C if\nP (AB|C) = P (A|C)P (B|C)\nIt is important to note that\n- unconditional independence does not imply conditional independence\n- conditional independence does not imply unconditional independence\ni.e. whether A and B are independent depends crucially on what we are conditioning on. There'll be an\nexercise with a counterexample on the next problem set.\n\nConditional Independence (not covered in lecture)\nWe can extend the definition of independence to conditional probabilities:\nDefinition 4 Two events A and B are said to be independent conditional on event C if the conditional\nprobabilities satisfy\nP (AB|C) = P (A|C)P (B|C)\nThis definition corresponds exactly to that of unconditional independence which we looked at before, only\nthat we restrict ourselves to the new sample space S0 = C. The notion of conditional independence is\ngoing to play an important role later on in econometrics, so it deserves a special mention. As a technical\npoint, it is important to notice that conditional independence does not imply unconditional independence,\nor vice versa. In other words, whether two events are independent depends crucially on what else we\nare conditioning on. I mentioned this in passing in the last lecture, and I'm now going to provide the\nfollowing example as an illustration:\nExample 9 Let's look again at a roll of a fair die, i.e. S = {1, 2, 3, 4, 5, 6}, where each outcome occurs\nwith probability 1\n6.\n(1) Making two independent events dependent: Consider the events A = {1, 2, 3, 4} and B = {2, 4, 6}.\nWe already saw in a previous example that these events are independent:\nP (A)P (B) = P ({1, 2, 3, 4})P ({2, 4, 6}) =\n·\n=\n= P ({2, 4}) = P (AB)\nNow let event C = {3, 6}. Then\nP (AC)\nP ({3})\nP ({6})\nP (BC)\nP (A|C) =\n=\n=\n=\n=\n= P (B|C)\nP (C)\nP ({3, 6})\nP (C)\nP (C)\nHowever,\nP (∅)\nP (AB|C) =\n= 0 6= P (A|C)P (B|C)\nP (C)\ni.e. A and B are not independent conditional on C since their intersections with C are disjoint.\n(2) Making two dependent events independent: Let D = {2, 3, 4} and E = {2, 4, 6}. We can check that\nD and E are dependent: we can see that P (D) = P (E) = 1\n2. However,\nP (DE) = P ({2, 4}) =\n=\n= P (D)P (E)\nBut if we condition on F = {3, 4, 5, 6},\nP ({4})\nP (DE|F ) =\n=\nP ({3, 4, 5, 6})\nwhereas\nP ({3, 4})\nP ({4, 6})\nP (D|F )P (E|F ) =\n·\n=\n·\n=\nP ({3, 4, 5, 6})\nP ({3, 4, 5, 6})\nso that by conditioning on F , D and E became independent."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/e126cf189fd96b8cadf7e28d578e12cf_MIT14_30s09_lec04.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 4\nKonrad Menzel\nFebruary 12, 2009\nBayes Theorem\nIn the last lecture, we introduced conditional probabilities, and we saw the Law of Total Probability\nas a way of relating the unconditional probability P (A) of an event A to the conditional probabilities\nP (A|Bi). Another important relationship between conditional probabilities is Bayes Law which relates\nthe conditional probability P (A|B) to the conditional probability P (B|A), i.e. how we can revert the\norder of conditioning. This result plays an important role in many areas of statistics and probability,\nmost importantly in situations in which we \"learn\" about the \"state of the world\" A from observing the\n\"data\" B.\nExample 1 The ancient Greeks (who apparently didn't know much statistics yet) noticed that each time\nafter a ship had sunk, all surviving seamen reported having prayed to Poseidon, the Greek god of the sea.\nFrom this observation, they inferred that they were in fact saved from drowning because they had prayed.\nThis example was actually brought up by the English philosopher Francis Bacon in the 16th century.\nIn statistical terms, let's define the events A =\"survives\" and B =\"prayed\", so that the question becomes\nwhether praying increases the odds of survival, i.e. whether P (A|B) > P (A) ≡ p, say. The observation\nthat all surviving seaman had been praying translates to P (B|A) = 1.\nIs that information actually\nsufficient to answer the question whether praying strictly increases the chances of survival? How do we\nuse the information on P (B|A) to learn about P (A|B)?\nFrom the definition of conditional probabilities, we obtain\nP (AB) = P (A|B)P (B) = P (B|A)P (A)\nRearranging the second equality, we get\nP (B|A)P (A)\nP (A|B) =\nP (B)\nWe've also seen that we can partition the event\nP (B) = P (B|A)P (A) + P (B|AC )P (AC )\nso that\nP (B|A)P (A)\nP (A|B) = P (B|A)P (A) + P (B|AC )P (AC )\nWe can generalize this to any partition of S as summarized in the following theorem:\n\nTheorem 1 (Bayes Theorem) If A1, A2, . . . is a partition of S, for any event B with P (B) > 0 we\ncan write\nP (B|Ai)P (Ai)\nP (B|Ai)P (Ai)\nP (Ai|B) =\n= P\nP (B)\nj≥1 P (B|Aj )P (Aj)\n- P (Ai) is the prior probability of an event Ai (i.e. probability before experiment is run)\n- P (Ai|B) is the posterior probability of Ai (i.e. the probability after we ran the experiment and got\ninformation B - as obtained from Bayes theorem)\nAn entire statistical theory of optimal decisions is built on this simple idea: Bayesian Decision Theory.\nExample 2 For the previous example of seamen surviving the sinking of a ship, we were able to observe\nP (B|A) = 1, and the (unconditional) survival rate of seamen, P (A). However, we can also see that we\ndon't have sufficient information to answer the question whether praying strictly increases the chances of\nsurvival since we couldn't observe P (B|AC ), the fraction of seamen who prayed among those who were\ngoing to drown. It is probably safe to assume that those, fearing for their lives, all of them prayed as well\n(implying P (B|AC ) = 1), so that\n1 · p\nP (A|B) =\n= p = P (A)\n1 · p + 1 · (1 -p)\nIn a sense, the reasoning of the ancient Greeks is an instance of \"survivor bias\" (well, in a very literal\nsense): Bayes theorem shows us that if we can only observe the survivors, we can't make a judgement\nabout why they survived unless we know more about the subpopulation which did not survive.\nExample 3 An important application of Bayes rule is how we should interpret a medical test. Suppose\na doctor tests a patient for a very nasty disease, and we'll call the event that the patient in fact has\nthe disease A. The test can either give a positive result - we'll call this event B - or a negative result,\ncorresponding to event BC . The test is not fully reliable in the sense that we can't determine for sure\nwhether the patient has the disease, but the probabilities of a positive test result is\nP (B|A) = 99%,\nP (B|AC ) = 5%\nFinally, we know that the disease is relatively rare and affects 0.5% of the population which shares the\npatient's age, sex, and other characteristics.\nLet's say the test gives a positive result.\nWhat is the\n(conditional) probability that the patient does in fact have the disease?\nBayes rule gives that\nP (B|A)P (A)\nP (B|A)P (A)\n0.99 · 0.005\nP (A|B) =\n=\n=\n≈ 0.0905\nP (B)\nP (B|A)P (A) + P (B|AC )P (AC )\n0.99 · 0.005 + 0.05 · 0.995\nSince the overall prevalence of the disease, P (A) is relatively low, even a positive test result gives only\nrelatively weak evidence for disease.\nExample 4 Romeo and Juliet have been dating for some time, and come Valentine's Day (as a reminder:\nthat's Saturday), Romeo can give Juliet either jewelery, J, or a serenade, S. Juliet wants jewelery, and\nif Romeo really loved her, he would read her wishes from her eyes, and besides, she had told Romeo about\nthe jewelery two weeks earlier, during the final half hour of the Superbowl. Juliet also has first doubts\nthat Romeo still loves her, an event we'll call L. To be specific\nP (L) = 0.95\n\nJuliet also knows that if Romeo loved her, he would give her jewelery with probability P (J|L) = 0.80, or\na serenade with probability\nP (S|L) = 0.20\n(this is actually only what Juliet thinks, keeping in mind that Romeo also loves football). If he doesn't\nlove her anymore, he has no idea what Juliet wants, and he'll give her a serenade (or, more realistically,\nthe roses she wanted last year, or forget about Valentine's Day altogether) with probability\nP (S|LC ) = 0.80\n(note that, though giving a serenade is still very embarrassing for Romeo, it's also much cheaper).\nIt turns out that Romeo ends up giving Juliet a serenade. Should she dump him right away? By Bayes'\ntheorem, Juliet's posterior beliefs about Romeo's intentions are\n·\nP (S|L)P (L)\n(1 -0.8)0.95\nP (L|S) =\n=\n=\n=\n≈ 0.826\nP (S|L)P (L) + P (S|LC )P (LC )\n(1 -0.8)0.95 + 0.8(1 -0.95)\n·\n+\n10 20\nand we'll let Juliet decide on her own whether this is still good enough for her.\nIn real-life situations, most people aren't very good at this type of judgments and tend to overrate the\nreliability of a test like the ones from the last two examples - in the cognitive psychology literature, this\nphenomenon is known as base-rate neglect, where in our example \"base-rate\" refers to the proportions\nP (A) and P (AC ) of infected and healthy individuals, or the prior probabilities P (L) and P (LC ) of\nRomeo loving or not loving Juliet, respectively. If these probabilities are very different, biases in intuitive\nreasoning can be quite severe.\nExample 5 The \"Monty Hall paradox\":1 There used to be a TV show in which a candidate was asked to\nchoose among three doors A, B, C. Behind one of the doors, there was a prize (say, a brand-new washing\nmachine), and behind each of the other two there was a goat. If the candidate picked the door with the\nprize, he could keep it, if he picked a door with a goat, he wouldn't win anything. In order to make the\ngame a little more interesting, after the candidate made an initial choice, the host of the show would\nalways open one of the two remaining doors with a goat behind it. Now the candidate was allowed to\nswitch to the other remaining door if he wanted. Would it be a good idea to switch?\nWithout loss of generality, assume I picked door A initially. The unconditional probability of the prize\nbeing behind door A is\n1 . If the prize was in fact behind door a, the host would open door b or door\nc, both of which have a goat behind them, with equal probability. If the initial guess was wrong, there is\nonly one door left which was neither chosen by the candidate nor contains the prize. Therefore, given I\ninitially picked A and the host then opened C,\n·\nP (prize behind A|C opened) = P (C opened|prize behind A)P (prize behind A) =\n3 = 1\nP (C opened)\nOn the other hand\nP (C opened|prize behind B)P (prize behind B)\n1 · 3\nP (prize behind B|C opened) =\n=\n=\nP (C opened)\nTherefore, I could increase my chances of winning the prize if I switch doors.\nIntuitively, the newly opened door does not convey any information about the likelihood of the prize being\n1You can read up on the debate on http://people.csail.mit.edu/carroll/probSem/Documents/Monty-NYTimes.pdf\n\nX\nbehind door A, since the host would not have opened it in any case - and in fact, given that we chose A,\nthe events \"A contains the prize\" and \"C is opened\" are independent. However, the fact that he did not\nopen B could arise from two scenarios: (1) the prize was behind A, and the host just chose to open C\nat random, or (2) the prize was behind door B, so the host opened door C only because he didn't have a\nchoice. Therefore, being able to rule out C only \"benefits\" event B.\nRecap Part 1: Probability\nBefore we move on to the second chapter of the lecture let's just summarize what we have done so far,\nand what you should eventually should feel familiar and comfortable with:\n2.1\nCounting Rules\n- drawing n out of N with replacement: N n possibilities\n- drawing n out of N without replacement:\n(N\nN\n-\n!\nn)! possibilities\n- permutations: N! possibilities\nN\n- combinations of n out of N:\npossibilities\nn\n2.2\nProbabilities\n- independence: P (AB) = P (A)P (B)\nP (AB)\n- conditional probability P (A|B) =\nP (B) if P (B) > 0.\n- P (A|B) = P (A) if and only if A and B are independent\n- Law of Total Probability: for a partition B1, . . . , Bn of S, where P (Bi) > 0\nn\nP (A) =\nP (A|Bi)P (Bi)\ni=1\n- Bayes Theorem:\nP (B|Ai)P (Ai)\nP (Ai|B) =\nP (B)\nThere are also a few things we saw about probabilistic reasoning in general:\n- use of set manipulations to reformulate event of interest into something for which it's easier to\ncalculate probabilities (e.g. complement, partitions etc.)\n- the importance of base rates in converting conditional into marginal/unconditional probabilities\n(e.g. in Bayes theorem or composition effects in the heart surgeons example)\n- can sometimes make dependent events A and B independent by conditioning on another event C\n(or make independent events dependent).\n\nRandom Variables\nNow let's move on to the second big topic of this class, random variables.\nExample 6 Flipping a coin, version I: We could define a variable X which takes the value 1 if the coin\ncomes up Heads H and 0 if we toss Tails T . The sample space for this random experiment is S = {H, T },\nand the range of the random variable is {0, 1}.\nDefinition 1 A real-valued random variable X is any function\nS → R\nX :\ns 7→ X(s)\nwhich maps the outcomes of an experiment to the real numbers.\nAs a historical aside, when the idea of random variables was developed around 1800, there was no role\nfor \"genuine\" randomness in the minds of mathematicians and other scientists. Rather, chance was seen\nas a consequence of us not having full knowledge about all parameters of a situation we are analyzing,\nand our inability to apply the (supposedly fully deterministic) laws of nature to predict the outcome of\nan experiment. A being able to do all this is known as the \"Laplacean demon\", described by the famous\nmathematician Pierre Simon de Laplace as follows:\nAn intellect which at any given moment knew all the forces that animate Nature and the\nmutual positions of the beings that comprise it, if this intellect were vast enough to submit\nits data to analysis, could condense into a single formula the movement of the great bodies of\nthe universe and that of the lightest atom: for such an intellect nothing could be uncertain,\nand the future just like the past would be present before its eyes.2\nThis view of the world doesn't quite hold up to subsequent developments in physics (e.g. genuine inde\nterminacy in quantum physics) or computational theory (e.g. G odel's theorem: the intellect would have\nto be more complex than itself since its predictions are part of the universe it's trying to predict), but\nit's still what underlies our basic concept of probabilities: randomness in the world around us primarily\nreflects our lack of information about it.\nExample 7 As an illustration, here is version II of the coin flip: in order to illustrate Laplace's idea, we\ncould think of a more complicated way of defining the sample space than in the first go above: in classical\nmechanics, we can (at least in principle) give a full description of the state of the coin (a rigid body)\nat any point in time, and then use the laws of classical mechanics to predict its full trajectory, and in\nparticular whether it is going to end up with heads (H) or tails (T ) on top. More specifically, we could\ndescribe the sample space as the state of the mechanical system at the point in time the coin is released\ninto the air. A full (though somewhat idealized) description of the state of the system is given by (1) the\nposition, and (2) the velocity of the center of mass of the coin together with (3) its orientation, and (4)\nits angular momentum at a given time t0 - each of these has 3 coordinates, so S = R12 . Each point s ∈ S\nbelongs to one of the two events {H, T } deterministically. If we assign values X = 1 to the event H ⊂ S\nthat heads are up, and X = 0 for tails T , this mapping is the random variable\nX : R12 →{0, 1},\ngiven by X :\ns 7→ 1\nif s ∈ H\ns 7→ 0\notherwise, i.e. if s ∈ T\nSince the problem is - almost literally - very knife-edged, the outcome is highly sensitive to tiny changes\n2Laplace, P. (1814): A Philosophical Essay on Probabilities\n\nFigure 1: Stroboscopic image of a coin flip (Courtesy of Andrew Davidhazy and the School of Photo Arts\nand Sciences of Rochester Institute of Technology. Used with permission. cAndrew Davidhazy, 2007.)\nin the initial state s ∈ S (not even taking into account external influences like, say, the gravitation of a\ncar driving by), and no matter how we flip the coin, it is totally impossible to control the initial position,\nvelocity, etc. precisely enough to produce the desired outcome with certainty. Also, it will typically be\nimpossible to solve the differential equations describing the system with sufficient precision. Therefore,\nwe can only give probabilities for being in parts of S, which again maps to probabilities for the outcomes\nH and T . So even though there need not be any \"genuine\" randomness in the situation, this is how it\nplays out for us in practice.\nWhile this definition of the random variable brings out more the philosophical point how we think about\nrandom variables and probabilities, it is clearly not very operational, and for practical purposes, we'd\nrather stick to the first way of describing the problem.\nRemark 1 The probability function on the sample space S induces a probability distribution for X via\nP (X ∈ A) = P ({s ∈ S : X(s) ∈ A})\nfor any event A ⊂ R in the range of X.\nEven though formally, X is a function from the sample space into the real numbers, we often treat it\nas a variable, i.e. we say that it can \"take on\" various values with the corresponding probabilities without\nspecifying its argument. In other words, for most applications, we will only specify P (X ∈ A) without\nany reference to the underlying sample space S and the probability on S. E.g. in the coin flip example - as\ndescribed above - we won't try figure out the exact relationship between coordinates in S (initial position,\nvelocity, orientation etc. of the coin) and outcomes (which is numerically impossible) and a probability\ndistribution over these coordinates, but we just need to know that P (X = 1) = P (X = 0) = 1\n2 .\nExample 8 If we toss 10 coins independently of another, we could define a random variable X =(Total\nNumber of Tails). We'll analyze the distribution for this type of random variable in more detail below.\nExample 9 We might be interested in the outcome of an election. Say there are 100 million voters\nand 2 candidates. Each voter can only vote for either of the candidates, so there are 2100,000,000 distinct\noutcomes in terms of which voter voted for which candidate. We could now define the random variable\nX corresponding to the total number of votes for candidate A (and for elections, that's typically all we\ncare about). For each value for the number of votes, there is a corresponding number of basic outcomes,\n\ne.g. there is only one way candidate A can get all the votes. We can formulate the probability of each\noutcome in terms of simple probabilities, and from there we can aggregate over equivalent outcomes to\nobtain the probability for a given total number of votes.\nRemark 2 Not all random events have a numerical characteristic associated with them in which we are\ninterested (e.g. if the event is \"it will rain tomorrow\", we might not care how much). Then we don't have\nto bother with random variables, but can just deal with events as before. Alternatively, we could define\na random variable which takes the value 1 if the event occurs, and 0 otherwise (we'll use that \"trick\"\nsometimes in the future)."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/e54b3838f350ab02d28c460cdad262b3_MIT14_30s09_lec05.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nX\nX\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 5\nKonrad Menzel\nFebruary 19, 2009\nWe distinguish 2 different types of random variables: discrete and continuous.\nDiscrete Random Variables\nDefinition 1 A random variable X has a discrete distribution if X can take on only a finite (or countably\ninfinite) number of values (x1, x2, . . .).\nDefinition 2 If random variable X has a discrete distribution, the probability density function (p.d.f.)\nof X is defined as the function\nfX (x) = P (X = x)\nIf {x1, x2, . . .} is the set of all possible values of X, then for any x /∈{x1, x2, . . .}, fX (x) = 0. Also\ninf\nfX (xi) = 1\ni=1\nThe probability that X ∈ A for A ⊂ R is\nP (X ∈ A) =\nfX (xi)\nxi∈A\nExample 1 If X is the number we rolled with a die, all integers 1, 2, . . . , 6 are equally likely. More\ngenerally, we can define the discrete uniform distribution over the numbers x1, x2, . . . , xk by its p.d.f.\nfX (x) =\nk\nif x ∈{x1, x2, . . . , xk}\notherwise\nThis corresponds to the simple probabilities for an experiment with sample space S = {x1, x2, . . . , xk}.\nExample 2 Suppose we toss 5 fair coins independently from another and define a random variable X\nwhich is equal to the observed number of heads.\nThen by our counting rules, n(S) = 25 = 32, and\nn(\"k heads\") =\n, using the rule on combinations. Therefore\nk\nP (X = 0) =\n=\n,\nP (X = 1) =\n=\n32,\nP (X = 2) =\n=\n,\nP (X = 3) =\n=\n32,\nP (X = 4) =\n=\n, and\nP (X = 5) =\n=\n.\n\nGr\nap\nh of a di\nsc\nre\nte\nunif or\nm\nprobability distribution.\nNote that these probabilities sum to 1.\nGraph of\na d\nisc\nre\nte\npr\noba\nbi\nli\nty\nd\nis\ntr\nibution for five coin tosses.\nNote that in the die roll example, every single outcome corresponded to exactly one value of the\nrandom variable. In contrast for the five coin tosses there was a big difference in the number of outcomes\ncorresponding to X = 2 compared to X = 0, say. So mapping outcomes into realizations of a random\nvariable may lead to highly skewed distributions even though the underlying outcomes of the random\nexperiment may all be equally likely.\n1.1\nThe Binomial Distribution\nTo generalize the preceding example, suppose we look at a sequence of n independent and identical trials,\neach of which can result in either a \"success\" or a \"failure\" (not necessarily with equal probability), and\nwe are interested in the total number X of successes.\nExample 3 Suppose we sample 100 pieces from a batch of car parts at the producing plant for quality\ncontrol. A piece passing the quality checks would constitute a \"success\", a piece falling short of one or\nmore of the criteria would be a \"failure\". We are interested in the distribution of failures as a function\nof the total share of defective parts in the batch in order to infer from the sample whether we have good\nreason to believe that no more than, say, 1% of the pieces don't meet the standards.\nSuppose the probability of a success equals p, and the probability of a failure is therefore q = 1 -p.\nSince the trials are independent by assumption, the probability of any given sequence of x successes and\nn -x failures in fixed order is\np x(1 -p)n-x\nImages by MIT OpenCourseWare.\n\nHowever, since we are only interested in the number X of successes, we have to take into account that\nn\nthere are\ndifferent sequences with x successes. Therefore, the probability of x successes is\nx\nP (X = x) =\nn\np x(1 -p)n-x\nx\nDefinition 3 A random variable X with probability density function\n⎧\n⎨\nn\npx(1 -p)n-x\nif x ∈{1, 2, . . . , n}\nfX (x) = P (X = x) =\nx\n⎩\notherwise\nis said to follow a binomial distribution with parameters p and n, written as\nX ∼ B(n, p)\nYou should notice that previously, we derived the probability distribution for every random experiment\nseparately, writing down the number of possible outcomes, outcomes in each event etc. The binomial\ndistribution serves as a model for a whole range of random experiments. For any given example which\nfalls into this category, we can just look up the probabilities for a given set of parameters (n, p).\nExample 4 In order to make some money off your classmates, you obtained a bent 25 cent coin that\ncomes up heads with a probability of pL = 5\n4 . Unfortunately, that coin got mixed up with your regular\nsmall coins, and only after you inserted 8 out of 9 quarters into the laundromat you notice your mistake.\nYou hastily toss the coin 10 times, and it comes up heads for a total of 8 times. Would it be a good idea to\ncontinue to rip offyour friends with the old coin trick or are you now stuck with a regular (fair) quarter\nwith pF = 1\n2 ? I.e. what is P (A|B) for A =\"remaining coin is bent\" and B =\"8 heads out of 10\"?\nIf the coin is fair,\nP (B|AC ) =\npF\n8 (1 -pF )10-8 =\nIf it is bent,\nP (B|A) =\npL\n8 (1 -pL)10-8 =\n48 · 12\nNow let's see what Bayes theorem has to say:\n48 ·12 1\nP (B|A)P (A)\n510 9\nP (A|B) =\n=\n\n=\n≈ 46.21%\nP (B|A)P (A) + P (B|AC )P (AC )\n48·12 1 +\n510 + 210\n510 9\n210 9\nTherefore, it is more likely that the coin you are left with is in fact a regular quarter - which doesn't mean\nthat in total, the probability of heads is still\nP (H|B) =\n· 46.21% +\n· 53.79% ≈ 63.86%\nHowever a better idea would of course be to do a few more tosses. If you can repeat the experiment\narbitrarily often, you will eventually be able to distinguish the two types of coins with an arbitrary degree\nof certainty. As an aside, you can see this exercise as a very basic example for a hypothesis test.\nSay you got another 8 heads out of another 10 trials (we'll call this event C), leaving the share of heads\n\nat the same value as before. Then, doing the same steps as before, this time based on the first posterior\nP (H|B) rather than the prior P (B), the conditional probability would be\n48 ·12\n510 · 46.21%\n46.21%\nP (H|B ∩C) =\n\n=\n≈ 85.51%\n48·12\n46.21% + 53.79% · 48210\n510 · 46.21% +\n210 · 53.79%\nAlternatively, if we just aggregate the two series of trials into 16 heads out of 20 trials, we get\n\nP (A|B0) =\n\n≈ 85.51%\n+\nso that it doesn't matter whether we update simultaneously or sequentially.\nThis is more generally a\ndesirable property of Bayesian updating: the final result only depends on the overall information we are\nusing, not the order in which we update.\nContinuous Random Variables\nMany types of data are results from measurements of some kind: weights, lengths, incomes etc., which\ncan - at least conceptually - take any value in some interval (sometimes all) of the real numbers. In\nthis case, the definition of a probability density function for discrete random variables is not practical,\nbecause (a) the number of possible outcomes is uncountable, so we can't just add up probabilities over\nsingle values, and (b) the probability of any particular value on the continuum typically has to be zero.\nThis is why we have to deal with this type of random variables separately from the discrete case.\nDefinition 4 A random variable X has a continuous distribution if X can take on any values in some\ninterval - bounded or unbounded - of the real line.\nFor discrete random variables, it was relatively straightforward to define a probability density function,\nsince there was only a finite number of values. A continuous random variable can take more than count\nably many values, and therefore the derivation becomes a little bit more involved.\nThe idea goes as follows: we can \"discretize\" the distribution by putting the possible values the random\nvariable can take into \"bins\", i.e. instead of looking at the probabilities P (X = x), we'll look at proba\nbilities for intervals, i.e. P (x1 ≤ X ≤ x2). The graphical representation of this is a histogram: we fix a\nset of points x0 < x1 < . . . < xn on the real line and calculate the probabilities for X falling into each\n\"bin\", i.e. interval between two subsequent points, so that P (xi-1 ≤ X ≤ xi). Then for values in the\ninterval [x0, xn], we can define a function\n⎧\n⎪\nP (x0≤X≤x1)\nif x ∈ [x0, x1)\n⎪\nx1-x0\n⎪\n⎪\n.\n⎪\n⎪\n.\n⎪\n.\n⎨\nhn(x) =\nP (xi-1≤X≤xi)\nif x ∈ [xi-1, xi)\nxi-xi-1\n⎪\n⎪\n⎪\n.\n⎪\n.\n⎪\n.\n⎪\n⎪\n⎩\nP (xn-1≤X≤xn)\nif x ∈ [xn-1, xn)\nxn-xn-1\n\nX\nX \"\n#\nDividing by the length of the interval [xi-1, xi) makes sure that the area under the graph for a given\ninterval equals the probability of the random variable X taking a value in that interval, i.e. we can\ncalculate\nk\nk\nZ xi\nZ xk\nP (xj ≤ X ≤ xk) =\nP (xi-1 ≤ X ≤ xi) =\nhn(t)dt =\nhn(t)dt\nfor xj < xk\ni=j+1\ni=j+1\nxi-1\nxj\n.5\n1.5\nDensity\n.5\n1.5\n2.5\nu\n.5\n1.5\nDensity\n.5\n1.5\n2.5\nu\nFigure 1: Histograms of the same Distribution for 10 and 30 Bins, respectively\n.5\n1.5\nDensity\n.5\n1.5\n2.5\nu\nFigure 2: Histogram with 60 Bins and Continuous Density\nThis is not completely satisfying yet, since this only allows us to calculate the probability of X falling\nbetween any two of the grid points from x0 < x1 < . . . < xn, but not e.g. of a subinterval of, say, [xj , xk].\nWe can address this by making the grid of points x1, x2, . . . finer, and therefore the intervals narrower.\nIf we shrink the distance between neighboring points xi-1, xi to an arbitrarily small \"dx\", we'll have a\nfunction hinf(x) for which the probability that X lies between any two points a and b can be expressed\n\nZ\nas the integral of hinf(x) from a to b. This limit is called the probability density function for a continuous\nrandom variable:\nDefinition 5 If random variable X has a continuous distribution, the probability density function\n(p.d.f.) of X is defined a positive function fX (x) such that for any interval A ⊂ R\nP (X ∈ A) =\nfX (t)dt\nA\nGr\naph o\nf a co nti\nnu\nous probability density distribution.\nFigure 3: P.D.F. of a Continuous Random\n\nImage by MIT OpenCourseWare.\nVariable\nFrom the axioms for a probability function, we can see that any continuous p.d.f. must satisfy\nfX (x) ≥ 0\n∀x ∈ R\nand\nZ inf\nfX (x) = 1\n-inf\nHence, if we want to know P (X ∈ A) for A = [a, b] ⊂ R, we can compute\nZ b\nP (X ∈ [a, b]) = P (a ≤ X ≤ b) =\nf(t)dt\na\nRemark 1 Note that for any x ∈ R,\nP (X = x) = 0\nif X has a continuous distribution.\nThis may seem a little counterintuitive in part also because we use continuous distributions to ap\nproximate things which are in fact discrete (e.g. income or time unemployed). So far we haven't seen\nany examples of continuous random variables in any of the probabilities we computed.\nExamples\nSuppose that a random variable is such that on some interval [a, b] on the real axis, the probability of\nX belonging to some subinterval [a0, b0] (where a ≤ a0 ≤ b0 ≤ b) is proportional to the length of that\nsubinterval.\n\nZ\nZ\nfX (x) =\nb-a\notherwise\nGraph\no\nf\na\npr\nobab\nility density function for a uniform random variable.\nFigure 4: p.d.f for a Uniform Random Variable, X ∼ [a, b]\nZ 4\nZ 4 1\nax2\nif 0 < x < 3\notherwise\na -0 = 9a\nDefinition 6 A random variable X is uniformly distributed on the interval [a, b], a < b, if it has the\nprobability density function\nif a ≤ x ≤ b\nIn symbols, we then write\nX ∼ U[a, b]\nFor example, if X ∼ U[0, 10], then\nP (3 < X < 4) =\nf(t)dt =\ndt =\nWhat is P (3 ≤ X ≤ 4)? Since the probability that P (X = 3) = 0 = P (X = 4), this is the same as\nP (3 < X < 4).\nExample 5 Suppose X has p.d.f.\nfX (x) =\nWhat does a have to be? - since P (X ∈ R) = 1, the density has to integrate to 1, so a must be such that\nZ inf\nZ 3\n\n3 3\n1 =\nfX (t)dt =\nat2dt =\nax\n=\n-inf\nTherefore, a = 9\n1 .\nWhat is P (1 < X < 2)? - let's calculate the integral\nZ 2 t2\nP (1 < X < 2) =\ndt =\n-\n=\n9 · 3\n9 · 3\nWhat is P (1 < X)?\ninf\n3 t2\n27 -1\nP (1 < X) =\nfX (t)dt =\ndt =\n=\nImage by MIT OpenCourseWare."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 6",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/a39b3988bd2f6241565473277cb82365_MIT14_30s09_lec06.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 6\nKonrad Menzel\nFebruary 24, 2009\nExamples\nSuppose that a random variable is such that on some interval [a, b] on the real axis, the probability of\nX belonging to some subinterval [a0, b0] (where a ≤ a0 ≤ b0 ≤ b) is proportional to the length of that\nsubinterval.\nDefinition 1 A random variable X is uniformly distributed on the interval [a, b], a < b, if it has the\nprobability density function\nif a ≤ x ≤ b\nfX (x) =\nb-a\notherwise\nIn symbols, we then write\nX ∼ U[a, b]\nGraph\no\nf\na\npr\nobab\nility density function for a uniform random variable.\nFigure 1: p.d.f for a Uniform Random Variable, X ∼ [a, b]\nFor example, if X ∼ U[0, 10], then\nZ 4\nZ 4 1\nP (3 < X < 4) =\nf(t)dt =\ndt =\nWhat is P (3 ≤ X ≤ 4)? Since the probability that P (X = 3) = 0 = P (X = 4), this is the same as\nP (3 < X < 4).\nImage by MIT OpenCourseWare.\n\nZ\nZ\nExample 1 Suppose X has p.d.f.\nax2\nif 0 < x < 3\nfX (x) =\notherwise\nWhat does a have to be? - since P (X ∈ R) = 1, the density has to integrate to 1, so a must be such that\nZ inf\nZ 3\nax3 3\n1 =\nfX (t)dt =\nat dt =\n=\na -0 = 9a\n-inf\nTherefore, a = 9\n1 .\nWhat is P (1 < X < 2)? - let's calculate the integral\nZ 2 t2\nP (1 < X < 2) =\ndt =\n-\n=\n9 · 3\n9 · 3\nWhat is P (1 < X)?\ninf\n3 t2\n27 -1\nP (1 < X) =\nfX (t)dt =\ndt =\n=\n1.1\nMixed Random Variables/Distributions\nMany kinds of real-world data exhibit point masses at some values mainly for two different reasons:\n- some outcomes are restricted to certain values mechanically, so a lot of probability mass tends to\ncumulate right at the corners of the range of the random variable, e.g. daily rainfall can possibly\ntake any positive real value, but there are many days at which rainfall is zero.\n- individuals taking economic decisions may respond to certain institutional rules by positioning\nthemselves right at some kind of kinks or discontinuities, e.g. if we look at incomes reported to\nSocial Security or the Internal Revenue Service, we observe \"bunching\" of individuals at the top\nends of the tax brackets (since for those individuals, a small increase in income would mean a\ndiscrete jump in the tax rate).\nThe corresponding distributions are, strictly speaking, not continuous, because even though realizations\ncan be any real-valued numbers, we can't define a probability density function as we did in the previous\nsection, but we'll have to deal with the point masses separately. Some of this is going to come up in your\neconometrics classes, but we won't spend time on this for now and only look at one example.\nExample 2 The following graph is constructed using data from the Current Population Survey (CPS)\nfor 1979.1\nFor the graph, the authors chose a subpopulation with very low income so that the fraction of the sample\nfor whom the minimum wage was binding was relatively high. There are some individuals to the left of\nthe 1979 value of the minimum wage presumably corresponding to employment in sectors which are in\npart exempt from minimum wage laws (e.g. farming, youth employment).\n1Figure 3b) on p. 1017 in DiNardo, J., N. Fortin and T. Lemieux. \"Labor Market Institutions and the Distribution of\nWages, 1973-1992: A Semiparametric Approach.\" Econometrica 64, no. 5 (1996): 1001-1044.\n\nGr\naph\nof\nlo\ng\nwages for female h\nigh-sc\nhool d\nropouts\nin 1979. The curve shows a steep peak followed by a tail.\nFigure 2: Log Wages for Female High-School\n\nImage by MIT OpenCourseWare.\nDropouts in 1979\nThe Cumulative Distribution Function (c.d.f.)\nDefinition 2 The cumulative distribution function (c.d.f.) FX of a random variable X is defined for\neach real number as\nFX (x) = P (X ≤ x)\nNote that this definition is the same for discrete, continuous or mixed random variables. In particular,\nsince we allow for X to be discrete, note that P (X ≤ x) may be different from P (X < x), so it's important\nto distinguish the corresponding events. In the definition of the c.d.f., we'll always use X \"less or equal\nto\" x.\nSince the c.d.f. is a probability, it inherits all the properties of probability functions, in particular\nProperty 1 The c.d.f. only takes values between 0 and 1\n0 ≤ FX (x) ≤ 1\nfor all x ∈ R\nAlso, since for x1 < x2, the event X ≤ x1 is included in X ≤ x2, we have\nProperty 2 FX is nondecreasing in x, i.e.\nFX (x1) ≤ FX (x2)\nfor x1 < x2\nIf we let x →-inf, the event (X ≤ x) becomes \"close\" (here I'm very sloppy about what that means)\nto the impossible event in terms of its probability of occurring, whereas if x →inf, the event (X ≤ x)\nbecomes almost certain, so that we have\nProperty 3\nlim\nF (x)\n=\nx→-inf\nlim F (x)\n=\nx→inf\n\nNote that a c.d.f. doesn't have to be continuous: if we define the left limit\nF (x -) =\nlim\nF (x -h)\nh>0,h→0\nand the right limit\nF (x +) =\nlim\nF (x + h)\nh>0,h→0\nRecall that in order to be continuous at x, F (x) must satisfy F (x-) = F (x+). This need not be true in\ngeneral, as the following example shows:\nExample 3 Consider again the experiment of rolling a die, where the random variable X corresponds\nto the number we rolled. Then the c.d.f. of X is given by\n⎧\nif x < 1\n⎪\n⎪\n⎪\n⎪\nif 1 ≤ x < 2\n⎨\nFX (x) =\n· · ·\n· · ·\n⎪\n⎪\nif 5 ≤ x < 6\n⎪\n⎪\n⎩\nif x ≥ 6\nwhich has discontinuous jumps at the the values 1, 2, . . . , 6.\nGr\nap\nh\nof\nt\nhe\nc\numu\nlativ\ne dis\ntr\nib\nut\nio\nn\nfunction of a die roll.\nFigure 3: c.d.f. of a\n\nImage by MIT OpenCourseWare.\ndie roll\nHowever, by a general result from real analysis, any monotone function (hence the c.d.f.\nFX in\nparticular) can only have countably many points of discontinuity.\nFurthermore, we always have\nProperty 4 Any c.d.f. is right-continuous, i.e.\nF (x) = F (x +)\nWe can now use our knowledge about probabilities to show some more properties of c.d.f.s\nProposition 1 For any given x,\nP (X > x) = 1 -FX (x)\n\nProof: From properties of probabilities,\nP (X > x) = 1 -P (X ≤ x) = 1 -FX (x)\nSimilarly,\nProposition 2 For two real numbers x1 < x2,\nP (x1 < X ≤ x2) = FX (x2) -FX (x1)\nProposition 3 For any x,\nP (X < x) = F (x -)\nProposition 4 For any x,\nP (X = x) = F (x +) -F (x -)\nThis last result means in particular that for continuous variables, P (X = x) = 0 for all values of x.\nExample 4 Let's check whether the function GX (x) in the following graph is a c.d.f. The function is\nGr\nap\nh\nof\na\nn\nex\nam\npl\ne\nfu\nnc\nti\non\nGX(x)\nthat is piecewise continuous.\nbetween 0 and 1, monotonically increasing, and right-continuous. Let's\n\nImage by MIT OpenCourseWare.\napply the last four propositions\nto this example (just reading numbers off the graph):\n- P (X > 4) = 1 -F (4) = 1 -\n=\n- P (3 < X ≤ 4) = 3\n4 -1\n4 = 1\n- P (X < 4) = F (4-) =\n2 = 1\n- P (X = 4) = F (4+) -F (4-)\n-\n=\nExample 5 Unlike for continuous random variables, where we have a one-line formula linking the p.d.f.\nand the c.d.f., in discrete case, have to use the results on deriving probabilities from c.d.f.s we just\ndiscussed. Let's look at the relationship in another graphical example\n\nZ\n\nGr\naph\ns\nof\n2th\ne c\numu\nlat\niv\ne\ndis\ntri\nbu\ntio\nn\nfu\nnct\nion\n(t\nop)\nan\nd\npr\nob\nabi\nli\nty\ndistr\nibution function (bottom) for a discrete random variable.\nFigure 4: c.d.f. and p.d.f. for a discrete\n\nImage by MIT OpenCourseWare.\nrandom variable\n2.1\np.d.f. and c.d.f for Continuous Random Variables\nIf X has a continuous distribution with p.d.f. f(x) and F (x) (I'll drop the X subscript from now on\nwherever there are no ambiguities), then\nx\nF (x) = P (X ≤ x) =\nf(t)dt\n-inf\nFrom the fundamental theorem of calculus, we can in this case write the relationship between c.d.f. and\np.d.f. as\nd\nF 0(x) =\nF (x) = f(x)\ndx\nExample 6 Let\nif x < 0\nF (x) =\nx\nif x ≥ 0\n1+x\nIs F (x) a c.d.f.? - let's check basic properties:\n\n- limx→-inf F (x) = 0\n- limx→inf F (x) = 1\n- F (·) is nondecreasing (can check derivative below)\nWhat is the p.d.f. f(x)?\nif x < 0\nf(x) = F 0(x) =\notherwise\n(1+x)2\nIs f(x) a p.d.f.? - well, we've essentially already shown that F (x) is a c.d.f. We can see right away that\nf(x) ≥ 0\nfor all x\nand also,\nZ inf\nf(t)dt = lim F (x) -\nlim\nF (x) = 1 -0 = 0\nx→inf\nx→-inf\n-inf\nExample 7 If X ∼ U[0, 1], then its c.d.f. is\n⎧\nZ x\n⎨ 0\nif x < 0\nFX (x) =\nfX (t)dt =\nx\nif 0 ≤ x < 1\n⎩\n-inf\nif x ≥ 1\nGr\nap\nhs\n\nof\nt\nhe cum\nulativ\ne\ndi\nstribution function (top) and probability distribution function (bottom) for a continuous uniform random variable.\nFigure 5: p.d.f. and c.d.f. for\n\nImage by MIT OpenCourseWare.\nX ∼U[a, b]\n\nX\nJoint Distributions of 2 Random Variables X, Y\nIn many situations, we are interested not only in a single random variable, but may care about relationship\nbetween two or more variables, e.g. whether the outcome of some process affects the outcome of another.\nE.g. we could look at\n- IQs of identical twins - i.e. X would be one kid's IQ, and Y that of her/his sibling\n- educational attainment X and income Y : while we could look at the distributions of income or\neducation separately, we can also plot both variables together for observations from a data set. And\nin the graph it looks like there is in fact a non-trivial relationship between the variables.\nGraph o\nf income vs. years of schooling. The scatter plot shows an increasing trend with some outliers.\nFigure 6: Schooling\n\nImage by MIT OpenCourseWare.\nand Income\n- relapse times: since it is often not possible to remove a cancer completely by surgery, we may want\nto evaluate the effectiveness of a medical procedure, by looking at how long it takes until either (a)\na new operation becomes necessary (X), or (b) the patient dies (Y ). While we are interested in\neither outcome, both outcomes are interdependent: if the patient dies before a new operation, we\nsimply don't observe when he would have had to undergo surgery otherwise.\nIn this part of the class, we will consider the properties of two (or more) random variables simultane\nously, including their relationship. We will also introduce concepts analogous to \"independence\" and\n\"conditional probabilities\" of events.\nWe let (X, Y ) be a pair random variables that (jointly) takes values (x, y), and either variable can be\ncontinuous, discrete, or mixed.\n3.1\nDiscrete Random Variables\nIn the discrete case, the joint p.d.f. is given by\nfXY (x, y) = P (X = x, Y = y)\nfor any (x, y) ∈ R2 . If {(x1, y1), . . . , (xn, yn)} contains all possible values of (X, Y ), then\nn\nfXY (xi, yi) = 1\ni=1\n\nX\nX X\nFor any subset A ⊂ R2 ,\nP ((X, Y ) ∈ A) =\nfXY (x, y)\n(x,y)∈A\nExample 8 In a supermarket, let X be the number of people in the regular checkout line, and Y the\nnumber of people in the express line. Then the joint p.d.f. of X and Y could look like this: A table of this\nfXY\nY\nTotal\nX\n0.1\n0.05\n0.15\n0.05\n0.2\n0.25\n0.05\n0.2\n0.1\n0.35\n0.05\n0.1\n0.15\n0.05\n0.05\n0.1\n0.2\n0.5\n0.25\n0.05\nform, summarizing the cell-probabilities from the joint p.d.f. of (X, Y ), and the marginal probabilities on\nthe sides, is also called a contingency table. As argued before, the probabilities in the table should add up\nto one, and they do.\nWe can see from the entries that there seems to be some relationship between the two variables: when the\nnumber of individuals at the regular checkout is high, then the number of persons in the express line also\ntends to be high.\nWe can also calculate probabilities for different events based on the p.d.f. as given in the table:\nP (X = 2)\n=\n0 + 0 + 0.1 + 0.1 + 0.05 = 0.25\nP (X ≥ 2, Y ≥ 2)\n=\nfXY (x, y) = 0.1 + 0.1 + 0.05 + 0 + 0 + 0.05 = 0.3\nx=2 y=2\nP (|X -Y | ≤1)\n=\nP (X = Y ) + P (|X -Y | = 1)\n=\n0.1 + 0.2 + 0.1 + 0 + 0.05 + 0.05 + 0.2 + 0 + 0.1 + 0 + 0.05 = 0.85"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 7",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/5eb6b62623ac2e828079db609e0a44b5_MIT14_30s09_lec07.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nZ Z\nZ\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 7\nKonrad Menzel\nFebruary 26, 2009\nJoint Distributions of 2 Random Variables X, Y (ctd.)\n1.1\nContinuous Random Variables\nIf X and Y are continuous random variables defined over the same sample space S. The joint p.d.f. of\n(X, Y ), fXY (x, y) is a function such that for any subset A of the (x, y) plane,\nP((X, Y ) ∈ A) =\nfXY (x, y)dxdy\nA\nAs in the single-variable case, this density must satisfy\nfXY (x, y) ≥ 0\nfor each (x, y) ∈ R2\nand\nZ inf\ninf\nfXY (x, y)dxdy = 1\n-inf\n-inf\nNote that\n- any single point has probability zero\n- any one-dimensional curve on the plane has probability zero\nExample 1 A UFO appears at a random location over Wyoming, which - ignoring the curvature of the\nEarth - can be described quite accurately as a rectangle of 276 times 375 miles. The position of the UFO\nis uniformly distributed over the entire state, and can be expressed as a random longitude X (ranging\nfrom -111 to -104 degrees) and latitude Y (with values between 41 and 45 degrees).\nThis means that the joint density of the coordinates is given by\nfXY (x, y) =\nif -111 ≤ x ≤-104 and 41 ≤ y ≤ 45\notherwise\nIf the UFO can be seen from a distance of up to 40 miles, what is the probability that it can be seen from\nCasper, WY (which is roughly in the middle of the state)?\nLet's look at the problem graphically: This suggests that the set of locations for which the UFO can be\nseen from Casper can be described as a circle with a 40-mile radius around Casper. Also, for the uniform\ndensity, the probability of the UFO showing up in a region A (i.e. the integral of a constant density over\n\nGrap\nh\nof\njoint density function of lives X and Y for sparkplugs 1 and 2.\n\nDiagram of\nWyoming sho\nwing where\nan UFO can\nbe view\ned from\nCaspar.\nFigure 1: The UFO at (x, y) can be seen\n\nImage by MIT OpenCourseWare.\nfrom Casper, WY\nA) of the state is proportional to the area of A. Therefore, we don't have to do any integration, but finding\nthe probability reduces to a purely geometric exercise. We can calculate the probability as\nArea(\"less than 40 miles from Casper\")\n402π\nP(\"less than 40 miles from Casper\") =\n=\n≈ 4.9%\nArea(\"All of Wyoming\")\n375 · 276\nYou should notice that for the uniform distribution, there is often no need to perform complicated inte\ngration, but you may be able to treat everything as a purely geometric problem.\nUnlike in the last example, typically, there's no way around integrating the density function in order to\nobtain probabilities, since any nonconstant density re-weights different regions in terms of probability\nmass. We'll do this in the clean, systematic fashion in the following example:\nExample 2 Suppose you have 2 spark plugs in your lawn mower, and let X be the life of spark plug 1,\nand Y the life of spark plug 2. Suppose we can describe the distribution by\nλ2e-λ(x+y)\nif x ≥ 0 and y ≥ 0\nfXY (x, y) =\notherwise\nFigure 2 on page 2 shows what the joint density looks like.\nFigure 2: Joint Density of Lives X and\n\nImage by MIT OpenCourseWare.\nY of Sparkplugs 1 and 2\n\nIn fact, this density can be derived from the assumption that the spark plugs fail independently of one\nanother at a fixed rate λ, which doesn't change over their lifetime.\nIf the lawn mower is going to work as long as either spark plug works, what is the probability that the\nlawn mower fails within 1000 hours?\nGraph\nof f\nv\ner\nsus x and y.\nFigure 3: The Event \"Lawn Mower Fails before 1000 hrs.\" in first situation\nZ 1000 Z 1000\nP(X ≤ 1000, Y ≤ 1000)\n=\nλ2 e -λ(x+y)dydx\nZ 1000 Z 1000\n=\nλ2 e -λx e -λydydx\nZ 1000\nZ 1000\n=\nλe-λx\nλe-λydy\ndx\nZ 1000\n=\nλe-λx\n1 -e -1000λ\ndx\n=\n1 -e -1000λ\nWhat is that probability if the second spark plug is only used if the first one fails, i.e. how do we calculate\nP(X + Y ≤ 1000)? Note that this only changes the \"event\" we care about, i.e. the region of R2 we\nGraph\nof f\nv\ner\nsus x and y.\nFigure 4: The Event \"Lawn Mower Fails\n\nImage by MIT OpenCourseWare.\nbefore 1000 hrs.\" in second situation\nintegrate over, but we still integrate the same density.\nZ 1000 Z 1000-x\nP(X + Y ≤ 1000)\n=\nλ2 e -λx e -λydy dx\nZ 1000\nZ 1000-x\n=\nλe-λx\nλe-λydy dx\nImage by MIT OpenCourseWare.\n\nZ\nZ\nX X\nX\nX\nZ 1000\nh\ni\n=\nλe-λx 1 -e -λ(1000-x) dx\nZ 1000\n=\nλ\n\ne -λx -e -1000λ\ndx\n=\n1 -e -1000λ -1000λe-1000λ = 1 -(1 + 1000λ)e -1000λ\nAgain, events over continuous bivariate random variables correspond to areas in the plane, and we find\nprobabilities by integrating the density over those areas.\nJoint c.d.f. of 2 Random Variables X, Y\nI'll just give definitions. We are not going to use this a lot in this class, but you should have seen this.\nDefinition 1 The joint c.d.f.\nfor random variables (X, Y ) is defined as the function FXY (x, y) for\n(x, y) ∈ R2\nFXY (x, y) = P(X ≤ x, Y ≤ y)\nWe compute probabilities from joint c.d.f.s as follows\nP(a ≤ X ≤ b, c ≤ Y ≤ d) = F(b, d) -F(a, d) -F(b, c) + F(a, c)\nWe have to add in the last term because in a sense, it got subtracted off twice before.\nJoint c.d.f.s are related to p.d.f.s in the following way: for continuous random variables,\ny\nx\nFXY (x, y)\n=\nfXY (u, v)dudv\n-inf\n-inf\n∂2\nfXY (x, y) =\nFXY (x, y)\n∂y∂x\nIn the discrete case,\nFXY (x, y) =\nfXY (u, v)\nu≤x v≤y\nMarginal p.d.f.s\nIf we have a joint distribution, we may want to recover distribution of one variable X.\nIf X and Y are discrete random variables with joint p.d.f. FXY , then\nfX(x)\n=\nfXY (x, y)\nall y\nfY (y)\n=\nfXY (x, y)\nall x\nIf X and Y are continuous, we'll essentially replace summation by integration, so that\nZ inf\nfX(x)\n=\nfXY (x, y)dy\n-inf\nZ inf\nfY (y)\n=\nfXY (x, y)dx\n-inf\n(1)\n\nZ\nExample 3 This example is based on real-world data extra-marital affairs collected by the Redbook mag\nazine in 1977.1 In the survey, individuals were asked to rate their marriage on a scale from 1 (unhappy)\nto 3 (happy), and to report the number of extra-marital affairs, divided by the number of years married.\nFor now let's look at the joint distribution of \"marriage quality\", X, with duration of marriage in years,\nY . We can start from the \"cell\" probabilities given by the joint p.d.f., and then fill in the marginal p.d.f.s\non the left and at the bottom of the table:\nIt is interesting to note that, even though the marginal distributions are relatively even, the joint distribu-\nY\nfXY\nfX\n4.66%\n11.48%\n12.98%\n29.12%\nX\n5.16%\n14.81%\n12.31%\n32.28%\n13.48%\n16.47%\n8.65%\n38.60%\nfY\n23.30%\n42.76%\n33.94%\n100.00%\ntion seems to be concentrated along the bottom left/top right diagonal, with the joint p.d.f. taking much\nlower values in the top-left and bottom-right corners of the table.\nExample 4 Recall the example with the two spark plugs from last time. The joint p.d.f. was\nλ2e-λ(x+y)\nif x ≥ 0 and y ≥ 0\nfXY (x, y) =\notherwise\nThe marginal density of X is\nZ inf\ninf\nfX(x)\n=\nfXY (x, y)dy =\nλ2 e -λ(x+y)dy\n-inf\nZ inf\n=\nλe-λx\nλe-λydy = λe-λx[1 -0] = λe-λx\nSimilarly,\nfY (y) = λe-λy\nIndependence\nRecall that we said that two events A and B were independent if P(AB) = P(A)P(B). Now we'll define\na similar notion for random variables.\nDefinition 2 We say that the random variables X and Y are independent if for any regions A, B ⊂ R,\nP(X ∈ A, Y ∈ B) = P(X ∈ A)P(Y ∈ B)\nNote that this requirement is very strict: we are looking at events of the type X ∈ A and Y ∈ B and\nrequire that all pairs of them are mutually independent.\nThis definition is not very practical per se, because it may be difficult to check, however if X and Y are\nindependent, it follows from the definition that in particular\nFXY (x, y) = P(X ≤ x, Y ≤ y) = P(X ≤ x)P(Y ≤ y) = FX(x)FY (y)\nFrom this, it is possible to derive the following condition which is usually much easier to verify\n1Data available at http://pages.stern.nyu.edu/ wgreene/Text/Edition6/tablelist6.htm\n\nZ\nZ\nZ\nZ\n\nZ\nZ\nProposition 1 X and Y are independent if and only if their joint and marginal p.d.f.s satisfy\nfXY (x, y) = fX(x)fY (y)\nProof:\nFor discrete random variables, this follows directly from applying the definition to A = {x}\nand B = {y}. For continuous random variables, we can show that if X and Y are independent, we can\ndifferentiate the equation\nFXY (x, y) = FX(x)FY (y)\non both sides in order to obtain\n∂2\n∂2\n∂\nfXY (x, y) =\nFXY (x, y) =\n[FX(x)FY (y)] =\nfX(x)FY (y) = fX(x)fY (y)\n∂y∂x\n∂y∂x\n∂y\nConversely, if the product of the marginal p.d.f.s equals the joint p.d.f., we can integrate\nP(X ∈ A, Y ∈ B)\n=\nfXY (x, y)dydx =\nfX(x)fY (y)dydx\nA\nB\nA\nB\n=\nfX(x)dx\nfY (y)dy\nA\nB\nso that the condition on the marginals implies independence, and we've proven both directions of the\nequivalence\nExample 5 Going back to the data on extra-marital affairs, remember that we calculated the marginal\np.d.f.s of reported \"marriage quality\", X, and years married, Y as\nfX(1) = 29.12%,\nfX(2) = 32.28%,\nfX(3) = 38.60%\nand\nfY (1) = 23.30%,\nfY (8) = 42.76%,\nfY (12) = 33.94%\nWhat should the joint distribution look like if the two random variables were in fact independent? E.g.\nf XY (3, 1) = fX(3)fY (1) = 38.60% · 23.30% = 8.99%\nThe actual value of the joint p.d.f. at that point was 13.48, so that apparently, the two variables are\nnot independent. We can now fill in the remainder of the table under the assumption of independence:\nComparing this to our last table we see some systematic discrepancies - in particular, the constructed\nY\nf XY\nfX\n6.78%\n12.45%\n9.88%\n29.12%\nX\n7.52%\n14.81%\n10.96%\n32.28%\n8.99%\n16.50%\n13.10%\n38.60%\nfY\n23.30%\n42.76%\n33.94%\n100.00%\njoint p.d.f. f XY is not as strongly concentrated on the diagonal, which seemed to be a noteworthy feature\nof the actual joint p.d.f..\nBut does this really mean that X and Y are not independent?\nOne caveat is that we calculated the\nprobabilities in the joint p.d.f. from a sample of \"draws\" from the underlying distribution, so there is\nsome uncertainty over how accurately we could measure the true cell probabilities. In the last part of the\nclass, we will see a method of testing formally whether the differences between the \"constructed\" and the\nactual p.d.f. are large enough to suggest that the random variables X and Y are in fact not independent.\n\nExample 6 Recall the example with the two spark plugs from last time. The joint p.d.f. was\nλ2e-λ(x+y)\nif x ≥ 0 and y ≥ 0\nfXY (x, y) =\notherwise\nand in the last section we derived the marginal p.d.f.s\nfX(x)\n=\nλe-λx\nfY (y)\n=\nλe-λy\nTherefore, the product is\nfX(x)fY (y) = λ2 e -λx e -λy = fXY (x, y)\nso that the lives of spark plug 1 and 2 are independent.\nRemark 1 The condition on the joint and marginal densities for independence can be restated as follows\nfor continuous random variables: Whenever we can factor the joint p.d.f. into\nfXY (x, y) = g(x)h(y)\nwhere g(·) depends only on x and h(·) depends only on y, then X and Y are independent. In particular,\nwe don't have to calculate the marginal densities explicitly.\nExample 7 Say, we have a joint p.d.f.\nce -(x+2y)\nif x ≥ 0, y ≥ 0\nfXY (x, y) =\notherwise\nThen we can choose e.g. g(x) = ce-x and h(y) = e-2y, and even though these aren't proper densities,\nthis is enough to show that X and Y are independent.\nExample 8 Suppose we have the joint p.d.f.\ncx2y\nif x2 ≤ y ≤ 1\nfXY (x, y) =\notherwise\nCan X and Y be independent?\nEven though in either case (i.e. whether x 2 ≤ y ≤ 1 holds or whether it doesn't) the p.d.f. factors into\nfunctions of x and y (for the zero part, that's trivially true), we can also see that the support of X depends\non the value of Y , and therefore, X and Y can't be independent - e.g. if X ≥ 2\n1 , we must have Y ≥ 1\n4 ,\nso that\n\nP\nX ≥\n, Y ≤\n= 0 < P\nX ≥\nP\nY ≤\nNote that the joint support of two random variables has to be rectangular (possibly all of R2) in order\nfor X and Y to be independent: if it's not, for some realizations of X, certain values of Y would be ruled\nout which could occur otherwise. But if that were true, knowing X does give us information about Y , so\nthey can't be independent. However, this condition on the support alone does not imply independence."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 8",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/9cda4d4c7bbf21f05d493c0888a45119_MIT14_30s09_lec08.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 8\nKonrad Menzel\nMarch 3, 2009\nConditional p.d.f.s\nDefinition 1 The conditional p.d.f. of Y given X is\nfXY (x, y)\nfY |X (y|x) =\nfX (x)\nNote that if X and Y are discrete,\nP (Y = y|X = x)\nfY |X (y|x) =\nP (X = x)\nwhich just corresponds to the conditional probability of the event corresponding to X = x given Y = y\nas defined two weeks ago.\nNote that\n- for a particular value of the conditioning variable, the conditional p.d.f. has all the properties of a\nusual p.d.f. (i.e. positive, integrates to 1)\n- the definition generalizes to any number of random variables on either side\nExample 1 Let's go back to the data on extra-marital affairs, and look at the variables we are actually\nmost interested in: the number of affairs during the last year, Z, and self-reported \"quality\" of the\nmarriage, X. The joint p.d.f. is given by Since three quarters of respondents reported not having had\nZ\nfXZ\nfX\n17.80%\n4.49%\n6.82%\n29.12%\nX\n24.29%\n3.83%\n4.16%\n32.28%\n32.95%\n3.33%\n2.33%\n38.60%\nfZ\n75.04%\n11.65%\n13.31%\n100.00%\nan affair, it might be more instructive to look at the p.d.f. of the number of affairs Z conditional on the\nrating of marriage quality. Conditional on the low rating, X = 1, we have\nfXZ (1, 0)\n17.80%\nfZ|X (0|1) =\n=\n= 61.13%\nfX (1)\n29.12%\n\nfZ|X\nZ\nX\n61.13%\n15.42%\n23.42%\n75.25%\n11.86%\n12.88%\n85.36%\n8.63%\n6.04%\nPutting the conditional c.d.f.s for the values of X = 1, 2, 3 together in a table, we get\nWhy is this exercise interesting? - while in the table with the joint p.d.f., the overall picture was not very\nclear, we can see that for lower values of marriage quality X, the conditional p.d.f. puts higher probability\nmass on higher numbers of affairs.\nDoes this mean that dissatisfaction with marriage causes extra-marital affairs? Certainly not: we could\njust do the reverse exercise, and look at the conditional p.d.f. of reported satisfaction with marriage, X,\ngiven the number of affairs, Z. E.g.\nfXZ (1, 0)\n17.80%\nfX|Z (1, 0) =\n=\n= 23.72%\nfZ (0)\n75.04%\nor, summarizing the conditional p.d.f.s in a table:\nWe see that the conditional p.d.f. of X given a larger number of affairs, Z, puts more probability on lower\nZ\nfX|Z\n23.72%\n38.54%\n51.24%\nX\n32.37%\n32.88%\n31.25%\n43.91%\n28.58%\n17.51%\nsatisfaction with the marriage. So we could as well read the numbers as extra-marital affairs ruining the\nrelationship. This is often referred to as \"reverse causality\": even though we may believe that A causes\nB, B may at the same time cause A.\nTherefore, even though the conditional distributions shift in a way which is compatible with either story,\nwe can't interpret the relationship as \"causal\" in either direction, because both stories are equally plausible,\nand presumably in reality, there is some truth to either of them.\nReview\nI don't expect you to memorize any of the examples we did in class, however, especially for \"text\"\nproblems they can be extremely helpful as \"models\" for particular situations/problems. Often you can\nfind a solution strategy to a given question by seeing analogies to examples we discussed in the lecture.\n1. Probability\nSample Space, Set Theory and Basic Operations\nwon't discuss this\n\n!\n\nX\nDefinition of probability\n(P1) P (A) ≥ 0 for all A ⊂ S\n(P2) P (S) = 1\n(P3) if A1, A2, . . . is a sequence of disjoint sets,\ninf\ninf\nP\nAi\n=\nP (Ai)\ni=1\ni=1\nSpecial Case: Simple Probabilities\n- S finite\n- P (A) = n(A) where n(B) denotes the number of outcomes in set B\nn(S)\nProperties of Probability Functions\n- P (AC ) = 1 -P (A)\n- P (∅) = 0\n- if A ⊂ B, then P (A) ≤ P (B)\n- 0 ≤ P (A) ≤ 1 for any event A ⊂ S\n- P (A ∪B) = P (A) + P (B) -P (A ∩B)\nCalculating Probabilities\nTry to attack problems in this order\n(i) define sample space and the event of interest in terms of outcomes\n(ii) for simple probabilities, make sure that you defined the sample space in a way that makes each\noutcome equally likely\n(iii) if you are stuck, start writing out outcomes in sample space explicitly\nCounting Rules\n- basic set-up: have set X1, . . . , XN of N objects\n- multiplication rule: have to be able to factor an experiment into k parts such that the number of\noutcomes mi in each of them does not depend on the outcomes in the other parts. Sometimes tricky\n(e.g. chess example).\n- several different ways of drawing k objects from the set (should remember those for the exam):\n1. k draws with replacement, order matters: N k possibilities\n2. k draws without replacement, order matters (special case: permutation, k = N):\n(N\nN\n-\n!\nk)!\npossibilities\n\n3. k draws without replacement, order doesn't matter (combination):\nN\nk\n= (N-\nN\nk\n!\n)!k! possi\nbilities (e.g. in binomial distribution, count the number of all different sequences of \"successes\"\nwhich give the same overall number of successes).\n- partitions: number of ways of allocating N objects across k groups, identities of objects don't\nmatter (e.g. number of different allocations a five identical blue balls to four urns): in general\nN + k -1\npossibilities, will discuss this below\nk -1\n- we saw that in one way or another, all these counting rules derive from the multiplication rule,\nwhere sometimes we had to divide by the number of different possibilities of obtaining the same\nevent (e.g. different orders of drawing the same combination).\nIndependence, Conditional Probability, Bayes' Theorem\n- A and B are independent if P (AB) = P (A)P (B)\n- conditional probability P (A|B) = P (AB) if P (B) > 0\nP (B)\n- P (A|B) = P (A) if, and only if, A and B are independent\n- law of total probability: if B1, . . . , Bn partition of S,\nP (A) = P (A|B1)P (B1) + . . . + P (A|Bn)P (Bn)\nThe law of total probability links conditional to marginal probabilities, i.e. how to relate P (A)\nto P (A|B1), . . . , P (A|Bn). Classical application: aggregating over subpopulations/subcases, e.g.\ndeath rates over different types of bypass surgery.\n- Bayes' Theorem (simple formulation): if P (B) > 0, then\nP (B|A)P (A)\nP (B|A)P (A)\nP (A|B) =\n=\nP (B)\nP (B|A)P (A) + P (B|AC )P (AC )\nBayes' Theorem tells us how to switch the order of conditioning, i.e.\nhow to go from P (B|A)\nto P (A|B). Classical application: update beliefs about event A given data B, e.g. medical test\nexample.\n- \"base rates\" matter a lot\nFor the exam, you should know these relationships by heart.\n2. Random Variables and Distribution Functions\n- random variables give numerical characterization of random events.\n- random variable X is a function from the sample space S to the real numbers R.\n- probability function on S induces a probability distribution of X in R,\nP (X ∈ A) = P {s ∈ S : X(x) ∈ A}\n\nZ\n\nX\nZ\n- probability density function (PDF) fX (x) is defined by\nP (X = x)\n=\nfX (x)\nif X is discrete\nP (X ∈ A)\n=\nfX (t)dt\nA\n- the cumulative distribution function (CDF) FX (x) is defined by\nFX (x) = P (X ≤ x)\nAs an important example for a discrete random variable, we spent some time looking at the Binomial\ndistribution, which describes the number X of \"successes\" in a sequence of N independent trials, with\na success probability equal to p for each trial. The p.d.f for the binomial distribution was (you should\nknow this for the exam)\nfX (x) = P (X = x) =\nN\np x(1 -p)N-x\nx\nRelationship between CDF and PDF\nGetting from the PDF to the CDF\n- if X is discrete, add up\nFX (x) =\nfX (xi)\nxi≤x\n- if X is continuous, integrate\nx\nFX (x) = P (X ≤ x) =\nfX (t)dt\n-inf\nGetting from the CDF to the PDF\n- if X is discrete,\nfX (x) = FX (x +) -FX (x -)\n- if X is continuous\nF 0\nd\nfX (x) =\nX (x) =\nFX (x)\ndx\nAlso, recall main properties of CDF\n- 0 ≤FX (x) ≤ 1 for all x ∈ R\n- FX (x) nondecreasing in x\n- FX (x) continuous from the right\n- FX (x) is continuous everywhere if and only if X is continuous\n\nJoint Distributions\nLooked at\n- joint PDF for X and Y (discrete or continuous)\n- marginal distribution of X with PDF\nZ inf\nfX (x) =\nfXY (x, y)dy\n-inf\n- independence of random variables, most importantly\nfXY (x, y) = fX (x)fY (y)\nfor all (x, y) ∈ R2\nif and only if X and Y are independent\n- conditional distribution of Y given X,\nfXY (x, y)\nfY |X (y|x) =\nfY (y)\nRandom Problems\nExample 2 (Spring 2003 Exam) A Monet expert is given a painting purported to be a lost Monet.\nHe is asked to assess the chances that it is genuine and has the following information:\n- In general, only 1% of the \"found\" paintings he receives turn out to be genuine, an event we'll call\nG\n- \"Found\" paintings have a different frequency of use of certain pigments than genuine Monets do:\n(a) cadmium yellow Y appears in 20% \"found\" paintings, but only 10% genuine ones\n(b) raw umber U appears in 80% of \"found\" paintings, but only 40% of genuine ones\n(c) burnt sienna S appears in 40% of \"found\", but 60% of genuine paintings\n- This particular painting uses burnt sienna, but not cadmium yellow or raw umber.\nWhat is the probability that this particular painting is genuine?\nDo we have to make any additional\nassumptions to answer the question?\nThis problem has the following structure: the problem seems to tell us what colors (\"data\" SY C U C )\nare how likely to appear given that the painting is genuine (\"state of the world\" G), i.e. P (B|A). But\nwe actually want to know how likely the painting is genuine given the colors that were used in it, i.e.\nP (A|B). So we are trying to switch the order of conditioning, so we'll try to use Bayes' Theorem.\nLet's first compile the information contained in the problem:\nP (Y )\n=\n0.2\nP (Y |G)\n=\n0.1\nP (U)\n=\n0.8\nP (U|G)\n=\n0.4\nP (S)\n=\n0.4\nP (S|G)\n=\n0.6\n\nand\nP (G) = 0.01\nBut what do we need to apply Bayes' theorem? - the theorem tells us that\nP (G|SY C U C ) = P (SY C U C |G)P (G)\nP (SY C U C )\nHowever, know only marginal probability of each color, but would need joint probabilities (both condi\ntional on G and unconditional).\nTherefore we have to make an additional assumption at this point, and the simplest way to attack this\nis to assume that the use of pigments is independent across the three colors, both unconditionally and\nconditional on G, i.e.\nP (SY C U C |G) = P (S|G)P (Y C |G)P (U C |G) = 0.6 · 0.9 · 0.6\nand\nP (SY C U C ) = P (S)P (Y C )P (U C ) = 0.4 · 0.8 · 0.2\nUsing Bayes' theorem we get therefore that under the independence assumption\n0.6 · 0.9 · 0.6 · 0.01\nP (G|SY C U C ) =\n=\n0.4 · 0.8 · 0.2\nTo see how much this assumption mattered, can invent a different dependence structure among the\ndifferent types of pigments: suppose that for genuine Monets, every painting using sienna S also uses\numbra U for sure. Then, by the definition of conditional probabilities\nP (SY C U C |G) ≤ P (SU C |G) = P (U C |SG)P (S|G) = 0 · 0.6 = 0\nso that for a true Monet, it is impossible to find sienna S, but not umbra, therefore we'd know for sure\nthat the painting in questions can't be a Monet (note that since our painting had this combination, it\nhas to be possible for \"found\" paintings in general).\nSo, summing up, this problem did not give us enough information to answer the question.\nExample 3 (Exam Fall 1998) Recycling is collected at my house sometime between 10am and noon,\nand any particular minute is as likely as any other.\nGarbage is collected sometime between 8:30am\nand 11:00am, again with any particular instant as likely as any other.\nThe two collection times are\nindependent.\n(a) What is the joint p.d.f. of the two collection times, R and G?\n(b) What is the probability that the recycling is collected before garbage?\nThe marginal distribution of R is (continuous) uniform with density\nfR(r) =\nif r ∈ [10, 12]\notherwise\nThe marginal distribution of G is discrete with p.d.f.\nfG(g) =\nif g ∈ [8.5, 11]\notherwise\n\nBy independence, the joint p.d.f. is\nif r ∈ [10, 12] and g ∈ [8.5, 11]\nfGR(g, r) = fG(g)fR(r) =\notherwise\nThe probability of the event R ≤ G can be calculated as\nZ 11 Z max{g,10} 1\nZ 11 max{g -10, 0}\nZ 11 g -10\ng2\nP (R ≤ G) =\ndrdg =\ndg =\ndg =\n-2g\n=\n-2 =\n8.5\n8.5\nExample 4 One of your classmates asked how one can solve the following problem: how many different\nways are there to allocate N indistinguishable blackboards to k different classrooms? This corresponds to\nchoosing a partition of blackboards over k classes. We can do the calculation as follows:\n- introduce k -1 \"separators\" Z1, Z2 . . . , Zk-1, which we mix with the blackboards B1, B2, . . . , BN\n- represent each allocation of blackboards to rooms as a reordering of B1, B2, . . . , BN , Z1, Z2, . . . , Zk-1.\nThe blackboards before the first Z to appear in the sequence are those which we are going to put up\nin the first classroom, the boards up to the second \"separator\" go into room 2, etc. If the sequence\nis e.g. Z5, B7, B2, B5, Z4, B9, . . ., then there is going to be no blackboards in room 1, boards 7, 2,\nand 5 go to room 2 etc.\n- the number of different orderings of the sequence is (N + (k -1))!\n- since blackboards and separators are equivalent (classrooms aren't), we have to divide by the number\nof permutations of each the blackboards (N! permutations), and the separators ((k -1)! permuta\ntions).\n- putting all pieces together, we have\n(N + k -1)!\nN + k -1\np =\n=\nN!(k -1)!\nk -1\npossible allocations."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture Notes 9",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/73fdac8f3116a25185265124138c33e6_MIT14_30s09_lec09.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n14.30 Introduction to Statistical Methods in Economics\nLecture Notes 9\nKonrad Menzel\nMarch 10, 2009\nFunctions of Random Variables\nIn this part of the lecture we are going to look at functions of random variables, Y = u(X). Note that Y\nis again a random variable: since X is a mapping from the sample space S into the real numbers,\nX : S\nR\n→\nand u : R\nR, the composition of u and X is also a mapping from S into the real numbers:\n→\nY = u\nX : S\nR\n*\n→\nExample 1 If X is the life of the first spark plug in a lawnmower, and Y the life of the second, we may\nbe interested in the sum of the two, Z = X + Y .\nExample 2 Before coming to MIT, I applied for several German fellowships, so I would receive a monthly\nstipend of X Euros, depending on which fellowship I was going to get, and the exchange rate in, say,\nSeptember 2005 was going to be Y Dollars per Euro. Each quantity was uncertain at the time I was\napplying, but since I was going to spend the money in the US, the main quantity of interest was the dollar\namount Z = X ∗Y I was going to receive (at least in terms of the Dollar exchange rate, I could not\ncomplain).\nWe now want to know how to obtain the density and c.d.f. for the transformed random variable u(X),\nso we can treat each problem involving a function of a random variable in the same way as a question\ninvolving only the random variable itself with a known p.d.f.\nWe'll consider three cases:\n1. underlying variable X discrete\n2. underlying variable X continuous\n3. X continuous and u(X) strictly increasing\nThe last case is of course a special case of the second, but we'll see that it's much easier to work with.\n\nX\n\nZ\n\n1.1\nDiscrete Case - \"2-Step\" Method\nIf X is a discrete random variable with p.d.f. fX (x), and Y = u(X), where u( ) is a known deterministic\n·\nfunction. Then\nfY (y) = P (Y = y) = P (u(X) = y) =\nfX (x)\nx:u(x)=y\nExample 3\nif\nfX (x) =\nx ∈{-2, -1, 0, 1, 2}\notherwise\nThen if Y = g(X) = X ,\n|\n|\n⎧\n⎪ fX (0) = 1\nif y = 0\n⎪\nfY (y) =\n⎨ fX (-1) + fX (1) = 5\nif y = 1\n⎪ fX (-2) + fX (2) = 2\nif y = 2\n⎪\n⎩ 0\notherwise\nNote that if X is discrete, then Y is also discrete.\n1.2\nContinuous Case - \"2-Step\" Method\nIf X is a continuous random variable with p.d.f. fX (x), and Y = u(X), then the c.d.f. of Y is given by\nFY (y) = P (Y ≤y) = P (u(X) ≤y) =\nfX (x)dx\nx:u(x)≤y\nIf Y is also continuous, then\nd\nfY (y) =\nFY (y)\ndy\nNote that even if X is continuous, Y need not be continuous.\nExample 4 Y = dXe, the largest integer smaller than X, is discrete regardless whether X is continuous\nor discrete.\nExample 5\nfX (x) =\nif -1 ≤x ≤1\notherwise\nLet's look at\nY = X2\nFrom X ∈[-1, 1], it follows that Y = [0.1]. How do we get the density of Y ? For y ∈[0, 1], the c.d.f. is\nZ √y\nFY (y) = P (Y ≤y) = P (X2 ≤y) = P (-√y ≤X ≤√y) =\n1 dx = √y\n-√y 2\nIn sum\n⎧\n⎨ 0\nif y < 0\nFY (y) =\n√y\nif y ∈[0, 1)\n⎩ 1\nif y ≥1\nSince Y is continuous, we can derive the density\n\nd\n2√y\nif y ∈[0, 1]\nfY (y) =\nFY (y) =\ndy\notherwise\n\nGraph of square root o\nf y.\nZ\nZ\n\n(\n\n1.3\nChange of Variables Formula for One-to-One Transformations\nIt is in general not very convenient to derive the density of Y from the density fX (x) of X through the\nc.d.f.s, in particular because this involves one integration and one differentiation. So one might wonder\nwhether there is a more direct connection between the p.d.f.s.\nBefore going to the more general case, suppose u(x) = ax for some constant a > 0. Then the c.d.f. of\nY = u(X) = aX is given by\ny\nFY (y) =\nfX (x)dx =\nfX (x)dx = FX\ny\na\nax≤y\nx≤a\nUsing the chain rule, we can derive the p.d.f. of Y\nd\nd\ny\n1 d\nfY (y) =\nFY (y) =\n=\nFX (x) =\nfX (x)\nFX\ndy\ndy\na\na dx\na\nWhat is a good intuition for this? - if a > 1, we could think of the transformation as stretching the axis\non which the random variable falls. This moves any pair of points on the axis apart by a factor of a,\nbut leaves constant the probability that the variable falls between the points. Therefore, the distribution\nof Y is \"thinned out\" by a factor of a\n1 compared to the distribution of X. One could visualize this by\nthinking about a lump of dough containing a number of raisins - the more we spread out the dough, the\nsparser the distribution of the raisins in the dough will be with respect to the surface of the table.\nFor differentiable monotone transformations u( ) of X we have the following result\n·\nProposition 1 Let X be a continuous random variable with known density fX (x) such that P (a ≤X ≤\nb) = 1, and Y = u(X). If u( ) is strictly increasing and differentiable on an interval [a, b], and has an\n·\ninverse s(y) = u-1(y), then the density of Y is given by\nfX (s(y)) d s(y)\nif\nu(b)\ndy\nu(a) ≤y ≤\nfY (y) =\notherwise\nNotice that an analogous result is true if u(x) is strictly decreasing on [a, b].\nExample 6 Let X be uniform on [0, 1], so it has p.d.f.\nif 0 ≤x ≤1\nfX (x) =\notherwise\nImage by MIT OpenCourseWare.\n\nGra\nphs\nof\ni\nnverse cumul\native distri\nbu\ntio n f\nunctio\nns.\n\nWhat is the p.d.f. of Y = X2? We can see that on the support of X, u(x) = x2 is strictly increasing and\ndifferentiable, so that we can use the inverse of u( ), s(y) = √y to obtain the p.d.f. of Y ,\n·\nd\n\nif 0 ≤√y ≤1\nfY (y) = fX (s(y)) dy s(y) = fX (√y)2√y =\n2√y\notherwise\nThis is similar to one example we did above, except that in the previous case, the support of X was [-1, 1],\nso that u(x) = x 2 was not monotone on the support of X.\nIt is very important to note that this formula works only for differentiable one-to-one - i.e. monotone\n- transformations. In other cases, we have to stick to the more cumbersome \"2-step\" methods for the\ndiscrete and continuous case, respectively.\n1.4\nProbability Integral / Quantile Transformation\nFor continuous random variables, there is an interesting - and also very useful - result: the \"c.d.f. of a\nc.d.f.\" is that of a uniform variable in the following sense:\nProposition 2 Let X be a continuous random variable with c.d.f. FX (x). Then the c.d.f. evaluated at\na random draw of X, FX (X) is uniformly distributed, i.e.\nFX (X) ∼U[0, 1]\nYou should notice that a function of a random variable is itself a random variable (we'll discuss this in\nmore detail later on).\nProof: Since the c.d.f. takes values only between zero and 1, we can already see that the c.d.f. G( ) of\n·\nF (X) satisfies\nG(F (X)) = P (F (X) ≤x)\n=\nif x < 0\nG(F (X)) = P (F (X) ≤x)\n=\nif x > 1\nWithout loss of generality (i.e. only avoiding a few uninteresting extra definitions or case distinctions),\nsuppose F ( ) is strictly monotonic - keeping in mind that all c.d.f.s are nondecreasing. This means that\n·\nthere is an inverse function F -1( ), i.e. a function such that F -1(F (x)) = x.\n·\nImage by MIT OpenCourseWare.\n\nThe inverse function will also be strictly monotonic, so that for 0 ≤x ≤1, the c.d.f. of the random\nvariable FX (X) is given by\nP\nFX (X) ≤x\n= P\nF -1(FX (X)) ≤F -1(x)\n= P\nX ≤F -1(x)\n= FX (F -1(x)) = x\nX\nX\nX\nX\n(the first equality uses monotonicity of F -1( ), and the third the definition of a c.d.f.).\n·\nSummarizing, the c.d.f. G( ) of the random variable F (X) is given by\n·\n⎧\n⎨ 0\nif x < 0\nG(F (x)) =\nx\nif 0 ≤x < 1\n⎩ 1\nif x ≥1\nWe can easily check that this is also the c.d.f. of a uniform random variable on the interval [0, 1], so that\nF (X) has the same probability distribution as U[0, 1]\nWhat is this result useful for? As an example, there are very efficient ways of generating uniform\nrandom numbers with a computer. If you want to get a sample of n draws from a random variable with\nc.d.f. FX ( ), you can\n·\n- draw U1, . . . , Un ∼U[0, 1]\n- transform each uniform draw according to\nXi = F -1(Ui)\nX\nBy the argument we made before, X1, , Xn behave like a random variable with c.d.f. FX ( ). This method\n·\n·\nis known as integral (or quantile) transformation.\nExample 7 Say, we have a computer program which allows us to draw a random variable U from a\nuniform distribution, but we actually want to obtain a random draw of X with p.d.f.\n1 e- 1\n2 x\nif x ≥0\notherwise\nfX (x) =\nWe can obtain the c.d.f. of X by integration:\nif x < 0\nFX (x) =\n1 -e- 1\n2 x\nif x ≥0\nso that the inverse of the c.d.f. is given by\nF -1(u) = -2 log(1 -u)\nfor u ∈[0, 1]\nX\nIf we try this using some statistics software or Excel, a histogram of the draws will look like this:\n\n.5\n1.5\nDensity\n.2\n.4\n.6\n.8\nUniform Draws\n.1\n.2\n.3\n.4\n.5\nDensity\nExponential Draws\nFigure 1: Histogram of 5,000 draws Ui from a Uniform (left), and the transformation Xi = -2 log(1-Ui)\n(right)\nIf you want to try a few examples on your own in Excel, you can create uniform random draws using the\nRAND() function. You can then plot histograms by clicking yourself through the menus (\"Tools\">\"Data\nAnalysis\">\"Analysis Tools\">\"Histogram\")."
    },
    {
      "category": "Lecture Notes",
      "title": "Appendix to Lecture Notes 10",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/93c9ca6053e598e97baf12194eb1afd4_MIT14_30s09_lec10ex.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n14.30 Introduction to Statistical Methods in Economics\nSpring 2009\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nq\np\nq\np\n\n14.30 Introduction to Statistical Methods in Economics\nAppendix to Lecture Notes 10\nKonrad Menzel\nMarch 12, 2009\nExample of Transformation Formula of Integration Limits\n4xy\nif 0 < x, y < 1\nfxy =\notherwise\nWhat is the p.d.f. of Z = X/Y ?\n1.1\nApproach 1: '2-step' method, too complicated\n- find (x, y) such that x/y ≤2.\n- integrate fxy(x, y) over those (x, y)'s to obtain c.d.f. Fz (z)\n- differentiate Fz (z) to obtain p.d.f. fz (z)\n-→We won't do this, we have an easier approach.\n1.2\nApproach 2: change-of-variable formula\n- problem: z = u1(x, y) = x/y one-dimensional, u(·) can't be one-to-one.\nw\nu1(x, y)\n- fix: introduce additional variable w = u2(x, y) = XY -→can invert\nz\n=\nu2(x, y)\nS1(w, z) = √wz =\nxy\nx =\n√\nx2 = X\n· y\nS2(w, z) =\nw =\nxy =\ny2 = Y\n(Note that x,y are positive with probability 1.)\nz\nx/y\nX\nS1(w, z)\n√\nWZ\ninverse function is\n=\n=\np\n.\n⇒\nY\nS2(w, z)\nW/Z\n⎡\n⎤\n\nZ\nW\n∂S1\n∂S1\n√\nW Z\n√\nW Z\nJacobian is J =\n∂W\n∂Z\n= ⎣\n1/Z\nW/Z2\n⎦ .\n∂S2\n∂S2\n⇒\n∂W\n∂Z\n2√\nW/Z\n-\n2√\nW/Z\nZW/Z2\nW/Z\n⇒ det(J) = -\n4W\n-\n4W = -2Z .\n\n|\n\n|\n\np\n\n- Use formula to get joint p.d.f. of (W, Z).\nfwz (w, z)\n=\nfxy(s1(w, z), s2(w, z)) det(J)\n=\n4s1(w, z)s2(w, z) · -2\nz\nif 0 < s1(w, z), s2(w, z) < 1\notherwise\n⎧\n⎨\nW < Z\n4W = 2 W\nif w, z > 0 and both (*)\n=\n2Z\nZ\nW < 1/Z\n⎩ 0\notherwise\nCondition (*) comes from\n1 > s1(w, z) = √wz\nw < 1/z\n⇒\nand\n1 > s2 =\nw/z\nw < z\n⇒\nRinf\n- How do we obtain fz(z) =\nfwz (w, z)dw?\n-inf\n- fwz (w, z) zero for W ≤0.\n- Fwz (w, z) zero for W > min(Z, 1/Z)\n- therefore,\nmax(0,min(z,1/z))\nZ\n\nmax(0,min(z,1/z))\nW\nW 2\nfz (z)\n=\ndw =\nZ\nZ\n⎧\n⎨ z\nif 0 < z < 1/z\nz < 1\n=\n1/z3\nif 0 < 1/z < z\n⇔\n0 ≤\nz\n⎩\n⇔\n1 ≤\nif z < 0"
    }
  ]
}