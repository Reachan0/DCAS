{
  "course_name": "Signal Processing: Continuous and Discrete",
  "course_description": "This course provides a solid theoretical foundation for the analysis and processing of experimental data, and real-time experimental control methods. Topics covered include spectral analysis, filter design, system identification, and simulation in continuous and discrete-time domains. The emphasis is on practical problems with laboratory exercises.",
  "topics": [
    "Engineering",
    "Electrical Engineering",
    "Digital Systems",
    "Signal Processing",
    "Mechanical Engineering",
    "Dynamics and Control",
    "Mathematics",
    "Computation",
    "Engineering",
    "Electrical Engineering",
    "Digital Systems",
    "Signal Processing",
    "Mechanical Engineering",
    "Dynamics and Control",
    "Mathematics",
    "Computation"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nTextbooks\n\nProakis, John G., and Dmitris K. Manolakis.\nDigital Signal Processing\n. 4th ed. Upper Saddle River, NJ: Prentice Hall, 2006. ISBN: 9780131873742.\n\nOppenheim, Alan V., Ronald W. Schafer, and John R. Buck.\nDiscrete-Time Signal Processing\n. 2nd ed. Upper Saddle River, NJ: Prentice Hall, 1999. ISBN: 9780137549207.\n\nThese are recommended highly, but not mandatory. A list of other references is available in the\nreadings\n.\n\nCredit and Content\n\n12 units, Graduate H level.\n\nPrerequisites\n\nThere is no stated prerequisite course for 2.161. Students entering this course are expected to have an undergraduate understanding of system dynamics and elementary linear system theory, such as provided by this department's 2.003, 2.004, and 2.14 undergraduate sequence. There is no expectation of familiarity with discrete time signal processing.\n\nMATLAB will be used extensively throughout the course. Students will be expected to be able to create \".m\" files.\n\nGrading\n\nThere will be three quizzes in the class. In addition there will be regular homework and project assignments. (Projects will involve the manipulation of real experimental data.) Grades will be allocated on a score consisting of:\n\nACTIVITIES\n\nPERCENTAGES\n\nQuizzes and projects\n\n80%\n\nHomework\n\n20%\n\nCourse Ethics: Guidelines for Independent Effort\n\nStudents may collaborate on the formulation of solutions to problem sets, but each student must turn in a solution that is obviously his/her own work.\n\nPlagiarism\n, or the copying of material from others, including paraphrasing materials from the reports of others without acknowledgment, is contrary to the standards of the Institute and will be considered\na\n\nserious academic offense\n.\n\nPossible sanctions against students suspected of plagiarism may include a grade of 0 for the report, a grade of F for the course, departmental probation, and/or appearance before the institute Committee on Discipline (COD).\n\nTopics to be Covered (not necessarily in this order)\n\n1) Review of Linear Continuous-Time Signal Processing\n\nFourier methods, Laplace transform, convolution, frequency/time domain processing. Passive and active continuous filters. Linear filter implementation using op-amps.\n\n2) Introduction to Real-Time Computation\n\nData converters (A/D, D/A), machine architecture, software considerations.\n\n3) Sampling and Reconstruction\n\nSampling theorem, aliasing, quantization, sampled data systems, cardinal (Whitaker) reconstruction, zero-, first-, second-order hold reconstructors, interpolators, non-resetting reconstructors, matched filtering. Interpolation and decimation.\n\n4) Discrete-Time Signal Processing\n\nThe z transform, difference equations, relationship between F(z) and F*(jw), mappings between s-domain and z-domain, inverse z transform. Discrete-time stability.\n\n5) Discrete Spectral Analysis\n\nThe DFT and its relationship to the continuous FT, the FFT and implementations (decimation in time and frequency), radix-2 implementation, leakage, windowing. Uses of the DFT: convolution -- (overlap and add, select savings), correlation. Random processes, power spectral density (PSD) estimation -- methods of smoothing the periodogram (Welch's method, windowing the correlation function, etc). ARMA methods.\n\n6) Real-Time Simulation Methods Using Difference Equations\n\nImpulse-, step-, ramp-invariant simulations. Tustin's method, matched poles/zeros, bilinear transform methods. Error analysis.\n\n7) Filter Design -- Continuous and Discrete\n\nButterworth, elliptic, Chebyshev low-pass filters. Low-pass design methods based on continuous prototypes. Realizations. Conversion to high-pass, band-pass, band-stop filters. Discrete-time filters: IIR and FIR. Linear phase filters. Frequency sampling filters.\n\n8) Statistical Signal Processing\n\nLinear prediction, adaptive filters (LMS), recursive least-squares.\n\n9) Introduction to Discrete-Time Feedback",
  "files": [
    {
      "category": "Assignment",
      "title": "Problem Set 1 Solution: Convolution and Fourier Transforms",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/af94d2a03a7866a7b8aed432219fff98_ps1soln.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nProblem Set 1 Solution: Convolution and Fourier Transforms\nProblem 1:\nUse the convolution definition\n!\n\"\n\"\n#\n#\n=\n$\n=\n%\n%\n%\nd\nt\nh\nf\nh\nf\nt\ny\n)\n(\n)\n(\n)\n(\n(a)\n)\n.0\n(\n)\n(\n)\n5.1\n(\n)\n(\n!\n+\n+\n+\n=\nt\nt\nt\nt\nf\n\"\n\"\n\"\n!\n\"\n#\n$\n$\n%\n%\n=\notherwise\nt\nt\nt\nh\n,0\n|,\n|\n)\n(\n(\n)\n,\n)\n(\n)\n.0\n(\n)\n(\n)\n(\n)\n(\n)\n5.1\n(\n)\n(\n)\n.0\n(\n)\n(\n)\n5.1\n(\n)\n(\n!\n!\n!\n!\n\"\n\"\n#\n\"\n\"\n#\n\"\n\"\n#\n\"\n\"\n#\n#\n#\n+\n#\n+\n#\n+\n=\n#\n#\n+\n+\n+\n=\n$\n$\n$\n%\n$\n$\n$\n%\n$\n$\n$\n%\n$\n$\n$\n%\n$\n%\n$\n%\nd\nt\nh\nd\nt\nh\nd\nt\nh\nd\nt\nh\nt\ny\nand using the sifting property of the impulse function,\n)\n.0\n(\n)\n(\n)\n5.1\n(\n)\n(\n!\n+\n+\n+\n=\nt\nh\nt\nh\nt\nh\nt\ny\n-3\n-2.5\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n2.5\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n(b) h(t) is the as same used in part (a)\n!\n\"\n#\n$\n$\n%\n=\notherwise\nt\nt\nf\n,0\n.0\n5.1\n,1\n)\n(\n,\n\n-4\n-3\n-2\n-1\n0.5\n)\n.1\n(\n))\n(\n1(\n)\n5.2\n(\n))\n(\n1(\n.0\n.0\n5.1\n5.1\n!\n=\n+\n!\n=\n!\n+\n+\n=\n!\n+\n=\n!\n!\n!\n!\n+\n!\n+\n!\n\"\n\"\nt\nt\nd\nt\nt\nt\nd\nt\nt\nt\nt\nt\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n)\n.0\n(\n5.0\n5.0\n))\n(\n1(\n)\n5.0\n(\n5.0\n5.0\n))\n(\n1(\n.0\n.0\n5.1\n5.1\n+\n!\n=\n+\n+\n+\n=\n+\n!\n!\n+\n!\n=\n+\n+\n!\n=\n+\n!\n+\n\"\n\"\n!\n!\nt\nt\nd\nt\nt\nt\nd\nt\nt\nt\nt\nt\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n-2\n-1\n0.5\nthen\n!\n!\n\"\n#\n#\n\"\n\"\n=\n\"\n=\n$\n=\n.0\n5.1\n)\n(\n)\n(\n)\n(\n)\n(\n%\n%\n%\n%\n%\nd\nt\nh\nd\nt\nh\nf\nh\nf\nt\ny\nFour basic cases can be observed while varying t (sliding the triangle waveform).,\nCase\nRange\nEquation\nPicture\nTriangle\noutside\nt≤-2.5\n1.75≤t\nLess\nthan\nhalf\ntriangle\ninside\n-2.5≤t≤ -1.5\n0.75≤t≤1.75\n-4\n-3\n-2\n-1\n0.5\nMore\nthan\nhalf\ntriangle\ninside\n-1.5≤t≤ -0.5\n-0.25≤t≤0.75\n-3\n-2\n-1\n0.5\nWhole\ntriangle\ninside\n-0.5≤t≤\n0.25\nThe result of the convolution, y(t), is plotted in the following figure\n-3\n-2.5\n-2\n-1.5\n-1\n-0.5\n0.5\n1.5\n0.25\n0.5\n0.75\n\n(c)\n!\"\n!#\n$\n%\n=\notherwise\nT\nt\nt\nf\n,0\n|\n|,1\n)\n(\nthen,\n!\n!\n!\n!\n\"\n!\n!\n!\n!\n#\n$\n%\n%\n&\n=\n%\n%\n&\n+\n=\n=\n&\n=\n&\n=\n'\n=\n(\n(\n(\n(\n&\n+\n&\n&\n)\n)\n&\notherwise\nT\nt\nT\nt\nd\nt\nT\nT\nt\nd\nd\nt\nf\nd\nt\nf\nf\nf\nf\nt\ny\nT\nT\nt\nT\nt\nT\nT\nT\n,0\n,\n,\n)\n(\n)\n(\n)\n(\n)\n(\n/\n*\n*\n*\n*\n*\n*\n*\n\n-T\n\nT\n\nT\n/\n)\n/\nsin(\n)\n(\n)\n(\n/\n/\n/\n/\n/\n!\n!\n!\n!\n!\n!\n!\n!\n!\n!\nT\nj\ne\ne\nj\ne\ndt\ne\ndt\ne\nt\nf\nj\nF\nT\nj\nT\nj\nT\nT\nt\nj\nT\nT\nt\nj\nt\nj\n=\n\"\n\"\n=\n#$\n%\n\"\n=\n=\n=\n\"\n\"\n\"\n\"\n\"\n&\n&\n\"\n\"\n'\n'\nwhen T=1,\n)\n(\n)\n(\n)\n(\nt\nf\nt\nf\nt\nh\n!\n=\nand from the convolution theorem\n)\nsin(\n/\n)\n/\nsin(\n)\n(\n)\n(\n)\n(\n!\n\"\n#\n$\n%\n&\n=\n!\n\"\n#\n$\n%\n&\n=\n=\nx\nx\nj\nF\nj\nF\nj\nH\n'\n'\n'\n'\n'\n\nProblem 2\n)\n(\n,\n)\n(\nbx\nax\ne\nx\nf\ne\nx\nf\n!\n!\n=\n=\n!\n!\n\"\n\"\n#\n#\n#\n#\n\"\n\"\n#\n=\n#\n=\n$\n=\n%\n%\n%\n%\n%\n%\nd\ne\ne\nd\nx\nf\nf\nf\nf\nx\ny\nx\nb\na\n)\n(\n)\n(\n)\n(\n)\n(\n!\n!\n!\n\"\n\"\n#\n$$\n%\n&\n''\n(\n)\n+\n#\n+\n#\n+\n#\n\"\n\"\n#\n+\n#\n$\n%\n&\n'\n(\n)\n+\n#\n+\n#\n\"\n\"\n#\n$$\n%\n&\n''\n(\n)\n+\n+\n+\n#\n+\n#\n=\n=\n=\n*\n*\n*\n*\n*\n*\n*\nd\ne\ne\nd\ne\nd\ne\nb\na\nbx\nb\na\nb\na\nabx\nb\na\nabx\nb\na\nbx\nb\na\nb\na\nbx\nb\na\nbx\nb\na\n)\n(\n)\n(\nusing the variable substitution:\nb\na\nd\nd\nb\na\nbx\nb\na\n+\n=\n+\n!\n+\n=\n\"\n#\n#\n\"\n,\n,\n)\n(\nx\ne\nb\na\nb\na\nd\ne\nx\ne\nt\ny\nb\na\nab\nb\na\nab\n+\n!\n\"\n\"\n!\n!\n+\n!\n+\n=\n+\n=\n#\n$\n%\n&\n&\nwhich is a Gaussian function.\nProblem 3\n)\n5.0\n(\n)\n(\n)\n5.0\n(\n)\n(\n!\n+\n+\n+\n=\nt\nt\nt\nt\nf\n\"\n\"\n\"\n)\ncos(\n)\n(\n)\n5.0\n(\n)\n(\n)\n5.0\n(\n)\n(\n)\n(\n!\n!\n!\n\"\n!\n\"\n!\n\"\n!\n!\n!\n+\n=\n+\n+\n=\n#\n+\n+\n+\n=\n=\n#\n$\n$\n#\n#\n$\n$\n#\n#\n$\n$\n#\n#\n$\n$\n#\n#\n%\n%\n%\n%\nj\nj\ne\ne\nj\nF\ndt\nt\nj\ne\nt\ndt\nt\nj\ne\nt\ndt\nt\nj\ne\nt\ndt\nt\nj\ne\nt\nf\njw\nF\n-10\n-8\n-6\n-4\n-2\n-1\n\nProblem 4\nThese solutions are all based on the elementary properties of the Fourier transform (see the class\nhandout).\n(a)\nW\nX\nW\nX\nW\nX\nd\nj\nX\nd\ne\nj\nX\nx\nt\nt\nj\n.\n2.\n)\n(\n|\n)\n(\n)\n(\n!\n!\n\"\n\"\n!\n\"\n\"\n!\n\"\n=\n#$\n%\n&'\n(\n+\n=\n=\n=\n)\n)\n*\n*\n+\n=\n*\n*\n+\n(b) Using the symmetry properties, we note that\n)\n( !\nj\nX\nis real, therefore\n,)\n(\n)\n(\nt\nx\nt\nx\n=\n!\nthat is\nthey are complex conjugates.\n(c) This one is a little tricky! We use the property that\n|)\n(\n)\n(\n=\n!\n!\n\"\n=\n#\n$\n$\nj\nX\ndt\nt\nx\nBUT note that there is a singularity at\n=\n!\n. The question is: what is the value of\n)\n( j\nX\n?\nThe problem statement specifies that\n)\n(\nX\nj\nX\n=\n!\nfor\n!\n\"\n<W, so you can argue that\n.\n)\n(\nX\ndt\nt\nx\n=\n!\n\"\n\"\n#\nOn the other hand if you approximate the step discontinuity with a smooth function (say erf())\n.0\n)\n(\nX\nj\nX\n=\naround\n=\n!\n, you can argue that the value of\n, or\n.\n.0\n)\n(\nX\ndt\nt\nx\n=\n!\n\"\n\"\n#\nSo the answer is dependent on your assumption about the discontinuity!\n(d) From Parseval's theorem\nW\nX\nW\nX\nW\nX\nd\nj\nX\ndt\nt\nx\n)\n.\n2.\n(\n|)\n(\n|\n|)\n(\n|\n!\n!\n\"\n\"\n!\n=\n+\n=\n=\n#\n#\n$\n$\n%\n$\n$\n%\n.\nProblem 5\n!\n\"\n#\n<\n=\notherwise\nj\nH\nc\n,0\n|\n|,1\n)\n(\n$\n$\n$\nIf and impulse is passed through the filter, we obtain the impulse response\n{\n}\n!\nj\nH\nF\nt\nh\n(\n)\n(\n\"\n=\n)\n(\nsinc\nsin\n)\n(\n)\n(\n)\n(\nct\nt\nt\ne\ne\njt\nd\ne\nd\ne\nj\nH\nt\nh\nc\nc\nc\nc\nt\nj\nt\nj\nt\nj\nt\nj\nc\nc\nc\nc\n!\n\"\n!\n!\n!\n\"\n!\n\"\n!\n\"\n!\n!\n\"\n!\n!\n!\n!\n!\n!\n=\n=\n#\n=\n=\n=\n#\n#\n$\n$\n#\n%\n%\n\nw/pi\nThe filter is acausal.\nProblem 6\nt\ne\nt\nh\n)\n(\n!\n=\nLet's compute the Fourier transform of h(t)\n)\n(\n+\n=\n= !\n\"\n#\n#\n$\n$\n$\nj\ndt\ne\ne\nj\nH\nt\nj\nt\nNote: lower limit in integral is 0 because a real filter is a causal system.\na) The transfer function can be found by taking the Laplace transform, which can be viewed as\na Fourier transform where jω is replaced by s=σ+jω .\n)\n(\n+\n= s\ns\nH\nb) The frequency response is given by H(jω) computed previously.\nc) We find the cut-off frequency by solving:\ns\nrad\nj\nH\nj\nH\nj\nH\nj\nH\nc\nc\nc\nc\nc\n/\n)\n(\n)\n(\n|\n|)\n(\n|\n|)\n(\n|\n=\n!\n=\n\"\n=\n!\n=\n+\n!\n=\n!\n=\n#\n#\n#\n#\n#"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 1: Convolution and Fourier Transforms",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/0308f5dcf805cc5e599e9957a3057999_ps1.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nh(t)\nt\n1.0\n1.0\n-1.0\n0.75\n-1.5\nf(t)\nt\n(a) Impulsive waveform\n(b) Impulse response\nh(t)\nt\n1.0\n1.0\n-1.0\n0.75\n-1.5\nf(t)\nt\n(a) Rectangular input function\n(b) Impulse response\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nProblem Set 1: Convolution and Fourier Transforms\nAssigned: Sept. 9, 2008\nDue: Sept. 18, 2008\nProblem 1:\n(a) Plot the result of convolving a one-dimensional function consisting of three impulses\nwith a triangular function as shown below:\n(b) Plot the result of convolving a one-dimensional function consisting of a rectangular\nfunction with the same triangular function used in part(a), as shown below:\n(c) Plot the result of convolving a pair of identical even \"top-hat\" (pulse) functions: f(t) = 1\nfor t < T/2 and f(t) = 0 otherwise. Use your result show that the Fourier transform\n| |\nof a triangular pulse (such as used in parts (a) and (b)) is of the form (sin(x)/x) .\nProblem 2: Show that when two gaussian functions\nf1(x)\n= e-ax\nf2(x)\n= e-bx2\nare convolved, the result is another gaussian function.\nHint: Complete the square in the exponent, change the variable of integration, and recognize\nthat\nZ inf\ne-x dx = √π\n-inf\n\n0.5\n-0.5\nf(t)\nt\nProblem 3: Find the Fourier Transform of three equally spaced impulses as shown below:\nPlot the result (real and imaginary parts).\nProblem 4: (The following is taken from the Signal Processing PhD Quals written exam\nfor January 2007. Note: this is not the complete exam.)\nAssume we have a signal x(t) with a Fourier transform X(jΩ) given by\nX(jΩ) =\n⎧\n⎪\n⎨\n⎪\n⎩\nΩ < -2W\nX0/2 -2W ≤ Ω < 0\n0 ≤ Ω < W\nX0\nΩ ≥ W\nwhere X0 is some real valued number, W is a real valued positive number, and Ω is specified\nin units of radians/second.\n(a) What is the value of x(t) at t = 0?\n(b) For an arbitrary t, what is the relationship between x(t) and x(-t)?\n(c) What is the value of\nR infx(t)dt?\n-inf\n(d) What is the value of\nR inf\nx(t)\ndt?\n-inf |\n|\nProblem 5:\nAn impulse δ(t) is passed through an ideal low-pass filter with frequency\nresponse H(jΩ) = 1 for Ω < Ωc and H(jΩ) = 0 otherwise. Find and sketch y(t), the\n| |\noutput of the filter. Is this a causal filter?\nProblem 6:\nAfter measurement and curve-fitting it is determined that a causal signal\nprocessing filter has an impulse response h(t) = 5e-3t for t > 0.. What is the filter's\n(a) transfer function, and (b) its frequency response function? Determine the -6 dB cut\noff frequency, that is the frequency at which the output amplitude is one half of the low\nfrequency response."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/aa32f9d7924e3e6715126ec1e5cc14f9_ps2.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nW ( r a d / s )\nF ( j W )\n1 0 0\n- 1 0 0\n5 0 0\n- 5 0 0\nW ( r a d / s )\nH ( j W )\n2 0 0\n- 2 0 0\n4 0 0\n- 4 0 0\nW ( r a d / s )\nH ( j W )\nW\n- W\nc\nc\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nProblem Set 2\nAssigned: Sept. 18, 2008\nDue: Sept. 25, 2008\nProblem 1: A waveform f(t) with a real even spectrum F (jΩ)\nis filtered by an ideal band-pass filter with a purely real frequency response H(jΩ)\nDetermine the filter response y(t). Is this a causal filter?\nProblem 2: Find the impulse response of an ideal high-pass filter, with cut-off frequency\nΩc:\n\n( a ) N = 1 5\n( b ) N = 3 1\n( c ) N = 6 3\nHints: Feel free to do this any way you wish, but you may find it useful to consider H(jΩ)\nas a superposition of functions with known FT relationships. In particular, the solution of\nProb. 5 in PS 1 might be useful and/or the following bits and pieces from the Frequency\nDomain class handout: the Fourier transform of a unit step function (p. 32), the duality\nproperty, the time shift property, time reversal property, linearity property, all might help\nyou.\nProblem 3: Use the Fourier transform of a sinusoid (p. 34 of the class handout) to express\nthe Fourier series representation of a periodic waveform\ninf\nx(t) =\nX\nAn sin (nΩ0t + φn)\nn=0\nas a Fourier transform.\nProblem 4: Gibb's phenomenon is associated with the synthesis of periodic waveforms with\nsharp (jump) discontinuities using a truncated Fourier series. Consider a periodic waveform\nxp(t) and its Fourier series\ninf\njnΩ0t\nxp(t)\n=\nX\nXne\nn=-inf\n1 Z T/2\nXn =\nxp(t)e-jnΩ0tdt\nT\n-T/2\nand let\nN\njnΩ0t\nxÞp,N (t) =\nX\nXne\nn=-N\nbe an approximation generated by truncating the series. It was observed in the late 1800's\nthat a finite series approximation created a ripple in the synthesized waveform in the region\nof a jump discontinuity in xp(t), and that although the width of the ripple decreased as more\nterms were included, the amplitude remained constant. The phenomenon was found to be\npresent for any finite N. The figure below shows the synthesis of a square wave xÞp,N (t) with\nN = 15, 31, and 63.\nGibb's phenomenon was the subject of much discussion in the mathematical literature around\n1900, and in fact was cited as a reason why Fourier analysis/synthesis did not work! The\ngreat mathematicians of the time did not understand what was going on. You, however, do\nunderstand it and your task is to explain the phenomenon.\n\ns - p l a n e\ns\nj W\no\nx\n- 3\n(a) Explain the truncation of the series in the frequency domain as an ideal multiplicative\nfiltering operation, and define the filter pass-band.\n(b) What is the equivalent time domain operation? OK - you win - it's convolution, but\nthe question is what are the two functions being convolved? Write the appropriate\nconvolution integral.\n(c) Explain (i) why the height of the ripple on the square wave is constant for any finite\nseries, and (ii) why the oscillatory frequency increases as N increases.\nProblem 5:\nAn \"all-pass\" filter has a frequency response magnitude H(jΩ) that is a\n|\n|\nconstant (ie is independent of frequency Ω).\n(a) Show that the first-order system with the pole-zero plot below is an all-pass filter.\n(b) Show that any system with (i) the same number of poles and zeros, (ii) with all poles\nin the left-half s-plane, and (iii) the zeros mirror the poles about the imaginary axis,\nthat is zi = -pi where x denotes the complex conjugate, is an all-pass filter.\n(c) Use MATLAB to plot (i) the frequency response, (ii) the impulse response, and (iii) the\nstep response of the filter with a pole and zero shown in (a) above. Choose an arbitrary\ngain constant.\n(Some useful functions might be zpk(), tf(), freqs(), bode(), impulse(),\nstep().)\n(d) What useful purpose might an all-pass filter serve?"
    },
    {
      "category": "Assignment",
      "title": "Solution of Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/4659e7309ee4f514502c1b99b1d36579_ps2soln.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nSolution of Problem Set 2\nAssigned: Sept. 18, 2008\nDue: Sept. 25, 2008\nProblem 1:\nY (jΩ) = H(jΩ)F(jΩ) and it is shown in the below figure\nY ( jw)\n1 Zinf\ny(t) =\nY (jΩ)ejΩtdt\n2π\n-inf\n10 Z400\n-Z200\n=\n(\nejΩtdt +\nejΩtdt)\n2π\n-400\n=\n(e 400jt -e 200jt -e -400jt + e -200jt)\n2πjt\n=\n(sin(400t) -sin(200t))\nπt\nIt is not a casual filter (since y(t) =\n\n0 for some t < 0).\nh(t)/5 and h(t) =\nProblem 2:\nWe define H∗(jΩ) = 1 - H(jΩ). Then H∗(jΩ) is a low pas filter, matching Prob. 5 in\nPS 1, which we have already found it's impulse response:\nH(jΩ) = 1 -H∗(jΩ)\nF -1 (H(jΩ)) = F -1 (1) -F -1 (H∗(jΩ))\nh(t) = δ(t) -h∗(t)\nh(t) = δ(t) - sin(Ωct)\nπt\n\nX\nX\nb\nb\nZ\n!\n!\nb\nZ\nZ\nb\nProblem 3:\ninf\ninf\nx(t) =\nAn sin(nΩ0t + φn) =\nAn (sin(nΩ0t) cos φn + cos(nΩ0t) sin φn)\nn=0\nn=0\ninf\nX(jΩ) = P An( F(sin(nΩ0t)) cos φn + F(cos(nΩ0t)) sin φn)\nn=0\ninf\nX(jΩ) = P An (cos φn (-jπ (δ(Ω -nΩ0) -δ(Ω + nΩ0))) + sin φn (π (δ(Ω -nΩ0) + δ(Ω + nΩ0))))\nn=0\ninf\nX(jΩ) = -jπ P An ((cos φn + j sin φn) (δ(Ω -nΩ0) + (-cos φn + j sin φn) (δ(Ω + nΩ0))\nn=0\ninf\nX(jΩ) = -jπ P An\nejφn δ(Ω -nΩ0) -e-jφn δ(Ω + nΩ0)\n\nn=0\nProblem 4:\n(a) The ideal multiplicative filtering operation is a low pass filtering with the pass-band\nΩc = NΩ0:\n\n1 |n| ≤N,\n|Ω| ≤Ωc\nHn =\n0 |n| > N,\n|Ω| > Ωc\nXbn = XnHn\n(b) It's a convolution in this specific form:\n1 Z T\nx(t) = x(t) ⊗h(t) =\nx(τ)h(t -τ)dτ\nT\n- T\nWe can prove that why convolution is in this specific integral form for our Periodic\nExponential Fourier Transform:\n\nT\ninf\ninf\nX XnHnejnΩ0t\n=\nX\n-jnΩ0τdτ\nejnΩ0t\nx(t) =\nXn\nh(τ)e\nT\n- T\nn=-inf\nn=-inf\ninf\n\nX\njnΩ0t\n!\ninf\n\nX\njnΩ0(t-τ)\n!\nT\nT\nXne\nXne\n-jnΩ0τ\nx(t) =\nh(τ)\ndτ =\nh(τ)\ndτ\ne\nT\nT\nT\nT\n-\n-\nn=-inf\nn=-inf\n1 Z T\nx(t) =\nh(τ)x(t -τ)dτ\nT\n- T\nWe can also find the specific form of our filter:\ninf\nN\nN\nN\nX\njnΩ0t\nX\njnΩ0t\nX\nX\nh(t) =\nHne\n=\ne\n= 1 + 2\ncos (nΩ0t) = -1 + 2\ncos (nΩ0t)\nn=-inf\nn=-N\nn=1\nn=0\n\nHere we use below trigonometric relation to simplify our summation, where φ = 0 and\nα = Ω0t:\n\n(n+1)α\nnα\nsin\n· cos (φ +\n2 )\ncos φ + cos (φ + α) + cos (φ + 2α) + · · · + cos (φ + nα) =\nsin α\n\n(N+1)Ω0t\nN\nsin\n· cos ( NΩ\n0t)\nh(t) = -1 + 2\nX\ncos (nΩ0t) = -1 + 2\nsin Ω0t\nn=0\nThen we use below trigonometric relation to simplify our impulse response:\n2 sin θ cos φ = sin(θ + φ) + sin(θ -φ)\n\n(N+1)Ω0 t\nsin\n· cos ( NΩ\n0t)\nsin\n(N + 1)Ω0t\n\n+ sin ( Ω0t)\nh(t) = -1 + 2\n= -1 +\nsin Ω0t\nsin Ω0t\nsin\n(N + 2\n1)Ω0t\n\nh(t) =\nsin Ω0t\nHere we further analyze this h(t) function, so we can use its properties for the next\npart of the problem:\nNote that for small t values, h(t) can be approximated to:\nsin\n(N + 2\n1)Ω0t\n\nt → 0 ⇒ h(t) →\nΩ0t\nsin (NΩ0t)\nThe value of h(t) |t→0, for large N values, is very close to h∗ =\nπt\nwhich can be\nobtained for a Continuous Fourier Transform of a Low Pass Filter with Ωc = NΩ0.\nHence, in the vicinity of t = 0, h(t) acts like a sinc function (with the maximum value\nof 2N + 1), but as soon as it gets close to its boundaries (|t| ≤ T\n2 ⇒|Ω0t| ≤ π), it\noscillates quickly with Ω = (N + 0.5)Ω0 around -1 and +1.\nNote that for the Continuous Fourier Transform, we expect a h∗(t); where it is to\nbe evaluated between -inf to +inf and contained with an envelope in the form of 1\nt .\nOn the other hand, for our case of Periodic Fourier Transform, h(t) it is to be evaluated\nbetween -T to + T and is also periodic.\nNote that for any N value, if x(t) ≡ 1 then xb(t) ≡ 1 which means that following\nrelation holds for any N:\n1 = 1\nT\nZ\nT\n- T h(τ)dτ = 2\nT\nZ\nT\nh(τ)dτ\nFurthermore, for very large N values, the h(t) function become very narrow, and hence\nabove integral can be approximated to the integration around any finite, non-zero\ninterval around t = 0:\nt ∗\nT\n1 Z\n1 Z\nT\n(Eq. 1)\nN →inf ⇒∀t ∗ s.t. 0 < t ∗ ≤\n:\nh(τ)dτ →\nh(τ)dτ\nT\nT\n\nThis properties can be used to prove that xb(t) values converge to x(t) values at any\ncontinuous point and to the mean of right and left limits at any stepwise discontinuous\npoint of x(t). Furthermore, the structure of h(t) shows that the ripple will vanish at\nany point in which x(t) is continuous. Besides, as we will see in the next part, only a\nfinite and determined value of ripple will be allowed to remain and it will be pushed\nto the edge of discontinuities.\n(c) The output signal is a convolution of the original signal with the h(t). Hence, it is very\nclear that ripples are due to deviation of h(t) from ideal case of δ(t). Consequently, as\nsoon as N goes up, h(t) becomes more like a δ(t) function, acts more locally, and the\noutput signal ripples with an increases frequency.\nFor very large N values, the ripple percentage is a fixed amount, although its location\nis dependent on N value. The amount of ripple is fixed, because although different\nh(t) functions have different curves, but always the maximum ripple corresponds to\nthe point where the edge of the central lobe matches with the discontinuity. We will\nprove this rigorously, but in fact since the ratio of the area of the central lobe, to the\nrest of the lobes remains constant, the ripple percentage remains constant as well.\nNote that due to Eq.\n1, only the behavior of function around discontinuity mat\nters (as long as discontinuities have a finite non-zero distance from each other). Hence,\nwithout the loss of generality, we extend discontinuity limits to the the full extent of\nthe function and consider our function in the below form where A value corresponds\nto the discontinuity jump:\nT\n\nA\n0 ≤ t <\nx(t) =\nT\n-\n≤ t < 0\nBelow figure shows this conditions:\nA\n+\n+\n+\n-\n-\n-\n-\nh(t) for N=10, not to the scale\nx(t), to the scale\nt_max\nT/2\n-T/2\nBy moving h(t) on the x(t), we can realize that, at each point, the xb(t) is an average\nof neighborhood points. Particularly, the sign of lobes determine that whether those\n\nb\nZ\nZ\nZ\nZ\nZ\nZ\npoint have a positive or negative contribution. Since, major contribution comes from\nthe central lobes, we can guess that the maximum ripple occurs when the edge of cen\ntral lobe match with t = 0. In that case, the next negative lobe cannot decrease the\nx(t) value and we have a maximum ripple. The next maxima and minima of ripples\nalso correspond to other lobe edges touching t = 0.\nNow we prove this rigorously. For our specific case of x(t), and our even h(t) function,\nwe can simplify the convolution integral:\nA\nA\nT\nT\nT -t\nxb(t) = T\nh(t -τ)x(τ)dτ = T\nh(t -τ)dτ = T\n-t\nh(τ)dτ\nT\n- 2\ndxb(t) = -h( T -t) + h(t)\ndt\nWe are interested in 0 < t <<\nT\nx(t)\n, and hence\ndb\n≈ h(t).\nConsequently, maxi\ndt\nmum/minimum values correspond to (N + 1\n2)Ω0tmax/min = kπ such that 0 < k << N.\nπ\nT\nThe highest maximum corresponds to the\nNow we compute\ntmax =\n=\n.\n(N+ )Ω0\n2(N+ )\nthe xb(tmax) value by breaking the original integral to two parts:\nA\n-tmax\nZ\n1 Z\nT\nT -tmax\nx(tmax) =\nh(τ)dτ = A(\nh(τ)dτ +\nh(τ)dτ)\nb\nT\n-tmax\nT\n-tmax\nT\nNow note that for large N values from Eq. 1 we can conclude that:\n-tmax\nT\nT\nh(τ)dτ) =\nh(τ)dτ) =\nT\nT\nAlso for the other part of integral, τ is very close to zero and we can simplify h(t) with\na sinc form and also change integration variable by θ = (N + 2\n1)Ω0t:\n1 Z\n1 Z\nsin ((N + 2)Ω0τ)\n1 Z\nsin θ 2\n1 Z π sin θ\nT\n-tmax\nh(τ)dτ) = T\n-tmax\nΩ\n0τ\ndτ = T\n-π\nθ\nΩ0\ndθ = π\nθ\ndθ\nA short survey of literature or a Taylor expansion of sin\nθ\nθ ends to:\nπ\n1 Z\nsin θ dθ =\n+ 0.089490...\nπ\nθ\nHence the maximum ripple corresponds to:\nxb(tmax) = A(2 + 2 + 0.089490...) = A(1 + 0.089490...)\nThis corresponds to about 9% overshoot and this overshoot is only dependent on the\nlocal discontinuity jump and independent of N or specific form of x(t). Other proofs,\nfor less general cases, could also be found in the Wikis.\n\n-----\ns\nProblem 5:\n(a)\ns -3\nH(s) = K s + 3\njΩ -3\n|H(jΩ)| = |K|\n\n= |K|\njΩ + 3\n(b) Consider this pole-zero plot:\nX\nX\nX\nO\nO\nO\nj w\ns - p l a n e\nr\nr\nr\nq\nq\nq\nLet the vectors from the poles and zeros to an arbitrary test frequency Ω be ri and qi:\n|q1| |q2| |q3|\n|H(jΩ)| = |K|\n= |K|\n|r1| |r1| |r1|\nsince |qi| = |ri| for all i regardless of the system order. Therefore, this given pole-zero\nconfiguration, as well as all who satisfy problem conditions, are all-pass filters.\n(c) MATLAB Command -line :\n>> H_s=tf([1 -3],[1 3])\nTransfer function:\ns - 3\ns + 3\n>> bode(H_s);\n>> subplot(2,1,1)\n\n>> step(H_s);\n>> subplot(2,1,2)\n>> impulse(H_s);\nBode Diagram\nMagnitude (abs)\nAmplitude\nAmplitude\nPhase (deg)\n0.8\n0.6\n0.4\n0.2\n-1\nFrequency (rad/sec)\nStep Response\n0.5\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nTime (sec)\n-0.5\n-1\nImpulse Response\n-2\n-4\n-6\n-8\n-10\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\nTime (sec)\n(d) These filters are useful for manipulating the phase of the spectral components in a\nsignal, without altering its magnitude."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3 Solution: Analog Filter design",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/545aba7a8ed9f100d972047456b66de0_ps3soln.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nProblem Set 3 Solution: Analog Filter design\nProblem 1: Use the nomenclature in the class handout. For both filters:\n= 0.5 -→ o = 1,\n= 0.1 -→ λ = 3\n1 + o2\n1 + λ2\n(a) For Filter A, Butterworth design:\nlog(λ/o)\nlog(3)\nN ≥\n=\n= 2.71\nlog(Ωr/Ωc)\nlog(1.5)\nTherefore select N = 3.\n(b) For Filter A, Chebyshev design:\ncosh-1(λ/o)\ncosh-1(3)\nN ≥\n=\n= 1.831\ncosh-1(Ωr/Ωc)\ncosh-1(1.5)\nTherefore select N = 2.\n(c) For Filter B, Butterworth design:\nlog(λ/o)\nlog(3)\nN ≥\n=\n= 6.81\nlog(Ωr/Ωc)\nlog(1.175)\nTherefore select N = 7.\n(d) For Filter B, Chebyshev design:\ncosh-1(λ/o)\ncosh-1(3)\nN ≥\n=\n= 3.02\ncosh-1(Ωr/Ωc)\ncosh-1(1.175)\nTherefore select N = 4.\n(e) % Design the filter\n[A,B]=butter(3,2*pi*10000,'s');\nfilt=tf(A,B);\n% Create a frequency vector\nw=[0:2*pi*100:2*pi*30000];\n% Compute the freq resp. at the frequencies in the vector\n[MAG, PHASE] = bode(filt, w);\n% Plot the response\nplot(w/(2*pi), squeeze(MAG).^2);\ngrid;\nxlabel('Frequency (Hz.)');\nylabel('Power Response');\ntitle('PS2 - Problem 1(e)');\n\nPower Response\nPS2 - Problem 1(e)\n0.5\n1.5\n2.5\n0.8\n0.6\n0.4\n0.2\nFrequency (Hz.)\nx 10\n(f) For the standard MATLAB functions we need to design a filter with Ωc = 1 rad/s.\nIn the following script we have done an implicit conversion by specifying Ωr = 1.175\nrad/s. The following script designs the bandpass filter, plots the power response on a\nlinear scale, and makes the Bode plots as requested:\n% Problem Set 2, Prob 1(f)\n% lp2bp() reqires a prototype lp filter with unity wc.\n% Note we specify the rejection band as being 10db down\n[b,a]=cheby2(4,10,1.175,'s');\n% Convert to a band-pass filter with center frequency\n% as the geometric\nmean of the band edges\n[pb,pa]=lp2bp(b,a,2*pi*sqrt(5000*15000),2*pi*10000);\nbpsys=tf(pb,pa);\n% Plot the power response\nw=[0:2*pi*100:2*pi*30000];\n[mag,phase]=bode(bpsys,w);\nplot(w/(2*pi),squeeze(mag).^2);\ntitle('PS2 Prob 1(f): Bandpass Filter Design');\nxlabel('Frequency (Hz)');\nylabel('Power Response');\n%\nfigure\nbode(bpsys)\nNote that since we were given the specs for the prototype lpf, we have no control\nover the stop-band edges. We can however compute them using Table 2 in the class\nhandout:\ns2 + Ω2\ng(s) =\no\nΔΩs\nso that the mapping of frequency Ωr in the prototype to Ωr in the band-pass filter is\ngiven by the absolute value of the roots of\nΩ2 - ΔΩΩrΩ - Ω2 =\no\nor Ω2 -(2π10000) × 1.175Ω - (2π5000) × (2π15000)\n=\nwhich gives frl = 4.590 kHz and fru = 16.340 kHz as indicated on the plot.\n\nPS2 Prob 1(f): Bandpass Filter Design\n0.2\n0.4\n0.6\n0.8\nPower Response\nf=16.340 kHz\nf=4.590 kHz\n0.5\n1.5\n2.5\nFrequency (Hz)\nx 10\nThe Bode plots are shown below:\nBode Diagram\n-100\n-80\n-60\n-40\n-20\nMagnitude (dB)\nPhase (deg)\nFrequency (rad/sec)\n\nProblem 2: We require a high-pass filter.\nΩc =\n2π50 rad/s\nΩr =\n2π20 rad/s\nRc =\n3 rad/s\nRs =\n40 rad/s\nLet's choose a Butterworth prototype, and convert to a high-pass filter as described in Section\n3.1 of the class handout Introduction to Continuous Time Filter Design using the following\nMATLAB script:\nwc = 2*pi* 50;\nwr = 2*pi*20;\nRc = 3;\nRs = 40;\nWr = wc/wr;\n%\n[N, Wn] = buttord(1, Wr,Rc,Rs,'s');\n[num,den]= butter(N, Wn,'s');\n[num_hp, den_hp] = lp2hp(num,den, wc);\nhpfilt=tf(num_hp, den_hp)\n%\nw=[0:2*pi:2*pi*100];\n[mag, phase] = bode(hpfilt,w);\nplot(w/(2*pi),squeeze(mag));\ntitle('PS2 Prob 2: Highpass Filter Design');\nxlabel('Frequency (Hz)');\nylabel('Frequency Response Magnitude');\ngrid;\nwhich produces the frequency response magnitude plot:\n\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nX: 50\nY: 0.9254\nFrequency Response Magnitude\nX: 20\nY: 0.01\nPS2 Prob 2: Highpass Filter Design\nFrequency (Hz)\nwhich meets the specifications.\nProblem 3:\nLet the lpf be a unity gain all-pole filter with transfer function\na0\nHlp(s) = sn + an-1sn-1 + . . . + a1s + a0\nthen the hiph-pass filter formed as\nHhp(s)\n=\n1 -Hlp(s)\na0\n=\n1 - sn + an-1sn-1 + . . . + a1s + a0\ns(sn-1 + an-1sn-2 + . . . + a1)\n=\nsn + an-1sn-1 + . . . + a1s + a0\nWe note that this is a high-pass filter because\n- It has the same number of poles as zeros, indicating unity gain at high frequencies,and\n- It has one or more zeroes at the origin, indicating that the gain goes to zero as the\nfrequency approaches zero.\n(a) In this case there is a single zero at the origin, while with the transformation method\ndescribed in the handout, there will be n zeros at the origin.\n(b) The attenuation rate as Ω → 0 will be much higher in the hpf designed by frequency\ntransformation (20n dB/decade as opposed to 20 db/decade.).\n\n(c) From the graphical s-plane interpretation of the frequency response, each zero at the\norigin contributes π/2 radians of phase shift at very low frequencies. Thus the hpf\ndesigned by frequency transformation will have +nπ/2 rad of phase lead at low fre\nquencies, the filter designed as proposed in this problem will have a phase lead of π/2\nrad.\n(d) As indicated above, any system with the same number of poles as zeros will have unity\ngain at very high frequencies.\nProblem 4: There are, of course, many solutions to this problem! Here's one possibility:\nDesign a band-pass filter, \"centered\" at 60 Hz and with at least 60 dB attenuation at 30 and\n60 Hz. Choose the specs\nΩ0 =\n2π60 rad/s\nΩcu =\n2π65 rad/s\nΩru =\n2π90 rad/s\nΩrl =\n2π30 rad/s\nRc =\n1 dB\nRs =\n60 dB\nLet's choose a Butterworth prototype, and convert to a band-pass filter as described in\nSection 3.1 of the class handout Introduction to Continuous Time Filter Design using the\nfollowing MATLAB script:\n% Design a band-stop filter\n% First define some ctitical frequencies\n% Passband edges\nwo = 2*pi*60;\nwcu = 2*pi*65;\nwcl = wo^2/wcu;\nBW = (wcu-wcl);\n% Stop band edges\nwsu = 2*pi*90;\nwsl = 2*pi*30;\n% Pass-band and stop-band attenuations:\nRc = 1;\nRs = 60;\n% Determine the stop-band edge in the lp prototype\n%\nW1 = (wo^2-wsu^2)/(BW*wsu);\nW2 = (wo^2-wsl^2)/(BW*wsl);\nWr = min(abs(W1),abs(W2));\n%\n% design the prototype low-pass filter\n%\n[N,Wn]\n= buttord(1,Wr, Rc, Rs, 's');\n\n[num,den]\n= butter(N, Wn, 's');\n% Convert to a band-stop filter\n[num_bpass,den_bpass] = lp2bp(num,den,wo,BW);\nfilt = tf(num_bpass,den_bpass);\n%\n% Plot the frequency response magnitude\n%\nf=[0:1:100];\n[mag,phase]=bode(filt,2*pi*f);\nplot(f,(squeeze(mag)));\ngrid\nxlabel('Frequency (Hz)');\nylabel('Response Magnitude');\nwhich produces the frequency response magnitude plot:\n0.2\n0.4\n0.6\n0.8\nX: 30\nY: 5.292e-005\nResponse Magnitude\nX: 55\nY: 0.9286\nX: 65\nY: 0.9671\nX: 90\nY: 0.001\nFrequency (Hz)\nwhich meets the specifications since 1 dB attenuation is a gain of 10-1/20 = 0.8913 and 60\ndb attenuation is a gain of 10-60/20 = 0.001."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3: Analog Filter design",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/15541fb6d833833772ab1091ccf2858f_ps3.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nProblem Set 3: Analog Filter design\nAssigned: Sept. 25, 2008\nDue: Oct. 2, 2008\nProblem 1: Consider the following two filter specifications:\nFilter A\nFilter B\nPassband\n0-10 kHz\n0-10 kHz\nMinimum power gain at Ωc\n0.5\n0.5\nStart of stop-band\n15 kHz\n11.75 kHz\nMaximum power gain at Ωr\n0.1\n0.1\n(a) What is the order of filter A if a Butterworth design is used.\n(b) What is the order of filter A if a Chebyshev design is used.\n(c) What is the order of filter B if a Butterworth design is used.\n(d) What is the order of filter B if a Chebyshev design is used.\n(e) Plot the power gain function H(jΩ) 2 of the Butterworth filter A using linear scales.\n|\n|\n(Use Matlab - don't do it by hand.) Use the plot to show that the filter meets the\nspecifications.\n(f) Use Matlab to design a Chebyshev Type 2 filter based on specifications for filter B. Then\nuse Matlab to convert this prototype design to a band-pass filter with a passband of\n5-15 kHz. Plot the Bode plots for the bandpass filter.\nProblem 2: Design a high-pass filter that will attenuate all components below 20 Hz by\nat least 40 dB, and pass all components above 50 Hz with a maximum attenuation of 3 dB.\n(Feel free to use Matlab)\nProblem 3:\nAnother way to design a high-pass filter is to design a unity gain low-pass\nfilter Hlp(jΩ) and then create the high-pass filter as\nHhp(j(Ω) = 1 - Hlp(j(Ω)\n(a) Compare the zeros of a high-pass filter created by this method with those created us\ning the transformation method described in the class handout by using a third order\nprototype low-pass filter.\n(b) Comment on the attenuation rate as Ω\n0 for high-pass filters developed by each\n→\nmethod.\n\n(c) Comment on the phase response of each filter as Ω\n0.\n→\n(d) Is the high frequency gain the same in each high-pass filter?\nProblem 4: An experimental set-up transmits three measurements over a single cable by\nencoding the information as the amplitude of three sinusoidal signals at 30Hz, 60 Hz, and\n90 Hz. Design a filter that will select out the 60 Hz component and attenuate the other two\nby at least 40 dB. Submit frequency response plots for your filter. (I realize that this is a\nvery \"loose\" specification - but that's the way it is in the real world!)"
    },
    {
      "category": "Assignment",
      "title": "Problem Set 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/5036a5cb9b61c3ccfa2beb1a2b9cd088_ps4.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n-1.5\n-1\n-0.5\n0.5\n1.5\nfam(t)\nt\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nProblem Set 4\nAssigned: Oct. 2, 2008\nDue: Oct. 9, 2008\nProblem 1:\nAn AM (amplitude-modulated) radio signal fAM (t) is described by\nfAM (t) = (1 + afaudio (t)) sin (Ωct)\nwhere faudio(t) is the audio signal, sin (Ωct) is known as radio-frequency carrier signal (fc =\n500 - 1600 kHz - the AM band), and a is a positive constant that determines the modulation\ndepth. (Note that we require afaudio (t) < 1 otherwise we have over-modulation.) the\n|\n|\nfollowing figure shows an AM signal with an \"audio\" waveform that is a simple low frequency\nsinusoid. You can see how the audio signal \"modulates\" the amplitude of the rf signal.\n(a) Sketch the magnitude of the Fourier transform of fAM (t) when faudio(t) = 0.\n(b) Let a = 0.5, and sketch the magnitude of the Fourier transform of fAM (t) when\nfaudio(t) = 0.5 cos(2π 1000t) + 0.25 cos(2π 2000t)\n·\n·\n(Hint: There is no need to actually compute the FT. Consider expanding fAM (t), or\nsimply use properties of the FT.)\n(c) Use your result from (b) to generalize, and sketch the magnitude spectrum of fAM (t)\nwhen faudio(t) has a spectrum (again let a = 0.5):\n\nw\nw\n- w\n- w\nu\nu\nl\nl\nw\nF ( j w )\nA\nA\n(d) If faudio has a bandwidth B = Ωu - Ωl, what is the bandwidth of a band-pass filter that\nwould be necessary to select the signal fAM (t) out of all the other AM radio stations?\nProblem 2:\nWe generally ignore in the phase response in filter design. Although you\nmight wish for a \"zero-phase\" filter, you can see from the class handout on causality that a\nfilter with a purely real frequency response is acausal, and as such cannot be implemented\nin a physical system. The following are a pair of tricks that may be used to do \"off-line\"\nzero-phase filtering of recorded data. (Note: these methods are used frequently in digital\nsignal processing - it is difficult to do this in continuous time.)\nAssume that you have a filter H(jΩ) with arbitrary phase response 6 H(jΩ), and that\nyour input signal is f(t) is recorded on a tape-recorder that can be played forwards or\nbackwards.\nMethod (1)\n1. Pass f(t) through the filter and record the output g(t) on another tape\nrecorder.\n2. Play g(t) backwards through the filter (that is the filter input is g(-t)) and record\nthe output x(t).\n3. The filtered output is found by playing the x(t) backwards, that is y(t) = x(-t).\nMethod (2)\n1. Pass f(t) through the filter and record the output g(t).\n2. Reverse f(t) so as to pass f(-t) through the filter and generate x(t).\n3. Reverse x(t) and sum with g(t) to form the output y(t) = g(t) + x(-t).\nShow that both methods generate an overall filter that has no phase shift, and find the\n\noverall magnitude response |Heq(jΩ)| in each case. Hint: F {f(-t)} = F (jΩ).\nProblem 3:\nProblem 5 in Problem Set 2 examined an all-pass filter with a transfer\nfunction\nH(s) = s - a\na > 0\ns + a\nand you showed that this filter had a frequency response in which H(jΩ) = 1 at all fre\n|\n|\nquencies.\nDesign an op-amp based first-order all-pass filter of this form that will have a phase shift\nof -90* at a frequency of 50 Hz. (Consider a modified form of the 3 op-amp circuit described\nin the handout - noting that you only need a first-order system.) Find \"appropriate\" values\n\n| H ( j ( W ) |\nW\nW\n0 . 7 0 7\nW\nW\nu\np\nl\nD\n- 3 d B b a n d w i d t h\nfor all resistors and capacitors.\nProblem 4:\nConsider the second-order bandpass filter with transfer function\na1s\nHbp(s) =\n.\ns2 + a1s + a0\nMany books on signal processing express this transfer function in terms of two parameters\nΩp and Q,\nΩp s\nQ\nHbp(s) =\ns2 + Ωp s + Ω2\nQ\np\nwhere Ωp is the (approximate) peak frequency (center of the passband), and Q is known as\nthe \"quality\" factor.\nAside: If you compare this to the classic second-order system description used in\nsystem dynamics and control, that is\n2ζΩns\nHbp(s) = s2 + 2ζΩns + Ω2\nn\nwhere Ωn is the undamped natural frequency, and ζ is the damping ratio, you can\nsee that\nQ =\n.\n2ζ\nIn this problem we examine the relationship between Q and the -3dB bandwidth of the\nsecond-order filter. Consider the magnitude plot below:\nLet Ωu and Ωl be the upper and lower -3db (0.707) response frequencies as shown, and let\nΔ = Ωu - Ωl be the -3dB bandwidth.\n\n(a) Show\n�\n\n�\nA 1\n!2\nΩu =\nΩp 1 +\n+\n1 +\n2Q2\nQ\n2Q\n�\n\n�\nA 1\n!2\nΩl =\nΩp 1 + 2Q2 - Q 1 + 2Q\n(b) Use these results to show that the -3dB bandwidth of the second-order filter is\nΩp\nΔ = Q\nHint: Write Δ =\n√\na + b -\n√\na - b.\n(c) Determine the transfer function of a second-order bandpass filter with a center frequency\nof 100 Hz., and a -3dB bandwidth of 10 Hz.\nProblem 5:\nA sampling system takes samples at regular intervals ΔT . Assume we have\na sinusoid\ny(t) = sin Ωt,\nso that the samples are y(nΔT ) = sin nΩΔT . We know that if the frequency Ω is greater\nthan the Nyquist frequency ΩN = π/ΔT , the sample set is aliased.\nNow consider two sinusoids, one y(t) = sin nΩ0ΔT with a frequency Ω0 that is below the\nNyquist frequency, and another with frequency Ω1 above the Nyquist frequency.\n(a) Assume y1(t) = sin Ω1t where\nΩ1 = 2kΩN - Ω0,\nk = 1 . . . inf is any positive integer.\nShow that the sample sets are related by y1(nΔT ) = -y(nΔT ) = - sin(nΩ0ΔT ),\n(b) Repeat part (a) with\nΩ1 = 2kΩN + Ω0,\nk = 1 . . . inf is any positive integer.\nand show that in this case the sample sets are identical, that is y2(nΔT ) = y(nΔT ) =\nsin(nΩ0ΔT ).\n(c) Use the results of (a) and (b) to graphically demonstrate the concept of \"frequency\nfolding\" of aliased sinusoids.\n(d) A periodic waveform is written as a Fourier Series\ny(t) = 5 sin(2π(25)t) + 2sin(2π(75)t) + 3 sin(2π(125)t).\nIf the waveform is sampled at 100 samples/sec, determine the frequencies and ampli\ntudes of the spectral components in the sampled waveform. (Hint: The results of parts\n(a) and (b) should help.)"
    },
    {
      "category": "Exam",
      "title": "Quiz #1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/9c5ea628cb00ecc710a8c4211663a94c_quiz1.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term, 2008\nQuiz #1 -- October 16, 2008\nNotes:\n- The quiz is closed-book, two sheets of notes are allowed.\n- The time allowed is ninety minutes.\n- There are 4 problems, answer them all.\n- Partial credit will be given.\n- Some possibly useful information is given at the\nback of this quiz.\n\nProblem 1: (20 points)\nA low-pass filter is to be designed from the power frequency response function\n|H(jΩ)| = 1 + Ω4\n(a) Determine a stable system transfer function based on this specification.\n(b) Make a pole-zero plot for the system and determine the filter class (low-pass, etc).\n(c) What type of design is this (Butterworth, Chebyshev Type I, etc).\n(d) Transform your filter design to a new filter H1(s), using the substitution\n2s\ns2 + 4 -→ s\nin H(s).\n(e) How many poles and zeros does H1(s) have, and what class of filter (low-pass etc) is it?.\nProblem 2: (20 points)\nYour advisor (who should remain nameless!) went out and bought you a new lab computer\ncomplete with A/D converters that will sample up to 10,000 samples/second. Without\nconsulting you he also went and bought a pressure sensor that produces a sinusoidal output\nwith a frequency that is proportional to pressure, in the range 0 to 7 kHz. He expects you\nto use the computer with the sensor.\nYour heart skips a beat. \"Oh, no - it cannot be!\", you cry in despair, \"The output of this\nsensor exceeds the maximum Nyquist rate allowed by my computer!\"\nBut, in fact, is everything lost?\nAssume that you have software that will allow you to take a record of sinusoidal data with\na sampling interval ΔT , and then report back its frequency. Determine and describe an\nexperimental procedure that will allow you to determine the frequency of the sensor output\nin the range 0 - 7 kHz, using a maximum sampling rate of 10 kHz.\nHints: 1) Remember that you are not asked to reconstruct an arbitrary unknown waveform,\ntherefore you know the effect of aliasing.\n2) You may want to consider taking more than one data record with different sampling rates.\nProblem 3: (35 points)\nWe are going to design a simple speech scrambler, that will encode an audio signal for \"secure\"\ntransmission (that is make it unintelligible) over the internet, yet allow it to be decoded at\nthe receiving end by a similar process.\nLet's start by investigating a Hilbert transformer, which is a linear system with a frequency\nresponse function\n1⁄2 -j, Ω > 0\nH(jΩ) =\nj, Ω < 0,\n\n(a) Determine the impulse response h(t) of the Hilbert transformer.\n\nIs this a causal filter?\nHint: F {sgn(t)} = 2/(jΩ) where sgn() is the signum function.\n(b) If the input to the Hilbert transformer is a sinusoid A sin(Ω1t), what is the output y(t)?\n\nWhat is the general effect on sinusoidal signals?\n(c) Now consider the block diagram of the complete speech scrambler below:\n\nInternally an oscillator generates a constant frequency sinusoid sin(Ωct). Assume for\nnow that the audio signal is a sinusoidal waveform A sin(Ω1t). Determine the output\nof the system y(t).\n(d) If the audio signal has a (one-sided) spectrum shown below\n\nsketch the magnitude spectrum |Y (jΩ)| of the output signal y(t). What will be the\namplitude and frequency of the component shown with frequency Ω1? Explain how\nthe scrambling operation works.\n(e) For extra credit, suggest what the \"descrambler\" needs to do to restore the original\nsignal.\nProblem 4: (25 points)\nA linear interpolator is a hardware, non-ideal, data reconstructor in which successive samples\nare connected by straight line segments (\"connect-the-dots\"). If the sample set is {f(nΔT)},\nthe reconstructed continuous waveform fˆ(t) can be written\nfˆ(t) = f ((n - 1) ΔT) + f(nΔT) - f ((n - 1) ΔT)(t - nΔT),\nnΔT ≤ t < (n + 1)ΔT\nΔT\n\nNotice that when t = nΔT, the interpolator output fˆ(t) = f((n - 1)ΔT), that is it is one\nstep ΔT behind. If we treat the linear interpolator as a filter,\n(a) Consider the response of the interpolator to the digital pulse train below:\n\nShow that the linear interpolator (with a single-step delay as above ) has an pulse\nresponse\n⎧\n⎨ t/ΔT,\n0 ≤ t < ΔT\nhˆ(t) =\n2 - t/ΔT,\nΔT ≤ t < 2ΔT,\n⎩ 0,\notherwise.\nSketch the pulse response (to help you in the next part).\n\n(b) Find the frequency response function Hˆ(jΩ) of the linear interpolator. You can use any\nmethod but, consider the two following possible methods:\nMethod 1:\nThe waveform x(t) to the left\n\nt/T, 0 ≤ t < T\nx(t) =\n0,\notherwise.\nhas a Fourier transform\ne-jΩT (jΩT + 1) - 1\nX(jΩ) =\nΩ2T\n(i) Use X(jΩ) to find the Fourier transform of the waveform x1(t) below\n\n(ii) Combine these results to find Hˆ(jΩ).\nMethod 2:\n- Consider h(t) as the convolution of two rect() functions...\n(c) Make a sketch of Hˆ(jΩ), and compare it to the frequency response of the ideal (cardi\nnal) reconstructor.\n\nSome useful/useless information:\nθ\nsin θ\ncos θ\ntan θ\nπ/6\nπ/4\nπ/3\nπ/2\n1/2\n√\n3/2\n√\n3/3\n√\n2/2\n√\n2/2\n√\n3/2\n1/2\n√\ninf\nx\nloge(x) log10(x)\n0.6931\n0.3010\n1.0986\n0.4771\n1.6094\n0.6990\n2.3026\n1.0000\nsin(a + b)\n=\nsin(a - b)\n=\ncos(a + b)\n=\ncos(a - b)\n=\ntan(a + b)\n=\ntan(a - b)\n=\nsin(a) cos(b) + cos(a) sin(b)\nsin(a) cos(b) - cos(a) sin(b)\ncos(a) cos(b) - cos(a) sin(b)\ncos(a) cos(b) + cos(a) sin(b)\ntan(a) + tan(b)\n1 - tan(a) tan(b)\ntan(a) - tan(b)\n1 + tan(a) tan(b)"
    },
    {
      "category": "Exam",
      "title": "Quiz #1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/5aace0acf21c0be1ac30f49fb4aed862_quiz1_07.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term, 2007\nQuiz #1 -- October 18, 2007\nNotes:\n- The quiz is open-book.\n- The time allowed is ninety minutes.\n- There are six problems, answer them all.\n- Partial credit will be given.\n\nProblem 1: (15 points)\nShow that to interpolate a value to the mid-point of a sampling interval in the sample set\n{fn}, n = 0 . . . N - 1, where fn = f(nΔT ), the cardinal (Whittaker) reconstructor may be\nwritten\n1 N-1\nf(nΔT + ΔT/2) =\nX\nfk\n(-1)k\nπ\n(n - k + 1/2)\nk=0\nProblem 2: (20 points)\n(a) Design (find the transfer function of) a unity-gain 3rd-order low-pass Butterworth analog\nfilter with a -3dB cut-off frequency of 10 rad/s.\n(b) Make a pole-zero plot for your filter.\n(c) Convert your design to a high-pass filter with the same cut-off frequency.\n(d) If (do not do it) you were to convert your design to a band-pass filter, what would be\nthe order of the filter, how many zeros would be created, and where in the s-plane\nwould the zeros lie?\nProblem 3: (15 points)\nMany real-life signal processing problems involve waveforms containing echoes, or reverber\nation. Consider a continuous-time linear filter with impulse response\nh(t) = δ(t) + δ(t - τ)\nAssume that the filter is excited with waveform f(t), and that the output is y(t)\n(i) Show that the output contains an echo, that is\ny(t) = f(t) + f(t - τ)\n(ii) Find the frequency response H(jω) for the filter, and express it in terms of its magnitude\n|H(jω)|, and phase 6 H(jω).\nHint:\n1 + e-jθ = e-jθ/2 h\nejθ/2 + e-jθ/2i\n(iii) Assume f(t) = sin ωt. At what values of ω will the filter exhibit no steady-state output?\n\nProblem 4: (20 points)\nAn AM (amplitude-modulated) radio signal fAM (t) is described by\nfAM (t) = (1 + afaudio (t)) sin (ωct)\nwhere faudio(t) is the audio signal, sin (ωct) is known as radio-frequency carrier signal (fc =\n500 - 1600 kHz - the AM band), and a is a positive constant that determines the modulation\ndepth. (Note that we require |afaudio (t)| < 1 otherwise we have over-modulation.) the\nfollowing figure shows an AM signal with an \"audio\" waveform that is a simple low frequency\nsinusoid. You can see how the audio signal \"modulates\" the amplitude of the rf signal.\nf (t)\nam\n1.5\n0.5\nt\n-0.5\n-1\n-1.5\n(a) Sketch the magnitude of the Fourier transform of fAM (t) when faudio(t) = 0.\n(b) Let a = 0.5, and sketch the magnitude of the Fourier transform of fAM (t) when\nfaudio(t) = 0.5 cos(2π · 1000t) + 0.25 cos(2π · 2000t)\n(Hint: There is no need to actually compute the FT. Consider expanding fAM (t), or\nsimply use properties of the FT.)\n(c) Use your result from (b) to generalize, and sketch the magnitude spectrum of fAM (t)\nwhen faudio(t) has a spectrum (again let a = 0.5):\n\n(d) If faudio has a bandwidth B = ωu - ωl, what is the bandwidth of a band-pass filter that\nwould be necessary to select the signal fAM (t) out of all the other AM radio stations?\n\nProblem 5: (15 points)\nThe most commonly used (approximate) data reconstructor is the \"zero-order hold\" (ZOH)\nwhich simply \"holds\" the output value y(nΔT) as a constant over the reconstruction interval:\ny(t) = f(nΔT)\nnΔT ≤ t < (n + 1)ΔT\nwhere f(nΔT) is the value of input at time t = nΔT. The output of the ZOH therefore\nlooks like a staircase function, with discrete jumps to a new value at each update time nΔT:\nZOH recon.\nf(t)\nt\nf(t)\n(a) Show that the ZOH can be represented as a linear filter with a pulse-like impulse response\nh(t)\n=\n\n≤ t < ΔT\n= 0\notherwise\nHint: Consider the sampled input data waveform f ∗(t) as a weighted impulse train at\nintervals ΔT,\ninf\nf ∗ (t) =\n\nf(nT)δ(t - nΔT).\nn=-inf\n(b) Find and sketch the frequency response function H(jω) for the ZOH data reconstructor.\n(c) Compare H(jω) with the frequency response of the ideal (cardinal) data reconstructor,\nand comment on why the ZOH is a non-ideal reconstructor.\n(d) The ZOH reconstruction (see the fig above) seems to be slightly delayed from f(t).\nDetermine the delay.\n\nProblem 6: (15 points)\nThe significant frequency range of an analog signal extends to 10 kHz. Beyond 10 kHz the\nsignal spectrum rolls-off (attenuates) at a rate of 20 dB/decade.\nThe signal is to be sampled at a rate of 200 kHz. The aliased frequency components intro\nduced into the 10 kHz range of interest must be kept below -60 dB as compared to signal\ncomponents.\nSuppose we use an analog low-pass pre-aliasing filter whose passband is flat over the 10 kHz\nband, and then attenuates at a rate steep enough to satisfy the above sampling require\nments. What is this attenuation rate in dB/decade? What would be the minimum order of\na low-pass filter to satisfy this condition?\nSome useful/useless information:\nθ\nπ/6\nπ/4\nπ/3\nπ/2\nx\nsin θ\ncos θ\ntan θ\n1/2\n√\n3/2\n√\n3/3\n√\n2/2\n√\n2/2\n√\n3/2\n1/2\n√\nsin(a + b)\n=\nsin(a - b)\n=\ncos(a + b)\n=\ncos(a - b)\n=\ntan(a + b)\n=\ntan(a - b)\n=\ninf\nloge(x) log10(x)\n0.6931\n0.3010\n1.0986\n0.4771\n1.6094\n0.6990\n2.3026\n1.0000\nsin(a) cos(b) + cos(a) sin(b)\nsin(a) cos(b) - cos(a) sin(b)\ncos(a) cos(b) - cos(a) sin(b)\ncos(a) cos(b) + cos(a) sin(b)\ntan(a) + tan(b)\n1 - tan(a) tan(b)\ntan(a) - tan(b)\n1 + tan(a) tan(b)"
    },
    {
      "category": "Exam",
      "title": "Quiz #2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/4b3148bfe88528f5a5bf4d92f160ef65_quiz2.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nDEPARTMENT OF MECHANICAL ENGINEERING\n2.161 Signal Processing - Continuous and Discrete\nFall Term, 2008\nQuiz #2 (Take Home)\nDue in class (1pm) on December 9, 2008\nNotes:\n- This is a take-home quiz.\n- Collaboration (with anybody) is expressly forbidden.\n- Do not spend excessive time on this quiz!\n- There are 4 problems, answer them all.\n- Partial credit will be given.\n- You may ask the teaching staff for help\nbut that help will be generally limited to\nensuring that you have access to the\nrequired data files.\n\nProblem 1: (20 points)\nHere is a simple way to design a digital high-pass filter from a low-pass design (this is not a\nmethod we talked about in class). Consider a prototype causal digital low-pass filter H lp(ej ω).\nThe figure below shows how a digital low-pass filter may be transformed to a high-pass filter\nby simply translating (shifting) its frequency response H( ej ω) by π, that is we create the\nhigh-pass filter from the prototype:\nHhp(ej ω) = Hlp( ej(ω-π)).\n\n(a) Assume that the original low-pass filter has a recursive difference equation\nN\nM\ny(n) = -\naky(n - k) +\nbkx(n - k)\nk=1\nk=0\ncorresponding to the discrete-time transfer function\nM bkz-k\nk=0\nHlp(z) =\nN\n1 +\nk=1 akz-k\nShow that the difference equation of the new high-pass filter is\nN\nM\ny(n) = -\n(-1)k aky(n - k) +\n(-1)kbkx(n - k)\nk=1\nk=0\nIn other words, a high-pass filter may be constructed by simply alternating the signs\nof the coefficients in the low-pass difference equation!\n(b) Show that the two discrete-time impulse responses are related by\nhhp(n) = (-1)nhlp(n)\n(c) How is the phase response Hhp(ej ω) of the high-pass filter related to the phase response\nHlp(ej ω) of the prototype low-pass filter?\nProblem 2: (25 points) An acoustic micro-GPS system.\nAn experiment on human movement requires that we monitor the position of a person's head\nduring the experiment. The experiment is to be conducted in a room 20×20 ft. with a 10 ft.\nceiling. Four loudspeakers have been installed in the top four corners of the room as shown\nbelow:\n\n! \"\n\n#\n\nThe human subject wears a microphone mounted on a helmet.\n- At regular intervals the transmitter broadcasts four uncorrelated wide-band acoustic\nsignals si(t), i = 1 . . . 4, simultaneously - each to one of the loudspeakers as shown\nabove.\n- The sampling rate used in both the transmitted and received signals is 100,000 sam\nples/sec.\n- The microphone signal r(t) is fed to the receiver, which computes and stores the carte\nsian coordinates x, y, z of the subject's head.\n- The transmitter and receiver have precision clocks that are synchronized, in other\nwords the receiver knows the time origin of each transmitted signal.\n- The speed of sound is 1125 ft/s.\n- There is \"significant\" noise in the room.\nThe Problem: You are given a file Q2Prob2.mat containing two MATLAB data ar\nrays: (1) A two-dimensional array s(4,500) containing the four transmitted waveforms\ns, and (2) a one-dimensional array r containing a single data record from the micro\nphone. Your task is to determine the cartesian coordinates (x, y, z) of the location of\nthe microphone at this time.\nNotes:\n- The system is (deliberately) over-determined. In fact you only need three speakers to\nsolve this problem. Just as in the GPS system the use of redundant sources allows\nfor situations when one source might be occluded from the microphone. Your solution\nshould use all four speakers. Use a least-squares approach to estimate the coordinates\nx, y, z. Suggestion: use MATLAB's lsqnonlin().\n\n- Since this is not a course in numerical optimization, most of the grade will be based\non setting up the data to pass to the least-squares solver.\n- MATLAB's lsqnonlin() requires you to write a function that returns an error vec\ntor (not the objective function). For example x = lsqnonlin(@myfun, x0) uses the\nfunction myfun(). See the help.\nProblem 3: (25 points) System Identification\nWe talked about the correlation method of system identification briefly in class, that is\nHˆ(j Ω) = Rfy(j Ω)\nRff(j Ω)\nwhere Hˆ(j Ω) is the estimated frequency response, Rff(j Ω) = F {ρff(τ)} is the auto-power\nspectrum at the input, and Rfy(j Ω) = F {ρfy(τ)} is the cross-power spectrum between input\nand output. This is all very nice in theory but, as we will see in this problem, things don't\nalways work out quite so well in practice.\nWe have an unknown plant with frequency response H(j Ω) and impulse response h(t).\nOur goal is to find estimates Hˆ(j Ω) and hˆ(t) of these quantities from input-output measure\nments. The system was driven with a wide-band input f(t), and the input and output y(t)\nwere sampled.\n\n$ % \" $ & '\nThe MATLAB file Q2Prob3.mat contains two data records (each of length 4096), recorded\nat 10,000 samples/sec. The vector f contains the input, and y contains the output.\n(a) Use the two data vectors to estimate H(j Ω) using the correlation method. Make plots\nof the magnitude and phase responses. (They are a bit messy!)\n(b) From your Hˆ(j Ω) find an estimate of the impulse response hˆ(n). Make a plot of the\nfirst 40 samples, using the stem() function.\n(c) Now repeat (a) and (b), but this time truncate the correlation functions so as to save\nonly the first 100 lags (a total of 201 samples). Apply a Hamming window of length 201\nto the new correlation sequences ρff(n), and cross-correlation ρfy(n), -100 ≤n ≤100,\nbefore computing the power spectra.\n(d) Discuss any improvements you see in the estimates of the frequency response and/or\nimpulse response resulting from the windowing.\nNotes:\n- In xcorr(x,y) MATLAB defines the cross-correlation function of two real sequences\nas\nRxy(m) = E {x(n + m)y(n)} .\n\n- Keep the following a secret: to help you assess your results, the \"unknown\" plant was\ncreated using\n[b, a] = butter(3,[0.15 0.5])\n- Hand in your MATLAB script and the plots you made.\nProblem 4: (30 points) Image Deblurring Revisited\nIn the image deblurring problem of Prob. Set 9 we were very careful to give you high precision\nvalues (MATLAB's double precision) for the RGB components of each pixel. Practical images\nare not stored with such accuracy; the intensity values are quantized to a fixed precision,\ncommonly 8 bits or a total of 28 = 256 possible levels for each of the RGB values. This\nintroduces an error into each of the pixels in the image. The following indicates a 1-D\ntime-based quantized signal with quantization interval Δ:\n(\n)\n#\nThe upshot is that quantization introduces random errors (or additive noise) into a sampled\ndata set, and common (dubious) assumptions about the noise are that\n- The noise is uniformly distributed across the quantization interval Δ, and\n- the noise is white.\nWhether or not the noise is truly \"white\" can be debated, but the significant thing for us is\nthat it has significant high frequency content. The simple inverse filter you constructed for\nProb. Set 9 had extremely large high-frequency gain (≈ 1013), with the result that it could\nnot tolerate any high frequency content in the blurred image without numerical failure.\nIn this problem we want you to modify your solution to the deblurring problem so that\nit will handle an image that has only eight bits of precision in the RGB values (with the\nresulting noise). Here are two simple empirical methods.\nMethod 1: A common way of dealing with noise amplification in inverse filters is to set an\nempirically chosen hard limit on the maximum gain in the inverse filter. In one-dimensional\nfiltering, if the distorting filter is H(j Ω) and the inverse filter is\nHinv(j Ω) = H(j Ω)\n\nwe can choose a maximum value γ for |Hinv(j Ω)| in a modified inverse filter\n⎪\n⎪\nif |H(j Ω)| >\nH′\ninv(j Ω) =\n⎨ H(j Ω)\nγ |H(j Ω)|\n⎧\nγ\n⎪\n⎪\nif |H(j Ω)| ≤ .\n⎩ H(j Ω)\nγ\nNotice that this retains the phase response, but limits the magnitude to a maximum of γ.\nMethod 2: Reza made the following suggestion. He reasoned that although the deblurred\nimage has higher frequency spectral content, is still essentially band-limited and we do\nnot need to retain all of the high frequency content. Therefore, eliminate high frequencies\ncompletely if the gain exceed the criterion γ using the modified inverse filter\n⎧\n⎪\nH′ (j Ω) =\n⎨ H(j Ω)\nif |H(j Ω)| > γ\ninv\n⎪\n⎩0\nif\n\n|H(j Ω)| ≤ .\nγ\nTo save you time, we have provided a basic deblurring file Q2Prob4.m that is based on our\nsolution to Prob. Set 9. Modify and use this file to investigate this problem. We also have\nprovided one of the blurred images used in Prob. Set 9, renamed to Q2Prob4.mat.\n- Q2Prob4.m starts by quantizing the image to 8 bits and converting it back to double\nprecision (but quantized) image with the line\nblurred8 = double(uint8(255*blurred))/255;\n(a) Modify Q2Prob4.m to implement Method 1. Investigate the effect of γ on the resulting\nimage. Start with γ = 1000, and find a value that you think is a good compromise\nbetween image sharpness and noise. (There is no \"correct\" answer)\n(b) Use your value of γ chosen in (a) and implement Method 2.\n(c) Compare the images from (a) and (b) (with the same value of γ), explain any differences\nyou see. In particular, look at the edges of the images.\n(d) Define the \"energy\" in a RGB image as the sum of the squared values of all pixels across\nthe whole image plane and all the color planes. Also define the signal to noise ratio\n(SNR) as\nenergy in the inverse filtered image\nSNR =\n.\nenergy in the inverse filtered noise\nCompute the SNR for Method 1 and Method 2 for values of γ = 1000, 100, 30, 3 before\nany intensity scaling. Does a high SNR generate a \"better\" output? Briefly (within a\nfew lines) discuss any compromises you see with regard to SNR and deblurring."
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/a6d15b07b9720f44e4bc2e9da4d3a5a2_lecture_01.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 11\nReading:\n-\nClass handout: The Dirac Delta and Unit-Step Functions\nIntroduction to Signal Processing\nIn this class we will primarily deal with processing time-based functions, but the methods\nwill also be applicable to spatial functions, for example image processing. We will deal with\n(a) Signal processing of continuous waveforms f(t), using continuous LTI systems (filters).\n\nand\n(b) Discrete-time (digital) signal processing of data sequences {fn} that might be samples of\nreal continuous experimental data, such as recorded through an analog-digital converter\n(ADC), or implicitly discrete in nature.\n\nSome typical applications that we look at will include\n(a) Data analysis, for example estimation of spectral characteristics, delay estimation in\necholocation systems, extraction of signal statistics.\n(b) Signal enhancement. Suppose a waveform has been contaminated by additive \"noise\",\nfor example 60Hz interference from the ac supply in the laboratory.\n1copyright ⃝c\nD.Rowell 2008\n1-1\n\n#\n\n$\n#\n$\n\n!\n\n#\n#\n\"\nThe task is to design a filter that will minimize the effect of the interference while not\ndestroying information from the experiment.\n(c) Signal detection. Given a noisy experimental record, ask the question whether a known\nsignal is present in the data.\n1.1\nProcessing methods\n(a) Passive Continuous Filters: We will investigate signal processing using passive con\ntinuous LTI (Linear Time-Invariant) dynamical systems. These will typically be elec\ntrical R-L-C systems, for example\n\nor even an electro mechanical system using rotational elements:\n\n(b) Active Continuous Filters: Modern continuous filters are implemented using oper\national amplifiers. We will investigate simple op-amp designs.\n\n1-2\n\n(c) Digital Signal Processors: Here a digital system (a computer or DSP chip) is used\nto process a data stream.\n\n%\n\n(i) The sampler (A/D converter) records the signal value at discrete times to produce\na sequence of samples {fn\n\n&\n\n!\n} where fn = f(nT ) (T is the sampling interval.\n(ii) At each interval, the output sample yn is computed, based on the history of the\ninput and output, for example\nyn =\n(fn + fn-1 + fn-2)\n3-point moving average filter, and\nyn = 0.8yn-1 + 0.2fn\nis a simple recursive first-order low-pass digital filter. Notice that they are algo\nrithms.\n(iii) The reconstructor takes each output sample and creates a continuous waveform.\nIn real-time signal processing the system operates in an infinite loop:\n\n' $\n( \"\n\n1-3\n\nProperties of LTI Continuous Filters\n\n!\n\nA LTI filter is dynamical SISO (single-input single-output) linear system, governed by an\nODE with constant coefficients. From elementary linear system theory, some fundamental\nproperties of LTI systems are:\n(a) The Principle of Superposition This is the fundamental property of linear systems.\nFor a system at rest at time t = 0, if the response to input f1(t) is y1(t), and the response\nto f2(t) is y2(t), then the response to a linear combination of f1(t) and f2(t), that is\nf3(t) = af1(t) + bf2(t) (a and b constants) is\ny3(t) = ay1(t) + by2(t).\n(b) The Differentiation Property\nIf the response to input f(t) is y(t), then the re\nsponse to the derivative of f(t), that is f1(t) = df/dt is\ndy\ny1(t) =\n.\ndt\n(c) The Integration Property\nIf the response to input f(t) is y(t), then the response\nt\nto the integral of f(t), that is f1(t) = -inf f(t)dt is\nt\ny1(t) =\ny(t)dt.\n-inf\n(d) Causality A causal system is non-anticipatory, that is it does not respond to an input\nbefore it occurs. Physical LTI systems are causal.\nThe Dirac Delta Function\nThe Dirac delta function is a non-physical, singularity function with the following definition\nfor t = 0\n\nδ(t) =\nundefined\nat t = 0\nbut with the requirement that\ninf\nδ(t)dt = 1,\n-inf\nthat is, the function has unit area. Despite its name, the delta function is not truly a\nfunction. Rigorous treatment of the Dirac delta requires measure theory or the theory of\ndistributions.\n1-4\n\nT\nT\nT\nT\na ) U n i t p u l s e s o f d i f f e r e n t e x t e n t s\nb ) T h e i m\np u l s e f u n c t i o n\n1 / T 1\n1 / T 2\n1 / T 3\n1 / T 4\nt\nd ( t )\nt\n\nd ( t )\nT\nThe figure below shows a unit pulse function δT (t), that is a brief rectangular pulse\nfunction of extent T , defined to have a constant amplitude 1/T over its extent, so that the\narea T × 1/T under the pulse is unity:\nδT (t) =\n\n⎧\n⎨\n⎩\nfor t ≤ 0\n1/T\n0 < t ≤ T\nfor t > T .\nThe Dirac delta function (also known as the impulse function) can be defined as the limiting\nform of the unit pulse δT (t) as the duration T approaches zero. As the extent T of δT (t)\ndecreases, the amplitude of the pulse increases to maintain the requirement of unit area\nunder the function, and\nδ(t) = lim δT (t).\nT\n→\nThe impulse is therefore defined to exist only at time t = 0, and although its value is strictly\nundefined at that time, it must tend toward infinity so as to maintain the property of unit\narea in the limit.\nProperties of the Delta Function\n4.0.1\nTime Shift\nAn impulse occurring at time t = a is δ(t - a).\n4.0.2\nThe strength of an impulse\nBecause the amplitude of an impulse is infinite, it does not make sense to describe a scaled\nimpulse by its amplitude. Instead, the strength of a scaled impulse Kδ(t) is defined by its\narea K.\n4.0.3\nThe \"Sifting\" Property of the Impulse\nWhen an impulse appears in a product within an integrand, it has the property of \"sifting\"\nout the value of the integrand at the time of its occurrence:\nZ inf\nf(t)δ(t - a)dt = f(a)\n-inf\n1-5\n\nThis is easily seen by noting that δ(t - a) is zero except at t = a, and for its infinitesimal\nduration f(t) may be considered a constant and taken outside the integral, so that\nZ inf\nZ inf\nf(t)δ(t - a)dt = f(a)\nδ(t - a)dt = f(a)\n-inf\n-inf\nfrom the unit area property.\n4.0.4\nScaling\nA helpful identity is the scaling property:\nZ inf\nZ inf\ndu\nδ(αt)dt =\nδ(u)\n=\n-inf\n-inf\n|α|\n|α|\nand so\nδ (αt) =\nδ(t).\n|α|\n4.0.5\nLaplace Transform\nZ inf\nL {δ(t)} =\n0- δ(t)e-stdt = 1\nby the sifting property.\n4.0.6\nFourier Transform\nZ inf\nδ(t)e-jΩtdt = 1\nF {δ(t)} =\n-inf\nby the sifting property.\nPractical Applications of the Dirac Delta Function\n- The most important application of δt in linear system theory is directly related to its\nLaplace transform property, L {δ(t)} = 1. Consider a SISO LTI system with transfer\nfunction H(s), with input u(t) and output y(t), so that in the Laplace domain\nY (s) = H(s)U(s).\nIf the input is u(t) = δ(t), so that U(s) = 1, then Y (s) = H(s).1, and through the\ninverse Laplace transform\ny(t) = h(t) = L-1 {H(s)} .\nwhere h(t) is defined as the system's impulse response. The impulse response com\npletely characterizes the system, in the sense that it allows computation of the transfer\nfunction (and hence the differential equation).\n1-6\n\n- The impulse response h(t) is used in the convolution integral.\n- In signal processing the delta function is used to create a Dirac comb (also known as\nan impulse train, or Shah function):\ninf\nΔT (t) =\nX\nδ(t - nT )\nn=-inf\nis used in sampling theory. A continuous waveform f(t) is sampled by multiplication\nby the Dirac comb\ninf\nf ∗(t) = f(t)ΔT (t) =\nX\nf(t - nT )δ(t - nT ),\nn=-inf\nwhere f ∗(t) is the sampled waveform, producing a train of weighted impulses.\n1-7"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/6a9dd6d7fe4f6102720e6dcded0c76e9_lecture_02.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 21\nReading:\n- Class handout: Convolution\n- Class handout: Sinusoidal Frequency Response\nContinuous LTI System Time-Domain Response\nA continuous linear filter is a LTI dynamical system (described by an ODE with constant\ncoefficients). We are interested in the input-output relationships and seek a method of\ndetermining the response y(t) to a given input u(t).\n\nThe relationship is developed as follows (see the handout for a detailed explanation)\n- The input u(t) is approximated as a zero-order (staircase) waveform uT (t) with intervals\nT .\n\nu T (t) = u(nT )\nfor nT ≤ t < (n + 1)T.\n- The approximation uT (t) is written as a superposition of non-overlapping pulses\ninf\nu T (t) =\npn(t)\nn=-inf\nc\n1copyright ⃝ D.Rowell 2008\n2-1\n\nwhere\nu(nT )\nnT ≤ t < (n + 1)T\npn(t) =\notherwise\nFor example, p3(t) is shown cross-hatched in the figure above.\n- Each component pulse pn(t) is written in terms of a delayed unit pulse δT (t), of width\nT and amplitude 1/T that is:\npn(t) = u(nT )δT (t - nT )T\nso that\ninf\nu T (t) =\nu(nT )δT (t - nT )T.\nn=-inf\n- Assume that the system response to an input δT (t) is a known function, and is desig\nnated hT (t) as shown below. If the system is linear and time-invariant, the response\nto a delayed unit pulse, occurring at time nT is simply a delayed version of the pulse\nresponse:\nyn(t) = hT (t - nT )\n\n- The principle of superposition allows the total system response to uT (t) to be written\nas the sum of the responses to all of the component weighted pulses:\ninf\ny T (t) =\nu(nT )hT (t - nT )T\nn=-inf\n\nFor causal systems the pulse response hT (t) is zero for time t < 0, and future com\nponents of the input do not contribute to the sum, so that the upper limit of the\nsummation may be rewritten:\nN\ny T (t) =\nu(nT )hT (t - nT )T\nfor NT ≤ t < (N + 1)T.\nn=-inf\n2-2\n\n- We now let the pulse width T become very small, and write nT = τ, T = dτ , and note\nthat limT →0 δT (t) = δ(t). As T → 0 the summation becomes an integral and\nN\n\ny(t) = lim\nT →0\nu(nT )hT (t - nT )T\nn=-inf\nt\n=\nu(τ)h(t - τ)dτ\n(1)\n-inf\nwhere h(t) is defined to be the system impulse response,\nh(t) = lim hT (t).\nT →0\nEquation (??) is an important integral in the study of linear systems and is known as the\nconvolution or superposition integral. It states that the system is entirely characterized by its\nresponse to an impulse function δ(t), in the sense that the forced response to any arbitrary\ninput u(t) may be computed from knowledge of the impulse response alone. The convolution\noperation is often written using the symbol ⊗:\nt\ny(t) = u(t) ⊗ h(t) =\nu(τ)h(t - τ)dτ.\n(2)\n-inf\nEquation (??) is in the form of a linear operator, in that it transforms, or maps, an input\nfunction to an output function through a linear operation.\n\nThe form of the integral in Eq. (??) is difficult to interpret because it contains the term\nh(t - τ) in which the variable of integration has been negated. The steps implicitly involved\nin computing the convolution integral may be demonstrated graphically below. The impulse\nresponse h(τ) is reflected about the origin to create h(-τ), and then shifted to the right\nby t to form h(t - τ). The product u(t)h(t - τ) is then evaluated and integrated to find\nthe response. This graphical representation is useful for defining the limits necessary in the\nintegration. For example, since for a physical system the impulse response h(t) is zero for all\nt < 0, the reflected and shifted impulse response h(t - τ) will be zero for all time τ > t. The\nupper limit in the integral is then at most t. If in addition the input u(t) is time limited,\nthat is u(t) ≡ 0 for t < t1 and t > t2, the limits are:\n⎧\nt\n⎪\n⎪\n⎨\nu(τ)h(t - τ)dτ\nfor t < t2\nyf (t) =\nt1 t2\n(3)\n⎪\n⎪\n⎩\nu(τ )h(t - τ)dτ\nfor t ≥ t2\nt1\n2-3\n\nSee the class handout for further details and examples.\n2-4\n\nSinusoidal Response of LTI Continuous Systems\nOf particular interest is the response of an LTI continuous system to sinusoidal inputs of the\nform u(t) = A sin(Ωt + φ), where A is the amplitude, Ω is the angular frequency (rad/s),\nand φ is a phase angle (rad). (We note that we can also write u(t) = A sin(2πFt + φ), where\nF is the frequency in Hz.)\nWe begin by noting that a sinusoid may be expressed in terms of complex exponentials\nthrough the Euler formulas:\nsin(Ωt)\n=\nejΩt -e -jΩt\n\n2j\ncos(Ωt)\n=\nejΩt + e -jΩt\n\nand first finding the steady-state solution to inputs of the form u(t) = ejΩt . Let the LTI\nsystem be described by an ODE of the form\ndny\ndn-1y\ndy\ndmu\ndm-1u\ndu\nan\n+ an-1\n+ · · · + a1\n+ a0y = bm\n+ bm-1\n+ · · · + b1\n+ b0u.\ndtn\ndtn-1\ndt\ndtn\ndtm-1\ndt\nThe steady-state response of the system (after all initial condition transients have decayed)\nmay be found using the method of undetermined coefficients, in which a form of the solution\nis assumed and solved for a set of coefficients. In particular, if the input is u(t) = ejΩt ,\nassume that\ny(t) = BejΩt .\nSubstitution into the differential equation gives\nan(jΩ)n + an-1(jΩ)n-1 + · · · + a1(jΩ) + a0 BejΩt\n= bm(jΩ)m + bn-1(jΩ)m-1 + · · · + b1(jΩ) + b0 ejΩt\nand solving for B\nan(jΩ)n + an-1(jΩ)n-1 + · · · + a1(jΩ) + a0\nB = bm(jΩ)m + bn-1(jΩ)m-1 + · · · + b1(jΩ) + b0\nso that\ny(t) = H(jΩ)ejΩt\nwhere\nN(jΩ)\nan(jΩ)n + an-1(jΩ)n-1 + · · · + a1(jΩ) + a0\nH(jΩ) =\n=\nD(jΩ)\nbm(jΩ)m + bn-1(jΩ)m-1 + · · · + b1(jΩ) + b0\nH(jΩ) is defined to be the frequency response function, and N(jΩ) and D(jΩ) are the\nnumerator and denominator polynomials respectively. We note the following:\n- The output y(t) is simply a (multiplicatively) weighted version of the input.\n- H(jΩ) is a property of the system. It is defined entirely by the describing differential\nequation.\n2-5\n\n- H(jΩ) is, in general, complex. Even powers of n and m in N(s) and D(s) will generate\nreal terms in the polynomials, while odd powers will generate imaginary terms.\n|H(jΩ)| = |N(jΩ)|\n|D(jΩ)|\nH(jΩ) =\nN(jΩ) - D(jΩ)\n- H(-jΩ) = H(jΩ), where H(jΩ) is the complex conjugate.\nThe response to the real sinusoid\nA\n\nu(t) = A sin (Ωt + φ) =\nej(Ωt+φ) - e -j(Ωt+φ)\n2j\nmay be found from the principle of superposition by summing the response to each compo\nnent:\ny(t)\n=\nA\nH(jΩ)ej(Ωt+φ) - H(-jΩ)e -j(Ωt+φ)\n2j\n= A\nH(jΩ)ej(Ωt+φ) - H(jΩ)e -j(Ωt+φ)\n2j\nCombining the real and imaginary parts gives the result\ny(t) = A |H(jΩ)| sin (Ωt + φ + H(jΩ))\nwhere |H(jΩ)| is the magnitude of the frequency response function, and H(jΩ) is the phase\nresponse.\n- The response to a real sinusoid is therefore a sinusoid of the same frequency as the\ninput.\n- The amplitude of the response at an input frequency of Ω has been modified by a factor\n|H(jΩ)|. If |H(jΩ)| > 1 the input has been amplified by the system, if |H(jΩ)| < 1,\nthe signal has been attenuated.\n- The system has imposed a frequency dependent phase shift H(jΩ) on the response.\nExample 1\nA first-order passive RC filter with the following circuit diagram\n\n2-6\n\nis described by the differential equation\ndvo\nRC\n+ vo = Vin(t)\ndt\nFind the frequency response function.\nBy inspection\nH(jΩ) = jRCΩ + 1\nand\n|H(jΩ)| =\n|1|\n=\n|1 + jRCΩ|\n(RCΩ)2 + 1\nH(jΩ) =\n(1) - (1 + jRCΩ) = 0 -tan-1 (RCΩ)\nClearly, as Ω →0, |H(jΩ)| →1, and H(jΩ) →0 rad. As Ω →inf, |H(jΩ)| →0,\nand H(jΩ) →-π/2 rad (-90*).\nThis is a low-pass filter, in that it passes low frequency sinusoids while attenuating\nhigh frequencies.\nExample 2\nA new first-order passive RC filter is formed by exchanging the resistor and\ncapacitor in the previous example:\n\nand is now described by the differential equation\ndvo\ndVin\nRC\n+ vo = RC\ndt\ndt\nFind the frequency response function.\nBy inspection\njRCΩ\nH(jΩ) = jRCΩ + 1\nand\n|H(jΩ)| =\n|jRCΩ|\n= RCΩ\n|1 + jRCΩ|\n(RCΩ)2 + 1\nH(jΩ) =\n(jRCΩ) - (1 + jRCΩ) = π -tan-1 (RCΩ)\n2-7\n\nClearly, as Ω → 0, |H(jΩ)| → 0, and 6 H(jΩ) → π/2 rad (90*). As Ω →inf,\n|H(jΩ)| → 1, and 6 H(jΩ) → 0 rad (0*).\nThis is a high-pass filter, in that it attenuates low frequency sinusoids while\npassing high frequencies.\n2-8"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/b81bf801e1256e9678a723342293972d_lecture_03.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 31\nReading:\n- Class handout: Frequency Domain Methods\nThe Fourier Series and Transform\nIn Lecture 2 we looked at the response of LTI continuous systems to sinusoidal inputs of the\nform\nu(t) = A sin(Ωt + φ)\nand saw that the system was characterized by the frequency response function H(jΩ).\nIn signal processing work, linear filters are usually specified by a desired frequency re\nsponse function. (We will see that often the magnitude function |H(jω)| alone is used to\nspecify a filter). The following figure shows the four basic forms of ideal linear filters:\n\nIn this lecture we generalize the response of LTI systems to non-sinusoidal inputs. We do\nthis using Fourier methods.\n1copyright ⃝c\nD.Rowell 2008\n3-1\n\nPeriodic Input Functions - The Fourier Series\nIn general, a periodic function is a function that satisfies the relationship:\nx(t) = x(t + T)\nfor all t, or x(t) = x(t + nT) for n = ±1, ±2, ±3, . . ., where T is defined as the period. Some\nexamples of periodic functions is shown below.\n\nThe fundamental angular frequency Ω0 (in radians/second) of a periodic waveform is defined\ndirectly from the period\n2π\nΩ0 =\n,\nT\nand the fundamental frequency F0 (in Hz) is\nF0 = T\nso that Ω0 = 2πF0.\n- Any periodic function with period T is also be periodic at intervals of nT for any\npositive integer n. Similarly any waveform with a period of T/n is periodic at intervals\nof T seconds.\n- Two waveforms whose periods, or frequencies, are related by a simple integer ratio are\nsaid to be harmonically related.\n- If two harmonically related functions are summed together to produce a new function\ng(t) = x1(t) + x2(t), then g(t) will be periodic with a period defined by the longest\nperiod of the two components. In general, when harmonically related waveforms are\nadded together the resulting function is also periodic with a repetition period equal to\nthe fundamental period.\n3-2\n\nExample 1\nA family of waveforms gN (t) (N = 1, 2 . . . 5) is formed by adding together the\nfirst N of up to five component functions, that is\nN\ngN (t) =\nxn(t)\n1 < N ≤ 5\nn=1\nwhere\nx1(t)\n=\n\nx2(t)\n=\nsin(2πt)\nx3(t)\n=\nsin(6πt)\nx4(t)\n=\nsin(10πt)\nx5(t)\n=\nsin(14πt).\nThe first term is a constant, and the four sinusoidal components are harmonically\nrelated, with a fundamental frequency of Ω0 = 2π rad/s and a fundamental period\nof T = 2π/Ω0 = 1 second. (The constant term may be considered to be periodic\nwith any arbitrary period, but is commonly considered to have a frequency of\nzero rad/s.) The figure below shows the evolution of the function that is formed\nas more of the individual terms are included into the summation. Notice that\nin all cases the period of the resulting gN (t) remains constant and equal to the\nperiod of the fundamental component (1 second). In this particular case, it can\nbe seen that the sum is tending toward a square wave as more terms are included.\n\n! \"\n3-3\n\nThe Fourier series representation of an arbitrary periodic waveform x(t) (subject to some\ngeneral conditions described later) is as an infinite sum of harmonically related sinusoidal\ncomponents, commonly written in the following three equivalent forms\ninf\nx(t)\n=\na0 +\n(an cos(nΩ0t) + bn sin(nΩ0t))\n(1)\nn=1\ninf\n=\na0 +\nAn sin(nΩ0t + φn)\n(2)\nn=1\n+inf\n=\nXnejnΩ0t .\n(3)\nn=-inf\nIn each representation knowledge of the fundamental frequency Ω0, and the sets of Fourier\ncoefficients {an} and {bn} (n = 0 . . . inf), or {An} and {φn}) (n = 0 . . . inf), or {Xn} (n =\n-inf . . . inf) is sufficient to completely define the waveform x(t).\nThese representations are related by\nAn =\na2\nn + b2\nn\nφn = tan-1(an/bn).\nand\nXn =\n1/2(an - jbn)\nX-n =\n1/2(an + jbn)\nSee the class handout for details.\nThe spectrum of a periodic waveform is the set of all of Fourier coefficients in any of\nthe representations, for example {An} and {φn}, expressed as a function of frequency. Be\ncause the harmonic components exist at discrete frequencies, periodic functions are said to\nexhibit line (or discrete) spectra, and it is common to express the spectrum graphically with\nfrequency Ω as the independent axis, and with the Fourier coefficients plotted as lines at\nintervals of Ω0. The first two forms of the Fourier series, based upon Eqs. (??) and (??),\ngenerate \"one-sided\" spectra because they are defined from positive values of n only, whereas\nthe complex form defined by Eq. (??) generates a \"two-sided\" spectrum because its summa\ntion requires positive and negative values of n. The figure below shows a complex spectrum\n(Eq. ??).\n3-4\n\n#\n$\n\n$\n#\n\n#\n$\n\n$\n#\n\n% &\n% &\n\n2.1\nComputation of the Fourier Coefficients\nSection (2.1) of the class handout derives the finite (truncated) Fourier series as a least-\nsquares approximation to the periodic function x(t). The results show that for the complex\nrepresentation\nt0+T\nXn =\nxp(t)e -jnΩ0tdt,\nT\nt0\nand for the real representation\n2 t0+T\nan =\nx(t) cos(nΩ0t)dt\nT\nt0\n2 t0+T\nbn =\nx(t) sin(nΩ0t)dt.\nT\nt0\nThe results are summarized in the following table:\nSinusoidal formulation\nExponential formulation\nSynthesis: x(t) = 1\n2 a0 +\ninf\n\nn=1\n(an cos(nΩ0t) + bn sin(nΩ0t))\nx(t) =\n+inf\n\nn=-inf\nXnejnΩ0t\nAnalysis:\nan\nbn\n= 2\nT\nt1+T\nt1\nx(t) cos(nΩ0t)dt\n= 2\nT\nt1+T\nt1\nx(t) sin(nΩ0t)dt\nXn = 1\nT\nt1+T\nt1\nx(t)e -jnΩ0tdt\n3-5\n\n2.2\nProperties of the Fourier Series\nThe following are some of the important properties of the Fourier series:\n(1) Existence of the Fourier Series For the series to exist, the Fourier analysis integral\nmust converge. A set of three sufficient conditions, known as the Dirichelet conditions,\nguarantee the existence of a Fourier series for a given periodic waveform x(t). They\nare\n- The function x(t) must be absolutely integrable over any period, that is\nt0+T\n|x(t)| dt < inf\nt0\nfor any t0.\n- There must be at most a finite number of maxima and minima in the function\nx(t) within any period.\n- There must be at most a finite number of discontinuities in the function x(t)\nwithin any period, and all such discontinuities must be finite in magnitude.\nThese requirements are satisfied by almost all waveforms found in engineering practice.\nThe Dirichelet conditions are a sufficient set of conditions to guarantee the existence\nof a Fourier series representation. They are not necessary conditions, and there are\nsome functions that have a Fourier series representation without satisfying all three\nconditions.\n(2) Linearity of the Fourier Series Representation The Fourier analysis and synthe\nsis operations are linear. Consider two periodic functions g(t) and h(t) with identical\nperiods T , and their complex Fourier coefficients\n1 T\nGn =\ng(t)e -jnΩ0tdt\nT\n1 T\nHn =\nh(t)e -jnΩ0tdt\nT\nand a third function defined as a weighted sum of g(t) and h(t)\nx(t) = ag(t) + bh(t)\nwhere a and b are constants. The linearity property, which may be shown by direct\nsubstitution into the integral, states that the Fourier coefficients of x(t) are\nXn = aGn + bHn,\nthat is the Fourier series of a weighted sum of two time-domain functions is the weighted\nsum of the individual series.\n3-6\n\n(3) Even and Odd Functions If x(t) exhibits symmetry about the t = 0 axis the Fourier\nseries representation may be simplified. If x(t) is an even function of time, that is\nx(-t) = x(t), the complex Fourier series has coefficients Xn that are purely real, with\nthe result that the real series contains only cosine terms, so that Eq. (??) simplifies to\ninf\nx(t) = a0 +\nan cos(nΩ0t).\nn=1\nSimilarly if x(t) is an odd function of time, that is x(-t) = -x(t), the coefficients Xn\nare imaginary, and the one-sided series consists of only sine terms:\ninf\nx(t) =\nbn sin(nΩ0t).\nn=1\nNotice that an odd function requires that x(t) have a zero average value.\n(4) The Fourier Series of a Time Shifted Function If the periodic function x(t) has\na Fourier series with complex coefficients Xn, the series representing a \"time-shifted\"\nversion g(t) = x(t + τ) has coefficients e-jnΩ0τXn. If\nthen\n1 T\nXn =\nx(t)e -jnΩ0tdt\nT\n1 T\nGn =\nf(t + τ)e -jnΩ0tdt.\nT\nChanging the variable of integration ν = t + τ gives\nτ+T\nGn =\nf(ν)e -jnΩ0(ν-τ)dν\nT\nτ\njnΩ0τ 1 τ+T\n-jnΩ0νtdν\n= e\nf(ν)e\nT\nτ\njnΩ0τXn.\n= e\nIf the nth spectral component is written in terms of its magnitude and phase\nxn(t) = An sin(nΩ0t + φn)\nthen\nxn(t + τ)\n=\nAn sin (nΩ0(t + τ ) + φn)\n= An sin (nΩ0t + φn + nΩ0τ ) .\nThe additional phase shift nΩ0τ, caused by the time shift τ , is directly proportional\nto the frequency of the component nΩ0.\n3-7\n\n(5) Interpretation of the Zero Frequency Term\nThe coefficients X0 in the complex\nseries and a0 in the real series are somewhat different from all of the other terms for\nthey correspond to a harmonic component with zero frequency. The complex analysis\nequation shows that\n1 t1+T\nX0 =\nx(t)dt\nT\nt1\nand the real analysis equation gives\n1 t1+T\na0 =\nx(t)dt\nT\nt1\nwhich are both simply the average value of the function over one complete period.\nIf a function x(t) is modified by adding a constant value to it, the only change in its\nseries representation is in the coefficient of the zero-frequency term, either X0 or a0.\n2.3\nThe Response of Linear Systems to Periodic Inputs\nConsider a linear single-input, single-output system with a frequency response function\nH(jΩ). Let the input u(t) be a periodic function with period T, and write it in terms\nof a real Fourier series:\ninf\nu(t) = a0 +\nAn sin(nΩ0t + φn)\nn=1\nThe nth real harmonic input component, un(t) = An sin(nΩ0t + φn), generates an output\nsinusoidal component yn(t) with a magnitude and a phase that is determined by the system's\nfrequency response function H(jΩ):\nyn(t) = |H(jnΩ0)| An sin(nΩ0t + φn + H(jnΩ0)).\nThe principle of superposition states that the total output y(t) is the sum of all such com\nponent outputs, or\ninf\ny(t)\n=\n\nyn(t)\nn=0\ninf\n=\na0H(j0) +\nAn |H(jnΩ0)| sin (nΩ0t + φn + H(jnΩ0)) ,\nn=1\nwhich is itself a Fourier series with the same fundamental and harmonic frequencies as the\ninput. The output y(t) is therefore also a periodic function with the same period T as\nthe input, but because the system frequency response function has modified the relative\nmagnitudes and the phases of the components, the waveform of the output y(t) differs in\nform and appearance from the input u(t).\nIn the complex formulation the input waveform is decomposed into a set of complex\nexponentials un(t) = UnejnΩ0t . Each such component is modified by the system frequency\nresponse so that the output component is\nyn(t) = H(jnΩ0)UnejnΩ0t\n3-8\n\nand the complete output Fourier series is\ninf\ninf\ny(t) =\nyn(t) =\nH(jnΩ0)UnejnΩ0t .\nn=-inf\nn=-inf\n\n\" \"\n\n\"\n\n' ( )\n*\n\n) \"\n\n) \"\n\n�\n+\n\n\"\n\n+\nThe system H(jΩ) acts as a frequency-domain filter and modifies the input wave\nform u(t) by (1) selectively amplifying/attenuating the spectral components, and (2)\napplying a frequency dependent phase shift.\nSee the class handout for examples.\nAperiodic Input Functions - The Fourier Transform\nMany waveforms found in practice are not periodic and therefore cannot be analyzed directly\nusing Fourier series methods. A large class of system excitation functions can be character\nized as aperiodic, or transient, in nature. These functions are limited in time, they occur\nonly once, and decay to zero as time becomes large.\nConsider a function x(t) of duration Δ that exists only within a defined interval t1 < t ≤\nt1 + Δ, and is identically zero outside of this interval. We begin by making a simple assump\ntion; namely that in observing the transient phenomenon x(t) within any finite interval that\nencompasses it, we have observed a fraction of a single period of a periodic function with a\nvery large period; much larger than the observation interval. Although we do not know what\nthe duration of this hypothetical period is, it is assumed that x(t) will repeat itself at some\ntime in the distant future, but in the meantime it is assumed that this periodic function\nremains identically zero for the rest of its period outside the observation interval.\nThe analysis thus conjectures a new function xp(t), known as a periodic extension of x(t),\nthat repeats every T seconds (T > Δ), but at our discretion we can let T become very large.\n3-9\n\n- 2 T\n- T\nT\n2 T\n3 T\nx ( t )\nx ( t )\np\nx ( t )\nD\nt\nAs observers of the function xp(t) we need not be concerned with its pseudo-periodicity\nbecause we will never be given the opportunity to experience it outside the first period, and\nfurthermore we can assume that if xp(t) is the input to a linear system, T is so large that the\nsystem response decays to zero before the arrival of the second period. Therefore we assume\nthat the response of the system to x(t) and xp(t) is identical within our chosen observation\ninterval. The important difference between the two functions is that xp(t) is periodic, and\ntherefore has a Fourier series description.\nThe development of Fourier analysis methods for transient phenomena is based on the\nlimiting behavior of the Fourier series describing xp(t) as the period T approaches infinity.\nThe derivation proceeds in the following steps (see the class handout for details).\n(1) The waveform xp(t) is described by a Fourier series with lines spaced at intervals\n2π\nΩ0 = T\nand coefficients\nt0+T\n1 Z\nXn =\nxp(t)e-jnΩ0tdt\nT\nt0\n(2) From the synthesis equation (with t0 = -T/2)\ninf\njnΩ0t\nxp(t)\n=\nX\nXne\nn=-inf\nZ T/2\n)\ninf (\nΩ0\njnΩ0t\n=\nX\nxp(t)e-jnΩ0tdt e\n2π\n-T/2\nn=-inf\nThe figure below shows how the line spectrum varies as the period T changes. Note that\nthe shape of the envelope defining the spectrum is unaltered, but the the magnitude\nand the line spacing changes.\n3-10\n\n1 . 0\nt\nx ( t )\nT = 4\n1 . 0\nt\nx ( t )\nT = 2\n1 . 0\nt\nx ( t )\nT = 1\nT X n\nn\nn\nn\n0w = 2 p\nr a d / s e c\n0w = p / 2\nr a d / s e c\n0w = p\nr a d / s e c\nT X n\nT X n\n(c) The period T is now allowed to become arbitrarily large, with the result that the fun\ndamental frequency Ω0 becomes very small and we write Ω0 = δΩ. We define x(t) as\nthe limiting case of xp(t) as T approaches infinity, that is\nx(t) =\nlim xp(t)\nT →inf\ninf\n(Z T/2\n(t)e-jnδΩtdt\n)\njnδΩtδΩ\n=\nlim\nX\nxp\ne\nT →inf\n2π\n-T/2\nn=-inf\nZ inf 1 1⁄2Z -inf\n3⁄4\n=\nx(t)e-jΩtdt ejΩtdΩ\n(4)\n2π\n-inf\n-inf\nwhere in the limit the summation has been replaced by an integral.\n(d) If the function inside the braces is defined to be X(jΩ), Eq. (??) may be expanded into\na pair of equations, known as the Fourier transform pair:\nZ inf\nX(jΩ) =\nx(t)e-jΩtdt\n-infZ inf\nx(t)\n=\nX(jΩ)ejΩtdΩ\n2π\n-inf\nwhich are the equations we seek.\n(To be continued in Lecture 4)\n3-11"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/b0a5f07216a4153e8f6160178f0ea764_lecture_04.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n°\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 41\nReading:\n-\nReview of Development of Fourier Transform:\nWe saw in Lecture 3 that the Fourier transform representation of aperiodic waveforms can be\nexpressed as the limiting behavior of the Fourier series as the period of a periodic extension\nis allowed to become very large, giving the Fourier transform pair\nZ inf\nX(jΩ) =\nx(t)e-jΩtdt\n(1)\n-infZ inf\nx(t)\n=\nX(jΩ)ejΩtdΩ\n(2)\n2π\n-inf\nEquation (??) is known as the forward Fourier transform, and is analogous to the analysis\nequation of the Fourier series representation. It expresses the time-domain function x(t)\nas a function of frequency, but unlike the Fourier series representation it is a continuous\nfunction of frequency. Whereas the Fourier series coefficients have units of amplitude, for\nexample volts or Newtons, the function X(jΩ) has units of amplitude density, that is the\ntotal \"amplitude\" contained within a small increment of frequency is X(jΩ)δΩ/2π.\nEquation (??) defines the inverse Fourier transform. It allows the computation of the\ntime-domain function from the frequency domain representation X(jΩ), and is therefore\nanalogous to the Fourier series synthesis equation. Each of the two functions x(t) or X(jΩ)\nis a complete description of the function and the pair allows the transformation between the\ndomains.\nWe adopt the convention of using lower-case letters to designate time-domain functions,\nand the same upper-case letter to designate the frequency-domain function. We also adopt\nthe nomenclature\nx(t)\nF\nX(jΩ)\n⇐⇒\nas denoting the bidirectional Fourier transform relationship between the time and frequency-\ndomain representations, and we also frequently write\nX(jΩ) = F{x(t)}\nx(t)\n= F-1 {X(jΩ)}\nas denoting the operation of taking the forward F{}, and inverse F-1{} Fourier transforms\nrespectively.\n1copyright c\nD.Rowell 2008\n4-1\n\n1.1\nAlternate Definitions\nAlthough the definitions of Eqs. (??) and (??) flow directly from the Fourier series, definitions\nfor the Fourier transform vary from text to text and in different disciplines. The main\nobjection to the convention adopted here is the asymmetry introduced by the factor 1/2π\nthat appears in the inverse transform. Some authors, usually in physics texts, define the\nso-called unitary Fourier transform pair as\n1 Z inf\nX(jΩ) =\nx(t)e-jΩtdt\n√\n2π\n-inf\n1 Z inf\nx(t)\n=\nX(jΩ)ejΩtdΩ\n√\n2π\n-inf\nso as to distribute the constant symmetrically over the forward and inverse transforms.\nMany engineering texts address the issue of the asymmetry by defining the transform\nwith respect to frequency F = 2πΩ in Hz, instead of angular frequency Ω in radians/s.\nThe effect, through the change in the variable in the inverse transform, is to redefine the\ntransform pair as\nZ inf\nx(t)e-j2πFtdt\nX(F )\n=\n-inf\nZ inf\nj2πFtdF\nx(t)\n=\nX(F )e\n-inf\nSome authors also adopt the notation of dropping the j from the frequency domain repre\nsentation and write X(Ω) or X(F ) as above.\nEven more confusing is the fact that some authors (particularly in physics) adopt a\ndefinition that reverses the sign convention on the exponential terms in the Fourier integral,\nthat is they define\nZ inf\nX(jΩ) =\nx(t)ejΩtdt\n-infZ inf\nx(t)\n=\nX(jΩ)e-jΩtdΩ\n2π\n-inf\nThese various definitions of the transform pair mean that care must be taken to understand\nthe particular definition adopted by texts and software packages. Throughout this course\nwe will retain the definitions in Eqs. (??) and (??).\n1.2\nFourier Transform Examples\nExample 1\nFind the Fourier transform of the pulse function\nx(t) =\n1⁄2 a\n|t| < T/2\notherwise.\n4-2\n\nt\nT / 2\n- T / 2\na\nx ( t )\n- 3 0\n3 0\nX ( j W )\nW\na T\nT\nT\nT\n- 2 0\n- 1 0\nT\n1 0\nT\n2 0\nT\nF o u r i e r T r a n s f o r m\nSolution: From the definition of the forward Fourier transform\nZ inf\nX(jΩ) =\nx(t)e-jΩtdt\n(i)\n-inf\nZ T/2\n= a\ne-jΩtdt\n(ii)\n-T/2\n· j\n�T/2\n= a\ne-jΩt\n(iii)\nΩ\n-T/2\n= ja £\ne-jΩT/2 - ejΩT/2¤\n(iv)\nΩ\nsin(ΩT/2)\n= aT\n.\n(v)\nΩT/2\nThe Fourier transform of the rectangular pulse is a real function, of the form\n(sin x)/x centered around the jΩ = 0 axis. Because the function is real, it\nis sufficient to plot a single graph showing only X(jΩ) . Notice that while\n|\n|\nX(jΩ) is a generally decreasing function of Ω it never becomes identically zero,\nindicating that the rectangular pulse function contains frequency components at\nall frequencies.\nThe function (sin x)/x = 0 when the argument x = nπ for any integer n (n = 0).\nThe main peak or \"lobe\" of the spectrum X(jΩ) is therefore contained within\nthe frequency band defined by the first two zero-crossings ΩT/2 < π or Ω <\n|\n|\n| |\n2π/T . Thus as the pulse duration T is decreased, the spectral bandwidth of the\npulse increases, indicating that short duration pulses have a relatively larger high\nfrequency content.\n4-3\n\nx ( t )\nt\na\nt\na\nT\nT / 4\na T\na T / 4\nW\nX ( j W )\nF o u r i e r T r a n s f o r m\nF o u r i e r T r a n s f o r m\nT / 2\n- T / 2\nT / 8\n- T / 8\nx ( t )\nX ( j W )\nW\nExample 2\nFind the Fourier transform of the Dirac delta function δ(t).\nSolution: When substituted into the forward Fourier transform\nZ inf\nΔ(jΩ) =\nδ(t)e-jΩtdt\n-inf\n= 1\n(i)\nby the sifting property. The spectrum of the delta function is therefore constant\nover all frequencies. It is this property that makes the impulse a very useful test\ninput for linear systems.\nExample 3\nFind the Fourier transform of the causal real exponential function x(t) = us(t)e-at\n( for a > 0).\n4-4\n\n- 2 0 a\n- 1 0 a\n1 0 a\n2 0 a\n- 1 . 5\n- 1 . 0\n- 0 . 5\n1 . 5\n- 2 0 a\n- 1 0 a\n1 0 a\n2 0 a W\n| X ( j W ) |\nx ( t )\na t\n1 . 0\n0 . 5\nF o u r i e r T r a n s f o r m\n0 . 5\n1 . 0\ne\n- a t\n1 / a\nW\n| X ( j W ) |\nSolution: From the definition of the forward Fourier transform\nX(jΩ) =\nZ inf\ne-at e-jΩtdt\n· -1 e-(a+jΩ)t\n�inf\n=\na + jΩ\n�\n= a + jΩ\nwhich is complex, and in terms of a magnitude and phase function is\n|X(jΩ)| = √\na2 + Ω2\n(i)\n6 X(jΩ) = tan-1\nμ-\na\nΩ¶\n(ii)\nOther examples are given in the class handout.\n1.3\nProperties of the Fourier Transform\nThe properties of the Fourier transform are covered more fully in the class handout and are\nsimply summarized here:\n(1) Existence of the Fourier Transform The three Dirichlet conditions are\nsufficient conditions, but are not strictly necessary:\n- The function x(t) must be integrable in the absolute sense over all time,\nthat is\nZ inf\n|x(t)| dt < inf.\n-inf\n4-5\n\nThere must be at most a finite number of maxima and minima in the\n-\nfunction x(t). Notice that periodic functions are excluded by this and\nthe previous condition.\nThere must be at most a finite number of discontinuities in the function\n-\nx(t), and all such discontinuities must be finite in magnitude.\n(2) Linearity of the Fourier Transform If\ng(t)\nF\nG(jΩ) and h(t)\nF\nH(jΩ)\n⇐⇒\n⇐⇒\nthen for arbitrary constants a and b,\nag(t) + bh(t)\nF\naG(jΩ) + bH(jΩ).\n(3)\n⇐⇒\n(3) Duality\nX(jt)\nF\n2πx(-Ω)\n⇐⇒\nwhere X(jt) is X(jΩ) where Ω has been replaced by t, and x(-Ω) is x(t)\nwhere t is replaced by -Ω. Therefore if we know the Fourier transform of\none function, we also know it for another.\n(4) Even and Odd Functions\nThe Fourier transform of a real even function of time is a real even\n-\nfunction\n- The Fourier transform of an real odd function is an imaginary odd\nfunction.\nThe same relationships hold for the inverse Fourier transform.\n(5) Time Shifting\nThe Fourier transform of x(t + τ), a time shifted version\nof x(t), is\nF{x(t + τ)} = ejΩτ X(jΩ).\nand in terms of a magnitude and phase\nF{x(t + τ )} = |X(jΩ)| ej(6 X(jΩ)+Ωτ ).\n(4) Time Scaling\nx(at)\nF\n1 X (jΩ/a) ,\na = 0\n⇐⇒ |a|\n(9) Time Reversal If a = -1, the time scaling property gives\nx(-t)\nF\nX(-jΩ).\n(4)\n⇐⇒\n(5) Waveform Energy Parseval's theorem asserts the equivalence of the total\nwaveform energy in the time and frequency domains by the relationship\nZ inf\nZ inf\nZ inf\n|x(t)| dt = 2π\n|X(jΩ)| dΩ = 2π\nX(jΩ)X(jΩ)dΩ.\n-inf\n-inf\n-inf\nIn other words, the quantity X(jΩ) 2 is a measure of the energy of the\n|\n|\nfunction per unit bandwidth.\n4-6\n\n(6) The Fourier Transform of the Derivative of a Function\n1⁄2dx3⁄4\nF\ndt\n= jΩX(jΩ),\nThe Fourier transform of the nth derivative of x(t) is\n1⁄2dnx3⁄4\nF\ndtn\n= (jΩ)nX(jΩ)\n(5)\n(7) The Fourier Transform of the Integral of a Function\nt\n1⁄2Z\n3⁄4\nF\nx(ν)dν\n= πX(0)δ(jΩ) + jΩ X(jΩ)\n-inf\n(7) Time Reversal If a function x(t) has a Fourier transform X(jΩ) then\nF {x(-t)} = X(-jΩ).\n1.4\nExtension of the Fourier Transform to Functions for which the Fourier\nIntegral does not Converge.\nThe Dirichlet conditions are sufficient but not necessary conditions for the existence of\nthe Fourier transform. If the use of the Dirac delta function δ(x) is allowed, the Fourier\ntransform of many functions with a non-convergent Fourier integral may de defined. This\ntopic is covered in greater detail in the class handout (Sec. 4.4), and a simple example is\ngiven here\nExample 4\nDefine the Fourier transform of the unit-step (Heaviside) function us(t), where\n1⁄2 0\nt < 0\nus(t) =\nt ≥ 0.\nClearly the Fourier integral\nZ inf\nZ inf\nUs(jΩ) =\nus(t)ejΩtdt =\ne-jΩtdt\ninf\ndoes not converge, and we seek an alternative approach.\nConsider the one-sided real exponential function\nx(t) = us(t)e-at\n4-7\n\nas described in Example 3, and note that us(t) = lima\n0 x(t) which implies\n→\nUs(jΩ) = lima\n0 X(jΩ). From Example 3\n→\na\nΩ\nX(jΩ) = a + jΩ = a2 + Ω2 - j a2 + Ω2\nThe real part is in the form of a Cauchy distribution, and we note that for a > 0\nZ inf\na\ndΩ = π\na2 + Ω2\n-inf\nand that as a\n0, a/(a2 + Ω2) becomes impulse-like, Therefore, as a\n0,\n→\n→\na\nΩ\na2 + Ω2 → πδ(Ω) and\n- j a2 + Ω2 →-j Ω\nso that we may define the Fourier transform of the unit-step function as\nUs(jΩ) = πδ(Ω) + jΩ\nThe Frequency Response of a Linear System Defined Directly\nfrom the Fourier Transform\nThe system frequency response function H(jΩ) may be defined directly using the trans\nform property of derivatives. Consider a linear system described by the single input/output\ndifferential equation\ndny\ndn-1y\ndy\nan dtn + an-1 dtn-1 + . . . + a1 dt + a0y =\ndmu\ndm-1u\ndu\nbm\n+ . . . + b1\n+ b0u\ndtm + bm-1 dtm-1\ndt\nand assume that the Fourier transforms of both the input u(t) and the output y(t) exist.\nThen the Fourier transform of both sides of the differential equation may be found by using\nthe derivative property:\n1⁄2dnf 3⁄4\nF\ndtn\n= (jΩ)nF (jΩ)\nto give\n(c)\nan(jΩ)n + an-1(jΩ)n-1 + . . . + a1(jΩ) + a0\na\nY (jΩ) =\n(c)\nbm(jΩ)m + bm-1(jΩ)m-1 + . . . + b1(jΩ) + b0\na\nU(jΩ),\nwhich has reduced the original differential equation to an algebraic equation in jΩ. This\nequation may be rewritten explicitly in terms of Y (jΩ) in terms of the frequency response\nH(jΩ)\nbm(jΩ)m + bm-1(jΩ)m-1 + . . . + b1(jΩ) + b0\nY (jΩ) =\nU(jΩ)\nan(jΩ)n + an-1(jΩ)n-1 + . . . + a1(jΩ) + a0\n= H(jΩ)U(jΩ),\nshowing the multiplicative frequency domain relationship between input and output.\n4-8\n\nF r e q u e n c y R e s p o n s e\nu ( t )\nY ( j W\n) = U ( j W\n) H ( j W\n)\ny ( t )\nt i m\ne d o m\na i n\nF o u r i e r d o m\na i n\nF\n- 1\nm\nu l t i p l i c a t i o n\nF\nU ( j W\n)\nH ( j W )\nc o n v o l u t i o n\nRelationship between the Frequency Response and the Impulse\nResponse\nThe Dirac delta function δ(t) has a unique property; its Fourier transform is unity for all\nfrequencies\nF {δ(t)} = 1,\nThe impulse response of a system h(t) is defined to be the response to an input u(t) = δ(t),\nthe output spectrum is then Yδ(jΩ) = F {h(t)},\nY (jΩ) = F {δ(t)} H(jΩ)\n= H(jΩ).\nor\nh(t) = F-1 {H(jΩ)} .\nIn other words, the system impulse response h(t) and its frequency response H(jΩ) are a\nFourier transform pair:\nh(t)\nF\nH(jΩ).\n⇐⇒\nIn the same sense that H(jΩ) completely characterizes a linear system in the frequency\nresponse, the impulse response provides a complete system characterization in the time\ndomain.\nThe Convolution Property\nA system with an impulse response h(t), driven by an input u(t), responds with an output\ny(t) given by the convolution integral\ny(t) = h(t) ⊗ u(t)\nZ inf\n=\nu(τ)h(t - τ )dτ\n-inf\nIn the frequency domain the input/output relationship for a linear system is multiplicative,\nthat is Y (jΩ) = U(jΩ)H(jΩ). Because by definition\ny(t)\nF\nY (jΩ),\n⇐⇒\n4-9\n\nwe are lead to the conclusion that\nh(t) ⊗ u(t)\nF\nH(jΩ)U(jΩ).\n(6)\n⇐⇒\nThe computationally intensive operation of computing the convolution integral has been\nreplaced by the operation of multiplication. This result, known as the convolution property\nof the Fourier transform, can be shown to be true for the product of any two spectra, for\nexample F (jΩ) and G(jΩ)\nZ inf\nZ inf\nF (jΩ)G(jΩ) =\nf(ν)e-jΩν dν.\ng(τ)e-jΩτ dτ\n-inf\n-inf\nZ inf Z inf\n=\nf(ν)g(τ )e-jΩ(ν+τ)dτdν,\n-inf\n-inf\nand with the substitution t = ν + τ\nZ inf 1⁄2Z inf\n3⁄4\nF (jΩ)G(jΩ) =\nf(t - τ)g(τ)dτ\ne-jΩtdt\n-inf\n-inf\nZ inf\n=\n(f(t) ⊗ g(t)) e-jΩtdt\n-inf\n= F {f(t) ⊗ g(t)} .\nA dual property holds: if any two functions, f(t) and g(t), are multiplied together in the\ntime domain, then the Fourier transform of their product is a convolution of their spectra.\nThe dual convolution/multiplication properties are\nf(t) ⊗ g(t)\nF\nF (jΩ)G(jΩ)\n(7)\n⇐⇒\nf(t)g(t)\nF\nF (jΩ) ⊗ G(jΩ).\n(8)\n⇐⇒ 2π\n4-10"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/aa46a1127460310c7506654176a72ec0_lecture_05.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\n°\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 51\nReading:\n-\nClass handout: The Laplace Transform.\n-\nClass handout: Understanding Poles and Zeros.\n-\nClass handout: Sinusoidal Frequency Response of Linear Systems.\nThe One-Sided Laplace Transform\nConsider a causal waveform x(t), such as the unit-step function us(t), for which the Fourier\nintegral\nZ inf\nx(t)e-jΩtdt =\nZ inf\nx(t)e-jΩtdt\n-inf\n0-\ndoes not converge. Clearly, for us(t), the Fourier integral\nZ inf\nUs(jΩ) =\n1.e-jΩtdt\n0-\ndoes not converge.\nNow consider a modified function xÞ(t) = x(t)w(t) where w(t) is a weighting function with\nthe property limt→inf w(t) = 0, chosen to ensure convergence, so that\nZ inf\nXÞ(jΩ, w) =\nx(t)w(t)e-jΩtdt\n0-\nmay be considered an approximation to X(jΩ).\nIn particular, consider w(t) = e-σt for real σ, and note that as σ\n0, x(t)w(t)\nx(t),\n→\n→\nso that the Fourier transform is\nF\n(c)\nx(t)e-σta\n= X(jΩ, σ) =\nZ inf\nx(t)e-σt e-jΩtdt =\nZ inf\nx(t)e-(σ+jΩ)tdt.\n0-\n0-\nIf we define a complex variable s = σ + jΩ we can write\nZ inf\nx(t)e-stdt\nL {x(t)} = X(s) =\n0-\nwhich defines the one-sided Laplace transform. (See the handout for the definition of the\ntwo-sided transform).\n1copyright c D.Rowell 2008\n5-1\n\nThe Laplace transform may be considered as an extension of the Fourier transform\n(for causal functions) that includes an exponential weighting term to extend the range\nof functions for which the integral converges.\nNote that for causal waveforms\nX(jΩ) = X(s)|s=jΩ\nand if x(t) is non-causal\nX(jΩ)\nX(s)|\n=\ns=jΩ ,\nfor example F {sin(Ω0t)}\nL {sin(Ω0t) }|\n=\ns=jΩ, since the Laplace transform assumes x(t) ≡0\nfor t < 0- .\n\nExample 1\nThe following are some simple examples of Laplace transforms:\ninf\nL {us(t) } =\n1.e -stdt =\n0-\ns\ninf\nL {δ(t) } =\nδ(t)e -stdt = 1\n0-\n\ninf\nL e -at\n=\ne -(s+a)tdt =\n0-\ns + a\n1.1\nThe Derivative Property of the Laplace Transform:\nIf a function x(t) has a Laplace transform X(s), the Laplace transform of the derivative of\nx(t) is\ndx\nL\n= sX(s) -x(0).\ndt\nUsing integration by parts\ndx\ninf dx\nL\n=\ne -stdt\ndt\n0- dt\ninf\n= x(t)e -st inf\n0- +\nsx(t)e -stdt\n0-\n= sX(s) -x(0).\n5-2\n\nThis procedure may be repeated to find the Laplace transform of higher order derivatives,\nfor example the Laplace transform of the second derivative is\nd2x\ndx\nL\n= s [sL {x(t)} -x(0)] -\ndt2\ndt t=0\ndx\n= s 2X(s) -sx(0) - dt t=0\nwhich may be generalized to\n\nn\n\nL dnx\n= s nX(s) -\n\ns n-i\ndi-1x\ndtn\ndti-1\ni=1\nt=0\nfor the n derivative of x(t).\nThe Transfer Function\nThe use of the derivative property of the Laplace transform generates a direct algebraic\nsolution method for determining the response of a system described by a linear input/output\ndifferential equation. Consider an nth order linear system, completely relaxed at time t = 0,\nand described by\ndny\ndn-1y\ndy\nan\n+ an-1\n+ . . . + a1\n+ a0y =\ndtn\ndtn-1\ndt\ndmu\ndm-1u\ndu\nbm\n+ bm-1\n+ . . . + b1\n+ b0u.\ndtm\ndtm-1\ndt\nIn addition assume that the input function u(t), and all of its derivatives are zero at time\nt = 0, and that any discontinuities occur at time t = 0+ . Under these conditions the Laplace\ntransforms of the derivatives of both the input and output simplify to\ndny\ndnu\nL\n= s nY (s),\nand L\n= s nU(s)\ndtn\ndtn\nso that if the Laplace transform of both sides is taken\nans n + an-1s n-1 + . . . + a1s + a0 Y (s) =\nbms m + bm-1s m-1 + . . . + b1s + b0 U(s)\nwhich has had the effect of reducing the original differential equation into an algebraic\nequation in the complex variable s. This equation may be rewritten to define the Laplace\ntransform of the output:\nbmsm + bm-1sm-1 + . . . + b1s + b0\nY (s)\n=\n\nU(s)\nansn + an-1sn-1 + . . . + a1s + a0\n= H(s)U(s)\n5-3\n\nThe Laplace transform generalizes the definition of the transfer function to a complete in\nput/output description of the system for any input u(t) that has a Laplace transform.\nThe system response y(t) = L-1 {Y (s)} may be found by decomposing the expression for\nY (s) = U(s)H(s) into a sum of recognizable components using the method of partial fractions\nas described above, and using tables of Laplace transform pairs to find the component\ntime domain responses. To summarize, the Laplace transform method for determining the\nresponse of a system to an input u(t) consists of the following steps:\n(1) If the transfer function is not available it may be computed by taking the\nLaplace transform of the differential equation and solving the resulting al\ngebraic equation for Y (s).\n(2) Take the Laplace transform of the input.\n(3) Form the product Y (s) = H(s)U(s).\n(4) Find y(t) by using the method of partial fractions to compute the inverse\nLaplace transform of Y (s).\n\nExample 2\nDetermine the transfer function of the first-order RC filter:\n\nThe differential equation relating vo(t) to vin(t) is\ndv0\nRC\n+ vo = vin(t)\ndt\nand taking the Laplace transform of both sides gives\n(RCs + 1)Vo(s) = Vin(s)\nfrom which\nVo(s)\nH(s) =\n=\nVin(s)\nRCs + 1\n5-4\n\n2.1\nThe Transfer function and the Sinusoidal Frequency Response\nWe have seen that\nbmsm + bm-1sm-1 + . . . + b1s + b0\nH(s) = ansn + an-1sn-1 + . . . + a1s + a0\nand\nbm(jΩ)m + bm-1(jΩ)m-1 + . . . + b1(jΩ) + b0\nH(jΩ) = an(jΩ)n + an-1(jΩ)n-1 + . . . + a1(jΩ) + a0\nso that\nH(jΩ) = H(s)|s=jΩ\nPoles and Zeros of the Transfer Function\nThe transfer function provides a basis for determining important system response character\nistics without solving the complete differential equation. As defined, the transfer function is\na rational function in the complex variable s = σ + jΩ, that is\nbmsm + bm-1sm-1 + . . . + b1s + b0\nH(s) = ansn + an-1sn-1 + . . . + a1s + a0\nIt is often convenient to factor the polynomials in the numerator and denominator, and to\nwrite the transfer function in terms of those factors:\nN(s)\n(s - z1)(s - z2) . . . (s - zm-1)(s - zm)\nH(s) =\n= K\n,\nD(s)\n(s - p1)(s - p2) . . . (s - pn-1)(s - pn)\nwhere the numerator and denominator polynomials, N(s) and D(s), have real coefficients\ndefined by the system's differential equation and K = bm/an. The zi's are the roots of the\nequation\nN(s) = 0,\nand are defined to be the system zeros, and the pi's are the roots of the equation\nD(s) = 0,\nand are defined to be the system poles. Clearly when s = zi the numerator N(s) = 0 and\nthe transfer function vanishes, that is\nlim H(s) = 0.\ns→zi\nand similarly when s = pi the denominator polynomial D(s) = 0 and the value of the transfer\nfunction becomes unbounded,\nlim H(s) = inf.\ns→pi\nAll of the coefficients of polynomials N(s) and D(s) are real, therefore the poles and zeros\nmust be either purely real, or appear in complex conjugate pairs. In general for the poles,\neither pi = σi, or else pi, pi+1 = σi ± jΩi. The existence of a single complex pole without a\ncorresponding conjugate pole would generate complex coefficients in the polynomial D(s).\nSimilarly, the system zeros are either real or appear in complex conjugate pairs.\n5-5\n\n3.1\nThe Pole-Zero Plot\nA system is characterized by its poles and zeros in the sense that they allow reconstruction of\nthe input/output differential equation. In general, the poles and zeros of a transfer function\nmay be complex, and the system dynamics may be represented graphically by plotting their\nlocations on the complex s-plane, whose axes represent the real and imaginary parts of the\ncomplex variable s. Such plots are known as pole-zero plots. It is usual to mark a zero\nlocation by a circle (*) and a pole location a cross (×). The location of the poles and zeros\nprovide qualitative insights into the response characteristics of a system. Many computer\nprograms are available to determine the poles and zeros of a system. The figure below is an\nexample of a pole-zero plot for a third-order system with a single real zero, a real pole and\na complex conjugate pole pair, that is;\n(3s + 6)\n(s - (-2))\nH(s) =\n= 3\n(s3 + 3s2 + 7s + 5)\n(s - (-1))(s - (-1 - 2j))(s - (-1 + 2j))\n\nNote that the pole-zero plot characterizes the system, except for the overall gain constant\nK.\nFrequency Response and the Pole-Zero Plot\nThe frequency response may be written in terms of the system poles and zeros by substituting\ndirectly into the factored form of the transfer function:\n(jΩ - z1)(jΩ - z2) . . . (jΩ - zm-1)(jΩ - zm)\nH(jΩ) = K\n.\n(jΩ - p1)(jΩ - p2) . . . (jΩ - pn-1)(jΩ - pn)\nBecause the frequency response is the transfer function evaluated on the imaginary axis of\nthe s-plane, that is when s = jΩ, the graphical method for evaluating the transfer function\nmay be applied directly to the frequency response. Each of the vectors from the n system\npoles to a test point s = jΩ has a magnitude and an angle:\n|jΩ - pi| =\nσ2 + (Ω - Ωi)2 ,\ni\n(s - pi) = tan-1\nΩ - Ωi\n,\n-σi\n5-6\n\nas shown above, with similar expressions for the vectors from the m zeros. The magnitude\nand phase angle of the complete frequency response may then be written in terms of the\nmagnitudes and angles of these component vectors\nm |(jΩ - zi)|\n|H(jΩ)| = K i=1\n|(jΩ - pi)|\nn\ni=1\nm\nn\nH(jΩ) =\n(jΩ - zi) -\n(jΩ - pi).\ni=1\ni=1\nIf the vector from the pole pi to the point s = jΩ has length qi and an angle θi from the\nhorizontal, and the vector from the zero zi to the point jΩ has a length ri and an angle φi,\nthe value of the frequency response at the point jΩ is\nr1 . . . rm\n|H(jΩ)| = K\n(1)\nq1 . . . qn\nH(jΩ)\n=\n(φ1 + . . . + φm) - (θ1 + . . . + θn)\n(2)\nThe graphical method can be very useful for deriving a qualitative picture of a system\nfrequency response. For example, consider the sinusoidal response of a first-order system\nwith a pole on the real axis at s = -1/τ as shown below. Even though the gain constant\nK cannot be determined from the pole-zero plot, the following observations may be made\ndirectly by noting the behavior of the magnitude and angle of the vector from the pole to\nthe imaginary axis as the input frequency is varied:\n\n5-7\n\n!\n\n1. At low frequencies the gain approaches a finite value, and the phase angle has a small\nbut finite lag.\n2. As the input frequency is increased the gain decreases (because the length of the vector\nincreases), and the phase lag also increases (the angle of the vector becomes larger).\n3. At very high input frequencies the gain approaches zero, and the phase angle ap\nproaches π/2.\nAs a second example consider a second-order system, with the damping ratio chosen so that\nthe pair of complex conjugate poles are located close to the imaginary axis as shown below.\nIn this case there are a pair of vectors connecting the two poles to the imaginary axis, and\nthe following conclusions may be drawn by noting how the lengths and angles of the vectors\nchange as the test frequency moves up the imaginary axis:\n\n1. At low frequencies there is a finite (but undetermined) gain and a small but finite\nphase lag associated with the system.\n2. As the input frequency is increased and the test point on the imaginary axis approaches\nthe pole, one of the vectors (associated with the pole in the second quadrant) decreases\nin length and at some point reaches a minimum. There is an increase in the value of\nthe magnitude function over a range of frequencies close to the pole.\n3. At very high frequencies, the lengths of both vectors tend to infinity, and the magnitude\nof the frequency response tends to zero, while the phase approaches an angle of π\nradians because the angle of each vector approaches π/2.\nThe following generalizations may be made about the sinusoidal frequency response of a\nlinear system, based upon the geometric interpretation of the pole-zero plot:\n1. If a system has an excess of poles over the number of zeros (n > m) the magnitude\nof the frequency response tends to zero as the frequency becomes large. Similarly,\nif a system has an excess of zeros (n < m) the gain increases without bound as the\n5-8\n\nfrequency of the input increases. (This cannot happen in physical energetic systems\nbecause it implies an infinite power gain through the system.) If n = m the system\ngain becomes constant at high frequencies.\n2. If a system has a pair of complex conjugate poles close to the imaginary axis, the\nmagnitude of the frequency response has a \"peak\", or resonance, at frequencies in the\nproximity of the pole. If the pole pair lies directly upon the imaginary axis, the system\nexhibits an infinite gain at that frequency.\n3. If a system has a pair of complex conjugate zeros close to the imaginary axis, the\nfrequency response has a \"dip\" or \"notch\" in its magnitude function at frequencies in\nthe vicinity of the zero. Should the pair of zeros lie directly upon the imaginary axis,\nthe response is identically zero at the frequency of the zero, and the system does not\nrespond at all to sinusoidal excitation at that frequency.\n4. A pole at the origin of the s-plane (corresponding to a pure integration term in the\ntransfer function) implies an infinite gain at zero frequency.\n5. Similarly a zero at the origin of the s-plane (corresponding to a pure differentiation)\nimplies a zero gain for the system at zero frequency.\n5-9"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 6",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/c4037fd4a6f244c39a4c4a348f91aaed_lecture_06.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 61\nReading:\n-\nClass handout: Sinusoidal Frequency Response of Linear Systems (Sec. 7).\n-\nClass handout: Sinusoidal Frequency Response of Linear Systems (Sec. 6.1).\n-\nClass handout: Introduction to Continuous Time Filter Design.\nPoles and Zeros of Filter Classes\nWe can use the s-plane relationship between a filter's poles and zeros and the frequency\nresponse function to make some general comments about the desgn of various classes of\nfilters:\n(a) Low-Pass Filters:\n- To ensure a high-frequency roll-off the number of poles must exceed the number\nof zeros, ie n > m. (In many low-pass filters m = 0.)\n- To ensure a finite low frequency gain there can be no poles or zeros at the origin.\n\n(b) High-Pass Filters\n- To ensure a constant high-frequency gain the number of poles must equal the\nnumber of zeros, ie n = m.\n- To ensure a low frequency gain that approaches zero, there must be one or more\nzeros at the origin.\n1copyright ⃝c\nD.Rowell 2008\n6-1\n\n(c) Band-Pass Filters\n- To ensure a high-frequency roll-off the number of poles must exceed the number\nof zeros, ie n > m.\n- To ensure a low frequency gain that approaches zero, there must be one or more\nzeros at the origin.\n- The band-pass characteristic is shaped by a group of poles clustered near the\nimaginary axis in the region of the passband,\n\n(d) Band-Stop Filters\n- To ensure a constant high-frequency gain the number of poles must equal the\nnumber of zeros, ie n = m.\n- To ensure a finite low frequency gain there can be no poles or zeros at the origin.\n- The band-reject characteristic is shaped by a group of zeros clustered on or near\nthe imaginary axis in the region of the stopband,\n6-2\n\nThe Decibel\nFilter frequency response magnitudes |H(jΩ)| are frequently plotted using the decibel log\narithmic scale. The Bel, named after Alexander Graham Bell, is defined as the logarithm\nto base 10 of the ratio of two power levels. In practice the Bel is too large a unit, and the\ndecibel (abbreviated dB), defined to be one tenth of a Bel, has become the standard unit of\nlogarithmic power ratio. The power flow P into any element in a system, may be expressed\nin terms of a logarithmic ratio Q to a reference power level Pref :\nP\nP\nQ = log10\nBel or Q = 10 log10\ndB.\n(1)\nPref\nPref\nBecause the power dissipated in a D-type element is proportional to the square of the\namplitude of a system variable applied to it, when the ratio of across or through variables is\ncomputed the definition becomes\n\nA\nA\nQ = 10 log10\n= 20 log10\ndB.\n(2)\nAref\nAref\nwhere A and Aref are amplitudes of variables. 2 Table ?? expresses some commonly used\ndecibel values in terms of the power and amplitude ratios.\nThe magnitude of the frequency response function |H (jΩ)| is defined as the ratio of the\namplitude of a sinusoidal output variable to the amplitude of a sinusoidal input variable.\nThis ratio is expressed in decibels, that is\n|Y (jΩ)|\n20 log10 |H(jΩ)| = 20 log10 |U(jΩ)| dB.\nAs noted this usage is not strictly correct because the frequency response function does not\ndefine a power ratio, and the decibel is a dimensionless unit whereas |H (jΩ)| may have\nphysical units.\n2This definition is only strictly correct when the two amplitude quantities are measured across a common\nD-type (dissipative) element. Through common usage, however, the decibel has been effectively redefined\nto be simply a convenient logarithmic measure of amplitude ratio of any two variables. This practice is\nwidespread in texts and references on system dynamics and control system theory. In this book we have also\nadopted this convention.\n6-3\n\nDecibels\nPower Ratio Amplitude Ratio\n-40\n0.0001\n0.01\n-20\n0.01\n0.1\n-10\n0.1\n0.3162\n-6\n0.25\n0.5\n-3\n0.5\n0.7071\n1.0\n1.0\n2.0\n1.414\n4.0\n2.0\n10.0\n3.162\n100.0\n10.0\n10000.0\n100.0\nTable 1: Common Decibel quantities and their corresponding power and amplitude ratios.\nLow-Pass Filter Design\nThe prototype low-pass filter is based upon the magnitude-squared of the frequency response\nfunction |H(jΩ)|2, or the frequency response power function. The phase response of the filter\nis not considered. We begin by defining tolerance regions on the power frequency response\nplot, as shown below:.\n\nThe filter specifications are that\n1 ≥|H(jΩ)|2 >\nfor |Ω| < Ωc\n1 + ε2\nand\n|H(jΩ)|2 <\nfor |Ω| > Ωr,\n1 + λ2\nwhere Ωc is the cut-off frequency, Ωr is the rejection frequency, and ε and λ are design\nparameters that select the filter attenuation at the two critical frequencies. For example, if\n6-4\n\nε = 1, at Ωc the power response response |H(jΩc)|2 = 0.5, the -3 dB response frequency.\nIn general we expect the response function to be monotonically decreasing in the transition\nband.\nThe filter functions examined in this document will be of the form\n|H(jΩ)|2 = 1 + f 2(Ω) .\n(3)\nwhere f(Ω) →0 as Ω →0, and f(Ω) →infas Ω →infto generate a low-pass filter action.\n3.1\nThe Butterworth Filter\nThe Butterworth filter is defined by the power gain\n|H(jΩ)|2 =\n1 + ε2 (Ω/Ωc)2N\nwhere N is a positive integer defining the filter order. Note that λ does not appear in this\nformulation, but clearly N and λ are interrelated, since at Ω = Ωr\n≥\n1 + λ2\n1 + ε2 (Ωr/Ωc)2N\nwhich may be solved to show\nlog(λ/ε)\nN ≥ log(Ωr/Ωc)\nendequation\nThe power response function of Butterworth filters for N = 1 . . . 5 is shown below:\n0.5\n1.5\n2.5\n3.5\n4.5\nNormalized frequency\nω/ω c\nButterworth filters are also known as \"maximally flat\" filters because the response has the\nmaximum number of vanishing derivatives at Ω = 0 and Ω = inffor filters of the form of Eq.\n1.\n6-5\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nPower response\nN=1\nN=5\nN increasing\n|H(j )| 2\nω\n\n3.1.1\nThe Butterworth Filter Transfer Function\nThe poles of the power gain transfer function may be found by substituting s = jΩ in the\ncharacteristic equation:\n\n2N\n1 + ε2\ns\n= 0\njΩc\nand solving for S, which yields 2N roots pv (n = 1 . . . 2N) that lie on a circle with radius\nr = Ωcε-1/N , and angular separation of π/N rad:\npn = Ωcε-1/N ejπ(2n+N -1)/2N\nn = 1 . . . 2N\nNotice that if N is odd a pair of poles will lie on the real axis at s = ±Ωcε-1/N , while if N\nis even the roots will form complex conjugate pairs.\nThe six poles of |H(s)|2 for a third-order (N = 3) Butterworth filter are shown in (a)\nbelow:\n\nFor a stable causal system we must have\n|H(jΩ)|2 = H(jΩ)H(jΩ) = H(s)H(-s)|s=jΩ\nwith all poles in the left-half-plane, which allows us to take take the N poles of |H(jΩ)|2 in\nthe left half-plane as the poles of the filter H(s), that is the poles specified by (n = 1 . . . N)\nin Eq. (8) above,\npn = Ωcε-1/N ejπ(2n+N -1)/2N\nn = 1 . . . N\n(4)\nas is shown in (b) above.\nIf the filter is to have unity gain at low frequencies\nlim |H(jΩ)| = 1\nΩ→0\nwe require the complete Butterworth transfer function to be\n(-p1)(-p2) . . . (-pN )\nH(s)\n=\n(s - p1)(s - p2) . . . (s - pN )\n(-1)N p1p2 . . . pN\n=\n,\n(s - p1)(s - p2) . . . (s - pN )\nwhere only the N stable left-half-plane poles (Eq. 4) are included.\n6-6\n\nDesign Procedure:\n1. Determine the filter order\nlog (λ/2)\nN ≥ log (Ωr/Ωc)\n2. Determine the Butterworth radius\nr = Ωc2-1/N\n3. Determine The Butterworth angles\n2n + N - 1\nθn = π\nn = 1 . . . 2N\n2N\n4. Determine the N left half-plane poles\npn = rejθn\nn = 1, . . . , N\n5. Form the transfer function\n-p1p2 . . . pN\nH(s) = (s - p1)(s - p2) . . . (s - pN )\n6-7"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 7",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/4dc3c856841a896bbcb8726c3dd4b41b_lecture_07.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 71\nReading:\n-\nClass handout: Introduction to Continuous Time Filter Design.\nButterworth Filter Design Example\n(Same problem as in the Class Handout). Design a Butterworth low-pass filter to meet the\npower gain specifications shown below:\n\nAt the two critical frequencies\n= 0.9 -→ ε = 0.3333\n1 + ε2\n= 0.05 -→ λ = 4.358\n1 + λ2\nThen\nlog(λ/ε)\nN ≥\n= 3.70\nlog(Ωr/Ωc)\n1copyright ⃝c\nD.Rowell 2008\n7-1\n\nwe therefore select N=4. The 4 poles (p1 . . . p4) lie on a circle of radius r = Ωcε-1/N = 13.16\nand are given by\n|pn| =\n13.16\npn = π(2n + 3)/8\nfor n = 1 . . . 4, giving a pair of complex conjugate pole pairs\np1,4 = -5.04 ± j12.16\np2,3 = -12.16 ± j5.04\nThe transfer function, normalized to unity gain, is\nH(s) = (s2 + 10.07s + 173.2)(s2 + 24.32s + 173.2)\nand the filter Bode plots are shown below.\nBode Diagram\n-1\nFrequency (rad/sec)\nChebyshev Filters\nThe order of a filter required to met a low-pass specification may often be reduced by relaxing\nthe requirement of a monotonically decreasing power gain with frequency, and allowing\n-150\n-100\n-50\nMagnitude (dB)\n-360\n-270\n-180\n-90\nPhase (deg)\n7-2\n\n\"ripple\" to occur in either the pass-band or the stop-band. The Chebyshev filters allow\nthese conditions:\nType 1\n|H(jΩ)| 2 = 1 + 22TN\n2 (Ω/Ωc)\n(1)\nType 2\n|H(jΩ)| 2 = 1 + 22 (TN\n2 (Ωr/Ωc)/TN\n2 (Ωr/Ω))\n(2)\nWhere TN (x) is the Chebyshev polynomial of degree N. Note the similarity of the form\nof the Type 1 power gain (Eq. (1)) to that of the Butterworth filter, where the function\nTN (Ω/Ωc) has replaced (Ω/Ωc)N . The Type 1 filter produces an all-pole design with slightly\ndifferent pole placement from the Butterworth filters, allowing resonant peaks in the pass\nband to introduce ripple, while the Type 2 filter introduces a set of zeros on the imaginary\naxis above Ωr, causing a ripple in the stop-band.\nThe Chebyshev polynomials are defined recursively as follows\nT0(x) =\nT1(x) = x\nT2(x) =\n2x 2 - 1\nT3(x) =\n4x 3 - 3x\n. . .\nTN (x)\n=\n2xTN-1(x) - TN-2(x),\nN > 1\n(3)\nwith alternate definitions\nTN (x) = cos(N cos-1(x))\n(4)\n= cosh(N cosh-1(x))\n(5)\nThe Chebyshev polynomials have the min-max property:\nOf all polynomials of degree N with leading coefficient equal to one, the polynomial\nTN (x)/2N-1\nhas the smallest magnitude in the interval x\nThis \"minimum maximum\"\namplitude is 21-N .\n| | ≤ 1.\nIn low-pass filters given by Eqs. (13) and (14), this property translates to the following\ncharacteristics:\nFilter\nPass-Band Characteristic\nStop-Band Characteristic\nButterworth\nMaximally flat\nMaximally flat\nChebyshev Type 1 Ripple between 1 and 1/(1 + 22) Maximally flat\nChebyshev Type 2 Maximally flat\nRipple between 1 and 1/(1 + λ2)\n7-3\n\n2.1\nThe Chebyshev Type 1 Filter\nWith the power response from Eq. (13)\n|H(jΩ)| 2 = 1 + 22TN\n2 (Ω/Ωc)\nand the filter specification from Fig. 1, the required filter order may be found as follows. At\nthe edge of the stop-band Ω = Ωr\n|H(jΩr| = 1 + 22TN\n2 (Ωr/Ωc) ≤ 1 + λ2\nso that\nλ ≤ 2TN (Ωr/Ωc) = 2 cosh\n¡\nN cosh-1 (Ωr/Ωc)\n¢\nand solving for N\ncosh-1 (λ/2)\nN ≥ cosh-1 (Ωr/Ωc)\n(6)\nThe characteristic equation of the power transfer function is\n1 + 22TN\nμ\njΩ\ns ¶\n= 0 or TN\nμ\njΩ\ns ¶\n= ± j\nc\nc\nNow TN (x) = cos(N cos-1(x)), so that\nμ\nμ s ¶¶\nj\ncos N cos-1\n= ±\n(7)\njΩc\nIf we write cos-1 (s/jΩc) = γ + jα, then\ns =\nΩc (j cos (γ + jα))\n=\nΩc (sinh α sin γ + j cosh α cos γ)\n(8)\nwhich defines an ellipse of width 2Ωc sinh(α) and height 2Ωc cosh(α) in the s-plane. The\npoles will lie on this ellipse. Substituting into Eq. (16)\nμ s ¶\nTN\n= cos (N (γ + jα))\njΩc\n= cos Nγ cosh Nα - j sin Nγ sinh Nα,\nthe characteristic equation becomes\nj\ncos Nγ cosh Nα - j sin Nγ sinh Nα = ± .\n(9)\nEquating the real and imaginary parts in Eq. (21), (1) since cosh x = 0 for real x we require\ncos Nγ = 0, or\nγn = (2n - 1)π\nn = 1, . . . , 2N\n(10)\n2N\n7-4\n\nand, (2) since at these values of γ, sin Nγ = ±1 we have\nα = ±N sinh-1\n(11)\nAs in the Butterworth design procedure, we select the left half-plane poles as the poles of\nthe filter frequency response.\nDesign Procedure:\n1. Determine the filter order\ncosh-1 (λ/2)\nN ≥ cosh-1 (Ωr/Ωc)\n2. Determine α\nα = ±N\n1 sinh-1 1\n3. Determine γn, n = 1 . . . N\n(2n - 1)π\nγn =\nn = 1, . . . , N\n2N\n4. Determine the N left half-plane poles\npn = Ωc (sinh α sin γn + j cosh α cos γn)\nn = 1, . . . , N\n5. Form the transfer function\n(a) If N is odd\n-p1p2 . . . pN\nH(s) = (s - p1)(s - p2) . . . (s - pN )\n(b) If N is even\np1p2 . . . pN\nH(s) = 1 + 22 (s - p1)(s - p2) . . . (s - pN )\nThe difference in the gain constants in the two cases arises because of\nthe ripple in the pass-band. When N is odd, the response H(j0) = 1,\n|\n|\nwhereas if N is even the value of H(j0) = 1/(1 + 22).\n|\n|\n7-5\n\nExample 1\nRepeat the previous Butterworth design example using a Chebyshev Type 1\ndesign.\nFrom the previous example we have Ωc = 10 rad/s., Ωr = 20 rad/s., 2 = 0.3333,\nλ = 4.358. The required order is\ncosh-1 (λ/2)\ncosh-1 13.07\nN ≥ cosh-1 (Ωr/Ωc) =\ncosh-1 2\n= 2.47\nTherefore take N = 3. Determine α:\nμ1¶\nα =\nsinh-1\n=\nsinh-1(3) = 0.6061\nN\nand sinh α = 0.6438, and cosh α = 1.189. Also, γn = (2n - 1)π/6 for n = 1 . . . 6\nas follows:\nn:\nγn:\nπ/6\nπ/2\n5π/6\n7π/6\n3π/2 11π/6\nsin γn:\n1/2\n1/2\n-1/2\n-1\n-1/2\ncos γn:\n√\n3/2\n-\n√\n3/2 -\n√\n3/2\n√\n3/2\nThen the poles are\npn =\nΩc (sinh α sin γn + j cosh α cos γn)\nA\n√\n!\np1 =\n10 0.6438\n+ j1.189\n= 3.219 + j10.30\n× 2\n× 2\np2 = 10 (0.6438 × 1 + j1.189 × 0) = 6.438\nA\n√\n!\np3 =\n10 0.6438\n2 - j1.189\n= 3.219 - j10.30\n×\n× 2\nA\n√\n!\np4 = 10 -0.6438\n2 - j1.189\n= -3.219 - j10.30\n×\n× 2\np5 = 10 (-0.6438 × 0 - j1.189 × 0) = -6.438\nA\n√\n!\np6 = 10 -0.6438\n+ j1.189\n= -3.219 + j10.30\n× 2\n× 2\nand the gain adjusted transfer function of the resulting Type 1 filter is\nH(s) = (s2 + 6.438s + 116.5)(s + 6.438)\nThe pole-zero plot for the Chebyshev Type 1 filter is shown below.\n7-6\n\nX\nX\nX\n- 6 . 4 3 8\ns\ns - p l a n e\nj 1 0 . 3 0\n- 3 . 2 1 9\n- j 1 0 . 3 0\nj W\n2.2\nThe Chebyshev Type 2 Filter\nThe Chebyshev Type 2 filter has a monotonically decreasing magnitude function in the pass\nband, but introduces equi-amplitude ripple in the stop-band by the inclusion of system zeros\non the imaginary axis. The Type 2 filter is defined by the power gain function:\n|H(jΩ)| 2 =\nN\n1 + 22 T 2 (Ωr/Ωc)\nT 2 (Ωr/Ω)\nN\n(12)\nIf we make the substitutions\nΩrΩc\nν =\nand 2ˆ =\nΩ\n2TN (Ωr/Ωc)\nEq. 24 may be written in terms of the modified frequency ν\nH(jν) 2 =\nˆ22TN\n2 (ν/Ωc)\n|\n|\n1 + ˆ22TN\n2 (ν/Ωc)\n(13)\nwhich has a denominator similar to the Type 1 filter, but has a numerator that contains a\nChebyshev polynomial, and is of order 2N. We can use a method similar to that used in the\nType 1 filter design to find the poles as follows:\n1. First define a complex variable, say τ = μ + jν (analogous to the Laplace variable\ns = σ + jΩ used in the type 1 design) and write the power transfer function:\n22TN\n|H(τ)| 2 = 1 + ˆ22TN\n2 (τ/jΩc)\nˆ\n2 (τ/jΩc)\n7-7\n\n2 =\n=\nThe poles are found using the method developed for the Type 1 filter, the zeros are\nfound as the roots of the polynomial TN (τ/jΩc) on the imaginary axis τ = jν. From\nthe definition TN (x) = cos (N cos-1 (x)) it is easy to see that the roots of the Chebyshev\npolynomial occur at\nx = cos\nμ(n - 1/2)π\nN\n¶\nn = 1 . . . N\nand from Eq. (25) the system zeros will be at\nτn = jΩc cos\nμ(n - 1/2)π ¶\nn = 1 . . . N.\nN\n2. The poles and zeros are mapped back to the s-plane using s = ΩrΩc/τ and the N left\nhalf-plane poles are selected as the poles of the filter.\n3. The transfer function is formed and the system gain is adjusted to unity at Ω = 0.\nExample 2\nRepeat the previous Chebyshev Type 1 design example using a Chebyshev Type\n2 filter.\nFrom the previous example we have Ωc = 10 rad/s., Ωr = 20 rad/s., 2 = 1/3,\nλ = 4.358. The procedure to find the required order is the same as before, and\nwe conclude that N = 3. Next, define\nΩrΩc\nν =\n=\nΩ\nΩ\nˆ\n= 0.1154\n2TN (Ωr/Ωc)\nT3(2)\nDetermine α:\nμ1¶\nα =\nsinh-1\n=\nsinh-1(8.666) = 0.9520\nN\nˆ2\nand sinh α = 1.1024, and cosh α = 1.4884.\nThe values of γn = (2n - 1)π/6 for n = 1 . . . 6 are the same as the design for the\n7-8\n\nType 1 filter, so that the poles of H(τ) 2 are\n|\n|\npn =\nΩc (sinh α sin γn + j cosh α cos γn)\nA\n√\n!\nτ1 =\n10 1.1024\n+ j1.4884\n= 5.512 + j12.890\n× 2\n× 2\nτ2 = 10 (1.1024 × 1 + j1.4884 × 0) = 11.024\nA\n√\n!\nτ3 =\n10 1.1024\n2 - j1.488\n= 5.512 - j12.890\n×\n× 2\nA\n√\n!\nτ4 = 10 -1.1024\n2 - j1.4884\n= -5.512 - j12.890\n×\n× 2\nμ\n¶\nτ5 = 10 -1.1024 × 2 - j1.488 × 0\n= -11.024\nA\n√\n!\nτ6 = 10 -1.1024\n+ j1.4884\n= -5.512 + j12.890\n× 2\n× 2\nThe three left half-plane poles (τ4, τ5, τ6) are mapped back to the s-plane using\ns = ΩrΩc/τ giving three filter poles\np1, p2 = -5.609 ± j13.117\np3 = -18.14\nThe system zeros are the roots of\nT3(ν/jΩc) = 4(ν/jΩc)3 - 3(ν/jΩc) = 0\nfrom the definition of TN (x), giving ν1 = 0 and ν2, ν3 = ±j8.666. Mapping these\nback to the s-plane gives two finite zeros z1, z2 = ±j23.07, z3 = inf (the zero at\ninf does not affect the system response) and the unity gain transfer function is\nH(s)\n= -p1p2p3\n(s - z1)(s - z2)\nz1z2\n(s - p1)(s - p2)(s - p3)\n6.9365(s2 + 532.2)\n= (s + 18.14)(s2 + 11.22s + 203.5)\nThe pole-zero plot for this filter is shown in below. Note that the poles again lie\non ellipse, and the presence of the zeros in the stop-band.\n7-9\n\n2.3\nComparison of Filter Responses\nBode plot responses for the three previous example filters are shown below:\nAngular frequency (rad/sec)\n-150\n-100\n-50\nMagnitude (dB)\n-360\n-180\nPhase (deg)\nButterworth (N=4)\nChebyshev Type 1 (N=3)\nChebyshev Type 2 (N=3)\nButterworth (N=4)\nChebyshev Type 1 (N=3)\nChebyshev Type 2 (N=3)\n7-10\n\nWhile all filters meet the design specification, it can be seen that the Butterworth and\nthe Chebyshev Type 1 filters are all-pole designs and have an asymptotic high-frequency\nmagnitude slope of -20N dB/decade, in this case -80 dB/decade for the Butterworth design\nand -60 dB/decade for the Chebyshev Type 1 design. The Type 2 Chebyshev design has\ntwo finite zeros on the imaginary axis at a frequency of 23.07 rad/s, forcing the response to\nzero at this frequency, but with the result that its asymptotic high frequency response has\na slope of only -20 dB/decade. Note also the singularity in the phase response of the Type\n2 Chebyshev filter, caused by the two purely imaginary zeros.\nThe pass-band and stop-band power responses are shown in below. Notice that the design\nmethod developed here guarantees that the response will meet the specification at the cut-off\nfrequency (in this case |H(jΩ)|2 = 0.9 at Ωc = 10. Other design methods (such as used by\nMATLAB) may not use this criterion.\n0.88\n0.9\n0.92\n0.94\n0.96\n0.98\n1.02\nPower response\nButterworth (N=4)\nChebyshev Type 1 (N=3)\nChebyshev Type 2 (N=3)\nAngular frequency (rad/sec)\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\nPower response\nButterworth (N=4)\nChebyshev Type 2 (N=3)\nChebyshev Type 1 (N=3)\nAngular frequency (rad/sec)\n7-11"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 8",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/32157b1c3d282eb849fbda43d513c5e3_lecture_08.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 81\nReading:\n-\nClass handout: Introduction to Continuous Time Filter Design.\n-\nClass Handout: Introduction to Operational Amplifiers.\n-\nClass Handout: Op-Amp Implementation of Analog Filters.\nSecond-Order Filter Sections\n(a) Low-Pass Filter\na0\nHlp(s) = s2 + a1s + a0\nHigh Frequency Behavior: The number of poles exceeds the number of zeros (n -\nm = 2) so that\nlim |H(jΩ)| = 0.\nΩ→inf\nand the high frequency asymptotic slope is -40dB/decade.\nLow Frequency Behavior:\nlim |H(jΩ)| = 1\nΩ→0\n√\nMid Frequency Behavior: The response in the region Ω ≈\na0 is determined by\nthe systems damping ratio ζ, and will exhibit a resonant peak if ζ < 0.707.\n\n1copyright ⃝c\nD.Rowell 2008\n8-1\n\n(b) High-Pass Filter\ns\nHhp(s) = s2 + a1s + a0\nHigh Frequency Behavior: The number of poles equals the number of zeros (n =\nm) so that\nlim |H(jΩ)| = 1.\nΩ→inf\nLow Frequency Behavior: There are a pair of zeros at the origin so that\nlim |H(jΩ)| = 0\nΩ→0\nand the low frequency asymptotic slope is +40dB/decade.\n√\nMid Frequency Behavior: The response in the region Ω ≈\na0 is determined by\nthe systems damping ratio ζ, and will exhibit a resonant peak if ζ < 0.707.\n\n(c) Band-Pass Filter\na1s\nHbp(s) = s2 + a1s + a0\nHigh Frequency Behavior: The number of poles exceeds the number of zeros (n -\nm = 1) so that\nlim |H(jΩ)| = 0.\nΩ→inf\nand the high frequency asymptotic slope is -20dB/decade.\nLow Frequency Behavior: There is a single of zero at the origin so that\nlim |H(jΩ)| = 0\nΩ→0\nand the low frequency asymptotic slope is +20dB/decade.\n√\nMid Frequency Behavior: When s = j\na0,\n√\nH(j\na0) = 1\nwhich defines the passband center frequency.\n8-2\n\n(d) Band-Stop Filter\ns2 + a0\nHbs(s) = s2 + a1s + a0\nHigh Frequency Behavior: The number of poles equals the number of zeros (n =\nm = 2) so that\nlim |H(jΩ)| = 1.\nΩ→inf\nLow Frequency Behavior: There are no zeros at the origin and\nlim |H(jΩ)| = 1\nΩ→0\n√\nMid Frequency Behavior: There are a pair of imaginary zeros at s = ±j\na0 forcing\n√\nthe response magnitude to zero at a frequency Ω =\na0.\n√\n|H(j\na0)| = 0\nwhich defines the band rejection (notch) center frequency.\n\n8-3\n\nTransformation of Low-Pass Filters to other Classes\nFilter specification tolerance bands for high-pass, band-pass and band-stop filters are shown\nThe most common procedure for the design of these filters is to design a prototype low-pass\nfilter using the methods described above, and then to transform the low-pass filter to the\ndesired form by a substitution in the transfer function, that is we substitute a function\ng(s) for s in the low-pass transfer function Hlp(s), so that the new transfer function is\nH′(s) = Hlp(g(s)). The effect is to modify the filter poles and zeros to produce the desired\nfrequency response characteristic.\n\nThe critical frequencies used in the design are as shown above. For band-pass and band-stop\nfilters it is convenient to define a center frequency Ωo as the geometric mean of the pass-pand\n8-4\n\nedges, and a bandwidth ΔΩ:\nΩo =\nΩcuΩcl\nΔΩ =\nΩcu - Ωcl.\nThe transformation formulas for a low-pass filter with cut-off frequency Ωc are given below\nLow-pass (Ωc1 ) → Low-pass (Ωc2 )\ng(s) = Ωc1\nΩc2\ns\nLow-pass (Ωc) → High-pass (Ωc)\ng(s) = Ω2\nc\ns\nLow-pass (Ωc = ΔΩ) → Band-pass (Ωcl, Ωcu) g(s) = s2 + Ω2\no\ns\nLow-pass (Ωc = ΔΩ) → Band-stop (Ωcl, Ωcu) g(s) = sΩ2\nc\ns2 + Ω2\no\nThe band-pass and band-stop transformations both double the order of the filter, since s2\nis involved it the transformation. The low-pass filter is designed to have a cut-off frequency\nΩc = Ωcu - Ωcl.\nThe above transformations will create an ideal gain characteristic from an ideal low-\npass filter. For practical filters, however, the \"skirts\" of the pass-bands will be a warped\nrepresentation of the low-pass prototype filter. This does not usually cause problems.\nExample 1\nTransform the first-order low-pass filter\nΩc\nHlp(s) = s + Ωc\nto a high-pass filter Hhp(s).\nUsing the transformation g(s) = Ω2\nc /s\nΩc\ns\nHhp(s) =\nΩ2\n=\nc\n+ Ωc\ns + Ωc\ns\nExample 2\nTransform the second-order low-pass Butterworth filter\nΩ2\nHlp(s) =\n√\nc\ns2 +\n2Ωcs + Ω2\nc\n8-5\n\nto a high-pass filter Hhp(s).\nUsing the transformation g(s) = Ω2\nc /s\nΩ2\ns2\nHhp(s) =\n√\nc\n\n=\n√\nΩ2\nΩ2\nc\nc\ns2 +\n2s + Ωc\n+\n+ Ω2\ns\ns\nc\nExample 3\nDesign a second-order bandpass filter with center frequency Ωo and bandwidth\nΔΩ.\nStep 1:\nDesign a first-order prototype low-pass filter with cut-off frequency\nΔΩ:\nΔΩ\n+Ω\ns\no\nHlp(s) = s + ΔΩ\nStep 2:\nTransform the prototype using\ns2 + Ω2\ng(s) =\no\ns\nso that\nΔΩ\nΔΩs\nH(s) =\n\n=\n2 + ΔΩs + Ω2\no\n+ ΔΩ\ns\ns\nExample 4\n+Ω\ns\no\nDesign a second-order band-stop filter with center frequency Ωo and notch-width\nΔΩ.\nStep 1:\nDesign a first-order prototype low-pass filter with cut-off frequency\nΔΩ:\nΔΩ\nHlp(s) = s + ΔΩ\nStep 2:\nTransform the prototype using\nsΔ2\ng(s) =\nΩ\ns2 + Ω2\no\nso that\nΔΩ\ns2 + Ω2\nH(s) =\nsΔ2\n=\no\nΩ\n+ ΔΩ\ns2 + ΔΩs + Ω2\no\n8-6\n\nState-Variable Active Filters\nPractical realizations of analog filters are usually based on factoring the transfer function\ninto cascaded second-order sections, each based on a complex conjugate pole-pair or a pair\nof real poles, and a first-order section if the order is odd. Any zeros in the system may be\ndistributed among the second- and first-order sections. Each first- and second-order section\nis then implemented by an active filter and connected in series. For example the third-order\nButterworth high-pass filter\ns3\nH(s) = s3 + 40s2 + 800s + 8000\nwould be implemented as\ns2\ns\nH(s) = s2 + 20s + 400 × s + 20\nas shown below:\n\nThe design of each low-order block can be handled independently.\nThe state-variable filter design method is based on the block diagram representation used\nin the so-called phase-variable description of linear systems that uses the outputs of a chain\nof cascaded integrators as state variables. Consider a second-order filter block with a transfer\nfunction\nY (s)\nb2s2 + b1s + b0\nH(s) =\n=\nU(s)\ns2 + a1s + a0\nand split H(s) into two sub-blocks representing the denominator and numerator by intro\nducing an intermediate variable x and rewrite\nX(s)\nH1(s)\n=\n\n=\nU(s)\ns2 + a1s + a0\nY (s)\nH2(s)\n=\n\n= b2s + b1s + b0\nX(s)\nso that H(s)\n=\nH2(s)H1(s).\nThe differential equations corresponding to H1(s) and H2(s) are\nd2x\ndx\n+ a1\n+ a0x = u\ndt2\ndt\nand\nd2x\ndx\ny = b2\n+ b1\n+ b0x.\ndt2\ndt\n8-7\n\nThe first equation may be rewritten explicitly in terms of the highest derivative\nd2x\ndx\n= -a1\n- a0x + u.\n(1)\ndt2\ndt\nConsider a pair of cascaded analog integrators with the output defined as x(t) so that the\nderivatives of x(t) appear as inputs to the integrators:\n\nNote that Eq. (1) gives an explicit expression for the input to the first block in terms of\nthe outputs of the two integrators and the system input, and therefore generates the block\ndiagram for H1(s) shown below:\n\nThe equation\nd2x\ndx\ny = b2\n+ b1\n+ b0x.\ndt2\ndt\nshows that the output y(t) is a weighted sum of x(t) and its derivatives, leading to the\ncomplete second-order state variable filter block diagram:\n\nThis basic structure may be used to realize the four basic filter types by appropriate\nchoice of the numerator.\nY1(s)\na0\nHlp(s)\n=\n\n=\na unity gain low-pass filter\n(2)\nU(s)\ns2 + a1s + a0\nY2(s)\na1s\nHbp(s)\n=\n\n=\na unity gain band-pass filter\n(3)\nU(s)\ns2 + a1s + a0\nY3(s)\ns2\nHhp(s)\n=\n\n=\na unity gain high-pass filter\n(4)\nU(s)\ns2 + a1s + a0\nY4(s)\ns2 + a0\nHbs(s)\n=\n\n=\na unity gain band-stop filter\n(5)\nU(s)\ns2 + a1s + a0\n8-8\n\ns\ns\nX ( s )\ns X ( s )\ns X ( s )\na\na\nU ( s )\n+\n-\n-\na 0\n+\n+\nY ( s ) ( l o w - p a s s )\nY ( s ) ( b a n d - p a s s )\nY ( s ) ( h i g h - p a s s )\nY ( s ) ( b a n d - s t o p )\na 1\na\n8-9"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 9",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/264d28b72e04d21740367f9c4cc485aa_lecture_09.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 91\nReading:\n-\nClass Handout: Introduction to the Operational Amplifier\n-\nClass Handout: Op-amp Implementation of Analog Filters\nOperational-Amplifier Based State-Variable Filters\nWe saw in Lecture 8 that second-order filters may be implemented using the block diagram\nstructure\n\nand that a high-order filter may be implemented by cascading second-order blocks, and\npossibly a first-order block (if the filter order is odd).\nWe now look into a method for implementing this filter structure using operational am\nplifiers.\n1.1\nThe Operational Amplifier\nWhat is an operational amplifier? It is simply a very high gain electronic amplifier, with a\npair of differential inputs. Its functionality comes about through the use of feedback around\nthe amplifier, as we show below.\n\n1copyright ⃝c\nD.Rowell 2008\n9-1\n\nThe op-amp has the following characteristics:\n- It is basically a \"three terminal\" amplifier, with two inputs and an output. It is a\ndifferential amplifier, that is the output is proportional to the difference in the voltages\napplied to the two inputs, with very high gain A,\nvout = A(v+ - v-)\nwhere A is typically 104 - 105, and the two inputs are known as the non-inverting (v+)\nand inverting (v-) inputs respectively. In the ideal op-amp we assume that the gain A\nis infinite.\n- In an ideal op-amp no current flows into either input, that is they are voltage-controlled\nand have infinite input resistance. In a practical op-amp the input current is in the\norder of pico-amps (10-12) amp, or less.\n- The output acts as a voltage source, that is it can be modeled as a Thevenin source\nwith a very low source resistance.\nThe following are some common op-amp circuit configurations that are applicable to the\nactive filter design method described here. (See the class handout for other common config\nurations).\nThe Inverting Amplifier:\n\nIn the configuration shown above we note\n- Because the gain A is very large, the voltage at the node designated summing junc\ntion is very small, and we approximate it as v- = 0 -- the so-called virtual ground\nassumption.\n- We assume that the current i- into the inverting input is zero.\nApplying Kirchoff's Current law at the summing junction we have\nvin\nvo\ni1 + if =\n+\n= 0\nR1\nRf\nfrom which\nRf\nvout = -\nvin\nRin\n9-2\n\nThe voltage gain is therefore defined by the ratio of the two resistors. The term inverting\namplifier comes about because of the sign change.\nThe Inverting Summer:\nThe inverting amplifier may be extended to include multiple\ninputs:\n\nAs before we assume that the inverting input is at a virtual ground (v- ≈ 0) and apply\nKirchoff's current law at the summing junction\nv1\nv2\nVout\ni1 + i2 + if =\n+\n+\n= 0\nR1\nR2\nRf\nor\nRf\nRf\nvout = -\nv1 +\nv2\nR1\nR2\nwhich is a weighted sum of the inputs.\nThe summer may be extended to include several inputs by simply adding additional input\nresistors Ri, in which case\nn\nRf\nvout = -\nvi\nRi\ni=1\nThe Integrator: If the feedback resistor in the inverting amplifier is replaced by a capac\nitor C the amplifier becomes an integrator.\n\n!\n\nAt the summing junction we apply Kirchoff's current law as before but the feedback current\nis now defined by the elemental relationship for the capacitor:\nvin\ndvout\niin + if =\n+ C\n= 0\nRin\ndt\n9-3\n\nThen\ndvout\n= -\nvin\ndt\nRinC\nor\nt\nvout = -\nvindt + vout(0)\nRinC\nAs above, the integrator may be extended to a summing configuration by simply adding\nextra input resistors:\nt\nn vi\nvout = -\ndt + vout(0)\nC\nRi\ni=1\nand if all input resistors have the same value R\n1 t\nn\nvout = -\nvi\ndt + vout(0)\nRC\ni=1\n1.2\nA Three Op-Amp Second-Order State Variable Filter\nA configuration using three op-amps to implement low-pass, high-pass, and bandbass filters\ndirectly is shown below:\n\" # \"\n\n!\nAmplifiers A1 and A2 are integrators with transfer functions\nH1(s) = -\nand H2(s) = -\n.\nR1C1\ns\nR2C2\ns\nLet τ1 = R1C1 and τ2 = R2C2. Because of the gain factors in the integrators and the sign\ninversions we have\ndv2\nd2v2\nv1(t) = -τ2\nand v3(t) = τ1τ2\n.\ndt\ndt2\nAmplifier A3 is the summer. However, because of the sign inversions in the op-amp circuits\nwe cannot use the elementary summer configuration described above. Applying Kirchoff's\nCurrent Law at the non-inverting and inverting inputs of A3 gives\nVin - v+\nv1 - v+\nv3 - v-\nv2 - v-\n+\n= 0 and\n+\n= 0.\nR5\nR6\nR4\nR1\n9-4\n\nUsing the infinite gain approximation for the op-amp, we set v- = v+ and\nR3\nR5\nR4\nR6\nv3 -\nv1 +\nv2 =\nVin,\nR3 + R4\nR5 + R6\nR3 + R4\nR5 + R6\nand substituting for v1 and v3 we generate a differential equation in v2\nd2v2\n1 + R4/R3\ndv2\nR4 1\n\n1 + R4/R3\n\n+\n+\nv2 =\nVin\ndt2\nτ1(1 + R6/R5)\ndt\nR3 τ1τ2\nτ1τ2 (1 + R5/R6)\nwhich corresponds to a low-pass transfer function with\nKlpa0\nH(s) = s2 + a1s + a0\nwhere\na0 =\nR4\nR3\nτ1τ2\n\n1 + R4/R3\na1 =\n1 + R6/R5\nτ1\n1 + R3/R4\nKlp = 1 + R5/R6\nA Band-Pass Filter:\nSelection of the output as the output of integrator A1 generates\nthe transfer function\n-Kbpa1s\nHbp(s) = -τ1sHlp(s) = s2 + a1s + a0\nwhere\nR6\nKbp = R5\nA High-Pass Filter:\nSelection of the output as the output of the summer A3 generates\nthe transfer function\nHhp(s) = τ1τ2s 2Hlp(s) =\nKhps2\ns2 + a1s + a0\nwhere\n1 + R4/R3\nKhp = 1 + R5/R6\nA Band-Stop Filter:\nThe band-stop configuration may be implemented with an addi\ntional summer to add the outputs of amplifiers A2 and A (with appropriate weights).\n1.3\nA Simplified Two Op-amp Based State-variable Filter:\nIf the required filter does not require a high-pass action (that is, access to the output of\nthe summer A1 above) the summing operation may be included at the input of the first\nintegrator, leading to a simplified circuit using only two op-amps shown below:\n9-5\n\n$\n\nConsider the input stage:\n\nWith the infinite gain assumption for the op-amps, that is V- = V+ , and with the assumption\nthat no current flows in either input, we can apply Kirchoff's Current Law (KCL) at the\nnode designated (a) above:\ni1 + if - i3 = (Vin - va)\n+ sC1(v1 - va) - va\n= 0\nR1\nR3\nAssuming va = Vout, and realizing that the second stage is a classical op-amp integrator with\ntransfer function\nVout(s)\n= -\nv1(s)\nR2C2s\n(Vin - Vout)\n+ sC1(-R2C2sVout - Vout) - Vout\n= 0\nR1\nR3\nwhich may be rearranged to give the second-order transfer function\nVout(s)\n1/τ1τ2\n=\nVin(s)\ns2 + (1/τ2)s + (1 + R1/R3)/τ1τ2\nwhich is of the form\nKlpa0\nHlp(s) = s2 + a1s + a0\nwhere\na0 =\n(1 +\n\nR1/R3) τ1τ2\na1 = τ2\nKlp = 1 + R1/R3\n9-6\n\n!\n\n1.4\nFirst-Order Filter Sections:\nSingle pole low-pass filter sections with a transfer function of the form\nKΩ0\nH(s) = s + Ω0\nmay be implemented in either an inverting or non-inverting configuration as shown in Fig.\n11.\n\n!\n\nThe inverting configuration (a) has transfer function\nVout(s)\nZf\nR1\n1/R1C\n= -\n= -\nVin(s)\nZin\nR2\ns + 1/R1C\nwhere Ω0 = 1/R1C and K = -R1/R2.\nThe non-inverting configuration (b) is a first-order R-C lag circuit buffered by a non-\ninverting (high input impedance) amplifier (see the class handout) with a gain K = 1 +\nR3/R2. Its transfer function is\n\nVout(s) = 1 + R3\n1/R1C .\nVin(s)\nR2\ns + 1/R1C\n9-7\n\nClassroom Demonstration\nExample 2 in the class handout \"Op-Amp Implementation of Analog Filters\" describes a\nstate-variable design for a 5th-order Chebyshev Type I low-pass filter with Ωc = 1000 rad/s\nand 1dB ripple in the passband.\nThe transfer function is\nH(s)\n=\n(s2 + 468.4s + 429300)(s2 + 178.9s + 988300)(s + 289.5)\n289.5\n=\n×\n×\ns2 + 468.4s + 429300\ns2 + 178.9s + 988300\ns + 289.5\nwhich is implemented in the handout as a pair of second-order two-op-amp sections followed\nby a first-order block:\n\n% &\n\n% &\n\n% &\n\n% &\n\n% &\n\n& '\n& &\n\n& &\n\n( '\n\nThis filter was constructed on a bread-board using 741 op-amps, and was demonstrated\nto the class, driven by a sinusoidal function generator and with an oscilloscope to display\nthe output. The demonstration included showing (1) the approximately 10% ripple in the\npassband, and (2) the rapid attenuation of inputs with frequency above 157 Hz (1000 rad/s).\n9-8\n\n$\n\"\nIntroduction to Discrete-Time Signal Processing\nConsider a continuous function f(t) that is limited in extent, T1 ≤ t < T2. In order to\nprocess this function in the computer it must be sampled and represented by a finite set of\nnumbers. The most common sampling scheme is to use a fixed sampling interval ΔT and to\nform a sequence of length N: {fn} (n = 0 . . . N - 1), where\nfn = f(T1 + nΔT).\nIn subsequent processing the function f(t) is represented by the finite sequence {fn} and the\nsampling interval ΔT.\nIn practice, sampling occurs in the time domain by the use of an analog-digital (A/D)\nconverter.\n# $\n% &\n\n&\n&\n\n% &\n\n&\n\n& &\n&\n\n& $ ' $ )\n&\n& &\n\n& ( & & * %\n\n(i) The sampler (A/D converter) records the signal value at discrete times nΔT to produce\na sequence of samples {fn} where fn = f(nΔT) (ΔT is the sampling interval.\n$\n\n)\n)\n)\n)\n)\n)\n)\n& )\n( )\n(ii) At each interval, the output sample yn is computed, based on the history of the input\nand output, for example\nyn =\n(fn + fn-1 + fn-2)\n3-point moving average filter, and\nyn = 0.8yn-1 + 0.2fn\nis a simple recursive first-order low-pass digital filter. Notice that they are algorithms.\n(iii) The reconstructor takes each output sample and creates a continuous waveform.\nIn real-time signal processing the system operates in an infinite loop:\n9-9\n\n$\n\n*\n\n$\n\n& $\n\n&\n\n&\n* & &\n&\n& *\n&\n*\n2.1\nSampling\nThe mathematical operation of sampling (not to be confused with the operation of an analog-\ndigital converter) is most commonly described as a multiplicative operation, in which f(t) is\nmultiplied by a Dirac comb sampling function s(t; ΔT ), consisting of a set of delayed Dirac\ndelta functions:\ninf\ns(t; ΔT ) =\nδ(t - nΔT ).\nn=-inf\nWe denote the sampled waveform f ⋆(t) as\ninf\nf ⋆(t) = s(t; ΔT )f(t) =\nf(t)δ(t - nΔT )\nn=-inf\n\n+\n$ , $ - +\n+\n9-10\n\nNote that f ⋆(t) is a set of delayed and weighted delta functions, and that the waveform must\nbe interpreted in the distribution sense by the strength (or area) of each component impulse.\nThe implied process to produce the discrete sample sequence {fn} is by integration across\neach impulse, that is\nnΔT +\nnΔT +\ninf\nfn =\nf ⋆(t)dt =\nf(t)δ(t - nΔT)dt\nnΔT -\nnΔT -\nn=-inf\nor\nfn = f(nΔT)\nby the sifting property of δ(t).\n2.2\nThe Spectrum of the Sampled Waveform f (t):\nNotice that sampling comb function s(t; ΔT) is periodic and is therefore described by a\nFourier series:\ninf\njnΩ0t\ns(t; ΔT) =\ne\nΔT n=-inf\nwhere all the Fourier coefficients are equal to (1/ΔT), and where Ω0 = 2π/ΔT is the fun\ndamental angular frequency. Using this form, the spectrum of the sampled waveform f ⋆(t)\nmay be written\n\ninf\ninf\n\ninf\n-jΩt dt\nF ⋆(jΩ) =\nf ⋆(t) e-jΩt dt =\nf(t) ejnΩ0t e\n-inf\nΔT n=-inf\n-inf\ninf\n=\nF (j (Ω - nΩ0))\nΔT n=-inf\ninf\n\n2πn\n=\nF\nj Ω -\nΔT\nΔT\nn=-inf\nThe Fourier transform of a sampled function f ⋆(t) is periodic in the frequency domain with\nperiod Ω0 = 2π/ΔT, and is a superposition of an infinite number of shifted replicas of the\nFourier transform, F(jΩ), of the original function scaled by a factor of 1/ΔT.\n. /\n. /\n\n+\n)\n\n)\n)\n)\n)\n\n)\n\n)\n)\n)\n)\n\n)\n)\n\n9-11"
    },
    {
      "category": "Lecture Notes",
      "title": "Lecture 10",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/2-161-signal-processing-continuous-and-discrete-fall-2008/2934569026a399e9062597924c730a78_lecture_10.pdf",
      "content": "MIT OpenCourseWare\nhttp://ocw.mit.edu\n2.161 Signal Processing: Continuous and Discrete\nFall 2008\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n\nMassachusetts Institute of Technology\nDepartment of Mechanical Engineering\n2.161 Signal Processing - Continuous and Discrete\nFall Term 2008\nLecture 101\nReading:\n-\nClass Handout: Sampling and the Discrete Fourier Transform\n-\nProakis & Manolakis (4th Ed.) Secs. 6.1 - 6.3, Sec. 7.1\n-\nOppenheim, Schafer & Buck (2nd Ed.) Secs. 4.1 - 4.3, Secs. 8.1 - 8.5\nThe Sampling Theorem\nGiven a set of samples {fn} and its generating function f(t), an important question to ask\nis whether the sample set uniquely defines the function that generated it? In other words,\ngiven {fn} can we unambiguously reconstruct f(t)? The answer is clearly no, as shown\nbelow, where there are obviously many functions that will generate the given set of samples.\nIn fact there are an infinity of candidate functions that will generate the same sample set.\nThe Nyquist sampling theorem places restrictions on the candidate functions and, if\nsatisfied, will uniquely define the function that generated a given set of samples. The theorem\nmay be stated in many equivalent ways, we present three of them here to illustrate different\naspects of the theorem:\n- A function f(t), sampled at equal intervals ΔT, can not be unambiguously\nreconstructed from its sample set {fn} unless it is known a-priori that f(t)\ncontains no spectral energy at or above a frequency of π/ΔT radians/s.\n- In order to uniquely represent a function f(t) by a set of samples, the sampling\ninterval ΔT must be sufficiently small to capture more than two samples per\ncycle of the highest frequency component present in f(t).\n- There is only one function f(t) that is band-limited to below π/ΔT radians/s\nthat is satisfied by a given set of samples {fn}.\n1copyright ⃝c\nD.Rowell 2008\n10-1\n\nNote that the sampling rate, Fs = 1/ΔT , must be greater than twice the highest cyclic\nfrequency Fmax in f(t). Thus if the frequency content of f(t) is limited to Ωmax radians/s\n(or Fmax cycles/s) the sampling interval ΔT must be chosen so that\nπ\nΔT < Ωmax\nor equivalently\nΔT < 2Fmax\nThe minimum sampling rate to satisfy the sampling theorem FN = Ωmax/π samples/s is\nknown as the Nyquist rate.\n1.1\nAliasing\nConsider a sinusoid\nf(t) = A sin(at + φ)\nsampled at intervals ΔT , so that the sample set is\n{fn} = {A sin(anΔT + φ)} ,\nand noting that sin(t) = sin(t + 2kπ) for any integer k,\n2πm\nfn = A sin(anΔT + φ) = A sin\na +\nnΔT + φ\nΔT\nwhere m is an integer, giving the following important result:\nGiven a sampling interval of ΔT , sinusoidal components with an angular frequency\na and a + 2πm/ΔT , for any integer m, will generate the same sample set.\nIn the figure below, a sinusoid is undersampled and a lower frequency sinusoid, shown as a\ndashed line, also satisfies the sample set.\nf(t)\nt\no\no\no\no\nΔ T\no\no\no\n10-2\n\nThis phenomenon is known as aliasing. After sampling any spectral component in F(jΩ)\nabove the Nyquist frequency π/ΔT will \"masquerade\" as a lower frequency component\nwithin the reconstruction bandwidth, thus creating an erroneous reconstructed function.\nThe phenomenon is also known as frequency folding since the high frequency components\nwill be \"folded\" down into the assumed system bandwidth.\nOne-half of the sampling frequency (i.e. 1/(2ΔT) cycles/second, or π/ΔT radians/second)\nis known as the aliasing frequency, or folding frequency for these reasons.\n\nThe following figure shows the effect of folding in another way. In (a) a function f(t) with\nFourier transform F(j Ω) has two disjoint spectral regions. The sampling interval ΔT is\nchosen so that the folding frequency π/ΔT falls between the two regions. The spectrum\nof the sampled system between the limits -π/ΔT < Ω ≤ π/ΔT is shown in (b). The\nfrequency components above the aliasing frequency have been folded down into the region\n-π/ΔT < Ω ≤ π/ΔT.\n\n1.2\nAnti-Aliasing Filtering:\nOnce a sample set {fn} has been taken, there is nothing that can be done to eliminate the\neffects of aliased frequency components. The only way to guarantee that the sample set\nunambiguously represents the generating function is to ensure that the sampling theorem\ncriteria have been met, either by\n10-3\n\n1. Selecting a sampling interval ΔT sufficiently small to capture all spectral components,\nor\n2. Processing the continuous-time function f(t) to \"eliminate\" all components at or above\nthe Nyquist rate.\nThe second method involves the use of a continuous-time processor before sampling f(t). A\nlow-pass aanti-aliasing filter is used to eliminate (or at least attenuate) spectral components\nat or above the Nyquist frequency. Ideally the anti-aliasing filter would have a transfer\nfunction\n\n1 for |Ω| < π/ΔT\nH(j Ω) =\n0 otherwise,.\n\nIn practice it is not possible to design a filter with such characteristics, and a more realistic\ngoal is to reduce the offending spectral components to insignificant levels, while maintaining\nthe fidelity of components below the folding frequency.\n1.3\nReconstruction of a Function from its Sample Set\nWe saw in Lecture 9 that the spectrum F ⋆(j Ω) of a sampled function f ⋆(t) is infinite in\nextent and consists of a scaled periodic extension of F(j Ω) with a period of 2π/ΔT, i.e.\ninf\n\n2πn\nF ⋆(j Ω) =\nF j\nΩ -\n.\nΔT\nΔT\nn=-inf\n\nIf it is assumed that the sampling theorem was obeyed during sampling, the repetitions in\nF ⋆(j Ω) will not overlap, and in fact f(t) will be entirely specified by a single period of F ⋆(j Ω).\nTherefore to reconstruct f(t) we can pass f ⋆(t) through an ideal low-pass filter with transfer\nfunction H(j Ω) that will retain spectral components in the range -π/ΔT < Ω < π/ΔT and\nreject all other frequencies.\n10-4\n\n!\n\nIf the transfer function of the reconstruction filter is\nΔT\nfor |Ω| < π/ΔT\nH(j Ω) =\notherwise,\nin the absence of aliasing in f ∗(t), that is no overlap between replications of F(j Ω) in F ∗(j Ω),\nthe filter output will be\ny(t) = F-1 {F ⋆(j Ω)H(j Ω)} = F-1 {F(j Ω)} = f(t).\nThe filter's impulse response h(t) is\nh(t) = F-1 {H(j Ω)} = sin (πt/ΔT) ,\nπt/ΔT\n\n\"\n# $\n\"\n\n$\n#\nand note that the impulse response h(t) = 0 at times t = ±nΔT for n = 1, 2, 3, . . . (the\nsampling times). The output of the reconstruction filter is the convolution of the input\nfunction f ⋆(t) with the impulse response h(t),\ninf\ninf\nf(t)\n=\nf ⋆(t) ⊗ h(t) =\nh(σ)\nf(t - σ)δ(t - nΔT - σ) dσ\ninf\nn=-inf\ninf inf\n\nsin (πσ/ΔT)\n=\nf(t - σ)δ(t - nΔT - σ) dσ\nπσ/ΔT\nn=-inf\ninf\ninf\n\nsin (π(t - nΔT)/ΔT)\n=\nf(nΔT)\n,\nπ(t - nΔT)/ΔT\nn=-inf\n10-5\n\nor in the case of a finite data record of length N\nN-1\n\nsin (π(t - nΔT )/ΔT )\nf(t) =\nfn\n.\nπ(t - nΔT )/ΔT\nn=0\nThis is known as the cardinal (or Whittaker) reconstruction function. It is a superposition\nof shifted sinc functions, with the important property that at t = nΔT , the reconstructed\nfunction f(t) = fn. This can be seen by letting t = nΔT , in which case only the nth term\nin the sum is nonzero. Between the sample points the interpolation is formed from the\nsum of the sinc functions. The reconstruction is demonstrated below, where a sample set\n(N = 13) with three nonzero samples is reconstructed. The individual sinc functions are\nshown, together with the sum (dashed line). Notice how the zeros of the sinc functions fall\nat the sample points.\no\no\no\no\no\no\no\no\no\no\no\no\no\n-0.3\nThe Discrete Fourier Transform (DFT)\nWe saw in Lecture 8 that the Fourier transform of the sampled waveform f ∗(t) can be written\nas a scaled periodic extension of F (j Ω)\ninf\n\n2nπ\nF ⋆(j Ω) =\nF j\nΩ -\nΔT\nT\nn=-inf\nWe now look at a different formulation of F ∗(j Ω). The Fourier transform of the sampled\nfunction f ⋆(t)\nF ⋆(j Ω) =\ninf\nf ⋆(t) e-j Ωtdt =\ninf\ninf\n\nf(t)δ(t - nΔT ) e-j Ωt dt\n-inf\n-inf n=-inf\ninf\n=\nf(nΔT ) e-j ΩnΔT\nn=-inf\n10-6\n\nby reversing the order of integration and summation, and using the sifting property of δ(t).\nWe note:\n- F ⋆(j Ω) is a continuous function of Ω, but is computed from the sample points f(nΔT)\nin f(t).\n- We have shown that F ⋆(j Ω) is periodic in Ω with period Ω0 = 2π/ΔT.\nWe now restrict ourselves to a finite, causal waveform f(t) in the interval 0 ≤ t < nΔT, so\nthat it has N samples, and let\nN-1\nF ∗ (j Ω) =\nf(nΔT) e-j ΩnΔT\nn=0\nwhich is known as the Discrete-Time Fourier Transform (DTFT).\nAs a further restriction consider computing a finite set of N samples of F ∗(j Ω) in a single\nperiod, from Ω = 0 to 2π/ΔT, that is at frequencies\n2πm\nΩm =\nfor m = 0, 1, 2, . . . , N - 1\nNΔT\n\n%\n\nand writing Fm = F ⋆(j Ωm) = F ⋆(j 2πm/NΔT), the DTFT becomes\nN-1\nFm =\nfn e -j 2πmn/N\nfor m = 0, 1, 2, . . . , N - 1\nn=0\nwhere fn = f(nΔT). This equation is known as the Discrete Fourier Transform (DFT) and\nrelates the sample set {fn} to a set of samples of its spectrum {Fm} - both of length N.\nThe DFT can be inverted and the sample set {fn} recovered as follows:\nN-1\nj 2πmn/N\nfn =\nFm e\nfor n = 0, 1, 2, . . . , N - 1\nN m=0\nwhich is known as the inverse DFT (IDFT). These two equations together form the DFT\npair.\n10-7\n\nThe DFT operations are a transform pair between two sequences {fn} and {Fm}.\n-\nThe DFT expressions do not explicitly involve the sampling interval ΔT or the sam\n-\npled frequency interval Ω = 2π/(nΔT ).\n- Simple substitution into the formulas will show that both Fm and fn are periodic\nwith period N, that is fn+pN = fn and Fm+pN = Fm for any integer p.\nThe inverse transform is easily demonstrated:\nN-1\nN-1 AN-1\n!\nX\nj 2πmn/N\nX\nX\nfk e-j 2πmk/N\nj 2πmn/N\nfn =\nFm e\n=\ne\nN\nN\nm=0\nm=0\nk=0\nN-1\nN-1\nj 2πm(n-k)/N\n=\nX\nfk\nX\ne\nN k=0\nm=0\n=\n(Nfn) = fn\nN\nsince\nN-1\n(\nN\nX\ne\n=\nfor n = k\nj 2πm(n-k)/N\notherwise.\nm=0\nAs in the continuous Fourier transform case, we adopt the notations\nDFT\n{fn} ⇐⇒ {Fm}\n{Fm}\n=\nDFT {fn}\n{fn}\n=\nIDFT {Fm}\nto indicate DFT relationships.\n10-8"
    }
  ]
}