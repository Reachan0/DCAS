{
  "course_name": "Nonlinear Dynamics: Chaos",
  "course_description": "This course provides an introduction to nonlinear dynamics and chaos in dissipative systems. The content is structured to be of general interest to undergraduates in science and engineering. The course concentrates on simple models of dynamical systems, mathematical theory underlying their behavior, their relevance to natural phenomena, and methods of data analysis and interpretation. The emphasis is on nonlinear phenomena that may be described by a few variables that evolve with time.",
  "topics": [
    "Mathematics",
    "Applied Mathematics",
    "Differential Equations",
    "Science",
    "Earth Science",
    "Geophysics",
    "Physics",
    "Classical Mechanics",
    "Mathematics",
    "Applied Mathematics",
    "Differential Equations",
    "Science",
    "Earth Science",
    "Geophysics",
    "Physics",
    "Classical Mechanics"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nPrerequisites\n\n(\n8.02 Physics II: Electricity And Magnetism\nor\n8.021 Physics II: Electricity And Magnetism\nor\n8.022 Physics II: Electricity And Magnetism\n) and (\n18.03 Differential Equations\nor\n18.032 Differential Equations\n)\n\nKnowledge of ordinary differential equations is essential. Some linear algebra (knowledge of eigenvectors and eigenvalues) is also necessary. Having some experience with numerical computation is helpful but not necessary.\n\nCourse Description\n\nThis course provides an introduction to nonlinear dynamics and chaos in dissipative systems. The content is structured to be of general interest to undergraduates in science and engineering.\n\nThe course concentrates on simple models of dynamical systems, mathematical theory underlying their behavior, their relevance to natural phenomena, and methods of data analysis and interpretation. The emphasis is on nonlinear phenomena that may be described by a few variables that evolve with time.\n\nTo promote the notion of numerical experiments, we assign several laboratory-like problem sets that involve numerical simulation of dynamical systems. Python and Matlab code will often be provided, but students are free to use whatever tools they desire.\n\nTextbook\n\nStrogatz, S.\nNonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering.\nCRC Press, 2020. ISBN: 9780738204536.\n\nReferences\n\nAmong the many books on nonlinear dynamics and chaos, you may find it interesting to consult, either during or after the course, the following:\n\nBerge, P., Y. Pomeau, and C. Vidal.\nOrder within Chaos: Towards a Deterministic Approach to Turbulence.\nWiley-VCH, 1987. ISBN: 9780471849674. (An undergraduate-level physical introduction to the subject.)\n\nCross, M. and H. Greenside.\nPattern Formation and Dynamics in Nonequilibrium Systems\n. Cambridge University Press, 2009. ISBN: 9780521770507.\n\nCvitanovic, P.\nUniversality in Chaos.\nAdam Hilger, Ltd., 1989. ISBN: 9780852747650. (Contains reprints of a number of original research papers in the field.)\n\nCvitanovic, P., R. Artuso, R. Mainieri, G. Tanner, and G. Vattay.\nChaos: Classical and Quantum\n(PDF - 8.4 MB)\n\nGleick, J.\nChaos\n. Viking Books, 1987. ISBN: 9780749386061. (An excellent popular introduction.)\n\nGuckenheimer, J. and P. Holmes,\nNonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields.\nSpringer, 1983. ISBN: 9780387908199. (A graduate-level applied mathematics textbook.)\n\nSchuster, H. and W. Just.\nDeterministic Chaos: An Introduction\n, 4\nth\nedition. Wiley-VCH, 2005. ISBN: 9783527404155. (An advanced book of interest to physicists.)\n\nTurcotte, D.\nFractals and Chaos in Geology and Geophysics\n, 2\nnd\nedition. Cambridge University Press, New York, 1997. ISBN: 9780521567336.\n\nRequirements\n\nThere are no exams.\n\nThere are ten problem sets, assigned usually once per week, but occasionally less frequently. Some problems will be analytical while others will require use of a computer. The problem sets must be completed and turned in on time for grading. Requests for extensions in exceptional circumstances must be made in advance.\n\nStudents are also required to complete a final project and briefly present their work during the final meeting of the class. A written report is also due at that time. The final project could be either an analysis of an interesting paper or topic in the scientific literature, an attempt of your own to apply what you have learned to your own interests, or a combination of the two.\n\nGrading\n\nProblem sets count for about 80% of the grade and the final project about 20%.",
  "files": [
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lecture 1: Introduction to Nonlinear Dynamics: Chaos",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec1.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nSeptember 8, 2022\nContents\n1 Introduction\n1.1 Who am I? . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2 What is this course? . . . . . . . . . . . . . . . . . . . . . . .\n1.2.1\nNonlinear systems . . . . . . . . . . . . . . . . . . . . .\n1.2.2\nDissipative systems . . . . . . . . . . . . . . . . . . . .\n1.3 Course goals . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4 Administrative details . . . . . . . . . . . . . . . . . . . . . .\n1.5 Syllabus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6 Course material . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.7 Students . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.8 Handouts and further reading . . . . . . . . . . . . . . . . . .\nIntroduction\nThis course is\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nProf. Daniel Rothman\nTA: Constantin Arnscheidt\n1.1\nWho am I?\nA professor of geophysics. My current interests focus on\n- How the carbon cycle works, including its relation to abrupt climate\n\nchange (via \"tipping points\")\n- Dynamical mechanisms underlying the coevolution of life and the envi\nronment, and catastrophes such as mass extinctions.\n- Complex systems in general.\nI created this course long ago, but have not taught it since 2006. I'm delighted\nto teach it again, and am exploring many ways of reinvigorating its content.\n1.2\nWhat is this course?\nAn undergraduate introduction to the theory and phenomenology of dissipa\ntive nonlinear dynamical systems.\nLet's parse that out:\n- Dynamical system: anything (physical, chemical, biological) that evolves\nwith time. Here we consider systems parameterized by only a few vari\nables (e.g., position and momentum. . .).\n- Dissipative: system has some friction (e.g., viscosity). As t →inf, sys\ntem approaches an attractor which does not depend (usually) on initial\nconditions (e.g., rest state of, say, a pendulum; terminal velocity of a\nfalling object).\nAlmost all systems in Nature are dissipative. Counter-examples: So\nlar system dynamics are conservative (\"Hamiltonian\"). Also molecular\ndynamics of an ideal gas (elastic collisions).\n- Nonlinear. Nonlinear science is literally the study of systems (theoretical\nor real) that are not linear.\nLet's look at the last two points more closely.\n\n1.2.1\nNonlinear systems\nThe Polish-American scientist Stanislas Ulam once famously remarked that\ndefining nonlinear science as above is \"like defining the bulk of zoology by\ncalling it the study of non-elephant animals [1].\"\nConsider, for example, the usual assumptions that\n- stress ∝ strain;\n- flux ∝ force; or\n- current ∝ voltage\nWe often think that, e.g. pushing something twice as hard yields twice the\nvelocity.\nBut consider these examples:\n- Push a block with a weak force. If the force is too weak, the block\nsticks to surface. If the force exceeds a threshold, the block slips.\nforce\nsimple friction\npinned\nterminal\nvelocity\nThis is the basis of \"stick-slip\" models for the dynamics of, e.g., earth\nquake faults. Or violin bows on a string.\n- Make a pile of sand by adding one grain at a time. Most of the time\nthe grains are at rest. But occasionally there are avalanches. Most are\nsmall, but some are quite big.\n- Heat a fluid from below. If the thermal gradient is weak, heat diffuses\nupward but the fluid does not move\nStronger thermal gradients: convection (fluid motion) carries warm, less\ndense fluid upward, and cold, more dense fluid downward.\n\nIf we place a probe somewhere in the fluid, the joint possibility of an\nupward or downward velocity x leads to a picture that looks like this\n(where r measures the thermal gradient):\n(c) Informa UK Limited. All rights reserved.\nThis content is excluded from our Creative\nCommons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use.\nStrogatz [2], Fig. 3.4.2\nHere, when r is less than a critical value rc, the zero-velocity state is sta\n)1/2\nble; above rc it is unstable and the typical velocity grows like (r - rc\n.\nWe'll look at such situations more generally in the next lecture.\nBut for now, we note that this is an example of a general characteristic of\nnonlinear systems: small changes in parameters can lead to qualitatively\ndifferent behavior.\n- Fluid dynamics more generally:\nu(x)\nu(x+dx)\nThe fluid velocity ~u(~x) changes in part because the fluid flows; i.e.,\n~u(~x) → ~u(~x + d~x)\nBut ~u also governs how fast this change occurs. Therefore d~u/dt depends\nnonlinearly on u, and includes a change like\n(~u · r)~u ∼ u\ni.e., a particle moves at velocity ~u along a velocity gradient r~u to a place\nwhere the velocity is different.\nWhen this nonlinearity is weak (because u is small), flow is smooth and\nlaminar. When it is stronger, flow becomes turbulent.\n- Climate. The climate \"system' involves fluids, convection, and perhaps\nthe most nonlinear system of all: life. So it is unquestionably nonlinear.\n\nBut is it unstable? There are many known--and unknown--positive\nfeedbacks. And plenty of examples of abrupt climate change in the past.\nUnderstanding the methods and concepts in this course is a necessary\nfirst step toward determining whether climate \"tipping points\" exist.\n- Social systems (e.g., political or economic). The same general remarks\nhold.\n1.2.2\nDissipative systems\nIn dissipative systems, energy input to a system is eventually balanced by\nfriction. The resulting \"steady state,\" a kind of \"attractor\" is sometimes\nquite simple.\nBut we shall see that the combination of nonlinearity and dissipation can lead\nto strange attractors, on which there is sensitivity to initial conditions.\nThe overall idea is that small changes in initial conditions lead to large\nchanges in the long term.\nThe classic example is the weather, explained first, in 1963, by MIT professor\nEdward Lorenz.\nLorenz's discovery was eventually termed the \"butterfly effect\": a butterfly\nthat flaps its wings in, say, Brazil, can affect, at a later time (in principle)\nthe weather in New York.\nThis deterministic unpredictability we call chaos.\nThe idea has now entered the cultural mainstream. But this course shows\nthat the notion of chaos in dissipative systems is really quite non-intuitive:\nwe'll understrand why it is possible for a system to be attracted to a statisti\n\ncally steady state--its attractor--regardless of initial conditions, while being\nsensitive to to initial conditions on the attractor.\n1.3\nCourse goals\nWe teach:\n- Elementary aspects of the theory of nonlinear dynamics and chaos.\n- Phenomenology (e.g., aspects of fluid turbulence, scaling laws, experi\nmental phenomena).\n- Computer experimentation.\n- Analysis of experimental data.\nOur computational experiments are exploratory. Rather than focusing on\nthe computation of a specific quantity (e.g., some integral), we construct\nsimple models and compute their evolution to determine qualitative aspects\nof dynamics.\nThese qualitative dynamics are often quite general and apply to a wide array\nof problems in science and engineering.\nThus a major goal of the course is for students to learn why such wide-ranging\napplicability exists in problems that may superficially appear quite different.\n1.4\nAdministrative details\n- TA: Constantin Arnscheidt.\n- All course materials will be available on Canvas.\n- Prereqs: Must know o.d.e.'s (18.03). Some linear algebra (e.g., eigenval\nues and eigenvectors).\n- Problem sets: Some analytic, some require numerical simulation.\n\n- We usually provide Matlab and Python codes, but modifications are\noften necessary. Only rudimentary coding skills are required, and they\ncan be learned in this course.\n- The objective of the numerical experiments is to impart a sense of dis\ncovery in the exploration of dynamical systems and comparison with\ntheoretical predictions (in the spirit of Lorenz and Feigenbaum).\n- Students with no experience in numerical computation may wish to con\nsult the TA for assistance.\n- Requirements\n- No exams.\n- There will be about 9 problem sets.\n- A final project: either a review of a topic in the literature, your own\nattempt to apply or extend what you've learned to a problem that\ninterests you, or a combination of both. A written report will be\ndue in the last class (Dec. 13), at which time students will also give\nbrief presentations. You should choose your topic by Nov. 8, and\nsubmit it for approval. Further guidelines will be given.\n- Problems sets count for about 80% of the grade and the final project\nabout 20%.\n- The first pset is due next Thursday. It is easy, but we want to be sure\nthat everyone is comfortable with the (modest) numerical computation.\n1.5\nSyllabus\n1. Elementary nonlinear dynamics and its empirical analysis\n(a) Flows and bifurcations in 1D.\n(b) Oscillators, phase space, stability, conservation/contraction of areas\nin phase space,\n(c) Limit cycles, Hopf bifurcations, excitability\n(d) Power spectra, autocorrelations, Poincar e sections, maps (e.g., xk+1 =\nf(xk)). Phase space reconstruction.\n\n(e) Fluid dynamics and Rayleigh-B enard (thermal) convection.\n2. Deterministic chaos in low-dimensional systems.\n(a) Strange attractors. Sensitivity to initial conditions. Lorenz attrac\ntor, H enon attractor, etc.\n(b) Quantifying chaos (\"measuring the strangeness of strange attrac\ntors\").\ni. Fractal dimension (how many \"degrees of freedom\"?; dynamics\nbecomes geometry).\nii. Lyaponov exponents (How sensitive to initial conditions?).\n(c) Transitions to chaos, scaling and universality.\ni. Period doubling. Oscillations of successively longer periods 2n\noccur when the control parameter has value μn, with\n(μinf- μn) ∝ δ-n\nwhere the system is chaotoc at μinf and δ = 4.669... is universal.\nii. Intermittency.\niii. Quasiperiodicity.\nThe second half of the course stresses the relations between pde's, ode's,\nand discrete mapping. We shall see that much of the complexity of non\nlinear pde's is contained in simple 1-D maps!\n3. Remaining time (if any): physical models of scale invariance (fractals)\nin nature.\n1.6\nCourse material\nStrongly recommended: Strogatz [2]. Beautifully written. Only a few lectures\nwill follow it in detail, but nearly all the subjects we cover are addressed in\nthe book. PDF is downloadable from the MIT Library.\nAll of our lectures will be accompanied by detailed lecture notes that will be\nposted to the Canvas website before or shortly after the lecture.\n\n1.7\nStudents\nWho should take this course?\n- Scientists and engineers who desire to learn how and why nonlinearity\nmanifests itself in natural systems.\n- Mathematicians who seek a scientific, physical, and phenomenological\ninspiration for the further development of mathematical theory.\n- Anyone interested in how one \"does science\" with computers.\n1.8\nHandouts and further reading\nYou should have\n- Guidelines\n- Syllabus\n- Problem Set 1. Much easier than usual, just to get started, and an op\nportunity to resolve now any technical problems with Python or Matlab.\nAlso: For general background, read Chapter 1 of Strogatz.\nReferences\n1. Campbell, D. K. Nonlinear science. Los Alamos Science 15, 218-262\n(1987).\n2. Strogatz, S. Nonlinear Dynamics and Chaos: With Applications to Physics,\nBiology, Chemistry, and Engineering (CRC Press, 2018).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lecture 19: Introduction to Strange Attractors",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec19.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nOctober 31, 2022\nContents\nIntroduction to strange attractors\n1.1\nDissipation and attraction . . . . . . . . . . . . . . . . . . . .\n1.2\nAttractors with d = 2 . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nAperiodic attractors\n. . . . . . . . . . . . . . . . . . . . . . .\n1.4\nExample: R ossler attractor . . . . . . . . . . . . . . . . . . . .\n1.5\nConclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nIntroduction to strange attractors\nReferences: Berg e et al. [1], Strogatz [2], Abraham and Shaw [3]\nThus far, we have studied classical attractors: fixed points and limit cycles.\nIn this lecture we begin our study of strange attractors. We emphasize their\ngeneric features.\n1.1\nDissipation and attraction\nOur studies of oscillators have revealed explicitly how forced systems can\nreach a stationary (yet dynamic) state characterized by an energy balance:\naverage energy supplied = average energy dissipated\nAn example is a limit cycle:\n\nθ\nθ\nInitital conditions inside or outside the limit cycle always evolve to the limit\ncycle.\nLimit cycles are a specific way in which\ndissipation ⇒attraction.\nMore generally, we have an n-dimensional flow\nd\ndtx(t) = F[x(t)],\nx ∈Rn\n(1)\nAssume that the flow x(t) is dissipative, with attractor A.\nProperties of the attractor A:\n- A is invariant with flow (i.e., it does not change with time).\n- A is contained within B, the basin of attraction. B is that part of phase\nspace from which all initial conditions lead to A as t →inf:\nA\nB\n- A has dimension d < n.\nConsider, for example, the case of a limit cycle:\n\nθ\nθ\nΓ\nThe surface Γ is reduced by the flow to a line segment on the limit cycle\n(the attractor). Here\nd = attractor dimension = 1\nn = phase-space dimension = 2.\nThis phenomenon is called reduction of dimensionality.\nConsequence: loss of information on initial conditions.\nWe have already quantified volume contraction. Given an initial volume V\nevolving according to the flow (1), the Lie derivative tells us that V changes\nas\nV\ndV\ndt = ∇· x =\nn\nX\ni\n∂ xi\n∂xi\nAs we showed earlier, dissipation yields volume contraction; i.e.,\ndV\ndt < 0.\nConsequently, the attractor cannot have n-dimensional volumes, so d < n.\nWhat, then, is the dimension of the attractor?\nWe proceed by example, by considering the case d = 2.\n1.2\nAttractors with d = 2\nWhat happens when d (the dimension of the attractor) is 2?\n\nAssume a quasiperiodic attractor on a torus T 2:\nω\nω\nC\nCut the torus on a small circle C and open it:\nA\nB\nA'\nB'\nFinally, cut the long way, from A to A′, and open it again:\nω1t\nω2t\nA\nA'\nB\nB'\n2π\n2π\nNote the parallel trajectories.\nAs usual, the quasiperiodic flows are characterized by two cases:\nω1/ω2 rational or irrational.\n- Rational. Consider, e.g., ω1/ω2 = 1/3:\nω1t\nω2t\n'\n2π\n2π\n\nThe trajectory repeats itself exactly every three times around the 2-axis,\nor each time around the 1-axis.\n- Irrational.\nω1t\nω2t\n'\n2π\n2π\nThe trajectories densely fill the plane.\nDeterminism forbids non-parallel trajectories, because they would cross:\nω1t\nω2t\n'\n2π\n2π\nThus a torus T 2 can only be a periodic or quasiperiodic attractor.\nThe attractor cannot be aperiodic if d = 2.\n1.3\nAperiodic attractors\nWe have already shown that the power spectrum of an aperiodic signal x(t)\nis continuous:\nxk 2\nk\n\nAnd the autocorrelation Ψm = ⟨xjxj+m⟩has finite width:\nΨm\nm\nThe finite width of Ψm implies that knowledge of no finite interval of x(t)\nallows prediction of all future x(t).\nThis \"unpredictability\" is associated with what we call \"chaos.\" We seek,\nhowever, a more precise definition of chaos.\nOn an aperiodic attractor, small differences in initial conditions on the at-\ntractor lead at later times to large differences, still on the attractor.\nIn phase space, trajectories on an aperiodic attractor can diverge, e.g.,\nWe shall see that the divergence of trajectories is exponential in time.\nThis phenomenon is called sensitivity to initial conditions (SIC). It defini-\ntively identifies chaos, i.e., a chaotic attractor.\nNote that, despite the precision of this definition, we are left with an apparent\nconundrum: simultaneously we have\n- attraction, such that trajectories converge.\n- sensitivity to initial conditions, such that trajectories diverge.\nThe conundrum is solved by noting that trajectories converge to the attractor,\n\nbut diverge on the attractor.\nNote further that divergence on the attractor implies that the attractor di-\nmension\nd > 2,\nsince phase tractories cannot diverge in two dimensions.\nThus we conclude that an aperiodic (chaotic) attractor must have phase space\ndimension\nn ≥3.\nAssume n = 3. How may trajectories converge, but still remain bounded on\nan attractor?\nThe trajectories are successively stretched (by SIC) and folded (thus remaining\nbounded).\n1.4\nExample: R ossler attractor\nWe use drawings [3] of the R ossler attractor to illustrate how this works:\nAbraham & Shaw [3]\n- Trajectories diverge in plane by spiralling out (stretching).\n- Trajectories leave plane.\n- Trajectories return to plane (folding), back to center of spiral.\nSee image credit on Page 12.\n\nAt the same time, we must have volume contraction. One dimension can\nexpand while another contracts:\nAbraham & Shaw [3]\nLet's consider the stretching and folding in more detail. The R ossler\nattractor reads\nx = -y -z\ny = x + ay\nz = b + z(x -c)\nwhere we assume\na > 0.\nAssume z and z are small. Then in the x, y plane the system is\napproximated by\nx = -y\ny = x + ay.\nThen\nx = - y = -x + a x\nyielding the negatively damped oscillator\nx -a x + x = 0.\nConsequently the trajectories spiral out of the origin.\nHow is the spreading confined? From the equation for z, we see that, for\nsmall b,\nx < c ⇒\nz < 0\nx > c ⇒\nz > 0\nThus we expect trajectories to behave as follows:\nSee image credit on Page 12.\n\n- Divergence from the origin creates x > c.\n- x > c ⇒z increases ⇒x decreases.\n- Eventually x decreases such that x < c.\n- Then x < c ⇒z decreases ⇒back in the x, y plane.\n- The process repeats.\nThus we have\n- stretching, from the outward spiral; and\n- folding, from the feedback of z into x.\nA sequence of figures shows how endless divergence occurs in bounded space.\nFirst, let's zoom in on the stretching:\nAbraham & Shaw [3]\nThen the attractor folds:\nAbraham & Shaw [3]\nTrajectories never close exactly as a surface, but more like filo dough:\nSee image credit on Page 12.\nSee image credit on Page 12.\n\nAbraham & Shaw [3]\nAnother iteration of stretching and folding looks like this:\nAbraham & Shaw [3]\nAnd again:\nAbraham & Shaw [3]\nSee image credit on Page 12.\nSee image credit on Page 12.\nSee image credit on Page 12.\n\nEach time we stretch and fold, we create layers of layers. And when we slice\nit with a Poincar/'e section, we would see gaps within gaps, and thus a\nfractal object.\nAbraham & Shaw [3]\nWe'll say more about this later, after we describe its earliest observation in\nthe Lorenz attractor.\n1.5\nConclusion\nWe arrive at the following conclusions:\n- Aperiodic attractors must have\nd > 2.\n- Since dissipation contracts volumes,\nd < n,\nwhere n is the dimension of the phase space.\n- Suppose n = 3. Then a chaotic attractor must have\n2 < d < 3.\nSee image credit on Page 12.\n\nHow can 2 < d < 3? The attractor has a fractional, or fractal dimension.\nWe shall look more closely at this later.\nFor now, we conclude that chaotic attractors have three properties:\n- Attraction\n- Sensitivity to initial conditions\n- Non-integer fractal dimension\nThe combination of these three properties defines a strange attractor. The\n\"strangeness\" arises not so much from each individual property but their\ncombined presence.\nNext we study the most celebrated strange attractor--the Lorenz attractor.\nReferences\n1.\nBerg e, P., Pomeau, Y. & Vidal, C. Order within Chaos: Towards a De-\nterministic Approach to Turbulence (John Wiley and Sons, New York,\n1984).\n2.\nStrogatz, S. Nonlinear Dynamics and Chaos: With Applications to Physics,\nBiology, Chemistry, and Engineering (CRC Press, 2018).\n3.\nAbraham, R. H. & Shaw, C. D. Dynamics-The Geometry of Behavior:\nPart 2: Chaotic Behavior (Aerial Press, Incorporated, 1984).\nImage Credit\nImages on Pages 7-11 from Abraham, R. H. & Shaw, C. D. Dynamics-The Geometry of\nBehavior: Part 2: Chaotic Behavior (Aerial Press, Incorporated, 1984). (c) Aerial Press. All\nrights reserved. This content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lecture 22: Henon Attractor",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec22.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nNovember 14, 2022\nContents\nH enon attractor\n1.1\nThe H enon map . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nDissipation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nNumerical simulations\n. . . . . . . . . . . . . . . . . . . . . .\nH enon attractor\nReferences: [1-3]\nThe chaotic phenomena of the Lorenz equations may be exhibited by even\nsimpler systems.\nWe now consider a discrete-time, 2-D mapping of the plane into itself. The\npoints in R2 are considered to be the the Poincar e section of a flow in higher\ndimensions, say, R3.\nThe restriction that d > 2 for a strange attractor does not apply, because\nmaps generate discrete points; thus the flow is not restricted by continuity\n(i.e., lines of points need not be parallel).\n1.1\nThe H enon map\nThe discrete time, 2-D mapping of H enon is\nXk+1 = Yk + 1 -αX2\nk\nYk+1 = βXk\n\n- α controls the nonlinearity.\n- β controls the dissipation.\nPictorially, we may consider a set of initial conditions given by an ellipse:\nX\nY\nNow bend the elllipse, but preserve the area inside it (we shall soon quantify\narea preservation):\nMap T1 :\nX′ = X\nY ′ = 1 -αX2 + Y\nX'\nY'\nNext, contract in the x-direction (|β| < 1)\nMap T2 :\nX′′ = βX′\nY ′′ = Y ′\nX''\nY''\nFinally, reorient along the x axis (i.e. flip across the diagonal).\nMap T3 :\nX′′′ = Y ′′\nY ′′′ = X′′\nX'''\nY'''\n\nThe composite of these maps is\nT = T3 *T2 *T1.\nWe readily find that T is the H enon map:\nX′′′ = 1 -αX2 + Y\nY ′′′ = βX\n1.2\nDissipation\nThe rate of dissipation may be quantified directly from the mapping via the\nJacobian.\nWe write the map as\nXk+1 = f(Xk, Yk)\nYk+1 = g(Xk, Yk)\nInfinitesimal changes in mapped quantities as a function of infinitesimal\nchanges in inputs follow\ndf = ∂f\n∂Xk\ndXk + ∂f\n∂Yk\ndYk\nWe may approximate, to first order, the increment ∆Xk+1 due to small in-\ncrements (∆Xk, ∆Yk) as\n∆Xk+1 ≃∂f\n∂Xk\n∆Xk + ∂f\n∂Yk\n∆Yk\nWhen (∆Xk, ∆Yk) are perturbations about a point (x0, y0), we have, to first\norder,\n∆Xk+1\n∆Yk+1\n\n=\nf ′\nXk(x0, y0) f ′\nYk(x0, y0)\ng′\nXk(x0, y0) g′\nYk(x0, y0)\n∆Xk\n∆Yk\n\n.\nRewrite simply as\n∆x′\n∆y′\n\n=\na b\nc d\n∆x\n∆y\n\n.\n\nGeometrically, this system describes the transformation of a rectangular area\ndetermined by the vertex (∆x, ∆y) to a parallelogram as follows:\nx\ny\n∆y\n∆x\n∆y\n∆x\n∆x ∆y\n(\n∆x ∆y\n(\n(b,d)\nx\ny\n,\n(a,c)\n)\n,\n')\n'\nHere we have taken account of transformations like\n(∆x, 0) →(a∆x, c∆x)\n(0, ∆y) →(b∆y, d∆y)\nIf the original rectangle has unit area (i.e., ∆x∆y = 1), then the area of the\nparallelogram is given by the magnitude of the cross product of (a, c) and\n(b, d), or, in general, the Jacobian determinant\nJ =\n\na b\nc d\n=\n\n∂Xk+1\n∂Xk\n∂Xk+1\n∂Yk\n∂Yk+1\n∂Xk\n∂Yk+1\n∂Yk\n\n(x0,y0)\nTherefore\n|J| > 1\n=⇒\ndilation\n|J| < 1\n=⇒\ncontraction\nFor the H enon map,\nJ =\n\n-2αXk 1\nβ\n= -β\nThus areas are multipled at each iteration by |β|.\nAfter k iterations of the map, an initial area a0 becomes\nak = a0|β|k.\n\n1.3\nNumerical simulations\nH enon chose α = 1.4, β = 0.3. The dissipation is thus considerably less than\nthe factor of 10-6 in the Lorenz model.\nThe attractor:\n-1.0\n-0.5\n0.5\n1.0\nx\n-0.4\n-0.2\n0.2\n0.4\ny\nSensitivity to initial conditions:\n50 k\n10-6\n10-5\n10-4\n0.001\n0.010\n0.100\ndistance\nThe weak dissipation allows one to see the fractal structure induced by the\nrepetitive folding:\n-1.0\n-0.5\n0.5\n1.0\nx\n-0.4\n-0.2\n0.2\n0.4\ny\n0.56 0.58 0.60 0.62 0.64 0.66 0.68 0.70x\n0.15\n0.16\n0.17\n0.18\n0.19\n0.20\ny\n0.6260.6280.6300.6320.6340.6360.6380.640x\n0.185\n0.186\n0.187\n0.188\n0.189\n0.190\n0.191\ny\n0.63060.63080.63100.63120.63140.63160.63180.6320\nx\n0.1889\n0.1890\n0.1891\n0.1892\n0.1893\n0.1894\n0.1895\ny\n\nNote the apparent scale-invariance: at each magnification of scale, we see\nthat the upper line is composed of 3 separate lines.\nThe fractal dimension D = 1.26. (We shall soon discuss how this is com-\nputed.)\nThe action of the H enon map near the attractor is evident in the deformation\nof a small circle of initial conditions on the attractor:\nRef. [2], Figure VI.22\nThe circle stretches in one dimension, by a factor Λ1, and is compressed in\nthe other, by a factor Λ2. While we don't know Λ1 and Λ2, we do know their\nproduct: Λ1Λ2 = β.\nThe larger of the two Λ's is related to the exponential rate at which the\nseparation of two initial conditions grows.\nAt the larger scale of the attractor itself (A), we can see the combined effects\nof stretching and folding (B and C):\nRef. [2], Figure VI.23\nBoth images on this page (c) John Wiley & Sons, Inc. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.\n\nReferences\n1.\nH enon, M. A two-dimensional mapping with a strange attractor. Com-\nmun. Math. Phys. 50, 69-77 (1976).\n2.\nBerg e, P., Pomeau, Y. & Vidal, C. Order within Chaos: Towards a De-\nterministic Approach to Turbulence (John Wiley and Sons, New York,\n1984).\n3.\nStrogatz, S. Nonlinear Dynamics and Chaos: With Applications to Physics,\nBiology, Chemistry, and Engineering (CRC Press, 2018).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lecture 23: Fractal Dimension",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec23.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nNovember 14, 2022\nContents\nFractals\n1.1\nDefinition . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nCorrelation dimension ν\n. . . . . . . . . . . . . . . . . . . . .\n1.3.1\nDefinition . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3.2\nComputation\n. . . . . . . . . . . . . . . . . . . . . . .\n1.4\nRelationship of ν to D . . . . . . . . . . . . . . . . . . . . . .\nFractals\nReferences: [1-4]\nWe now proceed to quantify the \"strangeness\" of strange attractors. There\nare two processes of interest, each associated with a measurable quantity:\n- sensitivity to initial conditions, quantified by Lyaponov exponents.\n- repetitive folding of attractors, quantified by the fractal dimension.\nNow we consider fractals, and defer Lyaponov exponents to the next lecture.\nWe shall see that the fractal dimension can be associated with the effective\nnumber of degrees of freedom that are \"excited\" by the dynamics, e.g.,\n- the number of independent variables;\n- the number of oscillatory modes; or\n- the number of peaks in the power spectrum\n\n1.1\nDefinition\nConsider an attractor A formed by a set of points in a p-dimensional space:\netc\nε\nWe contain each point within a (hyper)-cube of linear dimension ε.\nLet N(ε) = smallest number of cubes of size ε needed to cover A.\nThen if\nN(ε) = Cε-D,\nas ε →0,\nC = const.\nthen D is called the fractal (or Hausdorf ) dimension.\nSolve for D (in the limit ε →0):\nD = ln N(ε) -ln C\nln(1/ε)\n.\nSince ln C/ ln(1/ε) →0 as ε →0, we obtain the formal definition\nD = lim\nε→0\nln N(ε)\nln(1/ε).\n1.2\nExamples\nSuppose A is a line segment of length L:\nL\nThen the \"boxes\" that cover A are just line segments of length ε, and it is\nobvious that\nN(ε) = Lε-1 =⇒D = 1.\n\nNext suppose A is a surface or area S. Then\nN(ε) = Sε-2 =⇒D = 2.\nBut we have yet to learn anything from D.\nConsider instead the Cantor set. Start with a unit line segment:\nThe successively remove the middle third:\n1/3\n2/3\n1/9\n2/9\netc\netc\nNote that the structure is scale-invariant: from far away, you see the middle\n1/3 missing; closer up, you see a different middle 1/3 missing.\nThe effect is visually similar to that seen in the Lorenz, H enon, and R ossler\nattractors.\nThe fractal dimension of the Cantor set is easily calculated from the definition\nof D:\nObviously,\nN\n\nε = 1\n\n= 2\nThen\nN\n\nε = 1\n\n= 4\nN\n\n= 8 . . .\nThus\nN\n3m\n\n= 2m.\nTaking ε = 1/3 and using the definition of D,\nD = lim\nm→inf\nln 2m\nln 3m = ln 2\nln 3 ≃0.63\n\n1.3\nCorrelation dimension ν\nWe proceed now to an alternative procedure for the calculation of the fractal\ndimension, which offers additional (physical) insight.\nRather than calculating the fractal dimension via its definition, we calculate\nthe correlation dimension ν.\nWe shall show that ν ≤D. But first we define it.\n1.3.1\nDefinition\nConsider a set of points distributed on a plane.\nLet N(r) = number of points located inside a circle of radius r.\nAssume the points are uniformly distributed on a curve like\nr\nFor r sufficiently small compared to the curvature of the curve, we have\nN(r) ∝r\nor\nN(r) ∝rν,\nν = 1.\nNow assume the points are uniformly distributed along a surface in two di-\nmensions:\nr\n\nNow\nN(r) ∝r2 =⇒ν = 2.\nNext, reconsider the Cantor set:\nr\nWe expect that N(r) will grow more slowly than r.\nIndeed, calculations show that ν ≃0.63 = D, just as before.\n1.3.2\nComputation\nOur implicit definition of ν is clearly generalized by considering\n- an attractor in a p-dimensional space, and\n- N(r) = number of points in a p-dimensional hypersphere of radius r.\nFor a time series x(t), we reconstruct a p-dimensional phase space with the\ncoordinates\nx(t), x(t + τ), x(t + 2τ), . . . x(t + (p -1)τ) = x(t).\nSuppose there are m points on the attractor. We quantify the spatial corre-\nlation of these points by defining\nC(r) = lim\nm→inf\nm2 (number of pairs i, j for which |xi -xj| < r) .\nMore formally,\nC(r) = lim\nm→inf\nm2\nm\nX\ni\nm\nX\nj\nH(r -|xi -xj|)\n\nwhere\nH(x) =\n1 x > 0\n0 else.\nThe summation is performed by centering hyperspheres on each of the m\npoints.\nIn practice, one embeds the signal x(t) in a phase space of dimension p, for\np = 2, 3, 4, 5, . . .\np is called the embedding dimension.\nFor each p, we calculate C(r). Then, assuming\nC(r) = rν\nwe plot log C vs. log r and estimating the slope ν:\nslope = ν\nlog r\nlog C(r)\nConsider the example of white noise. Then x(t) is a series of uncorrelated\nrandom numbers, and we expect\nC(r) ∝rp,\np = embedding dimension.\nGraphically, one expect a series of plots like\nlog r\nlog C(r)\np=\n4 5\n\nHere\nν(p) = p,\na consequence of the fact that white noise has as many degrees of freedom\n(i.e., independent \"modes\") as there are data points.\nConsider instead X(t) = periodic function, i.e., a limit cycle, with only one\nfundamental frequency.\nThen the attractor looks like\np=2\np=3\nProvided that r is sufficiently smaller than the curvature of the limit cycle,\nwe expect\nC(r) ∝r1,\nfor p = 2, 3, 4, . . .\nGraphically, we obtain\nlog r\nlog C(r)\np= 2\nand therefore\nν(p) = 1,\nindependent of p.\nWe conclude that ν measures something related to the \"number of degrees\nof freedom\" needed to parameterize an attractor.\nSpecifically, suppose a dynamical regime has n oscillatory modes. The at-\n\ntractor is then a torus T n, and we expect\nC(r) ∝rn.\nThus\np ≤n =⇒C(r) ∝rp\nand\np > n =⇒C(r) ∝rn,\nindependent of p.\nConclusion: If, for embedding dimensions p ≥p0, ν is independent of p, then\nν is the number of degrees of freedom excited by the system.\nThis conclusion provides for an appealing conjecture: since white noise gives\nν(p) = p,\nν independent of p (and reasonably small) implies that the signal is deter-\nministic, and characterizable by ∼ν variables.\nThere are some practical limitations:\n- r must be small compared to the attractor size.\n- r and m must be large enough for reasonable statistics.\n- Experimental noise, non-stationary time series, and difficulties extrapo-\nlating r →0 can also be a problem.\n1.4\nRelationship of ν to D\nThe correlation dimension is not strictly the same as the fractal dimension,\nhowever it can be. We now derive their mathematical relation.\nSuppose we cover an attractor A with N(r) hypercubes of size r.\nIf the points are uniformly distributed on A, the probability that a point falls\ninto the ith hypercube is\npi = 1/N(r).\n\nBy definition, for an attractor containing m points,\nC(r) = lim\nm→inf\nm2\nm\nX\ni\nm\nX\nj\nH(r -|xi -xj|),\nH(x) =\n1 x > 0\nelse\nC(r) measures the number of pairs of points within a distance r of each other.\nIn a box of size r, there are on average mpi points, all within the range r.\nTherefore, within a factor of O(1) (i.e., ignoring box boundaries and factors of two arising\nfrom counting pairs twice),\nC(r) ≃\nm2\nN(r)\nX\ni=1\n(mpi)2\n=\nN(r)\nX\ni=1\np2\ni\nThen, using angle brackets to represent mean quantities, we have, from\nSchwartz's inequality,\nC(r) = N(r) ⟨p2\ni⟩≥N(r) ⟨pi⟩2 =\nN(r).\nIf the attractor has fractal dimension D, then\nN(r) ∝r-D,\nr →0.\nThe definition of the correlation dimension ν, on the other hand, gives\nC(r) ∝rν.\nSubstituting these relations into both sides of the inequality, we find\nrν ≥rD\nThus as r →0, we see that\nν ≤D\nThe equality is obtained when ⟨p2\ni⟩= ⟨pi⟩2.\nThus ν < D results from non-uniformity of points on the attractor.\n\nReferences\n1.\nGrassberger, P. & Procaccia, I. Measuring the strangeness of strange at-\ntractors. Physica D 9, 189-208 (1983).\n2.\nBerg e, P., Pomeau, Y. & Vidal, C. Order within Chaos: Towards a De-\nterministic Approach to Turbulence (John Wiley and Sons, New York,\n1984).\n3.\nGrassberger, P. Grassberger-Procaccia algorithm. Scholarpedia 2. revi-\nsion #91330, 3043 (2007).\n4.\nStrogatz, S. Nonlinear Dynamics and Chaos: With Applications to Physics,\nBiology, Chemistry, and Engineering (CRC Press, 2018).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lecture 24: Lyapunov Exponents",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec24.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nNovember 16, 2022\nContents\nLyapunov exponents\n1.1\nSensitivity to initial conditions in a chemical reaction . . . . .\n1.2\nDiverging trajectories . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nExample 1: time-independent Jacobian . . . . . . . . . . . . .\n1.4\nExample 2: time-dependent eigenvalues . . . . . . . . . . . . .\n1.5\nNumerical evaluation . . . . . . . . . . . . . . . . . . . . . . .\n1.6\nLyaponov exponents and attractors in 3-D . . . . . . . . . . .\n1.7\nSmale's horseshoe attractor\n. . . . . . . . . . . . . . . . . . .\nLyapunov exponents\nReferences: [1, 2]\nWhereas fractals quantify the geometry of strange attractors, Lyaponov ex-\nponents quantify their sensitivity to initial conditions.\nIn this lecture we broadly sketch some of the mathematical foundations of\nLyaponov exponents. We also briefly describe how they are obtained numer-\nically.\nWe conclude by showing how both fractals and Lyaponov exponents manifest\nthemselves in a simple model.\n1.1\nSensitivity to initial conditions in a chemical reaction\nWe begin by showing how the tools we have developed thus far allow us to\nvisualize sensitivity to initial conditions in time series data.\n\nWe consider data obtained in a nonlinear chemical reaction known as the\nBelousov-Zhabotinsky reaction [3]. Here the essential control parameter is\nthe rate at which reactants flow into a reactor, and the time series obtained\nmeasures the instantaneous concentrations of certain species.\nFor certain values of the flow rate, the time series appears quasiperiodic but\nits spectrum is broad. Phase space reconstruction by the method of delays\nyields a picture like this:\nReferences [1, 3]\nNow let's follow all trajectories that come very close to the lower left-corner\nof the plot (O), and watch how they spread for equal amounts of additional\ntime (A, B, and C):\nReferences [1, 3]\nBoth images on this page (c) John Wiley & Sons, Inc. and (c) Springer Nature. All rights reserved.\nThis content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use.\n\nWe proceed to show how why, in general, the divergence of trajectories is\nexponential.\n1.2\nDiverging trajectories\nLyapunov exponents measure the rate of divergence of trajectories on an\nattractor.\nConsider a flow φ(t) in phase space, given by\ndφ\ndt = F(φ)\nIf instead of initiating the flow at φ(0), it is initiated at φ(0)+ε(0), sensitivity\nto initial conditions would produce a divergent trajectory:\nφ(0)\nφ(\nε(0)\nε(t)\nt)\nHere |ε| grows with time. To first order,\nd(φ + ε)\ndt\n≃F(φ) + M(t) ε\nwhere\nMij(t) = ∂Fi\n∂φj\nφ(t)\n.\nWe thus find that\ndε\ndt = M(t) ε.\n(1)\nConsider the example of the Lorenz model. The Jacobian M is given by\nM(t) =\n\n-P\nP\n-Z(t) + r\n-1\n-X(t)\nY (t)\nX(t)\n-b\n\n.\nThe sensitivity to initial conditions is obvious.\n\nWe cannot solve for ε because of the unknown time dependence of M(t).\nHowever one may numerically solve for φ(t), and thus ε(t), to obtain (for-\nmally)\nε(t) = L(t) ε(0).\n1.3\nExample 1: time-independent Jacobian\nConsider a simple 3-D example in which M is time-independent.\nAssume additionally that the phase space coordinates correspond to M's\neigenvectors.\nThen M is diagonal and\nL(t) =\n\neλ1t\neλ2t\neλ3t\n\nwhere the λi are the eigenvalues of M. (Recall that if ε = Mε, then ε(t) = eMtε(0),\nwhere, in the coordinate system of the eigenvectors, eMt = L(t).)\nAs t increases, the eigenvalue with the largest real part dominates the flow\nε(t).\nTo express this formally, let L∗be the conjugate (Hermitian) transpose of L,\ni.e.\nL∗\nij = Lji.\nAlso let\nTr(L) = diagonal sum =\nX\ni=j\nLij.\nThen\nTr[L∗(t)L(t)] = e(λ1+λ∗\n1)t + e(λ2+λ∗\n2)t + e(λ3+λ∗\n3)t\nDefine\nλ = lim\nt→inf\n2t ln\n\nTr[L∗(t)L(t)]\n\nλ is the largest Lyapunov exponent. Its sign is crucial:\nλ < 0\n=⇒\nε(t) decays exponentially\nλ > 0\n=⇒\nε(t) grows exponentially.\n1.4\nExample 2: time-dependent eigenvalues\nNow suppose that M(t) varies with time in such a way that only its eigen-\nvalues, but not its eigenvectors, vary.\nLet\nφ =\n\nX(t)\nY (t)\nZ(t)\n\nand consider small displacements δX(t), δY (t), δZ(t) in the reference frame\nof the eigenvectors.\nThen, analogous to equation (1), and again assuming that phase space coor-\ndinates correspond to M's eigenvectors,\n\nδ X(t)\nδ Y (t)\nδ Z(t)\n\n=\n\nA[φ(t)]\nB[φ(t)]\nC[φ(t)]\n\nδX(t)\nδY (t)\nδZ(t)\n\n.\nHere A, B, C are the time-dependent eigenvalues (assumed to be real).\nThe solution for δX(t) is\nδX(t) = δX(0) exp\nZ t\ndt′A[φ(t′)]\n\nRearranging and dividing by t,\nt ln\n\nδX(t)\nδX(0)\n= 1\nt\nZ t\ndt′A[φ(t′)]\nThe RHS represents the time-average of the eigenvalue A. We assume that\nfor sufficiently long times this average is equivalent to an average of A for all\npossible flows φ evaluated at the same time.\n\nIn other words, we assume that the flow is ergodic.\nWe denote this average by angle brackets:\n⟨A⟩= φ-average of A[φ(t)]\n= time-average of A[φ(t)]\n=\nlim\nt→inf\nt\nZ t\ndt′A[φ(t′)]\n=\nlim\nt→inf\nt ln\n\nδX(t)\nδX(0)\n\n⟨A⟩is one of the three Lyapunov exponents for φ(t).\nMore sophisticated analyses show that the theory sketched above applies to\nthe general case in which both eigenvectors and eigenvalues vary with time.\n1.5\nNumerical evaluation\nLyaponov exponents are almost always evaluated numerically.\nThe most obvious method is the one used in the problem sets: For some ε(0),\nnumerically evaluate ε(t), and then find λ such that\n|ε(t)| ≃|ε(0)|eλt.\nThis corresponds to the definition of ⟨A⟩above.\nA better method avoids saturation at the size of the attractor by successively\naveraging small changes over the same trajectory:\nε(0)\nφ(0)\nφ(τ)\nφ(2τ)\nε(2τ)\nε(τ)\n\nHere ε is renormalized at each step such that\nε(τ) = ε(0)eγ1τ\nε(2τ) =\nε(τ)\n|ε(τ)|eγ2τ\nThe largest Lyaponov exponent is given by the long-time average:\nλ = lim\nn→inf\nn\nn\nX\ni=1\nγi = lim\nn→inf\nnτ\nn\nX\ni\nln |ε(iτ)|\nExperimental data poses greater challenges, because generally we have only\na single time series X(t).\nOne way is to compare two intervals on X(t), say\n[t1, t2]\nand\n[t′\n1, t′\n2],\nwhere X(t) is nearly the same on both intervals.\nThen the comparison of X(t) beyond t2 and t′\n2 may yield the largest Lyaponov\nexponent.\nAnother way is indicated in Section 1.1: after reconstruction of phase space\nby, say, the method of delays, all trajectories that pass near a certain point\nmay be compared to see the rate at which they diverge.\n1.6\nLyaponov exponents and attractors in 3-D\nConsider an attractor in a 3-D phase space. There are 3 Lyaponov exponents.\nTheir signs depend on the type of attractor:\nType\nSigns of Lyapunov exponents\nFixed point\n(-, -, -)\nLimit cycle\n(-, -, 0)\nTorus T 2\n(-, 0, 0)\nStrange attractor\n(-, 0, +)\n\nIf the attractor is a fixed point, all three exponents are negative.\nIf it is a limit cycle with one frequency, only two are negative, and the third\nis zero. The zero-exponent corresponds to the direction of flow--which can\nneither be expanding nor contracting.\nOf the other cases in the table below, the most interesting is that of a strange\nattractor:\n- The largest exponent is, by definition, positive.\n- There must also be a zero-exponent corresponding to the flow direction.\n- The smallest exponent must be negative--and of greater magnitude than\nthe largest, since volumes must be contracting.\n1.7\nSmale's horseshoe attractor\nWe have seen that\n- Lyaponov exponents measure \"stretching.\"\n- Fractal dimensions measure \"folding.\"\nSmale's horseshoe attractor exemplifies both, and allows easy quantification.\nStart with a rectangle:\nA\nB\nD\nC\nStretch by a factor of 2; squash by a factor of 1/(2η), η > 1:\n\nA'\nB'\nC'\nD'\nNow fold like a horseshoe and put back in ABCD:\n1/2η\n1/2η\nA\nB\nD\nC\nNow iterate the process. Stretch and squash:\nFold and place back in ABCD:\n1/(2η)2\nA\nB\nD\nC\nEach dimension is successively scaled by its own multiplier, called a Lyaponov\nnumber:\nΛ1 = 2\n(x -stretch)\nΛ2 =\n2η\n(y -squash)\nArea contraction is given by\nΛ1Λ2 = 1/η.\n\nThe Lyapunov exponents are\nλ1 = ln Λ1\nλ2 = ln Λ2\nNote also that vertical cuts through the attractor appear as the early itera-\ntions of a Cantor set.\nTo obtain the fractal dimension, we use the definition\nD = lim\nε→0\nln N(ε)\nln(1/ε).\nTaking the initial box height to be unity, the ε, N pairs for the number N of\nsegments of length ε required to cover the attractor is\nε\nN\n1/(2η)\n1/(2η)2\n. . .\n. . .\n1/(2η)m\n2m\nTherefore the dimension D of the Cantor set is\nD = ln 2\nln 2η.\nThe dimension D′ of the attractor in the plane ABCD is\nD′ = 1 + ln 2\nln 2η,\nwhere we have neglected the \"bend\" in the horseshoe (i.e., we've assumed\nthe box's width is much greater than its height.\nNote that,\nas η →1,\nD′ →2,\nbecause iterates nearly fill the plane. Conversely,\nas η →inf,\nD′ →1,\nmeaning that the attractor is nearly squashed to a simple line.\n\nReferences\n1.\nBerg e, P., Pomeau, Y. & Vidal, C. Order within Chaos: Towards a De-\nterministic Approach to Turbulence (John Wiley and Sons, New York,\n1984).\n2.\nStrogatz, S. Nonlinear Dynamics and Chaos: With Applications to Physics,\nBiology, Chemistry, and Engineering (CRC Press, 2018).\n3.\nRoux, J. & Swinney, H. L. in Nonlinear Phenomena in Chemical Dynam-\nics 38-43 (Springer, 1981).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lecture 28: Intermittency (and Quasiperiodicity)",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec28.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nDecember 5, 2022\nContents\nIntermittency (and quasiperiodicity)\n1.1\nGeneral characteristics of intermittency . . . . . . . . . . . . .\n1.2\nOne-dimensional map . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nAverage duration of laminar phase\n. . . . . . . . . . . . . . .\n1.4\nLyapunov number . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5\nQuasiperiodicity . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5.1\nAn historical note . . . . . . . . . . . . . . . . . . . . .\n1.5.2\nRuelle-Takens theory . . . . . . . . . . . . . . . . . . .\nIntermittency (and quasiperiodicity)\nReferences: Berg e et al. [1], Pomeau and Manneville [2]\nIn this lecture we discuss the other two generic routes to chaos, intermittency\nand quasiperiodicity.\nAlmost all our remarks will be on intermittency; we close with a brief de-\nscription of quasiperiodicity.\nDefinition: Intermittency is the occurrence of a signal that alternates ran-\ndomly between regular (laminar) phases and relatively short irregular bursts.\nIn the exercises we have already seen examples, particulary in the Lorenz\nmodel (where it was discovered, by Manneville and Pomeau).\nHere it is in the Lorenz model. First, at r = 166, there is a stable limit cycle:\n\n200 t\n-40\n-20\nx(t)\nAt r = 166.1, there are occasional bursts:\n200 t\n-40\n-20\nx(t)\nThe bursts become more frequent at r = 166.3:\n200 t\n-40\n-20\nx(t)\nAnd still more frequent at r = 167:\n200 t\n-40\n-20\nx(t)\nHere is the same phenomena in Rayleigh-B enard convection experiments:\n\nBerg e et al. [3], Fig. 1\nHere, Ra/Rac is 270, 300, and 335 in A, B, and C, respectively.\n1.1\nGeneral characteristics of intermittency\nLet r = control parameter.\nThe following summarizes the behavior with\nrespect to r:\n- For r < ri, system displays stable oscillations (e.g., a limit cycle).\n- For r > ri (r -ri small), system is in the intermittent regime: stable\noscillations are interrupted by fluctuations.\n- As r →ri from above, the fluctuations become increasingly rare, and\ndisappear for r < ri.\n- Only the average intermission time between fluctuations varies, not their\namplitude nor their duration.\nWe seek theories for\n- Linear stability of the limit cycle and \"relaminarization.\" (i.e. return to\nstability after irregular bursts).\n- Scaling law for intermission times.\n- Scaling law for Lyapunov exponents.\n(c) EDP Sciences. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.\n\n1.2\nOne-dimensional map\nWe consider the instability of a Poincar e map due to the crossing of the unit\ncircle at (+1) by an eigenvalue of the Floquet matrix.\nThis corresponds to the specific case of Type I intermittency.\nLet u be the coordinate in the plane of the Poincar e section that points in\nthe direction of the eigenvector whose eigenvalue λ crosses +1.\nThe lowest-order approximation of the 1-D map constructed along this line\nis\nu′ = λ(r)u.\n(1)\nTaking λ(ri) = 1 at the intermittency threshold, we have\nu′ = λ(ri)u = u.\n(2)\nWe consider this to be the leading term of a Taylor series expansion of u′(u, r)\nin the neighborhood of u = 0 and r = ri.\nExpand to first order in (r -ri) and second order in u:\nu′(u, r) ≃u′(0, ri) + u · ∂u′\n∂u\n\n0,ri\n+ 1\n2u2 · ∂2u′\n∂u2\n\n0,ri\n+ (r -ri) ∂u′\n∂r\n\n0,ri\nEvaluating equation (1), we find that the first term vanishes:\nu′(u = 0, r = ri) = 0.\nFrom equation (2), we have\n∂u′\n∂u\n\n0,ri\n= λ(ri) = 1.\nFinally, rescale u such that\n∂2u′\n∂u2\n\n0,ri\n= 1\n\nand set\nε ∝(r -ri).\nThe model now reads\nu′ = u + ε + u2,\nwhere ε is now the control parameter.\nGraphically, we have the following system:\n- ε < 0, i.e. r < ri.\n- u-is stable fixed point.\n- u+ is unstable.\nu-\nu+\nu\nu'\n- ε = 0, i.e. r = ri.\n- u′ is tangent to identity map.\n- u-= u+ = 0 is marginally stable.\nu\nu'\n\n- ε > 0, i.e. r > ri.\n- no fixed points.\nu\nu'\nFor ε < 0, the iterations look like\n- u-is an attractor for initial conditions\nu < u+ .\n- For initial conditions u > u+ , the itera-\ntions diverge.\nu-\nu+\nu\nu'\nThe situation changes for ε > 0, i.e. r > ri:\n- No fixed points.\n- Iterations beginning at u < 0 drift towards\nu > 0.\nu\nu'\nThe fixed points of u′(u) represent stable oscillations of the continuous flow.\nThus for u ≃0, the drift for ε > 0 corresponds to a flow qualitatively similar\nto the stable oscillations near u = 0 for ε < 0.\n\nHowever, when ε > 0, there is no fixed point, and thus no periodic solution.\nThe iterations eventually run away and become unstable--this is the inter-\nmittent burst of noise.\nHow does the laminar phase begin again, or \"relaminarize\"?\nQualitatively, the picture can look like\nu\nu'\nNote that the precise timing of the turbulent burst is unpredictable.\nThe discontinuity is not inconsistent with the presumed continuity of the\nunderlying equations of motion--this is a map, not a flow.\nMoreover the Lorenz map itself contains a discontinuity, corresponding to the\nlocation of the unstable fixed point.\n1.3\nAverage duration of laminar phase\nWhat can we say about the average duration of the laminar phases?\nWriting our theoretical model as a map indexed by k, we have\nuk+1 = uk + ε + u2\nk.\n\nFor uk+1 ≃uk, we can instead write the differential equation\ndu\ndk = ε + u2.\nThe general solution of this o.d.e. is\nu(k) = ε1/2 tan\nh\nε1/2(k -k0)\ni\n.\nTake k0 = 0, the step at which iterations traverse the narrowest part of the\nchannel.\nWe thus have\nu(k) = ε1/2 tan\n\nε1/2k\n\n.\nWe see that u(k) diverges when\nε1/2k = ±π\nor\nk = ±π\n2ε-1/2.\nThe divergence signifies a turbulent burst.\nWhen k ∼ε-1/2, uk+1 -uk is no longer small, and the differential approxi-\nmation of the difference equation is no longer valid.\nThus: if τ = time (∝number of iterations) needed to traverse the channel,\nthen\nτ ∝ε-1/2\nor\nτ ∝(r -ri)-1/2.\n(3)\nThus the laminar phase lasts increasingly long as the threshold r = ri is\napproached from above.\n1.4\nLyapunov number\nWe can also predict a scaling law for the Lyapunov number.\nNear the fixed point (u ≃0, ε > 0), the increment δuk+1 due to an increment\nδuk is, to first order,\nδuk+1 ≃λ1δuk\n\nwhere λ1 is eigenvalue that passes through (+1).\nAfter N iterations,\nδuN ≃λNλN-1λN-2 · · · λ1δu1.\nSuppose N ≃the duration of the laminar phase. Then\nλN > 1\nand\nλN-1 ≃λN-2 ≃· · · ≃λ1 ≃1.\nThe Lyapunov number Λ is\nΛ = 1\nN\nY\ni\nλi ≃λN\nN ∝1\nN ∝1\nτ ∝√ε.\nwhere the last relation used equation (3). (Recall that ln l = Lyapunov exponent.)\nResults from the Lorenz model verify this prediction.\nThe \"intermittent\nchannel\" of the Lorenz map is seen here:\nPomeau and Manneville [2], Fig. 2\nAnd here is the associated ε1/2 scaling of the Lyapunov number:\nPomeau and Manneville [2], Fig. 9\nBoth images on this page (c) Springer Nature Switzerland AG. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.\n\n1.5\nQuasiperiodicity\nFinally, we make a few remarks about the third universal route to chaos,\nknown as quasiperiodicity.\nRecall that there are 3 generic ways in which a limit cycle on a Poincar e map\nmay become unstable: An eigenvalue λ of the Floquet matrix (the Jacobian\nof the map) crosses the unit circle at\n- +1 (as in the example of intermittency above);\n- -1 (as we saw in the introduction to period doubling); and\n- λ = α ± iβ, |λ| > 1. This corresponds to the transition via quasiperiod-\nicity.\nAs we have seen, the latter case results in the addition of a second oscillation.\nThis is a Hopf bifurcation: the transformation of a limit cycle to a quasiperi-\nodic flow, or a torus T 2.\nThe route to chaos via quasiperiodicity describes how a torus T 2 (i.e., a\nquasiperiodic flow) can become a strange attractor.\n1.5.1\nAn historical note\nIn 1944, the Russian physicist Landau proposed a theory for the transition\nfrom laminar flow to turbulence as the Reynolds number is increased.\nBriefly, he envisioned the following sequence of events as Re increases beyond\nRec:\n- Laminar flow (constant velocity) becomes periodic with frequency f1 by\na Hopf bifurcation.\n- Period flow→quasiperiodic flow; i.e., another Hopf bifurcation. The sec-\nond frequency f2 is incommensurate with f1.\n\n- More incommensurate frequencies f3, f4, . . . , fr appear in succession (due\nto more Hopf bifurcations).\n- For r large, the spectrum appears continuous and the flow (on a torus\nT r) is aperiodic (i.e., turbulent).\nRecall that we have learned previously that, for dissipative flows,\ndimension of phase space > attractor dimension.\nThus a consequence of Landau's theory is that a system must have many\ndegrees of freedom to become chaotic.\nWe now know, however, from the work of Lorenz, that\n- 3 degrees of freedom suffice to give rise to a chaotic flow; and\n- the chaos occurs on a strange attractor, which is distinct from a torus\n(since trajectories diverge on the strange attractor).\n1.5.2\nRuelle-Takens theory\nLorenz's observations were deduced theoretically by Ruelle and Takens in\n1971.\nThe Ruelle-Takens theory is the quasiperiodic route to chaos. As a control\nparameter is varied, the following sequence of events can occur:\n- Laminar flow →oscillation with frequency f1.\n- A second Hopf bifurcation adds a second (incommensurate) frequency\nf2.\n- A third Hopf bifurcation adds a third frequency f3.\n- The torus T 3 can become unstable and be replaced by a strange attrac-\ntor.\n\nThe transition is demonstrated beautifully in terms of changing power spectra\nin the Rayleigh-B enard experiment described by Libchaber et al. [4]\nLib chab er et al. [4], Fig. 15\nNote that the Rayleigh number of the two spectra varies by less than 1%.\nReferences\n1.\nBerg e, P., Pomeau, Y. & Vidal, C. Order within Chaos: Towards a De-\nterministic Approach to Turbulence (John Wiley and Sons, New York,\n1984).\n2.\nPomeau, Y. & Manneville, P. Intermittent transition to turbulence in\ndissipative dynamical systems. Communications in Mathematical Physics\n74, 189-197 (1980).\n3.\nBerg e, P., Dubois, M., Manneville, P. & Pomeau, Y. Intermittency in\nRayleigh-B enard convection. Journal de Physique Lettres 41, 341-345\n(1980).\nCourtesy Elsevier, Inc., http://www.sciencedirect.com. Used with permission.\n\n4.\nLibchaber, A., Fauve, S. & Laroche, C. Two-parameter study of the routes\nto chaos. Physica D: Nonlinear Phenomena 7, 73-84 (1983).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lectures 10–11: Bifurcations in Two Dimensions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec10-11.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nOctober 3, 2022\nContents\nBifurcations in two dimensions\n1.1\nSaddle-node bifurcation . . . . . . . . . . . . . . . . . . . . . .\n1.2\nTranscritical and pitchfork bifurcations . . . . . . . . . . . . .\n1.3\nHopf bifurcations . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3.1\nSupercritical Hopf bifurcation . . . . . . . . . . . . . .\n1.3.2\nSubcritical Hopf bifurcation . . . . . . . . . . . . . . .\n1.4\nSaddle-node bifurcation of cycles\n. . . . . . . . . . . . . . . .\n1.5\nSpiking near limit cycles: excitability . . . . . . . . . . . . . .\nBifurcations in two dimensions\nReference: Strogatz, Chapter 8 [1].\nWe now extend our earlier discussion of bifurcations in 1-D to 2-D.\nUnlike 1-D, where trajectories either stop or go to infinity, now we shall meet\nthe class of bifurcations that create limit cycles.\nFirst let's generalize our earlier results.\n1.1\nSaddle-node bifurcation\nRecall that saddle-node bifurcations create or destroy fixed points. The 2-D\nprototype is\nx = μ -x2\ny = -y\n\nAll that we've done is add the equation for y, which sends trajectories toward\nthe x-axis.\nWhen μ < 0, there is a stable fixed point at\n(x∗, y∗) = (√μ, 0)\nand an unstable fixed point at\n(x∗, y∗) = (-√μ, 0)\nThe phase portraits show their collision at μ = 0:\nStrogatz [1], Fig. 8.1.1\nThe ghost is a kind of bottleneck: even after the fixed points disappear, the\nfact that they had been present causes the flow to be slow.\nTo see how slow it is, we compute the time taken to move along the x-axis\nin the one-dimensional case with μ < 0:\nT\n=\nZ inf\n-inf\ndx/dtdx\n=\nZ inf\n-inf\nμ -x2dx\n=\nπ\n√-μ\nwhich diverges as μ →0 from below. Exercise 4.3.1 in Strogatz shows how\nto evaluate the integral.\nWhile our prototypical example may appear special, it is really just a simple\nexample of a more general 2D system x = f(x, y), y = g(x, y) in which the\nnullclines for x = 0 and y = 0 intersect like this:\nSee image credit on Page 12.\n\nStrogatz [1], Fig. 8.1.2\nThen as a control parameter is varied, the nullclines begin to separate, the\ntwo fixed points must collide, and the system would behave as above.\n1.2\nTranscritical and pitchfork bifurcations\nIn analogy with the saddle-node case (and our earlier work in 1-D), the pro-\ntotypical cases are\nx = μx -x2,\ny = -y\ntranscritical\nx = μx -x3,\ny = -y\nsupercritical pitchfork\nx = μx + x3,\ny = -y\nsubcritical pitchfork\nThe pitchfork bifurcations will be most useful for us. Let's look at the super-\ncritical case.\nFor μ ≤0, there is a stable fixed point at the origin.\nFor μ > 0, two new stable fixed points appear, at\n(x∗, y∗) = (±√μ, 0)\nand the origin becomes an unstable saddle point:\nStrogatz [1], Fig. 8.1.6\nSee image credit on Page 12.\nSee image credit on Page 12.\n\n1.3\nHopf bifurcations\nThus far our examples of bifurcations have all been expressed in terms of\ncollisions of fixed points on a line, even though the line may exist as a curve\nin the plane. We now describe a bifurcation that can only exist in a phase\nspace of two or more dimensions.\nIn general, a stable fixed point may become unstable only if the real part of\none of the eigenvalues λ of the Jacobian becomes greater than zero as the\ncontrol parameter μ varies.\nRecall that the eigenvalues λ solve\ndet J -λI = 0,\nwhere J is the Jacobian and I is the identity matrix.\nIn 2-D, the resulting quadratic equation either has two real roots or two\ncomplex conjugate roots.\nSo when a fixed point is stable, either both roots are real and negative, or\nthe roots are complex conjugates with negative real parts:\nStrogatz [1], Fig. 8.2.1\nIn the saddle-node, transcritical, and pitchfork bifurcations, one of the purely\nreal roots passes through λ = 0 when the fixed point becomes unstable.\nA Hopf bifurcation occurs in the case in which the complex conjugate roots\ncross the imaginary axis. As in pitchfork bifurcations, there are two cases:\nsupercritical and subcritical.\nSee image credit on Page 12.\n\n1.3.1\nSupercritical Hopf bifurcation\nThe complex eigenvalues produce oscillatory solutions. One possibility is that\noscillations are damped for μ < μc and growing for μ > μc:\nStrogatz [1], Fig. 8.2.2\nThis situation corresponds to a supercritical Hopf bifurcation.\nWe can write a simple model of the supercritical Hopf bifurcation in terms\nof the radius r and angle θ in the 2-D phase space:\nr = μr -r3\nθ = ω + br2\nHere μ controls the stability, ω gives the frequency of oscillations when r\nis infinitesimal, and b determines the dependency of the frequency on the\namplitude of large oscillations.\nNote the similarity of the r-equation with the supercritical pitchfork bifurca-\ntion; the θ equation provides a kind of driving.\nWhen μ ≤0, the origin r = 0 is a stable spiral. When μ > 0, the origin is an\nunstable spiral:\nStrogatz [1], Fig. 8.2.3\nNote that for μ > 0 there is a stable limit cycle of size r = √μ.\nSee image credit on Page 12.\nSee image credit on Page 12.\n\nWhen μ = 0 the origin is still stable, but the amplitude of oscillations decays\nslower than exponentially (since r = -r2); this is another case of critical\nslowing down.\nThe eigenvalues at the origin are (unsurprisingly, but see the calculation in\nStrogatz)\nλ = μ ± iω\nWe can extract two important characteristics of supercritical Hopf bifurca-\ntions from this prototypical form:\n- The size of the limit cycle grows like √μ for μ near μc.\n- The frequency of the limit cycle near μc is approximately ω = Imλ,\nevaluated near at μc. The period is 2π/ω.\nIn our example, the eigenvalues cross the imaginary axis as a straight line\nparallel to the real axis. However the paths are usually curved:\nStrogatz [1], Fig. 8.2.4\nMoreover the limit cycle is usually elliptical and not circular near μc.\n1.3.2\nSubcritical Hopf bifurcation\nAs with pitchfork bifurcations, there is also a subcritical variety of Hopf\nbifurcations in which the stability of the fixed point and the limit cycle is\nreversed. It has some very interesting properties.\nHere's the prototype:\nr = μr + r3 -r5\nθ = ω + br2\nSee image credit on Page 12.\n\nNow the cubic term is destabilizing--it helps drive trajectories away from the\norigin.\nThe phase portraits look like this:\nStrogatz [1], Fig. 8.2.5\nWhen μ < 0 there are two attractors: a stable limit cycle and a stable fixed\npoint. These two attractors are separated by an unstable limit cycle.\nAs μ →0 from below, the unstable limit cycle shrinks to the origin.\nThe subcritical Hopf bifurcation occurs at μ = 0. Here the origin becomes\nunstable and the large amplitude limit cycle is the only attractor.\nConsequently any solution near the origin is forced to grow immediately to a\nlarge amplitude oscillation.\nThis strongly contrasts the supercritical case, in which the amplitude of the\nlimit cycle grows smoothly from zero, like μ1/2.\nHere's a pictorial summary of the supercritical and subcritical cases:\nIzhikevich [2], Fig. 6.9\nSee image credit on Page 12.\n(c) MIT Press. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.\n\nNote that pictures of the subcritical case omit the large amplitude stable\nlimit cycle.\nNote the similarity to the supercritical and subcritical pitchfork bifurcations\nin one dimension we saw previously:\nStrogatz [1], Fig. 3.4.2\nStrogatz [1], Fig. 3.4.7\nAs in the subcritical pitchfork bifurcation, there is also the possibility of\nhysteresis: once trajectories are on the large amplitude limit cycle for μ > 0,\nthey can't be turned offby returning μ to zero.\nIt turns out the that the large-amplitude limit cycle disappears at μc = -1/4.\nHow does that happen?\n1.4\nSaddle-node bifurcation of cycles\nWe can answer that question by considering only the equation for r. Plots of\nr for μ < μc, μ = μc, and μc < μ < 0 look like this:\nStrogatz [1], Fig. 8.4.1\nSee image credit on Page 12.\nSee image credit on Page 12.\n\nHere the inclusion of the phase portraits makes clear that a saddle-node\nbifurcation occurs at μ = μc.\nRather than just being a collision of an unstable and stable fixed point, here\nwe have a saddle node bifurcation of cycles: the unstable limit cycle collides\nwith the stable limit cycle, leaving only the stable fixed point.\nIn fact the origin remains stable all the time, while the large amplitude limit\ncycle is created, seemingly from nothing, as μ increases past μc.\n1.5\nSpiking near limit cycles: excitability\nRecall that the van der Pol equation\nx + μ(x2 -1) x + x = 0.\nmay be rewritten as\nx = y + x -x3\ny = -1\nμx\nWe showed earlier, via a physical argument, that the origin or rest position\nis always unstable, and that a limit cycle is instead stable.\nWe also showed that when μ ≫1, the system exhibits relaxation oscillations.\nThe picture looked like this:\nStrogatz [1], Figs. 7.5.1-2\nHere the x = 0 nullcline is the cubic. The y = 0 nullcline is the y-axis (i.e.,\nx = 0). Their intersection is at the unstable fixed point, the origin.\nSee image credit on Page 12.\n\nWe can make the fixed point stable, however, by tilting the y = 0 nullcline.\nAlong with a few other modifications of only cosmetic consequence, the mod-\nified system reads\nx = -y + x -x3/3 + z\ny =\nμ(x + a -by)\nComparing with the van der Pol equation, one obvious but inconsequential\ndifference is the change y →-y, which flips the cubic nullcline.\nThe y = 0 nullcline is now the line\ny = x + a\nb\nwhich not only provides a tilt of slope 1/b, but also adds a constant a/b. We\nhave also added a constant term z to the first equation.\nThis system is known as the Fitzhugh-Nagumo model [2-4]. It was introduced\nas a simple model of an action potential, which describes the firing of pulses\nor spikes of voltage, as is commonly observed in the behavior of neurons. The\nvariable x is then loosely related to the membrane potential and y is called\na recovery variable.\nThe Fitzhugh-Nagumo model was originally introduced as a simple way to\nexplain the behavior of the more detailed Hodgkin-Huxley model of the squid\ngiant axon [2].\nHere we are interested in the model when the nullclines intersect at only one\npoint and that point is stable. Here's how the flow appears in the phase\nplane:\n-2\n-1\n-1.0\n-0.5\n0.0\n0.5\n1.0\n1.5\nx\ny\nStable fixed point\nHere the parameters a = 0.7, b = 0.8, μ = 10, and z = 0.\n\nIf we were to increase z, the effect would be like stimulating the system with\na current. Eventually the system passes through a Hopf bifurcation, and the\nsystem would exhibit a limit cycle very similar to the van der Pol limit cycle.\nBut note above that the flow in phase space when the fixed point is stable\nlooks very similar to what one would expect for a limit cycle.\nConsequently, near the Hopf bifurcation, perturbations of the fixed point\nabove a threshold make the system behave as if the limit cycle existed, but\nonly for one cycle.\nHere are four perturbations of the fixed point, two below the threshold and\ntwo above the threshold:\n-2\n-1\n-1.0\n-0.5\n0.0\n0.5\n1.0\nx\ny\nAbove the threshold, the time series x(t) shows a single pulse or spike:\nt\n-2\n-1\nx\nSystems that exhibit such spiking behavior are called excitable. Models of\nexcitable systems have played a large role in neurophysiology. They may also\napply to other systems, including the climate and carbon cycle [5].\nIn the case we have considered here, for practical purposes the threshold for\nan excitation is sharp, but mathematically it is smooth (as can be seen in\n\nthe phase space trajectories above), and is thus called a quasithreshold.\nReferences\n1.\nStrogatz, S. Nonlinear Dynamics and Chaos: With Applications to Physics,\nBiology, Chemistry, and Engineering (CRC Press, 2018).\n2.\nIzhikevich, E. M. Dynamical Systems in Neuroscience: The Geometry of\nExcitability and Bursting (MIT Press, Cambridge, 2007).\n3.\nFitzHugh, R. Impulses and physiological states in theoretical models of\nnerve membrane. Biophysical Journal 1, 445-466 (1961).\n4.\nIzhikevich, E. M. & FitzHugh, R. FitzHugh-Nagumo model. Scholarpedia\n1. revision #123664, 1349 (2006).\n5.\nRothman, D. H. Characteristic disruptions of an excitable carbon cy-\ncle. Proceedings of the National Academy of Sciences 116, 14813-14822\n(2019).\nImage Credit\nImages on Pages 2-9 from Strogatz, S. Nonlinear Dynamics and Chaos: With Applications\nto Physics, Biology, Chemistry, and Engineering (CRC Press, 2018) (c) Informa UK Limited.\nAll rights reserved. This content is excluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-use.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lectures 12–14: Spectral Analysis for Dynamical Systems",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec12-14.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nOctober 12, 2022\nContents\nSpectral analysis for dynamical systems\n1.1\nFourier transforms\n. . . . . . . . . . . . . . . . . . . . . . . .\n1.1.1\nContinuous Fourier transform . . . . . . . . . . . . . .\n1.1.2\nDiscrete-time signals . . . . . . . . . . . . . . . . . . .\n1.1.3\nDiscrete Fourier transform . . . . . . . . . . . . . . . .\n1.1.4\nInverse discrete Fourier tranform\n. . . . . . . . . . . .\n1.2\nThe autocorrelation function and the power spectrum . . . . .\n1.3\nPower spectrum of a periodic signal . . . . . . . . . . . . . . .\n1.3.1\nSinusoidal signal\n. . . . . . . . . . . . . . . . . . . . .\n1.3.2\nNon-sinusoidal signal . . . . . . . . . . . . . . . . . . .\n1.3.3\ntmax/T = integer . . . . . . . . . . . . . . . . . . . . .\n1.3.4\nConclusion . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4\nQuasiperiodic signals . . . . . . . . . . . . . . . . . . . . . . .\n1.5\nAperiodic signals . . . . . . . . . . . . . . . . . . . . . . . . .\nSpectral analysis for dynamical systems\nPower spectra provide one of the most important tools for analyzing the\nbehavior of dynamical systems, both theoretically and experimentally.\n1.1\nFourier transforms\nThe precise oscillatory nature of an observed time series x(t) is usually not\nidentifiable from x(t) alone.\nWe may ask\n\n- How well-defined is the the dominant frequency of oscillation?\n- How many frequencies of oscillation are present?\n- What are the relative contributions of all frequencies?\nThe analytic tool for answering these and myriad related questions is the\nFourier transform.\n1.1.1\nContinuous Fourier transform\nWe first state the Fourier transform for functions that are continuous with\ntime.\nThe Fourier transform of a function f(t) is\nF(ω) =\n√\n2π\nZ inf\n-inf\nf(t)e-iωtdt\nSimilarly, the inverse Fourier transform is\nf(t) =\n√\n2π\nZ inf\n-inf\nF(ω)eiωtdω.\nThat the second relation is the inverse of the first may be proven, but we\nsave that calculation for the discrete transform, below.\n1.1.2\nDiscrete-time signals\nWe are interested in the analysis of observational or experimental data, which\nis almost always discrete. Thus we specialize to discrete Fourier transforms.\nIn modern data, one almost always observes a discretized signal\nxj,\nj = {0, 1, 2, . . . , n -1}\n\nWe take the sampling interval--the time between samples--to be ∆t. Then\nxj = x(j∆t).\nThe discretization process is pictured as\nt\nj\nj-1\nj+1\nx\nx(t)\n∆t\nA practical question concerns the choice of ∆t. To choose it, we must know\nthe highest frequency, fmax, contained in x(t).\nThe shortest period of oscillation is\nTmin = 1/fmax\nPictorially,\nx\nt\nTmin\nWe require at least two samples per period. Therefore\n∆t ≤Tmin\n=\n2fmax\n.\n1.1.3\nDiscrete Fourier transform\nThe discrete Fourier transform (DFT) of a time series xj, j = 0, 1, . . . , n -1\nis\nˆxk =\nn-1\nX\nj=0\nxj exp\n\n-i2πjk\nn\n\nk = 0, 1, . . . , n -1\n\nTo gain some intuitive understanding, consider the range of the exponential\nmultiplier.\n- k = 0 ⇒exp(-i2πjk/n) = 1. Then\nˆx0 =\nX\nj\nxj\nThus ˆx0 is n times the mean of the xj's.\nThis is the \"DC\" component of the transform.\nQuestion: Suppose a seismometer measures ground motion. What would\nˆx0 = 0 mean?\n- k = n/2 ⇒exp(-i2πjk/n) = exp(-iπj). Then\nˆxn/2 =\nX\nj\nxj(-1)j\n= x0 -x1 + x2 -x3 . . .\nFrequency index n/2 is clearly the highest accessible frequency.\n- The frequency indices k = 0, 1, . . . , n/2 correspond to frequencies\nfk = k/tmax,\ni.e., k oscillations per tmax, the period of observation.\nIndex k = n/2 then corresponds to\nfmax =\nn\nn∆t\n\n=\n2∆t\nBut if n/2 is the highest frequency that the signal can carry, what is the\nsignificance of ˆxk for k > n/2?\nFor real xj, frequency indices k > n/2 are redundant, being related by\nˆxk = ˆx∗\nn-k\nwhere z∗is the complex conjugate of z (i.e., if z = a + ib, z∗= a -ib).\n\nWe derive this relation as follows. From the definition of the DFT, we have\nˆx∗\nn-k =\nn-1\nX\nj=0\nxj exp\n\n+i2πj(n -k)\nn\n\n=\nn-1\nX\nj=0\nxj exp (i2πj)\n|\n{z\n}\nexp\n-i2πjk\nn\n\n=\nn-1\nX\nj=0\nxj exp\n-i2πjk\nn\n\n= ˆxk\nwhere the + in the first equation derives from the complex conjugation, and\nthe last line again employs the definition of the DFT.\nNote that we also have the relation\nˆx∗\n-k = ˆx∗\nn-k = ˆxk.\nThe frequency indices k > n/2 are therefore sometimes referred to as negative\nfrequencies\n1.1.4\nInverse discrete Fourier tranform\nThe inverse DFT is given by\nxj = 1\nn\nn-1\nX\nk=0\nˆxk exp\n\n+i2πjk\nn\n\nj = 0, 1, . . . , n -1\nWe proceed to demonstrate this inverse relation.\n\nWe begin by substituting the DFT for ˆxk, using dummy variable j′:\nxj =\nn\nn-1\nX\nk=0\n\nn-1\nX\nj′=0\nxj′ exp\n\n-i2πj′k\nn\n\nexp\n\n+i2πkj\nn\n\n=\nn\nn-1\nX\nj′=0\nxj′\nn-1\nX\nk=0\nexp\n\n-i2πk(j′ -j)\nn\n\n=\nn\nn-1\nX\nj′=0\nxj′ ×\nn, j′ = j\n0, j′ = j\n=\nn(nxj)\n= xj\nThe third relation derives from the fact that the previous P\nk amounts to a\nvanishing sum over the unit circle in the complex plane, except when j′ = j.\nTo see why the sum over the circle vanishes, consider the example of\nj′ -j = 1\nand\nn = 4.\nThe elements of the sum are then just the four points on the unit circle that\nintersect the real and imaginary axes, i.e.,\nX\nk=0\nexp\n\n-i2πk(j′ -j)\n\n= e0 + e-iπ/2 + e-iπ + e-i3π/2\n= 1 -i -1 + i\n= 0.\nFinally, note that the DFT relations imply that xj is periodic in n, so that\nxj+n = xj.\nConsequently a finite time series is treated as if it were recurring:\n\nmax\nt\ntmax\nt\nmax\nt-\nx(t)\n1.2\nThe autocorrelation function and the power spectrum\nAssume that the time series xj has zero mean and that it is periodic, i.e.,\nxj+n = xj.\nDefine the autocorrelation function ψ:\nψm =\nn-1\nX\nj=0\nx∗\njxj+m\nwhere\nψm = ψ(m∆t)\nThe autocorrelation function measures the degree to which a signal resembles\nitself over time. Thus it measures the predictability of the future from the\npast.\nTo gain some intuition:\n- Consider, for example, m = 0 and real xj. Then\nψ0 =\nn-1\nX\nj=0\nx2\nj,\nwhich is n times the mean squared value of xj.\n- Alternatively, if m∆t is much less than the dominant period of the data,\nψm should not be too much less than ψ0.\n- Last, if m∆t is much greater than the dominant period of the data, |ψm|\nis relatively small.\n\nA typical ψm looks like\nΨm\nm\nThe power spectrum of a time series is the magnitude squared of its Fourier\ntransform:\n|ˆxk|2 =\n\nn-1\nX\nj=0\nxj exp\n\n-i2πjk\nn\n\n.\nThe Wiener-Khintchin theorem states that\npower spectrum = Fourier transform of the autocorrelation.\nIn symbols,\n|ˆxk|2 =\nn-1\nX\nm=0\nψm exp\n\n-i2πkm\nn\n\nWe also have the inverse relation\nψm = 1\nn\nn-1\nX\nk=0\n|ˆxk|2 exp\n\n+i2πkm\nn\n\nTo prove the latter relation, we first substitute the inverse DFT for xj and\nxj+m in the definition of ψm:\nψm =\nn-1\nX\nj=0\nx∗\njxj+m\n=\nn-1\nX\nj=0\n\"\nn\nn-1\nX\nk=0\nˆx∗\nk exp\n\n-i2πkj\nn\n# \"\nn\nn-1\nX\nk′=0\nˆxk′ exp\n\ni2πk′(j + m)\nn\n#\n\nWe then change the order of the summations and simplify as follows:\nψm =\nn2\nn-1\nX\nk=0\nn-1\nX\nk′=0\nˆx∗\nkˆxk′ exp\n\ni2πmk′\nn\nn-1\nX\nj=0\nexp\n\ni2πj(k′ -k)\nn\n\n|\n{z\n}\n= n, k′ = k\n= 0, k′ = k\n=\nn\nn-1\nX\nk=0\nˆx∗\nkˆxk exp\n\ni2πmk\nn\n\nwhich is the Wiener-Khintchin relation.\nBy Fourier transforming ψm we also prove the inverse relation: the power\nspectrum is the Fourier transform of the autocorrelation.\nFor a real time series {xj}, we can use the previously derived relation\nˆx∗\nk = ˆxn-k = ˆx-k\nto show that\n|ˆxk|2 = ˆxkˆx∗\nk = ˆxkˆxn-k = ˆx∗\nn-kˆxn-k = |ˆxn-k|2.\nThis redundancy results from the fact that neither the autocorrelation nor\nthe power spectrum contain information on any \"phase lags\" in either xj or\nits individual frequency components.\nThus while the DFT of an n-point time series results in n independent quan-\ntities (2 ×n/2 complex numbers), the power spectrum yields only n/2 inde-\npendent quantities.\nOne may therefore show that there are an infinite number of time series that\nhave the same power spectrum, but that each time series uniquely defines its\nFourier transform, and vice-versa.\nConsequently a time series cannot be reconstructed from its power spectrum\nor autocorrelation function.\n\n1.3\nPower spectrum of a periodic signal\nConsider a periodic signal\nx(t) = x(t + T) = x\n\nt + 2π\nω\n\nConsider the extreme case where the period T is equal to the duration of the\nsignal:\nT = tmax = n△t\nThe Fourier components are separated by\n∆f =\ntmax\ni.e. at frequencies\n0, 1/T, 2/T, . . . , (n -1)/T.\n1.3.1\nSinusoidal signal\nIn the simplest case, x(t) is a sine or cosine, i.e.,\nx(t) = sin\n2πt\ntmax\n\n.\nWhat is the Fourier tranform? Pictorially, we expect\nx(t)\ntmax t\nxk 2\n∆\nk\nf = k/T\n1/T\n\nWe calculate the power spectrum analytically, beginning with the DFT:\nˆxk =\nX\nj\nxj exp\n-i2πjk\nn\n\n=\nX\nj\nsin\n2πj∆t\ntmax\n\nexp\n-i2πjk\nn\n\n=\n2i\nX\nj\n\nexp\ni2πj∆t\ntmax\n\n-exp\n-i2πj∆t\ntmax\n\nexp\n-i2πjk\nn\n\n=\n2i\nX\nj\n\nexp\n\ni2πj\n∆t\ntmax\n-k\nn\n\n-exp\n\n-i2πj\n∆t\ntmax\n+ k\nn\n\n= ± n\n2i\nwhen k = ±n∆t\ntmax\n.\nThus\n|ˆxk|2 = n2\nfor k = ±1.\n1.3.2\nNon-sinusoidal signal\nConsider now a non-sinusoidal yet periodic signal, similar to the relaxation\noscillations seen in the van der Pol limit cycle.\nThe non-sinusoidal character of such oscillations implies that it contains\nhigher-order harmonics, i.e., integer multiples of the fundamental frequency\n1/T. Thus, pictorially, we expect\nxk 2\n∆\nk\nf = k/T\n1/T\nx(t)\ntmax t\n2/T\n3/T\nharmonics\nfundamental\n\nNow suppose tmax = pT, where p is an integer. The non-zero components of\nthe power spectrum must still be at frequencies\n1/T, 2/T, . . . .\nBut since\n∆f =\ntmax\n= 1\npT\nthe frequency resolution is p times greater. Contributions to the power spec-\ntrum would remain at integer multiples of the frequency 1/T, but spaced p\nsamples apart on the frequency axis.\n1.3.3\ntmax/T = integer\nIf tmax/T is not an integer, the (effectively periodic) signal looks like\nx(t)\nt\ntmax\nWe calculate the power spectrum of such a signal, assuming the sinusoidal\nfunction\nx(t) = exp\n\ni2πt\nT\n\nwhich has the discrete form\nxj = exp\n\ni2πj∆t\nT\n\n.\nThe DFT is\nˆxk =\nn-1\nX\nj=0\nexp\n\ni2πj∆t\nT\n\nexp\n\n-i2πjk\nn\n\n.\nSet\nφk = ∆t\nT -k\nn.\n\nThen\nˆxk =\nn-1\nX\nj=0\nexp (i2πφkj) .\nRecall the identity\nn-1\nX\nj=0\nxj = xn -1\nx -1 .\nThen\nˆxk = exp(i2πφkn) -1\nexp(i2πφk) -1 .\nThe power spectrum is\n|ˆxk|2 = ˆxkˆx∗\nk = 1 -cos(2πφkn)\n1 -cos(2πφk)\n= sin2(πφkn)\nsin2(πφk) .\nNote that\nnφk = n∆t\nT\n-k = tmax\nT\n-k\nis the difference between a DFT index k and the \"real\" non-integral frequency\nindex tmax/T.\nAssume that n is large and k is close to that \"real\" frequency index such that\nnφk = n∆t\nT\n-k ≪n.\nConsequently φk ≪1, so we may also assume\nπφk ≪1.\nThen\n|ˆxk|2 ≃sin2(πφkn)\n(πφk)2\n= n2 sin2(πφkn)\n(πφkn)2\n∝sin2 z\nz2\n\nwhere\nz = nπφk = π\nn∆t\nT\n-k\n\n= π\ntmax\nT\n-k\n\n.\nThus |ˆxk|2 is no longer a simple spike. Instead, as a function of z = nπφk it\nappears as\nsin z / z2\nπφk\nπ\n2π\n3π\n-3π\n-2π\n-π\nz=n\nThe plot gives the kth component of the power spectrum of ei2πt/T as a\nfunction of π(tmax/T -k).\nTo interpret the plot, let k0 be the integer closest to tmax/T. There are then\ntwo extreme cases:\n1. tmax is an integral multiple of T:\ntmax\nT\n-k0 = 0.\nThe spectrum is perfectly sharp:\nxk 2\nk\nk0\nz\nsin2z/z\n2. tmax/T falls midway between two frequencies. Then\ntmax\nT\n-k0 = 1\n2.\nThe spectrum is smeared:\n\nxk 2\nk\nk0\nz\nsin2z/z\nThe smear decays like\n(k -tmax/T)2 ∼1\nk2\n1.3.4\nConclusion\nThe power spectrum of a periodic signal of period T is composed of:\n1. a peak at the frequency 1/T\n2. a smear (sidelobes) near 1/T\n3. possibly harmonics (integer multiples) of 1/T\n4. smears near the harmonics.\n1.4\nQuasiperiodic signals\nLet y be a function of r independent variables:\ny = y(t1, t2, . . . , tr).\ny is periodic, of period 2π in each argument, if\ny(t1, t2, . . . , tj + 2π, . . . , tr) = y(t1, t2, . . . , tj, . . . , tr),\nj = 1, . . . , r\ny is called quasiperiodic if each tj varies with time at a different rate (i.e.,\ndifferent \"clocks\"). We have then\ntj = ωjt,\nj = 1, . . . , r.\n\nThe quasiperiodic function y has r fundamental frequencies:\nfj = ωj\n2π\nand r periods\nTj = 1\nfj\n= 2π\nωj\n.\nExample: The astronomical position of a point on Earth's surface changes\ndue to\n- rotation of Earth about axis (T1 = 24 hours).\n- revolution of Earth around sun (T2 ≃365 days).\nAt long time scales, we also have changes in precession (26 Kyr), obliquity\n(41 Kyr), and eccentricity (∼100 Kyr).\nConsidering just two oscillations (e.g, rotation and revolution), we can con-\nceive of such a function on a 2-D torus T 2, existing in a 3-D space.\nT1\nT2\nHere we think of a disk spinning with period T1 while it revolves along the\ncircular path with period T2.\nSuch behavior can be conceived as a trajectory on the surface of a doughnut\nor inner tube, or a torus T2 in R3.\n\nf1\nf2\nWhat is the power spectrum of a quasiperiodic signal x(t)? There are two\npossibilities:\n1. The quasiperiodic signal is a linear combination of independent periodic\nfunctions. For example:\nx(t) =\nr\nX\ni=1\nxi(ωit).\nBecause the Fourier transform is a linear transformation, the power spec-\ntrum of x(t) is a set of peaks at frequencies\nf1 = ω1/2π, f2 = ω2/2π, . . .\nand their harmonics\nm1f1, m2f2, . . .\n(m1, m2, . . . positive integers).\n2. The quasiperiodic signal x(t) depends nonlinearly on periodic functions.\nFor example,\nx(t) = sin(2πf1t) sin(2πf2t) = 1\n2 cos(|f1 -f2|2πt) -1\n2 cos(|f1 + f2|2πt).\nThe fundamental frequencies are\n|f1 -f2|\nand\n|f1 + f2|.\nThe harmonics are\nm1|f1 -f2|\nand\nm2|f1 + f2|,\nm1, m2 positive integers.\n\nThe nonlinear case requires more attention. In general, if x(t) depends non-\nlinearly on r periodic functions, then the harmonics are\n|m1f1 + m2f2 + . . . + mrfr|,\nmi arbitrary integers.\nIn what follows, we specialize to r = 2 frequencies, and forget about finite\n∆f.\nEach nonzero component of the spectrum of x(ω1t, ω2t) is a peak at\nf = |m1f1 + m2f2|,\nm1, m2 integers .\nThere are two cases:\n1. f1/f2 rational ⇒sparse spectrum.\n2. f1/f2 irrational ⇒dense spectrum.\nTo understand this, rewrite f as\nf = f2\nm1\nf1\nf2\n+ m2\n.\nIn the rational case,\nf1\nf2\n= integer\ninteger.\nThen\nm1\nf1\nf2\n+ m2\n=\n\ninteger\nf2\n+ integer\n= integer multiple of 1\nf2\n.\nThus the peaks of the spectrum must be separated (i.e., sparse).\nAlternatively, if f1/f2 is irrational, then m1 and m2 may always be chosen so\nthat\nm1\nf1\nf2\n+ m2\nis not similarly restricted.\nThese distinctions have further implications.\n\nIn the rational case,\nf1\nf2\n= n1\nn2\n,\nn1, n2 integers.\nSince\nn1\nf1\n= n2\nf2\nthe quasiperiodic function is periodic with period\nT = n1T1 = n2T2.\nAll spectral peaks must then be harmonics of the fundamental frequency\nf0 = 1\nT = f1\nn1\n= f2\nn2\n.\nThus the rational quasiperiodic case is in fact periodic, and some writers\nrestrict quasiperiodicity to the irrational case.\nNote further that, in the irrational case, the signal never exactly repeats\nitself.\nOne may consider, as an example, the case of a child walking on a sidewalk,\nattempting with uniform steps to never step on a crack.\nThen if x(t) were the distance from the closest crack at each step, it would\nonly be possible to avoid stepping on a crack if the ratio\nstep size\ncrack width\nwere rational.\n1.5\nAperiodic signals\nAperiodic signals are neither periodic nor quasiperiodic.\nAperiodic signals appear random, though they may have a deterministic foun-\ndation.\n\nAn example is white noise, which is a signal that is \"new\" and unpredictable\nat each instant, e.g.,\nt\nx(t)\nStatistically, each sample of a white-noise signal is independent of the others,\nand therefore uncorrelated to them.\nThe power spectrum of white noise is, on average, flat:\nxk 2\nk\nThe flat spectrum of white noise is a consequence of its lack of harmonic\nstructure (i.e., one cannot recognize any particular tone, or dominant fre-\nquency).\nWe proceed to derive the spectrum of a white noise signal x(t).\nRather than considering only one white-noise signal, we consider an ensemble\nof such signals, i.e.,\nx(1)(t), x(2)(t), . . .\nwhere the superscipt denotes the particular realization within the ensemble.\nEach realization is independent of the others.\nNow discretize each signal so that\nxj = x(j∆t),\nj = 0, . . . , n -1\nWe take the signal to have finite length n but consider the ensemble to contain\nan infinite number of realizations.\n\nWe use angle brackets to denote ensemble averages.\nThe ensemble-averaged mean of the jth sample is then\n⟨xj⟩= lim\np→inf\np\np\nX\ni=1\nx(i)\nj\nSimilarly, the mean-square value of the jth sample is\n\nx2\nj\n\n= lim\np→inf\np\np\nX\ni=1\n\nx(i)\nj\nNow assume stationarity: ⟨xj⟩and\n\nx2\nj\n\nare independent of j. We take these\nmean values to be ⟨x⟩and\n\nx2\n, respectively, and assume ⟨x⟩= 0.\nRecall the autocorrelation ψm:\nψm =\nn-1\nX\nj=0\nxjxj+m.\nBy definition, each sample of white noise is uncorrelated with its past and\nfuture. Therefore\n⟨ψm⟩=\n*X\nj\nxjxj+m\n+\n= n\n\nx2\nδm\nwhere\nδm =\n1 m = 0\nelse\nWe obtain the power spectrum from the autocorrelation function by the\nWiener-Khintchine theorem:\n\n|ˆxk|2\n=\nn-1\nX\nm=0\n⟨ψm⟩exp\n\n-i2πmk\nn\n\n=\nn-1\nX\nm=0\nn\n\nx2\nδm exp\n\n-i2πmk\nn\n\n= n\n\nx2\n= constant.\n\nThus for white noise, the spectrum is indeed flat, as previously indicated:\nxk 2\nk\nA more common case is \"colored\" noise: a continuous spectrum, but not\nconstant:\nxk 2\nk\nIn such (red) colored spectra, there is a relative lack of high frequencies. The\nsignal is still apparently random, but only beyond some interval ∆t.\nThe autocorrelation of colored noise is broader, e.g.,\nΨm\nm\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lectures 15–16: Poincare Sections",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec15-16.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nOctober 17, 2022\nContents\nPoincar e sections\n1.1\nConstruction of Poincar e sections . . . . . . . . . . . . . . . .\n1.2\nTypes of Poincar e sections . . . . . . . . . . . . . . . . . . . .\n1.2.1\nPeriodic . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.2\nQuasiperiodic flows . . . . . . . . . . . . . . . . . . . .\n1.2.3\nAperiodic flows . . . . . . . . . . . . . . . . . . . . . .\n1.3\nFirst-return maps . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4\nRelation of flows to maps . . . . . . . . . . . . . . . . . . . . .\n1.4.1\nExample 1: the van der Pol equation . . . . . . . . . .\n1.4.2\nExample 2: R ossler attractor\n. . . . . . . . . . . . . .\n1.4.3\nExample 3: Reconstruction of phase space from exper-\nimental data . . . . . . . . . . . . . . . . . . . . . . . .\nReferences: [1-3]\nPoincar e sections\nThe dynamical systems we study are of the form\nd\ndtx(t) = F(x, t)\nSystems of such equations describe a flow in phase space.\nThe solution is often studied by considering the trajectories of such flows.\nBut the phase trajectory is itself often difficult to determine, if for no other\nreason than that the dimensionality of the phase space is too large.\n\nThus we seek a geometric depiction of the trajectories in a lower-dimensional\nspace--in essence, a view of phase space without all the detail.\n1.1\nConstruction of Poincar e sections\nSuppose we have a 3-D flow Γ. Instead of directly studying the flow in 3-D,\nconsider, e.g., its intersection with a plane (x3 = h):\nx1\nx2\nx3\nh\nS\nΓ\nP0\nP1\nP2\n- Points of intersection correspond (in this case) to x3 < 0 on Γ.\n- Height h of plane S is chosen so that Γ continually crosses S.\n- The points P0, P1, P2 form the 2-D Poincar e section.\nThe Poincar e section is a continuous mapping T of the plane S onto itself:\nPk+1 = T(Pk) = T [T(Pk-1)] = T 2(Pk-1) = . . .\nSince the flow is deterministic, P0 determines P1, P1 determines P2, etc.\nThe Poincar e section reduces a continuous flow to a discrete-time mapping.\nHowever the time interval from point to point is not necessarily constant.\nWe expect some geometric properties of the flow and the Poincar e section to\nbe the same:\n\n- Dissipation ⇒areas in the Poincar e section should contract.\n- If the flow has an attractor, we should see it in the Poincar e section.\nEssentially the Poincar e section provides a means to visualize an otherwise\nmessy, possibly aperiodic, attractor.\n1.2\nTypes of Poincar e sections\nAs we did with power spectra, we classify three types of flows: periodic,\nquasiperiodic, and aperiodic.\n1.2.1\nPeriodic\nThe flow is a closed orbit (e.g., a limit cycle):\nP0\nP0 is a fixed point of the Poincar e map:\nP0 = T(P0) = T 2(P0) = . . . .\nWe proceed to analyze the stability of the fixed point.\nTo first order, a Poincar e map T can be described by a matrix M defined in\nthe neighborhood of P0:\nMij = ∂Ti\n∂xj\n\nP0\n.\nIn this context, M is called a Floquet matrix. It describes how a point P0 + δ\nmoves after one intersection of the Poincar e map.\n\nA Taylor expansion about the fixed point yields:\nTi(P0 + δ) ≃Ti(P0) + ∂Ti\n∂x1\n\nP0\n· δ1 + ∂Ti\n∂x2\n\nP0\n· δ2,\ni = 1, 2\nSince T(P0) = P0,\nT(P0 + δ) ≃P0 + Mδ\nTherefore\nT\n\nT(P0 + δ)\n!\n≃T(P0 + Mδ)\n≃T(P0) + M 2δ\n≃P0 + M 2δ\nAfter m interations of the map,\nT m(P0 + δ) -P0 ≃M mδ.\nStability therefore depends on the properties of M.\nAssume that δ is an eigenvector of M. (There will always be a projection onto an\neigenvector.) Then\nM mδ = λmδ,\nwhere λ is the corresponding eigenvalue.\nTherefore\n|λ| < 1 ⇒\nlinearly stable\n|λ| > 1 ⇒\nlinearly unstable\nConclusion: a periodic map is unstable if one of the eigenvalues of the Floquet\nmatrix crosses the unit circle in the complex plane.\n1.2.2\nQuasiperiodic flows\nConsider a 3-D flow with two fundamental frequencies f1 and f2. The flow is\na torus T 2:\n\nThe points of intersection of the flow with the plane S appear on a closed\ncurve C.\nAs with power spectra, the form of the resulting Poincar e section depends on\nthe ratio f1/f2:\n- Irrational f1/f2. The frequencies are called incommensurate. The closed\ncurve C appears continuous, e.g.\nC\nx1\nx2\n- The trajectory on the torus T 2 never repeats itself exactly.\n- The curve is not traversed continuously, but rather\nT(C) = finite shift along C.\n- Rational f1/f2.\n- f1 and f2 are frequency locked.\n- There are finite number of intersections (points) along the curve C.\n\n- Trajectory repeats itself after n1 revolutions and n2 rotations.\n- The Poincar e section is periodic with\nperiod = n1/f1 = n2/f2\n- The Poincar e section contains just n1 points. Thus\nPi = T n1(Pi)\n- Example, n1 = 5:\nP0\nP1\nP4\nP2\nP3\n1.2.3\nAperiodic flows\nAperiodic flows may no longer lie on some reasonably simple curve.\nIn an extreme case, one has just a point cloud:\nThis would be expected for statistical white noise.\nDeterministic aperiodic systems often display more order, however. In some\ncases they create mild departures from a simple curve, e.g.\n\nSuch cases arise from strong dissipation (and the resulting contraction of\nareas in phase space).\nIt then becomes useful to define a coordinate x that falls roughly along this\ncurve, and to study the iterates of x. This is called a first return map.\n1.3\nFirst-return maps\nFirst return maps are 1-D reductions of the kind of 2-D Poincar e maps that\nwe have been considering.\nSuch maps are of the form\nxk+1 = f(xk).\nWe will study these extensively at the end of the course.\nWe shall give particular attention to the following quadratic mapping of the\nunit interval onto itself:\nxk+1 = 4μxk(1 -xk),\n0 ≤μ ≤1.\nThe mapping is easily described graphically. The quadratic rises from x = 0,\nfalls to x = 1, and has its maximum at x = 1/2, where it rises to height μ.\nConsider, for example, the case μ = 0.7:\nxk+1 = xk\nf(x0) =\nx0\nx1\nx\nx1\nx\nf(x)\nf(x)\n\nEventually the interations converge to x = x, which is where the diagonal\n(the identity map xk+1 = xk) intersects f(x).\nThus x is a fixed point of f, i.e.,\nx = f( x)\nAnother fixed point is x = 0, since f(0) = 0.\nHowever we can see graphically that x = 0 is unstable; iterates initiated near\nx = 0 still converges to x.\nThus x = 0 is an unstable fixed point, while x = x is stable.\nWhat determines stability? Consider graphically the case μ = 0.9:\nx\nf(x)\nWe infer that the slope f ′( x) determines whether x is stable. We proceed to\nshow this formally.\nSuppose x∗is any fixed point such that\nx∗= f(x∗).\nDefine\nxk = x∗+ εk,\nεk small.\nIn general, our mappings are described by\nxk+1 = f(xk).\n\nThen\nx∗+ εk+1 = f(x∗+ εk)\n= f(x∗) + f ′(x∗)εk + O(ε2\nk)\nTherefore\nεk+1 ≃f ′(x∗)εk.\nThus\n|f ′(x∗)| < 1 ⇒\nstability.\nIt is instructive to compare the stability of 1-D maps to the stability of the\n1-D flow\nx = f(x).\nRecall that the direction of flow depends on the sign of f(x) and that the\nstability at x∗depends on the sign of f ′(x∗):\nf(x)\nx\nx\nx1\nx2\nWhereas the stability of a continuous 1-D flow f depends on the sign of\nf ′(x∗), the stability of a 1-D map depends on the magnitude |f ′(x∗)|.\nIn higher dimensions this same distinction holds for the eigenvalues λ of\nthe Jacobian (which, in the case of mappings, we have called the Floquet\nmatrix). That is, the sign of Re(λ) determines the stability of flows, whereas\nthe magnitude |λ| is the relevant quantity for maps.\n1.4\nRelation of flows to maps\nWe now consider explicitly how flows may be related to maps.\n\n1.4.1\nExample 1: the van der Pol equation\nConsider again the van der Pol equation\nd2θ\ndt2 + ε(θ2 -1)dθ\ndt + θ = 0\nRecall that for ε > 0 the rest position is unstable and that the system has a\nlimit cycle.\nWe draw a ray emanating from the origin, and consider two representative\ntrajectories initiating and terminating on it:\nLet xk be the position of the kth intersection of the trajectory with the ray.\nThere is then some mapping f such that\nxk+1 = f(xk).\nThe precise form of f(x) is unknown, but physical and mathematical reason-\ning allows us to state some of its properties:\n- f maps xk to a unique xk+1.\n- f is continuous.\n- f ′(x) > 1 near the origin (divergent spirals).\n- f ′(x) < 1 far from the origin (convergent spirals).\n\n- f ′(x) > 0 for all x > 0 (since f(x + δ) > f(x)).\nThe simplest form of f is therefore a curve rising steeply from the origin,\nfollowed by a gentle upward slope:\nx*\nf(x*)\nx\nf(x)\nxk+1 = xk\nBy continuity, there must be a stable fixed point x∗characterized by\nx∗= f(x∗)\nand\nf ′(x∗) < 1.\nThus x∗gives the effective radius of the stable limit cycle.\n1.4.2\nExample 2: R ossler attractor\nConsider the following 3-D flow (the R ossler attractor):\nx = -y -z\ny = x + ay\nz = b + z(x -c)\na, b, and c are fixed parameters.\nNumerical solutions yield the time series x(t):\nt\n-10\n-5\nx(t)\n\nThe time series z(t):\ng\nz(t)\nThe true x-y phase plane:\n-10\n-5\nx(t)\n-10\n-5\ny(t)\nThe true flow in 3D:\nThe time series--especially z(t)--display significant irregularity, but the 2D\nphase plane and the 3D flow flow display some order.\nConsider now a Poincar e section in the plane\ny + z = 0.\nFrom the R ossler equations, we identify this plane with extrema in the time\n\nseries x(t), i.e., each intersection of the plane corresponds to\nx = 0.\nConsider a sequence xmax(k) of such extrema, but only when the extremum\nis a maximum of x(t).\nThen plot xmax(k + 1) vs. xmax(k):\nxmax(k)\nxmax(k+1)\nConclusions:\n- The 1-D map--a Poincar e section in the plane y = -z-reveals that the\nflow contains much order.\n- The time series, however, displays no apparent regularity.\nThis is the essence of deterministic chaos.\nWe proceed to show how such Poincar e sections and 1-D maps can be con-\nstructed from experimental data.\n1.4.3\nExample 3: Reconstruction of phase space from experimental data\nSuppose we measure some signal x(t) (e.g., the weather, the stock market,\netc.)\nIn most cases it is unlikely that we can specify the equations of motion of the\ndynamical system that is generating x(t).\n\nHow, then, may we visualize the system's phase space and its attractor?\nThe (heuristic but highly successful) idea is to measure any 3 independent\nquantities from x(t).\nFor example:\n- x(t), x(t+τ), x(t+ 2τ); τ large enough for \"independence,\" i.e., beyond\nan autocorrelation time. This is the most popular; it is known as the\nmethod of delays.\n- x(t), x(t), x(t) (where the derivatives are finite differences xk -xk-1,\netc.).\nSuch a representation of the attractor is not identical to the \"real\" phase\nspace, but it should retain similar geometric properties.\nAlthough we have discussed only qualitative, geometric properties. we shall\nsee that the various representations also yield similar quantitative properties\n(e.g., measures of Lyaponov exponents).\nYou'll investigate these ideas further in the next problem set.\nReferences\n1.\nBerg e, P., Pomeau, Y. & Vidal, C. Order within Chaos: Towards a De-\nterministic Approach to Turbulence (John Wiley and Sons, New York,\n1984).\n2.\nPackard, N. H., Crutchfield, J. P., Farmer, J. D. & Shaw, R. S. Geometry\nfrom a time series. Physical review letters 45, 712 (1980).\n3.\nStrogatz, S. Nonlinear Dynamics and Chaos: With Applications to Physics,\nBiology, Chemistry, and Engineering (CRC Press, 2018).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "12.006J F2022 Lectures 17–18: Fluid Dynamics and Rayleigh-Benard Convection",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/mit12_006jf22_lec17-18.pdf",
      "content": "Lecture notes for 12.006J/18.353J/2.050J, Nonlinear Dynamics: Chaos\nD. H. Rothman, MIT\nOctober 24, 2022\nContents\nFluid dynamics and Rayleigh-B enard convection\n1.1\nThe concept of a continuum . . . . . . . . . . . . . . . . . . .\n1.2\nMass conservation . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3\nMomentum conservation . . . . . . . . . . . . . . . . . . . . .\n1.3.1\nSubstantial derivative . . . . . . . . . . . . . . . . . . .\n1.3.2\nForces on fluid particle . . . . . . . . . . . . . . . . . .\n1.4\nNondimensionalization of Navier-Stokes equations . . . . . . .\n1.5\nRayleigh-B enard convection . . . . . . . . . . . . . . . . . . .\n1.6\nRayleigh-B enard equations . . . . . . . . . . . . . . . . . . . .\n1.6.1\nDimensional form . . . . . . . . . . . . . . . . . . . . .\n1.6.2\nDimensionless equations . . . . . . . . . . . . . . . . .\n1.6.3\nBifurcation diagram\n. . . . . . . . . . . . . . . . . . .\n1.6.4\nConvection in the Earth . . . . . . . . . . . . . . . . .\nFluid dynamics and Rayleigh-B enard convection\nReference: Tritton [1]\nIn these lectures we derive (mostly) the equations of fluid dynamics. We\nthen show how they may be generalized to the problem of Rayleigh-B enard\nconvection--the problem of a fluid heated from below. Later we show how\nthe RB problem itself may be reduced to the famous Lorenz equations.\nSome topics to be discussed:\n- The Navier-Stokes equations\n- Reynolds number\n\n- RB convection\n- Rayleigh number\nThus far we have dealt almost exclusively with the temporal behavior of a\nfew variables.\nIn these lectures we digress, and discuss the evolution of a continous field in\nspace and time.\nAside from the central role played by research in fluid turbulence and RB\nconvection in the development of the theory of chaos, we have another mo-\ntivation: an appreciation of a hierarchy of mathematical descriptions of dy-\nnamical systems, ranging from pde's to ode's to discrete maps.\n1.1\nThe concept of a continuum\nReal fluids are made of atoms or molecules. We could in principle write ordi-\nnary differential equations for the position and momentum of each particle.\nBut then we'd have ∼1023 equations! The concept of a continuum allows us\nto write a partial-differential equation instead.\nWe proceed to describe the essential assumption that makes this possible.\nConsider the following macroscopic length scales in a flow:\nU\nl\nl\nl\nIn adddition to the length scales li above, we define\n- Lhydro: the smallest characteristic length scale of macroscopic motions.\n\n- the mean free path lmfp: the characteristic length scale between molecular\ncollisions.\nFluids may be regarded as continuous fields if\nLhydro ≫lmfp.\nWhen this condition holds, the evolution of the macroscopic field may be\ndescribed by continuum mechanics, i.e., partial differential equations.\nTo make this idea clearer, consider a thought experiment in which we measure\nthe density of a fluid over a length scale lusing some particularly sensitive\ndevice. We then move the device in the x-direction over a distance of roughly\n10l.\nSuppose l∼L1 ∼lmfp. Then we expect the density to vary greatly in space\nas in Figure (a) below:\n(a)\n(b)\n(c)\nhydro\nx/L\nx/L\nx/L\ndensity\nWe expect that the fluctuations in (a) should decrease as lincreases. (Statistics\ntells us that these fluctuations should decrease like 1/N1/2, where N ∝l3 is the average number of\nmolecules in a box of size l. )\nOn the other hand, if l∼Lhydro (see (c)), variations in density should reflect\ndensity changes due to macroscopic motions (e.g., a rising hot plume), not\nmerely statistical fluctuations.\nOur assumption of a continuum implies that there is an intermediate scale,\nl∼L2, over which fluctuations are small. Thus the continuum hypothesis\n\nimplies a separation of scales between the molecular scale, L1 ∼lmfp, and the\nhydrodynamic scale, Lhydro.\nThe motion of the continuum is expressed by partial differential equations for\nevolution of conserved quantities. We begin with the conservation of mass.\n1.2\nMass conservation\nLet\nρ = density\nu = velocity\n\nof a macroscopic fluid particle\nConsider a volume V of fluid, fixed in space:\nV\ndS\nu\nds is an element of the surface, |ds| is its area, and it points in the outward\nnormal direction.\nu is the velocity.\nThe outward mass flux through the element ds is\nρu · ds.\nTherefore,\nrate of mass loss from V =\nZ\ns\nρu · ds.\nThe total mass in V is\nZ\nV\nρdv\nThus the rate of mass loss may be rewritten as\n-d\ndt\nZ\nV\nρdv = -\nZ\nV\n∂ρ\n∂t dv = +\nZ\ns\nρu · ds\n\nShrinking the volume, we eliminate the volume integrals and obtain\n∂ρ\n∂t = -lim\nV →0\nZ\nρu · ds/V\n\n.\nRecall that the RHS above is the definition of the divergence operator. We\nthus obtain\n∂ρ\n∂t = -∇· (ρu)\nWe see that to conserve mass, a net divergence creates a corresponding change\nin density.\nFor incompressible fluids,\nρ ∼constant.\n(This result is not an assumption, but instead derives from the assumption that the Mach number,\nthe square of the ratio of the fluid velocity to the speed of sound, is much less than unity.)\nThen\n∇· u = 0.\nwhich is the equation of continuity for incompressible fluids.\n1.3\nMomentum conservation\nWe seek an expression of Newton's second law:\nd\ndt(momentum of fluid particle) = force acting on fluid particle\n(1)\n1.3.1\nSubstantial derivative\nWe first focus on the LHS of (1).\nThere is a conceptual problem: d\ndt(particle momentum) cannot be given at a\nfixed location, because\n- the momentum field itself changes with respect to time; and\n\n- fluid particle can change its momentum by flowing to a place where the\nvelocity is different.\nTo better understand this problem physically, consider how a scalar property--\nthe temperature T--of a fluid particle changes in time.\nA small change δT is produced by small changes δt in time and δx, δy, δz in\nthe position of the fluid particle:\nδT = ∂T\n∂t δt + ∂T\n∂x δx + ∂T\n∂y δy + ∂T\n∂z δz\nDivide by δt to obtain the rate of change:\nδT\nδt = ∂T\n∂t + ∂T\n∂x\nδx\nδt + ∂T\n∂y\nδy\nδt + ∂T\n∂z\nδz\nδt\nIn the limit δt →0,\nδx\nδt →ux,\nδy\nδt →uy,\nδz\nδt →uz\nThe rate of change of T of a fluid particle is then\nDT\nDt\n= ∂T\n∂t + ux\n∂T\n∂x + uy\n∂T\n∂y + uz\n∂T\n∂z\n= ∂T\n∂t + u · ∇T\nwhere\nD\nDt = ∂\n∂t + u · ∇\nis the substantial derivative or convective derivative operator.\nThus we see that the temperature of a fluid particle can change because\n- the temperature field changes \"in place\" (via ∂/∂t); and\n- the particle can flow to a position where the temperature is different (via\nu · ∇).\n\nNote that the same analysis applies to vector fields such as the velocity u:\nDu\nDt = ∂u\n∂t + (u · ∇)u\nTherefore the velocity u enters Du/Dt in 2 ways:\n- u changes (in place) as the fluid moves (∂/∂t)\n- u governs how fast that change occurs (u · ∇).\nThis dual role of velocity is the essential nonlinearity of fluid dynamics and\nthus the cause of turbulent instabilities.\nWe can now express the rate-of-change of momentum per unit volume (i.e.,\nLHS of (1)):\nρDu\nDt = ρ∂u\n∂t + ρ(u · ∇)u\nρ is outside the differential because a fluid particle does not lose mass. Density changes thus mean\nvolume changes, which are irrelevant to the momentum change of that particle. Above we have\nwritten the (rate of change of momentum) per unit volume, which need not be equal to the rate of\nchange of (momentum per unit volume).\n1.3.2\nForces on fluid particle\nTo obtain the full dynamical equation, we need the RHS of\nρDu\nDt = Force acting on fluid particle / unit volume.\nThese forces are\n- body force (i.e., gravity)\n- pressure\n- viscous friction (internal stresses)\n\nBody force: We represent the externally imposed body force (per unit volume)\nby F.\nPressure: Fluid flows from high to low pressure. Thus\npressure force\nunit volume\n= -∂p\n∂x\nin 1-D\n= -∇p\nin 3-D\nViscous friction: Viscous stresses are the source of dissipation in fluids. They\nresist relative movements between fluid particles.\nFor example, the shear flow\ny\nx\nu\nu\nis resisted more by high viscosity fluids than low viscosity fluids.\nThis resistance derives from molecular motions. (A nice analog is Reif's picture of\ntwo mail trains, one initially fast and the other initially slow, that trade mailbags.)\nIn the simple shear flow above, random atomistic motions result in a flux of\nx-momentum in the y-direction.\nIn Newtonian fluids, this flux, which we call Pxy, is proportional to the ve-\nlocity gradient:\nPxy = -η∂ux\n∂y\nwhere η is called the dynamic viscosity. η has units of mass/(length × time).\nThe shear stress can occur at any orientation. Analogous to the 1-D Newto-\n\nnian condition above, we define the viscous momentum flux\nPij = -η ∂ui\n∂xj\n.\nThe conservation of momentum requires that the divergence of the momen-\ntum flux Pij be balanced by a change in the momentum of a fluid particle.\nLoosely stated,\n∂(ρui)\n∂t\n\nviscous\n= -∇· Pij = -\nX\nj\n∂\n∂xj\nPij = η\nX\nj\n∂2\n∂x2\nj\nui\nWe thus find that\nviscous force\nunit volume = η∇2u.\n(A careful derivation requires consideration of the tensorial relationship between viscous stress and\nthe rate of deformation.)\nNewton's second law then gives the Navier-Stokes equation for incompressible\nfluids:\nρ∂u\n∂t + ρ(u · ∇)u\n|\n{z\n}\n(mass per unit vol)×acceleration\n=\n-∇p + η∇2u\n|\n{z\n}\nstresses on fluid element per unit vol\n+\nF\n|{z}\nbody force per unit vol\nIncompressibility arose from our negelect of compressive forces on fluid ele-\nments.\n1.4\nNondimensionalization of Navier-Stokes equations\nDefine the characteristic length scale L and velocity scale U. We obtain the\nnon-dimensional quantities\nx′ = x\nL,\ny′ = y\nL,\nz′ = z\nL\nu′ = u\nU ,\nt′ = tU\nL,\np′ =\np\nρU 2\n\nThe dynamical equations (without body force) become\n∇′ · u′ = 0\n∂u′\n∂t′ + (u′ · ∇′)u′ = -∇′p′ + 1\nRe∇′2u′\nwhere\nRe = Reynolds number = ρUL\nη\nis the dimensionless control parameter.\nThe Reynolds number quantifies the relative importance of the nonlinear term\nto the viscous term. To see why, note the following dimensional quantities:\n|ρu · ∇u| ∼ρU 2\nL\nnonlinearity\n|η∇2u| ∼ηU\nL2\ndissipation\nTheir ratio is\n|ρu · ∇u|\n|η∇2u|\n∼ρUL\nη\n= Reynolds number\nHigh Re is associated with turbulence (i.e., nonlinearities). Low Re is asso-\nciated with laminar or creeping flows dominated by viscous friction.\nNote that as long as Re remains the same, the dimensional parameters like\nU and L can change but the the flow (i.e., the equation it solves) does not.\nThis is dynamical similarity.\nAn example is running vs. swimming:\nη\nρ\n\nair\n= 0.15 cm2/sec\nand\nη\nρ\n\nwater\n= 0.01 cm2/sec\nOn the other hand, comparing 100 meter world records,\nUrun ∼104 cm\n10 sec = 103 cm/sec\nUswim ∼104 cm\n50 sec ∼2 × 102 cm/sec\n\nTaking L ∼100 cm,\nRe(swim) ∼2 × 104\nand\nRe(run) ∼6 × 103\nThus for both swimming and running, Re ∼104, well into the turbulent\nregime.\nSurprisingly, despite the slower speed of swimming, Re(swim) is\nsomewhat greater.\nAnother example: bacteria swimming in water is roughly like us swimming in\nmolasses, since the the small size and slow speed of bacteria would correspond\nto a larger and faster body in a more viscous fluid.\n1.5\nRayleigh-B enard convection\nIn a thermally expansive fluid, hot fluid rises.\nR-B convection concerns the study of the instabilities caused by rising hot\nfluid and falling cold fluid.\nTypically, fluid is confined between two horizontal, heat-conducting plates:\nT=T0 + δT\nT=T0 + δT\nd\ng\nT=T0\n(cold)\nfluid\ntemperature\npure\nconduction\nT0\n(hot)\nIn the absence of convection--the transport of hot fluid up and cold fluid\ndown--the temperature gradient is constant.\nTwo cases of interest:\n- δT small: no convective motion, due to stabilizing effects of viscous\nfriction.\n\n- δT large: convective motion occurs.\nHow large is a \"large δT\" ? We seek a non-dimensional formulation.\nThe following fluid properties are important:\n- viscosity\n- density\n- thermal expansivity\n- thermal diffusivity (heat conductivity)\nConvection is also determined by\n- d, the box size\n- δT (of course)\nConsider a small displacement of a cold blob downwards and a hot blob\nupwards:\nT=T0 + δT\nT=T0\nLeft undisturbed, buoyancy forces would allow the hot blob to continue rising\nand cold blob to continue falling.\nThere are however damping (dissipation) mechanisms:\n- diffusion of heat\n\n- viscous friction\nLet DT = thermal diffusivity, which has units\n[DT] = length2\ntime\nThe temperature difference between the two blobs can therefore be main-\ntained at a characteristic time scale\nτth ∼d2\nDT\nWe also seek a characteristic time scale for buoyant displacement over the\nlength scale d.\nLet\nρ0 = mean density\n∆ρ = -αρ0∆T,\nα = expansion coefficient\nSetting ∆T = δT,\nbuoyancy force density = |g∆ρ|\n= gαρ0 δT.\nNote units:\n[gαρ0δT] =\nmass\n(length)2(time)2\nThe buoyancy force is resisted by viscous friction between the two blobs\nseparated by ∼d.\nThe viscous friction between the two blobs diminishes like 1/d (since viscous\nstresses ∝velocity gradients). The rescaled viscosity has units\nhη\nd\ni\n=\nmass\n(length)2(time)\nDividing the rescaled viscosity by the buoyancy force, we obtain the charac-\nteristic time τm for convective motion:\nτm ∼\nη/d\nbuoyancy force =\nη\ngαρ0 d δT .\n\nConvection (sustained motion) occurs if\ntime for motion < diffusion time for temperature difference\nτm < τth\nThus convection requires\nτth\nτm\n> constant\nor\nρ0gαd3\nηDT\nδT ≡Ra > constant\nRa is the Rayleigh number. A detailed stability calculation reveals that the\ncritical constant is 1708.\nOur derivation of the Rayleigh number shows that the convective instability\nis favored by\n- large δT, α, d, ρ0.\n- small η, DT.\nIn other words, convection occurs when the buoyancy force ρ0gαd3 δT exceeds\nthe dissipative effects of viscous drag and heat diffusion.\nNote that box height enters Ra as d3. This means that small increases in box\nsize can have a dramatic effect on Ra.\nFor Ra sufficiently large, the flow becomes turbulent. Some examples (from\nProf. Jun Zhang, NYU):\nHere the gray scale is related to the thermal\ngradient.\nImage courtesy of Prof. Jun Zhang, NYU. Used with permission.\n\nHere the viscous flow moves the floating\nboundary and the the boundary affects the\nflow, an interplay roughly analogous to fluid\nmotions beneath tectonic plates.\nA close-up (red is cool,\nblue is warm).\nAnd here's a picture of downgoing cold plumes (red) plunging from the upper\nthermal boundary layer into the warm (blue) fluid below:\nZocchi et al. [2]\nImage courtesy of Prof. Jun Zhang, NYU. Used with permission.\nImage courtesy of Prof. Jun Zhang,\nNYU. Used with permission.\nCourtesy Elsevier, Inc., http://www.sciencedirect.com. Used with permission.\n\n1.6\nRayleigh-B enard equations\n1.6.1\nDimensional form\nWe employ the Boussinesq approximation: density perturbations affect only\nthe gravitational force.\nThe momentum equation is therefore the Navier-Stokes equation augmented\nby the buoyancy force:\n∂u\n∂t + u · ∇u = -1\nρ0\n∇p + ν∇2u -gα(T -T0)\nHere we have written the kinematic viscosity\nν = η/ρ0\nThe mass conservation equation is again\n∇· u = 0.\nWe now additionally require an equation for the convection and diffusion of\nheat:\n∂T\n∂t + (u · ∇)T = DT∇2T.\n1.6.2\nDimensionless equations\nThe equations are nondimensionalized using\nlength scale = d\ntime scale = d2/DT\ntemperature scale = δT/Ra.\nAn additional dimensionless parameter arises:\nPr = Prandtl number = ν/DT,\nwhich is essentially the ratio of momentum diffusion to thermal diffusion.\n\nWe also use the dimensionless temperature fluctuation\nθ = deviation of dimensionless T from the simple conductive gradient\nDropping primes, the mass conservation equation is\n∇· u = 0.\nMomentum conservation yields (ˆz is the unit vector pointing up)\nPr\n∂u\n∂t + u · ∇u\n\n= -∇p + θˆz + ∇2u.\nThe heat equation becomes\n∂θ\n∂t + u · ∇θ = Ra(u · ˆz) + ∇2θ\nNote that there are two nonlinear terms:\n- u · ∇u\n- u · ∇θ\nTheir relative importance depends on Pr:\n- small Pr ⇒u · ∇u dominates. Instabilities are \"hydrodynamic.\"\n- large Pr ⇒u · ∇θ dominates. Instabilities are thermally induced.\n1.6.3\nBifurcation diagram\nFor Ra < Rac, there is no convection.\nFor Ra > Rac, but not too large, a regular structure of convection \"rolls\"\nforms, with hot fluid rising and cold fluid falling:\n\nT = T0\nT = T0 + δ\nd\nd\nNow imagine placing a probe that measures the vertical component v of\nvelocity, somewhere in the box midway between the top and bottom. A plot\nof v(Ra) looks like\nv\n0 conduction\nrest\nv+\nv-\nconvection (stable)\nconduction\n(unstable)\nRa\nRac\nThe transition from conduction to convection is therefore a supercritical\npitchfork bifurcation.\nNote that at any particular location we cannot know in advance whether the\nsymmetry is broken by an upgoing or downgoing velocity.\n1.6.4\nConvection in the Earth\nThe Earth's radius is about 6378 km. It is layered, with the main divisions\nbeing the inner core, outer core, mantle, and crust.\nThe Earth's crust--the outermost layer--is about 30 km thick.\nThe mantle ranges from about 30-2900 km.\nThe mantle is widely thought to be in a state of thermal convection. The\n\nsource of heat is thought to be the radioactive decay of isotopes of uranium,\nthorium, and potassium. Another heat source is related to the heat deriv-\ning from the gravitational energy dissipated by the formation of the Earth\nroughly 4.5 Ga.\nAt long time scales mantle rock is thought to flow like a fluid. However its\neffective viscosity is the subject of much debate.\nOne might naively think that the huge viscosity would make the Rayleigh\nnumber quite small. Recall, however, that Ra scales like d3, where d is the\n\"box size\". For the mantle, d is nearly 3000 km!!!\nConsequently Ra is probably quite high. Current estimates suggest that\n3 × 106 ≲Ramantle ≲109\nwhich corresponds to roughly\n103 × Rac ≲Ramantle ≲106Rac\nThe uncertainty derives principally from the viscosity, and its presumed vari-\nation by a factor of about 300 with depth.\nRegardless of the uncertainty, we can conclude that Ra for the mantle is\nmore than sufficient for convection, and therefore that convection is likely\nthe driving force of plate tectonics and volcanism.\nIt turns out that volcanism is, over the long-term, responsible for the CO2\nin the atmosphere, and thus the source of carbon that is fixed by plants.\n(Weathering reactions remove C from the atmosphere.)\nThus in some sense thermal convection may be said to also sustain life.\nThat is, without convection, there probably would be no CO2 in the atmo-\nsphere, and therefore we wouldn't be around to discuss it...\n\nReferences\n1.\nTritton, D. J. Physical Fluid Dynamics, 2nd edition (Clarendon Press,\nOxford, 1988).\n2.\nZocchi, G., Moses, E. & Libchaber, A. Coherent structures in turbulent\nconvection, an experimental study. Physica A: Statistical Mechanics and\nits Applications 166, 387-407 (1990).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n12.006J/18.353J/2.050J Nonlinear Dynamics: Chaos\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "allee_random.py",
      "type": "PY",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/allee_random.py",
      "content": "#!/usr/bin/env python3\n\n# here, we integrate Eq. (1) using a simple explicit Euler method\n# where we add random noise at each timestep\n# we're also going to change the parameter b linearly as time progresses\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import ode\nplt.rcParams.update({'font.size':14})\n\n# DEFINE FUNCTIONS\n# function to calculate the stable fixed point\ndef stable_fixed_point(r,a,b):\nreturn a/2 + np.sqrt(a**2/4-b)\n\n# defining the model: i.e. f(N,r,a,b)\ndef model(N,params):\nr,a,b = params\nndot = r*N*(-N**2+a*N-b)\nreturn ndot\n\n# DEFINE PARAMETERS: this is what you might need to change\n# define constants r and a, and the start and end values of b\nr = 1\na = 8\nb_start = 14\nb_end = 15\n\n# set up start and end times of the integration\ntstart = 0\ntend = 250\n\n# timestep (recommend not touching this)\ndt = 0.05\n\n# amplitude of random noise\namplitude = 0.6\n\n# INTEGRATE AND PLOT\nt = np.linspace(tstart,tend,int((tend-tstart)/dt))\nb_ramp = np.linspace(b_start,b_end,len(t))\nN = np.zeros(len(t))\nN[0] = stable_fixed_point(r,a,b_ramp[1])\n\nfor i in range(1,len(t)):\nN[i] = N[i-1] + model(N[i-1],[r,a,[b_ramp[i]]])*dt + np.random.normal(0,amplitude*dt)\n\nplt.plot(t,N)\nplt.xlabel('Time')\nplt.ylabel('N')\nplt.show()"
    },
    {
      "category": "Resource",
      "title": "allee.py",
      "type": "PY",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/allee.py",
      "content": "#!/usr/bin/env python3\n\n# integrates the simple model from Eq. (1) in Problem Set 2\n# we use the Scipy ode package: \"dop853\" refers to an eighth-order Runge-Kutta method (basically a fancy Euler method)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import ode\nplt.rcParams.update({'font.size':14})\n\n# DEFINE FUNCTIONS\n# the model itself\ndef model(t,N,params):\nr,a,b = params\nndot = r*N*(-N**2+a*N-b)\nreturn ndot\n\n# DEFINE PARAMETERS: this is what you might need to change\n# constants r, a, and b\nr = 1\na = 8\nb = 13\n\n# set up start and end times of the integration\ntstart = 0\ntend = 1\n\n# timestep\ndt = 0.01\n\n# initial condition\nN0 = 4\n\n# INTEGRATE AND PLOT\nt = np.linspace(tstart,tend,int((tend-tstart)/dt))\nN = np.zeros(len(t))\nN[0] = N0\n\nmodel_instance = ode(model).set_integrator(\"dop853\")\nmodel_instance.set_initial_value(N[0]).set_f_params([r,a,b])\n\nfor i in range(1,len(t)):\nmodel_instance.integrate(model_instance.t+dt)\nN[i] = model_instance.y\n\nplt.plot(t,N)\nplt.show()"
    },
    {
      "category": "Resource",
      "title": "bifdiag.py",
      "type": "PY",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/bifdiag.py",
      "content": "#!/usr/bin/env python3\n\n# Generate bifurcation diagrams for 1-D maps.\n#\n# For a range of different mu values, iterate the map for N steps and plot\n# the last L points. The assumption is that the last L points reflect the\n# asymptotic behavior.\n#\n# Example: bifdiag(0,0.001,1,1000,100)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef bifdiag(mu_start, mu_interval, mu_stop, N, L):\n\nplt.figure()\nx0=0.1 # initial condition\n\nmu = np.arange(mu_start,mu_stop,mu_interval)\n\nfor i in range(0,len(mu)):\nx = x0*np.ones((N))\nfor j in range(0,N-1):\nx[j+1] = 4*mu[i]*x[j]*(1-x[j]) # logistic map\n\nmu_plot = mu[i]*np.ones((L))\nplt.scatter(mu_plot, x[len(x)-L:len(x)],color='black',s=0.1);\n\nplt.show()"
    },
    {
      "category": "Resource",
      "title": "fft_demo.py",
      "type": "PY",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/fft_demo.py",
      "content": "#!/usr/bin/env python3\n\n# code to demonstrate usage of the fast Fourier Transform\n# notation generally follows the lecture notes\n# you will have to get from the DFT to the power spectrum by yourself\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# as a demonstration, set up an oscillation with frequency 1/100\n# we do this in terms of n rather than t,\n# this is equivalent to using a timestep of 1\nnmax = 1000\nn = np.arange(0,nmax,1)\nx = np.sin(2*np.pi*n/100)\n\n# calculate Discrete Fourier Transform\ndft = np.fft.fft(x)\nfreq = n/nmax\nplt.figure()\nplt.plot(freq,dft)\nplt.xlabel('Frequency')\nplt.ylabel('x_k')\n\nplt.show()"
    },
    {
      "category": "Resource",
      "title": "fitzhugh_nagumo.py",
      "type": "PY",
      "source_url": "https://ocw.mit.edu/courses/12-006j-nonlinear-dynamics-chaos-fall-2022/fitzhugh_nagumo.py",
      "content": "#!/usr/bin/env python3\n\n# integrates the FitzHugh-Nagumo model, making phase space and time evolution plots\n# we use the Scipy ode package: \"dop853\" refers to an eighth-order Runge-Kutta method (basically a fancy Euler method)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import ode\nplt.rcParams.update({'font.size':14})\n\n# DEFINE FUNCTIONS\n# the model itself\ndef model(t,x,params):\na,b,c = params\nxdot = np.zeros(2)\nxdot[0] = -x[1]+x[0]*(a-x[0])*(x[0]-1)\nxdot[1] = b*x[0]-c*x[1]\n\nreturn xdot\n\n# DEFINE PARAMETERS\n# you will have to change this\na = 0.1\n\n# we recommend not changing this\nb = 0.01\nc = 0.02\n\n# set up start and end times of the integration\ntstart = 0\ntend = 1000\n\n# timestep\ndt = 0.1\n\n# initial condition\nx0 = [0.2,0.0]\n\n# INTEGRATE AND PLOT\nt = np.linspace(tstart,tend,int((tend-tstart)/dt))\nx = np.zeros((len(t),2))\nx[0,:] = x0\n\nmodel_instance = ode(model).set_integrator(\"dop853\")\nmodel_instance.set_initial_value(x[0,:]).set_f_params([a,b,c])\n\nfor i in range(1,len(t)):\nmodel_instance.integrate(model_instance.t+dt)\nx[i,:] = model_instance.y\n\n# plot phase space evolution\nplt.plot(x[:,0],x[:,1],label='trajectory')\nplt.xlabel('x')\nplt.ylabel('y')\n\n# plot nullclines\nx_null = np.linspace(-0.25,1,100)\nplt.plot(x_null,x_null*(a-x_null)*(x_null-1),label='dx/dt = 0')\ny_null = np.linspace(-0.05,0.3,100)\nplt.plot(y_null*c/b,y_null,label='dy/dt=0')\nplt.legend()\n\n# plot time evolution plot\nplt.figure()\nplt.plot(t,x[:,0])\nplt.xlabel('Time')\nplt.ylabel('x')\n\nplt.show()"
    }
  ]
}