{
  "course_name": "Game Theory",
  "course_description": "This course provides a rigorous treatment of non-cooperative solution concepts in game theory, including rationalizability and Nash, sequential, and stable equilibria. It covers topics such as epistemic foundations, higher order beliefs, bargaining, repeated games, reputation, supermodular games, and global games. It also introduces cooperative solution concepts—Nash bargaining solution, core, Shapley value—and develops corresponding non-cooperative foundations.",
  "topics": [
    "Social Science",
    "Economics",
    "Game Theory",
    "Social Science",
    "Economics",
    "Game Theory"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nRecitations: 1 session / week, 1 hour / session\n\nPrerequisite\n\n14.122 Microeconomic Theory II\nis the prerequisite for this course.\n\nGrading\n\nACTIVITIES\n\nPERCENTAGES\n\n4 problem sets\n\n40%\n\nTake-home final exam\n\n60%\n\nRecommended Textbook\n\nFudenberg, Drew, and Jean Tirole.\nGame Theory\n. MIT Press, 1991. ISBN: 9780262061414.\n\nTopics\n\n1. Solution Concepts for Static Games\n\na. Complete information: rationalizability, Nash equilibrium, epistemic foundations\n\nb. Incomplete information: Bayesian Nash equilibrium, interim correlated\n\nrationalizability\n\n2. Solution Concepts for Extensive-form Games\n\na. Backwards induction, subgame perfection, iterated conditional dominance\n\nb. Bargaining with complete information\n\n3. Equilibrium Concepts for Games with Imperfect Information\n\n4. Signaling and Forward Induction\n\na. Stable equilirium, the intuitive criterion, iterated weak dominance, epistemic\n\nfoundations\n\n5. Repeated Games\n\n6. Reputation Formation\n\na. Reputation with short-lived opponents\n\nb. Screening and reputation in bargaining\n\n7. Supermodular Games\n\n8. Global Games\n\n9. Cooperative Games\n\na. Nash bargaining solution, core, Shapley value\n\nb. Non-cooperative implentations",
  "files": [
    {
      "category": "Assignment",
      "title": "14.126 S16 Problem Set 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/38a6c0a62cb3efebb9d4389f072c8073_MIT14_126S16_ProblemSet_1.pdf",
      "content": "14.126 GAME THEORY\nPROBLEM SET 1\nMIHAI MANEA\nQuestion 1\nProvide an example of a 2-player game with strategy set [0, inf) for either player and\npayoffs continuous in the strategy profile, such that no strategy survives iterated deletion of\nstrictly dominated strategies (Sinf= ∅), but the set of strategies remaining at every stage is\nnonempty (Sk = ∅for k = 1, 2, . . .).\nQuestion 2\nIn the normal form game below player 1 chooses rows, player 2 chooses columns, and\nL\nR\nU\nD\nA\nL\nR\nU\nD\nB\nL\nR\nU\nD\nC\nL\nR\nU\nD\nD\nplayer 3 chooses matrices. We only indicate player 3's payoff. Show that action D is not a\nbest response for player 3 to any independent belief about opponents' play (mixed strategy\nfor players 1 and 2), but that D is not strictly dominated. Comment.\nQuestion 3\nEach of two players i = 1, 2 receives a ticket with a number drawn from a finite set Θi.\nThe number written on a player's ticket represents the size of a prize he may receive. The\ntwo prizes are drawn independently, with the value on i's ticket distributed according to\nFi. Each player is asked simultaneously (and independently) whether he wants to exchange\nDate: February 17, 2016.\n\nMIHAI MANEA\nhis ticket for the other player's ticket. If both players agree then the prizes are exchanged;\notherwise each player receives his own prize. Find all Bayesian Nash equilibria (in pure or\nmixed strategies).\nQuestion 4\nA game G = (N, S, u) is said to be symmetric if S1 = S2 = · · · = Sn and there is some\nfunction f : S1 × Sn-1\n→R such that f(si, s\ni) is symmetric with respect to the entries in\n-\ns\ni, and ui (s) = f (si, s\n)\n-i for every player i.\n-\n(1) Consider a symmetric game G = (N, S, u) in which S1 is a compact and convex\nsubset of a Euclidean space and ui is continuous and quasiconcave in si. Show that\nthere exists a symmetric pure-strategy Nash equilibrium (i.e. a pure-strategy Nash\nequilibrium where every player uses the same strategy).\n(2) Suggest a definition for symmetric Bayesian games, G = (N, A, Θ, u, T, p), and find\nbroad conditions on such a game G that ensure that G has a symmetric Bayesian\nNash equilibrium.\n(3) Consider a Cournot oligopoly with inverse-demand function P and a cost function\nγ that is common to all firms.\nEach firm's cost depends on its production level\nand its idiosyncratic cost parameter, which is drawn from a finite set C. Assume\nthe vector of cost parameters (c1, . . . , cn) is symmetrically distributed. Each firm i\nprivately knows its own cost ci, but not the others' costs, and independently chooses\na quantity qi to produce. Find conditions on P and γ that guarantee existence of\na symmetric Bayesian Nash equilibrium in this game. (Note that the profit of each\nfirm i is qiP (q1 + · · · + qn) -γ (qi, ci).)\nQuestion 5\nLet N = {0, 1, . . . , n}2 be a two dimensional grid. Say that two points (x, y) and (x′, y′)\nin N are neighbors if |x-x′|+|y -y′| = 1. At each point i ∈N, there is a firm, also denoted\nby i. As in a Cournot oligopoly, simultaneously, each firm i chooses a quantity qi ∈[0, 1] to\n\nPROBLEM SET 1\nproduce at zero marginal cost, and sells at price\n\nX\nX\nk\ninf\nPi (θ, q, α) = θ -qi -\nαk-1\nk=1\n\nqj/ N k\ni\n.\nj∈Nk\ni\n\nHere, θ\n\n∈[1, 2] is a common demand parameter, and α ∈[0, 1) is an interaction parameter\nwith respect to distant neighbors. N k\ni is the k-th iterated set of neighbors of i: thus N 1\ni is\nthe immediate neighbors of i (e.g., N 1\n(0,0) = {(1, 0) , (0, 1)}), N 2\ni is the neighbors of neighbors\nof i (e.g., N 2\n(0,0) = {(0, 0) , (0, 2) , (2, 0) , (1, 1)}), and so on. The payoffof firm i is its profit:\nqiPi.\nThe value of α is common knowledge, but θ is unknown, drawn from some finite set\nΘ ⊆[1, 2]. The players' information about θ is represented by a finite type space T, with\nsome joint prior p ∈∆(Θ × T).\n(1) For any choice of a Bayesian Nash equilibrium qα\n∗: T →[0, 1]N of the above Bayesian\ngame (for each α), and for any ti ∈Ti, find limα\n0 qα\n∗(t\n→\ni).\n[It suffices to find a formula that consists of iterated expectations of the form\nEij1...jk [θ|ti] ≡E [E [· · · E [θ|tjk] · · · |tj1] |ti], where i, j1, . . . , jk ∈N.\nYour formula\ndoes not need to be in closed form, but it should not refer to q∗.]\n(2) Simplify your result in part (a) under the assumption that Eij [θ|ti] = E [θ|ti] for all\ni, j, and ti.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "14.126 S16 Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/f58708d8b2c0b9c44a62f68d02af6dd7_MIT14_126S16_ProblemSet_2.pdf",
      "content": "14.126 GAME THEORY\nPROBLEM SET 2\nMIHAI MANEA\nQuestion 1\nConsider the complete information game\nα\nβ\nα\nθ, θ\nθ -c, 0\nβ\n0, θ -c\n0, 0\nˆ\nwhere c > 0 and θ is equal to some known value θ ∈(0, c/2).\nImagine now an email\nˆ\ngame scenario in which there are two possible values of θ, namely θ and θ′, with some prior\nprobabilities p and 1-\nˆ\np. Player 1 knows the value of θ, and if θ = θ then the email exchange\ntakes place, where each email is lost with probability ε ∈(0, 1). If θ = θ′ then no emails\nare exchanged. For each action a ∈{α, β}, find the range of ε for which there is some email\ngame (i.e. some choice of θ′ and p) in which a is the unique rationalizable action for each\ntype. Briefly discuss your finding.\nQuestion 2\nLet G = (N, A, u) be a finite normal-form game. Suppose the players N play an infinite\nrepetition of G, but instead of discounting, players care only about the maximum of the per-\nperiod payoffs. That is, in each period t = 0, 1, 2, . . ., the stage game G is played, with each\nplayer having observed the action profile chosen at every previous period. This gives rise\nto an infinite history of action profiles (a0, a1, a2, . . .) (which may be random, if the players\nare mixing). For each realization of such a history, player i's payoffin the repeated game is\nDate: March 9, 2016.\n\nMIHAI MANEA\ndefined to be maxt\nu (at). Prove that (a) this repeated game is in general not continuous\n≥0\ni\nat infinity, but (b) the single-deviation principle still holds.\nQuestion 3\nFind all (a) Nash, (b) trembling-hand perfect, (c) proper equilibria (in pure or mixed\nstrategies) of the following normal-form game.\nL\nR\nU\n2,2\n2,2\nM\n3,3\n1,0\nD\n0,0\n1,1\nQuestion 4\nGive an example of a finite normal-form game G and a strategy profile σ such that for\neach player i, there exists a sequence σ1\ni, σ2\ni, . . . of independent trembles of i's opponents\n-\n-\n(i.e. each σk\ni specifies a full-support distribution over strategy profiles of players -i in which\n-\nthe various players j = i mix independently of each other), converging to σ\ni, such that σ\n-\ni\nis a best response to σk for each k, but σ is not a perfect equilibrium of G.\n-i\nQuestion 5\nIs the following statement true or false? Give a proof or counterexample. Suppose G\nis a finite extensive-form game with perfect recall, and hx = {x, x′}, hy = {y, y′} are two\ninformation sets, such that x is a predecessor of y, x′ is a predecessor of y′, and the action\ntaken from x along the tree toward y is the same as the action taken from x′ toward y′.\nThen there cannot be a consistent assessment (σ, μ) such that μ(x|hx) = 1 and μ(y|hy) = 0.\n(Note that this looks like the \"no signaling what you don't know\" condition, but now we do\nnot require that x immediately precedes y; there may be other nodes in between.)\nQuestion 6\nConsider the following version of Rubinstein alternating offers bargaining game. There are\nthree players and utility of player i = 1, 2, 3 from getting fraction xi of a pie in period T is\nequal to δTxi. In the first period, player 1 proposes a partition (i.e. a vector x = (x1, x2, x3)\nwith x1 + x2 + x3 = 1), and players 2 and 3 in turn accept or reject this proposal.\nIf\n\nPROBLEM SET 2\neither of them rejects it, then play passes to the next period, in which it is player 2s turn\nto propose a partition, to which players 3 and 1 in turn respond. If at least one of them\nrejects the proposal, then again play passes to the next period, in which player 3 makes a\nproposal, and players 1 and 2 respond. Players rotate proposals in this way until a proposal\nis accepted by both responders. Show that for any division of pie x if δ > 1/2 then there is\na subgame-perfect equilibrium in which x is agreed upon immediately.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "14.126 S16 Problem Set 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/7097eed6507aff970ab04db9488095a0_MIT14_126S16_ProblemSet_3.pdf",
      "content": "14.126 GAME THEORY\nPROBLEM SET 3\nMIHAI MANEA\nQuestion 1\nApply the forward-induction iterative elimination procedure described below to the fol-\nlowing game. Two players, 1 and 2, have to play the Battle of the Sexes (BoS) game with\nthe following payoffmatrix\nA\nB\nA\n3,1\nε, ε\nB\nε, ε\n1,3\nwhere ε is a small but positive number. Before playing this game, player 1 first decides\nwhether to burn a util; if he does so, his payoffs decrease by 1 at each action profile in BoS.\nThen player 2 observes player 1's decision and decides whether to burn a util herself, which\nwould reduce her payoffs by 1 for each action profile in BoS. After both players observe each\nother's burning decisions, they play BoS.\nThe iterative procedure is as follows. Let Si be player i's pure strategy space.\n- For step t = 0, set S0\ni = Si.\n- At any step t ≥1, for each player i and information set h of i, let ∆t\ni(h) be the set of\nall beliefs μi(h) ∈∆(St\ni) such that μi(s\nh\n-\n-i| ) > 0 only if h can be reached by some\nstrategy in Si × St\ni. For each si ∈St\ni, eliminate s\n-\ni if there exists an information set\nh for player i such that si is not sequentially rational at h with respect to any belief\nμ (h) ∈∆t(h). Let St+1\ni\ni\ni\ndenote the set of remaining strategies.\n- Iterate until no further elimination is possible.\nDate: April 9, 2016.\n\nMIHAI MANEA\nQuestion 2\n(a) Consider the repeated game RG(δ), where the stage game is matching pennies:\nH\nT\nH\n1,-1\n-1,1\nT\n-1,1\n1,-1\nFor any discount factor δ ∈(0, 1), find all the subgame-perfect equilibria of the\nrepeated game.\n(b) A game G = (N, A, u) is said to be a zero-sum game if\ni N ui(a) =\n∈\ni∈N ui(a′) for\nall a, a′ ∈A. For any discount factor δ ∈(0, 1) and an\nP\ny two-player zero-sum\nP\ngame,\ncompute the set of all payoffvectors that can occur in an SPE of the repeated game\nRG(δ).\nQuestion 3\nConsider the three-player coordination game shown below.\nA\nB\nA\n1,1,1\n0,0,0\nB\n0,0,0\n0,0,0\nA\nA\nB\nA\n0,0,0\n0,0,0\nB\n0,0,0\n1,1,1\nB\nShow that each player's minmax payoffis 0, but that there is ε > 0 such that in every\nSPE of the repeated game RG(δ), regardless of the discount factor δ, every player's payoff\nis at least ε. Why does this example not violate the Fudenberg-Maskin folk theorem?\nQuestion 4\nConsider a repeated game with imperfect public monitoring.\nAssume that the action\nspace and signal space are finite. Let E(δ) be the set of expected payoffvectors that can be\nachieved in perfect public equilibrium, where public randomization is available each period.\nShow that if δ < δ′, then E(δ) ⊆E(δ′).\nQuestion 5\nConsider a two-player, infinitely repeated game in which players maximize average dis-\ncounted value of stage payoffs with discount factor δ ∈(0, 1). At each date t, simultaneously\n\nPROBLEM SET 3\neach player i invests xi,t ∈{0, 1} in a public good, yt ∈{0, 1}, where\n\n2/3\nif x1,t + x2,t = 2\nP (yt = 1|x1,t, x2,t) =\n\n1/2\nif x1,t + x2,t = 1\nr\nif x1,t + x2,t = 0\nwhere r ∈(1/3, 5/12) is a parameter. The stage\n\npayoffof player i is 4yt -xi,t.\n(1) Assuming that all the previous moves are publicly observable, compute the most\nefficient symmetric subgame-perfect equilibrium (for each δ ∈(0, 1)).\n(2) Assume the previous levels of public goods (i.e., ys with s < t) are publicly observable\nbut individual investments are not. Find the range of δ under which the grim trigger\nstrategy profile is a public perfect equilibrium (Grim trigger: x1,t = x2,t = 0 if y has\never been 0 and x1,t = x2,t = 1 otherwise).\n(3) In part (b), find the range of δ under which the following is a public perfect equilib-\nrium: start with x1,t = x2,t = 1, and for any t > 0, select x1,t = x2,t = yt-1.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "14.126 S16 Problem Set 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/3cddd0c5553b4e65dbe5643a88518247_MIT14_126S16_ProblemSet_4.pdf",
      "content": "14.126 GAME THEORY\nPROBLEM SET 4\nMIHAI MANEA\nQuestion 1\nConsider a finitely repeated game with perfect monitoring, played by a long-run player\n(Player 1) against short run players (Player 2) for T rounds, where the stage game is\nB\nP\nH\n1, 1\n-1, 0\nL\n2, -1\n0, 0\nwith probability 1 -ε, and\nB\nP\nH\n1, 1\n-1, 0\nwith probability ε ∈(0, 1).\n(The stage game is the same in all periods.)\nThere is no\ndiscounting, and player 1 knows the stage game while the short run players do not. Find a\nsequential equilibrium of this game. For each ε > 0, find the minimal T under which Player\n1 plays H at the beginning for sure in the equilibrium you found. (You do not have to show\nthat the equilibrium is unique.)\nQuestion 2\nConsider an infinitely repeated game as in the Fudenberg-Levine setup discussed in the\nclass, with the following stage game. Each player i selects xi ∈X = {0, 0.01, 0.02, . . . , 0.99, 1}\nand the payoffof player i is\nui (x1, x2) =\n\nxi + (1 -x1 -x2) /2\nif x1 + x2 ≤1;\notherwise.\nDate: April 27, 2016.\n\nMIHAI MANEA\nAssume that for each x ∈X, there is a commitment type who plays x at every history.\nLet the probabilities of these types be fixed, and let the discount factor δ vary. Let v =\nlimδ\n1 U1 (σ [δ]) for some sequence (σ [δ]) where σ [δ] is a Nash equilibrium under discount\n→\nfactor δ and U1 is the expected average discounted utility of the rational type of the long-run\nplayer. What are the bounds on v given by Fudenberg and Levine?\nQuestion 3\nFor each case below, show that (X, ≥) is a lattice. Determine the join and meet operators\nand check whether it is complete.\n(1) X is the set of all probability distributions on the real line; ≥is the relation of\nfirst-order stochastic dominance.\nHint: You can take X as the set of CDFs F : R →[0, 1] and write\nF ≥G ⇐⇒[F (x) ≤G (x)\n∀x] .\nIf you feel more comfortable, you can confine X to continuous CDFs and/or restrict\nthe domain to [0, 1].\n(2) X is the set of all partitions of a fixed set A. ≥is the refinement ordering: for any\nP, P ′ ∈X, P ≥P ′ iffP is finer than P ′, i.e., for any S ∈P, S′ ∈P ′, if S ∩S′ = ∅,\nthen S ⊆S′. (You can take A finite if you feel more comfortable.)\n(3) Fix a finite type space (Θ∗, T ∗, p), where T ∗= T1\n∗× · · · × Tn\n∗and each type ti ∈Ti\n∗is\nassociated a belief pti ∈∆(Θ∗× T ∗). A belief-closed subspace is a pair (Θ, T), with\n-i\nT a nonempty set of the form T1 × · · · × Tn, where Θ ⊆Θ∗and Ti ⊆Ti\n∗for each i,\nand such that pti(Θ × T\ni) = 1 for each i and each ti ∈T .\n-\ni Take X to be the set of\nall belief-closed subspaces, together with (∅, ∅), and the ordering to be set inclusion:\n(Θ, T) ≥(Θ′, T ′) if Θ ⊇Θ′ and T ⊇T ′.\nQuestion 4\nConsider a Cournot oligopoly where players choose quantities qi, with set of firms N,\ninverse-demand function P, and with cost functions Ci(qi) for players i ∈N.\n(1) For the case of duopoly, find conditions on P and Ci that guarantee there are extremal\nequilibria that bound all rationalizable strategies.\n\nPROBLEM SET 4\n(2) For the case of oligopoly with three or more players and linear P and Ci, find the\nset of all rationalizable strategies and the set of all Nash equilibria in pure strategies.\nAssume P is decreasing and C1 = · · · = Cn is increasing and that each firm's strategy\nspace is restricted so that it cannot produce above the monopoly quantity.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "14.126 S16 Non-Cooperative Games Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/a4d0a3949ab29c2a2f55442a9723d205_MIT14_126S16_noncoop.pdf",
      "content": "NON-COOPERATIVE GAMES\nMIHAI MANEA\n1. Normal-Form Games\nA normal (or strategic) form game is a triplet (N, S, u) with the following properties:\n- N = {1, 2, . . . , n} is a finite set of players\n- Si ∋si is the set of pure strategies of player i; S = S1 × · · · × Sn ∋s = (s1, . . . , sn)\n- ui : S →R is the payofffunction of player i; u = (u1, . . . , un).\nOutcomes are interdependent. Player i ∈N receives payoffui(s1, . . . , sn) when the pure\nstrategy profile s = (s1, . . . , sn) ∈S is played. The game is finite if S is finite. We write\nS-i = Q\nj=i Sj ∋s-i.\nThe structure of the game is common knoweldge: all players know (N, S, u), and know\nthat their opponents know it, and know that their opponents know that they know, and so\non.\nFor any measurable space X we denote by ∆(X) the set of probability measures (or\ndistributions) on X.1 A mixed strategy for player i is an element σi of ∆(Si). A mixed\nstrategy profile σ ∈∆(S1) × · · · × ∆(Sn) specifies a mixed strategy for each player.\nA\ncorrelated strategy profile σ is an element of ∆(S). A mixed strategy profile can be seen as\na special case of a correlated strategy profile (by taking the product distribution), in which\ncase it is also called independent to emphasize the absence of correlation. A correlated belief\nfor player i is an element σ\ni of ∆(S\ni). The set of independent beliefs for i is\n-\n-\nQ\nj=i ∆(Sj).\nIt is assumed that player i has von Neumann-Morgenstern preferences over ∆(S) and ui\nextends to ∆(S) as follows\nui(σ) =\nX\nσ(s)ui(s).\ns∈S\nDate: January 19, 2017.\nThese notes benefitted from the proofreading and editing of Gabriel Carroll. The treatment of classic topics\nfollows Fudenberg and Tirole's text \"Game Theory\" (FT). Some material is borrowed from Muhamet Yildiz.\n1In most of our applications X is either finite or a subset of a Euclidean space.\nDepartment of Economics, MIT\n\nMIHAI MANEA\n2. Dominated Strategies\nAre there obvious predictions about how a game should be played?\nExample 1 (Prisoners' Dilemma). Two persons are arrested for a crime, but there is not\nenough evidence to convict either of them. Police would like the accused to testify against\neach other. The prisoners are put in different cells, with no possibility of communication.\nEach suspect can stay silent (\"cooperate\" with his accomplice) or testify against the other\n(\"defect\").\n- If a suspect testifies against the other and the other does not, the former is released\nand the latter gets a harsh punishment.\n- If both prisoners testify, they share the punishment.\n- If neither testifies, both serve time for a smaller offense.\nC\nD\nC\n1, 1\n-1, 2\nD\n2, -1\n0, 0∗\nNote that each prisoner is better offdefecting regardless of what the other does. Coop-\neration is a strictly dominated action for each prisoner. The only outcome if each player\nprivately optimizes is (D, D), even though it is Pareto dominated by (C, C).\nExample 2. Consider the game obtained from the prisoners' dilemma by changing player\n1's payofffor (C, D) from -1 to 1. No matter what player 1 does, player 2 still prefers\nC\nD\nC\n1, 1\n1, 2∗\nD\n2, -1\n0, 0\nD to C. If player 1 knows that 2 never plays C, then he prefers C to D. Unlike in the\nprisoners' dilemma example, we use an additional assumption to reach our prediction in this\ncase: player 1 needs to deduce that player 2 never plays a dominated strategy.\nDefinition 1. A strategy si ∈Si is strictly dominated by σi ∈∆(Si) if\nui(σi, s-i) > ui(si, s-i), ∀s-i ∈S-i.\n\nNON-COOPERATIVE GAMES\nExample 3. There are situations where a strategy is not strictly dominated by any pure\nstrategy, but is strictly dominated by a mixed one. For instance, in the game below B is\nL\nR\nT\n3, x\n0, x\nM\n0, x\n3, x\nB\n1, x\n1, x\nstrictly dominated by a 50-50 mix between T and M, but not by either T or M.\nExample 4 (A Beauty Contest). Consider an n-player game in which each player announces\na number in the set {1, 2, . . . , 100} and a prize of $1 is split equally between all players whose\nnumber is closest to 2/3 of the average of all numbers announced. Talk about the Keynesian\nbeauty contest.\nWe can iteratively eliminate dominated strategies, under the assumption that \"I know\nthat you know that I know. . . that I know the payoffs and that no one would ever use a\ndominated strategy.\nDefinition 2. For all i ∈N, set S0\ni = Si and define Sk\ni recursively by\nSk\ni = {si ∈Sk-1\ni\n| ∃σi ∈∆(Sk-1\ni\n), ui(σi, s\ni) > ui(si, s\n)\n-\n-i , ∀s-i ∈Sk-1\n-i }.\nThe set of pure strategies of player i that survive iterated deletion of strictly dominated\nstrategies is Sinf= ∩\nk\ni\nk\n0Si . The set of surviving mixed strategies is\n≥\n{σi ∈∆(Si\ninf)| ∃σi\n′ ∈∆(Si\ninf), ui(σi\n′, s\n)\n-i > ui(σi, s-i), ∀s-i ∈Sinf\n-i}.\nRemark 1. In a finite game the elimination procedure ends in a finite number of steps, so\nSinfis simply the set of surviving strategies at the last stage.\nRemark 2. In an infinite game, if S is a compact metric space and u is continuous, then\none can use Cantor's theorem (a decreasing nested sequence of non-empty compact sets has\nnonempty intersection) to show that Sinf= ∅.\nRemark 3. The definition above assumes that at each iteration all dominated strategies of\neach player are deleted simultaneously. Clearly, there are many other iterative procedures\n\nMIHAI MANEA\nthat can be used to eliminate strictly dominated strategies. However, the limit set Sinfdoes\nnot depend on the particular way deletion proceeds.2 The intuition is that a strategy which\nis dominated at some stage is dominated at any later stage.\nRemark 4. The outcome does not change if we eliminate strictly dominated mixed strategies\nat every step. The reason is that a strategy is dominated against all pure strategies of the\nopponents if and only if it is dominated against all their mixed strategies. Eliminating mixed\nstrategies for player i at any stage does not affect the set of strictly dominated pure strategies\nfor any player j = i at the next stage.\n2.1. Detour on common knowledge. Common knowledge looks like an innocuous as-\nsumption, but may have strong consequences in some situations. Consider the following\nstory. Once upon a time, there was a village with 100 married couples. The women had\nto pass a logic exam before being allowed to marry; thus all married women were perfect\nreasoners. The high priestess was not required to take that exam, but it was common knowl-\nedge that she was truthful. The village was small, so everyone would be able to hear any\nshot fired in the village. The women would gossip about adulterous relationships and each\nknew which of the other women's husbands were unfaithful. However, no one would ever\ninform a wife about her own cheating husband.\nThe high priestess knew that some husbands were unfaithful, and one day she decided\nthat such immorality should not be tolerated any further. This was a successful religion and\nall women agreed with the views of the priestess.\nThe priestess convened all the women at the temple and publicly announced that the well-\nbeing of the village had been compromised--there was at least one cheating husband. She\nalso pointed out that even though none of them knew whether her husband was faithful,\neach woman knew about the other unfaithful husbands. She ordered each woman to shoot\nher husband on the midnight of the day she was certain of his infidelity. 39 silent nights\nwent by and on the 40th shots were heard. How many husbands were shot? Were all the\nunfaithful husbands caught? How did some wives learn of their husbands' infidelity after 39\nnights in which nothing happened?\n2This property does not hold for weakly dominated strategies.\n\nNON-COOPERATIVE GAMES\nSince the priestess was truthful, there must have been at least one unfaithful husband in\nthe village. How would events have unfolded if there was exactly one unfaithful husband?\nHis wife, upon hearing the priestess' statement and realizing that she does not know of any\nunfaithful husband, would have concluded that her own marriage must be the only adulterous\none and would have shot her husband on the midnight of the first day. Clearly, there must\nhave been more than one unfaithful husband.\nIf there had been exactly two unfaithful\nhusbands, then each of the two cheated wives would have initially known of exactly one\nunfaithful husband, and after the first silent night would infer that there were exactly two\ncheaters and her husband is one of them. (Recall that the wives were all perfect logicians.)\nThe unfaithful husbands would thus both be shot on the second night. As no shots were\nheard on the first two nights, all women concluded that there were at least three cheating\nhusbands. . . Since shootings were heard on the 40th night, it must be that exactly 40 husbands\nwere unfaithful and they were all exposed and killed simultaneously.\n3. Rationalizability\nRationalizability is a solution concept introduced independently by Bernheim (1984) and\nPearce (1984). Like iterated strict dominance, rationalizability derives restrictions on play\nfrom common knowledge of the payoffs and of the fact that players are \"reasonable\" in a\ncertain way. Dominance: it is not reasonable to use a strategy that is strictly dominated.\nRationalizability: it is not rational for a player to choose a strategy that is not a best response\nto some beliefs about his opponents' strategies.\nWhat is a \"belief\"? In Bernheim (1984) and Pearce (1984) each player i's beliefs σ-i\nabout the play of j = i must be independent, i.e., σ\ni ∈\nj=i ∆(S ).\n-\n\nj\nAlternatively, we\nmay allow player i to believe that the actions of his opponen\nQ\nts are correlated, i.e., any\nσ\ni ∈∆(S\ni) is a possibility. The two definitions have different implications for n\n3.\n-\n-\n≥\nWe focus on the case with correlated beliefs. It should be emphasized that such beliefs\nrepresent a player's uncertainty about his opponents' actions and not his theory about their\ndeliberate randomization and coordination. For instance, i may place equal probability on\ntwo scenarios: either both j and k pick action A or they both play B. If i is not sure which\ntheory is true, then his beliefs are correlated even though he knows that j and k are acting\nindependently.\n\nMIHAI MANEA\nDefinition 3. A strategy σi ∈Si is a best response to a belief σ-i ∈∆(S-i) if\nui(σi, σ-i) ≥ui(si, σ-i), ∀si ∈Si.\nWe can again iteratively develop restrictions imposed by common knowledge of the payoffs\nand rationality to obtain the definition of rationalizability.\nDefinition 4. Set S0 = S and let Sk be given recursively by\nSk\ni = {si ∈Sk-1\ni\n|∃σ\ni ∈∆(Sk-1\n-\n-i ), ui(si, σ\ni) ≥ui(si\n′, σ\n,\n-i) ∀s′\ni ∈Sk-1\n-\ni\n}.\nThe set of correlated rationalizable strategies for player i is Si\ninf=\nk\nstrategy\n≥0 Sk\ni . A mixed\nσi ∈∆(Si) is rationalizable if there is a belief σ\ns.t.\n-i ∈∆(Sinf\n-i)\nT\nui(σi, σ-i) ≥ui(si, σ-i) for\nall si ∈Si\ninf.\nThe definition of independent rationalizability replaces ∆(Sk-1\ni ) and ∆(Sinf\ni) above with\nQ\n-\n-\nj=i ∆(Sk-1\nj\n) and Q\nj=i ∆(S\nely\n\nj\ninf), respectiv\n.\n\nExample 5 (Rationalizability in Cournot duopoly). Two firms compete on the market for\na divisible homogeneous good. Each firm i = 1, 2 has zero marginal cost and simultaneously\ndecides to produce an amount of output qi ≥0. The resulting price is p = 1-q1 -q2. Hence\nthe profit of firm i is given by qi(1 -q1 -q2). The best response correspondence of firm i is\nBi(qj) = max(0, (1 -qj)/2) (j = 3 -i). If i knows that qj ⪋q then Bi(qj) ⪌(1 -q)/2.\nWe know that q ≥q0 = 0 for i = 1, 2. Hence q ≤q1 = B (q0\ni\ni\ni\n) = (1-q )/2 and S1\ni = [0, q1]\nfor all i. But then q\ni ≥q = B\ni(q ) = (1 -q )/2 and Si = [q , q ] for all i. . . We obtain a\nsequence\nq0 ≤q2 ≤. . . ≤q2k ≤. . . ≤qi ≤. . . ≤q2k+1 ≤. . . ≤q1,\nwhere q2k = Pk\n1/4l = (1 -1/4k)/3 and q2k+1\nk\nl\n=\n=1\n(1 -q\n)/2 for all k ≥0 such that\nSk\ni = [qk-1, qk] for k odd and Sk\ni = [qk, qk-1] for k even. Clearly, limk\nqk = 1/3, hence the\n→inf\nonly rationalizable strategy for firm i is qi = 1/3. This is also the unique Nash equilibrium,\nwhich we define next. What are the rationalizable strategies when there are more than two\nfirms?\nWe say that a strategy σi is never a best response for player i if it is not a best response\nto any σ\ni ∈∆(S\ni). Recall that a strategy σi of player i is strictly dominated if there exists\n-\n-\nσi\n′ ∈∆(Si) s.t. ui(σi\n′, s-i) > ui(σi, s\ni), ∀s\n.\n-\ni ∈S\n-\n-i\n\nNON-COOPERATIVE GAMES\nTheorem 1. In a finite game, a strategy is never a best response if and only if it is strictly\ndominated.\nProof. Clearly, a strategy σi strictly dominated for player i by some σi\n′ cannot be a best\nresponse for any belief σ\ni ∈∆(S\ni) as σi\n′ yields a strictly higher payoffthan σi against any\n-\n-\nsuch σ\n.\n-i\nWe are left to show that a strategy which is never a best response must be strictly domi-\nnated. We prove that any strategy σ i of player i which is not strictly dominated must be a\nbest response for some beliefs. Define the set of \"dominated payoffs\" for i by\nD = {x ∈RS-i|∃σi ∈∆(Si), x ≤ui(σi, ·)}.\nClearly D is non-empty, closed and convex. Also, ui(σ i, ·) does not belong to the interior of\nD because it is not strictly dominated by any σi ∈∆(Si). By the supporting hyperplane\ntheorem, there exists α ∈RS-i different from the zero vector s.t. α · ui(σ i, ·) ≥α · x, ∀x ∈D.\nIn particular, α · ui(σ i, ·) ≥α · ui(σi, ·), ∀σi ∈∆(Si). Since D is not bounded from below,\neach component of α needs to be non-negative. We can normalize α so that its components\nsum to 1, in which case it can be interpreted as a belief in ∆(S-i) with the property that\nui(σ i, α) ≥ui(σi, α), ∀σi ∈∆(Si). Thus σ i is a best response to α.\n□\nCorollary 1. Correlated rationalizability and iterated strict dominance coincide.\nTheorem 2. For every k ≥0, each si ∈Sk\ni is a best response (within Si) to a belief in\n∆(Sk-1\ni ).\n-\nProof. Fix si ∈Sk\ni . We know that si is a best response within Sk-1\ni\nto some σ-i ∈∆(Sk-1\n-i ).\nIf si was not a best response within Si to σ\ni, let s′\ni be such a best response. Since s\n-\ni is a\nbest response within Sk-1\ni\nto σ\ni, and s′\ni is a strictly better response than si to σ\ni, we need\n-\n-\ns′\ni ∈/ Sk-1\ni\n. Then s′\ni was deleted at some step of the iteration, say s′\ni ∈Sl-1\ni\nbut s′\ni ∈/ Sl\ni for\nsome l ≤k -1. This contradicts the fact that s′\ni is a best response in Sl-1\ni\nto σ-i, which\nbelongs to ∆(Sk-1\ni ) ⊆∆(Sl-1\n-\n-i ).\n□\nCorollary 2. If the game is finite, then each si ∈Si\ninfis a best response (within Si) to a\nbelief in ∆(Sinf\n-i).\n\nMIHAI MANEA\nDefinition 5. A set Z = Z1 × . . . × Zn with Zi ⊆Si for i ∈N is closed under rational\nbehavior if, for all i, every strategy in Zi is a best response to a belief in ∆(Z-i).\nTheorem 3. If the game is finite (or if S is a compact metric space and u is continuous),\nthen Sinfis the largest set closed under rational behavior.\nProof. Clearly, Sinfis closed under rational behavior by Corollary ??. Suppose that there\nexists Z1 × . . . × Zn ⊂Sinfthat is closed under rational behavior. Consider the smallest k\nfor which there is an i such that Z ⊂Sk\n⊂\nk\ni\ni . It must be that k ≥1 and Z\ni\nS -1\n-\n-i . By\nassumption, every element in Zi is a best response to an element of ∆(Z\ni) ⊂∆(Sk-1),\n-\n-i\ncontradicting Zi ⊂Sk\ni .\n□\nRationalizability has strong epistemic foundations--it characterizes the strategic implica-\ntions of common knowledge of rationality (see next section). As we will see later, it also has\nsome evolutionary foundations. In any adaptive process the proportion of players who play\na non-rationalizable strategy vanishes as the system evolves.\n4. Common Knowledge of Rationality and Rationalizability\nWe now formalize the idea of common knowledge and show that rationalizability captures\nthe idea of common knowledge of rationality (and payoffs) precisely.3 We first introduce the\nnotion of an incomplete-information epistemic model.\nDefinition 6. (Information Structure) An information (or belief) structure is a list (Ω, (Ii)i N, (p )\n∈\ni i∈N)\nwhere\n- Ωis a finite state space;\n- Ii : Ω→2Ωis a partition of Ωfor each i ∈N such that Ii(ω) is the set of states that i\nthinks are possible when the true state is ω; it assumed that ω′ ∈Ii(ω) ⇔ω ∈Ii(ω′);\n- pi,Ii(ω) is a probability distribution on Ii(ω) representing i's belief at ω.\nThe state ω summarizes all the relevant facts about the world. Note that only one of\nthe state is the true state of the world; all others are hypothetical states needed to encode\nplayers' beliefs. In state ω, player i is informed that the state is in Ii(ω) and gets no other\ninformation. Such an information structure arises if each player observes a state-dependent\n3This section builds of notes by Muhamet Yildiz.\n\nNON-COOPERATIVE GAMES\nsignal, where Ii(ω) is the set of states for which player i's signal is identical to the signal at\nstate ω. The next definition formalizes the idea that Ii summarizes all of the information of\ni.\nDefinition 7. For any event F ⊆Ω, player i knows at ω that F obtains if Ii(ω) ⊆F . The\nevent that i knows F is\nKi(F) = {ω|Ii(ω) ⊆F}.\nThe event that everyone knows F is defined by\nK(F) = ∩i∈NKi(F).\nLet K0(F) = F and Kt+1(F) = K(Kt(F)) for t ≥0. Set Kinf(F) =\nt\nt\n0 K (F). Kinf(F) is\n≥\nthe set of states where F is common knowledge.\nT\nNote that K(Kinf(F)) = Kinf(F).\nThis leads to an alternative definition of common\nknowledge.\nAn event F ′ is public if F ′ = ∪ω′ F ′Ii(ω′) for all i, which is equivalent to\n∈\nK(F ′) = F ′ (and Kinf(F ′) = F ′). Then an event F is common knowledge at ω if and only if\nthere exists a public event F ′ with ω ∈F ′ ⊆F.\nWe have so far considered an abstract information structure for the players in N. Fix a\ngame (N, S, u). In order to give strategic meaning to the states, we also need to describe\nwhat players play at each state by introducing a strategy profile s : Ω→S.\nDefinition 8. A strategy profile s : Ω→S is adapted with respect to (Ω, (Ii)i∈N, (pi)i∈N) if\nsi(ω) = si(ω′) whenever Ii(ω) = Ii(ω′).\nPlayers must choose a constant action at all states in each information set since they\ncannot distinguish between states in the same information set.\nDefinition 9. An epistemic model (Ω, (Ii)i N, (pi)i N, s) consists of an information structure\n∈\n∈\nand an adapted strategy profile.\nThe ideas of rationality and common knowledge of rationality can be formalized as follows.\nDefinition 10. For any epistemic model (Ω, (Ii)i N, (pi)i N, s) and any ω ∈Ω, a player i is\n∈\n∈\nsaid to be rational at ω if\nsi(ω) ∈arg max\nX\nui(si, s\ni(ω′))pi,Ii(ω)(ω′).\nsiεSi\n-\nω′∈Ii(ω)\n\nMIHAI MANEA\nDefinition 11. A strategy si ∈Si consistent with common knowledge of rationality if there\nexists a model (Ω, (Ij)j∈N, (pj)j N, s) and state ω∗∈Ωwith si(ω∗) = s at\n∈\ni\nwhich it is\ncommon knowledge that all players are rational (i.e., the event R := {ω ∈Ω|every player i ∈\nN is rational at ω} is common knowledge at ω∗).\nGiven the alternative definition of common knowledge in terms of public events, si ∈\nSi consistent with common knowledge of rationality if there exists an epistemic model\n(Ω′, (Ij)j N, (pj)j N, s) such that sj(ω) is a best response to s\nj at each ω\n∈\n∈\n-\n∈Ωfor every\nplayer j ∈N (simply consider the restriction of the original model to Ω′ = Kinf(R)). The\nnext result states that rationalizability is equivalent to common knowledge of rationality in\nthe sense that Si\ninfis the set of strategies that are consistent with common knowledge of\nrationality.\nTheorem 4. For any i ∈N and si ∈Si, the strategy si is consistent with common knowledge\nof rationality if and only if si is rationalizable, i.e., si ∈Si\ninf.\nProof. (⇒) First, take any si that is consistent with common knowledge of rationality. Then\nthere exists a model (Ω, (Ij)j N, (pj)j N, s) with a state ω∗∈Ωsuch that s\n∈\n∈\ni(ω∗) = si and for\neach j and ω,\n(4.1)\nsj(ω) ∈arg max\nX\nuj(sj, s-j(ω′))pj,Ij(ω)(ω′)\nsj∈Sj ω′∈Ij(ω)\nDefine Zj = sj(Ω). Note that si ∈Zi. By Theorem ??, in order to show that si ∈Si\ninf, it\nsuffices to show that Z is closed under rational behavior. Since for each zj ∈Zj, there exists\nω ∈Ωsuch that zj = sj(ω), define belief μj,ω on Z-j by setting\nμj,ω(s-j) =\nX\npj,Ij(ω)(ω′)\nω′∈Ij(ω),s-j(ω′)=s-j\nThen, by (??),\nzj = sj(ω) ∈arg max\nX\nuj(sj, s-j(ω′))pj,I\nsj∈\nj(ω)(ω′)\nSj ω′∈Ij(ω)\n= arg max\nX\nμj,ω(s\nj)uj(sj, s\nj),\nsj\n-\n-\n∈Sj s-j∈Z-j\nwhich shows that Z is closed under rational behavior.\n\nNON-COOPERATIVE GAMES\n(⇐) Conversely, since Sinfis closed under rational behavior, for every si ∈Si\ninf, there exists\na probability distribution μi,si on Sinf\ni against which si is a best response. Define the model\n-\n(Sinf, (Ii)i∈N, (pi)i\n,\n∈N s) with\nIi(s)\n=\n{si} × Sinf\n-i\npi,s(s′)\n=\nμi,si s′\n-i\ns(s)\n=\ns.\n\nIn this model it is common knowledge that every player is rational. Indeed, for all s ∈Sinf,\nsi(s) = si ∈arg max\nX\nui (si\n′, s\ni) μi,s\ns′\ni\n\n= arg max\nui (s , s\ni) p\n)\ns′\ni∈Si\n-\n-\ni\n′\ni,s(s′ .\ns′\n∈\ninf\ni∈Si\n-\ns\ni S\ni\ns′\n-\n-\nX\n∈Ii(s)\nFor every si ∈Si\ninf, there exists s = (si, s\ni) ∈Sinfsuch that s\n-\ni(s) = si, showing that si is\nconsistent with common knowledge of rationality.\n□\n5. Nash Equilibrium\nMany games are not solvable by iterated strict dominance or rationalizability. The concept\nH\nT\nH\n1, -1\n-1, 1\nT\n-1, 1\n1, -1\nL\nR\nL\n1, 1\n0, 0\nR\n0, 0\n1, 1\nT\nS\nT\n3, 2\n1, 1\nS\n0, 0\n2, 3\nFigure 1. Matching Pennies, Coordination Game, Battle of the Sexes\nof Nash (1950) equilibrium has more bite in some situations. The idea of Nash equilibrium\nwas implicit in the particular examples of Cournot (1838) and Bertrand (1883) at an informal\nlevel.\nDefinition 12. A mixed-strategy profile σ∗is a Nash equilibrium if for each i ∈N\nui(σi\n∗, σ∗\n-i) ≥ui(si, σ∗), s\nS .\n-i\n∀i ∈\ni\nNote that if a player uses a nondegenerate mixed strategy in a Nash equilibrium (one\nthat places positive probability weight on more than one pure strategy) then he must be\nindifferent between all pure strategies in the support. Of course, the fact that there is no\nprofitable deviation in pure strategies implies that there is no profitable deviation in mixed\nstrategies either.\n\nMIHAI MANEA\nExample 6 (Matching Pennies). This simple game shows that there may sometimes not be\nany equilibria in pure strategies. We will establish that equilibria in mixed strategies exist\nH\nT\nH\n1, -1\n-1, 1\nT\n-1, 1\n1, -1\nfor any finite game.\nExample 7 (Partially Mixed Nash Equilibria). In these 3 × 3 examples, we see that mixed\nstrategy Nash equilibria may only put positive probability on some actions. The first matrix\nF\nC\nB\nF\n0, 5\n2, 3\n2, 3\nC\n2, 3\n0, 5\n3, 2\nB\n5, 0\n3, 2\n2, 3\nrepresents a tennis service game, where player 1 chooses whether to serve to player 2's\nforehand, center or backhand side; player 2 similarly chooses which side to favor for the\nreturn. The game has a unique mixed strategy equilibrium, which puts positive probability\nonly on strategies C and B for either player. Note first that choosing C with probability ε\nand B with probability 1 -ε (for small ε > 0) strictly dominates F for player 1. If player\n1 never chooses F, then C strictly dominates F for player 2. In the resulting 2 × 2 game,\nthere is a unique equilibrium, in which both players place probability 1/4 on C and 3/4 on\nB.\nH\nT\nC\nH\n1, -1\n-1, 1\n-1, -1\nT\n-1, 1\n1, -1\n-1, -1\nC\n-1, -1\n-1, -1\n3, 3\nThe second game is matching pennies with a third option: players may choose heads\nor tails as before, or they may cooperate. Cooperation produces the best outcome, but it\nis only worth it if both players choose it. The game has a total of 3 equilibria: a single\n\nNON-COOPERATIVE GAMES\npure strategy equilibrium (C, C), where players cooperate and ignore the matching pen-\nnies game; a partially mixed equilibrium ((1/2, 1/2, 0), (1/2, 1/2, 0)) where players play the\nmatching pennies game and ignore the option of cooperating; and a totally mixed equilibrium\n((2/5, 2/5, 1/5), (2/5, 2/5, 1/5)).\nTo show that these are the only equilibria, we can proceed as follows: first, if player 1 is\nmixing between H, T and C, he must be indifferent among all three actions, which implies\nthat player 2 is also mixing between H, T and C; then we can calculate the equilibrium\nprobabilities for the totally mixed equilibrium. If 1 is mixing between H and T (but not C)\nthen 2 must be mixing between H and T for this to be optimal, and 2 will never want to\nplay C since 1 never does. This leads to the partially mixed equilibrium. If 1 mixes between\nH and C (but not T), then 2 may only play T and C, but then 1 will never want to play\nH, a contradiction; so there are no equilibria of this form (the case where 1 mixes between\nT and C is analogous). Finally we check that the only pure equilibrium is (C, C).\nExample 8 (Stag Hunt). This example shows the difficulty of predicting the outcome in\ngames with multiple equilibria. In the stag hunt game, each player can choose to hunt hare\nby himself or hunt stag with the other player. Stag offers a higher payoff, but only if the\nplayers team up. The game has two pure strategy Nash equilibria, (S, S) and (H, H). How\nS\nH\nS\n9, 9\n0, 8\nH\n8, 0\n7, 7\nshould the hunters play? We may expect (S, S) to be played because it is Pareto dominant,\nthat is, it is better for both players to coordinate on hunting stag. However, if one player\nexpects the other to hunt hare, he is much better offhunting hare himself; and the potential\ndownside of choosing stag is bigger than the upside. Thus, hare is the safer choice. In the\nlanguage of Harsanyi and Selten (1988), H is the risk-dominant action: formally, if each\nplayer expects the other to play either action with probability 1/2, then H has a higher\nexpected payoff(7.5) than S (4.5). In fact, for a player to choose stag, he should expect the\nother player to play stag with probability at least 7/8. Note that this coordination problem\nmay persist even if players can communicate: regardless of what i intends to do, he would\nprefer j to play stag, so attempts to convince j to play stag may be cheap talk.\n\nMIHAI MANEA\nNash equilibria are \"consistent\" predictions of how the game will be played--if all players\nexpect that a specific Nash equilibrium will arise then no player has incentives to play dif-\nferently. Each player must have a correct \"conjecture\" about the strategies of his opponents\nand play a best response to his conjecture.\nFormally, Aumann and Brandenburger (1995) provide a framework that can be used to\nexamine the epistemic foundations of Nash equilibrium. The primitive of their model is an\ninteractive belief system in which there is a possible set of types for each player; each type\nhas associated to it a payofffor every action profile, a choice of which action to play, and\na belief about the types of the other players. Aumann and Brandenburger show that in\na 2-player game, if the game being played (i.e., both payofffunctions), the rationality of\nthe players, and their conjectures are all mutually known, then the conjectures constitute a\n(mixed strategy) Nash equilibrium. Thus common knowledge plays no role in the 2-player\ncase. However, for games with more than 2 players, we need to assume additionally that\nplayers have a common prior and that conjectures are commonly known. This ensures that\nany two players have identical and separable (i.e., independent) conjectures about other\nplayers, consistent with a (common) mixed strategy profile.\nIt is easy to show that every Nash equilibrium is rationalizable (e.g., by applying Theorem\n?? to the strategies played with positive probability). The converse is not true. For example,\nin the battle of the sexes (S, T) is not a Nash equilibrium, but both S and T are rationalizable\nfor either player. Of course, these strategies correspond to some Nash equilibria, but one\ncan easily construct a game in which some rationalizable strategies do not correspond to any\nNash equilibrium.\nSo far, we have motivated our solution concepts by presuming that players make predic-\ntions about their opponents' play by introspection and deduction, using knowledge of their\nopponents' payoffs, knowledge that the opponents are rational, knowledge about this knowl-\nedge. . . Alternatively, we may assume that players extrapolate from past observations of play\nin \"similar\" games, with either current opponents or \"similar\" ones. They form expecta-\ntions about future play based on past observations and adjust their actions to maximize\ntheir current payoffs with respect to these expectations.\nThe idea of using adjustment processes to model learning originates with Cournot (1838).\nHe considered the game in Example ??, and suggested that players take turns setting their\n\nNON-COOPERATIVE GAMES\noutputs, each player choosing a best response to the opponent's last-period action. Alterna-\ntively, we can assume simultaneous belief updating, best responding to sample average play,\npopulations of players being anonymously matched, etc. In the latter context, mixed strate-\ngies can also be interpreted as the proportion of players playing various strategies. If the\nprocess converges to a particular steady state, then the steady state is a Nash equilibrium.\nWhile convergence occurs in Example ??, this is not always the case. How sensitive is\nthe convergence to the initial state? If convergence obtains for all initial strategy profiles\nsufficiently close to the steady state, we say that the steady state is asymptotically stable.\nSee Figure ?? (FT, pp. 24-26). The Shapley (1964) cycling example from Figure ?? is also\ninteresting.\nFigure 2\nFigure 3\nL\nM\nR\nU\n0, 0\n4, 5\n5, 4\nM\n5, 4\n0, 0,\n4, 5\nD\n4, 5\n5, 4\n0, 0\nHowever, adjustment processes are myopic and do not offer a compelling description of\nbehavior.\nSuch processes definitely do not provide good predictions for behavior in the\nCourtesy of The MIT Press. Used with permission.\n\nMIHAI MANEA\nactual repeated game, if players care about play in future periods and realize that their\ncurrent actions can affect opponents' future play.\n6. Existence and Continuity of Nash Equilibria\nWe can show that a Nash equilibrium exists under broad regularity conditions on strategy\nspaces and payofffunctions.4 Some continuity and compactness assumptions are indispens-\nable because they are usually needed for the existence of solutions to (single agent) optimiza-\ntion problems. Convexity is usually required for fixed-point theorems, such as Kakutani's.5\nNash used Kakutani's fixed point theorem to show the existence of mixed strategy equilibria\nin finite games. We provide a generalization of his existence result. We start with some\nmathematical background.\n6.1. Topology Prerequisites. Consider two topological vector spaces X and Y . A corre-\nspondence F : X ⇒Y is a set valued function taking elements x ∈X into subsets F(x) ⊆Y .\nThe graph of F is defined by G(F) = {(x, y) |y ∈F (x)}. A point x ∈X is a fixed point\nof F if x ∈F(x). A correspondence F is non-empty/closed-valued/convex-valued if F (x) is\nnon-empty/closed/convex for all x ∈X.\nThe main continuity notion for correspondences we rely on is the following. A correspon-\ndence F has closed graph if G (F) is a closed subset of X ×Y . If X and Y are first-countable\nspaces (such as metric spaces), then F has closed graph if and only if for any sequence\n(xm, ym)m\n0 with ym ∈F (xm) for all m ≥0, which converges to a pair (x, y), we have\n≥\ny ∈F (x). Note that correspondences with closed graph are closed-valued. The converse is\nfalse.\nA related continuity concept is defined as follows. A correspondence F is upper hemicon-\ntinuous at x ∈X if for every open neighborhood VY of F (x), there exists a neighborhood VX\nof x such that x′ ∈VX ⇒F (x′) ⊂VY . In general, closed graph and upper hemicontinuity\nmay have different implications. For instance, the constant correspondence F : [0, 1] ⇒[0, 1]\ndefined by F(x) = (0, 1) is upper hemicontinuous, but does not have a closed graph. How-\never, the two concepts coincide for closed-valued correspondences in most spaces of interest.\n4This presentation builds on lecture notes by Muhamet Yildiz.\n5However, there are algebraic fixed point theorems that do not require convexity. We rely on such a result\ndue to Tarski later in the course.\n\nNON-COOPERATIVE GAMES\nTheorem 5 (Closed Graph Theorem). A correspondence F : X ⇒Y with compact Haus-\ndorffrange Y is closed if and only if it is upper hemicontinuous and closed-valued.\nAnother continuity property is lower hemicontinuity, which for compact metric spaces\nrequires that for any sequence (xm) →x and for any y ∈F (x), there exists a sequence\n(ym) with ym ∈F (xm) for each m such that ym →y. In general, solution concepts in game\ntheory are upper hemicontinuous but not lower hemicontinuous, a property inherited from\noptimization problems.\nThe maximum theorem states that in single agent optimization problems the optimal\nsolution correspondence is upper hemicontinuous in parameters when the objective function\nand the domain of optimization vary continuously in all relevant parameters.\nTheorem 6 (Berge's Maximum Theorem). Suppose that f : X × Y →R is a continuous\nfunction, where X and Y are metric spaces and Y is compact.\n(1) The function M : X →R, defined by\nM (x) = max f (x, y) ,\ny∈Y\nis continuous.\n(2) The correspondence F : X ⇒Y ,\nF (x) = arg max f (x, y)\ny∈Y\nis nonempty valued and has a closed graph.\nWe lastly state the fixed point result.\nTheorem 7 (Kakutani's Fixed-Point Theorem). Let X be a non-empty, compact, and convex\nsubset of a Euclidean space and let the correspondence F : X ⇒X have closed graph and\nnon-empty convex values. Then the set of fixed points of F is non-empty and compact.\nIn game theoretic applications of Kakutani's theorem, X is usually the strategy space,\nassumed to be compact and convex when we include mixed strategies.6 F is typically the\nbest response correspondence, which is non-empty valued and has a closed graph by the\n6We will see other applications of Kakutani's fixed point theorem and its extension to infinite dimensional\nspaces when we discuss my work on bargaining in dynamic markets.\n\nMIHAI MANEA\nMaximum Theorem. In that case, we can ensure that F is convex-valued by assuming that\nthe payofffunctions are quasi-concave.\nRecall that a function f : X →R is quasi-concave when X is a convex subset of a real\nvector space if\nf(tx + (1 -t)y) ≥min(f(x), f(y)), ∀t ∈[0, 1], x, y ∈X.\nIn particular, quasi-concavity implies convex upper contour sets and convex arg max.\n6.2. Existence of Nash Equilibrium.\nTheorem 8. Consider a game (N, S, u) such that Si is a convex and compact subset of a\nEuclidean space and that ui is continuous in s and quasi-concave in si for all i ∈N. Then\nthere exists a pure strategy Nash equilibrium.\nProof. We construct a correspondence F : S ⇒S that satisfies the conditions of Kakutani's\nFixed Point Theorem, whose fixed points constitute Nash equilibria.\nLet F : S ⇒S be the best response correspondence defined by\nF (s) = {(s∗\n1, . . . , s∗\nn)|s∗\ni ∈Bi (s-i) , ∀i ∈N} =\nY\nBi (s\n) , s\nS,\n-i\ni\n∀∈\n∈N\nwhere Bi (s\ni) := arg max\n-\ns′∈Si ui(s′\ni, s-i).\ni\nSince S is compact and the utility functions are continuous, the Maximum Theorem implies\nthat F is non-empty valued and has closed graph. Moreover, since ui is quasi-concave in si,\nthe set Bi (s-i) is convex for all i and s-i. Then F is convex-valued. Therefore, F satisfies\nthe conditions of Kakutani's fixed-point theorem and it must have a fixed point,\ns∗∈F (s∗) .\nBy definition, s∗\ni ∈Bi\ns∗\ni\n\nfor all i ∈N, thus s∗is a Nash equilibrium.\n□\n-\nFor games with convex strategy sets and quasiconcave utility functions, Theorem ?? proves\nexistence of a pure strategy Nash equilibrium.\nOne can use this result to establish the\nexistence of equilibrium in classical economic models, such as generalizations of the Cournot\ncompetition game introduced earlier. Theorem ?? also implies the existence of mixed strategy\nNash equilibria in finite games.\n\nNON-COOPERATIVE GAMES\nCorollary 3. Every finite game has a mixed strategy Nash equilibrium.\nProof. Since S is finite, each ∆(Si) is isomorphic to a simplex in a Euclidean space, which is\nconvex and compact. Player i's expected utility ui (σ) = P\ns ui (s) σ1 (s1) · · · σn (sn) from a\nmixed strategy profile σ is continuous in σ and linear--hence also quasi-concave--in σi. Then\nthe game (N, ∆(S1) , . . . , ∆(Sn) , u) satisfies the assumptions of Theorem ??. Therefore, it\nadmits a Nash equilibrium σ∗∈∆(S1) × · · · × ∆(Sn), which can be interpreted as a mixed\nNash equilibrium in the original game.\n□\n6.3. Upperhemicontinuity of Nash Equilibrium. The Maximum Theorem establishes\nthat the best-response correspondence in optimization problems is upper hemicontinuous in\nparameters when the payoffs are continuous and the domain is compact. Hence the limits of\noptimal solutions is a solution to the optimization problem in the limit. One can then find\na solution by considering approximate problems and taking the limit. There can be other\nsolutions in the limit, so the best response correspondence is not lower hemicontinuous in\ngeneral. Nash equilibrium (like many other solution concepts) inherits these properties of\nthe best response correspondence.\nConsider a compact metric space X of some payoff-relevant parameters. Fix a set N of\nplayers and set S of strategy profiles, where S is again a compact metric space (or a finite\nset). The payofffunction ui : S × X →R of every i ∈N is assumed to be continuous\nin both strategies and parameters. Write NE (x) and PNE (x) for the sets of all Nash\nequilibria and all pure Nash equilibria, respectively, of game (N, S, u (·, x)) in which it is\ncommon knowledge that the parameter value is x. Endow the space of mixed strategies with\nthe weak topology.\nTheorem 9. Under the stated assumptions, the correspondences NE and PNE have closed\ngraphs.\nProof. We establish the result for PNE; the proof for NE is similar. Consider any sequence\n(sm, xm) →(s, x) with sm ∈PNE (xm) for each m. Suppose that s ∈PNE (x). Then\nui (s′\ni, s\ni, x)\n-\n-ui (si, s-i, x) > 0\n\nMIHAI MANEA\nfor some i ∈N, s′\ni ∈Si. Then (sm, xm) →(s, x) and the continuity of ui imply that\nui s′\ni, sm\ni, xm\n>\n-\n-ui sm, sm\nm\ni\n-i, x\nfor sufficiently large m. Howev\ner,\n\nui\ns′\ni, sm\ni, xm\n> ui\nsm\ni , sm\ni, xm\n-\n-\ncontradicts sm\n\n∈PNE (xm).\n□\n7. Bayesian Games\nWhen some players are uncertain about the payoffs or types of others, the game is said\nto have incomplete information. Most often a player's type is simply defined by his payoff\nfunction. More generally, types may embody any private information that is relevant to\nplayers' decision making. This may include, in addition to the player's payofffunction, his\nbeliefs about other players' payofffunctions, his beliefs about what other players believe his\nbeliefs are, and so on. Modeling incomplete information about higher order beliefs is usually\nintractable and in most applications a player's uncertainty is assumed to be solely about his\nopponents' payoffs.7\nA Bayesian game is a list B = (N, S, Θ, u, p) where\n- N = {1, 2, . . . , n} is a finite set of players\n- Si is the set of pure strategies of player i; S = S1 × . . . × Sn\n- Θi is the set of types of player i; Θ = Θ1 × . . . × Θn\n- ui : Θ × S →R is the payofffunction of player i; u = (u1, . . . , un)\n- p ∈∆(Θ) is a common prior (we can relax this assumption).\nWe often assume that Θ is finite and the marginal p(θi) is positive for each type θi.\nExample 9 (First Price Auction with I.I.D. Private Values). One object is up for sale.\nSuppose that the value θi of player i ∈N for the object is uniformly distributed in Θi = [0, 1]\n\nand that the values are independent across players. This means that if θi ∈[0, 1], ∀i then\np(θi ≤ θi, ∀\n\ni) = Q\ni θi. Each player i submits a bid si ∈Si = [0, inf). The player with the\n7See the slides for the general model and a rigorous treatment of higher order beliefs in Bayesian games.\n\nNON-COOPERATIVE GAMES\nhighest bid wins the object and pays his bid. Ties are broken randomly. Hence the payoffs\nare given by\ni\nui(θ, s) =\n\nθi-s\n\nif s\ns\n|{ ∈\n|\n}|\ni ≥\nj,\nj N si=sj\n∀j ∈N\notherwise.\nExample 10 (An exchange game). Each player i = 1, 2 receives a ticket on which there\nis a number in some finite set Θi ⊂[0, 1].\nThe number on a player's ticket represents\nthe size of a prize he may receive. The two prizes are independently distributed, with the\nvalue on i's ticket distributed according to Fi.\nEach player is asked independently and\nsimultaneously whether he wants to exchange his prize for the other player's prize, hence\nSi = {agree, disagree}. If both players agree then the prizes are exchanged; otherwise each\nplayer receives his own prize. Thus the\n\npayoffof player i is\n\nθ3\ni\nif s =\n-\ns2 = agree\nui(θ, s) =\nθi\notherwise.\nIn the ex ante representation G(B) of\n\nthe Bayesian game B player i has strategies (si(θi))θi∈Θi ∈\nSΘi\ni --that is, his strategies are functions from types to strategies in B--and utility function\nUi given by\nUi((si(θi))θi∈Θi,i N) = Ep(ui(θ, s1(θ )\n∈\n1 , . . . , sn(θn))).\nThe interim representation IG(B) of the Bayesian game B has player set ∪iΘi.\nThe\nstrategy space of each player θi is Si. A strategy profile (sθi)i∈N,θi\nyields\n∈Θi\nutility\nUθi((sθi)i∈N,θi∈Θi) = Ep(ui(θ, sθ1, . . . , sθn)|θi)\nfor player θi. For the conditional expectation to be well-defined we need p(θi) > 0.\nDefinition 13. A Bayesian Nash equilibrium of B is a Nash equilibrium of IG(B).\nProposition 1. Every Bayesian Nash equilibrium of B is a Nash equilibrium of G(B). If\np(θ\ni) > 0 for all θi ∈Θi, i ∈N, the converse also holds.\nTheorem 10. Suppose that\n- N and Θ are finite\n8Strategies are mapped between the two games by si(θi) →sθi.\n\nMIHAI MANEA\n- each Si is a compact and convex subset of a Euclidean space\n- each ui is continuous in s and concave in si.\nThen B has a pure strategy Bayesian Nash equilibrium.\nProof. We have to show that IG(B) has a pure Nash equilibrium. The latter follows from\nTheorem ??. We use the concavity of ui in si to show that the corresponding Uθi is quasi-\nconcave in sθi. Quasi-concavity of ui in si does not typically imply quasi-concavity of Uθi in\ns\nθi because Uθi is an integral of ui over variables other than sθi.\n□\nExample 11 (Study groups). Two students work on a joint project. Each student i can\neither exert effort (ei = 1) or shirk (ei = 0). The cost of effort is a fixed (and commonly\nknown) c < 1 for all students. The project is a success if at least one student puts in effort,\nbut both fail otherwise. However, students vary in how much they care about the fate of the\nproject. Concretely, each student i has a type θi ∼U[0, 1]; the types of both students are\nindependently distributed and privately known. The payofffrom success is θ2\ni , so a student\ngets θ2\ni -c from working, θ2\ni from shirking if j works, and 0 if both shirk.\nThis game has a unique Bayesian Nash equilibrium. In equilibrium, both players use a\nthreshold strategy: i works if θi ≥θ∗= c 3, and shirks otherwise. For a proof, note that\nworking is rational for i iff\nθ2\ni -c ≥θ2\ni pj ⇐⇒(1 -pj)θ2\ni ≥c,\nwhere pj is i's belief about the probability that j will work.\n(Crucially, since types are\nindependent, p does not\nwith threshold θi\n∗=\nq depend on θi). This implies that i must play a threshold strategy,\nc\n1-pj . Since the same is true of player j, we have pj = 1 -θ∗\nj, so\nθ∗\ni =\nq c . This is true for i = 1, j = 2 and vice-versa, which implies the result.\nθj\n∗\nConsider a family of Bayesian games Bx parameterized by x ∈X, with X compact, such\nthat the payofffunctions are continuous in x. If S, Θ are finite, then the set of Bayesian\nNash equilibria of Bx is upper-hemicontinuous with respect to x.\nIndeed, BNE(Bx) =\nNE(IG(Bx)). Furthermore, we have upper-hemicontinuity with respect to beliefs.\nTheorem 11. Suppose that N, S, Θ are finite. Let P ⊂∆(Θ) be such that for every p ∈P\np(θi) > 0, ∀θi ∈Θ\np\ni, i ∈N. Then BNE(B ) is upper-hemicontinuous in p over P.\n9Sums of quasi-concave functions are not necessarily quasi-concave.\n\nNON-COOPERATIVE GAMES\nProof. Since BNE(Bp) = NE(IG(Bp)), it is sufficient to note that\nUi((si(θi))θi∈Θi,i∈N) = Ep(ui(θ, s1(θ1), . . . , sn(θn)))\n(as defined for G(Bp)) is continuous in p.\n□\n8. Auctions\nIn class we covered (see handouts)\n(1) the characterization of equilibria in first and second price auctions (pp. 14-20 in\n\"Auction Theory\" by Vijay Krishna)\n(2) the revenue equivalence theorem and optimal auctions (pp. 61-73 in \"Auction The-\nory\")\n(3) all-pay and third-price auctions (pp. 31-34 in \"Auction Theory\")\n(4) first-price auction with two asymmetric bidders (pp. 49-53 in \"Auction Theory\")\n(5) bilateral trade and the inefficiency theorem of Myerson and Satterthwaite (1983).\n9. Extensive Form Games\nAn extensive form game consists of\n- a finite set of players N = {1, 2, . . . , n}; nature is denoted as \"player 0\"\n- the order of moves specified by a tree\n- each player's payoffs at the terminal nodes in the tree\n- information partition\n- the set of actions available at every information set and a description of how actions\nlead to progress in the tree\n- moves by nature.\nGo over the extensive form Figure ?? (FT, p. 86).\nThe tree is described by a binary relationship (X, >), where x > y is interpreted as \"node\nx precedes node y.\" We assume that X is finite, there is an initial node φ ∈X (φ > x\nfor all x = φ), > is transitive (x > y, y > z ⇒x > z) and asymmetric (x > y ⇒y > x).\nHence the tree has no cycles.\nWe also require that each node x = φ has exactly one\nimmediate predecessor, i.e., ∃x′ > x such that x′′ > x, x′′ = x′ implies x′′ > x′. A node is\nterminal if it does not precede any other node; this means that the set of terminal nodes is\n\nMIHAI MANEA\nFigure 4\nCourtesy of The MIT Press. Used with permission.\nZ = {z| ∃x, z > x}. Each z ∈Z completely determines a path of moves through the tree\n(recall the finiteness assumption), with associated payoffui(z) for player i.\nAn information partition is a partition of X \\ Z. Node x belongs to the information set\nh(x). For each information set h, there is a player i(h) ∈N ∪{0}, who is to move at any\nnode x ∈h. The interpretation of the information partition is that i(h) knows that he is at\nsome node of h but does not know which one. (We must assume the same player moves at\nall x ∈h, otherwise players might disagree on whose turn it is.) We abuse notation writing\ni(x) = i(h(x)).\nThe set of available actions at x ∈X \\ Z for player i(x) is A(x).\nWe assume that\nA(x) = A(x′) =: A(h), ∀x′ ∈h(x) (otherwise i(h) might play an infeasible action).\nA\nfunction l labels each node x = φ with the last action taken to reach it. We require that\neach immediate successor of x is labeled with a different action in A(x), and each such action\nis used for some successor of x. Finally, a move by nature at some node x corresponds to a\nprobability distribution over A(x).\nLet Hi = {h|i(h) = i}. The set of pure strategies for player i is Si =\nh∈H A(h). As\ni\nusual, S = Q\ni N Si. A strategy is a complete contingent plan specifying\nQ\nan action to be\n∈\ntaken at each information set (if reached). We can define mixed strategies as probability\ndistributions over pure strategies, σi ∈∆(Si). Any mixed strategy profile σ ∈\nalong with the distribution of the moves by nature and the labeling of nodes with\nQ\ni N ∆(Si),\n∈\nactions,\nleads to a probability distribution O(σ) ∈∆(Z). We denote ui(σ) = EO(σ)(ui(z)). The\nstrategic form representation of the extensive form game is the normal form game defined\nby (N, S, u). A mixed strategy profile constitutes a Nash equilibrium of the extensive form\n\nNON-COOPERATIVE GAMES\ngame if it induces a Nash equilibrium in its strategic form representation. See Figure ??\n(FT, p. 85).\nFigure 5\nTwo strategies σi, σi\n′ ∈Si are outcome equivalent if O(σi, s\ni) = O(σi\n′, s\ni), ∀s\ni, that is,\n-\n-\n-\nthey lead to the same distribution over outcomes regardless of how the opponents play. See\nfigure 3.9 in FT p. 86. The strategies (b, c) and (b, d) are equivalent in that example. Let\nSR\ni be a subset of Si that contains exactly one strategy from each equivalence class. The\nreduced normal form game is given by (N, SR, u).\nA behavior strategy specifies a distribution over actions for each information set. Formally,\na behavior strategy bi(h) for player i(h) at information set h is an element of ∆(A(h)). We\nuse the notation bi(a|h) for the probability of action a at information set h. A behavior\nstrategy bi for i is an element of Q\nh H ∆(A(h)).\nNote that behavior strategies assume\n∈\ni\nindependent mixing at each information set. A profile b of behavior strategies determines a\ndistribution over Z in the obvious way. By definition, the behavior strategy bi is outcome\nequivalent to the mixed strategy\n(9.1)\nσi(si) =\nY\nbi(si(h)|h),\nh∈Hi\nwhere si(h) denotes the projection of si on A(h).\nCourtesy of The MIT Press. Used with permission.\n\nMIHAI MANEA\nTo guarantee that every mixed strategy is equivalent to a behavior strategy (reinterpreted\nas a mixed strategy as above) we need to impose the additional requirement of perfect recall.\nBasically, perfect recall means that no player ever forgets any information he once had and\nall players know the actions they have chosen previously. Formally, perfect recall stipulates\nthat if x′′ ∈h(x′), x is a predecessor of x′ and the same player i moves at both x and x′ (and\nthus at x′′) then there is a node xˆ in the same information set as x (possibly x itself) such\nthat xˆ is a predecessor of x′′ and the action taken at x along the path to x′ is the same as the\naction taken at xˆ along the path to x′′. Intuitively, the nodes x′ and x′′ are distinguished by\ninformation i does not have, so he cannot have had it at h(x); x′ and x′′ must be consistent\nwith the same action at h(x) since i must remember his action there. Stated differently,\nevery node in h ∈Hi must be reached via the same sequence of i's actions.\nDiscuss the absent-minded driver's paradox of Piccione and Rubinstein (1997).\nLet Ri(h) be the set of pure strategies for player i that do not preclude reaching the\ninformation set h ∈Hi, i.e., Ri(h) = {si|h is on the path of (si, s-i) for some s-i}. If the\ngame has perfect recall, a mixed strategy σi is equivalent to a behavior strategy bi defined\nby\nσ (s )\n(9.2)\nbi(a|\nP\ns (\nh\n{si∈Ri(h)| i h)=a\ni\ni\n) =\n}\nwhen\nP\nsi∈Ri(h) σi(si)\nthe denominator is positive, and letting bi(h) be any distribution when the above\ndenominator is zero.\nFor some intuition, let h1, . . . , h k be player i's information sets preceding h in the tree. In\na game of perfect recall, reaching any node in h requires i to take the same action ak at each\nhk. Then Ri(h) is simply the set of pure strategies si with si(hk) = ak for all k. Reaching\nany node x in h requires player i to choose a1, . . . , a k and other players to also take specific\nactions. Conditional on getting to x, the distribution of continuation play at x is given by\nthe relative probabilities of the actions available at h under the restriction of σi to the set\nof pure strategies {si|si(hk) = ak, ∀k = 1, k} compatible with reaching h,\nbi(a|h) =\nP\n{si|si(hk)=ak,∀k=1, k & si(h)=a} σi(si)\nP\n{si|si(hk)=ak,∀k=\n.\nσ (\n,k}\ni si)\nMany different mixed strategies can generate the same behavior strategy. Consider the\nexample from Figure ?? (FT, p. 88). Player 2 has four pure strategies, s2 = (A, C), s′\n2 =\n\nNON-COOPERATIVE GAMES\n(A, D), s′′\n2 = (B, C), s′′′\n2 = (B, D). Now consider two mixed strategies, σ2 = (1/4, 1/4, 1/4, 1/4),\nwhich assigns probability 1/4 to each pure strategy, and σ2\n′ = (1/2, 0, 0, 1/2), which assigns\nprobability 1/2 to each of s2 and s′′′\n2 . Both of these mixed strategies generate the behavior\nstrategy b2 with b2(A|h) = b2(B|h) = 1/2 and b2(C|h′) = b2(D|h′) = 1/2. Moreover, for any\nstrategy σ1 of player 1, all of σ2, σ2\n′ , b2 lead to the same probability distribution over terminal\nnodes. For example, the probability of reaching node z1 equals the probability of player 1\nplaying U times 1/2.\nFigure 6\nCourtesy of The MIT Press. Used with permission.\nThe relationship between mixed and behavior strategies is different in the game illustrated\nin Figure ?? (FT, p. 89), which is not a game of perfect recall (player 1 forgets what he did at\nthe initial node; formally, there are two nodes in his second information set which obviously\nsucceed the initial node, but are not reached by the same action at the initial node). Player 1\nhas four strategies in the strategic form, s1 = (A, C), s′\n1 = (A, D), s′′\n1 = (B, C), s′′′\n1 = (B, D).\nNow consider the mixed strategy σ1 = (1/2, 0, 0, 1/2). This generates the behavior strategy\nb1 = {(1/2, 1/2), (1/2, 1/2)}, where player 1 mixes 50 -50 at each information set. But b1\nis not equivalent to the σ1 that generated it. Indeed (σ1, L) generates a probability 1/2 for\nthe terminal node corresponding to (A, C, L) and a 1/2 probability for (B, L, D). However,\nsince behavior strategies describe independent randomizations at each information set, (b1, L)\nassigns probability 1/4 to each of the four paths (A, C, L), (A, D, L), (B, C, L), (B, D, L).\nSince both A vs. B and C vs. D are choices made by player 1, the strategy σ1 under\nwhich player 1 makes all his decisions at once allows choices at different information sets to\nbe correlated. Behavior strategies cannot produce this correlation, because when it comes\ntime to choose between C and D, player 1 has forgotten whether he chose A or B. By\nassumption, player 1 cannot distinguish between the nodes following A and B, and in line\n\nMIHAI MANEA\nwith this assumption, behavior strategies cannot condition on the past choice between A\nand B.\nFigure 7\nCourtesy of The MIT Press. Used with permission.\nTheorem 12 (Kuhn 1953). In extensive form games with perfect recall, mixed and behavior\nstrategies are outcome equivalent under the formulae ??-??.\nHereafter we restrict attention to games with perfect recall, and use mixed and behavior\nstrategies interchangeably. Behavior strategies prove more convenient in many arguments\nand constructions. We drop the notation b for behavior strategies and instead use σi(a|h) to\ndenote the probability with which player i chooses action a at information set h. . .\n10. Backward Induction and Subgame Perfection\nAn extensive form game has perfect information if all information sets are singletons.\nBackward induction can be applied to any extensive form game of perfect information with\nfinite X (which means that the number of \"stages\" and the number of actions feasible at\nany stage are finite). The idea of backward induction is formalized by Zermelo's algorithm.\nSince the game is finite, it has a set of penultimate nodes, i.e., nodes whose immediate\nsuccessors are (all) terminal nodes. Specify that the player who moves at each such node\nchooses the strategy leading to the terminal node with the highest payofffor him. In case of\na tie, make an arbitrary selection. Next each player at nodes whose immediate successors are\npenultimate (or terminal) nodes chooses the action maximizing his payoffover the feasible\nsuccessors, given that players at the penultimate nodes play as assumed. We can now roll\nback through the tree, specifying actions at each node. At the end of the process we have a\npure strategy for each player. It is easy to check that the resulting strategies form a Nash\nequilibrium.\n\nNON-COOPERATIVE GAMES\nTheorem 13 (Zermelo 1913; Kuhn 1953). A finite game of perfect information has a pure-\nstrategy Nash equilibrium.\nMoreover, the backward induction solution has the nice property that, if play starts at\nany intermediate node, each player's actions are again optimal if the play of the opponents is\nheld fixed, which we call subgame perfection. This rules out non-credible threats in response\nto deviations from the prescribed play. More generally, subgame perfection extends the logic\nof backward induction to games with imperfect information.\nThe idea is to replace the\n\"smallest\" subgame with one of its Nash equilibria and iterate this procedure on the reduced\ntree. In stages where the \"smallest\" subgame has multiple Nash equilibria, the procedure\nimplicitly assumes that all players believe the same equilibrium will be played. To define\nsubgame perfection formally we first need the definition of a subgame. Informally, a subgame\nis a portion of a game that can be analyzed as a game in its own right.\nDefinition 14. A subgame G of an extensive form game T consists of a single node x and\nall its successors in T, with the property that if x′ ∈G and x′′ ∈h(x′) then x′′ ∈G. The\ninformation sets, actions and payoffs of the subgame are inherited from the original game.\nThat is, two nodes are in the same information set in G if and only if they are in the same\ninformation set in T, and the payofffunction on the subgame is just the restriction of the\noriginal payofffunction to the terminal nodes of G (and likewise for the action sets and\naction labels).\nThe requirements that all the successors of x be in the subgame and that the subgame\ndoes not \"chop up\" any information set ensure that the subgame corresponds to a situation\nthat could arise in the original game. At the top of Figure ?? (FT, p. 95), the game on\nthe right is not a subgame of the game on the left, because on the right player 2 knows that\nplayer 1 has not played L, which he did not know in the original game.\nTogether, the requirements that the subgame begin with a single node x and respect\ninformation sets imply that in the original game x must be a singleton information set,\ni.e. h(x) = {x}. This ensures that the distribution over paths of play and payoffs in the\nsubgame, conditional on the subgame being reached, are well defined. In the bottom of\nFigure ??, the \"game\" on the right has the problem that player 2's optimal choice may\ndepend on the relative probabilities of nodes x and x′, but the specification of the game does\n\nMIHAI MANEA\nnot provide these probabilities. In other words, the diagram on the right cannot be analyzed\nas a separate game.\nFigure 8\nCourtesy of The MIT Press. Used with permission.\nGiven any strategy profile σ, payoffs within a subgame G are well-defined--just start play\nat the initial node of G, follow the actions specified by σ, and take the payoffs of the resulting\nterminal node (or their expectations, if mixing is involved). So we can test whether strategies\nyield a Nash equilibrium when restricted to the subgame.\nDefinition 15. A behavior strategy profile σ of an extensive form game is a subgame perfect\nequilibrium if the restriction of σ to G is a Nash equilibrium of G for every subgame G.\nBecause any game is a subgame of itself, a subgame perfect equilibrium profile is necessarily\na Nash equilibrium. If the only subgame is the whole game, the sets of Nash and subgame\nperfect equilibria coincide. If there are other subgames, some Nash equilibria may fail to be\nsubgame perfect.\nSubgame perfection coincides with backward induction in finite games of perfect informa-\ntion. Consider the penultimate nodes of the tree, where the last choices are made. Each of\nthese nodes begins a trivial one-player subgame, and Nash equilibrium in these subgames\nrequires that the player make a choice that maximizes his payoff. Thus any subgame perfect\nequilibrium must coincide with a backward induction solution at every penultimate node,\nand we can continue up the tree by induction.\n\nNON-COOPERATIVE GAMES\n11. Important Examples of Extensive Form Games\n11.1. Repeated games with perfect monitoring.\n- time t = 0, 1, 2, . . . (usually infinite)\n- stage game is a normal-form game G\n- G is played every period t\n- players observe the realized actions at the end of each period\n- payoffs are the sum of discounted payoffs in the stage game.\nRepeated games are a widely studied class of dynamic games. A lot of recent research deals\nwith the case of imperfect monitoring.\n11.2. Multi-stage games with observable actions.\n- stages t = 0, 1, 2, . . .\n- at stage t, after having observed a \"non-terminal\" history of play h = (a0, . . . , at-1),\neach player i simultaneously chooses an action at\ni ∈Ai(h)\n- payoffs given by u(h) for each terminal history h.\nOften it is natural to identify the \"stages\" of the game with time periods, but this is not\nalways the case. A game of perfect information can be viewed as a multi-stage game in which\nevery stage corresponds to some node. At every stage all but one player (the one moving\nat the node corresponding to that stage) have singleton action sets (\"do nothing\"; we can\nrefer to these players as \"inactive\"). Repeated versions of perfect information extensive form\ngames also lead to multi-stage games. Another important example is the Rubinstein (1982)\nalternating bargaining game, which we discuss later.\n12. Single (or One-Shot) Deviation Principle\nConsider a multi-stage game with observed actions. We show that in order to verify that a\nstrategy profile σ constitutes a subgame perfect equilibrium, it suffices to check whether there\nare any histories ht where some player i can gain by deviating from the action prescribed by\nσi at ht and conforming to σi elsewhere. (The notation ht denotes a history as of stage t.)\nIf σ is a strategy profile and ht a history, write ui(σ|ht) for the (expected) payoffto player\ni that results if play starts at ht and continues according to σ in each stage.\n\nMIHAI MANEA\nDefinition 16. A (behavior) strategy σi is unimprovable given σ-i if ui(σi, σ-i| ht) ≥\nui(σi\n′, σ\ni| ht) for every h and\n-\nt\nσi\n′ with σi\n′(h′\nt ) = σ\n′\ni(h′\nt ) for all h\n′\n′\nt′ = ht.\nHence a strategy σi is unimprovable if after every history, no strategy that differs from\nit only at that history can increase i's expected payoff. Obviously, if σ is a subgame per-\nfect equilibrium then σi is unimprovable given σ\ni. To establish the converse, we need an\n-\nadditional condition.\nDefinition 17. A game is continuous at infinity if for each player i the utility function ui\nsatisfies\nlim\nsup\n|ui(h)\nt→inf\n\n(h,h) ht=ht\n-\n\nui(h)| = 0.\n{\n|\n}\nContinuity at infinity requires that events in the distant future are relatively unimportant.\nIt is satisfied if the overall payoffs are a discounted sum of per-period payoffs and the stage\npayoffs are uniformly bounded. It also holds in the (degenerate) case of finite-stage games.\nThere exist versions for games with unobserved actions as well.\nTheorem 14. Consider a (finite or infinite horizon) multi-stage game with observed ac-\ntions10 that is continuous at infinity. If σi is unimprovable given σ\nthen\n-i for all i ∈N,\nσ\nconstitutes an SPE.\nProof. Suppose that σi is unimprovable given σ\ni, but σ is\n-\ni\nnot a best response to σ-i\nfollowing some history h\nt. Let σi be a strictly better response and define\n(12.1)\nε = ui(σ1\ni , σ-i|ht) -ui(σi, σ-i|ht) > 0.\nSince the game is continuous at infinity, there exists t′ > t and σ2\ni such that σ2\ni is identical\nto σ1\ni at all information sets up to (and including) stage t′, σ2\ni coincides with σi across all\nlonger histories and\n(12.2)\n|ui(σ2\ni , σ-i|ht) -u\ni(σi , σ-i|ht)| < ε/2.\nIn particular, ?? and ?? imply that\nui(σ2\ni , σ\ni|h )\n-\nt > ui(σi, σ-i|ht).\n10We allow for the possibility that the action set be infinite at some stages.\n\nNON-COOPERATIVE GAMES\nDenote by σ3\ni the strategy obtained from σ2\ni by replacing the stage t′ actions following\nany history ht′ with the corresponding actions under σi. Conditional on any history ht′, the\nstrategies σi and σ3\ni coincide, hence\n(12.3)\nu\ni(σi , σ-i|ht′) = ui(σi, σ-i|ht′).\nAs σi is unimprovable given σ-i, and conditional on ht′ the subsequent play in strategies σi\nand σ2\ni differs only at stage t′, we must have\n(12.4)\nui(σi, σ\n-i|ht′) ≥ui(σi , σ\nh ).\n-i|\nt′\nThen ?? and ?? lead to\nui(σ3\ni , σ\ni|ht′) ≥ui(σ2\ni , σ\nh\n-\n-i|\nt′)\nfor all histories h\nt′ (consistent with ht). Since σi and σi coincide before reaching stage t′,\nwe obtain\nui(σ3\ni , σ\ni|ht) ≥ui(σ2\ni , σ\nh\n-\n-i|\nt).\nSimilarly, we can construct σ4\n′\n′\ni , . . . , σt -t+3\ni\n. The final strategy σt\ni\n-t+3 is identical to σi\nconditional on ht and\nui(σ\nt′\nt+3\ni, σ\n) = u\n-i|ht\ni(σi\n-\n, σ-i|ht) ≥. . . ≥ui(σi , σ-i|ht) ≥ui(σi , σ-i|ht) > ui(σi, σ-i|ht),\na contradiction.\n□\n12.1. Applications. Apply the single deviation principle to repeated prisoners' dilemma to\nimplement various equilibrium paths for high discount factors:\n(1) (C, C), (C, C), . . .\n(2) (C, C), (C, C), (D, D), (C, C), (C, C), (D, D), . . .\n(3) (C, D), (D, C), (C, D), (D, C) . . .\nIn particular, note that cooperation is possible in repeated play.\nC\nD\nC\n1, 1\n-1, 2\nD\n2, -1\n0, 0∗\nAlso find the stationary equilibrium for the alternating bargaining game in which two\nplayers divide $1. We will show that is the unique subgame perfect equilibrium.\n\nMIHAI MANEA\n13. Iterated Conditional Dominance\nDefinition 18. In a multi-stage game with observable actions, an action ai is conditionally\ndominated at stage t given history ht if, in the subgame starting at ht, every strategy for\nplayer i that assigns positive probability to ai is strictly dominated.\nProposition 2. In any multi-stage game with observable actions, every subgame perfect\nequilibrium survives iterated elimination of conditionally dominated strategies.\n14. Bargaining with Alternating Offers\nOne important example of a multi-stage game with observed actions is the following bar-\ngaining game, analyzed by Rubinstein (1982).\nThe set of players is N = {1, 2}. For i = 1, 2 we write j = 3 -i. The set of feasible utility\npairs is\nU = {(u1, u2) ∈[0, inf)2|u2 ≤g2(u1)},\nwhere g2 is some strictly decreasing, concave (and hence continuous) function with g2(0) >\n0.11\nTime is discrete and infinite, t = 0, 1, . . . Each player i discounts payoffs by δi, so receiving\nu\nt\ni at time t is worth δiui.\nAt every time t = 0, 1, . . ., player i(t) proposes an alternative u = (u1, u2) ∈U to player\nj(t) = 3 -i(t); the bargaining protocol specifies that i(t) = 1 for t even and i(t) = 2 for\nt odd. If j(t) accepts the offer, then the game ends yielding a payoffvector (δt\n1u1, δt\n2u2).\nOtherwise, the game proceeds to period t + 1. If agreement is never reached, each player\nreceives a 0 payoff.\nIt is useful to define the function g1 = g-1\n2 . Notice that the graph of g2 (and g-1\n1 ) coincides\nwith the Pareto-frontier of U.\n11The set of feasible utility outcomes U can be generated from a set of contracts or decisions X in a natural\nway. Define U = {(v1 (x) , v2 (x)) |x ∈X} for a pair of utility functions v1 and v2 over X. With additional\nassumptions on X, v1, v2 we can ensure that the resulting U is compact and convex.\n\nNON-COOPERATIVE GAMES\n14.1. Stationary subgame perfect equilibrium. Let (m1, m2) be the unique solution to\nthe following system of equations\nm1\n=\nδ1g1 (m2)\nm2\n=\nδ2g2 (m1) .\nNote that (m1, m2) is the intersection of the graphs of the functions δ2g2 and (δ1g1)-1.\nWe are going to argue that the following \"stationary\" strategies constitute a subgame\nperfect equilibrium, and that any other subgame perfect equilibrium leads to the same out-\ncome. In any period where player i has to make an offer to j, he offers u with uj = mj and j\naccepts only offers u with uj ≥mj. We can use the single-deviation principle to check that\nthe constructed strategies form a subgame perfect equilibrium.\n14.2. Equilibrium uniqueness. We can use iterated conditional dominance to rule out\nmany actions and then prove that the stationary equilibrium is essentially the unique sub-\ngame perfect equilibrium.\nTheorem 15. The subgame perfect equilibrium is unique, except for the decision to accept\nor reject Pareto-inefficient offers.\nProof. Player i cannot obtain a period t expected payoffgreater than\nM 0\ni = δi max ui = δigi(0)\nu∈U\nfollowing a disagreement at date t. Hence rejecting an offer u with ui > M 0\ni is conditionally\ndominated by accepting such an offer for i. Once we eliminate these dominated actions,\ni accepts all offers u with ui > M 0\ni from j. Then making any offer u with ui > M 0\ni is\ndominated for j by an offer u = λu + (1 -λ) (M 0\ni , gj (M 0\ni )) for λ ∈(0, 1), since both offers\nwill be accepted immediately and the latter is better for j. We remove all the strategies\ninvolving such offers.\nUnder the surviving strategies, j can always reject an offer from i and make a counteroffer\nnext period that leaves him with slightly less than gj (M 0\ni ), which i accepts. Hence it is\nconditionally dominated for j to accept any offer that gives him less than\nm1\nj = δjgj\nM 0\ni\n\n.\n\nMIHAI MANEA\nAfter we eliminate the latter actions, i cannot expect to receive a continuation payoffgreater\nthan\nM 1\ni = max\nδigi\nmj\n\n, δi Mi\n\n= δigi\nmj\nin any future period following a disagreement. The second equality\n\nholds because δigi m1\nj\n=\nδigi (δjgj (M 0\ni )) ≥δigi (gj (M 0\ni )) = δiM 0\ni ≥δ2\ni M 0\ni .\n\nWe can recursively define the sequences\nmk+1\nj\n=\nδjgj\nM k\ni\nM k+1\n=\nδ g\nmk+1\ni\ni i\nj\n\nfor i = 1, 2 and k\n\n≥1. Since both g1 and g2 are decreasing functions, we can easily show\nthat the sequence (mk\ni ) is increasing and (M k\ni ) is decreasing. By arguments similar to those\nabove, we can prove by induction on k that, in any strategy that survives iterated conditional\ndominance, player i = 1, 2\n- never accepts offers with ui < mk\ni\n- always accepts offers with ui > M k\ni , but making such offers is dominated for j.\nOne step in the inductive argument for the latter claim is that max\n\nδig\nk\ni\nm +1 , δ2\nk\nj\n\ni Mi\n=\nδigi mk+1\nj\n= M k+1\ni\n, which follows from δig\nmk+1\ni\nj\n= δig\nδ\nk\ni\njgj Mi\n≥δigi gj M k\ni\n\n=\nδ\nk\niMi ≥δ2\ni M k\ni .\n\nThe sequences (mk\ni ) and (M k\ni ) are monotonic and bounded, so they need to converge. The\nlimits satisfy\nminf\nj\n=\nδjgj δigi mj\ninf\nMi\ninf\n=\nδigi\n\nminf\nj\n.\nIt follows that (m1\ninf, minf\n\n2 ) is the (unique) intersection point of the graphs of the functions\nδ\n2g2 and (δ1g1)-. Moreover, Mi\ninf= δigi\nminf\nj\n\n= minf\ni . Therefore, all strategies of i that\nsurvive iterated conditional dominance accept u with ui > Mi\ninf= minf\ni\nand reject u with\nui < minf\ni = Mi\ninf.\nThis uniquely determines the reply to every offer that i makes that gives j an amount\nother than minf\nj . Now, at any history where i is the proposer, he has the option of making\noffers (ui, gj(ui)) for ui arbitrarily close to (but less than) gi(minf\nj ), which will be accepted by\n\nNON-COOPERATIVE GAMES\nj. Hence i's equilibrium payoffat such a history must be at least gi(minf\nj ). On the other hand,\ni cannot get any more than gi(minf\nj ). Indeed, any offer made by i specifying a payoffgreater\nthan gi(minf\nj ) for himself would leave j with less than minf\nj , and we have shown that such\noffers are rejected by j. Moreover, j never offers i more than Mi\ninf= δigi(minf\nj ) ≤gi(minf\nj ). So\ni's equilibrium payoffat any history where i is the proposer must be exactly gi(minf\nj ), which\ncan only be attained if i offers (gi(minf\nj ), minf\nj ) and j accepts with probability 1.\nThis now uniquely pins down actions at every history, except those where agent j has just\nbeen given an offer (ui, minf\nj ) for some ui < gi(minf\nj ). In this case, j is indifferent between\naccepting and rejecting.\n□\n14.3. Properties of the subgame perfect equilibrium. The subgame perfect equilib-\nrium is efficient--agreement is obtained in the first period, without delay. The subgame\nperfect equilibrium payoffs are given by (g1(m2), m2), where (m1, m2) solve\nm1\n=\nδ1g1 (m2)\nm2\n=\nδ2g2 (m1) .\nIt can be easily shown that the payoffof player i is increasing in δi and decreasing in δj.\nFor a fixed δ1 ∈(0, 1), the payoffof player 2 converges to 0 as δ2 →0 and to maxu U u\n∈\nas δ2 →1. If U is symmetric and δ1 = δ2, player 1 enjoys a first mover advantage because\nm1 = m2 and g1(m2) > m2.\n15. Nash Bargaining\nAssume that U is such that g2 is decreasing, strictly concave and continuously differentiable\n(derivative exists and is continuous). The Nash (1950) bargaining solution u∗is defined\nby {u∗} = arg maxu∈U u1u2 = arg maxu U u1g2(u1). It is the outcome (u∗\n∈\n1, g2(u∗\n1)) uniquely\npinned down by the first order condition g2(u∗\n1)+u∗\n1g2\n′ (u∗\n1) = 0. Indeed, since g2 is decreasing\nand strictly concave, the function f, given by f(x) = g2(x) + xg2\n′ (x), is strictly decreasing\nand continuous and changes sign on the relevant range.\nTheorem 16 (Binmore, Rubinstein and Wolinsky 1985). Suppose that δ1 = δ2 =: δ in the\nalternating bargaining model. Then the unique subgame perfect equilibrium payoffs converge\nto the Nash bargaining solution as δ →1.\n\nMIHAI MANEA\nProof. 12 Recall that the subgame perfect equilibrium payoffs are given by (g1(m2), m2) where\n(m1, m2) satisfies\nm1\n=\nδg1 (m2)\nm2\n=\nδg2 (m1) .\nIt follows that g1(m2) = m1/δ, hence m2 = g2(g1(m2)) = g2(m1/δ). We rewrite the equations\nas follows\ng2(m1/δ)\n=\nm2\ng2 (m1)\n=\nm2/δ.\nBy the mean value theorem, there exists ξ ∈(m1, m1/δ) such that g2(m1/δ) -g2(m1) =\n(m1/δ-m1)g2\n′ (ξ), hence (m2-m2/δ) = (m1/δ-m1)g2\n′ (ξ) or, equivalently, m2+m1g2\n′ (ξ) = 0.\nSubstituting m2 = δg2 (m1) we obtain δg2 (m1) + m1g2\n′ (ξ) = 0.\nNote that (g1(m2), m2) converges to u∗as δ →1 if and only if (m1, m2) does. In order\nto show that (m1, m2) converges to u∗as δ →1, it is sufficient to show that any limit point\nof (m1, m2) as δ →1 is u∗. Let (m∗\n1, m∗\n2) be such a limit point corresponding to a sequence\n(δk)k\n0 →1. Recognizing that m\n≥\n1, m2, ξ are functions of δ, we have\n(15.1)\nδkg2 (m1(δk)) + m1(δk)g2\n′ (ξ(δk)) = 0.\nSince ξ(δk) ∈(m1(δk), m1(δk)/δk) with m1(δk), m1(δk)/δk →m∗\n1 as k →inf, and g2\n′ is con-\ntinuous by assumption, in the limit (??) becomes g2 (m∗\n1) + m∗\n1g2\n′ (m∗\n1) = 0.\nTherefore,\nm∗\n1 = u∗\n1.\n□\n16. Sequential Equilibrium\nIn multi-stage games with incomplete information, say where payoffs depend on initial\nmoves by nature, the only subgame is the original game, even if players observe one an-\nother's actions at the end of each period.\nThus the refinement of Nash equilibrium to\nsubgame perfect equilibrium has no bite. Since players do not know each other's types, the\ncontinuation starting from a given period can be analyzed as a separate subgame only if we\n12A simple graphical proof starts with the observation that m1g2 (m1) = m2g1 (m2), hence the points\n(m1, g2 (m1)) and (g1 (m2) , m2) belong to the intersection of g2's graph with the same hyperbola, which\napproaches the hyperbola tangent to the boundary of U (at the Nash bargaining solution) as δ →1.\n\nNON-COOPERATIVE GAMES\nhave a specification of players' beliefs about which node they start at. The concept of sequen-\ntial equilibrium provides a way to derive plausible beliefs at every information set. Based\non the beliefs, one can test whether the continuation strategies form a Nash equilibrium.\nThe complications that incomplete information causes are evident in \"signaling games,\" in\nwhich only one player has private information. The informed player moves first. The other\nplayer observes the informed player's action, but not her type, before choosing his own action.\nOne example is Spence's (1974) model of the job market. In that model, a worker knows her\nproductivity and must choose a level of education; a firm (or number of firms), observes the\nworker's education level, but not her productivity, and then decides what wage to offer her.\nIn the spirit of subgame perfection, the optimal wage should depend on the firm's beliefs\nabout the worker's productivity given the observed education. An equilibrium then needs\nto specify not only contingent actions, but also beliefs. At information sets that are reached\nwith positive probability in equilibrium, beliefs should be derived using Bayes' rule. What\nabout at information sets that are reached with probability zero? Some theoretical issues\narise here.\nFigure 9\nRefer for more motivation to the example in Figure ?? (FT, p. 322). The strategy profile\n(L, A) is a Nash equilibrium, and it is subgame perfect, as player 2's information set does\nnot initiate a subgame. However, it is not a very plausible equilibrium, since player 2 prefers\nplaying B rather than A at his information set, regardless of whether player 1 has chosen\nCourtesy of The MIT Press. Used with permission.\n\nMIHAI MANEA\nM or R. So, a good equilibrium concept should rule out the solution (L, A) in this example\nand ensure that 2 always plays B.\nFor most definitions, we focus on extensive form games of perfect recall with finite sets of\ndecision nodes. We use some of the notation introduced earlier.\nTo define sequential equilibrium (Kreps and Wilson 1982), we first define an assessment\nto be a pair (σ, μ), where σ is a (behavior) strategy profile and μ is a system of beliefs. The\nlatter component consists of a belief specification μ(h) for each information set h; μ(h) is a\nprobability distribution over the nodes in h. The definition of sequential equilibrium is based\non the concepts of sequential rationality and consistency. Sequential rationality requires that\nconditional on every information set h, the strategy σi(h) be a best response to σ-i(h) given\nthe beliefs μ(h). Formally,\nui(h)(σi(h), σ\ni(h)|h, μ(h)) ≥ui(h)(σi\n′\n(h), σ\nh,\n-\n-i(h)|\nμ(h))\nfor all information sets h and alternative strategies σ′. Here, the conditional payoffui(σ|h, μ(h))\nnow denotes the payoffthat results when play begins at a randomly selected node in the\ninformation set h, chosen according to the probability distribution μ(h), and subsequent play\nat each information set is as specified by the profile σ.\nBeliefs need to be consistent with strategies in the following sense. For any totally mixed\nstrategy profile σ --that is, one where each action is played with positive probability at every\ninformation set--all information sets are reached with positive probability, and Bayes' rule\nleads to a unique system of beliefs μσ . The assessment (σ, μ) is consistent if there exists a\nsequence of totally mixed strategy profiles (σm)m\n0 converging to σ such that the associated\n≥\nbeliefs μσm converge to μ as m →inf.\nDefinition 19. A sequential equilibrium is an assessment that is sequentially rational and\nconsistent.\nThe definition of sequential equilibrium rules out the strange equilibrium in the earlier\nexample (Figure ??). Since player 1 chooses L under the proposed equilibrium strategies,\nconsistency does not pin down player 2's beliefs at his information set. However, sequential\nrationality requires that player 2 have some beliefs and best-respond to them, which ensures\nthat A is not played.\n\nNON-COOPERATIVE GAMES\nFigure 10\nConsistency imposes more restrictions on the beliefs than Bayes' rule alone. Consider\nthe partial extensive form from Figure ?? (FT, p. 339). The information set h1 of player\n1 consists of two nodes x, x′. Player 1 can take an action D leading to y, y′ respectively.\nPlayer 2 cannot distinguish between y and y′ at the information set h2. If 1 never plays D in\nequilibrium, then Bayes' rule does not pin down beliefs at h2. However, consistency implies\nthat μ2(y|h2) = μ1(x|h1). The idea is that since 1 cannot distinguish between x and x′, he\nis equally likely to play D at either node. Hence consistency ensures that players' beliefs\n\"respect the information structure.\"\nMore generally, consistency imposes common beliefs following deviations from equilibrium\nbehavior. There are criticisms of this requirement--why should different players have the\nsame theory about something that was not supposed to happen? A counter-argument is that\nconsistency matches the spirit of equilibrium analysis, which normally assumes that players\nagree in their beliefs about other players' strategies (and moreover these beliefs are correct).\n17. Properties of Sequential Equilibrium\nTheorem 17. A sequential equilibrium exists for every finite extensive-form game.\nThis is a consequence of the existence of perfect equilibria, which we prove later.\nProposition 3. The sequential equilibrium correspondence has a closed graph with respect\nto payoffs.\nCourtesy of The MIT Press. Used with permission.\n\nMIHAI MANEA\nProof. Let uk →u be a convergent sequence of payofffunctions and (σk, μk) →(σ, μ) be a\nconvergent sequence of sequential equilibria of the games with corresponding payoffs uk. We\nneed to show that (σ, μ) is a sequential equilibrium for the game with payoffs given by u.\nSequential rationality of (σ, μ) is straightforward because the expected payoffs conditional\non reaching any information set are continuous in the payofffunctions and beliefs.\nWe also have to check consistency of (σ, μ). As (σk, μk) is a sequential equilibrium of the\ngame with payofffunction uk, there exists a sequence of totally mixed strategies (σm,k)m →\nσk, with corresponding induced beliefs given by (μm,k)m →μk. For every k, we can find\na sufficiently large m\nso that all components of σmk,k\nk\nand μmk,k are within 1/k from the\ncorresponding components of σk and μk. Since σk →σ, μk →μ, it must be that σmk,k →\nσ, μmk,k →μ. Thus we have obtained a sequence of totally mixed strategies converging to\nσ, which induces beliefs converging to μ.\n□\nKreps and Wilson show that in generic games (i.e., for a space of payofffunctions such\nthat the closure of its complement has measure zero, under any given tree structure), the\nset of outcome distributions that can be realized in some sequential equilibrium is finite.\nNevertheless, it is not generally true that the set of sequential equilibria is finite, as there\nmay be infinitely many belief specifications for off-path information sets that support some\nequilibrium strategies. It is not uncommon for the set of sequential equilibrium strategies\nto be infinite as well. Indeed, there may exist information sets offthe equilibrium path that\nallow for consistent beliefs with the property that the corresponding players are indifferent\nbetween several actions.\nMany mixtures over the latter actions can be compatible with\nsequential rationality. See Figure ?? (FT, p. 359) for an example. That game has two\nsequential equilibrium outcomes, (L, l) and A. While there is a unique equilibrium leading\nto (L, l), there are two one-parameter families of equilibria with outcome A. For A to be\nsequentially rational for player 1, it must be that 2 plays r with positive probability. In the\nfirst family of equilibria, player 2 chooses r with probability 1 and believes that μ(x) < 1/2.\nIn the second, player 2 chooses r with a probability in [2/5, 1] and believes that μ(x) = 1/2.\nKohlberg and Mertens (1986) criticized sequential equilibrium for allowing \"strategically\nneutral\" changes in the game tree to affect the equilibrium. Compare, for instance, the two\ngames in Figure ?? (FT, p. 343). The game on the right is identical to the one on the left,\n\nNON-COOPERATIVE GAMES\nFigure 11\nexcept that player 1's first move is split into two moves in a seemingly irrelevant way. Whereas\n(A, L2) can be supported as a sequential equilibrium for the game on the left, the strategy\nA is not part of a sequential equilibrium for the one on the right. For the latter game, in\nthe simultaneous-move subgame following NA, the only Nash equilibrium is (R1, R2), as L1\nis strictly dominated by R1 for player 1. Hence the unique sequential equilibrium strategies\nfor the right-hand game are ((NA, R1), R2). This example demonstrates that eliminating a\nstrictly dominated strategy affects the set of sequential equilibria.\nFigure 12\nNote that the sensitivity of sequential equilibrium to the addition of \"irrelevant moves\"\nis not a direct consequence of consistency, but is rather implied by sequential rationality.\nIn the example above, the problem arises even for subgame perfect equilibria. Kohlberg\nand Mertens (1986) further develop these ideas in their concept of a stable equilibrium.\nHowever, their criticism that good mistakes should be much more likely than bad mistakes\nis not necessarily compelling. If we take seriously the idea that players make mistakes at\neach information set, then it is not clear that the two extensive forms in the above example\nCourtesy of The MIT Press. Used with permission.\nCourtesy of The MIT Press. Used with permission.\n\nMIHAI MANEA\nare equivalent. In the game on the right, if player 1 makes the mistake of not playing A, he\nis still able to ensure that R1 is more likely than L1; in the game on the left, he might take\neither action by mistake when intending to play A.\n18. Perfect Bayesian Equilibrium\nPerfect Bayesian equilibrium was the original solution concept for extensive-form games\nwith imperfect information, when subgame perfection does not have enough force. It in-\ncorporated the ideas of sequential rationality and Bayesian updating of beliefs. Nowadays\nsequential equilibrium (which was invented later) is the preferred way of expressing these\nideas, but it's worthwhile to know about PBE since older papers refer to it.\nThe idea is similar to sequential equilibrium but with simpler requirements about how\nbeliefs are updated. Fudenberg and Tirole (1991) have a paper that describes various for-\nmulations of PBE. The basic requirements are that strategies should be sequentially rational\nand that beliefs should be derived from Bayes' rule wherever applicable, with no constraints\non beliefs at information sets reached with probability zero in equilibrium.\nPBE is tipically applied to multi-stage games with incomplete information in which nature\nassigns types to players and player actions are observed at the end of every stage. Here are\nsome other restrictions that can be imposed for such games.\n- If player types are drawn independently by nature, beliefs about different players\nshould remain independent at each history.\n- Updating should be \"consistent\": given a probability-zero history ht at time t, at\nwhich strategies call for a positive-probability transition to history ht+1, the beliefs\nat ht+1 should be given by updating beliefs at ht via Bayes' rule.\n- \"Not signaling what you don't know\": in multi-stage games with independent types,\nbeliefs about player i at the beginning of period t + 1 depend only on ht and action\nby player i at time t, not also on other players' actions at time t.\n- Two different players i, j should have the same belief about a third player k even at\nprobability-zero histories.\nAll of these conditions are implied by consistency.\n\nNON-COOPERATIVE GAMES\nAnyhow, there does not seem to be a single clear definition of PBE in the literature.\nDifferent sets of conditions are imposed by different authors. This is one more reason why\nusing sequential equilibrium is preferable.\n19. Perfect Equilibrium\nNow consider the following game:\nL\nR\nU\n1, 1\n0, 0\nD\n0, 0\n0, 0\nBoth (U, L) and (D, R) are sequential equilibria (sequential equilibrium coincides with\nNash equilibrium in a strategic-form game). But (D, R) seems non-robust: if player 1 thinks\nthat player 2 might make a mistake and play L with some small probability, he would rather\ndeviate to U. This motivates the definition of (trembling-hand) perfect equilibrium (Selten,\n1975) for strategic-form games. A profile σ is a PE if there is a sequence of \"trembles\"\nσm →σ, where each σm is a totally mixed strategy, such that σi is a best reply to σm\n-i for\neach m and all i ∈N.\nAn equivalent approach is to define a strategy profile σε to be an ε-perfect equilibrium\nif there exist ε(si) ∈(0, ε) for all i and si ∈Si such that σε is a Nash equilibrium of the\ngame where players are restricted to play mixed strategies in which every pure strategy si\nhas probability at least ε(si). A PE is a profile that is a limit of some sequence of ε-perfect\nequilibria σε as ε →0. (We will not show the equivalence here but it's not too hard.)\nTheorem 18. Every finite strategic-form game has a perfect equilibrium.\nProof. For any ε > 0, we can certainly find a Nash equilibrium of the modified game, where\neach player is restricted to play mixed strategies that place probability at least ε on every\npure strategy. (Just apply the usual Nash existence theorem for compact strategy sets and\nquasiconcave payoffs.) By compactness, there is some subsequence of these strategy profiles\nas ε →0 that converges, and the limit point is a perfect equilibrium by definition.\n□\nWe would like to extend this definition to extensive-form games. Consider the game in\nFigure ?? (FT, p. 353). They show an extensive-form game and its reduced normal form.\n\nMIHAI MANEA\nFigure 13\nThere is a unique SPE (L1L′\n1, L2). But (R1, R2) is a PE of the reduced normal form. Thus\nperfection in the normal form does not imply subgame-perfection. The perfect equilibrium\nis sustained only by trembles such that, conditional on trembling to L1 at the first node,\nplayer 1 is also fairly likely to play R1\n′ rather than L′\n1 at his second node.\nThis seems\nunreasonable--R1\n′ is only explainable as a tremble. Perfect equilibrium as defined so far\nthus has the disadvantage of allowing correlation in trembles at different information sets.\nThe solution to this is to impose perfection in the agent-normal form. We treat the two\ndifferent nodes of player 1 as being different players, thus requiring them to tremble inde-\npendently. More formally, in the agent-normal form game, we have a player corresponding\nto every information set. Given a strategy profile in this game, the \"player\" corresponding\nto any information set h enjoys the same payoffs as player i(h) under the corresponding\nstrategies in the extensive-form game. Thus, the game in Figure ?? turns into a three-player\ngame. The only perfect equilibrium of this game is (L1, L′\n1, L2).\nMore generally, a perfect equilibrium for an extensive form game is defined to be a perfect\nequilibrium of the corresponding agent-normal form.\nCourtesy of The MIT Press. Used with permission.\n\nNON-COOPERATIVE GAMES\nTheorem 19. Every PE of a finite extensive-form game is a sequential equilibrium (for\nsome appropriately chosen beliefs).\nProof. Let σ be a PE of the extensive-form game. Then there exist totally mixed strategy\nprofiles in the agent normal form game σm →σ such that σ\nm\nh is a best reply to σ-h for each\nm and all information sets h. For each σm we have a well-defined belief system μm induced\nby Bayes' rule. Pick a subsequence for which these belief systems converge to some μ. Then\nby definition (σ, μ) is consistent. Sequential rationality follows exactly from the fact that\nσh is a best reply given μm(·|h) and σm\n-h for each m along the subsequence, and hence also\nwith respect to the limit beliefs μ(·|h) and strategies σ\nh. (More properly, perfection implies\n-\nthat there are no one-shot deviations that benefit any player; by an appropriate adaptation\nof the one-shot deviation principle we infer that σ is in fact sequentially rational at every\ninformation set.)\n□\nThe converse is not true--not every sequential equilibrium is perfect, as we already saw\nwith the simple strategic-form example above. But for generic payoffs it is true (Kreps and\nWilson, 1982).\nThe set of perfect equilibrium outcomes does not have a closed graph (unlike sequential\nor subgame-perfect equilibrium). Consider the following game:\nL\nR\nU\n1, 1\n0, 0\nD\n0, 0\n1/n, 1/n\nIt has (D, R) as a perfect equilibrium for each n > 0, but in the limit where (D, R) has\npayoffs (0, 0) it is no longer a perfect equilibrium. We can think of this as an order-of-limits\nproblem: as n →infthe trembles against which D and R remain best responses become\nsmaller and smaller. Thus, whether or not (D, R) is a reasonable prediction in the limiting\ngame depends on whether we think the approximation error in describing the payoffs is larger\nthan the players' probability of trembling or vice versa.\n20. Proper Equilibrium\nMyerson (1978) considered the notion that when a player trembles, he is still more likely\nto play better actions than worse ones. Specifically, a player's probability of playing the\n\nMIHAI MANEA\nsecond-best action is at most ε times the probability of the best action, the probability of\nthe third-best action is at most ε times the probability of the second-best action, and so\nforth. Consider the game in Fig. 8.15 of FT (p. 357). (M, M) is a perfect equilibrium,\nbut Myerson argues that it can be supported only using unreasonable trembles, where each\nplayer has to be likely to tremble to a very bad reply rather than an almost-best reply.\nDefinition 20. An ε-proper equilibrium is a totally mixed strategy profile σε such that, if\nu (s , σε ) < u (s′, σε\nε\ni\ni\ni\ni\ni\ni), then σi (si) ≤εσε\ni (s′\ni). A proper equilibrium is any limit of some\n-\n-\nε-proper equilibria as ε →0.\nTheorem 20. Every finite strategic-form game has a proper equilibrium.\nProof. First prove existence of ε-proper equilibria, using the usual Kakutani argument ap-\nplied to the \"almost-best-reply\" correspondences BRε\ni rather than the usual best-reply corre-\nspondences. (BRε\ni(σ-i) is the set of mixed strategies for player i in a suitable compact space\nof totally mixed strategies that satisfy the inequality in the definiton of ε-proper equilib-\nrium.) Then use compactness to show that there exists a sequence that converges as ε →0;\nits limit is a proper equilibrium.\n□\nGiven an extensive-form game, a proper equilibrium of the corresponding normal form is\nautomatically subgame-perfect; we don't need to go to the agent-normal form. We can show\nthis by a backward-induction-type argument.\nKohlberg and Mertens (1986) showed that a proper equilibrium in a strategic-form game\nis sequential in every extensive-form game having the given normal form. However, it will\nnot necessarily be a trembling-hand perfect equilibrium in (the agent-normal form of) every\nsuch game. See Figure ?? (FT, p. 358): (L, r) is proper (and so sequential) in the normal\nform but not perfect in the agent-normal form.\n21. Forward Induction\nThe preceding ideas are all attempts to capture some kind of forward induction: players\nshould believe in the rationality of their opponents, even after observing a deviation; thus if\nyou observe an out-of-equilibrium action being played, you should believe that your opponent\nexpected you to respond in a way such that his action was reasonable, and this in turn is\n\nNON-COOPERATIVE GAMES\nFigure 14\ninformative about his type (or, in more general extensive forms, about how he plans to play\nin the future). Forward induction is not itself an equilibrium concept, since in equilibrium all\nplayers know that the specified strategies are to be exactly followed; rather, it is an attempt\nto describe reasoning by players who are not quite certain about what will be played. It also\nis not a single, rigorously defined concept, but rather a vague term for a form of reasoning\nabout play.\nConsider now the extensive-form game as follows: 1 can play O, leading to (2, 2), or I,\nleading to the following battle-of-the-sexes game:\nT\nW\nT\n0, 0\n3, 1\nW\n1, 3\n0, 0\nThere is an SPE in which player 1 first plays O; conditional on playing I, they play the\nequilibrium (W, T). But the following forward-induction argument suggests this equilibrium\nis unreasonable: if player 1 plays I, this suggests he is expecting to coordinate on (T, W)\nin the battle-of-the-sexes game, so player 2, anticipating this, will play W. If 1 can thus\nconvince 2 to play W by playing I in the first stage, he can get the higher payoff(3, 1).\nThis game can also be represented in (reduced) normal form.\nT\nW\nO\n2, 2\n2, 2\nIT\n0, 0\n3, 1\nIW\n1, 3\n0, 0\nCourtesy of The MIT Press. Used with permission.\n\nMIHAI MANEA\nThis representation of the game shows a connection between forward induction and strict\ndominance.\nWe can rule out IW because it is dominated by O; then the only perfect\nequilibrium of the remaining game is (IT, W) giving payoffs (3, 1). However, (O, T) can be\nenforced as a perfect (in fact a proper) equilibrium in the original strategic-form game.\nKohlberg and Mertens (1986) argue that an equilibrium concept that is not robust to\ndeletion of strictly dominated strategies is troubling. The above example, together with\nother cases of such non-robustness, leads them to define the notion of stable equilibria. It\nis a set-valued concept--not a property of an individual equilibrium but of sets of equilib-\nria. Kohlberg and Mertens first argue that a solution concept should meet the following\nrequirements:\n- Iterated dominance: every stable set must contain a stable set of any game obtained\nby deleting a strictly dominated strategy.\n- Admissibility: no mixed strategy appearing in a stable set assigns positive probability\nto a weakly dominated strategy.\n- Invariance to extensive-form representation: they define an equivalence relation be-\ntween extensive forms and require that any stable set in one game should be stable\nin any equivalent game.\nKohlberg and Mertens define strategic stability in a way such that these criteria are satisfied.\nDefinition 21. A closed set S of NE is strategically stable if it is minimal among sets with the\nfollowing property: for every η > 0, there exists ε > 0 such that all choices of ε(si) ∈(0, ε),\nthe game where each player i is constrained to play every si with probability at least ε(si)\nhas a Nash equilibrium which is within distance η of some equilibrium in S.\nAny sequence of ε-perturbed games as ε →0 should have equilibria corresponding to an\nequilibrium in S. Notice that we need the minimality property of S to give bite to this\ndefinition--otherwise, by upper hemi-continuity, we know that the set of all Nash equilibria\nwould be strategically stable, and we get no refinement. The difference with trembling-hand\nperfection is that there should be convergence to one of the equilibria in S for any sequence\nof perturbations, not just some sequence of perturbations.\nTheorem 21. There exists a stable set that is contained in a connected component of the\nset of Nash equilibria. Generically, each component of the set of Nash equilibria leads to a\n\nNON-COOPERATIVE GAMES\nsingle distribution over outcomes, so there exists a stable set that induces a unique outcome\ndistribution. A stable set contains a stable set of any game obtained by eliminating a weakly\ndominated strategy and also of any game obtained by deleting a strategy that is not a best\nresponse to any of the opponents' strategy profiles in the set (\"never a weak best reply\"\n(NWBR)).\nNWBR shows that the concept of stable equilibrium is robust to forward induction: know-\ning that player i will not use a particular strategy is consistent with the equilibrium theories\nfrom the stable set.\nEvery equilibrium in a stable set has to be a perfect equilibrium. This follows from the\nminimality condition--if an equilibrium is not a limiting equilibrium along some sequence\nof trembles, then there's no need to include it in the stable set. But notice, these equilibria\nare only guaranteed to be perfect in the normal form, not in the agent-normal form (for a\ngiven extensive-form game). Actually, an example due to Gul proves that there exist stable\nsets that do not contain any sequential equilibrium.\nNormal form games do not directly capture the reasoning of forward induction. Battigalli\nand Siniscalchi (2002) seek a general-purpose definition of forward induction by modeling the\nbelief revision process explicitly in the context of extensive form games. They are interested\nin the epistemic conditions that lead to forward induction.\nThey propose an epistemic model, with each player having a set Ωi of states of the form\nωi = (si, ti), where si represents player i's disposition to act and ti represents his disposition\nto believe. si specifies his action at each information set h of player i, and ti specifies a\nbelief gi,h ∈∆(Ω\ni) over states of the other players for each h. We say i is rational at\n-\nstate ω if si is a best reply to his beliefs ti at each information set.\nLet R be the set\nof states at which every player is rational. For any event E ⊆Ω, we can define the set\nBi,h(E) = {(s, t) ∈Ω| gi,h(E) = 1}, i.e.\nthe set of states where i is sure that E has\noccurred (at information set h). Finally SBi(E) = ∩h reachable given EBi,h(E) denotes the set\nof states at which i strongly believes in event E, meaning the set of states at which i would\nbe sure of E as long as he's reached an information set that is consistent with E occurring.\nFinally, Battigalli and Siniscalchi show that SB(R) identifies forward induction--that is,\nin the states of the world where everyone strongly believes that everyone is sequentially\n\nMIHAI MANEA\nrational, strategies must form a profile that is not ruled out by forward induction arguments\nof the sort discussed earlier.\nBattigalli and Siniscalchi take this a level further by iterating the strong-beliefs operator--\neveryone strongly believes that everyone strongly believes that everyone is rational, and\nso forth--and this operator leads to backward induction in games of perfect information;\nwithout perfect information, it leads to iterated deletion of strategies that are never a best\nreply. This leads to a formalization of the idea of rationalizability in extensive-form games.\n22. Forward Induction in Signaling Games\nThe NWBR property is a useful way to show that some components of equilibria are not\nstable. For instance, Cho and Kreps (1987) developed an equilibrium refinement for signaling\ngames that is weaker than stability-the intuitive criterion-based on iterated applications of\nNWBR. Kohlberg and Mertens (1986) motivated their stability concept by mathematical\nproperties they deemed desirable and robustness with respect to trembles a la Selten's perfect\nequilibrium. By contrast, Cho and Kreps provided a behavioral foundation based on refining\nthe set of plausible beliefs in the spirit of Kreps and Wilson's sequential equilibrium.\nIn a signaling game, there are two players, a sender S and a receiver R. There is a set T\nof types for the sender; the realized type will be denoted by t. p(t) denotes the probability\nof type t. The sender privately observes his type t, then sends a message m ∈M(t). The\nreceiver observes the message and chooses an action a ∈A(m). Finally both players receive\npayoffs uS(t, m, a), uR(t, m, a); thus the payoffs potentially depend on the true type, the\nmessage sent, and the action taken by the receiver. A signaling game is parameterized by\nthe set T, the prior p, the feasible message and action correspondences M, A, and the payoff\nfunctions uS, uR. In such a game we will use T(m) to denote the set {t | m ∈M(t)}.\nCho and Kreps' intuitive criterion provides a behavioral explanation of one aspect of the\nNWBR property: robustness to replacing the equilibrium path by its expected payoff. This\nsolution presumes that players are certain about play along the equilibrium path, but there\nis uncertainty about play offthe path. If we begin with a stable set and then, using NWBR,\ndelete a strategy in which type t plays an action m, the reduced game should have a stable\ncomponent contained in the original component. This means that the surviving equilibria\nshould assign probability zero to type t following message m.\n\nNON-COOPERATIVE GAMES\nConsider the beer-quiche signaling game from Figure ?? (FT, p. 450). In this example,\nplayer 1 is wimpy or surly, with respective probabilities 0.1 or 0.9. Player 2 is a bully who\nwould like to fight the wimpy type but not the surly one. Player 1 orders breakfast and 2\ndecides whether to fight him after observing his breakfast choice. In the notation above,\nT = {weak, surly}; M = M(t) = {beer, quiche}, ∀t ∈T; A(m) = {fight, not fight}, ∀m ∈\nM.\nFigure 15\nPlayer 1 gets a utility of 1 from having his favorite breakfast--beer if surly, quiche if\nweak--but a disutility of 2 from fighting. When player 1 is weak, player 2's utility is 1 if he\nfights and 0 otherwise; when 1 is surly, the payoffs to the two actions are reversed.\nOne can show that all equilibria involve pooling. The key idea in this game is to compare\nσ2(F|beer) and σ2(F|quiche). The breakfast leading to a smaller probability of fighting must\nbe selected with probability 1 in equilibrium by the type of player 1 who likes it. . . We find\nthat there are two classes of sequential equilibria, corresponding to two distinct outcomes.\nIn one set of sequential equilibria, both types of player 1 drink beer, while in the other both\ntypes of player 1 eat quiche. In both cases, player 2 must fight with probability at least\n1/2 when observing the out-of-equilibrium breakfast since otherwise one of the two types of\nplayer 1 would want to deviate to the other breakfast. Note that either type of equilibrium\ncan be supported with any belief for player 2 placing a probability weight of at least 1/2 on\nplayer 1 being wimpy following the out-of-equilibrium breakfast (hence there is an infinity\nof sequential equilibrium assessments).\nCho and Kreps argued that the equilibrium in which both types choose quiche is unrea-\nsonable for the following reason. It does not make any sense for the weak type to deviate\nCourtesy of The MIT Press. Used with permission.\n\nMIHAI MANEA\nto ordering beer, no matter how he thinks that the receiver will react, because he is already\ngetting payoff3 from quiche, whereas he cannot get more than 2 from switching to beer.\nOn the other hand, the surly type can benefit if he thinks that the receiver will react by\nnot fighting. Thus, conditional on seeing beer ordered, the receiver should conclude that the\nsender is surly and so should not want to fight. Clearly, the class of equilibria in which both\ntypes choose quiche violates NWBR.\nOn the other hand, this argument does not rule out the equilibrium in which both types\ndrink beer. In this case, in equilibrium the surly type is getting 3, whereas he gets at most\n2 from deviating no matter how the receiver reacts; hence he cannot want to deviate. The\nweak type, on the other hand, is getting 2, and he can get 3 by switching to quiche if he\nthinks this will induce the receiver not to fight him. Thus only the weak type would deviate,\nso the sender's belief (that the receiver is weak if he orders quiche) is reasonable.\nNow consider modifying the game by adding an extra option for the receiver: paying\na million dollars to the sender. Now the preceding argument doesn't rule out the quiche\nequilibrium--either type of sender might deviate to beer if he thinks this will induce the\nreceiver to pay him a million dollars. Hence, in order to apply the same argument, we need\nto make the additional assumption that the sender cannot expect the receiver to play a bad\nstrategy. Then we can restrict attention to the game without the million-dollar option, and\nthe argument goes through.\nCho and Kreps formalized this line of reasoning in the intuitive criterion, as follows. For\nany set of types T ′ ⊆T and any message m, write\nBR(T ′, m) = ∪μ | μ(T ′)=1 BR(μ, m)\n--the set of strategies that R could rationally play if he observes m and is sure that the\nsender's type is in T ′. Now with this notation established, consider any sequential equilib-\nrium, and let u∗\nS(t) be the equilibrium payoffto a sender of type t. Define\nT(m) = {t | u∗\nS(t) >\nmax\nuS(t, m, a)\na∈BR(T(m),m)\n}.\nThis is the set of types that do better in equilibrium than they could possibly do by sending\nm, no matter how R reacts, as long as R is playing a best response to some belief. We then\nsay that the proposed equilibrium fails the intuitive criterion if there exist a type t′ and a\n\nNON-COOPERATIVE GAMES\nmessage m ∈M(t′) such that\nu∗\nS(t′) <\nmin\nuS(t′, m, a).\na∈\n\nBR(T(m)\\T(m),m)\nIn words, the equilibrium fails the intuitive criterion if some type t′ of the sender is getting\nless than any payoffhe could possibly get by playing m, assuming he could thereby convince\n\nthe sender that he could not possibly be in T(m).\nIn the beer-quiche example, the all-quiche equilibirum fails this criterion: let t′ = surly\n\nand m = beer; check that T(m) = {weak}.\nWe can apply this procedure repeatedly, giving the iterated intuitive criterion. Given a\nproposed equilibrium, we can use the intuitive criterion as above to rule out pairs (t, m)--\ntypes t that cannot conceivably want to send message m. We can then rule out some actions\nof the receiver, by requiring that the receiver should best respond to a belief about the types\nthat have not yet been eliminated given the message. Under the surviving actions, we can\npossibly rule out more pairs (t, m), and so forth.\nThis idea has been further developed by Banks and Sobel (1987). They say that type t′\nis infinitely more likely to choose the out-of-equilibrium message m than type t under the\nfollowing condition: the set of possible best-replies by the receiver (possibly mixed) that make\nt′ strictly prefer to deviate to m is a strict superset of the possible best-replies that make t\nweakly prefer to deviate. If this holds, then conditional on observing m, the receiver should\nput probability 0 on type t. The analogue of the Intuitive Criterion under this elimination\nprocedure is known as D1. If we allow t′ to vary across different best replies by the sender,\nrequiring only that every best response that weakly induced t to deviate would also strictly\ninduce some t′ to deviate, then this gives criterion D2. We can also apply either of these\nrestrictions on beliefs to eliminate possible actions by the receiver, and proceed iteratively.\nIterating D2 leads to the equilibrium refinement criterion known as universal divinity.\nThe motivating application is Spence's job-market signaling model. With just two types\nof job applicant, the intuitive criterion selects the equilibrium where the low type gets the\nlowest level of education and the high type gets just enough education to deter the low type\nfrom imitating her. With more types, the intuitive criterion no longer accomplishes this. D1\ndoes manage to uniquely select the socially optimal separating equilibrium by having each\ntype get just enough education to deter the next-lower type from imitating her.\n\nMIHAI MANEA\n23. The Spence Signaling Model\nWe next consider Spence's (1973) signaling model of the job market.13 An employer faces\na worker of unknown ability θ. The ability of the worker is known to the worker though, and\nis either θ = H or θ = L, where H > L > 0. Interpret these numbers as the money value of\nwhat the worker would produce working in the firm.\nThe worker would like to transmit the knowledge of her ability to the firm; the problem\nis how to do so in a credible way. Think of education as just such a device.\n23.1. The Game. Specifically, suppose that a worker can choose to acquire e units of edu-\ncation, where e is any nonnegative number. Of course, the worker will have to study hard\nto obtain her education, and this creates disutility (studying for exams, doing homework,\netc.). Assume that a worker of true ability θ expends e/θ in disutility. The point is, then,\nthat H-types can acquire education easier than L-types.\nThe game proceeds as follows:\n1. Nature moves and chooses a worker type, H or L. The type is revealed to the worker\nbut not to the employer.\n2.\nThe worker then chooses e units of education.\nThis is perfectly observed by the\nemployer.\n3. The employer observes e and forms an estimate of θ. He then pays the worker a salary\nequal to this estimate, which is just the conditional expectation of θ given e, written IE(θ|e).\n4. The H-worker's payoffis IE(θ|e) -e/H, and the L-worker's payoffis IE(θ|e) -e/L.\nThe game is set up so simply that the employer's expected payoffis zero. Essentially, we\nassume that the worker's choice of education is visible to the world at large so that perfect\ncompetition must push her wage to IE(θ|e), the conditional expectation of θ given e.\nVery Important. Note well that IE(θ|e) is not just a given but it is an endogenous object\nderived from strategies. How it is computed will depend on worker strategies and how they\ntranslate in beliefs.\n23.2. Single Crossing. Suppose that a worker of type θ uses a probability distribution μθ\nover different education levels. First observe that if e is a possible choice of the high worker\n13This exposition is based on notes by Debraj Ray\n(http://www.econ.nyu.edu/user/debraj/Courses/05UGGameLSE/Handouts/05uggl10.pdf).\n\nNON-COOPERATIVE GAMES\nand e′ a possible choice of the low worker, then it must be that e ≥e′. This follows from the\nfollowing important single-crossing argument.\nThe H-type could have chosen e′ instead of e, so\ne\n(23.1)\nIE(θ|e) -H ≥IE(θ|e′) -e′\n,\nH\nwhile the L-type could have chosen e instead of e′, so\ne′\n(23.2)\nIE(θ|e′) -L ≥IE(θ|e) -e .\nL\nAdding both sides in (??) and (??), we see that\n(e -e′)\nL -1\nH\n\n≥.\nBecause 1/L > 1/H, it follows that e ≥e′.\nEssentially, if the low type weakly prefers a higher education to a lower one, the high type\nwould strictly prefer it. So a high type can never take strictly less education than a low type\nin equilibrium.\nThis sort of result typically follows from the assumption that being a high type reduces\nnot just the total cost from taking an action but also the marginal cost of that action; in this\ncase, of acquiring one more unit of education. As long as this feature is present, we could\nreplace the cost function e/θ by any cost function and the same analysis goes through.\n23.3. Equilibrium. Now that we know that the high type will not invest any less than the\nlow type, we are ready to describe the equilibria of this model. There are three kinds of\nequilibria here; the concepts are general and apply in many other situations.\n1. Separating Equilibrium. Each type takes a different action, and so the equilibrium\naction reveals the type perfectly. It is obvious that in this case, L must choose e = 0, for\nthere is nothing to be gained in making a positive effort choice.\nWhat about H? Note: she cannot play a mixed strategy because each of her actions fully\nreveals her type, so she might as well choose the least costly of those actions. So she chooses\na single action: call it e∗, and obtains a wage equal to H. Now these are the crucial incentive\nconstraints; we must have\ne∗\n(23.3)\nH -L ≤L,\n\nMIHAI MANEA\notherwise the low person will try to imitate the high type, and\ne∗\n(23.4)\nH -\nL,\nH ≥\notherwise the high person will try to imitate the low type.\nLook at the smallest value of e∗that just about satisfies (??); call it e1. And look at\nthe largest value of e∗that just about satisfies (??); call it e2. Clearly, e1 < e2, so the two\nrestrictions above are compatible.\nAny outcome in which the low type chooses 0 and the high type chooses some e∗∈[e1, e2]\nis supportable as a separating equilibrium. To show this we must also specify the beliefs\nof the employer.\nThere is a lot of leeway in doing this.\nHere is one set of beliefs that\nworks: the employer believes that any e < e∗(if observed) comes from the low type, while\nany e > e∗(if observed) comes from the high type. These beliefs are consistent because\nsequential equilibrium in this model imposes no restrictions on off-the-equilibrium beliefs.\nGiven these beliefs and equations (??) and (??), we can check that no type has incentives\nto deviate.\n2. Pooling Equilibrium. There is also a family of pooling equilibria in which only one\nsignal is received in equilibrium. It is sent by both types, so the employer learns nothing\nnew about the types. So if it sees that signal -- call it e∗-- it simply pays out the expected\nvalue calculated using the prior beliefs: pH + (1 -p)L.\nOf course, for this to be an equilibrium two conditions are needed. First, we need to\nspecify employer beliefs offthe equilibrium path. Again, a wide variety of such beliefs are\ncompatible; here is one: the employer believes that any action e = e∗is taken by the low\ntype. [It does not have to be this drastic.14] Given these beliefs, the employer will \"reward\"\nany signal not equal to e∗with a payment of L. So for the types not to deviate, it must be\nthat\ne∗\npH + (1 -p)L -\nL,\nθ ≥\nbut the binding constraint is clearly for θ = L, so rewrite as\ne∗\npH + (1 -p)L -L ≥L.\n14For instance, the employer might believe that any action e < e∗is taken by the low type, while any action\ne > e∗is taken by types in proportion to their likelihood: p : 1 -p.\n\nNON-COOPERATIVE GAMES\nThis places an upper bound on how big e∗can be in any pooling equilibrium. Any e∗between\n0 and this bound will do.\n3. Hybrid Equilibria. There is also a class of \"hybrid equilibria\" in which one or both\ntypes randomize. For instance, here is one in which the low type chooses 0 while the high\ntype randomizes between 0 (with probability q) and some e with probability 1 -q. If the\nemployer sees e he knows the type is high. If he sees 0 the posterior probability of the high\ntype there is -- by Bayes' Rule -- equal to\nqp\n,\nqp + (1 -p)\nand so the employer must pay out a wage of precisely\nqp\nqp + (1 -p)H +\n1 -p\nL.\nqp + (1 -p)\nBut the high type must be indifferent between the announcement of 0 and that of e, because\nhe willingly randomizes. It follows that\nqp\nqp + (1 -p)H +\n1 -p\nqp + (1 -p)L = H -e .\nH\nTo complete the argument we need to specify beliefs everywhere else. This is easy as we've\nseen more than once (just believe that all other e-choices come from low types). We therefore\nhave a hybrid equilibrium that is \"semi-separating\".\nIn the Spence model all three types of equilibria coexist. Part of the reason for this is that\nbeliefs can be so freely assigned offthe equilibrium path, thereby turning lots of outcomes\ninto equilibria. What we turn to next is a way of narrowing down these beliefs. To be sure,\nto get there we have to go further than just sequential equilibrium.\n23.4. The Intuitive Criterion. Consider a sequential equilibrium and a non-equilibrium\nannouncement (such as an nonequilibrium choice of education in the example above). What\nis the other recipient of such a signal (the employer in the example above) to believe when\nshe sees that signal?\nSequential equilibrium imposes little or no restrictions on such beliefs in signalling models.\n[We have seen, of course, that in other situations -- such as those involving moves by Nature\n-- that it does impose several restrictions, but not in the signalling games that we have been\n\nMIHAI MANEA\nstudying.] The purpose of the Intuitive Criterion is to try and narrow beliefs further. In this\nway we eliminate some equilibria and in so doing sharpen the predictive power of the model.\nConsider some non-equilibrium signal e. Consider some type of a player, and suppose\neven if she were to be treated in the best possible way following the emission of the signal\ne, she still would prefer to stick to her equilibrium action. Then we will say that signal e is\nequilibrium-dominated for the type in question. She would never want to emit that signal,\nexcept purely by error. Not strategically.\nThe Intuitive Criterion (IC) may now be stated.\nIf, under some ongoing equilibrium, a non-equilibrium signal is received which is equilibrium-\ndominated for some types but not others, then beliefs cannot place positive probability weight\non the former set of types.\nNotice that IC places no restrictions on beliefs over the types that are not equilibrium dom-\ninated, and in addition it also places no restrictions if every type is equilibrium-dominated.\nFor then the deviation signal is surely an error, and once that possibility is admitted, all\nbets about who is emitting that signal are off.\nThe idea behind IC is the following \"speech\" that a sender (of signals) might make to a\nrecipient:\nLook, I am sending you this signal which is equilibrium-dominated for types A, B or C.\nBut it is not so for types D and E. Therefore you cannot believe that I am types A, B or\nC.\nLet us apply this idea to the Spence model.\nProposition 4. In the Spence Signalling model, a single equilibrium outcome survives the\nIC, and it is the separating equilibrium in which L plays 0 while H plays e1, where e1 solves\n(??) with equality.\nProof. First we rule out all equilibria in which types H and L play the same value of e with\npositive probability. [This deals with all the pooling and all the hybrid equilibria.]\nAt such an e, the payoffto each type θ is\ne\nλH + (1 -λ)L -θ,\n\nNON-COOPERATIVE GAMES\nwhere λ represents the employer's posterior belief after seeing e. Now, there always exists\nan e′ > e such that\ne\nλH + (1 -λ)L -L = H -e′\nL < H -e′\nH\nIf we choose e′′ very close to e′ but slightly bigger than it, it will be equilibrium-dominated\nfor the low type --\ne\nλH + (1 -λ)L -L > H -e′′\n,\nL\nwhile it is not equilibrium-dominated for the high type:\ne\nλH + (1 -λ)L -H < H -e′′\n.\nH\nBut now the equilibrium is broken by having the high type deviate to e′′. By IC, the employer\nmust believe that the type there is high for sure and so must pay out H. But then the high\ntype benefits from this deviation relative to playing e.\nNext, consider all separating equilibria in which L plays 0 while H plays some e > e1.\nThen a value of e′ which is still bigger than e1 but smaller than e can easily be seen to\nbe equilibrium-dominated for the low type but not for the high type. So such values of e′\nmust be rewarded with a payment of H, by IC. But then the high type will indeed deviate,\nbreaking the equilibrium.\nThis proves that the only equilibrium that can survive the IC is the one in which the low\ntype plays 0 and the high type chooses e1.\n□\nThe heart of the intuitive criterion is an argument which is more general: it is called\nforward induction. The basic idea is that an off-equilibrium signal can be due to one of two\nthings: an error, or strategic play. If at all strategic play can be suspected, the error theory\nmust play second fiddle: that's what a forward induction argument would have us believe.\n24. Forward Induction and Iterated Weak Dominance\nIn the same way that iterated strict dominance and rationalizability can be used to narrow\ndown the set of predictions without pinning down strategies perfectly, the concept of iterated\nweak dominance (IWD) can be used to capture some of the force of forward and backward\ninduction without assuming that players coordinate on a certain equilibrium. Since the idea\nof forward induction is that players interpret a deviation as a signal of future play, forward\n\nMIHAI MANEA\ninduction is more compatible with a situation of considerable strategic uncertainty-a non-\nequilibrium model-rather than a theory in which players are certain about the opponents'\nstrategies.\nIn games with perfect information iterated weak dominance implies backward induction.\nIndeed, any suboptimal strategy at a penultimate node is weakly dominated, then we can\niterate this observation.\nIWD also captures part of the forward induction notion implicit in stability, since stable\ncomponents contain stable sets of games obtained by removing a weakly dominated action.\nFor instance, applying IWD to the motivating example of Kohlberg and Mertens we obtain\nT\nW\nO\n2, 2\n2, 2\nIT\n0, 0\n3, 1\nIW\n1, 3\n0, 0\nthe unique outcome (IT, W) predicted by stability.\nSimilarly, we can solve the beer-quiche game using IWD. Consider the ex ante game in\nwhich the types of player 1 are treated as two distinct information sets for the same player.\nPlayer 1's strategy (beer if wimp, quiche if surly) is strictly dominated by a strategy under\nwhich with probability .9 both types of player 1 eat quiche and with probability .1 both\ndrink beer. Indeed, for any strategy of player 2, the latter strategy involves the same total\nprobability that player 1 is fought by player 2 as the former, but the latter leads to player 1's\nfavorite breakfast with higher probability. Once we eliminate (beer if wimp, quiche if surly),\nonly the strategies (beer if wimp, beer if surly) and (quiche if wimp, beer if surly) generate\na breakfast of beer for player 1. Then the decision of whether player 2 should fight after\nobserving a breakfast of beer makes a difference only in the event that player 1 uses one of\nthese two strategies. The best response to either strategy is not fighting because it implies\na probability of at least .9 of confronting the surly type. This means that any strategy for\n2 that involves fighting after observing beer is weakly dominated in the strategic form by\none with no fighting after beer. Then the surly type should choose beer in any surviving\nequilibrium, which generates his highest possible payoffof 3-he has his preferred breakfast\nand is not challenged by player 2.\n\nNON-COOPERATIVE GAMES\nBen-Porath and Dekel (1992) consider the following striking example in which the mere\noption of \"burning money\" selects a player's favorite equilibrium in the following battle of\nthe sexes game. The outcome (U, L) is preferred by player 1 to any other outcome, and is\nL\nR\nU\n5, 1\n0, 0\nD\n0, 0\n1, 5\na strict Nash equilibrium. Suppose we extend the game to include a signaling stage, where\nplayer 1 has the possibility of burning, say, 2 units of utility before the game begins. Hence\nplayer 1 first chooses between the game above and the following game. Burning and then\nL\nR\nU\n3, 1\n-2, 0\nD\n-2, 0\n-1, 5\nplaying D is strongly dominated for player 1 (by not burning and playing D) hence if player 2\nobserves 1 burning, then 2 can conclude that 1 will play U. Therefore player 1 can guarantee\nherself a payoffof 3 by burning and playing U, since 2 (having concluded that 1 will play\nU after burning) will play L. Formally, any strategy in which 2 plays R after burning is\nweakly dominated by playing L after burning (the two strategies lead to the same outcome\nin the event that player 1 does not burn, hence the weak domination). Now, even if player\n1 does not burn, player 2 should conclude that 1 will play U. This is because, by playing\nD, player 1 can receive a payoffof at most 1, while the preceding argument demonstrated\nthat player 1 can guarantee 3 (by burning). That is, among the surviving strategies, player\n1's strategy of playing D after not burning is strictly dominated by burning and playing\nU. Hence, if 2 observes that 1 does not burn then 2 will play L-playing R after 1 does not\nburn is weakly dominated among the surviving strategies by playing L-leading to player 1's\npreferred outcome which involves no burning and (U, L). Thus player 1 can ensure that his\nmost preferred equilibrium is played even without burning. Ben-Porath and Dekel show that\nin any game where a player has a unique best outcome that is a strict Nash equilibrium and\ncan signal with a sufficiently fine grid of burning stakes, she will attain her most preferred\noutcome under IWD.\n\nMIHAI MANEA\n25. Repeated Games\nWe now move on to consider another important topic: repeated games. Let G = (N, A, u)\nbe a normal-form stage game. At time t = 0, 1, . . ., the players simultaneously play game\nG. At each period, the players can all observe play in each previous period; the history\nis denoted ht = (a0, . . . , at-1).\nPayoffs in the repeated game RG(δ) are given by Ui =\n(1 -δ) Pinf\nt=0 δtui(at). The (1 -δ) factor normalizes the sum so that payoffs in the repeated\ngame are on the same scale as in the stage game. We assume players follow behavior strategies\n(by Kuhn's theorem), so a strategy σi for player i is given by a choice of σi(ht) ∈∆(Ai) for\neach history ht. Given such strategies, we can define continuation payoffs after any history\nht: U (σ|ht\ni\n).\nIf α∗is a Nash equilibrium of the static game, then playing α∗at every history is a\nsubgame-perfect equilibrium of the repeated game. Conversely: for any finite game G and\n\nany ε > 0, there exists δ with the property that, for any δ < δ, any SPE of the repeated game\nRG(δ) has the property that, at every history, play is within ε of a static NE (in the strategy\nspace). However, interesting results generally occur when players have high discount factors,\nnot low discount factors.\nThe main results for repeated games are \"Folk Theorems\": for high enough δ, every feasible\nand individually rational payoffvector in the stage game can be attained in an equilibrium\nof the repeated game. There are several versions of such a theorem, which is why we use\nthe plural. For now, we look at repeated games with perfect monitoring (the class of games\ndefined above), where the appropriate equilibrium concept is SPE. We can check if a strategy\nprofile is an SPE by using the one-shot deviation principle. Conditional on a history ht, i's\npayofffrom playing a and then following σ in the continuation is given by the value function\n(25.1)\nVi(a) = (1 -δ)ui(a) + δUi(σ|ht, a).\nThis gives us an easy way to check whether or not a player wants to deviate from a proposed\nstrategy, given other player's strategies. σ is an SPE if and only if, for every history ht, σ|ht\nis a NE of the induced game G(ht, σ) whose payoffs are given by (??).\nTo state a folk theorem, we need to explain the terms \"individually rational\" and \"feasi-\nble.\" The minmax payoffof player i is the worst payoffhis opponents can hold him down\n\nNON-COOPERATIVE GAMES\nto if he knows their strategies:\nvi =\nQmin\n\nmax ui(ai, α-i)\nα-i∈\n∆(A\na\nj\ni\nj)\ni\n=\n∈Ai\n\n.\nWe will let mi, a minmax profile for i, denote a profile of strategies (ai, α\ni) that solves\n-\nthis minimization and maximization problem.\nNote that we require independent mixing\nby i's opponents. It is important to consider mixed, rather than just pure, strategies for\ni's opponents. For instance, in the matching pennies game the minmax when only pure\nstrategies are allowed for the opponent is 1, while the actual minmax, involving mixed\nstrategies, is 0.\nIn any SPE--in fact, any Nash equilibrium--i's payoffis at least his minmax payoff, since\nhe can always get at least this much by just best-responding to his opponents' (possibly\nindependently mixed) actions in each period separately. This motivates us to say that a\npayoffvector v (i.e. an element of RN, specifying a payofffor each player) is individually\nrational if vi ≥vi for each i, and it is strictly individually rational if the inequality is strict\nfor each i.\nThe set of feasible payoffs (properly, feasible payoffvectors) is the convex hull of the\nset {u(a) | a ∈A}. Again note that this can include payoffs that are not obtainable in the\nstage game using mixed strategies, because some such payoffs may require correlation among\nplayers to achieve. Under the common discount factor assumption, the normalized payoffs\nalong any path of play in the repeated game are certainly in the feasible set.\nAlso, in studying repeated games we usually assume the availability of a public random-\nization device that produces a publicly observed signal ωt ∈[0, 1], uniformly distributed and\nindependent across periods, so that players can condition their actions on the signal. Prop-\nerly, we should include the signals (or at least the current period's signal) in the specification\nof the history, but it is conventional not to write it out explicitly. The public randomization\ndevice is a convenient way to convexify the set of possible equilibrium payoffvectors: for\nexample, given equilibrium payoffvectors v and v′, any convex combination of them can be\nrealized by playing the equilibrium with payoffs v conditional on some realizations of the\ndevice and v′ otherwise. (Fudenberg and Maskin (1991) showed that one can actually do\n\nMIHAI MANEA\nthis without the public randomization device for sufficiently high δ, while preserving incen-\ntives, by appropriate choice of which periods to play each action profile involved in any given\nconvex combination.)\nAn easy folk theorem is that of Friedman (1971):\nTheorem 22. If e is the payoffvector of some Nash equilibrium of G, and v is a feasible\npayoffvector with vi > ei for each i, then for all sufficiently high δ, there exists an SPE with\npayoffs v.\nProof. Just specify that the players play whichever action profile gives payoffs v (using the\npublic randomization device to correlate their actions if necessary), and revert to the static\nNash permanently if anyone has ever deviated. When δ is high enough, the threat of reverting\nto Nash is severe enough to deter anyone from deviating.\n□\nSo, in particular, if there is a Nash equilibrium that gives everyone their minmax payoff\n(for example, in the prisoner's dilemma), then every strictly individually rational and feasible\npayoffvector is obtainable in SPE.\nHowever, it would be nice to have a full, or nearly full, characterization of the set of\npossible equilibrium payoffvectors (for large δ). In many repeated games, the Friedman folk\ntheorem is not strong enough for this. A more general folk theorem would say that every\nindividually rational, feasible payoffis achievable in SPE under general conditions. This is\nharder to show, because in order for one player to be punished by minmax if he deviates,\nothers need to be willing to punish him. Thus, for example, if all players have equal payoff\nfunctions, then it may not be possible to punish a player for deviating, because the punisher\nhurts himself as well as the deviator.\nFor this reason, the standard folk theorem (due to Fudenberg and Maskin, 1986) requires\na full-dimensionality condition.\nTheorem 23. Suppose the set of feasible payoffs has full dimension n. For any feasible and\nstrictly individually rational payoffvector v, there exists δ such that whenever δ > δ, there\nexists an SPE of RG(δ) with payoffs v.\nActually we don't quite need the full-dimensionality condition--all we need, conceptually,\nis that there are no two players who have the same payofffunctions; more precisely, no\n\nNON-COOPERATIVE GAMES\nplayer's payofffunction can be a positive affine transformation of any other's (Abreu, Dutta,\nand Smith, 1994). But the proof is easier under the stronger assumption.\nProof. We will first give the construction assuming that i's minmax action profile mi is pure.\nConsider the action profile a for which u(a) = v. Choose v′ in the interior of the feasible,\nindividually rational set with v\ni\ni\n′ < vi for each i. Let w denote v′ with ε added to each\nplayer's payoffexcept for player i; with ε low enough, this will again be a feasible payoff\nvector.\nStrategies are now specified as follows.\n- Phase I: play a, as long as there are no deviations. If i deviates, switch to IIi.\n- Phase II\ni\ni: play m . If player j deviates, switch to IIj. (If several players deviate\nsimultaneously, we may arbitrarily choose j among them; this makes little difference,\nsince verification of the equilibrium will only require checking single deviations.) Note\nthat if mi is a pure strategy profile it is clear what we mean by j deviating. If it\nrequires mixing it is not so clear; this will be discussed in the second part of the\nproof. Phase IIi lasts for T periods, where T is a number, independent of δ, to be\ndetermined, and if there are no deviations during this time, play switches to IIIi.\n- Phase III\ni\ni: play the action profile leading to payoffs w forever. If j deviates, go to\nIIj. (This is the \"reward\" phase that gives players -i incentives to punish in phase\nIIi.)\nWe check that there are no incentives to deviate, using the one-shot deviation principle\nfor each of the three phases: calculate the payoffto i from complying and possible deviations\nin each phase. Phases IIi and IIj (j = i) need to be considered separately, as do IIIi and\nIIIj.\n- Phase I: deviating gives at most (1 -δ)M + δ(1 -δT)v\nT\ni + δ\n+1vi\n′, where M is some\nupper bound on all of i's feasible payoffs, and complying gives vi. Whatever T we\nhave chosen, it is clear that as long as δ is sufficiently close to 1, complying produces\na higher payoffthan deviating, since vi\n′ < vi.\n- Phase IIi: Suppose there are T ′ ≤T remaining periods in this phase. Then complying\ngives i a payoffof (1 -δT ′)v\nT\ni + δ\n′vi\n′, whereas since i is being minmaxed, deviating\ncan't help in the current period and leads to T more periods of punishment, for a\n\nMIHAI MANEA\ntotal payoffof at most (1 -δT+1)v\nT\ni + δ\n+1vi\n′. Thus deviating is always worse than\ncomplying.\n- Phase II : With T ′ remaining periods, i gets (1 -δT ′\nj\n)ui(mj) + δT ′(vi\n′ + ε) from\ncomplying and at most (1 -δ)M + (δ -δT+1)v\nT\ni + δ\n+1vi\n′ from deviating. When δ is\nlarge enough, complying is preferred.\n- Phase IIIi: This is the one case that affects the choice of T. Complying gives vi\n′\nin every period, while deviating gives at most (1 -δ)M + δ(1 -δT)v\nT\ni + δ\n+1vi\n′.\nRearranging, the comparison is between (δ + δ2 + . . . + δT)(vi\n′ -vi) and M -v′\ni. For\nany δ ∈(0, 1), there exists T such that the desired inequality holds for all δ > δ.\n- Phase IIIj: Complying gives vi\n′ + ε forever, whereas deviating leads to a switch to\nphase IIi and so gives at most (1-δ)M +δ(1-δT)v\nT\ni +δ\n+1vi\n′. Again, for sufficiently\nlarge δ, complying is preferred.\nNow we need to deal with the part where minmax strategies are mixed. For this we need to\nchange the repeated-game strategies so that, during phase IIj, player i is indifferent among\nall the possible sequences of T realizations of his prescribed mixed action. We accomplish\nthis by choosing a different reward ε for each such sequence, so as to balance out their\ndifferent short-term payoffs. We're not going to talk about this in detail; see the Fudenberg\nand Maskin paper for this.\n□\n26. Repeated Games with Fixed δ < 1\nThe folk theorem shows that many payoffs are possible in SPE. But the construction of\nstrategies in the proof is fairly complicated, since we need to have punishments and then\nrewards for punishers to induce them not to deviate. In general, an equilibrium may be\nsupported by an elaborate hierarchy of punishments, and punishments of deviations from\nthe prescribed punishments, and so on. Also, the folk theorem is concerned with limits as\nδ →1, whereas we may be interested in the set of equilibria for a particular value of δ < 1.\nWe will now approach the question of identifying equilibrium payoffs for a given δ < 1.\nIn repeated games with perfect information, it turns out that an insight of Abreu (1988)\nwill simplify the analysis greatly: equilibrium strategies can be enforced by using a worst\npossible punishment for any deviator. First we need to show that there is a well-defined\nworst possible punishment.\n\nNON-COOPERATIVE GAMES\nTheorem 24. Suppose each player's action set in the stage game is a compact subset of a\nEuclidean space and payoffs are continuous in actions, and some pure-strategy SPE of the\nrepeated game exists. Then, among all pure-strategy SPEs, there is one that is worst for\nplayer i.\nThat is, the infimum of player i's payoffs, across all pure-strategy SPEs, is attained.\nProof. We prove this for every player i simultaneously.\nAn equilibrium play path is an infinite sequence of action profiles, one for each period, that\nis attained in some pure-strategy SPE. Fix a sequence of such play paths ai,k, k = 0, 1, 2, . . .\nsuch that Ui(ai,k) converges to the specified infimum y(i), as k →inf. We want to define a\nlimit of the play paths, in such a way that the limiting path is again achieved in some SPE,\nwith payoffy(i) to player i. The constructed equilibria rely on each other for punishments\noffthe equilibrium path.\nEach play path is an element of the strategy space Q\nt\n0 A, where A is the action space of\n≥\nthe stage game. Endow this space with the product topology. Convergence in the product\ntopology is defined componentwise--that is, ai,k →ai,infif and only if ai,k\nt\n→ai,\nt\ninffor each\nt.\nBecause the space of paths is sequentially compact,15 by passing to a subsequence if\nnecessary, we can ensure that the ai,k have a limiting play path ai,inf. It is easy to check that\nthe resulting payoffto player i is y(i).\nNow we just have to check that this limiting play path ai,infis supportable as an SPE\nby some strategy profile. We construct the following profile. Play starts in regime i. A\ndeviation by player j from the current regime leads to regime j. In each regime i, all players\nplay according to ai,inf.\n15By a diagonalisation argument, a countable product of sequentially compact spaces is sequentially compact.\nNote that while the set of play paths in Abreu's setting is sequentially compact, the space of pure strategy\nprofiles is not. This space is an uncountable product of Euclidean sets. For instance, second-period strategies\ndepend on the first period action profile and are represented by the set AA. Even when A is an closed interval,\nAA is not sequentially compact. (Note, however, that by Tychonoff's theorem AA is a compact set.) For\na proof, consider the set [0, 1][0,1] with the product topology. We can think of each point in the set as a\nfunction f : [0, 1] →[0, 1]. Convergence in the product topology reduces to point-wise convergence for such\nfunctions. Let fn(x) denote the nth digit in the binary expansion of x. The sequence (fn) does not admit a\nconvergent subsequence. Indeed, for any subsequence (fnk)k≥0 consider an x ∈[0, 1] whose binary expansion\nhas the nk entry equal to 0 for k even and 1 for k odd. Then (fnk(x))k\n0 is not a convergent sequence of\n≥\nreal numbers, and hence (fnk)k≥0 does not converge in the product topology.\n\nMIHAI MANEA\nNow we need to check that the |N| strategy profiles constructed this way are indeed SPEs.\nConsider a deviation by player j from stage τ of regime i to an action aj. His payofffrom\ndeviating is\ni,\nb\n(1 -δ)uj(baj, a inf\nj (τ)) + δy(j).\n-\nWe want to show that this is at most the continuation payofffrom complying,\ninf\n(1 -δ)\nX\nδtuj(ai,inf(τ + t)).\nt=0\nBut we know that for each k, there is some SPE whose equilibrium play path is ai,k; in SPE,\nj is disincentivized from deviating, and we also know that by deviating his value in future\nperiods is at least y(j) (by definition of y(j)). So for each k we have\ninf\n(1 -δ)\nX\nδtuj(ai,k(τ + t)) ≥uj(baj, ai,k\n+\n-j(τ))\nδy(j).\nt=0\nBy taking limits at k →inf, we see that there is no incentive to deviate in the strategy profile\nsupporting ai,inf, either.\nThis shows there are never incentives for a one-shot deviation. So by the one-shot deviation\nprinciple, we do have an SPE giving i his infimum of SPE payoffs, for each player i.\n□\nAbreu refers to an SPE that gives i his worst possible payoffas an optimal penal code.\nThe above theorem applies when there exists a pure-strategy SPE. If the stage game is\nfinite, there frequently will not be any pure-strategy SPE. In this case, there will be mixed-\nstrategy SPE, and we would like to again prove that an optimal (mixed-strategy) penal code\nexists. A different method is required; we invoke a theorem of Fudenberg and Levine (1983).\nTheorem 25. Consider an infinite-horizon repeated game with a finite stage game. The\nset of strategy profiles is simply the countable product\nht\ni ∆(Ai), taken over all possible\nfinite histories ht and players i. Put the product topology\nQ\non\nQ\nthis space. Then the set of SPE\nprofiles and payoffs are nonempty and compact.\nThe set of SPEs in nonempty because it includes strategies that play the same static Nash\nequilibrium following any history. Since the stage game is finite,\nht\ni ∆(Ai) is a countable\nproduct of sequentially compact spaces, so it is sequentially compact\nQ\nQ\n(see also footnote ??).\nOne can easily show that payoffs vary continuously in the strategy profile for the repeated\n\nNON-COOPERATIVE GAMES\ngame (with the product topology). Indeed, for any sequence σn →σ and any fixed t, the\ndistribution over date t histories/actions induced by σn converges to the one induced by σ\nas n →inf. Then the expected payoffs under σn converge to those under σ as n →inf. This\nimmediately implies that the set of SPEs is closed.16 Since Q\nht\nQ\ni ∆(Ai) is compact by\nTychonoff's theorem and closed subsets of compact sets are compact, it follows that the set\nof SPE strategies is compact. As payoffs are continuous in strategies, the set of SPE payoffs\nis also compact.17 In particular, for every player i there exists an SPE that minimizes i's\npayoff, that is, an optimal penal code for i.\nThe following result holds in either of the settings where we proved the existence of an\noptimal penal code--either for pure strategies when the stage game has continuous action\nspaces (and some SPE exists) or for mixed strategies when the stage game is finite.\nTheorem 26. (Abreu, 1988) Any distribution over play paths achievable by an SPE can be\ngenerated by an SPE enforced by optimal penal codes offthe equilibrium path, i.e. when i is\nthe first to deviate, continuation play follows the optimal penal code for i.\nFor mixed-strategy equilibria, \"offthe path\" means \"at histories that occur with proba-\nbility zero.\"\nProof. Let σˆ be the given SPE. Form a new strategy profile s by leaving play on the equilib-\nrium path as proposed by σˆ, and replacing play offthe equilibrium path by the optimal penal\ncode for i when i is the first deviator (or one of the first deviators, if there is more than one).\nBy the one-shot deviation principle and the fact that off-path play follows an SPE, we need\nonly check that i does not want to deviate when play so far is on the equilibrium path--but\nthis is immediate, because i is punished with y(i) in the continuation if he deviates, whereas\nin the original profile σˆ he would get at least y(i) in the continuation (by definition of y(i))\nand we know this was already low enough to deter deviation (because σˆ was an SPE).\n□\nAbreu (1986) looks at symmetric games and considers strongly symmetric equilibria--\nequilibria in which all players behave identically at every history, including asymmetric\n16Since countable product of metric spaces is metrizable, the product topology on\nh\ni ∆(Ai) is metrizable,\nt\nso closed sets can be defined in terms of convergent sequences.\n17These conclusions extend to multistage games with observable actions that ha\nQ\nve a\nQ\nfinite set of actions at\nevery stage and are continuous at infinity. See Theorem 4.4 in FT, relying on approximate equilibria of\ntruncated games.\n\nMIHAI MANEA\nhistories. This is a simple setting because everyone gets the same payoff, so there is one such\nequilibrium that is worst for everyone. One can similarly show that there is an equilibrium\nthat is best for everyone. Abreu considers a stage game that is a general version of a Cournut\noligopoly. The action spaces are given by [0, inf) (however, there exists an M such that\ntaking an action higher than M is never rational). He assumes that payoffs are continuous\nand bounded from above as well as (a) the payoffat a symmetric action profile where all\npayers choose action a are quasi-concave and decrease without bound as a →infand (b) the\nmaximum payoffa player can achieve by responding to a profile in which all of his opponents\nplay the same action a is decreasing in a.\nTheorem 27. Let e∗and e denote the highest and lowest payoffper player in a pure-strategy\n∗\nstrongly symmetric equilibrium.\n- The payoffe\ncan be attained in an equilibrium with strongly symmetric strategies\n∗\nof the following form: \"Begin in phase A, where players choose an action a\nthat\n∗\nsatisfies\n(1 -δ)u(a , . . . , a ) + δe∗= e .\n∗\n∗\n∗\nIf there are no deviations, switch to an equilibrium with payoffe∗(phase B). Other-\nwise, continue in phase A.\"\n- Phase B: the payoffe∗can be attained with strategies that play a constant action\na∗as long as there are no deviations and switch to the worst strongly symmetric\nequilibrium (phase A) if there are any deviations.\nFor a proof of the first part of the statement, fix some strongly symmetric equilibrium σˆ\nwith payoffe and first period action a. Since the continuation payoffs under σˆ cannot be\n∗\nmore than e∗, the first period payoffs u(a, . . . , a) must be at least (-δe∗+ e )/(1\nδ). Thus,\n∗\n-\nunder condition (a) there is an a\n≥a with u(a , . . . , a ) = (-δe∗+ e )/(1\n∗\n∗\n∗\n∗\n-δ). Let σ∗\ndenote the strategies constructed in phase A. By definition, the strategies σ are subgame\n∗\nperfect in phase B. In phase A, condition (b) and a ≥a imply that the short-run gain to\n∗\ndeviating is no more than that in the first period of σˆ. Since the punishment for deviating\nin phase A is the worst possible punishment, the fact that no player prefers to deviate in the\nfirst period of σˆ implies that no player prefers to deviate in phase A of σ .\n∗\n\nNON-COOPERATIVE GAMES\nThe good equilibrium can be sustained by punishments that last only one period due\nto assumption (a), which ensures that punishments can be made arbitrarily bad.\nThis\nis an important simplifying assumption.\nThen describing the set of strongly symmetric\nequilibrium payoffs is simple--there are just two numbers, a\nand a∗, and we just have\n∗\nto write the incentive constraints relating the two, which makes computing these extremal\nequilibria fairly easy. For either of the extremal equilibria, a first-period deviation leads to\none period of punishment with the profile (a , . . . , a ) and playing (a∗, . . . , a∗) thereafter.\n∗\n∗\nAbreu shows that this simple \"stick and carrot\" structure implies that a\nis the highest\n∗\naction and a∗is the lowest (recall that payoffs are decreasing in actions) among the pairs\n(a , a∗) for which the corresponding incentive constraints bind,\n∗\nmax ui(ai, a\ni) -ui(a , . . . , a )\n=\nδ(ui(a∗, . . . , a∗)\nu (\n))\ni Ai\n∗-\n∗\n∗\n-\ni a , . . . , a\na\n∗\n∗\n∈\nmax ui(ai, a∗\ni) -ui(a∗, . . . , a∗)\n=\nδ(u\nai∈Ai\n-\ni(a∗, . . . , a∗) -ui(a , . . . , a )).\n∗\n∗\nTypically the best outcome is better (and the worst punishment is worse) than the static\nNash equilibrium.\n27. Imperfect Public Monitoring\nNext we describe the paradigm of repeated games with imperfect public monitoring: play-\ners only see a signal of other players' past actions, rather than observing the actions fully.\nWe spell out the general model while simultaneously giving a classic motivating example,\nthe collusion model of Green and Porter (1984).\nMore specifically, each period there is a publicly observed signal y, which follows some\nprobability distribution conditional on the action profile a; write πy(a) for the probability of y\ngiven a. Each player i's payoffis ri(ai, y), something that depends only on his own action and\nthe signal. His expected payofffrom a strategy profile is then ui(a) = P\ny Y ri(ai, y)πy(a).\n∈\nIn the Green-Porter model, each player is a firm in a cartel that sets a production quan-\ntity. Quantities are only privately observed. There is also a market price, which is publicly\nobserved and depends stochastically on the players' quantity choices (thus there is an un-\nobserved demand shock each period). Each firm's payoffis the product of the market price\nand its quantity, as usual. So the firms are trying to collude by keeping quantities low and\nprices high, but in any given period prices may be low, and each firm doesn't know if prices\n\nMIHAI MANEA\nare low because of a demand shock or because some other firm deviated and produced a\nhigh quantity. In particular, Green and Porter assume that the support of the price signal\ny does not depend on the action profile played, which ensures that a low price may occur\neven when no firm has deviated.\nGreen and Porter did not try to solve for all equilibria of their model. Instead they simply\ndiscussed the idea of threshold equilibria: everyone plays the collusive action profile aˆ for a\nwhile; if the price y is ever observed to be below some threshold yˆ, revert to static Nash for\nsome number of periods T, and then return to the collusion phase. (Note: this is not pushing\nthe limits of what is feasible, since, for example, Abreu's work implies that there can be worse\npunishments possible than just reverting to static Nash.) In general, the optimal choice of\nT will be finite, since the punishment phase can be triggered accidentally in equilibrium and\nit is not optimal to end up stuck there forever.\nDefine λ(a) = P(y > yˆ|a), the probability of seeing a high price when action profile a is\nplayed. Equilibrium values are then given by\nvˆi = (1 -δ)ui(aˆ) + δλ(aˆ)vˆi + δ(1 -λ(aˆ))δTvˆi\n(after normalizing the static Nash payoffs to 0). This lets us calculate vˆ for any proposed aˆ\nand T,\n(1\nu\n)\nˆ\n-δ)\ni(aˆ\nv =\n.\n1 -δλ(aˆ) -δT+1(1 -λ(aˆ))\nThese strategies form an equilibrium only if no player wants to deviate in the collusive phase:\nδ(1 -δT)(λ(aˆ) -λ(a′\nui(a′\ni, aˆ\n(aˆ)\n-i) -ui\n≤\ni, aˆ-i))vˆi\n1 -δ\n= δ(1 -δT)(λ(ˆa) -λ(a′\ni, ˆa-i))ui(ˆa)\n1 -δλ(aˆ) -δT+1(1 -λ(aˆ))\nfor all possible deviations a′\ni. This compares the short-term incentives to deviate, the relative\nprobability that deviation will trigger a reversion to static Nash, and the severity of the\npunishment.\nIt is possible to sustain payoffs at least slightly above static Nash with trigger strategies\nfor high δ. One can check that the incentive constraints hold for T = infand aˆ just below the\nstatic Nash actions, with δ and λ close to 1 (and low yˆ) and some bounds on the derivative\nof λ. As already remarked, Green and Porter did not identify the best possible equilibria.\nTo describe how one would find better equilibria, we need a general theory of repeated\ngames with imperfect public monitoring. Accordingly, we return to the general setting; the\n\nNON-COOPERATIVE GAMES\nnotation is as laid out at the beginning of this section. We will present the theory of these\ngames as developed by Abreu, Pearce, and Stacchetti (1990) (hereafter referred to as APS).\nFor convenience we will assume that the action spaces Ai and the space Y of possible\nsignals are finite. Recall that we write πy(a) for the probability distribution over y given\naction profile a. It is clear how to generalize this to the distribution πy(α) where α is a\nmixed action profile.\nIf there were just one period, players would just be playing the normal-form game with\naction sets Ai and payoffs ui(a) = P\ny Y πy(a)ri(ai, y). With repetition, this is no longer the\n∈\ncase since play can be conditioned on the history--but may not be able to be conditioned\nexactly on past actions of opponents, as in the earlier, perfect-monitoring setting, because\nplayers do not see their opponents' actions.\nNotice that the perfect monitoring setting can be embedded into this framework, by simply\nletting Y = A be the space of action profiles, and y be the action profile actually played\nwith probability 1. We can also embed \"noisy\" repeated games with perfect monitoring,\nwhere each agent tries to play a particular action ai in each period but ends up playing any\nother action a′\ni with some small probability ε; each player can only observe the action profile\nactually played, rather than the actions that the opponents \"tried\" to play.\nIn a repeated game with imperfect public monitoring, at any time t, player i's information\nis given by his private history\nht\ni = (y0, . . . , yt-1; a0\ni , . . . , at\ni\n-1).\nThat is, he knows the history of public signals and his own actions (but not others' actions).\nHe can condition his action in the present period on this information. The public history\nht = (y0, . . . , yt-1) is commonly known.\nIn their original paper, APS restrict attention to pure strategies, which is a nontrivial\nrestriction.\nA strategy σi for player i is a public strategy if σi(ht\ni) depends only on the history of public\nsignals y0, . . . , yt-1.\nLemma 1. Every pure strategy is equivalent to a public strategy.\n\nMIHAI MANEA\nProof. Let σi be a pure strategy. Define a public strategy σi\n′ on length-t histories by induction:\nσi\n′(y0, . . . , yt-1) = σi(y0, . . . , yt-1; a0\ni , . . . , at-1\ni\n) where as\ni = σ\ni\n′(y , . . . , ys-1) for each s < t.\nThat is, at each period, i plays the actions specified by σi for the given public signals and\nthe history of private actions that i was supposed to play. It is straightforward to check\nthat σi\n′ is equivalent to σi, since they differ only at \"off-path\" histories reachable only by\ndeviations of player i.\n□\nThis shows that if attention is restricted to pure strategies, it is no further loss to restrict\nin turn to public strategies. However, instead of doing this, we will follow the exposition\nof Fudenberg, Levine, and Maskin (1994) and restrict attention to public (but potentially\nmixed) strategies.\nLemma 2. If i's opponents use public strategies, then i has a best response in public strate-\ngies.\nProof. At every date i knows what the other players will play, since their actions depend\nonly on the public history; hence i can just play a best response to their anticipated future\nplay, which does not depend on i's private history of past actions.\n□\nThis allows us to define a perfect public equilibrium (PPE): a profile σ = (σi) of public\nstrategies such that, at every public history ht = (y0, . . . , yt-1), the strategies σi|ht form a\nNash equilibrium of the continuation game.\n(This is the straightforward adaptation of the concept of subgame-perfect equilibrium to\nour setting. Notice that we cannot simply use subgame-perfect equilibrium because it has\nno bite in general--there are no subgames.)\nThe set of PPE's is stationary--they are the same at every history. This is why we look\nat PPE. Sequential equilibrium does not share this stationarity property, because a player\nmay want to condition his play in one period on the realization of his mixing in a previous\nperiod. Such correlation across periods can be self-sustaining in equilibrium: if i and j both\nmixed at a previous period, then the signal in that period gives i information about the\nrealization of j's mixing, which means it is informative about what j will do in the current\nperiod, and therefore affects i's current best response. On the other hand, some third player\nk may be unable to infer what j will do in the current period, since he does not know what\n\nNON-COOPERATIVE GAMES\ni played in the earlier period. Consequently, different players can have different information\nat time t about what will be played at time t, and stationarity is destroyed. We stick to\npublic equilibria in order to avoid this difficulty.\nImportantly, the one-shot deviation principle applies to our setting. That is, a set of public\nstrategies constitutes a PPE if and only if there is no beneficial one-shot deviation for any\nplayer.\nLet w : Y →Rn be a function. We interpret wi(y) as the continuation payoffplayer i\nexpects after signal y is realized.\nDefinition 22. A pair consisting of a (mixed) action profile α and payoffvector v ∈Rn is\nenforceable with respect to W ⊆Rn if there exists w : Y →W such that\nvi = (1 -δ)ui(α) + δ\nX\nπy(α)wi(y)\ny∈Y\nand\nvi ≥(1 -δ)ui(a′\ni, α\ni) + δ\nX\nπy(a′\ni, α\ni)w (\n-\n-\ni y)\ny∈Y\nfor all i and all a′\ni ∈Ai.\nThe idea of enforceability is that it is incentive-compatible for each player to play according\nto α in the present period if continuation payoffs are given by w, and the resulting (expected)\npayoffs starting from the present period are given by v.\nLet B(W) be the set of all v that are enforceable with respect to W for some action profile\nα. This is the set of payoffs generated by W.\nTheorem 28. Let E be the set of payoffvectors that are achieved by some PPE. Then\nE = B(E).\nProof. For any v ∈E generated by some equilibrium strategy profile σ, let αi = σi(∅) and\nwi(y) be the expected continuation payoffof player i in subsequent periods given that y is\nthe realized signal. Since play in subsequent periods again forms a PPE, w(y) ∈E for each\nsignal realization y. Then (α, v) is enforced by w on E--this is exactly the statement that v\nrepresents overall expected payoffs and players do not have incentives to deviate from α in\nthe first period. So v ∈B(E).\n\nMIHAI MANEA\nConversely, if v ∈B(E), let (α, v) be enforced by w on E.\nConsider the strategies\ndefined as follows: play α in the first period, and whatever signal y is observed, play in\nsubsequent periods follows a PPE with payoffs w(y). These strategies form a PPE, by the\none-shot deviation principle: enforcement means that there is no incentive to deviate in\nthe first period, and the fact that continuation play is given by a PPE ensures that there\nis no incentive to deviate in any subsequent period. Finally it is straightforward from the\ndefinition of enforcement that the payoffs are in fact given by v. Thus v ∈E.\n□\nDefinition 23. W ⊆Rn is self-generating if W ⊆B(W).\nWe have shown that E is self-generating. The next result shows that E is the largest\nbounded self-generating set.\nTheorem 29. If W is a bounded, self-generating set, then W ⊆E.\nProof. Let v ∈W. We want to construct a PPE with payoffs given by v. We construct the\nstrategies iteratively, simultaneously specifying, for each public history ht = (y0, . . . , yt-1),\nthe strategies to be played and the continuation values that each player should expect from\nsubsequent play for each realization of the signal.\nThe base case, t = 0, has players receiving continuation payoffs given by v. Now suppose\nwe have specified play for periods 0, . . . , t -1, and promised continuation payoffs for each\nhistory of signals y0, . . . , yt-1.\nSuppose the history of public signals so far is y0, . . . , yt-1 and promised continuation\npayoffs are given by v′ ∈W. Because W is self-generating, there is some action profile α\nand some w : Y →W such that (α, v′) is enforced by w. Specify that the players play α at\nthis history, and whatever signal y is observed, their continuation payoffs starting from the\nnext period should be w(y).\nThe expected payoffs following any public history match the target continuation payoffs;\nin particular, the constructed strategies generate expected payoffs of v at time 0. This follows\nfrom the adding-up identities, since they ensure that the continuation payofffollowing any\npublic history ht equals the expected total payoffs across the following s periods plus δs times\nthe promised continuation payofffrom period t+s onward, and the latter converges to zero as\ns →inf. Here the assumption that W is bounded is essential; otherwise we could run a Ponzi\n\nNON-COOPERATIVE GAMES\nscheme with promised continuation payoffs. Finally, these strategies form a PPE--this is\neasily checked using the one-shot deviation principle. Enforcement means exactly that there\nare no incentives to deviate at any history.\n□\nIn addition to obtaining this characterization of the set of PPE payoffs, Abreu, Pearce, and\nStacchetti also prove a monotonicity property with respect to the discount factor. Let E(δ)\nbe the set of PPE payoffs when the discount factor is δ. Suppose that E(δ) is convex: this\ncan be achieved either by incorporating public randomization into the model, or by having\na sufficiently rich space of public signals (however, in our version of the model Y is finite).\nThen if δ1 < δ2 we have E(δ1) ⊆B(E(δ1), δ2), and therefore, by the previous theorem,\nE(δ1) ⊆E(δ2). This is shown by the following approach: given v ∈E(δ1) = B(E(δ1), δ1),\nfind α and w that enforce v when the discount factor is δ1; then we can enforce (α, v) for\ndiscount factor δ2 with continuation payoffs given by a suitable convex combination of w and\n(the constant function) v. The operator B has the following properties.\n- If W is compact, so is B(W). This is shown by a straightforward topological argu-\nment.\n- B is monotone: if W ⊆W ′ then B(W) ⊆B(W ′).\n- If W is nonempty, so is B(W). To show this, just let α be a Nash equilibrium of the\nstage game, w : Y →W a constant function, and v the resulting payoffs.\nNow let V be the set of all feasible payoffs, which is certainly compact. Consider the\nsequence of iterates B0(V ), B1(V ), . . ., where B0(V ) = V and Bk(V ) = B(Bk-1(V )). By\ninduction, these sets are compact and form a decreasing sequence. Hence, their intersection\nBinf(V ) is non-empty and compact. Since E ⊆V and E = B(E), the set E is contained in\neach term of the sequence, so E ⊆Binf(V ).\nTheorem 30. E = Binf(V ).\nProof. We are left to prove that Binf(V ) ⊆E.\nIt suffices to show that Binf(V ) is self-\ngenerating. Suppose v ∈Binf(V ). Then there exists (αk, wk)k≥1 such that (αk, v) is enforced\nby some wk : Y →Bk-1(V ). By compactness, this sequence has a convergent subsequence.\nLet (αinf, winf) denote the limit of such a subsequence. It must be that winf(y) ∈Binf(V ) since\nwinf(y) is a limit point of the closed set Bk(V ) for all k. By continuity, (αinf, v) is enforced\nby winf: Y →Binf(V ), so v ∈B(Binf(V )).\n□\n\nMIHAI MANEA\nThis result characterizes the set of PPE payoffs: if we start with the set of all feasible\npayoffs and apply the operator B repeatedly, then the resulting sequence of sets converges\nto the set of equilibrium payoffs.\nCorollary 4. The set of PPE payoffvectors is nonempty and compact.\n(Nonemptiness is immediate because, for example, the infinite repetition of any static NE\nis a PPE.)\nIn their setting with finite action spaces and continuous signals with a common support,\nAPS also show a \"bang-bang\" property of perfect public equilibria. We say that w : Y →W\nhas the bang-bang property if w(y) is an extreme point of W for each y. They show that if\n(α, v) is enforceable on a compact W, it is in fact enforceable on the set ext(W) of extreme\npoints of W. Consequently, every vector in E can be achieved as the vector of payoffs from\na PPE such that the vector of continuation payoffs at every history lies in ext(E).\n28. The Folk Theorem for Imperfect Public Monitoring\nFudenberg, Levine, and Maskin (1994) (hereafter FLM) prove a folk theorem for repeated\ngames with imperfect public monitoring.\nThey identify conditions on the stage game--\nparticularly on how informative public signals need to be about actions--under which it\nis possible to construct convex sets with a smoothly curved boundary, approximating the\nset of feasible, individually rational payoffs arbitrarily closely that are self-generating for\nsufficiently high discount factors. This implies that a folk theorem obtains.\nThe proof is fairly complicated. We will briefly discuss the technical difficulties involved.\nFirst, there has to be statistical identifiability of each player's actions. If player i's deviation\nto αi\n′ generates exactly the same distribution over signals as some mixed action αi he is\nsupposed to play (given opponents' play α\ni), but gives him a higher payoffon average, then\n-\nclearly there is no way to enforce the action profile α in equilibrium. To avoid this problem,\nFLM assume an individual full-rank condition: given α\n,\n-i the different signal distributions\ngenerated by varying i's pure actions ai are linearly independent.\nThey need to further assume a pairwise full rank condition: deviations by player i are\nstatistically distinguishable from deviations by player j. Intuitively this is necessary because,\nif the signal suggests that someone has deviated, the players need to know who to punish.\n\nNON-COOPERATIVE GAMES\n(Radner, Myerson, and Maskin (1986) give an example of a game that violates this condition\nand where the folk theorem does not hold. There are two workers who put in effort to increase\nthe probability that a project succeeds; they both get 1 if it succeeds and 0 otherwise. The\noutcome of the project does not statistically distinguish between shirking by player 1 and\nshirking by player 2. So if the project fails, both players have to be punished by giving them\nlower continuation payoffs than if it succeeds. Because it fails some of the time even if both\nplayers are working, this means that equilibrium payoffs are bounded away from efficiency,\neven as δ →1.)\nThe statement of the pairwise full rank condition is as follows: given the action profile α,\nif we form one matrix whose rows represent the signal distributions from (ai, α\ni) as ai varies\n-\nover Ai, and another matrix whose rows represent the signal distributions from (aj, α-j) as\naj varies over Aj, and stack these two matrices, the combined matrix has rank |Ai|+|Aj|-1.\n(This is effectively \"full rank\"--it is not possible to have literal full rank |Ai| + |Aj|, since\nthe signal distribution generated by α is a linear combination of the rows of the first matrix\nand is also a linear combination of the rows of the second matrix.)\nWhen this condition is satisfied, it is possible to use continuation payoffs to transfer utility\nbetween the two players i, j in any desired ratio, depending on the signal, so as to incentivize\ni and j to play according to the desired action profile.\nHaving imposed appropriate formulations of these conditions, FLM show that the W they\nconstruct is locally self-generating: for every v ∈W, there is an open neighborhood U and\na δ < 1 such that U ∩W ⊆B(W) when δ > δ. This definition allows δ to vary with v. For\nW compact and convex, they show that local self-generation implies self-generation for all\nsufficiently high δ.\nThe intuition behind their approach to proving local self-generation is best grasped with\na picture. Suppose we want to achieve some payoffvector v on the boundary of W. The\nfull-rank conditions ensure we can enforce it using some continuation payoffs that lie below\nthe tangent hyperplane to W at v, by \"transferring\" continuation utility between players as\ndescribed above. As δ →1, the continuation payoffs sufficient to enforce v contract toward\nv, and the smoothness condition on the boundary of W ensures that they will eventually lie\ninside W. Thus (α, v) is enforced on W.\n[PICTURE--See p. 1013 of Fudenberg, Levine, Maskin (1994)]\n\nMIHAI MANEA\nSome extra work is needed to take care of the points v where the tangent hyperplane is a\ncoordinate hyperplane (i.e. one player's payoffis constant on this hyperplane).\nAn argument along these lines shows that every vector on the boundary of W is achievable\nusing continuation payoffs in W, when δ is high enough. Using public randomization among\nboundary points, we can then achieve any payoffvector v in the interior of W as well. It\nfollows that W is self-generating (for high δ).\n29. Changing the Information Structure with Time Period\nFollow FT pp. 197-200. Suppose players have a discount rate r and can only update\ntheir actions at times t, 2t, . . .. Then the effective discount rate is δ = e-rt. Hence the\nlimit δ →1 has two interpretations: either players become patient (r →0) or periods are\nshort (t →0). In games where actions are observable, as well as games with imperfect\npublic monitoring in which the amount of information revealed does not change with t, the\nvariables r and t enter symmetrically in δ and the limit set of PPE payoffs as δ →1 can\nbe interpreted both as the outcome when players are patient and when periods are short.\nHowever, if monitoring is imperfect and the quality of signals deteriorates as t →0, then the\nshort period interpretation is lost.\nAbreu, Milgrom, and Pearce (1991) point out that the two limits r →0 and t →0 may\nlead to distinct predictions. They focus on partnership games where the expected payoffs in\nthe stage game induce the structure of prisoners' dilemma. Players do not directly observe\neach other's level of effort. Instead, the total level of effort is imperfectly reflected in a public\nsignal, interpreted as the number of \"successes.\" The signal has a Poisson distribution with\nan intensity parameter λ if both players cooperate and μ if one of them defects. Assume\nthat λ > μ, so that signals indeed represent \"good news.\"18 For small t, the probability\nof observing more than one success is of order t2. As in FT, we simplify the analysis by\napproximating the signal structure with a setting in which there are either 0 or 1 successes\nobserved, with probabilities e-θt and 1 -e-θt, respectively, for θ ∈{λ, μ}.\nLet c denote the common payoffwhen both players cooperate, and c + g the payoffa\nplayer obtains from defecting when the other cooperates; payoffs when both players defect\nare normalized to 0. The static Nash equilibrium (defect, defect) generates the minmax\n18AMP also analyze the case of \"bad news,\" where signals indicate failures.\n\nNON-COOPERATIVE GAMES\npayofffor both players. Hence the worst equilibrium for either player in the repeated game\ndelivers zero payoffs.\nRestrict attention to pure strategy strongly symmetric equilibria. Let v∗denote the payoff\nin an optimal equilibrium within this class. It can be easily seen that such an equilibrium\nmust specify cooperation in the first period. Suppose that a public randomization device\nis available, so that continuation play when the number of successes observed is i = 0, 1\ncan be described by playing the worst equilibrium (minmax, static Nash), with 0 payoffs,\nwith probability α(i) and the best equilibrium, which yields common continuation payoffs\nv∗, with probability 1 -α(i).\nThe relevant PPE constraints are\nv∗\n=\n(1 -e-rt)c + e-rt e-λt(1 -α(0)) + (1 -e-λt)(1 -α(1)) v∗\n≥\n(1 -e-rt)(c + g) + e-rt e-μt(1 -α(0)) + (1\n\n-e-μt)(1 -α(1)) v∗\nSolving for v∗in the first equation, we obtain\n\n(1\nc\nv∗\n-e-rt)\n=\n.\n1 -e-rt (1 -α(1) -e-λt(α(0) -α(1)))\nThe incentive constraint becomes\n(1 -e-rt)g ≤e-rt(e-μt -e-λt)(α(0) -α(1))v∗,\nwhich simplifies to\nce-rt(e-μt\ng\n-e-λt)(α(0) -α(1))\n≤\n.\n1 -e-rt (1 -α(1) -e-λt(α(0) -α(1)))\nNote that v∗is decreasing in α(1) and the incentive constraint is also relaxed by decreas-\ning α(1). Hence an optimal symmetric equilibrium in pure strategies specifies α(1) = 0.\nIntuitively, an optimal equilibrium should not involve any punishment if a success occurs.\nSetting α(1) = 0, the constraints become\n(1\nv∗\n=\n-e-rt)c\n1 -e-rt(1 -e-λtα(0))\ne-rt(e-μt\ng/c\n-e-λt)α(0)\n≤\n1 -e-rt(1 -e-λtα(0))\nIt is possible to satisfy the inequality for α(0) ≤1 only if\ne-rt(e-μt\n(29.1)\ng/c\n-e-λt)\n≤1 -e-rt(1 -e-λt)\n\nMIHAI MANEA\nNote that\ne-rt(e-μt -e-λt) ≤e(λ-μ)t\n1 -e-rt(1 -e-λt)\n-1.\nThe RHS of the inequality above converges to 0 as t →0. Hence an equilibrium with payoffs\nabove static Nash does not exist for small t. The term e(λ-μ)t can be interpreted as the\nlikelihood ratio for no success. As t →0 this ratio converges to 1. Since we are almost\ncertain that no success occurs even when both players exert effort, the information provided\nby the public signal is too poor for there to be an equilibrium that improves on the static\nNash outcome.\nTaking the limit r →0 in ??, we obtain\n(29.2)\ng/c ≤e(λ-μ)t -1.\nHence an equilibrium with the desired properties exists for small r and certain values of t.\nFor the \"optimal\" (minimum) α(0), we find that when ?? holds,\ng\nlim v∗= c\nr→0\n-\n,\ne(λ-μ)t -1\nwhich is greater than limt\n0 v∗= 0 when ?? is satisfied with strict inequality.\n→\n30. Reputation\nRepeated games provide a useful setting for studying the concept of reputation build-\ning. The earliest repeated-game models of reputation were by the Gang of Four (Kreps,\nMilgrom, Roberts, and Wilson); in various combinations they wrote three papers that were\nsimultaneously published in JET 1982.\nThe motivating example was the \"chain-store paradox.\" In the chain-store game, there\nare two players, an entering firm and an incumbent monopolist. The entrant (player 1) can\nenter or stay out; if it enters, the incumbent (player 2) can fight or not. If the entrant stays\nout, payoffs are (0, a) where a > 1. If the entrant enters and the incumbent does not fight,\nthe payoffs are (b, 0) where b ∈(0, 1). If they do fight, payoffs are (b -1, -1). There is a\nunique SPE, in which the entrant enters and the incumbent does not fight.\nIn reality, incumbent firms seem to fight when a rival enters, and thereby deter other\npotential rivals.\nWhy would they do this?\nIn a one-shot game, it is irrational for the\nincumbent to fight the entrant. As pointed out by Selten, even if the game is repeated finitely\n\nNON-COOPERATIVE GAMES\nmany times, the unique SPE still has the property that there is entry and accommodation\nin every period, by backward induction.\nThe Kreps-Wilson explanation for entry deterrence is as follows: with some small positive\nprobability, the monopolist does not have the payoffs described above, but rather is obsessed\nwith fighting and has payoffs such that it always chooses to fight. Then, when there are a\nlarge number of periods, they show that there is no entry for most of the game, with entry\noccurring only in the last few periods.\nTheir analysis is tedious, so we will instead illustrate the concepts with a simpler example\ndue to Muhamet Yildiz: the centipede game from Figure ??. Initially each player has $1.\nPlayer 1 can end the game (giving payoffs (1, 1)), or he can give up $1 for player 2 to get $2.\nPlayer 2 can then end the game (giving (0, 3)), or can give up $1 for player 1 to get $2. Player\n1 can then end the game (with payoffs (2, 2)), or can give up $1 for player 2 to get $2. And\nso forth--until the payoffs reach (100, 100), at which point the game automatically ends. We\nwill refer to continuing the game as \"playing across\" and ending as \"playing down,\" due to\nthe shape of the centipede diagram.\nThere is a unique SPE in this game, in which both players play down at every opportunity.\nBut believing in SPE requires us to hold very strong assumptions about the players' higher-\norder knowledge of each other's rationality.\nSuppose instead that player 1 has two types. With probability 0.999, he is a \"normal\"\ntype and his payoffs are as above. With probability 0.001, he is a \"crazy\" type who always\n\nMIHAI MANEA\ngets utility -1 if he ends the game and 0 if player 2 ends the game. (Player 2's payoffs are\nthe same regardless of 1's type.) The crazy type of player 1 thus always wants to continue\nthe game. Player 2 never observes player 1's type.\nWhat happens in equilibrium? Initially player 1 has a low probability of being the crazy\ntype. If the normal player 1 plays down at some information set, and the crazy player 1\nacross, then after 1 plays across, player 2 must infer that 1 is crazy. But if player 1 is crazy\nthen he will continue the game until the end; knowing this, player 2 also wants to play across\nin order to accumulate money. Anticipating this, the normal type of player 1 in turn also\nwants to play across in order to get a high payoff.\nWith this intuition laid out, we analyze the game formally and describe the sequential\nequilibria. Number the periods, starting from the end, with 1 being player 2's last information\nset, 2 being player 1's previous information set,. . ., 198 being 1's first information set. The\ncrazy player 1 always plays across.\nPlayer 2 always plays across with positive probability at every period n > 1. (Proof: if\nnot, then the normal player 1 must play down at period n+1. Then, conditional on reaching\nn, player 2 knows that 1 is crazy with probability 1, hence he would rather go across and\ncontinue the game to the end.)\nHence there is positive probability of going across at every period, so the beliefs are\nuniquely determined from the equilibrium strategies by Bayes' rule.\nNext we see that the normal player 1 plays across with positive probability at every n > 2.\nProof: if not, then again, at n-1 player 2 is sure that he is facing a crazy type and therefore\nwants to go across. Given this strategy by player 2, then, the normal 1 also has incentives\nto go across at n so that he can go down at n -2, contradicting the assumption that 1 only\ngoes down at n.\nNext, if 2 goes across with probability 1 at n, then 1 goes across with probability 1 at\nn + 1, and this in turn implies that 2 goes across with probability 1 at n + 2. This is also\nseen by the same argument as in the previous paragraph. Therefore there is some cutoff\nn∗≥3 such that both players play across with probability 1 at n > n∗, and there is mixing\nfor 2 < n ≤n∗. (We know that both the normal 1 and 2 play down with probability 1 at\nn = 1, 2.)\n\nNON-COOPERATIVE GAMES\nLet pn be the probability of the normal type of player 1 going down at n, if n is even. Let\nμn be the probability player 2 assigns to the crazy type at node n.\nAt each odd node n, 2 < n ≤n∗, player 2 is to be indifferent between going across and\ndown. The payoffto going down is some x. The payoffto going across is (1 -μn)pn\n(x\n-1\n-\n1) + [1 -(1 -μn)pn\n1](x + 1), using the fact that player 2 is again indifferent (or strictly\n-\nprefers going down) two nodes later. Hence we get (1 -μn)pn-1 = 1/2: player 2 expects\nplayer 1 to play down with probability 1/2. But μn-2 = μn/(μn + (1 -μn)(1 -pn-1)) by\nBayes' rule; this simplifies to μn-2 = μn/(1 -(1 -μn)pn\n1) = 2μn. We already know that\n-\nμ1 = 1 since the normal player 1 goes down with certainty at node 2. Therefore μ3 = 1/2,\nμ5 = 1/4, and so forth; and in particular n∗≤20, since otherwise μ21 = 1/1024 < 0.001,\nbut clearly the posterior probability of the crazy type at any node cannot be lower than the\nprior. This shows that for all but the last 20 periods, both players are going across with\nprobability 1 in equilibrium.\n(One can in fact continue to solve for the complete description of the sequential equilib-\nrium: now that we know player 2's posterior at each period, we can compute player 1's mixing\nprobabilities from Bayes' rule, and we can also compute player 2's mixing probabilities given\nthat 1 must be indifferent whenever he mixes.)\nThis model illustrates the way that the concept of reputation is generally modeled in\nrepeated games. A player develops a reputation for playing a certain action; in equilibrium\nit is rational for him to continue with that action in order to maintain the reputation, even\nthough it would not be rational in a one-shot setting. Unraveling is prevented by having a\nsmall probability of a type that is committed to that action.\nThe papers by the Gang of Four consider repeated interactions between the same players,\nwith one-sided incomplete information. Inspired by this work, Fudenberg and Levine (1989)\nconsider a model in which a long-run player faces a series of short-run players, and where there\nare many possible \"crazy\" types of the long-run player, each with small positive probability.\nThey show that if the long-run player is sufficiently patient, he will get close to his Stackelberg\npayoffin any Nash equilibrium of the repeated game.\nThe model is as follows.\nThere are two players, playing the finite normal-form game\n(N, A, u) (with N = {1, 2}) in each period. Player 1 is a long-run player. Player 2 is a\nshort-run player (which we can think of as a series of players who play for one period each,\n\nMIHAI MANEA\nor one very impatient player). Incentive for short-run players are simple: they best respond\nto the long-run player's anticipated action in each stage.\nDefine\nu∗\n1 = max\nmin\nu1(a1, σ2).\na1∈A1 σ2∈BR2(a1)\nThis is player 1's Stackelberg payoff; the action a∗\n1 that achieves this maximum is the Stack-\nelberg action. Fudenberg and Levine (1989) only considers pure action selections by player\n1. The analysis is extended to mixed actions in a follow-up paper published in 1992.\nA strategy for player 1 consists of a function σt\n1 : Ht-1 →∆(A1) for each t ≥0. A strategy\nfor the player 2 who plays at time t consists of a function σt : Ht-1\n→∆(A2). With the\nusual discounted payoffformulation, the game described constitutes the unperturbed game.\nFudenberg, Kreps, and Maskin (1988) prove a version of the folk theorem for this game.\nLet B2 denote the set of mixed strategy best responses in the stage game for the short run\nplayers to mixed strategies of the long run player. Set\nu1 = min\nσ2∈B2 max\na1∈A1 u1(a1, σ2).\nFudenberg, Kreps, and Maskin show that any payoffabove u1 can be sustained in SPE for\nhigh enough δ. The main reputation result of Fudenberg and Levine shows that if there is\na rich space of crazy types of player 1, each with positive probability, this folk theorem is\ncompletely overturned--player 1 obtains a payoffof at least u∗\n1 in any Nash (not necessarily\nsubgame perfect) equilibrium for high δ. Note that for the standard Cournot duopoly with\ntwo firms and linear demand, u1 and u∗\n1 correspond to the follower and leader payoffs,\nrespectively.\nAccordingly, we consider the perturbed game, where there is a countable state space Ω.\nPlayer 1's payoffdepends on the state ω ∈Ω; thus write u1(a1, a2, ω). Player 2's payoffdoes\nnot depend on ω. There is some prior distribution μ on Ω, and the true state is known only\nto player 1. When the state is ω0 ∈Ω, player 1's payoffs are given by the original u1; we call\nthis the \"rational\" type of player 1.\nSuppose that for every a1 ∈A1, there is a state ω(a1) for which playing a1 at every\nhistory is a strictly dominant strategy in the repeated game.19 Thus, at state ω(a1), player\n19Assuming it is strictly dominant in the stage game is not enough. For instance, defection is a dominant\nstrategy in prisoners' dilemma, but always defecting is not a best response agains tit-for-tat in the repeated\ngame.\n\nNON-COOPERATIVE GAMES\n1 is guaranteed to play a1 at every history.\nWrite ω∗= ω(a∗\n1).\nWe assume also that\nμ∗= μ(ω∗) > 0. That is, with positive probability, player 1 is a type who is guaranteed to\nplay a∗\n1 in every period.\nAny strategy profile generates a joint probability distribution π over play paths and states,\nπ ∈∆((A1 × A2)inf× Ω). Let h∗be the event (in this path-state space) that at\n1 = a∗\n1 for all t.\nLet πt\n∗= π(at\n1 = a∗\n1|ht-1), the probability of seeing a∗\n1 at period t given the previous history;\nthis is a random variable (defined on path-state space) whose value is a function of ht-1. For\nany number π ∈(0, 1), let n(π∗\nt ≤π) denote the number of periods t such that π∗\nt ≤π. This\nis again a random variable, whose value may be infinite.\nThe next result provides the main ingredient of the analysis. Conditional on observing\na∗\n1 every period, it is guaranteed that there are at most ln μ∗/ ln π periods in which a∗\n1 is\nexpected with probability below π conditional on the history. In other words, player 2 can\nbe surprised by seeing a∗\n1 only a finite number of times.\nLemma 3. Let σ be a strategy profile such that π(h∗|ω∗) = 1. Then\nπ\n\nn(πt\n∗≤π) ≤ln μ∗\nln\nπ\n\nh∗\n\n= .\nGiven that π(h∗|ω∗) = 1, if the true state is ω∗, then\n\nplayer 1 will always play a∗\n1. Every\ntime the probability of seeing a∗\n1 next period is less than π, if a∗\n1 is in fact played, the posterior\nprobability of ω∗must increase by a factor of at least 1/π. The posterior probability starts\nout at μ∗and can never exceed 1, so it can increase no more than ln μ∗/ ln π times.\nFormally, consider any finite history ht at which a∗\n1 has been played every period, and such\nthat π(ht) > 0. Write ht,1 (ht,2) for the event where ht-1 is observed and then at period t\nplayer 1 (2) plays as in ht. We have that\nπ(ω∗|ht\nπ(ht & ω∗\n)\n)\n|ht-1\n=\nπ(ht|ht-1)\n=\nπ(ω∗|ht-1)π(ht|ω∗, ht-1)\nπ(ht|ht-1)\nπ(ω∗|ht-1)π(ht,1\n=\n|ω∗, ht-1)π(ht,2|ω∗, ht-1)\nπ(ht,1|ht-1)π(ht,2|ht-1)\nπ(ω∗\n=\n|ht-1)π(ht,2|ω∗, ht-1)\nπ(ht,1|ht-1)π(ht,2\nt\n|ht-1)\nπ(ω∗\n=\n|h -)\nπ∗\nt\n.\n\nMIHAI MANEA\nHere the first line of equalities uses Bayes' rule, the second holds because 1 and 2 mix\nindependently at period t, the third holds because if ω∗occurs then at\n1 = a∗\n1, and the fourth\nholds because player 2's behavior conditional on the history ht-1 cannot depend on 1's type.\nRepeatedly expanding, we have\n)\nπ(ω∗|\nt\nπ(ω∗\n) =\n|ht-1\nh\nπ∗\nt\n= . . . =\nπ(ω∗|h0)\nπ∗\nt π∗\nt-1 · · · π∗\n=\nμ∗\nπ∗\nt π∗\nt-1 · · · π∗\n.\nSince π(ω∗|ht) ≤1, at most ln μ∗/ ln π terms in the denominator of the last expression can\nbe less than or equal to π. Therefore, n(π∗\nt ≤π) ≤ln μ∗/ ln π with probability 1.\nNow we get to the main theorem. Let um = minσ2 u1(a∗\n1, σ2, ω0) denote the worst possible\nstage payofffor player 1 when he takes action a∗\n1.\nNote that the payoffu∗\n1 is a \"lower\nStackelberg payoff.\" There is also an \"upper Stackelberg payoff\" in the stage game,\nu1 = max\nmax\nu1(a1, a2).\na1\nσ2∈BR2(a1)\nLet uM = maxa u1(a, ω0) denote the highest payofffor the rational type of player 1 in the\nstage game. Denote by v1(δ, μ, ω0) and v 1(δ, μ, ω0) the infimum and supremum, respectively,\nof rational player 1's payoffs in the repeated game across all Nash equilibria in which player\n1 uses a pure strategy, for given discount factor δ and prior μ.\nTheorem 31. For any value μ∗, there exists a number κ(μ∗) with the following property:\nfor all δ and all (μ, Ω) with μ(ω∗) = μ∗, we have\nv\nκ\n1(δ, μ, ω0) ≥δ (μ∗)u∗\n1 + (1 -δκ(μ∗))um.\nMoreover, there exists κ such that for all δ, we have\nv 1(δ, μ, ω0) ≤δκu1 + (1 -δκ)uM.\nAs δ →1, the payoffbounds converge to u∗\n1 and u1, which are generically identical.\nProof. First, note that there exists a π < 1 such that, in every play path of every Nash\nequilibrium, at every stage t where π∗\nt > π, player 2 plays a best response to a∗\n1. This follows\nfrom the fact that the pure strategy best response correspondence has a closed graph and\nthe assumption that action spaces are finite.\nThus, by the lemma, we have a number κ(μ∗) of periods such that π(n(π∗≤π) >\nκ(μ∗) | h∗) = 0. Now, whatever player 2's equilibrium strategy is, if the rational player\n\nNON-COOPERATIVE GAMES\n1 deviates to simply playing a∗\n1 every period, there are at most κ(μ∗) periods in which player\n2 will not play a best response to a∗\n1--since player 2 is playing a best response to player 1's\nexpected play in each period. Thus the rational player 1 gets a stage payoffof at least um\nin each of these periods, and least u∗\n1 in all the other periods. This immediately gives that\nplayer 1's payofffrom deviating is at least δκ(μ∗)u∗\n1 + (1 -δκ(μ∗))um. Since we have a Nash\nequilibrium, player 1's payoffin equilibrium is at least his payofffrom deviating.\nAn argument similar to the one above establishes the second bound. The idea is to obtain\na version of Lemma ?? with ω∗replaced by ω0. Players may be surprised by the behavior of\ntype ω0 only a finite number of times. In all other periods, they must play a best response\nto the expected play of ω0.\n□\nFudenberg and Levine (1992) extend the result to mixed strategy Nash equilibria. In\ngeneric games, the lower and upper Stackelberg payoffs coincide and we get a unique equi-\nlibrium payofffor the rational player 1 in the limit as δ →1.\n31. Reputation and Bargaining\nAbreu and Gul (2000) consider reputation in the context of bargaining. Two players need\nto divide $1. Every player can be either rational or a crazy type who always demands a fixed\nshare of the dollar. Each player wants to develop a reputation for being irrational in order\nto get his opponent to concede to his demand.\nThe bargaining protocol is very general. Every player is allowed to make offers at a discrete\nset of dates. The analysis focuses on the continuous time limit in which each player gets\nthe opportunity to make offers in every time interval. It turns out that the details of the\nbargaining protocol do not affect the limit outcomes.\nAbreu and Gul show that whenever either player i has revealed himself to be rational\nby doing anything other than demanding αi, there will be almost immediate agreement: j\ncan get himself a share close to αj by continuing to use his reputation, leading i to concede\nquickly in equilibrium. This is similar to the Fudenberg-Levine reputation result, but it\nturns out to be complicated to prove. So what happens in equilibrium if both players are\nrational? They play a war of attrition--each player pretends to be irrational but has some\nprobability of conceding at each period (by revealing rationality), and as soon as one concedes\nthe ensuing payoffs are those given by the reputation story. These concession probabilities\n\nMIHAI MANEA\nmust make each player indifferent between conceding and not; from this we can show that\nthe probabilities are stationary, up to some finite time, and if both players have not conceded\nby that time they must be irrational (and so will never concede).\nThe setting is as follows. There are two players i = 1, 2. Player i has discount rate ri.\nIf an agreement (x1, x2) is reached at time t, the payoffs (if the players are rational) are\n(x e-r1t\n, x2e-r2t). Each player i, in additional to his rational type, has an irrational type,\nwhose behavior is fixed: this type always demands αi, and always accepts offers that give\nhim at least αi and rejects lower offers. We assume α1 + α2 > 1. The prior probability that\nplayer i is irrational is zi.\nWe consider bargaining protocols that are a generalization of the Rubinstein alternating-\noffers protocol. A protocol is given by a function g : [0, inf) →{0, 1, 2, 3}. If g(t) = 0, then\nnothing happens at time t. If g(t) = 1 then player 1 makes an offer, and 2 immediately\ndecides whether to accept or reject. If g(t) = 2 then the same happens with players 1 and 2\nreversed. If g(t) = 3 then both players simultaneously offer. If their offers are incompatible\n(the amount player 1 demands plus the amount player 2 demands exceeds 1) then both offers\nare rejected and the game continues; otherwise each player gets what he demands and the\nremaining surplus is split equally.\nThe protocol is discrete, meaning that for every t, g-1({1, 2, 3})∩[0, t) is finite. A sequence\nof such protocols (gn) converges to the continuous limit if, for all ε > 0, there exists n∗such\nthat for all n > n∗, and for all t, {1, 2} ⊆gn([t, t + ε]). For example, this is satisfied if\ngn is the Rubinstein alternating protocol with time increments of 1/n between offers. As\nAbreu and Gul show, each gn induces a game with a unique equilibrium outcome, and these\nequilibria converge to the unique equilibrium outcome of the continuous-time limit game.\nThe continuous-time limit game is a war of attrition. Each player initially demands αi. At\nany time, each player can concede or not. Thus, rational player i's strategy is a probability\ndistribution over times t ∈[0, inf] at which to concede (given that j has not already conceded);\nt = infcorresponds to never conceding.\nIf player i concedes at time t, the payoffs are\n(1 -αj)e-rit for i and αje-rjt for j. With probability zi, player i is the irrational type who\nnever concedes. (If there is no concession, both players get payoff0.)\n\nNON-COOPERATIVE GAMES\nBargaining follows a Coasian dynamics once one of the players is revealed to be rational.\nThe Coase conjecture asserts that when the time between offers is sufficiently small, bar-\ngaining between a seller with known valuation v and a buyer who may have one of many\nreservation values, all greater than v, results in almost immediate agreement at the lowest\nbuyer valuation. Myerson's (1991) text (pp. 399-404) offers a different perspective on this\nresult by recasting it in a reputational setting. The low valuation buyer is replaced by an\nirrational type who demands some constant amount and accepts no less than this amount. In\nan alternating offer bargaining game, he shows that as the time between offers goes to zero,\nagreement is reached without delay at the constant share demanded by the irrational type.\nSimilarly, in the Coase conjecture there is immediate agreement at the lowest buyer valua-\ntion. Both results are independent of the ex ante probability of the low type and the players'\nrelative discount factors so long as they are both close to 1, as implied by the assumption\nthat offers are frequent. Thus, Myerson observes that the influence of asymmetric informa-\ntion overwhelms the effect of impatience in determining the division of surplus. Abreu and\nGul extend Myerson's result as follows.\nLemma 4. For any ε > 0, if n is sufficiently high, then after any history in gn where i has\nrevealed rationality and j has not, in equilibrium play of the continuation game, i obtains at\nmost 1 -αj + ε and j obtains at least αj -ε.\nProof. Consider the equilibrium continuation play starting from some history at which i has\nrevealed rationality and j has not as of time t. It is sufficient to show that player j's payoff\nif he continues to act irrationally converges to αj as n →inf. Let tˆ be any time increment\nsuch that, with positive probability (in this continuation), the game still has not ended at\ntime t + tˆ. We will first show that there is an upper bound on tˆ.\nLet π be the probability that j does not reveal rationality under the equilibrium strategies\nin the interval [t, t + tˆ). Then i's expected continuation payoffas of time t satisfies vi ≤\n1 -π + πe-r ˆ\nit. We also have vi ≥(1 -αj)zt\nj where zt\nj is the posterior that j is irrational as\nof time t, since i could get this much by immediately conceding. Then\n1 -π + πe-r ˆ\nit ≥(1 -α\nt\nj)zj ≥(1 -αj)zj.\nIt must be that π is bounded above by some π < 1 for large enough tˆ.\n\nMIHAI MANEA\nNow we apply the reasoning from Fudenberg and Levine (1989). Assume tˆis large enough\nthat j always has a chance to offer in any interval of length tˆ. Each time an interval of\nlength tˆ goes by without j conceding, the posterior probability that j is irrational increases\nby a factor of at least 1/π > 1. The number of such increases that can occur is bounded\nabove (by ln(zi)/ ln(π )). Thus there is an upper bound on the amount of time the game can\ncontinue, as claimed.\nThe argument above shows that for every n, if player j continues to behave irrationally,\nplayer i concedes in finite time t (n). This time depends on n since we chose tˆsuch that j has\nan opportunity to make an offer. We next show that t (n) converges to zero as n increases.\nConsider the last ε units of time before player i would concede with certainty if j sticks to\nhis demand. Without loss of generality, assume rj = 1 and ri = r. Since with probability at\nleast zj player j is irrational, with positive probability player i is using some strategy that\ndoes not end the game for at least ε longer. Fix β ∈(0, 1). The expected payofffrom such\nstrategy is at most\n(1 -ζ)x + ζy\nwhere\n- x is i's expected payoffif j agrees to an offer worse than αj by time βε;\n- y is i's payoffif j does not agree to such an offer by time βε;\n- ζ is the probability i assigns to the latter event.\nFor i to have incentives to wait out ε more time rather than accept the offer αj, it must\nbe that\n(31.1)\n1 -αj ≤(1 -ζ)x + ζy.\nIf j agrees to a payoffless than αj, then i will find out he is rational. But then j knows that\nif he holds out for ε longer, he will get αj and, hence, j's payoffis at least e-εαj. Therefore\nx ≤1 -e-εαj. Similarly, if j does not agree to an offer by βε, then the best that i can do\nafter that time is 1 -e-(1-β)εαj. So y ≤e-βrε(1 -e-(1-β)εαj). Note that y < 1 -αj reduces\nto\nε\nj <\n-e-βr\nα\n1 -e-(βr+1-β)ε.\n\nNON-COOPERATIVE GAMES\nIn the limit ε →0 the latter inequality becomes αj < βr/(βr + 1 -β), which is satisfied for\nβ > αj/(αj + r(1 -αj).\nPlugging our bounds into inequality (??) we get\n1 -αj ≤1 -e-εαj + ζ(e-βrε(1 -e-(1-β)εαj) -(1 -e-εαj)).\nNote that for small ε, we have e-βrε(1 -e-(1-β)εαj) < 1 -αj < 1 -e-εαj, and hence the\ncoefficient of ζ above is negative. Reorganizing the terms to get a bound for ζ and taking\nthe limit ε →0 we obtain that\nα\n(31.2)\nζ ≤\nj\nβ(αj + (1 -αj)r) + k(ε)\nwhere limε→0 k(ε) = 0.\nFix β ∈\n\nαj\n, 1\nand let ε > 0 be small enough so that the right-hand side of the\nαj+(1-αj)r\ninequality (??) is strictly\n\nless than some δ < 1 whenever ε < ε .\nSuppose we have a history at time t where i has revealed rationality, j has not, and the\nlatest possible end of the game (if j continues not conceding) is t + ε. If j does not reveal\nrationality by time t + βε, the posterior probability that j is irrational must increase by at\nleast a factor 1/δ > 1. If j does not reveal rationality by the time (1 -β)2ε before the end\nof the game, the posterior probability of irrationality must increase by another factor of 1/δ,\nand so forth. There can only be some number k of such increments before the posterior\nbelief exceeds 1. Note that our argument for i's incentives assumes that i is able to make\noffers sufficiently close to each of the cutoffs in the argument above.\nAs n →inf, because the offers in the games gn become increasingly frequent, the corre-\nsponding upper bounds on ε go to 0. Thus, once i has revealed rationality, the maximum\namount of time that it can take before the game ends if j continues to act irrationally goes\nto 0 as n →inf. This means that by acting irrationally, j can guarantee himself a payoff\narbitrarily close to αj for n sufficiently high.\n□\nThis leads (with a little further technical work) to the result that the continuous-game\nequilibrium is the limit of the discrete-game equilibria. When one agent is known to be\nrational and there is a positive probability that her opponent is irrational, delay is not\npossible. This means that either the player i known to be rational gives in to the irrational\ndemand of the other player j or player j also reveals himself to be rational. The latter\n\nMIHAI MANEA\noutcome occurs only when j receives a payoffno less than αj when he reveals himself to be\nrational. Otherwise, j prefers to pretend to be irrational and be conceded to by i without\ndelay.\nWith this conclusion in place, a war of attrition emerges: at any time t, player i can\ncontinue pretending to be irrational and wait for j to make the offer 1 -αj or some offer\nthat reveals j's rationality. In either situation, i obtains a payoffno less than 1 -αj since\nαi > 1 -αj by assumption and i obtains a payoffof at least αi once j reveals himself to\nbe rational. Thus, player i's equilibrium payoffbefore either player reveals rationality is at\nleast 1 -αj. Whenever j decides to reveal his rationality, i receives a payoffof at least αi,\nwhich means that in equilibrium i and j get exactly αi and 1 -αi, respectively. But this is\nprecisely the set-up of a war of attrition where i's winning payoffis αi and her losing payoff\nis 1 -αj.\nIt remains to analyze the continuous-time war of attrition. This is a well-known game,\nbut with the twist that there are irrational types. In equilibrium, let Fi denote the cdf of\ntimes when i concedes--unconditional on i's type; thus limt\nF\n→inf\ni(t) ≤1 -zi because the\nirrational player never concedes.\nWhat are the rational player i's payoffs from holding out until time t, then conceding?\nWe get\nui\nt = αi\nZ t-\ne-riy dFj(y) +\n(αi + 1\nα )(\nri\nj\nFj(t)\nF\nt\nj(t-)) + (1\nαj)(1\nFj(t))e-\n-\n-\n-\n-\n(these terms correspond to i winning, both players conceding at the same time, and j winning,\nrespectively). Assuming that F1 and F2 have a common support and are continuous, it\nmust be that each ui\nt is constant and differentiable over the support. Taking derivatives\nwith respect to t we obtain that dFj/(1 -Fj) = ri(1 -αj)/(α1 + α2 -1) := λj.\nThe\nconcession rate of player j makes the rational type of player i indifferent about conceding\nˆ\nˆ\neverywhere on his support.\nLet (F1, F2) be the unique strategy profile satisfying T 0 =\n{ -\n-\n}\nˆ\nmin (\nlog z1)/λ1, (\nlog z2)/λ2 , ci = zieλ\niT , and F (t) = 1 -c e-λit\ni\ni\n.\nThe next result\nproves that these functions characterize the unique equilibrium. The proof resembles the\nargument showing equilibrium uniqueness in the first-price auction.\nˆ\nˆ\nProposition 5. The unique sequential equilibrium is (F1, F2).\n\nNON-COOPERATIVE GAMES\nProof. Let σ = (F1, F2) define a sequential equilibrium. We will argue that σ must have the\nform specified (i.e., uniqueness) and that these strategies do indeed define an equilibrium\n(existence).\nLet ui\ns denote the expected utility of a rational player i who concedes at time s. Define\nAi ≡{t|ui\nt = maxs ui\ns}. Since σ is an equilibrium, Ai = ∅for i = 1, 2. Also, let τ i = inf{t ≥\n0|Fi(t) = limt′\nFi(t′)}, where inf\n→inf\n∅≡inf.\n(a) τ 1 = τ 2. A rational player will not delay conceding once she knows that her opponent\nwill never concede.\n(b) If Fi jumps at t ∈R, then Fj does not jump at t. If Fi had a jump at t, then player j\nreceives a strictly higher utility by conceding an instant after t than by conceding exactly\nat t.\n(c) If Fi is continuous at t, then uj\ns is continuous at s = t for j = i. This follows immediately\nfrom the definition of ui\ns.\n(d) There is no interval (t′, t′′) such that 0 ≤t′ < t′′ ≤τ 1 where both F1 and F2 are constant\non the interval (t′, t′′). Assume the contrary and without loss of generality, let t∗≤τ 1\nbe the supremum of t′′ for which (t′, t′′) satisfies the above properties. Fix t ∈(t′, t∗)\nand note that for ε small there exists δ > 0 such that ui\nt -δ ≥ui\ns for all s ∈(t∗-ε, t∗)\nfor i = 1, 2. By (b) and (c) there exists i such that ui\ns is continuous at s = t∗. Hence,\nfor some η > 0, ui\ns < ui\nt for all s ∈(t∗, t∗+ η) for this player i. Since Fi is optimal,\nwe conclude that Fi is constant on the interval (t′, t∗+ η). The optimality of Fj then\nimplies that Fj is constant on (t′, t∗+ η). Hence, both functions are constant on the\nlatter interval. This contradicts the definition of t∗.\nAs we noted above if Fi is constant on some interval (t′, t′′), then the optimality of Fj\nimplies that Fj is constant on (t′, t′′); consequently, (d) implies (e):\n(e) If t′ < t′′ < τ 1, then Fi(t′′) > Fi(t′) for i = 1, 2.\n(f) Fi is continuous at t > 0. Indeed, if Fi has a jump at t then Fj is constant on the interval\n(t -ε, t) for j = i. This contradicts (e).\nFrom (e) it follows that Ai is dense in [0, τ i] for i = 1, 2. From (c) and (f) it follows\nthat ui\ns is continuous on (0, τ 1] and hence ui\ns = constant for all s ∈(0, τ 1]. Consequently\n\nMIHAI MANEA\nAi = (0, τ 1]. Hence, ui\nt is differentiable as a function of t and dui\nt/dt = 0 ∀t ∈(0, τ 1). Now\nt\nui\nt =\nZ\nαie-rixdFj(x) + (1 -αj)e-rit(1\nx=0\n-Fj(t)).\nThe differentiability of Fj follows from the differentiability of ui\nt on (0, τ 1). Differentiating\nin the equation above leads to\n0 = αie-ritfj(t) -(1 -αj)r\nri\nie-rit(1 -Fj(t)) -(1 -α\nt\nj)e-\nfj(t)\nwhere fj(t) = dFj(t)/dt. This in turn implies Fj(t) = 1 -cje-λjt where cj is yet to be\ndetermined. At τ 1 = τ 2 optimality for player i implies that F\ni\ni(τ ) = 1-zi. If Fj(0) > 0 then\nFi(0) = 0 by (b), so ci = 1. Let T i solve 1-e-λit = 1-zi. Then τ 1 = τ 2 = T 0 ≡min{T 1, T 2}\nand c , c are determined by the requirement 1 -c e-λ\niT\nˆ\ni\nj\ni\n= 1 -zi. So Fi = Fi for i = 1, 2.\nˆ\nIf j's strategy is Fj, then ui\nt is constant on (0, τ 1] and ui\ns < ui\nT 0 ∀s > τ 1. Hence any mixed\nˆ\nˆ\nˆ\nstrategy on this support, and, in particular, Fi is optimal for player i. Hence (F1, F2) is\nindeed an equilibrium.\n□\nProperties of the equilibrium\n- At most one player concedes at time 0. If both conceded at time 0 with positive\nprobability, then either player would prefer to wait and concede later; the loss from\nwaiting is negligible while the gain from winning is discrete.\n- There is no interval of time in which neither player concedes, but such that concessions\ndo happen later with positive probability. There is also no interval during which\nonly one player concedes with positive probability. Neither player's concession time\ndistribution has a mass point on any positive time.\n- After 0, each player concedes with a constant hazard rate. Moreover, i has to concede\nat a rate that makes j indifferent to conceding everywhere on his support. Writing\ndown j's local indifference condition, we see that it uniquely determines i's instant\nhazard rate of concession: λi = rj(1 -αj)/(α1 + α2 -1).\n- Both players stop conceding at the same time, at which point they are both known\nto be irrational. This is because if player i continued to concede after j could no\nlonger concede, then player i would prefer to deviate by conceding earlier. So they\nstop conceding at the same time, and no agreement can occur after that time. If i\n\nNON-COOPERATIVE GAMES\nstill had positive probability of being rational at that point, then i would prefer to\ncontinue conceding rather than not reaching an agreement.\nThe constant-hazard-rate finding tells us that Fi must have the form Fi(t) = 1 -cie-λit\nfor some constant ci. The constants c1, c2 can be computed from the fact that both players\nbecome known to be irrational at the same time (F -1\n1 (1 -z1) = F2\n-1(1 -z2)) and that only\none player can concede with positive probability at time 0 (so either c1 or c2 is 1).\nIf player i concedes with positive probability at time 0, then the expected equilibrium\npayoffof the rational type of player i must be 1-αj. Moreover, j's indifference for conceding\nat any positive time implies that his ex ante expected payoffis Fi(0)αj + (1 -Fi(0))(1 -αi).\nNote that T i = -log zi/λi measures player i's weakness, since T i > T j means that player\ni concedes at time 0. A more patient player has a stronger bargaining position. Indeed, a\nlower ri implies a lower concession rate λj = ri(1 -αi)/(α1 + α2 -1) for player j. This, in\nturn, leads to an increase in Tj and the probability 1 -cj of j conceding at time 0. Hence, if\nplayer j concedes at time 0 (cj < 1), then a small decrease in ri increases the probability of\nj conceding immediately. If player i concedes at time 0 (ci < 1), then a small decrease in ri\nwould lead to a reduction in the probability with which i concedes. In either case, a decrease\nin ri makes player i better offand player j worse off. An increase in zi has the same effect.\nFinally, note that the equilibrium exhibits delay and hence inefficiency.\nConsider the\nsymmetric case r1 = r2, α1 = α2 = α, z1 = z2 = z. Then, in equilibrium, F1(0) = F2(0) = 0.\nThe expected payoffof a rational player 1 is 1 -α since conceding at zero is in the support\nof his optimal concession times. The payoffof an irrational player cannot exceed 1 -α since\nit is bounded above by the payoffof a rational player who concedes at time T 0. Thus the\nexpected payoffof either player is less than 1 -α and the total utility loss is in excess of\n2α -1, which may be substantial. The inefficiency is a consequence of delay to reaching\nagreement rather than not reaching agreement at all; the ex ante probability of disagreement\nis just z2.\nAbreu and Gul generalize the analysis to multiple irrational types. They show that ex-\nistence and uniqueness of the equilibrium in the continuous time game extend to the more\ngeneral model. In equilibrium players may mix between several irrational types and need\nnot choose the type with the most extreme demand. The multiple types need to be mim-\nicked with appropriate weights. The resulting posterior probabilities modulate the relative\n\nMIHAI MANEA\nstrengths of the types such that all types mimicked with positive probability obtain the same\nequilibrium payoff.\nThe \"strength\" of a player depends upon the posterior probability of the type she mimics,\nand the latter probability decreases with the probability with which that type is mimicked.\nThe payoffs to a type being conceded to with positive probability at time zero are strictly\nincreasing in \"strength.\" Multiple equilibrium distributions over types being conceded to are\nin conflict with the requirement that types mimicked with positive probability must have\nequal payoffs that are not smaller than the payoffs of types that are not mimicked.\nWhen the probability of irrational types is vanishingly small, one could think of the rep-\nutational bargaining model as a perturbation of (a more general version of) Rubinstein's\nbargaining model. Abreu and Gul show that the complete information model is robust to\nsuch perturbations if type spaces are sufficiently rich. More precisely, if for any division of\nsurplus there is an irrational type that makes a demand close to this division of surplus, then\nthe inefficiency (in terms of delay) disappears as the probability of irrational types vanishes.\nIn the limit, in both models, rational players choose to be virtually compatible and share\nsurplus in proportion to impatience, i.e., player i mimics types close to ri/(r1 + r2) with\nlimit probability 1. This result confirms an earlier finding by Kambe (1994) who consid-\ners the model in which players are initially unrestricted in their demands and could gain\ncommitment to the chosen posture later in the game.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Bayesian Games Slides Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/6c5872fe3409e4c0c10343b695347b4a_MIT14_126S16_bayesian.pdf",
      "content": "Bayesian Games\nMihai Manea\nMIT\nPartly based on lecture notes by Muhamet Yildiz.\n\nBayesian Games\nA Bayesian game is a list (N, A, Θ, T, u, p)\n▶N: set of players\n▶A = (Ai)i∈N: set of action profiles\n▶Θ: set of payoff parameters\n▶Ti: set of types for player i; T = Q\ni∈N Ti\n▶ui : Θ × A →R: payoff function of player i\n▶pi(·|ti) ∈∆(Θ × T-i): belief of type ti\nEach player i knows his own type ti but does not necessarily know θ or\nother players' types. . . belief pi(·|ti).\nThe game has a common prior if there exists π ∈∆(Θ × T) such that\npi(·|ti) = π(·|ti), ∀ti ∈Ti, ∀i ∈N.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n2 / 30\n\nInfinite Hierarchies of Beliefs\nWhen a researcher models incomplete information, there is often no\nex-ante stage or explicit information structure in which players observe\nsignals and make inferences. At the modeling stage, each player i has an\ninfinite hierarchy of beliefs\n▶a first-order belief\nτ ∈∆(Θ)\ni\nabout payoffs (and other aspects of the\nworld)\n▶a second-order belief\nτi ∈\n×\nN\n∆Θ\n∆(Θ) \\{i} about θ and other\nplayers' first-order beliefs τ-i\na\n\n▶\nthird-order belief τi about correlations in player i's second-order\nuncertainty\nτi and other players' second-order beliefs\nτ-i. . .\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n3 / 30\n\nFormal Definition\nFor simplicity, consider two players.\nSuppose that Θ is a Polish (complete separable metric) space.\nPlayer i has beliefs about θ, about other's beliefs about θ,. . .\nX0\n=\nΘ\nX1\n=\nX0 × ∆(X0)\n...\nXn\n=\nXn-1 × ∆(Xn-1)\n...\nτi = (τ , τ , . . .)\ni\ni\n∈\ninf\nn= ∆(\nXn): belief hierarchy of player i\nHi =\ninf\nQ\nQ\nn= ∆(\nXn): set of i's hierarchies of beliefs\nEvery Xn is Polish. Endow Xn with the weak topology.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n4 / 30\n\nInterpretation of Type Space\nHarsanyi's (1967) parsimonious formalization of incomplete information\nthrough a type space (Θ, T, p) naturally generates an infinite hierarchy of\nbeliefs for each ti ∈Ti, which is consistent by construction:\nfirst-order belief:\nh1(\ni ·|ti) = margΘp(·|ti) =\np(θ, t-i|ti)\nt-i\nsecond-order belief:\nh2\nhˆ1\nX\nθ,\n|ti\n\n=\nX\np(θ,\ni\nt\n-i\n-i|ti) . . .\nt\nh1\nt\nhˆ1\n-i|\n(\n-·| -i)=\ni\n-i\nA type ti\nn\n∈T in\ni\na space (Θ, T, p) models a belief hierarchy\n(τ , τ , . . .)\ni\ni\nif\nh (\ni ·|t\nn\ni) = τi for each n.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n5 / 30\n\nCoherency\nHow expressive is Harsanyi's language?\nIs there (T, p) s.t. {hi(·|ti)|ti ∈Ti} = Hi?\nHierarchies should be coherent:\nmarg\nn\nn 1\nX\nτ = τ\nn\n-.\n-2\ni\ni\nDifferent levels of beliefs should not contradict one another.\nH0\ni : set of i's coherent hierarchies.\nProposition 1 (Brandenburger and Dekel 1993)\nThere exists a homeomorphism fi : H0\ni →∆(Θ × H-i) s.t.\nmarg\nn\nXn-1 fi(·|τi) = τ ,\ni ∀n ≥1.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n6 / 30\n\nCommon Knowledge of Coherency\nIs there (T, p) s.t. {hi(·|ti)|ti ∈Ti} = H0\ni ?\nWe need to restrict attention to hierarchies of beliefs under which there is\ncommon knowledge of coherency:\nH1\n=\ni\n{\n▶\nτi ∈Hi |fi(H-i|τi) = 1}\n▶H2 =\ni\n{τi ∈H1\ni |f\ni(H-i|τi) = 1}\n▶. . .\n▶Hi\n∗= T\nk≥0 Hk\ni\nProposition 2 (Brandenburger and Dekel 1993)\nThere exists a homeomorphism gi : Hi\n∗→∆(Θ × H∗) s.t.\n-i\nmarg\nn\nX\n( τ ) = τ ,\n.\nn-1 gi ·| i\ni ∀n ≥1\nHi\n∗: universal type space\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n7 / 30\n\nThe Interim Game\nFor any Ba yesian game B = (N, A, Θ, T, u, p), define the interim game\nIG(B) = Nˆ, Sˆ, U\n\n,\nNˆ\n=\n∪i∈NTi\nSˆti\n=\nAi\nUˆti(sˆ)\n=\nEpi(·|ti) [ui (θ, sˆ)] ≡\nX\npi(θ, t i|ti)ui (θ, sˆti, sˆt i) , ∀t\n-\ni\nNˆ\n-\n∈\n,\n(θ,t-i)\nwhere sˆ = (sˆti)ti∈Nˆ.\nAssume finite Θ × T to avoid measurability issues.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n8 / 30\n\nTh Ex Ante Game\nFor a Bayesian game B = (N, A, Θ, T, u, π) with a common prior π, the\nex-ante game G(B) = (N, S, U) is given by\nSi = ATi\ni\n∋si : Ti →Ai\nUi (s) = Eπ[ui(θ, s(t))].\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n9 / 30\n\nBayesian Nash Equilibrium\nStrategies of player i in B are mappings si : Ti →Ai (measurable when Ti\nis uncountable).\nDefinition 1\nIn a Bayesian game B = (N, A, Θ, T, u, p), a strategy profile s : T →A is\na Bayesian Nash equilibrium (BNE) if it corresponds to a Nash equilibrium\nof IG(B), i.e., for every i ∈N, ti ∈Ti\nEpi( ti) [ui (θ, si (t\ns\n·|\ni) ,\nt\nE\nu\na s\nt\na\nA\n-i ( -i))] ≥\npi(·|ti) [ i (θ,\ni,\n-i ( -i))] , ∀i ∈\ni.\nInterim rather than ex ante definition preferred since in models with a\ncontinuum of types the ex ante game has many spurious equilibria that\ndiffer on probability zero sets of types.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n10 / 30\n\nConnections to the Complete Information Games\nWhen i plays a best-response type by type, he also optimizes ex-ante\npayoffs (for any probability distribution over Ti). Therefore, a BNE of B is\nalso a Nash equilibrium of the ex-ante game G (B).\nBNE(B): Bayesian Nash equilibria of B\nProposition 3\nFor any Bayesian game B with a common prior π,\nBNE (B) ⊆NE (G (B)) .\nIf π (ti) > 0 for all ti ∈Ti and i ∈N, then\nBNE (B) = NE (G (B)) .\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n11 / 30\n\nExistence of Bayesian Nash Equilibrium\nTheorem 1\nLet B = (N, A, Θ, T, u, p) be a Bayesian game in which\n▶Ai is a convex, compact subset of a Euclidean space\n▶ui : Θ × A →R is continuous and concave in ai\n▶Θ is a compact metric space\n▶T is finite.\nThen B has a BNE in pure strategies.\nConcavity is used instead of quasi-concavity to ensure (quasi-)concavity of\npayoffs in the interim game. . . integrals (sums) of quasi-concave functions\nare not always quasi-concave.\nUpper-hemicontinuity of BNE with respect to parameters, including the\nbeliefs p, can be established similarly to the complete information case.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n12 / 30\n\nEx-ante Rationalizability\nIn a Bayesian game B = (N, A, Θ, T, u, p), a strategy si : Ti →Ai is\nex-ante rationalizable if si is rationalizable in the ex-ante game G(B).\nAppropriate solution concept if the ex-ante stage is real. Imposes\nrestrictions on players' interim beliefs: all player i's types have the same\nbeliefs about other players' actions.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n13 / 30\n\nAn Example\nΘ\n=\nθ, θ′\nT1\n=\n{t1, t1\n′\n\n}, T2 = {t2}\np(θ, t1, t2)\n=\np(θ′, t1\n′, t2) = 1/2\nθ\nL\nR\nU\n1, ε\n-2, 0\nD\n0, 0\n0, 1\nθ′\nL\nR\nU\n-2, ε\n1, 0\nD\n0, 0\n0, 1\nG(B) :\nL\nR\nUU\n-1/2, ε\n-1/2, 0\nUD\n1/2, ε/2\n-1, 1/2\nDU\n-1, ε/2\n1/2, 1/2\nDD\n0, 0\n0, 1\nSinf(G(B)) = {(DU, R)}\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n14 / 30\n\nInterim Independent Rationalizability\nIn a Bayesian game B = (N, A, Θ, T, u, p), an action ai is interim\nindependent rationalizable for type ti if ai is rationalizable in the interim\ngame IG(B).\nImplicit assumption on the interim game: common knowledge that the\nbelief of a player i about (θ, t-i) is independent of his belief about other\nplayers' actions\n. His belief about (θ, t-i, a-i) is derived from pi(·|ti)\nT i\n× μti for\nsome μti ∈∆A\n-\ni\n. We take expectations with respect to p\n-\ni(·|ti) in\ndefining IG(B) before considering ti's beliefs about other players' actions.\nti believes that θ and aj are independent conditional on tj.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n15 / 30\n\nExample\nΘ\n=\nθ, θ′\nT1\n=\n{t1, t1\n′\n\n}; T2 = {t2}\np(θ, t1, t2)\n=\np(θ′, t1\n′, t2) = 1/2\nθ\nL\nR\nU\n1, ε\n-2, 0\nD\n0, 0\n0, 1\nθ′\nL\nR\nU\n-2, ε\n1, 0\nD\n0, 0\n0, 1\nIG(B) : Nˆ = {t1, t1\n′, t2}; t1 chooses rows, t2 columns, and t1\n′ matrices\nL\nR\nU\n:\nU\n1, ε, -2\n-2, 0, 1\nD\n0, ε/2, -2\n0, 1/2, 1\nL\nR\nD\n:\nU\n1, ε/2, 0\n-2, 1/2, 0\nD\n0, 0, 0\n0, 1, 0\nSinf\nt1 (IG(B)) = Sinf\nt′\n1 (IG(B)) = {U, D}; Sinf\nt2 (IG(B)) = {L, R}.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n16 / 30\n\nInterim Correlated Rationalizability\nDekel, Fudenberg, and Morris (2007) allow ti to have correlated beliefs\nregarding θ and atj.\nFor each i ∈N, ti ∈Ti, set S0[ i] =\ni t\nAi and define Sk[\ni ti] for k ≥1\nai ∈Sk[\ni ti] ⇐⇒ai ∈arg max\nui(θ, a ,\ni\n′ a i)dπ(θ, t i, a i)\nai\n′\nZ\n-\n-\n-\nfor some π ∈∆(Θ × T-i × A-i) such that\nmarg\np ·|t\nand\n\na\n∈Sk-1\nΘ\nπ =\n×T\ni)\nπ\n[\ni\ni(\ni\nt\n-\n-\n] = 1.\n-i\n-i\nThe set of interim correlated rationalizable (ICR) actions\n\nfor type ti is\ninf\nS\nk\n[ ] =\n[ ].\ni\ninfti\n\\\nSi ti\nk=0\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n17 / 30\n\nICR and Higher Order Beliefs\nProposition 4\nSk[ti] depends only on ti's k-order beliefs about θ\ni\n. ICR is invariant with\nrespect to belief hierarchies.\nSufficient to show that S1[ti] depends only on ti's marginal on θ\ni\n. . .\nIf ai ∈S1[\ni ti], there exists π ∈∆(Θ × T-i × A-i) with margΘ T π = p\n× -i\ni(·|ti) s.t.\nai\n∈\narg max\nZ\nui(θ, ai\n′, a\nai\n′\n-i)dπ(θ, t-i, a-i)\n=\narg max\nai\n′\nZ\nui(θ, ai\n′, a i)dπ∗(θ, a\n-\n-i)\n=\narg max\nZ\nui(θ, a′, σ-i(θ))\ni\ndπ∗∗(θ)\nai\n′\nwhere π∗and π∗∗are π's marginals on Θ × A i and Θ, resp. and\n-\nσ-i(θ)\nrepresents the\nai ∈arg maxa′\nRmarginal of π on A-i conditional on θ. Conversely, if\nui(θ, a′, σ i(θ))dπ∗∗(θ)\ni\nand π∗∗= margΘpi(·|ti). . .\ni\n-\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n18 / 30\n\nBNE, IIR and Higher Order Beliefs\nΘ = {θ, θ′} , N = {1, 2}. Actions and payoffs:\nθ\nL\nR\nU\n1, 0\n0, 0\nD\n.6, 0\n.6, 0\nθ′\nL\nR\nU\n0, 0\n1, 0\nD\n.6, 0\n.6, 0\nType space T = {t1, t1\n′} × {t2, t2\n′} with common prior\nθ\nt2\nt2\n′\nt1\n1/6\n1/12\nt′\n1/12\n1/6\nθ′\nt2\nt′\nt1\n1/12\n1/6\nt′\n1/6\n1/12\nEvery action can be played in a BNE, e.g.,\ns∗(t1)\n=\nU, s1\n∗t1\n′ = D\ns∗( )\n=\n2 t2\nL, s2\n∗\n\nt2\n′\n= R.\nSecond BNE with flipped actions. Each action is played by each type in a\nBNE, so all actions are interim independent rationalizable.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n19 / 30\n\nA Different Type Space\nTˆ =\nnˆt1,ˆt2\no\nwith common prior p\nθ\nL\nR\n\nθ,ˆt\n\n= p\n\nθ′,ˆt\n\n= 1/2; same payoffs:\nU\n1, 0\n0, 0\nD\n.6, 0\n.6, 0\nθ′\nL\nR\nU\n0, 0\n1, 0\nD\n.6, 0\n.6, 0\nThe only rationalizable action for player 1 in this game is D. In any BNE ˆt1\nmust play D.\nThe two games represent the same hierarchy of beliefs! Each type ti ∈Ti\nin the first game assigns probability 1/2 on θ.\nThe first type space induces correlation between θ and a2 (via the\ncorrelation between t2 and θ), second does not. ICR allows this sort of\ncorrelation by definition and does not eliminate any action in this example.\nBNE and IIR are sensitive to the specification of the strategic environment,\nICR depends only on belief hierarchies.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n20 / 30\n\nCoordination Game\n▶N = {1, 2}\n▶Θ = {2/5, -2/5}\nα\nβ\nα\nθ, θ\nθ -1, 0\nβ\n0, θ -1\n0, 0\n▶Complete information with θ = 2/5\n▶multiple equilibria\n▶(α, α) is Pareto-dominant\n▶An incomplete information game\n▶the two states equally likely, player 1 learns θ\n▶if θ = 2/5 player 1 sends an email, which is lost with probability 1/2\n▶players send \"confirmation of receipt\" message until a message is lost;\neach message is lost with probability 1/2\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n21 / 30\n\nRubinstein's E-mail Game\nα\nβ\nα\nθ, θ\nθ -1, 0\nβ\n0, θ -1\n0, 0\n▶T1 = {-1, 1, 3, 5, . . .}\n▶T2 = {0, 2, 4, . . .}\n▶ti total number of messages sent or received by player i\nBeliefs derived from common prior\np(θ = -2/5, t1 = -1, t2 = 0)\n=\n1/2\np\n2 5 t\n2m -1 t\n2m -2\n2m\n(θ =\n/ , 1 =\n, 2 =\n)\n=\n1/2\np(θ = 2/5, t1 = 2m -1, t2 = 2m\n=\n1/22m\n)\n+\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n22 / 30\n\nRationalizable Actions\nα\nβ\nα\nθ, θ\nθ -1, 0\nβ\n0, θ -1\n0, 0\nβ is uniquely rationalizable for every type, Si\ninf[t] = {β} for all t\n▶type t1 = -1 knows that θ = -2/5, so α is strictly dominated by β and\nS1\ninf[t1 = -1] = {β}\n▶if θ = 2/5, β is best-response if probability the opponent plays β is at\nleast 2/5\n▶p(θ = -2/5, t1 = -1|t2 = 0) = 2/3 > 2/5 ⇒Sinf[0] =\n{β}.\n▶If Si\ninf[t] = {β}, then p (t|t + 1) = 2/3 > 2/5, Sj\ninf[t + 1] = {β}.\nType t ≥0 knows that θ = 2/5, that the other player knows this, and so on,\nup to order t. For high t, beliefs about θ approach the common knowledge\ncase with θ = 2/5, where both actions are rationalizable.\nContagion: far away types lead to different behavior for similar types.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n23 / 30\n\nA Different Game\nΘ = {2/5, 6/5}\nα\nβ\nα\nθ, θ\nθ -1, 0\nβ\n0, θ -1\n0, 0\nBeliefs derived from common prior\np(θ\n=\n6/5, t1 = -1, t2 = 0) = 1/2\np(θ\n=\n2/5, t1 = 2m -1\nm\n, t\n2 = 2m -2) = 1/2\np(θ\n=\n2/5, t1 = 2m -1\n, t2 = 2m) = 1/2 m+1\nα is uniquely rationalizable for every type, Sinf[\ni\nt] = {α} for all t\n▶t1 = -1 knows that θ = -2/5, so α strictly dominates β and\nSinf[\nt1 = -1] = {α}.\n▶if θ = 2/5, α is best-response if opponent plays α with probability at\nleast 3/5\n▶type t ≥0 places probability 2/3 > 3/5 on t -1. . .\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n24 / 30\n\nA General Model\nFix\n▶N: finite set of players\n▶Θ∗: set of parameters (fundamentals)\n▶A = A1 × ... × An: finite action space\n▶ui : Θ∗× A →R payoff function of i ∈N, assumed continuous\nConsider all Bayesian games B = (N, Θ, T, A, u, p) where Θ ⊆Θ∗.\n▶hierarchy of beliefs\nh\n\ni (ti|B\n) = h (\ni\nti|B) , h (\ni\nti|B) , . . .\n▶through h, every type space can be embedded contin\n\nuously in the\nuniversal type space T∗.\n▶topology on T∗\nh\nm\nm\nk\nm\nm\nk\ni\n\nt |B\n\n→h (\ni\ni ti|B) ⇐⇒\nh\nhi\n\nt |B\n\n→h (\ni\ni\nti|B) , ∀k\ni\n,\nwhere the last convergence is in the weak topology.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n25 / 30\n\nUpper Hemicontinuity\nTheorem 1 (Dekel, Fudenberg, and Morris 2006)\nSinf[t] is upper-hemicontinuous in t.\nI.e., ∀\n\ntm,\ni\nBm\n, (ti, B) with hi\n\ntm\ni |Bm\n→hi (ti|B),\nh\na\nm\nm\ni ∈Sinfh\nt |B\ni\n, ∀large m\ni\n⇒ai ∈Sinf[ti|B] .\ni\ni\ni\nCorollary 1\nIf Si\ninf[ti|B] = {ai}, then\nhi\n\ntm\ni |Bm\n→hi (ti|B) ⇒Si\ninfh\ntm\ni |Bmi\n= {ai} for large m.\nA researcher who gathers information about higher order beliefs can\neventually confirm that the set of rationalizable actions with respect to his\nevidence is a subset of ICR for the actual type. Not true for other solution\nconcepts.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n26 / 30\n\nStructure Theorem\nTheorem 2 (Weinstein and Yildiz 2007)\nAssume that Θ∗is rich, so that each action is strictly dominant at some θ.\nThen for any ai ∈Si\ninf[ti], there exists tm\ni\n→ti such that\nSi\ninfh\ntm\ni\ni\n= {ai} , ∀m.\nProof relies on an extension of the contagion argument.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n27 / 30\n\nComments\n▶In a game of complete information, every rationalizable strategy is\nsensitive to common-knowledge assumptions whenever there are\nmultiple rationalizable strategies.\n▶ICR does not have a proper refinement that is upper-hemicontinuous\nwith respect to belief hierarchies.\n▶ICR provides the only robust prediction with respect to higher order\nbeliefs. It characterizes the predictions that may be verified by a\nresearcher who can observe arbitrarily precise noisy signals about\narbitrarily high but finite orders of beliefs.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n28 / 30\n\nAn Epistemic Model\n▶Fix a finite Bayesian game B = (N, A, Θ, u, T, p) .\n▶Information structure (Ω, I, π)\n▶Ω: finite set of states\n▶I = (I1, . . . , In): profile of information partitions of Ω\n▶Ii (ω): information set of i that contains ω\n▶π = (πi,ω)i N,ω Ω: profile of beliefs π\n∈\ni\n∈∆(I\n∈\n,ω\ni (ω)) .\n▶Ii (ω) = Ii (ω′) ⇒πi,ω = πi,ω′\n▶Epistemic model for B: (Ω, I, π, θ, t, a)\n▶θ : Ω→Θ\n▶t : Ω\n▶\n→T\na : Ω→A\n▶ti and ai are constant over information sets of i\n▶πi,ω *(θ, t-i)-= pi (·|ti (ω)) for all ω, i\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n29 / 30\n\nCommon Knowledge of Rationality = ICR\nDefinitions 2\nRationality is common knowledge in (Ω, I, π, θ, t, a) ⇐⇒\nai (ω) ∈Bi\n\nπi,ω *\na\n(θ,\n-i)-\n, ∀i ∈N, ω ∈Ω.\nai is consistent with common knowledge of rationality for ti ⇐⇒there\nexists (Ω, I, π, θ, t, a) and ω ∈Ωs.t.\n▶ti (ω) = ti; ai (ω) = ai;\n▶rationality is common knowledge in (Ω, I, π, θ, t, a)\nTheorem 3 (Dekel, Fudenberg, and Morris 2007)\na∗\ni is consistent with common knowledge of rationality for t∗\ni iff a∗\ni ∈Sinf\ni\nh\nt∗\ni\ni\n.\nMihai Manea (MIT)\nBayesian Games\nJune 27, 2016\n30 / 30\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Cooperative Games Lecture Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/25c82e8213fd23daa72c9382e921a2b0_MIT14_126S16_cooperative.pdf",
      "content": "COOPERATIVE GAMES\nMIHAI MANEA\n1. Definitions\nA coalitional (or cooperative) game is a model of interacting decision-makers that focuses\non the behavior of groups of players.\nN denotes the set of players. A coalition is a group of players S ⊂N. We refer to N as\nthe grand coalition. Every coalition S has a set of available actions AS.\nAn outcome consists of a partition of N (coalition structure) and one action associated\nwith each coalition in the partition,\n(Sk, ak)\n\nk=1,...,k with Sj ∩Sk = ∅, ∀j = k, ∪kSk = N, ak ∈ASk.\nEach agent i has preferences over the set of all outcomes represented by a utility function\nui. We restrict attention to settings without externalities. Agent i cares only about the\naction of the coalition he belongs to, i.e., ∃Ui : ∪S A\nR s.t.\n∋i\nS →\nui((Sk, ak)\n\nk=1,...,k) = Ui(aj) if i ∈Sj.\nExample 1 (Three-player majority game). Three agents have access to a unit of output.\nAny majority--coalition of two or three agents--may control the allocation of the output.\nThe output may be shared among the members of the winning coalition any way they wish.\nNo agent can produce any output by himself. Each agent only cares about the amount of\noutput he receives (prefers more to less). Actions for each coalition? Feasible outcomes?\nExample 2 (Firm and workers). Consider a firm and n potential workers. The firm generates\nprofit f(k) from hiring k workers, where f is some exogenously given function. Any coalition\nconsisting only of workers produces profit 0. Each agent only cares about his own share of\nthe profit. Actions for each coalition? Feasible outcomes?\nDate: January 19, 2017.\nI thank Gabriel Carroll for proofreading.\nDepartment of Economics, MIT\n\nMIHAI MANEA\nExample 3 (Marriage market). A group of men and a group of women can be matched\nin pairs. A matching of a coalition of men and women is a partition of the coalition into\nman-woman pairs and single individuals. Each person cares only about her partner (and\nhow she/he compares to being single). Actions for each coalition? Feasible outcomes?\nDefinition 1. A game is cohesive if for every outcome (Sk, ak)\n\nk=1,...,k there exists an outcome\ngenerated by the grand coalition which is at least as desirable as (Sk, ak)\n\nk=1,...,k for every\nplayer.\nThe solution concepts we consider assume that the grand coalition forms (rather than\noutcomes involving a non-trivial coalition structure) and have attractive interpretations only\nfor cohesive games.\nDefinition 2. A game with transferable payoffs associates to any coalition S a real number\nv(S), which is interpreted as the worth of the coalition S. We assume v(∅) = 0. The set of\nactions available to coalition S consists of all possible divisions (xi)i\nof v(S) among the\n∈S\nmembers of S,\ni S xi = v(S).\n∈\nWhen is a game\nP\nwith transferable payoffs cohesive?\nWhich of the games above have\ntransferable payoffs? What are the corresponding worth functions?\n2. The Core\nWhich action may we expect the grand coalition to choose? We seek actions that withstand\nthe pressures imposed by the opportunities of each coalition. We define an action of the\ngrand coalition to be \"stable\" if no coalition can break away and choose an action that all\nits members prefer. Formally, a coalition S blocks an action aN of the grad coalition if there\nis an action aS ∈AS that all members of S strictly prefer to aN. The set of all actions that\ncannot be blocked forms the core.\nDefinition 3. The core of a coalitional game is the set of actions aN of the grand coalition\nN that are not blocked by any coalition.\nIf a coalition S has an action that all its members prefer to an action aN of the grand\ncoalition, we say that S blocks aN.\n\nCOOPERATIVE GAMES\nFor a game with transferable payoffs with payofffunction v, a coalition S can block the\nallocation (xi)i N iffxS < v(S), where xS = P\ni S xi. Hence the allocation x is in the core\n∈\n∈\nof the game iffxS ≥v(S), ∀S ⊂N.\nExample 4 (Two-player split the dollar with outside options). v({1}) = p, v({2}) =\nq, v({1, 2}) = 1. The core is given by the set of allocations\n{(x1, x2)|x1 + x2 = 1, x1 ≥p, x2 ≥q}.\nWhat happens for p = q = 0? What if p + q > 1?\nArgue that the core of the three-player majority game is empty.\nWhen is the core non-empty? A vector (λS)S∈2N of non-negative numbers is a balanced\ncollection of weights if\nλS = 1, i\n{S⊂N|i\n∀\n∈S\n∈N.\n}\nA payofffunction v is balanced if\nX\nS\nX\nλSv(S) ≤v(N) for every balanced collection of weights λ.\n⊂N\nInterpretation: each player has a unit of time, which he needs to distribute among all his\ncoalitions.\nFor coalition S to be active for λS time and generate payoffλSv(S), all its\nmembers need to be active in S for this fraction of time λS. A game is balanced if there is no\nallocation of time across coalitions that yields a total value greater than that of the grand\ncoalition.\nTheorem 1 (Bondareva 1963; Shapley 1967). A coalitional game with transferable payoffs\nhas a non-empty core iffit is balanced.\nProof. Consider the linear program\nmin\nX\nxi s.t.\ni∈N\nX\nxi\n)\ni S\n≥v(S , ∀S ⊂N.\n∈\nThe core is non-empty iffthe minimized sum is not greater than v(N).1 The dual of the\nlatter linear program is given by\nmax\nX\nλSv(S) s.t. λS\n⊂\n.\nS\nN\n≥0, ∀S\nN &\nX\nλS\n∈\nS∋i\n≤1, ∀i ∈N\n1Actually, the optimal value needs to be exactly v(N) in this case.\n\nMIHAI MANEA\nBy definition, the game is balanced iffthe optimal value for the dual does not exceed v(N).2\nNote that the primal linear program has an optimal solution. Then the conclusion follows\nfrom the duality theorem of linear programming, which implies that both problems have\nsolutions and the optimal values of the two objective functions are identical.\n[Easy proof of \"only if\" part. Let x be a core allocation and suppose that (λS)S∈2N is a\nbalanced collection of weights. Then\nX\nλSv(S) ≤\nλSxS =\nxi\nλS =\nxi = v(N).\n{S|S⊂N}\n{S\nX\n|S⊂N}\nX\ni∈N\nX\nS∋i\nX\ni∈N\nHence v is balanced.]\n□\nWe next introduce a simpler condition, convexity, which guarantees a non-empty core.\nDefinition 4. A game with transferable payoffs v is convex 3 if for any two coalitions S and\nT,\nv(S ∪T) + v(S ∩T) ≥v(S) + v(T).\nThe game v is superadditive if for any disjoint coalitions S and T,\nv(S ∪T) ≥v(S) + v(T).\nThe game v is monotone if for any coalitions S ⊂T,\nv(S) ≤v(T).\nNote that convexity implies superadditivity. If v is nonnegative, then superadditivity im-\nplies monotonicity. Also, you can check that superadditivity implies cohesiveness. Convexity\nowes its name to the following implication\n(2.1)\nS ⊂T & i ∈/ T =⇒v(T ∪{i}) -v(T) ≥v(S ∪{i}) -v(S),\nwhich says that the marginal contribution of an individual i to a coalition is (weakly) in-\ncreasing as the coalition gets larger. To see this, consider the coalitions S ∪{i} and T.\nIndeed, by convexity,\nv((S ∪{i}) ∪T) + v((S ∪{i}) ∩T) ≥v(S ∪{i}) + v(T).\n2See footnote 1.\n3Convexity is sometimes referred to as as super-modularity.\n\nCOOPERATIVE GAMES\nwhich can be rewritten as\nv(T ∪{i}) -v(T) ≥v(S ∪{i}) -v(S).\nProposition 1. Any convex game with transferable payoffs has a non-empty core.\nProof. We show that the allocation x, with xi = v({1, . . . , i}) -v({1, . . . , i -1}), belongs to\nthe core. For all i1 < i2 < · · · < ik,\nX\nk\nk\nxij\n=\nX\nv({1, . . . , ij -1, ij\n=1\nj=1\n}) -v({1, . . . , ij\nj\n-1})\nk\n≥\nX\nv( i1, . . . , ij-1, ij )\nv( i1, . . . , ij-1 )\nj=1\n{\n} -\n{\n}\n=\nv({i1, i2, . . . , ik}),\nwhere the inequality follows from {i1, . . . , ij\n1} ⊂{1, . . . , i\n-\nj -} and 2.1.\n□\nIt is easy to construct examples which illustrate that convexity is not a necessary condition\nfor the non-emptiness of the core (balancedness is).\n3. Core Implementation (Perry and Reny 1994)\nWe restrict attention to games with transferable payoffs.\nAn allocation which is not\nin the core is regarded as unstable. For every such allocation, some players can form a\ncoalition and obtain an allocation that each strictly prefers.\nAlmost sounds like a non-\ncooperative game!\nBut what's the dynamics/timing of forming and breaking coalitions?\nWhat sort of agreements are feasible/binding and what offers and counteroffers are allowed\nfollowing a history of outstanding proposals and binding agreements? Perry and Reny (1994)\nprovide a dynamic game in continuous time that implements (all and only) core allocations\nin equilibrium. The game is designed to match the ideas behind the definition of the core.\nThe game starts at t = 0, at which time one player can choose to make a proposal or be\nquiet. At any t > 0, a player can choose to make a proposal, accept the currently active\nproposal, be quiet, or leave. A proposal, (x, S), suggests a coalition S and an allocation of\nv(S) or less among the players in S (such proposals can be made by all players, including\nones outside S). A proposal (x, S) remains active until either it is accepted by all players\n\nMIHAI MANEA\nin S, in which case it becomes binding, or another proposal is made, in which case the new\nproposal becomes active and the old one disappears.\nAt any time there can thus be only one active proposal, but there can also be a number of\nbinding proposals that have been previously accepted. Whenever a binding proposal (x, S)\nexists, any new proposal's coalition has to be either disjoint from S or else fully include\nit. If the latter happens, then if the new proposal is accepted, the original proposal (x, S)\ndisappears. Thus, at all times, the coalitions associated with currently binding proposals are\nmutually disjoint.\nOnce a player accepts a proposal, he must remain quiet until it is binding or a new proposal\ndisplaces it. After a proposal becomes binding, each player involved can leave and consume\nor wait for better proposals. If one involved player decides to leave, all other players in the\ncoalition have to leave too.\nEach player's payoffis the amount allocated to him by the proposal that applies to him\nwhen he leaves. There is no discounting.\nA technical assumption on strategies is necessary. For every t and every history up to t,\nplayers are not allowed to choose to make a \"non-quiet\" decision either \"just before\" or \"right\nafter\" t. Technically, for any history up to time t, there is an ε > 0 such that each player is\nquiet in the intervals (t -ε, t) and (t, t + ε). First, this ensures that given any history up to\ntime t, the strategies induce a unique continuation path (and well-defined payoffs). Second,\nif we want to obtain only core outcomes in equilibrium, it is important that no player want\nto take a \"non-quiet\" action as near as possible, yet before or after, any time t. If a player\nhad that option then there would not be any way for another player to convince him to stick\naround with an appropriately timed blocking proposal.\nThe equilibrium concept is stationary subgame perfect equilibrium (SSPE), that is, an\nSPE in stationary strategies. A strategy is stationary if the player's action depends only on\nthe set of players who have not yet left, the currently active proposal with the set of players\nwho accepted it, and the currently binding proposals.\nTheorem 2. Every SSPE outcome belongs to the core.\nProof. Suppose that x is an SSPE outcome that does not belong to the core. There exists a\nproposal (y, S) such that yi > xi, ∀i ∈S. WLOG, assume S = {1, . . . , k}.\n\nCOOPERATIVE GAMES\nConsider a time t history where nothing has happened except that (y, S) was proposed and\n1, 2, . . . , k -1 accepted. After this history, player k accepts before anything else happens.\nSuppose not, let (z, T) be the next proposal. It must be that in equilibrium k gets at least\nyk > xk in the continuation game. By stationarity, it must be that in any subgame when only\n(z, T) is on the table (and there has been no acceptance), k obtains more than xk. Then\nk can deviate from the putative equilibrium by proposing (z, T) close to time 0, thereby\nobtaining more than xk, a contradiction with the equilibrium requirements.\nWe prove by induction on l that after any history where nothing happened except that\n1, 2, . . . , k -l accepted (y, S), player k -l + 1 accepts. We showed that the base case is true.\nIf k -l + 1 accepts, then by the induction hypothesis everyone accepts and k -l + 1 obtains\nyk\nl+1. If he does not accept, it must be that he can do even better and can obtain strictly\n-\nmore than yk\nl+1 making a proposal close to time 0.\n-\nThe induction hypothesis for l = k -1 implies that if 1 offers (y, S) close to time 0 and\naccepts it before any other action is taken, then he obtains a payoffy1 > x1. This contradicts\nx being an SSPE outcome.\n□\nThe result above also holds for subgames in which a subset of the players left and con-\nsumed. An outcome for the remaining players must be in the core of the cooperative game\nthey induce. One consequence of the result is that a necessary condition for an SSPE to\nexist is that the game be totally balanced, i.e., its restriction to any coalition is balanced (or\nany subgame has a non-empty core).\nTheorem 3. If the game is totally balanced, then any element of its core can be supported\nas an SSPE outcome.\nThe construction of an SSPE implementing any core point is involved, particularly offthe\nequilibrium path.\n4. The Core and Competitive Equilibria\nConsider an exchange economy with a set of consumers N and a set of goods G.\nA\nconsumption bundle is an element x ∈RG\n+. Consumer i enjoys utility ui(xi) from a bundle\nx\nG\ni. Each consumer starts with an endowment ωi ∈R+.\n\nMIHAI MANEA\nAn allocation {xi}i N, with xi ∈RG\n+, is feasible if\n∈\ni∈N xi =\ni∈N ωi, where ωi is consumer\ni's initial endowment of goods.\nP\nP\nSuppose that consumers interact in a market. A price is determined for every good and\nthe consumers take these prices as given. The price-taking assumption is reasonable for\nmarkets with many participants and a high degree of competition among them.\nDefinition 5 (Competitive Equilibrium). A competitive equilibrium is a price vector (p∗\ng)g∈G\nand a feasible allocation x∗= (x∗\ni )i∈N such that\np∗· xi ≤p∗· ωi =⇒ui(x∗\ni ) ≥ui(xi),\ni.e. x∗\ni maximizes consumer i's utility among all the consumption bundles that he can afford\ngiven the prices and his initial endowment.\n4.1. Aside on Existence. Does a competitive equilibrium exist? Yes it does, if one imposes\nsome regularity conditions on the utility functions. The standard proof involves Kakutani's\nfixed point theorem, which you are already familiar with. However, equilibrium existence is\nnot our focus here.\n4.2. Competitive Equilibria and Cooperative Games. We can view the market as a\ncooperative game. The actions available for any coalition of players S ⊆N is the set of all\ndistributions of their total endowment P\ni∈S ωi among themselves,\nAS =\n(\n(xi)i∈S |\nX\nxi =\ni∈S\nX\nωi\ni∈S\n)\n.\nOf course, the payoffof consumer j ∈S corresponding for the action (xi)i∈S is given by\nuj(xj). Note that for most utility functions the resulting game does not have transferable\nutility.\nExample 5. Let G =\n√\n{g}, N = {1, 2}, ω1 = ω2 = 1, and ui(xi) =\nxi. Then the set of\nfeasible payoffs (utilities) for the coalition {1, 2} is given by\n{(u1, u2) | u2\n1 + u2\n2 = 2; u1, u2 ≥0}.\n\nCOOPERATIVE GAMES\nExample 6. Consider a 2-consumer, 2-good economy. We can use the Edgeworth box to\nillustrate allocations, competitive equilibria, and the core. See pp. 515-525 in Mas-Colell,\nWhinston, and Green (posted).\nWe know how to define the core for any cooperative game, including the one derived\nhere. When can a coalition S block a feasible allocation x∗? It must be that the members\nof S can redistribute their total endowment\ni\nthemselv\n∈S ωi amongst\nes so as to make\neach of them better off. Formally, there exists\nP\nan allocation (xi)i∈S that is feasible for S\n(P\ni S xi = P\ni S ωi), which every agent prefers to x∗(ui(xi) > ui(x∗\n∈\n∈\ni ), ∀i ∈S).\nTheorem 4. Any competitive equilibrium is in the core.\nProof. Let x∗be a competitive equilibrium allocation corresponding to a price vector p.\nSuppose that a coalition S can block x∗. Then there exists (xi)i∈S such that P\ni∈S xi =\nP\ni∈S ωi and\nui(xi) > ui(x∗\ni ) ∀i ∈S\nBy definition of equilibrium the latter inequality implies that no i ∈S can afford xi, so\np · xi > p · ωi ∀i ∈S\nAdding up these conditions we obtain\np ·\nX\nxi > p\ni∈S\n·\nX\nωi\ni∈S\nwhich contradicts\ni∈S xi =\ni∈S ωi.\n□\nThe converse of\nP\nthis theorem\nP\nis not true. That is, not every point in the core is a compet-\nitive equilibrium allocation. For instance, one can see an example in the Edgeworth box in\nwhich the competitive equilibrium is unique but the core has a continuum of elements.\nHowever, it is true that as we increase the market by replicating every consumer a large\nnumber of times the non-equilibrium allocations gradually drop from the core, until in the\nlimit only equilibria survive. We will not prove this result.\n\nMIHAI MANEA\n4.3. Aside on Equilibrium Tatonnement. Even in environments where an equilibrium\nexists, the market may start at a price level which is not an equilibrium. What sort of price\ndynamics should we expect then?\nThere are some intuitive dynamic principles--if the demand for a good is larger than the\nsupply, then one may expect the price of that good to increase.\nThere are, however, many possible disequilibium dynamics that one can consider, and it\nis hard to argue that one is better than all others.\nI will provide an example just to illustrate the ideas. Let z(p) be the excess demand\nfunction at p. That is, we assume that the utility function ui is such that for any non-zero\nprice vector p and initial endowment ωi, player i has a unique optimal demand xi(p), where\nxi(p) = arg max\nui(xi)\nxi·p≤ωi·p\nThe excess demand function for good g is then given by\nzg(p) =\nX\n(xig(p) -ωig)\ni∈N\nWe say that good g is in excess demand (supply) if zg(p) > 0 (< 0).\nNote that p∗is an equilibrium price vector if and only if z(p∗) = 0. Suppose we start from\na disequilibrium price vector p. One price dynamic that adjusts prices upwards for goods in\nexcess demand and downwards for goods in excess supply is given by the following process\ndpg = cgzg(p)\ndt\nwhere dpg is the rate of change of the price of good g, and cg > 0 is a constant that determines\ndt\nthe speed of convergence. This process is guaranteed to converge to an equilibrium if several\nrestrictions are imposed on the utility functions. The paper we discuss next applies the idea\nof tatonnement in the context of the core.\n5. Core Tatonnement\nSee slides.\n\nCOOPERATIVE GAMES\n6. The Nash Bargaining Solution\nWe revisit the bargaining problem.4 The non-cooperative approach involves explicitly mod-\neling the bargaining process as an extensive form game. The Rubinstein (1982) alternating\noffer bargaining model discussed earlier constitutes a prominent example. We next adopt the\naxiomatic approach, which abstracts away from the details of the bargaining process. The\nlatter approach attempts to determine directly what \"reasonable\" or \"natural\" properties\nthe outcomes should satisfy. Nash (1950) provided a seminal contribution in this direction.\nThe immediate question is: What are \"reasonable\" axioms? Consider a situation where\ntwo players must split $1. If no agreement is reached, then the players receive nothing. If\nthe preferences over monetary prizes are identical, then we might expect that each player\nobtains 50 cents. This example reflects two desirable properties of an allocation: efficiency\nand symmetry of the outcome for identical preferences.\nA bargaining problem is a pair (U, d) where U ⊂R2 and d ∈U. We assume that U is\nconvex and compact and that there exists some u ∈U such that u > d. We denote the set\nof all possible bargaining problems by B. A bargaining solution is a function f : B →R2\nwith f(U, d) ∈U.\nDefinition 6. The Nash (1950) bargaining solution f N is defined by\n(6.1)\n{f N(U, d)} = arg max (u1 -d1)(u2 -d2).\nu∈U,u≥d\nGiven the assumptions on (U, d), the solution to the optimization problem above exists\nand is unique.\nWe will show that the Nash bargaining solution is the unique solution that satisfies the\nfollowing axioms.\nAxiom 1 (Pareto Efficiency). A bargaining solution f is Pareto efficient if for any bargaining\nproblem (U, d), there does not exist (u1, u2) ∈U such that u1 ≥f1(U, d) and u2 ≥f2(U, d),\nwith at least one strict inequality.\nThe motivation for this axiom is straightforward--an inefficient outcome is unlikely be-\ncause it leaves space for renegotiation.\n4This section builds on lecture notes by Asu Ozdaglar.\n\nMIHAI MANEA\nAxiom 2 (Symmetry). A bargaining solution f is symmetric if for any symmetric bargaining\nproblem (U, d) ((u1, u2) ∈U if and only if (u2, u1) ∈U and d1 = d2), we have f1(U, d) =\nf2(U, d).\nThe intuition for this axioms is that if players are indistinguishable, the agreement should\nnot discriminate between them.\nAxiom 3 (Invariance to Linear Transformations). A bargaining solution f is invariant if\nfor any bargaining problem (U, d) and all αi ∈(0, inf), βi ∈R (i = 1, 2), if we consider the\nbargaining problem (U ′, d′) with\nU ′\n=\n{(α1u1 + β1, α2u2 + β2) | (u1, u2) ∈U}\nd′\n=\n(α1d1 + β1, α2d2 + β2)\nthen fi(U ′, d′) = αifi(U, d) + βi for i = 1, 2.\nThe motivation for this axiom is that the feasible payoffs are derived from an underlying\noutcome space where agents have expected utility over lotteries. Linear transformations of\nthe utility functions lead to equivalent preferences over lotteries, and the bargaining outcome\nshould not be sensitive to the preference representation. The axiom effectively amounts to\na normalization of the bargaining problem.\nAxiom 4 (Independence of Irrelevant Alternatives). A bargaining solution f is independent\nif for any two bargaining problems (U, d) and (U ′, d) with U ′ ⊆U and f(U, d) ∈U ′, we have\nf(U ′, d) = f(U, d).\nTheorem 5. f N is the unique bargaining solution that satisfies the four axioms.\nProof. We first check that the Nash bargaining solution satisfies the axioms. We then show\nthat if a bargaining solution satisfies the axioms, then it must be identical to f N.\n(1) Pareto efficiency: This follows immediately from the fact that the objective function\nin 6.1 is increasing in u1 and u2.\n(2) Symmetry: Assume that (U, d) is a symmetric bargaining problem. Then\n(f N\n2 (U, d), f N\n1 (U, d)) ∈U also solves the optimization problem 6.1. By the uniqueness\nof the optimal solution, we must have f N\n1 (U, d) = f N\n2 (U, d).\n\nCOOPERATIVE GAMES\n(3) Independence of irrelevant alternatives: Suppose that f N(U, d) ∈U ′ ⊆U.\nThe\nvalue of the objective function in 6.1 for (U ′, d) cannot exceed that for (U, d). Since\nf N(U, d) ∈U ′, the two values must be equal, and by the uniqueness of the optimal\nsolution for 6.1, we have f N(U, d) = f N(U ′, d).\n(4) Invariance to linear transformations: Suppose that (U, d) and (U ′, d′) are related as\nin the statement of the axiom. By definition, f N(U ′, d′) is an optimal solution of the\nproblem\nmax\n(u1\n′ -α1d1 -β1)(u2\n′\nα2d2\nβ2)\n{(u′ ,u′ )|u′ =α1u1+β1,u′ =α2u2+β2,(u\nU\n1,u2)∈\n}\n-\n-\nIt follows immediately that f N\ni (U ′, d′) = αif N\ni (U, d) + βi for i = 1, 2.\nWe next show that f N is the only bargaining solution that satisfies the axioms. We show\nthat for any f with this property, f(U, d) = f N(U, d) for all (U, d).\nFix a bargaining problem (U, d) and let z = f N(U, d). There exists αi > 0, βi such that\nthe transformation ui →αiui + βi takes di to 0 and zi to 1/2. Define\nU ′ = {(α1u1 + β1, α2u2 + β2)|(u1, u2) ∈U}.\nSince both f and f N satisfy the invariance to linear transformations axiom, we have f(U, d) =\nf N(U, d) if and only if f(U ′, 0) = f N(U ′, 0) = (1/2, 1/2). Hence, to establish the desired\nclaim, it is sufficient to prove that f(U ′, 0) = (1/2, 1/2).\nNote that the line {(u1, u2)|u1 +u2 = 1} is tangent to the hyperbola {(u1, u2)|u1u2 = 1/4}\nat the point (1/2, 1/2). Given that f N(U ′, 0) = (1/2, 1/2), we can argue that u1 +u2 ≤1 for\nall u ∈U ′. Assume there is a u ∈U ′ with u1 + u2 > 1. Let t = (1 -λ)(1/2, 1/2) + λ(u1, u2)\nfor some λ ∈(0, 1). Since U ′ is convex, we have t ∈U ′. We can choose λ sufficiently small\nso that t1t2 > 1/4, a contradiction with the optimality of f N(U ′, 0) = (1/2, 1/2) in 6.1 for\nthe bargaining problem (U ′, 0).\nSince U ′ is bounded, we can find a rectangle U ′′ with one side along the line u1 + u2 = 1,\nsymmetric with respect to the line u1 = u2, such that U ′ ⊆U ′′ and (1/2, 1/2) is on the\nboundary of U ′′.\nSince f is efficient and symmetric, it must be that f(U ′′, 0) = (1/2, 1/2). We assumed\nthat f also satisfies the independence of irrelevant alternatives axiom. Then f(U ′′, 0) =\n(1/2, 1/2) ∈U ′ ⊆U ′′ leads to f(U ′, 0) = (1/2, 1/2), which completes the proof.\n□\n\nMIHAI MANEA\n7. Literature Discussion\n- Nash (1953) demand game; Abreu and Pearce's (2015) endogenous threats in a dy-\nnamic setting\n- Nash bargaining solution used as reduced form for equilibrium analysis in the macro\nand search literature (Diamond-Mortensen-Pissarides, Shimer-Smith)\n- the Kalai-Smorodinsky (1975) solution\n- axiomatic approach in matching theory\n8. The Shapley Value\nThe core of a coalitional game may be empty or quite large, which compromises its role as\na predictive theory in certain situations. Ideally, we would like to develop a theory selecting\na unique outcome for every cooperative game. A value for cooperative games is a function\nfrom the space of games to outcomes. Note that we allow the player set to vary and we\nimplicitly expect some \"consistency\" in the outcomes of \"related\" games. Here we restrict\nattention to games with transferable utility and assume that the set of feasible outcomes for\na game (N, v) consists of all divisions of v(N) among the players in N.\nShapley (1953) proposed a solution that has many properties that are economically desir-\nable and mathematically elegant.\nDefinition 7 (Shapley value). The Shapley value of a game with worth function v is given\nby\nφi(v) =\nX\n|S|!(|N| -|S| -1)!\nS⊂N\\{i}\n(v(S\n)\nN|!\n∪{i} -v(S)).\n|\nFor an interpretation, suppose that all players are randomly ordered in a line, all orders\nbeing equally likely. Then φi(v) represents the expected value of player i's contribution to\nthe coalition formed by the players preceding him in line. The values across players sum to\nv(N) because they do for every realization of the ordering.\nNote that, by the proof of Proposition 1, for convex games, the Shapley value is a convex\ncombination of core allocations. Since the core is a convex set, the Shapley value of a convex\ngame belongs to its core.\nWhat is special about the Shapley value? The following axioms describe some simple prop-\nerties one might want a value to have, and it will turn out that they completely characterize\n\nCOOPERATIVE GAMES\nthe Shapley value. Before stating the axioms, we need to introduce some new definitions.\nPlayer i is a dummy in v if v(S ∪{i}) = v(S) for all S. Players i and j are interchangeable\nin v if v(S ∪{i}) = v(S ∪{j}) for all S disjoint from {i, j}.\nAxiom 5 (Symmetry). If i and j are interchangeable in v then φi(v) = φj(v).\nAxiom 6 (Dummy Player). If i is a dummy in v then φi(v) = 0.\nAxiom 7 (Additivity). For any two games v and w, we have φ(v + w) = φ(v) + φ(w).\nThe first two axioms are quite straightforward. The additivity axiom is mathematically\nconvenient, but difficult to motivate.\nThe structure of v + w may induce behavior that\ndoes not arise when v or w are considered separately.5 If we rescale additivity to require\nthat φ(pv + (1 -p)w) = pφ(v) + (1 -p)φ(w), we can obtain an interpretation in terms of\nbargaining over uncertain outcomes and independence of the bargaining process from the\ntiming of resolution of uncertainty.\nTheorem 6. A value satisfies the three axioms above iffit is the Shapley value.\nProof. The \"if\" part is easy to check. The only step that is not immediate is showing that\nφ satisfies the symmetry axiom. For that, suppose that i and j are interchangeable. Then\nX\n|S|!(|N| -|S| -1)!\nφi(v)\n=\nS⊂N\\{i}\n(v(S\n|N|!\n∪{i}) -v(S))\n=\nS⊂\nX\n|S|!(|N| -|S| -1)!\nN\\{i,j}\n(v(S\ni\nN|!\n∪{ }) -v(S))\n|\n+\nX\n(|S| + 1)!(|N| -(|S| + 1) -1)!\nS⊂N\\{i,j}\n(v(S ∪{i, j}) -v(S ∪{j}))\n|N|!\n=\nS⊂\nX\n|S|!(|N| -|S| -1)!\nN\\{i,j}\n(v(S\nj\nN|!\n∪{ }) -v(S))\n|\nX\n(|S +\n+\n|\n1)!(|N| -(|S| + 1) -1)!\nS⊂N\\{i,j}\n(v(S\n|N|!\n∪{i, j}) -v(S ∪{i}))\n=\nφj(v).\n5This criticism is similar to that of the independence of irrelevant alternatives axiom for the Nash bargaining\nsolution.\n\nMIHAI MANEA\nWe next prove the \"only if\" part. Suppose that ψ is a value satisfying the three axioms.\nWe need to argue that ψ = φ.\nFor any non-empty coalition T, define the payofffunction vT with vT(S) = 1(0) if S ⊃T\n(S ⊃T). Such games are sometimes referred to as carrier games. Fix a ∈R. Note that\nby the symmetry axiom, ψi(avT) = ψj(avT) for all i, j ∈T. By the dummy player axiom,\nψi(avT) = 0 for all i ∈/ T. Hence ψi(avT) = a/|T|(0) for i ∈T (i ∈/ T), so ψ(avT) = φ(avT).\nWe show that the (2|N|-1) payofffunctions vT span the linear space of all payofffunctions.\nIf we view payofffunctions as (2|N| -1)-dimensional vectors, it is sufficient to show that the\nvectors corresponding to the (2|N|-1) functions are linearly independent. For a contradiction,\nsuppose that P\nT\nN αTvT = 0 with not all α's equal to zero. Let S be a set (one of the sets)\n⊂\nwith minimal cardinality satisfying αS = 0. Then P\nT\nN αTvT(S) = αS =\n0, a contradiction.\n⊂\nThus for any v there exist α's s.t. v = P\nαT\nT\nT⊂N\nv . The additivity of ψ and φ immediately\nimply that\nψ(v) = ψ\nX\nαTvT\n!\n=\nX\nψ(αTvT) =\nX\nφ(αTvT) = φ\n(v\n⊂N\nT⊂N\nT⊂\n\nαTvT\n= φ\n).\nT\nN\nT\nX\n⊂N\n!\n□\nAn alternative characterization of the Shapley value can be obtained in terms of the\nfollowing equity requirement--for any pair of players, the amounts that each player gains or\nloses from the other's withdrawal from the game are equal. The new characterization relates\nthe outcomes of games with different sets of players. For a coaltional game with transferable\npayoffs (N, v), we denote by v|M its restriction to the players in M.\nDefinition 8 (Balanced contributions). A value ψ has balanced contributions if for every\ncoaltional game with transferable payoffs (N, v) we have\nψi(v|N) -ψi(v|N \\ {j}) = ψj(v|N) -ψj(v|N \\ {i}), ∀i, j ∈N.\nNote that for N = {i, j} the condition above becomes\nψi(v) -v({i}) = ψj(v) -v({j}),\nwhich along with the constraint ψi(v)+ψj(v) = v({i, j}) leads to the Nash bargaining solution\nfor the game with bargaining set U = {(xi, xj)|xi + xj = v({i, j})} and disagreement payoffs\n\nCOOPERATIVE GAMES\ngiven by d = (v({i}), v({j})). Hence, for 2-player games, the Shapley value coincides with\nthe Nash bargaining solution of the underlying bargaining problem. The next result shows\nthat we can view the Shapley value as an extension of the Nash bargaining solution to\nmulti-player games.\nTheorem 7. The unique value that has balanced contributions is the Shapley value.\nProof. First, one can easily show that at most one value has balanced contributions. For a\ncontradiction, let φ′ and φ′′ be two different such values. Let (N, v) be a game with minimal\n|N| for which the two values yield different outcomes. Then for all i, j ∈N, φ′\ni(v|N \\ {j}) =\nφ′′\ni (v|N \\ {j}) and φ′\nj(v|N \\ {i}) = φ′′\nj(v|N \\ {i}), along with the balancedness of φ′ and φ′′,\nimply φ′\ni(v|N) -φ′′\ni (v|N) = φ′\nj(v|N) -φ′′\nj(v|N). Since\ni N(φ′\ni(v\ne\n∈\n|N) -φ′′\ni (v|N)) = 0, w\nimmediately obtain φ′\ni(v|N) -φ′′\ni (v|N) = 0, ∀i ∈N, or φ\nP\n′(v|N) = φ′′(v|N), a contradiction.\nWe next argue that the Shapley value has balanced contributions. The Shapley value φ is a\nlinear function of the game, so the set of games for which φ satisfies balanced contributions\nis closed under taking linear combinations.\nSince any game can be written as a linear\ncombination of \"carrier\" games (from the proof of the previous result), it is sufficient to show\nthat carrier games satisfy balanced contributions. The latter assertion is checked without\ndifficulty.\n□\n9. Values for Network Cooperation Structures\nUnder the Shapley value, the payoffof every player depends on the values of all coali-\ntions.\nThere are some situations where such symmetric treatment of coalitions may be\nunrealistic. There may be some exogenous factors--e.g., location, social relationships, trade\nagreements--that make some coalitions intrinsically more important/potent/feasible than\nothers. In such situations only a subset of coalitions can actually form and influence the\noutcome.\nMyerson (1977) looks at cooperation structures defined by networks. Fix N. A network\nG (with vertex set N) consists of a set of unordered pairs of players, which we call links; we\nuse the notation ij ∈G to represent the fact that i and j are linked in G. It is assumed\nthat only coalitions that are internally connected can negotiate effectively. A coalition is\n\nMIHAI MANEA\n(internally) connected if any two players in S are connected by a path of links in G among\nplayers in S.\nFor each coalition S, let S|G denote the partition of S into sets of players that are connected\nby G within S,\nS|G = {{i|i and j are connected by G within S}|j ∈S}.\nHence a coalition S is internally connected if S|G = {S}.\nConsider a worth function v. How does the outcome of the game generated by v depend\non the network G? An allocation rule ψ specifies an allocation ψi(G) for each i ∈N for all\nnetworks G, with the property that\n(9.1)\nX\nψi(G) = v(S),\ni∈S\n∀S ∈N|G, ∀G,\nThis condition asserts that if S is a connected component of G then the members of S ought\nto share the total wealth v(S) available to them.\nWe say that an allocation rule ψ is fair if\n(9.2)\nψi(G) -ψi(G ⊖ij) = ψj(G) -ψj(G ⊖ij), ∀ij ∈G, ∀G.\n(Here G ⊖ij is the network remaining when ij is removed from G.) Fairness requires that\nany two linked players benefit equally from their bilateral relationship.\nWe need one further definition to state the main result. What is the effective worth of a\ncoalition S that is internally disconnected in G? We denote by v|G the worth function given\nby\n(v|G)(S) =\nT\nX\nv(T),\n∈S|G\n∀S ⊂N.\nThis game can be interpreted as the result of altering the situation described by v to take\ninto account the communication constraints entailed by G.\nTheorem 8 (Myerson 1977). For any worth function v, there is a unique fair allocation\nrule. The unique fair allocation rule is defined by\nψ(G) = φ(v|G), ∀G,\nwhere φ is the Shapley value.\n\nCOOPERATIVE GAMES\nProof. We can establish that there is at most one fair allocation rule by an argument similar\nto that of the previous proof. The minimal counterexample involves a network with the\nsmallest number of links rather than vertices.\nWe are only left to show that the Myerson value is a fair allocation rule. First, we need\nto prove it is an allocation rule, that is, 9.1 holds. Note that\nT|G = ∪S∈N|G(T ∩S)|G,\nhence\nv|G =\nX\nuS,\nS∈N|G\nwhere uS is defined by\nuS(T) =\nR∈(\nX\nv(R), T\nN.\nT∩S)|G\n∀\n⊂\nAll players outside S are dummies for uS, so\nX\nφi(uS)\n=\nuS(N) = v(S)\nX\ni∈S\nφ\nS\ni(u )\n=\n0,\ni∈T\n∀T ∈N|G, T = S\nbecause φ satisfies the dummy player axiom. By the additivity of φ, we have\nφ(v|G) =\nS\nX\nφ(uS).\n∈N|G\nTherefore, for any T ∈N|G,\nX\nφi(v\ni∈T\n|G) =\nS\nX\n∈N|G\nX\nφi(uS) = uT(N) = v(T).\ni∈T\nSecond, we need to prove that the Myerson value is fair, that is, it satisfies 9.2. Define\nthe game w = v|G -v|(G ⊖ij).\nNote that i and j are interchangeable in w.\nIndeed,\nw(S ∪{i}) = w(S ∪{j}) = 0 for all S that do not contain i and j.\nSince φ satisfies\nthe symmetry axiom, it must be that φi(w) = φj(w). By the linearity of φ, we obtain\nφi(v|G) -φi(v|(G ⊖ij)) = φj(v|G) -φj(v|(G ⊖ij)).\n□\nAs homework, you will be asked to show stability (no player has incentives to drop links)\nfor superadditive games and will look at an example.\n\nMIHAI MANEA\n10. Non-Cooperative Implementation of the Shapley Value\nGul (1989) introduces a dynamic model of bargaining that, under a certain set of assump-\ntions, implements the Shapley value (in the limit, as players become patient or offers can be\nmade frequently). Consider a game with transferable utility (N, v). Assume that v is strictly\nsuperadditive,\nL ∩M = ∅⇒v(L) + v(M) < v(L ∪M) for all L, M ⊂N.\nWe interpret v as follows. Each player owns a resource, and various combinations of these\nresources produce payoffs according to the function v. When pooled together, the resources\nof a coalition M produce a payoffflow with discounted present value of v(M) (corresponding\nto a constant utility flow of (1-δ)v(M) per period). At any point in time an player controls\na bundle of resources he bought offother players (who sold everything and left the market),\nwhich he may choose to sell to another player who is still active in the market.\nIn every period t = 0, 1, . . . two active players are randomly (with equal probability)\nmatched.\nOne of the two matched players is randomly (with equal probability) chosen\nto make an offer for the entire bundle of the other player.\nIf the offer is accepted, the\nresponder leaves the market (becomes inactive) and the proposer inherits his bundle. The\ngame proceeds without change to the next period in case of rejection. The game is over\nwhen only one active player is left. Players have a common discount factor δ. The utility of\nplayer i is given by\ninf\nU i =\nX\n[(1 -δ)v(M i\nt)\nt=0\n-ri\nt]δt,\nwhere M i\nt denotes the coalition of players whose resources i holds at time t and ri\nt is the\npayment i makes at t.\nThe equilibrium notion is stationary subgame perfect equilibrium\n(SSPE). At any point in time each player's behavior depends only on the distribution of\nresources in the market and the current offer.\nA state q = (M1, M2, . . . , Mk) refers to the situation in which, after various rounds of\ntrading, there are k players left in the game and each player (who is still in the game) i owns\nresources Mk(i) ⊂\n\nN. Q is the set of all possible states (partitions of N). N ∈Q denotes\n\nthe finest partition of N, that is, N = ({1}, . . . , {n}). For all L, M ∈q, let R(q, L, M) ∈Q\n\nCOOPERATIVE GAMES\ndenote the partition obtained from q by replacing the elements L and M by L ∪M. That\nis, R(q, L, M) = (q\\{L, M}) ∪{L ∪M}.\nFix q = (M1, M2, . . . , Mk). Define the generalized Shapley value for the partition q as\nfollows\ns!(k\ns\n1)!\nS(Mm, q) =\n-\n{i1,i2,...,is}⊆{\nX\n-\n1,2,...,k}\\{m}\n(v(Mi\nk!\n1 ∪Mi2 ∪. . . Mis ∪Mm)\n-v(Mi1 ∪Mi2 ∪. . . ∪Mis)).\n\nObserve that S(i, N) is the Shapley value of i ∈N in the game (N, v). In general S(M, q) is\nthe Shapley value of the player who owns the resource bundle M in a game in which initial\nendowments are distributed according to q.\nTheorem 9. The payoffs of any family of equilibria in which every match leads to trade\nconverges to the Shapley value as δ →1.\nThe proof of the theorem follows from the following two lemmas.\nLemma 1. Assume that, after various rounds of trade, the economy has reached a situa-\ntion in which only two players remain. The continuation game is a two-player bargaining\ngame with randomly selected proposer. If at this stage q = (M, N\\M), then the expected\ncontinuation payoffs of the two remaining players are\nv(N)\nN\nU(M, q)\n-v(\n\\M) + v(M)\n=\n= S(M, q)\nv(N) -v(M) + v(N\\M)\nU(N\\M, q) =\n= S(N\n\\M, q)\nProof. Refer to the \"representative\" of M as player 1 and to that of N\\M as player 2. By\nstationarity, player 1 (2) always makes the same offer a (b) to 2 (1). Under the assumption\nthat the equilibrium leads to immediate agreement, we obtain the following equations for\nequilibrium payoffs\nu1 =\nb\n(v(N)\n-a) +\n.\na\nu2 =\n+\n(v(N)\n-b).\n\nMIHAI MANEA\nIf player 2 refuses the offer, then he enjoys the payoffflow (1-δ)v(N\\M) and continuation\npayoffδu2. In equilibrium, player 1 makes the offer that makes 2 exactly indifferent between\naccepting and rejecting,\na = (1 -δ)v(N\\M) + δu2.\nSimilarly,\nb = (1 -δ)v(M) + δu1.\nSubstituting the values of a and b in the formulae for u1 and u2, we find\nv(N)\nv(N M) + v(M)\nu1\n=\n-\n\\\nv(N)\nu2\n=\n-v(M) + v(N\\M).\n□\nLemma 2. Suppose that for any i, j ∈N, equilibrium payoffs in a game in which players i\n\nand j traded satisfy limδ\n1 U(M, R(N, i, j)) = S(M, R(N, i, j)) for all M ∈R(N, i, j). Then\n→\n\nlimδ\n1 U(i, N) = S(i, N).\n→\n\nProof. Taking into account all possible matches in the first period of the game, U(i, N) is\ngiven by the following expectation\n\nU(i, N) =\nn(n -1)\n\" X\nj=i\n\nU\nh\n(1 -δ)v({i}) + δ\n(i, N)+\n(1 -δ)v({\n\ni, j}) + δU(ij, R(N, i, j)) -(1 -δ)v(j) -δU(j, N)\ni\n+\nX\n(1 -\n\nδ)v({i\n{j,k}⊂N\\{i\n}) + δU(i, R(N, j, k))\n}\n\n#\nThe first term captures offers accepted from other players j, the second the gains from trade\nwhen i is the proposer, and the third term continuation payoffs when other pairs trade.\n\nThen (U(i, N))i N is the solution of a linear system of equations with coefficients that\n∈\nare linear functions of δ. Using Cramer's rule, each payoffcan be expressed as a fraction of\npolynomials in δ. One can easily show that if |N| ≥3 then the system in non-singular, and\n\nCOOPERATIVE GAMES\nhence the solution converges as δ →1 to the solution of the limit system,\n\nU(i, N) =\n\nX\n\n)\nj)) -\n\n[U(i, N + U(ij, R(N, i,\nU(j, N)] + 2\nU(i, R(N, j, k))\n.\nn(n -1)\nj=i\n{j,k}⊂N\\{i}\n\nX\n\nWe have to show that U(ij, R(N, i, j)) = S(ij, R(N, i, j)) for all i = j ∈N, then U(i, N) =\n\nS(i, N), which is equivalent to showing that the Shapley value satisfies\n\nS(i, N) =\n\nX\n\n[S(i, N) + S(ij, R(N, i, j))\nS(j, N)] + 2\nS(i, R(N, j, k))\n.\nn(n -1)\nj=\n\ni\n-\n{j,k}⊂\nX\nN\\{i}\n\nIn order to prove this last equation, we can again use carrier games and the linearity of the\n\nShapley value. A clean argument, showing that the desired formula leads to an alternative\ncharacterization of the Shapley value, can be found in Haviv (1995). The Shapley value\nsatisfies a consistency property with respect to amalgamations of pairs of players.\n□\nLemma 2 states that if after one transaction occurs, the equilibrium is such that for δ close\nto 1 it yields an expected payoffequal to his Shapley value for every remaining player (relative\nto a new distribution of resources), then for δ close enough 1 the equilibrium will yield each\nplayer expected payoffequal to his Shapley value in the original game before any transaction\ntakes place. But this is equivalent to saying that, if the equilibrium yields expected payoffs\naccording to the Shapley values in all n -1 player games, then the equilibrium will yield\npayoffs according to the Shapley value in all n player games.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Equilibrium Refinement Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/43872460b5a6668f0e0706ec6061ce65_MIT14_126S16_equilib.pdf",
      "content": "Equilibrium Refinements\nMihai Manea\nMIT\n\nSequential Equilibrium\n▶In multi-stage games where payoffs depend on initial moves by\nnature, the only subgame is the original game. . . subgame perfect\nequilibrium = Nash equilibrium\n▶Play starting at an information set can be analyzed as a separate\nsubgame if we specify players' beliefs about at which node they are.\n▶Based on the beliefs, we can test whether continuation strategies\nform a Nash equilibrium.\n▶Sequential equilibrium (Kreps and Wilson 1982): way to derive\nplausible beliefs at every information set.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n2 / 45\n\nAn Example with Incomplete Information\nSpence's (1974) job market signaling game\n▶The worker knows her ability (productivity) and chooses a level of\neducation.\n▶Education is more costly for low ability types.\n▶Firm observes the worker's education, but not her ability.\n▶The firm decides what wage to offer her.\nIn the spirit of subgame perfection, the optimal wage should depend on\nthe firm's beliefs about the worker's ability given the observed education.\nAn equilibrium needs to specify contingent actions and beliefs.\nBeliefs should follow Bayes' rule on the equilibrium path.\nWhat about off-path beliefs?\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n3 / 45\n\nAn Example with Imperfect Information\nFigure: (L, A) is a subgame perfect equilibrium. Is it plausible that 2 plays A?\nMihai Manea (MIT)\nEquilibrium Refinements\nCourtesy of The MIT Press. Used with permission.\nMarch 30, 2016\n4 / 45\n\nAssessments and Sequential Rationality\nFocus on extensive-form games of perfect recall with finitely many nodes.\nAn assessment is a pair (σ, μ)\n▶σ: (behavior) strategy profile\n▶μ = (μ(h) ∈∆(h))h∈H: system of beliefs\nui(σ|h, μ(h)): i's payoff when play begins at a node in h randomly selected\naccording to μ(h), and subsequent play specified by σ.\nThe assessment (σ, μ) is sequentially rational if\nui(h)(σi(h), σ-i(h)|h, μ(h)) ≥ui(h)(σ′\n, σ\ni(h)\ni(h)|h, μ(h\n-\n))\nfor all information sets h and alternative strategies σ′.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n5 / 45\n\nConsistency\nBeliefs need to be consistent with strategies.\nσ is totally mixed if supp(σ i(h)(h)) = A(h), i.e., all information sets are\nreached with positive probability.\nBayes' rule →unique system of beliefs μσ for any totally mixed σ .\nThe assessment (σ, μ) is consistent if there exists a sequence of totally\nmixed strategy profiles\nm\nm\n(σ )m≥0 →σ s.t. (μσ )m≥0 →μ.\nDefinition 1\nA sequential equilibrium is an assessment that is sequentially rational and\nconsistent.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n6 / 45\n\nImplications of Sequential Rationality\nFigure: No belief rationalizes A. 2 plays B, 1 optimally chooses R.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n7 / 45\nCourtesy of The MIT Press. Used with permission.\n\nImplications of Consistency\nFigure: By consistency, μ(y|h2) = μ(x|h1), even though D is never played.\nConsistency →common beliefs after deviations from equilibrium behavior.\nWhy should different players have the same theory about something not\nsupposed to happen?\nConsistency matches the spirit of equilibrium analysis, which assumes\nplayers hold identical beliefs about others' strategies.\nMihai Manea (MIT)\nEquilibrium Refinements\nCourtesy of The MIT Press. Used with permission.\nMarch 30, 2016\n8 / 45\n\nExistence of Sequential Equilibrium\nTheorem 1\nA sequential equilibrium exists for every finite extensive-form game.\nFollows from existence of perfect equilibria, prove later.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n9 / 45\n\nContinuity\nProposition 1\nThe sequential equilibrium correspondence has a closed graph with\nrespect to payoffs.\n▶(uk)k 0 →u: convergent sequence of payoff functions\n≥\nk\nk\n▶(σ , μ ): sequential equilibrium for uk\nIf\nk\nk\n▶\n(σ , μ )k≥0 →(σ, μ), is (σ, μ) a sequential equilibrium for u?\n▶(σ, μ) is sequentially rational because the expected payoffs\nconditional on reaching any information set are continuous in payoff\nfunctions and beliefs.\n▶Let\nm\n(σ\n,k\nm\n, μ\n,k\nk\nk\n)m\nbe a convergent sequence of\n≥0 →(σ , μ )\ncompletely mixed strategy profiles and corresponding induced beliefs.\nm\n▶Find mk s.t. σ\nk,k and\nm\nμ\nk,k are within 1/k from corresponding\ncomponents of\nk\nσ and\nk\nμ .\nk\nk\n▶(σ , μ )k 0 →\nm\n) ⇒\nm k\n(σ, μ\n(σ\nk, , μ\nk,k) →(σ, μ), so\nis\n≥\n(σ, μ)\nconsistent.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n10 / 45\n\nSequential Equilibrium Multiplicity\nTheorem 2\nFor generic payoff functions, the set of sequential equilibrium outcome\ndistributions is finite.\nSet of sequential equilibrium assesments often infinite\n▶Infinitely many belief specifications at off-path information sets\nsupporting some equilibrium strategies.\n▶Set of sequential equilibrium strategies may also be infinite. Off-path\ninformation sets may allow for consistent beliefs that make players\nindifferent between actions. . . many mixed strategies compatible with\nsequential rationality.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n11 / 45\n\nExample\nSequential equilibrium outcomes: (L, l) and A\nUnique equilibrium leading to (L, l)\nTwo families of equilibria with outcome A. . . 2 must choose r with positive\nprobability\n2 chooses r with probability 1 and believes μ(x) ∈[0, 1/2]\n2 chooses r with probability in [2/5, 1] and believes μ(x) = 1/2\nMihai Manea (MIT)\nEquilibrium Refinements\nCourtesy of The MIT Press. Used with permission.\nMarch 30, 2016\n12 / 45\n\nKohlberg and Mertens' (1986) Critique\n\"Strategically neutral\" changes in game tree affect equilibria.\nGame a: (A, L2) possible in a sequential equilibrium\nGame b: ((NA, R1), R2) unique sequential equilibrium strategies. In\nsubgame following NA, R1 strictly dominates L1. Then 2 chooses R2, and\n1 best responds with (NA, R1).\nMihai Manea (MIT)\nEquilibrium Refinements\nCourtesy of The MIT Press. Used with permission.\nMarch 30, 2016\n13 / 45\n\nResponse\nSensitivity of sequential equilibrium to \"irrelevant moves\" is not a\nconsequence of consistency, but of sequential rationality. . . problem\npresent even for subgame perfect equilibria.\nKohlberg and Mertens' solution: stable equilibria\n▶Theory of robustness with respect to any profile of small mistakes,\nsolution depending only on the strategic form\n▶If players make mistakes at every information set, are the two\nextensive forms equivalent?\n▶Game a: 1 might play either L1 or R1 by mistake intending to choose A.\n▶Game b: if 1 makes the mistake of not playing A, he is still able to\nensure that R1 is more likely than L1. . . why would first mistake be\ncorrelated with the second?\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n14 / 45\n\nPerfect Bayesian Equilibrium\nPerfect Bayesian equilibrium (PBE): original solution concept for\nextensive-form games with imperfect/incomplete information.\nSequential equilibrium now preferred, but worthwhile to know about PBE\n(used in early/applied research).\nPBE similar to sequential equilibrium with fewer restrictions on beliefs\n▶Strategies: sequentially rational\n▶Beliefs: derived from Bayes' rule wherever applicable\n▶Simplest version: no constraints on off-path beliefs\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n15 / 45\n\nOther Restrictions on Off-Path Beliefs\nFudenberg and Tirole (1991): other restrictions on beliefs in multi-stage\ngames with incomplete information (all implied by consistency)\n▶If player types are drawn independently by nature, beliefs about\ndifferent players should remain independent after every history.\n▶Updating should be \"consistent\": given a probability-zero history ht at\nwhich strategies call for a positive probability transition to ht+1, beliefs\nat ht+1 should be given by updating beliefs at ht using Bayes' rule.\n▶\"Not signaling what you don't know\": with independent types, beliefs\nabout player i's type at the beginning of period t + 1 depend only on\nht and i's action at t, not on other players' actions at t.\n▶Players i , j should have the same belief about a third player k even\nafter probability zero histories.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n16 / 45\n\nPerfect Equilibrium\nL\nR\nU\n1,1\n0,0\nD\n0,0\n0,0\nSelten (1975): (trembling-hand) perfect equilibrium\n▶Both (U, L) and (D, R) are Nash equilibria.\n▶(D, R) not robust to small mistakes: if 1 thinks that 2 might make a\nmistake and play L with positive probability, deviate to U.\nDefinition 2\nIn a strategic-form game, a profile σ is a perfect equilibrium if there is a\nsequence of trembles\nm\n(σ )m 0 →σ, where each\nm\n≥\nσ\nis a totally mixed\nstrategy, such that σi is a best reply to\nm\nσ-i for each m and all i ∈N.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n17 / 45\n\nExistence of Perfect Equilibria\nDefinition 3\nσε is an ε-perfect equilibrium if ∃ε(si) ∈(0, ε], ∀i ∈N, si ∈Si s.t. σε is a\nNash equilibrium of the game where players are restricted to play mixed\nstrategies in which every pure strategy si has probability at least ε(si).\nProposition 2\nA strategy profile is a perfect equilibrium iff it is the limit of a sequence of\nε-perfect equilibria as ε →0.\nTheorem 3\nEvery finite strategic-form game has a perfect equilibrium.\nProof.\nA 1/n-perfect equilibrium exists by the general Nash equilibrium existence\ntheorem. By compactness, the sequence of 1/n-perfect equilibria has a\nconvergent subsequence as n →inf. The limit is a perfect equilibrium.\n□\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n18 / 45\n\nPerfection in Strategic Form ⇒Subgame-Perfection\nUnique SPE: (L1L1\n′, L2)\n(R1, R2) is perfect in strategic form, sustained by trembles s.t. after\ntrembling to L1, player 1 chooses R1\n′ vs. L1\n′ with probability ratio ≥1/5.\nCorrelation in trembles at different information sets. . . unreasonable.\nMihai Manea (MIT)\nEquilibrium Refinements\nCourtesy of The MIT Press. Used with permission.\nMarch 30, 2016\n19 / 45\n\nPerfection in Extensive-Form Games\nSolution: agent-normal form\n▶A different player for every information set h.\n▶\"Player\" h has the same payoffs as i(h).\nDefinition 4\nA perfect equilibrium for an extensive-form game is a perfect equilibrium of\nits agent-normal form.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n20 / 45\n\nConnection to Sequential Equilibrium\nTheorem 4\nEvery perfect equilibrium of a finite extensive-form game is a sequential\nequilibrium (for some appropriately chosen beliefs).\n: perfect equilibrium of the extensive-form game ⇒∃\nm\n▶σ\n(σ )m≥0 →σ\ntotally mixed strategies in the agent-normal form s.t. σh is a best reply\nto\nm\nσ-h for each m and all information sets h.\n▶By compactness,\nm\n(μσ )m≥0 has a convergent subsequence, denote\nlimit by μ.\n▶By construction, (σ, μ) is consistent.\n▶σh is a best response to\nm\nμσ (h) and\nm\nσ-h for each m.\n▶By continuity, σh is a best response to μ(h) and σ-h.\n▶One-shot deviation principle: (σ, μ) is sequentially rational.\n□\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n21 / 45\n\nProperties of Perfect Equilibrium\nKreps and Wilson (1982): every sequential equilibrium is perfect for\ngeneric payoffs.\nThe set of perfect equilibrium outcomes does not have a closed graph.\nL\nR\nU\n1,1\n0,0\nD\n0,0\n1/n,1/n\n(D, R) is perfect for n > 0. In the limit n →inf, only (U, L) is perfect.\nOrder-of-limits problem\n▶As n →inf, the trembles against which D and R remain best\nresponses become smaller and smaller.\n▶(D, R) is a reasonable prediction in the limit game if the approximation\nerror in describing payoffs is greater than players' mistakes.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n22 / 45\n\nProper Equilibrium\nMyerson (1978): a player is infinitely more likely to tremble to better actions\nA player's probability of playing the second-best action is at most ε times\nthe probability of the best, the probability of the third-best action is at most\nε times the probability of the second-best. . .\nDefinition 5\nAn ε-proper equilibrium is a totally mixed strategy profile σε s.t. if\nui(si, σε ) <\ni\nui(si\n′, σε )\ni , then σε(\ni s )\n-\n-\ni ≤εσε(\ni si\n′). A proper equilibrium is any\nlimit of ε-proper equilibria as ε →0.\nTheorem 5\nEvery finite strategic-form game has a proper equilibrium.\nProve existence of ε-proper equilibria applying Kakutani's fixed point\ntheorem to \"mistake hierarchy ε-best response\" correspondences, then\nuse compactness to find a limit point.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n23 / 45\n\nProperties of Proper Equilibrium\nGiven an extensive-form game, a proper equilibrium of its strategic form is\nautomatically subgame-perfect (backward induction argument).\nKohlberg and Mertens (1986): a proper equilibrium in a normal-form game\nis sequential in every extensive-form game having the given normal form.\nHowever, not necessarily a trembling-hand perfect equilibrium in the\nagent-normal form of every such game.\n(L, r) is proper in the strategic form but not perfect in the extensive form.\nMihai Manea (MIT)\nEquilibrium Refinements\nCourtesy of The MIT Press. Used with permission.\nMarch 30, 2016\n24 / 45\n\nForward Induction\nEquilibrium: off-path observations interpreted as errors\nForward induction: players should believe in the rationality of their\nopponents even after observing deviations.\n▶When a player deviates from equilibrium strategies, the opponent\nshould believe that the player expects follow up play that makes the\ndeviation reasonable.\n▶The deviation is informative about the player's type or, in general\nextensive form games, about his future play.\nForward induction not an equilibrium concept: in equilibrium, all players\nexpect specified strategies to be exactly followed\nAn attempt to describe strategic uncertainty. . . no single, rigorous definition\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n25 / 45\n\nExample\n1 chooses between O, which generates payoffs (2, 2), or I, which leads to\nT\nW\nT\n0,0\n3,1\nW\n1,3\n0,0\nSPE: (OW, T). Reasonable?\n▶If 1 plays I, this suggests he does not intend to follow up with W: O\nyields a payoff of 2, while W leads to a payoff of at most 1 for player 1.\n▶Player 2, anticipating that 1 will play T, should play W.\n▶If 1 can convince 2 to play W, he gets the higher payoff from (T, W).\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n26 / 45\n\nForward Induction and Strict Dominance\nReduced normal form\nT\nW\nO\n2,2\n2,2\nIT\n0,0\n3,1\nIW\n1,3\n0,0\n(O, T) is a perfect (in fact, proper) equilibrium.\nIf we rule out IW because it is s. dominated by O, then the only perfect\nequilibrium is (IT, W).\nAn equilibrium concept that is not robust to deletion of s. dominated\nstrategies is troubling...\nKohlberg and Mertens (1986): stable equilibria\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n27 / 45\n\nRequirements\n▶Iterated dominance: every stable set must contain a stable set of any\ngame obtained by deleting a s. dominated strategy\n▶Admissibility: no mixed strategy in a stable set assigns positive\nprobability to a weakly dominated strategy\n▶Invariance to extensive-form representation: stable sets depend only\non the strategic form\nStability: necessarily set-valued\nL\nR\nU\n3,2\n2,2\nM\n1,1\n0,0\nD\n0,0\n1,1\nBoth M and D are strictly dominated. Depending on which one is\neliminated first, L or R becomes weakly dominated... both (U, L) and\n(U, R) must be contained in the solution.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n28 / 45\n\nStable Equilibria\nDefinition 6\nA closed set S of Nash equilibria in a finite strategic-form game is\nstrategically stable if it is minimal among sets with the property that for\nevery η > 0, there exists ε > 0 s.t. for all choices of ε(si) ∈(0, ε), the game\nwhere each player i is constrained to play every si with probability at least\nε(si) has a Nash equilibrium which is within η of some equilibrium in S.\nMinimality is necessary: by upper hemi-continuity, the set of all Nash\nequilibria would be strategically stable (no refinement).\nDifference with trembling-hand perfection: convergence to an equilibrium\nin S for any sequence of perturbations.\nEvery equilibrium in a stable set has to be a perfect equilibrium. . . implied\nby minimality. Perfection in the normal form, not in the agent-normal form.\nThere exist stable sets that do not contain any sequential equilibrium.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n29 / 45\n\nProperties of Stable Equilibria\nTheorem 6\nThere exists a stable set that is contained in a connected component of\nthe set of Nash equilibria. Generically, each component of the set of Nash\nequilibria leads to a single distribution over outcomes, so there exists a\nstable set that induces a unique outcome distribution. A stable set\ncontains a stable set of any game obtained by eliminating a weakly\ndominated strategy and also of any game obtained by deleting a strategy\nthat is not a best response to any of the opponents' strategy profiles in the\nset (NWBR).\nNWBR--robustness to forward induction: knowing that a player would not\nuse a particular strategy is consistent with the equilibrium theories from\nthe stable set\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n30 / 45\n\nForward Induction in Signaling Games\n▶NWBR useful to show that some equilibrium components are not\nstable\n▶Cho and Kreps (1987): equilibrium refinement for signaling games\nweaker than stability--the intuitive criterion--iterated applications of\nNWBR\n▶Kohlberg and Mertens (1986) motivate their stability concept by\nmathematical properties and robustness with respect to trembles a la\nSelten's perfect equilibrium.\n▶Cho and Kreps provide a behavioral foundation based on refining the\nset of plausible beliefs in the spirit of Kreps and Wilson's sequential\nequilibrium.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n31 / 45\n\nSignaling Games\n▶Two players: sender S and receiver R\n▶T: set of types for S\n▶p(t): probability of type t ∈T\n▶S privately observes his type t, then sends a message m ∈M(t)\n▶T(m) = {t | m ∈M(t)}: types that can send message m\n▶R observes m and chooses an action a ∈A(m)\n▶Payoffs uS(t, m, a) and uR(t, m, a)\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n32 / 45\n\nIntuitive Criterion Idea\n▶Behavioral explanation of one aspect of NWBR: robustness to\nreplacing the equilibrium path by its expected payoff.\n▶Presumes that players are certain about play on the equilibrium path,\nbut there is uncertainty off the path.\n▶If we begin with a stable set and delete a strategy in which type t\nsends message m using NWBR, the reduced game should have a\nstable set contained in the original set.\n▶Surviving equilibria should assign probability 0 to type t following m.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n33 / 45\n\nThe Beer-Quiche Game\n▶Player 1 is wimpy (w) or surly (s), with probabilities .1 and .9;\nT = {w, s}.\n▶1 orders breakfast: M = M(t) = {beer, quiche}, ∀t ∈T.\n▶Player 2 decides whether to fight: A(m) = {F, NF}, ∀m ∈M.\n▶1 gets utility 1 from having his favorite breakfast--beer if surly, quiche\nif wimp--but a disutility of 2 from fighting.\n▶When 1 is w, 2's payoff is 1 if he fights and 0 otherwise; when 1 is s,\npayoffs are reversed.\nMihai Manea (MIT)\nEquilibrium Refinements\nCourtesy of The MIT Press. Used with permission.\nMarch 30, 2016\n34 / 45\n\nSequential Equilibria\nAll sequential equilibria involve pooling\n▶Compare σ2(F|beer) and σ2(F|quiche)\n▶Breakfast leading to a smaller probability of fighting must be selected\nwith probability 1 in equilibrium by player 1 type who likes it. . .\nClasses of sequential equilibria\nBoth types of player 1 drink beer.\nBoth types of player 1 eat quiche.\nPlayer 2 does not fight in equilibrium. Player 2 must fight with probability at\nleast 1/2 when observing the out-of-equilibrium breakfast. . . supported by\nany belief for player 2 placing probability at least 1/2 on w following the\nout-of-equilibrium breakfast.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n35 / 45\n\nIntuitive Criterion in Beer-Quiche\nQuiche equilibrium unreasonable. . . NWBR violated\n▶Unreasonable for wimp to deviate to beer: no matter how 2 reacts,\nwimp cannot get more than 2, and he is already getting 3.\n▶Seeing beer, 2 should conclude that 1 is surly and not fight, which\nwould induce surly type to deviate.\nForward-induction argument does not rule out the beer equilibrium\n▶In the beer equilibrium, it is unreasonable for surly type to deviate to\nquiche, while reasonable for wimp.\n▶2's belief that 1 is wimpy if he orders quiche is reasonable.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n36 / 45\n\nIrrational Strategies for the Receiver\nWhat if 2 can also pay a milion dollars to 1?\n▶It would be reasonable for both types to deviate.\n▶But 2 would never want to pay a million dollars.\n▶Assume 1 cannot expect 2 to play a irrational strategy.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n37 / 45\n\nIntuitive Criterion\nFor any T′ ⊆T and any message m,\nBR(T′, m) = ∪μ | μ(T′)=1 BR(μ, m)\nfor strategies that R could rationally play after m and if he is certain that\nt ∈T′.\nConsider a sequential equilibrium\n▶u∗(\nS t): equilibrium payoff to type t\n▶T (m) = {t | u∗(\nS t) > maxa∈BR(T(m),m) uS(t, m, a)}: types that do better\nin equilibrium than they could possibly do by sending m, no matter\nhow R reacts, as long as R is rational.\nThe equilibrium fails the intuitive criterion if ∃t′ ∈T, m ∈M(t′) s.t.\nu∗(t′) <\nmin\nuS(\nS\nt′, m, a).\na∈BR(T(m)\\T (m),m)\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n38 / 45\n\nDiscussion\nThe equilibrium fails the intuitive criterion if some sender type is getting\nless than any payoff he could possibly get by playing m, assuming he\ncould convince the sender that he is not in T (m) because m does not\nmake sense for any of those types.\nIn the beer-quiche example, the quiche equilibrium fails this criterion.\nIterated intuitive criterion\n▶Use the intuitive criterion as above to rule out pairs (t, m).\n▶Rule out actions of R, by requiring that R best respond to a belief\nabout types that have not yet been eliminated given the message.\n▶Possibly rule out more pairs (t, m) given surviving strategies. . .\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n39 / 45\n\nBanks and Sobel (1987)\n▶A type t′ is infinitely more likely to choose the out-of-equilibrium\nmessage m than t if the set of possible best responses of R that\nmake t′ strictly prefer to deviate to m is a strict superset of the\nresponses that make t weakly prefer to deviate.\n▶Conditional on observing m, R should put probability 0 on type t.\n▶D1: analogue of intuitive criterion under this elimination procedure\n▶D2: allow t′ to vary across different best responses of S, requiring\nonly that every best response that weakly induces t to deviate would\nstrictly induce some t′ to deviate\n▶Universal divinity: iteration of D2\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n40 / 45\n\nForward Induction and Iterated Weak Dominance\nIterated strict dominance and rationalizability narrow down the set of\npredictions without pinning down strategies perfectly.\nIterated weak dominance (IWD) captures some of the force of backward\nand forward induction without assuming that players coordinate on a\ncertain equilibrium.\nIn games with perfect information, IWD implies backward induction: any\nsuboptimal strategy at a penultimate node is weakly dominated. . .\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n41 / 45\n\nBeer-quiche Game and IWD\nSolve beer-quiche game applying IWD to ex-ante normal form.\n(beer if w, quiche if s) s. dominated by .1 beer + .9 quiche for both w\nand s\n▶For any strategy of 2, same total probability that 1 is fought by 2.\n▶Player 1 has his favorite breakfast with probability 0 under first strategy\nand positive probability under second.\nFighting after beer weakly dominated by not fighting after beer\n▶Only surviving strategies leading to beer: beer for both w and s and\n(quiche if w, beer if s).\n▶Best response to either strategy is not fighting (probability of s ≥.9).\nSurly chooses beer in any surviving equilibrium, which generates his\nhighest possible payoff of 3.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n42 / 45\n\nStability and IWD\nIWD captures part of the forward induction notion implicit in stability.\nStable components contain stable sets of games obtained by removing a\nweakly dominated action.\nKohlberg and Mertens' motivating example\nT\nW\nO\n2,2\n2,2\nIT\n0,0\n3,1\nIW\n1,3\n0,0\n(IT, W): unique outcome under both IWD and stability\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n43 / 45\n\nBen-Porath and Dekel (1992)\nVariation of the battle of the sexes: before game starts, player 1 has the\noption to \"burn money.\"\nIf 1 decides not to burn money, play standard battle of the sexes\nL\nR\nU\n5,1\n0,0\nD\n0,0\n1,5\nIf 1 decides to burn two units of utility, the game is\nL\nR\nU\n3,1\n-2,0\nD\n-2,0\n-1,5\nIWD: 1 can ensure his favorite equilibrium without burning\nThe mere option of burning money selects player 1's favorite equilibrium.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n44 / 45\n\nBurning Money and IWD\nBurning followed by D s. dominated by not burning and D\nAny strategy playing R after burning weakly dominated by L after\nburning\n▶same outcome if 1 does not burn\n▶after burning, L is better than R against the only surviving strategy, U\nNot burning and D s. dominated by burning and U\n▶burning and U yields a payoff of 3 for player 1 under surviving\nstrategies (2 plays L after burning)\n▶not burning and D gives player 1 at most 1\nR after not burning weakly dominated by L after not burning\n▶same outcome if 1 burns\n▶after not burning, L is a best response to U\nOnly surviving outcome: no burning and (U, L).\nBen-Porath and Dekel: in any game where a player has a unique best\noutcome that is a strict Nash equilibrium and can signal with a sufficiently\nfine grid of burning stakes, she gets her best outcome under IWD.\nMihai Manea (MIT)\nEquilibrium Refinements\nMarch 30, 2016\n45 / 45\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Extensive Form Games Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/ecc1948438ed71a5e77eb29f123a4eef_MIT14_126S16_Extensive.pdf",
      "content": "Extensive Form Games\nMihai Manea\nMIT\n\nExtensive-Form Games\n▶N: finite set of players; nature is player 0 ∈N\n▶tree: order of moves\n▶payoffs for every player at the terminal nodes\n▶information partition\n▶actions available at every information set\n▶description of how actions lead to progress in the tree\n▶random moves by nature\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n2 / 33\nCourtesy of The MIT Press. Used with permission.\n\nGame Tree\n▶(X, >): tree\n▶X: set of nodes\n▶x > y: node x precedes node y\n▶φ ∈X: initial node, φ > x, ∀x ∈X \\ {φ}\n▶> transitive (x > y, y > z ⇒x > z) and asymmetric (x > y ⇒y >x)\n▶every node x ∈X \\ {φ} has one immediate predecessor: ∃x′ > x s.t.\nx′′ > x & x′′ , x′ ⇒x′′ > x′\n▶Z = {z | ∃x, z > x}: set of terminal nodes\n▶z ∈Z determines a unique path of moves through the tree, payoff\nui(z) for player i\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n3 / 33\n\nInformation Partition\n▶information partition: a partition of X \\ Z\n▶node x belongs to information set h(x)\n▶player i(h) ∈N moves at every node x in information set h\n▶i(h) knows that he is at some node of h but does not know which one\n▶same player moves at all x ∈h, otherwise players might disagree on\nwhose turn it is\n▶i(x) := i(h(x))\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n4 / 33\n\nActions\n▶A(x): set of available actions at x ∈X \\ Z for player i(x)\n▶A(x) = A(x′) =: A(h), ∀x′ ∈h(x) (otherwise i(h) might play an\ninfeasible action)\n▶each node x , φ associated with the last action taken to reach it\n▶every immediate successor of x labeled with a different a ∈A(x) and\nvice versa\n▶move by nature at node x: probability distribution over A(x)\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n5 / 33\n\nStrategies\n▶Hi = {h|i(h) = i}\n▶Si =\nh\ni\n∈Hi A(h): set of pure strategies for player\n▶si(h):\nQ\naction taken by player i at information set h ∈Hi under si ∈S\nQ\ni\n▶S =\ni N Si: strategy profiles\n∈\n▶A strategy is a complete contingent plan specifying the action to be\ntaken at each information set.\n▶Mixed strategies: σi ∈∆(Si)\n▶mixed strategy profile σ ∈\ni N ∆(Si)\n∈\n→probability distribution\nO(σ) ∈∆(Z)\n▶ui(σ) = E\nQ\nO(σ)(ui(z))\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n6 / 33\n\nStrategic Form\n▶The strategic form representation of the extensive form game is the\nnormal form game defined by (N, S, u)\n▶A mixed strategy profile is a Nash equilibrium of the extensive form\ngame if it constitutes a Nash equilibrium of its strategic form.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n7 / 33\n\nGrenade Threat Game\nPlayer 2 threatens to explode a grenade if player 1 doesn't give him\n$1000.\n▶Player 1 chooses between g and ¬g.\n▶Player 2 observes player 1's choice, then decides whether to explode\na grenade that would kill both.\n(0, 0)\n,\n(-inf, -inf)\nA\n¬g\n(-1000, 1000)\n,\n(-inf, -inf)\nA\ng\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n8 / 33\n\nStrategic Form Representation\n(0, 0)\n,\n(-inf, -inf)\nA\n¬g\n(-1000, 1000)\n,\n(-inf, -inf)\nA\ng\nA, A\nA, ,\n,, A\n,, ,\ng\n-inf, -inf\n-inf, -inf\n-1000, 1000∗\n-1000, 1000\n¬g\n-inf, -inf\n0, 0∗\n-inf, -inf\n0, 0∗\nThree pure strategy Nash equilibria. Only (¬g, ,, ,) is subgame perfect.\nA is not a credible threat.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n9 / 33\n\nBehavior Strategies\n▶bi(h) ∈∆(A(h)): behavior strategy for player i(h) at information set h\n▶bi(a|h): probability of action a at information set h\n▶behavior strategy bi ∈Q\nh Hi ∆(A(h))\n∈\n▶independent mixing at each information set\n▶bi outcome equivalent to the mixed strategy\nσi(si) =\nY\nbi(si(h)|h)\n(1)\nh∈Hi\n▶Is every mixed strategy equivalent to a behavior strategy?\n▶Yes, under perfect recall.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n10 / 33\n\nPerfect Recall\nNo player forgets any information he once had or actions he previously\nchose.\n▶If x′′ ∈h(x′), x > x′, and the same player i moves at both x and x′\n(and thus at x′′), then there exists xˆ ∈h(x) (possibly xˆ = x) s.t.\nxˆ > x′′ and the action taken at x along the path to x′ is the same as\nthe action taken at xˆ along the path to x′′.\n▶x′ and x′′ distinguished by information i does not have, so he cannot\nhave had it at h(x)\n▶x′ and x′′ consistent with the same action at h(x) since i must\nremember his action there\n▶Equivalently, every node in h ∈Hi must be reached via the same\nsequence of i's actions.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n11 / 33\n\nEquivalent Behavior Strategies\n▶Ri(h) = {si|h is on the path of (si, s-i) for some s-i}: set of i's pure\nstrategies that do not preclude reaching information set h ∈Hi\n▶Under perfect recall, a mixed strategy σi is equivalent to a behavior\nstrategy bi defined by\nP\nσi(si)\n{si∈Ri(h)|si(h)=a\nb\n}\ni(a|h) =\nP\nsi∈Ri(h)\nσi(si)\n(2)\nwhen the denominator is positive.\nTheorem 1 (Kuhn 1953)\nIn extensive form games with perfect recall, mixed and behavior strategies\nare outcome equivalent under the formulae (1) & (2).\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n12 / 33\n\nProof\n▶h1, . . . , hk : player i's information sets preceding h in the tree\n▶Under perfect recall, reaching any node in h requires i to take the\nsame action ak at each hk,\nRi(h) = {si|si(hk) = ak, ∀k = 1, k }.\n▶Conditional on getting to h, the distribution of continuation play at h is\ngiven by the relative probabilities of the actions available at h under\nthe restriction of σi to Ri(h),\n{s\n|\ni|si(hk)=ak,∀k\nP\n=\nbi(a h) =\n1, k & si(h)=a}\nσi(si)\nP\n{si|si(hk)=ak,∀k=1, k}\nσi(si)\n.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n13 / 33\n\nExample\nFigure: Different mixed strategies can generate the same behavior strategy.\n▶S2 = {(A, C), (A, D), (B, C), (B, D)}\n▶Both σ2 = 1/4(A, C) + 1/4(A, D) + 1/4(B, C) + 1/4(B, D) and\nσ2 = 1/2(A, C) + 1/2(B, D) generate--and are equivalent to--the\nbehavior strategy b2 with b2(A|h) = b2(B|h) = 1/2 and\nb2(C|h′) = b2(D|h′) = 1/2.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n14 / 33\nCourtesy of The MIT Press. Used with permission.\n\nExample with Imperfect Recall\nFigure: Player 1 forgets what he did at the initial node.\n▶S1 = {(A, C), (A, D), (B, C), (B, D)}\n▶σ1 = 1/2(A, C) + 1/2(B, D) →b1 = (1/2A + 1/2B, 1/2C + 1/2D)\n▶b1 not equivalent to σ1\n▶(σ1, L): prob. 1/2 for paths (A, L, C) and (B, L, D)\n▶(b1, L): prob. 1/4 to paths (A, L, C), (A, L, D), (B, L, C), (B, L, D)\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n15 / 33\nCourtesy of The MIT Press. Used with permission.\n\nImperfect Recall and Correlations\n▶Since both A vs. B and C vs. D are choices made by player 1, the\nstrategy σ1 under which player 1 makes all his decisions at once\nallows choices at different information sets to be correlated\n▶Behavior strategies cannot produce this correlation, because when it\ncomes time to choose between C and D, player 1 has forgotten\nwhether he chose A or B.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n16 / 33\nCourtesy of The MIT Press. Used with permission.\n\nAbsent Minded Driver\nPiccione and Rubinstein (1997)\n▶A drunk driver has to take the third out of five exits on the highway\n(exit 3 has payoff 1, other exits payoff 0).\n▶The driver cannot read the signs and forgets how many exits he has\nalready passed.\n▶At each of the first four exits, he can choose C (continue) or E\n(exit). . . imperfect recall: choose same action.\n▶C leads to exit 5, while E leads to exit 1.\n▶Optimal solution involves randomizing: probability p of choosing C\nmaximizes p2(1 -p), so p = 2/3.\n▶\"Beliefs\" given p = 2/3: (27/65, 18/65, 12/65, 8/65)\n▶E has conditional \"expected\" payoff of 12/65, C has 0. Optimal\nstrategy: E with probability 1, inconsistent.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n17 / 33\n\nConventions\n▶Restrict attention to games with perfect recall, so we can use mixed\nand behavior strategies interchangeably.\n▶Behavior strategies are more convenient.\n▶Drop notation b for behavior strategies and denote by σi(a|h) the\nprobability with which player i chooses action a at information set h.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n18 / 33\n\nSurvivor\nTHAI 21\n▶Two players face off in front of 21 flags.\n▶Players alternate in picking 1, 2, or 3 flags at a time.\n▶The player who successfully grabs the last flag wins.\nGame of luck?\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n19 / 33\n\nBackward Induction\n▶An extensive form game has perfect information if all information sets\nare singletons.\n▶Can solve games with perfect information using backward induction.\n▶Finite game →∃penultimate nodes (successors are terminal nodes).\n▶The player moving at each penultimate node chooses an action that\nmaximizes his payoff.\n▶Players at nodes whose successors are penultimate/terminal choose\nan optimal action given play at penultimate nodes.\n▶Work backwards to initial node. . .\nTheorem 2 (Zermelo 1913; Kuhn 1953)\nIn a finite extensive form game of perfect information, the outcome(s) of\nbackward induction constitutes a pure-strategy Nash equilibrium.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n20 / 33\n\nMarket Entrance\n▶Incumbent firm 1 chooses a level of capital K1 (which is then fixed).\n▶A potential entrant, firm 2, observes K1 and chooses its capital K2.\n▶The profit for firm i = 1, 2 is Ki(1 -K1 -K2) (firm i produces output Ki,\nwe use earlier demand function).\n▶Each firm dislikes capital accumulation by the other.\n▶A firm's marginal value of capital decreases with the other's.\n▶Capital levels are strategic substitutes.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n21 / 33\n\nStackelberg Competition\n▶Profit maximization by firm 2 requires\n1 -K\nK\n2 =\n.\n▶Firm 1 anticipates that firm 2 will act optimally, and therefore solves\nmax\nK1\n(\nK1\n\n1 -K1 -1 -K1\n.\n!)\n▶Solution involves K1 = 1/2, K2 = 1/4, π1 = 1/8, and π2 = 1/16.\n▶Firm 1 has first mover advantage.\n▶In contrast, in the simultaneous move game, K1 = 1/3, K2 = 1/3,\nπ1 = 1/9, and π2 = 1/9.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n22 / 33\n\nCentipede Game\n▶Player 1 has two piles in front of her: one contains 3 coins, the other\n1.\n▶Player 1 can either take the larger pile and give the smaller one to\nplayer 2 (T) or push both piles across the table to player 2 (C).\n▶Every time the piles pass across the table, one coin is added to each.\n▶Players alternate in choosing whether to take the larger pile (T) or\ntrust opponent with bigger piles (C).\n▶The game lasts 100 rounds.\nWhat's the backward induction solution?\nT\nT\nT\nT\nT\nC\nC\nC\nC\nC\n(3, 1)\n(2, 4)\n(5, 3)\n(101, 99) (100, 102)\n(103, 101)\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n23 / 33\n\nChess Players and Backward Induction\nPalacios-Huerta and Volij (2009)\n▶chess players and college students behave differently in the\ncentipede game.\n▶Higher-ranked chess players end the game earlier.\n▶All Grandmasters in the experiment stopped at the first opportunity.\n▶Chess players are familiar with backward induction reasoning and\nneed less learning to reach the equilibrium.\n▶Playing against non-chess-players, even chess players continue in\nthe game longer.\n▶In long games, common knowledge of the ability to do complicated\ninductive reasoning becomes important for the prediction.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n24 / 33\n\nSubgame Perfection\n▶Backward induction solution is more than a Nash equilibrium.\n▶Actions are optimal given others' play--and form an\nequilibrium--starting at any intermediate node: subgame\nperfection. . . rules out non-credible threats.\n▶Subgame perfection extends backward induction to imperfect\ninformation games.\n▶Replace \"smallest\" subgames with a Nash equilibrium and iterate on\nthe reduced tree (if there are multiple Nash equilibria in a subgame,\nall players expect same play).\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n25 / 33\n\nSubgames\nSubgame: part of a game that can be analyzed separately; strategically\nand informationally independent. . . information sets not \"chopped up.\"\nDefinition 1\nA subgame G of an extensive form game T consists of a single node x\nand all its successors in T, with the property that if x′ ∈G and x′′ ∈h(x′)\nthen x′′ ∈G. The information sets, actions and payoffs in the subgame are\ninherited from T.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n26 / 33\n\nFalse Subgames\nMihai Manea (MIT)\nExtensive-Form Games\nCourtesy of The MIT Press. Used with permission.\nMarch 2, 2016\n27 / 33\n\nSubgame Perfect Equilibrium\nσ: behavior strategy in T\n▶σ|G: the strategy profile induced by σ in subgame G of T (start play\nat the initial node of G, follow actions specified by σ, obtain payoffs\nfrom T at terminal nodes)\n▶Is σ|G a Nash equilibrium of G for any subgame G?\nDefinition 2\nA strategy profile σ in an extensive form game T is a subgame perfect\nequilibrium if σ|G is a Nash equilibrium of G for every subgame G of T.\n▶Any game is a subgame of itself →a subgame perfect equilibrium is a\nNash equilibrium.\n▶Subgame perfection coincides with backward induction in games of\nperfect information.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n28 / 33\n\nNuclear Crisis\nRussia provokes the US. . .\n▶The U.S. can choose to escalate (E) or end the game by ignoring the\nprovocation (I).\n▶If the game escalates, Russia faces a similar choice: to back down\n(B), but lose face, or escalate (E).\n▶Escalation leads to nuclear crisis: a simultaneous move game where\neach nation chooses to either retreat (R) and lose credibility or\ndetonate (). Unless both countries retreat, retaliation to the first\nnuclear strike culminates in nuclear disaster, which is infinitely costly.\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n29 / 33\n\nThe Extensive Form\nUS\nRussia\nUS\nRussia\n(-5, -5)\nR\n(-inf, -inf)\n\nR\n(-inf, -inf)\nR\n(-inf, -inf)\n\nE\n(10, -10)\nB\nE\n(0, 0)\nI\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n30 / 33\n\nLast Stage\nThe simultaneous-move game at the last stage has two Nash equilibria.\nR\n\nR\n-5, 5∗\n-inf, -inf\n\n-inf, -inf\n-inf, -inf∗\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n31 / 33\n\nOne Subgame Perfect Equilibrium\nUS\nRussia\nUS\nRussia\n(-5, -5)\nR\n(-inf, -inf)\n\nR\n(-inf, -inf)\nR\n(-inf, -inf)\n\nE\n(10, -10)\nB\nE\n(0,0)\nI\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n32 / 33\n\nAnother Subgame Perfect Equilibrium\nUS\nRussia\nUS\nRussia\n(-5, -5)\nR\n(-inf, -inf)\n\nR\n(-inf, -inf)\nR\n(-inf, -inf)\n\nE\n(10,-10)\nB\nE\n(0, 0)\nI\nMihai Manea (MIT)\nExtensive-Form Games\nMarch 2, 2016\n33 / 33\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 GameTheory Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/bba04a523a1daeeeffee6c9f2377af17_MIT14_126S16_gametheory.pdf",
      "content": "Game Theory\nMihai Manea\nMIT\n\nWhat is Game Theory?\nGame Theory is the formal study of strategic interaction.\nIn a strategic setting the actions of several agents are interdependent.\nEach agent's outcome depends not only on his actions, but also on the\nactions of other agents. How to predict opponents' play and respond\noptimally?\nEverything is a game. . .\n▶poker, chess, soccer, driving, dating, stock market\n▶advertising, setting prices, entering new markets, building a reputation\n▶bargaining, partnerships, job market search and screening\n▶designing contracts, auctions, insurance, environmental regulations\n▶international relations, trade agreements, electoral campaigns\nMost modern economic research includes game theoretical elements.\nEleven game theorists have won the economics Nobel Prize so far.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n2 / 69\n\nBrief History\n▶Cournot (1838): quantity setting duopoly\n▶Zermelo (1913): backward induction\n▶von Neumann (1928), Borel (1938), von Neumann and Morgenstern\n(1944): zero-sum games\n▶Flood and Dresher (1950): experiments\n▶Nash (1950): equilibrium\n▶Selten (1965): dynamic games\n▶Harsanyi (1967): incomplete information\n▶Akerlof (1970), Spence (1973): first applications\n▶1980s boom, continuing nowadays: repeated games, bargaining,\nreputation, equilibrium refinements, industrial organization, contract\ntheory, mechanism/market design\n▶1990s: parallel development of behavioral economics\n▶more recently: applications to computer science, political science,\npsychology, evolutionary biology\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n3 / 69\n\nKey Elements of a Game\n▶Players: Who is interacting?\n▶Strategies: What are the options of each player? In what order do\nplayers act?\n▶Payoffs: How do strategies translate into outcomes? What are\nplayers' preferences over possible outcomes?\n▶Information/Beliefs: What do players know/believe about the\nsituation and about one another? What actions do they observe\nbefore making decisions?\n▶Rationality: How do players think?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n4 / 69\n\nNormal-Form Games\nA normal (or strategic) form game is a triplet (N, S, u) with the following\nproperties:\n▶N = {1, 2, . . . , n}: finite set of players\n▶Si ∋si: set of pure strategies of player i\n▶S = S1 × · · · × Sn ∋s = (s1, . . . , sn): set of pure strategy profiles\nQ\n▶S-i =\nj,i Sj ∋s-i: pure strategy profiles of i's opponents\n▶ui : S →R: payoff function of player i; u = (u1, . . . , un).\nOutcomes are interdependent. Player i ∈N receives payoff ui(s1, . . . , sn)\nwhen s = (s1, . . . , sn) ∈S is played.\nThe structure of the game is common knoweldge: all players know\n(N, S, u), and know that their opponents know it, and know that their\nopponents know that everyone knows, and so on.\nThe game is finite if S is finite.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n5 / 69\n\nRock-Paper-Scissors\nR\nP\nS\nR\n0, 0\n-1, 1\n1, -1\nP\n1, -1\n0, 0\n-1, 1\nS\n-1, 1\n1, -1\n0, 0\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n6 / 69\n\nMixed and Correlated Strategies\n▶∆(X): set of probability measures (or distributions) over the\nmeasurable space X (usually, X is either finite or a subset of a\nEuclidean space)\n▶∆(Si) ∋σi: mixed strategies of player i\n▶σ ∈∆(S1) × · · · × ∆(Sn): mixed strategy profile, specifies a mixed\nstrategy for each player\n▶∆(S) ∋σ: correlated strategy profiles\n▶σ-i ∈∆(S-i): correlated belief for player i\nQ\n▶\nj,i ∆(Sj): set of independent beliefs for i\nPlayer i has von Neumann-Morgenstern preferences--expected\nutility--over ∆(S), i.e., ui extends to ∆(S) as follows:\nX\nui(σ) =\nσ(s)ui(s).\ns∈S\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n7 / 69\n\nDominated Strategies\nAre there obvious predictions about how a game should be played?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n8 / 69\n\nAdvertising War: Coke vs. Pepsi\n▶Without any advertising, each company earns $5b/year from Cola\nconsumers.\n▶Each company can choose to spend $2b/year on advertising.\n▶Advertising does not increase total sales for Cola, but if one company\nadvertises while the other does not, it captures $3b from the\ncompetitor.\nPepsi\nNo Ad\nAd\nCoke No Ad\n$5b, $5b\n$2b, $6b\nAd\n$6b, $2b\n$3b, $3b∗\n▶What will the Cola companies do?\n▶Is there a better feasible outcome?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n9 / 69\n\nPrisoners' Dilemma (PD)\nFlood and Dresher (1950): RAND corporation's investigations into game\ntheory for possible applications to global nuclear strategy\n▶Two persons are arrested for a crime.\n▶There is not enough evidence to convict either.\n▶Different cells, no communication.\n▶If a suspect testifies against the other (\"Defect\") and the other does not\n(\"Cooperate\"), the former is released and the latter gets a harsh\npunishment.\n▶If both prisoners testify, they share the punishment.\n▶If neither testifies, both serve time for a smaller offense.\nC\nD\nC\n2, 2\n0, 3\nD\n3, 0\n1, 1∗\n▶Each prisoner is better off defecting regardless of what the other\ndoes. We say D strictly dominates C for each prisoner.\n▶The resulting outcome is (D, D), which is worse than (C, C).\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n10 / 69\n\nModified Prisoners' Dilemma\nConsider the game obtained from the prisoners' dilemma by changing\nplayer 1's payoff for (C, D) from 0 to 2.\nC\nD\nC\n2, 2\n2, 3∗\nD\n3, 0\n1, 1\n▶No matter what player 1 does, player 2 still prefers D to C.\n▶If player 1 knows that 2 never plays C, then he prefers C to D.\n▶Unlike in the prisoners' dilemma example, we use an additional\nassumption to reach our prediction in this case: player 1 needs to\ndeduce that player 2 never plays a dominated strategy.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n11 / 69\n\nStrictly Dominated Strategies\nDefinition 1\nA strategy si ∈Si is strictly (s.) dominated by σi ∈∆(Si) if\nui(σi, s-i) > ui(si, s-i), ∀s-i ∈S-i.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n12 / 69\n\nPure Strategies May Be Dominated by Mixed Strategies\nL\nR\nT\n3, x\n0, x\nM\n0, x\n3, x\nB\n1, x\n1, x\nFigure: B is s. dominated by 1/2T + 1/2M.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n13 / 69\n\nThe Beauty Contest\n▶Players: everyone in the class\n▶Strategy space: any number in {1, 2, . . . , 100}\n▶The person whose number is closest to 2/3 of the class average wins\nthe game.\n▶Payoffs: one randomly selected winner receives $1.\nWhy is this game called a beauty contest?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n14 / 69\n\nKeynesian Beauty Contest\nKeynes described the action of rational actors in a market using an\nanalogy based on a newspaper contest. Entrants are asked to choose a\nset of 6 faces from photographs that they find \"most beautiful.\" Those who\npicked the most popular face are eligible for a prize.\nA naive strategy would be to choose the 6 faces that, in the opinion of the\nentrant, are most beautiful. A more sophisticated contest entrant, wishing\nto maximize the chances of winning against naive opponents, would guess\nwhich faces the majority finds attractive, and then make a selection based\non this inference.\nThis can be carried one step further to account for the fact that other\nentrants would each have their own opinions of what public perceptions of\nbeauty are. What does everyone believe about what everyone else\nbelieves about whom others find attractive?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n15 / 69\n\nThe Beauty Contest and the Stock Market\nIt is not a case of choosing those faces that, to the best of one's\njudgment, are really the prettiest, nor even those that average\nopinion genuinely thinks the prettiest. We have reached the third\ndegree where we devote our intelligences to anticipating what\naverage opinion expects the average opinion to be. And there\nare some, I believe, who practice the fourth, fifth and higher\ndegrees. (John Maynard Keynes, General Theory of\nEmployment, Interest and Money, 1936)\nKeynes suggested that similar behavior is observed in the stock market.\nShares are not priced based on what people think their fundamental value\nis, but rather on what they think everyone else thinks the value is and what\nthey think about these beliefs, and so on.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n16 / 69\n\nIterated Deletion of Strictly Dominated Strategies\nWe can iteratively eliminate dominated strategies, under the assumption\nthat \"I know that you know that other players know. . . that everyone knows\nthe payoffs and that no one would ever use a dominated strategy.\"\nDefinition 2\nFor all i ∈N, set S0\ni = Si and define Sk\ni recursively by\nSk\ni = {si ∈Sk-1\ni\n|∃σi ∈∆(Sk-1\ni\n), ui(σi, s-i) > ui(si, s-i), ∀s-i ∈Sk-1\n-i }.\nThe set of pure strategies of player i that survive iterated deletion of s.\ndominated strategies is Sinf\ni\n= ∩k≥0Sk\ni . The set of surviving mixed\nstrategies is\n{σi ∈∆(Sinf\ni )|∃σ′\ni ∈∆(Sinf\ni ), ui(σ′\ni, s-i) > ui(σi, s-i), ∀s-i ∈Sinf\n-i}.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n17 / 69\n\nRemarks\nIn a finite game, the elimination procedure ends in a finite number of steps,\nso Sinfis simply the set of strategies left at the final stage.\nIn an infinite game, if S is a compact metric space and u is continuous,\nthen one can use Cantor's theorem (a decreasing nested sequence of\nnon-empty compact sets has nonempty intersection) to show that Sinf, ∅.\nDefinition assumes that at each iteration all dominated strategies of every\nplayer are deleted simultaneously. In a finite game, the limit set Sinfdoes\nnot depend on the particular order in which deletion proceeds.\nOutcome does not change if we eliminate s. dominated mixed strategies at\nevery step. A strategy dominated against all pure strategies of the\nopponents iff it is dominated against all their mixed strategies. Eliminating\nmixed strategies for player i at any stage does not affect the set of s.\ndominated pure strategies for any j , i at the next stage.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n18 / 69\n\nDetour on Common Knowledge\n▶Is common knowledge a sensible assumption? What does the\ndefinition of S100\ni\nentail?\n▶Higher order beliefs, common knowledge of rationality. . .\n▶Why did the strategy of choosing 1 not win in the beauty contest?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n19 / 69\n\nThe Story of the Unfaithful Wives\n▶A village with 100 married couples and a high priest.\n▶The men had to pass a logic exam before being allowed to marry.\n▶It is common knowledge that the high priest is truthful.\n▶The men would gossip about adulterous relationships and each\nknows which of the other wives are unfaithful.\n▶No one would ever inform a husband about his cheating wife.\n▶The high priest knows that some wives are unfaithful and decides that\nsuch immorality should no longer be tolerated.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n20 / 69\n\nContinued Story\n▶The priest convenes all the men at the temple and publicly announces\nthat the integrity of the village has been compromised--there is at\nleast one cheating wife.\n▶He also points out that even though no one knows whether his wife is\nfaithful, each man has heard about the other unfaithful wives.\n▶He orders that every man certain of his wife's infidelity should shoot\nher at midnight.\n▶39 silent nights went by and. . . on the 40th shots were heard.\nHow many wives were shot? Were all the unfaithful wives murdered? How\ndid men learn of the infidelity of their wives after 39 nights in which nothing\nhappened?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n21 / 69\n\nRationalizability\n▶Solution concept introduced independently by Bernheim (1984) and\nPearce (1984).\n▶Like iterated dominance, rationalizability derives restrictions on play\nfrom common knowledge of payoffs and the fact that players are\n\"reasonable.\"\n▶Dominance: unreasonable to use a strategy that performs worse than\nanother (fixed) one in every scenario.\n▶Rationalizability: irrational for a player to choose a strategy that is not\na best response to some beliefs about opponents' strategies.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n22 / 69\n\nWhat is a \"Belief\"?\n▶Bernheim & Pearce: every player i's beliefs σ-i about the play of j , i\nQ\nmust be independent, i.e., σ-i ∈\nj,i ∆(Sj).\n▶Alternatively, allow player i to believe that the actions of opponents\nare correlated, i.e., any σ-i ∈∆(S-i) is a possibility.\n▶The two definitions have different implications for n ≥3.\nFocus on case with correlated beliefs. Such beliefs represent a player's\nuncertainty about his opponents' actions, not necessarily his theory about\ntheir deliberate randomization and coordination.\nPlayer i may place equal probability on two scenarios: either both j and k\npick action A or they both play B. If i is not sure which theory is true, then\nhis beliefs are correlated even though he knows that j and k are acting\nindependently.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n23 / 69\n\nBest Responses\nDefinition 3\nA strategy σi ∈Si is a best response to a belief σ-i ∈∆(S-i) if\nui(σi, σ-i) ≥ui(si, σ-i), ∀si ∈Si.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n24 / 69\n\nRationalizabile Strategies\nCommon knowledge of payoffs and rationality imposes restrictions on\nplay. . .\nDefinition 4\nSet S0 = S and let Sk be given recursively by\nSk\ni = {si ∈Sk-1\ni\n|∃σ-i ∈∆(Sk-1\n-i ), ui(si, σ-i) ≥ui(s′\ni , σ-i), ∀s′\ni ∈Sk-1\ni\n}.\nThe set of correlated rationalizable strategies for player i is Sinf\ni\n= T\nk≥0 Sk\ni .\nA mixed strategy σi ∈∆(Si) is rationalizable if there is a belief\nσ-i ∈∆(Sinf\n-i) s.t. ui(σi, σ-i) ≥ui(si, σ-i) for all si ∈Sinf\ni .\nThe definition of independent rationalizability replaces ∆(Sk-1\n-i ) and\n∆(Sinf\n-i) with Q\nj,i ∆(Sk-1\nj\n) and Q\nj,i ∆(Sinf\nj ), resp.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n25 / 69\n\nRationalizability in Cournot Duopoly\nTwo firms compete on the market for a divisible homogeneous good.\n▶Each firm i = 1, 2 has zero marginal cost and simultaneously decides\nto produce an amount of output qi ≥0.\n▶The resulting price is p = 1 -q1 -q2.\n▶Profit of firm i is qi(1 -q1 -q2).\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n26 / 69\n\nRationalizability in Cournot Duopoly\nBest response of one firm if the other produces q is\nB(q) = max(0, (1 -q)/2) (j = 3 -i); B is decreasing. If q ⪋r then\nB(q) ⪌(1 -r)/2.\n▶Since q\n≥q := 0, only strategies q\nq1\n:= B(q0\n≤\n) = (1 -q )/2 are\nbest responses, S1\n= [q0, q ]\ni\n.\n▶Then only q ≥q2 := B(q1) = (1 -q1)/2 survives the second round of\nelimination, S2\n= [q2, q ]\ni\n. . .\n▶We obtain a sequence\nq0\n2k\n2k+1\n≤q ≤. . . ≤q\n≤. . . ≤q\n≤. . . ≤q ,\nP\nwhere q2k\nk\nl\nk\n2k\n=\n/\n+1\n2k\n-/\n/\n-\n/\nl=\n(1\n=\n1 1 4 =\n1 4 ) 3 and q\n(1\nq\n) 2 s.t.\nS2k+1 = [\ni\nq2k, q2k+1] and S2k\n2k\n2k 1\n= [\n,\n-]\n≥\ni\nq\nq\nfor all k\n0.\nlimk→infqk = 1/3, so the only rationalizable strategy for firm i is qi = 1/3\n(the Nash equilibrium).\nWhat strategies are rationalizable with more than two firms?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n27 / 69\n\nNever Best Responses\nA strategy σi ∈∆(Si) is never a best response for player i if it is not a best\nresponse to any correlated belief σ-i ∈∆(S-i).\nRecall that σi ∈∆(Si) is s. dominated if ∃σ′\ni ∈∆(Si) s.t.\nui(σ′\ni, s-i) > ui(σi, s-i), ∀s-i ∈S-i.\nTheorem 1\nIn a finite game, a strategy is never a best response iff it is s. dominated.\nCorollary 1\nCorrelated rationalizability and iterated strict dominance coincide.\nIf σi is s. dominated by σ′\ni , then σi is not a best response for any belief\nσ-i ∈∆(S-i): σ′\ni yields a higher payoff than σi for player i against any σ-i.\nLeft to prove that a strategy that is not s. dominated is a best response for\nsome beliefs.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n28 / 69\n\nProof\nSuppose σ i is not s. dominated for player i.\n▶Define set of \"dominated payoffs\" for i by\nD = {x\nS\n∈R\n-i|∃σi ∈∆(Si), x ≤ui(σi, ·)}.\nD is non-empty, closed, and convex.\n▶ui(σ i, ·) does not belong to the interior of D because it is not s.\ndominated by any σi ∈∆(Si).\n▶By the supporting hyperplane theorem,\nS\n∃α ∈R\n-i \\ {0} s.t.\nα · ui(σ i, ·) ≥α · x, ∀x ∈D.\nIn particular, α · ui(σ i, ·) ≥α · ui(σi, ·), ∀σi ∈∆(Si).\n▶Since D is not bounded from below, α has non-negative components.\n▶Normalize α so that its components sum to 1; α interpreted as a belief\nin ∆(S-i) with the property that\nui(σ i, α) ≥ui(σi, α), ∀σi ∈∆(Si).\nThus σ i is a best response to belief α.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n29 / 69\n\nIteration and Best Responses\nTheorem 2\nFor every k ≥0, each si ∈Sk\ni is a best response (within Si) to a belief in\n∆(Sk-1\n-i ).\nProof.\nFix si ∈Sk\ni ; si is a best response within Sk-1\ni\nto some σ-i ∈∆(Sk-1\n-i ). If si\nwere not a best response within Si to σ-i, let s′\ni be a best response.\nSince si is a best response within Sk-1\ni\nto σ-i and s′\ni is a better response\nthan si to σ-i, we need s′\ni < Sk-1\ni\n.\nThen s′\ni was deleted at an earlier stage, say s′\ni ∈Sl-1\ni\nbut s′\ni < Sl\ni for some\nl ≤k -1. This contradicts the fact that s′\ni is a best response in Si ⊇Sl-1\ni\nto\nσ-i ∈∆(Sk-1\n-i ) ⊆∆(Sl-1\n-i ).\n□\nCorollary 2\nIf the game is finite, then each si ∈Sinf\ni\nis a best response (within Si) to a\nbelief in ∆(Sinf\n-i).\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n30 / 69\n\nClosed under Rational Behavior\nDefinition 5\nA set Z = Z1 × . . . × Zn with Zi ⊆Si for i ∈N is closed under rational\nbehavior if, for all i, every strategy in Zi is a best response to a belief in\n∆(Z-i).\nTheorem 3\nIf the game is finite (or if S is a compact metric space and u is continuous),\nthen Sinfis the largest set closed under rational behavior.\nProof.\nSinfis closed under rational behavior by Corollary 2. Suppose that there\nexists Z1 × . . . × Zn 1 Sinfthat is closed under rational behavior.\nConsider the smallest k for which there is an i such that Zi ⊆Sk\ni . It must\nbe that k ≥1 and Z-i ⊆Sk-1\n-i\n.\nBy assumption, every element of Zi is a best response to an element of\n∆(Z-i) ⊂∆(Sk-1\n-i ), contradicting Zi ⊆Sk\ni .\n□\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n31 / 69\n\nEpistemic Foundations of Rationalizability\nFormalize the idea of common knowledge and show that rationalizability\ncaptures the idea of common knowledge of rationality (and payoffs).\nDefinition 6 (Information Structure)\nAn information (or belief) structure is a list (Ω, (Ii)i∈N, (pi)i∈N)\n▶Ωis a finite state space\n▶Ii : Ω→2Ωis a partition of Ωfor each i ∈N s.t. Ii(ω) is the set of\nstates that i thinks are possible when the true state is ω;\nω′ ∈Ii(ω) ⇔ω ∈Ii(ω′)\n▶pi,Ii(ω) ∈∆(Ii(ω)): i's belief at ω\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n32 / 69\n\nInterpretation\n▶State ω summarizes all the relevant facts about the world. Only one\nof the states is true; all others are hypothetical states needed to\nencode players' beliefs.\n▶In state ω, player i is informed that the state is in Ii(ω) and gets no\nother information.\n▶Such an information structure arises if each player observes a\nstate-dependent signal and Ii(ω) is the set of states for which player\ni's signal is identical to the signal at ω.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n33 / 69\n\nKnowledge and Common Knowledge\nDefinition 7\nFor any event F ⊆Ω, player i knows at ω that F obtains if Ii(ω) ⊆F . The\nevent that i knows F is\nKi(F) = {ω|Ii(ω) ⊆F}.\nThe event that everyone knows F is defined by\nK(F) = ∩i∈NKi(F).\nLet K 0(F) = F and K t+1(F) = K(K t(F)) for t ≥0. Set\nK inf(F) = T\nt≥0 K t(F). K inf(F) is the set of states where F is common\nknowledge.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n34 / 69\n\nPublic Events\nK(K inf(F)) = K inf(F) →alternative definition of common knowledge\nEvent F′ is public if F′ = ∪\n′\n′\nω′∈F′Ii(ω ) for all i. If F is public, then\nK(F′) = F′, so K inf(F′) = F′.\nLemma 1\nAn event F is common knowledge at ω iff there exists a public event F′\nwith ω ∈F′ ⊆F.\nIf F is common knowledge at ω, there exists a submodel that includes\nstate ω and respects the information structure where F is true state by\nstate.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n35 / 69\n\nStrategies\nFix a finite game (N, S, u). To give strategic meaning to information states,\nintroduce a strategy profile s : Ω→S.\nDefinition 8\nA strategy profile s : Ω→S is adapted with respect to (Ω, (Ii)i∈N, (pi)i∈N)\nif si(ω) = si(ω′) whenever Ii(ω) = Ii(ω′).\nPlayers must choose a constant action at all states in each information set\nsince they cannot distinguish states in the same information set.\nDefinition 9\nAn epistemic model (Ω, (Ii)i∈N, (pi)i∈N, s) consists of an information\nstructure and an adapted strategy profile.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n36 / 69\n\nCommon Knowledge of Rationality\nDefinition 10\nFor an epistemic model (Ω, (Ii)i∈N, (pi)i∈N, s), player i is rational at ω ∈Ωif\nX\nsi(ω)\n′\n′\n∈arg max\nui(si, s-j(ω ))pi,Ii(ω)(ω ).\nsiεSi ω′∈Ii(ω)\nDefinition 11\nA strategy si ∈Si consistent with common knowledge of rationality if\nthere exists a model (Ω, (Ij)j∈N, (pj)j∈N, s) and state ω∗∈Ωwith\nsi(ω∗) = si at which it is common knowledge that all players are rational.\nEquivalently, ∃(Ω, (Ij)j∈N, (pj)j∈N, s) s.t. sj(ω) is a best response to s-j at\neach ω ∈Ωfor every player j ∈N.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n37 / 69\n\nResult\nTheorem 4\nFor any i ∈N and si ∈Si, si is consistent with common knowledge of\nrationality iff si ∈Sinf\ni .\nCan extend result to allow for payoff uncertainty (adding the hypothesis\nthat payoffs are common knowledge at the relevant state).\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n38 / 69\n\nProof\n(⇒) Fix si consistent with common knowledge of rationality.\n∃(Ω, (Ij)j∈N, (pj)\n∗\n∗\nj∈N, s) with ω ∈Ωs.t. si(ω ) = si and\nX\nsj(ω) ∈arg max\nuj(sj, s\nω)(ω′\n-j(ω′))p ,\n), ∀j ∈\nj Ij(\nN, ω ∈Ω.\nsj∈Sj ω′∈Ij(ω)\nDefine Zj = s\n∗\nj(Ω). Note that si = si(ω ) ∈si(Ω) = Zi. By Theorem 3, to\nshow that si ∈Sinf\ni , it suffices to prove that Z is closed under rational\nbehavior.\n∀zj ∈Zj, ∃ω ∈Ωs.t. zj = sj(ω). Define μj,ω ∈∆(Z-j) by\nX\nμj,ω(s\npj,Ij( )(ω′\n-j) =\nω\n).\nω′∈Ij(ω),s-j(ω′)=s-j\nThen\nX\nzj = sj(ω) ∈arg max\nuj(sj, s-j(ω′))p\n(\n(ω′\ni,I ω)\n)\nsj∈S\nj\nj ω′∈I\nX\nj(ω)\n= arg max\nμj,ω(s-j)uj(sj, s-j).\nsj∈Sj s-j∈Z-j\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n39 / 69\n\nProof\n(⇐) Since Sinfis closed under rational behavior, for every si ∈Sinf\ni , there\nexists μi,si ∈∆(Sinf\n-i) for which si is a best response. Define the model\n(Sinf, (Ii)i∈N, (pi)i∈N, s) :\nIi(s)\n=\n{si} × Sinf\n-i\npi,s(s′)\n=\nμi,si\n\ns′\n-i\n\ns(s)\n=\ns\nIn this model, it is common knowledge that every player is rational:\n∀s ∈Sinf, si(s) = si ∈arg max\ns′\ni ∈Si\nX\ns-i∈Sinf\n-i\nui\n\ns′\ni , s-i\n\nμi,s\n\ns′\n-i\n\n= arg max\ns′\ni ∈Si\nX\ns′∈Ii(s)\nui\n\ns′\ni , s-i\n\npi,s(s′).\nFor every si ∈Sinf\ni , there exists s = (si, s-i) ∈Sinfs.t. si(s) = si, showing\nthat si is consistent with common knowledge of rationality.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n40 / 69\n\nNash Equilibrium\nMany games are not dominance solvable. Nevertheless, the involved\nparties find a solution.\nL\nR\nL\n1, 1\n0, 0\nR\n0, 0\n1, 1\nT\nS\nT\n3, 2\n1, 1\nS\n0, 0\n2, 3\nH\nT\nH\n1, -1\n-1, 1\nT\n-1, 1\n1, -1\nFigure: Coordination Game, Battle of the Sexes, Matching Pennies\nA Nash equilibrium is a strategy profile with the property that no player can\nbenefit by deviating from his corresponding strategy.\nDefinition 12 (Nash 1950)\nA mixed-strategy profile σ∗is a Nash equilibrium if for every i ∈N,\nui(σ∗\ni , σ∗\n-i) ≥ui(si, σ∗\n-i), ∀si ∈Si.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n41 / 69\n\nRemarks\n▶The fact that there is no profitable deviation in pure strategies implies\nthere is no profitable deviation in mixed strategies either.\n▶If in equilibrium a player uses a mixed strategy that places positive\nprobability on several pure strategies, he must be indifferent between\nall pure strategies in its support.\n▶Strategies that do not survive iterated strict dominance (or are not\nrationalizable) cannot be played with positive probability in a Nash\nequilibrium.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n42 / 69\n\nWhat Are the Assumptions?\n▶Nash equilibria are \"consistent\" predictions (or \"stable\" conventions)\nof how the game will be played.\n▶If all players expect that a specific Nash equilibrium will arise, then no\nplayer has incentives to play differently.\n▶Each player must have correct conjectures about the strategies of his\nopponents and play a best response to his conjecture.\n▶We interpret mixed strategies as beliefs regarding opponents' play,\nnot necessarily as deliberate randomization.\n▶Assumes knowledge of strategies (beliefs) and rationality.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n43 / 69\n\nDo Soccer Players Flip Coins?\nPenalty kicks\n▶Kicker's strategy space: {L,M,R}\n▶Goalie's strategy space: {L,M,R}\n▶What are the payoffs?\n▶What's the Nash equilibrium?\n▶Simultaneous move game? (125mph, 0.2 seconds reaction time)\n▶What do players do in reality?\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n44 / 69\n\nPenalty Kicks\nChiappori, Levitt, and Groseclose (2002)\n▶459 kicks in French and Italian first leagues\n▶162 kickers, 88 goalies\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n45 / 69\n(c) Pierre-Andre Chiappori, Steven Levitt, Tim Groseclose, American Economic Association. All\nrights reserved. This content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/.\n\nTennis Service Game\nPlayer 1 chooses whether to serve to player 2's forehand, center or\nbackhand side, and player 2 chooses which side to favor for the return.\nUnique mixed strategy equilibrium, which puts positive probability only on\nstrategies C and B for either player.\nF\nC\nB\nF\n0, 5\n2, 3\n2, 3\nC\n2, 3\n0, 5\n3, 2\nB\n5, 0\n3, 2\n2, 3\n▶For player 1, playing C with probability ε and B with probability 1 -ε s.\ndominates F.\n▶If player 1 never chooses F, then C s. dominates F for player 2.\n▶In the remaining 2 × 2 game, there is a unique equilibrium, in which\nboth players place probability 1/4 on C and 3/4 on B.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n46 / 69\n\nStag Hunt\nEach player can choose to hunt hare by himself or hunt stag with the\nother. Stag offers a higher payoff, but only if players team up.\nS\nH\nS\n9, 9\n0, 8\nH\n8, 0\n7, 7\nThe game has two pure strategy Nash equilibria--(S, S) and (H, H)--and\na mixed strategy Nash equilibrium--(7/8S + 1/8H, 7/8S + 1/8H).\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n47 / 69\n\nWhich Equilibrium is More Plausible?\n▶We may expect (S, S) to be played because it is Pareto dominant.\nHowever, if one player expects the other to hunt hare, he is much\nbetter off hunting hare himself; and the potential downside of\nchoosing stag is bigger than the upside--hare is the safer choice.\n▶Harsanyi and Selten (1988): H is the risk-dominant action--if each\nplayer expects the other to choose either action with probability 1/2,\nthen H has a higher expected payoff (7.5) than S (4.5).\n▶For a player to optimally choose stag, he should expect the other to\nplay stag with probability ≥7/8.\n▶Coordination problem may persist even if players communicate:\nregardless of what i intends to do, he would prefer j to play stag, so\nattempts to convince j to play stag are cheap talk.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n48 / 69\n\nEpistemic Foundations\n▶Aumann and Brandenburger (1995): a framework that can be used to\nexamine the epistemic foundations of Nash equilibrium.\n▶The primitive of their model is an interactive belief system in which\nthere is a possible set of types for each player; each type has\nassociated to it a payoff for every action profile, a choice of which\naction to play, and a belief about the types of the other players.\n▶In a 2-player game, if the game being played, the rationality of the\nplayers, and their conjectures are all mutually known, then the\nconjectures constitute a Nash equilibrium.\n▶For games with more than 2 players, we need to assume additionally\nthat players have a common prior and that conjectures are commonly\nknown. This ensures that any two players have identical and\nseparable (independent) conjectures about other players, consistent\nwith a mixed strategy profile.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n49 / 69\n\nEvolutionary Foundations\n▶Solution concepts motivated by presuming that players make\npredictions about their opponents' play by introspection and\ndeduction, using knowledge of their opponents' payoffs, rationality. . .\n▶Alternatively, assume players extrapolate from past observations of\nplay in \"similar\" games and best respond to expectations based on\npast observations.\n▶Cournot (1838) suggested that players take turns setting their outputs\nin the duopoly game, best responding to the opponent's last-period\naction.\n▶Simultaneous action updating, best responding to average play,\npopulations of players anonymously matched (another way to think\nabout mixed strategies), etc.\n▶If the process converges to a particular steady state, then the steady\nstate is a Nash equilibrium.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n50 / 69\n\nConvergence\nHow sensitive is the convergence to the initial state? If convergence\nobtains for all initial strategy profiles sufficiently close to the steady state,\nwe say that the steady state is asymptotically stable.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n51 / 69\nCourtesy of The MIT Press. Used with permission.\n\nShapley (1964) Cycling\nL\nM\nR\nU\n0, 0\n4, 5\n5, 4\nM\n5, 4\n0, 0,\n4, 5\nD\n4, 5\n5, 4\n0, 0\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n52 / 69\n\nRemarks\n▶Evolutionary processes are myopic and do not offer a compelling\ndescription of behavior.\n▶Such processes do not provide good predictions for behavior in the\nactual repeated game, if players care about play in future periods and\nrealize that their current actions can affect opponents' future play.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n53 / 69\n\nExistence of Nash Equilibrium\nL\nR\nL\n1, 1\n0, 0\nR\n0, 0\n1, 1\nT\nF\nT\n3, 2\n1, 1\nF\n0, 0\n2, 3\nH\nT\nH\n1, -1\n-1, 1\nT\n-1, 1\n1, -1\nFigure: Coordination Game, Battle of the Sexes, Matching Pennies\n▶The coordination game and the battle of the sexes have multiple\nequilibria.\n▶Matching pennies does not have a pure strategy equilibrium. In the\nunique equilibrium, both players mix 50-50.\nTheorem 5 (Nash 1950)\nEvery finite game has an equilibrium (potentially in mixed strategies).\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n54 / 69\n\nNash (1950)\n,→\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n55 / 69\n\nProof\nMihai Manea (MIT)\nGame Theory\nCourtesy of John F. Nash, Jr. \"Equilibirum Points in N-Person Games.\" Proceedings of the\nNational Academy of Sciences of the United States of America 36 no. 1 (1949): 48-49.\nFebruary 17, 2016\n56 / 69\n\nKakutani\nA long time ago, the Japanese mathematician Kakutani asked\nme why so many economists had attended the lecture he had\njust given. When I told him that he was famous because of the\nKakutani fixed-point theorem, he replied, 'What is the Kakutani\nfixed-point theorem?' (Ken Binmore, Playing for Real, 2007)\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n57 / 69\n\nExistence of Nash Equilibria\nProve the existence of Nash equilibria in a more general setting.\n▶Continuity and compactness assumptions are indispensable, usually\nneeded for the existence of solutions to optimization problems.\n▶Convexity is usually required for fixed-point theorems.\nNeed some topology prerequisites. . .\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n58 / 69\n\nCorrespondences\nTopological vector spaces X and Y\n▶A correspondence F : X ⇒Y is a set valued function taking elements\nx ∈X into subsets F(x) ⊆Y.\n▶G(F) = (x, y) |y ∈F (x) : graph of F\n▶x ∈X is a fixed point of F if x ∈F(x)\n▶F is non-empty/closed-valued/convex-valued if F (x) is\nnon-empty/closed/convex for all x ∈X.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n59 / 69\n\nClosed Graph\n▶A correspondence F has closed graph if G (F) is a closed subset of\nX × Y.\n▶If X and Y are first-countable spaces (such as metric spaces), then F\nhas closed graph iff for any sequence (xm, ym)m≥0 with ym ∈F (xm)\nfor all m ≥0, which converges to a pair (x, y), we have y ∈F (x).\n▶Correspondences with closed graph are closed-valued.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n60 / 69\n\nUpper Hemicontinuity\n▶A correspondence F is upper hemicontinuous at x ∈X if for every\nopen neighborhood VY of F (x), there exists a neighborhood VX of x\nsuch that x′ ∈VX ⇒F (x′) ⊂VY.\n▶Closed graph and upper hemicontinuity may have different\nimplications. The constant correspondence F : [0, 1] ⇒[0, 1] defined\nby F(x) = (0, 1) is upper hemicontinuous, but does not have a closed\ngraph.\nThe two concepts coincide for closed-valued correspondences in most\nspaces of interest.\nTheorem 6 (Closed Graph Theorem)\nA correspondence F : X ⇒Y with compact Hausdorff range Y is closed iff\nit is upper hemicontinuous and closed-valued.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n61 / 69\n\nThe Maximum Theorem\nTheorem 7 (Berge's Maximum Theorem)\nSuppose that f : X × Y →R is a continuous function, where X and Y are\nmetric spaces and Y is compact.\nThe function M : X →R, defined by\nM (x) = max\ny∈Y f (x, y) ,\nis continuous.\nThe correspondence F : X ⇒Y,\nF (x) = arg max\ny∈Y f (x, y)\nis nonempty valued and has a closed graph.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n62 / 69\n\nA Fixed-Point Theorem\nTheorem 8 (Kakutani's Fixed-Point Theorem)\nLet X be a non-empty, compact, and convex subset of a Euclidean space\nand let the correspondence F : X ⇒X have closed graph and non-empty\nconvex values. Then the set of fixed points of F is non-empty and\ncompact.\nIn game theoretic applications, X is usually the strategy space, assumed\nto be compact and convex when we include mixed strategies.\nF is typically the best response correspondence, which is non-empty\nvalued and has a closed graph by the Maximum Theorem.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n63 / 69\n\nConvexity\nTo ensure that F is convex-valued, assume that payoff functions are\nquasi-concave.\nDefinition 13\nIf X is a convex subset of a real vector space, then the function f : X →R\nis quasi-concave if\nf(tx + (1 -t)y) ≥min(f(x), f(y)), ∀t ∈[0, 1], x, y ∈X.\nQuasi-concavity implies convex upper contour sets and convex arg max.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n64 / 69\n\nExistence of Nash Equilibrium\nTheorem 9\nConsider a game (N, S, u) such that Si is a convex and compact subset of\na Euclidean space and that ui is continuous in s and quasi-concave in si\nfor all i ∈N. Then there exists a pure strategy Nash equilibrium.\nThe result implies the existence of pure strategy Nash equilibria in\ngeneralizations of the Cournot competition game.\nTheorem 9 also implies the existence of mixed strategy Nash equilibria in\nfinite games.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n65 / 69\n\nProof\n▶Let Bi (s-i) := arg maxs′∈Si ui(s′,\ni s-i) and define F : S ⇒S,\ni\nY\nF (s) = (s∗, . . . , s∗\n∗\n{\nn)|s ∈\ni\nBi (s-i) , ∀i ∈N}\n=\nBi (s-i) , ∀s ∈S.\ni∈N\n▶Since S is compact and the utility functions are continuous, the\nMaximum Theorem implies that Bi and F are non-empty valued and\nhave closed graphs.\n▶As ui is quasi-concave in si, the set Bi (s-i) is convex for all i and s-i,\nso F is convex-valued.\n▶Kakutani's fixed-point theorem ⇒F has a fixed point,\ns∗∈F (s∗) .\n\ns∗∈\ni\nBi s∗\n, ∀\n-i\ni ∈N ⇒s∗is a Nash equilibrium.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n66 / 69\n\nExistence of Mixed-Strategy Nash Equilibrium\nCorollary 3\nEvery finite game has a mixed strategy Nash equilibrium.\nProof.\nSince S is finite, each ∆(Si) is isomorphic to a simplex in a Euclidean\nspace, which is convex and compact. Player i's expected utility\nui (σ) = P\ns ui (s) σ1 (s1) · · · σn (sn) from a mixed strategy profile σ is\ncontinuous in σ and linear--hence also quasi-concave--in σi. The game\n(N, ∆(S1) , . . . , ∆(Sn) , u) satisfies the assumptions of Theorem 9.\nTherefore, it admits a Nash equilibrium σ∗∈∆(S1) × · · · × ∆(Sn), which\ncan be interpreted as a mixed Nash equilibrium in the original game.\n□\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n67 / 69\n\nUpperhemicontinuity of Nash Equilibrium\nFix N and S.\n▶X: compact metric space of payoff-relevant parameters\n▶S is a compact metric space (or a finite set)\n▶payoff function ui : S × X →R of every i ∈N is continuous in\nstrategies and parameters\n▶NE (x) and PNE (x): sets of Nash equilibria and pure Nash equilibria,\nresp., of game (N, S, u (·, x)) in which it is common knowledge that\nthe parameter value is x\n▶Endow the space of mixed strategies with the weak topology.\nTheorem 10\nThe correspondences NE and PNE have closed graphs.\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n68 / 69\n\nProof\nConsider any sequence (sm, xm) →(s, x) with sm ∈PNE (xm) for each m.\nSuppose that s < PNE (x). Then\nui\n\ns′\ni , s-i, x\n\n-ui (si, s-i, x) > 0\nfor some i ∈N, s′\ni ∈Si. Then (sm, xm) →(s, x) and the continuity of ui\nimply that\nui\n\ns′\ni , sm\n-i, xm\n-ui\n\nsm\ni , sm\n-i, xm\n> 0\nfor sufficiently large m. However,\nui\n\ns′\ni , sm\n-i, xm\n> ui\n\nsm\ni , sm\n-i, xm\ncontradicts sm ∈PNE (xm).\nMihai Manea (MIT)\nGame Theory\nFebruary 17, 2016\n69 / 69\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Global Games Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/a7e807e5ba593f24b61ac492fc57f50e_MIT14_126S16_globalgames.pdf",
      "content": "Global Games\n14.126 Game Theory\nMuhamet Yildiz\n\nMotivation\nMultiple equilibria exist in settings with\nstrategic complementarities\nInvestment/Development\nSearch\nBank runs\nCurrency attacks\nGlobal Games: introducing a certain type of\nincomplete information leads to a unique\nequilibrium prediction.\n\nA partnership game\nInvest\nNot-Invest\nInvest\n\nNot-Invest\n\nis common knowledge\n< 0\nInvest\nNot-Invest\nInvest\n\nNot-Invest\n\nInvest\n\nis common knowledge\n> 1\nInvest\nNotInvest\nInvest\n\nNotInvest\n\nNotInvest\n\nis common knowledge\n< 1\nInvest\nNot-Invest\nInvest\n\nNot-Invest\n\nMultiple Equilibria\n\nis common knowledge\nNot-Invest\nMultiple\nInvest\nEquilibria\n\nis not common knowledge\nis uniformly distributed over a large interval\nEach player i gets a signal\nxi = +\ni\n(\n1,\n2) is bounded\nIndependent of\niid with continuous F (common knowledge)\nE[\ni] = 0\n\nRecall: Monotone supermodular games\nG = (N,T,A,u,p)\nT = T0 T1 ... Tn ( RM)\nA\nK\ni compact sublattice of R\nui : A T\nui(a,.): T\n\nui(. ,t): A\n\nsupermodular in ai,\nhas increasing differences in a and in (ai,t)\np(.|ti) is increasing function of ti--in the sense of 1st-order\nstochastic dominance (e.g. p is affiliated).\nTheorem: There exist BNE s* and s** such that\nFor each BNE s, s* s s**.\nBoth s* and s** are isotone.\n\nConditional Beliefs given xi\nd xi -\ni\ni.e. Pr(xi) = 1-F((xi-)/ ):=G(xi)\nxj d xi +\nj-\ni)\nPr(xjxjxi) = Pr( (\nj -\ni) xj\ni\n- x)\nPr( xj xjxi) =\n(\n{\n(\n}\nxj )/)( |\n) decreasing in xi\nbecause integrand decreasing in and G(xi)\nFOSD G(xi) whenever xi xi\n\nE[|xi] = xi\n\nPayoffs\nInvest > Not-Invest\nUi(ai,aj,x) is\nsupermodular.\nMonotone supermodular\nThere exist greatest and\nsmallest rationalizable\nstrategies, which are\nBayesian Nash Equilibria\nMonotone (isotone)\nInvest\nNot-Inv\nInvest\n\n-1\nNot-Inv\n\nMonotone BNE\nBest response\nInvest iff xi Pr(sj = Not-Invest|xi)\nAssume supp() = [a,b] where a < 0 < 1 < b.\nxi < 0 si(xi) = Not Invest\nxi > 1 si(xi) = Invest\nA cutoff xi* s.t.\nxi < xi* si(xi) = Not Invest; xi > xi* si(xi) = Invest\nSymmetry: x1* = x2* = x*\nx* = Pr(sj = Not-Invest|x*) = Pr(xj < x*|xi=x*) = 1/2\n\"Unique\" BNE\n\nQuestions\nWhat is the smallest BNE?\nWhat is the largest BNE?\nWhich strategies are rationalizable?\nCompute directly.\n\nis not common knowledge\nbut the noise is very small\nIt is very likely that\nNot-Invest\nInvest\n\n1/2\n\nRisk-dominance\nIn a 2 x 2 symmetric game, a strategy is said to be\n\"risk dominant\" iff it is a best reply when the other\nplayer plays each strategy with equal probabilities.\nInvest\nNot-Invest\nInvest\n\nInvest is RD iff\n\nNot-Invest\n\nPlayers play according to risk dominance\n\nCarlsson & van Damme\n\nRisk Dominance\nSuppose that (A,A) and\nA\nB\n(B,B) are NE.\nA\nu11,v11\nu12,v\n\n(A,A) is risk dominant if\n(u11-u21)(v -\nu21,v\n11 v12)\nB\nu22,v22\n(u22-u12) (v22-v21)\nAffine transformation: g a\n1 ...\n(A,A) risk dominant if\ng a\n1 g a\n2 > g b\n1 g b\ni is indifferent against sj;\n(A,A) risk dominant if\ns1 + s2 < 1\nA\nB\nA\ng a\n1 , g a\n0,0\n0,0\nB\ng b\n1 , g b\n\nDominance, risk-dominance regions\nDominance region\nD a\ni ={(u,v)| g a\ni >0, g b\ni <0}\nRisk-dominance region\nRa ={(u,v)| g a\n1 >0,g a\n2 >0; g b\n1 , g b\n2 >0 s1 + s2 < 1}\n\nModel\nRm is open; (u,v) are continuously differentiable\nfunctions of w/ bounded derivatives;\nprior on has a density h which is strictly positive,\ncontinuously differentiable, bounded.\nEach player i observes a signal\nxi = +\ni\n(\n1,\n2) is bounded,\nIndependent of ,\nAdmits a continuous density\n\nTheorem\nSuppose that\nx is on a continuous curve C\n(u(c),v(c)) Ra for each cC\n(u(c),v(c)) Da for some cC.\nThen A is the only rationalizable action at x\nwhen is small.\n\n\"Public\" Information\n\n~ N(y,2) and\ni ~ N(0,2)\n\nGiven xi,\n~ N(rx\ni+(1-r)y, r)\nxj ~ N(rxi+(1-r)y, 2(r+1))\nr = 2/(2+2)\n\n(Monotone supermodularity) monotone symmetric NE w/cutoff xc:\n\nUnique monotone NE (and rationalizable strategy) if\nis increasing in xc whenever zero, i.e.,\n< 24(r+1)\nr\nc\nc\n% (1 )(x y)\"\nrx (1 r )y Pr(x\nc\nj ' x | x xc\ni\n) &#\n\n#\n\n$\n\nr 1\n!\nrxc (1 r )y Pr(x\nc |\nc\nj ' x\nxi x )\n\nCourtesy of Stephen Morris and Hyun Song Shin. Used with permission.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Repeated Games Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/3fc58b6d07a73055a44dcbc5aaacc738_MIT14_126S16_Repeated.pdf",
      "content": "Repeated Games\nMihai Manea\nMIT\n\nRepeated Games with Perfect\nInformation\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n2 / 47\n\nRepeated Games with Perfect Information\n▶normal-form stage game G = (N, A, u)\n▶players simultaneously play game G at time t = 0, 1, . . .\n▶at each date t, players observe all past actions: ht = (a0, . . . , at-1)\n▶common discount factor δ ∈(0, 1)\n▶payoffs in the repeated game RG(δ) for h = (a0, a1, . . .):\nP\nUi(h) = (1\nt\nt\n-δ)\ninf\nδ\nt=0\nui(a )\n▶normalizing factor 1 -δ ensures payoffs in RG(δ) and G are on same\nscale\n▶behavior strategy σi for i ∈N specifies σi(ht) ∈∆(Ai) for every\nhistory ht\nCan check if σ constitutes an SPE using the single-deviation principle.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n3 / 47\n\nMinmax\nMinmax payoff of player i: lowest payoff his opponents can hold him down\nto if he anticipates their actions,\nvi =\nmin\nα-i∈Q\nj,i ∆(Aj)\n\"\nmax\nai∈Ai\nui(ai, α-i)\n#\n▶mi: minmax profile for i, an action profile (ai, α-i) that solves this\nminimization/maximization problem\n▶assumes independent mixing by i's opponents\n▶important to consider mixed, not just pure, actions for i's opponents:\nin the matching pennies game the minmax when only pure actions\nare allowed for the opponent is 1, while the actual minmax, involving\nmixed strategies, is 0\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n4 / 47\n\nEquilibrium Payoff Bounds\nIn any SPE--in fact, any Nash equilibrium--i's obtains at least his minmax\npayoff: can myopically best-respond to opponents' actions (known in\nequilibrium) in each period separately. Not true if players condition actions\non correlated private information!\nA payoff vector v ∈RN is individually rational if vi ≥vi for each i ∈N, and\nstrictly individually rational if the inequality is strict for all i.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n5 / 47\n\nFeasible Payoffs\nSet of feasible payoffs: convex hull of {u(a) | a ∈A}. For a common\ndiscount factor δ, normalized payoffs in RG(δ) belong to the feasible set.\nSet of feasible payoffs includes payoffs not obtainable in the stage game\nusing mixed strategies. . . some payoffs require correlation among players'\nactions (e.g., battle of the sexes).\nPublic randomization device produces a publicly observed signal\nt\nω ∈[0, 1], uniformly distributed and independent across periods. Players\ncan condition their actions on the signal (formally, part of history).\nPublic randomization provides a convenient way to convexify the set of\npossible (equilibrium) payoff vectors: given strategies generating payoffs v\nand v′, any convex combination can be realized by playing the strategy\ngenerating v conditional on some first-period realizations of the device and\nv′ otherwise.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n6 / 47\n\nNash Threat Folk Theorem\nTheorem 1 (Friedman 1971)\nIf e is the payoff vector of some Nash equilibrium of G and v is a feasible\npayoff vector with vi > ei for each i, then for all sufficiently high δ, RG(δ)\nhas SPE with payoffs v.\nProof.\nSpecify that players play an action profile that yields payoffs v (using the\npublic randomization device to correlate actions if necessary), and revert\nto the static Nash equilibrium permanently if anyone has ever deviated.\nWhen δ is high enough, the threat of reverting to Nash is severe enough to\ndeter anyone from deviating.\n□\nIf there is a Nash equilibrium that gives everyone their minmax payoff\n(e.g., prisoner's dilemma), then every strictly individually rational and\nfeasible payoff vector is obtainable in SPE.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n7 / 47\n\nGeneral Folk Theorem\nMinmax strategies often do not constitute static Nash equilibria. To\nconstruct SPEs in which i obtains a payoff close to vi, need to threaten to\npunish i for deviations with even lower continuation payoffs. Holding i's\npayoff down to vi may require other players to suffer while implementing\nthe punishment. Need to provide incentives for the punishers. . . impossible\nif punisher and deviator have indetical payoffs.\nTheorem 2 (Fudenberg and Maskin 1986)\nSuppose the set of feasible payoffs has full dimension |N|. Then for any\nfeasible and strictly individually rational payoff vector v, there exists δ such\nthat whenever δ > δ, there exists an SPE of RG(δ) with payoffs v.\nAbreu, Dutta, and Smith (1994) relax the full-dimensionality condition: only\nneed that no two players have the same payoff function (equivalent under\naffine transformation).\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n8 / 47\n\nProof Elements\n▶Assume first that i's minmax action profile mi is pure.\n▶Consider an action profile a for which u(a) = v (or a distribution over\nactions that achieves v using public randomization).\n▶By full-dimensionality, there exists v′ in the feasible individually\nrational set with vi < v′\ni < vi for each i.\n▶Let wi be v′ with ε added to each player's payoff except for i; for small\nε, wi is a feasible payoff.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n9 / 47\n\nEquilibrium Regimes\n▶Phase I: play a as long as there are no deviations. If i deviates,\nswitch to IIi.\n▶Phase IIi: play mi for T periods. If player j deviates, switch to IIj. If\nthere are no deviations, play switches to IIIi after T periods.\n▶If several players deviate simultaneously, arbitrarily choose a j among\nthem.\n▶If mi is a pure strategy profile, it is clear what it means for j to deviate. If\nit requires mixing. . . discuss at end of the proof.\n▶T independent of δ (to be determined).\n▶Phase IIIi: play the action profile leading to payoffs wi forever. If j\ndeviates, go to IIj.\nSPE? Use the single-shot deviation principle: calculate player i's payoff\nfrom complying with prescribed strategies and check for profitable\ndeviations at every stage of each phase.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n10 / 47\n\nDeviations from I and II\nPlayer i's incentives\n▶Phase I: deviating yields at most (1 -δ)M + δ(1 -δT)v\nT\n+ δ +1\ni\nv′\ni ,\nwhere M is an upper bound on i's feasible payoffs, and complying\nyields vi. For fixed T, if δ is sufficiently close to 1, complying produces\na higher payoff than deviating, since v′ <\ni\nvi.\n▶Phase IIi: suppose there are T′ ≤T remaining periods in this phase.\nThen complying gives i a payoff of (1\nT\n-δ\n′)vi + δT′v′\ni , whereas\ndeviating can't help in the current period since i is being minmaxed\nand leads to T more periods of punishment, for a total payoff of at\nmost (1 -δT+1)vi + δT+1v′\ni . Thus deviating is worse than complying.\n▶Phase IIj: with T′ remaining periods, i gets\n(1 -δT′)ui(mj) + δT′(v′\ni + ε) from complying and at most\n(1 -δ)M + (δ -δT+1)vi + δT+1v′\ni from deviating. For high δ,\ncomplying is preferred.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n11 / 47\n\nDeviations from III\nPlayer i's incentives\n▶Phase IIIi: determines choice of T. By following the prescribed\nstrategies, i receives v′\ni in every period. A (one-shot) deviation leaves\ni with at most (1 -δ)M + δ(1\nT\n-δ )vi + δT+1v′\ni . Rearranging, i\ncompares between (δ + δ2 + . . . + δT)(v′\ni -vi) and M -v′\ni . For any\nδ ∈(0, 1), ∃T s.t. former term is grater than latter for δ > δ.\n▶Phase IIIj: Player i obtains v′\ni + ε forever if he complies with the\nprescribed strategies. A deviation by i triggers phase IIi, which yields\nat most (1 -δ)M + δ(1 -δT)vi + δT+1v′\ni for i. Again, for sufficiently\nlarge δ, complying is preferred.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n12 / 47\n\nMixed Minmax\nWhat if minmax strategies are mixed? Punishers may not be indifferent\nbetween the actions in the support. . . need to provide incentives for mixing\nin phase II.\nChange phase III strategies so that during phase IIj player i is indifferent\namong all possible sequences of T realizations of his prescribed mixed\naction under mj. Make the reward εi of phase IIIj dependent on the history\nof phase IIj play.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n13 / 47\n\nDispensing with Public Randomization\nSorin (1986) shows that for high δ we can obtain any convex combination\nof stage game payoffs as a normalized discounted value of a deterministic\npath (u(at)). . . \"time averaging\"\nFudenberg and Maskin (1991): can dispense of the public randomization\ndevice for high δ, while preserving incentives, by appropriate choice of\nwhich periods to play each pure action profile involved in any given convex\ncombination. Idea is to stay within\nε of target payoffs at all stages.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n14 / 47\n\nRepeated Games with Fixed Discount Factor\n▶Folk theorem concerned with limit δ →1\n▶many payoffs possible in SPE\n▶elaborate hierarchies of punishments needed\n▶Equilibrium outcomes for fixed δ < 1?\n▶Abreu (1988): equilibrium strategies can be enforced by using worst\npunishment for every deviator\n▶Is there a worst possible punishment?\nTheorem 3 (Abreu 1988)\nAssume that\naction sets in stage game are compact subsets of Euclidean spaces;\npayoffs in stage game are continuous in actions;\nthere exists a pure-strategy SPE.\nThen among all pure-strategy SPEs, there is one that is worst for player i.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n15 / 47\n\nProof\n▶a = (at)t≥0: play path\n▶Ui(a): i's payoff in repeated game for path a\n▶equilibrium play path: play path of some pure-strategy SPE\n▶y(i) = inf{Ui(a)|a equilibrium play path}\n▶y(i) well-defined, set of equilibrium play paths is nonempty\n∃ai,k\n: sequence of equilibrium play paths s.t. U ai k\n▶\n(\n)k≥0\ni(\n, )\ny(i\nQ\n)\nA sequentially compact, convergent subsequence ai,k\n→\n▶\nt≥0\n→ai,inf\n(product topology)\n▶U\ni\ni(a ,inf) = y(i) by continuity of Ui\ni\n▶Prove that a ,infis an equilibrium play path. Candidate SPE\n▶in regime i, players follow strategies ai,inf\n▶play starts in regime i\n▶deviation by player j from current regime leads to regime j\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n16 / 47\n\nProof\nOne-shot deviation principle\n▶Consider deviation by player j from stage τ of regime i to action baj\n▶Show that j's one-shot deviation is not profitable,\nX\ninf\n(1\nt\ni,inf\ni,inf\n-δ)\nδ uj(a\n(τ + t)) ≥(1 -δ)uj(baj, a-(τ)) + δ\nj\ny(j).\nt=0\n▶For each k, there is some SPE whose play path is ai,k\n▶j does not have incentives to deviate to baj at τ\n▶j's continuation payoff is at least y(j) following any deviation (definition\nof y(j))\n▶For all k,\nX\ninf\n(1\nt\ni,k\n-δ)\nδ uj(a\n(τ + t\nb\nk\n))\na ,\n≥(1 -δ)uj(a\ni\nj,\n-(τ)) + δ\nj\ny(j).\nt=0\n▶Taking limit k →inf, we obtain desired inequality.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n17 / 47\n\nOptimal Penal Codes\n▶Optimal penal code for i: SPE giving i lowest possible payoff\n▶Showed existence of optimal penal codes for pure-strategy SPEs\n▶If stage game is finite, pure-strategy SPEs may not exist.\n▶Optimal penal codes for mixed-strategy SPEs?\nTheorem 4 (Fudenberg and Levine 1983)\nAssume that the stage game is finite. Then the set of SPE strategies and\npayoffs are nonempty and compact. In particular, among all SPEs, there is\none that is worst for player i.\nConclusion extends to multistage games with observable actions that have\na finite set of actions at every stage and are continuous at infinity.\nFudenberg and Levine used ε-perfect equilibria of finite-horizon\ntruncations.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n18 / 47\n\nProof\nQ\nQ\n▶\nht\ni ∆(Ai): set of mixed strategies (with product topology)\nQ\nQ\n▶\nht\ni ∆(Ai) is compact (Tychonoff's theorem)\n▶Payoffs in repeated game are continuous in strategies\n▶take a sequence of strategies (σn) converging to σ as n →inf\n▶for any date t, the distribution over histories/actions induced by σn at t\nalso converges to the one induced by σ\n▶expected payoffs at t under σn converge to those under σ\n▶Since payoffs are continuous, the set of SPEs is closed.\n▶Since set of strategies is compact, set of SPEs is compact (closed\nsubsets of compact sets are compact).\n▶Since payoffs are continuous in strategies and set of SPEs is\ncompact, the set of SPE payoffs is also compact.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n19 / 47\n\nEquilibrium Outcomes and Optimal Penal Codes\nTheorem 5 (Abreu 1988)\nAny SPE distribution over play paths can be generated by an SPE\nenforced by optimal penal codes off path, i.e., when i is the first deviator,\ncontinuation play follows the optimal penal code for i.\nFix SPE σˆ. Modify σˆ by replacing play off-path by the optimal penal code\nfor i when i is the first deviator. Modified strategy profile is an SPE.\nSufficient to check that on-path one-shot deviations are not profitable.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n20 / 47\n\nGeneralized Cournot Oligopoly\nAbreu (1986): application of Abreu (1988) to symmetric settings\n▶set of actions: [0, inf)\n▶∃M s.t. actions above M are never rational\n▶payoffs continuous and bounded from above\n▶C1: ui(a, . . . , a) is quasi-concave and decreases unboundedly in a\n▶C2: maxai∈Ai ui(ai, a . . . , a) is decreasing in a\nStrongly symmetric equilibria: equilibria in which all players behave\nidentically at every history, including asymmetric histories.\nThere is a strongly symmetric equilibrium that is worst for all players.\nThere is also a strongly symmetric equilibrium that is best for everyone.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n21 / 47\n\nExtremal Equilibria\nTheorem 6\nLet e∗and e∗denote the highest and lowest payoff per player in a\npure-strategy strongly symmetric equilibrium.\n▶The payoff e∗can be attained in an equilibrium with strongly\nsymmetric strategies of the following form: \"Begin in phase A, where\nplayers choose an action a∗that satisfies\n(1 -δ)u(a∗, . . . , a∗) + δe∗= e∗.\nIf there are no deviations, switch to an equilibrium with payoff e∗\n(phase B). Otherwise, continue in phase A.\"\n▶Phase B: the payoff e∗can be attained with strategies that play a\nconstant action a∗as long as there are no deviations and switch to\nthe worst strongly symmetric equilibrium (phase A) if there are any\ndeviations.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n22 / 47\n\nProof of First Part\nExistence of a∗\n▶σˆ: strongly symmetric equilibrium with payoff e∗and period 1 action a\n▶continuation payoffs under σˆ cannot be more than e∗, so\nui(a, . . . , a) ≥(-δe∗+ e∗)/(1 -δ).\n▶By C1, there is a∗≥a s.t. u(a∗, . . . , a∗) = (-δe∗+ e∗)/(1 -δ).\nLet σ∗denote the strategies constructed for phase A. No profitable\ndeviation in first period of σˆ ⇒no profitable deviation in phase A of σ∗\n▶by C2 and a∗≥a, short-run gain from deviating in phase A is not\nmore than that in the first period of σˆ\n▶punishment for deviating in phase A is worst possible\nPhase B: σ∗subgame perfect by definition\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n23 / 47\n\nDiscussion\n▶C1: punishments can be made arbitrarily bad.\n▶Good equilibrium can be sustained by one-shot punishments.\n▶Extremal equilibria described by two numbers a∗and a∗.\n▶Stick and carrot: first-period deviation leads to one period of\npunishment with (a∗, . . . , a∗) and playing (a∗, . . . , a∗) thereafter.\n▶(a∗, a∗): highest and lowest action s.t.\nmax ui(ai, a∗-i) -u (\n∗\ni a∗, . . . , a∗)\n=\nδ(ui(a∗, . . . , a ) -ui(a∗, . . . , a∗))\nai∈Ai\nmax u (a , a∗)\nu (a∗, . . . , a∗\ni\ni\n-\n-\ni\n)\n=\nδ(\n) -\ni\nui(a∗, . . . , a∗\nui(a∗, . . . , a∗))\nai∈Ai\n▶Typically best outcome is better (and worst is worse) than static Nash.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n24 / 47\n\nRepeated Games with Imperfect\nPublic Monitoring\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n25 / 47\n\nImperfect Public Monitoring\nPlayers only observe noisy signal of others' past actions\n▶y: public signal\n▶πy(a): distribution of y conditional on action profile a\n▶ri(ai, y): i's payoff\nP\n▶ui(a) =\ny∈Y ri(ai, y)πy(a): i's expected payoff\nGreen and Porter's (1984) collusion model\n▶Players: firms in a cartel setting production quantities\n▶Public signal: market price, stochastic function of quantities\n(unobserved demand shock each period)\n▶Payoff: product of price and own quantity\n▶Firms are trying to keep quantities low and prices high.\n▶But low prices may come from deviations or demand shocks.\n▶How to detect and punish deviations?\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n26 / 47\n\nGreen and Porter (1984)\nGreen and Porter focus on threshold equilibria\n▶Play collusive action profile aˆ for a while.\n▶If y > yˆ, revert to static Nash for T periods, then return to collusion.\nEquilibrium values (after normalizing static Nash payoffs to 0)\nv\nT\nˆi = (1 -δ)ui(aˆ) + δλ(aˆ)vˆi + δ(1 -λ(aˆ))δ vˆi,\nwhere λ(a) = P(y > yˆ|a). Rearranging,\n(1 -δ)ui(aˆ)\nvˆi = 1 -δλ(ˆa) -δT+1(1 -λ(ˆa)).\nNo player wants to deviate in the collusive phase: for all a′\ni\nui(a′\ni , ˆa-i) -ui(ˆa) ≤\nδ(1 -δT)(λ(ˆa) -λ(a′\ni , ˆa-i))ˆvi\n1 -δ\n=\nδ(1 -δT)(λ(ˆa) -λ(a′\ni , ˆa-i))ui(ˆa)\n1 -δλ(ˆa) -δT+1(1 -λ(ˆa))\n.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n27 / 47\n\nDiscussion\nIncentive constraints compare\n▶short-term incentives to deviate\n▶relative probability of triggering punishment by deviating\n▶severity of punishment\nPossible to sustain payoffs above static Nash for high δ: incentive\nconstraints hold for T = infand aˆ just below static Nash, with low yˆ and\nsome bounds on the derivative of λ.\nGreen and Porter did not identify the best possible equilibria. There can be\nworse punishments than static Nash.\nNeed a more general theory to find better equilibria.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n28 / 47\n\nAbreu, Pearce, and Stacchetti (APS) (1990)\n▶Ai and Y finite\n▶πy(α): distribution of y given mixed action profile α\nt\n▶h = (\ni\ny0, . . . , yt-1; a0, . . . ,\ni\nat-1)\ni\n: private history\n▶ht = (y0, . . . , yt-1): public history\nAPS assume continuum of signals and restrict attention to pure strategies.\nA strategy for player i is a public strategy if depends only public history.\nLemma 1\nEvery pure strategy σi is equivalent to a public strategy σ′\ni .\nProof.\nDefine σ′\ni on lenght-t histories by induction: for each s < t\nσ′\ni(y0, . . . , yt-1) = σi(y0, . . . , yt-1; a0\ni , . . . , at-1\ni\n),\nwhere as\ni = σ′\ni(y0, . . . , ys-1). σ′\ni is equivalent to σi: they differ only at\n\"off-path\" histories reachable only by deviations of player i.\n□\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n29 / 47\n\nPublic Perfect Equilibirum (PPE)\nLemma shows that public strategies are without loss if attention is\nrestricted to pure strategies, which is a nontrivial restriction.\nFudenberg, Levine, and Maskin (1994): restrict attention to public (but\npotentially mixed) strategies.\nLemma 2\nIf opponents use public strategies, then i has a best response in public\nstrategies.\nProof.\nAt every date, i always what the other players will play, since their actions\ndepend only on the public history; hence i can just play a best response to\ntheir anticipated future play, which does not depend on i's private history of\npast actions.\n□\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n30 / 47\n\nDiscussion of PPE\nPerfect public equilibrium: public strategies σ s.t., at every public history\nht, the strategies σi|ht form a Nash equilibrium of the continuation game.\nAllows for deviations to non-public strategies, but such deviations are\nirrelevant by Lemma 2.\nPPE adapts SPE to this setting (in general, no subgames).\nSet of PPE is stationary: same at every history\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n31 / 47\n\nSet of SE is Not Stationary\nA player may want to condition his play in one period on the realization of\nhis mixing in a previous period. Correlation across periods can be\nself-sustaining.\n▶Assume i and j both mixed at a previous period.\n▶The signal in that period informs i about the realization of j's mixing.\n▶Hence it is informative about what j will do in the current period,\naffecting i's current best response.\n▶Some third player k may be unable to infer what j will do in the current\nperiod, since he does not know what i played in the earlier period.\n▶Different players can have different beliefs about play at t.\n▶Stationarity is lost.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n32 / 47\n\nEnforceability\n(α, v) ∈Q\ni ∆(Ai) × Rn enforceable w.r.t. W ⊆Rn if there is w : Y →W s.t.\nvi = (1 -δ)ui(α) + δ\ny\nX\nπy(α)wi(y)\n∈Y\nand for all i and ai\n′ ∈Ai,\nvi ≥(1 -δ)ui(ai\n′, α i) + δ\nX\nπy(a′, α i)\ni\nw y\n-\n-\ni( ).\ny∈Y\nIncentive-compatible for each player to play according to α in the present\nperiod if continuation payoffs are given by w; expected present payoffs are\nv.\nB(W): set of v enforceable w.r.t. W for some α\nTheorem 7\nLet E be the set of PPE payoff vectors. Then E = B(E).\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n33 / 47\n\nProof\nE ⊆B(E)\n▶Suppose v ∈E, generated by PPE strategies σ.\n▶Let αi = σi(∅) and wi(y) be continuation payoff under σ given y.\n▶w(y) ∈E since play in subsequent periods forms a PPE.\n▶v ∈B(E) since (α, v) is enforced by w on E.\nB(E) ⊆E\n▶Suppose v ∈B(E) with (α, v) enforced by w on E.\n▶Define public strategies σ\n▶Play α in the first period.\n▶After y, follow PPE with payoffs w(y).\n▶σ is a PPE by the one-shot deviation principle.\n▶v ∈E since v is the payoff vector generated by σ.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n34 / 47\n\nSelf-Generating Sets\nDefinition 1\nW ⊆Rn is self-generating if W ⊆B(W).\nE is self-generating.\nTheorem 8\nIf W is a bounded self-generating set, then W ⊆E.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n35 / 47\n\nProof\nGiven v ∈W, we construct a PPE with payoffs v recursively by specifying\ncurrent play and continuation payoffs in W for every public strategy\n▶Base case (before game starts): continuation payoffs v\n▶Assume we have specified\n▶Play for periods 0, . . . , t -1\n▶Continuation payoffs in W for each history y0, . . . , yt-1\n▶Fix some history y0, . . . , yt-1 and continuation payoffs v′ ∈W.\n▶W ⊆B(W): pick α and w : Y →W s.t. (α, v′) enforced by w\n▶Specify play α at history y0, . . . , yt-1.\n▶Let w(y) be continuation payoffs if signal y is observed next.\nDo strategies implement desired payoffs?\nT\nv -(1 -δ)\nX\ntδ E[u\nt\nT\n(α )] = δ +1E[w(yT)],\nt=0\nRight-hand side goes to zero as T →inf(W bounded).\nConstructed strategies form a PPE by the one-shot deviation principle.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n36 / 47\n\nMonotonicity of PPE Payoffs in δ\nE(δ): set of PPE payoffs when discount factor is δ\nTheorem 9\nAssume E(δ) is convex (e.g., public randomization device). If δ1 < δ2, then\nE(δ1) ⊆E(δ2).\nProof.\nBy previous theorem, enough to show that E(δ1) ⊆B(E(δ1), δ2). Take\nv ∈E(δ1) = B(E(δ1), δ1). Find α and w that enforce v for discount factor\nδ1. By replacing w by a suitable convex combination of w and (the\nconstant function) v, we can enforce (α, v) for δ2.\n□\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n37 / 47\n\nCharacterization of PPE Payoffs\nProperties of B operator\n▶If W is compact, then B(W) is compact.\n▶B is monotone: if W ⊆W′, then B(W) ⊆B(W′).\n▶If W is nonempty, then B(W) is nonempty.\n▶If α is a Nash equilibrium of the stage game, w : Y →W a constant\nfunction, and v the resulting payoffs, then v ∈B(W).\nV: set of all feasible payoffs; nonempty compact\n(Bk\nk\n(V))k≥0: B (V) = V and B (V) = B(Bk-1(V)) for k = 1, 2, . . .\nBinf(V\nk\n) = ∩kB (V): intersection of a decresing sequence of non-empty\ncompact sets, hence nonempty and compact\nTheorem 10\nE = Binf(V). In particular, E is nonempty and compact.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n38 / 47\n\nProof\nProve that Binf(V) ⊆E by showing that Binf(V) is self-generating\n▶Suppose v ∈Binf(V).\n▶∃\nk\n(α , wk)k 1:\nv\nk\n≥\n(αk, ) enforced by w\n: Y\nBk-1(V)\ninfwinf: some limit point of\nk wk\n→\n▶(α ,\n)\n(α ,\n)k 0 (exists by compactness)\n≥\nwinfy ∈BinfV since for all k, winfy limit point of closed Bk\n▶\n( )\n( )\n( )\n(V)\n▶By continuity, (αinf, v) enforced by winf: Y →Binf(V)\nE ⊆Binf(V)\n▶E ⊆V implies E = B(E) ⊆B(V)\n▶By induction, E ⊆Bk(V) for all k.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n39 / 47\n\nBang-Bang Property\next(W): set of extreme points of W\nw : Y →W has the bang-bang property if w(y) ∈ext(W) for each y\nAPS: finite action spaces and continuous signals (common support)\nAPS: if (α, v) enforceable on compact W, then enforceable on ext(W)\nCorollary: every vector in E can be achieved as the vector of payoffs from\na PPE s.t. the vector of continuation payoffs at every history lies in ext(E)\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n40 / 47\n\nFolk Theorem for Imperfect Public Monitoring\nFudenberg, Levine, and Maskin (1994) approximate set of feasible\nindividually rational payoffs with \"smooth\" convex sets W that are\nself-generating for δ high enough.\nKey assumptions on informativeness of public signals about actions\n▶Individual full-rank: given α-i, the different signal distributions\ngenerated by varying i's pure actions ai are linearly independent. . . If\nαi and α′\ni generate the same distribution over signals given α-i and\nui(α′, α\ni\n-i) > ui(α), then it is impossible to enforce α in equilibrium.\n▶Pairwise full rank: deviations by player i are \"statistically\ndistinguishable\" from deviations by player j\n▶For any α, build two matrices whose rows represent signal distributions\nfrom (ai, α-i) and (aj, α-j) as ai and aj varies, resp.\n▶The stacked matrix has rank |Ai| + |Aj| -1.\n▶Intuitively, players need to know who to punish.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n41 / 47\n\nLocally Self-Generating Sets\nW locally self-generating: ∀v ∈W, ∃open neighborhood U and δ < 1 s.t.\nU ∩W ⊆B(W) when δ > δ.\nIf W compact and convex, then local self-generation implies\nself-generation for δ high enough.\nWe can use full-rank conditions to show that W is locally self-generating.\nFocus on boundary points W. . . interior points can then be achieved with\npublic randomization devices.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n42 / 47\n\n\"Proof\" of Local Self-Generation\n▶By pairwise full-rank, we can \"transfer\" continuation payoffs between\ntwo players in any desired ratio, depending on the signal. . . pairwise\nhyperplanes.\n▶We can \"decompose\" regular tangent hyperplanes using pairwise\nhyperplanes.\n▶Need individual full rank to enforce payoffs on coordinate hyperplanes\n▶Both individual and pairwise full rank needed only for a subset of\naction profiles. . . \"mixing in\" any such profile with small probability\ngenerates a dense set of profiles with full rank.\n▶Then any payoff vector v on the boundary of W is enforceable by\ncontinuation payoffs that lie below the tangent hyperplane to W at v.\n▶Using \"discount factor transformation\" (Theorem 9), the continuation\npayoffs that enforce v contract toward v at rate 1 -δ as δ →1.\n▶Since W is smooth, a translate of the tangent\n√\nhyperplane at distance\nof order 1 -δ has \"diameter\" of order\n1 -δ, so continuation payoffs\nlie inside W for high δ.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n43 / 47\n\nChanging the Information Structure with Time Period\nSuppose time is continuous.\nPlayers can only update actions at dates t, 2t, . . ..\nr: discount rate; δ = e-rt: discount factor\nδ →1 because\n▶r →0: players become patient\n▶t →0: periods become short\nAbreu, Milgrom, and Pearce (1991): limits r →0 and t →0 may lead to\ndistinct predictions if quality of public signals deteriorates as t →0.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n44 / 47\n\nSetup\nStage game: partnership game (prisoners' dilemma)\n▶c: common payoff when both cooperate\n▶c + g: payoff from defecting when other cooperates\n▶0: payoff if both defect\nAMP: Poisson signal (number of \"successes\") with intensity λ if both\ncooperate, μ if only one does.\nFor small t, prob. of observing more than one success is of order t2. To\nsimplify analysis, assume binary signal--0 or 1 successes--with prob. e-θt\nand 1 -e-θt, resp., for θ ∈{λ, μ}. Signals represent \"good news,\" λ > μ.\nPure strategy strongly symmetric equilibria with public randomization\n▶0: worst equilibrium payoff (minimax, static Nash)\n▶v∗: best equilibrium payoff\n▶α(i) (1 -α(i)): prob. of reverting to static Nash (playing best\nequilibrium) if signal i ∈{0, 1} is observed\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n45 / 47\n\nPPE Constraints\nBest equilibrium should specify cooperation in the first period.\nv∗\n1 -e-rt c\ne-rt e\nt\n=\n(\n) +\n-λt(1 -α(0)) + (1 -e-λ )(1 -α(1)) v∗\n≥\n(1 -e-rt)(c + g) +\n\ne-rt\ne-μt(1 -α(0)) + (1 -e-μt)(1 -\n\nα(1)) v∗\nSolve for v∗,\n\n(1\nv∗=\n-e-rt)c\n.\n1 -e-rt (1 -α(1) -e-λt(α(0) -α(1)))\nIncentive constraint\n(1 -e-rt)g ≤e-rt(e-μt -e-λt)(α(0) -α(1))v∗\nsimplifies to\nce-rt(e-μt\n-\ng\n-e λt)(α(0) -α(1))\n≤\n.\n1 -e-rt (1 -α(1) -e-λt(α(0) -α(1)))\nv∗is decreasing in α(1) and the incentive constraint is relaxed by\ndecreasing α(1) ⇒α(1) = 0.\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n46 / 47\n\nt →0 versus r →0\nα(1) = 0 ⇒\n(1\nv∗=\n-e-rt)c\ne-rt(e-μt\ne-λt)α(0)\nand\ng/c\n≤\n-e-rt\n-\n(1 -e-λtα(0))\n1 -e-rt(1 -e-λtα(0))\nPossible to satisfy the inequality for α(0) ≤1 only if\ne-rt(e-μt\ng/c\n-e-λt)\n≤\ne(λ-μ)t\n1.\n-λt) ≤\n-e-rt(1 -e\n-\nt →0: we cannot do better than static Nash since e(λ-μ)t\ne(λ-μ)t\n→\n▶\n: likelihood ratio for no success\n▶As t →0, almost certainly no success is observed.\n▶Informativeness of public signal is poor.\nr →0: we can do better than static Nash for some values of c, g, t\n▶Incentive constraint becomes g/c ≤e(λ-μ)t -1.\n▶\"Optimal\" α(0): v∗→c -\ng\ne(λ-μ)t-1 > 0\nMihai Manea (MIT)\nRepeated Games\nJune 27, 2016\n47 / 47\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Reputation Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/8a76b8f16b6c2c1dac0281cc7e194629_MIT14_126S16_reputation.pdf",
      "content": "Reputation\nMihai Manea\nMIT\n\nGame with Short-Run Players\n(N, A, u): two-player normal-form game played in every period t = 0, 1, . . .\n1 is a long-run player and 2 is a short-run player (series of one-period\nplayers or a very impatient player). 2 plays a best response to 1's\nanticipated action at every date.\nFudenberg, Kreps, and Maskin (1988): folk theorem if game is common\nknowledge\n▶B2: 2's mixed best responses in stage game to 1's mixed actions\n▶u =\n(\n, σ )\nminσ2∈B2 maxa1∈A1 u1 a1\n▶Any payoff for player 1 above u1 is sustainable in a subgame perfect\nequilibrium for high δ\nFudenberg and Levine (1989): if game is perturbed to allow for irrational\ntypes of player 1, folk theorem overturned\n▶u∗\n1 = maxa1∈A1 minσ2∈BR2(a1) u1(a1, σ2): Stackelberg payoff\n▶1 obtains his Stackelberg payoff in any Nash equilibrium for high δ\nCompare u1 and u∗\n1 for Cournot duopoly.\nMihai Manea (MIT)\nReputation\nApril 13, 2016\n2 / 8\n\nPerturbed Game\n▶Ω: countable space of types for player 1, prior μ\n▶Only player 1 knows his type\n▶u1(a, ω): player 1's payoff depends on ω; player 2's does not\n▶ω0: \"rational\" type of player 1 with payoffs given by original u1\n▶ω(a1): \"crazy\" type of player 1 for which playing a1 at every history is\na strictly dominant strategy in the repeated game\n▶ω∗= ω(a∗)\n1 with μ(ω∗) > 0\nMihai Manea (MIT)\nReputation\nApril 13, 2016\n3 / 8\n\nKey Lemma\n▶Any strategy profile σ (together with μ) generates a unique joint\ndistribution over play paths and types π ∈∆((A1 × A2)inf× Ω)\n▶h∗: event in (A\nt\nA2)inf\nΩin which a =\na1\n∗for all t\n∗\nat\n×\n×\na∗ht-1\n▶π = π(\n=\n|\n)\nt\n: probability of a at\nt\n∗\nt conditional on history h -1\n▶n(π∗\nt ≤π): number of periods t s.t. π∗\nt ≤π for π ∈(0, 1)\n▶π∗\nt and n(π∗\nt ≤π) are random variables defined on path-type space\nLemma 1\nLet σ be a strategy profile such that π(h∗|ω∗) = 1. Then\nπ\n\nn(π∗\nt ≤π) ≤ln μ∗\nln π\nh∗\n!\n= 1.\nMihai Manea (MIT)\nReputation\nApril 13, 2016\n4 / 8\n\nProof\nht: history of length t with π(ht) > 0 in which player 1 played a1\n∗every\nperiod\nht,1 (ht,2): event that ht-1 is observed and player 1 (2) plays at t as in ht\nht\nπ\nt\n(\n& ω∗\nπ(ω∗\n|ht-1)\n|h ) =\nπ(ht|ht-1)\n=\nπ(ω∗|ht-1)π(ht|ω∗, ht-1)\nπ(ht|ht-1)\n=\nπ(ω∗|ht-1)π(ht,1|ω∗, ht-1)π(ht,2|ω∗, ht-1)\nπ(ht,1|ht-1)π(ht,2|ht-1)\n=\nπ(ω∗|ht-1)π(ht,2|ω∗, ht-1)\nπ(ht,1|ht-1)π(ht,2|ht-1)\n=\nπ(ω∗|ht-1)\nπ∗\nt\nMihai Manea (MIT)\nReputation\nApril 13, 2016\n5 / 8\n\nProof\nπ\nπ(ω∗|ht\n(ω∗|ht-1)\n) =\nπ∗\nt\n= . . . =\nπ(ω∗|h0)\nπ∗\nt π∗\nt-1 · · · π∗\n=\nμ∗\nπ∗π∗\n· · · π\nt\nt\n∗\n-1\nSince π(ω∗|ht) ≤1, at most ln μ∗/ ln π terms in the denominator of the last\nexpression can be ≤π.\nTherefore, with probability 1,\nn(π∗\nt ≤π) ≤ln μ∗/ ln π.\nMihai Manea (MIT)\nReputation\nApril 13, 2016\n6 / 8\n\nMain Result\n▶um = minσ2 u1(a∗, σ\n2, ω0): lowest stage payoff for 1 when he plays a1\n∗\n▶uM = maxa u1(a, ω0): highest stage payoff for 1\n▶u1 = maxa1 maxσ2∈BR2(a1) u1(a1, a2) : \"upper\" Stackelberg payoff\n▶v (δ, μ, ω\n0) (v 1(δ, μ, ω0)): infimum (supremum) of 1's payoffs in\nrepeated game across Nash equilibria in which 1 uses a pure strategy\nTheorem 1\nFor any value μ∗, there exists a number κ(μ∗) s.t. for all δ and all (μ, Ω)\nwith μ(ω∗) = μ∗, we have\nv1(δ, μ, ω0) ≥δκ(μ∗)u∗\n1 + (1 -δκ(μ∗))um.\nMoreover, there exists κ such that for all δ, we have\nv1(δ, μ, ω0) ≤δκu1 + (1 -δκ)uM.\nAs δ →1, the payoff bounds converge to u∗\n1 and u1 (generically identical).\nMihai Manea (MIT)\nReputation\nApril 13, 2016\n7 / 8\n\nProof\n∃π < 1 s.t. in any Nash equilibrium player 2 plays a best response to a1\n∗at\nevery stage t where π∗>\nt\nπ\n▶Pure strategy best response correspondence has closed graph.\n▶Action spaces are finite.\n∃κ(μ∗) s.t. π(n(π∗≤π) > κ(μ∗) | h∗) = 0 (by the lemma)\nIf rational player 1 deviates to playing a\nκ(μ )\n∗always, there are at most\n∗\nperiods in which player 2 will not play a best response to a1\n∗. Then payoff\nfrom deviating is at least\nδκ(μ∗)u1\n∗\n∗\n+ (1 -δκ(μ ))um.\nProof for upper bound requires a version of the lemma for ω0. . . from the\nperspective of rational player 1, player 2 plays a best response to his\naction at all but a finite set of dates.\nFudenberg and Levine (1992): extension to mixed strategy Nash equilibria\nMihai Manea (MIT)\nReputation\nApril 13, 2016\n8 / 8\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "14.126 Spring 2016 Single-Deviation Principle and Bargaining Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-126-game-theory-spring-2016/0c31bb15a0fb73c568f12d3d855b6c22_MIT14_126S16_bargaining.pdf",
      "content": "Single-Deviation Principle and Bargaining\nMihai Manea\nMIT\n\nMulti-stage games with observable actions\n▶finite set of players N\n▶stages t = 0, 1, 2, . . .\n▶H: set of terminal histories (sequences of action profiles of possibly\ndifferent lengths)\n▶at stage t, after having observed a non-terminal history of play\nh\nt-1\nt = (a , . . . , a\n) < H, each player i simultaneously chooses an\naction at ∈\ni\nAi(ht)\n▶ui(h): payoff of i ∈N for terminal history h ∈H\n▶σi: behavior strategy for i ∈N specifies σi(h) ∈∆(Ai(h)) for h < H\nOften natural to identify \"stages\" with time periods.\nExamples\n▶repeated games\n▶alternating bargaining game\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n2 / 37\n\nUnimprovable Strategies\nTo verify that a strategy profile σ constitutes a subgame perfect equilibrium\n(SPE) in a multi-stage game with observed actions, it suffices to check\nwhether there are any histories ht where some player i can gain by\ndeviating from playing σi(ht) at t and conforming to σi elsewhere.\nui(σ|ht): expected payoff of player i in the subgame starting at ht and\nplayed according to σ thereafter\nDefinition 1\nA strategy σi is unimprovable given σ-i if ui(σi, σ-i| ht) ≥ui(σ′\ni, σ-i| ht) for\nevery ht and σ′\ni with σ′\ni(h) = σi(h) for all h , ht.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n3 / 37\n\nContinuity at Infinity\nIf σ is an SPE then σi is unimprovable given σ-i. For the converse. . .\nDefinition 2\nA game is continuous at infinity if\nlim\nt→inf\nsup\n{(h, h)|ht= ht}\n|ui(h) -ui( h)| = 0, ∀i ∈N.\nEvents in the distant future are relatively unimportant.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n4 / 37\n\nSingle (or One-Shot) Deviation Principle\nTheorem 1\nConsider a multi-stage game with observed actions that is continuous at\ninfinity. If σi is unimprovable given σ-i for all i ∈N, then σ constitutes an\nSPE.\nProof allows for infinite action spaces at some stages. There exist versions\nfor games with unobserved actions.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n5 / 37\n\nProof\nSuppose that σi is unimprovable given σ-i, but σi is not a best response\nto\nσ-i following some history ht. Let σi be a strictly better response and\ndefine\nε = ui(σ , σ\ni\n-i|ht) -ui(σi, σ-i|ht) > 0.\nSince the game is continuous at infinity, there exists t′ > t and\nσi s.t.\nσi is\nidentical to\n1 at all information sets up to (and including) stage t′,\nσ\nσ\ni\ni\ncoincides with σi across all longer histories and\n|u\ni(σ , σ-i|ht) -ui(σ , σ\ni\ni\n-i|ht)| < ε/2.\nThen\nu\ni(σ , σ\ni\n-i|ht) > ui(σi, σ-i|ht).\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n6 / 37\n\nProof\nσi : strategy obtained from\nσi by replacing the stage t′ actions following\nany history ht′ with the corresponding actions under σi\nConditional on any ht′, σi and\nσi coincide, hence\nu\ni(σ , σ\nσ\ni\n-i|ht′) = ui(σi,\n-i|ht′).\nAs σi is unimprovable given σ-i, and conditional on ht′ the subsequent\nplay in strategies σi and\nσi differs only at stage t′,\nui(σi, σ-i|ht′) ≥u\ni(σ , σ\ni\n-i|ht′).\nThen\nu\ni(σ , σ\ni\n-i|ht′) ≥u\ni(σ , σ\ni\n-i|ht′)\nfor all histories ht′. Since\nσi and\nσi coincide before reaching stage t′,\nu\ni(σ , σ\ni\n-i|ht) ≥u\ni(σ , σ\ni\n-i|ht).\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n7 / 37\n\nProof\nσi : strategy obtained from\nσi by replacing the stage t′ -1 actions\nfollowing any history ht′-1 with the corresponding actions under σi\nSimilarly,\nu\ni(σ , σ-i|ht) ≥ui(σ , σ-i|ht) . . .\ni\ni\nThe final strategy\nt′\nσ -t+3 is identical to σi\ni\nconditional on ht and\nui(σi, σ-i|h\nt′-t+3\nt) = ui(σ\n, σ\ni\n-i|ht) ≥. . .\n≥u\ni(σ , σ\ni\n-i|ht) ≥ui(σ , σ |\n) >\n(σ , σ |\n),\ni\n-i ht\nui\ni\n-i ht\na contradiction.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n8 / 37\n\nApplications\nApply the single deviation principle to repeated prisoners' dilemma to\nimplement the following equilibrium paths for high discount factors:\n▶(C, C), (C, C), . . .\n▶(C, C), (C, C), (D, D), (C, C), (C, C), (D, D), . . .\n▶(C, D), (D, C), (C, D), (D, C) . . .\nC\nD\nC\n1, 1\n-1, 2\nD\n2, -1\n0, 0\nCooperation is possible in repeated play.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n9 / 37\n\nBargaining with Alternating Offers\nRubinstein (1982)\n▶players i = 1, 2; j = 3 -i\n▶set of feasible utility pairs\nU = {(u1, u2) ∈[0\n, inf) |u2 ≤g2(u1)}\n▶g2 s. decreasing, concave (and hence continuous), g2(0) > 0\n▶δi: discount factor of player i\n▶at every time t = 0, 1, . . ., player i(t) proposes an alternative\nu = (u1, u2) ∈U to player j(t) = 3 -i(t)\n1 for\nt even\ni(t) = 2 for\nt odd\n▶if j(t) accepts the offer, game ends yielding payoffs (δt\n1u1, δt\n2u2)\n▶otherwise, game proceeds to period t + 1\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n10 / 37\n\nStationary SPE\nDefine g1 = g-1\n2 . Graphs of g2 and g-1\n1 : Pareto-frontier of U\nLet (m1, m2) be the unique solution to the following system of equations\nm1\n=\nδ1g1 (m2)\nm2\n=\nδ2g2 (m1) .\n(m1, m2) is the intersection of the graphs of δ2g2 and (δ1g1)-1.\nSPE in \"stationary\" strategies: in any period where player i has to make an\noffer to j, he offers u with uj = mj and ui = gi(mj), and j accepts only offers\nu with uj ≥mj.\nSingle-deviation principle: constructed strategies form an SPE.\nIs the SPE unique?\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n11 / 37\n\nIterated Conditional Dominance\nDefinition 3\nIn a multi-stage game with observable actions, an action ai is conditionally\ndominated at stage t given history ht if, in the subgame starting at ht,\nevery strategy for player i that assigns positive probability to ai is strictly\ndominated.\nProposition 1\nIn any multi-stage game with observable actions, every SPE survives the\niterated elimination of conditionally dominated strategies.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n12 / 37\n\nEquilibrium uniqueness\nIterated conditional dominance: stationary equilibrium is essentially the\nunique SPE.\nTheorem 2\nThe SPE of the alternating-offer bargaining game is unique, except for the\ndecision to accept or reject Pareto-inefficient offers.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n13 / 37\n\nProof\n▶Following a disagreement at date t, player i cannot obtain a period t\nexpected payoff greater than\nM0 = δ\ni\ni max ui = δigi(0)\nu∈U\n▶Rejecting an offer u with u\ni > Mi is conditionally dominated by\naccepting such an offer for i.\n▶Once we eliminate dominated actions, i accepts all offers u with\nui > M0\ni from j.\n▶Making any offer u with ui > M0\ni is dominated for j by an offer\n\nu\nu\nM0 g M0\n= λ + ( -λ)\n,\nj\ni\ni\nfor λ ∈(0, 1) (both offers are accepted\nimmediately).\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n14 / 37\n\nProof\nUnder the surviving strategies\n▶j can reject an offer from i and make a counteroff\n\ner next period that\nleaves him with slightly less than gj M0\ni , which i accepts; it is\nconditionally dominated for j to accept any offer smaller than\n\nm1\n= δ\nj\njgj Mi\n▶i cannot expect to receive a continuation payoff greater than\n\nM1\nmax\ng m1\n2M0\ng\n=\nδ\ni\ni\ni\n, δ\n= δ\nj\ni\ni\ni\ni mj\nafter rejecting an offer from j\n\nδigi m1\nδ\nj\ni\njgj M0\n= δig\n≥δ\ni\nigi g\nj M\n= δ\ni\niM ≥δ\ni\ni Mi\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n15 / 37\n\nProof\nRecursively define\nmk+1\nj\n=\nδjgj\n\nMk\ni\n\nMk+1\ni\n=\nδigi\n\nmk+1\nj\n\nfor i = 1, 2 and k ≥1. (mk\ni )k≥0 is increasing and (Mk\ni )k≥0 is decreasing.\nProve by induction on k that, under any strategy that survives iterated\nconditional dominance, player i = 1, 2\n▶never accepts offers with ui < mk\ni\n▶always accepts offers with ui > Mk\ni , but making such offers is\ndominated for j.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n16 / 37\n\nProof\n▶The sequences (mk)\ni\nand (Mk)\ni\nare monotonic and bounded, so they\nneed to converge. The limits satisfy\n\nminf\n=\nδ\nj\njgj δigi minf\n\nj\nMinf\n=\nδ\ni\nigi minf.\nj\n▶(minf,\n1 minf)\nis the (unique) intersection point of the graphs of the\nfunctions δ2g and\n(δ1g1)-\n\n▶Minf= δ\ni\nigi minf=\nj\nminf\ni\n▶All strategies of i that survive iterated conditional dominance accept u\nwith ui > Minf=\ninf\n<\ninf=\ninf\ni\nmi\nand reject u with ui\nmi\nMi .\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n17 / 37\n\nProof\nIn an SPE\n▶at any history where i is the proposer, i's payoff is at least gi(minf)\nj\n:\noffer u arbitrarily close to (gi(minf),\nj\nminf)\nj\n, which j accepts under the\nstrategies surviving the elimination process\n▶i cannot get more than gi(minf)\nj\n▶any offer made by i specifying a payoff greater than gi(minf)\nj\nfor himself\nwould leave j with less than minf\nj ; such offers are rejected by j under the\nsurviving strategies\n▶under the surviving strategies, j never offers i more than\nMinf= δ\ninf\ninf\ni\nigi(m ) ≤\nj\ngi(m )\nj\n▶hence i's payoff at any history where i is the proposer is exactly\ngi(minf)\nj\n; possible only if i offers (gi(minf),\nj\nminf)\nj\nand j accepts with\nprobability 1\nUniquely pinned down actions at every history, except those where j has\njust received an offer (ui, minf)\n<\nj\nfor some ui\ngi(minf)\nj\n. . .\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n18 / 37\n\nProperties of the equilibrium\n▶The SPE is efficient--agreement is obtained in the first period,\nwithout delay.\n▶SPE payoffs: (g1(m2), m2), where (m1, m2) solve\nm1\n=\nδ1g1 (m2)\nm2\n=\nδ2g2 (m1) .\n▶Patient players get higher payoffs: the payoff of player i is increasing\nin δi and decreasing in δj.\n▶For a fixed δ1 ∈(0, 1), the payoff of player 2 converges to 0 as δ2 →0\nand to maxu∈U u2 as δ2 →1.\n▶If U is symmetric and δ1 = δ2, player 1 enjoys a first mover\nadvantage: m1 = m2 and g1(m2) = m2/δ > m2.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n19 / 37\n\nNash Bargaining\nAssume g2 is decreasing, s. concave and continuously differentiable.\nNash (1950) bargaining solution:\nu∗\n{\n} = arg max u1u2 = arg max u1g2(u1).\nu∈U\nu∈U\nTheorem 3 (Binmore, Rubinstein and Wolinsky 1985)\nSuppose that δ1 = δ2 =: δ in the alternating bargaining model. Then the\nunique SPE payoffs converge to the Nash bargaining solution as δ →1.\nm1g2 (m1) = m2g1 (m2)\n(m1, g2 (m1)) and (g1 (m2) , m2) belong to the intersection of g2's graph\nwith the same hyperbola, which approaches the hyperbola tangent to the\nboundary of U (at u∗) as δ →1.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n20 / 37\n\nBargaining with random selection of proposer\n▶Two players need to divide $1.\n▶Every period t = 0, 1, . . . player 1 is chosen with probability p to make\nan offer to player 2.\n▶Player 2 accepts or rejects 1's proposal.\n▶Roles are interchanged with probability 1 -p.\n▶In case of disagreement the game proceeds to the next period.\n▶The game ends as soon as an offer is accepted.\n▶Player i = 1, 2 has discount factor δi.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n21 / 37\n\nEquilibrium\n▶The unique equilibrium is stationary, i.e., each player i has the same\nexpected payoff vi in every subgame.\n▶Payoffs solve\nv1\n=\np(1 -δ2v2) + (1 -p)δ1v1\nv2\n=\npδ2v2 + (1 -p)(1 -δ1v1).\n▶The solution is\np/(1 -δ1)\nv1\n=\np/(1 -δ1) + (1 -p)/(1 -δ2)\nv2\n=\n(1 -p)/(1 -δ2)\np/(1 -δ1) + (1 -p)/(1 -δ2).\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n22 / 37\n\nComparative Statics\nv1\n=\n1 + (1-p)(1-δ1)\np(1-δ2)\nv2\n=\n1 +\np(1-δ2)\n(1-p)(1-δ1)\n.\n▶Immediate agreement\n▶First mover advantage\n▶v1 increases with p, v2 decreases with p.\n▶For δ1 = δ2, we obtain v1 = p, v2 = 1 -p.\n▶Patience pays off\n▶vi increases with δi and decreases with δj (j = 3 -i).\n▶Fix δj and take δi →1, we get vi →1 and vj →0.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n23 / 37\n\nBargaining in Dynamic Markets\nManea (2014)\n▶Populations or player types: N = {1, 2, . . . , n}\n▶Surplus players i and j can generate: sij = sji ≥0\n▶Time: t = 0, 1, . . .\n▶In period t, an endogenously determined measure μit ≥0 of players i\nP\nparticipates in the market;\ni∈N μit > 0.\n▶Market at time t: μt = (μit)i∈N ∈[0\nn\n, inf) \\ {0}\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n24 / 37\n\nMatching Technology\nIn every period t market μt:\n▶A measure βijt(μt) ≥0 of players i have the opportunity to make an\noffer to one of the players j.\n▶βijt is continuous on [0\nn\n, inf) \\ {0}.\n▶No player is involved in more than one match at a time,\nX\nμit ≥\nβijt(μt) + βjit(μt), ∀i ∈N.\nj∈N\n∀t, μt, ∃i s.t. the inequality is strict.\n▶Each player i is selected to make an offer to a player of type j with\nprobability\nβijt(μ t)\nπijt(μt) = lim\nμ t →μt\nμ it>0\nμit\n.\nHence πijt is continuous on [0, inf)n \\ {0}.\nIt is not necessary to model the matching process explicitly. . .\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n25 / 37\n\nA Salient Matching Technology\n▶Every player gets matched with a fixed probability p.\n▶The conditional probability of i meeting a type j is proportional to the\nsize of population j (cf. Gale 1987).\n▶Players of type i are recognized as proposers in half of the matched\npairs (i, j) with i , j.\nβijt(μt)\n=\np\nμitμjt\nP\nk∈N μkt\nπijt(μt)\n=\np\nμjt\nP\nk∈N μkt\n, ∀i, j ∈N\n▶We can alternatively set βijt(μt) = 0 whenever sij = 0.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n26 / 37\n\nThe Benchmark Bargaining Game\n▶A measure λi0 ≥0 of players of type i is present at t = 0\n(\nn\nλ0 ∈[0, inf) \\ {0}). Let μi0 = λi0.\n▶Every period t = 0, 1, . . ., players are randomly matched to bargain\naccording to βt(μt).\n▶A player i who gets the opportunity to make an offer to some player j\ncan propose a division of sij.\n▶If j accepts the offer, then the two players exit the game with the shares\nagreed upon.\n▶If j rejects the offer, then i and j remain in the game for period t + 1.\n▶A measure λ\n≥\ni(t+1)\n0 of new players i enter at t + 1. The total stock\nof players i at the beginning of period t + 1 is μi(t+1).\n▶The players of type i have a common discount factor δi ∈(0, 1).\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n27 / 37\n\nInformation Structure and Solution Concept\nKey assumptions\n▶All players observe the state of the market μt at the beginning of\nperiod t.\n▶Matched pairs of players know each other's type.\nInformation about the realized matchings and ensuing negotiations\n▶Under perfect information, all players observe the entire history of\nmatched pairs and outcomes →subgame perfect equilibrium.\n▶Alternatively, players may have only partial knowledge of past\nbargaining encounters →belief-independent equilibrium.\nRestrict attention to robust equilibria: no player can affect the population\nsizes along the path by changing his strategy. Players take matching\nprobabilities as given.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n28 / 37\n\nThe Model with Exogenous Matching Probabilities\nClass of games\n▶Players from n populations are present in the market in every period\nt = 0, 1, . . .\n▶Every player of type i is given the opportunity to make an offer to one\nof the players j in period t with exogenous probability pijt.\n▶Bargaining proceeds as in the benchmark model.\nAgnostic about the market composition at each date. . . vague regarding\nthe inflows over time, the exact matching procedure, and the information\nstructure.\nEquilibrium behavior is independent of the details. . . (pijt) completely\ncharacterizes the strategic situation.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n29 / 37\n\nInterpretations\n▶Partial equilibrium approach: predict payoffs for a certain evolution of\nmarket conditions over time.\n▶Stubborn beliefs: all players start with identical beliefs about the path\nof matching probabilities and never revise expectations in response to\ntheir observations. In large markets, a participant may think that his\npersonal experience does not reflect future trends.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n30 / 37\n\nPayoff Equivalence\nTheorem 4\n∃(v∗\nit(p))i∈N,t≥0 s.t.\n(i) The only period t actions that may survive iterated conditional\ndominance specify that player i reject any offer smaller than\nδiv∗\ni(t+1)(p) and accept any offer greater than δiv∗\ni(t+1)(p).\n(ii) An equilibrium exists. In every equilibrium, the expected payoff of any\nplayer i present at the beginning of period t is v∗\nit(p).\n(iii) (v∗\nit(p))i∈N,t≥0 is the unique bounded solution (vit)i∈N,t≥0 to\nvit =\nX\nj∈N\npijt max\n\nsij -δjvj(t+1), δivi(t+1)\n\n+\n1 -\nX\nj∈N\npijt\nδivi(t+1).\n(iv) The payoffs v∗\nit(p) vary continuously in p for all i ∈N, t ≥0.\nTheorem 4 generalizes uniqueness results from Binmore and Herrero\n(1988) and Manea (2011).\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n31 / 37\n\nBounds\nDefine (mk)\nit i∈N,t≥0 and (Mk)\nit\ni∈N,t≥0 recursively for k = 0, 1, . . .\nm0 =\nit\n0, M0 =\nit\nmax sij\nj∈N\n\nX\n\nX\n\nmk+1\nk\nk\n\nijt\n-δj\n, δi\n\nk\n=\nij\n+\n-\nijtδi\nit\np\nmax s\nMj(t+1)\nmi(t+1)\np\n\nm\n\ni(t+1)\nj∈N\nj∈N\n\nX\n\nX\n\nMk+1\np\nmax s\nk\nk\n\nk\n=\nijt\nij -δjm\n, δiM\n+\ni(t+1\n\n.\n(\np\nj\n\nδ\n)\ni\nit\n-\nt+1)\nijt\nM\n\ni(t+1)\nj∈N\nj∈N\nUnder the strategies that survive iterated conditional dominance, every\nplayer i rejects offers < δimk\nand accepts offers > δiMk\nin period t.\ni(t+1)\ni(t+1)\nAs k →inf, the bounds converge to the same limit, v∗(p). We can\napproximately compute the unique payoffs.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n32 / 37\n\nEquilibrium Existence\nTheorem 5\nAn equilibrium exists for the bargaining game.\nThe result complements the analysis of Gale (1987), who explores\nproperties of equilibria abstracting away from existence issues.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n33 / 37\n\nSpaces for the Proof of Theorem 5\nDefine the sets of paths of. . .\nagreement rates:\nA = {(aijt)i,j∈N,t≥0|aijt ∈[0, 1], ∀i, j ∈N, t ≥0}\nmarket distributions:\nM = {(μit)i∈N,t≥0|μit ∈[0,\ntX\nτ=0\nλiτ], ∀i ∈N, t ≥0}\nmatching probabilities:\nP = {(pijt)i,j∈N,t≥0|pijt ∈[0, 1], ∀i, j ∈N, t ≥0}\nfeasible payoffs:\nV = {(vit)i∈N,t≥0|vit ∈[0, max\nj∈N sij], ∀i ∈N, t ≥0}\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n34 / 37\n\nIdea of the Proof for Theorem 5\nConstruct f : A⇒A, with f = α *v∗*π *κ,\nA\nκ→M\nπ→P\nv∗\n→V\nα\n⇒A\n▶κ(a): evolution of the market for a path of agreement rates a\n▶π: derived from the matching technology\n▶v∗(p): unique equilibrium payoffs in the model with an exogenous\npath of matching probabilities p\n▶α(v): set of agreement rates that are incentive compatible for an\nexpected path of payoffs v (bargaining at t proceeds as if\ndisagreement payoffs at t + 1 were vt+1)\nA is a locally convex topological vector space. By the Kakutani-Fan-\nGlicksberg theorem, f has a fixed point. . . describes an equilibrium path.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n35 / 37\n\nThe Kakutani-Fan-Glicksberg Theorem\nTheorem 6 (Kakutani-Fan-Glicksberg)\nLet S be a non-empty, compact and convex subset of a locally convex\nHausdorff topological vector space. Then any correspondence from S to S\nthat has a closed graph and non-empty convex values has a fixed point.\nSuppose V is a vector space over R and S ⊆V\n▶S is absolutely convex if it is closed under linear combinations whose\ncoefficients have absolute values summing to at most 1; equivalent to\n▶convex and\n▶balanced: x ∈S, |λ| ≤1 ⇒λx ∈S\n▶S is absorbent if V = ∪t>0tS\nA locally convex topological vector space is a topological vector space in\nwhich the origin has a local base of absolutely convex absorbent sets.\nHausdorff space: distinct points have disjoint neighborhoods\nRN with the product topology is a locally convex Hausdorff space.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n36 / 37\n\nAnother Fixed-Point Theorem\nTheorem 7 (Brouwer-Schauder-Tychonoff)\nLet S be a non-empty, compact and convex subset of a locally convex\nHausdorff topological vector space. Then any continuos function from S to\nS has a fixed point.\nCorollary 1 (Schauder)\nLet X be a bounded subset of Rk and let C(X) be the space of bounded\ncontinuous functions on X with the sup norm. Suppose that S ⊂C(X) is\nnon-empty, closed, bounded, and convex. Then any continuous mapping\nf : S →S such that f(S) is equicontinuous has a fixed point.\nA subset S of C(X) is equicontinuous if for every ε > 0 there exists δ > 0\nsuch that\n|x -y| < δ =⇒|f(x) -f(y)| < ε, ∀f ∈S.\nMihai Manea (MIT)\nSingle-Deviation Principle and Bargaining\nMarch 2, 2016\n37 / 37\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n14.126 Game Theory\nSpring 2016\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
    }
  ]
}