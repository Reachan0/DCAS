{
  "course_name": "Introduction to Representation Theory",
  "course_description": "No description found.",
  "topics": [
    "Mathematics",
    "Algebra and Number Theory",
    "Linear Algebra",
    "Mathematics",
    "Algebra and Number Theory",
    "Linear Algebra"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nDescription\n\nThe goal of this course is to give an undergraduate-level introduction to representation theory (of groups, Lie algebras, and associative algebras). Representation theory is an area of mathematics which, roughly speaking, studies symmetry in linear spaces.\n\nTopics\n\nBasic objects and notions of representation theory: Associative algebras. Algebras defined by generators and relations. Group algebras. Quivers and path algebras. Lie algebras and enveloping algebras. Representations. Irreducible and indecomposable representations. Schur's lemma. Representations of sl(2).\n\nBasic general results of representation theory. The density theorem. Representations of finite dimensional algebras. Semisimple algebras. Characters of representations. Jordan-Holder and Krull-Schmidt theorems. Extensions of representations.\n\nRepresentations of finite groups, basic results. Maschke's theorem. Sum of squares formula. Duals and tensor products of representations. Orthogonality of characters. Orthogonality of matrix elements. Character tables, examples. Unitary representations. Computation of tensor product and restriction multiplicities from character tables. Applications of representation theory of finite groups.\n\nRepresentations of finite groups, further results: Frobenius-Schur indicator. Frobenius determinant. Algebraic integers and Frobenius divisibility theorem. Applications to the theory of finite groups: Burnside's theorem. Induced representations and their characters (Mackey formula). Frobenius reciprocity. Representations of\nGL\n(2;\nFq\n). Representations of the symmetric group and the general linear group. Schur-Weyl duality. The fundamental theorem of invariant theory.\n\nRepresentations of quivers. Indecomposable representations of quivers of type A1, A2, A3, D4. The triple of subspaces problem. Gabriel's theorem. Proof of Gabriel's theorem: Simply laced root systems, reflection functors.\n\nPrerequisites\n\nThe prerequisites for the course are the standard algebra sequences Algebra I and II (18.701, 18.702) or Linear Algebra and Modern Algebra (18.700, 18.703). This means that to understand this course, it is necessary and sufficient to have a strong background in linear algebra and a decent understanding of basic algebraic structures, such as groups, rings, and fields. We will prove some general results, but a lot of the attention will be paid to examples, and there will be many hands-on exercises illustrating the course.\n\nTextbooks\n\nBesides the lecture notes, we will also use the beginning part of the books:\n\nFulton, William, and Joe Harris.\nRepresentation Theory: A First Course\n. Graduate texts in mathematics. Vol. 129. New York, NY: Springer, 1991. ISBN: 9780387974958.\n\nSerre, Jean Pierre.\nLinear Representations of Finite Groups\n. Graduate texts in mathematics. Vol. 42. New York, NY: Springer-Verlag, 1977. ISBN: 9780387901909.\n\nGrading\n\nTo pass the course, it will be required to solve homework assignments which will be assigned every Thursday and due the following Thursday. The homeworks are 75% of the grade. It is ok to collaborate on homework if you creatively participate in solving it and understand what you write. Also there will be a take-home final assignment at the end of the term, which will weigh 25% of the grade.\n\nACTIVITIES\n\nPERCENTAGES\n\nHomeworks\n\n75%\n\nTake-home final\n\n25%",
  "files": [
    {
      "category": "Assignment",
      "title": "Takehome Assignment",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/e1bcbdf2202bc6f8d7fb533d39a444ab_MIT18_712F10_712tk.pdf",
      "content": "1. 18.712 takehome assignment\n1. Let Q be a quiver, i.e. a finite oriented graph. Let A(Q) be the path\nalgebra of Q over a field k, i.e. the algebra whose basis is formed by paths\nin Q (compatible with orientations, and including paths of length 0 from a\nvertex to itself), and multiplication is concatenation of paths (if the paths\ncannot be concatenated, the product is zero).\n(i) Represent the algebra of upper triangular matrices as A(Q).\n(ii) Show that A(Q) is finite dimensional iff Q is acyclic, i.e. has no\noriented cycles.\n(iii) For any acyclic Q, decompose A(Q) (as a left module) in a direct\nsum of indecomposable modules.\n(iv) Find a condition on Q under which A(Q) is isomorphic to A(Q)op,\nthe algebra A(Q) with opposite multiplication. Use this to give an example\nof an algebra A that is not isomorphic to Aop.\n2. Classify irreducible representations of the group GL2(Fq) nF2\nq of affine\ntransformations of the 2-dimensional space over a finite field, and find their\ncharacters.\n3. Compute the decomposition into irreducible representations of all the\ninduced representations from the cyclic subgroups of the preimage Γ of A5 ⊂\nSO(3) (the group corresponding to the affine Dynkin diagram E 8).\n4. Find the multiplicities of the irreducible representations of sl(2) in\nV ⊗n, where V is the 2-dimensional vector represenation.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n18.712 Introduction to Representation Theory\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Basic notions of representation theory",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/6b7e3b7277dc86249ec40bb134186639_MIT18_712F10_ch1.pdf",
      "content": "Basic notions of representation theory\n1.1\nWhat is representation theory?\nIn technical terms, representation theory studies representations of associative algebras. Its general\ncontent can be very briefly summarized as follows.\nAn associative algebra over a field k is a vector space A over k equipped with an associative\nbilinear multiplication a, b 7⊃ ab, a, b 2 A. We will always consider associative algebras with unit,\ni.e., with an element 1 such that 1 · a = a · 1 = a for all a 2 A. A basic example of an associative\nalgebra is the algebra EndV of linear operators from a vector space V to itself. Other important\nexamples include algebras defined by generators and relations, such as group algebras and universal\nenveloping algebras of Lie algebras.\nA representation of an associative algebra A (also called a left A-module) is a vector space\nV equipped with a homomorphism δ : A ⊃ EndV , i.e., a linear map preserving the multiplication\nand unit.\nA subrepresentation of a representation V is a subspace U → V which is invariant under all\noperators δ(a), a 2 A. Also, if V1, V2 are two representations of A then the direct sum V1 V2\nhas an obvious structure of a representation of A.\nA nonzero representation V of A is said to be irreducible if its only subrepresentations are\n0 and V itself, and indecomposable if it cannot be written as a direct sum of two nonzero\nsubrepresentations. Obviously, irreducible implies indecomposable, but not vice versa.\nTypical problems of representation theory are as follows:\n1. Classify irreducible representations of a given algebra A.\n2. Classify indecomposable representations of A.\n3. Do 1 and 2 restricting to finite dimensional representations.\nAs mentioned above, the algebra A is often given to us by generators and relations. For\nexample, the universal enveloping algebra U of the Lie algebra sl(2) is generated by h, e, f with\ndefining relations\nhe - eh = 2e,\nhf - fh = -2f,\nef - fe = h.\n(1)\nThis means that the problem of finding, say, N-dimensional representations of A reduces to solving\na bunch of nonlinear algebraic equations with respect to a bunch of unknown N by N matrices,\nfor example system (1) with respect to unknown matrices h, e, f.\nIt is really striking that such, at first glance hopelessly complicated, systems of equations can\nin fact be solved completely by methods of representation theory! For example, we will prove the\nfollowing theorem.\nTheorem 1.1. Let k = C be the field of complex numbers. Then:\n(i) The algebra U has exactly one irreducible representation Vd of each dimension, up to equiv\nalence; this representation is realized in the space of homogeneous polynomials of two variables x, y\nof degree d - 1, and defined by the formulas\n@\n@\n@\n@\nδ(h) = x\n- y\n,\nδ(e) = x\n,\nδ(f) = y\n.\n@x\n@y\n@y\n@x\n(ii) Any indecomposable finite dimensional representation of U is irreducible. That is, any finite\n\ndimensional representation of U is a direct sum of irreducible representations.\nAs another example consider the representation theory of quivers.\nA quiver is a finite oriented graph Q. A representation of Q over a field k is an assignment\nof a k-vector space Vi to every vertex i of Q, and of a linear operator Ah : Vi ⊃ Vj to every directed\nedge h going from i to j (loops and multiple edges are allowed). We will show that a representation\nof a quiver Q is the same thing as a representation of a certain algebra PQ called the path algebra\nof Q. Thus one may ask: what are the indecomposable finite dimensional representations of Q?\nMore specifically, let us say that Q is of finite type if it has finitely many indecomposable\nrepresentations.\nWe will prove the following striking theorem, proved by P. Gabriel about 35 years ago:\nTheorem 1.2. The finite type property of Q does not depend on the orientation of edges. The\nconnected graphs that yield quivers of finite type are given by the following list:\n- An :\n-- · · · --\n\n- Dn:\n-- · · · --\n|\n- E6 :\n-----\n---\n|\n- E7 :\n------- ---\n|\n------------\n- E8 :\n|\nThe graphs listed in the theorem are called (simply laced) Dynkin diagrams. These graphs\narise in a multitude of classification problems in mathematics, such as classification of simple Lie\nalgebras, singularities, platonic solids, reflection groups, etc. In fact, if we needed to make contact\nwith an alien civilization and show them how sophisticated our civilization is, perhaps showing\nthem Dynkin diagrams would be the best choice!\nAs a final example consider the representation theory of finite groups, which is one of the most\nfascinating chapters of representation theory. In this theory, one considers representations of the\ngroup algebra A = C[G] of a finite group G - the algebra with basis ag, g 2 G and multiplication\nlaw agah = agh. We will show that any finite dimensional representation of A is a direct sum of\nirreducible representations, i.e., the notions of an irreducible and indecomposable representation\nare the same for A (Maschke's theorem). Another striking result discussed below is the Frobenius\ndivisibility theorem: the dimension of any irreducible representation of A divides the order of G.\nFinally, we will show how to use representation theory of finite groups to prove Burnside's theorem:\nany finite group of order paqb, where p, q are primes, is solvable. Note that this theorem does not\nmention representations, which are used only in its proof; a purely group-theoretical proof of this\ntheorem (not using representations) exists but is much more difficult!\n\n1.2\nAlgebras\nLet us now begin a systematic discussion of representation theory.\nLet k be a field. Unless stated otherwise, we will always assume that k is algebraically closed,\ni.e., any nonconstant polynomial with coefficients in k has a root in k. The main example is the\nfield of complex numbers C, but we will also consider fields of characteristic p, such as the algebraic\nclosure Fp of the finite field Fp of p elements.\nDefinition 1.3. An associative algebra over k is a vector space A over k together with a bilinear\nmap A × A ⊃ A, (a, b) 7⊃ ab, such that (ab)c = a(bc).\nDefinition 1.4. A unit in an associative algebra A is an element 1 2 A such that 1a = a1 = a.\nProposition 1.5. If a unit exists, it is unique.\nProof. Let 1,\n\n10 be two units. Then 1 = 110 = 10.\nFrom now on, by an algebra A we will mean an associative algebra with a unit. We will also\nassume that A = 0.\nExample 1.6. Here are some examples of algebras over k:\n1. A = k.\n2. A = k[x1, ..., xn] - the algebra of polynomials in variables x1, ..., xn.\n3. A = EndV - the algebra of endomorphisms of a vector space V over k (i.e., linear maps, or\noperators, from V to itself). The multiplication is given by composition of operators.\n4. The free algebra A = k*x1, ..., xni. A basis of this algebra consists of words in letters\nx1, ..., xn, and multiplication in this basis is simply concatenation of words.\n5. The group algebra A = k[G] of a group G. Its basis is {ag, g 2 G}, with multiplication law\nagah = agh.\nDefinition 1.7. An algebra A is commutative if ab = ba for all a, b 2 A.\nFor instance, in the above examples, A is commutative in cases 1 and 2, but not commutative in\ncases 3 (if dim V > 1), and 4 (if n > 1). In case 5, A is commutative if and only if G is commutative.\nDefinition 1.8. A homomorphism of algebras f : A ⊃ B is a linear map such that f(xy) =\nf(x)f(y) for all x, y 2 A, and f(1) = 1.\n1.3\nRepresentations\nDefinition 1.9. A representation of an algebra A (also called a left A-module) is a vector space\nV together with a homomorphism of algebras δ : A ⊃ EndV .\nSimilarly, a right A-module is a space V equipped with an antihomomorphism δ : A ⊃ EndV ;\ni.e., δ satisfies δ(ab) = δ(b)δ(a) and δ(1) = 1.\nThe usual abbreviated notation for δ(a)v is av for a left module and va for the right module.\nThen the property that δ is an (anti)homomorphism can be written as a kind of associativity law:\n(ab)v = a(bv) for left modules, and (va)b = v(ab) for right modules.\nHere are some examples of representations.\n\nExample 1.10. 1. V = 0.\n2. V = A, and δ : A ⊃ EndA is defined as follows: δ(a) is the operator of left multiplication by\na, so that δ(a)b = ab (the usual product). This representation is called the regular representation\nof A. Similarly, one can equip A with a structure of a right A-module by setting δ(a)b := ba.\n3. A = k. Then a representation of A is simply a vector space over k.\n4. A = k*x1, ..., xni. Then a representation of A is just a vector space V over k with a collection\nof arbitrary linear operators δ(x1), ..., δ(xn) : V ⊃ V (explain why!).\nDefinition 1.11. A subrepresentation of a representation V of an algebra A is a subspace W →V\nwhich is invariant under all the operators δ(a) : V ⊃ V , a 2 A.\nFor instance, 0 and V are always subrepresentations.\nDefinition 1.12. A representation V = 0 of A is irreducible (or simple) if the only subrepresenta\ntions of V are 0 and V .\nDefinition 1.13. Let V1, V2 be two representations of an algebra A. A homomorphism (or in\ntertwining operator) θ : V1 ⊃ V2 is a linear operator which commutes with the action of A, i.e.,\nθ(av) = aθ(v) for any v 2 V1. A homomorphism θ is said to be an isomorphism of representations\nif it is an isomorphism of vector spaces. The set (space) of all homomorphisms of representations\nV1 ⊃ V2 is denoted by HomA(V1, V2).\nNote that if a linear operator θ : V1 ⊃ V2 is an isomorphism of representations then so is the\n\nlinear operator θ-1 : V2 ⊃ V1 (check it!).\nTwo representations between which there exists an isomorphism are said to be isomorphic. For\npractical purposes, two isomorphic representations may be regarded as \"the same\", although there\ncould be subtleties related to the fact that an isomorphism between two representations, when it\nexists, is not unique.\nDefinition 1.14. Let V1, V2 be representations of an algebra A. Then the space V1 V2 has an\nobvious structure of a representation of A, given by a(v1 v2) = av1 av2.\nDefinition 1.15. A nonzero representation V of an algebra A is said to be indecomposable if it is\nnot isomorphic to a direct sum of two nonzero representations.\nIt is obvious that an irreducible representation is indecomposable. On the other hand, we will\nsee below that the converse statement is false in general.\nOne of the main problems of representation theory is to classify irreducible and indecomposable\nrepresentations of a given algebra up to isomorphism. This problem is usually hard and often can\nbe solved only partially (say, for finite dimensional representations). Below we will see a number\nof examples in which this problem is partially or fully solved for specific algebras.\nWe will now prove our first result - Schur's lemma. Although it is very easy to prove, it is\nfundamental in the whole subject of representation theory.\nProposition 1.16. (Schur's lemma) Let V1, V2 be representations of an algebra A over any field\nF (which need not be algebraically closed). Let θ : V1 ⊃ V2 be a nonzero homomorphism of\nrepresentations. Then:\n(i) If V1 is irreducible, θ is injective;\n\n(ii) If V2 is irreducible, θ is surjective.\nThus, if both V1 and V2 are irreducible, θ is an isomorphism.\nProof. (i) The kernel K of θ is a subrepresentation of V1. Since θ = 0, this subrepresentation\ncannot be V1. So by irreducibility of V1 we have K = 0.\n(ii) The image I of θ is a subrepresentation of V2. Since θ = 0, this subrepresentation cannot\nbe 0. So by irreducibility of V2 we have I = V2.\nCorollary 1.17. (Schur's lemma for algebraically closed fields) Let V be a finite dimensional\nirreducible representation of an algebra A over an algebraically closed field k, and θ : V ⊃ V is an\nintertwining operator. Then θ = ∂ · Id for some ∂ 2 k (a scalar operator).\nRemark. Note that this Corollary is false over the field of real numbers: it suffices to take\nA = C (regarded as an R-algebra), and V = A.\nProof. Let ∂ be an eigenvalue of θ (a root of the characteristic polynomial of θ). It exists since k is\nan algebraically closed field. Then the operator θ - ∂Id is an intertwining operator V ⊃ V , which\nis not an isomorphism (since its determinant is zero). Thus by Proposition 1.16 this operator is\nzero, hence the result.\nCorollary 1.18. Let A be a commutative algebra. Then every irreducible finite dimensional rep\nresentation V of A is 1-dimensional.\nRemark. Note that a 1-dimensional representation of any algebra is automatically irreducible.\nProof. Let V be irreducible. For any element a 2 A, the operator δ(a) : V ⊃ V is an intertwining\noperator. Indeed,\nδ(a)δ(b)v = δ(ab)v = δ(ba)v = δ(b)δ(a)v\n(the second equality is true since the algebra is commutative). Thus, by Schur's lemma, δ(a) is\na scalar operator for any a 2 A. Hence every subspace of V is a subrepresentation. But V is\nirreducible, so 0 and V are the only subspaces of V . This means that dim V = 1 (since V = 0).\nExample 1.19. 1. A = k. Since representations of A are simply vector spaces, V = A is the only\nirreducible and the only indecomposable representation.\n2. A = k[x]. Since this algebra is commutative, the irreducible representations of A are its\n1-dimensional representations. As we discussed above, they are defined by a single operator δ(x).\nIn the 1-dimensional case, this is just a number from k. So all the irreducible representations of A\nare V = k, ∂ 2 k, in which the action of A defined by δ(x) = ∂. Clearly, these representations are\npairwise non-isomorphic.\nThe classification of indecomposable representations of k[x] is more interesting. To obtain it,\nrecall that any linear operator on a finite dimensional vector space V can be brought to Jordan\nnormal form. More specifically, recall\nJ\n\nthat the Jordan block\n,n is the operator on kn which in\nthe standard basis is given by the formulas J,nei = ∂ei + ei-1 for i > 1, and J,ne1 = ∂e1. Then\nfor any linear operator B : V ⊃ V there exists a basis of V such that the matrix of B in this basis\nis a direct sum of Jordan blocks. This implies that all the indecomposable representations of A are\n\nV\nn\n,n = k , ∂ 2 k, with δ(x) = J,n. The fact that these representations are indecomposable and\npairwise non-isomorphic follows from the Jordan normal form theorem (which in particular says\nthat the Jordan normal form of an operator is unique up to permutation of blocks).\n⇒\n\nThis example shows that an indecomposable representation of an algebra need not be irreducible.\n3. The group algebra A = k[G], where G is a group. A representation of A is the same thing as\na representation of G, i.e., a vector space V together with a group homomorphism δ : G ⊃ Aut(V ),\nwhre Aut(V ) = GL(V ) denotes the group of invertible linear maps from the space V to itself.\nProblem 1.20. Let V be a nonzero finite dimensional representation of an algebra A. Show that\nit has an irreducible subrepresentation. Then show by example that this does not always hold for\ninfinite dimensional representations.\nProblem 1.21. Let A be an algebra over a field k. The center Z(A) of A is the set of all elements\nz 2 A which commute with all elements of A. For example, if A is commutative then Z(A) = A.\n(a) Show that if V is an irreducible finite dimensional representation of A then any element\nz 2 Z(A) acts in V by multiplication by some scalar νV (z). Show that νV : Z(A) ⊃ k is a\nhomomorphism. It is called the central character of V .\n(b) Show that if V is an indecomposable finite dimensional representation of A then for any\nz 2 Z(A), the operator δ(z) by which z acts in V has only one eigenvalue νV (z), equal to the\nscalar by which z acts on some irreducible subrepresentation of V . Thus νV : Z(A) ⊃ k is a\nhomomorphism, which is again called the central character of V .\n(c) Does δ(z) in (b) have to be a scalar operator?\nProblem 1.22. Let A be an associative algebra, and V a representation of A. By EndA(V ) one\ndenotes the algebra of all homomorphisms of representations V ⊃ V . Show that End\nop\nA(A) = A\n,\nthe algebra A with opposite multiplication.\nProblem 1.23. Prove the following \"Infinite dimensional Schur's lemma\" (due to Dixmier): Let\nA be an algebra over C and V be an irreducible representation of A with at most countable basis.\nThen any homomorphism of representations θ : V ⊃ V is a scalar operator.\nHint. By the usual Schur's lemma, the algebra D := EndA(V ) is an algebra with division.\nShow that D is at most countably dimensional. Suppose θ is not a scalar, and consider the subfield\nC(θ) →D. Show that C(θ) is a transcendental extension of C. Derive from this that C(θ) is\nuncountably dimensional and obtain a contradiction.\n1.4\nIdeals\nA left ideal of an algebra A is a subspace I ∧ A such that aI ∧ I for all a 2 A. Similarly, a right\nideal of an algebra A is a subspace I ∧ A such that Ia ∧ I for all a 2 A. A two-sided ideal is a\nsubspace that is both a left and a right ideal.\nLeft ideals are the same as subrepresentations of the regular representation A. Right ideals are\nthe same as subrepresentations of the regular representation of the opposite algebra Aop.\nBelow are some examples of ideals:\n- If A is any algebra, 0 and A are two-sided ideals. An algebra A is called simple if 0 and A\nare its only two-sided ideals.\n- If θ : A ⊃ B is a homomorphism of algebras, then ker θ is a two-sided ideal of A.\n- If S is any subset of an algebra A, then the two-sided ideal generated by S is denoted *Si and\nis the span of elements of the form asb, where a, b 2 A and s 2 S. Similarly we can define\n*Siφ = span{as} and *Sir = span{sb}, the left, respectively right, ideal generated by S.\n\n1.5\nQuotients\nLet A be an algebra and I a two-sided ideal in A. Then A/I is the set of (additive) cosets of I.\nLet β : A ⊃ A/I be the quotient map. We can define multiplication in A/I by β(a) · β(b) := β(ab).\nThis is well defined because if β(a) = β(a0) then\nβ(a0\n+\n\nb) = β(ab\n\n(a - a)b) = β(ab) + β((a0 - a)b) = β(ab)\nbecause (a0 - a)b 2 Ib ∧ I = ker β, as I is a right ideal; similarly, if β(b) = β(b0) then\n\n0 -\n\nβ(ab ) = β(ab + a(b\nb)) = β(ab) + β(a(b0 - b)) = β(ab)\nbecause a(b0 - b) 2 aI ∧ I = ker β, as I is also a left ideal. Thus, A/I is an algebra.\nSimilarly, if V is a representation of A, and W →V is a subrepresentation, then V/W is also a\nrepresentation. Indeed, let β : V ⊃ V/W be the quotient map, and set δV/W (a)β(x) := β(δV (a)x).\nAbove we noted that left ideals of A are subrepresentations of the regular representation of A,\nand vice versa. Thus, if I is a left ideal in A, then A/I is a representation of A.\nProblem 1.24. Let A = k[x1, ..., xn] and I = A be any ideal in A containing all homogeneous\npolynomials of degree ⊂ N. Show that A/I is an indecomposable representation of A.\nProblem 1.25. Let V =\n0 be a representation of A. We say that a vector v 2 V is cyclic if it\ngenerates V , i.e., Av = V . A representation admitting a cyclic vector is said to be cyclic. Show\nthat\n(a) V is irreducible if and only if all nonzero vectors of V are cyclic.\n(b) V is cyclic if and only if it is isomorphic to A/I, where I is a left ideal in A.\n(c) Give an example of an indecomposable representation which is not cyclic.\nHint. Let A = C[x, y]/I2, where I2 is the ideal spanned by homogeneous polynomials of degree\n⊂\n\n⊕\n2 (so A has a basis 1, x, y). Let V = A\nbe the space of linear functionals on A, with the action\nof A given by (δ(a)f)(b) = f(ba). Show that V provides such an example.\n1.6\nAlgebras defined by generators and relations\nIf f1, . . . , fm are elements of the free algebra k*x1, . . . , xni, we say that the algebra\nA := k*x1, . . . , xni/*{f1, . . . , fm}i is generated by x1, . . . , xn with defining relations f1 = 0, . . . , fm =\n0.\n1.7\nExamples of algebras\n1. The Weyl algebra, k*x, yi/*yx - xy - 1i.\n2. The q-Weyl algebra, generated by x, x-1, y, y-1 with defining relations yx = qxy and xx-1 =\nx-1x = yy-1 = y-1y = 1.\nProposition. (i) A basis for the\n\nWeyl algebra A is {xiyj, i, j ⊂ 0}.\n(ii) A basis for the q-Weyl algebra\ni j\nAq is {x y , i, j 2 Z}.\n⇒\n\nProof. (i) First let us show that\n\nthe elements xiyj are a spanning set for A. To do this, n\nny word in x, y can be ordered to have all the x on the left of the y, at the cost of interc\nome x and y. Since yx - xy = 1, this will lead to error terms, but these terms will be\nonomials that have a smaller number of letters x, y than the original word. Therefore, co\nhis process, we can order everything and represent any word as a linear combination of x\nThe\n\nproof that xiyj are linearly independent is based on representation theory. Namely,\n\nvariable, and E = tak[a][t, t-1] (here ta is just a formal symbol, so really E = k[a][t, t-1]).\ns a representation of A with action given by xf\n\n+\ntf\ndf\nd(ta\nn)\n=\nand yf =\n(where\n:= (a + n)\n\ndt\ndt\nuppose now that we have a nontrivial\nj\nlinear relation ⎨c\ni\nij x y = 0. Then the operator\n\nd\nj\nL =\nX\ncij ti\n\ndt\n\ncts by zero in E. Let us write L as\nr\n\nj\nd\nL =\nX\nQj(t)\n\ndt\n\n,\nj=0\nhere Qr = 0. Then we have\nX\nr\nLta =\nQj (t)a(a - 1)...(a\nj\n- j + 1)ta-j .\n=0\nhis must be zero, so\nr\n\nwe have ⎨\nj=0 Qj (t)a(a - 1)...(a - j + 1)t-j = 0 in k[a][t, t-1]. Ta\neading term in a, we get Qr(t) = 0, a contradiction.\n(ii) Any word in x, y, x-1\n\n, y-1 can be ordered at the cost of multiplying it by a power of\nasily implies both the spanning property and the linear independence.\nRemark. The proof of (i) shows that the Weyl algebra A can be viewed as the al\nolynomial differential operators in one variable t.\nThe proof of (i) also brings up the notion of a faithful representation.\nDefinition. A representation δ : A ⊃ End V is faithful if δ is injective.\nFor example, k[t] is a faithful representation of the Weyl algebra, if k has characteris\ncheck it!), but not in characteristic p, where (d/dt)pQ = 0 for any polynomial Q. Howe\nepresentation E = tak[a][t, t-1], as we've seen, is faithful in any characteristic.\nroblem 1.26. Let A be the Weyl algebra, generated by two elements x, y with the relati\nyx - xy - 1 = 0.\n(a) If chark = 0, what are the finite dimensional representations of A? What are the t\ndeals in A?\nHint. For the first question, use the fact that for two square matrices B, C, Tr(BC) =\nor the second question, show that any nonzero two-sided ideal in A contains a nonzero pol\nn x, and use this to characterize this ideal.\nSuppose for the rest of the problem that chark = p.\n(b) What is the center of A?\note that\na\nhanging\ns\nsums of\nm\nntinuing\nt\niyj.\nlet a be\na\nThen E\ni\nta+n-1).\nS\na\nw\n⇒\nT\nking the\nl\nq. This\ne\ngebra of\np\ntic zero\n(\nver, the\nr\nP\non\nwo-sided\ni\nTr(CB).\nF\nynomial\ni\n\n-\n\nShow\nxp and yp\nHint.\nthat\nare central elements.\n(c) Find all irreducible finite dimensional representations of A.\nHint. Let V be an irreducible finite dimensional representation of A, and v be an eigenvector\nof y in V . Show that {v, xv, x2v, ..., xp-1v} is a basis of V .\nProblem 1.27. Let q be a nonzero complex number, and A be the q-Weyl algebra over C generated\n±\n\n-1\nby x\n1 and y±1 with defining relations xx\n= x-1x =\n1, yy-= y-1y = 1, and xy = qyx.\n(a) What is the center of A for different q? If q is not a root of unity, what are the two-sided\nideals in A?\n(b) For which q does this algebra have finite dimensional representations?\nHint. Use determinants.\n(c) Find all finite dimensional irreducible representations of A for such q.\nHint. This is similar to part (c) of the previous problem.\n1.8\nQuivers\nDefinition 1.28. A quiver Q is a directed graph, possibly with self-loops and/or multiple edges\nbetween two vertices.\nExample 1.29.\n-\n-\n\n-\n-\nWe denote the set of vertices of the quiver Q as I, and the set of edges as E. For an edge h 2 E,\n\nlet h0, h00 denote the source and target of h, respectively:\n\nh\n\nh\nh\n-00\nDefinition 1.30. A representation of a quiver Q is an assignment to each vertex i 2 I of a vector\nspace Vi and to each edge h 2 E of a linear map xh : Vh⊗ -⊃ Vh⊗⊗ .\nIt turns out that the theory of representations of quivers is a part of the theory of representations\nof algebras in the sense that for each quiver Q, there exists a certain algebra PQ, called the path\nalgebra of Q, such that a representation of the quiver Q is \"the same\" as a representation of the\nalgebra PQ. We shall first define the path algebra of a quiver and then justify our claim that\nrepresentations of these two objects are \"the same\".\nDefinition 1.31. The path algebra PQ of a quiver Q is the algebra whose basis is formed by\noriented paths in Q, including the trivial paths pi, i 2 I, corresponding to the vertices of Q, and\nmultiplication is concatenation of paths: ab is the path obtained by first tracing b and then a. If\ntwo paths cannot be concatenated, the product is defined to be zero.\n\nRemark 1.32. It is easy to see that for a finite quiver ⎨pi = 1, so PQ is an algebra with unit.\ni2I\nProblem 1.33. Show that the algebra PQ is generated by pi for i 2 I and ah for h 2 E with the\ndefining relations:\nO/\no\n/\n\n1. p2\ni = pi, pipj = 0 for i = j\n2. ahph⊗ = ah, ahpj = 0 for j = h0\n3. ph⊗⊗ ah = ah, piah = 0 for i = h00\nWe now justify our statement that a representation of a quiver is the same thing as a represen\ntation of the path algebra of a quiver.\nLet V be a representation of the path algebra PQ. From this representation, we can construct a\nrepresentation of Q as follows: let Vi = piV, and for any edge h, let xh = ah|p\nV\n⊗\nh\n: ph⊗ V -⊃ ph⊗⊗ V\nbe the operator corresponding to the one-edge path h.\nSimilarly, let (Vi, xh) be a representation of a quiver Q. From this representation, we can\nconstruct a representation of the path algebra PQ: let V =\ni Vi, let pi : V ⊃ Vi ⊃ V be the\nprojection onto Vi, and for any path p = h1...hm let ap = xh1 ...x\nL\nhm : Vh⊗ m ⊃ V\n\nh⊗⊗be the composition\nof the operators corresponding to the edges occurring in p (and the action of this operator on the\nother Vi is zero).\nIt is clear that the above assignments V 7⊃ (piV) and (Vi) 7⊃\ni Vi are inverses of each other.\nThus, we have a bijection between isomorphism classes of represen\nL\ntations of the algebra PQ and of\nthe quiver Q.\nRemark 1.34. In practice, it is generally easier to consider a representation of a quiver as in\nDefinition 1.30.\nWe lastly define several previous concepts in the context of quivers representations.\nDefinition 1.35. A subrepresentation of a representation (Vi, xh) of a quiver Q is a representation\n(Wi, x0\nh) where Wi ∧ Vi for all i 2 I and where xh(Wh⊗ ) ∧ Wh⊗⊗ and x0\nh = xh|W ⊗\nh : Wh⊗ -⊃ Wh⊗⊗ for\nall h 2 E.\nDefinition 1.36. The direct sum of two representations (Vi, xh) and (Wi, yh) is the representation\n(Vi Wi, xh yh).\nAs with representations of algebras, a nonzero representation (Vi) of a quiver Q is said to be\nirreducible if its only subrepresentations are (0) and (Vi) itself, and indecomposable if it is not\nisomorphic to a direct sum of two nonzero representations.\nDefinition 1.37. Let (Vi, xh) and (Wi, yh) be representations of the quiver Q. A homomorphism\n' : (Vi) -⊃ (Wi) of quiver representations is a collection of maps 'i : Vi -⊃ Wi such that\nyh inf 'h⊗ = 'h⊗⊗ inf xh for all h 2 E.\nProblem 1.38. Let A be a Z+-graded algebra, i.e., A = n\n0A[n], and A[n] · A[m] →A[n + m].\n∧\n\nIf A[n] is finite dimensional, it is useful to consider the Hilbert series hA(t) =\ndim A[n]tn (the\ngenerating function of dimensions of A[n]). Often this series converges to a rational\n⎨\nfunction, and\nthe answer is written in the form of such function. For example, if A = k[x] and deg(xn) = n then\nh\nn\nA(t) = 1 + t + t + ... + t + ... = 1 - t\nFind the Hilbert series of:\n(a) A = k[x1, ..., xm] (where the grading is by degree of polynomials);\n⇒\n⇒\n⇒\n\n(b) A = k < x1, ..., xm > (the grading is by length of words);\n(c) A is the exterior (=Grassmann) algebra √k[x1, ..., xm], generated over some field k by\n\nx1, ..., xm with the defining relations xixj + xj xi = 0 and xi = 0 for all i, j (the grading is by\ndegree).\n(d) A is the path algebra PQ of a quiver Q (the grading is defined by deg(pi) = 0, deg(ah) = 1).\nHint. The closed answer is written in terms of the adjacency matrix MQ of Q.\n1.9\nLie algebras\nLet g be a vector space over a field k, and let [ , ] : g × g -⊃ g be a skew-symmetric bilinear map.\n(That is, [a, a] = 0, and hence [a, b] = -[b, a]).\nDefinition 1.39. (g, [ , ]) is a Lie algebra if [ , ] satisfies the Jacobi identity\n\n[a, b] , c\n\n+\n\n[b, c] , a\n\n+\n\n[c, a] , b\n\n= 0.\n(2)\nExample 1.40. Some examples of Lie algebras are:\n1. Any space g with [ , ] = 0 (abelian Lie algebra).\n2. Any associative algebra A with [a, b] = ab - ba .\n3. Any subspace U of an associative algebra A such that [a, b] 2 U for all a, b 2 U.\n4. The space Der(A) of derivations of an algebra A, i.e. linear maps D : A ⊃ A which satisfy\nthe Leibniz rule:\nD(ab) = D(a)b + aD(b).\nRemark 1.41. Derivations are important because they are the \"infinitesimal version\" of automor\nphisms (i.e., isomorphisms onto itself). For example, assume that g(t) is a differentiable family of\nautomorphisms of a finite dimensional algebra A over R or C parametrized by t 2 (-φ, φ) such that\ng(0) = Id. Then D := g0(0) : A ⊃ A is a derivation (check it!). Conversely, if D : A ⊃ A is a\nderivation, then\n\netD is a 1-parameter family of automorphisms (give a proof!).\nThis provides a motivation for the notion of a Lie algebra. Namely, we see that Lie algebras\narise as spaces of infinitesimal automorphisms (=derivations) of associative algebras. In fact, they\nsimilarly arise as spaces of derivations of any kind of linear algebraic structures, such as Lie algebras,\nHopf algebras, etc., and for this reason play a very important role in algebra.\nHere are a few more concrete examples of Lie algebras:\n1. R3 with [u, v] = u × v, the cross-product of u and v.\n2. sl(n), the set of n × n matrices with trace 0.\nFor example, sl(2) has the basis\n\ne =\nf =\nh =\n0 0\n0 -1\n\nwith relations\n[h, e] = 2e, [h, f] = -2f, [e, f] = h.\n\n3. The Heisenberg Lie algebra H of\n\nmatrices\n0 0\n⊕\n\n⊕\n0 0 0\n⊕\n\nIt has the basis\n\n1 0\nx =\n⎧\n@ 0\n⎝\ny =\n⎧\n0 0\n\nc =\n⎧\n\n@\n⎝\n@\n⎝\nwith relations [y, x] = c and [y, c] = [x, c] = 0.\n4. The algebra aff(1) of matrices ( ⊕\n0 0\n⊕\n)\nIts basis consists of X = ( 1 0 ) and Y = ( 0 1\n0 0\n0 0 ), with [X, Y ] = Y .\n5. so(n), the space of skew-symmetric n × n matrices, with [a, b] = ab - ba.\nExercise. Show that Example 1 is a special case of Example 5 (for n = 3).\nDefinition 1.42. Let g1, g2 be Lie algebras. A homomorphism ' : g1 -⊃ g2 of Lie algebras is a\nlinear map such that '([a, b]) = ['(a), '(b)].\nDefinition 1.43. A representation of a Lie algebra g is a vector space V with a homomorphism\nof Lie algebras δ : g -⊃ End V .\nExample 1.44. Some examples of representations of Lie algebras are:\n1. V = 0.\n2. Any vector space V with δ = 0 (the trivial representation).\n3. The adjoint representation V = g with δ(a)(b) := [a, b]. That this is a representation follows\nfrom Equation (2). Thus, the meaning of the Jacobi identity is that it is equivalent to the\nexistence of the adjoint representation.\nIt turns out that a representation of a Lie algebra g is the same thing as a representation of a\ncertain associative algebra U(g). Thus, as with quivers, we can view the theory of representations\nof Lie algebras as a part of the theory of representations of associative algebras.\nDefinition 1.45. Let g be a Lie algebra with basis xi and [ , ] defined by [xi, xj ] =\nk c xk. The\nuniversal enveloping algebra⎨ U(g) is the associative algebra generated by the\n⎨\nxi's with the\ndefining relations xixj\n=\nk\n- xjxi\n\nk cij xk.\nRemark. This is not a very good definition since it depends on the choice of a basis. Later we\nwill give an equivalent definition which will be basis-independent.\nExercise. Explain why a representation of a Lie algebra is the same thing as a representation\nof its universal enveloping algebra.\nExample 1.46. The associative algebra U(sl(2)) is the algebra generated by e, f, h with relations\nhe - eh = 2e\nhf - fh = -2f\nef - fe = h.\nExample 1.47. The algebra U(H), where H is the Heisenberg Lie algebra, is the algebra generated\nby x, y, c with the relations\nyx - xy = c\nyc - cy = 0\nxc - cx = 0.\nNote that the Weyl algebra is the quotient of U(H) by the relation c = 1.\n\n1.10\nTensor products\nIn this subsection we recall the notion of tensor product of vector spaces, which will be extensively\nused below.\nDefinition 1.48. The tensor product V\nW of vector spaces V and W over a field k is the quotient\nof the space V ∼ W whose basis is given by formal symbols v\nw, v 2 V , w 2 W , by the subspace\nspanned by the elements\n(v1 + v2)\nw - v1\nw - v2\nw, v\n(w1 + w2) - v\nw1 - v\nw2, av\nw - a(v\nw), v\naw - a(v\nw),\nwhere v 2 V, w 2 W, a 2 k.\nExercise. Show that V\nW can be equivalently defined as the quotient of the free abelian\ngroup V - W generated by v\nw, v 2 V, w 2 W by the subgroup generated by\n(v1 + v2)\nw - v1\nw - v2\nw, v\n(w1 + w2) - v\nw1 - v\nw2, av\nw - v\naw,\nwhere v 2 V, w 2 W, a 2 k.\nThe elements v\nw 2 V\nW , for v 2 V, w 2 W are called pure tensors. Note that in general,\nthere are elements of V\nW which are not pure tensors.\nThis allows one to define the tensor product of any number of vector spaces, V1\n...\nVn. Note\nthat this tensor product is associative, in the sense that (V1\nV2)\nV3 can be naturally identified\nwith V1\n(V2\nV3).\n\nIn particular, people often consider tensor products of the form V\nn = V\n...\nV (n times) for\na\n\ngiven vector space V , and, more generally, E := V\nn\n(V ⊕)\nm. This space is called the space of\ntensors of type (m, n) on V . For instance, tensors of type (0, 1) are vectors, of type (1, 0) - linear\nfunctionals (covectors), of type (1, 1) - linear operators, of type (2, 0) - bilinear forms, of type (2, 1)\n- algebra structures, etc.\nIf V\ni\n\nis finite dimensional with basis e , i = 1, ..., N, and ei is the dual basis of V ⊕, then a basis\nof E is the set of vectors\ne\nj1\njm\ni1\n...\nein\ne\n\n...\ne\n,\nand a typical element of E is\nX\nN\nT i1...in\nj\n... e\nj1\n...j ei\nin\ne\n... ejm ,\nm\ni1,...,in,j1,...,j\n\nm=1\n\nwhere T is a multidimensional table of numbers.\nPhysicists define a tensor as a collection of such multidimensional tables TB attached to every\nbasis B in V , which change according to a certain rule when the basis B is changed. Here it is\nimportant to distinguish upper and lower indices, since lower indices of T correspond to V and\nupper ones to V ⊕. The physicists don't write the sum sign, but remember that one should sum\nover indices that repeat twice - once as an upper index and once as lower. This convention is\ncalled the Einstein summation, and it also stipulates that if an index appears once, then there is\nno summation over it, while no index is supposed to appear more than once as an upper index or\nmore than once as a lower index.\n\nOne can also define the tensor product of linear maps. Namely, if A : V ⊃ V 0 and B : W ⊃ W 0\nare linear maps, then\n\none can define the linear map A\nB : V\nW ⊃ V 0\nW 0 given by the formula\n(A\nB)(v\nw) = Av\nBw (check that this is well defined!)\n\nThe most important properties of tensor products are summarized in the following problem.\nProblem 1.49. (a) Let U be any k-vector space. Construct a natural bijection between bilinear\nmaps V × W ⊃ U and linear maps V\nW ⊃ U.\n(b) Show that if {vi} is a basis of V and {wj } is a basis of W then {vi\nwj } is a basis of\nV\nW .\n(c) Construct a natural isomorphism V ⊕\nW ⊃ Hom(V, W ) in the case when V is finite\ndimensional (\"natural\" means that the isomorphism is defined without choosing bases).\n(d)\n\nLet V be a vector space over a field k. Let SnV be the quotient of V\nn (n-fold tensor product\nof V ) by the subspace spanned by the tensors T - s(T ) where T 2 V\nn, and s is some transposition.\nAlso let √nV be the quotient of V\nn by the subspace spanned by the tensors T such that s(T ) = T\nfor some transposition s. These spaces are called the n-th symmetric, respectively exterior, power\nof V . If {vi} is a basis of V , can you construct a basis of SnV, √nV ? If dimV = m, what are their\ndimensions?\n(e) If k has characteristic zero, find\n\na natural identification of S nV with the space of T 2 V\nn\nsuch that T = sT for all transpositions s, and\n\nof √nV with the space of T 2 V\nn such that T = -sT\nfor all transpositions s.\n(f) Let A : V ⊃ W be a linear operator. Then we have\n\nan operator A\nn : V\nn ⊃ W\nn, and\nits symmetric and exterior powers SnA : SnV ⊃ SnW , √nA : √nV ⊃√nW which are defined in\nan obvious way. Suppose V = W and has dimension N, and assume that the eigenvalues of A are\n∂1, ..., ∂N . Find Tr(SnA), Tr(√nA).\n(g) Show that √N A = det(A)Id, and use this equality to give a one-line proof of the fact that\ndet(AB) = det(A) det(B).\nRemark. Note that a similar definition to the above can be used to define the tensor product\nV\nA W , where A is any ring, V is a right A-module, and W is a left A-module. Namely, V\nA W\nis the abelian group which is the quotient of the group V - W freely generated by formal symbols\nv\nw, v 2 V , w 2 W , modulo the relations\n(v1 + v2)\nw - v1\nw - v2\nw, v\n(w1 + w2) - v\nw1 - v\nw2, va\nw - v\naw, a 2 A.\nExercise. Throughout this exercise, we let k be an arbitrary field (not necessarily of charac\nteristic zero, and not necessarily algebraically closed).\nIf A and B are two k-algebras, then an (A, B)-bimodule will mean a k-vector space V with\nboth a left A-module structure and a right B-module structure which satisfy (av) b = a (vb) for\nany v 2 V , a 2 A and b 2 B. Note that both the notions of \"left A-module\" and \"right A-\nmodule\" are particular cases of the notion of bimodules; namely, a left A-module is the same as an\n(A, k)-bimodule, and a right A-module is the same as a (k, A)-bimodule.\nLet B be a k-algebra, W a left B-module and V a right B-module. We denote by V\nB W the\nk-vector space (V\nk W ) / *vb\nw - v\nbw | v 2 V, w 2 W, b 2 Bi. We denote the projection of\na pure tensor v\nw (with v 2 V and w 2 W ) onto the space V\nB W by v\nB w. (Note that this\ntensor product V\nB W is the one defined in the Remark after Problem1.49.)\nIf, additionally, A is another k-algebra, and if the right B-module structure on V is part of an\n(A, B)-bimodule structure, then V\nB W becomes a left A-module by a (v\nB w) = av\nB w for\nany a 2 A, v 2 V and w 2 W .\n\nSimilarly, if C is another k-algebra, and if the left B-module structure on W is part of a (B, C)\nbimodule structure, then V\nB W becomes a right C-module by (v\nB w) c = v\nB wc for any\nc 2 C, v 2 V and w 2 W .\nIf V is an (A, B)-bimodule and W is a (B, C)-bimodule, then these two structures on V\nB W\ncan be combined into one (A, C)-bimodule structure on V\nB W .\n(a) Let A, B, C, D be four algebras. Let V be an (A, B)-bimodule, W be a (B, C)-bimodule,\nand X a (C, D)-bimodule. Prove that (V\nB W )\nC X ∪= V\nB (W\nC X) as (A, D)-bimodules.\nThe isomorphism (from left to right) is given by (v\nB w)\nC x 7⊃ v\nB (w\nC x) for all v 2 V ,\nw 2 W and x 2 X.\n(b) If A, B, C are three algebras, and if V is an (A, B)-bimodule and W an (A, C)-bimodule,\nthen the vector space HomA (V, W ) (the space of all left A-linear homomorphisms from V to W )\ncanonically becomes a (B, C)-bimodule by setting (bf) (v) = f (vb) for all b 2 B, f 2 HomA (V, W )\nand v 2 V and (fc) (v) = f (v) c for all c 2 C, f 2 HomA (V, W ) and v 2 V .\nLet A, B, C, D be four algebras. Let V be a (B, A)-bimodule, W be a (C, B)-bimodule, and X a\n(C, D)-bimodule. Prove that HomB (V, HomC (W, X)) ∪= HomC (W\nB V, X) as (A, D)-bimodules.\nThe isomorphism (from left to right) is given by f 7⊃ (w\nB v 7⊃ f (v) w) for all v 2 V , w 2 W\nand f 2 HomB (V, HomC (W, X)).\n1.11\nThe tensor algebra\nThe notion of tensor product allows us to give more conceptual (i.e., coordinate free) definitions\nof the free algebra, polynomial algebra, exterior algebra, and universal enveloping algebra of a Lie\nalgebra.\nNamely, given a vector space V , define\n\nits tensor algebra TV over a field k to be TV =\nn\nn\n0V\n,\n∧\nwith multiplication defined by a ·\n\nb := a\nb, a 2 V\nn, b 2 V\nm. Observe that a choice of a basis\nx1, ..., xN in V defines an isomorphism of TV with the free algebra k < x1, ..., xn >.\nAlso, one can make the following definition.\nDefinition 1.50. (i) The symmetric algebra SV of V is the quotient of TV by the ideal generated\nby v\nw - w\nv, v, w 2 V .\n(ii) The exterior algebra √V of V is the quotient of TV by the ideal generated by v\nv, v 2 V .\n(iii) If V is a Lie algebra, the universal enveloping algebra U(V ) of V is the quotient of TV by\nthe ideal generated by v\nw - w\nv - [v, w], v, w 2 V .\nIt is easy to see that a choice of a basis x1, ..., xN in V identifies SV with the polynomial algebra\nk[x1, ..., xN ], √V with the exterior algebra √k(x1, ..., xN ), and the universal enveloping algebra U(V )\nwith one defined previously.\nAlso, it is\n\neasy to see that we have decompositions SV = n∧0SnV , √V =\nn\nn∧0 √V .\n1.12\nHilbert's third problem\nProblem 1.51. It is known that if A and B are two polygons of the same area then A can be cut\nby finitely many straight cuts into pieces from which one can make B. David Hilbert asked in 1900\nwhether it is true for polyhedra in 3 dimensions. In particular, is it true for a cube and a regular\ntetrahedron of the same volume?\n\nThe answer is \"no\", as was found by Dehn in 1901. The proof is very beautiful. Namely, to\nany polyhedron A let us attach its \"Dehn invariant\" D(A) in V = R\n(R/Q) (the tensor product\nof Q-vector spaces). Namely,\n\nα(a)\nD(A) =\nX\nl(a)\n\n,\nβ\na\nwhere a runs over edges of A, and l(a), α(a) are the length of a and the angle at a.\n(a) Show that if you cut A into B and C by a straight cut, then D(A) = D(B) + D(C).\n(b) Show that φ = arccos(1/3)/β is not a rational number.\nHint. Assume that φ = 2m/n, for integers m, n. Deduce that\n\nroots of the equation x+x-1 = 2/3\nare roots of unity of degree n. Conclude\n\nthat xk + x-k has denominator 3k and get a contradiction.\n(c) Using (a) and (b), show that the answer to Hilbert's question is negative. (Compute the\nDehn invariant of the regular tetrahedron and the cube).\n1.13\nTensor products and duals of representations of Lie algebras\nDefinition 1.52. The tensor product of two representations V, W of a Lie algebra g is the space\nV\nW with δV\nW (x) = δV (x)\n\nId + Id\nδW (x).\nDefinition\n\n1.53. The dual representation V ⊕to a representation V of a Lie algebra g is the dual\n⊕\nspace V\nto V with δV (x) = -δV (x)⊕.\nIt is easy to check that these are indeed representations.\nProblem 1.54. Let V, W, U be finite dimensional representations of a Lie algebra g. Show that\nthe space Homg(V\nW, U) is isomorphic to Homg(V, U\nW ⊕). (Here Homg := HomU(g)).\n1.14\nRepresentations of sl(2)\nThis subsection is devoted to the representation theory of sl(2), which is of central importance in\nmany areas of mathematics. It is useful to study this topic by solving the following sequence of\nexercises, which every mathematician should do, in one form or another.\nProblem 1.55. According to the above, a representation of sl(2) is just a vector space V with a\ntriple of operators E, F, H such that HE - EH = 2E, HF - FH = -2F, EF - FE = H (the\ncorresponding map δ is given by δ(e) = E, δ(f) = F , δ(h) = H).\nLet V be a finite dimensional representation of sl(2) (the ground field in this problem is C).\n\n(a) Take eigenvalues of H and pick one with the biggest real part. Call it ∂. Let V (∂) be the\ngeneralized eigenspace corresponding to ∂. Show that E|V () = 0.\n(b) Let W be any representation of sl(2) and w 2 W be a nonzero vector such that Ew = 0.\nFor any k > 0 find a polynomial Pk(x) of degree k such that EkF kw = Pk(H)w. (First compute\nEF kw, then use induction in k).\n\n(c) Let v\nV (∂) be a generalized eigenvector of H with eigenvalue ∂. Show that there exists\n\nN > 0 such that F Nv = 0.\n(d) Show\n\nthat H is diagonalizable on V (∂). (Take\n\nN to be such that F N\n\n= 0 on V (∂), and\ncompute EN F N v,\n\nv 2 V (∂), by (b). Use the fact that Pk(x) does not have multiple roots).\n\n(e) Let Nv be the smallest N satisfying (c). Show that ∂ = Nv - 1.\n(f) Show that for each N > 0, there exists a unique up to isomorphism irreducible representation\nof sl(2) of dimension N. Compute the matrices E, F, H in this representation using a convenient\nbasis. (For V finite dimensional irreducible take ∂ as in (a) and v 2 V (∂) an eigenvector of H.\nShow that v, Fv, ..., F v is a basis of V , and compute the matrices of the operators E, F, H in this\nbasis.)\nDenote the ∂ + 1-dimensional irreducible representation from (f) by V. Below you will show\nthat any finite dimensional representation is a direct sum of V.\n(g) Show that the operator C = EF + FE + H2/2 (the so-called Casimir operator) commutes\n\n(+2)\nwith E, F, H and equals\nId on V.\nNow it will be easy to prove the direct sum decomposition. Namely, assume the contrary, and\nlet V be a reducible representation of the smallest dimension, which is not a direct sum of smaller\nrepresentations.\n(h) Show that\n\non\n+2)\nC has only one eigenvalue\nV ,\n(\n\nnamely\nfor some nonnegative integer ∂.\n(use that the generalized eigenspace decomposition of C must be a decomposition of representations).\n(i) Show that V has a subrepresentation W = V such that V/W = nV for some n (use (h)\nand the fact that V is the smallest which cannot be decomposed).\n(j) Deduce from (i) that the eigenspace V (∂) of H is n + 1-dimensional. If v1, ..., vn+1 is its\nbasis, show that F j vi, 1 ∗ i ∗ n + 1, 0 ∗ j ∗ ∂ are linearly independent and therefore form a basis\nof V\nμ μ\n(establish that if\n(\n2)\nFx = 0 and Hx = μx then Cx =\n-\nx and hence μ = -∂).\n(k) Define W = span(v , Fv , ..., F\ni\ni\ni\nvi). Show that Vi are subrepresentations of V and derive a\ncontradiction with the fact that V cannot be decomposed.\n(l) (Jacobson-Morozov Lemma) Let V be a finite dimensional complex vector space and A : V ⊃\nV a nilpotent operator. Show that there exists a unique, up to an isomorphism, representation of\nsl(2) on V such that E = A. (Use the classification of the representations and the Jordan normal\nform theorem)\n(m) (Clebsch-Gordan decomposition) Find the decomposition into irreducibles of the represen\ntation V\nVμ of sl(2).\nHint. For a finite dimensional representation V of sl(2) it is useful to introduce the character\nν\nxH\nV (x) = Tr(e\n), x 2 C. Show that νV\nW (x) = νV (x) + νW (x) and νV\nW (x) = νV (x)νW (x).\n∈\n\nThen compute the character of V and of V\nVμ and derive the decomposition. This decomposition\nis of fundamental importance in quantum mechanics.\n(n) Let V = CM\nCN , and A = JM (0)\nIdN + IdM\nJN (0), where Jn(0) is the Jordan block\nof size n with eigenvalue zero (i.e., Jn(0)ei = ei\n1, i = 2, ..., n, and J\n\n-\nn(0)e1 = 0). Find the Jordan\nnormal form of A using (l),(m).\n1.15\nProblems on Lie algebras\nProblem 1.56. (Lie's Theorem) The commutant K(g) of a Lie algebra g is the linear span\nof elements [x, y], x, y 2 g. This is an ideal in g (i.e., it is a subrepresentation of the adjoint\nrepresentation). A finite dimensional Lie algebra g over a field k is said to be solvable if there\nexists n such that Kn(g) = 0. Prove the Lie theorem: if k = C and V is a finite dimensional\nirreducible representation of a solvable Lie algebra g then V is 1-dimensional.\n\nHint. Prove the result by induction in dimension. By the induction assumption, K(g) has a\ncommon eigenvector v in V , that is there is a linear function ν : K(g) ⊃ C such that av = ν(a)v\nfor any a 2 K(g). Show that g preserves common eigenspaces of K(g) (for this you will need to\nshow that ν([x, a]) = 0 for x 2 g and a 2 K(g). To prove this, consider the smallest vector subspace\nU containing v and invariant under x. This subspace is invariant under K(g) and any a 2 K(g)\nacts with trace dim(U)ν(a) in this subspace. In particular 0 = Tr([x, a]) = dim(U)ν([x, a]).).\nProblem 1.57. Classify irreducible finite dimensional representations of the two dimensional Lie\nalgebra with basis X, Y and commutation relation [X, Y ] = Y . Consider the cases of zero and\npositive characteristic. Is the Lie theorem true in positive characteristic?\nProblem 1.58. (hard!) For any element x of a Lie algebra g let ad(x) denote the operator g ⊃\ng, y 7⊃ [x, y]. Consider the Lie algebra gn generated by two elements x, y with the defining relations\nad(x)2(y) = ad(y)n+1(x) = 0.\n(a) Show that the Lie algebras g1, g2, g3 are finite dimensional and find their dimensions.\n(b) (harder!) Show that the Lie algebra g4 has infinite dimension. Construct explicitly a basis\nof this algebra.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n18.712 Introduction to Representation Theory\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "General results of representation theory",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/0721b66f53c3c196ce86d6d867514442_MIT18_712F10_ch2.pdf",
      "content": "General results of representation theory\n2.1\nSubrepresentations in semisimple representations\nLet A be an algebra.\nDefinition 2.1. A semisimple (or completely reducible) representation of A is a direct sum of\nirreducible representations.\nExample. Let V be an irreducible representation of A of dimension n. Then Y = End(V ),\nwith action of A by left multiplication, is a semisimple representation of A, isomorphic to nV (the\ndirect sum of n copies of V ). Indeed, any basis v1, ..., vn of V gives rise to an isomorphism of\nrepresentations End(V ) ⊃ nV , given by x ⊃ (xv1, ..., xvn).\nRemark. Note that by Schur's lemma, any semisimple representation V of A is canonically\nidentified with X HomA(X, V )\nX, where X runs over all irreducible representations of A. Indeed,\nwe have a natural map f : X Hom(X, V )\nX ⊃ V , given by g\nx ⊃ g(x), x 2 X, g 2 Hom(X, V ),\nand it is easy to verify that this map is an isomorphism.\nWe'll see now how Schur's lemma allows us to classify subrepresentations in finite dimensional\nsemisimple representations.\nProposition 2.2. Let Vi, 1 ∗ i ∗ m be irreducible finite dimensional pairwise nonisomorphic\nrepresentations of A, and W be a subrepresentation of V = m\ni=1niVi. Then W is isomorphic to\nm\ni=1riVi, ri ∗ ni, and the inclusion θ : W ⊃ V is a direct sum of inclusions θi : riVi ⊃ niVi given\nby multiplication of a row vector of elements of Vi (of length ri) by a certain ri-by-ni matrix Xi\nwith linearly independent rows: θ(v1, ..., vri ) = (v1, ..., vri )Xi.\nProof. The proof is\nm\nby induction in n := ⎨\ni=1 ni. The base of induction (n = 1) is clear. To perform\nthe induction step, let us assume that W is nonzero, and fix an irreducible subrepresentation\nP →W . Such P exists (Problem 1.20). 2 Now, by Schur's lemma, P is isomorphic to Vi for some i,\nand the inclusion θ|P : P ⊃ V factors through niVi, and upon identification of P with Vi is given\nby the formula v 7⊃ (vq1, ..., vqni ), where ql 2 k are not all zero.\nNow note that the group Gi = GLni (k) of invertible ni-by-ni matrices over k acts on niVi\nby (v1, ..., vni ) ⊃ (v1, ..., vni )gi (and by the identity on njVj , j = i), and therefore acts on the\nset of subrepresentations of V , preserving the property we need to establish: namely, under the\naction of gi, the matrix Xi goes to Xigi, while Xj , j = i don't change. Take gi 2 Gi such that\n(q1, ..., qni )gi = (1, 0, ..., 0). Then Wgi contains the first summand Vi of niVi (namely, it is Pgi),\n\nhence Wgi = Vi W 0, where W 0 →n1V1 ... (ni - 1)Vi ... nmVm is the kernel of the projection\nof Wgi to the first summand Vi along the other summands. Thus the required statement follows\nfrom the induction assumption.\nRemark 2.3. In Proposition 2.2, it is not important that k is algebraically closed, nor it matters\nthat V is finite dimensional. If these assumptions are dropped, the only change needed is that the\nentries of the matrix Xi are no longer in k but in Di = EndA(Vi), which is, as we know, a division\nalgebra. The proof of this generalized version of Proposition 2.2 is the same as before (check it!).\n2Another proof of the existence of P , which does not use the finite dimensionality of V , is by induction in n.\nNamely, if W itself is not irreducible, let K be the kernel of the projection of W to the first summand V1. Then\nK is a subrepresentation of (n1 - 1)V1 ... nmVm, which is nonzero since W is not irreducible, so K contains an\nirreducible subrepresentation by the induction assumption.\n\n2.2\nThe density theorem\nLet A be an algebra over an algebraically closed field k.\nCorollary 2.4. Let V be an irreducible finite dimensional representation of A, and v1, ..., vn 2 V\nbe any linearly independent vectors. Then for any w1, ..., wn 2 V there exists an element a 2 A\nsuch that avi = wi.\nProof. Assume the contrary. Then the image of the map A ⊃ nV given by a ⊃ (av1, ..., avn) is a\nproper subrepresentation, so by Proposition 2.2 it corresponds to an r-by-n matrix X, r < n. Thus,\ntaking a = 1, we see that there exist vectors u1, ..., ur 2 V such that (u1, ..., ur)X = (v1, ...,⎨\nvn). Let\n\n(q1, ..., qn) be a nonzero\n\nvector such ⎨\nthat X(q1, ..., qn)T = 0 (it exists because r < n). Then\nq\n\nivi =\n\n(u\nT\n1, ..., ur )X(q1, ..., qn)\n= 0, i.e.\nqivi = 0 - a contradiction with the linear independence of\nvi.\nTheorem 2.5. (the Density Theorem). (i) Let V be an irreducible finite dimensional representation\nof A. Then the map δ : A ⊃ EndV is surjective.\n(ii) Let V = V1 ... Vr, where Vi are irreducible pairwise nonisomorphic finite dimensional\nr\nrepresentations of A. Then\n\nthe map r\ni=1δi : A ⊃i=1 End(Vi) is surjective.\nProof. (i) Let B be the image of A in End(V ). We want to show that B = End(V ). Let c 2 End(V ),\nv1, ..., vn be a basis of V , and wi = cvi. By Corollary 2.4, there exists a 2 A such that avi = wi.\nThen a maps to c, so c 2 B, and we are done.\n(ii) Let\n\nB\nEnd(V\nr\ni be the image of A in\ni), and B be the image of A in i=1 End(Vi). Recall that as\nof\n\na representation\nA, r\ni=1 End(Vi) is semisimple: it is isomorphic to r\ni=1diVi, where di = dim Vi.\nThen by Proposition 2.2, B = iBi. On the other hand, (i) implies that Bi = End(Vi). Thus (ii)\nfollows.\n2.3\nRepresentations of direct sums of matrix algebras\nIn this section we consider representations of algebras A =\ni Matdi (k) for any field k.\n= Lr\nTheorem 2.6. Let A\ni=1 Matdi (k). Then the irreducible\nL\nrepresentations of A are V1 =\nkd1 , . . . , V\nd\nr = k r , and any finite dimensional representation of A is a direct sum of copies of\nV1, . . . , Vr.\nIn order to prove Theorem 2.6, we shall need the notion of a dual representation.\nDefinition 2.7. (Dual representation) Let V be a representation of any algebra A. Then the\n\ndual representation V ⊕is the representation of the opposite algebra Aop (or, equivalently, right\nA-module) with the action\n(f · a)(v) := f(av).\nProof of Theorem 2.6. First, the given representations are clearly irreducible, as for any v = 0, w 2\nVi, there exists a 2 A such that av = w. Next, let X be an n-dimensional representation of\nA. Then, X⊕ is an n-dimensional\nop\nrepresentation of Aop. But\n\n(Matdi (k))\n∪= Matdi (k) with\n\nisomorphism '(X) = XT , as (BC)T = CT BT. Thus, A =∪ Aop and X⊕may be viewed as an\nn-dimensional representation of A. Define\nθ : A| ·{z· ·\n\nA} -⊃ X⊕\n\nn copies\n\nby\nθ(a1, . . . , an) = a1y1 + · · · + anyn\nwhere {yi} is a basis\n\nof X⊕. θ is clearly surjective, as k\nA. Thus, the dual map θ⊕: X\nAn⊕\n\nn⊕\n\n-\n∪\n\n→\n⊃\nis injective. But A\n= An as representations of A (check it!). Hence, Im θ⊕∪= X is a subrepresen\ntation of An\n\n. Next, Matdi (k) = diVi, so A = r\nn\nr\ni=1diVi, A\n= i=1ndiVi, as a representation of A.\nHence by Proposition 2.2, X\n\n= r\ni=1miVi, as desired.\nExercise. The goal of this exercise is to give an alternative proof of Theorem 2.6, not using\nany of the previous results of Chapter 2.\nLet A1, A2, ..., An be n algebras with units 11, 12, ..., 1n, respectively. Let A = A1 A2 ...An.\nClearly, 1i1j = ζij1i, and the unit of A is 1 = 11 + 12 + ... + 1n.\nFor every representation V of A, it is easy to see that 1iV is a representation of Ai for every\ni 2 {1, 2, ..., n}. Conversely, if V1, V2, ..., Vn are representations of A1, A2, ..., An, respectively,\nthen V1 V2 ... Vn canonically becomes a representation of A (with (a1, a2, ..., an) 2 A acting\non V1 V2 ... Vn as (v1, v2, ..., vn) 7⊃ (a1v1, a2v2, ..., anvn)).\n(a) Show that a representation V of A is irreducible if and only if 1iV is an irreducible repre\nsentation of Ai for exactly one i 2 {1, 2, ..., n}, while 1iV = 0 for all the other i. Thus, classify the\nirreducible representations of A in terms of those of A1, A2, ..., An.\n(b) Let d 2 N. Show that the only irreducible representation of Matd(k) is kd, and every finite\ndimensional representation of\n\nMatd(k) is a direct sum of copies of kd.\nHint: For every (i, j) 2 {1, 2, ..., d} 2, let Eij 2 Matd(k) be the matrix with 1 in the ith row of the\njth column and 0's everywhere else. Let V be a finite dimensional representation of Matd(k). Show\nthat V = E11V E22V ... EddV , and that i : E11V ⊃ EiiV , v 7⊃ Ei1v is an isomorphism for\nevery i 2 {1, 2, ..., d}. For every v 2 E11V , denote S (v) = *E11v, E21v, ..., Ed1vi. Prove that S (v)\nis a\n\nsubrepresentation of V isomorphic to kd (as a representation of Matd(k)), and that v 2 S (v).\nConclude that V = S (v1) S (v2) ... S (vk), where {v1, v2, ..., vk} is a basis of E11V .\n(c) Conclude Theorem 2.6.\n2.4\nFiltrations\nLet A be an algebra. Let V be a representation of A. A (finite) filtration of V is a sequence of\nsubrepresentations 0 = V0 → V1 →... → Vn = V .\nLemma 2.8. Any finite dimensional representation V of an algebra A admits a finite filtration\n0 = V0 → V1 →... → Vn = V such that the successive quotients Vi/Vi\neducible.\n-1 are irr\n\nProof. The proof is by induction in dim(V ). The base is clear, and only the induction step needs\nto be justified. Pick an irreducible subrepresentation V1 →V , and consider the representation\nU = V/V1. Then by the induction assumption U has a filtration 0 = U0 → U1 →... →Un\n= U\n-1\nsuch that Ui/Ui\n1 are irreducible. Define Vi for i ⊂ 2 to be the preimages of U\n-\ni\nunder\n-1\nthe\ntautological projection V ⊃ V/V1 = U. Then 0 = V0 → V1 →V2 →... →Vn = V is a filtration of V\nwith the desired property.\n\n2.5\nFinite dimensional algebras\nDefinition 2.9. The radical of a finite dimensional algebra A is the set of all elements of A which\nact by 0 in all irreducible representations of A. It is denoted Rad(A).\nProposition 2.10. Rad(A) is a two-sided ideal.\nProof. Easy.\nProposition 2.11. Let A be a finite dimensional algebra.\n(i) Let\n\nI be a nilpotent two-sided ideal in A, i.e., I n = 0 for some n. Then I → Rad(A).\n(ii) Rad(A) is a nilpotent ideal. Thus, Rad(A) is the largest nilpotent two-sided ideal in A.\nProof. (i) Let V be an irreducible representation of A. Let v 2 V . Then Iv →V is a subrepresen\ntation. If Iv = 0 then Iv = V so there is x 2 I such that xv = v. Then xn = 0, a contradiction.\nThus Iv = 0, so I acts by 0 in V and hence I → Rad(A).\n(ii) Let 0 = A0 → A1 →... →An = A be a filtration of the regular representation of A by\nsubrepresentations such that Ai+1/Ai are irreducible. It exists by Lemma 2.8. Let x 2 Rad(A).\nThen\n\nx acts on A\nn\ni+1/Ai by zero, so x maps Ai+1 to Ai. This implies that Rad(A)\n= 0, as\ndesired.\nTheorem 2.12. A finite dimensional algebra A has only finitely many irreducible representations\nVi up to isomorphism, these representations are finite dimensional, and\nA/Rad(A) ∪M\n=\nEnd Vi.\ni\nProof. First, for any irreducible representation V of A, and for any nonzero v 2 V , Av ∧ V is a\nfinite dimensional subrepresentation of V . (It is finite dimensional as A is finite dimensional.) As\nV is irreducible and Av = 0, V = Av and V is finite dimensional.\nNext, suppose we have non-isomorphic irreducible representations V1, V2, . . . , Vr. By Theorem\n2.5, the homomorphism\nM\n\nδi : A -⊃\nM\nEnd Vi\ni\ni\nis surjective. So r ∗ ⎨\ni dim End Vi ∗ dim A. Thus, A has only finitely many non-isomorphic\nirreducible representations (at most dim A).\nNow, let V1, V2, . . . , Vr be all non-isomorphic irreducible finite dimensional representations of\nA. By Theorem 2.5, the homomorphism\nM\n\nδi : A -⊃\nM\nEnd Vi\ni\ni\nis surjective. The kernel of this map, by definition, is exactly Rad(A).\nCorollary 2.13. ⎨\ni (dim\nVi) ∗ dim A, where the Vi's are the irreducible representations of A.\nProof. As dim End Vi =\n⎨\n(dim Vi) , Theorem\n⎨\n2.12 implies that dim A-dim Rad(A) =\ni dim End Vi =\ni (dim Vi) . As dim Rad(A) ⊂ 0,\ni (dim Vi) ∗ dim A.\n⎨\n\nExample 2.14. 1. Let A = k[x]/(xn). This algebra has a unique irreducible representation, which\nis a 1-dimensional space k, in which x acts by zero. So the radical Rad(A) is the ideal (x).\n2. Let A be the algebra of upper triangular n by n matrices. It is easy to check that the\nirreducible representations of A are Vi, i = 1, ..., n, which are 1-dimensional, and any matrix x acts\nby xii. So the radical Rad(A) is the ideal of strictly upper triangular matrices (as it is a nilpotent\nideal and contains the radical). A similar result holds for block-triangular matrices.\nDefinition 2.15. A finite dimensional algebra A is said to be semisimple if Rad(A) = 0.\nProposition 2.16. For a finite dimensional algebra A, the following are equivalent:\n1. A is semisimple.\n2. ⎨\ni (dim\nVi) = dim A, where the Vi's are the irreducible representations of A.\n3. A ∪= L\ni Matdi (k) for some di.\n4. Any finite dimensional representation of A is completely reducible (that is, isomorphic to a\ndirect sum of irreducible representations).\n5. A is a completely reducible representation of A.\nProof. As dim A-dim Rad(A) = ⎨\ni (dim\n2) , clearly dim\nA = ⎨\n\nVi\ni (dim Vi) if and only if Rad(A) =\n0. Thus, (1) ⊆ (2).\nNext, by Theorem 2.12, if\n∪\nLRad(A) = 0, then clearly A =\ni Matdi (k) for di = dim Vi. Thus,\n(1) ≥ (3). Conversely, if A ∪=\ni Matdi (k), then by Theorem 2.6,\nL\nRad(A) = 0, so A is semisimple.\nThus (3) ≥ (1).\nNext, (3) ≥ (4) by Theorem 2.6. Clearly (4) ≥ (5). To see that (5) ≥ (3), let A =\ni niVi.\nConsider EndA(A) (endomorphisms of A as a representation of A). As the Vi's are pairwise\nL\nnon-\nisomorphic, by Schur's lemma, no copy of Vi in A can\nL be mapped to a distinct Vj . Also, again by\nSchur's lemma,L\nEndA (Vi) = k.\n\nThus, EndA(A) ∪\nL\n=\ni MatniL\n(k). But EndA(A) = Aop by Problem\n\nop ∪\n\n∪\nop\n∪\n1.22, so A\n=\ni Matni (k). Thus, A = (\ni Matni (k))\n=\ni Matni(k), as desired.\n2.6\nCharacters of representations\nLet A be an algebra and V a finite-dimensional representation of A with action δ. Then the\ncharacter of V is the linear function νV : A ⊃ k given by\nνV (a) = tr|V (δ(a)).\nIf [A, A] is the span of commutators [x, y] := xy - yx over all x, y 2 A, then [A, A] ∧ ker νV . Thus,\nwe may view the character as a mapping νV : A/[A, A] ⊃ k.\nExercise. Show that if W →V are finite dimensional representations of A, then νV = νW +\nνV/W .\nTheorem 2.17. (i) Characters of (distinct) irreducible finite-dimensional representations of A are\nlinearly independent.\n(ii) If A is a finite-dimensional semisimple algebra, then these characters form a basis of\n(A/[A, A])⊕.\n\nProof. (i) If V1, . . . , Vr are nonisomorphic irreducible finite-dimensional representations of A, then\nδV1 · · · δVr : A ⊃ End V1 · · · End Vr is surjective by the density theorem, so νV1 , . . . , νVr are\n\nlinearly independent. (Indeed, if\n∂iνVi (a) = 0 for all a 2 A, then\n∂iTr(Mi) = 0 for all Mi 2\nEndkVi. But each tr(Mi) can range\n⎨\nindependently over k, so it must\n⎨\nbe that ∂1 = · · · = ∂r = 0.)\n(ii) First we prove that [Matd(k), Matd(k)] = sld(k), the set of all matrices with trace 0. It is\nclear that [Matd(k), Matd(k)] ∧ sld(k). If we denote by Eij the matrix with 1 in the ith row of the\njth column and 0's everywhere else, we have [Eij , Ejm] = Eim for i = m, and [Ei,i+1, Ei+1,i] = Eii -\nEi+1,i+1. Now {Eim}⊗{Eii-Ei+1,i+1} forms a basis in sld(k), so indeed [Matd(k), Matd(k)] = sld(k),\nas claimed.\nBy semisimplicity, we can write A = Matd1 (k) · · · Matdr (k). Then [A, A] = sld1(k)\n\n· · ·\nsldr (k), and A/[A, A] =∪ kr. By Theorem 2.6, there are exactly r irreducible representations of A\n(isomorphic to kd1 , . . . , kdr , respectively), and therefore r linearly independent characters on the\nr-dimensional vector space A/[A, A]. Thus, the characters form a basis.\n2.7\nThe Jordan-H older theorem\nWe will now state and prove two important theorems about representations of finite dimensional\nalgebras - the Jordan-H older theorem and the Krull-Schmidt theorem.\nTheorem 2.18. (Jordan-H older theorem). Let V be a finite dimensional representation of A,\nand 0 = V0 → V1 →... → Vn = V , 0 = V0\n0 →... →Vm\n0 = V be filtrations of V , such that the\nrepresentations Wi := Vi/Vi\n1 and W i\n:= Vi\n0/Vi\n1 are irreducible for all i. Then n = m, and there\n-\n-\nexists a permutation ε of 1, ..., n such that Wε(i) is isomorphic to Wi\n0.\nProof. First proof (for k of characteristic zero). The character of V obviously equals the sum\nof characters of Wi, and also the sum of characters of Wi\n0. But by Theorem 2.17, the charac\nters of irreducible representations are linearly independent, so the multiplicity of every irreducible\nrepresentation W of A among Wi and among Wi\n0 are the same.\n\nThis implies the theorem. 3\nSecond proof (general). The proof is by induction on dim V . The base of induction is clear,\nso let us prove the induction step. If W1 = W1\n0 (as subspaces), we are done, since by the induction\nassumption the theorem holds for V/W1. So assume W1 = W1\n0. In this case W1 ∈ W1\n0 = 0 (as\nW1, W 1\n0 are irreducible), so we have an embedding f : W1 W1\n0 ⊃ V . Let U = V/(W1 W1\n0), and\n0 = U0 → U1 →... →Up = U be a filtration of U with simple quotients Zi = Ui/Ui-1 (it exists by\nLemma 2.8). Then we see that:\n1) V/W1 has a filtration with successive quotients W1\n0, Z1, ..., Zp, and another filtration with\nsuccessive quotients W2, ...., Wn.\n2) V/W 1\n0 has a filtration with successive quotients W1, Z1, ..., Zp, and another filtration with\nsuccessive quotients W2\n0, ...., W n\n0 .\nBy the induction assumption, this means that the collection of irreducible representations with\nmultiplicities W1, W 1\n0, Z1, ..., Zp coincides on one hand with W1, ..., Wn, and on the other hand, with\nW1\n0, ..., W m\n0 . We are done.\nThe Jordan-H older theorem shows that the number n of terms in a filtration of V with irre\nducible successive quotients does not depend on the choice of a filtration, and depends only on\n\nThis proof does not work in characteristic p because it only implies that the multiplicities of Wi and W ⊗\ni are the\nsame modulo p, which is not sufficient. In fact, the character of the representation pV , where V is any representation,\nis zero.\n\nV . This number is called the length of V . It is easy to see that n is also the maximal length of a\nfiltration of V in which all the inclusions are strict.\nThe sequence of the irreducible representations W1, ..., Wn enumerated in the order they appear\nfrom some filtration of V as successive quoteints is called a Jordan-H older series of V .\n2.8\nThe Krull-Schmidt theorem\nTheorem 2.19. (Krull-Schmidt theorem) Any finite dimensional representation of A can be uniquely\n(up to an isomorphism and order of summands) decomposed into a direct sum of indecomposable\nrepresentations.\nProof. It is clear that a decomposition of V into a direct sum of indecomposable representations\nexists, so we just need to prove uniqueness. We will prove it by induction on dim V . Let V =\nV1 ... Vm = V1\n0 ... V n\n0. Let is : Vs ⊃ V , is\n0 : V s\n⊃ V , ps : V ⊃ Vs, ps\n0 : V ⊃ V s\nbe the natural\nmaps associated to these decompositions. Let χs = p1i0\ns\nn\np i1 : V1 ⊃ V1. We\n\ns\nhave\ns=1 χs = 1. Now\nwe need the following lemma.\n⎨\nLemma 2.20. Let W be a finite dimensional indecomposable representation of A. Then\n(i) Any homomorphism χ : W ⊃ W is either an isomorphism or nilpotent;\n(ii) If χs : W ⊃ W , s = 1, ..., n are nilpotent homomorphisms, then so is χ := χ1 + ... + χn.\nProof. (i) Generalized eigenspaces of χ are subrepresentations of W , and W is their direct sum.\nThus, χ can have only one eigenvalue ∂. If ∂ is zero, χ is nilpotent, otherwise it is an isomorphism.\n(ii) The proof is by induction in n. The base is clear. To make the induction step (n - 1 to n),\nassume that χ is not nilpotent.\nn\nThen by (i) χ is an isomorphism, so\ni=1 χ-1χi = 1. The morphisms\nχ-1χi are not isomorphisms, so they are nilpotent. Thus 1 - χ-1χ\n⎨\n= χ-1χ + ... + χ-1\nn\nχn\n1 is an\n-\nisomorphism, which is a contradiction with the induction assumption.\nBy the lemma, we find that for some s, χs must be an isomorphism; we may assume that\ns = 1. In this case, V1\n0 = Im(p1\n0 i1) Ker(p1i1\n0 ), so since V1\n0 is indecomposable, we get that\nf := p0\n1i1 : V1 ⊃ V1\n0 and g := p1i1\n0 : V1\n0 ⊃ V1 are isomorphisms.\n\nLet B = j>1Vj , B0 = j>1Vj\n0; then we have V = V1 B = V1\n0 B0. Consider the map\nh :\n\nB ⊃ B0 defined as a composition of the natural maps B ⊃ V ⊃ B0 attached to these\ndecompositions. We claim that h is an isomorphism. To show this, it suffices to show that Kerh = 0\n(as h is a map between spaces of the same dimension). Assume that v 2 Kerh →B. Then v 2 V1\n0.\nOn the other hand, the projection of v to V1 is zero, so gv = 0. Since g is an isomorphism, we get\nv = 0, as desired.\nNow by the induction assumption, m = n, and Vj ∪= V 0\nfor some permutation ε of 2, ..., n.\nε(j)\nThe theorem is proved.\nExercise. Let A be the algebra of real-valued continuous functions on R which are periodic\nwith period 1. Let M be the A-module of continuous functions f on R which are antiperiodic with\nperiod 1, i.e., f(x + 1) = -f(x).\n(i) Show that A and M are indecomposable A-modules.\n(ii) Show that A is not isomorphic to M but A A is isomorphic to M M.\n\nRemark. Thus, we see that in general, the Krull-Schmidt theorem fails for infinite dimensional\nmodules. However, it still holds for modules of finite length, i.e., modules M such that any filtration\nof M has length bounded above by a certain constant l = l(M).\n2.9\nProblems\nProblem 2.21. Extensions of representations. Let A be an algebra, and V, W be a pair of\nrepresentations of A. We would like to classify representations U of A such that V is a subrepre\nsentation of U, and U/V = W . Of course, there is an obvious example U = V W , but are there\nany others?\nSuppose we have a representation U as above. As a vector space, it can be (non-uniquely)\nidentified with V W , so that for any a 2 A the corresponding operator δU (a) has block triangular\nform\n\nδV (a)\nf(a)\nδU (a) =\n\n,\nδW (a)\nwhere f : A ⊃ Homk(W, V ) is a linear map.\n(a) What is the necessary and sufficient condition on f(a) under which δU (a) is a repre\nsentation? Maps f satisfying this condition are called (1-)cocycles (of A with coefficients in\nHomk(W, V )). They form a vector space denoted Z 1(W, V ).\n(b) Let X : W ⊃ V be a linear map. The coboundary of X, dX, is defined to be the function A ⊃\nHomk(W, V ) given by dX(a) = δV (a)X -XδW (a). Show that dX is a cocycle, which vanishes if and\nonly if X is a homomorphism of representations. Thus coboundaries form a subspace B 1(W, V ) →\nZ1(W, V ), which is isomorphic to Homk(W, V )/HomA(W, V ). The quotient Z1(W, V )/B1(W, V ) is\ndenoted Ext1(W, V ).\n(c)\n\nShow that if f, f 0 2 Z1(W, V\n\n) and f - f 0 2 B1(W, V ) then the corresponding extensions\nU, U 0 are isomorphic representations\n\nof A. Conversely, if θ : U ⊃ U 0 is an isomorphism such that\nθ(a) =\n\n1V\n∼\n1W\n\nthen f - f 0 2 B1(V, W ). Thus, the space Ext1(W, V ) \"classifies\" extensions of W by V .\n(d) Assume that W, V are finite dimensional irreducible representations of A. For any f 2\nExt1(W, V ), let Uf be the corresponding extension. Show that Uf is isomorphic to Uf⊗ as repre\nsentations if and only if f and\n\nf 0 are proportional. Thus isomorphism classes (as representations)\nof nontrivial extensions of W by V (i.e., those not isomorphic to W V ) are parametrized by the\nprojective space PExt1(W, V ). In particular, every extension is trivial if and only if Ext1(W, V ) = 0.\nProblem 2.22. (a) Let A = C[x1, ..., xn], and Va, Vb be one-dimensional representations in which\nxi act by ai and bi, respectively (ai, bi 2 C). Find Ext1(Va, Vb) and classify 2-dimensional repre\nsentations of A.\n(b) Let B be the algebra over C generated by x1, ..., xn with the defining relations xixj = 0 for\nall i, j. Show that for n > 1 the algebra B has infinitely many non-isomorphic indecomposable\nrepresentations.\nProblem 2.23. Let Q be a quiver without oriented cycles, and PQ the path algebra of Q. Find\nirreducible representations of PQ and\n\ncompute Ext1 between them. Classify 2-dimensional repre\nsentations of PQ.\n\nProblem 2.24. Let A be an algebra, and V a representation of A. Let δ : A ⊃ EndV . A formal\ndeformation of V is a formal series\nδ = δ\nn\n0 + tδ1 + ... + t δn + ...,\nwhere δi : A ⊃ End(V ) are linear maps, δ0 = δ, and δ (ab) = δ (a)δ (b).\nIf b(t) = 1 + b1t + b\n2t + ..., where bi 2 End(V ), and δ is a formal deformation of δ, then bδb\n-1\nis also a deformation of δ, which is said to be isomorphic to δ .\n(a) Show that if Ext1(V, V ) = 0, then any deformation of δ is trivial, i.e., isomorphic to δ.\n(b) Is the converse to (a) true? (consider the algebra of dual numbers A = k[x]/x2).\nProblem 2.25. The Clifford algebra. Let V be a finite dimensional complex vector space\nequipped with a symmetric bilinear form (, ). The Clifford algebra Cl(V ) is the quotient of the\ntensor algebra TV by the ideal generated by the elements v\nv - (v, v)1, v 2 V . More explicitly, if\nxi, 1 ∗ i ∗ N is a basis of V and (xi, xj ) = aij then Cl(V ) is generated by xi with defining relations\nxixj +\n\nxjxi = 2aij , x 2\ni = aii.\nThus, if (, ) = 0, Cl(V ) = √V .\n(i) Show that if (, ) is nondegenerate then Cl(V ) is semisimple, and has one irreducible repre\nsentation of dimension 2n if dim V = 2n (so in this case Cl(V ) is a matrix algebra), and two such\nrepresentations if dim(V ) = 2n +1 (i.e., in this case Cl(V ) is a direct sum of two matrix algebras).\nHint. In the even case, pick a basis a1, ..., an, b1, ..., bn of V in which (ai, aj ) = (bi, bj ) = 0,\n(ai, bj ) = ζij /2, and construct a representation of Cl(V ) on S := √(a1, ..., an) in which bi acts as\n\"differentiation\" with respect to ai. Show that S is irreducible. In the odd case the situation is\nsimilar, except there should be an additional basis vector c such that (c, ai) = (c, bi) = 0, (c, c) =\n1, and the action\n\nof c on S may be defined either by (-1)degree or by (-1)degree+1, giving two\nrepresentations S+, S\n(why are they non-isomorphic?). Show that there is no other irreducible\n-\n\nrepresentations by finding a spanning set of Cl(V ) with 2dim V elements.\n(ii) Show that Cl(V ) is semisimple if and only if (, ) is nondegenerate. If (, ) is degenerate, what\nis Cl(V )/Rad(Cl(V ))?\n2.10\nRepresentations of tensor products\nLet A, B be algebras. Then A\nB is also an algebra, with multiplication (a1\nb1)(a2\nb2) =\na1a2\nb1b2.\nExercise. Show that Matm(k)\nMatn(k) =∪ Matmn(k).\nThe following theorem describes irreducible finite dimensional representations of A\nB in terms\nof irreducible finite dimensional representations of A and those of B.\nTheorem 2.26. (i) Let V be an irreducible finite dimensional representation of A and W an\nirreducible finite dimensional representation of B. Then V\nW is an irreducible representation of\nA\nB.\n(ii) Any irreducible finite dimensional representation M of A\nB has the form (i) for unique\nV and W .\nRemark 2.27. Part (ii) of the theorem typically fails for infinite dimensional representations;\ne.g. it fails when A is the Weyl algebra in characteristic zero. Part (i) also may fail. E.g. let\nA = B = V = W = C(x). Then (i) fails, as A\nB is not a field.\n\nProof. (i) By the density theorem, the maps A ⊃ End V and B ⊃ End W are surjective. Therefore,\nthe map A\nB ⊃ End V\nEnd W = End(V\nW ) is surjective. Thus, V\nW is irreducible.\n(ii)\n\nFirst we show the existence of V and W . Let A0, B0 be the images of A, B in End M. Then\nA0\n\n, B0 are finite dimensional algebras, and M is a representation of A0\nB0, so we may assume\nwithout loss of generality that A and B are finite dimensional.\nIn this case, we claim that Rad(A\nB) = Rad(A)\nB + A\nRad(B). Indeed, denote the latter\nby J. Then J is a nilpotent ideal in A\nB, as Rad(A) and Rad(B) are nilpotent. On the other\nhand, (A\nB)/J = (A/Rad(A))\n(B/Rad(B)), which is a product of two semisimple algebras,\nhence semisimple. This implies J ∩ Rad(A\nB). Altogether, by Proposition 2.11, we see that\nJ = Rad(A\nB), proving the claim.\nThus, we see that\n(A\nB)/Rad(A\nB) = A/Rad(A)\nB/Rad(B).\nNow, M is an irreducible representation of (A\nB)/Rad(A\nB), so it is clearly of the form\nM = V\nW , where V is an irreducible representation of A/Rad(A) and W is an irreducible\nrepresentation of B/Rad(B), and V, W are uniquely determined by M (as all of the algebras\ninvolved are direct sums of matrix algebras).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n18.712 Introduction to Representation Theory\nFall 2010"
    },
    {
      "category": "Resource",
      "title": "Introduction",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/64ac0a7f209d31929d393a80e3ab85bb_MIT18_712F10_intro.pdf",
      "content": "INTRODUCTION\nVery roughly speaking, representation theory studies symmetry in linear spaces. It is a beautiful\nmathematical subject which has many applications, ranging from number theory and combinatorics\nto geometry, probability theory, quantum mechanics and quantum field theory.\nRepresentation theory was born in 1896 in the work of the German mathematician F. G.\nFrobenius. This work was triggered by a letter to Frobenius by R. Dedekind. In this letter Dedekind\nmade the following observation: take the multiplication table of a finite group G and turn it into a\nmatrix XG by replacing every entry g of this table by a variable xg. Then the determinant of XG\nfactors into a product of irreducible polynomials in {xg}, each of which occurs with multiplicity\nequal to its degree. Dedekind checked this surprising fact in a few special cases, but could not prove\nit in general. So he gave this problem to Frobenius. In order to find a solution of this problem\n(which\n\nwe will explain below), Frobenius created representation theory of finite groups. 1\nThe present lecture notes arose from a representation theory course given by the first author to\nthe remaining six authors in March 2004 within the framework of the Clay Mathematics Institute\nResearch Academy for high school students, and its extended version given by the first author to\nMIT undergraduate math students in the Fall of 2008. The lectures are supplemented by many\nproblems and exercises, which contain a lot of additional material; the more difficult exercises are\nprovided with hints.\nThe notes cover a number of standard topics in representation theory of groups, Lie algebras, and\nquivers. We mostly follow [FH], with the exception of the sections discussing quivers, which follow\n[BGP]. We also recommend the comprehensive textbook [CR]. The notes should be accessible to\nstudents with a strong background in linear algebra and a basic knowledge of abstract algebra.\nAcknowledgements. The authors are grateful to the Clay Mathematics Institute for hosting\nthe first version of this course. The first author is very indebted to Victor Ostrik for helping him\nprepare this course, and thanks Josh Nichols-Barrer and Thomas Lam for helping run the course\nin 2004 and for useful comments. He is also very grateful to Darij Grinberg for very careful reading\nof the text, for many useful comments and corrections, and for suggesting the Exercises in Sections\n1.10, 2.3, 3.5, 4.9, 4.26, and 6.8.\n1For more on the history of representation theory, see [Cu].\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n18.712 Introduction to Representation Theory\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Introduction to categories",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/fb4599a4582288fb3372f7ecb0509978_MIT18_712F10_ch6.pdf",
      "content": "Introduction to categories\n6.1\nThe definition of a category\nWe have now seen many examples of representation theories and of operations with representations\n(direct sum, tensor product, induction, restriction, reflection functors, etc.) A context in which one\ncan systematically talk about this is provided by Category Theory.\nCategory theory was founded by Saunders MacLane and Samuel Eilenberg around 1940. It is a\nfairly abstract theory which seemingly has no content, for which reason it was christened \"abstract\nnonsense\". Nevertheless, it is a very flexible and powerful language, which has become totally\nindispensable in many areas of mathematics, such as algebraic geometry, topology, representation\ntheory, and many others.\nWe will now give a very short introduction to Category theory, highlighting its relevance to the\ntopics in representation theory we have discussed. For a serious acquaintance with category theory,\nthe reader should use the classical book [McL].\nDefinition 6.1. A category C is the following data:\n(i) a class of objects Ob(C);\n(ii) for every objects X, Y 2 Ob(C), the class Hom (X, Y ) = Hom(X, Y ) of morphisms (or\nC\narrows) from X, Y (for f 2 Hom(X, Y ), one may write f : X ⊃ Y );\n(iii) For any objects X, Y, Z 2 Ob(C), a composition map Hom(Y, Z)×Hom(X, Y ) ⊃ Hom(X, Z),\n(f, g) 7⊃ f inf g,\nwhich satisfy the following axioms:\n1. The composition is associative, i.e., (f inf g) inf h = f inf (g inf h);\n2. For each X 2 Ob(C), there is a morphism 1X 2 Hom(X, X), called the unit morphism, such\nthat 1X inf f = f and g inf 1X = g for any f, g for which compositions make sense.\nRemark. We will write X 2 C instead of X 2 Ob(C).\nExample 6.2. 1. The category Sets of sets (morphisms are arbitrary maps).\n2. The categories Groups, Rings (morphisms are homomorphisms).\n3. The category Vectk of vector spaces over a field k (morphisms are linear maps).\n4. The category Rep(A) of representations of an algebra A (morphisms are homomorphisms of\nrepresentations).\n5. The category of topological spaces (morphisms are continuous maps).\n6. The homotopy category of topological spaces (morphisms are homotopy classes of continuous\nmaps).\nImportant remark. Unfortunately, one cannot simplify this definition by replacing the word\n\"class\" by the much more familiar word \"set\". Indeed, this would rule out the important Example 1,\nas it is well known that there is no set of all sets, and working with such a set leads to contradictions.\nThe precise definition of a class and the precise distinction between a class and a set is the subject\nof set theory, and cannot be discussed here. Luckily, for most practical purposes (in particular, in\nthese notes), this distinction is not essential.\n\nWe also mention that in many examples, including examples 1-6, the word \"class\" in (ii) can\nbe replaced by \"set\". Categories with this property (that Hom(X, Y ) is a set for any X, Y ) are\ncalled locally small; many categories that we encounter are of this kind.\nSometimes the collection Hom(X, Y ) of morphisms from X to Y in a given locally small category\nC is not just a set but has some additional structure (say, the structure of an abelian group, or a\nvector space over some field). In this case one says that C is enriched over another category D\n(which is a monoidal category, i.e., has a product operation and a unit object under this product, e.g.\nthe category of abelian groups or vector spaces with the tensor product operation). This means that\nfor each X, Y 2 C, Hom(X, Y ) is an object of D, and the composition Hom(Y, Z) × Hom(X, Y ) ⊃\nHom(X, Z) is a morphism in D. E.g., if D is the category of vector spaces, this means that the\ncomposition is bilinear, i.e. gives rise to a linear map Hom(Y, Z)\nHom(X, Y ) ⊃ Hom(X, Z). For\na more detailed discussion of this, we refer the reader to [McL].\nExample. The category Rep(A) of representations of a k-algebra A is enriched over the\ncategory of k-vector spaces.\nDefinition 6.3. A full subcategory of a category C is a category C0 whose objects are a subclass\nof objects of C, and Hom\n⊗ (X, Y ) = Hom\nC\nC (X, Y ).\nExample. The category AbelianGroups is a full subcategory of the category Groups.\n6.2\nFunctors\nWe would like to define arrows between categories. Such arrows are called functors.\nDefinition 6.4. A functor F : C ⊃D between categories C and D is\n(i) a map F : Ob(C) ⊃ Ob(D);\n(ii) for each X, Y 2 C, a map F = FX,Y : Hom(X, Y ) ⊃ Hom(F (X), F (Y )) which preserves\ncompositions and identity morphisms.\nNote that functors can be composed in an obvious way. Also, any category has the identity\nfunctor.\nExample 6.5. 1. A (locally small) category C with one object X is the same thing as a monoid.\nA functor between such categories is a homomorphism of monoids.\n2. Forgetful functors Groups ⊃ Sets, Rings ⊃ AbelianGroups.\n3. The opposite category of a given category is the same category with the order of arrows and\ncompositions reversed.\n\nThen V 7⊃ V ⊕is a functor Vectk 7⊃\nop\nVect\n.\nk\n4. The Hom functors: If C is a locally small category then we have the functor C ⊃ Sets given\nby Y 7⊃\n\nHom(X, Y ) and Cop ⊃ Sets given by Y 7⊃ Hom(Y, X).\n5. The assignment X 7⊃ Fun(X, Z) is a functor Sets ⊃ Ringsop.\n6. Let Q be a quiver. Consider the category C(Q) whose objects are the vertices and morphisms\nare oriented paths between them. Then functors from C(Q) to Vectk are representations of Q over\nk.\n7. Let K → G be groups. Then we have the induction functor\nG\nIndK : Rep(K) ⊃ Rep(G), and\n\nResG\nK : Rep(G) ⊃ Rep(K).\n\n8. We have an obvious notion of the Cartesian product of categories (obtained by taking the\nCartesian products of the classes of objects and morphisms of the factors). The functors of direct\nthen\n\nsum and tensor product are\nfunctors Vectk ×Vectk ⊃ Vectk. Also the operations V 7⊃ V\nn,\nV 7⊃ SnV , V 7⊃ √nV are functors on Vectk. More generally, if β is a representation of Sn, we\nhave functors V 7⊃ Hom\nn\nSn (β, V\n). Such functors (for irreducible β) are called the Schur functors.\nThey are labeled by Young diagrams.\n9. The reflection functors Fi\n± : Rep(Q) ⊃\n\nRep( Qi) are functors between representation cate\ngories of quivers.\n6.3\nMorphisms of functors\nOne of the important features of functors between categories which distinguishes them from usual\nmaps or functions is that the functors between two given categories themselves form a category,\ni.e., one can define a nontrivial notion of a morphism between two functors.\nDefinition 6.6. Let C, D be categories and F, G : C ⊃D be functors between them. A morphism\na : F ⊃ G (also called a natural transformation or a functorial morphism) is a collection of\nmorphisms aX : F (X) ⊃ G(X) labeled by the objects X of C, which is functorial in X, i.e., for\nany morphism f : X ⊃ Y (for X, Y 2 C) one has aY inf F (f) = G(f) inf aX .\n\n⊃\n\n-1\nA morphism a : F\nG is an isomorphism if there is another morphism a\n: G ⊃ F such that\na inf a-1 and a-1 inf a are the identities. The set of morphisms from F to G is denoted by Hom(F, G).\nExample 6.7. 1. Let FVectk be the category of finite dimensional vector spaces over k. Then the\nfunctors id and ∼∼ on this category are isomorphic. The isomorphism is defined by the standard\nmaps aV : V ⊃\n\nV ⊕⊕given by aV (u)(f) = f(u), u 2 V , f 2 V ⊕. But these two functors are not\nisomorphic on the category of all vector spaces Vectk, since for an infinite dimensional vector space\nV , V is not isomorphic to V ⊕⊕.\n2. Let FVect0\nk be the category of finite dimensional k-vector spaces, where the morphisms\nare the isomorphisms. We have a functor F from this category to itself sending any space V to\n\nV ⊕and any morphism a to (a⊕)-1. This functor satisfies the property that V is isomorphic to\nF (V ) for any V , but it is not isomorphic to the identity functor. This is because the isomorphism\n\nV ⊃ F (V ) = V ⊕cannot be chosen to be compatible with the action of GL(V ), as V is not\nisomorphic to V ⊕ as a representation of GL(V ).\n3. Let A be an algebra over a field k, and F : A - mod ⊃ Vectk be the forgetful functor.\nThen as follows from Problem 1.22, EndF = Hom(F, F ) = A.\n4. The set of endomorphisms of the identity functor on the category A - mod is the center of\nA (check it!).\n6.4\nEquivalence of categories\nWhen two algebraic or geometric objects are isomorphic, it is usually not a good idea to say that\nthey are equal (i.e., literally the same). The reason is that such objects are usually equal in many\ndifferent ways, i.e., there are many ways to pick an isomorphism, but by saying that the objects are\nequal we are misleading the reader or listener into thinking that we are providing a certain choice\nof the identification, which we actually do not do. A vivid example of this is a finite dimensional\nvector space V and its dual space V ⊕.\n\nFor this reason in category theory, one most of the time tries to avoid saying that two objects\nor two functors are equal. In particular, this applies to the definition of isomorphism of categories.\nNamely, the naive notion of isomorphism of categories is defined in the obvious way: a functor\nF : C ⊃D is an isomorphism if there exists F -1 : D ⊃C such that F inf F -1 and F -1 inf F are equal\nto the identity functors. But this definition is not very useful. We might suspect so since we have\nused the word \"equal\" for objects of a category (namely, functors) which we are not supposed to\ndo. And in fact here is an example of two categories which are \"the same for all practical purposes\"\nbut are not isomorphic; it demonstrates the deficiency of our definition.\nNamely, let C1 be the simplest possible category: Ob(C1) consists of one object X, with\nHom(X, X) = {1X }. Also, let C2 have two objects X, Y and 4 morphisms: 1X , 1Y , a : X ⊃ Y\nand b : Y ⊃ X. So we must have a inf b = 1Y , b inf a = 1X .\nIt is easy to check that for any category D, there is a natural bijection between the collections\nof isomorphism classes of functors C1 ⊃D and C2 ⊃D (both are identified with the collection of\nisomorphism classes of objects of D). This is what we mean by saying that C1 and C2 are \"the same\nfor all practical purposes\". Nevertheless they are not isomorphic, since C1 has one object, and C2\nhas two objects (even though these two objects are isomorphic to each other).\nThis shows that we should adopt a more flexible and less restrictive notion of isomorphism of\ncategories. This is accomplished by the definition of an equivalence of categories.\n\nDefinition 6.8. A functor F : C ⊃D is an equivalence of categories if there exists F 0 : D ⊃C\nsuch that\n\nF inf F 0 and F 0 inf F are isomorphic to the identity functors.\nIn this situation, F 0 is said to be a quasi-inverse to F .\nIn particular, the above categories C1 and C2 are equivalent (check it!).\nAlso, the category FSet of finite sets is equivalent to the category whose objects are nonneg\native integers, and morphisms are given by Hom(m, n) = Maps({1, ..., m}, {1, ..., n}). Are these\ncategories isomorphic? The answer to this question depends on whether you believe that there\nis only one finite set with a given number of elements, or that there are many of those. It seems\nbetter to think that there are many (without asking \"how many\"), so that isomorphic sets need not\nbe literally equal, but this is really a matter of choice. In any case, this is not really a reasonable\nquestion; the answer to this question is irrelevant for any practical purpose, and thinking about it\nwill give you nothing but a headache.\n6.5\nRepresentable functors\nA fundamental notion in category theory is that of a representable functor. Namely, let C be a\n(locally small) category, and F : C ⊃ Sets be a functor. We say that F is representable if there\nexists an object X 2 C such that F is isomorphic to the functor Hom(X, ?). More precisely, if we\nare given such an object X, together with an isomorphism : F =∪ Hom(X, ?), we say that the\nfunctor F is represented by X (using ).\nIn\n\na similar way, one can talk about representable functors from C op to Sets. Namely, one\ncalls such a functor representable if it is of the form Hom(?, X) for some object X 2 C, up to an\nisomorphism.\nNot every functor is representable, but if a representing object X exists, then it is unique.\nNamely, we have the following lemma.\n\nLemma 6.9. (The Yoneda Lemma) If a functor F is represented by an object X, then X is unique\nup to a unique isomorphism. I.e., if X, Y are two objects in C, then for any isomorphism of functors\nθ : Hom(X, ?) ⊃ Hom(Y, ?) there is a unique isomorphism aπ : X ⊃ Y inducing θ.\nProof. (Sketch) One sets a\n= θ-1\nπ\nY (1Y ), and shows that it is invertible by constructing the inverse,\nwhich\n\nis a-1\n= θX (1X ). It remains to show that the composition both ways is the identity, which\nπ\nwe will omit here. This establishes the existence of aπ. Its uniqueness is verified in a straightforward\nmanner.\nRemark. In a similar way, if a category C is enriched over another category D (say, the category\nof abelian groups or vector spaces), one can define the notion of a representable functor from C to\nD.\nExample 6.10. Let A be an algebra. Then the forgetful functor to vector spaces on the category\nof left A-modules is representable, and the representing object is the free rank 1 module (=the\nregular representation) M = A. But if A is infinite dimensional, and we restrict attention to the\ncategory of finite dimensional modules, then the forgetful functor, in general, is not representable\n(this is so, for example, if A is the algebra of complex functions on Z which are zero at all points\nbut finitely many).\n6.6\nAdjoint functors\nAnother fundamental notion in category theory is the notion of adjoint functors.\nDefinition 6.11. Functors F : C ⊃D and G : D ⊃C are said to be a pair of adjoint functors if for\nany X 2 C, Y 2 D we are given an isomorphism XY : HomC (F (X), Y ) ⊃ Hom (X, G(Y )) which is\nD\nfunctorial in X and Y ; in other words, if we are given an isomorphism of functors Hom(F (?), ?) ⊃\nHom(?, G(?)) (C × D ⊃ Sets). In this situation, we say that F is left adjoint to G and G is right\nadjoint to F .\nNot every functor has a left or right adjoint, but if it does, it is unique and can be constructed\ncanonically (i.e., if we somehow found two such functors, then there is a canonical isomorphism\nbetween them). This follows easily from the Yoneda lemma, as if F, G are a pair of adjoint functors\nthen F (X) represents the functor Y 7⊃ Hom(X, G(Y )), and G(Y ) represents the functor X 7⊃\nHom(F (X), Y ).\nRemark 6.12. The terminology \"left and right adjoint functors\" is motivated by the analogy\nbetween categories and inner product spaces. More specifically, we have the following useful dic\ntionary between category theory and linear algebra, which helps understand better many notions\nof category theory.\n\nDictionary between category theory and linear algebra\nCategory C\nVector space V with a nondegenerate inner product\nThe set of morphisms Hom(X, Y )\nInner product (x, y) on V (maybe nonsymmetric)\nOpposite category Cop\nSame space V with reversed inner product\nThe category Sets\nThe ground field k\nFull subcategory in C\nNondegenerate subspace in V\nFunctor F : C ⊃D\nLinear operator f : V ⊃ W\nFunctor F : C ⊃ Sets\nLinear functional f 2 V ⊕ = Hom(V, k)\n\nRepresentable functor\nLinear functional f 2 V ⊕given by f(v) = (u, v), u 2 V\nYoneda lemma\nNondegeneracy of the inner product (on both sides)\nNot all functors are representable\nIf dim V = ≤, not ⊕f 2 V ⊕, f(v) = (u, v)\nLeft and right adjoint functors\nLeft and right adjoint operators\nAdjoint functors don't always exist\nAdjoint operators may not exist if dim V = ≤\nIf they do, they are unique\nIf they do, they are unique\nLeft and right adjoints may not coincide\nThe inner product may be nonsymmetric\nExample 6.13. 1. Let V be a finite dimensional representation of a group G or a Lie algebra g.\nThen the left and right adjoint to the functor V\non the category of representations of G is the\nfunctor V ⊕\n.\n\n2. The functor ResG is left adjoint to IndG\nK\nK . This is nothing but the statement of the Frobenius\nreciprocity.\n3. Let Assock be the category of associative unital algebras, and Liek the category of Lie\nalgebras over some field k. We have a functor L : Assock ⊃ Liek, which attaches to an associative\nalgebra the same space regarded as a Lie algebra, with bracket [a, b] = ab - ba. Then the functor L\nhas a left adjoint, which is the functor U of taking the universal enveloping algebra of a Lie algebra.\n4. We have the functor GL1 : Assock ⊃ Groups, given by A 7⊃ GL1(A) = A×. This functor\nhas a left adjoint, which is the functor G 7⊃ k[G], the group algebra of G.\n5. The left adjoint to the forgetful functor Assock ⊃ Vectk is the functor of tensor algebra:\nV 7⊃ TV . Also, if we denote by Commk the category of commutative algebras, then the left adjoint\nto the forgetful functor Commk ⊃ Vectk is the functor of the symmetric algebra: V 7⊃ SV .\nOne can give many more examples, spanning many fields. These examples show that adjoint\nfunctors are ubiquitous in mathematics.\n6.7\nAbelian categories\nThe type of categories that most often appears in representation theory is abelian categories.\nThe standard definition of an abelian category is rather long, so we will not give it here, referring\nthe reader to the textbook [Fr]; rather, we will use as the definition what is really the statement of\nthe Freyd-Mitchell theorem:\nDefinition 6.14. An abelian category is a category (enriched over the category of abelian groups),\nwhich is equivalent to a full subcategory C of the category A-mod of left modules over a ring A,\nclosed under taking finite direct sums, as well as kernels, cokernels, and images of morphisms.\nWe see from this definition that in an abelian category, Hom(X, Y ) is an abelian group for each\nX, Y , compositions are group homomorphisms with respect to each argument, there is the zero ob\nject, the notion of an injective morphism (monomorphism) and surjective morphism (epimorphism),\nand every morphism has a kernel, a cokernel, and an image.\n\nExample 6.15. The category of modules over an algebra A and the category of finite dimensional\nmodules over A are abelian categories.\nRemark 6.16. The good thing about Definition 6.14 is that it allows us to visualize objects,\nmorphisms, kernels, and cokernels in terms of classical algebra. But the definition also has a big\ndrawback, which is that even if C is the whole category A-mod, the ring A is not determined by C.\nIn particular, two different rings can have equivalent categories of modules (such rings are called\nMorita equivalent). Actually, it is worse than that: for many important abelian categories there\nis no natural (or even manageable) ring A at all. This is why people prefer to use the standard\ndefinition, which is free from this drawback, even though it is more abstract.\nWe say that an abelian category C is k-linear if the groups HomC (X, Y ) are equipped with\na structure of a vector space over k, and composition maps are k-linear in each argument. In\nparticular, the categories in Example 6.15 are k-linear.\n6.8\nExact functors\nDefinition 6.17. A sequence of objects and morphisms\nX0 ⊃ X1 ⊃ ... ⊃ Xn+1\nin an abelian category is said to be a complex if the composition of any two consecutive arrows\nis zero. The\n\ncohomology of this complex is H i = Ker (di)/Im(di\n1), where di : X\n-\ni ⊃ Xi+1 (thus\nthe cohomology is defined for 1 ∗ i ∗ n). The complex is said to be exact in the i-th term if\nHi = 0, and is said to be an exact sequence if it is exact in all terms. A short exact sequence\nis an exact sequence of the form\n0 ⊃ X ⊃ Y ⊃ Z ⊃ 0.\nClearly, 0 ⊃ X ⊃ Y ⊃ Z ⊃ 0 is a short exact sequence if and only if X ⊃ Y is injective,\nY ⊃ Z is surjective, and the induced map Y/X ⊃ Z is an isomorphism.\nDefinition 6.18. A functor F between two abelian categories is additive if it induces homomor\nphisms on Hom groups. Also, for k-linear categories one says that F is k-linear if it induces k-linear\nmaps between Hom spaces.\nIt is easy to show that if F is an additive functor, then F (X Y ) is canonically isomorphic to\nF (X) F (Y ).\n\nExample 6.19. The functors IndG\nK , ResG\nK , HomG(V, ?) in the theory of group representations over\na field k are additive and k-linear.\nDefinition 6.20. An additive functor F : C ⊃D between abelian categories is left exact if for\nany exact sequence\n0 ⊃ X ⊃ Y ⊃ Z,\nthe sequence\n0 ⊃ F (X) ⊃ F (Y ) ⊃ F (Z)\nis exact. F is right exact if for any exact sequence\nX ⊃ Y ⊃ Z ⊃ 0,\nthe sequence\nF (X) ⊃ F (Y ) ⊃ F (Z) ⊃ 0\nis exact. F is exact if it is both left and right exact.\n\nDefinition 6.21. An abelian category C is semisimple if any short exact sequence in this category\nsplits, i.e., is isomorphic to a sequence\n0 ⊃ X ⊃ X Y ⊃ Y ⊃ 0\n(where the maps are obvious).\nExample 6.22. The category of representations of a finite group G over a field of characteristic\nnot dividing |G| (or 0) is semisimple.\nNote that in a semisimple category, any additive functor is automatically exact on both sides.\nExample 6.23. (i) The functors IndG\nK , ResG\nK are exact.\n(ii) The functor Hom(X, ?) is left exact, but not necessarily right exact. To see that it need not\nbe right exact, it suffices to consider the exact sequence\n0 ⊃ Z ⊃ Z ⊃ Z/2Z ⊃ 0,\nand apply the functor Hom(Z/2Z, ?).\n(iii) The functor X\nA for a right A-module X (on the category of left A-modules) is right exact,\nbut not necessarily left exact. To see this, it suffices to tensor multiply the above exact sequence\nby Z/2Z.\nExercise. Show that if (F, G) is a pair of adjoint additive functors between abelian categories,\nthen F is right exact and G is left exact.\nExercise. (a) Let Q be a quiver and i 2 Q a source. Let V be a representation of Q, and W a\nrepresentation of Qi (the quiver obtained from⎩ Q by reversing arrows at the vertex i). Prove that\n\nthere is a natural isomorphism between Hom Fi\n-V, W and Hom V, F +\ni W . In other words, the\nfunctor F +\ni is right adjoint to Fi\n-.\n⎩\n\n(b) Deduce that the functor F +\ni is\n\nleft exact, and Fi\n-is right exact.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n18.712 Introduction to Representation Theory\nFall 2010"
    },
    {
      "category": "Resource",
      "title": "Introduction to representation theory",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/24d8b3fa2ce48e48ee6c2d8d5e3562f6_MIT18_712F10_replect.pdf",
      "content": "Introduction to representation theory\nPavel Etingof, Oleg Golberg, Sebastian Hensel,\nTiankai Liu, Alex Schwendner, Dmitry Vaintrob, and Elena Yudovina\nFebruary 1, 2011\nContents\n1 Basic notions of representation theory\n1.1 What is representation theory? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2 Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3 Representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4 Ideals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.5 Quotients . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.6 Algebras defined by generators and relations . . . . . . . . . . . . . . . . . . . . . . . 11\n1.7 Examples of algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.8 Quivers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.9 Lie algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n1.10 Tensor products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n1.11 The tensor algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n1.12 Hilbert's third problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n1.13 Tensor products and duals of representations of Lie algebras . . . . . . . . . . . . . . 20\n1.14 Representations of sl(2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n1.15 Problems on Lie algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2 General results of representation theory\n2.1 Subrepresentations in semisimple representations . . . . . . . . . . . . . . . . . . . . 23\n2.2 The density theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.3 Representations of direct sums of matrix algebras . . . . . . . . . . . . . . . . . . . . 24\n2.4 Filtrations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.5 Finite dimensional algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n\n2.6 Characters of representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.7 The Jordan-H older theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.8 The Krull-Schmidt theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.9 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n2.10 Representations of tensor products . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3 Representations of finite groups: basic results\n3.1 Maschke's Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.2 Characters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.4 Duals and tensor products of representations . . . . . . . . . . . . . . . . . . . . . . 36\n3.5 Orthogonality of characters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n3.6 Unitary representations. Another proof of Maschke's theorem for complex represen\ntations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n3.7 Orthogonality of matrix elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.8 Character tables, examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n3.9 Computing tensor product multiplicities using character tables . . . . . . . . . . . . 42\n3.10 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4 Representations of finite groups: further results\n4.1 Frobenius-Schur indicator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n4.2 Frobenius determinant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n4.3 Algebraic numbers and algebraic integers . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.4 Frobenius divisibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n4.5 Burnside's Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.6 Representations of products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.7 Virtual representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.8 Induced Representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.9 The Mackey formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n4.10 Frobenius reciprocity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.11 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n4.12 Representations of Sn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n4.13 Proof of Theorem 4.36 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n4.14 Induced representations for Sn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n\n4.15 The Frobenius character formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n4.16 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n4.17 The hook length formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n4.18 Schur-Weyl duality for gl(V ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n4.19 Schur-Weyl duality for GL(V ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n4.20 Schur polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n4.21 The characters of L . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n4.22 Polynomial representations of GL(V ) . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n4.23 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n4.24 Representations of GL2(Fq) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n4.24.1 Conjugacy classes in GL2(Fq) . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n4.24.2 1-dimensional representations . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n4.24.3 Principal series representations . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n4.24.4 Complementary series representations . . . . . . . . . . . . . . . . . . . . . . 73\n4.25 Artin's theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n4.26 Representations of semidirect products . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n5 Quiver Representations\n5.1 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n5.2 Indecomposable representations of the quivers A1, A2, A3 . . . . . . . . . . . . . . . . 81\n5.3 Indecomposable representations of the quiver D4 . . . . . . . . . . . . . . . . . . . . 83\n5.4 Roots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n5.5 Gabriel's theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n5.6 Reflection Functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n5.7 Coxeter elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n5.8 Proof of Gabriel's theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n5.9 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n6 Introduction to categories\n6.1 The definition of a category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n6.2 Functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n6.3 Morphisms of functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n6.4 Equivalence of categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n6.5 Representable functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n\n6.6 Adjoint functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n6.7 Abelian categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n6.8 Exact functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n7 Structure of finite dimensional algebras\n7.1 Projective modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n7.2 Lifting of idempotents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n7.3 Projective covers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\nINTRODUCTION\nVery roughly speaking, representation theory studies symmetry in linear spaces. It is a beautiful\nmathematical subject which has many applications, ranging from number theory and combinatorics\nto geometry, probability theory, quantum mechanics and quantum field theory.\nRepresentation theory was born in 1896 in the work of the German mathematician F. G.\nFrobenius. This work was triggered by a letter to Frobenius by R. Dedekind. In this letter Dedekind\nmade the following observation: take the multiplication table of a finite group G and turn it into a\nmatrix XG by replacing every entry g of this table by a variable xg. Then the determinant of XG\nfactors into a product of irreducible polynomials in {xg}, each of which occurs with multiplicity\nequal to its degree. Dedekind checked this surprising fact in a few special cases, but could not prove\nit in general. So he gave this problem to Frobenius. In order to find a solution of this problem\n(which we will explain below), Frobenius created representation theory of finite groups. 1\nThe present lecture notes arose from a representation theory course given by the first author to\nthe remaining six authors in March 2004 within the framework of the Clay Mathematics Institute\nResearch Academy for high school students, and its extended version given by the first author to\nMIT undergraduate math students in the Fall of 2008. The lectures are supplemented by many\nproblems and exercises, which contain a lot of additional material; the more difficult exercises are\nprovided with hints.\nThe notes cover a number of standard topics in representation theory of groups, Lie algebras, and\nquivers. We mostly follow [FH], with the exception of the sections discussing quivers, which follow\n[BGP]. We also recommend the comprehensive textbook [CR]. The notes should be accessible to\nstudents with a strong background in linear algebra and a basic knowledge of abstract algebra.\nAcknowledgements. The authors are grateful to the Clay Mathematics Institute for hosting\nthe first version of this course. The first author is very indebted to Victor Ostrik for helping him\nprepare this course, and thanks Josh Nichols-Barrer and Thomas Lam for helping run the course\nin 2004 and for useful comments. He is also very grateful to Darij Grinberg for very careful reading\nof the text, for many useful comments and corrections, and for suggesting the Exercises in Sections\n1.10, 2.3, 3.5, 4.9, 4.26, and 6.8.\nFor more on the history of representation theory, see [Cu].\n\n@\n@\n@\n@\nBasic notions of representation theory\n1.1\nWhat is representation theory?\nIn technical terms, representation theory studies representations of associative algebras. Its general\ncontent can be very briefly summarized as follows.\nAn associative algebra over a field k is a vector space A over k equipped with an associative\nbilinear multiplication a, b 7⊃ ab, a, b 2 A. We will always consider associative algebras with unit,\ni.e., with an element 1 such that 1 a = a 1 = a for all a 2 A. A basic example of an associative\n·\n·\nalgebra is the algebra EndV of linear operators from a vector space V to itself. Other important\nexamples include algebras defined by generators and relations, such as group algebras and universal\nenveloping algebras of Lie algebras.\nA representation of an associative algebra A (also called a left A-module) is a vector space\nV equipped with a homomorphism δ : A ⊃ EndV , i.e., a linear map preserving the multiplication\nand unit.\nA subrepresentation of a representation V is a subspace U\nV which is invariant under all\n→\noperators δ(a), a 2 A. Also, if V1, V2 are two representations of A then the direct sum V1 V2\nhas an obvious structure of a representation of A.\nA nonzero representation V of A is said to be irreducible if its only subrepresentations are\n0 and V itself, and indecomposable if it cannot be written as a direct sum of two nonzero\nsubrepresentations. Obviously, irreducible implies indecomposable, but not vice versa.\nTypical problems of representation theory are as follows:\n1. Classify irreducible representations of a given algebra A.\n2. Classify indecomposable representations of A.\n3. Do 1 and 2 restricting to finite dimensional representations.\nAs mentioned above, the algebra A is often given to us by generators and relations. For\nexample, the universal enveloping algebra U of the Lie algebra sl(2) is generated by h, e, f with\ndefining relations\nhe - eh = 2e,\nhf - fh = -2f,\nef - fe = h.\n(1)\nThis means that the problem of finding, say, N-dimensional representations of A reduces to solving\na bunch of nonlinear algebraic equations with respect to a bunch of unknown N by N matrices,\nfor example system (1) with respect to unknown matrices h, e, f.\nIt is really striking that such, at first glance hopelessly complicated, systems of equations can\nin fact be solved completely by methods of representation theory! For example, we will prove the\nfollowing theorem.\nTheorem 1.1. Let k = C be the field of complex numbers. Then:\n(i) The algebra U has exactly one irreducible representation Vd of each dimension, up to equiv\nalence; this representation is realized in the space of homogeneous polynomials of two variables x, y\nof degree d - 1, and defined by the formulas\nδ(h) = x@x - y@y ,\nδ(e) = x@y ,\nδ(f) = y@x .\n(ii) Any indecomposable finite dimensional representation of U is irreducible. That is, any finite\n\n-\n|\n|\n|\ndimensional representation of U is a direct sum of irreducible representations.\nAs another example consider the representation theory of quivers.\nA quiver is a finite oriented graph Q. A representation of Q over a field k is an assignment\nof a k-vector space Vi to every vertex i of Q, and of a linear operator Ah : Vi ⊃ Vj to every directed\nedge h going from i to j (loops and multiple edges are allowed). We will show that a representation\nof a quiver Q is the same thing as a representation of a certain algebra PQ called the path algebra\nof Q. Thus one may ask: what are the indecomposable finite dimensional representations of Q?\nMore specifically, let us say that Q is of finite type if it has finitely many indecomposable\nrepresentations.\nWe will prove the following striking theorem, proved by P. Gabriel about 35 years ago:\nTheorem 1.2. The finite type property of Q does not depend on the orientation of edges. The\nconnected graphs that yield quivers of finite type are given by the following list:\n- An :\n- · · · -\n- · · · -\nDn:\n- E6 :\n----\n- E7 :\n-----\n------\nE8 :\n|\n-\nThe graphs listed in the theorem are called (simply laced) Dynkin diagrams. These graphs\narise in a multitude of classification problems in mathematics, such as classification of simple Lie\nalgebras, singularities, platonic solids, reflection groups, etc. In fact, if we needed to make contact\nwith an alien civilization and show them how sophisticated our civilization is, perhaps showing\nthem Dynkin diagrams would be the best choice!\nAs a final example consider the representation theory of finite groups, which is one of the most\nfascinating chapters of representation theory. In this theory, one considers representations of the\ngroup algebra A = C[G] of a finite group G - the algebra with basis ag, g 2 G and multiplication\nlaw agah = agh. We will show that any finite dimensional representation of A is a direct sum of\nirreducible representations, i.e., the notions of an irreducible and indecomposable representation\nare the same for A (Maschke's theorem). Another striking result discussed below is the Frobenius\ndivisibility theorem: the dimension of any irreducible representation of A divides the order of G.\nFinally, we will show how to use representation theory of finite groups to prove Burnside's theorem:\na\nany finite group of order p qb, where p, q are primes, is solvable. Note that this theorem does not\nmention representations, which are used only in its proof; a purely group-theoretical proof of this\ntheorem (not using representations) exists but is much more difficult!\n\n1.2\nAlgebras\nLet us now begin a systematic discussion of representation theory.\nLet k be a field. Unless stated otherwise, we will always assume that k is algebraically closed,\ni.e., any nonconstant polynomial with coefficients in k has a root in k. The main example is the\nfield of complex numbers C, but we will also consider fields of characteristic p, such as the algebraic\nclosure Fp of the finite field Fp of p elements.\nDefinition 1.3. An associative algebra over k is a vector space A over k together with a bilinear\nmap A × A ⊃ A, (a, b) 7⊃ ab, such that (ab)c = a(bc).\nDefinition 1.4. A unit in an associative algebra A is an element 1 2 A such that 1a = a1 = a.\nProposition 1.5. If a unit exists, it is unique.\nProof. Let 1, 10 be two units. Then 1 = 110 = 10.\nFrom now on, by an algebra A we will mean an associative algebra with a unit. We will also\nassume that A = 0.\n⇒\nExample 1.6. Here are some examples of algebras over k:\n1. A = k.\n2. A = k[x1, ..., xn] - the algebra of polynomials in variables x1, ..., xn.\n3. A = EndV - the algebra of endomorphisms of a vector space V over k (i.e., linear maps, or\noperators, from V to itself). The multiplication is given by composition of operators.\n4. The free algebra A = k x1, ..., xni. A basis of this algebra consists of words in letters\n*\nx1, ..., xn, and multiplication in this basis is simply concatenation of words.\n5. The group algebra A = k[G] of a group G. Its basis is {ag, g 2 G}, with multiplication law\nagah = agh.\nDefinition 1.7. An algebra A is commutative if ab = ba for all a, b 2 A.\nFor instance, in the above examples, A is commutative in cases 1 and 2, but not commutative in\ncases 3 (if dim V > 1), and 4 (if n > 1). In case 5, A is commutative if and only if G is commutative.\nDefinition 1.8. A homomorphism of algebras f : A ⊃ B is a linear map such that f(xy) =\nf(x)f(y) for all x, y 2 A, and f(1) = 1.\n1.3\nRepresentations\nDefinition 1.9. A representation of an algebra A (also called a left A-module) is a vector space\nV together with a homomorphism of algebras δ : A ⊃ EndV .\nSimilarly, a right A-module is a space V equipped with an antihomomorphism δ : A ⊃ EndV ;\ni.e., δ satisfies δ(ab) = δ(b)δ(a) and δ(1) = 1.\nThe usual abbreviated notation for δ(a)v is av for a left module and va for the right module.\nThen the property that δ is an (anti)homomorphism can be written as a kind of associativity law:\n(ab)v = a(bv) for left modules, and (va)b = v(ab) for right modules.\nHere are some examples of representations.\n\nV\nExample 1.10. 1. V = 0.\n2. V = A, and δ : A ⊃ EndA is defined as follows: δ(a) is the operator of left multiplication by\na, so that δ(a)b = ab (the usual product). This representation is called the regular representation\nof A. Similarly, one can equip A with a structure of a right A-module by setting δ(a)b := ba.\n3. A = k. Then a representation of A is simply a vector space over k.\n4. A = k x1, ..., xni. Then a representation of A is just a vector space V over k with a collection\n*\nof arbitrary linear operators δ(x1), ..., δ(xn) : V ⊃ V (explain why!).\nDefinition 1.11. A subrepresentation of a representation V of an algebra A is a subspace W →\nwhich is invariant under all the operators δ(a) : V ⊃ V , a 2 A.\nFor instance, 0 and V are always subrepresentations.\nDefinition 1.12. A representation V = 0 of A is irreducible (or simple) if the only subrepresenta\n⇒\ntions of V are 0 and V .\nDefinition 1.13. Let V1, V2 be two representations of an algebra A. A homomorphism (or in\ntertwining operator) θ : V1 ⊃ V2 is a linear operator which commutes with the action of A, i.e.,\nθ(av) = aθ(v) for any v 2 V1. A homomorphism θ is said to be an isomorphism of representations\nif it is an isomorphism of vector spaces. The set (space) of all homomorphisms of representations\nV1 ⊃ V2 is denoted by HomA(V1, V2).\nNote that if a linear operator θ : V1 ⊃ V2 is an isomorphism of representations then so is the\nlinear operator θ-1 : V2 ⊃ V1 (check it!).\nTwo representations between which there exists an isomorphism are said to be isomorphic. For\npractical purposes, two isomorphic representations may be regarded as \"the same\", although there\ncould be subtleties related to the fact that an isomorphism between two representations, when it\nexists, is not unique.\nDefinition 1.14. Let V1, V2 be representations of an algebra A. Then the space V1 V2 has an\nobvious structure of a representation of A, given by a(v1 v2) = av1 av2.\nDefinition 1.15. A nonzero representation V of an algebra A is said to be indecomposable if it is\nnot isomorphic to a direct sum of two nonzero representations.\nIt is obvious that an irreducible representation is indecomposable. On the other hand, we will\nsee below that the converse statement is false in general.\nOne of the main problems of representation theory is to classify irreducible and indecomposable\nrepresentations of a given algebra up to isomorphism. This problem is usually hard and often can\nbe solved only partially (say, for finite dimensional representations). Below we will see a number\nof examples in which this problem is partially or fully solved for specific algebras.\nWe will now prove our first result - Schur's lemma. Although it is very easy to prove, it is\nfundamental in the whole subject of representation theory.\nProposition 1.16. (Schur's lemma) Let V1, V2 be representations of an algebra A over any field\nF (which need not be algebraically closed). Let θ : V1 ⊃ V2 be a nonzero homomorphism of\nrepresentations. Then:\n(i) If V1 is irreducible, θ is injective;\n\n(ii) If V2 is irreducible, θ is surjective.\nThus, if both V1 and V2 are irreducible, θ is an isomorphism.\nProof. (i) The kernel K of θ is a subrepresentation of V1. Since θ = 0, this subrepresentation\n⇒\ncannot be V1. So by irreducibility of V1 we have K = 0.\n(ii) The image I of θ is a subrepresentation of V2. Since θ = 0, this subrepresentation cannot\n⇒\nbe 0. So by irreducibility of V2 we have I = V2.\nCorollary 1.17. (Schur's lemma for algebraically closed fields) Let V be a finite dimensional\nirreducible representation of an algebra A over an algebraically closed field k, and θ : V ⊃ V is an\nintertwining operator. Then θ = ∂ Id for some ∂ 2 k (a scalar operator).\n·\nRemark. Note that this Corollary is false over the field of real numbers: it suffices to take\nA = C (regarded as an R-algebra), and V = A.\nProof. Let ∂ be an eigenvalue of θ (a root of the characteristic polynomial of θ). It exists since k is\nan algebraically closed field. Then the operator θ - ∂Id is an intertwining operator V ⊃ V , which\nis not an isomorphism (since its determinant is zero). Thus by Proposition 1.16 this operator is\nzero, hence the result.\nCorollary 1.18. Let A be a commutative algebra. Then every irreducible finite dimensional rep\nresentation V of A is 1-dimensional.\nRemark. Note that a 1-dimensional representation of any algebra is automatically irreducible.\nProof. Let V be irreducible. For any element a 2 A, the operator δ(a) : V ⊃ V is an intertwining\noperator. Indeed,\nδ(a)δ(b)v = δ(ab)v = δ(ba)v = δ(b)δ(a)v\n(the second equality is true since the algebra is commutative). Thus, by Schur's lemma, δ(a) is\na scalar operator for any a 2 A. Hence every subspace of V is a subrepresentation. But V is\nirreducible, so 0 and V are the only subspaces of V . This means that dim V = 1 (since V = 0).\n⇒\nExample 1.19. 1. A = k. Since representations of A are simply vector spaces, V = A is the only\nirreducible and the only indecomposable representation.\n2. A = k[x]. Since this algebra is commutative, the irreducible representations of A are its\n1-dimensional representations. As we discussed above, they are defined by a single operator δ(x).\nIn the 1-dimensional case, this is just a number from k. So all the irreducible representations of A\nare V = k, ∂ 2 k, in which the action of A defined by δ(x) = ∂. Clearly, these representations are\npairwise non-isomorphic.\nThe classification of indecomposable representations of k[x] is more interesting. To obtain it,\nrecall that any linear operator on a finite dimensional vector space V can be brought to Jordan\nnormal form. More specifically, recall that the Jordan block J,n is the operator on kn which in\nthe standard basis is given by the formulas J,nei = ∂ei + ei-1 for i > 1, and J,ne1 = ∂e1. Then\nfor any linear operator B : V ⊃ V there exists a basis of V such that the matrix of B in this basis\nis a direct sum of Jordan blocks. This implies that all the indecomposable representations of A are\nV,n = kn , ∂ 2 k, with δ(x) = J,n. The fact that these representations are indecomposable and\npairwise non-isomorphic follows from the Jordan normal form theorem (which in particular says\nthat the Jordan normal form of an operator is unique up to permutation of blocks).\n\nThis example shows that an indecomposable representation of an algebra need not be irreducible.\n3. The group algebra A = k[G], where G is a group. A representation of A is the same thing as\na representation of G, i.e., a vector space V together with a group homomorphism δ : G ⊃ Aut(V ),\nwhre Aut(V ) = GL(V ) denotes the group of invertible linear maps from the space V to itself.\nProblem 1.20. Let V be a nonzero finite dimensional representation of an algebra A. Show that\nit has an irreducible subrepresentation. Then show by example that this does not always hold for\ninfinite dimensional representations.\nProblem 1.21. Let A be an algebra over a field k. The center Z(A) of A is the set of all elements\nz 2 A which commute with all elements of A. For example, if A is commutative then Z(A) = A.\n(a) Show that if V is an irreducible finite dimensional representation of A then any element\nz 2 Z(A) acts in V by multiplication by some scalar νV (z). Show that νV : Z(A) ⊃ k is a\nhomomorphism. It is called the central character of V .\n(b) Show that if V is an indecomposable finite dimensional representation of A then for any\nz 2 Z(A), the operator δ(z) by which z acts in V has only one eigenvalue νV (z), equal to the\nscalar by which z acts on some irreducible subrepresentation of V . Thus νV : Z(A) ⊃ k is a\nhomomorphism, which is again called the central character of V .\n(c) Does δ(z) in (b) have to be a scalar operator?\nProblem 1.22. Let A be an associative algebra, and V a representation of A. By EndA(V ) one\ndenotes the algebra of all homomorphisms of representations V ⊃ V . Show that EndA(A) = Aop,\nthe algebra A with opposite multiplication.\nProblem 1.23. Prove the following \"Infinite dimensional Schur's lemma\" (due to Dixmier): Let\nA be an algebra over C and V be an irreducible representation of A with at most countable basis.\nThen any homomorphism of representations θ : V ⊃ V is a scalar operator.\nHint. By the usual Schur's lemma, the algebra D := EndA(V ) is an algebra with division.\nShow that D is at most countably dimensional. Suppose θ is not a scalar, and consider the subfield\nC(θ)\nD. Show that C(θ) is a transcendental extension of C. Derive from this that C(θ) is\n→\nuncountably dimensional and obtain a contradiction.\n1.4\nIdeals\nA left ideal of an algebra A is a subspace I ∧ A such that aI ∧ I for all a 2 A. Similarly, a right\nideal of an algebra A is a subspace I ∧ A such that Ia ∧ I for all a 2 A. A two-sided ideal is a\nsubspace that is both a left and a right ideal.\nLeft ideals are the same as subrepresentations of the regular representation A. Right ideals are\nthe same as subrepresentations of the regular representation of the opposite algebra Aop.\nBelow are some examples of ideals:\n- If A is any algebra, 0 and A are two-sided ideals. An algebra A is called simple if 0 and A\nare its only two-sided ideals.\n- If θ : A ⊃ B is a homomorphism of algebras, then ker θ is a two-sided ideal of A.\n- If S is any subset of an algebra A, then the two-sided ideal generated by S is denoted *Si and\nis the span of elements of the form asb, where a, b 2 A and s 2 S. Similarly we can define\n*Siφ = span{as} and *Sir = span{sb}, the left, respectively right, ideal generated by S.\n\n1.5\nQuotients\nLet A be an algebra and I a two-sided ideal in A. Then A/I is the set of (additive) cosets of I.\nLet β : A ⊃ A/I be the quotient map. We can define multiplication in A/I by β(a) β(b) := β(ab).\n·\nThis is well defined because if β(a) = β(a0) then\nβ(a0b) = β(ab + (a0 - a)b) = β(ab) + β((a0 - a)b) = β(ab)\nbecause (a0 - a)b 2 Ib ∧ I = ker β, as I is a right ideal; similarly, if β(b) = β(b0) then\nβ(ab0) = β(ab + a(b0 - b)) = β(ab) + β(a(b0 - b)) = β(ab)\nbecause a(b0 - b) 2 aI ∧ I = ker β, as I is also a left ideal. Thus, A/I is an algebra.\nSimilarly, if V is a representation of A, and W\nV is a subrepresentation, then V/W is also a\n→\nrepresentation. Indeed, let β : V ⊃ V/W be the quotient map, and set δV/W (a)β(x) := β(δV (a)x).\nAbove we noted that left ideals of A are subrepresentations of the regular representation of A,\nand vice versa. Thus, if I is a left ideal in A, then A/I is a representation of A.\nProblem 1.24. Let A = k[x1, ..., xn] and I = A be any ideal in A containing all homogeneous\n⇒\npolynomials of degree ⊂ N. Show that A/I is an indecomposable representation of A.\nProblem 1.25. Let V = 0 be a representation of A. We say that a vector v 2 V is cyclic if it\n⇒\ngenerates V , i.e., Av = V . A representation admitting a cyclic vector is said to be cyclic. Show\nthat\n(a) V is irreducible if and only if all nonzero vectors of V are cyclic.\n(b) V is cyclic if and only if it is isomorphic to A/I, where I is a left ideal in A.\n(c) Give an example of an indecomposable representation which is not cyclic.\nHint. Let A = C[x, y]/I2, where I2 is the ideal spanned by homogeneous polynomials of degree\n⊂ 2 (so A has a basis 1, x, y). Let V = A⊕ be the space of linear functionals on A, with the action\nof A given by (δ(a)f)(b) = f(ba). Show that V provides such an example.\n1.6\nAlgebras defined by generators and relations\nIf f1, . . . , fm are elements of the free algebra k x1, . . . , xni, we say that the algebra\n*\nA := k*x1, . . . , xni/*{f1, . . . , fm}i is generated by x1, . . . , xn with defining relations f1 = 0, . . . , fm =\n0.\n1.7\nExamples of algebras\n1. The Weyl algebra, k x, yi/ yx - xy - 1i.\n*\n*\n2. The q-Weyl algebra, generated by x, x-1, y, y-1 with defining relations yx = qxy and xx-1 =\nx-1x = yy-1 = y-1y = 1.\nProposition. (i) A basis for the Weyl algebra A is {xiyj , i, j ⊂ 0}.\n(ii) A basis for the q-Weyl algebra Aq is {xiyj , i, j 2 Z}.\n\nX\nProof. (i) First let us show that the elements xiyj are a spanning set for A. To do this, note that\nany word in x, y can be ordered to have all the x on the left of the y, at the cost of interchanging\nsome x and y. Since yx - xy = 1, this will lead to error terms, but these terms will be sums of\nmonomials that have a smaller number of letters x, y than the original word. Therefore, continuing\nthis process, we can order everything and represent any word as a linear combination of xiyj.\nThe proof that xiyj are linearly independent is based on representation theory. Namely, let a be\na variable, and E = tak[a][t, t-1] (here ta is just a formal symbol, so really E = k[a][t, t-1]). Then E\ndf\nd(ta+n)\nis a representation of A with action given by xf = tf and yf = dt (where\ndt\n:= (a + n)ta+n-1).\ni\nSuppose now that we have a nontrivial linear relation ⎨ cij x yj = 0. Then the operator\ni\nL =\nX\ncij t\nd j\ndt\nacts by zero in E. Let us write L as\nr\nd j\nL =\nX\nQj(t) dt\n,\nj=0\nwhere Qr ⇒= 0. Then we have\nr\nLta =\nQj (t)a(a - 1)...(a - j + 1)ta-j .\nj=0\nThis must be zero, so we have ⎨r\nQj (t)a(a - 1)...(a - j + 1)t-j = 0 in k[a][t, t-1]. Taking the\nj=0\nleading term in a, we get Qr(t) = 0, a contradiction.\n(ii) Any word in x, y, x-1, y-1 can be ordered at the cost of multiplying it by a power of q. This\neasily implies both the spanning property and the linear independence.\nRemark. The proof of (i) shows that the Weyl algebra A can be viewed as the algebra of\npolynomial differential operators in one variable t.\nThe proof of (i) also brings up the notion of a faithful representation.\nDefinition. A representation δ : A ⊃ End V is faithful if δ is injective.\nFor example, k[t] is a faithful representation of the Weyl algebra, if k has characteristic zero\n(check it!), but not in characteristic p, where (d/dt)pQ = 0 for any polynomial Q. However, the\nrepresentation E = tak[a][t, t-1], as we've seen, is faithful in any characteristic.\nProblem 1.26. Let A be the Weyl algebra, generated by two elements x, y with the relation\nyx - xy - 1 = 0.\n(a) If chark = 0, what are the finite dimensional representations of A? What are the two-sided\nideals in A?\nHint. For the first question, use the fact that for two square matrices B, C, Tr(BC) = Tr(CB).\nFor the second question, show that any nonzero two-sided ideal in A contains a nonzero polynomial\nin x, and use this to characterize this ideal.\nSuppose for the rest of the problem that chark = p.\n(b) What is the center of A?\n\n-\n-\n-\n- O O\n-\n/ /\no o\n/ /\nHint. Show that xp and yp are central elements.\n(c) Find all irreducible finite dimensional representations of A.\nHint. Let V be an irreducible finite dimensional representation of A, and v be an eigenvector\nof y in V . Show that {v, xv, x2v, ..., xp-1v} is a basis of V .\nProblem 1.27. Let q be a nonzero complex number, and A be the q-Weyl algebra over C generated\nby x±1 and y±1 with defining relations xx-1 = x-1x = 1, yy-1 = y-1y = 1, and xy = qyx.\n(a) What is the center of A for different q? If q is not a root of unity, what are the two-sided\nideals in A?\n(b) For which q does this algebra have finite dimensional representations?\nHint. Use determinants.\n(c) Find all finite dimensional irreducible representations of A for such q.\nHint. This is similar to part (c) of the previous problem.\n1.8\nQuivers\nDefinition 1.28. A quiver Q is a directed graph, possibly with self-loops and/or multiple edges\nbetween two vertices.\nExample 1.29.\n-\nWe denote the set of vertices of the quiver Q as I, and the set of edges as E. For an edge h 2 E,\nlet h0, h00 denote the source and target of h, respectively:\nh0\nh\nh00\nDefinition 1.30. A representation of a quiver Q is an assignment to each vertex i 2 I of a vector\nspace Vi and to each edge h 2 E of a linear map xh : Vh⊗ -⊃ Vh⊗⊗ .\nIt turns out that the theory of representations of quivers is a part of the theory of representations\nof algebras in the sense that for each quiver Q, there exists a certain algebra PQ, called the path\nalgebra of Q, such that a representation of the quiver Q is \"the same\" as a representation of the\nalgebra PQ. We shall first define the path algebra of a quiver and then justify our claim that\nrepresentations of these two objects are \"the same\".\nDefinition 1.31. The path algebra PQ of a quiver Q is the algebra whose basis is formed by\noriented paths in Q, including the trivial paths pi, i 2 I, corresponding to the vertices of Q, and\nmultiplication is concatenation of paths: ab is the path obtained by first tracing b and then a. If\ntwo paths cannot be concatenated, the product is defined to be zero.\nRemark 1.32. It is easy to see that for a finite quiver ⎨ pi = 1, so PQ is an algebra with unit.\ni2I\nProblem 1.33. Show that the algebra PQ is generated by pi for i 2 I and ah for h 2 E with the\ndefining relations:\n\n1. p2\ni = pi, pipj = 0 for i = j\n⇒\n2. ahph⊗ = ah, ahpj = 0 for j = h0\n⇒\n3. ph⊗⊗ ah = ah, piah = 0 for i = h00\n⇒\nWe now justify our statement that a representation of a quiver is the same thing as a represen\ntation of the path algebra of a quiver.\nLet V be a representation of the path algebra PQ. From this representation, we can construct a\nrepresentation of Q as follows: let Vi = piV, and for any edge h, let xh = ah|ph⊗ V : ph⊗ V -⊃ ph⊗⊗ V\nbe the operator corresponding to the one-edge path h.\nSimilarly, let (Vi, xh) be a representation of a quiver Q. From this representation, we can\nconstruct a representation of the path algebra PQ: let V = L\ni Vi, let pi : V ⊃ Vi ⊃ V be the\nprojection onto Vi, and for any path p = h1...hm let ap = xh1 ...xhm : Vh⊗ ⊃ Vh⊗⊗ be the composition\nm\nof the operators corresponding to the edges occurring in p (and the action of this operator on the\nother Vi is zero).\nIt is clear that the above assignments V 7⊃ (piV) and (Vi) 7⊃ L Vi are inverses of each other.\ni\nThus, we have a bijection between isomorphism classes of representations of the algebra PQ and of\nthe quiver Q.\nRemark 1.34. In practice, it is generally easier to consider a representation of a quiver as in\nDefinition 1.30.\nWe lastly define several previous concepts in the context of quivers representations.\nDefinition 1.35. A subrepresentation of a representation (Vi, xh) of a quiver Q is a representation\n(Wi, x0\nh) where Wi ∧ Vi for all i 2 I and where xh(Wh⊗ ) ∧ Wh⊗⊗ and x0\nh = xh|Wh⊗ : Wh⊗ -⊃ Wh⊗⊗ for\nall h 2 E.\nDefinition 1.36. The direct sum of two representations (Vi, xh) and (Wi, yh) is the representation\n(Vi Wi, xh yh).\nAs with representations of algebras, a nonzero representation (Vi) of a quiver Q is said to be\nirreducible if its only subrepresentations are (0) and (Vi) itself, and indecomposable if it is not\nisomorphic to a direct sum of two nonzero representations.\nDefinition 1.37. Let (Vi, xh) and (Wi, yh) be representations of the quiver Q. A homomorphism\n' : (Vi) -⊃ (Wi) of quiver representations is a collection of maps 'i : Vi -⊃ Wi such that\nyh inf 'h⊗ = 'h⊗⊗ inf xh for all h 2 E.\nProblem 1.38. Let A be a Z+-graded algebra, i.e., A = n∧0A[n], and A[n] A[m]\nA[n + m].\nIf A[n] is finite dimensional, it is useful to consider the Hilbert series hA(t) =\n· ⎨ dim\n→\nA[n]tn (the\ngenerating function of dimensions of A[n]). Often this series converges to a rational function, and\nthe answer is written in the form of such function. For example, if A = k[x] and deg(xn) = n then\nhA(t) = 1 + t + t2 + ... + tn + ... =\n1 - t\nFind the Hilbert series of:\n(a) A = k[x1, ..., xm] (where the grading is by degree of polynomials);\n\n(b) A = k < x1, ..., xm > (the grading is by length of words);\n(c) A is the exterior (=Grassmann) algebra √k[x1, ..., xm], generated over some field k by\nx1, ..., xm with the defining relations xixj + xj xi = 0 and xi\n2 = 0 for all i, j (the grading is by\ndegree).\n(d) A is the path algebra PQ of a quiver Q (the grading is defined by deg(pi) = 0, deg(ah) = 1).\nHint. The closed answer is written in terms of the adjacency matrix MQ of Q.\n1.9\nLie algebras\nLet g be a vector space over a field k, and let [ , ] : g × g -⊃ g be a skew-symmetric bilinear map.\n(That is, [a, a] = 0, and hence [a, b] = -[b, a]).\nDefinition 1.39. (g, [ , ]) is a Lie algebra if [ , ] satisfies the Jacobi identity\n\n[a, b] , c\n\n+\n\n[b, c] , a\n\n+\n\n[c, a] , b\n\n= 0.\n(2)\nExample 1.40. Some examples of Lie algebras are:\n1. Any space g with [ , ] = 0 (abelian Lie algebra).\n2. Any associative algebra A with [a, b] = ab - ba .\n3. Any subspace U of an associative algebra A such that [a, b] 2 U for all a, b 2 U.\n4. The space Der(A) of derivations of an algebra A, i.e. linear maps D : A ⊃ A which satisfy\nthe Leibniz rule:\nD(ab) = D(a)b + aD(b).\nRemark 1.41. Derivations are important because they are the \"infinitesimal version\" of automor\nphisms (i.e., isomorphisms onto itself). For example, assume that g(t) is a differentiable family of\nautomorphisms of a finite dimensional algebra A over R or C parametrized by t 2 (-φ, φ) such that\ng(0) = Id. Then D := g0(0) : A ⊃ A is a derivation (check it!). Conversely, if D : A ⊃ A is a\nderivation, then etD is a 1-parameter family of automorphisms (give a proof!).\nThis provides a motivation for the notion of a Lie algebra. Namely, we see that Lie algebras\narise as spaces of infinitesimal automorphisms (=derivations) of associative algebras. In fact, they\nsimilarly arise as spaces of derivations of any kind of linear algebraic structures, such as Lie algebras,\nHopf algebras, etc., and for this reason play a very important role in algebra.\nHere are a few more concrete examples of Lie algebras:\n1. R3 with [u, v] = u × v, the cross-product of u and v.\n2. sl(n), the set of n × n matrices with trace 0.\nFor example, sl(2) has the basis\ne =\nf =\nh =\n0 0\n0 -1\nwith relations\n[h, e] = 2e, [h, f] = -2f, [e, f] = h.\n\n3. The Heisenberg Lie algebra H of matrices\n\n0 0\n0 ⊕ ⊕\n⊕\n0 0 0\nIt has the basis\n4. The algebra aff(1) of matrices ( ⊕⊕\n0 0 )\nIts basis consists of X = ( 1 0 ) and Y = ( 0 1 ), with [X, Y ] = Y .\n0 0\n0 0\n5. so(n), the space of skew-symmetric n × n matrices, with [a, b] = ab - ba.\nExercise. Show that Example 1 is a special case of Example 5 (for n = 3).\nDefinition 1.42. Let g1, g2 be Lie algebras. A homomorphism ' : g1 -⊃ g2 of Lie algebras is a\nlinear map such that '([a, b]) = ['(a), '(b)].\n⎧\n@\nwith relations [\n] = and [\n] = [\n] = 0.\ny, x\nc\ny, c\nx, c\nDefinition 1.43. A representation of a Lie algebra\nis a vector space V with a homomorphism\ng\nof Lie algebras δ : g -⊃ End V .\nExample 1.44. Some examples of representations of Lie algebras are:\n1. V = 0.\n2. Any vector space V with δ = 0 (the trivial representation).\n3. The adjoint representation V = g with δ(a)(b) := [a, b]. That this is a representation follows\nfrom Equation (2). Thus, the meaning of the Jacobi identity is that it is equivalent to the\nexistence of the adjoint representation.\nIt turns out that a representation of a Lie algebra g is the same thing as a representation of a\ncertain associative algebra U(g). Thus, as with quivers, we can view the theory of representations\nof Lie algebras as a part of the theory of representations of associative algebras.\nk\nDefinition 1.45. Let g be a Lie algebra with basis xi and [ , ] defined by [xi, xj ] = ⎨\nk cij xk. The\nuniversal enveloping algebra U(g) is the associative algebra generated by the xi's with the\nk\ndefining relations xixj - xjxi = ⎨\nk cij xk.\nRemark. This is not a very good definition since it depends on the choice of a basis. Later we\nwill give an equivalent definition which will be basis-independent.\nExercise. Explain why a representation of a Lie algebra is the same thing as a representation\nof its universal enveloping algebra.\nExample 1.46. The associative algebra U(sl(2)) is the algebra generated by e, f, h with relations\nhe - eh = 2e\nhf - fh = -2f\nef - fe = h.\n⎧\n@\n⎝\n⎝\n⎧\n@\n⎝\nx =\ny =\nc =\nExample 1.47. The algebra U(H), where H is the Heisenberg Lie algebra, is the algebra generated\nby x, y, c with the relations\nyx - xy = c\nyc - cy = 0\nxc - cx = 0.\nNote that the Weyl algebra is the quotient of U(H) by the relation c = 1.\n\n1.10\nTensor products\nIn this subsection we recall the notion of tensor product of vector spaces, which will be extensively\nused below.\nDefinition 1.48. The tensor product V\nW of vector spaces V and W over a field k is the quotient\nof the space V ∼ W whose basis is given by formal symbols v\nw, v 2 V , w 2 W , by the subspace\nspanned by the elements\n(v1 + v2)\nw - v1\nw - v2\nw, v\n(w1 + w2) - v\nw1 - v\nw2, av\nw - a(v\nw), v\naw - a(v\nw),\nwhere v 2 V, w 2 W, a 2 k.\nExercise. Show that V\nW can be equivalently defined as the quotient of the free abelian\ngroup V\nW generated by v\nw, v 2 V, w 2 W by the subgroup generated by\n-\n(v1 + v2)\nw - v1\nw - v2\nw, v\n(w1 + w2) - v\nw1 - v\nw2, av\nw - v\naw,\nwhere v 2 V, w 2 W, a 2 k.\nThe elements v\nw 2 V\nW , for v 2 V, w 2 W are called pure tensors. Note that in general,\nthere are elements of V\nW which are not pure tensors.\nThis allows one to define the tensor product of any number of vector spaces, V1\n...\nVn. Note\nthat this tensor product is associative, in the sense that (V1\nV2)\nV3 can be naturally identified\nwith V1\n(V2\nV3).\nIn particular, people often consider tensor products of the form V\nn = V\n...\nV (n times) for\na given vector space V , and, more generally, E := V\nn\n(V ⊕)\nm . This space is called the space of\ntensors of type (m, n) on V . For instance, tensors of type (0, 1) are vectors, of type (1, 0) - linear\nfunctionals (covectors), of type (1, 1) - linear operators, of type (2, 0) - bilinear forms, of type (2, 1)\n- algebra structures, etc.\nIf V is finite dimensional with basis ei, i = 1, ..., N, and ei is the dual basis of V ⊕, then a basis\nof E is the set of vectors\nei1\n...\nein\nej1\n...\nejm ,\nand a typical element of E is\nN\nX\nT i1...in\n\n...\nein\nj1\n...\nejm ,\nj1...jm ei1\n\ne\ni1,...,in,j1,...,jm=1\nwhere T is a multidimensional table of numbers.\nPhysicists define a tensor as a collection of such multidimensional tables TB attached to every\nbasis B in V , which change according to a certain rule when the basis B is changed. Here it is\nimportant to distinguish upper and lower indices, since lower indices of T correspond to V and\nupper ones to V ⊕. The physicists don't write the sum sign, but remember that one should sum\nover indices that repeat twice - once as an upper index and once as lower. This convention is\ncalled the Einstein summation, and it also stipulates that if an index appears once, then there is\nno summation over it, while no index is supposed to appear more than once as an upper index or\nmore than once as a lower index.\nOne can also define the tensor product of linear maps. Namely, if A : V ⊃ V 0 and B : W ⊃ W 0\nare linear maps, then one can define the linear map A\nB : V\nW ⊃ V 0\nW 0 given by the formula\n(A\nB)(v\nw) = Av\nBw (check that this is well defined!)\n\nThe most important properties of tensor products are summarized in the following problem.\nProblem 1.49. (a) Let U be any k-vector space. Construct a natural bijection between bilinear\nmaps V × W ⊃ U and linear maps V\nW ⊃ U.\n(b) Show that if {vi} is a basis of V and {wj } is a basis of W then {vi\nwj } is a basis of\nV\nW .\n(c) Construct a natural isomorphism V ⊕\nW ⊃ Hom(V, W ) in the case when V is finite\ndimensional (\"natural\" means that the isomorphism is defined without choosing bases).\n(d) Let V be a vector space over a field k. Let SnV be the quotient of V\nn (n-fold tensor product\nof V ) by the subspace spanned by the tensors T - s(T ) where T 2 V\nn, and s is some transposition.\nAlso let √nV be the quotient of V\nn by the subspace spanned by the tensors T such that s(T ) = T\nfor some transposition s. These spaces are called the n-th symmetric, respectively exterior, power\nof V . If {vi} is a basis of V , can you construct a basis of SnV, √nV ? If dimV = m, what are their\ndimensions?\n(e) If k has characteristic zero, find a natural identification of S nV with the space of T 2 V\nn\nsuch that T = sT for all transpositions s, and of √nV with the space of T 2 V\nn such that T = -sT\nfor all transpositions s.\n(f) Let A : V ⊃ W be a linear operator. Then we have an operator A\nn : V\nn ⊃ W\nn, and\nits symmetric and exterior powers SnA : SnV ⊃ SnW , √nA : √nV ⊃√nW which are defined in\nan obvious way. Suppose V = W and has dimension N, and assume that the eigenvalues of A are\n∂1, ..., ∂N . Find Tr(SnA), Tr(√nA).\n(g) Show that √N A = det(A)Id, and use this equality to give a one-line proof of the fact that\ndet(AB) = det(A) det(B).\nRemark. Note that a similar definition to the above can be used to define the tensor product\nV\nA W , where A is any ring, V is a right A-module, and W is a left A-module. Namely, V\nA W\nis the abelian group which is the quotient of the group V\nW freely generated by formal symbols\n-\nv\nw, v 2 V , w 2 W , modulo the relations\n(v1 + v2)\nw - v1\nw - v2\nw, v\n(w1 + w2) - v\nw1 - v\nw2, va\nw - v\naw, a 2 A.\nExercise. Throughout this exercise, we let k be an arbitrary field (not necessarily of charac\nteristic zero, and not necessarily algebraically closed).\nIf A and B are two k-algebras, then an (A, B)-bimodule will mean a k-vector space V with\nboth a left A-module structure and a right B-module structure which satisfy (av) b = a (vb) for\nany v 2 V , a 2 A and b 2 B. Note that both the notions of \"left A-module\" and \"right A-\nmodule\" are particular cases of the notion of bimodules; namely, a left A-module is the same as an\n(A, k)-bimodule, and a right A-module is the same as a (k, A)-bimodule.\nLet B be a k-algebra, W a left B-module and V a right B-module. We denote by V\nB W the\nk-vector space (V\nk W ) / *vb\nw - v\nbw | v 2 V, w 2 W, b 2 Bi. We denote the projection of\na pure tensor v\nw (with v 2 V and w 2 W ) onto the space V\nB W by v\nB w. (Note that this\ntensor product V\nB W is the one defined in the Remark after Problem1.49.)\nIf, additionally, A is another k-algebra, and if the right B-module structure on V is part of an\n(A, B)-bimodule structure, then V\nB W becomes a left A-module by a (v\nB w) = av\nB w for\nany a 2 A, v 2 V and w 2 W .\n\nSimilarly, if C is another k-algebra, and if the left B-module structure on W is part of a (B, C)\nbimodule structure, then V\nB W becomes a right C-module by (v\nB w) c = v\nB wc for any\nc 2 C, v 2 V and w 2 W .\nIf V is an (A, B)-bimodule and W is a (B, C)-bimodule, then these two structures on V\nB W\ncan be combined into one (A, C)-bimodule structure on V\nB W .\n(a) Let A, B, C, D be four algebras. Let V be an (A, B)-bimodule, W be a (B, C)-bimodule,\nand X a (C, D)-bimodule. Prove that (V\nB W )\nC X ∪V\nB (W\nC X) as (A, D)-bimodules.\n=\nThe isomorphism (from left to right) is given by (v\nB w)\nC x 7⊃ v\nB (w\nC x) for all v 2 V ,\nw 2 W and x 2 X.\n(b) If A, B, C are three algebras, and if V is an (A, B)-bimodule and W an (A, C)-bimodule,\nthen the vector space HomA (V, W ) (the space of all left A-linear homomorphisms from V to W )\ncanonically becomes a (B, C)-bimodule by setting (bf) (v) = f (vb) for all b 2 B, f 2 HomA (V, W )\nand v 2 V and (fc) (v) = f (v) c for all c 2 C, f 2 HomA (V, W ) and v 2 V .\nLet A, B, C, D be four algebras. Let V be a (B, A)-bimodule, W be a (C, B)-bimodule, and X a\n(C, D)-bimodule. Prove that HomB (V, HomC (W, X)) ∪= HomC (W\nB V, X) as (A, D)-bimodules.\nThe isomorphism (from left to right) is given by f 7⊃ (w\nB v 7⊃ f (v) w) for all v 2 V , w 2 W\nand f 2 HomB (V, HomC (W, X)).\n1.11\nThe tensor algebra\nThe notion of tensor product allows us to give more conceptual (i.e., coordinate free) definitions\nof the free algebra, polynomial algebra, exterior algebra, and universal enveloping algebra of a Lie\nalgebra.\nNamely, given a vector space V , define its tensor algebra TV over a field k to be TV = n∧0V\nn ,\nwith multiplication defined by a b := a\nb, a 2 V\nn , b 2 V\nm . Observe that a choice of a basis\n·\nx1, ..., xN in V defines an isomorphism of TV with the free algebra k < x1, ..., xn >.\nAlso, one can make the following definition.\nDefinition 1.50. (i) The symmetric algebra SV of V is the quotient of TV by the ideal generated\nby v\nw - w\nv, v, w 2 V .\n(ii) The exterior algebra √V of V is the quotient of TV by the ideal generated by v\nv, v 2 V .\n(iii) If V is a Lie algebra, the universal enveloping algebra U(V ) of V is the quotient of TV by\nthe ideal generated by v\nw - w\nv - [v, w], v, w 2 V .\nIt is easy to see that a choice of a basis x1, ..., xN in V identifies SV with the polynomial algebra\nk[x1, ..., xN ], √V with the exterior algebra √k(x1, ..., xN ), and the universal enveloping algebra U(V )\nwith one defined previously.\nAlso, it is easy to see that we have decompositions SV = n∧0SnV , √V = n∧0 √n V .\n1.12\nHilbert's third problem\nProblem 1.51. It is known that if A and B are two polygons of the same area then A can be cut\nby finitely many straight cuts into pieces from which one can make B. David Hilbert asked in 1900\nwhether it is true for polyhedra in 3 dimensions. In particular, is it true for a cube and a regular\ntetrahedron of the same volume?\n\nThe answer is \"no\", as was found by Dehn in 1901. The proof is very beautiful. Namely, to\nany polyhedron A let us attach its \"Dehn invariant\" D(A) in V = R\n(R/Q) (the tensor product\nof Q-vector spaces). Namely,\nD(A) =\nX\nl(a)\nα(a) ,\nβ\na\nwhere a runs over edges of A, and l(a), α(a) are the length of a and the angle at a.\n(a) Show that if you cut A into B and C by a straight cut, then D(A) = D(B) + D(C).\n(b) Show that φ = arccos(1/3)/β is not a rational number.\nHint. Assume that φ = 2m/n, for integers m, n. Deduce that roots of the equation x+x-1 = 2/3\nare roots of unity of degree n. Conclude that xk + x-k has denominator 3k and get a contradiction.\n(c) Using (a) and (b), show that the answer to Hilbert's question is negative. (Compute the\nDehn invariant of the regular tetrahedron and the cube).\n1.13\nTensor products and duals of representations of Lie algebras\nDefinition 1.52. The tensor product of two representations V, W of a Lie algebra g is the space\nV\nW with δV\nW (x) = δV (x)\nId + Id\nδW (x).\nDefinition 1.53. The dual representation V ⊕ to a representation V of a Lie algebra g is the dual\nspace V ⊕ to V with δV (x) = -δV (x)⊕.\nIt is easy to check that these are indeed representations.\nProblem 1.54. Let V, W, U be finite dimensional representations of a Lie algebra g. Show that\nthe space Homg(V\nW, U) is isomorphic to Homg(V, U\nW ⊕). (Here Homg := HomU(g)).\n1.14\nRepresentations of sl(2)\nThis subsection is devoted to the representation theory of sl(2), which is of central importance in\nmany areas of mathematics. It is useful to study this topic by solving the following sequence of\nexercises, which every mathematician should do, in one form or another.\nProblem 1.55. According to the above, a representation of sl(2) is just a vector space V with a\ntriple of operators E, F, H such that HE - EH = 2E, HF - FH = -2F, EF - FE = H (the\ncorresponding map δ is given by δ(e) = E, δ(f) = F , δ(h) = H).\nLet V be a finite dimensional representation of sl(2) (the ground field in this problem is C).\n\n(a) Take eigenvalues of H and pick one with the biggest real part. Call it ∂. Let V (∂) be the\ngeneralized eigenspace corresponding to ∂. Show that E|V () = 0.\n(b) Let W be any representation of sl(2) and w 2 W be a nonzero vector such that Ew = 0.\nFor any k > 0 find a polynomial Pk(x) of degree k such that EkF kw = Pk(H)w. (First compute\nEF kw, then use induction in k).\n\n(c) Let v 2 V (∂) be a generalized eigenvector of H with eigenvalue ∂. Show that there exists\nN > 0 such that F N v = 0.\n(d) Show that H is diagonalizable on V (∂). (Take N to be such that F N = 0 on V (∂), and\ncompute EN F N v, v 2 V (∂), by (b). Use the fact that Pk(x) does not have multiple roots).\n\n(e) Let Nv be the smallest N satisfying (c). Show that ∂ = Nv - 1.\n(f) Show that for each N > 0, there exists a unique up to isomorphism irreducible representation\nof sl(2) of dimension N. Compute the matrices E, F, H in this representation using a convenient\nbasis. (For V finite dimensional irreducible take ∂ as in (a) and v 2 V (∂) an eigenvector of H.\nShow that v, Fv, ..., F v is a basis of V , and compute the matrices of the operators E, F, H in this\nbasis.)\nDenote the ∂ + 1-dimensional irreducible representation from (f) by V. Below you will show\nthat any finite dimensional representation is a direct sum of V.\n(g) Show that the operator C = EF + FE + H2/2 (the so-called Casimir operator) commutes\nwith E, F, H and equals (\n+2) Id on V.\nNow it will be easy to prove the direct sum decomposition. Namely, assume the contrary, and\nlet V be a reducible representation of the smallest dimension, which is not a direct sum of smaller\nrepresentations.\n(h) Show that C has only one eigenvalue on V , namely (\n+2) for some nonnegative integer ∂.\n(use that the generalized eigenspace decomposition of C must be a decomposition of representations).\n(i) Show that V has a subrepresentation W = V such that V/W = nV for some n (use (h)\nand the fact that V is the smallest which cannot be decomposed).\n(j) Deduce from (i) that the eigenspace V (∂) of H is n + 1-dimensional. If v1, ..., vn+1 is its\nbasis, show that F j vi, 1 ∗ i ∗ n + 1, 0 ∗ j ∗ ∂ are linearly independent and therefore form a basis\nof V (establish that if Fx = 0 and Hx = μx then Cx = μ(μ-2) x and hence μ = -∂).\n(k) Define Wi = span(vi, Fvi, ..., F vi). Show that Vi are subrepresentations of V and derive a\ncontradiction with the fact that V cannot be decomposed.\n(l) (Jacobson-Morozov Lemma) Let V be a finite dimensional complex vector space and A : V ⊃\nV a nilpotent operator. Show that there exists a unique, up to an isomorphism, representation of\nsl(2) on V such that E = A. (Use the classification of the representations and the Jordan normal\nform theorem)\n(m) (Clebsch-Gordan decomposition) Find the decomposition into irreducibles of the represen\ntation V\nVμ of sl(2).\nHint. For a finite dimensional representation V of sl(2) it is useful to introduce the character\nνV (x) = Tr(exH ), x 2 C. Show that νV ∈W (x) = νV (x) + νW (x) and νV\nW (x) = νV (x)νW (x).\nThen compute the character of V and of V\nVμ and derive the decomposition. This decomposition\nis of fundamental importance in quantum mechanics.\n(n) Let V = CM\nCN , and A = JM (0)\nIdN + IdM\nJN (0), where Jn(0) is the Jordan block\nof size n with eigenvalue zero (i.e., Jn(0)ei = ei-1, i = 2, ..., n, and Jn(0)e1 = 0). Find the Jordan\nnormal form of A using (l),(m).\n1.15\nProblems on Lie algebras\nProblem 1.56. (Lie's Theorem) The commutant K(g) of a Lie algebra g is the linear span\nof elements [x, y], x, y 2 g. This is an ideal in g (i.e., it is a subrepresentation of the adjoint\nrepresentation). A finite dimensional Lie algebra g over a field k is said to be solvable if there\nexists n such that Kn(g) = 0. Prove the Lie theorem: if k = C and V is a finite dimensional\nirreducible representation of a solvable Lie algebra g then V is 1-dimensional.\n\nHint. Prove the result by induction in dimension. By the induction assumption, K(g) has a\ncommon eigenvector v in V , that is there is a linear function ν : K(g) ⊃ C such that av = ν(a)v\nfor any a 2 K(g). Show that g preserves common eigenspaces of K(g) (for this you will need to\nshow that ν([x, a]) = 0 for x 2 g and a 2 K(g). To prove this, consider the smallest vector subspace\nU containing v and invariant under x. This subspace is invariant under K(g) and any a 2 K(g)\nacts with trace dim(U)ν(a) in this subspace. In particular 0 = Tr([x, a]) = dim(U)ν([x, a]).).\nProblem 1.57. Classify irreducible finite dimensional representations of the two dimensional Lie\nalgebra with basis X, Y and commutation relation [X, Y ] = Y . Consider the cases of zero and\npositive characteristic. Is the Lie theorem true in positive characteristic?\nProblem 1.58. (hard!) For any element x of a Lie algebra g let ad(x) denote the operator g ⊃\ng, y 7⊃ [x, y]. Consider the Lie algebra gn generated by two elements x, y with the defining relations\nad(x)2(y) = ad(y)n+1(x) = 0.\n(a) Show that the Lie algebras g1, g2, g3 are finite dimensional and find their dimensions.\n(b) (harder!) Show that the Lie algebra g4 has infinite dimension. Construct explicitly a basis\nof this algebra.\n\nGeneral results of representation theory\n2.1\nSubrepresentations in semisimple representations\nLet A be an algebra.\nDefinition 2.1. A semisimple (or completely reducible) representation of A is a direct sum of\nirreducible representations.\nExample. Let V be an irreducible representation of A of dimension n. Then Y = End(V ),\nwith action of A by left multiplication, is a semisimple representation of A, isomorphic to nV (the\ndirect sum of n copies of V ). Indeed, any basis v1, ..., vn of V gives rise to an isomorphism of\nrepresentations End(V ) ⊃ nV , given by x ⊃ (xv1, ..., xvn).\nRemark. Note that by Schur's lemma, any semisimple representation V of A is canonically\nidentified with X HomA(X, V )\nX, where X runs over all irreducible representations of A. Indeed,\nwe have a natural map f : X Hom(X, V )\nX ⊃ V , given by g\nx ⊃ g(x), x 2 X, g 2 Hom(X, V ),\nand it is easy to verify that this map is an isomorphism.\nWe'll see now how Schur's lemma allows us to classify subrepresentations in finite dimensional\nsemisimple representations.\nProposition 2.2. Let Vi, 1 ∗ i ∗ m be irreducible finite dimensional pairwise nonisomorphic\nm\nrepresentations of A, and W be a subrepresentation of V =\ni=1niVi. Then W is isomorphic to\nm\n\ni=1riVi, ri ∗ ni, and the inclusion θ : W ⊃ V is a direct sum of inclusions θi : riVi ⊃ niVi given\nby multiplication of a row vector of elements of Vi (of length ri) by a certain ri-by-ni matrix Xi\nwith linearly independent rows: θ(v1, ..., vri ) = (v1, ..., vri )Xi.\nProof. The proof is by induction in n := ⎨m\ni=1 ni. The base of induction (n = 1) is clear. To perform\nthe induction step, let us assume that W is nonzero, and fix an irreducible subrepresentation\nP\nW . Such P exists (Problem 1.20). 2 Now, by Schur's lemma, P is isomorphic to Vi for some i,\n→\nand the inclusion θ|P : P ⊃ V factors through niVi, and upon identification of P with Vi is given\nby the formula v 7⊃ (vq1, ..., vqni ), where ql 2 k are not all zero.\nNow note that the group Gi = GLni (k) of invertible ni-by-ni matrices over k acts on niVi\nby (v1, ..., vni ) ⊃ (v1, ..., vni )gi (and by the identity on njVj , j = i), and therefore acts on the\n⇒\nset of subrepresentations of V , preserving the property we need to establish: namely, under the\naction of gi, the matrix Xi goes to Xigi, while Xj , j = i don't change. Take gi 2 Gi such that\n⇒\n(q1, ..., qni )gi = (1, 0, ..., 0). Then Wgi contains the first summand Vi of niVi (namely, it is Pgi),\nhence Wgi = Vi W 0, where W 0\nn1V1 ... (ni - 1)Vi ... nmVm is the kernel of the projection\n→\nof Wgi to the first summand Vi along the other summands. Thus the required statement follows\nfrom the induction assumption.\nRemark 2.3. In Proposition 2.2, it is not important that k is algebraically closed, nor it matters\nthat V is finite dimensional. If these assumptions are dropped, the only change needed is that the\nentries of the matrix Xi are no longer in k but in Di = EndA(Vi), which is, as we know, a division\nalgebra. The proof of this generalized version of Proposition 2.2 is the same as before (check it!).\nAnother proof of the existence of P , which does not use the finite dimensionality of V , is by induction in n.\nNamely, if W itself is not irreducible, let K be the kernel of the projection of W to the first summand V1. Then\nK is a subrepresentation of (n1 - 1)V1 ... nmVm, which is nonzero since W is not irreducible, so K contains an\nirreducible subrepresentation by the induction assumption.\n\n|\n{z\n}\n2.2\nThe density theorem\nLet A be an algebra over an algebraically closed field k.\nCorollary 2.4. Let V be an irreducible finite dimensional representation of A, and v1, ..., vn 2 V\nbe any linearly independent vectors. Then for any w1, ..., wn 2 V there exists an element a 2 A\nsuch that avi = wi.\nProof. Assume the contrary. Then the image of the map A ⊃ nV given by a ⊃ (av1, ..., avn) is a\nproper subrepresentation, so by Proposition 2.2 it corresponds to an r-by-n matrix X, r < n. Thus,\ntaking a = 1, we see that there exist vectors u1, ..., ur 2 V such that (u1, ..., ur)X = (v1, ..., vn). Let\n(q1, ..., qn) be a nonzero vector such that X(q1, ..., qn)T = 0 (it exists because r < n). Then ⎨ qivi =\n(u1, ..., ur )X(q1, ..., qn)T = 0, i.e. ⎨ qivi = 0 - a contradiction with the linear independence of\nvi.\nTheorem 2.5. (the Density Theorem). (i) Let V be an irreducible finite dimensional representation\nof A. Then the map δ : A ⊃ EndV is surjective.\n(ii) Let V = V1 ... Vr, where Vi are irreducible pairwise nonisomorphic finite dimensional\nrepresentations of A. Then the map r δi : A ⊃r\nEnd(Vi) is surjective.\ni=1\ni=1\nProof. (i) Let B be the image of A in End(V ). We want to show that B = End(V ). Let c 2 End(V ),\nv1, ..., vn be a basis of V , and wi = cvi. By Corollary 2.4, there exists a 2 A such that avi = wi.\nThen a maps to c, so c 2 B, and we are done.\n(ii) Let Bi be the image of A in End(Vi), and B be the image of A in r\nEnd(Vi). Recall that as\ni=1\na representation of A, r\nEnd(Vi) is semisimple: it is isomorphic to r diVi, where di = dim Vi.\ni=1\ni=1\nThen by Proposition 2.2, B = iBi. On the other hand, (i) implies that Bi = End(Vi). Thus (ii)\nfollows.\n2.3\nRepresentations of direct sums of matrix algebras\nIn this section we consider representations of algebras A = L\ni Matdi (k) for any field k.\nTheorem 2.6. Let A = Lr\ni=1 Matdi (k). Then the irreducible representations of A are V1 =\nkd1 , . . . , Vr = kdr , and any finite dimensional representation of A is a direct sum of copies of\nV1, . . . , Vr.\nIn order to prove Theorem 2.6, we shall need the notion of a dual representation.\nDefinition 2.7. (Dual representation) Let V be a representation of any algebra A. Then the\ndual representation V ⊕ is the representation of the opposite algebra Aop (or, equivalently, right\nA-module) with the action\n(f\na)(v) := f(av).\n·\nProof of Theorem 2.6. First, the given representations are clearly irreducible, as for any v = 0, w 2\n⇒\nVi, there exists a 2 A such that av = w. Next, let X be an n-dimensional representation of\nA. Then, X⊕ is an n-dimensional representation of Aop. But (Matdi (k))op = Matdi (k) with\n∪\nisomorphism '(X) = XT , as (BC)T = CT BT .\n= Aop\nThus, A ∪\nand X⊕ may be viewed as an\nn-dimensional representation of A. Define\nθ : A · · · A -⊃ X⊕\nn copies\n\nby\nθ(a1, . . . , an) = a1y1 +\n+ anyn\n· · ·\nwhere {yi} is a basis of X⊕. θ is clearly surjective, as k\nA. Thus, the dual map θ⊕ : X -⊃ An⊕\n→\nis injective. But An⊕ ∪= An as representations of A (check it!). Hence, Im θ⊕ ∪= X is a subrepresen\ntation of An . Next, Matdi (k) = diVi, so A = r\ni=1diVi, An = r\ni=1ndiVi, as a representation of A.\nHence by Proposition 2.2, X = i\nr\n=1miVi, as desired.\nExercise. The goal of this exercise is to give an alternative proof of Theorem 2.6, not using\nany of the previous results of Chapter 2.\nLet A1, A2, ..., An be n algebras with units 11, 12, ..., 1n, respectively. Let A = A1 A2 ...An.\nClearly, 1i1j = ζij1i, and the unit of A is 1 = 11 + 12 + ... + 1n.\nFor every representation V of A, it is easy to see that 1iV is a representation of Ai for every\ni 2 {1, 2, ..., n}. Conversely, if V1, V2, ..., Vn are representations of A1, A2, ..., An, respectively,\nthen V1 V2 ... Vn canonically becomes a representation of A (with (a1, a2, ..., an) 2 A acting\non V1 V2 ... Vn as (v1, v2, ..., vn) 7⊃ (a1v1, a2v2, ..., anvn)).\n(a) Show that a representation V of A is irreducible if and only if 1iV is an irreducible repre\nsentation of Ai for exactly one i 2 {1, 2, ..., n}, while 1iV = 0 for all the other i. Thus, classify the\nirreducible representations of A in terms of those of A1, A2, ..., An.\n(b) Let d 2 N. Show that the only irreducible representation of Matd(k) is kd, and every finite\ndimensional representation of Matd(k) is a direct sum of copies of kd .\nHint: For every (i, j) 2 {1, 2, ..., d} 2, let Eij 2 Matd(k) be the matrix with 1 in the ith row of the\njth column and 0's everywhere else. Let V be a finite dimensional representation of Matd(k). Show\nthat V = E11V E22V ... EddV , and that i : E11V ⊃ EiiV , v 7⊃ Ei1v is an isomorphism for\nevery i 2 {1, 2, ..., d}. For every v 2 E11V , denote S (v) = *E11v, E21v, ..., Ed1vi. Prove that S (v)\nis a subrepresentation of V isomorphic to kd (as a representation of Matd(k)), and that v 2 S (v).\nConclude that V = S (v1) S (v2) ... S (vk), where {v1, v2, ..., vk} is a basis of E11V .\n(c) Conclude Theorem 2.6.\n2.4\nFiltrations\nLet A be an algebra. Let V be a representation of A. A (finite) filtration of V is a sequence of\nsubrepresentations 0 = V0\nV1\n...\nVn = V .\n→\n→\n→\nLemma 2.8. Any finite dimensional representation V of an algebra A admits a finite filtration\n0 = V0\nV1\n...\nVn = V such that the successive quotients Vi/Vi-1 are irreducible.\n→\n→\n→\nProof. The proof is by induction in dim(V ). The base is clear, and only the induction step needs\nto be justified. Pick an irreducible subrepresentation V1\nV , and consider the representation\n→\nU = V/V1. Then by the induction assumption U has a filtration 0 = U0\nU1\n...\nUn-1 = U\n→\n→\n→\nsuch that Ui/Ui-1 are irreducible. Define Vi for i ⊂ 2 to be the preimages of Ui-1 under the\ntautological projection V ⊃ V/V1 = U. Then 0 = V0\nV1\nV2\n...\nVn = V is a filtration of V\n→\n→\n→\n→\nwith the desired property.\n\n2.5\nFinite dimensional algebras\nDefinition 2.9. The radical of a finite dimensional algebra A is the set of all elements of A which\nact by 0 in all irreducible representations of A. It is denoted Rad(A).\nProposition 2.10. Rad(A) is a two-sided ideal.\nProof. Easy.\nProposition 2.11. Let A be a finite dimensional algebra.\n(i) Let I be a nilpotent two-sided ideal in A, i.e., I n = 0 for some n. Then I\nRad(A).\n→\n(ii) Rad(A) is a nilpotent ideal. Thus, Rad(A) is the largest nilpotent two-sided ideal in A.\nProof. (i) Let V be an irreducible representation of A. Let v 2 V . Then Iv\nV is a subrepresen\nn\n→\ntation. If Iv = 0 then Iv = V so there is x 2 I such that xv = v. Then x\n= 0, a contradiction.\n⇒\n⇒\nThus Iv = 0, so I acts by 0 in V and hence I\nRad(A).\n→\n(ii) Let 0 = A0\nA1\n...\nAn = A be a filtration of the regular representation of A by\n→\n→\n→\nsubrepresentations such that Ai+1/Ai are irreducible. It exists by Lemma 2.8. Let x 2 Rad(A).\nThen x acts on Ai+1/Ai by zero, so x maps Ai+1 to Ai. This implies that Rad(A)n = 0, as\ndesired.\nTheorem 2.12. A finite dimensional algebra A has only finitely many irreducible representations\nVi up to isomorphism, these representations are finite dimensional, and\nA/Rad(A) ∪M\nEnd Vi.\n=\ni\nProof. First, for any irreducible representation V of A, and for any nonzero v 2 V , Av ∧ V is a\nfinite dimensional subrepresentation of V . (It is finite dimensional as A is finite dimensional.) As\nV is irreducible and Av = 0, V = Av and V is finite dimensional.\n⇒\nNext, suppose we have non-isomorphic irreducible representations V1, V2, . . . , Vr. By Theorem\n2.5, the homomorphism\nM\nδi : A -⊃\nM\nEnd Vi\ni\ni\nis surjective. So r ∗ ⎨\ni dim End Vi ∗ dim A. Thus, A has only finitely many non-isomorphic\nirreducible representations (at most dim A).\nNow, let V1, V2, . . . , Vr be all non-isomorphic irreducible finite dimensional representations of\nA. By Theorem 2.5, the homomorphism\nM\nδi : A -⊃\nM\nEnd Vi\ni\ni\nis surjective. The kernel of this map, by definition, is exactly Rad(A).\nCorollary 2.13. ⎨\ni (dim Vi)2 ∗ dim A, where the Vi's are the irreducible representations of A.\nProof. As dim End Vi = (dim Vi)2, Theorem 2.12 implies that dim A-dim Rad(A) = ⎨dim End Vi =\n⎨(dim Vi)2 . As dim Rad(A) ⊂ 0, ⎨(dim Vi)2 ∗ dim A.\ni\ni\ni\n\nExample 2.14. 1. Let A = k[x]/(xn). This algebra has a unique irreducible representation, which\nis a 1-dimensional space k, in which x acts by zero. So the radical Rad(A) is the ideal (x).\n2. Let A be the algebra of upper triangular n by n matrices. It is easy to check that the\nirreducible representations of A are Vi, i = 1, ..., n, which are 1-dimensional, and any matrix x acts\nby xii. So the radical Rad(A) is the ideal of strictly upper triangular matrices (as it is a nilpotent\nideal and contains the radical). A similar result holds for block-triangular matrices.\nDefinition 2.15. A finite dimensional algebra A is said to be semisimple if Rad(A) = 0.\nProposition 2.16. For a finite dimensional algebra A, the following are equivalent:\n1. A is semisimple.\n2. ⎨\ni (dim Vi)2 = dim A, where the Vi's are the irreducible representations of A.\n3. A ∪= L Matdi (k) for some di.\ni\n4. Any finite dimensional representation of A is completely reducible (that is, isomorphic to a\ndirect sum of irreducible representations).\n5. A is a completely reducible representation of A.\nProof. As dim A-dim Rad(A) = ⎨(dim Vi)2, clearly dim A = ⎨(dim Vi)2 if and only if Rad(A) =\ni\ni\n0. Thus, (1) ⊆ (2).\nNext, by Theorem 2.12, if Rad(A) =\n=\ni Matdi (k) for di = dim Vi. Thus,\n0, then clearly A ∪L\n(1) ≥ (3). Conversely, if A ∪= L Matdi (k), then by Theorem 2.6, Rad(A) = 0, so A is semisimple.\ni\nThus (3) ≥ (1).\nNext, (3) ≥ (4) by Theorem 2.6. Clearly (4) ≥ (5). To see that (5) ≥ (3), let A = L\ni niVi.\nConsider EndA(A) (endomorphisms of A as a representation of A). As the Vi's are pairwise non-\nisomorphic, by Schur's lemma, no copy of Vi in A can be mapped to a distinct Vj . Also, again by\nSchur's lemma, EndA (Vi) = k. Thus, EndA(A) ∪\nMatni\n= Aop by Problem\n= L\n(k). But EndA(A) ∪\n=\nL\n(k). Thus, A ∪\nMatni\ni\nMatni\n1.22, so Aop ∪\nMatni\n= (L\n(k))op = L\n(k), as desired.\ni\ni\ni\n2.6\nCharacters of representations\nLet A be an algebra and V a finite-dimensional representation of A with action δ. Then the\ncharacter of V is the linear function νV : A ⊃ k given by\nνV (a) = tr V (δ(a)).\n|\nIf [A, A] is the span of commutators [x, y] := xy - yx over all x, y 2 A, then [A, A] ∧ ker νV . Thus,\nwe may view the character as a mapping νV : A/[A, A] ⊃ k.\nExercise. Show that if W\nV are finite dimensional representations of A, then νV = νW +\n→\nνV/W .\nTheorem 2.17. (i) Characters of (distinct) irreducible finite-dimensional representations of A are\nlinearly independent.\n(ii) If A is a finite-dimensional semisimple algebra, then these characters form a basis of\n(A/[A, A])⊕.\n\nProof. (i) If V1, . . . , Vr are nonisomorphic irreducible finite-dimensional representations of A, then\nδV1 · · · δVr : A ⊃ End V1 · · · End Vr is surjective by the density theorem, so νV1 , . . . , νVr are\nlinearly independent. (Indeed, if ⎨ ∂iνVi (a) = 0 for all a 2 A, then ⎨ ∂iTr(Mi) = 0 for all Mi 2\nEndkVi. But each tr(Mi) can range independently over k, so it must be that ∂1 =\n= ∂r = 0.)\n· · ·\n(ii) First we prove that [Matd(k), Matd(k)] = sld(k), the set of all matrices with trace 0. It is\nclear that [Matd(k), Matd(k)] ∧ sld(k). If we denote by Eij the matrix with 1 in the ith row of the\njth column and 0's everywhere else, we have [Eij , Ejm] = Eim for i = m, and [Ei,i+1, Ei+1,i] = Eii -\n⇒\nEi+1,i+1. Now {Eim}⊗{Eii-Ei+1,i+1} forms a basis in sld(k), so indeed [Matd(k), Matd(k)] = sld(k),\nas claimed.\nBy semisimplicity, we can write A = Matd1\n(k). Then [A, A] = sld1\n(k) · · · Matdr\n(k) · · ·\nsldr (k), and A/[A, A] ∪kr .\n=\nBy Theorem 2.6, there are exactly r irreducible representations of A\n(isomorphic to kd1 , . . . , kdr , respectively), and therefore r linearly independent characters on the\nr-dimensional vector space A/[A, A]. Thus, the characters form a basis.\n2.7\nThe Jordan-H older theorem\nWe will now state and prove two important theorems about representations of finite dimensional\nalgebras - the Jordan-H older theorem and the Krull-Schmidt theorem.\nTheorem 2.18. (Jordan-H older theorem). Let V be a finite dimensional representation of A,\nand 0 = V0\nV1\n...\nVn = V , 0 = V0\n...\nVm\n0 = V be filtrations of V , such that the\n→\n→\n→\n→\n→\nrepresentations Wi := Vi/Vi-1 and W 0 := Vi\n0/Vi\n-1 are irreducible for all i. Then n = m, and there\ni\nexists a permutation ε of 1, ..., n such that Wε(i) is isomorphic to Wi\n0.\nProof. First proof (for k of characteristic zero). The character of V obviously equals the sum\nof characters of Wi, and also the sum of characters of Wi\n0. But by Theorem 2.17, the charac\nters of irreducible representations are linearly independent, so the multiplicity of every irreducible\nrepresentation W of A among Wi and among Wi\n0 are the same. This implies the theorem. 3\nSecond proof (general). The proof is by induction on dim V . The base of induction is clear,\nso let us prove the induction step. If W1 = W1\n0 (as subspaces), we are done, since by the induction\nassumption the theorem holds for V/W1. So assume W1 = W1\n0. In this case W1 ∈ W1\n0 = 0 (as\n⇒\nW1, W 1\n0 are irreducible), so we have an embedding f : W1 W1\n0 ⊃ V . Let U = V/(W1 W1\n0), and\n0 = U0\nU1\n...\nUp = U be a filtration of U with simple quotients Zi = Ui/Ui-1 (it exists by\n→\n→\n→\nLemma 2.8). Then we see that:\n1) V/W1 has a filtration with successive quotients W1\n0, Z1, ..., Zp, and another filtration with\nsuccessive quotients W2, ...., Wn.\n2) V/W 1\n0 has a filtration with successive quotients W1, Z1, ..., Zp, and another filtration with\nsuccessive quotients W2\n0, ...., W n\n0 .\nBy the induction assumption, this means that the collection of irreducible representations with\nmultiplicities W1, W 1\n0, Z1, ..., Zp coincides on one hand with W1, ..., Wn, and on the other hand, with\nW1\n0, ..., W 0 . We are done.\nm\nThe Jordan-H older theorem shows that the number n of terms in a filtration of V with irre\nducible successive quotients does not depend on the choice of a filtration, and depends only on\n3This proof does not work in characteristic p because it only implies that the multiplicities of Wi and Wi\n⊗ are the\nsame modulo p, which is not sufficient. In fact, the character of the representation pV , where V is any representation,\nis zero.\n\nV . This number is called the length of V . It is easy to see that n is also the maximal length of a\nfiltration of V in which all the inclusions are strict.\nThe sequence of the irreducible representations W1, ..., Wn enumerated in the order they appear\nfrom some filtration of V as successive quoteints is called a Jordan-H older series of V .\n2.8\nThe Krull-Schmidt theorem\nTheorem 2.19. (Krull-Schmidt theorem) Any finite dimensional representation of A can be uniquely\n(up to an isomorphism and order of summands) decomposed into a direct sum of indecomposable\nrepresentations.\nProof. It is clear that a decomposition of V into a direct sum of indecomposable representations\nexists, so we just need to prove uniqueness. We will prove it by induction on dim V . Let V =\nV1 ... Vm = V1\n0 ... V 0. Let is : Vs ⊃ V , i0 : V 0 ⊃ V , ps : V ⊃ Vs, p0 : V ⊃ V 0 be the natural\nn\ns\ns\ns\ns\nmaps associated to these decompositions. Let χs = p1i p i1 : V1 ⊃ V1. We have ⎨n\nχs = 1. Now\ns s\ns=1\nwe need the following lemma.\nLemma 2.20. Let W be a finite dimensional indecomposable representation of A. Then\n(i) Any homomorphism χ : W ⊃ W is either an isomorphism or nilpotent;\n(ii) If χs : W ⊃ W , s = 1, ..., n are nilpotent homomorphisms, then so is χ := χ1 + ... + χn.\nProof. (i) Generalized eigenspaces of χ are subrepresentations of W , and W is their direct sum.\nThus, χ can have only one eigenvalue ∂. If ∂ is zero, χ is nilpotent, otherwise it is an isomorphism.\n(ii) The proof is by induction in n. The base is clear. To make the induction step (n - 1 to n),\nassume that χ is not nilpotent. Then by (i) χ is an isomorphism, so ⎨n\ni=1 χ-1χi = 1. The morphisms\nχ-1χi are not isomorphisms, so they are nilpotent. Thus 1 - χ-1χn = χ-1χ1 + ... + χ-1χn-1 is an\nisomorphism, which is a contradiction with the induction assumption.\nBy the lemma, we find that for some s, χs must be an isomorphism; we may assume that\ns = 1. In this case, V1\n0 = Im(p1\n0 i1) Ker(p1i1\n0 ), so since V1\n0 is indecomposable, we get that\nf := p0\n1i1 : V1 ⊃ V1\n0 and g := p1i1\n0 : V1\n0 ⊃ V1 are isomorphisms.\nLet B = j>1Vj , B0 = j>1Vj\n0; then we have V = V1 B = V1\n0 B0. Consider the map\nh : B ⊃ B0 defined as a composition of the natural maps B ⊃ V ⊃ B0 attached to these\ndecompositions. We claim that h is an isomorphism. To show this, it suffices to show that Kerh = 0\n(as h is a map between spaces of the same dimension). Assume that v 2 Kerh\nB. Then v 2 V1\n0.\n→\nOn the other hand, the projection of v to V1 is zero, so gv = 0. Since g is an isomorphism, we get\nv = 0, as desired.\nNow by the induction assumption, m = n, and Vj ∪= Vε\n(j) for some permutation ε of 2, ..., n.\nThe theorem is proved.\nExercise. Let A be the algebra of real-valued continuous functions on R which are periodic\nwith period 1. Let M be the A-module of continuous functions f on R which are antiperiodic with\nperiod 1, i.e., f(x + 1) = -f(x).\n(i) Show that A and M are indecomposable A-modules.\n(ii) Show that A is not isomorphic to M but A A is isomorphic to M M.\n\nRemark. Thus, we see that in general, the Krull-Schmidt theorem fails for infinite dimensional\nmodules. However, it still holds for modules of finite length, i.e., modules M such that any filtration\nof M has length bounded above by a certain constant l = l(M).\n2.9\nProblems\nProblem 2.21. Extensions of representations. Let A be an algebra, and V, W be a pair of\nrepresentations of A. We would like to classify representations U of A such that V is a subrepre\nsentation of U, and U/V = W . Of course, there is an obvious example U = V W , but are there\nany others?\nSuppose we have a representation U as above. As a vector space, it can be (non-uniquely)\nidentified with V W , so that for any a 2 A the corresponding operator δU (a) has block triangular\nform\nδV (a)\nf(a)\nδU (a) =\n,\nδW (a)\nwhere f : A ⊃ Homk(W, V ) is a linear map.\n(a) What is the necessary and sufficient condition on f(a) under which δU (a) is a repre\nsentation? Maps f satisfying this condition are called (1-)cocycles (of A with coefficients in\nHomk(W, V )). They form a vector space denoted Z 1(W, V ).\n(b) Let X : W ⊃ V be a linear map. The coboundary of X, dX, is defined to be the function A ⊃\nHomk(W, V ) given by dX(a) = δV (a)X -XδW (a). Show that dX is a cocycle, which vanishes if and\nonly if X is a homomorphism of representations. Thus coboundaries form a subspace B 1(W, V )\nZ1(W, V ), which is isomorphic to Homk(W, V )/HomA(W, V ). The quotient Z1(W, V )/B1(W, V )\n→\nis\ndenoted Ext1(W, V ).\n(c) Show that if f, f 0 2 Z1(W, V ) and f - f 0 2 B1(W, V ) then the corresponding extensions\nU, U 0 are isomorphic representations of A. Conversely, if θ : U ⊃ U 0 is an isomorphism such that\nθ(a) =\n1V\n∼\n1W\nthen f - f 0 2 B1(V, W ). Thus, the space Ext1(W, V ) \"classifies\" extensions of W by V .\n(d) Assume that W, V are finite dimensional irreducible representations of A. For any f\nExt1(W, V ), let Uf be the corresponding extension. Show that Uf is isomorphic to Uf⊗ as repre\nsentations if and only if f and f 0 are proportional. Thus isomorphism classes (as representations)\nof nontrivial extensions of W by V (i.e., those not isomorphic to W V ) are parametrized by the\nprojective space PExt1(W, V ). In particular, every extension is trivial if and only if Ext1(W, V ) = 0.\nProblem 2.22. (a) Let A = C[x1, ..., xn], and Va, Vb be one-dimensional representations in which\nxi act by ai and bi, respectively (ai, bi 2 C). Find Ext1(Va, Vb) and classify 2-dimensional repre\nsentations of A.\n(b) Let B be the algebra over C generated by x1, ..., xn with the defining relations xixj = 0 for\nall i, j. Show that for n > 1 the algebra B has infinitely many non-isomorphic indecomposable\nrepresentations.\nProblem 2.23. Let Q be a quiver without oriented cycles, and PQ the path algebra of Q. Find\nirreducible representations of PQ and compute Ext1 between them. Classify 2-dimensional repre\nsentations of PQ.\n\nProblem 2.24. Let A be an algebra, and V a representation of A. Let δ : A ⊃ EndV . A formal\ndeformation of V is a formal series\nδ = δ0 + tδ1 + ... + tnδn + ...,\nwhere δi : A ⊃ End(V ) are linear maps, δ0 = δ, and δ (ab) = δ (a) δ(b).\nIf b(t) = 1 + b1t + b2t2 + ..., where bi 2 End(V ), and\nδb-1\nδ is a formal deformation of δ, then b\nis also a deformation of δ, which is said to be isomorphic to δ .\n(a) Show that if Ext1(V, V ) = 0, then any deformation of δ is trivial, i.e., isomorphic to δ.\n(b) Is the converse to (a) true? (consider the algebra of dual numbers A = k[x]/x2).\nProblem 2.25. The Clifford algebra. Let V be a finite dimensional complex vector space\nequipped with a symmetric bilinear form (, ). The Clifford algebra Cl(V ) is the quotient of the\ntensor algebra TV by the ideal generated by the elements v\nv - (v, v)1, v 2 V . More explicitly, if\nxi, 1 ∗ i ∗ N is a basis of V and (xi, xj ) = aij then Cl(V ) is generated by xi with defining relations\nxixj + xjxi = 2aij , x i\n2 = aii.\nThus, if (, ) = 0, Cl(V ) = √V .\n(i) Show that if (, ) is nondegenerate then Cl(V ) is semisimple, and has one irreducible repre\nsentation of dimension 2n if dim V = 2n (so in this case Cl(V ) is a matrix algebra), and two such\nrepresentations if dim(V ) = 2n +1 (i.e., in this case Cl(V ) is a direct sum of two matrix algebras).\nHint. In the even case, pick a basis a1, ..., an, b1, ..., bn of V in which (ai, aj ) = (bi, bj ) = 0,\n(ai, bj ) = ζij /2, and construct a representation of Cl(V ) on S := √(a1, ..., an) in which bi acts as\n\"differentiation\" with respect to ai. Show that S is irreducible. In the odd case the situation is\nsimilar, except there should be an additional basis vector c such that (c, ai) = (c, bi) = 0, (c, c) =\n1, and the action of c on S may be defined either by (-1)degree or by (-1)degree+1, giving two\nrepresentations S+, S\n(why are they non-isomorphic?). Show that there is no other irreducible\n-\nrepresentations by finding a spanning set of Cl(V ) with 2dim V elements.\n(ii) Show that Cl(V ) is semisimple if and only if (, ) is nondegenerate. If (, ) is degenerate, what\nis Cl(V )/Rad(Cl(V ))?\n2.10\nRepresentations of tensor products\nLet A, B be algebras. Then A\nB is also an algebra, with multiplication (a1\nb1)(a2\nb2) =\na1a2\nb1b2.\nExercise. Show that Matm(k)\nMatn\n= Matmn(k).\n(k) ∪\nThe following theorem describes irreducible finite dimensional representations of A\nB in terms\nof irreducible finite dimensional representations of A and those of B.\nTheorem 2.26. (i) Let V be an irreducible finite dimensional representation of A and W an\nirreducible finite dimensional representation of B. Then V\nW is an irreducible representation of\nA\nB.\n(ii) Any irreducible finite dimensional representation M of A\nB has the form (i) for unique\nV and W .\nRemark 2.27. Part (ii) of the theorem typically fails for infinite dimensional representations;\ne.g. it fails when A is the Weyl algebra in characteristic zero. Part (i) also may fail. E.g. let\nA = B = V = W = C(x). Then (i) fails, as A\nB is not a field.\n\nProof. (i) By the density theorem, the maps A ⊃ End V and B ⊃ End W are surjective. Therefore,\nthe map A\nB ⊃ End V\nEnd W = End(V\nW ) is surjective. Thus, V\nW is irreducible.\n(ii) First we show the existence of V and W . Let A0, B0 be the images of A, B in End M. Then\nA0, B0 are finite dimensional algebras, and M is a representation of A0\nB0, so we may assume\nwithout loss of generality that A and B are finite dimensional.\nIn this case, we claim that Rad(A\nB) = Rad(A)\nB + A\nRad(B). Indeed, denote the latter\nby J. Then J is a nilpotent ideal in A\nB, as Rad(A) and Rad(B) are nilpotent. On the other\nhand, (A\nB)/J = (A/Rad(A))\n(B/Rad(B)), which is a product of two semisimple algebras,\nhence semisimple. This implies J ∩ Rad(A\nB). Altogether, by Proposition 2.11, we see that\nJ = Rad(A\nB), proving the claim.\nThus, we see that\n(A\nB)/Rad(A\nB) = A/Rad(A)\nB/Rad(B).\nNow, M is an irreducible representation of (A\nB)/Rad(A\nB), so it is clearly of the form\nM = V\nW , where V is an irreducible representation of A/Rad(A) and W is an irreducible\nrepresentation of B/Rad(B), and V, W are uniquely determined by M (as all of the algebras\ninvolved are direct sums of matrix algebras).\n\nRepresentations of finite groups: basic results\nRecall that a representation of a group G over a field k is a k-vector space V together with a\ngroup homomorphism δ : G ⊃ GL(V ). As we have explained above, a representation of a group G\nover k is the same thing as a representation of its group algebra k[G].\nIn this section, we begin a systematic development of representation theory of finite groups.\n3.1\nMaschke's Theorem\nTheorem 3.1. (Maschke) Let G be a finite group and k a field whose characteristic does not divide\n|G|. Then:\n(i) The algebra k[G] is semisimple.\n(ii) There is an isomorphism of algebras ξ : k[G] ⊃iEndVi defined by g 7⊃ ig|\n, where Vi\nVi\nare the irreducible representations of G. In particular, this is an isomorphism of representations\nof G (where G acts on both sides by left multiplication). Hence, the regular representation k[G]\ndecomposes into irreducibles as i dim(Vi)Vi, and one has\nG =\nX\ndim(Vi)2 .\n| |\ni\n(the \"sum of squares formula\").\nProof. By Proposition 2.16, (i) implies (ii), and to prove (i), it is sufficient to show that if V is\na finite-dimensional representation of G and W\nV is any subrepresentation, then there exists a\n→\nsubrepresentation W 0\nV such that V = W W 0 as representations.\n→\nChoose any complement Wˆ of W in V . (Thus V = W Wˆ as vector spaces, but not necessarily\nas representations.) Let P be the projection along Wˆ onto W , i.e., the operator on V defined by\nP |W = Id and P |Wˆ = 0. Let\nP :=\nX\nδ(g)Pδ(g-1),\n|G| g2G\nwhere δ(g) is the action of g on V , and let\nW 0 = ker P.\nNow P |W = Id and P (V ) ∧ W , so P = P , so P is a projection along W 0. Thus, V = W W 0 as\nvector spaces.\nMoreover, for any h 2 G and any y 2 W 0,\nPδ(h)y =\n1 X\nδ(g)Pδ(g-1h)y =\n1 X\nδ(hσ)Pδ(σ-1)y = δ(h)P y = 0,\n|G| g2G\n|G| φ2G\nso δ(h)y 2 ker P = W 0. Thus, W 0 is invariant under the action of G and is therefore a subrepre\nsentation of V . Thus, V = W W 0 is the desired decomposition into subrepresentations.\nThe converse to Theorem 3.1(i) also holds.\nProposition 3.2. If k[G] is semisimple, then the characteristic of k does not divide G .\n| |\n\nProof. Write k[G] = Lr\ni=1 End Vi, where the Vi are irreducible representations and V1 = k is the\ntrivial one-dimensional representation. Then\nr\nr\nk[G] = k\nM\nEnd Vi = k\nM\ndiVi,\ni=2\ni=2\nwhere di = dim Vi. By Schur's Lemma,\nHomk[G](k, k[G]) = kΓ\nHomk[G](k[G], k) = kφ,\nfor nonzero homomorphisms of representations φ : k[G] ⊃ k and Γ : k ⊃ k[G] unique up to scaling.\nWe can take φ such that φ(g) = 1 for all g 2 G, and Γ such that Γ(1) = ⎨\ng2G g. Then\nφ inf Γ(1) = φ\nX\ng\n\n=\nX\n1 = |G|.\ng2G\ng2G\nIf |G| = 0, then Γ has no left inverse, as (aφ) inf Γ(1) = 0 for any a 2 k. This is a contradiction.\nExample 3.3. If G = Z/pZ and k has characteristic p, then every irreducible representation of G\nover k is trivial (so k[Z/pZ] indeed is not semisimple). Indeed, an irreducible representation of this\ngroup is a 1-dimensional space, on which the generator acts by a p-th root of unity, and every p-th\nroot of unity in k equals 1, as xp - 1 = (x - 1)p over k.\nProblem 3.4. Let G be a group of order pn . Show that every irreducible representation of G over\na field k of characteristic p is trivial.\n3.2\nCharacters\nIf V is a finite-dimensional representation of a finite group G, then its character νV : G ⊃ k\nis defined by the formula νV (g) = tr V (δ(g)). Obviously, νV (g) is simply the restriction of the\n|\ncharacter νV (a) of V as a representation of the algebra A = k[G] to the basis G\nA, so it carries\n→\nexactly the same information. The character is a central or class function: νV (g) depends only on\nthe conjugacy class of g; i.e., νV (hgh-1) = νV (g).\nTheorem 3.5. If the characteristic of k does not divide G , characters of irreducible representa\n| |\ntions of G form a basis in the space Fc(G, k) of class functions on G.\nProof. By the Maschke theorem, k[G] is semisimple, so by Theorem 2.17, the characters are linearly\nindependent and are a basis of (A/[A, A])⊕, where A = k[G]. It suffices to note that, as vector\nspaces over k,\n(A/[A, A])⊕ ∪\n| gh - hg 2 ker ' ⊕g, h 2 G}\n= {' 2 Homk(k[G], k)\n= {f 2 Fun(G, k) f(gh) = f(hg) ⊕g, h 2 G},\n∪\n|\nwhich is precisely Fc(G, k).\nCorollary 3.6. The number of isomorphism classes of irreducible representations of G equals the\nnumber of conjugacy classes of G (if G = 0 in k).\n| | ⇒\n\nExercise. Show that if G = 0 in k then the number of isomorphism classes of irreducible\n| |\nrepresentations of G over k is strictly less than the number of conjugacy classes in G.\nHint. Let P = ⎨\ng2G g 2 k[G]. Then P 2 = 0. So P has zero trace in every finite dimensional\nrepresentation of G over k.\nCorollary 3.7. Any representation of G is determined by its character if k has characteristic 0;\nnamely, νV = νW implies V ∪= W .\n3.3\nExamples\nThe following are examples of representations of finite groups over C.\n1. Finite abelian groups G = Zn1 × · · · × Znk . Let G∗ be the set of irreducible representations\nof G. Every element of G forms a conjugacy class, so G∗= G . Recall that all irreducible\n|\n|\n| |\nrepresentations over C (and algebraically closed fields in general) of commutative algebras and\ngroups are one-dimensional. Thus, G∗ is an abelian group: if δ1, δ2 : G ⊃ C× are irreducible\nrepresentations then so are δ1(g)δ2(g) and δ1(g)-1 . G∗ is called the dual or character group\nof G.\nFor given n ⊂ 1, define δ : Zn ⊃ C× by δ(m) = e2νim/n. Then Z∗\nn = {δk : k = 0, . . . , n - 1},\nso Z∗= Zn. In general,\nn ∪\n(G1 × G2 × · · · × Gn)∗ = G1\n∗× G∗\n2 × · · · × G∗\nn ,\nso G∗ = G for any finite abelian group G. This isomorphism is, however, noncanonical:\n∪\nthe particular decomposition of G as Zn1\nis not unique as far as which elements\n× · · · × Znk\nof G correspond to Zn1 , etc. is concerned. On the other hand, G ∪(G∗)∗ is a canonical\n=\nisomorphism, given by ' : G ⊃ (G∗)∗, where '(g)(ν) = ν(g).\n2. The symmetric group S3. In Sn, conjugacy classes are determined by cycle decomposition\nsizes: two permutations are conjugate if and only if they have the same number of cycles\nof each length. For S3, there are 3 conjugacy classes, so there are 3 different irreducible\nrepresentations over C. If their dimensions are d1, d2, d3, then d1\n2 +d2\n2 +d3\n2 = 6, so S3 must have\ntwo 1-dimensional and one 2-dimensional representations. The 1-dimensional representations\nare the trivial representation C+ given by δ(ε) = 1 and the sign representation C\ngiven by\nδ(ε) = (-1)ε .\n-\nThe 2-dimensional representation can be visualized as representing the symmetries of the\nequilateral triangle with vertices 1, 2, 3 at the points (cos 120∨, sin 120∨), (cos 240∨, sin 240∨),\n(1, 0) of the coordinate plane, respectively. Thus, for example,\ncos 120∨ - sin 120∨\nδ((12)) =\n,\nδ((123)) =\n.\n0 -1\nsin 120∨\ncos 120∨\nTo show that this representation is irreducible, consider any subrepresentation V . V must be\nthe span of a subset of the eigenvectors of δ((12)), which are the nonzero multiples of (1, 0)\nand (0, 1). V must also be the span of a subset of the eigenvectors of δ((123)), which are\ndifferent vectors. Thus, V must be either C2 or 0.\n3. The quaternion group Q8 = {±1, ±i, ±j, ±k}, with defining relations\ni = jk = -kj,\nj = ki = -ik,\nk = ij = -ji,\n-1 = i2 = j2 = k2 .\n\nThe 5 conjugacy classes are {1}, {-1}, {±i}, {±j}, {±k}, so there are 5 different irreducible\nrepresentations, the sum of the squares of whose dimensions is 8, so their dimensions must\nbe 1, 1, 1, 1, and 2.\nThe center Z(Q8) is {±1}, and Q8/Z(Q8) ∪Z2 × Z2. The four 1-dimensional irreducible\n=\nrepresentations of Z2 × Z2 can be \"pulled back\" to Q8. That is, if q : Q8 ⊃ Q8/Z(Q8) is the\nquotient map, and δ any representation of Q8/Z(Q8), then δ inf q gives a representation of Q8.\nThe 2-dimensional representation is V = C2, given by δ(-1) = -Id and\n\n-\n∀-1\n-∀0\n-1\n\n-∀0\n-1\n-∀-1\nδ(i) =\n,\nδ(j) =\n,\nδ(k) =\n.\n(3)\nThese are the Pauli matrices, which arise in quantum mechanics.\nExercise. Show that the 2-dimensional irreducible representation of Q8 can be realized in\nthe space of functions f : Q8 ⊃ C such that f(gi) = ∀-1f(g) (the action of G is by right\nmultiplication, g inf f(x) = f(xg)).\n4. The symmetric group S4.\nThe order of S4 is 24, and there are 5 conjugacy classes:\ne, (12), (123), (1234), (12)(34). Thus the sum of the squares of the dimensions of 5 irreducible\nrepresentations is 24. As with S3, there are two of dimension 1: the trivial and sign repre\nsentations, C+ and C-. The other three must then have dimensions 2, 3, and 3. Because\n= S4/Z2 × Z2, where Z2 × Z2 is {e, (12)(34), (13)(24), (14)(23)}, the 2-dimensional repre\nS3 ∪\nsentation of S3 can be pulled back to the 2-dimensional representation of S4, which we will\ncall C2 .\nWe can consider S4 as the group of rotations of a cube acting by permuting the interior\ndiagonals (or, equivalently, on a regular octahedron permuting pairs of opposite faces); this\ngives the 3-dimensional representation C3\n+.\nThe last 3-dimensional representation is C3 , the product of C3 with the sign representation.\n-\n+\nC3 and C3 are different, for if g is a transposition, det g\n= 1 while det g\n= (-1)3\n+\n-\n= -1.\n|\n|\n+\nC\nC-\nNote that another realization of C3\n- is by action of S4 by symmetries (not necessarily rotations)\nof the regular tetrahedron. Yet another realization of this representation is the space of\nfunctions on the set of 4 elements (on which S4 acts by permutations) with zero sum of\nvalues.\n3.4\nDuals and tensor products of representations\nIf V is a representation of a group G, then V ⊕ is also a representation, via\nδV (g) = (δV (g)⊕)-1 = (δV (g)-1)⊕ = δV (g-1)⊕.\nThe character is νV (g) = νV (g-1).\nWe have νV (g) = ⎨ ∂i, where the ∂i are the eigenvalues of g in V . These eigenvalues must be\nroots of unity because δ(g)|G| = δ(g|G|) = δ(e) = Id. Thus for complex representations\nνV (g) = νV (g-1) =\nX\n∂-\ni\n1 =\nX\n∂i =\nX\n∂i = νV (g).\nIn particular, V ∪= V ⊕ as representations (not just as vector spaces) if and only if νV (g) 2 R for all\ng 2 G.\n\nIf V, W are representations of G, then V\nW is also a representation, via\nδV\nW (g) = δV (g)\nδW (g).\nTherefore, νV\nW (g) = νV (g)νW (g).\nAn interesting problem discussed below is to decompose V\nW (for irreducible V, W ) into the\ndirect sum of irreducible representations.\n3.5\nOrthogonality of characters\nWe define a positive definite Hermitian inner product on Fc(G, C) (the space of central functions)\nby\n(f1, f2) = 1 X\nf1(g)f2(g).\n|G| g2G\nThe following theorem says that characters of irreducible representations of G form an orthonormal\nbasis of Fc(G, C) under this inner product.\nTheorem 3.8. For any representations V, W\n(νV , νW ) = dim HomG(W, V ),\nand\n1, if V ∪= W,\n(νV , νW ) =\n0, if V W\nif V, W are irreducible.\nProof. By the definition\n(νV , νW )\n=\n1 X\nνV (g)νW (g) = 1 X\nνV (g)νW (g)\n|G| g2G\n|G| g2G\n=\n1 X\nνV\nW (g) = Tr V\nW (P ),\n|G| g2G\n|\nwhere P = |G|\n⎨\ng2G g 2 Z(C[G]). (Here Z(C[G]) denotes the center of C[G]). If X is an irreducible\nrepresentation of G then\nId, if X = C,\nP X =\n|\n0, X = C.\n⇒\nTherefore, for any representation X the operator P X is the G-invariant projector onto the subspace\n|\nXG of G-invariants in X. Thus,\nTr |V\nW (P ) = dim HomG(C, V\nW ⊕)\n= dim(V\nW ⊕)G = dim HomG(W, V ).\n\nTheorem 3.8 gives a powerful method of checking if a given complex representation V of a finite\ngroup G is irreducible. Indeed, it implies that V is irreducible if and only if (νV , νV ) = 1.\nExercise. Let G be a finite group. Let Vi be the irreducible complex representations of G.\nFor every i, let\nξi = dim Vi X\nνVi (g) g-1 2 C [G] .\n|G|\ng2G\n·\n(i) Prove that ξi acts on Vj as the identity if j = i, and as the null map if j = i.\n⇒\n(ii) Prove that ξi are idempotents, i.e., ξi\n2 = ξi for any i, and ξiξj = 0 for any i = j.\n⇒\nHint: In (i), notice that ξi commutes with any element of k [G], and thus acts on Vj as an\nintertwining operator. Corollary 1.17 thus yields that ξi acts on Vj as a scalar. Compute this\nscalar by taking its trace in Vj .\nHere is another \"orthogonality formula\" for characters, in which summation is taken over irre\nducible representations rather than group elements.\nTheorem 3.9. Let g, h 2 G, and let Zg denote the centralizer of g in G. Then\nX\nνV (g)νV (h) =\n|Zg| if g is conjugate to h\n0, otherwise\nV\nwhere the summation is taken over all irreducible representations of G.\nProof. As noted above, νV (h) = νV (h), so the left hand side equals (using Maschke's theorem):\nX\nνV (g)νV (h) = Tr|∈V V\nV (g\n(h⊕)-1) =\nV\nTr|∈V EndV (x 7⊃ gxh-1) = Tr|C[G](x 7⊃ gxh-1).\nIf g and h are not conjugate, this trace is clearly zero, since the matrix of the operator x 7⊃ gxh-1\nin the basis of group elements has zero diagonal entries. On the other hand, if g and h are in the\nsame conjugacy class, the trace is equal to the number of elements x such that x = gxh-1, i.e., the\norder of the centralizer Zg of g. We are done.\nRemark. Another proof of this result is as follows. Consider the matrix U whose rows are\nlabeled by irreducible representations of G and columns by conjugacy classes, with entries UV,g =\nνV (g)/\np\n|Zg|. Note that the conjugacy class of g is G/Zg, thus |G|/|Zg| is the number of elements\nconjugate to G. Thus, by Theorem 3.8, the rows of the matrix U are orthonormal. This means\nthat U is unitary and hence its columns are also orthonormal, which implies the statement.\n3.6\nUnitary representations. Another proof of Maschke's theorem for complex\nrepresentations\nDefinition 3.10. A unitary finite dimensional representation of a group G is a representation of G\non a complex finite dimensional vector space V over C equipped with a G-invariant positive definite\nHermitian form4 (, ), i.e., such that δV (g) are unitary operators: (δV (g)v, δV (g)w) = (v, w).\n4We agree that Hermitian forms are linear in the first argument and antilinear in the second one.\n\nTheorem 3.11. If G is finite, then any finite dimensional representation of G has a unitary\nstructure. If the representation is irreducible, this structure is unique up to scaling by a positive\nreal number.\nProof. Take any positive definite form B on V and define another form B as follows:\nB(v, w) =\nX\nB(δV (g)v, δV (g)w)\ng2G\nThen B is a positive definite Hermitian form on V, and δV (g) are unitary operators. If V is\nan irreducible representation and B1, B2 are two positive definite Hermitian forms on V, then\nB1(v, w) = B2(Av, w) for some homomorphism A : V ⊃ V (since any positive definite Hermitian\nform is nondegenerate). By Schur's lemma, A = ∂Id, and clearly ∂> 0.\nTheorem 3.11 implies that if V is a finite dimensional representation of a finite group G, then\nthe complex conjugate representation V (i.e., the same space V with the same addition and the same\naction of G, but complex conjugate action of scalars) is isomorphic to the dual representation V ⊕.\nIndeed, a homomorphism of representations V ⊃ V ⊕ is obviously the same thing as an invariant\nsesquilinear form on V (i.e. a form additive on both arguments which is linear on the first one and\nantilinear on the second one), and an isomorphism is the same thing as a nondegenerate invariant\nsesquilinear form. So one can use a unitary structure on V to define an isomorphism V ⊃ V ⊕.\nTheorem 3.12. A finite dimensional unitary representation V of any group G is completely re\nducible.\nProof. Let W be a subrepresentation of V . Let W ? be the orthogonal complement of W in V\nunder the Hermitian inner product. Then W ? is a subrepresentation of W , and V = W W ?.\nThis implies that V is completely reducible.\nTheorems 3.11 and 3.12 imply Maschke's theorem for complex representations (Theorem 3.1).\nThus, we have obtained a new proof of this theorem over the field of complex numbers.\nRemark 3.13. Theorem 3.12 shows that for infinite groups G, a finite dimensional representation\nmay fail to admit a unitary structure (as there exist finite dimensional representations, e.g. for\nG = Z, which are indecomposable but not irreducible).\n3.7\nOrthogonality of matrix elements\nLet V be an irreducible representation of a finite group G, and v1, v2, . . . , vn be an orthonormal\nbasis of V under the invariant Hermitian form. The matrix elements of V are tV (x) = (δV (x)vi, vj ).\nij\nProposition 3.14.\n(i) Matrix elements of nonisomorphic irreducible representations are orthog\nonal in Fun(G, C) under the form (f, g) = |G|\n⎨\nx2G f(x)g(x).\n(ii) (tV\ni⊗j⊗ ) = ζii⊗ ζjj⊗\nij , tV\n· dim V\nThus, matrix elements of irreducible representations of G form an orthogonal basis of Fun(G, C).\nProof. Let V and W be two irreducible representations of G. Take {vi} to be an orthonormal basis\nof V and {wi} to be an orthonormal basis of W under their positive definite invariant Hermitian\nforms. Let wi\n⊕2 W ⊕ be the linear function on W defined by taking the inner product with\n\nwi: wi\n⊕(u) = (u, wi). Then for x 2 G we have (xwi\n⊕, wj\n⊕) = (xwi, wj ). Therefore, putting P =\n1 ⎨\nx2G x, we have\n|G|\nV\nW\n(tij , ti⊗j⊗ ) = |G|-1 X\n(xvi, vj )(xwi⊗ , wj⊗ ) = |G|-1 X\n(xvi, vj )(xwi\n⊕\n⊗ , wj\n⊕\n⊗ ) = (P (vi\nwi\n⊕\n⊗ ), vj\nwj\n⊕\n⊗ )\nx2G\nx2G\nIf V = W, this is zero, since P projects to the trivial representation, which does not occur in\n⇒\nV\nW ⊕. If V = W, we need to consider (P (vi\nvi\n⊕\n⊗ ), vj\nvj\n⊕\n⊗ ). We have a G-invariant decomposition\n=\nV\nV ⊕\nC L\nC = span(\nX\nvk\nvk\n⊕)\nP\nL = spana:\nk akk =0(\nX\naklvk\nvl\n⊕),\nk,l\nand P projects to the first summand along the second one. The projection of vi\nvi\n⊕\n⊗ to C\nC L\n→\nis thus\nζii⊗\nX\nvk\nvk\n⊕\ndim V\nThis shows that\n(P (vi\nvi\n⊕\n⊗ ), vj\nvj\n⊕\n⊗ ) = ζii⊗ ζjj⊗\ndim V\nwhich finishes the proof of (i) and (ii). The last statement follows immediately from the sum of\nsquares formula.\n3.8\nCharacter tables, examples\nThe characters of all the irreducible representations of a finite group can be arranged into a char\nacter table, with conjugacy classes of elements as the columns, and characters as the rows. More\nspecifically, the first row in a character table lists representatives of conjugacy classes, the second\none the numbers of elements in the conjugacy classes, and the other rows list the values of the\ncharacters on the conjugacy classes. Due to Theorems 3.8 and 3.9 the rows and columns of a\ncharacter table are orthonormal with respect to the appropriate inner products.\nNote that in any character table, the row corresponding to the trivial representation consists\nof ones, and the column corresponding to the neutral element consists of the dimensions of the\nrepresentations.\nS3\nId\n(12)\n(123)\n#\nHere is, for example, the character table of S3 : C+\nC\n-1\n-\nC2\n-1\nIt is obtained by explicitly computing traces in the irreducible representations.\nFor another example consider A4, the group of even permutations of 4 items. There are three\none-dimensional representations (as A4 has a normal subgroup Z2 Z2, and A4/Z2 Z2 = Z3).\nSince there are four conjugacy classes in total, there is one more irreducible representation of\ndimension 3. Finally, the character table is\n\nId\n(123)\n(132)\n(12)(34)\n#\nA4\nC\nφ2\nφ\nCρ\nφ2\nφ\nCρ2\nC3\n-1\nwhere φ = exp( 2\nνi ).\nThe last row can be computed using the orthogonality of rows. Another way to compute the\nlast row is to note that C3 is the representation of A4 by rotations of the regular tetrahedron: in\nthis case (123), (132) are the rotations by 1200 and 2400 around a perpendicular to a face of the\ntetrahedron, while (12)(34) is the rotation by 1800 around an axis perpendicular to two opposite\nedges.\nExample 3.15. The following three character tables are of Q8, S4, and A5 respectively.\n(123)\n-\n--\n-+\nC+-\nC\n-1\ni\nj\nk\nQ8\n#\nC++\n-1\n-1\n-1\n-1\nC\n-1\n-1\nC2\n-2\nId\n(12)\n(12)(34)\n(1234)\n#\nS4\nC+\nC\n-1\n-1\nC2\n-1\nC3\n-1\n-1\n+\nC3\n-1\n-1\n-\nId\n(123)\n(12)(34)\n(12345)\n(13245)\nA5\n#\nC\nC3\n-1\n1+\n⊗\n+\nC3\n-1\n1-\n2⊗\n-\nC4\n-1\nC5\n-1\n1-\n⊗\n1+\n2⊗\n-1\nIndeed, the computation of the characters of the 1-dimensional representations is straightfor\nward.\nThe character of the 2-dimensional representation of Q8 is obtained from the explicit formula\n(3) for this representation, or by using the orthogonality.\nFor S4, the 2-dimensional irreducible representation is obtained from the 2-dimensional irre\nducible representation of S3 via the surjective homomorphism S4 ⊃ S3, which allows to obtain its\ncharacter from the character table of S3.\nThe character of the 3-dimensional representation C3 is computed from its geometric realization\n+\nby rotations of the cube. Namely, by rotating the cube, S4 permutes the main diagonals. Thus\n(12) is the rotation by 1800 around an axis that is perpendicular to two opposite edges, (12)(34)\n\nis the rotation by 1800 around an axis that is perpendicular to two opposite faces, (123) is the\nrotation around a main diagonal by 1200, and (1234) is the rotation by 900 around an axis that is\nperpendicular to two opposite faces; this allows us to compute the traces easily, using the fact that\nthe trace of a rotation by the angle θ in R3 is 1 + 2 cos θ.\nis found by\nNow the character of C3\n-\nC\nmultiplying the character of\nby the character of the sign representation.\n+\nC\nThis representation is denoted by\n-\nFinally, we explain how to obtain the character table of A5 (even permutations of 5 items). The\ngroup A5 is the group of rotations of the regular icosahedron. Thus it has a 3-dimensional \"rotation\nrepresentation\" C3 , in which (12)(34) is the rotation by 1800 around an axis perpendicular to two\n+\nopposite edges, (123) is the rotation by 1200 around an axis perpendicular to two opposite faces,\nand (12345), (13254) are the rotations by 720, respectively 1440, around axes going through two\nopposite vertices. The character of this representation is computed from this description in a\nstraightforward way.\nAnother representation of A5, which is also 3-dimensional, is C3 twisted by the automorphism\n+\n, except that the conjugacy classes (12345) and (13245) are interchanged.\nof A5 given by conjugation by (12) inside S5.\n. It has the\nsame character as C3\n+\nThere are two remaining irreducible representations, and by the sum of squares formula their\ndimensions are 4 and 5. So we call them C4 and C5 .\nThe representation C4 is realized on the space of functions on the set {1, 2, 3, 4, 5} with zero\nsum of values, where A5 acts by permutations (check that it is irreducible!). The character of\nthis representation is equal to the character of the 5-dimensional permutation representation minus\nthe character of the 1-dimensional trivial representation (constant functions). The former at an\nelement g equals to the number of items among 1,2,3,4,5 which are fixed by g.\nThe representation C5 is realized on the space of functions on pairs of opposite vertices of the\nicosahedron which has zero sum of values (check that it is irreducible!). The character of this\nrepresentation is computed similarly to the character of C4, or from the orthogonality formula.\n3.9\nComputing tensor product multiplicities using character tables\nCharacter tables allow us to compute the tensor product multiplicities Nij\nk using\nVi\nVj =\nX\nNij\nk Vk,\nNij\nk = (νiνj , νk)\nExample 3.16. The following tables represent computed tensor product multiplicities of irre\nC2\nC2\nS3\nC+\nC-\n-\n-\nC+\nC+\nC\nducible representations of S3, S4, and A5 respectively.\nC+\nC2\nC2\nC\nC-\nC+ C- C2\nC3\nC2\nC3\n+\nS4\nC+\nC-\nC2\nC3\n+\n-\nC+\nC+\nC\nC+\n-\nC3\n+\nC2\nC\n\n+\n-\nC\nC\nC\n\n-\n+\n-\nC-\nC3\nC -\n-\nC2\nC3\n+\nC3\nC\n\n+\n-\n-\nC\n\n+\n-\nC3\nC3\n+ C3\nC+ C\nC+ C2\n- C2\nC+ C2\nC\nC3\n\nC3\nC3\nC4\n+\nC C5 C+\nC3\n-\nC-\n-\nC\nA5\nC\nC+\nC4\nC5\nC4\nC5\nC\nC\nC+\nC3\nC3\nC4 C5\n+ C3\n+ C4 C5\n+ C3\nC\n\n+\n-\n-\n-\n-\n+ C3\n-\nC\nC4 C5\nC4 C5\nC3\nC5\nC C5 C3\n+\nC3\n+ C3\n- C C4 C5\nC3\nC C3\n2C5 C4\n2C4 2C5\nC5\n3.10\nProblems\nProblem 3.17. Let G be the group of symmetries of a regular N-gon (it has 2N elements).\n(a) Describe all irreducible complex representations of this group (consider the cases of odd and\neven N)\n(b) Let V be the 2-dimensional complex representation of G obtained by complexification of the\nstandard representation on the real plane (the plane of the polygon). Find the decomposition of\nV\nV in a direct sum of irreducible representations.\nProblem 3.18. Let G be the group of 3 by 3 matrices over Fp which are upper triangular and have\nones on the diagonal, under multiplication (its order is p3). It is called the Heisenberg group. For\nany complex number z such that zp = 1 we define a representation of G on the space V of complex\nfunctions on Fp, by\n⎧\n@\n⎝ f)(x) = f(x - 1),\n(δ\n⎧\n@\n⎝ f)(x) = z xf(x).\n(δ\n(note that zx makes sense since zp = 1).\n(a) Show that such a representation exists and is unique, and compute δ(g) for all g 2 G.\n(b) Denote this representation by Rz. Show that Rz is irreducible if and only if z = 1.\n⇒\n(c) Classify all 1-dimensional representations of G. Show that R1 decomposes into a direct sum\nof 1-dimensional representations, where each of them occurs exactly once.\n(d) Use (a)-(c) and the \"sum of squares\" formula to classify all irreducible representations of\nG.\nProblem 3.19. Let V be a finite dimensional complex vector space, and GL(V ) be the group of\ninvertible linear transformations of V . Then SnV and ΓmV (m ∗ dim(V )) are representations of\nGL(V ) in a natural way. Show that they are irreducible representations.\nHint: Choose a basis {ei} in V . Find a diagonal element H of GL(V ) such that δ(H) has\ndistinct eigenvalues. (where δ is one of the above representations). This shows that if W is a\nsubrepresentation, then it is spanned by a subset S of a basis of eigenvectors of δ(H). Use the\ninvariance of W under the operators δ(1 + Eij ) (where Eij is defined by Eij ek = ζjkei) for all i = j\n⇒\nto show that if the subset S is nonempty, it is necessarily the entire basis.\nProblem 3.20. Recall that the adjacency matrix of a graph (without multiple edges) is the matrix\nin which the ij-th entry is 1 if the vertices i and j are connected with an edge, and zero otherwise.\nLet be a finite graph whose automorphism group is nonabelian. Show that the adjacency matrix\nof must have repeated eigenvalues.\n\nProblem 3.21. Let I be the set of vertices of a regular icosahedron ( I = 12). Let Fun(I) be the\n| |\nspace of complex functions on I. Recall that the group G = A5 of even permutations of 5 items\nacts on the icosahedron, so we have a 12-dimensional representation of G on Fun(I).\n(a) Decompose this representation in a direct sum of irreducible representations (i.e., find the\nmultiplicities of occurrence of all irreducible representations).\n(b) Do the same for the representation of G on the space of functions on the set of faces and\nthe set of edges of the icosahedron.\nProblem 3.22. Let Fq be a finite field with q elements, and G be the group of nonconstant inho\nmogeneous linear transformations, x ⊃ ax + b, over Fq (i.e., a 2 F×, b 2 Fq). Find all irreducible\nq\ncomplex representations of G, and compute their characters. Compute the tensor products of irre\nducible representations.\nHint. Let V be the representation of G on the space of functions on Fq with sum of all values\nequal to zero. Show that V is an irreducible representation of G.\nProblem 3.23. Let G = SU(2) (unitary 2 by 2 matrices with determinant 1), and V = C2 the\nstandard 2-dimensional representation of SU(2). We consider V as a real representation, so it is\n4-dimensional.\n(a) Show that V is irreducible (as a real representation).\n(b) Let H be the subspace of EndR(V ) consisting of endomorphisms of V as a real representation.\nShow that H is 4-dimensional and closed under multiplication. Show that every nonzero element in\nH is invertible, i.e., H is an algebra with division.\n(c) Find a basis 1, i, j, k of H such that 1 is the unit and i2 = j2 = k2 = -1, ij = -ji = k, jk =\n-kj = i, ki = -ik = j. Thus we have that Q8 is a subgroup of the group H× of invertible elements\nof H under multiplication.\nThe algebra H is called the quaternion algebra.\n(d) For q = a+bi+cj+dk, a, b, c, d 2 R, let q = a-bi-cj-dk, and ||q||2 = qq = a2 +b2 +c2 +d2 .\nShow that q1q2 = q 2q 1, and ||q1q2|| = ||q1|| · ||q2||.\n(e) Let G be the group of quaternions of norm 1. Show that this group is isomorphic to SU(2).\n(Thus geometrically SU(2) is the 3-dimensional sphere).\n(f) Consider the action of G on the space V → H spanned by i, j, k, by x ⊃ qxq-1 , q 2 G,\nx 2 V . Since this action preserves the norm on V , we have a homomorphism h : SU(2) ⊃ SO(3),\nwhere SO(3) is the group of rotations of the three-dimensional Euclidean space. Show that this\nhomomorphism is surjective and that its kernel is {1, -1}.\nProblem 3.24. It is known that the classification of finite subgroups of SO(3) is as follows:\n1) the cyclic group Z/nZ, n ⊂ 1, generated by a rotation by 2β/n around an axis;\n2) the dihedral group Dn of order 2n, n ⊂ 2 (the group of rotational symmetries in 3-space of\na plane containing a regular n-gon5;\n3) the group of rotations of the regular tetrahedron (A4).\n4) the group of rotations of the cube or regular octahedron (S4).\n5) the group of rotations of a regular dodecahedron or icosahedron (A5).\n5A regular 2-gon is just a line segment.\n\n(a) Derive this classification.\nHint. Let G be a finite subgroup of SO(3). Consider the action of G on the unit sphere. A\npoint of the sphere preserved by some nontrivial element of G is called a pole. Show that every\nnontrivial element of G fixes a unique pair of opposite poles, and that the subgroup of G fixing a\nparticular pole P is cyclic, of some order m (called the order of P). Thus the orbit of P has n/m\nelements, where n = G . Now let P1, ..., Pk be the poles representing all the orbits of G on the set\n| |\nof poles, and m1, ..., mk be their orders. By counting nontrivial elements of G, show that\n2(1 - 1 ) =\nX\n(1 - 1 ).\nn\nmi\ni\nThen find all possible mi and n that can satisfy this equation and classify the corresponding groups.\n(b) Using this classification, classify finite subgroups of SU(2) (use the homomorphism SU(2) ⊃\nSO(3)).\nProblem 3.25. Find the characters and tensor products of irreducible complex representations of\nthe Heisenberg group from Problem 3.18.\nProblem 3.26. Let G be a finite group, and V a complex representation of G which is faithful,\ni.e., the corresponding map G ⊃ GL(V ) is injective. Show that any irreducible representation of\nG occurs inside SnV (and hence inside V\nn) for some n.\nHint. Show that there exists a vector u 2 V ⊕ whose stabilizer in G is 1. Now define the map\nSV ⊃ Fun(G, C) sending a polynomial f on V ⊕ to the function fu on G given by fu(g) = f(gu).\nShow that this map is surjective and use this to deduce the desired result.\nProblem 3.27. This problem is about an application of representation theory to physics (elasticity\ntheory). We first describe the physical motivation and then state the mathematical problem.\nImagine a material which occupies a certain region U in the physical space V = R3 (a space\nwith a positive definite inner product). Suppose the material is deformed. This means, we have\napplied a diffeomorphism (=change of coordinates) g : U ⊃ U 0. The question in elasticity theory\nis how much stress in the material this deformation will cause.\nFor every point P 2 U, let AP : V ⊃ V be defined by AP = dg(P ). AP is nondegenerate,\nso it has a polar decomposition AP = DP OP , where OP is orthogonal and DP is symmetric. The\nmatrix OP characterizes the rotation part of AP (which clearly produces no stress), and DP is\nthe distortion part, which actually causes stress. If the deformation is small, DP is close to 1, so\nDP = 1+ dP , where dP is a small symmetric matrix, i.e., an element of S2V . This matrix is called\nthe deformation tensor at P .\nNow we define the stress tensor, which characterizes stress. Let v be a small nonzero vector in\nV , and ε a small disk perpendicular to v centered at P of area ||v||. Let Fv be the force with which\nthe part of the material on the v-side of ε acts on the part on the opposite side. It is easy to deduce\nfrom Newton's laws that Fv is linear in v, so there exists a linear operator SP : V ⊃ V such that\nFv = SP v. It is called the stress tensor.\nAn elasticity law is an equation SP = f(dP ), where f is a function. The simplest such law is a\nlinear law (Hooke's law): f : S2V ⊃ End(V ) is a linear function. In general, such a function is\ndefined by 9 6 = 54 parameters, but we will show there are actually only two essential ones - the\n·\ncompression modulus K and the shearing modulus μ. For this purpose we will use representation\ntheory.\n\nRecall that the group SO(3) of rotations acts on V , so S2V , End(V ) are representations of this\ngroup. The laws of physics must be invariant under this group (Galileo transformations), so f must\nbe a homomorphism of representations.\n(a) Show that End(V ) admits a decomposition RV W , where R is the trivial representation,\nV is the standard 3-dimensional representation, and W is a 5-dimensional representation of SO(3).\nShow that S2V = R W\n(b) Show that V and W are irreducible, even after complexification. Deduce using Schur's\nlemma that SP is always symmetric, and for x 2 R, y 2 W one has f(x + y) = Kx + μy for some\nreal numbers K, μ.\nIn fact, it is clear from physics that K, μ are positive. Physically, the compression modulus K\ncharacterises resistance of the material to compression or dilation, while the shearing modulus μ\ncharacterizes its resistance to changing the shape of the object without changing its volume. For\ninstance, clay (used for sculpting) has a large compression modulus but a small shearing modulus.\n\nRepresentations of finite groups: further results\n4.1\nFrobenius-Schur indicator\nSuppose that G is a finite group and V is an irreducible representation of G over C. We say that\nV is\n- of complex type, if V V ⊕,\n- of real type, if V has a nondegenerate symmetric form invariant under G,\n- of quaternionic type, if V has a nondegenerate skew form invariant under G.\nProblem 4.1. (a) Show that EndR[G] V is C for V of complex type, Mat2(R) for V of real type,\nand H for V of quaternionic type, which motivates the names above.\nHint. Show that the complexification VC of V decomposes as V V ⊕. Use this to compute the\ndimension of EndR[G] V in all three cases. Using the fact that C\nEndR[G] V , prove the result\n→\nin the complex case. In the remaining two cases, let B be the invariant bilinear form on V , and\n(, ) the invariant positive Hermitian form (they are defined up to a nonzero complex scalar and a\npositive real scalar, respectively), and define the operator j : V ⊃ V such that B(v, w) = (v, jw).\nShow that j is complex antilinear (ji = -ij), and j2 = ∂ Id, where ∂ is a real number, positive in\n·\nthe real case and negative in the quaternionic case (if B is renormalized, j multiplies by a nonzero\ncomplex number z and j2 by zz , as j is antilinear). Thus j can be normalized so that j2 = 1 for\nthe real case, and j2 = -1 in the quaternionic case. Deduce the claim from this.\n(b) Show that V is of real type if and only if V is the complexification of a representation VR\nover the field of real numbers.\nExample 4.2. For Z/nZ all irreducible representations are of complex type, except the trivial one\nand, if n is even, the \"sign\" representation, m ⊃ (-1)m, which are of real type. For S3 all three\nirreducible representations C+, C-, C2 are of real type. For S4 there are five irreducible representa\ntions C+, C-, C2 , C3\n+, C3 , which are all of real type. Similarly, all five irreducible representations\nof A5 - C, C+\n3 , C3 , C4 , C\n-\n5 are of real type. As for Q8, its one-dimensional representations are of\n-\nreal type, and the two-dimensional one is of quaternionic type.\nDefinition 4.3. The Frobenius-Schur indicator FS(V ) of an irreducible representation V is 0 if it\nis of complex type, 1 if it is of real type, and -1 if it is of quaternionic type.\nTheorem 4.4. (Frobenius-Schur) The number of involutions (=elements of order ∗ 2) in G is\nequal to ⎨\nV dim(V )FS(V ), i.e., the sum of dimensions of all representations of G of real type\nminus the sum of dimensions of its representations of quaternionic type.\nProof. Let A : V ⊃ V have eigenvalues ∂1, ∂2, . . . , ∂n. We have\nTr S2V (A\nA)\n=\nX\n∂i∂j\n|\ni\nj\n→\nTr 2V (A\nA)\n=\nX\n∂i∂j\n|\ni<j\nThus,\nTr|S2V (A\nA) - Tr|2V (A\nA) =\nX\n∂2 = Tr(A2).\ni\ni\nn\n→→\n\nX\nX\nY\nThus for g 2 G we have\nνV (g 2) = νS2V (g) - ν2V (g)\nTherefore,\n⎞\n⎟\n⎠\n1, if V is of real type\n2V )G\nG|-1νV (\nX\ng 2) = νS2V (P )-ν√2V (P ) = dim(S2V )G -dim(√\n-1, if V is of quaternionic type\n0,\n|\n=\nif V is of complex type\ng2G\nFinally, the number of involutions in G equals\nV\n|G|\ndim V νV (\nX\ng 2) =\nX\ndim V -\ndim V.\ng2G\nreal V\nquat V\nCorollary 4.5. Assume that all representations of a finite group G are defined over real numbers\n(i.e., all complex representations of G are obtained by complexifying real representations). Then\nthe sum of dimensions of irreducible representations of G equals the number of involutions in G.\nExercise. Show that any nontrivial finite group of odd order has an irreducible representation\nwhich is not defined over R (i.e., not realizable by real matrices).\n4.2\nFrobenius determinant\nEnumerate the elements of a finite group G as follows: g1, g2, . . . , gn. Introduce n variables indexed\nwith the elements of G :\nxg1 , xg2 , . . . , xgn .\nDefinition 4.6. Consider the matrix XG with entries aij = xgigj . The determinant of XG is some\npolynomial of degree n of xg1 , xg2 , . . . , xgn that is called the Frobenius determinant.\nThe following theorem, discovered by Dedekind and proved by Frobenius, became the starting\npoint for creation of representation theory (see [Cu]).\nTheorem 4.7.\nr\nPj (x)deg Pj\ndet XG =\nj=1\nfor some pairwise non-proportional irreducible polynomials Pj (x), where r is the number of conju\ngacy classes of G.\nWe will need the following simple lemma.\nLemma 4.8. Let Y be an n × n matrix with entries yij. Then det Y is an irreducible polynomial\nof {yij }.\nProof. Let Y = t Id+⎨\ni\nn\n=1 xiEi,i+1, where i+1 is computed modulo n, and Ei,j are the elementary\n·\nmatrices. Then det(Y ) = tn - (-1)nx1...xn, which is obviously irreducible. Hence det(Y ) is\nirreducible (since factors of a homogeneous polynomial are homogeneous).\nNow we are ready to proceed to the proof of Theorem 4.7.\n\nProof. Let V = C[G] be the regular representation of G. Consider the operator-valued polynomial\nL(x) =\nX\nxgδ(g),\ng2G\nwhere δ(g) 2 EndV is induced by g. The action of L(x) on an element h 2 G is\nL(x)h =\nX\nxgδ(g)h =\nX\nxggh =\nX\nxzh-1 z\ng2G\ng2G\nz2G\nSo the matrix of the linear operator L(x) in the basis g1, g2, . . . , gn is XG with permuted columns\nand hence has the same determinant up to sign.\nFurther, by Maschke's theorem, we have\nr\ndetV L(x) =\nY\n(detVi L(x))dim Vi ,\ni=1\nwhere Vi are the irreducible representations of G. We set Pi = detVi L(x). Let {eim} be bases of Vi\nand Ei,jk 2 End Vi be the matrix units in these bases. Then {Ei,jk} is a basis of C[G] and\nL(x) Vi =\nX\nyi,jkEi,jk,\n|\nj,k\nwhere yi,jk are new coordinates on C[G] related to xg by a linear transformation. Then\nPi(x) = det |\nL(x) = det(yi,jk)\nVi\nHence, Pi are irreducible (by Lemma 4.8) and not proportional to each other (as they depend on\ndifferent collections of variables yi,jk). The theorem is proved.\n4.3\nAlgebraic numbers and algebraic integers\nWe are now passing to deeper results in representation theory of finite groups. These results require\nthe theory of algebraic numbers, which we will now briefly review.\nDefinition 4.9. z 2 C is an algebraic number (respectively, an algebraic integer), if z is a\nroot of a monic polynomial with rational (respectively, integer) coefficients.\nDefinition 4.10. z 2 C is an algebraic number, (respectively, an algebraic integer), if z is an\neigenvalue of a matrix with rational (respectively, integer) entries.\nProposition 4.11. Definitions (4.9) and (4.10) are equivalent.\nProof. To show (4.10) ≥ (4.9), notice that z is a root of the characteristic polynomial of the matrix\n(a monic polynomial with rational, respectively integer, coefficients).\nTo show (4.9) ≥ (4.10), suppose z is a root of\np(x) = x n + a1x n-1 + . . . + an-1x + an.\nThen the characteristic polynomial of the following matrix (called the companion matrix) is\np(x):\n\n⎧0\n0 . . . 0\n-an\nB1\n0 . . . 0 -an-1⎜\nB\n0 . . . 0\n⎜\nB\n-an-2⎜.\nB\n.\n⎜\nB\n.\n⎜\n@\n.\n⎝\n0 . . . 1\n-a1\nSince z is a root of the characteristic polynomial of this matrix, it is an eigenvalue of this matrix.\nThe set of algebraic numbers is denoted by Q, and the set of algebraic integers by A.\nProposition 4.12. (i) A is a ring.\n(ii) Q is a field. Namely, it is an algebraic closure of the field of rational numbers.\nProof. We will be using definition (4.10). Let φ be an eigenvalue of\nA 2 Matn(C)\nwith eigenvector v, let α be an eigenvalue of\nB 2 Matm(C)\nwith eigenvector w. Then φ ± α is an eigenvalue of\nA\nIdm ± Idn\nB,\nand φα is an eigenvalue of\nA\nB.\nThe corresponding eigenvector is in both cases v\nw. This shows that both A and Q are rings.\nTo show that the latter is a field, it suffices to note that if φ = 0 is a root of a polynomial p(x) of\nd\n⇒\ndegree d, then φ-1 is a root of x p(1/x). The last statement is easy, since a number φ is algebraic\nif and only if it defines a finite extension of Q.\nProposition 4.13. A ∈ Q = Z.\nProof. We will be using definition (4.9). Let z be a root of\nn\np(x) = x + a1x n-1 + . . . + an-1x + an,\nand suppose\nz = p\nq 2 Q, gcd(p, q) = 1.\nNotice that the leading term of p(x) will have qn in the denominator, whereas all the other terms\nwill have a lower power of q there. Thus, if q = ±1, then p(z) 2/ Z, a contradiction. Thus,\n⇒\nz 2 A ∈ Q ≥ z 2 Z. The reverse inclusion follows because n 2 Z is a root of x - n.\nEvery algebraic number φ has a minimal polynomial p(x), which is the monic polynomial\nwith rational coefficients of the smallest degree such that p(φ) = 0. Any other polynomial q(x) with\nrational coefficients such that q(φ) = 0 is divisible by p(x). Roots of p(x) are called the algebraic\nconjugates of φ; they are roots of any polynomial q with rational coefficients such that q(φ) = 0.\n\nNote that any algebraic conjugate of an algebraic integer is obviously also an algebraic inte\nger. Therefore, by the Vieta theorem, the minimal polynomial of an algebraic integer has integer\ncoefficients.\nBelow we will need the following lemma:\nLemma 4.14. If φ1, ..., φm are algebraic numbers, then all algebraic conjugates to φ1 + ... + φm\nare of the form φ1\n0 + ... + φ0 , where φ0 are some algebraic conjugates of φi.\nm\ni\nProof. It suffices to prove this for two summands. If φi are eigenvalues of rational matrices Ai of\nsmallest size (i.e., their characteristic polynomials are the minimal polynomials of φi), then φ1 + φ2\nis an eigenvalue of A := A1\nId + Id\nA2. Therefore, so is any algebraic conjugate to φ1 + φ2.\nBut all eigenvalues of A are of the form φ1\n0 + φ2\n0 , so we are done.\nProblem 4.15. (a) Show that for any finite group G there exists a finite Galois extension K\nC\n→\nof Q such that any finite dimensional complex representation of G has a basis in which the matrices\nof the group elements have entries in K.\nHint. Consider the representations of G over the field Q of algebraic numbers.\n(b) Show that if V is an irreducible complex representation of a finite group G of dimension\n> 1 then there exists g 2 G such that νV (g) = 0.\nHint: Assume the contrary. Use orthonormality of characters to show that the arithmetic mean\nof the numbers |νV (g)|2 for g =\n⇒\n1 is < 1. Deduce that their product α satisfies 0 < α < 1.\nShow that all conjugates of α satisfy the same inequalities (consider the Galois conjugates of the\nrepresentation V , i.e. representations obtained from V by the action of the Galois group of K over\nQ on the matrices of group elements in the basis from part (a)). Then derive a contradiction.\nRemark. Here is a modification of this argument, which does not use (a). Let N = G . For\nj\n| |\nany 0 < j < N coprime to N, show that the map g 7⊃ g\nis a bijection G ⊃ G. Deduce that\n⎛\ng=1\ninf\n|νV (gj )| = α. Then show that α 2 K := Q(ψ), ψ = e2νi/N , and does not change under the\nautomorphism of K given by ψ 7⊃ ψj. Deduce that α is an integer, and derive a contradiction.\n4.4\nFrobenius divisibility\nTheorem 4.16. Let G be a finite group, and let V be an irreducible representation of G over C.\nThen\ndim V divides G .\n| |\nProof. Let C1, C2, . . . , Cn be the conjugacy classes of G. Set\n∂i = νV (gCi ) |Ci| ,\ndim V\nwhere gCi is a representative of Ci.\nProposition 4.17. The numbers ∂i are algebraic integers for all i.\nProof. Let C be a conjugacy class in G, and P = ⎨\nh2C h. Then P is a central element of Z[G], so it\nacts on V by some scalar ∂, which is an algebraic integer (indeed, since Z[G] is a finitely generated\nZ-module, any element of Z[G] is integral over Z, i.e., satisfies a monic polynomial equation with\ninteger coefficients). On the other hand, taking the trace of P in V , we get C νV (g) = ∂ dim V ,\n|C|αV (g)\n| |\ng 2 C, so ∂ =\n.\ndim V\n\nNow, consider\nX\n∂iνV (gCi ).\ni\nThis is an algebraic integer, since:\n(i) ∂i are algebraic integers by Proposition 4.17,\n(ii) νV (gCi ) is a sum of roots of unity (it is the sum of eigenvalues of the matrix of δ(gCi ), and\nsince gC\n|G\ni\n| = e in G, the eigenvalues of δ(gCi ) are roots of unity), and\n(iii) A is a ring (Proposition 4.12).\nOn the other hand, from the definition of ∂i,\nX\n∂iνV (gCi ) =\nX |Ci|νV (gCi )νV (gCi ) .\ndim V\nCi\ni\nRecalling that νV is a class function, this is equal to\nX νV (g)νV (g) = |G|(νV , νV ) .\ndim V\ndim V\ng2G\nSince V is an irreducible representation, (νV , νV ) = 1, so\nX\n∂iνV (gCi ) = |G| .\ndim V\nCi\nSince dim\n|G|\nV 2 Q and ⎨\nCi ∂iνV (gCi ) 2 A, by Proposition 4.13 dim\n|G|\nV 2 Z.\n4.5\nBurnside's Theorem\nDefinition 4.18. A group G is called solvable if there exists a series of nested normal subgroups\n{e} = G1 γ G2 γ . . . γ Gn = G\nwhere Gi+1/Gi is abelian for all 1 ∗ i ∗ n - 1.\nRemark 4.19. Such groups are called solvable because they first arose as Galois groups of poly\nnomial equations which are solvable in radicals.\na\nTheorem 4.20 (Burnside). Any group G of order p qb, where p and q are prime and a, b ⊂ 0, is\nsolvable.\nThis famous result in group theory was proved by the British mathematician William Burnside\nin the early 20-th century, using representation theory (see [Cu]). Here is this proof, presented in\nmodern language.\nBefore proving Burnside's theorem we will prove several other results which are of independent\ninterest.\nTheorem 4.21. Let V be an irreducible representation of a finite group G and let C be a conjugacy\nclass of G with gcd(|C|, dim(V )) = 1. Then for any g 2 C, either νV (g) = 0 or g acts as a scalar\non V .\n\nThe proof will be based on the following lemma.\nLemma 4.22. If π1, π2 . . . πn are roots of unity such that\n(π1 + π2 + . . . + πn) is an algebraic\nn\ninteger, then either π1 = . . . = πn or π1 + . . . + πn = 0.\nProof. Let a = 1 (π1 + . . . + πn). If not all πi are equal, then a < 1. Moreover, since any algebraic\nn\n| |\nconjugate of a root of unity is also a root of unity, a0 ∗ 1 for any algebraic conjugate a0 of a. But\n|\n|\nthe product of all algebraic conjugates of a is an integer. Since it has absolute value < 1, it must\nequal zero. Therefore, a = 0.\nProof of theorem 4.21.\nLet dim V = n. Let π1, π2, . . . πn be the eigenvalues of δV (g). They are roots of unity, so\nνV (g) is an algebraic integer. Also, by Proposition 4.17, n |C|νV (g) is an algebraic integer. Since\ngcd(n, C ) = 1, there exist integers a, b such that a C + bn = 1. This implies that\n| |\n| |\nνV (g)\n=\n(π1 + . . . + πn).\nn\nn\nis an algebraic integer. Thus, by Lemma 4.22, we get that either π1 = . . . = πn or π1 + . . . + πn =\nνV (g) = 0. In the first case, since δV (g) is diagonalizable, it must be scalar. In the second case,\nνV (g) = 0. The theorem is proved.\nTheorem 4.23. Let G be a finite group, and let C be a conjugacy class in G of order pk where p\nis prime and k > 0. Then G has a proper nontrivial normal subgroup (i.e., G is not simple).\nProof. Choose an element g 2 C. Since g = e, by orthogonality of columns of the character table,\n⇒\nX\ndim V νV (g) = 0.\n(4)\nV 2IrrG\nWe can divide IrrG into three parts:\n1. the trivial representation,\n2. D, the set of irreducible representations whose dimension is divisible by p, and\n3. N, the set of non-trivial irreducible representations whose dimension is not divisible by p.\nLemma 4.24. There exists V 2 N such that νV (g) = 0.\n⇒\nProof. If V 2 D, the number 1 dim(V )νV (g) is an algebraic integer, so\np\nX 1\na =\ndim(V )νV (g)\np\nV 2D\nis an algebraic integer.\nNow, by (4), we have\n0 = νC(g) +\nX\ndim V νV (g) +\nX\ndim V νV (g) = 1 + pa +\nX\ndim V νV (g).\nV 2D\nV 2N\nV 2N\nThis means that the last summand is nonzero.\n\nNow pick V 2 N such that νV (g) = 0; it exists by Lemma 4.24. Theorem 4.21 implies that g\n⇒\n(and hence any element of C) acts by a scalar in V . Now let H be the subgroup of G generated\nby elements ab-1 , a, b 2 C. It is normal and acts trivially in V , so H =\n⇒\nG, as V is nontrivial. Also\nH = 1, since C > 1.\n⇒\n| |\nProof of Burnside's theorem.\nAssume Burnside's theorem is false. Then there exists a nonsolvable group G of order paqb . Let\nG be the smallest such group. Then G is simple, and by Theorem 4.23, it cannot have a conjugacy\nclass of order pk or qk , k ⊂ 1. So the order of any conjugacy class in G is either 1 or is divisible\na\nby pq. Adding the orders of conjugacy classes and equating the sum to p qb, we see that there has\nto be more than one conjugacy class consisting just of one element. So G has a nontrivial center,\nwhich gives a contradiction.\n4.6\nRepresentations of products\nTheorem 4.25. Let G, H be finite groups, {Vi} be the irreducible representations of G over a\nfield k (of any characteristic), and {Wj } be the irreducible representations of H over k. Then the\nirreducible representations of G × H over k are {Vi\nWj}.\nProof. This follows from Theorem 2.26.\n4.7\nVirtual representations\nDefinition 4.26. A virtual representation of a finite group G is an integer linear combination of\nirreducible representations of G, V = ⎨ niVi, ni 2 Z (i.e., ni are not assumed to be nonnegative).\nThe character of V is νV := ⎨ niνVi .\nThe following lemma is often very useful (and will be used several times below).\nLemma 4.27. Let V be a virtual representation with character νV . If (νV , νV ) = 1 and νV (1) > 0\nthen νV is a character of an irreducible representation of G.\nProof. Let V1, V2, . . . , Vm be the irreducible representations of G, and V = ⎨ niVi. Then by\northonormality of characters, (νV , νV ) = ⎨\ni . So ⎨\n= 1, meaning that ni = ±1 for exactly\ni n\ni ni\none i, and nj = 0 for j = i. But νV (1) > 0, so ni = +1 and we are done.\n⇒\n4.8\nInduced Representations\nGiven a representation V of a group G and a subgroup H\nG, there is a natural way to construct\n→\na representation of H. The restricted representation of V\nH V is the representation given\nto H, ResG\nby the vector space V and the action δResG V = δV H .\nH\n|\nThere is also a natural, but more complicated way to construct a representation of a group G\ngiven a representation V of its subgroup H.\nDefinition 4.28. If G is a group, H\nG, and V is a representation of H, then the induced\n→\nrepresentation IndG V is the representation of G with\nH\nIndG\nf(hx) = δV (h)f(x)⊕x 2 G, h 2 H}\nH V = {f : G ⊃ V |\n\nand the action g(f)(x) = f(xg) ⊕g 2 G.\nRemark 4.29. In fact, IndG\nis naturally isomorphic to HomH (k[G], V ).\nH V\nLet us check that IndG\nis indeed a representation:\nH V\ng(f)(hx) = f(hxg) = δV (h)f(xg) = δV (h)g(f)(x), and g(g0(f))(x) = g0(f)(xg) = f(xgg0) =\n(gg0)(f)(x) for any g, g0, x 2 G and h 2 H.\nRemark 4.30. Notice that if we choose a representative xε from every right H-coset ε of G, then\nany f 2 IndG\nis uniquely determined by {f(xε)}.\nH V\nBecause of this,\ndim(IndG\n|G| .\nH V ) = dim V · H\n|\n|\nProblem 4.31. Check that if K\nH\nH IndH\nG are groups and V a representation of K then IndG\nK V\nis isomorphic to IndG\n→\n→\nK V .\nExercise. Let K\nG be finite groups, and ν : K ⊃ C⊕ be a homomorphism. Let Cα be the\n→\ncorresponding 1-dimensional representation of K. Let\neα =\n1 X\nν(g)-1 g 2 C[K]\n|K| g2K\nbe the idempotent corresponding to ν. Show that the G-representation IndG\nis naturally iso-\nK Cα\nmorphic to C[G]eα (with G acting by left multiplication).\n4.9\nThe Mackey formula\nLet us now compute the character ν of IndG\nIn each right coset ε 2 H\\G, choose a representative\nH V .\nxε.\nTheorem 4.32. (The Mackey formula) One has\nν(g) =\nX\nνV (xεgx-\nε\n1).\n-1\nε2H\\G:x gx 2H\nRemark. If the characteristic of the ground field k is relatively prime to H , then this formula\n|\n|\ncan be written as\nν(g) = 1\nX\nνV (xgx-1).\n|H|\nx2G:xgx-12H\nProof. For a right H-coset ε of G, let us define\n= {f 2 IndG\nf(g) = 0 ⊕g\nVε\nH V |\n⇒2 ε}.\nThen one has\nIndG\n=\nM\nH V\nVε,\nε\nand so\nν(g) =\nX\nνε(g),\nε\n\nwhere νε(g) is the trace of the diagonal block of δ(g) corresponding to Vε.\nSince g(ε) = εg is a right H-coset for any right H-coset ε, νε(g) = 0 if ε = εg.\n⇒\nNow assume that ε = εg. Then xεg = hxε where h = xεgx-\nε\n1 2 H. Consider the vector space\nhomomorphism φ : Vε ⊃ V with φ(f) = f(xε). Since f 2 Vε is uniquely determined by f(xε), φ\nis an isomorphism. We have\nφ(gf) = g(f)(xε ) = f(xεg) = f(hxε) = δV (h)f(xε) = hφ(f),\nand gf = φ-1hφ(f). This means that νε(g) = νV (h). Therefore\nν(g) =\nX\nνV (xεgx-\nε\n1).\nε2H\\G,εg=ε\n4.10\nFrobenius reciprocity\nA very important result about induced representations is the Frobenius Reciprocity Theorem which\nconnects the operations Ind and Res.\nTheorem 4.33. (Frobenius Reciprocity)\nLet H\nG be groups, V be a representation of G and W a representation of H. Then\nHomG(V, Ind\n→\nG\nH V, W ).\nH W ) is naturally isomorphic to HomH (ResG\nProof. Let E = HomG(V, IndG\nH W ) and E0 = HomH (ResG\n0 and F 0\nH V, W ). Define F : E ⊃ E\n: E ⊃\nE as follows: F (φ)v = (φv)(e) for any φ 2 E and (F 0(α)v)(x) = α(xv) for any α 2 E0.\nIn order to check that F and F 0 are well defined and inverse to each other, we need to check\nthe following five statements.\nLet φ 2 E, α 2 E0, v 2 V , and x, g 2 G.\n(a) F (φ) is an H-homomorphism, i.e., F (φ)hv = hF (φ)v.\nIndeed, F (φ)hv = (φhv)(e) = (hφv)(e) = (φv)(he) = (φv)(eh) = h (φv)(e) = hF (φ)v.\n·\n(b) F 0\nH W , i.e., (F (α)v)(hx) = h(F 0(α)v)(x).\n(α)v 2 IndG\nIndeed, (F 0(α)v)(hx) = α(hxv) = hα(xv) = h(F 0(α)v)(x).\n(c) F 0(α) is a G-homomorphism, i.e. F 0(α)gv = g(F 0(α)v).\nIndeed, (F 0(α)gv)(x) = α(xgv) = (F 0(α)v)(xg) = (g(F 0(α)v))(x).\n(d) F inf F 0 = IdE⊗ .\nThis holds since F (F 0(α))v = (F 0(α)v)(e) = α(v).\n(e) F 0 inf F = IdE , i.e., (F 0(F (φ))v)(x) = (φv)(x).\nIndeed, (F 0(F (φ))v)(x) = F (φxv) = (φxv)(e) = (xφv)(e) = (φv)(x), and we are done.\nExercise. The purpose of this exercise is to understand the notions of restricted and induced\nrepresentations as part of a more advanced framework. This framework is the notion of tensor\nproducts over k-algebras (which generalizes the tensor product over k which we defined in Definition\n\n1.48). In particular, this understanding will lead us to a new proof of the Frobenius reciprocity\nand to some analogies between induction and restriction.\nThroughout this exercise, we will use the notation and results of the Exercise in Section 1.10.\nLet G be a finite group and H\nG a subgroup. We consider k [G] as a (k [H] , k [G])-bimodule\n→\n(both module structures are given by multiplication inside k [G]). We denote this bimodule by\nk [G]1. On the other hand, we can also consider k [G] as a (k [G] , k [H])-bimodule (again, both\nmodule structures are given by multiplication). We denote this bimodule by k [G]2.\n(a) Let V be a representation of G. Then, V is a left k [G]-module, thus a (k [G] , k)-bimodule.\nThus, the tensor product k [G]1\nk[G] V is a (k [H] , k)-bimodule, i. e., a left k [H]-module. Prove\nthat this tensor product is isomorphic to ResG\nH V ⊃\nH V as a left k [H]-module. The isomorphism ResG\nis given by v 7⊃ 1\nk[G] v for every v 2 ResG\nk [G]1\nk[G] V\nH V .\n(b) Let W be a representation of H. Then, W is a left k [H]-module, thus a (k [H] , k)\nbimodule. Then, IndG\n= HomH (k [G] , W ), according to Remark 4.30. In other words, IndG\n=\nH W ∪\nH W ∪\nHomk[H] (k [G]1 , W ). Now, use part (b) of the Exercise in Section 1.10 to conclude Theorem 4.33.\n(c) Let V be a representation of G. Then, V is a left k [G]-module, thus a (k [G] , k)-bimodule.\nProve that not only k [G]1\nk[G] V , but also Homk[G] (k [G]2 , V ) is isomorphic to ResG\nas a left\nH V\nk [H]-module. The isomorphism Homk[G] (k [G]2 , V ) ⊃ ResG\nis given by f 7⊃ f (1) for every\nH V\nf 2 Homk[G] (k [G]2 , V ).\n(d) Let W be a representation of H. Then, W is a left k [H]-module, thus a (k [H] , k)\nbimodule. Show that IndG\n, W ), but also isomorphic to\nH W is not only isomorphic to Homk[H] (k [G]1\nk [G]2\nk[H]W . The isomorphism Homk[H] (k [G]1 , W ) ⊃ k [G]2\nk[H]W is given by f 7⊃ ⎨\ng2P g-1\nk[H]\nf (g) for every f 2 Homk[H] (k [G]1 , W ), where P is a set of distinct representatives for the right\nH-cosets in G. (This isomorphism is independent of the choice of representatives.)\n(e) Let V be a representation of G and W a representation of H. Use (b) to prove that\nHomG\n⎩\nIndG\n⎩\nW, ResG\nH W, V\n\nis naturally isomorphic to HomH\nH V\n\n.\n(f) Let V be a representation of H. Prove that IndG\n=\nH V\n⊕ as representations of\nH (V ⊕) ∪⎩\nIndG\nG. [Hint: Write IndG\nas k [G]2\nk[H] V\nH (V ⊕) as Homk[H] (k [G]1 , V ⊕). Prove\nH V\nand write IndG\nthat the map Homk[H] (k [G]1 , V ⊕)\nH (V ⊕)\n\n⊃ k given by\n⎩\nf,\n⎩\nx\nk[H] v\n\n7⊃ (f (Sx)) (v) is\n⎩\nIndG\n×\na nondegenerate G-invariant bilinear form, where S : k [G] ⊃ k [G] is the linear map defined by\nSg = g-1 for every g 2 G.]\n4.11\nExamples\nHere are some examples of induced representations (we use the notation for representations from\nthe character tables).\n1. Let G =\n=\nUsing the Frobenius reciprocity, we obtain: IndG\n= C2\nS3, H\nZ2.\nH C+\nC+,\nIndG\n- = C2 C-.\nH C\n2. Let G = S3, H = Z3.\nH C+\n, IndG\nH Cρ2 = C2\nThen we obtain IndG\n= C+ C-\nH Cρ = IndG\n.\n3. Let G = S4, H = S3.\nH C+\n-, IndG\n- = C-C3\nH C2 = C2\n-C+\n3 .\nThen IndG\n= C+C3\nH C\n, IndG\nC3\n+\nProblem 4.34. Compute the decomposition into irreducibles of all the representations of A5 in\nduced from all the irreducible representations of\n\n(a) Z2\n(b) Z3\n(c) Z5\n(d) A4\n(e) Z2 × Z2\n4.12\nRepresentations of Sn\nIn this subsection we give a description of the representations of the symmetric group Sn for any\nn.\nDefinition 4.35. A partition ∂ of n is a representation of n in the form n = ∂1 + ∂2 + ... + ∂p,\nwhere ∂i are positive integers, and ∂i ⊂ ∂i+1.\nTo such ∂ we will attach a Young diagram Y, which is the union of rectangles -i ∗ y ∗-i+1,\n0 ∗ x ∗ ∂i in the coordinate plane, for i = 1, ..., p. Clearly, Y is a collection of n unit squares. A\nYoung tableau corresponding to Y is the result of filling the numbers 1, ..., n into the squares of\nY in some way (without repetitions). For example, we will consider the Young tableau T obtained\nby filling in the numbers in the increasing order, left to right, top to bottom.\nWe can define two subgroups of Sn corresponding to T:\n1. The row subgroup P: the subgroup which maps every element of {1, ..., n} into an element\nstanding in the same row in T.\n2. The column subgroup Q: the subgroup which maps every element of {1, ..., n} into an\nelement standing in the same column in T.\nClearly, P ∈ Q = {1}.\nDefine the Young projectors:\na := 1\nX\ng,\n|P| g2P\nb :=\nX\n(-1)gg,\n|Q| g2Q\nwhere (-1)g denotes the sign of the permutation g. Set c = ab. Since P ∈ Q = {1}, this\nelement is nonzero.\nThe irreducible representations of Sn are described by the following theorem.\nTheorem 4.36. The subspace V := C[Sn]c of C[Sn] is an irreducible representation of Sn under\nleft multiplication. Every irreducible representation of Sn is isomorphic to V for a unique ∂.\nThe modules V are called the Specht modules.\nThe proof of this theorem is given in the next subsection.\nExample 4.37.\nFor the partition ∂ = (n), P = Sn, Q = {1}, so c is the symmetrizer, and hence V is the trivial\nrepresentation.\n\nFor the partition ∂ = (1, ..., 1), Q = Sn, P = {1}, so c is the antisymmetrizer, and hence V is\nthe sign representation.\nn = 3. For ∂ = (2, 1), V = C2 .\nn = 4. For ∂ = (2, 2), V = C2; for ∂ = (3, 1), V = C3 ; for ∂ = (2, 1, 1), V = C3\n-\n+.\nCorollary 4.38. All irreducible representations of Sn can be given by matrices with rational entries.\nProblem 4.39. Find the sum of dimensions of all irreducible representations of the symmetric\ngroup Sn.\nHint. Show that all irreducible representations of Sn are real, i.e., admit a nondegenerate\ninvariant symmetric form. Then use the Frobenius-Schur theorem.\n4.13\nProof of Theorem 4.36\nLemma 4.40. Let x 2 C[Sn]. Then axb = σ(x)c, where σ is a linear function.\nProof. If g 2 PQ, then g has a unique representation as pq, p 2 P, q 2 Q, so agb = (-1)qc.\nThus, to prove the required statement, we need to show that if g is a permutation which is not in\nPQ then agb = 0.\nTo show this, it is sufficient to find a transposition t such that t 2 P and g-1tg 2 Q; then\nagb = atgb = ag(g-1tg)b = -agb,\nso agb = 0. In other words, we have to find two elements i, j standing in the same row in the\ntableau T = T, and in the same column in the tableau T 0 = gT (where gT is the tableau of the\nsame shape as T obtained by permuting the entries of T by the permutation g). Thus, it suffices to\nshow that if such a pair does not exist, then g 2 PQ, i.e., there exists p 2 P, q0 2 Q\n0 := gQg-1\nsuch that pT = q0T 0 (so that g = pq-1, q = g-1q0g 2 Q).\nAny two elements in the first row of T must be in different columns of T 0, so there exists q1\n0 2 Q\nwhich moves all these elements to the first row. So there is p1 2 P such that p1T and q1\n0 T 0 have\nthe same first row. Now do the same procedure with the second row, finding elements p2, q2\n0 such\nthat p2p1T and q2\n0 q1\n0 T 0 have the same first two rows. Continuing so, we will construct the desired\nelements p, q0. The lemma is proved.\nLet us introduce the lexicographic ordering on partitions: ∂> μ if the first nonvanishing\n∂i - μi is positive.\nLemma 4.41. If ∂> μ then aC[Sn]bμ = 0.\nProof. Similarly to the previous lemma, it suffices to show that for any g 2 Sn there exists a\ntransposition t 2 P such that g-1tg 2 Qμ. Let T = T and T 0 = gTμ. We claim that there are\ntwo integers which are in the same row of T and the same column of T 0. Indeed, if ∂1 > μ1, this is\nclear by the pigeonhole principle (already for the first row). Otherwise, if ∂1 = μ1, like in the proof\nof the previous lemma, we can find elements p1 2 P, q1\n0 2 gQμg-1 such that p1T and q1\n0 T 0 have the\nsame first row, and repeat the argument for the second row, and so on. Eventually, having done\ni - 1 such steps, we'll have ∂i > μi, which means that some two elements of the i-th row of the first\ntableau are in the same column of the second tableau, completing the proof.\n\nLemma 4.42. c is proportional to an idempotent. Namely, c\n2 = dim\nn!\nV c.\nProof. Lemma 4.40 implies that c2\nis proportional to c. Also, it is easy to see that the trace of\nc in the regular representation is n! (as the coefficient of the identity element in c is 1). This\nimplies the statement.\nLemma 4.43. Let A be an algebra and e be an idempotent in A. Then for any left A-module M,\none has HomA(Ae, M) ∪= eM (namely, x 2 eM corresponds to fx : Ae ⊃ M given by fx(a) = ax,\na 2 Ae).\nProof. Note that 1 - e is also an idempotent in A. Thus the statement immediately follows from\nthe fact that HomA(A, M) ∪= M and the decomposition A = Ae A(1 - e).\nNow we are ready to prove Theorem 4.36. Let ∂ ⊂ μ. Then by Lemmas 4.42, 4.43\nHomSn (V, Vμ) = HomSn (C[Sn]c, C[Sn]cμ) = cC[Sn]cμ.\nThe latter space is zero for ∂> μ by Lemma 4.41, and 1-dimensional if ∂ = μ by Lemmas 4.40\nand 4.42. Therefore, V are irreducible, and V is not isomorphic to Vμ if ∂ = μ. Since the number\n⇒\nof partitions equals the number of conjugacy classes in Sn, the representations V exhaust all the\nirreducible representations of Sn. The theorem is proved.\n4.14\nInduced representations for Sn\nDenote by U the representation IndSn C. It is easy to see that U can be alternatively defined as\nP\nU = C[Sn]a.\nProposition 4.44. Hom(U, Vμ) = 0 for μ < ∂, and dim Hom(U, V) = 1. Thus, U =\nμ∧KμVμ, where Kμ are nonnegative integers and K = 1.\nDefinition 4.45. The integers Kμ are called the Kostka numbers.\nProof. By Lemmas 4.42 and 4.43,\nHom(U, Vμ) = Hom(C[Sn]a, C[Sn]aμbμ) = aC[Sn]aμbμ,\nand the result follows from Lemmas 4.40 and 4.41.\nNow let us compute the character of U. Let Ci be the conjugacy class in Sn having il cycles\nof length l for all l ⊂ 1 (here i is a shorthand notation for (i1, ..., il, ...)). Also let x1, ..., xN be\nvariables, and let\nm\nHm(x) =\nX\nxi\ni\nbe the power sum polynomials.\nTheorem 4.46. Let N ⊂ p (where p is the number of parts of ∂). Then νU (Ci) is the coefficient6\nof x := ⎛ xj\nj in the polynomial\nY\nHm(x)im .\nm∧1\nIf j > p, we define j to be zero.\n\nProof. The proof is obtained easily from the Mackey formula. Namely, νU (Ci) is the number of\nelements x 2 Sn such that xgx-1 2 P (for a representative g 2 Ci), divided by |P|. The order of\nP is ⎛∂i!, and the number of elements x such that xgx-1 2 P is the number of elements in P\ni\nconjugate to g (i.e. |Ci ∈ P|) times the order of the centralizer Zg of g (which is n!/|Ci|). Thus,\nνU (Ci) = ⎛|Z\nj\ng\n∂\n|\nj! |Ci ∈ P|.\nNow, it is easy to see that the centralizer Zg of g is isomorphic to ⎛\nm Sim ∼ (Z/mZ)im , so\n|Zg| =\nY\nm im im!,\nm\nand we get\n⎛ mim im!\nνU (Ci) =\nm⎛\nj ∂j!\n|Ci ∈ P|.\nNow, since P = ⎛\nj Sj , we have\nX Y\n∂j !\n=\n,\n|Ci ∈ P|\nr\n⎛\nm∧1 mrjm rjm!\nj∧1\nwhere r = (rjm) runs over all collections of nonnegative integers such that\nX\nmrjm = ∂j ,\nX\nrjm = im.\nm\nj\nIndeed, an element of Ci that is in P would define an ordered partition of each ∂j into parts\n(namely, cycle lengths), with m occuring rjm times, such that the total (over all j) number of times\neach part m occurs is im. Thus we get\n!\nνU (Ci) =\nX Y\n⎛\nj\nim\nrjm!\nr\nm\nBut this is exactly the coefficient of x in\nm\nm\nY\n(x1 + ... + xN )im\nm∧1\nm\n(rjm is the number of times we take xj ).\n4.15\nThe Frobenius character formula\nLet (x) = ⎛\ni<j\n(xi - xj ). Let δ = (N - 1, N - 2, ..., 0) 2 CN . The following theorem, due\nN\n→\n→\nto Frobenius, gives a character formula for the Specht modules V.\nTheorem 4.47. Let N ⊂ p. Then νV (Ci) is the coefficient of x+χ := ⎛ xj\nj +N-j in the polyno\nmial\n(x)\nY\nHm(x)im .\nm∧1\nRemark. Here is an equivalent formulation of Theorem 4.47: νV (Ci) is the coefficient of x\nin the (Laurent) polynomial\nY\n1 - x\nx\nj\ni\nY\nHm(x)im .\ni<j\nm∧1\n\nProof. Denote νV shortly by ν. Let us denote the class function defined in the theorem by χ. We\nclaim that this function has the property χ = ⎨\nμ∧ Lμνμ, where Lμ are integers and L = 1.\nIndeed, from Theorem 4.46 we have\nχ =\nX\n(-1)ενU+-() ,\nε2SN\nwhere if the vector ∂ + δ - ε(δ) has a negative entry, the corresponding term is dropped, and if\nit has nonnegative entries which fail to be nonincreasing, then the entries should be reordered in\nthe nonincreasing order, making a partition that we'll denote ∂ + δ - ε(δ)i (i.e., we agree that\n*\nU+χ-ε(χ) := U *+χ-ε(χ)i). Now note that μ = *∂ + δ - ε(δ)i is obtained from ∂ by adding vectors\nof the form ei - ej, i < j, which implies that μ > ∂ or μ = ∂, and the case μ = ∂ arises only if\nε = 1, as desired.\nTherefore, to show that χ = ν, by Lemma 4.27, it suffices to show that (χ, χ) = 1.\nWe have\n(χ, χ) = n\n!\nX\n|Ci|χ(Ci)2 .\ni\nUsing that\nn!\n|Ci| = ⎛\nm mim im! ,\nwe conclude that (χ, χ) is the coefficient of x+χy+χ in the series R(x, y) = (x)(y)S(x, y),\nwhere\nY (⎨\nj xj )im (⎨\nk yk\nX Y (⎨\nj,k xj yk /m)im\nS(x, y) =\nX\nm\nmim im!\nm)im\n=\nm\nim!\nm\n.\ni\nm\ni\nm\nSumming over i and m, we get\nS(x, y) =\nY\nexp(\nX\nx m\nj yk\nm/m) = exp(-\nX\nlog(1 - xj yk)) =\nY\n(1 - xjyk)-1\nm\nj,k\nj,k\nj,k\nThus,\n⎛\n(xi - xj )(yi - yj )\nR(x, y) =\ni<j⎛\n(1 - xiyj)\n.\ni,j\nNow we need the following lemma.\nLemma 4.48.\n⎛\n(zj - zi)(yi - yj )\ni<j⎛\ni,j(zi - yj)\n= det( zi -\nyj\n).\nProof. Multiply both sides by ⎛\n(zi-yj). Then the right hand side must vanish on the hyperplanes\ni,j\nzi = zj and yi = yj (i.e., be divisible by (z)(y)), and is a homogeneous polynomial of degree\nN(N - 1). This implies that the right hand side and the left hand side are proportional. The\nproportionality coefficient (which is equal to 1) is found by induction by multiplying both sides by\nzN - yN and then setting zN = yN .\nNow setting in the lemma zi = 1/xi, we get\nCorollary 4.49. (Cauchy identity)\nR(x, y) = det(\n) =\nX\n.\n1 - xiyj\nε2SN\n⎛N (1 - xjyε(j))\nj=1\n\nCorollary 4.49 easily implies that the coefficient of x+χy+χ is 1. Indeed, if ε = 1 is a permu\ntation in SN , the coefficient of this monomial in\n(1-x\nj y(j)) is obviously zero.\n⇒\nQ\nRemark. For partitions ∂ and μ of n, let us say that ∂ μ or μ\n∂ if μ - ∂ is a sum of\n⇔\nvectors of the form ei - ej , i < j (called positive roots). This is a partial order, and μ\n∂ implies\n⇔\nμ ⊂ ∂. It follows from Theorem 4.47 and its proof that\nν = μ≥KeμνUμ .\nThis implies that the Kostka numbers Kμ vanish unless μ\n∂.\n⇔\n4.16\nProblems\nIn the following problems, we do not make a distinction between Young diagrams and partitions.\nProblem 4.50. For a Young diagram μ, let A(μ) be the set of Young diagrams obtained by adding\na square to μ, and R(μ) be the set of Young diagrams obtained by removing a square from μ.\n(a) Show that ResSn\nVμ = 2R(μ)V.\nSn-1\n(b) Show that IndSn\nSn-1 Vμ = 2A(μ)V.\nProblem 4.51. The content c(∂) of a Young diagram ∂ is the sum ⎨⎨j\nLet C =\nj\ni=1(i - j).\n⎨\ni<j (ij) 2 C[Sn] be the sum of all transpositions. Show that C acts on the Specht module V by\nmultiplication by c(∂).\nProblem 4.52. (a) Let V be any finite dimensional representation of Sn. Show that the element\nE := (12) + ... + (1n) is diagonalizable and has integer eigenvalues on V , which are between 1 - n\nand n - 1.\nHint. Represent E as Cn - Cn-1, where Cn = C is the element from Problem 4.51.\n(b) Show that the element (12)+...+(1n) acts on V by a scalar if and only if ∂ is a rectangular\nYoung diagram, and compute this scalar.\n4.17\nThe hook length formula\nLet us use the Frobenius character formula to compute the dimension of V. According to the\ncharacter formula, dim V is the coefficient of x+χ in (x)(x1 + ... + xN )n . Let lj = ∂j + N - j.\nThen, using the determinant formula for (x) and expanding the determinant as a sum over\npermutations, we get\ndim V =\nX\n(-1)s\nn!\n=\nn!\nX\n(-1)s Y\nlj (lj -1)...(lj -N+s(j)+1) =\n⎛(lj - N + s(j))!\nl1!...lN !\ns2SN :lj ∧N-s(j)\nj\ns2SN\nj\nn!\n⎛\nj lj! det(lj (lj - 1)...(lj - N + i + 1)).\nUsing column reduction and the Vandermonde determinant formula, we see from this expression\nthat\ndim V =\nn!\ndet(lN-i) =\nn!\nY\n(li - lj )\n(5)\nj\n⎛\nj lj !\n⎛\nj lj ! 1\ni<j\nN\n→\n→\n\n(where N ⊂ p).\nIn this formula, there are many cancelations. After making some of these cancelations, we\nobtain the hook length formula. Namely, for a square (i, j) in a Young diagram ∂ (i, j ⊂ 1, i ∗ ∂j),\ndefine the hook of (i, j) to be the set of all squares (i0, j0) in ∂ with i0 ⊂ i, j0 = j or i0 = i, j0 ⊂ j.\nLet h(i, j) be the length of the hook of i, j, i.e., the number of squares in it.\nTheorem 4.53. (The hook length formula) One has\nn!\ndim V = ⎛\nh(i, j) .\ni\nj\n→\nProof. The formula follows from formula (5). Namely, note that\nl1!\n=\nY\nk.\n1<j\nN\n⎛\n(l1 - lj )\nk\nl1,k=l1-lj\n→\n→→\ninf\nIt is easy to see that the factors in this product are exactly the hooklengths h(i, 1). Now delete the\nfirst row of the diagram and proceed by induction.\n4.18\nSchur-Weyl duality for gl(V )\nWe start with a simple result which is called the Double Centralizer Theorem.\nTheorem 4.54. Let A, B be two subalgebras of the algebra End E of endomorphisms of a finite\ndimensional vector space E, such that A is semisimple, and B = EndA E. Then:\n(i) A = EndB E (i.e., the centralizer of the centralizer of A is A);\n(ii) B is semisimple;\n(iii) as a representation of A\nB, E decomposes as E = i2I Vi\nWi, where Vi are all the\nirreducible representations of A, and Wi are all the irreducible representations of B. In particular,\nwe have a natural bijection between irreducible representations of A and B.\nProof. Since A is semisimple, we have a natural decomposition E = i2I Vi\nWi, where Wi :=\nHomA(Vi, E), and A = i End Vi. Therefore, by Schur's lemma, B = EndA(E) is naturally identi\nfied with i End(Wi). This implies all the statements of the theorem.\nWe will now apply Theorem 4.54 to the following situation: E = V\nn , where V is a finite\ndimensional vector space over a field of characteristic zero, and A is the image of C[Sn] in End E.\nLet us now characterize the algebra B. Let gl(V ) be End V regarded as a Lie algebra with operation\nab - ba.\nTheorem 4.55. The algebra B = EndA E is the image of the universal enveloping algebra U(gl(V ))\nunder its natural action on E. In other words, B is generated by elements of the form\nn(b) := b\n...\n1 + 1\nb\n...\n1 + ... + 1\n...\nb,\nb 2 gl(V ).\nProof. Clearly, the image of U(gl(V )) is contained in B, so we just need to show that any element\nof B is contained in the image of U(gl(V )). By definition, B = Sn End V , so the result follows from\npart (ii) of the following lemma.\n\nLemma 4.56. Let k be a field of characteristic zero.\n(i) For any finite dimensional vector space U over k, the space SnU is spanned by elements of\nthe form u\n...\nu, u 2 U.\n(ii) For any algebra A over k, the algebra SnA is generated by elements n(a), a 2 A.\nProof. (i) The space SnU is an irreducible representation of GL(U) (Problem 3.19). The subspace\nspanned by u\n...\nu is a nonzero subrepresentation, so it must be everything.\n(ii) By the fundamental theorem on symmetric functions, there exists a polynomial P with\nrational coefficients such that P (H1(x), ..., Hn(x)) = x1...xn (where x = (x1, ..., xn)). Then\nP (n(a), n(a 2), ..., n(a n)) = a\n...\na.\nThe rest follows from (i).\nNow, the algebra A is semisimple by Maschke's theorem, so the double centralizer theorem\napplies, and we get the following result, which goes under the name \"Schur-Weyl duality\".\nTheorem 4.57. (i) The image A of C[Sn] and the image B of U(gl(V )) in End(V\nn) are central\nizers of each other.\n(ii) Both A and B are semisimple. In particular, V\nn is a semisimple gl(V )-module.\n(iii) We have a decomposition of A\nB-modules V\nn = V\nL, where the summation\nis taken over partitions of n, V are Specht modules for Sn, and L are some distinct irreducible\nrepresentations of gl(V ) or zero.\n4.19\nSchur-Weyl duality for GL(V )\nThe Schur-Weyl duality for the Lie algebra gl(V ) implies a similar statement for the group GL(V ).\nProposition 4.58. The image of GL(V ) in End(V\nn) spans B.\nProof. Denote the span of g\nn , g 2 GL(V ), by B0. Let b 2 End V be any element.\nWe claim that B0 contains b\nn . Indeed, for all values of t but finitely many, t Id+b is invertible,\n·\nso (t Id + b)\nn belongs to B0. This implies that this is true for all t, in particular for t = 0, since\n·\n(t Id + b)\nn is a polynomial in t.\n·\nThe rest follows from Lemma 4.56.\nCorollary 4.59. As a representation of Sn × GL(V ), V\nn decomposes as V\nL, where\nL = HomSn (V, V\nn) are distinct irreducible representations of GL(V ) or zero.\nExample 4.60. If ∂ = (n) then L = SnV , and if ∂ = (1n) (n copies of 1) then L = √nV . It was\nshown in Problem 3.19 that these representations are indeed irreducible (except that √nV is zero\nif n > dim V ).\n\n4.20\nSchur polynomials\nLet ∂ = (∂1, ..., ∂p) be a partition of n, and N ⊂ p. Let\nN\nj +N-j\nj +N-j\nD(x) =\nX\n(-1)s Y\nx\n= det(x\n).\ns(j)\ni\ns2SN\nj=1\nDefine the polynomials\nD(x)\nS(x) := D0(x)\n(clearly D0(x) is just (x)). It is easy to see that these are indeed polynomials, as D is an\ntisymmetric and therefore must be divisible by . The polynomials S are called the Schur\npolynomials.\nProposition 4.61.\nm\nm\nY\n(x1 + ... + xN )im =\nX\nν(Ci)S(x).\nm\n:p\nN\n→\nProof. The identity follows from the Frobenius character formula and the antisymmetry of\nm\nm\n(x)\nY\n(x1 + ... + xN )im .\nm\nCertain special values of Schur polynomials are of importance. Namely, we have\nProposition 4.62.\nS(1, z, z 2 , ..., z N-1) =\nY\nzi-i - zj -j\nz-i - z-j\ni<j\nN\n→\n→\nTherefore,\nS(1, ..., 1) =\nY\n∂i - ∂j + j - i\nj - i\ni<j\nN\n→\n→\nProof. The first identity is obtained from the definition using the Vandermonde determinant. The\nsecond identity follows from the first one by setting z = 1.\n4.21\nThe characters of L\nProposition 4.61 allows us to calculate the characters of the representations L.\nNamely, let dim V = N, g 2 GL(V ), and x1, ..., xN be the eigenvalues of g on V . To compute\nthe character νL (g), let us calculate TrV\nn (g\nns), where s 2 Sn. If s 2 Ci, we easily get that this\ntrace equals\nY\nTr(g m)im =\nY\nHm(x)im .\nm\nm\nOn the other hand, by the Schur-Weyl duality\nTrV\nn (g\nn s) =\nX\nν(Ci)TrL (g).\nComparing this to Proposition 4.61 and using linear independence of columns of the character table\nof Sn, we obtain\n\nTheorem 4.63. (Weyl character formula) The representation L is zero if and only if N < p,\nwhere p is the number of parts of ∂. If N ⊂ p, the character of L is the Schur polynomial S(x).\nTherefore, the dimension of L is given by the formula\ndim L =\nY\n∂i - ∂j + j - i\nj - i\ni<j\nN\n→\n→\nThis shows that irreducible representations of GL(V ) which occur in V\nn for some n are labeled\nby Young diagrams with any number of squares but at most N = dim V rows.\nProposition 4.64. The representation L+1N (where 1N = (1, 1, ..., 1) 2 ZN ) is isomorphic to\nL\n√N V .\nProof. Indeed, L\n√N V → V\nn\n√N V → V\nn+N , and the only component of V\nn+N that has\nthe same character as L\n√N V is L+1N . This implies the statement.\n4.22\nPolynomial representations of GL(V )\nDefinition 4.65. We say that a finite dimensional representation Y of GL(V ) is polynomial (or\nalgebraic, or rational) if its matrix elements are polynomial functions of the entries of g, g -1 ,\ng 2 GL(V ) (i.e., belong to k[gij ][1/ det(g)]).\nFor example, V\nn and hence all L are polynomial. Also define L-r 1N := L\n(√N V ⊕)\nr (this\n·\ndefinition makes sense by Proposition 4.64). This is also a polynomial representation. Thus we\nhave attached a unique irreducible polynomial representation L of GL(V ) = GLN to any sequence\n(∂1, ..., ∂N ) of integers (not necessarily positive) such that ∂1 ⊂ ... ⊂ ∂N . This sequence is called\nthe highest weight of L.\nTheorem 4.66. (i) Every finite dimensional polynomial representation of GL(V ) is completely\nreducible, and decomposes into summands of the form L (which are pairwise non-isomorphic).\n(ii) (the Peter-Weyl theorem for GL(V )). Let R be the algebra of polynomial functions on\nGL(V ). Then as a representation of GL(V ) × GL(V ) (with action (δ(g, h)θ)(x) = θ(g-1xh),\ng, h, x 2 GL(V ), θ 2 R), R decomposes as\nR = L⊕\n\nL,\nwhere the summation runs over all ∂.\nProof. (i) Let Y be a polynomial representation of GL(V ). We have an embedding : Y ⊃ Y\nR\ngiven by (u, (v))(g) := u(gv), u 2 V ⊕. It is easy to see that is a homomorphism of representations\n(where the action of GL(V ) on the first component of Y\nR is trivial). Thus, it suffices to prove\nthe theorem for a subrepresentation Y\nRm . Now, every element of R is a polynomial of gij\n→\ntimes a nonpositive power of det(g). Thus, R is a quotient of a direct sum of representations of the\nform Sr(V\nV ⊕)\n(√N V ⊕)\ns . So we may assume that Y is contained in a quotient of a (finite)\ndirect sum of such representations. As V ⊕ = √N-1V\n√N V ⊕, Y is contained in a direct sum of\nrepresentations of the form V\nn\n(√N V ⊕)\ns, and we are done.\n(ii) Let Y be a polynomial representation of GL(V ), and let us regard R as a representation\nof GL(V ) via (δ(h)θ)(x) = θ(xh). Then HomGL(V )(Y, R) is the space of polynomial functions\non GL(V ) with values in Y ⊕, which are GL(V )-equivariant. This space is naturally identified\n\nwith Y ⊕. Taking into account the proof of (i), we deduce that R has the required decomposition,\nwhich is compatible with the second action of GL(V ) (by left multiplications). This implies the\nstatement.\nNote that the Peter-Weyl theorem generalizes Maschke's theorem for finite group, one of whose\nforms states that the space of complex functions Fun(G, C) on a finite group G as a representation\nof G × G decomposes as V 2Irrep(G)V ⊕\nV .\nRemark 4.67. Since the Lie algebra sl(V ) of traceless operators on V is a quotient of gl(V ) by\nscalars, the above results extend in a straightforward manner to representations of the Lie algebra\nsl(V ). Similarly, the results for GL(V ) extend to the case of the group SL(V ) of operators with\ndeterminant 1. The only difference is that in this case the representations L and L+1m are\nisomorphic, so the irreducible representations are parametrized by integer sequences ∂1 ⊂ ... ⊂ ∂N\nup to a simultaneous shift by a constant.\nIn particular, one can show that any finite dimensional representation of sl(V ) is completely\nreducible, and any irreducible one is of the form L (we will not do this here). For dim V = 2 one\nthen recovers the representation theory of sl(2) studied in Problem 1.55.\n4.23\nProblems\nProblem 4.68. (a) Show that the Sn-representation V\n0 := C[Sn]ba is isomorphic to V.\nHint. Define Sn-homomorphisms f : V ⊃ V\n0 and g : V\n0 ⊃ V by the formulas f(x) = xa and\ng(y) = yb, and show that they are inverse to each other up to a nonzero scalar.\n(b) Let θ : C[Sn] ⊃ C[Sn] be the automorphism sending s to (-1)ss for any permutation s.\nShow that θ maps any representation V of Sn to V\nC-. Show also that θ(C[Sn]a) = C[Sn]θ(a),\nfor a 2 C[Sn]. Use (a) to deduce that V\nC- = V , where ∂⊕ is the conjugate partition to ∂,\nobtained by reflecting the Young diagram of ∂.\nProblem 4.69. Let Rk,N be the algebra of polynomials on the space of k-tuples of complex N by N\nmatrices X1, ..., Xk, invariant under simultaneous conjugation. An example of an element of Rk,N\nis the function Tw := Tr(w(X1, ..., Xk )), where w is any finite word on a k-letter alphabet. Show\nthat Rk,N is generated by the elements Tw.\nHint. Consider invariant functions that are of degree di in each Xi, and realize this space as\na tensor product\niSdi (V\nV ⊕). Then embed this tensor product into (V\nV ⊕)\nN = End(V )\nn ,\nand use the Schur-Weyl duality to get the result.\n4.24\nRepresentations of GL2(Fq)\n4.24.1\nConjugacy classes in GL2(Fq)\nLet Fq be a finite field of size q of characteristic other than 2, and G = GL2(Fq). Then\n|G| = (q 2 - 1)(q 2 - q),\nsince the first column of an invertible 2 by 2 matrix must be non-zero and the second column may\nnot be a multiple of the first one. Factoring,\n|GL2(Fq)| = q(q + 1)(q - 1)2 .\n\nThe goal of this section is to describe the irreducible representations of G.\nTo begin, let us find the conjugacy classes in GL2(Fq).\nRepresentatives\nScalar\n⎩ x\n0 x\nParabolic\n⎩ x\n0 x\nHyperbolic\n⎩ x\n0 y\n, y = x\n⇒\nElliptic\n⎩ x ζy\n, x\ny\ny x\n2 Fq,\nF×\nq , π 2 Fq \\ F2\nq (characteris\ntic polynomial over Fq is irre\nducible)\nNumber of elements in a conjugacy\nclass\n1 (this is a central element)\nq2 - 1 (elements that commute with\nthis one are of the form\n⎩\nt u\nt\n\n, t =\n⇒\n0)\nq2 + q (elements that commute with\nthis one are of the form\n⎩\nt\nu\n, t, u =\n⇒\n0)\nq2 - q (the reason will be described\nbelow)\nNumber of classes\nq -1 (one for every non\nzero x)\nq -1 (one for every non\nzero x)\n1 (q - 1)(q - 2) (x, y = 0\n⇒\nand x = y)\n⇒\n1 q(q -1) (matrices with\ny and -y are conjugate)\nMore on the conjugacy class of elliptic matrices: these are the matrices whose characteristic\npolynomial is irreducible over Fq and which therefore don't have eigenvalues in Fq. Let A be such\na matrix, and consider a quadratic extension of Fq,\nFq(∀π), π 2 Fq \\ F2 .\nq\nOver this field, A will have eigenvalues\nφ = φ1 + ∀πφ2\nand\nφ = φ1 -∀πφ2,\nwith corresponding eigenvectors\nv, v (Av = φv, Av = φv).\nChoose a basis\n{e1 = v + v, e2 = ∀π(v - v)}.\nIn this basis, the matrix A will have the form\nφ1 πφ2\n\nφ2\nφ1\n,\njustifying the description of representative elements of this conjugacy class.\nIn the basis {v, v}, matrices that commute with A will have the form\n∂ 0\n0 ∂\n,\nfor all\n∂ 2 F×\nq2 ,\nso the number of such matrices is q2 - 1.\n\n4.24.2\n1-dimensional representations\nFirst, we describe the 1-dimensional representations of G.\nProposition 4.70. [G, G] = SL2(Fq).\nProof. Clearly,\ndet(xyx-1 y-1) = 1,\nso\n[G, G] ∧ SL2(Fq).\nTo show the converse, it suffices to show that the matrices\n1 a\n0 1\n1 , 0 a-1 , 1\nare commutators (as such matrices generate SL2(Fq).) Clearly, by using transposition, it suffices\nto show that only the first two matrices are commutators. But it is easy to see that the matrix\nis the commutator of the matrices\n1/2\nA =\n, B =\n,\n0 -1\nwhile the matrix\na\n0 a-1\nis the commutator of the matrices\na 0\nA =\n, B =\n,\nThis completes the proof.\nTherefore,\nG/[G, G] ∪\nvia g ⊃ det(g).\n= F×\nq\nThe one-dimensional representations of G thus have the form\nδ(g) =\n⎩\ndet(g)\n\n,\nwhere is a homomorphism\n: F×\nq ⊃ C×;\nso there are q - 1 such representations, denoted C.\n\n4.24.3\nPrincipal series representations\nLet\nB → G, B = {\n∼\n∼\n}\n∼\n(the set of upper triangular matrices); then\n|B| = (q - 1)2 q,\n[B, B] = U = {\n1 ∼\n},\nand\nB/[B, B] ∪\nq × F×\nq\n= F×\n(the isomorphism maps an element of B to its two diagonal entries).\nLet\n∂ : B ⊃ C×\nbe a homomorphism defined by\na\nb\n∂\n= ∂1(a)∂2(c),for some pair of homomorphisms ∂1, ∂2 : F×\nq ⊃ C×.\n0 c\nDefine\nV1,2 = IndG\nB C,\nwhere C is the 1-dimensional representation of B in which B acts by ∂. We have\ndim(V1,2 ) = |G| = q + 1.\n|B|\nTheorem 4.71.\n1. ∂1 = ∂2 ≥ V1,2 is irreducible.\n⇒\n2. ∂1 = ∂2 = μ ≥ V1,2 = Cμ Wμ, where Wμ is a q-dimensional irreducible representation of\nG.\n∪\n∪\n1,2\n⊗\n{∂\n⊗\n⊗\n3. Wμ = Wξ if and only if μ = λ; V1,2 = V⊗\nif and only if {∂1, ∂2} =\n1, ∂ 2} (in the\n⊗\n⊗\nsecond case, ∂1 = ∂2, ∂ = ∂2).\n⇒\n1 ⇒\nProof. From the Mackey formula, we have\ntrV1,2 (g) = 1\nX\n∂(aga-1).\n|B|\na2G, aga-1 2B\nIf\nx 0\ng =\n,\n0 x\nthe expression on the right evaluates to\n∂(g) |G| = ∂1(x)∂2(x)\n⎩\nq + 1\n\n.\n|B|\nIf\nx 1\ng =\n,\n0 x\n\nthe expression evaluates to\n∂(g) 1,\n·\nsince here\naga-1 2 B ≥ a 2 B.\nIf\nx 0\ng = 0 y ,\nthe expression evaluates to\n⎩\n∂1(x)∂2(y) + ∂1(y)∂2(x)\n\n1,\n·\nsince here\naga-1 2 B ≥ a 2 B or a is an element of B multiplied by the transposition matrix.\nIf\nx πy\ng =\n, x = y\ny\nx\n⇒\nthe expression on the right evaluates to 0 because matrices of this type don't have eigenvalues over\nFq (and thus cannot be conjugated into B). From the definition, ∂i(x)(i = 1, 2) is a root of unity,\nso\n|G|*νV1 ,2 , νV1,2 i = (q + 1)2(q - 1) + (q 2 - 1)(q - 1)\n+ 2(q + q)(q - 1)(q - 2) + (q + q)\nX\n∂1(x)∂2(y)∂1(y)∂2(x).\nx=y\ninf\nThe last two summands come from the expansion\n|a + b| 2 = |a| 2 + |b| 2 + ab + ab.\nIf\n∂1 = ∂2 = μ,\nthe last term is equal to\n(q 2 + q)(q - 2)(q - 1),\nand the total in this case is\n(q + 1)(q - 1)[(q + 1) + (q - 1) + 2q(q - 2)] = (q + 1)(q - 1)2q(q - 1) = 2|G|,\nso\n*νV1,2 , νV1,2 i = 2.\nClearly,\nCμ ∧ IndG\nB Cμ,μ,\nsince\nHomG(Cμ, IndG\nBCμ,μ) = HomB(Cμ, Cμ) = C (Theorem 4.33).\nTherefore, IndG\nis irreducible; and the character of Wμ is different for distinct\nBCμ,μ = Cμ Wμ; Wμ\nvalues of μ, proving that Wμ are distinct.\n\nIf ∂1 = ∂2, let z = xy-1 , then the last term of the summation is\n⇒\n(q + q)\nX\n∂1(z)∂2(z) = (q + q)\nX ∂1 (z) = (q + q)(q - 1)\nX ∂1 (z).\n∂2\n∂2\nx=y\nx;z=1\nz=1\ninf\ninf\ninf\nSince\nX ∂1 (z) = 0,\n∂2\n×\nz2Fq\nbecause the sum of all roots of unity of a given order m > 1 is zero, the last term becomes\n-(q + q)(q - 1)\nX ∂1 (1) = -(q + q)(q - 1).\n∂2\nz=1\ninf\nThe difference between this case and the case of ∂1 = ∂2 is equal to\n-(q 2 + q)[(q - 2)(q - 1) + (q - 1)] = |G|,\nso this is an irreducible representation by Lemma 4.27.\nTo prove the third assertion of the theorem, we look at the characters on hyperbolic elements\nand note that the function\n∂1(x)∂2(y) + ∂1(y)∂2(x)\ndetermines ∂1, ∂2 up to permutation.\n4.24.4\nComplementary series representations\nLet Fq2 ∩ Fq be a quadratic extension Fq(∀π), π 2 Fq \\ F2\nq. We regard this as a 2-dimensional vector\nspace over Fq; then G is the group of linear transformations of Fq2 over Fq. Let K\nG be the cyclic\n→\ngroup of multiplications by elements of F×\nq2 ,\nx πy\nK = { y\nx }, |K| = q 2 - 1.\nFor λ : K ⊃ C× a homomorphism, let\nYξ = IndG\nK Cξ.\nThis representation, of course, is very reducible. Let us compute its character, using the Mackey\nformula. We get\nx 0\nν\n= q(q - 1)λ(x);\n0 x\nν(A) = 0 for A parabolic or hyperbolic;\nx πy\nx πy\nx πyq\nν\n= λ\n+ λ\n.\ny\nx\ny\nx\ny\nx\nThe last assertion holds because if we regard the matrix as an element of Fq2 , conjugation is an\nautomorphism of Fq2 over Fq, but the only nontrivial automorphism of Fq2 over Fq is the qth power\nmap.\n\nWe thus have\nIndG\n= IndG\nK Cξq ∪\nK Cξ\nbecause they have the same character. Therefore, for λ q =\n⇒\nλ we get 2\n1 q(q - 1) representations.\nNext, we look at the following tensor product:\nW1\nV,1,\nwhere 1 is the trivial character and W1 is defined as in the previous section. The character of this\nrepresentation is\nx 0\nν\n= q(q + 1)φ(x);\n0 x\nν(A) = 0 for A parabolic or elliptic;\nx 0\nν\n= φ(x) + φ(y).\n0 y\nThus the \"virtual representation\"\nW1\nV,1 - V,1 - IndG\nK Cξ ,\nwhere φ is the restriction of λ to scalars, has character\nx 0\nν\n= (q - 1)φ(x);\n0 x\nx 1\nν\n= -φ(x);\n0 x\nx 0\nν\n= 0;\n0 y\nx πy\nx πy\nx πy\nν\n= -λ\n- λq\n.\ny\nx\ny\nx\ny\nx\nIn all that follows, we will have λq = λ.\n⇒\nThe following two lemmas will establish that the inner product of this character with itself is\nequal to 1, that its value at 1 is positive. As we know from Lemma 4.27, these two properties imply\nthat it is the character of an irreducible representation of G.\nLemma 4.72. Let ν be the character of the \"virtual representation\" defined above. Then\n*ν, νi = 1\nand\nν(1) > 0.\nProof.\nν(1) = q(q + 1) - (q + 1) - q(q - 1) = q - 1 > 0.\nWe now compute the inner product ν, νi. Since φ is a root of unity, this will be equal to\n*\n\n(q-1) (q-1)2 1+(q-1) 1 (q -1)+ q(q - 1)\nX\n(λ(ψ)+λq(ψ))(λ(ψ) + λq(ψ))\n\n(q - 1)2q(q + 1)\n·\n·\n· ·\n·\nλ elliptic\n\nBecause λ is also a root of unity, the last term of the expression evaluates to\nX\n(2 + λq-1(ψ) + λ1-q(ψ)).\nλ elliptic\nLet's evaluate the last summand.\nSince F×\nq2 is cyclic and λq = λ,\n⇒\nX\nλq-1(ψ) =\nX\nλ1-q(ψ) = 0.\nλ2F×\nq2\nλ2F×\nq2\nTherefore,\nX\n(λq-1(ψ) + λ1-q(ψ)) = -\nX\n(λq-1(ψ) + λ1-q(ψ)) = -2(q - 1) =\nλ elliptic\nλ2F×\nq\nsince F× is cyclic of order q - 1. Therefore,\nq\nν, νi = (q - 1)2\nq(q + 1)\n⎩\n(q -1) (q -1)2 1+(q -1) 1 (q -1)+ q(q\n- 1) (2(q -q)-2(q -1))\n\n= 1.\n*\n·\n·\n· ·\n·\nWe have now shown that for any λ with λq = λ the representation Yξ with the same character\n⇒\nas\nW1\nV,1 - V,1 - IndG\nK Cξ\nexists and is irreducible. These characters are distinct for distinct pairs (φ, λ) (up to switch\nλ ⊃ λq), so there are q(q-1) such representations, each of dimension q - 1.\nWe have thus found q - 1 1-dimensional representations of G, q(q-1) principal series repre\nsentations, and q(q-1) complementary series representations, for a total of q - 1 representations,\ni.e., the number of conjugacy classes in G. This implies that we have in fact found all irreducible\nrepresentations of GL2(Fq).\n4.25\nArtin's theorem\nTheorem 4.73. Let X be a conjugation-invariant system of subgroups of a finite group G. Then\ntwo conditions are equivalent:\n(i) Any element of G belongs to a subgroup H 2 X.\n(ii) The character of any irreducible representation of G belongs to the Q-span of characters of\ninduced representations IndG\nis an irreducible representation of H.\nH V , where H 2 X and V\nRemark. Statement (ii) of Theorem 4.73 is equivalent to the same statement with Q-span\nreplaced by C-span. Indeed, consider the matrix whose columns consist of the coefficients of the\ndecomposition of IndG\n(for various H, V ) with respect to the irreducible representations of G.\nH V\nThen both statements are equivalent to the condition that the rows of this matrix are linearly\nindependent.\n\nProof. Proof that (ii) implies (i). Assume that g 2 G does not belong to any of the subgroups\nH 2 X. Then, since X is conjugation invariant, it cannot be conjugated into such a subgroup.\nHence by the Mackey formula, νIndG (V )(g) = 0 for all H 2 X and V . So by (ii), for any irreducible\nH\nrepresentation W of G, νW (g) = 0. But irreducible characters span the space of class functions, so\nany class function vanishes on g, which is a contradiction.\nProof that (i) implies (ii). Let U be a virtual representation of G over C (i.e., a linear combina\ntion of irreducible representations with nonzero integer coefficients) such that (νU , νIndG V ) = 0 for\nH\nall H, V . So by Frobenius reciprocity, (νU|H , νV ) = 0. This means that νU vanishes on H for any\nH 2 X. Hence by (i), νU is identically zero. This implies (ii) (because of the above remark).\nCorollary 4.74. Any irreducible character of a finite group is a rational linear combination of\ninduced characters from its cyclic subgroups.\n4.26\nRepresentations of semidirect products\nLet G, A be groups and θ : G ⊃ Aut(A) be a homomorphism. For a 2 A, denote θ(g)a by g(a).\nThe semidirect product G ∼ A is defined to be the product A × G with multiplication law\n(a1, g1)(a2, g2) = (a1g1(a2), g1g2).\nClearly, G and A are subgroups of G ∼ A in a natural way.\nWe would like to study irreducible complex representations of G ∼ A. For simplicity, let us do\nit when A is abelian.\nIn this case, irreducible representations of A are 1-dimensional and form the character group\nA∗, which carries an action of G. Let O be an orbit of this action, x 2 O a chosen element,\nand Gx the stabilizer of x in G. Let U be an irreducible representation of Gx. Then we define a\nrepresentation V(O,U) of G ∼ A as follows.\nAs a representation of G, we set\nV(O,x,U) = IndG U = {f : G ⊃ U|f(hg) = hf(g), h 2 Gx}.\nGx\nNext, we introduce an additional action of A on this space by (af)(g) = x(g(a))f(g). Then it's\neasy to check that these two actions combine into an action of G ∼ A. Also, it is clear that this\nrepresentation does not really depend on the choice of x, in the following sense. Let x, y 2 O,\nand g 2 G be such that gx = y, and let g(U) be the representation of Gy obtained from the\nrepresentation U of Gx by the action of g. Then V(O,x,U) is (naturally) isomorphic to V(O,y,g(U)).\nThus we will denote V(O,x,U) by V(O,U) (remembering, however, that x has been fixed).\nTheorem 4.75. (i) The representations V(O,U) are irreducible.\n(ii) They are pairwise nonisomorphic.\n(iii) They form a complete set of irreducible representations of G ∼ A.\n(iv) The character of V = V(O,U) is given by the Mackey-type formula\nνV (a, g) =\nX\nx(h(a))νU (hgh-1).\n|Gx|\nh2G:hgh-12Gx\n\nProof. (i) Let us decompose V = V(O,U) as an A-module. Then we get\nV = y2OVy,\nwhere Vy = {v 2 V(O,U)|av = (y, a)v, a 2 A}. (Equivalently, Vy = {v 2 V(O,U)|v(g) = 0 unless gy =\nx}). So if W → V is a subrepresentation, then W = y2OWy, where Wy → Vy. Now, Vy is a\nrepresentation of Gy, which goes to U under any isomorphism Gy ⊃ Gx determined by g 2 G\nmapping x to y. Hence, Vy is irreducible over Gy, so Wy = 0 or Wy = Vy for each y. Also, if hy = z\nthen hWy = Wz, so either Wy = 0 for all y or Wy = Vy for all y, as desired.\n(ii) The orbit O is determined by the A-module structure of V , and the representation U by\nthe structure of Vx as a Gx-module.\n(iii) We have\nX\ndim V(\nU,O) =\nX\n|O| 2(dim U)2 =\nU,O\nU,O\nX\n|O| |Gx| =\nX\n|O||G/Gx||Gx| = |G|\nX\n|O| = |G||A∗| = |G ∼ A|.\nO\nO\nO\n(iv) The proof is essentially the same as that of the Mackey formula.\nExercise. Redo Problems 3.17(a), 3.18, 3.22 using Theorem 4.75.\nExercise. Deduce parts (i)-(iii) of Theorem 4.75 from part (iv).\n\n|\nQuiver Representations\n5.1\nProblems\nProblem 5.1. Field embeddings. Recall that k(y1, ..., ym) denotes the field of rational functions\nof y1, ..., ym over a field k. Let f : k[x1, ..., xn] ⊃ k(y1, ..., ym) be an injective k-algebra homomor\nphism. Show that m ⊂ n. (Look at the growth of dimensions of the spaces WN of polynomials of\ndegree N in xi and their images under f as N ⊃≤). Deduce that if f : k(x1, ..., xn) ⊃ k(y1, ..., ym)\nis a field embedding, then m ⊂ n.\nProblem 5.2. Some algebraic geometry.\nLet k be an algebraically closed field, and G = GLn(k). Let V be a polynomial representation\nof G. Show that if G has finitely many orbits on V then dim(V ) ∗ n2 . Namely:\n(a) Let x1, ..., xN be linear coordinates on V . Let us say that a subset X of V is Zariski dense\nif any polynomial f(x1, ..., xN ) which vanishes on X is zero (coefficientwise). Show that if G has\nfinitely many orbits on V then G has at least one Zariski dense orbit on V .\n(b) Use (a) to construct a field embedding k(x1, ..., xN ) ⊃ k(gpq), then use Problem 5.1.\n(c) generalize the result of this problem to the case when G = GLn1 (k) × ... × GLnm (k).\nProblem 5.3. Dynkin diagrams.\nLet be a graph, i.e., a finite set of points (vertices) connected with a certain number of edges\n(we allow multiple edges). We assume that is connected (any vertex can be connected to any\nother by a path of edges) and has no self-loops (edges from a vertex to itself). Suppose the vertices\nof are labeled by integers 1, ..., N. Then one can assign to an N × N matrix R = (rij ), where\nrij is the number of edges connecting vertices i and j. This matrix is obviously symmetric, and is\ncalled the adjacency matrix. Define the matrix A = 2I - R, where I is the identity matrix.\nMain definition: is said to be a Dynkin diagram if the quadratic from on RN with matrix\nA is positive definite.\nDynkin diagrams appear in many areas of mathematics (singularity theory, Lie algebras, rep\nresentation theory, algebraic geometry, mathematical physics, etc.) In this problem you will get a\ncomplete classification of Dynkin diagrams. Namely, you will prove\nTheorem. is a Dynkin diagram if and only if it is one on the following graphs:\n- An :\n- · · · -\n- · · · -\n- Dn:\n|\n- E6 :\n----\n\n|\n- E7 :\n-----\n------\n- E8 :\n|\n(a) Compute the determinant of A where = AN , DN . (Use the row decomposition rule, and\nwrite down a recursive equation for it). Deduce by Sylvester criterion7 that AN , DN are Dynkin\ndiagrams.8\n(b) Compute the determinants of A for E6, E7, E8 (use row decomposition and reduce to (a)).\nShow they are Dynkin diagrams.\n(c) Show that if is a Dynkin diagram, it cannot have cycles. For this, show that det(A) = 0\nfor a graph below 9\n(show that the sum of rows is 0). Thus has to be a tree.\n(d) Show that if is a Dynkin diagram, it cannot have vertices with 4 or more incoming edges,\nand that can have no more than one vertex with 3 incoming edges. For this, show that det(A) = 0\nfor a graph below:\n(e) Show that det(A) = 0 for all graphs below:\n7Recall the Sylvester criterion: a symmetric real matrix is positive definite if and only if all its upper left corner\nprincipal minors are positive.\n8The Sylvester criterion says that a symmetric bilinear form (, ) on RN is positive definite if and only if for any\nk N, det1i,jk (ei, ej ) > 0.\n9Please ignore the numerical labels; they will be relevant for Problem 5.5 below.\n\n(f) Deduce from (a)-(e) the classification theorem for Dynkin diagrams.\n(g) A (simply laced) affine Dynkin diagram is a connected graph without self-loops such that the\nquadratic form defined by A is positive semidefinite. Classify affine Dynkin diagrams. (Show that\nthey are exactly the forbidden diagrams from (c)-(e)).\nProblem 5.4. Let Q be a quiver with set of vertices D. We say that Q is of finite type if it\nhas finitely many indecomposable representations. Let bij be the number of edges from i to j in Q\n(i, j 2 D).\nThere is the following remarkable theorem, proved by P. Gabriel in early seventies.\nTheorem. A connected quiver Q is of finite type if and only if the corresponding unoriented\ngraph (i.e., with directions of arrows forgotten) is a Dynkin diagram.\nIn this problem you will prove the \"only if\" direction of this theorem (i.e., why other quivers\nare NOT of finite type).\n(a) Show that if Q is of finite type then for any rational numbers xi ⊂ 0 which are not simul\ntaneously zero, one has q(x1, ..., xN ) > 0, where\nq(x1, ..., xN ) :=\nX\nxi\n2 - 2\n1 X\nbij xixj.\ni2D\ni,j2D\nHint. It suffices to check the result for integers: xi = ni. First assume that ni ⊂ 0, and consider\nthe space W of representations V of Q such that dimVi = ni. Show that the group ⎛\ni GLni (k) acts\nwith finitely many orbits on W k, and use Problem 5.2 to derive the inequality. Then deduce the\nresult in the case when ni are arbitrary integers.\n(b) Deduce that q is a positive definite quadratic form.\nHint. Use the fact that Q is dense in R.\n(c) Show that a quiver of finite type can have no self-loops. Then, using Problem 5.3, deduce\nthe theorem.\nProblem 5.5. Let G = 1 be a finite subgroup of SU(2), and V be the 2-dimensional representation\n⇒\nof G coming from its embedding into SU(2). Let Vi, i 2 I, be all the irreducible representations of\nG. Let rij be the multiplicity of Vi in V\nVj.\n(a) Show that rij = rji.\n(b) The McKay graph of G, M(G), is the graph whose vertices are labeled by i 2 I, and i is\nconnected to j by rij edges. Show that M(G) is connected. (Use Problem 3.26)\n(c) Show that M(G) is an affine Dynkin graph (one of the \"forbidden\" graphs in Problem 5.3).\nFor this, show that the matrix aij = 2ζij - rij is positive semidefinite but not definite, and use\nProblem 5.3.\nHint. Let f = ⎨ xiνVi , where νVi be the characters of Vi. Show directly that ((2-νV )f, f) ⊂ 0.\nWhen is it equal to 0? Next, show that M(G) has no self-loops, by using that if G is not cyclic\nthen G contains the central element -Id 2 SU(2).\n\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n/ /\n/ /\n/ /\n/ /\n/ / o o\n/ /\n/ /\n(d) Which groups from Problem 3.24 correspond to which diagrams?\n(e) Using the McKay graph, find the dimensions of irreducible representations of all finite\nG\nSU(2) (namely, show that they are the numbers labeling the vertices of the affine Dynkin\n→\ndiagrams on our pictures). Compare with the results on subgroups of SO(3) we obtained in\nProblem 3.24.\n5.2\nIndecomposable representations of the quivers A1, A2, A3\nWe have seen that a central question about representations of quivers is whether a certain connected\nquiver has only finitely many indecomposable representations. In the previous subsection it is shown\nthat only those quivers whose underlying undirected graph is a Dynkin diagram may have this\nproperty. To see if they actually do have this property, we first explicitly decompose representations\nof certain easy quivers.\nRemark 5.6. By an object of the type 1\n�0 we mean a map from a one-dimensional vector\nspace to the zero space. Similarly, an object of the type 0\n�1 is a map from the zero space into\na one-dimensional space. The object 1\n�1 means an isomorphism from a one-dimensional to\nanother one-dimensional space. The numbers in such diagrams always mean the dimension of the\nattached spaces and the maps are the canonical maps (unless specified otherwise)\nExample 5.7 (A1). The quiver A1 consists of a single vertex and has no edges. Since a repre\nsentation of this quiver is just a single vector space, the only indecomposable representation is the\nground field (=a one-dimensional space).\nExample 5.8 (A2). The quiver A2 consists of two vertices connected by a single edge.\nA representation of this quiver consists of two vector spaces V, W and an operator A : V ⊃ W .\nA\nV-\nW-\nTo decompose this representation, we first let V 0 be a complement to the kernel of A in V and\nlet W 0 be a complement to the image of A in W . Then we can decompose the representation as\nfollows\nA\nA �\n0 �\ns �\n0 �\nV-\nW-\n= ker-A\n-0 V\n-0\nIm-A -0\nW\n- 0\nThe first summand is a multiple of the object 1\n�0 , the second a multiple of 1\n�1 , the\nthird of 0\n�1 . We see that the quiver A2 has three indecomposable representations, namely\n�0 ,\n�1\nand\n�1 .\nExample 5.9 (A3). The quiver A3 consists of three vertices and two connections between them.\nSo we have to choose between two possible orientations.\nor\n1. We first look at the orientation\n.\n\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n/ /\n/ /\n/ /\n/ /\n/ /\n/ /\n/ /\n/ / / /\n/ /\n/ / / /\n/ /\n/ /\n\n/ /\n/ / / /\n/ /\n/ /\n/ / / /\n\n/ / o o\nThen a representation of this quiver looks like\nA\nB\n-\nV\nW\n-\n.\nY\nLike in Example 5.8 we first split away\n-\n-\nker A\n-\n-\n.\nThis object is a multiple of 1\n�0\n�0 . Next, let Y 0 be a complement of ImB in Y .\nThen we can also split away\n-\nY\n-\n-\n-\nwhich is a multiple of the object 0\n�0\n�1 . This results in a situation where the map\nA is injective and the map B is surjective (we rename the spaces to simplify notation):\n\nA\nB\nV\nY\n-\n.\n-W\nNext, let X = ker(B inf A) and let X0 be a complement of X in V . Let W 0 be a complement\nof A(X) in W such that A(X0)\nW . Then we get\n→\n\nA\nB\nA\nB\n\nA\nB\n=\n-\nTo simplify notation, we redefine\nV = X0, W = W 0.\n-\nV\nW\nY\nX\nY\nW\ns �\nThe first of these summands is a multiple of 1\n0 . Looking at the second summand,\nwe now have a situation where A is injective, B is surjective and furthermore ker(B\nA) = 0.\ninf\nNext\nlet X\nIm(B\nA) and let X\nbe\ncomplement of X in Y\nFurthermore, let\ninf\nwe\n=\na\n.\n-\nW\nB\n(X ). Then W is a complement of A(V ) in W This yields the decomposition\n=\n.\n-\nA\nB\nA\nB\nB\nV\nW\nY\nV\nX\nW\nX\n-\nA(-X)\nX\n�\n=\ns\n�\ns\n�\nA(-V )\nHere, the first summand is a multiple of 1 s � 1 s � 1 . By splitting away the kernel of B,\nthe second summand can be decomposed into multiples of 0\n�1 s � 1 and 0\n�1\n�0 .\nSo, on the whole, this quiver has six indecomposable representations:\n�0\n�0 ,\n�0\n�1 ,\n1 s � 1\n�0 ,\n1 s � 1 s � 1 ,\n�1 s � 1 ,\n�1\n�0\n2. Now we look at the orientation\n.\n-\n-\n-\n-\n-\n-\nVery similarly to the other orientation, we can split away objects of the type\n�0�\n0 ,\n�0�\nwhich results in a situation where both A and B are injective:\n\nA\n�\n\nB\n? _\nV\nW\nY .\n\n/ /\no o\n? _\n\n/ /\no o\n? _\n/ /\ns\no o\ns\n\n_\n\n_\n\n/ /\no o\n? _\n/ / o\ns\n\n/ / o o\ns\ns\ns\n/ /\no oO O-\n/ /\no oO O-\nBy identifying V and Y as subspaces of W , this leads to the problem of classifying pairs of\nsubspaces of a given space W up to isomorphism (the pair of subspaces problem). To do\n-\nso, we first choose a complement W 0 of V ∈ Y in W , and set V 0 = W 0 ∈ V , Y 0 = W 0 ∈ Y .\nThen we can decompose the representation as follows:\n-\nV\nW\nY\nW\nV ∈ Y\nV ∈ Y\nV ∈ Y\n-\n-\n-\n-\n-\n=\n.\n-\nV\nY\n-\n�\n�\n�\n\n?\n?\n-\nThe second summand is a multiple of the object 1 s � 1� s 1 . We go on decomposing the\nfirst summand. Again, to simplify notation, we let\n-\nV = V 0, W = W 0, Y = Y 0.\n-\nWe can now assume that V ∈ Y = 0. Next, let W 0 be a complement of V Y in W . Then\nwe get\nV\nW\nY\nV\nY\nW\n-\n-\n-\n-\n=\n-\nV\nY\n\n-\n-\n-\n�\nThe second of these summands is a multiple of the indecomposable object 0\n0 .\nThe first summand can be further decomposed as follows:\n-\nV\nY\nV\nY\nV\nV\nY\nY\n\n-\n-\n-\n-\n-\n=\nThese summands are multiples of\n�1�\n0 ,\n�1�\nSo - like in the other orientation - we get 6 indecomposable representations of A3:\n�0�\n0 ,\n�0�\n1 ,\n�1�\n1 ,\n�1�\n0 ,\n�1�\n0 ,\n�1�\n5.3\nIndecomposable representations of the quiver D4\nAs a last - slightly more complicated - example we consider the quiver D4.\nExample 5.10 (D4). We restrict ourselves to the orientation\n.\n-\n-\nSo a representation of this quiver looks like\nA1\nV\nA3\n-\n-\n-\nV1\nV3\nA2\n-\nV2\n-\n\n/ /\no o\n/ /\no o\n/ /\no o\nO\nO\nO O\nO\nO\nO O\n\n_\n/ /\no o\n?\nO O-\n?\n/ /\no oO O-\n?\nO O\nO O-\n\nO\nO O-\nO\nThe first thing we can do is - as usual - split away the kernels of the maps A1, A2, A3. More\nprecisely, we split away the representations\n-\n-\n-\n-\n-\n-\nto reach a situation where\nV1 + V2 + V3 = V.\nBy letting Y = V1 ∈ V2 ∈ V3, choosing a complement V 0 of Y in V , and setting Vi\n0 = V 0 ∈ Vi,\ni = 1, 2, 3, we can decompose this representation into\n\nV\n�\n�\n? _\ns � Y �\ns\nker A1\nker A3\n-\n-\n-\n-\n-\n-\n-\n-\nker A2\nThese representations are multiples of the indecomposable objects\n�\n�\n�\n\n-\n-\n-\n-\n-\nY\nY\n-\n-\n-\n-\n-\nV1\nV3\nA2\n-\n-\nY\n-\n-\n-\n-\n0-\nV\n-\n-\n-\n-\n0-\nV\n-\nV\nSo we get to a situation where all of the maps A1, A2, A3 are injective.\n\nA1\nV\nA3\nV2\nAs in 2, we can then identify the spaces V1, V2, V3 with subspaces of V . So we get to the triple of\nsubspaces problem of classifying a triple of subspaces of a given space V .\nThe next step is to split away a multiple of\nThe last summand is a multiple of the indecomposable representation\ns � 1 �\ns\n-\n-\n-\n\n?\n?\nO O\nO O\nO O\n\nO\nO O\nO\nO O-\n?\n?\nO O\nO O\n\nO O-\n/ /\no o\n/ /\no o\nO O\nO O-\nV\nSo - considering the first summand and renaming the spaces to simplify notation - we are in a\nsituation where\nV = V1 + V2 + V3,\nV1 ∈ V2 ∈ V3 = 0.\nof Y in V such that V3\n,\nAs a next step, we let Y = V1 ∈ V2 and we choose a complement V\n= V 0 ∈ V2. This yields the decomposition\n→\n0 = V 0 ∈ V1, V2\nand set V\n\n� V �\n? _\n\nV\n�\n�\n? _\ns � Y � -\n-\nV1\nV3\n-\n-\n-\n-\n-\n-\n-\nV\nV3\nY\n=\n-\n-\n-\nY\nV\nV2\nThe second summand is a multiple of the indecomposable object\ns � 1 �\n.\n-\n-\n-\n-\nIn the resulting situation we have V1 ∈ V2 = 0. Similarly we can split away multiples of\ns � 1 �\ns\n� 1 �\ns\n�\n-\nand\nO\n-\n-\n-\n-\n-\n-\n-\n-\n-\nto reach a situation where the spaces V1, V2, V3 do not intersect pairwise\nV1 ∈ V2 = V1 ∈ V3 = V2 ∈ V3 = 0.\nIf V1 * V2 V3 we let Y = V1 ∈ (V2 V3). We let V1\n0 be a complement of Y in V1. Since then\nV1\n0 ∈ (V2 V3) = 0, we can select a complement V 0 of V 0 in V which contains V2 V3. This gives\nus the decomposition\n\n� V �\n? _\ns V\n� 1\n�\n\nV\n�\n�\n? _\n-\nV1\nV3\n-\n-\n-\n-\n-\nV3\nY\nV\n=\n-\n-\n-\nV2\nV2\nThe first of these summands is a multiple of\ns � 1 �\n-\n-\n-\nBy splitting these away we get to a situation where V1 ∧ V2 V3. Similarly, we can split away\nobjects of the type\ns\n-\nO\nand\n-\n-\n-\n-\n-\n-\nto reach a situation in which the following conditions hold\n\n_\n\n_\nM\n-\n- O O\n-\n/ /\no o\n1. V1 + V2 + V3 = V.\n2. V1 ∈ V2 = 0,\nV1 ∈ V3 = 0,\nV2 ∈ V3 = 0.\n3. V1 ∧ V2 V3,\nV2 ∧ V1 V3,\nV3 ∧ V1 V2.\nBut this implies that\nV1 V2 = V1 V3 = V2 V3 = V.\nSo we get\ndim V1 = dim V2 = dim V3 = n\nand\ndim V = 2n.\nSince V3 ∧ V1 V2 we can write every element of V3 in the form\nx 2 V3,\nx = (x1, x2), x1 2 V1, x2 2 V2.\nWe then can define the projections\nB1 : V3 ⊃ V1,\n(x1, x2) 7⊃ x1,\nB2 : V3 ⊃ V2,\n(x1, x2) 7⊃ x2.\nSince V3 ∈ V1 = 0, V3 ∈ V2 = 0, these maps have to be injective and therefore are isomorphisms. We\nthen define the isomorphism\nA = B2 inf B-1 : V1 ⊃ V2.\nLet e1, . . . , en be a basis for V1. Then we get\nV1 = C e1 C e2 · · · C en\nV2 = C Ae1 C Ae2 · · · C Aen\nV3\n).\n= C (e1 + Ae1) C (e2 + Ae2) · · · C (en + Aen\nSo we can think of V3 as the graph of an isomorphism A : V1 ⊃ V2. From this we obtain the\ndecomposition\n\nV\n\nC2\n�\n\n?\n�\n\n?\nn\nV\n-\n-�\nV\n-\nC(1\n-\n, 0)\n-�\nC(1\n-\n, 1)\n=\n?\nj=1\n?\nV\n-\nC(0\n-\n, 1)\nThese correspond to the indecomposable object\n-\nThus the quiver D4 with the selected orientation has 12 indecomposable objects. If one were to\nexplicitly decompose representations for the other possible orientations, one would also find 12\nindecomposable objects.\nIt appears as if the number of indecomposable representations does not depend on the orienta\ntion of the edges, and indeed - Gabriel's theorem will generalize this observation.\n\nz}|{\n5.4\nRoots\nFrom now on, let be a fixed graph of type An, Dn, E6, E7, E8. We denote the adjacency matrix\nof by R.\nDefinition 5.11 (Cartan Matrix). We define the Cartan matrix as\nA = 2Id - R.\nOn the lattice Zn (or the space Rn) we then define an inner product\nB(x, y) = x T Ay\ncorresponding to the graph .\nLemma 5.12.\n1. B is positive definite.\n2. B(x, x) takes only even values for x 2 Zn .\nProof.\n1. This follows by definition, since is a Dynkin diagram.\n2. By the definition of the Cartan matrix we get\nB(x, x) = x T Ax =\nX\nxi aij xj = 2\nX\nxi +\nX\nxi aij xj = 2\nX\nxi + 2\nX\naij xixj\n·\ni,j\ni\ni,j, i=j\ni\ni<j\ninf\nwhich is even.\nDefinition 5.13. A root with respect to a certain positive inner product is a shortest (with respect\nto this inner product), nonzero vector in Zn .\nSo for the inner product B, a root is a nonzero vector x 2 Zn such that\nB(x, x) = 2.\nRemark 5.14. There can be only finitely many roots, since all of them have to lie in some ball.\nDefinition 5.15. We call vectors of the form\ni-th\nφi = (0, . . . , 1 , . . . , 0)\nsimple roots.\nThe φi naturally form a basis of the lattice Zn .\nLemma 5.16. Let φ be a root, φ = ⎨n\nkiφi. Then either ki ⊂ 0 for all i or ki ∗ 0 for all i.\ni=1\nProof. Assume the contrary, i.e., ki > 0, kj < 0. Without loss of generality, we can also assume\nthat ks = 0 for all s between i and j. We can identify the indices i, j with vertices of the graph .\nρ\ni0\n-\n-\ni\n-\n-\n-j\n-\n-\n-\n\nNext, let φ be the edge connecting i with the next vertex towards j and i0 be the vertex on the other\nend of φ. We then let 1, 2 be the graphs obtained from by removing φ. Since is supposed\nto be a Dynkin diagram - and therefore has no cycles or loops - both 1 and 2 will be connected\ngraphs, which are not connected to each other.\n-\n-\ni\n-\n-\n-j\n-\n-\n-\nThen we have i 2 1, j 2 2. We define\nα =\nX\nkmφm,\nρ =\nX\nkmφm.\nm21\nm22\nWith this choice we get\nφ = α + ρ.\nSince ki > 0, kj < 0 we know that α = 0, ρ = 0 and therefore\n⇒\n⇒\nB(α, α) ⊂ 2,\nB(ρ, ρ) ⊂ 2.\nFurthermore,\nB(α, ρ) = -kiki⊗ ,\nsince 1, 2 are only connected at φ. But this has to be a nonnegative number, since ki > 0 and\nki⊗ ∗ 0. This yields\nB(φ, φ) = B(α + ρ, α + ρ) = B(α, α) +2 B(α, ρ) + B(ρ, ρ) ⊂ 4.\n| {z }\n| {z }\n| {z }\n∧2\n∧0\n∧2\nBut this is a contradiction, since φ was assumed to be a root.\nDefinition 5.17. We call a root φ = ⎨kiφi a positive root if all ki ⊂ 0. A root for which ki ∗ 0\ni\nfor all i is called a negative root.\nRemark 5.18. Lemma 5.16 states that every root is either positive or negative.\nExample 5.19.\n1. Let be of the type AN-1. Then the lattice L = ZN-1 can be realized as\na subgroup of the lattice ZN by letting L ∧ ZN be the subgroup of all vectors (x1, . . . , xN )\nsuch that\nX\nxi = 0.\ni\nThe vectors\nφ1 = (1, -1, 0, . . . , 0)\nφ2 = (0, 1, -1, 0, . . . , 0)\n. . .\nφN-1 = (0, . . . , 0, 1, -1)\nnaturally form a basis of L. Furthermore, the standard inner product\n(x, y) =\nX\nxiyi\n\non ZN restricts to the inner product B given by on L, since it takes the same values on the\nbasis vectors:\n(φi, φi) = 2\ni, j adjacent\n-1\n(φi, φj ) =\notherwise\nThis means that vectors of the form\n(0, . . . , 0, 1, 0, . . . , 0, -1, 0, . . . , 0) = φi + φi+1 +\n+ φj-1\n· · ·\nand\n(0, . . . , 0, -1, 0, . . . , 0, 1, 0, . . . , 0) = -(φi + φi+1 +\n+ φj-1)\n· · ·\nare the roots of L. Therefore the number of positive roots in L equals\nN(N - 1) .\n2. As a fact we also state the number of positive roots in the other Dynkin diagrams:\nDN\nE6\nN(N - 1)\n36 roots\nE7\n63 roots\nE8\n120 roots\nDefinition 5.20. Let φ 2 Zn be a positive root. The reflection s is defined by the formula\ns(v) = v - B(v, φ)φ.\nWe denote si by si and call these simple reflections.\nRemark 5.21. As a linear operator of Rn , s fixes any vector orthogonal to φ and\ns(φ) = -φ\nTherefore s is the reflection at the hyperplane orthogonal to φ, and in particular fixes B. The\nsi generate a subgroup W ∧ O(Rn), which is called the Weyl group of . Since for every w 2 W ,\nw(φi) is a root, and since there are only finitely many roots, W has to be finite.\n5.5\nGabriel's theorem\nDefinition 5.22. Let Q be a quiver with any labeling 1, . . . , n of the vertices. Let V = (V1, . . . , Vn)\nbe a representation of Q. We then call\nd(V ) = (dim V1, . . . , dim Vn)\nthe dimension vector of this representation.\nWe are now able to formulate Gabriel's theorem using roots.\nTheorem 5.23 (Gabriel's theorem). Let Q be a quiver of type An, Dn, E6, E7, E8. Then Q has\nfinitely many indecomposable representations. Namely, the dimension vector of any indecomposable\nrepresentation is a positive root (with respect to B) and for any positive root φ there is exactly\none indecomposable representation with dimension vector φ.\n\n/ /\no o- O O\no o\n/ /\n\n' :\nM\nM\nM\n5.6\nReflection Functors\nDefinition 5.24. Let Q be any quiver. We call a vertex i 2 Q a sink if all edges connected to i\npoint towards i.\ni\nWe call a vertex i 2 Q a source if all edges connected to i point away from i.\ni -\nDefinition 5.25. Let Q be any quiver and i 2 Q be a sink (a source). Then we let Qi be the\nquiver obtained from Q by reversing all arrows pointing into (pointing out of) i.\nWe are now able to define the reflection functors (also called Coxeter functors).\nDefinition 5.26. Let Q be a quiver, i 2 Q be a sink. Let V be a representation of Q. Then we\ndefine the reflection functor\n+\nF\n: RepQ ⊃ RepQi\ni\nby the rule\nF +(V )k = Vk\nif k = i\n⇒\ni\n⎧\n@\n⎝ .\n+\nF (V )i = ker\nVj ⊃ Vi\ni\nj⊥i\nAlso, all maps stay the same but those now pointing out of i; these are replaced by compositions\nof the inclusion of ker ' into Vj with the projections Vj ⊃ Vk.\nDefinition 5.27. Let Q be a quiver, i 2 Q be a source. Let V be a representation of Q. Let ξ be\nthe canonical map\nξ : Vi ⊃\nVj .\ni\nj\n⊥\n⎧\n@\nThen we define the reflection functor\nFi\n- : RepQ ⊃ RepQi\nby the rule\nFi\n-(V )k = Vk\nif k = i\n⇒\n⎝ /Imξ.\nFi\n-(V )i = Coker (ξ) =\nVj\ni⊥j\nAgain, all maps stay the same but those now pointing into i; these are replaced by the compositions\nof the inclusions Vk ⊃i⊥jVj with the natural map Vj ⊃Vj/Imξ.\nProposition 5.28. Let Q be a quiver, V an indecomposable representation of Q.\n\n-\n- O O\n-\n/ /\no o\n\n-\n- O O\n-\n/ /\no o\n1. Let i 2 Q be a sink. Then either dim Vi = 1, dim Vj = 0 for j = i or\n⇒\n' :\nM\nVj ⊃ Vi\nj⊥i\nis surjective.\n2. Let i 2 Q be a source. Then either dim Vi = 1, dim Vj = 0 for j = i or\n⇒\nξ : Vi ⊃\nM\nVj\ni⊥j\nis injective.\nProof.\n1. Choose a complement W of Im'. Then we get\nW\nV\n=\nV 0\n-\nSince V is indecomposable, one of these summands has to be zero. If the first summand is\nzero, then ' has to be surjective. If the second summand is zero, then the first one has to be\nof the desired form, because else we could write it as a direct sum of several objects of the\ntype\n-\nwhich is impossible, since V was supposed to be indecomposable.\n2. Follows similarly by splitting away the kernel of ξ.\nProposition 5.29. Let Q be a quiver, V be a representation of Q.\n1. If\n' :\nM\nVj ⊃ Vi\nj⊥i\nis surjective, then\nFi\n-F +V = V.\ni\n2. If\nξ : Vi ⊃\nM\nVj\ni⊥j\nis injective, then\n+Fi\n-V = V.\nF i\nProof. In the following proof, we will always mean by i ⊃ j that i points into j in the original\nquiver Q. We only establish the first statement and we also restrict ourselves to showing that the\nspaces of V and Fi\n-F +V are the same. It is enough to do so for the i-th space. Let\ni\n' :\nM\nVj ⊃ Vi\nj⊥i\n\nM\nM\nM\nM\nM\n' :\nM\nbe surjective and let\nK = ker '.\n+\nWhen applying F , the space Vi gets replaced by K. Furthermore, let\ni\nξ : K ⊃\nVj .\nj⊥i\nAfter applying Fi\n-, K gets replaced by\nj⊥i\nBut\nImξ = K\nand therefore\n⎧\n@\n⎝\nK0\nVj\n/(Imξ).\n=\nj⊥i\nj⊥i\nj⊥i\nby the homomorphism theorem. Since ' was assumed to be surjective, we get\nK0 = Vi.\nProposition 5.30. Let Q be a quiver, and V be an indecomposable representation of Q. Then\n⎧\n@\n⎝\n⎧\n@\n⎝\nK0\nVj\n/ ker(' :\nVj ⊃ Vi)\n= Im(' :\nVj ⊃ Vi)\n=\n+V and Fi\n-\nF\nV (whenever defined) are either indecomposable or 0.\ni\n+V - the case Fi\n-\nProof. We prove the proposition for F\nV follows similarly. By Proposition 5.28 it\ni\nfollows that either\nVj ⊃ Vi\nj⊥i\nis surjective or dim Vi = 1, dim Vj = 0,\nj = i. In the last case\n⇒\n+\nF V = 0.\ni\n+\nSo we can assume that ' is surjective. In this case, assume that F V is decomposable as\ni\n+\nF V = X Y\ni\n+\nwith X, Y = 0. But F\n⇒\nV is injective at i, since the maps are canonical projections, whose direct\ni\nsum is the tautological embedding. Therefore X and Y also have to be injective at i and hence (by\n5.29)\n+\n+\nFi\n-X = X,\nF Fi\n-Y = Y\nF i\ni\nIn particular\nFi\n-X ⇒= 0,\nFi\n-Y ⇒= 0.\nTherefore\nV = Fi\n-F +V = Fi\n-X Fi\n-Y\ni\nwhich is a contradiction, since V was assumed to be indecomposable. So we can infer that\n+\nF V\ni\nis indecomposable.\n\nProposition 5.31. Let Q be a quiver and V a representation of Q.\n1. Let i 2 Q be a sink and let V be surjective at i. Then\nd(Fi\n+V ) = si(d(V )).\n2. Let i 2 Q be a source and let V be injective at i. Then\nd(Fi\n-V ) = si(d(V )).\nProof. We only prove the first statement, the second one follows similarly. Let i 2 Q be a sink and\nlet\n' :\nM\nVj ⊃ Vi\nj⊥i\nbe surjective. Let K = ker '. Then\ndim K =\nX\ndim Vj - dim Vi.\nj⊥i\nTherefore we get\n⎩\nd(F +V ) - d(V )\n\n=\nX\ndim Vj - 2 dim Vi = -B (d(V ), φi)\ni\ni\nj⊥i\nand\n⎩\nd(Fi\n+V ) - d(V )\n\nj = 0,\nj = i.\n⇒\nThis implies\nd(Fi\n+V ) - d(V ) = -B (d(V ), φi) φi\n⊆\nd(F +V ) = d(V ) - B (d(V ), φi) φi = si (d(V )) .\ni\n5.7\nCoxeter elements\nDefinition 5.32. Let Q be a quiver and let be the underlying graph. Fix any labeling 1, . . . , n\nof the vertices of . Then the Coxeter element c of Q corresponding to this labeling is defined as\nc = s1s2 . . . sn.\nLemma 5.33. Let\nα =\nX\nkiφi\ni\nwith ki ⊂ 0 for all i but not all ki = 0. Then there is N 2 N, such that\nN α\nc\nhas at least one strictly negative coefficient.\n\nProof. c belongs to a finite group W . So there is M 2 N, such that\nc M = 1.\nWe claim that\n1 + c + c 2 +\n+ c M-1 = 0\n· · ·\nas operators on Rn . This implies what we need, since α has at least one strictly positive coefficient,\nso one of the elements\ncα, c2α, . . . , cM-1α\nmust have at least one strictly negative one. Furthermore, it is enough to show that 1 is not an\neigenvalue for c, since\n(1 + c + c 2 +\n+ c M-1)v = w = 0\n· · ·\n⇒\n≥\ncw = c\n⎩\n1 + c + c + · · · + c M-1\nv = (c + c + c + · · · + c M-1 + 1)v = w.\nAssume the contrary, i.e., 1 is a eigenvalue of c and let v be a corresponding eigenvector.\ncv = v\ns1 . . . snv = v\n≥\n⊆\ns2 . . . snv = s1v.\nBut since si only changes the i-th coordinate of v, we get\ns1v = v and s2 . . . snv = v.\nRepeating the same procedure, we get\nsiv = v\nfor all i. But this means\nB(v, φi) = 0.\nfor all i, and since B is nondegenerate, we get v = 0. But this is a contradiction, since v is an\neigenvector.\n5.8\nProof of Gabriel's theorem\nLet V be an indecomposable representation of Q. We introduce a fixed labeling 1, . . . n on Q, such\nthat i < j if one can reach j from i. This is possible, since we can assign the highest label to any\nsink, remove this sink from the quiver, assign the next highest label to a sink of the remaining\nquiver and so on. This way we create a labeling of the desired kind.\nWe now consider the sequence\nV (0)\n= F +\n= F + F +\n= V, V (1)\nn V, V (2)\nn-1\nn V, . . .\nThis sequence is well defined because of the selected labeling: n has to be a sink of Q, n - 1 has\nto be a sink of Qn (where Qn is obtained from Q by reversing all the arrows at the vertex r) and\nso on. Furthermore, we note that V (n) is a representation of Q again, since every arrow has been\nreversed twice (since we applied a reflection functor to every vertex). This implies that we can\ndefine\nV (n+1) = Fn\n+V (n), . . .\nand continue the sequence to infinity.\n\nTheorem 5.34. There is m 2 N, such that\nd\n\nV (m)\n= φp\nfor some p.\nProof. If V (i) is surjective at the appropriate vertex k, then\n\nV (i+1)\n\nF +V (i)\n\nV (i)\nd\n= d\nk\n= skd\n.\nThis implies, that if V (0), . . . , V (i-1) are surjective at the appropriate vertices, then\nd\n\nV (i)\n= . . . sn-1snd(V ).\nBy Lemma 5.33 this cannot continue indefinitely - since d\n⎩\nV (i)\nmay not have any negative entries.\nLet i be smallest number such that V (i) is not surjective at the appropriate vertex. By Proposition\n5.30 it is indecomposable. So, by Proposition 5.28, we get\nd(V (i)) = φp\nfor some p.\nWe are now able to prove Gabriel's theorem. Namely, we get the following corollaries.\nCorollary 5.35. Let Q be a quiver, V be any indecomposable representation. Then d(V ) is a\npositive root.\nProof. By Theorem 5.34\nsi1 . . . sim (d(V )) = φp.\nSince the si preserve B, we get\nB(d(V ), d(V )) = B(φp, φp) = 2.\nCorollary 5.36. Let V, V 0 be indecomposable representations of Q such that d(V ) = d(V 0). Then\nV and V 0 are isomorphic.\nProof. Let i be such that\nd\n\nV (i)\n= φp.\nThen we also get d\n⎩\nV 0(i)\n= φp. So\nV 0(i) = V (i) =: V i .\nFurthermore we have\nV (i) = F + . . . F + F +V (0)\nk\nn-1\nn\nV 0(i) = Fk\n+ . . . F n\n+\n-1Fn\n+V 0(0).\nBut both V (i-1), . . . , V (0) and V 0(i-1), . . . , V 0(0) have to be surjective at the appropriate vertices.\nThis implies\nFn\n-F -\n. . . F -F + . . . F + Fn\n+\n= V\nF -F -\n. . . F -V i =\nn-1\nk\nk\nn-1\nV (0)\n= V (0)\nn\nn-1\nk\nFn\n-F n\n-\n-1 . . . F k\n-Fk\n+ . . . F n\n+\n-1Fn\n+V 0(0) = V 0(0) = V 0\n\nThese two corollaries show that there are only finitely many indecomposable representations\n(since there are only finitely many roots) and that the dimension vector of each of them is a positive\nroot. The last statement of Gabriel's theorem follows from\nCorollary 5.37. For every positive root φ, there is an indecomposable representation V with\nd(V ) = φ.\nProof. Consider the sequence\nsnφ, sn-1snφ, . . .\nConsider the first element of this sequence which is a negative root (this has to happen by Lemma\n5.33) and look at one step before that, calling this element α. So α is a positive root and siα is a\nnegative root for some i. But since the si only change one coordinate, we get\nα = φi\nand\n(sq . . . sn-1sn)φ = φi.\nWe let C(i) be the representation having dimension vector φi. Then we define\nV = Fn\n-F n\n-\n-1 . . . Fq\n-C(i).\nThis is an indecomposable representation and\nd(V ) = φ.\nExample 5.38. Let us demonstrate by example how reflection functors work. Consider the quiver\nD4 with the orientation of all arrows towards the node (which is labeled by 4). Start with the\n1-dimensional representation V4 sitting at the 4-th vertex. Apply to V4 the functor F3\n-F2\n-F1\n-.\nThis yields\nF1\n-F2\n-F3\n-V4 = V1+2+3+4 .\nNow applying F4\n-we get\nF4\n-F1\n-F2\n-F3\n-V4 = V1+2+3+24 .\nNote that this is exactly the inclusion of 3 lines into the plane, which is the most complicated\nindecomposable representation of the D4 quiver.\n5.9\nProblems\nProblem 5.39. Let Qn be the cyclic quiver of length n, i.e., n vertices connected by n oriented edges\nforming a cycle. Obviously, the classification of indecomposable representations of Q1 is given by\nthe Jordan normal form theorem. Obtain a similar classification of indecomposable representations\nof Q2. In other words, classify pairs of linear operators A : V ⊃ W and B : W ⊃ V up to\nisomorphism. Namely:\n(a) Consider the following pairs (for n ⊂ 1):\n1) En,: V = W = Cn , A is the Jordan block of size n with eigenvalue ∂, B = 1 (∂ 2 C).\n2) En,≤: is obtained from En,0 by exchanging V with W and A with B.\n\n3) Hn: V = Cn with basis vi, W = Cn-1 with basis wi, Avi = wi, Bwi = vi+1 for i < n, and\nAvn = 0.\n4) Kn is obtained from Hn by exchanging V with W and A with B.\nShow that these are indecomposable and pairwise nonisomorphic.\n(b) Show that if E is a representation of Q2 such that AB is not nilpotent, then E = E0 E00,\nwhere E00 = En, for some ∂ = 0.\n⇒\n(c) Consider the case when AB is nilpotent, and consider the operator X on V W given\nby X(v, w) = (Bw, Av). Show that X is nilpotent, and admits a basis consisting of chains (i.e.,\nsequences u, Xu, X2u, ...Xl-1u where Xlu = 0) which are compatible with the direct sum decompo\nsition (i.e., for every chain u 2 V or u 2 W ). Deduce that (1)-(4) are the only indecomposable\nrepresentations of Q2.\n(d)(harder!) generalize this classification to the Kronecker quiver, which has two vertices 1 and\n2 and two edges both going from 1 to 2.\n(e)(still harder!) can you generalize this classification to Qn, n > 2, with any orientation?\nProblem 5.40. Let L\n1 Z8 be the lattice of vectors where the coordinates are either all integers\n→ 2\nor all half-integers (but not integers), and the sum of all coordinates is an even integer.\n(a) Let φi = ei - ei+1, i = 1, ..., 6, φ7 = e6 + e7, φ8 = -1/2 ⎨8\nShow that φi are a basis\ni=1 ei.\nof L (over Z).\n(b) Show that roots in L (under the usual inner product) form a root system of type E8 (compute\nthe inner products of φi).\n(c) Show that the E7 and E6 lattices can be obtained as the sets of vectors in the E8 lattice L\nwhere the first two, respectively three, coordinates (in the basis ei) are equal.\n(d) Show that E6, E7, E8 have 72,126,240 roots, respectively (enumerate types of roots in terms\nof the presentations in the basis ei, and count the roots of each type).\nProblem 5.41. Let V be the indecomposable representation of a Dynkin quiver Q which corre\nsponds to a positive root φ. For instance, if φi is a simple root, then Vi has a 1-dimensional space\nat i and 0 everywhere else.\n(a) Show that if i is a source then Ext1(V, Vi ) = 0 for any representation V of Q, and if i is\na sink, then Ext1(Vi , V ) = 0.\n(b) Given an orientation of the quiver, find a Jordan-H older series of V for that orientation.\n\nIntroduction to categories\n6.1\nThe definition of a category\nWe have now seen many examples of representation theories and of operations with representations\n(direct sum, tensor product, induction, restriction, reflection functors, etc.) A context in which one\ncan systematically talk about this is provided by Category Theory.\nCategory theory was founded by Saunders MacLane and Samuel Eilenberg around 1940. It is a\nfairly abstract theory which seemingly has no content, for which reason it was christened \"abstract\nnonsense\". Nevertheless, it is a very flexible and powerful language, which has become totally\nindispensable in many areas of mathematics, such as algebraic geometry, topology, representation\ntheory, and many others.\nWe will now give a very short introduction to Category theory, highlighting its relevance to the\ntopics in representation theory we have discussed. For a serious acquaintance with category theory,\nthe reader should use the classical book [McL].\nDefinition 6.1. A category C is the following data:\n(i) a class of objects Ob(C);\n(ii) for every objects X, Y 2 Ob(C), the class HomC (X, Y ) = Hom(X, Y ) of morphisms (or\narrows) from X, Y (for f 2 Hom(X, Y ), one may write f : X ⊃ Y );\n(iii) For any objects X, Y, Z 2 Ob(C), a composition map Hom(Y, Z)×Hom(X, Y ) ⊃ Hom(X, Z),\n(f, g) 7⊃ f inf g,\nwhich satisfy the following axioms:\n1. The composition is associative, i.e., (f inf g) inf h = f inf (g inf h);\n2. For each X 2 Ob(C), there is a morphism 1X 2 Hom(X, X), called the unit morphism, such\nthat 1X inf f = f and g inf 1X = g for any f, g for which compositions make sense.\nRemark. We will write X 2 C instead of X 2 Ob(C).\nExample 6.2. 1. The category Sets of sets (morphisms are arbitrary maps).\n2. The categories Groups, Rings (morphisms are homomorphisms).\n3. The category Vectk of vector spaces over a field k (morphisms are linear maps).\n4. The category Rep(A) of representations of an algebra A (morphisms are homomorphisms of\nrepresentations).\n5. The category of topological spaces (morphisms are continuous maps).\n6. The homotopy category of topological spaces (morphisms are homotopy classes of continuous\nmaps).\nImportant remark. Unfortunately, one cannot simplify this definition by replacing the word\n\"class\" by the much more familiar word \"set\". Indeed, this would rule out the important Example 1,\nas it is well known that there is no set of all sets, and working with such a set leads to contradictions.\nThe precise definition of a class and the precise distinction between a class and a set is the subject\nof set theory, and cannot be discussed here. Luckily, for most practical purposes (in particular, in\nthese notes), this distinction is not essential.\n\nWe also mention that in many examples, including examples 1-6, the word \"class\" in (ii) can\nbe replaced by \"set\". Categories with this property (that Hom(X, Y ) is a set for any X, Y ) are\ncalled locally small; many categories that we encounter are of this kind.\nSometimes the collection Hom(X, Y ) of morphisms from X to Y in a given locally small category\nC is not just a set but has some additional structure (say, the structure of an abelian group, or a\nvector space over some field). In this case one says that C is enriched over another category D\n(which is a monoidal category, i.e., has a product operation and a unit object under this product, e.g.\nthe category of abelian groups or vector spaces with the tensor product operation). This means that\nfor each X, Y 2 C, Hom(X, Y ) is an object of D, and the composition Hom(Y, Z) × Hom(X, Y ) ⊃\nHom(X, Z) is a morphism in D. E.g., if D is the category of vector spaces, this means that the\ncomposition is bilinear, i.e. gives rise to a linear map Hom(Y, Z)\nHom(X, Y ) ⊃ Hom(X, Z). For\na more detailed discussion of this, we refer the reader to [McL].\nExample. The category Rep(A) of representations of a k-algebra A is enriched over the\ncategory of k-vector spaces.\nDefinition 6.3. A full subcategory of a category C is a category C0 whose objects are a subclass\nof objects of C, and HomC⊗ (X, Y ) = HomC (X, Y ).\nExample. The category AbelianGroups is a full subcategory of the category Groups.\n6.2\nFunctors\nWe would like to define arrows between categories. Such arrows are called functors.\nDefinition 6.4. A functor F : C ⊃D between categories C and D is\n(i) a map F : Ob(C) ⊃ Ob(D);\n(ii) for each X, Y 2 C, a map F = FX,Y : Hom(X, Y ) ⊃ Hom(F (X), F (Y )) which preserves\ncompositions and identity morphisms.\nNote that functors can be composed in an obvious way. Also, any category has the identity\nfunctor.\nExample 6.5. 1. A (locally small) category C with one object X is the same thing as a monoid.\nA functor between such categories is a homomorphism of monoids.\n2. Forgetful functors Groups ⊃ Sets, Rings ⊃ AbelianGroups.\n3. The opposite category of a given category is the same category with the order of arrows and\ncompositions reversed. Then V 7⊃ V ⊕ is a functor Vectk 7⊃ Vectop .\nk\n4. The Hom functors: If C is a locally small category then we have the functor C ⊃ Sets given\nby Y 7⊃ Hom(X, Y ) and Cop ⊃ Sets given by Y 7⊃ Hom(Y, X).\n5. The assignment X 7⊃ Fun(X, Z) is a functor Sets ⊃ Ringsop.\n6. Let Q be a quiver. Consider the category C(Q) whose objects are the vertices and morphisms\nare oriented paths between them. Then functors from C(Q) to Vectk are representations of Q over\nk.\n7. Let K\nG be groups. Then we have the induction functor IndG\nResG\n→\nK : Rep(K) ⊃ Rep(G), and\nK : Rep(G) ⊃ Rep(K).\n\n8. We have an obvious notion of the Cartesian product of categories (obtained by taking the\nCartesian products of the classes of objects and morphisms of the factors). The functors of direct\nsum and tensor product are then functors Vectk ×Vectk ⊃ Vectk. Also the operations V 7⊃ V\nn ,\nV 7⊃ SnV , V 7⊃ √nV are functors on Vectk. More generally, if β is a representation of Sn, we\nhave functors V 7⊃ HomSn (β, V\nn). Such functors (for irreducible β) are called the Schur functors.\nThey are labeled by Young diagrams.\n9. The reflection functors Fi\n± : Rep(Q) ⊃ Rep( Q i) are functors between representation cate\ngories of quivers.\n6.3\nMorphisms of functors\nOne of the important features of functors between categories which distinguishes them from usual\nmaps or functions is that the functors between two given categories themselves form a category,\ni.e., one can define a nontrivial notion of a morphism between two functors.\nDefinition 6.6. Let C, D be categories and F, G : C ⊃D be functors between them. A morphism\na : F ⊃ G (also called a natural transformation or a functorial morphism) is a collection of\nmorphisms aX : F (X) ⊃ G(X) labeled by the objects X of C, which is functorial in X, i.e., for\nany morphism f : X ⊃ Y (for X, Y 2 C) one has aY inf F (f) = G(f) inf aX .\nA morphism a : F ⊃ G is an isomorphism if there is another morphism a-1 : G ⊃ F such that\na inf a-1 and a-1 inf a are the identities. The set of morphisms from F to G is denoted by Hom(F, G).\nExample 6.7. 1. Let FVectk be the category of finite dimensional vector spaces over k. Then the\nfunctors id and ∼∼ on this category are isomorphic. The isomorphism is defined by the standard\nmaps aV : V ⊃ V ⊕⊕ given by aV (u)(f) = f(u), u 2 V , f 2 V ⊕. But these two functors are not\nisomorphic on the category of all vector spaces Vectk, since for an infinite dimensional vector space\nV , V is not isomorphic to V ⊕⊕.\n2. Let FVect0\nk be the category of finite dimensional k-vector spaces, where the morphisms\nare the isomorphisms. We have a functor F from this category to itself sending any space V to\nV ⊕ and any morphism a to (a⊕)-1 . This functor satisfies the property that V is isomorphic to\nF (V ) for any V , but it is not isomorphic to the identity functor. This is because the isomorphism\nV ⊃ F (V ) = V ⊕ cannot be chosen to be compatible with the action of GL(V ), as V is not\nisomorphic to V ⊕ as a representation of GL(V ).\n3. Let A be an algebra over a field k, and F : A - mod ⊃ Vectk be the forgetful functor.\nThen as follows from Problem 1.22, EndF = Hom(F, F ) = A.\n4. The set of endomorphisms of the identity functor on the category A - mod is the center of\nA (check it!).\n6.4\nEquivalence of categories\nWhen two algebraic or geometric objects are isomorphic, it is usually not a good idea to say that\nthey are equal (i.e., literally the same). The reason is that such objects are usually equal in many\ndifferent ways, i.e., there are many ways to pick an isomorphism, but by saying that the objects are\nequal we are misleading the reader or listener into thinking that we are providing a certain choice\nof the identification, which we actually do not do. A vivid example of this is a finite dimensional\nvector space V and its dual space V ⊕.\n\nFor this reason in category theory, one most of the time tries to avoid saying that two objects\nor two functors are equal. In particular, this applies to the definition of isomorphism of categories.\nNamely, the naive notion of isomorphism of categories is defined in the obvious way: a functor\nF : C ⊃D is an isomorphism if there exists F -1 : D ⊃C such that F inf F -1 and F -1 inf F are equal\nto the identity functors. But this definition is not very useful. We might suspect so since we have\nused the word \"equal\" for objects of a category (namely, functors) which we are not supposed to\ndo. And in fact here is an example of two categories which are \"the same for all practical purposes\"\nbut are not isomorphic; it demonstrates the deficiency of our definition.\nNamely, let C1 be the simplest possible category: Ob(C1) consists of one object X, with\nHom(X, X) = {1X }. Also, let C2 have two objects X, Y and 4 morphisms: 1X , 1Y , a : X ⊃ Y\nand b : Y ⊃ X. So we must have a inf b = 1Y , b inf a = 1X .\nIt is easy to check that for any category D, there is a natural bijection between the collections\nof isomorphism classes of functors C1 ⊃D and C2 ⊃D (both are identified with the collection of\nisomorphism classes of objects of D). This is what we mean by saying that C1 and C2 are \"the same\nfor all practical purposes\". Nevertheless they are not isomorphic, since C1 has one object, and C2\nhas two objects (even though these two objects are isomorphic to each other).\nThis shows that we should adopt a more flexible and less restrictive notion of isomorphism of\ncategories. This is accomplished by the definition of an equivalence of categories.\nDefinition 6.8. A functor F : C ⊃D is an equivalence of categories if there exists F 0 : D ⊃C\nsuch that F inf F 0 and F 0 inf F are isomorphic to the identity functors.\nIn this situation, F 0 is said to be a quasi-inverse to F .\nIn particular, the above categories C1 and C2 are equivalent (check it!).\nAlso, the category FSet of finite sets is equivalent to the category whose objects are nonneg\native integers, and morphisms are given by Hom(m, n) = Maps({1, ..., m}, {1, ..., n}). Are these\ncategories isomorphic? The answer to this question depends on whether you believe that there\nis only one finite set with a given number of elements, or that there are many of those. It seems\nbetter to think that there are many (without asking \"how many\"), so that isomorphic sets need not\nbe literally equal, but this is really a matter of choice. In any case, this is not really a reasonable\nquestion; the answer to this question is irrelevant for any practical purpose, and thinking about it\nwill give you nothing but a headache.\n6.5\nRepresentable functors\nA fundamental notion in category theory is that of a representable functor. Namely, let C be a\n(locally small) category, and F : C ⊃ Sets be a functor. We say that F is representable if there\nexists an object X 2 C such that F is isomorphic to the functor Hom(X, ?). More precisely, if we\nare given such an object X, together with an isomorphism : F = Hom(X, ?), we say that the\n∪\nfunctor F is represented by X (using ).\nIn a similar way, one can talk about representable functors from C op to Sets. Namely, one\ncalls such a functor representable if it is of the form Hom(?, X) for some object X 2 C, up to an\nisomorphism.\nNot every functor is representable, but if a representing object X exists, then it is unique.\nNamely, we have the following lemma.\n\nLemma 6.9. (The Yoneda Lemma) If a functor F is represented by an object X, then X is unique\nup to a unique isomorphism. I.e., if X, Y are two objects in C, then for any isomorphism of functors\nθ : Hom(X, ?) ⊃ Hom(Y, ?) there is a unique isomorphism aπ : X ⊃ Y inducing θ.\nProof. (Sketch) One sets aπ = θ-\nY\n1(1Y ), and shows that it is invertible by constructing the inverse,\nwhich is a-\nπ\n1 = θX (1X ). It remains to show that the composition both ways is the identity, which\nwe will omit here. This establishes the existence of aπ. Its uniqueness is verified in a straightforward\nmanner.\nRemark. In a similar way, if a category C is enriched over another category D (say, the category\nof abelian groups or vector spaces), one can define the notion of a representable functor from C to\nD.\nExample 6.10. Let A be an algebra. Then the forgetful functor to vector spaces on the category\nof left A-modules is representable, and the representing object is the free rank 1 module (=the\nregular representation) M = A. But if A is infinite dimensional, and we restrict attention to the\ncategory of finite dimensional modules, then the forgetful functor, in general, is not representable\n(this is so, for example, if A is the algebra of complex functions on Z which are zero at all points\nbut finitely many).\n6.6\nAdjoint functors\nAnother fundamental notion in category theory is the notion of adjoint functors.\nDefinition 6.11. Functors F : C ⊃D and G : D ⊃C are said to be a pair of adjoint functors if for\nany X 2 C, Y 2 D we are given an isomorphism XY : HomC (F (X), Y ) ⊃ HomD(X, G(Y )) which is\nfunctorial in X and Y ; in other words, if we are given an isomorphism of functors Hom(F (?), ?) ⊃\nHom(?, G(?)) (C × D ⊃ Sets). In this situation, we say that F is left adjoint to G and G is right\nadjoint to F .\nNot every functor has a left or right adjoint, but if it does, it is unique and can be constructed\ncanonically (i.e., if we somehow found two such functors, then there is a canonical isomorphism\nbetween them). This follows easily from the Yoneda lemma, as if F, G are a pair of adjoint functors\nthen F (X) represents the functor Y 7⊃ Hom(X, G(Y )), and G(Y ) represents the functor X 7⊃\nHom(F (X), Y ).\nRemark 6.12. The terminology \"left and right adjoint functors\" is motivated by the analogy\nbetween categories and inner product spaces. More specifically, we have the following useful dic\ntionary between category theory and linear algebra, which helps understand better many notions\nof category theory.\n\nDictionary between category theory and linear algebra\nCategory C\nVector space V with a nondegenerate inner product\nThe set of morphisms Hom(X, Y )\nInner product (x, y) on V (maybe nonsymmetric)\nOpposite category Cop\nSame space V with reversed inner product\nThe category Sets\nThe ground field k\nFull subcategory in C\nNondegenerate subspace in V\nFunctor F : C ⊃D\nLinear operator f : V ⊃ W\nFunctor F : C ⊃ Sets\nLinear functional f 2 V ⊕ = Hom(V, k)\nRepresentable functor\nLinear functional f 2 V ⊕ given by f(v) = (u, v), u 2 V\nYoneda lemma\nNondegeneracy of the inner product (on both sides)\nNot all functors are representable\nIf dim V = ≤, not ⊕f 2 V ⊕, f(v) = (u, v)\nLeft and right adjoint functors\nLeft and right adjoint operators\nAdjoint functors don't always exist\nAdjoint operators may not exist if dim V = ≤\nIf they do, they are unique\nIf they do, they are unique\nLeft and right adjoints may not coincide\nThe inner product may be nonsymmetric\nExample 6.13. 1. Let V be a finite dimensional representation of a group G or a Lie algebra g.\nThen the left and right adjoint to the functor V\non the category of representations of G is the\nfunctor V ⊕\n.\n2. The functor ResG\nK . This is nothing but the statement of the Frobenius\nK is left adjoint to IndG\nreciprocity.\n3. Let Assock be the category of associative unital algebras, and Liek the category of Lie\nalgebras over some field k. We have a functor L : Assock ⊃ Liek, which attaches to an associative\nalgebra the same space regarded as a Lie algebra, with bracket [a, b] = ab - ba. Then the functor L\nhas a left adjoint, which is the functor U of taking the universal enveloping algebra of a Lie algebra.\n4. We have the functor GL1 : Assock ⊃ Groups, given by A 7⊃ GL1(A) = A×. This functor\nhas a left adjoint, which is the functor G 7⊃ k[G], the group algebra of G.\n5. The left adjoint to the forgetful functor Assock ⊃ Vectk is the functor of tensor algebra:\nV 7⊃ TV . Also, if we denote by Commk the category of commutative algebras, then the left adjoint\nto the forgetful functor Commk ⊃ Vectk is the functor of the symmetric algebra: V 7⊃ SV .\nOne can give many more examples, spanning many fields. These examples show that adjoint\nfunctors are ubiquitous in mathematics.\n6.7\nAbelian categories\nThe type of categories that most often appears in representation theory is abelian categories.\nThe standard definition of an abelian category is rather long, so we will not give it here, referring\nthe reader to the textbook [Fr]; rather, we will use as the definition what is really the statement of\nthe Freyd-Mitchell theorem:\nDefinition 6.14. An abelian category is a category (enriched over the category of abelian groups),\nwhich is equivalent to a full subcategory C of the category A-mod of left modules over a ring A,\nclosed under taking finite direct sums, as well as kernels, cokernels, and images of morphisms.\nWe see from this definition that in an abelian category, Hom(X, Y ) is an abelian group for each\nX, Y , compositions are group homomorphisms with respect to each argument, there is the zero ob\nject, the notion of an injective morphism (monomorphism) and surjective morphism (epimorphism),\nand every morphism has a kernel, a cokernel, and an image.\n\nExample 6.15. The category of modules over an algebra A and the category of finite dimensional\nmodules over A are abelian categories.\nRemark 6.16. The good thing about Definition 6.14 is that it allows us to visualize objects,\nmorphisms, kernels, and cokernels in terms of classical algebra. But the definition also has a big\ndrawback, which is that even if C is the whole category A-mod, the ring A is not determined by C.\nIn particular, two different rings can have equivalent categories of modules (such rings are called\nMorita equivalent). Actually, it is worse than that: for many important abelian categories there\nis no natural (or even manageable) ring A at all. This is why people prefer to use the standard\ndefinition, which is free from this drawback, even though it is more abstract.\nWe say that an abelian category C is k-linear if the groups HomC (X, Y ) are equipped with\na structure of a vector space over k, and composition maps are k-linear in each argument. In\nparticular, the categories in Example 6.15 are k-linear.\n6.8\nExact functors\nDefinition 6.17. A sequence of objects and morphisms\nX0 ⊃ X1 ⊃ ... ⊃ Xn+1\nin an abelian category is said to be a complex if the composition of any two consecutive arrows\nis zero. The cohomology of this complex is H i = Ker (di)/Im(di-1), where di : Xi ⊃ Xi+1 (thus\nthe cohomology is defined for 1 ∗ i ∗ n). The complex is said to be exact in the i-th term if\nHi = 0, and is said to be an exact sequence if it is exact in all terms. A short exact sequence\nis an exact sequence of the form\n0 ⊃ X ⊃ Y ⊃ Z ⊃ 0.\nClearly, 0 ⊃ X ⊃ Y ⊃ Z ⊃ 0 is a short exact sequence if and only if X ⊃ Y is injective,\nY ⊃ Z is surjective, and the induced map Y/X ⊃ Z is an isomorphism.\nDefinition 6.18. A functor F between two abelian categories is additive if it induces homomor\nphisms on Hom groups. Also, for k-linear categories one says that F is k-linear if it induces k-linear\nmaps between Hom spaces.\nIt is easy to show that if F is an additive functor, then F (X Y ) is canonically isomorphic to\nF (X) F (Y ).\nExample 6.19. The functors IndG\nK , HomG(V, ?) in the theory of group representations over\nK , ResG\na field k are additive and k-linear.\nDefinition 6.20. An additive functor F : C ⊃D between abelian categories is left exact if for\nany exact sequence\n0 ⊃ X ⊃ Y ⊃ Z,\nthe sequence\n0 ⊃ F (X) ⊃ F (Y ) ⊃ F (Z)\nis exact. F is right exact if for any exact sequence\nX ⊃ Y ⊃ Z ⊃ 0,\nthe sequence\nF (X) ⊃ F (Y ) ⊃ F (Z) ⊃ 0\nis exact. F is exact if it is both left and right exact.\n\nDefinition 6.21. An abelian category C is semisimple if any short exact sequence in this category\nsplits, i.e., is isomorphic to a sequence\n0 ⊃ X ⊃ X Y ⊃ Y ⊃ 0\n(where the maps are obvious).\nExample 6.22. The category of representations of a finite group G over a field of characteristic\nnot dividing G (or 0) is semisimple.\n| |\nNote that in a semisimple category, any additive functor is automatically exact on both sides.\nExample 6.23. (i) The functors IndG\nK are exact.\nK , ResG\n(ii) The functor Hom(X, ?) is left exact, but not necessarily right exact. To see that it need not\nbe right exact, it suffices to consider the exact sequence\n0 ⊃ Z ⊃ Z ⊃ Z/2Z ⊃ 0,\nand apply the functor Hom(Z/2Z, ?).\n(iii) The functor X\nA for a right A-module X (on the category of left A-modules) is right exact,\nbut not necessarily left exact. To see this, it suffices to tensor multiply the above exact sequence\nby Z/2Z.\nExercise. Show that if (F, G) is a pair of adjoint additive functors between abelian categories,\nthen F is right exact and G is left exact.\nExercise. (a) Let Q be a quiver and i 2 Q a source. Let V be a representation of Q, and W a\nrepresentation of Qi (the quiver obtained from Q by reversing arrows at the vertex i). Prove that\nthere is a natural isomorphism between Hom\n⎩\nFi\n-V, W\n\nand Hom\n⎩\nV, F\nW\n\n.\n+\nIn other words, the\ni\nfunctor F + is right adjoint to Fi\n-\ni\n.\n(b) Deduce that the functor F + is left exact, and Fi\n- is right exact.\ni\n\nStructure of finite dimensional algebras\nIn this section we return to studying the structure of finite dimensional algebras. Throughout the\nsection, we work over an algebraically closed field k (of any characteristic).\n7.1\nProjective modules\nLet A be an algebra, and P be a left A-module.\nTheorem 7.1. The following properties of P are equivalent:\n(i) If φ : M ⊃ N is a surjective morphism, and λ : P ⊃ N any morphism, then there exists a\nmorphism μ : P ⊃ M such that φ inf μ = λ.\n(ii) Any surjective morphism φ : M ⊃ P splits, i.e., there exists μ : P ⊃ M such that φinfμ = id.\n(iii) There exists another A-module Q such that P Q is a free A-module, i.e., a direct sum of\ncopies of A.\n(iv) The functor HomA(P, ?) on the category of A-modules is exact.\nProof. To prove that (i) implies (ii), take N = P . To prove that (ii) implies (iii), take M to be free\n(this can always be done since any module is a quotient of a free module). To prove that (iii) implies\n(iv), note that the functor HomA(P, ?) is exact if P is free (as HomA(A, N) = N), so the statement\nfollows, as if the direct sum of two complexes is exact, then each of them is exact. To prove that\n(iv) implies (i), let K be the kernel of the map φ, and apply the exact functor HomA(P, ?) to the\nexact sequence\n0 ⊃ K ⊃ M ⊃ N ⊃ 0.\nDefinition 7.2. A module satisfying any of the conditions (i)-(iv) of Theorem 7.1 is said to be\nprojective.\n7.2\nLifting of idempotents\nLet A be a ring, and I\nA a nilpotent ideal.\n→\nProposition 7.3. Let e0 2 A/I be an idempotent, i.e., e2 = e0. There exists an idempotent e 2 A\nwhich is a lift of e0 (i.e., it projects to e0 under the reduction modulo I). This idempotent is unique\nup to conjugation by an element of 1 + I.\nProof. Let us first establish the statement in the case when I 2 = 0. Note that in this case I is a\nleft and right module over A/I. Let e⊕ be any lift of e0 to A. Then e⊕\n2 - e⊕ = a 2 I, and e0a = ae0.\nWe look for e in the form e = e⊕ + b, b 2 I. The equation for b is e0b + be0 - b = a.\nSet b = (2e0 - 1)a. Then\ne0b + be0 - b = 2e0a - (2e0 - 1)a = a,\nso e is an idempotent. To classify other solutions, set e0 = e + c. For e0 to be an idempotent, we\nmust have ec + ce - c = 0. This is equivalent to saying that ece = 0 and (1 - e)c(1 - e) = 0, so\nc = ec(1 - e) + (1 - e)ce = [e, [e, c]]. Hence e0 = (1 + [c, e])e(1 + [c, e])-1 .\n\nNow, in the general case, we prove by induction in k that there exists a lift ek of e0 to A/Ik+1 ,\nand it is unique up to conjugation by an element of 1 + I k (this is sufficient as I is nilpotent).\nAssume it is true for k = m - 1, and let us prove it for k = m. So we have an idempotent\nem-1 2 A/Im, and we have to lift it to A/Im+1 . But (Im)2 = 0 in A/Im+1, so we are done.\nDefinition 7.4. A complete system of orthogonal idempotents in a unital algebra B is a collection\nof elements e1, ..., en 2 B such that eiej = ζijei, and ⎨\ni\nn\n=1 ei = 1.\nCorollary 7.5. Let e01, ..., e0m be a complete system of orthogonal idempotents in A/I. Then there\nexists a complete system of orthogonal idempotents e1, ..., em (eiej = ζijei, ⎨ ei = 1) in A which\nlifts e01, ..., e0m.\nProof. The proof is by induction in m. For m = 2 this follows from Proposition 7.3. For m > 2,\nwe lift e01 to e1 using Proposition 7.3, and then apply the induction assumption to the algebra\n(1 - e1)A(1 - e1).\n7.3\nProjective covers\nObviously, every finitely generated projective module over a finite dimensional algebra A is a direct\nsum of indecomposable projective modules, so to understand finitely generated projective modules\nover A, it suffices to classify indecomposable ones.\nLet A be a finite dimensional algebra, with simple modules M1, ..., Mn.\nTheorem 7.6. (i) For each i = 1, ..., n there exists a unique indecomposable finitely generated\nprojective module Pi such that dim Hom(Pi, Mj ) = ζij .\n(ii) A = i\nn\n=1(dim Mi)Pi.\n(iii) any indecomposable finitely generated projective module over A is isomorphic to Pi for\nsome i.\nProof. Recall that A/Rad(A) =\ni\nn\n=1 End(Mi), and Rad(A) is a nilpotent ideal. Pick a basis of\nEi\n\nMi, and let eij =\njj, the rank 1 projectors projecting to the basis vectors of this basis (j =\n1, ..., dim Mi). Then eij\n0 are orthogonal idempotents in A/Rad(A). So by Corollary 7.5 we can lift\nthem to orthogonal idempotents eij in A. Now define Pij = Aeij . Then A = i dim Mi Pij , so Pij\nj=1\nare projective. Also, we have Hom(Pij , Mk) = eij Mk, so dim Hom(Pij , Mk) = ζik. Finally, Pij is\nindependent of j up to an isomorphism, as eij for fixed i are conjugate under A× by Proposition\n7.3; thus we will denote Pij by Pi.\nWe claim that Pi is indecomposable. Indeed, if Pi = Q1 Q2, then Hom(Ql, Mj ) = 0 for all j\neither for l = 1 or for l = 2, so either Q1 = 0 or Q2 = 0.\nAlso, there can be no other indecomposable finitely generated projective modules, since any\nsuch module has to occur in the decomposition of A. The theorem is proved.\nReferences\n[BGP] J. Bernstein, I. Gelfand, V. Ponomarev, Coxeter functors and Gabriel's theorem, Russian\nMath. Surveys 28 (1973), no. 2, 17-32.\n\n[Cu] C. Curtis, Pioneers of Representation Theory: Frobenius, Burnside, Schur, and Brauer, AMS,\n1999.\n[CR] C. Curtis and I. Reiner, Representation Theory of Finite Groups and Associative Algebras,\nAMS, 2006.\n[FH] W. Fulton and J. Harris, Representation Theory, A first course, Springer, New York, 1991.\n[Fr] Peter J. Freyd, Abelian Categories, an Introduction to the Theory of Functors. Harper and\nRow (1964).\n[McL] S. MacLane, Categories for a working Mathematician: 2nd Ed., Graduate Texts in Mathe\nmatics 5, Springer, 1998.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n18.712 Introduction to Representation Theory\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Quiver Representations",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/cabe7aec8816cbba978080c2f1cf5e82_MIT18_712F10_ch5.pdf",
      "content": "Quiver Representations\n5.1\nProblems\nProblem 5.1. Field embeddings. Recall that k(y1, ..., ym) denotes the field of rational functions\nof y1, ..., ym over a field k. Let f : k[x1, ..., xn] ⊃ k(y1, ..., ym) be an injective k-algebra homomor\nphism. Show that m ⊂ n. (Look at the growth of dimensions of the spaces WN of polynomials of\ndegree N in xi and their images under f as N ⊃≤). Deduce that if f : k(x1, ..., xn) ⊃ k(y1, ..., ym)\nis a field embedding, then m ⊂ n.\nProblem 5.2. Some algebraic geometry.\nLet k be an algebraically closed field, and G = GLn(k). Let V be a polynomial representation\nof G. Show that if\n\nG has finitely many orbits on V then dim(V ) ∗ n2. Namely:\n(a) Let x1, ..., xN be linear coordinates on V . Let us say that a subset X of V is Zariski dense\nif any polynomial f(x1, ..., xN ) which vanishes on X is zero (coefficientwise). Show that if G has\nfinitely many orbits on V then G has at least one Zariski dense orbit on V .\n(b) Use (a) to construct a field embedding k(x1, ..., xN ) ⊃ k(gpq), then use Problem 5.1.\n(c) generalize the result of this problem to the case when G = GLn1 (k) × ... × GLnm (k).\nProblem 5.3. Dynkin diagrams.\nLet be a graph, i.e., a finite set of points (vertices) connected with a certain number of edges\n(we allow multiple edges). We assume that is connected (any vertex can be connected to any\nother by a path of edges) and has no self-loops (edges from a vertex to itself). Suppose the vertices\nof are labeled by integers 1, ..., N. Then one can assign to an N × N matrix R = (rij ), where\nrij is the number of edges connecting vertices i and j. This matrix is obviously symmetric, and is\ncalled the adjacency matrix. Define the matrix A = 2I - R, where I is the identity matrix.\nMain definition: is said to be a Dynkin diagram if the quadratic from on RN with matrix\nA is positive definite.\nDynkin diagrams appear in many areas of mathematics (singularity theory, Lie algebras, rep\nresentation theory, algebraic geometry, mathematical physics, etc.) In this problem you will get a\ncomplete classification of Dynkin diagrams. Namely, you will prove\nTheorem. is a Dynkin diagram if and only if it is one on the following graphs:\n- An :\n-- · · · --\n--\n\nD :\n· · · --\n-\nn\n|\n- E6 :\n--------\n|\n\n- E7 :\n-------\n|\n---\n------------\n- E8 :\n|\n(a) Compute the determinant of A where = AN , DN . (Use the row decomposition rule, and\nwrite down a recursive equation for it). Deduce by Sylvester criterion7 that AN , DN are Dynkin\ndiagrams.8\n(b) Compute the determinants of A for E6, E7, E8 (use row decomposition and reduce to (a)).\nShow they are Dynkin diagrams.\n(c) Show that if is a Dynkin diagram, it cannot have cycles. For this, show that det(A) = 0\nfor a\n\ngraph below 9\n(show that the sum of rows is 0). Thus has to be a tree.\n(d) Show that if is a Dynkin diagram, it cannot have vertices with 4 or more incoming edges,\nand that can have no more than one vertex with 3 incoming edges. For this, show that det(A) = 0\nfor a graph below:\n(e) Show that det(A) = 0 for all graphs below:\n7Recall the Sylvester criterion: a symmetric real matrix is positive definite if and only if all its upper left corner\nprincipal minors are positive.\n8The Sylvester\n\ncriterion says that a symmetric bilinear form (, ) on RN is positive definite if and only if for any\nk N, det1i,jk (ei, ej ) > 0.\n9Please ignore the numerical labels; they will be relevant for Problem 5.5 below.\n\n(f) Deduce from (a)-(e) the classification theorem for Dynkin diagrams.\n(g) A (simply laced) affine Dynkin diagram is a connected graph without self-loops such that the\nquadratic form defined by A is positive semidefinite. Classify affine Dynkin diagrams. (Show that\nthey are exactly the forbidden diagrams from (c)-(e)).\nProblem 5.4. Let Q be a quiver with set of vertices D. We say that Q is of finite type if it\nhas finitely many indecomposable representations. Let bij be the number of edges from i to j in Q\n(i, j 2 D).\nThere is the following remarkable theorem, proved by P. Gabriel in early seventies.\nTheorem. A connected quiver Q is of finite type if and only if the corresponding unoriented\ngraph (i.e., with directions of arrows forgotten) is a Dynkin diagram.\nIn this problem you will prove the \"only if\" direction of this theorem (i.e., why other quivers\nare NOT of finite type).\n(a) Show that if Q is of finite type then for any rational numbers xi ⊂ 0 which are not simul\ntaneously zero, one has q(x1, ..., xN ) > 0, where\n\nq(x1, ..., xN ) :=\nX\n\nx2\ni - 2\nX\nbij xixj.\ni D\ni,j2D\nHint. It suffices to check the result for integers: xi = ni. First assume that ni ⊂ 0, and consider\nthe space W of representations V of Q such that dimVi = ni. Show that the group\ni GLni (k) acts\nwith finitely many orbits on W k, and use Problem 5.2 to derive the inequality. Then\n⎛\ndeduce the\nresult in the case when ni are arbitrary integers.\n(b) Deduce that q is a positive definite quadratic form.\nHint. Use the fact that Q is dense in R.\n(c) Show that a quiver of finite type can have no self-loops. Then, using Problem 5.3, deduce\nthe theorem.\nProblem 5.5. Let G = 1 be a finite subgroup of SU(2), and V be the 2-dimensional representation\nof G coming from its embedding into SU(2). Let Vi, i 2 I, be all the irreducible representations of\nG. Let rij be the multiplicity of Vi in V\nVj.\n(a) Show that rij = rji.\n(b) The McKay graph of G, M(G), is the graph whose vertices are labeled by i 2 I, and i is\nconnected to j by rij edges. Show that M(G) is connected. (Use Problem 3.26)\n(c) Show that M(G) is an affine Dynkin graph (one of the \"forbidden\" graphs in Problem 5.3).\nFor this, show that the matrix aij = 2ζij - rij is positive semidefinite but not definite, and use\nProblem 5.3.\nHint. Let f = ⎨ xiνVi , where νVi be the characters of Vi. Show directly that ((2-νV )f, f) ⊂ 0.\nWhen is it equal to 0? Next, show that M(G) has no self-loops, by using that if G is not cyclic\nthen G contains the central element -Id 2 SU(2).\n\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n(d) Which groups from Problem 3.24 correspond to which diagrams?\n(e) Using the McKay graph, find the dimensions of irreducible representations of all finite\nG →SU(2) (namely, show that they are the numbers labeling the vertices of the affine Dynkin\ndiagrams on our pictures). Compare with the results on subgroups of SO(3) we obtained in\nProblem 3.24.\n5.2\nIndecomposable representations of the quivers A1, A2, A3\nWe have seen that a central question about representations of quivers is whether a certain connected\nquiver has only finitely many indecomposable representations. In the previous subsection it is shown\nthat only those quivers whose underlying undirected graph is a Dynkin diagram may have this\nproperty. To see if they actually do have this property, we first explicitly decompose representations\nof certain easy quivers.\nRemark 5.6. By an object of the type 1\n0 we mean a map from a one-dimensional vector\nspace to the zero space. Similarly, an object of the type 0\n1 is a map from the zero space into\na one-dimensional space. The object 1\n1 means an isomorphism from a one-dimensional to\nanother one-dimensional space. The numbers in such diagrams always mean the dimension of the\nattached spaces and the maps are the canonical maps (unless specified otherwise)\nExample 5.7 (A1). The quiver A1 consists of a single vertex and has no edges. Since a repre\nsentation of this quiver is just a single vector space, the only indecomposable representation is the\nground field (=a one-dimensional space).\nExample 5.8 (A2). The quiver A2 consists of two vertices connected by a single edge.\n\nA representation of this quiver consists of two vector spaces V, W and an operator A : V ⊃ W .\n-\nA\nV\nW-\n\nTo decompose this representation, we first let V 0 be a complement to the kernel of A in V and\nlet W 0 be a complement to the image of A in W . Then we can decompose the representation as\nfollows\nA\n\nV-\nA\nW-\n=\ns\n\nker-\n\nA\n-0 -0\nV\nIm-A -0\nW\n- 0\nThe first summand is a multiple of the object 1\n0 , the second a multiple of 1\n1 , the\nthird of 0\n1 . We see that the quiver A2 has three indecomposable representations, namely\n0 ,\nand\n1 .\nExample 5.9 (A3). The quiver A3 consists of three vertices and two connections between them.\nSo we have to choose between two possible orientations.\n\nor\n1. We first look at the orientation\n\n- .\n/\n/\n/\n/\n/ o\n/\n/\n\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\nThen a representation of this quiver looks like\n-\nA\n\nV\nW-\nB\n.\nY-\nLike in Example 5.8 we first split away\n\nker- A\n0-\n0- .\n\nThis object is a multiple of 1\n0 . Next, let Y 0 be a complement of ImB in Y .\nThen we can also split away\n\n0-\n0-\n\nY-0\nwhich is a multiple of the object 0\n1 . This results in a situation where the map\nA is injective and the map B is surjective (we rename the spaces to simplify notation):\n\n-\nA\n\n-\nB\n- .\nV\nW\nY\nNext, let X = ker(B inf A) and let X0 be a\n\ncomplement of X in V . Let W 0 be a complement\nof A(X) in W such that A(X0) → W 0. Then we get\n\n-\nA\n\nB\n\nA\n\nB\n\n=\n-\n-\nA\n\nB\n\nV\nW\nY\nX\nA(X)\nW 0\nX\nY\n\nThe first of these summands is a multiple of 1 s\n0 . Looking at the second summand,\nwe now have a situation where A is injective, B is surjective and furthermore ker(B inf A) = 0.\nTo simplify notation, we redefine\nV = X0, W = W 0.\nNext we let X = Im(B infA) and let X0 be a complement of X in Y . Furthermore, let\nW 0 = B-1(X0). Then W 0 is a complement of A(V ) in W . This yields the decomposition\n\n-\nA\n\nB\nA\nB\ns\n\n-\n\nB\n\ns\n\n=\nV\nW\nY\nV\nX\nW 0\n\nX0\n\nA(-V )\nHere, the first summand is a\n\nmultiple of 1 s 1 s 1 . By splitting away the kernel of B,\nthe\ne\n\nsecond summand can b decomposed into multiples of 0\n1 s 1 and 0\n0 .\nSo, on the whole, this quiver has six indecomposable representations:\n0 ,\n\n1 ,\n1 s 1\n0 ,\n\n1 s\n1 s 1 ,\n1 s 1 ,\n2. Now we look at the orientation\n-\n-\n- .\nVery similarly to the other orientation, we can split away objects of the type\n0 ,\nwhich results in a situation where both A and B are injective:\n\n-\nA\n\nV\nW-\nB\nY- .\n\n/\n/\n/\n/\n/\n/\n/\n/ /\n/\n/ /\n/\n/\n/\n/ /\n/\n/\n/ /\n/ o\n\n_\n\nBy identifying V and Y as subspaces of W , this leads to the problem of classifying pairs of\nsubspaces of a given space W up to isomorphism (the pair of subspaces problem). To do\nso, we\n\nfirst choose a complement W\nof V ∈ in W , and set V 0 = W 0 ∈\n\nY\nV , Y 0 = W 0 ∈ Y .\nThen we can decompose the representation as follows:\n\n-\n-\n-\n=\n\nV\nW\n-\n\n-\n\ns\n\nY\nV\nW-\n\nY 0\nV - Y\nV -\ns\n\n.\n∈\n∈ Y\nV -∈ Y\nThe second summand is a multiple of the object 1 s 1\ns 1 . We go on decomposing the\nfirst summand. Again, to simplify notation, we let\nV = V 0, W = W 0, Y = Y 0.\nWe can now\n\n0. Next, let\nassume that V ∈ Y =\nW be a complement of V Y in W . Then\nwe get\n\n-\n=\nV\nW-\nY-\n\nV-\nV - Y\nY-\n\n-0\nW- 0\n-\n\nThe second of these summands is a multiple of the indecomposable object 0\n0 .\nThe first summand can be further decomposed as follows:\n\n-\n-\n-\n= -\ns\n\nV\nV\nY\nY\nV\n\ns\n\n-\n-\n0-\n\nV\nY-\nY-\nThese summands are multiples of\n0 ,\nSo - like in the other orientation - we get 6 indecomposable representations of A3:\ns\ns\n0 ,\n1 ,\n1 ,\n0 ,\n0 ,\n5.3\nIndecomposable representations of the quiver D4\nAs a last - slightly more complicated - example we consider the quiver D4.\nExample 5.10 (D4). We restrict ourselves to the orientation\n-\n-\n\n- .\n-\nSo a representation of this quiver looks like\nA1\nV\n-\n-\nA3\n\nV1\nV\n-\nA2\n\nV\n-\n\n/\no\n? _\n\n/\no\n? _\n/ o\n\n_\n\n_\n\n/\no\n? _\n/ o\n/ o\n/\noO\n/\noO\n?\n\nThe first thing we can do is - as usual - split away the kernels of the maps A1, A2, A3. More\nprecisely, we split away the representations\n-\n-\n-\n\nker\n-\n\nA1\n-\n-\n\n-\n-\nker\n-\nA3\n\n-\n\nker\n-\nA2\n-\n\nThese representations are multiples of the indecomposable objects\n-\n-\n-\n-\n-\n-\n-\n-\n\n-\n-\n-\n-\nSo we get to a situation where all of the maps A1, A2, A3 are injective.\n\n-\nA1\nV\n\nA3 -\nV\n-\nV3\nA2\n\nV\n-\nAs in 2, we can then identify the spaces V1, V2, V3 with subspaces of V . So we get to the triple of\nsubspaces problem of classifying a triple of subspaces of a given space V .\nThe next step is to split away a multiple of\n-\n\n-\n-\n-\n\nto reach a situation where\nV1 + V2 + V3 = V.\nBy letting Y =\n\nV1 ∈ V2 ∈ V3, choosing a complement V 0 of Y in V , and setting Vi\n0 = V 0 ∈ Vi,\ni = 1, 2, 3, we can decompose this representation into\n\nV 0\n\ns Y\ns\n-\n-\n-\n\nV 1\nV 3\nY\n-\n-\nY\n-\n\n-\n\nV 2\nY\n-\n\nThe last summand is a multiple of the indecomposable representation\ns\ns\n\n-\n-\n-\n\n-\n\n/\no\n/\no\n/\no\nO\nO\nO\nO\nO\nO\n\n_\n/\no\n?\nO\n?\n/\noO\n?\nO\nO\nO\nO\nO\n\n_\n\nSo - considering the first summand and renaming the spaces to simplify notation - we are in a\nsituation where\nV = V1 + V2 + V3,\nV1 ∈ V2 ∈ V3 = 0.\nAs a next step, we let Y = V1 ∈ V2 and we choose a complement V 0 of Y in V such that V3\n\n→ V 0,\nand set V 1\n0 = V 0 ∈ V1, V2\n0 = V 0 ∈ V2. This yields the decomposition\n\nV\n\nV 0\n\ns Y\n\nV\n-\n-\nV\n-\nV\n-\n-\n\n-\n\n-\n\nV\n-\nY\n-\n\n=\n\n-\n-\n-\nV2\nV 2\nY\nThe second summand is a multiple of the indecomposable object\ns\n-\n-\n- .\n\n-\nIn the resulting situation we have V1 ∈ V2 = 0. Similarly we can split away multiples of\ns\ns\ns\n-\n-\n-\n-\n-\n-\nand\n\n-\n-\n\nto reach a situation where the spaces V1, V2, V3 do not intersect pairwise\nV1 ∈ V2 = V1 ∈ V3 = V2 ∈ V3 = 0.\nIf V1 * V2 V3 we let Y = V1 ∈ (V2 V3). We let V1\n0 be a complement of Y in V1. Since then\n\nV1\n0 ∈ (V2 V3) = 0, we can select a complement V 0 of V 1\nin V which contains V2 V3. This gives\nus the decomposition\n\nV\n\nV 0\n\n-\n\nV1\nV\n-\ns\nV\n-\nV\n-\n-1\n\n-\n\nY\n-\n\n-\nV\n-\n=\n\n-\nV2\n-\nV\n-\nThe first of these summands is a multiple of\ns\n1 -\n-\n-\n\n-\n\nBy splitting these away we get to a situation where V1 ∧ V2 V3. Similarly, we can split away\nobjects of the type\n\ns\n-\n-\n-\n-\n-\n-\n\nand\n-\n-\nto reach a situation in which the following conditions hold\n\n?\n?\nO\nO\nO\nO\nO\nO\nO\n?\n?\nO\nO\n\nO\n/\no\n/\no\nO\nO\n\n_\n\n_\nO\n\n_\n\n_\nO\n\n1. V1 + V2 + V3 = V.\n2. V1 ∈ V2 = 0,\nV1 ∈ V3 = 0,\nV2 ∈ V3 = 0.\n3. V1 ∧ V2 V3,\nV2 ∧ V1 V3,\nV3 ∧ V1 V2.\nBut this implies that\nV1 V2 = V1 V3 = V2 V3 = V.\nSo we get\ndim V1 = dim V2 = dim V3 = n\nand\ndim V = 2n.\nSince V3 ∧ V1 V2 we can write every element of V3 in the form\nx 2 V3,\nx = (x1, x2), x1 2 V1, x2 2 V2.\nWe then can define the projections\nB1 : V3 ⊃ V1,\n(x1, x2) 7⊃ x1,\nB2 : V3 ⊃ V2,\n(x1, x2) 7⊃ x2.\nSince V3 ∈ V1 = 0, V3 ∈ V2 = 0, these maps have to be injective and therefore are isomorphisms. We\nthen define the isomorphism\n\n-1\nA = B2 infB1 : V1 ⊃ V2.\nLet e1, . . . , en be a basis for V1. Then we get\nV1 = C e1 C e2 · · · C en\nV2 = C Ae1 C Ae2 · · · C Aen\nV3 = C (e1 + Ae1) C (e2 + Ae2) · · · C (en + Aen).\nSo we can think of V3 as the graph of an isomorphism A : V1 ⊃ V2. From this we obtain the\ndecomposition\n\nV\n\nC2\n-\n\nV\n-\nM\nn\n-\nV\n\nC(1\n-\n, 0)\n-\nC(1\n-\n, 1)\n=\n\n-\nj=1\nV2\nC(0\n-\n, 1)\nThese correspond to the indecomposable object\n\n-\n\n-\n\n-\n\n-\nThus the quiver D4 with the selected orientation has 12 indecomposable objects. If one were to\nexplicitly decompose representations for the other possible orientations, one would also find 12\nindecomposable objects.\nIt appears as if the number of indecomposable representations does not depend on the orienta\ntion of the edges, and indeed - Gabriel's theorem will generalize this observation.\n\n_\n\n_\nO/\no\n\n?\n?\n?\n?\n\n5.4\nRoots\nFrom now on, let be a fixed graph of type An, Dn, E6, E7, E8. We denote the adjacency matrix\nof by R.\nDefinition 5.11 (Cartan Matrix). We define the Cartan matrix as\nA = 2Id - R.\nOn\n\nthe lattice Zn (or the space Rn) we then define an inner product\n\nB(x, y) = x T Ay\ncorresponding to the graph .\nLemma 5.12.\n1. B is positive definite.\n2. B(x, x) takes only even values\n\nfor x 2 Zn.\nProof.\n1. This follows by definition, since is a Dynkin diagram.\n2. By the definition of the Cartan matrix we get\n\nB(x, x) = x T Ax =\nX\nxi aij xj = 2\nX\nx2\ni +\nX\nxi aij xj = 2\nX\nx2\ni + 2 ·\ni,j\nX\naij xixj\n\ni\ni,j, i=j\ni\ni<j\nwhich is even.\nz}|{\nDefinition 5.13. A root with respect to a certain positive inner product is a shortest (with respect\n\nto this inner product), nonzero vector in Zn.\nSo for the inner product B, a root\n\nis a nonzero vector x 2 Zn such that\nB(x, x) = 2.\nRemark 5.14. There can be only finitely many roots, since all of them have to lie in some ball.\nDefinition 5.15. We call vectors of the form\ni-th\nφi = (0, . . . , 1 , . . . , 0)\nsimple roots.\nThe\n\nφi naturally form a basis of the lattice Zn.\nLemma 5.16. Let φ\n\nbe a root, φ = ⎨n\ni=1 kiφi. Then either ki ⊂ 0 for all i or ki ∗ 0 for all i.\nProof. Assume the contrary, i.e., ki > 0, kj < 0. Without loss of generality, we can also assume\nthat ks = 0 for all s between i and j. We can identify the indices i, j with vertices of the graph .\nρ\ni0\n-\n-\ni\n-\n-\n-j\n-\n-\n-\n\nNext, let φ be the edge connecting i with the\n\nnext vertex towards j and i0 be the vertex on the other\nend of φ. We then let 1, 2 be the graphs obtained from by removing φ. Since is supposed\nto be a Dynkin diagram - and therefore has no cycles or loops - both 1 and 2 will be connected\ngraphs, which are not connected to each other.\n-\n-\ni\n-\n-\n-j\n-\n-\n-\nThen we have i 2 1, j 2 2. We define\n\n=\nX\n\nα\nkmφm,\nρ =\nX\nkmφm.\nm21\nm22\nWith this choice we get\nφ = α + ρ.\nSince ki > 0, kj < 0 we know that α = 0, ρ = 0 and therefore\nB(α, α) ⊂ 2,\nB(ρ, ρ) ⊂ 2.\nFurthermore,\nB(α, ρ) = -kiki⊗ ,\nsince 1, 2 are only connected at φ. But this has to be a nonnegative number, since ki > 0 and\nki⊗ ∗ 0. This yields\nB(φ, φ) = B(α + ρ, α + ρ) = B(α, α) +2 B(α, ρ) +\n| {z\nB(ρ, ρ) ⊂ 4.\n\n∧2\n}\n|\n∧\n{z\n}\n|\n∧\n{z\n}\nBut this is a contradiction, since φ was assumed to be a root.\nDefinition 5.17. We call a root φ = ⎨\ni kiφi a positive root if all ki ⊂ 0. A root for which ki ∗ 0\nfor all i is called a negative root.\nRemark 5.18. Lemma 5.16 states that every root is either positive or negative.\nExample 5.19.\n1. Let\nThen\n\nbe of the type AN\n1.\nthe lattice L = ZN-1 can be realized as\n-\na subgroup\n\nthe lattice ZN\nof\nby letting L ∧ ZN be the subgroup of all vectors (x1, . . . , xN )\nsuch that\nX\nxi = 0.\ni\nThe vectors\nφ1 = (1, -1, 0, . . . , 0)\nφ2 = (0, 1, -1, 0, . . . , 0)\n. . .\nφN\n1 = (0, . . . , 0, 1, 1)\n-\n-\n\nnaturally form a basis of L. Furthermore, the standard inner product\n\n(x, y) =\nX\nxiyi\n⇒\n⇒\n\non ZN restricts to the inner product B given by on L, since it takes the same values on the\nbasis vectors:\n(φ\n\ni, φi) = 2\n-1 i, j adjacent\n(φi, φj ) =\notherwise\nThis means that vectors of the form\n(0, . . . , 0, 1, 0, . . . , 0, -1, 0, . . . , 0) = φi + φi+1 + · · · + φj-1\nand\n(0, . . . , 0, -1, 0, . . . , 0, 1, 0, . . . , 0) = -(φi + φi+1 + · · · + φj\n)\n-1\nare the roots of L. Therefore the number of positive roots in L equals\nN(N - 1) .\n2. As a fact we also state the number of positive roots in the other Dynkin diagrams:\nDN\nN(N - 1)\nE6\n36 roots\nE7\n63 roots\nE8\n120 roots\nDefinition 5.20.\n\nLet φ 2 Zn be a positive root. The reflection s is defined by the formula\ns(v) = v - B(v, φ)φ.\nWe denote si by si and call these simple reflections.\nRemark 5.21. As a linear operator of Rn , s fixes any vector orthogonal to φ and\ns(φ) = -φ\nTherefore s is the reflection at the hyperplane orthogonal to φ, and in particular fixes B. The\nsi generate a subgroup W ∧ O(Rn), which is called the Weyl group of . Since for every w 2 W ,\nw(φi) is a root, and since there are only finitely many roots, W has to be finite.\n5.5\nGabriel's theorem\nDefinition 5.22. Let Q be a quiver with any labeling 1, . . . , n of the vertices. Let V = (V1, . . . , Vn)\nbe a representation of Q. We then call\nd(V ) = (dim V1, . . . , dim Vn)\nthe dimension vector of this representation.\nWe are now able to formulate Gabriel's theorem using roots.\nTheorem 5.23 (Gabriel's theorem). Let Q be a quiver of type An, Dn, E6, E7, E8. Then Q has\nfinitely many indecomposable representations. Namely, the dimension vector of any indecomposable\nrepresentation is a positive root (with respect to B) and for any positive root φ there is exactly\none indecomposable representation with dimension vector φ.\n\n5.6\nReflection Functors\nDefinition 5.24. Let Q be any quiver. We call a vertex i 2 Q a sink if all edges connected to i\npoint towards i.\ni\n-\n\nWe call a vertex i 2 Q a source if all edges connected to i point away from i.\ni\n\n-\n\nDefinition 5.25. Let Q be any quiver and i 2 Q be a sink (a source). Then we let Qi be the\nquiver obtained from Q by reversing all arrows pointing into (pointing out of) i.\nWe are now able to define the reflection functors (also called Coxeter functors).\nDefinition 5.26. Let Q be a quiver, i 2 Q be a sink. Let V be a representation of Q. Then we\ndefine the reflection functor\nF +\ni : RepQ ⊃ RepQi\nby the rule\nF +\ni (V )k = Vk\nif k = i\n\nF +\ni (V )i = ker\n⎧\n@ ' :\nM\nVj ⊃ Vi\n⎝ .\nj⊥i\nAlso, all maps stay the same but those now pointing out of i; these are replaced by compositions\nof the inclusion of ker ' into Vj with the projections Vj ⊃ Vk.\nDefinition 5.27. Let Q be a quiver, i 2 Q be a source. Let V be a representation of Q. Let ξ be\nthe canonical map\nM\nξ : Vi ⊃\nVj .\ni⊥j\nThen we define the reflection functor\nFi\n- : RepQ ⊃ RepQi\nby the rule\nFi\n-(V )k = Vk\nif k = i\n\nFi\n-(V )i = Coker (ξ) =\n⎧\n@M\nVj\n⎝\n\n/Imξ.\ni⊥j\nAgain, all maps stay the same but those now pointing into i; these are replaced by the compositions\nof the inclusions Vk ⊃i\njVj with the natural map\n⊥\nVj ⊃Vj/Imξ.\nProposition 5.28. Let Q be a quiver, V an indecomposable representation of Q.\n/\noO\no\n/\n\n1. Let i 2 Q be a sink. Then either dim Vi = 1, dim Vj = 0 for j = i or\n' :\nM\nVj ⊃ Vi\nj⊥i\nis surjective.\n2. Let i 2 Q be a source. Then either dim Vi = 1, dim Vj = 0 for j = i or\n\nξ : Vi ⊃\nM\nVj\ni⊥j\nis injective.\nProof.\n1. Choose a complement W of Im'. Then we get\nW\n\n-\n-\n\n-\n\nV\n=\n\nV\n-\nSince V is indecomposable, one of these summands has to be zero. If the first summand is\nzero, then ' has to be surjective. If the second summand is zero, then the first one has to be\nof the desired form, because else we could write it as a direct sum of several objects of the\ntype\n-\n\n-\n-\n-\nwhich is impossible, since V was supposed to be indecomposable.\n2. Follows similarly by splitting away the kernel of ξ.\nProposition 5.29. Let Q be a quiver, V be a representation of Q.\n1. If\n' :\nM\nVj ⊃ Vi\nj⊥i\nis surjective, then\nFi\n-F +\ni V = V.\n2. If\nξ : Vi ⊃\nM\nVj\ni⊥j\nis injective, then\nF +\ni Fi\n-V = V.\nProof. In the following proof, we will always mean by i ⊃ j that i points into j in the original\nquiver Q. We only establish the first statement and we also restrict ourselves to showing that the\nspaces of V and Fi\n-F +\ni V are the same. It is enough to do so for the i-th space. Let\n\n' :\nM\nVj ⊃ Vi\nj⊥i\nO/\no\nO/\no\n⇒\n⇒\n\nbe surjective and let\nK = ker '.\nWhen applying F +\ni , the space Vi gets replaced by K. Furthermore, let\n\nξ : K ⊃\nM\nVj .\nj⊥i\nAfter applying Fi\n-, K gets replaced by\nK0 =\n⎧\nM\nV\n@\nj\nj⊥i\n⎝ /(Imξ).\nBut\nImξ = K\nand therefore\n\nK0 =\n⎧\nVj\n⎧\n@M\n\n⎝ / @ ker(' :\nM\nVj ⊃ Vi)\n\n⎝= Im(' :\nM\nVj ⊃ Vi)\nj⊥i\nj⊥i\nj⊥i\nby the homomorphism theorem. Since ' was assumed to be surjective, we get\nK0 = Vi.\nProposition 5.30. Let Q be a quiver, and V be an indecomposable representation of Q. Then\nF +\ni V and Fi\n-V (whenever defined) are either indecomposable or 0.\nProof. We prove the proposition for F +\ni V - the case Fi\n-V follows similarly. By Proposition 5.28 it\nfollows that either\n\n' :\nM\nVj\nj\ni\n⊃ Vi\n⊥\nis surjective or dim Vi = 1, dim Vj = 0,\nj = i. In the last case\nF +\ni V = 0.\nSo we can assume that ' is surjective. In this case, assume that F +\ni V is decomposable as\nF +\ni V = X Y\nwith X, Y = 0. But F +\ni V is injective at i, since the maps are canonical projections, whose direct\nsum is the tautological embedding. Therefore X and Y also have to be injective at i and hence (by\n5.29)\nF +F\n+\ni\ni\n-X = X,\nF i Fi\n-Y = Y\nIn particular\nFi\n-X = 0,\nFi\n-Y = 0.\nTherefore\nV = Fi\n-F +\ni V = Fi\n-X Fi\n-Y\nwhich is a contradiction, since V was assumed to be indecomposable. So we can infer that\nF +\ni V\nis indecomposable.\n⇒\n⇒\n⇒\n\nProposition 5.31. Let Q be a quiver and V a representation of Q.\n1. Let i 2 Q be a sink and let V be surjective at i. Then\nd(F +\ni V ) = si(d(V )).\n2. Let i 2 Q be a source and let V be injective at i. Then\nd(Fi\n-V ) = si(d(V )).\nProof. We only prove the first statement, the second one follows similarly. Let i 2 Q be a sink and\nlet\nM\n' :\nVj ⊃ Vi\nj⊥i\nbe surjective. Let K = ker '. Then\n\ndim K =\nX\ndim Vj - dim Vi.\nj⊥i\nTherefore we get\n⎩\nd(F +\ni V ) - d(V )\n\n=\nX\ndim Vj\n2 dim Vi =\nB (d(V ), φi)\ni\nj⊥i\n-\n-\nand\n⎩\n\nd(F +\ni V ) - d(V )\n\n= 0,\nj = i.\nj\nThis implies\nd(F +\ni V ) - d(V ) = -B (d(V ), φi) φi\n⊆\nd(F +\ni V ) = d(V ) - B (d(V ), φi) φi = si (d(V )) .\n5.7\nCoxeter elements\nDefinition 5.32. Let Q be a quiver and let be the underlying graph. Fix any labeling 1, . . . , n\nof the vertices of . Then the Coxeter element c of Q corresponding to this labeling is defined as\nc = s1s2 . . . sn.\nLemma 5.33. Let\n\nα =\nX\nkiφi\ni\nwith ki ⊂ 0 for all i but not all ki = 0. Then there is N 2 N, such that\n\nc Nα\nhas at least one strictly negative coefficient.\n⇒\n\nProof. c belongs to a finite group W . So there is M 2 N, such that\nc M = 1.\nWe claim that\n1 + c + c 2 + · · · c M-1\n+\n= 0\nas operators on Rn . This implies what we need, since α has at least one strictly positive coefficient,\nso one of the elements\ncα, c2α, . . . , cM-1α\nmust have at least one strictly negative one. Furthermore, it is enough to show that 1 is not an\neigenvalue for c, since\n(1 + c + c 2 + · · · + c M-1)v = w = 0\n\n≥\ncw = c 1 + c 2\n+ c + · · · + c M-1 v =\n(c + c + c + · · · + c M-1 + 1)v = w.\nAssume the contrary, i.e.,\n⎩\n1 is a eigenvalue of c\n\nand let v be a corresponding eigenvector.\ncv = v\n≥\ns1 . . . snv = v\n⊆\ns2 . . . snv = s1v.\nBut since si only changes the i-th coordinate of v, we get\ns1v = v and s2 . . . snv = v.\nRepeating the same procedure, we get\nsiv = v\nfor all i. But this means\nB(v, φi) = 0.\nfor all i, and since B is nondegenerate, we get v = 0. But this is a contradiction, since v is an\neigenvector.\n5.8\nProof of Gabriel's theorem\nLet V be an indecomposable representation of Q. We introduce a fixed labeling 1, . . . n on Q, such\nthat i < j if one can reach j from i. This is possible, since we can assign the highest label to any\nsink, remove this sink from the quiver, assign the next highest label to a sink of the remaining\nquiver and so on. This way we create a labeling of the desired kind.\nWe now consider the sequence\n(0)\n\n(1)\n+ (2)\n+\n+\nV\n= V, V\n= Fn V, V\n= Fn\nF\n-1\nn V, . . .\nThis sequence is well defined because of the selected labeling: n has to be a sink of Q, n - 1 has\nto be a sink of Qn (where Qn is obtained from Q by reversing all the arrows at the vertex r) and\nso on. Furthermore, we note that V (n) is a representation of Q again, since every arrow has been\nreversed twice (since we applied a reflection functor to every vertex). This implies that we can\ndefine\nV (n+1) = F +\nn V (n), . . .\nand continue the sequence to infinity.\n⇒\n\nTheorem 5.34. There is m 2 N, such that\nd\n\nV (m)\n= φp\nfor some p.\nProof. If V (i) is surjective at the appropriate vertex k, then\nd\n\nV (i+1)\n= d\n\nF +\nV (i)\n= s\n\nV (i)\nk\nkd\n\n.\n\nThis implies, that if V (0), . . . , V (i-1) are surjective at the appropriate vertices, then\nd\n\nV (i)\n= . . . sn-1snd(V ).\n\nBy Lemma 5.33 this cannot continue indefinitely - since d\n⎩\nV (i)\nmay not have any negative entries.\n\nLet i be smallest number such that V (i) is not surjective at the appropriate vertex. By Proposition\n5.30 it is indecomposable. So, by Proposition 5.28, we get\nd(V (i)) = φp\nfor some p.\nWe are now able to prove Gabriel's theorem. Namely, we get the following corollaries.\nCorollary 5.35. Let Q be a quiver, V be any indecomposable representation. Then d(V ) is a\npositive root.\nProof. By Theorem 5.34\nsi1 . . . sim (d(V )) = φp.\nSince the si preserve B, we get\nB(d(V ), d(V )) = B(φp, φp) = 2.\nCorollary 5.36. Let V, V 0 be indecomposable representations of Q such that d(V ) = d(V 0). Then\nV and V 0 are isomorphic.\nProof. Let i be such that\nd\n\n(i)\n\nV (i)\n= φp.\nThen we also get d\n⎩\nV 0\n\n= φp. So\nV 0(i) = V (i) =:\n\nV i.\nFurthermore we have\nV (i) = F + . . . F + F +V (0)\nk\nn-1\nn\n0(i)\n\nV\n\n= F +\nk . . . F +\nn-1F +\nn V 0(0).\nBut\n\nboth V (i-1), . . . , V (0) and V 0(i-1)\n\n, . . . , V 0(0) have to be surjective at the appropriate vertices.\nThis implies\n\n+\n+\n+\n(0)\n(0)\nF -F -\n. . . F -V i\nFn\n-F n\n-\n1 . . . F -F . . . F n\n1Fn V\n= V\n= V\n=\n-\nk\nk\nn\nn\n-\n-1\nk\n\nF\n\n+\nn\n-F -\n-1 . . . F k\n-F +\nk . . . F\n+\n(0)\n(0)\nn\nn\n1F\n-\nn V\n= V 0\n= V 0\n\nThese two corollaries show that there are only finitely many indecomposable representations\n(since there are only finitely many roots) and that the dimension vector of each of them is a positive\nroot. The last statement of Gabriel's theorem follows from\nCorollary 5.37. For every positive root φ, there is an indecomposable representation V with\nd(V ) = φ.\nProof. Consider the sequence\nsnφ, sn-1snφ, . . .\nConsider the first element of this sequence which is a negative root (this has to happen by Lemma\n5.33) and look at one step before that, calling this element α. So α is a positive root and siα is a\nnegative root for some i. But since the si only change one coordinate, we get\nα = φi\nand\n(sq . . . sn-1sn)φ = φi.\nWe let C(i) be the representation having dimension vector φi. Then we define\nV = Fn\n-F n\n-\n-1 . . . Fq\n-C(i).\nThis is an indecomposable representation and\nd(V ) = φ.\nExample 5.38. Let us demonstrate by example how reflection functors work. Consider the quiver\nD4 with the orientation of all arrows towards the node (which is labeled by 4). Start with the\n1-dimensional representation V4 sitting at the 4-th vertex. Apply to V4 the functor F3\n-F2\n-F1\n-.\nThis yields\nF1\n-F2\n-F3\n-V4 = V1+2+3+4 .\nNow applying F4\n-we get\nF4\n-F1\n-F2\n-F3\n-V4 = V1+2+3+24 .\nNote that this is exactly the inclusion of 3 lines into the plane, which is the most complicated\nindecomposable representation of the D4 quiver.\n5.9\nProblems\nProblem 5.39. Let Qn be the cyclic quiver of length n, i.e., n vertices connected by n oriented edges\nforming a cycle. Obviously, the classification of indecomposable representations of Q1 is given by\nthe Jordan normal form theorem. Obtain a similar classification of indecomposable representations\nof Q2. In other words, classify pairs of linear operators A : V ⊃ W and B : W ⊃ V up to\nisomorphism. Namely:\n(a) Consider the following pairs (for n ⊂ 1):\n1) En,: V =\n\nW = Cn, A is the Jordan block of size n with eigenvalue ∂, B = 1 (∂ 2 C).\n2) En,\n: is obtained from E\n≤\nn,0 by exchanging V with W and A with B.\n\n3) Hn: V = Cn with\n\nbasis vi, W = Cn-1 with basis wi, Avi = wi, Bwi = vi+1 for i < n, and\nAvn = 0.\n4) Kn is obtained from Hn by exchanging V with W and A with B.\nShow that these are indecomposable and pairwise nonisomorphic.\n(b) Show that if E is a representation of Q2 such that\n\nAB is not nilpotent, then E = E0 E00,\nwhere E00 = En, for some ∂ = 0.\n(c) Consider the case when AB is nilpotent, and consider the operator X on V W given\nby X(v, w) = (Bw, Av). Show that X is nilpotent, and admits a basis consisting of chains (i.e.,\nsequences u, Xu, X2u, ...Xl-1u where Xlu = 0) which are compatible with the direct sum decompo\nsition (i.e., for every chain u 2 V or u 2 W ). Deduce that (1)-(4) are the only indecomposable\nrepresentations of Q2.\n(d)(harder!) generalize this classification to the Kronecker quiver, which has two vertices 1 and\n2 and two edges both going from 1 to 2.\n(e)(still harder!) can you generalize this classification to Qn, n > 2, with any orientation?\nProblem 5.40. Let L\n→ Z8 be the lattice of vectors where the coordinates are either all integers\nor all half-integers (but not integers), and the sum of all coordinates is an even integer.\n\n-\n\n(a) Let φi = ei\nei+1, i = 1, ..., 6, φ7 = e6 + e7, φ8 = -1/2 ⎨\ni=1 ei. Show that φi are a basis\nof L (over Z).\n(b) Show that roots in L (under the usual inner product) form a root system of type E8 (compute\nthe inner products of φi).\n(c) Show that the E7 and E6 lattices can be obtained as the sets of vectors in the E8 lattice L\nwhere the first two, respectively three, coordinates (in the basis ei) are equal.\n(d) Show that E6, E7, E8 have 72,126,240 roots, respectively (enumerate types of roots in terms\nof the presentations in the basis ei, and count the roots of each type).\nProblem 5.41. Let V be the indecomposable representation of a Dynkin quiver Q which corre\nsponds to a positive root φ. For instance, if φi is a simple root, then Vi has a 1-dimensional space\nat i and 0 everywhere else.\n(a) Show that if i is a source then Ext1(V, Vi ) = 0 for any representation V of Q, and if i is\na sink, then Ext1(Vi , V ) = 0.\n(b) Given an orientation of the quiver, find a Jordan-H older series of V for that orientation.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n18.712 Introduction to Representation Theory\nFall 2010"
    },
    {
      "category": "Resource",
      "title": "Representations of finite groups: basic results",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/0abca81c8a50d3d529fa0fc3d3e5319a_MIT18_712F10_ch3.pdf",
      "content": "Representations of finite groups: basic results\nRecall that a representation of a group G over a field k is a k-vector space V together with a\ngroup homomorphism δ : G ⊃ GL(V ). As we have explained above, a representation of a group G\nover k is the same thing as a representation of its group algebra k[G].\nIn this section, we begin a systematic development of representation theory of finite groups.\n3.1\nMaschke's Theorem\nTheorem 3.1. (Maschke) Let G be a finite group and k a field whose characteristic does not divide\n|G|. Then:\n(i) The algebra k[G] is semisimple.\n(ii) There is an isomorphism of algebras ξ : k[G] ⊃iEndVi defined by g 7⊃ ig|Vi , where Vi\nare the irreducible representations of G. In particular, this is an isomorphism of representations\nof G (where G acts on both sides by left multiplication). Hence, the regular representation k[G]\ndecomposes into irreducibles as i dim(Vi)Vi, and one has\nG =\nX\n| |\n\ndim(Vi)2.\ni\n(the \"sum of squares formula\").\nProof. By Proposition 2.16, (i) implies (ii), and to prove (i), it is sufficient to show that if V is\na finite-dimensional representation of G and W →V is any subrepresentation, then there exists a\nsubrepresentation W 0 → V such that V = W W 0 as representations.\nChoose any complement ˆW of W in\nˆ\nV . (Thus V = W W as vector spaces, but not necessarily\nˆ\nas representations.) Let P be the projection along W onto W , i.e., the operator on V defined by\nP |W = Id and P | ˆ = 0. Let\nW\nP :=\nX\nδ(g)Pδ(g-1),\n|G| g2G\nwhere δ(g) is the action of g on V , and let\nW 0 = ker P.\n\nNow P |W = Id and P (V ) ∧ W , so\nP\n= P , so P is a projection along W 0. Thus, V =\n\nW W 0 as\nvector spaces.\nMoreover, for any h 2 G and any y 2 W 0,\nX\n\nPδ(h y =\nδ(g) δ(g-1\n)\nP\nh)y =\nδ(hσ)Pδ(σ-1)y = δ(h)P y = 0,\n|G| g2G\n|G| φ\nX\n2G\nso δ(h)y 2 ker P\n\n= W 0. Thus, W 0 is invariant under the action of G and is therefore a subrepre\nsentation of V . Thus, V = W W 0 is the desired decomposition into subrepresentations.\nThe converse to Theorem 3.1(i) also holds.\nProposition 3.2. If k[G] is semisimple, then the characteristic of k does not divide |G|.\n\nr\nProof. Write k[G] = L\ni=1 End Vi, where the Vi are irreducible representations and V1 = k is the\ntrivial one-dimensional representation. Then\nk[G] = k\nM\nr\nr\nEnd Vi = k\nM\ndiVi,\ni=2\ni=2\nwhere di = dim Vi. By Schur's Lemma,\nHomk[G](k, k[G]) = kΓ\nHomk[G](k[G], k) = kφ,\nfor nonzero homomorphisms of representations φ : k[G] ⊃ k and Γ : k ⊃ k[G] unique up to scaling.\n\nWe can take φ such that φ(g) = 1 for all g 2 G, and Γ such that Γ(1) = ⎨\ng2G g. Then\nφ inf Γ(1) = φ\nX\n\ng\n\n=\nX\n1 = |G|.\ng2G\ng2G\nIf |G| = 0, then Γ has no left inverse, as (aφ) inf Γ(1) = 0 for any a 2 k. This is a contradiction.\nExample 3.3. If G = Z/pZ and k has characteristic p, then every irreducible representation of G\nover k is trivial (so k[Z/pZ] indeed is not semisimple). Indeed, an irreducible representation of this\ngroup is a 1-dimensional space, on which the generator acts by a p-th root of unity, and every p-th\nroot of\n\nunity in k equals 1, as xp - 1 = (x - 1)p over k.\nProblem 3.4.\n\nLet G be a group of order pn. Show that every irreducible representation of G over\na field k of characteristic p is trivial.\n3.2\nCharacters\nIf V is a finite-dimensional representation of a finite group G, then its character νV : G ⊃ k\nis defined by the formula νV (g) = tr|V (δ(g)). Obviously, νV (g) is simply the restriction of the\ncharacter νV (a) of V as a representation of the algebra A = k[G] to the basis G →A, so it carries\nexactly the same information. The character is a central or class function: νV (g) depends only on\nthe conjugacy class of g; i.e., ν\nV (hgh-) = νV (g).\nTheorem 3.5. If the characteristic of k does not divide |G|, characters of irreducible representa\ntions of G form a basis in the space Fc(G, k) of class functions on G.\nProof. By the Maschke theorem, k[G] is semisimple, so by Theorem 2.17, the characters are linearly\nindependent and are a basis of (A/[A, A])⊕, where A = k[G]. It suffices to note that, as vector\nspaces over k,\n\n(A/[A, A])⊕∪= {' 2 Homk(k[G], k) | gh - hg 2 ker ' ⊕g, h 2 G}\n=∪ {f 2 Fun(G, k) | f(gh) = f(hg) ⊕g, h 2 G},\nwhich is precisely Fc(G, k).\nCorollary 3.6. The number of isomorphism classes of irreducible representations of G equals the\nnumber of conjugacy classes of G (if |G| = 0 in k).\n⇒\n\nExercise. Show that if |G | = 0 in k then the number of isomorphism classes of irreducible\nrepresentations of G over k is strictly less than the number of conjugacy classes in G.\n\nHint. Let P = ⎨\n\ng G g 2 k[G]. Then P 2 = 0. So P has zero trace in every finite dimensional\nrepresentation of G over k.\nCorollary 3.7. Any representation of G is determined by its character if k has characteristic 0;\nnamely, νV = νW implies V ∪= W .\n3.3\nExamples\nThe following are examples of representations of finite groups over C.\n1. Finite\n\nabelian groups G = Zn1 × · · · × Znk . Let G∗be the set of irreducible representations\nof G. Every element of G forms a conjugacy class, so |G∗| = |G|. Recall that all irreducible\nrepresentations over C (and algebraically closed fields in general) of commutative algebras and\ngroups are one-dimensional. Thus, G∗ is an abelian group: if δ1, δ2 : G\n\n⊃ C× are irreducible\nrepresentations then so are δ1(g)δ2(g) and δ1(g)-1. G∗ is called the dual or character group\nof G.\nFor given n ⊂ 1, define δ : Zn ⊃ C× by δ(m) = e2νim/n. Then Z∗\nn = {δk : k = 0, . . . , n - 1},\nso Z∗\nn =∪ Zn. In general,\n×\n× · · · ×\n∗\n(G1\nG2\nGn)\n= G1\n∗\n× G∗\n2 × · · · × G∗\nn ,\nso G∗ =∪ G for any finite abelian group G. This isomorphism is, however, noncanonical:\nthe particular decomposition of G as Zn1 × · · · × Znk is not unique as far as which elements\nof G correspond to Zn1 , etc. is concerned. On\n=\n∗\n\nthe other hand, G ∪ (G )∗is a canonical\nisomorphism, given by ' : G ⊃ (G∗)∗, where '(g)(ν) = ν(g).\n2. The symmetric group S3. In Sn, conjugacy classes are determined by cycle decomposition\nsizes: two permutations are conjugate if and only if they have the same number of cycles\nof each length. For S3, there are 3 conjugacy classes, so there are 3 different irreducible\n\nrepresentations over C. If their dimensions are d1, d2, d\n3, then d1+d2 +d3 = 6, so S3 must have\ntwo 1-dimensional and one 2-dimensional representations. The 1-dimensional representations\nare the trivial representation C+ given by δ(ε) = 1 and the sign representation C\ngiven by\nδ(ε)\n(-\n\n-\n=\n1)ε.\nThe 2-dimensional representation can be visualized as representing the symmetries of the\nequilateral triangle with vertices 1, 2, 3 at the points (cos 120∨, sin 120∨), (cos 240∨, sin 240∨),\n(1, 0) of the coordinate plane, respectively. Thus, for example,\n\ncos 120∨\nsin 120∨\nδ((12)) =\n\n,\nδ((123)) =\n-\n-\n\n.\n\nsin 120∨\ncos 120∨\nTo show that this representation is irreducible, consider any subrepresentation V . V must be\nthe span of a subset of the eigenvectors of δ((12)), which are the nonzero multiples of (1, 0)\nand (0, 1). V must also be the span of a subset of the eigenvectors of δ((123)), which are\ndifferent vectors. Thus,\n\nV must be either C2 or 0.\n3. The quaternion group Q8 = {±1, ±i, ±j, ±k}, with defining relations\ni = jk = -kj,\nj\n\n= ki = -ik,\nk = ij = -\n\nji,\n-1 = i2 = j2 = k2.\n\nThe 5 conjugacy classes are {1}, {-1}, {±i}, {±j}, {±k}, so there are 5 different irreducible\nrepresentations, the sum of the squares of whose dimensions is 8, so their dimensions must\nbe 1, 1, 1, 1, and 2.\nThe center Z(Q8) is {±1}, and Q8/Z(Q8) =∪ Z2 × Z2. The four 1-dimensional irreducible\nrepresentations of Z2 × Z2 can be \"pulled back\" to Q8. That is, if q : Q8 ⊃ Q8/Z(Q8) is the\nquotient map, and δ any representation of Q8/Z(Q8), then δ inf q gives a representation of Q8.\nThe 2-dimensional representation is V = C2, given by δ(-1) = -Id and\nδ(i) = -1 0\n\n∀\n\n∀\n\n-\n,\nδ(j) =\n,\nδ(k) =\n-\n-\n.\n(3)\n∀\n-\n-1\n\n∀\n-\n-1\n\nThese are the Pauli matrices, which arise in quantum mechanics.\nExercise. Show that the 2-dimensional irreducible representation of Q8 can be realized in\nthe space of functions f : Q8 ⊃ C such that f(gi) = ∀-1f(g) (the action of G is by right\nmultiplication, g inf f(x) = f(xg)).\n4. The symmetric group S4.\nThe order of S4 is 24, and there are 5 conjugacy classes:\ne, (12), (123), (1234), (12)(34). Thus the sum of the squares of the dimensions of 5 irreducible\nrepresentations is 24. As with S3, there are two of dimension 1: the trivial and sign repre\nsentations, C+ and C . The other three must then have dimensions 2, 3, and 3. Because\n-\nS3 ∪= S4/Z2 × Z2, where Z2 × Z2 is {e, (12)(34), (13)(24), (14)(23)}, the 2-dimensional repre\nsentation of S3 can be pulled back to the 2-dimensional representation of S4, which we will\ncall C2 .\nWe can consider S4 as the group of rotations of a cube acting by permuting the interior\ndiagonals (or, equivalently, on a regular octahedron permuting pairs of opposite faces); this\ngives the 3-dimensional representation C3\n+.\nThe\n\nlast 3-dimensional representation is C3 , the product of C3 with the sign representation.\n-\n+\nC3\n+ and C3 are different,\n\nfor if g is a transposition, det g| C3 = 1 while det g|\n= ( 1)3\nC3\n-\n=\n1.\n-\n+\n-\n-\nNote that another realization of C3\nis by action of S4 by symmetries (not necessarily rotations)\n-\nof the regular tetrahedron. Yet another realization of this representation is the space of\nfunctions on the set of 4 elements (on which S4 acts by permutations) with zero sum of\nvalues.\n.4\nDuals and tensor products of representations\nf V is a\n\nrepresentation of a group G, then V ⊕is also a representation, via\n\nδV (g) = (δV (g)⊕)-1 = (δV (g)-1)⊕= δV (g-1)⊕.\nhe character is ν\nV (g) = νV (g-).\n\nWe have νV (g) = ⎨∂i, where the ∂i are the eigenvalues of g in V . These eigenvalues must be\noots of unity because\n\nδ(g)|G| = δ(g|G|) = δ(e) = Id. Thus for complex representations\n\nνV (g) = ν\n(g-) =\nX\n∂\nV\ni\n-\n\n=\nX\n∂i =\nX\n∂i = νV (g).\nn particular, V ∪= V ⊕ as representations (not just as vector spaces) if and only if νV (g) 2 R for all\n2 G.\nI\nT\nr\nI\ng\n\nIf V, W are representations of G, then V\nW is also a representation, via\nδV\nW (g) = δV (g)\nδ\n\nW (g).\nTherefore, νV\nW (g) = νV (g)νW (g).\nAn interesting problem discussed below is to decompose V\nW (for irreducible V, W ) into the\ndirect sum of irreducible representations.\n3.5\nOrthogonality of characters\nWe define a positive definite Hermitian inner product on Fc(G, C) (the space of central functions)\nby\n\n(f1, f2) =\nf (g)f (g).\n|G| g\nX\n2G\nThe following theorem says that characters of irreducible representations of G form an orthonormal\nbasis of Fc(G, C) under this inner product.\nTheorem 3.8. For any representations V, W\n(νV , νW ) = dim HomG(W, V ),\nand\n1, if V ∪= W,\n(νV , νW ) =\n0, if V W\nif V, W are irreducible.\nProof. By the definition\n\n(νV , νW )\n=\nν (g)ν\n(g) =\nν (g)ν\n(g)\n|G|\nX\nV\nW\n\nV\nW\ng2G\n|G| g\nX\n2G\n\n=\nνV\nW (g) = Tr\n\n|V\nW (P ),\n|G| g\nX\n2G\n\nwhere P = 1 ⎨\ng G g 2 Z(C[G]). (Here Z(C[G]) denotes the center of\n]).\nG|\nC[G\nIf X is an irreducible\n|\nrepresentation of G then\nId, if X = C,\nP |X =\n\n0, X = C.\nTherefore, for any representation X the operator P |X is the G-invariant projector onto the subspace\nXG of G-invariants in X. Thus,\nTr |V\nW (P ) = dim HomG(C, V\nW ⊕)\n\n= dim(V\nW ⊕\n\n)G = dim HomG(W, V ).\n⇒\n\nTheorem 3.8 gives a powerful method of checking if a given complex representation V of a finite\ngroup G is irreducible. Indeed, it implies that V is irreducible if and only if (νV , νV ) = 1.\nExercise. Let G be a finite group. Let Vi be the irreducible complex representations of G.\nFor every i, let\ndim V\n\ni X\n· -1\nξi =\nν\n|\nV (g) g\nC [G] .\nG\n\n|\ni\ng2G\n(i) Prove that ξi acts on Vj as the identity if j = i, and as the null map if j = i.\n\n(ii) Prove that ξi are idempotents, i.e., ξ2\ni = ξi for any i, and ξiξj = 0 for any i = j.\nHint: In (i), notice that ξi commutes with any element of k [G], and thus acts on Vj as an\nintertwining operator. Corollary 1.17 thus yields that ξi acts on Vj as a scalar. Compute this\nscalar by taking its trace in Vj .\nHere is another \"orthogonality formula\" for characters, in which summation is taken over irre\nducible representations rather than group elements.\nTheorem 3.9. Let g, h 2 G, and let Zg denote the centralizer of g in G. Then\nX\n\n|Zg| if g is conjugate to h\nνV (g)νV (h) =\n0, otherwise\nV\nwhere the summation is taken over all irreducible representations of G.\nProof. As noted above, νV (h) = νV (h), so the left hand side equals (using Maschke's theorem):\nX\nνV (g)νV (h) = Tr|\nV V\nV (g\n(h⊕)-1) =\n∈\n\nV\nTr|∈V EndV (x 7⊃ gxh-1) = Tr|C[G](x 7⊃ gxh-1).\n\nIf g and h are not conjugate, this trace is clearly zero, since the matrix of the operator x 7⊃ gxh-1\nin the basis of group elements has zero diagonal entries. On the other hand, if g and h are in the\nsame conjugacy class, the trace is equal to the number of elements x such that x = gxh-1, i.e., the\norder of the centralizer Zg of g. We are done.\nRemark. Another proof of this result is as follows. Consider the matrix U whose rows are\nlabeledp\nby irreducible representations of G and columns by conjugacy classes, with entries UV,g =\nνV (g)/\n|Zg|. Note that the conjugacy class of g is G/Zg, thus |G|/|Zg| is the number of elements\nconjugate to G. Thus, by Theorem 3.8, the rows of the matrix U are orthonormal. This means\nthat U is unitary and hence its columns are also orthonormal, which implies the statement.\n3.6\nUnitary representations. Another proof of Maschke's theorem for complex\nrepresentations\nDefinition 3.10. A unitary finite dimensional representation of a group G is a representation of G\non a complex finite dimensional vector space V over C equipped with a G-invariant positive definite\nHermitian form4 (, ), i.e., such that δV (g) are unitary operators: (δV (g)v, δV (g)w) = (v, w).\n4We agree that Hermitian forms are linear in the first argument and antilinear in the second one.\n⇒\n⇒\n\nTheorem 3.11. If G is finite, then any finite dimensional representation of G has a unitary\nstructure. If the representation is irreducible, this structure is unique up to scaling by a positive\nreal number.\nProof. Take any positive definite form B on V and define another form B as follows:\nB(v, w) =\nX\nB(δV (g)v, δV (g)w)\ng2G\nThen B is a positive definite Hermitian form on V, and δV (g) are unitary operators. If V is\nan irreducible representation and B1, B2 are two positive definite Hermitian forms on V, then\nB1(v, w) = B2(Av, w) for some homomorphism A : V ⊃ V (since any positive definite Hermitian\nform is nondegenerate). By Schur's lemma, A = ∂Id, and clearly ∂> 0.\nTheorem 3.11 implies that if V is a finite dimensional representation of a finite group G, then\nthe complex conjugate representation V (i.e., the same space V with the same addition and the same\naction of G, but complex conjugate action of scalars) is isomorphic to the dual representation V ⊕.\nIndeed, a homomorphism of representations V ⊃ V ⊕ is obviously the same thing as an invariant\nsesquilinear form on V (i.e. a form additive on both arguments which is linear on the first one and\nantilinear on the second one), and an isomorphism is the same thing as a nondegenerate invariant\nsesquilinear form. So one can use a unitary structure on V to define an isomorphism V ⊃ V ⊕.\nTheorem 3.12. A finite dimensional unitary representation V of any group G is completely re\nducible.\nProof. Let W be a subrepresentation of V\n\n. Let W ? be the orthogonal complement of W in V\nunder the Hermitian inner product. Then\n\nW ? is a subrepresentation of W , and V = W W ?.\nThis implies that V is completely reducible.\nTheorems 3.11 and 3.12 imply Maschke's theorem for complex representations (Theorem 3.1).\nThus, we have obtained a new proof of this theorem over the field of complex numbers.\nRemark 3.13. Theorem 3.12 shows that for infinite groups G, a finite dimensional representation\nmay fail to admit a unitary structure (as there exist finite dimensional representations, e.g. for\nG = Z, which are indecomposable but not irreducible).\n3.7\nOrthogonality of matrix elements\nLet V be an irreducible representation of a finite group G, and v1, v2, . . . , vn be an orthonormal\nbasis\n\nof V under the invariant Hermitian form. The matrix elements of V are tV\nij (x) = (δV (x)vi, vj ).\nProposition 3.14.\n(i) Matrix elements of nonisomorphic irreducible representations are orthog\n\nonal in Fun(G, C) under the form (f, g) = 1 ⎨\nx G f(x)g(x).\n|G|\n(ii) (tV\n\nij , tV\n⊗⊗ ) =\n·\n\nζ\nζ\njj⊗\ni j\nii⊗\ndim V\nThus, matrix elements of irreducible representations of G form an orthogonal basis of Fun(G, C).\nProof. Let V and W be two irreducible representations of G. Take {vi} to be an orthonormal basis\nof V and {wi} to be an orthonormal basis of W under their positive definite invariant Hermitian\nforms. Let\n\nwi\n⊕2 W ⊕be the linear function on W defined by taking the inner product with\n\nwi: wi\n⊕\n⎨(u) = (u, wi). Then for x 2 G we have (xwi\n⊕, wj\n⊕) = (xwi, wj ). Therefore, putting P =\n\nx2G x, we have\n|G|\nV\nW\n| |-1\n=\nX\n\n(tij , ti⊗j⊗ )\nG\n(xvi, v\nj )(xwi⊗ , wj⊗ ) = |G|-X\n(xvi, vj )(xwi\n⊕\n⊗ , wj\n⊕\n⊗ ) = (P (vi\nwi\n⊕\n⊗ ), vj\nwj\n⊕\n⊗ )\nx2G\nx2G\nIf V = W, this is zero, since P projects to the trivial representation, which does not occur in\nV\nW ⊕. If V = W, we need to consider (P (vi\nvi\n⊕\n⊗ ), vj\nvj\n⊕\n⊗ ). We have a G-invariant decomposition\nV\nV ⊕ =\nC L\nC = span(\nX\nvk\nvk\n⊕)\n\nL = spana:P akk =0(\nX\naklvk\nk\n\nvl\n⊕),\nk,l\nand P projects to the first summand along the second one. The projection of vi\nvi\n⊕\n⊗ to C →C L\nis thus\nζii⊗\n\nv\n⊕\nv\ndim V\nX\nk\nk\nThis shows that\nζ\nζ\n\n⊕\n\n⊕\nii⊗jj⊗\n(P(vi\nvi⊗ ), vj\nvj⊗ ) = dim V\nwhich finishes the proof of (i) and (ii). The last statement follows immediately from the sum of\nsquares formula.\n3.8\nCharacter tables, examples\nThe characters of all the irreducible representations of a finite group can be arranged into a char\nacter table, with conjugacy classes of elements as the columns, and characters as the rows. More\nspecifically, the first row in a character table lists representatives of conjugacy classes, the second\none the numbers of elements in the conjugacy classes, and the other rows list the values of the\ncharacters on the conjugacy classes. Due to Theorems 3.8 and 3.9 the rows and columns of a\ncharacter table are orthonormal with respect to the appropriate inner products.\nNote that in any character table, the row corresponding to the trivial representation consists\nof ones, and the column corresponding to the neutral element consists of the dimensions of the\nrepresentations.\nS3\nId\n(12)\n(123)\n#\nHere is, for example, the character table of S3 : C+\nC\n-1\n-\nC2\n-1\nIt is obtained by explicitly computing traces in the irreducible representations.\nFor another example consider A4, the group of even permutations of 4 items. There are three\none-dimensional representations (as A4 has a normal subgroup Z2 Z2, and A4/Z2 Z2 = Z3).\nSince there are four conjugacy classes in total, there is one more irreducible representation of\ndimension 3. Finally, the character table is\n\nA4\nId\n(123)\n(132)\n(12)(34)\n#\nC\nC\nφ\nφ2\nρ\nC\nφ2\nρ2\nφ\nC3\n-1\nwhere φ = exp( 2νi ).\nThe last row can be computed using the orthogonality of rows. Another way to compute the\n\nlast row is to note that C3 is the representation of A4 by rotations of the regular tetrahedron: in\nthis case (123), (132) are the\n\nrotations by 1200 and 2400 around a perpendicular to a face of the\ntetrahedron, while (12)(34) is the rotation by 1800 around an axis perpendicular to two opposite\nedges.\nExample 3.15. The following three character tables are of Q8, S4, and A5 respectively.\n(123)\nC+-\nC -+\n--\n-\n-1\nQ8\ni\nj\nk\n#\nC++\n-1\n-1\n-1\n-1\nC\n-1\n-1\nC2\n-2\nId\n(12)\nS4\n(12)(34)\n(1234)\n#\nC+\nC\n-1\n-1\nC2\n-1\nC3\n+\n-1\n-1\nC3\n-1\n-1\n-\nA5\nId\n(123)\n(12)(34)\n(12345)\n(13245)\n#\nC\nC3\n-1\n1+\n⊗\n+\nC3\n\n⊗\n-\n-1\n-\nC4\n-1\n⊗\n-\nC5\n-1\n1+\n⊗\n-1\nIndeed, the computation of the characters of the 1-dimensional representations is straightfor\nward.\nThe character of the 2-dimensional representation of Q8 is obtained from the explicit formula\n(3) for this representation, or by using the orthogonality.\nFor S4, the 2-dimensional irreducible representation is obtained from the 2-dimensional irre\nducible representation of S3 via the surjective homomorphism S4 ⊃ S3, which allows to obtain its\ncharacter from the character table of S3.\nThe character of the\n\n3-dimensional representation C3\n+ is computed from its geometric realization\nby rotations of the cube. Namely, by rotating the cube, S4 permutes the main diagonals. Thus\n(12) is the\n\nrotation by 1800 around an axis that is perpendicular to two opposite edges, (12)(34)\n\nExample 3.16. The following tables represent computed tensor product multiplicities of irre\nC2\nC2\nS3\nC+\nC-\n-\n-\nC+\nC+\nC\nducible representations of S3, S4, and A5 respectively.\nC+\nC2\nC2\nC\nC-\nC+ C- C2\nC3\nC2\nC3\n+\nS4\nC+\nC-\nC2\nC3\n+\n-\nC+\nC+\nC\nC+\n-\nC3\n+\nC2\nC\n\n+\n-\nC\nC\nC\n\n-\n+\n-\nC-\nC3\nC -\n-\nC2\nC3\n+\nC3\nC\n\n+\n-\n-\nC\n\n+\n-\nC3\nC3\n+ C3\nC+ C\nC+ C2\n- C2\nC+ C2\nC\nC3\n\nis the rotation by 1800 around an axis that is perpendicular to two opposite faces, (123) is the\nrotation around a main diagonal by 1200, and\n\n(1234) is the rotation by 900 around an axis that is\nperpendicular to two opposite faces; this allows us to compute the traces easily, using the fact that\nthe trace of a rotation by the\n\nangle θ in R3 is 1 + 2 cos θ. Now the character of C3 is found by\nmultiplying the character of C3\n-\n+ by the character of the sign representation.\nFinally, we explain how to obtain the character table of A5 (even permutations of 5 items). The\ngroup A5 is the group of rotations of the regular icosahedron. Thus it has a 3-dimensional \"rotation\nC3\n\nrepresentation\"\n, in which (12)(34) is the rotation by 1800\n+\naround an axis perpendicular to two\nopposite edges, (123) is the\n\nrotation by 1200 around an axis perpendicular to two opposite faces,\nand (12345), (13254) are the rotations by 720, respectively 1440, around axes going through two\nopposite vertices. The character of this representation is computed from this description in a\nstraightforward way.\nAnother representation of A5, which is also 3-dimensional, is C3\n+ twisted by the automorphism\nof A5 given by conjugation by (12) inside S5. This representation is denoted by C3 . It has the\n-\nsame character as C3\n+, except that the conjugacy classes (12345) and (13245) are interchanged.\nThere are two remaining irreducible representations, and by the sum of squares formula their\ndimensions are 4 and\n\n5. So we\nthem C4\ncall\nand C5.\nThe representation C4 is realized on the space of functions on the set {1, 2, 3, 4, 5} with zero\nsum of values, where A5 acts by permutations (check that it is irreducible!). The character of\nthis representation is equal to the character of the 5-dimensional permutation representation minus\nthe character of the 1-dimensional trivial representation (constant functions). The former at an\nelement g equals to the number of items among 1,2,3,4,5 which are fixed by g.\nThe representation C5 is realized on the space of functions on pairs of opposite vertices of the\nicosahedron which has zero sum of values (check that it is irreducible!). The character of this\nrepresentation is computed similarly to the character of C4, or from the orthogonality formula.\n3.9\nComputing tensor product multiplicities using character tables\n\nk\nCharacter tables allow us to compute the tensor product multiplicities Nij using\n\nVi\n\nVj =\nX\nN k\nijVk,\nN k\nij = (νiνj , νk)\n\nA5\nC\nC3\n+\nC3\n-\nC4\nC5\nC\nC\nC\n\nC+\nC+\nC5\n\nC+\nC\nC3\n-\nC3\n-\nC4\n\nC5\n\nC5\nC3\n+\n\nC3\n+\nC4\nC4\nC3\n\nC4\nC5\n-\nC3\n\nC4\nC5\n+\n\nC3\nC C4\n\n-\n\nC5\nC\nC5\nC5\nC3\n\nC3\nC4\nC5\n+\nC3\n\n-\n\nC3\nC4\nC5\n+\n\n-\nC3\n\nC3\n2C5\nC4\n+\n\n-\n\nC3\n2C4\n2C5\n+ C3\n\n-\n\n3.10\nProblems\nProblem 3.17. Let G be the group of symmetries of a regular N-gon (it has 2N elements).\n(a) Describe all irreducible complex representations of this group (consider the cases of odd and\neven N)\n(b) Let V be the 2-dimensional complex representation of G obtained by complexification of the\nstandard representation on the real plane (the plane of the polygon). Find the decomposition of\nV\nV in a direct sum of irreducible representations.\nProblem 3.18. Let G be the group of 3 by 3 matrices over Fp which are upper triangular and have\nones on the diagonal, under multiplication (its order is p3). It is called the Heisenberg group. For\n\np\nany complex number z such that z = 1 we define a representation of G on the space V of complex\nfunctions on Fp, by\n\n⎧1\n(δ @ 0\n⎝ f)(x) = f(x - 1),\n⎧1\n(δ @ 0\n⎝ f)(x) = z xf(x).\n(note that zx makes\n\nsense since zp = 1).\n(a) Show that such a representation exists and is unique, and compute δ(g) for all g 2 G.\n(b) Denote this representation by Rz. Show that Rz is irreducible if and only if z = 1.\n(c) Classify all 1-dimensional representations of G. Show that R1 decomposes into a direct sum\nof 1-dimensional representations, where each of them occurs exactly once.\n(d) Use (a)-(c) and the \"sum of squares\" formula to classify all irreducible representations of\nG.\nProblem 3.19. Let V be a finite dimensional complex vector space, and GL(V ) be the group of\ninvertible linear transformations of V . Then SnV and ΓmV (m ∗ dim(V )) are representations of\nGL(V ) in a natural way. Show that they are irreducible representations.\nHint: Choose a basis {ei} in V . Find a diagonal element H of GL(V ) such that δ(H) has\ndistinct eigenvalues. (where δ is one of the above representations). This shows that if W is a\nsubrepresentation, then it is spanned by a subset S of a basis of eigenvectors of δ(H). Use the\ninvariance of W under the operators δ(1 + Eij ) (where Eij is defined by Eij ek = ζjkei) for all i = j\nto show that if the subset S is nonempty, it is necessarily the entire basis.\nProblem 3.20. Recall that the adjacency matrix of a graph (without multiple edges) is the matrix\nin which the ij-th entry is 1 if the vertices i and j are connected with an edge, and zero otherwise.\nLet be a finite graph whose automorphism group is nonabelian. Show that the adjacency matrix\nof must have repeated eigenvalues.\n\nProblem 3.21. Let I be the set of vertices of a regular icosahedron (|I| = 12). Let Fun(I) be the\nspace of complex functions on I. Recall that the group G = A5 of even permutations of 5 items\nacts on the icosahedron, so we have a 12-dimensional representation of G on Fun(I).\n(a) Decompose this representation in a direct sum of irreducible representations (i.e., find the\nmultiplicities of occurrence of all irreducible representations).\n(b) Do the same for the representation of G on the space of functions on the set of faces and\nthe set of edges of the icosahedron.\nProblem 3.22. Let Fq be a finite field with q elements, and G be the group of nonconstant inho\nmogeneous linear transformations, x ⊃ ax + b, over Fq (i.e., a 2 F×\nq , b 2 Fq). Find all irreducible\ncomplex representations of G, and compute their characters. Compute the tensor products of irre\nducible representations.\nHint. Let V be the representation of G on the space of functions on Fq with sum of all values\nequal to zero. Show that V is an irreducible representation of G.\nProblem 3.23. Let G = SU(2) (unitary 2 by 2 matrices with determinant 1), and V = C\nthe\nstandard 2-dimensional representation of SU(2). We consider V as a real representation, so it is\n4-dimensional.\n(a) Show that V is irreducible (as a real representation).\n(b) Let H be the subspace of EndR(V ) consisting of endomorphisms of V as a real representation.\nShow that H is 4-dimensional and closed under multiplication. Show that every nonzero element in\nH is invertible, i.e., H is an algebra with division.\n(c) Find a basis 1, i, j, k of H such that 1 is the unit and i2 = j2 = k2 = -1, ij = -ji = k, jk =\n-kj = i, ki = -ik =\n\nj. Thus we have that Q8 is a subgroup of the group H× of invertible elements\nof H under multiplication.\nThe algebra H is called the quaternion algebra.\n(d) For q = a+bi+cj+dk, a, b, c, d 2 R, let q = a-bi-cj-dk, and ||q||2 = qq = a2 +b2 +c2\n.\nShow that q1q2 = q 2q 1, and ||q1q2|| = ||q1|| · ||q2||.\n(e) Let G be the group of quaternions of norm 1. Show that this group is isomorphic to SU(2).\n(Thus geometrically SU(2) is the 3-dimensional sphere).\n(f) Consider the action of G on the space V → H spanned\n\nby i, j, k, by x ⊃ qxq-1, q\nG,\nx 2 V . Since this action preserves the norm on V , we have a homomorphism h : SU(2) ⊃ SO(3),\nwhere SO(3) is the group of rotations of the three-dimensional Euclidean space. Show that this\nhomomorphism is surjective and that its kernel is {1, -1}.\nProblem 3.24. It is known that the classification of finite subgroups of SO(3) is as follows:\n1) the cyclic group Z/nZ, n ⊂ 1, generated by a rotation by 2β/n around an axis;\n2) the dihedral group Dn of order 2n, n ⊂ 2 (the group of rotational symmetries in 3-space of\na plane containing a regular n-gon5;\n3) the group of rotations of the regular tetrahedron (A4).\n4) the group of rotations of the cube or regular octahedron (S4).\n5) the group of rotations of a regular dodecahedron or icosahedron (A5).\n5A regular 2-gon is just a line segment.\n\n(a) Derive this classification.\nHint. Let G be a finite subgroup of SO(3). Consider the action of G on the unit sphere. A\npoint of the sphere preserved by some nontrivial element of G is called a pole. Show that every\nnontrivial element of G fixes a unique pair of opposite poles, and that the subgroup of G fixing a\nparticular pole P is cyclic, of some order m (called the order of P). Thus the orbit of P has n/m\nelements, where n = |G|. Now let P1, ..., Pk be the poles representing all the orbits of G on the set\nof poles, and m1, ..., mk be their orders. By counting nontrivial elements of G, show that\nX\n2(1 - ) =\n(1 -\n).\nn\nmi\ni\nThen find all possible mi and n that can satisfy this equation and classify the corresponding groups.\n(b) Using this classification, classify finite subgroups of SU(2) (use the homomorphism SU(2) ⊃\nSO(3)).\nProblem 3.25. Find the characters and tensor products of irreducible complex representations of\nthe Heisenberg group from Problem 3.18.\nProblem 3.26. Let G be a finite group, and V a complex representation of G which is faithful,\ni.e., the corresponding map G ⊃ GL(V ) is injective. Show that any irreducible representation of\nG occurs inside SnV (and hence inside V\nn) for some n.\nHint. Show that there exists a vector\n\nu 2 V ⊕whose stabilizer in G is 1. Now define the map\nSV ⊃ Fun(G, C) sending a polynomial\n\nf on V ⊕to the function fu on G given by fu(g) = f(gu).\nShow that this map is surjective and use this to deduce the desired result.\nProblem 3.27. This problem is about an application of representation theory to physics (elasticity\ntheory). We first describe the physical motivation and then state the mathematical problem.\nImagine a material which occupies a certain region U in the physical space V = R3 (a space\nwith a positive definite inner product). Suppose the material is deformed. This means, we have\napplied a diffeomorphism (=change of coordinates) g : U ⊃ U 0. The question in elasticity theory\nis how much stress in the material this deformation will cause.\nFor every point P 2 U, let AP : V ⊃ V be defined by AP = dg(P ). AP is nondegenerate,\nso it has a polar decomposition AP = DP OP , where OP is orthogonal and DP is symmetric. The\nmatrix OP characterizes the rotation part of AP (which clearly produces no stress), and DP is\nthe distortion part, which actually causes stress. If the deformation is small, DP is close to 1, so\nDP = 1+ dP , where dP is a small symmetric matrix, i.e., an element of S2V . This matrix is called\nthe deformation tensor at P .\nNow we define the stress tensor, which characterizes stress. Let v be a small nonzero vector in\nV , and ε a small disk perpendicular to v centered at P of area ||v||. Let Fv be the force with which\nthe part of the material on the v-side of ε acts on the part on the opposite side. It is easy to deduce\nfrom Newton's laws that Fv is linear in v, so there exists a linear operator SP : V ⊃ V such that\nFv = SP v. It is called the stress tensor.\nAn elasticity law is an equation SP = f(dP ), where f is a function. The simplest such law is a\nlinear law (Hooke's law): f : S2V ⊃ End(V ) is a linear function. In general, such a function is\ndefined by 9 · 6 = 54 parameters, but we will show there are actually only two essential ones - the\ncompression modulus K and the shearing modulus μ. For this purpose we will use representation\ntheory.\n\nRecall that the group SO(3) of rotations acts on V , so S2V , End(V ) are representations of this\ngroup. The laws of physics must be invariant under this group (Galileo transformations), so f must\nbe a homomorphism of representations.\n(a) Show that End(V ) admits a decomposition RV W , where R is the trivial representation,\nV is the standard 3-dimensional representation, and W is a 5-dimensional representation of SO(3).\nShow that S2V = R W\n(b) Show that V and W are irreducible, even after complexification. Deduce using Schur's\nlemma that SP is always symmetric, and for x 2 R, y 2 W one has f(x + y) = Kx + μy for some\nreal numbers K, μ.\nIn fact, it is clear from physics that K, μ are positive. Physically, the compression modulus K\ncharacterises resistance of the material to compression or dilation, while the shearing modulus μ\ncharacterizes its resistance to changing the shape of the object without changing its volume. For\ninstance, clay (used for sculpting) has a large compression modulus but a small shearing modulus.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n18.712 Introduction to Representation Theory\nFall 2010\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Representations of finite groups: further results",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/84358595a02a73bced2c4e363a5d66f0_MIT18_712F10_ch4.pdf",
      "content": "Representations of finite groups: further results\n4.1\nFrobenius-Schur indicator\nSuppose that G is a finite group and V is an irreducible representation of G over C. We say that\nV is\n- of complex type, if V V ⊕,\n- of real type, if V has a nondegenerate symmetric form invariant under G,\n- of quaternionic type, if V has a nondegenerate skew form invariant under G.\nProblem 4.1. (a) Show that EndR[G] V is C for V of complex type, Mat2(R) for V of real type,\nand H for V of quaternionic type, which motivates the names above.\nHint. Show that the complexification VC of V decomposes as V V ⊕. Use this to compute the\ndimension of EndR[G] V in all three cases. Using the fact that C →EndR[G] V , prove the result\nin the complex case. In the remaining two cases, let B be the invariant bilinear form on V , and\n(, ) the invariant positive Hermitian form (they are defined up to a nonzero complex scalar and a\npositive real scalar, respectively), and define the operator j : V\nV such that B(v, w) = (v, jw).\n\n-\n\n⊃\nShow that j is complex antilinear (ji =\nij), and j\n= ∂ · Id, where ∂ is a real number, positive in\nthe real case and negative in the quaternionic case (if B is renormalized, j multiplies by a nonzero\n\ncomplex number z and j2 by zz , as j is antilinear). Thus j can be normalized so that j2 = 1 for\nthe real case, and j2 = -1 in the quaternionic case. Deduce the claim from this.\n(b) Show that V is of real type if and only if V is the complexification of a representation VR\nover the field of real numbers.\nExample 4.2. For Z/nZ all irreducible representations are of complex type, except the trivial one\nand, if n is even, the \"sign\" representation, m ⊃ (-1)m, which are of real type. For S3 all three\nirreducible representations C+, C , C2 are of real type. For S\n-\n4 there are five irreducible representa\ntions C+, C , C2 , C3\n+, C3 , which are all of real type. Similarly, all five irreducible representations\n-\n-\nof A5 - C, C3\n+, C3 , C4 , C5 are of real type. As for Q8, its one-dimensional representations are of\n-\nreal type, and the two-dimensional one is of quaternionic type.\nDefinition 4.3. The Frobenius-Schur indicator FS(V ) of an irreducible representation V is 0 if it\nis of complex type, 1 if it is of real type, and -1 if it is of quaternionic type.\nTheorem⎨ 4.4. (Frobenius-Schur) The number of involutions (=elements of order ∗ 2) in G is\nequal to\nV dim(V )FS(V ), i.e., the sum of dimensions of all representations of G of real type\nminus the sum of dimensions of its representations of quaternionic type.\nProof. Let A : V ⊃ V have eigenvalues ∂1, ∂2, . . . , ∂n. We have\n\nTr|S2V (A\nA)\n=\nX\n∂i∂j\n|\nX\ni→j\nTr 2V (A\nA)\n=\n∂i∂j\ni<j\nThus,\n\nTr|S2V (A\nA) - Tr|2V (A\nA) =\n1→\nX\n∂= Tr(A2\ni\n).\ni→n\n\nThus for g 2 G we have\nνV (g 2) = νS2V (g) - ν2V (g)\nTherefore,\nX\n\nis of real\n\n, if V\ntype\n|\n\nG|-νV (\ng ) = νS2V (P )-ν\n2V (P ) = dim(S2V )G-dim(√ 2V )G =\n⎞\n⎟\n⎠-1, if V is of quaternionic type\n√\n\ng G\n0, if V is of complex\ntype\nFinally, the number of involutions in G equals\n\ndim V ν\n(\ng ) =\ndim V\n\n|G\n-\ndim V.\n|\nX\nV\nV\ng\nX\n2G\nreal\nX\nV\nquat\nX\nV\nCorollary 4.5. Assume that all representations of a finite group G are defined over real numbers\n(i.e., all complex representations of G are obtained by complexifying real representations). Then\nthe sum of dimensions of irreducible representations of G equals the number of involutions in G.\nExercise. Show that any nontrivial finite group of odd order has an irreducible representation\nwhich is not defined over R (i.e., not realizable by real matrices).\n4.2\nFrobenius determinant\nEnumerate the elements of a finite group G as follows: g1, g2, . . . , gn. Introduce n variables indexed\nwith the elements of G :\nxg1 , xg2 , . . . , xgn .\nDefinition 4.6. Consider the matrix XG with entries aij = xgigj . The determinant of XG is some\npolynomial of degree n of xg1 , xg2 , . . . , xgn that is called the Frobenius determinant.\nThe following theorem, discovered by Dedekind and proved by Frobenius, became the starting\npoint for creation of representation theory (see [Cu]).\nTheorem 4.7.\nY\nr\nPj (x)deg\ndet X\nPj\nG =\nj=1\nfor some pairwise non-proportional irreducible polynomials Pj (x), where r is the number of conju\ngacy classes of G.\nWe will need the following simple lemma.\nLemma 4.8. Let Y be an n × n matrix with entries yij. Then det Y is an irreducible polynomial\nof {yij }.\nn\nProof. Let Y = t·Id+⎨\ni=1 xiEi,i+1, where i+1 is computed modulo n, and Ei,j are the elementary\nmatrices. Then\n\ndet(Y ) = tn - (-1)nx1...xn, which is obviously irreducible. Hence det(Y ) is\nirreducible (since factors of a homogeneous polynomial are homogeneous).\nNow we are ready to proceed to the proof of Theorem 4.7.\n\nProof. Let V = C[G] be the regular representation of G. Consider the operator-valued polynomial\n\nL(x) =\nX\nxgδ(g),\ng2G\nwhere δ(g) 2 EndV is induced by g. The action of L(x) on an element h 2 G is\nX\n\nL(x)h =\nxgδ(g)h =\nX\nxggh =\nX\nxzh-1 z\ng2G\ng2G\nz2G\nSo the matrix of the linear operator L(x) in the basis g1, g2, . . . , gn is XG with permuted columns\nand hence has the same determinant up to sign.\nFurther, by Maschke's theorem, we have\nr\ndetV L(x) =\nY\n\n(detVi L(x))dim Vi ,\ni=1\nwhere Vi are the irreducible representations of G. We set Pi = detVi L(x). Let {eim} be bases of Vi\nand Ei,jk 2 End Vi be the matrix units in these bases. Then {Ei,jk} is a basis of C[G] and\n\nL(x)|Vi =\nX\nyi,jkEi,jk,\nj,k\nwhere yi,jk are new coordinates on C[G] related to xg by a linear transformation. Then\nPi(x) = det |Vi L(x) = det(yi,jk)\nHence, Pi are irreducible (by Lemma 4.8) and not proportional to each other (as they depend on\ndifferent collections of variables yi,jk). The theorem is proved.\n4.3\nAlgebraic numbers and algebraic integers\nWe are now passing to deeper results in representation theory of finite groups. These results require\nthe theory of algebraic numbers, which we will now briefly review.\nDefinition 4.9. z 2 C is an algebraic number (respectively, an algebraic integer), if z is a\nroot of a monic polynomial with rational (respectively, integer) coefficients.\nDefinition 4.10. z 2 C is an algebraic number, (respectively, an algebraic integer), if z is an\neigenvalue of a matrix with rational (respectively, integer) entries.\nProposition 4.11. Definitions (4.9) and (4.10) are equivalent.\nProof. To show (4.10) ≥ (4.9), notice that z is a root of the characteristic polynomial of the matrix\n(a monic polynomial with rational, respectively integer, coefficients).\nTo show (4.9) ≥ (4.10), suppose z is a root of\n\np(x) = x n + a1x n-1 + . . . + an-1x + an.\nThen the characteristic polynomial of the following matrix (called the companion matrix) is\np(x):\n\n⎧\n\n0 . . . 0\n-an\nB\nB1\n0 . . . 0 -a\nB\nn-1\nB0\n0 . . . 0 -an-2\n⎜\n⎜\n⎜.\n@\nB\n.\n\n. .\n\n0 . . . 1\n-a1\n⎜\n⎜\n⎝\nSince z is a root of the characteristic polynomial of this matrix, it is an eigenvalue of this matrix.\nThe set of algebraic numbers is denoted by Q, and the set of algebraic integers by A.\nProposition 4.12. (i) A is a ring.\n(ii) Q is a field. Namely, it is an algebraic closure of the field of rational numbers.\nProof. We will be using definition (4.10). Let φ be an eigenvalue of\nA 2 Matn(C)\nwith eigenvector v, let α be an eigenvalue of\nB 2 Matm(C)\nwith eigenvector w. Then φ ± α is an eigenvalue of\nA\nIdm ± Idn\nB,\nand φα is an eigenvalue of\nA\nB.\nThe corresponding eigenvector is in both cases v\nw. This shows that both A and Q are rings.\nTo show that the latter is a field, it suffices to note that if φ = 0 is a root of a polynomial p(x) of\ndegree d, then φ-1 is a root of xdp(1/x). The last statement is easy, since a number φ is algebraic\nif and only if it defines a finite extension of Q.\nProposition 4.13. A ∈ Q = Z.\nProof. We will be using definition (4.9). Let z be a root of\nn\np(x) = x +\n\na1x n-1 + . . . + an-1x + an,\nand suppose\np\nz =\n=\nq 2 Q, gcd(p, q)\n1.\n\nNotice that the\n\nleading term of p(x) will have qn in the denominator, whereas all the other terms\nwill have a lower power of q there. Thus, if q = ±1, then p(z) 2/ Z, a contradiction. Thus,\nz 2 A ∈ Q ≥ z 2 Z. The reverse inclusion follows because n 2 Z is a root of x - n.\nEvery algebraic number φ has a minimal polynomial p(x), which is the monic polynomial\nwith rational coefficients of the smallest degree such that p(φ) = 0. Any other polynomial q(x) with\nrational coefficients such that q(φ) = 0 is divisible by p(x). Roots of p(x) are called the algebraic\nconjugates of φ; they are roots of any polynomial q with rational coefficients such that q(φ) = 0.\n⇒\n⇒\n\nNote that any algebraic conjugate of an algebraic integer is obviously also an algebraic inte\nger. Therefore, by the Vieta theorem, the minimal polynomial of an algebraic integer has integer\ncoefficients.\nBelow we will need the following lemma:\nLemma 4.14. If φ1, ..., φm are algebraic numbers, then all algebraic conjugates to φ1 + ... + φm\nare of the form φ1\n0 + ... + φ0\nm, where φ0\ni are some algebraic conjugates of φi.\nProof. It suffices to prove this for two summands. If φi are eigenvalues of rational matrices Ai of\nsmallest size (i.e., their characteristic polynomials are the minimal polynomials of φi), then φ1 + φ2\nis an eigenvalue of A := A1\nId + Id\nA2. Therefore, so is any algebraic conjugate to φ1 + φ2.\nBut all eigenvalues of A are of the form φ1\n0 + φ2\n0 , so we are done.\nProblem 4.15. (a) Show that for any finite group G there exists a finite Galois extension K →C\nof Q such that any finite dimensional complex representation of G has a basis in which the matrices\nof the group elements have entries in K.\nHint. Consider the representations of G over the field Q of algebraic numbers.\n(b) Show that if V is an irreducible complex representation of a finite group G of dimension\n> 1 then there exists g 2 G such that νV (g) = 0.\nHint: Assume the contrary. Use orthonormality of characters to show that the arithmetic mean\nof the numbers |\n\nνV (g)|2 for g = 1 is < 1. Deduce that their product α satisfies 0 < α < 1.\nShow that all conjugates of α satisfy the same inequalities (consider the Galois conjugates of the\nrepresentation V , i.e. representations obtained from V by the action of the Galois group of K over\nQ on the matrices of group elements in the basis from part (a)). Then derive a contradiction.\nRemark. Here is a modification of this argument, which does not use (a). Let N = G\n\n| |. For\nany\n⎛ 0 < j < N coprime to N, show that the map g 7⊃ gj is a bijection G ⊃ G. Deduce that\n\n|\nj |2\n\ng=1 νV (g )\n= α. Then show that α 2 K := Q(ψ), ψ = e2νi/N, and does not change under the\nautomorphism of K given by ψ 7⊃ ψj. Deduce that α is an integer, and derive a contradiction.\n4.4\nFrobenius divisibility\nTheorem 4.16. Let G be a finite group, and let V be an irreducible representation of G over C.\nThen\ndim V divides |G|.\nProof. Let C1, C2, . . . , Cn be the conjugacy classes of G. Set\nC\n∂i =\ni\nνV (gCi ) |\n| ,\ndim V\nwhere gCi is a representative of Ci.\nProposition 4.17. The numbers ∂i are algebraic integers for all i.\nProof. Let C be a conjugacy class in G, and P =\nh C h. Then P is a central element of Z[G], so it\nacts on V by some scalar ∂, which is an algebraic\n⎨\ninteger (indeed, since Z[G] is a finitely generated\nZ-module, any element of Z[G] is integral over Z, i.e., satisfies a monic polynomial equation with\ninteger coefficients). On the other hand, taking the trace of P in V , we get |C|νV (g) = ∂ dim V ,\n|C|αV (g)\ng 2 C, so ∂ =\n.\ndim V\n⇒\n\nNow, consider\nX\n∂iνV (gCi ).\ni\nThis is an algebraic integer, since:\n(i) ∂i are algebraic integers by Proposition 4.17,\n(ii) νV (gCi ) is a sum of roots of unity (it is the sum of eigenvalues of the matrix of δ(gCi ), and\nsince g|G |\nC\n= e in G, the eigenvalues of δ(gCi ) are roots of unity), and\ni\n(iii) A is a ring (Proposition 4.12).\nOn the other hand, from the definition of ∂i,\nX\nCi νV (gC )νV (gC\n∂iν\ni\ni )\nV (gCi ) =\nX |\n|\n.\ndim V\nCi\ni\nRecalling that νV is a class function, this is equal to\nX νV (g)νV (g)\n|G|(νV , νV )\n=\n.\ndim V\ndim V\ng2G\nSince V is an irreducible representation, (νV , νV ) = 1, so\nX\n∂iνV (gCi ) = |G| .\ndim V\nCi\n\n|G|\n2 Q\n⎨\n2 A\n\n|G\nSince\nand\nC ∂νV (g\n)\n,\n\ni\nCi\nby Proposition 4.13\n|\n\ndim V\ni\ndim V 2 Z.\n4.5\nBurnside's Theorem\nDefinition 4.18. A group G is called solvable if there exists a series of nested normal subgroups\n{e} = G1 γ G2 γ . . . γ Gn = G\nwhere Gi+1/Gi is abelian for all 1 ∗ i ∗ n - 1.\nRemark 4.19. Such groups are called solvable because they first arose as Galois groups of poly\nnomial equations which are solvable in radicals.\nTheorem 4.20 (Burnside). Any group G of order paqb, where p and q are prime and a, b ⊂ 0, is\nsolvable.\nThis famous result in group theory was proved by the British mathematician William Burnside\nin the early 20-th century, using representation theory (see [Cu]). Here is this proof, presented in\nmodern language.\nBefore proving Burnside's theorem we will prove several other results which are of independent\ninterest.\nTheorem 4.21. Let V be an irreducible representation of a finite group G and let C be a conjugacy\nclass of G with gcd(|C|, dim(V )) = 1. Then for any g 2 C, either νV (g) = 0 or g acts as a scalar\non V .\n\nThe proof will be based on the following lemma.\nLemma 4.22. If π1, π2 . . . πn are roots of unity such that\n(π1 + π2 + . . . + πn) is an algebraic\nn\ninteger, then either π1 = . . . = πn or π1 + . . . + πn = 0.\nProof. Let a = 1 (π1 + . . . + πn). If not all πi are equal, then a\nn\n| | < 1. Moreover, since any algebraic\nconjugate of a root\n|\n\nof unity is also a root of unity, a0| ∗ 1 for any algebraic conjugate a0 of a. But\nthe product of all algebraic conjugates of a is an integer. Since it has absolute value < 1, it must\nequal zero. Therefore, a = 0.\nProof of theorem 4.21.\nLet dim V = n. Let π1, π2, . . . πn be the eigenvalues of δV (g). They are roots of unity, so\n\nνV (g) is an algebraic integer. Also, by Proposition 4.17,\n|C|νV (g) is an algebraic integer. Since\nn\ngcd(n, |C|) = 1, there exist integers a, b such that a|C| + bn = 1. This implies that\nνV (g)\n=\n(π1 + . . . + πn).\nn\nn\nis an algebraic integer. Thus, by Lemma 4.22, we get that either π1 = . . . = πn or π1 + . . . + πn =\nνV (g) = 0. In the first case, since δV (g) is diagonalizable, it must be scalar. In the second case,\nνV (g) = 0. The theorem is proved.\nTheorem 4.23. Let G be a finite\n\ngroup, and let C be a conjugacy class in G of order pk where p\nis prime and k > 0. Then G has a proper nontrivial normal subgroup (i.e., G is not simple).\nProof. Choose an element g 2 C. Since g = e, by orthogonality of columns of the character table,\nX\ndim V νV (g) = 0.\n(4)\nV 2IrrG\nWe can divide IrrG into three parts:\n1. the trivial representation,\n2. D, the set of irreducible representations whose dimension is divisible by p, and\n3. N, the set of non-trivial irreducible representations whose dimension is not divisible by p.\nLemma 4.24. There exists V 2 N such that νV (g) = 0.\nProof. If V 2 D, the number 1 dim(V )νV (g) is an algebraic integer, so\np\nX 1\na =\ndim(V )νV (g)\np\nV 2D\nis an algebraic integer.\nNow, by (4), we have\n\n0 = ν (g) +\nX\n\nC\ndim V νV (g) +\nX\ndim V νV (g) = 1 + pa +\nX\ndim V νV (g).\nV 2D\nV 2N\nV 2N\nThis means that the last summand is nonzero.\n⇒\n\nNow pick V 2 N such that νV (g) = 0; it exists by Lemma 4.24. Theorem 4.21 implies that g\n(and hence any element of C) acts by a scalar in V . Now let H be the subgroup of G generated\n\nby elements ab-1, a, b 2 C. It is normal and acts trivially in V , so H = G, as V is nontrivial. Also\nH = 1, since |C| > 1.\nProof of Burnside's theorem.\nAssume Burnside's theorem is false. Then there\n\nexists a nonsolvable group G of order paqb. Let\nG be the smallest such group. Then G is simple, and by Theorem 4.23, it cannot have a conjugacy\nclass of order pk or qk , k ⊂ 1. So the order of any conjugacy class in G is either 1 or is divisible\nby pq. Adding the orders of conjugacy classes and equating the sum to paqb, we see that there has\nto be more than one conjugacy class consisting just of one element. So G has a nontrivial center,\nwhich gives a contradiction.\n4.6\nRepresentations of products\nTheorem 4.25. Let G, H be finite groups, {Vi} be the irreducible representations of G over a\nfield k (of any characteristic), and {Wj } be the irreducible representations of H over k. Then the\nirreducible representations of G × H over k are {Vi\nWj}.\nProof. This follows from Theorem 2.26.\n4.7\nVirtual representations\nDefinition 4.26. A virtual representation\n⎨\nof a finite group G is an integer linear combination of\n\nirreducible representations of⎨\nG, V =\nniVi, ni 2 Z (i.e., ni are not assumed to be nonnegative).\n\nThe character of V is νV :=\nniνVi .\nThe following lemma is often very useful (and will be used several times below).\nLemma 4.27. Let V be a virtual representation with character νV . If (νV , νV ) = 1 and νV (1) > 0\nthen νV is a character of an irreducible representation of G.\n\nProof. Let V1, V2, . . . , Vm be the irreducible representations of G, and V =\nniVi. Then by\northonormality of characters, (ν , ν ) = ⎨n2\nV\n\nV\ni\ni . So\ni ni = 1, meaning that n\n⎨\ni = ±1 for exactly\none i, and nj = 0 for j = i. But νV (1) > 0, so ni = +1\n⎨\nand we are done.\n4.8\nInduced Representations\nGiven a representation V of a group G and a subgroup H →G, there is a natural way to construct\na representation\n\nof H. The restricted representation of V to H, ResG\nH V is the representation given\nby the vector space V and the action δResG V = δV |H .\nH\nThere is also a natural, but more complicated way to construct a representation of a group G\ngiven a representation V of its subgroup H.\nDefinition 4.28. If G is a group, H →G, and V is a representation of H, then the induced\nrepresentation IndG\nH V is the representation of G with\nIndG\nH V = {f : G ⊃ V |f(hx) = δV (h)f(x)⊕x 2 G, h 2 H}\n⇒\n⇒\n⇒\n\nand the action g(f)(x) = f(xg) ⊕g 2 G.\nRemark 4.29. In fact,\n\nIndG\nH V is naturally isomorphic to HomH (k[G], V ).\nLet us check that\n\nIndG\nH V is indeed a representation:\ng(f)(hx) = f(hxg) = δV (h)f(xg) = δV (h)g(f)(x), and g(g0(f))(x) = g0(f)(xg) = f(xgg0) =\n(gg0)(f)(x) for any g, g0, x 2 G and h 2 H.\nRemark 4.30. Notice that if we choose a representative xε from every right H-coset ε of G, then\nany f 2 IndG\nH V is uniquely determined by {f(xε)}.\nBecause of this,\ndim(IndG\n|G| .\nH V ) = dim V · |H|\nProblem 4.31. Check that if K →H → G are groups and V a representation of K then IndG\nH\nH IndK V\nis isomorphic to\n\nIndG\nK V .\nExercise. Let K →G be finite groups, and ν : K ⊃ C⊕ be a homomorphism. Let Cα be the\ncorresponding 1-dimensional representation of K. Let\neα =\nX\nν(g)-1 g C[K]\n|K| g2K\nbe the idempotent corresponding to\n\nν. Show that the G-representation IndG\nK Cα is naturally iso-\nmorphic to C[G]eα (with G acting by left multiplication).\n4.9\nThe Mackey formula\nLet us now compute the\n\ncharacter ν of IndG\nH V . In each right coset ε 2 H\\G, choose a representative\nxε.\nTheorem 4.32. (The Mackey formula) One has\n\nν(g) =\nν\nV (xεgx-\nε ).\nε2\nH\\G\nX\n:x\n-\ngx 2H\nRemark. If the characteristic of the ground field k is relatively prime to |H|, then this formula\ncan be written as\n\nν(g) =\nX\nνV (xgx-1).\n|H|\nx2G:xgx-12H\nProof. For a right H-coset ε of G, let us define\n{ 2\nG\nVε = f\nIndH V |f(g) = 0 ⊕g ⇒2 ε}.\nThen one has\n\nIndG\nH V =\nM\nVε,\nε\nand so\nν(g) =\nX\nνε(g),\nε\n\nwhere νε(g) is the trace of the diagonal block of δ(g) corresponding to Vε.\nSince g(ε) = εg is a right H-coset for any right H-coset ε, νε(g) = 0 if ε = εg.\nNow assume that ε =\n\nεg. Then xεg = hxε where h = xεgx-1\nε 2 H. Consider the vector space\nhomomorphism φ : Vε ⊃ V with φ(f) = f(xε). Since f 2 Vε is uniquely determined by f(xε), φ\nis an isomorphism. We have\nφ(gf) = g(f)(xε ) = f(xεg) = f(hxε) = δV (h)f(xε) = hφ(f),\nand gf = φ-1hφ(f). This means that νε(g) = νV (h). Therefore\nν(g) =\nX\nνV (x\nεgx-\nε ).\nε2H\\G,εg=ε\n4.10\nFrobenius reciprocity\nA very important result about induced representations is the Frobenius Reciprocity Theorem which\nconnects the operations Ind and Res.\nTheorem 4.33. (Frobenius Reciprocity)\nLet H →G be groups, V be a representation of G and W a representation of H. Then\nHomG(V,\nW\nG\nIndG\nH\n) is naturally isomorphic to HomH (ResH V, W ).\nProof. Let E = HomG(V,\n\nIndGW ) and E0 = HomH (ResG\nH\nH V, W ). Define F : E ⊃ E0 and F 0 : E0 ⊃\nE as follows: F (φ)v = (φv)(e) for any φ 2 E and (F 0(α)v)(x) = α(xv) for any α 2 E0.\n\nIn order to check that F and F 0 are well defined and inverse to each other, we need to check\nthe following five statements.\nLet φ 2 E, α 2 E0, v 2 V , and x, g 2 G.\n(a) F (φ) is an H-homomorphism, i.e., F (φ)hv = hF (φ)v.\nIndeed, F (φ)hv = (φhv)(e) = (hφv)(e) = (φv)(he) = (φv)(eh) = h · (φv)(e) = hF (φ)v.\n(b) F 0(α)v 2 IndG\nH W , i.e.,\n\n(F 0(α)v)(hx) = h(F 0(α)v)(x).\nIndeed, (F 0(α)v)(hx) = α(hxv) = hα(xv) = h(F 0(α)v)(x).\n(c) F 0(α) is a G-homomorphism, i.e. F 0(α)gv = g(F 0(α)v).\nIndeed, (F 0(α)gv)(x) = α(xgv) = (F 0(α)v)(xg) = (g(F 0(α)v))(x).\n\n(d) F inf F 0 = IdE⊗ .\nThis holds since F (F 0(α))v = (F 0(α)v)(e) = α(v).\n(e) F 0 inf F = IdE , i.e., (F 0(F (φ))v)(x) = (φv)(x).\nIndeed, (F 0(F (φ))v)(x) = F (φxv) = (φxv)(e) = (xφv)(e) = (φv)(x), and we are done.\nExercise. The purpose of this exercise is to understand the notions of restricted and induced\nrepresentations as part of a more advanced framework. This framework is the notion of tensor\nproducts over k-algebras (which generalizes the tensor product over k which we defined in Definition\n⇒\n\n1.48). In particular, this understanding will lead us to a new proof of the Frobenius reciprocity\nand to some analogies between induction and restriction.\nThroughout this exercise, we will use the notation and results of the Exercise in Section 1.10.\nLet G be a finite group and H →G a subgroup. We consider k [G] as a (k [H] , k [G])-bimodule\n(both module structures are given by multiplication inside k [G]). We denote this bimodule by\nk [G]1. On the other hand, we can also consider k [G] as a (k [G] , k [H])-bimodule (again, both\nmodule structures are given by multiplication). We denote this bimodule by k [G]2.\n(a) Let V be a representation of G. Then, V is a left k [G]-module, thus a (k [G] , k)-bimodule.\nThus, the tensor product k [G]1\nk[G] V is a (k [H] , k)-bimodule, i. e., a left k [H]-module. Prove\nthat this tensor product is isomorphic to\n\nResG\nH V as a left k [H]-module. The isomorphism ResG\nH V\nG\n⊃\nk [G]1\nk[G] V is given by v 7⊃ 1\nk[G] v for every v 2 ResH V .\n(b) Let W be a representation of H. Then, W is a left k [H]-module, thus a (k [H] , k)\nbimodule. Then, IndG\nH W =∪\nk [G] , W ), according to Remark 4.30. In\n\nHomH (\nother words, IndG\nH W =∪\nHomk[H] (k [G]1 , W ). Now, use part (b) of the Exercise in Section 1.10 to conclude Theorem 4.33.\n(c) Let V be a representation of G. Then, V is a left k [G]-module, thus a (k [G] , k)-bimodule.\nProve that not only k [G]\nV , but also Hom\n(k [G] , V ) is isomorphic to ResG\nk[G]\nk[G]\nH V as a left\nk [H]-module. The isomorphism Homk[G] (k [G]2 , V ) ⊃ ResG\nH V is given by f 7⊃ f (1) for every\nf 2 Homk[G] (k [G]2 , V ).\n(d) Let W be a representation of H. Then, W is a left k [H]-module, thus a (k [H] , k)\nbimodule.\n\nShow that IndG\nH W is not only isomorphic to Homk[H] (k [G]1 , W ), but also isomorphic to\n\nk [G]2\nk[H]W . The isomorphism Homk[H] (k [G]1 , W ) ⊃ k [G]2\nk[H]W is given by f 7⊃ ⎨\ng\ng-1\n2P\n\nk[H]\nf (g) for every f 2 Homk[H] (k [G]1 , W ), where P is a set of distinct representatives for the right\nH-cosets in G. (This isomorphism is independent of the choice of representatives.)\n(e) ⎩Let V be a representation of G and W a representation of H. Use (b) to prove that\n\nHom\nG\nG\nG IndH W, V is naturally isomorphic to HomH\n⎩\nW, ResH V\n\n.\n\nG\n⊕ ∪\n⎩\nG\n(f) Let V be a representation of H. Prove that Ind\n=\nH V\n⊕\nH (V )\nInd\nas representations of\n\nG. [Hint: Write IndG\nH V as k [G]2\nk[H] V and write IndG\nH (V ⊕) as Homk[H] (k [G]1 , V ⊕). Prove\n\nthat the map Homk[H] (k [G]1 , V ⊕ ×\nG\n)\nIndH (V ⊕) ⊃ k given by f, x\nk[H] v\n7⊃ (f (Sx)) (v) is\na nondegenerate G-invariant bilinear\n⎩\nform, where\n\nS : k [G] ⊃ k\n⎩\n[G]\n⎩\nis the linear\n\nmap defined by\nSg = g-1 for every g 2 G.]\n4.11\nExamples\nHere are some examples of induced representations (we use the notation for representations from\nthe character tables).\n1. Let G = S3, H\n\n= Z2. Using the Frobenius reciprocity, we obtain: IndG\n= C2\nH C+\nC+,\nIndG C\n= C2\nH\nC .\n-\n\n-\n2. Let G = S3, H = Z3. Then we\n\nobtain IndG\nH C+ = C+ C , IndGC = IndG\n-\nH Cρ = C2\nH\nρ\n.\n3. Let G = S , H = S . Then IndG\nH C+ = C+C3\nG C\nC\nC3\nG C2\nC2\nC3\nC3\n, Ind\n=\n=\n.\n-\nH\n-\n, Ind\n-\n+\nH\n\n-\n+\nProblem 4.34. Compute the decomposition into irreducibles of all the representations of A5 in\nduced from all the irreducible representations of\n\n(a) Z2\n(b) Z3\n(c) Z5\n(d) A4\n(e) Z2 × Z2\n4.12\nRepresentations of Sn\nIn this subsection we give a description of the representations of the symmetric group Sn for any\nn.\nDefinition 4.35. A partition ∂ of n is a representation of n in the form n = ∂1 + ∂2 + ... + ∂p,\nwhere ∂i are positive integers, and ∂i ⊂ ∂i+1.\nTo such ∂ we will attach a Young diagram Y, which is the union of rectangles -i ∗ y ∗-i+1,\n0 ∗ x ∗ ∂i in the coordinate plane, for i = 1, ..., p. Clearly, Y is a collection of n unit squares. A\nYoung tableau corresponding to Y is the result of filling the numbers 1, ..., n into the squares of\nY in some way (without repetitions). For example, we will consider the Young tableau T obtained\nby filling in the numbers in the increasing order, left to right, top to bottom.\nWe can define two subgroups of Sn corresponding to T:\n1. The row subgroup P: the subgroup which maps every element of {1, ..., n} into an element\nstanding in the same row in T.\n2. The column subgroup Q: the subgroup which maps every element of {1, ..., n} into an\nelement standing in the same column in T.\nClearly, P ∈ Q = {1}.\nDefine the Young projectors:\n|\nX\na :=\ng,\n|P g2P\n\nb :=\nX\n(-1)gg,\n|Q| g2Q\nwhere (-1)g denotes the sign of the permutation g. Set c = ab. Since P ∈ Q = {1}, this\nelement is nonzero.\nThe irreducible representations of Sn are described by the following theorem.\nTheorem 4.36. The subspace V := C[Sn]c of C[Sn] is an irreducible representation of Sn under\nleft multiplication. Every irreducible representation of Sn is isomorphic to V for a unique ∂.\nThe modules V are called the Specht modules.\nThe proof of this theorem is given in the next subsection.\nExample 4.37.\nFor the partition ∂ = (n), P = Sn, Q = {1}, so c is the symmetrizer, and hence V is the trivial\nrepresentation.\n\nFor the partition ∂ = (1, ..., 1), Q = Sn, P = {1}, so c is the antisymmetrizer, and hence V is\nthe sign representation.\nn = 3. For\n\n∂ = (2, 1), V = C2.\nn = 4. For ∂ = (2, 2), V = C2; for ∂\n\n= (3, 1), V = C3 ;\n\nfor ∂ = (2, 1, 1), V = C3\n-\n+.\nCorollary 4.38. All irreducible representations of Sn can be given by matrices with rational entries.\nProblem 4.39. Find the sum of dimensions of all irreducible representations of the symmetric\ngroup Sn.\nHint. Show that all irreducible representations of Sn are real, i.e., admit a nondegenerate\ninvariant symmetric form. Then use the Frobenius-Schur theorem.\n4.13\nProof of Theorem 4.36\nLemma 4.40. Let x 2 C[Sn]. Then axb = σ(x)c, where σ is a linear function.\nProof. If g 2 PQ, then g has a unique representation as pq, p 2 P, q 2 Q, so agb\nq\n= (-1) c.\nThus, to prove the required statement, we need to show that if g is a permutation which is not in\nPQ then agb = 0.\nTo show this, it is sufficient to find a transposition t such that t 2 P and g-1tg 2 Q; then\nagb\n= atgb = ag(g-tg)b = -agb,\nso agb = 0. In other words, we have to find two elements i, j standing in the same row in the\ntableau T =\n\nT, and in the same column in the tableau T 0 = gT (where gT is the tableau of the\nsame shape as T obtained by permuting the entries of T by the permutation g). Thus, it suffices to\nshow that if\n\nsuch a pair does not exist, then g 2 PQ, i.e., there exists p 2 P, q0 2 Q\n0 := gQg-1\nsuch that pT = q0T 0 (so that g = pq-1, q = g-1q0g 2 Q).\nAny two elements in the first row of T must be in different columns of T 0, so there exists q1\n0 2 Q\nwhich moves all these\n\nelements to the first row. So there is p1 2 P such that p1T and q1\n0 T 0 have\nthe same first row. Now do the same procedure with the second row, finding elements p2, q2\n0 such\n\nthat p2p1T and q2\n0 q1\n0 T 0 have the same first two rows. Continuing so, we will construct the desired\nelements p, q0. The lemma is proved.\nLet us introduce the lexicographic ordering on partitions: ∂> μ if the first nonvanishing\n∂i - μi is positive.\nLemma 4.41. If ∂> μ then aC[Sn]bμ = 0.\nProof. Similarly to the previous lemma, it suffices to show that for any g 2 Sn there exists a\ntransposition t 2 P such that g-1tg 2 Qμ. Let T = T and\n\nT 0 = gTμ. We claim that there are\ntwo integers which are in the same row of T and the same column of T 0. Indeed, if ∂1 > μ1, this is\nclear by the pigeonhole principle (already for the first row). Otherwise, if ∂1 = μ1, like in the proof\nof the previous lemma, we can find elements p1 2 P, q1\n0 2\n\ngQ g-1\nμ\nsuch that p1T and q1\n0 T 0 have the\nsame first row, and repeat the argument for the second row, and so on. Eventually, having done\ni - 1 such steps, we'll have ∂i > μi, which means that some two elements of the i-th row of the first\ntableau are in the same column of the second tableau, completing the proof.\n\nLemma 4.42. c is proportional to an\n\nidempotent. Namely, c2\n=\nn!\nc .\ndim V\n\nProof. Lemma 4.40 implies that c2\nis proportional to c. Also, it is easy to see that the trace of\nc in the regular representation is n! (as the coefficient of the identity element in c is 1). This\nimplies the statement.\nLemma 4.43. Let A be an algebra and e be an idempotent in A. Then for any left A-module M,\none has HomA(Ae, M) ∪= eM (namely, x 2 eM corresponds to fx : Ae ⊃ M given by fx(a) = ax,\na 2 Ae).\nProof. Note that 1 - e is also an idempotent in A. Thus the statement immediately follows from\nthe fact that HomA(A, M) ∪= M and the decomposition A = Ae A(1 - e).\nNow we are ready to prove Theorem 4.36. Let ∂ ⊂ μ. Then by Lemmas 4.42, 4.43\nHomSn (V, Vμ) = HomSn (C[Sn]c, C[Sn]cμ) = cC[Sn]cμ.\nThe latter space is zero for ∂> μ by Lemma 4.41, and 1-dimensional if ∂ = μ by Lemmas 4.40\nand 4.42. Therefore, V are irreducible, and V is not isomorphic to Vμ if ∂ = μ. Since the number\nof partitions equals the number of conjugacy classes in Sn, the representations V exhaust all the\nirreducible representations of Sn. The theorem is proved.\n4.14\nInduced representations for Sn\nDenote by U the representation IndSn C. It is easy to see that U can be alternatively defined as\nP\nU = C[Sn]a.\nProposition 4.44. Hom(U, Vμ) = 0 for μ < ∂, and dim Hom(U, V) = 1. Thus, U =\nμ\nKμVμ, where Kμ are nonnegative integers and K\n=\n∧\n\n1.\nDefinition 4.45. The integers Kμ are called the Kostka numbers.\nProof. By Lemmas 4.42 and 4.43,\nHom(U, Vμ) = Hom(C[Sn]a, C[Sn]aμbμ) = aC[Sn]aμbμ,\nand the result follows from Lemmas 4.40 and 4.41.\nNow let us compute the character of U. Let Ci be the conjugacy class in Sn having il cycles\nof length l for all l ⊂ 1 (here i is a shorthand notation for (i1, ..., il, ...)). Also let x1, ..., xN be\nvariables, and let\nX\nH\nm\nm(x) =\nxi\ni\nbe the power sum polynomials.\nTheorem 4.46. Let N\n⎛\n⊂ p\n\n(where p is the number of parts of ∂). Then ν\nU (Ci\n\n) is the coefficient\nx\nof\n:=\n\nx\nj\nj\nin the polynomial\nY\nHm(x)im .\nm∧1\n6If j > p, we define j to be zero.\n\nProof. The proof is obtained easily from the Mackey formula. Namely, νU (Ci) is the number of\n\nelemen⎛ts x 2 Sn such that xgx-1 2 P (for a representative g 2 Ci), divided by |P|. The order of\nP is\n∂i!, and the num er of\n\ni\nb\nelements x such that xgx-1 2 P is the number of elements in P\nconjugate to g (i.e. |Ci ∈ P|) times the order of the centralizer Zg of g (which is n!/|Ci|). Thus,\nZg\nνU\ni\n(Ci) = ⎛|\n|\nj ∂j! |C ∈ P|.\n\nNow, it is easy to see that the centralizer Zg of g is isomorphic to ⎛\nm Sim ∼ (Z/mZ)im , so\n|Zg| =\nY\nm im im!,\nm\nand we get\nmim im!\nν\nm\nU (Ci) =\n⎛\nNow, since P =\nj S , we have\n⎛\nP\nj\n|C\n.\n∂j!\ni ∈\n|\n⎛\nj\n\n∂ !\n|Ci ∈ P\n\nX Y\nj\n| =\n\n,\nr\nr\nm\n1 m jm rjm!\nj∧1\n⎛\n∧\nwhere r = (rjm) runs over all collections of nonnegative integers such that\nX\n\nmrjm = ∂j ,\nX\nrjm = im.\nm\nj\nIndeed, an element of Ci that is in P would define an ordered partition of each ∂j into parts\n(namely, cycle lengths), with m occuring rjm times, such that the total (over all j) number of times\neach part m occurs is im. Thus we get\n\nim!\nνU (Ci) =\nX Y\n⎛\nj rjm!\nr\nm\nBut this is\n\nexactly the coefficient of x in\nY\n(xm\nm im\n1 + ... + xN )\nm∧1\n(rjm is the number of times we take xm\nj ).\n4.15\nThe Frobenius character formula\nLet (x) = ⎛\n\ni<j\nN(xi - xj ). Let δ = (N - 1, N - 2, ..., 0) 2 CN. The following theorem, due\n→\n→\nto Frobenius, gives a character formula for the Specht modules V.\n\n+N\nj\nTheorem 4.47. Let N ⊂ p. Then νV (Ci) is the coefficient of x+χ := ⎛x\nj\n-\nj\nin the polyno\nmial\n(x)\nY\nH (x)im\nm\n.\nm∧1\nRemark. Here is an equivalent formulation\n\nof Theorem 4.47: νV (Ci) is the coefficient of x\nin the (Laurent) polynomial\nY\n\nx\ni<j\n-\nj\n)\ni\nY\nHm(x im .\nx\n\nm∧1\n\nProof. Denote νV shortly by ν. Let us denote the class function defined in the theorem by χ . We\n\nclaim that this function has the property χ = ⎨\nμ\nLμνμ, where Lμ are integers and L = 1.\n∧\nIndeed, from Theorem 4.46 we have\nχ =\nX\n(-1)ενU+-() ,\nε2SN\nwhere if the vector ∂ + δ - ε(δ) has a negative entry, the corresponding term is dropped, and if\nit has nonnegative entries which fail to be nonincreasing, then the entries should be reordered in\nthe nonincreasing order, making a partition that we'll denote *∂ + δ - ε(δ)i (i.e., we agree that\nU+χ\nε(χ) := U +χ\nε(χ) ). Now note that μ = *∂ + δ - ε(δ)\n-\n*\n-\ni\ni is obtained from ∂ by adding vectors\nof the form ei - ej, i < j, which implies that μ > ∂ or μ = ∂, and the case μ = ∂ arises only if\nε = 1, as desired.\nTherefore, to show that χ = ν, by Lemma 4.27, it suffices to show that (χ, χ) = 1.\nWe have\n\n(χ, χ) =\nC\nn!\nX\n|\ni|χ(Ci)2.\ni\nUsing that\n\n|Ci| =\nwe conclude that (χ, χ) is the coefficient of\n⎛\nn!\n\n,\nm mim im!\nx+χy+χ in the series R(x, y) = (x)(y)S(x, y),\nwhere\nX Y (⎨\nm\nx )im\ni\n\n(\nm\nk ym\n\nm m\nim\n\nj\nj\nk )\n(\nj,k xj y /m)\nS(x, y) =\n=\nk\n.\nmim i\n⎨\nm!\nX Y ⎨\nim!\ni\nm\ni\nm\nSumming over i and m, we get\nS x, y) =\nY\n\nexp(\nX\n\n(\nx m m\nj yk /m) = exp(-\nX\nlog(1 - xj y\nk)) =\nY\n(1 - xjyk)-\nm\nj,k\nj,k\nj,k\nThus,\n⎛\ni<j(xi - xj )(yi - yj )\nR(x, y) =\n⎛\n.\ni,j(1 - xiyj)\nNow we need the following lemma.\nLemma 4.48.\n⎛\ni<j(zj - zi)(yi - y\n\n⎛\nj )\n= det(\n).\ni,j(zi - yj)\nzi - yj\nProof. Multiply both sides by\ni,j(zi-yj). Then the right hand side must vanish on the hyperplanes\nzi = zj and yi = yj (i.e., be divisible\n⎛\nby (z)(y)), and is a homogeneous polynomial of degree\nN(N - 1). This implies that the right hand side and the left hand side are proportional. The\nproportionality coefficient (which is equal to 1) is found by induction by multiplying both sides by\nzN - yN and then setting zN = yN .\nNow setting in the lemma zi = 1/xi, we get\nCorollary 4.49. (Cauchy identity)\n\nR(x, y) = det(\n) =\nX\n.\n1 - xiy\nN\nj\n⎛\n\nj=1(1 - xjy\nε\nε(j))\nSN\n\nCorollary 4.49 easily implies that the coefficient of x+χy+χ is 1. Indeed, if ε = 1 is a permu\ntation\n\nin SN , the coefficient of this monomial in\nis obviously zero.\nQ(1-xj y(j))\nRemark. For partitions ∂ and μ of n, let us say that ∂ μ or μ ⇔∂ if μ - ∂ is a sum of\nvectors of the form ei - ej , i < j (called positive roots). This is a partial order, and μ ⇔ ∂ implies\nμ ⊂ ∂. It follows from Theorem 4.47 and its proof that\nν = μ≥KμνUμ .\nThis implies that the Kostka numbers Kμ vanish unless\ne\nμ ⇔ ∂.\n4.16\nProblems\nIn the following problems, we do not make a distinction between Young diagrams and partitions.\nProblem 4.50. For a Young diagram μ, let A(μ) be the set of Young diagrams obtained by adding\na square to μ, and R(μ) be the set of Young diagrams obtained by removing a square from μ.\n(a) Show that ResSn\nVμ =\nSn-1\n2R(μ)V.\n(b) Show that IndSn\nS\nVμ = A(μ)V .\nn-1\n\nProblem 4.51. The content\n\n⎨\nc(∂) of a Young diagram ∂ is the sum ⎨⎨\nj\nj\ni=1(i - j). Let C =\ni<j (ij) 2 C[Sn] be the sum of all transpositions. Show that C acts on the Specht module V by\nmultiplication by c(∂).\nProblem 4.52. (a) Let V be any finite dimensional representation of Sn. Show that the element\nE := (12) + ... + (1n) is diagonalizable and has integer eigenvalues on V , which are between 1 - n\nand n - 1.\nHint. Represent E as Cn - Cn\n1, where C\n= C is the element from Problem 4.51.\n-\nn\n(b) Show that the element (12)+...+(1n) acts on V by a scalar if and only if ∂ is a rectangular\nYoung diagram, and compute this scalar.\n4.17\nThe hook length formula\nLet us use the Frobenius character formula to compute the dimension of V. According to the\ncharacter formula, dim V\n+χ\nn\nis the coefficient of x\nin (x)(x1 + ... + xN ) . Let lj = ∂j + N - j.\nThen, using the determinant formula for (x) and expanding the determinant as a sum over\npermutations, we get\n\ns\nn!\nn!\n\ndim =\n(-1)\n=\n(-\n\nV\n1)s\nlj (lj -1)...(lj -N+s(j)+1) =\nj(lj\nN + s(j))!\nl1!...lN !\ns SN :l\nX\nj ∧N-s(j)\nX\nY\n⎛\n-\ns2SN\nj\nn!\n⎛\ndet(lj (lj - 1)...(lj\nN + i + 1)).\nj lj!\n-\nUsing column reduction and the Vandermonde determinant formula, we see from this expression\nthat\nn!\ndim V\nN\ni\nn!\n\n= ⎛\ndet(lj\n-) =\n(li\nlj )\n(5)\nj lj !\n⎛\nj lj !\nY\n-\n1→i<j→N\n\n(where N ⊂ p).\nIn this formula, there are many cancelations. After making some of these cancelations, we\nobtain the hook length formula. Namely, for a square (i, j) in a Young diagram ∂ (i, j ⊂ 1, i\n∂j),\n\n0 ⊂ 0\n\n∗\n\ndefine the hook of (i, j) to be the set of all squares (i , j ) in ∂with i\ni, j = j or i = i, j0 ⊂ j.\nLet h(i, j) be the length of the hook of i, j, i.e., the number of squares in it.\nTheorem 4.53. (The hook length formula) One has\nn!\ndim V = ⎛\n.\ni\nh(i, j)\n→\nj\nProof. The formula follows from formula (5). Namely, note that\n\n⎛\nl1!\n=\nY\nk.\n1<j\nN(l1 - lj )\n→\n1→k→l1,k=l1-lj\nIt is easy to see that the factors in this product are exactly the hooklengths h(i, 1). Now delete the\nfirst row of the diagram and proceed by induction.\n4.18\nSchur-Weyl duality for gl(V )\nWe start with a simple result which is called the Double Centralizer Theorem.\nTheorem 4.54. Let A, B be two subalgebras of the algebra End E of endomorphisms of a finite\ndimensional vector space E, such that A is semisimple, and B = EndA E. Then:\n(i) A = EndB E (i.e., the centralizer of the centralizer of A is A);\n(ii) B is semisimple;\n(iii) as a representation of A\nB, E decomposes as E = i I Vi\nWi, where V\ni are all the\nirreducible representations of A, and Wi are all the irreducible representations of B. In particular,\nwe have a natural bijection between irreducible representations of A and B.\nProof. Since A is semisimple, we have a natural decomposition E = i I Vi\nWi, where W\ni :=\nHomA(Vi, E), and A = i End Vi. Therefore, by Schur's lemma, B = EndA(E) is naturally identi\nfied with i End(Wi). This implies all the statements of the theorem.\nWe will now apply Theorem 4.54 to the following situation: E =\n\nV\nn, where V is a finite\ndimensional vector space over a field of characteristic zero, and A is the image of C[Sn] in End E.\nLet us now characterize the algebra B. Let gl(V ) be End V regarded as a Lie algebra with operation\nab - ba.\nTheorem 4.55. The algebra B = EndA E is the image of the universal enveloping algebra U(gl(V ))\nunder its natural action on E. In other words, B is generated by elements of the form\nn(b) := b\n...\n1 + 1\nb\n...\n1 + ... + 1\n...\nb,\nb 2 gl(V ).\nProof. Clearly, the image of U(gl(V )) is contained in B, so we just need to show that any element\nof B is contained in the image of U(gl(V )). By definition,\n\nB = Sn End V , so the result follows from\npart (ii) of the following lemma.\ninf\n\nLemma 4.56. Let k be a field of characteristic zero.\n(i) For any finite dimensional vector space U over k, the space SnU is spanned by elements of\nthe form u\n...\nu, u 2 U.\n(ii) For any algebra A over k, the algebra SnA is generated by elements n(a), a 2 A.\nProof. (i) The space SnU is an irreducible representation of GL(U) (Problem 3.19). The subspace\nspanned by u\n...\nu is a nonzero subrepresentation, so it must be everything.\n(ii) By the fundamental theorem on symmetric functions, there exists a polynomial P with\nrational coefficients such that P (H1(x), ..., Hn(x)) = x1...xn (where x = (x1, ..., xn)). Then\nP (n(a), n(a 2), ..., n(a n)) = a\n...\na.\nThe rest follows from (i).\nNow, the algebra A is semisimple by Maschke's theorem, so the double centralizer theorem\napplies, and we get the following result, which goes under the name \"Schur-Weyl duality\".\nTheorem 4.57. (i) The image A of C[S ] and the image B of U(gl(V )) in End(V\nn\nn\n) are central\nizers of each other.\n\n(ii) Both A and B are semisimple. In particular, V\nn is a semisimple gl(V )-module.\n(iii) We have a decomposition of\n\nA\nB-modules V\nn = V\nL, where the summation\nis taken over partitions of n, V are Specht modules for Sn, and L are some distinct irreducible\nrepresentations of gl(V ) or zero.\n4.19\nSchur-Weyl duality for GL(V )\nThe Schur-Weyl duality for the Lie algebra gl(V ) implies a similar statement for the group GL(V ).\nProposition 4.58. The image of GL(V ) in End(V\nn) spans B.\n\nProof. Denote the span of g\nn, g 2 GL(V ), by B0. Let b 2 End V be any element.\n\nWe claim that B0 contains b\nn. Indeed, for all values of t but finitely many, t·Id+b is invertible,\nso\n\n(t · Id + b)\nn belongs to B0. This implies that this is true for all t, in particular for t = 0, since\n(t · Id + b)\nn is a polynomial in t.\nThe rest follows from Lemma 4.56.\nCorollary 4.59.\n\nAs a representation of Sn × GL(V ), V\nn decomposes as V\nL, where\nL = HomSn (V, V\nn) are distinct irreducible representations of GL(V ) or zero.\nExample 4.60. If ∂ = (n) then L = SnV , and if ∂ = (1n) (n copies of 1) then L = √nV . It was\nshown in Problem 3.19 that these representations are indeed irreducible (except that √nV is zero\nif n > dim V ).\n\n4.20\nSchur polynomials\nLet ∂ = (∂1, ..., ∂p) be a partition of n, and N ⊂ p. Let\n\nX\nN\n-\ns Y\nj +N-j\n\nj +N\nj\nD(x) =\n( 1)\nx\n= det(x\n-\ni\n).\ns(j)\ns2SN\nj=1\nDefine the polynomials\nD(x)\nS(x) := D0(x)\n(clearly D0(x) is just (x)). It is easy to see that these are indeed polynomials, as D is an\ntisymmetric and therefore must be divisible by . The polynomials S are called the Schur\npolynomials.\nProposition 4.61.\nY\n\n(xm\n1 + ... + xm\nN )im =\nX\nν(Ci)S(x).\nm\n:p→N\nProof. The identity follows from the Frobenius character formula and the antisymmetry of\n(x)\nY\n(xm +\nm\nm\n... + x\n\nN )i .\nm\nCertain special values of Schur polynomials are of importance. Namely, we have\nProposition 4.62.\nY\nzi-i\n\nN\n- zj -j\nS(1, z, z , ..., z -) =\n\nz-i - z-j\n1→i<j→N\nTherefore,\nY\n∂i - ∂j + j - i\nS(1, ..., 1) =\nj - i\n1→i<j→N\nProof. The first identity is obtained from the definition using the Vandermonde determinant. The\nsecond identity follows from the first one by setting z = 1.\n4.21\nThe characters of L\nProposition 4.61 allows us to calculate the characters of the representations L.\nNamely, let dim V = N, g 2 GL(V ), and x1, ..., xN be the eigenvalues of g on V . To compute\nthe character νL (g), let us calculate TrV\nn (g\nns), where s 2 Sn. If s 2 Ci, we easily get that this\ntrace equals\nY\n\nTr(g m)im =\nY\nHm(x)im .\nm\nm\nOn the other hand, by the Schur-Weyl duality\n\nTr\nn\nV\nn (g\ns) =\nX\nν(Ci)TrL (g).\nComparing this to Proposition 4.61 and using linear independence of columns of the character table\nof Sn, we obtain\n\nTheorem 4.63. (Weyl character formula) The representation L is zero if and only if N < p,\nwhere p is the number of parts of ∂. If N ⊂ p, the character of L is the Schur polynomial S(x).\nTherefore, the dimension of L is given by the formula\nY\n∂i - ∂\ndim L =\nj + j - i\nj - i\n1→i<j→N\nThis shows that irreducible representations of\n\nGL(V ) which occur in V\nn for some n are labeled\nby Young diagrams with any number of squares but at most N = dim V rows.\nProposition 4.64. The representation\n\nL+1N (where 1N = (1, 1, ...,\n\n1) 2 ZN) is isomorphic to\nL\n√N V .\n\n√N →\nn\n\nProof. Indeed, L\nV\nV\n\n√NV → V\nn+N , and the only component of V\nn+N\n\nthat has\nthe same character as\n\nL\nN\n\n√V is L+1N . This implies the statement.\n4.22\nPolynomial representations of GL(V )\nDefinition 4.65. We say that a finite dimensional representation Y of GL(V ) is polynomial (or\nalgebraic, or rational) if its matrix elements are polynomial functions of the entries of g, g -1 ,\ng 2 GL(V ) (i.e., belong to k[gij ][1/ det(g)]).\nFor example, V\nn and hence all L are polynomial. Also define\n\nL\nN\n\nr 1N := L\n(√V ⊕)\nr (this\n-·\ndefinition makes sense by Proposition 4.64). This is also a polynomial representation. Thus we\nhave attached a unique irreducible polynomial representation L of GL(V ) = GLN to any sequence\n(∂1, ..., ∂N ) of integers (not necessarily positive) such that ∂1 ⊂ ... ⊂ ∂N . This sequence is called\nthe highest weight of L.\nTheorem 4.66. (i) Every finite dimensional polynomial representation of GL(V ) is completely\nreducible, and decomposes into summands of the form L (which are pairwise non-isomorphic).\n(ii) (the Peter-Weyl theorem for GL(V )). Let R be the algebra of polynomial functions on\nGL(V ). Then as a representation of GL(V ) × GL(V ) (with action (δ(g, h)θ)(x) = θ(g-1xh),\ng, h, x 2 GL(V ), θ 2 R), R decomposes as\nR = L⊕\n\nL,\nwhere the summation runs over all ∂.\nProof. (i) Let Y be a polynomial representation of GL(V ). We have an embedding : Y ⊃ Y\nR\ngiven by (u, (v))(g) := u(gv), u 2 V ⊕. It is easy to see that is a homomorphism of representations\n(where the action of GL(V ) on the first component of Y\nR is trivial). Thus, it suffices to prove\nthe theorem for\n→\n\na subrepresentation Y\nRm. Now, every element of R is a polynomial of gij\ntimes a nonpositive power of det(g). Thus, R is a quotient of a direct sum of representations of the\n\nr\n\n⊕\n√N\n\nform S (V\nV )\n(\nV ⊕)\ns. So we may assume that Y is contained in a quotient of a (finite)\n\ndirect sum of such representations. As V ⊕= √N-1V\n√N V ⊕, Y is contained in a direct sum of\nrepresentations of the form V\nn\n(√N V ⊕)\ns, and we are done.\n(ii) Let Y be a polynomial representation of GL(V ), and let us regard R as a representation\nof GL(V ) via (δ(h)θ)(x) = θ(xh). Then HomGL(V )(Y, R) is the space of polynomial functions\non GL(V ) with values in Y ⊕, which are GL(V )-equivariant. This space is naturally identified\n\nwith Y ⊕. Taking into account the proof of (i), we deduce that R has the required decomposition,\nwhich is compatible with the second action of GL(V ) (by left multiplications). This implies the\nstatement.\nNote that the Peter-Weyl theorem generalizes Maschke's theorem for finite group, one of whose\nforms states that the space of complex functions Fun(G, C) on a finite group G as a representation\nof G × G decomposes\n\nas V 2Irrep(G)V ⊕\nV .\nRemark 4.67. Since the Lie algebra sl(V ) of traceless operators on V is a quotient of gl(V ) by\nscalars, the above results extend in a straightforward manner to representations of the Lie algebra\nsl(V ). Similarly, the results for GL(V ) extend to the case of the group SL(V ) of operators with\ndeterminant 1. The only difference is that in this case the representations L and L+1m are\nisomorphic, so the irreducible representations are parametrized by integer sequences ∂1 ⊂ ... ⊂ ∂N\nup to a simultaneous shift by a constant.\nIn particular, one can show that any finite dimensional representation of sl(V ) is completely\nreducible, and any irreducible one is of the form L (we will not do this here). For dim V = 2 one\nthen recovers the representation theory of sl(2) studied in Problem 1.55.\n4.23\nProblems\nProblem 4.68. (a) Show that the Sn-representation V\n0 := C[Sn]ba is isomorphic to V.\nHint. Define Sn-homomorphisms f : V ⊃ V\n0 and g : V\n0 ⊃ V by the formulas f(x) = xa and\ng(y) = yb, and show that they are inverse to each other up to a nonzero scalar.\n(b) Let θ : C[Sn] ⊃ C[Sn] be the automorphism sending s to (-1)ss for any permutation s.\nShow that θ maps any representation V of Sn to V\nC . Show also that θ(C[S\n\n-\nn]a) = C[Sn]θ(a),\nfor a 2 C[Sn]. Use (a) to deduce\n\nthat V\nC\n= V , where ∂⊕is the conjugate partition to ∂,\n-\nobtained by reflecting the Young diagram of ∂.\nProblem 4.69. Let Rk,N be the algebra of polynomials on the space of k-tuples of complex N by N\nmatrices X1, ..., Xk, invariant under simultaneous conjugation. An example of an element of Rk,N\nis the function Tw := Tr(w(X1, ..., Xk )), where w is any finite word on a k-letter alphabet. Show\nthat Rk,N is generated by the elements Tw.\nHint. Consider invariant functions that are of degree di in each Xi, and realize this space as\na tensor\n\nproduct\nd\niS\ni (V\nV ⊕). Then embed this tensor product into (V\nV ⊕)\nN = End(V )\nn,\nand use the Schur-Weyl duality to get the result.\n4.24\nRepresentations of GL2(Fq)\n4.24.1\nConjugacy classes in GL2(Fq)\nLet Fq be a finite field of size q of characteristic other than 2, and G = GL2(Fq). Then\n|G| = (q 2 -\n\n1)(q 2 - q),\nsince the first column of an invertible 2 by 2 matrix must be non-zero and the second column may\nnot be a multiple of the first one. Factoring,\n|GL2(Fq)| = q(q + 1)(q - 1)2 .\n\nThe goal of this section is to describe the irreducible representations of G.\nTo begin, let us find the conjugacy classes in GL2(Fq).\nNumber of elements in a conjugacy\nRepresentatives\nNumber of classes\nclass\n⎩\n\nx 0\nq 1 (one for every non\nScalar\n0 x\n1 (this is a central element)\n-\nzero x)\n⎩\n\nq -1 (elements that comm\n⎩ute\nwith\nx 1\n\nq -1 (one for every non\nParabolic\n\nthis one are\nform\nt u\n0 x\n\nof the\n\n0 t , t = zero x)\n0)\n⎩\n\nq + q (elements that comm\n⎩\nute\n\nwith\n\n(q 1)(q 2) (x, y = 0\nHyperbolic\nx 0 , y = x\nthis one are of the form\nt 0\n0 y\n0 u , t, u =\n\n-\n-\nand x = y)\n0)\n\nElliptic\nx ζy\ny x , x 2 Fq, y 2\nF×\nq , π 2\n⎩\nF\n\nq \\ F2\nq (characteris\nq2 -\nq (the reason will be described\nq(q 1) (matrices with\n-\ntic polynomial over Fq is irre\nbelow)\ny and -y are conjugate)\nducible)\nMore on the conjugacy class of elliptic matrices: these are the matrices whose characteristic\npolynomial is irreducible over Fq and which therefore don't have eigenvalues in Fq. Let A be such\na matrix, and consider a quadratic extension of Fq,\nFq(∀π), π 2 Fq \\ F2\nq.\nOver this field, A will have eigenvalues\nφ = φ1 + ∀πφ2\nand\nφ = φ1\n∀\n-\nπφ2,\nwith corresponding eigenvectors\nv, v (Av = φv, Av = φv).\nChoose a basis\n{e1 = v + v, e2 = ∀π(v - v)}.\nIn this basis, the matrix A will have the form\n\nφ1 πφ2\nφ2\nφ1\n\n,\njustifying the description of representative elements of this conjugacy class.\nIn the basis {v, v}, matrices that commute with A will have the form\n∂ 0\n0 ∂\n\n,\nfor all\n∂ 2 F×\nq2 ,\nso the\n\nnumber of such matrices is q2 - 1.\n⇒\n⇒\n\n4.24.2\n1-dimensional representations\nFirst, we describe the 1-dimensional representations of G.\nProposition 4.70. [G, G] = SL2(Fq).\nProof. Clearly,\n\ndet(xyx-1y-1) = 1,\nso\n[G, G] ∧ SL2(Fq).\nTo show the converse, it suffices to show that the matrices\n\n1 a\n0 1\n,\n0 a-1 , 1\n\nare commutators (as such matrices generate SL2(Fq).) Clearly, by using transposition, it suffices\nto show that only the first two matrices are commutators. But it is easy to see that the matrix\n\nis the commutator of the matrices\n\n1/2\nA = 0\n\n,\nB =\n\n,\n0 -1\nwhile the matrix\n\na\n0 a-1\n\nis the commutator of the matrices\na 0\n\nA =\n, B =\n\n,\nThis completes the proof.\nTherefore,\nG/[G, G] ∪= F×\nq via g ⊃ det(g).\nThe one-dimensional representations of G thus have the form\nδ(g) =\n⎩\ndet(g)\n\n,\nwhere is a homomorphism\n: F×\nq ⊃ C×;\nso there are q - 1 such representations, denoted C.\n\n4.24.3\nPrincipal series representations\nLet\n\nB → G, B =\n∼\n∼\n{\n\n}\n∼\n(the set of upper triangular matrices); then\n|B| = (q - 1)2 q,\n[B, B] = U = {\n∼\n\n},\nand\nB/[B, B] ∪= Fq\n×\n× F×\nq\n(the isomorphism maps an element of B to its two diagonal entries).\nLet\n∂ :\n\nB ⊃ C×\nbe a homomorphism defined by\n\na\nb\n∂\n\n= ∂1(a)∂2(c),for some pair of homomorphisms ∂1, ∂\n\n2 : F×\n\n0 c\nq ⊃ C×.\nDefine\nV1,2 = IndG\nB C,\nwhere C is the 1-dimensional representation of B in which B acts by ∂. We have\nG\ndim(V1,2 ) = | | = q + 1.\n|B|\nTheorem 4.71.\n1. ∂1 = ∂2 ≥ V1,2 is irreducible.\n\n2. ∂1 = ∂2 = μ ≥ V1,2 = Cμ Wμ, where Wμ is a q-dimensional irreducible representation of\nG.\n3. Wμ =∪ Wξ if and only if\n\n∪\n\n{\n}\n{\n⊗\n⊗\nμ = λ; V\n\nV\n⊗,⊗\n1,2 =\n\nif and only if\n∂1, ∂2\n=\n∂\n1, ∂ 2} (in the\nsecond case,\n⊗\n∂\n⊗\n1 = ∂2, ∂ 1 = ∂2).\nProof. From the Mackey formula, we have\n\ntrV , (g) =\n∂(aga\n-1).\n|B|\na2G,\nX\naga-1 2B\nIf\n\nx 0\ng =\n\n,\n0 x\nthe expression on the right evaluates to\n∂(g) |G| = ∂1(x)∂2(x)\n⎩\nq + 1\n\n.\n|B|\nIf\nx 1\ng =\n,\n0 x\n⇒\n⇒\n⇒\n\nthe expression evaluates to\n∂(g) · 1,\nsince here\naga-1 2 B ≥ a 2 B.\nIf\nx 0\ng = 0 y\n\n,\nthe expression evaluates to\n⎩\n\n∂1(x)∂2(y) + ∂1(y)∂2(x)\n\n· 1,\nsince here\naga-1 2 B ≥ a 2 B or a is an element of B multiplied by the transposition matrix.\nIf\n\nx πy\ng =\n, x = y\ny\nx\n\nthe expression on the right evaluates to 0 because matrices of this type don't have eigenvalues over\nFq (and thus cannot be conjugated into B). From the definition, ∂i(x)(i = 1, 2) is a root of unity,\nso\n|G|*\n\nν\nV , , νV\n\n, i = (q + 1) (q - 1) + (q\n\n-1)(q - 1)\n(q - 1)(q -\n\n2)\n+ 2(q + q)\n+ (q 2 + q)\nX\n∂1(x)∂2(y)∂1(y)∂2(x).\nx=y\nThe last two summands come from the expansion\n|a + b| 2 = | | 2\n\na\n+ |b| 2 + ab + ab.\nIf\n∂1 = ∂2 = μ,\nthe last term is equal to\n\n(q 2 + q)(q - 2)(q - 1),\nand the total in this case is\n(q + 1)(q - 1)[(q + 1) + (q - 1) + 2q(q - 2)] = (q + 1)(q - 1)2q(q - 1) = 2|G|,\nso\n*νV , , νV , i = 2.\nClearly,\nCμ ∧ IndG\nB Cμ,μ,\nsince\nHomG(Cμ, IndG\nBCμ,μ) = HomB(Cμ, Cμ) = C (Theorem 4.33).\nTherefore, IndG\nBCμ,μ = Cμ Wμ; Wμ is irreducible; and the character of Wμ is different for distinct\nvalues of μ, proving that Wμ are distinct.\n⇒\n\nIf ∂1\n\n= ∂2, let z = xy-1, then the last term of the summation is\n\nX\n\nX ∂1\n\n-\n\nX ∂1\n(q + q)\n∂1(z)∂2(z) = (q + q)\n(z) = (q + q)(q\n1)\n(z).\n∂2\n∂2\nx=y\nx;z=1\nz=1\nSince\nX ∂1 (z) = 0,\n× ∂\n\nz2Fq\nbecause the sum of all roots of unity of a given order m > 1 is zero, the last term becomes\n\n-\n∂\n\n-\n\nX\n(q + q)(q\n1)\n(1) = -(q 2 + q)(q - 1).\n∂2\nz=1\nThe difference between this case and the case of ∂1 = ∂2 is equal to\n-(q 2 + q)[(q - 2)(q - 1) + (q - 1)] = |G|,\nso this is an irreducible representation by Lemma 4.27.\nTo prove the third assertion of the theorem, we look at the characters on hyperbolic elements\nand note that the function\n∂1(x)∂2(y) + ∂1(y)∂2(x)\ndetermines ∂1, ∂2 up to permutation.\n4.24.4\nComplementary series representations\nLet Fq2 ∩ Fq be a quadratic\n\nextension Fq(∀π), π 2 Fq \\ F2\nq. We regard this as a 2-dimensional vector\nspace over Fq; then G is the group of linear transformations of Fq2 over Fq. Let K →G be the cyclic\ngroup of multiplications by elements of F×\nq2 ,\n\nx πy\nK = {\n\n} |\n\n, K\n\n| = q 2\ny\nx\n-.\nFor λ : K ⊃ C× a homomorphism, let\nYξ = IndG\nK Cξ.\nThis representation, of course, is very reducible. Let us compute its character, using the Mackey\nformula. We get\nx 0\nν\n= q(q - 1)λ(x);\n0 x\nν(A) = 0 for A parabolic or hyperbolic;\nx πy\nx πy\n\nx\nq\nπy\nν\n= λ\n+ λ\ny\n\n.\n\ny\nx\nx\ny\nx\nThe last assertion holds because if we regard the matrix as an element of Fq2 , conjugation is an\n\nautomorphism of Fq2 over Fq, but the only nontrivial automorphism of Fq2 over Fq is the qth power\nmap.\n⇒\n\nWe thus have\n\nIndGC\n=\nG\nK\nξq ∪IndK Cξ\nbecause\n\nthey have the same character. Therefore, for λ q =\n\nλ we get 1q(q\n- 1) representations.\nNext, we look at the following tensor product:\nW1\nV,1,\nwhere 1 is the trivial character and W1 is defined as in the previous section. The character of this\nrepresentation is\nx 0\nν\n= q(q + 1)φ(x);\n0 x\nν(A) = 0 for A parabolic or elliptic;\nx 0\nν\n= φ(x) + φ(y).\n0 y\nThus the \"virtual representation\"\nW\nG\nV,1 - V,1 - IndK Cξ ,\nwhere φ is the restriction of λ to scalars, has character\n\nx 0\nν\n= (q 1)φ(x);\n0 x\n\n-\nx 1\nν\n=\nφ(x);\n0 x\n-\nν\n\nx 0\n= 0;\n0 y\nx πy\n\nx πy\n\nν\n\nx πy\n\n= -λ\n- λq\n\n.\ny\nx\ny\nx\ny\nx\nIn all that follows, we will\n\nhave λq = λ.\nThe following two lemmas will establish that the inner product of this character with itself is\nequal to 1, that its value at 1 is positive. As we know from Lemma 4.27, these two properties imply\nthat it is the character of an irreducible representation of G.\nLemma 4.72. Let ν be the character of the \"virtual representation\" defined above. Then\n*ν, νi = 1\nand\nν(1) > 0.\nProof.\nν(1) = q(q + 1) - (q + 1) - q(q - 1) = q - 1 > 0.\nWe now compute the inner product *ν, νi. Since φ is a root of unity, this will be equal to\n\nq(\n1)\n\nq\n(q-1) (q-1)2 1+(q-1) 1 (q 2-1)+\n-\nX\n(λ(ψ)+λq(ψ))(λ(ψ) + λq(ψ))\n\n(q - 1)2q(q + 1)\n·\n·\n· ·\n·\nλ elliptic\n⇒\n⇒\n\nBecause λ is also a root of unity, the last term of the expression evaluates to\nX\n(2 + λq-1(ψ) + λ1-q(ψ)).\nλ elliptic\nLet's evaluate the last summand.\nSince F×\nq2 is cyclic and λq = λ,\nX\n\nλq-1(ψ) =\nX\nλ1-q(ψ) = 0.\nλ2\n×\nFq2\nλ2\n×\nFq2\nTherefore,\nX\n\n(λq-1(ψ) + λ1-q(ψ)) =\n\n(λq-1(ψ) + λ1-q(ψ)) =\n2(q 1) =\nλ elliptic\n-\nX\n-\n-\nλ2\n×\nFq\nsince F×\nq is cyclic of order q - 1. Therefore,\n\nq(q 1)\n\nν, νi =\n⎩\n(q -1) (q\n-\n-1)2 1+(q -1) 1 (q 2 -1)+\n(2(q 2 -q)-2(q\n(q -\n2q(q + 1)\n-1))\n1)\n\n= 1.\n*\n·\n·\n· ·\n·\nWe have now shown that for any\n\nλ with λq = λ the representation Yξ with the same character\nas\nW1\nV\nG\n,1 - V,1 - IndK Cξ\nexists and is irreducible. These characters are distinct for distinct pairs (φ, λ) (up to switch\nλ ⊃ λq), so there are q(q-1) such representations, each of dimension q - 1.\nWe have thus found q - 1\nq(q\n1)\n1-dimensional representations of G,\n-\nprincipal series repre\nsentations, and q(q-1) complementary series representations, for a total of q2 - 1 representations,\ni.e., the number of conjugacy classes in G. This implies that we have in fact found all irreducible\nrepresentations of GL2(Fq).\n4.25\nArtin's theorem\nTheorem 4.73. Let X be a conjugation-invariant system of subgroups of a finite group G. Then\ntwo conditions are equivalent:\n(i) Any element of G belongs to a subgroup H 2 X.\n(ii) The character of any irreducible representation of G belongs to the Q-span of characters of\n\ninduced representations IndG\nH V , where H 2 X and V is an irreducible representation of H.\nRemark. Statement (ii) of Theorem 4.73 is equivalent to the same statement with Q-span\nreplaced by C-span. Indeed, consider the matrix whose columns consist of the coefficients of the\ndecomposition of IndG\nH V (for various H, V ) with respect to the irreducible representations of G.\nThen both statements are equivalent to the condition that the rows of this matrix are linearly\nindependent.\n⇒\n⇒\n\nProof. Proof that (ii) implies (i). Assume that g 2 G does not belong to any of the subgroups\nH 2 X. Then, since X is conjugation invariant, it cannot be conjugated into such a subgroup.\nHence by the Mackey formula, νIndG (V )(g) = 0 for all H 2 X and V . So by (ii), for any irreducible\nH\nrepresentation W of G, νW (g) = 0. But irreducible characters span the space of class functions, so\nany class function vanishes on g, which is a contradiction.\nProof that (i) implies (ii). Let U be a virtual representation of G over C (i.e., a linear combina\ntion of irreducible representations with nonzero integer coefficients) such that (νU , νIndG V ) = 0 for\nH\nall H, V . So by Frobenius reciprocity, (νU|H , νV ) = 0. This means that νU vanishes on H for any\nH 2 X. Hence by (i), νU is identically zero. This implies (ii) (because of the above remark).\nCorollary 4.74. Any irreducible character of a finite group is a rational linear combination of\ninduced characters from its cyclic subgroups.\n4.26\nRepresentations of semidirect products\nLet G, A be groups and θ : G ⊃ Aut(A) be a homomorphism. For a 2 A, denote θ(g)a by g(a).\nThe semidirect product G ∼ A is defined to be the product A × G with multiplication law\n(a1, g1)(a2, g2) = (a1g1(a2), g1g2).\nClearly, G and A are subgroups of G ∼ A in a natural way.\nWe would like to study irreducible complex representations of G ∼ A. For simplicity, let us do\nit when A is abelian.\nIn this case, irreducible representations of A are 1-dimensional and form the character group\nA∗, which carries an action of G. Let O be an orbit of this action, x 2 O a chosen element,\nand Gx the stabilizer of x in G. Let U be an irreducible representation of Gx. Then we define a\nrepresentation V(O,U) of G ∼ A as follows.\nAs a representation of G, we set\n\nV(O,x,U) = IndG\nGx U = {f : G ⊃ U|f(hg) = hf(g), h 2 Gx}.\nNext, we introduce an additional action of A on this space by (af)(g) = x(g(a))f(g). Then it's\neasy to check that these two actions combine into an action of G ∼ A. Also, it is clear that this\nrepresentation does not really depend on the choice of x, in the following sense. Let x, y 2 O,\nand g 2 G be such that gx = y, and let g(U) be the representation of Gy obtained from the\nrepresentation U of Gx by the action of g. Then V(O,x,U) is (naturally) isomorphic to V(O,y,g(U)).\nThus we will denote V(O,x,U) by V(O,U) (remembering, however, that x has been fixed).\nTheorem 4.75. (i) The representations V(O,U) are irreducible.\n(ii) They are pairwise nonisomorphic.\n(iii) They form a complete set of irreducible representations of G ∼ A.\n(iv) The character of V = V(O,U) is given by the Mackey-type formula\n\nνV (a, g) =\nX\nx(h(a))νU (hgh-1).\n|Gx|\nh2G:hgh-12Gx\n\nProof. (i) Let us decompose V = V(O,U) as an A-module. Then we get\nV = y2OVy,\nwhere Vy = {v 2 V(O,U)|av = (y, a)v, a 2 A}. (Equivalently, Vy = {v 2 V(O,U)|v(g) = 0 unless gy =\nx}). So if W → V is a subrepresentation, then W = y OWy, where W\ny → Vy. Now, Vy is a\nrepresentation of Gy, which goes to U under any isomorphism Gy ⊃ Gx determined by g 2 G\nmapping x to y. Hence, Vy is irreducible over Gy, so Wy = 0 or Wy = Vy for each y. Also, if hy = z\nthen hWy = Wz, so either Wy = 0 for all y or Wy = Vy for all y, as desired.\n(ii) The orbit O is determined by the A-module structure of V , and the representation U by\nthe structure of Vx as a Gx-module.\n(iii) We have\nX\n\ndim V(U,O) =\nX\n|O| 2(dim U)2 =\nU,O\nU,O\nX\n|O|2|Gx| =\nX\n\n|O||G/Gx||Gx| = |G|\n\nX\n|O| = G||A∗\n\n|\n| = |G ∼ A|.\nO\nO\nO\n(iv) The proof is essentially the same as that of the Mackey formula.\nExercise. Redo Problems 3.17(a), 3.18, 3.22 using Theorem 4.75.\nExercise. Deduce parts (i)-(iii) of Theorem 4.75 from part (iv).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n18.712 Introduction to Representation Theory\nFall 2010"
    },
    {
      "category": "Resource",
      "title": "Structure of finite dimensional algebras",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/70961c084499052681efb7485af37858_MIT18_712F10_ch7.pdf",
      "content": "Structure of finite dimensional algebras\nIn this section we return to studying the structure of finite dimensional algebras. Throughout the\nsection, we work over an algebraically closed field k (of any characteristic).\n7.1\nProjective modules\nLet A be an algebra, and P be a left A-module.\nTheorem 7.1. The following properties of P are equivalent:\n(i) If φ : M ⊃ N is a surjective morphism, and λ : P ⊃ N any morphism, then there exists a\nmorphism μ : P ⊃ M such that φ inf μ = λ.\n(ii) Any surjective morphism φ : M ⊃ P splits, i.e., there exists μ : P ⊃ M such that φinfμ = id.\n(iii) There exists another A-module Q such that P Q is a free A-module, i.e., a direct sum of\ncopies of A.\n(iv) The functor HomA(P, ?) on the category of A-modules is exact.\nProof. To prove that (i) implies (ii), take N = P . To prove that (ii) implies (iii), take M to be free\n(this can always be done since any module is a quotient of a free module). To prove that (iii) implies\n(iv), note that the functor HomA(P, ?) is exact if P is free (as HomA(A, N) = N), so the statement\nfollows, as if the direct sum of two complexes is exact, then each of them is exact. To prove that\n(iv) implies (i), let K be the kernel of the map φ, and apply the exact functor HomA(P, ?) to the\nexact sequence\n0 ⊃ K ⊃ M ⊃ N ⊃ 0.\nDefinition 7.2. A module satisfying any of the conditions (i)-(iv) of Theorem 7.1 is said to be\nprojective.\n7.2\nLifting of idempotents\nLet A be a ring, and I → A a nilpotent ideal.\nProposition 7.3. Let e0 2 A/I\n\nbe an idempotent, i.e., e2\n0 = e0. There exists an idempotent e 2 A\nwhich is a lift of e0 (i.e., it projects to e0 under the reduction modulo I). This idempotent is unique\nup to conjugation by an element of 1 + I.\nProof. Let us first establish the statement in the case when\n\nI 2 = 0. Note that in this case I is a\nleft and right module over\n\nA/I. Let e be any lift of e\n0 to A. Then e - e = a I, and e a = ae .\n⊕\n⊕\n⊕\nWe look for e in the form e = e + b, b 2 I. The equation for b is e0b + be0 - b = a.\n⊕\nSet b = (2e0 - 1)a. Then\ne0b + be0 - b = 2e0a - (2e0 - 1)a = a,\nso\n\ne is an idempotent. To classify other\n\nsolutions, set e0 = e + c. For e0 to be an idempotent, we\nmust have ec + ce - c = 0. This is equivalent to saying that ece = 0 and (1 - e)c(1 - e) = 0, so\nc\n\n= ec(1 - e) + (1 -\n\ne)ce = [e, [e, c]]. Hence e0 = (1 + [c, e])e(1 + [c, e])-1.\n\nNow, in the general case, we prove by induction in k that there exists a lift ek of\n\ne0 to A/Ik+1,\nand it is unique up\n\nto conjugation by an element of 1 + I k (this is sufficient as I is nilpotent).\nAssume it is true for k = m - 1, and let us prove it for k = m. So we have an idempotent\nem\n1 2 A/Im, and we have to lift it\n\nto A/Im+1. But (Im)2 = 0 in A/Im+1, so we are done.\n-\nDefinition 7.4. A complete system of orthogonal idemp\n⎨otents in a unital algebra B is a collection\nof elements e1, ..., en 2 B such that eiej = ζijei, and\nn\ni=1 ei = 1.\nCorollary 7.5. Let e01, ..., e0m be a complete system of orthogonal idempotents in A/I. Then there\n\nexists a complete system of orthogonal idempotents e1, ..., em (eiej = ζijei, ⎨ei = 1) in A which\nlifts e01, ..., e0m.\nProof. The proof is by induction in m. For m = 2 this follows from Proposition 7.3. For m > 2,\nwe lift e01 to e1 using Proposition 7.3, and then apply the induction assumption to the algebra\n(1 - e1)A(1 - e1).\n7.3\nProjective covers\nObviously, every finitely generated projective module over a finite dimensional algebra A is a direct\nsum of indecomposable projective modules, so to understand finitely generated projective modules\nover A, it suffices to classify indecomposable ones.\nLet A be a finite dimensional algebra, with simple modules M1, ..., Mn.\nTheorem 7.6. (i) For each i = 1, ..., n there exists a unique indecomposable finitely generated\nprojective module Pi such that dim Hom(Pi, Mj ) = ζij .\n(ii) A = n\ni=1(dim Mi)Pi.\n(iii) any indecomposable finitely generated projective module over A is isomorphic to Pi for\nsome i.\nProof.\n\nRecall that A/Rad(A) = n\ni=1 End(Mi), and Rad(A) is a nilpotent ideal. Pick a basis of\n\nMi, and let e0\nEi\nij =\njj, the rank 1 projectors projecting to the basis vectors of this basis (j =\n\n1, ..., dim Mi). Then e0\nij are orthogonal idempotents in A/Rad(A). So by Corollary 7.5 we can lift\nthem to orthogonal idempotents\n\ne\ndim\n\nij in A. Now define Pij = Ae\nMi\nij . Then A = i j=1\nPij , so Pij\nare projective. Also, we have Hom(Pij , Mk) = eij Mk, so dim Hom(Pij , Mk) = ζik. Finally, Pij is\n\n×\nindependent of j up to an isomorphism, as eij for fixed i are conjugate under A\nby Proposition\n7.3; thus we will denote Pij by Pi.\nWe claim that Pi is indecomposable. Indeed, if Pi = Q1 Q2, then Hom(Ql, Mj ) = 0 for all j\neither for l = 1 or for l = 2, so either Q1 = 0 or Q2 = 0.\nAlso, there can be no other indecomposable finitely generated projective modules, since any\nsuch module has to occur in the decomposition of A. The theorem is proved.\nReferences\n[BGP] J. Bernstein, I. Gelfand, V. Ponomarev, Coxeter functors and Gabriel's theorem, Russian\nMath. Surveys 28 (1973), no. 2, 17-32.\n\n[Cu] C. Curtis, Pioneers of Representation Theory: Frobenius, Burnside, Schur, and Brauer, AMS,\n1999.\n[CR] C. Curtis and I. Reiner, Representation Theory of Finite Groups and Associative Algebras,\nAMS, 2006.\n[FH] W. Fulton and J. Harris, Representation Theory, A first course, Springer, New York, 1991.\n[Fr] Peter J. Freyd, Abelian Categories, an Introduction to the Theory of Functors. Harper and\nRow (1964).\n[McL] S. MacLane, Categories for a working Mathematician: 2nd Ed., Graduate Texts in Mathe\nmatics 5, Springer, 1998.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.\n18.712 Introduction to Representation Theory\nFall 2010"
    }
  ]
}