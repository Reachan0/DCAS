{
  "course_name": "Affective Computing",
  "course_description": "No description found.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Artificial Intelligence",
    "Science",
    "Cognitive Science",
    "Social Science",
    "Psychology",
    "Engineering",
    "Computer Science",
    "Artificial Intelligence",
    "Science",
    "Cognitive Science",
    "Social Science",
    "Psychology"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 1 session / week, 3 hours / session\n\nCourse Overview\n\nThis course instructs students on how to develop technologies that help people measure and communicate emotion, that respectfully read and that intelligently respond to emotion, and have internal mechanisms inspired by the useful roles emotions play. Topics vary from year to year, and may include the interaction of emotion with cognition and perception; the communication of human emotion via face, voice, physiology, and behavior; construction of computers, agents, and robots having skills of emotional intelligence; the role of emotion in decision-making and learning; and affective technologies for education, autism, health, and market research applications. Weekly reading, discussion, and a term project are required.\n\nSample Topics\n-\nFinal topics will be selected with input from this year's class\n:\n\nEmotionally Intelligent Human Computer Interaction\n\nEmotion and Perception, Decision-making, and Creativity\n\nEmotion and Learning\n\nPhysiology of Emotion\n\nNeuroscience Findings Related to Emotion\n\nAffect Recognition by Machines (include wearable systems)\n\nCommunicating Frustration / Stress in Autism and in Customer Experience\n\nResponding to User Emotion to Reduce User Frustration\n\nInducing Emotion\n\nRobots / Agents that \"have\" Emotion\n\nEmotion and Behavior\n\nExpression of Emotion by Machines / Agents / Synthetic characters\n\nPhilosophical, Social, Ethical Implications of Affective Computing\n\nMachine / Mobile Empathy and Emotional Support\n\nLie Detection and Stress Detection\n\nPrerequisites\n\nMIT students were required to obtain permission of the instructor.\n\nExpectations\n\nAll students are expected to attend all classes and all project and proposal presentations.\n\nAbsence from class, especially on project and proposal presentation days, will significantly affect your learning experience and grade.\n\nGrading\n\nACTIVITIES\n\nPERCENTAGES\n\nClassroom participation\n\n20%\n\nWeekly assignments (reading / response)\n\n35%\n\nFinal project and presentation\n\n45%",
  "files": [
    {
      "category": "Resource",
      "title": "MAS.630F15 Affective Computing Ethical Discussions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-630-affective-computing-fall-2015/22ac0d7015d449fa3d8280ab2751bec8_MITMAS_630F15_Ethical.pdf",
      "content": "MAS.630 Ethical Discussions\nMAS.630 Ethical Discussions Sign Up: In Session 9 we will discuss several ethical\nissues in Affective Computing. Please answer the below to indicate what topics you'd be\nwilling to be assigned to discuss (everybody will be assigned one). If you can't get\njazzed about any of these then add one that you're really eager to tackle. Also, it's OK if\nyou don't know what you believe on the issues: That is all the more reason for us to\ndiscuss them.\n\nSuppose it were possible to create a wearable technology that regulates the\nwearer's emotions - so that they never get \"out of control\".\nI'm willing to argue for \"let's support letting it be built\"\nI'm willing to argue for \"let's not let it be built\"\nI could argue either side of this issue\n\nRobots walking around in public (with eyes/cameras) should have the ability to\nsee not only that you are a person, but also if you are a happy, interested,\nconfused, or annoyed person. However they should be limited from making more\nsophisticated moral-affective judgments about people, such as \"you are sulking\".\nI'm willing to argue for \"Let's let the robots make such moral-affective judgments\nabout people\"\nI'm willing to argue for \"Let's NOT let the robots make such moral-affective\njudgments about people\"\nI could argue either side of this issue\n\nSuppose it were possible to create a technology that you can wear covertly (like a\nspy camera) that reads whether or not the person in front of you is having the\n\"fight or flight\" autonomic response associated with lying.\nI'm willing to argue for \"let's support letting it be built\"\nI'm willing to argue for \"let's NOT support letting it be built\"\nI could argue either side of this issue\n\nIf computers can be given true emotions, then they can take over the world\n(including possibly enslaving or destroying human-kind).\nI'm willing to argue for \"The movies have it right - this really could happen if we\ngive computers emotions\"\nI'm willing to argue for \"This is hogwash: adding emotions does not enable this\noutcome.\"\nI could argue either side of this issue\n\nRobots of the future, which interact with lots of people, may need to form\njudgments as to who is \"good\" and who is \"not good.\" Robot feelings should be\nallowed to be hidden from people in these cases.\nI'm willing to argue \"Yes, allow robot emotions to be hidden in cases like this.\"\nI'm willing to argue \"No, do NOT allow robot emotions to be hidden.\"\nI could argue either side of this issue\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.630 Affective Computing\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MAS.630F15 Frustration, Empathy, and Relational Agents",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-630-affective-computing-fall-2015/155f682d08d2b9efb01d24b068e88c51_MITMAS_630F15_Frustration.pdf",
      "content": "Handling frustration, Relational\nand Caring computers, Empathy,\n**PubPub**\n\n- Four out of five have seen colleagues\nhurling abuse at their PCs\n- Three quarters admit that they swear\nat their computers.\n- Nearly half of all people working with\ncomputers feel frustrated or stressed\nbecause of IT problems\n- A quarter of all under-25-year-olds\nadmit they have kicked their computer\n(MORI survey in UK, 1250 users)\n\nSkills of Emotional Intelligence:\n- Expressing emotions\n- Recognizing emotions\n- Handling another's emotions\n- Regulating emotions \\\n- Utilizing emotions /\n(Salovey and Mayer 90, Goleman 95, Picard 97)\nif \"have emotion\"\n\n\"Bad Day\"\n\"A real bad day at the office\"\nImage courtesy of the Portland Center Stage on flickr. License CC BY-NC.\n\nHow do you build empathetic\ntechnology? What happens when\ntechnology appears to show\nempathy?\n\nKlein, J., Moon, Y., & Picard, R. W. (1999). This computer responds to user frustration In\n, CHI '99 extended abstracts on Human factors in computing systems (pp. 242-243).\nPittsburgh, Pennsylvania: ACM. doi: 10.1145/632716.632866.\n\nBickmore, T., & Schulman, D. (2007). Practical approaches to comforting users with\nrelational agents In , CHI '07 extended abstracts on Human factors in computing\nsystems (pp. 2291-2296). San Jose, CA, USA: ACM. doi: 10.1145/1240866.1240996.\n\nPicard, R. W., & Liu, K. K. (2007). Relative subjective count and assessment of\ninterruptive technologies applied to mobile monitoring of stress, Int. J. Hum.-Comput.\nStud., 65(4), 361-375. doi: 10.1016/j.ijhcs.2006.11.019.\n\nNass, C., Jonsson, I., Harris, H., Reaves, B., Endo, J., Brave, S., et al. (2005). Improving\nautomotive safety by pairing driver emotion and car voice emotion In , CHI '05 extended\nabstracts on Human factors in computing systems (pp. 1973-1976). Portland, OR, USA:\nACM.\nComputer empathy\n\nWhat is the affect elicited? Is the affect ignored or addressed?\nWhat kind of emotional intelligence is this showing?\n(c) Mendeley. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nExample: Emotional Intelligence (from Ben Bloomberg HWK1) 404 page on\nTumblr.com\n(c) LiveJournal. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\n\"Management of\nUser Emotional State\"\n\n1. You can't always fix the problem at the time the user is\nfrustrated.\n\n2. You can still help: actively support someone in their ability to\nregulate, manage, and recover from their own negative emotional\nstates.\n\nGoal:\nHelp relieve user frustration\n\nStrategy:\n1. Recognize situation as frustrating\n2. Is user willing to talk? If so:\n- Practice active listening, with empathy and\nsympathy\n\n\"Sorry to hear your experience wasn't better\"\n\n\"This computer apologizes to you for ...\"\n- Allow for repair...\n\nEvaluation:\nBuild it. Test this \"AFFECT-SUPPORT\" with 70 subjects\nagainst two control conditions: IGNORE and VENT.\n\nTest/evaluation: 70 subjects\n\nHere's the 6 conditions again, from a different view. We ran 70 subjects, half men half women,\nand here's what they did: first they were briefed on the cover story from a script. Then they\nplayed a timed game for 5 minutes, in which the user directs a character to go through a maze\nand find treasure--we deliberately designed it to be boring, and users confirmed this. Folks in\nthe top half of this diagram just played the game, but subjects in the bottom of this diagram got\nnailed.\n\n(POINT) See it only appeared to be a web browser (the whole thing was done in Director).\nDuring the five minutes of timed play, we faked a mess of web-server delays, so that the\ncharacter was frozen to the user's controls but the on-screen timer continued to elapse. This\nwas the DELAY condition.\n\nThen subjects answered one of three apparent on-line questionnaires: One asked questions\nabout the user and the game through radio buttons, not allowing the user to report anything\nrelated to a problem. The second questionnaire asked some of the same questions as the first,\nbut then enabled subjects to report the problem and describe any emotional reaction. The third\nquestionnaire started out like the first two, but then turned into the AFFECT-SUPPORT agent I\nshowed you.\n\nAll subjects were then asked to play the game a second time for at least 3 minutes, after which\nthey could quit at any time (up to a 20 minute max). This time there was no prize or any other\nincentive to play for any length of time.\n\nKlein '99\n\nThe cover story we told subjects was that we\nhad a new, high-tech, Web-based game\nprototype we needed them to evaluate, but to\ndo their absolute best at. Two $100 prizes\nwould be given to the top two scorers, and get\nthis, even novice gamers could do well, since\nsuccess was based on intelligence (and these\nwere mostly MIT students, so this got them\ngoing).\n\nHypothesis 1:\nDELAY condition should frustrate more\nthan NO-DELAY\n\nResult 1:\nManipulation check: Delay did frustrate\nmore\n- Full factorial ANOVA, F(1, 64) = 4.54, p<.05\n\nHypothesis 2:\nAFFECT-SUPPORT group (following\nintervention) should play longest compared to\nIGNORE and VENT groups\n\nResults confirmed hypothesis 2:\nMain effect for the three kinds of feedback\n- Full factorial ANOVA, F(2, 64) = 8.00, p<.01\n- 2 Planned orthogonal comparisons, p<.01\n\nOther Results\n- No effect from gender, age, trait\narousability or game play experience\n- Main effect for frustration level\n- Full factorial ANOVA, F(1, 64) = 9.20, p<.001\n- No significant differences found\nbetween IGNORE and VENT conditions\n\n-Klein, J., Moon, Y., & Picard, R. W. (1999). This computer responds to user frustration In\n, CHI '99 extended abstracts on Human factors in computing systems (pp. 242-243).\nPittsburgh, Pennsylvania: ACM. doi: 10.1145/632716.632866.\n\n-Bickmore, T., & Schulman, D. (2007). Practical approaches to comforting users with\nrelational agents In , CHI '07 extended abstracts on Human factors in computing\nsystems (pp. 2291-2296). San Jose, CA, USA: ACM. doi: 10.1145/1240866.1240996.\n\n-Picard, R. W., & Liu, K. K. (2007). Relative subjective count and assessment of\ninterruptive technologies applied to mobile monitoring of stress, Int. J. Hum.-Comput.\nStud., 65(4), 361-375. doi: 10.1016/j.ijhcs.2006.11.019.\n\n-Nass, C., Jonsson, I., Harris, H., Reaves, B., Endo, J., Brave, S., et al. (2005). Improving\nautomotive safety by pairing driver emotion and car voice emotion In , CHI '05 extended\nabstracts on Human factors in computing systems (pp. 1973-1976). Portland, OR, USA:\nACM.\n\nIt's not about the nail\n\nConsider this criticism:\n\n\"Empathetic technology\" cannot succeed\nbecause technology cannot feel what\npeople feel. Can you give an example\nwhere one person cannot feel what\nanother person feels, and yet their\nempathy succeeds?\n\nWhat happens when people interact with a \"Relational\" agent\nfor a month, compared to a Non-Relational agent, where both\nagents have same scripts encouraging exercise, and the\nrelational has other skills, e.g., empathy\nRELATIONAL:\nalso asked about\n& responded to\naffect, used small\ntalk, adjusted\nlanguage over\ntime, adjusted\nsocial distance...\n\nSignificant effects of adding\nRelational skills to agent:\n- \"Laura and I respect each other.\" (p<.001)\n- \"Laura and I trust one another.\" (p<.001)\n- \"I feel Laura cares about me...\" (p<.001)\n- \"I feel Laura appreciates me.\" (p=.009)\n- \"I believe Laura likes me.\" (p<.001)\n- Liking of Laura. (p=.007)\n- Desire to continue working with Laura. (p=.001)\n\n(Bickmore and Picard, TOCHI 2004)\n\nReferences\nSalovey, P., and John D. Mayer. \"Emotional Intelligence.\" (PDF)\nImagination, Cognition, and Personality 9, no. 3 (1990): 185-211.\n\nGoleman, Daniel. Emotional Intelligence: Why It Can Matter\nMore Than IQ. Bantam Books, 1995. ISBN: 9780553383713.\n\nBickmore, Timothy W., and Rosalind W. Picard. \"Establishing\nand Maintaining Long-Term Human-Computer Relationships.\"\nAcm Transactions on Computer Human Interaction 12, no. 2\n(2005): 293-327.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.630 Affective Computing\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MAS.630F15 Week 2  - Extra Slides on EDA and Arousal",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-630-affective-computing-fall-2015/4d9896c3e3cf7c3e0f35eac6aa4d85db_MITMAS_630F15_Week2.pdf",
      "content": "MIT Media Lab\n\nHow do you figure out what is painful or\ndistressing to a non-speaking person?\n\nMany do not\nshow outward\nsigns\nconsistent\nwith internal\nstress/state.\nImage courtesy of John Glenn\n\non flickr. License CC BY-NC-SA.\n\nMIT Media Lab\nSympathetic division\nStimulation: \"fight or flight\"\nParasympathetic division\nInhibitory: \"rest and digest\"\nAUTONOMIC NERVOUS SYSTEM\n(Not shown: Enteric division)\n(c) Robert Sapolsky. All rights reserved. This content is excluded from our Creative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMIT Media Lab\nTraditional\nElectrodermal Activity (EDA) Sensors\nAffectiva QTM\nMIT Media Lab\nInnovations\n(c) BIOPAC Systems Inc. All rights reserved. This content\nis excluded from our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use/.\n(c) Affectiva. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more\ninformation, see http://ocw.mit.edu/help/faq-fair-use /.\n\nMIT Media Lab\nTypical placement skin conductance\nelectrodes (figure 4 from Figner-Murphy)\n(c) Psychology Press. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMIT Media Lab\nExample: Measuring sympathetic nervous system\nresponse via electrodermal activity (EDA) on lower\nlegs\n(c) Sensory Processing Disorder Foundation. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMIT Media Lab\nPatriots\nTouchdown\n\nDoritos\nMouse\nPatriots\n1st Down\nEnd Zone\nOverthrown\nLeading up to\nPatriotsTouchdown\nArousal predicts memory and attention\n\nMIT Media Lab\nWhat makes EDA go up? | Demo\n(c) Affectiva. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n(c) Affectiva. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMIT Media Lab\n(Sano & Picard; MIT, EMBC 2011, collaborations with Bob Stickgold,\nHarvard & Beth Israel hospital, Chuck Czeisler, Harvard & Brigham &\nWomen's hospital)\nState of the art:\n- Built sensor & algorithms\n- Detects \"peak storms\" (92% in Non-REM)\n- Measuring connections to learning & memory &\nstress\n\nMIT Media Lab\narousals picked up\nby wristband while\ntrying to fall asleep\n\nEDA arousals relate to quality of sleep in Autism Spectrum\nDisorders Sano, Picard, el Kaliouby, Malow, Goldman, IMFAR\n2011.\n\nMIT Media Lab\nEDA \"Storms\" during sleep\nSkin conductance,\nμS\nInvestigating relation to sleep quality and to improvement\non a visual discrimination task\nSano, Picard, Wang, Stickgold, APSS 2011.\n\nMIT Media Lab\nSano A., Picard R.W., \"Recognition of Sleep Dependent Memory\nConsolidation with Multi-modal Sensor Data\", The 10th Annual Body\nSensor Networks Conference 2013, Cambridge, USA, May 2013\nEDA gives the highest accuracy\ndetermining who improved the most on\nthe learning task\n\nMIT Media Lab\nSeizures\nLabeled\nfrom\nEEG\n94% accurate convulsive seizure detection using\na wrist-worn electrodermal activity and\naccelerometry biosensor. Poh et al (2012),\nEpilepsia.\n(c) Wiley. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nMIT Media Lab\nCanadian Epilepsy Alliance video:\nPlayground Convulsive Seizure\n\nMIT Media Lab\nMangina & Beuzeron-Mangina 1996, Int. J.\nPsychophysiology 22(1996)1-8.\nStimulation on\nbrain's left side\nStimulation on\nbrain's right side L AmygL aHpcL pHpcL CingR AmygRaHpcRpHpcRCing\n(c) International Journal of Psychopsychology. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n.\n\nSudden Unexplained Death in Epilepsy\n(SUDEP)\n\nPost-ictal EEG Suppression:\nPossible biomarker for SUDEP risk\nLhatoo, S.D. et al., Ann Neurol 68 (2010)\n(c) Annals of Neurology. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nAutonomic response (from wrist) is correlated\nwith duration of EEG suppression (SUDEP\nbiomarker)\nPoh et al. (2012) Neurology\n(c) Neurology. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nLarger Sympathetic\n(EDA) occurs with\nlonger post-ictal EEG\nsuppression (PGES)\nPoh et al. (2012) Neurology\nLower Parasympathetic\n(Heart Rate Variability\nHigh Frequency) occurs\nwith longer PGES\n(c) Neurology. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\n(c) Neurology . All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\n\nHuman Embryo: Three tissue layers\n\nEctoderm\nSkin and neural tissue\nEndoderm\nDigestive and respiratory track\nMesoderm\nMuscle and bone\nThis image is in the public domain.\n\nMIT Media Lab\nWhy look at both left and right EDA, separately?\n\nRight amygdala is associated with\nthreat/negative stimuli\n\nLeft amygdala is associated with a\nmix of positive and negative\narousal.\n\nJi G, Neugebauer V. (2009) \"Hemispheric\nlateralization of pain processing by amygdala\nneurons\" J Neurophysiol. 2009 Oct;102(4):2253-\n64. Epub 2009 Jul 22\nImage courtesy of BruceBlaus. License CC BY.\n\nMIT Media Lab\nWhy look at left and right EDA?\nRight\namygda\nla\nactivate\ns EDA\non Right\nwrist\n\nLeft\namygd\nala\nactivate\ns EDA\non Left\nwrist\nSkin conductance (sympathetic nervous response) is\nipsilateral to these limbic brain structures\n\nAmygdala\nPosterior hippocampus\nAnterior hippocampus\nAnterior cingulate gyri\n\nMangina & Beuzeron-Mangina 1996, Int. J. Psychophysiology 22(1996)1-8.\n(c) Affectiva. All rights reserved. This\ncontent is excluded fromour Creative\nCommons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\n(c) Affectiva. All rights reserved. This\ncontent is excluded fromour Creative\nCommons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\nImage courtesy of BruceBlaus. License CC BY.\n\nMIT Media Lab\nReferences\nFigner, Bernd, and Ryan O. Murphy. \"Using Skin Conductance in Judgment and Decision Making Research.\"\nIn A Handbook of Process Tracing Methods for Decision Research: A Critical Review and User's\nGuide. Edited by M. Schulte-Mecklenbeck, A. Kuehberger, and R. Ranyard. Psychology Press. ISBN:\n9781848728646.\nSano, Akane, Rosalind W. Picard, et al. \"Quantitative Analysis of Wrist Electrodermal Activity\nduring Sleep.\" International Journal of Psychophysiologym 94, no. 3, (2014): 382-9.\nSano, Akane, Rosalind W. Picard, et al. \"Autonomic Sleep Patterns in Children with Autism Spectrum\nDisorders.\" In the Extended Abstract of IMFAR 2011, San Diego, CA, USA, May 12-14. 2011.\nSano, Akane, Rosalind W. Picard, H. Wang, et al. \"Autonomic Sleep Patterns in Visual Discrimination Task\nImprovement.\" (PDF) SLEEP 2011 25th Annual Meeting of the Associated Professional Sleep Societies\n(APSS), June 11-15, 2011, in Minneapolis, Minnesota, USA, May 12-14. 2011.\nSano, Akane, and Rosalind W. Picard. \"Recognition of Sleep Dependent Memory Consolidation with Multi-\nmodal Sensor Data.\" (PDF) The 10th Annual Body Sensor Networks Conference 2013, Cambridge, USA,\nMay 2013.\nPoh, Ming-Zher, Tobias Loddenkemper, et al. \"Convulsive Seizure Detection Using a Wrist-Worn Electrodermal\nActivity and Accelerometry Biosensor.\" Epilepsia 53, no. 5 (2012).\nMangina, CA, and JH Beuzeron-Mangina. \"Direct Electrical Stimulation of Specific Human Brain Structures\nand Bilateral Electrodermal Activity.\" International Journal of Psychophysiology : Official Journal of the\nInternational Organization of Psychophysiology 22, no. 1-2 (1996): 1-8.\n\nMIT Media Lab\nReferences cont.\nLhatoo, SD, H J Faulkner, et al. \"An Electroclinical Case-Control Study of Sudden Unexpected Death in\nEpilepsy.\" Annals of Neurology 68, no. 6 (2010): 787-96.\nJi, G., and V. Neugebauer. \"Hemispheric Lateralization of Pain Processing by Amygdala Neurons.\" Journal of\nNeurophysiology 102, no. 4 (2009): 2253-64.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.630 Affective Computing\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MAS.630F15 Week 4 - Isen, Forgas, Mood++",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-630-affective-computing-fall-2015/f4f57ffa457b4c41bd91cda79d512777_MITMAS_630F15_Week4.pdf",
      "content": "Week 4: Indirect mood\nassessment and learnings from\nyour homeworks...\n\nPositive & negative bias\nperception\n(e.g., Halberstadt, Niedenthal, and Kushner,\n1995; Bouhuys, Bloem, and Groothuis, 1995;\nMayer and Salovey, 1993; Niedenthal and\nKitayama, 1994)\n\nPositive\n\nBand\nPresents\nMorning\nPour\nSweet\nWon\nPane\nHeal\nDear\nPeace\nNegative\n\nBanned\nPresence\nMourning\nPoor\nSuite\nOne\nPain\nHeel\nDeer\nPiece\n\nForgas & Moylan (1987)\nAfter the movies: P asked to fill out a brief\npublic-opinion-survey (13 questions)\n- Political judgments\n- Likelihood of future events\n- Judging responsibility and guilt\n- Satisfaction with personal and work life\n\nForgas & Moylan (1987)\nExperimental design: Why are these\nimportant?\n\nExperimenter blind to hypothesis\n\nCheck mood as LAST question (not sooner)\n\nCheck moods going in (separate study)\n\nAge, gender, SES influences\n\nIsen et al. Positive affect enhances\ncreativity\nImproves solving of Duncker's Candle Task, leads to\ngreater Remote Word associations; Isen, Daubman,\nand Nowicki, 1987; Isen, Johnson, Mertz, and\nRobinson, 1985\nDuncker's Candle\nTask: Affix the candle\nto the wall and light it,\nin such a way that it\ndoesn't drip on the\nground. (20% -> 75%)\nThis image is in the public domain.\n\nIsen et al. 1987 Methodology\n- Why have them rate the pleasantness of unfamiliar\nwords up front (but after the pos/neutral film shown?)\n- Why include a \"facilitative control?\"\n- Why did candy bar manipulation likely fail?\n- Why include easy + moderate + hard items on Remote\nAssociates Test?\n\nCase study: can we tell if a new typography\nprovides a better experience for the reader?\n- Measure: speed of reading, ease of reading, reading\ncomprehension, \"do you like the appearance?\"\n- These show no difference\n\n- The experts think the \"aesthetic experience\" is better\n-Solution: Measure\n\n1. direct affective experience while reading\n\n2. results of having had a positive-affect experience\n\nCase study: can we tell if a new typography\nprovides a better experience for the reader?\nThis image is in the public domain.\nImage courtesy of Stephen Coles on flickr. License CC BY-NC-SA.\nImage courtesy of Stephen Coles on flickr.\nLicense CC BY-NC-SA.\n\nIndirect measures hypothesized:\nIf you have had a positive experience,\nThen you are more likely to underestimate the time\nspent on the task\n\nThen you will be better at solving creative problems\n\nWe found (N=20) in comparing \"good\"\ntypography to \"bad\":\nNo difference in self-reported liking of the experience\n(questionnaires with Likert scales)\n\nSignificant underestimating of the time spent on the\nreading task for the \"good\" type\n\nBetter performance solving two kinds of creative\nproblems for the \"good\" type\n\nWhen is a good time for a mobile system to\ninterrupt you?\nFitsense EKG, Accelerometer and\nLocation Sensors wirelessly talk to\nCell Phone or HP IPAQ\n\nWill empathetic response\nhelp if it interrupts at a\nbad time, or if you are\nstressed?\nImage courtesy of Reflex Blue\non flickr. License CC BY-NC.\nImage courtesy of Peter Parkes on\nWikimedia Commons. License CC-BY.\nImage courtesy of Bryan Collick on flickr.\nLicense CC BY-NC-SA.\n\nMeasuring frustration?\nHow many times does it seem like\nI've interrupted you today?\nmore than 30\ntimes\n25-29\n20-24\n15-19\nless than 15\ntimes\nSorry for so many\ninterruptions. It'd be\ngreat if you could give\nme feedback how to be\nless frustrating.\nGive feedback now\nAsk me later\nNo thanks\nThanks so much for\nall your input today. I\nhope I wasn't too\nfrustrating. See you\ntomorrow - bye.\nGive feedback\nBye!\nCalculate\nrelative\nsubjective\ncount\nHigh RSC\nLow RSC\n(rel. to Ziegarnik\neffect)\n\nChallenge: Get LOTS of annotated data from\npeople\nGoal: Technology learns patterns of activity,\nstress, good/bad timing & adapts to these\n\nProblem: Users HATE to be\ninterrupted all day to ask for\ndata.\n\n\"You can't pay them enough to be a\nsubject\" - Lisa Feldman-Barrett\n\n?Solution: Empathy?\n\nEach interaction can be initiated\nby user or by system:\nIf user initiates interaction to annotate, the interaction\nlooks like this:\n\nEach interaction can be initiated by\nuser or by system:\nWhen the system initiates interaction (interrupts\nuser), the interaction looks like this:\n-S: Morning, Jane!\n-S: Do you have a minute?\n-U: Yes.\n-S: You know the drill -- feeling stressed?\n-U: Its there - but not the worst.\n-S: Thanks so much for all your input. I hope I\nhaven't been too frustrating.\n\nIn \"Empathetic\" condition the\ndialogue also includes red text:\n-S: Morning, Jane!\n-S: Do you have a minute?\n-U: Yes.\n-S: You know the drill -- feeling stressed?\n-U: Its there - but not the worst.\n-S: Wish it was better. Hope things start looking up.\n-S: Thanks so much for all your input. I hope I haven't\nbeen too frustrating.\n\n\"How many times does it seem like the system\ninterrupted you today?\" (N=10 subjects)\nSystem 1: (empathetic)\n\nActual interruptions = 496, User estimate = 336\n\n336/496 = 0.677\n\nSystem 2: (non-empathetic)\n\nActual interruptions = 295, User estimate = 292\n\n292/295 = 0.989\n\nt(45), p = .0024 between these two \"relative subjective counts\"\n\nWHY LOOK AT MOOD?\n\nThe World Health Organization (WHO) reports that one suicide\nhappens every 40 seconds, and that suicide is increasing at a rate\nthat is predicted to be 1 suicide every 20 seconds by the year\n\nMajor Depressive Disorder is the leading cause of disability in the\nU.S. for ages 15-44. (World Health Org. 2004)\n\nDepression affects 30 million adults in the U.S. (Kessler et al\n2003)\n\n41,149 suicides were reported in 2013 (CDC 2013)\n\n\"#1 Problem in Africa\" (IBM Africa)\n\nReferences\nHalberstadt, J. B., P. M. Niedenthal, et al. \"Resolution of Lexical Ambiguity by Emotional\nState.\" Psychological Science 6, no. 5 (1995): 278-82.\n\nBouhuys, A. L., G. M. Bloem, et al. \"Induction of Depressed and Elated Mood by Music\nInfluences the Perception of Facial Emotional Expressions in Healthy Subjects.\" Journal\nof Affective Disorders 33, no. 4 (1995): 215.\n\nMayer, John D., and Peter Salovey. \"The Intelligence of Emotional Intelligence.\"\nIntelligence 17 (1993): 433-42.\n\nNiedenthal, Paula M., and Shinobu Kitayama. The Heart's Eye: Emotional Influences\nin Perception and Attention. Academic Press, 1994. ISBN: 978-0124105607.\n\nJoseph, P. F., and Moylan Stephanie. \"After the Movies : Transient Mood and Social\nJudgments.\" Personality and Social Psychology Bulletin 13, no. 4 (1987): 467-77.\n\nReferences cont.\nIsen, A. M., K. A. Daubman, et al. \"Positive Affect Facilitates Creative Problem Solving.\"\nJournal of Personality and Social Psychology 52 no. 6 (1987): 1122-31.\n\nIsen, A. M., M. M. Johnson, et al. \"The Influence of Positive Affect on the Unusualness\nof Word Associations.\" Journal of Personality and Social Psychology 48, no. 6 (1985):\n1413-26.\n\nKessler, R. C., P. Berglund, et al. \"The Epidemiology of Major Depressive Disorder:\nResults from the National Comorbidity Survey Replication (ncs-R).\" Jama 289, no. 23\n(2003): 3095-105.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.630 Affective Computing\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "MAS.630F15 Weeks 1-3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/mas-630-affective-computing-fall-2015/d12a5e328d127ead2771c212efeb1f14_MITMAS_630F15_Weeks1-3.pdf",
      "content": "MAS630: Affective Computing\nPLEASE FILL OUT INDEX CARD & HAND IN BEFORE YOU LEAVE\nTODAY:\n\nNAME\n\nProbability taking class for credit\nEmail\nProgram of study & Year in it\nResearch (thesis) advisor\n\nWhy are you interested in affective computing? What topics do\nyou most want to see us cover this semester?\n\nMAS630: Affective Computing\nhttp://courses.media.mit.edu/2015fall/mas630\n\nRosalind Picard, Sc.D., Professor\n\nIntroductions: Who is here...?\n\nCourse Logistics\n\nhttp://courses.media.mit.edu/2015fall/mas630\n\nCourse Logistics\n\nhttp://courses.media.mit.edu/2015fall/mas630\n\nFirst ideas about projects due in two weeks!\n\nMIT COUHES - Sept 24 & Oct 27 deadlines\n\nWeek 1: Overview\n\nTerminology: Affect, emotions, moods,\nfeelings, expressions, displays...\n\nBasic Emotion: Categories? Dimensions?\n\nEmotion is like weather. We ALWAYS have emotion.\n\nContinuous: Wind velocity, humidity, temperature,\nbarometric pressure, precipitation\n\n81 °F / 27 °C Partly Cloudy Humidity: 79% Dew Point: 73 °F / 23 °C Wind: 6 mph /\n9 km/h from the South Pressure: 29.80 in / 1009 hPa Heat Index: 85 °F / 30 °C\nVisibility: 6.2 miles / 10.0 kilometers UV: 0 out of 16 Clouds: Few 1300 ft / 396 m\n\n6 mph / 9 km/h , Wind Dir: 190° (South) Ceiling: Unlimited\n\nDiscrete: Storm, tornado, blizzard, hurricane, typhoon\n\nWhat is emotion? Is it discrete (anger, joy,...) or\ncontinuous (aroused-calm, positive-negative, ...),\nor...? (~100 definitions: Kleinginna & Kleinginna 1981)\n\nFlowers\nMutilated\nface\nWin World\nSeries\nCemetery\nCute baby\nArousal\nValence\nSkin conductance is a good indicator of arousal,\nwhich is a good indicator of memory and attention\n\n(c) Pergamon. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nWhich emotion is this person feeling?\nHappiness\nAnger\nSurprise\nFear\nSadness\nDisgust\nImage courtesy of Eduardo Siquier Cortes\non flickr. License CC BY-NC-SA.\n\nWhich emotion is this person feeling?\nPride\nAnger\nSurprise\nFear\nSadness\nDisgust\n\n(works for any positive term - happy, joy, pride,\nelated, serenity, etc.)\n\nImage courtesy of Eduardo Siquier Cortes\non flickr. License CC BY-NC-SA.\n\nEmotional touch can be measured\n1977, Manfred Clynes (Also coined \"cyborg\" in Clynes & Klein, 1960)\n(c) Prism Pr Ltd. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\n(c) Manfred Clynes. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee http://ocw.mit.edu/help/faq-fair-use/.\n\nEssentic\nForms\n(Clynes)\n(c) Psychology Today. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nWhat is affective computing?\n\nComputing that relates to arises from or\ndeliberately influences emotion or other\naffective phenomena.\n\nGiving technology skills of \"emotional\nintelligence\" for interacting with us\n\nMotivation for AC...\n\nThis character barges into your office when you're busy. He\ndoesn't apologize, and doesn't notice you are annoyed.\nHe offers you useless advice.\nYou express more annoyance. He ignores it.\nHe continues to be unhelpful. The clarity of your emotional\nexpression escalates.\nHe ignores it.\n(this goes on)\nFinally you tell him explicitly \"Go Away\"\nHe winks, and does a happy little dance before exiting.\nImage courtesy of Alex Muller on flickr. License CC BY-NC-SA.\n\n...doesn't notice you are annoyed.\n[Doesn't recognize your emotion]\nYou express more annoyance. He ignores it.\n[Doesn't respond appropriately to emotion]\nHe winks, and does a happy little dance before exiting.\n[Stupid about expressing emotion.]\nImage courtesy of Alex Muller on flickr. License CC BY-NC-SA.\n\n- Expressing emotions\n- Recognizing emotions\n- Handling another's emotions\n- Regulating emotions \\\n- Utilizing emotions /\n(Salovey and Mayer 90, Goleman 95)\nSkills of Emotional Intelligence:\nif \"have emotion\"\n\nYou may\nalready be an\nexpert at this.\n\nHere is why.\n\n(c) Center for the Study of Language and Inf. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nHuman -\ncomputer\ninteraction\nis\nnatural and\nsocial\n(Reeves and Nass 1996)\n(c) Center for the Study of Language and Inf. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nHuman- human interaction\nSuppose that a person starts to give\nyou help at a bad time.\nYou try ignoring, then frowning at, then\nmaybe glaring at him or her...\nThe smart person infers you don't like\nthis, ceases the interruption, notes the\ncontext, and learns from the feedback.\n\nHuman- human interaction\nSuppose that a person starts to give\nyou help at a bad time.\nYou try ignoring, then frowning at, then\nmaybe glaring at him or her...\nThe smart person infers you don't like\nthis, ceases the interruption, notes the\ncontext, and learns from the feedback.\n\nHuman-Computer interaction\nSuppose that a computer starts to give\nyou help at a bad time.\nYou try ignoring, then frowning at, then\nmaybe glaring at it...\nThe smart computer infers you don't\nlike this, ceases the interruption, notes the\ncontext, and learns from the feedback.\n\n\"But the computer wouldn't frustrate\npeople if it was only more intelligent?\"\nConsider:\n\"But the person wouldn't frustrate\npeople if he/she was only more intelligent?\"\n\nFact: The most intelligent people are still\nfrustrating (at least sometimes).\nPeople and computers can't always prevent frustration. Thus, they\nshould be prepared to handle it intelligently.\n\n1. Notice when the person you're interacting with\nis frustrated (or showing another emotional state).\n2. Determine how best to respond.\n3. Respond/make it so.\n4. Assess how that worked.\n5. Learn. Adjust if needed for next time.\nEmotional intelligence includes:\n\nIntelligent expression by computers requires\nfirst recognizing affective context (and also\nconsidering goals & predicting outcome)\nThese should stop looking happy\n\"Like one who takes away a garment on a cold day, or like vinegar poured on\nsoda, is one who sings songs to a heavy heart\" Proverbs 25:20\nImage courtesy of Alex Muller\non flickr. License CC BY-NC-SA.\nImage courtesy of charamelody on flickr. License CC BY-NC.\n(c) Microsoft. All rights reserved. This content\nis excluded from our Creative Commons\nlicense. For more information, see\nhttp://ocw.mit.edu/help/faq-fair-use/.\n\nWeek 2: From your homeworks...\n\nHow should a car voice sound, given a driver is either\nHappy or Upset?\nDriver Affect:\nCar Voice:\nHappy\nEnthused\nHappy\nSubdued\nUpset\nEnthused\nUpset\nSubdued\nNumber of\naccidents\nMinutes driver\nspoke\nJonsson, I.-M. and Nass, C. (2004) Effects of driver emotion and car voice emotion on\nactual and perceived driving performance. Stanford CA: Stanford Univ.\n\nFinding: Choosing response appropriate to driver\naffective state improves driver safety and performance.\nDriver Affect:\nCar Voice:\nHappy\nEnthused\nHappy\nSubdued\nUpset\nEnthused\nUpset\nSubdued\nNumber of\naccidents\n8.3\n9.6\n6.3\nMinutes driver\nspoke\n5.8\n4.2\n3.9\n4.7\nJonsson, I.-M. and Nass, C. (2004) Effects of driver emotion and car voice emotion on\nactual and perceived driving performance. Stanford CA: Stanford Univ.\n\nHow do we measure emotion?\n\nEmotions give rise to changes that can be sensed:\nDistance Face, voice\nSensing: Posture\nGestures, movement, behavior\n\nTemperature\n\nRespiration\nUp-close Pupil dilation\nSensing:\n\nSkin conductance\n\nECG, EEG, Blood pressure\n\nInternal Hormones\nSensing: Neurotransmitters\n...\n\nWhat are the natural affordances\nof the environment?\nImage courtesy of Judy Baxter on flickr.\nLicense CC BY-NC-SA.\nImage courtesy of Daniel Hoherd on flickr.\nLicense CC BY-NC.\n\nMouse pressure may increase with frustration, distress\nfrustration linked to factors that cause wrist problems\n(Dennerlein, et al., International Ergonomics Association '03)\nPressure\nSensitive Mouse\n(Reynolds)\n(c) Reynolds. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see http://ocw.mit.edu/help/faq-fair-use/.\n\nCan we teach a chair to recognize\nbehaviors indicative of interest and\nboredom? (Mota & Picard)\nSit upright\nLean Forward\nSlump Back\nSide Lean\n\nSensor chair is a significant\nnonverbal channel for discriminating\nlearner interest...\n\nResults (on children not in training data, Mota and Picard, 2003):\n69-83% accuracy recognizing if child is in state of:\nHigh Interest, Low interest, Taking a Break\n\nEmotion recognition & response\n\"Kismet\" robot\nImage is in the public domain.\n\nEmotional arousal and physiology\n\nSubject intentionally expressing 8 emotions:\n\n1. Neutral\n\n5. Platonic Love\n\n2. Anger\n\n6. Romantic Love\n\n3. Hate\n\n7. Joy\n\n4. Grief\n\n8. Reverence\nEach emotion collected daily, for > 4 weeks\n4 physiological signals:\nEMG on jaw, skin conductance, BVP,\nrespiration\n\nClassification Accuracy:\n81% on 8 emotions (person dependent)\nPicard et al., IEEE Trans. Pattern Analysis Machine Intell.,Oct 2001.\n1. Neutral\n\n5. Platonic Love\n2. Anger\n\n6. Romantic Love\n3. Hate\n\n7. Joy\n4. Grief\n\n8. Reverence\n\nSimultaneously examine physiology and behavior for\nrecognizing level of stress: up to 96% accurate, across\n12 drivers.\n(Healey and Picard, ICPR 2000)\n\n皮膚の伝導性に関する再考\nRethinking skin conductance sensing\n(Selene Mota, Hoda Eydgahi, Rich Fletcher)\n\nAudience's \"glow\" (aggregate skin conductivity)\nconveys excitement\nwww.media.mit.edu/galvactivator\n\nSkin conductance often\nincreases with these:\n- Significant thoughts\n- Exciting events\n- Exercise/breathing deeply\n- Motion artifacts\n- Humidity/moisture increase\n- Lying\n- Pain\n\nStartleCam:\nA Cybernetic Wearable Camera\n(Healey & Picard, ISWC 98)\n\nStartleCam Filter\n\nStartleCam Filter Algorithm\n\nWearable Affective DJ chooses music\nfrom your play-list that helps you attain the level of \"activation\"\nyou specify or otherwise regulate your feelings/mood (Healey,\nDabek, Picard, 1998)\n\nWeek 3: From your homeworks...\n\nEDA, GSR etc.\nElectrodermal activity (EDA): general\nphenomenon\n\nWays to measure: conductance, potential,\nresistance, etc.\n\nOld terminology (not specific - could refer\nto any of the above): GSR\n\nErrors\n- GSR is traditionally measured on the\n\"non-dominant hand\" (Chap 14 says\ndominant) Note: We now think it's\nimportant to measure both sides in\nmany cases, and the dominant side for\nmore threat/anxiety/grief/sadness\n\nErrors\n- HR increases do not imply an increase\nin Sympathetic Nervous System (SNS)\nactivation. HR increases may also be\ncaused by withdrawal of the vagus\nnerve, part of the Parasympathetic\nNervous System (PNS)\n\nErrors\nThese are not the same:\n- Conductance is (microSiemens).\n- Conductivity is conductance per unit of\nlength (microSiemens/cm).\n\nReferences\nMayer, John D., Peter Salovey, et al. \"Emotional Intelligence: Theory, Findings, and Implications\".\nPsychological Inquiry 15, no. 3 (2004): 197-215.\n\nReeves, Byron, and Clifford Nass. The Media Equation: How People Treat Computers,\nTelevision, and New Media Like Real People and Places. Center for the Study of Language and\nInf, 2003.\n\nJonsson, Ing-Marie. \"Matching In-Car Voice with Driver State: Impact on Attitude and Driving\nPerformance.\" Proceedings of the 3rd International Driving Symposium on Human Factors in\nDriver Assessment, Training, and Vehicle Design : Driving Assessment 2005 : Samoset Resort\non the Ocean, Rockport, Maine, Usa, June 27-30, (2005): 173-80.\n\nChen, JC, JT Dennerlein, et al. \"Knee Pain and Driving Duration: A Secondary Analysis\nof the Taxi Drivers' Health Study.\" American Journal of Public Health 94, no. 4 (2004): 575-81.\n\nMota, S, and R.W Picard. \"Automated Posture Analysis for Detecting Learner's Interest\nLevel.\" Ieee Computer Society Conference on Computer Vision and Pattern Recognition\nWorkshops 5 (2003).\n\nReferences cont.\nPicard, R.W., Elias Vyzas, et al. \"Toward Machine Emotional Intelligence: Analysis of Affective\nPhysiological State.\" IEEE Transactions Pattern Analysis and Machine Intelligence 23,\nno. 10 (2001): 1175-91.\n\nHealey, Jennifer and Rosalind W. Picard. \"Smartcar: Detecting Driver Stress.\" Proceedings. 4\n(2000): 218-221.\n\n__ __ __. \"Startlecam: A Cybernetic Wearable Camera.\" Wearable Computers (1998): 42-49.\n\nHealey, Jennifer, Rosalind W. Picard, and Frank Dabek. \"A New Affect-Perceiving Interface and\nIts Application to Personalized Music Selection.\" Proceedings of the 1998 Workshop on\nPerceptual User Interfaces (1998): 4-6.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nMAS.630 Affective Computing\nFall 2015\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}