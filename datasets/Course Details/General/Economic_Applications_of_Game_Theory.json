{
  "course_name": "Economic Applications of Game Theory",
  "course_description": "Game Theory, also known as Multiperson Decision Theory, is the analysis of situations in which the payoff of a decision maker depends not only on his own actions but also on those of others. Game Theory has applications in several fields, such as economics, politics, law, biology, and computer science. In this course, I will introduce the basic tools of game theoretic analysis. In the process, I will outline some of the many applications of Game Theory, primarily in economics.",
  "topics": [
    "Social Science",
    "Economics",
    "Game Theory",
    "Social Science",
    "Economics",
    "Game Theory"
  ],
  "syllabus_content": "Course Meeting Times\n\nLectures: 2 sessions / week, 1.5 hours / session\n\nReciations: 1 session / week\n\nPrerequisites\n\n14.01 Principles of Microeconomics\n\n14.03 Microeconomic Theory and Public Policy\n\n14.04 Intermediate Microeconomic Theory\n\n6.041 Probablistic Systems Analysis and Applied Probability\n\nBear in mind that you should be at ease with basic probability theory and calculus, and more importantly, you should be used to thinking in mathematical terms. In particular, in addition to 14.01, a student must have taken either 14.03, or 14.04, or an intermediate course in probability theory. Otherwise, the student needs my explicit consent. In any case, if you are taking this course, you should be prepared to work hard.\n\nCourse Description\n\nGame Theory, also known as Multiperson Decision Theory, is the analysis of situations in which the payoff of a decision maker depends not only on his own actions but also on those of others. Game Theory has applications in several fields, such as economics, politics, law, biology, and computer science. In this course, I will introduce the basic tools of game theoretic analysis. In the process, I will outline some of the many applications of Game Theory, primarily in economics.\n\nGame Theory has emerged as a branch of mathematics and is still quite mathematical. My emphasis will be on the conceptual analysis and applications, keeping the level of mathematical technicalities to a minimum, especially at a level that should be quite acceptable to the average MIT student.\n\nRecitations\n\nGiven the class size and the difficulty of the subject, you may not follow all of my lectures. You will probably need a lot of help. This year there will be three Teaching Assistants (TAs). They will help you. There will be three recitations on each Friday. In these recitations, TAs will go over the topics that are covered by that week's lecture and answer your questions. Most weeks there will be some important points that I would want you to understand well, the points about which you will be examined. These points will also be covered in recitation.\n\nTextbooks\n\nThe main source of the material is the detailed lecture notes I will be posting. The official textbook is:\n\nGibbons, Robert.\nGame Theory for Applied Economists\n. Princeton University Press, 1992. ISBN: 9780691003955. [Preview with\nGoogle Books\n]\n\nGrading\n\nASSIGNMENTS\n\nPERCENTAGES\n\nTwo midterms\n\nFinal exam\n\nFive problem sets\n\nHomework Policy\n\nThe problem sets are meant to teach you the material. Hence, you are encouraged to work in groups, but every student has to write his or her own solution and submit it individually.\n\nExam Policy\n\nAll exams are closed books. You may be able to get partial credit by stating the relevant facts, such as the definition of the solution concept to be used, towards the correct solution. You will also get 10% credit for each problem (or subproblem) that you leave empty (or write something like \"I don't know the answer\") because acknowledging ignorance is the first step to the knowledge. Nonetheless, you will not get any points for stating irrelevant facts, e.g. writing the solution to a similar problem from the problem set or past exam.",
  "files": [
    {
      "category": "Assignment",
      "title": "Problem Set 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/005d8ee7453eb01e130531af26cf9a6b_MIT14_12F12_pset1.pdf",
      "content": "14.12 Game Theory\nMuhamet Yildiz\nFall 2012\nHomework 1\nDue on 9/25/2012\n1. Consider a homeowner with Von-Neumann and Morgenstern utility function u, where\nu (x) = 1 - e-x for wealth level x, measured in million US dollars. His entire wealth\nis his house. The value of a house is 1 (million US dollars), but the house can be\ndestroyed by a fiood, reducing its value to 0, with probability π ∈ (0, 1).\n(a) What is the largest premium P is the homeowner is willing to pay for a full\ninsurance? (He pays the premium P and gets back 1 in case of a fiood, making\nhis wealth 1 - P regardless of the fiood.)\n(b) Suppose there is a local insurance company who has insured n houses, all in\nhis neighborhood, for premium P . Suppose also that with probability π there\ncan be fiood in the neighborhood destroying all houses (i.e., either all houses are\ndestroyed or none of them is destroyed). Suppose finally that P is small enough\nthat the homeowner has insured is house. Having insured his house, what is the\nlargest Q that he is willing to pay to get the 1/n share of the company? (The\nvalue of the company is the total premium it collects minus the payments to the\ninsured homeowners in case of a fiood.)\n(c) Answer part (b) assuming now that the insurance company is global. It insured n\nhouses in different parts of the world (all outside of his neighborhood), so that the\ndestruction of houses by fiood are all independent (i.e., the probability of fiood in\none house is π independent of how many other houses has been fiooded).\nn\nk/nπk (1 - π)n-k ∼\nπ+π(1-π)/(2n)\n(d) Assume that n is large enough so that\nk=0 Cn,ke\n= e\n,\ndiscuss your answers to above questions (briefiy). [Here, Cn,k denotes the number\nof k combinations out of n, and the sum is one minus the expected payoff from\nthe loss due to the payments to the fiooded houses.]\n2. Consider the game in which the following are commonly known. First, Ann chooses\nbetween actions a and b. Then, with probability 1/3, Bob observes which action Ann\nhas chosen and with probability 2/3 he does not observe the action she has chosen. In\nall cases (regardless of whether he has observed Ann chose a, or he has observed Ann\nchose b, or he has not observed any action), Bob chooses between actions α and β.\nThe payoff of each player is 1 after (a, α) and (b, β) and 0 otherwise.\n(a) Write the above game in extensive form.\n(b) Write the above game in normal form.\n3. Consider the following variation of the above game. First, Ann chooses between actions\na and b. Then, Bob decides whether to observe the chosen action of Ann or not, by\nchoosing between the actions Open and Shut, respectively. In all cases, Bob then\n\nchooses between actions α and β. The payoff of Ann is 1 after (a, α) and (b, β) and\n0 otherwise, regardless of whether Bob chooses Open or Shut. The payoff of Bob is\nequal to the payoff of Ann if he has chosen Shut, and his payoff is equal to the payoff\nof Ann minus 1/2 if he has chosen Open.\n(a) Write the above game in extensive form.\n(b) Write the above game in normal form.\n4. Federal government is planning to build an interstate highway between two states,\nnamed A and B. The highway costs C > 0 to the government, and the value of the\nhighway to the states A and B are vA ≥ 0 and vB ≥ 0, respectively. Simultaneously,\neach state i ∈{A, B} is to bid bi ∈ [0, inf). If bA + bB ≥ C the highway is constructed.\nFor any distinct i, j ∈{A, B}, state i pays C - bj to the federal government if bj <\nC ≤ bA + bB . (There is no payment otherwise.) The payoff of a state is the value of\nthe highway to the state minus its own payment to the government if the highway is\nbuilt, and 0 otherwise. (You can focus on the case vA + vB < C.)\n(a) Write this in the normal form.\n(b) Check if there is a dominant strategy equilibrium, and compute it if there is one.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 1 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/3f046bc9e4037ce9614c3ffd7ccfdfa4_MIT14_12F12_pset1sol.pdf",
      "content": "14.12 Game Theory\nMuhamet Yildiz\nFall 2012\nHomework 1\nDue on 9/25/2012\n1. Consider a homeowner with Von-Neumann and Morgenstern utility function u, where u (x) =\n1 - e-x for wealth level x, measured in million US dollars. His entire wealth is his house.\nThe value of a house is 1 (million US dollars), but the house can be destroyed by a flood,\nreducing its value to 0, with probability π ∈ (0, 1).\n(a) What is the largest premium P is the homeowner is willing to pay for a full insurance?\n(He pays the premium P and gets back 1 in case of a flood, making his wealth 1 - P\nregardless of the flood.)\nThe homeowner's utility for getting 1 - P always is\n-(1-P )\nu(1 - P ) = 1 - e\nhis utility in the outside option is\n-1)\nπu(0) + (1 - π)u(1) = (1 - π)(1 - e\nThe largest premium P he is willing to pay is the P that makes him indifferent between\nbuying and not buying insurance.\n-1)\n1 - e -(1-P ) = (1 - π)(1 - e\n1 - P = -ln(1 - (1 - π)(1 - e -1))\nP = 1 + ln(1 - (1 - π)(1 - e -1))\n(b) Suppose there is a local insurance company who has insured n houses, all in his neigh\nborhood, for premium P . Suppose also that with probability π there can be flood in the\nneighborhood destroying all houses (i.e., either all houses are destroyed or none of them\nis destroyed). Suppose finally that P is small enough that the homeowner has insured\nis house. Having insured his house, what is the largest Q that he is willing to pay to\nget the 1/n share of the company? (The value of the company is the total premium it\ncollects minus the payments to the insured homeowners in case of a flood.)\nThe company's value is nP with probability (1 - π) and nP - n with probability π. His\nutility from buying insurance and not buying stock is\n-(1-P )\nu(1 - P ) = 1 - e\n\nAnd his utility from buying stock and insurance is\n(1 - π)u(1 - P - Q + P ) + πu(1 - P - Q + P - 1) =\n(1 - π)(1 - exp(-1 + Q)) + π(1 - exp(Q))\nWe find the Q that makes him indifferent between buying and not buying:\n1 - e -(1-P ) = (1 - π)(1 - exp(-1 + Q)) + π(1 - exp(Q))\nexp(-Q) exp(P ) = (1 - π) exp(0) + π exp(1)\nQ = P - ln(1 - π + πe)\nWe saw before that it must be true that exp(P ) ≤ π exp(1) + (1 - π) exp(0) (this is a\nrearrangement of the indifference condition of part (a)), so we need exp(-Q) ≥ 1, so\nQ ≤ 0. Thus, the homeowner is never willing to buy the stock.\n(c) Answer part (b) assuming now that the insurance company is global. It insured n houses\nin different parts of the world (all outside of his neighborhood), so that the destruction\nof houses by flood are all independent (i.e., the probability of flood in one house is π\nindependent of how many other houses has been flooded).\nThe chance that i houses flood, out of n is\nπi(1 - π)n-iCn,i\nand the company's wealth is nP - i. Thus, the buyer's expected utility from buying\ninsurance and stock is\ni\n\n1 -\nπi(1 - π)n-iCn,i exp(-(1 - P - Q + P - i/n))\nSetting this equal to his outside option\ni\n\n1 - e -(1-P ) = 1 -\nπi(1 - π)n-iCn,i exp(-(1 - P - Q + P - i/n))\ni\n\n-e -Q = -\nπi(1 - π)n-iCn,i exp(-(P - i/n))\ni\n\nQ = P - ln(\nπi(1 - π)n-iCn,i exp(i/n))\nn\nk/nπk (1 - π)n-k ∼eπ+π(1-π)/(2n)\n(d) Assume that n is large enough so that\nk=0 Cn,ke\n=\n,\ndiscuss your answers to above questions (briefly). [Here, Cn,k denotes the number of k\ncombinations out of n, and the sum is one minus the expected payoff from the loss due\nto the payments to the flooded houses.]\nSubstituting in to our last result, we get\nQ = P - π - π(1 - π)/(2n)\nThe expected value of a share of the company is P - π. You can see that the player's\nwillingness to pay for a share of the company is the expected value minus π(1-π)/(2n).\n\nFor this utility function and a lottery that is normally distributed (which is this case\nfor large n), the agent's willingness to pay is always μ - σ2/2\nIn part b, we found that the agent would never buy into the company that only insures\npeople like him. This is the equivalent of paying for a company to sell himself insurance.\nHowever, when the company insures many different people, the company's splits the risk\nof all of the people. Thus, a 1/N share of the company holds less risk as N increases.\nThe agent that buys a share holds a part of everyone's risk, which is preferrable to\nholding only his own risk.\n2. Consider the game in which the following are commonly known. First, Ann chooses between\nactions a and b. Then, with probability 1/3, Bob observes which action Ann has chosen and\nwith probability 2/3 he does not observe the action she has chosen. In all cases (regardless\nof whether he has observed Ann chose a, or he has observed Ann chose b, or he has not\nobserved any action), Bob chooses between actions α and β. The payoff of each player is 1\nafter (a, α) and (b, β) and 0 otherwise.\n(a) Write the above game in extensive form.\n(b) Write the above game in normal form.\n3), where s1 ∈{α, β} ,\ndenotes the choice of the information set (numbered as 1\nB = (s1\nStrategy of Ann is simple: {a, b}.\n2 ∈{α, β} , s3 ∈{α, β}.\nin the picture) and s\nStrategy of Bob is s\n, s , s\ns\ns\n3 is for node 3. Utility of outcomes is in the\nis for node 2, and s\nfollowing table.\na\nb\nααα\n1,1\n0,0\nααβ\n1,1\n3, 1\nαβα\n3, 2\n0,0\nαββ\n3, 2\n3, 1\nβαα\n3, 1\n3, 2\nβαβ\n3, 1\n1,1\nββα\n0,0\n3, 2\nβββ\n0,0\n1,1\n3. Consider the following variation of the above game. First, Ann chooses between actions a\nand b. Then, Bob decides whether to observe the chosen action of Ann or not, by choosing\nbetween the actions Open and Shut, respectively. In all cases, Bob then chooses between\nactions α and β. The payoff of Ann is 1 after (a, α) and (b, β) and 0 otherwise, regardless of\nwhether Bob chooses Open or Shut. The payoff of Bob is equal to the payoff of Ann if he has\nchosen Shut, and his payoff is equal to the payoff of Ann minus 1/2 if he has chosen Open.\n(a) Write the above game in extensive form.\n(b) Write the above game in normal form.\nStrategy of Ann is simple: {a, b}. Strategy of Bob is s B = (s 1, s 2, s , s 4), where s ∈\n\n{O, S} , s2 ∈{α, β} , s3 ∈{α, β} , s4 ∈{α, β}. s2 denotes the choice of the node 1 (the\nleft one) and s3 is for node 2, s4is for the information set on the right side (numbered\nas 3 in the picture). Utility of outcomes is in the following table.\na\nb\nOααα 1, 0.5 0,-0.5\nOααβ\n1, 0.5 0,-0.5\nOαβα 1, 0.5 1, 0.5\nOαββ\n1, 0.5 1, 0.5\nOβαα 0,-0.5 0,-0.5\nOβαβ\n0,-0.5 0,-0.5\nOββα 0,-0.5 1, 0.5\nOβββ\n0,-0.5 1, 0.5\nSααα\n1,1\n0,0\nSααβ\n0,0\n1,1\nSαβα\n1,1\n0,0\nSαββ\n0,0\n1,1\nSβαα\n1,1\n0,0\nSβαβ\n0,0\n1,1\nSββα\n1,1\n0,0\nSβββ\n0,0\n1,1\n4. Federal government is planning to build an interstate highway between two states, named A\nand B. The highway costs C > 0 to the government, and the value of the highway to the\nstates A and B are vA ≥ 0 and vB ≥ 0, respectively. Simultaneously, each state i ∈{A, B} is\nto bid bi ∈ [0, inf). If bA + bB ≥ C the highway is constructed. For any distinct i, j ∈{A, B},\nstate i pays C - bj to the federal government if bj < C ≤ bA + bB. (There is no payment\notherwise.) The payoff of a state is the value of the highway to the state minus its own\npayment to the government if the highway is built, and 0 otherwise. (You can focus on the\ncase vA + vB < C.)\n(a) Write this in the normal form.\nStrategy of player i is choice of bi ∈ [0, inf). Utility from strategy profile x of player i is\nui(bA, bB ) = vi - C + bj if bA + bB ≥ C\n= 0\nif bA + bB < C\n(b) Check if there is a dominant strategy equilibrium, and compute it if there is one.\nThere is a unique dominant strategy equilibrium, (vA, vB ). In other words, bidding\nown value is the dominant strategy equilibrium.\nFrom player A's point of view, there are three cases. If bB ≥ C, then uA = vA,\nregardless of what bA is. If C - vA ≤ bB < C, then A wants to build the highway as\nuA = vA - C + bB ≥ 0. Thus, bA ≥ C - bB is the best response. Lastly, if bB < C - vA,\nthen A does not want to build the highway as uA = vA - C + bB < 0. The best response\nfor this case is bA < C - bB.\n\nFor bB = C - vA + t (0 < t < vA), we need bA ≥ C - bB = vA - t. As this inequaility\nhas to hold for all 0 < t < vA, we need bA ≥ vA. Similarly, for bB = C - vA - t\n(0 < t < C - vA), we need bA < C - bB = vA + t. As this inequaility has to hold for\nall 0 < t < C - vA, we need bA ≤ vA. Therefore, the dominant strategy is bA = vA. For\nexample, if A chooses bA = vA + δ (δ > 0), when bB = C - vA - 2\nδ , uA = -2\nδ < 0 while\nbA = vA gives uA = 0.\n\nFigure 1: Question 2\n\nFigure 2: Question 3\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/e877f701c77f1a5d6da44553d3b255e9_MIT14_12F12_pset2.pdf",
      "content": "14.12 Game Theory\nMuhamet Yildiz\nFall 2012\nHomework 2\nDue on 10/5/2012 (in recitation)\n1. Consider the following game.\n\n2,0 0,5 1,0 0,4\n4,1 2,1 0,2 1,0\n2,1 5,0 0,0 0,3\n0,0 1,0 4,1 0,0\n(a) Compute the set of rationalizable strategies.\n(b) Compute the set of all Nash equilibria.\n2. Consider the following game.\nC\n1/2\nA\nB\n1/2\nL\nR\nL\nR\nL\nR\nl\nr\n(a) Find all Nash equilibria in pure strategies.\n(b) Find a Nash equilibrium in which Player 1 plays a mixed strategy (without putting\nprobability 1 on any of his strategies).\n\n3. Use backwards induction to compute a Nash equilibrium of the following game.\nL\nR\n1/4\n3/4\nl\nr\nA\nB\nA\nB\nx\ny\n4. A unit mass of kids are uniformly located on a street, denoted by the [0 1] interval.\nThere are two ice cream parlors, one located in and the other is located in 1 - ,\nwhere ¿ 12. A kid located in is to pay cost | - | to go to a store located at\n, where 0. Given the prices and for the ice cream in stores located at and\n1 - , respectively, each kid buys one unit of ice cream from the store with the lowest\ntotal cost, which is the sum of the price and the cost to go to the store. (If the total\ncost is the same, she flips a coin to choose the store to buy.)\n(a) Compute the revenue for each firm, as a function of price vector ( ).\nThe\n\nrevenue is price times the total mass of the kids who buy from the given store.\n(b) Assume that each store set their own price simultaneously and try to maximize\nthe expected value of its own revenue, as computed in part (a). Write this game\nin normal form.\n(c) Compute the set of Nash equilibria.\n(d) Compute the set of rationalizable strategies.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 2 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/4d1b402c3a1d45debbfc9bed005727e5_MIT14_12F12_pset2sol.pdf",
      "content": "14.12 Game Theory\nMuhamet Yildiz\nFall 2012\nHomework 2\n1. Consider the following game.\na\nb\nc\nd\nw\n2,0\n0,5\n1,0\n0,4\nx\n4,1\n2,1\n0,2\n1,0\ny\n2,1\n5,0\n0,0\n0,3\nz\n0,0\n1,0\n4,1\n0,0\n(a) Compute the set of rationalizable strategies.\nWe find the rationalizable strategies by iterated strict dominance.\nw is dominated by a mixed strategy putting 2/3 on x and 1/3 on z.\na is dominated by a mixed strategy putting 3/5 on c and 2/5 on d.\nb is dominated by a mixed strategy putting 3/5 on c and 2/5 on d.\ny is dominated by a mixed strategy putting 1/2 on x and 1/2 on z.\nd is dominated by c.\nx is dominated by z.\nThe set of rationalizable strategies is {z} × {c}\n(b) Compute the set of all Nash equilibria.\nThe only nash equilbrium is (z, c) because there is only 1 rationalizable strategy for\neach player\n2. Consider the following game.\n(a) Find all Nash equilibria in pure strategies.\nTo find the nash equilibrium of the extensive form game, we must write it as a normal\nform game. The cells in bold are pure strategy nash equilibria.\n(b) Find a Nash equilibrium in which Player 1 plays a mixed strategy (without putting\nprobability 1 on any of his strategies).\nTo find a mixed strategy, we look at which strategies allow player 1 to make player 2\nindifferent between any of his strategies. Since we found pure NE on A and B , we look\nfor some mixing between those two. By putting probability 3/4 on A and 1/4 on B, we\nmake player 2 indifferent between all of his strategies. Then he can mix with a total\n\nTable 1: Table\nLl\nLr\nRl\nRr\nA\n3,1\n3,1\n0,0\n0,0\nB\n0,0\n0,0\n1,3\n1,3\nC\n1.5\n0.5\nprobability of 1/4 on Ll and Lr and 3/4 probability on some combination of Rl and\nRr. This makes player 1 indifferent. In addition, we must check that C is not the best\nresponse to player 2's strategy. To do that, we need 1.5σ(Ll)+0.5σ(Lr)+σ(Rl) < 0.75.\nFor this to be true, player 2 must put positive probability on Rr.\nThere is another set of mixed equilibria: Player 2 plays Rl and Player 1 mixes, putting\nprobability p ∈[1/3, 1] on B and 1 -p on C.\n3. Use backwards induction to compute a Nash equilibrium of the following game.\nAfter L, player 2 plays B and player 1 plays A. Player 1's equilibrium utility from L is 3.\nAfter Rr, player 1 plays y, so after R player 2 will choose to play l. Player 1's equilibrium\nutility from R is 2, so player 1 will play L. The nash equilibrium from backwards induction\nis LAy, Bl.\n4.\n(a) For p > q + c (1 -2x) , all kids go to firm 2. Thus, the revenue for firm 1 and 2 are zero\nand q , respectively. For p = q + c (1 -2x), kids from x0 ≤x are indifferent and kids\nfrom x0 > x prefer firm 2. The revenue for firm 1 and 2 are 1px and 1px + q(1\n-x),\nrespectively. Similarly, for q > p+c (1 -2x), the revenue for firm 1 and 2 are p and zero.\nFor q = p + c (1 -2x), the revenue for firm 1 and 2 are px + 1p(1 -x) and 1q(1\nx).\n-\nFor |p -q| < c (1 -2x), we have an interior solution: there is a \"mid-point\" x∗such\nthat x < x∗< 1 -x and kid at x∗is indifferent. In other words,\nc |x∗-x| + p = c |x∗-(1 -x)| + q\nSolving, we get\nq\np\nx∗=\n+\n-\n2c\nNote that |p -q| < c (1 -2x) implies x < x∗< 1 -x. For |p -q| < c (1 -2x), the\nrevenue for firm 1 (located at x) is\nx∗p =\nq\n+\n-p\n2c\n\n· p\nFor firm 2 (located at 1 -x), the revenue is\nq\n(1\np\n-x∗) q =\n+\n-\n2c\n\n· q\n(b) Strategy of firm 1 is to choose p ∈[0, inf] and Strategy of firm 2 is to choose q ∈[0, inf].\nUtility (payoff) of firm 1 is zero if p > q + c (1\n2x), p if q > p + c (1\n2x), 1px if p =\n-\n-\n\nq+c (1 -2x) , px+ 1p(1-x) if q = p+c (1 -2x), and\n1 + q-p\n·p if |p -q\n(1\n| < c\n2c\n-2x).\nUtility of firm 2 is 0 if q > p + c(1 -2x), qif p > q + c(1 -2x), 1qx if q = p + c(1 -2x),\nqx + 1q(1 -x) if q = p -c(1 -2x), and\n1 + p-q\n2c\n· q if |p -q| < c (1 -2x).\n(c) If q ≥p + c(1 -2x), firm 2 would deviate to q = p + c(1 -2x) -ε, where ε > 0 and ε is\nsmall, as\np -(p + c(1 -2x)\nε\n+\n-)\n{p + c(1 -2x) -ε} -\n{p + c(1\n2c\n-x)} x > 0\nsimilarly, if p ≥q + c(1 -2x), firm 1 would deviate to p = q + c(1 -2x) -ε, where\nε > 0 and ε is small. Thus, to search Nash equilibrium, we only need to consider the\ncase |p -q| < c (1 -2x). Best response functions are given by the first order conditions\n(FOC): qBR(p) = p+c, pBR(q) = q+c. Solving, we get p = q = c. This is the unique\nNash equilibrium.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/8abb72c6dc731138d4bdcafcc53697f7_MIT14_12F12_pset3.pdf",
      "content": "14.12 Game Theory\nMuhamet Yildiz\nFall 2012\nHomework 3\nDue on 10/26/2012 (in recitation)\n1. [Recall Problem 4 in Homework 2.] Compute the subgame-perfect Nash equilibria in\nthe following game. A unit mass of kids are uniformly located on a street, denoted\nby the [0, 1] interval. There are two ice cream parlors, namely 1 and 2. First, each\nice cream parlor i selects location xi ∈[0, 1], simultaneously. Then, observing (x1, x2),\neach ice cream parlor i sets a price pi ≥0 for its own ice cream, simultaneously. A kid\nlocated in w is to pay cost c (w -y)2 to go to a store located at y, where c > 0. Given\nthe locations x1 and x2 and prices p1 and p2, each kid buys one unit of ice cream from\nthe store with the lowest total cost, which is the sum of the price and the cost to go\nto the store. (If the total cost is the same, she flips a coin to choose the store to buy.)\n2. Exercise 1 in Lecture Notes Section 11.5.\n3. Exercise 10 in Lecture Notes Section 11.5.\n4. Exercise 11 in Lecture Notes Section 11.5. Assume that n = 3, p1 = p2 = p3, and δ is\nsufficiently large.\nHint: Consider a strategy profile where the play depends on the \"state.\" There are m\nstates k = 1, . . . , m. The game starts at some state k0. For each state k, there is a\ndivision xk = (xk,1, . . . , xk,3). At state k, the proposer is to offer xk and xk is to be\naccepted by all players. If an offer y by proposer i is rejected by j, in the next round we\nproceed to a state K (k, i, y, j). You should find m, divisions x1, . . . , xm and a function\nK, and determine which offers are rejected by which players at a given state. Verify\nthat any offer y = xk is indeed rejected by some player at state k, and verify that the\nstrategy profile you found is indeed a SPE using single deviation principle.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 3 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/d84670f6abe9d20fc0382373c7514f33_MIT14_12F12_pset3sol.pdf",
      "content": "Problem 1\nThere are two subgames, or stages. At stage 1, each ice cream parlor i (I call it\nfirm i from now on) selects location xi simultaneously. At stage 2, each firm i\nchooses prices pi. To find SPE, we start from stage 2.\nAt stage 2, (x1, x2) are given. If x1 = x2, whoever charges less gets the\nwhole consumers and if their prices are same, each get half of the consumers.\nThus, only possible Nash equilibrium is p1 = p2 = 0, as setting any positive\nprice would make the other firm to undercut slighly (your price - ε) and take all\nthe kids; and you want to undercut the other firm slightly to take all the kids\nback.\nConsider the case x1 = x2. Without the loss of generality, I assume x1 < x2.\nNote that NE is only possible when we have an interior solution: there is a\n\"mid-point\" t such that x1 < t < x2 and kid at t is indifferent. If we do not\nhave interior solution, it means that kids at [0, x1] or [x2, 1]are indifferent and\nothers prefer one firm, or all kids go to one firm, say firm i. For the latter case,\nfirm j would deviate to a slightly lower price so that it can make positive profit.\nFor the former case, firm j would deviate to a slightly lower price so that it can\nsell to [0, x1] and some more, instead of selling only to x1\n2 kids (this case is for\nj = 1; j = 2 case is similar).\nFor the interior solution case, we have\nc (x1 -\nt) + p1 = c (x2 -t) + p2\nSolving, we get\np2\nt =\n-p1\nx1 + x2\n+\n2c (x2 -x1)\nFirm 1 solves the following profit maximization problem:\np2\np1\nx1 + x2\nMaxp1tp1 =\n\n-\n+\np\n2c (x2 -x1)\n\nTaking FOC (first order condition), we have\np2\nc x\npBR\n(p2) =\n+\n2 -x2\n\nSimilarly, firm 2 solves\n\np2\nMaxp2(1 -t)p2 =\n-p\n-\nx1 + x2\n+\np2\n2c (x2 -x1)\n\nTaking FOC, we have\np\npBR\n(p1) = c (x2 -\nc x2\nx1) +\n-x2\n2 -\n\nSolving two equations, we get NE:\nc\nc\np1 =\n(x2 -x1) (x1 + x2 + 2) , p2 =\n(x2\n-x1) (4 -x1 -x2)\n\nHomework #3 Solutions\n\nProfits are\nc\nc\nπ1 =\n(x2 -\nx1) (x1 + x2 + 2) , π2 =\n(x2\n-x1) (4 -x1 -x2)\nAt stage 1, choosing x1 = x2 cannot be an equilibrium, as in this case, they\nwill make zero profit at the stage 2 since p1 = p2 = 0 is NE in the stage 2.\nFirm 1 knows that his profit will be π1 =\nc\n(x2 -x1) (x1 + x2 + 2)\ngiven x2.\nTaking FOC, we have\n∂π1\nc\n=\n(x1 + x2 + 2) (x2\n∂x1\n-3x1 -2) < 0\nas 0 ≤x1 < x2 ≤1. Thus, choosing x1 = 0 is optimal. Similiarly, for firm 2,\n∂π2\nc\n=\n(4 + x1 -3x2) (4 -x1 -x2) > 0\n∂x2\nTherefore, choosing x2 = 1 is optimal.\nIn summary, SPE is that at stage 1, firm 1 chooses x1 = 0 and firm 2\nchooses x2 = 1.\nFor stage 2, if x1 = x2, p1 = p2 = 0.\nIf x1 = x2, p1 =\nc (x\nc\n(\n-x1) (x1 + x2 + 2) , p2 =\nx2\n-x1) (4 -x1 -x2).\nProblem 2\nI denote choices as P1 chooses L or R, P2 chooses l or r, P1 chooses A or B, P2\nchooses a or b (from top to bottom order). The bottom subgame has three NE:\n(A, a) , (B, b) ,\n1A + 3B,\n1a + 1b\n.\nAt the next subgame, If the first NE is played, payoffis 3 for both players\nso\nP2 will choose r.\n1A + 3B,\n1a + 1b\nOtherwise, payoffis less than 2 (1 for (B, b) and 3\n4 for\n), so P2 will choose l.\nFor the next (and last) subgame, if (A, a) is played and P2 played r, P1 will\nchoose R. Otherwise, he is indifferent between L and R.\nTherefore, SPE are (RA, ra), ({pL + (1 -p)R} B, lb) ,\n{pL + (1 -p)R}\n1A + 3B\n\n,\n\nl, 1a + 1b\n\n.\nProblem 3\nThe proposed strategy is for player i to offer δpi to other players and 1-δ(1-pi)\nfor himself, and to accept an offer if it is at least pi. To check that this strategy\nis a SPE, we consider all single deviations.\nSuppose i is the proposer after any history. His equilibrium strategy has\npayoff1-δ(1-pi). He can deviate to any strategy which offers all other players\nkj ≥δpj, which would be accepted, yielding a payoffof 1-δ\nkj ≤1-δ(1-pi).\nThis is not a profitable deviation. He can deviate to offer some player less,\nkj < pj for some j. Then the offer is rejected, and in the\nP\nnext round he has\nexpected payoffδpi < 1 -δ(1 -pi). This is not a profitable deviation.\nNext, consider i as a non-proposer after any history. Suppose he is offered\nki ≥δpi. If he accepts the offer, he gets either ki if all other non proposers\naccept, or expected δpi in the next round. He can deviate to reject the offer,\n\nand he would get an expected payoffδpi in the next round. Thus, deviating is\nnot profitable.\nIf a non-proposer is offered ki < δpi, he should reject in equilibrium, for an\nexpected payoffof δpi in the next round. If he deviates to accept, he gets either\nki if all other players accept, or δpi if someone reject. Both cases are weakly\nworse than rejecting, so deviating is not profitable.\nWe have checked all possible single deviations and none are profitable.\nProblem 4\nFor this problem, let us define πt(1) to be the proposer in period t and πt(2), πt(3)\nto be the first and second responders in period t. Let ei be the proposal that\ngives 1 to player i and 0 to everyone else. Define xt to be the proposal at period\nt and xt\ni be i's share of that.\nThe states are: {k0, p(1), p(2), p(3)}.\nFor any division a = (p1, p2, 1-p1-p2) where each player has strictly positive\npayoff, there is some δ where a SPE gives division a. Consider the following\nstrategy:\nAt t = 0, we start in state k0. In this state, player π0(1) proposes x0 = a.\nπ0(2) accepts iffx0 = a. π0(3) accepts if x0 = a or x0\nπ0(3) ≥δ.\nAfter k0, if x0 = a we go to stage p(π0(1)). Otherwise, if π0(2) rejected,\nwe go to stage p(π0(2)). If π0(2) accepts and π0(3) rejected, we go to stage\np(π0(3)).\nIn stage p(i), the proposer offers xt = ei. In these states, πt(2) accepts if\nthe proposer offers xt = ei. πt(3) accepts if xt\nπt(3) ≥δ OR xt = ei.\nAfter rejection in state p(i), we stay in p(i) if xt = ei. Otherwise, if πt(2)\nrejects, we go to p(πt(2)). If πt(2) accepts and πt(3) rejects, we go to p(πt(2)).\nTo check that this is an equilibrium, we look at all single deviations after\nany valid history. We first check that there are no profitable deviations at t = 0.\nProposer: At t = 0, π0(1) offers xt = a. If he deviates and offers x0 = a, it\nis rejected by π0(2). Then in the next period we are in stage p(π0(2)), where\neπ0(2) is offered and accepted. This gives payoff0 to player π0(1), which is not\na profitable deviation.\nNext, we look at deviations by the responder at t = 0.\nCase: x0 = a. In equilibrium both responders accept. If either responder\nchooses to reject, we go to state p(π0(1)), where both responders get payoff0.\nThis is clearly not a profitable deviation.\nCase: x0 = a and x0\nπ0(3) ≥δ. Consider π0(3). Assume π0(2) accepts. In\nequilibrium, π0(3) accepts and gets x0\nπ0(3) ≥δ. If he deviates and rejects, we go\nto state p(π0(3)), which leads to payoffδ, so deviation is not profitable. After\nthe history where π0(2) does not accept, π0(3) is indifferent between his actions.\nConsider π0(2).\nIn equilibrium, π0(2) rejects the offer, we go to state\np(π0(2)) which yields payoffδ. If player π0(2) instead deviates and accepts,\n\nwe know that π0(3) also accepts, which yields payoffof x0\nπ0(2) for π0(2). Since\nwe assume that δ is large and xt\nπ0(3) ≥δ, xπ0(2) must be small, and thus less\nthan δ. This requires δ ≥0.5.\nCase: x0 = a and x0\nπ0(3) < δ. Consider π0(3). Assume π0(2) accepts. Player\nπ0(3) rejects in equilibrium and gets δ in state p(π0(3)).\nIf π0(3) accepts,\nhe instead gets x0\n< δ, which is not profitable. if π0(2) rejects, π0\nπ0(3)\n(3) is\nindifferent again.\nConsider π0(2). In equilibrium, π0(2) rejects and gets δ. If he deviates and\naccepts, π0(3) rejects and we go to p(π0(3)), where π0(2) gets 0.\nNext, we consider t ≥1, when we are in state p(i).\nTo see that the proposer has no profitable deviation, consider two cases.\nIf we are not in state p(πt(1)): In equilibrium the proposer offers ei and is\naccepted, so the proposer has payoff0. If he offers any other xt = ei, the offer is\nrejected and we go to p(πt(2)), where the proposer has payoff0. The proposer\nis indifferent between any offer.\nIf we are in the state p(πt(1)): In equilibrium, πt(1) offers xt = eπt(1), it\nis accepted and he has payoff1. This is his maximum payoff, so there is no\nprofitable deviation.\nFinally, we have to check that responders have no profitable deviation, in\nthree cases.\n1. xt = ei\n2. xt = ei and xt\nπt(3) ≥δ\n3. xt = ei and xt\nπt(3) < δ\nCase 1: In equilibrium all responders accept xt. By deviating to rejection\n(for either player), we return to this state again in the next period, and all\nplayers are weakly worse off.\nCase 2: First consider πt(3). Suppose that πt(2) accepts. In equilibrium,\nπt(3) accepts and gets a payoffof δtxt\nπt(3). If he deviates and rejects, we go\nto p(πt(3)), where he gets a payoffδt+1, which is not a profitable deviation. If\nπt(2) rejected, πt(3) is indifferent.\nNow consider πt(2). In equilibrium, he rejects, and we go to p(πt(2)), where\nhe gets δt+1. If he deviates and accepts, he instead gets δtxt\nπt(2). Because δ is\nlarge and xt\nπ(3) ≥δ, we can assume that δtxt\nπt(2) ≤δt+1.\nCase 3: First consider πt(3). Suppose that πt(2) accepts. In equilibrium,\nπt(3) rejects and gets payoffδt+1. If he deviates and accepts, he gets δtxt\nπt(3)\nstrictly less. This is not a profitable deviation. If πt(2) rejected, πt(3) is indif-\nferent.\nNow consider πt(2). In equilibrium he rejects, and we go to p(πt(2)), where\nthe payoffis δt+1. If instead he deviates and accepts, πt(3) rejects, we go to\np(πt(3)) and πt(2) gets payoff0. This is not profitable.\n\nThus, we see that there is no single profitable deviation, and we have a\nsubgame perfect equilibrium.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/9163781007c28557ecf4b78a98e5a1c8_MIT14_12F12_pset4.pdf",
      "content": "14.12 Game Theory\nMuhamet Yildiz\nFall 2012\nHomework 4\nDue on 11/9/2012 (Recitation)\n1. Consider the -times repeated game with the following stage game\n\n(a) Find a lower bound for the average payoffof each player in all pure strategy Nash\nequilibria. Prove indeed that the payoffof a player is at least in every pure-strategy\nNash equilibrium. (Your grade will be 10.)\n(b) Construct a pure-strategy subgame-perfect Nash equilibrium in which the payoffof each\nplayer is at most +1. Verify that the strategy profile is indeed a subgame-perfect Nash\nequilibrium.\n2. Consider the infinitely repeated game with discount factor ∈(01) and the stage game\nA\nX\n(1,0,0)\nI\nB\nR\nL\nC\nL\nR\nL\nR\n(0,2,2)\n(5,0,0)\n(5,0,0)\n(2,1,1)\nFor each of the strategy profile below, find the range of under which the strategy profile is\na subgame-perfect Nash equilibrium.\n(a) The play is () if () has been played at all previous days, and () is\nplayed otherwise.\n(b) On \"Sundays\", i.e., at ∈{0714}, () is played; on other days, ()\nis played if () has been played at all previous such days and () is played\notherwise.\n(c) On \"Sundays\", () is played; on other days, () is played if () has been\nplayed at all previous such days and () is played otherwise.\n\n3. Consider the infinitely repeated prisoners' dilemma game with discount factor = 0999; the\nstage game is\n\n(a) Find a subgame-perfect Nash equilibrium in pure strategies under which the average\npayoffof each player is in between 1.1 and 1.2. Verify that your strategy profile is indeed\na subgame-perfect Nash equilibrium.\n(b) Find a subgame perfect Nash equilibrium in pure strategies under which the average\npayoffof player 1 is at least 57. Verify that your strategy profile is indeed a subgame-\nperfect Nash equilibrium.\n(c) Can you find a subgame-perfect Nash equilibrium under which the average payoffof\nplayer 1 is more than 5.8?\n4. [Recall Problem 4 in Homework 2.] Consider the repeated game with the following stage\ngame. A unit mass of kids are uniformly located on a street, denoted by the [01] interval.\nThere are two ice cream parlors, namely 1 and 2, located at 0 and 1, respectively. Each ice\ncream parlor sets a price ≤ for its own ice cream, simultaneously, where\n\n0.1 A kid\nlocated in is to pay cost |-| to go to a store located at , where ∈(0\n3). Given\nthe prices 1 and 2, each kid buys one unit of ice cream from the store with the lowest total\ncost, which is the sum of the price and the cost to go to the store. (If the total cost is the\nsame, she flips a coin to choose the store to buy.)\n(a) Assume that the above game is repeated 100 times, and find the subgame-perfect Nash\nequilibria.\n(b) Assume that the above game is repeated infinitely many times and the discount rate is\n∈(131). For each of the following strategy profile, find the highest ∗under which\nthe strategy profile is a subgame-perfect Nash equilibrium. (Here, ∗may be a function\nof . You need to choose both ∗and ˆ to make the strategy profile a subgame-perfect\nNash equilibrium.)\n1. At the beginning each parlor chooses = ∗and continues to do so until some\nplayer sets a different price; each selects price = ˆthereafter.\n2. There are two states: Collusion and War. The game starts at the state Collusion. In\nCollusion state, each player chooses = ∗, and in War state each player chooses\n= ˆ. If both players set the price prescribed for the state, then the state in the\nnext round is Collusion; the state in the next round is War otherwise.\n3. Bonus: In part (ii), assume that ˆ ≥0 but war can last multiple periods. State such\na strategy profile formally and answer the above question for such a strategy profile.\n1Note the difference from the previous exercise. The price can now be negative (e.g. ice cream parlor can give a\ngift to the kids who buy) and bounded from above (e.g. the kids cannot pay more than a fixed amount).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set 4 Solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/a45d206a6b7665b3e8057596f36efeb2_MIT14_12F12_pset4sol.pdf",
      "content": "Problem 1\na. The lower bound is 1. If n is even, let X be ((c, c), ..., (b, b)...), where\n(c, c) is played for n/2 periods and (b, b) is played for n/2 periods. For n odd,\nX = ((c, c), ..., (b, b), ..., (a, a)), where (c, c) is played for (n - 1)/2 periods, (b, b)\nis played for (n - 1)/2 periods. The nash equilibrium strategy is to play X as\nlong as X has been played in every previous period, and otherwise play (c, c)\nfor the rest of the game. This is a nash equilibrium because there is no possible\ndeviation for either player. If a player deviates, he will get payoff at most 1 in\nevery future period, so the best he can get by deviating is payoff n, which he is\nindifferent to.\nb. For n even, Xn = ((c, c), ..., (b, b), ..., (a, a)), where (c, c) is played for n/2\nperiods, (b, b) is played for n/2-1 periods. If n is odd, let X be ((c, c), ..., (b, b)...),\nwhere (c, c) is played for (n - 1)/2 periods and (b, b) is played for (n + 1)/2 pe\nriods. For n = 1, the strategy is to play (b, b), for payoff 2. We prove by\ninduction.\nSuppose that for n < T , there is a subgame perfect equilibrium with payoff\nn + 1. At n = T , the subgame perfect equilibrium is to play XT as long as\neveryone has played on the equilibrium path. If a player deviates from playing\n(c, c) at some period with t rounds remaining, we play Xt as punishment. If a\nplayer deviates from playing (b, b) or (a, a), we continue on XT .\nA player that deviates with t rounds remaining gets payoff 1 in that round,\nand then plays the Xt subgame perfect equilibrium with payoff t +1, for a total\nof t+2. This will never exceed T +1, so on histories on the equilbrium path there\nare no profitable deviations. There are no deviations after histories when we are\non Xt because they are subgame perfect equilbria, by the inductive hypothesis.\nProblem 2\na. This is never SPE. Player 2 has payoff 0 in equilibrium, so he can always\ndeivate to R for payoff 1.\nb. This is also never SPE, for the same reason.\nc. This is always a SPE. In every period, players are playing a stage game\nnash equilibrium, so the strategy is subgame perfect equilibrium.\nProblem 3\n(a) Suppose for each cycle, (C,C) is played a times and (D,D) is played b\n5a+b\ntimes. Then average payoff for the cycle is 5a+b . To make 1.1 <\n< 1.2, we\na+b\na+b\nneed 19a < b < 39a. Let's choose a = 1, b = 20. The strategy profile is for each\nplayer, play D for t = 21k + i, for i = 1, 2, . . . , 20 and play C for t = 21k if no\ndeviation has occurred. If any deviation has occured, play D forever.\nNo player has incentive to deviate when some player has deviated since (D,D)\nis NE of the stage game. When a player is supposed to play D at t = 21k + i,\nto prevent deviation we need\nδ\n6 + 1 ·\n≤ 1 ·\n+ 4δ21-i\n1 - δ21\n1 - δ\n1 - δ\nnote that the right side of inequality is minimized at i = 1, so we only need\nto check that case. For δ = 0.999, it holds.\nWhen a player is supposed to play C, to prevent deviation we need\nHomework #4 Solutions\n\nδ\n6 + 1 ·\n≤ 1 ·\n+ 4 · 1 - δ21\n1 - δ\n1 - δ\nFor δ = 0.999, it holds.\n(b) The strategy profile is that player 1 plays D for t = 4k + i, for i = 0, 1, 2\nand plays C for t = 4k + 3 and player 2 plays C for all t if no deviation has\noccurred. If any deviation has occured, play D forever. When (D,C) is supposed\nto be played, player 1 has no incentive to deviate as he gets the maximum\npossible payoff. For player 2, we only need to check t = 4k case (similar logic\nfrom part a) as if she were to deviate she would have maximum incentive at\nthat case. To prevent deviation we need\n1 ·\n≤ δ3 · 5 ·\n1 - δ\n1 - δ3\nfor δ = 0.999, it holds. When (C,C) is supposed to be played, for player 1 we\nδ\nδ\nneed 6 + 1 ·\n≤ 6 ·\n-\nand for player 2 we need 6 + 1 ·\n≤ 5 ·\n1-δ\n1-δ\n1-δ3\n1-δ\n1-δ3 .\nBoth holds for δ = 0.999.\n(c) The answer is no. To give player 1 the average payoff of more than 5.8,\nwe have to give player to the average payoff of less than 1. Since player 2 can\nget at least 1 by deviation and can get at least 1 in all static NE, we cannot\nconstruct SPE where player 2 gets less than 1 on average.\nNo player has incentive to deviate when some player has deviated since (D,D)\nis NE of the stage game.\nProblem 4\n∗\n(a) If |p1 - p2| < c, we have an interior solution: there is a \"mid-point\" x\n∗\nsuch that 0 < x ∗ < 1 and kid at x is indifferent. In other words,\n∗\ncx + p1 = c (1 - x ∗ ) + p2\n∗\np2 -p1\nso x =\n+\n. If |p1 - p2| ≥ c, then all kids go to one firm.\n2c\nTo start, we find one stage (static) NE. If |p1 - p2| ≥ c, it cannot be an\nequilibrium as higher price firm makes zero and has incentive to cut its price so\nthat it can make positive profit. For |p1 - p2| < c, firm 1 solves\n\np2 - p1\nmaxp1 p1\n+\n2c\nBR\nc+p2\nBR\nc+p1\nTaking FOC, you get p\n(p2) =\n. Similirly, p\n(p1) =\n. Thus,\np1 = p2 = c as NE.\nSince this NE is a unique SPE for the stage game, playing this NE for all\nperiod is a unique SPE for finite games.\n∗\n(b-1) Check what would be the best response if the other firm plays p . If\n∗ - c ≥ p ∗ +c\n∗\np\n(or p ≥ 3c), then BR is to charge p ∗ - c and capture the whole\nmarket. In this case, to make sure that there is no incentive to deviate, we need\n∗\np\nc\n1 + δ + δ2 + · · ·\n≥ (p ∗ - c) +\nδ + δ2 + · · ·\n\n∗\np\ncδ\n≥ (p ∗ - c) (1 - δ) +\n∗\n(2δ - 1) p\n≥ (3δ - 2) c\nNote that pˆ = c here.\n∗ ≥ 3δ-2\n∗\nIf δ > 1\n2 , then p\nc. Thus, maximum p is p .\n2δ-1\n∗\nIf δ = , then 0 ≥-2c works for all p ∗, so maximum p is p .'\n∗ ≤ 2-3δ\nIf δ < 1 , then p\nc = pmax.\n1-2δ\n∗\nIf δ ≥ 1\n3 , pmax ≥ 3c so maximum p is p .\n+c\nIf δ < 1 , pmax < 3c so the best responce is p ∗\n. In this case, to make sure\nthat there is no incentive to deviate, we need\n∗\n∗\np\n(p + c)\nc\n1 + δ + δ2 + · · ·\n≥\n+\nδ + δ2 + · · ·\n8c\n∗\n∗\np\n(p + c)\ncδ\n≥\n(1 - δ) +\n8c\nSolving, we get\n1 + 3δ\n∗\np ≤\nc\n1 - δ\n(b-2) Suppose the firm makes u0 by deviating during the war period. Note\nthat u0 is zero if pˆ ≤ 0 and positive if ˆp > 0.\nLet V0 as a sum of current and future profit at the war period. Then V0 =\npˆ\np\nδ\n+\n∗\nand to prevent deviation during the war state, we need\n2 1-δ\nδ\nV0 ≥ u0 +\nV0\n1 - δ\n1 - δ\nor V0 ≥ u0. Since u0 ≥ 0, the best punishment is to choose V0 = u0 = 0.\nδ\n∗\nThis could be done by choosing pˆ = -\np .\n1-δ\nFor collusion period, to prevent deviation we need\n∗\np\n≥ (1 - δ) (p ∗ - c) + δ · 0\n\n∗\n- δ\np\n≤ (1 - δ) c\n\n∗\n∗\n(1-δ)c\nThus, if δ ≥ 1 , then p = p. If δ < 1 , then p = min\np,\n.\n1 -δ\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set Week 4",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/c375b6c43824cc7eb19b0cccb22c85e9_MIT14_12F12_recitation%202.pdf",
      "content": "14.12 Recitation 2\nSeptember 28, 2012\nConcepts\n1. Rationality: formally, a player is said to be rational if and only if he maximizes\nthe expected value of his payoffs (given his beliefs about the other players'\nstrategies.)\n∗\n2. Dominance: A strategy s strictly dominates si if and only if\ni\n∗\nui(si , s-i) > ui(si, s-i), ∀s-i ∈ S-i.\nBR\n3. Best response: For any player i, a strategy s\nis a best response to s-i\ni\nif and only if\nBR\nui(s\n, s-i) ≥ ui(si, s-i), ∀si ∈ Si\ni\nThis definition is identical to that of a dominant strategy except that it is\nnot for all s-i ∈ S-i but for a specific strategy s-i. If it were true for all s-i,\nBR\nthen Si\nwould also be a dominant strategy, which is a stronger requirement\nthan being a best response against some strategy s-i.\nNE\nNE\n4. Nash Equilibrium: strategy profile (s\n, ...s\n) is a Nash Equilibrium if\nN\nNE\nNE\nNE\nNE\nNE\nNE\nand only if s\nis a best response to s\n= (s\n, ...si-1, si+1 , ...s\n) for each\ni\n-i\nN\ni. That is, for all i, we have that\nNE\nNE\nNE\nui(s\n, s\n) ≥ ui(si, s\n) ∀si ∈ Si.\ni\n-i\n-i\nProblem 1 (Similar to HW1-4)\nSuppose there is a (polluting) firm and a (pollution-averse) consumer. The firm\neither pollutes or is shut down. One way for the (rich) government to resolve\nthe externality is as follows:\n1. Ask the firm to state the monetary benefit ˆb of generating pollution\n2. Ask the consumer to state the monetary equivalent of the cost of suffering\npollution, cˆ.\n3. Shut the firm down iff cˆ ≥ ˆb. If the firm is open, give the consumer ˆb and\ncharge the firm cˆ\nThe players are 1) the firm, and 2) the consumer. True benefit and cost are\nb and c, respectively.\n\n(a) Write this in the normal form.\nThe strategies\nˆ\n\nare b ∈[0, inf] and\ncˆ ∈[0, inf]. Utility (pa yoffs) from strategy\nprofile ˆ\n(\n\nˆ\nˆ\nb, cˆ\nof players are u b, cˆ\n= (b cˆ) b > cˆ\n= (b cˆ) 1\nand\n\nf\n-\n-\n[ˆb>cˆ]\nˆ\nˆ\nˆ\nuc b, cˆ\n(\n=\n\nb c\nb > cˆ .\n(\n\nt\n( (\n\n(\n-\nt\n(\n(b) Check if there is a dominant strategy equilibrium, and compute\nit if there is one.\nFirst, check the firm. Suppose ˆb > b. Then, three cases:\n\ni) ˆ\n>\nˆ\nb > b\ncˆ: uf\n(\nb, cˆ\n\n(\n= (b - cˆ) = uf (b, cˆ)\n\nii) ˆ\nˆ\nb > cˆ ≥ b: uf (b, cˆ = - (cˆ - b) < 0 = uf (b, cˆ)\n\niii) cˆ ≥ ˆb > b:\nˆ\nuf b, cˆ = 0 = uf (b, cˆ)\nNow, suppose b > ˆb\n\ni) b > ˆ\n\nˆ\nb > cˆ: uf b, cˆ = (b - cˆ) = uf (b, cˆ)\n\nii)\nˆb:\nˆ\nb > cˆ ≥\nuf\n(\n\n(\nb, cˆ\n\n(\n= 0 < b - cˆ = uf (b, cˆ)\n\niii)\nˆ\ncˆ ≥ b > ˆb: uf b, cˆ = 0 = uf (b,( cˆ)\nHence, for any ˆ,\n≥\nˆ\n\nand there exist\nˆ\n(\nb\nuf (b, cˆ)\nuf b, cˆ\ncˆ∗ b\nsuch that\n\nˆ\nuf (b, cˆ∗) > uf b, cˆ∗.\n(\nNow, check the consumer.\n(\n\nSuppose\n(\ncˆ > c. Then,\ni)\n≥ ˆ\nˆ\nˆ\ncˆ > c\nb : uc b, cˆ = 0 = uc b, c\nii) ≥ ˆ\nˆ\ncˆ\nb > c : uc b, cˆ = 0 < ˆb - c =\nˆ\nuc b, c\niii) ˆb >\nˆ\nˆ\nˆ\ncˆ > c : uc\n(\n\n(\nb, cˆ\n\n= b - c = uc b, c\n(\n\nFinally, suppose c > cˆ :\n(\n\ni)\nˆ\nˆ\nˆ\nc > cˆ ≥ b : uc\n(\n\n(b, cˆ = 0 = uc\n(\n\n(\nb,\nii)\nˆ\nc\n\n≥ ˆ\n\n-\n-ˆ\n\n(\nˆ\nc\nb > cˆ : uc b, cˆ =\nc\nb\n< 0 = uc b, c\niii) ˆb > c > c\n(\nˆ\n\nˆ\n\n(\nˆ\nˆ : uc b, cˆ = b - c = uc\nb, c\n\nTherefore, both the consumer and the firm\n\nhave truth-telling as a weakly\ndominant strategy.\nOne problem: The government suffers a deficit of ˆb - cˆ, (or it may suffer a\nsurplus if the firm is closed if the government taxes everyone beforehand).\n\nProblem 2 (2011 Midterm 1-1)\n(a) Compute the set of all rationalizable strategies in the following\ngame.\nw\nx\ny\nz\na\n0,3\n0,1\n3,0\n0,1\nb\n3,0\n0,2\n2,4\n1,1\nc\n2,4\n3,2\n1,2\n10,1\nd\n0,5\n5,3\n1,2\n0,10\nAnswer: Iterated Elimination of Strictly Dominated Strategies: eliminate\nall the strictly dominated strategies and iterate this k-times. In this procedure,\none eliminates all the strictly dominated strategies and iterates this k times.\nTwo main points are:\n1. One must eliminate only the strictly dominated strategies. One cannot\neliminate a strategy if it is weakly dominated but not strictly dominated.\n2. One must eliminate the strategies that are stricly dominated by mixed\nstrategies (but not necessarily by pure strategies).\nStrategy\n\nx is strictly dominated by the mixed strategy σ2 with σ2(w)\n∈\n,\nσ2(y) = 1\nσ2(w)\nand\n-\n. In the first round, x is therefore eliminated. (No\nother strategy is eliminated in that round.) In the second round, d is strictly\ndominated by b and eliminated. In the third round, z is strictly dominated by\nσ2 above and eliminated. In the fourth round, c is strictly dominated by b and\neliminated. There are no other elimination, and the set of rationalizable strate-\ngies is {a,b}×{w,y}. (Note: explain how to find which strategy to eliminate by\nchecking best responses)\n(b) Compute the set of all Nash equilibria.\nAnswer: The only Nash equilibrium is σ∗where σ\n∗(a) =\n, σ\n∗(b) =\n7 and\nσ∗(w) = 1, σ∗(y) = 3\n4. (Note: explain how to derive this - in order for one\nplayer to mix strategies and play multiple strategies with positive probabilities,\nhe must be indifferent between those strategies, or have the same expected\nutility for all choices)\nProblem 3 (2009 HW2-1)\nConsider the following investment game. There are two firms, each of them has\nto decide how much to invest. If we let ki ≥0 be the investment choice of firm\ni, then the profits of the firm are given by:\nk2\nπi(ki, kj) = Aki -\ni\nwhere the productivity of firm i is given by A = α + (ki + kj)(1\nα), where\nα ∈( 2\n-\n, 1]\n. Note how productivity depends on the investment level of both\nfirms.\n\n(a) What are the best response function for each firm as a function\nof α?\nEach firm will maximize its profit given the other firm's strategy. The first order\ncondition is\n∂πi = α + kj (1 - α) + ki(1 - 2α) = 0\n∂ki\nIn other words,\nα + kj (1 - α)\nki = BRi(kj ) =\n2α - 1\n(b) Find the Nash equilibrium of the game, call it (k(α), k (α)). Note\nthat in the Nash equilibrium both firms choose the same investment\nlevels.\nThe Nash equilibrium is the point at which the two best response functions\nintersect. By symmetry, we set ki = kj = k and solve\nα + k(1 - α)\nk =\n2α - 1\n(\nα\nα\nThe NE is\n,\n.\n3α-2\n3α-2\n(c) What happens when α → 1? Does the equilibrium investment\nlevel increase or decrease? Do you have intuition for this result?\nα\n2/3\nk =\n=\n+\n. Thus, as α → 1, the investment level decreases. Intuition\n3α-2\n3α-2\nis clear: as α increases, productivity depends less on the total investment level\nand firms want to invest less.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Assignment",
      "title": "Problem Set  5",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/8b2fb653beb3051314806bbf65ae3a86_MIT14_12F12_pset5.pdf",
      "content": "14.12 Game Theory\nMuhamet Yildiz\nFall 2012\nHomework 5\nDue on 12/7/2012 (Recitation)\n1. Alice and Bob have inherited a factory from their parents. The value of the factory is vA\nfor Alice and vB for Bob, where vA and vB are independently and uniformly distributed over\n[0, 1], and each of them knows his or her own value. Simultaneously, Alice and Bob bid bA\nand bB, respectively, and the highest bidder wins the factory and pays the other sibling's bid.\n(If the bids are equal, the winner is determined by a coin toss.) Find a symmetric, linear\nBayesian Nash equilibrium of this game.\n2. An object is to be sold to one of n bidders through a first-price auction. The value of object\nfor bidder i is vi ≥ 0, which is privately known by the bidder i. The values (v1, . . . , vn) are\nindependently and identically distributed with probability density function f and cumulative\ndistribution function F . Write this formally as a Bayesian game and compute the symmetric\nBayesian Nash equilibria in increasing differentiable strategies.\n3. There are n hunters. Simultaneously each hunter chooses between Stag and Rabbit. If a\nhunter chooses Rabbit, his payoff is θ regardless of what other hunters do. If he chooses Stag,\nhe gets v > 0 if at least k other hunters also choose Stag and gets 0 otherwise. The possible\nvalues for θ is [a, b] where a < 0 and b > v.\n(a) Assume that θ is known and compute the set of pure strategy Nash equilibria.\n(b) Assume that θ is not known. Each player i observes a signal\nxi = θ + εηi\nwhere 0 < ε « min {-a, b - v} and (η1, . . . , η ) are independently and identically dis-\nn\ntributed with uniform distribution on [-1, 1]. Find the set of symmetric, monotone\nBayesian Nash equilibria. (That is, find the possible values for a cutoff x ∗ such that each\nplayer i chooses Stag if and only if xi ≤ x ∗ in equilibrium.)\nHint: By symmetry, the probability that xi is the mth highest among (x1, . . . , xn) is\n1/n.\n(c) Briefiy discuss your answers.\n4. Alice owns a car, and Bob may buy it. The car can be a Lemon or a Peach. Alice knows\nwhether it is Lemon or Peach, while Bob assigns probability 1/2 to each case. The value of\na Lemon is $1,000 for Alice and $3,000 for Bob, and the value of a Peach is $5,000 for Alice\nand $10,000 for Bob. Alice sets a price p ∈ P , and Bob decides whether to accept the price.\nIf the price is accepted, they trade the car at price p; no trade occurs otherwise. For each set\nP below find a sequential equilibrium and verify that it is indeed a sequential equilibrium.\n(a) P = {2000, 7000}\n(b) P = [0, inf).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "Problems from Past Exams",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/947b34e09116f448f48c84147340ad81_MIT14_12F12_Selected_Prob.pdf",
      "content": "Answers to Selected Problems from Past Final Exams\nMaksim Pinkovskiy\nDecember 17, 2011\nProblem 1, Final 2004\nDenote the type with probability 0.4 as strong, and the type with probability 0.6 as weak.\nIt is clear that if player 1 is strong, he will play A over D at node 1.\nSuppose that player 2 believes that P1 is strong with probability f and weak with probability 1 - f.\nSince player 1 plays A whenever he is strong, it follows that\nP (8)\nf =\n0.4\nP (8) + P (AW) P (W)\nThen, P2 chooses if 2 (1 - f) 1, or 1 - f 0., or f 0.. )therwise, P2 chooses\n. Clear that\nneither separating nor pooling works here. +hy,\nSeparating: must involve weak P1 playing , and P2 playing\n. .ut then, weak P1 wants to play .\nPooling: P2 wants to play , and weak P2 then wants to play .\nConsider the following: +eak P1 plays a mixed strategy such that f = 0., so P (W) =\n- P (8) =\n\n= 2 , and P2 plays a mixed strategy such that weak P1 is indiferent. Speci/cally, P2 plays with\n\nprobability , so weak P1 gets + (1 - ) from , and 2 from . Therefore, we have -2 = 2, or = 0..\nCheck that this is an SE. The pro/le speci/ed is\nA, 2 + 1 , 1 + 1\n, (0., 0.) . +e implicitly did\n\nthis in the derivation.\nSe0uential 1ationality: At 1(strong), A is a strictly dominant strategy. At 1(weak), P1 is indiferent\nbetween and . At 2, P2 is indiferent between and\n.\nConsistency: Since strong P1 always plays A, 2so P (A8) = 1), and weak P1 plays with probability 2 ,\nwe have that f = 0..\nProblem 4, Final 2004\nThe timing of the game is as follows:\n1) Professor chooses cutof score , E [0, 100]\n2) Student observes type t E {H, L} and decides whether to take class. If does not take class, professor\ngets 0, and student gets Wt, where 0 < WL < WH < 100\n3) If student takes class, he exerts efort e and gets grade s = e . (t = L) + 2e . (t = H). The professor's\npayof is s. The student's payof is 100 . (s ,) - e/2.\nI will let t = 0 stand for the low-ability student and t = 1 stand for the high-ability student. Hence, the\ngrade production function of a student with ability t is s (e) = 2t-1e.\nConsider the last stage of the game. Then, the student solves max {100 . (2te ,) - e/2} = max ((100 - e/2) (2te ,) , -e\ne\nIf student decides to fail, sets e = 0, and gets 0.\nIf student decides to pass, sets e = f\n\" , and gets 100 -\nf\nIn particular, gets UL = 100 - f , and\n2\" ' .\nUH = 100 - f .\n\nConsider the second stage. Then, the student takes the class i¤ 100\n\nWt\n2t+1\n. In particular, low types\ntake the class i¤ 100\n\n> WL\nand high types take the class\nNow, consider the ...rst stage. The professor's payo¤is E\ni¤ 100 > WH\n.\nt+1 W\n\nt =\n(1\n4 WH +\n) 100\nIf everyone takes the course, the professor should set = min (4 (100 WH\nget min (2 (100\nWH) ; (100\nWL))\n\n) ; 2 (10\nWL)), and would\n\nIf only high types take the course, the professor should set = 4 (100 WH), and would get 2 (100 WH)\nIf only low types take the course, the professor should set = 2 (100 WL) ;and would get (100 WL) (1 )\nSuppose that > 1 100WL\nW\n2 100W\nand\nH < 100+WL\n2 (100\nWH) > 2 100\n100+WL\n= 100\nWL\nH\n. Then,\n,\nso making the course for all would get the professor 100 WL > (100 WL) (\n1 ).\nNow, 2 (100\nWH) > 100\nWL, so he will make the course for the high types only.\n\nSuppose that > 1 2 100WH\nW\nand WH >\n100+WL\n.\nThen, 2 (100\nL\nWH) < (100 WL), so PU =\n2 (100 WH) > 2 (100 WH) . Moreover,\n(100 WL) (1 ) < (100 WL)\n\n1 2 100WH\n(100\nWL\n\n= 2\nWH), so PU is maximum and every-\none takes the course.\nSuppose that < 1 100WL and W\n< 100+WL\nH\n. Then, 2 (100\nW )\n2 100H > 100\nWL\nWL\nWH\n, so PU = 100\n>\n(100 W ) (1 ). Now, 2 (100 W ) < 1 100\nW\nL\nH\nL = 100\nW\nWL, so everyone takes the course (since P\nU\nis maximum).\nH\nThe grades are 100 WL, 2 (100 WH) < 100 WL, and 100 WL. Therefore, the grades at the ...rst\nand third institutions are the same. The grade at the second institution is too low.\nProblem 2, Final 2007 (Regular Exam)\nFirst note that we have one type for player 2, and three types for player 1: A, B, and C. Player 2 knows\nwhether player 1 played L1,L2,L3 or R1,R2,R3, but doesn't know player 1's type. Also note how I labeled\nall the nodes in this diagram.\nIt is clear that 1A has R1 as a dominant strategy, and 1B has L1 as a dominant strategy. Therefore, at\ninformation set 2L, player 2 knows that player 1 is either type A or B and played Left, so player 2 must\nconclude that player 1 has type B. Therefore, player 2 will play b at information set 2L.\nConsider player 2's play at information set 2R. Then, player 2 knows that player 1's type is not B.\nLet be player 2's belief that he is at 2RA, and 1 be his belief that he is at 2RC. Note that =\nP (2RjA)P (A)\n(1=3)\n=\nP (2RjA)P (A)+P (2R\n.\njC)P (C)\n(1=3)+(1=3)P (2RjC) 2\nWhat is player 2's best response given a belief ? Player 2 will play l i¤ 2 (1 ) or 2\n3.\nSuppose that type 1C always plays L3:Then, = 1, and player 2 should play l, which he wants to do.\nHowever, type 1C would do better by playing R3 and getting 2, so this is not an SE.\nSuppose that type 1C always plays R3. Then, = 1\n2 and player 2 should play r. But then, type 1C\nwould do better by playing L3 and getting 1, so this is not an SE.\nHence, it is clear that type 1C has to mix, and therefore, has to be indi¤erent between L3 and R3.\nMoreover, player 2 has to mix at information set 2R, so as to make type 1C indi¤erent. Then, player 2\nherself must be indi¤eren t between l and r, so it must be the case that = 2\n3. The only way we can have\n= 2\n3 is if P (2RjC) =\n2 1 3 = 1\n2, so type 1C must mix between L3 and R3 with probability 1\n2. Now,\nsuppose that player 2 mixes with probability p of going left. We have that for type 1C, U (L3) = 1, and\nU (R3) = 2p, so must have p = 1\n2. We have now pinned down the strategies and beliefs of all the players,\nand the sequential equilibrium is\n\nR1; L1;\nR3 +\nL3\n; b;\nl +\nr\n; = 0, =\n\nHow to check that this is an SE: Check sequential rationality and consistency. We did all the calculations\nin the work, so just write what you would have needed to check:\n1) SR at node 1A: 1A has a dominant strategy R1\n2) SR at node 1B: 1B has a dominant strategy L2\n3) SR at node 1C: 1C is indi¤erent between L3 and R3, so he can mix\n4) SR at information set 2L: P2 believes he is at 2LB, so plays b\n5) SR at information set 2R: P2 believes he is at 2RA with probability 2\n3, so is indi¤erent between l and\nr, and can mix\n1) Consistency at information set 2L: Only 1B ever plays L2, so the probability that we are at 2LA,\n= 0.\n2) Consistency at information set 2R: 1A always plays R1, and 1C plays R3 one-half of the time, so the\nprobability we are at 2RA, = 2\n3.\nProblem 2, Final 2010\nThree bidders, two objects. Values independent and uniform; each vi 2 [0; 1]. Perform a ...rst-price auction.\na) Set of players: N = f1; 2; 3g\nb) Set of types: Ti = [0; 1] 8i 2 N\nc) Set of actions: bi 2 R\nd) Set of expectations: pi (t\nijti) = 1\nv\n;\ne) Set of payo¤s: ui (b; v =\ni b\n)\ni\n\nt\n2 [0; 1]\ni\nbi > min (bi)\n\n0; bi = min (bi)\nWe are to ...nd a symmetric BNE in strictly increasing and di¤erentiable strategies.\nStep 0: De...ne what you are looking for:\nWe have bi (vi) = b (vi), where b0 (vi) exists and b0 (vi) > 0 for vi 2 (0; 1) :\nStep 1: Compute expected utility\nU (bijvi)\n=\nE\n\nui\n\nb\nZ\ni; b (vj)\n; v\nv\nj=i\n\nj i\n=\nui\nbi; b (vj)\n\n; v dv\ni\nj=i\nZ\nv\n2[0;1]2\n¬\n\ni\n=\n(vi\n) dv\ni>min(b )\nbi\nb\ni\nj\n=\n(vi bi) P0(bi > min (b (vj)))\n=\n(vi bi) @1 Y\nP (bi < b (vj))\nj=i\nA\n=\n(vi bi)\n@1 Y\nP b\nj=i\n1 (bi) < vj\n\n=\n(vi bi)\n\nA\nb1 (bi)\nStep 2: Take the FOC\n\ndU\n0 =\n=\nb ( i)\nb\n+ 2 1\n(\ndb\nb1 bi) (vi\ni\nbi)\n\nb0 (b1 (bi))\n\nNow, make the substitution bi = b (vi), so b1\n\n(b (vi\n\n)) = vi. Hen\n\nce,\n\n=\n\n1 [1 vi]\n\n+ 2 [1 vi] (vi b (vi))\n\nb0 (vi)\n\n=\n\n1 [1 vi]\n\nb0 (vi) + 2 [1 vi] (vi b (vi))\nStep 3: Check the solution satis...es our hypotheses\nWe have bi (vi) = b (vi), and we have\n\n1 [1 vi]\n\nb0 (vi) = 2 [1 vi] (vi b (vi)) > 0 for vi 2 (0; 1)\nStep 4: Solve if you can (lots of partial credit if stop here)\nNotice that\nd\n1 [1 2\nvi]\n\n(b (vi))\n=\ndv\n\n1 [1 vi]\ni\n\nb0 (vi) + 2 [1 vi] (b (vi))\nTherefore,\nd\n1 (1 2\nvi)\n\nb (vi)\n\n= 2vi (1\ndvi\nvi)\nand\n\nZ\n1 (1 vi)\nb (vi) =\n2vi (1 v )\ni dvi = 2\n\nv\ni v3\ni\n\n+ C\nso\nv2 1\n2v + C\nb (v) =\n\nv (2 v\n\n)\nTo have\n, we need\nv [1 2 v]+C\nv\n[1\nv\n2 v\nlimb ( ) = 0\n0 = lim\n= lim\n3 ] + lim\nC\n= 0 + lim\nC\n!\n!\nv(2v)\n!\n(2v)\nv\nv\nv\nv\nv!\n(2\nv)\nv! v(2\nv), which\nimplies that C = 0.\nTherefore,\n2 (3\nb (v) = v\n2v)\n3 (4 2v)\nv\nand the bidders shade their bids.\nProblem 4, Final 2010\nStage game: a 2 [0; 1], b 2 [0; 1], uA (a; b) = 2b a, uB (a; b) = 2a b.\na) Clear that the best response functions are aA (b) = 0, bB (a) = 0, since uA and uB are decreasing in\nown strategy. Moreover, clear that any strategy a^ > 0 is strictly dominated by 0, since\nuA (0; b) uA (a;^ b) = a^ > 0\nHence, all strategies besides 0 are strictly dominated and deleted in the ...rst round. Therefore, the only\nrationalizable strategies are f0g for each player. The only NE of the stage game is therefore (a; b) = (0; 0)\nb) The worst punishment is the minmax payo¤, which is also the Nash equilibrium in this stage game.\nConsider the following strategy pro...le: play (a; b) until someone deviates, and play (0; 0) if anyone ever\ndeviates. Then, the single deviation test requires that for every history without a deviation, we have\nfor A: 2b 2ba ()\n\n2b\n\nB 2a\n2a\nb\n2a\n\nb\n\n, and for\n:\n\n()\n\n1 .\n\nSu\nppos\ne that a b. Then, if 2b\n\n0, it must be the case that 2a\n\nb\n\n>\n2b\n\n0. So therefore, only\n\none\n\nof the conditions can be binding.\n\nIn particular, the frontier of (a; b) that is sustainable with discount factor is given by\nmin (a; b)\nmax (a; b)\nIt is clear that if < 0:5, this inequality cannot hold for max (a; b) > 0 because\n1 max (a ;\nb) >\nmax (a; b) min (a; b), since 2 < 1.\nHence, for < 0:5, the only sustainable candidate pro...le is\n(a; b) = (0; 0). For 0:5, the sustainable cooperation contributions (a; b) must satisfy\n\nb\n1 a; a > b\n2a b; b > a\nThe region of sustainable contributions looks like a \"kite\" with vertices at (0; 0) ;\n1; 1\n;\n1 ; 1\nand\n(1; 1). Therefore, the maximum contribution for 0:5 from any given player is equal to unity. As grows,\nthe contribution pattern can become more and more unequal, with the limit being\n1;\n\n2 , with the payo¤\nfor the higher contributor approaching zero.\nc)Since play in the stage game has no impact on the continuation value, it must\nbe an\n\nNE, so we must\nhave\n^\na;^ b\n= (0; 0).\nWe now look for values of (aA; bA) and (aB; bB) such that the following is an equilibrium: A accepts any\nproposal (a; b) such that 2ba\n2bBaB\nand B\n\naccepts any proposal (a; b) such that 2ab\n2aAbA , A\nproposes (aA; bA) and B proposes (aB; bB). Suppose there exists an SPE of this form, and Alice has been\nmade an o¤er (a; b). Then, next period, Alice will o¤er (aA; bA) and Bob will (barely) accept, so Alice will\naccept (a; b) i¤ 2ba 2bA\n\naA\n\n. Hence, it must be the case that\n(2bB aB) = (2bA aA)\nSimilarly, for Bob, it must be the case that\n(2aA bA) = (2aB bB)\nIf Alice is proposing, it is obvious that she will not propose (a; b) such that 2ab < 2aA\nbA\n, because her\npayo¤ from rejection is 2bBaB < 2bB\naB < 2bA\naA\n\n. However, she would want to propose (a; b) such that\n2a\nb\n= 2aA\nb\n\nbA\n\nand to maximize\na\ne\n. Hence, Alic would solve\nmax (2b a) st. 2a b = 2aA bA, b 2 [0; 1] ; a\na;b\n2 [0; 1]\nNow, we then have that b = 2a (2aA bA), so the problem becomes\nmax (3a\n2 (2aA\nbA)) st. 2a\n(2aA\nbA)\n[0; 1] ; a\n[0; 1]\na;b\nIt is clear that Alice will have a corner solution. Setting a = 1 cannot be optimal for Alice. Neither\ncan Alice set a = 0, since then, b would have to be negative. Finally, it is obvious that we cannot have\n2a (2aA bA) = 0, since then we would require bA = 0, which implies aA = 0, which is clearly ine¢ cient.\nTherefore, Alice will set b = 2a (2aA bA) = 1, so\nbA = 1\nBy symmetry, it must be the case that aB = 1. Hence, the acceptance conditions reduce to:\n(2bB 1) = (2 aA)\nand\n\n(2aA 1) = (2 bB)\nBy symmetry, it must be the case that aA = bB =: x, so we have the single equation\n2 + 1\n2x 1 = (2 x) ) x () = 2 +\nNote that x () is increasing in from x (0) = 1 to x (1) = 1\n.\nTherefore, the pro...le in which A o¤ers (aA; bA) = (x () ; 1), B o¤ers (aB; bB) = (1; x ()), and they\naccept only o¤ers yielding them at least U (aB; bB) and U (aA; bA) respectively is an SPE. We can check\nsingle deviation at acceptance and proposal nodes (the checks are identical for A and B), but we constructed\nthe SPE assuming these checks hold.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Exam",
      "title": "2007 Final Exam",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/4dc8aeabea7ca68343e27a83ff40b84d_MIT14_12F12_Final_07_sol.pdf",
      "content": "14.12 Game Theory -- Final (Answers)\n12/21/2007\nProf. Muhamet Yildiz\nInstructions. This is an open book exam; you can use any written material. You have two\nhour and 50 minutes. Each question is 25 points. Good luck!\n1. There are two siblings, who have inherited a factory from their parents. The value of\nthe factory is for sibling , where (12) are independently and uniformly distributed\nover [01], and each of them knows his or her own value. Simultaneously, each bids\n, and the highest bidder wins the factory and pays his own bid to the other sibling.\n(If the bids are equal, the winner is determined by a coin toss.) Note that if wins,\ngets -and gets .\n(a) (5 points) Write this as a Bayesian game.\nAnswer: = {12}; = [01]; the CDF is (|) = ; = [0inf);\n(1212) =\n1⁄2 -\nif\n\notherwise\n(b) (10 points) Compute a symmetric, linear Bayesian Nash equilibrium.\nAnswer: See Part c.\n(c) (10 points) Find all symmetric Bayesian Nash equilibrium in strictly increasing\nand differentiable strategies.\nAnswer: We are looking for an equilibrium in which each type bids () for\nsome increasing differentiable function. The expected payofffrom bidding for\na type is\n(|) = (-) -1 () +\nZ\n()\n-1()\nHence, the first-order condition for the best response is\n--1 () + (\n-) 0 ¡\n-()\n¢\n-0 ¡\n-()\n¢\n= 0\nThis must be satisfied at = ():\n-+ (-2()) 0 () = 0\nThat is,\n= 0 () + 2()\nThe unique solution to this differential equation is\n() = 3\n(This is of course also the unique linear symmetric BNE.)\n\n2. Find a perfect Bayesian Nash equilibrium of the following game:\nA\nC\n1/1/33 B\n1/1/33\n1/3\n1/3\nL1\nL1\nR1\nR1\nL2\nL2\nL3\nL3\nR2\nR2\nR3\nR3\na\nb\na\nb\na\nb\nl\nr\nl\nl\nr\nr\n3. Alice and Bob are bargaining using alternating offers, Alice making offers at =\n024and Bob making offers at = 135.\nThe set of consumption pairs\ndepends on the date. When Alice makes an offer, the set of possible consumption\npairs is = {() : + ≤1} where 1 0 and and are the\nconsumptions of Alice and Bob, respectively. When Bob makes an offer that set is\n= {() : + ≤1}. At each date , proposer offers a pair () of cosumption\nfrom the available set\n¡\nat , a¢nd the responder either accepts the offer, ending the game\nwith payoffvector , or rejects the offer, in which case we proceed to the next\ndate. If they never agree, each gets 0.\n(a) (20 points) Find a subgame perfect equilibrium of this game.\nAnswer: We are looking for a SPE in which Alice always offers () and Bob\nalways offers (), and these offers are accepted. Given that he will get\nin the next period, Bob must accept an offer () iff≥. Therefore, Alice\nmust offer the best pair () ∈for Alice with ≥. That is,\n+\n=\n(1)\n\n=\n\n(2)\nSimilarly, Alice accepts () iff≥and Bob offers () with\n+\n=\n(3)\n\n=\n\n(4)\n(If you came up here, you will get 15.) We need to solve these equation system.\nBy substituing (2) and (4) in (4), we obtain\n2+ =\n\nTogether with (1), this yields\n\n=\n-\n-2\n(1\n\n=\n=\n-)\n-2\n\n=\n1 -=\n-\n-2\n(\n\n=\n=\n-)\n-2\n(b) (5 points) What happens as →1? Briefly interpret.\nAnswer: Clearly, and converge to ∗= (1 -) (-), and and\nconverge to ∗= (-1) (-). We could find this limit without solving the\nequations. At = 1, the equations (2) and (4) become = and = .\nThat is, the soluition converge to the intersection (∗∗) of the boundaries of\nand . In usual bargaining, the shares converge to equal splitting, and this is\ninterpreted as fairness of the outcome. This example shows that the conclusion\nis fragile. Take = 1 + and = 1 -where →0. Then the available\nsets are approximately as in the original model. But the limit solution is now\n∗= (+ 1) and ∗= 1(+ 1), i.e. depending on it can be anywhere on\nthe boundary.\n4. There is a seller, who can produce a consumption good. There is also a buyer who\nwould get\n() =\n(2\n-) -\nif he buys units of good at price , where ∈[01]. There are periods: 0, 1, 2,\n. . . , -1. Buyer can trade at only one period. If he buys units at period for price\n, then his utility is () and the seller utility is where ∈(01) is known.\nIn each period , Seller sets a price , and if he has not traded yet, the buyer decides\nwhether to buy. If he decides to buy, then he also decides how much to buy, , and\nthe game ends. Otherwise, we proceed to next period. If they do not trade at any\nperiod, there will be no trade and each gets 0.\n(a) (5 points) Assuming is commonly known, for = 2, apply backward induction\nto find a subgame-perfect equilibrium.\n(b) (5 points) Assuming is commonly known, for arbitrary , apply backward in-\nduction to find a subgame-perfect equilibrium.\nAnswer: Since the game ends when the consumer buys, he buys the optimal\nquantity for him i.e. max(). Compute that the optimal quantity is () =\n-, and the buyer's payoffis (-)2 2. Note that if the buyer demands (),\nthen the optimal price is ∗= 2. The following is the outcome of backward\ninduction. In the last period, the buyer buys at every price and buys ()\namount, and the seller offers price ∗= 2. At -1, the buyer rejects the prices\nwith (-)2 24, i.e., ≡\n√\n-\n2. Clearly, At any price ≤ , the\n\nbuyer accepts the price and buy (). Since\n\n∗, the seller offers ∗at -1\ntoo. The behavior at any ≤is as in the period -1.\n(c) (15 points) Take = 2. Assume that seller does not know , i.e., is private\ninformation of the buyer, uniformly distributed on [01]. Find a strategy of the\nbuyer that is played in a perfect Bayesian Nash equilibrium. (Hint: There exist\nfunctions 0 (0), 1 (1), and a cutoff0 (0), such that given 0 the types\n≥0 (0) buy 0 (0) units at = 0 and the other types wait for period 1,\nwhen each type buys 1 (1) units if he has not traded yet.)\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2007 Midterm 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/0049859501ea2fa71af67ff1bf9cbafb_MIT14_12F12_mid071.pdf",
      "content": "14.12 Game Theory -- Midterm I\n10/18/2007\nProf. Muhamet Yildiz\nInstructions. This is an open book exam; you can use any written material. You have one\nhour and 20 minutes. You need to show your work when it is needed. Good luck!\n1. Consider the following game.\ny\nx\nR\nC\nM\nL\nB\nA\nR\nM\nL\n(a) (10 pts) Write this game in normal form.\n(b) (10 pts) Compute the set of all rationalizable strategies.\n(c) (10 pts) Find all pure strategy Nash Equilibria.\n(d) (10 pts) Compute a mixed strategy Nash equilibrium.\n2. Consider the Cournot duopoly with linear demand function P = 1 - Q, where P is the\nprice and Q = q1 + q2 is the total supply.1 Firm 1 has zero marginal cost. Firm 2 has\nmarginal cost c (q2) = q2, so that the total cost of producing q2 is q2\n2/2.\n(a) (10 points) Compute all the Nash equilibria.\n(b) (15 points) Compute the set of all rationalizable strategies. Explain your steps.\n3. (35 points) [Read the bonus note at the end before you answer the question.]\nThis question is about arbitration, a common dispute resolution method in the US.\nWe have a Worker, an Employer, and an Arbitrator. They want to set the wage w. If\nthey determine the wage w at date t, the payoffs of the Worker, the Employer and the\nArbitrator will be δt w, δt (1 - w) and w (1 - w), respectively, where δ ∈ (0, 1). The\ntimeline is as follows:\n1Recall that in Cournot duopoly Firms 1 and 2 simultaneously produce q1 and q2, and they sell at price\nP .\n\n- At t = 0,\n-- the Worker offers a wage w0;\n-- the Employer accepts or rejects the offer;\n-- if she accepts the offer, then the wage is set at w0 and the game ends; otherwise\nwe proceed to the next date;\n- at t = 1,\n-- the Employer offers a wage w1;\n-- the Worker accepts or rejects the offer;\n-- if he accepts the offer, then the wage is set at w1 and the game ends; otherwise\nwe proceed to the next date;\n- at t = 2, the Arbitrator sets a wage w2 ∈ [0, 1] and the game ends.\nCompute an equilibrium of this game using backward induction.\nBonus: If you solve the following variation instead, then you will get extra 10 points\n(45 points instead of 35 points). Final Offer Arbitration: At t = 2, the Arbitrator sets\na wage w2 ∈ {w0, w1}, i.e., the Arbitrator has to choose one of the offers made by the\nparties.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2007 Midterm 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/b6f5664c3935d959e94382068a0f8c9d_MIT14_12F12_midt2_2007.pdf",
      "content": "14.12 Game Theory -- Midterm II\n11/15/2007\nProf. Muhamet Yildiz\nInstructions. This is an open book exam; you can use any written material. You have one hour\nand 20 minutes. Each question is 25 points. Good luck!\n1. Compute all the subgameperfect equilibria in pure strategies for the following game:\nL\nM\nR\nl\nr\na\nb\na\nb\n-1\nx\ny\nx\ny\nL\nM\nR\nl\nr\na\nb\na b\n-1\nx\ny\nx\ny\n-1\nANSWER:\nFirst, notice that the game has two subgames: a proper subgame originated when player 1\nplays L, and the whole game itself.\nSince we are looking for SPEs, we need to make sure that the equilibria we find are NE of\nevery subgame. So then, lets restrict our search to NE of the proper subgame first. This game\ncan be represented by\nl\nr\nx\n(2,1)\n(1,1)\ny (1,10) (0,0)\nwhere the underlined values are best responses. Then, we can see that the only NE of this\nsubgame is (x,r):\n\nFigure 1:\nHaving solved for the NE of this subgame, the game reduces to the\nsecond figure above.\nThis game is represented by\na\nb\nL\n(1,1)\n(1,1)\nM (0,2)\n(0,1)\nR\n(2,0) (0,1)\nwhere again the BR are underlined. We can see that this game has 2 NE, which are the SPE\nwe are looking for. They can be written as (Lx,br), and (Rx, ar).\n2 Consider the infinitely repeated game with the following stage game:\nChicken Lion\nChicken\nLion\n3,3\n1,4\n4,1\n0,0\nAll the previous actions are observed, and each player maximizes the discounted sum of his\nstage payoff with discount factor δ = 0.99. For each strategy profile below check if it is a\nsubgameperfect equilibrium. (You need to state your arguments clearly; you will not get\nany points for Yes or No answers.)\n(a) (10 points) There are two modes: Cooperation and Fight. The game starts in the\nCooperation mode. In Cooperation mode, each player plays Chicken. If both players\nplay Chicken, then they remain in the Cooperation mode; otherwise they go to the\nFight mode in the next period. In the Fight mode, both play Lion, and they go back\nto the Cooperation mode in the following period (regardless of the actions).\n\nANSWER:\nIt is not SPE because in the fight mode each player has an incentive to deviate. In the\nfight mode, according to the strategy profile both players play Lion and get 0 and then\ngo back to the cooperation mode where they both get 3 forever. This yields present\nvalue of 0 + 3δ/(1 - δ) to each player. If a player deviates in the fight mode and plays\nchicken, his payoff is 1 in period t and then they will still go back to the cooperation\nin period t+1 and obtain 3 forever. This yields a higher present value of 1 + 3/(1 - δ).\nb) (15 points) There are three modes: Cooperation, P1 and P2. The game starts in the\nCooperation mode. In the Cooperation mode, each player plays Chicken. If they play (Chicken,\nChicken) or (Lion, Lion), then they remain in the Cooperation mode in the next period. If player i\nplays Lion while the other player plays Chicken, then in the next period they go to Pi mode. In Pi\nmode player i plays Chicken while the other player plays Lion; they then go back to Cooperation\nmode (regardless of the actions).\nANSWER: We use the singledeviation principle to check if this is a SPE. In the cooperation\nmode according to the strategy profile both players will always play Chicken. This yields present\nvalue of 3/(1-δ) to each player. If player i deviates in period t and plays Lion, his payoff increases\nto 4 in that period. In period t + 1, according to the strategy profile they go to Pi mode. In\nPi mode player i plays Chicken while the other player plays Lion. Then in the next period they\ngo back to the Cooperation mode. This yields a present value of 4 + 1δ + 3δ2/(1 - δ). Players\ndon't want to deviate if 3/(1 - δ) > 4 + 1δ + 3δ2/(1 - δ) ⇔ δ > 1/2.Since P1 and P2 modes are\nsymmetrical we only have to verify for one of these modes. In mode P1 player 1 plays Chicken\nwhile the other player plays Lion. This is a NE of the stage game. Since in the next period they\ngo back to the Cooperation mode regardless of the actions, neither player wants to deviate. If\nplayer 1 does not deviate his present payoff is 1 + 3δ/(1 - δ). If he deviates and plays Lion his\npresent payoff is 0 + 3δ/(1 - δ). Hence, player 1 does not want to deviate. We can easily see that\nplayer 2 also does not want to deviate in the P1 mode. If he plays Lion his present value payoff\nis 4 + 3δ/(1 - δ), while if he deviates and plays chicken his present value payoff is 3 + 3δ/(1 - δ).\n3) Consider the infinitely repeated game with the following stage game (Linear Bertrand\nduopoly). Simultaneously, Firms 1 and 2 choose prices p1 ∈ [0, 1] and p2 ∈ [0, 1], respectively.\nFirm i sells\n⎧\n1 - pi\nif pi < pj\n⎨\nqi (p1, p2) =\n(1 - pi) /2 if pi = pj\n⎩\nif pi > pj\nunits at price pi, obtaining the stage payoff of piqi (p1, p2). (All the previous prices are observed,\nand each player maximizes the discounted sum of his stage payoffs with discount factor δ ∈ (0, 1).)\nFor each strategy profile below, find the range of parameters under which the strategy profile is a\nsubgameperfect equilibrium.\na) (10 points) They both charge pi = 1/2 until somebody deviates; they both charge 0 there\nafter. (You need to find the range of δ.)\nANSWER: If nobody has deviated before:\nPayoff to not deviate: 1/8, 1/8, ...⇒ 1/8(1 - δ)\nPayoff to deviate: Notice that the only profitable deviation occurs by undercutting the price\nand the most profitable undercutting is just to charge infinitesmall less than your competition.\nYou will get something very close to 1/4 by doing this so 1/4,0,0,0,...⇒ 1/4\n\nSo we need 1/8(1 - δ) > 1/4 ⇒ 1\n2 > 1 - δ ⇒ δ > 1\nWe don't get any meaningful restrictions from the histories with previous deviations.\nb) (15 points) There are n + 1 modes: Collusion, the first day of war (W1), the second day\nof war (W2), ..., and the nth day of war (Wn). The game starts in the Collusion mode. They\nboth charge pi = 1/2 in the Collusion mode and pi = p ∗ in the war modes (W1,. . . , Wn), where\np ∗ < 1/2. If both players charge what they are supposed to charge, then the Collusion mode leads\nto the Collusion mode, W1 leads to W2, W2 leads to W3, . . . , Wn-1 leads to Wn, and Wn leads\nto the Collusion mode. If any firm deviates from what it is supposed to charge at any mode,\nthen they go to W1. (Every deviation takes us to the first day of a new war.) (You need to find\ninequalities with δ, p ∗, and n.)\nANSWER: If nobody has ever deviated before:\nPayoff to not to deviate: 1/8 ,1/8, 1/8,...⇒ 1/8(1 - δ)\nPayoff to deviate: 1/4, p*(1p*)/2, p*(1p*)/2,...,p*(1p*)/2,1/8, 1/8,...\nδn+1\np ∗(1-p ∗)δ(1-δn)\n⇒\n+\n+\n2(1-δ)\n8(1-δ)\nδn+1\np ∗(1-p ∗)δ(1-δn)\nso one condition we have:\n>\n+\n+\n8(1-δ)\n2(1-δ)\n8(1-δ)\nIf we are in a war mode: Notice that we don't have to check for all the war modes. Because\nthe lowest cost of deviattion happens in the first war mode (W1) and the benefit of deviation in a\nwar mode is always the same.\nPayoff to not to deviate: p*(1p*)/2, p*(1p*)/2,...,p*(1p*)/2,1/8, 1/8,...\np ∗(1-p ∗)(1-δn)\nδn\n⇒\n+\n2(1-δ)\n8(1-δ)\nPayoff to deviate: The most profitable deviation is once again to undercut your opponent by\nan infinitesmall amount. This will result in a payoff that is approximately:p ∗(1 - p ∗)\np*(1p*),p*(1p*)/2, p*(1p*)/2,...,p*(1p*)/2,1/8, 1/8,...\n∗(1-p ∗)δ(1-δn)\n⇒ p ∗(1 - p ∗) + p\n+ δn+1\n2(1-δ)\n8(1-δ)\nSo our second condition is:\np ∗(1-p ∗)(1-δn)\nδn\n∗(1-p ∗)δ(1-δn)\n+\n> p ∗(1 - p ∗) + p\n+ δn+1\n2(1-δ)\n8(1-δ)\n2(1-δ)\n8(1-δ)\n4 The players in the following game are Alice, who is an MIT senior looking for a job, and\nGoogle. She has also received a wage offer r from Yahoo, but we do not consider Yahoo\nas a player. Alice and Google are negotiating. They use alternating offer bargaining, Alice\noffering at even dates t = 0, 2, 4, . . . and Google offering at odd dates t = 1, 3, . . .. When\nAlice makes an offer w, Google either accepts the offer, by hiring Alice at wage w and ending\nthe bargaining, or rejects the offer and the negotiation continues. When Google makes an\noffer w, Alice\n- either accepts the offer w and starts working for Google for wage w, ending the game,\n- or rejects the offer w and takes Yahoo's offer r, working for Yahoo for wage r and ending\nthe game,\n- or rejects the offer w and then the negotiation continues.\nIf the game continues to date t ≤inf, then the game ends with zero payoffs for both players.\nIf Alice takes Yahoo's offer at t < t , then the payoff of Alice is rδt and the payoff of Google\nis 0, where δ ∈ (0, 1). If Alice starts working for Google at t < t for wage w, then Alice's\npayoff is wδt and Google's payoff is (π - w) δt, where\nπ/2 < r < π.\n(Note that she cannot work for both Yahoo and Google.)\n\n(a) (10 points) Compute the subgame perfect equilibrium for t = 4. (There are four rounds\nof bargaining.)\nANSWER:\n- (2.5pts) Consider t = 3. Alice will get w if she accepts Google, r if she accepts\nYahoo, and 0 if she rejects and continues. Thus, she must choose\nGoogle\nif w ≥ r\nsA,3 =\nY ahoo otherwise.\nGiven this, Google gets 0 if w < r and π - w if w ≥ r. Therefore, it must choose\nw3 = r.\n- (2.5pts) Consider t = 2. Google will get π - w if it accepts an offer w by Alice and\nπ - w3 next day if it rejects the offer. Hence Google must\nAccept iff (π - w) ≥ δ (π - w3) i.e. w ≤ π (1 - δ) + δr.\nThe best reply for Alice is to offer\nw2 = π (1 - δ) + δr.\n- (2.5pts) [This is the most important step. Disturbingly, the majority of\nthe students failed at this step.] Consider t = 1. Consider Alice's decision.\nAlice will get w if she accepts Google, r if she accepts Yahoo, and δw2 if she rejects\nand continues. We nned to check whether she prefers Yahoo's offer to continuing.\nNote that\nπδ (1 - δ)\nπδ\nr > δw2 = πδ (1 - δ) + δ2 r ⇐⇒ r >\n=\n.\n1 - δ2\n1 + δ\nSince r > π/2 > πδ , this implies that r > δw2. That is, Alice prefers Yahoo's offer\n1+δ\nto continuing, and hence she will never reject and continue. Therefore, she must\nchoose\n\nGoogle\nif w ≥ r\nsA,1 = sA,3 =\nY ahoo otherwise.\nGoogle then must offer w1 = r.\n- (2.5 pts) Consider t = 0. It must be obvious now that it is the same as t = 2.\nGoogle Accepts iff w ≤ w2 and Alice offers\nw0 = w2 = π (1 - δ) + δr.\n(b) (15 points) Take t = inf. Conjecture a subgameperfect equilibrium and check that the\nconjectured strategy profile is indeed a subgameperfect equilibrium.\nANSWER:\nFrom part (a), it is easy to conjecture that the following is a SPE:\ns ∗ : At an odd date Alice accepts an offer w iff w ≥ r, otherwise she takes Yahoo's\noffer. Google offers wG = r. At an even date Alice offers wA = π (1 - δ) + δ, and\nGoogle accepts an offer w iff w ≤ wA.\n\nWe use singledeviation principle to check that s ∗ is indeed a SPE. There are 4 major\ncases two check:\n- Consider the case Alice is offered w.\n-- Suppose that w ≥ wG ≡ r. Alice is supposed to accept and receive w today.\nIf she deviates by rejecting w and taking Yahoo's offer, she will get r, which\nis not better that w. If she deviates by rejecting and continuing, she will\noffer wA at the next day, which will be accepted. The present value of this is\nδwA = πδ (1 - δ) + δ2r < r ≤ w, i.e. this deviation yields even a lower payoff.\n-- Suppose that w < wG ≡ r. Alice is supposed to reject it and take Yahoo's\noffer with payoff r. If she deviates accepting w, she will get the lower payoff of\nw < r. If she deviates by rejecting and continuing, she will get wA next day,\nwith a lower present value of δwA = πδ (1 - δ) + δ2r < r.\n- Consider a case Google offers w. If w ≥ r, it will be accepted, yielding a payoff of\nπ - w to Google. If w < r, then Alice will go to Yahoo, with payoff of 0 to Google.\nTherefore, the best response is to offer w = r > 0, as in s ∗ . There is no profitable\n(single) deviation.\n- Consider the case Google is offered w.\n-- Suppose that w ≤ wA. If Google deviates and rejects, it will pay δ tomorrow\nwith payoff δ (π - r) = (π - wA), which is not better than π - wA.\n-- Suppose that w > wA. If Google deviates and accepts, then it will get only\nπ - w, while it would get the present value of δ (π - r) = (π - wA) by rejecting\nthe offer.\n- Consider a node in which Alice offers. Google will accept iff w ≤ wA. If she offers\nw > wA she gets r next day, with present value of δr < wA. Therefore, the best\nreply is to offer w = wA, and there is no profitable deviation.\n[In part (b) most important cases are the acceptance/rejection cases, especially that of\nAlice. Many of you skipped those cases, and wrongly concluded that a nonSPE profile\nis a SPE.]\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2008 Midterm 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/4258cac2abaeda798e42a2fcc44d4d52_MIT14_12F12_midterm1_2008.pdf",
      "content": "14.12 Game Theory\n10/16/2008\nProf. Casey Rothschild\nInstructions. This is an open book exam; you can use any written material. You may use a\ncalculator. You may not use a computer or any electronic device with wireless communication\ncapacity. You have one hour and 20 minutes. Each question is 25 points, and the breakdown\nof points within each question is specified below. Good luck!\n1. A normal form Game is depicted below. Player 1 chooses the row (T or B), Player 2\nchooses the column (L,M, or R), and Player 3 chooses the matrix (W,X,Y, or Z).\nW\nX\nL\nM\nR\nL\nM\nR\n1,1,10\n\nT\n1,0,10\n\n5,-5,0\n0,1,10\n\nB\n0,0,-10\n\n5,-5,0\nB\n1,1,-10\n\nT\n1,0,10\n\n5,-5,0\n0,0,10\n\n5,-5,0\n0,1,10\n\nL\nM\nR\nL\nM\nR\n20,15,2\nT\n12,20,2\n5,-5,40\n16,20,2\nB\n20,15,2\n5,-5,40\n8,8,-20\n\nT\n8,8,-20\n\n5,40,-20\n\n8,8,-20\n\nB\n8,8,-20\n\n5,40,-20\n\nY\nZ\n(a) (5 points) Write a strategic form game tree for this game, and indicate the payoffs\non any two terminal nodes of your choice. You don't need to write the payoffs at\nany other terminal nodes.\n(b) (5 points) Find all pure strategy Nash Equilibria for this game.\n(c) (5 points) Find a mixed strategy equilibrium of the two-player game (between\nPlayers 1 and 2) that results if Player 3 is forced to play Y.\n(d) (10 points) Find all of the rationalizable strategies in the full 3 player game.\nShow your reasoning.\n\n2. \"Quickies\" Part (a) Required. CHOOSE 1 or (b) or (c).\n(a) (REQUIRED; 15 points) If Bob, Sue and Mary are rational voters with strict\npreferences given in the table to the right, with top being better, and all this is\ncommon knowledge, what outcome do you expect the binary agenda at left to\nproduce?\nBo\nb\nSu\ne\nMa\ny\nx2\nx1\nx1\nx0\nx2\nx3\nx0\nx3\nx0\nx2\nX1\nX0\nX3\nX3\nX2\nX0\nX2\nX1\nX1\nX0\nX3\nX2\nStrictly Worse\n(b) (CHOOSE (b) OR (c);10 points) What, if anything, is wrong with the following\npattern of choices? (If you don't have a calulator and want to know: 5/6 = 0.83.)\n- Choice 1: 0.5[$100] + 0.5[$0] = p A q = 0.6[$80] + 0.4[$0].\n- Choice 2: 1[$80] = r A s = (5/6)[$100] + (1/6)[$0].(10 points)\n(c) (If you already answered (b) don't do this -- we won't grade it!) Consider\na Judicial Settlement problem:\n- At each date t = 1, 2, ...n the Plaintiff makes a settlement offer st. The\nDefendent can either accept or reject each offer. (Note that the same player\nis making offers each period.)\n- If the Plaintiff accepts at date t, the \"game\" ends with the Defendent paying\nst to the Plaintiff, and the Defendent and Plaintiff paying tcD and tcP to their\nrespective lawyers.\n- If the Plaintiff rejects at all dates, the case goes to court. The Plaintiff will\nlose and have to pay J to the Defendent. The Plaintif and Defendent will\nalso have to pay lawyer's fees (n + 1)cP and (n + 1)cD respectively.\nIf it is common knowledge that Plaintiff and Defendent are sequentially rational,\nhow much will the settlement be, and at what date will it take place? (You don't\nhave to show the backward induction reasoning explicitly. Just give the answer\nand 1 or two sentences of intuition.)\n\n3. In this question you are asked to compute the rationalizable strategies in a linear\nBertrand-duopoly with discrete prices and fixed \"startup\" costs. We consider a world\nwhere the prices must be an odd multiple of 10 cents, i.e.,\nP = {0.1, 0.3, 0.5, ..., 0.1 + 0.2n, ...}\nis the set of feasible prices. For each price p, the demand is:\nQ(p) = max{1 - p, 0}.\nWe have two firms N = {1, 2}, each with 0 marginal cost, but each with a fixed \"start\nup\" cost k. That is, if the firm produces a positive amount, it must bear the cost k. If\nit produces 0, it does not have to pay k. Simultaneously, each firm sets a price pi ∈ P .\nObserving prices p1 and p2, consumers buy from the firm with the lowest price. When\nprices are equal, they divide the demand equally between the two firms. Each firm i\nwishes to maximize its profit.\n⎧\n⎨\n⎩\n⎫\n⎬\n⎭\npiQ(pi) - k\nif pi < pj and Q(pi) > 0\n= pj and Q(pi) > 0\nπi(p1, p2) = piQ(pi)/2 - k\notherwise\n\npi\n.\n(a) If k = 0.1 :\n1. (5 points) Show that pi = 0.1 is strictly dominated.\n2. (5 points) Show that there are prices greater than the monopoly price (p =\n0.5) that are not strictly dominated.\n3. (15 points) Iteratively eliminate all strictly dominated strategies to find the\nset of rationalizable strategies. Explain your reasoning.\n\n4. There are three \"dates\", t = 1, 2, 3, and two players: Government and Worker.\n- At t = 1, Worker expends effort to build K ∈ [0, inf) units of capital.\n- At t = 2, Government sets tax rates τ K ∈ [0, 1] and τ e ∈ [0, 1] on capital-holdings\nand on labor income.\n- At t = 3, Worker chooses effort e2 ∈ [0, inf) to produce output Ke2.\nThe payoffs of Government and Worker are:\nUG = τ K K + τ eKe2\nand\nUW = (1 - τ e)Ke2 + (1 - τ K )K - K2/2 - e2\n2/2.\n(a) (20 points) Solve the game by backwards induction.\n(b) (5 points) Now suppose before the game is played, Government can \"delegate\"\nits job to an independent IRS Agent at period t = 0. At t = 0, the Government\nwill offer a fraction βK ∈ [0, 1] of its capital tax revenue and a fraction βe ∈ [0, 1]\nof its labor tax revenue to the Agent. The Agent can either Accept or Reject. If\nthe Agent Accepts, she will take the place of the Government in setting tax rates\nτ K ∈ [0, 1] and τ e ∈ [0, 1] at t = 2. If the Agent Rejects, the game procedes as\nbefore. The Agent has payoff:\n1⁄2\n3⁄4\nKe2 - ε if accept\nβK τ K K + βeτ e\nUA =\n,\n0 if reject.\nwhere ε is a very small but positive \"acceptance\" cost. The Government's payoff\nwill be:\n1⁄2\n3⁄4\n(1 - βK )τ K K + (1 - βe)τ eKe2 if Agent Accepts\nUG =\n.\nτ K K + τ eKe2 otherwise\nAssume that an Agent who accepts will choose the smalest tax rate(s) consis\ntent with sequential rationality. Find an equilbrium of the game using backward\ninduction, and briefly comment on it.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2008 Midterm 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/1e89f574760591b6d71eba68fc1ff1d5_MIT14_12F12_midterm1_2010.pdf",
      "content": "14.12 Game Theory -- Midterm I\n10/19/2010\nProf. Muhamet Yildiz\nInstructions. This is an open book exam; you can use any written material. You have one\nhour and 20 minutes. Each question is 25 points. Good luck!\n1. Consider the following game.\n(a) Using backward induction find an equilibrium.\nAnswer: At the last node, Player 1 chooses ; at the right node, Player 2 then\nchooses . At the left node, she chooses . Hence, at the beginning, Player 1\nchooses . The equilibrium is ( ).\n(b) Write the game in normal form.\nAnswer: The game in normal form is\n1\\2\n\n2,1 2,1 1,2 1,2\n2,1 2,1 1,2 1,2\n2,1 1,0 2,1 1,0\n2,1 0,1 2,1 0,1\n2. Compute a Nash equilibrium of the following game. (This is a version of Rock-Scissors-\nPaper with preference for Paper.)\nR\nS\nP\nR\nS\nP\n0 0\n2 -2 -2 3\n-2 2\n0 0\n2 -1\n3 1\n-1 2\n1 1\nAnswer: (Because of a typo, the question became asymmetric, making the answer\nlonger. We gave nearly full credit to the students who thought the game was symmet\nric.)\n\nThis game has a unique Nash equilibrium, which is in mixed strategies. Write , ,\nand for the probabilities with which player plays strategies R, S, and P, respectively.\nOf course,\n+ + = 1\n(1)\nNow, (222) must make Player 1 indifferent between his strategies. Indifference\nbetween R and S yields 2 (2 - 2) = 2 (2 - 2), i.e.,\n22 = 2 + 2\nSince 2 + 2 = 1 - 2 by (1), this yields\n2 = 13\nOn the other hand, the indifference between S and P yields 2 (2 - 2) = 1+2 (2 - 2).\nSubstituting 2 = 13, we obtain 42 - 22 = -13. Together with 2 + 2 = 23, this\nyields\n2 =\n2 =\nSimilarly, indifference between R and S for player 2 yields 2 (1 - 1) = 21 - 1, i.e.,\n31 = 2 (1 + 1). Since 1 + 1 = 1 - 1, this yields\n1 = 25\nThe indifference between S and P yields 2 (1 - 1) = 1+2 (1 - 1), yielding 41-21 =\n-15. Together with 1 + 1 = 35, this yields\n1 =\n1 =\n3. Ann and Bob own a small business. Ann provides the capital, denoted by ∈ [0 1]\nand Bob provides the labor, denoted by ∈ [0 1]. They equally share the revenue,\n√\nwhich is given by\n. The cost of capital for Ann is 4, and the cost of Labor for\n√\nBob is 24. In summary, the utility function of Ann and Bob are 1 - 4 and\n√\n1 - 24. Note that Ann can choose any in [0 1]; Bob can choose any in\n[0 1], and everything is common knowledge.\n(a) Compute the set of Nash equilibria in pure strategies.\nAnswer: The best response function of Ann is\n() =\n(2)\nThe best response function of Bob is\np\n() =\n3 4\n(3)\nThe Nash equilibria are the intersections of the best-response functions, i.e., =\np\np\nand = 3 4. That is, = = 3 4. Clearly, = = 0 is a solution.\nThe other solution is given by 2 = 14, i.e., = = 12. The Nash equilibria\nare (0 0) and (12 12).\n\n(b) Compute the set of rationalizable strategies.\nAnswer: Graph of the best response functions will be useful:\nLet's apply iterated dominance.\nRound 1 : Since = , each ∈ [01] is a best response to some = ∈\np\n[01], and no is eliminated. On the other hand, every (1) =\n14 is\np\n√\nstrictly dominated by 3 14. Indeed, for any ∈ [01], () ≡ 1 -\n\np\np\n24 3 14 because (0) is decreasing in 0 on [ 3 4inf) and\np\n(1) ≥\n4. Hence, all such strategies are eliminated for Bob. All the\nother strategies are a best response to some as in the figure, hence they are\nnot eliminated. The resulting set is [01] for Ann and [01] for Bob where\np\n1 = 1 and 1 =\n3 14\nRound 2 : In this round nothing is eliminated for Bob (because nothing was\neliminated for Ann in the previous round). For Ann all the strategies 1\nare eliminated because they are now strictly dominated by 1 as in the previous\nround. The resulting set is [02] for Ann and [02] for Bob where 2 = 1 and\n2 = 1\nTowards a mathematical induction, assume that at the end of Round 2, the\nresulting set is [02] for Ann and [02] for Bob where 2 = 2. Now,\nRound 2+ 1: Since = and 2 = 2, each ∈ [02] is a best\nresponse to some = ∈ [02], and no is eliminated. On the other hand,\np\np\nevery (2) = 24 is strictly dominated by\n24, as in Round\n1. All the other strategies are a best response to some , hence they are not\neliminated. The resulting set is [02+1] for Ann and [02+1] for Bob where\np\n2+1 = 2 and 2+1 =\nRound 2+ 2: In this round nothing is eliminated for Bob (because nothing was\neliminated for Ann in the previous round). For Ann all the strategies 2+1\n\nare eliminated because they are now strictly dominated by 2+1. The resulting\nset is [02+2] for Ann and [02+2] for Bob where\np\n2+2 = 2+1 and 2+2 = 2+1 =\nCombining the two equations we obtain\np\n2+2 = 2+2 =\nWith the initial condition 0 = 0 = 1, this decreasing sequence converges to\n(infinf) where inf = inf is the largest solution to\np\ninf =\n3 inf4\nThat is,\ninf = inf = 12\nThe rationalizable strategies are [012] and [012] for Ann and Bob, respectively.\n4. In a family, there are 3 sisters, named Alice, Beatrice, and Caroline. They have a\nbig piece of cake, whose size we normalize to 1. Alice divides the cake into 3 pieces,\nwhich can be of different sizes. Next, Beatrice picks one of the pieces for herself. Next,\nCaroline picks one of the remaining two pieces. Alice picks the last piece. Each sister's\npayoff is the size of the cake she gets.\n(a) Using backward induction, compute an equilibrium of this game.\nAnswer: Given the remaining two pieces, Caroline chooses the larger one, leaving\nthe smaller one to Alice. When Beatrice's turn, she chooses the largest of the\nthree pieces. Therefore, given any division (123), Beatrice gets the largest,\nCaroline gets the middle one, and Alice gets the smallest i.e. min (123).\nTherefore, in dividing the cake Alice must\nmax\nmin (123)\n(123)\n1+2+3=1\nThe unique solution is (131313).\n(b) Repeat (a) assuming instead that Beatrice picks a piece for Alice; Caroline picks\na piece for Beatrice, and the remaining piece is given to Caroline.\nAnswer: There are multiple solutions. The first solution is as follows. Given the\nremaining two pieces, Caroline gives the smaller to Beatrice, keeping the larger one\nfor herself. Given the three pieces, Beatrice will get the smaller of the remaining\ntwo. Hence, it is a best response to Beatrice to give Alice the smallest of the\nthree. Therefore, once again Alice receives the smallest of the three pieces, and\ntherefore she divides the cake equally (131313).\nThere is also a continuum of other equilibria. To see this, note that when 1\n2 = 3, Beatrice has multiple best responses. She can give 3 to Alice and\nend up receiving 2 or give 3 to Alice and end up receiving 2 again. Hence,\nfor any ∈ [013], the following is also an outcome of backward induction. If\n1 2 = 3 and 2 , she gives 3 = to Alice and if 1 2 = 3 and\n2 ≥ , she gives 1 to Alice. Alice picks 1 = 1 - 2 and 2 = 3 = .\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2008 Midterm 1 solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/9f6eb790fd0326e9526cb37fc3ac51c0_MIT14_12F12_mid1sol_2008.pdf",
      "content": "14.12 Game Theory\nMIDTERM 1 SOLUTIONS\n10/16/2008\nProf. Casey Rothschild\nInstructions. This is an open book exam; you can use any written material. You may use a\ncalculator. You may not use a computer or any electronic device with wireless communication\ncapacity. You have one hour and 20 minutes. Each question is 25 points, and the breakdown\nof points within each question is specifed below. Good luck!\n1. A normal form Game is depicted below. Player 1 chooses the row (T or B), Player 2\nchooses the column (L,M, or R), and Player 3 chooses the matrix (W,X,Y, or Z).\n(a) (5 points) Write a strategic form game tree for this game, and indicate the payofs\non any two terminal nodes of your choice. You don't need to write the payofs at\nany other terminal nodes.\nAnswer. The strategic form game tree for this game is the following\n\nW\nX\nY\nZ\nL\nM\nR\nL\nM\nR\nL\nM\nR\nL\nM\nR\nB T B T B T B T B T B T B T B T B T B T B T B\n-10\n(b) (5 points) Find utilities that player 1 can get by playing each of his actions are:\nUT\n=\n20p + 12(1 - p) = 12 + 8p\nUB =\n16p + 20(1 - p) = 20 - 4p\nPlayer 1 will therefore be indiferent between his two actions if and only if\nUT\n= UB\n12 + 8p =\n20 - 4p\nwhich implies\np = 3\nNow, let's assume that player 1 plays T and B with probability a and 1 - a,\nrespectively; then player 2 will get expected utilities given by\nUL =\n15a + 20(1 - a) = 20 - 5a\nUM =\n20a + 15(1 - a) = 15 + 5a\nTherefore, player 2 will be indiferent and willing to randomize if and only if\nUL = UM\n20 - 5a = 15 + 5a\nwhich implies\na = 2\nThus, if player 3 is forced to play Y , then the only mixed strategy Nash equilibrium\n\nis given by\np(T )\n=\np(B)\n=\np(L)\n=\np(M)\n=\n(c) (10 points) Find all of the rationalizable strategies in the full 3 player game.\nShow your reasoning.\nAnswer. First of all, remember that, as we saw in problem set 1, in a three player\ngame the set of rationalizable strategies corresponds to the set that survives iter\nated elimination of strictly dominated strategies only if we allow for the possibility\nof correlated beliefs. Therefore, if you simply eliminate iteratively all the strictly\ndominated strategies without specifying that you are assuming correlated beliefs,\nyou lose some points. Alternatevely, you can leave out correlated beliefs and check\nthat all the strategies that survive iterated elimination are indeed best response\nto some rationalizable strategy.\nFirt notice that strategy Z is strictly dominated for player 3. Once we eliminate\nZ, then R for player 2 becomes strictly dominated. There are no other strictly\ndominated strategies and the algorithm stops here. Thus, if you explicitly allow\nfor correlated beliefs, the solution is (T, B) for player 1, (L, M) for player 2 and\n(W, X, Y ) for player 3. However, if you don't mention specifc assumptions about\nbeliefs, then you need to check that each of the remaining strategies is a best\nresponse to some rationalizable strategy. In particular, notice that Y is not an\noptimal response to any rationalizable strategy. To see this, let a and p be the\nprobabilities that T and L are played, respectively. Then player 3 will get utilities\nUw\n=\n10ap + 10a(1 - p) + 10p(1 - a) - 10(1 - a)(1 - p)\n=\n20a + 20p - 20pa - 10\nUx = -10ap + 10a(1 - p) + 10p(1 - a) + 10(1 - a)(1 - p)\n=\n10 - 20ap\nUy\n=\n\nNow, consider, for example, the mixed strategy p(W) = p and p(X) = 1-p. This\ngives player 3 utility\npUw + (1 - p)Ux =\n20ap + 20p - 20p a - 10p + 10 (1 - p) - 20ap(1 - p)\n=\n20ap + 20p - 20p a - 10p + 10 - 10p - 20ap + 20ap\n=\n20p - 20p + 10\nwhich is always greater than Uy = 2. Therefore, for each set of beliefs, player 3\ncan play a mixed strategy that gives him a payof higher than Y . This means that\n\nY is never a best response. Once we eliminate Y , then strategy B for player 1\nwill be strictly dominated by T . The elimination of B makes strategy M strictly\ndominated for player 2. Finally, after eliminating M, strategy X will be strictly\ndominated for player 3. The only rationalizable strategies are therefore T for\nplayer 1, L for player 2 and W for player 3. Notice that these strategies form the\nunique Nash equilibrium found in part b.\n2. \"Quickies\" Part (a) Required. CHOOSE 1 or (b) or (c).\n(a) (REQUIRED; 15 points) If Bob, Sue and May are rational voters with strict\npreferences given in the table to the right, with top being better, and all this is\ncommon knowledge, what outcome do you expect the binary agenda at left to\nproduce?\nAnswer. By assumption, Bob, Sue and May are rational voters. This means\nthat, when they vote at a particular node, they take into account what will happen\nin the following nodes. Therefore, we can solve the game by backward induction.\nLet's start from the penultimate nodes which are circled in the following picture:\n\nWhen asked to vote between Xl and Xo the voters will choose Xo (Sue and May\nprefer Xo over Xl). In the same way, Xo will be preferred over X2 and X3 over Xo.\nNow, consider the node circled in the following graph:\nwhere I have eliminated the branches that will not be chosen. If voters are rational\nthen they will understand that, if they choose X2, the fnal outcome will end up\nbeing Xo, while if they opt for X3, then the fnal outcome will indeed be X3. In\nthe node circled in the fgure, therefore, the voters will vote for X3 (Bob and May\nprefer this choice over Xo). Finally, let's consider the initial node:\nRational voters will understand that in the initial node they are not asked to\nchoose between Xl and X2, but instead between Xo and X3. Therefore, they will\nchoose X2 and the fnal outcome of the voting agenda will be X3.\n(b) (CHOOSE (b) OR (c);10 points) What, if anything, is wrong with the following\npattern of choices? (If you don't have a calculator and want to know: 5/6 = 0.83.)\n- Choice 1: 0.5[$100] + 0.5[$0] = p > q = 0.6[$80] + 0.4[$0].\n\nChoice 2: 1[$80] = r s = (5=6)[$100] + (1=6)[$0]:(10 points)\nAnswer.\nNotice that lottery p can be rewritten as 0:6[s] + 0:4[$0], while q is\nequivalent to 0:6[r] + 0:4[$0]. When transformed in this way, it is very easy to\nsee that the two choices violate the independece axiom. The reason is that, if\nthe independence axiom is true, then Choice 1 implies that s r which is the\nopposite of Choice 2.\n(c) (If you already answered (b) don't do this -we won't grade it!) Consider\na Judicial Settlement problem:\nAt each date t = 1; 2; :::n the Plainti¤ makes a settlement o¤er st. The\nDefendent can either accept or reject each o¤er. (Note that the same player\nis making o¤ers each period.)\nIf the Defendent accepts at date t, the \"game\"ends with the Defendent paying\nst to the Plainti¤, and the Defendent and Plainti¤ paying tcD and tcP to their\nrespective lawyers.\nIf the Defendent rejects at all dates, the case goes to court. The Defendent\nwill lose and have to pay J to the Plainti¤. The Plainti¤ and Defendent will\nalso have to pay lawyer's fees (n + 1)cP and (n + 1)cD respectively.\nIf it is common knowledge that Plainti¤ and Defendent are sequentially rational,\nhow much will the settlement be, and at what date will it take place? (You don't\nhave to show the backward induction reasoning explicitly. Just give the answer\nand 1 or two sentences of intuition.)\nAnswer. Under the assumption of common knowledge of sequential rationality\nof both players, we can solve the game by backward induction. In the penul-\ntimate period, t = n, the Plainti¤ will o¤er a settlement o¤er sn which makes\nthe defendent exactly indi¤erent between accepting the o¤er and rejecting it and\n\npaying J + cD in the court. In fact, any ofer smaller than Sn = J + cD will result\nin a loss for the Plaintf given that the Defendent will accept any ofer smaller or\nequal to J + cD. In the third to last period, t = n - 1, the Plaintif will again\nmake the Defendent indiferent between accepting and not accepting, that is, he\nwill ofer a settlement of Sn-l = J + 2cD. Proceeding in this way, we fnd that in\nthe initial node of the game, at time t = 1, the Plaintif will make a settlement\nofer Sl = J + ncD and the game will end with the Defendent accepting the ofer.\n\n3. In this question you are asked to compute the rationalizable strategies in a linear\nBertrandduopoly with discrete prices and fxed \"startup\" costs. We consider a world\nwhere the prices must be an odd multiple of 10 cents, i.e.,\nP = {0.1, 0.3, 0.5, ..., 0.1 + 0.2n, ...}\nis the set of feasible prices. For each price p, the demand is:\nQ(p) = max{1 - p, 0}.\nWe have two frms N = {1, 2}, each with 0 marginal cost, but each with a fxed \"start\nup\" cost k. That is, if the frm produces a positive amount, it must bear the cost k. If\nit produces 0, it does not have to pay k. Simultaneously, each frm sets a price pi E P.\nObserving prices pl and p2, consumers buy from the frm with the lowest price. When\nprices are equal, they divide the demand equally between the two frms. Each frm i\nwishes to maximize its proft.\n\nif pi < pj and Q(pi) > 0\n{\npiQ(pi) - k\n\n1i(pl, p2) =\npiQ(pi)/2 - k\npi = pj and Q(pi) > 0 } .\notherwise\n(a) If k = 0.1 :\n1. (5 points) Show that pi = 0.1 is strictly dominated.\nSOLUTION: Claim: pi = 0.1 is strictly dominated by pi = 0.5. (It is also\nstrictly dominated by every other strategy EXCEPT for pi = 0.9).\nLet us\nsee this. Suppose pi = 0.1 is played. The payofs will be:\n-0.055 when pj = 0.1\n1i(0.1, pj ) =\n-0.01\nwhen pj > 0.1\nThe payof, as can be seen, will always be strictly less than zero. Therefore,\nas long as there is some strategy that ensures a payof of at least 0 in all cases,\nit will strictly dominate playing 0.01. pi = 0.5 is one of these strategies (but\ncertainly not the only one). If 0.5 is the strictly smaller than the other players\nstrategy, it will yield a payof of 0.15, and if the other player also plays 0.5,\nthe frm will get a payof of 0.025. Finally, if the other player plays strictly\nless that 0.05, then the frm will get zero. Thus, it strictly dominates 0.1.\n(3 points credit given for showing that the payof is negative and saying that\nthis is strictly dominated by \"not participating\". To get full credit, you must\nhave pointed to a strategy (which was a price p) that strictly dominated 0.1\nand explained why).\n2. (5 points) Show that there are prices greater than the monopoly price (p =\n0.5) that are not strictly dominated.\nSOLUTION: Suppose that the other frm plays 0.1. Then, you do NOT want\nto \"win\" the price war, since playing 0.1 will yield a negative payof Playing\nanything above 0.1 will be a best response as anything strictly above will\nyield a payof of zero. Thus playing any strategy above the monopoly price\nwill be a best response to the belief that the other frm will be playing 0.1.\n(They are weakly dominated, but NOT strictly dominated).\n\n3. (15 points) Iteratively eliminate all strictly dominated strategies to ...nd the\nset of rationalizable strategies. Explain your reasoning.\nSOLUTION:\nFirst round: Eliminate 0:1 from both players strategies.\nWe know that we can eliminate 0:1 because it is strictly dominated by\n0:5 as discussed in part (i).\nSecond round: Eliminate all pi 0:9 from both players strategies. (All\nare strictly dominated by 0:3)\nLook at pi = 0:3. Note that:\n0:005\nwhen p = 0:3\ni(0:3; p\nj\nj) =\n\n0:11\nwhen pj > 0:3\nSo, once 0:1 is eliminated, 0:3 will always produce a payo¤ that is strictly\ngreater than zero. Now consider the payo¤ of playing pi = 0:9 :\n<\nwhen pj < 0:9\ni(0:9; pj) = : 0:055\nwhen pj = 0:9\n0:01\nwhen pj > 0:9\nThus, playing 0:9 will never produce a playo¤greater than zero, so it is strictly\ndominated by 0:3.. Playing pi > 0:9 will always yield a payo¤ of exactly zero,\nso will also be strictly dominated by 0:3 which always yields positive payo¤.\n(once 0:1 has been eliminated)..\nThird round:\nEliminate pi = 0:7 for both players as it is strictly domi-\nnated by 0:3.\nNow we are just left with the strategies 0:3; 0:5; 0:7. Claim: playing 0:3 will\nstrictly dominate playing 0:7. Let us look ...rst at playing 0:3:\n0:005\nwhen pj = 0:3\ni(0:3; pj) =\n<\n: 0:11\nwhen pj = 0:5\n0:11\nwhen pj = 0:7\nNow look at playing 0:7 :\nwhen pj = 0:3\ni(0:7; pj) =\n<\nwhen pj = 0:5\n0:005\nwhen pj = 0:7\nThus, it is clear that playing 0:3\n:\nstrictly dominates playing 0:7. This leaves\n0:3 and 0:5.\nFourth round: Eliminate pi = 0:5 for both players as is strictly dominated\nby 0:3.\nIf the other player plays 0:3; you get 0:005 for playing 0:3 and zero for\nplaying 0:5, and if the other player plays 0:5, you get 0:11 for playing 0:3\nand only 0:025 for playing 0:5).\nThus 0:3 is the unique rationalizable\nstrategy achieved through the iteration of strictly dominated strategies.\n\n(Only partial credit given if the eliminations were made without saying what\nstrategies were actually strictly dominating the strategies that were elimi\nnated. For example, a number of people said that 0.9 could be eliminated in\nthe frst round. This is NOT true, as it is still a best response to 0.1.)\n\n4. There are three \"dates\", t = 1, 2, 3, and two players: Government and Worker.\n- At t = 1, Worker expends efort to build K E [0, C) units of capital.\n- At t = 2, Government sets tax rates T K E [0, 1] and T e E [0, 1] on capitalholdings\nand on labor income.\n- At t = 3, Worker chooses efort e2 E [0, C) to produce output Ke2.\nThe payofs of Government and Worker are:\nUc = T KK + T eKe2\nand\nUw = (1 - T e)Ke2 + (1 - T K)K - K2/2 - e2\n2/2.\n(a) (20 points) Solve the game by backwards induction.\nSolution:\n- At t = 3, worker maximizes Uw taking everything else as given. The frst\norder conditions give:\nek\n2 = (1 - T e)K.\n(5 points)\n- At t = 2, the Government chooses T K and T e to maximize Uc, recognizing\nthat their choice of T e efects ek\n2. They thus maximize\nT KK + T eK(1 - T e)K\nThe frst order condition for T e gives\nT k\nl\n=\nif K > 0\ne\nT k\ne E [0, 1] if K = 0.\n(5 points; 1 for not noting what happens if K = 0). The frst order condition\nfor T K doesn't have a solution: UuG > 0 if K > 0. Hence,\nUT K\nT k = 1 if K > 0\n\nT k\nE [0, 1] if K = 0.\n(5 points).\n- At t = 1, the worker chooses K to maximize Uw , recognizing that his choice\nwill efect the tax rates and his future efort e2. Plugging in the solutions from\nt = 2, 3 for K > 0 gives:\n\nUw\n=\n(1 -\n)K(1 -\n)K + (1 - 1)K - K2/2 -\n(1 -\n)K\n/2\nK2\nK2\nK2\n=\n-\n= -\n.\nHence, the Uw is maximized at K = 0. (5 points.)\n\n(b) (5 points) Now suppose before the game is played, Government can \"delegate\"\nits job to an independent IRS Agent at period t = 0. At t = 0, the Government\nwill o¤er a fraction K 2 [0; 1] of its capital tax revenue and a fraction e 2 [0; 1]\nof its labor tax revenue to the Agent. The Agent can either Accept or Reject. If\nthe Agent Accepts, she will take the place of the Government in setting tax rates\nK 2 [0; 1] and e 2 [0; 1] at t = 2: If the Agent Rejects, the game procedes as\nbefore. The Agent has payo¤:\nK KK + e eKe2 \" if accept\nUA =\n,\n0 if reject.\n\nwhere \" is a very small but positive \"acceptance\"cost. The Government's payo¤\nwill be:\n(1 K) KK + (1 e) eKe2 if Agent Accepts\nUG =\nKK + eKe2 otherwise\n\n:\nAssume that an Agent who accepts will choose the smalest tax rate(s) consis-\ntent with sequential rationality. Find an equilbrium of the game using backward\ninduction, and brie++y comment on it.\nSolution:\nAs in part (a), at t = 3,\ne\n2 = (1 e)K:\nAt t = 2, the same solutions apply if the Agent has Rejected. If the Agent\nAccepted and k > 0 and e > 0: If the Agent accepted and i = 0 for i = e\nor k the Agent doesn't care what i is; by assumption they choose a tax rate\nof 0. So if the Agent Accepts:\n\ne = 1\n2 if K > 0 and e > 0\n\ne = 0 if K = 0 or e = 0\n\nk = 1 if K > 0 and k > 0\n\nk 2 0 if K = 0 or k = 0:\nAt t = 1, K = 0, as in part (a) if the Agent Rejects or if the Agent accepts and\nboth k > 0 and e > 0:. If k > 0 and e = 0, then the worker maximizes\n(1 0)K(1 0)K + (1 1)K K2=2 ((1 0)K)2 =2 = 0:\nSo any K is equally good.\nK 2 [0; 1) if k > 0 and e = 0\nIf k = 0 and e > 0, then the worker maximizes\nU\nW\n=\n(1 )K(1\n)K + (1\n0)K\nK =2\n(1\n)K\n=2\n\n=\nK K2:\nThe ...rst order conditions give\nK =\nif k = 0 and e > 0:\n\n- At t = 0, the Agent clearly Rejects if P = 0 and Pe = 0. If P = 0 and\nPe > 0, his payof will be:\nPe 4\n(1 - 1/2) - c.\n2 3\nSo the Agent will Accept if Pe > c, Reject if Pe < c and be willing to\ndo either if Pe = c. If P\n> 0 and Pe = 0, whether or not the Agent will\n\naccept depends on what he anticipates K will be (since the worker will be\nindiferent) Since we're just told to fnd an equilibrium, let's assume K = 0\nin thise case.\n- At t = 0, the Government will get a payof of 0 by ofering P = 0 and Pe = 0\n(as in (a)) Given the assumption above that the Worker will choose K = 0 if\nP > 0 and Pe = 0, the Government will get a 0 payof by ofering P > 0 and\nPe = 0 (also as in (a)). If Government ofers P = 0 and Pe 2 c the Agent\n\nwill Accept, the worker will work, and the Government will get a positive\npayof, (so long as Pe < 1, which is OK to assume, since c is small). It wants\nto choose the smallest agent share, so it picks Pe = c.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2008 Midterm 2",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/7ff9d6c1dd6e0b37b81ac0a5fc6bddad_MIT14_12F12_Midterm_2_2008.pdf",
      "content": "14.12 Game Theory Midterm 2\n11/13/2008\nProf. Casey Rothschild\nInstructions. This is an open book exam; you can use any written material. You may use a\ncalculator. You may not use a computer or any electronic device with wireless communication\ncapacity. You have one hour and 20 minutes. There are three questions. The breakdown\nof points within each question is specifed below. Please answer each question in a separate\nblue book. Be sure to put your name on each book. Good luck!\n1. This problem deals with the game depicted below, where e is some parameter.\n(a) (10 points) If e = -1, fnd all of the SPE of the 8-times repeated version of this\ngame. Explain how you know you found them all.\n(b) (15 points) Now suppose instead that e = 2 and consider a T-times repeated ver\nsion of this game. For each of the following, state whether the proposed strategies\ncould be played in the frst round of a subgame perfect equilibrium or not. If\nthey can, describe a full set of SPE strategies that implement it.\n1. T=2, and (Y,C)\n2. T=2 and (X,B)\n3. T=3 and (X,C)\n(c) (10 points) Now suppose that e is known by player 2 but not by player 1, who\nbelieves that there is a 1/2 chance that e = -1 and a 1/2 chance that e = 2. Find\nand describe all of the Bayesian Nash Equilibria of the game.\n\n2. Alice and Bob jointly own a dollar which they can have only if they agree on a division.\nIn every round, one of the two will be the \"oferer\" and the other will be the \"receiver.\"\nAt the beginning of round 1, they fip a coin to determine who gets to be oferer.\nAt the beginning of every round after round 1, there is a computer program that\ngenerates outcomes {5, R, E} with probabilities Ps, PR and PE, respectively, where\nPs + PR + PE = 1 and PE > O. If the computer generates 5, the oferer stays the\nSAME as the in the last round. If the computer generates R, the player who was the\nRECEIVER in the previous round gets to be the oferer. In any given round:\n- If it is the second round or later and the outcome is E, then the game ends with\npayof vector 0.\n- If Alice is the oferer, then\n- Alice ofers a division (1 - x, x), where x is the share of Bob,\n- Bob decides whether to accept the ofer;\n- if ofer is accepted the game ends with payof vector (1 - x, x); otherwise the\ngame proceeds to the next round.\n- If Bob is the oferer\n- Bob ofers a division (x, 1 - x), where x is the share of Alice,\n- Alice decides whether to accept the ofer;\n- if ofer is accepted the game ends with payof vector (x, 1 - x); otherwise we\nproceed to the next round.\nConsider the strategy profle\ns* : Alice always ofers (1 - xB , xB ) and accepts an ofer (x, 1 - x) if and only if x 2 xA.\nBob always ofers (xA, 1 - xA) and accepts an ofer (1 - x, x) if and only if x 2 xB .\n(a) (10 points) Explain precisely why xB = 1, xA = O is not a subgame perfect\nequilbirium.\n(b) (20 points) Find a subgame-perfect equilibrium of the game, and use the single\ndeviation principle to prove that it is indeed a subgame perfect equilibrium.\n\n3. Consider the following infnitely repeated game.\n- There is an Incumbent and a (potential) Entrant.\n- Each date t has two stages:\n- At the frst stage, the Entrant decides whether to Enter or Stay Out.\n- If the Entrant decides to Enter, it bears an entry cost of k = O.1. The two\nplayers then play a standard \"Cournot\" game:\n* Each of the two frms simultaneously decide on a non-negative output qE\nand qI.\n* The demand curve is given by P = 1 - Q, where Q = qE + qI, so the price\nof output is given by P = 1 - Q. (Notice that we allow negative prices\nhere; but you should be able to ignore that for the sake of this problem.)\n* The marginal cost of production is zero, so the profts are given by:\nI = qI P\nE = qE P - k.\n- If the Entrant Stays Out, it gets a payof of 0, and the Incumbent decides on\na production level qI to produce, facing the same demand curve.\n- The game is infnitely repeated, with a discount factor 6 E (O, 1).\n- Notice that the entrant bears the cost k in each round in which she enters.\n(a) (10 points) Find the subgame perfect equilibrium of the non-repeated version of\nthis game (the game that takes place at any t).\n(b) (10 points) Prove that the following strategy profle is a subgame perfect equilib\nrium for sufciently high 6, and fnd the minimal 6 for which it is:\n- The Entrant Enters every round.\ni\n- Every producer produces q =\n, so long as no producer has ever produced a\n\nquantity other than i.\n\n- If any producer has ever produced a quantity other than i, \"trigger\" to play\n\ning the subgame perfect equilibrium from part (a) in every period.\n(c) (10 points) For 6 = .9, is there a subgame perfect equilibrium in which entry is\nalways deterred (i.e., in which the Entrant never Enters)? If so, fnd one. If not,\nexplain why not.\n(d) (5 points) Describe strategies that can implement the same outcome as part (b)\nfor some 6 < 66.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2008 Midterm 2 solutions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/13300416d796ea52e7734681caa5d2db_MIT14_12F12_MT2_2008_sol.pdf",
      "content": "14.12 Game Theory\nCasey Rothschild\nFall 2008\nMidterm 2\nsolutions\nProblem 1\na) If we substitute in the value e = -1, the payof matrix becomes:\nA\nB\nC\nX\nY\n6, 0 0, 0\n0, 1\n0, 0 2, -1 9, 1\nIt is easy to see that strategy C for player 2 dominates all the other strategies. Once we\neliminate A and B, then strategy X for player 1 will become conditionally dominated.\nTherefore, the unique Nash equilibrium of this game is (Y, C). In class we have seen\na theorem which states that whenever a stage game has a unique Nash equilibrium\nand it is repeated a fnite number of times, then there is only one subgame perfect\nequilibrium with the players playing the Nash equilibrium in every period.\nb) Let's now substitute in the value e = 2. The stage game becomes:\nA\nB\nC\nX\nY\n6, 6 0, 0 0, -2\n0, 0 2, 2 9, -2\nWe can immediately see that C is dominated for player 2, thus we can safely ig\nnore it when computing the Nash equilibria of the game. There are 2 pure-strategy\nNash equilibria (X, A) and (Y, B) and one mixed-strategy Nash equilibria (01, 02) =\n\nX +\nY, 1\nA +\nB . The payofs associated with the latter equilibrium are\n2 ,\n2 ,\nwhich are lower than those associated with the two pure-strategy Nash equilibria. Thus\nwe can try to use the usual trick of rewarding the players when they comply with the\nproposed strategy and punish them in case of deviation. The reward will be the most\nproftable Nash equilibrium (X, A) while the punishment will be the mixed-strategy\nequilibrium (01, 02).\n1. Consider the strategies:\n\nplay Y at t = 1\n1 = play X at t = 2 if (Y, C)\nplay 01 otherwise\nand\n\nplay C at t = 1\n2 = play A at t = 2 if (Y, C)\nplay 02 otherwise\n\nThe only player who may have an incentive to deviate is player 2 (player 1 is\ngetting the highest payo¤ at t = 1). If player 2 deviates, he will play B and get 2\nin the ...rst period and 3\n2 in the second period. His total payo¤ from deviating will\nbe 7\n2 which is lower than the total payo¤ of 4 he gets from not deviating. Thus,\n(Y; C) can be played in the ...rst round of a SPE.\n2. Consider the strategies:\n<\nplay X at t = 1\ns1 = : play X at t = 2 if (X; B)\nplay 1 otherwise\nand\n<\nplay B at t = 1\ns2 =\nplay A at t = 2 if (X; B)\nplay 2 otherwise\nAlso in this case player 2 is t\n:\nhe player with the most pro...table deviation. Indeed\nhe can deviate by getting 6 instead of 0 in the ...rst round. Therefore, his total\npayo¤ from deviating will be 15\n2 which is higher than the total payo¤ of 6 he gets\nfrom not deviating. Thus, (Y; C) cannot be played in the ...rst round of a SPE.\n3. Consider the strategies:\nplay X at t = 1\ns1 =\n>\n>\n>\n>\n<\nplay X at t = 2 if (X; B)\n>\nplay\n>\n1 otherwise\n:\n>\n> play X at t = 3 if (X; B) , (X; A)\nplay 1 otherwise\nand\nplay C at t = 1\ns2 =\n>\n>\n>\n>\n<\nplay A at t = 2 if (X; C)\n>\nplay\n>\n2 otherwise\n:\n>\n> play A at t = 3 if (X; C) , (X; A)\nplay 2 otherwise\nThe player with the most pro...table deviation is now player 1. She can deviate\nin period 1 by getting 9 and then 3\n2 in each of the following periods. Her total\npayo¤ from deviating will be 12 which is therefore equal to the total payo¤ of 12\nshe gets from not deviating. Thus, (X; C) can be played in the ...rst round of a\nSPE.\nc) From part a) we know that whenever = 1, C is a dominant strategy for player 2.\nThus, in any Bayesian Nash Equilibrium type = 1 of player 2 will always play\nhis dominant strategy, that is, s\n2(1) = C.\nLet's now consider player 1.\nGiven\ns\n2(1) = C, player 1 will get at most 16 + 10 = 3\nby playing X (which happens\nwhen type = 2 plays A) and at least 10 + 19 = 4:5\nY\nby playing\n(which happens\nwhen type = 2 plays A). In other words, given s\n2(1) = C, X is dominated by Y\nfor player 1.\n\nLet's now consider type = 2 of player 2. As shown already above, for this type C is\na dominated action. Thus type = 2 will choose either A or B (or he will randomize\nbetween the two). Given s\n1 = Y and s\n2(1) = C, type = 2 will face the following\nchoice:\n0 if s = A\nu2(s\n1; s\n2(1); s2; = 2) =\n\n2 if s2 = B\nThus type = 2 will choose B. Therefore (s\n1; s\n2(1); s\n2(2)) = (Y; C; B) is the unique\nBNE of this game.\n\nProblem 2\na) To be a subgame perfect equilibrium, neither of the players must have a single deviation\nthat could make them better of, given any possible history. Therefore, to show that\nthis is not SPE, we must fnd a history and a deviation that will make one of the\nplayer's better of. The key lies in Bob's acceptance strategy. The strategy says that\nBob will accept if X 2 1.\nSo he will reject anything less than 1.\nThis is not SPE.\n\nSuppose Alice ofers X E (Ps + PR, 1).\nLet's check the single deviation principle.\nIf\nhe accepts, he will get X.\nIf he rejects, with probability Ps + PR he will get 1 in the\nnext round (whether he or Alice ofers), so he will get a payof of Ps + PR.\nSince\nX > Ps + PR, he will be strictly better of deviating by accepting Alice's ofer.\nb) To fnd the SPE, we will look at their acceptance strategies and apply the single deviation\nprinciple:\nAlice will accept if X 2 XA.\nSuppose Bob ofers some x\nA.\nIf Alice were to\nX < X\ndeviate and to accept, she will get Xx. If she rejects (and then strategies are played as\ncalled for), there will be a Ps probability that Bob will ofer again and she'll get XA,\nthere will be a PR probability that she will ofer and get 1 -XB, and there will be a PE\nprobability that she will get 0. So her payof, if she rejects would be PsXA +PR(1-XB).\nTherefore, for her NOT to have an incentive to deviate, it must be the case that:\nXx Ps XA + PR(1 - XB)\nX < XA\nx\nNow consider an x\nA. If Alice deviates and rejects this ofer, she will get P\nA +\nX > X\nsX\nPR(1 - XB ).\nIf she accepts it as she is supposed to in the strategy, she will get Xx.\nTherefore, for her NOT to have an incentive to deviate, it must be the case that:\nXx 2 Ps XA + PR(1 - XB) for all Xx 2 XA\nTherefore, the inequality must bind for Xx = XA. So, we get the equation:\nXA = PsXA + PR(1 - XB)\nParallel analysis for Bob's acceptance strategy will yield the equation:\nXA = Ps XB + PR(1 - XA)\nSolving these two equations and two unknowns will yield:\nPR\nX\n= X\n=\nA\nB\n1 + P\n- P\nR\ns\nThus, the SPE of the game will be the strategies as listed in the problem where XA and\nXB are as in the above equation. We have calculated it by checking the single deviation\nprinciple for both of their acceptance strategies. (You should therefore get 15 points up\nto this point). The fnal thing that we need to do is to check, using the single deviation\nstrategies, that neither of them have an incentive to deviate when ofering.\nAlice is\nsuppose to ofer XB to Bob.\nIf she does this, he will accept and she will get a payof\nof 1 - XB .\nIf she deviates by ofering more than XB to Bob, he will accept (given his\n\nstrategies), and she will do strictly worse of. Suppose she deviates by ofering X < XB .\nThen Bob will reject, and she will get an expected payof of Ps (1 - XB) + PRXA. She\nwill not have an incentive to deviate as long as: (1 - XB) 2 Ps (1 - XB ) + PRXA.\nPlug in the values of XA and XB to see that this is equivalent to the condition that\n1-Ps\nPs -Ps\nj+PR\nj\n.\nSo we just need to check that:\n1 - Ps 2 Ps - Ps\n2 + PR\n2 .\n1+PR-Ps\n1+PR-Ps\nRearranging, we get that this would mean that 1 - 2P + P 2 - P 2 2 0.\nWhich can\ns\ns\nR\nbe changed to: (1 - Ps )2 - PR\n2 2 0, or (1 - Ps + PR)(1 - Ps - PR) 2 0. Since the frst\nfactor is clearly greater than 0, and the second factor is equal to PE > 0, this must be\ntrue. Therefore, Alice will not have an incentive to deviate when she is ofering XB to\nBob.\nWith the exact same analysis, Bob will not have an incentive to deviate when\nofering XA to Alice.\n\nProblem 3\n1.\n(a)\nIf the entrant exits, qI\n= 1:\n2 (-2 points for not noting this as part of SPE).\nIf the entrant enters, k is a sunk cost, so this is strategically equivalent to a\nstandard Cournot game, and, from class, qI\n= qE\n= 1:\nEntrant enters, since 1\n3 (1 2)\n3 :1 = 1\n9 :1 > 0, so higher pro...ts from\nentering than exiting.\n(b)\nThere are several possible subgames we need to check. When I say \"deviation\"\nhere, I mean a deviation away from q = 1:\n- First, note that all subgames which occur after a deviation satisfy the\nsingle deviation principle, since, by (a), the strategies in these history are\nrepeated SPE of the stage game.\n- Second, in no-deviation histories, note that the entrant never wants to\nexit: this doesn't a¤ect the future, and it lowers his pro...t in the present\nperiod.\n- Third, in a no-deviation history where the entrant enters, the single de-\nviation principle requires\n\nmax\nqE(1\nqE\nqE)\n4 k\n+\n(\n1 9 k)\n8 k\n\n+\n(\n1 8 k)\nand, since the k's fall out of this equation, the same condition has to hold\nfor the incumbent. Solving the max gives qE = 3=8, so the condition\nreduces to\n\n+\n1 9 8 1 8\nor\n\n.\nSolving for the critical gives b =\n9 :\n17 (8 points for getting this far)\n- Fourth, consider the nodes when there has been no deviation (away from\nq = 1\n4) but after an \"exit\"by the Encumbent. According to the proposed\nstrategies, the incumbent is supposed to produce qI = 1\n4. He'd prefer to\nproduce qI = 1\n2, but this will lead to a deviation history. He's willing to\nproduce 1\n4 precisely when:\n\n+\n( )\n1 9\n+\n( )\n1 8\nSolving for the critical gives b =\n9 :\n11 . Since this is bigger than\n9 ;\n17 this\nis the critical value for these strategies to be an SPE.\n- Note that the nodes from the previous bullet aren't very important -it\nwould be easy to adjust the strategies so that this would be an SPE for\nb =\n17. This will be my \"trick\"for part (d).\n(c)\nYes. There are many possibilities. Here's one:\n\n- Normal mode: always exit and produce q\nI = 2. If enter, produce qI = 1\nand qE = 0:\n- Trigger mode: play the SPE from (a) forever.\n- Stay in Normal mode unless Enter AND qI = 1:\nUsing single deviation principle, note that the only place where anyone would\npotentially want to deviate is the incumbent producing qI = 1 after an entry.\nShe is willing to do this whenever\n\n0 + 1\n\n+\n\n;\nor when > 9: Since :9 > 9;\n5 , we're good.\n(d)\nSomething like \"carrot and stick\"from class would work. But here it's easier\nif you got (b) right.\nSimply change the strategies from (b) from\n- if any producer has ever produced a quantity other than 1\n4, \"trigger\"to\nplaying the subgame perfect equilibrium from part (a) in every period.\nTO\n- if any producer has ever produced a quantity other than 1\n4 AFTER EN-\nTRY, \"trigger\"to playing the subgame perfect equilibrium from part (a)\nin every period.\nAND from\n- Every producer produces q = 1\n4, so long as no producer has ever produced\na quantity other than 1:\nTO\n- After entry, every producer produces q = 1\n4, so long as no producer has\never produced a quantity other than 1\n4 IN A ROUND WHERE THERE\nWAS ENTRY. After Exit, produce q = 1:\nThen the same reasoning from (b) applies, and we get an equilibrium when-\never b =\n17 or greater, which is lower than the correct answer from (b).\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "2009 Midterm 1",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/5646a975f098bd4edf0f418ca9fef5c1_MIT14_12F12_midterm1_2009.pdf",
      "content": "14.12 Midterm Exam #1\nOctober 8, 2009\nAnswer all questions. You have 85 minutes in which to complete the exam. Please\nshow your calculations and provide rough explanations where you can't give formal state\nments so I can give you partial credit.\n1. (15 Minutes - 20 Points) Answer each of the following subquestions BRIEFLY.\n(a) (5 points) In my second lecture I defined a solution concept called \"pure strategy iterated\nstrict dominance.\" In my fifth lecture I defined a more powerful version of iterated strict\ndominance. What was the difference betweeen them and why was the game below a useful\nexample?\nL\nC\nR\nU\nM\nD\n10, 9\n10, 6\n10, 10\n-5, 9\n15, 10\n11, 12\n-35, 10\n10, 7\n15, 5\n(b) (5 points) Find all pure strategy Nash equilibria of the game below.\nX\nY\nZ\nA\nB\nC\n4, 3\n5, 2\n5, 1\n1, 7\n6, 6\n4, 3\n2, 3\n7, 3\n5, 3\n(c) (5 points) In class I discussed the general discrete choice model of price competition\nbetween N firms: the firms choose prices p1, . . . , pn and each consumer i decides to purchase\nfrom the firm j for which v-pj +Eij is largest. Describe briefly what happens to equilibrium\nprices as the number of firms N goes to infinity both for uniformly distributed Eij and under\ngeneral distributions.\n(d) (5 points) Describe precisely an example of a game that has no pure or mixed strategy\nNash equilibrium. Describe as well as you can a theorem that provides conditions under\nwhich a game with an infinite number of pure stategies must have a Nash equilibrium.\nWhat conditions of your theorem are violated in your example?\n\n2. (25 Minutes - 30 Points)\nWhen my daughter Anna was 3 years old, she liked to play Rock-Paper-Scissors. How\never, she faced a difficulty - three year olds find it hard to make \"scissors\" with their\nfingers.\nSuppose that we capture this problem by treating her playing Rock-Paper-Scissors\nagainst her older sister using the asymmetric 3 × 3 game shown below (with Anna as\nplayer 1).\nR\nP\nS\nR\nP\nS\n0, 0\n-1, 1\n1, -1\n1, -1\n0, 0\n-1, 1\n-1 - c, 1\n1 - c, -1\n-c, 0\n(a) (13 Points) Consider first the version of this game where c > 1. (You can think\nof this as a model for the extreme situation where Anna is physically incapable of playing\nscissors.) Find a mixed-strategy Nash Equilibrium of this game.\n(b) (3 points) What is Anna's expected payoff in the equilibrium you found in part (a)?\n(c) (14 points) Consider now the version of this game with 0 < c < 1. Find a mixed\nstrategy Nash equilibrium of this game in which both players play every strategy with\npositive probability.\n\n3. (15 Minutes - 22 Points)\nTwo students are deciding how long to spend studying for 14.12 on the night before\nthe exam. Let ei be the fraction of the available time student i devotes to studying with\n0 ≤ ei ≤ 1. Assume that the students' utilities are\nu1(e1, e2) = log(1 + 3e1 - e2) - e1\nu2(e1, e2) = log(1 + 3e2 - e1) - e2\n(A story for this would be that the first term reflects the benefits they get from learning\nand getting a good grade, whereas the second reflects the opportunity cost of time. The\nnegative effect of e2 on student 1's utility could reflect that student 1 will get a lower grade\nif student 2 studies more and does better on the exam.)\n(a) (5 points) What is player 1's best response to a choice of e2 by player 2.\n(b) (13 points) Find a pure strategy Nash equilibrium of the game where players 1 and\n2 choose e1 and e2 simultaneously.\n(c) (4 points) Is this game solvable by iterated strict dominance? How do you know\nthis?\n\n4. (25 Minutes - 28 Points)\nSuppose Prof. Ellison decides to run a classroom experiment to teach about mixed\nstrategy equilibrium (and make some money). He chooses two students from the class.\nEach student is required to write down an integer from 1 to 100 inclusive. The rules of\nthe game are that the student who writes down the smaller number must pay Prof. Ellison\nthat number of dollars. The student who writes down the larger number pays nothing. If\nboth students write down the same number assume that both pay.\nAssume that both students are risk-neutral and self-interested so that this game can be\nrepresented as S1 = S2 = {1, 2, . . . , 100} with\ns\nif s\ns\nu1(s1, s2) =\n-1\n1 ≤\nif s1 > s2\n-s2 if s2 ≤ s1\nu2(s1, s2) =\nif s2 > s1\n(a) (3 points) Are any strategies in this game strictly dominated?\n(b) (7 points) This game has two pure strategy Nash equilibria. What are they?\n(c) (3 points) Discuss briefly why you should expect given what I told you in part (b)\nthat this game would also have a mixed strategy Nash equilibrium.\n(d) (15 points) Find a symmetric mixed strategy Nash equilibrium of this game.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Resource",
      "title": "Table of Contents",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/61572392501c282ac81968a9fdd897ec_MIT14_12F12_tableofcontnts.pdf",
      "content": "14.12 Game Theory Lecture Notes\nMuhamet Yildiz\nMIT Economics Department\nFall 2012\n\nii\n\nContents\n1 Introduction\n2 Decision Theory\n2.1 The basic theory of choice . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2 Decision-making under uncertainty . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Modeling Strategic Situations . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.4 Attitudes Towards Risk . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.4.1 Risk sharing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.4.2 Insurance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3 Representation of Games\n3.1 Normal form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.2 Extensive form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.3 Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4 Dominance\n4.1 Rationality and Dominance . . . . . . . . . . . . . . . . . . . . . . . . . 33\n4.2 Dominant-strategy equilibrium . . . . . . . . . . . . . . . . . . . . . . . . 36\n5 Rationalizability\n6 Nash Equilibrium\n6.1 Introduction and Definition . . . . . . . . . . . . . . . . . . . . . . . . . 47\n6.2 Mixed-strategy Nash equilibrium . . . . . . . . . . . . . . . . . . . . . . 50\n6.3 Evolution of Hawks and Doves . . . . . . . . . . . . . . . . . . . . . . . . 52\niii\n\niv\nCONTENTS\n7 Application: Imperfect Competition\n7.1 Cournot (Quantity) Competition . . . . . . . . . . . . . . . . . . . . . . 57\n7.1.1 Cournot Duopoly . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n7.1.2 Cournot Oligopoly . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n7.2 Bertrand (Price) Competition . . . . . . . . . . . . . . . . . . . . . . . . 65\n7.2.1\nNash Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n7.2.2 Rationalizability with discrete prices . . . . . . . . . . . . . . . . 66\n7.2.3 Price competition with search costs . . . . . . . . . . . . . . . . . 69\n8 Backward Induction\n9 Application: Negotiation\n9.1 Congressional Bargaining-Voting with a Binary Agenda . . . . . . . . . 85\n9.2 Pre-trial Negotiations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n9.3 Sequential Bargaining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n10 Subgame-Perfect Nash Equilibrium\n11 Application: Imperfect Competition\n11.1 Cournot (Quantity) Competition . . . . . . . . . . . . . . . . . . . . . . 103\n11.1.1 Cournot Duopoly . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n11.1.2 Cournot Oligopoly . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n11.2 Bertrand (Price) Competition . . . . . . . . . . . . . . . . . . . . . . . . 111\n11.2.1 Nash Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\n11.2.2 Rationalizability with discrete prices . . . . . . . . . . . . . . . . 113\n11.2.3 Price competition with search costs . . . . . . . . . . . . . . . . . 115\n12 Repeated Games\n12.1 Finitely-repeated games . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\n12.2 Infinitely repeated games with observed actions . . . . . . . . . . . . . . 126\n13 Application: Implicit Cartels\n13.1 Infinitely Repeated Cournot Oligopoly . . . . . . . . . . . . . . . . . . . 136\n13.2 Monopoly Production with Patient Firms . . . . . . . . . . . . . . . . . . 136\n13.3 Optimal Production Level with a Fixed δ . . . . . . . . . . . . . . . . . . 138\n\nCONTENTS\nv\n13.4 Reward and Punishment: Carrot-Stick Strategies . . . . . . . . . . . . . 140\n13.5 Price Wars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\n13.6 Exercises with Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\n14 Static Games with Incomplete Information\n14.1 Examples of Previous Exam Questions with Solutions . . . . . . . . . . . 157\n15 Static Applications with Incomplete Information\n15.1 Cournot Duopoly with incomplete information . . . . . . . . . . . . . . . 160\n15.2 First-price Auction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162\n15.3 Double Auction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\n15.4 Investment in a Joint Project . . . . . . . . . . . . . . . . . . . . . . . . 171\n15.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176\n16 Dynamic Games with Incomplete Information\n16.1 Sequential Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\n16.2 Sequential equilibrium in Beer and Quiche Game . . . . . . . . . . . . . 189\n16.3 A Simple example of Reputation Formation . . . . . . . . . . . . . . . . 196\n16.4 Bargaining with Incomplete Information . . . . . . . . . . . . . . . . . . 199\n\nvi\nCONTENTS\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 1 Lecture Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/be4ea56c748b36e5808fa7d93269f1d1_MIT14_12F12_chap1_intro.pdf",
      "content": "Chapter 1\nIntroduction\nGame Theory is a misnomer for Multiperson Decision Theory. It develops tools, meth\nods, and language that allow a coherent analysis of the decision-making processes when\nthere are more than one decision-makers and each player's payoff possibly depends on\nthe actions taken by the other players. In this lecture, I will illustrate some of these\nmethods on simple examples.\nNote that, since a player's preferences on his actions depend on which actions the\nother parties take, his action depends on his beliefs about what the others do. Of course,\nwhat the others do depends on their beliefs about what each player does. In this way, a\nplayer's action, in principle, depends on the actions available to each player, each player's\npreferences on the outcomes, each player's beliefs about which actions are available to\neach player and how each player ranks the outcomes, and further his beliefs about each\nplayer's beliefs, ad infinitum.\nWhen players think through what the other players will do, taking what the other\nplayers think about them into account, they may find a clear way to play the game.\nConsider the following \"game\":\n1\\2\nL\nm\nR\nT\nM\nB\n1, 1 0, 2\n2, 1\n2, 2 1, 1\n0, 0\n1, 0 0, 0 -1, 1\nHere, There are two players, namely Player 1 and Player 2. Player 1 has strategies,\nT, M, B, and Player 2 has strategies L, m, R. They pick their strategies simultaneously.\n\nCHAPTER 1. INTRODUCTION\nEvery pair of strategies leads to a payoff to each player, a payoff measured by a real\nnumber. In each entry, the first number is the payoff of Player 1, and the second entry\nis the payoff of Player 2. For instance, if Player 1 plays T and Player 2 plays R, then\nPlayer 1 gets a payoff of 2 and Player 2 gets a payoff of 1. Let's assume that each player\nknows that these are the strategies and the payoffs, each player knows that each player\nknows this, each player knows that each player knows that each player knows this,. . .\nad infinitum.\nNow, Player 1 looks at his payoffs, and realizes that, no matter what the other player\nplays, it is better for him to play M rather than B. That is, if Player 2 plays L, M\ngives 2 and B gives 1; if Player 2 plays m, M gives 1, B gives 0; and if Player 2 plays\nR, M gives 0, B gives -1. Therefore, he realizes that he should not play B. Now h e\ncompares T and M. He realizes that, if Player 2 p\n\nlays L or m, M is better than T , but\nif she plays R, T is definitely better than M. Would Player 2 play R? What w ould s he\nplay? To find an answer to these questions, Player 1 looks at the game from Player 2's\npoint of view. He realizes that, for Player 2, there is no strategy that is outright better\nthan any other strategy. For instance, R is the best strategy if Player 1 plays B, but\notherwise it is strictly worse than m. Would Player 2 think that Player 1 would play\nB? Well, she knows that Player 1 is trying to maximize his expected payoff, given by\nthe first entries as everyone knows. She must then deduce that Player 1 will not play B.\nTherefore, Player 1 concludes, she will not play R (as it is worse t han m\nin this case).\nRuling out the possibility that Player 2 plays R, Player 1 looks at his payoffs and sees\nthat M is now better than T , no matter what. On the other side, Player 2 goes through\nsimilar reasoning, and concludes that Player 1 must play M, and therefore plays L.\nExercise 1 In the above analysis, players are assumed to make many assumptions about\nthe other players' reasoning capabilities. What are these assumptions? How would the\nanalysis change if these assumptions are changed, e.g., if players act rationally but as\nsumes that the other parties play a random strategy?\nThe kind of reasoning in the above analyses does not always yield such a clear\nprediction. Imagine that you want to meet with a friend in one of two places, about\nwhich you both are indifferent. Unfortunately, you cannot communicate with each other\nuntil you meet. This situation is formalized in the following game, which is called pure\ncoordination game:\n\n1 \\ 2\nLeft\n\nRight\n\nTop\n1, 1\n0, 0\nBottom\n0, 0\n1, 1\nHere, Player 1 chooses between Top and Bottom rows, while Player 2 chooses between\nLeft and Right columns. In each box, the first and the second numbers denote the payoffs\nof players 1 and 2, respectively. Note that Player 1 prefers Top to Bottom if he knows\nthat Player 2 plays Left; he prefers Bottom if he knows that Player 2 plays Right.\nSimilarly, Player 2 prefers Left if she knows that Player 1 plays Top. There is no clear\nprediction about the outcome of this game.\nOne may look for the stable outcomes (strategy profiles) in the sense that no player\nhas incentive to deviate if he knows that the other players play the prescribed strategies.\n(Such strategy profiles are called Nash equilibrium, named after John Nash.) Here, Top-\nLeft and Bottom-Right are such outcomes. But Bottom-Left and Top-Right are not\nstable in this sense. For instance, if Bottom-Left is known to be played, each player\nwould like to deviate.\nUnlike in this game, mostly players have different preferences on the outcomes, in\nducing conflict. In the following game, which is known as the Battle of Sexes, conflict\nand the need for coordination are present together.\n1 \\ 2\nLeft\nRight\n\nTop\n2, 1\n0, 0\nBottom\n0, 0\n1, 2\nHere, once again players would like to coordinate on Top-Left or Bottom-Right, but\nnow Player 1 prefers to coordinate on Top-Left, while Player 2 prefers to coordinate on\nBottom-Right. The stable outcomes are again Top-Left and Bottom- Right.\nThe above analysis assumes that players take their actions simultaneously, so that\na player does not observe the action taken by the others when chooses his own action.\nIn general, a player may observe some of the actions of some other players. Such a\nknowledge may have a dramatic impact on the outcome of the game. For an illustration,\nin the Battle of Sexes, imagine that Player 2 knows what Player 1 does when she takes\nher action. This can be formalized via the tree in Figure 1.1. Here, Player 1 first\nchooses between Top and Bottom, and then Player 2 chooses between Left and Right,\n\nCHAPTER 1. INTRODUCTION\nB\nO\nB\nO\nB\nO\n2,1\n0,0\n0,0\n1,2\nFigure 1.1: Battle of Sexes with sequential moves\nknowing what Player 1 has chosen. Clearly, now Player 2 would choose Left if Player\n1 plays Top, and choose Right if Player 1 plays Bottom. Knowing this, Player 1 would\nplay Top. Therefore, one can argue that the only reasonable outcome of this game is\nTop-Left. (This kind of reasoning is called backward induction.)\nWhen Player 2 is able to check what the other player does, he gets only 1, while\nPlayer 1 gets 2. (In the previous game, two outcomes were stable, in which Player 2\nwould get 1 or 2.) That is, Player 2 prefers that Player 1 has information about what\nPlayer 2 does, rather than she herself has information about what Player 1 does. When\nit is common knowledge that a player has some information or not, the player may prefer\nnot to have that information-a robust fact that we will see in various contexts.\nExercise 2 Clearly, this is generated by the fact that Player 1 knows that Player 2\nwill know what Player 1 does when she moves. Consider the situation that Player 1\nthinks that Player 2 will know what Player 1 does only with probability π < 1, and t his\nprobability does not depend on what Player 1 does. What will happen in a \"reasonable\"\nequilibrium? [By the end of this course, hopefully, you will be able to formalize this\nsituation, and compute the equilibria.]\nAnother interpretation is that Player 1 can communicate to Player 2, who cannot\ncommunicate to player 1. This enables Player 1 to commit to his actions, providing a\nstrong position in the relation.\n\nB\n(3/2,3/2)\nPlay\nExit\nB\nO\nO\n(2,1)\n(0,0)\n(0,0)\n(1,2)\nFigure 1.2: Battle of Sexes with exit option\nExercise 3 Consider the following version of the last game: after knowing what Player\n2 does, Player 1 gets a chance to change his action; then, the game ends. In other words,\nPlayer 1 chooses between Top and Bottom; knowing Player 1's choice, Player 2 chooses\nbetween Left and Right; knowing 2's choice, Player 1 decides whether to stay where he\nis or to change his position. What is the \"reasonable\" outcome? What would happen if\nchanging his action would cost player 1 c utiles?\nImagine that, before playing the Battle of Sexes, Player 1 has the option of exiting,\nin which case each player will get 3/2, or playing the Battle of Sexes. When asked to\nplay, Player 2 will know that Player 1 chose to play the Battle of Sexes, as depicted\nin Figure 1.2. There are two \"reasonable\" equilibria (or stable outcomes). One is that\nPlayer 1 exits, thinking that, if he plays the Battle of Sexes, they will play the Bottom-\nRight equilibrium of the Battle of Sexes, yielding only 1 for Player 1. The second one is\nthat Player 1 chooses to Play the Battle of Sexes, and in the Battle of Sexes they play\nTop-Left equilibrium.\nSome would argue that the first outcome is not really reasonable? Because, when\nasked to play, Player 2 will know that Player 1 has chosen to play the Battle of Sexes,\nforgoing the payoff of 3/2. She must therefore realize that Player 1 cannot possibly be\nplanning to play Bottom, which yields the payoff of 1 max. That is, when asked to play,\nPlayer 2 should understand that Player 1 is planning to play Top, and thus she should\nplay Left. Anticipating this, Player 1 should choose to play the Battle of Sexes game,\nin which they play Top-Left. Therefore, the second outcome is the only reasonable one.\n\nCHAPTER 1. INTRODUCTION\n(This kind of reasoning is called Forward Induction.)\nHere are some more examples of games that will be referred to frequently throughout\nthe course.\nPrisoners' Dilemma\n1 \\ 2\nCooperate\nDefect\n\nCooperate\nDefect\n5, 5\n0, 6\n6, 0\n1, 1\nThis is a well known game that most of you know. Two prisoners are arrested for a\ncrime for which there is no firm evidence, and they are being interrogated in separate\nrooms. Each prisoner could either cooperate with the other and not confess their crime\nor defect and confess the crime. In this game no matter what the other player does,\neach player would like to defect, confessing their crime. This yields (1, 1). If they both\ncooperated and not confessed their crime, each would get a better payoff of 5.\nHawk-Dove game\n1 \\ 2\nHawk\n\nDove\n\nHawk\nV -C\n2 , V -C\nV , 0\nDove\n0,V\nV\n2 , V\nThis is an important biological game, but is also quite similar to many games in Eco\nnomics and Political Science. V is the value of a resource that one of the players will\nenjoy. If they shared the resource, their values are V/2. Hawk stands for a \"tough\"\nstrategy, whereby the player does not give up the resource. However, if the other player\nis also playing hawk, they end up fighting, and incur the cost C/2 each. On the other\nhand, a Hawk player gets the whole resource for itself when playing a Dove. When\nV > C, this is a Prisoners' Dilemma game, yielding a fight.\nWhen V < C, so that fighting is costly, this game is similar to another well-known\ngame, named \"Chicken\", where two players driving towards a cliff have to decide whether\nto stop or continue. The one who stops first loses face, but may save his life. More\ngenerally, a class of games called \"wars of attrition\" are used to model this type of\nsituations. In this case, a player would like to play Hawk if his opponent plays Dove,\nand play Dove if his opponent plays Hawk.\n\nAn investment game:\n1 \\ 2 Invest\nDon't Invest\nInvest\nθ, θ\nθ - c, 0\nDon't Invest\n0,θ - c\n0,0\nHere, two parties simultaneously decide whether two invest; the investment is more\nvaluable if the other party also invests (as in the coordination game). For example,\nconsider a potential worker and a potential employer, potential worker deciding whether\nto get education (investing in his human capital), and the potential employer deciding\nwether to invest in a technology that would require human capital. (Think about what\nare the reasonable outcomes for various values of θ and c. How would you analyze this\nsituations if the players do not know the actual values of these parameters, but have\nsome private information about what these values could be?)\n\nCHAPTER 1. INTRODUCTION\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 1 Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/624bf7cc4b26e29962b1c6c9814ceae5_MIT14_12F12_Slides1.pdf",
      "content": "14.12 Economic Applications of\nGame Theory\n- Professor: Muhamet Yildiz\n\nA map\nshowing\nEngland\n, Franc\ne, and\nthe E\nnglish cha\nnnel bet\nween th\nem.\nImage by MIT OpenCourseWare.\n\nName of the game\nGame Theory = Multi-person decision theory\n- The outcome is determined by the actions\nindependently taken by multiple decision\nmakers.\n- Strategic interaction.\n- Need to understand what the others will do\n... what the others think that you will do\n\nA coordination game\nLeft\nRight\nTop\n(1,1)\n(0,0)\nBottom\n(0,0)\n(1,1 )\n\nA game\nL\nm\nR\nT\n(1,1)\n(0,2)\n(2,1)\nM\n(2,2)\n(1,1)\n(0,0)\nB\n(1 ,0)\n(0,0)\n(-1,1)\n\nA coordination game\nLeft\nRight\nTop\n(1,1)\n(0,0)\nBottom\n(0,0)\n(1,1 )\n\nBattle of Sexes\nBaseball\nOpera\nBaseball\n(2,1 )\n(0,0)\nOpera\n(0,0)\n(1,2)\n\nBattle of The Sexes with perfect information\nB\no\n2,1\n0,0\n0,0\n1,2\n\nBattle of Sexes with outside option\nExit\nB\n(2,1)\n(0,0)\n(3/2,3/2)\nB\no\n(0,0)\n(1,2)\n\nAn illustration\nof\ndove\ns and t\nhe hea\nd\ns\n\no\nf\n\nh\naw\nk\ns\n.\nImage by MIT OpenCourseWare.\n\nAn illustration\nof do\nves\nand th\ne heads\nof h\naw\nks.\nImage by MIT OpenCourseWare.\n\nAn illus\ntration\nof chi\nc\nke ns and th\ne he ad s o\nf\nlions.\nImage by MIT OpenCourseWare.\n\nIllustrati\non\ns of r\nabbits\na\nnd the\nheads\nof stags.\nImage by MIT OpenCourseWare.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 2 Lecture Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/dc2132d365c6f2ab8b35f9b5976574f6_MIT14_12F12_chapter2.pdf",
      "content": "Chapter 2\nDecision Theory\n2.1\nThe basic theory of choice\nWe consider a set of alternatives. Alternatives are mutually exclusive in the sense\nthat one cannot choose two distinct alternatives at the same time. We also take the set\nof feasible alternatives exhaustive so that a player's choices is always well-defined.1\nWe are interested in a player's preferences on . Such preferences are modeled\nthrough a relation o on , which is simply a subset of × . A relation o is said to\nbe complete if and only if, given any ∈ , either o or o . A relation o is\nsaid to be transitive if and only if, given any ∈ ,\n[ o and o ] ⇒ o .\nA relation is a preference relation if and only if it is complete and transitive. Given any\npreference relation o, we can define strict preference A by\nA ⇐⇒\n[ o and o ]\nand the indifference ∼ by\n∼ ⇐⇒ [ o and o ]\n1This is a matter of modeling. For instance, if we have options Coffee and Tea, we define alternatives\nas = Coffee but no Tea, = Tea but no Coffee, = Coffee and Tea, and = no Coffee and no\nTea.\n\nCHAPTER 2. DECISION THEORY\nA preference relation can be represented by a utility function : → R in the\nfollowing sense:\no ⇐⇒ () ≥ ()\n∀ ∈\nThis statement can be spelled out as follows. First, if () ≥ (), then the player finds\nalternative as good as alternative . Second, and conversely, if the player finds at\nleast as good as , then () must be at least as high as (). In other words, the\nplayer acts as if he is trying to maximize the value of (·).\nThe following theorem states further that a relation needs to be a preference relation\nin order to be represented by a utility function.\nTheorem 2.1 Let be finite. A relation can be presented by a utility function if and\nonly if it is complete and transitive. Moreover, if : → R represents o, and if\n: R → R is a strictly increasing function, then * also represents o.\nBy the last statement, such utility functions are called ordinal, i.e., only the order\ninformation is relevant.\nIn order to use this ordinal theory of choice, we should know the player's preferences\non the alternatives. As we have seen in the previous lecture, in game theory, a player\nchooses between his strategies, and his preferences on his strategies depend on the strate\ngies played by the other players. Typically, a player does not know which strategies the\nother players play. Therefore, we need a theory of decision-making under uncertainty.\n2.2\nDecision-making under uncertainty\nConsider a finite set of prizes, and let be the set of all probability distributions\nP\n: → [0 1] on , where\n∈ () = 1. We call these probability distributions\nlotteries. A lottery can be depicted by a tree. For example, in Figure 2.1, Lottery 1\ndepicts a situation in which the player gets $10 with probability 1/2 (e.g. if a coin toss\nresults in Head) and $0 with probability 1/2 (e.g. if the coin toss results in Tail).\nIn the above situation, the probabilities are given, as in a casino, where the probabili\nties are generated by a machine. In most real-world situations, however, the probabilities\nare not given to decision makers, who may have an understanding of whether a given\nevent is more likely than another given event. For example, in a game, a player is not\n\n2.2. DECISION-MAKING UNDER UNCERTAINTY\nLottery 1\nFigure 2.1:\ngiven a probability distribution regarding the other players' strategies. Fortunately, it\nhas been shown by Savage (1954) under certain conditions that a player's beliefs can be\nrepresented by a (unique) probability distribution. Using these probabilities, one can\nrepresent the decision makers' acts by lotteries.\nWe would like to have a theory that constructs a player's preferences on the lotteries\nfrom his preferences on the prizes. There are many of them. The most well-known-and\nthe most canonical and the most useful-one is the theory of expected utility maximiza\ntion by Von Neumann and Morgenstern. A preference relation o on is said to be\nrepresented by a von Neumann-Morgenstern utility function : → R if and only if\nX\nX\no ⇐⇒ () ≡\n()() ≥\n()() ≡ ()\n(2.1)\n∈\n∈\nfor each ∈ . This statement has two crucial parts:\n1. : → R represents o in the ordinal sense. That is, if () ≥ (), then the\nplayer finds lottery as good as lottery . And conversely, if the player finds at\nleast as good as , then () must be at least as high as ().\n2. The function takes a particular form: for each lottery , () is the expected\nP\nvalue of under . That is, () ≡\n∈ ()(). In other words, the player acts\nas if he wants to maximize the expected value of . For instance, the expected\n1/2\n1/2\nutility of Lottery 1 for the player is ((Lottery 1)) = 1\n2(10) + 1\n2(0).2\nIn the sequel, I will describe the necessary and sufficient conditions for a represen\n2If were a continuum, like R, we would compute the expected utility of by\ntation as in (2.1). The first condition states that the relation is indeed a preference\nrelation:\nR\n()().\n\nCHAPTER 2. DECISION THEORY\nd\nd\n\nPPPPPPPPP\nPPPPPPPPP\nFigure 2.2: Two lotteries\nAxiom 2.1 o is complete and transitive.\nThis is necessary by Theorem 2.1, for represents o in ordinal sense. The second\ncondition is called independence axiom, stating that a player's preference between two\nlotteries and does not change if we toss a coin and give him a fixed lottery if \"tail\"\ncomes up.\nAxiom 2.2 For any ∈ , and any ∈ (0 1], + (1 - ) A + (1 - ) ⇐⇒\nA .\nLet and be the lotteries depicted in Figure 2.2. Then, the lotteries +(1- )\nand + (1 - ) can be depicted as in Figure 2.3, where we toss a coin between a\nfixed lottery and our lotteries and . Axiom 2.2 stipulates that the player would not\nchange his mind after the coin toss. Therefore, the independence axiom can be taken as\nan axiom of \"dynamic consistency\" in this sense.\nThe third condition is purely technical, and called continuity axiom. It states that\nthere are no \"infinitely good\" or \"infinitely bad\" prizes.\nAxiom 2.3 For any ∈ with A , there exist ∈ (0 1) such that + (1 -\n) A and A + (1 - ).\nAxioms 2.1 and 2.2 imply that, given any ∈ and any ∈ [0 1],\nif ∼ , then + (1 - ) ∼ + (1 - )\n(2.2)\nThis has two implications:\n1. The indifference curves on the lotteries are straight lines.\n\n2.2. DECISION-MAKING UNDER UNCERTAINTY\n\nd\n¡ PPPPPPPPP\n¡\n¡\n\n¡\n¡\nd\n@\n@1 -\n@\n@\n@\n+ (1 - )\n(2)\n@\n@\n@\n@\n\n@\n@\n\n@\nH\nHHHHHHHHH\n@\n@\n@\nd\n¡ PPPPPPPPP\n¡\n¡\n\n¡\n¡\nd\n@\n@1 -\n@\n@\n@\n+ (1 - )\nFigure 2.3: Two compound lotteries\n\n¡@\n¡\n@\nHHHHHHHHHHHHHHHH\n¡0\n@\n¡\n@\n¡\n@\n¡\n@\n¡\n@\n¡\n@\n¡\n@\n¡\n@\n- (1)\nFigure 2.4: Indifference curves on the space of lotteries\n\nCHAPTER 2. DECISION THEORY\n2. The indifference curves, which are straight lines, are parallel to each other.\nTo illustrate these facts, consider three prizes 01, and 2, where 2 A 1 A 0.\nA lottery can be depicted on a plane by taking (1) as the first coordinate (on the\nhorizontal axis), and (2) as the second coordinate (on the vertical axis). The remaining\nprobability (0) is 1 - (1) - (2). [See Figure 2.4 for the illustration.] Given any\ntwo lotteries and , the convex combinations +(1 - ) with ∈ [0 1] form the line\nsegment connecting to . Now, taking = , we can deduce from (2.2) that, if ∼ ,\nthen + (1 - ) ∼ + (1 - ) = for each ∈ [0 1]. That is, the line segment\nconnecting to is an indifference curve. Moreover, if the lines and 0 are parallel, then\n= |0| ||, where || and |0| are the distances of and 0 to the origin, respectively.\nHence, taking = , we compute that 0 = + (1 - ) 0 and 0 = + (1 - ) 0 ,\nwhere 0 is the lottery at the origin and gives 0 with probability 1. Therefore, by (2.2),\nif is an indifference curve, 0 is also an indifference curve, showing that the indifference\ncurves are parallel.\nLine can be defined by equation 1 (1)+2 (2) = for some 12 ∈ R. Since\n0 is parallel to , then 0 can also be defined by equation 1 (1) +2 (2) = 0 for some\n0. Since the indifference curves are defined by equality 1 (1)+2 (2) = for various\nvalues of , the preferences are represented by\n()\n=\n0 + 1 (1) + 2 (2)\n≡ (0)(0) + (1) (1) + (2)(2)\nwhere\n(0)\n=\n(1)\n=\n(2)\n=\ngiving the desired representation.\nThis is true in general, as stated in the next theorem:\nTheorem 2.2 A relation o on can be represented by a von Neumann-Morgenstern\nutility function : → as in (2.1) if and only if o satisfies Axioms 2.1-2.3. Moreover,\nand represent the same preference relation if and only if = + for some 0\nand ∈ R.\n\n2.3. MODELING STRATEGIC SITUATIONS\nBy the last statement in our theorem, this representation is \"unique up to affine\ntransformations\". That is, a decision maker's preferences do not change when we change\nhis von Neumann-Morgenstern (VNM) utility function by multiplying it with a positive\nnumber, or adding a constant to it; but they do change when we transform it through a\nnon-linear transformation. In this sense, this representation is \"cardinal\". Recall that,\nin ordinal representation, the preferences wouldn't change even if the transformation\n√\nwere non-linear, so long as it was increasing. For instance, under certainty, =\n\nand would represent the same preference relation, while (when there is uncertainty)\n√\nthe VNM utility function =\nrepresents a very different set of preferences on the\nlotteries than those are represented by .\n2.3\nModeling Strategic Situations\nIn a game, when a player chooses his strategy, in principle, he does not know what the\nother players play. That is, he faces uncertainty about the other players' strategies.\nHence, in order to define the player's preferences, one needs to define his preference\nunder such uncertainty. In general, this makes modeling a difficult task. Fortunately,\nusing the utility representation above, one can easily describe these preferences in a\ncompact way.\nConsider two players Alice and Bob with strategy sets and . If Alice plays\nand Bob plays , then the outcome is (). Hence, it suffices to take the set of\noutcomes = × = {() | ∈ ∈ } as the set of prizes. Consider\nAlice. When she chooses her strategy, she has a belief about the strategies of Bob,\nrepresented by a probability distribution on , where () is the probability\nthat Bob plays , for any strategy . Given such a belief, each strategy induces a\nlottery, which yields the outcome () with probability (). Therefore, we can\nconsider each of her strategies as a lottery.\nExample 2.1 Let = {} and = {}. Then, the outcome set is =\n{}. Suppose that Alice assigns probability () = 13 to and\n() = 23 to . Then, under this belief, her strategies and yield the following\n\nCHAPTER 2. DECISION THEORY\nlotteries:\nTL\n\nTL\n\n1/3\n\nTR\n\nTR\n\n2/3\n\nB1/\n3 1\n/3\nT1/3\nBL\n\nBL\n2/3\n\nBL\n\nBL\n\nOn the other hand, if she assigns probability () = 12 to and () = 12 to ,\nthen her strategies and yield the following lotteries:\nTL\n\nTL\n\n1/2\n\nTR\n\nTR\n\n1/2\nB\n1/\n2 1\n/\nT1/2\nBL\n\nBL\n1/2\n\nBL\n\nBL\n\nThe objective of a game theoretical analysis is to understand what players believe\nabout the other players' strategies and what they would play. In other words, the players'\nbeliefs, and , are determined at the end of the analysis, and we do not know them\nwhen we model the situation. Hence, in order to describe a player's preferences, we need\nto describe his preferences among all the lotteries as above for every possible belief he\nmay hold. In the example above, we need to describe how Alice compares the lotteries\nTL\n\nTL\n\np\nTR\n\nTR\n\n1-p\nB\np\np\nTp\nBL\n\nB\nL\n1-p\nBL\n\nBL\n\n(2.3)\n\n2.3. MODELING STRATEGIC SITUATIONS\nfor every ∈ [01]. That is clearly a challenging task.\nFortunately, under Axioms 2.1-2.3, which we will assume throughout the course, we\ncan describe the preferences of Alice by a function\n: × → R\nSimilarly, we can describe the preferences of Bob by a function\n: × → R\nIn the example above, all we need to do is to find four numbers for each player. The\npreferences of Alice is described by (), (), (), and ().\nExample 2.2 In the previous example, assume that regarding the lotteries in (2.3), the\npreference relation of Alice is such that\nA\nif\n\n(2.4)\n\n∼\nif =\n\nA\nif\n\nand she is indifferent between the sure outcomes () and ().\nUnder\nAxioms\n\n2.1-2.3, we can represent her preferences by\n()\n=\n\n()\n=\n-1\n()\n=\n\n()\n=\nThe derivation is as follows. By using the fact that she is indifferent between () and\n(), we reckon that () = (). By the second part of Theorem 2.2, we\ncan set () = 0 (or any other number you like)! Moreover, in (2.3), the lottery\nyields\n() = () + (1 - ) ()\nand the lottery yields\n() = () + (1 - ) () = 0\n\nCHAPTER 2. DECISION THEORY\nHence, the condition (2.4) can be rewritten as\n() + (1 - ) () 0\nif 14\n() + (1 - ) ()\n=\n\nif = 14\n() + (1 - ) () 0\nif 14\nThat is,\n() + () = 0\nand\n() ()\nIn other words, all we need to do is to find numbers () 0 and () 0\nwith () = -3 (), as in our solution. (Why would any such two numbers\nyield the same preference relation?)\n2.4\nAttitudes Towards Risk\nHere, we will relate the attitudes of an individual towards risk to the properties of his\nvon-Neumann-Morgenstern utility function. Towards this end, consider the lotteries\nwith monetary prizes and consider a decision maker with utility function : R → R.\nA lottery is said to be a fair gamble if its expected value is 0. For instance, consider\na lottery that gives with probability and with probability 1- ; denote this lottery\nby (; ). Such a lottery is a fair gamble if and only if + (1 - ) = 0\nA decision maker is said to be risk-neutral if and only if he is indifferent between\naccepting and rejecting all fair gambles. Hence, a decision maker with utility function\nis risk-neutral if and only if\nX\nX\n() () = (0) whenever\n() = 0\nThis is true if and only if the utility function is linear, i.e., () = + for some\nreal numbers and . Therefore, an agent is risk-neutral if and only if he has a linear\nVon-Neumann-Morgenstern utility function.\nA decision maker is strictly risk-averse if and only if he rejects all fair gambles,\nexcept for the gamble that gives 0 with probability 1. That is,\nX\n3X\n\n() () (0) =\n()\n\n2.4. ATTITUDES TOWARDS RISK\nHere, the inequality states that he rejects the lottery , and the equality is by the fact\nthat the lottery is a fair gamble. As in the case of risk neutrality, it suffices to consider\nthe binary lotteries ( ; ), in which case the above inequality reduces to\n() + (1 - )() ( + (1 - ))\nThis is a familiar inequality from calculus: a function is said to be strictly concave if\nand only if\n( + (1 - )) () + (1 - )()\nfor all ∈ (0 1). Therefore, strict risk-aversion is equivalent to having a strictly concave\nutility function. A decision maker is said to be risk-averse iff he has a concave utility\nfunction, i.e., ( + (1 - )) ≥ () + (1 - )() for each , , and . Similarly,\na decision maker is said to be (strictly) risk seeking iff he has a (strictly) convex utility\nfunction.\nConsider Figure 2.5. A risk averse decision maker's expected utility is () =\n(1) + (1 - ) (2) if he has a gamble that gives 1 with probability and 2\nwith probability 1-. On the other hand, if he had the expected value 1 +(1 - ) 2\nfor sure, his expected utility would be (1 + (1 - ) 2). Hence, the cord AB is the\nutility difference that this risk-averse agent would lose by taking the gamble instead of\nits expected value. Likewise, the cord BC is the maximum amount that he is willing\nto pay in order to avoid taking the gamble instead of its expected value. For example,\nsuppose that 2 is his wealth level; 2 - 1 is the value of his house, and is the\nprobability that the house burns down. In the absence of fire insurance, the expected\nutility of this individual is (gamble), which is lower than the utility of the expected\nvalue of the gamble.\n2.4.1\nRisk sharing\n√\nConsider an agent with utility function : 7\n. He has a (risky) asset that gives $100\n→\nwith probability 1/2 and gives $0 with probability 1/2. The expected utility of the asset\n√\n√\nfor the agent is 0 = 1\n2 0 + 1\n2 100 = 5. Consider also another agent who is identical\nto this one, in the sense that he has the same utility function and an asset that pays\n$100 with probability 1/2 and gives $0 with probability 1/2. Assume throughout that\nwhat an asset pays is statistically independent from what the other asset pays. Imagine\n\nCHAPTER 2. DECISION THEORY\nEU\nu(pW1+(1- p)W2)\nEU(Gamble)\nu\nB\nC\nA\nW1\npW1+(1-p)W2\nW2\nFigure 2.5:\n\n2.4. ATTITUDES TOWARDS RISK\nthat the two agents form a mutual fund by pooling their assets, each agent owning half\nof the mutual fund. This mutual fund gives $200 the probability 1/4 (when both assets\nyield high dividends), $100 with probability 1/2 (when only one on the assets gives high\ndividend), and gives $0 with probability 1/4 (when both assets yield low dividends).\nThus, each agent's share in the mutual fund yields $100 with probability 1/4, $50 with\nprobability 1/2, and $0 with probability 1/4. Therefore, his expected utility from the\n√\n√\n√\nshare in this mutual fund is =\n0 = 60355. This is clearly\n100 +\n50 +\nlarger than his expected utility from his own asset which yields only 5. Therefore, the\nabove agents gain from sharing the risk in their assets.\n2.4.2\nInsurance\nImagine a world where in addition to one of the agents above (with utility function\n√\n: 7\nand a risky asset that gives $100 with probability 1/2 and gives $0 with\n→\nprobability 1/2), we have a risk-neutral agent with lots of money. We call this new agent\nthe insurance company. The insurance company can insure the agent's asset, by giving\nhim $100 if his asset happens to yield $0. How much premium, , the agent would be\nwilling to pay to get this insurance? [A premium is an amount that is to be paid to\ninsurance company regardless of the outcome.]\nIf the risk-averse agent pays premium and buys the insurance, his wealth will be\n$100 - for sure. If he does not, then his wealth will be $100 with probability 1/2 and\n$0 with probability 1/2. Therefore, he is willing to pay in order to get the insurance\niff\n(100 - ) ≥ (0) + (100)\ni.e., iff\n√\n√\n√\n100 - ≥\n0 +\nThe above inequality is equivalent to\n≤ 100 - 25 = 75\nThat is, he is willing to pay 75 dollars premium for an insurance. On the other hand, if\nthe insurance company sells the insurance for premium , it gets for sure and pays\n$100 with probability 1/2. Therefore it is willing to take the deal iff\n≥ 100 = 50\n\nCHAPTER 2. DECISION THEORY\nTherefore, both parties would gain, if the insurance company insures the asset for a\npremium ∈ (50 75), a deal both parties are willing to accept.\nExercise 2.1 Now consider the case that we have two identical risk-averse agents as\nabove, and the insurance company. Insurance company is to charge the same premium\nfor each agent, and the risk-averse agents have an option of forming a mutual fund.\nWhat is the range of premiums that are acceptable to all parties?\n2.5\nExercises with Solution\n1. [Homework 1, 2006] In which of the following pairs of games the players' preferences\nover lotteries are the same?\n(a)\n\n2 -2 1 1\n-3 7\n1 10\n0 4\n0 4\n-2 1 1 7 -1 -5\n\n12 -1 5 0 -3 2\n5 3\n3 1\n3 1\n-1 0\n5 2 1 -2\n(b)\n\n1 2\n7 0 4 -1\n6 1\n2 2\n8 4\n3 -1 9 2\n5 0\n1 5\n7 1 4 -1\n6 3\n2 4\n8 8\n3 -1 9 5\n5 1\nSolution: Recall from Theorem 2.2 that two utility functions represent the same\npreferences over lotteries if and only if one is an affine transformation of the other.\nThat is, we must have = + for some and where and are the\nutility functions on the left and right, respectively, for each player . In Part 1, the\npreferences of player 1 are different in two games. To see this, note that 1 ( ) =\n0 and 1 ( ) = 3. Hence, we must have = 3. Moreover, 1 ( ) = 1 and\n1 ( ) = 5. Hence, we must have = 2. But then, 1 ( ) + = 7 6=\n12 = 1 ( ), showing that it is impossible to have an affine transformation.\nSimilarly, one can check that the preferences of Player 2 are different in Part 2.\n\n2.5. EXERCISES WITH SOLUTION\nNow, comparisons of payoffs for ( ) and ( ) yield that = 2 and = 1, but\nthen the payoffs for ( ) do not match under the resulting transformation.\n2. [Homework 1, 2011] Alice and Bob want to meet in one of three places, namely\nAquarium (denoted by ), Boston Commons (denoted by ) and a Celtics game\n(denoted by ). Each of them has strategies . If they both play the same\nstrategy, then they meet at the corresponding place, and they end up at different\nplaces if their strategies do not match. You are asked to find a pair of utility\nfunctions to represent their preferences, assuming that they are expected utility\nmaximizers.\nAlice's preferences: She prefers any meeting to not meeting, and she is indiffer\nence towards where they end up if they do not meet. She is indifferent between a\nsituation in which she will meet Bob at , or , or , each with probability 1/3,\nand a situation in which she meets Bob at with probability 1/2 and does not\nmeet Bob with probability 1/2. If she believes that Bob goes to Boston Commons\nwith probability and to the Celtics game with probability 1 - , she weakly\nprefers to go to Boston Commons if and only if ≥ 13.\nBob's preferences: If he goes to the Celtics game, he is indifferent where Alice\ngoes. If he goes to Aquarium or Boston commons, then he prefers any meeting to\nnot meeting, and he is indifferent towards where they end up in the case they do\nnot meet. He is indifferent between playing , , and if he believes that Alice\nmay choose any of her strategies with equal probabilities.\n(a) Assuming that they are expected utility maximizers, find a pair of utility\nfunctions : { }2 → R and : { }2 → R that represent the\npreferences of Alice and Bob on the lotteries over { }2 .\nSolution: Alice's utility function is determined as follows. Since she is indif\nferent between any ( ) with 6= , by Theorem 2.2, one can normalize\nher payoff for any such strategy profile to ( ) = 0. Moreover, since\nshe prefers meeting to not meeting, ( ) 0 for all ∈ { }.\nBy Theorem 2.2, one can also set ( ) = 1 by a normalization. The\nindifference condition in the question can then be written as\n( ) + ( ) + ( ) = ( )\n\nCHAPTER 2. DECISION THEORY\nThe last preference in the question also leads to\n( ) = ( )\nForm the last equality, ( ) = 2, and from the previous displayed equal\nity, ( ) = 6.\nBob's utility function can be obtained similarly, by setting ( ) = 0\nfor any distinct when ∈ { }. The first and the last indifference\nconditions also imply that ( ) 0, and hence one can set ( ) = 1\nfor all ∈ { } by the first indifference. The last indifference then\nimplies that\n( ) = ( ) = ( ) = 1\nyielding ( ) = ( ) = 3.\n(b) Find another representation of the same preferences.\nSolution: By Theorem 2.2, we can find another pair of utility functions by\ndoubling all payoffs.\n(c) Find a pair of utility functions that yield the same preference as and\ndoes among the sure outcomes but do not represent the preferences above.\nSolution: Take ( ) = 60 and ( ) = ( ) = 30 while keep\ning all other payoffs as before. By Theorem 2.1, the preferences among sure\noutcomes do not change, but the preferences among some lotteries change by\nTheorem 2.2.\n3. [Homework 1, 2011] In this question you are asked to price a simplified version of\nmortgage-backed securities. A banker lends money to homeowners, where each\nhomeowner signs a mortgage contract. According to the mortgage contract, the\nhomeowner is to pay the lender 1 million dollar, but he may go bankrupt with\nprobability , in which case there will be no payment. There is also an investor\nwho can buy a contract in which case he would receive the payment from the\nhomeowner who has signed the contract. The utility function of the investor is\ngiven by () = - exp (-), where is the net change in his wealth.\n(a) How much is the investor willing to pay for a mortgage contract?\n\n2.5. EXERCISES WITH SOLUTION\nSolution: He pays a price if and only if [ ( - )] ≥ (0), i.e.,\n-(1 -) exp (- (1 - )) - exp (- (0 - )) ≥-1\nThat is,\n≤ ∗ ≡- ln ( + (1 -) exp (-))\n\nwhere ∗ is the maximum willing to pay.\n(b) Now suppose that the banker can form \"mortgage-backed securities\" by\npooling all the mortgage contracts and dividing them equally. A mortgage\nbacked security yields 1 of the total payments by the homeowners, i.e., if\nhomeowners go bankrupt, a security pays ( -) millions dollar. Assume\nthat homeowners' bankruptcy are stochastically independent from each other.\nHow much is the investor willing to pay for a mortgage-backed security?\nAssuming that is large find an approximate value for the price he is willing\nto pay. [Hint: for large , approximately, the average payment is normally\ndistributed with mean 1 - (million dollars) and variance (1 -) . If\nis normally distributed with mean and variance 2, the expected value of\n¡\n¡\n¢¢\nexp (-) is exp - -2\n1 2 .] How much more can the banker raise by\ncreating mortgage-backed securities? (Use the approximate values for large\n.)\nSolution: Writing for the number of combinations out of , the prob\nability that there are bankruptcies is (1 -)-. If he pays for\na mortgage-backed security, his net revenue in the case of bankruptcies is\n1 - -. Hence, his expected payoff is\n\nX\n-\nexp (- (1 - -)) (1 -)-\n=0\nHe is willing to pay if the above amount is at least -1, the payoff from 0.\nTherefore, he is willing to pay at most\nA\n!\n\nX\n∗ = 1 - 1 ln\nexp () (1 -)-\n\n=0\nFor large ,\n(1 -)\n∗ ∼= 1 -\nln (exp ( ( + (1 -) (2)))) = 1 - -\n\nCHAPTER 2. DECISION THEORY\nNote that he is asking a discount of (1 -) 2 from the expected payoff\nagainst the risk, and behaves approximately risk neutral for large . The\nbanker gets an extra revenue of ∗ - ∗ from creating mortgage-backed se\ncurities. (Check that ∗ - ∗ 0.)\n(c) Answer part (b) by assuming instead that the homeowners' bankruptcy are\nperfectly correlated: with probability all homeowners go bankrupt and with\nprobability 1 - none of them go bankrupt. Briefly compare your answers\nfor parts (b) and (c).\nSolution: With perfect correlation, a mortgage-backed security is equivalent\nto one contract, and hence he is willing to pay at most ∗ . In general, when\nthere is a positive correlation between the bankruptcies of different homeown\ners (e.g. due to macroeconomic conditions), the value of mortgage backed\nsecurities will be less than what it would have been under independence.\nTherefore, mortgage back securities that are priced under the erroneous as\nsumption of independence would be over-priced.\n2.6\nExercises\n1. [Homework 1, 2000] Consider a decision maker with Von Neumann and Morgen\nstren utility function with () = ( -1)2 . Check whether the following VNM\nutility functions can represent this decision maker's preferences. (Provide the de\ntails.)\n(a) ∗ : →\n-1;\n(b) ∗∗ : 7→( -1)4 ;\n(c) ˆ : 7→-( -1)2 ;\n(d) : 7→2 ( -1)2 -1\n2. [Homework 1, 2004] Which of the following pairs of games are strategically equiv\nalent, i.e., can be taken as two different representations of the same decision prob\nlem?\n\n2.6. EXERCISES\n(a)\nL\nR\nL\nR\nT\nT\nB\nB\n2,2 4,0\n3,3 1,0\n-6,4\n0,0\n-3,6 -9,0\n(b)\nL\nR\nL\nR\nT\nT\nB\nB\n2,2 4,0\n3,3 1,0\n4,4 16,0\n9,9\n1,0\n(c)\nL\nR\nL\nR\nT\nT\nB\nB\n2,2 4,0\n3,3 1,0\n4,2 2,0\n3,3 1,0\n3. [Homework 1, 2001] We have two dates: 0 and 1. We have a security that pays a\nsingle dividend, at date 1. The dividend may be either $100, or $50, or $0, each\nwith probability 1/3. Finally, we have a risk-neutral agent with a lot of money.\n(The agent will learn the amount of the dividend at the beginning of date 1.)\n(a) An agent is asked to decide whether to buy the security or not at date 0. If he\ndecides to buy, he needs to pay for the security only at date 1 (not immediately\nat date 0). What is the highest price at which the risk-neutral agent is\nwilling to buy this security?\n(b) Now consider an \"option\" that gives the holder the right (but not obligation)\nto buy this security at a strike price at date 1 - after the agent learns\nthe amount of the dividend. If the agent buys this option, what would be the\nagent's utility as a function of the amount of the dividend?\n(c) An agent is asked to decide whether to buy this option or not at date 0. If he\ndecides to buy, he needs to pay for the option only at date 1 (not immediately\nat date 0). What is the highest price at which the risk-neutral agent is\nwilling to buy this option?\n4. [Homework 1, 2001] Take = R, the set of real numbers, as the set of alternatives.\nDefine a relation o on by\no ⇐⇒ ≥ - 12\nfor all ∈ .\n\nCHAPTER 2. DECISION THEORY\n(a) Is o a preference relation? (Provide a proof.)\n(b) Define the relations A and ∼ by\nA ⇐⇒ [o and o6\n]\nand\n∼ ⇐⇒ [ o and o ]\nrespectively. Is A transitive? Is ∼ transitive? Prove your claims.\n(c) Would o be a preference relation if we had = N, where N = {012} is\nthe set of all natural numbers?\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 2 Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/e9b804c79a1f7536e48295c1e40cf271_MIT14_12F12_slides2.pdf",
      "content": "14.12 Game Theory\nLecture 2: Decision Theory\nMuhamet Yildiz\n\nRoad Map\n1. Basic Concepts (Alternatives, preferences, ... )\n2. Ordinal representation of preferences\n3. Cardinal representation - Expected utility\ntheory\n4. Modeling preferences in games\n5. Applications: Risk sharing and Insurance\n\nBasic Concepts: Alternatives\n- Agent chooses between the alternatives\n- X = The set of all alternatives\n- Alternatives are\n- Mutually exclusive, and\n- Exhaustive\n\nExample\n- Options = {Algebra, Biology}\n- X= {\n- a = Algebra,\n- b = Biology,\n- ab = Algebra and Biology,\n- n = none}\n\nBasic Concepts: Preferences\n- A relation ~ (on X) is any subset of XxX.\n- e.g.,\n~*= {( a,b ),( a,ab ),( a,n),(b,ab ),(b,n),(n,ab)}\n- a ~ b - (a, b) E ~.\n- ~ is complete iff Vx,y E X,\nx~y or y~x.\n- ~ is transitive iff Vx,y,z E X,\n[x~y and y~z] ===? X~Z.\n\nPreference Relation\nDefinition: A relation is a preference relation\niff it is complete and transitive.\n\nExamples\nDefine a relation among the students in this\nclass by\n- x T y iff x is at least as tall as y;\n- x M y iffx's final grade in 14.04 is at least\nas high as y's final grade;\n- x H y iff x and y went to the same high\nschool;\n- x Y y iff x is strictly younger than y;\n- x S y iff x is as old as y;\n\nMore relations\n- Strict preference:\nx > y ~ [ x ~ y and y ';f x ],\n- Indifference:\nx ~ y ~ [ x ~ y and y ~ x].\n\nExamples\nDefine a relation among the students in this\nclass by\n- x T y iff x is at least as tall as y;\n- x Y y iff x is strictly younger than y;\n- x S y iff x is as old as y;\n\nOrdinal representation\nDefinition: ~ represented by u : X ----+ Riff\nx ~ y <=> u(x) > u(y) VX,YEX. (OR)\n\nExample\n'-\n'l\" ** --\n{( a,b ),( a,ab ),( a,n),(b,ab ),(b,n),(n,ab ),( a,a),(b,\nb ),( ab,ab ),(n,n)}\nis represented by u** where\nu**(a) =\nu**(b) =\nu**(ab)=\nu**(n) =\n\nExercises\n- Imagine a group of students sitting around a round\ntable. Define a relation R, by writing x R y iff x sits\nto the right of y. Can you represent R by a utility\nfunction?\n- Consider a relation:;:': among positive real numbers\nrepresented by u with u(x) = x2.\nCan this relation be represented by u*(x) = X1 /2?\nWhat about u**(x) = lIx?\n\nTheorem - Ordinal Representation\nLet X be finite ( or countable). A relation ~ can\nbe represented by a utility function U in the\nsense of (OR) iff ~ is a preference relation.\nIf U: X ---+ R represents ~, and iff: R ---+ R is\nstrictly increasing, thenfcU also represents ~.\nDefinition: ~ represented by u : X --* Riff\nx ~ y <=> u(x) 2: u(y) 'IIX,YEX (OR)\n\nTwo Lotteries\n~\n$ 1000\n1001/\n$1M\n.3\n.007\n.999~\n$0\n\nCardinal representation - definitions\n- Z = a finite set of consequences or prizes.\n- A lottery is a probability distribution on Z.\n- P = the set of all lotteries.\n- A lottery:\n1001/\n$1M\n.007\n.999~\n$0\n\nCardinal representation\n- Von Neumann-Morgenstern representation:\nExpected value of\nu underp\n/\nAlottery ~\n(inP)\nI p>-q ~ LU(Z)p(z) > Lu(z)q(z)\nZEZ\nZEZ\n,\n,\n'~~y~---'\ny\nU(P)\n>\nU(q)\n\nVNMAxioms\nAxiom A1: ~ is complete and transitive.\n\nVNMAxioms\nAxiom A2 (Independence): For any p,q,rEP,\nand any a E (0,1],\nap + (l-a)r > aq + (l-a)r <=> p > q.\nP\nq\n$1000\n.5 ~\n.5\n>\n.~$IM\n.5\n.99999\n$0\n.5\n$100\n>\n.5\n.5\nA trip to Florida\nA trip to Florida\n\nVNMAxioms\nAxiom A3 (Continuity): For any p,q,rEP with\np >- q, there exist a,bE (0,1) such that\nap + (I-a)r >- q & p >- bq + (I-b) r.\n\nTheorem - VNM-representation\nA relation ~ on P can be represented by a\nVNM utility function u : Z ---+ R iff ~\nsatisfies Axioms AI-A3.\nu and v represent ~ iff v = au + b for some\na > 0 and any b.\n\nExercise\n- Consider a relation ~ among positive real\nnumbers represented by VNM utility\nfunction u with u(x) = 2\nx .\nCan this relation be represented by VNM\nutility function u*(x) = x1l2?\nWhat about u**(x) = l /x?\n\nDecisions in Games\n- Outcomes:\nBob\nL\nR\nZ = {TL,TR,BL,BR}\nA lice\n- Players do not know each\nT\nother's strategy\nB\n- p = Pr(L) according to Alice\nT\nTL\nP\nTR\n-p\nBL\no 0\nBR\n\nExample\n- T?= B ~ P > 14; BL ~ BR\n- uA(B,L) = uA(B,R) = 0\n- P uA(T,L) + (l-p) uA(T,R) > 0 ~ p > 14;\n- (114) uA(T,L) + (3/4) uA(T,R) = 0\n- Utility of A:\nL\nR\nT\n-1\nB\n\nAttitudes towards Risk\n- A fair gamble:\n~--\nx\npx+(1-p)y = O.\nI-p\nY\n- An agent is risk neutral iff\nhe is indifferent towards all fair gambles.\n- He is (strictly) risk averse iff\nhe never wants to take any fair gamble.\n- He is (strictly) risk seeking iff\nhe always wants to take fair gambles.\n\n- An agent is risk-neutral iffhis utility function is\nlinear, i.e., u(x) = ax + h.\n- An agent is risk-averse iff his utility function is\nconcave.\n- An agent is risk-seeking iff his utility function is\nconvex.\n\nRisk Sharing\n- Two agents, each having a utility function u\nwith u(x)= -f; and an \"asset:\" .~\n~\n$100\n---. $0\n.5\n- For each agent, the value ofthe asset is\n5.\n- Assume that the outcomes of assets are\nindependently distributed.\n\n- If they form a mutual fund so that each\nagent owns half of each asset, each gets\n~\n$ 100\no---,,-,-,\n~\n1I2=--. $50\n$0\n-The Value of the mutual fund for an agent is\n(1/4)(100)1 /2 + (1/2)(50)1 /2 + (1/4)(0)1 /2\n:::: 10/4 + 712 = 6\n\nInsurance\n- We have an agent with u(x) = X1l2 and\n$IM\n--\n.5\n$0\n- And a risk-neutral insurance company with\nlots of money, selling full insurance for\n\"premium\" P.\n\nInsurance -continued\n- The agent is willing to pay premium PA\nwhere\n(1M-P )1 /2 > (1/2)(1M) 1/2 + (1/2)(0) 112\nA\n= 500\n1.e.,\nPA < $lM - $250K = $750K.\n- The company is willing to accept premium\nPI > (1I2)(1M) = $500K.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 3 Lecture Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/b90ef0b930888cc7a1828d5eaf91f5c9_MIT14_12F12_chapter3.pdf",
      "content": "Chapter 3\nRepresentation of Games\nWe are now ready to formally introduce games and some fundamental concepts, such as\na strategy. In order to analyze a strategic situations, one needs to know\n- who the players are,\n- which actions are available to them,\n- how much each player values each outcome,\n- what each player knows.\nA game is just a formal representation of the above information. This is usually done\nin one of the following two ways:\n1. The extensive-form representation, in which the above information is explicitly\ndescribed using game trees and information sets;\n2. The normal-form (or strategic-form) representation, in which the above informa\ntion is summarized by use of strategies.\nBoth forms of representation are useful in their on way, and I will use both representa\ntions extensively throughout the course.\nIt is important to emphasize that, when describing what a player knows, one needs to\nspecify not only what he knows about external parameters, such as the payoffs, but also\nwhat he knows about the other players' knowledge and beliefs about these parameters,\n\nCHAPTER 3. REPRESENTATION OF GAMES\nas well as what he knows about the other players' knowledge of his own beliefs, and so\non. In both representations such information is encoded in an economical manner. In the\nfirst half of this course, we will focus on non-informational issues, by confining ourselves\nto the games of complete information, in which everything that is known by a player is\nknown by everybody. In the second half, we will focus on informational issues, allowing\nplayers to have asymmetric information, so that one may know a piece of information\nthat is not known by another.\nThe outline of this lecture is as follows. The first section is devoted to the extensive-\nform representation of games. The second section is devoted to the concept of strategy.\nThe third section is devoted to the normal-form representation, and the equivalence\nbetween the two representations. The final section contains exercises and some of their\nsolutions.\n3.1\nExtensive-form Representation\nThe extensive-form representation of a game contains all the information about the game\nexplicitly, by defining who moves when, what each player knows when he moves, what\nmoves are available to him, and where each move leads to, etc. This is done by use of a\ngame tree and information sets-as well as more basic information such as players and\nthe payoffs.\n3.1.1\nGame Tree\nDefinition 3.1 A tree is a set of nodes and directed edges connecting these nodes such\nthat\n1. there is an initial node, for which there is no incoming edge;\n2. for every other node, there is exactly one incoming edge;\n3. for any two nodes, there is a unique path that connect these two nodes.\nFor a visual aid, imagine the branches of a tree arising from its trunk. For example,\nthe graph in Figure 3.1 is a tree. There is a unique starting node, and it branches out\nfrom there without forming a loop. It does look like a tree. On the other hand, the\n\n3.1. EXTENSIVE-FORM REPRESENTATION\ngraphs in Figure 3.2 are not trees. In the graph on the left-hand side, there are two\nalternative paths to node A from the initial node, one through node B and one through\nnode C. This violates the third condition. (Here, the second condition in the definition is\nalso violated, as there are two incoming edges to node A.) On the right-hand side, there\nis no path that connects the nodes x and y, once again violating the third condition.\n(Once again, the second condition is also violated.)\nFigure 3.1: A tree.\nx\nA\nB\nC\ny\nFigure 3.2: Two graphs that are not a tree\nNote that edges (or arrows) come with labels, which can be same for two different\narrows. In a game tree there are two types of nodes, terminal nodes, at which the game\nends, and non-terminal nodes, at which a player would need to make a further decision.\nThis is formally stated as follows.\nDefinition 3.2 The nodes that are not followed by another node are called terminal.\n\nCHAPTER 3. REPRESENTATION OF GAMES\nThe other nodes are called non-terminal.\nTerminal Nodes\nNon-terminal\nnodes\nFigure 3.3: Terminal and non-terminal nodes.\nFor example, the terminal and non-terminal nodes for the game tree in Figure 3.1\nare as in Figure 3.3. There is no outgoing arrow in any terminal node, indication that\nthe game has ended. A terminal node may also be referred to as an outcome in the\ngame. At such a node, we need to specify the players' payoffs towards describing their\npreferences among the outcomes. On the other hand, there are some outgoing arrows in\nany non-terminal node, indicating that some further decisions are to be made. In that\ncase, on needs to describe who makes a decision and what he knows at the time of the\ndecision. A game is formally defined just like this, next.\n3.1.2\nGames in Extensive Form\nDefinition 3.3 (Extensive form) A Game consists of\n- a set of players,\n- a tree,\n\n3.1. EXTENSIVE-FORM REPRESENTATION\n- an allocation of non-terminal nodes of the tree to the players,\n- an informational partition of the non-terminal nodes (to be made precise in the\nnext subsection), and\n- payoffs for each player at each terminal node.\nPlayers The set of players consists of the decision makers or actors who make some\ndecision during the course of the game. Some games may also contain a special player\nNature (or Chance) that represent the uncertainty the players face, as it will be explained\nin Subsection 3.1.4. The set of games is often denoted by\n= {12}\nand ∈ are designated as generic players.\nOutcomes and Payoffs The set of terminal nodes often denoted by . At a terminal\nnode, the game has ended, leading to some outcome. At that point, one specifies a\npayoff, which is a real number, for each player . The mapping\n: → R\nthat maps each terminal node to the payoff of player at that node is the Von-Neumann\nand Morgenstern utility function of player . Recall from the previous chapter that this\nmeans that player tries to maximize the expected value of . That is, given any two\nlotteries and on , he prefers to if and only if leads to a higher expected value for\nP\nP\nfunction than does, i.e.,\n() () ≥\n() (). Recall also that these\n∈\n∈\npreferences do not change if we multiply all payoffs with a fixed positive number or add a\nfixed number to all payoffs. The preferences do change under any other transformation.\nDecision Nodes In a non-terminal node, a new decision is to be made. Hence, in the\ndefinition of a game, a player is assigned to each non-terminal node. This is the player\nwho will make the decision at that point. Towards describing the decision problem of\nthe player at the time, one defines the available choices to the player at the moment.\nThese are the outgoing arrows at the node, each of them leading to a different node.\nEach of these choices is also called move or action (interchangeably). Note that the\n\nCHAPTER 3. REPRESENTATION OF GAMES\nmoves come with their labels, and two different arrows can have the same label. In that\ncase, they are the same move.\nHead\nTail\nhead\ntail\nhead\ntail\n(-1,1)\n(1,-1)\n(1,-1)\n(-1,1)\nFigure 3.4: Matching Pennies with Perfect Information\nExample 3.1 (Matching Pennies with Perfect Information) Consider the game\nin Figure 3.4.The tree consists of 7 nodes. The first one is allocated to Player 1, and\nthe next two to Player 2.\nThe four end-nodes have payoffs attached to them.\nSince\nthere are two players, payoff vectors have two elements. The first number is the payoff\nof Player 1 and the second is the payoff of Player 2. These payoffs are von Neumann-\nMorgenstern utilities. That is, each player tries to maximize the expected value of his\nown payoffs given his beliefs about how the other players will play the game.\nOne also needs to describe what the player knows at the moment of his decision\nmaking. This is formally done by information sets, as follows.\n3.1.3\nInformation Sets\nDefinition 3.4 An information set is a collection of nodes such that\n1. the same player is to move at each of these nodes;\n2. the same moves are available at each of these nodes.\nDefinition 3.5 An information partition is an allocation of each non-terminal node of\nthe tree to an information set; the starting node must be \"alone\".\n\n3.1. EXTENSIVE-FORM REPRESENTATION\nThe meaning of an information set is that when the individual is in that information\nset, he knows that one of the nodes in the information set is reached, but he cannot\nrule out any of the nodes in the information set. Moreover, in a game, the information\nset belongs to the player who is to move in the given information set, representing his\nuncertainty. That is, the player who is to move at the information set is unable to\ndistinguish between the points in the information set, but able to distinguish between the\npoints outside the information set from those in it. Therefore, the above definition would\nbe meaningless without condition 1, while condition 2 requires that the player knows his\navailable choices. The latter condition can be taken as a simplifying assumption. I also\nrefer to information sets as history and write for a generic history at which player\nmoves.\nFor an example, consider the game in Figure 3.5. Here, Player 2 knows that Player\n1 has taken action or and not action ; but Player 2 cannot know for sure whether\n1 has taken or .\nx\nT\nB\nL\nR\nL\nR\nFigure 3.5: A game\nExample 3.2 (Matching Pennies with Perfect Information) In Figure 3.4, the\ninformational partition is very simple. Every information set has only one element.\nHence, there is no uncertainty regarding the previous play in the game.\n1Throughout the course, the information sets are depicted either by circles (as in sets), or by dashed\ncurves connecting the nodes in the information sets, depending on convenience. Moreover, the informa\ntion sets with only one node in them are depicted in the figures. For example, in Figure 3.5, the initial\nnode is in an information set that contains only that node.\n\nCHAPTER 3. REPRESENTATION OF GAMES\nA game is said to have perfect information if every information set has only one\nelement. Recall that in a tree, each node is reached through a unique path. Hence,\nin a perfect-information game, a player can construct the previous play perfectly. For\ninstance in Figure 3.4, Player 2 knows whether Player 1 chose Head or Tail. And Player\n1 knows that when he plays Head or Tail, Player 2 will know what Player 1 has played.\n3.1.4\nNature as a player and representation of uncertainty\nThe set of players includes the decision makers taking part in the game. However, in\nmany games there is room for chance, e.g. the throw of dice in backgammon or the card\ndraws in poker. More broadly, the players often face uncertainty about some relevant\nfact, including what the other players know. In that case, once again chance plays a role\n(as a representation). To represent these possibilities we introduce a fictional player:\nNature. There is no payoff for Nature at end nodes, and every time a node is allocated\nto Nature, a probability distribution over the branches that follow needs to be specified,\ne.g., Tail with probability of 1/2 and Head with probability of 1/2. Note that this is the\nsame as adding lotteries in the previous section to the game.\nFor an example, consider the game in Figure 3.6. In this game, a fair coin is tossed,\nwhere the probability of Head is 1/2. If Head comes up, Player 1 chooses between Left\nand Right; if Tail comes up, Player 2 chooses between Left and Right. The payoffs also\ndepend on the coin toss.\n(5, 0)\nLeft\nHead\n1/2\nRight\n(2, 2)\nNature\n(3, 3)\n1/2\nLeft\nTail\nRight\n(0, -5)\nFigure 3.6: A game with chance\n\n3.1. EXTENSIVE-FORM REPRESENTATION\n3.1.5\nCommonly Known Assumptions\nThe structure of a game is assumed to be known by all the players, and it is assumed\nthat all players know the structure and so on. That is, in a more formal language, the\nstructure of game is common knowledge.2 For example, in the game of Figure 3.5, Player\n1 knows that if he chooses or , Player 2 will know that Player 1 has chosen one of the\nabove actions without being able to rule out either one. Moreover, Player 2 knows that\nPlayer 1 has the above knowledge, and Player 1 knows that Player 2 knows it, and so\non. Using information sets and richer game trees, one can model arbitrary information\nstructures like this. For example, one could also model a situation in which Player 1\ndoes not know whether Player 2 could distinguish the actions and . One could do\nthat by having three information set for Player 2; one of them is reached only after ,\none of them is reached only after and one of them can be reached after both and .\nTowards modeling uncertainty of Player 1, one would further introduce a chance move,\nwhose outcome either leads to the first two information sets (observable case) or to the\nlast information case (unobservable case).\nExercise 3.1 Write the variation of the game in Figure 3.5, in which Player 1 believes\nthat Player 2 can distinguish actions and with probability 13 and cannot distinguish\nthem probability 23, and this beliefs is common knowledge.\nTo sum up:\nAt any node, the following are known: which player is to move, which\nmoves are available to the player, and which information set contains the node, sum\nmarizing the player's information at the node. Of course, if two nodes are in the same\ninformation set, the available moves in these nodes must be the same, for otherwise the\nplayer could distinguish the nodes by the available choices. Again, all these are assumed\nto be common knowledge.\n2Formally, a proposition is said to be common knowledge if all of the following are true: is\ntrue; everybody knows that is true; everybody knows that everybody knows that is true; . . . ;\neverybody knows that . . . everybody knows that is true, ad infinitum.\n\nCHAPTER 3. REPRESENTATION OF GAMES\n3.2\nStrategies\nDefinition 3.6 A strategy of a player is a complete contingent-plan determining which\naction he will take at each information set he is to move (including the information sets\nthat will not be reached according to this strategy). More mathematically, a strategy of a\nplayer is a function that maps every information set of player to an action that\nis available at .\nIt is important to note the following three subtleties in the definition.\n1. One must assign a move to every information set of the player. (If we omit to\nassign a move for an information set, we would not know what the player would\nhave done when that information set is reached.)\n2. The assigned move must be available at the information set. (If the assigned move\nis not available at an information set, then the plan would not be feasible as it\ncould not be executed when that information set is reached.)\n3. At all nodes in a given information set, the player plays the same move. (After\nall, the player cannot distinguish those nodes from each other.)\nExample 3.3 (Matching Pennies with Perfect Information) In Figure 3.4, Player\n1 has only one information set. Hence, the set of strategies for Player 1 is {Head, Tail}.\nOn the other hand, Player 2 has two information sets. Hence, a strategy of Player 2\ndetermines what to do at each information set, i.e., depending on what Player 1 does.\nSo, her strategies are:\n= Head if Player 1 plays Head, and Head if Player 1 plays Tail;\n= Head if Player 1 plays Head, and Tail if Player 1 plays Tail;\n= Tail if Player 1 plays Head, and Head if Player 1 plays Tail;\n= Tail if Player 1 plays Head, and Tail if Player 1 plays Tail.\nExample 3.4 In Figure 3.5, both players have one information set. Hence, the sets of\nstrategies for Players 1 and 2 are\n1 = {} and 2 = {}\n\n3.2. STRATEGIES\nrespectively. Although Player 2 moves at two different nodes, they are both in the same\ninformation set. Hence, she needs to either play at both nodes or at both nodes.\nFor certain purposes it might suffice to look at the reduced-form strategies. A re\nduced form strategy is defined as an incomplete contingent plan that determines which\naction the agent will take at each information set he is to move and that has not been\nprecluded by this plan. But for many other purposes we need to look at all the strategies.\nThroughout the course, we must consider all strategies.\nWhat are the outcomes of strategies of players? What are the payoffs generated by\nthose strategies? Towards answering these questions, we need first a couple of jargon.\nDefinition 3.7 In a game with players = {1}, a strategy profile is a list\n= (1)\nof strategies, one for each player.\nDefinition 3.8 In a game without Nature, each strategy profile leads to a unique\nterminal node (), called the outcome of . The payoff vector from strategy is the\npayoff vector at ().\nSometimes the outcome is also described by the resulting history, which can also be\ncalled as the path of play.\nExample 3.5 (Matching Pennies with Perfect Information) In Figure 3.4, if Player\n1 plays Head and Player 2 plays , then the outcome is\nboth players choose Head,\nand the payoff vector is (-11). If Player 1 plays Head and Player 2 plays , the\noutcome is the same, yielding the payoff vector (-11). If Player 1 plays Tail and\nPlayer 2 plays HT, then the outcome is now\nboth players choose Tail,\nbut the payoff vector is (-11) once again. Finally, if Player 1 plays Tail and Player 2\nplays , then the outcome is\nPlayer 1 chooses Tail and Player 2 chooses Head,\n\nCHAPTER 3. REPRESENTATION OF GAMES\nand the payoff vector is (1-1). One can compute the payoffs for the other strategy\nprofiles similarly.\nIn games with Nature, a strategy profile leads to a probability distribution on the set\nof terminal nodes. The outcome of the strategy profile is then the resulting probability\ndistribution. The payoff vector from the strategy profile is the expected payoff vector\nunder the resulting probability distribution.\nExample 3.6 (A game with Chance) In Figure 3.5, each player has two strategies,\nLeft and Right. The outcome of the strategy profile (Left,Left) is the lottery that\nNature chooses Head and Player 1 plays Left\nwith probability 1/2 and\nNature chooses Tail and Player 2 plays Left\nwith probability 1/2. Hence, the expected payoff vector is\n() = (50) +\n(33) = (432)\nSometimes, it suffices to summarize all of the information above by the set of strate\ngies and the utility vectors from the strategy profiles, computed as above. Such a\nsummary representation is called formal-form or strategic-form representation.\n3.3\nNormal form\nDefinition 3.9 (Normal form) A game is any list\n= (1; 1)\nwhere, for each ∈ = {1}, is the set of all strategies that are available to\nplayer , and\n: 1 × × → R\nis player 's von Neumann-Morgenstern utility function.\n\n3.3. NORMAL FORM\nNotice that a player's utility depends not only on his own strategy but also on the\nstrategies played by other players. Moreover, each player tries to maximize the expected\nvalue of (where the expected values are computed with respect to his own beliefs); in\nother words, is a von Neumann-Morgenstern utility function. We will say that player\nis rational iff he tries to maximize the expected value of (given his beliefs).\nIt is also assumed that it is common knowledge that the players are = {1},\nthat the set of strategies available to each player is , and that each tries to maximize\nexpected value of given his beliefs.\nWhen there are only two players, we can represent the normal form game by a\nbimatrix (i.e., by two matrices):\n1\\2\n\n0 2\n1 1\n4 1\n3 2\nHere, Player 1 has strategies and , and Player 2 has the strategies and\n. In each box the first number is Player 1's payoff and the second one is Player 2's\npayoff (e.g., 1 ( ) = 0, 2 ( ) = 2.)\n3.3.1\nFrom Extensive Form to Normal Form\nAs it has been described in detail in the previous section, in an extensive form game, the\nset of strategies is the set of all complete contingent plans, mapping information sets to\nthe available moves. Moreover, each strategy profile leads to an outcome (), which\nis in general probability distribution on the set of terminal nodes. The payoff vector is\nthe expected payoff vector from (). One can always convert an extensive-form game\nto a normal form game in this way.\nExample 3.7 (Matching Pennies with Perfect Information) In Figure 3.4, based\non the earlier analyses, the normal or the strategic form game corresponding to the\nmatching penny game with perfect information is\n\n-1 1 -1 1 1 -1 1 -1\n1 -1 -1 1 1 -1 -1 1\n\nCHAPTER 3. REPRESENTATION OF GAMES\nHead\nTail\nhead\ntail\nhead\ntail\n(-1,1)\n(1,-1)\n(1,-1)\n(-1,1)\nFigure 3.7: Matching Pennies Game\nInformation sets are very important. To see this, consider the following standard\nmatching-penny game. This game has imperfect information.\nExample 3.8 (Matching Pennies) Consider the game in Figure 3.7. This is the\nstandard matching penny game, which has imperfect information as the players move\nsimultaneously. In this game, each player has only two strategies: Head and Tail. The\nnormal-form representation is\n1\\2\nhead\ntail\n\nHead -1 1 1 -1\nTail\n1 -1 -1 1\nThe two matching penny games may appear similar (in extensive form), but they\ncorrespond to two distinct situations. Under perfect information Player 2 knows what\nPlayer 1 has done, while nobody knows about the other player's move under the version\nwith imperfect information.\nAs mentioned above, when there are chance moves, one needs to compute the ex\npected payoffs in order to obtain the normal-form representation. This is illustrated in\nthe next example.\nExample 3.9 (A game with Nature) As mentioned, in Figure 3.6, each player has\ntwo strategies, Left and Right. Following the earlier calculations, the normal-form rep\n\n3.3. NORMAL FORM\nHH\nHT\nTH\nTT\nH\nT\nH\nT\n‐1\n‐1\nH\nT\nH\nT\n‐1\n‐1\n‐1\n‐1\n‐1\n‐1\nFigure 3.8: A matching penny game with perfect information?\nresentation is obtained as follows:\n1\\2\nLeft\nRight\n\nLeft\n4 32\n52 -52\nRight 52 52\n1 -32\nThe payoff from (Left,Left) has been computed already. The payoff from (Left, Right)\ncomputed as\n(5 0) +\n(0 -5) = (52 -52)\nWhile there is a unique normal-form representation for any extensive-form game (up\nto a relabeling of strategies), there can be many extensive-form games with the same\nnormal-form representation. After all, any normal-form game can also be represented\nas a simultaneous action game in extensive form. For example, the normal-form game\nof matching pennies with perfect information can also be represented as in Figure 3.8.\n3.3.2\nMixed Strategies\nIn many cases a player may not be able to guess exactly which strategies the other\nplayers play. In order to cover these situations we introduce the mixed strategies:\nDefinition 3.10 A mixed strategy of a player is a probability distribution over the set\nof his strategies.\n\nCHAPTER 3. REPRESENTATION OF GAMES\nIf player has strategies = {12}, then a mixed strategy for player\nis a function on such that 0 ≤ ( ) ≤ 1 and\n(1) + (2) + · · · + () = 1\nThere are many interpretations for mixed strategies, from deliberate randomization (as\nin coin tossing) to heterogeneity of strategies in the population. In all cases, however,\nthey serve as a device to represent the uncertainty the other players face regarding the\nstrategy played by player . Throughout the course, is interpreted as the other players'\nbeliefs about the strategy player plays.\n3.4\nExercises with Solutions\n1. What is the normal-form representation for the game in Figure 3.12?\nSolution: Player 1 has two information sets with two action in each. Since the set\nof strategies is functions that map information sets to the available moves, he has\nthe following four strategies: . The meaning here is straightforward:\nassigns to the first information set and to the last information set. On the\nother hand, Player 2 has only two strategies: and . Filling in the payoffs from\nthe tree, one obtains the following normal-form representation:\n1\\2\n\n1-5 52\n2. [Midterm 1, 2001] Find the normal-form representation of the game in Figure 3.9.\n\n3.4. EXERCISES WITH SOLUTIONS\nFigure 3.9:\nSolution:\n1\\2\n\n2 1 2 1 2 1\n2 1 2 1 2 1\n2 1 2 1 2 1\n2 1 2 1 2 1\n1 2 3 1 1 3\n1 2 3 1 3 1\n1 2 1 3 1 3\n1 2 1 3 3 1\n3. [Make up for Midterm 1, 2007] Write the game in Figure 3.10 in normal form.\nSolution: The important point in this exercise is that Player 2 has to play the same\nmove in a given information set. For example, she cannot play on the left node\nand on the right node of her second information set. Hence, her set of strategies\nis { }.\n\n3 3 3 3\n0 0\n0 0\n3 3 3 3\n0 0\n0 0\n0 0 0 0\n3 3\n3 3\n0 0 0 0\n3 3\n3 3\n2 2 2 2 1 -1 -1 3\n2 2 2 2 -1 1 1 -1\n\nCHAPTER 3. REPRESENTATION OF GAMES\nA\nc\nB\nb\na\nb\na\nb\na\nX\nY\nx\ny\nx\ny\n‐1\n‐1\n‐1\n‐1\nFigure 3.10:\n4. [Make up for Midterm 1, 2007] Write the following game in normal form, where\nthe first entry is the payoff of student and the second entry is the payoff of Prof.\nhealthy\nsick\n.5\n.5\nstudent\nregular\nMake up\nstudent\nregular\nMake up\nProf\nsame\nnew\nsame\nnew\n-1\n-1\n-c\n-c\nhealthy\nsick\n.5\n.5\nstudent\nregular\nMake up\nstudent\nregular\nMake up\nProf\nsame\nnew\nsame\nnew\n-1\n-1\n-c\n-c\nSolution: Write the strategies of the student as , , , and , where\nmeans Regular when Healthy and Make up when Sick, means Make up\n\n3.5. EXERCISES\nFigure 3.11:\nwhen Healthy and Regular when Sick, etc. The normal form game is as follows:\nStudent\\Prof\nsame\nnew\n\n1 0\n1 0\n3 12\n32 (1 - ) 2\n2 -1\n12 -(1 + )2\n4 -12\n1 -\nHere, the payoffs are obtained by taking expectations over whether the student\nis healthy or sick. For example, leads to (2 1) and (0 -1) with equal prob\nabilities, yielding (1 0), regardless of the strategy of Prof. On the other hand,\n( new) leads to (2 1) and (1 -) with equal probabilities, yielding (32 (1 - ) 2).\n5. [Midterm 2006] Write the game in Figure 3.11 in normal form.\nSolution:\n1\\2\n\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n3 2\n3 2\n3 2\n3 2\n3 1\n3 1\n0 0\n0 0\n0 0\n0 0\n0 0\n0 0\n0 -1\n2 3\n0 -1\n2 3\n3.5\nExercises\n1. [Midterm 1, 2010] Write the game in Figure 3.13 in normal form.\n\nCHAPTER 3. REPRESENTATION OF GAMES\nD\n(4,4)\nA\nδ\n(5,2)\nα\na\nd\n(3,3)\n(1,-5)\nFigure 3.12: A centepede-like game\nFigure 3.13:\n\n3.5. EXERCISES\n2. [Midterm 1, 2005] Write the game in Figure 3.14 in normal form.\n3. [Midterm 1, 2004] Write the game in Figure 3.15 in normal form.\nFigure 3.14:\n4. [Midterm 1, 2007] Write the following game in normal form.\nFigure 3.15:\n\nCHAPTER 3. REPRESENTATION OF GAMES\nFigure 3.16:\n5. [Homework 1, 2011] Find the normal-form representation of the extensive-form\ngame in Figure 3.16.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 3 Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/639bdf709a7bfa2fea2047244a6bfa73_MIT14_12F12_slides3.pdf",
      "content": "Lecture 3\nRepresentation of Games\n14.12 Game Theory\nMuhamet Yildiz\n\nGame: Ingredients\n- Who are the players (decision makers)?\n- What moves are available to each player\nand when?\n- What does each player know at the time of\neach of his decisions?\n- What are the outcomes and payoffs at the\nend?\n\nRoad Map\n1. Extensive form representation\n2. Strategy\n3. Normal form representation\n4. Mixed strategy\n\nExtensive-form representation\nDefinition: A tree is a set of nodes connected with\ndirected arcs such that\n1.\nThere is an initial node;\n2.\nFor each other node, there is one incoming arc;\n3.\neach node can be reached through a unique path.\n\nA tree\n/ ... -- ... -,\nr\nI\nNon-terminal\nI\n\\\nrm\nnodes\n/\nll..lIe\n___ ina_ I_N_o_d_es ....\nI\n,\n\\ ,\n\\\nI\nI\nI\nI , -, ,\n\nExtensive form - definition\nDefinition: A game consists of\n- a set of players\n- a tree\n- an allocation of each non-terminal node to a\nplayer\n- an informational partition (to be made precise)\n- a payoff for each player at each terminal node.\n\nInformation set\nAn information set is a collection of nodes\nsuch that\n1. The same player is to move at each of\nthese nodes;\n2. The same moves are available at each of\nthese nodes.\nAn informational partition is an allocation\nof each non-terminal node of the tree to an\ninformation set.\n\nA game\nL\nR\n(2,2)\nI\nr\nu\n(0,0)\nA\np\np\n(1,3)\n(3, 1)\n(3,3)\n(1, I)\n\nAnother game\nx\nT\nB\nL\nR\nR\nL\n\nThe Same Game\nx\nT\nB\nL\nR\n\nWhat is wrong?\nx\nT\nB\nUp\nL\nR\nR\nL\n\nWhat is wrong?\nx\nT\nB\nL\nR\nR\nL\n\nWhat is wrong?\nA\nB\n\nStrategy\nA strategy of a player is a complete\ncontingent-plan, determining which action\nhe will take at each information set he is to\nmove (including the information sets that\nwill not be reached according to this\nstrategy).\n\nMatching pennies with perfect information\n2's Strategies:\nHH = Head if 1 plays Head,\nHead if 1 plays Tail;\nHT = Head if I plays Head,\nHead\nTail\nTail if 1 plays Tail;\nTH = Tail if 1 plays Head,\nHead if 1 plays Tail;\nhead\ntail\nhead\ntail\nTT = Tail if 1 plays Head,\nTail if 1 plays Tail.\n(-1,1)\n(1,-1)\n(1,-1)\n(-1,1)\n\nMatching pennies with perfect information\nHH\nHT\nTH\nTT\nQ\nQ\nQ\nQ\nHead (-1,1) -1,1)\n(1,-1) (1,-1)\nQ\nQ\nQ\nQ\nTail\n(1,-1) -1,1)\n(1,-1) (-1,1)\nHead\nTai\nhead\nhead\ntail\n(-1 ,1)\n(1,-1)\n(1,-1)\n(-1,1)\n\nN ormal-form representation\nDefinition (Normal form): A game is any list\nG = (Sp ... ' Sn; up \"\n, ,uJ\nwhere, for each i E N = {1,2, ... , n} ,\n- S; is the set of all strategies available to i,\n- u\n: SI x·· · X Sn ---t 9t is the VNM utility function of\ni\nplayer i.\nAssumption: G is \"common knowledge\".\nDefinition: A player i is rational iff he tries to\nmaximize the expected value of U ; given his beliefs.\n\nAn illus\nt\nra\ntion of chi\nckens\nan d t\nhe\nheads of\nl ions\n.\nImage by MIT OpenCourseWare.\n\nMatching pennies\nHead\nTail\nHead\n(-1,1)\n(1,-1)\nTail\n(1,-1)\n(-1,1)\n\nExtensive v. Normal Forms\n- Extensive to Normal:\n- Find the set of strategies for each player\n- Every strategy profile s leads to an outcome\nz( s), a terminal history\n- Utility from s is u(z(s))\n- Normal to Extensive: many possibilities\n\nMatching pennies with perfect information\nHH\nHT\nTH\nTT\nQ\nQ\nQ\nQ\nHead (-1,1) -1,1)\n(1,-1) (1,-1)\nQ\nQ\nQ\nQ\nTail\n(1,-1) -1,1)\n(1,-1) (-1,1)\nHead\nTai\nhead\nhead\ntail\n(-1 ,1)\n(1,-1)\n(1,-1)\n(-1,1)\n\nMatching pennies with imperfect\ninformation\nI\nHead\nTail\nHead\nTail\nHead\n(-1,1)\n(1,-1)\nhead\ntail\nTail\n(1,-1)\n(-1,1)\n(-1,1)\n(1,-1)\n(1,-1)\n(-1,1)\n\nA game\nA\na\na\n,-------------,-------,---~ (1,-5)\nD\nd\n(4,4)\n(5,2)\n(3,3)\n\nA game with nature\n(5,0)\nLeft\nHead\nRight\n(2,2)\nNature 0\n(3,3)\nLeft\nTail\nRight\n(0, -5)\n\nMixed Strategy\nDefinition: A mixed strategy of a player is a\nprobability distribution over the set of his strategies.\nPure strategies: Si = {Sil ,Si2\" .. ,Sik}\nA mixed strategy: cri: Si --* [0,1] S.t.\ncri(Sij) + cri(Si2) + ... + crlsik) = 1.\nIf the other players play S_i =(Sj, ... , Si_j,si+j\"\",sn), then\nthe expected utility of playing cri is\ncrlSij)Ui(Sij,SJ + crlsi2) UlSi2,SJ + ... + cri(Sik) UlSik,SJ.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 4 Lecture Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/0136e76dcd45a6f1d7b386c563452ff0_MIT14_12F12_chapter4.pdf",
      "content": "Chapter 4\nDominance\nThe previous lectures focused on how to formally describe a strategic situation. We now\nstart analyzing strategic situations in order to find which outcomes are more reasonable\nand likely to realize. In order to do that, we consider certain sets of assumptions about\nthe players' beliefs and discover their implications on what they would play. Such analy\nses will lead to solution concepts, which yield a set of strategy profiles1. These are the\nstrategy profiles deemed to be possible by the solution concept. This lecture is devoted\nto two solution concepts: dominant strategy equilibrium and rationalizability. These\nsolution concepts are based on the idea that a rational player does not play a strategy\nthat is dominated by another strategy.\n4.1\nRationality and Dominance\nA player is said to be rational if and only if he maximizes the expected value of his\npayoffs (given his beliefs about the other players' strategies). For example, consider the\nfollowing game.\n1\\2\n\n(4.1)\n\n2 0\n-1 1\n0 10\n0 0\n-1 -6\n2 0\n1A strategy profile is a list of strategies, prescribing a strategy for each player.\n\nCHAPTER 4. DOMINANCE\nConsider Player 1. He is contemplating about whether to play , or , or . A quick\ninspection of his payoffs reveals that his best play depends on what he thinks the other\nplayer does. Let's then write for the probability he assigns to (as Player 2's play).\nThen, his expected payoffs from playing , , and are\n=\n2- (1 - ) = 3- 1\n\n=\n\n= -+ 2(1 - ) = 2 - 3\nrespectively. These values as a function of are plotted in Figure 4.1. As it is clear\nfrom the graph, is the largest when 12, and is the largest when 12. At\n= 12, = 0. Hence, if player 1 is rational, then he plays when 12,\nwhen 12, and or when = 12. Notice that, if Player 1 is rational, then he\nnever plays -no matter what he believes about the strategy of Player 2. Therefore,\nif we assume that Player 1 is rational (and that the game is as it is described above),\nthen we can conclude that Player 1 does not play . This is because is a strictly\ndominated strategy, a concept that we define now.\n-1\nU\nUM\nUT\nUB\np\nFigure 4.1: Expected payoffs in (4.1) as a function of probability of .\nTowards describing this idea more generally and formally, let us use the notation -\n\n4.1. RATIONALITY AND DOMINANCE\nto mean the list of strategies played by all the players other than , i.e.,\n- = (1-1+1)\nDefinition 4.1 A strategy ∗\nstrictly dominates if and only if\n(\n∗ -) (-)∀- ∈ -\nThat is, no matter what the other players play, playing ∗\nis strictly better than\nplaying for player . In that case, if is rational, he would never play the strictly\ndominated strategy . That is, there is no belief under which he would play , for ∗\n\nwould always yield a higher expected payoff than no matter what player believes\nabout the other players.2\nA mixed strategy dominates a strategy in a similar way: strictly dominates\nif and only if\n(1)(1-) + (2)(2-) + · · · ()(-) (-)∀- ∈ -\nNotice that neither of the pure strategies , , and dominates any strategy.\nNevertheless, is dominated by the mixed strategy that 1 that puts probability 1/2\non each of and . For each , the payoff from 1 is\n1 = (3- 1) + (2 - 3) =\nwhich is larger than 0, the payoff from . Recall that is a best response to any .\nThis is indeed a general result. Towards stating the result, I introduce a couple of\nbasic concepts. Write\nY\n- =\n\n6=\nfor the set of other players' strategies, and define a belief of player as a probability\ndistribution - on -.\nDefinition 4.2 For any player , a strategy is a best response to - if and only if\n(-) ≥ (0\n-)\n∀0\n∈\n2As a simple exercise, prove this statement.\n\nCHAPTER 4. DOMINANCE\nA strategy is said to be a best response to a belief - if and only if playing yields\nthe highest expected payoff under -, i.e.,\nX\nX\n(-) - (-) ≥\n(0\n-) - (-)\n∀0\n∈\n-∈-\n-∈-\nThe concept of a best response is one of the main concepts in game theory, used\nthroughout the course. It is important to understand the definition well and be able to\ncompute the best response in relatively simple games, as those covered in this class. A\nrational player can play a strategy under a belief only if it is a best response to that\nbelief.\nTheorem 4.1 A strategy is a best response to some belief if and only if is not\ndominated.3 Therefore, playing strategy is never rational if and only if is dominated\nby a (mixed or pure) strategy.\nTo sum up: if one assumes that players are rational (and that the game is as\ndescribed), then one can conclude that no player plays a strategy that is strictly dominated\n(by some mixed or pure strategy), and this is all one can conclude.\nAlthough there are few strictly dominated strategies-and thus one can conclude\nlittle from the assumption that players are rational-in general, there are interesting\ngames in which this weak assumption can lead to counterintuitive conclusions. For\nexample, consider the well-known Prisoners' Dilemma game, introduced in Chapter 1:\n1 \\ 2 Cooperate Defect\nCooperate\nDefect\nClearly, Cooperate is strictly dominated by Defect, and hence we expect each player to\nplay Defect, assuming that the game is as described and players are rational. Some found\nthe conclusion counterintuitive because if both players play Cooperate, the outcome\nwould be much better for both players.\n3If you like mathematical challenges try to prove this statement.\n\n4.2. DOMINANT-STRATEGY EQUILIBRIUM\n4.2\nDominant-strategy equilibrium\nThis section introduces two concepts of dominance, one is stronger than the other. It\nthe uses the weak dominance to define dominant-strategy equilibrium.\nDefinition 4.3 A strategy\n∗ is a strictly dominant strategy for player if and only if\n\n∗ strictly dominates all the other strategies of player .\nFor example, in the prisoners' dilemma game, Defect strictly dominates the only other\nstrategy of Cooperate. Hence, Defect is a strictly dominant strategy. If is rational and\nhas a strictly dominant strategy ∗\n, then he will not play any other strategy. In that\ncase, it is reasonable to expect that he will play\n∗ .\nThe problem is that there are only few interesting strategic situations in which play\ners have a strictly dominant strategies. Such situations can be analyzed as individual\ndecision problems. A slightly weaker form of dominance is more common, especially in\ndynamic games (which we will analyze in the future) and in situation that arise in struc\ntured environments, such as under suitably designed trading mechanisms as in auctions.\nThis weaker form is called weak dominance:\nDefinition 4.4 A strategy ∗\nweakly dominates if and only if\n(\n∗ -) ≥ (-)∀- ∈ -\nand\n(\n∗ -) (-)\nfor some - ∈ -.\nThat is, no matter what the other players play, playing\n∗ is at least as good as\nplaying , and there are some contingencies in which playing\n∗ is strictly better than\n. In that case, if rational, would play only if he believes that these contingencies\nwill never occur. If he is cautious in the sense that he assigns some positive probability\nfor each contingency, then he will not play . This weak dominance is used in the\ndefinition of a dominant strategy:\nDefinition 4.5 A strategy\n∗ of a player is a (weakly) dominant strategy if and only\nif\n∗ weakly dominates all the other strategies of player .\nWhen there is a weakly dominant strategy, if the player is rational and cautious,\nthen he will play the dominant strategy.\n\nCHAPTER 4. DOMINANCE\nExample:\n1\\2\nwork\n\nhard\n\nshirk\n\n(4.2)\nhire\ndon't hire\n2 2\n1 3\n0 0\n0 0\nIn this game, player 1 (firm) has a strictly dominant strategy: \"hire.\" Player 2 has\nonly a weakly dominated strategy. If players are rational, and in addition Player 2 is\ncautious, then Player 1 hires and Player 2 shirks.\nWhen every player has a dominant strategy, one can make a strong prediction about\nthe outcome. This case yields the first solution concept in the course.\nDefinition 4.6 A strategy profile ∗ = (1\n∗2\n∗\n∗ ) is a dominant strategy equilibrium,\nif and only if for each player , ∗\nis a weakly dominant strategy.\nAs an example consider the Prisoner's Dilemma.\n1 \\ 2 Cooperate Defect\nCooperate\nDefect\n5 5\n0 6\n6 0\n1 1\nDefect is a strictly dominant strategy for both players, therefore (Defect, Defect) is a\ndominant strategy equilibrium. Note that dominant strategy equilibrium only requires\nweak dominance. For example, (hire, shirk) is a dominant strategy equilibrium in game\n(4.2).\nWhen it exists, the dominant strategy equilibrium has an obvious attraction.\nIn\nthat case, rational cautious players will play the dominant strategy equilibrium. Unfor\ntunately, it does not exist in general.\nFor example, consider the Battle of the Sexes\ngame:\nopera football\nopera\nfootball\n3 1\n0 0\n0 0\n1 3\nClearly, no player has a dominant strategy: opera is a strict best reply to opera and\nfootball is a strict best reply to football. Therefore, there is no dominant strategy\nequilibrium.\n\n4.3. EXAMPLE: SECOND-PRICE AUCTION\n4.3\nExample: second-price auction\nAs already mentioned, under suitably designed trading mechanisms, it is possible to\nhave a dominant strategy equilibrium. Such mechanisms are desirable for they give\nthe economic agents strong incentive to play a particular strategy (which is presumably\npreferred by the market designer) and eliminate the agents' uncertainty about what the\nother players play, as it becomes irrelevant for the agent what the other players are\ndoing. The most famous trading mechanism with dominant-strategy equilibrium is the\nsecond-price auction.\nThere is an object to be sold through an auction. There are two buyers. The value\nof the object for any buyer is , which is known by the buyer . Each buyer submits\na bid in a sealed envelope, simultaneously. Then, the envelopes are opened, and the\nbuyer ∗ who submits the highest bid\n∗ = max {12}\ngets the object and pays the second highest bid (which is with 6= ∗). (If two or\nmore buyers submit the highest bid, one of them is selected by a coin toss.)\nFormally the game is defined by the player set = {12}, the strategies , and the\npayoffs\n⎧\n⎪\n⎨\n⎪\n⎩\n-\nif\n(12) =\n( - ) 2 if =\nif\nwhere 6\n.\n=\nIn this game, bidding his true valuation is a dominant strategy for each player\n\nTo see this, consider the strategy of bidding some other value\nshow that is weakly dominated by bidding . Consider the case\n6= . We want to\n.\n. If the other\n\nand . If\nplayer bids some\n, player would get - under both strategies\n\n, player would get\nunder both strategies\n\n- 0, while yields only ( - ) 2. Likewise, if\nthe other player bids some\nand .\n≥\n\nBut if = 0\n, bidding yields\n\nweakly dominates\nyields only 0. Therefore, bidding\n, bidding yields - 0, while\n\nis similar, except for when\n\nyields negative payoff - 0. Therefore, bidding is dominant\nThe case\n, bidding\n\n.\n\nyields , while\n\nstrategy. Since this is true for each player , (12) is a dominant-strategy equilibrium.\n\nCHAPTER 4. DOMINANCE\nExercise 4.1 Extend this to the -buyer case.\n4.4\nExercises with Solutions\n1. [Homework 1, 2011] There are students in a class. Simultaneously, each student\nchooses an effort level incurring cost 2\nfor some 0. The student receives\nan increase in his grade from his own effort, but this also raises the curve and\ndecreases the grade of every other student by for some 0. The resulting\nutility of player is\nX\n(1) = -\n- 2\n\n6=\nAll of the above is common knowledge.\n(a) Write this game in normal form.\nSolution: The set of players is = {1}. For each ∈ , = R, and\n: R → R is given in the question.\n(b) Is there a dominant strategy equilibrium? If so, compute the dominant strat\negy equilibrium.\nSolution: For any - = (1-1+1), the best response can\nbe found by\n= 1 - 2 = 0\n\nThe solution to this equation is the unique best response:\n∗ =\n\nSince\n∗ is best response to every strategy,\n∗ dominates any other strategy\n:\n(\n∗ -) (-)\n(∀-)\n¡\n¢\nTherefore,\n1 1\nis the dominant-strategy equilibrium.\n(c) Compute the (1) vector that maximizes the sum 1 (1) +\n· · ·+ (1) of grades. Comparing your answers to (b) and (c), briefly\ndiscuss your findings.\n\n4.4. EXERCISES WITH SOLUTIONS\nSolution: The total utility is\nA\n!\nX\nX\nX\nX\n=\n-\n-\n= (1 - (- 1) )\n-\n\n6=\n\nThe first order condition is\n= 1 - (- 1) - 2 = 0\n\nTherefore, is maximized at\nμ\n¶\n1 - (- 1)\n1 - (- 1)\n\nNote that the the dominant-strategy equilibrium corresponds to the case\n= 0, ignoring the negative impact on the other students' grades. The\ndominant strategy equilibrium always yield a higher effort than the socially\noptimal level that maximizes . This is a version of the commons problem,\na generalization of the Prisoners' Dilemma game. In commons problem, the\nplayers' efforts have positive impact on the others payoffs, as they produce\nsome public good. In that problem, equilibrium effort is lower than the opti\nmal one. Here, the impact is negative, and students work harder than socially\noptimal. (Professors want them to work even harder!)\n2. [Homework 1, 2010] Consider an auction in which identical objects are sold to\nbidders. Each bidder needs only one object and has a valuation for\nthe object. In the auction, simultaneously, every bidder bids . The highest\nbidders win. Each winner gets one object and pays the +1 highest bidder (i.e.,\nthe price is the highest bid among the bidders who do not get an object). (The\nties are broken by a coin toss.) Each of the losing bidders gets a gift of value\nfor their participation. (The winners do not get a gift.) Show that the game has\na dominant strategy equilibrium, and compute the equilibrium.\nSolution: The dominant strategy equilibrium is (1 - 2 - - ). To\nshow that ∗\n= - is dominant strategy, consider any 6= ∗\n. Consider the\ncase,\n∗ . Towards showing that ∗\nweakly dominates , take any bid - by\nthe others. Relabeling the players, one can take = and 1 ≥ 2 ≥ · · · ≥ -1.\n\nCHAPTER 4. DOMINANCE\nIf , then under both bids and ∗\n, wins the object and pays price = ,\nenjoying the payoff level of - . If , then under both bids and\n∗ ,\nloses the object and gets . Consider the case, ∗\n. In that case, under\n∗\n∗\n∗\n, wins and gets - . Under , he gets . But, since = - , bid\nyields a higher payoff: - . The cases of ties and ∗\nare dealt similarly.\n3. For the following strategy space and utility pairs, check if best response exists for\nplayer 1, and compute it when it exists.\nNote: In general a best response exists if 1 is compact (i.e. closed and bounded for\nall practical purposes) and is continuous in . In particular, it exists whenever\n1 is finite. Fortunately it may exists even if the above conditions fail.\n(a) 1 = [01]; 1 (1) = 1 if 1 1 and 1 (1) = 0.\nSolution: Clearly, there is no best response. Plot a graph for illustration.\n(Continuity fails here.)\n(b) 1 = 2 = [0inf); 1 (1) = 12.\nSolution: Everything is a best response when 2 = 0, and nothing is a best\nresponse when 2 6= 0. Compactness fails. This also shows that there can be\nmore than one best response.\n(c) Partnership Game: 1 = 2 = [0inf); 1 (1) =\n2 - 2 where 0.\nSolution: Best response exists although 1 is not compact. Take the partial\nderivative with respect to 1 and set it equal to zero in order to obtain the\n\"first-order condition\" for maximum:\n1 = 2 - 21 = 0\nThat is, the best response is\n1 = 22\nOne does not need to check the second order condition because 1 is concave.\n(d) First-Price Auction: 1 = 2 = [0inf);\n- 1\nif 1 2\n1 (12) = (- 1) 2 if 1 = 2\notherwise\n⎧\n⎪\n⎨\n⎪\n⎩\n\n4.5. EXERCISES\nwhere 0.\nSolution: Everything is a best response when 2 = ; any 1 2 is a best\nresponse when 2 , and nothing is a best response when 2 . Continuity\nfails.\n(e) Price Competition: 1 = 2 = [0inf);\n1 (12) =\n⎧\n⎪\n⎨\n⎪\n⎩\n(1 - 1) 1\nif 1 2\n(1 - 1) 12 if 1 = 2\notherwise.\nSolution: Everything is a best response when 2 = 0, and nothing is a best\nresponse when 2 6\n.\n= 0 Continuity fails.\n(f) Quantity Competition: 1 = 2 = [0inf); 1 (12) = (1 - 1 - 2) 1 - 1.\nSolution: There is a unique best response. As in part (c), the first-order\ncondition is\n1 = 1 - 21 - 2 - = 0\nyielding\n1 = 1 - 2 -\n\n4.5\nExercises\n1. Show that there cannot be a dominant strategy in mixed strategies.\n2. [Homework 1, 2007] The Federal Government is to decide whether to construct\na road between the towns Arlington and Belmont. The values of the road for\nArlington and Belmont are ≥ 0 and ≥ 0, respectively. The cost of constructing\nthe road is 0. The Federal Government wants to construct the road if and\nonly if + ≥ . The values and are known by the towns, but not by the\ngovernment; is known by everybody. To learn these values, the government asks\neach town to submit the value of the road for the town. Given the submitted\nvaluations and , which need to be non-negative, the government constructs\nthe bridge if and only if + ≥ and tax Arlington and Belmont ()\n\nCHAPTER 4. DOMINANCE\nand (), respectively, where\n(\n- if + ≥ and\n()\n=\notherwise\n(\n- if + ≥ and\n()\n=\notherwise.\nFind the dominant strategy equilibrium; show that the strategies that you identify\nare indeed dominant.\n3. [Homework 1, 2006] There are players and an object. The game is as follows:\n- First, for each player , Nature chooses a number from {01299},\nwhere each number is equally likely, and reveals to player and nobody\nelse. ( is the value of the object for player .)\n- Then, each player simultaneously bids a number .\n- The player who bids the highest number wins the object and pays where\nis the highest number bid by a player other than the winner. (If two or more\nplayers bid the highest bid, the winner is determined by a coin toss among\nthe highest bidders.) The payoff of player is ( - ) if he is the winner and\n0 otherwise.\n(a) Write this game in normal form. That is, determine the set of strategies for\neach player, and the payoff of each player for each strategy profile.\n(b) Show that there is a dominant strategy equilibrium. State the equilibrium.\n4. [Homework 1, 2010] Alice, Bob, and Caroline are moving into a 3-bedroom apart\nment (with rooms, named 1, 2, and 3). In this problem we want to help them to\nselect their rooms. Each roommate has a strict preference over the rooms. The\nroommates simultaneously submit their preferences in an envelope, and then the\nrooms are allocated according to one of the following mechanisms. For each mech\nanism, check whether submitting the true preferences is a dominant strategy for\neach roommate.\n\n4.5. EXERCISES\nMechanism 1 First, Alice gets her top ranked room. Then, Bob gets his top\nranked room among the remaining two rooms. Finally, Caroline gets the\nremaining room.\nMechanism 2 Alice, Bob, and Caroline have priority scores 03, 0, and -03,\nrespectively; the priority score of a roommate is denoted by . For each\nroommate and room , let rank be 3 if ranks highest, 2 if ranks\nsecond highest, and 1 if ranks lowest. Write = + for the aggregate\nscore. In the mechanism, Room 1 is given to the roommate with the highest\naggregate score 1. Then, among the remaining two, the one with the highest\naggregate score 02 gets Room 2, and the other gets Room 3.\n\nCHAPTER 4. DOMINANCE\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 4 Lecture Slides",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/27c874fec3bb42205e2c17145fa41b06_MIT14_12F12_slides4.pdf",
      "content": "Lecture 4\nDominance\n14.12 Game Theory\nMuhamet Yildiz\n\nRoad Map\n1. Dominance & Rationality\n2. Dominant-Strategy Equilibrium\n3. 2nd price auction\n\nPrisoners' Dilemma\nCooperate\nDefect\nCooperate\n(5,5)\n(0,6)\nDefect\n(6,0)\n(1,1 )\n\nDominance\nDefinition: A pure strategy Sj * strictly\ndominates Sj if and only if\nu(s*\nI\nI .,s - I .»u(s,s\nI\nI\n- [ .) \\/s.\n- I\nA mixed strategy (Jj strictly dominates Sj iff\nO)SiJ )UJSil' S_i) + ... + (Ji (Sik )ui (Sik' S_i ) > Ui (Si' S_i )\n'lis - / .\nA rational player never plays a strictly\ndominated strategy.\n\nPrisoners' Dilemma\nCooperate\nDefect\nCooperate\n(5,5)\n(0,6)\nDefect\n(6,0)\n(1,1 )\n\nv M = 0\nV\n= 2p-(I-p) = 3p-1\nA Game\nT\nVB = -p+2 (I-p) = 2-3p\nV\nL\nR\nT\n(2,0)\n(-1,1)\nM\n(0,10) (0,0)\nB\n(-1,-6) (2,0)\n-I ~\n_______\n-------'\no\np\nP\nI-p\n\nWeak Dominance\nDefinition: A pure strategy Sj * weakly dominates Sj\nif and only if\nu(s*,s\nI\nI\n- I .) > u I .(s,s\nl\n- l .) \\is.\n- I\nand at least one of the inequalities is strict. A mixed\nstrategy a/ weakly dominates Sj iff\nand at least one of the inequalities is strict.\nIf a player is rational and cautious (i.e., he assigns\npositive probability to each of his opponents'\nstrategies), then he will not playa weakly\ndominated strategy.\n\nDominant-strategy equilibrium\nDefinition: A strategy Sj * is a dominant\nstrategy iff Sj * weakly dominates every\nother strategy Sj.\nDefinition: A strategy profile s* is a\ndominant-strategy equilibrium iff Sj* is a\ndominant strategy for each player i.\n\nPrisoners' Dilemma\nCooperate\nDefect\nCooperate\n(5,5)\n(0,6)\n..J..>\n~ 7\nDefect\n(6,0)\nr(c l,l~\n\"-\n./\n\nSecond-price auction\n-\n-\nf\n-\ns\n- i\nt\ns\nN = {1,2} buyers;\nThe value of the house\nor buyer i is Vi;\nEach buyer i\nimultaneously bids bi;\n* with bi> = max bi gets\nhe house and pays the\necond highest bid\np = maxj*ibjo\nCourtesy of Machovka on OpenClipart.org.\n\n2nd price Auction\n- Strategies:\nb E\ni\n[0,(0)\n- Payoffs:\nUi (bi,b) = Vi - bj\nifb·\nI > bJ ·\n= (Vi - b)12\nifb·\nI = b· J\n= °\notherwise.\n\nb = Vi\ni\nis a dominant strategy\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    },
    {
      "category": "Lecture Notes",
      "title": "Session 5 Lecture Notes",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/14-12-economic-applications-of-game-theory-fall-2012/2bdf274a0b9a16d2dfe60c49add6fe92_MIT14_12F12_chapter5.pdf",
      "content": "Chapter 5\nRationalizability\nA player is said to be rational if he maximizes expected value of his utility function, as\ndescribed in the game. The previous lecture explored the implications of rationality. This\nwas captured by dominance. In natural strategic environments, this often yields weak\npredictions. Moreover the games in which dominance alone leads to a sharp prediction\n(e.g. the games with a dominant strategy equilibrium) are not interesting for game\ntheory because in such a game each player's decision can be analyzed separately without\nrequiring a game theoretical analysis.\nNevertheless, in definition of a game, one assumes much more than rationality of the\nplayers. One further assumes that it is common knowledge that the players are rational.\nThat is, everybody is rational; everybody knows that everybody is rational; everybody\nknows that everybody knows that everybody is rational ... up to infinity. If some of\nthese assumptions fail, then one would need to consider a different game, the game\nthat reflects the failure of those assumptions. This lecture explores the implications\nof the common knowledge of rationality. These implications are precisely captured by\na solution concept called rationalizability, which is equivalent to iterative elimination\nof strictly dominated strategies. In this way, rationalizability precisely captures the\nimplications of the assumptions embedded in the definition of the game.\n\nCHAPTER 5. RATIONALIZABILITY\n5.1\nDefinition and Illustration\nIt is useful to illustrate the solution concept on the leading example of the previous\nsection: (4.1). We have seen there that strategy is strictly dominated (by a mixture\nof and ) and hence it cannot be a best response to any belief. Hence, rationality of\nplayer 1 implies that Player 1 does not play . No other strategy is strictly dominated.\nFor example, for Player 2, her both strategies can be a best reply. If she thinks that\nPlayer 1 is not likely to play , then she must play , and if she thinks that it is very\nlikely that Player 1 will play , then she must play . Hence, rationality of Player 2\ndoes not put any restriction on her behavior. But, what if she thinks that it is very\nlikely that player 1 is rational (and that his payoff are as in (4.1))? In that case, since\na rational player 1 does not play , she must assign very small probability for player 1\nplaying . In fact, if she knows that player 1 is rational, then she must be sure that he\nwill not play . In that case, being rational, she must play . In summary, if Player\n2 is rational and she knows that player 1 is rational, then she must play R.\nNotice that we first eliminated all of the strategies that are strictly dominated\n(namely ), then taking the resulting game, we eliminated again all of the strate\ngies that are strictly dominated (namely ). This is called twice iterated elimination of\nstrictly dominated strategies. In general, if a player is rational and knows that the other\nplayers are also rational (and the payoffs are as given), then he must play a strategy\nthat survives twice iterated elimination of strictly dominated strategies.\nUnder further rationality assumptions, one can further iteratively eliminate strictly\ndominated strategies (if there remains any). In example (4.1), recall that rationality\nof Player 1 requires him to play or , and knowledge of the fact that Player 2 is\nalso rational does not put any restriction on his behavior-as rationality itself does not\nrestrict Player 2's behavior. Now, assume that Player 1 also knows that Player 2 is\nrational and that Player 2 knows that Player 1 is rational (and that the game is as in\n(4.1)). Then, as the above analysis shows, Player 1 must know that Player 2 will play\n. In that case, being rational he must play .\nThis analysis yields a mechanical procedure to analyze games, -times Iterated Elim\nination of Strictly Dominated Strategies: eliminate all the strictly dominated strategies\nand iterate this -times. In this procedure, one eliminates all the strictly dominated\nstrategies and iterates this times.\n\n5.1. DEFINITION AND ILLUSTRATION\nGeneral fact: If (1) every player is rational, (2) every player knows that every\nplayer is rational, (3) every player knows that every player knows that every player is\nrational, . . . and () every player knows that every player knows that . . . every player is\nrational, then every player must play a strategy that survives -times iterated elimination\nof strictly dominated strategies.\nCaution: Two points are crucial for the elimination procedure:\n1. One must eliminate only the strictly dominated strategies. One cannot eliminate\na strategy if it is weakly dominated but not strictly dominated. For example, in\nthe game\n\n1 1 0 0\n0 0 0 0\n() is a dominant strategy equilibrium, but no strategy is eliminated because\ndoes not strictly dominate and does not strictly dominate .\n2. One must eliminate the strategies that are strictly dominated by mixed strategies\n(but not necessarily by pure strategies). For example, in the game in (4.1),\nmust be eliminated although neither nor dominates .\nWhen there are only finitely many strategies, this elimination process must stop at\nsome . That is, at some there will be no dominated strategy to eliminate. In that\ncase, iterating the elimination further would not have any effect.\nDefinition 5.1 The elimination process that keeps iteratively eliminating all strictly\ndominated strategies until there is no strictly dominated strategy is called Iterated Elim\nination of Strictly Dominated Strategies; one eliminates indefinitely if the process does\nnot stop. A strategy is said to be rationalizable if and only if it survives iterated elimi\nnation of strictly dominated strategies.\nAs depicted in Figure 5.1, the procedure is as follows. Eliminate all the strictly\ndominated strategies. In the resulting smaller game, some of the strategies may become\nstrictly dominated. Check for those strategies. If there is one, apply the procedure one\nmore time to the smaller game. This continues until there is no strictly dominated strat\negy; the elimination continues indefinitely if the process does not stop. The remaining\n\nCHAPTER 5. RATIONALIZABILITY\nEliminate all the strictly\ndominated strategies.\nYes\nAny dominated strategy\nIn the new game?\nNo\nRationalizable strategies\nFigure 5.1: Algorithm for rationalizability\nstrategies are called rationalizable. When the game is finite, the order of eliminations\ndoes not matter for the resulting outcome. For example, even if one does not eliminate\na strictly dominated strategy at a given round, the eventual outcome is not affected by\nsuch an omission. In that case, it is also okay to eliminate a strategy whenever it is\ndeemed to be strictly dominated.\nTheorem 5.1 If it is common knowledge that every player is rational (and the game\nis as described), then every player must play a rationalizable strategy. Moreover, any\nrationalizable strategy is consistent with common knowledge of rationality.\nA general problem with rationalizability is that there are usually too many rational\nizable strategies; the elimination process usually stops too early. In that case one cannot\nmake much prediction based on such analysis. For example, in the Matching Pennies\ngame\n1\\2\n\n-11\n1-1\n\n1-1\n-11\nevery strategy is rationalizable, and we cannot say what the players will do.\n\n5.2. EXAMPLE: BEAUTY CONTEST\n5.2\nExample: Beauty Contest\nConsider an -player game in which each player has strategies ∈ [0100], and payoff\nμ\n¶2\n2 1 + · · ·\n(1) = - -\n\nNotice that, in this game, each player tries to play a strategy that is equal to two thirds of\nthe average strategy, which is also affected by his own strategy. Each person is therefore\ninterested guessing the other players' average strategies, which depends on the other\nplayers' estimate of the average strategy.\nOne iteratively eliminate strictly dominated strategies as follows. First, since each\nstrategy must be less than or equal to 100, the average cannot exceed 100, and hence\nany strategy 2003 is strictly dominated by 200/3. Indeed, any strategy 1 is\nstrictly dominated by 1 where1\n2 (- 1)\n1 =\n3- 2\nTo show that 1 is strictly dominated by 1, we fix any (1-1+1)\nand show that\n¡\n¢\n(1-1+1) 1-11+1\n(5.1)\nBy taking the derivative of with respect to , we obtain\nμ\n¶ μ\n¶\n\n2 1 + · · ·\n= -2\n1 -\n-\n\nClearly, 0 if\nμ\n¶\n2 1 + · · ·\n-\n\nwhich would be the case if\nX\n\n≡ ∗\n(5.2)\n3- 2 6=\nHence, is strictly increasing when ∗ and strictly decreasing when ∗. On\nP\nthe other hand, since each ≤ 100, the sum\n6= is less than or equal to (- 1) 100.\nHence, it suffices that\n\n(- 1) 100 = 1\n3- 2\n1Here 1 is just a real number, where superscript 1 indicates that we are in Round 1.\n\nCHAPTER 5. RATIONALIZABILITY\nTherefore, for any 1, we have ∗ ≤ 1 Since we have established that is a\nstrictly decreasing function of in this region, this proves that (5.1) is satisfied. This\nshows that all the strategies 1 are eliminated in the first round.\nOn the other hand, each ≤ 1 is a best response to some (1-1+1)\nwith\nX\n=\n\n3- 2 6=\nTherefore, at the end of the first round the set of surviving strategies is [01].\n£\n¤\nNow, suppose that at the end of round , the set of surviving strategies is 0 for\nsome number . By repeating the same analysis above with instead of 100, we can\n£\n¤\nconclude that at the end of round +1, the set of surviving strategies is 0+1 where\n2 (- 1)\n+1 =\n\n3- 2\nThe solution to this equation with 0 = 100 is\n∙\n\n2 (- 1)\n=\n3- 2\nTherefore, for each , at the end of round , a strategy survives if and only if\n∙\n\n2 (- 1)\n0 ≤ ≤\n3- 2\nSince\n∙\n\n2 (- 1)\nlim\n100 = 0\n→inf\n3- 2\nthe only rationalizable strategy is = 0.\nNotice that the speed at which goes to zero determines how fast we eliminate\nthe strategies. If the elimination is slow (e.g. when 2 (- 1) (3- 2) is large), then\nmany strategies are eliminated at very high iterations. In that case, predictions based on\nrationalizability will heavily rely on strong assumptions about rationality, i.e., everybody\nknows that everybody knows that ... everybody is rational. For example, if the is\nlarge or the ratio 23 is replaced by a number close to 1, the elimination is slow and the\npredictions of rationalizability are less reliable. On the other hand, if is small or the\nratio 23 is replaced by a small number, the elimination is fast and the predictions of\nrationalizability are more reliable. In particular, the predictions of rationalizability for\nthis game is more robust in a small group than a larger group.\n\n5.2. EXAMPLE: BEAUTY CONTEST\nIt is important that one analyzes the game that describes the actual situation. For\nexample, when the above game is played in classroom, there are often some students who\nwould rather move the mean in an unexpected direction and upset the other students\nthan get the prize of being closest to the two thirds of the average. Those students\nbid 100 instead. In such experiments, the resulting outcome is often different from the\nrationalizable solution of 0 for the above game, which does not take into account the\nexistence of such students. In fact, some students bid 0 in the first time they play\nthe game and switch to relatively higher bids in the follow up games. To analyze that\nsituation, consider the following variation.\nFor example, in the beauty contest game suppose that there are mischievous\nstudents with utility function\nμ\n¶2\n1 + · · ·\n(1) = -\n\nThe remaining -students are as before. The best response of a mischievous student\nP\nis 0 if the expected value of\n(-1) is greater than 50, and it is 100 otherwise.\n=\nHence at the first round all strategies other than 0 and 100 are eliminated for the\nmischievous students.\nFor each round there are such that survives rounds of iterated elimination for\na regular student iff ≤ ≤ Note that for = 0 = 0 and = 100. In the\nearlier rounds, both 0 and 100 are available for mischievous students, and in that case\nthe lower bound remains = 0 because 0 is a best response to 0 for regular students.\nP\nTo compute the upper bound, fix a regular student . The expected value of\n=\n\n-1\ncan take any value in [0100+ (--1) -1], where 100+ (--1)\nis\nobtained by taking the highest possible bid for each remaining students, mischievous\n-1\nstudents playing 100 and (--1) regular students playing\n. The best reply to\nthis value give us the upper bound:\n=\n[100+ (--1) -1]\n(5.3)\n3-2\nP\nwhich is obtained by substituting 100+ (--1) -1 for\nin 5.2. As above,\n=\nall is eliminated. Note that as →inf converges to\n· 100\ninf\n3-2\n\n=\n=\n(5.4)\n1 -3\n-2 (--1)\n+ 2\n\nCHAPTER 5. RATIONALIZABILITY\n(One can obtain inf by substituting inf for and -1 in 5.3.)\nThe lower bound depends on whether 0 remains a best response to a mischievous\nstudent. This is the case when\n( -) + 100( -1) ≥50\n-1\nIf ≥ 4, then inf satisfies the above inequality. In that case, all satisfy the\ninequality, and neither 0 nor 100 is eliminated for the mischievous students. In that case,\nthe rationalizable strategies are {0 100} for mischievous students and [0 200(+2)]\nfor the regular students. If ≥4, then inf fails the above inequality. Then, there\nexists ∗ such that fails the inequality for every ≥∗ and satisfies the inequality\nfor all ∗ In that case at round ∗ + 1 0 is eliminated for mischievous students.\nConsequently, at round = ∗ + 2 and after, for any regular student , the lowest value\nP\nfor\n=\nis 100 + ( - -1)-1 As in the above analysis, the best response to\n\nthis yields the lower bound at :\n=\n[100 + ( - -1)-1]\n(5.5)\n3 -2\nOf course, as →inf, converges to\ninf\ninf =\n=\n\n+ 2\nIn that case, the unique rationalizable strategy is 200( + 2) for regular students\nand 100 for the mischievous students. The rationalizable strategy is plotted in Figure\n2. Note that the mischievous students have a large impact. For example, when 10% of\nthe students are mischievous, the rationalizable strategy for regular students is 2012 ∼=\n16667 and the average rationalizable bid is 25.\n5.3\nExercises with Solution\n1. [Homework 2, 2011] Compute the set of rationalizable strategies in the following\ngame.\n\n3 1\n1 0\n0 2\n1 1\n1 0\n0 10\n1 0 0 10\n2 1\n1 0\n0 0\n0 0\n0 0 12 0 3 1\n0 0\n\n5.3. EXERCISES WITH SOLUTION\nFigure 5.2: Rationalizable strategy as a function of the fraction of the mischievous\nstudents\nSolution: For player 1, strategy is dominated by a mixed strategy that puts\nprobability 12 on and probability 1/2 on . No other strategy is dominated.\nAfter elimination of , strategies and become dominated; both and are\ndominated by any strategy that puts positive probabilities on and and zero\nprobability on and . Strategies and are eliminated in the second round. In\nthe next round, is eliminated because it becomes dominated by a mixed strategy\nthat puts probability 12 on and probability 1/2 on . The eliminations so far\nleaves the following strategies:\n\n3 1 0 2\n\n0 0 3 1\nOne can easily see that the strategy and then are eliminated next, yielding\n( ) as the only rationalizable strategies. The games with unique rationalizable\nstrategy are called dominance-solvable. We got one of them here.\n2. [Midterm 1, 2011] Compute the set of all rationalizable strategies in the following\n\nCHAPTER 5. RATIONALIZABILITY\ngame.\n\n0,3 0,1 3,0\n0,1\n3,0 0,2 2,4\n1,1\n2,4 3,2 1,2 10,1\n0,5 5,3 1,2 0,10\n(a) Solution: Strategy is strictly dominated by the mixed strategy 2 with\n2 () ∈ (13 12) and 2 () = 1 - 2 (). In the first round, is therefore\neliminated. (No other strategy is eliminated in that round.) In the second\nround, is strictly dominated by and eliminated. In the third round,\nis strictly dominated by 2 above and eliminated. In the fourth round, is\nstrictly dominated by and eliminated. There are no other elimination, and\nthe set of rationalizable strategies is { } × { }.\n3. [Midterm 1, 2001] Find all the pure strategies that are consistent with the common\nknowledge of rationality in the following game. (State the rationality/knowledge\nassumptions corresponding to each operation.)\n1\\2\n\n1 1 0 4 2 2\n2 4 2 1 1 2\n1 0 0 1 0 2\nSolution: Clearly, one needs to compute rationalizable strategies and state the\nunderlying rationalizability assumptions along the way.\nRound 1 For player 1, strictly dominates . Since Player 1 is rational, he\nwill not play , and we eliminate this strategy:\n1\\2\n\n1 1 0 4 2 2\n2 4 2 1 1 2\nRound 2 Since Player 2 knows that Player 1 is rational, he knows that\nPlayer 1 will not play . Given this, the mixed strategy that assigns prob\nability 1/2 to each of the strategies and strictly dominates . Since\n\n5.3. EXERCISES WITH SOLUTION\nPlayer 2 is rational, in that case, he will not play . We eliminate this\nstrategy:\n1\\2\n\n11 04\n24 21\nRound 3 Since Player 1 knows that Player 2 is rational and that Player\n2 knows that Player 1 is rational, he knows that Player 2 will not play\n. Given this, strictly dominates . Since Player 1 is rational, he will\nnot play , either. We are left with\n1\\2\n\n24 21\n\nRound 4 Since Player 2 knows that Player 1 is rational, and that Player\n1 knows that Player 2 is rational, and that Player 1 knows that\nPlayer 2 knows that Player 1 is rational, he knows that Player 1 will\nnot play or . Given this, strictly dominates . Since Player 2 is\nrational, he will not play , either. He will play .\n1\\2\n\nThus, the only strategies that are consistent with the common knowledge of\nrationality are for Player 1 and for Player 2.\n4. [Midterm 1, 2011] Compute the set of all rationalizable strategies in the following\ngame. Simultaneously, Alice and Bob select arrival times and , respectively,\nfor their meeting, where ∈ {012100}. The payoffs of Alice and Bob\nare\n(\n2 - ( - )2 if\n()\n=\n\n- ( - )2 otherwise\n(\n2 - ( - )2 if\n()\n=\n\n- ( - )2 otherwise,\nrespectively. [Note that and are integers between 0 and 100.]\n\nCHAPTER 5. RATIONALIZABILITY\nSolution: If the set of remaining strategies from the earlier rounds is {0max}\nfor some max 0, then the max is strictly dominated by max -1 and is eliminated.\n(Proof: For = max,\n(max - 1max) = 1 0 = (maxmax)\nand for any max,\n(max - 1) = - (max - 1 - )2 - (max - )2 = (max)\nshowing that max -1 strictly dominates max for Alice. The same argument applies\nfor Bob.)\nTherefore, we eliminate 100 in round 1, 99 in round 2, . . . , and 1 in round 100.\nThe set of rationalizable strategies is {0} for both players.\n5. [Midterm 1 make up, 2007] Consider the following game:\n1\\2\n\n01 010000\n(a) Compute the rationalizable strategies.\nSolution: First and then are eliminated. The rationalizable strategies\nare for Player 1 and for Player 2.\n(b) Now assume that players can tremble: when a player intends to play a strategy\n, with probability = 0001, Nature switches it to the other strategy 0. For\ninstance, if player 2 plays (or intends to play ), with probability ,\nis played, with probability 1 - , is played. Assume that the trembling\nprobabilities are independent. Compute the rationalizable strategies for this\nnew game.\nSolution: Taking into the Nature's move, the new game is as follows in\nnormal form:\n1\\2\n\n1 - 1 - + 100002\n1 - + 10000 (1 - )\n1 - + 10000(1 - )\n10000 (1 - )2 + 1 -\n\n5.4. EXERCISES\nTo see how the payoffs are computed consider (). If this strategy profile\nis intended, the outcome is () with probability (1 - )2 [nobody trem\nbles], () with probability (1 - ) [only Player 2 trembles], () with\nprobability (1 - ) [only Player 1 trembles], and () with probability 2\n[everybody trembles]. We mix the payoff vectors with the above probabili\nties to obtain the table. One can use the structure of payoffs to shorten the\ncalculations. For example, Player 1 gets 1 if he does not tremble and gets 0\notherwise, yielding 1 - .\nTo compute the rationalizable strategies, note that is still dominated by\nand is eliminated in the first round. In the second round, we cannot eliminate\n, however. Indeed, the payoffs from and are approximately 1 and 10,\nrespectively. Hence, is eliminated in the second round, yielding () as\nthe only rationalizable strategy profile.\nThis example shows that rationalizability may be sensitive to the possibility\nof trembling, depending on the relative magnitude of trembling probabilities\nand the payoff differences.\n5.4\nExercises\n1. [Homework 1, 2004] Consider the following game in normal form.\n\n0-1 44 00 20\n00 44 10\n20 13 13\n10 01 05\n(a) Iteratively eliminate all strictly dominated strategies; state the assumptions\nnecessary for each elimination.\n(b) What are the rationalizable strategies?\n\nCHAPTER 5. RATIONALIZABILITY\n2. Compute the set of rationalizable strategies in the following game:\n\n2 0\n2 4\n0 0 0 -1\n1 -2 -2 -2 4 2 0 1\n1 3\n0 0\n1 3 5 2\n0 5\n-1 0\n0 1 4 4\n3. [Midterm 1, 2000] Consider the following game.\n1\\2\n\n3 2 4 0 1 1\n2 0 3 3 0 0\n1 1 0 2 2 3\n(a) Iteratively eliminate all the strictly dominated strategies.\n(b) State the rationality/knowledge assumptions corresponding to each elimina\ntion.\n(c) What are the rationalizable strategies?\n4. [Homework 1, 2004] Consider the game depicted in Figure 5.3 in extensive form\n(where the payoff of player 1 is written on top, and the payoff of 2 is on the\nbottom).\n(a) Write this game in strategic form.\n(b) What are the strategies that survive the iterative elimination of weakly-\ndominated strategies in the following order: first eliminate all weakly-dominated\nstrategies of player 1; then, eliminate all the strategies of player 2 that are\nweakly dominated in the remaining game; then, eliminate all the strategies\nof player 1 that are weakly dominated in the remaining game, and so on?\n5. [Homework 1, 2001] Compute the set of rationalizable strategies in the following\ngame that is played in a class of students where ≥ 2: Without discussing with\nanyone, each student is to write down a real number ∈ [0 100] on a paper and\nsubmit it to the TA. The TA will then compute the average\n1 + 2 + · · · +\n=\n\n5.4. EXERCISES\nL\nR\nX\nl\nl\nr\na\nb\nr\n.5\nFigure 5.3:\nof these numbers. The students who submit the number that is closest to 3 will\nshare the total payoff of 100, while the other students get 0. Everything described\nabove is common knowledge. (Bonus: would the answer change if the students did\nnot know , but it were common knowledge that ≥ 2?)\n6. [Homework 2, 2011] There are students. Simultaneously, each student submits\na real number ∈ [0100] and each student receives the payoff of\nμ\n¶2\n(1) = 100 - - (1)\n\nwhere finds the median.\n(a) Write this game formally in normal form.\n(b) Compute the sets of rationalizable strategies and Nash equilibria.\n(c) Answer part (b) assuming that there are ∈ (0(- 1) 2) mischievous\nstudents with payoff ( - (1))2 .\n(d) Bonus: Answer part (c) for ∈ (2).\n\nCHAPTER 5. RATIONALIZABILITY\n7. [Midterm 1, 2007] Compute the set of all rationalizable strategies in Exercise 4 in\nSection 3.5.)\n8. [Midterm 1, 2005] Compute the set of all rationalizable strategies in the game in\nFigure 3.14. (See Exercise 2 in Section 3.5.)\n9. [Homework 1, 2001] Consider the game in Figure 5.4.\nL\nR\n(2,2)\nr\nl\n(0,0)\nu\n\n(1,3)\n(3,1)\n(3,3)\n(1,1)\nFigure 5.4:\n(a) Write this game in the strategic form.\n(b) What are the strategies that survive the iterative elimination of weakly-\ndominated strategies in the following order: first eliminate all weakly-dominated\nstrategies of player 1; then, eliminate all the strategies of player 2 that are\nweakly dominated in the remaining game; then, eliminate all the strategies\nof player 1 that are weakly dominated in the remaining game, and so on?\n10. [Homework 1, 2002] Consider the game depicted in Figure 5.5 in extensive form.\n(a) Write this game in strategic form.\n(b) What are the strategies that survive the iterative elimination of weakly-\ndominated strategies in the following order: first eliminate all weakly-dominated\nstrategies of player 1; then, eliminate all the strategies of player 2 that are\n\n5.4. EXERCISES\nL\nM\nR\nl\nr\nl\nr\na\nb\nc\nx\ny\nL\nM\nR\nl\nr\nl\nr\na\nb\nc\nL\nM\nR\nl\nr\nl\nr\na\nb\nc\nx\ny\nFigure 5.5:\nL\nR\nl\nr\nl\nr\nX\nY\nA\nB\nx\ny\nFigure 5.6:\nweakly dominated in the remaining game; then, eliminate all the strategies\nof player 1 that are weakly dominated in the remaining game, and so on?\n11. [Homework 1, 2006] Consider the game depicted in Figure 5.6 in extensive form.\n(a) Write this game in strategic form.\n(b) Iteratively eliminate all weakly dominated strategies.\n(c) What are the rationalizable strategies?\n12. Consider any collection of sets 1 ⊆ 1, . . . , ⊆ such that there exists no\n∈ that is strictly dominated when the others' strategies are restricted to be\n\nCHAPTER 5. RATIONALIZABILITY\nin -. That is, for every ∈ and every mixed strategy of player , there\nexists a strategy profile - of other players such that ∈ for every =6\nand\nX\n(-) ≥\n() (-)\n∈\nShow that each ∈ is rationalizable.\n13. Show that the set of rationalizable strategies satisfy the above property that no\nrationalizable strategy is dominated when others' strategies are resticted to be\nrationalizable.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\n14.12 Economic Applications of Game Theory\nFall 2012\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
    }
  ]
}